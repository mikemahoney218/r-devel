From murdoch.duncan at gmail.com  Mon Aug  1 00:57:38 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 31 Jul 2011 18:57:38 -0400
Subject: [Rd] Front ends handling help.search() results?
In-Reply-To: <CAFDcVCSqET-X08R-kf-ZZbaEYa1YAtG55M0Lg7iyfd6cYhdcFg@mail.gmail.com>
References: <4E32F7E3.4080604@gmail.com>
	<CAFDcVCSqET-X08R-kf-ZZbaEYa1YAtG55M0Lg7iyfd6cYhdcFg@mail.gmail.com>
Message-ID: <4E35DDE2.7080903@gmail.com>

On 11-07-31 12:32 PM, Henrik Bengtsson wrote:
> The R.rsp package has a proof of concept page:
>
> 1. library("R.rsp")
> 2. browseRsp(path="/R/help/")
> 3. At the bottom, there is a "help.search" form.  Type in search term,
> e.g. "svd".
>
> This is all web browser based, so it should be able to handle compiled
> vignettes (as long as there are valid paths/URL paths).

help.search() won't give the paths.  You can get those from the 
vignette() function, or by reading the <pkg>/Meta/vignette.rds database.

There will be code in R-devel to do this that you could copy, once I 
commit (maybe tonight).

Duncan Murdoch


From murdoch.duncan at gmail.com  Mon Aug  1 13:16:33 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 1 Aug 2011 07:16:33 -0400
Subject: [Rd] example package for devel newcomers
In-Reply-To: <201107311845.50264@spsconsultoria.com>
References: <201107311845.50264@spsconsultoria.com>
Message-ID: <4E368B11.8090209@gmail.com>

On 11-07-31 5:45 PM, Alexandre Aguiar wrote:
> Hi,
>
> I'd like to know whether there is a package (or more, of course) regarded
> as a good example that could be used also as an instructional tool for
> newcomers to R extensions development.

I don't think there is a canonical one; different people prefer 
different programming styles.

I'd suggest you find a package by an author where you understand the 
contents and like the style, and study that.  If it involves subject 
matter that interests you it will be easier to understand than if it's 
completely new.

Duncan Murdoch


From murdoch.duncan at gmail.com  Mon Aug  1 14:03:48 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 01 Aug 2011 08:03:48 -0400
Subject: [Rd] Front ends handling help.search() results?
In-Reply-To: <201107311634.55821.thomas.friedrichsmeier@ruhr-uni-bochum.de>
References: <4E32F7E3.4080604@gmail.com>	<201107301040.07068.thomas.friedrichsmeier@ruhr-uni-bochum.de>	<4E34289D.4030806@gmail.com>
	<201107311634.55821.thomas.friedrichsmeier@ruhr-uni-bochum.de>
Message-ID: <4E369624.7090208@gmail.com>

On 11-07-31 10:34 AM, Thomas Friedrichsmeier wrote:
> On Saturday 30 July 2011, Duncan Murdoch wrote:
>> I have not committed this code yet, because the new types of entries
>> could mess up existing front ends and I wanted to give people some
>> warning.  I expect I'll commit (to R-devel only) within a day or two.
>
> Many thanks for the warning! I have added (untested) support for the new
> result types in RKWard.

I've just committed the changes to R-devel.  Let me know if there is 
anything worse than what I described.

There were a lot of changes to the display of links in help.search() and 
related results, and it's possible I got some of them wrong.  (They are 
tricky because we still try to support static help, but I don't have 
that installed and haven't tested it.)  Please let me know if you come 
across any broken links that look like they are in base R.

Duncan Murdoch


From hadley at rice.edu  Mon Aug  1 16:02:59 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Mon, 1 Aug 2011 09:02:59 -0500
Subject: [Rd] [R] Save generic plot to file (before rendering to device)
In-Reply-To: <CABFfbXsfomX3yMuOax9K_evryQ=CXE7b7AhJ744Vwa_RbWVuxw@mail.gmail.com>
References: <1310400495706-3659999.post@n4.nabble.com>
	<067B2EEC-F9BC-4777-8366-6CB1D6D5F69D@comcast.net>
	<CABFfbXu_OnsymK4LJM8Bhg77Hoe+f3QCXK0=jm3mO16r__Z4HA@mail.gmail.com>
	<B37C0A15B8FB3C468B5BC7EBC7DA14CC6349B349DD@LP-EXMBVS10.CO.IHC.COM>
	<alpine.LFD.2.02.1107112146130.10467@gannet.stats.ox.ac.uk>
	<CABFfbXudx6jkeC_jvsicEmPjVHJB0f3-dptb8xs5Gjzc_8PmPA@mail.gmail.com>
	<4E21C7D5.4060506@statistik.tu-dortmund.de>
	<CABdHhvEuZHykKSuHLZBhNpTBVHScR7MDdeM+C3nANVESfXxDkg@mail.gmail.com>
	<4E21E189.6060806@statistik.tu-dortmund.de>
	<CABFfbXsfomX3yMuOax9K_evryQ=CXE7b7AhJ744Vwa_RbWVuxw@mail.gmail.com>
Message-ID: <CABdHhvG28Na2cRveLuVNnkuvUc32VeSszo2ABTRemd0YsE6LLg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110801/012db225/attachment.pl>

From asaguiar at spsconsultoria.com  Tue Aug  2 08:01:12 2011
From: asaguiar at spsconsultoria.com (Alexandre Aguiar)
Date: Tue, 2 Aug 2011 03:01:12 -0300
Subject: [Rd] example package for devel newcomers
In-Reply-To: <CAB9w6Xz=etsY70+ZkxJ5XRR5P9BKe6ehZqch9+bdqhzE6Ra2+Q@mail.gmail.com>
References: <201107311845.50264@spsconsultoria.com>
	<CAB9w6Xz=etsY70+ZkxJ5XRR5P9BKe6ehZqch9+bdqhzE6Ra2+Q@mail.gmail.com>
Message-ID: <201108020301.16636@spsconsultoria.com>

Em Segunda 01 Agosto 2011, voc? escreveu:
> Is there a preferred language you would like to use in your package
> development? I randomly downloaded packages until I found some that
> helped me along my way, and might be able to help you pick one. If you
> are just looking at building a package of R functions and data you
> have developed, possibly the following example will get you started
> till you feel comfortable with the "Writing R Extensions"
> documentation (http://cran.r-project.org/doc/manuals/R-exts.pdf):

Dan, your message is cool. Well, here is what my project is about: it is a 
package to embed php into R. Named Rphp for now. It is mostly done from 
scratch. I have loved R-exts.pdf. Great stuff.

Why embed php into R? My primary purpose is to use web content management 
systems (WCMS) ready and extensively tested code from R cgi scripts. 
Someone more experienced with php might think of other uses. My approach 
is RAD(ical) and innovative (IMextremelyHO :-D) because:
a) *any* php based WCMS can be used from R code with no php or html 
coding;
b) output fully compliant with the website appearance;
c) WCMS automatic upgrades and interfaces changes (skins or themes) will 
be so unlikey to cause need for maintenance in R cgi scripts;
d) R cgi scripts will not demand changes in php code;
e) the builtin php session support obviates the need for any special 
session coding by R (likely non-web) programmers;
f) potential for improved analysis of web databases and even of systems 
surveillance tasks.

During my explorations of the R interface for extensions and the time 
spent in this tiny project, some questions emerged.

1. my code uses no recursion but I do not really know what is inside php 
code. Stack size could be a concern. Has any of you there ever needed to 
allocate a new stack for a package? Is it better to wait for complaints 
(if anyone ever would like to try this package...)?

2. can R_registerRoutines be called more than once within the same library 
(the same DllInfo data) so that it can reconfigure itself on the fly?

3. Is it safe (I guess it is) to "re-export" a function pointer retrieved 
with R_GetCCallable?

4. when loading a second library (in this case libphp5.so) is it better to 
put it in the package library directory and load it using the 'char 
*path' member of DllInfo? Using a second library has implications:
a) a given R setup can be limited to the user space without root access;
b) in the case of desktops where someone might use Rphp, most systems do 
not have libphp5.so installed by default and installing it frequently 
means to install apache and all (many) related packages;
c) many sysadmins do not have root access but can compile their own php 
version;
d) building the libphp5.so may not be an easy task for many.

5. Similar to 3, is it safe to "export" functions of the second library? 
libphp5.so will not be registered to R and has some interesting functions 
that can be "exported" directly or as pointers within Rphp library. A 
stub function can be used.

6. related to 4, with the many machine architectures and operating systems 
around I think it is neither desirable nor feasible to distribute 
precompiled libphp5.so versions; the package itself can download (wget 
and curl are everywhere) and compile php. Compiling php is not a lengthy 
task (6m12.9s in my quadcore desktop) but is a lot tricky and demands 
several development packages not installed by default in desktop systems. 
Their installations would require root access. What is the suggested 
approach to deploy libphp5.so?

7. I do not know how to produce a version for windows if requested. I have 
only an old MSC++ 97 and lcc (current) and have xp in a virtual box. This 
concern includes php. Can I get help regarding windows in this list? It 
might mean actual work: adapting code, compiling, packaging, etc. Not 
sure what is needed.

8. system safety does not seem a concern regarding this use of php, but... 
Any suggestions?

I guess some manual steps will be necessary because of potential security 
breaches related to the use of a second library. Patching php to produce 
a special build to be used as the package library would not be a trivial 
task and would demand updates at every new php version. Something I can't 
assure I can do. And would have to distribute the whole php source code: 
still have to study php licensing scheme. 

BTW, I copied Rdynpriv.h by hand to my include path to get access 
to 'struct _DllInfo' definition. The R install process did not copy this 
file. Am I doing something wrong here?

Sorry for the lengthy message. Thanx for your help.

-- 


Alexandre

--
Alexandre Santos Aguiar, MD, SCT
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 198 bytes
Desc: This is a digitally signed message part.
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110802/1f8cc52a/attachment.bin>

From drf28 at cornell.edu  Mon Aug  1 15:46:16 2011
From: drf28 at cornell.edu (Daniel Fuka)
Date: Mon, 1 Aug 2011 09:46:16 -0400
Subject: [Rd] example package for devel newcomers
In-Reply-To: <201107311845.50264@spsconsultoria.com>
References: <201107311845.50264@spsconsultoria.com>
Message-ID: <CAB9w6Xz=etsY70+ZkxJ5XRR5P9BKe6ehZqch9+bdqhzE6Ra2+Q@mail.gmail.com>

Hi Alexandre,

Is there a preferred language you would like to use in your package
development? I randomly downloaded packages until I found some that
helped me along my way, and might be able to help you pick one. If you
are just looking at building a package of R functions and data you
have developed, possibly the following example will get you started
till you feel comfortable with the "Writing R Extensions"
documentation (http://cran.r-project.org/doc/manuals/R-exts.pdf):

# Start R
dir.create("mynewpackage")
setwd("mynewpackage/")
rm(list=objects())
mydata<-data.frame(a=c(1,3,5),b=c(3,6,8))
mystat<-function(x,y){x*y}
package.skeleton(list=objects(),name="mypackage")
list.files()
list.files("mypackage/")
system("R CMD build mypackage")
system("R CMD check mypackage_1.0.tar.gz")
# You will see an error here which directs you to look at the .Rcheck
directory...
edit(file="mypackage.Rcheck/00install.out")
# indicates you need to fill in the title fields of the man pages need
to be filled in.

This should give you a start and get you using the Writing R
Extensions docs. If you need more help, feel free to contact me
outside of the list. Don't worry, the first one might be confusing,
but after the first, they become fun.

Enjoy,
dan


On Sun, Jul 31, 2011 at 5:45 PM, Alexandre Aguiar
<asaguiar at spsconsultoria.com> wrote:
> Hi,
>
> I'd like to know whether there is a package (or more, of course) regarded
> as a good example that could be used also as an instructional tool for
> newcomers to R extensions development.
>
> Thanks.
>
> --
>
>
> Alexandre
>
> --
> Alexandre Santos Aguiar, MD, SCT
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From landronimirc at gmail.com  Tue Aug  2 13:55:01 2011
From: landronimirc at gmail.com (Liviu Andronic)
Date: Tue, 2 Aug 2011 13:55:01 +0200
Subject: [Rd] 'data.frame' method for base::rep()
Message-ID: <CABxs9VmouqjKpNvkzG5emHevXQtTRo9f81nxhOS9FvBo5V4maw@mail.gmail.com>

Dear R developers
Would you consider adding a 'data.frame' method for the base::rep
function? The need to replicate a df row-wise can easily arise while
programming, and rep() is unable to handle such a case. See below.
> x <- iris[1, ]
> x
  Sepal.Length Sepal.Width Petal.Length Petal.Width Species
1          5.1         3.5          1.4         0.2  setosa
> rep(x, 2)
$Sepal.Length
[1] 5.1

$Sepal.Width
[1] 3.5

$Petal.Length
[1] 1.4

$Petal.Width
[1] 0.2

$Species
[1] setosa
Levels: setosa versicolor virginica

$Sepal.Length
[1] 5.1

$Sepal.Width
[1] 3.5

$Petal.Length
[1] 1.4

$Petal.Width
[1] 0.2

$Species
[1] setosa
Levels: setosa versicolor virginica


I found a 'rep.data.frame' function in package 'mefa' [2], but I think
it would be nice to have it in base R. In any case, the code used by
the method is very simple.
> require(mefa)
Loading required package: mefa
mefa 3.2-1 	 2011-05-13
> mefa:::rep.data.frame
function (x, ...)
as.data.frame(lapply(x, rep, ...))
<environment: namespace:mefa>

And here's the example above:
> rep(x, 2)
  Sepal.Length Sepal.Width Petal.Length Petal.Width Species
1          5.1         3.5          1.4         0.2  setosa
2          5.1         3.5          1.4         0.2  setosa


Please le t me know what you think. Regards
Liviu

[1] http://finzi.psych.upenn.edu/R/library/mefa/html/rep.data.frame.html
[2] http://cran.at.r-project.org/web/packages/mefa/index.html


-- 
Do you know how to read?
http://www.alienetworks.com/srtest.cfm
http://goodies.xfce.org/projects/applications/xfce4-dict#speed-reader
Do you know how to write?
http://garbl.home.comcast.net/~garbl/stylemanual/e.htm#e-mail


From Thorn.Thaler at rdls.nestle.com  Tue Aug  2 13:48:00 2011
From: Thorn.Thaler at rdls.nestle.com (Thaler, Thorn, LAUSANNE,
	Applied Mathematics)
Date: Tue, 2 Aug 2011 13:48:00 +0200
Subject: [Rd] update.default: fall back on model.frame in case that the data
	frame is not in the parent environment
Message-ID: <F54EF8F1B477CF448729593FE421F6465C759B@HQVEVE0032.nestle.com>

Dear all,

Suppose the following code:

--------------8<--------------
mm <- function(datf) {
  lm(y ~ x, data = datf)
}
mydatf <- data.frame(x = rep(1:2, 10), y = rnorm(20, rep(1:2, 10)))

l <- mm(mydatf)
-------------->8--------------

If I want to update l now without providing the data argument an error
occurs:

--------------8<--------------
> update(l, . ~ .)
Error in inherits(x, "data.frame") : object 'datf' not found
-------------->8--------------

and I've to provide the data argument explicitly:
--------------8<--------------
update(l, . ~ ., data = mydatf)
update(l, . ~ ., data = model.frame(l))
-------------->8--------------

While the first work-around is additionally error prone (what if I
change the name of mydatf earlier in the file? In the best case I just
get an error if mydatf is not defined), both options are kind of
semantically questionable (I do not want to _update_ the data argument
of the lm object it should remain untouched).

So my suggestion would be that update falls back on the data stored in
model.frame in case that the data argument in the lm call cannot be
resolved in the parent.frame of update, which can be easily achieved by
adding just four lines to update.default:

--------------8<--------------
update.default <- function (object, formula., ..., evaluate = TRUE) {
    call <- object$call
    if (is.null(call)) 
        stop("need an object with call component")
    extras <- match.call(expand.dots = FALSE)$...
    if (!missing(formula.)) 
        call$formula <- update.formula(formula(object), formula.)
    if (length(extras)) {
        existing <- !is.na(match(names(extras), names(call)))
        for (a in names(extras)[existing]) call[[a]] <- extras[[a]]
        if (any(!existing)) {
            call <- c(as.list(call), extras[!existing])
            call <- as.call(call)
        }
    }
    if (!is.null(call$data)) {
        if (!exists(as.character(call$data), envir = parent.frame()))
            call$data <- model.frame(object)
    }
    if (evaluate) 
        eval(call, parent.frame())
    else call
}
-------------->8--------------

This is just a quick dirty hack which works fine here (with an ugly
drawback that in the standard output of lm I now see the lengthy
explicit data.frame statement) but I'm sure there are some cracks out
there who could take it over from here and beautify this idea.

I don't see any problems with this proposition regarding old code, but
if I'm wrong and there are some reasons not to touch update.default in
the way I was proposing please let me know. Any other feedback is highly
appreciated too.

Thanks for sharing your thoughts with me.

KR,

-Thorn


From murdoch.duncan at gmail.com  Tue Aug  2 15:41:17 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 02 Aug 2011 09:41:17 -0400
Subject: [Rd] update.default: fall back on model.frame in case that the
 data frame is not in the parent environment
In-Reply-To: <F54EF8F1B477CF448729593FE421F6465C759B@HQVEVE0032.nestle.com>
References: <F54EF8F1B477CF448729593FE421F6465C759B@HQVEVE0032.nestle.com>
Message-ID: <4E37FE7D.20801@gmail.com>

It looks to me as though your proposal would allow update to remove 
variables, but would give erroneous results when adding them.  For example:

mm <- function(datf) {
   lm(y ~ x, data = datf)
}
mydatf <- data.frame(x = rep(1:2, 10), y = rnorm(20, rep(1:2, 10)), z = 
rnorm(20))

l <- mm(mydatf)
update(l, . ~ . + z)   # This fails, z is not found

z <- rnorm(20)
update(l, . ~ . + z)   # This finds the wrong z, without a warning

I'd rather get the "datf not found" error than wrong results.

Duncan Murdoch

On 02/08/2011 7:48 AM, Thaler, Thorn, LAUSANNE, Applied Mathematics wrote:
> Dear all,
>
> Suppose the following code:
>
> --------------8<--------------
> mm<- function(datf) {
>    lm(y ~ x, data = datf)
> }
> mydatf<- data.frame(x = rep(1:2, 10), y = rnorm(20, rep(1:2, 10)))
>
> l<- mm(mydatf)
> -------------->8--------------
>
> If I want to update l now without providing the data argument an error
> occurs:
>
> --------------8<--------------
> >  update(l, . ~ .)
> Error in inherits(x, "data.frame") : object 'datf' not found
> -------------->8--------------
>
> and I've to provide the data argument explicitly:
> --------------8<--------------
> update(l, . ~ ., data = mydatf)
> update(l, . ~ ., data = model.frame(l))
> -------------->8--------------
>
> While the first work-around is additionally error prone (what if I
> change the name of mydatf earlier in the file? In the best case I just
> get an error if mydatf is not defined), both options are kind of
> semantically questionable (I do not want to _update_ the data argument
> of the lm object it should remain untouched).
>
> So my suggestion would be that update falls back on the data stored in
> model.frame in case that the data argument in the lm call cannot be
> resolved in the parent.frame of update, which can be easily achieved by
> adding just four lines to update.default:
>
> --------------8<--------------
> update.default<- function (object, formula., ..., evaluate = TRUE) {
>      call<- object$call
>      if (is.null(call))
>          stop("need an object with call component")
>      extras<- match.call(expand.dots = FALSE)$...
>      if (!missing(formula.))
>          call$formula<- update.formula(formula(object), formula.)
>      if (length(extras)) {
>          existing<- !is.na(match(names(extras), names(call)))
>          for (a in names(extras)[existing]) call[[a]]<- extras[[a]]
>          if (any(!existing)) {
>              call<- c(as.list(call), extras[!existing])
>              call<- as.call(call)
>          }
>      }
>      if (!is.null(call$data)) {
>          if (!exists(as.character(call$data), envir = parent.frame()))
>              call$data<- model.frame(object)
>      }
>      if (evaluate)
>          eval(call, parent.frame())
>      else call
> }
> -------------->8--------------
>
> This is just a quick dirty hack which works fine here (with an ugly
> drawback that in the standard output of lm I now see the lengthy
> explicit data.frame statement) but I'm sure there are some cracks out
> there who could take it over from here and beautify this idea.
>
> I don't see any problems with this proposition regarding old code, but
> if I'm wrong and there are some reasons not to touch update.default in
> the way I was proposing please let me know. Any other feedback is highly
> appreciated too.
>
> Thanks for sharing your thoughts with me.
>
> KR,
>
> -Thorn
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Tue Aug  2 15:43:58 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 02 Aug 2011 09:43:58 -0400
Subject: [Rd] update.default: fall back on model.frame in case that the
 data frame is not in the parent environment
In-Reply-To: <4E37FE7D.20801@gmail.com>
References: <F54EF8F1B477CF448729593FE421F6465C759B@HQVEVE0032.nestle.com>
	<4E37FE7D.20801@gmail.com>
Message-ID: <4E37FF1E.6070504@gmail.com>

On 02/08/2011 9:41 AM, Duncan Murdoch wrote:
> It looks to me as though your proposal would allow update to remove
> variables, but would give erroneous results when adding them.  For example:
>
> mm<- function(datf) {
>     lm(y ~ x, data = datf)
> }
> mydatf<- data.frame(x = rep(1:2, 10), y = rnorm(20, rep(1:2, 10)), z =
> rnorm(20))
>
> l<- mm(mydatf)
> update(l, . ~ . + z)   # This fails, z is not found
>
> z<- rnorm(20)
> update(l, . ~ . + z)   # This finds the wrong z, without a warning
>
> I'd rather get the "datf not found" error than wrong results.

... of course, the standard code will give wrong results if there's 
another variable named "datf" in the global environment, so the status 
quo isn't ideal either.

Duncan Murdoch

> Duncan Murdoch
>
> On 02/08/2011 7:48 AM, Thaler, Thorn, LAUSANNE, Applied Mathematics wrote:
> >  Dear all,
> >
> >  Suppose the following code:
> >
> >  --------------8<--------------
> >  mm<- function(datf) {
> >     lm(y ~ x, data = datf)
> >  }
> >  mydatf<- data.frame(x = rep(1:2, 10), y = rnorm(20, rep(1:2, 10)))
> >
> >  l<- mm(mydatf)
> >  -------------->8--------------
> >
> >  If I want to update l now without providing the data argument an error
> >  occurs:
> >
> >  --------------8<--------------
> >  >   update(l, . ~ .)
> >  Error in inherits(x, "data.frame") : object 'datf' not found
> >  -------------->8--------------
> >
> >  and I've to provide the data argument explicitly:
> >  --------------8<--------------
> >  update(l, . ~ ., data = mydatf)
> >  update(l, . ~ ., data = model.frame(l))
> >  -------------->8--------------
> >
> >  While the first work-around is additionally error prone (what if I
> >  change the name of mydatf earlier in the file? In the best case I just
> >  get an error if mydatf is not defined), both options are kind of
> >  semantically questionable (I do not want to _update_ the data argument
> >  of the lm object it should remain untouched).
> >
> >  So my suggestion would be that update falls back on the data stored in
> >  model.frame in case that the data argument in the lm call cannot be
> >  resolved in the parent.frame of update, which can be easily achieved by
> >  adding just four lines to update.default:
> >
> >  --------------8<--------------
> >  update.default<- function (object, formula., ..., evaluate = TRUE) {
> >       call<- object$call
> >       if (is.null(call))
> >           stop("need an object with call component")
> >       extras<- match.call(expand.dots = FALSE)$...
> >       if (!missing(formula.))
> >           call$formula<- update.formula(formula(object), formula.)
> >       if (length(extras)) {
> >           existing<- !is.na(match(names(extras), names(call)))
> >           for (a in names(extras)[existing]) call[[a]]<- extras[[a]]
> >           if (any(!existing)) {
> >               call<- c(as.list(call), extras[!existing])
> >               call<- as.call(call)
> >           }
> >       }
> >       if (!is.null(call$data)) {
> >           if (!exists(as.character(call$data), envir = parent.frame()))
> >               call$data<- model.frame(object)
> >       }
> >       if (evaluate)
> >           eval(call, parent.frame())
> >       else call
> >  }
> >  -------------->8--------------
> >
> >  This is just a quick dirty hack which works fine here (with an ugly
> >  drawback that in the standard output of lm I now see the lengthy
> >  explicit data.frame statement) but I'm sure there are some cracks out
> >  there who could take it over from here and beautify this idea.
> >
> >  I don't see any problems with this proposition regarding old code, but
> >  if I'm wrong and there are some reasons not to touch update.default in
> >  the way I was proposing please let me know. Any other feedback is highly
> >  appreciated too.
> >
> >  Thanks for sharing your thoughts with me.
> >
> >  KR,
> >
> >  -Thorn
> >
> >  ______________________________________________
> >  R-devel at r-project.org mailing list
> >  https://stat.ethz.ch/mailman/listinfo/r-devel
>


From drf28 at cornell.edu  Tue Aug  2 16:11:12 2011
From: drf28 at cornell.edu (Daniel Fuka)
Date: Tue, 2 Aug 2011 10:11:12 -0400
Subject: [Rd] example package for devel newcomers
In-Reply-To: <201108020301.16636@spsconsultoria.com>
References: <201107311845.50264@spsconsultoria.com>
	<CAB9w6Xz=etsY70+ZkxJ5XRR5P9BKe6ehZqch9+bdqhzE6Ra2+Q@mail.gmail.com>
	<201108020301.16636@spsconsultoria.com>
Message-ID: <CAB9w6Xw9TCTJ9uW2GE=QaGn0HbO4jf-8gWeA-T5w1-F4DxzftA@mail.gmail.com>

Howdy again Alexandre,

This sounds interesting and valuable, though might be touching some
areas of R that makes me think others should chime in. I have a
history of encouraging behavior that is sometimes not supported by the
general public. First search does not find a project currently trying
to accomplish what you are trying to do, though someone else might
know of a similar project.

Now that I have absolved myself of responsibility {: -)  . I think
this would be kind of kewl/useful. But, I wonder if it might actually
be easier to embed one of the well tested and secured mini-apache web
servers into R, which would accomplish much of what you want to do,
and I think remove several of the questions you have. It does destroy
the "any WCMS" desire you have in a), but I think that it accomplishes
b,c,d,f, with the ability to develop out e as you interface the 2. It
also might be an easier first package type project, which will get you
used to the development environment, and it can support all OS's out
of the box.

I played with http://appwebserver.org/ this morning, and think you
might be able to frame a simple package, and do not see any major
issues in porting/wrapper'ing it yet in the first 15 minutes of
playing with it.

Could others please chime in and bail me out or shoot me down, which
ever is best?

Enjoy,
dan



On Tue, Aug 2, 2011 at 2:01 AM, Alexandre Aguiar
<asaguiar at spsconsultoria.com> wrote:
> Em Segunda 01 Agosto 2011, voc? escreveu:
>> Is there a preferred language you would like to use in your package
>> development? I randomly downloaded packages until I found some that
>> helped me along my way, and might be able to help you pick one. If you
>> are just looking at building a package of R functions and data you
>> have developed, possibly the following example will get you started
>> till you feel comfortable with the "Writing R Extensions"
>> documentation (http://cran.r-project.org/doc/manuals/R-exts.pdf):
>
> Dan, your message is cool. Well, here is what my project is about: it is a
> package to embed php into R. Named Rphp for now. It is mostly done from
> scratch. I have loved R-exts.pdf. Great stuff.
>
> Why embed php into R? My primary purpose is to use web content management
> systems (WCMS) ready and extensively tested code from R cgi scripts.
> Someone more experienced with php might think of other uses. My approach
> is RAD(ical) and innovative (IMextremelyHO :-D) because:
> a) *any* php based WCMS can be used from R code with no php or html
> coding;
> b) output fully compliant with the website appearance;
> c) WCMS automatic upgrades and interfaces changes (skins or themes) will
> be so unlikey to cause need for maintenance in R cgi scripts;
> d) R cgi scripts will not demand changes in php code;
> e) the builtin php session support obviates the need for any special
> session coding by R (likely non-web) programmers;
> f) potential for improved analysis of web databases and even of systems
> surveillance tasks.
>
> During my explorations of the R interface for extensions and the time
> spent in this tiny project, some questions emerged.
>
> 1. my code uses no recursion but I do not really know what is inside php
> code. Stack size could be a concern. Has any of you there ever needed to
> allocate a new stack for a package? Is it better to wait for complaints
> (if anyone ever would like to try this package...)?
>
> 2. can R_registerRoutines be called more than once within the same library
> (the same DllInfo data) so that it can reconfigure itself on the fly?
>
> 3. Is it safe (I guess it is) to "re-export" a function pointer retrieved
> with R_GetCCallable?
>
> 4. when loading a second library (in this case libphp5.so) is it better to
> put it in the package library directory and load it using the 'char
> *path' member of DllInfo? Using a second library has implications:
> a) a given R setup can be limited to the user space without root access;
> b) in the case of desktops where someone might use Rphp, most systems do
> not have libphp5.so installed by default and installing it frequently
> means to install apache and all (many) related packages;
> c) many sysadmins do not have root access but can compile their own php
> version;
> d) building the libphp5.so may not be an easy task for many.
>
> 5. Similar to 3, is it safe to "export" functions of the second library?
> libphp5.so will not be registered to R and has some interesting functions
> that can be "exported" directly or as pointers within Rphp library. A
> stub function can be used.
>
> 6. related to 4, with the many machine architectures and operating systems
> around I think it is neither desirable nor feasible to distribute
> precompiled libphp5.so versions; the package itself can download (wget
> and curl are everywhere) and compile php. Compiling php is not a lengthy
> task (6m12.9s in my quadcore desktop) but is a lot tricky and demands
> several development packages not installed by default in desktop systems.
> Their installations would require root access. What is the suggested
> approach to deploy libphp5.so?
>
> 7. I do not know how to produce a version for windows if requested. I have
> only an old MSC++ 97 and lcc (current) and have xp in a virtual box. This
> concern includes php. Can I get help regarding windows in this list? It
> might mean actual work: adapting code, compiling, packaging, etc. Not
> sure what is needed.
>
> 8. system safety does not seem a concern regarding this use of php, but...
> Any suggestions?
>
> I guess some manual steps will be necessary because of potential security
> breaches related to the use of a second library. Patching php to produce
> a special build to be used as the package library would not be a trivial
> task and would demand updates at every new php version. Something I can't
> assure I can do. And would have to distribute the whole php source code:
> still have to study php licensing scheme.
>
> BTW, I copied Rdynpriv.h by hand to my include path to get access
> to 'struct _DllInfo' definition. The R install process did not copy this
> file. Am I doing something wrong here?
>
> Sorry for the lengthy message. Thanx for your help.
>
> --
>
>
> Alexandre
>
> --
> Alexandre Santos Aguiar, MD, SCT
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From dwinsemius at comcast.net  Tue Aug  2 16:14:59 2011
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 2 Aug 2011 10:14:59 -0400
Subject: [Rd] 'data.frame' method for base::rep()
In-Reply-To: <CABxs9VmouqjKpNvkzG5emHevXQtTRo9f81nxhOS9FvBo5V4maw@mail.gmail.com>
References: <CABxs9VmouqjKpNvkzG5emHevXQtTRo9f81nxhOS9FvBo5V4maw@mail.gmail.com>
Message-ID: <7EDF51C9-0E2A-47CA-81BF-3C73050D2B36@comcast.net>


On Aug 2, 2011, at 7:55 AM, Liviu Andronic wrote:

> Dear R developers
> Would you consider adding a 'data.frame' method for the base::rep
> function? The need to replicate a df row-wise can easily arise while
> programming, and rep() is unable to handle such a case. See below.
>> x <- iris[1, ]
>
x[ rep(1,2), ] # "works"

> I found a 'rep.data.frame' function in package 'mefa' [2], but I think
> it would be nice to have it in base R. In any case, the code used by
> the method is very simple.
>> require(mefa)
> Loading required package: mefa
> mefa 3.2-1 	 2011-05-13
>> mefa:::rep.data.frame
> function (x, ...)
> as.data.frame(lapply(x, rep, ...))
> <environment: namespace:mefa>
>
> And here's the example above:
>> rep(x, 2)
>  Sepal.Length Sepal.Width Petal.Length Petal.Width Species
> 1          5.1         3.5          1.4         0.2  setosa
> 2          5.1         3.5          1.4         0.2  setosa
>

I do not think the mefa 'rep.data.frame' code is a good example to  
replicate ... as it were. It strips classes from any column that does  
not have an associated 'rep' method, and the repetoire (we are in some  
kind of self-referential loop here) of rep.* methods is pretty meager.

My initial thought was that the expected functionality would be found  
with "[" using the template:

  dfrm[rep(vec, times/each= vec2) , ]

It appears "[" proves would preserve classes for a much larger range.

methods("[")

 > x <- data.frame(a = as.Date('2000-01-01'), b=as.Date('2001-01-01'))
 > x$d <- x$a -x$b
 > require(mefa)
 > rep(x, 2)
            a          b    d
1 2000-01-01 2001-01-01 -366
2 2000-01-01 2001-01-01 -366
 > str(rep(x,2))
'data.frame':	2 obs. of  3 variables:
  $ a: Date, format:  ...
  $ b: Date, format:  ...
  $ d: num  -366 -366   # notice that a difftime object has lost its  
class

# Whereas using the [rep(. , .) , ] approach does preserve the  
difftime class.
 > str(x[rep(1,2) , ])
'data.frame':	2 obs. of  3 variables:
  $ a: Date, format:  ...
  $ b: Date, format:  ...
  $ d:Class 'difftime'  atomic [1:2] -366 -366   # leap year
   .. ..- attr(*, "units")= chr "days"

Since that works out of the box with fewer potential side-effects, I  
am not sure a new method is needed.

-- 
David.
>
> Please le t me know what you think. Regards
> Liviu
>
> [1] http://finzi.psych.upenn.edu/R/library/mefa/html/rep.data.frame.html
> [2] http://cran.at.r-project.org/web/packages/mefa/index.html
>
>
> -- 


David Winsemius, MD
West Hartford, CT


From simon.urbanek at r-project.org  Tue Aug  2 16:32:22 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 2 Aug 2011 10:32:22 -0400
Subject: [Rd] example package for devel newcomers
In-Reply-To: <CAB9w6Xw9TCTJ9uW2GE=QaGn0HbO4jf-8gWeA-T5w1-F4DxzftA@mail.gmail.com>
References: <201107311845.50264@spsconsultoria.com>
	<CAB9w6Xz=etsY70+ZkxJ5XRR5P9BKe6ehZqch9+bdqhzE6Ra2+Q@mail.gmail.com>
	<201108020301.16636@spsconsultoria.com>
	<CAB9w6Xw9TCTJ9uW2GE=QaGn0HbO4jf-8gWeA-T5w1-F4DxzftA@mail.gmail.com>
Message-ID: <E2134178-595D-4E43-A2AF-1BE28CE1C81A@r-project.org>

.. also note that there is Rserve PHP client (used, e.g., by FastRWeb) which works around a lot of the issues you encounter when you try to embed R into PHP (initialization cost, lack of thread-safety, no workspace separation etc.).

Cheers,
Simon


On Aug 2, 2011, at 10:11 AM, Daniel Fuka wrote:

> Howdy again Alexandre,
> 
> This sounds interesting and valuable, though might be touching some
> areas of R that makes me think others should chime in. I have a
> history of encouraging behavior that is sometimes not supported by the
> general public. First search does not find a project currently trying
> to accomplish what you are trying to do, though someone else might
> know of a similar project.
> 
> Now that I have absolved myself of responsibility {: -)  . I think
> this would be kind of kewl/useful. But, I wonder if it might actually
> be easier to embed one of the well tested and secured mini-apache web
> servers into R, which would accomplish much of what you want to do,
> and I think remove several of the questions you have. It does destroy
> the "any WCMS" desire you have in a), but I think that it accomplishes
> b,c,d,f, with the ability to develop out e as you interface the 2. It
> also might be an easier first package type project, which will get you
> used to the development environment, and it can support all OS's out
> of the box.
> 
> I played with http://appwebserver.org/ this morning, and think you
> might be able to frame a simple package, and do not see any major
> issues in porting/wrapper'ing it yet in the first 15 minutes of
> playing with it.
> 
> Could others please chime in and bail me out or shoot me down, which
> ever is best?
> 
> Enjoy,
> dan
> 
> 
> 
> On Tue, Aug 2, 2011 at 2:01 AM, Alexandre Aguiar
> <asaguiar at spsconsultoria.com> wrote:
>> Em Segunda 01 Agosto 2011, voc? escreveu:
>>> Is there a preferred language you would like to use in your package
>>> development? I randomly downloaded packages until I found some that
>>> helped me along my way, and might be able to help you pick one. If you
>>> are just looking at building a package of R functions and data you
>>> have developed, possibly the following example will get you started
>>> till you feel comfortable with the "Writing R Extensions"
>>> documentation (http://cran.r-project.org/doc/manuals/R-exts.pdf):
>> 
>> Dan, your message is cool. Well, here is what my project is about: it is a
>> package to embed php into R. Named Rphp for now. It is mostly done from
>> scratch. I have loved R-exts.pdf. Great stuff.
>> 
>> Why embed php into R? My primary purpose is to use web content management
>> systems (WCMS) ready and extensively tested code from R cgi scripts.
>> Someone more experienced with php might think of other uses. My approach
>> is RAD(ical) and innovative (IMextremelyHO :-D) because:
>> a) *any* php based WCMS can be used from R code with no php or html
>> coding;
>> b) output fully compliant with the website appearance;
>> c) WCMS automatic upgrades and interfaces changes (skins or themes) will
>> be so unlikey to cause need for maintenance in R cgi scripts;
>> d) R cgi scripts will not demand changes in php code;
>> e) the builtin php session support obviates the need for any special
>> session coding by R (likely non-web) programmers;
>> f) potential for improved analysis of web databases and even of systems
>> surveillance tasks.
>> 
>> During my explorations of the R interface for extensions and the time
>> spent in this tiny project, some questions emerged.
>> 
>> 1. my code uses no recursion but I do not really know what is inside php
>> code. Stack size could be a concern. Has any of you there ever needed to
>> allocate a new stack for a package? Is it better to wait for complaints
>> (if anyone ever would like to try this package...)?
>> 
>> 2. can R_registerRoutines be called more than once within the same library
>> (the same DllInfo data) so that it can reconfigure itself on the fly?
>> 
>> 3. Is it safe (I guess it is) to "re-export" a function pointer retrieved
>> with R_GetCCallable?
>> 
>> 4. when loading a second library (in this case libphp5.so) is it better to
>> put it in the package library directory and load it using the 'char
>> *path' member of DllInfo? Using a second library has implications:
>> a) a given R setup can be limited to the user space without root access;
>> b) in the case of desktops where someone might use Rphp, most systems do
>> not have libphp5.so installed by default and installing it frequently
>> means to install apache and all (many) related packages;
>> c) many sysadmins do not have root access but can compile their own php
>> version;
>> d) building the libphp5.so may not be an easy task for many.
>> 
>> 5. Similar to 3, is it safe to "export" functions of the second library?
>> libphp5.so will not be registered to R and has some interesting functions
>> that can be "exported" directly or as pointers within Rphp library. A
>> stub function can be used.
>> 
>> 6. related to 4, with the many machine architectures and operating systems
>> around I think it is neither desirable nor feasible to distribute
>> precompiled libphp5.so versions; the package itself can download (wget
>> and curl are everywhere) and compile php. Compiling php is not a lengthy
>> task (6m12.9s in my quadcore desktop) but is a lot tricky and demands
>> several development packages not installed by default in desktop systems.
>> Their installations would require root access. What is the suggested
>> approach to deploy libphp5.so?
>> 
>> 7. I do not know how to produce a version for windows if requested. I have
>> only an old MSC++ 97 and lcc (current) and have xp in a virtual box. This
>> concern includes php. Can I get help regarding windows in this list? It
>> might mean actual work: adapting code, compiling, packaging, etc. Not
>> sure what is needed.
>> 
>> 8. system safety does not seem a concern regarding this use of php, but...
>> Any suggestions?
>> 
>> I guess some manual steps will be necessary because of potential security
>> breaches related to the use of a second library. Patching php to produce
>> a special build to be used as the package library would not be a trivial
>> task and would demand updates at every new php version. Something I can't
>> assure I can do. And would have to distribute the whole php source code:
>> still have to study php licensing scheme.
>> 
>> BTW, I copied Rdynpriv.h by hand to my include path to get access
>> to 'struct _DllInfo' definition. The R install process did not copy this
>> file. Am I doing something wrong here?
>> 
>> Sorry for the lengthy message. Thanx for your help.
>> 
>> --
>> 
>> 
>> Alexandre
>> 
>> --
>> Alexandre Santos Aguiar, MD, SCT
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From Thorn.Thaler at rdls.nestle.com  Tue Aug  2 16:48:12 2011
From: Thorn.Thaler at rdls.nestle.com (Thaler, Thorn, LAUSANNE,
	Applied Mathematics)
Date: Tue, 2 Aug 2011 16:48:12 +0200
Subject: [Rd] update.default: fall back on model.frame in case that the
	data frame is not in the parent environment
In-Reply-To: <4E37FE7D.20801@gmail.com>
References: <F54EF8F1B477CF448729593FE421F6465C759B@HQVEVE0032.nestle.com>
	<4E37FE7D.20801@gmail.com>
Message-ID: <F54EF8F1B477CF448729593FE421F6465C75E8@HQVEVE0032.nestle.com>

> mm <- function(datf) {
>    lm(y ~ x, data = datf)
> }
> mydatf <- data.frame(x = rep(1:2, 10), y = rnorm(20, rep(1:2, 10)), z
=
> rnorm(20))
> 
> l <- mm(mydatf)
> update(l, . ~ . + z)   # This fails, z is not found

Good point. So let me rephrase the initial problem:

1.) An lm object is fitted somewhere with some data, which resides
somewhere in the memory.
2.) An ideal update function would know where the original data is
(rather than assuming that it is stored 
  a.) in the parent frame
  b.) under the name given in the call slot of the lm object)
    
While from my point of view assumption a.) seems to be reasonable,
assumption b.) is kind of awkward as pointed out, because it makes it
kind of cumbersome to update models, which were created inside a
function (which should not be a too rare use case).

Thus, I've to questions:
1.) Is it somehow possible to retrieve the original data.frame with
which an lm is fitted just from the knowledge of the fit? I fear that
model.frame is the best I have. 
2.) Is there any other way of making update aware of where to look for
the model building data?

By the way, another work-around I was just thinking of is to use

mm <- function(datf) {
   l <- lm(y ~ x, data = datf)
   call <- l$call 
   call$data <- substitute(datf)
   l$call <- call
   l   
}

which solves my issue (and with which I can very well live with), but I
was wondering whether you see any chance that update could be made
smarter? Thanks for your input.


KR,

-Thorn


From murdoch.duncan at gmail.com  Tue Aug  2 21:06:16 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 02 Aug 2011 15:06:16 -0400
Subject: [Rd] update.default: fall back on model.frame in case that the
 data frame is not in the parent environment
In-Reply-To: <F54EF8F1B477CF448729593FE421F6465C75E8@HQVEVE0032.nestle.com>
References: <F54EF8F1B477CF448729593FE421F6465C759B@HQVEVE0032.nestle.com>
	<4E37FE7D.20801@gmail.com>
	<F54EF8F1B477CF448729593FE421F6465C75E8@HQVEVE0032.nestle.com>
Message-ID: <4E384AA8.6040008@gmail.com>

On 02/08/2011 10:48 AM, Thaler,Thorn,LAUSANNE,Applied Mathematics wrote:
> >  mm<- function(datf) {
> >     lm(y ~ x, data = datf)
> >  }
> >  mydatf<- data.frame(x = rep(1:2, 10), y = rnorm(20, rep(1:2, 10)), z
> =
> >  rnorm(20))
> >
> >  l<- mm(mydatf)
> >  update(l, . ~ . + z)   # This fails, z is not found
>
> Good point. So let me rephrase the initial problem:
>
> 1.) An lm object is fitted somewhere with some data, which resides
> somewhere in the memory.
> 2.) An ideal update function would know where the original data is
> (rather than assuming that it is stored
>    a.) in the parent frame
>    b.) under the name given in the call slot of the lm object)
>
> While from my point of view assumption a.) seems to be reasonable,
> assumption b.) is kind of awkward as pointed out, because it makes it
> kind of cumbersome to update models, which were created inside a
> function (which should not be a too rare use case).
>
> Thus, I've to questions:
> 1.) Is it somehow possible to retrieve the original data.frame with
> which an lm is fitted just from the knowledge of the fit? I fear that
> model.frame is the best I have.

I don't think so.  You can get the environment in which the formula was 
created from the "terms" component of the result; that's the second 
place lm() will look.  The first place it will look is in the explicitly 
specified data variable, and you can get its name, but I don't think the 
result object necessarily stores the full "data" argument or the 
environment in which to look it up.  (In your example, you can look up 
"datf" in environment(l$terms) and get it, but that wouldn't work if the 
formula had also been specified as an argument to mm().)


> 2.) Is there any other way of making update aware of where to look for
> the model building data?
>
> By the way, another work-around I was just thinking of is to use
>
> mm<- function(datf) {
>     l<- lm(y ~ x, data = datf)
>     call<- l$call
>     call$data<- substitute(datf)
>     l$call<- call
>     l
> }
>
> which solves my issue (and with which I can very well live with), but I
> was wondering whether you see any chance that update could be made
> smarter? Thanks for your input.

I would suggest something simpler:  return a list containing both l and 
datf, and pass datf to update.  You can attach a class to that list to 
hide some of the ugliness if you like.

Duncan Murdoch


From hpages at fhcrc.org  Tue Aug  2 22:48:02 2011
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 02 Aug 2011 13:48:02 -0700
Subject: [Rd] png() broken in R-devel
Message-ID: <4E386282.7060504@fhcrc.org>

Hi,

Seems like this recent change broke the png() device:

hpages at latitude:~/svn/R-devel/src/library/grDevices/src$ svn diff -r 
56568:56569
Index: cairo/Makefile.in
===================================================================
--- cairo/Makefile.in	(revision 56568)
+++ cairo/Makefile.in	(revision 56569)
@@ -38,7 +38,8 @@

  R: Makefile
  	@$(MAKE) $(cairo_la)
-	@cp $(cairo_la) $(R_HOME)/library/grDevices/libs$(R_ARCH)
+	@$(MKINSTALLDIRS) $(top_builddir)/library/$(pkg)/libs at R_ARCH@
+	@cp $(cairo_la) $(top_builddir)/library/$(pkg)/libs at R_ARCH@

  $(top_builddir)/src/modules/X11/rbitmap.o:
  	(cd $(top_builddir)/src/modules/X11; $(MAKE) rbitmap.o)

With R-devel r56578:

 > png()
Warning messages:
1: In png() :
   unable to load shared object 
'/home/hpages/R-2.14/library/grDevices/libs//cairo.so':
   /home/hpages/R-2.14/library/grDevices/libs//cairo.so: cannot open 
shared object file: No such file or directory
2: In png() : failed to load cairo DLL

 > sessionInfo()
R Under development (unstable) (2011-07-31 r56578)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
  [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
  [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
  [7] LC_PAPER=C                 LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

Thanks!
H.

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From hankin.robin at gmail.com  Wed Aug  3 05:53:15 2011
From: hankin.robin at gmail.com (robin hankin)
Date: Wed, 3 Aug 2011 15:53:15 +1200
Subject: [Rd] NAMESPACE problems
Message-ID: <CAHHjBM5SZ_m_M2ddOZe1uetnXibUu7c14gz1dmYR+pwwW2jHRg@mail.gmail.com>

Hi.

I am having difficulty following section 1.6.6 of the R-extensions manual.

I am trying to update the Brobdingnag package to include a NAMESPACE file (the
untb package requires the Brobdingnag package).

Without the NAMESPACE file, the package passes R CMD check cleanly.

However, if I include a NAMESPACE file, even an empty one, R CMD check
gives the following error in 00install.out:



wt118:~/packages% cat Brobdingnag.Rcheck/00install.out
* installing *source* package ?Brobdingnag? ...
** R
** inst
** preparing package for lazy loading
Creating a generic for ?max? in package ?Brobdingnag?
    (the supplied definition differs from and overrides the implicit generic
    in package ?base?: Classes: "nonstandardGenericFunction", "standardGeneric")
Creating a generic for ?min? in package ?Brobdingnag?
    (the supplied definition differs from and overrides the implicit generic
    in package ?base?: Classes: "nonstandardGenericFunction", "standardGeneric")
Creating a generic for ?range? in package ?Brobdingnag?
    (the supplied definition differs from and overrides the implicit generic
    in package ?base?: Classes: "nonstandardGenericFunction", "standardGeneric")
Creating a generic for ?prod? in package ?Brobdingnag?
    (the supplied definition differs from and overrides the implicit generic
    in package ?base?: Classes: "nonstandardGenericFunction", "standardGeneric")
Creating a generic for ?sum? in package ?Brobdingnag?
    (the supplied definition differs from and overrides the implicit generic
    in package ?base?: Classes: "nonstandardGenericFunction", "standardGeneric")
Error in setGeneric(f, where = where) :
  must supply a function skeleton, explicitly or via an existing function
Error : unable to load R code in package 'Brobdingnag'
ERROR: lazy loading failed for package ?Brobdingnag?
* removing ?/Users/rksh/packages/Brobdingnag.Rcheck/Brobdingnag?
wt118:~/packages%


AFAICS, all the setGeneric() calls are pretty much like this:

setGeneric("getX",function(x){standardGeneric("getX")})



Can anyone advise?


thank you

Robin


-- 
Robin Hankin
Uncertainty Analyst
hankin.robin at gmail.com


From asaguiar at spsconsultoria.com  Wed Aug  3 07:28:34 2011
From: asaguiar at spsconsultoria.com (Alexandre Aguiar)
Date: Wed, 3 Aug 2011 02:28:34 -0300
Subject: [Rd] example package for devel newcomers
In-Reply-To: <E2134178-595D-4E43-A2AF-1BE28CE1C81A@r-project.org>
References: <201107311845.50264@spsconsultoria.com>
	<CAB9w6Xw9TCTJ9uW2GE=QaGn0HbO4jf-8gWeA-T5w1-F4DxzftA@mail.gmail.com>
	<E2134178-595D-4E43-A2AF-1BE28CE1C81A@r-project.org>
Message-ID: <201108030228.39854@spsconsultoria.com>

Simon,

Thanx for your feedback.

Em Ter?a 02 Agosto 2011, voc? escreveu:
> .. also note that there is Rserve PHP client (used, e.g., by FastRWeb)
> which works around a lot of the issues you encounter when you try to
> embed R into PHP (initialization cost, lack of thread-safety, no
> workspace separation etc.).

Did not overlook Rserve. Nice piece of software.

The purpose of (to be) Rphp is different. Suppose we have php files 
top.php, right.php, left.php and bottom.php that build the frame around a 
central portion of a website's webpages. This basic scheme is used by 
most web content management systems (WCMS).

In a simple view things will work like:

--------R cgi script pseudocode-----------
# first get data from command line
data <- getcgidata()
html.title <- function(txt) {
   print(paste"<center><h1>",txt,"</h1></center><br><br>",sep="")
}
php("include '/somedir/top.php'") # php needs full path
php("include '/somedir/left.php'")
# perform calculations
RES <- calculations(data)
html.title("Results")
# printout results in the RES R variable
print(RES)
php("include '/somedir/right.php'")
php("include '/somedir/bottom.php'")
-------------------------------------------

The intended result is to have an output fully compliant with the WCMS 
without messing up with WCMS itself. Besides php(), another function is 
implemented to get values from specific php variables, user defined or 
system.

BTW, libphp5.so output is directed to R cgi script output (stdout in cgi) 
that is sent away through the internet connection but could also be 
trapped and saved to a variable for further handling.

---+ pesudocode----------
php("$V1=2")
php("$V2=5;")
php("$V3=4;$V4=4")
php("$VAL=$V1+$V2+$V3-$V4")
calc_val <- php.get("VAL") # or calc_val <- php("echo $VAL")
-------------------------

In the php() function the semicolon statement delimiter can be omitted 
after the last or the only php statement.

The pseudocode operation above is not useful at all. However, any function 
added with php() or declared within php files included or php systemwide 
extensions available (PEAR libraries, for instance) can be called by R 
scripts. Users always get creative and despite my own limited purpose, I 
guess many inventive uses may appear. For instance, Berkeley db, inifiles 
support, time/zone database, support to exif info in jpeg and tiff files, 
some 20 or 30 different hashes, ftp support, JSON, SOAP client  and 
server (this can do amazing things) can all become available to R.

Kindest regards.


-- 


Alexandre

--
Alexandre Santos Aguiar, MD, SCT
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 198 bytes
Desc: This is a digitally signed message part.
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110803/5058a846/attachment.bin>

From ripley at stats.ox.ac.uk  Wed Aug  3 07:34:26 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 3 Aug 2011 06:34:26 +0100 (BST)
Subject: [Rd] NAMESPACE problems
In-Reply-To: <CAHHjBM5SZ_m_M2ddOZe1uetnXibUu7c14gz1dmYR+pwwW2jHRg@mail.gmail.com>
References: <CAHHjBM5SZ_m_M2ddOZe1uetnXibUu7c14gz1dmYR+pwwW2jHRg@mail.gmail.com>
Message-ID: <alpine.LFD.2.02.1108030628080.21653@gannet.stats.ox.ac.uk>

On Wed, 3 Aug 2011, robin hankin wrote:

> Hi.
>
> I am having difficulty following section 1.6.6 of the R-extensions manual.

Also in following the posting guide: which version of R is this (it 
matters here!)?

It seems you are failing to import the functions you are attempting to 
take over as S4 generics: most likely plot() so you need

importFrom(graphics, plot)

at least in R 2.13.x.

>
> I am trying to update the Brobdingnag package to include a NAMESPACE file (the
> untb package requires the Brobdingnag package).
>
> Without the NAMESPACE file, the package passes R CMD check cleanly.
>
> However, if I include a NAMESPACE file, even an empty one, R CMD check
> gives the following error in 00install.out:
>
>
>
> wt118:~/packages% cat Brobdingnag.Rcheck/00install.out
> * installing *source* package ?Brobdingnag? ...
> ** R
> ** inst
> ** preparing package for lazy loading
> Creating a generic for ?max? in package ?Brobdingnag?
>    (the supplied definition differs from and overrides the implicit generic
>    in package ?base?: Classes: "nonstandardGenericFunction", "standardGeneric")
> Creating a generic for ?min? in package ?Brobdingnag?
>    (the supplied definition differs from and overrides the implicit generic
>    in package ?base?: Classes: "nonstandardGenericFunction", "standardGeneric")
> Creating a generic for ?range? in package ?Brobdingnag?
>    (the supplied definition differs from and overrides the implicit generic
>    in package ?base?: Classes: "nonstandardGenericFunction", "standardGeneric")
> Creating a generic for ?prod? in package ?Brobdingnag?
>    (the supplied definition differs from and overrides the implicit generic
>    in package ?base?: Classes: "nonstandardGenericFunction", "standardGeneric")
> Creating a generic for ?sum? in package ?Brobdingnag?
>    (the supplied definition differs from and overrides the implicit generic
>    in package ?base?: Classes: "nonstandardGenericFunction", "standardGeneric")
> Error in setGeneric(f, where = where) :
>  must supply a function skeleton, explicitly or via an existing function
> Error : unable to load R code in package 'Brobdingnag'
> ERROR: lazy loading failed for package ?Brobdingnag?
> * removing ?/Users/rksh/packages/Brobdingnag.Rcheck/Brobdingnag?
> wt118:~/packages%
>
>
> AFAICS, all the setGeneric() calls are pretty much like this:
>
> setGeneric("getX",function(x){standardGeneric("getX")})
>
>
>
> Can anyone advise?
>
>
> thank you
>
> Robin
>
>
> -- 
> Robin Hankin
> Uncertainty Analyst
> hankin.robin at gmail.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From landronimirc at gmail.com  Wed Aug  3 08:45:47 2011
From: landronimirc at gmail.com (Liviu Andronic)
Date: Wed, 3 Aug 2011 08:45:47 +0200
Subject: [Rd] 'data.frame' method for base::rep()
In-Reply-To: <7EDF51C9-0E2A-47CA-81BF-3C73050D2B36@comcast.net>
References: <CABxs9VmouqjKpNvkzG5emHevXQtTRo9f81nxhOS9FvBo5V4maw@mail.gmail.com>
	<7EDF51C9-0E2A-47CA-81BF-3C73050D2B36@comcast.net>
Message-ID: <CABxs9VnmNAqDuBoGiH_CmznCpjceNJ+o9JN3eDg5bwO0xfAoyA@mail.gmail.com>

Hello David


On Tue, Aug 2, 2011 at 4:14 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>> x <- data.frame(a = as.Date('2000-01-01'), b=as.Date('2001-01-01'))
>> x$d <- x$a -x$b
>> require(mefa)
>> rep(x, 2)
> ? ? ? ? ? a ? ? ? ? ?b ? ?d
> 1 2000-01-01 2001-01-01 -366
> 2 2000-01-01 2001-01-01 -366
>> str(rep(x,2))
> 'data.frame': ? 2 obs. of ?3 variables:
> ?$ a: Date, format: ?...
> ?$ b: Date, format: ?...
> ?$ d: num ?-366 -366 ? # notice that a difftime object has lost its class
>
Nice catch. Thanks for pointing it out.


> # Whereas using the [rep(. , .) , ] approach does preserve the difftime
> class.
>> str(x[rep(1,2) , ])
> 'data.frame': ? 2 obs. of ?3 variables:
> ?$ a: Date, format: ?...
> ?$ b: Date, format: ?...
> ?$ d:Class 'difftime' ?atomic [1:2] -366 -366 ? # leap year
> ?.. ..- attr(*, "units")= chr "days"
>
The above is nice. I wouldn't have thought of it.


> Since that works out of the box with fewer potential side-effects, I am not
> sure a new method is needed.
>
Your solution still seems more like an obscure side-effect of
subsetting than an intuitive feature, in the sense that before trying
it out the average user would probably first turn to base::rep() when
in need to replicate a df, and then (perhaps) to
mefa:::rep.data.frame() (with all the associated confusion and
pitfalls). I would tend to believe that if there is a clean R-ish way
to implement a base::rep.data.frame() it could still be useful.

Best regards
Liviu


From lachmann at eva.mpg.de  Wed Aug  3 09:25:22 2011
From: lachmann at eva.mpg.de (Michael Lachmann)
Date: Wed, 3 Aug 2011 09:25:22 +0200
Subject: [Rd] one way to solve bad looking density plots in postscript
Message-ID: <9318F8C2-1470-4AFB-A9E1-EC9CBF940150@eva.mpg.de>

Hi,

When R generates density plots and these are exported to postscript( 
a=matrix(1:100,10,10);image(a,col=rainbow(100);dev.copy2eps(file="image.eps")
)
The result often looks bad when rendered on screen. The help page states that this is because programs use anti-aliasing. That seems to be true - turning off anti-aliasing for gs (-dGraphicsAlphaBits=1) of in OSX's preview makes the plots look really smooth, but makes everything else look bad (personal opinion..). The plots do look ok in acrobat reader. I think it would be much better if R corrected this problem - even if it is not totally R's fault.
It seems that using the option useRaster=T in image() solved this problem, but creates other problems for OSX's Preview (it seems that OSX's preview first anti-aliases the raster, and then scales it... creating a mess). 

Density plots produced by gnuplot do not seem to have this problem:
---
set pm3d map
set pm3d at b
set ticslevel 0.8
set isosample 40,40
set output "gtest.eps"
set term postscript eps color
splot [-3:3] [-3:3] x*x*exp(-x*x)*y*y*exp(-y*y)
--
But I haven't figured out why that is. Maybe someone who understands more about postscript can. Maybe it is something about the order that the rectangles are rendered? I did notice that rectangles are plotted with slightly different sizes - 50, 51, 50, 51 and so on. Is that it?

After a lot of experimentation, I found that a small change in the eps file can correct the output.
If in the eps file produced above, you change the line
/p2  { gsave bg fill grestore newpath } def
with
/p2  { bg gsave fill grestore stroke newpath } def
and add
0.0001 setlinewidth
two lines before the next p2 - i.e. before we start plotting the rectangles of the image:
change:
/bg { 1 0 0 setrgb } def
59.04 73.44 41.47 37.15 r p2
to:
0.0001 setlinewidth
/bg { 1 0 0 setrgb } def
59.04 73.44 41.47 37.15 r p2

What this does is plot the outline of each rectangle in addition to filling it.
The page at:
http://pages.uoregon.edu/noeckel/MathematicaGraphics.html#ExportGraphics
Claims that Mathematica also has/had this problem, and how it can be solved there (sadly, I don't know enough Mathematica to understand that solution)

The output of the image would look even better if the axes were drawn AFTER the density rectangles, not before. That would cause the rectangles not to overwrite part of the lines of the axes. But that is probably a change in the image() routine, not in the postscript driver....

Thanks for listening,

Michael Lachmann


From thomas.friedrichsmeier at ruhr-uni-bochum.de  Wed Aug  3 11:32:41 2011
From: thomas.friedrichsmeier at ruhr-uni-bochum.de (Thomas Friedrichsmeier)
Date: 3 Aug 2011 11:32:41 +0200
Subject: [Rd] Front ends handling help.search() results?
In-Reply-To: <4E369624.7090208@gmail.com>
References: <4E32F7E3.4080604@gmail.com>
	<201107311634.55821.thomas.friedrichsmeier@ruhr-uni-bochum.de>
	<4E369624.7090208@gmail.com>
Message-ID: <201108031132.45533.thomas.friedrichsmeier@ruhr-uni-bochum.de>

On Monday 01 August 2011, Duncan Murdoch wrote:
> I've just committed the changes to R-devel.  Let me know if there is
> anything worse than what I described.

Well, you did not give detail on that, but I was surprised about the "topic" 
field for vignettes. Here (on a Debian/Linux system), for some vignettes, 
"topic" contains a file path, which - I guess - may have been used during 
installation of the package, but is no longer present on my system. E.g:

  topic
  "/tmp/RtmpMQhWJi/R.INSTALL494a2adb/AnnotationDbi/inst/doc/AnnotationDbi" 
  title 
  "AnnotationDbi: How to use the \".db\" annotation packages" 
  Package 
  "AnnotationDbi"

I would expect the "topic" field to always contain a string suitable for use as 
the "topic" parameter in vignette(). For some other vignettes() found by 
help.search() this is is working. I did not figure out a pattern, so far.

Besides that, while testing, I found that the dynamic help fails to display 
the result of
  help.search ("grid")
with this message:
  Error in .HTMLsearch(query) : 
  number of items to replace is not a multiple of replacement length
I note that in the matches of that query, several vignettes are listed twice. 
This probably indicates a problem in my installation, but may still be worth 
fixing.

Regards
Thomas
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 198 bytes
Desc: This is a digitally signed message part.
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110803/12aa0ec0/attachment.bin>

From lachmann at eva.mpg.de  Wed Aug  3 14:23:52 2011
From: lachmann at eva.mpg.de (Michael Lachmann)
Date: Wed, 3 Aug 2011 14:23:52 +0200
Subject: [Rd] one way to solve bad looking density plots in postscript
In-Reply-To: <9318F8C2-1470-4AFB-A9E1-EC9CBF940150@eva.mpg.de>
References: <9318F8C2-1470-4AFB-A9E1-EC9CBF940150@eva.mpg.de>
Message-ID: <64058E1C-3122-4D67-9894-897EEFE4F9E2@eva.mpg.de>

Some more digging.

1. 
The following code will fix density plots for me:
---
.ps.prolog=grDevices:::.ps.prolog
i=grep("/p2",.ps.prolog)
.ps.prolog[i] = "/p2 { bg gsave fill grestore 0.001 setlinewidth stroke
newpath } def"
---

2. 
It seems that it doesn't matter where in image.default() the box is drawn, before or after 
.Internal(image(as.double(x), as.double(y), as.integer(zi), 
        col))
is called, the resulting eps has the box in front.

Michael

On 3 Aug 2011, at 9:25AM, Michael Lachmann wrote:

> When R generates density plots and these are exported to postscript( 
> a=matrix(1:100,10,10);image(a,col=rainbow(100);dev.copy2eps(file="image.eps")
> )
> The result often looks bad when rendered on screen. The help page states that this is because programs use anti-aliasing. That seems to be true - turning off anti-aliasing for gs (-dGraphicsAlphaBits=1) of in OSX's preview makes the plots look really smooth, but makes everything else look bad (personal opinion..). The plots do look ok in acrobat reader. I think it would be much better if R corrected this problem - even if it is not totally R's fault.
> It seems that using the option useRaster=T in image() solved this problem, but creates other problems for OSX's Preview (it seems that OSX's preview first anti-aliases the raster, and then scales it... creating a mess). 
> 
> Density plots produced by gnuplot do not seem to have this problem:
> ---
> set pm3d map
> set pm3d at b
> set ticslevel 0.8
> set isosample 40,40
> set output "gtest.eps"
> set term postscript eps color
> splot [-3:3] [-3:3] x*x*exp(-x*x)*y*y*exp(-y*y)
> --
> But I haven't figured out why that is. Maybe someone who understands more about postscript can. Maybe it is something about the order that the rectangles are rendered? I did notice that rectangles are plotted with slightly different sizes - 50, 51, 50, 51 and so on. Is that it?
> 
> After a lot of experimentation, I found that a small change in the eps file can correct the output.
> If in the eps file produced above, you change the line
> /p2  { gsave bg fill grestore newpath } def
> with
> /p2  { bg gsave fill grestore stroke newpath } def
> and add
> 0.0001 setlinewidth
> two lines before the next p2 - i.e. before we start plotting the rectangles of the image:
> change:
> /bg { 1 0 0 setrgb } def
> 59.04 73.44 41.47 37.15 r p2
> to:
> 0.0001 setlinewidth
> /bg { 1 0 0 setrgb } def
> 59.04 73.44 41.47 37.15 r p2
> 
> What this does is plot the outline of each rectangle in addition to filling it.
> The page at:
> http://pages.uoregon.edu/noeckel/MathematicaGraphics.html#ExportGraphics
> Claims that Mathematica also has/had this problem, and how it can be solved there (sadly, I don't know enough Mathematica to understand that solution)
> 
> The output of the image would look even better if the axes were drawn AFTER the density rectangles, not before. That would cause the rectangles not to overwrite part of the lines of the axes. But that is probably a change in the image() routine, not in the postscript driver....
> 
> Thanks for listening,
> 
> Michael Lachmann
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> 


From maechler at stat.math.ethz.ch  Wed Aug  3 14:44:20 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 3 Aug 2011 14:44:20 +0200
Subject: [Rd] 'data.frame' method for base::rep()
In-Reply-To: <7EDF51C9-0E2A-47CA-81BF-3C73050D2B36@comcast.net>
References: <CABxs9VmouqjKpNvkzG5emHevXQtTRo9f81nxhOS9FvBo5V4maw@mail.gmail.com>
	<7EDF51C9-0E2A-47CA-81BF-3C73050D2B36@comcast.net>
Message-ID: <20025.17060.612385.124610@stat.math.ethz.ch>

>>>>> David Winsemius <dwinsemius at comcast.net>
>>>>>     on Tue, 2 Aug 2011 10:14:59 -0400 writes:

    > On Aug 2, 2011, at 7:55 AM, Liviu Andronic wrote:

    >> Dear R developers Would you consider adding a
    >> 'data.frame' method for the base::rep function? The need
    >> to replicate a df row-wise can easily arise while
    >> programming, and rep() is unable to handle such a
    >> case. See below.
    >>> x <- iris[1, ]
    >> 
    > x[ rep(1,2), ] # "works"

Yes, indeed, and that I think is my "definitive" answer
to the proposal.
Defining a rep() method for data frames seems much less sensible
First because one simple "substitute" exists (namely indexing,
see above), and to me, not the least because there are several problems /
questions that would have to be answered

- Why should rep() for data frame necessarily replicate rows and
  not columns?
- If some rows should be resampled, why each row exactly the
  same number of times?
- any solution that is not compatible to    x [ rep(i, k) , ]
  would be unsatisfactory
- What rownames should the new data frame get in case of "real"
  rownames (i.e., not the fast "1:n" pseudo-rownames)?
  The informal definition of a data frame says that the rownames
  must be unique.
 
  --> and of course, the indexing solution

     xx <- iris[ rep(1:nrow(iris), 3) , ]
 
  does implement one sensible way of producing unique row.names,
  {though, I must say, not the "optimal" one if the issue is efficiency}

Rather keep using [,] and let's not get into having to maintain
yet another data.frame method ..

Martin Maechler, ETH Zurich


From murdoch.duncan at gmail.com  Wed Aug  3 14:57:44 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 03 Aug 2011 08:57:44 -0400
Subject: [Rd] Front ends handling help.search() results?
In-Reply-To: <201108031132.45533.thomas.friedrichsmeier@ruhr-uni-bochum.de>
References: <4E32F7E3.4080604@gmail.com>
	<201107311634.55821.thomas.friedrichsmeier@ruhr-uni-bochum.de>
	<4E369624.7090208@gmail.com>
	<201108031132.45533.thomas.friedrichsmeier@ruhr-uni-bochum.de>
Message-ID: <4E3945C8.8030003@gmail.com>

On 03/08/2011 5:32 AM, Thomas Friedrichsmeier wrote:
> On Monday 01 August 2011, Duncan Murdoch wrote:
> >  I've just committed the changes to R-devel.  Let me know if there is
> >  anything worse than what I described.
>
> Well, you did not give detail on that, but I was surprised about the "topic"
> field for vignettes. Here (on a Debian/Linux system), for some vignettes,
> "topic" contains a file path, which - I guess - may have been used during
> installation of the package, but is no longer present on my system. E.g:
>
>    topic
>    "/tmp/RtmpMQhWJi/R.INSTALL494a2adb/AnnotationDbi/inst/doc/AnnotationDbi"
>    title
>    "AnnotationDbi: How to use the \".db\" annotation packages"
>    Package
>    "AnnotationDbi"
>
> I would expect the "topic" field to always contain a string suitable for use as
> the "topic" parameter in vignette(). For some other vignettes() found by
> help.search() this is is working. I did not figure out a pattern, so far.
>
> Besides that, while testing, I found that the dynamic help fails to display
> the result of
>    help.search ("grid")
> with this message:
>    Error in .HTMLsearch(query) :
>    number of items to replace is not a multiple of replacement length
> I note that in the matches of that query, several vignettes are listed twice.
> This probably indicates a problem in my installation, but may still be worth
> fixing.

Thanks, I'll take a look at those.

Duncan


From murdoch.duncan at gmail.com  Wed Aug  3 15:09:11 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 03 Aug 2011 09:09:11 -0400
Subject: [Rd] Front ends handling help.search() results?
In-Reply-To: <201108031132.45533.thomas.friedrichsmeier@ruhr-uni-bochum.de>
References: <4E32F7E3.4080604@gmail.com>
	<201107311634.55821.thomas.friedrichsmeier@ruhr-uni-bochum.de>
	<4E369624.7090208@gmail.com>
	<201108031132.45533.thomas.friedrichsmeier@ruhr-uni-bochum.de>
Message-ID: <4E394877.4090402@gmail.com>

On 03/08/2011 5:32 AM, Thomas Friedrichsmeier wrote:
> On Monday 01 August 2011, Duncan Murdoch wrote:
> >  I've just committed the changes to R-devel.  Let me know if there is
> >  anything worse than what I described.
>
> Well, you did not give detail on that, but I was surprised about the "topic"
> field for vignettes. Here (on a Debian/Linux system), for some vignettes,
> "topic" contains a file path, which - I guess - may have been used during
> installation of the package, but is no longer present on my system. E.g:
>
>    topic
>    "/tmp/RtmpMQhWJi/R.INSTALL494a2adb/AnnotationDbi/inst/doc/AnnotationDbi"
>    title
>    "AnnotationDbi: How to use the \".db\" annotation packages"
>    Package
>    "AnnotationDbi"
>
> I would expect the "topic" field to always contain a string suitable for use as
> the "topic" parameter in vignette(). For some other vignettes() found by
> help.search() this is is working. I did not figure out a pattern, so far.

I have fixed that one, will commit soon.
> Besides that, while testing, I found that the dynamic help fails to display
> the result of
>    help.search ("grid")
> with this message:
>    Error in .HTMLsearch(query) :
>    number of items to replace is not a multiple of replacement length
> I note that in the matches of that query, several vignettes are listed twice.
> This probably indicates a problem in my installation, but may still be worth
> fixing.

I can't reproduce this.  Can you get any more detail, e.g. by setting 
options(error=recover) or similar?  Vignettes listed twice sounds as 
though you may have two copies of grid installed in your .libPath(), but 
that shouldn't happen for a base package.  I'll see what happens if I do 
it for a contributed package.

Duncan Murdoch


From simon.urbanek at r-project.org  Wed Aug  3 16:52:31 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 3 Aug 2011 10:52:31 -0400
Subject: [Rd] example package for devel newcomers
In-Reply-To: <201108030228.39854@spsconsultoria.com>
References: <201107311845.50264@spsconsultoria.com>
	<CAB9w6Xw9TCTJ9uW2GE=QaGn0HbO4jf-8gWeA-T5w1-F4DxzftA@mail.gmail.com>
	<E2134178-595D-4E43-A2AF-1BE28CE1C81A@r-project.org>
	<201108030228.39854@spsconsultoria.com>
Message-ID: <66771A9D-6044-40B8-AAC1-BCDCD581EA89@r-project.org>

Alexandre,

thanks, I see your point. Somehow I parsed your e-mail as the inverse (and Dan's suggestion which I feel did the same didn't help ;)). Embedding PHP into R sound like fun and in fact FastRWeb would benefit from your package :).

In that light you may want to explain why you need 2-5 since the easiest way is to simply link to libphp. Given that you need wrappers for R anyway there is no point in pass-through re-exports since R can't use it anyway and other packages can as easily link to libphp. So I think you'll need to be more specific what you intend to do with 2-5 ...

As for 6, for small sources it's common to include them in the package, but anything more complex it is more common to simply require it using SystemRequirements: Admittedly, in your case it's bit more complicated because even machines that have PHP installed often don't install libphp at the system level. In addition, php has a whole separate set of "libraries" (like R packages) which makes it challenging to add it simply as a static build (which we do on OS X for most libraries, for example).

As for 7, R uses mingw gcc (see Windows FAQ, we provide all the tools) so as long as php can be built that way there should due no issues. 

Cheers,
Simon


On Aug 3, 2011, at 1:28 AM, Alexandre Aguiar wrote:

> Simon,
> 
> Thanx for your feedback.
> 
> Em Ter?a 02 Agosto 2011, voc? escreveu:
>> .. also note that there is Rserve PHP client (used, e.g., by FastRWeb)
>> which works around a lot of the issues you encounter when you try to
>> embed R into PHP (initialization cost, lack of thread-safety, no
>> workspace separation etc.).
> 
> Did not overlook Rserve. Nice piece of software.
> 
> The purpose of (to be) Rphp is different. Suppose we have php files 
> top.php, right.php, left.php and bottom.php that build the frame around a 
> central portion of a website's webpages. This basic scheme is used by 
> most web content management systems (WCMS).
> 
> In a simple view things will work like:
> 
> --------R cgi script pseudocode-----------
> # first get data from command line
> data <- getcgidata()
> html.title <- function(txt) {
>   print(paste"<center><h1>",txt,"</h1></center><br><br>",sep="")
> }
> php("include '/somedir/top.php'") # php needs full path
> php("include '/somedir/left.php'")
> # perform calculations
> RES <- calculations(data)
> html.title("Results")
> # printout results in the RES R variable
> print(RES)
> php("include '/somedir/right.php'")
> php("include '/somedir/bottom.php'")
> -------------------------------------------
> 
> The intended result is to have an output fully compliant with the WCMS 
> without messing up with WCMS itself. Besides php(), another function is 
> implemented to get values from specific php variables, user defined or 
> system.
> 
> BTW, libphp5.so output is directed to R cgi script output (stdout in cgi) 
> that is sent away through the internet connection but could also be 
> trapped and saved to a variable for further handling.
> 
> ---+ pesudocode----------
> php("$V1=2")
> php("$V2=5;")
> php("$V3=4;$V4=4")
> php("$VAL=$V1+$V2+$V3-$V4")
> calc_val <- php.get("VAL") # or calc_val <- php("echo $VAL")
> -------------------------
> 
> In the php() function the semicolon statement delimiter can be omitted 
> after the last or the only php statement.
> 
> The pseudocode operation above is not useful at all. However, any function 
> added with php() or declared within php files included or php systemwide 
> extensions available (PEAR libraries, for instance) can be called by R 
> scripts. Users always get creative and despite my own limited purpose, I 
> guess many inventive uses may appear. For instance, Berkeley db, inifiles 
> support, time/zone database, support to exif info in jpeg and tiff files, 
> some 20 or 30 different hashes, ftp support, JSON, SOAP client  and 
> server (this can do amazing things) can all become available to R.
> 
> Kindest regards.
> 
> 
> -- 
> 
> 
> Alexandre
> 
> --
> Alexandre Santos Aguiar, MD, SCT
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From dwinsemius at comcast.net  Wed Aug  3 16:54:52 2011
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 3 Aug 2011 10:54:52 -0400
Subject: [Rd] 'data.frame' method for base::rep()
In-Reply-To: <CABxs9VnmNAqDuBoGiH_CmznCpjceNJ+o9JN3eDg5bwO0xfAoyA@mail.gmail.com>
References: <CABxs9VmouqjKpNvkzG5emHevXQtTRo9f81nxhOS9FvBo5V4maw@mail.gmail.com>
	<7EDF51C9-0E2A-47CA-81BF-3C73050D2B36@comcast.net>
	<CABxs9VnmNAqDuBoGiH_CmznCpjceNJ+o9JN3eDg5bwO0xfAoyA@mail.gmail.com>
Message-ID: <F0A5E038-9BBC-496F-8244-0D4E09C70202@comcast.net>


On Aug 3, 2011, at 2:45 AM, Liviu Andronic wrote:

> Hello David
>
>
> On Tue, Aug 2, 2011 at 4:14 PM, David Winsemius <dwinsemius at comcast.net 
> > wrote:
>>> x <- data.frame(a = as.Date('2000-01-01'), b=as.Date('2001-01-01'))
>>> x$d <- x$a -x$b
>>> require(mefa)
>>> rep(x, 2)
>>           a          b    d
>> 1 2000-01-01 2001-01-01 -366
>> 2 2000-01-01 2001-01-01 -366
>>> str(rep(x,2))
>> 'data.frame':   2 obs. of  3 variables:
>>  $ a: Date, format:  ...
>>  $ b: Date, format:  ...
>>  $ d: num  -366 -366   # notice that a difftime object has lost its  
>> class
>>
> Nice catch. Thanks for pointing it out.
>
>
>> # Whereas using the [rep(. , .) , ] approach does preserve the  
>> difftime
>> class.
>>> str(x[rep(1,2) , ])
>> 'data.frame':   2 obs. of  3 variables:
>>  $ a: Date, format:  ...
>>  $ b: Date, format:  ...
>>  $ d:Class 'difftime'  atomic [1:2] -366 -366   # leap year
>>  .. ..- attr(*, "units")= chr "days"
>>
> The above is nice. I wouldn't have thought of it.
>
>
>> Since that works out of the box with fewer potential side-effects,  
>> I am not
>> sure a new method is needed.
>>
> Your solution still seems more like an obscure side-effect of
> subsetting than an intuitive feature, in the sense that before trying
> it out the average user would probably first turn to base::rep() when
> in need to replicate a df, and then (perhaps) to
> mefa:::rep.data.frame() (with all the associated confusion and
> pitfalls). I would tend to believe that if there is a clean R-ish way
> to implement a base::rep.data.frame() it could still be useful.

To me that _is_ the R-ish way. It did not seem at all obscure.  
Duplicating column numbers also a way to replicate columns or  
rearrange them:

Try:

xtest=data.frame(a=letters[1:10], b=1:10)
xtest[ , c(1,2,2,1)]

-- 
David.


From asaguiar at spsconsultoria.com  Wed Aug  3 19:19:42 2011
From: asaguiar at spsconsultoria.com (Alexandre Aguiar)
Date: Wed, 3 Aug 2011 14:19:42 -0300
Subject: [Rd] example package for devel newcomers
In-Reply-To: <66771A9D-6044-40B8-AAC1-BCDCD581EA89@r-project.org>
References: <201107311845.50264@spsconsultoria.com>
	<201108030228.39854@spsconsultoria.com>
	<66771A9D-6044-40B8-AAC1-BCDCD581EA89@r-project.org>
Message-ID: <201108031419.42767@spsconsultoria.com>

Simon,

Em Quarta 03 Agosto 2011, voc? escreveu:
> In that light you may want to explain why you need 2-5 since the
> easiest way is to simply link to libphp.

Resources accessible to libphp through apache are limited by ssytem 
configurations. With libphp fully available to every user there are 
potential problems. For instance, snooping into system configurations 
especially in networked applications or a maliciously hacked user 
compiled libphp.

About 2: the need for configuration changes tailored to local 
restrictions. Have convinced myself that building R_CMethodDef and 
R_CallMethodDef dinamically will be better. For instance, in 
a "precompiled scenario" php functions that make use of db4 libraries 
would cause a crash if those libraries are not available.

About 5: a user could redefine parameters to "reuse" libphp directly 
using "good guy" loading mechanism of Rphp. While Rphp itself would be 
harmless, loading its library would make libphp available within the R 
process. R might be used as unsuspected hacking tool.

I mean, exporting functions from libphp can be good or evil and 
potentially harmful without the limits imposed by apache and with the 
potential use of a hacked libphp.

> As for 7, R uses mingw gcc (see Windows FAQ, we provide all the tools)
> so as long as php can be built that way there should due no issues.

I'll check that out asap.

Regarding recursion and stack size, I have been assured by a php developer 
that it currently is not a concern. Have also found that a recursion 
problem with libpcre (used by libphp) has been solved.

In a phrase: problems I foresee are related to deployment of libphp and 
potential security breaches.

Thanx and cheers.


-- 


Alexandre

--
Alexandre Santos Aguiar, MD, SCT
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 198 bytes
Desc: This is a digitally signed message part.
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110803/b6389011/attachment.bin>

From thomas.friedrichsmeier at ruhr-uni-bochum.de  Wed Aug  3 19:23:54 2011
From: thomas.friedrichsmeier at ruhr-uni-bochum.de (Thomas Friedrichsmeier)
Date: 3 Aug 2011 19:23:54 +0200
Subject: [Rd] Front ends handling help.search() results?
In-Reply-To: <4E394877.4090402@gmail.com>
References: <4E32F7E3.4080604@gmail.com>
	<201108031132.45533.thomas.friedrichsmeier@ruhr-uni-bochum.de>
	<4E394877.4090402@gmail.com>
Message-ID: <201108031924.00205.thomas.friedrichsmeier@ruhr-uni-bochum.de>

On Wednesday 03 August 2011, Duncan Murdoch wrote:
> I can't reproduce this.  Can you get any more detail, e.g. by setting
> options(error=recover) or similar?

Interestingly, that does not start a browser, and options(error=dump.frames) 
appears to have no effect, either. geterrmessage() does list the error, though. 
I'm not sure whether that is or is not the expected handling of errors inside 
input handlers.

Either way, I found I can trigger the error using
   tools:::httpd("/doc/html/Search", c(pattern = "grid"))
debugging from there shows that the error is on line
   vignettes[i,] <- c(pkg, unlist(vignette[,c("File", "Title", "PDF", "R")]))
At this point, "vignette" is:
                File                 Title             PDF  Depends Keywords
   1 displaylist.Rnw Display Lists in grid displaylist.pdf graphics         
   2 displaylist.Snw Display Lists in grid displaylist.pdf graphics         
                 R
   1 displaylist.R
   2 displaylist.R

> Vignettes listed twice sounds as
> though you may have two copies of grid installed in your .libPath(), but
> that shouldn't happen for a base package.

It appears, the cause of the problem was failure to "make clean" every once in 
a while, and this resulted in installing both displaylist.Rnw and 
displaylist.Snw (into a single library location).

Regards
Thomas
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 198 bytes
Desc: This is a digitally signed message part.
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110803/a5128fef/attachment.bin>

From murdoch.duncan at gmail.com  Wed Aug  3 20:00:01 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 03 Aug 2011 14:00:01 -0400
Subject: [Rd] Front ends handling help.search() results?
In-Reply-To: <201108031924.00205.thomas.friedrichsmeier@ruhr-uni-bochum.de>
References: <4E32F7E3.4080604@gmail.com>	<201108031132.45533.thomas.friedrichsmeier@ruhr-uni-bochum.de>	<4E394877.4090402@gmail.com>
	<201108031924.00205.thomas.friedrichsmeier@ruhr-uni-bochum.de>
Message-ID: <4E398CA1.80209@gmail.com>

On 03/08/2011 1:23 PM, Thomas Friedrichsmeier wrote:
> On Wednesday 03 August 2011, Duncan Murdoch wrote:
> >  I can't reproduce this.  Can you get any more detail, e.g. by setting
> >  options(error=recover) or similar?
>
> Interestingly, that does not start a browser, and options(error=dump.frames)
> appears to have no effect, either. geterrmessage() does list the error, though.
> I'm not sure whether that is or is not the expected handling of errors inside
> input handlers.
>
> Either way, I found I can trigger the error using
>     tools:::httpd("/doc/html/Search", c(pattern = "grid"))
> debugging from there shows that the error is on line
>     vignettes[i,]<- c(pkg, unlist(vignette[,c("File", "Title", "PDF", "R")]))
> At this point, "vignette" is:
>                  File                 Title             PDF  Depends Keywords
>     1 displaylist.Rnw Display Lists in grid displaylist.pdf graphics
>     2 displaylist.Snw Display Lists in grid displaylist.pdf graphics
>                   R
>     1 displaylist.R
>     2 displaylist.R
>
> >  Vignettes listed twice sounds as
> >  though you may have two copies of grid installed in your .libPath(), but
> >  that shouldn't happen for a base package.
>
> It appears, the cause of the problem was failure to "make clean" every once in
> a while, and this resulted in installing both displaylist.Rnw and
> displaylist.Snw (into a single library location).

Thanks.  I'll put in code to protect against that possibility.

Duncan


From simon.urbanek at r-project.org  Wed Aug  3 21:37:37 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 3 Aug 2011 15:37:37 -0400
Subject: [Rd] example package for devel newcomers
In-Reply-To: <201108031419.42767@spsconsultoria.com>
References: <201107311845.50264@spsconsultoria.com>
	<201108030228.39854@spsconsultoria.com>
	<66771A9D-6044-40B8-AAC1-BCDCD581EA89@r-project.org>
	<201108031419.42767@spsconsultoria.com>
Message-ID: <62071B9A-7AD9-411D-B2A7-D3FB8081AB08@r-project.org>

Alexandre,

On Aug 3, 2011, at 1:19 PM, Alexandre Aguiar wrote:

> Simon,
> 
> Em Quarta 03 Agosto 2011, voc? escreveu:
>> In that light you may want to explain why you need 2-5 since the
>> easiest way is to simply link to libphp.
> 
> Resources accessible to libphp through apache are limited by ssytem 
> configurations. With libphp fully available to every user there are 
> potential problems. For instance, snooping into system configurations 
> especially in networked applications or a maliciously hacked user 
> compiled libphp.
> 
> About 2: the need for configuration changes tailored to local 
> restrictions. Have convinced myself that building R_CMethodDef and 
> R_CallMethodDef dinamically will be better. For instance, in 
> a "precompiled scenario" php functions that make use of db4 libraries 
> would cause a crash if those libraries are not available.
> 
> About 5: a user could redefine parameters to "reuse" libphp directly 
> using "good guy" loading mechanism of Rphp. While Rphp itself would be 
> harmless, loading its library would make libphp available within the R 
> process. R might be used as unsuspected hacking tool.
> 
> I mean, exporting functions from libphp can be good or evil and 
> potentially harmful without the limits imposed by apache and with the 
> potential use of a hacked libphp.
> 

To be honest I don't understand what you mean at all. Registering .C/.Call/... symbols in R is just a convenience - mostly for argument checking on the R side. There is nothing stopping users from calling any C entry point, because R allows users to load any dynamic object they want and call any symbol therein - so they can simply load libphp directly without any trouble. The moment you include R you have access to everything. I also don't understand your point with db4, because the registrations you mention are for R wrappers, not for native API, so you can't call any function in libphp directly so you have to abstract the functionality anyway (let's say throwing an error if the capability is not included). I suspect either I misunderstand what you want or you misunderstand the symbol registration.


>> As for 7, R uses mingw gcc (see Windows FAQ, we provide all the tools)
>> so as long as php can be built that way there should due no issues.
> 
> I'll check that out asap.
> 
> Regarding recursion and stack size, I have been assured by a php developer 
> that it currently is not a concern. Have also found that a recursion 
> problem with libpcre (used by libphp) has been solved.
> 
> In a phrase: problems I foresee are related to deployment of libphp and 
> potential security breaches.
> 

Well, the moment R is in the mix, there is no access control so that seems like worrying about a crack while the door is open ;). But, again, I may not quite understand what you really mean.

Cheers,
Simon


From murdoch.duncan at gmail.com  Wed Aug  3 22:04:30 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 03 Aug 2011 16:04:30 -0400
Subject: [Rd] Front ends handling help.search() results?
In-Reply-To: <201108031924.00205.thomas.friedrichsmeier@ruhr-uni-bochum.de>
References: <4E32F7E3.4080604@gmail.com>	<201108031132.45533.thomas.friedrichsmeier@ruhr-uni-bochum.de>	<4E394877.4090402@gmail.com>
	<201108031924.00205.thomas.friedrichsmeier@ruhr-uni-bochum.de>
Message-ID: <4E39A9CE.3020903@gmail.com>

On 03/08/2011 1:23 PM, Thomas Friedrichsmeier wrote:
> On Wednesday 03 August 2011, Duncan Murdoch wrote:
> >  I can't reproduce this.  Can you get any more detail, e.g. by setting
> >  options(error=recover) or similar?
>
> Interestingly, that does not start a browser, and options(error=dump.frames)
> appears to have no effect, either. geterrmessage() does list the error, though.
> I'm not sure whether that is or is not the expected handling of errors inside
> input handlers.
>
> Either way, I found I can trigger the error using
>     tools:::httpd("/doc/html/Search", c(pattern = "grid"))
> debugging from there shows that the error is on line
>     vignettes[i,]<- c(pkg, unlist(vignette[,c("File", "Title", "PDF", "R")]))
> At this point, "vignette" is:
>                  File                 Title             PDF  Depends Keywords
>     1 displaylist.Rnw Display Lists in grid displaylist.pdf graphics
>     2 displaylist.Snw Display Lists in grid displaylist.pdf graphics
>                   R
>     1 displaylist.R
>     2 displaylist.R
>
> >  Vignettes listed twice sounds as
> >  though you may have two copies of grid installed in your .libPath(), but
> >  that shouldn't happen for a base package.
>
> It appears, the cause of the problem was failure to "make clean" every once in
> a while, and this resulted in installing both displaylist.Rnw and
> displaylist.Snw (into a single library location).

I've put a workaround for this into the help.search code, and a new 
check in the package install code to quit if you have a situation like 
this.  For people working in R-devel this might cause builds to fail 
until you fix and re-install the bad packages.

Duncan Murdoch


From baptiste.auguie at googlemail.com  Wed Aug  3 23:14:46 2011
From: baptiste.auguie at googlemail.com (baptiste auguie)
Date: Thu, 4 Aug 2011 09:14:46 +1200
Subject: [Rd] one way to solve bad looking density plots in postscript
In-Reply-To: <64058E1C-3122-4D67-9894-897EEFE4F9E2@eva.mpg.de>
References: <9318F8C2-1470-4AFB-A9E1-EC9CBF940150@eva.mpg.de>
	<64058E1C-3122-4D67-9894-897EEFE4F9E2@eva.mpg.de>
Message-ID: <CANLFJPp1N0YWq5u3H91p+z=BLyZKvyRF9obKWHzL4710OyJniw@mail.gmail.com>

Hi,

I was going to suggest panel.last to redraw a box around the image,
but for some reason it does not seem to come after the image neither
(this is perhaps to be expected from the note in ?plot.default).

plot(1,1, panel.last={box(lwd=50, col="#0000FF")})

image(volcano, panel.last={box(lwd=50, col="#0000FF")})

sessionInfo()
R version 2.13.1 (2011-07-08)
Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)

locale:
[1] en_NZ.UTF-8/en_NZ.UTF-8/C/C/en_NZ.UTF-8/en_NZ.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  grid
methods   base

other attached packages:
[1] ggplot2_0.8.9 proto_0.3-9.2 reshape_0.8.4 plyr_1.6

loaded via a namespace (and not attached):
[1] tools_2.13.1

Best,

baptiste

On 4 August 2011 00:23, Michael Lachmann <lachmann at eva.mpg.de> wrote:
> Some more digging.
>
> 1.
> The following code will fix density plots for me:
> ---
> .ps.prolog=grDevices:::.ps.prolog
> i=grep("/p2",.ps.prolog)
> .ps.prolog[i] = "/p2 { bg gsave fill grestore 0.001 setlinewidth stroke
> newpath } def"
> ---
>
> 2.
> It seems that it doesn't matter where in image.default() the box is drawn, before or after
> .Internal(image(as.double(x), as.double(y), as.integer(zi),
> ? ? ? ?col))
> is called, the resulting eps has the box in front.
>
> Michael
>
> On 3 Aug 2011, at 9:25AM, Michael Lachmann wrote:
>
>> When R generates density plots and these are exported to postscript(
>> a=matrix(1:100,10,10);image(a,col=rainbow(100);dev.copy2eps(file="image.eps")
>> )
>> The result often looks bad when rendered on screen. The help page states that this is because programs use anti-aliasing. That seems to be true - turning off anti-aliasing for gs (-dGraphicsAlphaBits=1) of in OSX's preview makes the plots look really smooth, but makes everything else look bad (personal opinion..). The plots do look ok in acrobat reader. I think it would be much better if R corrected this problem - even if it is not totally R's fault.
>> It seems that using the option useRaster=T in image() solved this problem, but creates other problems for OSX's Preview (it seems that OSX's preview first anti-aliases the raster, and then scales it... creating a mess).
>>
>> Density plots produced by gnuplot do not seem to have this problem:
>> ---
>> set pm3d map
>> set pm3d at b
>> set ticslevel 0.8
>> set isosample 40,40
>> set output "gtest.eps"
>> set term postscript eps color
>> splot [-3:3] [-3:3] x*x*exp(-x*x)*y*y*exp(-y*y)
>> --
>> But I haven't figured out why that is. Maybe someone who understands more about postscript can. Maybe it is something about the order that the rectangles are rendered? I did notice that rectangles are plotted with slightly different sizes - 50, 51, 50, 51 and so on. Is that it?
>>
>> After a lot of experimentation, I found that a small change in the eps file can correct the output.
>> If in the eps file produced above, you change the line
>> /p2 ?{ gsave bg fill grestore newpath } def
>> with
>> /p2 ?{ bg gsave fill grestore stroke newpath } def
>> and add
>> 0.0001 setlinewidth
>> two lines before the next p2 - i.e. before we start plotting the rectangles of the image:
>> change:
>> /bg { 1 0 0 setrgb } def
>> 59.04 73.44 41.47 37.15 r p2
>> to:
>> 0.0001 setlinewidth
>> /bg { 1 0 0 setrgb } def
>> 59.04 73.44 41.47 37.15 r p2
>>
>> What this does is plot the outline of each rectangle in addition to filling it.
>> The page at:
>> http://pages.uoregon.edu/noeckel/MathematicaGraphics.html#ExportGraphics
>> Claims that Mathematica also has/had this problem, and how it can be solved there (sadly, I don't know enough Mathematica to understand that solution)
>>
>> The output of the image would look even better if the axes were drawn AFTER the density rectangles, not before. That would cause the rectangles not to overwrite part of the lines of the axes. But that is probably a change in the image() routine, not in the postscript driver....
>>
>> Thanks for listening,
>>
>> Michael Lachmann
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From lachmann at eva.mpg.de  Wed Aug  3 23:51:27 2011
From: lachmann at eva.mpg.de (Michael Lachmann)
Date: Wed, 3 Aug 2011 23:51:27 +0200
Subject: [Rd] one way to solve bad looking density plots in postscript
In-Reply-To: <CANLFJPp1N0YWq5u3H91p+z=BLyZKvyRF9obKWHzL4710OyJniw@mail.gmail.com>
References: <9318F8C2-1470-4AFB-A9E1-EC9CBF940150@eva.mpg.de>
	<64058E1C-3122-4D67-9894-897EEFE4F9E2@eva.mpg.de>
	<CANLFJPp1N0YWq5u3H91p+z=BLyZKvyRF9obKWHzL4710OyJniw@mail.gmail.com>
Message-ID: <80E0BF0D-20C0-4934-A775-4B0649DF3822@eva.mpg.de>

Sorry, I must have made a mistake before.
In my R, the attached replacement for image.default DOES put the axes last, and does look better. 

I also tested my code for the change in the eps header on some linux machines (I'm using a mac), and there the grid effects were less pronounced, and my code did not help...

anyway, here is the plot.default function that does seem to put the box after the image is drawn.


Michael


The only change is adding box(...) at the end, and doing the first call to plot with bty="n".
--
image.default = function (x = seq(0, 1, length.out = nrow(z)), y = seq(0, 1, 
    length.out = ncol(z)), z, zlim = range(z[is.finite(z)]), 
    xlim = range(x), ylim = range(y), col = heat.colors(12), 
    add = FALSE, xaxs = "i", yaxs = "i", xlab, ylab, breaks, 
    oldstyle = FALSE, useRaster = FALSE, ...) 
{
    if (missing(z)) {
        if (!missing(x)) {
            if (is.list(x)) {
                z <- x$z
                y <- x$y
                x <- x$x
            }
            else {
                if (is.null(dim(x))) 
                  stop("argument must be matrix-like")
                z <- x
                x <- seq.int(0, 1, length.out = nrow(z))
            }
            if (missing(xlab)) 
                xlab <- ""
            if (missing(ylab)) 
                ylab <- ""
        }
        else stop("no 'z' matrix specified")
    }
    else if (is.list(x)) {
        xn <- deparse(substitute(x))
        if (missing(xlab)) 
            xlab <- paste(xn, "x", sep = "$")
        if (missing(ylab)) 
            ylab <- paste(xn, "y", sep = "$")
        y <- x$y
        x <- x$x
    }
    else {
        if (missing(xlab)) 
            xlab <- if (missing(x)) 
                ""
            else deparse(substitute(x))
        if (missing(ylab)) 
            ylab <- if (missing(y)) 
                ""
            else deparse(substitute(y))
    }
    if (any(!is.finite(x)) || any(!is.finite(y))) 
        stop("'x' and 'y' values must be finite and non-missing")
    if (any(diff(x) <= 0) || any(diff(y) <= 0)) 
        stop("increasing 'x' and 'y' values expected")
    if (!is.matrix(z)) 
        stop("'z' must be a matrix")
    if (length(x) > 1 && length(x) == nrow(z)) {
        dx <- 0.5 * diff(x)
        x <- c(x[1] - dx[1], x[-length(x)] + dx, x[length(x)] + 
            dx[length(x) - 1])
    }
    if (length(y) > 1 && length(y) == ncol(z)) {
        dy <- 0.5 * diff(y)
        y <- c(y[1] - dy[1], y[-length(y)] + dy, y[length(y)] + 
            dy[length(y) - 1])
    }
    if (missing(breaks)) {
        nc <- length(col)
        if (!missing(zlim) && (any(!is.finite(zlim)) || diff(zlim) < 
            0)) 
            stop("invalid z limits")
        if (diff(zlim) == 0) 
            zlim <- if (zlim[1] == 0) 
                c(-1, 1)
            else zlim[1] + c(-0.4, 0.4) * abs(zlim[1])
        z <- (z - zlim[1])/diff(zlim)
        zi <- if (oldstyle) 
            floor((nc - 1) * z + 0.5)
        else floor((nc - 1e-05) * z + 1e-07)
        zi[zi < 0 | zi >= nc] <- NA
    }
    else {
        if (length(breaks) != length(col) + 1) 
            stop("must have one more break than colour")
        if (any(!is.finite(breaks))) 
            stop("breaks must all be finite")
        zi <- .C("bincode", as.double(z), length(z), as.double(breaks), 
            length(breaks), code = integer(length(z)), (TRUE), 
            (TRUE), nok = TRUE, NAOK = TRUE, DUP = FALSE, PACKAGE = "base")$code - 
            1
    }
    if (!add) 
        plot(NA, NA, xlim = xlim, ylim = ylim, type = "n", xaxs = xaxs, 
            yaxs = yaxs, xlab = xlab, ylab = ylab,bty="n", ...)
    if (length(x) <= 1) 
        x <- par("usr")[1:2]
    if (length(y) <= 1) 
        y <- par("usr")[3:4]
    if (length(x) != nrow(z) + 1 || length(y) != ncol(z) + 1) 
        stop("dimensions of z are not length(x)(-1) times length(y)(-1)")
    if (useRaster) {
        dx <- diff(x)
        dy <- diff(y)
        if ((length(dx) && !isTRUE(all.equal(dx, rep(dx[1], length(dx))))) || 
            (length(dy) && !isTRUE(all.equal(dy, rep(dy[1], length(dy)))))) 
            stop("useRaster=TRUE can only be used with a regular grid")
        if (!is.character(col)) {
            p <- palette()
            pl <- length(p)
            col <- as.integer(col)
            col[col < 1] <- NA
            col <- p[((col - 1)%%pl) + 1]
        }
        zc <- col[zi + 1]
        dim(zc) <- dim(z)
        zc <- t(zc)[ncol(zc):1, ]
        rasterImage(as.raster(zc), min(x), min(y), max(x), max(y), 
            interpolate = FALSE)
    }
    else .Internal(image(as.double(x), as.double(y), as.integer(zi), 
        col))
    box(...)
}

--

On 3 Aug 2011, at 11:14PM, baptiste auguie wrote:

> Hi,
> 
> I was going to suggest panel.last to redraw a box around the image,
> but for some reason it does not seem to come after the image neither
> (this is perhaps to be expected from the note in ?plot.default).
> 
> plot(1,1, panel.last={box(lwd=50, col="#0000FF")})
> 
> image(volcano, panel.last={box(lwd=50, col="#0000FF")})
> 
> sessionInfo()
> R version 2.13.1 (2011-07-08)
> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
> 
> locale:
> [1] en_NZ.UTF-8/en_NZ.UTF-8/C/C/en_NZ.UTF-8/en_NZ.UTF-8
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  grid
> methods   base
> 
> other attached packages:
> [1] ggplot2_0.8.9 proto_0.3-9.2 reshape_0.8.4 plyr_1.6
> 
> loaded via a namespace (and not attached):
> [1] tools_2.13.1
> 
> Best,
> 
> baptiste
> 
> On 4 August 2011 00:23, Michael Lachmann <lachmann at eva.mpg.de> wrote:
>> Some more digging.
>> 
>> 1.
>> The following code will fix density plots for me:
>> ---
>> .ps.prolog=grDevices:::.ps.prolog
>> i=grep("/p2",.ps.prolog)
>> .ps.prolog[i] = "/p2 { bg gsave fill grestore 0.001 setlinewidth stroke
>> newpath } def"
>> ---
>> 
>> 2.
>> It seems that it doesn't matter where in image.default() the box is drawn, before or after
>> .Internal(image(as.double(x), as.double(y), as.integer(zi),
>>        col))
>> is called, the resulting eps has the box in front.
>> 
>> Michael
>> 
>> On 3 Aug 2011, at 9:25AM, Michael Lachmann wrote:
>> 
>>> When R generates density plots and these are exported to postscript(
>>> a=matrix(1:100,10,10);image(a,col=rainbow(100);dev.copy2eps(file="image.eps")
>>> )
>>> The result often looks bad when rendered on screen. The help page states that this is because programs use anti-aliasing. That seems to be true - turning off anti-aliasing for gs (-dGraphicsAlphaBits=1) of in OSX's preview makes the plots look really smooth, but makes everything else look bad (personal opinion..). The plots do look ok in acrobat reader. I think it would be much better if R corrected this problem - even if it is not totally R's fault.
>>> It seems that using the option useRaster=T in image() solved this problem, but creates other problems for OSX's Preview (it seems that OSX's preview first anti-aliases the raster, and then scales it... creating a mess).
>>> 
>>> Density plots produced by gnuplot do not seem to have this problem:
>>> ---
>>> set pm3d map
>>> set pm3d at b
>>> set ticslevel 0.8
>>> set isosample 40,40
>>> set output "gtest.eps"
>>> set term postscript eps color
>>> splot [-3:3] [-3:3] x*x*exp(-x*x)*y*y*exp(-y*y)
>>> --
>>> But I haven't figured out why that is. Maybe someone who understands more about postscript can. Maybe it is something about the order that the rectangles are rendered? I did notice that rectangles are plotted with slightly different sizes - 50, 51, 50, 51 and so on. Is that it?
>>> 
>>> After a lot of experimentation, I found that a small change in the eps file can correct the output.
>>> If in the eps file produced above, you change the line
>>> /p2  { gsave bg fill grestore newpath } def
>>> with
>>> /p2  { bg gsave fill grestore stroke newpath } def
>>> and add
>>> 0.0001 setlinewidth
>>> two lines before the next p2 - i.e. before we start plotting the rectangles of the image:
>>> change:
>>> /bg { 1 0 0 setrgb } def
>>> 59.04 73.44 41.47 37.15 r p2
>>> to:
>>> 0.0001 setlinewidth
>>> /bg { 1 0 0 setrgb } def
>>> 59.04 73.44 41.47 37.15 r p2
>>> 
>>> What this does is plot the outline of each rectangle in addition to filling it.
>>> The page at:
>>> http://pages.uoregon.edu/noeckel/MathematicaGraphics.html#ExportGraphics
>>> Claims that Mathematica also has/had this problem, and how it can be solved there (sadly, I don't know enough Mathematica to understand that solution)
>>> 
>>> The output of the image would look even better if the axes were drawn AFTER the density rectangles, not before. That would cause the rectangles not to overwrite part of the lines of the axes. But that is probably a change in the image() routine, not in the postscript driver....
>>> 
>>> Thanks for listening,
>>> 
>>> Michael Lachmann
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>> 
>>> 
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
> 
> 
> 


From htl10 at users.sourceforge.net  Thu Aug  4 02:38:39 2011
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Thu, 4 Aug 2011 01:38:39 +0100 (BST)
Subject: [Rd] R check mis-identifying Illumina data file format as
	executable and other thoughts.
Message-ID: <1312418319.73495.YahooMailClassic@web29514.mail.ird.yahoo.com>

This is somewhat a summary/continuation of an R bug report:
(https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=14645)

Illumina's cluster definition files (*.egt) are one of the proprietary and
undocumented file formats used by their GenomeStudio line of products for
genomic studies.

snpMatrix 1.17.0.7 onwards 
(http://sourceforge.net/projects/outmodedbonsai/files/snpMatrix%20next/)
contains codes for reading that file format, as well as two example files of such type generated from public data, and also a vignette demonstrating their usefulness and relevance to genomic studies.

R svn check (the upcoming 2.14) mis-identifies those bundled files as undeclared binary executable files and aborts with that as error.
 
(1) the files are not executables, they just happened to be mis-identified as such
(2) even if they are genuine binary executables, there might be legitimate
reasons to bundle them with a package? (e.g. I have R code to look at their
content, and just treat them as arbitrary proprietary undocumented formats).

I can think of some rather interesting possible enhancement to R core's bytecode-compiler for parsing and morphing genuine binary executables - that might be useful for just-in-time compilation for R on the android platform. So surely there are genuine/legitimate needs for shipping binary executables in an R package?



From mark_difford at yahoo.co.uk  Thu Aug  4 16:24:18 2011
From: mark_difford at yahoo.co.uk (Mark Difford)
Date: Thu, 4 Aug 2011 07:24:18 -0700 (PDT)
Subject: [Rd] Graphical option to update.packages in development version
 (build of the 2011-07-31 r56569) for Windows not working properly
Message-ID: <1312467858969-3718847.post@n4.nabble.com>

Dear R-core/development-team,

The problem noted in the subject-line has been a problem in the last three
development versions of R for Windows that I have downloaded and tested, the
most recent of them being a version I downloaded this morning.

Update.packages() using the graphical option, i.e. called as

update.packages(ask='graphics', checkBuilt=TRUE)

does not work as it should, but presents a list of all of the installed
packages, regardless of version/time-stamp.

The call

update.packages(old.packages())

works as it should.

> sessionInfo()
R Under development (unstable) (2011-07-31 r56569)
Platform: x86_64-pc-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_South Africa.1252  LC_CTYPE=English_South Africa.1252   
[3] LC_MONETARY=English_South Africa.1252 LC_NUMERIC=C                         
[5] LC_TIME=English_South Africa.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] tools_2.14.0


-----
Mark Difford (Ph.D.)
Research Associate
Botany Department
Nelson Mandela Metropolitan University
Port Elizabeth, South Africa
--
View this message in context: http://r.789695.n4.nabble.com/Graphical-option-to-update-packages-in-development-version-build-of-the-2011-07-31-r56569-for-Windowy-tp3718847p3718847.html
Sent from the R devel mailing list archive at Nabble.com.


From oliver.ratmann at duke.edu  Thu Aug  4 20:33:23 2011
From: oliver.ratmann at duke.edu (oliver ratmann)
Date: Thu, 4 Aug 2011 14:33:23 -0400
Subject: [Rd] How to seed the R random number generator in C (standalone)
 with an instance of .Random.seed
Message-ID: <CAFBqEu9qNUoQYcMG=Yf=ijQWiLEUFMSsz=fFR9cj+nZrjL6ALw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110804/166ebd10/attachment.pl>

From murdoch.duncan at gmail.com  Thu Aug  4 21:46:14 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 04 Aug 2011 15:46:14 -0400
Subject: [Rd] How to seed the R random number generator in C
 (standalone) with an instance of .Random.seed
In-Reply-To: <CAFBqEu9qNUoQYcMG=Yf=ijQWiLEUFMSsz=fFR9cj+nZrjL6ALw@mail.gmail.com>
References: <CAFBqEu9qNUoQYcMG=Yf=ijQWiLEUFMSsz=fFR9cj+nZrjL6ALw@mail.gmail.com>
Message-ID: <4E3AF706.10804@gmail.com>

On 04/08/2011 2:33 PM, oliver ratmann wrote:
> hello all,
>
> I use the R standalone math library in my own C program, and the default R
> random number generator can be seeded with
>
> set_seed(const unsigned int, const unsigned int).
>
> How could I seed the RNG with an instance of .Random.seed ?
>
>
>
> I would need this or a similar workaround for debugging purposes.
>
> More precisely, I use the default R random number generator to sample from
> various distributions in my own C code
>
> SEED<- .Random.seed
> save(SEED, args, file= "last.call.R")
> out<- .Call("my.fun", args)
>
> and can reproduce segmentation faults etc via
>
> load("last.call.R")
> .Random.seed<- SEED
> out<- .Call("my.fun", args)
>
> In order to use valgrind, I wrote a little C program "debug.my.fun" that
> reads in 'args' and 'SEED',
> and then calls "my.fun" (without the SEXP overhead of course).
>
> But the seeds are not set accordingly and segmentation faults are not
> reproducible.

I would guess you are failing to call GetRNGstate() (or possibly 
PutRNGstate()) in your C code, so it never sees (or updates) the 
.Random.seed value.

Duncan Murdoch

> More precisely, I need to replace the set_seed line in the following snippet
> with something else.
>
> #include<Rmath.h>
> int main(int argc,char* argv[])
> {
>      const unsigned int SEED1= 12345, SEED2= 67890;
>      set_seed(SEED1, SEED2);
>
> ...
>
> }
>
>
>
>
> Thanks in advance,
> Oliver
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From lachmann at eva.mpg.de  Thu Aug  4 23:26:02 2011
From: lachmann at eva.mpg.de (Michael Lachmann)
Date: Thu, 4 Aug 2011 23:26:02 +0200
Subject: [Rd] slightly speeding up readChar()
Message-ID: <BAC8BBAE-B965-4BD7-ABFD-A016AC875223@eva.mpg.de>

Hi,

I was trying to have R read files faster with readChar(). That was before I noticed that readChar() is not that bad! In any case, below I suggest a few simple changes that will make readChar slightly faster.

I followed readChar(useBytes=T), and tried to identify all O(N) operations, where N is the size of the file. The assumption is that for LARGE files we want to avoid any O(N) operations, and any O(N) memory allocations.

Here they are:

1. In readFixedString in envir.c, an N sized vector is 
allocated, and memset to 0. O(N)

2. The file is read into the buffer with con->read O(N) (but this probably can't be dropped)

3. mkChar is called, which calls mkCharLenCE(name, strlen(name), CE_NATIVE);
   strlen is O(N)

4. In mkCharLenCE, a loop along the string looks for 0s to tell if the string includes NULs (notice that because strlen was called before, that can't really happen) O(N)

5. A hashcode is computed for the string to see if it is already in memory. That is an O(N) operation.

6. A Charsxp of size N is allocated

7. The data is copied to the Charsxp - O(N).

So, as far as I could tell, in addition to the reading operation, 5 O(N) operations are done, and double the memory of what is needed is allocated.

A couple of these operations are easy to drop:

1. One could only zero the memory beyond what was read, in case not N chars were read.

2. We know the length of the string, so we can call mkCharLenCE directly from readFixedString with the right length. 

Others could maybe be dropped.

3. Does one really need to look for 0s?
In readFixedString there is a comment:
    /* String may contain nuls which we now (R >= 2.8.0) assume to be
       padding and ignore silently */
4. If a file was just read, is it likely that it is in the hash? Is it worth paying the time for those people who read in the same file twice? 

Finally about the allocation.

Could the Charsxp be allocated to begin with, and the data read straight into it?
Then we'd save one extra allocation, and a memcpy. For that one would need something like mkEmptyCharLen.

One could also allocate a slighly bigger memory region, and then pass that so that instead of allocating it a new the old pointer is used (?).

In any case, here is an updated readFixedString(), which would drop 2 O(N) operations.

---
static SEXP
	readFixedString(Rconnection con, int len, int useBytes)
{
	SEXP ans;
	char *buf;
	int  m;
	const void *vmax = vmaxget();

	if(utf8locale && !useBytes) {
		int i, clen;
		char *p, *q;

		p = buf = (char *) R_alloc(MB_CUR_MAX*len+1, sizeof(char));
		memset(buf, 0, MB_CUR_MAX*len+1);
		for(i = 0; i < len; i++) {
			q = p;
			m = con->read(p, sizeof(char), 1, con);
			if(!m) { if(i == 0) return R_NilValue; else break;}
			clen = utf8clen(*p++);
			if(clen > 1) {
				m = con->read(p, sizeof(char), clen - 1, con);
				if(m < clen - 1) error(_("invalid UTF-8 input in readChar()"));
				p += clen - 1;
		/* NB: this only checks validity of multi-byte characters */
				if((int)mbrtowc(NULL, q, clen, NULL) < 0)
					error(_("invalid UTF-8 input in readChar()"));
			}
		}
	} else {
		buf = (char *) R_alloc(len+1, sizeof(char));
   //memset() was here
		m = con->read(buf, sizeof(char), len, con);
		if(m < len )
			memset(buf, m+1, len+1); // changed
		if(len && !m) return R_NilValue;
	}
	/* String may contain nuls which we now (R >= 2.8.0) assume to be
	padding and ignore silently */
	ans = mkCharLenCE(buf, len, CE_NATIVE); // changed (one could also use no. read bytes as size)
	vmaxset(vmax);
	return ans;
}
--

The other changes are also not that hard - I'd do them if people think such changes should be included....


Thanks for listening,

Michael Lachmann


From simon.urbanek at r-project.org  Thu Aug  4 23:50:43 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 4 Aug 2011 17:50:43 -0400
Subject: [Rd] slightly speeding up readChar()
In-Reply-To: <BAC8BBAE-B965-4BD7-ABFD-A016AC875223@eva.mpg.de>
References: <BAC8BBAE-B965-4BD7-ABFD-A016AC875223@eva.mpg.de>
Message-ID: <9DA22EB1-E813-4D5D-91EB-46C1E9E8947C@r-project.org>


On Aug 4, 2011, at 5:26 PM, Michael Lachmann wrote:

> Hi,
> 
> I was trying to have R read files faster with readChar(). That was before I noticed that readChar() is not that bad! In any case, below I suggest a few simple changes that will make readChar slightly faster.
> 
> I followed readChar(useBytes=T), and tried to identify all O(N) operations, where N is the size of the file. The assumption is that for LARGE files we want to avoid any O(N) operations, and any O(N) memory allocations.
> 

I'm not sure it's really worth bothering with such optimizations, on my machine I get

> system.time(readChar("large.file",1e8,T))
   user  system elapsed 
  0.295   0.048   0.343 

so that is a fraction of a second for 100MB of data. Besides, why in the world would you want to use character vectors to store bytes? It's much more efficient to work with raw vectors instead...

AFAICS the only lesson from the list below is that we could add in an internal function for safe_mkCharLenCE that doesn't check for NULs. But that seems a little contrived for a very special case. Everything else is either increasing complexity at the cost of safety or could lead to internal inconsistencies (hashing is mandatory, otherwise you can't compare CHARSXPs).

BTW: your code doesn't do what you think it does - you'll force a pretty ugly buffer overflow - perfect illustration why optimization should be done only if really needed, otherwise you are just likely to introduce bugs...

Cheers,
Simon



> Here they are:
> 
> 1. In readFixedString in envir.c, an N sized vector is 
> allocated, and memset to 0. O(N)
> 
> 2. The file is read into the buffer with con->read O(N) (but this probably can't be dropped)
> 
> 3. mkChar is called, which calls mkCharLenCE(name, strlen(name), CE_NATIVE);
>   strlen is O(N)
> 
> 4. In mkCharLenCE, a loop along the string looks for 0s to tell if the string includes NULs (notice that because strlen was called before, that can't really happen) O(N)
> 
> 5. A hashcode is computed for the string to see if it is already in memory. That is an O(N) operation.
> 
> 6. A Charsxp of size N is allocated
> 
> 7. The data is copied to the Charsxp - O(N).
> 
> So, as far as I could tell, in addition to the reading operation, 5 O(N) operations are done, and double the memory of what is needed is allocated.
> 
> A couple of these operations are easy to drop:
> 
> 1. One could only zero the memory beyond what was read, in case not N chars were read.
> 
> 2. We know the length of the string, so we can call mkCharLenCE directly from readFixedString with the right length. 
> 
> Others could maybe be dropped.
> 
> 3. Does one really need to look for 0s?
> In readFixedString there is a comment:
>    /* String may contain nuls which we now (R >= 2.8.0) assume to be
>       padding and ignore silently */
> 4. If a file was just read, is it likely that it is in the hash? Is it worth paying the time for those people who read in the same file twice? 
> 
> Finally about the allocation.
> 
> Could the Charsxp be allocated to begin with, and the data read straight into it?
> Then we'd save one extra allocation, and a memcpy. For that one would need something like mkEmptyCharLen.
> 
> One could also allocate a slighly bigger memory region, and then pass that so that instead of allocating it a new the old pointer is used (?).
> 
> In any case, here is an updated readFixedString(), which would drop 2 O(N) operations.
> 
> ---
> static SEXP
> 	readFixedString(Rconnection con, int len, int useBytes)
> {
> 	SEXP ans;
> 	char *buf;
> 	int  m;
> 	const void *vmax = vmaxget();
> 
> 	if(utf8locale && !useBytes) {
> 		int i, clen;
> 		char *p, *q;
> 
> 		p = buf = (char *) R_alloc(MB_CUR_MAX*len+1, sizeof(char));
> 		memset(buf, 0, MB_CUR_MAX*len+1);
> 		for(i = 0; i < len; i++) {
> 			q = p;
> 			m = con->read(p, sizeof(char), 1, con);
> 			if(!m) { if(i == 0) return R_NilValue; else break;}
> 			clen = utf8clen(*p++);
> 			if(clen > 1) {
> 				m = con->read(p, sizeof(char), clen - 1, con);
> 				if(m < clen - 1) error(_("invalid UTF-8 input in readChar()"));
> 				p += clen - 1;
> 		/* NB: this only checks validity of multi-byte characters */
> 				if((int)mbrtowc(NULL, q, clen, NULL) < 0)
> 					error(_("invalid UTF-8 input in readChar()"));
> 			}
> 		}
> 	} else {
> 		buf = (char *) R_alloc(len+1, sizeof(char));
>   //memset() was here
> 		m = con->read(buf, sizeof(char), len, con);
> 		if(m < len )
> 			memset(buf, m+1, len+1); // changed
> 		if(len && !m) return R_NilValue;
> 	}
> 	/* String may contain nuls which we now (R >= 2.8.0) assume to be
> 	padding and ignore silently */
> 	ans = mkCharLenCE(buf, len, CE_NATIVE); // changed (one could also use no. read bytes as size)
> 	vmaxset(vmax);
> 	return ans;
> }
> --
> 
> The other changes are also not that hard - I'd do them if people think such changes should be included....
> 
> 
> Thanks for listening,
> 
> Michael Lachmann
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From lachmann at eva.mpg.de  Fri Aug  5 00:15:43 2011
From: lachmann at eva.mpg.de (Michael Lachmann)
Date: Fri, 5 Aug 2011 00:15:43 +0200
Subject: [Rd] slightly speeding up readChar()
In-Reply-To: <9DA22EB1-E813-4D5D-91EB-46C1E9E8947C@r-project.org>
References: <BAC8BBAE-B965-4BD7-ABFD-A016AC875223@eva.mpg.de>
	<9DA22EB1-E813-4D5D-91EB-46C1E9E8947C@r-project.org>
Message-ID: <590F85D8-4CD2-4182-917F-6E8900A040DB@eva.mpg.de>


On 4 Aug 2011, at 11:50PM, Simon Urbanek wrote:

> 
> On Aug 4, 2011, at 5:26 PM, Michael Lachmann wrote:
> 
>> Hi,
>> 
>> I was trying to have R read files faster with readChar(). That was before I noticed that readChar() is not that bad! In any case, below I suggest a few simple changes that will make readChar slightly faster.
>> 
>> I followed readChar(useBytes=T), and tried to identify all O(N) operations, where N is the size of the file. The assumption is that for LARGE files we want to avoid any O(N) operations, and any O(N) memory allocations.
>> 
> 
> I'm not sure it's really worth bothering with such optimizations, on my machine I get

No it isn't worth it, you're right. Though 100MB is much smaller than my average file size. But you're right, readChar is quite efficient.

> 
>> system.time(readChar("large.file",1e8,T))
>   user  system elapsed 
>  0.295   0.048   0.343 
> 
> so that is a fraction of a second for 100MB of data. Besides, why in the world would you want to use character vectors to store bytes? It's much more efficient to work with raw vectors instead...
> 
> AFAICS the only lesson from the list below is that we could add in an internal function for safe_mkCharLenCE that doesn't check for NULs. But that seems a little contrived for a very special case. Everything else is either increasing complexity at the cost of safety or could lead to internal inconsistencies (hashing is mandatory, otherwise you can't compare CHARSXPs).

You're right. Then the harder changes aren't worth it, unless you manage to save on one of the allocations. 

> 
> BTW: your code doesn't do what you think it does - you'll force a pretty ugly buffer overflow - 

But here I don't agree. memset and strlen can be dropped. 

> perfect illustration why optimization should be done only if really needed, otherwise you are just likely to introduce bugs...


Right again. I shouldn't really have bothered... but I did.

Michael


> Cheers,
> Simon
> 
> 
> 
>> Here they are:
>> 
>> 1. In readFixedString in envir.c, an N sized vector is 
>> allocated, and memset to 0. O(N)
>> 
>> 2. The file is read into the buffer with con->read O(N) (but this probably can't be dropped)
>> 
>> 3. mkChar is called, which calls mkCharLenCE(name, strlen(name), CE_NATIVE);
>>  strlen is O(N)
>> 
>> 4. In mkCharLenCE, a loop along the string looks for 0s to tell if the string includes NULs (notice that because strlen was called before, that can't really happen) O(N)
>> 
>> 5. A hashcode is computed for the string to see if it is already in memory. That is an O(N) operation.
>> 
>> 6. A Charsxp of size N is allocated
>> 
>> 7. The data is copied to the Charsxp - O(N).
>> 
>> So, as far as I could tell, in addition to the reading operation, 5 O(N) operations are done, and double the memory of what is needed is allocated.
>> 
>> A couple of these operations are easy to drop:
>> 
>> 1. One could only zero the memory beyond what was read, in case not N chars were read.
>> 
>> 2. We know the length of the string, so we can call mkCharLenCE directly from readFixedString with the right length. 
>> 
>> Others could maybe be dropped.
>> 
>> 3. Does one really need to look for 0s?
>> In readFixedString there is a comment:
>>   /* String may contain nuls which we now (R >= 2.8.0) assume to be
>>      padding and ignore silently */
>> 4. If a file was just read, is it likely that it is in the hash? Is it worth paying the time for those people who read in the same file twice? 
>> 
>> Finally about the allocation.
>> 
>> Could the Charsxp be allocated to begin with, and the data read straight into it?
>> Then we'd save one extra allocation, and a memcpy. For that one would need something like mkEmptyCharLen.
>> 
>> One could also allocate a slighly bigger memory region, and then pass that so that instead of allocating it a new the old pointer is used (?).
>> 
>> In any case, here is an updated readFixedString(), which would drop 2 O(N) operations.
>> 
>> ---
>> static SEXP
>> 	readFixedString(Rconnection con, int len, int useBytes)
>> {
>> 	SEXP ans;
>> 	char *buf;
>> 	int  m;
>> 	const void *vmax = vmaxget();
>> 
>> 	if(utf8locale && !useBytes) {
>> 		int i, clen;
>> 		char *p, *q;
>> 
>> 		p = buf = (char *) R_alloc(MB_CUR_MAX*len+1, sizeof(char));
>> 		memset(buf, 0, MB_CUR_MAX*len+1);
>> 		for(i = 0; i < len; i++) {
>> 			q = p;
>> 			m = con->read(p, sizeof(char), 1, con);
>> 			if(!m) { if(i == 0) return R_NilValue; else break;}
>> 			clen = utf8clen(*p++);
>> 			if(clen > 1) {
>> 				m = con->read(p, sizeof(char), clen - 1, con);
>> 				if(m < clen - 1) error(_("invalid UTF-8 input in readChar()"));
>> 				p += clen - 1;
>> 		/* NB: this only checks validity of multi-byte characters */
>> 				if((int)mbrtowc(NULL, q, clen, NULL) < 0)
>> 					error(_("invalid UTF-8 input in readChar()"));
>> 			}
>> 		}
>> 	} else {
>> 		buf = (char *) R_alloc(len+1, sizeof(char));
>>  //memset() was here
>> 		m = con->read(buf, sizeof(char), len, con);
>> 		if(m < len )
>> 			memset(buf, m+1, len+1); // changed
>> 		if(len && !m) return R_NilValue;
>> 	}
>> 	/* String may contain nuls which we now (R >= 2.8.0) assume to be
>> 	padding and ignore silently */
>> 	ans = mkCharLenCE(buf, len, CE_NATIVE); // changed (one could also use no. read bytes as size)
>> 	vmaxset(vmax);
>> 	return ans;
>> }
>> --
>> 
>> The other changes are also not that hard - I'd do them if people think such changes should be included....
>> 
>> 
>> Thanks for listening,
>> 
>> Michael Lachmann
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> 
> 
> 
> 


From edd at debian.org  Fri Aug  5 01:20:24 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 4 Aug 2011 18:20:24 -0500
Subject: [Rd] slightly speeding up readChar()
In-Reply-To: <590F85D8-4CD2-4182-917F-6E8900A040DB@eva.mpg.de>
References: <BAC8BBAE-B965-4BD7-ABFD-A016AC875223@eva.mpg.de>
	<9DA22EB1-E813-4D5D-91EB-46C1E9E8947C@r-project.org>
	<590F85D8-4CD2-4182-917F-6E8900A040DB@eva.mpg.de>
Message-ID: <20027.10552.641615.124070@max.nulle.part>


On 5 August 2011 at 00:15, Michael Lachmann wrote:
| > I'm not sure it's really worth bothering with such optimizations, on my machine I get
| 
| No it isn't worth it, you're right. Though 100MB is much smaller than my average file size. But you're right, readChar is quite efficient.

When you know the (fixed) structure of the data, the CRAN package mmap can be
a huge winner.

Dirk

-- 
Gauss once played himself in a zero-sum game and won $50.
                      -- #11 at http://www.gaussfacts.com


From jon.clayden at gmail.com  Fri Aug  5 12:41:12 2011
From: jon.clayden at gmail.com (Jon Clayden)
Date: Fri, 5 Aug 2011 11:41:12 +0100
Subject: [Rd] initFields() method no longer coerces arguments in R-devel
Message-ID: <CAM9CR=2fg_5io9xGZnW86JB-51BOTqxH_Ui=gPh5odciPa7eGA@mail.gmail.com>

Dear all,

I've just had a package update bounced from CRAN because of a recent
change in R-devel which seems to affect the behaviour of the
initFields() reference class method. (The change must be very recent
because I tested the package on a week-old build of R-devel.) It seems
that the method no longer coerces its arguments to the expected type
of each field. For a simple example:

> Foo <- setRefClass("Foo", fields=list(number="integer"), methods=list(initialize=function (number = NULL) initFields(number=number)))
> Foo$new()
Error in function (value)  :
  invalid replacement for field ?number?, should be from class
?integer? or a subclass (was class ?NULL?)

(This used to work, with "number" being set to "integer(0)"). In fact
it is now extremely strict, not even allowing a double literal which
is equal to an integer:

> Foo$new(number=1)
Error in function (value)  :
  invalid replacement for field ?number?, should be from class
?integer? or a subclass (was class ?numeric?)

I don't see anything about this in the NEWS, so I was wondering if I
could get clarification on whether this is now the intended behaviour,
before I further modify the package. I must say that this will be a
bit of a pain to "correct"...

All the best,
Jon


From ripley at stats.ox.ac.uk  Fri Aug  5 13:13:51 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 5 Aug 2011 12:13:51 +0100
Subject: [Rd] [R] RPMs needed to compile R using the tar.gz file
In-Reply-To: <20110805102445.GD5650@slingshot.co.nz>
References: <20110805102445.GD5650@slingshot.co.nz>
Message-ID: <alpine.LFD.2.02.1108051149050.5069@gannet.stats.ox.ac.uk>

First off, this was an R-devel question (or maybe an r-sig-fedora 
one).

It is not at all easy to give a complete answer: the list is very long 
and changes rapidly as Fedora updates.  If you can use yum to install 
a minimal list and let it get the dependencies the list would be 
manageable.  And the simplest way to get a minimal list would be to 
look in the spec file for the Fedora SRPM.

But here's a start, from yum -v install R

pkgconfig
gcc-gfortran
gcc-c++ (optional for R)
libX11-devel
libXt-devel
libXmu-devel
pango-devel
tcl-devel
tk-devel
readline-devel
libpng-devel
libjpeg-turbo-devel
libtiff-devel
libicu-devel

(Fedora uses lots of things like pcre, bzip2 which have copies 
in R.)

A lot of that is actually documented in the R-admin manual.



On Fri, 5 Aug 2011, Patrick Connolly wrote:

> I don't wish to install R by rpm.  I need to know what Fedora rpms I
> need to install to give me the capability to install R using the
> tar.gz source file as I've done for years.
>
> On previous occasions when I've installed Fedora, I've used the DVD
> which has thousands of RPMs.  Lately I've installed Fedora 15 from the
> Live CD which has a lot fewer and so a lot of necessary stuff is not
> installed yet.
>
> I've done the same not long ago with Kubuntu which required me to
> install about 20 debs before I could compile R.  If I had access to
> that installation, I could probably work out what the corresponding
> rpms are.  But I figured some clever person will have a list of the
> necessary rpms somewhere already.  Or even a smarter search string
> than I can think of would be appreciated.
>
> There's a lot of information about installing R from an rpm but that's
> not what I wish to do.
>
> TIA
>
> -- 
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>   ___    Patrick Connolly
> {~._.~}                   Great minds discuss ideas
> _( Y )_  	         Average minds discuss events
> (:_~*~_:)                  Small minds discuss people
> (_)-(_)  	                      ..... Eleanor Roosevelt
>
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pingou at pingoured.fr  Fri Aug  5 13:47:50 2011
From: pingou at pingoured.fr (Pierre-Yves Chibon)
Date: Fri, 05 Aug 2011 13:47:50 +0200
Subject: [Rd] [R] RPMs needed to compile R using the tar.gz file
In-Reply-To: <alpine.LFD.2.02.1108051149050.5069@gannet.stats.ox.ac.uk>
References: <20110805102445.GD5650@slingshot.co.nz>
	<alpine.LFD.2.02.1108051149050.5069@gannet.stats.ox.ac.uk>
Message-ID: <1312544870.2754.0.camel@cyan.pingoured.fr>

On Fri, 2011-08-05 at 12:13 +0100, Prof Brian Ripley wrote:
>   And the simplest way to get a minimal list would be to 
> look in the spec file for the Fedora SRPM. 
See:
http://pkgs.fedoraproject.org/gitweb/?p=R.git;a=blob_plain;f=R.spec;hb=HEAD

Pierre


From lachmann at eva.mpg.de  Fri Aug  5 15:22:40 2011
From: lachmann at eva.mpg.de (Michael Lachmann)
Date: Fri, 5 Aug 2011 15:22:40 +0200
Subject: [Rd] slightly speeding up readChar()
In-Reply-To: <20027.10552.641615.124070@max.nulle.part>
References: <BAC8BBAE-B965-4BD7-ABFD-A016AC875223@eva.mpg.de>
	<9DA22EB1-E813-4D5D-91EB-46C1E9E8947C@r-project.org>
	<590F85D8-4CD2-4182-917F-6E8900A040DB@eva.mpg.de>
	<20027.10552.641615.124070@max.nulle.part>
Message-ID: <5EC3682B-D93E-4764-803A-BE5A56F1FB4E@eva.mpg.de>


On 5 Aug 2011, at 1:20AM, Dirk Eddelbuettel wrote:

> When you know the (fixed) structure of the data, the CRAN package mmap can be
> a huge winner.

Thanks! I didn't know that.

Is there a package that provides methods for mmap, like sum(x) or maybe even y=x+z
where x, and z are mmaps?

I assume that once you mmap to a huge file, you do operations on it by working on chunks at a time... are there packages for that, or do I have to write my own code?

Thanks!

Michael

From simon.urbanek at r-project.org  Fri Aug  5 16:24:51 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 5 Aug 2011 10:24:51 -0400
Subject: [Rd] initFields() method no longer coerces arguments in R-devel
In-Reply-To: <CAM9CR=2fg_5io9xGZnW86JB-51BOTqxH_Ui=gPh5odciPa7eGA@mail.gmail.com>
References: <CAM9CR=2fg_5io9xGZnW86JB-51BOTqxH_Ui=gPh5odciPa7eGA@mail.gmail.com>
Message-ID: <050B398D-DF57-49E5-8DB3-9DCB3D33E984@r-project.org>

It's worth actually reading the list you post to ...
http://r.789695.n4.nabble.com/Reference-classes-assignments-to-fields-td3708168.html


On Aug 5, 2011, at 6:41 AM, Jon Clayden wrote:

> Dear all,
> 
> I've just had a package update bounced from CRAN because of a recent
> change in R-devel which seems to affect the behaviour of the
> initFields() reference class method. (The change must be very recent
> because I tested the package on a week-old build of R-devel.) It seems
> that the method no longer coerces its arguments to the expected type
> of each field. For a simple example:
> 
>> Foo <- setRefClass("Foo", fields=list(number="integer"), methods=list(initialize=function (number = NULL) initFields(number=number)))
>> Foo$new()
> Error in function (value)  :
>  invalid replacement for field ?number?, should be from class
> ?integer? or a subclass (was class ?NULL?)
> 
> (This used to work, with "number" being set to "integer(0)"). In fact
> it is now extremely strict, not even allowing a double literal which
> is equal to an integer:
> 
>> Foo$new(number=1)
> Error in function (value)  :
>  invalid replacement for field ?number?, should be from class
> ?integer? or a subclass (was class ?numeric?)
> 
> I don't see anything about this in the NEWS, so I was wondering if I
> could get clarification on whether this is now the intended behaviour,
> before I further modify the package. I must say that this will be a
> bit of a pain to "correct"...
> 
> All the best,
> Jon
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From jeffrey.ryan at lemnica.com  Fri Aug  5 16:37:24 2011
From: jeffrey.ryan at lemnica.com (Jeffrey Ryan)
Date: Fri, 5 Aug 2011 09:37:24 -0500
Subject: [Rd] slightly speeding up readChar()
In-Reply-To: <5EC3682B-D93E-4764-803A-BE5A56F1FB4E@eva.mpg.de>
References: <BAC8BBAE-B965-4BD7-ABFD-A016AC875223@eva.mpg.de>
	<9DA22EB1-E813-4D5D-91EB-46C1E9E8947C@r-project.org>
	<590F85D8-4CD2-4182-917F-6E8900A040DB@eva.mpg.de>
	<20027.10552.641615.124070@max.nulle.part>
	<5EC3682B-D93E-4764-803A-BE5A56F1FB4E@eva.mpg.de>
Message-ID: <CABDUZc-FNKFHqD=d0XAoTjhdQtc+yKa3XcwJetnG6YRyJ1zE-g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110805/c889fa6a/attachment.pl>

From jmc at r-project.org  Fri Aug  5 19:22:32 2011
From: jmc at r-project.org (John Chambers)
Date: Fri, 05 Aug 2011 10:22:32 -0700
Subject: [Rd] initFields() method no longer coerces arguments in R-devel
In-Reply-To: <050B398D-DF57-49E5-8DB3-9DCB3D33E984@r-project.org>
References: <CAM9CR=2fg_5io9xGZnW86JB-51BOTqxH_Ui=gPh5odciPa7eGA@mail.gmail.com>
	<050B398D-DF57-49E5-8DB3-9DCB3D33E984@r-project.org>
Message-ID: <4E3C26D8.3030300@r-project.org>

There is also an item in the NEWS file:

     Field assignments in reference classes are now consistent with 
slots in S4 classes: the assigned value must come from the declared 
class (if any) for the field or from a subclass.

On 8/5/11 7:24 AM, Simon Urbanek wrote:
> It's worth actually reading the list you post to ...
> http://r.789695.n4.nabble.com/Reference-classes-assignments-to-fields-td3708168.html
>
>
> On Aug 5, 2011, at 6:41 AM, Jon Clayden wrote:
>
>> Dear all,
>>
>> I've just had a package update bounced from CRAN because of a recent
>> change in R-devel which seems to affect the behaviour of the
>> initFields() reference class method. (The change must be very recent
>> because I tested the package on a week-old build of R-devel.) It seems
>> that the method no longer coerces its arguments to the expected type
>> of each field. For a simple example:
>>
>>> Foo<- setRefClass("Foo", fields=list(number="integer"), methods=list(initialize=function (number = NULL) initFields(number=number)))
>>> Foo$new()
>> Error in function (value)  :
>>   invalid replacement for field ?number?, should be from class
>> ?integer? or a subclass (was class ?NULL?)
>>
>> (This used to work, with "number" being set to "integer(0)"). In fact
>> it is now extremely strict, not even allowing a double literal which
>> is equal to an integer:
>>
>>> Foo$new(number=1)
>> Error in function (value)  :
>>   invalid replacement for field ?number?, should be from class
>> ?integer? or a subclass (was class ?numeric?)
>>
>> I don't see anything about this in the NEWS, so I was wondering if I
>> could get clarification on whether this is now the intended behaviour,
>> before I further modify the package. I must say that this will be a
>> bit of a pain to "correct"...
>>
>> All the best,
>> Jon
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From simon.urbanek at r-project.org  Fri Aug  5 20:36:47 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 5 Aug 2011 14:36:47 -0400
Subject: [Rd] Tesla GPUs
In-Reply-To: <C1E35915-690A-4FA6-93A5-DEA2FE3CE749@r-project.org>
References: <1311004330702-3675684.post@n4.nabble.com>
	<4E245D01.1010407@gmail.com>
	<1311027322959-3676667.post@n4.nabble.com>
	<CC044BB2-F9EA-440F-8A64-5B4639B2A529@r-project.org>
	<1311048424023-3677232.post@n4.nabble.com>
	<alpine.LFD.2.02.1107190640280.28269@gannet.stats.ox.ac.uk>
	<C1E35915-690A-4FA6-93A5-DEA2FE3CE749@r-project.org>
Message-ID: <EDA29725-27D6-4F8F-90B9-1804A17C6A56@r-project.org>


On Jul 19, 2011, at 12:56 PM, Simon Urbanek wrote:

> 
> On Jul 19, 2011, at 2:26 AM, Prof Brian Ripley wrote:
> 
>> On Mon, 18 Jul 2011, Alireza Mahani wrote:
>> 
>>> Simon,
>>> 
>>> Thank you for elaborating on the limitations of R in handling float types. I
>>> think I'm pretty much there with you.
>>> 
>>> As for the insufficiency of single-precision math (and hence limitations of
>>> GPU), my personal take so far has been that double-precision becomes crucial
>>> when some sort of error accumulation occurs. For example, in differential
>>> equations where boundary values are integrated to arrive at interior values,
>>> etc. On the other hand, in my personal line of work (Hierarchical Bayesian
>>> models for quantitative marketing), we have so much inherent uncertainty and
>>> noise at so many levels in the problem (and no significant error
>>> accumulation sources) that single vs double precision issue is often
>>> inconsequential for us. So I think it really depends on the field as well as
>>> the nature of the problem.
>> 
>> The main reason to use only double precision in R was that on modern CPUs double precision calculations are as fast as single-precision ones, and with 64-bit CPUs they are a single access.  So the extra precision comes more-or-less for free.  You also under-estimate the extent to which stability of commonly used algorithms relies on double precision.  (There are stable single-precision versions, but they are no longer commonly used.  And as Simon said, in some cases stability is ensured by using extra precision where available.)
>> 
>> I disagree slightly with Simon on GPUs: I am told by local experts that the double-precision on the latest GPUs (those from the last year or so) is perfectly usable.  See the performance claims on http://en.wikipedia.org/wiki/Nvidia_Tesla of about 50% of the SP performance in DP.
>> 
> 
> That would be good news. Unfortunately those seem to be still targeted at a specialized market and are not really graphics cards in traditional sense. Although this is sort of required for the purpose it removes the benefit of ubiquity. So, yes, I agree with you that it may be an interesting way forward, but I fear it's too much of a niche to be widely supported. I may want to ask our GPU specialists here to see if they have any around so I could re-visit our OpenCL R benchmarks. Last time we abandoned our OpenCL R plans exactly due to the lack of speed in double precision.
> 

A quick update - it turns out we have a few Tesla/Fermi machines here, so I ran some very quick benchmarks on them. The test case was the same as for the original OpenCL comparisons posted here a while ago when Apple introduced it: dnorm on long vectors:

64M, single:
-- GPU -- total: 4894.1 ms, compute: 234.5 ms, compile: 4565.7 ms, real: 328.3 ms
-- CPU -- total: 2290.8 ms

64M, double:
-- GPU -- total: 5448.4 ms, compute: 634.1 ms, compile: 4636.4 ms, real: 812.0 ms
-- CPU -- total: 2415.8 ms

128M, single:
-- GPU -- total: 5843.7 ms, compute: 469.2 ms, compile: 5040.5 ms, real: 803.1 ms
-- CPU -- total: 4568.9 ms

128M, double:
-- GPU -- total: 6042.8 ms, compute: 1093.9 ms, compile: 4583.3 ms, real: 1459.5 ms
-- CPU -- total: 4946.8 ms

The CPU times are based on a dual Xeon X5690 machine (12 cores @ 3.47GHz) using OpenMP, but are very approximate, because there were two other jobs running on machine -- still, it should be a good ballpark figure. The GPU times are run on Tesla S2050 using OpenCL, addressed as one device so presumably comparable to the performance of one Tesla M2050.
The figures to compare are GPU.real (which is computation + host memory I/O) and CPU.total, because we can assume that we can compile the kernel in advance, but you can't save on the memory transfer (unless you find a good way to chain calls which is not realistic in R).

So the good news is that the new GPUs fulfill their promise : double precision is only twice as slow as single precision. Also they scale approximately linearly - see the real time of 64M double is almost the same as 128M single. They also outperform the CPUs as well, although not by an order of magnitude.

The double precision support is very good news, and even though we are still using GPUs in a suboptimal manner, they are faster than the CPUs. The only practical drawback is that using OpenCL requires serious work, it's not as easy as slapping omp pragmas on existing code. Also the HPC Teslas are quite expensive so I don't expect to see them in desktops anytime soon. However, for people that are thinking about big computation, it may be an interesting way to go. Given that it's not mainstream I don't expect core R to have OCL support just yet, but it may be worth keeping in mind for the future as we are designing the parallelization framework in R.

Cheers,
Simon


From jon.clayden at gmail.com  Fri Aug  5 22:10:07 2011
From: jon.clayden at gmail.com (Jon Clayden)
Date: Fri, 5 Aug 2011 21:10:07 +0100
Subject: [Rd] initFields() method no longer coerces arguments in R-devel
In-Reply-To: <4E3C26D8.3030300@r-project.org>
References: <CAM9CR=2fg_5io9xGZnW86JB-51BOTqxH_Ui=gPh5odciPa7eGA@mail.gmail.com>
	<050B398D-DF57-49E5-8DB3-9DCB3D33E984@r-project.org>
	<4E3C26D8.3030300@r-project.org>
Message-ID: <CAM9CR=1F4ji7b13UyrPE--0nQ0eE13BAi6BnC5FM7zZ-9wxayw@mail.gmail.com>

OK, apologies - on both fronts I obviously searched on the wrong
terms. Sorry to waste your time.

Jon


On 5 August 2011 18:22, John Chambers <jmc at r-project.org> wrote:
> There is also an item in the NEWS file:
>
> ? ?Field assignments in reference classes are now consistent with slots in
> S4 classes: the assigned value must come from the declared class (if any)
> for the field or from a subclass.
>
> On 8/5/11 7:24 AM, Simon Urbanek wrote:
>>
>> It's worth actually reading the list you post to ...
>>
>> http://r.789695.n4.nabble.com/Reference-classes-assignments-to-fields-td3708168.html
>>
>>
>> On Aug 5, 2011, at 6:41 AM, Jon Clayden wrote:
>>
>>> Dear all,
>>>
>>> I've just had a package update bounced from CRAN because of a recent
>>> change in R-devel which seems to affect the behaviour of the
>>> initFields() reference class method. (The change must be very recent
>>> because I tested the package on a week-old build of R-devel.) It seems
>>> that the method no longer coerces its arguments to the expected type
>>> of each field. For a simple example:
>>>
>>>> Foo<- setRefClass("Foo", fields=list(number="integer"),
>>>> methods=list(initialize=function (number = NULL) initFields(number=number)))
>>>> Foo$new()
>>>
>>> Error in function (value) ?:
>>> ?invalid replacement for field ?number?, should be from class
>>> ?integer? or a subclass (was class ?NULL?)
>>>
>>> (This used to work, with "number" being set to "integer(0)"). In fact
>>> it is now extremely strict, not even allowing a double literal which
>>> is equal to an integer:
>>>
>>>> Foo$new(number=1)
>>>
>>> Error in function (value) ?:
>>> ?invalid replacement for field ?number?, should be from class
>>> ?integer? or a subclass (was class ?numeric?)
>>>
>>> I don't see anything about this in the NEWS, so I was wondering if I
>>> could get clarification on whether this is now the intended behaviour,
>>> before I further modify the package. I must say that this will be a
>>> bit of a pain to "correct"...
>>>
>>> All the best,
>>> Jon
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From r.m.krug at gmail.com  Fri Aug  5 15:09:34 2011
From: r.m.krug at gmail.com (Rainer M Krug)
Date: Fri, 5 Aug 2011 15:09:34 +0200
Subject: [Rd] Usage of options() for user defined options
Message-ID: <CAGhLh6G3pfgumJ8hcg3w3qRE+xY9Hd2jD8ue0wwbwdKe_P-37A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110805/b840b29e/attachment.pl>

From pawel.matykiewicz at gmail.com  Fri Aug  5 23:33:56 2011
From: pawel.matykiewicz at gmail.com (=?ISO-8859-2?Q?Pawe=B3_Matykiewicz?=)
Date: Fri, 5 Aug 2011 17:33:56 -0400
Subject: [Rd] e1071 ver 1.5-27 and older - SVM bug report
In-Reply-To: <CAEdd+FYFJ-Ua+ZOhs_dBoG=qC2GBj_uynmLVkRKafN1FB90hGw@mail.gmail.com>
References: <CAEdd+FYFJ-Ua+ZOhs_dBoG=qC2GBj_uynmLVkRKafN1FB90hGw@mail.gmail.com>
Message-ID: <CAEdd+Fbr8UpHUGrNmW+My67ro8hyYERJoVzCz-aEwTH42Cy5=A@mail.gmail.com>

Dear All:


I found a problem with the SVM internal cross-validation (CV) accuracy
estimation in the e1071 package.

File: Rsvm.c
Line: 120

Today, it is:

int j = rand()%(prob->l-i);

Should be:

int j = i + rand()%(prob->l-i);

The erroneous code doesn't shuffle objects. Instead, it "randomly"
moves objects from beginning to the end.


In hope for a prompt response from the e1071 developer team,
Thank you,
Regards,
--
Pawel Matykiewicz
http://www.neuron.m4u.pl
http://www.linkedin.com/in/pawelmatykiewicz


From meyerd at technikum-wien.at  Sat Aug  6 12:38:11 2011
From: meyerd at technikum-wien.at (David Meyer)
Date: Sat, 06 Aug 2011 12:38:11 +0200
Subject: [Rd]  e1071 ver 1.5-27 and older - SVM bug report
Message-ID: <4E3D1993.7060505@technikum-wien.at>

Dear Pawel:

yes, this is a bug. Fixed in the next release.

Thanks

David

-----------------------------------------

Dear All:


I found a problem with the SVM internal cross-validation (CV) accuracy
estimation in the e1071 package.

File: Rsvm.c
Line: 120

Today, it is:

int j = rand()%(prob->l-i);

Should be:

int j = i + rand()%(prob->l-i);

The erroneous code doesn't shuffle objects. Instead, it "randomly"
moves objects from beginning to the end.


From tobias.verbeke at openanalytics.eu  Sat Aug  6 16:00:14 2011
From: tobias.verbeke at openanalytics.eu (Tobias Verbeke)
Date: Sat, 06 Aug 2011 16:00:14 +0200
Subject: [Rd] Tesla GPUs
In-Reply-To: <EDA29725-27D6-4F8F-90B9-1804A17C6A56@r-project.org>
References: <1311004330702-3675684.post@n4.nabble.com>	<4E245D01.1010407@gmail.com>	<1311027322959-3676667.post@n4.nabble.com>	<CC044BB2-F9EA-440F-8A64-5B4639B2A529@r-project.org>	<1311048424023-3677232.post@n4.nabble.com>	<alpine.LFD.2.02.1107190640280.28269@gannet.stats.ox.ac.uk>	<C1E35915-690A-4FA6-93A5-DEA2FE3CE749@r-project.org>
	<EDA29725-27D6-4F8F-90B9-1804A17C6A56@r-project.org>
Message-ID: <4E3D48EE.9060602@openanalytics.eu>

On 08/05/2011 08:36 PM, Simon Urbanek wrote:
>
> On Jul 19, 2011, at 12:56 PM, Simon Urbanek wrote:
>
>>
>> On Jul 19, 2011, at 2:26 AM, Prof Brian Ripley wrote:
>>
>>> On Mon, 18 Jul 2011, Alireza Mahani wrote:
>>>
>>>> Simon,
>>>>
>>>> Thank you for elaborating on the limitations of R in handling float types. I
>>>> think I'm pretty much there with you.
>>>>
>>>> As for the insufficiency of single-precision math (and hence limitations of
>>>> GPU), my personal take so far has been that double-precision becomes crucial
>>>> when some sort of error accumulation occurs. For example, in differential
>>>> equations where boundary values are integrated to arrive at interior values,
>>>> etc. On the other hand, in my personal line of work (Hierarchical Bayesian
>>>> models for quantitative marketing), we have so much inherent uncertainty and
>>>> noise at so many levels in the problem (and no significant error
>>>> accumulation sources) that single vs double precision issue is often
>>>> inconsequential for us. So I think it really depends on the field as well as
>>>> the nature of the problem.
>>>
>>> The main reason to use only double precision in R was that on modern CPUs double precision calculations are as fast as single-precision ones, and with 64-bit CPUs they are a single access.  So the extra precision comes more-or-less for free.  You also under-estimate the extent to which stability of commonly used algorithms relies on double precision.  (There are stable single-precision versions, but they are no longer commonly used.  And as Simon said, in some cases stability is ensured by using extra precision where available.)
>>>
>>> I disagree slightly with Simon on GPUs: I am told by local experts that the double-precision on the latest GPUs (those from the last year or so) is perfectly usable.  See the performance claims on http://en.wikipedia.org/wiki/Nvidia_Tesla of about 50% of the SP performance in DP.
>>>
>>
>> That would be good news. Unfortunately those seem to be still targeted at a specialized market and are not really graphics cards in traditional sense. Although this is sort of required for the purpose it removes the benefit of ubiquity. So, yes, I agree with you that it may be an interesting way forward, but I fear it's too much of a niche to be widely supported. I may want to ask our GPU specialists here to see if they have any around so I could re-visit our OpenCL R benchmarks. Last time we abandoned our OpenCL R plans exactly due to the lack of speed in double precision.
>>
>
> A quick update - it turns out we have a few Tesla/Fermi machines here, so I ran some very quick benchmarks on them. The test case was the same as for the original OpenCL comparisons posted here a while ago when Apple introduced it: dnorm on long vectors:
>
> 64M, single:
> -- GPU -- total: 4894.1 ms, compute: 234.5 ms, compile: 4565.7 ms, real: 328.3 ms
> -- CPU -- total: 2290.8 ms
>
> 64M, double:
> -- GPU -- total: 5448.4 ms, compute: 634.1 ms, compile: 4636.4 ms, real: 812.0 ms
> -- CPU -- total: 2415.8 ms
>
> 128M, single:
> -- GPU -- total: 5843.7 ms, compute: 469.2 ms, compile: 5040.5 ms, real: 803.1 ms
> -- CPU -- total: 4568.9 ms
>
> 128M, double:
> -- GPU -- total: 6042.8 ms, compute: 1093.9 ms, compile: 4583.3 ms, real: 1459.5 ms
> -- CPU -- total: 4946.8 ms
>
> The CPU times are based on a dual Xeon X5690 machine (12 cores @ 3.47GHz) using OpenMP, but are very approximate, because there were two other jobs running on machine -- still, it should be a good ballpark figure. The GPU times are run on Tesla S2050 using OpenCL, addressed as one device so presumably comparable to the performance of one Tesla M2050.
> The figures to compare are GPU.real (which is computation + host memory I/O) and CPU.total, because we can assume that we can compile the kernel in advance, but you can't save on the memory transfer (unless you find a good way to chain calls which is not realistic in R).
>
> So the good news is that the new GPUs fulfill their promise : double precision is only twice as slow as single precision. Also they scale approximately linearly - see the real time of 64M double is almost the same as 128M single. They also outperform the CPUs as well, although not by an order of magnitude.
>
> The double precision support is very good news, and even though we are still using GPUs in a suboptimal manner, they are faster than the CPUs. The only practical drawback is that using OpenCL requires serious work, it's not as easy as slapping omp pragmas on existing code. Also the HPC Teslas are quite expensive so I don't expect to see them in desktops anytime soon. However, for people that are thinking about big computation, it may be an interesting way to go. Given that it's not mainstream I don't expect core R to have OCL support just yet, but it may be worth keeping in mind for the future as we are designing the parallelization framework in R.

+1. Chip vendors nowadays also offer a CPU runtime for execution of
OpenCL code on common x86 multi-core CPUs (e.g. of the Opteron series
or Core i7 family) so it may be more ubiquitous soon.

Best,
Tobias


From timothy.c.bates at gmail.com  Sat Aug  6 19:29:16 2011
From: timothy.c.bates at gmail.com (Timothy Bates)
Date: Sat, 6 Aug 2011 18:29:16 +0100
Subject: [Rd] adding examples of stop and break to function.Rd and Control.Rd
Message-ID: <6A05ACD3-86AA-4EDF-BB9E-57FF0BAE7C95@gmail.com>

function.Rd currently has no example of "stop", Similarly in Control.Rd, there is currently no example of break: these might be helpful for users.

function.Rd suggestion:
# Often it is useful to be able to exit a function on some condition: Use "stop" to do this
testJunk <- function(junk) {
	if( is.null(junk)) {
		stop("Junk must not be null!")
	}	
}
junk=NULL
testJunk(junk)



Control.Rd suggestion:

# Example using break: prints n unless n^2 exceeds 9: in which case it exits the loop.

for(n in 1:5) {
   if(n^2>9){
   	break
   } else {
   	cat(n,"\n")
   }
}


From tim.bates at ed.ac.uk  Sun Aug  7 17:12:54 2011
From: tim.bates at ed.ac.uk (Timothy Bates)
Date: Sun, 7 Aug 2011 16:12:54 +0100
Subject: [Rd] \example for replace.Rd
Message-ID: <DC1E6AB0-DF99-44D4-B3A2-659741748C0F@ed.ac.uk>

The base help file replace.Rd has no usage example. Might this example be helpful?


\examples{
	foo <- c("Yes","n","no answer")
	foo <- replace(foo, list=c(2, 3), values=c("No?, NA))
	foo # "Yes" "No"  NA
}



Also, the Rd file doesn?t point to other relevant functions the user coming here might find useful. I?d suggest:

\seealso{
  \code{\link{rename} (reshape package)}
}

-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From jorismeys at gmail.com  Mon Aug  8 00:26:03 2011
From: jorismeys at gmail.com (Joris Meys)
Date: Mon, 8 Aug 2011 00:26:03 +0200
Subject: [Rd] all.equal doesn't work for POSIXlt objects
Message-ID: <CAO1zAVauL433-rOyNR6Y-9b+e8YOowL2MoRFZ+3aj1fiZjbHEw@mail.gmail.com>

Hi all,

following sample code illustrates the problem :

  Date1 <- Date2 <-
as.POSIXlt(seq.Date(as.Date("2010-04-01"),as.Date("2011-04-01"),by='day'))
  identical(Date1,Date2)
  all.equal(Date1,Date2)

identical() gives the correct answer. As there is no all.equal method
for POSIXlt objects, all.equal.list is used instead. Subsetting using
[[]] doesn't work on POSIXlt objects. I solved the problem by adding a
function all.equal.POSIXlt() :

all.equal.POSIXlt <- function(target, current, ..., scale=1) {
  check_tzones(target, current)
  target <- unclass(target)
  current <- unclass(current)
  NextMethod("all.equal.list")
}

This seems to work bugfree, but I'm not sure about it. So am I doing
it correct, and if so, can this be added to the next R release? I'm
not sure where else I should drop this proposal...

Cheers
Joris

-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Applied mathematics, biometrics and process control

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From r.turner at auckland.ac.nz  Mon Aug  8 02:49:44 2011
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 08 Aug 2011 12:49:44 +1200
Subject: [Rd] Xll.options().
Message-ID: <4E3F32A8.6020401@auckland.ac.nz>


This question seemed to me to be more appropriate for r-devel
than for r-help.  My apologies if this is not the case.

Recently I installed ``cairo'' on my lap-top so that I could make
use of the (newish) polypath() function, with on-screen graphics.
(The polypath() function does not work with X11(type="Xlib").)

The installation went smoothly, X11(type="cairo") works just fine,
and polypath() works just fine.

However the default "type" for X11() remains "Xlib" rather than
"cairo".

The help for X11.options() says (in respect of "type"):

     Default "cairo" where available and reliable, otherwise "Xlib".

Now "cairo" is definitely available:

 > capabilities()["cairo"]
     cairo
      TRUE

and moreover it works (just fine!) when I do X11(type="cairo")
explicitly.

I know that I can set the default to be "cairo" in my .Rprofile, but
I am curious as to why "cairo" does not become the default automatically.

Is it the case that "cairo" is ``not reliable'' under my system?  It 
***seems***
to be reliable.

 > sessionInfo()
R version 2.13.1 Patched (2011-07-17 r56404)
Platform: i686-pc-linux-gnu (32-bit)

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] datasets  utils     stats     graphics  grDevices methods   base

other attached packages:
[1] misc_0.0-13     gtools_2.6.2    spatstat_1.23-1 deldir_0.0-15
[5] mgcv_1.7-6      fortunes_1.4-2  MASS_7.3-13

loaded via a namespace (and not attached):
[1] grid_2.13.1        lattice_0.19-30    Matrix_0.999375-50 nlme_3.1-101

     cheers,

         Rolf Turner


From hkawakat at gmail.com  Mon Aug  8 03:40:05 2011
From: hkawakat at gmail.com (Hiroyuki Kawakatsu)
Date: Mon, 8 Aug 2011 10:40:05 +0900
Subject: [Rd] R-admin.html fixes (for cairo support in windoze)
Message-ID: <CADBEN2wnPM_jXz0dqE-Ai7D5UmssVjpv4FM=ya+PqzUo4h1CvA@mail.gmail.com>

Hi,

For building r56651 on windoze (32bit), I was re-reading R-admin.html
and noticed cairo support (section 3.1.5). The description in that
section appears to be missing the instruction to build the dll. By
looking at the makefile, I figured that to be `make cairodevices'.

Also the links in option 1 appear to be dead. After downloading
several files, I found that the "bundled" file
http://ftp.gnome.org/pub/gnome/binaries/win32/gtk+/2.22/gtk+-bundle_2.22.1-20101227_win32.zip
seems the easiest to use (for option 1).

h.
-- 
+---
| Hiroyuki Kawakatsu
| Business School, Dublin City University
| Dublin 9, Ireland. Tel +353 (0)1 700 7496


From Kurt.Hornik at wu.ac.at  Mon Aug  8 08:07:23 2011
From: Kurt.Hornik at wu.ac.at (Kurt Hornik)
Date: Mon, 8 Aug 2011 08:07:23 +0200
Subject: [Rd] all.equal doesn't work for POSIXlt objects
In-Reply-To: <CAO1zAVauL433-rOyNR6Y-9b+e8YOowL2MoRFZ+3aj1fiZjbHEw@mail.gmail.com>
References: <CAO1zAVauL433-rOyNR6Y-9b+e8YOowL2MoRFZ+3aj1fiZjbHEw@mail.gmail.com>
Message-ID: <20031.32027.537956.411788@fangorn.hornik.net>

>>>>> Joris Meys writes:

This is already fixed in r-devel.

-k

> Hi all,
> following sample code illustrates the problem :

>   Date1 <- Date2 <-
> as.POSIXlt(seq.Date(as.Date("2010-04-01"),as.Date("2011-04-01"),by='day'))
>   identical(Date1,Date2)
>   all.equal(Date1,Date2)

> identical() gives the correct answer. As there is no all.equal method
> for POSIXlt objects, all.equal.list is used instead. Subsetting using
> [[]] doesn't work on POSIXlt objects. I solved the problem by adding a
> function all.equal.POSIXlt() :

> all.equal.POSIXlt <- function(target, current, ..., scale=1) {
>   check_tzones(target, current)
>   target <- unclass(target)
>   current <- unclass(current)
>   NextMethod("all.equal.list")
> }

> This seems to work bugfree, but I'm not sure about it. So am I doing
> it correct, and if so, can this be added to the next R release? I'm
> not sure where else I should drop this proposal...

> Cheers
> Joris

> -- 
> Joris Meys
> Statistical consultant

> Ghent University
> Faculty of Bioscience Engineering
> Department of Applied mathematics, biometrics and process control

> tel : +32 9 264 59 87
> Joris.Meys at Ugent.be
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Mon Aug  8 10:20:16 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 8 Aug 2011 10:20:16 +0200
Subject: [Rd] X11.options().
In-Reply-To: <4E3F32A8.6020401@auckland.ac.nz>
References: <4E3F32A8.6020401@auckland.ac.nz>
Message-ID: <20031.40000.460197.554924@stat.math.ethz.ch>

Hi Rolf,

please excuse a short "top-reply":

As I see you are using an operating system (instead of Win..),
can you try in the shell

       echo 'X11.options()$type' | R --vanilla --slave

and does that really *not* report 
[1] "cairo"

??

(and BTW: Your subject had   tolower("LL")  instead of  "11" )

>>>>> Rolf Turner <r.turner at auckland.ac.nz>
>>>>>     on Mon, 8 Aug 2011 12:49:44 +1200 writes:

    > This question seemed to me to be more appropriate for
    > r-devel than for r-help.  My apologies if this is not the
    > case.

    > Recently I installed ``cairo'' on my lap-top so that I
    > could make use of the (newish) polypath() function, with
    > on-screen graphics.  (The polypath() function does not
    > work with X11(type="Xlib").)

    > The installation went smoothly, X11(type="cairo") works
    > just fine, and polypath() works just fine.

    > However the default "type" for X11() remains "Xlib" rather
    > than "cairo".

    > The help for X11.options() says (in respect of "type"):

    >      Default "cairo" where available and reliable,
    > otherwise "Xlib".

    > Now "cairo" is definitely available:

    >> capabilities()["cairo"]
    >      cairo TRUE

    > and moreover it works (just fine!) when I do
    > X11(type="cairo") explicitly.

    > I know that I can set the default to be "cairo" in my
    > .Rprofile, but I am curious as to why "cairo" does not
    > become the default automatically.

    > Is it the case that "cairo" is ``not reliable'' under my
    > system?  It ***seems*** to be reliable.

    >> sessionInfo()
    > R version 2.13.1 Patched (2011-07-17 r56404) Platform:
    > i686-pc-linux-gnu (32-bit)

    > locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3]
    > LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5]
    > LC_MONETARY=C LC_MESSAGES=en_US.UTF-8 [7]
    > LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C
    > LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8
    > LC_IDENTIFICATION=C

    > attached base packages: [1] datasets utils stats graphics
    > grDevices methods base

    > other attached packages: [1] misc_0.0-13 gtools_2.6.2
    > spatstat_1.23-1 deldir_0.0-15 [5] mgcv_1.7-6
    > fortunes_1.4-2 MASS_7.3-13

    > loaded via a namespace (and not attached): [1] grid_2.13.1
    > lattice_0.19-30 Matrix_0.999375-50 nlme_3.1-101

    >      cheers,

    >          Rolf Turner

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From r.turner at auckland.ac.nz  Mon Aug  8 10:29:28 2011
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 08 Aug 2011 20:29:28 +1200
Subject: [Rd] X11.options().
In-Reply-To: <20031.40000.460197.554924@stat.math.ethz.ch>
References: <4E3F32A8.6020401@auckland.ac.nz>
	<20031.40000.460197.554924@stat.math.ethz.ch>
Message-ID: <4E3F9E68.4020305@auckland.ac.nz>

On 08/08/11 20:20, Martin Maechler wrote:
> Hi Rolf,
>
> please excuse a short "top-reply":
No problema.  Thanks for replying.
> As I see you are using an operating system (instead of Win..),
> can you try in the shell
>
>         echo 'X11.options()$type' | R --vanilla --slave
>
> and does that really *not* report
> [1] "cairo"
Sure.

It really does *not* report "cairo"!!!:

> ~> echo 'X11.options()$type' | R --vanilla --slave
> [1] "Xlib"
> ??
>
> (and BTW: Your subject had   tolower("LL")  instead of  "11" )
Whoops.  Oh dear.  Blame it on senility. :-(

     cheers,

         Rolf


From jeroen.ooms at stat.ucla.edu  Mon Aug  8 13:02:52 2011
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Mon, 8 Aug 2011 13:02:52 +0200
Subject: [Rd] Overwriting imported function in another package
Message-ID: <CABFfbXvuYi=nYQ72ULVyQX87q288Wu7jAioPMXmBhKU6EvcJ+g@mail.gmail.com>

I am running into a limitation of the grid::grid.newpage function, for
which I would like to overwrite this function with a slightly modified
one. Hopefully this is a temporary working solution until the package
gets updated. I found a way to overwrite the function in the
package:grid namespace. However, lattice imports grid rather than
depending on it. So I need a way to overwrite this imported version as
well. The code below shows the fix which works for ggplot (because it
depends on grid), but it doesn't work for lattice, because it imports
grid. Is there any way to overwrite grid.newpage for all
instantiations of it?

#packages
library(grid);
library(lattice);
library(ggplot2);

#create the modified function.
hookfun <- deparse(body(plot.new))[1:6]
oldfun <- deparse(body(grid::grid.newpage))[-1];
newfun <- grid::grid.newpage;
body(newfun) <- parse(text=c(hookfun, oldfun));

#overwrite it in the package
unlockBinding("grid.newpage", as.environment("package:grid"))
assign("grid.newpage", newfun, pos="package:grid")

#this seems ok:
get('grid.newpage', as.environment("package:grid"));
get('grid.newpage', as.environment("package:lattice"));

#but this is still the old one
get('grid.newpage', environment(histogram));

#test if it worked:
setHook("before.plot.new", function() {message("Yay! A new plot.");});
qplot(rnorm(100)); #it worked for ggplot2
histogram(rnorm(100)); #didn't work for lattice


From murdoch.duncan at gmail.com  Mon Aug  8 14:19:30 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 08 Aug 2011 08:19:30 -0400
Subject: [Rd] Overwriting imported function in another package
In-Reply-To: <CABFfbXvuYi=nYQ72ULVyQX87q288Wu7jAioPMXmBhKU6EvcJ+g@mail.gmail.com>
References: <CABFfbXvuYi=nYQ72ULVyQX87q288Wu7jAioPMXmBhKU6EvcJ+g@mail.gmail.com>
Message-ID: <4E3FD452.8070209@gmail.com>

On 08/08/2011 7:02 AM, Jeroen Ooms wrote:
> I am running into a limitation of the grid::grid.newpage function, for
> which I would like to overwrite this function with a slightly modified
> one. Hopefully this is a temporary working solution until the package
> gets updated. I found a way to overwrite the function in the
> package:grid namespace. However, lattice imports grid rather than
> depending on it. So I need a way to overwrite this imported version as
> well. The code below shows the fix which works for ggplot (because it
> depends on grid), but it doesn't work for lattice, because it imports
> grid. Is there any way to overwrite grid.newpage for all
> instantiations of it?

Yes, modify the source and recompile R.

Duncan Murdoch

> #packages
> library(grid);
> library(lattice);
> library(ggplot2);
>
> #create the modified function.
> hookfun<- deparse(body(plot.new))[1:6]
> oldfun<- deparse(body(grid::grid.newpage))[-1];
> newfun<- grid::grid.newpage;
> body(newfun)<- parse(text=c(hookfun, oldfun));
>
> #overwrite it in the package
> unlockBinding("grid.newpage", as.environment("package:grid"))
> assign("grid.newpage", newfun, pos="package:grid")
>
> #this seems ok:
> get('grid.newpage', as.environment("package:grid"));
> get('grid.newpage', as.environment("package:lattice"));
>
> #but this is still the old one
> get('grid.newpage', environment(histogram));
>
> #test if it worked:
> setHook("before.plot.new", function() {message("Yay! A new plot.");});
> qplot(rnorm(100)); #it worked for ggplot2
> histogram(rnorm(100)); #didn't work for lattice
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jeroen.ooms at stat.ucla.edu  Mon Aug  8 14:40:53 2011
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Mon, 8 Aug 2011 14:40:53 +0200
Subject: [Rd] Overwriting imported function in another package
In-Reply-To: <4E3FD452.8070209@gmail.com>
References: <CABFfbXvuYi=nYQ72ULVyQX87q288Wu7jAioPMXmBhKU6EvcJ+g@mail.gmail.com>
	<4E3FD452.8070209@gmail.com>
Message-ID: <CABFfbXvTUCS+BJZkbYJPSaD6uFqw0kEf1_kkq6dXQ75CDp1sjA@mail.gmail.com>

> Yes, modify the source and recompile R.

That is what I am doing now, but can't expect that everyone who uses
my code is willing to recompile R from src...


From murdoch.duncan at gmail.com  Mon Aug  8 14:47:30 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 08 Aug 2011 08:47:30 -0400
Subject: [Rd] Overwriting imported function in another package
In-Reply-To: <CABFfbXvTUCS+BJZkbYJPSaD6uFqw0kEf1_kkq6dXQ75CDp1sjA@mail.gmail.com>
References: <CABFfbXvuYi=nYQ72ULVyQX87q288Wu7jAioPMXmBhKU6EvcJ+g@mail.gmail.com>
	<4E3FD452.8070209@gmail.com>
	<CABFfbXvTUCS+BJZkbYJPSaD6uFqw0kEf1_kkq6dXQ75CDp1sjA@mail.gmail.com>
Message-ID: <4E3FDAE2.3000700@gmail.com>

On 08/08/2011 8:40 AM, Jeroen Ooms wrote:
> >  Yes, modify the source and recompile R.
>
> That is what I am doing now, but can't expect that everyone who uses
> my code is willing to recompile R from src...

But everyone who uses your code has a right to expect that other 
packages are not affected by it.

Duncan Murdoch


From simon.urbanek at r-project.org  Mon Aug  8 17:50:26 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 8 Aug 2011 11:50:26 -0400
Subject: [Rd] OpenCL [Was: Tesla GPUs]
In-Reply-To: <EDA29725-27D6-4F8F-90B9-1804A17C6A56@r-project.org>
References: <1311004330702-3675684.post@n4.nabble.com>
	<4E245D01.1010407@gmail.com>
	<1311027322959-3676667.post@n4.nabble.com>
	<CC044BB2-F9EA-440F-8A64-5B4639B2A529@r-project.org>
	<1311048424023-3677232.post@n4.nabble.com>
	<alpine.LFD.2.02.1107190640280.28269@gannet.stats.ox.ac.uk>
	<C1E35915-690A-4FA6-93A5-DEA2FE3CE749@r-project.org>
	<EDA29725-27D6-4F8F-90B9-1804A17C6A56@r-project.org>
Message-ID: <938A4B7D-00A2-43E0-8097-17AB23A39D7F@r-project.org>

I have created a small package called OpenCL which allows the use of OpenCL kernels in R. It supports both single and double precision and arbitrary number of input arguments. The kernel in the ?oclRun example is very close to what I used for the testing below (obviously you won't be able to run fair single-precision tests, because R needs to convert both input and output vectors to/from double precision).
Its home is at
http://rforge.net/OpenCL
and CRAN deo volente it may appear on CRAN soon.

Cheers,
Simon


On Aug 5, 2011, at 2:36 PM, Simon Urbanek wrote:

> 
> On Jul 19, 2011, at 12:56 PM, Simon Urbanek wrote:
> 
>> 
>> On Jul 19, 2011, at 2:26 AM, Prof Brian Ripley wrote:
>> 
>>> On Mon, 18 Jul 2011, Alireza Mahani wrote:
>>> 
>>>> Simon,
>>>> 
>>>> Thank you for elaborating on the limitations of R in handling float types. I
>>>> think I'm pretty much there with you.
>>>> 
>>>> As for the insufficiency of single-precision math (and hence limitations of
>>>> GPU), my personal take so far has been that double-precision becomes crucial
>>>> when some sort of error accumulation occurs. For example, in differential
>>>> equations where boundary values are integrated to arrive at interior values,
>>>> etc. On the other hand, in my personal line of work (Hierarchical Bayesian
>>>> models for quantitative marketing), we have so much inherent uncertainty and
>>>> noise at so many levels in the problem (and no significant error
>>>> accumulation sources) that single vs double precision issue is often
>>>> inconsequential for us. So I think it really depends on the field as well as
>>>> the nature of the problem.
>>> 
>>> The main reason to use only double precision in R was that on modern CPUs double precision calculations are as fast as single-precision ones, and with 64-bit CPUs they are a single access.  So the extra precision comes more-or-less for free.  You also under-estimate the extent to which stability of commonly used algorithms relies on double precision.  (There are stable single-precision versions, but they are no longer commonly used.  And as Simon said, in some cases stability is ensured by using extra precision where available.)
>>> 
>>> I disagree slightly with Simon on GPUs: I am told by local experts that the double-precision on the latest GPUs (those from the last year or so) is perfectly usable.  See the performance claims on http://en.wikipedia.org/wiki/Nvidia_Tesla of about 50% of the SP performance in DP.
>>> 
>> 
>> That would be good news. Unfortunately those seem to be still targeted at a specialized market and are not really graphics cards in traditional sense. Although this is sort of required for the purpose it removes the benefit of ubiquity. So, yes, I agree with you that it may be an interesting way forward, but I fear it's too much of a niche to be widely supported. I may want to ask our GPU specialists here to see if they have any around so I could re-visit our OpenCL R benchmarks. Last time we abandoned our OpenCL R plans exactly due to the lack of speed in double precision.
>> 
> 
> A quick update - it turns out we have a few Tesla/Fermi machines here, so I ran some very quick benchmarks on them. The test case was the same as for the original OpenCL comparisons posted here a while ago when Apple introduced it: dnorm on long vectors:
> 
> 64M, single:
> -- GPU -- total: 4894.1 ms, compute: 234.5 ms, compile: 4565.7 ms, real: 328.3 ms
> -- CPU -- total: 2290.8 ms
> 
> 64M, double:
> -- GPU -- total: 5448.4 ms, compute: 634.1 ms, compile: 4636.4 ms, real: 812.0 ms
> -- CPU -- total: 2415.8 ms
> 
> 128M, single:
> -- GPU -- total: 5843.7 ms, compute: 469.2 ms, compile: 5040.5 ms, real: 803.1 ms
> -- CPU -- total: 4568.9 ms
> 
> 128M, double:
> -- GPU -- total: 6042.8 ms, compute: 1093.9 ms, compile: 4583.3 ms, real: 1459.5 ms
> -- CPU -- total: 4946.8 ms
> 
> The CPU times are based on a dual Xeon X5690 machine (12 cores @ 3.47GHz) using OpenMP, but are very approximate, because there were two other jobs running on machine -- still, it should be a good ballpark figure. The GPU times are run on Tesla S2050 using OpenCL, addressed as one device so presumably comparable to the performance of one Tesla M2050.
> The figures to compare are GPU.real (which is computation + host memory I/O) and CPU.total, because we can assume that we can compile the kernel in advance, but you can't save on the memory transfer (unless you find a good way to chain calls which is not realistic in R).
> 
> So the good news is that the new GPUs fulfill their promise : double precision is only twice as slow as single precision. Also they scale approximately linearly - see the real time of 64M double is almost the same as 128M single. They also outperform the CPUs as well, although not by an order of magnitude.
> 
> The double precision support is very good news, and even though we are still using GPUs in a suboptimal manner, they are faster than the CPUs. The only practical drawback is that using OpenCL requires serious work, it's not as easy as slapping omp pragmas on existing code. Also the HPC Teslas are quite expensive so I don't expect to see them in desktops anytime soon. However, for people that are thinking about big computation, it may be an interesting way to go. Given that it's not mainstream I don't expect core R to have OCL support just yet, but it may be worth keeping in mind for the future as we are designing the parallelization framework in R.
> 
> Cheers,
> Simon
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From jahftw at googlemail.com  Mon Aug  8 18:44:51 2011
From: jahftw at googlemail.com (=?ISO-8859-1?Q?Lars_Wi=DFler?=)
Date: Mon, 8 Aug 2011 18:44:51 +0200
Subject: [Rd] Adressing Problems: R with Fortran and OpenMP
Message-ID: <CADJn3heK_dfMLAPxOPE=r-F1K_8vjsbOq4dUHrYJLN9TwTz-cw@mail.gmail.com>

Hello,

I am programming an R program with nested Fortran calls for
calculations and OpenMP for parallelization. I am getting a changing
error corresponding to memory addressing problems, when using a 64-bit
system. Using a 32-bit System the application runs without problems.
The errors on 64-bit range from null-pointer failures, over
segmentation faults, over stack imbalances (changing differences and I
am not using C/C++) to finishing without exception but with wrong
values. Sometimes it even works correctly on 64-bit, mostly when
executing a second time within the same R session. Sometimes an
endless loop "Error: bad target context--should NEVER happen; please
bug.report() [R_run_onexits]" appears.

The problem seems to be platform independent. I have tried windows 7,
windows vista and open suse 11.3. (x86-64). Evaluation with valgrid
reveals a major possible memory leak, though the leak appears on
32-bit systems as well, just no errors. I am using a gfortran 4.5.0
x86-64 compiler and R version 2.12.

valgrid log extract:
==22989== 25,559,200 bytes in 4 blocks are possibly lost in loss
record 5,678 of 5,678
==22989==    at 0x4C26C3A: malloc (in
/usr/lib64/valgrind/vgpreload_memcheck-amd64-linux.so)
==22989==    by 0x4F39907: Rf_allocVector (in /usr/lib64/R/lib/libR.so)
==22989==    by 0x4EDAF96: duplicate1 (in /usr/lib64/R/lib/libR.so)
==22989==    by 0x4FC204E: R_subassign3_dflt (in /usr/lib64/R/lib/libR.so)
==22989==    by 0x4FC24A2: do_subassign3 (in /usr/lib64/R/lib/libR.so)
==22989==    by 0x4F00B4A: Rf_eval (in /usr/lib64/R/lib/libR.so)
==22989==    by 0x4F0346F: do_set (in /usr/lib64/R/lib/libR.so)
==22989==    by 0x4F00B4A: Rf_eval (in /usr/lib64/R/lib/libR.so)
==22989==    by 0x4F02EB1: applydefine (in /usr/lib64/R/lib/libR.so)
==22989==    by 0x4F00B4A: Rf_eval (in /usr/lib64/R/lib/libR.so)
==22989==    by 0x4F035EB: do_begin (in /usr/lib64/R/lib/libR.so)
==22989==    by 0x4F00B4A: Rf_eval (in /usr/lib64/R/lib/libR.so)
==22989==
==22989== LEAK SUMMARY:
==22989==    definitely lost: 82 bytes in 1 blocks
==22989==    indirectly lost: 0 bytes in 0 blocks
==22989==      possibly lost: 109,720,966 bytes in 26,330 blocks
==22989==    still reachable: 23,101,045 bytes in 5,105 blocks
==22989==         suppressed: 0 bytes in 0 blocks

All pointers in Fortran are explicitly defined with integer*4 and
real*8 as double.

I am really lost in this, because i just dont know where to start and
stop looking. It is obvious to me, that there is some kind of memory
adressing problem related to 64-bit architecture but since I dont know
if its related to R or Fortran or OpenMp or a combination of those, it
is very hard to find. Also the program is part of a library with 40+
files which interact, so I it would be really hard and time consuming
to cut the program down to a size, where the error will be reproduced
and still managable.

Any help, ideas, suggestions as to what to do, where to look and what
to try would be very welcome. I have been trying to solve this problem
for nearly two weeks and read everything I could find regarding
x86-64, R, Fortran, OpenMP and memory issues. I could post more and
more specific information regarding the errors, but then the
description would get even bigger. So if I need to supply more
information, please tell me and I will do so.

Regards
Lars

Following are the code snippets for the Fortran call and the entrance
to the Fortran program with OpenMp definition. If the program fails
with an statement about where it failed (i.e. segmentation fault),
then it gives this call as place. But since I only get R errors and
not Fortran errors, the error might actually occur anywhere in
Fortran.

 z <- .Fortran("nlrdtirg",
                as.integer(si),
                as.integer(ngrad),
                as.integer(ddim[1]),
                as.integer(ddim[2]),
                as.integer(ddim[3]),
                as.logical(mask),
                as.double(object at btb),
                as.double(sdcoef),
                th0=as.double(s0),
                D=double(6*prod(ddim)),
                as.integer(200),
                as.double(1e-6),
                res=double(ngrad*prod(ddim)),
                rss=double(prod(ddim)),
                double(ngrad*num_threads),
				as.integer(num_threads),
                PACKAGE="dti",DUP=TRUE)


     subroutine nlrdtirg(s,nb,n1,n2,n3,mask,b,sdcoef,th0,D,niter,eps,
     1                    res,rss,varinv,nt)

      use omp_lib
      implicit logical*4 (a-z)
      integer*4 nb,n1,n2,n3,s(nb,n1,n2,n3),niter,nt,tid
      logical mask(n1,n2,n3)
      real*8 D(6,n1,n2,n3),b(6,nb),res(nb,n1,n2,n3),
     1    th0(n1,n2,n3),eps,rss(n1,n2,n3),sdcoef(4),varinv(nt*nb)
      integer*4 i1,i2,i3,j

      DO i3=1,n3
         DO i2=1,n2
C$OMP PARALLEL DEFAULT(NONE)
C$OMP& SHARED(mask,s,b,sdcoef,th0,D,res,rss,varinv,nb,niter,eps)
C$OMP& FIRSTPRIVATE(i2,i3,n1)
C$OMP& PRIVATE(i1,j,tid)
C$OMP DO SCHEDULE(DYNAMIC,1)


From ligges at statistik.tu-dortmund.de  Mon Aug  8 21:38:06 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 08 Aug 2011 21:38:06 +0200
Subject: [Rd] X11.options().
In-Reply-To: <20031.40000.460197.554924@stat.math.ethz.ch>
References: <4E3F32A8.6020401@auckland.ac.nz>
	<20031.40000.460197.554924@stat.math.ethz.ch>
Message-ID: <4E403B1E.2070008@statistik.tu-dortmund.de>



On 08.08.2011 10:20, Martin Maechler wrote:
> Hi Rolf,
>
> please excuse a short "top-reply":
>
> As I see you are using an operating system (instead of Win..),
> can you try in the shell
>
>         echo 'X11.options()$type' | R --vanilla --slave


Martin,

given the R on my non-OS had X11.options, I'd rather written:

R --slave --vanilla -e "X11.options()$type"

Don't know why you have to type more on your OS.

Uwe


> and does that really *not* report
> [1] "cairo"
>
> ??
>
> (and BTW: Your subject had   tolower("LL")  instead of  "11" )
>
>>>>>> Rolf Turner<r.turner at auckland.ac.nz>
>>>>>>      on Mon, 8 Aug 2011 12:49:44 +1200 writes:
>
>      >  This question seemed to me to be more appropriate for
>      >  r-devel than for r-help.  My apologies if this is not the
>      >  case.
>
>      >  Recently I installed ``cairo'' on my lap-top so that I
>      >  could make use of the (newish) polypath() function, with
>      >  on-screen graphics.  (The polypath() function does not
>      >  work with X11(type="Xlib").)
>
>      >  The installation went smoothly, X11(type="cairo") works
>      >  just fine, and polypath() works just fine.
>
>      >  However the default "type" for X11() remains "Xlib" rather
>      >  than "cairo".
>
>      >  The help for X11.options() says (in respect of "type"):
>
>      >       Default "cairo" where available and reliable,
>      >  otherwise "Xlib".
>
>      >  Now "cairo" is definitely available:
>
>      >>  capabilities()["cairo"]
>      >       cairo TRUE
>
>      >  and moreover it works (just fine!) when I do
>      >  X11(type="cairo") explicitly.
>
>      >  I know that I can set the default to be "cairo" in my
>      >  .Rprofile, but I am curious as to why "cairo" does not
>      >  become the default automatically.
>
>      >  Is it the case that "cairo" is ``not reliable'' under my
>      >  system?  It ***seems*** to be reliable.
>
>      >>  sessionInfo()
>      >  R version 2.13.1 Patched (2011-07-17 r56404) Platform:
>      >  i686-pc-linux-gnu (32-bit)
>
>      >  locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3]
>      >  LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5]
>      >  LC_MONETARY=C LC_MESSAGES=en_US.UTF-8 [7]
>      >  LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C
>      >  LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8
>      >  LC_IDENTIFICATION=C
>
>      >  attached base packages: [1] datasets utils stats graphics
>      >  grDevices methods base
>
>      >  other attached packages: [1] misc_0.0-13 gtools_2.6.2
>      >  spatstat_1.23-1 deldir_0.0-15 [5] mgcv_1.7-6
>      >  fortunes_1.4-2 MASS_7.3-13
>
>      >  loaded via a namespace (and not attached): [1] grid_2.13.1
>      >  lattice_0.19-30 Matrix_0.999375-50 nlme_3.1-101
>
>      >       cheers,
>
>      >           Rolf Turner
>
>      >  ______________________________________________
>      >  R-devel at r-project.org mailing list
>      >  https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From gomoris at battelle.org  Mon Aug  8 20:53:51 2011
From: gomoris at battelle.org (sgomori)
Date: Mon, 8 Aug 2011 11:53:51 -0700 (PDT)
Subject: [Rd] Making rmath.dll (or equivalent)
Message-ID: <1312829631500-3727906.post@n4.nabble.com>

I currently have R 2.12.1 installed, both 32 and 64 bit. I also have a file
that was passed to me named rmath.dll. I do not know what version of R it
was created from, but I do know it is 32-bit only. I am developing an
application in C# that uses this library as a reference but I have to
downgrade it to 32-bit in order to use the DLL file. 

I wish to make a rmath.dll from the version of R I have on my computer. I
have looked for instructions online for this, but all I can find reference
folders/files not in my install, I am guessing these instructions are for
older versions of R.

Can anyone point me to how I can accomplish this, creating a 64-bit DLL for
R's math functonality?

Thanks in advance.

--
View this message in context: http://r.789695.n4.nabble.com/Making-rmath-dll-or-equivalent-tp3727906p3727906.html
Sent from the R devel mailing list archive at Nabble.com.


From maechler at stat.math.ethz.ch  Mon Aug  8 21:46:33 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 8 Aug 2011 21:46:33 +0200
Subject: [Rd] X11.options().
In-Reply-To: <4E403B1E.2070008@statistik.tu-dortmund.de>
References: <4E3F32A8.6020401@auckland.ac.nz>
	<20031.40000.460197.554924@stat.math.ethz.ch>
	<4E403B1E.2070008@statistik.tu-dortmund.de>
Message-ID: <20032.15641.407322.641625@stat.math.ethz.ch>

>>>>> Uwe Ligges <ligges at statistik.tu-dortmund.de>
>>>>>     on Mon, 8 Aug 2011 21:38:06 +0200 writes:

    > On 08.08.2011 10:20, Martin Maechler wrote:
    >> Hi Rolf,
    >> 
    >> please excuse a short "top-reply":
    >> 
    >> As I see you are using an operating system (instead of
    >> Win..), can you try in the shell
    >> 
    >> echo 'X11.options()$type' | R --vanilla --slave


    > Martin,

    > given the R on my non-OS had X11.options, I'd rather
    > written:

    > R --slave --vanilla -e "X11.options()$type"

    > Don't know why you have to type more on your OS.

:-)   

touch?,  Uwe!

Martin


From kasperdanielhansen at gmail.com  Mon Aug  8 23:30:41 2011
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Mon, 8 Aug 2011 17:30:41 -0400
Subject: [Rd] NAMESPACE imports
Message-ID: <CAC2h7usjGdE=JVNfjZB3YRDDKeXSvVGfydHh2Lx3vxwqSJ6kMg@mail.gmail.com>

Is there some functionality for NAMSPACE files where I can import a
package, except a couple of functions, something like
  importExcept

The situation is that I import from two different packages, A and B .
A (Biobase) is quite big and I essentially want to import all of the
package.  B (matrixStats) is very small and I also want to import the
whole package,  However, there is a name conflict (rowMedians and
anyMissing exists in both packages) and I prefer to keep the version
from the small package B.  As I understand it, this means I need to
change my current
  import(Biobase)
  import(matrixStats)
to something like
  importFrom(Biobase, ***)
  import(matrixStats)
where *** is a list of all functions in Biobase except rowMedians (and
anyMissing), because right now R CMD check complains.  Is there a
better way?  If not, I would like to put in a request for something
like
  importFromExcept()

Thanks,
Kasper


From r.turner at auckland.ac.nz  Tue Aug  9 01:10:38 2011
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 09 Aug 2011 11:10:38 +1200
Subject: [Rd] X11.options().
In-Reply-To: <20032.15641.407322.641625@stat.math.ethz.ch>
References: <4E3F32A8.6020401@auckland.ac.nz>	<20031.40000.460197.554924@stat.math.ethz.ch>	<4E403B1E.2070008@statistik.tu-dortmund.de>
	<20032.15641.407322.641625@stat.math.ethz.ch>
Message-ID: <4E406CEE.6070707@auckland.ac.nz>



Uh, to get back to the (my) point --- anybody have any ideas as to why
X11.options()$type is defaulting to "Xlib" rather than "cairo" even though
cairo is available and apparently (???) ``reliable''?

     cheers,

         Rolf


From Mark.Bravington at csiro.au  Tue Aug  9 03:58:27 2011
From: Mark.Bravington at csiro.au (Mark.Bravington at csiro.au)
Date: Tue, 9 Aug 2011 11:58:27 +1000
Subject: [Rd] Overwriting imported function in another package
In-Reply-To: <4E3FDAE2.3000700@gmail.com>
References: <CABFfbXvuYi=nYQ72ULVyQX87q288Wu7jAioPMXmBhKU6EvcJ+g@mail.gmail.com>
	<4E3FD452.8070209@gmail.com>
	<CABFfbXvTUCS+BJZkbYJPSaD6uFqw0kEf1_kkq6dXQ75CDp1sjA@mail.gmail.com>
	<4E3FDAE2.3000700@gmail.com>
Message-ID: <3D59DF35E7CF3E42BA70C23BD5CBE6A85F510934C8@exvic-mbx04.nexus.csiro.au>


[Jeroen Ooms wrote:]
> > I am running into a limitation of the grid::grid.newpage function, for which I would like to overwrite this function
> > with a slightly modified one. Hopefully this is a temporary working solution until the package gets updated. I found a 
> > way to overwrite the function in the package:grid namespace. However, lattice imports grid rather than depending on it. 
> > So I need a way to overwrite this imported version as well. The code below shows the fix which works for ggplot (because 
> > it depends on grid), but it doesn't work for lattice, because it imports grid. Is there any way to overwrite 
> > grid.newpage for all instantiations of it?

[Duncan Murdoch wrote:]
> But everyone who uses your code has a right to expect that other
> packages are not affected by it. 

One should of course only do such things reluctantly and responsibly, as Duncan points out; any changes shouldn't modify *expectable* behaviour of existing functions! But if it's just a bug-fix or innocuous extension of functionality, and/or just in one's own work, then I can see two approaches that might help.

First is to set a load hook something like this (assuming 'newpage' isn't an S3 method, which would entail a tweak):

setHook( packageEvent( 'grid', 'onLoad'), function( ...) { 
  ns <- asNamespace( 'grid')
  unlockBinding( 'grid.newpage', ns)
  assign( 'grid.newpage', << patched version >>, envir=ns)
  lockBinding( 'grid.newpage', ns)
  cat( "Patched grid.newpage\n")
  invisible( NULL)
})

This must be done before the offending package gets loaded, so it won't work eg as an "autopatch" strategy if you want to put it into a package you're writing. But it works fine if you put it in your own .First or other startup mechanism; if you are just helping out some mates, give them this code & tell them how to use it. I've used it for exactly the case mentioned: to "auto-patch" buggy code pending a new release of a buggy package.

Second: *after* loading the offending package, (e.g. in the '.onLoad' of your own package, if you're putting this into a package) you could use 'fun.locator' in 'mvbutils' to find all instances of the offending function including imports, and then change each copy manually. An example is 'mtrace' in 'debug', which deliberately tries to find and change all copies of a function. (Whether 'fun.locator' finds absolutely every copy, I'm not sure, but it does try; NB it won't work as-is for S4, and needs to be used differently for ref classes.) This is uglier, but should be automatic (and should also ensure that any subsequent imports of the offender pick up the patched version, though I haven't checked).

Note that this won't work retrospectively for copies that are imported into a package namespace under an alias, which I think used to be a theoretical possibility but may not be any more.

HTH
Mark

-- 
Mark Bravington
CSIRO Mathematical & Information Sciences
Marine Laboratory
Castray Esplanade
Hobart 7001
TAS

ph (+61) 3 6232 5118
fax (+61) 3 6232 5012
mob (+61) 438 315 623

-- 
Mark Bravington
CSIRO Mathematical & Information Sciences
Marine Laboratory
Castray Esplanade
Hobart 7001
TAS

ph (+61) 3 6232 5118
fax (+61) 3 6232 5012
mob (+61) 438 315 623

Duncan Murdoch wrote:
> On 08/08/2011 8:40 AM, Jeroen Ooms wrote:
>>>  Yes, modify the source and recompile R.
>> 
>> That is what I am doing now, but can't expect that everyone who uses
>> my code is willing to recompile R from src...
> 
> But everyone who uses your code has a right to expect that other
> packages are not affected by it. 
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From ripley at stats.ox.ac.uk  Tue Aug  9 06:50:37 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 9 Aug 2011 05:50:37 +0100 (BST)
Subject: [Rd] Making rmath.dll (or equivalent)
In-Reply-To: <1312829631500-3727906.post@n4.nabble.com>
References: <1312829631500-3727906.post@n4.nabble.com>
Message-ID: <alpine.LFD.2.02.1108090545360.8266@gannet.stats.ox.ac.uk>

It is Rmath.dll: case often matters in searching.

You should look in the obvious manual in your (old) installation, the 
'R Installation and Administration' manual.  The current version is at

http://cran.r-project.org/doc/manuals/R-admin.html#The-standalone-Rmath-library

On Mon, 8 Aug 2011, sgomori wrote:

> I currently have R 2.12.1 installed, both 32 and 64 bit. I also have a file
> that was passed to me named rmath.dll. I do not know what version of R it
> was created from, but I do know it is 32-bit only. I am developing an
> application in C# that uses this library as a reference but I have to
> downgrade it to 32-bit in order to use the DLL file.
>
> I wish to make a rmath.dll from the version of R I have on my computer. I
> have looked for instructions online for this, but all I can find reference
> folders/files not in my install, I am guessing these instructions are for
> older versions of R.

If you have a binary install, you cannot build R from it.

> Can anyone point me to how I can accomplish this, creating a 64-bit DLL for
> R's math functonality?
>
> Thanks in advance.
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Making-rmath-dll-or-equivalent-tp3727906p3727906.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jwiley.psych at gmail.com  Tue Aug  9 07:11:27 2011
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Mon, 8 Aug 2011 22:11:27 -0700
Subject: [Rd] Overwriting imported function in another package
In-Reply-To: <3D59DF35E7CF3E42BA70C23BD5CBE6A85F510934C8@exvic-mbx04.nexus.csiro.au>
References: <CABFfbXvuYi=nYQ72ULVyQX87q288Wu7jAioPMXmBhKU6EvcJ+g@mail.gmail.com>
	<4E3FD452.8070209@gmail.com>
	<CABFfbXvTUCS+BJZkbYJPSaD6uFqw0kEf1_kkq6dXQ75CDp1sjA@mail.gmail.com>
	<4E3FDAE2.3000700@gmail.com>
	<3D59DF35E7CF3E42BA70C23BD5CBE6A85F510934C8@exvic-mbx04.nexus.csiro.au>
Message-ID: <CANz9Z_+PGLW9JFmCXxtNSzd72V70Ewfb9PH66Q_2GzUfN=8pcQ@mail.gmail.com>

> [Jeroen Ooms wrote:]
>> > I am running into a limitation of the grid::grid.newpage function, for which I would like to overwrite this function
>> > with a slightly modified one. Hopefully this is a temporary working solution until the package gets updated. I found a
>> > way to overwrite the function in the package:grid namespace. However, lattice imports grid rather than depending on it.
>> > So I need a way to overwrite this imported version as well. The code below shows the fix which works for ggplot (because
>> > it depends on grid), but it doesn't work for lattice, because it imports grid. Is there any way to overwrite
>> > grid.newpage for all instantiations of it?
>
> [Duncan Murdoch wrote:]
>> But everyone who uses your code has a right to expect that other
>> packages are not affected by it.

<Mark.Bravington at csiro.au> wrote:
> One should of course only do such things reluctantly and responsibly, as Duncan points out; any changes shouldn't modify *expectable* behaviour of existing functions! But if it's just a bug-fix or innocuous extension of functionality, and/or just in one's own work, then I can see two approaches that might help.

As a user, I would be strongly opposed to this, even for "buggy" code.

> Second: *after* loading the offending package, (e.g. in the '.onLoad' of your own package, if you're putting this into a package) you could use 'fun.locator' in 'mvbutils' to find all instances of the offending function including imports, and then change each copy manually. An example is 'mtrace' in 'debug', which deliberately tries to find and change all copies of a function. (Whether 'fun.locator' finds absolutely every copy, I'm not sure, but it does try; NB it won't work as-is for S4, and needs to be used differently for ref classes.) This is uglier, but should be automatic (and should also ensure that any subsequent imports of the offender pick up the patched version, though I haven't checked).
>
> Note that this won't work retrospectively for copies that are imported into a package namespace under an alias, which I think used to be a theoretical possibility but may not be any more.

This strikes me as essentially as a package that, when
installed/loaded "infects" other packages and software.  R and CRAN
are open source.  If you need something different than what you have,
make something different.  You could make: JOsggplot2, JOslattice,
etc. and have your package depend on those.  User's do not need to
compile from source, and rather than hijacking other packages, it is
clear that a package similar to but different from ggplot2 and lattice
is being used.

Josh


From ligges at statistik.tu-dortmund.de  Tue Aug  9 10:43:50 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 09 Aug 2011 10:43:50 +0200
Subject: [Rd] X11.options().
In-Reply-To: <4E406CEE.6070707@auckland.ac.nz>
References: <4E3F32A8.6020401@auckland.ac.nz>	<20031.40000.460197.554924@stat.math.ethz.ch>	<4E403B1E.2070008@statistik.tu-dortmund.de>
	<20032.15641.407322.641625@stat.math.ethz.ch>
	<4E406CEE.6070707@auckland.ac.nz>
Message-ID: <4E40F346.2000404@statistik.tu-dortmund.de>

Fine for me on a recent Debian with R-2.13.1 patched.
I think we will need more details of a really clean install and your 
version of cairo etc.
[I'm on vacations and may be offline until Thursday]

Uwe


On 09.08.2011 01:10, Rolf Turner wrote:
>
>
> Uh, to get back to the (my) point --- anybody have any ideas as to why
> X11.options()$type is defaulting to "Xlib" rather than "cairo" even though
> cairo is available and apparently (???) ``reliable''?
>
> cheers,
>
> Rolf


From r.turner at auckland.ac.nz  Wed Aug 10 00:57:48 2011
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 10 Aug 2011 10:57:48 +1200
Subject: [Rd] X11.options().
In-Reply-To: <4E40F346.2000404@statistik.tu-dortmund.de>
References: <4E3F32A8.6020401@auckland.ac.nz>	<20031.40000.460197.554924@stat.math.ethz.ch>	<4E403B1E.2070008@statistik.tu-dortmund.de>
	<20032.15641.407322.641625@stat.math.ethz.ch>
	<4E406CEE.6070707@auckland.ac.nz>
	<4E40F346.2000404@statistik.tu-dortmund.de>
Message-ID: <4E41BB6C.8000202@auckland.ac.nz>

On 09/08/11 20:43, Uwe Ligges wrote:
> Fine for me on a recent Debian with R-2.13.1 patched.

Psigh!  Why do the Computer Gods always pick on ***me***?

> I think we will need more details of a really clean install and your 
> version of cairo etc.
> [I'm on vacations and may be offline until Thursday]
>
When you get some time, can you please give me some explicit instructions as
to how to produce the details that you need?

No rush; this is kind of an academic question since I've worked around 
the problem
by explicitly setting X11.options(type="cairo") in my .Rprofile.

     cheers,

         Rolf


From vqnguyen at uci.edu  Wed Aug 10 01:40:38 2011
From: vqnguyen at uci.edu (Vinh Nguyen)
Date: Tue, 9 Aug 2011 16:40:38 -0700
Subject: [Rd] build 32-bit R on x86_64?
Message-ID: <CA+2Dmwget5gngXcUDU96GuTPFAu42weTm0TSV3HcDuMBQMF1ew@mail.gmail.com>

Dear R-Devel,

I'm using Ubuntu on an x86_64 machine and would like to have both the
32-bit and 64-bit versions of R built from source.  By default,
following the usual build procedures yields 64 bit R.  Looking at
[these](http://cran.r-project.org/doc/manuals/R-admin.html#Sub_002darchitectures),
I thought I could build 32-bit R by executing

r_arch=32 ./configure

and building R like usual (make).  However, after seeing this error message,

/usr/bin/install: cannot create regular file
`../../include/32/Rconfig.h': No such file or directory

I realize I am misunderstanding the instructions.  Could someone
please clarify how I could go about compiling both 32-bit and 64-bit
versions of R on my Linux machine?  Thank you!

-- Vinh


From jorismeys at gmail.com  Wed Aug 10 01:52:06 2011
From: jorismeys at gmail.com (Joris Meys)
Date: Wed, 10 Aug 2011 01:52:06 +0200
Subject: [Rd] build 32-bit R on x86_64?
In-Reply-To: <CA+2Dmwget5gngXcUDU96GuTPFAu42weTm0TSV3HcDuMBQMF1ew@mail.gmail.com>
References: <CA+2Dmwget5gngXcUDU96GuTPFAu42weTm0TSV3HcDuMBQMF1ew@mail.gmail.com>
Message-ID: <CAO1zAVYwyQGgDySx7+aWXGJdo1OfO7T5x06StrC2yBVVDw8ezg@mail.gmail.com>

The architecture is called i386. Try

r_arch=i386 ./configure

That should work.
Cheers
Joris

On Wed, Aug 10, 2011 at 1:40 AM, Vinh Nguyen <vqnguyen at uci.edu> wrote:
> Dear R-Devel,
>
> I'm using Ubuntu on an x86_64 machine and would like to have both the
> 32-bit and 64-bit versions of R built from source. ?By default,
> following the usual build procedures yields 64 bit R. ?Looking at
> [these](http://cran.r-project.org/doc/manuals/R-admin.html#Sub_002darchitectures),
> I thought I could build 32-bit R by executing
>
> r_arch=32 ./configure
>
> and building R like usual (make). ?However, after seeing this error message,
>
> /usr/bin/install: cannot create regular file
> `../../include/32/Rconfig.h': No such file or directory
>
> I realize I am misunderstanding the instructions. ?Could someone
> please clarify how I could go about compiling both 32-bit and 64-bit
> versions of R on my Linux machine? ?Thank you!
>
> -- Vinh
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Applied mathematics, biometrics and process control

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From vqnguyen at uci.edu  Wed Aug 10 02:08:24 2011
From: vqnguyen at uci.edu (Vinh Nguyen)
Date: Tue, 9 Aug 2011 17:08:24 -0700
Subject: [Rd] build 32-bit R on x86_64?
In-Reply-To: <CAO1zAVYwyQGgDySx7+aWXGJdo1OfO7T5x06StrC2yBVVDw8ezg@mail.gmail.com>
References: <CA+2Dmwget5gngXcUDU96GuTPFAu42weTm0TSV3HcDuMBQMF1ew@mail.gmail.com>
	<CAO1zAVYwyQGgDySx7+aWXGJdo1OfO7T5x06StrC2yBVVDw8ezg@mail.gmail.com>
Message-ID: <CA+2DmwhNQ_kfGmMc9JThTFv_+oB17SuyUL8pzk0muG1vWGz_kQ@mail.gmail.com>

On Tue, Aug 9, 2011 at 4:52 PM, Joris Meys <jorismeys at gmail.com> wrote:
> The architecture is called i386. Try
>
> r_arch=i386 ./configure
>
> That should work.
> Cheers
> Joris

Thank you for your response Joris.  However, I still get:
/usr/bin/install: cannot create regular file
`../../include/i386/Rconfig.h': No such file or directory

I don't think r_arch necessarily instruct make to build 32-bit
versions of R; I think it's more of a prefix in the name.


From edd at debian.org  Wed Aug 10 02:12:18 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 9 Aug 2011 19:12:18 -0500
Subject: [Rd] build 32-bit R on x86_64?
In-Reply-To: <CA+2Dmwget5gngXcUDU96GuTPFAu42weTm0TSV3HcDuMBQMF1ew@mail.gmail.com>
References: <CA+2Dmwget5gngXcUDU96GuTPFAu42weTm0TSV3HcDuMBQMF1ew@mail.gmail.com>
Message-ID: <20033.52450.484029.887948@max.nulle.part>


Hi Vinh,

On 9 August 2011 at 16:40, Vinh Nguyen wrote:
| Dear R-Devel,
| 
| I'm using Ubuntu on an x86_64 machine and would like to have both the
| 32-bit and 64-bit versions of R built from source.  By default,
| following the usual build procedures yields 64 bit R.  Looking at
| [these](http://cran.r-project.org/doc/manuals/R-admin.html#Sub_002darchitectures),
| I thought I could build 32-bit R by executing
| 
| r_arch=32 ./configure
| 
| and building R like usual (make).  However, after seeing this error message,
| 
| /usr/bin/install: cannot create regular file
| `../../include/32/Rconfig.h': No such file or directory
| 
| I realize I am misunderstanding the instructions.  Could someone
| please clarify how I could go about compiling both 32-bit and 64-bit
| versions of R on my Linux machine?  Thank you!

I do not think that multiarch build (ie 32 and 64 at the same time) are fully
supported yet on Ubuntu or Debian. It is coming, but just like a number of
other things, not exactly overnight. It is a release goal.

In the meantime, you can always use virtualization. I have a Debian 32-bit
system and an Ubuntu 32-bit system in KVM virtualization on my Ubuntu 64-bit
server.  That works well.  Kvm, or Xen, or Virtualbox, or Vmware, ... all
offer fairly decent virtualization.  

Debian/Ubuntu specific questions are even more welcome on r-sig-debian.

Dirk

-- 
Two new Rcpp classes scheduled for New York and San Francisco, details at
http://dirk.eddelbuettel.com/blog/2011/08/04#rcpp_classes_2011-09_and_2011-10


From simon.urbanek at r-project.org  Wed Aug 10 03:24:40 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 9 Aug 2011 21:24:40 -0400
Subject: [Rd] build 32-bit R on x86_64?
In-Reply-To: <20033.52450.484029.887948@max.nulle.part>
References: <CA+2Dmwget5gngXcUDU96GuTPFAu42weTm0TSV3HcDuMBQMF1ew@mail.gmail.com>
	<20033.52450.484029.887948@max.nulle.part>
Message-ID: <44C7902F-1807-4873-877C-8CF3CC5D110B@r-project.org>


On Aug 9, 2011, at 8:12 PM, Dirk Eddelbuettel wrote:

> 
> Hi Vinh,
> 
> On 9 August 2011 at 16:40, Vinh Nguyen wrote:
> | Dear R-Devel,
> | 
> | I'm using Ubuntu on an x86_64 machine and would like to have both the
> | 32-bit and 64-bit versions of R built from source.  By default,
> | following the usual build procedures yields 64 bit R.  Looking at
> | [these](http://cran.r-project.org/doc/manuals/R-admin.html#Sub_002darchitectures),
> | I thought I could build 32-bit R by executing
> | 
> | r_arch=32 ./configure
> | 
> | and building R like usual (make).  However, after seeing this error message,
> | 
> | /usr/bin/install: cannot create regular file
> | `../../include/32/Rconfig.h': No such file or directory
> | 
> | I realize I am misunderstanding the instructions.  Could someone
> | please clarify how I could go about compiling both 32-bit and 64-bit
> | versions of R on my Linux machine?  Thank you!
> 
> I do not think that multiarch build (ie 32 and 64 at the same time) are fully supported yet on Ubuntu or Debian. It is coming, but just like a number of other things, not exactly overnight. It is a release goal.
> 

It actually works ;) I'm using it for testing on my RForge.net machine and yes, it's Debian - everything just works there :).

But back to the original question. First a minor detail, don't set environment variables use configure variables instead. Second, don't build in the source directory, always create an object directory. Third, r_arch is simply a name you set for the architecture, it has no meaning other than that it's a label.

So now to the real stuff. If you want 32-bit build, you'll need 32-bit runtime of everything important in your system and the multilib compilers. In Debian (and thus likely in Ubuntu too) that can be achieved by something like

sudo apt-get install  ia32-libs-dev lib32readline6-dev lib32ncurses5-dev lib32icu-dev gcc-multilib gfortran-multilib

Then you can build both 64-bit and 32-bit R, the difference will be in the all compiler flags -- for 64-bit you'll use -m64 (or nothing since it's the default) and for 32-bit you'll use -m32.

So roughly something like

tar fxz R-2.13.1.tar.gz
mkdir obj-32
cd obj-32
../R-2.13.1/configure r_arch=i386 CC='gcc -std=gnu99 -m32' CXX='g++ -m32' FC='gfortran -m32' F77='gfortran -m32' 
make -j24 && sudo make install rhome=/usr/local/R/2.13
cd ..
mkdir obj-64
cd obj-64
../R-2.13.1/configure r_arch=amd64
make -j24 && sudo make install rhome=/usr/local/R/2.13

That will leave you with multi-arch R that you can run with
R --arch=i386 # 32-bit
R --arch=amd64 # 64-bit
Packages will be also built as multi-libs. Good luck :)
[BTW the rhome=... setting is entirely optional, I just like to keep my R versions organized?]

Cheers,
Simon



> In the meantime, you can always use virtualization. I have a Debian 32-bit
> system and an Ubuntu 32-bit system in KVM virtualization on my Ubuntu 64-bit
> server.  That works well.  Kvm, or Xen, or Virtualbox, or Vmware, ... all
> offer fairly decent virtualization.  
> 
> Debian/Ubuntu specific questions are even more welcome on r-sig-debian.
> 
> Dirk
> 
> -- 
> Two new Rcpp classes scheduled for New York and San Francisco, details at
> http://dirk.eddelbuettel.com/blog/2011/08/04#rcpp_classes_2011-09_and_2011-10
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From edd at debian.org  Wed Aug 10 03:41:23 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 9 Aug 2011 20:41:23 -0500
Subject: [Rd] build 32-bit R on x86_64?
In-Reply-To: <44C7902F-1807-4873-877C-8CF3CC5D110B@r-project.org>
References: <CA+2Dmwget5gngXcUDU96GuTPFAu42weTm0TSV3HcDuMBQMF1ew@mail.gmail.com>
	<20033.52450.484029.887948@max.nulle.part>
	<44C7902F-1807-4873-877C-8CF3CC5D110B@r-project.org>
Message-ID: <20033.57795.598633.661417@max.nulle.part>


On 9 August 2011 at 21:24, Simon Urbanek wrote:
| 
| On Aug 9, 2011, at 8:12 PM, Dirk Eddelbuettel wrote:
| 
| > 
| > Hi Vinh,
| > 
| > On 9 August 2011 at 16:40, Vinh Nguyen wrote:
| > | Dear R-Devel,
| > | 
| > | I'm using Ubuntu on an x86_64 machine and would like to have both the
| > | 32-bit and 64-bit versions of R built from source.  By default,
| > | following the usual build procedures yields 64 bit R.  Looking at
| > | [these](http://cran.r-project.org/doc/manuals/R-admin.html#Sub_002darchitectures),
| > | I thought I could build 32-bit R by executing
| > | 
| > | r_arch=32 ./configure
| > | 
| > | and building R like usual (make).  However, after seeing this error message,
| > | 
| > | /usr/bin/install: cannot create regular file
| > | `../../include/32/Rconfig.h': No such file or directory
| > | 
| > | I realize I am misunderstanding the instructions.  Could someone
| > | please clarify how I could go about compiling both 32-bit and 64-bit
| > | versions of R on my Linux machine?  Thank you!
| > 
| > I do not think that multiarch build (ie 32 and 64 at the same time) are fully supported yet on Ubuntu or Debian. It is coming, but just like a number of other things, not exactly overnight. It is a release goal.
| > 
| 
| It actually works ;) I'm using it for testing on my RForge.net machine and yes, it's Debian - everything just works there :).
| 
| But back to the original question. First a minor detail, don't set environment variables use configure variables instead. Second, don't build in the source directory, always create an object directory. Third, r_arch is simply a name you set for the architecture, it has no meaning other than that it's a label.
| 
| So now to the real stuff. If you want 32-bit build, you'll need 32-bit runtime of everything important in your system and the multilib compilers. In Debian (and thus likely in Ubuntu too) that can be achieved by something like
| 
| sudo apt-get install  ia32-libs-dev lib32readline6-dev lib32ncurses5-dev lib32icu-dev gcc-multilib gfortran-multilib

Nice one :)  

I had these installed but was always under the impression that we'd lack
things like jpeg, png, ... libs.  So it all works as R has 'enough batteries'
included?  Good to know ...
| 
| Then you can build both 64-bit and 32-bit R, the difference will be in the all compiler flags -- for 64-bit you'll use -m64 (or nothing since it's the default) and for 32-bit you'll use -m32.
| 
| So roughly something like
| 
| tar fxz R-2.13.1.tar.gz
| mkdir obj-32
| cd obj-32
| ../R-2.13.1/configure r_arch=i386 CC='gcc -std=gnu99 -m32' CXX='g++ -m32' FC='gfortran -m32' F77='gfortran -m32' 
| make -j24 && sudo make install rhome=/usr/local/R/2.13
| cd ..
| mkdir obj-64
| cd obj-64
| ../R-2.13.1/configure r_arch=amd64
| make -j24 && sudo make install rhome=/usr/local/R/2.13
| 
| That will leave you with multi-arch R that you can run with
| R --arch=i386 # 32-bit
| R --arch=amd64 # 64-bit
| Packages will be also built as multi-libs. Good luck :)
| [BTW the rhome=... setting is entirely optional, I just like to keep my R versions organized?]

I shall keep that for the day I'll have to start supporting multiarch in all
the r-cran-* packages :)

Thanks for waving the cluebat.

Dirk

| 
| Cheers,
| Simon
| 
| 
| 
| > In the meantime, you can always use virtualization. I have a Debian 32-bit
| > system and an Ubuntu 32-bit system in KVM virtualization on my Ubuntu 64-bit
| > server.  That works well.  Kvm, or Xen, or Virtualbox, or Vmware, ... all
| > offer fairly decent virtualization.  
| > 
| > Debian/Ubuntu specific questions are even more welcome on r-sig-debian.
| > 
| > Dirk
| > 
| > -- 
| > Two new Rcpp classes scheduled for New York and San Francisco, details at
| > http://dirk.eddelbuettel.com/blog/2011/08/04#rcpp_classes_2011-09_and_2011-10
| > 
| > ______________________________________________
| > R-devel at r-project.org mailing list
| > https://stat.ethz.ch/mailman/listinfo/r-devel
| > 
| > 
| 

-- 
Two new Rcpp classes scheduled for New York and San Francisco, details at
http://dirk.eddelbuettel.com/blog/2011/08/04#rcpp_classes_2011-09_and_2011-10


From simon.urbanek at r-project.org  Wed Aug 10 03:57:56 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 9 Aug 2011 21:57:56 -0400
Subject: [Rd] build 32-bit R on x86_64?
In-Reply-To: <20033.57795.598633.661417@max.nulle.part>
References: <CA+2Dmwget5gngXcUDU96GuTPFAu42weTm0TSV3HcDuMBQMF1ew@mail.gmail.com>
	<20033.52450.484029.887948@max.nulle.part>
	<44C7902F-1807-4873-877C-8CF3CC5D110B@r-project.org>
	<20033.57795.598633.661417@max.nulle.part>
Message-ID: <FE98F5E8-92B8-4BE8-A99F-2A3FA2A66563@r-project.org>


On Aug 9, 2011, at 9:41 PM, Dirk Eddelbuettel wrote:

> 
> On 9 August 2011 at 21:24, Simon Urbanek wrote:
> | 
> | On Aug 9, 2011, at 8:12 PM, Dirk Eddelbuettel wrote:
> | 
> | > 
> | > Hi Vinh,
> | > 
> | > On 9 August 2011 at 16:40, Vinh Nguyen wrote:
> | > | Dear R-Devel,
> | > | 
> | > | I'm using Ubuntu on an x86_64 machine and would like to have both the
> | > | 32-bit and 64-bit versions of R built from source.  By default,
> | > | following the usual build procedures yields 64 bit R.  Looking at
> | > | [these](http://cran.r-project.org/doc/manuals/R-admin.html#Sub_002darchitectures),
> | > | I thought I could build 32-bit R by executing
> | > | 
> | > | r_arch=32 ./configure
> | > | 
> | > | and building R like usual (make).  However, after seeing this error message,
> | > | 
> | > | /usr/bin/install: cannot create regular file
> | > | `../../include/32/Rconfig.h': No such file or directory
> | > | 
> | > | I realize I am misunderstanding the instructions.  Could someone
> | > | please clarify how I could go about compiling both 32-bit and 64-bit
> | > | versions of R on my Linux machine?  Thank you!
> | > 
> | > I do not think that multiarch build (ie 32 and 64 at the same time) are fully supported yet on Ubuntu or Debian. It is coming, but just like a number of other things, not exactly overnight. It is a release goal.
> | > 
> | 
> | It actually works ;) I'm using it for testing on my RForge.net machine and yes, it's Debian - everything just works there :).
> | 
> | But back to the original question. First a minor detail, don't set environment variables use configure variables instead. Second, don't build in the source directory, always create an object directory. Third, r_arch is simply a name you set for the architecture, it has no meaning other than that it's a label.
> | 
> | So now to the real stuff. If you want 32-bit build, you'll need 32-bit runtime of everything important in your system and the multilib compilers. In Debian (and thus likely in Ubuntu too) that can be achieved by something like
> | 
> | sudo apt-get install  ia32-libs-dev lib32readline6-dev lib32ncurses5-dev lib32icu-dev gcc-multilib gfortran-multilib
> 
> Nice one :)  
> 
> I had these installed but was always under the impression that we'd lack
> things like jpeg, png, ... libs.  So it all works as R has 'enough batteries'
> included?  Good to know ...

Yes, it's enough to build, but obviously it's like having one AAA battery installed ;)


> | 
> | Then you can build both 64-bit and 32-bit R, the difference will be in the all compiler flags -- for 64-bit you'll use -m64 (or nothing since it's the default) and for 32-bit you'll use -m32.
> | 
> | So roughly something like
> | 
> | tar fxz R-2.13.1.tar.gz
> | mkdir obj-32
> | cd obj-32
> | ../R-2.13.1/configure r_arch=i386 CC='gcc -std=gnu99 -m32' CXX='g++ -m32' FC='gfortran -m32' F77='gfortran -m32' 
> | make -j24 && sudo make install rhome=/usr/local/R/2.13
> | cd ..
> | mkdir obj-64
> | cd obj-64
> | ../R-2.13.1/configure r_arch=amd64
> | make -j24 && sudo make install rhome=/usr/local/R/2.13
> | 
> | That will leave you with multi-arch R that you can run with
> | R --arch=i386 # 32-bit
> | R --arch=amd64 # 64-bit
> | Packages will be also built as multi-libs. Good luck :)
> | [BTW the rhome=... setting is entirely optional, I just like to keep my R versions organized?]
> 
> I shall keep that for the day I'll have to start supporting multiarch in all
> the r-cran-* packages :)
> 

Well, I did give it a shot for RForge.net but the list of ia32 libraries is a bit short compared to what's available in a full 32-bit system. Obviously you can get far with using native i386 packages, but then you won't be able to take advantage of all the magic of dpkg. So I don't think you'll need to worry about multiarch R r-cran* packages too soon ;). I'm keeping multiarch R around for testing of packages since it's a pretty good test of badly written package configuration, but I would not use it for production ... (it's bad enough that I need to worry about it on OS X ;)).

Cheers,
Simon



> Thanks for waving the cluebat.
> 
> Dirk
> 
> | 
> | Cheers,
> | Simon
> | 
> | 
> | 
> | > In the meantime, you can always use virtualization. I have a Debian 32-bit
> | > system and an Ubuntu 32-bit system in KVM virtualization on my Ubuntu 64-bit
> | > server.  That works well.  Kvm, or Xen, or Virtualbox, or Vmware, ... all
> | > offer fairly decent virtualization.  
> | > 
> | > Debian/Ubuntu specific questions are even more welcome on r-sig-debian.
> | > 
> | > Dirk
> | > 
> | > -- 
> | > Two new Rcpp classes scheduled for New York and San Francisco, details at
> | > http://dirk.eddelbuettel.com/blog/2011/08/04#rcpp_classes_2011-09_and_2011-10
> | > 
> | > ______________________________________________
> | > R-devel at r-project.org mailing list
> | > https://stat.ethz.ch/mailman/listinfo/r-devel
> | > 
> | > 
> | 
> 
> -- 
> Two new Rcpp classes scheduled for New York and San Francisco, details at
> http://dirk.eddelbuettel.com/blog/2011/08/04#rcpp_classes_2011-09_and_2011-10
> 
> 


From lawrence.michael at gene.com  Wed Aug 10 13:51:30 2011
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Wed, 10 Aug 2011 04:51:30 -0700
Subject: [Rd] Win7 x64 "device not ready" error when DLLpath passed to
	dyn.load
Message-ID: <CAOQ5NyfOqE2rEc5j3U7WEZzqjz3tgfqueguz3yDf0fgp-Kgqhw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110810/d60f8ec5/attachment.pl>

From murdoch.duncan at gmail.com  Wed Aug 10 14:07:58 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 10 Aug 2011 08:07:58 -0400
Subject: [Rd] Win7 x64 "device not ready" error when DLLpath passed to
 dyn.load
In-Reply-To: <CAOQ5NyfOqE2rEc5j3U7WEZzqjz3tgfqueguz3yDf0fgp-Kgqhw@mail.gmail.com>
References: <CAOQ5NyfOqE2rEc5j3U7WEZzqjz3tgfqueguz3yDf0fgp-Kgqhw@mail.gmail.com>
Message-ID: <4E42749E.4020905@gmail.com>

On 11-08-10 7:51 AM, Michael Lawrence wrote:
> Hi,
>
> Does anyone have any idea why some installations of 64 bit Windows 7 yields
> an error like this when passing DLLpath to dyn.load or library.dynam?
>
>> library(RGtk2)
> Error in inDL(x, as.logical(local), as.logical(now), ...) :
>   unable to load shared object 'c:/R/libuser/RGtk2/libs/x64/
> RGtk2.dll':
>   LoadLibrary failure:  The device is not ready.
>
> For now I guess I will fall back to setting the PATH explicitly.

One source of problems like that is interference from anti-virus 
programs.  If they have exclusive access to the DLL to check it for 
problems, then LoadLibrary won't be able to load it.

I don't know if there's a way to avoid this automatically.

Duncan Murdoch


From vqnguyen at uci.edu  Wed Aug 10 17:37:08 2011
From: vqnguyen at uci.edu (Vinh Nguyen)
Date: Wed, 10 Aug 2011 08:37:08 -0700
Subject: [Rd] build 32-bit R on x86_64?
In-Reply-To: <44C7902F-1807-4873-877C-8CF3CC5D110B@r-project.org>
References: <CA+2Dmwget5gngXcUDU96GuTPFAu42weTm0TSV3HcDuMBQMF1ew@mail.gmail.com>
	<20033.52450.484029.887948@max.nulle.part>
	<44C7902F-1807-4873-877C-8CF3CC5D110B@r-project.org>
Message-ID: <CA+2DmwgERWB+m_JsstpmQgbtYnHJVM66fKLDjXoCdGicpmVmxw@mail.gmail.com>

On Tue, Aug 9, 2011 at 6:24 PM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
> It actually works ;) I'm using it for testing on my RForge.net machine and yes, it's Debian - everything just works there :).
>
> But back to the original question. First a minor detail, don't set environment variables use configure variables instead. Second, don't build in the source directory, always create an object directory. Third, r_arch is simply a name you set for the architecture, it has no meaning other than that it's a label.
>
> So now to the real stuff. If you want 32-bit build, you'll need 32-bit runtime of everything important in your system and the multilib compilers. In Debian (and thus likely in Ubuntu too) that can be achieved by something like
>
> sudo apt-get install ?ia32-libs-dev lib32readline6-dev lib32ncurses5-dev lib32icu-dev gcc-multilib gfortran-multilib
>
> Then you can build both 64-bit and 32-bit R, the difference will be in the all compiler flags -- for 64-bit you'll use -m64 (or nothing since it's the default) and for 32-bit you'll use -m32.
>
> So roughly something like
>
> tar fxz R-2.13.1.tar.gz
> mkdir obj-32
> cd obj-32
> ../R-2.13.1/configure r_arch=i386 CC='gcc -std=gnu99 -m32' CXX='g++ -m32' FC='gfortran -m32' F77='gfortran -m32'
> make -j24 && sudo make install rhome=/usr/local/R/2.13
> cd ..
> mkdir obj-64
> cd obj-64
> ../R-2.13.1/configure r_arch=amd64
> make -j24 && sudo make install rhome=/usr/local/R/2.13
>
> That will leave you with multi-arch R that you can run with
> R --arch=i386 # 32-bit
> R --arch=amd64 # 64-bit
> Packages will be also built as multi-libs. Good luck :)
> [BTW the rhome=... setting is entirely optional, I just like to keep my R versions organized?]
>
> Cheers,
> Simon
>

Thanks Simon!  Confirm that these instructions work.  ia32-libs-dev
was not available for Ubuntu Natty, so I installed ia32-libs instead,
and the compilation works!

-- Vinh


From gene at ccs.neu.edu  Wed Aug 10 20:11:02 2011
From: gene at ccs.neu.edu (Gene Cooperman)
Date: Wed, 10 Aug 2011 14:11:02 -0400
Subject: [Rd] DMTCP: checkpoint-restart for R
Message-ID: <20110810181102.GT7761@mspacman.ccs.neu.edu>

Hello,
    I hope we have the right mailing list.  We are two of a team of
developers for DMTCP (transparent checkpoint-restart).  It runs under
Linux, and is free software (LGPLv3+), found at:
  http://dmtcp.sourceforge.net
    In our latest release, version 1.2.3, we have done some simple
testing on R, and find that we can successfully checkpoint and restart.
Its usage can be as simple as:
  dmtcp_checkpoint R   [ run under checkpoint control ]
  dmtcp_command --checkpoint [ from a diff. window, creates ckpt_R_*.dmtcp ]
  dmtcp_restart ckpt_R_*.dmtcp [ from original window ]
  ALTERNATIVELY:  ./dmtcp_restart_script.sh

    We are interested in supporting R to a fuller extent.  But we don't
have enough experience with R to do more thorough testing.  We have tested
DMTCP on a small test in C, which frequently loads and unloads libraries
(w/ dlopen).  We added this test in C, because we understand that loading
and unloading libraries is part of the core design of R.
    Would it be possible for someone to try out R/DMTCP on some realistic
R programs and give us feedback on what works or doesn't work?  We believe
that transparent checkpointing would be helpful to the R community for
any long-running programs.

Thanks and best wishes,
- Gene and Kapil (representing the DMTCP team)


From timjurka at gmail.com  Thu Aug 11 01:12:14 2011
From: timjurka at gmail.com (Tim Jurka)
Date: Wed, 10 Aug 2011 16:12:14 -0700
Subject: [Rd] Referencing non-CRAN extension from CRAN package
Message-ID: <3FE9A89C-C6FD-4560-A61B-2A47B044D29E@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110810/80663f41/attachment.pl>

From Kurt.Hornik at wu.ac.at  Thu Aug 11 09:01:12 2011
From: Kurt.Hornik at wu.ac.at (Kurt Hornik)
Date: Thu, 11 Aug 2011 09:01:12 +0200
Subject: [Rd] Referencing non-CRAN extension from CRAN package
In-Reply-To: <3FE9A89C-C6FD-4560-A61B-2A47B044D29E@gmail.com>
References: <3FE9A89C-C6FD-4560-A61B-2A47B044D29E@gmail.com>
Message-ID: <20035.32312.416004.209099@fangorn.hornik.net>

>>>>> Tim Jurka writes:

> Hi r-devel,

> I would like to submit a package to CRAN that makes use of an Omegahat
> extension, RStem ( http://www.omegahat.org/Rstem/ ). What is the best
> way to reference it in my package, and ensure compliance with CRAN
> submission guidelines?

CRAN can deal with package dependencies from BioC and Omegahat.

So e.g., Depends: Rstem in DESCRIPTION if you have Rstem as a depends.

Best
-k

> Thank you for your help!

> Tim



> --
> Timothy P. Jurka
> Department of Political Science
> University of California, Davis
> www.timjurka.com

> 	[[alternative HTML version deleted]]

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From lawrence.michael at gene.com  Thu Aug 11 13:07:00 2011
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Thu, 11 Aug 2011 04:07:00 -0700
Subject: [Rd] relist.list broken for skeletons with empty elements
Message-ID: <CAOQ5NydUPZO3WAmXpNUecfndwPtFUSinpz+5qPL2e12HiKndDQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110811/4bbaa84f/attachment.pl>

From mweiler at wu.ac.at  Thu Aug 11 13:02:02 2011
From: mweiler at wu.ac.at (Maria Weiler)
Date: Thu, 11 Aug 2011 13:02:02 +0200
Subject: [Rd] CRAN Service Notification - Downtime TODAY 13:00 - 13:30
Message-ID: <4E43B6AA.50808@wu.ac.at>

Dear users,

There will be an outage of the CRAN Server in a few minutes as we need 
to temporarily move the corresponding server to another building. There 
are maintenance works at the main power supply of the WU Vienna. The 
service will be available as soon as possible. Another short downtime 
will occur on Monday (or Tuesday) as we need to return the server.

We are sorry for the inconvenience caused.

Best regards,

The statmath-it Team


From bxc at steno.dk  Thu Aug 11 17:07:05 2011
From: bxc at steno.dk (BXC (Bendix Carstensen))
Date: Thu, 11 Aug 2011 17:07:05 +0200
Subject: [Rd] Combining levels of factors
Message-ID: <2F73FA3AF524144C863B7C2C903DBC3303001E30E9@exdkmbx002.corp.novocorp.net>

The existing relevel() function in "stats" could conveniently be replaced with the
Relevel() from the "Epi" package, which gives some added functionality:

- Moving more than one level up first
- Allowing to combine levels of factors

This functionality is not something specific for epidemiology.

The existing relevel is (almost literally) a subset of Relevel().

b.r.
Bendix
_________________________________________

Bendix Carstensen
Senior Statistician
Steno Diabetes Center A/S
Niels Steensens Vej 2-4
DK-2820 Gentofte
Denmark
+45 44 43 87 38 (direct)
+45 30 75 87 38 (mobile)
bxc at steno.dk    www.biostat.ku.dk/~bxc
www.steno.dk


From lawrence.michael at gene.com  Thu Aug 11 17:49:58 2011
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Thu, 11 Aug 2011 08:49:58 -0700
Subject: [Rd] autogenerated namespaces not initialized correctly
Message-ID: <CAOQ5Nyf=4O8RZUakZ4NPpD80VFnfTnyjy9AmyhHjHnV38ER7GQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110811/32b0b980/attachment.pl>

From ripley at stats.ox.ac.uk  Thu Aug 11 18:39:08 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 11 Aug 2011 17:39:08 +0100 (BST)
Subject: [Rd] autogenerated namespaces not initialized correctly
In-Reply-To: <CAOQ5Nyf=4O8RZUakZ4NPpD80VFnfTnyjy9AmyhHjHnV38ER7GQ@mail.gmail.com>
References: <CAOQ5Nyf=4O8RZUakZ4NPpD80VFnfTnyjy9AmyhHjHnV38ER7GQ@mail.gmail.com>
Message-ID: <alpine.LFD.2.02.1108111735240.10826@gannet.stats.ox.ac.uk>

On Thu, 11 Aug 2011, Michael Lawrence wrote:

> Hi guys,
>
> This probably isn't news, but when a package is given an autogenerated
> namespace, its .First.lib, if any, is no longer called.

Please do read the NEWS file: .First.lib *is* called as either .onLoad 
or .onAttach.

> This causes problems, e.g., when a package is loading a dynamic 
> library. Probably no good solution here. The initialization routines 
> could be made to call .First.lib, code could be rewritten on the 
> fly, a useDynlib() could be added for a package that has one, etc. 
> Nothing too appealing.

But actually it works well enough in 97% of the cases on CRAN.

>
> Thanks,
> Michael
>
> 	[[alternative HTML version deleted]]

Please do follow the posting guide!

> _____________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jahftw at googlemail.com  Thu Aug 11 15:06:07 2011
From: jahftw at googlemail.com (=?ISO-8859-1?Q?Lars_Wi=DFler?=)
Date: Thu, 11 Aug 2011 15:06:07 +0200
Subject: [Rd] .C and .Call: convolve example not working
Message-ID: <CADJn3hfrTG9dOMi3QKqZ0FmgOTtU96D+QsxU1c1xK1CA-3PMrQ@mail.gmail.com>

Dear R users,

I want to call C code via the .C or .Call interface. This works fine
with integer values but using doubles the array received in C will be
set to zeros.

I have tried the convolve examples (Writing R extensions, chapter 5.2)
and still the resulting array consists of zeros.

My code (shortened for my purposes. Original did not work either):
------------------------------------------------------------
convolve.r

a=array(1, c(4))
b=array(3, c(4))

print(a)
print(b)

.C("convolve",
    as.double(a),
    as.double(b))

----------------------------------------------------------------
convolve.c

void convolve(double* a, double* b){
     int i;

     for(i=0;i<4;i++) Rprintf("a: %d", a[i]);
     for(i=0;i<4;i++) Rprintf("b: %d", b[i]);
}

--------------------------------------------------------------

ouput:

[1] "starting C code..."
[1] 1 1 1 1
[1] 3 3 3 3
a: 30467528
a: 0
a: 0
a: 0
b: 0
b: 0
b: 0
b: 0

Any suggestions as to why this is happening and what I am doing wrong
would be much appreciated. I have tried .Call with conversion SEXP to
double with REAL(a)/REAL(b) with the same results (the entry first
entry of a has a different number, but is huge as well). I am quite
astonished with the results I am getting.

Thanks and regards,

Lars Wissler


From tlumley at uw.edu  Thu Aug 11 23:50:39 2011
From: tlumley at uw.edu (Thomas Lumley)
Date: Fri, 12 Aug 2011 09:50:39 +1200
Subject: [Rd] .C and .Call: convolve example not working
In-Reply-To: <CADJn3hfrTG9dOMi3QKqZ0FmgOTtU96D+QsxU1c1xK1CA-3PMrQ@mail.gmail.com>
References: <CADJn3hfrTG9dOMi3QKqZ0FmgOTtU96D+QsxU1c1xK1CA-3PMrQ@mail.gmail.com>
Message-ID: <CAJ55+d+vxv6nskRwqo1xp30EkPx4sVCYvAMGZpULqJUx7QpAjA@mail.gmail.com>

On Fri, Aug 12, 2011 at 1:06 AM, Lars Wi?ler <jahftw at googlemail.com> wrote:
> Dear R users,
>
> I want to call C code via the .C or .Call interface. This works fine
> with integer values but using doubles the array received in C will be
> set to zeros.
>
> I have tried the convolve examples (Writing R extensions, chapter 5.2)
> and still the resulting array consists of zeros.
>
> My code (shortened for my purposes. Original did not work either):
> ------------------------------------------------------------
> convolve.r
>
> a=array(1, c(4))
> b=array(3, c(4))
>
> print(a)
> print(b)
>
> .C("convolve",
> ? ?as.double(a),
> ? ?as.double(b))
>
> ----------------------------------------------------------------
> convolve.c
>
> void convolve(double* a, double* b){
> ? ? int i;
>
> ? ? for(i=0;i<4;i++) Rprintf("a: %d", a[i]);
> ? ? for(i=0;i<4;i++) Rprintf("b: %d", b[i]);
> }


The C code here is wrong for two reasons.  Firstly, there's no
declaration for Rprintf(), because you don't include the header file.

Secondly, you're using %d to print, which means you are telling the
compiler you're passing ints to Rprintf(), but you are actually
passing doubles.

When I fix these problems the code works for me.

    -thomas

Thomas Lumley
Professor of Biostatistics
University of Auckland


From jahftw at googlemail.com  Fri Aug 12 10:47:48 2011
From: jahftw at googlemail.com (=?ISO-8859-1?Q?Lars_Wi=DFler?=)
Date: Fri, 12 Aug 2011 10:47:48 +0200
Subject: [Rd] .C and .Call: convolve example not working
In-Reply-To: <CAJ55+d+vxv6nskRwqo1xp30EkPx4sVCYvAMGZpULqJUx7QpAjA@mail.gmail.com>
References: <CADJn3hfrTG9dOMi3QKqZ0FmgOTtU96D+QsxU1c1xK1CA-3PMrQ@mail.gmail.com>
	<CAJ55+d+vxv6nskRwqo1xp30EkPx4sVCYvAMGZpULqJUx7QpAjA@mail.gmail.com>
Message-ID: <CADJn3hcKpNc5z+20PeBDicEjKbx3jky9QFR_UfknSKQGBgAtuw@mail.gmail.com>

Thanks a lot for the help Thomas and William, that solved it. I am
used to programming Java and didn't think of checking my print
function.

Regards Lars

2011/8/11 Thomas Lumley <tlumley at uw.edu>:
> On Fri, Aug 12, 2011 at 1:06 AM, Lars Wi?ler <jahftw at googlemail.com> wrote:
>> Dear R users,
>>
>> I want to call C code via the .C or .Call interface. This works fine
>> with integer values but using doubles the array received in C will be
>> set to zeros.
>>
>> I have tried the convolve examples (Writing R extensions, chapter 5.2)
>> and still the resulting array consists of zeros.
>>
>> My code (shortened for my purposes. Original did not work either):
>> ------------------------------------------------------------
>> convolve.r
>>
>> a=array(1, c(4))
>> b=array(3, c(4))
>>
>> print(a)
>> print(b)
>>
>> .C("convolve",
>> ? ?as.double(a),
>> ? ?as.double(b))
>>
>> ----------------------------------------------------------------
>> convolve.c
>>
>> void convolve(double* a, double* b){
>> ? ? int i;
>>
>> ? ? for(i=0;i<4;i++) Rprintf("a: %d", a[i]);
>> ? ? for(i=0;i<4;i++) Rprintf("b: %d", b[i]);
>> }
>
>
> The C code here is wrong for two reasons. ?Firstly, there's no
> declaration for Rprintf(), because you don't include the header file.
>
> Secondly, you're using %d to print, which means you are telling the
> compiler you're passing ints to Rprintf(), but you are actually
> passing doubles.
>
> When I fix these problems the code works for me.
>
> ? ?-thomas
>
> Thomas Lumley
> Professor of Biostatistics
> University of Auckland
>


From giuseppe.casalicchio at gmail.com  Fri Aug 12 10:52:21 2011
From: giuseppe.casalicchio at gmail.com (mafia88)
Date: Fri, 12 Aug 2011 01:52:21 -0700 (PDT)
Subject: [Rd] gsub("\\", "\\\\", "C:\Program Files\R")
Message-ID: <1313139141809-3738251.post@n4.nabble.com>

Hi,

I think it is not possible in R but I rather ask before giving up:

What I have: I have copied "C:\Program Files\R" into my clipboard.
What I want: setwd(transform("C:\Program Files\R")) where the function
transform should change the "C:\Program Files\R" from my clipboard to
"C:\\Program Files\\R" so that R can handle it. Is this possible?
I've tried with gsub("\\", "\\\\", "C:\Program Files\R") but failed, then
tried first to split the full clipboard string cause \P is reserved in R but
with strsplit("C:\Program Files\R", "") I also failed.

Therefore the question: It is really necessary to manually add a second "\"
in "C:\Program Files\R", so that setwd("C:\\Program Files\\R") can change my
work directory? 
Cause I am getting tired making this manually... yes I know I can use the
Search&Replace function from the Editor but I thought R can do everything?

I hope someone could help me :(

--
View this message in context: http://r.789695.n4.nabble.com/gsub-C-Program-Files-R-tp3738251p3738251.html
Sent from the R devel mailing list archive at Nabble.com.


From falk.hilliges at twain-systems.com  Fri Aug 12 11:28:27 2011
From: falk.hilliges at twain-systems.com (Geophagus)
Date: Fri, 12 Aug 2011 02:28:27 -0700 (PDT)
Subject: [Rd] cbind with different vector lengths
Message-ID: <1313141307075-3738320.post@n4.nabble.com>

Hi @ all,
I have the following question:
Is there a possibilty to cbind tree dataframes with different numbers of
rows?

Here is my example:

/> b2007
5 8 
1 1 

> b2008
3 6 8 
3 1 2 

> b2009
1 3 8 
1 2 1 

> cbind (b2007,b2008,b2009)

  b2007 b2008 b2009
3     1     3     1
6     1     1     2
8     1     2     1
Warnmeldung:
In cbind(b2007, b2008, b2009) :
  number of rows of result is not a multiple of vector length (arg 1)/

I also need the row name "5" and the "1" with NA or 0 as value in the
result.
I hope my problem was understandable.

Thanks a lot in advance!
Falk aka Geophagus


--
View this message in context: http://r.789695.n4.nabble.com/cbind-with-different-vector-lengths-tp3738320p3738320.html
Sent from the R devel mailing list archive at Nabble.com.


From jinghuazhao at hotmail.com  Fri Aug 12 14:04:15 2011
From: jinghuazhao at hotmail.com (jing hua zhao)
Date: Fri, 12 Aug 2011 12:04:15 +0000
Subject: [Rd] bookmarks with PDF()
In-Reply-To: <1313141307075-3738320.post@n4.nabble.com>
References: <1313141307075-3738320.post@n4.nabble.com>
Message-ID: <COL105-W251A24D62343201B2D3106A5250@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110812/969bbe7d/attachment.pl>

From ligges at statistik.tu-dortmund.de  Fri Aug 12 14:14:06 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 12 Aug 2011 14:14:06 +0200
Subject: [Rd] gsub("\\", "\\\\", "C:\Program Files\R")
In-Reply-To: <1313139141809-3738251.post@n4.nabble.com>
References: <1313139141809-3738251.post@n4.nabble.com>
Message-ID: <4E45190E.7040000@statistik.tu-dortmund.de>



On 12.08.2011 10:52, mafia88 wrote:
> Hi,
>
> I think it is not possible in R but I rather ask before giving up:
>
> What I have: I have copied "C:\Program Files\R" into my clipboard.
> What I want: setwd(transform("C:\Program Files\R")) where the function
> transform should change the "C:\Program Files\R" from my clipboard to
> "C:\\Program Files\\R" so that R can handle it. Is this possible?
> I've tried with gsub("\\", "\\\\", "C:\Program Files\R") but failed, then
> tried first to split the full clipboard string cause \P is reserved in R but
> with strsplit("C:\Program Files\R", "") I also failed.
>
> Therefore the question: It is really necessary to manually add a second "\"
> in "C:\Program Files\R", so that setwd("C:\\Program Files\\R") can change my
> work directory?
> Cause I am getting tired making this manually... yes I know I can use the
> Search&Replace function from the Editor but I thought R can do everything?
>
> I hope someone could help me :(


Not really: You need to get it "transformed" before the R parser has its 
hand on it, therefore the best solution is to ask your editor to do that.

Uwe Ligges




> --
> View this message in context: http://r.789695.n4.nabble.com/gsub-C-Program-Files-R-tp3738251p3738251.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From lachmann at eva.mpg.de  Fri Aug 12 14:19:16 2011
From: lachmann at eva.mpg.de (Michael Lachmann)
Date: Fri, 12 Aug 2011 14:19:16 +0200
Subject: [Rd] gsub("\\", "\\\\", "C:\Program Files\R")
In-Reply-To: <1313139141809-3738251.post@n4.nabble.com>
References: <1313139141809-3738251.post@n4.nabble.com>
Message-ID: <F2039884-1CD7-4266-93FA-097669EFC152@eva.mpg.de>

Interesting question. It is really about how to avoid the interpretation of \ as an escape character in a string. I wonder if it is possible.

Anyway, have you tried the following:
setwd(readLines("clipboard",warn=F))

"clipboard" is a special filename that tells R to read from the clipboard.

Michael

On 12 Aug 2011, at 10:52AM, mafia88 wrote:

> Hi,
> 
> I think it is not possible in R but I rather ask before giving up:
> 
> What I have: I have copied "C:\Program Files\R" into my clipboard.
> What I want: setwd(transform("C:\Program Files\R")) where the function
> transform should change the "C:\Program Files\R" from my clipboard to
> "C:\\Program Files\\R" so that R can handle it. Is this possible?
> I've tried with gsub("\\", "\\\\", "C:\Program Files\R") but failed, then
> tried first to split the full clipboard string cause \P is reserved in R but
> with strsplit("C:\Program Files\R", "") I also failed.
> 
> Therefore the question: It is really necessary to manually add a second "\"
> in "C:\Program Files\R", so that setwd("C:\\Program Files\\R") can change my
> work directory? 
> Cause I am getting tired making this manually... yes I know I can use the
> Search&Replace function from the Editor but I thought R can do everything?
> 
> I hope someone could help me :(
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/gsub-C-Program-Files-R-tp3738251p3738251.html
> Sent from the R devel mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> 


From murdoch.duncan at gmail.com  Fri Aug 12 14:20:11 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 12 Aug 2011 08:20:11 -0400
Subject: [Rd] gsub("\\", "\\\\", "C:\Program Files\R")
In-Reply-To: <1313139141809-3738251.post@n4.nabble.com>
References: <1313139141809-3738251.post@n4.nabble.com>
Message-ID: <4E451A7B.9040904@gmail.com>

On 11-08-12 4:52 AM, mafia88 wrote:
> Hi,
>
> I think it is not possible in R but I rather ask before giving up:
>
> What I have: I have copied "C:\Program Files\R" into my clipboard.
> What I want: setwd(transform("C:\Program Files\R")) where the function
> transform should change the "C:\Program Files\R" from my clipboard to
> "C:\\Program Files\\R" so that R can handle it. Is this possible?

No, but you shouldn't be doing that.  You should read the string from 
the clipboard as a string, not as R code, because it's a string, not R code.

For example, if your clipboard contains that string,

dir <- readClipboard()
setwd(dir)


> I've tried with gsub("\\", "\\\\", "C:\Program Files\R") but failed, then
> tried first to split the full clipboard string cause \P is reserved in R but
> with strsplit("C:\Program Files\R", "") I also failed.
>
> Therefore the question: It is really necessary to manually add a second "\"
> in "C:\Program Files\R", so that setwd("C:\\Program Files\\R") can change my
> work directory?

No.  You only want a single backslash in the string.  The problem is 
that you are using the parser:  to get the parser to create a string 
with a single backslash in it, you need to give two to the parser.

So don't use the parser.

Duncan Murdoch

> Cause I am getting tired making this manually... yes I know I can use the
> Search&Replace function from the Editor but I thought R can do everything?
>
> I hope someone could help me :(
>
> --
> View this message in context: http://r.789695.n4.nabble.com/gsub-C-Program-Files-R-tp3738251p3738251.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From timothy.c.bates at gmail.com  Sat Aug 13 14:01:34 2011
From: timothy.c.bates at gmail.com (Timothy Bates)
Date: Sat, 13 Aug 2011 13:01:34 +0100
Subject: [Rd] Rd for write.table {utils}: Be explicit about the default
	separator
Message-ID: <57A3AA76-1873-4C7D-A4BE-776ED1D80591@gmail.com>

In "utils/write.table.Rd" the default separator is shown as the invisible character "	". 

In the further documentation, the default separator is not named.

It would helpful to specify it using an escape character in the \Usage section "\s" or "\t"?

and to name it explicitly in the \Arguments section


From murdoch.duncan at gmail.com  Sat Aug 13 18:17:06 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 13 Aug 2011 12:17:06 -0400
Subject: [Rd] Rd for write.table {utils}: Be explicit about the default
 separator
In-Reply-To: <57A3AA76-1873-4C7D-A4BE-776ED1D80591@gmail.com>
References: <57A3AA76-1873-4C7D-A4BE-776ED1D80591@gmail.com>
Message-ID: <4E46A382.4020100@gmail.com>

On 11-08-13 8:01 AM, Timothy Bates wrote:
> In "utils/write.table.Rd" the default separator is shown as the invisible character "	".
>
> In the further documentation, the default separator is not named.
>
> It would helpful to specify it using an escape character in the \Usage section "\s" or "\t"?
>
> and to name it explicitly in the \Arguments section

The default for that argument is an ascii space, and " " is the usual 
way that is expressed in R.  \s is not defined in R.

I agree naming the argument could be helpful for some people, but there 
are dozens of instances of this, and I think people will catch on.

Duncan Murdoch


From radford at cs.toronto.edu  Sat Aug 13 22:56:43 2011
From: radford at cs.toronto.edu (Radford Neal)
Date: Sat, 13 Aug 2011 16:56:43 -0400
Subject: [Rd] Latent flaw in SEXPREC definition
Message-ID: <20110813205643.GA4049@cs.toronto.edu>

There seems to be a latent flaw in the definition of struct SEXPREC
in Rinternals.h, which likely doesn't cause problems now, but could
if the relative sizes of data types changes.

The SEXPREC structure contains a union that includes a primsxp,
symsxp, etc, but not a vecsxp.  However, in allocVector in memory.c,
zero-length vectors are allocated using allocSExpNonCons, which
appears to allocates a SEXPREC structure.  This won't work if a vecsxp
is larger than the other types that are in the union in the SEXPREC
structure.

Simply adding a vecsxp to the union would seem to fix this, as in
the following patch:

Index: src/include/Rinternals.h
===================================================================
--- src/include/Rinternals.h    (revision 56640)
+++ src/include/Rinternals.h    (working copy)
@@ -219,6 +219,7 @@
 typedef struct SEXPREC {
     SEXPREC_HEADER;
     union {
+       struct vecsxp_struct vecsxp;
        struct primsxp_struct primsxp;
        struct symsxp_struct symsxp;
        struct listsxp_struct listsxp;


From pdalgd at gmail.com  Sun Aug 14 01:59:41 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 14 Aug 2011 01:59:41 +0200
Subject: [Rd] Latent flaw in SEXPREC definition
In-Reply-To: <20110813205643.GA4049@cs.toronto.edu>
References: <20110813205643.GA4049@cs.toronto.edu>
Message-ID: <7DE8973C-B303-4201-9964-F5117FD283E8@gmail.com>


On Aug 13, 2011, at 22:56 , Radford Neal wrote:

> There seems to be a latent flaw in the definition of struct SEXPREC
> in Rinternals.h, which likely doesn't cause problems now, but could
> if the relative sizes of data types changes.
> 
> The SEXPREC structure contains a union that includes a primsxp,
> symsxp, etc, but not a vecsxp.  However, in allocVector in memory.c,
> zero-length vectors are allocated using allocSExpNonCons, which
> appears to allocates a SEXPREC structure.  This won't work if a vecsxp
> is larger than the other types that are in the union in the SEXPREC
> structure.
> 
> Simply adding a vecsxp to the union would seem to fix this, as in
> the following patch:

But the whole point of separating VECTOR_SEXPREC from the other SEXPRECs is that they are _shorter_. A vecsxp is only going to be larger than (say) an envsxp if 2 R_len_t's are more than 3 pointers, which is quite unlikely since R_len_t variables holds things that one might add to pointers.

NOT having vecsxp in the SEXPREC union prevents programmers from mistakingly using SEXP* where VECSXP* should have been used. Since the distinction wasn't always there, I suspect that flagging usage of x->u.vecsxp.length by the compiler was rather important at some point in time.  


> 
> Index: src/include/Rinternals.h
> ===================================================================
> --- src/include/Rinternals.h    (revision 56640)
> +++ src/include/Rinternals.h    (working copy)
> @@ -219,6 +219,7 @@
> typedef struct SEXPREC {
>     SEXPREC_HEADER;
>     union {
> +       struct vecsxp_struct vecsxp;
>        struct primsxp_struct primsxp;
>        struct symsxp_struct symsxp;
>        struct listsxp_struct listsxp;
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
"D?den skal tape!" --- Nordahl Grieg


From radford at cs.toronto.edu  Sun Aug 14 03:50:09 2011
From: radford at cs.toronto.edu (Radford Neal)
Date: Sat, 13 Aug 2011 21:50:09 -0400
Subject: [Rd] Latent flaw in SEXPREC definition
In-Reply-To: <7DE8973C-B303-4201-9964-F5117FD283E8@gmail.com>
References: <20110813205643.GA4049@cs.toronto.edu>
	<7DE8973C-B303-4201-9964-F5117FD283E8@gmail.com>
Message-ID: <20110814015009.GA746@cs.toronto.edu>

> But the whole point of separating VECTOR_SEXPREC from the other
> SEXPRECs is that they are _shorter_. A vecsxp is only going to be
> larger than (say) an envsxp if 2 R_len_t's are more than 3 pointers,
> which is quite unlikely since R_len_t variables holds things that
> one might add to pointers.

Unlikely, yes, but it's not inconceivable that someone might have a
configuration where R_len_t is 64 bits (say, for some sort of
compatibility reason) while pointers are 32 bits (say, for speed).

> NOT having vecsxp in the SEXPREC union prevents programmers from
> mistakingly using SEXP* where VECSXP* should have been used. Since
> the distinction wasn't always there, I suspect that flagging usage
> of x->u.vecsxp.length by the compiler was rather important at some
> point in time.

If that's an issue, one can just call the field something other than
vecsxp.

Of course, an alternative solution is to not use allocSExpNonCons to
allocate zero-length vectors.


From radford at cs.toronto.edu  Sun Aug 14 18:01:01 2011
From: radford at cs.toronto.edu (Radford Neal)
Date: Sun, 14 Aug 2011 12:01:01 -0400
Subject: [Rd] Improved version of Rprofmem
Message-ID: <20110814160101.GA15411@cs.toronto.edu>

The Rprofmem facility is currently enabled only if the configuration
option --enable-memory-profiling is used.  However, the overhead of
having it enabled is negligible when profiling is not actually being
done, and can easily be made even smaller.  So I think it ought to be
enabled all the time.  

I've attached a patch doing this, which also makes a number of other
improvements to Rprofmem, which are upward-compatible with the current
version.

First, it allows for the profiling reports to be printed to the
terminal (with Rprintf) as well as or instead of going to a file.
This is not only a convenience, but also provides more information
when these reports are interspersed with other output, allowing the
source of the memory allocations to be better determined.

Second, it gives the option for the alloction reports to include the
type of the vector and its length, not just the number of bytes
allocated.

Third, it allows for all vector allocations to be reported, not just
those that are large enough to be done with malloc (this distinction
doesn't seem important for most uses).  It also allows for reports to
be produced only when the vector allocated has at least some number of
elements, rather than only providing a threshold based on number of
bytes.  This seems more natural if a user knows that they are dealing
with some vectors of length 100000 and wants to see only those (or
bigger ones).

Also, if either the option for terminal output or for type and length
details is used, allocation reports always end with a newline.  For
some reason, the present code doesn't write a newline if the call
stack happens to be empty.  (Though not documented, this is clearly
deliberate, not a bug.)  Though I can't see why one would want this,
it is retained as the default behaviour for backward compatibility.

Finally, I changed the printf format for values that are cast with
(unsigned long) to %lu, rather than %ld, which I think is not correct.

I think incorporating this in the upcoming 2.14.0 release would be
useful.  For instance, the following gives some useful insights into
what R is doing with memory allocation:

     > Rprofmem("",terminal=TRUE,pages=FALSE,details=TRUE,nelem=10000)
     > f <- function (x)
     + { cat("Now in f\n");
     +   s <- sum(x);
     +   cat("sum =",s,"\n");
     +   x[10] <- 1;
     +   s <- sum(x);
     +   cat("sum =",s,"\n")
     +   x[20] <- 1;
     +   s <- sum(x);
     +   cat("sum =",s,"\n")
     +   y <<- x
     +   NULL
     + }
     > f(rep(2,10000))
     Now in f
     RPROFMEM: 40040 (integer 10000):"f" 
     RPROFMEM: 40040 (integer 10000):"f" 
     RPROFMEM: 80040 (double 10000):"f" 
     sum = 20000 
     RPROFMEM: 80040 (double 10000):"f" 
     sum = 19999 
     sum = 19998 
     RPROFMEM: 80040 (double 10000):"f" 
     NULL
     > y[1] <- 0
     > Rprofmem("")

You can see the details of my modifications from the output of
help(Rprofmem) after applying the patch I have attached, which
I've put below:


Rprofmem                 package:utils                 R Documentation

Enable Profiling of R's Memory Use

Description:

     Enable or disable reporting of memory allocation in R.

Usage:

     Rprofmem(filename = "Rprofmem.out", append = FALSE, 
              threshold = 0, nelem = 0, 
              terminal = FALSE, pages = TRUE, details = FALSE)
     
Arguments:

filename: The file to which reports of memory allocations are written,
          or 'NULL' or '""' if reports should not go to a file.

  append: logical: should the file be appended to rather than
          overwritten?

threshold: numeric: only allocations of vectors with size larger than
          this number of bytes will be reported.

   nelem: numeric: only allocations of vectors with at least this many
          elements will be reported.

terminal: logical: should reports be printed on the terminal (as well
          as possibly written to 'filename')?

   pages: logical: should allocation of pages for small vectors be
          reported, and reporting of individual small vector
          allocations suppressed?

 details: logical: should details of allocation be reported, rather
          than only the total number of bytes?

Details:

     The profiler tracks memory allocations, some of which will be to
     previously used memory and will not increase the total memory use
     of R.

     Calling 'Rprofmem' with either 'terminal=TRUE' or with 'filename'
     something other than 'NULL' or '""' (or both) will enable
     profiling, with allocation reports going to one or both places.
     Reports to the terminal are preceded by "RPROFMEM:".  Enabling
     profiling automatically disables any existing profiling to another
     or the same file or to the terminal.

     Calling 'Rprofmem' with 'terminal=FALSE' (the default) and
     'filename' either 'NULL' or '""' will disable profiling.

     If 'pages=TRUE' (the default) allocations of individual vectors
     will be reported only if they are "large", and allocations of
     pages to hold small vectors will be reported.  The size of a page
     of memory and the size over which a vector is "large" (and hence
     for which 'malloc' is used) are compile-time constants, by default
     2000 and 128 bytes respectively.

     If 'pages=FALSE', allocations of all vectors with size over
     'threshold' and number of elements at least 'nelem' are reported,
     and page allocations are not reported.

     A report of an allocation of a vector (to 'filename' and/or the
     terminal) will contain the number of bytes allocated and the names
     of functions in the call stack.  If 'details=TRUE' (not the
     default), the type and length of the vector allocated will also be
     displayed (in parentheses) before the call stack.

     An allocation of a page for small vectors (when 'pages=TRUE') will
     result in a report consisting of "new page:" followed by the call
     stack.

     When 'terminal=TRUE' or 'details=TRUE', a newline is always
     written after each allocation report.  For backward compatibility,
     this is otherwise not the case when the call stack is empty.

Value:

     None

Note:

     The memory profiler can be used at the same time as other R and C
     profilers.

See Also:

     The R sampling profiler, 'Rprof' also collects memory information.

     'tracemem' traces duplications of specific objects.

     The "Writing R Extensions" manual section on "Tidying and
     profiling R code"

Examples:

     # Reports printed to the terminal, with details, for all vectors of 
     # at least 10 elements.
     Rprofmem("", terminal=TRUE, pages=FALSE, details=TRUE, nelem=10)
     v <- numeric(10)
     v[3] <- 1
     u <- v
     v[3] <- 2
     Rprofmem("")
     
     ## Not run:
     
     # Reports go to a file.
     Rprofmem("Rprofmem.out", threshold=1000)
     example(glm)
     Rprofmem(NULL)
     noquote(readLines("Rprofmem.out", n=5))
     ## End(Not run)
-------------- next part --------------
Index: src/library/utils/R/Rprof.R
===================================================================
--- src/library/utils/R/Rprof.R	(revision 35)
+++ src/library/utils/R/Rprof.R	(working copy)
@@ -21,8 +21,10 @@
     invisible(.Internal(Rprof(filename, append, interval, memory.profiling)))
 }
 
-Rprofmem <- function(filename = "Rprofmem.out", append = FALSE, threshold = 0)
+Rprofmem <- function(filename = "Rprofmem.out", append = FALSE, threshold = 0,
+             nelem = 0, terminal = FALSE, pages = TRUE, details = FALSE)
 {
     if(is.null(filename)) filename <- ""
-    invisible(.Internal(Rprofmem(filename, append, as.double(threshold))))
+    invisible(.Internal(Rprofmem(filename, append, as.double(threshold), 
+                                 as.double(nelem), terminal, pages, details)))
 }
Index: src/library/utils/man/Rprofmem.Rd
===================================================================
--- src/library/utils/man/Rprofmem.Rd	(revision 35)
+++ src/library/utils/man/Rprofmem.Rd	(working copy)
@@ -10,35 +10,66 @@
  Enable or disable reporting of memory allocation in R.
 }
 \usage{
-Rprofmem(filename = "Rprofmem.out", append = FALSE, threshold = 0)
+Rprofmem(filename = "Rprofmem.out", append = FALSE, 
+         threshold = 0, nelem = 0, 
+         terminal = FALSE, pages = TRUE, details = FALSE)
 }
 \arguments{
-  \item{filename}{The file to be used for recording the memory
-    allocations. Set to \code{NULL} or \code{""} to disable reporting. }
-  \item{append}{logical: should the file be over-written or appended to? }
-  \item{threshold}{numeric: allocations on R's "large vector" heap
-    larger than this number of bytes will be reported.
-  }
+  \item{filename}{The file to which reports of memory allocations are written, 
+    or \code{NULL} or \code{""} if reports should not go to a file. }
+  \item{append}{logical: should the file be appended to rather than 
+                overwritten?}
+  \item{threshold}{numeric: only allocations of vectors 
+    with size larger than this number of bytes will be reported.}
+  \item{nelem}{numeric: only allocations of vectors 
+    with at least this many elements will be reported.}
+  \item{terminal}{logical: should reports be printed on the terminal (as
+    well as possibly written to \code{filename})?}
+  \item{pages}{logical: should allocation of pages for small vectors 
+    be reported, and reporting of individual small vector allocations 
+    suppressed?}
+  \item{details}{logical: should details of allocation be reported,
+    rather than only the total number of bytes?}
 }
 \details{
-  Enabling profiling automatically disables any existing profiling to
-  another or the same file.
+  The profiler tracks memory allocations, some of which will be to previously
+  used memory and will not increase the total memory use of R.
 
-  Profiling writes the call stack to the specified file every time
-  \code{malloc} is called to allocate a large vector object or to
-  allocate a page of memory for small objects. The size of a page of
-  memory and the size above which \code{malloc} is used for vectors are
-  compile-time constants, by default 2000 and 128 bytes respectively.
+  Calling \code{Rprofmem} with either \code{terminal=TRUE} or with
+  \code{filename} something other than \code{NULL} or \code{""} (or both)
+  will enable profiling, with allocation reports going to one or both
+  places.  Reports to the terminal are preceded by "RPROFMEM:".
+  Enabling profiling automatically disables any 
+  existing profiling to another or the same file or to the terminal.
 
-  The profiler tracks allocations, some of which will be to previously
-  used memory and will not increase the total memory use of R.
+  Calling \code{Rprofmem} with \code{terminal=FALSE} (the default) and
+  \code{filename} either \code{NULL} or \code{""} will disable profiling.
+
+  If \code{pages=TRUE} (the default) allocations of individual
+  vectors will be reported only if they are "large", and allocations of 
+  pages to hold small vectors will be reported.
+  The size of a page of memory and the size over which a vector is "large"  
+  (and hence for which \code{malloc} is used) are compile-time constants, 
+  by default 2000 and 128 bytes respectively.
+
+  If \code{pages=FALSE}, allocations
+  of all vectors with size over \code{threshold} and number of elements 
+  at least \code{nelem} are reported, and page allocations are not reported.
+
+  A report of an allocation of a vector (to \code{filename} and/or the 
+  terminal) will contain the number of bytes allocated and the names of 
+  functions in the call stack.  If \code{details=TRUE} (not the default), 
+  the type and length of the vector allocated will also be displayed 
+  (in parentheses) before the call stack.  
+
+  An allocation of a page for small vectors (when \code{pages=TRUE}) will
+  result in a report consisting of "new page:" followed by the call stack.
+
+  When \code{terminal=TRUE} or \code{details=TRUE}, a newline is always 
+  written after each allocation report.  For backward compatibility, this 
+  is otherwise not the case when the call stack is empty.
 }
 \note{
-  The memory profiler slows down R even when not in use, and so is a
-  compile-time option.
-#ifdef Windows
-  (It is enabled in a standard Windows build of \R.)
-#endif
   The memory profiler can be used at the same time as other \R and C profilers.
   }
 \value{
@@ -53,8 +84,18 @@
 
   The "Writing R Extensions" manual section on "Tidying and profiling R code"
 }
-\examples{\dontrun{
-## not supported unless R is compiled to support it.
+\examples{
+# Reports printed to the terminal, with details, for all vectors of 
+# at least 10 elements.
+Rprofmem("", terminal=TRUE, pages=FALSE, details=TRUE, nelem=10)
+v <- numeric(10)
+v[3] <- 1
+u <- v
+v[3] <- 2
+Rprofmem("")
+
+\dontrun{
+# Reports go to a file.
 Rprofmem("Rprofmem.out", threshold=1000)
 example(glm)
 Rprofmem(NULL)
Index: src/main/names.c
===================================================================
--- src/main/names.c	(revision 35)
+++ src/main/names.c	(working copy)
@@ -749,7 +749,7 @@
 {"rowSums",	do_colsum,	2,	11,	4,	{PP_FUNCALL, PREC_FN,	0}},
 {"rowMeans",	do_colsum,	3,	11,	4,	{PP_FUNCALL, PREC_FN,	0}},
 {"Rprof",	do_Rprof,	0,	11,	4,	{PP_FUNCALL, PREC_FN,	0}},
-{"Rprofmem",	do_Rprofmem,	0,	11,	3,	{PP_FUNCALL, PREC_FN,	0}},
+{"Rprofmem",	do_Rprofmem,	0,	11,	7,	{PP_FUNCALL, PREC_FN,	0}},
 {"tracemem",    do_tracemem,    0,      1,	1,      {PP_FUNCALL, PREC_FN,	0}},
 {"retracemem",  do_retracemem,  0,      201,     -1,      {PP_FUNCALL, PREC_FN,	0}},
 {"untracemem",  do_untracemem,  0,      101,	1,      {PP_FUNCALL, PREC_FN,	0}},
Index: src/main/memory.c
===================================================================
--- src/main/memory.c	(revision 35)
+++ src/main/memory.c	(working copy)
@@ -220,10 +220,17 @@
 # define FORCE_GC 0
 #endif
 
-#ifdef R_MEMORY_PROFILING
-static void R_ReportAllocation(R_size_t);
+/* Declarations relating to Rprofmem */
+
+static int R_IsMemReporting;
+static int R_MemReportingToTerminal;
+static int R_MemPagesReporting;
+static int R_MemDetailsReporting;
+static FILE *R_MemReportingOutfile;
+static R_size_t R_MemReportingThreshold;
+static R_len_t R_MemReportingNElem;
+static void R_ReportAllocation (R_size_t, SEXPTYPE, R_len_t);
 static void R_ReportNewPage();
-#endif
 
 extern SEXP framenames;
 
@@ -790,9 +797,7 @@
 	if (page == NULL)
 	    mem_err_malloc((R_size_t) R_PAGE_SIZE);
     }
-#ifdef R_MEMORY_PROFILING
-    R_ReportNewPage();
-#endif
+    if (R_IsMemReporting) R_ReportNewPage();
     page->next = R_GenHeap[node_class].pages;
     R_GenHeap[node_class].pages = page;
     R_GenHeap[node_class].PageCount++;
@@ -2312,6 +2317,13 @@
 	}
     }
 
+    if (R_IsMemReporting) {
+        if (!R_MemPagesReporting
+              || size > 0 && node_class >= NUM_SMALL_NODE_CLASSES)
+            R_ReportAllocation (sizeof(SEXPREC_ALIGN) + size * sizeof(VECREC),
+                                type, length);
+    }
+
     /* save current R_VSize to roll back adjustment if malloc fails */
     old_R_VSize = R_VSize;
 
@@ -2351,9 +2363,6 @@
 		    s = malloc(sizeof(SEXPREC_ALIGN) + size * sizeof(VECREC));
 		}
 		if (s != NULL) success = TRUE;
-#ifdef R_MEMORY_PROFILING
-		R_ReportAllocation(sizeof(SEXPREC_ALIGN) + size * sizeof(VECREC));
-#endif
 	    }
 	    if (! success) {
 		double dsize = (double)size * sizeof(VECREC)/1024.0;
@@ -3247,63 +3256,82 @@
 int  attribute_hidden (IS_CACHED)(SEXP x) { return IS_CACHED(x); }
 
 /*******************************************/
-/* Non-sampling memory use profiler
-   reports all large vector heap
-   allocations and all calls to GetNewPage */
+/* Non-sampling memory use profiler reports vector allocations and/or
+   calls to GetNewPage */
 /*******************************************/
 
-#ifndef R_MEMORY_PROFILING
-
-SEXP attribute_hidden do_Rprofmem(SEXP call, SEXP op, SEXP args, SEXP rho)
+static void R_OutputStackTrace (void)
 {
-    error(_("memory profiling is not available on this system"));
-    return R_NilValue; /* not reached */
-}
+    RCNTXT *cptr;
+    int newline;
 
-#else
-static int R_IsMemReporting;  /* Rboolean more appropriate? */
-static FILE *R_MemReportingOutfile;
-static R_size_t R_MemReportingThreshold;
+    newline = R_MemReportingToTerminal | R_MemDetailsReporting;
 
-static void R_OutputStackTrace(FILE *file)
-{
-    int newline = 0;
-    RCNTXT *cptr;
-
     for (cptr = R_GlobalContext; cptr; cptr = cptr->nextcontext) {
 	if ((cptr->callflag & (CTXT_FUNCTION | CTXT_BUILTIN))
 	    && TYPEOF(cptr->call) == LANGSXP) {
 	    SEXP fun = CAR(cptr->call);
 	    if (!newline) newline = 1;
-	    fprintf(file, "\"%s\" ",
-		    TYPEOF(fun) == SYMSXP ? CHAR(PRINTNAME(fun)) :
-		    "<Anonymous>");
+	    if (R_MemReportingOutfile != NULL)
+                fprintf(R_MemReportingOutfile, "\"%s\" ",
+		        TYPEOF(fun) == SYMSXP ? CHAR(PRINTNAME(fun)) :
+		        "<Anonymous>");
+	    if (R_MemReportingToTerminal)
+                Rprintf("\"%s\" ",
+		        TYPEOF(fun) == SYMSXP ? CHAR(PRINTNAME(fun)) :
+		        "<Anonymous>");
 	}
     }
-    if (newline) fprintf(file, "\n");
+
+    if (newline) {
+        if (R_MemReportingOutfile != NULL) 
+            fprintf(R_MemReportingOutfile, "\n");
+        if (R_MemReportingToTerminal) 
+            Rprintf("\n");
+    }
 }
 
-static void R_ReportAllocation(R_size_t size)
+static void R_ReportAllocation (R_size_t size, SEXPTYPE type, R_len_t length)
 {
-    if (R_IsMemReporting) {
-	if(size > R_MemReportingThreshold) {
-	    fprintf(R_MemReportingOutfile, "%ld :", (unsigned long) size);
-	    R_OutputStackTrace(R_MemReportingOutfile);
-	}
+    if (size > R_MemReportingThreshold && length >= R_MemReportingNElem) {
+        if (R_MemReportingOutfile != NULL) {
+            if (R_MemDetailsReporting)
+                fprintf (R_MemReportingOutfile, "%lu (%s %lu):", 
+                  (unsigned long) size, 
+                  type==intCHARSXP ? "char" : type2char(type), 
+                  (unsigned long) length);
+            else 
+                fprintf (R_MemReportingOutfile, "%lu :", 
+                  (unsigned long) size);
+        }
+        if (R_MemReportingToTerminal) {
+            if (R_MemDetailsReporting)
+                Rprintf ("RPROFMEM: %lu (%s %lu):", 
+                  (unsigned long) size, 
+                  type==intCHARSXP ? "char" : type2char(type), 
+                  (unsigned long) length);
+            else
+                Rprintf ("RPROFMEM: %lu :", 
+                  (unsigned long) size);
+        }
+        R_OutputStackTrace();
     }
     return;
 }
 
 static void R_ReportNewPage(void)
 {
-    if (R_IsMemReporting) {
-	fprintf(R_MemReportingOutfile, "new page:");
-	R_OutputStackTrace(R_MemReportingOutfile);
+    if (R_MemPagesReporting) {
+        if (R_MemReportingOutfile != NULL)
+            fprintf(R_MemReportingOutfile, "new page:");
+        if (R_MemReportingToTerminal)
+            Rprintf("RPROFMEM: new page:");
+	R_OutputStackTrace();
     }
     return;
 }
 
-static void R_EndMemReporting()
+static void R_EndMemReporting(void)
 {
     if(R_MemReportingOutfile != NULL) {
 	/* does not fclose always flush? */
@@ -3315,39 +3343,66 @@
     return;
 }
 
-static void R_InitMemReporting(SEXP filename, int append,
-			       R_size_t threshold)
+static void R_InitMemReporting(SEXP filename, int append)
 {
-    if(R_MemReportingOutfile != NULL) R_EndMemReporting();
-    R_MemReportingOutfile = RC_fopen(filename, append ? "a" : "w", TRUE);
-    if (R_MemReportingOutfile == NULL)
-	error(_("Rprofmem: cannot open output file '%s'"), filename);
-    R_MemReportingThreshold = threshold;
+    if (R_IsMemReporting)
+        R_EndMemReporting();
+
+    if (strlen(CHAR(filename)) > 0) {
+        R_MemReportingOutfile = RC_fopen(filename, append ? "a" : "w", TRUE);
+        if (R_MemReportingOutfile == NULL)
+            error(_("Rprofmem: cannot open output file '%s'"), filename);
+    }
+    else
+        R_MemReportingOutfile = NULL;
+
     R_IsMemReporting = 1;
+
     return;
 }
 
 SEXP attribute_hidden do_Rprofmem(SEXP call, SEXP op, SEXP args, SEXP rho)
 {
-    SEXP filename;
-    R_size_t threshold;
+    SEXP filename, ap;
     int append_mode;
 
     checkArity(op, args);
-    if (!isString(CAR(args)) || (LENGTH(CAR(args))) != 1)
+
+    ap = args;
+    if (!isString(CAR(ap)) || (LENGTH(CAR(ap))) != 1)
 	error(_("invalid '%s' argument"), "filename");
-    append_mode = asLogical(CADR(args));
-    filename = STRING_ELT(CAR(args), 0);
-    threshold = REAL(CADDR(args))[0];
-    if (strlen(CHAR(filename)))
-	R_InitMemReporting(filename, append_mode, threshold);
+    filename = STRING_ELT(CAR(ap), 0);
+
+    ap = CDR(ap);
+    append_mode = asLogical(CAR(ap));
+
+    ap = CDR(ap);
+    if (!isReal(CAR(ap)) || (LENGTH(CAR(ap))) != 1)
+	error(_("invalid '%s' argument"), "threshold");
+    R_MemReportingThreshold = REAL(CAR(ap))[0];
+
+    ap = CDR(ap);
+    if (!isReal(CAR(ap)) || (LENGTH(CAR(ap))) != 1)
+	error(_("invalid '%s' argument"), "nelem");
+    R_MemReportingNElem = REAL(CAR(ap))[0];
+
+    ap = CDR(ap);
+    R_MemReportingToTerminal = asLogical(CAR(ap));
+
+    ap = CDR(ap);
+    R_MemPagesReporting = asLogical(CAR(ap));
+
+    ap = CDR(ap);
+    R_MemDetailsReporting = asLogical(CAR(ap));
+
+    if (R_MemReportingToTerminal || strlen(CHAR(filename)) > 0)
+	R_InitMemReporting(filename, append_mode);
     else
 	R_EndMemReporting();
+
     return R_NilValue;
 }
 
-#endif /* R_MEMORY_PROFILING */
-
 /* RBufferUtils, moved from deparse.c */
 
 #include "RBufferUtils.h"
Index: doc/manual/R-exts.texi
===================================================================
--- doc/manual/R-exts.texi	(revision 35)
+++ doc/manual/R-exts.texi	(working copy)
@@ -5273,8 +5273,8 @@
 Measuring memory use in @R{} code is useful either when the code takes
 more memory than is conveniently available or when memory allocation
 and copying of objects is responsible for slow code. There are three
-ways to profile memory use over time in @R{} code. All three require
- at R{} to have been compiled with @option{--enable-memory-profiling},
+ways to profile memory use over time in @R{} code. All except @code{Rprofmem}
+require @R{} to have been compiled with @option{--enable-memory-profiling},
 which is not the default. All can be misleading, for different
 reasons.
 

From timothy.c.bates at gmail.com  Mon Aug 15 19:08:02 2011
From: timothy.c.bates at gmail.com (Timothy Bates)
Date: Mon, 15 Aug 2011 18:08:02 +0100
Subject: [Rd] "\examples" section for "base/man/replace.Rd"
Message-ID: <CC3B0B07-CE35-431D-8C9E-364D793155B9@gmail.com>

There is no usage example for replace(). Here is a patch to replace.Rd that offers one.


# Clean up a vector of text answers
foo <- c("Yes?, "n?, "no answer")
foo <- replace(foo, list=c(2, 3), values=c("No?, NA))
foo 
# "Yes" "No?  NA


diff attached
best wishes,
tim



From bbolker at gmail.com  Sun Aug 14 08:22:56 2011
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 14 Aug 2011 02:22:56 -0400
Subject: [Rd] trivial typo in R administration manual
Message-ID: <4E4769C0.60300@ufl.edu>


  the attached should probably read "regarded by some OSes as separate
..."  Patch attached from latest SVN.

  Ben Bolker

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Rdiff.txt
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110814/8d18540b/attachment.txt>

From hadley at rice.edu  Tue Aug 16 17:53:34 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Tue, 16 Aug 2011 15:53:34 +0000
Subject: [Rd] sysdata.rda, namespaces and package dependencies
Message-ID: <CABdHhvHJCstQrsoCWhMTys6Jba5egWO6iprm2TuFy0Zrb==U1Q@mail.gmail.com>

Hi all,

I'm struggling with accessing a package dataset (munsell.map, stored
in sysdata.rda) when that package is imported, not required.  A simple
reproducible example is:

install.packages("munsell")
munsell::mnsl("10B 4/6")
# Error in match(col, munsell.map$name) : object 'munsell.map' not found

library(munsell)
munsell::mnsl("10B 4/6")
# Function works correctly

Am I doing something wrong, or is this namespace bug?

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From uschmitt at mineway.de  Tue Aug 16 09:10:50 2011
From: uschmitt at mineway.de (Uwe Schmitt)
Date: Tue, 16 Aug 2011 09:10:50 +0200
Subject: [Rd] windows directory structure
Message-ID: <4E4A17FA.2000807@mineway.de>

Hi,

I have some trouble to get the Python bindings RPy2 running with
the latest release of R. I'm using Windows.

The reason is, that RPy2 looks at certain places for R.dll,
as $R_HOME/bin and $R_HOME/lib, but not at $R_HOME/bin/i386
where the dll is located on my machine.

So I suspect that the directory structure has changed and the
RPy2 team did not notice it. I would like to discuss a patch with
the RPy2 team and therefore I need some information:

Did the structure really change ? If yes: when did that happen ?
Which variations are possible for different windows versions ?

Regards, Uwe


From uschmitt at mineway.de  Tue Aug 16 14:44:59 2011
From: uschmitt at mineway.de (Uwe Schmitt)
Date: Tue, 16 Aug 2011 14:44:59 +0200
Subject: [Rd] License question
Message-ID: <op.v0a4c9t1fg6blk@ws002>


Hi,

I'm not sure if this is the right mailing list for my question,
so please redirect me if this is the wrong place for the
following question:

Am I allowed to include R.dll and Rblas.dll in other software ?

In my case I'm want to run some R commands from a Python script
and save the results. I tried RPy2 which has some trouble running
on Windows.

Regards, Uwe



-- 
	
Dr. rer. nat. Uwe Schmitt
Forschung & Entwicklung Mathematik

mineway GmbH
Geb?ude 4
Im Helmerswald 2
66121 Saarbr?cken

Telefon: +49 (0)681 8390 5334
Telefax: +49 (0)681 830 4376

uschmitt at mineway.de
www.mineway.de

Gesch?ftsf?hrung: Dr.-Ing. Mathias Bauer
Amtsgericht Saarbr?cken HRB 12339


From kw.stat at gmail.com  Tue Aug 16 22:23:54 2011
From: kw.stat at gmail.com (Kevin Wright)
Date: Tue, 16 Aug 2011 15:23:54 -0500
Subject: [Rd] License question
In-Reply-To: <op.v0a4c9t1fg6blk@ws002>
References: <op.v0a4c9t1fg6blk@ws002>
Message-ID: <CAKFxdiSQY+iYOvkPCJTvmVS-px_H9Oe5C2VeTuMfbuHqE0qcAw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110816/07b3b898/attachment.pl>

From uschmitt at mineway.de  Tue Aug 16 22:33:31 2011
From: uschmitt at mineway.de (Uwe Schmitt)
Date: Tue, 16 Aug 2011 22:33:31 +0200
Subject: [Rd] License question
In-Reply-To: <CAKFxdiSQY+iYOvkPCJTvmVS-px_H9Oe5C2VeTuMfbuHqE0qcAw@mail.gmail.com>
References: <op.v0a4c9t1fg6blk@ws002>
	<CAKFxdiSQY+iYOvkPCJTvmVS-px_H9Oe5C2VeTuMfbuHqE0qcAw@mail.gmail.com>
Message-ID: <4E4AD41B.2090803@mineway.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110816/77a83400/attachment.pl>

From pingou at pingoured.fr  Tue Aug 16 22:42:52 2011
From: pingou at pingoured.fr (Pierre-Yves Chibon)
Date: Tue, 16 Aug 2011 22:42:52 +0200
Subject: [Rd] License question
In-Reply-To: <4E4AD41B.2090803@mineway.de>
References: <op.v0a4c9t1fg6blk@ws002>
	<CAKFxdiSQY+iYOvkPCJTvmVS-px_H9Oe5C2VeTuMfbuHqE0qcAw@mail.gmail.com>
	<4E4AD41B.2090803@mineway.de>
Message-ID: <1313527372.23852.24.camel@ambre.pingoured.fr>

On Tue, 2011-08-16 at 22:33 +0200, Uwe Schmitt wrote:
> The question is, if I am allowed to distribute the R.dll and the
> related libraries together with my software, or
> if it is better to ask the user to install these himself. 

By principle it is better *not* to bundle libraries into the software.
This allows your user to benefits from bug-fixes and improvement which
are done upstream.
A list of reasons to discourage bundle library can be found there:
http://fedoraproject.org/wiki/Packaging:No_Bundled_Libraries

Regards,
Pierre


From ligges at statistik.tu-dortmund.de  Wed Aug 17 01:00:14 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 17 Aug 2011 01:00:14 +0200
Subject: [Rd] windows directory structure
In-Reply-To: <4E4A17FA.2000807@mineway.de>
References: <4E4A17FA.2000807@mineway.de>
Message-ID: <4E4AF67E.8010905@statistik.tu-dortmund.de>



On 16.08.2011 09:10, Uwe Schmitt wrote:
> Hi,
>
> I have some trouble to get the Python bindings RPy2 running with
> the latest release of R. I'm using Windows.
>
> The reason is, that RPy2 looks at certain places for R.dll,
> as $R_HOME/bin and $R_HOME/lib, but not at $R_HOME/bin/i386
> where the dll is located on my machine.
>
> So I suspect that the directory structure has changed and the
> RPy2 team did not notice it. I would like to discuss a patch with
> the RPy2 team and therefore I need some information:
>
> Did the structure really change ?

Yes.


> If yes: when did that happen ?

With the release of R-2.12.0

> Which variations are possible for different windows versions ?

Currently, the subfolders can be i386 or x64 as you will have seen in 
the manuals.

Best,
Uwe Ligges



> Regards, Uwe
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.tu-dortmund.de  Wed Aug 17 01:29:27 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 17 Aug 2011 01:29:27 +0200
Subject: [Rd] trivial typo in R administration manual
In-Reply-To: <4E4769C0.60300@ufl.edu>
References: <4E4769C0.60300@ufl.edu>
Message-ID: <4E4AFD57.4090508@statistik.tu-dortmund.de>

Thanks, fixed.

Uwe


On 14.08.2011 08:22, Ben Bolker wrote:
>
>    the attached should probably read "regarded by some OSes as separate
> ..."  Patch attached from latest SVN.
>
>    Ben Bolker
>
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From lachmann at eva.mpg.de  Wed Aug 17 01:45:21 2011
From: lachmann at eva.mpg.de (Michael Lachmann)
Date: Wed, 17 Aug 2011 01:45:21 +0200
Subject: [Rd] fitted valued should mention predict
Message-ID: <E80CF30C-E435-4D99-B5FF-AB0F1A3C1E1A@eva.mpg.de>

Hi,

I think the help on fitted.values and fitted should mention predict in the "see also". (And maybe vice versa)

Michael

From xie at yihui.name  Wed Aug 17 07:15:48 2011
From: xie at yihui.name (Yihui Xie)
Date: Wed, 17 Aug 2011 00:15:48 -0500
Subject: [Rd] customize the stylesheet R.css for a package?
Message-ID: <CANROs4daPSeZ40iuUfLYnT2xLUaMPu7AOD24yHC3sVtw9gbFmg@mail.gmail.com>

Hi,

Since R 2.13.0 the stylesheet R.css is installed a per-package basis,
and I wish that package developers could be allowed to put a
customized R.css in their packages.

Thanks!

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 515-294-2465 Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


From nashjc at uottawa.ca  Wed Aug 17 10:27:21 2011
From: nashjc at uottawa.ca (John C Nash)
Date: Wed, 17 Aug 2011 04:27:21 -0400
Subject: [Rd] An example of very slow computation
Message-ID: <4E4B7B69.6030106@uottawa.ca>

This message is about a curious difference in timing between two ways of computing the
same function. One uses expm, so is expected to be a bit slower, but "a bit" turned out to
be a factor of >1000. The code is below. We would be grateful if anyone can point out any
egregious bad practice in our code, or enlighten us on why one approach is so much slower
than the other. The problem arose in an activity to develop guidelines for nonlinear
modeling in ecology (at NCEAS, Santa Barbara, with worldwide participants), and we will be
trying to include suggestions of how to prepare problems like this for efficient and
effective solution. The code for nlogL was the "original" from the worker who supplied the
problem.

Best,

John Nash

--------------------------------------------------------------------------------------

cat("mineral-timing.R == benchmark MIN functions in R\n")
#  J C Nash July 31, 2011

require("microbenchmark")
require("numDeriv")
library(Matrix)
library(optimx)
# dat<-read.table('min.dat', skip=3, header=FALSE)
# t<-dat[,1]
t <- c(0.77,  1.69,  2.69,  3.67,  4.69,  5.71,  7.94,  9.67, 11.77, 17.77,
 23.77, 32.77, 40.73, 47.75, 54.90, 62.81, 72.88, 98.77, 125.92, 160.19,
 191.15, 223.78, 287.70, 340.01, 340.95, 342.01)

# y<-dat[,2] # ?? tidy up
 y<- c(1.396, 3.784, 5.948, 7.717, 9.077, 10.100, 11.263, 11.856, 12.251, 12.699,
12.869, 13.048, 13.222, 13.347, 13.507, 13.628, 13.804, 14.087, 14.185, 14.351,
14.458, 14.756, 15.262, 15.703, 15.703, 15.703)


ones<-rep(1,length(t))
theta<-c(-2,-2,-2,-2)


nlogL<-function(theta){
  k<-exp(theta[1:3])
  sigma<-exp(theta[4])
  A<-rbind(
  c(-k[1], k[2]),
  c( k[1], -(k[2]+k[3]))
  )
  x0<-c(0,100)
  sol<-function(t)100-sum(expm(A*t)%*%x0)
  pred<-sapply(dat[,1],sol)
  -sum(dnorm(dat[,2],mean=pred,sd=sigma, log=TRUE))
}

getpred<-function(theta, t){
  k<-exp(theta[1:3])
  sigma<-exp(theta[4])
  A<-rbind(
  c(-k[1], k[2]),
  c( k[1], -(k[2]+k[3]))
  )
  x0<-c(0,100)
  sol<-function(tt)100-sum(expm(A*tt)%*%x0)
  pred<-sapply(t,sol)
}

Mpred <- function(theta) {
# WARNING: assumes t global
kvec<-exp(theta[1:3])
k1<-kvec[1]
k2<-kvec[2]
k3<-kvec[3]
#   MIN problem terbuthylazene disappearance
    z<-k1+k2+k3
    y<-z*z-4*k1*k3
    l1<-0.5*(-z+sqrt(y))
    l2<-0.5*(-z-sqrt(y))
    val<-100*(1-((k1+k2+l2)*exp(l2*t)-(k1+k2+l1)*exp(l1*t))/(l2-l1))
} # val should be a vector if t is a vector

negll <- function(theta){
# non expm version JN 110731
  pred<-Mpred(theta)
  sigma<-exp(theta[4])
  -sum(dnorm(dat[,2],mean=pred,sd=sigma, log=TRUE))
}

theta<-rep(-2,4)
fand<-nlogL(theta)
fsim<-negll(theta)
cat("Check fn vals: expm =",fand,"   simple=",fsim,"  diff=",fand-fsim,"\n")

cat("time the function in expm form\n")
tnlogL<-microbenchmark(nlogL(theta), times=100L)
tnlogL

cat("time the function in simpler form\n")
tnegll<-microbenchmark(negll(theta), times=100L)
tnegll

ftimes<-data.frame(texpm=tnlogL$time, tsimp=tnegll$time)
# ftimes


boxplot(log(ftimes))
title("Log times in nanoseconds for matrix exponential and simple MIN fn")


From renaud at mancala.cbio.uct.ac.za  Wed Aug 17 10:45:51 2011
From: renaud at mancala.cbio.uct.ac.za (Renaud Gaujoux)
Date: Wed, 17 Aug 2011 10:45:51 +0200
Subject: [Rd] R cmd check and multicore foreach loop
Message-ID: <4E4B7FBF.1020109@cbio.uct.ac.za>

Hi,

in R 2.12.1, R CMD check hangs when building a vignette that uses a 
foreach loop with the doMC parallel backend.
This does not happen in R 2.13.1, nor if I use doSEQ instead of doMC.
All versions of multicore, doMC and foreach are the same on both my R 
installations.

Has anybody encountered a similar issue?

Thank you.
Renaud


 

###
UNIVERSITY OF CAPE TOWN 

This e-mail is subject to the UCT ICT policies and e-mai...{{dropped:5}}


From lachmann at eva.mpg.de  Wed Aug 17 11:14:44 2011
From: lachmann at eva.mpg.de (Michael Lachmann)
Date: Wed, 17 Aug 2011 11:14:44 +0200
Subject: [Rd] An example of very slow computation
In-Reply-To: <4E4B7B69.6030106@uottawa.ca>
References: <4E4B7B69.6030106@uottawa.ca>
Message-ID: <6FC14F7C-CF2D-49D7-A7DE-9F7C98CBF025@eva.mpg.de>

I think one difference is that negll() is fully vectorized - no loops, whereas
nlogL calls the function sol() inside sapply, i.e. a loop.

Michael


On 17 Aug 2011, at 10:27AM, John C Nash wrote:

> This message is about a curious difference in timing between two ways of computing the
> same function. One uses expm, so is expected to be a bit slower, but "a bit" turned out to
> be a factor of >1000. The code is below. We would be grateful if anyone can point out any
> egregious bad practice in our code, or enlighten us on why one approach is so much slower
> than the other. The problem arose in an activity to develop guidelines for nonlinear
> modeling in ecology (at NCEAS, Santa Barbara, with worldwide participants), and we will be
> trying to include suggestions of how to prepare problems like this for efficient and
> effective solution. The code for nlogL was the "original" from the worker who supplied the
> problem.
> 
> Best,
> 
> John Nash
> 
> --------------------------------------------------------------------------------------
> 
> cat("mineral-timing.R == benchmark MIN functions in R\n")
> #  J C Nash July 31, 2011
> 
> require("microbenchmark")
> require("numDeriv")
> library(Matrix)
> library(optimx)
> # dat<-read.table('min.dat', skip=3, header=FALSE)
> # t<-dat[,1]
> t <- c(0.77,  1.69,  2.69,  3.67,  4.69,  5.71,  7.94,  9.67, 11.77, 17.77,
> 23.77, 32.77, 40.73, 47.75, 54.90, 62.81, 72.88, 98.77, 125.92, 160.19,
> 191.15, 223.78, 287.70, 340.01, 340.95, 342.01)
> 
> # y<-dat[,2] # ?? tidy up
> y<- c(1.396, 3.784, 5.948, 7.717, 9.077, 10.100, 11.263, 11.856, 12.251, 12.699,
> 12.869, 13.048, 13.222, 13.347, 13.507, 13.628, 13.804, 14.087, 14.185, 14.351,
> 14.458, 14.756, 15.262, 15.703, 15.703, 15.703)
> 
> 
> ones<-rep(1,length(t))
> theta<-c(-2,-2,-2,-2)
> 
> 
> nlogL<-function(theta){
>  k<-exp(theta[1:3])
>  sigma<-exp(theta[4])
>  A<-rbind(
>  c(-k[1], k[2]),
>  c( k[1], -(k[2]+k[3]))
>  )
>  x0<-c(0,100)
>  sol<-function(t)100-sum(expm(A*t)%*%x0)
>  pred<-sapply(dat[,1],sol)
>  -sum(dnorm(dat[,2],mean=pred,sd=sigma, log=TRUE))
> }
> 
> getpred<-function(theta, t){
>  k<-exp(theta[1:3])
>  sigma<-exp(theta[4])
>  A<-rbind(
>  c(-k[1], k[2]),
>  c( k[1], -(k[2]+k[3]))
>  )
>  x0<-c(0,100)
>  sol<-function(tt)100-sum(expm(A*tt)%*%x0)
>  pred<-sapply(t,sol)
> }
> 
> Mpred <- function(theta) {
> # WARNING: assumes t global
> kvec<-exp(theta[1:3])
> k1<-kvec[1]
> k2<-kvec[2]
> k3<-kvec[3]
> #   MIN problem terbuthylazene disappearance
>    z<-k1+k2+k3
>    y<-z*z-4*k1*k3
>    l1<-0.5*(-z+sqrt(y))
>    l2<-0.5*(-z-sqrt(y))
>    val<-100*(1-((k1+k2+l2)*exp(l2*t)-(k1+k2+l1)*exp(l1*t))/(l2-l1))
> } # val should be a vector if t is a vector
> 
> negll <- function(theta){
> # non expm version JN 110731
>  pred<-Mpred(theta)
>  sigma<-exp(theta[4])
>  -sum(dnorm(dat[,2],mean=pred,sd=sigma, log=TRUE))
> }
> 
> theta<-rep(-2,4)
> fand<-nlogL(theta)
> fsim<-negll(theta)
> cat("Check fn vals: expm =",fand,"   simple=",fsim,"  diff=",fand-fsim,"\n")
> 
> cat("time the function in expm form\n")
> tnlogL<-microbenchmark(nlogL(theta), times=100L)
> tnlogL
> 
> cat("time the function in simpler form\n")
> tnegll<-microbenchmark(negll(theta), times=100L)
> tnegll
> 
> ftimes<-data.frame(texpm=tnlogL$time, tsimp=tnegll$time)
> # ftimes
> 
> 
> boxplot(log(ftimes))
> title("Log times in nanoseconds for matrix exponential and simple MIN fn")
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> 


From malmaud at gmail.com  Wed Aug 17 05:17:56 2011
From: malmaud at gmail.com (Jonathan Malmaud)
Date: Tue, 16 Aug 2011 23:17:56 -0400
Subject: [Rd] Referencing 'inst' directory in installed package
Message-ID: <A6A6DD95-ED16-4651-8902-76FB34C437C3@gmail.com>

Hi,
My R package has files in the 'inst' directory that it needs to reference. How can the R scripts in my package find out the full path to the 'inst' directory after the package is installed, given that different users may have installed the package to different libraries? 

Thanks,
Jon Malmaud

From renaud at mancala.cbio.uct.ac.za  Wed Aug 17 13:39:34 2011
From: renaud at mancala.cbio.uct.ac.za (Renaud Gaujoux)
Date: Wed, 17 Aug 2011 13:39:34 +0200
Subject: [Rd] R cmd check and multicore foreach loop
In-Reply-To: <CAC+N9BX=Gt8VLufTQ67i_e_uTSthdYZL5e4NRVtb=aA2-gWVgA@mail.gmail.com>
References: <4E4B7FBF.1020109@cbio.uct.ac.za>
	<CAC+N9BX=Gt8VLufTQ67i_e_uTSthdYZL5e4NRVtb=aA2-gWVgA@mail.gmail.com>
Message-ID: <4E4BA876.3060401@cbio.uct.ac.za>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110817/70281832/attachment.pl>

From renaud at mancala.cbio.uct.ac.za  Wed Aug 17 13:59:14 2011
From: renaud at mancala.cbio.uct.ac.za (Renaud Gaujoux)
Date: Wed, 17 Aug 2011 13:59:14 +0200
Subject: [Rd] R cmd check and multicore foreach loop
In-Reply-To: <CAC+N9BXxfkOpCCRKFickMfFX+se6eq0P1dCOj2W9iafgh10wRA@mail.gmail.com>
References: <4E4B7FBF.1020109@cbio.uct.ac.za>
	<CAC+N9BX=Gt8VLufTQ67i_e_uTSthdYZL5e4NRVtb=aA2-gWVgA@mail.gmail.com>
	<4E4BA876.3060401@cbio.uct.ac.za>
	<CAC+N9BXxfkOpCCRKFickMfFX+se6eq0P1dCOj2W9iafgh10wRA@mail.gmail.com>
Message-ID: <4E4BAD12.8030003@cbio.uct.ac.za>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110817/2a275310/attachment.pl>

From ttriche at usc.edu  Wed Aug 17 13:50:18 2011
From: ttriche at usc.edu (Tim Triche, Jr.)
Date: Wed, 17 Aug 2011 04:50:18 -0700
Subject: [Rd] R cmd check and multicore foreach loop
In-Reply-To: <4E4BA876.3060401@cbio.uct.ac.za>
References: <4E4B7FBF.1020109@cbio.uct.ac.za>
	<CAC+N9BX=Gt8VLufTQ67i_e_uTSthdYZL5e4NRVtb=aA2-gWVgA@mail.gmail.com>
	<4E4BA876.3060401@cbio.uct.ac.za>
Message-ID: <CAC+N9BXxfkOpCCRKFickMfFX+se6eq0P1dCOj2W9iafgh10wRA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110817/c4b45df7/attachment.pl>

From kasperdanielhansen at gmail.com  Wed Aug 17 14:29:28 2011
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Wed, 17 Aug 2011 08:29:28 -0400
Subject: [Rd] Referencing 'inst' directory in installed package
In-Reply-To: <A6A6DD95-ED16-4651-8902-76FB34C437C3@gmail.com>
References: <A6A6DD95-ED16-4651-8902-76FB34C437C3@gmail.com>
Message-ID: <CAC2h7uuCf4a8zbh_jp67v7EkNHvHk4o0p-1WB_47W4BGs8977A@mail.gmail.com>

On Tue, Aug 16, 2011 at 11:17 PM, Jonathan Malmaud <malmaud at gmail.com> wrote:
> Hi,
> My R package has files in the 'inst' directory that it needs to reference. How can the R scripts in my package find out the full path to the 'inst' directory after the package is installed, given that different users may have installed the package to different libraries?


The inst directory does not exists after installation (this is
described in R-exts).  Use something like
   system.file("extdata", package = "MyPackage")
to locate a directory etc.

Kasper



>
> Thanks,
> Jon Malmaud
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From marc_schwartz at me.com  Wed Aug 17 14:35:41 2011
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 17 Aug 2011 07:35:41 -0500
Subject: [Rd] Referencing 'inst' directory in installed package
In-Reply-To: <A6A6DD95-ED16-4651-8902-76FB34C437C3@gmail.com>
References: <A6A6DD95-ED16-4651-8902-76FB34C437C3@gmail.com>
Message-ID: <7C2452FB-FF87-42F4-BD13-D8A23C36C600@me.com>

On Aug 16, 2011, at 10:17 PM, Jonathan Malmaud wrote:

> Hi,
> My R package has files in the 'inst' directory that it needs to reference. How can the R scripts in my package find out the full path to the 'inst' directory after the package is installed, given that different users may have installed the package to different libraries? 
> 
> Thanks,
> Jon Malmaud


See ?path.package and ?file.path

Example:

> require(WriteXLS)
Loading required package: WriteXLS

# I am on OSX
> path.package("WriteXLS")
[1] "/Library/Frameworks/R.framework/Versions/2.13/Resources/library/WriteXLS"

I have Perl scripts in my package, which are in the /inst/Perl folder in the package source, so:

> file.path(path.package("WriteXLS"), "Perl/WriteXLS.pl")
[1] "/Library/Frameworks/R.framework/Versions/2.13/Resources/library/WriteXLS/Perl/WriteXLS.pl"


HTH,

Marc Schwartz


From edd at debian.org  Wed Aug 17 14:49:26 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 17 Aug 2011 07:49:26 -0500
Subject: [Rd] Referencing 'inst' directory in installed package
In-Reply-To: <A6A6DD95-ED16-4651-8902-76FB34C437C3@gmail.com>
References: <A6A6DD95-ED16-4651-8902-76FB34C437C3@gmail.com>
Message-ID: <20043.47318.301993.51991@max.nulle.part>


On 16 August 2011 at 23:17, Jonathan Malmaud wrote:
| Hi,
| My R package has files in the 'inst' directory that it needs to reference. How can the R scripts in my package find out the full path to the 'inst' directory after the package is installed, given that different users may have installed the package to different libraries? 

It is slightly different:  files and directories below the inst/ directory in
the _sources_ will be installed in the toplevel diretory of the _installed package_.

You can then use system.file() to get the location at run-time for the
installed package. E.g. to get the example file 'fib.r' from the Fibonacci
directory within the examples of Rcpp of my installed version:

R> system.file(package="Rcpp", "examples", "Fibonacci", "fib.r")
[1] "/usr/local/lib/R/site-library/Rcpp/examples/Fibonacci/fib.r"

The result of that system.file() call could now be fed to source() etc. 

system.file() can be used for other files within the package too. 'Writing R
Extensions' details what other files are installed by default -- but as
stated, everything below inst/ gets copied as is, without the layer of inst/
itself.

Hope this helps,  Dirk

-- 
Two new Rcpp master classes for R and C++ integration scheduled for 
New York (Sep 24) and San Francisco (Oct 8), more details are at
http://dirk.eddelbuettel.com/blog/2011/08/04#rcpp_classes_2011-09_and_2011-10
http://www.revolutionanalytics.com/products/training/public/rcpp-master-class.php


From brian at braverock.com  Wed Aug 17 14:56:53 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 17 Aug 2011 07:56:53 -0500
Subject: [Rd] R cmd check and multicore foreach loop
In-Reply-To: <CAC+N9BXxfkOpCCRKFickMfFX+se6eq0P1dCOj2W9iafgh10wRA@mail.gmail.com>
References: <4E4B7FBF.1020109@cbio.uct.ac.za>
	<CAC+N9BX=Gt8VLufTQ67i_e_uTSthdYZL5e4NRVtb=aA2-gWVgA@mail.gmail.com>
	<4E4BA876.3060401@cbio.uct.ac.za>
	<CAC+N9BXxfkOpCCRKFickMfFX+se6eq0P1dCOj2W9iafgh10wRA@mail.gmail.com>
Message-ID: <1313585813.3760.13.camel@brian-rcg>

On Wed, 2011-08-17 at 04:50 -0700, Tim Triche, Jr. wrote:
> I'll see if I can put together a self-contained example.  Primarily,
> the times that I use multicore (and attempted to use doSMP, mostly
> because one of my users refuses to ditch Windows) are when I am
> reading a ton of binary files, none of which depend on the others.
> This is a blindingly obvious use-case for e.g. doMC and doSMP, yet
> what typically happens is that the entire operation wedges.  I'm told
> that doSMP really only works well with Revolution R, but per above, I
> will try to put together a working self-contained example to show
> how. 

Remember that physical I/O can bind up the processes too.  Having a
bunch of processes all trying to read from local disk at the same time
(especially when they are all trying to read the same file(s), a problem
it seems you may not have) is a recipe for I/O locks that can seize up
your processes.

So, if the problem only occurs with physical I/O, the first thing I
would try is to move that storage to a storage device on another machine
that is tuned for that level of disk I/O.

Regards,

   - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From renaud at mancala.cbio.uct.ac.za  Wed Aug 17 15:33:59 2011
From: renaud at mancala.cbio.uct.ac.za (Renaud Gaujoux)
Date: Wed, 17 Aug 2011 15:33:59 +0200
Subject: [Rd] R cmd check and multicore foreach loop
In-Reply-To: <1313585813.3760.13.camel@brian-rcg>
References: <4E4B7FBF.1020109@cbio.uct.ac.za>	
	<CAC+N9BX=Gt8VLufTQ67i_e_uTSthdYZL5e4NRVtb=aA2-gWVgA@mail.gmail.com>	
	<4E4BA876.3060401@cbio.uct.ac.za>	
	<CAC+N9BXxfkOpCCRKFickMfFX+se6eq0P1dCOj2W9iafgh10wRA@mail.gmail.com>
	<1313585813.3760.13.camel@brian-rcg>
Message-ID: <4E4BC347.9020205@cbio.uct.ac.za>

Uhm... maybe this is the issue.
The issue seems to specially occur when I am building the vignette, 
which performs some parallel computations on a reduced example, 
therefore faster than in a normal usage of the package.
The two processes (on my dual core) output some logging information 
using cat, which are normally sent to the console, but I guess that in 
the case of a vignette these are written to tex file. It is very few 
data though (a loop counter), so writing should be also very quick, even 
in a file.

Could it be possible that a I/O deadlock happens because of this output?
I actually use mutexes, at the end of each loop to perform bigger 
writing operation on a common file, but I hadn't think these would be 
required for the logging output,  assuming that stdout and stderr were 
thread safe. Maybe I should use mutexes at this level too.
Does multicore or doMC provide optional separate logging as doMPI does? 
(I guess this might be better posted to R-hpc)

Thank you.
Renaud



On 17/08/2011 14:56, Brian G. Peterson wrote:
> On Wed, 2011-08-17 at 04:50 -0700, Tim Triche, Jr. wrote:
>> I'll see if I can put together a self-contained example.  Primarily,
>> the times that I use multicore (and attempted to use doSMP, mostly
>> because one of my users refuses to ditch Windows) are when I am
>> reading a ton of binary files, none of which depend on the others.
>> This is a blindingly obvious use-case for e.g. doMC and doSMP, yet
>> what typically happens is that the entire operation wedges.  I'm told
>> that doSMP really only works well with Revolution R, but per above, I
>> will try to put together a working self-contained example to show
>> how.
> Remember that physical I/O can bind up the processes too.  Having a
> bunch of processes all trying to read from local disk at the same time
> (especially when they are all trying to read the same file(s), a problem
> it seems you may not have) is a recipe for I/O locks that can seize up
> your processes.
>
> So, if the problem only occurs with physical I/O, the first thing I
> would try is to move that storage to a storage device on another machine
> that is tuned for that level of disk I/O.
>
> Regards,
>
>     - Brian
>

 

###
UNIVERSITY OF CAPE TOWN 

This e-mail is subject to the UCT ICT policies and e-mai...{{dropped:5}}


From msuzen at mango-solutions.com  Wed Aug 17 18:04:49 2011
From: msuzen at mango-solutions.com (Mehmet Suzen)
Date: Wed, 17 Aug 2011 17:04:49 +0100
Subject: [Rd] Referencing 'inst' directory in installed package
In-Reply-To: <A6A6DD95-ED16-4651-8902-76FB34C437C3@gmail.com>
References: <A6A6DD95-ED16-4651-8902-76FB34C437C3@gmail.com>
Message-ID: <3CBFCFB1FEFFA841BA83ADF2F2A9C6FA0183597C@mango-data1.Mango.local>

You can use
system.file(package="your_package_name")
which will return you library directory.


-----Original Message-----
From: r-devel-bounces at r-project.org
[mailto:r-devel-bounces at r-project.org] On Behalf Of Jonathan Malmaud
Sent: 17 August 2011 04:18
To: r-devel at r-project.org
Subject: [Rd] Referencing 'inst' directory in installed package

Hi,
My R package has files in the 'inst' directory that it needs to
reference. How can the R scripts in my package find out the full path to
the 'inst' directory after the package is installed, given that
different users may have installed the package to different libraries? 

Thanks,
Jon Malmaud
______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel
LEGAL NOTICE
This message is intended for the use o...{{dropped:10}}


From renaud at mancala.cbio.uct.ac.za  Wed Aug 17 18:12:24 2011
From: renaud at mancala.cbio.uct.ac.za (Renaud Gaujoux)
Date: Wed, 17 Aug 2011 18:12:24 +0200
Subject: [Rd] getNativeSymbolInfo("user_unif_rand") returns different
 results on windows and linux
Message-ID: <4E4BE868.7010504@cbio.uct.ac.za>

Hi,

When loading a package that provides the user-supplied RNG hook 
user_unif_rand, calling getNativeSymbolInfo("user_unif_rand") returns 
informations about the loaded symbol.
I am using this to identify which package currently provides the RNG hook.
The results are the same on windows and linux if only one library 
provides the hook.

If one loads a second package that provides this hook, then on linux 
(Ubuntu 10.10), calling again getNativeSymbolInfo("user_unif_rand") 
returns the latest symbol information (which I presume is the correct 
result).
On windows (XP and Vista) however the symbol information does not change 
(same pointer address) and the package data is NULL.
See results for both systems below. I tested this with R 2.12.1, 2.13.0 
and 2.13.1 on Windows.

Is this a normal behaviour for dll loaded on Windows?
Thank you.

Renaud


#####################
# LINUX
#####################
 > library(rlecuyer)
 > getNativeSymbolInfo("user_unif_rand")
$name
[1] "user_unif_rand"

$address
<pointer: 0x7ff55acffed0>
attr(,"class")
[1] "NativeSymbol"

$package
DLL name: rlecuyer
Filename: 
/home/renaud/R/x86_64-pc-linux-gnu-library/2.12/rlecuyer/libs/rlecuyer.so
Dynamic lookup: TRUE

attr(,"class")
[1] "NativeSymbolInfo"
 > library(rstream)
 > getNativeSymbolInfo("user_unif_rand")
$name
[1] "user_unif_rand"

$address
<pointer: 0x7ff55aaf58c0>
attr(,"class")
[1] "NativeSymbol"

$package
DLL name: rstream
Filename: 
/home/renaud/R/x86_64-pc-linux-gnu-library/2.12/rstream/libs/rstream.so
Dynamic lookup: TRUE

attr(,"class")
[1] "NativeSymbolInfo"

#####################
# WINDOWS
#####################
 > library(rlecuyer)
 > getNativeSymbolInfo("user_unif_rand")
$name
[1] "user_unif_rand"

$address
<pointer: 0x6bb84fb8>
attr(,"class")
[1] "NativeSymbol"

$package
DLL name: rlecuyer
Filename: C:/Program
         Files/R/R-2.13.1/library/rlecuyer/libs/i386/rlecuyer.dll
Dynamic lookup: TRUE

attr(,"class")
[1] "NativeSymbolInfo"
 > library(rstream)
 > getNativeSymbolInfo("user_unif_rand")
$name
[1] "user_unif_rand"

$address
<pointer: 0x6bb84fb8>
attr(,"class")
[1] "NativeSymbol"

$package
NULL

attr(,"class")
[1] "NativeSymbolInfo"






 

###
UNIVERSITY OF CAPE TOWN 

This e-mail is subject to the UCT ICT policies and e-mai...{{dropped:5}}


From cberry at tajo.ucsd.edu  Wed Aug 17 19:08:17 2011
From: cberry at tajo.ucsd.edu (cberry at tajo.ucsd.edu)
Date: Wed, 17 Aug 2011 10:08:17 -0700
Subject: [Rd] An example of very slow computation
References: <4E4B7B69.6030106@uottawa.ca>
Message-ID: <87aab82cfy.fsf@tajo.ucsd.edu>

John C Nash <nashjc at uottawa.ca> writes:

> This message is about a curious difference in timing between two ways of computing the
> same function. One uses expm, so is expected to be a bit slower, but "a bit" turned out to
> be a factor of >1000. The code is below. We would be grateful if anyone can point out any
> egregious bad practice in our code, or enlighten us on why one approach is so much slower
> than the other. 

Looks like A*t in expm(A*t) is a "matrix".

'getMethod("expm","matrix")' coerces it arg to a "Matrix", then calls
expm(), whose method coerces its arg to a "dMatrix" and calls expm(),
whose method coerces its arg to a 'dgeMatrix' and calls expm(), whose
method finally calls '.Call(dgeMatrix_exp, x)' 

Whew!

The time difference between 'expm( diag(10)+1 )' and 'expm( as( diag(10)+1,
"dgeMatrix" ))' is a factor of 10 on my box. 

Dunno 'bout the other factor of 100.

Chuck




> The problem arose in an activity to develop guidelines for nonlinear
> modeling in ecology (at NCEAS, Santa Barbara, with worldwide participants), and we will be
> trying to include suggestions of how to prepare problems like this for efficient and
> effective solution. The code for nlogL was the "original" from the worker who supplied the
> problem.
>
> Best,
>
> John Nash
>
> --------------------------------------------------------------------------------------
>
> cat("mineral-timing.R == benchmark MIN functions in R\n")
> #  J C Nash July 31, 2011
>
> require("microbenchmark")
> require("numDeriv")
> library(Matrix)
> library(optimx)
> # dat<-read.table('min.dat', skip=3, header=FALSE)
> # t<-dat[,1]
> t <- c(0.77,  1.69,  2.69,  3.67,  4.69,  5.71,  7.94,  9.67, 11.77, 17.77,
>  23.77, 32.77, 40.73, 47.75, 54.90, 62.81, 72.88, 98.77, 125.92, 160.19,
>  191.15, 223.78, 287.70, 340.01, 340.95, 342.01)
>
> # y<-dat[,2] # ?? tidy up
>  y<- c(1.396, 3.784, 5.948, 7.717, 9.077, 10.100, 11.263, 11.856, 12.251, 12.699,
> 12.869, 13.048, 13.222, 13.347, 13.507, 13.628, 13.804, 14.087, 14.185, 14.351,
> 14.458, 14.756, 15.262, 15.703, 15.703, 15.703)
>
>
> ones<-rep(1,length(t))
> theta<-c(-2,-2,-2,-2)
>
>
> nlogL<-function(theta){
>   k<-exp(theta[1:3])
>   sigma<-exp(theta[4])
>   A<-rbind(
>   c(-k[1], k[2]),
>   c( k[1], -(k[2]+k[3]))
>   )
>   x0<-c(0,100)
>   sol<-function(t)100-sum(expm(A*t)%*%x0)
>   pred<-sapply(dat[,1],sol)
>   -sum(dnorm(dat[,2],mean=pred,sd=sigma, log=TRUE))
> }
>
> getpred<-function(theta, t){
>   k<-exp(theta[1:3])
>   sigma<-exp(theta[4])
>   A<-rbind(
>   c(-k[1], k[2]),
>   c( k[1], -(k[2]+k[3]))
>   )
>   x0<-c(0,100)
>   sol<-function(tt)100-sum(expm(A*tt)%*%x0)
>   pred<-sapply(t,sol)
> }
>
> Mpred <- function(theta) {
> # WARNING: assumes t global
> kvec<-exp(theta[1:3])
> k1<-kvec[1]
> k2<-kvec[2]
> k3<-kvec[3]
> #   MIN problem terbuthylazene disappearance
>     z<-k1+k2+k3
>     y<-z*z-4*k1*k3
>     l1<-0.5*(-z+sqrt(y))
>     l2<-0.5*(-z-sqrt(y))
>     val<-100*(1-((k1+k2+l2)*exp(l2*t)-(k1+k2+l1)*exp(l1*t))/(l2-l1))
> } # val should be a vector if t is a vector
>
> negll <- function(theta){
> # non expm version JN 110731
>   pred<-Mpred(theta)
>   sigma<-exp(theta[4])
>   -sum(dnorm(dat[,2],mean=pred,sd=sigma, log=TRUE))
> }
>
> theta<-rep(-2,4)
> fand<-nlogL(theta)
> fsim<-negll(theta)
> cat("Check fn vals: expm =",fand,"   simple=",fsim,"  diff=",fand-fsim,"\n")
>
> cat("time the function in expm form\n")
> tnlogL<-microbenchmark(nlogL(theta), times=100L)
> tnlogL
>
> cat("time the function in simpler form\n")
> tnegll<-microbenchmark(negll(theta), times=100L)
> tnegll
>
> ftimes<-data.frame(texpm=tnlogL$time, tsimp=tnegll$time)
> # ftimes
>
>
> boxplot(log(ftimes))
> title("Log times in nanoseconds for matrix exponential and simple MIN fn")
>

-- 
Charles C. Berry                         cberry at tajo.ucsd.edu


From rvaradhan at jhmi.edu  Wed Aug 17 20:32:50 2011
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Wed, 17 Aug 2011 18:32:50 +0000
Subject: [Rd] An example of very slow computation
In-Reply-To: <87aab82cfy.fsf@tajo.ucsd.edu>
References: <4E4B7B69.6030106@uottawa.ca> <87aab82cfy.fsf@tajo.ucsd.edu>
Message-ID: <2F9EA67EF9AE1C48A147CB41BE2E15C3059E2B@DOM-EB-MAIL2.win.ad.jhu.edu>

Yes, the culprit is the evaluation of expm(A*t).  This is a lazy way of solving the system of ODEs, where you save analytic effort, but you pay for it dearly in terms of computational effort!

Even in this lazy approach, I am sure there ought to be faster ways to evaluating exponent of a matrix than that in "Matrix" package.

Ravi.

-------------------------------------------------------
Ravi Varadhan, Ph.D.
Assistant Professor,
Division of Geriatric Medicine and Gerontology School of Medicine Johns Hopkins University

Ph. (410) 502-2619
email: rvaradhan at jhmi.edu

-----Original Message-----
From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of cberry at tajo.ucsd.edu
Sent: Wednesday, August 17, 2011 1:08 PM
To: r-devel at stat.math.ethz.ch
Subject: Re: [Rd] An example of very slow computation

John C Nash <nashjc at uottawa.ca> writes:

> This message is about a curious difference in timing between two ways of computing the
> same function. One uses expm, so is expected to be a bit slower, but "a bit" turned out to
> be a factor of >1000. The code is below. We would be grateful if anyone can point out any
> egregious bad practice in our code, or enlighten us on why one approach is so much slower
> than the other. 

Looks like A*t in expm(A*t) is a "matrix".

'getMethod("expm","matrix")' coerces it arg to a "Matrix", then calls
expm(), whose method coerces its arg to a "dMatrix" and calls expm(),
whose method coerces its arg to a 'dgeMatrix' and calls expm(), whose
method finally calls '.Call(dgeMatrix_exp, x)' 

Whew!

The time difference between 'expm( diag(10)+1 )' and 'expm( as( diag(10)+1,
"dgeMatrix" ))' is a factor of 10 on my box. 

Dunno 'bout the other factor of 100.

Chuck




> The problem arose in an activity to develop guidelines for nonlinear
> modeling in ecology (at NCEAS, Santa Barbara, with worldwide participants), and we will be
> trying to include suggestions of how to prepare problems like this for efficient and
> effective solution. The code for nlogL was the "original" from the worker who supplied the
> problem.
>
> Best,
>
> John Nash
>
> --------------------------------------------------------------------------------------
>
> cat("mineral-timing.R == benchmark MIN functions in R\n")
> #  J C Nash July 31, 2011
>
> require("microbenchmark")
> require("numDeriv")
> library(Matrix)
> library(optimx)
> # dat<-read.table('min.dat', skip=3, header=FALSE)
> # t<-dat[,1]
> t <- c(0.77,  1.69,  2.69,  3.67,  4.69,  5.71,  7.94,  9.67, 11.77, 17.77,
>  23.77, 32.77, 40.73, 47.75, 54.90, 62.81, 72.88, 98.77, 125.92, 160.19,
>  191.15, 223.78, 287.70, 340.01, 340.95, 342.01)
>
> # y<-dat[,2] # ?? tidy up
>  y<- c(1.396, 3.784, 5.948, 7.717, 9.077, 10.100, 11.263, 11.856, 12.251, 12.699,
> 12.869, 13.048, 13.222, 13.347, 13.507, 13.628, 13.804, 14.087, 14.185, 14.351,
> 14.458, 14.756, 15.262, 15.703, 15.703, 15.703)
>
>
> ones<-rep(1,length(t))
> theta<-c(-2,-2,-2,-2)
>
>
> nlogL<-function(theta){
>   k<-exp(theta[1:3])
>   sigma<-exp(theta[4])
>   A<-rbind(
>   c(-k[1], k[2]),
>   c( k[1], -(k[2]+k[3]))
>   )
>   x0<-c(0,100)
>   sol<-function(t)100-sum(expm(A*t)%*%x0)
>   pred<-sapply(dat[,1],sol)
>   -sum(dnorm(dat[,2],mean=pred,sd=sigma, log=TRUE))
> }
>
> getpred<-function(theta, t){
>   k<-exp(theta[1:3])
>   sigma<-exp(theta[4])
>   A<-rbind(
>   c(-k[1], k[2]),
>   c( k[1], -(k[2]+k[3]))
>   )
>   x0<-c(0,100)
>   sol<-function(tt)100-sum(expm(A*tt)%*%x0)
>   pred<-sapply(t,sol)
> }
>
> Mpred <- function(theta) {
> # WARNING: assumes t global
> kvec<-exp(theta[1:3])
> k1<-kvec[1]
> k2<-kvec[2]
> k3<-kvec[3]
> #   MIN problem terbuthylazene disappearance
>     z<-k1+k2+k3
>     y<-z*z-4*k1*k3
>     l1<-0.5*(-z+sqrt(y))
>     l2<-0.5*(-z-sqrt(y))
>     val<-100*(1-((k1+k2+l2)*exp(l2*t)-(k1+k2+l1)*exp(l1*t))/(l2-l1))
> } # val should be a vector if t is a vector
>
> negll <- function(theta){
> # non expm version JN 110731
>   pred<-Mpred(theta)
>   sigma<-exp(theta[4])
>   -sum(dnorm(dat[,2],mean=pred,sd=sigma, log=TRUE))
> }
>
> theta<-rep(-2,4)
> fand<-nlogL(theta)
> fsim<-negll(theta)
> cat("Check fn vals: expm =",fand,"   simple=",fsim,"  diff=",fand-fsim,"\n")
>
> cat("time the function in expm form\n")
> tnlogL<-microbenchmark(nlogL(theta), times=100L)
> tnlogL
>
> cat("time the function in simpler form\n")
> tnegll<-microbenchmark(negll(theta), times=100L)
> tnegll
>
> ftimes<-data.frame(texpm=tnlogL$time, tsimp=tnegll$time)
> # ftimes
>
>
> boxplot(log(ftimes))
> title("Log times in nanoseconds for matrix exponential and simple MIN fn")
>

-- 
Charles C. Berry                         cberry at tajo.ucsd.edu

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From duncan at wald.ucdavis.edu  Wed Aug 17 20:59:58 2011
From: duncan at wald.ucdavis.edu (Duncan Temple Lang)
Date: Wed, 17 Aug 2011 11:59:58 -0700
Subject: [Rd] getNativeSymbolInfo("user_unif_rand") returns different
 results on windows and linux
In-Reply-To: <4E4BE868.7010504@cbio.uct.ac.za>
References: <4E4BE868.7010504@cbio.uct.ac.za>
Message-ID: <4E4C0FAE.8060803@wald.ucdavis.edu>


Hi Renaud

  I cannot presently step through the code on Windows to verify the cause of the problem,
but looking at the code, I would _presume_ the reason is that symbol lookup is cached on
Windows but not on Linux or OS X (at least by default).
Thus when we perform the second search for user_unif_rand, we find it in the cache
rather than searching all the DLLs.

This happens because we did not specify a value for the PACKAGE parameter.

When we load a new DLL, the cache should probably be cleared or we
intelligently update it as necessary for the new DLLs on demand, i.e.
for a new search for a symbol we look in the new DLLs and then use the cache.
(This involves some book-keeping that could become convoluted.)

If we had specified a value for PACKAGE, e.g.

  getNativeSymbolInfo("user_unif_rand", "rstream")

we would get the version in that package's DLL.

So this gives a workaround that you can use with just R code

  findNativeSymbolInfo =
  function(sym,  dlls = rev(getLoadedDLLs()))  {

      for(d in dlls) {
         z = getNativeSymbolInfo(sym, d)
         if(!is.null(z))
          return(z)
      }

    NULL
  }

We'll think about whether to change the behaviour on Windows and how to do it
without affecting performance excessively.

 Best,
   D.


On 8/17/11 9:12 AM, Renaud Gaujoux wrote:
> Hi,
> 
> When loading a package that provides the user-supplied RNG hook user_unif_rand, calling
> getNativeSymbolInfo("user_unif_rand") returns informations about the loaded symbol.
> I am using this to identify which package currently provides the RNG hook.
> The results are the same on windows and linux if only one library provides the hook.
> 
> If one loads a second package that provides this hook, then on linux (Ubuntu 10.10), calling again
> getNativeSymbolInfo("user_unif_rand") returns the latest symbol information (which I presume is the correct result).
> On windows (XP and Vista) however the symbol information does not change (same pointer address) and the package data is
> NULL.
> See results for both systems below. I tested this with R 2.12.1, 2.13.0 and 2.13.1 on Windows.
> 
> Is this a normal behaviour for dll loaded on Windows?
> Thank you.
> 
> Renaud
> 
> 
> #####################
> # LINUX
> #####################
>> library(rlecuyer)
>> getNativeSymbolInfo("user_unif_rand")
> $name
> [1] "user_unif_rand"
> 
> $address
> <pointer: 0x7ff55acffed0>
> attr(,"class")
> [1] "NativeSymbol"
> 
> $package
> DLL name: rlecuyer
> Filename: /home/renaud/R/x86_64-pc-linux-gnu-library/2.12/rlecuyer/libs/rlecuyer.so
> Dynamic lookup: TRUE
> 
> attr(,"class")
> [1] "NativeSymbolInfo"
>> library(rstream)
>> getNativeSymbolInfo("user_unif_rand")
> $name
> [1] "user_unif_rand"
> 
> $address
> <pointer: 0x7ff55aaf58c0>
> attr(,"class")
> [1] "NativeSymbol"
> 
> $package
> DLL name: rstream
> Filename: /home/renaud/R/x86_64-pc-linux-gnu-library/2.12/rstream/libs/rstream.so
> Dynamic lookup: TRUE
> 
> attr(,"class")
> [1] "NativeSymbolInfo"
> 
> #####################
> # WINDOWS
> #####################
>> library(rlecuyer)
>> getNativeSymbolInfo("user_unif_rand")
> $name
> [1] "user_unif_rand"
> 
> $address
> <pointer: 0x6bb84fb8>
> attr(,"class")
> [1] "NativeSymbol"
> 
> $package
> DLL name: rlecuyer
> Filename: C:/Program
>         Files/R/R-2.13.1/library/rlecuyer/libs/i386/rlecuyer.dll
> Dynamic lookup: TRUE
> 
> attr(,"class")
> [1] "NativeSymbolInfo"
>> library(rstream)
>> getNativeSymbolInfo("user_unif_rand")
> $name
> [1] "user_unif_rand"
> 
> $address
> <pointer: 0x6bb84fb8>
> attr(,"class")
> [1] "NativeSymbol"
> 
> $package
> NULL
> 
> attr(,"class")
> [1] "NativeSymbolInfo"
> 
> 
> 
> 
> 
> 
> 
> 
> ###
> UNIVERSITY OF CAPE TOWN
> This e-mail is subject to the UCT ICT policies and e-mai...{{dropped:5}}
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From rvaradhan at jhmi.edu  Wed Aug 17 23:24:03 2011
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Wed, 17 Aug 2011 21:24:03 +0000
Subject: [Rd] An example of very slow computation
In-Reply-To: <2F9EA67EF9AE1C48A147CB41BE2E15C3059E2B@DOM-EB-MAIL2.win.ad.jhu.edu>
References: <4E4B7B69.6030106@uottawa.ca> <87aab82cfy.fsf@tajo.ucsd.edu>
	<2F9EA67EF9AE1C48A147CB41BE2E15C3059E2B@DOM-EB-MAIL2.win.ad.jhu.edu>
Message-ID: <2F9EA67EF9AE1C48A147CB41BE2E15C3059E9C@DOM-EB-MAIL2.win.ad.jhu.edu>

A principled way to solve this system of ODEs is to use the idea of "fundamental matrix", which is the same idea as that of diagonalization of a matrix (see Boyce and DiPrima or any ODE text).

Here is the code for that:


nlogL2 <- function(theta){
  k <- exp(theta[1:3])
  sigma <- exp(theta[4])
  A <- rbind(
  c(-k[1], k[2]),
  c( k[1], -(k[2]+k[3]))
  )
	eA <- eigen(A)
	T <- eA$vectors
	r <- eA$values
	x0 <- c(0,100)
	Tx0 <- T %*% x0

	sol <- function(t) 100 - sum(T %*% diag(exp(r*t)) %*% Tx0)
 	pred <- sapply(dat[,1], sol)
  	-sum(dnorm(dat[,2], mean=pred, sd=sigma, log=TRUE)) 
}
This is much faster than using expm(A*t), but much slower than "by hand" calculations since we have to repeatedly do the diagonalization.  An obvious advantage of this fuunction is that it applies to *any* linear system of ODEs for which the eigenvalues are real (and negative).

Ravi.

-------------------------------------------------------
Ravi Varadhan, Ph.D.
Assistant Professor,
Division of Geriatric Medicine and Gerontology School of Medicine Johns Hopkins University

Ph. (410) 502-2619
email: rvaradhan at jhmi.edu


-----Original Message-----
From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of Ravi Varadhan
Sent: Wednesday, August 17, 2011 2:33 PM
To: 'cberry at tajo.ucsd.edu'; r-devel at stat.math.ethz.ch; 'nashjc at uottawa.ca'
Subject: Re: [Rd] An example of very slow computation

Yes, the culprit is the evaluation of expm(A*t).  This is a lazy way of solving the system of ODEs, where you save analytic effort, but you pay for it dearly in terms of computational effort!

Even in this lazy approach, I am sure there ought to be faster ways to evaluating exponent of a matrix than that in "Matrix" package.

Ravi.

-------------------------------------------------------
Ravi Varadhan, Ph.D.
Assistant Professor,
Division of Geriatric Medicine and Gerontology School of Medicine Johns Hopkins University

Ph. (410) 502-2619
email: rvaradhan at jhmi.edu

-----Original Message-----
From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of cberry at tajo.ucsd.edu
Sent: Wednesday, August 17, 2011 1:08 PM
To: r-devel at stat.math.ethz.ch
Subject: Re: [Rd] An example of very slow computation

John C Nash <nashjc at uottawa.ca> writes:

> This message is about a curious difference in timing between two ways of computing the
> same function. One uses expm, so is expected to be a bit slower, but "a bit" turned out to
> be a factor of >1000. The code is below. We would be grateful if anyone can point out any
> egregious bad practice in our code, or enlighten us on why one approach is so much slower
> than the other. 

Looks like A*t in expm(A*t) is a "matrix".

'getMethod("expm","matrix")' coerces it arg to a "Matrix", then calls
expm(), whose method coerces its arg to a "dMatrix" and calls expm(),
whose method coerces its arg to a 'dgeMatrix' and calls expm(), whose
method finally calls '.Call(dgeMatrix_exp, x)' 

Whew!

The time difference between 'expm( diag(10)+1 )' and 'expm( as( diag(10)+1,
"dgeMatrix" ))' is a factor of 10 on my box. 

Dunno 'bout the other factor of 100.

Chuck




> The problem arose in an activity to develop guidelines for nonlinear
> modeling in ecology (at NCEAS, Santa Barbara, with worldwide participants), and we will be
> trying to include suggestions of how to prepare problems like this for efficient and
> effective solution. The code for nlogL was the "original" from the worker who supplied the
> problem.
>
> Best,
>
> John Nash
>
> --------------------------------------------------------------------------------------
>
> cat("mineral-timing.R == benchmark MIN functions in R\n")
> #  J C Nash July 31, 2011
>
> require("microbenchmark")
> require("numDeriv")
> library(Matrix)
> library(optimx)
> # dat<-read.table('min.dat', skip=3, header=FALSE)
> # t<-dat[,1]
> t <- c(0.77,  1.69,  2.69,  3.67,  4.69,  5.71,  7.94,  9.67, 11.77, 17.77,
>  23.77, 32.77, 40.73, 47.75, 54.90, 62.81, 72.88, 98.77, 125.92, 160.19,
>  191.15, 223.78, 287.70, 340.01, 340.95, 342.01)
>
> # y<-dat[,2] # ?? tidy up
>  y<- c(1.396, 3.784, 5.948, 7.717, 9.077, 10.100, 11.263, 11.856, 12.251, 12.699,
> 12.869, 13.048, 13.222, 13.347, 13.507, 13.628, 13.804, 14.087, 14.185, 14.351,
> 14.458, 14.756, 15.262, 15.703, 15.703, 15.703)
>
>
> ones<-rep(1,length(t))
> theta<-c(-2,-2,-2,-2)
>
>
> nlogL<-function(theta){
>   k<-exp(theta[1:3])
>   sigma<-exp(theta[4])
>   A<-rbind(
>   c(-k[1], k[2]),
>   c( k[1], -(k[2]+k[3]))
>   )
>   x0<-c(0,100)
>   sol<-function(t)100-sum(expm(A*t)%*%x0)
>   pred<-sapply(dat[,1],sol)
>   -sum(dnorm(dat[,2],mean=pred,sd=sigma, log=TRUE))
> }
>
> getpred<-function(theta, t){
>   k<-exp(theta[1:3])
>   sigma<-exp(theta[4])
>   A<-rbind(
>   c(-k[1], k[2]),
>   c( k[1], -(k[2]+k[3]))
>   )
>   x0<-c(0,100)
>   sol<-function(tt)100-sum(expm(A*tt)%*%x0)
>   pred<-sapply(t,sol)
> }
>
> Mpred <- function(theta) {
> # WARNING: assumes t global
> kvec<-exp(theta[1:3])
> k1<-kvec[1]
> k2<-kvec[2]
> k3<-kvec[3]
> #   MIN problem terbuthylazene disappearance
>     z<-k1+k2+k3
>     y<-z*z-4*k1*k3
>     l1<-0.5*(-z+sqrt(y))
>     l2<-0.5*(-z-sqrt(y))
>     val<-100*(1-((k1+k2+l2)*exp(l2*t)-(k1+k2+l1)*exp(l1*t))/(l2-l1))
> } # val should be a vector if t is a vector
>
> negll <- function(theta){
> # non expm version JN 110731
>   pred<-Mpred(theta)
>   sigma<-exp(theta[4])
>   -sum(dnorm(dat[,2],mean=pred,sd=sigma, log=TRUE))
> }
>
> theta<-rep(-2,4)
> fand<-nlogL(theta)
> fsim<-negll(theta)
> cat("Check fn vals: expm =",fand,"   simple=",fsim,"  diff=",fand-fsim,"\n")
>
> cat("time the function in expm form\n")
> tnlogL<-microbenchmark(nlogL(theta), times=100L)
> tnlogL
>
> cat("time the function in simpler form\n")
> tnegll<-microbenchmark(negll(theta), times=100L)
> tnegll
>
> ftimes<-data.frame(texpm=tnlogL$time, tsimp=tnegll$time)
> # ftimes
>
>
> boxplot(log(ftimes))
> title("Log times in nanoseconds for matrix exponential and simple MIN fn")
>

-- 
Charles C. Berry                         cberry at tajo.ucsd.edu

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From lachmann at eva.mpg.de  Wed Aug 17 23:27:39 2011
From: lachmann at eva.mpg.de (Michael Lachmann)
Date: Wed, 17 Aug 2011 23:27:39 +0200
Subject: [Rd] An example of very slow computation
In-Reply-To: <87aab82cfy.fsf@tajo.ucsd.edu>
References: <4E4B7B69.6030106@uottawa.ca> <87aab82cfy.fsf@tajo.ucsd.edu>
Message-ID: <1BA7596D-1AC9-44E9-A165-BB7EF17FB045@eva.mpg.de>


On 17 Aug 2011, at 7:08PM, <cberry at tajo.ucsd.edu> <cberry at tajo.ucsd.edu> wrote:

> John C Nash <nashjc at uottawa.ca> writes:
> 
>> This message is about a curious difference in timing between two ways of computing the
>> same function. One uses expm, so is expected to be a bit slower, but "a bit" turned out to
>> be a factor of >1000. 
> 
> Looks like A*t in expm(A*t) is a "matrix".
> 
> 'getMethod("expm","matrix")' coerces it arg to a "Matrix", then calls
> expm(), whose method coerces its arg to a "dMatrix" and calls expm(),
> whose method coerces its arg to a 'dgeMatrix' and calls expm(), whose
> method finally calls '.Call(dgeMatrix_exp, x)' 
> 
> Whew!
> 
> The time difference between 'expm( diag(10)+1 )' and 'expm( as( diag(10)+1,
> "dgeMatrix" ))' is a factor of 10 on my box. 
> 

You are right! 

I was testing running nlogL below 100 times. expm() is then called 2500 times.
The total running time on my machine was 13 seconds.

If you replace in nlogL the part:
--
 A<-rbind(
 c(-k[1], k[2]),
 c( k[1], -(k[2]+k[3]))
 )
 x0<-c(0,100)
 sol<-function(t)100-sum(expm(A*t)%*%x0)
--
with:
--
 A<-rbind(
 c(-k[1], k[2]),
 c( k[1], -(k[2]+k[3]))
 )
 A<-as(A,"dgeMatrix")  # <--- this is the difference
  sol<-function(t)100-sum(expm(A*t)%*%x0)
--

this time drops to 1.5 seconds (!).

At that point, expm() takes up much less time than, for example, calculating A*t in sol(), and the sum() - I think because conversions have to be done.

Thus, if m is a 2x2 dgeMatrix, then 
> system.time({for(i in 1:2500) m*3.2})
   user  system elapsed 
  0.425   0.004   0.579 
(i.e. 1/3 of the total time for nlogL() above)

whereas if mm=as.matrix(m), then
> system.time({for(i in 1:2500) mm*3.2})
   user  system elapsed 
  0.004   0.000   0.005 

(!!)

and, similarly:
--
> system.time({for(i in 1:2500) sum(m)})
   user  system elapsed 
  0.399   0.002   0.494 
> system.time({for(i in 1:2500) sum(mm)})
   user  system elapsed 
  0.002   0.000   0.028 
--
whereas
> system.time({for(i in 1:2500) expm(m)})
   user  system elapsed 
  0.106   0.001   0.118 

to sum it up, of 13 seconds, 11.5 were spent on conversions to dgeMatrix
0.5 are spent on multiplying a dgeMatrix by a double
0.5 are spent on summing a dgeMatrix
and 0.1 are actually spent in expm.

Michael

P.S. You could have used Rprof() to see these times, only that interpreting summaryRprof() is a bit hard. (Is there something that does summaryRprof(), but also shows the call graph?)





> Dunno 'bout the other factor of 100.
> 
> Chuck
> 
> 
> 
> 
>> The problem arose in an activity to develop guidelines for nonlinear
>> modeling in ecology (at NCEAS, Santa Barbara, with worldwide participants), and we will be
>> trying to include suggestions of how to prepare problems like this for efficient and
>> effective solution. The code for nlogL was the "original" from the worker who supplied the
>> problem.
>> 
>> Best,
>> 
>> John Nash
>> 
>> --------------------------------------------------------------------------------------
>> 
>> cat("mineral-timing.R == benchmark MIN functions in R\n")
>> #  J C Nash July 31, 2011
>> 
>> require("microbenchmark")
>> require("numDeriv")
>> library(Matrix)
>> library(optimx)
>> # dat<-read.table('min.dat', skip=3, header=FALSE)
>> # t<-dat[,1]
>> t <- c(0.77,  1.69,  2.69,  3.67,  4.69,  5.71,  7.94,  9.67, 11.77, 17.77,
>> 23.77, 32.77, 40.73, 47.75, 54.90, 62.81, 72.88, 98.77, 125.92, 160.19,
>> 191.15, 223.78, 287.70, 340.01, 340.95, 342.01)
>> 
>> # y<-dat[,2] # ?? tidy up
>> y<- c(1.396, 3.784, 5.948, 7.717, 9.077, 10.100, 11.263, 11.856, 12.251, 12.699,
>> 12.869, 13.048, 13.222, 13.347, 13.507, 13.628, 13.804, 14.087, 14.185, 14.351,
>> 14.458, 14.756, 15.262, 15.703, 15.703, 15.703)
>> 
>> 
>> ones<-rep(1,length(t))
>> theta<-c(-2,-2,-2,-2)
>> 
>> 
>> nlogL<-function(theta){
>>  k<-exp(theta[1:3])
>>  sigma<-exp(theta[4])
>>  A<-rbind(
>>  c(-k[1], k[2]),
>>  c( k[1], -(k[2]+k[3]))
>>  )
>>  x0<-c(0,100)
>>  sol<-function(t)100-sum(expm(A*t)%*%x0)
>>  pred<-sapply(dat[,1],sol)
>>  -sum(dnorm(dat[,2],mean=pred,sd=sigma, log=TRUE))
>> }
>> 
>> getpred<-function(theta, t){
>>  k<-exp(theta[1:3])
>>  sigma<-exp(theta[4])
>>  A<-rbind(
>>  c(-k[1], k[2]),
>>  c( k[1], -(k[2]+k[3]))
>>  )
>>  x0<-c(0,100)
>>  sol<-function(tt)100-sum(expm(A*tt)%*%x0)
>>  pred<-sapply(t,sol)
>> }
>> 
>> Mpred <- function(theta) {
>> # WARNING: assumes t global
>> kvec<-exp(theta[1:3])
>> k1<-kvec[1]
>> k2<-kvec[2]
>> k3<-kvec[3]
>> #   MIN problem terbuthylazene disappearance
>>    z<-k1+k2+k3
>>    y<-z*z-4*k1*k3
>>    l1<-0.5*(-z+sqrt(y))
>>    l2<-0.5*(-z-sqrt(y))
>>    val<-100*(1-((k1+k2+l2)*exp(l2*t)-(k1+k2+l1)*exp(l1*t))/(l2-l1))
>> } # val should be a vector if t is a vector
>> 
>> negll <- function(theta){
>> # non expm version JN 110731
>>  pred<-Mpred(theta)
>>  sigma<-exp(theta[4])
>>  -sum(dnorm(dat[,2],mean=pred,sd=sigma, log=TRUE))
>> }
>> 
>> theta<-rep(-2,4)
>> fand<-nlogL(theta)
>> fsim<-negll(theta)
>> cat("Check fn vals: expm =",fand,"   simple=",fsim,"  diff=",fand-fsim,"\n")
>> 
>> cat("time the function in expm form\n")
>> tnlogL<-microbenchmark(nlogL(theta), times=100L)
>> tnlogL
>> 
>> cat("time the function in simpler form\n")
>> tnegll<-microbenchmark(negll(theta), times=100L)
>> tnegll
>> 
>> ftimes<-data.frame(texpm=tnlogL$time, tsimp=tnegll$time)
>> # ftimes
>> 
>> 
>> boxplot(log(ftimes))
>> title("Log times in nanoseconds for matrix exponential and simple MIN fn")
>> 
> 
> -- 
> Charles C. Berry                         cberry at tajo.ucsd.edu
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> 


From lachmann at eva.mpg.de  Thu Aug 18 00:30:32 2011
From: lachmann at eva.mpg.de (Michael Lachmann)
Date: Thu, 18 Aug 2011 00:30:32 +0200
Subject: [Rd] An example of very slow computation
In-Reply-To: <1BA7596D-1AC9-44E9-A165-BB7EF17FB045@eva.mpg.de>
References: <4E4B7B69.6030106@uottawa.ca> <87aab82cfy.fsf@tajo.ucsd.edu>
	<1BA7596D-1AC9-44E9-A165-BB7EF17FB045@eva.mpg.de>
Message-ID: <6E90EB3D-12F3-4C92-9EB2-A03F839124EA@eva.mpg.de>

Just a small addition:

If you replace below
> sol<-function(t)100-sum(expm(A*t)%*%x0)
by
sol<-function(t){A at x=A at x*t;100-sum(expm(A)@x * x0)}

(ugly! But avoiding the conversions and generics)

The time on my machine drop further down to 0.3 seconds. (from the original 13 seconds, and then from the 1.5 seconds change mentioned below.

So, overall a ~40 fold improvement, though on my machine, the initial ratio was ~3200 times slower, so a ~80 fold slowdown is still present.

Michael

On 17 Aug 2011, at 11:27PM, Michael Lachmann wrote:

> 
> On 17 Aug 2011, at 7:08PM, <cberry at tajo.ucsd.edu> <cberry at tajo.ucsd.edu> wrote:
> 
>> John C Nash <nashjc at uottawa.ca> writes:
>> 
>>> This message is about a curious difference in timing between two ways of computing the
>>> same function. One uses expm, so is expected to be a bit slower, but "a bit" turned out to
>>> be a factor of >1000. 
>> 
>> Looks like A*t in expm(A*t) is a "matrix".
>> 
>> 'getMethod("expm","matrix")' coerces it arg to a "Matrix", then calls
>> expm(), whose method coerces its arg to a "dMatrix" and calls expm(),
>> whose method coerces its arg to a 'dgeMatrix' and calls expm(), whose
>> method finally calls '.Call(dgeMatrix_exp, x)' 
>> 
>> Whew!
>> 
>> The time difference between 'expm( diag(10)+1 )' and 'expm( as( diag(10)+1,
>> "dgeMatrix" ))' is a factor of 10 on my box. 
>> 
> 
> You are right! 
> 
> I was testing running nlogL below 100 times. expm() is then called 2500 times.
> The total running time on my machine was 13 seconds.
> 
> If you replace in nlogL the part:
> --
> A<-rbind(
> c(-k[1], k[2]),
> c( k[1], -(k[2]+k[3]))
> )
> x0<-c(0,100)
> sol<-function(t)100-sum(expm(A*t)%*%x0)
> --
> with:
> --
> A<-rbind(
> c(-k[1], k[2]),
> c( k[1], -(k[2]+k[3]))
> )
> A<-as(A,"dgeMatrix")  # <--- this is the difference
>  sol<-function(t)100-sum(expm(A*t)%*%x0)
> --
> 
> this time drops to 1.5 seconds (!).
> 
> At that point, expm() takes up much less time than, for example, calculating A*t in sol(), and the sum() - I think because conversions have to be done.
> 
> Thus, if m is a 2x2 dgeMatrix, then 
>> system.time({for(i in 1:2500) m*3.2})
>   user  system elapsed 
>  0.425   0.004   0.579 
> (i.e. 1/3 of the total time for nlogL() above)
> 
> whereas if mm=as.matrix(m), then
>> system.time({for(i in 1:2500) mm*3.2})
>   user  system elapsed 
>  0.004   0.000   0.005 
> 
> (!!)
> 
> and, similarly:
> --
>> system.time({for(i in 1:2500) sum(m)})
>   user  system elapsed 
>  0.399   0.002   0.494 
>> system.time({for(i in 1:2500) sum(mm)})
>   user  system elapsed 
>  0.002   0.000   0.028 
> --
> whereas
>> system.time({for(i in 1:2500) expm(m)})
>   user  system elapsed 
>  0.106   0.001   0.118 
> 
> to sum it up, of 13 seconds, 11.5 were spent on conversions to dgeMatrix
> 0.5 are spent on multiplying a dgeMatrix by a double
> 0.5 are spent on summing a dgeMatrix
> and 0.1 are actually spent in expm.
> 
> Michael
> 
> P.S. You could have used Rprof() to see these times, only that interpreting summaryRprof() is a bit hard. (Is there something that does summaryRprof(), but also shows the call graph?)
> 
> 
> 
> 
> 
>> Dunno 'bout the other factor of 100.
>> 
>> Chuck
>> 
>> 
>> 
>> 
>>> The problem arose in an activity to develop guidelines for nonlinear
>>> modeling in ecology (at NCEAS, Santa Barbara, with worldwide participants), and we will be
>>> trying to include suggestions of how to prepare problems like this for efficient and
>>> effective solution. The code for nlogL was the "original" from the worker who supplied the
>>> problem.
>>> 
>>> Best,
>>> 
>>> John Nash
>>> 
>>> --------------------------------------------------------------------------------------
>>> 
>>> cat("mineral-timing.R == benchmark MIN functions in R\n")
>>> #  J C Nash July 31, 2011
>>> 
>>> require("microbenchmark")
>>> require("numDeriv")
>>> library(Matrix)
>>> library(optimx)
>>> # dat<-read.table('min.dat', skip=3, header=FALSE)
>>> # t<-dat[,1]
>>> t <- c(0.77,  1.69,  2.69,  3.67,  4.69,  5.71,  7.94,  9.67, 11.77, 17.77,
>>> 23.77, 32.77, 40.73, 47.75, 54.90, 62.81, 72.88, 98.77, 125.92, 160.19,
>>> 191.15, 223.78, 287.70, 340.01, 340.95, 342.01)
>>> 
>>> # y<-dat[,2] # ?? tidy up
>>> y<- c(1.396, 3.784, 5.948, 7.717, 9.077, 10.100, 11.263, 11.856, 12.251, 12.699,
>>> 12.869, 13.048, 13.222, 13.347, 13.507, 13.628, 13.804, 14.087, 14.185, 14.351,
>>> 14.458, 14.756, 15.262, 15.703, 15.703, 15.703)
>>> 
>>> 
>>> ones<-rep(1,length(t))
>>> theta<-c(-2,-2,-2,-2)
>>> 
>>> 
>>> nlogL<-function(theta){
>>> k<-exp(theta[1:3])
>>> sigma<-exp(theta[4])
>>> A<-rbind(
>>> c(-k[1], k[2]),
>>> c( k[1], -(k[2]+k[3]))
>>> )
>>> x0<-c(0,100)
>>> sol<-function(t)100-sum(expm(A*t)%*%x0)
>>> pred<-sapply(dat[,1],sol)
>>> -sum(dnorm(dat[,2],mean=pred,sd=sigma, log=TRUE))
>>> }
>>> 
>>> getpred<-function(theta, t){
>>> k<-exp(theta[1:3])
>>> sigma<-exp(theta[4])
>>> A<-rbind(
>>> c(-k[1], k[2]),
>>> c( k[1], -(k[2]+k[3]))
>>> )
>>> x0<-c(0,100)
>>> sol<-function(tt)100-sum(expm(A*tt)%*%x0)
>>> pred<-sapply(t,sol)
>>> }
>>> 
>>> Mpred <- function(theta) {
>>> # WARNING: assumes t global
>>> kvec<-exp(theta[1:3])
>>> k1<-kvec[1]
>>> k2<-kvec[2]
>>> k3<-kvec[3]
>>> #   MIN problem terbuthylazene disappearance
>>>   z<-k1+k2+k3
>>>   y<-z*z-4*k1*k3
>>>   l1<-0.5*(-z+sqrt(y))
>>>   l2<-0.5*(-z-sqrt(y))
>>>   val<-100*(1-((k1+k2+l2)*exp(l2*t)-(k1+k2+l1)*exp(l1*t))/(l2-l1))
>>> } # val should be a vector if t is a vector
>>> 
>>> negll <- function(theta){
>>> # non expm version JN 110731
>>> pred<-Mpred(theta)
>>> sigma<-exp(theta[4])
>>> -sum(dnorm(dat[,2],mean=pred,sd=sigma, log=TRUE))
>>> }
>>> 
>>> theta<-rep(-2,4)
>>> fand<-nlogL(theta)
>>> fsim<-negll(theta)
>>> cat("Check fn vals: expm =",fand,"   simple=",fsim,"  diff=",fand-fsim,"\n")
>>> 
>>> cat("time the function in expm form\n")
>>> tnlogL<-microbenchmark(nlogL(theta), times=100L)
>>> tnlogL
>>> 
>>> cat("time the function in simpler form\n")
>>> tnegll<-microbenchmark(negll(theta), times=100L)
>>> tnegll
>>> 
>>> ftimes<-data.frame(texpm=tnlogL$time, tsimp=tnegll$time)
>>> # ftimes
>>> 
>>> 
>>> boxplot(log(ftimes))
>>> title("Log times in nanoseconds for matrix exponential and simple MIN fn")
>>> 
>> 
>> -- 
>> Charles C. Berry                         cberry at tajo.ucsd.edu
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> 
>> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> 


From radler12 at op.pl  Thu Aug 18 11:09:59 2011
From: radler12 at op.pl (Krystian Radlak)
Date: Thu, 18 Aug 2011 02:09:59 -0700 (PDT)
Subject: [Rd] Use logical expresion on ff object
Message-ID: <1313658599381-3752127.post@n4.nabble.com>

I want to do operation with ff vector from packages ff like simple operation
in R like this. (I have read data from file)
Example 
a=1:10
b=a[a>5]

how to do this operation with ff packages:
Example :
a=ff(1, length=15*10^7)

I know that I could get logical vector like this:

k=bit(15*10^7) # from bit packages
a=ff(-1,15*10^7)
system.time(
		for (i in chunk(a)){ k[i]<- a[i]<1}
)

Any suggestions?

Best,
Krystian



--
View this message in context: http://r.789695.n4.nabble.com/Use-logical-expresion-on-ff-object-tp3752127p3752127.html
Sent from the R devel mailing list archive at Nabble.com.


From lukasz.reclawowicz at gmail.com  Thu Aug 18 13:14:42 2011
From: lukasz.reclawowicz at gmail.com (=?ISO-8859-2?B?o3VrYXN6IFLqY7Nhd293aWN6?=)
Date: Thu, 18 Aug 2011 13:14:42 +0200
Subject: [Rd] Use logical expresion on ff object
In-Reply-To: <1313658599381-3752127.post@n4.nabble.com>
References: <1313658599381-3752127.post@n4.nabble.com>
Message-ID: <CAE2rZEkqJHPv2Totn-1O0HSbO=g_JY-b731VKhrz7bTBpL0VfQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110818/2838bd7d/attachment.pl>

From radler12 at op.pl  Thu Aug 18 15:57:17 2011
From: radler12 at op.pl (Krystian Radlak)
Date: Thu, 18 Aug 2011 06:57:17 -0700 (PDT)
Subject: [Rd] Use logical expresion on ff object
In-Reply-To: <CAE2rZEkqJHPv2Totn-1O0HSbO=g_JY-b731VKhrz7bTBpL0VfQ@mail.gmail.com>
References: <1313658599381-3752127.post@n4.nabble.com>
	<CAE2rZEkqJHPv2Totn-1O0HSbO=g_JY-b731VKhrz7bTBpL0VfQ@mail.gmail.com>
Message-ID: <1313675837352-3752673.post@n4.nabble.com>

Yes, it's necessery. Operator < is not definied in ff packages.

str(a<1)
 logi(0)

Mayby it's possible to do the same thing easier...

--
View this message in context: http://r.789695.n4.nabble.com/Use-logical-expresion-on-ff-object-tp3752127p3752673.html
Sent from the R devel mailing list archive at Nabble.com.


From lukasz.reclawowicz at gmail.com  Thu Aug 18 16:26:23 2011
From: lukasz.reclawowicz at gmail.com (=?ISO-8859-2?B?o3VrYXN6IFLqY7Nhd293aWN6?=)
Date: Thu, 18 Aug 2011 16:26:23 +0200
Subject: [Rd] Use logical expresion on ff object
In-Reply-To: <1313675837352-3752673.post@n4.nabble.com>
References: <1313658599381-3752127.post@n4.nabble.com>
	<CAE2rZEkqJHPv2Totn-1O0HSbO=g_JY-b731VKhrz7bTBpL0VfQ@mail.gmail.com>
	<1313675837352-3752673.post@n4.nabble.com>
Message-ID: <CAE2rZEnmDH=V_SjkyUSmgr_3bANSx=UFTUDaQtqpJyCBEELo7w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110818/b815ac04/attachment.pl>

From jorismeys at gmail.com  Thu Aug 18 17:53:42 2011
From: jorismeys at gmail.com (Joris Meys)
Date: Thu, 18 Aug 2011 17:53:42 +0200
Subject: [Rd] problems with connections when applied in tryCatch
Message-ID: <CAO1zAVaQ=uZnp0YZpintN-1XeC+qE3Mqg596fPphnUrVM9FLjg@mail.gmail.com>

Recently on stackoverflow following problem came up :

http://stackoverflow.com/questions/7103429/all-the-connections-are-in-use-execution-halted/7108799#7108799

A reproducible example: When trying

replicate(200,tryCatch(read.table("this.is.no.file"),
          warning=function(w){print(showConnections());print("warning")}))

No connections are shown, but after a number of calls, suddenly the message

Error in file(file, "rt") : all connections are in use

pops up. Trying to get them deleted with closeAllConnections() causes
R to crash on Windows 7. Another user reported a segfault. (see the
link to stackoverflow)

Although I initially thought on.exit() was somehow skipped, that's not
the case. In fact, the connection couldn't be opened, so it can't be
closed either. I have no clue as to why this goes wrong, but it shows
there's something odd happening with the connections. For the record,
I am aware that the use of the warning handler in that call is rather
peculiar. But even then, R shouldn't crash.

Cheers
Joris


-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Applied mathematics, biometrics and process control

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From lukasz.reclawowicz at gmail.com  Thu Aug 18 18:07:51 2011
From: lukasz.reclawowicz at gmail.com (=?ISO-8859-2?B?o3VrYXN6IFLqY7Nhd293aWN6?=)
Date: Thu, 18 Aug 2011 18:07:51 +0200
Subject: [Rd] Use logical expresion on ff object
In-Reply-To: <CAE2rZEnmDH=V_SjkyUSmgr_3bANSx=UFTUDaQtqpJyCBEELo7w@mail.gmail.com>
References: <1313658599381-3752127.post@n4.nabble.com>
	<CAE2rZEkqJHPv2Totn-1O0HSbO=g_JY-b731VKhrz7bTBpL0VfQ@mail.gmail.com>
	<1313675837352-3752673.post@n4.nabble.com>
	<CAE2rZEnmDH=V_SjkyUSmgr_3bANSx=UFTUDaQtqpJyCBEELo7w@mail.gmail.com>
Message-ID: <CAE2rZEm+1ZehoFrCSvwWCiiO0Qhy3WTegJn2gkkN+2OgEr-YXw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110818/a8d3ca50/attachment.pl>

From lukasz.reclawowicz at gmail.com  Thu Aug 18 18:42:52 2011
From: lukasz.reclawowicz at gmail.com (=?ISO-8859-2?B?o3VrYXN6IFLqY7Nhd293aWN6?=)
Date: Thu, 18 Aug 2011 18:42:52 +0200
Subject: [Rd] Use logical expresion on ff object
In-Reply-To: <1313675837352-3752673.post@n4.nabble.com>
References: <1313658599381-3752127.post@n4.nabble.com>
	<CAE2rZEkqJHPv2Totn-1O0HSbO=g_JY-b731VKhrz7bTBpL0VfQ@mail.gmail.com>
	<1313675837352-3752673.post@n4.nabble.com>
Message-ID: <CAE2rZE=yzAvsMF9_HRYMSULQXYEG3Lm-cXf0CBpqPQWxc51hKA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110818/66f0a92f/attachment.pl>

From janko.thyson.rstuff at googlemail.com  Thu Aug 18 19:31:02 2011
From: janko.thyson.rstuff at googlemail.com (Janko Thyson)
Date: Thu, 18 Aug 2011 19:31:02 +0200
Subject: [Rd] Bug: argument 'lib.loc' not passed on appropriately in
	'library()'?
Message-ID: <4E4D4C56.7070100@googlemail.com>

Dear list,

I'm experimenting with setting up custom 'lib' and 'destdir' directories 
for my R packages. It seems to me that 'library()' does handle a custom 
'lib.loc' argument the way it should for an arbitrary package but NOT 
for its dependencies on other packages. The latter are looked for in the 
default lib path (~/R/R-2.x.x/library) and NOT in the custom lib path.

Below is a little code example illustrating the error I'm getting. It'd 
be great if someone could validate this.

Thanks a lot for any comments,
Janko

### CODE EXAMPLE ###

# Package that I'm sure of that it's not already installed and has 
dependencies
pkg <- "rworldmap"

# Making sure that dependencies are not available in the default library
remove.packages("sp")
remove.packages("maptools")
remove.packages("foreign")
remove.packages("lattice")

# Setting custom lib and destdir
path.r.lib <- "C:/temp/R/library"
dir.create(path.r.lib, recursive=TRUE, showWarning=FALSE)
path.r.destdir <- "C:/temp/R/destdir"
dir.create(path.r.destdir, recursive=TRUE, showWarning=FALSE)

# Core processing
try.res <- try(
     eval(substitute(
         library(PKG, lib.loc=path.r.lib, verbose=FALSE),
         list(PKG=pkg)
     )),
     silent=TRUE
)
if(inherits(try.res, "try-error")){
     msg <- c(
         paste("Required package '", pkg, "' not available locally", 
sep=""),
         paste("Looking for package '", pkg, "' in remote repository", 
sep="")
     )
     cat(msg, sep="\n")
     install.packages(
         pkg,
         repos=getOption("repos"),
         lib=path.r.lib,
         destdir=path.r.destdir,
         dependencies="Depends"
     )
     eval(substitute(
         library(PKG, lib.loc=path.r.lib, verbose=FALSE),
         list(PKG=pkg)
     ))
# Here's where the error occurs. Seems to me that 'lib.loc' is not really
# passed on appropriately within 'library()', but instead the default 
lib path
# is used to look for dependencies.
}


From janko.thyson.rstuff at googlemail.com  Thu Aug 18 20:20:19 2011
From: janko.thyson.rstuff at googlemail.com (Janko Thyson)
Date: Thu, 18 Aug 2011 20:20:19 +0200
Subject: [Rd] Fwd: Bug: argument 'lib.loc' not passed on appropriately in
	'library()'?
In-Reply-To: <4E4D4C56.7070100@googlemail.com>
References: <4E4D4C56.7070100@googlemail.com>
Message-ID: <4E4D57E3.8070800@googlemail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110818/dfbec5b0/attachment.pl>

From pdalgd at gmail.com  Fri Aug 19 00:37:38 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 19 Aug 2011 00:37:38 +0200
Subject: [Rd] An example of very slow computation
In-Reply-To: <2F9EA67EF9AE1C48A147CB41BE2E15C3059E9C@DOM-EB-MAIL2.win.ad.jhu.edu>
References: <4E4B7B69.6030106@uottawa.ca> <87aab82cfy.fsf@tajo.ucsd.edu>
	<2F9EA67EF9AE1C48A147CB41BE2E15C3059E2B@DOM-EB-MAIL2.win.ad.jhu.edu>
	<2F9EA67EF9AE1C48A147CB41BE2E15C3059E9C@DOM-EB-MAIL2.win.ad.jhu.edu>
Message-ID: <6872DD31-1949-44D3-8D02-283ED822D3BA@gmail.com>


On Aug 17, 2011, at 23:24 , Ravi Varadhan wrote:

> A principled way to solve this system of ODEs is to use the idea of "fundamental matrix", which is the same idea as that of diagonalization of a matrix (see Boyce and DiPrima or any ODE text).
> 
> Here is the code for that:
> 
> 
> nlogL2 <- function(theta){
>  k <- exp(theta[1:3])
>  sigma <- exp(theta[4])
>  A <- rbind(
>  c(-k[1], k[2]),
>  c( k[1], -(k[2]+k[3]))
>  )
> 	eA <- eigen(A)
> 	T <- eA$vectors
> 	r <- eA$values
> 	x0 <- c(0,100)
> 	Tx0 <- T %*% x0
> 
> 	sol <- function(t) 100 - sum(T %*% diag(exp(r*t)) %*% Tx0)
> 	pred <- sapply(dat[,1], sol)
>  	-sum(dnorm(dat[,2], mean=pred, sd=sigma, log=TRUE)) 
> }
> This is much faster than using expm(A*t), but much slower than "by hand" calculations since we have to repeatedly do the diagonalization.  An obvious advantage of this fuunction is that it applies to *any* linear system of ODEs for which the eigenvalues are real (and negative).

I believe this is method 14 of the "19 dubious ways..." (Google for it) and doesn't work for certain non-symmetric A matrices. 

> 
> Ravi.
> 
> -------------------------------------------------------
> Ravi Varadhan, Ph.D.
> Assistant Professor,
> Division of Geriatric Medicine and Gerontology School of Medicine Johns Hopkins University
> 
> Ph. (410) 502-2619
> email: rvaradhan at jhmi.edu
> 
> 
> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of Ravi Varadhan
> Sent: Wednesday, August 17, 2011 2:33 PM
> To: 'cberry at tajo.ucsd.edu'; r-devel at stat.math.ethz.ch; 'nashjc at uottawa.ca'
> Subject: Re: [Rd] An example of very slow computation
> 
> Yes, the culprit is the evaluation of expm(A*t).  This is a lazy way of solving the system of ODEs, where you save analytic effort, but you pay for it dearly in terms of computational effort!
> 
> Even in this lazy approach, I am sure there ought to be faster ways to evaluating exponent of a matrix than that in "Matrix" package.
> 
> Ravi.
> 
> -------------------------------------------------------
> Ravi Varadhan, Ph.D.
> Assistant Professor,
> Division of Geriatric Medicine and Gerontology School of Medicine Johns Hopkins University
> 
> Ph. (410) 502-2619
> email: rvaradhan at jhmi.edu
> 
> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of cberry at tajo.ucsd.edu
> Sent: Wednesday, August 17, 2011 1:08 PM
> To: r-devel at stat.math.ethz.ch
> Subject: Re: [Rd] An example of very slow computation
> 
> John C Nash <nashjc at uottawa.ca> writes:
> 
>> This message is about a curious difference in timing between two ways of computing the
>> same function. One uses expm, so is expected to be a bit slower, but "a bit" turned out to
>> be a factor of >1000. The code is below. We would be grateful if anyone can point out any
>> egregious bad practice in our code, or enlighten us on why one approach is so much slower
>> than the other. 
> 
> Looks like A*t in expm(A*t) is a "matrix".
> 
> 'getMethod("expm","matrix")' coerces it arg to a "Matrix", then calls
> expm(), whose method coerces its arg to a "dMatrix" and calls expm(),
> whose method coerces its arg to a 'dgeMatrix' and calls expm(), whose
> method finally calls '.Call(dgeMatrix_exp, x)' 
> 
> Whew!
> 
> The time difference between 'expm( diag(10)+1 )' and 'expm( as( diag(10)+1,
> "dgeMatrix" ))' is a factor of 10 on my box. 
> 
> Dunno 'bout the other factor of 100.
> 
> Chuck
> 
> 
> 
> 
>> The problem arose in an activity to develop guidelines for nonlinear
>> modeling in ecology (at NCEAS, Santa Barbara, with worldwide participants), and we will be
>> trying to include suggestions of how to prepare problems like this for efficient and
>> effective solution. The code for nlogL was the "original" from the worker who supplied the
>> problem.
>> 
>> Best,
>> 
>> John Nash
>> 
>> --------------------------------------------------------------------------------------
>> 
>> cat("mineral-timing.R == benchmark MIN functions in R\n")
>> #  J C Nash July 31, 2011
>> 
>> require("microbenchmark")
>> require("numDeriv")
>> library(Matrix)
>> library(optimx)
>> # dat<-read.table('min.dat', skip=3, header=FALSE)
>> # t<-dat[,1]
>> t <- c(0.77,  1.69,  2.69,  3.67,  4.69,  5.71,  7.94,  9.67, 11.77, 17.77,
>> 23.77, 32.77, 40.73, 47.75, 54.90, 62.81, 72.88, 98.77, 125.92, 160.19,
>> 191.15, 223.78, 287.70, 340.01, 340.95, 342.01)
>> 
>> # y<-dat[,2] # ?? tidy up
>> y<- c(1.396, 3.784, 5.948, 7.717, 9.077, 10.100, 11.263, 11.856, 12.251, 12.699,
>> 12.869, 13.048, 13.222, 13.347, 13.507, 13.628, 13.804, 14.087, 14.185, 14.351,
>> 14.458, 14.756, 15.262, 15.703, 15.703, 15.703)
>> 
>> 
>> ones<-rep(1,length(t))
>> theta<-c(-2,-2,-2,-2)
>> 
>> 
>> nlogL<-function(theta){
>>  k<-exp(theta[1:3])
>>  sigma<-exp(theta[4])
>>  A<-rbind(
>>  c(-k[1], k[2]),
>>  c( k[1], -(k[2]+k[3]))
>>  )
>>  x0<-c(0,100)
>>  sol<-function(t)100-sum(expm(A*t)%*%x0)
>>  pred<-sapply(dat[,1],sol)
>>  -sum(dnorm(dat[,2],mean=pred,sd=sigma, log=TRUE))
>> }
>> 
>> getpred<-function(theta, t){
>>  k<-exp(theta[1:3])
>>  sigma<-exp(theta[4])
>>  A<-rbind(
>>  c(-k[1], k[2]),
>>  c( k[1], -(k[2]+k[3]))
>>  )
>>  x0<-c(0,100)
>>  sol<-function(tt)100-sum(expm(A*tt)%*%x0)
>>  pred<-sapply(t,sol)
>> }
>> 
>> Mpred <- function(theta) {
>> # WARNING: assumes t global
>> kvec<-exp(theta[1:3])
>> k1<-kvec[1]
>> k2<-kvec[2]
>> k3<-kvec[3]
>> #   MIN problem terbuthylazene disappearance
>>    z<-k1+k2+k3
>>    y<-z*z-4*k1*k3
>>    l1<-0.5*(-z+sqrt(y))
>>    l2<-0.5*(-z-sqrt(y))
>>    val<-100*(1-((k1+k2+l2)*exp(l2*t)-(k1+k2+l1)*exp(l1*t))/(l2-l1))
>> } # val should be a vector if t is a vector
>> 
>> negll <- function(theta){
>> # non expm version JN 110731
>>  pred<-Mpred(theta)
>>  sigma<-exp(theta[4])
>>  -sum(dnorm(dat[,2],mean=pred,sd=sigma, log=TRUE))
>> }
>> 
>> theta<-rep(-2,4)
>> fand<-nlogL(theta)
>> fsim<-negll(theta)
>> cat("Check fn vals: expm =",fand,"   simple=",fsim,"  diff=",fand-fsim,"\n")
>> 
>> cat("time the function in expm form\n")
>> tnlogL<-microbenchmark(nlogL(theta), times=100L)
>> tnlogL
>> 
>> cat("time the function in simpler form\n")
>> tnegll<-microbenchmark(negll(theta), times=100L)
>> tnegll
>> 
>> ftimes<-data.frame(texpm=tnlogL$time, tsimp=tnegll$time)
>> # ftimes
>> 
>> 
>> boxplot(log(ftimes))
>> title("Log times in nanoseconds for matrix exponential and simple MIN fn")
>> 
> 
> -- 
> Charles C. Berry                         cberry at tajo.ucsd.edu
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
"D?den skal tape!" --- Nordahl Grieg


From rvaradhan at jhmi.edu  Fri Aug 19 01:32:39 2011
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Thu, 18 Aug 2011 23:32:39 +0000
Subject: [Rd] An example of very slow computation
In-Reply-To: <6872DD31-1949-44D3-8D02-283ED822D3BA@gmail.com>
References: <4E4B7B69.6030106@uottawa.ca> <87aab82cfy.fsf@tajo.ucsd.edu>
	<2F9EA67EF9AE1C48A147CB41BE2E15C3059E2B@DOM-EB-MAIL2.win.ad.jhu.edu>
	<2F9EA67EF9AE1C48A147CB41BE2E15C3059E9C@DOM-EB-MAIL2.win.ad.jhu.edu>,
	<6872DD31-1949-44D3-8D02-283ED822D3BA@gmail.com>
Message-ID: <2F9EA67EF9AE1C48A147CB41BE2E15C305A17D@DOM-EB-MAIL2.win.ad.jhu.edu>

Which is why I said it applies when the system is "diagonalizable".  It won't work for non-diagonalizable matrix A, because T (eigenvector matrix) is singular.

Ravi.
________________________________________
From: peter dalgaard [pdalgd at gmail.com]
Sent: Thursday, August 18, 2011 6:37 PM
To: Ravi Varadhan
Cc: 'cberry at tajo.ucsd.edu'; r-devel at stat.math.ethz.ch; 'nashjc at uottawa.ca'
Subject: Re: [Rd] An example of very slow computation

On Aug 17, 2011, at 23:24 , Ravi Varadhan wrote:

> A principled way to solve this system of ODEs is to use the idea of "fundamental matrix", which is the same idea as that of diagonalization of a matrix (see Boyce and DiPrima or any ODE text).
>
> Here is the code for that:
>
>
> nlogL2 <- function(theta){
>  k <- exp(theta[1:3])
>  sigma <- exp(theta[4])
>  A <- rbind(
>  c(-k[1], k[2]),
>  c( k[1], -(k[2]+k[3]))
>  )
>       eA <- eigen(A)
>       T <- eA$vectors
>       r <- eA$values
>       x0 <- c(0,100)
>       Tx0 <- T %*% x0
>
>       sol <- function(t) 100 - sum(T %*% diag(exp(r*t)) %*% Tx0)
>       pred <- sapply(dat[,1], sol)
>       -sum(dnorm(dat[,2], mean=pred, sd=sigma, log=TRUE))
> }
> This is much faster than using expm(A*t), but much slower than "by hand" calculations since we have to repeatedly do the diagonalization.  An obvious advantage of this fuunction is that it applies to *any* linear system of ODEs for which the eigenvalues are real (and negative).

I believe this is method 14 of the "19 dubious ways..." (Google for it) and doesn't work for certain non-symmetric A matrices.

>
> Ravi.
>
> -------------------------------------------------------
> Ravi Varadhan, Ph.D.
> Assistant Professor,
> Division of Geriatric Medicine and Gerontology School of Medicine Johns Hopkins University
>
> Ph. (410) 502-2619
> email: rvaradhan at jhmi.edu
>
>
> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of Ravi Varadhan
> Sent: Wednesday, August 17, 2011 2:33 PM
> To: 'cberry at tajo.ucsd.edu'; r-devel at stat.math.ethz.ch; 'nashjc at uottawa.ca'
> Subject: Re: [Rd] An example of very slow computation
>
> Yes, the culprit is the evaluation of expm(A*t).  This is a lazy way of solving the system of ODEs, where you save analytic effort, but you pay for it dearly in terms of computational effort!
>
> Even in this lazy approach, I am sure there ought to be faster ways to evaluating exponent of a matrix than that in "Matrix" package.
>
> Ravi.
>
> -------------------------------------------------------
> Ravi Varadhan, Ph.D.
> Assistant Professor,
> Division of Geriatric Medicine and Gerontology School of Medicine Johns Hopkins University
>
> Ph. (410) 502-2619
> email: rvaradhan at jhmi.edu
>
> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of cberry at tajo.ucsd.edu
> Sent: Wednesday, August 17, 2011 1:08 PM
> To: r-devel at stat.math.ethz.ch
> Subject: Re: [Rd] An example of very slow computation
>
> John C Nash <nashjc at uottawa.ca> writes:
>
>> This message is about a curious difference in timing between two ways of computing the
>> same function. One uses expm, so is expected to be a bit slower, but "a bit" turned out to
>> be a factor of >1000. The code is below. We would be grateful if anyone can point out any
>> egregious bad practice in our code, or enlighten us on why one approach is so much slower
>> than the other.
>
> Looks like A*t in expm(A*t) is a "matrix".
>
> 'getMethod("expm","matrix")' coerces it arg to a "Matrix", then calls
> expm(), whose method coerces its arg to a "dMatrix" and calls expm(),
> whose method coerces its arg to a 'dgeMatrix' and calls expm(), whose
> method finally calls '.Call(dgeMatrix_exp, x)'
>
> Whew!
>
> The time difference between 'expm( diag(10)+1 )' and 'expm( as( diag(10)+1,
> "dgeMatrix" ))' is a factor of 10 on my box.
>
> Dunno 'bout the other factor of 100.
>
> Chuck
>
>
>
>
>> The problem arose in an activity to develop guidelines for nonlinear
>> modeling in ecology (at NCEAS, Santa Barbara, with worldwide participants), and we will be
>> trying to include suggestions of how to prepare problems like this for efficient and
>> effective solution. The code for nlogL was the "original" from the worker who supplied the
>> problem.
>>
>> Best,
>>
>> John Nash
>>
>> --------------------------------------------------------------------------------------
>>
>> cat("mineral-timing.R == benchmark MIN functions in R\n")
>> #  J C Nash July 31, 2011
>>
>> require("microbenchmark")
>> require("numDeriv")
>> library(Matrix)
>> library(optimx)
>> # dat<-read.table('min.dat', skip=3, header=FALSE)
>> # t<-dat[,1]
>> t <- c(0.77,  1.69,  2.69,  3.67,  4.69,  5.71,  7.94,  9.67, 11.77, 17.77,
>> 23.77, 32.77, 40.73, 47.75, 54.90, 62.81, 72.88, 98.77, 125.92, 160.19,
>> 191.15, 223.78, 287.70, 340.01, 340.95, 342.01)
>>
>> # y<-dat[,2] # ?? tidy up
>> y<- c(1.396, 3.784, 5.948, 7.717, 9.077, 10.100, 11.263, 11.856, 12.251, 12.699,
>> 12.869, 13.048, 13.222, 13.347, 13.507, 13.628, 13.804, 14.087, 14.185, 14.351,
>> 14.458, 14.756, 15.262, 15.703, 15.703, 15.703)
>>
>>
>> ones<-rep(1,length(t))
>> theta<-c(-2,-2,-2,-2)
>>
>>
>> nlogL<-function(theta){
>>  k<-exp(theta[1:3])
>>  sigma<-exp(theta[4])
>>  A<-rbind(
>>  c(-k[1], k[2]),
>>  c( k[1], -(k[2]+k[3]))
>>  )
>>  x0<-c(0,100)
>>  sol<-function(t)100-sum(expm(A*t)%*%x0)
>>  pred<-sapply(dat[,1],sol)
>>  -sum(dnorm(dat[,2],mean=pred,sd=sigma, log=TRUE))
>> }
>>
>> getpred<-function(theta, t){
>>  k<-exp(theta[1:3])
>>  sigma<-exp(theta[4])
>>  A<-rbind(
>>  c(-k[1], k[2]),
>>  c( k[1], -(k[2]+k[3]))
>>  )
>>  x0<-c(0,100)
>>  sol<-function(tt)100-sum(expm(A*tt)%*%x0)
>>  pred<-sapply(t,sol)
>> }
>>
>> Mpred <- function(theta) {
>> # WARNING: assumes t global
>> kvec<-exp(theta[1:3])
>> k1<-kvec[1]
>> k2<-kvec[2]
>> k3<-kvec[3]
>> #   MIN problem terbuthylazene disappearance
>>    z<-k1+k2+k3
>>    y<-z*z-4*k1*k3
>>    l1<-0.5*(-z+sqrt(y))
>>    l2<-0.5*(-z-sqrt(y))
>>    val<-100*(1-((k1+k2+l2)*exp(l2*t)-(k1+k2+l1)*exp(l1*t))/(l2-l1))
>> } # val should be a vector if t is a vector
>>
>> negll <- function(theta){
>> # non expm version JN 110731
>>  pred<-Mpred(theta)
>>  sigma<-exp(theta[4])
>>  -sum(dnorm(dat[,2],mean=pred,sd=sigma, log=TRUE))
>> }
>>
>> theta<-rep(-2,4)
>> fand<-nlogL(theta)
>> fsim<-negll(theta)
>> cat("Check fn vals: expm =",fand,"   simple=",fsim,"  diff=",fand-fsim,"\n")
>>
>> cat("time the function in expm form\n")
>> tnlogL<-microbenchmark(nlogL(theta), times=100L)
>> tnlogL
>>
>> cat("time the function in simpler form\n")
>> tnegll<-microbenchmark(negll(theta), times=100L)
>> tnegll
>>
>> ftimes<-data.frame(texpm=tnlogL$time, tsimp=tnegll$time)
>> # ftimes
>>
>>
>> boxplot(log(ftimes))
>> title("Log times in nanoseconds for matrix exponential and simple MIN fn")
>>
>
> --
> Charles C. Berry                         cberry at tajo.ucsd.edu
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

--
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
"D?den skal tape!" --- Nordahl Grieg









From lachmann at eva.mpg.de  Fri Aug 19 02:08:48 2011
From: lachmann at eva.mpg.de (Michael Lachmann)
Date: Fri, 19 Aug 2011 02:08:48 +0200
Subject: [Rd] An example of very slow computation
In-Reply-To: <2F9EA67EF9AE1C48A147CB41BE2E15C305A17D@DOM-EB-MAIL2.win.ad.jhu.edu>
References: <4E4B7B69.6030106@uottawa.ca> <87aab82cfy.fsf@tajo.ucsd.edu>
	<2F9EA67EF9AE1C48A147CB41BE2E15C3059E2B@DOM-EB-MAIL2.win.ad.jhu.edu>
	<2F9EA67EF9AE1C48A147CB41BE2E15C3059E9C@DOM-EB-MAIL2.win.ad.jhu.edu>,
	<6872DD31-1949-44D3-8D02-283ED822D3BA@gmail.com>
	<2F9EA67EF9AE1C48A147CB41BE2E15C305A17D@DOM-EB-MAIL2.win.ad.jhu.edu>
Message-ID: <BEF2E70E-5AEF-47CF-8ABE-B393E9793D3F@eva.mpg.de>

On my trials, after eliminating all the extra matrix<->dgeMatrix conversions, 
using expm() and the method below were equally fast.

Michael


On 19 Aug 2011, at 1:32AM, Ravi Varadhan wrote:

> Which is why I said it applies when the system is "diagonalizable".  It won't work for non-diagonalizable matrix A, because T (eigenvector matrix) is singular.
> 
> Ravi.
> ________________________________________
> From: peter dalgaard [pdalgd at gmail.com]
> Sent: Thursday, August 18, 2011 6:37 PM
> To: Ravi Varadhan
> Cc: 'cberry at tajo.ucsd.edu'; r-devel at stat.math.ethz.ch; 'nashjc at uottawa.ca'
> Subject: Re: [Rd] An example of very slow computation
> 
> On Aug 17, 2011, at 23:24 , Ravi Varadhan wrote:
> 
>> A principled way to solve this system of ODEs is to use the idea of "fundamental matrix", which is the same idea as that of diagonalization of a matrix (see Boyce and DiPrima or any ODE text).
>> 
>> Here is the code for that:
>> 
>> 
>> nlogL2 <- function(theta){
>> k <- exp(theta[1:3])
>> sigma <- exp(theta[4])
>> A <- rbind(
>> c(-k[1], k[2]),
>> c( k[1], -(k[2]+k[3]))
>> )
>>      eA <- eigen(A)
>>      T <- eA$vectors
>>      r <- eA$values
>>      x0 <- c(0,100)
>>      Tx0 <- T %*% x0
>> 
>>      sol <- function(t) 100 - sum(T %*% diag(exp(r*t)) %*% Tx0)
>>      pred <- sapply(dat[,1], sol)
>>      -sum(dnorm(dat[,2], mean=pred, sd=sigma, log=TRUE))
>> }
>> This is much faster than using expm(A*t), but much slower than "by hand" calculations since we have to repeatedly do the diagonalization.  An obvious advantage of this fuunction is that it applies to *any* linear system of ODEs for which the eigenvalues are real (and negative).
> 
> I believe this is method 14 of the "19 dubious ways..." (Google for it) and doesn't work for certain non-symmetric A matrices.
> 
>> 
>> Ravi.
>> 
>> -------------------------------------------------------
>> Ravi Varadhan, Ph.D.
>> Assistant Professor,
>> Division of Geriatric Medicine and Gerontology School of Medicine Johns Hopkins University
>> 
>> Ph. (410) 502-2619
>> email: rvaradhan at jhmi.edu
>> 
>> 
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of Ravi Varadhan
>> Sent: Wednesday, August 17, 2011 2:33 PM
>> To: 'cberry at tajo.ucsd.edu'; r-devel at stat.math.ethz.ch; 'nashjc at uottawa.ca'
>> Subject: Re: [Rd] An example of very slow computation
>> 
>> Yes, the culprit is the evaluation of expm(A*t).  This is a lazy way of solving the system of ODEs, where you save analytic effort, but you pay for it dearly in terms of computational effort!
>> 
>> Even in this lazy approach, I am sure there ought to be faster ways to evaluating exponent of a matrix than that in "Matrix" package.
>> 
>> Ravi.
>> 
>> -------------------------------------------------------
>> Ravi Varadhan, Ph.D.
>> Assistant Professor,
>> Division of Geriatric Medicine and Gerontology School of Medicine Johns Hopkins University
>> 
>> Ph. (410) 502-2619
>> email: rvaradhan at jhmi.edu
>> 
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of cberry at tajo.ucsd.edu
>> Sent: Wednesday, August 17, 2011 1:08 PM
>> To: r-devel at stat.math.ethz.ch
>> Subject: Re: [Rd] An example of very slow computation
>> 
>> John C Nash <nashjc at uottawa.ca> writes:
>> 
>>> This message is about a curious difference in timing between two ways of computing the
>>> same function. One uses expm, so is expected to be a bit slower, but "a bit" turned out to
>>> be a factor of >1000. The code is below. We would be grateful if anyone can point out any
>>> egregious bad practice in our code, or enlighten us on why one approach is so much slower
>>> than the other.
>> 
>> Looks like A*t in expm(A*t) is a "matrix".
>> 
>> 'getMethod("expm","matrix")' coerces it arg to a "Matrix", then calls
>> expm(), whose method coerces its arg to a "dMatrix" and calls expm(),
>> whose method coerces its arg to a 'dgeMatrix' and calls expm(), whose
>> method finally calls '.Call(dgeMatrix_exp, x)'
>> 
>> Whew!
>> 
>> The time difference between 'expm( diag(10)+1 )' and 'expm( as( diag(10)+1,
>> "dgeMatrix" ))' is a factor of 10 on my box.
>> 
>> Dunno 'bout the other factor of 100.
>> 
>> Chuck
>> 
>> 
>> 
>> 
>>> The problem arose in an activity to develop guidelines for nonlinear
>>> modeling in ecology (at NCEAS, Santa Barbara, with worldwide participants), and we will be
>>> trying to include suggestions of how to prepare problems like this for efficient and
>>> effective solution. The code for nlogL was the "original" from the worker who supplied the
>>> problem.
>>> 
>>> Best,
>>> 
>>> John Nash
>>> 
>>> --------------------------------------------------------------------------------------
>>> 
>>> cat("mineral-timing.R == benchmark MIN functions in R\n")
>>> #  J C Nash July 31, 2011
>>> 
>>> require("microbenchmark")
>>> require("numDeriv")
>>> library(Matrix)
>>> library(optimx)
>>> # dat<-read.table('min.dat', skip=3, header=FALSE)
>>> # t<-dat[,1]
>>> t <- c(0.77,  1.69,  2.69,  3.67,  4.69,  5.71,  7.94,  9.67, 11.77, 17.77,
>>> 23.77, 32.77, 40.73, 47.75, 54.90, 62.81, 72.88, 98.77, 125.92, 160.19,
>>> 191.15, 223.78, 287.70, 340.01, 340.95, 342.01)
>>> 
>>> # y<-dat[,2] # ?? tidy up
>>> y<- c(1.396, 3.784, 5.948, 7.717, 9.077, 10.100, 11.263, 11.856, 12.251, 12.699,
>>> 12.869, 13.048, 13.222, 13.347, 13.507, 13.628, 13.804, 14.087, 14.185, 14.351,
>>> 14.458, 14.756, 15.262, 15.703, 15.703, 15.703)
>>> 
>>> 
>>> ones<-rep(1,length(t))
>>> theta<-c(-2,-2,-2,-2)
>>> 
>>> 
>>> nlogL<-function(theta){
>>> k<-exp(theta[1:3])
>>> sigma<-exp(theta[4])
>>> A<-rbind(
>>> c(-k[1], k[2]),
>>> c( k[1], -(k[2]+k[3]))
>>> )
>>> x0<-c(0,100)
>>> sol<-function(t)100-sum(expm(A*t)%*%x0)
>>> pred<-sapply(dat[,1],sol)
>>> -sum(dnorm(dat[,2],mean=pred,sd=sigma, log=TRUE))
>>> }
>>> 
>>> getpred<-function(theta, t){
>>> k<-exp(theta[1:3])
>>> sigma<-exp(theta[4])
>>> A<-rbind(
>>> c(-k[1], k[2]),
>>> c( k[1], -(k[2]+k[3]))
>>> )
>>> x0<-c(0,100)
>>> sol<-function(tt)100-sum(expm(A*tt)%*%x0)
>>> pred<-sapply(t,sol)
>>> }
>>> 
>>> Mpred <- function(theta) {
>>> # WARNING: assumes t global
>>> kvec<-exp(theta[1:3])
>>> k1<-kvec[1]
>>> k2<-kvec[2]
>>> k3<-kvec[3]
>>> #   MIN problem terbuthylazene disappearance
>>>   z<-k1+k2+k3
>>>   y<-z*z-4*k1*k3
>>>   l1<-0.5*(-z+sqrt(y))
>>>   l2<-0.5*(-z-sqrt(y))
>>>   val<-100*(1-((k1+k2+l2)*exp(l2*t)-(k1+k2+l1)*exp(l1*t))/(l2-l1))
>>> } # val should be a vector if t is a vector
>>> 
>>> negll <- function(theta){
>>> # non expm version JN 110731
>>> pred<-Mpred(theta)
>>> sigma<-exp(theta[4])
>>> -sum(dnorm(dat[,2],mean=pred,sd=sigma, log=TRUE))
>>> }
>>> 
>>> theta<-rep(-2,4)
>>> fand<-nlogL(theta)
>>> fsim<-negll(theta)
>>> cat("Check fn vals: expm =",fand,"   simple=",fsim,"  diff=",fand-fsim,"\n")
>>> 
>>> cat("time the function in expm form\n")
>>> tnlogL<-microbenchmark(nlogL(theta), times=100L)
>>> tnlogL
>>> 
>>> cat("time the function in simpler form\n")
>>> tnegll<-microbenchmark(negll(theta), times=100L)
>>> tnegll
>>> 
>>> ftimes<-data.frame(texpm=tnlogL$time, tsimp=tnegll$time)
>>> # ftimes
>>> 
>>> 
>>> boxplot(log(ftimes))
>>> title("Log times in nanoseconds for matrix exponential and simple MIN fn")
>>> 
>> 
>> --
>> Charles C. Berry                         cberry at tajo.ucsd.edu
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> "D?den skal tape!" --- Nordahl Grieg
> 
> 
> 
> 
> 
> 
> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> 


From radler12 at op.pl  Fri Aug 19 11:03:03 2011
From: radler12 at op.pl (Krystian Radlak)
Date: Fri, 19 Aug 2011 02:03:03 -0700 (PDT)
Subject: [Rd] Use logical expresion on ff object
In-Reply-To: <CAE2rZE=yzAvsMF9_HRYMSULQXYEG3Lm-cXf0CBpqPQWxc51hKA@mail.gmail.com>
References: <1313658599381-3752127.post@n4.nabble.com>
	<CAE2rZEkqJHPv2Totn-1O0HSbO=g_JY-b731VKhrz7bTBpL0VfQ@mail.gmail.com>
	<1313675837352-3752673.post@n4.nabble.com>
	<CAE2rZE=yzAvsMF9_HRYMSULQXYEG3Lm-cXf0CBpqPQWxc51hKA@mail.gmail.com>
Message-ID: <1313744583548-3754673.post@n4.nabble.com>

It's not corect. Vector with length 15*10^6 you could store in memory without
ff packages.
For vector 15*10^7

 k=bit(15*10^7) 
 a=ff(2,15*10^7) 
 system.time(k<-a[,chunk(1,length.ff(a),1e4)]<1)

Error: cannot allocate vector of size 572.2 Mb
In addition: Warning messages:
1: In system.time(k <- a[, chunk(1, length.ff(a), 10000)] < 1) :
  Reached total allocation of 1535Mb: see help(memory.size)
2: In system.time(k <- a[, chunk(1, length.ff(a), 10000)] < 1) :
  Reached total allocation of 1535Mb: see help(memory.size)
3: In system.time(k <- a[, chunk(1, length.ff(a), 10000)] < 1) :
  Reached total allocation of 1535Mb: see help(memory.size)
4: In system.time(k <- a[, chunk(1, length.ff(a), 10000)] < 1) :
  Reached total allocation of 1535Mb: see help(memory.size)
Timing stopped at: 2.13 0.84 10.45 

And you don't understand my question. In simple operation in R I could do:
a=c(1,4,5,6)
b=a[a>1]
b
[1] 4 5 6

If a is ff object (for example length=15*10^7) this operation doesn't work.
Mayby I don't understand something or this operation is not definied
currently in this package. 
In summarizing:
I have very long vector stored in ff object and I want to chse elements from
this vector which fulfil logical expresion (for example a>1). 

--
View this message in context: http://r.789695.n4.nabble.com/Use-logical-expresion-on-ff-object-tp3752127p3754673.html
Sent from the R devel mailing list archive at Nabble.com.


From lukasz.reclawowicz at gmail.com  Fri Aug 19 14:36:28 2011
From: lukasz.reclawowicz at gmail.com (=?ISO-8859-2?B?o3VrYXN6IFLqY7Nhd293aWN6?=)
Date: Fri, 19 Aug 2011 14:36:28 +0200
Subject: [Rd] Use logical expresion on ff object
In-Reply-To: <1313744583548-3754673.post@n4.nabble.com>
References: <1313658599381-3752127.post@n4.nabble.com>
	<CAE2rZEkqJHPv2Totn-1O0HSbO=g_JY-b731VKhrz7bTBpL0VfQ@mail.gmail.com>
	<1313675837352-3752673.post@n4.nabble.com>
	<CAE2rZE=yzAvsMF9_HRYMSULQXYEG3Lm-cXf0CBpqPQWxc51hKA@mail.gmail.com>
	<1313744583548-3754673.post@n4.nabble.com>
Message-ID: <CAE2rZEmWZs73ghGb6gPECoS+-+Jx9Krkbe3oyT3Qq7bSdfssGg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110819/671eb8d1/attachment.pl>

From murdoch.duncan at gmail.com  Fri Aug 19 19:15:16 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 19 Aug 2011 13:15:16 -0400
Subject: [Rd] License question
In-Reply-To: <4E4AD41B.2090803@mineway.de>
References: <op.v0a4c9t1fg6blk@ws002>	<CAKFxdiSQY+iYOvkPCJTvmVS-px_H9Oe5C2VeTuMfbuHqE0qcAw@mail.gmail.com>
	<4E4AD41B.2090803@mineway.de>
Message-ID: <4E4E9A24.6010600@gmail.com>

On 11-08-16 4:33 PM, Uwe Schmitt wrote:
> Am 16.08.2011 22:23, schrieb Kevin Wright:
>> With open source software, you can do anything you want on your own
>> computer.  The difficult questions arise when you want to
>> re-distribute software.
>>
>> You have provided very little context for your question, so the
>> standard answer on this email list is "Talk to your lawyer".
>>
> Hi,
>
> I'm working on a Python based suite for processing mass spectroscopy
> data. The software will be open source.
> My goal is to glue good solutions together, one of them is the R based
> XCMS library.
>
> The question is, if I am allowed to distribute the R.dll and the related
> libraries together with my software, or
> if it is better to ask the user to install these himself.

You are allowed to bundle those with your software as long as it is 
licenced under version 2 or 3 of the GPL, or under a compatible license. 
  You need to be prepared to distribute the R source of whatever version 
you distribute, as well as the full source of your own project.

Duncan Murdoch

>
> Regards,
>
> Uwe
>
>> Kevin
>>
>>
>> On Tue, Aug 16, 2011 at 7:44 AM, Uwe Schmitt<uschmitt at mineway.de
>> <mailto:uschmitt at mineway.de>>  wrote:
>>
>>
>>      Hi,
>>
>>      I'm not sure if this is the right mailing list for my question,
>>      so please redirect me if this is the wrong place for the
>>      following question:
>>
>>      Am I allowed to include R.dll and Rblas.dll in other software ?
>>
>>      In my case I'm want to run some R commands from a Python script
>>      and save the results. I tried RPy2 which has some trouble running
>>      on Windows.
>>
>>      Regards, Uwe
>>
>>
>>
>>      --
>>
>>      Dr. rer. nat. Uwe Schmitt
>>      Forschung&  Entwicklung Mathematik
>>
>>      mineway GmbH
>>      Geb?ude 4
>>      Im Helmerswald 2
>>      66121 Saarbr?cken
>>
>>      Telefon: +49 (0)681 8390 5334<tel:%2B49%20%280%29681%208390%205334>
>>      Telefax: +49 (0)681 830 4376<tel:%2B49%20%280%29681%20830%204376>
>>
>>      uschmitt at mineway.de<mailto:uschmitt at mineway.de>
>>      www.mineway.de<http://www.mineway.de>
>>
>>      Gesch?ftsf?hrung: Dr.-Ing. Mathias Bauer
>>      Amtsgericht Saarbr?cken HRB 12339
>>
>>      ______________________________________________
>>      R-devel at r-project.org<mailto:R-devel at r-project.org>  mailing list
>>      https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
>
> 	[[alternative HTML version deleted]]
>
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From lokkju at gmail.com  Fri Aug 19 23:26:59 2011
From: lokkju at gmail.com (Lokkju Brennr)
Date: Fri, 19 Aug 2011 14:26:59 -0700
Subject: [Rd] Licensing Issue with JRI
Message-ID: <CAOCX9Dm4fD6P200cgXhX0icHZw1Y2D+n2zgNQ797Di2dng=H_A@mail.gmail.com>

Hoping someone can clear up a licencing question...

My understanding is that R is licensed under the GPL, with some
headers licensed under the LGPL (per COPYRIGHTS, so that R plugins
don't have to be GPL - arguably incorrect, but besides the point).
JRI states that it is licensed under the LGPL - but it links against R
shared libraries (or so is my understanding - please correct me if I'm
wrong).
This seems incompatible, as per
(http://www.gnu.org/licenses/gpl-faq.html#GPLModuleLicense) if there
is any GPL code in a compiled assembly, the resulting binary must be
GPL, and per (http://www.gnu.org/licenses/gpl-faq.html#IfLibraryIsGPL)
if a library is GPL, then anything that links against it must be GPL.

Anyone have any input here?

Thanks

Loki


From ligges at statistik.tu-dortmund.de  Sat Aug 20 20:30:00 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 20 Aug 2011 20:30:00 +0200
Subject: [Rd] Graphical option to update.packages in development version
 (build of the 2011-07-31 r56569) for Windows not working properly
In-Reply-To: <1312467858969-3718847.post@n4.nabble.com>
References: <1312467858969-3718847.post@n4.nabble.com>
Message-ID: <4E4FFD28.4000701@statistik.tu-dortmund.de>

This one seems to be fixed by Brian Ripley already although I have not 
found his reponse to your message.

Best,
Uwe Ligges


On 04.08.2011 16:24, Mark Difford wrote:
> Dear R-core/development-team,
>
> The problem noted in the subject-line has been a problem in the last three
> development versions of R for Windows that I have downloaded and tested, the
> most recent of them being a version I downloaded this morning.
>
> Update.packages() using the graphical option, i.e. called as
>
> update.packages(ask='graphics', checkBuilt=TRUE)
>
> does not work as it should, but presents a list of all of the installed
> packages, regardless of version/time-stamp.
>
> The call
>
> update.packages(old.packages())
>
> works as it should.
>
>> sessionInfo()
> R Under development (unstable) (2011-07-31 r56569)
> Platform: x86_64-pc-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=English_South Africa.1252  LC_CTYPE=English_South Africa.1252
> [3] LC_MONETARY=English_South Africa.1252 LC_NUMERIC=C
> [5] LC_TIME=English_South Africa.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_2.14.0
>
>
> -----
> Mark Difford (Ph.D.)
> Research Associate
> Botany Department
> Nelson Mandela Metropolitan University
> Port Elizabeth, South Africa
> --
> View this message in context: http://r.789695.n4.nabble.com/Graphical-option-to-update-packages-in-development-version-build-of-the-2011-07-31-r56569-for-Windowy-tp3718847p3718847.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From mark_difford at yahoo.co.uk  Sat Aug 20 22:38:54 2011
From: mark_difford at yahoo.co.uk (Mark Difford)
Date: Sat, 20 Aug 2011 13:38:54 -0700 (PDT)
Subject: [Rd] Graphical option to update.packages in development version
 (build of the 2011-07-31 r56569) for Windows not working properly
In-Reply-To: <4E4FFD28.4000701@statistik.tu-dortmund.de>
References: <1312467858969-3718847.post@n4.nabble.com>
	<4E4FFD28.4000701@statistik.tu-dortmund.de>
Message-ID: <1313872734219-3757596.post@n4.nabble.com>

Thanks for the feedback, Uwe. Will try the most recent development version.

Best,
Mark Difford.

-----
Mark Difford (Ph.D.)
Research Associate
Botany Department
Nelson Mandela Metropolitan University
Port Elizabeth, South Africa
--
View this message in context: http://r.789695.n4.nabble.com/Graphical-option-to-update-packages-in-development-version-build-of-the-2011-07-31-r56569-for-Windowy-tp3718847p3757596.html
Sent from the R devel mailing list archive at Nabble.com.


From friendly at yorku.ca  Mon Aug 22 16:21:22 2011
From: friendly at yorku.ca (Michael Friendly)
Date: Mon, 22 Aug 2011 10:21:22 -0400
Subject: [Rd] CRAN packages maintained by you
In-Reply-To: <20031.59603.428313.370382@fangorn.hornik.net>
References: <20031.59603.428313.370382@fangorn.hornik.net>
Message-ID: <4E5265E2.4010500@yorku.ca>

It is A Good Thing to regularize Authors and Maintainers of packages, 
particularly for citation()
and toBibTex().

Could I add a suggested TODO item for the maintainer of package.skeleton 
and friends to
help reinforce this for new packages:

- Please add appropriate templates for Author at R in the skeleton 
DESCRIPTION file generated,
indicating the proper format as well as the use of role= to signal the 
creator and
maintainer.

- a comment to see ?person for descriptions of fields wouldn't hurt either

best,
-Michael


On 8/8/2011 9:46 AM, Kurt Hornik wrote:
> Dear maintainers,
>
> This concerns the packages
>
>     CITAN ENmisc Formula MSBVAR RExcelInstaller RcmdrPlugin.mosaic
>     Rd2roxygen Rz SGP betareg expectreg fastcluster glmc gptk heplots pxR
>     sideChannelAttack sp spacetime trapezoid vcd
>
> maintained by one of you.
>
> I see that you have added Author at R fields providing enhanced information
> on package authors to your DESCRIPTION files, which since R 2.12.0 is
> used for auto-generating citations.
>
> In current r-devel, we have finally added functionality for also
> auto-generating package DESCRIPTION Author and Maintainer fields from
> the enhanced information "if needed" [i.e., existing fields will not be
> overwritten].
>
> However, in the process of this the field was renamed to 'Authors at R', so
> please change your DESCRIPTION files accordingly.
>
> In doing so, pls note that to auto-generate Maintainer fields the
> Authors at R fields need to provide authors with a maintainer (cre) role
> and an email address.  Currently, packages
>
>     CITAN MSBVAR SGP fastcluster glmc gptk heplots sideChannelAttack sp
>     spacetime trapezoid
>
> do not specify the package maintainer in their Authors at R field.
>
> (Note that to take advantage of the new auto-generation functionality,
> you need to rename to Authors at R, remove the DESCRIPTION Author and
> Maintainer fields in the package sources, and then run R CMD build from
> a current version of r-devel.)
>
> Best
> -k


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From ligges at statistik.tu-dortmund.de  Mon Aug 22 19:49:41 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 22 Aug 2011 19:49:41 +0200
Subject: [Rd] problems with connections when applied in tryCatch
In-Reply-To: <CAO1zAVaQ=uZnp0YZpintN-1XeC+qE3Mqg596fPphnUrVM9FLjg@mail.gmail.com>
References: <CAO1zAVaQ=uZnp0YZpintN-1XeC+qE3Mqg596fPphnUrVM9FLjg@mail.gmail.com>
Message-ID: <4E5296B5.6040303@statistik.tu-dortmund.de>



On 18.08.2011 17:53, Joris Meys wrote:
> Recently on stackoverflow following problem came up :
>
> http://stackoverflow.com/questions/7103429/all-the-connections-are-in-use-execution-halted/7108799#7108799
>
> A reproducible example: When trying
>
> replicate(200,tryCatch(read.table("this.is.no.file"),
>            warning=function(w){print(showConnections());print("warning")}))
>
> No connections are shown, but after a number of calls, suddenly the message
>
> Error in file(file, "rt") : all connections are in use
>
> pops up. Trying to get them deleted with closeAllConnections() causes
> R to crash on Windows 7. Another user reported a segfault. (see the
> link to stackoverflow)
>
> Although I initially thought on.exit() was somehow skipped, that's not
> the case. In fact, the connection couldn't be opened, so it can't be
> closed either. I have no clue as to why this goes wrong, but it shows
> there's something odd happening with the connections. For the record,
> I am aware that the use of the warning handler in that call is rather
> peculiar. But even then, R shouldn't crash.

Right, and not trivial to track down! At least I can reproduce it with 
R-devel under Windows Server 2008. Can you please file a bug report so 
it won't be forgotten.

Thanks,
Uwe Ligges



> Cheers
> Joris
>
>


From jorismeys at gmail.com  Tue Aug 23 12:57:40 2011
From: jorismeys at gmail.com (Joris Meys)
Date: Tue, 23 Aug 2011 12:57:40 +0200
Subject: [Rd] problems with connections when applied in tryCatch
In-Reply-To: <4E5296B5.6040303@statistik.tu-dortmund.de>
References: <CAO1zAVaQ=uZnp0YZpintN-1XeC+qE3Mqg596fPphnUrVM9FLjg@mail.gmail.com>
	<4E5296B5.6040303@statistik.tu-dortmund.de>
Message-ID: <CAO1zAVa59ukaY7Daw6vTz==nriCB=coR0dkVDYnZE3k_3wg1JA@mail.gmail.com>

Bug committed with number 14660
Cheers
Joris

2011/8/22 Uwe Ligges <ligges at statistik.tu-dortmund.de>:
>
>
> On 18.08.2011 17:53, Joris Meys wrote:
>>
>> Recently on stackoverflow following problem came up :
>>
>>
>> http://stackoverflow.com/questions/7103429/all-the-connections-are-in-use-execution-halted/7108799#7108799
>>
>> A reproducible example: When trying
>>
>> replicate(200,tryCatch(read.table("this.is.no.file"),
>> ? ? ? ? ? warning=function(w){print(showConnections());print("warning")}))
>>
>> No connections are shown, but after a number of calls, suddenly the
>> message
>>
>> Error in file(file, "rt") : all connections are in use
>>
>> pops up. Trying to get them deleted with closeAllConnections() causes
>> R to crash on Windows 7. Another user reported a segfault. (see the
>> link to stackoverflow)
>>
>> Although I initially thought on.exit() was somehow skipped, that's not
>> the case. In fact, the connection couldn't be opened, so it can't be
>> closed either. I have no clue as to why this goes wrong, but it shows
>> there's something odd happening with the connections. For the record,
>> I am aware that the use of the warning handler in that call is rather
>> peculiar. But even then, R shouldn't crash.
>
> Right, and not trivial to track down! At least I can reproduce it with
> R-devel under Windows Server 2008. Can you please file a bug report so it
> won't be forgotten.
>
> Thanks,
> Uwe Ligges
>
>
>
>> Cheers
>> Joris
>>
>>
>



-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Applied mathematics, biometrics and process control

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From renaud at mancala.cbio.uct.ac.za  Tue Aug 23 16:40:19 2011
From: renaud at mancala.cbio.uct.ac.za (Renaud Gaujoux)
Date: Tue, 23 Aug 2011 16:40:19 +0200
Subject: [Rd] getNativeSymbolInfo("user_unif_rand") returns different
 results on windows and linux
Message-ID: <4E53BBD3.7050907@cbio.uct.ac.za>

Hi,

sorry to bump this post but I did not get any reply on this puzzling 
issue, which looks important though.

While investigating the issue it came out that the value returned by 
getNativeSymbolInfo('user_unif_rand') (on Windows XP) seems to depend on 
whether it has already been called on the same symbol (see test code 
below. Each sequence needs to be run on on a fresh R session).

Things works perfectly under Linux.

Thank you for any explanation on the matter.

Renaud

########## SEQUENCE 1 ##################
library(rstream)
getNativeSymbolInfo('user_unif_rand')
# this returns complete info pointing to rstream's hook
#### RESULT
$name
[1] "user_unif_rand"

$address
<pointer: 0x6ee41280>
attr(,"class")
[1] "NativeSymbol"

$package
DLL name: rstream
Filename: C:/Program
         Files/R/R-2.13.1/library/rstream/libs/i386/rstream.dll
Dynamic lookup: TRUE

attr(,"class")
[1] "NativeSymbolInfo"
####

# call again getNativeSymbolInfo
getNativeSymbolInfo('user_unif_rand')
# this returns INcomplete info pointing to rstream's hook
### RESULT
$name
[1] "user_unif_rand"

$address
<pointer: 0x6ee41280>
attr(,"class")
[1] "NativeSymbol"

$package
NULL

attr(,"class")
[1] "NativeSymbolInfo"
############################


########## SEQUENCE 2 ##################
library(rstream)
library(rlecuyer)
getNativeSymbolInfo('user_unif_rand')
# this returns complete info pointing to relcuyer's hook
########## RESULT ##################
$name
[1] "user_unif_rand"

$address
<pointer: 0x6bb84fb8>
attr(,"class")
[1] "NativeSymbol"

$package
DLL name: rlecuyer
Filename: C:/Program
         Files/R/R-2.13.1/library/rlecuyer/libs/i386/rlecuyer.dll
Dynamic lookup: TRUE

attr(,"class")
[1] "NativeSymbolInfo"
############################

########## SEQUENCE 3 ##################
####### Load library that provides a hook for user_unif_rand
library(rstream)
getNativeSymbolInfo('user_unif_rand')
# this returns complete info pointing to rstream's hook
## RESULT ##
$name
[1] "user_unif_rand"

$address
<pointer: 0x6ee41280>
attr(,"class")
[1] "NativeSymbol"

$package
DLL name: rstream
Filename: C:/Program
         Files/R/R-2.13.1/library/rstream/libs/i386/rstream.dll
Dynamic lookup: TRUE

attr(,"class")
[1] "NativeSymbolInfo"
##

####### Load other library that provides the hook
library(rlecuyer)
getNativeSymbolInfo('user_unif_rand')
# this returns INcomplete info pointing to rstream's hook
## RESULT ##
$name
[1] "user_unif_rand"

$address
<pointer: 0x6ee41280>
attr(,"class")
[1] "NativeSymbol"

$package
NULL

attr(,"class")
[1] "NativeSymbolInfo"
############################


 > sessionInfo()
R version 2.13.1 (2011-07-08)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_South Africa.1252  LC_CTYPE=English_South 
Africa.1252
[3] LC_MONETARY=English_South Africa.1252 LC_NUMERIC=C 

[5] LC_TIME=English_South Africa.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] rlecuyer_0.3-1 rstream_1.3.1



###

UNIVERSITY OF CAPE TOWN 

This e-mail is subject to the UCT ICT policies and e-mai...{{dropped:5}}


From renaud at mancala.cbio.uct.ac.za  Tue Aug 23 18:41:31 2011
From: renaud at mancala.cbio.uct.ac.za (Renaud Gaujoux)
Date: Tue, 23 Aug 2011 18:41:31 +0200
Subject: [Rd] getNativeSymbolInfo("user_unif_rand") returns different
 results on windows and linux
In-Reply-To: <4E53CE14.1010609@fhcrc.org>
References: <4E53BBD3.7050907@cbio.uct.ac.za> <4E53CE14.1010609@fhcrc.org>
Message-ID: <4E53D83B.2090806@cbio.uct.ac.za>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110823/3c3d02a0/attachment.pl>

From janko.thyson.rstuff at googlemail.com  Tue Aug 23 20:23:43 2011
From: janko.thyson.rstuff at googlemail.com (Janko Thyson)
Date: Tue, 23 Aug 2011 20:23:43 +0200
Subject: [Rd] Increase transparency: suggestion on how to avoid namespaces
 and/or unnecessary overwrites of existing functions
Message-ID: <4E53F02F.106@googlemail.com>

aDear list,

I'm aware of the fact that I posted on something related a while ago, 
but I just can't sweat this off and would like to ask your for an opinion:

The problem:
Namespaces are great, but they don't resolve certain conflicts regarding 
name clashes. There are more and more people out there trying to come up 
with their own R packages, which is great also! Yet, it becomes more and 
more likely that programmers will choose identical names for their 
exported functions and/or that they add functionality to existing 
function (i.e. overwriting existing functions).
The whole process of which packages overwrite which functions is 
somewhat obscure and in addition depends on their order in the search 
path. On the other hand, it is not possible to use "namespace" 
functionality (i.e. 'namespace::fun()'; also less efficient than direct 
call; see illustration below) during early stages of the development 
process (i.e. the package is not finished yet) as there is no namespace 
available yet.

I know of at least two cases where such overwrites (I think it's called 
masking, right?) led to some confusion at our chair:
1) loading package forecast overwrites certain functions in stats which 
made some code refactoring necessary
2) loading package 'R.utils' followed by package 'roxygen' overwrites 
'parse.default()' which results in errors for something like 
'eval(parse(text="a <- 1"))' ; see illustration below)
And I'm sure the community could come up with lots more of such scenarios.

Suggestions:
1) In order to avoid name clashes/unintended overwrites, how about 
switching to a coding paradigm that explicitly (and automatically) 
includes a package's name in all its functions' names once code is 
turned into a real package? E.g., getting used to "preemptively" type 
'package_fun()' or 'package.fun()' instead of just 'fun()'. Better to be 
save than sorry, right? This could be realized pretty easily (see 
example below) and, IMHO, would significantly increase transparency.
2) In order to avoid intended (but for the user often pretty obscure) 
overwrites of existing functions, we could use the same mechanism 
together with the "rule": just don't provide any functions that 
overwrite existing ones, rather prepend your version of that function 
with your package name and leave it up to the user which version he 
wants to call.

At the moment, all of this is probably not that big of a deal yet, but 
my suggestion has more of a mid-term/long-term character.

Below you find a little illustration. I'm probably asking too much, but 
it'd be great if we could get a little discussion going on how to 
improve the way of loading packages!

Best regards and thanks for R and all it's packages!
Janko

################################################################################
# PROOF OF CONCEPT
################################################################################

# 1) PROBLEM
# IMHO, with the number of packages submitted to CRAN constantly increasing,
# over time we will be likely to see problems with respect to name clashes.
# The main reasons I see for this are the following:
# a) package developers picking identical names for their exported functions
# b) package developers overwriting base functions in order to add 
functionality
#    to existing functions
# c) ...
#
# This can create scenarios in which the user might not exactly know that
# he/she is using a 'modified' version of a specific function. More so, 
the user
# needs to carefully read the description of each new package he plans
# to use in order to find out which functions are exported and which 
existing
# functions might be overwritten. This in turn might imply that the user's
# existing code needs to be refactored (i.e. instead of using 'fun()' it
# might now be necessary to type 'namespace::fun()' to be sure that the 
desired
# function is called).

# 2) SUGGESTED SOLUTION
# That being said, why don't we switch to a 'preemptive' coding paradigm
# where the default way of calling functions includes the specification of
# its namespace? In principle, the functionality offered by 
'namespace::fun()'
# gets the job done.
# BUT:
# a) it is slower compared to the direct way of calling a function.
#    (see illustration below).
# b) this option is not available througout the development process of a 
package
#    as there is no namespace yet and there's no way to emulate one. 
This in
#    turn means that even though a package developer would buy into 
strictly
#    using 'mypkg::fun()' throughout his package code, he can only do so 
at the
#    very final stage of the process RIGHT before turning his code into a
#    working package (when he's absolutely sure everything is working as 
planned).
#    For debugging he would need to go back to using 'fun()'. Pretty 
cumbersome.

# So how about simply automatically prepending a given function's name with
# the package's name for each package that is build (e.g. 'pkg.fun()' or
# 'pkg_fun()')? In the end, this would just be a small change for new 
packages
# without a significant decrease of performance and it could also be 
realized
# at early stages of the development process (see illustration below).

# 3) ILLUSTRATION

# Example case where base function 'parse.default' is overwritten:
parse(text="a <- 5")    # Works
require(R.utils)
require(roxygen)
parse(text="a <- 5")    # Does not work anymore

################# START A NEW R SESSION BEFORE YOU CONTINUE 
####################

# Inefficiency of 'namespace::fun()':
require(microbenchmark)
res.a <- microbenchmark(eval(parse(text="a <- 5")))
res.b <- microbenchmark(eval(base::parse(text="a <- 5")))
median(res.a$time)/median(res.b$time)

# Can be made up by explicit assignment:
foo <- base::parse
res.a <- microbenchmark(eval(parse(text="a <- 5")))
res.b <- microbenchmark(eval(foo(text="a <- 5")))
median(res.a$time)/median(res.b$time)

# Automatically prepend function names:
processNamespaces <- function(
     do.global=FALSE,
     do.verbose=FALSE,
     .delim.name="_",
     ...
){
     srch.list.0 <- search()
     srch.list <- gsub("package:", "", srch.list.0)
     if(!do.global){
         assign(".NS", new.env(), envir=.GlobalEnv)
     }
     out <- lapply(1:length(srch.list), function(x.pkg){
         pkg <- srch.list[x.pkg]

         # SKIP LIST
         if(pkg %in% c(".GlobalEnv", "Autoloads")){
             return(NULL)
         }
         # /

         # TARGET ENVIR
         if(!do.global){
             # ADD PACKAGE TO .NS ENVIRONMENT
             envir <- eval(substitute(
                 assign(PKG, new.env(), envir=.NS),
                 list(PKG=pkg)
             ))
             # /
#            envir <- get(pkg, envir=.NS, inherits=FALSE)
             envir.msg <- paste(".NS$", pkg, sep="")
         } else {
             envir <- .GlobalEnv
             envir.msg <- ".GlobalEnv"
         }
         # /

         # PROCESS FUNCTIONS
         cnt <- ls(pos=x.pkg)
         out <- unlist(sapply(cnt, function(x.cnt){
             value <- get(x.cnt, pos=x.pkg, inherits=FALSE)
             obj.mod <- paste(pkg, x.cnt, sep=.delim.name)
             if(!is.function(value)){
                 return(NULL)
             }
             if(do.verbose){
                 cat(paste("Assigning '", obj.mod, "' to '", envir.msg,
                     "'", sep=""), sep="\n")
             }
             eval(substitute(
                 assign(OBJ.MOD, value, envir=ENVIR),
                 list(
                     OBJ.MOD=obj.mod,
                     ENVIR=envir
                 )
             ))
             return(obj.mod)
         }))
         names(out) <- NULL
         # /
         return(out)
     })
     names(out) <- srch.list
     return(out)
}

# +++++

funs <- processNamespaces(do.verbose=TRUE)
ls(.NS)
ls(.NS$base)
.NS$base$base_parse

res.a <- microbenchmark(eval(parse(text="a <- 5")))
res.b <- microbenchmark(eval(.NS$base$base_parse(text="a <- 5")))
median(res.a$time)/median(res.b$time)

#+++++

funs <- processNamespaces(do.global=TRUE, do.verbose=TRUE)
base_parse

res.a <- microbenchmark(eval(parse(text="a <- 5")))
res.b <- microbenchmark(eval(base_parse(text="a <- 5")))
median(res.a$time)/median(res.b$time)


From rkoenker at uiuc.edu  Tue Aug 23 23:40:19 2011
From: rkoenker at uiuc.edu (RKoenker)
Date: Tue, 23 Aug 2011 14:40:19 -0700 (PDT)
Subject: [Rd] google fusiontables
Message-ID: <1314135619483-3763950.post@n4.nabble.com>

I'm wondering whether anyone knows of an interface of R to google's
relatively new fusiontables

http://www.google.com/fusiontables/public/tour/index.html

http://code.google.com/apis/fusiontables/docs/developers_guide.html

having googled around a bit one comes eventually to this:  

http://andrei.lopatenko.com/rstat/fusion-tables.R

but it seems to have been dropped when the author bit the Apple.  I'm
looking for a  simple way to 
generate web based stuff from R for classes, and this looked like a more
lively option than the defunct
Rpad, or other things that I've uncovered.  If there are other good options,
preferably with some
documentation and examples,  I'd be happy to hear about them too.

TIA,
Roger


--
View this message in context: http://r.789695.n4.nabble.com/google-fusiontables-tp3763950p3763950.html
Sent from the R devel mailing list archive at Nabble.com.


From janko.thyson.rstuff at googlemail.com  Wed Aug 24 00:02:37 2011
From: janko.thyson.rstuff at googlemail.com (Janko Thyson)
Date: Wed, 24 Aug 2011 00:02:37 +0200
Subject: [Rd] Implementing a "plugin" paradigm with R methods
Message-ID: <4E54237D.3090809@googlemail.com>

Dear list,

I was wondering how to best implement some sort of a "plugin" paradigm 
using R methods and the dispatcher:
Say we have a function/method ('foo') that does something useful, but 
that should be open for extension in ONE specific area by OTHERS using 
my package. Of course they could go ahead and write a whole new 'foo' 
method including the features they'd like to see, but that's not really 
necessary. Rather, they should be able to just write a new "plugin" 
method for that part of 'foo' that I'd like to open for such plugins.

The way I chose below works, but generates warnings as my method has 
signature arguments that don't correspond to formal classes (which is 
totally fine). Of course I could go ahead and make sure that such 
"dummy" classes exist, but I was wondering if there's a better way.

It'd be great if anyone could let me know how they handle "plugin" 
scenarios based on some sort of method dispatch!

Thanks,
Janko

##### CODE EXAMPLE #####

setGeneric(name="foo", signature=c("src"), function(src, ...) 
standardGeneric("foo"))
setGeneric(name="plugin", signature=c("src", "link", "plugin"),
     function(src, link, plugin, ...) standardGeneric("plugin")
)
setMethod(f="plugin", signature=signature(src="character", link="foo", 
plugin="punct"),
     function(src, link, plugin, ...){
         out <- gsub("[[:punct:]]", "", src)
         return(out)
     }
)
setMethod(f="plugin", signature=signature(src="character", link="foo", 
plugin="digit"),
     function(src, link, plugin, ...){
         out <- gsub("[[:digit:]]", "", src)
         return(out)
     }
)
setMethod(f="foo", signature=signature(src="character"),
     function(src, plugin=NULL, ...){
         if(!is.null(plugin)){
             if(!existsMethod(f="plugin",
                 signature=c(src=class(src), link="foo", plugin=plugin)
             )){
                 stop("Invalid plugin")
             }
             .plugin <- selectMethod(
                 "plugin",
                 signature=c(src=class(src), link="foo", plugin=plugin),
                 useInherited=c(src=TRUE, plugin=FALSE)
             )
             out <- .plugin(src=src)
         } else {
             out <- paste("Hello world: ", src, sep="")
         }
         return(out)
     }
)
foo(src="Teststring:-1234_56/")
foo(src="Teststring:-1234_56/", plugin="punct")
foo(src="Teststring:-1234_56/", plugin="digit")


From mtmorgan at fhcrc.org  Wed Aug 24 06:37:08 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Tue, 23 Aug 2011 21:37:08 -0700
Subject: [Rd] Implementing a "plugin" paradigm with R methods
In-Reply-To: <4E54237D.3090809@googlemail.com>
References: <4E54237D.3090809@googlemail.com>
Message-ID: <4E547FF4.6060605@fhcrc.org>

On 08/23/2011 03:02 PM, Janko Thyson wrote:
> Dear list,
>
> I was wondering how to best implement some sort of a "plugin" paradigm
> using R methods and the dispatcher:
> Say we have a function/method ('foo') that does something useful, but
> that should be open for extension in ONE specific area by OTHERS using
> my package. Of course they could go ahead and write a whole new 'foo'

One possibility is to write class / method pairs. The classes extend 
'Plugin', and the methods are on generic 'plug', with the infrastructure

   ## Approach 1: class / method pairs
   setClass("Plugin")

   setClass("DefaultPlugin", contains="Plugin")

   DefaultPlugin <- function() new("DefaultPlugin")

   setGeneric("plug",
              function(plugin, src) standardGeneric("plug"),
              signature="plugin",
              valueClass="character")

   setMethod(plug, "Plugin", function(plugin, src) {
       src
   })

   foo <- function(src, plugin=DefaultPlugin()) {
       plug(plugin, src)
   }

This is extended by writing class / method pairs

   setClass("Punct", contains="Plugin")

   Punct <- function() new("Punct")

   setMethod(plug, "Punct", function(plugin, src) {
       gsub("[[:punct:]]", "", src)
   })


   setClass("Digit", contains="Plugin")

   Digit <- function() new("Digit")

   setMethod(plug, "Digit", function(plugin, src) {
       gsub("[[:digit:]]", "", src)
   })

The classes could have slots with state, accessible within the method. 
An easier-on-the-user approach might have the Plugin class contain or 
have slots of class "function". The user would only be obliged to 
provide an appropriate function.

   ## Approach 2:
   setClass("Plugin", prototype=prototype(function(src) {
       src
   }), contains="function")

   Plugin <- function() new("Plugin")

   setGeneric("foo",
              function(src, plugin) standardGeneric("foo"))

   setMethod(foo, c("character", "missing"),
             function(src, plugin) foo(src, Plugin()))

   setMethod(foo, c("character", "Plugin"),
             function(src, plugin) plugin(src))

   ## 'Developer' classes
   setClass("Punct", prototype=prototype(function(src) {
       gsub("[[:punct:]]", "", src)
   }), contains="Plugin")

   Punct <- function() new("Punct")

   setClass("Digit", prototype=prototype(function(src) {
       gsub("[[:digit:]]", "", src)
   }), contains="Plugin")

   Digit <- function() new("Digit")

   ## General-purpose 'user' class
   setClass("User", contains="Plugin")

   User <- function(fun) new("User", fun)

This could have syntax checking in the validity method to catch some 
mistakes early. In the S3 world, this is the approach taken by glm for 
its 'family' argument, for instance str(gaussian().

Martin

> method including the features they'd like to see, but that's not really
> necessary. Rather, they should be able to just write a new "plugin"
> method for that part of 'foo' that I'd like to open for such plugins.
>
> The way I chose below works, but generates warnings as my method has
> signature arguments that don't correspond to formal classes (which is
> totally fine). Of course I could go ahead and make sure that such
> "dummy" classes exist, but I was wondering if there's a better way.
>
> It'd be great if anyone could let me know how they handle "plugin"
> scenarios based on some sort of method dispatch!
>
> Thanks,
> Janko
>
> ##### CODE EXAMPLE #####
>
> setGeneric(name="foo", signature=c("src"), function(src, ...)
> standardGeneric("foo"))
> setGeneric(name="plugin", signature=c("src", "link", "plugin"),
> function(src, link, plugin, ...) standardGeneric("plugin")
> )
> setMethod(f="plugin", signature=signature(src="character", link="foo",
> plugin="punct"),
> function(src, link, plugin, ...){
> out <- gsub("[[:punct:]]", "", src)
> return(out)
> }
> )
> setMethod(f="plugin", signature=signature(src="character", link="foo",
> plugin="digit"),
> function(src, link, plugin, ...){
> out <- gsub("[[:digit:]]", "", src)
> return(out)
> }
> )
> setMethod(f="foo", signature=signature(src="character"),
> function(src, plugin=NULL, ...){
> if(!is.null(plugin)){
> if(!existsMethod(f="plugin",
> signature=c(src=class(src), link="foo", plugin=plugin)
> )){
> stop("Invalid plugin")
> }
> .plugin <- selectMethod(
> "plugin",
> signature=c(src=class(src), link="foo", plugin=plugin),
> useInherited=c(src=TRUE, plugin=FALSE)
> )
> out <- .plugin(src=src)
> } else {
> out <- paste("Hello world: ", src, sep="")
> }
> return(out)
> }
> )
> foo(src="Teststring:-1234_56/")
> foo(src="Teststring:-1234_56/", plugin="punct")
> foo(src="Teststring:-1234_56/", plugin="digit")
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From janko.thyson.rstuff at googlemail.com  Wed Aug 24 10:10:51 2011
From: janko.thyson.rstuff at googlemail.com (Janko Thyson)
Date: Wed, 24 Aug 2011 10:10:51 +0200
Subject: [Rd] Implementing a "plugin" paradigm with R methods
In-Reply-To: <4E547FF4.6060605@fhcrc.org>
References: <4E54237D.3090809@googlemail.com> <4E547FF4.6060605@fhcrc.org>
Message-ID: <4E54B20B.8000908@googlemail.com>

Hi Martin,

thanks a lot for the quick reply. I'll try your suggestions.

Regards,
Janko

On 24.08.2011 06:37, Martin Morgan wrote:
> On 08/23/2011 03:02 PM, Janko Thyson wrote:
>> Dear list,
>>
>> I was wondering how to best implement some sort of a "plugin" paradigm
>> using R methods and the dispatcher:
>> Say we have a function/method ('foo') that does something useful, but
>> that should be open for extension in ONE specific area by OTHERS using
>> my package. Of course they could go ahead and write a whole new 'foo'
>
> One possibility is to write class / method pairs. The classes extend 
> 'Plugin', and the methods are on generic 'plug', with the infrastructure
>
>   ## Approach 1: class / method pairs
>   setClass("Plugin")
>
>   setClass("DefaultPlugin", contains="Plugin")
>
>   DefaultPlugin <- function() new("DefaultPlugin")
>
>   setGeneric("plug",
>              function(plugin, src) standardGeneric("plug"),
>              signature="plugin",
>              valueClass="character")
>
>   setMethod(plug, "Plugin", function(plugin, src) {
>       src
>   })
>
>   foo <- function(src, plugin=DefaultPlugin()) {
>       plug(plugin, src)
>   }
>
> This is extended by writing class / method pairs
>
>   setClass("Punct", contains="Plugin")
>
>   Punct <- function() new("Punct")
>
>   setMethod(plug, "Punct", function(plugin, src) {
>       gsub("[[:punct:]]", "", src)
>   })
>
>
>   setClass("Digit", contains="Plugin")
>
>   Digit <- function() new("Digit")
>
>   setMethod(plug, "Digit", function(plugin, src) {
>       gsub("[[:digit:]]", "", src)
>   })
>
> The classes could have slots with state, accessible within the method. 
> An easier-on-the-user approach might have the Plugin class contain or 
> have slots of class "function". The user would only be obliged to 
> provide an appropriate function.
>
>   ## Approach 2:
>   setClass("Plugin", prototype=prototype(function(src) {
>       src
>   }), contains="function")
>
>   Plugin <- function() new("Plugin")
>
>   setGeneric("foo",
>              function(src, plugin) standardGeneric("foo"))
>
>   setMethod(foo, c("character", "missing"),
>             function(src, plugin) foo(src, Plugin()))
>
>   setMethod(foo, c("character", "Plugin"),
>             function(src, plugin) plugin(src))
>
>   ## 'Developer' classes
>   setClass("Punct", prototype=prototype(function(src) {
>       gsub("[[:punct:]]", "", src)
>   }), contains="Plugin")
>
>   Punct <- function() new("Punct")
>
>   setClass("Digit", prototype=prototype(function(src) {
>       gsub("[[:digit:]]", "", src)
>   }), contains="Plugin")
>
>   Digit <- function() new("Digit")
>
>   ## General-purpose 'user' class
>   setClass("User", contains="Plugin")
>
>   User <- function(fun) new("User", fun)
>
> This could have syntax checking in the validity method to catch some 
> mistakes early. In the S3 world, this is the approach taken by glm for 
> its 'family' argument, for instance str(gaussian().
>
> Martin
>
>> method including the features they'd like to see, but that's not really
>> necessary. Rather, they should be able to just write a new "plugin"
>> method for that part of 'foo' that I'd like to open for such plugins.
>>
>> The way I chose below works, but generates warnings as my method has
>> signature arguments that don't correspond to formal classes (which is
>> totally fine). Of course I could go ahead and make sure that such
>> "dummy" classes exist, but I was wondering if there's a better way.
>>
>> It'd be great if anyone could let me know how they handle "plugin"
>> scenarios based on some sort of method dispatch!
>>
>> Thanks,
>> Janko
>>
>> ##### CODE EXAMPLE #####
>>
>> setGeneric(name="foo", signature=c("src"), function(src, ...)
>> standardGeneric("foo"))
>> setGeneric(name="plugin", signature=c("src", "link", "plugin"),
>> function(src, link, plugin, ...) standardGeneric("plugin")
>> )
>> setMethod(f="plugin", signature=signature(src="character", link="foo",
>> plugin="punct"),
>> function(src, link, plugin, ...){
>> out <- gsub("[[:punct:]]", "", src)
>> return(out)
>> }
>> )
>> setMethod(f="plugin", signature=signature(src="character", link="foo",
>> plugin="digit"),
>> function(src, link, plugin, ...){
>> out <- gsub("[[:digit:]]", "", src)
>> return(out)
>> }
>> )
>> setMethod(f="foo", signature=signature(src="character"),
>> function(src, plugin=NULL, ...){
>> if(!is.null(plugin)){
>> if(!existsMethod(f="plugin",
>> signature=c(src=class(src), link="foo", plugin=plugin)
>> )){
>> stop("Invalid plugin")
>> }
>> .plugin <- selectMethod(
>> "plugin",
>> signature=c(src=class(src), link="foo", plugin=plugin),
>> useInherited=c(src=TRUE, plugin=FALSE)
>> )
>> out <- .plugin(src=src)
>> } else {
>> out <- paste("Hello world: ", src, sep="")
>> }
>> return(out)
>> }
>> )
>> foo(src="Teststring:-1234_56/")
>> foo(src="Teststring:-1234_56/", plugin="punct")
>> foo(src="Teststring:-1234_56/", plugin="digit")
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From janko.thyson.rstuff at googlemail.com  Wed Aug 24 11:35:24 2011
From: janko.thyson.rstuff at googlemail.com (Janko Thyson)
Date: Wed, 24 Aug 2011 11:35:24 +0200
Subject: [Rd] Bug in 'setRefClass()' regarding how args in '...' are passed
 to 'setClass()'?
Message-ID: <4E54C5DC.1030703@googlemail.com>

Dear list,

in ?setRefClass it says that '...' can be used to supply other arguments 
that are passed to 'setClass()'.

Yet, I think that's not true for argument 'prototype', but maybe I 
overlooked something:

setClass("Plugin")
setClass(Class="PluginDefault", contains="Plugin",
     representation=representation(.PRIMARY="function"),
     prototype=prototype(.PRIMARY=function(src) src)
)
PluginDefault <- function() new("PluginDefault")
PluginDefault()
PluginDefault()$.PRIMARY    # Desired prototype content

#+++++ START A NEW R SESSION BEFORE CONTINUING

setRefClass("Plugin")
setRefClass(Class="PluginDefault", contains="Plugin", 
fields=list(.PRIMARY="function"),
     prototype=prototype(.PRIMARY=function(src) src)
)
PluginDefault <- function() new("PluginDefault")
PluginDefault()
PluginDefault()$.PRIMARY     # No prototype content

Regards,
Janko


From janko.thyson.rstuff at googlemail.com  Wed Aug 24 18:18:08 2011
From: janko.thyson.rstuff at googlemail.com (Janko Thyson)
Date: Wed, 24 Aug 2011 18:18:08 +0200
Subject: [Rd] Implementing a "plugin" paradigm with R methods
In-Reply-To: <4E547FF4.6060605@fhcrc.org>
References: <4E54237D.3090809@googlemail.com> <4E547FF4.6060605@fhcrc.org>
Message-ID: <4E552440.20800@googlemail.com>

Hi Martin,

thanks a lot again for your suggestions! I played around a bit with it 
today and this is the solution that I like the most.
The main extensions compared to your code are:
1) Using Reference Classes (I don't know, but I just like them somehow ;-))
1) Basing method dispatch for plugin methods on multiple signature 
arguments to ensure transparency/minimize the risk of name clashes for 
plugins
2) Hide as much definition details for signature argument classes from 
the user as possible (see 'apiClassesEnsure()' and 'pluginObjectCreate()')

One neat thing would be to get around the warnings when defining plugin 
methods ('apiClassesEnsure()' which takes care of setting formal classes 
for signature arguments is called at 'run time' when calling
'foo()', so the formal classes are not there yet). But I guess I just 
have to turn them off temporarily when sourcing in methods from a directory.

It'd be cool if you could tell me what you think of that approach!

Regards,
Janko

#-------------------------------------------------------------------------------
# APPROACH 6 r-devel
#-------------------------------------------------------------------------------

# Set system environments
.HIVE <- new.env()
.HIVE$.protected <- new.env()
.HIVE$.protected$classes <- new.env()

#+++++

# Define plugin class providing all necessary signature arguments for 
method
# dispatch of plugin methods
setRefClass("Plugin",
     fields=list(
         ns="character",     # Namespace
         link="character",   # Name of the function/method for which the 
plugin is intended
         mount="character",  # 'Mounting point' within the link 
function. Possibly the linked function can be open for plugins at 
different 'sections'
         plugin="character", # Name of the plugin method
         src="character"     # Main input for plugin method
     ),
     methods=list(
         # Processes plugins based on fields signature fields above
         pluginProcess=function(...){
             pluginProcessRef(.self=.self, ...)
         }
     )
)

#+++++

# Define a function that takes care of 'registering' the classes needed for
# the signature fields above in order to follow a clean method dispatch
# paradigm based on formal classes
apiClassesEnsure <- function(src, do.overwrite=FALSE,...){
     out <- sapply(src, function(x.src){
         if(!isClass(x.src)){
             x.src <- paste("API_", x.src, sep="")
         }
         if( !exists(x.src, envir=.HIVE$.protected$classes, 
inherits=FALSE) |
             do.overwrite
         ){
             cat(paste("apiClassesEnsure/assigning class '", x.src,
                 "' to '.HIVE$.protected$classes'", sep=""), sep="\n")
             if(!isClass(x.src)){
                 expr <- substitute(
                     setClass(
                         Class=CLASS,
                         contains="NULL",
                         where=ENVIR
                     ),
                     list(CLASS=x.src, ENVIR=.HIVE$.protected$classes)
                 )
                 eval(expr)
                 eval(substitute(
                     assign(CLASS, expr, envir=ENVIR),
                     list(CLASS=x.src, ENVIR=.HIVE$.protected$classes)
                 ))
             } else {
                 eval(substitute(
                     assign(CLASS, CLASS, envir=ENVIR),
                     list(CLASS=x.src, ENVIR=.HIVE$.protected$classes)
                 ))
             }
         }
         out <- x.src
         return(out)
     })
     return(out)
}

#+++++

# Define a function that creates plugin objects
pluginObjectCreate <- function(ns=NULL, link=NULL, mount=NULL, plugin=NULL,
     src=NULL, do.overwrite=FALSE){
     out <- new("Plugin")
     out$initFields(
         ns=apiClassesEnsure(src=ns, do.overwrite=do.overwrite),
         link=apiClassesEnsure(src=link, do.overwrite=do.overwrite),
         mount=apiClassesEnsure(src=mount, do.overwrite=do.overwrite),
         plugin=apiClassesEnsure(src=plugin, do.overwrite=do.overwrite),
         src=src
     )
     apiClassesEnsure(src=class(src), do.overwrite=do.overwrite)
     return(out)
}
pluginObjectCreate()
pluginObjectCreate()$ns
pluginObjectCreate()$link
pluginObjectCreate()$pluginProcess

#+++++

# Set generics
setGeneric(name="pluginProcessRef", signature=c(".self"),
     function(.self, ...) standardGeneric("pluginProcessRef")
)
setGeneric(name="pluginExecute",
     signature=c("ns", "link", "mount", "plugin", "src"),
     function(ns, link, mount, plugin, src, ...) 
standardGeneric("pluginExecute")
)

#+++++

# Set method for 'pluginProcessRef'.
# The method has two modi operandi:
# 1) 'do.explicit.clss = FALSE' implies that plugin methods have been 
defined
#    based on the 'unprocessed' class names for signature arguments, i.e.
#    'signature(ns="mypkg", link="foo", mount="default", plugin="punct",
#       src="character")'
#    instead of
#    'signature(ns="API_mypkg", link="API_foo", mount="API_default",
#       plugin="API_punct", src="character")'
# 2) 'do.explicit.clss = TRUE' implies the use of the 'processed' class 
names
setMethod(
     f=pluginProcessRef,
     signature=c(.self="Plugin"),
     function(.self, do.explicit.clss=FALSE, ...){
         out <- NULL
         if(length(.self$ns)){
             if(!do.explicit.clss){
                 rgx.subst <- "API_"
                 ns <- gsub(rgx.subst, "", .self$ns)
                 names(ns) <- NULL
                 link <- gsub(rgx.subst, "", .self$link)
                 names(link) <- NULL
                 mount <- gsub(rgx.subst, "", .self$mount)
                 names(mount) <- NULL
                 plugin <- gsub(rgx.subst, "", .self$plugin)
                 names(plugin) <- NULL

                 if(!existsMethod(
                     f="pluginExecute",
                     signature=c(ns=ns, link=link, mount=mount, 
plugin=plugin,
                         src=class(.self$src))
                 )){
                     stop("Invalid plugin")
                 }
                 .pluginExecute <- selectMethod(
                     "pluginExecute",
                     signature=c(ns=ns, link=link, mount=mount, 
plugin=plugin,
                         src=class(.self$src)),
                     useInherited=c(ns=FALSE, link=FALSE, mount=FALSE, 
plugin=FALSE,
                         src=TRUE)
                 )
                 out <- .pluginExecute(src=.self$src)
             } else {
                 out <- pluginExecute(ns=new(.self$ns), 
link=new(.self$link),
                     mount=new(.self$mount), plugin=new(.self$plugin), 
src=.self$src)
             }
         }
         return(out)
     }
)

#+++++

# Define the actual plugin methods. For illustration, one using a implicit
# and the other using explicit class names notation for signature arguments.
# Unfortunately I don't know how to avoid warnings at this point; guess 
I can't
setMethod(f=pluginExecute, signature=c(ns="mypkg", link="objectModify",
         mount="default", plugin="punct",src="character"),
     function(ns, link, mount, plugin, src, ...){
         out <- gsub("[[:punct:]]", "", src)
     }
)
setMethod(f=pluginExecute, signature=c(ns="API_mypkg", 
link="API_objectModify",
         mount="API_default", plugin="API_digit", src="character"),
     function(ns, link, mount, plugin, src, ...){
         out <- gsub("[[:digit:]]", "", src)
     }
)
showMethods("pluginExecute")

#+++++

# Define the function/method that should be open for plugins
foo <- function(plugin=pluginObjectCreate(), do.explicit.clss=FALSE, ...){
     cat("Here: computations before plugin", sep="\n")
     cat(paste("Calling plugin '", class(plugin), "'", sep=""), sep="\n")
     out <- plugin$pluginProcess(do.explicit.clss=do.explicit.clss)
     cat("Here: computations after plugin", sep="\n")
     return(out)
}

#+++++

# Apply
foo()
foo( plugin=pluginObjectCreate(ns="mypkg", link="objectModify", 
mount="default",
     plugin="punct", src="string___123"))
foo(plugin=pluginObjectCreate(ns="mypkg", link="objectModify", 
mount="default",
         plugin="digit", src="string123"))
# No such plugin method as explicit class names have been used for 'digit
foo(plugin=pluginObjectCreate(ns="mypkg", link="objectModify", 
mount="default",
         plugin="digit", src="string123"), do.explicit.clss=TRUE)

# /APPROACH 6 r-devel ----------

On 24.08.2011 06:37, Martin Morgan wrote:
> On 08/23/2011 03:02 PM, Janko Thyson wrote:
>> Dear list,
>>
>> I was wondering how to best implement some sort of a "plugin" paradigm
>> using R methods and the dispatcher:
>> Say we have a function/method ('foo') that does something useful, but
>> that should be open for extension in ONE specific area by OTHERS using
>> my package. Of course they could go ahead and write a whole new 'foo'
>
> One possibility is to write class / method pairs. The classes extend 
> 'Plugin', and the methods are on generic 'plug', with the infrastructure
>
>   ## Approach 1: class / method pairs
>   setClass("Plugin")
>
>   setClass("DefaultPlugin", contains="Plugin")
>
>   DefaultPlugin <- function() new("DefaultPlugin")
>
>   setGeneric("plug",
>              function(plugin, src) standardGeneric("plug"),
>              signature="plugin",
>              valueClass="character")
>
>   setMethod(plug, "Plugin", function(plugin, src) {
>       src
>   })
>
>   foo <- function(src, plugin=DefaultPlugin()) {
>       plug(plugin, src)
>   }
>
> This is extended by writing class / method pairs
>
>   setClass("Punct", contains="Plugin")
>
>   Punct <- function() new("Punct")
>
>   setMethod(plug, "Punct", function(plugin, src) {
>       gsub("[[:punct:]]", "", src)
>   })
>
>
>   setClass("Digit", contains="Plugin")
>
>   Digit <- function() new("Digit")
>
>   setMethod(plug, "Digit", function(plugin, src) {
>       gsub("[[:digit:]]", "", src)
>   })
>
> The classes could have slots with state, accessible within the method. 
> An easier-on-the-user approach might have the Plugin class contain or 
> have slots of class "function". The user would only be obliged to 
> provide an appropriate function.
>
>   ## Approach 2:
>   setClass("Plugin", prototype=prototype(function(src) {
>       src
>   }), contains="function")
>
>   Plugin <- function() new("Plugin")
>
>   setGeneric("foo",
>              function(src, plugin) standardGeneric("foo"))
>
>   setMethod(foo, c("character", "missing"),
>             function(src, plugin) foo(src, Plugin()))
>
>   setMethod(foo, c("character", "Plugin"),
>             function(src, plugin) plugin(src))
>
>   ## 'Developer' classes
>   setClass("Punct", prototype=prototype(function(src) {
>       gsub("[[:punct:]]", "", src)
>   }), contains="Plugin")
>
>   Punct <- function() new("Punct")
>
>   setClass("Digit", prototype=prototype(function(src) {
>       gsub("[[:digit:]]", "", src)
>   }), contains="Plugin")
>
>   Digit <- function() new("Digit")
>
>   ## General-purpose 'user' class
>   setClass("User", contains="Plugin")
>
>   User <- function(fun) new("User", fun)
>
> This could have syntax checking in the validity method to catch some 
> mistakes early. In the S3 world, this is the approach taken by glm for 
> its 'family' argument, for instance str(gaussian().
>
> Martin
>
>> method including the features they'd like to see, but that's not really
>> necessary. Rather, they should be able to just write a new "plugin"
>> method for that part of 'foo' that I'd like to open for such plugins.
>>
>> The way I chose below works, but generates warnings as my method has
>> signature arguments that don't correspond to formal classes (which is
>> totally fine). Of course I could go ahead and make sure that such
>> "dummy" classes exist, but I was wondering if there's a better way.
>>
>> It'd be great if anyone could let me know how they handle "plugin"
>> scenarios based on some sort of method dispatch!
>>
>> Thanks,
>> Janko
>>
>> ##### CODE EXAMPLE #####
>>
>> setGeneric(name="foo", signature=c("src"), function(src, ...)
>> standardGeneric("foo"))
>> setGeneric(name="plugin", signature=c("src", "link", "plugin"),
>> function(src, link, plugin, ...) standardGeneric("plugin")
>> )
>> setMethod(f="plugin", signature=signature(src="character", link="foo",
>> plugin="punct"),
>> function(src, link, plugin, ...){
>> out <- gsub("[[:punct:]]", "", src)
>> return(out)
>> }
>> )
>> setMethod(f="plugin", signature=signature(src="character", link="foo",
>> plugin="digit"),
>> function(src, link, plugin, ...){
>> out <- gsub("[[:digit:]]", "", src)
>> return(out)
>> }
>> )
>> setMethod(f="foo", signature=signature(src="character"),
>> function(src, plugin=NULL, ...){
>> if(!is.null(plugin)){
>> if(!existsMethod(f="plugin",
>> signature=c(src=class(src), link="foo", plugin=plugin)
>> )){
>> stop("Invalid plugin")
>> }
>> .plugin <- selectMethod(
>> "plugin",
>> signature=c(src=class(src), link="foo", plugin=plugin),
>> useInherited=c(src=TRUE, plugin=FALSE)
>> )
>> out <- .plugin(src=src)
>> } else {
>> out <- paste("Hello world: ", src, sep="")
>> }
>> return(out)
>> }
>> )
>> foo(src="Teststring:-1234_56/")
>> foo(src="Teststring:-1234_56/", plugin="punct")
>> foo(src="Teststring:-1234_56/", plugin="digit")
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From simon.urbanek at r-project.org  Thu Aug 25 17:24:24 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 25 Aug 2011 16:24:24 +0100
Subject: [Rd] Licensing Issue with JRI
In-Reply-To: <CAOCX9Dm4fD6P200cgXhX0icHZw1Y2D+n2zgNQ797Di2dng=H_A@mail.gmail.com>
References: <CAOCX9Dm4fD6P200cgXhX0icHZw1Y2D+n2zgNQ797Di2dng=H_A@mail.gmail.com>
Message-ID: <D861327C-4091-4073-95F2-1FD8AF61AA21@r-project.org>


On Aug 19, 2011, at 10:26 PM, Lokkju Brennr wrote:

> Hoping someone can clear up a licencing question...
> 
> My understanding is that R is licensed under the GPL, with some
> headers licensed under the LGPL (per COPYRIGHTS, so that R plugins
> don't have to be GPL - arguably incorrect, but besides the point).
> JRI states that it is licensed under the LGPL - but it links against R
> shared libraries (or so is my understanding - please correct me if I'm
> wrong).
> This seems incompatible, as per
> (http://www.gnu.org/licenses/gpl-faq.html#GPLModuleLicense) if there
> is any GPL code in a compiled assembly, the resulting binary must be
> GPL, and per (http://www.gnu.org/licenses/gpl-faq.html#IfLibraryIsGPL)
> if a library is GPL, then anything that links against it must be GPL.
> 

IANAL, so please consult a lawyer, this doesn't constitute a legal advice, but there is nothing saying that JRI cannot be LGPL since it is not derived from GPL code. It uses a defined API (that is even released as LGPL but that's probably beside the point as you said). Obviously, if you use it with R then the whole will be covered by GPL and LGPL is GPL-compatible [http://www.gnu.org/licenses/license-list.html#GPLCompatibleLicenses ]. FWIW note that rJava - which is the distribution of JRI - is licensed as GPL.

Cheers,
Simon


From lokkju at gmail.com  Thu Aug 25 18:40:58 2011
From: lokkju at gmail.com (Lokkju Brennr)
Date: Thu, 25 Aug 2011 09:40:58 -0700
Subject: [Rd] Licensing Issue with JRI
In-Reply-To: <D861327C-4091-4073-95F2-1FD8AF61AA21@r-project.org>
References: <CAOCX9Dm4fD6P200cgXhX0icHZw1Y2D+n2zgNQ797Di2dng=H_A@mail.gmail.com>
	<D861327C-4091-4073-95F2-1FD8AF61AA21@r-project.org>
Message-ID: <CAOCX9DnPo9JRSLH7umT9cGK62Quuw66VQXp1mVL_HFA98oSVTg@mail.gmail.com>

Simon,

I wasn't trying to claim that JRI *couldn't* be licensed under LGPL
(though if it sounded that way, I understand - I was a bit unclear),
but rather that it made no sense, as there is no way to use JRI under
the LGPL, since it must always be linked with R to be of any use - and
that linking would cause the entire work to be under GPL.
rJava is a different beast entirely from JRI, though JRI is now
included with it - rJava allows R to call Java code, where as JRI
allows Java to call R.  They are separate code bases, and just happen
to be package together in the rJava release.

It looks like the solution to my conundrum (calling R from a non-GPL
compatible application) can be solved by using Rserve and the socket
API - but I still think the license on JRI is unclear, since it
advertises itself as LGPL, even though there is no way to make use of
it as such.

Loki

On Thu, Aug 25, 2011 at 8:24 AM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
>
> On Aug 19, 2011, at 10:26 PM, Lokkju Brennr wrote:
>
>> Hoping someone can clear up a licencing question...
>>
>> My understanding is that R is licensed under the GPL, with some
>> headers licensed under the LGPL (per COPYRIGHTS, so that R plugins
>> don't have to be GPL - arguably incorrect, but besides the point).
>> JRI states that it is licensed under the LGPL - but it links against R
>> shared libraries (or so is my understanding - please correct me if I'm
>> wrong).
>> This seems incompatible, as per
>> (http://www.gnu.org/licenses/gpl-faq.html#GPLModuleLicense) if there
>> is any GPL code in a compiled assembly, the resulting binary must be
>> GPL, and per (http://www.gnu.org/licenses/gpl-faq.html#IfLibraryIsGPL)
>> if a library is GPL, then anything that links against it must be GPL.
>>
>
> IANAL, so please consult a lawyer, this doesn't constitute a legal advice, but there is nothing saying that JRI cannot be LGPL since it is not derived from GPL code. It uses a defined API (that is even released as LGPL but that's probably beside the point as you said). Obviously, if you use it with R then the whole will be covered by GPL and LGPL is GPL-compatible [http://www.gnu.org/licenses/license-list.html#GPLCompatibleLicenses ]. FWIW note that rJava - which is the distribution of JRI - is licensed as GPL.
>
> Cheers,
> Simon
>
>


From simon.urbanek at r-project.org  Thu Aug 25 20:36:18 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 25 Aug 2011 19:36:18 +0100
Subject: [Rd] Licensing Issue with JRI
In-Reply-To: <CAOCX9DnPo9JRSLH7umT9cGK62Quuw66VQXp1mVL_HFA98oSVTg@mail.gmail.com>
References: <CAOCX9Dm4fD6P200cgXhX0icHZw1Y2D+n2zgNQ797Di2dng=H_A@mail.gmail.com>
	<D861327C-4091-4073-95F2-1FD8AF61AA21@r-project.org>
	<CAOCX9DnPo9JRSLH7umT9cGK62Quuw66VQXp1mVL_HFA98oSVTg@mail.gmail.com>
Message-ID: <8480CA0E-4F4F-4CF3-968B-EAAB8C11CCC2@r-project.org>


On Aug 25, 2011, at 5:40 PM, Lokkju Brennr wrote:

> Simon,
> 
> I wasn't trying to claim that JRI *couldn't* be licensed under LGPL
> (though if it sounded that way, I understand - I was a bit unclear),
> but rather that it made no sense, as there is no way to use JRI under
> the LGPL, since it must always be linked with R to be of any use - and
> that linking would cause the entire work to be under GPL.
> rJava is a different beast entirely from JRI, though JRI is now
> included with it - rJava allows R to call Java code, where as JRI
> allows Java to call R.  They are separate code bases, and just happen
> to be package together in the rJava release.
> 
> It looks like the solution to my conundrum (calling R from a non-GPL
> compatible application) can be solved by using Rserve and the socket
> API - but I still think the license on JRI is unclear, since it
> advertises itself as LGPL,

Which it is period. As you said yourself, there is no problem with that. 


> even though there is no way to make use of it as such.
> 

Since R is only one of several implementations of the same API you still have the choice to use it and it's just a matter of the license of the implementation of that API that you use. 

Cheers,
Simon


> 
> On Thu, Aug 25, 2011 at 8:24 AM, Simon Urbanek
> <simon.urbanek at r-project.org> wrote:
>> 
>> On Aug 19, 2011, at 10:26 PM, Lokkju Brennr wrote:
>> 
>>> Hoping someone can clear up a licencing question...
>>> 
>>> My understanding is that R is licensed under the GPL, with some
>>> headers licensed under the LGPL (per COPYRIGHTS, so that R plugins
>>> don't have to be GPL - arguably incorrect, but besides the point).
>>> JRI states that it is licensed under the LGPL - but it links against R
>>> shared libraries (or so is my understanding - please correct me if I'm
>>> wrong).
>>> This seems incompatible, as per
>>> (http://www.gnu.org/licenses/gpl-faq.html#GPLModuleLicense) if there
>>> is any GPL code in a compiled assembly, the resulting binary must be
>>> GPL, and per (http://www.gnu.org/licenses/gpl-faq.html#IfLibraryIsGPL)
>>> if a library is GPL, then anything that links against it must be GPL.
>>> 
>> 
>> IANAL, so please consult a lawyer, this doesn't constitute a legal advice, but there is nothing saying that JRI cannot be LGPL since it is not derived from GPL code. It uses a defined API (that is even released as LGPL but that's probably beside the point as you said). Obviously, if you use it with R then the whole will be covered by GPL and LGPL is GPL-compatible [http://www.gnu.org/licenses/license-list.html#GPLCompatibleLicenses ]. FWIW note that rJava - which is the distribution of JRI - is licensed as GPL.
>> 
>> Cheers,
>> Simon
>> 
>> 
> 
> 


From jds at dmu.dk  Fri Aug 26 13:23:43 2011
From: jds at dmu.dk (Jeremy David Silver)
Date: Fri, 26 Aug 2011 13:23:43 +0200
Subject: [Rd] matrix bands
Message-ID: <4E57823F.8010407@dmu.dk>

Dear R developers,

I was looking for a function analogous to base::diag() for getting and 
setting bands of a matrix. The closest I could find was Matrix::band(), 
but this was not exactly what I wanted for two reasons. Firstly, 
Matrix::band() returns a matrix rather than just the specified band. 
Secondly, Matrix::band() cannot be used for setting the values for a 
matrix band.

Setting or getting a matrix band could be of interest for sufficiently 
many users that you might consider including it in base R. 
Alternatively, something like this could be included in the Matrix package.

I have included two versions of these functions, a simple and naive 
version, and a more efficient version. The band index, n, is positive 
for bands above the diagonal and negative for bands below the diagonal.

Regards,
Jeremy Silver

###############################################

## less clear formulation - more efficient
band <- function(x,n = 0){
   dx <- dim(x)
   if(length(dx) != 2L)
     stop("only matrix bands can be accessed")

   max.dx <- max(dx)
   n <- as.integer(n)

   ij <- cbind(i = seq(1,max.dx) - n,
               j = seq(1,max.dx))
   ij <- ij[1 <= ij[,1] & ij[,1] <= dx[1] & 1 <= ij[,2] & ij[,2] <= 
dx[2],,drop=FALSE]

   if(nrow(ij) == 0)
     stop('cannot access this matrix band')

   x[ij]
}

'band<-' <- function(x,n = 0, value){
   dx <- dim(x)
   if(length(dx) != 2L)
     stop("only matrix bands can be replaced")

   max.dx <- max(dx)
   n <- as.integer(n)

   ij <- cbind(i = seq(1,max.dx) - n,
               j = seq(1,max.dx))
   ij <- ij[1 <= ij[,1] & ij[,1] <= dx[1] & 1 <= ij[,2] & ij[,2] <= 
dx[2],,drop=FALSE]

   if(nrow(ij) == 0)
     stop('cannot replace this matrix band')

   x[ij] <- value

   x
}

## simple, clear formulation - not very efficient
band2 <- function(x, n = 0) {
   x[col(x) - row(x) == as.integer(n)]
}

'band2<-' <- function(x, n = 0, value) {
   x[which(col(x) - row(x) == as.integer(n))] <- value
   x
}

## here are some examples to show that it works

## define a test matrix
 > A <- matrix(rnorm(12),3,4)
 > A
            [,1]       [,2]      [,3]       [,4]
[1,] -1.5560200  0.6452762  1.072565  0.1923451
[2,]  0.7940685  1.2441817  1.699486 -0.2998814
[3,] -0.7762252 -0.4824173 -0.981055 -0.9265627

## access some of the bands

 > band(A,1)
[1]  0.6452762  1.6994858 -0.9265627
 > band(A,-2)
[1] -0.7762252
 > band(A,2)
[1]  1.0725649 -0.2998814

## set one of the bands

 > band(A,2) <- 2:1
 > A
            [,1]       [,2]      [,3]       [,4]
[1,] -1.5560200  0.6452762  2.000000  0.1923451
[2,]  0.7940685  1.2441817  1.699486  1.0000000
[3,] -0.7762252 -0.4824173 -0.981055 -0.9265627

## another example - a single column

 > A <- matrix(1:10)
 > A
       [,1]
  [1,]    1
  [2,]    2
  [3,]    3
  [4,]    4
  [5,]    5
  [6,]    6
  [7,]    7
  [8,]    8
  [9,]    9
[10,]   10
 > band(A,0)
[1] 1
 > band(A,1)
Error in band(A, 1) : cannot access this matrix band
 > band(A,-1)
[1] 2
 > band(A,-5)
[1] 6

## compare the results from the two versions of the function

 > for(i in -2:3){print(band(A,i));print(band2(A,i))}
[1] -0.7762252
[1] -0.7762252
[1]  0.7940685 -0.4824173
[1]  0.7940685 -0.4824173
[1] -1.556020  1.244182 -0.981055
[1] -1.556020  1.244182 -0.981055
[1]  0.6452762  1.6994858 -0.9265627
[1]  0.6452762  1.6994858 -0.9265627
[1] 2 1
[1] 2 1
[1] 0.1923451
[1] 0.1923451

## show that the naive version is very slow for large matrices

 > N <- 1e4
 > M <- matrix(0,N,N)
 > system.time(band(M,2))
    user  system elapsed
   0.005   0.003   0.007
 > system.time(band2(M,2))
    user  system elapsed
  18.509   2.121  20.754


From gavin.simpson at ucl.ac.uk  Fri Aug 26 13:44:25 2011
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Fri, 26 Aug 2011 12:44:25 +0100
Subject: [Rd] methods() not listing some S3 plot methods...?
Message-ID: <1314359065.22902.12.camel@prometheus.geog.ucl.ac.uk>

Dear List,

This may be related to this email thread initiated by Ben Bolker last
month: https://stat.ethz.ch/pipermail/r-devel/2011-July/061630.html

In answering this Question on StackOverflow
http://stackoverflow.com/q/7195628/429846 I noticed that `methods()` was
not listing some S3 methods for `plot()` provided by the mgcv package.
At the time I wanted to check the development version of R as I recalled
Uwe mentioning that `plot.function` was listed by `methods()` there but
not in R2.13.x. I have now compiled the development version on two
Fedora installations and certain plot methods are still not being
listed. Details of the exact revision of R Devel are shown at the end of
this email.

As an example, consider:

> require(mgcv)
Loading required package: mgcv
This is mgcv 1.7-6. For overview type 'help("mgcv-package")'.
> methods("plot")
 [1] plot.acf*              plot.ACF*              plot.augPred*         
 [4] plot.compareFits*      plot.data.frame*       plot.decomposed.ts*   
 [7] plot.default           plot.dendrogram*       plot.density          
[10] plot.ecdf              plot.factor*           plot.formula*         
[13] plot.function          plot.gam               plot.gls*             
[16] plot.hclust*           plot.histogram*        plot.HoltWinters*     
[19] plot.intervals.lmList* plot.isoreg*           plot.lm               
[22] plot.lme*              plot.lmList*           plot.medpolish*       
[25] plot.mlm               plot.nffGroupedData*   plot.nfnGroupedData*  
[28] plot.nls*              plot.nmGroupedData*    plot.pdMat*           
[31] plot.ppr*              plot.prcomp*           plot.princomp*        
[34] plot.profile.nls*      plot.ranef.lme*        plot.ranef.lmList*    
[37] plot.shingle*          plot.simulate.lme*     plot.spec             
[40] plot.stepfun           plot.stl*              plot.table*           
[43] plot.trellis*          plot.ts                plot.tskernel*        
[46] plot.TukeyHSD          plot.Variogram*       

   Non-visible functions are asterisked

> pmeth <- methods("plot")
> grep("plot.mgcv.smooth", pmeth)
integer(0)
> getS3method("plot", "mgcv.smooth")
Error in getS3method("plot", "mgcv.smooth") : 
  S3 method 'plot.mgcv.smooth' not found
> pfun <- getAnywhere("plot.mgcv.smooth")
> str(pfun)
List of 5
 $ name   : chr "plot.mgcv.smooth"
 $ objs   :List of 1
  ..$ :function (x, P = NULL, data = NULL, label = "", se1.mult = 1, 
    se2.mult = 2, partial.resids = FALSE, rug = TRUE, se = TRUE, 
    scale = -1, n = 100, n2 = 40, pers = FALSE, theta = 30, phi = 30, 
    jit = FALSE, xlab = NULL, ylab = NULL, main = NULL, ylim = NULL, 
    xlim = NULL, too.far = 0.1, shade = FALSE, shade.col = "gray80", 
    shift = 0, trans = I, by.resids = FALSE, scheme = NULL, ...)  
 $ where  : chr "namespace:mgcv"
 $ visible: logi FALSE
 $ dups   : logi FALSE
 - attr(*, "class")= chr "getAnywhere"

Both `methods()` and `getS3method()` don't list/find this method, but
the function exists in the mgcv name space and this method will be used
via R's S3 dispatch system in `plot.gam()`.

Shouldn't this method be returned by either `methods()` or
`getS3method()`?

TIA,

Gavin

> sessionInfo()
R Under development (unstable) (2011-08-26 r56801)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_GB.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_GB.UTF-8        LC_COLLATE=en_GB.UTF-8    
 [5] LC_MONETARY=en_GB.UTF-8    LC_MESSAGES=en_GB.UTF-8   
 [7] LC_PAPER=C                 LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods
base     

other attached packages:
[1] mgcv_1.7-6

loaded via a namespace (and not attached):
[1] grid_2.14.0        lattice_0.19-33    Matrix_0.9996875-3
nlme_3.1-102      
[5] tools_2.14.0
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From maechler at stat.math.ethz.ch  Fri Aug 26 14:08:19 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 26 Aug 2011 14:08:19 +0200
Subject: [Rd] matrix bands
In-Reply-To: <4E57823F.8010407@dmu.dk>
References: <4E57823F.8010407@dmu.dk>
Message-ID: <20055.36019.732209.391727@stat.math.ethz.ch>

>>>>> Jeremy David Silver <jds at dmu.dk>
>>>>>     on Fri, 26 Aug 2011 13:23:43 +0200 writes:

    > Dear R developers, I was looking for a function analogous
    > to base::diag() for getting and setting bands of a
    > matrix. The closest I could find was Matrix::band(), but
    > this was not exactly what I wanted for two
    > reasons. Firstly, Matrix::band() returns a matrix rather
    > than just the specified band.  Secondly, Matrix::band()
    > cannot be used for setting the values for a matrix band.

Yes, but did you not look at  help(band)
or not look carefully enough ?

--->

  See Also:

       ?bandSparse? for the _construction_ of a banded sparse matrix
       directly from its non-zero diagonals.



    > Setting or getting a matrix band could be of interest for
    > sufficiently many users that you might consider including
    > it in base R.  Alternatively, something like this could be
    > included in the Matrix package.

well, see above and let us know if you see anything lacking in
bandSparse().
Till now we haven't got much feedback about it, and there may
well be room for improvement.

Martin Maechler, ETH Zurich  and co- maintainer("Matrix")


    > I have included two versions of these functions, a simple
    > and naive version, and a more efficient version. The band
    > index, n, is positive for bands above the diagonal and
    > negative for bands below the diagonal.

    > Regards, Jeremy Silver

    > ###############################################

## less clear formulation - more efficient
    > band <- function(x,n = 0){ dx <- dim(x) if(length(dx) !=
    > 2L) stop("only matrix bands can be accessed")

    >    max.dx <- max(dx) n <- as.integer(n)

    >    ij <- cbind(i = seq(1,max.dx) - n, j = seq(1,max.dx))
    > ij <- ij[1 <= ij[,1] & ij[,1] <= dx[1] & 1 <= ij[,2] &
    > ij[,2] <= dx[2],,drop=FALSE]

    >    if(nrow(ij) == 0) stop('cannot access this matrix
    > band')

    >    x[ij] }

    > 'band<-' <- function(x,n = 0, value){ dx <- dim(x)
    > if(length(dx) != 2L) stop("only matrix bands can be
    > replaced")

    >    max.dx <- max(dx) n <- as.integer(n)

    >    ij <- cbind(i = seq(1,max.dx) - n, j = seq(1,max.dx))
    > ij <- ij[1 <= ij[,1] & ij[,1] <= dx[1] & 1 <= ij[,2] &
    > ij[,2] <= dx[2],,drop=FALSE]

    >    if(nrow(ij) == 0) stop('cannot replace this matrix
    > band')

    >    x[ij] <- value

    >    x }

    > ## simple, clear formulation - not very efficient band2 <-
    > function(x, n = 0) { x[col(x) - row(x) == as.integer(n)] }

    > 'band2<-' <- function(x, n = 0, value) { x[which(col(x) -
    > row(x) == as.integer(n))] <- value x }

    > ## here are some examples to show that it works

    > ## define a test matrix
    >> A <- matrix(rnorm(12),3,4) A
    >             [,1] [,2] [,3] [,4] [1,] -1.5560200 0.6452762
    > 1.072565 0.1923451 [2,] 0.7940685 1.2441817 1.699486
    > -0.2998814 [3,] -0.7762252 -0.4824173 -0.981055 -0.9265627

    > ## access some of the bands

    >> band(A,1)
    > [1] 0.6452762 1.6994858 -0.9265627
    >> band(A,-2)
    > [1] -0.7762252
    >> band(A,2)
    > [1] 1.0725649 -0.2998814

    > ## set one of the bands

    >> band(A,2) <- 2:1 A
    >             [,1] [,2] [,3] [,4] [1,] -1.5560200 0.6452762
    > 2.000000 0.1923451 [2,] 0.7940685 1.2441817 1.699486
    > 1.0000000 [3,] -0.7762252 -0.4824173 -0.981055 -0.9265627

    > ## another example - a single column

    >> A <- matrix(1:10) A
    >        [,1] [1,] 1 [2,] 2 [3,] 3 [4,] 4 [5,] 5 [6,] 6 [7,]
    > 7 [8,] 8 [9,] 9 [10,] 10
    >> band(A,0)
    > [1] 1
    >> band(A,1)
    > Error in band(A, 1) : cannot access this matrix band
    >> band(A,-1)
    > [1] 2
    >> band(A,-5)
    > [1] 6

    > ## compare the results from the two versions of the
    > function

    >> for(i in -2:3){print(band(A,i));print(band2(A,i))}
    > [1] -0.7762252 [1] -0.7762252 [1] 0.7940685 -0.4824173 [1]
    > 0.7940685 -0.4824173 [1] -1.556020 1.244182 -0.981055 [1]
    > -1.556020 1.244182 -0.981055 [1] 0.6452762 1.6994858
    > -0.9265627 [1] 0.6452762 1.6994858 -0.9265627 [1] 2 1 [1]
    > 2 1 [1] 0.1923451 [1] 0.1923451

    > ## show that the naive version is very slow for large
    > matrices

    >> N <- 1e4 M <- matrix(0,N,N) system.time(band(M,2))
    >     user system elapsed 0.005 0.003 0.007
    >> system.time(band2(M,2))
    >     user system elapsed 18.509 2.121 20.754

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From jds at dmu.dk  Fri Aug 26 15:08:03 2011
From: jds at dmu.dk (Jeremy David Silver)
Date: Fri, 26 Aug 2011 15:08:03 +0200
Subject: [Rd] matrix bands
In-Reply-To: <20055.36019.732209.391727@stat.math.ethz.ch>
References: <4E57823F.8010407@dmu.dk>
	<20055.36019.732209.391727@stat.math.ethz.ch>
Message-ID: <4E579AB3.8040305@dmu.dk>

Thanks for the suggestion, Martin!

I looked at both Matrix::band and Matrix::bandSparse. Maybe I 
misunderstand the help pages and the examples, but from what I can see 
neither of them provides the functionality I was looking for.

For the getter version of the function I was looking for, I can't use 
Matrix::band (by extracting the non-zero elements) because this would 
require the assumption that the specified band is entirely non-zero, e.g.:

band3 <- function(x,n){
   x <- Matrix::band(x,n,n)
   x[x!=0] ## works for a dense matrix, but not if band n has zeroes
}

As for the setter version of the function I was looking for, it should 
set the values of a specified band in an existing matrix to be the 
vector of values provided. As far as I understand, Matrix::bandSparse 
constructs a matrix rather than modifying the values of an existing matrix.

The functions included in my last post filled this gap. If Matrix::band 
and Matrix::bandSparse can set/get bands in this way, I would like to 
see how this can be done. If not, then perhaps they could be extended to 
achieve this functionality.


On 2011-08-26 14:08, Martin Maechler wrote:
>>>>>> Jeremy David Silver<jds at dmu.dk>
>>>>>>      on Fri, 26 Aug 2011 13:23:43 +0200 writes:
>      >  Dear R developers, I was looking for a function analogous
>      >  to base::diag() for getting and setting bands of a
>      >  matrix. The closest I could find was Matrix::band(), but
>      >  this was not exactly what I wanted for two
>      >  reasons. Firstly, Matrix::band() returns a matrix rather
>      >  than just the specified band.  Secondly, Matrix::band()
>      >  cannot be used for setting the values for a matrix band.
>
> Yes, but did you not look at  help(band)
> or not look carefully enough ?
>
> --->
>
>    See Also:
>
>         ?bandSparse? for the _construction_ of a banded sparse matrix
>         directly from its non-zero diagonals.
>
>
>
>      >  Setting or getting a matrix band could be of interest for
>      >  sufficiently many users that you might consider including
>      >  it in base R.  Alternatively, something like this could be
>      >  included in the Matrix package.
>
> well, see above and let us know if you see anything lacking in
> bandSparse().
> Till now we haven't got much feedback about it, and there may
> well be room for improvement.
>
> Martin Maechler, ETH Zurich  and co- maintainer("Matrix")
>


From mtmorgan at fhcrc.org  Fri Aug 26 16:06:49 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Fri, 26 Aug 2011 07:06:49 -0700
Subject: [Rd] methods() not listing some S3 plot methods...?
In-Reply-To: <1314359065.22902.12.camel@prometheus.geog.ucl.ac.uk>
References: <1314359065.22902.12.camel@prometheus.geog.ucl.ac.uk>
Message-ID: <4E57A879.1040601@fhcrc.org>

On 08/26/2011 04:44 AM, Gavin Simpson wrote:
> Dear List,
>
> This may be related to this email thread initiated by Ben Bolker last
> month: https://stat.ethz.ch/pipermail/r-devel/2011-July/061630.html
>
> In answering this Question on StackOverflow
> http://stackoverflow.com/q/7195628/429846 I noticed that `methods()` was
> not listing some S3 methods for `plot()` provided by the mgcv package.

Hi Gavin --

In the mgcv NAMESPACE, the methods is not registered with S3method 
(which would have made it appear with a *) and is not export'ed; the 
author of the package apparently intends that it be strictly internal to 
the package. Dispatch works within the package name space, but not 
outside, e.g., a=list; class(a) = "mgcv.smooth"; plot(a) ends up at 
plot.default.

> At the time I wanted to check the development version of R as I recalled
> Uwe mentioning that `plot.function` was listed by `methods()` there but
> not in R2.13.x. I have now compiled the development version on two

It looks like the cog that has changed between release and devel is the 
addition of export(plot.function) and S3method(plot, "function") to the 
NAMESPACE of graphics.

Martin

> Fedora installations and certain plot methods are still not being
> listed. Details of the exact revision of R Devel are shown at the end of
> this email.
>
> As an example, consider:
>
>> require(mgcv)
> Loading required package: mgcv
> This is mgcv 1.7-6. For overview type 'help("mgcv-package")'.
>> methods("plot")
>   [1] plot.acf*              plot.ACF*              plot.augPred*
>   [4] plot.compareFits*      plot.data.frame*       plot.decomposed.ts*
>   [7] plot.default           plot.dendrogram*       plot.density
> [10] plot.ecdf              plot.factor*           plot.formula*
> [13] plot.function          plot.gam               plot.gls*
> [16] plot.hclust*           plot.histogram*        plot.HoltWinters*
> [19] plot.intervals.lmList* plot.isoreg*           plot.lm
> [22] plot.lme*              plot.lmList*           plot.medpolish*
> [25] plot.mlm               plot.nffGroupedData*   plot.nfnGroupedData*
> [28] plot.nls*              plot.nmGroupedData*    plot.pdMat*
> [31] plot.ppr*              plot.prcomp*           plot.princomp*
> [34] plot.profile.nls*      plot.ranef.lme*        plot.ranef.lmList*
> [37] plot.shingle*          plot.simulate.lme*     plot.spec
> [40] plot.stepfun           plot.stl*              plot.table*
> [43] plot.trellis*          plot.ts                plot.tskernel*
> [46] plot.TukeyHSD          plot.Variogram*
>
>     Non-visible functions are asterisked
>
>> pmeth<- methods("plot")
>> grep("plot.mgcv.smooth", pmeth)
> integer(0)
>> getS3method("plot", "mgcv.smooth")
> Error in getS3method("plot", "mgcv.smooth") :
>    S3 method 'plot.mgcv.smooth' not found
>> pfun<- getAnywhere("plot.mgcv.smooth")
>> str(pfun)
> List of 5
>   $ name   : chr "plot.mgcv.smooth"
>   $ objs   :List of 1
>    ..$ :function (x, P = NULL, data = NULL, label = "", se1.mult = 1,
>      se2.mult = 2, partial.resids = FALSE, rug = TRUE, se = TRUE,
>      scale = -1, n = 100, n2 = 40, pers = FALSE, theta = 30, phi = 30,
>      jit = FALSE, xlab = NULL, ylab = NULL, main = NULL, ylim = NULL,
>      xlim = NULL, too.far = 0.1, shade = FALSE, shade.col = "gray80",
>      shift = 0, trans = I, by.resids = FALSE, scheme = NULL, ...)
>   $ where  : chr "namespace:mgcv"
>   $ visible: logi FALSE
>   $ dups   : logi FALSE
>   - attr(*, "class")= chr "getAnywhere"
>
> Both `methods()` and `getS3method()` don't list/find this method, but
> the function exists in the mgcv name space and this method will be used
> via R's S3 dispatch system in `plot.gam()`.
>
> Shouldn't this method be returned by either `methods()` or
> `getS3method()`?
>
> TIA,
>
> Gavin
>
>> sessionInfo()
> R Under development (unstable) (2011-08-26 r56801)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>   [1] LC_CTYPE=en_GB.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_GB.UTF-8        LC_COLLATE=en_GB.UTF-8
>   [5] LC_MONETARY=en_GB.UTF-8    LC_MESSAGES=en_GB.UTF-8
>   [7] LC_PAPER=C                 LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods
> base
>
> other attached packages:
> [1] mgcv_1.7-6
>
> loaded via a namespace (and not attached):
> [1] grid_2.14.0        lattice_0.19-33    Matrix_0.9996875-3
> nlme_3.1-102
> [5] tools_2.14.0


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From maechler at stat.math.ethz.ch  Fri Aug 26 18:11:02 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 26 Aug 2011 18:11:02 +0200
Subject: [Rd] matrix bands
In-Reply-To: <4E579AB3.8040305@dmu.dk>
References: <4E57823F.8010407@dmu.dk>
	<20055.36019.732209.391727@stat.math.ethz.ch>
	<4E579AB3.8040305@dmu.dk>
Message-ID: <20055.50582.165120.831467@stat.math.ethz.ch>

>>>>> Jeremy David Silver <jds at dmu.dk>
>>>>>     on Fri, 26 Aug 2011 15:08:03 +0200 writes:

    > Thanks for the suggestion, Martin!  I looked at both
    > Matrix::band and Matrix::bandSparse. Maybe I misunderstand the
    > help pages and the examples, but from what I can see neither of
    > them provides the functionality I was looking for.

    > For the getter version of the function I was looking for, I
    > can't use Matrix::band (by extracting the non-zero elements)
    > because this would require the assumption that the specified
    > band is entirely non-zero, e.g.:

>     band3 <- function(x,n){
>        x <- Matrix::band(x,n,n)
>        x[x!=0] ## works for a dense matrix, but not if band n has zeroes
>     }

> As for the setter version of the function I was looking for, it should 
> set the values of a specified band in an existing matrix to be the 
> vector of values provided. As far as I understand, Matrix::bandSparse 
> constructs a matrix rather than modifying the values of an existing matrix.

Yes, you are right.  The current bandSparse() doesn't do that...
and while you could use constructions like  
    diag(A[,-1]) <- dd
there will probably better (more efficient) alternatives.

> The functions included in my last post filled this gap. If Matrix::band 
> and Matrix::bandSparse can set/get bands in this way, I would like to 
> see how this can be done. If not, then perhaps they could be extended to 
> achieve this functionality.

That's a good suggestion, and I'll look at it,
further I'll look at your examples of "getting" ... 
and at the moment I'm still a bit curious why, i.e., to what end
/ in what application you need them [ rather than  band(*,.,.) ].
We may e-talk about this off-public if you want.

Martin


> On 2011-08-26 14:08, Martin Maechler wrote:
> >>>>>> Jeremy David Silver<jds at dmu.dk>
> >>>>>>      on Fri, 26 Aug 2011 13:23:43 +0200 writes:
> >      >  Dear R developers, I was looking for a function analogous
> >      >  to base::diag() for getting and setting bands of a
> >      >  matrix. The closest I could find was Matrix::band(), but
> >      >  this was not exactly what I wanted for two
> >      >  reasons. Firstly, Matrix::band() returns a matrix rather
> >      >  than just the specified band.  Secondly, Matrix::band()
> >      >  cannot be used for setting the values for a matrix band.
> >
> > Yes, but did you not look at  help(band)
> > or not look carefully enough ?
> >
> > --->
> >
> >    See Also:
> >
> >         ?bandSparse? for the _construction_ of a banded sparse matrix
> >         directly from its non-zero diagonals.
> >
> >
> >
> >      >  Setting or getting a matrix band could be of interest for
> >      >  sufficiently many users that you might consider including
> >      >  it in base R.  Alternatively, something like this could be
> >      >  included in the Matrix package.
> >
> > well, see above and let us know if you see anything lacking in
> > bandSparse().
> > Till now we haven't got much feedback about it, and there may
> > well be room for improvement.
> >
> > Martin Maechler, ETH Zurich  and co- maintainer("Matrix")


From goran.brostrom at gmail.com  Fri Aug 26 21:28:22 2011
From: goran.brostrom at gmail.com (=?UTF-8?B?R8O2cmFuIEJyb3N0csO2bQ==?=)
Date: Fri, 26 Aug 2011 21:28:22 +0200
Subject: [Rd] read.table segfaults
Message-ID: <CAJxcB8mtJ_B=vLm5FSGLpqaN0V1ttKFzLaiBw+mUijBP0wzEyA@mail.gmail.com>

 > fil2s <- read.table("../Data/fil2_s.txt", header = FALSE, sep = "\t")

Program received signal SIGSEGV, Segmentation fault.
0x000000000041c2e1 in RunGenCollect (size_needed=8192000) at memory.c:1514
1514	    PROCESS_NODES();
(gdb)

 > sessionInfo()
R version 2.13.1 Patched (2011-08-25 r56798)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base
 >

The text file 'fil2_s.txt' is Huge, around 11 million records and 17
variables, but ...?



-- 
G?ran Brostr?m


From goran.brostrom at gmail.com  Fri Aug 26 22:10:05 2011
From: goran.brostrom at gmail.com (=?UTF-8?B?R8O2cmFuIEJyb3N0csO2bQ==?=)
Date: Fri, 26 Aug 2011 22:10:05 +0200
Subject: [Rd] read.table segfaults
In-Reply-To: <CAJxcB8mtJ_B=vLm5FSGLpqaN0V1ttKFzLaiBw+mUijBP0wzEyA@mail.gmail.com>
References: <CAJxcB8mtJ_B=vLm5FSGLpqaN0V1ttKFzLaiBw+mUijBP0wzEyA@mail.gmail.com>
Message-ID: <CAJxcB8nLnw1j_xhS7bFNQhxNdP2xXU0fev=1ZNNg60HJfg0tbw@mail.gmail.com>

Another one:

The 'death.RData' was created about a year ago, but ...? Same info as below.

G?ran

> load("../Data/death.RData")
> summary(death)

 *** caught segfault ***
address 0x40000e04959, cause 'memory not mapped'

Traceback:
 1: match(x, levels)
 2: factor(a, levels = ll[!(ll %in% exclude)], exclude = if (useNA ==
   "no") NA)
 3: table(object)
 4: summary.factor(X[[6L]], ...)
 5: FUN(X[[6L]], ...)
 6: lapply(as.list(object), summary, maxsum = maxsum, digits = 12,     ...)
 7: summary.data.frame(death)
 8: summary(death)

Possible actions:
1: abort (with core dump, if enabled)
2: normal R exit
3: exit R without saving workspace
4: exit R saving workspace
Selection:


2011/8/26 G?ran Brostr?m <goran.brostrom at gmail.com>:
> ?> fil2s <- read.table("../Data/fil2_s.txt", header = FALSE, sep = "\t")
>
> Program received signal SIGSEGV, Segmentation fault.
> 0x000000000041c2e1 in RunGenCollect (size_needed=8192000) at memory.c:1514
> 1514 ? ? ? ?PROCESS_NODES();
> (gdb)
>
> ?> sessionInfo()
> R version 2.13.1 Patched (2011-08-25 r56798)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
> ?[1] LC_CTYPE=en_US.UTF-8 ? ? ? LC_NUMERIC=C
> ?[3] LC_TIME=en_US.UTF-8 ? ? ? ?LC_COLLATE=en_US.UTF-8
> ?[5] LC_MONETARY=C ? ? ? ? ? ? ?LC_MESSAGES=en_US.UTF-8
> ?[7] LC_PAPER=en_US.UTF-8 ? ? ? LC_NAME=C
> ?[9] LC_ADDRESS=C ? ? ? ? ? ? ? LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
> ?>
>
> The text file 'fil2_s.txt' is Huge, around 11 million records and 17
> variables, but ...?
>
>
>
> --
> G?ran Brostr?m
>



-- 
G?ran Brostr?m


From goran.brostrom at gmail.com  Fri Aug 26 22:16:01 2011
From: goran.brostrom at gmail.com (=?UTF-8?B?R8O2cmFuIEJyb3N0csO2bQ==?=)
Date: Fri, 26 Aug 2011 22:16:01 +0200
Subject: [Rd] read.table segfaults
In-Reply-To: <CAJxcB8nLnw1j_xhS7bFNQhxNdP2xXU0fev=1ZNNg60HJfg0tbw@mail.gmail.com>
References: <CAJxcB8mtJ_B=vLm5FSGLpqaN0V1ttKFzLaiBw+mUijBP0wzEyA@mail.gmail.com>
	<CAJxcB8nLnw1j_xhS7bFNQhxNdP2xXU0fev=1ZNNg60HJfg0tbw@mail.gmail.com>
Message-ID: <CAJxcB8nXiyoXtj=avOhfHoXV8+Ae2wJb6YoOkZhEU6XFtnNpUg@mail.gmail.com>

One further note:

No problem with  R version 2.13.0 (2011-04-13)

G?ran

2011/8/26 G?ran Brostr?m <goran.brostrom at gmail.com>:
> Another one:
>
> The 'death.RData' was created about a year ago, but ...? Same info as below.
>
> G?ran
>
>> load("../Data/death.RData")
>> summary(death)
>
> ?*** caught segfault ***
> address 0x40000e04959, cause 'memory not mapped'
>
> Traceback:
> ?1: match(x, levels)
> ?2: factor(a, levels = ll[!(ll %in% exclude)], exclude = if (useNA ==
> ? "no") NA)
> ?3: table(object)
> ?4: summary.factor(X[[6L]], ...)
> ?5: FUN(X[[6L]], ...)
> ?6: lapply(as.list(object), summary, maxsum = maxsum, digits = 12, ? ? ...)
> ?7: summary.data.frame(death)
> ?8: summary(death)
>
> Possible actions:
> 1: abort (with core dump, if enabled)
> 2: normal R exit
> 3: exit R without saving workspace
> 4: exit R saving workspace
> Selection:
>
>
> 2011/8/26 G?ran Brostr?m <goran.brostrom at gmail.com>:
>> ?> fil2s <- read.table("../Data/fil2_s.txt", header = FALSE, sep = "\t")
>>
>> Program received signal SIGSEGV, Segmentation fault.
>> 0x000000000041c2e1 in RunGenCollect (size_needed=8192000) at memory.c:1514
>> 1514 ? ? ? ?PROCESS_NODES();
>> (gdb)
>>
>> ?> sessionInfo()
>> R version 2.13.1 Patched (2011-08-25 r56798)
>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>
>> locale:
>> ?[1] LC_CTYPE=en_US.UTF-8 ? ? ? LC_NUMERIC=C
>> ?[3] LC_TIME=en_US.UTF-8 ? ? ? ?LC_COLLATE=en_US.UTF-8
>> ?[5] LC_MONETARY=C ? ? ? ? ? ? ?LC_MESSAGES=en_US.UTF-8
>> ?[7] LC_PAPER=en_US.UTF-8 ? ? ? LC_NAME=C
>> ?[9] LC_ADDRESS=C ? ? ? ? ? ? ? LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>> ?>
>>
>> The text file 'fil2_s.txt' is Huge, around 11 million records and 17
>> variables, but ...?
>>
>>
>>
>> --
>> G?ran Brostr?m
>>
>
>
>
> --
> G?ran Brostr?m
>



-- 
G?ran Brostr?m


From ncbi2r at googlemail.com  Fri Aug 26 21:41:37 2011
From: ncbi2r at googlemail.com (Scott)
Date: Fri, 26 Aug 2011 12:41:37 -0700 (PDT)
Subject: [Rd] read.table segfaults
In-Reply-To: <CAJxcB8mtJ_B=vLm5FSGLpqaN0V1ttKFzLaiBw+mUijBP0wzEyA@mail.gmail.com>
References: <CAJxcB8mtJ_B=vLm5FSGLpqaN0V1ttKFzLaiBw+mUijBP0wzEyA@mail.gmail.com>
Message-ID: <1314387697378-3771817.post@n4.nabble.com>

It does look like you've got a memory issue. perhaps using 
  as.is=TRUE, and/or stringsAsFactors=FALSE will help as optional arguments
to read.table

if you don't specify these sorts of things, R can have to look through the
file and figure out which columns are characters/factors etc and so the
larger files cause more of a headache for R I'm guess. Hopefully someone
else can comment further on this? I'd true toggling TRUE/FALSE for as.is and
stringsAsFactors.

   do you have other objects loaded in memory as well? this file by itself
might not be the problem - but it's a cumulative issue. 
   have you checked the file structure in any other manner?
   how large (Mb/kb) is the file that you're trying to read?
   if you just read in parts of the file, is it okay?
      read.table(filename,header=FALSE,sep="\t",nrows=100)
      read.table(filename,header=FALSE,sep="\t",skip=20000,nrows=100)



--
View this message in context: http://r.789695.n4.nabble.com/read-table-segfaults-tp3771793p3771817.html
Sent from the R devel mailing list archive at Nabble.com.


From vandita at iirs.gov.in  Fri Aug 26 14:44:50 2011
From: vandita at iirs.gov.in (Vandita Srivastava)
Date: Fri, 26 Aug 2011 19:14:50 +0630
Subject: [Rd] Problem in calling R functions from Matlab
Message-ID: <20110826124450.M4165@iirs.gov.in>

Hi,

I wish to use R (version 2.13.1)?from within Matlab(ver R2009a) on windows XP plaform (on both 64 bit and 32 bit OS) . For this I have installed StatConnector (http://rcom.univie.ac.at/download/current/statconnDCOM.latest.exe) for calling R from within Matlab (R2009a) on Windows XP platform. I have added all the files of MATLAB_RLINK folder (downloaded from http://www.mathworks.com/matlabcentral/fileexchange/5051) into the default?Matlab working path?(D:\User\MATLAB) and also added the folder MATLAB_RLINK to the matlab path C:\Program Files\MATLAB\R2009a\toolbox . It seems that Matlab is able to connect to R however I am facing a problem while trying to call R functions from within Matlab. I have loaded all required libraries. Shown below is the sequence of commands tried in blue, outcomes in black and errors/unexpected/ undesired outcomes in red colour, and my comments in black,italic ?after the command:

>> [a b c] = openR

a =???? 1

b =???? ''

c =???? COM.StatConnectorSrv_StatConnector

>> Rdemo

b =???? 1???? 4???? 9??? 16??? 25??? 36??? 49??? 64??? 81?? 100

c =???? 2???? 5??? 10??? 17??? 26??? 37??? 50??? 65??? 82?? 101

I then tried running the Rdemo available on http://www.mathworks.com/matlabcentral/fx_files/5051/1/content/Rdemo.html

evalR('demo("persp")') works well. Also the arithmetic functions all work well:

a = 1:10;

putRdata('a',a)

b = evalR('a^2')

evalR('b <- a^2');

evalR('c <- b + 1');

c = getRdata('c')

However ?Now copy the volcano data into MATLAB? section and all related sessions therefore don?t work.

>> volcano = getRdata('volcano')

volcano =???? []

>> size(volcano)

ans =???? 0???? 0

>> surf(volcano);

(see the attached figure:surf_volcano_output.jpg)

It seems Matlab is able to read/get data from R. Other subsequent commands related to this section don?t work.

I tried looking at the loaded libraries in R and in Matlab. In R everything works well, but doesn?t seem to be so in Matlab:

>> [a b c] = evalR('.libPaths()')

a = C:/Program Files/R/R-2.13.1/library

b =???? 1

c = ?????''

>> [a b c] = evalR('library()')

a = ??'ActiveX VT_ERROR: '

??? 'base'

??? 'ActiveX VT_ERROR: '

b =???? 1

c =???? ''

>> [a b c] = evalR('library(rgdal)')

a = 'rscproxy'

??? 'lattice'

??? 'fields'

??? 'spam'

??? 'rgdal'

??? 'sp'

??? 'stats'

??? 'graphics'

??? 'grDevices'

??? 'utils'

??? 'datasets'

??? 'methods'

??? 'base'

b =???? 1

c =???? ''

As it shows that rgdal library is loaded, also the rscproxy library is loaded, in addition to all others. I tried following:

imshow(imread('testimg_p.tif')) displays the image properly, however calling this from R using rgdal from within Matlab gives error;

>> [a b c] = evalR('img <- readGDAL("testimg_p.tif")')

a = ?????[]

b = ?????0

c = Invoke Error, Dispatch Exception: Object is static; operation not allowed

The command works from R prompt:

> img <- readGDAL("testimg_p.tif") 
testimg_p.tif has GDAL driver GTiff 
and has 280 rows and 272 columns

It is giving same error while loading gstat library:

>> [a b c] = evalR('library(gstat) ')

a =???? []

b =???? 0

c = Invoke Error, Dispatch Exception: Object is static; operation not allowed

I guess the error is not related to readGDAL or gstat library but something else which I am unable to trace. I have also tried to explore if this is problem related to version of Matlab/windows 64/32 bit or R version but even that does not seem to be an issue. (I have tried this on two differemt machines one Workstation with?WinXP 64 bit OS?with R version 2.13.1and Matlab Version 7.8.0 R2009a and also?on another?portable workstation with?WinXP 32 bit?OS with R version 2.12.1 and Matlab Version 7.8.0 R2009a. This indicates that version of R or Matlab or win version 64 bit/32 bit does not seem to be an issue.

I also checked for some solution on page http://www.mathworks.com/matlabcentral/fileexchange/5051 where others also faced somewhat similar problem and it was suggested to check for setting R_HOME and PATH variables in the environment variables for your system. I understand I had followed all instructions carefully and hopefully all paths/R_HOME were set correctly, as the command evalR('.libPaths()') recognized R home path correctly. ?

I request R team to help.

Vandita Srivastava 
Scientist/Engineer "SE", 
Indian Institute of Remote Sensing(NRSC), 
ISRO/Department of Space, Govt. of India

>>Please don't print this Email unless you really need to - this will preserve trees 
on planet earth.

?

?

?

?

?

?

?

 

From lawrence.michael at gene.com  Fri Aug 26 23:47:21 2011
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Fri, 26 Aug 2011 14:47:21 -0700
Subject: [Rd] S3 methods in default namespace
Message-ID: <CAOQ5Nyd8bWX7Vh=Y5dXPAPLR3JVpu07XQw1=+sdWnbMebW_QuQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110826/92d81ce1/attachment.pl>

From bbolker at gmail.com  Fri Aug 26 23:55:51 2011
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 26 Aug 2011 21:55:51 +0000
Subject: [Rd] read.table segfaults
References: <CAJxcB8mtJ_B=vLm5FSGLpqaN0V1ttKFzLaiBw+mUijBP0wzEyA@mail.gmail.com>
	<1314387697378-3771817.post@n4.nabble.com>
Message-ID: <loom.20110826T234733-73@post.gmane.org>

Scott <ncbi2r <at> googlemail.com> writes:

> 
> It does look like you've got a memory issue. perhaps using 
>   as.is=TRUE, and/or stringsAsFactors=FALSE will help as optional arguments
> to read.table
> 
> if you don't specify these sorts of things, R can have to look through the
> file and figure out which columns are characters/factors etc and so the
> larger files cause more of a headache for R I'm guess. Hopefully someone
> else can comment further on this? I'd true toggling TRUE/FALSE for as.is and
> stringsAsFactors.
> 
>    do you have other objects loaded in memory as well? this file by itself
> might not be the problem - but it's a cumulative issue. 
>    have you checked the file structure in any other manner?
>    how large (Mb/kb) is the file that you're trying to read?
>    if you just read in parts of the file, is it okay?
>       read.table(filename,header=FALSE,sep="\t",nrows=100)
>       read.table(filename,header=FALSE,sep="\t",skip=20000,nrows=100)

  There seem to be two issues here:

1. what can the original poster (OP) do to work around this problem?
(e.g. get the data into a relational data base and import it from 
there; use something from the High Performance task view such as
ff or data.table ...)

2. reporting a bug -- according to the R FAQ, any low-level
(segmentation-fault-type) crash of R when one is not messing
around with dynamically loaded code constitutes a bug. Unfortunately,
debugging problems like this is a huge pain in the butt.

  Goran, can you randomly or systematically generate an
object of this size, write it to disk, read it back in, and
generate the same error?  In other words, does something like

set.seed(1001)
d <- data.frame(label=rep(LETTERS[1:11],1e6),
                values=matrix(rep(1.0,11*17*1e6),ncol=17)
write.table(d,file="big.txt")
read.table("big.txt")

do the same thing?

Reducing it to this kind of reproducible example will make
it possible for others to debug it without needing to gain
access to your huge file ...


From gavin.simpson at ucl.ac.uk  Sat Aug 27 00:17:03 2011
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Fri, 26 Aug 2011 23:17:03 +0100
Subject: [Rd] methods() not listing some S3 plot methods...?
In-Reply-To: <4E57A879.1040601@fhcrc.org>
References: <1314359065.22902.12.camel@prometheus.geog.ucl.ac.uk>
	<4E57A879.1040601@fhcrc.org>
Message-ID: <1314397023.2674.2.camel@chrysothemis.geog.ucl.ac.uk>

On Fri, 2011-08-26 at 07:06 -0700, Martin Morgan wrote:
> On 08/26/2011 04:44 AM, Gavin Simpson wrote:
> > Dear List,
> >
> > This may be related to this email thread initiated by Ben Bolker last
> > month: https://stat.ethz.ch/pipermail/r-devel/2011-July/061630.html
> >
> > In answering this Question on StackOverflow
> > http://stackoverflow.com/q/7195628/429846 I noticed that `methods()` was
> > not listing some S3 methods for `plot()` provided by the mgcv package.
> 
> Hi Gavin --
> 
> In the mgcv NAMESPACE, the methods is not registered with S3method 
> (which would have made it appear with a *) and is not export'ed; the 
> author of the package apparently intends that it be strictly internal to 
> the package. Dispatch works within the package name space, but not 
> outside, e.g., a=list; class(a) = "mgcv.smooth"; plot(a) ends up at 
> plot.default.

Thanks for the explanation Martin. This strikes me as being somewhat
suboptimal and not conducive to studying and understanding code. Now
that I am aware of the distinction I won't be surprised when methods
don't show up.

Cheers

G

> > At the time I wanted to check the development version of R as I recalled
> > Uwe mentioning that `plot.function` was listed by `methods()` there but
> > not in R2.13.x. I have now compiled the development version on two
> 
> It looks like the cog that has changed between release and devel is the 
> addition of export(plot.function) and S3method(plot, "function") to the 
> NAMESPACE of graphics.
> 
> Martin
> 
> > Fedora installations and certain plot methods are still not being
> > listed. Details of the exact revision of R Devel are shown at the end of
> > this email.
> >
> > As an example, consider:
> >
> >> require(mgcv)
> > Loading required package: mgcv
> > This is mgcv 1.7-6. For overview type 'help("mgcv-package")'.
> >> methods("plot")
> >   [1] plot.acf*              plot.ACF*              plot.augPred*
> >   [4] plot.compareFits*      plot.data.frame*       plot.decomposed.ts*
> >   [7] plot.default           plot.dendrogram*       plot.density
> > [10] plot.ecdf              plot.factor*           plot.formula*
> > [13] plot.function          plot.gam               plot.gls*
> > [16] plot.hclust*           plot.histogram*        plot.HoltWinters*
> > [19] plot.intervals.lmList* plot.isoreg*           plot.lm
> > [22] plot.lme*              plot.lmList*           plot.medpolish*
> > [25] plot.mlm               plot.nffGroupedData*   plot.nfnGroupedData*
> > [28] plot.nls*              plot.nmGroupedData*    plot.pdMat*
> > [31] plot.ppr*              plot.prcomp*           plot.princomp*
> > [34] plot.profile.nls*      plot.ranef.lme*        plot.ranef.lmList*
> > [37] plot.shingle*          plot.simulate.lme*     plot.spec
> > [40] plot.stepfun           plot.stl*              plot.table*
> > [43] plot.trellis*          plot.ts                plot.tskernel*
> > [46] plot.TukeyHSD          plot.Variogram*
> >
> >     Non-visible functions are asterisked
> >
> >> pmeth<- methods("plot")
> >> grep("plot.mgcv.smooth", pmeth)
> > integer(0)
> >> getS3method("plot", "mgcv.smooth")
> > Error in getS3method("plot", "mgcv.smooth") :
> >    S3 method 'plot.mgcv.smooth' not found
> >> pfun<- getAnywhere("plot.mgcv.smooth")
> >> str(pfun)
> > List of 5
> >   $ name   : chr "plot.mgcv.smooth"
> >   $ objs   :List of 1
> >    ..$ :function (x, P = NULL, data = NULL, label = "", se1.mult = 1,
> >      se2.mult = 2, partial.resids = FALSE, rug = TRUE, se = TRUE,
> >      scale = -1, n = 100, n2 = 40, pers = FALSE, theta = 30, phi = 30,
> >      jit = FALSE, xlab = NULL, ylab = NULL, main = NULL, ylim = NULL,
> >      xlim = NULL, too.far = 0.1, shade = FALSE, shade.col = "gray80",
> >      shift = 0, trans = I, by.resids = FALSE, scheme = NULL, ...)
> >   $ where  : chr "namespace:mgcv"
> >   $ visible: logi FALSE
> >   $ dups   : logi FALSE
> >   - attr(*, "class")= chr "getAnywhere"
> >
> > Both `methods()` and `getS3method()` don't list/find this method, but
> > the function exists in the mgcv name space and this method will be used
> > via R's S3 dispatch system in `plot.gam()`.
> >
> > Shouldn't this method be returned by either `methods()` or
> > `getS3method()`?
> >
> > TIA,
> >
> > Gavin
> >
> >> sessionInfo()
> > R Under development (unstable) (2011-08-26 r56801)
> > Platform: x86_64-unknown-linux-gnu (64-bit)
> >
> > locale:
> >   [1] LC_CTYPE=en_GB.UTF-8       LC_NUMERIC=C
> >   [3] LC_TIME=en_GB.UTF-8        LC_COLLATE=en_GB.UTF-8
> >   [5] LC_MONETARY=en_GB.UTF-8    LC_MESSAGES=en_GB.UTF-8
> >   [7] LC_PAPER=C                 LC_NAME=C
> >   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> > [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods
> > base
> >
> > other attached packages:
> > [1] mgcv_1.7-6
> >
> > loaded via a namespace (and not attached):
> > [1] grid_2.14.0        lattice_0.19-33    Matrix_0.9996875-3
> > nlme_3.1-102
> > [5] tools_2.14.0
> 
> 

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From goran.brostrom at gmail.com  Sat Aug 27 11:27:47 2011
From: goran.brostrom at gmail.com (=?UTF-8?B?R8O2cmFuIEJyb3N0csO2bQ==?=)
Date: Sat, 27 Aug 2011 11:27:47 +0200
Subject: [Rd] read.table segfaults
In-Reply-To: <loom.20110826T234733-73@post.gmane.org>
References: <CAJxcB8mtJ_B=vLm5FSGLpqaN0V1ttKFzLaiBw+mUijBP0wzEyA@mail.gmail.com>
	<1314387697378-3771817.post@n4.nabble.com>
	<loom.20110826T234733-73@post.gmane.org>
Message-ID: <CAJxcB8kQdaSRMzzRWvK=stW2uTWmS-TjQ=o4102KkNsDhbj1zQ@mail.gmail.com>

On Fri, Aug 26, 2011 at 11:55 PM, Ben Bolker <bbolker at gmail.com> wrote:
> Scott <ncbi2r <at> googlemail.com> writes:
>
>>
>> It does look like you've got a memory issue. perhaps using
>> ? as.is=TRUE, and/or stringsAsFactors=FALSE will help as optional arguments
>> to read.table
>>
>> if you don't specify these sorts of things, R can have to look through the
>> file and figure out which columns are characters/factors etc and so the
>> larger files cause more of a headache for R I'm guess. Hopefully someone
>> else can comment further on this? I'd true toggling TRUE/FALSE for as.is and
>> stringsAsFactors.
>>
>> ? ?do you have other objects loaded in memory as well? this file by itself
>> might not be the problem - but it's a cumulative issue.
>> ? ?have you checked the file structure in any other manner?
>> ? ?how large (Mb/kb) is the file that you're trying to read?
>> ? ?if you just read in parts of the file, is it okay?
>> ? ? ? read.table(filename,header=FALSE,sep="\t",nrows=100)
>> ? ? ? read.table(filename,header=FALSE,sep="\t",skip=20000,nrows=100)
>
> ?There seem to be two issues here:
>
> 1. what can the original poster (OP) do to work around this problem?
> (e.g. get the data into a relational data base and import it from
> there; use something from the High Performance task view such as
> ff or data.table ...)

Interestingly, the text file was created by a selection from an SQL
data base. I have access to 'db2' on an ubuntu machine, I run, at the
bash prompt,

$ db2 < file2.sql

where file2.sql contains

connect to linnedb user goran using xxxxxxxxxxx
export to '/home/goran/ALC/SQL/fil2_s.txt' of del modified by coldelX09
 select  linneid, fodelsear, kon, ....... from u09021.fil2
connect reset

How do I get a direct connection between  R  and the data base 'linnedb'?

> 2. reporting a bug -- according to the R FAQ, any low-level
> (segmentation-fault-type) crash of R when one is not messing
> around with dynamically loaded code constitutes a bug. Unfortunately,
> debugging problems like this is a huge pain in the butt.
>
> ?Goran, can you randomly or systematically generate an
> object of this size, write it to disk, read it back in, and
> generate the same error? ?In other words, does something like
>
> set.seed(1001)
> d <- data.frame(label=rep(LETTERS[1:11],1e6),
> ? ? ? ? ? ? ? ?values=matrix(rep(1.0,11*17*1e6),ncol=17)
> write.table(d,file="big.txt")
> read.table("big.txt")
>
> do the same thing?

No but I get new errors:

> ss <- read.table("big.txt")
Error in read.table("big.txt") : duplicate 'row.names' are not allowed

(there are no duplicates)

I tried to add an item to the first line and

> ss <- read.table("big.txt", header = TRUE)
Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
  line 10610008 did not have 19 elements

which is wrong; that line has 19 elements.

G?ran

> Reducing it to this kind of reproducible example will make
> it possible for others to debug it without needing to gain
> access to your huge file ...
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
G?ran Brostr?m


From goran.brostrom at gmail.com  Sat Aug 27 11:49:21 2011
From: goran.brostrom at gmail.com (=?UTF-8?B?R8O2cmFuIEJyb3N0csO2bQ==?=)
Date: Sat, 27 Aug 2011 11:49:21 +0200
Subject: [Rd] read.table segfaults
In-Reply-To: <1314387697378-3771817.post@n4.nabble.com>
References: <CAJxcB8mtJ_B=vLm5FSGLpqaN0V1ttKFzLaiBw+mUijBP0wzEyA@mail.gmail.com>
	<1314387697378-3771817.post@n4.nabble.com>
Message-ID: <CAJxcB8mDdf0_kN8dOv6e5hYDVRjO6BMzie5bwUtxvBYfHpY6cw@mail.gmail.com>

On Fri, Aug 26, 2011 at 9:41 PM, Scott <ncbi2r at googlemail.com> wrote:
> It does look like you've got a memory issue. perhaps using
> ?as.is=TRUE, and/or stringsAsFactors=FALSE will help as optional arguments
> to read.table
>
> if you don't specify these sorts of things, R can have to look through the
> file and figure out which columns are characters/factors etc and so the
> larger files cause more of a headache for R I'm guess. Hopefully someone
> else can comment further on this? I'd true toggling TRUE/FALSE for as.is and
> stringsAsFactors.
>
> ? do you have other objects loaded in memory as well? this file by itself
> might not be the problem - but it's a cumulative issue.
> ? have you checked the file structure in any other manner?
> ? how large (Mb/kb) is the file that you're trying to read?
> ? if you just read in parts of the file, is it okay?
> ? ? ?read.table(filename,header=FALSE,sep="\t",nrows=100)
> ? ? ?read.table(filename,header=FALSE,sep="\t",skip=20000,nrows=100)

Today, after a night's sleep, there are no segfaults! (The computer
also slept, I turned it off.)  So what is going on? Maybe I shouldn't
bother.... but I installed the latest patched version yesterday,
immediately tried to read the file with a segfault as a result, turned
the machine off and on, and no problems. Do we need to reboot after a
new install (note, this is not Windows)?

G?ran

>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/read-table-segfaults-tp3771793p3771817.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
G?ran Brostr?m


From kryberg at live.com  Fri Aug 26 23:50:48 2011
From: kryberg at live.com (kryberg)
Date: Fri, 26 Aug 2011 14:50:48 -0700 (PDT)
Subject: [Rd] Rd2pdf and Rd2dvi don't find texi2dvi
In-Reply-To: <A50D693C-C20C-4188-BF76-11F976832A9A@gmail.com>
References: <AF958FF9-6AE8-468F-B7A4-116B806D59CA@gmail.com>
	<4D8C8EF3.4000400@gmail.com>
	<A50D693C-C20C-4188-BF76-11F976832A9A@gmail.com>
Message-ID: <1314395448790-3772117.post@n4.nabble.com>

Did you every find a resolution to this?  I have the exact same problem and
have had no success solving it.  I'd like to know your solution if you found
one.

In R
system("texi2dvi --version") 
texi2dvi (GNU Texinfo 4.8) 1.34

Copyright (C) 2004 Free Software Foundation, Inc.
There is NO warranty.  You may redistribute this software
under the terms of the GNU General Public License.
For more information about these matters, see the files named COPYING.

At the command prompt

% texi2dvi --version
texi2dvi (GNU Texinfo 4.8) 1.34

Copyright (C) 2004 Free Software Foundation, Inc.
There is NO warranty.  You may redistribute this software
under the terms of the GNU General Public License.
For more information about these matters, see the files named COPYING.

I can use Sweave and create LaTeX documents outside of R.  But R CMD chekc
pkgname gives me

Re-running with no redirection of stdout/stderr.
Hmm ... looks like a package
Error in texi2dvi("Rd2.tex", pdf = (out_ext == "pdf"), quiet = FALSE,  : 
  pdflatex is not available
Error in running tools::texi2dvi
You may want to clean up by 'rm -rf
/var/folders/We/Wevm0EqRHPC3qT+IfM76U+eiwUY/-Tmp-//RtmpuP3CAs/Rd2pdf626fdc61'


texi2dvi is in my PATH at /usr/bin/texi2dvi


R version 2.13.1 (2011-07-08)
Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
Mac OS X version 10.6.8




--
View this message in context: http://r.789695.n4.nabble.com/Rd2pdf-and-Rd2dvi-don-t-find-texi2dvi-tp3405172p3772117.html
Sent from the R devel mailing list archive at Nabble.com.


From ligges at statistik.tu-dortmund.de  Sat Aug 27 19:24:36 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 27 Aug 2011 19:24:36 +0200
Subject: [Rd] S3 methods in default namespace
In-Reply-To: <CAOQ5Nyd8bWX7Vh=Y5dXPAPLR3JVpu07XQw1=+sdWnbMebW_QuQ@mail.gmail.com>
References: <CAOQ5Nyd8bWX7Vh=Y5dXPAPLR3JVpu07XQw1=+sdWnbMebW_QuQ@mail.gmail.com>
Message-ID: <4E592854.9010508@statistik.tu-dortmund.de>



On 26.08.2011 23:47, Michael Lawrence wrote:
> Hi guys,
>
> Are there any plans for figuring out potential S3 methods and declaring them
> with S3method() in the automatic default NAMESPACE?

There are no safe ways to do that.

Uwe


>
> Thanks,
> Michael
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hadley at rice.edu  Sat Aug 27 20:02:56 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Sat, 27 Aug 2011 13:02:56 -0500
Subject: [Rd] S3 methods in default namespace
In-Reply-To: <4E592854.9010508@statistik.tu-dortmund.de>
References: <CAOQ5Nyd8bWX7Vh=Y5dXPAPLR3JVpu07XQw1=+sdWnbMebW_QuQ@mail.gmail.com>
	<4E592854.9010508@statistik.tu-dortmund.de>
Message-ID: <CABdHhvEDe6CmKW2Jh+7wpX+pU_KL_wXOnTS5xDJM3FBVCRujrw@mail.gmail.com>

>> Are there any plans for figuring out potential S3 methods and declaring
>> them
>> with S3method() in the automatic default NAMESPACE?
>
> There are no safe ways to do that.

So doesn't that break packages that use S3 but don't have a NAMESPACE?

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From ligges at statistik.tu-dortmund.de  Sun Aug 28 17:25:31 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 28 Aug 2011 17:25:31 +0200
Subject: [Rd] S3 methods in default namespace
In-Reply-To: <CABdHhvEDe6CmKW2Jh+7wpX+pU_KL_wXOnTS5xDJM3FBVCRujrw@mail.gmail.com>
References: <CAOQ5Nyd8bWX7Vh=Y5dXPAPLR3JVpu07XQw1=+sdWnbMebW_QuQ@mail.gmail.com>
	<4E592854.9010508@statistik.tu-dortmund.de>
	<CABdHhvEDe6CmKW2Jh+7wpX+pU_KL_wXOnTS5xDJM3FBVCRujrw@mail.gmail.com>
Message-ID: <4E5A5DEB.6080701@statistik.tu-dortmund.de>



On 27.08.2011 20:02, Hadley Wickham wrote:
>>> Are there any plans for figuring out potential S3 methods and declaring
>>> them
>>> with S3method() in the automatic default NAMESPACE?
>>
>> There are no safe ways to do that.
>
> So doesn't that break packages that use S3 but don't have a NAMESPACE?

Maybe, but since the methods are exported as functions they are also 
found for method dispatch and imported, if another package imports from 
the Namspace. The problem I see is what happens if method dispatch is 
done on a package that is not attached but just the Namespace is only 
loaded.

Anyway, we should really recommend that package authors write NAMESPACE 
files in case their packages are not trivial.
Note that there are many CRAN packages that fail under R-devel, some of 
them sue to NAMESPACE issues.

Best,
Uwe






>
> Hadley
>


From hadley at rice.edu  Mon Aug 29 14:20:00 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Mon, 29 Aug 2011 07:20:00 -0500
Subject: [Rd] S3 methods in default namespace
In-Reply-To: <4E5A5DEB.6080701@statistik.tu-dortmund.de>
References: <CAOQ5Nyd8bWX7Vh=Y5dXPAPLR3JVpu07XQw1=+sdWnbMebW_QuQ@mail.gmail.com>
	<4E592854.9010508@statistik.tu-dortmund.de>
	<CABdHhvEDe6CmKW2Jh+7wpX+pU_KL_wXOnTS5xDJM3FBVCRujrw@mail.gmail.com>
	<4E5A5DEB.6080701@statistik.tu-dortmund.de>
Message-ID: <CABdHhvEmpotLWD+kSi6SHvhr3Bcoutpx7zJVsRbUYk6DbzZT8Q@mail.gmail.com>

>> So doesn't that break packages that use S3 but don't have a NAMESPACE?
>
> Maybe, but since the methods are exported as functions they are also found
> for method dispatch and imported, if another package imports from the
> Namspace. The problem I see is what happens if method dispatch is done on a
> package that is not attached but just the Namespace is only loaded.
>
> Anyway, we should really recommend that package authors write NAMESPACE
> files in case their packages are not trivial.
> Note that there are many CRAN packages that fail under R-devel, some of them
> sue to NAMESPACE issues.

I'm not sure I understand the approach of providing a default
NAMESPACE.  Why not just make it a requirement to pass R CMD check?
That seems like it would be a safer approach, although it would create
some work for people who have not yet started using namespaces.

Hadley


-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From ligges at statistik.tu-dortmund.de  Mon Aug 29 14:37:52 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 29 Aug 2011 14:37:52 +0200
Subject: [Rd] S3 methods in default namespace
In-Reply-To: <CABdHhvEmpotLWD+kSi6SHvhr3Bcoutpx7zJVsRbUYk6DbzZT8Q@mail.gmail.com>
References: <CAOQ5Nyd8bWX7Vh=Y5dXPAPLR3JVpu07XQw1=+sdWnbMebW_QuQ@mail.gmail.com>
	<4E592854.9010508@statistik.tu-dortmund.de>
	<CABdHhvEDe6CmKW2Jh+7wpX+pU_KL_wXOnTS5xDJM3FBVCRujrw@mail.gmail.com>
	<4E5A5DEB.6080701@statistik.tu-dortmund.de>
	<CABdHhvEmpotLWD+kSi6SHvhr3Bcoutpx7zJVsRbUYk6DbzZT8Q@mail.gmail.com>
Message-ID: <4E5B8820.9070307@statistik.tu-dortmund.de>



On 29.08.2011 14:20, Hadley Wickham wrote:
>>> So doesn't that break packages that use S3 but don't have a NAMESPACE?
>>
>> Maybe, but since the methods are exported as functions they are also found
>> for method dispatch and imported, if another package imports from the
>> Namspace. The problem I see is what happens if method dispatch is done on a
>> package that is not attached but just the Namespace is only loaded.
>>
>> Anyway, we should really recommend that package authors write NAMESPACE
>> files in case their packages are not trivial.
>> Note that there are many CRAN packages that fail under R-devel, some of them
>> sue to NAMESPACE issues.
>
> I'm not sure I understand the approach of providing a default
> NAMESPACE.  Why not just make it a requirement to pass R CMD check?
> That seems like it would be a safer approach, although it would create
> some work for people who have not yet started using namespaces.

Making it an requirement would certainly be the cleanest approach, but 
there are other constraints. One of them CRAN maintainability. Example: 
Consider some people do not fix packages in time that are in the list of 
dependencies of others, then the whole hierarchy is broken. We try to 
make the transition a bit more smoothly.


Uwe


> Hadley
>
>


From murdoch.duncan at gmail.com  Mon Aug 29 14:40:53 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 29 Aug 2011 08:40:53 -0400
Subject: [Rd] S3 methods in default namespace
In-Reply-To: <CABdHhvEmpotLWD+kSi6SHvhr3Bcoutpx7zJVsRbUYk6DbzZT8Q@mail.gmail.com>
References: <CAOQ5Nyd8bWX7Vh=Y5dXPAPLR3JVpu07XQw1=+sdWnbMebW_QuQ@mail.gmail.com>	<4E592854.9010508@statistik.tu-dortmund.de>	<CABdHhvEDe6CmKW2Jh+7wpX+pU_KL_wXOnTS5xDJM3FBVCRujrw@mail.gmail.com>	<4E5A5DEB.6080701@statistik.tu-dortmund.de>
	<CABdHhvEmpotLWD+kSi6SHvhr3Bcoutpx7zJVsRbUYk6DbzZT8Q@mail.gmail.com>
Message-ID: <4E5B88D5.2030709@gmail.com>

On 29/08/2011 8:20 AM, Hadley Wickham wrote:
> >>  So doesn't that break packages that use S3 but don't have a NAMESPACE?
> >
> >  Maybe, but since the methods are exported as functions they are also found
> >  for method dispatch and imported, if another package imports from the
> >  Namspace. The problem I see is what happens if method dispatch is done on a
> >  package that is not attached but just the Namespace is only loaded.
> >
> >  Anyway, we should really recommend that package authors write NAMESPACE
> >  files in case their packages are not trivial.
> >  Note that there are many CRAN packages that fail under R-devel, some of them
> >  sue to NAMESPACE issues.
>
> I'm not sure I understand the approach of providing a default
> NAMESPACE.  Why not just make it a requirement to pass R CMD check?
> That seems like it would be a safer approach, although it would create
> some work for people who have not yet started using namespaces.

About 1000 packages on CRAN didn't have a NAMESPACE file.  Most of them 
were very simple so our default NAMESPACE is sufficient.  Some of them 
were not so simple, and those ones really need to have a NAMESPACE.

Adding the namespace makes all of the packages more predictable and 
reliable (because it gives a defined search order for functions), but 
there's no point forcing 1000 package authors to do it if it can be done 
automatically.  However, there are at least a few dozen who should have 
done it long ago, and those ones will need to do it to pass checks.

Duncan Murdoch


From lani.lichtenstein at gmail.com  Mon Aug 29 18:25:35 2011
From: lani.lichtenstein at gmail.com (Ilana Lichtenstein)
Date: Tue, 30 Aug 2011 02:25:35 +1000
Subject: [Rd] R-loadable dll with minGW-compiled linked library
Message-ID: <CACqXi8+Ep5D1oAWwobOqeLEpbCiiNFgpbgfBNu4koUjwCAcdpw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110830/a4bb1647/attachment.pl>

From edd at debian.org  Mon Aug 29 20:43:58 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 29 Aug 2011 13:43:58 -0500
Subject: [Rd] R-loadable dll with minGW-compiled linked library
In-Reply-To: <CACqXi8+Ep5D1oAWwobOqeLEpbCiiNFgpbgfBNu4koUjwCAcdpw@mail.gmail.com>
References: <CACqXi8+Ep5D1oAWwobOqeLEpbCiiNFgpbgfBNu4koUjwCAcdpw@mail.gmail.com>
Message-ID: <20059.56814.828413.374600@max.nulle.part>


On 30 August 2011 at 02:25, Ilana Lichtenstein wrote:
| The tutorials on the web regarding creation of C++ dlls do not discuss
| linking to libraries.

Well, there are working examples among the 3200+ CRAN packages...

| Thus my two questions are:
| (1) Does anyone know how to compile a C++ program which links to a library,
| which dyn.load will accept? What flags are required in the R makeconf? How
| do you link in a library to the dll?  What flags must I compile the libdai
| and boost libraries with?

Sure. I am as self-centered as the next guy so I welcome you to look at my
RQuantLib project (on CRAN and R-Forge) which has been doing that for a
decade -- and the QuantLib project / library itself uses parts of Boost. 

Moreover, Rcpp is a package whose goal it is to make C++ interchange from /
to R a little less painful.  There are now three dozen packages on CRAN using
it (see the 'reverse depends' via the Rcpp CRAN page) and several of these
link to other external libraries.

[ All that said, I suspect you need to build everything with MinGW. You
certainly cannot mix object code generated via compilers from the visual
whichever suites (as C++ function headers get mangled) and I am pretty
certain that Cygwin's g++ may be doomed for the same reason. I'd be happy to
be convinced otherwise; this would be something worth documenting better. ]

| (2) If my interfacing issue cannot be resolved, does anyone know any tools
| that interface to R that do machine learning belief propagation?

Did you look at the machine learning Task View ?

Dirk


-- 
Two new Rcpp master classes for R and C++ integration scheduled for 
New York (Sep 24) and San Francisco (Oct 8), more details are at
http://dirk.eddelbuettel.com/blog/2011/08/04#rcpp_classes_2011-09_and_2011-10
http://www.revolutionanalytics.com/products/training/public/rcpp-master-class.php


From alireza.s.mahani at gmail.com  Mon Aug 29 20:48:52 2011
From: alireza.s.mahani at gmail.com (Alireza Mahani)
Date: Mon, 29 Aug 2011 11:48:52 -0700 (PDT)
Subject: [Rd] How to safely using OpenMP pragma inside a .C() function?
Message-ID: <1314643732236-3777036.post@n4.nabble.com>

I am trying to parallelize part of a C function that is called from R (via
.C) using OpenMP's "parallel for" pragma. I get mixed results: some runs
finish with no problem, but some lead to R crashing after issuing a long
error message involving memory violations.

I found this post, which describes how a .Call() function can be made to
avoid crashing R by raising the stack limit:

http://www.r-bloggers.com/using-openmp-ized-c-code-with-r/

However, trying this in my .C function doesn't help things. Any
suggestions/tips on whether I can safely use OpenMP inside a .C function,
and if yes how?

Thank you,
Alireza Mahani

--
View this message in context: http://r.789695.n4.nabble.com/How-to-safely-using-OpenMP-pragma-inside-a-C-function-tp3777036p3777036.html
Sent from the R devel mailing list archive at Nabble.com.


From hb at biostat.ucsf.edu  Mon Aug 29 21:22:19 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Mon, 29 Aug 2011 12:22:19 -0700
Subject: [Rd] http://cran.r-project.org/src/base/NEWS.html points to R
	v2.13.0
Message-ID: <CAFDcVCRpPJ=1W3uSpg_BC8XjiDAoY2vE+Jb+myOj0nQPOTCHxg@mail.gmail.com>

FYI,

http://cran.r-project.org/src/base/NEWS.html [May 18, 2011] is for R
v2.13.0 whereas http://cran.r-project.org/src/base/NEWS [July 8, 2011]
is for R v2.13.1.  The former is linked to on a few places on
http://cran.r-project.org/.

/Henrik


From gmbecker at ucdavis.edu  Tue Aug 30 00:37:48 2011
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Mon, 29 Aug 2011 15:37:48 -0700
Subject: [Rd] Out-of-date manual or small bug in R CMD check?
Message-ID: <CADwqtCMOb8FghsFe7-Jic6VmCVEcTH4=C0QLhkXASZ+j4fwLDw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110829/ddc5541f/attachment.pl>

From murdoch.duncan at gmail.com  Tue Aug 30 02:30:22 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 29 Aug 2011 20:30:22 -0400
Subject: [Rd] Out-of-date manual or small bug in R CMD check?
In-Reply-To: <CADwqtCMOb8FghsFe7-Jic6VmCVEcTH4=C0QLhkXASZ+j4fwLDw@mail.gmail.com>
References: <CADwqtCMOb8FghsFe7-Jic6VmCVEcTH4=C0QLhkXASZ+j4fwLDw@mail.gmail.com>
Message-ID: <4E5C2F1E.3090000@gmail.com>

On 11-08-29 6:37 PM, Gabriel Becker wrote:
> Hey all,
>
> I get a warning about an unsupported file type in the data directory during
> R CMD check (for R 2.13.1) if I use the save function to create an Rdata,
> but if I save the same object to a .rda file, no warning.
>
> Section 1.1.5 (pg 11 of the pdf) of the Writing R Extensions manual (2.13.1)
> appears to say that .Rdata files should be fine:
>
> " Data files can have one of three types as indicated by their extension:
> plain R code (?.R? or
> ?.r?), tables (?.tab?, ?.txt?, or ?.csv?, see ?data for the file formats,
> and note that ?.csv? is not
> the standard14 CSV format), or save() images (?.RData? or ?.rda?). "
>
> Am I misunderstanding some difference between .rda and .Rdata files in terms
> of the save calls, or should R CMD check and the extensions manual agree on
> this?

.RData and .Rdata aren't the same.

Duncan Murdoch

>
> Thanks for all your hard work.
> ~G
>
> SessionInfo:
>
> R version 2.13.1 (2011-07-08)
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> locale:
>   [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
>   [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
>   [5] LC_MONETARY=C             LC_MESSAGES=en_US.utf8
>   [7] LC_PAPER=en_US.utf8       LC_NAME=C
>   [9] LC_ADDRESS=C              LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] grid      stats     graphics  grDevices utils     datasets  methods
> [8] base
>
> other attached packages:
> [1] gridSVG_0.5-10      ProteinVis_0.4      latticeExtra_0.6-18
> [4] RColorBrewer_1.0-2  lattice_0.19-33
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From simon.urbanek at r-project.org  Tue Aug 30 02:36:24 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 30 Aug 2011 01:36:24 +0100
Subject: [Rd] How to safely using OpenMP pragma inside a .C() function?
In-Reply-To: <1314643732236-3777036.post@n4.nabble.com>
References: <1314643732236-3777036.post@n4.nabble.com>
Message-ID: <B2571962-7567-4F59-A1CB-415088594F47@r-project.org>


On Aug 29, 2011, at 7:48 PM, Alireza Mahani wrote:

> I am trying to parallelize part of a C function that is called from R (via
> .C) using OpenMP's "parallel for" pragma. I get mixed results: some runs
> finish with no problem, but some lead to R crashing after issuing a long
> error message involving memory violations.
> 

You'll have to provide the code. In general it works (even R uses it itself), but there are strict requirements (no R API calls) that you must adhere to.


> I found this post, which describes how a .Call() function can be made to
> avoid crashing R by raising the stack limit:
> 
> http://www.r-bloggers.com/using-openmp-ized-c-code-with-r/
> 

I skimmed through the post and all of the examples are broken - they will only work (incidentally) as R internals, not officially (and they are unnecessary inefficient).


> However, trying this in my .C function doesn't help things. Any
> suggestions/tips on whether I can safely use OpenMP inside a .C function,
> and if yes how?
> 

There are issues with OpenMP on some platforms in general (in fact pretty much every platform had some issue at some point in time), but apart from those you only have to make sure that you declare shared/private variables properly and don't use *any* R API calls in the parallel part (this includes things like LENGTH, REAL, ...).

Cheers,
Simon



> Thank you,
> Alireza Mahani
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/How-to-safely-using-OpenMP-pragma-inside-a-C-function-tp3777036p3777036.html
> Sent from the R devel mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From gmbecker at ucdavis.edu  Tue Aug 30 03:55:00 2011
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Mon, 29 Aug 2011 18:55:00 -0700
Subject: [Rd] Out-of-date manual or small bug in R CMD check?
In-Reply-To: <4E5C2F1E.3090000@gmail.com>
References: <CADwqtCMOb8FghsFe7-Jic6VmCVEcTH4=C0QLhkXASZ+j4fwLDw@mail.gmail.com>
	<4E5C2F1E.3090000@gmail.com>
Message-ID: <CADwqtCO745sYmGGo0eCZ_0Brm1O6DzdETKB6uGF4UJdMARzg-Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110829/11930de2/attachment.pl>

From ligges at statistik.tu-dortmund.de  Tue Aug 30 11:21:59 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 30 Aug 2011 11:21:59 +0200
Subject: [Rd] http://cran.r-project.org/src/base/NEWS.html points to R
 v2.13.0
In-Reply-To: <CAFDcVCRpPJ=1W3uSpg_BC8XjiDAoY2vE+Jb+myOj0nQPOTCHxg@mail.gmail.com>
References: <CAFDcVCRpPJ=1W3uSpg_BC8XjiDAoY2vE+Jb+myOj0nQPOTCHxg@mail.gmail.com>
Message-ID: <4E5CABB7.9080400@statistik.tu-dortmund.de>



On 29.08.2011 21:22, Henrik Bengtsson wrote:
> FYI,
>
> http://cran.r-project.org/src/base/NEWS.html [May 18, 2011] is for R
> v2.13.0 whereas http://cran.r-project.org/src/base/NEWS [July 8, 2011]
> is for R v2.13.1.  The former is linked to on a few places on
> http://cran.r-project.org/.

Thnaks, probably the automatism that generates the NEWS does not yet 
generate the NEWS.html for CRAN. CCing CRAN at ...... so this won't get 
lost in the mailing list archives.

Uwe



>
> /Henrik
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From pdalgd at gmail.com  Tue Aug 30 11:52:01 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 30 Aug 2011 11:52:01 +0200
Subject: [Rd] http://cran.r-project.org/src/base/NEWS.html points to R
	v2.13.0
In-Reply-To: <4E5CABB7.9080400@statistik.tu-dortmund.de>
References: <CAFDcVCRpPJ=1W3uSpg_BC8XjiDAoY2vE+Jb+myOj0nQPOTCHxg@mail.gmail.com>
	<4E5CABB7.9080400@statistik.tu-dortmund.de>
Message-ID: <E759833F-5D24-47DA-B92C-312399D06A39@gmail.com>


On Aug 30, 2011, at 11:21 , Uwe Ligges wrote:

> 
> 
> On 29.08.2011 21:22, Henrik Bengtsson wrote:
>> FYI,
>> 
>> http://cran.r-project.org/src/base/NEWS.html [May 18, 2011] is for R
>> v2.13.0 whereas http://cran.r-project.org/src/base/NEWS [July 8, 2011]
>> is for R v2.13.1.  The former is linked to on a few places on
>> http://cran.r-project.org/.
> 
> Thnaks, probably the automatism that generates the NEWS does not yet generate the NEWS.html for CRAN. CCing CRAN at ...... so this won't get lost in the mailing list archives.
> 


This was already noted by Kurt back in May and I promised to fix the R-build-dist script "when I had a clear head after grading exams", which apparently never happened...

Done now (incl. CRAN). 


> Uwe
> 
> 
> 
>> 
>> /Henrik
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From nachouve at gmail.com  Tue Aug 30 00:06:27 2011
From: nachouve at gmail.com (Nacho Uve)
Date: Tue, 30 Aug 2011 00:06:27 +0200
Subject: [Rd] Problem exporting table with many columns to dbf
Message-ID: <CAGYV1bJCqzF9r4H9Qqv3-SS6zCr-88hW+pKJEzrre9gOKLYVmg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110830/c1576620/attachment.pl>

From henrik at singmann.org  Tue Aug 30 12:35:41 2011
From: henrik at singmann.org (henrik at singmann.org)
Date: Tue, 30 Aug 2011 12:35:41 +0200 (CEST)
Subject: [Rd] unexpected behavior of callNextMethod() when passing arguments
 in methods to generic function
Message-ID: <1154482497.90845.1314700541556.JavaMail.open-xchange@oxltgw04.schlund.de>


Hi,
?
there seems to be an unexpected behavior when using callNextMethod() in a method
to a (user defined) generic function so that additional arguments to the ones
defined in the signature of the generic are not passed correctly (i.e., their
value are lost/replaced by the default).
?
Problem description:
We have two hierarchical classes, "foo" and subclass "bar" and a generic
function "foobar". There exists methods for foobar for both "foo" and "bar" that
have the same signature, which differs from the signature in the generic
function (i.e., there are additional arguments in the methods).There are default
values for the additional arguments in the two methods.The method for "bar"
contains a callNextMethod() statement.
Now calling "foobar" for an object of class "bar" with an additional argument
set to a non-defualt value leads to: in the method for "bar", the the additional
argument is equal to the input; in the method for "foo" (i.e., within the
callNextMethod() statement) the additional argument is equal to the default for
that method (i.e., instead of equal to the user input).
?
This behavior contrasts with my reading of ?callNextMethod which states:
For a formal argument, sayx, that appears in the original call, there is a
corresponding argument in the next method call equivalent tox = x. In effect,
this means that the next method sees the same actual arguments, but arguments
are evaluated only once.
?
Therefore I would expect the additional argument be passed on by
callNextMethod() as inputted by the user.?
?
Example: ?

setClass("foo", representation(x = "numeric"))
setClass("bar", contains = "foo")

setGeneric("foobar", function(object, ...) standardGeneric("foobar"))

setMethod("foobar", "foo", function(object, another.argument = FALSE, ...) {
??? print(paste("another.argument in foo-method:", another.argument))
??? object at x
})

setMethod("foobar", "bar", function(object, another.argument = FALSE, ...) {
??? print(paste("another.argument in bar-method:", another.argument))
??? callNextMethod()
})

o1 <- new("bar", x = 4)

> foobar(o1, another.argument = TRUE)
[1] "another.argument in bar-method: TRUE"
[1] "another.argument in foo-method: FALSE"
[1] 4
?

Related Issues:
I already asked this question on stackoverflow
(http://stackoverflow.com/q/7190697/289572) and got a helpful answer with
workarounds from Martin Morgan. However, I have the feeling that this may be of
interest here, too.?
This problem may or may not be related to the following similar bug reported on
r-devel:?
http://thread.gmane.org/gmane.comp.lang.r.devel/23263/focus=23266
?
Best,
Henrik?
?
?
PS:
> sessionInfo()
R version 2.13.1 (2011-07-08)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United Kingdom.1252? LC_CTYPE=English_United
Kingdom.1252??? LC_MONETARY=English_United Kingdom.1252
[4] LC_NUMERIC=C??????????????????????????? LC_TIME=English_United
Kingdom.1252???

attached base packages:
[1] stats???? graphics? grDevices utils???? datasets? methods?? base????

other attached packages:
[1] fortunes_1.4-2


From alireza.s.mahani at gmail.com  Tue Aug 30 13:53:21 2011
From: alireza.s.mahani at gmail.com (Alireza Mahani)
Date: Tue, 30 Aug 2011 04:53:21 -0700 (PDT)
Subject: [Rd] How to safely using OpenMP pragma inside a .C() function?
In-Reply-To: <B2571962-7567-4F59-A1CB-415088594F47@r-project.org>
References: <1314643732236-3777036.post@n4.nabble.com>
	<B2571962-7567-4F59-A1CB-415088594F47@r-project.org>
Message-ID: <1314705201298-3778482.post@n4.nabble.com>

I have no R API calls inside the parallelized block. I will work on creating
a self-contained example and post it for your review. Thanks! -Alireza

--
View this message in context: http://r.789695.n4.nabble.com/How-to-safely-use-OpenMP-pragma-inside-a-C-function-tp3777036p3778482.html
Sent from the R devel mailing list archive at Nabble.com.


From hadley at rice.edu  Tue Aug 30 15:27:01 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Tue, 30 Aug 2011 08:27:01 -0500
Subject: [Rd] sysdata.rda, namespaces and package dependencies
In-Reply-To: <CABdHhvHJCstQrsoCWhMTys6Jba5egWO6iprm2TuFy0Zrb==U1Q@mail.gmail.com>
References: <CABdHhvHJCstQrsoCWhMTys6Jba5egWO6iprm2TuFy0Zrb==U1Q@mail.gmail.com>
Message-ID: <CABdHhvES1MW=erb_gTNn1CUop2AmKrNeAp4=HpQpxygk3jm7bw@mail.gmail.com>

Bump.  Any comments on this?
Hadley

On Tue, Aug 16, 2011 at 10:53 AM, Hadley Wickham <hadley at rice.edu> wrote:
> Hi all,
>
> I'm struggling with accessing a package dataset (munsell.map, stored
> in sysdata.rda) when that package is imported, not required. ?A simple
> reproducible example is:
>
> install.packages("munsell")
> munsell::mnsl("10B 4/6")
> # Error in match(col, munsell.map$name) : object 'munsell.map' not found
>
> library(munsell)
> munsell::mnsl("10B 4/6")
> # Function works correctly
>
> Am I doing something wrong, or is this namespace bug?
>
> Hadley
>
> --
> Assistant Professor / Dobelman Family Junior Chair
> Department of Statistics / Rice University
> http://had.co.nz/
>



-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From xie at yihui.name  Tue Aug 30 17:06:28 2011
From: xie at yihui.name (Yihui Xie)
Date: Tue, 30 Aug 2011 10:06:28 -0500
Subject: [Rd] sysdata.rda, namespaces and package dependencies
In-Reply-To: <CABdHhvES1MW=erb_gTNn1CUop2AmKrNeAp4=HpQpxygk3jm7bw@mail.gmail.com>
References: <CABdHhvHJCstQrsoCWhMTys6Jba5egWO6iprm2TuFy0Zrb==U1Q@mail.gmail.com>
	<CABdHhvES1MW=erb_gTNn1CUop2AmKrNeAp4=HpQpxygk3jm7bw@mail.gmail.com>
Message-ID: <CANROs4e6YrR_v2D5q9NXiKHcgbyWrd0E=2MFZkJCYt=YpMZYYQ@mail.gmail.com>

I struggled with this for a while too, and I have no idea why this
data object is unavailable. Finally I found this can do the trick:

data(munsell_map, package = "munsell")
munsell::mnsl("10B 4/6")
## works

But I still cannot understand this.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 515-294-2465 Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA



On Tue, Aug 30, 2011 at 8:27 AM, Hadley Wickham <hadley at rice.edu> wrote:
> Bump. ?Any comments on this?
> Hadley
>
> On Tue, Aug 16, 2011 at 10:53 AM, Hadley Wickham <hadley at rice.edu> wrote:
>> Hi all,
>>
>> I'm struggling with accessing a package dataset (munsell.map, stored
>> in sysdata.rda) when that package is imported, not required. ?A simple
>> reproducible example is:
>>
>> install.packages("munsell")
>> munsell::mnsl("10B 4/6")
>> # Error in match(col, munsell.map$name) : object 'munsell.map' not found
>>
>> library(munsell)
>> munsell::mnsl("10B 4/6")
>> # Function works correctly
>>
>> Am I doing something wrong, or is this namespace bug?
>>
>> Hadley
>>
>> --
>> Assistant Professor / Dobelman Family Junior Chair
>> Department of Statistics / Rice University
>> http://had.co.nz/
>>
>
>
>
> --
> Assistant Professor / Dobelman Family Junior Chair
> Department of Statistics / Rice University
> http://had.co.nz/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From hadley at rice.edu  Tue Aug 30 17:27:14 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Tue, 30 Aug 2011 10:27:14 -0500
Subject: [Rd] sysdata.rda, namespaces and package dependencies
In-Reply-To: <4E5CF273.5060309@gmail.com>
References: <CABdHhvHJCstQrsoCWhMTys6Jba5egWO6iprm2TuFy0Zrb==U1Q@mail.gmail.com>
	<CABdHhvES1MW=erb_gTNn1CUop2AmKrNeAp4=HpQpxygk3jm7bw@mail.gmail.com>
	<4E5CF273.5060309@gmail.com>
Message-ID: <CABdHhvG2tKmGGBwuh+khFHCFWXBmFePOCnAyyBVS=8jU_H3oVA@mail.gmail.com>

> Your package is doing something weird, so I think it's you: ?you are loading
> the munsell.map file via "load.r" in the top level of the package. ?That's
> not a standard thing to do, and it's not being executed in the first case.
>
> Put that load statement into one of the files in the R directory and things
> should be fine.

I think that's a red-herring - load.r is for development and is never
run during usual package installation.  Or are you saying I need to
explicit load data stored in sysdata.rda within the package?

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From ggrothendieck at gmail.com  Tue Aug 30 17:42:15 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 30 Aug 2011 11:42:15 -0400
Subject: [Rd] Problems with r-help
Message-ID: <CAP01uR=Bt5rBc20hFbEZkZLC55hWk4GVQFGuPS4qwrhxoU1oww@mail.gmail.com>

I am getting messages like this whenever I try to post to r-help.  The
message seems to say that the problem is with on the r-help end (the
recipient domain).


Delivery to the following recipient failed permanently:

    r-help at r-project.org

Technical details of permanent failure:
Google tried to deliver your message, but it was rejected by the
recipient domain. We recommend contacting the other email provider for
further information about the cause of this error. The error that the
other server returned was: 550 550-Callout verification failed:
550 550 5.7.1 Mail from 129.132.202.242 refused - see
http://www.orbitrbl.com/ (state 14).

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From ggrothendieck at gmail.com  Tue Aug 30 18:16:42 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 30 Aug 2011 12:16:42 -0400
Subject: [Rd] Problems with r-help
In-Reply-To: <CAP01uR=Bt5rBc20hFbEZkZLC55hWk4GVQFGuPS4qwrhxoU1oww@mail.gmail.com>
References: <CAP01uR=Bt5rBc20hFbEZkZLC55hWk4GVQFGuPS4qwrhxoU1oww@mail.gmail.com>
Message-ID: <CAP01uR=h4Q+VROFrm3KtO+z4FP86Sh=vEucHx0wB-fU3UWq6wA@mail.gmail.com>

On Tue, Aug 30, 2011 at 11:42 AM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> I am getting messages like this whenever I try to post to r-help. ?The
> message seems to say that the problem is with on the r-help end (the
> recipient domain).
>
>
> Delivery to the following recipient failed permanently:
>
> ? ?r-help at r-project.org
>
> Technical details of permanent failure:
> Google tried to deliver your message, but it was rejected by the
> recipient domain. We recommend contacting the other email provider for
> further information about the cause of this error. The error that the
> other server returned was: 550 550-Callout verification failed:
> 550 550 5.7.1 Mail from 129.132.202.242 refused - see
> http://www.orbitrbl.com/ (state 14).

It seems this was temporary since I was just able to post a test
message and an actual message to r-help.


-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From pawel.matykiewicz at gmail.com  Tue Aug 30 18:57:48 2011
From: pawel.matykiewicz at gmail.com (pawelm)
Date: Tue, 30 Aug 2011 09:57:48 -0700 (PDT)
Subject: [Rd] How to safely using OpenMP pragma inside a .C() function?
In-Reply-To: <1314705201298-3778482.post@n4.nabble.com>
References: <1314643732236-3777036.post@n4.nabble.com>
	<B2571962-7567-4F59-A1CB-415088594F47@r-project.org>
	<1314705201298-3778482.post@n4.nabble.com>
Message-ID: <1314723468677-3779214.post@n4.nabble.com>

Simon,

I found that files R-2.13.1/src/library/stats/src/distance.c and
R-2.13.1/src/main/array.c have openmp code (example below). I have couple
questions regarding best practices when using R internals and openmp. 

Can we use R-2.13.1/src/library/stats/src/distance.c and
R-2.13.1/src/main/array.c as an example how to interact with R code and R
internals?
What are my other options if I want to work with SEXP structures in my
parallel code?

Thank you
Regards

=============

#ifdef HAVE_OPENMP
        /* This gives a spurious -Wunused-but-set-variable error */
        if (R_num_math_threads > 0) 
            nthreads = R_num_math_threads;
        else 
            nthreads = 1; /* for now */
#pragma omp parallel for num_threads(nthreads) default(none) \
    private(j, i, ix, rx) \
    firstprivate(x, ans, n, p, type, cnt, sum, \
                 NaRm, keepNA, R_NaReal, R_NaInt, OP)
#endif
        for (j = 0; j < p; j++) {
            switch (type) {
            case REALSXP:
                rx = REAL(x) + n*j; 
                if (keepNA)
                    for (sum = 0., i = 0; i < n; i++) sum += *rx++;
                else {
                    for (cnt = 0, sum = 0., i = 0; i < n; i++, rx++)
                        if (!ISNAN(*rx)) {cnt++; sum += *rx;}
                        else if (keepNA) {sum = NA_REAL; break;}
                }    
                break;
            case INTSXP:
                ix = INTEGER(x) + n*j; 
                for (cnt = 0, sum = 0., i = 0; i < n; i++, ix++)
                    if (*ix != NA_INTEGER) {cnt++; sum += *ix;}
                    else if (keepNA) {sum = NA_REAL; break;}
                break;
            case LGLSXP:
                ix = LOGICAL(x) + n*j; 
                for (cnt = 0, sum = 0., i = 0; i < n; i++, ix++)
                    if (*ix != NA_LOGICAL) {cnt++; sum += *ix;}
                    else if (keepNA) {sum = NA_REAL; break;}
                break;
            default:
                /* we checked the type above, but be sure */
                UNIMPLEMENTED_TYPEt("do_colsum", type);
            }
            if (OP == 1) {
                if (cnt > 0) sum /= cnt; else sum = NA_REAL;
            }
            REAL(ans)[j] = sum;
        }


--
View this message in context: http://r.789695.n4.nabble.com/How-to-safely-use-OpenMP-pragma-inside-a-C-function-tp3777036p3779214.html
Sent from the R devel mailing list archive at Nabble.com.


From murdoch.duncan at gmail.com  Tue Aug 30 18:59:44 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 30 Aug 2011 12:59:44 -0400
Subject: [Rd] sysdata.rda, namespaces and package dependencies
In-Reply-To: <CABdHhvG2tKmGGBwuh+khFHCFWXBmFePOCnAyyBVS=8jU_H3oVA@mail.gmail.com>
References: <CABdHhvHJCstQrsoCWhMTys6Jba5egWO6iprm2TuFy0Zrb==U1Q@mail.gmail.com>
	<CABdHhvES1MW=erb_gTNn1CUop2AmKrNeAp4=HpQpxygk3jm7bw@mail.gmail.com>
	<4E5CF273.5060309@gmail.com>
	<CABdHhvG2tKmGGBwuh+khFHCFWXBmFePOCnAyyBVS=8jU_H3oVA@mail.gmail.com>
Message-ID: <4E5D1700.407@gmail.com>

On 30/08/2011 11:27 AM, Hadley Wickham wrote:
> >  Your package is doing something weird, so I think it's you:  you are loading
> >  the munsell.map file via "load.r" in the top level of the package.  That's
> >  not a standard thing to do, and it's not being executed in the first case.
> >
> >  Put that load statement into one of the files in the R directory and things
> >  should be fine.
>
> I think that's a red-herring - load.r is for development and is never
> run during usual package installation.  Or are you saying I need to
> explicit load data stored in sysdata.rda within the package?
>

Sorry, I didn't realize you weren't executing that file.  (Should it be 
included in the tar?  That's a different issue...)

Lazy data is stored in a separate file that is loaded when 
library(munsell) is called.  It appears it isn't being loaded when you 
only use munsell::mnsl to load it but not attach it.  Certainly loading 
it from one of your .R files would work; I'm not sure if it is 
intentional that this is necessary or not.  Perhaps someone else will 
comment?

Duncan Murdoch


From ligges at statistik.tu-dortmund.de  Tue Aug 30 19:19:21 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 30 Aug 2011 19:19:21 +0200
Subject: [Rd] sysdata.rda, namespaces and package dependencies
In-Reply-To: <4E5D1700.407@gmail.com>
References: <CABdHhvHJCstQrsoCWhMTys6Jba5egWO6iprm2TuFy0Zrb==U1Q@mail.gmail.com>
	<CABdHhvES1MW=erb_gTNn1CUop2AmKrNeAp4=HpQpxygk3jm7bw@mail.gmail.com>
	<4E5CF273.5060309@gmail.com>
	<CABdHhvG2tKmGGBwuh+khFHCFWXBmFePOCnAyyBVS=8jU_H3oVA@mail.gmail.com>
	<4E5D1700.407@gmail.com>
Message-ID: <4E5D1B99.6060609@statistik.tu-dortmund.de>



On 30.08.2011 18:59, Duncan Murdoch wrote:
> On 30/08/2011 11:27 AM, Hadley Wickham wrote:
>> > Your package is doing something weird, so I think it's you: you are
>> loading
>> > the munsell.map file via "load.r" in the top level of the package.
>> That's
>> > not a standard thing to do, and it's not being executed in the first
>> case.
>> >
>> > Put that load statement into one of the files in the R directory and
>> things
>> > should be fine.
>>
>> I think that's a red-herring - load.r is for development and is never
>> run during usual package installation. Or are you saying I need to
>> explicit load data stored in sysdata.rda within the package?
>>
>
> Sorry, I didn't realize you weren't executing that file. (Should it be
> included in the tar? That's a different issue...)
>
> Lazy data is stored in a separate file that is loaded when
> library(munsell) is called. It appears it isn't being loaded when you
> only use munsell::mnsl to load it but not attach it. Certainly loading
> it from one of your .R files would work; I'm not sure if it is
> intentional that this is necessary or not. Perhaps someone else will
> comment?

This is expected. The data object is not exported from the Namespace and 
hence not loaded if a reference to the Namespace is made without 
*attaching* the package. Hence data(..., package=...) is the way to go.

Uwe





>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jeffrey.ryan at lemnica.com  Tue Aug 30 19:50:37 2011
From: jeffrey.ryan at lemnica.com (Jeffrey Ryan)
Date: Tue, 30 Aug 2011 12:50:37 -0500
Subject: [Rd] Non-GPL C (or R) inside of a package
Message-ID: <CABDUZc-ML9bzu=zyHqptDEQehDQkMqpGZPRd-j=pnWvk+4ioog@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110830/257b640d/attachment.pl>

From hadley at rice.edu  Tue Aug 30 19:52:47 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Tue, 30 Aug 2011 12:52:47 -0500
Subject: [Rd] sysdata.rda, namespaces and package dependencies
In-Reply-To: <4E5D1B99.6060609@statistik.tu-dortmund.de>
References: <CABdHhvHJCstQrsoCWhMTys6Jba5egWO6iprm2TuFy0Zrb==U1Q@mail.gmail.com>
	<CABdHhvES1MW=erb_gTNn1CUop2AmKrNeAp4=HpQpxygk3jm7bw@mail.gmail.com>
	<4E5CF273.5060309@gmail.com>
	<CABdHhvG2tKmGGBwuh+khFHCFWXBmFePOCnAyyBVS=8jU_H3oVA@mail.gmail.com>
	<4E5D1700.407@gmail.com> <4E5D1B99.6060609@statistik.tu-dortmund.de>
Message-ID: <CABdHhvGrOWBSpz2qkg=iWnCEPynQ2PCmvO7oDyi3sWuqVmFigw@mail.gmail.com>

>> Lazy data is stored in a separate file that is loaded when
>> library(munsell) is called. It appears it isn't being loaded when you
>> only use munsell::mnsl to load it but not attach it. Certainly loading
>> it from one of your .R files would work; I'm not sure if it is
>> intentional that this is necessary or not. Perhaps someone else will
>> comment?
>
> This is expected. The data object is not exported from the Namespace and
> hence not loaded if a reference to the Namespace is made without *attaching*
> the package. Hence data(..., package=...) is the way to go.

So how should I include package local data?  The dataset is only used
internally by munsell functions (it's basically a big lookup table)
and should not be available to the user - i.e. it should not be
exported.  This, I thought, was the purpose of sysdata.rda.

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From ligges at statistik.tu-dortmund.de  Tue Aug 30 20:35:07 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 30 Aug 2011 20:35:07 +0200
Subject: [Rd] sysdata.rda, namespaces and package dependencies
In-Reply-To: <CABdHhvGrOWBSpz2qkg=iWnCEPynQ2PCmvO7oDyi3sWuqVmFigw@mail.gmail.com>
References: <CABdHhvHJCstQrsoCWhMTys6Jba5egWO6iprm2TuFy0Zrb==U1Q@mail.gmail.com>
	<CABdHhvES1MW=erb_gTNn1CUop2AmKrNeAp4=HpQpxygk3jm7bw@mail.gmail.com>
	<4E5CF273.5060309@gmail.com>
	<CABdHhvG2tKmGGBwuh+khFHCFWXBmFePOCnAyyBVS=8jU_H3oVA@mail.gmail.com>
	<4E5D1700.407@gmail.com>
	<4E5D1B99.6060609@statistik.tu-dortmund.de>
	<CABdHhvGrOWBSpz2qkg=iWnCEPynQ2PCmvO7oDyi3sWuqVmFigw@mail.gmail.com>
Message-ID: <4E5D2D5B.8000500@statistik.tu-dortmund.de>



On 30.08.2011 19:52, Hadley Wickham wrote:
>>> Lazy data is stored in a separate file that is loaded when
>>> library(munsell) is called. It appears it isn't being loaded when you
>>> only use munsell::mnsl to load it but not attach it. Certainly loading
>>> it from one of your .R files would work; I'm not sure if it is
>>> intentional that this is necessary or not. Perhaps someone else will
>>> comment?
>>
>> This is expected. The data object is not exported from the Namespace and
>> hence not loaded if a reference to the Namespace is made without *attaching*
>> the package. Hence data(..., package=...) is the way to go.
>
> So how should I include package local data?  The dataset is only used
> internally by munsell functions (it's basically a big lookup table)
> and should not be available to the user - i.e. it should not be
> exported.  This, I thought, was the purpose of sysdata.rda.
>
> Hadley
>

Ahhhh!!!!
Now I understand you are referring to the special name "sysdata.rda" 
that is not to be loaded via data() - I thought you were talking about 
the regular data including process.
That works fine for me as well and then this special data are available 
when the Namespace is loaded already. Have you put that file into 
package/R rather than package/data? Which R version?

Uwe


From murdoch.duncan at gmail.com  Tue Aug 30 21:09:16 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 30 Aug 2011 15:09:16 -0400
Subject: [Rd] Non-GPL C (or R) inside of a package
In-Reply-To: <CABDUZc-ML9bzu=zyHqptDEQehDQkMqpGZPRd-j=pnWvk+4ioog@mail.gmail.com>
References: <CABDUZc-ML9bzu=zyHqptDEQehDQkMqpGZPRd-j=pnWvk+4ioog@mail.gmail.com>
Message-ID: <4E5D355C.1090205@gmail.com>

On 30/08/2011 1:50 PM, Jeffrey Ryan wrote:
> R-devel,
>
> I am interested in creating a package that requires non-GPL'd (commercial) C
> code to work.  In essence it is a single .c file with no use of R headers
> (all .C callable functions).  For example's sake:
>
>    1 #include<stdio.h>
>    2
>    3 void test (int *a) {
>    4   *a = 101;
>    5 }
>
> The package isn't destined for CRAN, and I realize that this isn't R-legal,
> but looking for some expert advice from anyone else who may have encountered
> this previously.
>
> The question is whether or not one can distribute code that has multiple
> licenses (.c or individual .R files), including some that are not
> GPL-compatible, as a tar.gz (or binary) file.  i.e., does the packaging
> process [R CMD ***] cause everything to become GPL, as we are using R itself
> to build the package?
>
I can only say that the answer to the last question is "no":  the author 
gets to choose the license for what s/he wrote.  The fact that you used 
R to package it is irrelevant.  (Some extremists will disagree, and say 
that because your package is intended to "link" to R, it must be 
licensed compatibly with the GPL if you distribute it.  I don't think 
that's true.)

If you are intending to distribute this file you are putting together, 
you'll probably want to consult someone who knows the legalities as to 
whether you can legally link to the commercial library...

Duncan Murdoch

> I can of course provide the C libs in this case as a separate install, but
> that adds complexity to the overall build and install process.
>
> Thanks,
> Jeff
>


From ripley at stats.ox.ac.uk  Tue Aug 30 22:52:21 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 30 Aug 2011 21:52:21 +0100 (BST)
Subject: [Rd] Non-GPL C (or R) inside of a package
In-Reply-To: <4E5D355C.1090205@gmail.com>
References: <CABDUZc-ML9bzu=zyHqptDEQehDQkMqpGZPRd-j=pnWvk+4ioog@mail.gmail.com>
	<4E5D355C.1090205@gmail.com>
Message-ID: <alpine.LFD.2.02.1108302118390.1833@gannet.stats.ox.ac.uk>

On Tue, 30 Aug 2011, Duncan Murdoch wrote:

> On 30/08/2011 1:50 PM, Jeffrey Ryan wrote:
>> R-devel,
>> 
>> I am interested in creating a package that requires non-GPL'd 
>> (commercial) C code to work.  In essence it is a single .c file 
>> with no use of R headers (all .C callable functions).  For 
>> example's sake:
>>
>>    1 #include<stdio.h>
>>    2
>>    3 void test (int *a) {
>>    4   *a = 101;
>>    5 }
>> 
>> The package isn't destined for CRAN, and I realize that this isn't 
>> R-legal, but looking for some expert advice from anyone else who 
>> may have encountered this previously.
>> 
>> The question is whether or not one can distribute code that has 
>> multiple licenses (.c or individual .R files), including some that 
>> are not GPL-compatible, as a tar.gz (or binary) file.  i.e., does 
>> the packaging process [R CMD ***] cause everything to become GPL, 
>> as we are using R itself to build the package?
>> 
> I can only say that the answer to the last question is "no":  the author gets 
> to choose the license for what s/he wrote.  The fact that you used R to 
> package it is irrelevant.  (Some extremists will disagree, and say that 
> because your package is intended to "link" to R, it must be licensed 
> compatibly with the GPL if you distribute it.  I don't think that's true.)

If no distribution is involved, the conditions under which the tarball 
can be distributed is not relevant.

As e.g. GNU tar is itself under GPL, using R to do the packaging is no 
different in principle to using GNU tar to do so and I've never heard 
anyone argue that using GNU tar affects the licence of the tarball.

I don't think that is the same issue as distributing non-GPLed code 
for use with R.  In the latter case the issue is what 'link to' 
actually entails, and one source of advice is the GPL FAQs.  E.g.
http://www.gnu.org/licenses/old-licenses/gpl-2.0-faq.html
http://www.gnu.org/licenses/gpl-faq.html

> If you are intending to distribute this file you are putting together, you'll 
> probably want to consult someone who knows the legalities as to whether you 
> can legally link to the commercial library...



>
> Duncan Murdoch
>
>> I can of course provide the C libs in this case as a separate install, but
>> that adds complexity to the overall build and install process.
>> 
>> Thanks,
>> Jeff
>> 
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From wdunlap at tibco.com  Wed Aug 31 00:05:00 2011
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 30 Aug 2011 22:05:00 +0000
Subject: [Rd] Out-of-date manual or small bug in R CMD check?
In-Reply-To: <4E5C2F1E.3090000@gmail.com>
References: <CADwqtCMOb8FghsFe7-Jic6VmCVEcTH4=C0QLhkXASZ+j4fwLDw@mail.gmail.com>
	<4E5C2F1E.3090000@gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B9304E376@PA-MBX04.na.tibco.com>


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of Duncan Murdoch
> Sent: Monday, August 29, 2011 5:30 PM
> To: Gabriel Becker
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] Out-of-date manual or small bug in R CMD check?
> 
> On 11-08-29 6:37 PM, Gabriel Becker wrote:
> > Hey all,
> >
> > I get a warning about an unsupported file type in the data directory during
> > R CMD check (for R 2.13.1) if I use the save function to create an Rdata,
> > but if I save the same object to a .rda file, no warning.
> >
> > Section 1.1.5 (pg 11 of the pdf) of the Writing R Extensions manual (2.13.1)
> > appears to say that .Rdata files should be fine:
> >
> > " Data files can have one of three types as indicated by their extension:
> > plain R code ('.R' or
> > '.r'), tables ('.tab', '.txt', or '.csv', see ?data for the file formats,
> > and note that '.csv' is not
> > the standard14 CSV format), or save() images ('.RData' or '.rda'). "
> >
> > Am I misunderstanding some difference between .rda and .Rdata files in terms
> > of the save calls, or should R CMD check and the extensions manual agree on
> > this?
> 
> .RData and .Rdata aren't the same.

Should that paragraph say that capitalization matters and that the following
file name extensions are recognized
  TXT
  txt
  CSV
  csv
  tab
  r
  R
  rdata
  RData
  rda
(and that others that vary only by case, such as TAB, Rdata and Rda, are not)?

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com

> 
> Duncan Murdoch
> 
> >
> > Thanks for all your hard work.
> > ~G
> >
> > SessionInfo:
> >
> > R version 2.13.1 (2011-07-08)
> > Platform: x86_64-pc-linux-gnu (64-bit)
> >
> > locale:
> >   [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
> >   [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
> >   [5] LC_MONETARY=C             LC_MESSAGES=en_US.utf8
> >   [7] LC_PAPER=en_US.utf8       LC_NAME=C
> >   [9] LC_ADDRESS=C              LC_TELEPHONE=C
> > [11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C
> >
> > attached base packages:
> > [1] grid      stats     graphics  grDevices utils     datasets  methods
> > [8] base
> >
> > other attached packages:
> > [1] gridSVG_0.5-10      ProteinVis_0.4      latticeExtra_0.6-18
> > [4] RColorBrewer_1.0-2  lattice_0.19-33
> >
> >
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From mdowle at mdowle.plus.com  Wed Aug 31 00:43:22 2011
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Tue, 30 Aug 2011 23:43:22 +0100
Subject: [Rd] Possible to read R_StringHash from a package?
Message-ID: <1314744202.1965.124.camel@netbook>

Is there any way to look at R_StringHash from a package? I've read
R-Ints 1.16.1 "Hiding C entry points" and seen that R_StringHash is
declared as extern0 in Defn.h. So it seems the answer is no.

Thanks,
Matthew


From hadley at rice.edu  Wed Aug 31 02:41:51 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Tue, 30 Aug 2011 19:41:51 -0500
Subject: [Rd] sysdata.rda, namespaces and package dependencies
In-Reply-To: <4E5D2D5B.8000500@statistik.tu-dortmund.de>
References: <CABdHhvHJCstQrsoCWhMTys6Jba5egWO6iprm2TuFy0Zrb==U1Q@mail.gmail.com>
	<CABdHhvES1MW=erb_gTNn1CUop2AmKrNeAp4=HpQpxygk3jm7bw@mail.gmail.com>
	<4E5CF273.5060309@gmail.com>
	<CABdHhvG2tKmGGBwuh+khFHCFWXBmFePOCnAyyBVS=8jU_H3oVA@mail.gmail.com>
	<4E5D1700.407@gmail.com> <4E5D1B99.6060609@statistik.tu-dortmund.de>
	<CABdHhvGrOWBSpz2qkg=iWnCEPynQ2PCmvO7oDyi3sWuqVmFigw@mail.gmail.com>
	<4E5D2D5B.8000500@statistik.tu-dortmund.de>
Message-ID: <CABdHhvFgdevpa1zcXv268Z-_7G9cs4T4OTA54kKvv-_mKgeefg@mail.gmail.com>

> That works fine for me as well and then this special data are available when
> the Namespace is loaded already. Have you put that file into package/R
> rather than package/data? Which R version?

Yes, sysdata.rda is in package/R - source code available here:
https://github.com/cwickham/munsell/tree/master/R

I'm running 2.13.1 (on a mac)

Hadley


-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From Roger.bivand at nhh.no  Wed Aug 31 12:35:24 2011
From: Roger.bivand at nhh.no (Roger Bivand)
Date: Wed, 31 Aug 2011 10:35:24 +0000
Subject: [Rd] Problem exporting table with many columns to dbf
References: <CAGYV1bJCqzF9r4H9Qqv3-SS6zCr-88hW+pKJEzrre9gOKLYVmg@mail.gmail.com>
Message-ID: <loom.20110831T122609-237@post.gmane.org>

Nacho Uve <nachouve <at> gmail.com> writes:

> 
> Hello,
> 
> I'm newbie in R and I have a problem exporting a table with many columns to
> a dbf file.

In many sources, the maximum number of fields is said to be 128 or 255. I have
seen a reference to 1024. It varies a great deal with the software being used.
DBF is certainly not a good choice for writing objects with many columns. The
page refered to on ?write.dbf:

http://www.clicketyclick.dk/databases/xbase/format/dbf.html#DBF_STRUCT

gives 128 fields; on googling for "DBF maximum number of fields", I see that:

http://www.rhinocerus.net/forum/lang-clipper/193953-maximum-fields-per-record-dbf.html

gets to 1023/4, but there are reports of very varying behaviour across different
applications. Anything over 128 may be tempting fate.

> I found an error when I open the result DBF file on other software and also
> importing it on R again.
> 
> Here a example snippet of the problem (on a GNU/Linux OS):
> http://pastebin.com/0SMJqqwb
> 
> Is it a bug?

No, more an infelicity of a legacy format with unspecified extensions.

Hope this clarifies,

Roger

> 
> Thank you,
> Nacho V


From murdoch.duncan at gmail.com  Wed Aug 31 13:42:09 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 31 Aug 2011 07:42:09 -0400
Subject: [Rd] sysdata.rda, namespaces and package dependencies
In-Reply-To: <CABdHhvFgdevpa1zcXv268Z-_7G9cs4T4OTA54kKvv-_mKgeefg@mail.gmail.com>
References: <CABdHhvHJCstQrsoCWhMTys6Jba5egWO6iprm2TuFy0Zrb==U1Q@mail.gmail.com>
	<CABdHhvES1MW=erb_gTNn1CUop2AmKrNeAp4=HpQpxygk3jm7bw@mail.gmail.com>
	<4E5CF273.5060309@gmail.com>
	<CABdHhvG2tKmGGBwuh+khFHCFWXBmFePOCnAyyBVS=8jU_H3oVA@mail.gmail.com>
	<4E5D1700.407@gmail.com>
	<4E5D1B99.6060609@statistik.tu-dortmund.de>
	<CABdHhvGrOWBSpz2qkg=iWnCEPynQ2PCmvO7oDyi3sWuqVmFigw@mail.gmail.com>
	<4E5D2D5B.8000500@statistik.tu-dortmund.de>
	<CABdHhvFgdevpa1zcXv268Z-_7G9cs4T4OTA54kKvv-_mKgeefg@mail.gmail.com>
Message-ID: <4E5E1E11.9020107@gmail.com>

On 11-08-30 8:41 PM, Hadley Wickham wrote:
>> That works fine for me as well and then this special data are available when
>> the Namespace is loaded already. Have you put that file into package/R
>> rather than package/data? Which R version?
>
> Yes, sysdata.rda is in package/R - source code available here:
> https://github.com/cwickham/munsell/tree/master/R
>

I think the problem was you weren't using the github code.  When I 
install it, I don't get the error.  I only get it from the CRAN version 
of the package, which had the munsell.map in an .rda file in the data 
subdir.

Duncan Murdoch


From simon.urbanek at r-project.org  Wed Aug 31 14:19:13 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 31 Aug 2011 08:19:13 -0400
Subject: [Rd] How to safely using OpenMP pragma inside a .C() function?
In-Reply-To: <1314723468677-3779214.post@n4.nabble.com>
References: <1314643732236-3777036.post@n4.nabble.com>
	<B2571962-7567-4F59-A1CB-415088594F47@r-project.org>
	<1314705201298-3778482.post@n4.nabble.com>
	<1314723468677-3779214.post@n4.nabble.com>
Message-ID: <CF452446-89EC-4A05-9B07-42B57984A4CD@r-project.org>


On Aug 30, 2011, at 12:57 PM, pawelm wrote:

> Simon,
> 
> I found that files R-2.13.1/src/library/stats/src/distance.c and
> R-2.13.1/src/main/array.c have openmp code (example below). I have couple
> questions regarding best practices when using R internals and openmp. 
> 
> Can we use R-2.13.1/src/library/stats/src/distance.c and
> R-2.13.1/src/main/array.c as an example how to interact with R code and R
> internals?

Technically, close, but not quite, because R internals actually use different code than R packages: in R internals calls to REAL, LENGTH etc. are macros and thus operate directly on the object (and thus optimizable), whereas in packages those are function calls (thus they do change the stack and are not optimizable!). This implies that in theory you can't use any R API calls (and things like REAL are function calls) since you have absolutely no idea what they may touch (e.g., they could - in theory - move things around since everything is serial in R which would bomb any OMP part). In practice they are more harmless, but my point is that you may want to be on the safe side, especially in the simple cases where you can avoid them.

For a trivial example you can use something like:

#include <math.h>
#include <Rinternals.h>

SEXP omp_dnorm(SEXP s_x, SEXP s_mu, SEXP s_sigma) {
    double *x = REAL(s_x);
    R_len_t n = LENGTH(s_x);
    const double mu = asReal(s_mu), sigma = asReal(s_sigma), div = sigma * sqrt(2 * M_PI);
    SEXP res = allocVector(REALSXP, n);
    double *y = REAL(res);
    R_len_t i;

#pragma omp parallel for firstprivate(x, y, n) default(none)
    for (i = 0; i < n; i++)
        y[i] = exp(-0.5 * ((x[i] - mu)/sigma) * ((x[i] - mu)/sigma)) / div;

    return res;
}

> dyn.load("ompx.so")
> x = 1:1e7/1e6
> system.time(.Call("omp_dnorm", x, 0, 1))
   user  system elapsed 
  1.680   0.020   0.095 
> system.time(dnorm(x, 0, 1))
   user  system elapsed 
  2.410   0.020   0.658 

Cheers,
Simon



> What are my other options if I want to work with SEXP structures in my
> parallel code?
> 
> Thank you
> Regards
> 
> =============
> 
> #ifdef HAVE_OPENMP
>        /* This gives a spurious -Wunused-but-set-variable error */
>        if (R_num_math_threads > 0) 
>            nthreads = R_num_math_threads;
>        else 
>            nthreads = 1; /* for now */
> #pragma omp parallel for num_threads(nthreads) default(none) \
>    private(j, i, ix, rx) \
>    firstprivate(x, ans, n, p, type, cnt, sum, \
>                 NaRm, keepNA, R_NaReal, R_NaInt, OP)
> #endif
>        for (j = 0; j < p; j++) {
>            switch (type) {
>            case REALSXP:
>                rx = REAL(x) + n*j; 
>                if (keepNA)
>                    for (sum = 0., i = 0; i < n; i++) sum += *rx++;
>                else {
>                    for (cnt = 0, sum = 0., i = 0; i < n; i++, rx++)
>                        if (!ISNAN(*rx)) {cnt++; sum += *rx;}
>                        else if (keepNA) {sum = NA_REAL; break;}
>                }    
>                break;
>            case INTSXP:
>                ix = INTEGER(x) + n*j; 
>                for (cnt = 0, sum = 0., i = 0; i < n; i++, ix++)
>                    if (*ix != NA_INTEGER) {cnt++; sum += *ix;}
>                    else if (keepNA) {sum = NA_REAL; break;}
>                break;
>            case LGLSXP:
>                ix = LOGICAL(x) + n*j; 
>                for (cnt = 0, sum = 0., i = 0; i < n; i++, ix++)
>                    if (*ix != NA_LOGICAL) {cnt++; sum += *ix;}
>                    else if (keepNA) {sum = NA_REAL; break;}
>                break;
>            default:
>                /* we checked the type above, but be sure */
>                UNIMPLEMENTED_TYPEt("do_colsum", type);
>            }
>            if (OP == 1) {
>                if (cnt > 0) sum /= cnt; else sum = NA_REAL;
>            }
>            REAL(ans)[j] = sum;
>        }
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/How-to-safely-use-OpenMP-pragma-inside-a-C-function-tp3777036p3779214.html
> Sent from the R devel mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From simon.urbanek at r-project.org  Wed Aug 31 14:37:45 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 31 Aug 2011 08:37:45 -0400
Subject: [Rd] How to safely using OpenMP pragma inside a .C() function?
In-Reply-To: <1314723468677-3779214.post@n4.nabble.com>
References: <1314643732236-3777036.post@n4.nabble.com>
	<B2571962-7567-4F59-A1CB-415088594F47@r-project.org>
	<1314705201298-3778482.post@n4.nabble.com>
	<1314723468677-3779214.post@n4.nabble.com>
Message-ID: <798B5A8C-40DD-4BFD-B02A-45950F94EAF4@r-project.org>

On Aug 30, 2011, at 12:57 PM, pawelm wrote:

> Simon,
> 
> I found that files R-2.13.1/src/library/stats/src/distance.c and
> R-2.13.1/src/main/array.c have openmp code (example below). I have couple
> questions regarding best practices when using R internals and openmp. 
> 
> Can we use R-2.13.1/src/library/stats/src/distance.c and
> R-2.13.1/src/main/array.c as an example how to interact with R code and R
> internals?
> What are my other options if I want to work with SEXP structures in my
> parallel code?
> 

I forgot to answer this one in my previous response, sorry.

The short answer is none. If you can't access what you need before the omp loop you may be in trouble. For example you can't allocate anything in the parallel code, so you can't create character elements or assign objects. There are some things (very few) you can do like using ISNA() or ISNAN() but the trouble is that without looking at the sources you don't know what you can do (note that the pragma below declares R_NaReal although it actually uses NA_REAL -- in theory that is only possible in internal R code because it knows that NA_REAL is defined as R_NaReal variable and not a fixed constant - which is entirely a matter of implementation and thus not under your control).

Cheers,
Simon


> Thank you
> Regards
> 
> =============
> 
> #ifdef HAVE_OPENMP
>        /* This gives a spurious -Wunused-but-set-variable error */
>        if (R_num_math_threads > 0) 
>            nthreads = R_num_math_threads;
>        else 
>            nthreads = 1; /* for now */
> #pragma omp parallel for num_threads(nthreads) default(none) \
>    private(j, i, ix, rx) \
>    firstprivate(x, ans, n, p, type, cnt, sum, \
>                 NaRm, keepNA, R_NaReal, R_NaInt, OP)
> #endif
>        for (j = 0; j < p; j++) {
>            switch (type) {
>            case REALSXP:
>                rx = REAL(x) + n*j; 
>                if (keepNA)
>                    for (sum = 0., i = 0; i < n; i++) sum += *rx++;
>                else {
>                    for (cnt = 0, sum = 0., i = 0; i < n; i++, rx++)
>                        if (!ISNAN(*rx)) {cnt++; sum += *rx;}
>                        else if (keepNA) {sum = NA_REAL; break;}
>                }    
>                break;
>            case INTSXP:
>                ix = INTEGER(x) + n*j; 
>                for (cnt = 0, sum = 0., i = 0; i < n; i++, ix++)
>                    if (*ix != NA_INTEGER) {cnt++; sum += *ix;}
>                    else if (keepNA) {sum = NA_REAL; break;}
>                break;
>            case LGLSXP:
>                ix = LOGICAL(x) + n*j; 
>                for (cnt = 0, sum = 0., i = 0; i < n; i++, ix++)
>                    if (*ix != NA_LOGICAL) {cnt++; sum += *ix;}
>                    else if (keepNA) {sum = NA_REAL; break;}
>                break;
>            default:
>                /* we checked the type above, but be sure */
>                UNIMPLEMENTED_TYPEt("do_colsum", type);
>            }
>            if (OP == 1) {
>                if (cnt > 0) sum /= cnt; else sum = NA_REAL;
>            }
>            REAL(ans)[j] = sum;
>        }
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/How-to-safely-use-OpenMP-pragma-inside-a-C-function-tp3777036p3779214.html
> Sent from the R devel mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From hadley at rice.edu  Wed Aug 31 16:08:45 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Wed, 31 Aug 2011 09:08:45 -0500
Subject: [Rd] sysdata.rda, namespaces and package dependencies
In-Reply-To: <4E5E1E11.9020107@gmail.com>
References: <CABdHhvHJCstQrsoCWhMTys6Jba5egWO6iprm2TuFy0Zrb==U1Q@mail.gmail.com>
	<CABdHhvES1MW=erb_gTNn1CUop2AmKrNeAp4=HpQpxygk3jm7bw@mail.gmail.com>
	<4E5CF273.5060309@gmail.com>
	<CABdHhvG2tKmGGBwuh+khFHCFWXBmFePOCnAyyBVS=8jU_H3oVA@mail.gmail.com>
	<4E5D1700.407@gmail.com> <4E5D1B99.6060609@statistik.tu-dortmund.de>
	<CABdHhvGrOWBSpz2qkg=iWnCEPynQ2PCmvO7oDyi3sWuqVmFigw@mail.gmail.com>
	<4E5D2D5B.8000500@statistik.tu-dortmund.de>
	<CABdHhvFgdevpa1zcXv268Z-_7G9cs4T4OTA54kKvv-_mKgeefg@mail.gmail.com>
	<4E5E1E11.9020107@gmail.com>
Message-ID: <CABdHhvFhVfiJxcmecOdNCHrtWAep7xevKypzDBDNBoUVs64T5w@mail.gmail.com>

>> Yes, sysdata.rda is in package/R - source code available here:
>> https://github.com/cwickham/munsell/tree/master/R
>
> I think the problem was you weren't using the github code. ?When I install
> it, I don't get the error. ?I only get it from the CRAN version of the
> package, which had the munsell.map in an .rda file in the data subdir.

Argh, that was dumb!  Thanks for picking it up and sorry for wasting
your time :(

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From oliver at first.in-berlin.de  Wed Aug 31 17:08:48 2011
From: oliver at first.in-berlin.de (oliver)
Date: Wed, 31 Aug 2011 17:08:48 +0200
Subject: [Rd] Non-GPL C (or R) inside of a package
In-Reply-To: <CABDUZc-ML9bzu=zyHqptDEQehDQkMqpGZPRd-j=pnWvk+4ioog@mail.gmail.com>
References: <CABDUZc-ML9bzu=zyHqptDEQehDQkMqpGZPRd-j=pnWvk+4ioog@mail.gmail.com>
Message-ID: <20110831150848.GA7790@siouxsie>

If you compile/link the code together,
and distribute the software, then the code must be GPL.

Seperate install makes sense. IMHO.
So then the user would put together the parts.
Not sure, but maybe the different parts also must be shipped seperated.


Ciao,
   Oliver


On Tue, Aug 30, 2011 at 12:50:37PM -0500, Jeffrey Ryan wrote:
> R-devel,
> 
> I am interested in creating a package that requires non-GPL'd (commercial) C
> code to work.  In essence it is a single .c file with no use of R headers
> (all .C callable functions).  For example's sake:
> 
>   1 #include <stdio.h>
>   2
>   3 void test (int *a) {
>   4   *a = 101;
>   5 }
> 
> The package isn't destined for CRAN, and I realize that this isn't R-legal,
> but looking for some expert advice from anyone else who may have encountered
> this previously.
> 
> The question is whether or not one can distribute code that has multiple
> licenses (.c or individual .R files), including some that are not
> GPL-compatible, as a tar.gz (or binary) file.  i.e., does the packaging
> process [R CMD ***] cause everything to become GPL, as we are using R itself
> to build the package?
> 
> I can of course provide the C libs in this case as a separate install, but
> that adds complexity to the overall build and install process.
> 
> Thanks,
> Jeff
> 
> -- 
> Jeffrey Ryan
> jeffrey.ryan at lemnica.com
> 
> www.lemnica.com
> www.esotericR.com
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jeffrey.ryan at lemnica.com  Wed Aug 31 17:34:38 2011
From: jeffrey.ryan at lemnica.com (Jeffrey Ryan)
Date: Wed, 31 Aug 2011 10:34:38 -0500
Subject: [Rd] Non-GPL C (or R) inside of a package
In-Reply-To: <alpine.LFD.2.02.1108302118390.1833@gannet.stats.ox.ac.uk>
References: <CABDUZc-ML9bzu=zyHqptDEQehDQkMqpGZPRd-j=pnWvk+4ioog@mail.gmail.com>
	<4E5D355C.1090205@gmail.com>
	<alpine.LFD.2.02.1108302118390.1833@gannet.stats.ox.ac.uk>
Message-ID: <CABDUZc8wCtL6ntuZV22=yu1kxw_xsW6CpAze22vKp3dpOkaoSg@mail.gmail.com>

On Tue, Aug 30, 2011 at 3:52 PM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
>
> On Tue, 30 Aug 2011, Duncan Murdoch wrote:
>
>> On 30/08/2011 1:50 PM, Jeffrey Ryan wrote:
>>>
>>> R-devel,
>>>
>>> I am interested in creating a package that requires non-GPL'd (commercial) C code to work. ?In essence it is a single .c file with no use of R headers (all .C callable functions). ?For example's sake:
>>>
>>> ? 1 #include<stdio.h>
>>> ? 2
>>> ? 3 void test (int *a) {
>>> ? 4 ? *a = 101;
>>> ? 5 }
>>>
>>> The package isn't destined for CRAN, and I realize that this isn't R-legal, but looking for some expert advice from anyone else who may have encountered this previously.
>>>
>>> The question is whether or not one can distribute code that has multiple licenses (.c or individual .R files), including some that are not GPL-compatible, as a tar.gz (or binary) file. ?i.e., does the packaging process [R CMD ***] cause everything to become GPL, as we are using R itself to build the package?
>>>
>> I can only say that the answer to the last question is "no": ?the author gets to choose the license for what s/he wrote. ?The fact that you used R to package it is irrelevant. ?(Some extremists will disagree, and say that because your package is intended to "link" to R, it must be licensed compatibly with the GPL if you distribute it. ?I don't think that's true.)
>
> If no distribution is involved, the conditions under which the tarball can be distributed is not relevant.
>
> As e.g. GNU tar is itself under GPL, using R to do the packaging is no different in principle to using GNU tar to do so and I've never heard anyone argue that using GNU tar affects the licence of the tarball.

Good point. ?Thanks.
>
> I don't think that is the same issue as distributing non-GPLed code for use with R. ?In the latter case the issue is what 'link to' actually entails, and one source of advice is the GPL FAQs. ?E.g.
> http://www.gnu.org/licenses/old-licenses/gpl-2.0-faq.html
> http://www.gnu.org/licenses/gpl-faq.html

I do think this is the same issue. ?The key part of that rather
wandering FAQ to me is:

http://www.gnu.org/licenses/gpl-faq.html#IfInterpreterIsGPL

Which states:

"Another similar and very common case is to provide libraries with the
interpreter which are themselves interpreted. For instance, Perl comes
with many Perl modules, and a Java implementation comes with many Java
classes. These libraries and the programs that call them are always
dynamically linked together.

A consequence is that if you choose to use GPL'd Perl modules or Java
classes in your program, you must release the program in a
GPL-compatible way, regardless of the license used in the Perl or Java
interpreter that the combined Perl or Java program will run on."

In my own terms, this seems to say using *ANY* GPL code in your
program - even if interpretted at some later point - forces all code
to be GPLed.  e.g. A script that creates a simple vector using
something like "v = 1:10" is using the GPLed base package and
therefore must be GPLed itself.

My case is a bit more subtle, as the code that I am writing makes no
use of any GPL code, aside from the compilation and linking to allow
GPL "R" code to access it.

Jeff

>
>> If you are intending to distribute this file you are putting together, you'll probably want to consult someone who knows the legalities as to whether you can legally link to the commercial library...
>
>
>
>>
>> Duncan Murdoch
>>
>>> I can of course provide the C libs in this case as a separate install, but
>>> that adds complexity to the overall build and install process.
>>>
>>> Thanks,
>>> Jeff
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> --
> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



--
Jeffrey Ryan
jeffrey.ryan at lemnica.com

www.lemnica.com
www.esotericR.com


From oliver at first.in-berlin.de  Wed Aug 31 17:40:12 2011
From: oliver at first.in-berlin.de (oliver)
Date: Wed, 31 Aug 2011 17:40:12 +0200
Subject: [Rd] Non-GPL C (or R) inside of a package
In-Reply-To: <CABDUZc8wCtL6ntuZV22=yu1kxw_xsW6CpAze22vKp3dpOkaoSg@mail.gmail.com>
References: <CABDUZc-ML9bzu=zyHqptDEQehDQkMqpGZPRd-j=pnWvk+4ioog@mail.gmail.com>
	<4E5D355C.1090205@gmail.com>
	<alpine.LFD.2.02.1108302118390.1833@gannet.stats.ox.ac.uk>
	<CABDUZc8wCtL6ntuZV22=yu1kxw_xsW6CpAze22vKp3dpOkaoSg@mail.gmail.com>
Message-ID: <20110831154012.GA8329@siouxsie>

On Wed, Aug 31, 2011 at 10:34:38AM -0500, Jeffrey Ryan wrote:
[...]
> My case is a bit more subtle, as the code that I am writing makes no
> use of any GPL code, aside from the compilation and linking to allow
> GPL "R" code to access it.
[...]

Just ask people from the FSF, if your issue is complicated.

Or ask the owner of the nmon-GPLed code, if it is possible
to make it open for your project.

That does not necessarily mean that the same code in olther
products of the company also needs to become open.

It's possible to make a "fork".

You just can't make GPLed code again closed.


Ciao,
   Oliver


From jeffrey.ryan at lemnica.com  Wed Aug 31 17:48:08 2011
From: jeffrey.ryan at lemnica.com (Jeffrey Ryan)
Date: Wed, 31 Aug 2011 10:48:08 -0500
Subject: [Rd] Non-GPL C (or R) inside of a package
In-Reply-To: <20110831154012.GA8329@siouxsie>
References: <CABDUZc-ML9bzu=zyHqptDEQehDQkMqpGZPRd-j=pnWvk+4ioog@mail.gmail.com>
	<4E5D355C.1090205@gmail.com>
	<alpine.LFD.2.02.1108302118390.1833@gannet.stats.ox.ac.uk>
	<CABDUZc8wCtL6ntuZV22=yu1kxw_xsW6CpAze22vKp3dpOkaoSg@mail.gmail.com>
	<20110831154012.GA8329@siouxsie>
Message-ID: <CABDUZc9ghS8vUx3ZEdt7zHr2RbdOxsbs84Rr5Pq=Y8GR6QMd+Q@mail.gmail.com>

On Wed, Aug 31, 2011 at 10:40 AM, oliver <oliver at first.in-berlin.de> wrote:
> On Wed, Aug 31, 2011 at 10:34:38AM -0500, Jeffrey Ryan wrote:
> [...]
>> My case is a bit more subtle, as the code that I am writing makes no
>> use of any GPL code, aside from the compilation and linking to allow
>> GPL "R" code to access it.
> [...]
>
> Just ask people from the FSF, if your issue is complicated.
>
> Or ask the owner of the nmon-GPLed code, if it is possible
> to make it open for your project.
>
> That does not necessarily mean that the same code in olther
> products of the company also needs to become open.
>
> It's possible to make a "fork".
>
> You just can't make GPLed code again closed.

Right.  I understand that perfectly.  So likely a tarball with varying
licenses *might* be ok, even if all are not GPL compatible - since one
file wouldn't affect the other.  The final compiled work though would
have to be GPLd though, since you couldn't hide the GPLd sections
under another license.  Seems to make sense to me.  And the end-user
would have to compile it to have it work, and would need to carry a
GPL license... yikes what a mess.

I think the external library via an additional download is likely the
simplest and safest route all around.

Best,
Jeff
>
>
> Ciao,
> ? Oliver
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Jeffrey Ryan
jeffrey.ryan at lemnica.com

www.lemnica.com
www.esotericR.com


From pawel.matykiewicz at gmail.com  Wed Aug 31 22:06:03 2011
From: pawel.matykiewicz at gmail.com (pawelm)
Date: Wed, 31 Aug 2011 13:06:03 -0700 (PDT)
Subject: [Rd] How to safely using OpenMP pragma inside a .C() function?
In-Reply-To: <798B5A8C-40DD-4BFD-B02A-45950F94EAF4@r-project.org>
References: <1314643732236-3777036.post@n4.nabble.com>
	<B2571962-7567-4F59-A1CB-415088594F47@r-project.org>
	<1314705201298-3778482.post@n4.nabble.com>
	<1314723468677-3779214.post@n4.nabble.com>
	<798B5A8C-40DD-4BFD-B02A-45950F94EAF4@r-project.org>
Message-ID: <1314821163584-3782073.post@n4.nabble.com>

Simon,

This is very useful example and explanation. Thank you very, very much. The
icing on the cake would be some guidelines how to set up the number of
threads. R source code uses global variable R_num_math_threads. Can we use
that? Or each openmp-enabled R package would have it's own mechanism?

Related question: I was trying to find out if R_num_math_threads could be
set up by a user and I found this line in the ./src/main/names.c file:

{"setNumMathThreads", do_setnumthreads, 0, 11, 1, {PP_FUNCALL, PREC_FN, 0}}

It suppose to be a function name but all I get in R command line is: 

Error: could not find function "setNumMathThreads"

Any thoughts?

Thank you
Regards

--
View this message in context: http://r.789695.n4.nabble.com/How-to-safely-use-OpenMP-pragma-inside-a-C-function-tp3777036p3782073.html
Sent from the R devel mailing list archive at Nabble.com.


From pawel.matykiewicz at gmail.com  Wed Aug 31 22:46:06 2011
From: pawel.matykiewicz at gmail.com (pawelm)
Date: Wed, 31 Aug 2011 13:46:06 -0700 (PDT)
Subject: [Rd] How to safely using OpenMP pragma inside a .C() function?
In-Reply-To: <1314821163584-3782073.post@n4.nabble.com>
References: <1314643732236-3777036.post@n4.nabble.com>
	<B2571962-7567-4F59-A1CB-415088594F47@r-project.org>
	<1314705201298-3778482.post@n4.nabble.com>
	<1314723468677-3779214.post@n4.nabble.com>
	<798B5A8C-40DD-4BFD-B02A-45950F94EAF4@r-project.org>
	<1314821163584-3782073.post@n4.nabble.com>
Message-ID: <1314823566871-3782178.post@n4.nabble.com>

I just found this (performance improvement of the "dist" function when using
openmp):

.Internal(setMaxNumMathThreads(1)); .Internal(setNumMathThreads(1)); m <-
matrix(rnorm(810000),900,900); system.time(d <- dist(m))

  user  system elapsed 
  3.510   0.013   3.524 

.Internal(setMaxNumMathThreads(5)); .Internal(setNumMathThreads(5)); m <-
matrix(rnorm(810000),900,900); system.time(d <- dist(m));

   user  system elapsed 
  3.536   0.007   1.321 

Works great! Just the question stays if it's a good practice to use
"R_num_math_threads" in external packages?

Thanks

--
View this message in context: http://r.789695.n4.nabble.com/How-to-safely-use-OpenMP-pragma-inside-a-C-function-tp3777036p3782178.html
Sent from the R devel mailing list archive at Nabble.com.


From simon.urbanek at r-project.org  Wed Aug 31 23:01:55 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 31 Aug 2011 17:01:55 -0400
Subject: [Rd] How to safely using OpenMP pragma inside a .C() function?
In-Reply-To: <1314823566871-3782178.post@n4.nabble.com>
References: <1314643732236-3777036.post@n4.nabble.com>
	<B2571962-7567-4F59-A1CB-415088594F47@r-project.org>
	<1314705201298-3778482.post@n4.nabble.com>
	<1314723468677-3779214.post@n4.nabble.com>
	<798B5A8C-40DD-4BFD-B02A-45950F94EAF4@r-project.org>
	<1314821163584-3782073.post@n4.nabble.com>
	<1314823566871-3782178.post@n4.nabble.com>
Message-ID: <BDB09C50-B682-4593-B219-B2F0EC952198@r-project.org>

Pawel,

On Aug 31, 2011, at 4:46 PM, pawelm wrote:

> I just found this (performance improvement of the "dist" function when using
> openmp):
> 
> .Internal(setMaxNumMathThreads(1)); .Internal(setNumMathThreads(1)); m <-
> matrix(rnorm(810000),900,900); system.time(d <- dist(m))
> 
>  user  system elapsed 
>  3.510   0.013   3.524 
> 
> .Internal(setMaxNumMathThreads(5)); .Internal(setNumMathThreads(5)); m <-
> matrix(rnorm(810000),900,900); system.time(d <- dist(m));
> 
>   user  system elapsed 
>  3.536   0.007   1.321 
> 
> Works great! Just the question stays if it's a good practice to use
> "R_num_math_threads" in external packages?
> 

Normally you don't need to mess with all this and I would recommend not to do so. The R internals use a different strategy since they need to cope with the fall-back case, but packages should not worry about that. The default number of threads is defined by the OMP_NUM_THREADS environment variable and that is the documented way in OpenMP, so my recommendation would be to not mess with num_threads() which is precisely why I did not use it in the example I gave you.

That said, R-devel has new facilities for parallelization so things may change in the future.

Cheers,
Simon


