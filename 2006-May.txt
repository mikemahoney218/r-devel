From groemping at tfh-berlin.de  Mon May  1 10:36:21 2006
From: groemping at tfh-berlin.de (groemping at tfh-berlin.de)
Date: Mon,  1 May 2006 10:36:21 +0200 (CEST)
Subject: [Rd] wishlist: summary for regression models to report number of
	omitted cases because of NAs (PR#8824)
Message-ID: <20060501083621.65E1D18DFB@slim.kubism.ku.dk>

Full_Name: Ulrike Gr?mping
Version: 2.3.0
OS: Windows
Submission from: (NULL) (84.190.150.205)


Whenever any observations are excluded from a regression analysis (lm, glm, and
other similar procedures) because of missing values, I would find it very useful
if this fact is directly visible from the output. I think that the information
should not only be available (I can e.g. look at length of the na.action element
of the lm object) but that a serious statistical software should draw users'
attention to the fact that observations have been excluded. 
For convenience, it would also be nice in general if the number of observations
used in the analysis is indicated (for lm it is of course possible but a bit
awkward to find this number in case of many parameters). 

I hope that this will be implemented because it is quite easy to do (as far as I
can see). It would make it easier for students and applied researchers to comply
with my preaching to always report on the number of valid observations and the
portion of values excluded for missingness.

With kind regards,
Ulrike Gr?mping


From maechler at stat.math.ethz.ch  Mon May  1 16:07:08 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 1 May 2006 16:07:08 +0200
Subject: [Rd] example(ask = .) - default ?
In-Reply-To: <17493.64271.123188.584580@stat.math.ethz.ch>
References: <s450ebc4.044@MC-GWDOM2.newcastle.edu.au>
	<38b9f0350604270427k162d1f42r4baeeb460aae6622@mail.gmail.com>
	<17488.60426.120454.694934@stat.math.ethz.ch>
	<4451317E.7000202@free.fr>
	<20060427211529.GA14791@alcyon.progiciels-bpi.ca>
	<17493.64271.123188.584580@stat.math.ethz.ch>
Message-ID: <17494.5644.615623.261489@stat.math.ethz.ch>

Diverting to R-devel.

After looking at more use cases, etc, I think I would like to
the change the default of 'ask' 
from	   ask = dev.interactive(orNone = TRUE)   # as of two hours ago 
to	   ask = echo && dev.interactive(orNone = TRUE)

since all the cases I've looked which specify  'echo = FALSE'
would also want 'ask = FALSE'.

Comments?

>>>>> "Martin" == Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Mon, 1 May 2006 14:11:59 +0200 writes:

>>>>> "FrPi" == Fran?ois Pinard <pinard at iro.umontreal.ca>
>>>>>     on Thu, 27 Apr 2006 17:15:29 -0400 writes:

    FrPi> [Romain Francois]
    >>> [...] it would be useful to add an option 'ask' in
    >>> 'example', maybe with a default to TRUE in interactive
    >>> mode

    FrPi> Seconded.  `example(...)' would be more friendly for
    FrPi> the average use.

    Martin> I've added it now to R-devel.  The default is 'ask =
    Martin> dev.interactive(orNone = TRUE)' where
    Martin> dev.interactive() has also been extended with the
    Martin> 'orNone' argument.

    Martin> The not-entirely satisfying aspect is that it
    Martin> currently does apply to traditional graphics only as
    Martin> opposed to grid-based graphics.

    Martin> Martin


From murdoch at stats.uwo.ca  Mon May  1 18:23:47 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 01 May 2006 12:23:47 -0400
Subject: [Rd] format.info() versus format.default():  Comments please
Message-ID: <44563613.3070903@stats.uwo.ca>

The format.info() function currently takes args (x, digits = NULL,
nsmall = 0), while format.default() takes many more:

function (x, trim = FALSE, digits = NULL, nsmall = 0, justify = c("left",
      "right", "centre", "none"), width = NULL, na.encode = TRUE,
      scientific = NA, big.mark = "", big.interval = 3, small.mark = "",
      small.interval = 5, decimal.mark = ".", zero.print = NULL,
      ...)

I think it would make sense for format.info to take at least the width,
scientific, big.*, small.*, and zero.print arguments, as these all
affect the output that format.info is calculating, i.e. the width,
decimal places, and scientific notation digits.  (It would probably be
sensible for it to take all possible format() arguments, but ignore some.)

For example, I was just writing some code to format durations as
HH:MM:SS.SSS (where the number of decimal places on the seconds was
chosen according to the values); here I wanted to tell format not
to use scientific notation, but I needed to use options(scipen=) to do
that because format.info doesn't take the scientific=FALSE argument.

Comments?

Duncan Murdoch


From ripley at stats.ox.ac.uk  Mon May  1 18:49:22 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 1 May 2006 17:49:22 +0100 (BST)
Subject: [Rd] format.info() versus format.default():  Comments please
In-Reply-To: <44563613.3070903@stats.uwo.ca>
References: <44563613.3070903@stats.uwo.ca>
Message-ID: <Pine.LNX.4.64.0605011735340.15100@gannet.stats.ox.ac.uk>

format.info() is used in no CRAN package (except in lists of known 
functions) and nowhere in R itself so I think you could do whatever you 
wanted by way of extending it.  However, I don't think it going to be 
easy, as apart from scientific those arguments are handled via 
postprocessing by prettyNum.

I would be tempted to replace format.info by a function that analysed the 
results.  The current description is wrong, of course:

> format.info(123456)
[1] 6 0 0
> format(123456, big.mark=",")
[1] "123,456"

There are also assumptions that digits and the decimal mark are of width 
one, but those are I think benign.

On Mon, 1 May 2006, Duncan Murdoch wrote:

> The format.info() function currently takes args (x, digits = NULL,
> nsmall = 0), while format.default() takes many more:
>
> function (x, trim = FALSE, digits = NULL, nsmall = 0, justify = c("left",
>      "right", "centre", "none"), width = NULL, na.encode = TRUE,
>      scientific = NA, big.mark = "", big.interval = 3, small.mark = "",
>      small.interval = 5, decimal.mark = ".", zero.print = NULL,
>      ...)
>
> I think it would make sense for format.info to take at least the width,
> scientific, big.*, small.*, and zero.print arguments, as these all
> affect the output that format.info is calculating, i.e. the width,
> decimal places, and scientific notation digits.  (It would probably be
> sensible for it to take all possible format() arguments, but ignore some.)
>
> For example, I was just writing some code to format durations as
> HH:MM:SS.SSS (where the number of decimal places on the seconds was
> chosen according to the values); here I wanted to tell format not
> to use scientific notation, but I needed to use options(scipen=) to do
> that because format.info doesn't take the scientific=FALSE argument.
>
> Comments?
>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From sfalcon at fhcrc.org  Mon May  1 19:17:07 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Mon, 01 May 2006 10:17:07 -0700
Subject: [Rd] row.names != rownames for data.frame?
Message-ID: <m24q09vf58.fsf@ziti.local>

With a recent R 2.4 I notice the following:

df <- data.frame(x=1:2)
> row.names(df)
[1] "1" "2"
> rownames(df)
[1] 1 2

This seems related to recent changes in the internal storage format of
the row names data for data frames. 

The man page for rownames says:

     For a data frame, 'rownames' and 'colnames' are equivalent to
     'row.names' and 'names' respectively.

A number of Bioconductor packages seem to be relying on this.


--

+ seth




R.version
               _                                                               
platform       powerpc-apple-darwin8.6.0                                       
arch           powerpc                                                         
os             darwin8.6.0                                                     
system         powerpc, darwin8.6.0                                            
status         Under development (unstable)                                    
major          2                                                               
minor          4.0                                                             
year           2006                                                            
month          05                                                              
day            01                                                              
svn rev        37951                                                           
language       R                                                               
version.string R version 2.4.0 Under development (unstable) (2006-05-01 r37951)


From pinard at iro.umontreal.ca  Mon May  1 23:51:06 2006
From: pinard at iro.umontreal.ca (=?iso-8859-1?Q?Fran=E7ois?= Pinard)
Date: Mon, 1 May 2006 17:51:06 -0400
Subject: [Rd] [R] plot cdf
In-Reply-To: <17493.64271.123188.584580@stat.math.ethz.ch>
References: <s450ebc4.044@MC-GWDOM2.newcastle.edu.au>
	<38b9f0350604270427k162d1f42r4baeeb460aae6622@mail.gmail.com>
	<17488.60426.120454.694934@stat.math.ethz.ch>
	<4451317E.7000202@free.fr>
	<20060427211529.GA14791@alcyon.progiciels-bpi.ca>
	<17493.64271.123188.584580@stat.math.ethz.ch>
Message-ID: <20060501215106.GA28517@alcyon.progiciels-bpi.ca>

[Martin Maechler]

>The default is  'ask = dev.interactive(orNone = TRUE)'
>where dev.interactive() has also been extended with the 'orNone'
>argument.

Thanks, Martin! :-)  (As I'm not aware of the meaning of this `orNone' 
argument, I cannot fully appreciate yet the extent of your solution.)

`?dev.interactive' says:

   Test if an interactive graphics device is in use.

I'm not sure what is the meaning of "in use" in that sentence.
An interactive device may be opened, while not being current, so some 
may say that this device is in use, others may say that it is not.  I'm 
not English speaking, but yet, I would dare to suggest either:

    Test if the current graphics device is interactive.

or:

    Test if some opened interactive graphics device is interactive.

rephrased in correct English if needed.

`ask' would ideally be TRUE if the _current_ device is interactive.  If 
there is a used (opened) device which is interactive, but the current 
device is not interactive, it would then be nicer if `ask' was FALSE.

-- 
Fran?ois Pinard   http://pinard.progiciels-bpi.ca


From fparlamis at mac.com  Tue May  2 04:53:47 2006
From: fparlamis at mac.com (Parlamis Franklin)
Date: Mon, 1 May 2006 16:53:47 -1000
Subject: [Rd] methods for @ operator
Message-ID: <F162114B-C9C8-4B99-870B-7CBF8FEC6995@mac.com>

i often find myself having a list of similarly-classed S4 objects and  
needing a list containing a particular extracted slot from those  
objects.  so i did the following:

 > setMethod("slot", signature(object = "list"),
+ 	function(object, name)
+ 		lapply(object, function(i) slot(i, name)))
Creating a new generic function for 'slot' in '.GlobalEnv'
[1] "slot"

which works as expected.

 > setClass("foo", representation(a = "numeric", b = "character"))
[1] "foo"
 > o1 <- new("foo", a = 1:5, b = "one")
 > o2 <- new("foo", a = 6:9, b = "two")
 > slot(list(o1,o2), "a")
[[1]]
[1] 1 2 3 4 5

[[2]]
[1] 6 7 8 9

 > slot(list(o1, list(o1,o2)), "a")
[[1]]
[1] 1 2 3 4 5

[[2]]
[[2]][[1]]
[1] 1 2 3 4 5

[[2]][[2]]
[1] 6 7 8 9

now, because i am too lazy to type the longer syntax required by the  
'slot' function, i am interested in doing something analogous for the  
'@' operator.
i attempted to do this as I have done it for infix operators like  
'+' , but am not meeting with success.   i am pretty sure this is  
because '+' has a predefined generic with
"dispatchable" formals e1 and e2, whereas no generic is predefined  
for '@'

 > getGeneric("+")
standardGeneric for "+" defined from package "base"
   belonging to group(s): Arith

function (e1, e2)
standardGeneric("+", .Primitive("+"))
<environment: 0x169dea44>
Methods may be defined for arguments: e1, e2

 > getGeneric("@")
NULL

nor can one be set

 > setGeneric("@")
[1] "@"
Warning message:
'@' is a primitive function;  methods can be defined, but the generic  
function is implicit, and cannot be changed. in: setGeneric("@")

however, in this last warning message, R says "methods can be  
defined" so i am left with a ray of hope.  is there some way to do this?

franklin parlamis


From fparlamis at mac.com  Tue May  2 07:16:06 2006
From: fparlamis at mac.com (Parlamis Franklin)
Date: Mon, 1 May 2006 19:16:06 -1000
Subject: [Rd] expression objects
Message-ID: <FD681FBF-70BC-4D28-99A9-4260850E1D56@mac.com>

if 'e' is a vector of mode 'expression', will the following always  
return TRUE:

identical(e, parse(text = as.character(e)))  ?

 > (e <- expression(x, y, z, 200*f%/%d, sin(e)))
expression(x, y, z, 200 * f%/%d, sin(e))
 > identical(e, parse(text = as.character(e)))
[1] TRUE

i have been relying on this fact in some of my code, and would be  
appreciative of any counterexamples.

franklin parlamis


From ggrothendieck at gmail.com  Tue May  2 08:26:08 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 2 May 2006 02:26:08 -0400
Subject: [Rd] expression objects
In-Reply-To: <FD681FBF-70BC-4D28-99A9-4260850E1D56@mac.com>
References: <FD681FBF-70BC-4D28-99A9-4260850E1D56@mac.com>
Message-ID: <971536df0605012326h53dd163ib3d923c3eee37c29@mail.gmail.com>

Try this:

   e <- as.expression("A")
   identical(parse(text = as.character(e)), e) # FALSE


On 5/2/06, Parlamis Franklin <fparlamis at mac.com> wrote:
> if 'e' is a vector of mode 'expression', will the following always
> return TRUE:
>
> identical(e, parse(text = as.character(e)))  ?
>
>  > (e <- expression(x, y, z, 200*f%/%d, sin(e)))
> expression(x, y, z, 200 * f%/%d, sin(e))
>  > identical(e, parse(text = as.character(e)))
> [1] TRUE
>
> i have been relying on this fact in some of my code, and would be
> appreciative of any counterexamples.
>
> franklin parlamis
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From maechler at stat.math.ethz.ch  Tue May  2 08:42:17 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 2 May 2006 08:42:17 +0200
Subject: [Rd] [R] plot cdf
In-Reply-To: <20060501215106.GA28517@alcyon.progiciels-bpi.ca>
References: <s450ebc4.044@MC-GWDOM2.newcastle.edu.au>
	<38b9f0350604270427k162d1f42r4baeeb460aae6622@mail.gmail.com>
	<17488.60426.120454.694934@stat.math.ethz.ch>
	<4451317E.7000202@free.fr>
	<20060427211529.GA14791@alcyon.progiciels-bpi.ca>
	<17493.64271.123188.584580@stat.math.ethz.ch>
	<20060501215106.GA28517@alcyon.progiciels-bpi.ca>
Message-ID: <17494.65353.938757.623213@stat.math.ethz.ch>

>>>>> "FrPi" == Fran?ois Pinard <pinard at iro.umontreal.ca>
>>>>>     on Mon, 1 May 2006 17:51:06 -0400 writes:

    FrPi> [Martin Maechler]
    >> The default is 'ask = dev.interactive(orNone = TRUE)'
    >> where dev.interactive() has also been extended with the
    >> 'orNone' argument.

    FrPi> Thanks, Martin! :-) (As I'm not aware of the meaning
    FrPi> of this `orNone' argument, I cannot fully appreciate
    FrPi> yet the extent of your solution.)

    FrPi> `?dev.interactive' says:

    FrPi>    Test if an interactive graphics device is in use.

    FrPi> I'm not sure what is the meaning of "in use" in that
    FrPi> sentence.  An interactive device may be opened, while
    FrPi> not being current, so some may say that this device is
    FrPi> in use, others may say that it is not.  I'm not
    FrPi> English speaking, but yet, I would dare to suggest
    FrPi> either:

    FrPi>     Test if the current graphics device is interactive.

Thank you, Fran?ois, for the suggestion.  Yes, it's the above,
and I agree it's clearer than the current text.

The new possibility
    dev.interactive(orNull = TRUE)
also returns TRUE when there is no current device
*and* the default device is an interactive one.

    FrPi> or:

    FrPi>     Test if some opened interactive graphics device is
    FrPi> interactive.

    FrPi> rephrased in correct English if needed.

    FrPi> `ask' would ideally be TRUE if the _current_ device is
    FrPi> interactive.  If there is a used (opened) device which
    FrPi> is interactive, but the current device is not
    FrPi> interactive, it would then be nicer if `ask' was
    FrPi> FALSE.

indeed; and that's the case.
Martin

    FrPi> -- Fran?ois Pinard http://pinard.progiciels-bpi.ca


From ripley at stats.ox.ac.uk  Tue May  2 09:51:22 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 2 May 2006 08:51:22 +0100 (BST)
Subject: [Rd] row.names != rownames for data.frame?
In-Reply-To: <m24q09vf58.fsf@ziti.local>
References: <m24q09vf58.fsf@ziti.local>
Message-ID: <Pine.LNX.4.64.0605020847500.27331@gannet.stats.ox.ac.uk>

On Mon, 1 May 2006, Seth Falcon wrote:

> With a recent R 2.4 I notice the following:
>
> df <- data.frame(x=1:2)
>> row.names(df)
> [1] "1" "2"
>> rownames(df)
> [1] 1 2
>
> This seems related to recent changes in the internal storage format of
> the row names data for data frames.
>
> The man page for rownames says:
>
>     For a data frame, 'rownames' and 'colnames' are equivalent to
>     'row.names' and 'names' respectively.
>
> A number of Bioconductor packages seem to be relying on this.

Interesting: nothing on CRAN did.  Those are `equivalent' but not 
identical, but let's make them identical again.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Peter.Ruckdeschel at uni-bayreuth.de  Tue May  2 11:34:06 2006
From: Peter.Ruckdeschel at uni-bayreuth.de (Peter Ruckdeschel)
Date: Tue, 02 May 2006 11:34:06 +0200
Subject: [Rd] optimize() and extrema at the interval bounds
Message-ID: <4457278E.2000703@uni-bayreuth.de>

Dear r-devels,

by construction, optimize() only evaluates the objective function
*inside* the bounds of argument 'interval'.

It does not seem to be an 'extremely' rare case that extrema are attained
*at* the bounds of argument 'interval' :-)

It is fairly easy to write a wrapper to optimize()
enforcing an evaluation of the objective function at these
bounds, too, but wouldn't it be a good idea to a add an
extra argument 'evalbounds' of optimize() defaulting to FALSE
(behavior of optimize() as it is now), but which if TRUE
does evaluate the objective at the bounds?

I do not know how costly two extra evaluations are in general
as to computation time at evaluation of optimize(), nor
how many conflicts of unmatched arguments an extra argument
to optimize() would cause; so consider this just as a proposal.

Thank you for your attention,
Peter


From xiao.gang.fan1 at libertysurf.fr  Tue May  2 15:57:25 2006
From: xiao.gang.fan1 at libertysurf.fr (xiao.gang.fan1 at libertysurf.fr)
Date: Tue,  2 May 2006 15:57:25 +0200 (CEST)
Subject: [Rd] Call trellis function in a function (PR#8827)
Message-ID: <20060502135725.BF70519B22@slim.kubism.ku.dk>

Full_Name: Fan
Version: 2.2.1
OS: Windows
Submission from: (NULL) (159.50.101.9)


Hello,

When I call trellis function (such as histogram, densityplot, etc.) in a
function,
the call seems being ignored (no graphics is drawing) if some other instructions

are placed afeter that call. 

Here's an example:

y = rnorm(100*3)
b = sample(1:3,300,replace=T)

f = function()
{
  densityplot(~y|b)
}

f1 = function()
{
  densityplot(~y|b)
  return(1)
}

f1()  # this will not draw the histogram
f()   # this will draw the histogram

Thanks in advance
Kind regards
--
Fan


From Roger.Bivand at nhh.no  Tue May  2 16:13:10 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 2 May 2006 16:13:10 +0200 (CEST)
Subject: [Rd] Call trellis function in a function (PR#8827)
In-Reply-To: <20060502135725.BF70519B22@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.44.0605021612390.19564-100000@reclus.nhh.no>

On Tue, 2 May 2006 xiao.gang.fan1 at libertysurf.fr wrote:

This is a FAQ:

http://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-do-lattice_002ftrellis-graphics-not-work_003f

> Full_Name: Fan
> Version: 2.2.1
> OS: Windows
> Submission from: (NULL) (159.50.101.9)
> 
> 
> Hello,
> 
> When I call trellis function (such as histogram, densityplot, etc.) in a
> function,
> the call seems being ignored (no graphics is drawing) if some other instructions
> 
> are placed afeter that call. 
> 
> Here's an example:
> 
> y = rnorm(100*3)
> b = sample(1:3,300,replace=T)
> 
> f = function()
> {
>   densityplot(~y|b)
> }
> 
> f1 = function()
> {
>   densityplot(~y|b)
>   return(1)
> }
> 
> f1()  # this will not draw the histogram
> f()   # this will draw the histogram
> 
> Thanks in advance
> Kind regards
> --
> Fan
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From murdoch at stats.uwo.ca  Tue May  2 18:09:16 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 02 May 2006 12:09:16 -0400
Subject: [Rd] Force action in package install?
Message-ID: <4457842C.3000701@stats.uwo.ca>

I'd like to substitute the Subversion revision number for a string in a 
package man page every time the package is installed or built.  I can 
assume it is being installed or built from a Subversion working copy.

I tried putting a target that depends on FORCE into Makefile or Makevars 
in the src directory, but it is not being built.  What sort of make 
magic do I need, and where do I put it in order to get R CMD INSTALL to 
run my code?

Duncan Murdoch


From dupan at northwestern.edu  Tue May  2 18:34:24 2006
From: dupan at northwestern.edu (dupan at northwestern.edu)
Date: Tue,  2 May 2006 18:34:24 +0200 (CEST)
Subject: [Rd] Installation problem of R.app GUI 1.15 for R 2.3.0 (PR#8828)
Message-ID: <20060502163424.31EC7CCD9@slim.kubism.ku.dk>

Full_Name: Pan Du
Version: 2.3.0
OS: Mac OS X 10.4.6
Submission from: (NULL) (165.124.152.227)


Hi,

I just downloaded the latest R2.3.0 for Mac. When I tried to install R.app GUI
1.15, it told me "You cannot install R GUI for Mac OS X on this volume. Requires
Mac OS X 10.4.4 or higher." But actually I am using Mac OS X 10.4.6, which is
higher than 10.4.4. Is there anyone knows what the problem is? BTW, all other
packages were installed smoothly. Thanks a lot!

Best,

Pan


From tibshirani at gmail.com  Tue May  2 18:44:25 2006
From: tibshirani at gmail.com (Tibshirani)
Date: Tue, 02 May 2006 12:44:25 -0400
Subject: [Rd] normal random number generator in R
Message-ID: <200605021244.26160.tibshirani@gmail.com>

Hi,

I am trying to figure out how normal random number generator works in R. As I 
look at .../src/nmath/snorm.c file, I find the default algorithm is inverse 
CDF method. In more detail, instead of directly using uniform value by 
unif_rand(), snorm function will first get a sum by adding unif_rand() and 
2^27*unif_rand(), then divide it by 2^27 and transfer it to qnorm5() function 
for inverting. Only a short comment for this operation is available in the 
source:
/* unif_rand() alone is not of high enough precision */

Just curious why this operation is needed? Is it a general algorithm for 
inverse CDF method, or simply unif_rand() in R returns float precision?

Thanks
Tib


From ripley at stats.ox.ac.uk  Tue May  2 18:54:20 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 2 May 2006 17:54:20 +0100 (BST)
Subject: [Rd] normal random number generator in R
In-Reply-To: <200605021244.26160.tibshirani@gmail.com>
References: <200605021244.26160.tibshirani@gmail.com>
Message-ID: <Pine.LNX.4.64.0605021745570.24527@gannet.stats.ox.ac.uk>

On Tue, 2 May 2006, Tibshirani wrote:

> Hi,
>
> I am trying to figure out how normal random number generator works in R. As I
> look at .../src/nmath/snorm.c file, I find the default algorithm is inverse
> CDF method. In more detail, instead of directly using uniform value by
> unif_rand(), snorm function will first get a sum by adding unif_rand() and
> 2^27*unif_rand(), then divide it by 2^27 and transfer it to qnorm5() function
> for inverting. Only a short comment for this operation is available in the
> source:
> /* unif_rand() alone is not of high enough precision */
>
> Just curious why this operation is needed? Is it a general algorithm for
> inverse CDF method, or simply unif_rand() in R returns float precision?

unif_rand() returns a uniform over about 2^31 distinct doubles, and that 
gives granularity in the far tails of a normal.

It is a known (at least to me) trick for improving the accuracy of 
inversion.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ksawery.pasciak at gmail.com  Tue May  2 20:05:23 2006
From: ksawery.pasciak at gmail.com (ksawery.pasciak at gmail.com)
Date: Tue,  2 May 2006 20:05:23 +0200 (CEST)
Subject: [Rd] Histogram to pdf file (PR#8829)
Message-ID: <20060502180523.EE7B51995A@slim.kubism.ku.dk>

Full_Name: Ksawery
Version: 2.30
OS: WinXp
Submission from: (NULL) (195.150.76.2)


The bug apears when I'm trying to save, for example histogram into PDF file.I'm
using Polish language, and while in R letters are correct, in PDF file I have
some strange one...


From simon.urbanek at r-project.org  Tue May  2 20:43:25 2006
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 2 May 2006 14:43:25 -0400
Subject: [Rd] Installation problem of R.app GUI 1.15 for R 2.3.0
	(PR#8828)
In-Reply-To: <20060502163424.31EC7CCD9@slim.kubism.ku.dk>
References: <20060502163424.31EC7CCD9@slim.kubism.ku.dk>
Message-ID: <4D39810C-FDB0-4D82-A346-DA414E6E8C35@r-project.org>

Pan,

On May 2, 2006, at 12:34 PM, dupan at northwestern.edu wrote:

> I just downloaded the latest R2.3.0 for Mac. When I tried to  
> install R.app GUI 1.15, it told me "You cannot install R GUI for  
> Mac OS X on this volume. Requires Mac OS X 10.4.4 or higher." But  
> actually I am using Mac OS X 10.4.6, which is higher than 10.4.4.  
> Is there anyone knows what the problem is? BTW, all other packages  
> were installed smoothly. Thanks a lot!
>

Indeed there is a bug in that PackageMaker that causes the individual  
installer for Packages/R-GUI.pkg to fail (SpecType should be plist  
not bundle). Please use the regular R package instead (R.mpkg) - that  
should work.

FWIW: If R.app is all you want, you may in fact just get it from the  
nightly page ( http://R.research.att.com ), because as it appears it  
has an important bug fix:
http://R.research.att.com/R-GUI-3114-2.3-Deployment.dmg

Cheers,
Simon


From simon.urbanek at r-project.org  Tue May  2 22:25:53 2006
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 2 May 2006 16:25:53 -0400
Subject: [Rd] Force action in package install?
In-Reply-To: <4457842C.3000701@stats.uwo.ca>
References: <4457842C.3000701@stats.uwo.ca>
Message-ID: <559D7B3C-2D8C-49EF-881C-4C9A420B2386@r-project.org>


On May 2, 2006, at 12:09 PM, Duncan Murdoch wrote:

> I tried putting a target that depends on FORCE into Makefile or  
> Makevars in the src directory, but it is not being built.  What  
> sort of make magic do I need, and where do I put it in order to get  
> R CMD INSTALL to run my code?
>

I don't think that's supported at all. I have successfully used this  
VeryUglyHack(TM) in the package's Makevars:

OBJECTS=dummy.o real1.o real2.o

dummy.o: myExtraTarget
	echo "" > dummy.c
	$(CC) $(ALL_CPPFLAGS) $(ALL_CFLAGS) -c dummy.c -o $@

where real1.o and real2.o are real object files that have  
corresponding sources and dummy.c is a non-existent file thus forcing  
make to use my extra target. This hack exploits the fact that SHLIB  
will let Makevars override the objects list (the above is not the  
exact application I use, but the essence of the idea).

I agree that it would be great to add something like $(EXTRA_TARGETS)  
to SHLIB such that Makevars can define extra targets.

Back to your original problem, though, I never build packages  
directly from development sources (didn't we have a discussion about  
this recently?) for the reasons discussed - IMHO it's much better to  
have a script build the package tar ball, stamping files as necessary.

Cheers,
Simon


From simon.urbanek at r-project.org  Tue May  2 22:46:55 2006
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 2 May 2006 16:46:55 -0400
Subject: [Rd] Force action in package install?
In-Reply-To: <559D7B3C-2D8C-49EF-881C-4C9A420B2386@r-project.org>
References: <4457842C.3000701@stats.uwo.ca>
	<559D7B3C-2D8C-49EF-881C-4C9A420B2386@r-project.org>
Message-ID: <BBB6E524-39D5-4AEA-86A3-7D435F40771C@r-project.org>


On May 2, 2006, at 4:25 PM, Simon Urbanek wrote:

>
> On May 2, 2006, at 12:09 PM, Duncan Murdoch wrote:
>
>> I tried putting a target that depends on FORCE into Makefile or  
>> Makevars in the src directory, but it is not being built.  What  
>> sort of make magic do I need, and where do I put it in order to  
>> get R CMD INSTALL to run my code?
>>
>
> I don't think that's supported at all. I have successfully used  
> this VeryUglyHack(TM) in the package's Makevars:
>

Oops - I just realized that it's a huge overkill for what you  
described (the application actually did matter - it involved  
generated c files). The generated files force make to re-make the  
target unconditionally when using phony target, but that's another  
story. Sorry for the noise - feel free to delete it :).

Cheers,
Simon


From ghuang at stat.nctu.edu.tw  Wed May  3 04:24:55 2006
From: ghuang at stat.nctu.edu.tw (ghuang at stat.nctu.edu.tw)
Date: Wed,  3 May 2006 04:24:55 +0200 (CEST)
Subject: [Rd] cannot use fanny in package cluster (PR#8830)
Message-ID: <20060503022455.7A304F8F8@slim.kubism.ku.dk>

Full_Name: Guan-Hua Huang
Version: 2.0.1
OS: Linux
Submission from: (NULL) (140.113.114.123)


I install the package cluster by using install.packages("cluster"). After
install it, it runs fine for function clara, but it does not work for function
fanny. I did the following things:

library(cluster)
set.seed(21)
x <- rbind(cbind(rnorm(10, 0, 0.5), rnorm(10, 0, 0.5)),
           cbind(rnorm(15, 5, 0.5), rnorm(15, 5, 0.5)),
           cbind(rnorm( 3,3.2,0.5), rnorm( 3,3.2,0.5)))
.proctime00 <- proc.time()
(fannyx <- fanny(x, 2))

and got the following messages:

Error in .Fortran("fanny", as.integer(n), as.integer(jp), k, x2, dis = dv, ;
Fortran function name not in DLL for package cluster

Any help.

Guan-Hua


From ligges at statistik.uni-dortmund.de  Wed May  3 08:39:33 2006
From: ligges at statistik.uni-dortmund.de (ligges at statistik.uni-dortmund.de)
Date: Wed,  3 May 2006 08:39:33 +0200 (CEST)
Subject: [Rd] cannot use fanny in package cluster (PR#8830)
Message-ID: <20060503063933.C5F17E93A@slim.kubism.ku.dk>

ghuang at stat.nctu.edu.tw wrote:

> Full_Name: Guan-Hua Huang
> Version: 2.0.1
> OS: Linux
> Submission from: (NULL) (140.113.114.123)
> 
> 
> I install the package cluster by using install.packages("cluster"). After
> install it, it runs fine for function clara, but it does not work for function
> fanny. I did the following things:
> 
> library(cluster)
> set.seed(21)
> x <- rbind(cbind(rnorm(10, 0, 0.5), rnorm(10, 0, 0.5)),
>            cbind(rnorm(15, 5, 0.5), rnorm(15, 5, 0.5)),
>            cbind(rnorm( 3,3.2,0.5), rnorm( 3,3.2,0.5)))
> .proctime00 <- proc.time()
> (fannyx <- fanny(x, 2))
> 
> and got the following messages:
> 
> Error in .Fortran("fanny", as.integer(n), as.integer(jp), k, x2, dis = dv, ;
> Fortran function name not in DLL for package cluster
> 
> Any help.
> 
> Guan-Hua
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


If this is a bug, then with your installation of the package, but NOT 
with R nor with the package.

Please read the FAQs what a bug is and how to report it (check with a 
***recent*** version of R first!).

Uwe Ligges


From ligges at statistik.uni-dortmund.de  Wed May  3 08:48:52 2006
From: ligges at statistik.uni-dortmund.de (ligges at statistik.uni-dortmund.de)
Date: Wed,  3 May 2006 08:48:52 +0200 (CEST)
Subject: [Rd] Histogram to pdf file (PR#8829)
Message-ID: <20060503064852.D30E719A1D@slim.kubism.ku.dk>

ksawery.pasciak at gmail.com wrote:

> Full_Name: Ksawery
> Version: 2.30

Currently we have R-2.3.0. 2.30 will be released in October 2019, if R 
core does not manage to get R-3.0.0 out some day before.


> OS: WinXp
> Submission from: (NULL) (195.150.76.2)
> 
> 
> The bug apears when I'm trying to save, for example histogram into PDF file.I'm
> using Polish language, and while in R letters are correct, in PDF file I have
> some strange one...


Which bug?
Please read the FAQs what a bug is and how to report it.

I'd highly recommend to *ask* a question on R-help how to solve your 
problem rather than claiming there is a bug without giving a 
reproducible example that helps to fix it.

Uwe Ligges



> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Wed May  3 13:58:17 2006
From: maechler at stat.math.ethz.ch (maechler at stat.math.ethz.ch)
Date: Wed,  3 May 2006 13:58:17 +0200 (CEST)
Subject: [Rd] cannot use fanny in package cluster (PR#8830)
Message-ID: <20060503115817.AC433D922@slim.kubism.ku.dk>

>>>>> "UweL" == Uwe Ligges <ligges at statistik.uni-dortmund.de>
>>>>>     on Wed,  3 May 2006 08:39:33 +0200 (CEST) writes:

    UweL> ghuang at stat.nctu.edu.tw wrote:
    >> Full_Name: Guan-Hua Huang Version: 2.0.1 OS: Linux
    >> Submission from: (NULL) (140.113.114.123)
    >> 
    >> 
    >> I install the package cluster by using
    >> install.packages("cluster"). After install it, it runs
    >> fine for function clara, but it does not work for
    >> function fanny. I did the following things:
    >> 
    >> library(cluster) set.seed(21) x <- rbind(cbind(rnorm(10,
    >> 0, 0.5), rnorm(10, 0, 0.5)), cbind(rnorm(15, 5, 0.5),
    >> rnorm(15, 5, 0.5)), cbind(rnorm( 3,3.2,0.5), rnorm(
    >> 3,3.2,0.5))) .proctime00 <- proc.time() (fannyx <-
    >> fanny(x, 2))
    >> 
    >> and got the following messages:
    >> 
    >> Error in .Fortran("fanny", as.integer(n), as.integer(jp),
    >> k, x2, dis = dv, ; Fortran function name not in DLL for
    >> package cluster
    >> 
    >> Any help.
    >> 
    >> Guan-Hua

    UweL> If this is a bug, then with your installation of the
    UweL> package, but NOT with R nor with the package.

    UweL> Please read the FAQs what a bug is and how to report
    UweL> it (check with a ***recent*** version of R first!).

Indeed.

However, as Uwe properly pointed out in a related E-mail,
there is a bug -- still not in R , and hence not for R-bugs !! ---
in the DESCRIPTION file of newer versions of 'cluster':

You shouldn't have been able to install the current version of
the package 'cluster' with your ancient version of R, since
cluster effectively requires R version >= 2.2.1
(because earlier versions of R had a bug in their registration
 of Fortran symbols).

Hence, if you want to continue using your outdated version of R,
you should really use the old version cluster that was part of
your version of R...

Martin


From smanz at ix.urz.uni-heidelberg.de  Wed May  3 16:14:57 2006
From: smanz at ix.urz.uni-heidelberg.de (Sebastian Manz)
Date: Wed, 3 May 2006 16:14:57 +0200 (METDST)
Subject: [Rd] R freezes under Windows while loading package
Message-ID: <Pine.A41.4.42.0605031551350.48928-100000@aixterm6.urz.uni-heidelberg.de>

Hi,

we build this R package using C++ code and under linux it works fine.
After installing:
- R version 2.2.1
- minGW gcc version 3.4.2
- perl version 5.8.8
it finally compiled under Windows as well. But, if we try to load the
library, R freezes without stressing the CPU.

Maybe someone had a similar problem and now has a simple solution for
it.


Thanks,
Sebastian Manz,
Timo Breitner.


From murdoch at stats.uwo.ca  Wed May  3 16:22:39 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 03 May 2006 10:22:39 -0400
Subject: [Rd] R freezes under Windows while loading package
In-Reply-To: <Pine.A41.4.42.0605031551350.48928-100000@aixterm6.urz.uni-heidelberg.de>
References: <Pine.A41.4.42.0605031551350.48928-100000@aixterm6.urz.uni-heidelberg.de>
Message-ID: <4458BCAF.80704@stats.uwo.ca>

On 5/3/2006 10:14 AM, Sebastian Manz wrote:
> Hi,
> 
> we build this R package using C++ code and under linux it works fine.
> After installing:
> - R version 2.2.1
> - minGW gcc version 3.4.2
> - perl version 5.8.8
> it finally compiled under Windows as well. But, if we try to load the
> library, R freezes without stressing the CPU.
> 
> Maybe someone had a similar problem and now has a simple solution for
> it.

Presumably the problem is in the DLL.  Can you use dyn.load() to load it 
manually?  If so, you can set a debug breakpoint on each entry point, 
and see where things are going wrong.  Instructions for doing C-level 
debugging under Windows are on my web page,

http://www.stats.uwo.ca/faculty/murdoch/software/debuggingR/

and more general-purpose instructions are in the Writing R Extensions 
manual in 2.3.0.

Duncan Murdoch


From spencer.graves at pdf.com  Wed May  3 19:29:05 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 03 May 2006 10:29:05 -0700
Subject: [Rd] as.factor: changed behaviour for Date class
In-Reply-To: <b0808fdc0604270331r400ee269q5323f117da3610e4@mail.gmail.com>
References: <b0808fdc0604270331r400ee269q5323f117da3610e4@mail.gmail.com>
Message-ID: <4458E861.9010309@pdf.com>

	  Have you received a reply to this post?  I haven't seen one.
 > t9 <- 9:10
 > class(t9) <- "Date"
 > t9
[1] "1970-01-10" "1970-01-11"
 > as.factor(t9)
[1] 9  10
Levels: 9 10

	  I confirmed what you got with a slightly different example:

 > t9 <- 9:10
 > class(t9) <- "Date"
 > t9
[1] "1970-01-10" "1970-01-11"
# Apparently, 'class(times) <- "Date"' had the anticipated effect

	  As you indicated, 'as.factor' in R-2.2.1 used character string 
representations of the dates as levels, while in R-2.3.0 it did not:

 > as.factor(t9) # in R-2.3.0
[1] 9  10
Levels: 9 10

 > as.factor(t9) # in R-2.2.1
[1] 1970-01-10 1970-01-11
Levels: 1970-01-10 1970-01-11

	  R-2.2.1 and R-2.3.0 returned the same for the following:
 >  as.numeric(as.factor(t9))
[1] 1 2

 > sessionInfo()
Version 2.3.0 (2006-04-24)
i386-pc-mingw32

attached base packages:
[1] "grid"      "methods"   "stats"     "graphics"  "grDevices" "utils"
[7] "datasets"  "base"

other attached packages:
  tseries      zoo quadprog  lattice
"0.10-0"  "1.0-6"  "1.4-8" "0.13-8"

 > sessionInfo()
Version 2.3.0 (2006-04-24)
i386-pc-mingw32

attached base packages:
[1] "grid"      "methods"   "stats"     "graphics"  "grDevices" "utils"
[7] "datasets"  "base"

other attached packages:
  tseries      zoo quadprog  lattice
"0.10-0"  "1.0-6"  "1.4-8" "0.13-8"

	  hope this helps.
	  spencer graves

Antonio, Fabio Di Narzo wrote:

> Dear all,
> I have noticed a little change in the behaviour of as.factor from R-2.2.1 to
> R-2.3.0, and can't find it in the NEWS.
> 
> In R-2.3.0:
> 
>>times <- 1:5
>>class(times) <- "Date"
>>as.factor(times)
> 
> [1] 1 2 3 4 5
> Levels: 1 2 3 4 5
> 
> In R-2.2.1:
> 
>>as.factor(times)
> 
> [1] 1970-01-02 1970-01-03 1970-01-04 1970-01-05 1970-01-06
> Levels: 1970-01-02 1970-01-03 1970-01-04 1970-01-05 1970-01-06
> 
> Is this the intended behaviour?
> Note that the change is reflected on other functions which seems to use
> as.factor internally, for example 'tapply'.
> Consider the following code:
> 
> times <- 1:5
> class(times) <- "Date"
> id <- rep(times, each=2)
> vals <- rep(1:2,5)
> tapply(vals, id, mean)
> 
> Under R-2.2.1 this gives:
> 1970-01-02 1970-01-03 1970-01-04 1970-01-05 1970-01-06
>        1.5        1.5        1.5        1.5        1.5
> 
> But under R-2.3.0 the output is:
>  1   2   3   4   5
> 1.5 1.5 1.5 1.5 1.5
> 
> Antonio, Fabio Di Narzo.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From smanz at ix.urz.uni-heidelberg.de  Wed May  3 18:47:51 2006
From: smanz at ix.urz.uni-heidelberg.de (Seb)
Date: Wed, 3 May 2006 18:47:51 +0200
Subject: [Rd] R freezes under Windows while loading package
In-Reply-To: <4458BCAF.80704@stats.uwo.ca>
References: <Pine.A41.4.42.0605031551350.48928-100000@aixterm6.urz.uni-heidelberg.de>
	<4458BCAF.80704@stats.uwo.ca>
Message-ID: <20060503184751.5a4c69c7@localhost>

On Wed, 03 May 2006 10:22:39 -0400
Duncan Murdoch <murdoch at stats.uwo.ca> wrote:

> On 5/3/2006 10:14 AM, Sebastian Manz wrote:
> > Hi,
> > 
> > we build this R package using C++ code and under linux it works
> > fine. After installing:
> > - R version 2.2.1
> > - minGW gcc version 3.4.2
> > - perl version 5.8.8
> > it finally compiled under Windows as well. But, if we try to load
> > the library, R freezes without stressing the CPU.
> > 
> > Maybe someone had a similar problem and now has a simple solution
> > for it.
> 
> Presumably the problem is in the DLL.  Can you use dyn.load() to load
> it manually?  If so, you can set a debug breakpoint on each entry
> point, and see where things are going wrong.  Instructions for doing
> C-level debugging under Windows are on my web page,
> 
> http://www.stats.uwo.ca/faculty/murdoch/software/debuggingR/
> 
> and more general-purpose instructions are in the Writing R Extensions 
> manual in 2.3.0.
> 
> Duncan Murdoch

Thank you very much for your fast reply.

The problem is found. It had something to do with a library we're
using. 

Sorry we bothered you,
Sebastian Manz


From pinard at iro.umontreal.ca  Thu May  4 00:04:36 2006
From: pinard at iro.umontreal.ca (=?iso-8859-1?Q?Fran=E7ois?= Pinard)
Date: Wed, 3 May 2006 18:04:36 -0400
Subject: [Rd] abline and its documentation
Message-ID: <20060503220436.GA18145@phenix.sram.qc.ca>

Hi, people.  The documentation of abline says:


Usage:

     abline(a, b, untf = FALSE, ...)
     abline(h=, untf = FALSE, ...)
     abline(v=, untf = FALSE, ...)
     abline(coef=, untf = FALSE, ...)
     abline(reg=, untf = FALSE, ...)


so suggesting that h= and v= usages are exclusive.  There are examples 
in the mailing list archives of using both at the same time, and I find 
convenient, for example, doing:

    abline(h=0, v=0, ...)

for bolding the position of the origin or the axes through the origin.


By doing so, we are using undocumented capabilities of abline and 
consequently, writing bugged R code.  It does not matter so much 
interactively, but scripts may be more sensitive.

Would it be acceptable to amend abline documentation, so to commit the 
capability of abline to do both h= and v= at once?   Or even combined 
with intercept and slope?  (abline is able to do all three at once 
already!)  Then, R users and code could more safely rely on this.

Just a suggestion, and not a big matter, of course! :-)

-- 
Fran?ois Pinard   http://pinard.progiciels-bpi.ca


From ggrothendieck at gmail.com  Thu May  4 02:36:43 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 3 May 2006 20:36:43 -0400
Subject: [Rd] [R] Aggregate?
In-Reply-To: <971536df0605031327o56993db3n43d82a67fcab8b10@mail.gmail.com>
References: <BA6FF017E924044A9BF748AFAEEA6F30A53314@FWC-TLEX3.fwc.state.fl.us>
	<971536df0605031327o56993db3n43d82a67fcab8b10@mail.gmail.com>
Message-ID: <971536df0605031736p3c59f182u6da8e565aeed60e0@mail.gmail.com>

I am moving this from r-help to r-devel.

The poster pointed out to me that my solution works in 2.2.1 but not
in 2.3.0 patched.  Does anyone know what the problem is?

> # 2.3.0 patched -- gives error
> DF <- data.frame(A = gl(2,2), B = gl(2,2), C = 1:4)  # test data
> out.by <- by(DF, DF$A, function(x) replace(x[1,], "C", sum(x$C)))
> do.call(rbind, out.by)
Error in data.frame(A = c("1", "2"), B = c("1", "2"), C = c("3", "7"),  :
        row names contain missing values
> R.version.string # Windows XP
[1] "Version 2.3.0 Patched (2006-04-28 r37936)"

> # 2.3.1 -- works ok
> DF <- data.frame(A = gl(2,2), B = gl(2,2), C = 1:4)  # test data
> out.by <- by(DF, DF$A, function(x) replace(x[1,], "C", sum(x$C)))
> do.call(rbind, out.by)
  A B C
1 1 1 3
2 2 2 7
> R.version.string # Windows XP
[1] "R version 2.2.1, 2005-12-20"

On 5/3/06, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> Suppose we want to sum C over levels of A and that B is constant
> within levels of A.  Then:
>
> DF <- data.frame(A = gl(2,2), B = gl(2,2), C = 1:4)  # test data
> do.call("rbind", by(DF, DF$A, function(x) replace(x[1,], "C", sum(x$C))))
>
>
>
> On 5/3/06, Guenther, Cameron <Cameron.Guenther at myfwc.com> wrote:
> > Hello,
> >
> > I have a data set with a grouping variable (TRIPID) and  several other
> > variables.  TRIPID is repeated in some areas and I would like to use a
> > function like aggregate to sum the variable UNITS according to TRIPID.
> > However I would also like to retain the other variables as they are in
> > the data set with the new summed TRIPID.
> >
> > So what I have is something like this:
> >
> > YEAR    MONTH   DAY     CONTINUE        SPL     AREA    COUNTY  DEPTH
> > DEPUNIT GEAR    GEAR2   TRAPS   SOAKTIME        UNITS   FACTOR  DISPOSIT
> > NUMSETS TRIPST  TRIPID
> > 1992            1           26              1         SP0073928       8
> > 25         4           NA      1000000     NA          NA
> > NA              161             1           NA              NA
> > NA      0216    3399054     1992            1           26
> > 1         SP0073928       8             25         4           NA
> > 1000000     NA          NA              NA              8
> > 1           NA              NA              NA      0216    3399054
> > 1992            1           26              2         SP0004228       8
> > 25         4           NA      1000000     NA          NA
> > NA              161             1           NA              NA
> > NA      0216    3399054      1992            1           26
> > 2         SP0004228       8             25         4           NA
> > 1000000     NA          NA              NA              8
> > 1           NA              NA              NA      0216    3399054
> > 1992            1           25              NA      SP0052652       8
> > 25         4           NA      1000000     NA          NA
> > NA              85              1           NA              NA
> > NA      0216    3399057       1992            1           26
> > NA      SP0037940       8             25         4           NA
> > 1000000     NA          NA              NA              70
> > 1           NA              NA              NA      0216    3399058
> > 1992            1           27              NA      SP0072357       8
> > 25         4           NA      1000000     NA          NA
> > NA              15              1           NA              NA
> > NA      0216    3399059
> > 1992            1           27              NA      SP0072357       8
> > 25         4           NA      1000000     NA          NA
> > NA              20              1           NA              NA
> > NA      0216    3399059     1992            1           27
> > NA      SP0026324       8             25         4           NA
> > 1000000     NA          NA              NA              8
> > 1           NA              NA              NA      0216    3399060
> > 1992            1           28              1         SP0072357       8
> > 25         4           NA      1000000     NA          NA
> > NA              200            1           NA              NA
> > NA      0216    3399062
> >
> > And what I want is this:
> >
> > YEAR    MONTH   DAY     CONTINUE        SPL     AREA    COUNTY  DEPTH
> > DEPUNIT GEAR    GEAR2   TRAPS   SOAKTIME        UNITS   FACTOR  DISPOSIT
> > NUMSETS TRIPST  TRIPID
> > 1992            1           26              1         SP0073928       8
> > 25         4           NA      1000000     NA          NA
> > NA              338            1           NA              NA
> > NA      0216    3399054      1992            1           25
> > NA      SP0052652       8             25         4           NA
> > 1000000     NA          NA              NA              85
> > 1           NA              NA              NA      0216    3399057
> > 1992            1           26              NA      SP0037940       8
> > 25         4           NA      1000000     NA          NA
> > NA              70              1           NA              NA
> > NA      0216    3399058
> > 1992            1           27              NA      SP0072357       8
> > 25         4           NA      1000000     NA          NA
> > NA              35              1           NA              NA
> > NA      0216    3399059
> > 1992            1           27              NA      SP0026324       8
> > 25         4           NA      1000000     NA          NA
> > NA              8               1           NA              NA
> > NA      0216    3399060
> > 1992            1           28              1         SP0072357       8
> > 25         4           NA      1000000     NA          NA
> > NA              200            1           NA              NA
> > NA      0216    3399062
> >
> >
> > Does anyone know how to do this.  Data file is attached.
> > Thanks in advance
> >
> > Cameron Guenther, Ph.D.
> > Associate Research Scientist
> > FWC/FWRI, Marine Fisheries Research
> > 100 8th Avenue S.E.
> > St. Petersburg, FL 33701
> > (727)896-8626 Ext. 4305
> > cameron.guenther at myfwc.com
> >
> >        [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
>


From rpeng at jhsph.edu  Thu May  4 03:24:26 2006
From: rpeng at jhsph.edu (Roger Peng)
Date: Wed, 03 May 2006 21:24:26 -0400
Subject: [Rd] [R] Aggregate?
In-Reply-To: <971536df0605031736p3c59f182u6da8e565aeed60e0@mail.gmail.com>
References: <BA6FF017E924044A9BF748AFAEEA6F30A53314@FWC-TLEX3.fwc.state.fl.us>
	<971536df0605031327o56993db3n43d82a67fcab8b10@mail.gmail.com>
	<971536df0605031736p3c59f182u6da8e565aeed60e0@mail.gmail.com>
Message-ID: <445957CA.1060709@jhsph.edu>

This was fixed fairly recently in 2.3.0 patched.  It works in SVN 
revision 37953.

-roger

Gabor Grothendieck wrote:
> I am moving this from r-help to r-devel.
> 
> The poster pointed out to me that my solution works in 2.2.1 but not
> in 2.3.0 patched.  Does anyone know what the problem is?
> 
> 
>># 2.3.0 patched -- gives error
>>DF <- data.frame(A = gl(2,2), B = gl(2,2), C = 1:4)  # test data
>>out.by <- by(DF, DF$A, function(x) replace(x[1,], "C", sum(x$C)))
>>do.call(rbind, out.by)
> 
> Error in data.frame(A = c("1", "2"), B = c("1", "2"), C = c("3", "7"),  :
>         row names contain missing values
> 
>>R.version.string # Windows XP
> 
> [1] "Version 2.3.0 Patched (2006-04-28 r37936)"
> 
> 
>># 2.3.1 -- works ok
>>DF <- data.frame(A = gl(2,2), B = gl(2,2), C = 1:4)  # test data
>>out.by <- by(DF, DF$A, function(x) replace(x[1,], "C", sum(x$C)))
>>do.call(rbind, out.by)
> 
>   A B C
> 1 1 1 3
> 2 2 2 7
> 
>>R.version.string # Windows XP
> 
> [1] "R version 2.2.1, 2005-12-20"
> 
> On 5/3/06, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> 
>>Suppose we want to sum C over levels of A and that B is constant
>>within levels of A.  Then:
>>
>>DF <- data.frame(A = gl(2,2), B = gl(2,2), C = 1:4)  # test data
>>do.call("rbind", by(DF, DF$A, function(x) replace(x[1,], "C", sum(x$C))))
>>
>>
>>
>>On 5/3/06, Guenther, Cameron <Cameron.Guenther at myfwc.com> wrote:
>>
>>>Hello,
>>>
>>>I have a data set with a grouping variable (TRIPID) and  several other
>>>variables.  TRIPID is repeated in some areas and I would like to use a
>>>function like aggregate to sum the variable UNITS according to TRIPID.
>>>However I would also like to retain the other variables as they are in
>>>the data set with the new summed TRIPID.
>>>
>>>So what I have is something like this:
>>>
>>>YEAR    MONTH   DAY     CONTINUE        SPL     AREA    COUNTY  DEPTH
>>>DEPUNIT GEAR    GEAR2   TRAPS   SOAKTIME        UNITS   FACTOR  DISPOSIT
>>>NUMSETS TRIPST  TRIPID
>>>1992            1           26              1         SP0073928       8
>>>25         4           NA      1000000     NA          NA
>>>NA              161             1           NA              NA
>>>NA      0216    3399054     1992            1           26
>>>1         SP0073928       8             25         4           NA
>>>1000000     NA          NA              NA              8
>>>1           NA              NA              NA      0216    3399054
>>>1992            1           26              2         SP0004228       8
>>>25         4           NA      1000000     NA          NA
>>>NA              161             1           NA              NA
>>>NA      0216    3399054      1992            1           26
>>>2         SP0004228       8             25         4           NA
>>>1000000     NA          NA              NA              8
>>>1           NA              NA              NA      0216    3399054
>>>1992            1           25              NA      SP0052652       8
>>>25         4           NA      1000000     NA          NA
>>>NA              85              1           NA              NA
>>>NA      0216    3399057       1992            1           26
>>>NA      SP0037940       8             25         4           NA
>>>1000000     NA          NA              NA              70
>>>1           NA              NA              NA      0216    3399058
>>>1992            1           27              NA      SP0072357       8
>>>25         4           NA      1000000     NA          NA
>>>NA              15              1           NA              NA
>>>NA      0216    3399059
>>>1992            1           27              NA      SP0072357       8
>>>25         4           NA      1000000     NA          NA
>>>NA              20              1           NA              NA
>>>NA      0216    3399059     1992            1           27
>>>NA      SP0026324       8             25         4           NA
>>>1000000     NA          NA              NA              8
>>>1           NA              NA              NA      0216    3399060
>>>1992            1           28              1         SP0072357       8
>>>25         4           NA      1000000     NA          NA
>>>NA              200            1           NA              NA
>>>NA      0216    3399062
>>>
>>>And what I want is this:
>>>
>>>YEAR    MONTH   DAY     CONTINUE        SPL     AREA    COUNTY  DEPTH
>>>DEPUNIT GEAR    GEAR2   TRAPS   SOAKTIME        UNITS   FACTOR  DISPOSIT
>>>NUMSETS TRIPST  TRIPID
>>>1992            1           26              1         SP0073928       8
>>>25         4           NA      1000000     NA          NA
>>>NA              338            1           NA              NA
>>>NA      0216    3399054      1992            1           25
>>>NA      SP0052652       8             25         4           NA
>>>1000000     NA          NA              NA              85
>>>1           NA              NA              NA      0216    3399057
>>>1992            1           26              NA      SP0037940       8
>>>25         4           NA      1000000     NA          NA
>>>NA              70              1           NA              NA
>>>NA      0216    3399058
>>>1992            1           27              NA      SP0072357       8
>>>25         4           NA      1000000     NA          NA
>>>NA              35              1           NA              NA
>>>NA      0216    3399059
>>>1992            1           27              NA      SP0026324       8
>>>25         4           NA      1000000     NA          NA
>>>NA              8               1           NA              NA
>>>NA      0216    3399060
>>>1992            1           28              1         SP0072357       8
>>>25         4           NA      1000000     NA          NA
>>>NA              200            1           NA              NA
>>>NA      0216    3399062
>>>
>>>
>>>Does anyone know how to do this.  Data file is attached.
>>>Thanks in advance
>>>
>>>Cameron Guenther, Ph.D.
>>>Associate Research Scientist
>>>FWC/FWRI, Marine Fisheries Research
>>>100 8th Avenue S.E.
>>>St. Petersburg, FL 33701
>>>(727)896-8626 Ext. 4305
>>>cameron.guenther at myfwc.com
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>>
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/


From ggrothendieck at gmail.com  Thu May  4 03:32:41 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 3 May 2006 21:32:41 -0400
Subject: [Rd] [R] Aggregate?
In-Reply-To: <445957CA.1060709@jhsph.edu>
References: <BA6FF017E924044A9BF748AFAEEA6F30A53314@FWC-TLEX3.fwc.state.fl.us>
	<971536df0605031327o56993db3n43d82a67fcab8b10@mail.gmail.com>
	<971536df0605031736p3c59f182u6da8e565aeed60e0@mail.gmail.com>
	<445957CA.1060709@jhsph.edu>
Message-ID: <971536df0605031832g1eca9105p36a5e79daab6d7d@mail.gmail.com>

I guess there is no Windows binary for that version yet since I downloaded
the most recent Windows binary off CRAN a minute before I tried it.

On 5/3/06, Roger Peng <rpeng at jhsph.edu> wrote:
> This was fixed fairly recently in 2.3.0 patched.  It works in SVN
> revision 37953.
>
> -roger
>
> Gabor Grothendieck wrote:
> > I am moving this from r-help to r-devel.
> >
> > The poster pointed out to me that my solution works in 2.2.1 but not
> > in 2.3.0 patched.  Does anyone know what the problem is?
> >
> >
> >># 2.3.0 patched -- gives error
> >>DF <- data.frame(A = gl(2,2), B = gl(2,2), C = 1:4)  # test data
> >>out.by <- by(DF, DF$A, function(x) replace(x[1,], "C", sum(x$C)))
> >>do.call(rbind, out.by)
> >
> > Error in data.frame(A = c("1", "2"), B = c("1", "2"), C = c("3", "7"),  :
> >         row names contain missing values
> >
> >>R.version.string # Windows XP
> >
> > [1] "Version 2.3.0 Patched (2006-04-28 r37936)"
> >
> >
> >># 2.3.1 -- works ok
> >>DF <- data.frame(A = gl(2,2), B = gl(2,2), C = 1:4)  # test data
> >>out.by <- by(DF, DF$A, function(x) replace(x[1,], "C", sum(x$C)))
> >>do.call(rbind, out.by)
> >
> >   A B C
> > 1 1 1 3
> > 2 2 2 7
> >
> >>R.version.string # Windows XP
> >
> > [1] "R version 2.2.1, 2005-12-20"
> >
> > On 5/3/06, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> >
> >>Suppose we want to sum C over levels of A and that B is constant
> >>within levels of A.  Then:
> >>
> >>DF <- data.frame(A = gl(2,2), B = gl(2,2), C = 1:4)  # test data
> >>do.call("rbind", by(DF, DF$A, function(x) replace(x[1,], "C", sum(x$C))))
> >>
> >>
> >>
> >>On 5/3/06, Guenther, Cameron <Cameron.Guenther at myfwc.com> wrote:
> >>
> >>>Hello,
> >>>
> >>>I have a data set with a grouping variable (TRIPID) and  several other
> >>>variables.  TRIPID is repeated in some areas and I would like to use a
> >>>function like aggregate to sum the variable UNITS according to TRIPID.
> >>>However I would also like to retain the other variables as they are in
> >>>the data set with the new summed TRIPID.
> >>>
> >>>So what I have is something like this:
> >>>
> >>>YEAR    MONTH   DAY     CONTINUE        SPL     AREA    COUNTY  DEPTH
> >>>DEPUNIT GEAR    GEAR2   TRAPS   SOAKTIME        UNITS   FACTOR  DISPOSIT
> >>>NUMSETS TRIPST  TRIPID
> >>>1992            1           26              1         SP0073928       8
> >>>25         4           NA      1000000     NA          NA
> >>>NA              161             1           NA              NA
> >>>NA      0216    3399054     1992            1           26
> >>>1         SP0073928       8             25         4           NA
> >>>1000000     NA          NA              NA              8
> >>>1           NA              NA              NA      0216    3399054
> >>>1992            1           26              2         SP0004228       8
> >>>25         4           NA      1000000     NA          NA
> >>>NA              161             1           NA              NA
> >>>NA      0216    3399054      1992            1           26
> >>>2         SP0004228       8             25         4           NA
> >>>1000000     NA          NA              NA              8
> >>>1           NA              NA              NA      0216    3399054
> >>>1992            1           25              NA      SP0052652       8
> >>>25         4           NA      1000000     NA          NA
> >>>NA              85              1           NA              NA
> >>>NA      0216    3399057       1992            1           26
> >>>NA      SP0037940       8             25         4           NA
> >>>1000000     NA          NA              NA              70
> >>>1           NA              NA              NA      0216    3399058
> >>>1992            1           27              NA      SP0072357       8
> >>>25         4           NA      1000000     NA          NA
> >>>NA              15              1           NA              NA
> >>>NA      0216    3399059
> >>>1992            1           27              NA      SP0072357       8
> >>>25         4           NA      1000000     NA          NA
> >>>NA              20              1           NA              NA
> >>>NA      0216    3399059     1992            1           27
> >>>NA      SP0026324       8             25         4           NA
> >>>1000000     NA          NA              NA              8
> >>>1           NA              NA              NA      0216    3399060
> >>>1992            1           28              1         SP0072357       8
> >>>25         4           NA      1000000     NA          NA
> >>>NA              200            1           NA              NA
> >>>NA      0216    3399062
> >>>
> >>>And what I want is this:
> >>>
> >>>YEAR    MONTH   DAY     CONTINUE        SPL     AREA    COUNTY  DEPTH
> >>>DEPUNIT GEAR    GEAR2   TRAPS   SOAKTIME        UNITS   FACTOR  DISPOSIT
> >>>NUMSETS TRIPST  TRIPID
> >>>1992            1           26              1         SP0073928       8
> >>>25         4           NA      1000000     NA          NA
> >>>NA              338            1           NA              NA
> >>>NA      0216    3399054      1992            1           25
> >>>NA      SP0052652       8             25         4           NA
> >>>1000000     NA          NA              NA              85
> >>>1           NA              NA              NA      0216    3399057
> >>>1992            1           26              NA      SP0037940       8
> >>>25         4           NA      1000000     NA          NA
> >>>NA              70              1           NA              NA
> >>>NA      0216    3399058
> >>>1992            1           27              NA      SP0072357       8
> >>>25         4           NA      1000000     NA          NA
> >>>NA              35              1           NA              NA
> >>>NA      0216    3399059
> >>>1992            1           27              NA      SP0026324       8
> >>>25         4           NA      1000000     NA          NA
> >>>NA              8               1           NA              NA
> >>>NA      0216    3399060
> >>>1992            1           28              1         SP0072357       8
> >>>25         4           NA      1000000     NA          NA
> >>>NA              200            1           NA              NA
> >>>NA      0216    3399062
> >>>
> >>>
> >>>Does anyone know how to do this.  Data file is attached.
> >>>Thanks in advance
> >>>
> >>>Cameron Guenther, Ph.D.
> >>>Associate Research Scientist
> >>>FWC/FWRI, Marine Fisheries Research
> >>>100 8th Avenue S.E.
> >>>St. Petersburg, FL 33701
> >>>(727)896-8626 Ext. 4305
> >>>cameron.guenther at myfwc.com
> >>>
> >>>       [[alternative HTML version deleted]]
> >>>
> >>>______________________________________________
> >>>R-help at stat.math.ethz.ch mailing list
> >>>https://stat.ethz.ch/mailman/listinfo/r-help
> >>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >>>
> >>
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
> --
> Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/
>


From murdoch at stats.uwo.ca  Thu May  4 03:46:49 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 03 May 2006 21:46:49 -0400
Subject: [Rd] [R] Aggregate?
In-Reply-To: <971536df0605031832g1eca9105p36a5e79daab6d7d@mail.gmail.com>
References: <BA6FF017E924044A9BF748AFAEEA6F30A53314@FWC-TLEX3.fwc.state.fl.us>	<971536df0605031327o56993db3n43d82a67fcab8b10@mail.gmail.com>	<971536df0605031736p3c59f182u6da8e565aeed60e0@mail.gmail.com>	<445957CA.1060709@jhsph.edu>
	<971536df0605031832g1eca9105p36a5e79daab6d7d@mail.gmail.com>
Message-ID: <44595D09.4050601@stats.uwo.ca>

On 5/3/2006 9:32 PM, Gabor Grothendieck wrote:
> I guess there is no Windows binary for that version yet since I downloaded
> the most recent Windows binary off CRAN a minute before I tried it.

The build process that leads to the binaries on CRAN is fairly flaky. 
When something goes wrong, it blocks until I notice and kill a few jobs. 
  Right now, for example, the latest builds are from April 28 (as they 
say, right at the bottom of the page).  I restarted things today, so 
tomorrow you might see newer builds there.

When the R Foundation starts paying my salary, I'll devote my full 
attention to the build process.

Duncan Murdoch

> 
> On 5/3/06, Roger Peng <rpeng at jhsph.edu> wrote:
>> This was fixed fairly recently in 2.3.0 patched.  It works in SVN
>> revision 37953.
>>
>> -roger
>>
>> Gabor Grothendieck wrote:
>>> I am moving this from r-help to r-devel.
>>>
>>> The poster pointed out to me that my solution works in 2.2.1 but not
>>> in 2.3.0 patched.  Does anyone know what the problem is?
>>>
>>>
>>>> # 2.3.0 patched -- gives error
>>>> DF <- data.frame(A = gl(2,2), B = gl(2,2), C = 1:4)  # test data
>>>> out.by <- by(DF, DF$A, function(x) replace(x[1,], "C", sum(x$C)))
>>>> do.call(rbind, out.by)
>>> Error in data.frame(A = c("1", "2"), B = c("1", "2"), C = c("3", "7"),  :
>>>         row names contain missing values
>>>
>>>> R.version.string # Windows XP
>>> [1] "Version 2.3.0 Patched (2006-04-28 r37936)"
>>>
>>>
>>>> # 2.3.1 -- works ok
>>>> DF <- data.frame(A = gl(2,2), B = gl(2,2), C = 1:4)  # test data
>>>> out.by <- by(DF, DF$A, function(x) replace(x[1,], "C", sum(x$C)))
>>>> do.call(rbind, out.by)
>>>   A B C
>>> 1 1 1 3
>>> 2 2 2 7
>>>
>>>> R.version.string # Windows XP
>>> [1] "R version 2.2.1, 2005-12-20"
>>>
>>> On 5/3/06, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
>>>
>>>> Suppose we want to sum C over levels of A and that B is constant
>>>> within levels of A.  Then:
>>>>
>>>> DF <- data.frame(A = gl(2,2), B = gl(2,2), C = 1:4)  # test data
>>>> do.call("rbind", by(DF, DF$A, function(x) replace(x[1,], "C", sum(x$C))))
>>>>
>>>>
>>>>
>>>> On 5/3/06, Guenther, Cameron <Cameron.Guenther at myfwc.com> wrote:
>>>>
>>>>> Hello,
>>>>>
>>>>> I have a data set with a grouping variable (TRIPID) and  several other
>>>>> variables.  TRIPID is repeated in some areas and I would like to use a
>>>>> function like aggregate to sum the variable UNITS according to TRIPID.
>>>>> However I would also like to retain the other variables as they are in
>>>>> the data set with the new summed TRIPID.
>>>>>
>>>>> So what I have is something like this:
>>>>>
>>>>> YEAR    MONTH   DAY     CONTINUE        SPL     AREA    COUNTY  DEPTH
>>>>> DEPUNIT GEAR    GEAR2   TRAPS   SOAKTIME        UNITS   FACTOR  DISPOSIT
>>>>> NUMSETS TRIPST  TRIPID
>>>>> 1992            1           26              1         SP0073928       8
>>>>> 25         4           NA      1000000     NA          NA
>>>>> NA              161             1           NA              NA
>>>>> NA      0216    3399054     1992            1           26
>>>>> 1         SP0073928       8             25         4           NA
>>>>> 1000000     NA          NA              NA              8
>>>>> 1           NA              NA              NA      0216    3399054
>>>>> 1992            1           26              2         SP0004228       8
>>>>> 25         4           NA      1000000     NA          NA
>>>>> NA              161             1           NA              NA
>>>>> NA      0216    3399054      1992            1           26
>>>>> 2         SP0004228       8             25         4           NA
>>>>> 1000000     NA          NA              NA              8
>>>>> 1           NA              NA              NA      0216    3399054
>>>>> 1992            1           25              NA      SP0052652       8
>>>>> 25         4           NA      1000000     NA          NA
>>>>> NA              85              1           NA              NA
>>>>> NA      0216    3399057       1992            1           26
>>>>> NA      SP0037940       8             25         4           NA
>>>>> 1000000     NA          NA              NA              70
>>>>> 1           NA              NA              NA      0216    3399058
>>>>> 1992            1           27              NA      SP0072357       8
>>>>> 25         4           NA      1000000     NA          NA
>>>>> NA              15              1           NA              NA
>>>>> NA      0216    3399059
>>>>> 1992            1           27              NA      SP0072357       8
>>>>> 25         4           NA      1000000     NA          NA
>>>>> NA              20              1           NA              NA
>>>>> NA      0216    3399059     1992            1           27
>>>>> NA      SP0026324       8             25         4           NA
>>>>> 1000000     NA          NA              NA              8
>>>>> 1           NA              NA              NA      0216    3399060
>>>>> 1992            1           28              1         SP0072357       8
>>>>> 25         4           NA      1000000     NA          NA
>>>>> NA              200            1           NA              NA
>>>>> NA      0216    3399062
>>>>>
>>>>> And what I want is this:
>>>>>
>>>>> YEAR    MONTH   DAY     CONTINUE        SPL     AREA    COUNTY  DEPTH
>>>>> DEPUNIT GEAR    GEAR2   TRAPS   SOAKTIME        UNITS   FACTOR  DISPOSIT
>>>>> NUMSETS TRIPST  TRIPID
>>>>> 1992            1           26              1         SP0073928       8
>>>>> 25         4           NA      1000000     NA          NA
>>>>> NA              338            1           NA              NA
>>>>> NA      0216    3399054      1992            1           25
>>>>> NA      SP0052652       8             25         4           NA
>>>>> 1000000     NA          NA              NA              85
>>>>> 1           NA              NA              NA      0216    3399057
>>>>> 1992            1           26              NA      SP0037940       8
>>>>> 25         4           NA      1000000     NA          NA
>>>>> NA              70              1           NA              NA
>>>>> NA      0216    3399058
>>>>> 1992            1           27              NA      SP0072357       8
>>>>> 25         4           NA      1000000     NA          NA
>>>>> NA              35              1           NA              NA
>>>>> NA      0216    3399059
>>>>> 1992            1           27              NA      SP0026324       8
>>>>> 25         4           NA      1000000     NA          NA
>>>>> NA              8               1           NA              NA
>>>>> NA      0216    3399060
>>>>> 1992            1           28              1         SP0072357       8
>>>>> 25         4           NA      1000000     NA          NA
>>>>> NA              200            1           NA              NA
>>>>> NA      0216    3399062
>>>>>
>>>>>
>>>>> Does anyone know how to do this.  Data file is attached.
>>>>> Thanks in advance
>>>>>
>>>>> Cameron Guenther, Ph.D.
>>>>> Associate Research Scientist
>>>>> FWC/FWRI, Marine Fisheries Research
>>>>> 100 8th Avenue S.E.
>>>>> St. Petersburg, FL 33701
>>>>> (727)896-8626 Ext. 4305
>>>>> cameron.guenther at myfwc.com
>>>>>
>>>>>       [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at stat.math.ethz.ch mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>> --
>> Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From lmr-core at stat.math.ethz.ch  Thu May  4 10:00:48 2006
From: lmr-core at stat.math.ethz.ch (Ollie Sewell)
Date: Thu, 04 May 2006 00:00:48 -0800
Subject: [Rd] yo stop work today
Message-ID: <8i07071b4127196399a622t3096sw19t8998j50p763t@129.132.145.15>

R-core

How are ya....
+-------------------------------------------------------------------------------------------------------------+
|                 GET YOUR U|NIVERSITY DIP'LOMA                                  |
|                                                                                                                |
|     Do you want a prosperous future, increased earning power               |
|                more money and the respect of all?                                         |
|                                                                                                                |
|             Call this number: 1-206-339-8143 (24 hours)                               |
|                                                                                                                |
|                                                                                                                |
|     There are no required tests, classes, books, or interviews!                 |
|                                                                                                                |
|     Get a Ba;chelors, Maste_rs, MBA, and Doctorat-e (PhD) Dip`loma!    |
|                                                                                                                |
|     Receive the benefits and admiration that comes with a Di'ploma!     |
|                                                                                                                |
|           No one is turned down! Start making money Now!                       |
|                                                                                                                |
|                                                                                                                |
|         Call Today 1-206-339-8143 (7 days a week, 24 hours a day)         |
|                                                                                                                | 
|                           Confidentiality assured!                                                 |
|                                                                                                                | 
+--------------------------------------------------------------------------------------------------------------+
 
 Chat Later
 
 Ollie Sewell


From Kurt.Hornik at wu-wien.ac.at  Thu May  4 09:18:53 2006
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Thu, 4 May 2006 09:18:53 +0200
Subject: [Rd] abline and its documentation
In-Reply-To: <20060503220436.GA18145@phenix.sram.qc.ca>
References: <20060503220436.GA18145@phenix.sram.qc.ca>
Message-ID: <17497.43741.908109.939891@mithrandir.hornik.net>

>>>>> Fran?ois Pinard writes:

> Hi, people.  The documentation of abline says:
> Usage:

>      abline(a, b, untf = FALSE, ...)
>      abline(h=, untf = FALSE, ...)
>      abline(v=, untf = FALSE, ...)
>      abline(coef=, untf = FALSE, ...)
>      abline(reg=, untf = FALSE, ...)


> so suggesting that h= and v= usages are exclusive.  There are examples 
> in the mailing list archives of using both at the same time, and I find 
> convenient, for example, doing:

>     abline(h=0, v=0, ...)

> for bolding the position of the origin or the axes through the origin.


> By doing so, we are using undocumented capabilities of abline and 
> consequently, writing bugged R code.  It does not matter so much 
> interactively, but scripts may be more sensitive.

> Would it be acceptable to amend abline documentation, so to commit the 
> capability of abline to do both h= and v= at once?   Or even combined 
> with intercept and slope?  (abline is able to do all three at once 
> already!)  Then, R users and code could more safely rely on this.

> Just a suggestion, and not a big matter, of course! :-)

Afaic, I would change the \usage to just given the function synopsis
(removing \synopsis along the way), and indicate the various usage
scenarios via details and/or examples.

-k


From Kurt.Hornik at wu-wien.ac.at  Thu May  4 14:25:55 2006
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Thu, 4 May 2006 14:25:55 +0200
Subject: [Rd] proposed modifications to deprecated
In-Reply-To: <4450E082.5010206@fhcrc.org>
References: <4450E082.5010206@fhcrc.org>
Message-ID: <17497.62163.53804.774546@mithrandir.hornik.net>

>>>>> Robert Gentleman writes:

> Hi,
>    Over the past six months we have had a few problems with deprecation 
> and Seth Falcon and I want to propose a few additions to the mechanism 
> that will help deal with cases other than the deprecation of functions.

>   In the last release one of the arguments to La.svd was deprecated, but 
> the warning message was very unclear and suggested that in fact La.svd 
> was deprecated.
>    Adding a third argument to .Deprecated, msg say (to be consistent 
> with the internal naming mechanism) that contains the message string 
> would allow for handling the La.svd issue in a more informative way. It 
> is a strict addition so no existing code is likely to be broken.

That's a very nice idea afaic.

>    We also need to deprecate data from time to time. Since the field of 
> genomics is moving fast as good example from five years ago is often no 
> longer a good example today. This one is a bit harder, but we can modify
>    tools:::.make_file_exts("data")

>    to first look for a ".DEP" extension (this does not seem to be a 
> widely used extension), and if such a file exists, ie NameofData.DEP
>   one of two things happens: if it contains a character string we use 
> that for the message (we could source it for the message?), if not print 
> a standard message (just as .Deprecated does) and then continue with the 
> search using the other file extensions.

>    Defunct could be handled similarly.

>   Comments, alternative suggestions?

I thought about more declarative (R-code-based) alternatives, but using
a new extension seems most convenient (as it also achieves registration
with no need for further code analysis).

I would have a slight preference for using ".deprecated", and similar
using ".defunct" if necessary.

One of the annoying things about the current two-cycle deprecate/defunct
process is that R CMD check can only catch usages in code run by the
examples.  It would be nice to use the codetools infrastructure for an
improved code analysis here (checking for calling deprecated "global"
variables or function arguments (e.g., for the La.svd() example).  Of
course, this would not only require that codetools can be made to work
again for 2.4.0 (and we do pay a heavy price for the NULL environment
changes here afaic), but also that we have a registry for deprecated
things ...

Btw, is there a formal way of deprecating arguments to functions?  Part
of the possible La.svd() confusion might come from using

    if(is.numeric(x) && method == "dgesvd")
        .Deprecated('La.svd(method = "dgesvd")')

Best
-k


From gkotler at rics.bwh.harvard.edu  Thu May  4 19:12:59 2006
From: gkotler at rics.bwh.harvard.edu (Gregory Kotler)
Date: Thu, 04 May 2006 13:12:59 -0400
Subject: [Rd] Cox survival model
Message-ID: <445A361B.40909@rics.bwh.harvard.edu>

Hi ALL,

I am trying to modify Cox propotional hazard function according to my 
project needs.
Is it possible to find source code of C procedures used for fittinf 
PHREG model:
coxfit2.c and  coxmart.c.?

   Thank you,
      Gregory Kotler


From tlumley at u.washington.edu  Thu May  4 20:04:31 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 4 May 2006 11:04:31 -0700 (PDT)
Subject: [Rd] Cox survival model
In-Reply-To: <445A361B.40909@rics.bwh.harvard.edu>
References: <445A361B.40909@rics.bwh.harvard.edu>
Message-ID: <Pine.LNX.4.64.0605041104130.29649@homer21.u.washington.edu>

On Thu, 4 May 2006, Gregory Kotler wrote:

> Hi ALL,
>
> I am trying to modify Cox propotional hazard function according to my
> project needs.
> Is it possible to find source code of C procedures used for fittinf
> PHREG model:
> coxfit2.c and  coxmart.c.?

They are in the source code package.

 	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From eatkinso at mdanderson.org  Thu May  4 20:08:47 2006
From: eatkinso at mdanderson.org (eatkinso at mdanderson.org)
Date: Thu,  4 May 2006 20:08:47 +0200 (CEST)
Subject: [Rd] R 2.3.0 and rgl on OS X 10.4.6 (PR#8833)
Message-ID: <20060504180847.EBEC119B99@slim.kubism.ku.dk>

I just downloaded and installed R 2.3.0 on my Mac G5 running
OS X 10.4.6. I also updated with R.app revision 3114 as
recommended. Now, when I attemp to use package rgl
I get the error

> library(rgl)
Error: package 'rgl' is not installed for 'arch=ppc'
>

I have tried reinstalling from CRAN using both binary
and source. The source install fails, The binary install
yields

>
Warning in install.packages(file.choose(), , NULL, type = "mac.binary") :
       argument 'lib' is missing: using /Users/neely/Library/R/library
>

and does not fix the problem.

The same problem occurs with some packages (e1071, svmpath)
but not others (gdata, gplots, gtools).

Any advice would be greatly appreciated.

Neely Atkinson
eatkinso at mdanderson.org
713-792-2619


From murdoch at stats.uwo.ca  Thu May  4 20:22:09 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 04 May 2006 14:22:09 -0400
Subject: [Rd] R 2.3.0 and rgl on OS X 10.4.6 (PR#8833)
In-Reply-To: <20060504180847.EBEC119B99@slim.kubism.ku.dk>
References: <20060504180847.EBEC119B99@slim.kubism.ku.dk>
Message-ID: <445A4651.4010501@stats.uwo.ca>

On 5/4/2006 2:08 PM, eatkinso at mdanderson.org wrote:
> I just downloaded and installed R 2.3.0 on my Mac G5 running
> OS X 10.4.6. I also updated with R.app revision 3114 as
> recommended. Now, when I attemp to use package rgl
> I get the error
> 
>> library(rgl)
> Error: package 'rgl' is not installed for 'arch=ppc'
>>
> 
> I have tried reinstalling from CRAN using both binary
> and source. The source install fails, The binary install
> yields
> 
>>
> Warning in install.packages(file.choose(), , NULL, type = "mac.binary") :
>        argument 'lib' is missing: using /Users/neely/Library/R/library
>>
> 
> and does not fix the problem.
> 
> The same problem occurs with some packages (e1071, svmpath)
> but not others (gdata, gplots, gtools).
> 
> Any advice would be greatly appreciated.

I expect you'll need to install from source, but I don't know who will 
be able to help you to diagnose why it is failing.  I'd suggest trying 
on the R-SIG-Mac mailing list.

If you can determine what the problem is and can fix it I'd be happy to 
incorporate your patch.  Otherwise, all I can suggest is that you try a 
more commonly used platform.

Duncan Murdoch


From ripley at stats.ox.ac.uk  Thu May  4 20:38:06 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 4 May 2006 19:38:06 +0100 (BST)
Subject: [Rd] Cox survival model
In-Reply-To: <Pine.LNX.4.64.0605041104130.29649@homer21.u.washington.edu>
References: <445A361B.40909@rics.bwh.harvard.edu>
	<Pine.LNX.4.64.0605041104130.29649@homer21.u.washington.edu>
Message-ID: <Pine.LNX.4.64.0605041934290.23562@gannet.stats.ox.ac.uk>

On Thu, 4 May 2006, Thomas Lumley wrote:

> On Thu, 4 May 2006, Gregory Kotler wrote:
>
>> Hi ALL,
>>
>> I am trying to modify Cox propotional hazard function according to my
>> project needs.
>> Is it possible to find source code of C procedures used for fittinf
>> PHREG model:
>> coxfit2.c and  coxmart.c.?
>
> They are in the source code package.

I presume the level of problem here is that that user does not know about 
that, and is a Windows or Mac user.

Go to your nearest CRAN mirror and visit the equivalent of
http://cran.r-project.org/src/contrib/Descriptions/survival.html

That has a link to 'Package source:'  Download it, and it you are a 
Windows user unpack it using the tools from

http://www.murdoch-sutherland.com/Rtools/

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hb at stat.berkeley.edu  Thu May  4 23:49:58 2006
From: hb at stat.berkeley.edu (Henrik Bengtsson (max 7Mb))
Date: Thu, 4 May 2006 14:49:58 -0700
Subject: [Rd] Rgui, Startup, HOME, R_USER, ...
Message-ID: <59d7961d0605041449q6a7086f0gd7c4d503527f6bd0@mail.gmail.com>

Hi,

Main objective: Let Rgui find my ~/.Rprofile and ~/.Renviron files,
where ~ is equal to getwd("~").

I have few comments/questions:

(A) On my WinXP Pro installation, the system environment variable
'HOME' is not availble to R, e.g. Sys.getenv("HOME") is empty.  I
believe this is default case (correct me if I'm wrong).  However, if I
set the "Start in:" to %HOME% in the Properties for the Rgui.exe file,
the working directory is indeed set to getwd("~"), so 'HOME' is
available for the startup of R.  Excuse me for my lack of
understanding WinXP, but why is this?  What sysenv variables are
available to the R process?  PS. I know I can add HOME=<path> in the
Rgui.exe properties, however I'm interested in the default lookup
path. DS.

(B) With the default "Start in:" value of "C:\Program
Files\R\R-2.3.0pat", the ~/My Documents/.Rprofile is called.  I tried
to understand why exactly this path.  Reading the R FAQ for Windows,
it says that 'R_USER' is used as the default value for the home
directory.  Where/when is this set, and how?  I don't set it myself. 
It looks like it is set equal to 'HOME' and if that is not set, the to
the default %HOMEDRIVE%\%HOMEPATH%\My Documents\, e.g.

M:\>set HOME=
M:\>Rterm --quiet
> Sys.getenv("R_USER")
                                        R_USER
"C:\\Documents and Settings\\hb\\My Documents"
M:\>set HOME=%HOMEDRIVE%\%HOMEPATH%
M:\>Rterm --quiet
> Sys.getenv("R_USER")
                            R_USER
"C:\\\\Documents and Settings\\hb"

M:\>set HOME=%HOMEDRIVE%\%HOMEPATH%\foo
M:\>Rterm --quiet
> Sys.getenv("R_USER")
                                 R_USER
"C:\\\\Documents and Settings\\hb\\foo"

>From the above I found out that I should put .Rprofile etc in ~/My
Documents/ for Rgui to find it by default.  Is this behavior
documented somewhere and why this specific directory?  For parallelism
to Unix etc, it would be more natural to have ~/.Rprofile search for
by default, but that is not the case (unless I set HOME).

(C) Is it possible to set HOME globally to %HOMEDRIVE%\%HOMEPATH% once
and for all without editing the Rgui.exe properties?

(D) Depending a little bit how and when R_USER is set, could I suggest
the the default "Start in:" path for Rgui.exe is changed from the
installation directory to %HOME% instead?  This is more user friendly,
especially to beginners, I think.

Best,

/Henrik


From ggrothendieck at gmail.com  Fri May  5 00:22:37 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 4 May 2006 18:22:37 -0400
Subject: [Rd] Rgui, Startup, HOME, R_USER, ...
In-Reply-To: <59d7961d0605041449q6a7086f0gd7c4d503527f6bd0@mail.gmail.com>
References: <59d7961d0605041449q6a7086f0gd7c4d503527f6bd0@mail.gmail.com>
Message-ID: <971536df0605041522m1e5e0dabw604fc3656fbf44fe@mail.gmail.com>

Just a few comments:

- although one can use environment variables in Windows applications
(I am referring to applications generally and not just R) its not
the preferred way of doing things.  Its ok to support environment
variables but they should not be relied on as the preferred way
to set configurations though they could be an alternate way.

- HOME is really bad since it can conflict with other applications,
usually ones that have been ported from UNIX

- to find out how startup works I think you will likely have to review the
startup source of code of R.  I once tried to add some lookup of these to
batchfiles (but I ultimately decided to simplify it to the point
where none of them were required) and found that reviewing the R
souce was the quickest way to be sure. That was
a whlie ago though.


On 5/4/06, Henrik Bengtsson (max 7Mb) <hb at stat.berkeley.edu> wrote:
> Hi,
>
> Main objective: Let Rgui find my ~/.Rprofile and ~/.Renviron files,
> where ~ is equal to getwd("~").
>
> I have few comments/questions:
>
> (A) On my WinXP Pro installation, the system environment variable
> 'HOME' is not availble to R, e.g. Sys.getenv("HOME") is empty.  I
> believe this is default case (correct me if I'm wrong).  However, if I
> set the "Start in:" to %HOME% in the Properties for the Rgui.exe file,
> the working directory is indeed set to getwd("~"), so 'HOME' is
> available for the startup of R.  Excuse me for my lack of
> understanding WinXP, but why is this?  What sysenv variables are
> available to the R process?  PS. I know I can add HOME=<path> in the
> Rgui.exe properties, however I'm interested in the default lookup
> path. DS.
>
> (B) With the default "Start in:" value of "C:\Program
> Files\R\R-2.3.0pat", the ~/My Documents/.Rprofile is called.  I tried
> to understand why exactly this path.  Reading the R FAQ for Windows,
> it says that 'R_USER' is used as the default value for the home
> directory.  Where/when is this set, and how?  I don't set it myself.
> It looks like it is set equal to 'HOME' and if that is not set, the to
> the default %HOMEDRIVE%\%HOMEPATH%\My Documents\, e.g.
>
> M:\>set HOME=
> M:\>Rterm --quiet
> > Sys.getenv("R_USER")
>                                        R_USER
> "C:\\Documents and Settings\\hb\\My Documents"
> M:\>set HOME=%HOMEDRIVE%\%HOMEPATH%
> M:\>Rterm --quiet
> > Sys.getenv("R_USER")
>                            R_USER
> "C:\\\\Documents and Settings\\hb"
>
> M:\>set HOME=%HOMEDRIVE%\%HOMEPATH%\foo
> M:\>Rterm --quiet
> > Sys.getenv("R_USER")
>                                 R_USER
> "C:\\\\Documents and Settings\\hb\\foo"
>
> >From the above I found out that I should put .Rprofile etc in ~/My
> Documents/ for Rgui to find it by default.  Is this behavior
> documented somewhere and why this specific directory?  For parallelism
> to Unix etc, it would be more natural to have ~/.Rprofile search for
> by default, but that is not the case (unless I set HOME).
>
> (C) Is it possible to set HOME globally to %HOMEDRIVE%\%HOMEPATH% once
> and for all without editing the Rgui.exe properties?
>
> (D) Depending a little bit how and when R_USER is set, could I suggest
> the the default "Start in:" path for Rgui.exe is changed from the
> installation directory to %HOME% instead?  This is more user friendly,
> especially to beginners, I think.
>
> Best,
>
> /Henrik
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From murdoch at stats.uwo.ca  Fri May  5 00:55:42 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 04 May 2006 18:55:42 -0400
Subject: [Rd] !
In-Reply-To: <59d7961d0605041449q6a7086f0gd7c4d503527f6bd0@mail.gmail.com>
References: <59d7961d0605041449q6a7086f0gd7c4d503527f6bd0@mail.gmail.com>
Message-ID: <445A866E.1000002@stats.uwo.ca>

On 5/4/2006 5:49 PM, Henrik Bengtsson (max 7Mb) wrote:
> Hi,
> 
> Main objective: Let Rgui find my ~/.Rprofile and ~/.Renviron files,
> where ~ is equal to getwd("~").
> 
> I have few comments/questions:
> 
> (A) On my WinXP Pro installation, the system environment variable
> 'HOME' is not availble to R, e.g. Sys.getenv("HOME") is empty.  I
> believe this is default case (correct me if I'm wrong).  However, if I
> set the "Start in:" to %HOME% in the Properties for the Rgui.exe file,
> the working directory is indeed set to getwd("~"), so 'HOME' is
> available for the startup of R. 

On my system, doing that gives a different directory:  the desktop.

> Excuse me for my lack of
> understanding WinXP, but why is this?  

Presumably Windows Explorer is doing something special with %HOME%. 
It's not simply an environment lookup.

 > What sysenv variables are
> available to the R process?  PS. I know I can add HOME=<path> in the
> Rgui.exe properties, however I'm interested in the default lookup
> path. DS.
> 
> (B) With the default "Start in:" value of "C:\Program
> Files\R\R-2.3.0pat", the ~/My Documents/.Rprofile is called.  I tried
> to understand why exactly this path.  Reading the R FAQ for Windows,
> it says that 'R_USER' is used as the default value for the home
> directory.  Where/when is this set, and how?  I don't set it myself. 

It's set by R during the startup if you didn't set it before that.  In 
XP, some of the environment variables given to new processes started 
from Explorer are found in

Control Panel|System|Advanced|Environment Variables

Other ones are also set, e.g. HOMEDRIVE and HOMEPATH (which as we found 
last year, are not set consistently).


> It looks like it is set equal to 'HOME' and if that is not set, the to
> the default %HOMEDRIVE%\%HOMEPATH%\My Documents\, e.g.
> 
> M:\>set HOME=
> M:\>Rterm --quiet
>> Sys.getenv("R_USER")
>                                         R_USER
> "C:\\Documents and Settings\\hb\\My Documents"

What you see in a command shell may be different, because variables can 
be set or cleared when the shell starts up.  Whatever happens there is 
local to the shell, so programs started directly from Explorer won't see 
the changes.

I imagine there's a way to change the global values from the shell, but 
I don't know it.  Gabor probably does!

> M:\>set HOME=%HOMEDRIVE%\%HOMEPATH%
> M:\>Rterm --quiet
>> Sys.getenv("R_USER")
>                             R_USER
> "C:\\\\Documents and Settings\\hb"
> 
> M:\>set HOME=%HOMEDRIVE%\%HOMEPATH%\foo
> M:\>Rterm --quiet
>> Sys.getenv("R_USER")
>                                  R_USER
> "C:\\\\Documents and Settings\\hb\\foo"
> 
>>From the above I found out that I should put .Rprofile etc in ~/My
> Documents/ for Rgui to find it by default.  Is this behavior
> documented somewhere and why this specific directory?  

It's in an appendix of the R Intro manual, "Invoking R under Windows".

 > For parallelism
> to Unix etc, it would be more natural to have ~/.Rprofile search for
> by default, but that is not the case (unless I set HOME).

The ~ path is not a Windows concept, it's faked by R. Windows has a much 
more complicated idea of what a user environment is like than Unix does, 
with a few dozen special directories defined (google for the 
ShGetSpecialFolderLocation docs for the list).  The normal place to put 
things that the user will edit corresponds to ~/My Documents. 
~/Application Data is normally the place to store user-specific config 
files that the user won't edit directly.  Nobody but Windows is supposed 
to write to the directory R calls ~.

> (C) Is it possible to set HOME globally to %HOMEDRIVE%\%HOMEPATH% once
> and for all without editing the Rgui.exe properties?

You could, but you're not supposed to be writing there.

> (D) Depending a little bit how and when R_USER is set, could I suggest
> the the default "Start in:" path for Rgui.exe is changed from the
> installation directory to %HOME% instead?  This is more user friendly,
> especially to beginners, I think.

It might make sense (from a Windows point of view) to change it to the 
My Documents folder.  I'm not sure what the official definition of 
%HOME% is.

Duncan Murdoch


From murdoch at stats.uwo.ca  Fri May  5 00:56:46 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 04 May 2006 18:56:46 -0400
Subject: [Rd] Rgui, Startup, HOME, R_USER, ...
In-Reply-To: <59d7961d0605041449q6a7086f0gd7c4d503527f6bd0@mail.gmail.com>
References: <59d7961d0605041449q6a7086f0gd7c4d503527f6bd0@mail.gmail.com>
Message-ID: <445A86AE.3070305@stats.uwo.ca>

(Not sure if the previous message went out; sorry if this is a dupe. 
The only change is to fix the subject.)

On 5/4/2006 5:49 PM, Henrik Bengtsson (max 7Mb) wrote:
> Hi,
> 
> Main objective: Let Rgui find my ~/.Rprofile and ~/.Renviron files,
> where ~ is equal to getwd("~").
> 
> I have few comments/questions:
> 
> (A) On my WinXP Pro installation, the system environment variable
> 'HOME' is not availble to R, e.g. Sys.getenv("HOME") is empty.  I
> believe this is default case (correct me if I'm wrong).  However, if I
> set the "Start in:" to %HOME% in the Properties for the Rgui.exe file,
> the working directory is indeed set to getwd("~"), so 'HOME' is
> available for the startup of R. 

On my system, doing that gives a different directory:  the desktop.

> Excuse me for my lack of
> understanding WinXP, but why is this?  

Presumably Windows Explorer is doing something special with %HOME%. 
It's not simply an environment lookup.

 > What sysenv variables are
> available to the R process?  PS. I know I can add HOME=<path> in the
> Rgui.exe properties, however I'm interested in the default lookup
> path. DS.
> 
> (B) With the default "Start in:" value of "C:\Program
> Files\R\R-2.3.0pat", the ~/My Documents/.Rprofile is called.  I tried
> to understand why exactly this path.  Reading the R FAQ for Windows,
> it says that 'R_USER' is used as the default value for the home
> directory.  Where/when is this set, and how?  I don't set it myself. 

It's set by R during the startup if you didn't set it before that.  In 
XP, some of the environment variables given to new processes started 
from Explorer are found in

Control Panel|System|Advanced|Environment Variables

Other ones are also set, e.g. HOMEDRIVE and HOMEPATH (which as we found 
last year, are not set consistently).


> It looks like it is set equal to 'HOME' and if that is not set, the to
> the default %HOMEDRIVE%\%HOMEPATH%\My Documents\, e.g.
> 
> M:\>set HOME=
> M:\>Rterm --quiet
>> Sys.getenv("R_USER")
>                                         R_USER
> "C:\\Documents and Settings\\hb\\My Documents"

What you see in a command shell may be different, because variables can 
be set or cleared when the shell starts up.  Whatever happens there is 
local to the shell, so programs started directly from Explorer won't see 
the changes.

I imagine there's a way to change the global values from the shell, but 
I don't know it.  Gabor probably does!

> M:\>set HOME=%HOMEDRIVE%\%HOMEPATH%
> M:\>Rterm --quiet
>> Sys.getenv("R_USER")
>                             R_USER
> "C:\\\\Documents and Settings\\hb"
> 
> M:\>set HOME=%HOMEDRIVE%\%HOMEPATH%\foo
> M:\>Rterm --quiet
>> Sys.getenv("R_USER")
>                                  R_USER
> "C:\\\\Documents and Settings\\hb\\foo"
> 
>>From the above I found out that I should put .Rprofile etc in ~/My
> Documents/ for Rgui to find it by default.  Is this behavior
> documented somewhere and why this specific directory?  

It's in an appendix of the R Intro manual, "Invoking R under Windows".

 > For parallelism
> to Unix etc, it would be more natural to have ~/.Rprofile search for
> by default, but that is not the case (unless I set HOME).

The ~ path is not a Windows concept, it's faked by R. Windows has a much 
more complicated idea of what a user environment is like than Unix does, 
with a few dozen special directories defined (google for the 
ShGetSpecialFolderLocation docs for the list).  The normal place to put 
things that the user will edit corresponds to ~/My Documents. 
~/Application Data is normally the place to store user-specific config 
files that the user won't edit directly.  Nobody but Windows is supposed 
to write to the directory R calls ~.

> (C) Is it possible to set HOME globally to %HOMEDRIVE%\%HOMEPATH% once
> and for all without editing the Rgui.exe properties?

You could, but you're not supposed to be writing there.

> (D) Depending a little bit how and when R_USER is set, could I suggest
> the the default "Start in:" path for Rgui.exe is changed from the
> installation directory to %HOME% instead?  This is more user friendly,
> especially to beginners, I think.

It might make sense (from a Windows point of view) to change it to the 
My Documents folder.  I'm not sure what the official definition of 
%HOME% is.

Duncan Murdoch


From ggrothendieck at gmail.com  Fri May  5 03:54:25 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 4 May 2006 21:54:25 -0400
Subject: [Rd] Rgui, Startup, HOME, R_USER, ...
In-Reply-To: <445A86AE.3070305@stats.uwo.ca>
References: <59d7961d0605041449q6a7086f0gd7c4d503527f6bd0@mail.gmail.com>
	<445A86AE.3070305@stats.uwo.ca>
Message-ID: <971536df0605041854h7078b250w30d71ae3cdcce5ad@mail.gmail.com>

On 5/4/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:

> I imagine there's a way to change the global values from the shell, but

I have never tried it but I think it could be done using regedit by
by setting the appropriate registry key:
http://vlaurie.com/computers2/Articles/environment.htm

It can also be done via vbscript, javascript or any programming language
that can access COM objects, such as R with RDCOMClient or rcom,
using the wscript.shell object:
http://hacks.oreilly.com/pub/h/1107


From jason_rogers at wsu.edu  Fri May  5 04:35:46 2006
From: jason_rogers at wsu.edu (jason_rogers at wsu.edu)
Date: Fri,  5 May 2006 04:35:46 +0200 (CEST)
Subject: [Rd] Data editor in Mac OS X (PR#8837)
Message-ID: <20060505023546.81224ECD9@slim.kubism.ku.dk>

Full_Name: Jason Rogers
Version: 2.3.0 Framework 1.15 Gui
OS: OS X
Submission from: (NULL) (70.110.38.195)


The data editor should allow you to change the variable name and type when you
double click it, however it does not. I have search the web web and found others
reporting the same problem. 

It might stem from Rcmdr


From s.wood at bath.ac.uk  Fri May  5 12:39:25 2006
From: s.wood at bath.ac.uk (s.wood at bath.ac.uk)
Date: Fri,  5 May 2006 12:39:25 +0200 (CEST)
Subject: [Rd] `power' documentation slip (PR#8838)
Message-ID: <20060505103925.1EFB83F0B7@slim.kubism.ku.dk>

Full_Name: simon wood
Version: 2.3.0
OS: linux (suse 9.3)
Submission from: (NULL) (138.38.32.85)


In the `Details' section of the `power' help page `non-negative' should be
`non-positive'.


From antonio.fabio at gmail.com  Fri May  5 13:02:42 2006
From: antonio.fabio at gmail.com (Antonio, Fabio Di Narzo)
Date: Fri, 5 May 2006 13:02:42 +0200
Subject: [Rd] plot.ts bad default labelling and lag.plot incomplete doc
Message-ID: <b0808fdc0605050402p5b751bd1md5f704159cd2bd19@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060505/edc5805b/attachment.pl 

From murdoch at stats.uwo.ca  Fri May  5 14:39:13 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 05 May 2006 08:39:13 -0400
Subject: [Rd] `power' documentation slip (PR#8838)
In-Reply-To: <20060505103925.1EFB83F0B7@slim.kubism.ku.dk>
References: <20060505103925.1EFB83F0B7@slim.kubism.ku.dk>
Message-ID: <445B4771.8000209@stats.uwo.ca>

On 5/5/2006 6:39 AM, s.wood at bath.ac.uk wrote:
> Full_Name: simon wood
> Version: 2.3.0
> OS: linux (suse 9.3)
> Submission from: (NULL) (138.38.32.85)
> 
> 
> In the `Details' section of the `power' help page `non-negative' should be
> `non-positive'.

Thanks, I'll fix that.

Duncan Murdoch


From KKIII at Indiana.Edu  Fri May  5 14:42:45 2006
From: KKIII at Indiana.Edu (Ken Kelley)
Date: Fri, 05 May 2006 08:42:45 -0400
Subject: [Rd] Including a single function from a package
Message-ID: <445B4845.6010804@Indiana.Edu>

Hello all.

I'm building a package where I want to include a function from two 
different packages. In particular, I want to include mvrnorm and 
hyperg_2F1 from MASS and gsl, respectively (but the specific functions 
do not matter). With what I've tried after reading the "Specifying 
imports and exports" section from the "Writing R Extensions" manual, I 
get an error: "Namespace dependencies not required."

My NAMESPACE file consists of the following:
importFrom(MASS, mvrnorm)
importFrom(gsl, hyperg_2F1)
exportPattern("^[^\\.]")

A completely separate issue is that when running check, I get a warning 
at the "checking S3 generic/method consistency" line that states: 
"Warning: use of NULL environment is depreciated." I've looked at the 
"Generic functions and methods" in the Writing R Extensions manual and 
I'm still not sure what the "use of NULL environment is depreciated." I 
suppose this is not a big deal, but it seems best not to have any warnings.


I'm sure I'm just missing something simple on both of these issues. Any 
insight would be appreciated. I'm building the package with Win. XP.

Thanks,
Ken

-- 
Ken Kelley, Ph.D.
Indiana University
Inquiry Methodology Program
201 North Rose Avenue, Room 4040
Bloomington, Indiana 47405
(P/F) 812-856-8330 / 812-856-8333
http://www.indiana.edu/~kenkel


From ripley at stats.ox.ac.uk  Fri May  5 14:55:36 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 5 May 2006 13:55:36 +0100 (BST)
Subject: [Rd] Including a single function from a package
In-Reply-To: <445B4845.6010804@Indiana.Edu>
References: <445B4845.6010804@Indiana.Edu>
Message-ID: <Pine.LNX.4.64.0605051350530.613@gannet.stats.ox.ac.uk>

On Fri, 5 May 2006, Ken Kelley wrote:

> Hello all.
>
> I'm building a package where I want to include a function from two
> different packages. In particular, I want to include mvrnorm and
> hyperg_2F1 from MASS and gsl, respectively (but the specific functions
> do not matter). With what I've tried after reading the "Specifying
> imports and exports" section from the "Writing R Extensions" manual, I
> get an error: "Namespace dependencies not required."

When do you get the error?

> My NAMESPACE file consists of the following:
> importFrom(MASS, mvrnorm)
> importFrom(gsl, hyperg_2F1)
> exportPattern("^[^\\.]")

Does your DESCRIPTION file contain

Imports: MASS gsl

?

> A completely separate issue is that when running check, I get a warning
> at the "checking S3 generic/method consistency" line that states:
> "Warning: use of NULL environment is depreciated." I've looked at the
> "Generic functions and methods" in the Writing R Extensions manual and
> I'm still not sure what the "use of NULL environment is depreciated." I
> suppose this is not a big deal, but it seems best not to have any warnings.

It is a big deal: your code will fail in 2.4.0 and not be allowed on CRAN 
now.  The message is probably not to do with that topic but to do with 
loading your package.  So can you install and load the package without any 
messages?

> I'm sure I'm just missing something simple on both of these issues. Any
> insight would be appreciated. I'm building the package with Win. XP.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch at stats.uwo.ca  Fri May  5 14:58:20 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 05 May 2006 08:58:20 -0400
Subject: [Rd] Including a single function from a package
In-Reply-To: <445B4845.6010804@Indiana.Edu>
References: <445B4845.6010804@Indiana.Edu>
Message-ID: <445B4BEC.9040102@stats.uwo.ca>

On 5/5/2006 8:42 AM, Ken Kelley wrote:
> Hello all.
> 
> I'm building a package where I want to include a function from two 
> different packages. In particular, I want to include mvrnorm and 
> hyperg_2F1 from MASS and gsl, respectively (but the specific functions 
> do not matter). With what I've tried after reading the "Specifying 
> imports and exports" section from the "Writing R Extensions" manual, I 
> get an error: "Namespace dependencies not required."
> 
> My NAMESPACE file consists of the following:
> importFrom(MASS, mvrnorm)
> importFrom(gsl, hyperg_2F1)
> exportPattern("^[^\\.]")

I don't see this in a quick test in the current R-patched.

> A completely separate issue is that when running check, I get a warning 
> at the "checking S3 generic/method consistency" line that states: 
> "Warning: use of NULL environment is depreciated." I've looked at the 
> "Generic functions and methods" in the Writing R Extensions manual and 
> I'm still not sure what the "use of NULL environment is depreciated." I 
> suppose this is not a big deal, but it seems best not to have any warnings.

It indicates a bug somewhere or other, but the version of R you're using 
(you didn't say) is willing to work around it for now.  The next version 
will not.

 From the location where you saw the error, it looks like a bug in R 
rather than in your code, but surely such a thing would have been seen 
before.  Are you using an unreleased version?

This may also explain the problems with your namespace file.

Duncan Murdoch
> 
> 
> I'm sure I'm just missing something simple on both of these issues. Any 
> insight would be appreciated. I'm building the package with Win. XP.
> 
> Thanks,
> Ken
>


From udr-core at stat.math.ethz.ch  Fri May  5 16:20:49 2006
From: udr-core at stat.math.ethz.ch (udr-core at stat.math.ethz.ch)
Date: Fri, 05 May 2006 09:20:49 -0500
Subject: [Rd] hey sis!
Message-ID: <3J40CPI345A878J-8638-DS@129.132.145.15>

R-core

Hey
+-------------------------------------------------------------------------------------------------------------+
|                 GET YOUR UNIVER|SITY DIPL!OMA                                  |
|                                                                                                                |
|     Do you want a prosperous future, increased earning power               |
|                more money and the respect of all?                                         |
|                                                                                                                |
|             Call this number: 1-206-600-4655 (24 hours)                               |
|                                                                                                                |
|                                                                                                                |
|     There are no required tests, classes, books, or interviews!                 |
|                                                                                                                |
|     Get a Bachelor;s, Mas.ters, MBA, and Doctorat:e (PhD) Diplom_a!    |
|                                                                                                                |
|     Receive the benefits and admiration that comes with a Dip`loma!     |
|                                                                                                                |
|           No one is turned down! Start making money Now!                       |
|                                                                                                                |
|                                                                                                                |
|         Call Today 1-206-600-4655 (7 days a week, 24 hours a day)         |
|                                                                                                                | 
|                           Confidentiality assured!                                                 |
|                                                                                                                | 
+--------------------------------------------------------------------------------------------------------------+
 
 Take Care
 
 Carolyn Lilly


From KKIII at Indiana.Edu  Fri May  5 16:02:21 2006
From: KKIII at Indiana.Edu (Ken Kelley)
Date: Fri, 05 May 2006 10:02:21 -0400
Subject: [Rd] Including a single function from a package
In-Reply-To: <Pine.LNX.4.64.0605051350530.613@gannet.stats.ox.ac.uk>
References: <445B4845.6010804@Indiana.Edu>
	<Pine.LNX.4.64.0605051350530.613@gannet.stats.ox.ac.uk>
Message-ID: <445B5AED.7090108@Indiana.Edu>

Thank you both very much for your quick and helpful responses.

I added "Imports: MASS, gsl" to the DESCRIPTION file and that took care 
of loading in the desired functions just fine. I went back and took 
another look at the "Specifying imports and exports" section (section 
1.6.1) of the Writing R Extensions manual and I do not see anything 
about including an "Imports:" line in the DESCRIPTION file when 
including an "importFrom" in the NAMESPACE file. Perhaps including this 
information in a future update should be considered.

I was building the package on a machine that had a pre-release version 
of R 2.3.0 (from some time ago). After updating to the released version 
of 2.3, the warning about a "depreciated NULL environment" did not occur 
and the package built just fine.

Thanks again and have a good day,
Ken


Prof Brian Ripley wrote:
> On Fri, 5 May 2006, Ken Kelley wrote:
> 
>> Hello all.
>>
>> I'm building a package where I want to include a function from two
>> different packages. In particular, I want to include mvrnorm and
>> hyperg_2F1 from MASS and gsl, respectively (but the specific functions
>> do not matter). With what I've tried after reading the "Specifying
>> imports and exports" section from the "Writing R Extensions" manual, I
>> get an error: "Namespace dependencies not required."
> 
> 
> When do you get the error?
> 
>> My NAMESPACE file consists of the following:
>> importFrom(MASS, mvrnorm)
>> importFrom(gsl, hyperg_2F1)
>> exportPattern("^[^\\.]")
> 
> 
> Does your DESCRIPTION file contain
> 
> Imports: MASS gsl
> 
> ?
> 
>> A completely separate issue is that when running check, I get a warning
>> at the "checking S3 generic/method consistency" line that states:
>> "Warning: use of NULL environment is depreciated." I've looked at the
>> "Generic functions and methods" in the Writing R Extensions manual and
>> I'm still not sure what the "use of NULL environment is depreciated." I
>> suppose this is not a big deal, but it seems best not to have any 
>> warnings.
> 
> 
> It is a big deal: your code will fail in 2.4.0 and not be allowed on 
> CRAN now.  The message is probably not to do with that topic but to do 
> with loading your package.  So can you install and load the package 
> without any messages?
> 
>> I'm sure I'm just missing something simple on both of these issues. Any
>> insight would be appreciated. I'm building the package with Win. XP.
> 
> 

-- 
Ken Kelley, Ph.D.
Indiana University
Inquiry Methodology Program
201 North Rose Avenue, Room 4040
Bloomington, Indiana 47405
(P/F) 812-856-8330 / 812-856-8333
http://www.indiana.edu/~kenkel


From ripley at stats.ox.ac.uk  Fri May  5 16:12:05 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 5 May 2006 15:12:05 +0100 (BST)
Subject: [Rd] Including a single function from a package
In-Reply-To: <445B5AED.7090108@Indiana.Edu>
References: <445B4845.6010804@Indiana.Edu>
	<Pine.LNX.4.64.0605051350530.613@gannet.stats.ox.ac.uk>
	<445B5AED.7090108@Indiana.Edu>
Message-ID: <Pine.LNX.4.64.0605051509060.3432@gannet.stats.ox.ac.uk>

On Fri, 5 May 2006, Ken Kelley wrote:

> Thank you both very much for your quick and helpful responses.
>
> I added "Imports: MASS, gsl" to the DESCRIPTION file and that took care of 
> loading in the desired functions just fine. I went back and took another look 
> at the "Specifying imports and exports" section (section 1.6.1) of the 
> Writing R Extensions manual and I do not see anything about including an 
> "Imports:" line in the DESCRIPTION file when including an "importFrom" in the 
> NAMESPACE file. Perhaps including this information in a future update should 
> be considered.

Well, no, it described under the DESCRIPTION file:

   The optional @samp{Imports} field lists packages whose namespaces are
   imported from but which do not need to be attached.

Note that caveat which complicates the issue and I think makes in 
inappropriate for that section.

> I was building the package on a machine that had a pre-release version of R 
> 2.3.0 (from some time ago). After updating to the released version of 2.3, 
> the warning about a "depreciated NULL environment" did not occur and the 
> package built just fine.
>
> Thanks again and have a good day,
> Ken
>
>
> Prof Brian Ripley wrote:
>> On Fri, 5 May 2006, Ken Kelley wrote:
>> 
>>> Hello all.
>>> 
>>> I'm building a package where I want to include a function from two
>>> different packages. In particular, I want to include mvrnorm and
>>> hyperg_2F1 from MASS and gsl, respectively (but the specific functions
>>> do not matter). With what I've tried after reading the "Specifying
>>> imports and exports" section from the "Writing R Extensions" manual, I
>>> get an error: "Namespace dependencies not required."
>> 
>> 
>> When do you get the error?
>> 
>>> My NAMESPACE file consists of the following:
>>> importFrom(MASS, mvrnorm)
>>> importFrom(gsl, hyperg_2F1)
>>> exportPattern("^[^\\.]")
>> 
>> 
>> Does your DESCRIPTION file contain
>> 
>> Imports: MASS gsl
>> 
>> ?
>> 
>>> A completely separate issue is that when running check, I get a warning
>>> at the "checking S3 generic/method consistency" line that states:
>>> "Warning: use of NULL environment is depreciated." I've looked at the
>>> "Generic functions and methods" in the Writing R Extensions manual and
>>> I'm still not sure what the "use of NULL environment is depreciated." I
>>> suppose this is not a big deal, but it seems best not to have any 
>>> warnings.
>> 
>> 
>> It is a big deal: your code will fail in 2.4.0 and not be allowed on CRAN 
>> now.  The message is probably not to do with that topic but to do with 
>> loading your package.  So can you install and load the package without any 
>> messages?
>> 
>>> I'm sure I'm just missing something simple on both of these issues. Any
>>> insight would be appreciated. I'm building the package with Win. XP.
>> 
>> 
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From sfalcon at fhcrc.org  Fri May  5 16:56:02 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Fri, 05 May 2006 07:56:02 -0700
Subject: [Rd] Including a single function from a package
In-Reply-To: <Pine.LNX.4.64.0605051509060.3432@gannet.stats.ox.ac.uk> (Brian
	Ripley's message of "Fri, 5 May 2006 15:12:05 +0100 (BST)")
References: <445B4845.6010804@Indiana.Edu>
	<Pine.LNX.4.64.0605051350530.613@gannet.stats.ox.ac.uk>
	<445B5AED.7090108@Indiana.Edu>
	<Pine.LNX.4.64.0605051509060.3432@gannet.stats.ox.ac.uk>
Message-ID: <m23bfoed19.fsf@ziti.local>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> On Fri, 5 May 2006, Ken Kelley wrote:
>
>> Thank you both very much for your quick and helpful responses.
>>
>> I added "Imports: MASS, gsl" to the DESCRIPTION file and that took care of 
>> loading in the desired functions just fine. I went back and took another look 
>> at the "Specifying imports and exports" section (section 1.6.1) of the 
>> Writing R Extensions manual and I do not see anything about including an 
>> "Imports:" line in the DESCRIPTION file when including an "importFrom" in the 
>> NAMESPACE file. Perhaps including this information in a future update should 
>> be considered.
>
> Well, no, it described under the DESCRIPTION file:
>
>    The optional @samp{Imports} field lists packages whose namespaces are
>    imported from but which do not need to be attached.
>
> Note that caveat which complicates the issue and I think makes in 
> inappropriate for that section.

I think it would be an improvement to mention in the namespace
documentation that imported package must appear in either Depends or
Imports in the DESCRIPTION file as well as being mentioned in the
NAMESPACE file.  The requirment that this information be repeated is
not obvious to many.  That is, one might reasonably imagine that
specifying imports with an importsFrom directive in the NAMESPACE file
is enough.

+ seth


From maechler at stat.math.ethz.ch  Fri May  5 17:40:06 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 5 May 2006 17:40:06 +0200
Subject: [Rd] Including a single function from a package
In-Reply-To: <m23bfoed19.fsf@ziti.local>
References: <445B4845.6010804@Indiana.Edu>
	<Pine.LNX.4.64.0605051350530.613@gannet.stats.ox.ac.uk>
	<445B5AED.7090108@Indiana.Edu>
	<Pine.LNX.4.64.0605051509060.3432@gannet.stats.ox.ac.uk>
	<m23bfoed19.fsf@ziti.local>
Message-ID: <17499.29142.172707.782147@stat.math.ethz.ch>

>>>>> "Seth" == Seth Falcon <sfalcon at fhcrc.org>
>>>>>     on Fri, 05 May 2006 07:56:02 -0700 writes:

    Seth> Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:
    >> On Fri, 5 May 2006, Ken Kelley wrote:
    >> 
    >>> Thank you both very much for your quick and helpful
    >>> responses.
    >>> 
    >>> I added "Imports: MASS, gsl" to the DESCRIPTION file and
    >>> that took care of loading in the desired functions just
    >>> fine. I went back and took another look at the
    >>> "Specifying imports and exports" section (section 1.6.1)
    >>> of the Writing R Extensions manual and I do not see
    >>> anything about including an "Imports:" line in the
    >>> DESCRIPTION file when including an "importFrom" in the
    >>> NAMESPACE file. Perhaps including this information in a
    >>> future update should be considered.
    >>  Well, no, it described under the DESCRIPTION file:
    >> 
    >> The optional @samp{Imports} field lists packages whose
    >> namespaces are imported from but which do not need to be
    >> attached.
    >> 
    >> Note that caveat which complicates the issue and I think
    >> makes in inappropriate for that section.

    Seth> I think it would be an improvement to mention in the
    Seth> namespace documentation that imported package must
    Seth> appear in either Depends or Imports in the DESCRIPTION
    Seth> file as well as being mentioned in the NAMESPACE file.
    Seth> The requirment that this information be repeated is
    Seth> not obvious to many.  That is, one might reasonably
    Seth> imagine that specifying imports with an importsFrom
    Seth> directive in the NAMESPACE file is enough.

I do have to agree with Seth;
I've helped several people now all of whom had problems with the
above when they were told to follow work along the documentation
in "Writing R Extensions".
The typical package writer will start with

DESCRIPTION, R/*.R, then, man/*.Rd, etc  
and at some point learn about NAMESPACE and read in the manual
about things related to the "new NAMESPACE".  It's very natural
*not* go back and reread the docu about DESCRIPTION as well.

Martin


From khansen at stat.Berkeley.EDU  Fri May  5 19:54:08 2006
From: khansen at stat.Berkeley.EDU (Kasper Daniel Hansen)
Date: Fri, 5 May 2006 10:54:08 -0700
Subject: [Rd] suppressing "global" cppflags in an individual package
Message-ID: <9294B498-A4DB-47B1-AE99-71C1559EABB3@stat.berkeley.edu>

Hi

I can use PKG_CPPFLAGS in a Makevars file to add additional flags to  
the c++ compiler for a given package. Is it possible to remove flags  
passed to the packages from R. Eg: say R have been compiled with -O2  
and I want the package to be compiled with another optimization level?

/Kasper


From hb at stat.berkeley.edu  Fri May  5 20:58:19 2006
From: hb at stat.berkeley.edu (Henrik Bengtsson (max 7Mb))
Date: Fri, 5 May 2006 11:58:19 -0700
Subject: [Rd] str() with attr(*, "names") is extremely slow for long vectors
Message-ID: <59d7961d0605051158x4e482d93y780a428a494eacdc@mail.gmail.com>

Hi,

I noticed some time ago that, for instance, named vectors that are
really makes str() really slow when displaying the names attribute.  I
don't know exactly when this started, but it wasn't the case say 1-2
years ago.  Example (on a WinXP 1.8GHz):

> s <- 1:1000; names(s) <- s
> system.time(str(s))
 Named int [1:1000] 1 2 3 4 5 6 7 8 9 10 ...
 - attr(*, "names")= chr [1:1000] "1" "2" "3" "4" ...
[1] 0.08 0.00 0.09   NA   NA

> s <- 1:100000; names(s) <- s
> system.time(str(s))
 Named int [1:100000] 1 2 3 4 5 6 7 8 9 10 ...
 - attr(*, "names")= chr [1:100000] "1" "2" "3" "4" ...
[1] 8.82 0.00 9.11   NA   NA

I looks like all strings elements are processed although only the
first few are displayed.

Cheers

Henrik


From simon.urbanek at r-project.org  Sat May  6 00:45:41 2006
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 5 May 2006 18:45:41 -0400
Subject: [Rd] Data editor in Mac OS X (PR#8837)
In-Reply-To: <20060505023546.81224ECD9@slim.kubism.ku.dk>
References: <20060505023546.81224ECD9@slim.kubism.ku.dk>
Message-ID: <D96FCB73-92B9-404A-9142-5237970EE4A7@r-project.org>

Jason,

On May 4, 2006, at 10:35 PM, jason_rogers at wsu.edu wrote:

> Full_Name: Jason Rogers
> Version: 2.3.0 Framework 1.15 Gui
> OS: OS X
> Submission from: (NULL) (70.110.38.195)
>
>
> The data editor should allow you to change the variable name and  
> type when you double click it, however it does not. I have search  
> the web web and found others reporting the same problem.
>

Can you, please, tell us exactly what you mean and where you want to  
change a name? It is your responsibility to assign the result of edit 
(..) to a variable, there is nothing to double-click on. Also if you  
found "others" reporting this, you may tell us where, because I'm not  
aware of any such report related to R.

> It might stem from Rcmdr
>

If the "data editor" you mean is a feature of Rcmdr, you should read  
the posting guide and report such issues to the maintainer - that is  
NOT a bug in R!

Cheers,
Simon


From simon.urbanek at r-project.org  Sat May  6 03:50:03 2006
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 5 May 2006 21:50:03 -0400
Subject: [Rd] R 2.3.0 and rgl on OS X 10.4.6 (PR#8833)
In-Reply-To: <20060504180847.EBEC119B99@slim.kubism.ku.dk>
References: <20060504180847.EBEC119B99@slim.kubism.ku.dk>
Message-ID: <C5B8BD22-D6BD-444B-A338-1A5498C7080A@r-project.org>

Neely,

as Duncan was saying R-SIG-Mac is a better place to discuss it.

On May 4, 2006, at 2:08 PM, eatkinso at mdanderson.org wrote:

> I just downloaded and installed R 2.3.0 on my Mac G5 running OS X  
> 10.4.6. I also updated with R.app revision 3114 as ecommended. Now,  
> when I attemp to use package rgl
> I get the error
>
>> library(rgl)
> Error: package 'rgl' is not installed for 'arch=ppc'

This usually means that you have an old package for R 2.2.0 and you  
are trying to use it in R 2.3.0. *)

> I have tried reinstalling from CRAN using both binary and source.  
> The source install fails, The binary install yields
>

AFAIR rgl is currently broken, so there is no binary:
http://r.research.att.com/reports/tiger-universal/results/2.3.0/html/ 
rgl.report.html
I remember fixing this a while ago - it wasn't as simple as casting,  
because the structures are wrong, but I'll see if I can dig out the fix.

> The same problem occurs with some packages (e1071, svmpath) but not  
> others (gdata, gplots, gtools).
>

My guess is that you forgot to re-install them (or you have old local  
packages somewhere). This happens most often if you install libraries  
in your home directory. On OS X it's usually much safer to use system- 
wide packages, because that prevents cross-version problems, version- 
confusion and the GUI allows you to re-install them automatically.  
That doesn't work for your local packages in home.

Cheers,
Simon

*) - for completeness, you also get this error if you install a  
binary that was not built for the universal R or if the ppc  
architecture build failed. However, neither should not happen with  
CRAN binaries.


From murdoch at stats.uwo.ca  Sat May  6 13:03:47 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 06 May 2006 07:03:47 -0400
Subject: [Rd] R 2.3.0 and rgl on OS X 10.4.6
In-Reply-To: <C5B8BD22-D6BD-444B-A338-1A5498C7080A@r-project.org>
References: <20060504180847.EBEC119B99@slim.kubism.ku.dk>
	<C5B8BD22-D6BD-444B-A338-1A5498C7080A@r-project.org>
Message-ID: <445C8293.5080903@stats.uwo.ca>

On 5/5/2006 9:50 PM, Simon Urbanek wrote:
> Neely,
> 
> as Duncan was saying R-SIG-Mac is a better place to discuss it.
> 
> On May 4, 2006, at 2:08 PM, eatkinso at mdanderson.org wrote:
> 
>> I just downloaded and installed R 2.3.0 on my Mac G5 running OS X  
>> 10.4.6. I also updated with R.app revision 3114 as ecommended. Now,  
>> when I attemp to use package rgl
>> I get the error
>>
>>> library(rgl)
>> Error: package 'rgl' is not installed for 'arch=ppc'
> 
> This usually means that you have an old package for R 2.2.0 and you  
> are trying to use it in R 2.3.0. *)

Oops, sorry about my "more commonly used platform" comment.  I thought 
this was an older Mac platform, not a current one.

> 
>> I have tried reinstalling from CRAN using both binary and source.  
>> The source install fails, The binary install yields
>>
> 
> AFAIR rgl is currently broken, so there is no binary:
> http://r.research.att.com/reports/tiger-universal/results/2.3.0/html/ 
> rgl.report.html
> I remember fixing this a while ago - it wasn't as simple as casting,  
> because the structures are wrong, but I'll see if I can dig out the fix.

A simple fix for the error shown on that page is in the patch below. 
(The line numbers don't match because I'm working with an unreleased 
version.)  I'm hoping there will be another release soon; there are some 
additions to rgl.

Duncan Murdoch

Index: api.cpp
===================================================================
--- api.cpp	(revision 453)
+++ api.cpp	(working copy)
@@ -680,12 +680,14 @@
    int success = RGL_FAIL;
    GLdouble* vertex = pixel;
    int columns = idata[0];
+  GLint viewport[4];

    Device* device = deviceManager->getAnyDevice();

    if ( device ) {
+  	for (int i=0; i<4; i++) viewport[i] = view[i];
    	for (int i=0; i<columns; i++) {
-		gluProject(point[0],point[1],point[2],model,proj,view,
+		gluProject(point[0],point[1],point[2],model,proj,viewport,
  		vertex,vertex+1,vertex+2);
  		vertex[0] /= view[2];
  		vertex[1] /= view[3];
@@ -703,14 +705,16 @@
    int success = RGL_FAIL;
    GLdouble* vertex = point;
    int columns = idata[0];
+  GLint viewport[4];

    Device* device = deviceManager->getAnyDevice();

    if ( device ) {
+    	for (int i=0; i<4; i++) viewport[i] = view[i];
    	for (int i=0; i<columns; i++) {
  	        pixel[0] *= view[2];
  	        pixel[1] *= view[3];
-		gluUnProject(pixel[0],pixel[1],pixel[2],model,proj,view,
+		gluUnProject(pixel[0],pixel[1],pixel[2],model,proj,viewport,
  		vertex,vertex+1,vertex+2);
  		pixel += 3;
  		vertex += 3;


From marina.saadia at freesbee.fr  Sat May  6 13:37:24 2006
From: marina.saadia at freesbee.fr (marina.saadia at freesbee.fr)
Date: Sat,  6 May 2006 13:37:24 +0200 (CEST)
Subject: [Rd] irr package exits (PR#8839)
Message-ID: <20060506113724.8E58F103F9@slim.kubism.ku.dk>

Full_Name: Marina Saadia Otero
Version: R 2.2.0
OS: Mac OS X 10.3.9
Submission from: (NULL) (81.67.12.179)


After having installed the "irr" package (from the
installation Menu of the Mac interface), the command
    library(irr)
makes the R application quit. This has been tested from
a clean new session, and even from a brand new account.
Re-installing the package does not solve the problem.

Thanks in advance for your help!


From ripley at stats.ox.ac.uk  Sat May  6 13:44:42 2006
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Sat,  6 May 2006 13:44:42 +0200 (CEST)
Subject: [Rd] irr package exits (PR#8839)
Message-ID: <20060506114442.F10B815FE1@slim.kubism.ku.dk>

Please contact the package maintainer (Cc:ed here).  From the R FAQ:

   Finally, check carefully whether the bug is with R, or a contributed
   package.  Bug reports on contributed packages should be sent first to
   the package maintainer, and only submitted to the R-bugs repository by
   package maintainers, mentioning the package in the subject line.

and there is similar advice in the R posting guide.

On Sat, 6 May 2006, marina.saadia at freesbee.fr wrote:

> Full_Name: Marina Saadia Otero
> Version: R 2.2.0
> OS: Mac OS X 10.3.9
> Submission from: (NULL) (81.67.12.179)
>
>
> After having installed the "irr" package (from the
> installation Menu of the Mac interface), the command
>    library(irr)
> makes the R application quit. This has been tested from
> a clean new session, and even from a brand new account.
> Re-installing the package does not solve the problem.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From marina.saadia at freesbee.fr  Sat May  6 14:26:35 2006
From: marina.saadia at freesbee.fr (marina.saadia at freesbee.fr)
Date: Sat,  6 May 2006 14:26:35 +0200 (CEST)
Subject: [Rd] Bug solved / Re:  irr package exits (PR#8839)
Message-ID: <20060506122635.6643E103F9@slim.kubism.ku.dk>

Dear Profs. Ripley & Gamer,

Thanks a lot for your prompt answer and your advice. Indeed, I managed
to track the bug by launching R from the c-shell instead of the Mac GUI.
In that case, after typing
> library(irr)
I obtained the following error message:
> Erreur dans parse(file, n, text, prompt) : syntax error at
> 653: irr.name =3D "R
> Erreur : unable to load R code in package 'irr'

Because Mac, PC and Unix encode end-of-lines differently, this actually
corresponds to line # 1304 in the file "~/Library/R/library/irr/R/irr"
(it should be line # 653 if you work on a PC):
>   rval <- list(method =3D "Mean of bivariate correlations R=FF",
>                subjects =3D ns, raters =3D nr,
>                irr.name =3D "R=FF", value =3D coeff)

The character "=FF" (displayed as a "?" in the c-shell) is clearly not=20=

understood.
I thus tried to replace it here by a normal "y", and similarly for=20
"Rho=FF" several
lines lower, and now the package loads without any problem.

I still need to understand how to avoid a conflict between the "icc"=20
functions
defined both in the "irr" and "psy" packages, but this is another=20
story. [Please
feel free to give me any other advice!]

Thanks again; your sincerely,
                                            Marina Saadia Otero

On May 6th, 2006, at 13:44, Prof Brian Ripley wrote:
> Please contact the package maintainer (Cc:ed here).  =46rom the R FAQ:
>
>   Finally, check carefully whether the bug is with R, or a contributed
>   package.  Bug reports on contributed packages should be sent first =
to
>   the package maintainer, and only submitted to the R-bugs repository=20=

> by
>   package maintainers, mentioning the package in the subject line.
>
> and there is similar advice in the R posting guide.
>
> On Sat, 6 May 2006, marina.saadia at freesbee.fr wrote:
>
>> Full_Name: Marina Saadia Otero
>> Version: R 2.2.0
>> OS: Mac OS X 10.3.9
>> Submission from: (NULL) (81.67.12.179)
>>
>> After having installed the "irr" package (from the
>> installation Menu of the Mac interface), the command
>>    library(irr)
>> makes the R application quit. This has been tested from
>> a clean new session, and even from a brand new account.
>> Re-installing the package does not solve the problem.


From maechler at stat.math.ethz.ch  Mon May  8 10:28:01 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 8 May 2006 10:28:01 +0200
Subject: [Rd] str() with attr(*,
	"names") is extremely slow for long vectors
In-Reply-To: <59d7961d0605051158x4e482d93y780a428a494eacdc@mail.gmail.com>
References: <59d7961d0605051158x4e482d93y780a428a494eacdc@mail.gmail.com>
Message-ID: <17503.273.278827.980343@stat.math.ethz.ch>

>>>>> "HenrikB" == Henrik Bengtsson (max 7Mb) <hb at stat.berkeley.edu>
>>>>>     on Fri, 5 May 2006 11:58:19 -0700 writes:

    HenrikB> Hi,
    HenrikB> I noticed some time ago that, for instance, named vectors that are
    HenrikB> really makes str() really slow when displaying the names attribute.

    HenrikB> I don't know exactly when this started, but it
    HenrikB> wasn't the case say 1-2 years ago.  Example (on a WinXP 1.8GHz):

Thank you, Henrik, for the note.
Indeed, str() is unnecessary slow for long character vectors in
general, not just when they are names(); and Rprof() +
Rprofsummary() quickly reveal were the culprits lie.

This shouldn't be too hard to improve, I'm having a look.

Martin Maechler, ETH Zurich



    >> s <- 1:1000; names(s) <- s
    >> system.time(str(s))
    HenrikB> Named int [1:1000] 1 2 3 4 5 6 7 8 9 10 ...
    HenrikB> - attr(*, "names")= chr [1:1000] "1" "2" "3" "4" ...
    HenrikB> [1] 0.08 0.00 0.09   NA   NA

    >> s <- 1:100000; names(s) <- s
    >> system.time(str(s))
    HenrikB> Named int [1:100000] 1 2 3 4 5 6 7 8 9 10 ...
    HenrikB> - attr(*, "names")= chr [1:100000] "1" "2" "3" "4" ...
    HenrikB> [1] 8.82 0.00 9.11   NA   NA

    HenrikB> I looks like all strings elements are processed although only the
    HenrikB> first few are displayed.

    HenrikB> Cheers

    HenrikB> Henrik

    HenrikB> ______________________________________________
    HenrikB> R-devel at r-project.org mailing list
    HenrikB> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>> "HenrikB" == Henrik Bengtsson (max 7Mb) <hb at stat.berkeley.edu>
>>>>>     on Fri, 5 May 2006 11:58:19 -0700 writes:

    HenrikB> Hi, I noticed some time ago that, for instance,
    HenrikB> named vectors that are really makes str() really
    HenrikB> slow when displaying the names attribute.  I don't
    HenrikB> know exactly when this started, but it wasn't the
    HenrikB> case say 1-2 years ago.  Example (on a WinXP
    HenrikB> 1.8GHz):

    >> s <- 1:1000; names(s) <- s system.time(str(s))
    HenrikB>  Named int [1:1000] 1 2 3 4 5 6 7 8 9 10 ...  -
    HenrikB> attr(*, "names")= chr [1:1000] "1" "2" "3" "4" ...
    HenrikB> [1] 0.08 0.00 0.09 NA NA

    >> s <- 1:100000; names(s) <- s system.time(str(s))
    HenrikB>  Named int [1:100000] 1 2 3 4 5 6 7 8 9 10 ...  -
    HenrikB> attr(*, "names")= chr [1:100000] "1" "2" "3" "4"
    HenrikB> ...  [1] 8.82 0.00 9.11 NA NA

    HenrikB> I looks like all strings elements are processed
    HenrikB> although only the first few are displayed.

    HenrikB> Cheers

    HenrikB> Henrik

    HenrikB> ______________________________________________
    HenrikB> R-devel at r-project.org mailing list
    HenrikB> https://stat.ethz.ch/mailman/listinfo/r-devel


From x.sole at iconcologia.net  Mon May  8 12:06:57 2006
From: x.sole at iconcologia.net (x.sole at iconcologia.net)
Date: Mon,  8 May 2006 12:06:57 +0200 (CEST)
Subject: [Rd] Inconsistency in AIC values for glm with family poisson
	(PR#8840)
Message-ID: <20060508100657.87099C9E8@slim.kubism.ku.dk>

Full_Name: Xavier Sol?
Version: 2.3.0
OS: Windows XP SP2
Submission from: (NULL) (213.151.99.160)


#When computing AIC for one of the models shown in ?glm we get an inconsistent
AIC value. We also get the same wrong value if we use "extractAIC" o "AIC"
functions.

example(glm)

glm.D93

extractAIC(glm.D93)

#AIC of this model should be 15.129 (residual deviance + 2*effective degrees of
freedom), but the AIC which R returns is 56.76. Function extractAIC returns the
right number of effective degrees of freedom (5), but anyway seems to fail in
calculating the correct AIC value.


From h.wickham at gmail.com  Mon May  8 12:08:41 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 8 May 2006 12:08:41 +0200
Subject: [Rd] Patch for r-intro to update xgobi to ggobi
Message-ID: <f8e6ff050605080308i34132262n131e19e02067d0f3@mail.gmail.com>

Patch attached.

If this is acceptable, would someone please be able to check this in for me?

Thanks,

Hadley

From ligges at statistik.uni-dortmund.de  Mon May  8 12:49:24 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 08 May 2006 12:49:24 +0200
Subject: [Rd] Patch for r-intro to update xgobi to ggobi
In-Reply-To: <f8e6ff050605080308i34132262n131e19e02067d0f3@mail.gmail.com>
References: <f8e6ff050605080308i34132262n131e19e02067d0f3@mail.gmail.com>
Message-ID: <445F2234.5060201@statistik.uni-dortmund.de>

hadley wickham wrote:

> Patch attached.
> 
> If this is acceptable, would someone please be able to check this in for 
> me?


Probably you do not wanted to post this to R-edev (where the attachment 
has been stripped off anyway)....

Uwe Ligges



> Thanks,
> 
> Hadley
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.uni-dortmund.de  Mon May  8 12:51:05 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 08 May 2006 12:51:05 +0200
Subject: [Rd] Patch for r-intro to update xgobi to ggobi
In-Reply-To: <445F2234.5060201@statistik.uni-dortmund.de>
References: <f8e6ff050605080308i34132262n131e19e02067d0f3@mail.gmail.com>
	<445F2234.5060201@statistik.uni-dortmund.de>
Message-ID: <445F2299.4020701@statistik.uni-dortmund.de>

Uwe Ligges wrote:

> hadley wickham wrote:
> 
>> Patch attached.
>>
>> If this is acceptable, would someone please be able to check this in 
>> for me?
> 
> 
> 
> Probably you do not wanted to post this to R-edev (where the attachment 
> has been stripped off anyway)....

In fact, I meant to write:
probably you did not want to post this to R-devel ...


> Uwe Ligges
> 
> 
> 
>> Thanks,
>>
>> Hadley
>>
>>
>> ------------------------------------------------------------------------
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
>


From ripley at stats.ox.ac.uk  Mon May  8 12:51:20 2006
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Mon,  8 May 2006 12:51:20 +0200 (CEST)
Subject: [Rd] Inconsistency in AIC values for glm with family poisson
	(PR#8841)
Message-ID: <20060508105120.25D5DCCE2@slim.kubism.ku.dk>

  This message is in MIME format.  The first part should be readable text,
  while the remaining parts are likely unreadable without MIME-aware tools.

--27464147-1557463723-1147085467=:8118
Content-Type: TEXT/PLAIN; charset=iso-8859-1; format=flowed
Content-Transfer-Encoding: 8BIT

On Mon, 8 May 2006, x.sole at iconcologia.net wrote:

> Full_Name: Xavier Sol?
> Version: 2.3.0
> OS: Windows XP SP2
> Submission from: (NULL) (213.151.99.160)
>
>
> #When computing AIC for one of the models shown in ?glm we get an 
> inconsistent AIC value. We also get the same wrong value if we use 
> "extractAIC" o "AIC" functions.

Inconsistent with what?  It seems to me that it consistently gives the 
right answer, but you have not used the actual definition of AIC.

> example(glm)
>
> glm.D93
>
> extractAIC(glm.D93)
>
> #AIC of this model should be 15.129 (residual deviance + 2*effective 
> degrees of freedom), but the AIC which R returns is 56.76. Function 
> extractAIC returns the right number of effective degrees of freedom (5), 
> but anyway seems to fail in calculating the correct AIC value.

Where do you get that from (it is not the definition of AIC)?

> AIC(glm.D93)
[1] 56.76132
> extractAIC(glm.D93)
[1]  5.00000 56.76132
> logLik(glm.D93)
'log Lik.' -23.38066 (df=5)

Did you read ?AIC, which gives the actual definition?  You may also need 
to review the definitions (note, plural) of `deviance'.

Please don't expect us to accept your assertions for definitions 
of statistical quantities: you need to supply your credentials and 
references.  In this case the help page actually points out that the 
quantity is not unambiguously defined.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595
--27464147-1557463723-1147085467=:8118--


From john.peters at nmi.gov.au  Mon May  8 14:55:57 2006
From: john.peters at nmi.gov.au (john.peters at nmi.gov.au)
Date: Mon,  8 May 2006 14:55:57 +0200 (CEST)
Subject: [Rd] mean of complex vector (PR#8842)
Message-ID: <20060508125557.67B80CCDA@slim.kubism.ku.dk>

Full_Name: John Peters
Version: 2.3.0
OS: Windows 2000, xp
Submission from: (NULL) (220.233.20.203)


In R2.3.0 on Windows 2000 and xp

> mean(c(1i))
[1] 0+2i
> mean(c(1i,1i))
[1] 0+3i
> mean(c(1i,1i,1i))
[1] 0+4i

OK in R2.2.1


From p.dalgaard at biostat.ku.dk  Mon May  8 15:43:57 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 08 May 2006 15:43:57 +0200
Subject: [Rd] mean of complex vector (PR#8842)
In-Reply-To: <20060508125557.67B80CCDA@slim.kubism.ku.dk>
References: <20060508125557.67B80CCDA@slim.kubism.ku.dk>
Message-ID: <x2fyjkein6.fsf@viggo.kubism.ku.dk>

john.peters at nmi.gov.au writes:

> Full_Name: John Peters
> Version: 2.3.0
> OS: Windows 2000, xp
> Submission from: (NULL) (220.233.20.203)
> 
> 
> In R2.3.0 on Windows 2000 and xp
> 
> > mean(c(1i))
> [1] 0+2i
> > mean(c(1i,1i))
> [1] 0+3i
> > mean(c(1i,1i,1i))
> [1] 0+4i
> 
> OK in R2.2.1

Yes. This comes from a blunder in summary.c, apparently attempting to
copy the code from the REALSXP case, mutatis mutandis, but not quite so...

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From boom2k1 at hotmail.com  Tue May  9 02:20:23 2006
From: boom2k1 at hotmail.com (Charles Cheung)
Date: Mon, 08 May 2006 17:20:23 -0700
Subject: [Rd] Efficient Merging of two huge sorted data frames?---Use
	merge()?
Message-ID: <BAY106-F385999B945C45E45AF07AA8A90@phx.gbl>

Hello all,

A problem I encounter today is the speed which takes to sort two huge data 
frames...

I wish to sort by (X,Y)

Dataframe One consists of variables:
X, Y, sequence, position
having ~700 000 records

another dataframe consists of
X,Y, intensities
having ~900 000 records


Every (X,Y) pair in dataframe One is included in dataframe Two,
however,  the reverse is not true.
Furthermore,  (X,Y, position) in data frame One makes the record unique.
(That means there can be multiple records with the same (X,Y) records!)

Added together, it makes it hard to just combine the two data frames 
together by simply going
data.frame(dataFrameOne, dataFrameTwo) because the mapping won't correspond 
even in sorted records by X and Y.


Intuitive, it should only require very little time <O(n) complexity> after 
the data records are sorted.
However, it takes so long (I haven't finished the process in 20 minutes.. it 
should only take <1 min) to merge the list by X and Y using

merge(dataFrameOne, dataFrameTwo, by=c("X","Y") , which leads me to suspect 
this process is not optimized for already sorted list.

* assuming the two frames have been sorted, I would be able to do the 
following:


X Y seq Pos
1 1   AA  32
1 2   AG  44
1 3   GC  65


X Y intensities
1 1  0.4
1 3  0.552

>>Cursor at beginning (1,1) (1,1) -->merge the (1,1) pair.. then cursor 
>>moves to (1,2) (1,3)  --> can't find..     cursor moves to (1,3) (1,3) .. 
>>merge that pair

Is the merge function doing that already?


Is there an efficient way to merge the data frames? (What do you suggest I 
should do?)


(to produce)
X Y seq pos intensities
1 1 AA   32     0.4
1 3 GC  65     0.552

Thank you in advance!


Charles Cheung


From pinard at iro.umontreal.ca  Tue May  9 03:03:55 2006
From: pinard at iro.umontreal.ca (=?iso-8859-1?Q?Fran=E7ois?= Pinard)
Date: Mon, 8 May 2006 21:03:55 -0400
Subject: [Rd] "Unfelicity" :-) with edit()
Message-ID: <20060509010355.GA25342@alcyon.progiciels-bpi.ca>

Hi, people.  This is about R 2.3.0 under Linux.

It seems that edit() may change a function environment.  Here is 
a transcript, more comments follow:

======================================================================>
> fix(f)

> f
function ()
{
}

> fix(f)
Erreur dans edit(name, file, title, editor) :
        une erreur s'est produite ? la ligne 3
 utilisez une commande du genre
 x <- edit()
 pour corriger

> f <- edit()

> f
function ()
{
}
<environment: base>
======================================================================<

The initial ``fix(f)`` called an editor, which I exited right away.  For 
the second ``fix(f)``, I used the editor for adding a slash between 
braces, and exited.  The French comment produced by R speaks about an 
error at line 3 and suggests using something like ``x <- edit()`` to 
make a correction.  On the third call to the editor, I remove the slash 
and exit.  Now, the environment of the function became "base".

This has unfortunate effects when editing a more substantial function, 
because for example, "stats" or "utils" is not readily available anymore 
after the editing.  Is it reasonable to suggest an improvement in the 
mechanics of edit(), for alleviating this drawback ?

-- 
Fran?ois Pinard   http://pinard.progiciels-bpi.ca


From murdoch at stats.uwo.ca  Tue May  9 03:23:56 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 08 May 2006 21:23:56 -0400
Subject: [Rd] "Unfelicity" :-) with edit()
In-Reply-To: <20060509010355.GA25342@alcyon.progiciels-bpi.ca>
References: <20060509010355.GA25342@alcyon.progiciels-bpi.ca>
Message-ID: <445FEF2C.5000800@stats.uwo.ca>

On 5/8/2006 9:03 PM, Fran?ois Pinard wrote:
> Hi, people.  This is about R 2.3.0 under Linux.
> 
> It seems that edit() may change a function environment.  Here is 
> a transcript, more comments follow:
> 
> ======================================================================>
>> fix(f)
> 
>> f
> function ()
> {
> }
> 
>> fix(f)
> Erreur dans edit(name, file, title, editor) :
>         une erreur s'est produite ? la ligne 3
>  utilisez une commande du genre
>  x <- edit()
>  pour corriger
> 
>> f <- edit()
> 
>> f
> function ()
> {
> }
> <environment: base>
> ======================================================================<
> 
> The initial ``fix(f)`` called an editor, which I exited right away.  For 
> the second ``fix(f)``, I used the editor for adding a slash between 
> braces, and exited.  The French comment produced by R speaks about an 
> error at line 3 and suggests using something like ``x <- edit()`` to 
> make a correction.  On the third call to the editor, I remove the slash 
> and exit.  Now, the environment of the function became "base".
> 
> This has unfortunate effects when editing a more substantial function, 
> because for example, "stats" or "utils" is not readily available anymore 
> after the editing.  Is it reasonable to suggest an improvement in the 
> mechanics of edit(), for alleviating this drawback ?

edit() is a hack, so you should expect problems.  You're better off 
keeping your source in an editor and using source() to get it.  There is 
no way it could preserve the environment of a function if you go through 
the steps you went through above.

However, it's a bug (introduced by me last year when converting NULL to 
.BaseEnv) that it ends up with the base environment instead of the 
global environment.  I'll fix it.

Duncan Murdoch


From berwin at maths.uwa.edu.au  Tue May  9 09:49:02 2006
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Tue, 9 May 2006 15:49:02 +0800
Subject: [Rd] Question about match.fun()
Message-ID: <17504.18798.614739.269753@bossiaea.maths.uwa.edu.au>

Dear all,

I was recently contacted by a user about an alledged problem/bug in
the latest version of lasso2.  After some investigation, we found out
that it was a user error which boils down to the following:

> x <- matrix(rnorm(200), ncol=2)
> var <- "fred"
> apply(x, 2, var)
Error in get(x, envir, mode, inherits) : variable "fred" of mode "function" was not found

only that the "offending" apply() command happened inside the gl1ce()
function of lasso2.

I was under the impression that R can now distinguish between
variables and functions with the same name and, indeed, the following
works:

> var <- 2
> apply(x, 2, var)
[1] 1.053002 1.250875

Poking a bit around, I guess that the ability to distinguish between
variables and functions with the same name comes from the introduction
of the function match.fun() and, after reading its help page, the
reasons why an error is triggered the first time but not the second
time is perfectly clear to me.

I wonder whether it would make sense to change match.fun() such that
the first case does not result in an error?  I was thinking along the
line that if the argument to match.fun() is a variable that contains a
character vector of length one then, using get(), match.fun() attemps
to find a function with that name.  If the get() command does not
succeed, then a second try is made using the name of the variable
passed by the caller to match.fun().

So before trying to modify match.fun() and submitting a patch, I
wanted to ask whether such a change would be accepted?  Is there an
argument that I don't see that the first case should always result in
an error and not be silently resolved?

Cheers,

        Berwin


From ripley at stats.ox.ac.uk  Tue May  9 09:50:36 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 9 May 2006 08:50:36 +0100 (BST)
Subject: [Rd] Efficient Merging of two huge sorted data frames?---Use
 merge()?
In-Reply-To: <BAY106-F385999B945C45E45AF07AA8A90@phx.gbl>
References: <BAY106-F385999B945C45E45AF07AA8A90@phx.gbl>
Message-ID: <Pine.LNX.4.64.0605090837590.6119@gannet.stats.ox.ac.uk>

merge() is not optimized for large data frames.  To do things on this 
scale you really want to be using a DBMS not R.  See the `R Data 
Import/Export Manual'.

Sorting is not really relevant, especially as merge is not assuming that 
the match is unique.  Hashing could be used, but is not.

As R is open source, you have the source code and it would be kinder to 
read it yourself rather than expect this list to read it for you.  A 
useful contribution to the R project would be to contribute a more 
efficient version, and we look forwards to seeing your contribution.

On Mon, 8 May 2006, Charles Cheung wrote:

> Hello all,
>
> A problem I encounter today is the speed which takes to sort two huge data
> frames...
>
> I wish to sort by (X,Y)
>
> Dataframe One consists of variables:
> X, Y, sequence, position
> having ~700 000 records
>
> another dataframe consists of
> X,Y, intensities
> having ~900 000 records
>
>
> Every (X,Y) pair in dataframe One is included in dataframe Two,
> however,  the reverse is not true.
> Furthermore,  (X,Y, position) in data frame One makes the record unique.
> (That means there can be multiple records with the same (X,Y) records!)
>
> Added together, it makes it hard to just combine the two data frames
> together by simply going
> data.frame(dataFrameOne, dataFrameTwo) because the mapping won't correspond
> even in sorted records by X and Y.
>
>
> Intuitive, it should only require very little time <O(n) complexity> after
> the data records are sorted.
> However, it takes so long (I haven't finished the process in 20 minutes.. it
> should only take <1 min) to merge the list by X and Y using
>
> merge(dataFrameOne, dataFrameTwo, by=c("X","Y") , which leads me to suspect
> this process is not optimized for already sorted list.
>
> * assuming the two frames have been sorted, I would be able to do the
> following:
>
>
> X Y seq Pos
> 1 1   AA  32
> 1 2   AG  44
> 1 3   GC  65
>
>
> X Y intensities
> 1 1  0.4
> 1 3  0.552
>
>>> Cursor at beginning (1,1) (1,1) -->merge the (1,1) pair.. then cursor
>>> moves to (1,2) (1,3)  --> can't find..     cursor moves to (1,3) (1,3) ..
>>> merge that pair
>
> Is the merge function doing that already?
>
>
> Is there an efficient way to merge the data frames? (What do you suggest I
> should do?)
>
>
> (to produce)
> X Y seq pos intensities
> 1 1 AA   32     0.4
> 1 3 GC  65     0.552
>
> Thank you in advance!
>
>
> Charles Cheung
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From h.wickham at gmail.com  Tue May  9 11:06:58 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 9 May 2006 11:06:58 +0200
Subject: [Rd] Seg fault when installing package from bad repository
Message-ID: <f8e6ff050605090206j763a2438n914d6dd8f639cba@mail.gmail.com>

> install.packages("rggobi", repos="http://ggobi.org/r/")
Warning in install.packages("rggobi", repos = "http://ggobi.org/r/") :
         argument 'lib' is missing: using /Users/hadley/Library/R/library/
Reading symbols for shared libraries . done

Program received signal EXC_BAD_ACCESS, Could not access memory.
Reason: KERN_INVALID_ADDRESS at address: 0x5f4d4550
0x90002f48 in strlen ()
(gdb) where
#0  0x90002f48 in strlen ()
#1  0x9000d7d0 in __vfprintf$LDBL128 ()
#2  0x900273cc in vsnprintf$LDBL128 ()
#3  0x0108ea1c in Rvsnprintf (buf=0xbfff35f4 "B", size=1000,
format=0x3 <Address 0x3 out of bounds>, ap=0x34 <Address 0x34 out of
bounds>) at ../../../../R-2.3.0/src/main/errors.c:211
#4  0x01092e68 in Rf_warning (format=0x3 <Address 0x3 out of bounds>)
at ../../../../R-2.3.0/src/main/errors.c:223
#5  0x023c39a8 in in_R_HTTPOpen (url=0x212c930
"/Library/Frameworks/R.framework/Resources/share/locale/en/LC_MESSAGES/R.mo",
cacheOK=404) at
../../../../../R-2.3.0/src/modules/internet/internet.c:490
#6  0x023c3f00 in in_do_download (call=0x5f4d4553, op=0xbfff2a03,
args=0x195d300, env=0x34) at
../../../../../R-2.3.0/src/modules/internet/internet.c:320
#7  0x010b6290 in do_download (call=0x18d0078, op=0x181c2a8,
args=0x18c3b50, env=0x18cfd64) at
../../../../R-2.3.0/src/main/internet.c:99
#8  0x010cefc4 in do_internal (call=0x18c3b50, op=0xbfff2a03,
args=0x0, env=0x18cfd64) at ../../../../R-2.3.0/src/main/names.c:1089
#9  0x0109d798 in Rf_eval (e=0x18d0040, rho=0x18cfd64) at
../../../../R-2.3.0/src/main/eval.c:391
#10 0x0109f87c in do_set (call=0x18d17b0, op=0x180a190,
args=0x18d0008, rho=0x18cfd64) at
../../../../R-2.3.0/src/main/eval.c:1303
#11 0x0109d798 in Rf_eval (e=0x18d17b0, rho=0x18cfd64) at
../../../../R-2.3.0/src/main/eval.c:391
#12 0x0109d798 in Rf_eval (e=0x18d16b4, rho=0x18cfd64) at
../../../../R-2.3.0/src/main/eval.c:391
#13 0x0109f93c in do_begin (call=0x18d1920, op=0x180a0cc,
args=0x18d1628, rho=0x18cfd64) at
../../../../R-2.3.0/src/main/eval.c:1067
#14 0x0109d798 in Rf_eval (e=0x18d1920, rho=0x18cfd64) at
../../../../R-2.3.0/src/main/eval.c:391
#15 0x010a0d34 in Rf_applyClosure (call=0x18f8cf4, op=0x18d2580,
arglist=0x18cfb50, rho=0x18f61ac, suppliedenv=0x181d200) at
../../../../R-2.3.0/src/main/eval.c:581
#16 0x0109d634 in Rf_eval (e=0x18f8cf4, rho=0x18f61ac) at
../../../../R-2.3.0/src/main/eval.c:422
#17 0x0109d66c in Rf_eval (e=0x18d2894, rho=0x18d293c) at
../../../../R-2.3.0/src/main/eval.c:370
#18 0x0109d938 in Rf_eval (e=0x1826b18, rho=0x18d293c) at
../../../../R-2.3.0/src/main/eval.c:357
#19 0x0109f93c in do_begin (call=0x1a37720, op=0x180a0cc,
args=0x1a38f2c, rho=0x18d293c) at
../../../../R-2.3.0/src/main/eval.c:1067
#20 0x0109d798 in Rf_eval (e=0x1a37720, rho=0x18d293c) at
../../../../R-2.3.0/src/main/eval.c:391
#21 0x0109d798 in Rf_eval (e=0x1a37800, rho=0x18d293c) at
../../../../R-2.3.0/src/main/eval.c:391
#22 0x0109f93c in do_begin (call=0x1a37838, op=0x180a0cc,
args=0x1a3781c, rho=0x18d293c) at
../../../../R-2.3.0/src/main/eval.c:1067
#23 0x0109d798 in Rf_eval (e=0x1a37838, rho=0x18d293c) at
../../../../R-2.3.0/src/main/eval.c:391
#24 0x010a0d34 in Rf_applyClosure (call=0x18f8cbc, op=0x1a378c4,
arglist=0x18d28b0, rho=0x18f61ac, suppliedenv=0x181d200) at
../../../../R-2.3.0/src/main/eval.c:581
#25 0x0109d634 in Rf_eval (e=0x18f8cbc, rho=0x18f61ac) at
../../../../R-2.3.0/src/main/eval.c:422
#26 0x0109f87c in do_set (call=0x18f8c68, op=0x180a190,
args=0x18f8c84, rho=0x18f61ac) at
../../../../R-2.3.0/src/main/eval.c:1303
#27 0x0109d798 in Rf_eval (e=0x18f8c68, rho=0x18f61ac) at
../../../../R-2.3.0/src/main/eval.c:391
#28 0x0109f93c in do_begin (call=0x18f88e8, op=0x180a0cc,
args=0x18f8c4c, rho=0x18f61ac) at
../../../../R-2.3.0/src/main/eval.c:1067
#29 0x0109d798 in Rf_eval (e=0x18f88e8, rho=0x18f61ac) at
../../../../R-2.3.0/src/main/eval.c:391
#30 0x0109d798 in Rf_eval (e=0x18f9724, rho=0x18f61ac) at
../../../../R-2.3.0/src/main/eval.c:391
#31 0x0109f93c in do_begin (call=0x18f94d8, op=0x180a0cc,
args=0x18f9708, rho=0x18f61ac) at
../../../../R-2.3.0/src/main/eval.c:1067
#32 0x0109d798 in Rf_eval (e=0x18f94d8, rho=0x18f61ac) at
../../../../R-2.3.0/src/main/eval.c:391
#33 0x0109d798 in Rf_eval (e=0x18fa350, rho=0x18f61ac) at
../../../../R-2.3.0/src/main/eval.c:391
#34 0x0109f93c in do_begin (call=0x18fa174, op=0x180a0cc,
args=0x18fa334, rho=0x18f61ac) at
../../../../R-2.3.0/src/main/eval.c:1067
#35 0x0109d798 in Rf_eval (e=0x18fa174, rho=0x18f61ac) at
../../../../R-2.3.0/src/main/eval.c:391
#36 0x010a0074 in do_for (call=0x18fa104, op=0x1808958,
args=0x18fa120, rho=0x18f61ac) at
../../../../R-2.3.0/src/main/eval.c:963
#37 0x0109d798 in Rf_eval (e=0x18fa104, rho=0x18f61ac) at
../../../../R-2.3.0/src/main/eval.c:391
#38 0x0109f93c in do_begin (call=0x18fb2fc, op=0x180a0cc,
args=0x18fa0e8, rho=0x18f61ac) at
../../../../R-2.3.0/src/main/eval.c:1067
#39 0x0109d798 in Rf_eval (e=0x18fb2fc, rho=0x18f61ac) at
../../../../R-2.3.0/src/main/eval.c:391
#40 0x010a0d34 in Rf_applyClosure (call=0x1910b18, op=0x18fbf5c,
arglist=0x18f6120, rho=0x190c0cc, suppliedenv=0x181d200) at
../../../../R-2.3.0/src/main/eval.c:581
#41 0x0109d634 in Rf_eval (e=0x1910b18, rho=0x190c0cc) at
../../../../R-2.3.0/src/main/eval.c:422
#42 0x0109f87c in do_set (call=0x1910ac4, op=0x180a190,
args=0x1910ae0, rho=0x190c0cc) at
../../../../R-2.3.0/src/main/eval.c:1303
#43 0x0109d798 in Rf_eval (e=0x1910ac4, rho=0x190c0cc) at
../../../../R-2.3.0/src/main/eval.c:391
#44 0x0109d798 in Rf_eval (e=0x1910a38, rho=0x190c0cc) at
../../../../R-2.3.0/src/main/eval.c:391
#45 0x0109f93c in do_begin (call=0x19161ac, op=0x180a0cc,
args=0x1910a00, rho=0x190c0cc) at
../../../../R-2.3.0/src/main/eval.c:1067
#46 0x0109d798 in Rf_eval (e=0x19161ac, rho=0x190c0cc) at
../../../../R-2.3.0/src/main/eval.c:391
#47 0x010a0d34 in Rf_applyClosure (call=0x19376ec, op=0x1916c30,
arglist=0x190cd2c, rho=0x192e698, suppliedenv=0x181d200) at
../../../../R-2.3.0/src/main/eval.c:581
#48 0x0109d634 in Rf_eval (e=0x19376ec, rho=0x192e698) at
../../../../R-2.3.0/src/main/eval.c:422
#49 0x0109f93c in do_begin (call=0x19374bc, op=0x180a0cc,
args=0x19376d0, rho=0x192e698) at
../../../../R-2.3.0/src/main/eval.c:1067
#50 0x0109d798 in Rf_eval (e=0x19374bc, rho=0x192e698) at
../../../../R-2.3.0/src/main/eval.c:391
#51 0x0109d798 in Rf_eval (e=0x1937414, rho=0x192e698) at
../../../../R-2.3.0/src/main/eval.c:391
#52 0x0109f93c in do_begin (call=0x19373dc, op=0x180a0cc,
args=0x19373f8, rho=0x192e698) at
../../../../R-2.3.0/src/main/eval.c:1067
#53 0x0109d798 in Rf_eval (e=0x19373dc, rho=0x192e698) at
../../../../R-2.3.0/src/main/eval.c:391
#54 0x0109d798 in Rf_eval (e=0x1938eb4, rho=0x192e698) at
../../../../R-2.3.0/src/main/eval.c:391
#55 0x0109f93c in do_begin (call=0x193ceec, op=0x180a0cc,
args=0x1938e98, rho=0x192e698) at
../../../../R-2.3.0/src/main/eval.c:1067
#56 0x0109d798 in Rf_eval (e=0x193ceec, rho=0x192e698) at
../../../../R-2.3.0/src/main/eval.c:391
#57 0x010a0d34 in Rf_applyClosure (call=0x193dd64, op=0x193c85c,
arglist=0x192e4d8, rho=0x181d1e4, suppliedenv=0x181d200) at
../../../../R-2.3.0/src/main/eval.c:581
#58 0x0109d634 in Rf_eval (e=0x193dd64, rho=0x181d1e4) at
../../../../R-2.3.0/src/main/eval.c:422
#59 0x010bcdac in Rf_ReplIteration (rho=0x181d1e4, savestack=0,
browselevel=18992200, state=0xbffff068) at
../../../../R-2.3.0/src/main/main.c:254
#60 0x010bd0e0 in R_ReplConsole (rho=0x181d1e4, savestack=0,
browselevel=0) at ../../../../R-2.3.0/src/main/main.c:302
#61 0x010bd3f8 in run_Rmainloop () at ../../../../R-2.3.0/src/main/main.c:905
#62 0x00002cd8 in main (ac=1598899539, av=0xbfff2a03) at
../../../../R-2.3.0/src/main/Rmain.c:33

platform       powerpc-apple-darwin8.6.0
arch           powerpc
os             darwin8.6.0
system         powerpc, darwin8.6.0
status
major          2
minor          3.0
year           2006
month          04
day            24
svn rev        37909
language       R
version.string Version 2.3.0 (2006-04-24)

http://ggobi.org/r/ is currently returning a 403 Forbidden header, but
it shouldn't segfault (not a high priority either, though)

Regards,

Hadley


From maechler at stat.math.ethz.ch  Tue May  9 11:10:38 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 9 May 2006 11:10:38 +0200
Subject: [Rd] combn(n, k, ...) and all its re-inventions
Message-ID: <17504.23694.497985.819330@stat.math.ethz.ch>

It seems people are reinventing the wheel here:
The goal is to generate  all combinations of 1:n of size k.
This (typically) results in a matrix of size  k * choose(n,k)
i.e. needs O(n ^ k) space, hence is only applicable to
relatively small k.
Then alternatives have been devised to generate the combinations 
"one by one", and I think I remember there has been a
quiz/challenge about 20 years ago, at an S user's conference in
Australia(?), on this topic.

Anyway, AFAIK, the first nice and efficient function for this
has been provided by Scott Chasalow for S (not R)  and he made
his S code available at the University of Wageningen as
"combinat" module. Later this became into an R package which is
now maintained by Vince Carey.  The source of 'combinat' still
shows
#       DATE WRITTEN: 14 April 1994          LAST REVISED:  10 July 1995
#       AUTHOR:  Scott Chasalow

OTOH, people have since reinvented the wheel quite prolifically:
There's combinations() in gtools {based on Bill Venables' code from R News 1/1},
combs() in CAtools, subsets() in BHH2, and nchoosek() in vsn (bioconductor);
then 'fwd.combn' in package "forward" which states explicitly
that it is Scott's combn() renamed..
I stopped searching for more, and I've made sure all
these 6 functions compute the same thing, at least in the most simple case.

After simply replacing nCm() by choose(), and some other minor
tweaks, I have now a version of combn() that is faster than all
the other implementations {only slightly faster than
combinations()}, and I plan to add this to R's standard package
'utils'. 
Hopefully, the reinventing can be stopped by this, once people
can rely on a relatively fast implementation of the
functionality.

One might also consider to include a version of the ``one by
one'' combination generators {as mentioned above} which is
needed for larger k.

Opinions ?

Martin Maechler, ETH Zurich


From h.wickham at gmail.com  Tue May  9 11:19:11 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 9 May 2006 11:19:11 +0200
Subject: [Rd] Seg fault when installing package from bad repository
In-Reply-To: <f8e6ff050605090206j763a2438n914d6dd8f639cba@mail.gmail.com>
References: <f8e6ff050605090206j763a2438n914d6dd8f639cba@mail.gmail.com>
Message-ID: <f8e6ff050605090219l5819fb2era4209d44ebf17c1e@mail.gmail.com>

It still segfaults even now that I've fixed the access error.  Ah, 
but if I specify type="source", so it must be a problem with having a
mac binary path but no packages in it.  Is there anyway to fall back
to source automatically?

Thanks,

Hadley

On 5/9/06, hadley wickham <h.wickham at gmail.com> wrote:
> > install.packages("rggobi", repos="http://ggobi.org/r/")
> Warning in install.packages("rggobi", repos = "http://ggobi.org/r/") :
>          argument 'lib' is missing: using /Users/hadley/Library/R/library/
> Reading symbols for shared libraries . done
>
> Program received signal EXC_BAD_ACCESS, Could not access memory.
> Reason: KERN_INVALID_ADDRESS at address: 0x5f4d4550
> 0x90002f48 in strlen ()
> (gdb) where
> #0  0x90002f48 in strlen ()
> #1  0x9000d7d0 in __vfprintf$LDBL128 ()
> #2  0x900273cc in vsnprintf$LDBL128 ()
> #3  0x0108ea1c in Rvsnprintf (buf=0xbfff35f4 "B", size=1000,
> format=0x3 <Address 0x3 out of bounds>, ap=0x34 <Address 0x34 out of
> bounds>) at ../../../../R-2.3.0/src/main/errors.c:211
> #4  0x01092e68 in Rf_warning (format=0x3 <Address 0x3 out of bounds>)
> at ../../../../R-2.3.0/src/main/errors.c:223
> #5  0x023c39a8 in in_R_HTTPOpen (url=0x212c930
> "/Library/Frameworks/R.framework/Resources/share/locale/en/LC_MESSAGES/R.mo",
> cacheOK=404) at
> ../../../../../R-2.3.0/src/modules/internet/internet.c:490
> #6  0x023c3f00 in in_do_download (call=0x5f4d4553, op=0xbfff2a03,
> args=0x195d300, env=0x34) at
> ../../../../../R-2.3.0/src/modules/internet/internet.c:320
> #7  0x010b6290 in do_download (call=0x18d0078, op=0x181c2a8,
> args=0x18c3b50, env=0x18cfd64) at
> ../../../../R-2.3.0/src/main/internet.c:99
> #8  0x010cefc4 in do_internal (call=0x18c3b50, op=0xbfff2a03,
> args=0x0, env=0x18cfd64) at ../../../../R-2.3.0/src/main/names.c:1089
> #9  0x0109d798 in Rf_eval (e=0x18d0040, rho=0x18cfd64) at
> ../../../../R-2.3.0/src/main/eval.c:391
> #10 0x0109f87c in do_set (call=0x18d17b0, op=0x180a190,
> args=0x18d0008, rho=0x18cfd64) at
> ../../../../R-2.3.0/src/main/eval.c:1303
> #11 0x0109d798 in Rf_eval (e=0x18d17b0, rho=0x18cfd64) at
> ../../../../R-2.3.0/src/main/eval.c:391
> #12 0x0109d798 in Rf_eval (e=0x18d16b4, rho=0x18cfd64) at
> ../../../../R-2.3.0/src/main/eval.c:391
> #13 0x0109f93c in do_begin (call=0x18d1920, op=0x180a0cc,
> args=0x18d1628, rho=0x18cfd64) at
> ../../../../R-2.3.0/src/main/eval.c:1067
> #14 0x0109d798 in Rf_eval (e=0x18d1920, rho=0x18cfd64) at
> ../../../../R-2.3.0/src/main/eval.c:391
> #15 0x010a0d34 in Rf_applyClosure (call=0x18f8cf4, op=0x18d2580,
> arglist=0x18cfb50, rho=0x18f61ac, suppliedenv=0x181d200) at
> ../../../../R-2.3.0/src/main/eval.c:581
> #16 0x0109d634 in Rf_eval (e=0x18f8cf4, rho=0x18f61ac) at
> ../../../../R-2.3.0/src/main/eval.c:422
> #17 0x0109d66c in Rf_eval (e=0x18d2894, rho=0x18d293c) at
> ../../../../R-2.3.0/src/main/eval.c:370
> #18 0x0109d938 in Rf_eval (e=0x1826b18, rho=0x18d293c) at
> ../../../../R-2.3.0/src/main/eval.c:357
> #19 0x0109f93c in do_begin (call=0x1a37720, op=0x180a0cc,
> args=0x1a38f2c, rho=0x18d293c) at
> ../../../../R-2.3.0/src/main/eval.c:1067
> #20 0x0109d798 in Rf_eval (e=0x1a37720, rho=0x18d293c) at
> ../../../../R-2.3.0/src/main/eval.c:391
> #21 0x0109d798 in Rf_eval (e=0x1a37800, rho=0x18d293c) at
> ../../../../R-2.3.0/src/main/eval.c:391
> #22 0x0109f93c in do_begin (call=0x1a37838, op=0x180a0cc,
> args=0x1a3781c, rho=0x18d293c) at
> ../../../../R-2.3.0/src/main/eval.c:1067
> #23 0x0109d798 in Rf_eval (e=0x1a37838, rho=0x18d293c) at
> ../../../../R-2.3.0/src/main/eval.c:391
> #24 0x010a0d34 in Rf_applyClosure (call=0x18f8cbc, op=0x1a378c4,
> arglist=0x18d28b0, rho=0x18f61ac, suppliedenv=0x181d200) at
> ../../../../R-2.3.0/src/main/eval.c:581
> #25 0x0109d634 in Rf_eval (e=0x18f8cbc, rho=0x18f61ac) at
> ../../../../R-2.3.0/src/main/eval.c:422
> #26 0x0109f87c in do_set (call=0x18f8c68, op=0x180a190,
> args=0x18f8c84, rho=0x18f61ac) at
> ../../../../R-2.3.0/src/main/eval.c:1303
> #27 0x0109d798 in Rf_eval (e=0x18f8c68, rho=0x18f61ac) at
> ../../../../R-2.3.0/src/main/eval.c:391
> #28 0x0109f93c in do_begin (call=0x18f88e8, op=0x180a0cc,
> args=0x18f8c4c, rho=0x18f61ac) at
> ../../../../R-2.3.0/src/main/eval.c:1067
> #29 0x0109d798 in Rf_eval (e=0x18f88e8, rho=0x18f61ac) at
> ../../../../R-2.3.0/src/main/eval.c:391
> #30 0x0109d798 in Rf_eval (e=0x18f9724, rho=0x18f61ac) at
> ../../../../R-2.3.0/src/main/eval.c:391
> #31 0x0109f93c in do_begin (call=0x18f94d8, op=0x180a0cc,
> args=0x18f9708, rho=0x18f61ac) at
> ../../../../R-2.3.0/src/main/eval.c:1067
> #32 0x0109d798 in Rf_eval (e=0x18f94d8, rho=0x18f61ac) at
> ../../../../R-2.3.0/src/main/eval.c:391
> #33 0x0109d798 in Rf_eval (e=0x18fa350, rho=0x18f61ac) at
> ../../../../R-2.3.0/src/main/eval.c:391
> #34 0x0109f93c in do_begin (call=0x18fa174, op=0x180a0cc,
> args=0x18fa334, rho=0x18f61ac) at
> ../../../../R-2.3.0/src/main/eval.c:1067
> #35 0x0109d798 in Rf_eval (e=0x18fa174, rho=0x18f61ac) at
> ../../../../R-2.3.0/src/main/eval.c:391
> #36 0x010a0074 in do_for (call=0x18fa104, op=0x1808958,
> args=0x18fa120, rho=0x18f61ac) at
> ../../../../R-2.3.0/src/main/eval.c:963
> #37 0x0109d798 in Rf_eval (e=0x18fa104, rho=0x18f61ac) at
> ../../../../R-2.3.0/src/main/eval.c:391
> #38 0x0109f93c in do_begin (call=0x18fb2fc, op=0x180a0cc,
> args=0x18fa0e8, rho=0x18f61ac) at
> ../../../../R-2.3.0/src/main/eval.c:1067
> #39 0x0109d798 in Rf_eval (e=0x18fb2fc, rho=0x18f61ac) at
> ../../../../R-2.3.0/src/main/eval.c:391
> #40 0x010a0d34 in Rf_applyClosure (call=0x1910b18, op=0x18fbf5c,
> arglist=0x18f6120, rho=0x190c0cc, suppliedenv=0x181d200) at
> ../../../../R-2.3.0/src/main/eval.c:581
> #41 0x0109d634 in Rf_eval (e=0x1910b18, rho=0x190c0cc) at
> ../../../../R-2.3.0/src/main/eval.c:422
> #42 0x0109f87c in do_set (call=0x1910ac4, op=0x180a190,
> args=0x1910ae0, rho=0x190c0cc) at
> ../../../../R-2.3.0/src/main/eval.c:1303
> #43 0x0109d798 in Rf_eval (e=0x1910ac4, rho=0x190c0cc) at
> ../../../../R-2.3.0/src/main/eval.c:391
> #44 0x0109d798 in Rf_eval (e=0x1910a38, rho=0x190c0cc) at
> ../../../../R-2.3.0/src/main/eval.c:391
> #45 0x0109f93c in do_begin (call=0x19161ac, op=0x180a0cc,
> args=0x1910a00, rho=0x190c0cc) at
> ../../../../R-2.3.0/src/main/eval.c:1067
> #46 0x0109d798 in Rf_eval (e=0x19161ac, rho=0x190c0cc) at
> ../../../../R-2.3.0/src/main/eval.c:391
> #47 0x010a0d34 in Rf_applyClosure (call=0x19376ec, op=0x1916c30,
> arglist=0x190cd2c, rho=0x192e698, suppliedenv=0x181d200) at
> ../../../../R-2.3.0/src/main/eval.c:581
> #48 0x0109d634 in Rf_eval (e=0x19376ec, rho=0x192e698) at
> ../../../../R-2.3.0/src/main/eval.c:422
> #49 0x0109f93c in do_begin (call=0x19374bc, op=0x180a0cc,
> args=0x19376d0, rho=0x192e698) at
> ../../../../R-2.3.0/src/main/eval.c:1067
> #50 0x0109d798 in Rf_eval (e=0x19374bc, rho=0x192e698) at
> ../../../../R-2.3.0/src/main/eval.c:391
> #51 0x0109d798 in Rf_eval (e=0x1937414, rho=0x192e698) at
> ../../../../R-2.3.0/src/main/eval.c:391
> #52 0x0109f93c in do_begin (call=0x19373dc, op=0x180a0cc,
> args=0x19373f8, rho=0x192e698) at
> ../../../../R-2.3.0/src/main/eval.c:1067
> #53 0x0109d798 in Rf_eval (e=0x19373dc, rho=0x192e698) at
> ../../../../R-2.3.0/src/main/eval.c:391
> #54 0x0109d798 in Rf_eval (e=0x1938eb4, rho=0x192e698) at
> ../../../../R-2.3.0/src/main/eval.c:391
> #55 0x0109f93c in do_begin (call=0x193ceec, op=0x180a0cc,
> args=0x1938e98, rho=0x192e698) at
> ../../../../R-2.3.0/src/main/eval.c:1067
> #56 0x0109d798 in Rf_eval (e=0x193ceec, rho=0x192e698) at
> ../../../../R-2.3.0/src/main/eval.c:391
> #57 0x010a0d34 in Rf_applyClosure (call=0x193dd64, op=0x193c85c,
> arglist=0x192e4d8, rho=0x181d1e4, suppliedenv=0x181d200) at
> ../../../../R-2.3.0/src/main/eval.c:581
> #58 0x0109d634 in Rf_eval (e=0x193dd64, rho=0x181d1e4) at
> ../../../../R-2.3.0/src/main/eval.c:422
> #59 0x010bcdac in Rf_ReplIteration (rho=0x181d1e4, savestack=0,
> browselevel=18992200, state=0xbffff068) at
> ../../../../R-2.3.0/src/main/main.c:254
> #60 0x010bd0e0 in R_ReplConsole (rho=0x181d1e4, savestack=0,
> browselevel=0) at ../../../../R-2.3.0/src/main/main.c:302
> #61 0x010bd3f8 in run_Rmainloop () at ../../../../R-2.3.0/src/main/main.c:905
> #62 0x00002cd8 in main (ac=1598899539, av=0xbfff2a03) at
> ../../../../R-2.3.0/src/main/Rmain.c:33
>
> platform       powerpc-apple-darwin8.6.0
> arch           powerpc
> os             darwin8.6.0
> system         powerpc, darwin8.6.0
> status
> major          2
> minor          3.0
> year           2006
> month          04
> day            24
> svn rev        37909
> language       R
> version.string Version 2.3.0 (2006-04-24)
>
> http://ggobi.org/r/ is currently returning a 403 Forbidden header, but
> it shouldn't segfault (not a high priority either, though)
>
> Regards,
>
> Hadley
>


From ebarreto at igc.gulbenkian.pt  Tue May  9 12:28:04 2006
From: ebarreto at igc.gulbenkian.pt (ebarreto at igc.gulbenkian.pt)
Date: Tue,  9 May 2006 12:28:04 +0200 (CEST)
Subject: [Rd] Rmpi instlation problem (PR#8846)
Message-ID: <20060509102804.AF6D519A00@slim.kubism.ku.dk>

Ive tryed this:

R CMD INSTALL Rmpi_0.5-2.tar.gz

But occurred this error:

gcc -shared -L/usr/local/lib64 -o Rmpi.so conversion.o internal.o RegQuery.o
Rmpi.o -lmpi -llam -lutil -lpthread   -L/usr/local/lib64/R/lib -lR
/usr/lib64/gcc-lib/x86_64-suse-linux/3.3.3/../../../../x86_64-suse-linux/bin
/ld: /usr/local/lib/libmpi.a(infoset.o): relocation R_X86_64_32 can not be
used when making a shared object; recompile with -fPIC
/usr/local/lib/libmpi.a: could not read symbols: Bad value
collect2: ld returned 1 exit status
make: *** [Rmpi.so] Error 1
chmod: cannot access `/usr/local/lib64/R/library/Rmpi/libs/*': No such file
or directory
ERROR: compilation failed for package 'Rmpi'
** Removing '/usr/local/lib64/R/library/Rmpi'

May you give me some advice

Best 
EBH


--------------------------------------------------------
Emiliano Barreto_Hernandez
Profesor Asociado 
Colombia EMBnet Node Manager
Centro de Bioinform?tica
Instituto de Biotecnolog?a - Universidad Nacional de Colombia
Edificio Manuel Ancizar
Bogot? - Colombia
Tel +57 3165000 ext 16956 Fax +571 3165415
ebarretoh at unal.edu.co
http://bioinf.ibun.unal.edu.co
http://www.co.embnet.org


From ripley at stats.ox.ac.uk  Tue May  9 13:03:18 2006
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Tue,  9 May 2006 13:03:18 +0200 (CEST)
Subject: [Rd] Rmpi instlation problem (PR#8846)
Message-ID: <20060509110318.61023CD3C@slim.kubism.ku.dk>

  This message is in MIME format.  The first part should be readable text,
  while the remaining parts are likely unreadable without MIME-aware tools.

--27464147-1443006808-1147172576=:8133
Content-Type: TEXT/PLAIN; charset=iso-8859-1; format=flowed
Content-Transfer-Encoding: 8BIT

First, please do not abuse the bug reporting address to report errors in 
your own system or in a contributed package: see the FAQ and posting 
guide.  Basic information is missing here, but this looks like a x86_64 
version of Linux.

The message here is very clear: the error is in /usr/local/lib/libmpi.a.
This issue is discussed in the R-admin manual, so please consult it.
You need to re-build your installation of MPI as the message suggests.

On Tue, 9 May 2006, ebarreto at igc.gulbenkian.pt wrote:

> Ive tryed this:
>
> R CMD INSTALL Rmpi_0.5-2.tar.gz
>
> But occurred this error:
>
> gcc -shared -L/usr/local/lib64 -o Rmpi.so conversion.o internal.o RegQuery.o
> Rmpi.o -lmpi -llam -lutil -lpthread   -L/usr/local/lib64/R/lib -lR
> /usr/lib64/gcc-lib/x86_64-suse-linux/3.3.3/../../../../x86_64-suse-linux/bin
> /ld: /usr/local/lib/libmpi.a(infoset.o): relocation R_X86_64_32 can not be
> used when making a shared object; recompile with -fPIC
> /usr/local/lib/libmpi.a: could not read symbols: Bad value
> collect2: ld returned 1 exit status
> make: *** [Rmpi.so] Error 1
> chmod: cannot access `/usr/local/lib64/R/library/Rmpi/libs/*': No such file
> or directory
> ERROR: compilation failed for package 'Rmpi'
> ** Removing '/usr/local/lib64/R/library/Rmpi'
>
> May you give me some advice
>
> Best
> EBH
>
>
> --------------------------------------------------------
> Emiliano Barreto_Hernandez
> Profesor Asociado
> Colombia EMBnet Node Manager
> Centro de Bioinform?tica
> Instituto de Biotecnolog?a - Universidad Nacional de Colombia
> Edificio Manuel Ancizar
> Bogot? - Colombia
> Tel +57 3165000 ext 16956 Fax +571 3165415
> ebarretoh at unal.edu.co
> http://bioinf.ibun.unal.edu.co
> http://www.co.embnet.org
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595
--27464147-1443006808-1147172576=:8133--


From p.dalgaard at biostat.ku.dk  Tue May  9 13:54:05 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 09 May 2006 13:54:05 +0200
Subject: [Rd] combn(n, k, ...) and all its re-inventions
In-Reply-To: <17504.23694.497985.819330@stat.math.ethz.ch>
References: <17504.23694.497985.819330@stat.math.ethz.ch>
Message-ID: <x28xpb9zxe.fsf@viggo.kubism.ku.dk>

Martin Maechler <maechler at stat.math.ethz.ch> writes:


> tweaks, I have now a version of combn() that is faster than all
> the other implementations {only slightly faster than
> combinations()}, and I plan to add this to R's standard package
> 'utils'. 
> Hopefully, the reinventing can be stopped by this, once people
> can rely on a relatively fast implementation of the
> functionality.
> 
> One might also consider to include a version of the ``one by
> one'' combination generators {as mentioned above} which is
> needed for larger k.
> 
> Opinions ?

While you're in there... combn() has a nice feature that you can apply
a function to each combination, which can be quite useful (and fun) if
you're demonstrating permutation tests:

> x <- combn(20,10,function(i)mean(sleep$extra[i]))
> x <- round(x,2) # this is needed, or you get artifacts
> plot(sort(unique(x)),table(x),type="h")
> plot(sort(x),type="l")
> sum(x <= mean(sleep$extra[1:10])) / length(x)
[1] 0.04072398


However, combn() does its work in sapply() style: First create a list,
then simplify. As this quickly becomes a rather *long* list (e.g., a
slightly larger case with choose(29, 14)==77558760 combinations kills
R for me on a 2GB 64 bit machine), it might be desirable to have an option,
"assume.scalar" or so, to specify that the function always returns a
single scalar.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ripley at stats.ox.ac.uk  Tue May  9 15:01:59 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 9 May 2006 14:01:59 +0100 (BST)
Subject: [Rd] Seg fault when installing package from bad repository
In-Reply-To: <f8e6ff050605090219l5819fb2era4209d44ebf17c1e@mail.gmail.com>
References: <f8e6ff050605090206j763a2438n914d6dd8f639cba@mail.gmail.com>
	<f8e6ff050605090219l5819fb2era4209d44ebf17c1e@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0605091344000.12602@gannet.stats.ox.ac.uk>

On Tue, 9 May 2006, hadley wickham wrote:

> It still segfaults even now that I've fixed the access error.  Ah,
> but if I specify type="source", so it must be a problem with having a
> mac binary path but no packages in it.

It seems to be corruption inside the intl library on your machine: note 
how the url has been changed to be a file path and the format is an 
invalid address.  This sort of thing works correctly on my systems:

> download.file("http://ggobi.org/r/bin/macosx/powerpc/contrib/2.2/PACKAGES", 
"/tmp/foo")
trying URL 'http://ggobi.org/r/bin/macosx/powerpc/contrib/2.2/PACKAGES'
Error in 
download.file("http://ggobi.org/r/bin/macosx/powerpc/contrib/2.2/PACKAGES", 
:
         cannot open URL 
'http://ggobi.org/r/bin/macosx/powerpc/contrib/2.2/PACKAGES'
In addition: Warning message:
cannot open: HTTP status was '404 Not Found'

so I surmise it is a MacOS-specific problem.


> Is there anyway to fall back
> to source automatically?

No.

>
> Thanks,
>
> Hadley
>
> On 5/9/06, hadley wickham <h.wickham at gmail.com> wrote:
>>> install.packages("rggobi", repos="http://ggobi.org/r/")
>> Warning in install.packages("rggobi", repos = "http://ggobi.org/r/") :
>>          argument 'lib' is missing: using /Users/hadley/Library/R/library/
>> Reading symbols for shared libraries . done
>>
>> Program received signal EXC_BAD_ACCESS, Could not access memory.
>> Reason: KERN_INVALID_ADDRESS at address: 0x5f4d4550
>> 0x90002f48 in strlen ()
>> (gdb) where
>> #0  0x90002f48 in strlen ()
>> #1  0x9000d7d0 in __vfprintf$LDBL128 ()
>> #2  0x900273cc in vsnprintf$LDBL128 ()
>> #3  0x0108ea1c in Rvsnprintf (buf=0xbfff35f4 "B", size=1000,
>> format=0x3 <Address 0x3 out of bounds>, ap=0x34 <Address 0x34 out of
>> bounds>) at ../../../../R-2.3.0/src/main/errors.c:211
>> #4  0x01092e68 in Rf_warning (format=0x3 <Address 0x3 out of bounds>)
>> at ../../../../R-2.3.0/src/main/errors.c:223
>> #5  0x023c39a8 in in_R_HTTPOpen (url=0x212c930
>> "/Library/Frameworks/R.framework/Resources/share/locale/en/LC_MESSAGES/R.mo",
>> cacheOK=404) at
>> ../../../../../R-2.3.0/src/modules/internet/internet.c:490
>> #6  0x023c3f00 in in_do_download (call=0x5f4d4553, op=0xbfff2a03,
>> args=0x195d300, env=0x34) at
>> ../../../../../R-2.3.0/src/modules/internet/internet.c:320
>> #7  0x010b6290 in do_download (call=0x18d0078, op=0x181c2a8,
>> args=0x18c3b50, env=0x18cfd64) at
>> ../../../../R-2.3.0/src/main/internet.c:99
>> #8  0x010cefc4 in do_internal (call=0x18c3b50, op=0xbfff2a03,
>> args=0x0, env=0x18cfd64) at ../../../../R-2.3.0/src/main/names.c:1089
>> #9  0x0109d798 in Rf_eval (e=0x18d0040, rho=0x18cfd64) at
>> ../../../../R-2.3.0/src/main/eval.c:391
>> #10 0x0109f87c in do_set (call=0x18d17b0, op=0x180a190,
>> args=0x18d0008, rho=0x18cfd64) at
>> ../../../../R-2.3.0/src/main/eval.c:1303
>> #11 0x0109d798 in Rf_eval (e=0x18d17b0, rho=0x18cfd64) at
>> ../../../../R-2.3.0/src/main/eval.c:391
>> #12 0x0109d798 in Rf_eval (e=0x18d16b4, rho=0x18cfd64) at
>> ../../../../R-2.3.0/src/main/eval.c:391
>> #13 0x0109f93c in do_begin (call=0x18d1920, op=0x180a0cc,
>> args=0x18d1628, rho=0x18cfd64) at
>> ../../../../R-2.3.0/src/main/eval.c:1067
>> #14 0x0109d798 in Rf_eval (e=0x18d1920, rho=0x18cfd64) at
>> ../../../../R-2.3.0/src/main/eval.c:391
>> #15 0x010a0d34 in Rf_applyClosure (call=0x18f8cf4, op=0x18d2580,
>> arglist=0x18cfb50, rho=0x18f61ac, suppliedenv=0x181d200) at
>> ../../../../R-2.3.0/src/main/eval.c:581
>> #16 0x0109d634 in Rf_eval (e=0x18f8cf4, rho=0x18f61ac) at
>> ../../../../R-2.3.0/src/main/eval.c:422
>> #17 0x0109d66c in Rf_eval (e=0x18d2894, rho=0x18d293c) at
>> ../../../../R-2.3.0/src/main/eval.c:370
>> #18 0x0109d938 in Rf_eval (e=0x1826b18, rho=0x18d293c) at
>> ../../../../R-2.3.0/src/main/eval.c:357
>> #19 0x0109f93c in do_begin (call=0x1a37720, op=0x180a0cc,
>> args=0x1a38f2c, rho=0x18d293c) at
>> ../../../../R-2.3.0/src/main/eval.c:1067
>> #20 0x0109d798 in Rf_eval (e=0x1a37720, rho=0x18d293c) at
>> ../../../../R-2.3.0/src/main/eval.c:391
>> #21 0x0109d798 in Rf_eval (e=0x1a37800, rho=0x18d293c) at
>> ../../../../R-2.3.0/src/main/eval.c:391
>> #22 0x0109f93c in do_begin (call=0x1a37838, op=0x180a0cc,
>> args=0x1a3781c, rho=0x18d293c) at
>> ../../../../R-2.3.0/src/main/eval.c:1067
>> #23 0x0109d798 in Rf_eval (e=0x1a37838, rho=0x18d293c) at
>> ../../../../R-2.3.0/src/main/eval.c:391
>> #24 0x010a0d34 in Rf_applyClosure (call=0x18f8cbc, op=0x1a378c4,
>> arglist=0x18d28b0, rho=0x18f61ac, suppliedenv=0x181d200) at
>> ../../../../R-2.3.0/src/main/eval.c:581
>> #25 0x0109d634 in Rf_eval (e=0x18f8cbc, rho=0x18f61ac) at
>> ../../../../R-2.3.0/src/main/eval.c:422
>> #26 0x0109f87c in do_set (call=0x18f8c68, op=0x180a190,
>> args=0x18f8c84, rho=0x18f61ac) at
>> ../../../../R-2.3.0/src/main/eval.c:1303
>> #27 0x0109d798 in Rf_eval (e=0x18f8c68, rho=0x18f61ac) at
>> ../../../../R-2.3.0/src/main/eval.c:391
>> #28 0x0109f93c in do_begin (call=0x18f88e8, op=0x180a0cc,
>> args=0x18f8c4c, rho=0x18f61ac) at
>> ../../../../R-2.3.0/src/main/eval.c:1067
>> #29 0x0109d798 in Rf_eval (e=0x18f88e8, rho=0x18f61ac) at
>> ../../../../R-2.3.0/src/main/eval.c:391
>> #30 0x0109d798 in Rf_eval (e=0x18f9724, rho=0x18f61ac) at
>> ../../../../R-2.3.0/src/main/eval.c:391
>> #31 0x0109f93c in do_begin (call=0x18f94d8, op=0x180a0cc,
>> args=0x18f9708, rho=0x18f61ac) at
>> ../../../../R-2.3.0/src/main/eval.c:1067
>> #32 0x0109d798 in Rf_eval (e=0x18f94d8, rho=0x18f61ac) at
>> ../../../../R-2.3.0/src/main/eval.c:391
>> #33 0x0109d798 in Rf_eval (e=0x18fa350, rho=0x18f61ac) at
>> ../../../../R-2.3.0/src/main/eval.c:391
>> #34 0x0109f93c in do_begin (call=0x18fa174, op=0x180a0cc,
>> args=0x18fa334, rho=0x18f61ac) at
>> ../../../../R-2.3.0/src/main/eval.c:1067
>> #35 0x0109d798 in Rf_eval (e=0x18fa174, rho=0x18f61ac) at
>> ../../../../R-2.3.0/src/main/eval.c:391
>> #36 0x010a0074 in do_for (call=0x18fa104, op=0x1808958,
>> args=0x18fa120, rho=0x18f61ac) at
>> ../../../../R-2.3.0/src/main/eval.c:963
>> #37 0x0109d798 in Rf_eval (e=0x18fa104, rho=0x18f61ac) at
>> ../../../../R-2.3.0/src/main/eval.c:391
>> #38 0x0109f93c in do_begin (call=0x18fb2fc, op=0x180a0cc,
>> args=0x18fa0e8, rho=0x18f61ac) at
>> ../../../../R-2.3.0/src/main/eval.c:1067
>> #39 0x0109d798 in Rf_eval (e=0x18fb2fc, rho=0x18f61ac) at
>> ../../../../R-2.3.0/src/main/eval.c:391
>> #40 0x010a0d34 in Rf_applyClosure (call=0x1910b18, op=0x18fbf5c,
>> arglist=0x18f6120, rho=0x190c0cc, suppliedenv=0x181d200) at
>> ../../../../R-2.3.0/src/main/eval.c:581
>> #41 0x0109d634 in Rf_eval (e=0x1910b18, rho=0x190c0cc) at
>> ../../../../R-2.3.0/src/main/eval.c:422
>> #42 0x0109f87c in do_set (call=0x1910ac4, op=0x180a190,
>> args=0x1910ae0, rho=0x190c0cc) at
>> ../../../../R-2.3.0/src/main/eval.c:1303
>> #43 0x0109d798 in Rf_eval (e=0x1910ac4, rho=0x190c0cc) at
>> ../../../../R-2.3.0/src/main/eval.c:391
>> #44 0x0109d798 in Rf_eval (e=0x1910a38, rho=0x190c0cc) at
>> ../../../../R-2.3.0/src/main/eval.c:391
>> #45 0x0109f93c in do_begin (call=0x19161ac, op=0x180a0cc,
>> args=0x1910a00, rho=0x190c0cc) at
>> ../../../../R-2.3.0/src/main/eval.c:1067
>> #46 0x0109d798 in Rf_eval (e=0x19161ac, rho=0x190c0cc) at
>> ../../../../R-2.3.0/src/main/eval.c:391
>> #47 0x010a0d34 in Rf_applyClosure (call=0x19376ec, op=0x1916c30,
>> arglist=0x190cd2c, rho=0x192e698, suppliedenv=0x181d200) at
>> ../../../../R-2.3.0/src/main/eval.c:581
>> #48 0x0109d634 in Rf_eval (e=0x19376ec, rho=0x192e698) at
>> ../../../../R-2.3.0/src/main/eval.c:422
>> #49 0x0109f93c in do_begin (call=0x19374bc, op=0x180a0cc,
>> args=0x19376d0, rho=0x192e698) at
>> ../../../../R-2.3.0/src/main/eval.c:1067
>> #50 0x0109d798 in Rf_eval (e=0x19374bc, rho=0x192e698) at
>> ../../../../R-2.3.0/src/main/eval.c:391
>> #51 0x0109d798 in Rf_eval (e=0x1937414, rho=0x192e698) at
>> ../../../../R-2.3.0/src/main/eval.c:391
>> #52 0x0109f93c in do_begin (call=0x19373dc, op=0x180a0cc,
>> args=0x19373f8, rho=0x192e698) at
>> ../../../../R-2.3.0/src/main/eval.c:1067
>> #53 0x0109d798 in Rf_eval (e=0x19373dc, rho=0x192e698) at
>> ../../../../R-2.3.0/src/main/eval.c:391
>> #54 0x0109d798 in Rf_eval (e=0x1938eb4, rho=0x192e698) at
>> ../../../../R-2.3.0/src/main/eval.c:391
>> #55 0x0109f93c in do_begin (call=0x193ceec, op=0x180a0cc,
>> args=0x1938e98, rho=0x192e698) at
>> ../../../../R-2.3.0/src/main/eval.c:1067
>> #56 0x0109d798 in Rf_eval (e=0x193ceec, rho=0x192e698) at
>> ../../../../R-2.3.0/src/main/eval.c:391
>> #57 0x010a0d34 in Rf_applyClosure (call=0x193dd64, op=0x193c85c,
>> arglist=0x192e4d8, rho=0x181d1e4, suppliedenv=0x181d200) at
>> ../../../../R-2.3.0/src/main/eval.c:581
>> #58 0x0109d634 in Rf_eval (e=0x193dd64, rho=0x181d1e4) at
>> ../../../../R-2.3.0/src/main/eval.c:422
>> #59 0x010bcdac in Rf_ReplIteration (rho=0x181d1e4, savestack=0,
>> browselevel=18992200, state=0xbffff068) at
>> ../../../../R-2.3.0/src/main/main.c:254
>> #60 0x010bd0e0 in R_ReplConsole (rho=0x181d1e4, savestack=0,
>> browselevel=0) at ../../../../R-2.3.0/src/main/main.c:302
>> #61 0x010bd3f8 in run_Rmainloop () at ../../../../R-2.3.0/src/main/main.c:905
>> #62 0x00002cd8 in main (ac=1598899539, av=0xbfff2a03) at
>> ../../../../R-2.3.0/src/main/Rmain.c:33
>>
>> platform       powerpc-apple-darwin8.6.0
>> arch           powerpc
>> os             darwin8.6.0
>> system         powerpc, darwin8.6.0
>> status
>> major          2
>> minor          3.0
>> year           2006
>> month          04
>> day            24
>> svn rev        37909
>> language       R
>> version.string Version 2.3.0 (2006-04-24)
>>
>> http://ggobi.org/r/ is currently returning a 403 Forbidden header, but
>> it shouldn't segfault (not a high priority either, though)
>>
>> Regards,
>>
>> Hadley
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pinard at iro.umontreal.ca  Tue May  9 15:17:05 2006
From: pinard at iro.umontreal.ca (=?iso-8859-1?Q?Fran=E7ois?= Pinard)
Date: Tue, 9 May 2006 09:17:05 -0400
Subject: [Rd] "Unfelicity" :-) with edit()
In-Reply-To: <445FEF2C.5000800@stats.uwo.ca>
References: <20060509010355.GA25342@alcyon.progiciels-bpi.ca>
	<445FEF2C.5000800@stats.uwo.ca>
Message-ID: <20060509131705.GA3969@alcyon.progiciels-bpi.ca>

[Duncan Murdoch]

>I'll fix it.

Thanks, Duncan.  While I quite understand that more serious work should 
be done within real sources files, fixing and editing is still useful 
for quick, evanescent interactive toying.

>edit() is a hack, so you should expect problems.  You're better off 
>keeping your source in an editor and using source() to get it.

This is not the first time I read such a remark.  Maybe it would be 
worth a note within ?edit.

>There is no way it could preserve the environment of a function [...]

That might be worth another note within ?edit.

Speaking of which, this "x <- edit()" usage (interactively suggested by 
fix when it fails to re-parse the result of edition) is not covered by 
?edit.  I mean that by reading ?edit, one does not get information about 
what a mere "edit()" does.  It might be useful that ?edit says a few 
words about this particular usage.

The remaining of this message quotes the original message:

[Fran?ois Pinard]
>Hi, people.  This is about R 2.3.0 under Linux.

>It seems that edit() may change a function environment.  Here is 
>a transcript, more comments follow:

>======================================================================>
>>fix(f)

>>f
>function ()
>{
>}

>>fix(f)
>Erreur dans edit(name, file, title, editor) :
>         une erreur s'est produite ? la ligne 3
>  utilisez une commande du genre
>  x <- edit()
>  pour corriger

>>f <- edit()

>>f
>function ()
>{
>}
><environment: base>
>======================================================================<

>The initial ``fix(f)`` called an editor, which I exited right away.  For 
>the second ``fix(f)``, I used the editor for adding a slash between 
>braces, and exited.  The French comment produced by R speaks about an 
>error at line 3 and suggests using something like ``x <- edit()`` to 
>make a correction.  On the third call to the editor, I remove the slash 
>and exit.  Now, the environment of the function became "base".

>This has unfortunate effects when editing a more substantial function, 
>because for example, "stats" or "utils" is not readily available anymore 
>after the editing.  Is it reasonable to suggest an improvement in the 
>mechanics of edit(), for alleviating this drawback ?

-- 
Fran?ois Pinard   http://pinard.progiciels-bpi.ca


From murdoch at stats.uwo.ca  Tue May  9 15:31:12 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 09 May 2006 09:31:12 -0400
Subject: [Rd] "Unfelicity" :-) with edit()
In-Reply-To: <20060509131705.GA3969@alcyon.progiciels-bpi.ca>
References: <20060509010355.GA25342@alcyon.progiciels-bpi.ca>
	<445FEF2C.5000800@stats.uwo.ca>
	<20060509131705.GA3969@alcyon.progiciels-bpi.ca>
Message-ID: <446099A0.1000309@stats.uwo.ca>

On 5/9/2006 9:17 AM, Fran?ois Pinard wrote:
> [Duncan Murdoch]
> 
>>I'll fix it.
> 
> Thanks, Duncan.  While I quite understand that more serious work should 
> be done within real sources files, fixing and editing is still useful 
> for quick, evanescent interactive toying.
> 
>>edit() is a hack, so you should expect problems.  You're better off 
>>keeping your source in an editor and using source() to get it.
> 
> This is not the first time I read such a remark.  Maybe it would be 
> worth a note within ?edit.
> 
>>There is no way it could preserve the environment of a function [...]
> 
> That might be worth another note within ?edit.
> 
> Speaking of which, this "x <- edit()" usage (interactively suggested by 
> fix when it fails to re-parse the result of edition) is not covered by 
> ?edit.  I mean that by reading ?edit, one does not get information about 
> what a mere "edit()" does.  It might be useful that ?edit says a few 
> words about this particular usage.

Yes, it probably would be.  Just to clarify:  fix(f) *does* preserve the 
environment of f, but

fix(f) # introduce a syntax error
f <- edit()

does not.

Duncan Murdoch

> 
> The remaining of this message quotes the original message:
> 
> [Fran?ois Pinard]
>>Hi, people.  This is about R 2.3.0 under Linux.
> 
>>It seems that edit() may change a function environment.  Here is 
>>a transcript, more comments follow:
> 
>>======================================================================>
>>>fix(f)
> 
>>>f
>>function ()
>>{
>>}
> 
>>>fix(f)
>>Erreur dans edit(name, file, title, editor) :
>>         une erreur s'est produite ? la ligne 3
>>  utilisez une commande du genre
>>  x <- edit()
>>  pour corriger
> 
>>>f <- edit()
> 
>>>f
>>function ()
>>{
>>}
>><environment: base>
>>======================================================================<
> 
>>The initial ``fix(f)`` called an editor, which I exited right away.  For 
>>the second ``fix(f)``, I used the editor for adding a slash between 
>>braces, and exited.  The French comment produced by R speaks about an 
>>error at line 3 and suggests using something like ``x <- edit()`` to 
>>make a correction.  On the third call to the editor, I remove the slash 
>>and exit.  Now, the environment of the function became "base".
> 
>>This has unfortunate effects when editing a more substantial function, 
>>because for example, "stats" or "utils" is not readily available anymore 
>>after the editing.  Is it reasonable to suggest an improvement in the 
>>mechanics of edit(), for alleviating this drawback ?
>


From hin-tak.leung at cimr.cam.ac.uk  Tue May  9 18:49:29 2006
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Tue, 09 May 2006 17:49:29 +0100
Subject: [Rd] suppressing "global" cppflags in an individual package
In-Reply-To: <9294B498-A4DB-47B1-AE99-71C1559EABB3@stat.berkeley.edu>
References: <9294B498-A4DB-47B1-AE99-71C1559EABB3@stat.berkeley.edu>
Message-ID: <4460C819.6090407@cimr.cam.ac.uk>

Kasper Daniel Hansen wrote:
> Hi
> 
> I can use PKG_CPPFLAGS in a Makevars file to add additional flags to  
> the c++ compiler for a given package. Is it possible to remove flags  
> passed to the packages from R. Eg: say R have been compiled with -O2  
> and I want the package to be compiled with another optimization level?

Do you mean the flags passed to the c++ compiler (CXXFLAGS) or
to the C proprocessor (CPPFLAGS)? Do not confuse the two.

I think the "proper" way would be to write a full makefile.
(there are plenty of examples on CRAN).

Now, out of curiosity - why would you want to do that? The actual 
difference in CPU time usage is often small (10%?), so unless the
package triggers a compiler bug at specific optimization level and
gets mis-compiled, it is probably not worth the trouble. And if
the package is that sensitive to optimization level and can get 
mis-compiled, one of them (the package or the compiler) needs fixing.

HTL


From khansen at stat.Berkeley.EDU  Tue May  9 19:11:47 2006
From: khansen at stat.Berkeley.EDU (Kasper Daniel Hansen)
Date: Tue, 9 May 2006 10:11:47 -0700
Subject: [Rd] suppressing "global" cppflags in an individual package
In-Reply-To: <4460C819.6090407@cimr.cam.ac.uk>
References: <9294B498-A4DB-47B1-AE99-71C1559EABB3@stat.berkeley.edu>
	<4460C819.6090407@cimr.cam.ac.uk>
Message-ID: <8315342E-192B-4BF4-86BC-8F947769530E@stat.Berkeley.EDU>


On May 9, 2006, at 9:49 AM, Hin-Tak Leung wrote:

> Kasper Daniel Hansen wrote:
>> Hi
>> I can use PKG_CPPFLAGS in a Makevars file to add additional flags  
>> to  the c++ compiler for a given package. Is it possible to remove  
>> flags  passed to the packages from R. Eg: say R have been compiled  
>> with -O2  and I want the package to be compiled with another  
>> optimization level?
>
> Do you mean the flags passed to the c++ compiler (CXXFLAGS) or
> to the C proprocessor (CPPFLAGS)? Do not confuse the two.

Hmm good point. I think I have indeed confused the two.

> I think the "proper" way would be to write a full makefile.
> (there are plenty of examples on CRAN).

I would like to avoid this, see below.

> Now, out of curiosity - why would you want to do that? The actual  
> difference in CPU time usage is often small (10%?), so unless the
> package triggers a compiler bug at specific optimization level and
> gets mis-compiled, it is probably not worth the trouble. And if
> the package is that sensitive to optimization level and can get mis- 
> compiled, one of them (the package or the compiler) needs fixing.

It is indeed the case that after updating to GCC 4 the package gets  
broken using -O2. I agree this needs to be fixed, but the error  
(which I believe I have kind of localized, but not really understood)  
stems from a C++ library we have little control over, so it would be  
nice to have a fix for the time being that does not require a  
reinstallation of R - especially since we actually have users who  
currently (or soon will be) testing it. I was thus looking for a  
temporary quick fix allowing me to disable the optimization level,  
while I take the time to fix it properly.

Kurt Hornik have replied of-list that it is possible to do so using a  
~/.R/Makevars file (which I have not had the time to test  
unfortunately), but reading your comment about CPPFLAGS and CXXFLAGS  
makes me think I can indeed override it using the package Makevars  
file. The flags I was passing to the compiler were library locations  
anyway which was for the preprocessor.

Thanks for the help, Kasper


> HTL


From roebuck at mdanderson.org  Tue May  9 21:15:39 2006
From: roebuck at mdanderson.org (Paul Roebuck)
Date: Tue, 9 May 2006 14:15:39 -0500 (CDT)
Subject: [Rd] YA S4 method dispatch question
Message-ID: <Pine.OSF.4.58.0605091347380.485682@wotan.mdacc.tmc.edu>

I recently encountered this and was wondering if someone
could explain what happened. Basis of question involves
what the difference between the calls makes as the end
result is the same:

> identical(matrix(1:8, nrow = 1), array(1:8, c(1, 8)))
TRUE

If I run the code below as shown, I get the following:

> foo(1:8, 4)
foo (vector, numeric)
	 val = 4
foo (matrix, ANY)
	 val = 500
foo (matrix, numeric)
	 val = 500
[1] 500 500 500 500 500 500 500 500

Exchanging the current return for one of the commented ones
(HERE) yields the expected answer:

> foo(1:8, 4)
foo (vector, numeric)
	 val = 4
foo (matrix, numeric)
	 val = 4
[1] 4 4 4 4 4 4 4 4


When invoked with array(), it loses track of the second
parameter and gives the wrong answer. While it would seem
to have something to do with the first parameter's
evaluation time, I don't follow why one works and the other
doesn't. Forcing the evaluation via assignment (third case)
also provides the correct result.

Example code follows:


##------------------------------------------------------------------------------
library(methods)

setGeneric("foo",
           function(x, val = 500) {
               standardGeneric("foo")
           })

setMethod("foo",
          signature(x = "vector", val = "numeric"),
          function(x, val) {
              cat(match.call()[[1]], "(vector, numeric)", "\n")
              cat("\t", "val =", val, "\n")
## HERE ##
#              return(drop(callGeneric(matrix(x, nrow = 1), val)))
              return(drop(callGeneric(array(x, c(1, length(x)), val))))
#              return(drop(callGeneric(xm <- array(x, c(1, length(x))), val)))
          })

setMethod("foo",
          signature(x = "vector"),
          function(x, val) {
              cat(match.call()[[1]], "(vector, ANY)", "\n")
              callGeneric(x, val)
          })

setMethod("foo",
          signature(x = "matrix", val = "numeric"),
          function(x, val) {
              cat(match.call()[[1]], "(matrix, numeric)", "\n")
              cat("\t", "val =", val, "\n")
              return(apply(x, c(1, 2), function(m, v) { m <- v }, val))
          })

setMethod("foo",
          signature(x = "matrix"),
          function(x, val) {
              cat(match.call()[[1]], "(matrix, ANY)", "\n")
              cat("\t", "val =", val, "\n")
              callGeneric(x, val)
          })

setMethod("foo",
          signature(x = "array"),
          function(x, val) {
              cat(match.call()[[1]], "(array, ANY)", "\n")
              stop(sprintf("method not defined for %s argument",
data.class(x)))
          })

setMethod("foo",
          signature(x = "ANY"),
          function(x, val) {
              cat(match.call()[[1]], "(ANY, ANY)", "\n")
              stop(sprintf("method not defined for %s argument",
data.class(x)))
          })

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)


From simon.urbanek at r-project.org  Tue May  9 23:49:48 2006
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 9 May 2006 17:49:48 -0400
Subject: [Rd] suppressing "global" cppflags in an individual package
In-Reply-To: <8315342E-192B-4BF4-86BC-8F947769530E@stat.Berkeley.EDU>
References: <9294B498-A4DB-47B1-AE99-71C1559EABB3@stat.berkeley.edu>
	<4460C819.6090407@cimr.cam.ac.uk>
	<8315342E-192B-4BF4-86BC-8F947769530E@stat.Berkeley.EDU>
Message-ID: <B99D44A2-42C4-4BAA-828D-F7A6DEE648CE@r-project.org>

On May 9, 2006, at 1:11 PM, Kasper Daniel Hansen wrote:

> It is indeed the case that after updating to GCC 4 the package  
> gets  broken using -O2. I agree this needs to be fixed, but the error
> [...]
> unfortunately), but reading your comment about CPPFLAGS and  
> CXXFLAGS makes me think I can indeed override it using the package  
> Makevars file. The flags I was passing to the compiler were library  
> locations anyway which was for the preprocessor.
>

AFAIR you cannot override CPPFLAGS/CXXFLAGS in Makevars, because it  
gets included first. You can, however, use something like this:

all: $(SHLIB)

MYCFLAGS=-O0

%.o: %.c
         $(CC) $(ALL_CPPFLAGS) $(ALL_CFLAGS) $(MYCFLAGS) -c $< -o $@

for C, or for C++ accordingly:

%.o: %.cc
         $(CXX) $(ALL_CPPFLAGS) $(ALL_CXXFLAGS) $(MYCXXFLAGS) -c $< - 
o $@

However, don't ask me how portable this is ;). It exploits the fact  
that old-style rules .c.o used by Makeconf are overridden by the new- 
style rules regardless of their position. Nevertheless, you could  
still use specific rules if desired without a full-blown Makefile. (I  
always recommend the use of Makevars as far as possible, because most  
writers of Makefiles get the shlib compilation wrong).

Cheers,
Simon


From murdoch at stats.uwo.ca  Wed May 10 00:41:09 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 09 May 2006 18:41:09 -0400
Subject: [Rd] RFC:  log='z' for image, contour, persp?
Message-ID: <44611A85.8090605@stats.uwo.ca>

I've been thinking of adding the possibility of including "z" among the 
axes to be logged in image, contour, and persp.  In the first two, it 
would only affect where the breaks were set if they are calculated 
automatically; it would have a bigger effect in persp.

For example,

image(x, y, z, log="z")

would set 12 colours evenly spaced on a log scale of the z values.  (12 
because that's the default).

We already support

image(x, y, z, log="x")

to scale the x axis (though there's a spurious warning; I'll fix that).

image(z, log="x")

fails because it tries to take a log of zero.

Does it seem like a good idea for these 3D functions to support log="z" 
the way 2D functions do?

Duncan Murdoch


From mtmorgan at fhcrc.org  Wed May 10 05:43:33 2006
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Tue, 09 May 2006 20:43:33 -0700
Subject: [Rd] YA S4 method dispatch question
In-Reply-To: <Pine.OSF.4.58.0605091347380.485682@wotan.mdacc.tmc.edu> (Paul
	Roebuck's message of "Tue, 9 May 2006 14:15:39 -0500 (CDT)")
References: <Pine.OSF.4.58.0605091347380.485682@wotan.mdacc.tmc.edu>
Message-ID: <6phy7xaczoa.fsf@gopher3.fhcrc.org>

You won't like this ...;)

return(drop(callGeneric(array(x,
                              c(1, length(x)),
                              val)
                        )))

i.e., 'val' is inside 'array'!

I was discouraged from answering sooner by the complexity of your
example; simplifying it might have provided an immediate answer...

> x <- 1:8
> foo(array(x, c(1,length(x)), val)
+ 

! Martin




Paul Roebuck <roebuck at mdanderson.org> writes:

> I recently encountered this and was wondering if someone
> could explain what happened. Basis of question involves
> what the difference between the calls makes as the end
> result is the same:
>
>> identical(matrix(1:8, nrow = 1), array(1:8, c(1, 8)))
> TRUE
>
> If I run the code below as shown, I get the following:
>
>> foo(1:8, 4)
> foo (vector, numeric)
> 	 val = 4
> foo (matrix, ANY)
> 	 val = 500
> foo (matrix, numeric)
> 	 val = 500
> [1] 500 500 500 500 500 500 500 500
>
> Exchanging the current return for one of the commented ones
> (HERE) yields the expected answer:
>
>> foo(1:8, 4)
> foo (vector, numeric)
> 	 val = 4
> foo (matrix, numeric)
> 	 val = 4
> [1] 4 4 4 4 4 4 4 4
>
>
> When invoked with array(), it loses track of the second
> parameter and gives the wrong answer. While it would seem
> to have something to do with the first parameter's
> evaluation time, I don't follow why one works and the other
> doesn't. Forcing the evaluation via assignment (third case)
> also provides the correct result.
>
> Example code follows:
>
>
> ##------------------------------------------------------------------------------
> library(methods)
>
> setGeneric("foo",
>            function(x, val = 500) {
>                standardGeneric("foo")
>            })
>
> setMethod("foo",
>           signature(x = "vector", val = "numeric"),
>           function(x, val) {
>               cat(match.call()[[1]], "(vector, numeric)", "\n")
>               cat("\t", "val =", val, "\n")
> ## HERE ##
> #              return(drop(callGeneric(matrix(x, nrow = 1), val)))
>               return(drop(callGeneric(array(x, c(1, length(x)), val))))
> #              return(drop(callGeneric(xm <- array(x, c(1, length(x))), val)))
>           })
>
> setMethod("foo",
>           signature(x = "vector"),
>           function(x, val) {
>               cat(match.call()[[1]], "(vector, ANY)", "\n")
>               callGeneric(x, val)
>           })
>
> setMethod("foo",
>           signature(x = "matrix", val = "numeric"),
>           function(x, val) {
>               cat(match.call()[[1]], "(matrix, numeric)", "\n")
>               cat("\t", "val =", val, "\n")
>               return(apply(x, c(1, 2), function(m, v) { m <- v }, val))
>           })
>
> setMethod("foo",
>           signature(x = "matrix"),
>           function(x, val) {
>               cat(match.call()[[1]], "(matrix, ANY)", "\n")
>               cat("\t", "val =", val, "\n")
>               callGeneric(x, val)
>           })
>
> setMethod("foo",
>           signature(x = "array"),
>           function(x, val) {
>               cat(match.call()[[1]], "(array, ANY)", "\n")
>               stop(sprintf("method not defined for %s argument",
> data.class(x)))
>           })
>
> setMethod("foo",
>           signature(x = "ANY"),
>           function(x, val) {
>               cat(match.call()[[1]], "(ANY, ANY)", "\n")
>               stop(sprintf("method not defined for %s argument",
> data.class(x)))
>           })
>
> ----------------------------------------------------------
> SIGSIG -- signature too long (core dumped)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Jani.Erola at tukkk.fi  Wed May 10 08:19:53 2006
From: Jani.Erola at tukkk.fi (Jani.Erola at tukkk.fi)
Date: Wed, 10 May 2006 08:19:53 +0200 (CEST)
Subject: [Rd] R, Rcmdr crash on WinXP PRO laptop (PR#8583)
Message-ID: <20060510061953.A0BF219A56@slim.kubism.ku.dk>

 
I think I might have a workaround now. Originally I had all the scripts
on my desktop, so I came to think about if the problem is with the
shortcuts to the other programs or to My computer or something like
that. I put all the scripts to a folder which is still on my desktop,
and I haven't experienced any crashes since. My best guess is that it is
an explorer/graphics card related issue.

JE


From brainmaps at gmail.com  Wed May 10 09:12:07 2006
From: brainmaps at gmail.com (Shawn Mikula)
Date: Wed, 10 May 2006 00:12:07 -0700
Subject: [Rd] R, Rcmdr crash on WinXP PRO laptop (PR#8583)
Message-ID: <7a68883e0605100012s78f2ae73tfdcd01bd90f3cd78@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060510/d63e6ff9/attachment.pl 

From maechler at stat.math.ethz.ch  Wed May 10 10:23:15 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 10 May 2006 10:23:15 +0200
Subject: [Rd] RFC:  log='z' for image, contour, persp?
In-Reply-To: <44611A85.8090605@stats.uwo.ca>
References: <44611A85.8090605@stats.uwo.ca>
Message-ID: <17505.41715.206150.888328@stat.math.ethz.ch>

>>>>> "Duncan" == Duncan Murdoch <murdoch at stats.uwo.ca>
>>>>>     on Tue, 09 May 2006 18:41:09 -0400 writes:

    Duncan> I've been thinking of adding the possibility of
    Duncan> including "z" among the axes to be logged in image,
    Duncan> contour, and persp.  In the first two, it would only
    Duncan> affect where the breaks were set if they are
    Duncan> calculated automatically; it would have a bigger
    Duncan> effect in persp.

    Duncan> For example,

    Duncan> image(x, y, z, log="z")

    Duncan> would set 12 colours evenly spaced on a log scale of
    Duncan> the z values.  (12 because that's the default).

    Duncan> We already support

    Duncan> image(x, y, z, log="x")

    Duncan> to scale the x axis (though there's a spurious
    Duncan> warning; I'll fix that).

    Duncan> image(z, log="x")

    Duncan> fails because it tries to take a log of zero.

    Duncan> Does it seem like a good idea for these 3D functions
    Duncan> to support log="z" the way 2D functions do?

Yes, I think it's a good idea.

You forgot to mention   filled.contour()
which is  image() + "color - legend"
For that one, it would be particularly useful to automatically
get a "evenly space in log-scale" one.

    Duncan> Duncan Murdoch

Note that for things like the above, I have added
a simple function lseq() in package 'sfsmisc' -- which I have
contemplated moving to R.  Maybe this could happen at the same
time and you could make use of it for the above.

Martin


From Robert.McGehee at geodecapital.com  Tue May  9 18:58:58 2006
From: Robert.McGehee at geodecapital.com (Robert.McGehee at geodecapital.com)
Date: Tue,  9 May 2006 18:58:58 +0200 (CEST)
Subject: [Rd] Typo in getAllMethods() (PR#8848)
Message-ID: <20060509165858.E441BC04D@slim.kubism.ku.dk>

This is a multi-part message in MIME format.

------_=_NextPart_001_01C67389.C6480D9F
Content-Type: text/plain;
	charset="us-ascii"
Content-Transfer-Encoding: quoted-printable

The function getAllMethods in the methods package uses the non-existent
function packageName where I believe the function getPackageName was
intended.=20

For example:

> getAllMethods("formula")
Error in sprintf(gettext(fmt, domain =3D domain), ...) :=20
	could not find function "packageName"

The patch to RMethodUtils.R is here:

  238c238
<           warning(gettextf("'%s' from '%s' is a non-generic function;
no methods available", f, packageName(gwhere)), domain =3D NA)
---
>           warning(gettextf("'%s' from '%s' is a non-generic function;
no methods available", f, getPackageName(gwhere)), domain =3D NA) =20

> R.version
               _                        =20
platform       i386-pc-mingw32          =20
arch           i386                     =20
os             mingw32                  =20
system         i386, mingw32            =20
status                                  =20
major          2                        =20
minor          3.0                      =20
year           2006                     =20
month          04                       =20
day            24                       =20
svn rev        37909                    =20
language       R                        =20
version.string Version 2.3.0 (2006-04-24)

Robert McGehee
Quantitative Analyst
Geode Capital Management, LLC
53 State Street, 5th Floor | Boston, MA | 02109
Tel: 617/392-8396    Fax:617/476-6389
mailto:robert.mcgehee at geodecapital.com



> This e-mail, and any attachments hereto, are intended for use by the
> addressee(s) only and may contain information that is (i) confidential
> information of Geode Capital Management, LLC and/or its affiliates,
> and/or (ii) proprietary information of Geode Capital Management, LLC
> and/or its affiliates. If you are not the intended recipient of this
> e-mail, or if you have otherwise received this e-mail in error, please
> immediately notify me by telephone (you may call collect), or by
> e-mail, and please permanently delete the original, any print outs and
> any copies of the foregoing. Any dissemination, distribution or
> copying of this e-mail is strictly prohibited.=20
>=20

------_=_NextPart_001_01C67389.C6480D9F
Content-Type: text/html;
	charset="us-ascii"
Content-Transfer-Encoding: quoted-printable

<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
<HEAD>
<META HTTP-EQUIV=3D"Content-Type" CONTENT=3D"text/html; =
charset=3Dus-ascii">
<META NAME=3D"Generator" CONTENT=3D"MS Exchange Server version =
6.0.6617.90">
<TITLE>Typo in getAllMethods()</TITLE>
</HEAD>
<BODY>
<!-- Converted from text/rtf format -->

<P><FONT SIZE=3D2 FACE=3D"Courier New">The function getAllMethods in the =
methods package uses the non-existent function packageName where I =
believe the function getPackageName was intended. </FONT></P>

<P><FONT SIZE=3D2 FACE=3D"Courier New">For example:</FONT>
</P>

<P><FONT SIZE=3D2 FACE=3D"Courier New">&gt; =
getAllMethods(&quot;formula&quot;)</FONT>

<BR><FONT SIZE=3D2 FACE=3D"Courier New">Error in sprintf(gettext(fmt, =
domain =3D domain), ...) : </FONT>

<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <FONT SIZE=3D2 =
FACE=3D"Courier New">could not find function =
&quot;packageName&quot;</FONT>
</P>

<P><FONT SIZE=3D2 FACE=3D"Courier New">The patch to RMethodUtils.R is =
here:</FONT>
</P>

<P><FONT SIZE=3D2 FACE=3D"Courier New">&nbsp; 238c238</FONT>

<BR><FONT SIZE=3D2 FACE=3D"Courier =
New">&lt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; =
warning(gettextf(&quot;'%s' from '%s' is a non-generic function; no =
methods available&quot;, f, packageName(gwhere)), domain =3D =
NA)</FONT></P>

<P><FONT SIZE=3D2 FACE=3D"Courier New">---</FONT>

<BR><FONT SIZE=3D2 FACE=3D"Courier =
New">&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; =
warning(gettextf(&quot;'%s' from '%s' is a non-generic function; no =
methods available&quot;, f, getPackageName(gwhere)), domain =3D =
NA)&nbsp; </FONT></P>

<P><FONT SIZE=3D2 FACE=3D"Courier New">&gt; R.version</FONT>

<BR><FONT SIZE=3D2 FACE=3D"Courier =
New">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&n=
bsp;&nbsp;&nbsp; =
_&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; =
</FONT>

<BR><FONT SIZE=3D2 FACE=3D"Courier =
New">platform&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; =
i386-pc-mingw32&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbs=
p; </FONT>

<BR><FONT SIZE=3D2 FACE=3D"Courier =
New">arch&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; =
i386&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nb=
sp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </FONT>

<BR><FONT SIZE=3D2 FACE=3D"Courier =
New">os&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=
&nbsp; =
mingw32&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </FONT>

<BR><FONT SIZE=3D2 FACE=3D"Courier =
New">system&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; i386, =
mingw32&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=
&nbsp; </FONT>

<BR><FONT SIZE=3D2 FACE=3D"Courier =
New">status&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&n=
bsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nb=
sp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; =
</FONT>

<BR><FONT SIZE=3D2 FACE=3D"Courier =
New">major&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; =
2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; =
</FONT>

<BR><FONT SIZE=3D2 FACE=3D"Courier =
New">minor&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; =
3.0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbs=
p;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </FONT>

<BR><FONT SIZE=3D2 FACE=3D"Courier =
New">year&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; =
2006&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nb=
sp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </FONT>

<BR><FONT SIZE=3D2 FACE=3D"Courier =
New">month&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; =
04&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp=
;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; =
</FONT>

<BR><FONT SIZE=3D2 FACE=3D"Courier =
New">day&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp=
; =
24&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp=
;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; =
</FONT>

<BR><FONT SIZE=3D2 FACE=3D"Courier New">svn =
rev&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; =
37909&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&n=
bsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </FONT>

<BR><FONT SIZE=3D2 FACE=3D"Courier =
New">language&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; =
R&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; =
</FONT>

<BR><FONT SIZE=3D2 FACE=3D"Courier New">version.string Version 2.3.0 =
(2006-04-24)</FONT>
</P>

<P><B><FONT SIZE=3D2 FACE=3D"Arial">Robert McGehee</FONT></B>

<BR><FONT SIZE=3D2 FACE=3D"Arial">Quantitative Analyst</FONT>

<BR><FONT SIZE=3D2 FACE=3D"Arial">Geode Capital Management, LLC</FONT>

<BR><FONT SIZE=3D2 FACE=3D"Arial">53 State Street, 5<SUP>th</SUP> Floor =
| Boston, MA | 02109</FONT>

<BR><FONT SIZE=3D2 FACE=3D"Arial">Tel: 617/392-8396&nbsp;&nbsp;&nbsp; =
Fax:617/476-6389</FONT>

<BR><A HREF=3D"mailto:robert.mcgehee at geodecapital.com"><U><FONT =
COLOR=3D"#0000FF" SIZE=3D2 =
FACE=3D"Arial">mailto:robert.mcgehee at geodecapital.com</FONT></U></A>
</P>
<BR>
<BR>

<P><B><I><FONT COLOR=3D"#808080" SIZE=3D1 FACE=3D"Verdana">This e-mail, =
and any attachments hereto, are intended for use by the addressee(s) =
only and may contain information that is (i) confidential information of =
Geode Capital Management, LLC and/or its affiliates, and/or (ii) =
proprietary information of Geode Capital Management, LLC and/or its =
affiliates. If you are not the intended recipient of this e-mail, or if =
you have otherwise received this e-mail in error, please immediately =
notify me by telephone (you may call collect), or by e-mail, and please =
permanently delete the original, any print outs and any copies of the =
foregoing. Any dissemination, distribution or copying of this e-mail is =
strictly prohibited.</FONT></I></B><I></I> </P>

</BODY>
</HTML>
------_=_NextPart_001_01C67389.C6480D9F--


From h.wickham at gmail.com  Wed May 10 11:58:07 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Wed, 10 May 2006 11:58:07 +0200
Subject: [Rd] Warning: use of NULL environment is deprecated (in R CMD check)
Message-ID: <f8e6ff050605100258p6a7ed22bye939abfba2176c64@mail.gmail.com>

* checking S3 generic/method consistency ... WARNING
Warning: use of NULL environment is deprecated
Warning: use of NULL environment is deprecated
See section 'Generic functions and methods' of the 'Writing R Extensions'
manual.

I don't get any other warnings or errors.  Can anyone suggest what the
problem might be? (R2.3.0, OS X)

Thanks,

Hadley


From hin-tak.leung at cimr.cam.ac.uk  Wed May 10 12:56:11 2006
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Wed, 10 May 2006 11:56:11 +0100
Subject: [Rd] suppressing "global" cppflags in an individual package
In-Reply-To: <8315342E-192B-4BF4-86BC-8F947769530E@stat.Berkeley.EDU>
References: <9294B498-A4DB-47B1-AE99-71C1559EABB3@stat.berkeley.edu>
	<4460C819.6090407@cimr.cam.ac.uk>
	<8315342E-192B-4BF4-86BC-8F947769530E@stat.Berkeley.EDU>
Message-ID: <4461C6CB.7040602@cimr.cam.ac.uk>

Kasper Daniel Hansen wrote:
<snipped>
> It is indeed the case that after updating to GCC 4 the package gets 
> broken using -O2. I agree this needs to be fixed, but the error (which I 
> believe I have kind of localized, but not really understood) stems from 
> a C++ library we have little control over, so it would be nice to have a 
> fix for the time being that does not require a reinstallation of R - 
> especially since we actually have users who currently (or soon will be) 
> testing it. I was thus looking for a temporary quick fix allowing me to 
> disable the optimization level, while I take the time to fix it properly.
> 
> Kurt Hornik have replied of-list that it is possible to do so using a 
> ~/.R/Makevars file (which I have not had the time to test 
> unfortunately), but reading your comment about CPPFLAGS and CXXFLAGS 
> makes me think I can indeed override it using the package Makevars file. 
> The flags I was passing to the compiler were library locations anyway 
> which was for the preprocessor.

Can't do that with Makevars, because its defines are included first (and 
get overriden by R's built-time flags later in the command line), as 
Simon on the list has pointed out.

If it is a one-off operation, you can be slightly barbaric and just
record all the operations done by R CMD SHLIB/INSTALL
e.g. piping them to a file with >& , edit the file manually and exec
the operations by "sh file", then copy the differently-built shared
library over by hand, over-writing the broken one. Not very elegant,
but it will buy you some time until either the compiler or the package 
get fixed.

Hin-Tak Leung


From murdoch at stats.uwo.ca  Wed May 10 13:17:46 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 10 May 2006 07:17:46 -0400
Subject: [Rd] RFC:  log='z' for image, contour, persp?
In-Reply-To: <17505.41715.206150.888328@stat.math.ethz.ch>
References: <44611A85.8090605@stats.uwo.ca>
	<17505.41715.206150.888328@stat.math.ethz.ch>
Message-ID: <4461CBDA.7060706@stats.uwo.ca>

On 5/10/2006 4:23 AM, Martin Maechler wrote:
>>>>>> "Duncan" == Duncan Murdoch <murdoch at stats.uwo.ca>
>>>>>>     on Tue, 09 May 2006 18:41:09 -0400 writes:
> 
>     Duncan> I've been thinking of adding the possibility of
>     Duncan> including "z" among the axes to be logged in image,
>     Duncan> contour, and persp.  In the first two, it would only
>     Duncan> affect where the breaks were set if they are
>     Duncan> calculated automatically; it would have a bigger
>     Duncan> effect in persp.
> 
>     Duncan> For example,
> 
>     Duncan> image(x, y, z, log="z")
> 
>     Duncan> would set 12 colours evenly spaced on a log scale of
>     Duncan> the z values.  (12 because that's the default).
> 
>     Duncan> We already support
> 
>     Duncan> image(x, y, z, log="x")
> 
>     Duncan> to scale the x axis (though there's a spurious
>     Duncan> warning; I'll fix that).
> 
>     Duncan> image(z, log="x")
> 
>     Duncan> fails because it tries to take a log of zero.
> 
>     Duncan> Does it seem like a good idea for these 3D functions
>     Duncan> to support log="z" the way 2D functions do?
> 
> Yes, I think it's a good idea.
> 
> You forgot to mention   filled.contour()
> which is  image() + "color - legend"
> For that one, it would be particularly useful to automatically
> get a "evenly space in log-scale" one.

Thanks for pointing that out.  This is a little tricky:  I think 
filled.contour would want evenly spaced contours, but use the axTicks() 
version of pretty labels on the legend; but contour() would probably 
want the contours themselves to be at nice round values.

It looks as though I'll need to think about adding a log=TRUE option to 
pretty(), to expose or duplicate the internal code that sets log axes. 
(axTicks is close, but I don't think it allows for automatic computation 
of axp[3]).

Duncan
> 
>     Duncan> Duncan Murdoch
> 
> Note that for things like the above, I have added
> a simple function lseq() in package 'sfsmisc' -- which I have
> contemplated moving to R.  Maybe this could happen at the same
> time and you could make use of it for the above.
> 
> Martin
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch at stats.uwo.ca  Wed May 10 13:22:50 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 10 May 2006 07:22:50 -0400
Subject: [Rd] Warning: use of NULL environment is deprecated (in R CMD
 check)
In-Reply-To: <f8e6ff050605100258p6a7ed22bye939abfba2176c64@mail.gmail.com>
References: <f8e6ff050605100258p6a7ed22bye939abfba2176c64@mail.gmail.com>
Message-ID: <4461CD0A.20705@stats.uwo.ca>

On 5/10/2006 5:58 AM, hadley wickham wrote:
> * checking S3 generic/method consistency ... WARNING
> Warning: use of NULL environment is deprecated
> Warning: use of NULL environment is deprecated
> See section 'Generic functions and methods' of the 'Writing R Extensions'
> manual.
> 
> I don't get any other warnings or errors.  Can anyone suggest what the
> problem might be? (R2.3.0, OS X)

I'd guess you're using a pre-release version of 2.3.0.  If that's not 
it, then it may be an error in your package, using envir=NULL some place 
you shouldn't (but that doesn't explain why the error arose where it did).

If neither of those apply, I'd like to try to duplicate the error. 
Could you send me a tarball of the package?

Duncan Murdoch


From roebuck at mdanderson.org  Wed May 10 13:28:43 2006
From: roebuck at mdanderson.org (Paul Roebuck)
Date: Wed, 10 May 2006 06:28:43 -0500 (CDT)
Subject: [Rd] array dimname argument (was Re: YA S4 method dispatch question)
In-Reply-To: <6phy7xaczoa.fsf@gopher3.fhcrc.org>
References: <Pine.OSF.4.58.0605091347380.485682@wotan.mdacc.tmc.edu>
	<6phy7xaczoa.fsf@gopher3.fhcrc.org>
Message-ID: <Pine.OSF.4.58.0605100454070.519265@wotan.mdacc.tmc.edu>

On Tue, 9 May 2006, Martin Morgan wrote:

> You won't like this ...;)
>
> return(drop(callGeneric(array(x,
>                               c(1, length(x)),
>                               val)
>                         )))
>
> i.e., 'val' is inside 'array'!
>
> I was discouraged from answering sooner by the complexity of your
> example; simplifying it might have provided an immediate answer...
>
> > x <- 1:8
> > foo(array(x, c(1,length(x)), val)
> +
>

Geez... I should have noticed that. Thanks for the catch.
I am rather surprised (never having tried it before) that
array() silently disregards my unintentional dimname
argument.

> x <- 1:8
> matrix(x, 1, length(x), dimnames = "argument used")
Error in matrix(x, 1, dimnames = "argument used") :
	'dimnames' must be a list
> array(x, c(1, length(x)), "argument silently ignored")
     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]
[1,]    1    2    3    4    5    6    7    8
> array
function (data = NA, dim = length(data), dimnames = NULL)
{
    data <- as.vector(data)
    vl <- prod(dim)
    if (length(data) != vl) {
        if (vl > .Machine$integer.max)
            stop("'dim' specifies too large an array")
        data <- rep(data, length.out = vl)
    }
    if (length(dim))
        dim(data) <- dim
    if (is.list(dimnames) && length(dimnames)) ##HERE##
        dimnames(data) <- dimnames
    data
}
<environment: namespace:base>

The matrix method performs no check prior to assigning
dimnames. Why doesn't array function the same way?

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)


From h.wickham at gmail.com  Wed May 10 13:43:21 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Wed, 10 May 2006 13:43:21 +0200
Subject: [Rd] Warning: use of NULL environment is deprecated (in R CMD
	check)
In-Reply-To: <f8e6ff050605100258p6a7ed22bye939abfba2176c64@mail.gmail.com>
References: <f8e6ff050605100258p6a7ed22bye939abfba2176c64@mail.gmail.com>
Message-ID: <f8e6ff050605100443r7d09309dr595ef3022bf8481@mail.gmail.com>

> I don't get any other warnings or errors.  Can anyone suggest what the
> problem might be? (R2.3.0, OS X)

For reference: the problem was caused by having dependent packages
that been installed prior to R 2.3.0.

Hadley


From pinard at iro.umontreal.ca  Wed May 10 20:16:52 2006
From: pinard at iro.umontreal.ca (=?iso-8859-1?Q?Fran=E7ois?= Pinard)
Date: Wed, 10 May 2006 14:16:52 -0400
Subject: [Rd] Mere chat on vectorisation matters
Message-ID: <20060510181652.GA15816@phenix.sram.qc.ca>

Hi, people.  Allow me to chat a tiny bit on two vectorisation-related 
matters, in the context of R.  I'm curious about if the following ideas 
have ever been considered, and rejected already.

First is about using the so-called Duff's device for partially unrolling 
loops.  I did not overly check in R sources, and am not familiar with 
them anyway, but the only usage I saw is within "src/gnuwin32/malloc.c".  
Maybe it could be put to good usage in "src/main/arithmetic.c" and 
elsewhere.  Second is about what is called "chaining" on some vector 
computers, in which one vector operation uses, as an operand, the result 
of another vector operation, even before that result is sent for 
register or memory storage; R could use this technique for sparing 
memory, when it "knows" that the result is going to be discarded anyway.

I used and abused Duff's device a good while ago, when I was working
in computer graphics; it was routinely used to speed up image-wide 
operations.  With a few properly devised C pre-processor macros, it was 
made easy to use (I thrown mine away a few years ago, recognizing I lost 
interest in low-level coding matters, the macros could easily be 
rethought anyway).  Questions existed at the time about unrolled loops 
fitting or not within specialised fetch-next-instruction caches of some 
CPUs, but nowadays, memory caches are much bigger then they used to be, 
I have the prejudice it is just not a problem anymore.  Maybe more of 
a concern might be the conditionals implementing vector recycling 
(already hidden in macros), as they may disrupt the speed of merely 
falling through linear code.  One might probably do without jumps using 
clever masking operations, yet I wonder how far we would safely 
benchmark at configuration time to decide best code to generate, and how 
good C would be to write masked conditionals.  I'm not familiar enough 
with modern CPUs to judge if this really needs to be addressed or not.

I would not doubt that hardware chaining is worth all the efforts the 
engineers put so the hardware recognises and activates it on the fly.  
Vectorised chaining implemented in software as a way to spare memory, 
may be much of a challenge, as it requires sort of half-compilation.  
One one hand, it might alleviate memory problems which are often the 
subject of discussions on R-help; through thrashing, going over real 
memory and into paging may considerably slow down an R application.  On 
the other hand, unless very carefully implemented, chaining overhead 
might slow down all non-thrashing applications, which is most of them.  
Nevertheless, being softer on memory requirements is already a concern 
in R, I vaguely remember having read that R "tries to prove" that 
a vector being modified will not needed anymore in its original form, 
and when the proof succeeds, the original vector gets modified without 
prior copying.  Chaining, despite difficult to implement, might be 
a significant further step, and so, be worth a discussion.

-- 
Fran?ois Pinard   http://pinard.progiciels-bpi.ca


From sfalcon at fhcrc.org  Wed May 10 21:52:14 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed, 10 May 2006 12:52:14 -0700
Subject: [Rd] What is callGeneric used for?
Message-ID: <m2u07xmzdd.fsf@ziti.local>

I've recently come across two pieces of code using calls to
callGeneric() inside the definition of a method.

In both cases, it appears to me that the callGeneric call could be
replaced with a "real" call to the generic, say foo(x) instead of
callGeneric(x) inside method foo.

My understanding from the docs is that when called with arguments, it
is just like calling the actual generic.  Clear enough, but what does
this provide that just calling the actual generic doesn't?

Similarly, when would one want to make the recursive call that results
from calling callGeneric with no args? 

Thanks,

+ seth


From henric.nilsson at statisticon.se  Wed May 10 22:20:27 2006
From: henric.nilsson at statisticon.se (henric.nilsson at statisticon.se)
Date: Wed, 10 May 2006 22:20:27 +0200 (CEST)
Subject: [Rd] Allowed quasibinomial links (PR#8851)
Message-ID: <20060510202027.E532F19B2A@slim.kubism.ku.dk>

Full_Name: Henric Nilsson
Version: 2.3.0 Patched (2006-05-09 r38014)
OS: Windows 2000 SP4
Submission from: (NULL) (83.253.9.137)


When supplying an unavailable link to `quasibinomial', the error message looks
strange. E.g.
> quasibinomial("x")
Error in quasibinomial("x") : 'x' link not available for quasibinomial family,
available links are "logit", ", ""probit" and "cloglog"
                          ^^^^^^^^
Clearly, something's missing. A quick peek in the code reveals that `log' is
allowed, but is missing from the above list.

Furthermore, shouldn't `quasibinomial' also allow the `cauchit' link?


From Darin.Perusich at cognigencorp.com  Wed May 10 22:32:19 2006
From: Darin.Perusich at cognigencorp.com (Darin Perusich)
Date: Wed, 10 May 2006 16:32:19 -0400
Subject: [Rd] 2.3.0 make install fails on solaris
Message-ID: <44624DD3.4080502@cognigencorp.com>

hello r development team,

i'm building R 2.3.0 on solaris and when i run the 'make install' i'm 
getting a syntax error during the "installing etc ..." which causes the 
installation to fail. i get this error whether i use gnu-make of 
sun-make, see the error and reasons below.

gmake[1]: Entering directory `/export/medusa/darin/build/R-2.3.0/etc'
installing etc ...
/bin/bash: -c: line 1: syntax error near unexpected token `;'
/bin/bash: -c: line 1: `for f in ; do  /opt/csw/bin/ginstall -c -m 644 
${f} "/export/home/darin/build/R-2.3.0/cswstage/opt/csw/lib/R/etc";  done'
gmake[1]: *** [install] Error 2
gmake[1]: Leaving directory `/export/medusa/darin/build/R-2.3.0/etc'
gmake: *** [install] Error 1

in etc/Makefile if i comment lines 60-62 make install continues without 
incident, here are those lines.

         @for f in $(EXPORTFILES); do \
           $(INSTALL_DATA) $${f} "$(rhome)/$(subdir)"; \
         done

this has changed from R-2.2.1.

diff etc/Makefile ../R-2.2.1/etc/Makefile"

60c52
<       @for f in $(EXPORTFILES); do \
---
 >       @for f in $(OBJECTS) $(EXPORTFILES); do \

should i open a bug for this issue? i'm also curious as to if this has 
come up on other platforms.

-- 
Darin Perusich
Unix Systems Administrator
Cognigen Corporation
395 Youngs Rd.
Williamsville, NY 14221
darinper at cognigencorp.com


From macq at llnl.gov  Wed May 10 22:58:38 2006
From: macq at llnl.gov (Don MacQueen)
Date: Wed, 10 May 2006 13:58:38 -0700
Subject: [Rd] RFC:  log='z' for image, contour, persp?
In-Reply-To: <44611A85.8090605@stats.uwo.ca>
References: <44611A85.8090605@stats.uwo.ca>
Message-ID: <p06210208c08804458f78@[128.115.153.6]>

Yes, it does. I've needed it more often than not.
-Don

At 6:41 PM -0400 5/9/06, Duncan Murdoch wrote:
>I've been thinking of adding the possibility of including "z" among the
>axes to be logged in image, contour, and persp.  In the first two, it
>would only affect where the breaks were set if they are calculated
>automatically; it would have a bigger effect in persp.
>
>For example,
>
>image(x, y, z, log="z")
>
>would set 12 colours evenly spaced on a log scale of the z values.  (12
>because that's the default).
>
>We already support
>
>image(x, y, z, log="x")
>
>to scale the x axis (though there's a spurious warning; I'll fix that).
>
>image(z, log="x")
>
>fails because it tries to take a log of zero.
>
>Does it seem like a good idea for these 3D functions to support log="z"
>the way 2D functions do?
>
>Duncan Murdoch
>
>______________________________________________
>R-devel at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA


From p.dalgaard at biostat.ku.dk  Wed May 10 23:44:33 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 10 May 2006 23:44:33 +0200
Subject: [Rd] 2.3.0 make install fails on solaris
In-Reply-To: <44624DD3.4080502@cognigencorp.com>
References: <44624DD3.4080502@cognigencorp.com>
Message-ID: <x23bfhk11a.fsf@turmalin.kubism.ku.dk>

Darin Perusich <Darin.Perusich at cognigencorp.com> writes:

> hello r development team,
> 
> i'm building R 2.3.0 on solaris and when i run the 'make install' i'm 
> getting a syntax error during the "installing etc ..." which causes the 
> installation to fail. i get this error whether i use gnu-make of 
> sun-make, see the error and reasons below.
> 
> gmake[1]: Entering directory `/export/medusa/darin/build/R-2.3.0/etc'
> installing etc ...
> /bin/bash: -c: line 1: syntax error near unexpected token `;'
> /bin/bash: -c: line 1: `for f in ; do  /opt/csw/bin/ginstall -c -m 644 
> ${f} "/export/home/darin/build/R-2.3.0/cswstage/opt/csw/lib/R/etc";  done'
> gmake[1]: *** [install] Error 2
> gmake[1]: Leaving directory `/export/medusa/darin/build/R-2.3.0/etc'
> gmake: *** [install] Error 1
> 
> in etc/Makefile if i comment lines 60-62 make install continues without 
> incident, here are those lines.
> 
>          @for f in $(EXPORTFILES); do \
>            $(INSTALL_DATA) $${f} "$(rhome)/$(subdir)"; \
>          done
> 
> this has changed from R-2.2.1.
> 
> diff etc/Makefile ../R-2.2.1/etc/Makefile"
> 
> 60c52
> <       @for f in $(EXPORTFILES); do \
> ---
>  >       @for f in $(OBJECTS) $(EXPORTFILES); do \
> 
> should i open a bug for this issue? i'm also curious as to if this has 
> come up on other platforms.

It only happens if your bash is old enough. I get the 

rubin:~/> for f in ; do echo $f ; done
bash: syntax error near unexpected token `;'
rubin:~/>help
GNU bash, version 2.05.0(1)-release (sparc-sun-solaris2.9)
for f in ; do echo $f ; done

but not on Linux boxes with bash 3.x. However, I don't think we assume
bash 3.x (or bash as such for that matter and sh has same issue on
Solaris 9), so it is indeed a bug.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From sfalcon at fhcrc.org  Thu May 11 02:16:49 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed, 10 May 2006 17:16:49 -0700
Subject: [Rd] S4 initialize methods, unexpected recursive callNextMethod
Message-ID: <m2lkt9l8jy.fsf@ziti.local>

Hi,

Given a simple three class hierarchy: A <-- B <-- C

I want to define an initialize method for each class such that when I
call new("C", x=5), the initialize methods for A and B are used to
incrementally build the object.

When I do what seems obvious to me using callNextMethod, I get an
infinite recursion.  An example follows...

setClass("A", representation(a="numeric"))
setClass("B", representation(b="numeric"), contains="A")
setClass("C", representation(c="numeric"), contains="B")

setMethod("initialize", signature(.Object="A"),
          function(.Object, x) {
              cat("in A\n")
              .Object at a <- x
              .Object
          })

setMethod("initialize", signature(.Object="B"),
          function(.Object, x) {
              cat("in B\n")
              .Object <- callNextMethod(.Object=.Object, x=x)
              .Object at b <- .Object at a + 1
              .Object
          })

setMethod("initialize", signature(.Object="C"),
          function(.Object, x) {
              cat("in C\n")
              .Object <- callNextMethod(.Object=.Object, x=x)
              .Object at c <- .Object at a + .Object at b + 1
              .Object
          })


## Works as I am expecting for B
> myB <- new("B", 4)
in B
in A

## When you create a C, the B method gets called but the appropriate
## next method info seems lost and we end up back in C's method ?!
> myC <- new("C", 5)
in C
in B
in C
in B
in C
  C-c C-c

Should this work?  Is there a better way to organize the initializers
for a simple hierarchy (perhaps assume that args to the initializers
are not the same for A, B, and C).

Thanks,

+ seth


From ggrothendieck at gmail.com  Thu May 11 03:29:46 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 10 May 2006 21:29:46 -0400
Subject: [Rd] What is callGeneric used for?
In-Reply-To: <m2u07xmzdd.fsf@ziti.local>
References: <m2u07xmzdd.fsf@ziti.local>
Message-ID: <971536df0605101829s41bc0f5bk7573ba595e82bf75@mail.gmail.com>

In the case of arithmetic methods you might not know or care
whether the generic is, say, + or -.

On 5/10/06, Seth Falcon <sfalcon at fhcrc.org> wrote:
> I've recently come across two pieces of code using calls to
> callGeneric() inside the definition of a method.
>
> In both cases, it appears to me that the callGeneric call could be
> replaced with a "real" call to the generic, say foo(x) instead of
> callGeneric(x) inside method foo.
>
> My understanding from the docs is that when called with arguments, it
> is just like calling the actual generic.  Clear enough, but what does
> this provide that just calling the actual generic doesn't?
>
> Similarly, when would one want to make the recursive call that results
> from calling callGeneric with no args?
>
> Thanks,
>
> + seth
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From khansen at stat.Berkeley.EDU  Thu May 11 06:37:01 2006
From: khansen at stat.Berkeley.EDU (Kasper Daniel Hansen)
Date: Wed, 10 May 2006 21:37:01 -0700
Subject: [Rd] suppressing "global" cppflags in an individual package
In-Reply-To: <B99D44A2-42C4-4BAA-828D-F7A6DEE648CE@r-project.org>
References: <9294B498-A4DB-47B1-AE99-71C1559EABB3@stat.berkeley.edu>
	<4460C819.6090407@cimr.cam.ac.uk>
	<8315342E-192B-4BF4-86BC-8F947769530E@stat.Berkeley.EDU>
	<B99D44A2-42C4-4BAA-828D-F7A6DEE648CE@r-project.org>
Message-ID: <7B99B6C0-B4AC-47D4-9912-9238585C5311@stat.Berkeley.EDU>

Thank you Simon, a little comment below

On May 9, 2006, at 2:49 PM, Simon Urbanek wrote:

> On May 9, 2006, at 1:11 PM, Kasper Daniel Hansen wrote:
>
>> It is indeed the case that after updating to GCC 4 the package  
>> gets  broken using -O2. I agree this needs to be fixed, but the error
>> [...]
>> unfortunately), but reading your comment about CPPFLAGS and  
>> CXXFLAGS makes me think I can indeed override it using the package  
>> Makevars file. The flags I was passing to the compiler were  
>> library locations anyway which was for the preprocessor.
>>
>
> AFAIR you cannot override CPPFLAGS/CXXFLAGS in Makevars, because it  
> gets included first. You can, however, use something like this:
>
> all: $(SHLIB)
>
> MYCFLAGS=-O0
>
> %.o: %.c
>         $(CC) $(ALL_CPPFLAGS) $(ALL_CFLAGS) $(MYCFLAGS) -c $< -o $@
>
> for C, or for C++ accordingly:
>
> %.o: %.cc
>         $(CXX) $(ALL_CPPFLAGS) $(ALL_CXXFLAGS) $(MYCXXFLAGS) -c $< - 
> o $@

Actually you do not need the all: line, and since I use .cpp as C++  
extension, all I needed was

%.o: %.cpp
<TAB>$(CXX) $(ALL_CPPFLAGS) -O0 -c $< -o $@

Note that I needed to delete the $(ALL_CXXFLAGS) which basically  
reads R's flags.

Now, is there any way to (in the Makevars file) operate on $ 
(ALL_CXXFLAGS), since all I want is to delete any -O* flag? Or is  
defining rules and variables all I can do?

Actually, where do I read about the Makevars syntax. Is it from  
autoconf (of which I only now the name). The section on it in R-exts  
is useful (hey, I managed to make one in the first place), but not  
comprehensive.

/Kasper


> However, don't ask me how portable this is ;). It exploits the fact  
> that old-style rules .c.o used by Makeconf are overridden by the  
> new-style rules regardless of their position. Nevertheless, you  
> could still use specific rules if desired without a full-blown  
> Makefile. (I always recommend the use of Makevars as far as  
> possible, because most writers of Makefiles get the shlib  
> compilation wrong).
>
> Cheers,
> Simon


From simon.urbanek at r-project.org  Thu May 11 09:21:59 2006
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 11 May 2006 03:21:59 -0400
Subject: [Rd] suppressing "global" cppflags in an individual package
In-Reply-To: <7B99B6C0-B4AC-47D4-9912-9238585C5311@stat.Berkeley.EDU>
References: <9294B498-A4DB-47B1-AE99-71C1559EABB3@stat.berkeley.edu>
	<4460C819.6090407@cimr.cam.ac.uk>
	<8315342E-192B-4BF4-86BC-8F947769530E@stat.Berkeley.EDU>
	<B99D44A2-42C4-4BAA-828D-F7A6DEE648CE@r-project.org>
	<7B99B6C0-B4AC-47D4-9912-9238585C5311@stat.Berkeley.EDU>
Message-ID: <38E1F480-172E-462C-AA72-B8AC37592946@r-project.org>

Kasper,

On May 11, 2006, at 12:37 AM, Kasper Daniel Hansen wrote:

> Thank you Simon, a little comment below
>
> On May 9, 2006, at 2:49 PM, Simon Urbanek wrote:
>
>> On May 9, 2006, at 1:11 PM, Kasper Daniel Hansen wrote:
>>
>>> It is indeed the case that after updating to GCC 4 the package  
>>> gets  broken using -O2. I agree this needs to be fixed, but the  
>>> error
>>> [...]
>>> unfortunately), but reading your comment about CPPFLAGS and  
>>> CXXFLAGS makes me think I can indeed override it using the  
>>> package Makevars file. The flags I was passing to the compiler  
>>> were library locations anyway which was for the preprocessor.
>>>
>>
>> AFAIR you cannot override CPPFLAGS/CXXFLAGS in Makevars, because  
>> it gets included first. You can, however, use something like this:
>>
>> all: $(SHLIB)
>>
>> MYCFLAGS=-O0
>>
>> %.o: %.c
>>         $(CC) $(ALL_CPPFLAGS) $(ALL_CFLAGS) $(MYCFLAGS) -c $< -o $@
>>
>> for C, or for C++ accordingly:
>>
>> %.o: %.cc
>>         $(CXX) $(ALL_CPPFLAGS) $(ALL_CXXFLAGS) $(MYCXXFLAGS) -c $<  
>> -o $@
>
> Actually you do not need the all: line, and since I use .cpp as C++  
> extension, all I needed was
>
> %.o: %.cpp
> <TAB>$(CXX) $(ALL_CPPFLAGS) -O0 -c $< -o $@
>

If it worked for you, fine ... but it doesn't for me (using plain  
SHLIB), because you're replacing the first target, the .so doesn't  
get built.

> Note that I needed to delete the $(ALL_CXXFLAGS) which basically  
> reads R's flags.
>

Well actually the point was that you *don't* need to do that and you  
should not. Most compilers (including gcc) ignore preceding  
conflicting flags, so -O3 -O0 will give you simply -O0 and that's  
what you wanted.

> Now, is there any way to (in the Makevars file) operate on $ 
> (ALL_CXXFLAGS), since all I want is to delete any -O* flag? Or is  
> defining rules and variables all I can do?
>

Yes. Again, I'm talking GNU make now, so I suspect this is not  
portable (so kids, don't do this at home), but you should be able to use

MYCXXFLAGS=$(filter-out -O3,$(ALL_CXXFLAGS))

However as stated above I don't think you want to do that - just  
append -O0 and you're safe.

Cheers,
Simon


From ripley at stats.ox.ac.uk  Thu May 11 09:50:00 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 11 May 2006 08:50:00 +0100 (BST)
Subject: [Rd] 2.3.0 make install fails on solaris
In-Reply-To: <x23bfhk11a.fsf@turmalin.kubism.ku.dk>
References: <44624DD3.4080502@cognigencorp.com>
	<x23bfhk11a.fsf@turmalin.kubism.ku.dk>
Message-ID: <Pine.LNX.4.64.0605110848500.13084@gannet.stats.ox.ac.uk>

This is already changed in R-patched: please use that.

On Wed, 10 May 2006, Peter Dalgaard wrote:

> Darin Perusich <Darin.Perusich at cognigencorp.com> writes:
>
>> hello r development team,
>>
>> i'm building R 2.3.0 on solaris and when i run the 'make install' i'm
>> getting a syntax error during the "installing etc ..." which causes the
>> installation to fail. i get this error whether i use gnu-make of
>> sun-make, see the error and reasons below.
>>
>> gmake[1]: Entering directory `/export/medusa/darin/build/R-2.3.0/etc'
>> installing etc ...
>> /bin/bash: -c: line 1: syntax error near unexpected token `;'
>> /bin/bash: -c: line 1: `for f in ; do  /opt/csw/bin/ginstall -c -m 644
>> ${f} "/export/home/darin/build/R-2.3.0/cswstage/opt/csw/lib/R/etc";  done'
>> gmake[1]: *** [install] Error 2
>> gmake[1]: Leaving directory `/export/medusa/darin/build/R-2.3.0/etc'
>> gmake: *** [install] Error 1
>>
>> in etc/Makefile if i comment lines 60-62 make install continues without
>> incident, here are those lines.
>>
>>          @for f in $(EXPORTFILES); do \
>>            $(INSTALL_DATA) $${f} "$(rhome)/$(subdir)"; \
>>          done
>>
>> this has changed from R-2.2.1.
>>
>> diff etc/Makefile ../R-2.2.1/etc/Makefile"
>>
>> 60c52
>> <       @for f in $(EXPORTFILES); do \
>> ---
>> >       @for f in $(OBJECTS) $(EXPORTFILES); do \
>>
>> should i open a bug for this issue? i'm also curious as to if this has
>> come up on other platforms.
>
> It only happens if your bash is old enough. I get the
>
> rubin:~/> for f in ; do echo $f ; done
> bash: syntax error near unexpected token `;'
> rubin:~/>help
> GNU bash, version 2.05.0(1)-release (sparc-sun-solaris2.9)
> for f in ; do echo $f ; done
>
> but not on Linux boxes with bash 3.x. However, I don't think we assume
> bash 3.x (or bash as such for that matter and sh has same issue on
> Solaris 9), so it is indeed a bug.
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu May 11 12:24:37 2006
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Thu, 11 May 2006 12:24:37 +0200 (CEST)
Subject: [Rd] Allowed quasibinomial links (PR#8851)
Message-ID: <20060511102437.1E10419A66@slim.kubism.ku.dk>

This was already corrected in R-devel (including allowing cauchit): I have
moved the relevant part of the fix to R-patched now.

On Wed, 10 May 2006, henric.nilsson at statisticon.se wrote:

> Full_Name: Henric Nilsson
> Version: 2.3.0 Patched (2006-05-09 r38014)
> OS: Windows 2000 SP4
> Submission from: (NULL) (83.253.9.137)
>
>
> When supplying an unavailable link to `quasibinomial', the error message looks
> strange. E.g.
>> quasibinomial("x")
> Error in quasibinomial("x") : 'x' link not available for quasibinomial family,
> available links are "logit", ", ""probit" and "cloglog"
>                          ^^^^^^^^
> Clearly, something's missing. A quick peek in the code reveals that `log' is
> allowed, but is missing from the above list.
>
> Furthermore, shouldn't `quasibinomial' also allow the `cauchit' link?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu May 11 14:40:09 2006
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Thu, 11 May 2006 14:40:09 +0200 (CEST)
Subject: [Rd] (PR#8824) wishlist: summary for regression models to report
Message-ID: <20060511124009.676E41C917@slim.kubism.ku.dk>

  This message is in MIME format.  The first part should be readable text,
  while the remaining parts are likely unreadable without MIME-aware tools.

--27464147-1097610713-1146500823=:15100
Content-Type: TEXT/PLAIN; CHARSET=ISO-8859-1; FORMAT=flowed
Content-Transfer-Encoding: 8BIT
Content-ID: <Pine.LNX.4.64.0605100926211.14434 at gannet.stats.ox.ac.uk>

You are apparently unaware that 'na.action' is an argument to lm (which 
defaults to the value of an option), and need not only take the value 
'na.omit'.  Your request does not make sense for other possible 
'na.action's except 'na.exclude' (for example those which impute).

However, there is already a mechanism provided for giving a suitable 
message, naprint(), so all you need to do is to instruct the audience of 
your sermon how to make use of it.  You might do better to tell them to 
use na.action=na.fail (as S does and as I advise my students to do), and 
perhaps also to discuss developments in the field in the last 50 years.

For 2.4.0-to-be I have added a line of output in the print.summary.[g]lm 
methods that will add to the information on degrees of freedom based on 
naprint().

On Mon, 1 May 2006, groemping at tfh-berlin.de wrote:

> Full_Name: Ulrike Gr?mping
> Version: 2.3.0
> OS: Windows
> Submission from: (NULL) (84.190.150.205)
>
>
> Whenever any observations are excluded from a regression analysis (lm, 
> glm, and other similar procedures) because of missing values, I would 
> find it very useful if this fact is directly visible from the output. I 
> think that the information should not only be available (I can e.g. look 
> at length of the na.action element of the lm object) but that a serious 
> statistical software should draw users' attention to the fact that 
> observations have been excluded.

R is nothing like so dictatorial, but does already provide the tools for 
this viewpoint (as well as for others).

> For convenience, it would also be nice in general if the number of 
> observations used in the analysis is indicated (for lm it is of course 
> possible but a bit awkward to find this number in case of many 
> parameters).

(It is in fact very easy to find: see e.g. the code for logLik.lm.)

> I hope that this will be implemented because it is quite easy to do (as 
> far as I can see). It would make it easier for students and applied 
> researchers to comply with my preaching to always report on the number 
> of valid observations and the portion of values excluded for 
> missingness.

If you want something added to R, please be prepared to contribute a patch 
for it. (I believe you could have learned a lot from doing so, including 
about what is already provided.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595
--27464147-1097610713-1146500823=:15100--


From ripley at stats.ox.ac.uk  Thu May 11 15:18:45 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 11 May 2006 14:18:45 +0100 (BST)
Subject: [Rd] Question about match.fun()
In-Reply-To: <17504.18798.614739.269753@bossiaea.maths.uwa.edu.au>
References: <17504.18798.614739.269753@bossiaea.maths.uwa.edu.au>
Message-ID: <Pine.LNX.4.64.0605100934450.14434@gannet.stats.ox.ac.uk>

On Tue, 9 May 2006, Berwin A Turlach wrote:

> Dear all,
>
> I was recently contacted by a user about an alledged problem/bug in
> the latest version of lasso2.  After some investigation, we found out
> that it was a user error which boils down to the following:
>
>> x <- matrix(rnorm(200), ncol=2)
>> var <- "fred"
>> apply(x, 2, var)
> Error in get(x, envir, mode, inherits) : variable "fred" of mode "function" was not found
>
> only that the "offending" apply() command happened inside the gl1ce()
> function of lasso2.
>
> I was under the impression that R can now distinguish between
> variables and functions with the same name and, indeed, the following
> works:
>
>> var <- 2
>> apply(x, 2, var)
> [1] 1.053002 1.250875
>
> Poking a bit around, I guess that the ability to distinguish between
> variables and functions with the same name comes from the introduction
> of the function match.fun() and, after reading its help page, the

No, not really.  It comes in general from the internal C functions knowing 
from the context what they are looking for from the parse context.

> reasons why an error is triggered the first time but not the second
> time is perfectly clear to me.
>
> I wonder whether it would make sense to change match.fun() such that
> the first case does not result in an error?  I was thinking along the
> line that if the argument to match.fun() is a variable that contains a
> character vector of length one then, using get(), match.fun() attemps
> to find a function with that name.  If the get() command does not
> succeed, then a second try is made using the name of the variable
> passed by the caller to match.fun().

This is tricky, and indeed the bit that appears strange to me is that
the second works.  It comes from

r5628 | pd | 1999-08-26 14:31:42 +0100 (Thu, 26 Aug 1999) | 2 lines
match.fun fixes

which is not very informative, but I found e.g.

http://tolstoy.newcastle.edu.au/R/help/99b/0254.html
PD> This also applies (!) to various other places that need to deal
PD> with FUN arguments (apply, sapply, sweep, outer). It might be
PD> preferable to make match.fun smarter, at the expense of making it
PD> completely obscure.

(and I think we succeeded!)  The essence of that example would appear to 
be

xlev <-list(a=1:7, length=NULL)
sapply(xlev, is.null)

which failed long, long ago.

Note that ?apply (and so on) in 2.3.0 only mention the possibility of 
supplying a function or a character string.  Even the latter seems 
unnecessary these days now we have backquotes:

x <- matrix(runif(20), 10, 2)
apply(x, 2, `+`, 7)

I spent some time recently tidying up the family functions in R-devel. 
There the issues are similar but complicated by the fact that in 
binomial(probit) there is no object `probit'.

I've come to the view that we are trying too hard in many of these cases.
So I would like to see arguments why we need to allow more than

         function
         symbol
         length-one character vector.

and I don't see it lessens the confusion to allow the name of a length-one 
character vector to mean either the value of the first element of the 
object or a symbol if the value is not visible as a function.

> So before trying to modify match.fun() and submitting a patch, I
> wanted to ask whether such a change would be accepted?  Is there an
> argument that I don't see that the first case should always result in
> an error and not be silently resolved?

The main argument is that it is not as documented, and confusing.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jmc at r-project.org  Thu May 11 17:51:01 2006
From: jmc at r-project.org (John Chambers)
Date: Thu, 11 May 2006 11:51:01 -0400
Subject: [Rd] S4 initialize methods, unexpected recursive callNextMethod
In-Reply-To: <m2lkt9l8jy.fsf@ziti.local>
References: <m2lkt9l8jy.fsf@ziti.local>
Message-ID: <44635D65.50602@r-project.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060511/c2b0cf66/attachment.pl 

From daniel.oshea at dnr.state.mn.us  Thu May 11 19:31:00 2006
From: daniel.oshea at dnr.state.mn.us (daniel.oshea at dnr.state.mn.us)
Date: Thu, 11 May 2006 19:31:00 +0200 (CEST)
Subject: [Rd] bug report - cor (PR#8852)
Message-ID: <20060511173100.8E06A19B37@slim.kubism.ku.dk>

Full_Name: daniel t. O'Shea
Version: 2.2.1
OS: xp
Submission from: (NULL) (156.98.28.4)


using the cor command in the base package.

cor(x,y)

x is a matrix (15 rows and 1000 columns).  I did not specify a column and R
crashed - shut down.  

error signature
AppName:rgui.exe AppVer 2.21.51220.0
ModName: r.dll
ModVer: 2.21.51220.0


From ligges at statistik.uni-dortmund.de  Thu May 11 19:39:13 2006
From: ligges at statistik.uni-dortmund.de (ligges at statistik.uni-dortmund.de)
Date: Thu, 11 May 2006 19:39:13 +0200 (CEST)
Subject: [Rd] bug report - cor (PR#8852)
Message-ID: <20060511173913.0238D19B90@slim.kubism.ku.dk>

daniel.oshea at dnr.state.mn.us wrote:

> Full_Name: daniel t. O'Shea
> Version: 2.2.1

Please read how to report a bug:
Please check at least the latest release, which is R-2.3.0!


> OS: xp
> Submission from: (NULL) (156.98.28.4)
> 
> 
> using the cor command in the base package.
> 
> cor(x,y)
>

Please read how to report a bug:
Please specify reproducible examples!

Under R-2.3.0 the following works for me:

set.seed(1)
x <- y <- matrix(rnorm(15000), nrow=15)
res <- cor(x,y)


Uwe Ligges



> x is a matrix (15 rows and 1000 columns).  I did not specify a column and R
> crashed - shut down.  
>
> error signature
> AppName:rgui.exe AppVer 2.21.51220.0
> ModName: r.dll
> ModVer: 2.21.51220.0
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From fparlamis at mac.com  Thu May 11 20:53:56 2006
From: fparlamis at mac.com (Parlamis Franklin)
Date: Thu, 11 May 2006 08:53:56 -1000
Subject: [Rd] @ accesses attributes, not just formal slots ?
Message-ID: <C413B816-C6F7-498E-9145-7BB66AF5E921@mac.com>

Using the '@' operator, I am able to extract a 'names' attribute  
assigned to a formal object.
However, I can not use the replacement form ('@<-') to assign that  
attribute.

 > setClass("foo", representation("numeric"))
[1] "foo"
 > (new("foo", 1:4)->a)
An object of class ?foo?
[1] 1 2 3 4
 > names(a) <- LETTERS[1:4]
 > a at names
[1] "A" "B" "C" "D"
 > a at names <- LETTERS[5:8]
Error in checkSlotAssignment(object, name, value) :
	"names" is not a slot in class "foo"

I don't know that this asymmetry will ever cause a problem, but I  
just wanted to note it because it appears from the help pages
'slot {methods}'  and 'slotOp {base}' that the '@' operator is only  
intended to provide access to defined slots.

I am still on R 2.2.1.


From sfalcon at fhcrc.org  Thu May 11 20:56:51 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Thu, 11 May 2006 11:56:51 -0700
Subject: [Rd] S4 initialize methods, unexpected recursive callNextMethod
In-Reply-To: <44635D65.50602@r-project.org> (John Chambers's message of "Thu,
	11 May 2006 11:51:01 -0400")
References: <m2lkt9l8jy.fsf@ziti.local> <44635D65.50602@r-project.org>
Message-ID: <m21wv0jsp8.fsf@ziti.local>

John Chambers <jmc at r-project.org> writes:

> It's a bug resulting from the combination of:
>  1. multiple recursive levels of callNextMethod()
>  2. nonstandard arguments in the method definition; that is, (.Object,
>     x) vs .Object, ...) for the generic.

Thanks for the explanation and work around suggestion.  If I'm feeling
brave, perhaps I'll take a look at the addNextMethod and
callNextMethod computations.  We found this bug for a "real" use-case,
so I have some interest in a solution that doesn't involve changing
the initializers for the three classes involved...

Best,

+ seth


From ripley at stats.ox.ac.uk  Thu May 11 21:53:37 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 11 May 2006 20:53:37 +0100 (BST)
Subject: [Rd] @ accesses attributes, not just formal slots ?
In-Reply-To: <C413B816-C6F7-498E-9145-7BB66AF5E921@mac.com>
References: <C413B816-C6F7-498E-9145-7BB66AF5E921@mac.com>
Message-ID: <Pine.LNX.4.64.0605112046260.6541@gannet.stats.ox.ac.uk>

On Thu, 11 May 2006, Parlamis Franklin wrote:

> Using the '@' operator, I am able to extract a 'names' attribute
> assigned to a formal object.
> However, I can not use the replacement form ('@<-') to assign that
> attribute.
>
> > setClass("foo", representation("numeric"))
> [1] "foo"
> > (new("foo", 1:4)->a)
> An object of class ?foo?
> [1] 1 2 3 4
> > names(a) <- LETTERS[1:4]
> > a at names
> [1] "A" "B" "C" "D"
> > a at names <- LETTERS[5:8]
> Error in checkSlotAssignment(object, name, value) :
> 	"names" is not a slot in class "foo"
>
> I don't know that this asymmetry will ever cause a problem, but I
> just wanted to note it because it appears from the help pages
> 'slot {methods}'  and 'slotOp {base}' that the '@' operator is only
> intended to provide access to defined slots.

Yes, it is intended so.  It is a side effect of the current implementation 
that @ will also access attributes, but that may change.  Note that the
help page for @ says

      These operators support the formal classes of package 'methods'.
      See 'slot' for further details. Currently there is no checking
      that the object is an instance of a class.

so this should not come as a surprise to you.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pgilbert at bank-banque-canada.ca  Thu May 11 22:32:29 2006
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Thu, 11 May 2006 16:32:29 -0400
Subject: [Rd] PGI 6.1 compile error
Message-ID: <44639F5D.1080101@bank-banque-canada.ca>

I am trying to compile R-2.3.0 (both first release and patched 
2006-05-10) on Red Hat Enterprise Linux AS release 3 (Taroon Update 7) 
using the Portland Group compiler version 6.1 and the notes from 
Jennifer Lai on p33 of "R Installation and Administration" version 2.3.0 
(2006-04-24). I have not used this compiler before, so it is possible 
things are messed up more than usual, even for me.

Following  the R Installation and Administration notes I set
      export PGI=/usr/pgi/linux86-64/6.1
      export PATH=$PGI/bin:$PATH
      export MANPATH=$MANPATH=$PGI/man:/
      export CC=pgcc
      export CFLAGS="-g -O2 -Kieee"
      export CPPFLAGS="-I$PGI/include -I$PGI/include/CC"
      export F77=pgf77
      export FFLAGS="-g -O2 -Kieee"
      export CXX="pgCC"
      export CXXFLAGS="-g -O2 -Kieee"
      export F95=pgf95
      export FCFLAGS="-g -O2 -Kieee"
      export SHLIB_CXXLDFLAGS=-shared
      export SHLIB_LDFLAGS=-shared
      export LDFLAGS="-L$PGI/libso -L/usr/lib64"

However, the last line causes
:../../src/R-2.3.0-patched/configure
checking build system type... x86_64-unknown-linux-gnu
checking host system type... x86_64-unknown-linux-gnu
loading site script '../../src/R-2.3.0-patched/config.site'
....
checking for gcc... pgcc
checking for C compiler default output file name... a.out
checking whether the C compiler works... configure: error: cannot run C 
compiled programs.
If you meant to cross compile, use `--host'.
See `config.log' for more details.


Either unsetting  LDFLAGS, or setting it to  "-L/usr/lib64"

.../../src/R-2.3.0-patched/configure --x-libraries=/usr/X11R6/lib64
configures but I get

checking whether C99 double complex is supported...
checking complex.h usability... no
checking complex.h presence... yes
configure: WARNING: complex.h: present but cannot be compiled
configure: WARNING: complex.h:     check for missing prerequisite headers?
configure: WARNING: complex.h: see the Autoconf documentation
configure: WARNING: complex.h:     section "Present But Cannot Be Compiled"
configure: WARNING: complex.h: proceeding with the preprocessor's result
configure: WARNING: complex.h: in the future, the compiler will take 
precedence
configure: WARNING:     ## ----------------------------------- ##
configure: WARNING:     ## Report this to r-bugs at R-project.org ##
configure: WARNING:     ## ----------------------------------- ##
checking for complex.h... yes
checking for double complex... no
no
checking for cblas_cdotu_sub in vecLib framework... no
....
R is now configured for x86_64-unknown-linux-gnu

  Source directory:          ../../src/R-2.3.0-patched
  Installation directory:    /usr/local

  C compiler:                pgcc  -g -O2 -Kieee
  Fortran 77 compiler:       pgf77  -g -O2 -Kieee

  C++ compiler:              pgCC  -g -O2 -Kieee
  Fortran 90/95 compiler:    pgf95 -g -O2 -Kieee

  Interfaces supported:      X11, tcltk
  External libraries:        readline
  Additional capabilities:   PNG, JPEG, iconv, MBCS, NLS
  Options enabled:           R profiling

  Recommended packages:      yes

configure: WARNING: you cannot build info or html versions of the R manuals


However, when I make I get

....
pgcc -shared  -L/usr/lib64 -o tools.so text.o init.o Rmd5.o md5.o   
mkdir -p -- ../../../../library/tools/libs
make[5]: Leaving directory 
`/home/mfa/gilp/toolchain/R/mfa04559/R-2.3.0PGI/src/library/tools/src'
make[4]: Leaving directory 
`/home/mfa/gilp/toolchain/R/mfa04559/R-2.3.0PGI/src/library/tools/src'
**ERROR: in routine alloca() there is a
stack overflow: thread 0, max 10228KB, used 0KB, request 16B
make[3]: *** [all] Error 1
make[3]: Leaving directory 
`/home/mfa/gilp/toolchain/R/mfa04559/R-2.3.0PGI/src/library/tools'
make[2]: *** [R] Error 1
make[2]: Leaving directory 
`/home/mfa/gilp/toolchain/R/mfa04559/R-2.3.0PGI/src/library'
make[1]: *** [R] Error 1
make[1]: Leaving directory 
`/home/mfa/gilp/toolchain/R/mfa04559/R-2.3.0PGI/src'
make: *** [R] Error 1

Any help would be appreciated.

Paul Gilbert
====================================================================================

La version fran?aise suit le texte anglais.

------------------------------------------------------------------------------------

This email may contain privileged and/or confidential inform...{{dropped}}


From hojr-devel at stat.math.ethz.ch  Fri May 12 06:01:43 2006
From: hojr-devel at stat.math.ethz.ch (Natasha Scott)
Date: Thu, 11 May 2006 23:01:43 -0500
Subject: [Rd] Lfie Expirecene Deeergs
Message-ID: <1z08743r0619331851f664i0859xv63p4579r26k484s@129.132.145.15>

Thu, 11 May 2006 23:01:43 -0500

How are ya....

Knowledge is solving  problems no one else can.

Expand your knowledge get a De:gree in less then 2 weeks no study re:quired 1:0:0% verifiable

Bachel:ors, Maste:rs, MBA, and Doct:orate (PhD) Dip:loma!

Call us now 1-206-202-4570  24:hours a day 7:days a week 

 

 Get In Touch Soon
 
 Lee Fontenot


From jagat.k.sheth at citigroup.com  Fri May 12 14:44:02 2006
From: jagat.k.sheth at citigroup.com (Sheth, Jagat K)
Date: Fri, 12 May 2006 08:44:02 -0400
Subject: [Rd] X11 and vfonts modules on AIX 5.2
Message-ID: <FD2342224DDA68419F21B64CA7A47E7B44E288@EXNJMB30.nam.nsroot.net>


I am trying to get R-2.2.1 to pass make check on an AIX 5.2 at work (I know R-2.2.1 is not the latest release, but I encountered make errors in my attempts to install either R-2.3.0 or the R-patched_2006-05-10 on the version of AIX I am on. I will post those errors in a separate posting from this.)   

So far, configure and make finish without error for R-2.2.1 using gnu make, gcc-4.1.0, and 

CC=/usr/local/bin/gcc 
F77=/usr/local/bin/gfortran
CXX=/usr/local/bin/g++ 
MAIN_LDFLAGS=-Wl,-brtl 
SHLIB_LDFLAGS=-Wl,-G
CFLAGS='-g -O'
FFLAGS='-O'
CXXFLAGS='-g -O'

bash-3.00$ ./configure --disable-nls

...

R is now configured for powerpc-ibm-aix5.2.0.0

  Source directory:          .
  Installation directory:    /usr/local

  C compiler:                /usr/local/bin/gcc -mno-fp-in-toc -g -O
  C++ compiler:              /usr/local/bin/g++  -g -O
  Fortran compiler:          /usr/local/bin/gfortran  -O

  Interfaces supported:      X11
  External libraries:        readline
  Additional capabilities:   MBCS
  Options enabled:           R profiling

  Recommended packages:      yes


After make, I can run R-2.2.1 from its build directory but I get the following X11 module loading error when trying to plot
 

> plot(1:10)
  
Error in X11() : X11 module cannot be loaded
In addition: Warning message:
unable to load shared library '/home/js36954/src/R-2.2.1/modules/R_X11.so':
  rtld: 0712-001 Symbol log10 was referenced
      from module /home/js36954/src/R-2.2.1/modules/R_X11.so(), but a runtime definition of the symbol was not found.
rtld: 0712-001 Symbol floor was referenced
      from module /home/js36954/src/R-2.2.1/modules/R_X11.so(), but a runtime definition of the symbol was not found.
rtld: 0712-001 Symbol pow was referenced
      from module /home/js36954/src/R-2.2.1/modules/R_X11.so(), but a runtime definition of the symbol was not found.
rtld: 0712-001 Symbol sin was referenced
      from module /home/js36954/src/R-2.2.1/modules/R_X11.so(), but a runtime definition of the symbol was not found.
rtld: 0712-001 Symbol cos was referenced
      from module /home/js36954/src/R-2.2.1/modules/R_X11.so(), but a runtime definition of the symbol was not found.
rtld: 0712-001 Symbol tan was referenced
      from module /home/js36954/src/R-2.2.1/modules 

This error didn't occur for R-2.0.1 which passes make check using the above config.site settings on the same AIX 5.2. 

Searching the archives on R-devel for similar AIX problems, I tried a diff between the X11 makefiles for R-2.0.1 and R-2.2.1 

diff ~/src/R-2.0.1/src/modules/X11/Makefile ~/src/R-2.2.1/src/modules/X11/Makefile
54c54
<       $(SHLIB_LINK) -o $@ $(R_X11_la_LDFLAGS) $(R_X11_la_OBJECTS) $(R_X11_la_LIBADD) $(LIBS)
---

>     $(SHLIB_LINK) -o $@ $(R_X11_la_LDFLAGS) $(R_X11_la_OBJECTS) $(R_X11_la_LIBADD)
  

...

Adding $(LIBS) at the end of line 54 in the R-2.2.1 X11 makefile caused the loading error above to go away, but I don't know if this is what I should be doing ...

After editing that makefile, I was able to plot in R-2.2.1 but eventually encountered a similar error on the vfonts module during make check   


> Vf <- c("serif", "plain")
> text(4, 2, "\\#J2438\\#J2421\\#J2451\\#J2473", vfont = Vf)
  
Warning: unable to load shared library '/home/js36954/src/R-2.2.1/modules/vfonts.so':
  rtld: 0712-001 Symbol cos was referenced
      from module /home/js36954/src/R-2.2.1/modules/vfonts.so(), but a runtime definition
      of the symbol was not found.
rtld: 0712-001 Symbol sin was referenced
      from module /home/js36954/src/R-2.2.1/modules/vfonts.so(), but a runtime definition
      of the symbol was not found.
Error in text.default(4, 2, "\\#J2438\\#J2421\\#J2451\\#J2473", vfont = Vf) : 
    Hershey fonts cannot be loaded

A diff on the R-2.0.1 and R-2.2.1 vfonts module makefiles,
 
diff ~/src/R-2.0.1/src/modules/vfonts/Makefile ~/src/R-2.2.1/src/modules/vfonts/Makefile
51c51
<       $(SHLIB_LINK) -o $@ $(vfonts_la_LDFLAGS) $(vfonts_la_OBJECTS) $(vfonts_la_LIBADD) $(LIBS)
---

>     $(SHLIB_LINK) -o $@ $(vfonts_la_LDFLAGS) $(vfonts_la_OBJECTS) $(vfonts_la_LIBADD)
  

...

I added $(LIBS) at the end of the R-2.2.1 vfonts makefile, and the above error went away the next time I ran make check. 

So, where I am currently at is that I can get R-2.2.1 to pass make check on my AIX 5.2 with the above two makefile edits, but I am not sure how harmful that may be overall ... 

E.g. the plots I now get in R-2.2.1, after editing the X11 and vfonts makefiles, appear with darker axis labels and tick marks than in R-2.0.1, say.

Any advice to help clean things up would be greatly appreciated. I would be happy to provide any additional details.  

Thanks,
Jagat     




Jagat K. Sheth         1000 Technology Drive           
> Mortgage Analytics    Third Floor, Mail Station 55
> CitiMortgage, Inc.    O'Fallon, MO 63368-2240
> Tel:(636)261-1407     FAX:(636)261-1312
> 
> Email: jagat.k.sheth at citigroup.com
> 
> 
> 
> 
> 
>


From jagat.k.sheth at citigroup.com  Fri May 12 14:45:51 2006
From: jagat.k.sheth at citigroup.com (Sheth, Jagat K)
Date: Fri, 12 May 2006 08:45:51 -0400
Subject: [Rd] R-2.3.0 make error on AIX 5.2
Message-ID: <FD2342224DDA68419F21B64CA7A47E7B03E8768F@EXNJMB30.nam.nsroot.net>

I am encountering a make error on an AIX 5.2 with R-2.3.0 and R-patched_2006-05-10 after successfully configuring them using gcc-4.1.0, gnu make, and the following configure options
 
CC=/usr/local/bin/gcc 
F77=/usr/local/bin/gfortran
CXX=/usr/local/bin/g++ 
MAIN_LDFLAGS=-Wl,-brtl 
SHLIB_LDFLAGS=-Wl,-G
CFLAGS='-g -O'
FFLAGS='-O'
CXXFLAGS='-g -O'

bash-3.00$ ./configure --disable-nls

The gcc specs on this machine are 

bash-3.00$ /usr/local/bin/gcc -v
Using built-in specs.
Target: powerpc-ibm-aix5.2.0.0
Configured with: ../gcc-4.1.0/configure --disable-aix64 --disable-nls
Thread model: aix
gcc version 4.1.0

The make error from R-patched_2006-05-10 is 

make[4]: Entering directory `/sas/data/cmi/ma/data/js36954/src/R-patched/src/mod
ules/internet'
/usr/local/bin/gcc -I. -I../../../src/include -I../../../src/include -I/usr/loca
l/include -DHAVE_CONFIG_H -mno-fp-in-toc   -g -O  -c internet.c -o internet.o
internet.c: In function 'in_R_newurl':
internet.c:174: error: 'struct Rconn' has no member named 'open64'
make[4]: *** [internet.o] Error 1
make[4]: Leaving directory `/sas/data/cmi/ma/data/js36954/src/R-patched/src/modu
les/internet'
make[3]: *** [R] Error 2
make[3]: Leaving directory `/sas/data/cmi/ma/data/js36954/src/R-patched/src/modu
les/internet'
make[2]: *** [R] Error 1
make[2]: Leaving directory `/sas/data/cmi/ma/data/js36954/src/R-patched/src/modu
les'
make[1]: *** [R] Error 1
make[1]: Leaving directory `/sas/data/cmi/ma/data/js36954/src/R-patched/src'
make: *** [R] Error 1

I haven't encountered any make errors on this machine when building R-2.0.1 or R-2.2.1 (although the latter failed make check and didn't load the X11 and vfonts modules unless $(LIBS) was added to their makefiles as mentioned in a separate posting from this).

Any advice on the above would be greatly appreciated. I will be happy to provide other additional details.

Thanks,
Jagat  

Jagat K. Sheth         1000 Technology Drive           
> Mortgage Analytics    Third Floor, Mail Station 55
> CitiMortgage, Inc.    O'Fallon, MO 63368-2240
> Tel:(636)261-1407     FAX:(636)261-1312
> 
> Email: jagat.k.sheth at citigroup.com
> 
> 
> 
> 
> 
>


From bhs2 at mevik.net  Fri May 12 14:48:59 2006
From: bhs2 at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge_Mevik?=)
Date: Fri, 12 May 2006 14:48:59 +0200
Subject: [Rd] Dropping dimnames doesn't matter (anymore)?
Message-ID: <m08xp7cssk.fsf@bar.nemo-project.org>

In the "old days", one way of speeding up matrix calculations was to
drop the dimnames of the matrices prior to the calculations, i.e.,
dimnames(X) <- NULL.  I distinctly remember that this could have a
great impact at least in Splus 3.x (under UNIX/Linux).

I just did a small, informal test of this with a couple of functions I
use to fit plsr models, in R 2.3.0 (Linux).  It didn't seem to have
any effect at all (the functions actually ran a tiny bit slower,
probably due to the "dimnames(X) <- NULL" command).

Is the "general rule-of-thumb" with current R versions that the
overhead of keeping the dimnames through calculations is negligible?

-- 
Bj?rn-Helge Mevik


From ripley at stats.ox.ac.uk  Fri May 12 15:05:52 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 12 May 2006 14:05:52 +0100 (BST)
Subject: [Rd] R-2.3.0 make error on AIX 5.2
In-Reply-To: <FD2342224DDA68419F21B64CA7A47E7B03E8768F@EXNJMB30.nam.nsroot.net>
References: <FD2342224DDA68419F21B64CA7A47E7B03E8768F@EXNJMB30.nam.nsroot.net>
Message-ID: <Pine.LNX.4.64.0605121403500.21999@gannet.stats.ox.ac.uk>

We've seen something almost identical before.  Looks like fcntl is 
redefining open (and not open()).  At the top of the file is

#ifdef HAVE_FCNTL_H
# include <fcntl.h>
#endif

Insert

#undef open

in there.


On Fri, 12 May 2006, Sheth, Jagat K wrote:

> I am encountering a make error on an AIX 5.2 with R-2.3.0 and R-patched_2006-05-10 after successfully configuring them using gcc-4.1.0, gnu make, and the following configure options
>
> CC=/usr/local/bin/gcc
> F77=/usr/local/bin/gfortran
> CXX=/usr/local/bin/g++
> MAIN_LDFLAGS=-Wl,-brtl
> SHLIB_LDFLAGS=-Wl,-G
> CFLAGS='-g -O'
> FFLAGS='-O'
> CXXFLAGS='-g -O'
>
> bash-3.00$ ./configure --disable-nls
>
> The gcc specs on this machine are
>
> bash-3.00$ /usr/local/bin/gcc -v
> Using built-in specs.
> Target: powerpc-ibm-aix5.2.0.0
> Configured with: ../gcc-4.1.0/configure --disable-aix64 --disable-nls
> Thread model: aix
> gcc version 4.1.0
>
> The make error from R-patched_2006-05-10 is
>
> make[4]: Entering directory `/sas/data/cmi/ma/data/js36954/src/R-patched/src/mod
> ules/internet'
> /usr/local/bin/gcc -I. -I../../../src/include -I../../../src/include -I/usr/loca
> l/include -DHAVE_CONFIG_H -mno-fp-in-toc   -g -O  -c internet.c -o internet.o
> internet.c: In function 'in_R_newurl':
> internet.c:174: error: 'struct Rconn' has no member named 'open64'
> make[4]: *** [internet.o] Error 1
> make[4]: Leaving directory `/sas/data/cmi/ma/data/js36954/src/R-patched/src/modu
> les/internet'
> make[3]: *** [R] Error 2
> make[3]: Leaving directory `/sas/data/cmi/ma/data/js36954/src/R-patched/src/modu
> les/internet'
> make[2]: *** [R] Error 1
> make[2]: Leaving directory `/sas/data/cmi/ma/data/js36954/src/R-patched/src/modu
> les'
> make[1]: *** [R] Error 1
> make[1]: Leaving directory `/sas/data/cmi/ma/data/js36954/src/R-patched/src'
> make: *** [R] Error 1
>
> I haven't encountered any make errors on this machine when building R-2.0.1 or R-2.2.1 (although the latter failed make check and didn't load the X11 and vfonts modules unless $(LIBS) was added to their makefiles as mentioned in a separate posting from this).
>
> Any advice on the above would be greatly appreciated. I will be happy to provide other additional details.
>
> Thanks,
> Jagat
>
> Jagat K. Sheth         1000 Technology Drive
>> Mortgage Analytics    Third Floor, Mail Station 55
>> CitiMortgage, Inc.    O'Fallon, MO 63368-2240
>> Tel:(636)261-1407     FAX:(636)261-1312
>>
>> Email: jagat.k.sheth at citigroup.com
>>
>>
>>
>>
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Fri May 12 15:13:58 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 12 May 2006 14:13:58 +0100 (BST)
Subject: [Rd] X11 and vfonts modules on AIX 5.2
In-Reply-To: <FD2342224DDA68419F21B64CA7A47E7B44E288@EXNJMB30.nam.nsroot.net>
References: <FD2342224DDA68419F21B64CA7A47E7B44E288@EXNJMB30.nam.nsroot.net>
Message-ID: <Pine.LNX.4.64.0605121411050.22390@gannet.stats.ox.ac.uk>

I think rather you want to add $(LIBM) to the end of ...la_LIBADD.

We've seen things like this before, but OTOH people have succeeded in 
building R-2.2.1 on AIX 5.2/3.

On Fri, 12 May 2006, Sheth, Jagat K wrote:

>
> I am trying to get R-2.2.1 to pass make check on an AIX 5.2 at work (I know R-2.2.1 is not the latest release, but I encountered make errors in my attempts to install either R-2.3.0 or the R-patched_2006-05-10 on the version of AIX I am on. I will post those errors in a separate posting from this.)
>
> So far, configure and make finish without error for R-2.2.1 using gnu make, gcc-4.1.0, and
>
> CC=/usr/local/bin/gcc
> F77=/usr/local/bin/gfortran
> CXX=/usr/local/bin/g++
> MAIN_LDFLAGS=-Wl,-brtl
> SHLIB_LDFLAGS=-Wl,-G
> CFLAGS='-g -O'
> FFLAGS='-O'
> CXXFLAGS='-g -O'
>
> bash-3.00$ ./configure --disable-nls
>
> ...
>
> R is now configured for powerpc-ibm-aix5.2.0.0
>
>  Source directory:          .
>  Installation directory:    /usr/local
>
>  C compiler:                /usr/local/bin/gcc -mno-fp-in-toc -g -O
>  C++ compiler:              /usr/local/bin/g++  -g -O
>  Fortran compiler:          /usr/local/bin/gfortran  -O
>
>  Interfaces supported:      X11
>  External libraries:        readline
>  Additional capabilities:   MBCS
>  Options enabled:           R profiling
>
>  Recommended packages:      yes
>
>
> After make, I can run R-2.2.1 from its build directory but I get the following X11 module loading error when trying to plot
>
>
>> plot(1:10)
>
> Error in X11() : X11 module cannot be loaded
> In addition: Warning message:
> unable to load shared library '/home/js36954/src/R-2.2.1/modules/R_X11.so':
>  rtld: 0712-001 Symbol log10 was referenced
>      from module /home/js36954/src/R-2.2.1/modules/R_X11.so(), but a runtime definition of the symbol was not found.
> rtld: 0712-001 Symbol floor was referenced
>      from module /home/js36954/src/R-2.2.1/modules/R_X11.so(), but a runtime definition of the symbol was not found.
> rtld: 0712-001 Symbol pow was referenced
>      from module /home/js36954/src/R-2.2.1/modules/R_X11.so(), but a runtime definition of the symbol was not found.
> rtld: 0712-001 Symbol sin was referenced
>      from module /home/js36954/src/R-2.2.1/modules/R_X11.so(), but a runtime definition of the symbol was not found.
> rtld: 0712-001 Symbol cos was referenced
>      from module /home/js36954/src/R-2.2.1/modules/R_X11.so(), but a runtime definition of the symbol was not found.
> rtld: 0712-001 Symbol tan was referenced
>      from module /home/js36954/src/R-2.2.1/modules
>
> This error didn't occur for R-2.0.1 which passes make check using the above config.site settings on the same AIX 5.2.
>
> Searching the archives on R-devel for similar AIX problems, I tried a diff between the X11 makefiles for R-2.0.1 and R-2.2.1
>
> diff ~/src/R-2.0.1/src/modules/X11/Makefile ~/src/R-2.2.1/src/modules/X11/Makefile
> 54c54
> <       $(SHLIB_LINK) -o $@ $(R_X11_la_LDFLAGS) $(R_X11_la_OBJECTS) $(R_X11_la_LIBADD) $(LIBS)
> ---
>
>>     $(SHLIB_LINK) -o $@ $(R_X11_la_LDFLAGS) $(R_X11_la_OBJECTS) $(R_X11_la_LIBADD)
>
>
> ...
>
> Adding $(LIBS) at the end of line 54 in the R-2.2.1 X11 makefile caused the loading error above to go away, but I don't know if this is what I should be doing ...
>
> After editing that makefile, I was able to plot in R-2.2.1 but eventually encountered a similar error on the vfonts module during make check
>
>
>> Vf <- c("serif", "plain")
>> text(4, 2, "\\#J2438\\#J2421\\#J2451\\#J2473", vfont = Vf)
>
> Warning: unable to load shared library '/home/js36954/src/R-2.2.1/modules/vfonts.so':
>  rtld: 0712-001 Symbol cos was referenced
>      from module /home/js36954/src/R-2.2.1/modules/vfonts.so(), but a runtime definition
>      of the symbol was not found.
> rtld: 0712-001 Symbol sin was referenced
>      from module /home/js36954/src/R-2.2.1/modules/vfonts.so(), but a runtime definition
>      of the symbol was not found.
> Error in text.default(4, 2, "\\#J2438\\#J2421\\#J2451\\#J2473", vfont = Vf) :
>    Hershey fonts cannot be loaded
>
> A diff on the R-2.0.1 and R-2.2.1 vfonts module makefiles,
>
> diff ~/src/R-2.0.1/src/modules/vfonts/Makefile ~/src/R-2.2.1/src/modules/vfonts/Makefile
> 51c51
> <       $(SHLIB_LINK) -o $@ $(vfonts_la_LDFLAGS) $(vfonts_la_OBJECTS) $(vfonts_la_LIBADD) $(LIBS)
> ---
>
>>     $(SHLIB_LINK) -o $@ $(vfonts_la_LDFLAGS) $(vfonts_la_OBJECTS) $(vfonts_la_LIBADD)
>
>
> ...
>
> I added $(LIBS) at the end of the R-2.2.1 vfonts makefile, and the above error went away the next time I ran make check.
>
> So, where I am currently at is that I can get R-2.2.1 to pass make check on my AIX 5.2 with the above two makefile edits, but I am not sure how harmful that may be overall ...
>
> E.g. the plots I now get in R-2.2.1, after editing the X11 and vfonts makefiles, appear with darker axis labels and tick marks than in R-2.0.1, say.
>
> Any advice to help clean things up would be greatly appreciated. I would be happy to provide any additional details.
>
> Thanks,
> Jagat
>
>
>
>
> Jagat K. Sheth         1000 Technology Drive
>> Mortgage Analytics    Third Floor, Mail Station 55
>> CitiMortgage, Inc.    O'Fallon, MO 63368-2240
>> Tel:(636)261-1407     FAX:(636)261-1312
>>
>> Email: jagat.k.sheth at citigroup.com
>>
>>
>>
>>
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Fri May 12 15:16:00 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 12 May 2006 14:16:00 +0100 (BST)
Subject: [Rd] Dropping dimnames doesn't matter (anymore)?
In-Reply-To: <m08xp7cssk.fsf@bar.nemo-project.org>
References: <m08xp7cssk.fsf@bar.nemo-project.org>
Message-ID: <Pine.LNX.4.64.0605121414040.22390@gannet.stats.ox.ac.uk>

On Fri, 12 May 2006, Bj?rn-Helge Mevik wrote:

> In the "old days", one way of speeding up matrix calculations was to
> drop the dimnames of the matrices prior to the calculations, i.e.,
> dimnames(X) <- NULL.  I distinctly remember that this could have a
> great impact at least in Splus 3.x (under UNIX/Linux).
>
> I just did a small, informal test of this with a couple of functions I
> use to fit plsr models, in R 2.3.0 (Linux).  It didn't seem to have
> any effect at all (the functions actually ran a tiny bit slower,
> probably due to the "dimnames(X) <- NULL" command).
>
> Is the "general rule-of-thumb" with current R versions that the
> overhead of keeping the dimnames through calculations is negligible?

It depends on whether the dimnames are an appreciable part of the size of 
the object.  If they are (e.g. a nx1 array for large n) then manipulating 
them will add an appeciable overhead.  (BTW, character vectors such as 
dimnames are faster in R for some operations but take much more memory.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From pat.hodgson at sympatico.ca  Fri May 12 16:32:42 2006
From: pat.hodgson at sympatico.ca (pat.hodgson at sympatico.ca)
Date: Fri, 12 May 2006 16:32:42 +0200 (CEST)
Subject: [Rd] wilcox.exact function (PR#8856)
Message-ID: <20060512143242.B2770E93A@slim.kubism.ku.dk>

Full_Name: Patrick Hodgson
Version: 2.0
OS: solaris 2.9
Submission from: (NULL) (65.94.128.161)


The value reported for the parameter W in the function wilcox.exact appears to
be incorrect.  I have checked the reference in the help file for this function
(Myles & Hollander 1973, as well as 2nd ed. 1999 by same authors) and it is
clear that W is the sum of the ranks of the data set with the smaller number of
members.
Here is sample input/output:
> x<-c(1,2,3,4,5,6,7,8,9,10)
> y<-c(11,12,13,14,15)           
> library(exactRankTests)
> wil<-wilcox.exact(x,y)
> wil

        Exact Wilcoxon rank sum test

data:  x and y 
W = 0, p-value = 0.000666
alternative hypothesis: true mu is not equal to 0 

In this case W should be the sum of the ranks of y (coincidentally also the
values of the y data)= 11+12+13+14+15 = 65.
W of zero is ridiculous.

Similarly, in this case W should be 2+4+6+8 = 20, not 10 as reported.
> x<-c(1,3,5,7,9)
> y<-c(2,4,6,8)
> wil<-wilcox.exact(x,y)
> wil

        Exact Wilcoxon rank sum test

data:  x and y 
W = 10, p-value = 1
alternative hypothesis: true mu is not equal to 0


From p.dalgaard at biostat.ku.dk  Fri May 12 16:48:23 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 12 May 2006 16:48:23 +0200
Subject: [Rd] wilcox.exact function (PR#8856)
In-Reply-To: <20060512143242.B2770E93A@slim.kubism.ku.dk>
References: <20060512143242.B2770E93A@slim.kubism.ku.dk>
Message-ID: <x2zmhn5mfc.fsf@turmalin.kubism.ku.dk>

pat.hodgson at sympatico.ca writes:

> Full_Name: Patrick Hodgson
> Version: 2.0
> OS: solaris 2.9
> Submission from: (NULL) (65.94.128.161)
> 
> 
> The value reported for the parameter W in the function wilcox.exact appears to
> be incorrect.  I have checked the reference in the help file for this function
> (Myles & Hollander 1973, as well as 2nd ed. 1999 by same authors) and it is
> clear that W is the sum of the ranks of the data set with the smaller number of
> members.

You should not use the bug repository to report on a (non-core)
package. However, it is the same W used by wilcox.test and
help(wilcox.test)  has the explanation. 



> Here is sample input/output:
> > x<-c(1,2,3,4,5,6,7,8,9,10)
> > y<-c(11,12,13,14,15)           
> > library(exactRankTests)
> > wil<-wilcox.exact(x,y)
> > wil
> 
>         Exact Wilcoxon rank sum test
> 
> data:  x and y 
> W = 0, p-value = 0.000666
> alternative hypothesis: true mu is not equal to 0 
> 
> In this case W should be the sum of the ranks of y (coincidentally also the
> values of the y data)= 11+12+13+14+15 = 65.
> W of zero is ridiculous.
> 
> Similarly, in this case W should be 2+4+6+8 = 20, not 10 as reported.
> > x<-c(1,3,5,7,9)
> > y<-c(2,4,6,8)
> > wil<-wilcox.exact(x,y)
> > wil
> 
>         Exact Wilcoxon rank sum test
> 
> data:  x and y 
> W = 10, p-value = 1
> alternative hypothesis: true mu is not equal to 0
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From jagat.k.sheth at citigroup.com  Fri May 12 17:24:23 2006
From: jagat.k.sheth at citigroup.com (Sheth, Jagat K)
Date: Fri, 12 May 2006 11:24:23 -0400
Subject: [Rd] R-2.3.0 make error on AIX 5.2
Message-ID: <FD2342224DDA68419F21B64CA7A47E7B44E289@EXNJMB30.nam.nsroot.net>

Thanks, that worked. Make finished without any errors on the R-patched_2006-05-10. 

To get R-patched_2006-05-10 to pass make check on the AIX 5.2 here I added $(LIBM) as you suggested in the other posting for R-2.2.1 to the end of R_X11_la_LIBADD and vfonts_la_LIBADD in the X11 and vfonts modules makefiles respectively before running make. So those makefiles, namely .../src/modules/X11/Makefile and .../src/modules/vfonts/Makefile, have 

R_X11_la_LIBADD = $(ALL_X_LIBS) $(BITMAP_LIBS) $(LIBR) $(LIBM)
vfonts_la_LIBADD = $(LIBR) $(LIBM)

Similar editing for the R-2.2.1 version over here allows it to pass make check. Although for some reason the axis labels and tick marks for both R-2.2.1 and R-2.3.0 still seem darker and bold-faced on the x11 device compared to R-2.0.1. Don't know what to make of that, but looks like I can live with everything so far.

Thanks, 
Jagat    


-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
Sent: Friday, May 12, 2006 8:06 AM
To: Sheth, Jagat K
Cc: r-devel at stat.math.ethz.ch
Subject: Re: [Rd] R-2.3.0 make error on AIX 5.2


We've seen something almost identical before.  Looks like fcntl is 
redefining open (and not open()).  At the top of the file is

#ifdef HAVE_FCNTL_H
# include <fcntl.h>
#endif

Insert

#undef open

in there.


On Fri, 12 May 2006, Sheth, Jagat K wrote:

> I am encountering a make error on an AIX 5.2 with R-2.3.0 and R-patched_2006-05-10 after successfully configuring them using gcc-4.1.0, gnu make, and the following configure options
>
> CC=/usr/local/bin/gcc
> F77=/usr/local/bin/gfortran
> CXX=/usr/local/bin/g++
> MAIN_LDFLAGS=-Wl,-brtl
> SHLIB_LDFLAGS=-Wl,-G
> CFLAGS='-g -O'
> FFLAGS='-O'
> CXXFLAGS='-g -O'
>
> bash-3.00$ ./configure --disable-nls
>
> The gcc specs on this machine are
>
> bash-3.00$ /usr/local/bin/gcc -v
> Using built-in specs.
> Target: powerpc-ibm-aix5.2.0.0
> Configured with: ../gcc-4.1.0/configure --disable-aix64 --disable-nls
> Thread model: aix
> gcc version 4.1.0
>
> The make error from R-patched_2006-05-10 is
>
> make[4]: Entering directory `/sas/data/cmi/ma/data/js36954/src/R-patched/src/mod
> ules/internet'
> /usr/local/bin/gcc -I. -I../../../src/include -I../../../src/include -I/usr/loca
> l/include -DHAVE_CONFIG_H -mno-fp-in-toc   -g -O  -c internet.c -o internet.o
> internet.c: In function 'in_R_newurl':
> internet.c:174: error: 'struct Rconn' has no member named 'open64'
> make[4]: *** [internet.o] Error 1
> make[4]: Leaving directory `/sas/data/cmi/ma/data/js36954/src/R-patched/src/modu
> les/internet'
> make[3]: *** [R] Error 2
> make[3]: Leaving directory `/sas/data/cmi/ma/data/js36954/src/R-patched/src/modu
> les/internet'
> make[2]: *** [R] Error 1
> make[2]: Leaving directory `/sas/data/cmi/ma/data/js36954/src/R-patched/src/modu
> les'
> make[1]: *** [R] Error 1
> make[1]: Leaving directory `/sas/data/cmi/ma/data/js36954/src/R-patched/src'
> make: *** [R] Error 1
>
> I haven't encountered any make errors on this machine when building R-2.0.1 or R-2.2.1 (although the latter failed make check and didn't load the X11 and vfonts modules unless $(LIBS) was added to their makefiles as mentioned in a separate posting from this).
>
> Any advice on the above would be greatly appreciated. I will be happy to provide other additional details.
>
> Thanks,
> Jagat
>
> Jagat K. Sheth         1000 Technology Drive
>> Mortgage Analytics    Third Floor, Mail Station 55
>> CitiMortgage, Inc.    O'Fallon, MO 63368-2240
>> Tel:(636)261-1407     FAX:(636)261-1312
>>
>> Email: jagat.k.sheth at citigroup.com
>>
>>
>>
>>
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Fri May 12 17:31:46 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 12 May 2006 16:31:46 +0100 (BST)
Subject: [Rd] R-2.3.0 make error on AIX 5.2
In-Reply-To: <FD2342224DDA68419F21B64CA7A47E7B44E289@EXNJMB30.nam.nsroot.net>
References: <FD2342224DDA68419F21B64CA7A47E7B44E289@EXNJMB30.nam.nsroot.net>
Message-ID: <Pine.LNX.4.64.0605121628090.28701@gannet.stats.ox.ac.uk>

On Fri, 12 May 2006, Sheth, Jagat K wrote:

> Thanks, that worked. Make finished without any errors on the R-patched_2006-05-10.
>
> To get R-patched_2006-05-10 to pass make check on the AIX 5.2 here I added $(LIBM) as you suggested in the other posting for R-2.2.1 to the end of R_X11_la_LIBADD and vfonts_la_LIBADD in the X11 and vfonts modules makefiles respectively before running make. So those makefiles, namely .../src/modules/X11/Makefile and .../src/modules/vfonts/Makefile, have
>
> R_X11_la_LIBADD = $(ALL_X_LIBS) $(BITMAP_LIBS) $(LIBR) $(LIBM)
> vfonts_la_LIBADD = $(LIBR) $(LIBM)
>
> Similar editing for the R-2.2.1 version over here allows it to pass make 
> check.

Thanks for the confirmation.  I have now committed those changes to 
R-patched and R-devel.

> Although for some reason the axis labels and tick marks for both 
> R-2.2.1 and R-2.3.0 still seem darker and bold-faced on the x11 device 
> compared to R-2.0.1. Don't know what to make of that, but looks like I 
> can live with everything so far.

2.0.1 was choosing the wrong fonts on devices far from 75dpi except 
100+/-0.5dpi.  So this should be an improvement, and is for most people 
and most X servers.

>
> Thanks,
> Jagat
>
>
> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> Sent: Friday, May 12, 2006 8:06 AM
> To: Sheth, Jagat K
> Cc: r-devel at stat.math.ethz.ch
> Subject: Re: [Rd] R-2.3.0 make error on AIX 5.2
>
>
> We've seen something almost identical before.  Looks like fcntl is
> redefining open (and not open()).  At the top of the file is
>
> #ifdef HAVE_FCNTL_H
> # include <fcntl.h>
> #endif
>
> Insert
>
> #undef open
>
> in there.
>
>
> On Fri, 12 May 2006, Sheth, Jagat K wrote:
>
>> I am encountering a make error on an AIX 5.2 with R-2.3.0 and R-patched_2006-05-10 after successfully configuring them using gcc-4.1.0, gnu make, and the following configure options
>>
>> CC=/usr/local/bin/gcc
>> F77=/usr/local/bin/gfortran
>> CXX=/usr/local/bin/g++
>> MAIN_LDFLAGS=-Wl,-brtl
>> SHLIB_LDFLAGS=-Wl,-G
>> CFLAGS='-g -O'
>> FFLAGS='-O'
>> CXXFLAGS='-g -O'
>>
>> bash-3.00$ ./configure --disable-nls
>>
>> The gcc specs on this machine are
>>
>> bash-3.00$ /usr/local/bin/gcc -v
>> Using built-in specs.
>> Target: powerpc-ibm-aix5.2.0.0
>> Configured with: ../gcc-4.1.0/configure --disable-aix64 --disable-nls
>> Thread model: aix
>> gcc version 4.1.0
>>
>> The make error from R-patched_2006-05-10 is
>>
>> make[4]: Entering directory `/sas/data/cmi/ma/data/js36954/src/R-patched/src/mod
>> ules/internet'
>> /usr/local/bin/gcc -I. -I../../../src/include -I../../../src/include -I/usr/loca
>> l/include -DHAVE_CONFIG_H -mno-fp-in-toc   -g -O  -c internet.c -o internet.o
>> internet.c: In function 'in_R_newurl':
>> internet.c:174: error: 'struct Rconn' has no member named 'open64'
>> make[4]: *** [internet.o] Error 1
>> make[4]: Leaving directory `/sas/data/cmi/ma/data/js36954/src/R-patched/src/modu
>> les/internet'
>> make[3]: *** [R] Error 2
>> make[3]: Leaving directory `/sas/data/cmi/ma/data/js36954/src/R-patched/src/modu
>> les/internet'
>> make[2]: *** [R] Error 1
>> make[2]: Leaving directory `/sas/data/cmi/ma/data/js36954/src/R-patched/src/modu
>> les'
>> make[1]: *** [R] Error 1
>> make[1]: Leaving directory `/sas/data/cmi/ma/data/js36954/src/R-patched/src'
>> make: *** [R] Error 1
>>
>> I haven't encountered any make errors on this machine when building R-2.0.1 or R-2.2.1 (although the latter failed make check and didn't load the X11 and vfonts modules unless $(LIBS) was added to their makefiles as mentioned in a separate posting from this).
>>
>> Any advice on the above would be greatly appreciated. I will be happy to provide other additional details.
>>
>> Thanks,
>> Jagat
>>
>> Jagat K. Sheth         1000 Technology Drive
>>> Mortgage Analytics    Third Floor, Mail Station 55
>>> CitiMortgage, Inc.    O'Fallon, MO 63368-2240
>>> Tel:(636)261-1407     FAX:(636)261-1312
>>>
>>> Email: jagat.k.sheth at citigroup.com
>>>
>>>
>>>
>>>
>>>
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From therneau at mayo.edu  Sat May 13 00:28:46 2006
From: therneau at mayo.edu (Terry Therneau)
Date: Fri, 12 May 2006 17:28:46 -0500 (CDT)
Subject: [Rd] reusing routines
Message-ID: <200605122228.k4CMSkL06384@blindpig.mayo.edu>

   I've created some Splus code for a microarray problem that
	- needed to be in C, to take advantage of some sparse matrix
properties
	- uses a cholesky decompostion as part of the computation

 For the cholesky, I used the cholesky2 routine, which is a part of the
survival library.  It does just what I want and I'm familiar with it (after
all, I wrote it).  

  In Splus, this all works fine.  A colleague working on the same problem
prefers R; things don't work there.  The dyn.load command complains that
the routine is not found, even when the survival library is already loaded.

  I looked at the manual page for dyn.load, but don't see anything.  What
are we missing?

  Please reply via email, as I don't read this list.  (But I likely will start
to later this summer, when I port the newest mixed-effects Cox model code
over from S).

	Terry Therneau
	Mayo Clinic
	therneau.terry at mayo.edu


From ggrothendieck at gmail.com  Sat May 13 02:11:45 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 12 May 2006 20:11:45 -0400
Subject: [Rd] reusing routines
In-Reply-To: <200605122228.k4CMSkL06384@blindpig.mayo.edu>
References: <200605122228.k4CMSkL06384@blindpig.mayo.edu>
Message-ID: <971536df0605121711x2f835e6bg73153bad36aa49d0@mail.gmail.com>

R has a sparse matrix package called Matrix.  Maybe with
that you don't need any C?

On 5/12/06, Terry Therneau <therneau at mayo.edu> wrote:
>   I've created some Splus code for a microarray problem that
>        - needed to be in C, to take advantage of some sparse matrix
> properties
>        - uses a cholesky decompostion as part of the computation
>
>  For the cholesky, I used the cholesky2 routine, which is a part of the
> survival library.  It does just what I want and I'm familiar with it (after
> all, I wrote it).
>
>  In Splus, this all works fine.  A colleague working on the same problem
> prefers R; things don't work there.  The dyn.load command complains that
> the routine is not found, even when the survival library is already loaded.
>
>  I looked at the manual page for dyn.load, but don't see anything.  What
> are we missing?
>
>  Please reply via email, as I don't read this list.  (But I likely will start
> to later this summer, when I port the newest mixed-effects Cox model code
> over from S).
>
>        Terry Therneau
>        Mayo Clinic
>        therneau.terry at mayo.edu
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From Gerhard.Thallinger at tugraz.at  Sat May 13 12:54:10 2006
From: Gerhard.Thallinger at tugraz.at (Gerhard Thallinger)
Date: Sat, 13 May 2006 12:54:10 +0200
Subject: [Rd] str() with attr(*,
	"names") is extremely slow for long vectors
Message-ID: <000201c6767b$918bc8b0$0400a8c0@mobilix>

>>>>> "HenrikB" == Henrik Bengtsson (max 7Mb) <hb at stat.berkeley.edu> 
>>>>> on Fri, 5 May 2006 11:58:19 -0700 writes: 

  HenrikB> Hi,
  HenrikB> I noticed some time ago that, for instance, named vectors 
  HenrikB> that are really makes str() really slow when displaying the
  HenrikB> names attribute.

  HenrikB> I don't know exactly when this started, but it wasn't the   
  HenrikB> case say 1-2 years ago. Example (on a WinXP 1.8GHz): 

It got slower with R 2.3.0. Comparing str() for a big exprSet object
from the "Biobase" package I got the following numbers 
(system.time(str(anaexp)) on WinXP 1.8 GHz):

  R 2.2.0

    1. 14.64  0.13 14.90    NA    NA
    2.  4.33  0.09  4.43    NA    NA
    3.  4.20  0.15  4.38    NA    NA

  R 2.3.0

    1. 65.36  0.18 66.12    NA    NA
    2. 51.75  0.21 52.55    NA    NA
    3. 51.79  0.17 52.45    NA    NA


One can notice a considerable speed-up in the 2nd & 3rd call to str() 
in R 2.2.0, which is much less pronounced in R 2.3.0.
  
Hth 

Gerhard

------------------------------------------------------------------------
DI Gerhard Thallinger              E-mail:  Gerhard.Thallinger at tugraz.at
Institute for Genomics and Bioinformatics   Web: http://genome.tugraz.at
Graz University of Technology               Tel:        +43 316 873 5343
Petersgasse 14/V                            Fax:        +43 316 873 5340
8010 Graz, Austria                 Map: http://genome.tugraz.at/Loc.html


From jmc at r-project.org  Sat May 13 15:59:58 2006
From: jmc at r-project.org (John Chambers)
Date: Sat, 13 May 2006 09:59:58 -0400
Subject: [Rd] S4 initialize methods, unexpected recursive callNextMethod
In-Reply-To: <m2lkt9l8jy.fsf@ziti.local>
References: <m2lkt9l8jy.fsf@ziti.local>
Message-ID: <4465E65E.1010308@r-project.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060513/5416ed89/attachment.pl 

From maechler at stat.math.ethz.ch  Sat May 13 17:16:19 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 13 May 2006 17:16:19 +0200
Subject: [Rd] str() with attr(*,
	"names") is extremely slow for long vectors
In-Reply-To: <000201c6767b$918bc8b0$0400a8c0@mobilix>
References: <000201c6767b$918bc8b0$0400a8c0@mobilix>
Message-ID: <17509.63555.958767.122255@stat.math.ethz.ch>

>>>>> "Gerhard" == Gerhard Thallinger <Gerhard.Thallinger at tugraz.at>
>>>>>     on Sat, 13 May 2006 12:54:10 +0200 writes:

>>>>> "HenrikB" == Henrik Bengtsson (max 7Mb) <hb at stat.berkeley.edu> 
>>>>> on Fri, 5 May 2006 11:58:19 -0700 writes: 

But have you looked at R 2.3.0-patched  at all?

I did acknowledge that str(<long character>) had become unacceptably slow, 
and had implemented a simple patch almost "immediately".

Martin

    HenrikB> Hi, I noticed some time ago that, for instance,
    HenrikB> named vectors that are really makes str() really
    HenrikB> slow when displaying the names attribute.

    HenrikB> I don't know exactly when this started, but it
    HenrikB> wasn't the case say 1-2 years ago. Example (on a
    HenrikB> WinXP 1.8GHz):

    Gerhard> It got slower with R 2.3.0. Comparing str() for a
    Gerhard> big exprSet object from the "Biobase" package I got
    Gerhard> the following numbers (system.time(str(anaexp)) on
    Gerhard> WinXP 1.8 GHz):

    Gerhard>   R 2.2.0

    Gerhard>     1. 14.64 0.13 14.90 NA NA 2.  4.33 0.09 4.43 NA
    Gerhard> NA 3.  4.20 0.15 4.38 NA NA

    Gerhard>   R 2.3.0

    Gerhard>     1. 65.36 0.18 66.12 NA NA 2. 51.75 0.21 52.55
    Gerhard> NA NA 3. 51.79 0.17 52.45 NA NA


    Gerhard> One can notice a considerable speed-up in the 2nd &
    Gerhard> 3rd call to str() in R 2.2.0, which is much less
    Gerhard> pronounced in R 2.3.0.
  
    Gerhard> Hth

    Gerhard> Gerhard

    Gerhard> ------------------------------------------------------------------------
    Gerhard> DI Gerhard Thallinger E-mail:
    Gerhard> Gerhard.Thallinger at tugraz.at Institute for Genomics
    Gerhard> and Bioinformatics Web: http://genome.tugraz.at
    Gerhard> Graz University of Technology Tel: +43 316 873 5343
    Gerhard> Petersgasse 14/V Fax: +43 316 873 5340 8010 Graz,
    Gerhard> Austria Map: http://genome.tugraz.at/Loc.html


From Gerhard.Thallinger at tugraz.at  Sat May 13 18:54:11 2006
From: Gerhard.Thallinger at tugraz.at (Gerhard.Thallinger at tugraz.at)
Date: Sat, 13 May 2006 18:54:11 +0200 (CEST)
Subject: [Rd] windows( ... ,rescale="fixed") bug (PR#8857)
Message-ID: <20060513165411.6D12221EAA@slim.kubism.ku.dk>

Full_Name: Gerhard Thallinger
Version: 2.3.0; 2.2.0
OS: Windows XP
Submission from: (NULL) (212.183.54.87)


Invoking windows() with the parameter rescale="fixed" followed by plot.new()
or any other plot command causes very often the following error:

  windows(width=7, height=7, rescale="fixed");plot.new()
  Error in plot.new() : outer margins too large (fig.region too small)

The values in the width and height parameters seem not to have an influence.
Investigating the problem more deeply shows that certain values
in the device structure are set to 0 or have some invalid value 
(bty, cex, ljoin, ... ) after the call to windows() when plot.new() fails.

This indicates that the device structure is either not initialized properly 
or gets clobbered somehow.


From murdoch at stats.uwo.ca  Sat May 13 19:51:39 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 13 May 2006 13:51:39 -0400
Subject: [Rd] windows( ... ,rescale="fixed") bug (PR#8857)
In-Reply-To: <20060513165411.6D12221EAA@slim.kubism.ku.dk>
References: <20060513165411.6D12221EAA@slim.kubism.ku.dk>
Message-ID: <44661CAB.40500@stats.uwo.ca>

On 5/13/2006 12:54 PM, Gerhard.Thallinger at tugraz.at wrote:
> Full_Name: Gerhard Thallinger
> Version: 2.3.0; 2.2.0
> OS: Windows XP
> Submission from: (NULL) (212.183.54.87)
> 
> 
> Invoking windows() with the parameter rescale="fixed" followed by plot.new()
> or any other plot command causes very often the following error:
> 
>   windows(width=7, height=7, rescale="fixed");plot.new()
>   Error in plot.new() : outer margins too large (fig.region too small)
> 
> The values in the width and height parameters seem not to have an influence.
> Investigating the problem more deeply shows that certain values
> in the device structure are set to 0 or have some invalid value 
> (bty, cex, ljoin, ... ) after the call to windows() when plot.new() fails.
> 
> This indicates that the device structure is either not initialized properly 
> or gets clobbered somehow.
> 

I can confirm the bug in R-devel.  A workaround is to open the window 
without specifying "fixed", then in the menu, select fixed.  That 
suggests to me something wasn't being initialized.  I'll take a look...

Duncan Murdoch


From murdoch at stats.uwo.ca  Sat May 13 21:26:43 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 13 May 2006 15:26:43 -0400
Subject: [Rd] windows( ... ,rescale="fixed") bug (PR#8857)
In-Reply-To: <44661CAB.40500@stats.uwo.ca>
References: <20060513165411.6D12221EAA@slim.kubism.ku.dk>
	<44661CAB.40500@stats.uwo.ca>
Message-ID: <446632F3.4030908@stats.uwo.ca>

On 5/13/2006 1:51 PM, Duncan Murdoch wrote:
> On 5/13/2006 12:54 PM, Gerhard.Thallinger at tugraz.at wrote:
>> Full_Name: Gerhard Thallinger
>> Version: 2.3.0; 2.2.0
>> OS: Windows XP
>> Submission from: (NULL) (212.183.54.87)
>>
>>
>> Invoking windows() with the parameter rescale="fixed" followed by plot.new()
>> or any other plot command causes very often the following error:
>>
>>   windows(width=7, height=7, rescale="fixed");plot.new()
>>   Error in plot.new() : outer margins too large (fig.region too small)
>>
>> The values in the width and height parameters seem not to have an influence.
>> Investigating the problem more deeply shows that certain values
>> in the device structure are set to 0 or have some invalid value 
>> (bty, cex, ljoin, ... ) after the call to windows() when plot.new() fails.
>>
>> This indicates that the device structure is either not initialized properly 
>> or gets clobbered somehow.
>>
> 
> I can confirm the bug in R-devel.  A workaround is to open the window 
> without specifying "fixed", then in the menu, select fixed.  That 
> suggests to me something wasn't being initialized.  I'll take a look...

I've taken a look, and tracked it down this far:

While setting up, the graphics device installs a callback called 
HelpExpose that's called when drawing the window.  For some reason I 
haven't figured out, rescale="fixed" causes this to be called before the 
window is ready, and junk in the structure leads to the error.

I won't be able to do any more on this for a couple of days.

Duncan Murdoch


From murdoch at stats.uwo.ca  Sat May 13 21:27:13 2006
From: murdoch at stats.uwo.ca (murdoch at stats.uwo.ca)
Date: Sat, 13 May 2006 21:27:13 +0200 (CEST)
Subject: [Rd] windows( ... ,rescale="fixed") bug (PR#8857)
Message-ID: <20060513192713.AB88F19B29@slim.kubism.ku.dk>

On 5/13/2006 1:51 PM, Duncan Murdoch wrote:
> On 5/13/2006 12:54 PM, Gerhard.Thallinger at tugraz.at wrote:
>> Full_Name: Gerhard Thallinger
>> Version: 2.3.0; 2.2.0
>> OS: Windows XP
>> Submission from: (NULL) (212.183.54.87)
>>
>>
>> Invoking windows() with the parameter rescale="fixed" followed by plot.new()
>> or any other plot command causes very often the following error:
>>
>>   windows(width=7, height=7, rescale="fixed");plot.new()
>>   Error in plot.new() : outer margins too large (fig.region too small)
>>
>> The values in the width and height parameters seem not to have an influence.
>> Investigating the problem more deeply shows that certain values
>> in the device structure are set to 0 or have some invalid value 
>> (bty, cex, ljoin, ... ) after the call to windows() when plot.new() fails.
>>
>> This indicates that the device structure is either not initialized properly 
>> or gets clobbered somehow.
>>
> 
> I can confirm the bug in R-devel.  A workaround is to open the window 
> without specifying "fixed", then in the menu, select fixed.  That 
> suggests to me something wasn't being initialized.  I'll take a look...

I've taken a look, and tracked it down this far:

While setting up, the graphics device installs a callback called 
HelpExpose that's called when drawing the window.  For some reason I 
haven't figured out, rescale="fixed" causes this to be called before the 
window is ready, and junk in the structure leads to the error.

I won't be able to do any more on this for a couple of days.

Duncan Murdoch


From pinard at iro.umontreal.ca  Sat May 13 23:31:07 2006
From: pinard at iro.umontreal.ca (=?iso-8859-1?Q?Fran=E7ois?= Pinard)
Date: Sat, 13 May 2006 17:31:07 -0400
Subject: [Rd] Mere chat on vectorisation matters
In-Reply-To: <20060510181652.GA15816@phenix.sram.qc.ca>
References: <20060510181652.GA15816@phenix.sram.qc.ca>
Message-ID: <20060513213107.GA1517@phenix.sram.qc.ca>

Hi to all.  Not so long ago, I wrote:

>Allow me to chat a tiny bit on two vectorisation-related matters, in 
>the context of R.  I'm curious about if the following ideas have ever 
>been considered, and rejected already. [... then, a few words about 
>Duff's device, and operation chaining ...]

As this letter did not generate any reply, I presumed the ideas have not 
be rejected, on the premise that if they have been, someone would have 
been kind enough to tell me :-).  So, today, I went forward and added 
Duff's device within arithmetic.c.

There might have been operational or experimental error, of course, as 
I'm far from mastering R installation matters.  But if there were no 
such error, I'm now reporting, for the record, that Duff's device does 
_not_ yield an interesting speedup.

-- 
Fran?ois Pinard   http://pinard.progiciels-bpi.ca


From juan_sr at uol.com.br  Sun May 14 00:29:49 2006
From: juan_sr at uol.com.br (Juan Santiago Ramseyer)
Date: Sat, 13 May 2006 19:29:49 -0300
Subject: [Rd] Error Compiling RMySQL in Fedora Core 5 86x64
Message-ID: <1147559389.3127.9.camel@localhost.localdomain>

in download and automatic install the RMySQL, R show the error (look
under session attach. MySQL is install and operational.

Juan Santiago Ramseyer.



> install.packages('RMySQL')
--- Please select a CRAN mirror for use in this session ---
Loading Tcl/Tk interface ... done
tentando a URL
'http://cran.br.r-project.org/src/contrib/RMySQL_0.5-7.tar.gz'
Content type 'application/x-tar' length 142507 bytes
URL aberta
==================================================
downloaded 139Kb

* Installing *source* package 'RMySQL' ...
creating cache ./config.cache
checking how to run the C preprocessor... cc -E
checking for compress in -lz... yes
checking for getopt_long in -lc... yes
checking for mysql_init in -lmysqlclient... no
checking for mysql.h... no
checking for mysql_init in -lmysqlclient... no
checking for mysql_init in -lmysqlclient... no
checking for mysql_init in -lmysqlclient... no
checking for mysql_init in -lmysqlclient... no
checking for mysql_init in -lmysqlclient... no
checking for /usr/local/include/mysql/mysql.h... no
checking for /usr/include/mysql/mysql.h... yes

Configuration error:
  could not find the MySQL installation include and/or library
  directories.  Manually specify the location of the MySQL
  libraries and the header files and re-run R CMD INSTALL.

INSTRUCTIONS:

1. Define and export the 2 shell variables PKG_CPPFLAGS and
   PKG_LIBS to include the directory for header files (*.h)
   and libraries, for example (using Bourne shell syntax):

      export PKG_CPPFLAGS="-I<MySQL-include-dir>"
      export PKG_LIBS="-L<MySQL-lib-dir> -lmysqlclient"

   Re-run the R INSTALL command:

      R CMD INSTALL RMySQL_<version>.tar.gz

2. Alternatively, you may pass the configure arguments
      --with-mysql-dir=<base-dir> (distribution directory)
   or
      --with-mysql-inc=<base-inc> (where MySQL header files reside)
      --with-mysql-lib=<base-lib> (where MySQL libraries reside)
   in the call to R INSTALL --configure-args='...'

   R CMD INSTALL --configure-args='--with-mysql-dir=DIR'
RMySQL_<version>.tar.gz

ERROR: configuration failed for package 'RMySQL'
** Removing '/usr/lib64/R/library/RMySQL'

The downloaded packages are in
        /tmp/RtmpLXIne5/downloaded_packages
Warning message:
installation of package 'RMySQL' had non-zero exit status in:
install.packages("                        RMySQL")
>


From duncan at wald.ucdavis.edu  Sun May 14 01:21:47 2006
From: duncan at wald.ucdavis.edu (Duncan Temple Lang)
Date: Sat, 13 May 2006 16:21:47 -0700
Subject: [Rd] reusing routines
In-Reply-To: <200605122228.k4CMSkL06384@blindpig.mayo.edu>
References: <200605122228.k4CMSkL06384@blindpig.mayo.edu>
Message-ID: <44666A0B.3060508@wald.ucdavis.edu>

Hi Terry.

If I am inferring correctly from your description, in S-Plus
your C code for the microarray automatically finds the cholesky2 routine
in the survival package without any need to tell it to do so.
While it may be convenient, this is not very desirable at all.
Rather, you should have to tell the microarray C code about
cholesky2 when compiling and linking that code.

You didn't mention which operating system you and your colleague
are each using.  But perhaps the local argument of dyn.load()
may work for you; use
   dyn.load(system.file("libs",
                        paste("survival", .Platform$dynlib.ext, sep =""),
                        package = "survival"),
            local = FALSE)


Then  dyn.load() the other dynamically loadable library which uses 
cholesky2.

   In the next few months, we'll be able to link native code from one 
package into another and this is a much more sensible approach than
using the global symbol table and risking conflicts and ambiguities.

  D.

Terry Therneau wrote:
>    I've created some Splus code for a microarray problem that
> 	- needed to be in C, to take advantage of some sparse matrix
> properties
> 	- uses a cholesky decompostion as part of the computation
> 
>  For the cholesky, I used the cholesky2 routine, which is a part of the
> survival library.  It does just what I want and I'm familiar with it (after
> all, I wrote it).  
> 
>   In Splus, this all works fine.  A colleague working on the same problem
> prefers R; things don't work there.  The dyn.load command complains that
> the routine is not found, even when the survival library is already loaded.
> 
>   I looked at the manual page for dyn.load, but don't see anything.  What
> are we missing?
> 
>   Please reply via email, as I don't read this list.  (But I likely will start
> to later this summer, when I port the newest mixed-effects Cox model code
> over from S).
> 
> 	Terry Therneau
> 	Mayo Clinic
> 	therneau.terry at mayo.edu
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Gerhard.Thallinger at tugraz.at  Sun May 14 15:19:20 2006
From: Gerhard.Thallinger at tugraz.at (Gerhard Thallinger)
Date: Sun, 14 May 2006 15:19:20 +0200
Subject: [Rd] str() with attr(*,
	"names") is extremely slow for long vectors
Message-ID: <000001c67759$03ceff90$0400a8c0@mobilix>

>>>>> "MartinM" == Martin Maechler maechler at stat.math.ethz.ch
>>>>>    Sat, May 13 2006 15:16:19 +0200 writes: 

  MartinM> But have you looked at R 2.3.0-patched at all?
  MartinM> 
  MartinM> I did acknowledge that str(<long character>) had become 
  MartinM> unacceptably slow, and had implemented a simple patch 
  MartinM> almost "immediately".

Yes, I did. Here are the timings (WinXP 1.8 GHz):

  R 2.2.0

    1. 14.64  0.13 14.90    NA    NA
    2.  4.33  0.09  4.43    NA    NA
    3.  4.20  0.15  4.38    NA    NA

  R 2.3.0

    1. 65.36  0.18 66.12    NA    NA
    2. 51.75  0.21 52.55    NA    NA
    3. 51.79  0.17 52.45    NA    NA

  R 2.3.0 Patched (2006-05-11 r38037) 

    1. 44.09  0.09 44.45    NA    NA
    2. 34.96  0.08 35.66    NA    NA
    3. 34.52  0.07 34.81    NA    NA

Hth 

Gerhard

------------------------------------------------------------------------
DI Gerhard Thallinger              E-mail:  Gerhard.Thallinger at tugraz.at
Institute for Genomics and Bioinformatics   Web: http://genome.tugraz.at
Graz University of Technology               Tel:        +43 316 873 5343
Petersgasse 14/V                            Fax:        +43 316 873 5340
8010 Graz, Austria                 Map: http://genome.tugraz.at/Loc.html


From pinard at iro.umontreal.ca  Sun May 14 16:08:52 2006
From: pinard at iro.umontreal.ca (=?iso-8859-1?Q?Fran=E7ois?= Pinard)
Date: Sun, 14 May 2006 10:08:52 -0400
Subject: [Rd] Suggestion for system.time()
Message-ID: <20060514140852.GA8854@phenix.sram.qc.ca>

Hi, people.  A tiny suggestion for the system.time function.

Could the returned vector have names?  These could be like:

   c("User", "System", "Elapsed", "Sub.User", "Sub.System")

That would then produce self-documenting output.

-- 
Fran?ois Pinard   http://pinard.progiciels-bpi.ca


From mtmorgan at fhcrc.org  Sun May 14 21:15:41 2006
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Sun, 14 May 2006 12:15:41 -0700
Subject: [Rd] bindingIsLocked returns illogical logical
Message-ID: <6phody0ct9e.fsf@gopher3.fhcrc.org>

bindingIsLocked applied to a locked binding returns a 'logical' that
is niether true nor false.

Martin

> e <- new.env()
> e$x <- 1
> e$y <- 2
> lockBinding("x", e)
NULL
> bindingIsLocked("x", e)
[1] TRUE
> bindingIsLocked("x", e)==TRUE
[1] FALSE
> bindingIsLocked("x", e)==FALSE
[1] FALSE
> bindingIsLocked("y", e)
[1] FALSE
> bindingIsLocked("y", e)==FALSE
[1] TRUE
> bindingIsLocked("y", e)==TRUE
[1] FALSE
> sessionInfo()
R version 2.4.0 Under development (unstable) (2006-05-13 r38060) 
x86_64-unknown-linux-gnu 

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets" 
[7] "base"


From sfalcon at fhcrc.org  Sun May 14 21:37:30 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Sun, 14 May 2006 12:37:30 -0700
Subject: [Rd] Suggestion for system.time()
In-Reply-To: <20060514140852.GA8854@phenix.sram.qc.ca> (=?iso-8859-1?Q?Fra?=
	=?iso-8859-1?Q?n=E7ois?= Pinard's message of "Sun, 14 May 2006 10:08:52
	-0400")
References: <20060514140852.GA8854@phenix.sram.qc.ca>
Message-ID: <m21wuwqtxh.fsf@ziti.local>

Fran?ois Pinard <pinard at iro.umontreal.ca> writes:

> Hi, people.  A tiny suggestion for the system.time function.
>
> Could the returned vector have names?  These could be like:
>
>    c("User", "System", "Elapsed", "Sub.User", "Sub.System")
>
> That would then produce self-documenting output.

Here's a function you could try.  It names the result as you
suggested.  It also can be nested, which system.time cannot, because
it uses on.exit without specifying add=TRUE.

timeit <- function (expr, gcFirst = TRUE) 
{
    nms <- c("User", "System", "Elapsed", "Sub.User", "Sub.System")
    if (!exists("proc.time")) {
        ans <- rep(as.numeric(NA), 5)
        names(ans) <- nms
        return(ans)
    }
    loc.frame <- parent.frame()
    if (gcFirst) 
        gc(FALSE)
    expr <- substitute(expr)
    time <- proc.time()
    show_time <- function() {
        t <- proc.time() - time
        names(t) <- nms
        cat("Timing stopped at:\n")
        print(t)
        t 
    }
    tryCatch(eval(expr, envir = loc.frame),
             error=function(e) {
                 msg <- paste("Error in", deparse(conditionCall(e)),
                              ":", conditionMessage(e), "\n")
                 cat(msg)
             })
    show_time()
}


## Examples


> t <- timeit(z <- rnorm(10000))
Timing stopped at:
      User     System    Elapsed   Sub.User Sub.System 
     0.007      0.001      0.008      0.000      0.000 
> t
      User     System    Elapsed   Sub.User Sub.System 
     0.007      0.001      0.008      0.000      0.000 

## Nested calls.  I dunno, could be useful in some debugging 
## situations *shrug*


> t <- timeit({z <- rnorm(10000);timeit(q <- runif(50000))})
Timing stopped at:
      User     System    Elapsed   Sub.User Sub.System 
     0.012      0.002      0.014      0.000      0.000 
Timing stopped at:
      User     System    Elapsed   Sub.User Sub.System 
     0.090      0.003      0.146      0.000      0.000 
> t
      User     System    Elapsed   Sub.User Sub.System 
     0.090      0.003      0.146      0.000      0.000 


## With an error

> t <- timeit(plot(foobarbaz))
Error in plot(foobarbaz) : object "foobarbaz" not found 
Timing stopped at:
      User     System    Elapsed   Sub.User Sub.System 
     0.002      0.000      0.038      0.000      0.000 
> t
      User     System    Elapsed   Sub.User Sub.System 
     0.002      0.000      0.038      0.000      0.000


From pinard at iro.umontreal.ca  Sun May 14 22:29:44 2006
From: pinard at iro.umontreal.ca (=?iso-8859-1?Q?Fran=E7ois?= Pinard)
Date: Sun, 14 May 2006 16:29:44 -0400
Subject: [Rd] Suggestion for system.time()
In-Reply-To: <m21wuwqtxh.fsf@ziti.local>
References: <20060514140852.GA8854@phenix.sram.qc.ca>
	<m21wuwqtxh.fsf@ziti.local>
Message-ID: <20060514202944.GA28762@alcyon.progiciels-bpi.ca>

[Seth Falcon]
>[Fran?ois Pinard]

>> Hi, people.  A tiny suggestion for the system.time function.
>> Could the returned vector have names?  These could be like:
>>    c("User", "System", "Elapsed", "Sub.User", "Sub.System")
>> That would then produce self-documenting output.

>Here's a function you could try.  It names the result as you
>suggested.  It also can be nested, which system.time cannot, because
>it uses on.exit without specifying add=TRUE.

Thanks, Seth.  Your code could be useful, I'm saving it. :-)

Just to be clear, my suggestion was more thought as a small benefit for 
the community of R users, rather than for myself alone.

-- 
Fran?ois Pinard   http://pinard.progiciels-bpi.ca


From sfalcon at fhcrc.org  Mon May 15 01:06:20 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Sun, 14 May 2006 16:06:20 -0700
Subject: [Rd] Suggestion for system.time()
In-Reply-To: <20060514202944.GA28762@alcyon.progiciels-bpi.ca>
	(=?iso-8859-1?Q?Fran=E7ois?= Pinard's message of "Sun,
	14 May 2006 16:29:44 -0400")
References: <20060514140852.GA8854@phenix.sram.qc.ca>
	<m21wuwqtxh.fsf@ziti.local>
	<20060514202944.GA28762@alcyon.progiciels-bpi.ca>
Message-ID: <m2wtcop5oz.fsf@ziti.local>

Fran?ois Pinard <pinard at iro.umontreal.ca> writes:

> [Seth Falcon]
>>Here's a function you could try.  It names the result as you
>>suggested.  It also can be nested, which system.time cannot, because
>>it uses on.exit without specifying add=TRUE.
>
> Thanks, Seth.  Your code could be useful, I'm saving it. :-)

You make it sound like that code is going to mature like a wine.  I'd
say, if it isn't useful now, it will be less useful later, but hey,
disk space is cheap :-D

> Just to be clear, my suggestion was more thought as a small benefit
> for the community of R users, rather than for myself alone.

That's what I understood.  I bothered to post some code because I
agree and saw a couple of small ways to improve system.time: add
names, allow nesting, and compute the time once instead of twice[*].
Perhaps others will agree and consider a change.

Best,

+ seth


[*] system.time computes the elapsed time twice: once when running the
on.exit hook, which gets called explicitly (!), and once for the
return value.  Here's the relevant lines:

    on.exit(cat("Timing stopped at:", proc.time() - time, "\n"))  ## once
    eval(expr, envir = loc.frame)
    new.time <- proc.time()
    on.exit()
    new.time - time                                               ## twice


From pinard at iro.umontreal.ca  Mon May 15 02:29:44 2006
From: pinard at iro.umontreal.ca (=?iso-8859-1?Q?Fran=E7ois?= Pinard)
Date: Sun, 14 May 2006 20:29:44 -0400
Subject: [Rd] Suggestion for system.time()
In-Reply-To: <m2wtcop5oz.fsf@ziti.local>
References: <20060514140852.GA8854@phenix.sram.qc.ca>
	<m21wuwqtxh.fsf@ziti.local>
	<20060514202944.GA28762@alcyon.progiciels-bpi.ca>
	<m2wtcop5oz.fsf@ziti.local>
Message-ID: <20060515002944.GA32296@alcyon.progiciels-bpi.ca>

[Seth Falcon]
>[Fran?ois Pinard]
>> [Seth Falcon]

>>>Here's a function you could try.

>> Thanks, Seth.  Your code could be useful, I'm saving it. :-)

>You make it sound like that code is going to mature like a wine.
>I'd say, if it isn't useful now, it will be less useful later, but hey,
>disk space is cheap :-D

:-) :-).  The truth is that it's _me_, and not the saved code, which is 
slowly maturing.  More time goes, more I become able to appreciate code 
and ideas.

I'm started in a long journey that should lead me in various corners of 
R and statistics.  There are flurry, plenty of these corners.  While 
most of them are still opaque for me, I begin to see tiny spots of 
transparency here and there, yet only after having paid many visits :-).
All in all, the whole experience is intriguing, and still passionating.

-- 
Fran?ois Pinard   http://pinard.progiciels-bpi.ca


From sfalcon at fhcrc.org  Mon May 15 08:40:01 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Sun, 14 May 2006 23:40:01 -0700
Subject: [Rd] bindingIsLocked returns illogical logical
In-Reply-To: <6phody0ct9e.fsf@gopher3.fhcrc.org> (Martin Morgan's message of
	"Sun, 14 May 2006 12:15:41 -0700")
References: <6phody0ct9e.fsf@gopher3.fhcrc.org>
Message-ID: <m2lkt3n64e.fsf@ziti.local>

Martin Morgan <mtmorgan at fhcrc.org> writes:

> bindingIsLocked applied to a locked binding returns a 'logical' that
> is niether true nor false.

Is this a philosophical question? :-)

Here's what I think is going on:

BINDING_IS_LOCKED does not return 0/1, but the result of a bit op that
will be either 0 or some int where bit 14 is set.

The behavior you describe is consistent with a logical value escaping
to R where the underlying int is some x > 1.

I wonder if ScalarLogical should force 0/1:

Index: include/Rinlinedfuns.h
===================================================================
--- include/Rinlinedfuns.h      (revision 38060)
+++ include/Rinlinedfuns.h      (working copy)
@@ -494,7 +494,7 @@
 INLINE_FUN SEXP ScalarLogical(int x)
 {
     SEXP ans = allocVector(LGLSXP, 1);
-    INTEGER(ans)[0] = x;
+    INTEGER(ans)[0] = (x == 0) ? 0 : 1;
     return ans;
 }

Otherwise, I think do_bndIsLocked needs to make a similar operation
before calling ScalarLogical.  But preventing these all purpose
logicals from escaping would seem to be a good argument for changing
ScalarLogical.

+ seth


From ripley at stats.ox.ac.uk  Mon May 15 09:05:32 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 15 May 2006 08:05:32 +0100 (BST)
Subject: [Rd] bindingIsLocked returns illogical logical
In-Reply-To: <m2lkt3n64e.fsf@ziti.local>
References: <6phody0ct9e.fsf@gopher3.fhcrc.org> <m2lkt3n64e.fsf@ziti.local>
Message-ID: <Pine.LNX.4.64.0605150803070.8993@gannet.stats.ox.ac.uk>

On Sun, 14 May 2006, Seth Falcon wrote:

> Martin Morgan <mtmorgan at fhcrc.org> writes:
>
>> bindingIsLocked applied to a locked binding returns a 'logical' that
>> is niether true nor false.
>
> Is this a philosophical question? :-)

But there is such a value defined for R logical vectors.

> Here's what I think is going on:
>
> BINDING_IS_LOCKED does not return 0/1, but the result of a bit op that
> will be either 0 or some int where bit 14 is set.
>
> The behavior you describe is consistent with a logical value escaping
> to R where the underlying int is some x > 1.
>
> I wonder if ScalarLogical should force 0/1:

Not a good idea: what about the third value, NA?

> Index: include/Rinlinedfuns.h
> ===================================================================
> --- include/Rinlinedfuns.h      (revision 38060)
> +++ include/Rinlinedfuns.h      (working copy)
> @@ -494,7 +494,7 @@
> INLINE_FUN SEXP ScalarLogical(int x)
> {
>     SEXP ans = allocVector(LGLSXP, 1);
> -    INTEGER(ans)[0] = x;
> +    INTEGER(ans)[0] = (x == 0) ? 0 : 1;
>     return ans;
> }
>
> Otherwise, I think do_bndIsLocked needs to make a similar operation
> before calling ScalarLogical.  But preventing these all purpose
> logicals from escaping would seem to be a good argument for changing
> ScalarLogical.

I think it needs to handle NAs.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hin-tak.leung at cimr.cam.ac.uk  Mon May 15 13:26:30 2006
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Mon, 15 May 2006 12:26:30 +0100
Subject: [Rd] Error Compiling RMySQL in Fedora Core 5 86x64
In-Reply-To: <1147559389.3127.9.camel@localhost.localdomain>
References: <1147559389.3127.9.camel@localhost.localdomain>
Message-ID: <44686566.6020802@cimr.cam.ac.uk>

on fedora core 5, you'll need to install the mysql-devel package.
the "mysql.h" header is in /usr/include/mysql/ .

So you need:
export PKG_CPPFLAGS="-I/usr/include/mysql"
export PKG_LIBS="-L/usr/lib64/mysql -lmysqlclient"

Juan Santiago Ramseyer wrote:
> in download and automatic install the RMySQL, R show the error (look
> under session attach. MySQL is install and operational.
> 
> Juan Santiago Ramseyer.
> 
> 
> 
>> install.packages('RMySQL')
> --- Please select a CRAN mirror for use in this session ---
> Loading Tcl/Tk interface ... done
> tentando a URL
> 'http://cran.br.r-project.org/src/contrib/RMySQL_0.5-7.tar.gz'
> Content type 'application/x-tar' length 142507 bytes
> URL aberta
> ==================================================
> downloaded 139Kb
> 
> * Installing *source* package 'RMySQL' ...
> creating cache ./config.cache
> checking how to run the C preprocessor... cc -E
> checking for compress in -lz... yes
> checking for getopt_long in -lc... yes
> checking for mysql_init in -lmysqlclient... no
> checking for mysql.h... no
> checking for mysql_init in -lmysqlclient... no
> checking for mysql_init in -lmysqlclient... no
> checking for mysql_init in -lmysqlclient... no
> checking for mysql_init in -lmysqlclient... no
> checking for mysql_init in -lmysqlclient... no
> checking for /usr/local/include/mysql/mysql.h... no
> checking for /usr/include/mysql/mysql.h... yes
> 
> Configuration error:
>   could not find the MySQL installation include and/or library
>   directories.  Manually specify the location of the MySQL
>   libraries and the header files and re-run R CMD INSTALL.
> 
> INSTRUCTIONS:
> 
> 1. Define and export the 2 shell variables PKG_CPPFLAGS and
>    PKG_LIBS to include the directory for header files (*.h)
>    and libraries, for example (using Bourne shell syntax):
> 
>       export PKG_CPPFLAGS="-I<MySQL-include-dir>"
>       export PKG_LIBS="-L<MySQL-lib-dir> -lmysqlclient"
> 
>    Re-run the R INSTALL command:
> 
>       R CMD INSTALL RMySQL_<version>.tar.gz
> 
> 2. Alternatively, you may pass the configure arguments
>       --with-mysql-dir=<base-dir> (distribution directory)
>    or
>       --with-mysql-inc=<base-inc> (where MySQL header files reside)
>       --with-mysql-lib=<base-lib> (where MySQL libraries reside)
>    in the call to R INSTALL --configure-args='...'
> 
>    R CMD INSTALL --configure-args='--with-mysql-dir=DIR'
> RMySQL_<version>.tar.gz
> 
> ERROR: configuration failed for package 'RMySQL'
> ** Removing '/usr/lib64/R/library/RMySQL'
> 
> The downloaded packages are in
>         /tmp/RtmpLXIne5/downloaded_packages
> Warning message:
> installation of package 'RMySQL' had non-zero exit status in:
> install.packages("                        RMySQL")
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From m.vroonhoven at erasmusmc.nl  Mon May 15 15:09:56 2006
From: m.vroonhoven at erasmusmc.nl (m.vroonhoven at erasmusmc.nl)
Date: Mon, 15 May 2006 15:09:56 +0200 (CEST)
Subject: [Rd] Memory allocation fails in R 2.2.1 and R 2.3.0 on SGI Irix,
	while plenty of memory available (PR#8861)
Message-ID: <20060515130956.5B71619B2D@slim.kubism.ku.dk>

Dear R developers,

We have a big SGI Origin computation server with 32 cpu's and 64 Gb of
RAM. In R 2.0.0 we could run large jobs, allocating 8 Gb of RAM was not
a problem, for example by running:
  > v1 <- seq(1,2^29)
  > v2 <- seq(1,2^29)
  > v3 <- seq(1,2^29)
  > v4 <- seq(1,2^29)
This yields an R process, consuming about 8 Gb of RAM:
       PID       PGRP USERNAME PRI  SIZE   RES STATE    TIME WCPU% CPU% COMMAND
    177484     177484 mirjam    20 8225M 8217M sleep    1:18  29.3 0.00 R

After upgrading from R 2.0.0 to R 2.2.1, we cannot allocate more than
about 1300 M of memory, as shown below:
  > v1 <- seq(1,2^29)
  Error: cannot allocate vector of size 2097152 Kb
  > v1 <- seq(1,2^28)
  > v2 <- seq(1,2^27)
  Error: cannot allocate vector of size 524288 Kb
  > v2 <- seq(1,2^25)
  > v3 <- seq(1,2^24)
  > v4 <- seq(1,2^23)
  > v5 <- seq(1,2^22)
  Error: cannot allocate vector of size 16384 Kb
  > v5 <- seq(1,2^21)
  > v6 <- seq(1,2^20)
  > v7 <- seq(1,2^19)
  > v8 <- seq(1,2^18)
  > q()
  Save workspace image? [y/n/c]: n
Upgrading to R 2.3.0 yields the same results.
This yields an R executable taking 1284M of RAM, refusing to allocate
more RAM, with about 30Gb free on the machine.

Is there any special configuration option I should turn on to make it
possible to use more memory? The OS memory limits (ulimit -a) are set
appropriately:

data seg size         (kbytes, -d) unlimited
max memory size       (kbytes, -m) 63385824
stack size            (kbytes, -s) 65536
virtual memory        (kbytes, -v) unlimited

If it is not some special (compile time) option that I should have set,
I think this is a bug.....


						With kind regards,


						Mirjam van Vroonhoven
-- 
Dr. Mirjam van Vroonhoven
	system administrator/programmer, dept. of Bioinformatics
	Erasmus Medical Center, Rotterdam, The Netherlands
	Room Number Ee 15.32, phone +31-10-463 81 11
Web: 	http://www.erasmusmc.nl/bioinformatics/
E-mail: m.vroonhoven at erasmusmc.nl


From tlumley at u.washington.edu  Mon May 15 16:48:29 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 15 May 2006 07:48:29 -0700 (PDT)
Subject: [Rd] Memory allocation fails in R 2.2.1 and R 2.3.0 on SGI Irix,
 while plenty of memory available (PR#8861)
In-Reply-To: <20060515130956.5B71619B2D@slim.kubism.ku.dk>
References: <20060515130956.5B71619B2D@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.64.0605150740250.29777@homer23.u.washington.edu>

On Mon, 15 May 2006, m.vroonhoven at erasmusmc.nl wrote:

> Dear R developers,
>
> We have a big SGI Origin computation server with 32 cpu's and 64 Gb of
> RAM. In R 2.0.0 we could run large jobs, allocating 8 Gb of RAM was not
> a problem, for example by running:
>  > v1 <- seq(1,2^29)
>  > v2 <- seq(1,2^29)
>  > v3 <- seq(1,2^29)
>  > v4 <- seq(1,2^29)
> This yields an R process, consuming about 8 Gb of RAM:
>       PID       PGRP USERNAME PRI  SIZE   RES STATE    TIME WCPU% CPU% COMMAND
>    177484     177484 mirjam    20 8225M 8217M sleep    1:18  29.3 0.00 R
>
> After upgrading from R 2.0.0 to R 2.2.1, we cannot allocate more than
> about 1300 M of memory, as shown below:
>  > v1 <- seq(1,2^29)
>  Error: cannot allocate vector of size 2097152 Kb
>  > v1 <- seq(1,2^28)
>  > v2 <- seq(1,2^27)
>  Error: cannot allocate vector of size 524288 Kb
>  > v2 <- seq(1,2^25)
>  > v3 <- seq(1,2^24)
>  > v4 <- seq(1,2^23)
>  > v5 <- seq(1,2^22)
>  Error: cannot allocate vector of size 16384 Kb
>  > v5 <- seq(1,2^21)
>  > v6 <- seq(1,2^20)
>  > v7 <- seq(1,2^19)
>  > v8 <- seq(1,2^18)
>  > q()
>  Save workspace image? [y/n/c]: n
> Upgrading to R 2.3.0 yields the same results.
> This yields an R executable taking 1284M of RAM, refusing to allocate
> more RAM, with about 30Gb free on the machine.


You can tell if you have a 64bit build of R by looking at
.Machine$sizeof.pointer in R, which should be 8.

If not, then you need to set whatever C and Fortran compilation flags give 
a 64bit system. It doesn't look to me as if R's configure script has any 
special handling for C compiler flags on SGI.

If you have a 64bit build then something strange is happening. The message 
you quote happens only when malloc() returns NULL, so it is hard to see 
how R could be causing it, though.

 	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From tlumley at u.washington.edu  Mon May 15 16:48:44 2006
From: tlumley at u.washington.edu (tlumley at u.washington.edu)
Date: Mon, 15 May 2006 16:48:44 +0200 (CEST)
Subject: [Rd] Memory allocation fails in R 2.2.1 and R 2.3.0 on SGI Irix,
	(PR#8862)
Message-ID: <20060515144844.DD796CD4A@slim.kubism.ku.dk>

On Mon, 15 May 2006, m.vroonhoven at erasmusmc.nl wrote:

> Dear R developers,
>
> We have a big SGI Origin computation server with 32 cpu's and 64 Gb of
> RAM. In R 2.0.0 we could run large jobs, allocating 8 Gb of RAM was not
> a problem, for example by running:
>  > v1 <- seq(1,2^29)
>  > v2 <- seq(1,2^29)
>  > v3 <- seq(1,2^29)
>  > v4 <- seq(1,2^29)
> This yields an R process, consuming about 8 Gb of RAM:
>       PID       PGRP USERNAME PRI  SIZE   RES STATE    TIME WCPU% CPU% COMMAND
>    177484     177484 mirjam    20 8225M 8217M sleep    1:18  29.3 0.00 R
>
> After upgrading from R 2.0.0 to R 2.2.1, we cannot allocate more than
> about 1300 M of memory, as shown below:
>  > v1 <- seq(1,2^29)
>  Error: cannot allocate vector of size 2097152 Kb
>  > v1 <- seq(1,2^28)
>  > v2 <- seq(1,2^27)
>  Error: cannot allocate vector of size 524288 Kb
>  > v2 <- seq(1,2^25)
>  > v3 <- seq(1,2^24)
>  > v4 <- seq(1,2^23)
>  > v5 <- seq(1,2^22)
>  Error: cannot allocate vector of size 16384 Kb
>  > v5 <- seq(1,2^21)
>  > v6 <- seq(1,2^20)
>  > v7 <- seq(1,2^19)
>  > v8 <- seq(1,2^18)
>  > q()
>  Save workspace image? [y/n/c]: n
> Upgrading to R 2.3.0 yields the same results.
> This yields an R executable taking 1284M of RAM, refusing to allocate
> more RAM, with about 30Gb free on the machine.


You can tell if you have a 64bit build of R by looking at
.Machine$sizeof.pointer in R, which should be 8.

If not, then you need to set whatever C and Fortran compilation flags give 
a 64bit system. It doesn't look to me as if R's configure script has any 
special handling for C compiler flags on SGI.

If you have a 64bit build then something strange is happening. The message 
you quote happens only when malloc() returns NULL, so it is hard to see 
how R could be causing it, though.

 	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From ripley at stats.ox.ac.uk  Mon May 15 17:09:38 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 15 May 2006 16:09:38 +0100 (BST)
Subject: [Rd] (PR#8861) Memory allocation fails in R 2.2.1 and R 2.3.0
 on SGI Irix, while plenty of memory available
In-Reply-To: <Pine.LNX.4.64.0605150740250.29777@homer23.u.washington.edu>
References: <20060515130956.5B71619B2D@slim.kubism.ku.dk>
	<Pine.LNX.4.64.0605150740250.29777@homer23.u.washington.edu>
Message-ID: <Pine.LNX.4.64.0605151602300.23923@gannet.stats.ox.ac.uk>

(Your reply to R-bugs started a new report, so I am aiming to re-file it.)

On Mon, 15 May 2006, Thomas Lumley wrote:

> On Mon, 15 May 2006, m.vroonhoven at erasmusmc.nl wrote:
>
>> Dear R developers,
>>
>> We have a big SGI Origin computation server with 32 cpu's and 64 Gb of
>> RAM. In R 2.0.0 we could run large jobs, allocating 8 Gb of RAM was not
>> a problem, for example by running:
>> > v1 <- seq(1,2^29)
>> > v2 <- seq(1,2^29)
>> > v3 <- seq(1,2^29)
>> > v4 <- seq(1,2^29)
>> This yields an R process, consuming about 8 Gb of RAM:
>>       PID       PGRP USERNAME PRI  SIZE   RES STATE    TIME WCPU% CPU% COMMAND
>>    177484     177484 mirjam    20 8225M 8217M sleep    1:18  29.3 0.00 R
>>
>> After upgrading from R 2.0.0 to R 2.2.1, we cannot allocate more than
>> about 1300 M of memory, as shown below:
>> > v1 <- seq(1,2^29)
>>  Error: cannot allocate vector of size 2097152 Kb
>> > v1 <- seq(1,2^28)
>> > v2 <- seq(1,2^27)
>>  Error: cannot allocate vector of size 524288 Kb
>> > v2 <- seq(1,2^25)
>> > v3 <- seq(1,2^24)
>> > v4 <- seq(1,2^23)
>> > v5 <- seq(1,2^22)
>>  Error: cannot allocate vector of size 16384 Kb
>> > v5 <- seq(1,2^21)
>> > v6 <- seq(1,2^20)
>> > v7 <- seq(1,2^19)
>> > v8 <- seq(1,2^18)
>> > q()
>>  Save workspace image? [y/n/c]: n
>> Upgrading to R 2.3.0 yields the same results.
>> This yields an R executable taking 1284M of RAM, refusing to allocate
>> more RAM, with about 30Gb free on the machine.
>
>
> You can tell if you have a 64bit build of R by looking at
> .Machine$sizeof.pointer in R, which should be 8.

And if this is a 32-bit build, it is working as expected given the limited 
address space.

> If not, then you need to set whatever C and Fortran compilation flags give
> a 64bit system. It doesn't look to me as if R's configure script has any
> special handling for C compiler flags on SGI.

Well, the R-admin manual says (under IRIX)

   @R{} 2.1.0 has been successfully built on IRIX64 6.5 using both
   @command{gcc} and the native (MipsPro 7.4) compiler. However, neither
   version has passed @command{make check} due to a problem with time
   zones (see below).  A 64-bit executable has not been successfully
   built.

so we could not use special handling for a system we have not been told 
how to build in 64-bit mode.

Here we don't know the OS, the compiler, the flags used .... and that 
definitely is a bug.

> If you have a 64bit build then something strange is happening. The message
> you quote happens only when malloc() returns NULL, so it is hard to see
> how R could be causing it, though.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From sfalcon at fhcrc.org  Mon May 15 17:23:32 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Mon, 15 May 2006 08:23:32 -0700
Subject: [Rd] bindingIsLocked returns illogical logical
In-Reply-To: <Pine.LNX.4.64.0605150803070.8993@gannet.stats.ox.ac.uk> (Brian
	Ripley's message of "Mon, 15 May 2006 08:05:32 +0100 (BST)")
References: <6phody0ct9e.fsf@gopher3.fhcrc.org> <m2lkt3n64e.fsf@ziti.local>
	<Pine.LNX.4.64.0605150803070.8993@gannet.stats.ox.ac.uk>
Message-ID: <m2ves7ia6j.fsf@ziti.local>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> On Sun, 14 May 2006, Seth Falcon wrote:
>> I wonder if ScalarLogical should force 0/1:
>
> Not a good idea: what about the third value, NA?

Indeed, I should have been sleeping (or perhaps I was already :-)

Is it enough to check for NA_LOGICAL or should all NA_* values be
checked for?  Is there an easier/better way to do this sort of check?

Index: Rinlinedfuns.h
===================================================================
--- Rinlinedfuns.h      (revision 38060)
+++ Rinlinedfuns.h      (working copy)
@@ -494,6 +494,8 @@
 INLINE_FUN SEXP ScalarLogical(int x)
 {
     SEXP ans = allocVector(LGLSXP, 1);
+    if ((x != NA_LOGICAL) && (x != 0))
+        x = 1;
     INTEGER(ans)[0] = x;
     return ans;
 }             

Perhaps for completeness, even though at present they are identical,
NA_INTEGER should be in the checking...

INLINE_FUN SEXP ScalarLogical(int x)
{
    SEXP ans = allocVector(LGLSXP, 1);
    if ((x == NA_LOGICAL) || (x == NA_INTEGER))
        x = NA_LOGICAL;
    else if (x != 0)
        x = 1;
     INTEGER(ans)[0] = x;
     return ans;
}

Or perhaps there is a better solution entirely.  

+ seth



>
>> Index: include/Rinlinedfuns.h
>> ===================================================================
>> --- include/Rinlinedfuns.h      (revision 38060)
>> +++ include/Rinlinedfuns.h      (working copy)
>> @@ -494,7 +494,7 @@
>> INLINE_FUN SEXP ScalarLogical(int x)
>> {
>>     SEXP ans = allocVector(LGLSXP, 1);
>> -    INTEGER(ans)[0] = x;
>> +    INTEGER(ans)[0] = (x == 0) ? 0 : 1;
>>     return ans;
>> }
>>
>> Otherwise, I think do_bndIsLocked needs to make a similar operation
>> before calling ScalarLogical.  But preventing these all purpose
>> logicals from escaping would seem to be a good argument for changing
>> ScalarLogical.
>
> I think it needs to handle NAs.
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Mon May 15 17:43:24 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 15 May 2006 16:43:24 +0100 (BST)
Subject: [Rd] bindingIsLocked returns illogical logical
In-Reply-To: <m2ves7ia6j.fsf@ziti.local>
References: <6phody0ct9e.fsf@gopher3.fhcrc.org> <m2lkt3n64e.fsf@ziti.local>
	<Pine.LNX.4.64.0605150803070.8993@gannet.stats.ox.ac.uk>
	<m2ves7ia6j.fsf@ziti.local>
Message-ID: <Pine.LNX.4.64.0605151639280.29105@gannet.stats.ox.ac.uk>

On Mon, 15 May 2006, Seth Falcon wrote:

> Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:
>
>> On Sun, 14 May 2006, Seth Falcon wrote:
>>> I wonder if ScalarLogical should force 0/1:
>>
>> Not a good idea: what about the third value, NA?
>
> Indeed, I should have been sleeping (or perhaps I was already :-)
>
> Is it enough to check for NA_LOGICAL or should all NA_* values be
> checked for?  Is there an easier/better way to do this sort of check?

NA_LOGICAL and NA_INTEGER are the same value, and only NA_LOGICAL should 
occur here.  I used

/* As from R 2.4.0 we check that the value is allowed. */
INLINE_FUN SEXP ScalarLogical(int x)
{
     SEXP ans = allocVector(LGLSXP, 1);
     if (x == NA_LOGICAL) INTEGER(ans)[0] = NA_LOGICAL;
     else INTEGER(ans)[0] = (x != 0);
     return ans;
}

mainly because its intentions are crystal clear.

>
> Index: Rinlinedfuns.h
> ===================================================================
> --- Rinlinedfuns.h      (revision 38060)
> +++ Rinlinedfuns.h      (working copy)
> @@ -494,6 +494,8 @@
> INLINE_FUN SEXP ScalarLogical(int x)
> {
>     SEXP ans = allocVector(LGLSXP, 1);
> +    if ((x != NA_LOGICAL) && (x != 0))
> +        x = 1;
>     INTEGER(ans)[0] = x;
>     return ans;
> }
>
> Perhaps for completeness, even though at present they are identical,
> NA_INTEGER should be in the checking...
>
> INLINE_FUN SEXP ScalarLogical(int x)
> {
>    SEXP ans = allocVector(LGLSXP, 1);
>    if ((x == NA_LOGICAL) || (x == NA_INTEGER))
>        x = NA_LOGICAL;
>    else if (x != 0)
>        x = 1;
>     INTEGER(ans)[0] = x;
>     return ans;
> }
>
> Or perhaps there is a better solution entirely.
>
> + seth
>
>
>
>>
>>> Index: include/Rinlinedfuns.h
>>> ===================================================================
>>> --- include/Rinlinedfuns.h      (revision 38060)
>>> +++ include/Rinlinedfuns.h      (working copy)
>>> @@ -494,7 +494,7 @@
>>> INLINE_FUN SEXP ScalarLogical(int x)
>>> {
>>>     SEXP ans = allocVector(LGLSXP, 1);
>>> -    INTEGER(ans)[0] = x;
>>> +    INTEGER(ans)[0] = (x == 0) ? 0 : 1;
>>>     return ans;
>>> }
>>>
>>> Otherwise, I think do_bndIsLocked needs to make a similar operation
>>> before calling ScalarLogical.  But preventing these all purpose
>>> logicals from escaping would seem to be a good argument for changing
>>> ScalarLogical.
>>
>> I think it needs to handle NAs.
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From m.vroonhoven at erasmusmc.nl  Mon May 15 17:54:04 2006
From: m.vroonhoven at erasmusmc.nl (Mirjam van Vroonhoven)
Date: Mon, 15 May 2006 17:54:04 +0200
Subject: [Rd] (PR#8861) Memory allocation fails in R 2.2.1 and R 2.3.0
	on SGI Irix, while plenty of memory available
In-Reply-To: <Pine.LNX.4.64.0605151602300.23923@gannet.stats.ox.ac.uk>
References: <20060515130956.5B71619B2D@slim.kubism.ku.dk>
	<Pine.LNX.4.64.0605150740250.29777@homer23.u.washington.edu>
	<Pine.LNX.4.64.0605151602300.23923@gannet.stats.ox.ac.uk>
Message-ID: <20060515155403.GJ6479@bioinf-235-161.pc.fgg.eur.nl>

Prof Brian Ripley wrote on Mon, May 15, 2006 at 04:09:38PM +0100:
> >You can tell if you have a 64bit build of R by looking at
> >.Machine$sizeof.pointer in R, which should be 8.
> 
> And if this is a 32-bit build, it is working as expected given the limited 
> address space.

It is a 32 bit build. My R 2.0.0 is a 64bit build.

> >If not, then you need to set whatever C and Fortran compilation flags give
> >a 64bit system. It doesn't look to me as if R's configure script has any
> >special handling for C compiler flags on SGI.
> 
> Well, the R-admin manual says (under IRIX)
> 
>   @R{} 2.1.0 has been successfully built on IRIX64 6.5 using both
>   @command{gcc} and the native (MipsPro 7.4) compiler. However, neither
>   version has passed @command{make check} due to a problem with time
>   zones (see below).  A 64-bit executable has not been successfully
>   built.
> 
> so we could not use special handling for a system we have not been told 
> how to build in 64-bit mode.
> 
> Here we don't know the OS, the compiler, the flags used .... and that 
> definitely is a bug.

The OS is irix 6.5.27, compiler = gcc, no special flags.

But that is no different from what I recall to have done when building
R 2.0.0 a long time ago.

I'll try to find out how to build a 64 bit executable, and see wether it
works. Probably that is easier using the native mipspro compiler.
Will report back to you guys when I find out a way to build a working
64bit R 2.3.0 on SGI/irix64

Thanks for the time,

                                                Mirjam

-- 
Dr. Mirjam van Vroonhoven
	system administrator/programmer, dept. of Bioinformatics
	Erasmus Medical Center, Rotterdam, The Netherlands
	Room Number Ee 15.32, phone +31-10-463 81 11
Web: 	http://www.erasmusmc.nl/bioinformatics/
E-mail: m.vroonhoven at erasmusmc.nl


From sfalcon at fhcrc.org  Mon May 15 18:28:31 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Mon, 15 May 2006 09:28:31 -0700
Subject: [Rd] bindingIsLocked returns illogical logical
In-Reply-To: <Pine.LNX.4.64.0605151639280.29105@gannet.stats.ox.ac.uk> (Brian
	Ripley's message of "Mon, 15 May 2006 16:43:24 +0100 (BST)")
References: <6phody0ct9e.fsf@gopher3.fhcrc.org> <m2lkt3n64e.fsf@ziti.local>
	<Pine.LNX.4.64.0605150803070.8993@gannet.stats.ox.ac.uk>
	<m2ves7ia6j.fsf@ziti.local>
	<Pine.LNX.4.64.0605151639280.29105@gannet.stats.ox.ac.uk>
Message-ID: <m2zmhjgsls.fsf@ziti.local>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> On Mon, 15 May 2006, Seth Falcon wrote:
>> Is it enough to check for NA_LOGICAL or should all NA_* values be
>> checked for?  Is there an easier/better way to do this sort of check?
>
> NA_LOGICAL and NA_INTEGER are the same value, and only NA_LOGICAL
> should occur here.  

Makes sense (I knew that NA_LOGICAL and NA_INTEGER are the same, but I
didn't know whether this was a convenience or to allow for them to be
different in the future).

> I used
>
> /* As from R 2.4.0 we check that the value is allowed. */
> INLINE_FUN SEXP ScalarLogical(int x)
> {
>      SEXP ans = allocVector(LGLSXP, 1);
>      if (x == NA_LOGICAL) INTEGER(ans)[0] = NA_LOGICAL;
>      else INTEGER(ans)[0] = (x != 0);
>      return ans;
> }
>
> mainly because its intentions are crystal clear.

Agreed.  Thanks for fixing this so quickly and for the
reminders/answers regarding NA handling.

Best,

+ seth


From pinard at iro.umontreal.ca  Tue May 16 01:35:29 2006
From: pinard at iro.umontreal.ca (pinard at iro.umontreal.ca)
Date: Tue, 16 May 2006 01:35:29 +0200 (CEST)
Subject: [Rd] Truncated labels in hist (PR#8864)
Message-ID: <20060515233529.D3223ECD9@slim.kubism.ku.dk>

Hi, people.  Executing the following command:

   hist(rpois(100,5), labels=TRUE)

yields a graphic in which some labels are truncated (on an X11 device).
The truncated labels are those over the highest bars.  The hist function
should ideally manage enough room for the labels, automatically.
(Specifying ylim solves my problem, but yet, hist could be frienlier.)

--please do not edit the information below--

Version:
 platform = x86_64-unknown-linux-gnu
 arch = x86_64
 os = linux-gnu
 system = x86_64, linux-gnu
 status = 
 major = 2
 minor = 3.0
 year = 2006
 month = 04
 day = 24
 svn rev = 37909
 language = R
 version.string = Version 2.3.0 (2006-04-24)

Locale:
LC_CTYPE=fr_CA.UTF-8;LC_NUMERIC=C;LC_TIME=fr_CA.UTF-8;LC_COLLATE=fr_CA.UTF-8;LC_MONETARY=fr_CA.UTF-8;LC_MESSAGES=fr_CA.UTF-8;LC_PAPER=C;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=C;LC_IDENTIFICATION=C

Search Path:
 .GlobalEnv, package:methods, package:stats, package:graphics, package:utils, package:datasets, fp.etc, package:grDevices, Autoloads, package:base

-- 
Fran??ois Pinard   http://pinard.progiciels-bpi.ca


From mtmorgan at fhcrc.org  Tue May 16 01:40:49 2006
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Mon, 15 May 2006 16:40:49 -0700
Subject: [Rd] R CMD check does not remove all S4 methods defined in examples
Message-ID: <6phslna501q.fsf@gopher3.fhcrc.org>

Methods for generics created in '\example{}' sections of Rd files are
not entirely removed at the end of the example. This is because the
methods package caches these (in the environment returned by
getGeneric("initialize"), for the example below) as well as storing
their definition in the global environment.

The following would be derived from example code in pkg/man/eg1.Rd and
pkg/man/eg2.Rd. 'initialize' created for the first example persists in
the second, leading eventually (during R CMD check) to

> a <- new("A")
Shouldn't be here
Error in initialize(value, ...) : initialize method returned an object of class "NULL" instead of the required class "A"

[standard code and comments from pkg-Ex.R removed]
### * eg1

flush(stderr()); flush(stdout())

setClass("A", representation(x="numeric"))
setMethod("initialize", "A",
          function(.Object, ...) cat("Shouldn't be here\n"))

cleanEx(); ..nameEx <- "eg2"

### * eg2

flush(stderr()); flush(stdout())

setClass("A", representation(x="numeric"))
a <- new("A")


From murdoch at stats.uwo.ca  Tue May 16 02:41:09 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 15 May 2006 20:41:09 -0400
Subject: [Rd] Truncated labels in hist (PR#8864)
In-Reply-To: <20060515233529.D3223ECD9@slim.kubism.ku.dk>
References: <20060515233529.D3223ECD9@slim.kubism.ku.dk>
Message-ID: <44691FA5.7040807@stats.uwo.ca>

On 5/15/2006 7:35 PM, pinard at iro.umontreal.ca wrote:
> Hi, people.  Executing the following command:
> 
>    hist(rpois(100,5), labels=TRUE)
> 
> yields a graphic in which some labels are truncated (on an X11 device).
> The truncated labels are those over the highest bars.  The hist function
> should ideally manage enough room for the labels, automatically.
> (Specifying ylim solves my problem, but yet, hist could be frienlier.)

I don't see this on Windows using windows(), or Linux using X11().  I 
imagine it's a case that the device isn't reporting the size of fonts 
properly, and since my X server shows things properly, I would guess 
it's a problem with your X server, not with R.

Duncan Murdoch

> 
> --please do not edit the information below--
> 
> Version:
>  platform = x86_64-unknown-linux-gnu
>  arch = x86_64
>  os = linux-gnu
>  system = x86_64, linux-gnu
>  status = 
>  major = 2
>  minor = 3.0
>  year = 2006
>  month = 04
>  day = 24
>  svn rev = 37909
>  language = R
>  version.string = Version 2.3.0 (2006-04-24)
> 
> Locale:
> LC_CTYPE=fr_CA.UTF-8;LC_NUMERIC=C;LC_TIME=fr_CA.UTF-8;LC_COLLATE=fr_CA.UTF-8;LC_MONETARY=fr_CA.UTF-8;LC_MESSAGES=fr_CA.UTF-8;LC_PAPER=C;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=C;LC_IDENTIFICATION=C
> 
> Search Path:
>  .GlobalEnv, package:methods, package:stats, package:graphics, package:utils, package:datasets, fp.etc, package:grDevices, Autoloads, package:base
>


From ripley at stats.ox.ac.uk  Tue May 16 09:53:40 2006
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Tue, 16 May 2006 09:53:40 +0200 (CEST)
Subject: [Rd] optim "CG" bug w/patch proposal (PR#8786)
Message-ID: <20060516075340.C2D4524795@slim.kubism.ku.dk>

[Sorry for the belated reply: this came in just as I was leaving for a 
trip.]

I've checked the original source, and the C code in optim does accurately 
reflect the published algorithm.

Since your example is a discontinuous function, I don't see why you expect 
CG to work on it.  John Nash reports on his extensive experience that 
method 3 is the worst, and I don't think we should let a single 2D example 
of a badly-behaved function override that.

Note that no other optim method copes with the discontiuity here: had your 
reported that it would have been clear that the problem was with the 
example.

On Fri, 21 Apr 2006, westfeld at inf.tu-dresden.de wrote:

> Dear R team,
>
> when using optim with method "CG" I got the wrong $value for the
> reported $par.
>
> Example:
> f<-function(p) {
>        if (!all(p>-.7)) return(2)
>        if (!all(p<.7)) return(2)
>        sin((p[1])^2)*sin(p[2])
> }
> optim(c(0.1,-0.1),f,method="CG",control=list(trace=0,type=1))
> $par 19280.68 -10622.32
> $value -0.2346207 # should be 2!
>
> optim(c(0.1,-0.1),f,method="CG",control=list(trace=0,type=2))
> $par 3834.021 -2718.958
> $value -0.0009983175 # should be 2!
>
> Fix:
> --- optim.c     (Revision 37878)
> +++ optim.c     (Arbeitskopie)
> @@ -970,7 +970,8 @@
>                            if (!accpoint) {
>                                steplength *= stepredn;
>                                if (trace) Rprintf("*");
> -                           }
> +                           } else
> +                               *Fmin = f;
>                        }
>                    } while (!(count == n || accpoint));
>                    if (count < n) {
>
> After fix:
> optim(c(0.1,-0.1),f,method="CG",control=list(trace=0,type=1))
> $par 0.6993467 -0.4900145
> $value -0.2211150
> optim(c(0.1,-0.1),f,method="CG",control=list(trace=0,type=2))
> $par 3834.021 -2718.958
> $value 2
>
> Wishlist:
>
> 1. Please make type=3 the default in optim (it is more robust).
>
> 2. The $par reported for type=2 is still not satisfactory. I found out
> that this can be improved by limiting G3 to a maximum of about 2000
> (maybe even smaller). However, I'm not a "CG" expert and can live with a
> suboptimal result.
>
> --- optim.c     (Revision 37878)
> +++ optim.c     (Arbeitskopie)
> @@ -946,6 +946,8 @@
>                        G3 = G1 / G2;
>                    else
>                        G3 = 1.0;
> +                   if (G3 > 2e3)
> +                       G3 = 2e3;
>                    gradproj = 0.0;
>                    for (i = 0; i < n; i++) {
>                        t[i] = t[i] * G3 - g[i];
>
> Andreas
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From westfeld at inf.tu-dresden.de  Tue May 16 10:56:22 2006
From: westfeld at inf.tu-dresden.de (westfeld at inf.tu-dresden.de)
Date: Tue, 16 May 2006 10:56:22 +0200 (CEST)
Subject: [Rd] optim "CG" bug w/patch proposal (PR#8786)
Message-ID: <20060516085622.85A7D3F0AD@slim.kubism.ku.dk>

Probably I included too much at once in my bug report. I can live with
an unfulfilled wishlist and thank you for thinking about it. The
"badly-behaved" function is just an example to demonstrate the bug I
reported. I think it is a bug if optim returns (without any warning) an
unmatching pair of par and value: f(par) != value. And it is easily fixed.

Andreas

Prof Brian Ripley wrote:

> [Sorry for the belated reply: this came in just as I was leaving for a
> trip.]
>
> I've checked the original source, and the C code in optim does
> accurately reflect the published algorithm.
>
> Since your example is a discontinuous function, I don't see why you
> expect CG to work on it.  John Nash reports on his extensive
> experience that method 3 is the worst, and I don't think we should let
> a single 2D example of a badly-behaved function override that.
>
> Note that no other optim method copes with the discontiuity here: had
> your reported that it would have been clear that the problem was with
> the example.
>
> On Fri, 21 Apr 2006, westfeld at inf.tu-dresden.de wrote:
>
>> Dear R team,
>>
>> when using optim with method "CG" I got the wrong $value for the
>> reported $par.
>>
>> Example:
>> f<-function(p) {
>>        if (!all(p>-.7)) return(2)
>>        if (!all(p<.7)) return(2)
>>        sin((p[1])^2)*sin(p[2])
>> }
>> optim(c(0.1,-0.1),f,method="CG",control=list(trace=0,type=1))
>> $par 19280.68 -10622.32
>> $value -0.2346207 # should be 2!
>>
>> optim(c(0.1,-0.1),f,method="CG",control=list(trace=0,type=2))
>> $par 3834.021 -2718.958
>> $value -0.0009983175 # should be 2!
>>
>> Fix:
>> --- optim.c     (Revision 37878)
>> +++ optim.c     (Arbeitskopie)
>> @@ -970,7 +970,8 @@
>>                            if (!accpoint) {
>>                                steplength *= stepredn;
>>                                if (trace) Rprintf("*");
>> -                           }
>> +                           } else
>> +                               *Fmin = f;
>>                        }
>>                    } while (!(count == n || accpoint));
>>                    if (count < n) {
>>
>> After fix:
>> optim(c(0.1,-0.1),f,method="CG",control=list(trace=0,type=1))
>> $par 0.6993467 -0.4900145
>> $value -0.2211150
>> optim(c(0.1,-0.1),f,method="CG",control=list(trace=0,type=2))
>> $par 3834.021 -2718.958
>> $value 2
>>
>> Wishlist: 
>
[wishlist deleted]


-- 
Andreas Westfeld, 0432 01CC F511 9E2B 0B57 5993 0B22 98F8 4AD8 EEEA
<westfeld at inf.tu-dresden.de> http://www.inf.tu-dresden.de/~aw4
TU Dresden Fakult?t Informatik, Institut f?r Systemarchitektur
Datenschutz und Datensicherheit, Tel. +49-351-463-37918


From hin-tak.leung at cimr.cam.ac.uk  Tue May 16 11:45:04 2006
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Tue, 16 May 2006 10:45:04 +0100
Subject: [Rd] (PR#8861) Memory allocation fails in R 2.2.1 and R 2.3.0
 on SGI Irix, while plenty of memory available
In-Reply-To: <20060515155403.GJ6479@bioinf-235-161.pc.fgg.eur.nl>
References: <20060515130956.5B71619B2D@slim.kubism.ku.dk>	<Pine.LNX.4.64.0605150740250.29777@homer23.u.washington.edu>	<Pine.LNX.4.64.0605151602300.23923@gannet.stats.ox.ac.uk>
	<20060515155403.GJ6479@bioinf-235-161.pc.fgg.eur.nl>
Message-ID: <44699F20.9070706@cimr.cam.ac.uk>

On a solaris 9 box here, gcc 3.4.2 defaults to build 32-bit binaries for 
some unknown reason, but can be pursuaded to build 64-bit executables
by passing the -m64 switch explicitly. (this is first hand experience, 
discovered while looking into a similiar anomaly with another piece
of software). I think gcc on early version of Mac OS X (10.2?) has
a similiar behavior also of defaulting to 32-bit unless told otherwise,
but can be pursuaded. Maybe gcc on IRIS can be similiarly pursuaded
too?

gcc -v
Reading specs from /usr/local/lib/gcc/sparc-sun-solaris2.9/3.4.2/specs
Configured with: ../configure --with-as=/usr/ccs/bin/as 
--with-ld=/usr/ccs/bin/ld --disable-nls

Mirjam van Vroonhoven wrote:
> Prof Brian Ripley wrote on Mon, May 15, 2006 at 04:09:38PM +0100:
>>> You can tell if you have a 64bit build of R by looking at
>>> .Machine$sizeof.pointer in R, which should be 8.
>> And if this is a 32-bit build, it is working as expected given the limited 
>> address space.
> 
> It is a 32 bit build. My R 2.0.0 is a 64bit build.
> 
>>> If not, then you need to set whatever C and Fortran compilation flags give
>>> a 64bit system. It doesn't look to me as if R's configure script has any
>>> special handling for C compiler flags on SGI.
>> Well, the R-admin manual says (under IRIX)
>>
>>   @R{} 2.1.0 has been successfully built on IRIX64 6.5 using both
>>   @command{gcc} and the native (MipsPro 7.4) compiler. However, neither
>>   version has passed @command{make check} due to a problem with time
>>   zones (see below).  A 64-bit executable has not been successfully
>>   built.
>>
>> so we could not use special handling for a system we have not been told 
>> how to build in 64-bit mode.
>>
>> Here we don't know the OS, the compiler, the flags used .... and that 
>> definitely is a bug.
> 
> The OS is irix 6.5.27, compiler = gcc, no special flags.
> 
> But that is no different from what I recall to have done when building
> R 2.0.0 a long time ago.
> 
> I'll try to find out how to build a 64 bit executable, and see wether it
> works. Probably that is easier using the native mipspro compiler.
> Will report back to you guys when I find out a way to build a working
> 64bit R 2.3.0 on SGI/irix64
> 
> Thanks for the time,
> 
>                                                 Mirjam
>


From ripley at stats.ox.ac.uk  Tue May 16 11:39:33 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 16 May 2006 10:39:33 +0100 (BST)
Subject: [Rd] (PR#8861) Memory allocation fails in R 2.2.1 and R 2.3.0
 on SGI Irix, while plenty of memory available
In-Reply-To: <44699F20.9070706@cimr.cam.ac.uk>
References: <20060515130956.5B71619B2D@slim.kubism.ku.dk>
	<Pine.LNX.4.64.0605150740250.29777@homer23.u.washington.edu>
	<Pine.LNX.4.64.0605151602300.23923@gannet.stats.ox.ac.uk>
	<20060515155403.GJ6479@bioinf-235-161.pc.fgg.eur.nl>
	<44699F20.9070706@cimr.cam.ac.uk>
Message-ID: <Pine.LNX.4.64.0605161031380.8297@gannet.stats.ox.ac.uk>

On Tue, 16 May 2006, Hin-Tak Leung wrote:

> On a solaris 9 box here, gcc 3.4.2 defaults to build 32-bit binaries for some 
> unknown reason,

Actually, for a well-documented reason.  (You need both a suitable CPU and 
the appropriate parts of the OS installed for 64-bit binaries to be 
usable, and you need to be working on large structures for them to be 
desirable.)

BTW, g77 3.4.2 is broken, so please don't use it to build R.

> but can be pursuaded to build 64-bit executables by passing the -m64 
> switch explicitly. (this is first hand experience, discovered while 
> looking into a similiar anomaly with another piece of software). I think 
> gcc on early version of Mac OS X (10.2?) has

Really?  It is documented explicitly on the gcc man page and in the 
R-admin manual.

However, on Solaris there is more to this than using -m64, and that too is 
documented in the R-admin manual: you need to ensure that you get 64-bit 
libraries.

> a similiar behavior also of defaulting to 32-bit unless told otherwise,
> but can be pursuaded. Maybe gcc on IRIS can be similiarly pursuaded
> too?
>
> gcc -v
> Reading specs from /usr/local/lib/gcc/sparc-sun-solaris2.9/3.4.2/specs
> Configured with: ../configure --with-as=/usr/ccs/bin/as 
> --with-ld=/usr/ccs/bin/ld --disable-nls
>
> Mirjam van Vroonhoven wrote:
>> Prof Brian Ripley wrote on Mon, May 15, 2006 at 04:09:38PM +0100:
>>>> You can tell if you have a 64bit build of R by looking at
>>>> .Machine$sizeof.pointer in R, which should be 8.
>>> And if this is a 32-bit build, it is working as expected given the limited 
>>> address space.
>> 
>> It is a 32 bit build. My R 2.0.0 is a 64bit build.
>> 
>>>> If not, then you need to set whatever C and Fortran compilation flags 
>>>> give
>>>> a 64bit system. It doesn't look to me as if R's configure script has any
>>>> special handling for C compiler flags on SGI.
>>> Well, the R-admin manual says (under IRIX)
>>>
>>>   @R{} 2.1.0 has been successfully built on IRIX64 6.5 using both
>>>   @command{gcc} and the native (MipsPro 7.4) compiler. However, neither
>>>   version has passed @command{make check} due to a problem with time
>>>   zones (see below).  A 64-bit executable has not been successfully
>>>   built.
>>> 
>>> so we could not use special handling for a system we have not been told 
>>> how to build in 64-bit mode.
>>> 
>>> Here we don't know the OS, the compiler, the flags used .... and that 
>>> definitely is a bug.
>> 
>> The OS is irix 6.5.27, compiler = gcc, no special flags.
>> 
>> But that is no different from what I recall to have done when building
>> R 2.0.0 a long time ago.
>> 
>> I'll try to find out how to build a 64 bit executable, and see wether it
>> works. Probably that is easier using the native mipspro compiler.
>> Will report back to you guys when I find out a way to build a working
>> 64bit R 2.3.0 on SGI/irix64
>> 
>> Thanks for the time,
>>
>>                                                 Mirjam
>> 
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pinard at iro.umontreal.ca  Tue May 16 14:29:32 2006
From: pinard at iro.umontreal.ca (=?iso-8859-1?Q?Fran=E7ois?= Pinard)
Date: Tue, 16 May 2006 08:29:32 -0400
Subject: [Rd] Truncated labels in hist (PR#8864)
In-Reply-To: <44691FA5.7040807@stats.uwo.ca>
References: <20060515233529.D3223ECD9@slim.kubism.ku.dk>
	<44691FA5.7040807@stats.uwo.ca>
Message-ID: <20060516122932.GA10873@alcyon.progiciels-bpi.ca>

[Duncan Murdoch]
>[Fran?ois Pinard]
>> Hi, people.  Executing the following command:
>>    hist(rpois(100,5), labels=TRUE)
>> yields a graphic in which some labels are truncated (on an X11 

> I don't see this on Windows using windows(), or Linux using X11().  
> I imagine it's a case that the device isn't reporting the size of 
> fonts properly, and since my X server shows things properly, I would 
> guess it's a problem with your X server, not with R.

Thanks a lot, Duncan, for checking on your side, and replying.  I'll try 
to explore if something is wrong here, that I could understand :-).

-- 
Fran?ois Pinard   http://pinard.progiciels-bpi.ca


From murdoch at stats.uwo.ca  Tue May 16 14:34:06 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 16 May 2006 08:34:06 -0400
Subject: [Rd] optim "CG" bug w/patch proposal (PR#8786)
In-Reply-To: <20060516085622.85A7D3F0AD@slim.kubism.ku.dk>
References: <20060516085622.85A7D3F0AD@slim.kubism.ku.dk>
Message-ID: <4469C6BE.5030306@stats.uwo.ca>

On 5/16/2006 4:56 AM, westfeld at inf.tu-dresden.de wrote:
> Probably I included too much at once in my bug report. I can live with
> an unfulfilled wishlist and thank you for thinking about it. The
> "badly-behaved" function is just an example to demonstrate the bug I
> reported. I think it is a bug if optim returns (without any warning) an
> unmatching pair of par and value: f(par) != value. And it is easily fixed.

I agree with you that on return f(par) should be value.  I agree with 
Brian that changes to the underlying strategy need much more thought.

Duncan Murdoch

> 
> Andreas
> 
> Prof Brian Ripley wrote:
> 
>> [Sorry for the belated reply: this came in just as I was leaving for a
>> trip.]
>>
>> I've checked the original source, and the C code in optim does
>> accurately reflect the published algorithm.
>>
>> Since your example is a discontinuous function, I don't see why you
>> expect CG to work on it.  John Nash reports on his extensive
>> experience that method 3 is the worst, and I don't think we should let
>> a single 2D example of a badly-behaved function override that.
>>
>> Note that no other optim method copes with the discontiuity here: had
>> your reported that it would have been clear that the problem was with
>> the example.
>>
>> On Fri, 21 Apr 2006, westfeld at inf.tu-dresden.de wrote:
>>
>>> Dear R team,
>>>
>>> when using optim with method "CG" I got the wrong $value for the
>>> reported $par.
>>>
>>> Example:
>>> f<-function(p) {
>>>        if (!all(p>-.7)) return(2)
>>>        if (!all(p<.7)) return(2)
>>>        sin((p[1])^2)*sin(p[2])
>>> }
>>> optim(c(0.1,-0.1),f,method="CG",control=list(trace=0,type=1))
>>> $par 19280.68 -10622.32
>>> $value -0.2346207 # should be 2!
>>>
>>> optim(c(0.1,-0.1),f,method="CG",control=list(trace=0,type=2))
>>> $par 3834.021 -2718.958
>>> $value -0.0009983175 # should be 2!
>>>
>>> Fix:
>>> --- optim.c     (Revision 37878)
>>> +++ optim.c     (Arbeitskopie)
>>> @@ -970,7 +970,8 @@
>>>                            if (!accpoint) {
>>>                                steplength *= stepredn;
>>>                                if (trace) Rprintf("*");
>>> -                           }
>>> +                           } else
>>> +                               *Fmin = f;
>>>                        }
>>>                    } while (!(count == n || accpoint));
>>>                    if (count < n) {
>>>
>>> After fix:
>>> optim(c(0.1,-0.1),f,method="CG",control=list(trace=0,type=1))
>>> $par 0.6993467 -0.4900145
>>> $value -0.2211150
>>> optim(c(0.1,-0.1),f,method="CG",control=list(trace=0,type=2))
>>> $par 3834.021 -2718.958
>>> $value 2
>>>
>>> Wishlist: 
>>
> [wishlist deleted]
> 
>


From brandon.barker at gmail.com  Tue May 16 15:25:33 2006
From: brandon.barker at gmail.com (Brandon Barker)
Date: Tue, 16 May 2006 09:25:33 -0400
Subject: [Rd] Cofnigure (Building) trouble
Message-ID: <3e078a5e0605160625r5d3571ccnb22b4258f83c0c85@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060516/9f999bc8/attachment.pl 

From ripley at stats.ox.ac.uk  Tue May 16 15:45:09 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 16 May 2006 14:45:09 +0100 (BST)
Subject: [Rd] Problems on SuSE 10.1 (was Cofnigure (Building) trouble)
In-Reply-To: <3e078a5e0605160625r5d3571ccnb22b4258f83c0c85@mail.gmail.com>
References: <3e078a5e0605160625r5d3571ccnb22b4258f83c0c85@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0605161441010.30844@gannet.stats.ox.ac.uk>

On Tue, 16 May 2006, Brandon Barker wrote:

> Hi, I'm trying to build R on SuSE 10.1/x86_64.  I had to download fortran as
> it wasn't supplied by SuSE.  Octave, which also uses both C and Fortran was
> able to compile w/o trouble.  The problem I run in to with R is the
> following.  R's configure script will complain that it can't find the
> fortran libraries (octave didn't give this complaint).  When I specify them
> using LDFLAGS, for some reason this causes the C test to fail (even though I
> can still use gcc w/o trouble):
>
> brandon at dell:~/R-2.3.0> export LDFLAGS=/usr/local/fortran/lib64

This should be -L/usr/local/fortran/lib64, and that error causes R's build 
command to be invalid.

Please note that this is covered in the R-admin manual which the INSTALL 
file asked you to read (instead of asking other people to read it for 
you).

> brandon at dell:~/R-2.3.0> echo $LDFLAGS
> /usr/local/fortran/lib64
> brandon at dell:~/R-2.3.0> export F77=/usr/local/fortran/bin/gfortran
> ...
> checking for C compiler default output file name... configure: error: C
> compiler cannot create executables
> See `config.log' for more details.
>
> I've put up my config.log at http://sweb.uky.edu/~bebark2/config.log
>
> Thanks in advance for the advice.
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Tue May 16 19:03:18 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 16 May 2006 18:03:18 +0100 (BST)
Subject: [Rd] R CMD SHLIB
Message-ID: <Pine.LNX.4.64.0605161737400.20542@gannet.stats.ox.ac.uk>

It is possible to do things like

 	env PKG_LIB="-L/opt/foo/lib -lbar" R CMD SHLIB *.c

to add libraries to the creation of a shared object, but I have from time 
to time wondered if we should allow

 	R CMD SHLIB *.c -L/opt/foo/lib -lbar

not least as users seems to expect it to work.  It looks simple to do (at 
least under Unix) if we pass -L* -l* *.a directly to the link command.

Would this be worthwhile?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tlumley at u.washington.edu  Tue May 16 19:15:11 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 16 May 2006 10:15:11 -0700 (PDT)
Subject: [Rd] R CMD SHLIB
In-Reply-To: <Pine.LNX.4.64.0605161737400.20542@gannet.stats.ox.ac.uk>
References: <Pine.LNX.4.64.0605161737400.20542@gannet.stats.ox.ac.uk>
Message-ID: <Pine.LNX.4.64.0605161013270.30229@homer22.u.washington.edu>

On Tue, 16 May 2006, Prof Brian Ripley wrote:

> It is possible to do things like
>
> 	env PKG_LIB="-L/opt/foo/lib -lbar" R CMD SHLIB *.c
>
> to add libraries to the creation of a shared object, but I have from time
> to time wondered if we should allow
>
> 	R CMD SHLIB *.c -L/opt/foo/lib -lbar
>
> not least as users seems to expect it to work.  It looks simple to do (at
> least under Unix) if we pass -L* -l* *.a directly to the link command.
>
> Would this be worthwhile?

Yes.

My only reservation is that users may then expect all compiler/linker 
flags to work, not just -L/-l

 	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From rafalku at gmail.com  Tue May 16 21:50:31 2006
From: rafalku at gmail.com (rafalku at gmail.com)
Date: Tue, 16 May 2006 21:50:31 +0200 (CEST)
Subject: [Rd] bug in rbind.data.frame with factors (PR#8868)
Message-ID: <20060516195031.28119494DB@slim.kubism.ku.dk>

Full_Name: Rafal Kustra
Version: 2.1.1
OS: Linux, MacOS 10.3
Submission from: (NULL) (69.195.47.62)


When Rbinding two data frames with factors, strange result occur (but no error)
when the order of data frame variables is different in two data frames:

> d1=as.data.frame(list(x=1:10,y=letters[1:10]))
> d2=as.data.frame(list(y=LETTERS[1:5],x=7:11))
> d2
  y  x
1 A  7
2 B  8
3 C  9
4 D 10
5 E 11
> rbind(d1,d2)
    x    y
1   1    a
2   2    b
3   3    c
4   4    d
5   5    e
6   6    f
7   7    g
8   8    h
9   9    i
10 10    j
11  7 <NA>
21  8 <NA>
31  9 <NA>
41 10 <NA>
51 11 <NA>
Warning message:
invalid factor level, NAs generated in: "[<-.factor"(`*tmp*`, ri, value = c("A",
"B", "C", "D", "E")) 


Things work correctly when the order of variables is the same:

> d3=as.data.frame(list(x=7:11,y=LETTERS[1:5]))
> rbind(d1,d3)
    x y
1   1 a
2   2 b
3   3 c
4   4 d
5   5 e
6   6 f
7   7 g
8   8 h
9   9 i
10 10 j
11  7 A
21  8 B
31  9 C
41 10 D
51 11 E
>


From ehlers at math.ucalgary.ca  Tue May 16 23:24:53 2006
From: ehlers at math.ucalgary.ca (Peter Ehlers)
Date: Tue, 16 May 2006 15:24:53 -0600
Subject: [Rd] bug in rbind.data.frame with factors (PR#8868)
In-Reply-To: <20060516195031.28119494DB@slim.kubism.ku.dk>
References: <20060516195031.28119494DB@slim.kubism.ku.dk>
Message-ID: <446A4325.3080609@math.ucalgary.ca>

How is this a bug? From the help page for cbind/rbind:

Description
Take a sequence of vector, matrix or data frames arguments and
combine by _columns_ or _rows_, respectively.
(emphasis added)

Note that it does _not_ say "combine by variable names".

Peter Ehlers

rafalku at gmail.com wrote:

> Full_Name: Rafal Kustra
> Version: 2.1.1
> OS: Linux, MacOS 10.3
> Submission from: (NULL) (69.195.47.62)
> 
> 
> When Rbinding two data frames with factors, strange result occur (but no error)
> when the order of data frame variables is different in two data frames:
> 
> 
>>d1=as.data.frame(list(x=1:10,y=letters[1:10]))
>>d2=as.data.frame(list(y=LETTERS[1:5],x=7:11))
>>d2
> 
>   y  x
> 1 A  7
> 2 B  8
> 3 C  9
> 4 D 10
> 5 E 11
> 
>>rbind(d1,d2)
> 
>     x    y
> 1   1    a
> 2   2    b
> 3   3    c
> 4   4    d
> 5   5    e
> 6   6    f
> 7   7    g
> 8   8    h
> 9   9    i
> 10 10    j
> 11  7 <NA>
> 21  8 <NA>
> 31  9 <NA>
> 41 10 <NA>
> 51 11 <NA>
> Warning message:
> invalid factor level, NAs generated in: "[<-.factor"(`*tmp*`, ri, value = c("A",
> "B", "C", "D", "E")) 
> 
> 
> Things work correctly when the order of variables is the same:
> 
> 
>>d3=as.data.frame(list(x=7:11,y=LETTERS[1:5]))
>>rbind(d1,d3)
> 
>     x y
> 1   1 a
> 2   2 b
> 3   3 c
> 4   4 d
> 5   5 e
> 6   6 f
> 7   7 g
> 8   8 h
> 9   9 i
> 10 10 j
> 11  7 A
> 21  8 B
> 31  9 C
> 41 10 D
> 51 11 E
> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From rafalku at gmail.com  Tue May 16 23:31:49 2006
From: rafalku at gmail.com (Rafal Kustra)
Date: Tue, 16 May 2006 17:31:49 -0400
Subject: [Rd] bug in rbind.data.frame with factors (PR#8868)
In-Reply-To: <446A4325.3080609@math.ucalgary.ca>
References: <20060516195031.28119494DB@slim.kubism.ku.dk>
	<446A4325.3080609@math.ucalgary.ca>
Message-ID: <62a2e65d0605161431l465eda0eqc2de4dfcad28355e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060516/a9bf07b1/attachment.pl 

From ripley at stats.ox.ac.uk  Tue May 16 23:38:46 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 16 May 2006 22:38:46 +0100 (BST)
Subject: [Rd] bug in rbind.data.frame with factors (PR#8868)
In-Reply-To: <446A4325.3080609@math.ucalgary.ca>
References: <20060516195031.28119494DB@slim.kubism.ku.dk>
	<446A4325.3080609@math.ucalgary.ca>
Message-ID: <Pine.LNX.4.64.0605162228370.11772@gannet.stats.ox.ac.uk>

On Tue, 16 May 2006, Peter Ehlers wrote:

> How is this a bug? From the help page for cbind/rbind:
>
> Description
> Take a sequence of vector, matrix or data frames arguments and
> combine by _columns_ or _rows_, respectively.
> (emphasis added)
>
> Note that it does _not_ say "combine by variable names".

That was my first reaction, but in fact it does attempt to match up the 
colunn names.  So this is a bug in an undocumented extension, the bug 
being that when it looks into extending the levels of a factor, it checks 
if the column number was a factor in the first data frame and not in the 
(possibly permuted) columns of the data frame under consideration.

It is unclear from the S documentation what it is supposed to do, but it 
seems that it generates the same problematic output.

>
> Peter Ehlers
>
> rafalku at gmail.com wrote:
>
>> Full_Name: Rafal Kustra
>> Version: 2.1.1

Please don't report on obselete versions of R: we do ask so quite 
explicitly.

>> OS: Linux, MacOS 10.3
>> Submission from: (NULL) (69.195.47.62)
>>
>>
>> When Rbinding two data frames with factors, strange result occur (but no error)
>> when the order of data frame variables is different in two data frames:
>>
>>
>>> d1=as.data.frame(list(x=1:10,y=letters[1:10]))
>>> d2=as.data.frame(list(y=LETTERS[1:5],x=7:11))
>>> d2
>>
>>   y  x
>> 1 A  7
>> 2 B  8
>> 3 C  9
>> 4 D 10
>> 5 E 11
>>
>>> rbind(d1,d2)
>>
>>     x    y
>> 1   1    a
>> 2   2    b
>> 3   3    c
>> 4   4    d
>> 5   5    e
>> 6   6    f
>> 7   7    g
>> 8   8    h
>> 9   9    i
>> 10 10    j
>> 11  7 <NA>
>> 21  8 <NA>
>> 31  9 <NA>
>> 41 10 <NA>
>> 51 11 <NA>
>> Warning message:
>> invalid factor level, NAs generated in: "[<-.factor"(`*tmp*`, ri, value = c("A",
>> "B", "C", "D", "E"))
>>
>>
>> Things work correctly when the order of variables is the same:
>>
>>
>>> d3=as.data.frame(list(x=7:11,y=LETTERS[1:5]))
>>> rbind(d1,d3)
>>
>>     x y
>> 1   1 a
>> 2   2 b
>> 3   3 c
>> 4   4 d
>> 5   5 e
>> 6   6 f
>> 7   7 g
>> 8   8 h
>> 9   9 i
>> 10 10 j
>> 11  7 A
>> 21  8 B
>> 31  9 C
>> 41 10 D
>> 51 11 E
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rafalku at gmail.com  Wed May 17 02:48:38 2006
From: rafalku at gmail.com (Rafal Kustra)
Date: Tue, 16 May 2006 20:48:38 -0400
Subject: [Rd] bug in rbind.data.frame with factors (PR#8868)
In-Reply-To: <Pine.LNX.4.64.0605162228370.11772@gannet.stats.ox.ac.uk>
References: <20060516195031.28119494DB@slim.kubism.ku.dk>
	<446A4325.3080609@math.ucalgary.ca>
	<Pine.LNX.4.64.0605162228370.11772@gannet.stats.ox.ac.uk>
Message-ID: <62a2e65d0605161748w7ff9dc98tccbad87ef3b7ea9c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060516/c5fb8281/attachment.pl 

From vincent.goulet at act.ulaval.ca  Wed May 17 05:02:10 2006
From: vincent.goulet at act.ulaval.ca (Vincent Goulet)
Date: Tue, 16 May 2006 23:02:10 -0400
Subject: [Rd] New probability law functions
Message-ID: <200605162302.10729.vincent.goulet@act.ulaval.ca>

Dear developers,

I am currently writing, for a package of mine, {d,p,q,r}dist() functions for 
some probability laws not already found in base R. I was wondering if the 
Core Team would see any interest in having some or all the functions 
integrated in base R. I'm talking here of distributions like the Pareto, 
Burr, inverted gamma and, ultimately, four parameter transformed beta and 
transformed gamma (as named in Klugman, Panjer & Willmot, Loss Models, Second 
Edition, Wiley, 2004).

If there is interest, I will gladly contribute patches to relevant files. I'm 
asking beforehand since my current implementation is simpler than what is 
found in random.c and I would prefer to go one route or another.

Thanks in advance for any feedback.

-- 
  Vincent Goulet, Associate Professor
  ?cole d'actuariat
  Universit? Laval, Qu?bec 
  Vincent.Goulet at act.ulaval.ca   http://vgoulet.act.ulaval.ca


From maechler at stat.math.ethz.ch  Wed May 17 08:40:02 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 17 May 2006 08:40:02 +0200
Subject: [Rd] R CMD SHLIB
In-Reply-To: <Pine.LNX.4.64.0605161013270.30229@homer22.u.washington.edu>
References: <Pine.LNX.4.64.0605161737400.20542@gannet.stats.ox.ac.uk>
	<Pine.LNX.4.64.0605161013270.30229@homer22.u.washington.edu>
Message-ID: <17514.50498.635200.940425@stat.math.ethz.ch>

>>>>> "TL" == Thomas Lumley <tlumley at u.washington.edu>
>>>>>     on Tue, 16 May 2006 10:15:11 -0700 (PDT) writes:

    TL> On Tue, 16 May 2006, Prof Brian Ripley wrote:
    >> It is possible to do things like
    >> 
    >> env PKG_LIB="-L/opt/foo/lib -lbar" R CMD SHLIB *.c
    >> 
    >> to add libraries to the creation of a shared object, but
    >> I have from time to time wondered if we should allow
    >> 
    >> R CMD SHLIB *.c -L/opt/foo/lib -lbar
    >> 
    >> not least as users seems to expect it to work.  It looks
    >> simple to do (at least under Unix) if we pass -L* -l* *.a
    >> directly to the link command.
    >> 
    >> Would this be worthwhile?

    TL> Yes.

    TL> My only reservation is that users may then expect all
    TL> compiler/linker flags to work, not just -L/-l

I had exactly the same thought.

Maybe Brian's proposal can be extended into

  "all switches that are not recognized by 'R CMD SHLIB' are
   passed to compiler / linker  ...."

hmm, or maybe not, since the question quickly become *which* are
passed to compiler and which to linker (and which to both ?) ...

Martin Maechler, ETH Zurich


From ripley at stats.ox.ac.uk  Wed May 17 08:54:41 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 17 May 2006 07:54:41 +0100 (BST)
Subject: [Rd] R CMD SHLIB
In-Reply-To: <17514.50498.635200.940425@stat.math.ethz.ch>
References: <Pine.LNX.4.64.0605161737400.20542@gannet.stats.ox.ac.uk>
	<Pine.LNX.4.64.0605161013270.30229@homer22.u.washington.edu>
	<17514.50498.635200.940425@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.64.0605170751010.32238@gannet.stats.ox.ac.uk>

On Wed, 17 May 2006, Martin Maechler wrote:

>>>>>> "TL" == Thomas Lumley <tlumley at u.washington.edu>
>>>>>>     on Tue, 16 May 2006 10:15:11 -0700 (PDT) writes:
>
>    TL> On Tue, 16 May 2006, Prof Brian Ripley wrote:
>    >> It is possible to do things like
>    >>
>    >> env PKG_LIB="-L/opt/foo/lib -lbar" R CMD SHLIB *.c
>    >>
>    >> to add libraries to the creation of a shared object, but
>    >> I have from time to time wondered if we should allow
>    >>
>    >> R CMD SHLIB *.c -L/opt/foo/lib -lbar
>    >>
>    >> not least as users seems to expect it to work.  It looks
>    >> simple to do (at least under Unix) if we pass -L* -l* *.a
>    >> directly to the link command.
>    >>
>    >> Would this be worthwhile?
>
>    TL> Yes.
>
>    TL> My only reservation is that users may then expect all
>    TL> compiler/linker flags to work, not just -L/-l
>
> I had exactly the same thought.
>
> Maybe Brian's proposal can be extended into
>
>  "all switches that are not recognized by 'R CMD SHLIB' are
>   passed to compiler / linker  ...."
>
> hmm, or maybe not, since the question quickly become *which* are
> passed to compiler and which to linker (and which to both ?) ...

On looking at the code, currently all items on the command line not
recognized as flags, source files or object files are ignored, so we can 
just pass those to the linker.

It's a little more complicated under Windows since Perl is used and
-L* looks like an unknown option and so need to be preceded by --.

Will commit these changes to R-devel shortly.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From michael.dondrup at cebitec.uni-bielefeld.de  Wed May 17 12:09:22 2006
From: michael.dondrup at cebitec.uni-bielefeld.de (Michael Dondrup)
Date: Wed, 17 May 2006 12:09:22 +0200
Subject: [Rd] protect/unprotect howto in C code
Message-ID: <200605171209.23534.michael.dondrup@cebitec.uni-bielefeld.de>

Hi,

Im currently trying to debug a 'error in unprotect: stack imbalance' problem 
and I am curious about two basic questions on the use of PROTECT and 
UNPROTECT, which I could not figure out:

- which objects have to be protected, namely, if the code is something like:

SEXP fun, e;
/* get the expression e ... */
fun = eval(e, R_GlobalEnv);
/* or like this?: PROTECT(fun = eval(e, R_GlobalEnv)); */
PROTECT(fun = VECTOR_ELT(fun, 1));
/* do more things with fun ... */

does one need to protect the result of a call to 'eval' immediately? And how 
about R_tryEval?
While searching for code examples in the sources, I found both protected evals 
and fewer non-protected.

- Can someone give a hint (or some documents) on a way to simplify debugging 
such problem in addition to using gdb, please? I thought about temporarily 
defining macros such as 
#define DEBUG_Protect(x)  PROTECT(x); fprintf(stderr, "Protecting in %s, l: 
%d\n", __FILE__, __LINE__)
#define UNDEBUG_Protect(x) fprintf(stderr, "Unprotecting %d  in %s, l:, %d  
\n", x , __FILE__, __LINE__); UNPROTECT(x);
and then replace all calls temporarily in the package source. But there must 
be a better way... 

Thank you very much
(and my appologies, if this sounds odd to more experineced c programmers ;) )
Michael


From Gerhard.Thallinger at tugraz.at  Wed May 17 13:27:10 2006
From: Gerhard.Thallinger at tugraz.at (Gerhard Thallinger)
Date: Wed, 17 May 2006 13:27:10 +0200
Subject: [Rd] str() with attr(*,
	"names") is extremely slow for long vectors
Message-ID: <001b01c679a4$dd8b7720$c200020a@mobilix>

>>>>> "MartinM" == Martin Maechler maechler at stat.math.ethz.ch
>>>>>    Sat, May 13 2006 15:16:19 +0200 writes: 

  MartinM> But have you looked at R 2.3.0-patched at all?
  MartinM> 
  MartinM> I did acknowledge that str(<long character>) had become 
  MartinM> unacceptably slow, and had implemented a simple patch 
  MartinM> almost "immediately".

> Yes, I did. Here are the timings (WinXP 1.8 GHz):

>  R 2.3.0 Patched (2006-05-11 r38037) 
>
>   1. 44.09  0.09 44.45    NA    NA
>   2. 34.96  0.08 35.66    NA    NA
>   3. 34.52  0.07 34.81    NA    NA

  When I made the test I used an incomplete version of R patched (the
  new version of the utils package was missing). With the complete
  version of R patch the timings are now the same as with R 2.2.0.

Gerhard

------------------------------------------------------------------------
DI Gerhard Thallinger              E-mail:  Gerhard.Thallinger at tugraz.at
Institute for Genomics and Bioinformatics   Web: http://genome.tugraz.at
Graz University of Technology               Tel:        +43 316 873 5343
Petersgasse 14/V                            Fax:        +43 316 873 5340
8010 Graz, Austria                 Map: http://genome.tugraz.at/Loc.html


From p.dalgaard at biostat.ku.dk  Wed May 17 13:59:25 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 17 May 2006 13:59:25 +0200
Subject: [Rd] R 2.3.1 scheduled for June 1
Message-ID: <x23bf86ew2.fsf@viggo.kubism.ku.dk>


We plan to release R version 2.3.1 on June 1, in order to clean up a
couple of embarrasments and platform-specific build issues  2.3.0.

Beta releases will be available starting this Friday.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From tlumley at u.washington.edu  Wed May 17 16:55:06 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 17 May 2006 07:55:06 -0700 (PDT)
Subject: [Rd] protect/unprotect howto in C code
In-Reply-To: <200605171209.23534.michael.dondrup@cebitec.uni-bielefeld.de>
References: <200605171209.23534.michael.dondrup@cebitec.uni-bielefeld.de>
Message-ID: <Pine.LNX.4.64.0605170732440.24764@homer24.u.washington.edu>

On Wed, 17 May 2006, Michael Dondrup wrote:

> Hi,
>
> Im currently trying to debug a 'error in unprotect: stack imbalance' problem
> and I am curious about two basic questions on the use of PROTECT and
> UNPROTECT, which I could not figure out:
>
> - which objects have to be protected, namely, if the code is something like:
>
> SEXP fun, e;
> /* get the expression e ... */
> fun = eval(e, R_GlobalEnv);
> /* or like this?: PROTECT(fun = eval(e, R_GlobalEnv)); */
> PROTECT(fun = VECTOR_ELT(fun, 1));
> /* do more things with fun ... */
>
> does one need to protect the result of a call to 'eval' immediately? And how
> about R_tryEval?
> While searching for code examples in the sources, I found both protected evals
> and fewer non-protected.

The first rule is that any newly created R object needs to be protected 
before the garbage collector runs, and unprotected before exiting the 
function and after the last time the garbage collector runs.

The second rule is that protection applies to the contents of a variable 
(the R object) not to the variable.

The second rule is that protecting an object protects all its elements.

In the example above
     fun = eval(e, R_GlobalEnv);
may create a new object (it might just return a pointer to an existing 
function) and so probably needs to be protected.

On the other hand
  fun = VECTOR_ELT(fun, 1);
does not then need protecting. Since fun is protected, its second element 
is also protected.

So
    PROTECT(fun = eval(e, R_GlobalEnv));
    fun = VECTOR_ELT(fun, 1);
    /* do more stuff with fun */
    UNPROTECT(1);

If you don't know exactly which functions might return a new object or 
trigger the garbage collector it is probably safe to assume that anything 
might [this is the advice in 'Writing R Extensiosn'].  Unless you are 
getting close to the limits of the pointer protection stack (eg in 
recursive algorithms), you might be safer writing code like
    PROTECT(fun = eval(e, R_GlobalEnv));
    PROTECT(fun = VECTOR_ELT(fun, 1));
    /* do more stuff with fun */
    UNPROTECT(2);
but I think it is useful to know that the vector accessors and mutators do 
not allocate memory.


A stack imbalance is often due to different numbers of PROTECTs on 
different code paths. These are slightly annoying and become more frequent 
if you use more PROTECTs. On the other hand, R does detect them for you. 
If you don't use enough PROTECTs you get bugs that are very hard to track 
down [the best bet is probably valgrind + gctorture() to provoke them into 
showing themselves early, but that's only available on Linux].

 	-thomas


From maechler at stat.math.ethz.ch  Wed May 17 17:08:13 2006
From: maechler at stat.math.ethz.ch (maechler at stat.math.ethz.ch)
Date: Wed, 17 May 2006 17:08:13 +0200 (CEST)
Subject: [Rd] optim "CG" bug w/patch proposal (PR#8786)
Message-ID: <20060517150813.ED0EFECD9@slim.kubism.ku.dk>


>>>>> "Duncan" == Duncan Murdoch <murdoch at stats.uwo.ca>
>>>>>     on Tue, 16 May 2006 08:34:06 -0400 writes:

    Duncan> On 5/16/2006 4:56 AM, westfeld at inf.tu-dresden.de
    Duncan> wrote:
    >> Probably I included too much at once in my bug report. I
    >> can live with an unfulfilled wishlist and thank you for
    >> thinking about it. The "badly-behaved" function is just
    >> an example to demonstrate the bug I reported. I think it
    >> is a bug if optim returns (without any warning) an
    >> unmatching pair of par and value: f(par) != value. And it
    >> is easily fixed.

    >>  Andreas

    Duncan> I agree with you that on return f(par) should be
    Duncan> value.  I agree with Brian that changes to the
    Duncan> underlying strategy need much more thought.

I agree (to both).
However, isn't Andreas' patch just fixing the problem
and not changing the underlying strategy at all?
[No, I did not study the code in very much detail ...]

Martin Maechler

    >> Prof Brian Ripley wrote:
    >> 
    >>> [Sorry for the belated reply: this came in just as I was leaving for a
    >>> trip.]
    >>> 
    >>> I've checked the original source, and the C code in optim does
    >>> accurately reflect the published algorithm.
    >>> 
    >>> Since your example is a discontinuous function, I don't see why you
    >>> expect CG to work on it.  John Nash reports on his extensive
    >>> experience that method 3 is the worst, and I don't think we should let
    >>> a single 2D example of a badly-behaved function override that.
    >>> 
    >>> Note that no other optim method copes with the discontiuity here: had
    >>> your reported that it would have been clear that the problem was with
    >>> the example.
    >>> 
    >>> On Fri, 21 Apr 2006, westfeld at inf.tu-dresden.de wrote:
    >>> 
    >>>> Dear R team,
    >>>> 
    >>>> when using optim with method "CG" I got the wrong $value for the
    >>>> reported $par.
    >>>> 
    >>>> Example:
    >>>> f<-function(p) {
    >>>> if (!all(p>-.7)) return(2)
    >>>> if (!all(p<.7)) return(2)
    >>>> sin((p[1])^2)*sin(p[2])
    >>>> }
    >>>> optim(c(0.1,-0.1),f,method="CG",control=list(trace=0,type=1))
    >>>> $par 19280.68 -10622.32
    >>>> $value -0.2346207 # should be 2!
    >>>> 
    >>>> optim(c(0.1,-0.1),f,method="CG",control=list(trace=0,type=2))
    >>>> $par 3834.021 -2718.958
    >>>> $value -0.0009983175 # should be 2!
    >>>> 
    >>>> Fix:
    >>>> --- optim.c     (Revision 37878)
    >>>> +++ optim.c     (Arbeitskopie)
    >>>> @@ -970,7 +970,8 @@
    >>>> if (!accpoint) {
    >>>> steplength *= stepredn;
    >>>> if (trace) Rprintf("*");
    >>>> -                           }
    >>>> +                           } else
    >>>> +                               *Fmin = f;
    >>>> }
    >>>> } while (!(count == n || accpoint));
    >>>> if (count < n) {
    >>>> 
    >>>> After fix:
    >>>> optim(c(0.1,-0.1),f,method="CG",control=list(trace=0,type=1))
    >>>> $par 0.6993467 -0.4900145
    >>>> $value -0.2211150
    >>>> optim(c(0.1,-0.1),f,method="CG",control=list(trace=0,type=2))
    >>>> $par 3834.021 -2718.958
    >>>> $value 2
    >>>> 
    >>>> Wishlist: 
    >>> 
    >> [wishlist deleted]
    >> 
    >> 

    Duncan> ______________________________________________
    Duncan> R-devel at r-project.org mailing list
    Duncan> https://stat.ethz.ch/mailman/listinfo/r-devel


From michael.dondrup at cebitec.uni-bielefeld.de  Wed May 17 18:12:09 2006
From: michael.dondrup at cebitec.uni-bielefeld.de (Michael Dondrup)
Date: Wed, 17 May 2006 18:12:09 +0200
Subject: [Rd] protect/unprotect howto in C code
In-Reply-To: <Pine.LNX.4.64.0605170732440.24764@homer24.u.washington.edu>
References: <200605171209.23534.michael.dondrup@cebitec.uni-bielefeld.de>
	<Pine.LNX.4.64.0605170732440.24764@homer24.u.washington.edu>
Message-ID: <200605171812.10303.michael.dondrup@cebitec.uni-bielefeld.de>

Thank you very much, Thomas!

Thanks to the explanation, I think I could almost track down that bug. May I, 
just for clarification, ask a further bunch of  questions (sorry). From what 
you say, did I get it right: 

- 'error in unprotect: stack imbalance' is only a warning, it will not cause 
termination, unless R is running as an embedded process (I'm working with 
RSPerl package in perl here)?  
- Forgetting to unprotect a value is harmless, and will only provoke these 
warnings?
- If the protect/unprotect is unbalanced within a function call, R will give 
the warning/error already at the exit of this specific function?
- If that is the case, what if I want to return a pointer to a value from a 
function? Do have to unprotect it anyway, before?

btw: I'm working on FreeBSD,  I found an experimental port of valgrind, too.

Thank you very much again!

Michael


On Wednesday 17 May 2006 16:55 Thomas Lumley wrote:
> On Wed, 17 May 2006, Michael Dondrup wrote:
> > Hi,
> >
> > Im currently trying to debug a 'error in unprotect: stack imbalance'
> > problem and I am curious about two basic questions on the use of PROTECT
> > and UNPROTECT, which I could not figure out:
> >
> > - which objects have to be protected, namely, if the code is something
> > like:
> >
> > SEXP fun, e;
> > /* get the expression e ... */
> > fun = eval(e, R_GlobalEnv);
> > /* or like this?: PROTECT(fun = eval(e, R_GlobalEnv)); */
> > PROTECT(fun = VECTOR_ELT(fun, 1));
> > /* do more things with fun ... */
> >
> > does one need to protect the result of a call to 'eval' immediately? And
> > how about R_tryEval?
> > While searching for code examples in the sources, I found both protected
> > evals and fewer non-protected.
>
> The first rule is that any newly created R object needs to be protected
> before the garbage collector runs, and unprotected before exiting the
> function and after the last time the garbage collector runs.
>
> The second rule is that protection applies to the contents of a variable
> (the R object) not to the variable.
>
> The second rule is that protecting an object protects all its elements.
>
> In the example above
>      fun = eval(e, R_GlobalEnv);
> may create a new object (it might just return a pointer to an existing
> function) and so probably needs to be protected.
>
> On the other hand
>   fun = VECTOR_ELT(fun, 1);
> does not then need protecting. Since fun is protected, its second element
> is also protected.
>
> So
>     PROTECT(fun = eval(e, R_GlobalEnv));
>     fun = VECTOR_ELT(fun, 1);
>     /* do more stuff with fun */
>     UNPROTECT(1);
>
> If you don't know exactly which functions might return a new object or
> trigger the garbage collector it is probably safe to assume that anything
> might [this is the advice in 'Writing R Extensiosn'].  Unless you are
> getting close to the limits of the pointer protection stack (eg in
> recursive algorithms), you might be safer writing code like
>     PROTECT(fun = eval(e, R_GlobalEnv));
>     PROTECT(fun = VECTOR_ELT(fun, 1));
>     /* do more stuff with fun */
>     UNPROTECT(2);
> but I think it is useful to know that the vector accessors and mutators do
> not allocate memory.
>
>
> A stack imbalance is often due to different numbers of PROTECTs on
> different code paths. These are slightly annoying and become more frequent
> if you use more PROTECTs. On the other hand, R does detect them for you.
> If you don't use enough PROTECTs you get bugs that are very hard to track
> down [the best bet is probably valgrind + gctorture() to provoke them into
> showing themselves early, but that's only available on Linux].
>
>  	-thomas


From bill at insightful.com  Wed May 17 18:44:11 2006
From: bill at insightful.com (Bill Dunlap)
Date: Wed, 17 May 2006 09:44:11 -0700 (PDT)
Subject: [Rd] R CMD SHLIB
In-Reply-To: <17514.50498.635200.940425@stat.math.ethz.ch>
References: <Pine.LNX.4.64.0605161737400.20542@gannet.stats.ox.ac.uk>
	<Pine.LNX.4.64.0605161013270.30229@homer22.u.washington.edu>
	<17514.50498.635200.940425@stat.math.ethz.ch>
Message-ID: <Pine.GSO.4.56.0605170934570.17220@durian.statsci.com>

On Wed, 17 May 2006, Martin Maechler wrote:

> >>>>> "TL" == Thomas Lumley <tlumley at u.washington.edu>
> >>>>>     on Tue, 16 May 2006 10:15:11 -0700 (PDT) writes:
>
>     TL> On Tue, 16 May 2006, Prof Brian Ripley wrote:
>     >> It is possible to do things like
>     >>
>     >> env PKG_LIB="-L/opt/foo/lib -lbar" R CMD SHLIB *.c
>     >>
>     >> to add libraries to the creation of a shared object, but
>     >> I have from time to time wondered if we should allow
>     >>
>     >> R CMD SHLIB *.c -L/opt/foo/lib -lbar
>     >>
>     >> not least as users seems to expect it to work.  It looks
>     >> simple to do (at least under Unix) if we pass -L* -l* *.a
>     >> directly to the link command.
>     >>
>     >> Would this be worthwhile?
>
>     TL> Yes.
>
>     TL> My only reservation is that users may then expect all
>     TL> compiler/linker flags to work, not just -L/-l
>
> I had exactly the same thought.
>
> Maybe Brian's proposal can be extended into
>
>   "all switches that are not recognized by 'R CMD SHLIB' are
>    passed to compiler / linker  ...."
>
> hmm, or maybe not, since the question quickly become *which* are
> passed to compiler and which to linker (and which to both ?) ...

I'd rather have SHLIB complain if it sees a -flag
that SHLIB doesn't recognize.  Otherwise we get
portability problems.  E.g., when using the Microsoft
C compiler and linker a SHLIB that knows about the
-l and -L flags can translate
    -lfoo -L/dir/subdir
into LDFLAGS that link.exe knows about:
    foo.lib /libpath:\dir\subdir

If you need other linker flags, could they be in compiler/platform-
specific Makevars-<compiler/platform>?  I think other
ones are not very common.

----------------------------------------------------------------------------
Bill Dunlap
Insightful Corporation
bill at insightful dot com
360-428-8146

 "All statements in this message represent the opinions of the author and do
 not necessarily reflect Insightful Corporation policy or position."


From ripley at stats.ox.ac.uk  Wed May 17 18:46:45 2006
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Wed, 17 May 2006 18:46:45 +0200 (CEST)
Subject: [Rd] optim "CG" bug w/patch proposal (PR#8786)
Message-ID: <20060517164645.59D782477B@slim.kubism.ku.dk>

On Wed, 17 May 2006, maechler at stat.math.ethz.ch wrote:

>
>>>>>> "Duncan" == Duncan Murdoch <murdoch at stats.uwo.ca>
>>>>>>     on Tue, 16 May 2006 08:34:06 -0400 writes:
>
>    Duncan> On 5/16/2006 4:56 AM, westfeld at inf.tu-dresden.de
>    Duncan> wrote:
>    >> Probably I included too much at once in my bug report. I
>    >> can live with an unfulfilled wishlist and thank you for
>    >> thinking about it. The "badly-behaved" function is just
>    >> an example to demonstrate the bug I reported. I think it
>    >> is a bug if optim returns (without any warning) an
>    >> unmatching pair of par and value: f(par) != value. And it
>    >> is easily fixed.
>
>    >>  Andreas
>
>    Duncan> I agree with you that on return f(par) should be
>    Duncan> value.  I agree with Brian that changes to the
>    Duncan> underlying strategy need much more thought.
>
> I agree (to both).
> However, isn't Andreas' patch just fixing the problem
> and not changing the underlying strategy at all?
> [No, I did not study the code in very much detail ...]

The (minor) issue is that x is updated but not f(x).  I think the intended 
stategy was to update neither, so Andreas' patch was a change of stategy. 
In particular, a question is if this should be marked as a convergence 
failure.  But people really need to read the reference before commenting,
and I at least need to find the time to do so in more detail.

> Martin Maechler
>
>    >> Prof Brian Ripley wrote:
>    >>
>    >>> [Sorry for the belated reply: this came in just as I was leaving for a
>    >>> trip.]
>    >>>
>    >>> I've checked the original source, and the C code in optim does
>    >>> accurately reflect the published algorithm.
>    >>>
>    >>> Since your example is a discontinuous function, I don't see why you
>    >>> expect CG to work on it.  John Nash reports on his extensive
>    >>> experience that method 3 is the worst, and I don't think we should let
>    >>> a single 2D example of a badly-behaved function override that.
>    >>>
>    >>> Note that no other optim method copes with the discontiuity here: had
>    >>> your reported that it would have been clear that the problem was with
>    >>> the example.
>    >>>
>    >>> On Fri, 21 Apr 2006, westfeld at inf.tu-dresden.de wrote:
>    >>>
>    >>>> Dear R team,
>    >>>>
>    >>>> when using optim with method "CG" I got the wrong $value for the
>    >>>> reported $par.
>    >>>>
>    >>>> Example:
>    >>>> f<-function(p) {
>    >>>> if (!all(p>-.7)) return(2)
>    >>>> if (!all(p<.7)) return(2)
>    >>>> sin((p[1])^2)*sin(p[2])
>    >>>> }
>    >>>> optim(c(0.1,-0.1),f,method="CG",control=list(trace=0,type=1))
>    >>>> $par 19280.68 -10622.32
>    >>>> $value -0.2346207 # should be 2!
>    >>>>
>    >>>> optim(c(0.1,-0.1),f,method="CG",control=list(trace=0,type=2))
>    >>>> $par 3834.021 -2718.958
>    >>>> $value -0.0009983175 # should be 2!
>    >>>>
>    >>>> Fix:
>    >>>> --- optim.c     (Revision 37878)
>    >>>> +++ optim.c     (Arbeitskopie)
>    >>>> @@ -970,7 +970,8 @@
>    >>>> if (!accpoint) {
>    >>>> steplength *= stepredn;
>    >>>> if (trace) Rprintf("*");
>    >>>> -                           }
>    >>>> +                           } else
>    >>>> +                               *Fmin = f;
>    >>>> }
>    >>>> } while (!(count == n || accpoint));
>    >>>> if (count < n) {
>    >>>>
>    >>>> After fix:
>    >>>> optim(c(0.1,-0.1),f,method="CG",control=list(trace=0,type=1))
>    >>>> $par 0.6993467 -0.4900145
>    >>>> $value -0.2211150
>    >>>> optim(c(0.1,-0.1),f,method="CG",control=list(trace=0,type=2))
>    >>>> $par 3834.021 -2718.958
>    >>>> $value 2
>    >>>>
>    >>>> Wishlist:
>    >>>
>    >> [wishlist deleted]
>    >>
>    >>
>
>    Duncan> ______________________________________________
>    Duncan> R-devel at r-project.org mailing list
>    Duncan> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tlumley at u.washington.edu  Wed May 17 18:47:12 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 17 May 2006 09:47:12 -0700 (PDT)
Subject: [Rd] protect/unprotect howto in C code
In-Reply-To: <200605171812.10303.michael.dondrup@cebitec.uni-bielefeld.de>
References: <200605171209.23534.michael.dondrup@cebitec.uni-bielefeld.de>
	<Pine.LNX.4.64.0605170732440.24764@homer24.u.washington.edu>
	<200605171812.10303.michael.dondrup@cebitec.uni-bielefeld.de>
Message-ID: <Pine.LNX.4.64.0605170940580.23107@homer22.u.washington.edu>

On Wed, 17 May 2006, Michael Dondrup wrote:

> Thank you very much, Thomas!
>
> Thanks to the explanation, I think I could almost track down that bug. May I,
> just for clarification, ask a further bunch of  questions (sorry). From what
> you say, did I get it right:
>
> - 'error in unprotect: stack imbalance' is only a warning, it will not cause
> termination, unless R is running as an embedded process (I'm working with
> RSPerl package in perl here)?

Correct.

> - Forgetting to unprotect a value is harmless, and will only provoke these
> warnings?

Well, it causes a memory leak, and in the unlikely event that you have 
finalizers set on the objects the finalizers won't run. Otherwise, yes.

> - If the protect/unprotect is unbalanced within a function call, R will give
> the warning/error already at the exit of this specific function?

Not quite. The warning comes on return from .Call(). If the function you 
.Call calls other C functions you will still only get the warning on 
return to R.

> - If that is the case, what if I want to return a pointer to a value from a
> function? Do have to unprotect it anyway, before?

Rule 1 applies to the code that calls your function, too.  If you return 
(a pointer to) an object that from the point of view of the calling 
function is newly created, the calling function has to PROTECT it. In 
particular, the return value of .Call will be protected if you store it in 
a variable.

 	-thomas


From ripley at stats.ox.ac.uk  Wed May 17 18:49:49 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 17 May 2006 17:49:49 +0100 (BST)
Subject: [Rd] R CMD SHLIB
In-Reply-To: <Pine.GSO.4.56.0605170934570.17220@durian.statsci.com>
References: <Pine.LNX.4.64.0605161737400.20542@gannet.stats.ox.ac.uk>
	<Pine.LNX.4.64.0605161013270.30229@homer22.u.washington.edu>
	<17514.50498.635200.940425@stat.math.ethz.ch>
	<Pine.GSO.4.56.0605170934570.17220@durian.statsci.com>
Message-ID: <Pine.LNX.4.64.0605171746510.30505@gannet.stats.ox.ac.uk>

On Wed, 17 May 2006, Bill Dunlap wrote:

> On Wed, 17 May 2006, Martin Maechler wrote:
>
>>>>>>> "TL" == Thomas Lumley <tlumley at u.washington.edu>
>>>>>>>     on Tue, 16 May 2006 10:15:11 -0700 (PDT) writes:
>>
>>     TL> On Tue, 16 May 2006, Prof Brian Ripley wrote:
>>    >> It is possible to do things like
>>    >>
>>    >> env PKG_LIB="-L/opt/foo/lib -lbar" R CMD SHLIB *.c
>>    >>
>>    >> to add libraries to the creation of a shared object, but
>>    >> I have from time to time wondered if we should allow
>>    >>
>>    >> R CMD SHLIB *.c -L/opt/foo/lib -lbar
>>    >>
>>    >> not least as users seems to expect it to work.  It looks
>>    >> simple to do (at least under Unix) if we pass -L* -l* *.a
>>    >> directly to the link command.
>>    >>
>>    >> Would this be worthwhile?
>>
>>     TL> Yes.
>>
>>     TL> My only reservation is that users may then expect all
>>     TL> compiler/linker flags to work, not just -L/-l
>>
>> I had exactly the same thought.
>>
>> Maybe Brian's proposal can be extended into
>>
>>   "all switches that are not recognized by 'R CMD SHLIB' are
>>    passed to compiler / linker  ...."
>>
>> hmm, or maybe not, since the question quickly become *which* are
>> passed to compiler and which to linker (and which to both ?) ...
>
> I'd rather have SHLIB complain if it sees a -flag
> that SHLIB doesn't recognize.  Otherwise we get
> portability problems.  E.g., when using the Microsoft
> C compiler and linker a SHLIB that knows about the
> -l and -L flags can translate
>    -lfoo -L/dir/subdir
> into LDFLAGS that link.exe knows about:
>    foo.lib /libpath:\dir\subdir
>
> If you need other linker flags, could they be in compiler/platform-
> specific Makevars-<compiler/platform>?  I think other
> ones are not very common.

In R, we are not dealing with such compilers/linkers (fortunately). Given 
that there are plenty of ways to hang oneself here, I do not want to be 
unduly restrictive as to what one can pass.  (All the autoconf etc 
mechanisms assume flags like -L and -l, and also that some reordering is 
done by the frontends.)

> ----------------------------------------------------------------------------
> Bill Dunlap
> Insightful Corporation
> bill at insightful dot com
> 360-428-8146
>
> "All statements in this message represent the opinions of the author and do
> not necessarily reflect Insightful Corporation policy or position."
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch at stats.uwo.ca  Wed May 17 18:54:51 2006
From: murdoch at stats.uwo.ca (murdoch at stats.uwo.ca)
Date: Wed, 17 May 2006 18:54:51 +0200 (CEST)
Subject: [Rd] optim "CG" bug w/patch proposal (PR#8786)
Message-ID: <20060517165451.A5700494D4@slim.kubism.ku.dk>

On 5/17/2006 11:07 AM, Martin Maechler wrote:
>>>>>> "Duncan" == Duncan Murdoch <murdoch at stats.uwo.ca>
>>>>>>     on Tue, 16 May 2006 08:34:06 -0400 writes:
> 
>     Duncan> On 5/16/2006 4:56 AM, westfeld at inf.tu-dresden.de
>     Duncan> wrote:
>     >> Probably I included too much at once in my bug report. I
>     >> can live with an unfulfilled wishlist and thank you for
>     >> thinking about it. The "badly-behaved" function is just
>     >> an example to demonstrate the bug I reported. I think it
>     >> is a bug if optim returns (without any warning) an
>     >> unmatching pair of par and value: f(par) != value. And it
>     >> is easily fixed.
> 
>     >>  Andreas
> 
>     Duncan> I agree with you that on return f(par) should be
>     Duncan> value.  I agree with Brian that changes to the
>     Duncan> underlying strategy need much more thought.
> 
> I agree (to both).
> However, isn't Andreas' patch just fixing the problem
> and not changing the underlying strategy at all?
> [No, I did not study the code in very much detail ...]

Brian and I only quoted part of his message.  The patch we quoted isn't 
bad, but I'm not sure it's the best:  in particular, with the patch 
optim() returns a function value that is larger than f at the starting 
value (see below).  I think this means it would be better to change 
optim$par rather than changing optim$value to achieve consistency, but a 
quick look at optim.c made me think it would take more time than I had 
to do this without messing up something else.

I don't think I'll have a chance to look at this before 2.3.1, so if 
nobody else takes it on, I'd prefer to leave this as an unresolved bug 
report for now.

> 
> Martin Maechler
> 
>     >> Prof Brian Ripley wrote:
>     >> 
>     >>> [Sorry for the belated reply: this came in just as I was leaving for a
>     >>> trip.]
>     >>> 
>     >>> I've checked the original source, and the C code in optim does
>     >>> accurately reflect the published algorithm.
>     >>> 
>     >>> Since your example is a discontinuous function, I don't see why you
>     >>> expect CG to work on it.  John Nash reports on his extensive
>     >>> experience that method 3 is the worst, and I don't think we should let
>     >>> a single 2D example of a badly-behaved function override that.
>     >>> 
>     >>> Note that no other optim method copes with the discontiuity here: had
>     >>> your reported that it would have been clear that the problem was with
>     >>> the example.
>     >>> 
>     >>> On Fri, 21 Apr 2006, westfeld at inf.tu-dresden.de wrote:
>     >>> 
>     >>>> Dear R team,
>     >>>> 
>     >>>> when using optim with method "CG" I got the wrong $value for the
>     >>>> reported $par.
>     >>>> 
>     >>>> Example:
>     >>>> f<-function(p) {
>     >>>> if (!all(p>-.7)) return(2)
>     >>>> if (!all(p<.7)) return(2)
>     >>>> sin((p[1])^2)*sin(p[2])
>     >>>> }
>     >>>> optim(c(0.1,-0.1),f,method="CG",control=list(trace=0,type=1))
>     >>>> $par 19280.68 -10622.32
>     >>>> $value -0.2346207 # should be 2!

>     >>>> optim(c(0.1,-0.1),f,method="CG",control=list(trace=0,type=2))
>     >>>> $par 3834.021 -2718.958
>     >>>> $value -0.0009983175 # should be 2!

I think this is f(0.1, -0.1), so really $par should be 0.1, -0.1 in this 
case.  In the one above, it appears to have made a little progress 
before it went off track, but -0.234 is better than 2, so it should be 
returned if it's really an f(p) value.

Duncan Murdoch


>     >>>> 
>     >>>> Fix:
>     >>>> --- optim.c     (Revision 37878)
>     >>>> +++ optim.c     (Arbeitskopie)
>     >>>> @@ -970,7 +970,8 @@
>     >>>> if (!accpoint) {
>     >>>> steplength *= stepredn;
>     >>>> if (trace) Rprintf("*");
>     >>>> -                           }
>     >>>> +                           } else
>     >>>> +                               *Fmin = f;
>     >>>> }
>     >>>> } while (!(count == n || accpoint));
>     >>>> if (count < n) {
>     >>>> 
>     >>>> After fix:
>     >>>> optim(c(0.1,-0.1),f,method="CG",control=list(trace=0,type=1))
>     >>>> $par 0.6993467 -0.4900145
>     >>>> $value -0.2211150
>     >>>> optim(c(0.1,-0.1),f,method="CG",control=list(trace=0,type=2))
>     >>>> $par 3834.021 -2718.958
>     >>>> $value 2
>     >>>> 
>     >>>> Wishlist: 
>     >>> 
>     >> [wishlist deleted]
>     >> 
>     >> 
> 
>     Duncan> ______________________________________________
>     Duncan> R-devel at r-project.org mailing list
>     Duncan> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Wed May 17 20:40:08 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 17 May 2006 19:40:08 +0100 (BST)
Subject: [Rd] Non-ASCII chars in R code
Message-ID: <Pine.LNX.4.64.0605171855440.26452@gannet.stats.ox.ac.uk>

The report on R_help about problems loading package irr (in a 
UTF-8 locale, it seemed) prompted me to look a little deeper.  There are 
quite a few packages with Latin-1 chars in their .R files, and a couple in 
UTF-8.

Apart from non-ASCII chars in comments, this is a problem as the code 
concerned cannot be represented in some locales R runs in (for example 
Japanese on Windows).  It happens that irr is so small that lazy-loading 
is not used, but when lazy-loading or a saved image is used, the locale in 
use when the package is installed determines how the code is parsed (and 
may not be the same as when the package is used, and indeed it is not 
uncommon on Linux/Unix systems for different users to use different 
locales).

This means that using non-ASCII chars is not portable, and I've added code 
to R CMD check in R-devel to warn about such usage.  In the examples I 
have investigated the usages have been

- messages in a non-English language, typically French.
- startup messages with people's names.
- use of characters that I can only guess are intended to be in the
   WinAnsi encoding, e.g. a copyright symbol.

The only reason I have not made this an error is that people might want to 
produce packages for a known locale, e.g. a student class, but perhaps it 
should be an error for packages submitted to CRAN.

I do not believe there is much we can do about this: messages which are 
not entirely in ASCII cannot be displayed on many R platforms and it seems 
incorrect to allow French messages and not Japanese ones.

The packages currently throwing warnings are

FactoMineR FunCluster JointGLM LoopAnalyst Sciviews ade4 adehabitat ape 
climatol crossdes deal grasper irr lsa mvrpart pastecs sn surveillance 
truncgof


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From juha.heljoranta at iki.fi  Wed May 17 20:42:43 2006
From: juha.heljoranta at iki.fi (juha.heljoranta at iki.fi)
Date: Wed, 17 May 2006 20:42:43 +0200 (CEST)
Subject: [Rd] prcomp: problem with zeros? (PR#8870)
Message-ID: <20060517184243.A337B1990D@slim.kubism.ku.dk>

Full_Name: Juha Heljoranta
Version: R 2.1.1 (2005-06-20)
OS: Gentoo Linux
Submission from: (NULL) (88.112.29.250)


prcomp has a bug which causes following error

    Error in svd(x, nu = 0) : infinite or missing values in 'x'

on a valid data set (no Infs, no missing values). The error is most likely
caused by the zeros in data.

My code and temporary workaround:


  m = matrix(...
  ...
  prcomp(m, center = TRUE, scale = TRUE)
  Error in svd(x, nu = 0) : infinite or missing values in 'x'


  m = matrix(...
  ...
  # ugly work around
  m = m + 1e-120 
  # too small values will not work
  # m = m + 1e-150 
  prcomp(m, center = TRUE, scale = TRUE)
  # success


The matrix in question is ~1024x13000 containing double values, thus totaling of
~103M of raw data. I can put it online if needed.


From ripley at stats.ox.ac.uk  Wed May 17 21:02:40 2006
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Wed, 17 May 2006 21:02:40 +0200 (CEST)
Subject: [Rd] prcomp: problem with zeros? (PR#8870)
Message-ID: <20060517190240.0A383494DA@slim.kubism.ku.dk>

On Wed, 17 May 2006, juha.heljoranta at iki.fi wrote:

> Full_Name: Juha Heljoranta
> Version: R 2.1.1 (2005-06-20)

Not a current version of R.

> OS: Gentoo Linux
> Submission from: (NULL) (88.112.29.250)
>
> prcomp has a bug which causes following error
>
>    Error in svd(x, nu = 0) : infinite or missing values in 'x'
>
> on a valid data set (no Infs, no missing values). The error is most likely
> caused by the zeros in data.

Why do you say that?  Without a reproducible example, we cannot judge what 
is going on.  If you called prcomp with scale=TRUE on a matrix that has a 
completely zero (or constant) column, then this is a reasonable error 
message.

> My code and temporary workaround:
>
>
>  m = matrix(...
>  ...
>  prcomp(m, center = TRUE, scale = TRUE)
>  Error in svd(x, nu = 0) : infinite or missing values in 'x'
>
>
>  m = matrix(...
>  ...
>  # ugly work around
>  m = m + 1e-120
>  # too small values will not work
>  # m = m + 1e-150
>  prcomp(m, center = TRUE, scale = TRUE)
>  # success
>
>
> The matrix in question is ~1024x13000 containing double values, thus totaling of
> ~103M of raw data. I can put it online if needed.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jari.oksanen at oulu.fi  Wed May 17 21:25:53 2006
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Wed, 17 May 2006 22:25:53 +0300
Subject: [Rd] prcomp: problem with zeros? (PR#8870)
In-Reply-To: <20060517190240.0A383494DA@slim.kubism.ku.dk>
References: <20060517190240.0A383494DA@slim.kubism.ku.dk>
Message-ID: <bb12b242f645d6ffbcacccfbc115da60@oulu.fi>


On 17 May 2006, at 22:02, ripley at stats.ox.ac.uk wrote:

> On Wed, 17 May 2006, juha.heljoranta at iki.fi wrote:
>>
>> prcomp has a bug which causes following error
>>
>>    Error in svd(x, nu = 0) : infinite or missing values in 'x'
>>
>> on a valid data set (no Infs, no missing values). The error is most 
>> likely
>> caused by the zeros in data.
>
> Why do you say that?  Without a reproducible example, we cannot judge 
> what
> is going on.  If you called prcomp with scale=TRUE on a matrix that 
> has a
> completely zero (or constant) column, then this is a reasonable error
> message.

Constant columns (which is a likely reason here) indeed become NaN 
after scale(), but the error message was:

Error in svd(x, nu = 0) : infinite or missing values in 'x'

and calling this 'reasonable' is stretching the limits of reason.

However, in general this is "easy" to solve:  scale() before the 
analysis and replace NaN with 0 (prcomp handles zeros).  For instance,

x <- scale(x)
x[is.nan(x)] <- 0
prcomp(x)

(and a friendly prcomp() would do this internally.)

cheers, jari oksanen
--
Jari Oksanen, Oulu, Finland


From stein at galton.uchicago.edu  Wed May 17 22:17:23 2006
From: stein at galton.uchicago.edu (stein at galton.uchicago.edu)
Date: Wed, 17 May 2006 22:17:23 +0200 (CEST)
Subject: [Rd] Documentation for taper in spec.taper (PR#8871)
Message-ID: <20060517201723.8C3C7CD14@slim.kubism.ku.dk>

Full_Name: Michael Stein
Version: Version 2.1.1
OS: linux
Submission from: (NULL) (128.135.149.112)


The documentation for spec.taper says

      p: The total proportion to be tapered, either a scalar or a
          vector of the length of the number of series.

Details:

     The cosine-bell taper is applied to the first and last 'p[i]/2'
     observations of time series 'x[, i]'.


However, the program actually applies the taper to the first and last p[i]
observations, so 2 * p is the total proportion to be tapered.

The documentation for spec.pgram says

   taper: proportion of data to taper.  A split cosine bell taper is
          applied to this proportion of the data at the beginning and
          end of the series.

The second statement is correct, but this means that the proportion of the data

that is tapered is 2 * taper, not taper.  This documentation could easily lead
to
users getting twice as much tapering as they think they are getting.


From rproject at boonstra.org  Wed May 17 22:37:30 2006
From: rproject at boonstra.org (rproject at boonstra.org)
Date: Wed, 17 May 2006 22:37:30 +0200 (CEST)
Subject: [Rd] Convention difference in tseries.maxdrawdown (PR#8872)
Message-ID: <20060517203730.3158DCD14@slim.kubism.ku.dk>

Full_Name: Brian K. Boonstra
Version: 2.2.1
OS: WinXP, OSX
Submission from: (NULL) (63.172.178.137)


The maxdrawdown function in tseries defines the maximum drawdown in terms of
absolute dollars (or whatever units the input is in).  Industry convention is to
do this in percentage terms.  I have written the code below as
maximumdrawdown(), which retains backward compatibility with the current
version.  It has the flaw that it does not check for zero or negative values.

maximumdrawdown <- function (x) 
{
    if (NCOL(x) > 1) 
        stop("x is not a vector or univariate time series")
    if (any(is.na(x))) 
        stop("NAs in x")
    cminx <- x/cummax(x)
    mdd <- min(cminx)
    to <- which(mdd == cminx)
    from <- double(NROW(to))
    for (i in 1:NROW(to)) {
      from[i] <- max( which(cminx[1:to[i]] == 1) )
      }
    return(list(maximumdrawdown = 1-mdd, maxdrawdown = (1-mdd)*x[from], from =
from, to = to))
}


From ggrothendieck at gmail.com  Wed May 17 23:20:11 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 17 May 2006 17:20:11 -0400
Subject: [Rd] Convention difference in tseries.maxdrawdown (PR#8872)
In-Reply-To: <20060517203730.3158DCD14@slim.kubism.ku.dk>
References: <20060517203730.3158DCD14@slim.kubism.ku.dk>
Message-ID: <971536df0605171420s2eb922c0p5e92ba0f318c000d@mail.gmail.com>

Regarding the upwardly compatible comment, the dollar drawdown that
corresponds to the maximum fractional drawdown is not necessarily the
maximum dollar drawdown.

For example, in this situation the maximum fractional drawdown
is from 100 to 75 but the maximum dollar drawdown is from 200
to 160.

> x <- c(1, 100, 75, 200, 160)

> maximumdrawdown(x) # function defined in post
$maximumdrawdown
[1] 0.25

$maxdrawdown
[1] 25

$from
[1] 2

$to
[1] 3

> maxdrawdown(x) # function from tseries
$maxdrawdown
[1] 40

$from
[1] 4

$to
[1] 5

On 5/17/06, rproject at boonstra.org <rproject at boonstra.org> wrote:
> Full_Name: Brian K. Boonstra
> Version: 2.2.1
> OS: WinXP, OSX
> Submission from: (NULL) (63.172.178.137)
>
>
> The maxdrawdown function in tseries defines the maximum drawdown in terms of
> absolute dollars (or whatever units the input is in).  Industry convention is to
> do this in percentage terms.  I have written the code below as
> maximumdrawdown(), which retains backward compatibility with the current
> version.  It has the flaw that it does not check for zero or negative values.
>
> maximumdrawdown <- function (x)
> {
>    if (NCOL(x) > 1)
>        stop("x is not a vector or univariate time series")
>    if (any(is.na(x)))
>        stop("NAs in x")
>    cminx <- x/cummax(x)
>    mdd <- min(cminx)
>    to <- which(mdd == cminx)
>    from <- double(NROW(to))
>    for (i in 1:NROW(to)) {
>      from[i] <- max( which(cminx[1:to[i]] == 1) )
>      }
>    return(list(maximumdrawdown = 1-mdd, maxdrawdown = (1-mdd)*x[from], from =
> from, to = to))
> }
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From hpages at fhcrc.org  Wed May 17 23:30:51 2006
From: hpages at fhcrc.org (Herve Pages)
Date: Wed, 17 May 2006 14:30:51 -0700
Subject: [Rd] 'R CMD config' doesn't work on Windows
In-Reply-To: <20060517203730.3158DCD14@slim.kubism.ku.dk>
References: <20060517203730.3158DCD14@slim.kubism.ku.dk>
Message-ID: <446B960B.6000204@fhcrc.org>

Hi everybody,

I'd like to report this problem I have on Windows with R 2.2.1, R 2.3.0,
R-2.3.0 patched (r38086) and R 2.4.0 devel (r37925):
    D:\hpages>R\bin\R CMD config CC
    Can't open perl script "D:\hpages\R-2.3.1/bin/config": No such file 
or directory
Best,

H.

-- 
------------------------
Herv? Pag?s
E-mail: hpages at fhcrc.org
 Phone: (206) 667-5791
   Fax: (206) 667-1319


From hpages at fhcrc.org  Wed May 17 23:44:33 2006
From: hpages at fhcrc.org (Herve Pages)
Date: Wed, 17 May 2006 14:44:33 -0700
Subject: [Rd] 'R CMD ' doesn't work on Windows
In-Reply-To: <20060517203730.3158DCD14@slim.kubism.ku.dk>
References: <20060517203730.3158DCD14@slim.kubism.ku.dk>
Message-ID: <446B9941.2030200@fhcrc.org>

Hi,

Something else I'd like to report.
If a segmentation fault occurs during the "creating vignettes" step,
then 'R CMD build' ignores the problem and end up building the source
package anyway:

   /loc/biocbuild/1.9d/R/bin/R CMD build RMAGEML
   * checking for file 'RMAGEML/DESCRIPTION' ... OK
   * preparing 'RMAGEML':

   ...

   * DONE (RMAGEML)
   * creating vignettes ...sh: line 1:  8070 Segmentation fault      '/loc/biocbuild/1.9d/R/bin/R' --vanilla --no-save 
--quiet /tmp/Rout656233925 2>&1
    OK
   * cleaning src
   * removing junk files
   * checking for LF line-endings in source files
   * checking for empty or unneeded directories
   * building 'RMAGEML_2.7.0.tar.gz'

'R CMD check' behaves the same way during the "checking package vignettes" step.
I have observed this problem with R 2.3.0 and R 2.4.0 devel (r37925).

Best,

H.

-- 
------------------------
Herv? Pag?s
E-mail: hpages at fhcrc.org
Phone: (206) 667-5791
   Fax: (206) 667-1319


From tdhock at OCF.Berkeley.EDU  Wed May 17 23:45:38 2006
From: tdhock at OCF.Berkeley.EDU (tdhock at OCF.Berkeley.EDU)
Date: Wed, 17 May 2006 23:45:38 +0200 (CEST)
Subject: [Rd] install.packages bug (PR#8873)
Message-ID: <20060517214538.50582B6BA@slim.kubism.ku.dk>

Hello,

I've been using R for about 3 years now and I'm pretty sure this is a bug. 
I'm using R 2.2.0.

The way R is set up to get packages from CRAN using install.packages is 
really convenient --- if you are installing to your system's main package 
directory. However, I observe the following problem:

I want package X but it requires package Y. Further, I have neither 
package right now. And, I want to install both of them to my homedir (say 
at ~/mylib) rather than the main R package directory. What I would want to 
do then is:

> install.packages('X',lib='~/mylib',dependencies=TRUE)

However, this doesn't work. It does notice that X depends on Y and so it 
downloads Y first, but it downloads Y to the wrong directory!! It should 
download both to ~/mylib in my opinion!!!

Sincerely,
Toby Dylan Hocking
http://www.ocf.berkeley.edu/~tdhock


From hpages at fhcrc.org  Wed May 17 23:46:54 2006
From: hpages at fhcrc.org (Herve Pages)
Date: Wed, 17 May 2006 14:46:54 -0700
Subject: [Rd] 'R CMD build' ignoring segfaults occuring during the vignettes
	creation
In-Reply-To: <20060517203730.3158DCD14@slim.kubism.ku.dk>
References: <20060517203730.3158DCD14@slim.kubism.ku.dk>
Message-ID: <446B99CE.1090401@fhcrc.org>

Sorry for erroneous subject of my previous post. Here it goes again.
----------------------------------------------------------------------------

Hi,

Something else I'd like to report.
If a segmentation fault occurs during the "creating vignettes" step,
then 'R CMD build' ignores the problem and end up building the source
package anyway:

   /loc/biocbuild/1.9d/R/bin/R CMD build RMAGEML
   * checking for file 'RMAGEML/DESCRIPTION' ... OK
   * preparing 'RMAGEML':

   ...

   * DONE (RMAGEML)
   * creating vignettes ...sh: line 1:  8070 Segmentation fault      '/loc/biocbuild/1.9d/R/bin/R' --vanilla --no-save
--quiet /tmp/Rout656233925 2>&1
    OK
   * cleaning src
   * removing junk files
   * checking for LF line-endings in source files
   * checking for empty or unneeded directories
   * building 'RMAGEML_2.7.0.tar.gz'

'R CMD check' behaves the same way during the "checking package vignettes" step.
I have observed this problem with R 2.3.0 and R 2.4.0 devel (r37925).

Best,

H.

-- 
------------------------
Herv? Pag?s
E-mail: hpages at fhcrc.org
Phone: (206) 667-5791
   Fax: (206) 667-1319


From sfalcon at fhcrc.org  Wed May 17 23:51:10 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed, 17 May 2006 14:51:10 -0700
Subject: [Rd] 'R CMD config' doesn't work on Windows
In-Reply-To: <446B960B.6000204@fhcrc.org> (Herve Pages's message of "Wed,
	17 May 2006 14:30:51 -0700")
References: <20060517203730.3158DCD14@slim.kubism.ku.dk>
	<446B960B.6000204@fhcrc.org>
Message-ID: <m2psiccoc1.fsf@ziti.fhcrc.org>

Herve Pages <hpages at fhcrc.org> writes:
> I'd like to report this problem I have on Windows with R 2.2.1, R 2.3.0,
> R-2.3.0 patched (r38086) and R 2.4.0 devel (r37925):
>     D:\hpages>R\bin\R CMD config CC
>     Can't open perl script "D:\hpages\R-2.3.1/bin/config": No such file 
> or directory

A bit of background...

For Bioconductor's automated builds, we are trying to provide
developers with more information about the build platforms upon which
their packages are tested.  For example, see here:
http://www.bioconductor.org/checkResults/1.9/gopher5-NodeInfo.html

So R CMD config <var> provides a lot of useful details, but it doesn't
seem to work on Windows for us.  It would be very nice to be able to
provide the same level of detail about our Windows build system.

Cheers,

+ seth


From pinard at iro.umontreal.ca  Thu May 18 03:20:34 2006
From: pinard at iro.umontreal.ca (=?iso-8859-1?Q?Fran=E7ois?= Pinard)
Date: Wed, 17 May 2006 21:20:34 -0400
Subject: [Rd] ?hist and $density explanation
Message-ID: <20060518012034.GA24249@phenix.sram.qc.ca>

Hi, people.  Within ?hist (using R 2.3.0), one reads:

 density: values f^(x[i]), as estimated density values. If
          'all(diff(breaks) == 1)', they are the relative frequencies
          'counts/n' and in general satisfy sum[i; f^(x[i])
          (b[i+1]-b[i])] = 1, where b[i] = 'breaks[i]'.

I trip on this explanation each time I read it.  Some R guardians will 
be tempted to say that since R itself does not trip, I am necessarily 
the problem :-).  But yet, non-obstant and nevertheless, maybe these few 
lines of documentation could be improved.

The "f^(x[i])" bit is somehow cryptic and not explained.  It suggests 
that there are as many densities as possible "i" values, and since "i" 
indexes "x", it indirectly suggests that length(density) == length(x), 
which cannot be right.  The "sum[i; ...]" has to be taken up to the 
number of cells, not the number of "x" values.  Because "x[i]" is a bit 
meaningless in the above context, it should better be avoided.

The "^" may mean that "x[i]" is an index of "f", some kind of TeX device 
for shifting the notation.  It may also means "hat" to suggest the 
density is an approximation.  But the approximation of what?  Of course, 
I understand an untold model by which "density" estimates the density of 
some continuous distribution out of which the "x" values were sampled, 
before the "hist()" function was called.  But "x" is not necessarily 
a sample of a continuum, it may well be the population, and the 
densities in the histogram may well be exact, and not an approximation.  
So it might be simpler to drop the "^" as well.

The concept of relative frequency is explained in case of equal width 
cells only, and not otherwise.  This concept is not reused elsewhere in 
"?hist".  So, it is not so useful, we could use "d" instead of "f".

Finally, writing "breaks[i+1]-breaks[i]" is simpler and clearer than 
introducing an intermediate "b[i]" device.  Let's drop it.


Let me suggest a simpler rewriting of these few lines, using humbler 
notation while being more precise.  Let's start with something like:

 density: For each cell i, density[i] is the proportion of all x[]
          which get sorted into that cell, divided by the cell width.
          So, the value of 'sum(density * diff(breaks))' is 1.

and improve on it.

-- 
Fran?ois Pinard   http://pinard.progiciels-bpi.ca


From meredith at easynet.co.uk  Thu May 18 03:52:51 2006
From: meredith at easynet.co.uk (meredith at easynet.co.uk)
Date: Thu, 18 May 2006 03:52:51 +0200 (CEST)
Subject: [Rd] Noncentral dt() with tiny 'x' values (PR#8874)
Message-ID: <20060518015251.9C9A9CCDA@slim.kubism.ku.dk>

Full_Name: Mike Meredith
Version: 2.3.0
OS: WinXP SP2
Submission from: (NULL) (210.195.228.29)



Using dt() with a non-centrality parameter and near-zero values for 'x' results
in erratic output. Try this:

tst <- c(1e-12, 1e-13, 1e-14, 1e-15, 1e-16, 1e-17, 0)
dt(tst,16,1)

I get:  0.2381019 0.2385462 0.2296557 0.1851817 0.6288373 3.8163916 (!!)
0.2382217

The 0.238 values are okay, the others nonsense, and they cause confusing spikes
on plots of dt() vs 'x' if 'x' happens to include tiny values. (Other values of
df and ncp also malfunction, but not all give results out by an order of
magnitude!)

I'm using the work-around dt(round(x,10),...), but dt() should really take care
of this itself.

Regards,  Mike.


From murdoch at stats.uwo.ca  Thu May 18 04:11:34 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 17 May 2006 22:11:34 -0400
Subject: [Rd] 'R CMD config' doesn't work on Windows
In-Reply-To: <m2psiccoc1.fsf@ziti.fhcrc.org>
References: <20060517203730.3158DCD14@slim.kubism.ku.dk>	<446B960B.6000204@fhcrc.org>
	<m2psiccoc1.fsf@ziti.fhcrc.org>
Message-ID: <446BD7D6.1070702@stats.uwo.ca>

On 5/17/2006 5:51 PM, Seth Falcon wrote:
> Herve Pages <hpages at fhcrc.org> writes:
>> I'd like to report this problem I have on Windows with R 2.2.1, R 2.3.0,
>> R-2.3.0 patched (r38086) and R 2.4.0 devel (r37925):
>>     D:\hpages>R\bin\R CMD config CC
>>     Can't open perl script "D:\hpages\R-2.3.1/bin/config": No such file 
>> or directory
> 
> A bit of background...
> 
> For Bioconductor's automated builds, we are trying to provide
> developers with more information about the build platforms upon which
> their packages are tested.  For example, see here:
> http://www.bioconductor.org/checkResults/1.9/gopher5-NodeInfo.html
> 
> So R CMD config <var> provides a lot of useful details, but it doesn't
> seem to work on Windows for us.  It would be very nice to be able to
> provide the same level of detail about our Windows build system.

What is "config"?  On Windows, it's assumed to be a Perl script stored 
in RHOME/bin and as the message says, there's no such thing.

If it's a .exe or .bat file, you need to specify the extension for R CMD 
to find it.  This is described in the Intro to R manual, in "invoking R 
from the command line".

Duncan Murdoch


From murdoch at stats.uwo.ca  Thu May 18 04:13:44 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 17 May 2006 22:13:44 -0400
Subject: [Rd] install.packages bug (PR#8873)
In-Reply-To: <20060517214538.50582B6BA@slim.kubism.ku.dk>
References: <20060517214538.50582B6BA@slim.kubism.ku.dk>
Message-ID: <446BD858.3010602@stats.uwo.ca>

On 5/17/2006 5:45 PM, tdhock at OCF.Berkeley.EDU wrote:
> Hello,
> 
> I've been using R for about 3 years now and I'm pretty sure this is a bug. 
> I'm using R 2.2.0.

The latest release is 2.3.0 and 2.3.1 has been announced.  Please try 
R-patched (which will become 2.3.1 in a couple of weeks), and see if you 
still have this problem.

Duncan Murdoch
> 
> The way R is set up to get packages from CRAN using install.packages is 
> really convenient --- if you are installing to your system's main package 
> directory. However, I observe the following problem:
> 
> I want package X but it requires package Y. Further, I have neither 
> package right now. And, I want to install both of them to my homedir (say 
> at ~/mylib) rather than the main R package directory. What I would want to 
> do then is:
> 
>> install.packages('X',lib='~/mylib',dependencies=TRUE)
> 
> However, this doesn't work. It does notice that X depends on Y and so it 
> downloads Y first, but it downloads Y to the wrong directory!! It should 
> download both to ~/mylib in my opinion!!!
> 
> Sincerely,
> Toby Dylan Hocking
> http://www.ocf.berkeley.edu/~tdhock
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From sfalcon at fhcrc.org  Thu May 18 05:29:01 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed, 17 May 2006 20:29:01 -0700
Subject: [Rd] 'R CMD config' doesn't work on Windows
In-Reply-To: <446BD7D6.1070702@stats.uwo.ca> (Duncan Murdoch's message of "Wed,
	17 May 2006 22:11:34 -0400")
References: <20060517203730.3158DCD14@slim.kubism.ku.dk>
	<446B960B.6000204@fhcrc.org> <m2psiccoc1.fsf@ziti.fhcrc.org>
	<446BD7D6.1070702@stats.uwo.ca>
Message-ID: <m28xp0c8oy.fsf@ziti.fhcrc.org>

Duncan Murdoch <murdoch at stats.uwo.ca> writes:
> What is "config"?  

    Usage: R CMD config [options] [VAR]
    
    Get the value of a basic R configure variable VAR which must be
    among those listed in the 'Variables' section below, or the header
    and library flags necessary for linking against R.

> On Windows, it's assumed to be a Perl script stored in RHOME/bin and
> as the message says, there's no such thing.

I guess this is a feature request then :-(
Any Perl experts keen on translating the shell script that does R CMD
config?  I assume that is more or less what would be required.


From juha.heljoranta at iki.fi  Thu May 18 08:08:19 2006
From: juha.heljoranta at iki.fi (juha.heljoranta at iki.fi)
Date: Thu, 18 May 2006 08:08:19 +0200 (CEST)
Subject: [Rd] prcomp: problem with zeros? (PR#8870)
Message-ID: <20060518060819.3FA481F9BB@slim.kubism.ku.dk>

Prof Brian Ripley wrote:
>>    Error in svd(x, nu = 0) : infinite or missing values in 'x'
> 
> Why do you say that?  Without a reproducible example, we cannot judge
> what is going on.  If you called prcomp with scale=TRUE on a matrix that
> has a completely zero (or constant) column, then this is a reasonable
> error message.

My bad, the matrix has actually a zero column.

Thank you for your time and sorry for any inconveniences that this may
have caused.

Regards,
Juha Heljoranta


From ripley at stats.ox.ac.uk  Thu May 18 08:24:08 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 18 May 2006 07:24:08 +0100 (BST)
Subject: [Rd] 'R CMD config' doesn't work on Windows
In-Reply-To: <m28xp0c8oy.fsf@ziti.fhcrc.org>
References: <20060517203730.3158DCD14@slim.kubism.ku.dk>
	<446B960B.6000204@fhcrc.org>
	<m2psiccoc1.fsf@ziti.fhcrc.org> <446BD7D6.1070702@stats.uwo.ca>
	<m28xp0c8oy.fsf@ziti.fhcrc.org>
Message-ID: <Pine.LNX.4.64.0605180719350.15879@gannet.stats.ox.ac.uk>

On Wed, 17 May 2006, Seth Falcon wrote:

> Duncan Murdoch <murdoch at stats.uwo.ca> writes:
>> What is "config"?
>
>    Usage: R CMD config [options] [VAR]
>
>    Get the value of a basic R configure variable VAR which must be
>    among those listed in the 'Variables' section below, or the header
>    and library flags necessary for linking against R.
>
>> On Windows, it's assumed to be a Perl script stored in RHOME/bin and
>> as the message says, there's no such thing.
>
> I guess this is a feature request then :-(
> Any Perl experts keen on translating the shell script that does R CMD
> config?  I assume that is more or less what would be required.

You also need to collect the information.  Much of it is only relevant to 
building R on a Unix-alike: as the comment says

## <NOTE>
## The variables are basically the precious configure variables (with
## the R_* and MAIN_* ones removed), plus FLIBS and BLAS_LIBS.

and they are extracted from ${R_HOME}/etc${R_ARCH}/Makeconf which does not 
exist on Windows.

I think it is up to those who feel this is needed to contribute and 
maintin the code.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu May 18 08:54:08 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 18 May 2006 07:54:08 +0100 (BST)
Subject: [Rd] Documentation for taper in spec.taper (PR#8871)
In-Reply-To: <20060517201723.8C3C7CD14@slim.kubism.ku.dk>
References: <20060517201723.8C3C7CD14@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.64.0605180753480.15879@gannet.stats.ox.ac.uk>

Thanks, reworded in R-patched (and later).


On Wed, 17 May 2006, stein at galton.uchicago.edu wrote:

> Full_Name: Michael Stein
> Version: Version 2.1.1
> OS: linux
> Submission from: (NULL) (128.135.149.112)
>
>
> The documentation for spec.taper says
>
>      p: The total proportion to be tapered, either a scalar or a
>          vector of the length of the number of series.
>
> Details:
>
>     The cosine-bell taper is applied to the first and last 'p[i]/2'
>     observations of time series 'x[, i]'.
>
>
> However, the program actually applies the taper to the first and last p[i]
> observations, so 2 * p is the total proportion to be tapered.
>
> The documentation for spec.pgram says
>
>   taper: proportion of data to taper.  A split cosine bell taper is
>          applied to this proportion of the data at the beginning and
>          end of the series.
>
> The second statement is correct, but this means that the proportion of the data
>
> that is tapered is 2 * taper, not taper.  This documentation could easily lead
> to
> users getting twice as much tapering as they think they are getting.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu May 18 09:08:53 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 18 May 2006 08:08:53 +0100 (BST)
Subject: [Rd] 'R CMD config' doesn't work on Windows
In-Reply-To: <Pine.LNX.4.64.0605180719350.15879@gannet.stats.ox.ac.uk>
References: <20060517203730.3158DCD14@slim.kubism.ku.dk>
	<446B960B.6000204@fhcrc.org>
	<m2psiccoc1.fsf@ziti.fhcrc.org> <446BD7D6.1070702@stats.uwo.ca>
	<m28xp0c8oy.fsf@ziti.fhcrc.org>
	<Pine.LNX.4.64.0605180719350.15879@gannet.stats.ox.ac.uk>
Message-ID: <Pine.LNX.4.64.0605180757470.15879@gannet.stats.ox.ac.uk>

On Thu, 18 May 2006, Prof Brian Ripley wrote:

> On Wed, 17 May 2006, Seth Falcon wrote:
>
>> Duncan Murdoch <murdoch at stats.uwo.ca> writes:
>>> What is "config"?
>>
>>    Usage: R CMD config [options] [VAR]
>>
>>    Get the value of a basic R configure variable VAR which must be
>>    among those listed in the 'Variables' section below, or the header
>>    and library flags necessary for linking against R.
>>
>>> On Windows, it's assumed to be a Perl script stored in RHOME/bin and
>>> as the message says, there's no such thing.
>>
>> I guess this is a feature request then :-(
>> Any Perl experts keen on translating the shell script that does R CMD
>> config?  I assume that is more or less what would be required.
>
> You also need to collect the information.  Much of it is only relevant to
> building R on a Unix-alike: as the comment says
>
> ## <NOTE>
> ## The variables are basically the precious configure variables (with
> ## the R_* and MAIN_* ones removed), plus FLIBS and BLAS_LIBS.
>
> and they are extracted from ${R_HOME}/etc${R_ARCH}/Makeconf which does not
> exist on Windows.
>
> I think it is up to those who feel this is needed to contribute and
> maintain the code.

There are a few more problems:

1) The R for Windows build is relocatable, yet some of the answers
will need to be relative to the installation.  Since R CMD knows where 
R_HOME is, it could expand them out, or they could be in terms of R_HOME, 
depending on the intended usage.

2) This will not work when cross-compiling.

3) In some cases the answers are not available, e.g. for TCLTK_CPPFLAGS 
the headers are not usually installed.  So somehow you would have to 
ascertain if this was a source build or a binary distribution.

4) In some cases the answers depend on the MkRules file, which is an 
optional install.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From prechelt at inf.fu-berlin.de  Thu May 18 09:44:51 2006
From: prechelt at inf.fu-berlin.de (Lutz Prechelt)
Date: Thu, 18 May 2006 09:44:51 +0200
Subject: [Rd] R CMD check: "T used instead of TRUE"
Message-ID: <793FF35679078340BCDDA196B495E57EC260@spree.pcpool.mi.fu-berlin.de>

Hello everybody,
 
I am just trying to put together my first own CRAN-able package.
I have completed the programming and my code works OK.
But now when I perform
  R CMD check agsemisc_1.0-2.tar.gz
and R gets to the step
  * checking examples ...
I receive the following error message:
  > print(bwplot(Species~Sepal.Length, data=iris, panel=panel.bwstrip))
  Error in rep(T, length(x)) : T used instead of TRUE
which apparently complains about a use of T that occurs not 
in the example, but rather in the implementation of the function 
called by the example.

I have searched the R-devel archives for a reference to that
error message and in
https://stat.ethz.ch/pipermail/r-devel/2006-February/036520.html
found a mention of function cleanEx() that is
apparently generated by R CMD check(?) and that contains
  delayedAssign("T", stop("T used instead of TRUE"),
    assign.env = .CheckExEnv)
  delayedAssign("F", stop("F used instead of FALSE"),
    assign.env = .CheckExEnv)
(BTW: A rather fascinating feature. I would not have thought
 this possible.)

My questions:

- Is my perception correct that this is meant as a check
  for robust programming style? 
  (Because T might change while TRUE cannot?)
- Is it correct that I should change ALL occurrences of 
  T or F in my package code independent of their context?
  Or are there different kinds of contexts?
- Are there any other similar checks that are performed by
  R CMD check?
- I cannot find such a thing mentioned in Secion 1.3.1 of 
  R-exts.pdf that describes the actions of R CMD check.
  The most pertinent item appears to be number 13:
    "The examples provided by the package's documentation are run."
  Would you say this is a documentation defect that I ought
  to report to R-bugs?

Any help is appreciated.
Thanks in advance,

  Lutz Prechelt

Prof. Dr. Lutz Prechelt; prechelt at inf.fu-berlin.de
Institut fuer Informatik; Freie Universitaet Berlin
Takustr. 9; 14195 Berlin; Germany
+49 30 838 75115; http://www.inf.fu-berlin.de/inst/ag-se/


From ripley at stats.ox.ac.uk  Thu May 18 09:59:24 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 18 May 2006 08:59:24 +0100 (BST)
Subject: [Rd] R CMD check: "T used instead of TRUE"
In-Reply-To: <793FF35679078340BCDDA196B495E57EC260@spree.pcpool.mi.fu-berlin.de>
References: <793FF35679078340BCDDA196B495E57EC260@spree.pcpool.mi.fu-berlin.de>
Message-ID: <Pine.LNX.4.64.0605180851040.18261@gannet.stats.ox.ac.uk>

On Thu, 18 May 2006, Lutz Prechelt wrote:

> Hello everybody,
>
> I am just trying to put together my first own CRAN-able package.
> I have completed the programming and my code works OK.
> But now when I perform
>  R CMD check agsemisc_1.0-2.tar.gz
> and R gets to the step
>  * checking examples ...
> I receive the following error message:
>  > print(bwplot(Species~Sepal.Length, data=iris, panel=panel.bwstrip))
>  Error in rep(T, length(x)) : T used instead of TRUE
> which apparently complains about a use of T that occurs not
> in the example, but rather in the implementation of the function
> called by the example.
>
> I have searched the R-devel archives for a reference to that
> error message and in
> https://stat.ethz.ch/pipermail/r-devel/2006-February/036520.html
> found a mention of function cleanEx() that is
> apparently generated by R CMD check(?) and that contains
>  delayedAssign("T", stop("T used instead of TRUE"),
>    assign.env = .CheckExEnv)
>  delayedAssign("F", stop("F used instead of FALSE"),
>    assign.env = .CheckExEnv)
> (BTW: A rather fascinating feature. I would not have thought
> this possible.)
>
> My questions:
>
> - Is my perception correct that this is meant as a check
>  for robust programming style?
>  (Because T might change while TRUE cannot?)

Yes.

> - Is it correct that I should change ALL occurrences of
>  T or F in my package code independent of their context?
>  Or are there different kinds of contexts?

All those where T and F mean TRUE/FALSE and not variable names.

This is in An Introduction to R, section 2.4.

> - Are there any other similar checks that are performed by
>  R CMD check?
> - I cannot find such a thing mentioned in Secion 1.3.1 of
>  R-exts.pdf that describes the actions of R CMD check.
>  The most pertinent item appears to be number 13:
>    "The examples provided by the package's documentation are run."
>  Would you say this is a documentation defect that I ought
>  to report to R-bugs?

It is the pertinent item (but it is item 14 in current R).  It does not 
say how they are run (and they are for example each run in as clean an 
environment as possible).  I think it would be wrong to assume that the 
description there is exhaustive.  But we'll add a cross-reference.

> Any help is appreciated.
> Thanks in advance,
>
>  Lutz Prechelt
>
> Prof. Dr. Lutz Prechelt; prechelt at inf.fu-berlin.de
> Institut fuer Informatik; Freie Universitaet Berlin
> Takustr. 9; 14195 Berlin; Germany
> +49 30 838 75115; http://www.inf.fu-berlin.de/inst/ag-se/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Thu May 18 11:58:01 2006
From: maechler at stat.math.ethz.ch (maechler at stat.math.ethz.ch)
Date: Thu, 18 May 2006 11:58:01 +0200 (CEST)
Subject: [Rd] Noncentral dt() with tiny 'x' values (PR#8874)
Message-ID: <20060518095801.582EE494E7@slim.kubism.ku.dk>

>>>>> "MikeMer" == meredith  <meredith at easynet.co.uk>
>>>>>     on Thu, 18 May 2006 03:52:51 +0200 (CEST) writes:

    MikeMer> Full_Name: Mike Meredith
    MikeMer> Version: 2.3.0
    MikeMer> OS: WinXP SP2
    MikeMer> Submission from: (NULL) (210.195.228.29)



    MikeMer> Using dt() with a non-centrality parameter and near-zero values for 'x' results
    MikeMer> in erratic output. Try this:

    MikeMer> tst <- c(1e-12, 1e-13, 1e-14, 1e-15, 1e-16, 1e-17, 0)
    MikeMer> dt(tst,16,1)

    MikeMer> I get:  0.2381019 0.2385462 0.2296557 0.1851817 0.6288373 3.8163916 (!!)
    MikeMer> 0.2382217

I get quite different values (several '0', BTW), which just
confirms the erratic nature.

As often, plots give even a clearer picture:

if(!require(sfsmisc)) # pkg 'sfsmisc'
    lseq <- function (from, to, length) 
         2^seq(log2(from), log2(to), length.out = length)
x <- lseq(1e-3, 1e-33, length= 301)

plot(x, dt(x, df=16, ncp=1),   type = "o", cex=.5, log = "x")
plot(x, dt(x, df=16, ncp=0.1), type = "o", cex=.5, log = "x")
plot(x, dt(x, df= 3, ncp=0.1), type = "o", cex=.5, log = "x")



    MikeMer> The 0.238 values are okay, the others nonsense, and
    MikeMer> they cause confusing spikes on plots of dt() vs 'x'
    MikeMer> if 'x' happens to include tiny values. (Other
    MikeMer> values of df and ncp also malfunction, but not all
    MikeMer> give results out by an order of magnitude!)

I think almost all do, once you start looking at plots like the above.

    MikeMer> I'm using the work-around dt(round(x,10),...), but
    MikeMer> dt() should really take care of this itself.

or actually rather do something more smart; the cutoff at 1e-10
is quite crude.

Note that this is not a new bug at all; but rather as old as
we have dt(*, ncp= .) in R.

Thanks for reporting it!
Martin Maechler, ETH Zurich


From benfitz at utk.edu  Thu May 18 14:31:09 2006
From: benfitz at utk.edu (benfitz at utk.edu)
Date: Thu, 18 May 2006 14:31:09 +0200 (CEST)
Subject: [Rd] anova F-tests (PR#8875)
Message-ID: <20060518123109.E9D63CCD9@slim.kubism.ku.dk>

Full_Name: Ben Fitzpatrick
Version: 2.3.0
OS: Windows XP and Mac OSX
Submission from: (NULL) (160.36.15.155)


When you fit a linear model (lm) and use the summary command, the assessment of
the statistical significance of explanatory variables is very different than if
you use the anova command. The F statistics calculated by anova are much larger
than what you get out of SAS, for example. I think R is not calculating F
statistics correctly.
-Ben


From prechelt at inf.fu-berlin.de  Thu May 18 16:00:31 2006
From: prechelt at inf.fu-berlin.de (Lutz Prechelt)
Date: Thu, 18 May 2006 16:00:31 +0200
Subject: [Rd] R CMD check: checking examples: how to (not) pause execution
Message-ID: <793FF35679078340BCDDA196B495E57EC272@spree.pcpool.mi.fu-berlin.de>

Hello all,
 
trying to prepare my first package for submission to CRAN 
I am stumbling over the "checking examples" step
of R CMD check.
 
I have some examples that produce more than one plot.
I currently separate those plot calls by
  readline("Press <Return> for a plot including a density plot")
or some such to have R wait before producing the next plot.

This works OK for end users, but fails miserably 
during R CMD check, which appears to just eat the
next line of the example source file for the input of readline
(which took me quite a while to understand it).

What is the right way to solve this problem?

I can hardly believe that there is none (although the
examples of 'plot' suggest exactly this: They run 
through multiple plots in a hurry.)

I guess the appropriate approach would be if
example() had some kind of single-stepping option?

Any hints?

  Lutz Prechelt

P.S.: 
Documentation remark:
For users struggling with R CMD check it might be
very helpful if R-exts.pdf contained some pointers
to the functions or mechanisms used by R CMD check, 
or the names of source files where to find such information
so they can better understand what is going on.

Prof. Dr. Lutz Prechelt; prechelt at inf.fu-berlin.de
Institut fuer Informatik; Freie Universitaet Berlin
Takustr. 9; 14195 Berlin; Germany
+49 30 838 75115; http://www.inf.fu-berlin.de/inst/ag-se/


From a.trapletti at swissonline.ch  Thu May 18 16:00:53 2006
From: a.trapletti at swissonline.ch (Adrian Trapletti)
Date: Thu, 18 May 2006 16:00:53 +0200
Subject: [Rd] Convention difference in tseries.maxdrawdown (PR#8872)
Message-ID: <446C7E15.9080205@swissonline.ch>

>
> Regarding the upwardly compatible comment, the dollar drawdown that
> corresponds to the maximum fractional drawdown is not necessarily the
> maximum dollar drawdown.
>
> For example, in this situation the maximum fractional drawdown
> is from 100 to 75 but the maximum dollar drawdown is from 200
> to 160.
>
>> x <- c(1, 100, 75, 200, 160)
>
>

What type of drawdown to work with depends on the context. If working in 
percent is more appropriate, then you might use

maxdrawdown(log(x))$maxdrawdown

or if log returns are not appropriate then the following transformation 
provides the equivalent what was suggested

-(exp(-maxdrawdown(log(x))$maxdrawdown)-1)


Best regards
Adrian

>> maximumdrawdown(x) # function defined in post
>
> $maximumdrawdown
> [1] 0.25
>
> $maxdrawdown
> [1] 25
>
> $from
> [1] 2
>
> $to
> [1] 3
>
>> maxdrawdown(x) # function from tseries
>
> $maxdrawdown
> [1] 40
>
> $from
> [1] 4
>
> $to
> [1] 5
>
> On 5/17/06, rproject at boonstra.org <rproject at boonstra.org> wrote:
>
>> Full_Name: Brian K. Boonstra
>> Version: 2.2.1
>> OS: WinXP, OSX
>> Submission from: (NULL) (63.172.178.137)
>>
>>
>> The maxdrawdown function in tseries defines the maximum drawdown in 
>> terms of
>> absolute dollars (or whatever units the input is in).  Industry 
>> convention is to
>> do this in percentage terms.  I have written the code below as
>> maximumdrawdown(), which retains backward compatibility with the current
>> version.  It has the flaw that it does not check for zero or negative 
>> values.
>>
>> maximumdrawdown <- function (x)
>> {
>>    if (NCOL(x) > 1)
>>        stop("x is not a vector or univariate time series")
>>    if (any(is.na(x)))
>>        stop("NAs in x")
>>    cminx <- x/cummax(x)
>>    mdd <- min(cminx)
>>    to <- which(mdd == cminx)
>>    from <- double(NROW(to))
>>    for (i in 1:NROW(to)) {
>>      from[i] <- max( which(cminx[1:to[i]] == 1) )
>>      }
>>    return(list(maximumdrawdown = 1-mdd, maxdrawdown = 
>> (1-mdd)*x[from], from =
>> from, to = to))
>> }
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>


From tlumley at u.washington.edu  Thu May 18 16:10:18 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 18 May 2006 07:10:18 -0700 (PDT)
Subject: [Rd] anova F-tests (PR#8875)
In-Reply-To: <20060518123109.E9D63CCD9@slim.kubism.ku.dk>
References: <20060518123109.E9D63CCD9@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.64.0605180652420.5754@homer24.u.washington.edu>

On Thu, 18 May 2006, benfitz at utk.edu wrote:

> Full_Name: Ben Fitzpatrick
> Version: 2.3.0
> OS: Windows XP and Mac OSX
> Submission from: (NULL) (160.36.15.155)
>
>
> When you fit a linear model (lm) and use the summary command, the assessment of
> the statistical significance of explanatory variables is very different than if
> you use the anova command. The F statistics calculated by anova are much larger
> than what you get out of SAS, for example. I think R is not calculating F
> statistics correctly.


The anova() function is not supposed to give the same results as 
summary().

You don't say *which* SAS results it is "much larger" than (or even 
provide a single example), but if you mean the most common SAS anova table 
based on "Type III SS" then (a) the anova() results are not supposed to be 
the same and (b) it is not true that they are always "much larger". They 
can be the same or (much) smaller.

If you had read the FAQ you would at least know that the anova() output 
was not supposed to be the same as that from SAS. You could then have 
either asked why it was different or asked how to get the output you 
wanted.

If R were really giving completely wrong answers for a very simple and 
widely used analysis and no-one had noticed, an example would still have 
been needed to make this a useful bug report.


 	-thomas


From pgilbert at bank-banque-canada.ca  Thu May 18 16:29:04 2006
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Thu, 18 May 2006 10:29:04 -0400
Subject: [Rd] R CMD check: checking examples: how to (not) pause
	execution
In-Reply-To: <793FF35679078340BCDDA196B495E57EC272@spree.pcpool.mi.fu-berlin.de>
References: <793FF35679078340BCDDA196B495E57EC272@spree.pcpool.mi.fu-berlin.de>
Message-ID: <446C84B0.2060102@bank-banque-canada.ca>

I think the more usual way to solve this is to have the user set 
par(ask=TRUE) is they want to be prompted. This gives the user the 
option of being prompted, or not. It makes the example tests work, and 
simplifies your code because you don't need to worry about the prompt 
mechanism. It also potentially helps with multi-language support, etc, etc.

Paul

Lutz Prechelt wrote:

>Hello all,
> 
>trying to prepare my first package for submission to CRAN 
>I am stumbling over the "checking examples" step
>of R CMD check.
> 
>I have some examples that produce more than one plot.
>I currently separate those plot calls by
>  readline("Press <Return> for a plot including a density plot")
>or some such to have R wait before producing the next plot.
>
>This works OK for end users, but fails miserably 
>during R CMD check, which appears to just eat the
>next line of the example source file for the input of readline
>(which took me quite a while to understand it).
>
>What is the right way to solve this problem?
>
>I can hardly believe that there is none (although the
>examples of 'plot' suggest exactly this: They run 
>through multiple plots in a hurry.)
>
>I guess the appropriate approach would be if
>example() had some kind of single-stepping option?
>
>Any hints?
>
>  Lutz Prechelt
>
>P.S.: 
>Documentation remark:
>For users struggling with R CMD check it might be
>very helpful if R-exts.pdf contained some pointers
>to the functions or mechanisms used by R CMD check, 
>or the names of source files where to find such information
>so they can better understand what is going on.
>
>Prof. Dr. Lutz Prechelt; prechelt at inf.fu-berlin.de
>Institut fuer Informatik; Freie Universitaet Berlin
>Takustr. 9; 14195 Berlin; Germany
>+49 30 838 75115; http://www.inf.fu-berlin.de/inst/ag-se/
>
>______________________________________________
>R-devel at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel
>  
>
-------------- next part --------------
====================================================================================

La version fran?aise suit le texte anglais.

------------------------------------------------------------------------------------

This email may contain privileged and/or confidential inform...{{dropped}}


From ripley at stats.ox.ac.uk  Thu May 18 16:47:35 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 18 May 2006 15:47:35 +0100 (BST)
Subject: [Rd] R CMD check: checking examples: how to (not) pause
	execution
In-Reply-To: <446C84B0.2060102@bank-banque-canada.ca>
References: <793FF35679078340BCDDA196B495E57EC272@spree.pcpool.mi.fu-berlin.de>
	<446C84B0.2060102@bank-banque-canada.ca>
Message-ID: <Pine.LNX.4.64.0605181545050.16258@gannet.stats.ox.ac.uk>

On Thu, 18 May 2006, Paul Gilbert wrote:

> I think the more usual way to solve this is to have the user set 
> par(ask=TRUE) is they want to be prompted. This gives the user the option of 
> being prompted, or not. It makes the example tests work, and simplifies your 
> code because you don't need to worry about the prompt mechanism. It also 
> potentially helps with multi-language support, etc, etc.

And in R-devel example() has an 'ask' argument that has a sensible 
default which sets par(ask=TRUE) when it looks like an interactive 
session.

>
> Paul
>
> Lutz Prechelt wrote:
>
>> Hello all,
>> 
>> trying to prepare my first package for submission to CRAN I am stumbling 
>> over the "checking examples" step
>> of R CMD check.
>> 
>> I have some examples that produce more than one plot.
>> I currently separate those plot calls by
>>  readline("Press <Return> for a plot including a density plot")
>> or some such to have R wait before producing the next plot.
>> 
>> This works OK for end users, but fails miserably during R CMD check, which 
>> appears to just eat the
>> next line of the example source file for the input of readline
>> (which took me quite a while to understand it).
>> 
>> What is the right way to solve this problem?
>> 
>> I can hardly believe that there is none (although the
>> examples of 'plot' suggest exactly this: They run through multiple plots in 
>> a hurry.)
>> 
>> I guess the appropriate approach would be if
>> example() had some kind of single-stepping option?
>> 
>> Any hints?
>>
>>  Lutz Prechelt
>> 
>> P.S.: Documentation remark:
>> For users struggling with R CMD check it might be
>> very helpful if R-exts.pdf contained some pointers
>> to the functions or mechanisms used by R CMD check, or the names of source 
>> files where to find such information
>> so they can better understand what is going on.
>> 
>> Prof. Dr. Lutz Prechelt; prechelt at inf.fu-berlin.de
>> Institut fuer Informatik; Freie Universitaet Berlin
>> Takustr. 9; 14195 Berlin; Germany
>> +49 30 838 75115; http://www.inf.fu-berlin.de/inst/ag-se/
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jranke at uni-bremen.de  Thu May 18 17:14:34 2006
From: jranke at uni-bremen.de (jranke at uni-bremen.de)
Date: Thu, 18 May 2006 17:14:34 +0200 (CEST)
Subject: [Rd] predict.lm does not have a weights argument for newdata
	(PR#8877)
Message-ID: <20060518151434.8DD8624781@slim.kubism.ku.dk>

Full_Name: Johannes Ranke
Version: 2.3.0
OS: Linux-i386
Submission from: (NULL) (134.102.60.74)


In the case that predict.lm is used on an object resulting from weighted linear
regression with interval="prediction", the prediction intervals currently depend
on 
the absolute size of object$weights:

data(anscombe); attach(anscombe)
m1 <- lm(y1 ~ x1, w = rep(1,length(x1)))
m2 <- lm(y1 ~ x1, w = rep(3,length(x1)))
predict(m1, data.frame(x1 = 5), interval = "prediction")
predict(m2, data.frame(x1 = 5), interval = "prediction")

This make sense only if the weights are taken to be the numbers of replicates
used
for deriving the x values in newdata, and even then, the given prediction
interval
is only correct if the number of replicates for establishing the x values in
newdata is always one.

The desired behavior would be that the user gives a vector weights.newdata for
newdata, matching the weighting scheme applied for the weighted regression (e.g.
calculated from a variance function).

My education in statistics is only medium, so I am not sure if my proposed
solution is correct. Please check my patch to fix this:

--- lm.R.orig   2006-04-10 00:19:39.000000000 +0200
+++ lm.R        2006-05-18 17:10:29.000000000 +0200
@@ -591,7 +591,8 @@
     function(object, newdata, se.fit = FALSE, scale = NULL, df = Inf,
             interval = c("none", "confidence", "prediction"),
             level = .95,  type = c("response", "terms"),
-            terms = NULL, na.action = na.pass, ...)
+            terms = NULL, na.action = na.pass, ...,
+       weights.newdata = rep(1, length(newdata[[1]])))
 {
     tt <- terms(object)
     if(missing(newdata) || is.null(newdata)) {
@@ -630,6 +631,11 @@
                r <- object$residuals
                w <- object$weights
                rss <- sum(if(is.null(w)) r^2 else r^2 * w)
+    if(!is.null(w) && interval == "prediction" && weights.newdata ==
rep(1,length(newdata[[1]]))) {
+        warning(paste(
+          "To find prediction intervals from linear models with weights,",
+          "you probably want weights.newdata different from one."))
+    }
                df <- n - p
                rss/df
            } else scale^2
@@ -715,7 +721,7 @@
        tfrac <- qt((1 - level)/2, df)
        hwid <- tfrac * switch(interval,
                               confidence = sqrt(ip),
-                              prediction = sqrt(ip+res.var)
+                              prediction = sqrt(ip+res.var/weights.newdata)
                               )
        if(type != "terms") {
            predictor <- cbind(predictor, predictor + hwid %o% c(1, -1))

---------------------------end patch-------------------------------------------

if you apply this to lm.R, you get the same result from both lines:

predict(m1, data.frame(x1 = 5), interval = "prediction") 
predict(m2, data.frame(x1 = 5), interval = "prediction", weights.newdata = 3)

except that you get a warning if you set all newweights to one (default),
because this is probably not what you want for a prediction interval from
weighted regression.

All it does is to (down)scale the part of the variance that each new data point
contributes to the variance of the predicted y.


From kevin.hendricks at sympatico.ca  Thu May 18 17:46:43 2006
From: kevin.hendricks at sympatico.ca (Kevin B. Hendricks)
Date: Thu, 18 May 2006 11:46:43 -0400
Subject: [Rd] helping out
Message-ID: <8A036DC9-74BA-4AB2-B6AB-7C20BFC9D5B2@sympatico.ca>

Hi,

I just joined the list and wanted to introduce myself.  I am a  
professor of operations management at a Canadian University and an  
empirical researcher (using mainly archival data from finance and  
accounting primarily with econometric methods).  I have finally made  
the leap to remove all of SAS from my machines (damn license code  
nonsense was killing me) and decided to adopt R.  So I am very new to  
the R system and still just getting up to speed (reading the fine  
*long* manuals and etc).

I am also an old programmer (read that late 1970s, early 1980s  
timeframe) and more recently I have been an open source volunteer for  
OpenOffice.org (ran their lingucomponent project until last year), a  
volunteer for the Blackdown Java project (helped do the initial port  
of Java 1.1.1 to PowerPC Linux) and I have submitted bug fixes and  
patches to the Linux kernel, glibc, gcc, and the like,  mainly to  
support PPC Linux.  I now primarily use x86_64 Linux and MacOSX.  I  
can program in C, C++, Fortran and a number of other languages.

So once I get up to speed, I would love to volunteer to help pay back  
for the really nice system you have made available.

I found this mailing list by accident looking for something to tell  
me about the NULL environment issue that hit me when I moved from  
version 2.2.1 to version 2.3.0.  If there is a developers page that  
lists cvs checkout info (or do you use subversion or some other  
system) and the details of who to submit all patches and things to  
(is this list for diffs?), I would love to be pointed at it.

I am on too many mailing lists right now, so I signed up for digest  
mode.  So if anyone wants/needs an immediate response please simply  
cc me.

Thanks,

Kevin Hendricks


Professor of Operations Management and Information Technology
Richard Ivey School of Business
University of Western Ontario
London, ON
kevin.hendricks at sympatico.ca


From pinard at iro.umontreal.ca  Thu May 18 17:50:47 2006
From: pinard at iro.umontreal.ca (pinard at iro.umontreal.ca)
Date: Thu, 18 May 2006 17:50:47 +0200 (CEST)
Subject: [Rd] Truncated labels in hist (PR#8864)
Message-ID: <20060518155047.B5BC0494E2@slim.kubism.ku.dk>

[paul murrell]

>I can get this (on Windows, but I'm sure elsewhere too) by just 
>resizing the window.  The report is correct in that the hist() does not 
>ensure that there is room for labels on the plot, but this seems more 
>like a wish-list item than a bug.

Hi, Paul.  Thanks for the feedback!

Should I confess, at least for the R project, I sometimes miss the 
subtleties between wish-list items and bugs -- not only for this one, 
but in general.  We surely wish bugs to be addressed: this, I get :-).

But I sometimes feel we exaggerate the exegesis of the distinction 
between wishes and bugs, as this exercise is a bit irritating, without 
being fruitful.  I wonder why the distinction is deemed so important.

Merely chatting, of course.   Keep happy!

-- 
Fran?ois Pinard   http://pinard.progiciels-bpi.ca


From pgilbert at bank-banque-canada.ca  Thu May 18 17:59:37 2006
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Thu, 18 May 2006 11:59:37 -0400
Subject: [Rd] R-devel and PGI 6.0 compile error
Message-ID: <446C99E9.7080206@bank-banque-canada.ca>


I am trying to compile R-devel (R-devel_2006-05-17.tar.gz) on Red Hat 
Enterprise Linux AS release 3 (Taroon Update 7) using the Portland Group 
compiler 6.0.  (I have not yet successful compiled R on this 
configuration, so I don't know if this is a new problem.) I get an error

pgcc -L/usr/local/pgi/linux86-64/6.0/libso -L/usr/lib64 -o dftables 
dftables.o
../dftables chartables.h
../dftables: error while loading shared libraries: libpgc.so: cannot open 
shared object file: No such file or directory
make[3]: *** [chartables.h] Error 127

The library containing  libpgc.so is in both my LD_LIBRARY_PATH and in 
LDFLAGS. More details are below. In configure I am also getting

checking whether C99 double complex is supported...
checking complex.h usability... no
checking complex.h presence... yes
configure: WARNING: complex.h: present but cannot be compiled
configure: WARNING: complex.h:     check for missing prerequisite headers?
configure: WARNING: complex.h: see the Autoconf documentation
configure: WARNING: complex.h:     section "Present But Cannot Be Compiled"
configure: WARNING: complex.h: proceeding with the preprocessor's result
configure: WARNING: complex.h: in the future, the compiler will take 
precedence
configure: WARNING:     ## ----------------------------------- ##
configure: WARNING:     ## Report this to r-bugs at R-project.org ##
configure: WARNING:     ## ----------------------------------- ##
checking for complex.h... yes

Paul Gilbert

_____________________

~/toolchain/R/clusterPGI/R-devel:../../src/R-devel/configure  --with-x=no
checking build system type... x86_64-unknown-linux-gnu
checking host system type... x86_64-unknown-linux-gnu
loading site script '../../src/R-devel/config.site'
checking for pwd... /bin/pwd
checking whether builddir is srcdir... no
checking for working aclocal... found
checking for working autoconf... found
checking for working automake... found
checking for working autoheader... found
checking for working makeinfo... found
checking for gawk... gawk
checking for egrep... grep -E
checking whether ln -s works... yes
checking for ranlib... ranlib
checking for bison... bison -y
checking for ar... ar
checking for a BSD-compatible install... /usr/bin/install -c
checking for sed... /bin/sed
checking for less... /usr/bin/less
checking for perl... /usr/bin/perl
checking whether perl version is at least 5.004... yes
checking for dvips... no
checking for tex... no
checking for latex... no
configure: WARNING: you cannot build DVI versions of the R manuals
checking for makeindex... no
checking for pdftex... no
checking for pdflatex... no
configure: WARNING: you cannot build PDF versions of the R manuals
checking for makeinfo... /usr/bin/makeinfo
checking for unzip... /usr/bin/unzip
checking for zip... /usr/bin/zip
checking for gzip... /bin/gzip
checking for firefox... no
checking for mozilla... no
checking for netscape... no
checking for galeon... no
checking for kfmclient... no
checking for opera... no
checking for gnome-moz-remote... no
checking for open... /usr/bin/open
using default browser ... /usr/bin/open
checking for acroread... no
checking for acroread4... no
checking for xpdf... no
checking for gv... no
checking for gnome-gv... no
checking for ggv... no
checking for kghostview... no
checking for open... /usr/bin/open
checking for gcc... pgcc
checking for C compiler default output file name... a.out
checking whether the C compiler works... yes
checking whether we are cross compiling... no
checking for suffix of executables...
checking for suffix of object files... o
checking whether we are using the GNU C compiler... no
checking whether pgcc accepts -g... yes
checking for pgcc option to accept ANSI C... none needed
checking how to run the C preprocessor... pgcc -E
checking how to run the C preprocessor... pgcc -E
defining F77 to be pgf77
checking whether we are using the GNU Fortran 77 compiler... no
checking whether pgf77 accepts -g... yes
checking whether we are using the GNU C++ compiler... no
checking whether pgCC accepts -g... yes
checking how to run the C++ preprocessor... pgCC -E
checking whether __attribute__((visibility())) is supported... no
checking whether pgcc accepts -fvisibility... yes
checking whether pgf77 accepts -fvisibility... yes
checking for a sed that does not truncate output... /bin/sed
checking for non-GNU ld... /usr/bin/ld
checking if the linker (/usr/bin/ld) is GNU ld... yes
checking for /usr/bin/ld option to reload object files... -r
checking for BSD-compatible nm... /usr/bin/nm -B
checking how to recognise dependent libraries... pass_all
checking for ANSI C header files... yes
checking for sys/types.h... yes
checking for sys/stat.h... yes
checking for stdlib.h... yes
checking for string.h... yes
checking for memory.h... yes
checking for strings.h... yes
checking for inttypes.h... yes
checking for stdint.h... yes
checking for unistd.h... yes
checking dlfcn.h usability... yes
checking dlfcn.h presence... yes
checking for dlfcn.h... yes
checking the maximum length of command line arguments... 32768
checking command to parse /usr/bin/nm -B output from pgcc object... ok
checking for objdir... .libs
checking for ranlib... (cached) ranlib
checking for strip... strip
checking if pgcc static flag  works... yes
checking for pgcc option to produce PIC...
checking if pgcc supports -c -o file.o... yes
checking whether the pgcc linker (/usr/bin/ld -m elf_x86_64) supports 
shared libraries... yes
checking dynamic linker characteristics... GNU/Linux ld.so
checking how to hardcode library paths into programs... immediate
checking whether stripping libraries is possible... yes
checking if libtool supports shared libraries... yes
checking whether to build shared libraries... yes
checking whether to build static libraries... no
configure: creating libtool
appending configuration tag "CXX" to libtool
checking whether the pgCC linker (/usr/bin/ld -m elf_x86_64) supports 
shared libraries... yes
checking for pgCC option to produce PIC...
checking if pgCC supports -c -o file.o... yes
checking whether the pgCC linker (/usr/bin/ld -m elf_x86_64) supports 
shared libraries... yes
checking dynamic linker characteristics... GNU/Linux ld.so
checking how to hardcode library paths into programs... immediate
checking whether stripping libraries is possible... yes
appending configuration tag "F77" to libtool
checking if libtool supports shared libraries... yes
checking whether to build shared libraries... yes
checking whether to build static libraries... no
checking for pgf77 option to produce PIC...
checking if pgf77 supports -c -o file.o... yes
checking whether the pgf77 linker (/usr/bin/ld -m elf_x86_64) supports 
shared libraries... yes
checking dynamic linker characteristics... GNU/Linux ld.so
checking how to hardcode library paths into programs... immediate
checking whether stripping libraries is possible... yes
checking whether makeinfo version is at least 4.7... no
configure: WARNING: you cannot build info or html versions of the R manuals
checking for cos in -lm... yes
checking for sin in -lm... yes
checking for dlopen in -ldl... yes
checking readline/history.h usability... yes
checking readline/history.h presence... yes
checking for readline/history.h... yes
checking readline/readline.h usability... yes
checking readline/readline.h presence... yes
checking for readline/readline.h... yes
checking for rl_callback_read_char in -lreadline... no
checking for main in -lncurses... yes
checking for rl_callback_read_char in -lreadline... yes
checking for history_truncate_file... yes
checking for ANSI C header files... (cached) yes
checking whether time.h and sys/time.h may both be included... yes
checking for dirent.h that defines DIR... yes
checking for library containing opendir... none required
checking for sys/wait.h that is POSIX.1 compatible... yes
checking arpa/inet.h usability... yes
checking arpa/inet.h presence... yes
checking for arpa/inet.h... yes
checking dl.h usability... no
checking dl.h presence... no
checking for dl.h... no
checking for dlfcn.h... (cached) yes
checking elf.h usability... yes
checking elf.h presence... yes
checking for elf.h... yes
checking fcntl.h usability... yes
checking fcntl.h presence... yes
checking for fcntl.h... yes
checking floatingpoint.h usability... no
checking floatingpoint.h presence... no
checking for floatingpoint.h... no
checking fpu_control.h usability... yes
checking fpu_control.h presence... yes
checking for fpu_control.h... yes
checking grp.h usability... yes
checking grp.h presence... yes
checking for grp.h... yes
checking ieee754.h usability... yes
checking ieee754.h presence... yes
checking for ieee754.h... yes
checking ieeefp.h usability... no
checking ieeefp.h presence... no
checking for ieeefp.h... no
checking limits.h usability... yes
checking limits.h presence... yes
checking for limits.h... yes
checking locale.h usability... yes
checking locale.h presence... yes
checking for locale.h... yes
checking netdb.h usability... yes
checking netdb.h presence... yes
checking for netdb.h... yes
checking netinet/in.h usability... yes
checking netinet/in.h presence... yes
checking for netinet/in.h... yes
checking pwd.h usability... yes
checking pwd.h presence... yes
checking for pwd.h... yes
checking for strings.h... (cached) yes
checking sys/param.h usability... yes
checking sys/param.h presence... yes
checking for sys/param.h... yes
checking sys/select.h usability... yes
checking sys/select.h presence... yes
checking for sys/select.h... yes
checking sys/socket.h usability... yes
checking sys/socket.h presence... yes
checking for sys/socket.h... yes
checking for sys/stat.h... (cached) yes
checking sys/resource.h usability... yes
checking sys/resource.h presence... yes
checking for sys/resource.h... yes
checking sys/time.h usability... yes
checking sys/time.h presence... yes
checking for sys/time.h... yes
checking sys/times.h usability... yes
checking sys/times.h presence... yes
checking for sys/times.h... yes
checking sys/utsname.h usability... yes
checking sys/utsname.h presence... yes
checking for sys/utsname.h... yes
checking time.h usability... yes
checking time.h presence... yes
checking for time.h... yes
checking for unistd.h... (cached) yes
checking errno.h usability... yes
checking errno.h presence... yes
checking for errno.h... yes
checking for inttypes.h... (cached) yes
checking stdarg.h usability... yes
checking stdarg.h presence... yes
checking for stdarg.h... yes
checking for stdint.h... (cached) yes
checking for string.h... (cached) yes
checking whether setjmp.h is POSIX.1 compatible... yes
checking whether sigsetjmp is declared... yes
checking whether siglongjmp is declared... yes
checking for GNU C library with version >= 2... yes
checking return type of signal handlers... void
checking for pid_t... yes
checking for size_t... yes
checking whether SIZE_MAX is declared... yes
checking for blkcnt_t... yes
checking for type of socket length... socklen_t *
checking for stack_t... yes
checking for intptr_t... yes
checking for uintptr_t... yes
checking whether byte ordering is bigendian... no
checking for an ANSI C-conforming const... yes
checking for inline... inline
checking for int... yes
checking size of int... 4
checking for long... yes
checking size of long... 8
checking for long long... yes
checking size of long long... 8
checking for long double... yes
checking size of long double... 8
checking whether we can compute C Make dependencies... yes, using cpp -M
checking whether pgcc supports -c -o FILE.lo... yes
checking how to get verbose linking output from pgf77... -v
checking for Fortran libraries of pgf77...  
-L/usr/local/pgi/linux86-64/6.0/libso -L/usr/lib64' -L/usr/lib64 
-L/usr/local/pgi/linux86-64/6.0/lib 
-L/usr/lib/gcc-lib/x86_64-redhat-linux/3.2.3 -lpgftnrtl -lnspgc -lpgc -lm
checking how to get verbose linking output from pgcc... -v
checking for C libraries of pgcc...  
-L/usr/local/pgi/linux86-64/6.0/libso -L/usr/lib64' -L/usr/lib64 
-L/usr/local/pgi/linux86-64/6.0/lib 
-L/usr/lib/gcc-lib/x86_64-redhat-linux/3.2.3 -lnspgc -lpgc -lm
checking for dummy main to link with Fortran libraries... none
checking for Fortran name-mangling scheme... lower case, underscore, no 
extra underscore
checking whether pgf77 appends underscores to external names... yes
checking whether pgf77 appends extra underscores to external names... no
checking whether mixed C/Fortran code can be run... yes
checking whether pgf77 and pgcc agree on int and double... yes
checking whether pgf77 and pgcc agree on double complex... yes
checking whether pgCC accepts -M for generating dependencies... yes
checking whether C runtime needs -D__NO_MATH_INLINES... no
checking for xmkmf... no
checking for off_t... yes
checking for working alloca.h... yes
checking for alloca... yes
checking whether alloca is declared... yes
checking for fseeko... yes
checking for ftello... yes
checking for isblank... yes
checking for matherr... yes
checking whether fcntl exists and is declared... yes
checking whether getgrgid exists and is declared... yes
checking whether expm1 exists and is declared... yes
checking whether hypot exists and is declared... yes
checking whether log1p exists and is declared... yes
checking whether log2 exists and is declared... no
checking whether log10 exists and is declared... yes
checking whether rint exists and is declared... yes
checking whether getpwuid exists and is declared... yes
checking whether sigaction exists and is declared... yes
checking whether sigaltstack exists and is declared... yes
checking whether sigemptyset exists and is declared... yes
checking whether va_copy exists and is declared... yes
checking whether __va_copy exists and is declared... no
checking whether fdopen exists and is declared... yes
checking whether popen exists and is declared... yes
checking whether realpath exists and is declared... yes
checking whether setenv exists and is declared... yes
checking whether system exists and is declared... yes
checking whether unsetenv exists and is declared... yes
checking whether strcoll exists and is declared... yes
checking whether strerror exists and is declared... yes
checking whether getrlimit exists and is declared... yes
checking whether getrusage exists and is declared... yes
checking whether mkfifo exists and is declared... yes
checking whether stat exists and is declared... yes
checking whether gettimeofday exists and is declared... yes
checking whether times exists and is declared... yes
checking whether access exists and is declared... yes
checking whether chdir exists and is declared... yes
checking whether ftruncate exists and is declared... yes
checking whether getcwd exists and is declared... yes
checking whether getuid exists and is declared... yes
checking whether symlink exists and is declared... yes
checking whether sysconf exists and is declared... yes
checking for putenv... yes
checking whether putenv is declared... yes
checking for vasprintf... yes
checking whether vasprintf is declared... no
checking for finite... yes
checking for isnan... yes
checking whether isfinite is declared... no
checking whether isnan is declared... yes
checking whether you have IEEE 754 floating-point arithmetic... yes
checking for nl_langinfo and CODESET... yes
checking for acosh... yes
checking for asinh... yes
checking for atanh... yes
checking for mkdtemp... yes
checking for snprintf... yes
checking for strdup... yes
checking for strncasecmp... yes
checking for vsnprintf... yes
checking whether acosh is declared... yes
checking whether asinh is declared... yes
checking whether atanh is declared... yes
checking whether mkdtemp is declared... yes
checking whether snprintf is declared... yes
checking whether strdup is declared... yes
checking whether strncasecmp is declared... yes
checking whether vsnprintf is declared... yes
checking for library containing connect... none required
checking for library containing gethostbyname... none required
checking for library containing xdr_string... none required
checking for __setfpucw... no
checking for working calloc... yes
checking for working finite... no
checking for working log... no
checking for working log1p... yes
checking whether ftell works correctly on files opened for append... yes
checking whether C99 double complex is supported...
checking complex.h usability... no
checking complex.h presence... yes
configure: WARNING: complex.h: present but cannot be compiled
configure: WARNING: complex.h:     check for missing prerequisite headers?
configure: WARNING: complex.h: see the Autoconf documentation
configure: WARNING: complex.h:     section "Present But Cannot Be Compiled"
configure: WARNING: complex.h: proceeding with the preprocessor's result
configure: WARNING: complex.h: in the future, the compiler will take 
precedence
configure: WARNING:     ## ----------------------------------- ##
configure: WARNING:     ## Report this to r-bugs at R-project.org ##
configure: WARNING:     ## ----------------------------------- ##
checking for complex.h... yes
checking for double complex... no
no
checking for cblas_cdotu_sub in vecLib framework... no
checking for dgemm_... no
checking for ATL_xerbla in -latlas... no
checking for dgemm_ in -lblas... yes
checking for dgemm_ in -ldgemm... no
checking for dgemm_ in -lsunperf... no
checking for dgemm_ in -lblas... (cached) yes
checking for dgemm_ in -lessl... no
checking for dgemm_ in -lblas... (cached) yes
checking whether double complex BLAS can be used... no
checking iconv.h usability... yes
checking iconv.h presence... yes
checking for iconv.h... yes
checking for iconv... yes
checking whether iconv() accepts "UTF-8", "latin1" and "UCS-*"... yes
checking for iconvlist... no
checking wchar.h usability... yes
checking wchar.h presence... yes
checking for wchar.h... yes
checking wctype.h usability... yes
checking wctype.h presence... yes
checking for wctype.h... yes
checking whether mbrtowc exists and is declared... yes
checking whether wcrtomb exists and is declared... yes
checking whether wcscoll exists and is declared... yes
checking whether wcsftime exists and is declared... yes
checking whether mbstowcs exists and is declared... yes
checking whether wcstombs exists and is declared... yes
checking whether wctrans exists and is declared... yes
checking whether iswblank exists and is declared... no
checking whether wctype exists and is declared... yes
checking whether iswctype exists and is declared... yes
checking for wctrans_t... yes
checking for mbstate_t... yes
checking for X... disabled
using X11 ... no
checking for CFStringGetSystemEncoding in CoreFoundation framework... no
checking for tclConfig.sh... no
checking for tclConfig.sh in library (sub)directories... 
/usr/lib64/tclConfig.shchecking for tkConfig.sh... no
checking for tkConfig.sh in library (sub)directories... 
/usr/lib64/tkConfig.sh
checking /usr/include/tcl8.3/generic/tcl.h usability... no
checking /usr/include/tcl8.3/generic/tcl.h presence... no
checking for /usr/include/tcl8.3/generic/tcl.h... no
checking /usr/include/tcl8.3/tcl.h usability... no
checking /usr/include/tcl8.3/tcl.h presence... no
checking for /usr/include/tcl8.3/tcl.h... no
checking /usr/include/tcl.h usability... no
checking /usr/include/tcl.h presence... no
checking for /usr/include/tcl.h... no
checking for tcl.h... no
checking for BSD networking... yes
checking if jpeglib version >= 6b... no
checking for main in -lz... yes
checking if libpng version >= 1.0.5... no
checking rpc/types.h usability... yes
checking rpc/types.h presence... yes
checking for rpc/types.h... yes
checking for rpc/xdr.h... yes
checking for XDR support... yes
checking whether zlib support needs to be compiled... yes
checking mmap support for zlib... yes
checking whether bzip2 support needs to be compiled... yes
checking whether PCRE support needs to be compiled... yes
checking whether leap seconds are treated according to POSIX... yes
checking for setitimer... yes
checking for special C compiler options needed for large files... no
checking for _FILE_OFFSET_BITS value needed for large files... no
checking for _LARGE_FILES value needed for large files... no
checking for _LARGEFILE_SOURCE value needed for large files... 1
checking for fseeko... (cached) yes
checking whether KERN_USRSTACK sysctl is supported... no
checking for lpr... lpr
checking for paperconf... false
checking for java... /usr/bin/java
checking for javac... /usr/bin/javac
checking whether Java interpreter works... no
checking for f95... no
checking for fort... no
checking for xlf95... no
checking for ifc... no
checking for efc... no
checking for pgf95... pgf95
checking whether we are using the GNU Fortran compiler... no
checking whether pgf95 accepts -g... yes
checking for Fortran flag to compile .f90 files... none
checking for Fortran flag to compile .f95 files... none
checking for recommended packages... yes
checking whether NLS is requested... yes
checking whether make sets $(MAKE)... yes
checking for msgfmt... /usr/bin/msgfmt
checking for gmsgfmt... /usr/bin/msgfmt
checking for xgettext... no
checking for msgmerge... /usr/bin/msgmerge
checking whether we are using the GNU C Library 2 or newer... yes
checking for library containing strerror... none required
checking for signed... yes
checking for inline... inline
checking for off_t... (cached) yes
checking for long long... (cached) yes
checking for long double... yes
checking for wchar_t... yes
checking for wint_t... yes
checking for inttypes.h... yes
checking for stdint.h... yes
checking for intmax_t... yes
checking whether printf() supports POSIX/XSI format strings... yes
checking for stdlib.h... (cached) yes
checking for unistd.h... (cached) yes
checking for getpagesize... yes
checking for working mmap... yes
checking whether we are using the GNU C Library 2.1 or newer... yes
checking whether integer division by zero raises SIGFPE... yes
checking for unsigned long long... yes
checking for inttypes.h... yes
checking whether the inttypes.h PRIxNN macros are broken... no
checking for stdint.h... (cached) yes
checking for SIZE_MAX... yes
checking for stdint.h... (cached) yes
checking for CFPreferencesCopyAppValue... no
checking for CFLocaleCopyCurrent... no
checking for GNU ld... /usr/bin/ld -m elf_x86_64
checking if the linker (/usr/bin/ld -m elf_x86_64) is GNU ld... yes
checking for shared library run path origin... done
checking for ptrdiff_t... yes
checking argz.h usability... yes
checking argz.h presence... yes
checking for argz.h... yes
checking for limits.h... (cached) yes
checking for locale.h... (cached) yes
checking nl_types.h usability... yes
checking nl_types.h presence... yes
checking for nl_types.h... yes
checking malloc.h usability... yes
checking malloc.h presence... yes
checking for malloc.h... yes
checking stddef.h usability... yes
checking stddef.h presence... yes
checking for stddef.h... yes
checking for stdlib.h... (cached) yes
checking for string.h... (cached) yes
checking for unistd.h... (cached) yes
checking for sys/param.h... (cached) yes
checking for asprintf... yes
checking for fwprintf... yes
checking for getcwd... yes
checking for getegid... yes
checking for geteuid... yes
checking for getgid... yes
checking for getuid... yes
checking for mempcpy... yes
checking for munmap... yes
checking for putenv... (cached) yes
checking for setenv... yes
checking for setlocale... yes
checking for snprintf... (cached) yes
checking for stpcpy... yes
checking for strcasecmp... yes
checking for strdup... (cached) yes
checking for strtoul... yes
checking for tsearch... yes
checking for wcslen... yes
checking for __argz_count... yes
checking for __argz_stringify... yes
checking for __argz_next... yes
checking for __fsetlocking... yes
checking whether _snprintf is declared... no
checking whether _snwprintf is declared... no
checking whether feof_unlocked is declared... yes
checking whether fgets_unlocked is declared... no
checking whether getc_unlocked is declared... yes
checking for iconv... yes
checking for iconv declaration...
         extern size_t iconv (iconv_t cd, char * *inbuf, size_t 
*inbytesleft, char * *outbuf, size_t *outbytesleft);
checking for nl_langinfo and CODESET... (cached) yes
checking for LC_MESSAGES... yes
checking for bison... bison
checking version of bison... 1.875, ok
checking for CFPreferencesCopyAppValue... (cached) no
checking for CFLocaleCopyCurrent... (cached) no
checking whether NLS is requested... yes
checking whether included gettext is requested... no
checking for GNU gettext in libc... yes
checking whether to use NLS... yes
checking where the gettext function comes from... libc
configure: creating ./config.status
config.status: creating Makeconf
config.status: creating Makefile
config.status: creating doc/Makefile
config.status: creating doc/html/Makefile
config.status: creating doc/html/search/Makefile
config.status: creating doc/manual/Makefile
config.status: creating etc/Makefile
config.status: creating etc/Makeconf
config.status: creating etc/Renviron
config.status: creating etc/ldpaths
config.status: creating m4/Makefile
config.status: creating po/Makefile.in
config.status: creating share/Makefile
config.status: creating src/Makefile
config.status: creating src/appl/Makefile
config.status: creating src/extra/Makefile
config.status: creating src/extra/bzip2/Makefile
config.status: creating src/extra/intl/Makefile
config.status: creating src/extra/pcre/Makefile
config.status: creating src/extra/xdr/Makefile
config.status: creating src/extra/zlib/Makefile
config.status: creating src/include/Makefile
config.status: creating src/include/Rmath.h0
config.status: creating src/include/R_ext/Makefile
config.status: creating src/library/Recommended/Makefile
config.status: creating src/library/Makefile
config.status: creating src/library/base/DESCRIPTION
config.status: creating src/library/base/Makefile
config.status: creating src/library/datasets/DESCRIPTION
config.status: creating src/library/datasets/Makefile
config.status: creating src/library/graphics/DESCRIPTION
config.status: creating src/library/graphics/Makefile
config.status: creating src/library/grDevices/DESCRIPTION
config.status: creating src/library/grDevices/Makefile
config.status: creating src/library/grDevices/src/Makefile
config.status: creating src/library/grid/DESCRIPTION
config.status: creating src/library/grid/Makefile
config.status: creating src/library/grid/src/Makefile
config.status: creating src/library/methods/DESCRIPTION
config.status: creating src/library/methods/Makefile
config.status: creating src/library/methods/src/Makefile
config.status: creating src/library/profile/Makefile
config.status: creating src/library/stats/DESCRIPTION
config.status: creating src/library/stats/Makefile
config.status: creating src/library/stats/src/Makefile
config.status: creating src/library/stats4/DESCRIPTION
config.status: creating src/library/stats4/Makefile
config.status: creating src/library/splines/DESCRIPTION
config.status: creating src/library/splines/Makefile
config.status: creating src/library/splines/src/Makefile
config.status: creating src/library/tcltk/DESCRIPTION
config.status: creating src/library/tcltk/Makefile
config.status: creating src/library/tcltk/src/Makefile
config.status: creating src/library/tools/DESCRIPTION
config.status: creating src/library/tools/Makefile
config.status: creating src/library/tools/src/Makefile
config.status: creating src/library/utils/DESCRIPTION
config.status: creating src/library/utils/Makefile
config.status: creating src/main/Makefile
config.status: creating src/modules/Makefile
config.status: creating src/modules/X11/Makefile
config.status: creating src/modules/internet/Makefile
config.status: creating src/modules/lapack/Makefile
config.status: creating src/modules/vfonts/Makefile
config.status: creating src/nmath/Makefile
config.status: creating src/nmath/standalone/Makefile
config.status: creating src/scripts/Makefile
config.status: creating src/scripts/COMPILE
config.status: creating src/scripts/INSTALL
config.status: creating src/scripts/REMOVE
config.status: creating src/scripts/R.sh
config.status: creating src/scripts/Rdconv
config.status: creating src/scripts/Rprof
config.status: creating src/scripts/SHLIB
config.status: creating src/scripts/Sd2Rd
config.status: creating src/scripts/build
config.status: creating src/scripts/check
config.status: creating src/unix/Makefile
config.status: creating tests/Makefile
config.status: creating tests/Embedding/Makefile
config.status: creating tests/Examples/Makefile
config.status: creating tests/Native/Makefile
config.status: creating tools/Makefile
config.status: creating src/include/config.h
config.status: executing default-1 commands
config.status: creating po/POTFILES
config.status: creating po/Makefile
config.status: executing stamp-h commands

R is now configured for x86_64-unknown-linux-gnu

  Source directory:          ../../src/R-devel
  Installation directory:    /usr/local

  C compiler:                pgcc  -g -O2 -pc 64 -Kieee -fPIC
  Fortran 77 compiler:       pgf77  -g -O2 -pc 64 -Kieee -fPIC

  C++ compiler:              pgCC  -g -O2 -pc 64 -Kieee -fPIC
  Fortran 90/95 compiler:    pgf95 -g -O2 -pc 64 -Kieee -fPIC

  Interfaces supported:     
  External libraries:        readline
  Additional capabilities:   iconv, MBCS, NLS
  Options enabled:           R profiling

  Recommended packages:      yes

configure: WARNING: you cannot build DVI versions of the R manuals
configure: WARNING: you cannot build info or html versions of the R manuals
configure: WARNING: you cannot build PDF versions of the R manuals
~/toolchain/R/clusterPGI/R-devel:make
make[1]: Entering directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/m4'
make[1]: Nothing to be done for `R'.
make[1]: Leaving directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/m4'
make[1]: Entering directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/tools'
make[1]: Nothing to be done for `R'.
make[1]: Leaving directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/tools'make[1]: Entering 
directory `/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/doc'
make[2]: Entering directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/doc/html'
make[3]: Entering directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/doc/html'
make[3]: Leaving directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/doc/html'
make[3]: Entering directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/doc/html/search'
make[4]: Entering directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/doc/html/search'
make[4]: Leaving directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/doc/html/search'
make[3]: Leaving directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/doc/html/search'
make[2]: Leaving directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/doc/html'
make[2]: Entering directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/doc/manual'
make[2]: Nothing to be done for `R'.
make[2]: Leaving directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/doc/manual'
make[2]: Entering directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/doc'
make[2]: Leaving directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/doc'
make[1]: Leaving directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/doc'
make[1]: Entering directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/etc'
make[1]: Leaving directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/etc'
make[1]: Entering directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/share'
make[2]: Entering directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/share'
mkdir -p -- ../share/R
mkdir -p -- ../share/encodings
mkdir -p -- ../share/licenses
mkdir -p -- ../share/make
mkdir -p -- ../share/perl
mkdir -p -- ../share/perl/R
mkdir -p -- ../share/perl/Text
mkdir -p -- ../share/sh
mkdir -p -- ../share/texmf
make[2]: Leaving directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/share'make[1]: Leaving 
directory `/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/share'make[1]: 
Entering directory `/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/src'
make[2]: Entering directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/src/scripts'
creating src/scripts/R.fe
make[3]: Entering directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/src/scripts'
mkdir -p -- ../../bin
make[3]: Leaving directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/src/scripts'
make[2]: Leaving directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/src/scripts'
make[2]: Entering directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/src/include'
mkdir -p -- ../../include
make[3]: Entering directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/src/include/R_ext'
mkdir -p -- ../../../include/R_ext
make[3]: Leaving directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/src/include/R_ext'
make[2]: Leaving directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/src/include'
make[2]: Entering directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/src/extra'
make[3]: Entering directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/src/extra/bzip2'
make[4]: Entering directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/src/extra/bzip2'
making blocksort.d from 
.../../../../../src/R-devel/src/extra/bzip2/blocksort.c
making bzlib.d from ../../../../../src/R-devel/src/extra/bzip2/bzlib.c
making compress.d from ../../../../../src/R-devel/src/extra/bzip2/compress.c
making crctable.d from ../../../../../src/R-devel/src/extra/bzip2/crctable.c
making decompress.d from 
.../../../../../src/R-devel/src/extra/bzip2/decompress.cmaking huffman.d 
from ../../../../../src/R-devel/src/extra/bzip2/huffman.c
making randtable.d from 
.../../../../../src/R-devel/src/extra/bzip2/randtable.c
make[4]: Leaving directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/src/extra/bzip2'
make[4]: Entering directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/src/extra/bzip2'
pgcc -I../../../../../src/R-devel/src/extra/bzip2 -I. 
-I../../../src/include -I../../../../../src/R-devel/src/include 
-I/usr/local/pgi/linux86-64/6.0/include 
-I/usr/local/pgi/linux86-64/6.0/include/CC -DHAVE_CONFIG_H   -g -O2 -pc 
64 -Kieee -fPIC -c 
.../../../../../src/R-devel/src/extra/bzip2/blocksort.c -o blocksort.o
pgcc -I../../../../../src/R-devel/src/extra/bzip2 -I. 
-I../../../src/include -I../../../../../src/R-devel/src/include 
-I/usr/local/pgi/linux86-64/6.0/include 
-I/usr/local/pgi/linux86-64/6.0/include/CC -DHAVE_CONFIG_H   -g -O2 -pc 
64 -Kieee -fPIC -c ../../../../../src/R-devel/src/extra/bzip2/bzlib.c -o 
bzlib.o
pgcc -I../../../../../src/R-devel/src/extra/bzip2 -I. 
-I../../../src/include -I../../../../../src/R-devel/src/include 
-I/usr/local/pgi/linux86-64/6.0/include 
-I/usr/local/pgi/linux86-64/6.0/include/CC -DHAVE_CONFIG_H   -g -O2 -pc 
64 -Kieee -fPIC -c ../../../../../src/R-devel/src/extra/bzip2/compress.c 
-o compress.o
pgcc -I../../../../../src/R-devel/src/extra/bzip2 -I. 
-I../../../src/include -I../../../../../src/R-devel/src/include 
-I/usr/local/pgi/linux86-64/6.0/include 
-I/usr/local/pgi/linux86-64/6.0/include/CC -DHAVE_CONFIG_H   -g -O2 -pc 
64 -Kieee -fPIC -c ../../../../../src/R-devel/src/extra/bzip2/crctable.c 
-o crctable.o
pgcc -I../../../../../src/R-devel/src/extra/bzip2 -I. 
-I../../../src/include -I../../../../../src/R-devel/src/include 
-I/usr/local/pgi/linux86-64/6.0/include 
-I/usr/local/pgi/linux86-64/6.0/include/CC -DHAVE_CONFIG_H   -g -O2 -pc 
64 -Kieee -fPIC -c 
.../../../../../src/R-devel/src/extra/bzip2/decompress.c -o 
decompress.opgcc -I../../../../../src/R-devel/src/extra/bzip2 -I. 
-I../../../src/include -I../../../../../src/R-devel/src/include 
-I/usr/local/pgi/linux86-64/6.0/include 
-I/usr/local/pgi/linux86-64/6.0/include/CC -DHAVE_CONFIG_H   -g -O2 -pc 
64 -Kieee -fPIC -c ../../../../../src/R-devel/src/extra/bzip2/huffman.c 
-o huffman.o
pgcc -I../../../../../src/R-devel/src/extra/bzip2 -I. 
-I../../../src/include -I../../../../../src/R-devel/src/include 
-I/usr/local/pgi/linux86-64/6.0/include 
-I/usr/local/pgi/linux86-64/6.0/include/CC -DHAVE_CONFIG_H   -g -O2 -pc 
64 -Kieee -fPIC -c 
.../../../../../src/R-devel/src/extra/bzip2/randtable.c -o randtable.o
rm -f libbz2.a
ar cr libbz2.a blocksort.o bzlib.o compress.o crctable.o decompress.o 
huffman.o randtable.o
ranlib libbz2.a
make[4]: Leaving directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/src/extra/bzip2'
make[3]: Leaving directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/src/extra/bzip2'
make[3]: Entering directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/src/extra/pcre'
pgcc -I../../../../../src/R-devel/src/extra/pcre -I. 
-I../../../src/include -I../../../../../src/R-devel/src/include 
-I/usr/local/pgi/linux86-64/6.0/include 
-I/usr/local/pgi/linux86-64/6.0/include/CC -DHAVE_CONFIG_H   -g -O2 -pc 
64 -Kieee -fPIC -c ../../../../../src/R-devel/src/extra/pcre/dftables.c 
-o dftables.o
pgcc -L/usr/local/pgi/linux86-64/6.0/libso -L/usr/lib64 -o dftables 
dftables.o
../dftables chartables.h
../dftables: error while loading shared libraries: libpgc.so: cannot open 
shared object file: No such file or directory
make[3]: *** [chartables.h] Error 127
make[3]: Leaving directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/src/extra/pcre'
make[2]: *** [R] Error 1
make[2]: Leaving directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/src/extra'
make[1]: *** [R] Error 1
make[1]: Leaving directory 
`/home/mfa/gilp/toolchain/R/clusterPGI/R-devel/src'
make: *** [R] Error 1
~/toolchain/R/clusterPGI/R-devel:
~/toolchain/R/clusterPGI/R-devel:
~/toolchain/R/clusterPGI/R-devel:
~/toolchain/R/clusterPGI/R-devel:set
BASH=/bin/bash
BASH_VERSINFO=([0]="2" [1]="05b" [2]="0" [3]="1" [4]="release" 
[5]="x86_64-redhat-linux-gnu")
BASH_VERSION='2.05b.0(1)-release'
BSTINPUTS=/home/mfa/gilp/BOCcite:
CC=pgcc
CFLAGS='-g -O2 -pc 64 -Kieee -fPIC'
CMSS_MYSQL_HOST=mfa01518
CMSS_MYSQL_PWD=cmss
COLORS=/etc/DIR_COLORS.xterm
COLUMNS=80
CPPFLAGS='-I/usr/local/pgi/linux86-64/6.0/include 
-I/usr/local/pgi/linux86-64/6.0/include/CC'
CVSDIRS='dse Mybin MyNotes papers cmss toolchain boc systems-config 
HomeOnTheWeb'
CVSEDITOR=vi
CVSROOT=/home/mfa/gilp/cvsroot
CVS_RSH=ssh
CXX=pgCC
CXXFLAGS='-g -O2 -pc 64 -Kieee -fPIC'
DIRSTACK=()
DISPLAY=localhost:11.0
EUID=598
F77=pgf77
F95=pgf95
FCFLAGS='-g -O2 -pc 64 -Kieee -fPIC'
FFLAGS='-g -O2 -pc 64 -Kieee -fPIC'
GROUPS=()
GS_OPTIONS=-dAutoRotatePages=/None
G_BROKEN_FILENAMES=1
HISTFILE=/home/mfa/gilp/.bash_history
HISTFILESIZE=1000
HISTSIZE=1000
HOME=/home/mfa/gilp
HOSTNAME=node01
HOSTTYPE=x86_64
IFS=$' \t\n'
INPUTRC=/etc/inputrc
LANG=en_US.UTF-8
LANGVAR=en_US.UTF-8
LDFLAGS='-L/usr/local/pgi/linux86-64/6.0/libso -L/usr/lib64'
LD_LIBRARY_PATH='-L/usr/local/pgi/linux86-64/6.0/libso -L/usr/lib64'
LESSOPEN='|/usr/bin/lesspipe.sh %s'
LINES=24
LM_LICENSE_FILE=/usr/local/pgi/license.dat
LOGNAME=gilp
LS_COLORS='no=00:fi=00:di=00;34:ln=00;36:pi=40;33:so=00;35:bd=40;33;01:cd=40;33;01:or=01;05;37;41:mi=01;05;37;41:ex=00;32:*.cmd=00;32:*.exe=00;32:*.com=00;32:*.btm=00;32:*.bat=00;32:*.sh=00;32:*.csh=00;32:*.tar=00;31:*.tgz=00;31:*.arj=00;31:*.taz=00;31:*.lzh=00;31:*.zip=00;31:*.z=00;31:*.Z=00;31:*.gz=00;31:*.bz2=00;31:*.bz=00;31:*.tz=00;31:*.rpm=00;31:*.cpio=00;31:*.jpg=00;35:*.gif=00;35:*.bmp=00;35:*.xbm=00;35:*.xpm=00;35:*.png=00;35:*.tif=00;35:'
MACHTYPE=x86_64-redhat-linux-gnu
MAIL=/var/spool/mail/gilp
MAILCHECK=60
MANPATH=/usr/local/pgi/linux86-64/6.0/man:/
MOABHOMEDIR=/usr/local/moab
OLDPWD=/home/mfa/gilp/toolchain/R/clusterPGI
OPTERR=1
OPTIND=1
OSTYPE=linux-gnu
PADI_CLEANUP=cleanup.simple.server
PADI_STARTUP=simple.server
PATH=/usr/local/bin:/home/mfa/gilp/Mybin:/home/mfa/gilp/bin-cluster:/apps/bin:/usr/local/pgi/linux86-64/6.0/bin:/usr/kerberos/bin:/usr/local/bin:/bin:/usr/bin:/usr/X11R6/bin:/usr/local/pbs/x86_64/bin:/usr/local/pbs/x86_64/sbin:/usr/local/moab/x86_64/bin:/opt/xcat/bin:/opt/xcat/sbin:/opt/xcat/x86_64/bin:/opt/xcat/x86_64/sbin
PBS_DEFAULT=cc-mgnt01
PGI=/usr/local/pgi/linux86-64/6.0
PIPESTATUS=([0]="2")
PPID=14266
PS1='\w:'
PS2='> '
PS4='+ '
PWD=/home/mfa/gilp/toolchain/R/clusterPGI/R-devel
SHELL=/bin/bash
SHELLOPTS=braceexpand:emacs:hashall:histexpand:history:interactive-comments:monitor
SHLIB_CXXLDFLAGS=-shared
SHLIB_LDFLAGS=-shared
SHLVL=1
SSH_ASKPASS=/usr/libexec/openssh/gnome-ssh-askpass
SSH_CLIENT='172.20.0.1 56584 22'
SSH_CONNECTION='172.20.0.1 56584 172.20.101.1 22'
SSH_TTY=/dev/pts/1
SUPPORTED=en_US.UTF-8:en_US:en
TERM=xterm
TEXINPUTS=/home/mfa/gilp/BOCcite:
UID=598
USER=gilp
XARCH=x86_64
XCATPREFIX=/opt/xcat
XCATROOT=/opt/xcat
_=make
http_proxy=http://wwwproxy:8080
ssl_proxy=ftp://wwwproxy:8080
x=Linux
~/toolchain/R/clusterPGI/R-devel:
~/toolchain/R/clusterPGI/R-devel:
~/toolchain/R/clusterPGI/R-devel:uname -a
Linux node01 2.4.21-37.ELsmp #1 SMP Wed Sep 7 13:32:18 EDT 2005 x86_64 
x86_64 x86_64 GNU/Linux
~/toolchain/R/clusterPGI/R-devel:
~/toolchain/R/clusterPGI/R-devel:ls -l 
/usr/local/pgi/linux86-64/6.0/libso/*pgc*
-rw-r--r--    1 909      1004         1456 Nov  4  2005 
/usr/local/pgi/linux86-64/6.0/libso/libnspgc.a
-rw-r--r--    1 909      1004       453956 Nov  4  2005 
/usr/local/pgi/linux86-64/6.0/libso/libpgc.a
-rwxr-xr-x    2 909      1004       271084 Nov  4  2005 
/usr/local/pgi/linux86-64/6.0/libso/libpgc.so
~/toolchain/R/clusterPGI/R-devel:


====================================================================================

La version fran?aise suit le texte anglais.

------------------------------------------------------------------------------------

This email may contain privileged and/or confidential inform...{{dropped}}


From pgilbert at bank-banque-canada.ca  Thu May 18 18:28:22 2006
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Thu, 18 May 2006 12:28:22 -0400
Subject: [Rd] helping out
In-Reply-To: <8A036DC9-74BA-4AB2-B6AB-7C20BFC9D5B2@sympatico.ca>
References: <8A036DC9-74BA-4AB2-B6AB-7C20BFC9D5B2@sympatico.ca>
Message-ID: <446CA0A6.1050100@bank-banque-canada.ca>

Kevin

The developers page is available from the  left side menu frame on the 
main R page <http://www.r-project.org/> ,  but not from CRAN.

(BTW, R-devel does not have nearly as much traffic as R-help, so digest 
mode may not be so important.)

Paul Gilbert

Kevin B. Hendricks wrote:

>Hi,
>
>I just joined the list and wanted to introduce myself.  I am a  
>professor of operations management at a Canadian University and an  
>empirical researcher (using mainly archival data from finance and  
>accounting primarily with econometric methods).  I have finally made  
>the leap to remove all of SAS from my machines (damn license code  
>nonsense was killing me) and decided to adopt R.  So I am very new to  
>the R system and still just getting up to speed (reading the fine  
>*long* manuals and etc).
>
>I am also an old programmer (read that late 1970s, early 1980s  
>timeframe) and more recently I have been an open source volunteer for  
>OpenOffice.org (ran their lingucomponent project until last year), a  
>volunteer for the Blackdown Java project (helped do the initial port  
>of Java 1.1.1 to PowerPC Linux) and I have submitted bug fixes and  
>patches to the Linux kernel, glibc, gcc, and the like,  mainly to  
>support PPC Linux.  I now primarily use x86_64 Linux and MacOSX.  I  
>can program in C, C++, Fortran and a number of other languages.
>
>So once I get up to speed, I would love to volunteer to help pay back  
>for the really nice system you have made available.
>
>I found this mailing list by accident looking for something to tell  
>me about the NULL environment issue that hit me when I moved from  
>version 2.2.1 to version 2.3.0.  If there is a developers page that  
>lists cvs checkout info (or do you use subversion or some other  
>system) and the details of who to submit all patches and things to  
>(is this list for diffs?), I would love to be pointed at it.
>
>I am on too many mailing lists right now, so I signed up for digest  
>mode.  So if anyone wants/needs an immediate response please simply  
>cc me.
>
>Thanks,
>
>Kevin Hendricks
>
>
>Professor of Operations Management and Information Technology
>Richard Ivey School of Business
>University of Western Ontario
>London, ON
>kevin.hendricks at sympatico.ca
>
>______________________________________________
>R-devel at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel
>  
>
====================================================================================

La version fran?aise suit le texte anglais.

------------------------------------------------------------------------------------

This email may contain privileged and/or confidential inform...{{dropped}}


From prechelt at inf.fu-berlin.de  Thu May 18 19:33:29 2006
From: prechelt at inf.fu-berlin.de (Lutz Prechelt)
Date: Thu, 18 May 2006 19:33:29 +0200
Subject: [Rd] Trellis equivalent of par(ask=TRUE)?
Message-ID: <793FF35679078340BCDDA196B495E57EC27F@spree.pcpool.mi.fu-berlin.de>

(was:  AW: [Rd] R CMD check: checking examples: how to (not) pause
execution)

Paul, Brian,
 
> > I think the more usual way to solve this is to have the user set 
> > par(ask=TRUE) is they want to be prompted.

thank you.
Looking back, 'par' would have been a likely candidate for looking.
One reason I did NOT look there is that I need the functionality
for print.trellis in fact, not for plot.
par(ask=TRUE) does not influence print.trellis.
trellis.par.get() does not have an equivalent for par(ask=).
Nor does gpar() or any other method in Grid that I could find.

I have tried to help myself (in an admittedly crude way) by putting
  \dontshow{plot(1,type="n")  # make R stop and ask}
before each Lattice plot call in my .Rd file.
But that does not work either. 
It leads to R CMD check output as follows:
  > par(ask=TRUE)
  > ## Don't show:
  > plot(1,type="n")  # make R stop and ask
  Press Return for next plot:## End Don't sh> ow
  Error: object "ow" not found
Rather weird.
Any ideas?
I am using R 2.2.1.

  Lutz Prechelt

Prof. Dr. Lutz Prechelt; prechelt at inf.fu-berlin.de
Institut fuer Informatik; Freie Universitaet Berlin
Takustr. 9; 14195 Berlin; Germany
+49 30 838 75115; http://www.inf.fu-berlin.de/inst/ag-se/


From ross at biostat.ucsf.edu  Thu May 18 19:45:17 2006
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Thu, 18 May 2006 10:45:17 -0700
Subject: [Rd] S4 classes and C
Message-ID: <1147974317.10544.23.camel@iron.psg.net>

Is there any good source of information on how S4 classes (and methods)
work from C?

E.g., for reading
how to read a slot value
how to invoke a method
how to test if you have an s4 object

For writing, how to make a new instance of an S4 object.

I've found scattered hints in the archive, including a link to a talk on
this subject "I am using C code to create an S4 object based on Douglas
Bates's example in his lecture notes on
<http://www.ci.tuwien.ac.at/Conferences/DSC-2003/Tutorials/RExtensions/slide
s.pdf>"
but the link is no longer good (after putting it all on one line).

"Writing R Extensions" (2.3.0 version) makes no reference to this topic
that I can see.
-- 
Ross Boylan                                      wk:  (415) 514-8146
185 Berry St #5700                               ross at biostat.ucsf.edu
Dept of Epidemiology and Biostatistics           fax: (415) 514-8150
University of California, San Francisco
San Francisco, CA 94107-1739                     hm:  (415) 550-1062


From Robert.McGehee at geodecapital.com  Thu May 18 19:53:59 2006
From: Robert.McGehee at geodecapital.com (McGehee, Robert)
Date: Thu, 18 May 2006 13:53:59 -0400
Subject: [Rd] S4 classes and C
Message-ID: <67DCA285A2D7754280D3B8E88EB548020F8EF4BC@MSGBOSCLB2WIN.DMN1.FMR.COM>

I believe the paper on which those lecture notes were based can be found
here:
http://www.ci.tuwien.ac.at/Conferences/DSC-2003/Drafts/BatesDebRoy.pdf 

-----Original Message-----
From: r-devel-bounces at r-project.org
[mailto:r-devel-bounces at r-project.org] On Behalf Of Ross Boylan
Sent: Thursday, May 18, 2006 1:45 PM
To: R Development List
Subject: [Rd] S4 classes and C

Is there any good source of information on how S4 classes (and methods)
work from C?

E.g., for reading
how to read a slot value
how to invoke a method
how to test if you have an s4 object

For writing, how to make a new instance of an S4 object.

I've found scattered hints in the archive, including a link to a talk on
this subject "I am using C code to create an S4 object based on Douglas
Bates's example in his lecture notes on
<http://www.ci.tuwien.ac.at/Conferences/DSC-2003/Tutorials/RExtensions/s
lide
s.pdf>"
but the link is no longer good (after putting it all on one line).

"Writing R Extensions" (2.3.0 version) makes no reference to this topic
that I can see.
-- 
Ross Boylan                                      wk:  (415) 514-8146
185 Berry St #5700                               ross at biostat.ucsf.edu
Dept of Epidemiology and Biostatistics           fax: (415) 514-8150
University of California, San Francisco
San Francisco, CA 94107-1739                     hm:  (415) 550-1062

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From tlumley at u.washington.edu  Thu May 18 19:59:25 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 18 May 2006 10:59:25 -0700 (PDT)
Subject: [Rd] helping out
In-Reply-To: <8A036DC9-74BA-4AB2-B6AB-7C20BFC9D5B2@sympatico.ca>
References: <8A036DC9-74BA-4AB2-B6AB-7C20BFC9D5B2@sympatico.ca>
Message-ID: <Pine.LNX.4.64.0605181051590.21587@homer24.u.washington.edu>

On Thu, 18 May 2006, Kevin B. Hendricks wrote:
>
> I found this mailing list by accident looking for something to tell
> me about the NULL environment issue that hit me when I moved from
> version 2.2.1 to version 2.3.0.  If there is a developers page that
> lists cvs checkout info (or do you use subversion or some other
> system) and the details of who to submit all patches and things to
> (is this list for diffs?), I would love to be pointed at it.

We use subversion.  The developer page is http://developer.r-project.org 
and it has subversion logs. The subversion server is svn.r-project.org if 
you want to check out current code, or there are daily snapshots at
   ftp://ftp.stat.math.ethz.ch/Software/R 
r-devel is the right place for patches, or r-bugs if it really is a bug fix.

 	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From ross at biostat.ucsf.edu  Thu May 18 20:05:45 2006
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Thu, 18 May 2006 11:05:45 -0700
Subject: [Rd] S4 classes and C
In-Reply-To: <67DCA285A2D7754280D3B8E88EB548020F8EF4BC@MSGBOSCLB2WIN.DMN1.FMR.COM>
References: <67DCA285A2D7754280D3B8E88EB548020F8EF4BC@MSGBOSCLB2WIN.DMN1.FMR.COM>
Message-ID: <1147975545.10544.25.camel@iron.psg.net>

On Thu, 2006-05-18 at 13:53 -0400, McGehee, Robert wrote:
> I believe the paper on which those lecture notes were based can be found
> here:
> http://www.ci.tuwien.ac.at/Conferences/DSC-2003/Drafts/BatesDebRoy.pdf 
> 
Thank you.  It looks as if it has some useful stuff in it.
Ross


From deepayan.sarkar at gmail.com  Thu May 18 20:13:23 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Thu, 18 May 2006 13:13:23 -0500
Subject: [Rd] Trellis equivalent of par(ask=TRUE)?
In-Reply-To: <793FF35679078340BCDDA196B495E57EC27F@spree.pcpool.mi.fu-berlin.de>
References: <793FF35679078340BCDDA196B495E57EC27F@spree.pcpool.mi.fu-berlin.de>
Message-ID: <eb555e660605181113t18d28697vb6f712522351c548@mail.gmail.com>

On 5/18/06, Lutz Prechelt <prechelt at inf.fu-berlin.de> wrote:
> (was:  AW: [Rd] R CMD check: checking examples: how to (not) pause
> execution)
>
> Paul, Brian,
>
> > > I think the more usual way to solve this is to have the user set
> > > par(ask=TRUE) is they want to be prompted.
>
> thank you.
> Looking back, 'par' would have been a likely candidate for looking.
> One reason I did NOT look there is that I need the functionality
> for print.trellis in fact, not for plot.
> par(ask=TRUE) does not influence print.trellis.
> trellis.par.get() does not have an equivalent for par(ask=).
> Nor does gpar() or any other method in Grid that I could find.

?grid.prompt

Deepayan


From ross at biostat.ucsf.edu  Thu May 18 20:23:40 2006
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Thu, 18 May 2006 11:23:40 -0700
Subject: [Rd] Recommended style with calculator and persistent data
Message-ID: <1147976620.10544.43.camel@iron.psg.net>

I have some calculations that require persistent state.  For example,
they retain most of the data across calls with different parameters.
They retain parameters across calls with different subsets of the cases
(this is for distributed computation).  They retain early analysis of
the problem to speed later computations.

I've created an S4 object, and the stylized code looks like this
calc <- makeCalculator(a, b, c)
calc <- setParams(calc, d, e)
calc <- compute(calc)
results <- results(calc)
The client code (such as that above) must remember to do the
assignments, not just invoke the functions.

I notice this does not seem to be the usual style, which is more like
results <- compute(calc)

and possibly using assignment operators like
params(calc) <- x
(actually, I have a call like that, but some of the updates take
multiple arguments).

Another route would be to use lexical scoping to bundle all the
functions together (umm, I'm not sure how that would work with S4
methods) to ensure persistence without requiring assignment by the
client code.  Obviously this would decrease portability to S, but I'm
already using lexical scope a bit.

Is there a recommended R'ish way to approach the problem?  My current
approach works, but I'm concerned it is non-standard, and so would be
unnatural for users.
-- 
Ross Boylan                                      wk:  (415) 514-8146
185 Berry St #5700                               ross at biostat.ucsf.edu
Dept of Epidemiology and Biostatistics           fax: (415) 514-8150
University of California, San Francisco
San Francisco, CA 94107-1739                     hm:  (415) 550-1062


From forms at boonstra.org  Thu May 18 20:54:02 2006
From: forms at boonstra.org (B. Boonstra)
Date: Thu, 18 May 2006 13:54:02 -0500
Subject: [Rd] Convention difference in tseries.maxdrawdown (PR#8872)
In-Reply-To: <446C7E15.9080205@swissonline.ch>
References: <446C7E15.9080205@swissonline.ch>
Message-ID: <446CC2CA.7020101@boonstra.org>

Gunther is quite correct.  I should have said I had written something 
API-compatible.

Adrian's worakround suggestion of using log() with the current version 
of maxdrawdown() works nicely, of course.   I would suggest, however, 
that working in proportional [rather than absolute] terms be the default 
behavior of the maxdrawdown() function, as that is industry convention.

If changing the behavior is unacceptable, the absolute-drawdown gotcha 
should at the least be extremely clearly documented.   It already caused 
me to misquote drawdowns in a backtest to my boss!!


  -- Brian K. Boonstra




Adrian Trapletti wrote:
>>
>> Regarding the upwardly compatible comment, the dollar drawdown that
>> corresponds to the maximum fractional drawdown is not necessarily the
>> maximum dollar drawdown.
>>
>> For example, in this situation the maximum fractional drawdown
>> is from 100 to 75 but the maximum dollar drawdown is from 200
>> to 160.
>>
>>> x <- c(1, 100, 75, 200, 160)
>>
>>
>
> What type of drawdown to work with depends on the context. If working 
> in percent is more appropriate, then you might use
>
> maxdrawdown(log(x))$maxdrawdown
>
> or if log returns are not appropriate then the following 
> transformation provides the equivalent what was suggested
>
> -(exp(-maxdrawdown(log(x))$maxdrawdown)-1)
>
>
> Best regards
> Adrian
>
>>> maximumdrawdown(x) # function defined in post
>>
>> $maximumdrawdown
>> [1] 0.25
>>
>> $maxdrawdown
>> [1] 25
>>
>> $from
>> [1] 2
>>
>> $to
>> [1] 3
>>
>>> maxdrawdown(x) # function from tseries
>>
>> $maxdrawdown
>> [1] 40
>>
>> $from
>> [1] 4
>>
>> $to
>> [1] 5
>>
>> On 5/17/06, rproject at boonstra.org <rproject at boonstra.org> wrote:
>>
>>> Full_Name: Brian K. Boonstra
>>> Version: 2.2.1
>>> OS: WinXP, OSX
>>> Submission from: (NULL) (63.172.178.137)
>>>
>>>
>>> The maxdrawdown function in tseries defines the maximum drawdown in 
>>> terms of
>>> absolute dollars (or whatever units the input is in).  Industry 
>>> convention is to
>>> do this in percentage terms.  I have written the code below as
>>> maximumdrawdown(), which retains backward compatibility with the 
>>> current
>>> version.  It has the flaw that it does not check for zero or 
>>> negative values.
>>>
>>> maximumdrawdown <- function (x)
>>> {
>>>    if (NCOL(x) > 1)
>>>        stop("x is not a vector or univariate time series")
>>>    if (any(is.na(x)))
>>>        stop("NAs in x")
>>>    cminx <- x/cummax(x)
>>>    mdd <- min(cminx)
>>>    to <- which(mdd == cminx)
>>>    from <- double(NROW(to))
>>>    for (i in 1:NROW(to)) {
>>>      from[i] <- max( which(cminx[1:to[i]] == 1) )
>>>      }
>>>    return(list(maximumdrawdown = 1-mdd, maxdrawdown = 
>>> (1-mdd)*x[from], from =
>>> from, to = to))
>>> }
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>
>


From sfalcon at fhcrc.org  Thu May 18 21:22:36 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Thu, 18 May 2006 12:22:36 -0700
Subject: [Rd] S4 classes and C
In-Reply-To: <1147974317.10544.23.camel@iron.psg.net> (Ross Boylan's message
	of "Thu, 18 May 2006 10:45:17 -0700")
References: <1147974317.10544.23.camel@iron.psg.net>
Message-ID: <m23bf79lz7.fsf@ziti.fhcrc.org>

Ross Boylan <ross at biostat.ucsf.edu> writes:

> Is there any good source of information on how S4 classes (and methods)
> work from C?
>
> E.g., for reading
> how to read a slot value
> how to invoke a method
> how to test if you have an s4 object

You might look at Bioconductor's Ruuid package.  It does some of this
and is fairly small, so it is easy to see what is going on.

http://bioconductor.org/packages/1.8/bioc/html/Ruuid.html

+ seth


From sfalcon at fhcrc.org  Thu May 18 21:40:20 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Thu, 18 May 2006 12:40:20 -0700
Subject: [Rd] Recommended style with calculator and persistent data
In-Reply-To: <1147976620.10544.43.camel@iron.psg.net> (Ross Boylan's message
	of "Thu, 18 May 2006 11:23:40 -0700")
References: <1147976620.10544.43.camel@iron.psg.net>
Message-ID: <m2r72r86l7.fsf@ziti.fhcrc.org>

Ross Boylan <ross at biostat.ucsf.edu> writes:

> I have some calculations that require persistent state.  For example,
> they retain most of the data across calls with different parameters.
> They retain parameters across calls with different subsets of the cases
> (this is for distributed computation).  They retain early analysis of
> the problem to speed later computations.
>
> I've created an S4 object, and the stylized code looks like this
> calc <- makeCalculator(a, b, c)
> calc <- setParams(calc, d, e)
> calc <- compute(calc)
> results <- results(calc)
> The client code (such as that above) must remember to do the
> assignments, not just invoke the functions.
>
> I notice this does not seem to be the usual style, which is more like
> results <- compute(calc)
>
> and possibly using assignment operators like
> params(calc) <- x
> (actually, I have a call like that, but some of the updates take
> multiple arguments).

I think the setReplaceMethod approach has some advantages in the sense
that you don't have to remember to capture the return.  You can handle
multiple parameters in a couple of ways:

params(calc, p="num_iter") <- 1000
params(calc, p="verbose") <- FALSE

params(calc) <- list(num_iter=100, verbose=FALSE)



  + seth


From maechler at stat.math.ethz.ch  Fri May 19 11:46:02 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 19 May 2006 11:46:02 +0200
Subject: [Rd] S4 classes and C
In-Reply-To: <m23bf79lz7.fsf@ziti.fhcrc.org>
References: <1147974317.10544.23.camel@iron.psg.net>
	<m23bf79lz7.fsf@ziti.fhcrc.org>
Message-ID: <17517.37850.60690.443326@stat.math.ethz.ch>

>>>>> "Seth" == Seth Falcon <sfalcon at fhcrc.org>
>>>>>     on Thu, 18 May 2006 12:22:36 -0700 writes:

    Seth> Ross Boylan <ross at biostat.ucsf.edu> writes:
    >> Is there any good source of information on how S4 classes (and methods)
    >> work from C?

Hmm, yes; there's nothing in the "Writing R Extensions" manual,
and there's not so much in the ``The Green Book''
(Chambers 1998), which is prominently cited by Doug Bates (and Saikat Debroy)
in the paper given at DSC 2003 (mentioned earlier in this
thread, http://www.ci.tuwien.ac.at/Conferences/DSC-2003/Drafts/BatesDebRoy.pdf )


    >> E.g., for reading
    >> how to read a slot value

GET_SLOT(); also  SET_SLOT(), NEW_OBJECT(), MAKE_CLASS(), ...

    >> how to invoke a method

Well, an S4 method is still an R function so that's partly
covered by "R-exts" -- something I may want to avoid, rather
call the C function that *underlies* the (R) S4 method...

    >> how to test if you have an s4 object

{I'd usually do those tests in R code}

    Seth> You might look at Bioconductor's Ruuid package.  It does some of this
    Seth> and is fairly small, so it is easy to see what is going on.

    Seth> http://bioconductor.org/packages/1.8/bioc/html/Ruuid.html

Indeed,.  And the package which lead to the paper has later
become 'lme4' the C code of which *currently* is in the 'Matrix'
package  -- which is much larger than Ruuid, but I think still
contains a many interesting examples of  using S4 classes from C.
Since Matrix development uses a publicly-readable subversion
archive, you can directly browse the code at
https://svn.R-project.org/R-packages/trunk/Matrix/ (but for
extensive browsing do download and unpack the released version
of from CRAN, e.g., the US mirror,
http://cran.us.r-project.org/src/contrib/Descriptions/Matrix.html )
Particularly look at the src/...Matrix.c files and their
R/...Matrix.R counterparts.

Martin

    Seth> + seth


From ripley at stats.ox.ac.uk  Fri May 19 12:04:15 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 19 May 2006 11:04:15 +0100 (BST)
Subject: [Rd] Non-ASCII chars in R code
In-Reply-To: <Pine.LNX.4.64.0605171855440.26452@gannet.stats.ox.ac.uk>
References: <Pine.LNX.4.64.0605171855440.26452@gannet.stats.ox.ac.uk>
Message-ID: <Pine.LNX.4.64.0605191014180.8872@gannet.stats.ox.ac.uk>

A little more digging revealed a Unix/Windows discrepancy here.

On Unix, saving images and preparing for lazyloading/lazydata is done with 
LC_ALL=C: on Windows with LC_COLLATE=C.  I will change Windows to match.

Unfortunately how the C locale is implemented is OS-dependent.  Strictly 
it should not allow bytes 0x80 to 0xff but it does on some OSes (including 
Windows).  So the strict consequences of this should be that when using
lazy-loading or a saved image

- all names have to be ASCII alphanumeric
- \uxxxx sequences are not allowed except \u007f and lower (they are not
   valid at all in a C locale prior to 2.3.1 so I would not expect to see
   them in a package).
- bytes in character strings are copied byte for byte.

This leaves an inconsistency between packages which use lazy-loading / 
save image and those which do not.  We could resolve that by switching to 
the C locale when loading R code in packages (or, better, R code that was 
not a loader stub): I didn't think that would be worthwhile but in fact 5 
of the packages listed are small enough not to be lazy-loaded.

The other consequence is that the only way we allow packages to have 
object names which are not ASCII alphanumeric is to disable lazy loading.
One possibility is to allow a package to specify its required locale for 
loading in the DESCRIPTION file, and make use of that.

I am inclined to do nothing about these issues unless people have an 
actual need to have packages tailored on a non-English locale.


On Wed, 17 May 2006, Prof Brian Ripley wrote:

> The report on R_help about problems loading package irr (in a UTF-8 locale, 
> it seemed) prompted me to look a little deeper.  There are quite a few 
> packages with Latin-1 chars in their .R files, and a couple in UTF-8.
>
> Apart from non-ASCII chars in comments, this is a problem as the code 
> concerned cannot be represented in some locales R runs in (for example 
> Japanese on Windows).  It happens that irr is so small that lazy-loading is 
> not used, but when lazy-loading or a saved image is used, the locale in use 
> when the package is installed determines how the code is parsed (and may not 
> be the same as when the package is used, and indeed it is not uncommon on 
> Linux/Unix systems for different users to use different locales).
>
> This means that using non-ASCII chars is not portable, and I've added code to 
> R CMD check in R-devel to warn about such usage.  In the examples I have 
> investigated the usages have been
>
> - messages in a non-English language, typically French.
> - startup messages with people's names.
> - use of characters that I can only guess are intended to be in the
>  WinAnsi encoding, e.g. a copyright symbol.
>
> The only reason I have not made this an error is that people might want to 
> produce packages for a known locale, e.g. a student class, but perhaps it 
> should be an error for packages submitted to CRAN.
>
> I do not believe there is much we can do about this: messages which are not 
> entirely in ASCII cannot be displayed on many R platforms and it seems 
> incorrect to allow French messages and not Japanese ones.
>
> The packages currently throwing warnings are
>
> FactoMineR FunCluster JointGLM LoopAnalyst Sciviews ade4 adehabitat ape 
> climatol crossdes deal grasper irr lsa mvrpart pastecs sn surveillance 
> truncgof
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From prechelt at inf.fu-berlin.de  Fri May 19 12:44:30 2006
From: prechelt at inf.fu-berlin.de (prechelt at inf.fu-berlin.de)
Date: Fri, 19 May 2006 12:44:30 +0200 (CEST)
Subject: [Rd] ?attr: wrong parameter name (PR#8880)
Message-ID: <20060519104430.4EE4B494DC@slim.kubism.ku.dk>

Full_Name: Lutz Prechelt
Version: 2.2.1
OS: WinXP
Submission from: (NULL) (130.133.8.114)


?attr declares base:attr as
     attr(x, which)
     attr(x, which) <- value
The following text under "Value", however, says:
     The first form first looks for an exact match 
     to 'code' amongst the attributed of 'x'
This has two errors:
- 'code' should be 'which'
- 'attributed' should be 'attributes'

  Lutz


From rdpeng at gmail.com  Fri May 19 15:54:15 2006
From: rdpeng at gmail.com (Roger D. Peng)
Date: Fri, 19 May 2006 09:54:15 -0400
Subject: [Rd] delayedAssign and interrupts
Message-ID: <446DCE07.2080504@gmail.com>

I noticed something recently that I thought was odd:

delayedAssign("x", { Sys.sleep(5); 1 })
x  ## Hit Ctrl-C within the first second or 2

gives me:

 > delayedAssign("x", { Sys.sleep(5); 1 })
 > x  ## Hit Ctrl-C within the first second or two

 > x
Error: recursive default argument reference
 >

My only problem here is that now I'm stuck---there's no way to recover whatever 
'x' was supposed to be (i.e. 1).

In reality, I want 'x' to be a promise to load a moderately large data object. 
But if I (or a user) Ctrl-C's during the load I'll have to start from scratch. 
Is there anyway to recover the promise (or the value of the expression) in case 
of an interrupt?

-roger
-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/


From ripley at stats.ox.ac.uk  Fri May 19 16:09:33 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 19 May 2006 15:09:33 +0100 (BST)
Subject: [Rd] helping out
In-Reply-To: <Pine.LNX.4.64.0605181051590.21587@homer24.u.washington.edu>
References: <8A036DC9-74BA-4AB2-B6AB-7C20BFC9D5B2@sympatico.ca>
	<Pine.LNX.4.64.0605181051590.21587@homer24.u.washington.edu>
Message-ID: <Pine.LNX.4.64.0605181908170.8076@gannet.stats.ox.ac.uk>

On Thu, 18 May 2006, Thomas Lumley wrote:

> On Thu, 18 May 2006, Kevin B. Hendricks wrote:
>>
>> I found this mailing list by accident looking for something to tell
>> me about the NULL environment issue that hit me when I moved from
>> version 2.2.1 to version 2.3.0.  If there is a developers page that
>> lists cvs checkout info (or do you use subversion or some other
>> system) and the details of who to submit all patches and things to
>> (is this list for diffs?), I would love to be pointed at it.
>
> We use subversion.  The developer page is http://developer.r-project.org
> and it has subversion logs. The subversion server is svn.r-project.org if
> you want to check out current code, or there are daily snapshots at
>   ftp://ftp.stat.math.ethz.ch/Software/R

> r-devel is the right place for patches, or r-bugs if it really is a bug fix.

Experience shows however that using either for patches is error-prone.
R-bugs tends to mangle attachments (or perhaps not unmangle what a mailer 
has done to them), inline patches get mangled (wrapped, tabs expanded) and
attachments get stripped (even though some are allowed).

I think if you want to offer a patch, the best way to do it is to put it 
on a website and include a URL, or offer to email it to interested people.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch at stats.uwo.ca  Fri May 19 16:15:20 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 19 May 2006 10:15:20 -0400
Subject: [Rd] delayedAssign and interrupts
In-Reply-To: <446DCE07.2080504@gmail.com>
References: <446DCE07.2080504@gmail.com>
Message-ID: <446DD2F8.5060900@stats.uwo.ca>

On 5/19/2006 9:54 AM, Roger D. Peng wrote:
> I noticed something recently that I thought was odd:
> 
> delayedAssign("x", { Sys.sleep(5); 1 })
> x  ## Hit Ctrl-C within the first second or 2
> 
> gives me:
> 
>  > delayedAssign("x", { Sys.sleep(5); 1 })
>  > x  ## Hit Ctrl-C within the first second or two
> 
>  > x
> Error: recursive default argument reference
>  >
> 
> My only problem here is that now I'm stuck---there's no way to recover whatever 
> 'x' was supposed to be (i.e. 1).
> 
> In reality, I want 'x' to be a promise to load a moderately large data object. 
> But if I (or a user) Ctrl-C's during the load I'll have to start from scratch. 
> Is there anyway to recover the promise (or the value of the expression) in case 
> of an interrupt?

I don't know of one.  Normally substitute(x) is supposed to retrieve the 
  promise expression, but by a strange quirk of history, it does not 
work when x is in .GlobalEnv.

I'd say the behaviour you're seeing is a bug.  If I do

 > x <- 2
 > x <- {Sys.sleep(1); 1}  # Break before complete

 > x
[1] 2

nothing is changed about x.  I would think the same thing should happen 
when x is a promise:  if the evaluation of the promised expression 
fails, the promise should not be changed.

Duncan Murdoch


From luke at stat.uiowa.edu  Fri May 19 16:37:22 2006
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Fri, 19 May 2006 09:37:22 -0500 (CDT)
Subject: [Rd] delayedAssign and interrupts
In-Reply-To: <446DD2F8.5060900@stats.uwo.ca>
References: <446DCE07.2080504@gmail.com> <446DD2F8.5060900@stats.uwo.ca>
Message-ID: <Pine.LNX.4.64.0605190920520.9980@nokomis.stat.uiowa.edu>

On Fri, 19 May 2006, Duncan Murdoch wrote:

> On 5/19/2006 9:54 AM, Roger D. Peng wrote:
>> I noticed something recently that I thought was odd:
>>
>> delayedAssign("x", { Sys.sleep(5); 1 })
>> x  ## Hit Ctrl-C within the first second or 2
>>
>> gives me:
>>
>> > delayedAssign("x", { Sys.sleep(5); 1 })
>> > x  ## Hit Ctrl-C within the first second or two
>>
>> > x
>> Error: recursive default argument reference
>> >
>>
>> My only problem here is that now I'm stuck---there's no way to recover whatever
>> 'x' was supposed to be (i.e. 1).
>>
>> In reality, I want 'x' to be a promise to load a moderately large data object.
>> But if I (or a user) Ctrl-C's during the load I'll have to start from scratch.
>> Is there anyway to recover the promise (or the value of the expression) in case
>> of an interrupt?
>
> I don't know of one.  Normally substitute(x) is supposed to retrieve the
>  promise expression, but by a strange quirk of history, it does not
> work when x is in .GlobalEnv.
>
> I'd say the behaviour you're seeing is a bug.  If I do
>
> > x <- 2
> > x <- {Sys.sleep(1); 1}  # Break before complete
>
> > x
> [1] 2
>
> nothing is changed about x.  I would think the same thing should happen
> when x is a promise:  if the evaluation of the promised expression
> fails, the promise should not be changed.

I don't think this is a clear as you make it out--given that these
uses of promises often have side effects, and some of those side
effects may have occurred prior to an error, it isn't clear that
pretending like no evaluation had happened is the right way to go.

It should not be too hard to write a delayedAssignmentReset function
if that is really useful; alternatively a user of delayedAssign should
be able to arrange via tryCatch to chatch interrupts and re-install
the delayed assignment if one occurs.

It might not be a bad idea for us to look into the promise evaluation
internals and see if we should/can separate the promise black-holing
from detection of recursive default argument references to get more
reasonable error messages in these situations and maybe allow
resetting more gnerally.  But anything done here had better keep
efficiency in mind since this is prety core to R function call
evaluation.  I may try to look into this when I get back to workign on
R internals.

luke



-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From murdoch at stats.uwo.ca  Fri May 19 16:39:55 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 19 May 2006 10:39:55 -0400
Subject: [Rd] delayedAssign and interrupts
In-Reply-To: <446DCE07.2080504@gmail.com>
References: <446DCE07.2080504@gmail.com>
Message-ID: <446DD8BB.5030606@stats.uwo.ca>

On 5/19/2006 9:54 AM, Roger D. Peng wrote:
> I noticed something recently that I thought was odd:
> 
> delayedAssign("x", { Sys.sleep(5); 1 })
> x  ## Hit Ctrl-C within the first second or 2
> 
> gives me:
> 
>  > delayedAssign("x", { Sys.sleep(5); 1 })
>  > x  ## Hit Ctrl-C within the first second or two
> 
>  > x
> Error: recursive default argument reference
>  >
> 
> My only problem here is that now I'm stuck---there's no way to recover whatever 
> 'x' was supposed to be (i.e. 1).
> 
> In reality, I want 'x' to be a promise to load a moderately large data object. 
> But if I (or a user) Ctrl-C's during the load I'll have to start from scratch. 
> Is there anyway to recover the promise (or the value of the expression) in case 
> of an interrupt?

Here's the code that causes this:

static SEXP forcePromise(SEXP e)
{
   if (PRVALUE(e) == R_UnboundValue) {
     SEXP val;
     if(PRSEEN(e))
       errorcall(R_GlobalContext->call,
		_("recursive default argument reference"));
     SET_PRSEEN(e, 1);
     val = eval(PRCODE(e), PRENV(e));
     SET_PRSEEN(e, 0);
     SET_PRVALUE(e, val);
   }
   return PRVALUE(e);
}

The idea is that you don't want to get into an infinite loop by having 
something like

f <- function(x = x)

or

delayedAssign(x, x)

so the PRSEEN bit is set before trying to evaluate the promise. 
However, if the eval() aborts it jumps right back up to the top level, 
the bit never gets reset to 0, and you get the spurious error message 
you saw.

I'll look into fixing this for 2.3.1.

Duncan Murdoch


From murdoch at stats.uwo.ca  Fri May 19 16:55:08 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 19 May 2006 10:55:08 -0400
Subject: [Rd] delayedAssign and interrupts
In-Reply-To: <Pine.LNX.4.64.0605190920520.9980@nokomis.stat.uiowa.edu>
References: <446DCE07.2080504@gmail.com> <446DD2F8.5060900@stats.uwo.ca>
	<Pine.LNX.4.64.0605190920520.9980@nokomis.stat.uiowa.edu>
Message-ID: <446DDC4C.7040209@stats.uwo.ca>

On 5/19/2006 10:37 AM, Luke Tierney wrote:
> On Fri, 19 May 2006, Duncan Murdoch wrote:
> 
>> On 5/19/2006 9:54 AM, Roger D. Peng wrote:
>>> I noticed something recently that I thought was odd:
>>>
>>> delayedAssign("x", { Sys.sleep(5); 1 })
>>> x  ## Hit Ctrl-C within the first second or 2
>>>
>>> gives me:
>>>
>>> > delayedAssign("x", { Sys.sleep(5); 1 })
>>> > x  ## Hit Ctrl-C within the first second or two
>>>
>>> > x
>>> Error: recursive default argument reference
>>> >
>>>
>>> My only problem here is that now I'm stuck---there's no way to recover whatever
>>> 'x' was supposed to be (i.e. 1).
>>>
>>> In reality, I want 'x' to be a promise to load a moderately large data object.
>>> But if I (or a user) Ctrl-C's during the load I'll have to start from scratch.
>>> Is there anyway to recover the promise (or the value of the expression) in case
>>> of an interrupt?
>>
>> I don't know of one.  Normally substitute(x) is supposed to retrieve the
>>  promise expression, but by a strange quirk of history, it does not
>> work when x is in .GlobalEnv.
>>
>> I'd say the behaviour you're seeing is a bug.  If I do
>>
>> > x <- 2
>> > x <- {Sys.sleep(1); 1}  # Break before complete
>>
>> > x
>> [1] 2
>>
>> nothing is changed about x.  I would think the same thing should happen
>> when x is a promise:  if the evaluation of the promised expression
>> fails, the promise should not be changed.
> 
> I don't think this is a clear as you make it out--given that these
> uses of promises often have side effects, and some of those side
> effects may have occurred prior to an error, it isn't clear that
> pretending like no evaluation had happened is the right way to go.

Right, but the user would have seen the error, and can decide how to 
recover from it.  If trying to evaluate x again is the wrong thing to 
do, the user is the one who would know that.

> It should not be too hard to write a delayedAssignmentReset function
> if that is really useful; alternatively a user of delayedAssign should
> be able to arrange via tryCatch to chatch interrupts and re-install
> the delayed assignment if one occurs.
> 
> It might not be a bad idea for us to look into the promise evaluation
> internals and see if we should/can separate the promise black-holing
> from detection of recursive default argument references to get more
> reasonable error messages in these situations and maybe allow
> resetting more gnerally.  But anything done here had better keep
> efficiency in mind since this is prety core to R function call
> evaluation.  I may try to look into this when I get back to workign on
> R internals.

This is a very rare situation, so I agree putting in some slow way to 
recover from an error is a bad idea.  I think we should do the following:

  - fix substitute so it could be used to extract the promise expression 
even if x lives in .GlobalEnv.  (This can't happen for 2.3.1.)

  - add delayedAssignmentReset to repair x if that's preferred.  (Is 
this a reasonable addition to a patch release?)

This won't leave promises alone in case of an error, but will make it 
fairly easy for a user to recover using tryCatch.

Duncan


From rdpeng at gmail.com  Fri May 19 16:56:44 2006
From: rdpeng at gmail.com (Roger D. Peng)
Date: Fri, 19 May 2006 10:56:44 -0400
Subject: [Rd] delayedAssign and interrupts
In-Reply-To: <Pine.LNX.4.64.0605190920520.9980@nokomis.stat.uiowa.edu>
References: <446DCE07.2080504@gmail.com> <446DD2F8.5060900@stats.uwo.ca>
	<Pine.LNX.4.64.0605190920520.9980@nokomis.stat.uiowa.edu>
Message-ID: <446DDCAC.5040108@gmail.com>



Luke Tierney wrote:
> On Fri, 19 May 2006, Duncan Murdoch wrote:
> 
>> On 5/19/2006 9:54 AM, Roger D. Peng wrote:
>>> I noticed something recently that I thought was odd:
>>>
>>> delayedAssign("x", { Sys.sleep(5); 1 })
>>> x  ## Hit Ctrl-C within the first second or 2
>>>
>>> gives me:
>>>
>>> > delayedAssign("x", { Sys.sleep(5); 1 })
>>> > x  ## Hit Ctrl-C within the first second or two
>>>
>>> > x
>>> Error: recursive default argument reference
>>> >
>>>
>>> My only problem here is that now I'm stuck---there's no way to 
>>> recover whatever
>>> 'x' was supposed to be (i.e. 1).
>>>
>>> In reality, I want 'x' to be a promise to load a moderately large 
>>> data object.
>>> But if I (or a user) Ctrl-C's during the load I'll have to start from 
>>> scratch.
>>> Is there anyway to recover the promise (or the value of the 
>>> expression) in case
>>> of an interrupt?
>>
>> I don't know of one.  Normally substitute(x) is supposed to retrieve the
>>  promise expression, but by a strange quirk of history, it does not
>> work when x is in .GlobalEnv.
>>
>> I'd say the behaviour you're seeing is a bug.  If I do
>>
>> > x <- 2
>> > x <- {Sys.sleep(1); 1}  # Break before complete
>>
>> > x
>> [1] 2
>>
>> nothing is changed about x.  I would think the same thing should happen
>> when x is a promise:  if the evaluation of the promised expression
>> fails, the promise should not be changed.
> 
> I don't think this is a clear as you make it out--given that these
> uses of promises often have side effects, and some of those side
> effects may have occurred prior to an error, it isn't clear that
> pretending like no evaluation had happened is the right way to go.
> 
> It should not be too hard to write a delayedAssignmentReset function
> if that is really useful; alternatively a user of delayedAssign should
> be able to arrange via tryCatch to chatch interrupts and re-install
> the delayed assignment if one occurs.

This was my original thought, and I think it would be possible to use tryCatch 
to reinstall the delayed assignment.  However, I couldn't figure out how to have 
the reinstalled expression to be able to catch interrupts without getting into 
some infinite expression....  Perhaps I need to investigate it further.

> 
> It might not be a bad idea for us to look into the promise evaluation
> internals and see if we should/can separate the promise black-holing
> from detection of recursive default argument references to get more
> reasonable error messages in these situations and maybe allow
> resetting more gnerally.  But anything done here had better keep
> efficiency in mind since this is prety core to R function call
> evaluation.  I may try to look into this when I get back to workign on
> R internals.
> 
> luke
> 
> 
> 

-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/


From ripley at stats.ox.ac.uk  Fri May 19 17:01:21 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 19 May 2006 16:01:21 +0100 (BST)
Subject: [Rd] UseMethod infelicity
Message-ID: <Pine.LNX.4.64.0605191348300.6158@gannet.stats.ox.ac.uk>

If I do

> example(lm)
...
> mycoef <- function(object, ...) UseMethod("coef", object)
> mycoef(lm.D9)
Error in mycoef(lm.D9) : no applicable method for "coef"

which is pretty surprising, as coef has a default method.

After a bit of digging, this comes from do_usemethod having

        defenv = environment where the generic was defined */
     defenv = ENCLOS(env);

so it is assuming that UseMethod() is called within the defining generic 
for its first argument.  That plainly does not need to be true, e.g.

> coefficients
function (object, ...)
UseMethod("coef")
<environment: namespace:stats>

It is clear to me that we need to search for 'generic' and find its 
defining environment rather than that of the current caller.  It is not 
entirely clear where to search from as I think we need to avoid

mycoef <- function(x)
{
    mycoef <- function(x) stop("not this one")
    UseMethod("mycoef")
}

so I used ENCLOS(env).

This adds some overhead, hopefully no more than searching for methods.

BTW, I noticed that R_LookupMethod uses findVar, that is looks for any 
object not for functions: that must be another infelicity.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.dalgaard at biostat.ku.dk  Fri May 19 17:16:13 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 19 May 2006 17:16:13 +0200
Subject: [Rd] helping out
In-Reply-To: <Pine.LNX.4.64.0605181908170.8076@gannet.stats.ox.ac.uk>
References: <8A036DC9-74BA-4AB2-B6AB-7C20BFC9D5B2@sympatico.ca>
	<Pine.LNX.4.64.0605181051590.21587@homer24.u.washington.edu>
	<Pine.LNX.4.64.0605181908170.8076@gannet.stats.ox.ac.uk>
Message-ID: <x2mzde11vm.fsf@turmalin.kubism.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:


> R-bugs tends to mangle attachments (or perhaps not unmangle what a mailer 
> has done to them), inline patches get mangled (wrapped, tabs expanded) and
> attachments get stripped (even though some are allowed).

This happens in the remailing step. It should still be possible (for
maintainers, at least) to download raw messages and sort out the
attachments. It's a bit of a pain to rmember how, though: I tried it
out with mutt just now: "mutt -f Desktop/wishlist", show message, then
"v", then "s" to save the relevant part.
 
> I think if you want to offer a patch, the best way to do it is to put it 
> on a website and include a URL, or offer to email it to interested people.



-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From kevin.hendricks at sympatico.ca  Fri May 19 17:37:49 2006
From: kevin.hendricks at sympatico.ca (Kevin B. Hendricks)
Date: Fri, 19 May 2006 11:37:49 -0400
Subject: [Rd] helping out
In-Reply-To: <Pine.LNX.4.64.0605181908170.8076@gannet.stats.ox.ac.uk>
References: <8A036DC9-74BA-4AB2-B6AB-7C20BFC9D5B2@sympatico.ca>
	<Pine.LNX.4.64.0605181051590.21587@homer24.u.washington.edu>
	<Pine.LNX.4.64.0605181908170.8076@gannet.stats.ox.ac.uk>
Message-ID: <AA227BF1-7377-4A52-8462-B4031F24F0EE@sympatico.ca>

Hi,

I have built my own tuned atlas libs enabling multiple processors and  
pthread support.  Then based on the note on page 23 of the "R  
Installation and Administration" manual, I added --disable-R- 
profiling to the configuration options

Unfortunately, the code in R/src/main/eval.c [updated from trunk this  
morning] references the static variable R_Profiling outside of the  
R_PROFILING ifdef which protects it declaration.

One possible solution would be the following.  Of course, you may  
want the static variable to exist all of the time but keep its 0  
value (ie. move its declaration outside the ifdef).

Hope this helps (the patch is only for demonstration purposes since  
you may want a different solution.


--- eval.c.prev 2006-05-19 11:28:54.000000000 -0400
+++ eval.c      2006-05-19 11:28:22.000000000 -0400
@@ -432,7 +432,11 @@
             R_Visible = 1 - PRIMPRINT(op);
             /* We used to do insert a context only if profiling,
                but helps for tracebacks too. */
+#ifdef R_PROFILING
             if (R_Profiling || (PPINFO(op).kind == PP_FOREIGN)) {
+#else
+           if (PPINFO(op).kind == PP_FOREIGN) {
+#endif
                 begincontext(&cntxt, CTXT_BUILTIN, e,
                              R_BaseEnv, R_BaseEnv, R_NilValue,  
R_NilValue);
                 tmp = PRIMFUN(op) (e, op, tmp, rho);

Kevin


From willylotto at virgilio.it  Fri May 19 18:24:44 2006
From: willylotto at virgilio.it (willylotto at virgilio.it)
Date: Fri, 19 May 2006 18:24:44 +0200 (CEST)
Subject: [Rd] I: L.D.L (PR#8881)
Message-ID: <20060519162444.26C0CCD3B@slim.kubism.ku.dk>

------=_Part_64172_20357219.1148055774494
Content-Type: message/rfc822

Message-ID: <8670732.1148050654196.JavaMail.root at pswm13.cp.tin.it>
Date: Fri, 19 May 2006 15:57:34 +0100 (GMT+01:00)
From:  <willylotto at virgilio.it>
Reply-To:  <willylotto at virgilio.it>
Subject: L.D.L
Mime-Version: 1.0
Content-Type: text/plain;charset="UTF-8"
Content-Transfer-Encoding: 7bit



Dear Winner, 

Am please to announce you as one of the ten lucky winners in the 
L.D.L draw held 
yesterday.All ten winning Addresses were randomly 
selected 
from a batch of 
fifty thousand international Emails. Your email address emerged alongside nine 
others 
as category two Winners. 

Consequently, you have therefore been approved for a total pay out of  
1m only. 



Please contact the under listed  e mail


Email- willsonhillary at netscape.net

+31-651045640




You are advice to keep this award confidential until prize are 
claimed to avert incidence of impersonation by unscrupulous elements. 


Sincerely yours,
Paul Green
 L.D.L 

The L.D.L Awards is proudly sponsored by the Microsoft 
Corporation, the Intel Group, Toshiba, Dell Computers,Mackintosh and a 
Conglomeration of other international IT companies. 

The L.D.L Internet Draw is held once in a year and is so 
organized to encourage the use of The Internet and computers worldwide. 


We also encourage you to visit our website at www.luckyday.nl and Take 
your 
chance to play and 
become part of our annual winners.
------=_Part_64172_20357219.1148055774494--


From ross at biostat.ucsf.edu  Fri May 19 19:23:19 2006
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Fri, 19 May 2006 10:23:19 -0700
Subject: [Rd] S4 classes and C
In-Reply-To: <17517.37850.60690.443326@stat.math.ethz.ch>
References: <1147974317.10544.23.camel@iron.psg.net>
	<m23bf79lz7.fsf@ziti.fhcrc.org>
	<17517.37850.60690.443326@stat.math.ethz.ch>
Message-ID: <1148059399.10544.52.camel@iron.psg.net>

On Fri, 2006-05-19 at 11:46 +0200, Martin Maechler wrote:
> >>>>> "Seth" == Seth Falcon <sfalcon at fhcrc.org>
> >>>>>     on Thu, 18 May 2006 12:22:36 -0700 writes:
> 
>     Seth> Ross Boylan <ross at biostat.ucsf.edu> writes:
>     >> Is there any good source of information on how S4 classes (and methods)
>     >> work from C?
> 
> Hmm, yes; there's nothing in the "Writing R Extensions" manual,
> and there's not so much in the ``The Green Book''
> (Chambers 1998), which is prominently cited by Doug Bates (and Saikat Debroy)
> in the paper given at DSC 2003 (mentioned earlier in this
> thread, http://www.ci.tuwien.ac.at/Conferences/DSC-2003/Drafts/BatesDebRoy.pdf )

Particularly relevant is Appendix A.6 of the Green book.  The index
isn't particularly helpful finding it.  Of course, Appendix A can't
answer the question of how the R implementation might differ.

For example, A.6 discusses GET_SLOT_OFFSET, which does not appear to be
available in R.

Thanks for the pointers.


From hornyaks at mail.nih.gov  Fri May 19 22:44:12 2006
From: hornyaks at mail.nih.gov (hornyaks at mail.nih.gov)
Date: Fri, 19 May 2006 22:44:12 +0200 (CEST)
Subject: [Rd] Possible issue with make install (PR#8883)
Message-ID: <20060519204412.613DC494D6@slim.kubism.ku.dk>

Full_Name: Stanley Hornyak
Version: 2.3.0
OS: Solaris 9
Submission from: (NULL) (128.231.93.143)


# make install
installing doc ...
installing doc/html ...
installing doc/html/search ...
installing doc/manual ...
installing etc ...
bash: -c: line 1: syntax error near unexpected token `;'
*** Error code 2
make: Fatal error: Command failed for target `install'
Current working directory /home/hornyaks/Compiles/R/R-2.3.0/etc
*** Error code 1
make: Fatal error: Command failed for target `install'


bash version is the Solaris default of 2.0.5.

Everything else seems to be OK.  I used straight borne shell during the
configure and make.



Suggestions?


From mschwartz at mn.rr.com  Fri May 19 22:55:35 2006
From: mschwartz at mn.rr.com (mschwartz at mn.rr.com)
Date: Fri, 19 May 2006 22:55:35 +0200 (CEST)
Subject: [Rd] Possible issue with make install (PR#8883)
Message-ID: <20060519205535.C7AB524785@slim.kubism.ku.dk>

On Fri, 2006-05-19 at 22:44 +0200, hornyaks at mail.nih.gov wrote:
> Full_Name: Stanley Hornyak
> Version: 2.3.0
> OS: Solaris 9
> Submission from: (NULL) (128.231.93.143)
> 
> 
> # make install
> installing doc ...
> installing doc/html ...
> installing doc/html/search ...
> installing doc/manual ...
> installing etc ...
> bash: -c: line 1: syntax error near unexpected token `;'
> *** Error code 2
> make: Fatal error: Command failed for target `install'
> Current working directory /home/hornyaks/Compiles/R/R-2.3.0/etc
> *** Error code 1
> make: Fatal error: Command failed for target `install'
> 
> 
> bash version is the Solaris default of 2.0.5.
> 
> Everything else seems to be OK.  I used straight borne shell during the
> configure and make.
> 
> 
> 
> Suggestions?

Either use r-patched, available from:

  ftp://ftp.stat.math.ethz.ch/Software/R/R-patched.tar.gz

or as Peter just noted on r-help, better yet and if willing, use
2.3.1Beta from:

  http://cran.r-project.org/src/base-prerelease/

This bug was reported previously and fixed:

  https://stat.ethz.ch/pipermail/r-devel/2006-May/037626.html

HTH,

Marc Schwartz


From eNews at 3rdmill.com  Fri May 19 22:56:22 2006
From: eNews at 3rdmill.com (eNews at 3rdmill.com)
Date: 19 May 2006 16:56:22 -0400
Subject: [Rd] =?windows-1252?q?Innovative_Enterprise_Microarray_Software?=
Message-ID: <SANTANA8r6beUzmRf6C000066f7@santana.lemond.3rdmill.com>


3rd Millennium is announcing the release of its award winning Array Repository and Data Analysis System (ARDAS) version 2. ARDAS is a web-enabled enterprise software system that provides a complete and fully integrated solution to microarray data acquisition, management, and analysis.

ARDAS includes three main modules:
1- A Laboratory Information Management System (LIMS)
2- A repository and data warehouse
3- An Analysis Information Management System (AIMS) based on bioconductor and R

ARDAS is a robust and scalable enterprise system based on an Oracle relational database and is offered at desktop prices ($1900-$2900). To learn more or request a trial, please visit our web site at http://www.3rdmill.com/em1

Thank you.

3rd Millennium, Inc.
391 Totten Pond Rd. Suite 104
Waltham, MA 02451
eSales at 3rdmill.com
781-890-4440
www.3rdmill.com

---------------------------------------------------------------------
If you'd rather not receive emails from 3rd Millennium, please reply
to this email with the word REMOVE in the body of your message.



From eNews at 3rdmill.com  Fri May 19 22:56:22 2006
From: eNews at 3rdmill.com (eNews at 3rdmill.com)
Date: 19 May 2006 16:56:22 -0400
Subject: [Rd] =?windows-1252?q?Innovative_Enterprise_Microarray_Software?=
Message-ID: <SANTANAvKwq5BI1n3q7000066f6@santana.lemond.3rdmill.com>


3rd Millennium is announcing the release of its award winning Array Repository and Data Analysis System (ARDAS) version 2. ARDAS is a web-enabled enterprise software system that provides a complete and fully integrated solution to microarray data acquisition, management, and analysis.

ARDAS includes three main modules:
1- A Laboratory Information Management System (LIMS)
2- A repository and data warehouse
3- An Analysis Information Management System (AIMS) based on bioconductor and R

ARDAS is a robust and scalable enterprise system based on an Oracle relational database and is offered at desktop prices ($1900-$2900). To learn more or request a trial, please visit our web site at http://www.3rdmill.com/em1

Thank you.

3rd Millennium, Inc.
391 Totten Pond Rd. Suite 104
Waltham, MA 02451
eSales at 3rdmill.com
781-890-4440
www.3rdmill.com

---------------------------------------------------------------------
If you'd rather not receive emails from 3rd Millennium, please reply
to this email with the word REMOVE in the body of your message.



From Dan.Kelley at Dal.Ca  Sat May 20 00:27:06 2006
From: Dan.Kelley at Dal.Ca (Dan.Kelley at Dal.Ca)
Date: Sat, 20 May 2006 00:27:06 +0200 (CEST)
Subject: [Rd] PR#8822
Message-ID: <20060519222706.48387494D6@slim.kubism.ku.dk>

Below my signature is an illustration of how I fixed this bug.   
(First, of course, I renamed the "R" file to "R-orig".)

Dan E. Kelley, Assoc. Prof.		phone:(902)494-1694
Dept. Oceanography				fax:(902)494-2885
Dalhousie University				mailto:Dan.Kelley at Dal.CA
Halifax, NS, Canada B3H 4J1   	http://www.phys.ocean.dal.ca/~kelley/ 
Kelley_Dan.html



$ diff -Naur /Library/Frameworks/R.framework/Resources/bin/R /Library/ 
Frameworks/R.framework/Resources/bin/R-orig


--- /Library/Frameworks/R.framework/Resources/bin/R     2006-05-19  
19:08:56.000000000 -0300
+++ /Library/Frameworks/R.framework/Resources/bin/R-orig         
2006-05-19 19:08:58.000000000 -0300
@@ -20,8 +20,7 @@
# This script is shared by parallel installs, so nothing in it should
# depend on the sub-architecture except the default here.
#=== BEGIN CRAN CHANGES ===
-R_ARCH=/`arch`
-export R_ARCH
+: ${R_ARCH=/`arch`}
PATH=/usr/local/gcc4.0/bin:$PATH
export PATH
#==== END CRAN CHANGES ====


From retsofaj at mac.com  Sat May 20 00:37:02 2006
From: retsofaj at mac.com (Jason Foster)
Date: Fri, 19 May 2006 18:37:02 -0400
Subject: [Rd] Memory allocator on OS/X
Message-ID: <2A01E769-8CC9-4AF4-8170-51D7BAB89923@mac.com>

A quick scan though the mailing list archives didn't reveal any  
reference to this article, so here goes:

   http://ridiculousfish.com/blog/archives/2006/05/16/36/

In response to a criticism of OS X, a diligent blogger examined a  
claim that it was an inherently slow operating system.  The  
application in question was R, and the results were...

"Linux uses ptmalloc, which is a thread-safe implemenation based on  
Doug Lea?s allocator (Sekhon?s test is single threaded,  
incidentally). R also uses the Lea allocator on Windows instead of  
the default Windows malloc. But on Mac OS X, it uses the default  
allocator."

... and ...

"If you use the same allocator on Mac OS X that R uses on Windows,  
the performance differences all but disappear."

Would it make sense for the build process that generates R binaries  
for OS X to use the Lea allocator?

Jason Foster


From simon.urbanek at r-project.org  Sat May 20 01:33:50 2006
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 19 May 2006 19:33:50 -0400
Subject: [Rd] Memory allocator on OS/X
In-Reply-To: <2A01E769-8CC9-4AF4-8170-51D7BAB89923@mac.com>
References: <2A01E769-8CC9-4AF4-8170-51D7BAB89923@mac.com>
Message-ID: <E208D068-FCF1-44B6-91F6-E53B3C1D7293@r-project.org>

Jason,

On May 19, 2006, at 6:37 PM, Jason Foster wrote:

> A quick scan though the mailing list archives didn't reveal any  
> reference to this article

Somehow you managed to miss it, we had a discussion about this quite  
recently:
http://www.mail-archive.com/r-sig-mac%40stat.math.ethz.ch/msg00770.html

Also based on private e-mail exchange with all involved parties the  
preliminary answer is no. The mentioned speed-up occurred only after  
patching the involved code, R was actually not even modified. It is  
still unclear whether a modification of R is safe and whether any  
speed up is to be expected. I hope to have a quiet minute during the  
weekend so I can test the various hypotheses... (There are two  
separate issues to be addressed: system malloc/free and BLAS  
performance).

Cheers,
Simon


> [...]
>
> Would it make sense for the build process that generates R binaries
> for OS X to use the Lea allocator?
>
> Jason Foster
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From retsofaj at mac.com  Sat May 20 01:47:58 2006
From: retsofaj at mac.com (Jason Foster)
Date: Fri, 19 May 2006 19:47:58 -0400
Subject: [Rd] Memory allocator on OS/X
In-Reply-To: <E208D068-FCF1-44B6-91F6-E53B3C1D7293@r-project.org>
References: <2A01E769-8CC9-4AF4-8170-51D7BAB89923@mac.com>
	<E208D068-FCF1-44B6-91F6-E53B3C1D7293@r-project.org>
Message-ID: <30D7E3E0-759D-4443-965B-8A77C22982FF@mac.com>

> Somehow you managed to miss it, we had a discussion about this  
> quite recently:
> http://www.mail-archive.com/r-sig-mac%40stat.math.ethz.ch/ 
> msg00770.html

My bad; I focused on the r-devel list and didn't check the SIG.   
Sorry about the noise.  Jason


From ecu at info.fundp.ac.be  Thu May 18 16:51:02 2006
From: ecu at info.fundp.ac.be (ecu at info.fundp.ac.be)
Date: Thu, 18 May 2006 16:51:02 +0200 (CEST)
Subject: [Rd] Negatives density values (PR#8876)
Message-ID: <20060518145102.B2AF8CD3B@slim.kubism.ku.dk>

Full_Name: Cuvelier Etienne
Version: R version 2.2.1
OS: Windows XP
Submission from: (NULL) (81.240.71.204)


If we use the "density" function "far" from the data, some values are
negatives.
I know that these value of the density are "near equal" to zero, but the change
of sign can involve some "false" decision.

Here is an example of this fact:


> x = c(0.006, 0.002, 0.024, 0.02, 0.034, 0.09, 0.074, 0.072, 0.122,
+ 0.048, 0.044, 0.168)
> 
> min(x)
[1] 0.002
> max(x)
[1] 0.168
> 
> result = density(x,n=20, from = -1 , to = 1)
> 
> result$y
 [1]  2.433854e-17  1.726562e-17  1.285227e-16  2.359248e-16
 [5]  4.628709e-17 -1.535879e-16  1.438105e-16  2.023210e-16
 [9]  2.649354e-11  1.438340e-01  7.679909e+00  1.767860e+00
[13]  2.056151e-04 -1.407219e-16 -3.575895e-18 -1.979607e-16
[17] -1.574544e-17 -2.257917e-17 -2.305234e-16  4.052727e-18
>
> #A plot of the "fluctuations" near zero
> plot(result$x,result$y,type="l",xlim=c(-1,1),ylim=c(-10^-14,10^-14))
> abline(h=0)
>
> #All neagtives value of density are "near equal" to zero 
> all(apply(as.matrix(result$y[result$y<0]),1,all.equal, target=0)==TRUE)
[1] TRUE


>  sessionInfo()
R version 2.2.1, 2005-12-20, i386-pc-mingw32

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils"
[6] "datasets"  "base"

> Sys.info()
                      sysname                       release 
                    "Windows"                      "NT 5.1" 
                      version                      nodename 
"(build 2600) Service Pack 2"                       "WINXP" 
                      machine                         login 
                        "x86"                     "Etienne" 
                         user 
                    "Etienne" 

> R.Version()
$platform
[1] "i386-pc-mingw32"

$arch
[1] "i386"

$os
[1] "mingw32"

$system
[1] "i386, mingw32"

$status
[1] ""

$major
[1] "2"

$minor
[1] "2.1"

$year
[1] "2005"

$month
[1] "12"

$day
[1] "20"

$"svn rev"
[1] "36812"

$language
[1] "R"


From murdoch at stats.uwo.ca  Sat May 20 17:03:28 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 20 May 2006 11:03:28 -0400
Subject: [Rd] Negatives density values (PR#8876)
In-Reply-To: <20060518145102.B2AF8CD3B@slim.kubism.ku.dk>
References: <20060518145102.B2AF8CD3B@slim.kubism.ku.dk>
Message-ID: <446F2FC0.9060709@stats.uwo.ca>

On 5/18/2006 10:51 AM, ecu at info.fundp.ac.be wrote:
> Full_Name: Cuvelier Etienne
> Version: R version 2.2.1
> OS: Windows XP
> Submission from: (NULL) (81.240.71.204)
> 
> 
> If we use the "density" function "far" from the data, some values are
> negatives.
> I know that these value of the density are "near equal" to zero, but the change
> of sign can involve some "false" decision.

I wouldn't consider this a bug, rather a consequence of using the 
Fourier transform to do the density estimate, as documented.

If slightly negative values of the density cause trouble for you, then 
use pmax(density, 0) to force them to be non-negative, or use a 
different algorithm for the estimates.

Duncan Murdoch
> 
> Here is an example of this fact:
> 
> 
>> x = c(0.006, 0.002, 0.024, 0.02, 0.034, 0.09, 0.074, 0.072, 0.122,
> + 0.048, 0.044, 0.168)
>> min(x)
> [1] 0.002
>> max(x)
> [1] 0.168
>> result = density(x,n=20, from = -1 , to = 1)
>>
>> result$y
>  [1]  2.433854e-17  1.726562e-17  1.285227e-16  2.359248e-16
>  [5]  4.628709e-17 -1.535879e-16  1.438105e-16  2.023210e-16
>  [9]  2.649354e-11  1.438340e-01  7.679909e+00  1.767860e+00
> [13]  2.056151e-04 -1.407219e-16 -3.575895e-18 -1.979607e-16
> [17] -1.574544e-17 -2.257917e-17 -2.305234e-16  4.052727e-18
>> #A plot of the "fluctuations" near zero
>> plot(result$x,result$y,type="l",xlim=c(-1,1),ylim=c(-10^-14,10^-14))
>> abline(h=0)
>>
>> #All neagtives value of density are "near equal" to zero 
>> all(apply(as.matrix(result$y[result$y<0]),1,all.equal, target=0)==TRUE)
> [1] TRUE
> 
> 
>>  sessionInfo()
> R version 2.2.1, 2005-12-20, i386-pc-mingw32
> 
> attached base packages:
> [1] "methods"   "stats"     "graphics"  "grDevices" "utils"
> [6] "datasets"  "base"
> 
>> Sys.info()
>                       sysname                       release 
>                     "Windows"                      "NT 5.1" 
>                       version                      nodename 
> "(build 2600) Service Pack 2"                       "WINXP" 
>                       machine                         login 
>                         "x86"                     "Etienne" 
>                          user 
>                     "Etienne" 
> 
>> R.Version()
> $platform
> [1] "i386-pc-mingw32"
> 
> $arch
> [1] "i386"
> 
> $os
> [1] "mingw32"
> 
> $system
> [1] "i386, mingw32"
> 
> $status
> [1] ""
> 
> $major
> [1] "2"
> 
> $minor
> [1] "2.1"
> 
> $year
> [1] "2005"
> 
> $month
> [1] "12"
> 
> $day
> [1] "20"
> 
> $"svn rev"
> [1] "36812"
> 
> $language
> [1] "R"
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Sat May 20 19:54:12 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 20 May 2006 18:54:12 +0100 (BST)
Subject: [Rd] UseMethod infelicity
In-Reply-To: <Pine.LNX.4.64.0605191348300.6158@gannet.stats.ox.ac.uk>
References: <Pine.LNX.4.64.0605191348300.6158@gannet.stats.ox.ac.uk>
Message-ID: <Pine.LNX.4.64.0605201620420.28607@gannet.stats.ox.ac.uk>

Here are three examples where this matters, and I think the bug is 
elsewhere!

1) Package accuracy does

ZeligHooks<-function (...) {
    if (exists(".simHooked",envir=.GlobalEnv)) {
         return(TRUE)
    }
    origsim=get("sim",envir=as.environment("package:Zelig"))
    sim.replacement=function (object, x, ...) {
     if  (inherits(object,"sensitivity")) {
        psim(object,x,...)
     } else {
       origsim(object,x,...)
     }
    }
    assignInNamespace("sim",sim.replacement,"Zelig")
    unlockBinding("sim",as.environment("package:Zelig"))
    assign("sim",sim.replacement, envir=as.environment("package:Zelig"))
    assign("sim",sim.replacement, envir=.GlobalEnv)
    assign(".simHooked",TRUE,envir=.GlobalEnv)
}

Now, origsim() becomes a generic calling "sim", with defining environment 
namespace:Zelig.  However, sim in namespace:Zelig has been altered to be a 
new function, whose enclosure is not namespace:Zelig and hence cannot see 
the methods registered on the original sim() in namespace:Zelig.  I think 
that is the correct behaviour (the new sim might have nothing to do with 
the old one).  The fix would appear to be to set the environment of the 
replacement to namespace:Zelig, but then origsim will not be visible from 
sim.

Note that the package writes in the workspace and clobbers any object 
called 'sim' there.  Surely a less intrusive solution is needed?

There's a similar (maybe the same) problem in package VDCutil.


2) Package arules fails its tests.  The problem is in Matrix:

> base::as.matrix
function (x)
UseMethod("as.matrix")
<environment: namespace:base>
> library(Matrix)
> base::as.matrix
standardGeneric for "as.matrix" defined from package "base"

function (x)
standardGeneric("as.matrix")
<environment: 0x1453cc8>
Methods may be defined for arguments: x

Now is converting to an S4 generic *not* supposed to alter the function in 
the original package/namespace? It does not do it if I do it by hand:

> setClass("foo", "numeric")
[1] "foo"
> setMethod("as.matrix", "foo", function(x) x)
Creating a new generic function for 'as.matrix' in '.GlobalEnv'
[1] "as.matrix"
> base::as.matrix
function (x)
UseMethod("as.matrix")
<environment: namespace:base>

and this looks like a bug.


3) Package R.oo has things like UseMethod("$") whereas this is documented 
to work for functions (not operators).  This is unnecessary ($ does 
internal dispatch) and the existing code is getting the wrong defining 
environment (and although I've reinstated this as a workaround, I think it 
should be an error).


Aargh ... fixing one bug is not supposed to uncover three others.


On Fri, 19 May 2006, Prof Brian Ripley wrote:

> If I do
>
>> example(lm)
> ...
>> mycoef <- function(object, ...) UseMethod("coef", object)
>> mycoef(lm.D9)
> Error in mycoef(lm.D9) : no applicable method for "coef"
>
> which is pretty surprising, as coef has a default method.
>
> After a bit of digging, this comes from do_usemethod having
>
>        defenv = environment where the generic was defined */
>     defenv = ENCLOS(env);
>
> so it is assuming that UseMethod() is called within the defining generic
> for its first argument.  That plainly does not need to be true, e.g.
>
>> coefficients
> function (object, ...)
> UseMethod("coef")
> <environment: namespace:stats>
>
> It is clear to me that we need to search for 'generic' and find its
> defining environment rather than that of the current caller.  It is not
> entirely clear where to search from as I think we need to avoid
>
> mycoef <- function(x)
> {
>    mycoef <- function(x) stop("not this one")
>    UseMethod("mycoef")
> }
>
> so I used ENCLOS(env).
>
> This adds some overhead, hopefully no more than searching for methods.
>
> BTW, I noticed that R_LookupMethod uses findVar, that is looks for any
> object not for functions: that must be another infelicity.
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jranke at uni-bremen.de  Sat May 20 22:49:25 2006
From: jranke at uni-bremen.de (jranke at uni-bremen.de)
Date: Sat, 20 May 2006 22:49:25 +0200 (CEST)
Subject: [Rd] (PR#8877) predict.lm does not have a weights argument for
	newdata
Message-ID: <20060520204925.1E26919B2C@slim.kubism.ku.dk>

Dear R developers,

I am a little disappointed that my bug report only made it to the
wishlist, with the argument:

	Well, it does not say it has.
	Only relevant to prediction intervals.

predict.lm does calculate prediction intervals for linear models from 
weighted regression, so they should be correct, right? 

As far as I can see they are bound to be wrong in almost all cases, if
no weights for newdata can be given. So the point is that predict.lm
needs such an argument in order to give correct prediction intervals for
models from weighted linear regression.

Also, it strikes me that in the absence of a "newdata" argument, the
weights from the "lm" object need to be taken into account for
constructing prediction intervals.

My updated proposal fixing both points as well as the help file can be found at:

	http://www.uft.uni-bremen.de/chemie/ranke/r-patches/lm.predict.patch

and I wrote up a small demonstration of the problem and my proposed solution:

	http://www.uft.uni-bremen.de/chemie/ranke/r-patches/lm.predict.pdf

Kind regards,

Johannes Ranke

-- 
Dr. Johannes Ranke                 jranke at uni-bremen.de
UFT Bremen, Leobenerstr. 1         +49 421 218 8971 
D-28359 Bremen                     http://www.uft.uni-bremen.de/chemie/ranke


From zhou at stat.columbia.edu  Sun May 21 03:32:44 2006
From: zhou at stat.columbia.edu (zhou at stat.columbia.edu)
Date: Sun, 21 May 2006 03:32:44 +0200 (CEST)
Subject: [Rd] increase size of the limit of memory (PR#8885)
Message-ID: <20060521013244.D8FF112C69@slim.kubism.ku.dk>

Full_Name: Shouhao Zhou
Version: 2.2.1
OS: windows
Submission from: (NULL) (128.59.110.149)


if you run the following code in R after version 2.1.1:

n.sims<-6000;n<-30000
y<-array(NA,c(n.sims,n))

with output:

Error: cannot allocate vector of size 703125 Kb
In addition: Warning messages:
1: Reached total allocation of 509Mb: see help(memory.size) 
2: Reached total allocation of 509Mb: see help(memory.size) 

then I try to increase the size by command which made sense in R before version
2.0.1 and can help to allocate vector y of size 703125 Kb:

memory.limit(14000000000)

but now we get the output in such away:

Error in memory.size(size) : don't be silly!: your machine has a 4Gb address
limit

What can I do now to allocate the vector y<-array(NA,c(6000,30000)) in the
latest version of R?


From ripley at stats.ox.ac.uk  Sun May 21 08:37:32 2006
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Sun, 21 May 2006 08:37:32 +0200 (CEST)
Subject: [Rd] increase size of the limit of memory (PR#8885)
Message-ID: <20060521063732.A0F09CD29@slim.kubism.ku.dk>

The help page says

     size: numeric. If 'NA' report the memory size, otherwise request a
           new limit, in Mb.  Values of up to 4096 are allowed, but see
           Details.

You requested a limit of 14 billion megabytes of memory, which was indeed 
silly.

Please do read the R FAQs and the posting guide as you are asked before 
posting.

On Sun, 21 May 2006, zhou at stat.columbia.edu wrote:

> Full_Name: Shouhao Zhou
> Version: 2.2.1
> OS: windows
> Submission from: (NULL) (128.59.110.149)
>
>
> if you run the following code in R after version 2.1.1:
>
> n.sims<-6000;n<-30000
> y<-array(NA,c(n.sims,n))
>
> with output:
>
> Error: cannot allocate vector of size 703125 Kb
> In addition: Warning messages:
> 1: Reached total allocation of 509Mb: see help(memory.size)
> 2: Reached total allocation of 509Mb: see help(memory.size)
>
> then I try to increase the size by command which made sense in R before version
> 2.0.1 and can help to allocate vector y of size 703125 Kb:
>
> memory.limit(14000000000)
>
> but now we get the output in such away:
>
> Error in memory.size(size) : don't be silly!: your machine has a 4Gb address
> limit
>
> What can I do now to allocate the vector y<-array(NA,c(6000,30000)) in the
> latest version of R?
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ggrothendieck at gmail.com  Sun May 21 13:41:55 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 21 May 2006 07:41:55 -0400
Subject: [Rd] print.trellis(..., draw.in=...)
Message-ID: <971536df0605210441s5833a4cdr8286fdd23f560b7c@mail.gmail.com>

A year ago I had posted this code

https://stat.ethz.ch/pipermail/r-devel/2005-June/033508.html

and the associated discussion was that there would be a print.trellis
argument that could be used to eliminate the need for with.vpPath
or with.viewport there.  I assume that that is what draw.in= in
print.trellis is for.  When I try it I get an error.  I did notice that
?print.trellis says draw.in= has not been well tested yet.  Is
this a bug?

After running the the code at the end I get this error
message:

 Error in downViewport.vpPath(vpPathDirect(name), strict, recording =
recording) :
        Viewport 'viewport[GRID.VP.1]' was not found

The only difference between the code below and the code in the
link above (which works) is that in the for loop at the end the
'with' in the code in the link has been removed and draw.in=
used in the print call in its place.

I am using Windows XP and get similar messages in 2.2.1 and
2.3.0 patched.


library(grid)
library(lattice)

pushLayout <- function(nr, nc, name="layout") {
  pushViewport(viewport(layout=grid.layout(nr, nc), name=name))
  for (i in 1:nr) {
    for (j in 1:nc) {
      pushViewport(viewport(layout.pos.row=i, layout.pos.col=j))
      upViewport()
    }
  }
  upViewport()
}

names.vpPath <- names.viewport <- function(x) x$name

with.vpPath <- with.viewport <- function(data, expr, ...) {
      # if data is a vpPath it cannot be ROOT since
      # NULL will never dispatch here
      depth <- if (data$name == "ROOT") 0 else downViewport(names(data))
      result <- eval.parent(substitute(expr))
      upViewport(depth)
      invisible(result)
}

getChildren.viewport <- function(x) x$children

grid.newpage()

# specify number of cells to fill and number of rows
n <- 5; nr <- 3

nc <- ceiling(n/nr)
downViewport(pushLayout(nr, nc))

vpt <- current.vpTree(all = FALSE)
for(k in 1:n)
      print( xyplot(v ~ v, list(v = 1:k)), newpage = FALSE,
		draw.in = getChildren.viewport(vpt)[[k]] )


From spencer.graves at pdf.com  Sun May 21 17:45:14 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 21 May 2006 08:45:14 -0700
Subject: [Rd] Suggesting changes to HELP files?
Message-ID: <44708B0A.1050409@pdf.com>

	  Is there a procedure for suggesting changes to HELP files of the core 
R distribution?  If yes, what is it?  If it would be considered a 
friendly gesture, I could find the relevant *.Rd file and submit a 
suggested modification to it someplace.  Alternatively, I could just 
send suggestions someplace if they would receive appropriate 
consideration.

	  On many occasions, I think of modifications, e.g., additional 
examples, that could be added to 'help' pages that I believe would make 
it easier for people to understand how to use some R feature.  Instead, 
I often provide the same answer multiple times to different posts.

	  I can think of two changes off the top of my head that I'd like to 
see:  First, many if not all of the helps page in the nlme and lme4 
packages should, I believe, include a reference Pinheiro and Bates. 
This is not the place for modesty on the part of Pinheiro, Bates, and 
co-workers.  I believe that many requests for help might be eliminated 
if such references were added.  Failing that, it would be easier for 
people like me to suggest someone read that book, because I wouldn't 
feel such a need to spell out the entire citation every time.

	  Second, I think the description of 'vignette' could be enhanced to 
include some version of my 'p.s.' to 
'http://finzi.psych.upenn.edu/R/Rhelp02a/archive/73494.html' and other 
similar posts.  In particular, I see that the 'edit' method is described 
there, but I didn't understand what it said until I already knew how to 
use it.  Also, 'edit' doesn't work for me under ESS / Emacs.  For that, 
I use Stangle (as Sundar Dorai-Raj taught me).

	  Thanks,
	  Spencer Graves


From ggrothendieck at gmail.com  Sun May 21 18:02:41 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 21 May 2006 12:02:41 -0400
Subject: [Rd] Suggesting changes to HELP files?
In-Reply-To: <44708B0A.1050409@pdf.com>
References: <44708B0A.1050409@pdf.com>
Message-ID: <971536df0605210902u3810b9a4nf4f7c4d967e98e5@mail.gmail.com>

You could consider adding something to the wiki while you are
waiting.

On 5/21/06, Spencer Graves <spencer.graves at pdf.com> wrote:
>          Is there a procedure for suggesting changes to HELP files of the core
> R distribution?  If yes, what is it?  If it would be considered a
> friendly gesture, I could find the relevant *.Rd file and submit a
> suggested modification to it someplace.  Alternatively, I could just
> send suggestions someplace if they would receive appropriate
> consideration.
>
>          On many occasions, I think of modifications, e.g., additional
> examples, that could be added to 'help' pages that I believe would make
> it easier for people to understand how to use some R feature.  Instead,
> I often provide the same answer multiple times to different posts.
>
>          I can think of two changes off the top of my head that I'd like to
> see:  First, many if not all of the helps page in the nlme and lme4
> packages should, I believe, include a reference Pinheiro and Bates.
> This is not the place for modesty on the part of Pinheiro, Bates, and
> co-workers.  I believe that many requests for help might be eliminated
> if such references were added.  Failing that, it would be easier for
> people like me to suggest someone read that book, because I wouldn't
> feel such a need to spell out the entire citation every time.
>
>          Second, I think the description of 'vignette' could be enhanced to
> include some version of my 'p.s.' to
> 'http://finzi.psych.upenn.edu/R/Rhelp02a/archive/73494.html' and other
> similar posts.  In particular, I see that the 'edit' method is described
> there, but I didn't understand what it said until I already knew how to
> use it.  Also, 'edit' doesn't work for me under ESS / Emacs.  For that,
> I use Stangle (as Sundar Dorai-Raj taught me).
>
>          Thanks,
>          Spencer Graves
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From murdoch at stats.uwo.ca  Sun May 21 19:12:13 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 21 May 2006 13:12:13 -0400
Subject: [Rd] Suggesting changes to HELP files?
In-Reply-To: <44708B0A.1050409@pdf.com>
References: <44708B0A.1050409@pdf.com>
Message-ID: <44709F6D.2000002@stats.uwo.ca>

On 5/21/2006 11:45 AM, Spencer Graves wrote:
> 	  Is there a procedure for suggesting changes to HELP files of the core 
> R distribution?  If yes, what is it?  If it would be considered a 
> friendly gesture, I could find the relevant *.Rd file and submit a 
> suggested modification to it someplace.  Alternatively, I could just 
> send suggestions someplace if they would receive appropriate 
> consideration.

I don't think there's a formal procedure.  Generally the idea is to find 
an R Core member (i.e. someone who can commit changes) who thinks your 
changes are a good idea, and then they'll commit them.  How you do that 
convincing depends on who you're talking to.  For your examples below:

> 	  On many occasions, I think of modifications, e.g., additional 
> examples, that could be added to 'help' pages that I believe would make 
> it easier for people to understand how to use some R feature.  Instead, 
> I often provide the same answer multiple times to different posts.
> 
> 	  I can think of two changes off the top of my head that I'd like to 
> see:  First, many if not all of the helps page in the nlme and lme4 
> packages should, I believe, include a reference Pinheiro and Bates. 
> This is not the place for modesty on the part of Pinheiro, Bates, and 
> co-workers.  I believe that many requests for help might be eliminated 
> if such references were added.  Failing that, it would be easier for 
> people like me to suggest someone read that book, because I wouldn't 
> feel such a need to spell out the entire citation every time.

nlme and lme4 are both contributed packages, so you want to talk to the 
maintainers about changes to them.  nlme is distributed with binary 
builds, but isn't strictly speaking part of the "core R distribution".
Only packages labelled as "Priority: base" in the DESCRIPTION file are 
part of the core distribution.

> 	  Second, I think the description of 'vignette' could be enhanced to 
> include some version of my 'p.s.' to 
> 'http://finzi.psych.upenn.edu/R/Rhelp02a/archive/73494.html' and other 
> similar posts.  In particular, I see that the 'edit' method is described 
> there, but I didn't understand what it said until I already knew how to 
> use it.  

For something like this, it's probably best to draft some text, and post 
it to R-devel.  You could also look at the Subversion history of the 
appropriate file (src/library/utils/man/vignette.Rd) to see who has been 
active with changes to it recently; they might be more interested in 
making changes to it than others.  In this case, the log is

Revision: 33828
Author: leisch
Date: 2:37:14 AM, Tuesday, April 05, 2005
Message:
example where the vignette name is not the package name


Revision: 32054
Author: leisch
Date: 9:52:24 AM, Friday, November 26, 2004
Message:
new print and edit methods for vignette objects


Revision: 27442
Author: ripley
Date: 2:24:25 AM, Tuesday, December 09, 2003
Message:
split from base

so Fritz Leisch might be interested, but the last change is more than a 
year ago, so it might not be at the top of his mind.

The latter observation is the main reason suggested changes might not 
make it into the source:  you need to get someone's attention, and 
they'll need to devote some time to dealing with your suggestion.  It 
needs to be clear that the change is an improvement.  Things like minor 
typos are easy, but something like the suggestion above would need to be 
evaluated by someone familiar with what vignette() does, and what it is 
intended to do.  So you need to make it as easy as possible to evaluate 
and incorporate your change, and sometimes it still won't get in, 
because the only people to do it are working on other things.

You should also be prepared to hear criticism of your suggestion, and be 
able to defend it or change it.  Don't be offended if someone rewrites 
your change, or if they ask you to rewrite it.

 > Also, 'edit' doesn't work for me under ESS / Emacs.  For that,
> I use Stangle (as Sundar Dorai-Raj taught me).

That sounds like an ESS or Emacs bug, and should be reported to the 
maintainers of one of those.

Duncan Murdoch


From deepayan.sarkar at gmail.com  Sun May 21 19:19:34 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Sun, 21 May 2006 12:19:34 -0500
Subject: [Rd] print.trellis(..., draw.in=...)
In-Reply-To: <971536df0605210441s5833a4cdr8286fdd23f560b7c@mail.gmail.com>
References: <971536df0605210441s5833a4cdr8286fdd23f560b7c@mail.gmail.com>
Message-ID: <eb555e660605211019s31fac589hb4107dd88c6f69c6@mail.gmail.com>

On 5/21/06, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> A year ago I had posted this code
>
> https://stat.ethz.ch/pipermail/r-devel/2005-June/033508.html
>
> and the associated discussion was that there would be a print.trellis
> argument that could be used to eliminate the need for with.vpPath
> or with.viewport there.  I assume that that is what draw.in= in
> print.trellis is for.  When I try it I get an error.  I did notice that
> ?print.trellis says draw.in= has not been well tested yet.  Is
> this a bug?

No, but perhaps a lack of clarity in the documentation. ?print.trellis says:

 draw.in: An optional (grid) viewport (used as the 'name' argument in
          'downViewport') in which the plot is to be drawn.  ...

and ?downViewport says

    name: A character value to identify a viewport in the tree.

Your code supplies viewports, not character names (in the older
working example, you did this conversion inside with.vpPath).

-Deepayan

> After running the the code at the end I get this error
> message:
>
>  Error in downViewport.vpPath(vpPathDirect(name), strict, recording =
> recording) :
>         Viewport 'viewport[GRID.VP.1]' was not found
>
> The only difference between the code below and the code in the
> link above (which works) is that in the for loop at the end the
> 'with' in the code in the link has been removed and draw.in=
> used in the print call in its place.
>
> I am using Windows XP and get similar messages in 2.2.1 and
> 2.3.0 patched.
>
>
> library(grid)
> library(lattice)
>
> pushLayout <- function(nr, nc, name="layout") {
>   pushViewport(viewport(layout=grid.layout(nr, nc), name=name))
>   for (i in 1:nr) {
>     for (j in 1:nc) {
>       pushViewport(viewport(layout.pos.row=i, layout.pos.col=j))
>       upViewport()
>     }
>   }
>   upViewport()
> }
>
> names.vpPath <- names.viewport <- function(x) x$name
>
> with.vpPath <- with.viewport <- function(data, expr, ...) {
>       # if data is a vpPath it cannot be ROOT since
>       # NULL will never dispatch here
>       depth <- if (data$name == "ROOT") 0 else downViewport(names(data))
>       result <- eval.parent(substitute(expr))
>       upViewport(depth)
>       invisible(result)
> }
>
> getChildren.viewport <- function(x) x$children
>
> grid.newpage()
>
> # specify number of cells to fill and number of rows
> n <- 5; nr <- 3
>
> nc <- ceiling(n/nr)
> downViewport(pushLayout(nr, nc))
>
> vpt <- current.vpTree(all = FALSE)
> for(k in 1:n)
>       print( xyplot(v ~ v, list(v = 1:k)), newpage = FALSE,
>                 draw.in = getChildren.viewport(vpt)[[k]] )


From spencer.graves at pdf.com  Sun May 21 19:23:18 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 21 May 2006 10:23:18 -0700
Subject: [Rd] Suggesting changes to HELP files?
In-Reply-To: <971536df0605210902u3810b9a4nf4f7c4d967e98e5@mail.gmail.com>
References: <44708B0A.1050409@pdf.com>
	<971536df0605210902u3810b9a4nf4f7c4d967e98e5@mail.gmail.com>
Message-ID: <4470A206.1070703@pdf.com>

Hi, Gabor:

	  Thanks.  My initial failed attempt to add to "R wiki" generated the 
following two questions:

	  1.  What's the best way to find the R Wiki from "www.r-project.org"? 
  I found it just now via RSiteSearch("R wiki").  Might it be reasonable 
to add, e.g., a hot link to "R Wiki" under "Documentation"?

	  2.  I just found a page that reads, 'R Wiki - Documentation
The ?Wikified? version of all R man pages. To access a given page, type 
the name of an R function in the search box at top right and click 
?search?. Select the corresponding page in the search result.

Alternatively, you can click the name of a function in an R code chunk 
anywhere.'  (http://wiki.r-project.org/rwiki/doku.php?id=rdoc:rdoc)

	  I tried searching for 'vignette' but failed to get anything useful. 
What am I missing?

	  Thanks again,
	  Spencer Graves

Gabor Grothendieck wrote:
> You could consider adding something to the wiki while you are
> waiting.
> 
> On 5/21/06, Spencer Graves <spencer.graves at pdf.com> wrote:
>>          Is there a procedure for suggesting changes to HELP files of 
>> the core
>> R distribution?  If yes, what is it?  If it would be considered a
>> friendly gesture, I could find the relevant *.Rd file and submit a
>> suggested modification to it someplace.  Alternatively, I could just
>> send suggestions someplace if they would receive appropriate
>> consideration.
>>
>>          On many occasions, I think of modifications, e.g., additional
>> examples, that could be added to 'help' pages that I believe would make
>> it easier for people to understand how to use some R feature.  Instead,
>> I often provide the same answer multiple times to different posts.
>>
>>          I can think of two changes off the top of my head that I'd 
>> like to
>> see:  First, many if not all of the helps page in the nlme and lme4
>> packages should, I believe, include a reference Pinheiro and Bates.
>> This is not the place for modesty on the part of Pinheiro, Bates, and
>> co-workers.  I believe that many requests for help might be eliminated
>> if such references were added.  Failing that, it would be easier for
>> people like me to suggest someone read that book, because I wouldn't
>> feel such a need to spell out the entire citation every time.
>>
>>          Second, I think the description of 'vignette' could be 
>> enhanced to
>> include some version of my 'p.s.' to
>> 'http://finzi.psych.upenn.edu/R/Rhelp02a/archive/73494.html' and other
>> similar posts.  In particular, I see that the 'edit' method is described
>> there, but I didn't understand what it said until I already knew how to
>> use it.  Also, 'edit' doesn't work for me under ESS / Emacs.  For that,
>> I use Stangle (as Sundar Dorai-Raj taught me).
>>
>>          Thanks,
>>          Spencer Graves
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>


From spencer.graves at pdf.com  Sun May 21 19:26:19 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 21 May 2006 10:26:19 -0700
Subject: [Rd] Suggesting changes to HELP files?
In-Reply-To: <44709F6D.2000002@stats.uwo.ca>
References: <44708B0A.1050409@pdf.com> <44709F6D.2000002@stats.uwo.ca>
Message-ID: <4470A2BB.2000902@pdf.com>

Hi, Duncan:  Thanks very much.  This helps.  Best Wishes, Spencer Graves

Duncan Murdoch wrote:
> On 5/21/2006 11:45 AM, Spencer Graves wrote:
>>       Is there a procedure for suggesting changes to HELP files of the 
>> core R distribution?  If yes, what is it?  If it would be considered a 
>> friendly gesture, I could find the relevant *.Rd file and submit a 
>> suggested modification to it someplace.  Alternatively, I could just 
>> send suggestions someplace if they would receive appropriate 
>> consideration.
> 
> I don't think there's a formal procedure.  Generally the idea is to find 
> an R Core member (i.e. someone who can commit changes) who thinks your 
> changes are a good idea, and then they'll commit them.  How you do that 
> convincing depends on who you're talking to.  For your examples below:
> 
>>       On many occasions, I think of modifications, e.g., additional 
>> examples, that could be added to 'help' pages that I believe would 
>> make it easier for people to understand how to use some R feature.  
>> Instead, I often provide the same answer multiple times to different 
>> posts.
>>
>>       I can think of two changes off the top of my head that I'd like 
>> to see:  First, many if not all of the helps page in the nlme and lme4 
>> packages should, I believe, include a reference Pinheiro and Bates. 
>> This is not the place for modesty on the part of Pinheiro, Bates, and 
>> co-workers.  I believe that many requests for help might be eliminated 
>> if such references were added.  Failing that, it would be easier for 
>> people like me to suggest someone read that book, because I wouldn't 
>> feel such a need to spell out the entire citation every time.
> 
> nlme and lme4 are both contributed packages, so you want to talk to the 
> maintainers about changes to them.  nlme is distributed with binary 
> builds, but isn't strictly speaking part of the "core R distribution".
> Only packages labelled as "Priority: base" in the DESCRIPTION file are 
> part of the core distribution.
> 
>>       Second, I think the description of 'vignette' could be enhanced 
>> to include some version of my 'p.s.' to 
>> 'http://finzi.psych.upenn.edu/R/Rhelp02a/archive/73494.html' and other 
>> similar posts.  In particular, I see that the 'edit' method is 
>> described there, but I didn't understand what it said until I already 
>> knew how to use it.  
> 
> For something like this, it's probably best to draft some text, and post 
> it to R-devel.  You could also look at the Subversion history of the 
> appropriate file (src/library/utils/man/vignette.Rd) to see who has been 
> active with changes to it recently; they might be more interested in 
> making changes to it than others.  In this case, the log is
> 
> Revision: 33828
> Author: leisch
> Date: 2:37:14 AM, Tuesday, April 05, 2005
> Message:
> example where the vignette name is not the package name
> 
> 
> Revision: 32054
> Author: leisch
> Date: 9:52:24 AM, Friday, November 26, 2004
> Message:
> new print and edit methods for vignette objects
> 
> 
> Revision: 27442
> Author: ripley
> Date: 2:24:25 AM, Tuesday, December 09, 2003
> Message:
> split from base
> 
> so Fritz Leisch might be interested, but the last change is more than a 
> year ago, so it might not be at the top of his mind.
> 
> The latter observation is the main reason suggested changes might not 
> make it into the source:  you need to get someone's attention, and 
> they'll need to devote some time to dealing with your suggestion.  It 
> needs to be clear that the change is an improvement.  Things like minor 
> typos are easy, but something like the suggestion above would need to be 
> evaluated by someone familiar with what vignette() does, and what it is 
> intended to do.  So you need to make it as easy as possible to evaluate 
> and incorporate your change, and sometimes it still won't get in, 
> because the only people to do it are working on other things.
> 
> You should also be prepared to hear criticism of your suggestion, and be 
> able to defend it or change it.  Don't be offended if someone rewrites 
> your change, or if they ask you to rewrite it.
> 
>  > Also, 'edit' doesn't work for me under ESS / Emacs.  For that,
>> I use Stangle (as Sundar Dorai-Raj taught me).
> 
> That sounds like an ESS or Emacs bug, and should be reported to the 
> maintainers of one of those.
> 
> Duncan Murdoch


From ggrothendieck at gmail.com  Sun May 21 19:33:41 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 21 May 2006 13:33:41 -0400
Subject: [Rd] print.trellis(..., draw.in=...)
In-Reply-To: <eb555e660605211019s31fac589hb4107dd88c6f69c6@mail.gmail.com>
References: <971536df0605210441s5833a4cdr8286fdd23f560b7c@mail.gmail.com>
	<eb555e660605211019s31fac589hb4107dd88c6f69c6@mail.gmail.com>
Message-ID: <971536df0605211033j7a57be5eo78d029d0ac489846@mail.gmail.com>

Thanks.  I should have realized that.  Now that I read it again with
your explanation it is clear.

At the same time it would be convenient if one could specify a viewport
or vpPath, as well.  If that were the case we could also eliminate the
names.* methods in this example. (These were included to encapsulate
access to them so that the main code does not muck around in the
internals.)

At any rate, for the record, here is the code again corrected:

library(grid)
library(lattice)

pushLayout <- function(nr, nc, name="layout") {
 pushViewport(viewport(layout=grid.layout(nr, nc), name=name))
 for (i in 1:nr) {
   for (j in 1:nc) {
     pushViewport(viewport(layout.pos.row=i, layout.pos.col=j))
     upViewport()
   }
 }
 upViewport()
}

names.vpPath <- names.viewport <- function(x) x$name

getChildren.viewport <- function(x) x$children

grid.newpage()

# specify number of cells to fill and number of rows
n <- 5; nr <- 3

nc <- ceiling(n/nr)
downViewport(pushLayout(nr, nc))

vpt <- current.vpTree(all = FALSE)
children <- getChildren.viewport(vpt)
for(k in 1:n)
     print( xyplot(v ~ v, list(v = 1:k)), newpage = FALSE,
               draw.in = names(children[[k]]) )


On 5/21/06, Deepayan Sarkar <deepayan.sarkar at gmail.com> wrote:
> On 5/21/06, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> > A year ago I had posted this code
> >
> > https://stat.ethz.ch/pipermail/r-devel/2005-June/033508.html
> >
> > and the associated discussion was that there would be a print.trellis
> > argument that could be used to eliminate the need for with.vpPath
> > or with.viewport there.  I assume that that is what draw.in= in
> > print.trellis is for.  When I try it I get an error.  I did notice that
> > ?print.trellis says draw.in= has not been well tested yet.  Is
> > this a bug?
>
> No, but perhaps a lack of clarity in the documentation. ?print.trellis says:
>
>  draw.in: An optional (grid) viewport (used as the 'name' argument in
>          'downViewport') in which the plot is to be drawn.  ...
>
> and ?downViewport says
>
>    name: A character value to identify a viewport in the tree.
>
> Your code supplies viewports, not character names (in the older
> working example, you did this conversion inside with.vpPath).
>
> -Deepayan
>
> > After running the the code at the end I get this error
> > message:
> >
> >  Error in downViewport.vpPath(vpPathDirect(name), strict, recording =
> > recording) :
> >         Viewport 'viewport[GRID.VP.1]' was not found
> >
> > The only difference between the code below and the code in the
> > link above (which works) is that in the for loop at the end the
> > 'with' in the code in the link has been removed and draw.in=
> > used in the print call in its place.
> >
> > I am using Windows XP and get similar messages in 2.2.1 and
> > 2.3.0 patched.
> >
> >
> > library(grid)
> > library(lattice)
> >
> > pushLayout <- function(nr, nc, name="layout") {
> >   pushViewport(viewport(layout=grid.layout(nr, nc), name=name))
> >   for (i in 1:nr) {
> >     for (j in 1:nc) {
> >       pushViewport(viewport(layout.pos.row=i, layout.pos.col=j))
> >       upViewport()
> >     }
> >   }
> >   upViewport()
> > }
> >
> > names.vpPath <- names.viewport <- function(x) x$name
> >
> > with.vpPath <- with.viewport <- function(data, expr, ...) {
> >       # if data is a vpPath it cannot be ROOT since
> >       # NULL will never dispatch here
> >       depth <- if (data$name == "ROOT") 0 else downViewport(names(data))
> >       result <- eval.parent(substitute(expr))
> >       upViewport(depth)
> >       invisible(result)
> > }
> >
> > getChildren.viewport <- function(x) x$children
> >
> > grid.newpage()
> >
> > # specify number of cells to fill and number of rows
> > n <- 5; nr <- 3
> >
> > nc <- ceiling(n/nr)
> > downViewport(pushLayout(nr, nc))
> >
> > vpt <- current.vpTree(all = FALSE)
> > for(k in 1:n)
> >       print( xyplot(v ~ v, list(v = 1:k)), newpage = FALSE,
> >                 draw.in = getChildren.viewport(vpt)[[k]] )
>


From deepayan.sarkar at gmail.com  Sun May 21 19:48:20 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Sun, 21 May 2006 12:48:20 -0500
Subject: [Rd] print.trellis(..., draw.in=...)
In-Reply-To: <971536df0605211033j7a57be5eo78d029d0ac489846@mail.gmail.com>
References: <971536df0605210441s5833a4cdr8286fdd23f560b7c@mail.gmail.com>
	<eb555e660605211019s31fac589hb4107dd88c6f69c6@mail.gmail.com>
	<971536df0605211033j7a57be5eo78d029d0ac489846@mail.gmail.com>
Message-ID: <eb555e660605211048g6b2a260p763947d77a8cb308@mail.gmail.com>

On 5/21/06, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> Thanks.  I should have realized that.  Now that I read it again with
> your explanation it is clear.
>
> At the same time it would be convenient if one could specify a viewport
> or vpPath, as well.  If that were the case we could also eliminate the
> names.* methods in this example. (These were included to encapsulate
> access to them so that the main code does not muck around in the
> internals.)

Probably true, but that's a change that belongs in grid. I don't want
to make unnecessary assumptions about grid functions and then be
caught by an API change (which is one of the reasons I don't want to
be explicit in ?print.trellis about what the 'draw.in' argument must
be).

Deepayan


From ggrothendieck at gmail.com  Sun May 21 19:49:54 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 21 May 2006 13:49:54 -0400
Subject: [Rd] Suggesting changes to HELP files?
In-Reply-To: <4470A206.1070703@pdf.com>
References: <44708B0A.1050409@pdf.com>
	<971536df0605210902u3810b9a4nf4f7c4d967e98e5@mail.gmail.com>
	<4470A206.1070703@pdf.com>
Message-ID: <971536df0605211049l557b8d52tb8c18c1198947f93@mail.gmail.com>

On 5/21/06, Spencer Graves <spencer.graves at pdf.com> wrote:
> Hi, Gabor:
>
>          Thanks.  My initial failed attempt to add to "R wiki" generated the
> following two questions:
>
>          1.  What's the best way to find the R Wiki from "www.r-project.org"?
>  I found it just now via RSiteSearch("R wiki").  Might it be reasonable
> to add, e.g., a hot link to "R Wiki" under "Documentation"?

wiki.r-project.org will get you to it.  Hopefully there will be a link
from the R home page at some point.


>
>          2.  I just found a page that reads, 'R Wiki - Documentation
> The "Wikified" version of all R man pages. To access a given page, type
> the name of an R function in the search box at top right and click
> "search". Select the corresponding page in the search result.
>
> Alternatively, you can click the name of a function in an R code chunk
> anywhere.'  (http://wiki.r-project.org/rwiki/doku.php?id=rdoc:rdoc)
>
>          I tried searching for 'vignette' but failed to get anything useful.
> What am I missing?

There is a search box in the upper right on the wiki if you want to search
or you can browse through the table of contents to find an appropriate
spot to add info.

>
>          Thanks again,
>          Spencer Graves
>
> Gabor Grothendieck wrote:
> > You could consider adding something to the wiki while you are
> > waiting.
> >
> > On 5/21/06, Spencer Graves <spencer.graves at pdf.com> wrote:
> >>          Is there a procedure for suggesting changes to HELP files of
> >> the core
> >> R distribution?  If yes, what is it?  If it would be considered a
> >> friendly gesture, I could find the relevant *.Rd file and submit a
> >> suggested modification to it someplace.  Alternatively, I could just
> >> send suggestions someplace if they would receive appropriate
> >> consideration.
> >>
> >>          On many occasions, I think of modifications, e.g., additional
> >> examples, that could be added to 'help' pages that I believe would make
> >> it easier for people to understand how to use some R feature.  Instead,
> >> I often provide the same answer multiple times to different posts.
> >>
> >>          I can think of two changes off the top of my head that I'd
> >> like to
> >> see:  First, many if not all of the helps page in the nlme and lme4
> >> packages should, I believe, include a reference Pinheiro and Bates.
> >> This is not the place for modesty on the part of Pinheiro, Bates, and
> >> co-workers.  I believe that many requests for help might be eliminated
> >> if such references were added.  Failing that, it would be easier for
> >> people like me to suggest someone read that book, because I wouldn't
> >> feel such a need to spell out the entire citation every time.
> >>
> >>          Second, I think the description of 'vignette' could be
> >> enhanced to
> >> include some version of my 'p.s.' to
> >> 'http://finzi.psych.upenn.edu/R/Rhelp02a/archive/73494.html' and other
> >> similar posts.  In particular, I see that the 'edit' method is described
> >> there, but I didn't understand what it said until I already knew how to
> >> use it.  Also, 'edit' doesn't work for me under ESS / Emacs.  For that,
> >> I use Stangle (as Sundar Dorai-Raj taught me).
> >>
> >>          Thanks,
> >>          Spencer Graves
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
>


From ggrothendieck at gmail.com  Sun May 21 20:02:49 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 21 May 2006 14:02:49 -0400
Subject: [Rd] print.trellis(..., draw.in=...)
In-Reply-To: <eb555e660605211048g6b2a260p763947d77a8cb308@mail.gmail.com>
References: <971536df0605210441s5833a4cdr8286fdd23f560b7c@mail.gmail.com>
	<eb555e660605211019s31fac589hb4107dd88c6f69c6@mail.gmail.com>
	<971536df0605211033j7a57be5eo78d029d0ac489846@mail.gmail.com>
	<eb555e660605211048g6b2a260p763947d77a8cb308@mail.gmail.com>
Message-ID: <971536df0605211102w8523b5du47cdc65cd2f856f0@mail.gmail.com>

On 5/21/06, Deepayan Sarkar <deepayan.sarkar at gmail.com> wrote:
> On 5/21/06, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> > Thanks.  I should have realized that.  Now that I read it again with
> > your explanation it is clear.
> >
> > At the same time it would be convenient if one could specify a viewport
> > or vpPath, as well.  If that were the case we could also eliminate the
> > names.* methods in this example. (These were included to encapsulate
> > access to them so that the main code does not muck around in the
> > internals.)
>
> Probably true, but that's a change that belongs in grid. I don't want
> to make unnecessary assumptions about grid functions and then be
> caught by an API change (which is one of the reasons I don't want to
> be explicit in ?print.trellis about what the 'draw.in' argument must
> be).
>
> Deepayan
>

I agree.  Maybe Paul will consider adding something to facilitate
using a name, viewport or vpPath interchangeably so the user
does not have to concern himself with such details.  This seems
like a good application of OO.


From francoisromain at free.fr  Sun May 21 20:14:43 2006
From: francoisromain at free.fr (Romain Francois)
Date: Sun, 21 May 2006 20:14:43 +0200
Subject: [Rd] Suggesting changes to HELP files?
In-Reply-To: <4470A206.1070703@pdf.com>
References: <44708B0A.1050409@pdf.com>	<971536df0605210902u3810b9a4nf4f7c4d967e98e5@mail.gmail.com>
	<4470A206.1070703@pdf.com>
Message-ID: <4470AE13.6050707@free.fr>

Hello Spencer,

Le 21.05.2006 19:23, Spencer Graves a ?crit :
> Hi, Gabor:
>
> 	  Thanks.  My initial failed attempt to add to "R wiki" generated the 
> following two questions:
>
> 	  1.  What's the best way to find the R Wiki from "www.r-project.org"? 
>   I found it just now via RSiteSearch("R wiki").  Might it be reasonable 
> to add, e.g., a hot link to "R Wiki" under "Documentation"?
>   

The wiki is still a young project, so philippe does not want that kind 
of link yet, not before everything is set up allright, including for 
example the conversion of help pages in a wiki format that will be (in 
some way) editable to propose changes / new examples to package 
maintainers.

> 	  2.  I just found a page that reads, 'R Wiki - Documentation
> The ?Wikified? version of all R man pages. To access a given page, type 
> the name of an R function in the search box at top right and click 
> ?search?. Select the corresponding page in the search result.
>
> Alternatively, you can click the name of a function in an R code chunk 
> anywhere.'  (http://wiki.r-project.org/rwiki/doku.php?id=rdoc:rdoc)
>
> 	  I tried searching for 'vignette' but failed to get anything useful. 
> What am I missing?
>   

That page comes from the future, when the help pages will be there, that 
will work. But maybe something wiser could be done, to search *only* on 
the help pages. You are not missing anything, you just came too early. 
Of course, you can already add material into the wiki, but the user 
level is not really ready I think.
Also, there is a special interest list about the wiki where you can find 
more answers to your questions.
https://stat.ethz.ch/mailman/listinfo/r-sig-wiki

Regards,

Romain


> 	  Thanks again,
> 	  Spencer Graves
>
> Gabor Grothendieck wrote:
>   
>> You could consider adding something to the wiki while you are
>> waiting.
>>
>> On 5/21/06, Spencer Graves <spencer.graves at pdf.com> wrote:
>>     
>>>          Is there a procedure for suggesting changes to HELP files of 
>>> the core
>>> R distribution?  If yes, what is it?  If it would be considered a
>>> friendly gesture, I could find the relevant *.Rd file and submit a
>>> suggested modification to it someplace.  Alternatively, I could just
>>> send suggestions someplace if they would receive appropriate
>>> consideration.
>>>
>>>          On many occasions, I think of modifications, e.g., additional
>>> examples, that could be added to 'help' pages that I believe would make
>>> it easier for people to understand how to use some R feature.  Instead,
>>> I often provide the same answer multiple times to different posts.
>>>
>>>          I can think of two changes off the top of my head that I'd 
>>> like to
>>> see:  First, many if not all of the helps page in the nlme and lme4
>>> packages should, I believe, include a reference Pinheiro and Bates.
>>> This is not the place for modesty on the part of Pinheiro, Bates, and
>>> co-workers.  I believe that many requests for help might be eliminated
>>> if such references were added.  Failing that, it would be easier for
>>> people like me to suggest someone read that book, because I wouldn't
>>> feel such a need to spell out the entire citation every time.
>>>
>>>          Second, I think the description of 'vignette' could be 
>>> enhanced to
>>> include some version of my 'p.s.' to
>>> 'http://finzi.psych.upenn.edu/R/Rhelp02a/archive/73494.html' and other
>>> similar posts.  In particular, I see that the 'edit' method is described
>>> there, but I didn't understand what it said until I already knew how to
>>> use it.  Also, 'edit' doesn't work for me under ESS / Emacs.  For that,
>>> I use Stangle (as Sundar Dorai-Raj taught me).
>>>
>>>          Thanks,
>>>          Spencer Graves
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>       
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>   


-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
mixmod 1.7 is released : http://www-math.univ-fcomte.fr/mixmod/index.php
+---------------------------------------------------------------+
| Romain FRANCOIS - http://francoisromain.free.fr               |
| Doctorant INRIA Futurs / EDF                                  |
+---------------------------------------------------------------+


From ggrothendieck at gmail.com  Sun May 21 20:20:11 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 21 May 2006 14:20:11 -0400
Subject: [Rd] print.trellis(..., draw.in=...)
In-Reply-To: <971536df0605211102w8523b5du47cdc65cd2f856f0@mail.gmail.com>
References: <971536df0605210441s5833a4cdr8286fdd23f560b7c@mail.gmail.com>
	<eb555e660605211019s31fac589hb4107dd88c6f69c6@mail.gmail.com>
	<971536df0605211033j7a57be5eo78d029d0ac489846@mail.gmail.com>
	<eb555e660605211048g6b2a260p763947d77a8cb308@mail.gmail.com>
	<971536df0605211102w8523b5du47cdc65cd2f856f0@mail.gmail.com>
Message-ID: <971536df0605211120v7749c1b0n28545b89a99fd073@mail.gmail.com>

And while we are at it it would be nice to be able to get rid of
getChildren.viewport in this example too.  Its only purpose
was to encapsulate access to the internals but if there were
an official way to do it it would be preferable.

On 5/21/06, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> On 5/21/06, Deepayan Sarkar <deepayan.sarkar at gmail.com> wrote:
> > On 5/21/06, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> > > Thanks.  I should have realized that.  Now that I read it again with
> > > your explanation it is clear.
> > >
> > > At the same time it would be convenient if one could specify a viewport
> > > or vpPath, as well.  If that were the case we could also eliminate the
> > > names.* methods in this example. (These were included to encapsulate
> > > access to them so that the main code does not muck around in the
> > > internals.)
> >
> > Probably true, but that's a change that belongs in grid. I don't want
> > to make unnecessary assumptions about grid functions and then be
> > caught by an API change (which is one of the reasons I don't want to
> > be explicit in ?print.trellis about what the 'draw.in' argument must
> > be).
> >
> > Deepayan
> >
>
> I agree.  Maybe Paul will consider adding something to facilitate
> using a name, viewport or vpPath interchangeably so the user
> does not have to concern himself with such details.  This seems
> like a good application of OO.
>


From spencer.graves at pdf.com  Sun May 21 20:25:30 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 21 May 2006 11:25:30 -0700
Subject: [Rd] Suggesting changes to HELP files?
In-Reply-To: <971536df0605211049l557b8d52tb8c18c1198947f93@mail.gmail.com>
References: <44708B0A.1050409@pdf.com>	
	<971536df0605210902u3810b9a4nf4f7c4d967e98e5@mail.gmail.com>	
	<4470A206.1070703@pdf.com>
	<971536df0605211049l557b8d52tb8c18c1198947f93@mail.gmail.com>
Message-ID: <4470B09A.7040803@pdf.com>

Hi, Gabor:

<see inline>

Gabor Grothendieck wrote:
> On 5/21/06, Spencer Graves <spencer.graves at pdf.com> wrote:
>> Hi, Gabor:
>>
>>          Thanks.  My initial failed attempt to add to "R wiki" 
>> generated the
>> following two questions:
>>
>>          1.  What's the best way to find the R Wiki from 
>> "www.r-project.org"?
>>  I found it just now via RSiteSearch("R wiki").  Might it be reasonable
>> to add, e.g., a hot link to "R Wiki" under "Documentation"?
> 
> wiki.r-project.org will get you to it.  Hopefully there will be a link
> from the R home page at some point.
> 
> 
>>
>>          2.  I just found a page that reads, 'R Wiki - Documentation
>> The "Wikified" version of all R man pages. To access a given page, type
>> the name of an R function in the search box at top right and click
>> "search". Select the corresponding page in the search result.
>>
>> Alternatively, you can click the name of a function in an R code chunk
>> anywhere.'  (http://wiki.r-project.org/rwiki/doku.php?id=rdoc:rdoc)
>>
>>          I tried searching for 'vignette' but failed to get anything 
>> useful.
>> What am I missing?
> 
> There is a search box in the upper right on the wiki if you want to search
> or you can browse through the table of contents to find an appropriate
> spot to add info.
> 
SG:  I got the following from searching for 'vignette' using the box in 
the upper right:

Search

You can find the results of your search below. If you didn?t find what 
you were looking for, you can create or edit the page named after your 
query with the appropriate button.
Results
...
guides:stats-with-r:01intro-to-r: 1 Hits
...ProbForecastGOP/doc/vignette.pdf...

SG:  Clicking on "vignette" did nothing that I could see.  Clicking on 
"guides:..." sent me some place, but searching for "vignette" led me 
nowhere.

	  Someplace I thought I saw mention of "wikified" version(s) of all the 
help files.  Is that there, and I just don't know how to find it?  If 
not, is someone working on some auto-transfer protocol that would 
produce an initial version of such?  If yes, I wonder if I should wait 
until that's completed.  If no, then if I'm going to contribute to this 
'wiki', I need to better understand how it works.

           Thanks again,
           Spencer Graves
>>
>> Gabor Grothendieck wrote:
>> > You could consider adding something to the wiki while you are
>> > waiting.
>> >
>> > On 5/21/06, Spencer Graves <spencer.graves at pdf.com> wrote:
>> >>          Is there a procedure for suggesting changes to HELP files of
>> >> the core
>> >> R distribution?  If yes, what is it?  If it would be considered a
>> >> friendly gesture, I could find the relevant *.Rd file and submit a
>> >> suggested modification to it someplace.  Alternatively, I could just
>> >> send suggestions someplace if they would receive appropriate
>> >> consideration.
>> >>
>> >>          On many occasions, I think of modifications, e.g., additional
>> >> examples, that could be added to 'help' pages that I believe would 
>> make
>> >> it easier for people to understand how to use some R feature.  
>> Instead,
>> >> I often provide the same answer multiple times to different posts.
>> >>
>> >>          I can think of two changes off the top of my head that I'd
>> >> like to
>> >> see:  First, many if not all of the helps page in the nlme and lme4
>> >> packages should, I believe, include a reference Pinheiro and Bates.
>> >> This is not the place for modesty on the part of Pinheiro, Bates, and
>> >> co-workers.  I believe that many requests for help might be eliminated
>> >> if such references were added.  Failing that, it would be easier for
>> >> people like me to suggest someone read that book, because I wouldn't
>> >> feel such a need to spell out the entire citation every time.
>> >>
>> >>          Second, I think the description of 'vignette' could be
>> >> enhanced to
>> >> include some version of my 'p.s.' to
>> >> 'http://finzi.psych.upenn.edu/R/Rhelp02a/archive/73494.html' and other
>> >> similar posts.  In particular, I see that the 'edit' method is 
>> described
>> >> there, but I didn't understand what it said until I already knew 
>> how to
>> >> use it.  Also, 'edit' doesn't work for me under ESS / Emacs.  For 
>> that,
>> >> I use Stangle (as Sundar Dorai-Raj taught me).
>> >>
>> >>          Thanks,
>> >>          Spencer Graves
>> >>
>> >> ______________________________________________
>> >> R-devel at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >>
>>
>


From ggrothendieck at gmail.com  Sun May 21 20:41:46 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 21 May 2006 14:41:46 -0400
Subject: [Rd] Suggesting changes to HELP files?
In-Reply-To: <4470B09A.7040803@pdf.com>
References: <44708B0A.1050409@pdf.com>
	<971536df0605210902u3810b9a4nf4f7c4d967e98e5@mail.gmail.com>
	<4470A206.1070703@pdf.com>
	<971536df0605211049l557b8d52tb8c18c1198947f93@mail.gmail.com>
	<4470B09A.7040803@pdf.com>
Message-ID: <971536df0605211141x62c92648hb63a4a84cf85ef49@mail.gmail.com>

I think there is or was some work on wikied help pages but
I don't think that it exists yet.  When I was referring to the wiki
I just meant that that was somewhere where you can post
material.

On 5/21/06, Spencer Graves <spencer.graves at pdf.com> wrote:
> Hi, Gabor:
>
> <see inline>
>
> Gabor Grothendieck wrote:
> > On 5/21/06, Spencer Graves <spencer.graves at pdf.com> wrote:
> >> Hi, Gabor:
> >>
> >>          Thanks.  My initial failed attempt to add to "R wiki"
> >> generated the
> >> following two questions:
> >>
> >>          1.  What's the best way to find the R Wiki from
> >> "www.r-project.org"?
> >>  I found it just now via RSiteSearch("R wiki").  Might it be reasonable
> >> to add, e.g., a hot link to "R Wiki" under "Documentation"?
> >
> > wiki.r-project.org will get you to it.  Hopefully there will be a link
> > from the R home page at some point.
> >
> >
> >>
> >>          2.  I just found a page that reads, 'R Wiki - Documentation
> >> The "Wikified" version of all R man pages. To access a given page, type
> >> the name of an R function in the search box at top right and click
> >> "search". Select the corresponding page in the search result.
> >>
> >> Alternatively, you can click the name of a function in an R code chunk
> >> anywhere.'  (http://wiki.r-project.org/rwiki/doku.php?id=rdoc:rdoc)
> >>
> >>          I tried searching for 'vignette' but failed to get anything
> >> useful.
> >> What am I missing?
> >
> > There is a search box in the upper right on the wiki if you want to search
> > or you can browse through the table of contents to find an appropriate
> > spot to add info.
> >
> SG:  I got the following from searching for 'vignette' using the box in
> the upper right:
>
> Search
>
> You can find the results of your search below. If you didn't find what
> you were looking for, you can create or edit the page named after your
> query with the appropriate button.
> Results
> ...
> guides:stats-with-r:01intro-to-r: 1 Hits
> ...ProbForecastGOP/doc/vignette.pdf...
>
> SG:  Clicking on "vignette" did nothing that I could see.  Clicking on
> "guides:..." sent me some place, but searching for "vignette" led me
> nowhere.
>
>          Someplace I thought I saw mention of "wikified" version(s) of all the
> help files.  Is that there, and I just don't know how to find it?  If
> not, is someone working on some auto-transfer protocol that would
> produce an initial version of such?  If yes, I wonder if I should wait
> until that's completed.  If no, then if I'm going to contribute to this
> 'wiki', I need to better understand how it works.
>
>           Thanks again,
>           Spencer Graves
> >>
> >> Gabor Grothendieck wrote:
> >> > You could consider adding something to the wiki while you are
> >> > waiting.
> >> >
> >> > On 5/21/06, Spencer Graves <spencer.graves at pdf.com> wrote:
> >> >>          Is there a procedure for suggesting changes to HELP files of
> >> >> the core
> >> >> R distribution?  If yes, what is it?  If it would be considered a
> >> >> friendly gesture, I could find the relevant *.Rd file and submit a
> >> >> suggested modification to it someplace.  Alternatively, I could just
> >> >> send suggestions someplace if they would receive appropriate
> >> >> consideration.
> >> >>
> >> >>          On many occasions, I think of modifications, e.g., additional
> >> >> examples, that could be added to 'help' pages that I believe would
> >> make
> >> >> it easier for people to understand how to use some R feature.
> >> Instead,
> >> >> I often provide the same answer multiple times to different posts.
> >> >>
> >> >>          I can think of two changes off the top of my head that I'd
> >> >> like to
> >> >> see:  First, many if not all of the helps page in the nlme and lme4
> >> >> packages should, I believe, include a reference Pinheiro and Bates.
> >> >> This is not the place for modesty on the part of Pinheiro, Bates, and
> >> >> co-workers.  I believe that many requests for help might be eliminated
> >> >> if such references were added.  Failing that, it would be easier for
> >> >> people like me to suggest someone read that book, because I wouldn't
> >> >> feel such a need to spell out the entire citation every time.
> >> >>
> >> >>          Second, I think the description of 'vignette' could be
> >> >> enhanced to
> >> >> include some version of my 'p.s.' to
> >> >> 'http://finzi.psych.upenn.edu/R/Rhelp02a/archive/73494.html' and other
> >> >> similar posts.  In particular, I see that the 'edit' method is
> >> described
> >> >> there, but I didn't understand what it said until I already knew
> >> how to
> >> >> use it.  Also, 'edit' doesn't work for me under ESS / Emacs.  For
> >> that,
> >> >> I use Stangle (as Sundar Dorai-Raj taught me).
> >> >>
> >> >>          Thanks,
> >> >>          Spencer Graves
> >> >>
> >> >> ______________________________________________
> >> >> R-devel at r-project.org mailing list
> >> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >> >>
> >>
> >
>


From francoisromain at free.fr  Sun May 21 20:51:58 2006
From: francoisromain at free.fr (Romain Francois)
Date: Sun, 21 May 2006 20:51:58 +0200
Subject: [Rd] Suggesting changes to HELP files?
In-Reply-To: <971536df0605211141x62c92648hb63a4a84cf85ef49@mail.gmail.com>
References: <44708B0A.1050409@pdf.com>	<971536df0605210902u3810b9a4nf4f7c4d967e98e5@mail.gmail.com>	<4470A206.1070703@pdf.com>	<971536df0605211049l557b8d52tb8c18c1198947f93@mail.gmail.com>	<4470B09A.7040803@pdf.com>
	<971536df0605211141x62c92648hb63a4a84cf85ef49@mail.gmail.com>
Message-ID: <4470B6CE.6040309@free.fr>

Le 21.05.2006 20:41, Gabor Grothendieck a ?crit :
> I think there is or was some work on wikied help pages but
> I don't think that it exists yet.  When I was referring to the wiki
> I just meant that that was somewhere where you can post
> material.
>   
Hi,

Can we move that discussion to : 
https://stat.ethz.ch/mailman/listinfo/r-sig-wiki
Philippe Grosjean is currently working on Rdconv script to convert Rd 
files into wiki, see :
https://stat.ethz.ch/pipermail/r-sig-wiki/2006-May/000261.html

Romain

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
mixmod 1.7 is released : http://www-math.univ-fcomte.fr/mixmod/index.php
+---------------------------------------------------------------+
| Romain FRANCOIS - http://francoisromain.free.fr               |
| Doctorant INRIA Futurs / EDF                                  |
+---------------------------------------------------------------+


From murdoch at stats.uwo.ca  Sun May 21 23:00:26 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 21 May 2006 17:00:26 -0400
Subject: [Rd] delayedAssign and interrupts
In-Reply-To: <446DDC4C.7040209@stats.uwo.ca>
References: <446DCE07.2080504@gmail.com>
	<446DD2F8.5060900@stats.uwo.ca>	<Pine.LNX.4.64.0605190920520.9980@nokomis.stat.uiowa.edu>
	<446DDC4C.7040209@stats.uwo.ca>
Message-ID: <4470D4EA.1000109@stats.uwo.ca>

On 5/19/2006 10:55 AM, Duncan Murdoch wrote:
> On 5/19/2006 10:37 AM, Luke Tierney wrote:
>> On Fri, 19 May 2006, Duncan Murdoch wrote:
>>
>>> On 5/19/2006 9:54 AM, Roger D. Peng wrote:
>>>> I noticed something recently that I thought was odd:
>>>>
>>>> delayedAssign("x", { Sys.sleep(5); 1 })
>>>> x  ## Hit Ctrl-C within the first second or 2
>>>>
>>>> gives me:
>>>>
>>>>> delayedAssign("x", { Sys.sleep(5); 1 })
>>>>> x  ## Hit Ctrl-C within the first second or two
>>>>> x
>>>> Error: recursive default argument reference
>>>> My only problem here is that now I'm stuck---there's no way to recover whatever
>>>> 'x' was supposed to be (i.e. 1).
>>>>
>>>> In reality, I want 'x' to be a promise to load a moderately large data object.
>>>> But if I (or a user) Ctrl-C's during the load I'll have to start from scratch.
>>>> Is there anyway to recover the promise (or the value of the expression) in case
>>>> of an interrupt?
>>> I don't know of one.  Normally substitute(x) is supposed to retrieve the
>>>  promise expression, but by a strange quirk of history, it does not
>>> work when x is in .GlobalEnv.
>>>
>>> I'd say the behaviour you're seeing is a bug.  If I do
>>>
>>>> x <- 2
>>>> x <- {Sys.sleep(1); 1}  # Break before complete
>>>> x
>>> [1] 2
>>>
>>> nothing is changed about x.  I would think the same thing should happen
>>> when x is a promise:  if the evaluation of the promised expression
>>> fails, the promise should not be changed.
>> I don't think this is a clear as you make it out--given that these
>> uses of promises often have side effects, and some of those side
>> effects may have occurred prior to an error, it isn't clear that
>> pretending like no evaluation had happened is the right way to go.
> 
> Right, but the user would have seen the error, and can decide how to 
> recover from it.  If trying to evaluate x again is the wrong thing to 
> do, the user is the one who would know that.
> 
>> It should not be too hard to write a delayedAssignmentReset function
>> if that is really useful; alternatively a user of delayedAssign should
>> be able to arrange via tryCatch to chatch interrupts and re-install
>> the delayed assignment if one occurs.
>>
>> It might not be a bad idea for us to look into the promise evaluation
>> internals and see if we should/can separate the promise black-holing
>> from detection of recursive default argument references to get more
>> reasonable error messages in these situations and maybe allow
>> resetting more gnerally.  But anything done here had better keep
>> efficiency in mind since this is prety core to R function call
>> evaluation.  I may try to look into this when I get back to workign on
>> R internals.
> 
> This is a very rare situation, so I agree putting in some slow way to 
> recover from an error is a bad idea.  I think we should do the following:
> 
>   - fix substitute so it could be used to extract the promise expression 
> even if x lives in .GlobalEnv.  (This can't happen for 2.3.1.)
> 
>   - add delayedAssignmentReset to repair x if that's preferred.  (Is 
> this a reasonable addition to a patch release?)
> 
> This won't leave promises alone in case of an error, but will make it 
> fairly easy for a user to recover using tryCatch.

I took a look at doing DelayedAssignmentReset, but haven't done it. It 
requires some tricky stuff (you can't evaluate the argument in the 
regular way, etc.)  It also needs some thought:  should you be able to 
reset a promise that isn't messed up in this way, so it evaluates its 
expression again?

So I don't plan to do anything for now.  If someone else wants to take 
it on, please do.

Duncan Murdoch


From edward.m at psu.ac.th  Mon May 22 09:05:40 2006
From: edward.m at psu.ac.th (edward.m at psu.ac.th)
Date: Mon, 22 May 2006 09:05:40 +0200 (CEST)
Subject: [Rd] Sys.setlocale upsets windows graphics device (PR#8887)
Message-ID: <20060522070540.8E4D419B27@slim.kubism.ku.dk>

Full_Name: Edward McNeil
Version: 2.3.0
OS: Widows XP
Submission from: (NULL) (203.170.234.5)


Type the following:

> Sys.setlocale("LC_ALL","C")
> hist(1:10)

CRASH


From maechler at stat.math.ethz.ch  Mon May 22 09:12:07 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 22 May 2006 09:12:07 +0200
Subject: [Rd] Suggesting changes to HELP files?
In-Reply-To: <971536df0605211049l557b8d52tb8c18c1198947f93@mail.gmail.com>
References: <44708B0A.1050409@pdf.com>
	<971536df0605210902u3810b9a4nf4f7c4d967e98e5@mail.gmail.com>
	<4470A206.1070703@pdf.com>
	<971536df0605211049l557b8d52tb8c18c1198947f93@mail.gmail.com>
Message-ID: <17521.25672.698.693401@stat.math.ethz.ch>

>>>>> "Gabor" == Gabor Grothendieck <ggrothendieck at gmail.com>
>>>>>     on Sun, 21 May 2006 13:49:54 -0400 writes:

    Gabor> On 5/21/06, Spencer Graves <spencer.graves at pdf.com> wrote:
    >> Hi, Gabor:
    >> 
    >> Thanks.  My initial failed attempt to add to "R wiki" generated the
    >> following two questions:
    >> 
    >> 1.  What's the best way to find the R Wiki from "www.r-project.org"?
    >> I found it just now via RSiteSearch("R wiki").  Might it be reasonable
    >> to add, e.g., a hot link to "R Wiki" under "Documentation"?

    Gabor> wiki.r-project.org will get you to it.  Hopefully there will be a link
    Gabor> from the R home page at some point.

The Wiki isn't advertized yet at all, for a good reason:
It is still in "setup state" -- a bit more for Wiki authors than
readers, and also has "holes" that should be filled (or marked)
before wiki "release".
Its principal maintainer is Philippe Grosjean.

Please use the R-SIG-Wiki mailing list for more on this,
or maybe start browsing its archives a bit :
https://stat.ethz.ch/pipermail/r-sig-wiki/

    >> 2.  I just found a page that reads, 'R Wiki - Documentation
    >> The "Wikified" version of all R man pages. To access a given page, type
    >> the name of an R function in the search box at top right and click
    >> "search". Select the corresponding page in the search result.

AFAIK, the  `` "Wikified" version of all R man pages ''
is the biggest project yet to be completed before "Wiki release"

Martin


From ripley at stats.ox.ac.uk  Mon May 22 09:32:42 2006
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Mon, 22 May 2006 09:32:42 +0200 (CEST)
Subject: [Rd] Sys.setlocale upsets windows graphics device (PR#8887)
Message-ID: <20060522073242.4E56DCC0C@slim.kubism.ku.dk>

Works perfectly for me.  There was a bug in 2.2.1, but it was fixed in
2.2.1 patched (see CHANGES).

What locale were you changing from?  (This might be a Windows problem 
specific to your locale.)

On Mon, 22 May 2006, edward.m at psu.ac.th wrote:

> Full_Name: Edward McNeil
> Version: 2.3.0
> OS: Widows XP
> Submission from: (NULL) (203.170.234.5)
>
>
> Type the following:
>
>> Sys.setlocale("LC_ALL","C")
>> hist(1:10)
>
> CRASH
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From edward.m at psu.ac.th  Mon May 22 09:44:39 2006
From: edward.m at psu.ac.th (edward.m at psu.ac.th)
Date: Mon, 22 May 2006 09:44:39 +0200 (CEST)
Subject: [Rd] Sys.setlocale upsets windows graphics device (PR#8887)
Message-ID: <20060522074439.345DACCDD@slim.kubism.ku.dk>

Hi,
We tried it on 3 separate windows XP computers using version 2.3.0.
The original locale is set for Thailand on all 3.
So how do we fix it? Is there another patch?
And why does the crash not happen with earlier R versions (eg. 2.2.1) on the 
same computer?

---
> Sys.getlocale()
[1] 
"LC_COLLATE=Thai_Thailand.874;LC_CTYPE=Thai_Thailand.874;LC_MONETARY=Thai_Thailand.874;LC_NUMERIC=C;LC_TIME=Thai_Thailand.874"
---

Thanks
Edward

----- Original Message ----- 
From: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
To: <edward.m at psu.ac.th>
Cc: <R-bugs at biostat.ku.dk>
Sent: Monday, May 22, 2006 2:32 PM
Subject: Re: [Rd] Sys.setlocale upsets windows graphics device (PR#8887)


> Works perfectly for me.  There was a bug in 2.2.1, but it was fixed in
> 2.2.1 patched (see CHANGES).
>
> What locale were you changing from?  (This might be a Windows problem 
> specific to your locale.)
>
> On Mon, 22 May 2006, edward.m at psu.ac.th wrote:
>
>> Full_Name: Edward McNeil
>> Version: 2.3.0
>> OS: Widows XP
>> Submission from: (NULL) (203.170.234.5)
>>
>>
>> Type the following:
>>
>>> Sys.setlocale("LC_ALL","C")
>>> hist(1:10)
>>
>> CRASH
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Mon May 22 10:01:31 2006
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Mon, 22 May 2006 10:01:31 +0200 (CEST)
Subject: [Rd] Sys.setlocale upsets windows graphics device (PR#8887)
Message-ID: <20060522080131.A0A2619A4F@slim.kubism.ku.dk>

On Mon, 22 May 2006, Edward wrote:

> Hi,
> We tried it on 3 separate windows XP computers using version 2.3.0.
> The original locale is set for Thailand on all 3.
> So how do we fix it? Is there another patch?

Don't try to do graphics in the C locale on your computer?

I suspect this is a font problem in Windows, in that your fonts may be 
specific to the Thai localization.  But without a means of reproducing 
this, I can only guess.

If you can set up a debugger (see the rw-FAQ), you may be able to give us
some additional clues as the where the crash is occuring.

> And why does the crash not happen with earlier R versions (eg. 2.2.1) on the 
> same computer?

Because of the issue mentioned in the CHANGES file, the change to the C 
locale was reverted by opening a graphics window.

>
> ---
>> Sys.getlocale()
> [1] 
> "LC_COLLATE=Thai_Thailand.874;LC_CTYPE=Thai_Thailand.874;LC_MONETARY=Thai_Thailand.874;LC_NUMERIC=C;LC_TIME=Thai_Thailand.874"
> ---
>
> Thanks
> Edward
>
> ----- Original Message ----- From: "Prof Brian Ripley" 
> <ripley at stats.ox.ac.uk>
> To: <edward.m at psu.ac.th>
> Cc: <R-bugs at biostat.ku.dk>
> Sent: Monday, May 22, 2006 2:32 PM
> Subject: Re: [Rd] Sys.setlocale upsets windows graphics device (PR#8887)
>
>
>> Works perfectly for me.  There was a bug in 2.2.1, but it was fixed in
>> 2.2.1 patched (see CHANGES).
>> 
>> What locale were you changing from?  (This might be a Windows problem 
>> specific to your locale.)
>> 
>> On Mon, 22 May 2006, edward.m at psu.ac.th wrote:
>> 
>>> Full_Name: Edward McNeil
>>> Version: 2.3.0
>>> OS: Widows XP
>>> Submission from: (NULL) (203.170.234.5)
>>> 
>>> 
>>> Type the following:
>>> 
>>>> Sys.setlocale("LC_ALL","C")
>>>> hist(1:10)
>>> 
>>> CRASH
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>> 
>> 
>> -- 
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595 
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Mon May 22 11:04:00 2006
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Mon, 22 May 2006 11:04:00 +0200 (CEST)
Subject: [Rd] Sys.setlocale upsets windows graphics device (PR#8887)
Message-ID: <20060522090400.37600494D6@slim.kubism.ku.dk>

I tried this by installing Thai on my laptop (WinXP) and rebooting into 
Thai, and it failed for me.  The crash is in mbstowcs in MSVCRT.dll,
and does not happen in any English locale I tried, only C.

So I am afraid it is a Windows (or VC++) bug specific to your locale, and 
the only workaround is to avoid the C locale.  (In any case, the C locale 
does not work properly on Windows, and seems equivalent in most respects 
to US English, with WinANSI encoding (rather than ASCII).)


On Mon, 22 May 2006, Prof Brian Ripley wrote:

> On Mon, 22 May 2006, Edward wrote:
>
>> Hi,
>> We tried it on 3 separate windows XP computers using version 2.3.0.
>> The original locale is set for Thailand on all 3.
>> So how do we fix it? Is there another patch?
>
> Don't try to do graphics in the C locale on your computer?
>
> I suspect this is a font problem in Windows, in that your fonts may be 
> specific to the Thai localization.  But without a means of reproducing this, 
> I can only guess.
>
> If you can set up a debugger (see the rw-FAQ), you may be able to give us
> some additional clues as the where the crash is occuring.
>
>> And why does the crash not happen with earlier R versions (eg. 2.2.1) on 
>> the same computer?
>
> Because of the issue mentioned in the CHANGES file, the change to the C 
> locale was reverted by opening a graphics window.
>
>> 
>> ---
>>> Sys.getlocale()
>> [1] 
>> "LC_COLLATE=Thai_Thailand.874;LC_CTYPE=Thai_Thailand.874;LC_MONETARY=Thai_Thailand.874;LC_NUMERIC=C;LC_TIME=Thai_Thailand.874"
>> ---
>> 
>> Thanks
>> Edward
>> 
>> ----- Original Message ----- From: "Prof Brian Ripley" 
>> <ripley at stats.ox.ac.uk>
>> To: <edward.m at psu.ac.th>
>> Cc: <R-bugs at biostat.ku.dk>
>> Sent: Monday, May 22, 2006 2:32 PM
>> Subject: Re: [Rd] Sys.setlocale upsets windows graphics device (PR#8887)
>> 
>> 
>>> Works perfectly for me.  There was a bug in 2.2.1, but it was fixed in
>>> 2.2.1 patched (see CHANGES).
>>> 
>>> What locale were you changing from?  (This might be a Windows problem 
>>> specific to your locale.)
>>> 
>>> On Mon, 22 May 2006, edward.m at psu.ac.th wrote:
>>> 
>>>> Full_Name: Edward McNeil
>>>> Version: 2.3.0
>>>> OS: Widows XP
>>>> Submission from: (NULL) (203.170.234.5)
>>>> 
>>>> 
>>>> Type the following:
>>>> 
>>>>> Sys.setlocale("LC_ALL","C")
>>>>> hist(1:10)
>>>> 
>>>> CRASH
>>>> 
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> 
>>>> 
>>> 
>>> -- 
>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>> University of Oxford,             Tel:  +44 1865 272861 (self)
>>> 1 South Parks Road,                     +44 1865 272866 (PA)
>>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595 
>> 
>> 
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From fhahne at gmx.de  Mon May 22 11:17:28 2006
From: fhahne at gmx.de (Florian Hahne)
Date: Mon, 22 May 2006 11:17:28 +0200
Subject: [Rd] rerender tcltk toplevel
Message-ID: <447181A8.2010902@gmx.de>

Hi everybody,
I am trying to write a simple progress display based on a tcltk
toplevel. My first approach was to use  the progressBar widget from the
BWidget library but since this is not available on every system (missing
on at least almost all windows systems, I guess...) I wanted to have a
backup there. So my second strategy was to use a simple toplevel with a
label and update the tclvariable assigned to it. This works nicely on
windows systems but on my linux box (Suse10) the label is not updated on
every round of iteration but rather once the iterator finishes.

tt <-tktoplevel()
tkwm.geometry(tt, "250x140")
prog <-  tclVar("0")
label <- tklabel(tt, textvariable=prog)
tkgrid(label)

for(i in 1:50) {
    tmp <- rnorm(1e+05)
    tclvalue(prog) <- i*2
}

When I combine both approaches and add the label to a toplevel that
already contains the progress bar updating the label works:

tt <-tktoplevel()
tkwm.geometry(tt, "250x140")
prog <-  tclVar("0")
label <- tklabel(tt, textvariable=prog)
progBar <- tkwidget(tt, "ProgressBar", variable=prog)
tclRequire("BWidget")
tkgrid(progBar)
tkgrid(label)

for(i in 1:50) {
    tmp <- rnorm(1e+05)
    tclvalue(prog) <- i*2
}

Is there a way to explicitly rerender a tcltk toplevel? There must be
one since the ProgressBar widget causes this to happen, or am I wrong?
Or is there another way I could make this work?
Hope someone can help me here,

Florian

PS:
sessionInfo()
Version 2.3.0 Under development (unstable) (2006-02-20 r37405)
x86_64-unknown-linux-gnu

attached base packages:
 [1] "grid"      "tools"     "tcltk"     "stats"     "graphics"  "grDevices"
 [7] "utils"     "datasets"  "methods"   "base"

other attached packages:
       prada RColorBrewer      Biobase
     "1.9.2"      "0.2-3"     "1.9.18"


-- 
Florian Hahne
Abt. Molekulare Genomanalyse (B050)
Deutsches Krebsforschungszentrum (DKFZ)
Im Neuenheimer Feld 580
D-69120 Heidelberg
phone: 0049 6221 424764
fax: 0049 6221 422399
web: www.dkfz.de/mga


From p.dalgaard at biostat.ku.dk  Mon May 22 11:53:02 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 22 May 2006 11:53:02 +0200
Subject: [Rd] rerender tcltk toplevel
In-Reply-To: <447181A8.2010902@gmx.de>
References: <447181A8.2010902@gmx.de>
Message-ID: <x2zmhaxu69.fsf@viggo.kubism.ku.dk>

Florian Hahne <fhahne at gmx.de> writes:

> Hi everybody,
> I am trying to write a simple progress display based on a tcltk
> toplevel. My first approach was to use  the progressBar widget from the
> BWidget library but since this is not available on every system (missing
> on at least almost all windows systems, I guess...) I wanted to have a
> backup there. So my second strategy was to use a simple toplevel with a
> label and update the tclvariable assigned to it. This works nicely on
> windows systems but on my linux box (Suse10) the label is not updated on
> every round of iteration but rather once the iterator finishes.
> 
> tt <-tktoplevel()
> tkwm.geometry(tt, "250x140")
> prog <-  tclVar("0")
> label <- tklabel(tt, textvariable=prog)
> tkgrid(label)
> 
> for(i in 1:50) {
>     tmp <- rnorm(1e+05)
>     tclvalue(prog) <- i*2
> }
> 
> When I combine both approaches and add the label to a toplevel that
> already contains the progress bar updating the label works:
> 
> tt <-tktoplevel()
> tkwm.geometry(tt, "250x140")
> prog <-  tclVar("0")
> label <- tklabel(tt, textvariable=prog)
> progBar <- tkwidget(tt, "ProgressBar", variable=prog)
> tclRequire("BWidget")
> tkgrid(progBar)
> tkgrid(label)
> 
> for(i in 1:50) {
>     tmp <- rnorm(1e+05)
>     tclvalue(prog) <- i*2
> }
> 
> Is there a way to explicitly rerender a tcltk toplevel? There must be
> one since the ProgressBar widget causes this to happen, or am I wrong?
> Or is there another way I could make this work?
> Hope someone can help me here,
> 
> Florian

tcl("update") should do the trick. Notice that this is "considered
harmful" by some, although I don't see much of an issue here. Possibly,
tcl("update", "idletasks") is safer.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ripley at stats.ox.ac.uk  Mon May 22 12:53:32 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 22 May 2006 11:53:32 +0100 (BST)
Subject: [Rd] Changing the generic of as.data.frame
Message-ID: <Pine.LNX.4.64.0605221128030.14394@gannet.stats.ox.ac.uk>

I have changed the generic to as.data.frame in R-devel by adding a '...'
argument.  This means that any methods which do not have a '...' argument 
(quite a few do) will generate a warning in R CMD check: the fix is very 
simple (and backwards compatible): just add a '...' argument to the 
method.

We already had a problem with as.data.frame.table which had an extra 
argument (at the request of users), but required that the method had to be 
called explicitly to use.  Adding as.data.frame.ftable compounded that 
problem.

Packages that have S4 methods for as.data.frame still work *unless* they 
set an explicit generic (as FLCore does).

The other motivation was to allow the option to not convert character 
vectors to factors, which needed an additional argument to 
as.data.frame.character.  So data.frame now has an argument 'charToFactor' 
controlled by a global option (which also controls the default of as.is in 
read.table).  More experience will be needed as to whether it is safe to 
work with the global option set to FALSE, so that aspect should be 
regarded as experimental until 2.4.0 is released or it is withdrawn.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From r.hankin at noc.soton.ac.uk  Mon May 22 13:07:38 2006
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Mon, 22 May 2006 12:07:38 +0100
Subject: [Rd] R CMD check problem
Message-ID: <362788DA-397C-4513-A3EF-7D16162B4A03@soc.soton.ac.uk>

Hi

I have a package that I'm testing.
It seems to install fine and it works, as far as I can tell.
For example, I can install the package, and use it,
  and source the test suite with no errors.

My problem is with R CMD check.

It passes on R-2.2-0:

Robin-Hankins-Computer:~/scratch% R CMD check ./partitions_1.1-0.tar.gz
* checking for working latex ... OK

[snip]

make[1]: Leaving directory `/users/sat/rksh/partitions.Rcheck/tests'
OK
* creating partitions-manual.tex ... OK
* checking partitions-manual.tex ... OK




But it doesn't pass on R-2.3.0, MacOSX:



Robin-Hankins-Computer:~/scratch% R CMD check ./partitions_1.1-0.tar.gz
* checking for working latex ... OK
*[snip]

* checking examples ... OK
* checking tests ...
   Running 'aaa.R'
make[1]: *** [aaa.Rout] Error 1
make: *** [all] Error 2
ERROR

checking  aaa.Rout.fail, I get

Robin-Hankins-Computer:~/scratch% cat ./partitions.Rcheck/tests/ 
aaa.Rout.fail
/Library/Frameworks/R.framework/Resources/bin/R: line 192: /Library/ 
Frameworks/R.framework/Resources/bin/exec/i386/R: cannot execute  
binary file
/Library/Frameworks/R.framework/Resources/bin/R: line 192: /Library/ 
Frameworks/R.framework/Resources/bin/exec/i386/R: Unknown error: 0
Robin-Hankins-Computer:~/scratch%



anyone got any insight into this?




--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743


From fhahne at gmx.de  Mon May 22 13:08:29 2006
From: fhahne at gmx.de (Florian Hahne)
Date: Mon, 22 May 2006 13:08:29 +0200
Subject: [Rd] rerender tcltk toplevel
In-Reply-To: <x2zmhaxu69.fsf@viggo.kubism.ku.dk>
References: <447181A8.2010902@gmx.de> <x2zmhaxu69.fsf@viggo.kubism.ku.dk>
Message-ID: <44719BAD.4000505@gmx.de>

Thanks Peter,
that's what I was looking for. Works like a charm now...
Florian

Peter Dalgaard schrieb:
> Florian Hahne <fhahne at gmx.de> writes:
>
>   
>> Hi everybody,
>> I am trying to write a simple progress display based on a tcltk
>> toplevel. My first approach was to use  the progressBar widget from the
>> BWidget library but since this is not available on every system (missing
>> on at least almost all windows systems, I guess...) I wanted to have a
>> backup there. So my second strategy was to use a simple toplevel with a
>> label and update the tclvariable assigned to it. This works nicely on
>> windows systems but on my linux box (Suse10) the label is not updated on
>> every round of iteration but rather once the iterator finishes.
>>
>> tt <-tktoplevel()
>> tkwm.geometry(tt, "250x140")
>> prog <-  tclVar("0")
>> label <- tklabel(tt, textvariable=prog)
>> tkgrid(label)
>>
>> for(i in 1:50) {
>>     tmp <- rnorm(1e+05)
>>     tclvalue(prog) <- i*2
>> }
>>
>> When I combine both approaches and add the label to a toplevel that
>> already contains the progress bar updating the label works:
>>
>> tt <-tktoplevel()
>> tkwm.geometry(tt, "250x140")
>> prog <-  tclVar("0")
>> label <- tklabel(tt, textvariable=prog)
>> progBar <- tkwidget(tt, "ProgressBar", variable=prog)
>> tclRequire("BWidget")
>> tkgrid(progBar)
>> tkgrid(label)
>>
>> for(i in 1:50) {
>>     tmp <- rnorm(1e+05)
>>     tclvalue(prog) <- i*2
>> }
>>
>> Is there a way to explicitly rerender a tcltk toplevel? There must be
>> one since the ProgressBar widget causes this to happen, or am I wrong?
>> Or is there another way I could make this work?
>> Hope someone can help me here,
>>
>> Florian
>>     
>
> tcl("update") should do the trick. Notice that this is "considered
> harmful" by some, although I don't see much of an issue here. Possibly,
> tcl("update", "idletasks") is safer.
>
>   


-- 
Florian Hahne
Abt. Molekulare Genomanalyse (B050)
Deutsches Krebsforschungszentrum (DKFZ)
Im Neuenheimer Feld 580
D-69120 Heidelberg
phone: 0049 6221 424764
fax: 0049 6221 422399
web: www.dkfz.de/mga


From ripley at stats.ox.ac.uk  Mon May 22 14:07:49 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 22 May 2006 13:07:49 +0100 (BST)
Subject: [Rd] R CMD check problem
In-Reply-To: <362788DA-397C-4513-A3EF-7D16162B4A03@soc.soton.ac.uk>
References: <362788DA-397C-4513-A3EF-7D16162B4A03@soc.soton.ac.uk>
Message-ID: <Pine.LNX.4.64.0605221305530.15222@gannet.stats.ox.ac.uk>

This is specific to the `universal' MacOS X binary: it is saying it cannot 
run the i386 executable.  If this is not a i386 Mac, some variable is set 
wrong. In any case, I suggest the R-sig-mac list.

On Mon, 22 May 2006, Robin Hankin wrote:

> Hi
>
> I have a package that I'm testing.
> It seems to install fine and it works, as far as I can tell.
> For example, I can install the package, and use it,
>  and source the test suite with no errors.
>
> My problem is with R CMD check.
>
> It passes on R-2.2-0:
>
> Robin-Hankins-Computer:~/scratch% R CMD check ./partitions_1.1-0.tar.gz
> * checking for working latex ... OK
>
> [snip]
>
> make[1]: Leaving directory `/users/sat/rksh/partitions.Rcheck/tests'
> OK
> * creating partitions-manual.tex ... OK
> * checking partitions-manual.tex ... OK
>
>
>
>
> But it doesn't pass on R-2.3.0, MacOSX:
>
>
>
> Robin-Hankins-Computer:~/scratch% R CMD check ./partitions_1.1-0.tar.gz
> * checking for working latex ... OK
> *[snip]
>
> * checking examples ... OK
> * checking tests ...
>   Running 'aaa.R'
> make[1]: *** [aaa.Rout] Error 1
> make: *** [all] Error 2
> ERROR
>
> checking  aaa.Rout.fail, I get
>
> Robin-Hankins-Computer:~/scratch% cat ./partitions.Rcheck/tests/
> aaa.Rout.fail
> /Library/Frameworks/R.framework/Resources/bin/R: line 192: /Library/
> Frameworks/R.framework/Resources/bin/exec/i386/R: cannot execute
> binary file
> /Library/Frameworks/R.framework/Resources/bin/R: line 192: /Library/
> Frameworks/R.framework/Resources/bin/exec/i386/R: Unknown error: 0
> Robin-Hankins-Computer:~/scratch%
>
>
>
> anyone got any insight into this?
>
>
>
>
> --
> Robin Hankin
> Uncertainty Analyst
> National Oceanography Centre, Southampton
> European Way, Southampton SO14 3ZH, UK
>  tel  023-8059-7743
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From wade.rogers at ciradiscovery.com  Mon May 22 14:18:31 2006
From: wade.rogers at ciradiscovery.com (wade.rogers at ciradiscovery.com)
Date: Mon, 22 May 2006 14:18:31 +0200 (CEST)
Subject: [Rd] ssize_t not defined in sockconn.c (PR#8889)
Message-ID: <20060522121831.D7A8C494DE@slim.kubism.ku.dk>

Problem:
Build of R failed when compiling sockconn.c.  The problem seemed to be
that ssize_t was not defined.

The following change in sock.h fixes the problem, though it's probably
not fixed the _right_ way.

/* Following line changed by WTR (Cira) to overcome make problem.
#if defined Win32 && !defined _SSIZE_T_
typedef int ssize_t;
#endif
*/
typedef int ssize_t;

Thanks!
Wade

--please do not edit the information below--

Version:
  platform = i686-pc-linux-gnu
  arch = i686
  os = linux-gnu
  system = i686, linux-gnu
  status =
  major = 2
  minor = 3.0
  year = 2006
  month = 04
  day = 24
  svn rev = 37909
  language = R
  version.string = Version 2.3.0 (2006-04-24)

Locale:
LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=en_US.UTF-8;LC_MESSAGES=en_US.UTF-8;LC_PAPER=C;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=C;LC_IDENTIFICATION=C

Search Path:
  .GlobalEnv, package:methods, package:stats, package:graphics, 
package:grDevices, package:utils, package:datasets, Autoloads, package:base


Wade T. Rogers, Ph.D.
President & CEO
Cira Discovery Sciences, Inc.
3701 Market St Suite 340
Philadelphia, PA  19104
wade.rogers at CiraDiscovery.com
215.966.6131 (office)
215.966.6001 (fax)
610.368.5821 (mobile)
www.CiraDiscovery.com  
	[[alternative HTML version deleted]]


From p.dalgaard at biostat.ku.dk  Mon May 22 14:38:57 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 22 May 2006 14:38:57 +0200
Subject: [Rd] ssize_t not defined in sockconn.c (PR#8889)
In-Reply-To: <20060522121831.D7A8C494DE@slim.kubism.ku.dk>
References: <20060522121831.D7A8C494DE@slim.kubism.ku.dk>
Message-ID: <x2mzdaxmhq.fsf@viggo.kubism.ku.dk>

wade.rogers at ciradiscovery.com writes:

> Problem:
> Build of R failed when compiling sockconn.c.  The problem seemed to be
> that ssize_t was not defined.

You have too little information here. Which platform, compiler, etc is
this? 

R certainly builds fine on at least some i686-pc-linux-gnu systems.

I believe this is supposed to be defined via <sys/types.h> (and "int"
could well be wrong on 64-bit systems), but your include chain may
somehow be broken.
 
> The following change in sock.h fixes the problem, though it's probably
> not fixed the _right_ way.
> 
> /* Following line changed by WTR (Cira) to overcome make problem.
> #if defined Win32 && !defined _SSIZE_T_
> typedef int ssize_t;
> #endif
> */
> typedef int ssize_t;
> 
> Thanks!
> Wade
> 
> --please do not edit the information below--
> 
> Version:
>   platform = i686-pc-linux-gnu
>   arch = i686
>   os = linux-gnu
>   system = i686, linux-gnu
>   status =
>   major = 2
>   minor = 3.0
>   year = 2006
>   month = 04
>   day = 24
>   svn rev = 37909
>   language = R
>   version.string = Version 2.3.0 (2006-04-24)
> 
> Locale:
> LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=en_US.UTF-8;LC_MESSAGES=en_US.UTF-8;LC_PAPER=C;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=C;LC_IDENTIFICATION=C
> 
> Search Path:
>   .GlobalEnv, package:methods, package:stats, package:graphics, 
> package:grDevices, package:utils, package:datasets, Autoloads, package:base
> 
> 
> Wade T. Rogers, Ph.D.
> President & CEO
> Cira Discovery Sciences, Inc.
> 3701 Market St Suite 340
> Philadelphia, PA  19104
> wade.rogers at CiraDiscovery.com
> 215.966.6131 (office)
> 215.966.6001 (fax)
> 610.368.5821 (mobile)
> www.CiraDiscovery.com  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From MSchwartz at mn.rr.com  Mon May 22 14:46:39 2006
From: MSchwartz at mn.rr.com (MSchwartz at mn.rr.com)
Date: Mon, 22 May 2006 14:46:39 +0200 (CEST)
Subject: [Rd] ssize_t not defined in sockconn.c (PR#8889)
Message-ID: <20060522124639.ED0C8CD4A@slim.kubism.ku.dk>

On Mon, 2006-05-22 at 14:18 +0200, wade.rogers at ciradiscovery.com wrote:
> Problem:
> Build of R failed when compiling sockconn.c.  The problem seemed to be
> that ssize_t was not defined.
> 
> The following change in sock.h fixes the problem, though it's probably
> not fixed the _right_ way.
> 
> /* Following line changed by WTR (Cira) to overcome make problem.
> #if defined Win32 && !defined _SSIZE_T_
> typedef int ssize_t;
> #endif
> */
> typedef int ssize_t;
> 
> Thanks!
> Wade

This has been reported at least three times previously and has already
been fixed in 2.3.0patched and 2.3.1Beta by Prof. Ripley.

It is an issue with older Linux distro headers, having been confirmed on
both RH 8.0 and RH 9. Are you using either one of those, which you did
not indicate?  If so, please consider updating your system as well.

You can get the Beta tarball from:

  http://cran.r-project.org/src/base-prerelease/

Please review the list archives and existing bug reports before filing a
new one.

Marc Schwartz


From ripley at stats.ox.ac.uk  Mon May 22 14:46:55 2006
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Mon, 22 May 2006 14:46:55 +0200 (CEST)
Subject: [Rd] ssize_t not defined in sockconn.c (PR#8889)
Message-ID: <20060522124655.0CF5AC9E8@slim.kubism.ku.dk>

This is already fixed in 2.3.1 beta: see the R FAQ for reporting on 
current versions only.

On Mon, 22 May 2006, wade.rogers at ciradiscovery.com wrote:

> Problem:
> Build of R failed when compiling sockconn.c.  The problem seemed to be
> that ssize_t was not defined.
>
> The following change in sock.h fixes the problem, though it's probably
> not fixed the _right_ way.

No, it's not.  The right way is to ensure that a suitable header file is 
includer.  ssize_t is not int on 64-bit platforms.

> /* Following line changed by WTR (Cira) to overcome make problem.
> #if defined Win32 && !defined _SSIZE_T_
> typedef int ssize_t;
> #endif
> */
> typedef int ssize_t;
>
> Thanks!
> Wade
>
> --please do not edit the information below--
>
> Version:
>  platform = i686-pc-linux-gnu
>  arch = i686
>  os = linux-gnu
>  system = i686, linux-gnu

Strange, which actual OS is this?  It has been defined in glibc since at 
least 2.3.0.

>  status =
>  major = 2
>  minor = 3.0
>  year = 2006
>  month = 04
>  day = 24
>  svn rev = 37909
>  language = R
>  version.string = Version 2.3.0 (2006-04-24)
>
> Locale:
> LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=en_US.UTF-8;LC_MESSAGES=en_US.UTF-8;LC_PAPER=C;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=C;LC_IDENTIFICATION=C
>
> Search Path:
>  .GlobalEnv, package:methods, package:stats, package:graphics,
> package:grDevices, package:utils, package:datasets, Autoloads, package:base
>
>
> Wade T. Rogers, Ph.D.
> President & CEO
> Cira Discovery Sciences, Inc.
> 3701 Market St Suite 340
> Philadelphia, PA  19104
> wade.rogers at CiraDiscovery.com
> 215.966.6131 (office)
> 215.966.6001 (fax)
> 610.368.5821 (mobile)
> www.CiraDiscovery.com
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From nakama at ki.rim.or.jp  Mon May 22 16:01:17 2006
From: nakama at ki.rim.or.jp (Ei-ji Nakama)
Date: Mon, 22 May 2006 23:01:17 +0900
Subject: [Rd] Sys.setlocale upsets windows graphics device (PR#8887)
In-Reply-To: <20060522080131.A0A2619A4F@slim.kubism.ku.dk>
References: <20060522080131.A0A2619A4F@slim.kubism.ku.dk>
Message-ID: <dc41e1260605220701u5cbe3d1r6742a7e85b48c272@mail.gmail.com>

 If a return value of locale does not have a period, a function of libmingwex
gives back NULL in strchr and refers to NULL pointer in atoi.

But it will be right to fix mingw...

--- locales.R.orig      Mon Apr 10 07:19:19 2006
+++ locales.R   Mon May 22 22:55:21 2006
@@ -10,6 +10,7 @@
 {
     category <- match(category, c("LC_ALL", "LC_COLLATE", "LC_CTYPE",
                                   "LC_MONETARY", "LC_NUMERIC", "LC_TIME"))
+    if(locale == "C") locale = "English_United States.1252");
     if(is.na(category)) stop("invalid 'category' argument")
     .Internal(setlocale(category, locale))
 }


2006/5/22, ripley at stats.ox.ac.uk <ripley at stats.ox.ac.uk>:
> On Mon, 22 May 2006, Edward wrote:
>
> > Hi,
> > We tried it on 3 separate windows XP computers using version 2.3.0.
> > The original locale is set for Thailand on all 3.
> > So how do we fix it? Is there another patch?
>
> Don't try to do graphics in the C locale on your computer?
>
> I suspect this is a font problem in Windows, in that your fonts may be
> specific to the Thai localization.  But without a means of reproducing
> this, I can only guess.
>
> If you can set up a debugger (see the rw-FAQ), you may be able to give us
> some additional clues as the where the crash is occuring.
>
> > And why does the crash not happen with earlier R versions (eg. 2.2.1) on the
> > same computer?
>
> Because of the issue mentioned in the CHANGES file, the change to the C
> locale was reverted by opening a graphics window.
>
> >
> > ---
> >> Sys.getlocale()
> > [1]
> > "LC_COLLATE=Thai_Thailand.874;LC_CTYPE=Thai_Thailand.874;LC_MONETARY=Thai_Thailand.874;LC_NUMERIC=C;LC_TIME=Thai_Thailand.874"
> > ---
> >
> > Thanks
> > Edward
> >
> > ----- Original Message ----- From: "Prof Brian Ripley"
> > <ripley at stats.ox.ac.uk>
> > To: <edward.m at psu.ac.th>
> > Cc: <R-bugs at biostat.ku.dk>
> > Sent: Monday, May 22, 2006 2:32 PM
> > Subject: Re: [Rd] Sys.setlocale upsets windows graphics device (PR#8887)
> >
> >
> >> Works perfectly for me.  There was a bug in 2.2.1, but it was fixed in
> >> 2.2.1 patched (see CHANGES).
> >>
> >> What locale were you changing from?  (This might be a Windows problem
> >> specific to your locale.)
> >>
> >> On Mon, 22 May 2006, edward.m at psu.ac.th wrote:
> >>
> >>> Full_Name: Edward McNeil
> >>> Version: 2.3.0
> >>> OS: Widows XP
> >>> Submission from: (NULL) (203.170.234.5)
> >>>
> >>>
> >>> Type the following:
> >>>
> >>>> Sys.setlocale("LC_ALL","C")
> >>>> hist(1:10)
> >>>
> >>> CRASH
> >>>
> >>> ______________________________________________
> >>> R-devel at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>
> >>>
> >>
> >> --
> >> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> >> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> >> University of Oxford,             Tel:  +44 1865 272861 (self)
> >> 1 South Parks Road,                     +44 1865 272866 (PA)
> >> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >
> >
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
EI-JI Nakama  <nakama at ki.rim.or.jp>
"\u4e2d\u9593\u6804\u6cbb"  <nakama at ki.rim.or.jp>


From jranke at uni-bremen.de  Mon May 22 17:36:02 2006
From: jranke at uni-bremen.de (jranke at uni-bremen.de)
Date: Mon, 22 May 2006 17:36:02 +0200 (CEST)
Subject: [Rd] (PR#8877) Literature for proposed fix
Message-ID: <20060522153602.6D85C24785@slim.kubism.ku.dk>

Dear R Developers,

Prediction intervals for weighted regression are treated in 

	Brown, P. J. (1994) Measurement, Regression and Calibration. Oxford

on p. 35. However, the prediction interval for Z is not really
spelled out in a way that would be accessible for me.

So I give up on this. I find my proposed solution (further updated since
my last mail) plausible, but I don't know and can't find enough theory
to support it.
	
	http://www.uft.uni-bremen.de/chemie/ranke/r-patches/predict.lm.patch

Ceterum censeo PR#8877 esse corrigendum.

Johannes Ranke

-- 
Dr. Johannes Ranke                 jranke at uni-bremen.de
UFT Bremen, Leobenerstr. 1         +49 421 218 8971 
D-28359 Bremen                     http://www.uft.uni-bremen.de/chemie/ranke


From bill at insightful.com  Mon May 22 17:50:34 2006
From: bill at insightful.com (Bill Dunlap)
Date: Mon, 22 May 2006 08:50:34 -0700 (PDT)
Subject: [Rd] Changing the generic of as.data.frame
In-Reply-To: <Pine.LNX.4.64.0605221128030.14394@gannet.stats.ox.ac.uk>
References: <Pine.LNX.4.64.0605221128030.14394@gannet.stats.ox.ac.uk>
Message-ID: <Pine.GSO.4.56.0605220839170.25139@octopus>

On Mon, 22 May 2006, Prof Brian Ripley wrote:

> The other motivation was to allow the option to not convert character
> vectors to factors, which needed an additional argument to
> as.data.frame.character.  So data.frame now has an argument 'charToFactor'
> controlled by a global option (which also controls the default of as.is in
> read.table).  More experience will be needed as to whether it is safe to
> work with the global option set to FALSE, so that aspect should be
> regarded as experimental until 2.4.0 is released or it is withdrawn.

Splus's data.frame() and as.data.frame() have had the 'stringsAsFactors'
argument to data.frame and as.data.frame since version 6.0 (2001).  Their
default values come from options("stringsAsFactors").  read.table() and
a few other data.frame-oriented functions have the same argument.
It looks like stringsAsFactors has the same functionality as your
new charToFactor.  Would it be feasible to change its name to stringsAsFactors?

Splus> help(data.frame)
                     Construct a Data Frame Object

USAGE:

data.frame(..., row.names, check.rows=F, check.names=T,
           na.strings="NA", dup.row.names=F, stringsAsFactors=<<see below>>)
data.frameAux(x, ...)
as.data.frame(x, row.names=NULL,  stringsAsFactors=<<see below>>, ...)
is.data.frame(x)
...
   stringsAsFactors
          a logical flag; if TRUE then convert character arguments
          to factors whose levels are the unique strings in the
          argument. This may save time and space if there a many
          repeated values in the strings and may make the
          statistical modelling functions easier to use. The
          default is TRUE, unless one sets options(stringsAsFactors=FALSE).
...


----------------------------------------------------------------------------
Bill Dunlap
Insightful Corporation
bill at insightful dot com
360-428-8146

 "All statements in this message represent the opinions of the author and do
 not necessarily reflect Insightful Corporation policy or position."


From ripley at stats.ox.ac.uk  Mon May 22 18:08:06 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 22 May 2006 17:08:06 +0100 (BST)
Subject: [Rd] Changing the generic of as.data.frame
In-Reply-To: <Pine.GSO.4.56.0605220839170.25139@octopus>
References: <Pine.LNX.4.64.0605221128030.14394@gannet.stats.ox.ac.uk>
	<Pine.GSO.4.56.0605220839170.25139@octopus>
Message-ID: <Pine.LNX.4.64.0605221652260.10069@gannet.stats.ox.ac.uk>

On Mon, 22 May 2006, Bill Dunlap wrote:

> On Mon, 22 May 2006, Prof Brian Ripley wrote:
>
>> The other motivation was to allow the option to not convert character
>> vectors to factors, which needed an additional argument to
>> as.data.frame.character.  So data.frame now has an argument 'charToFactor'
>> controlled by a global option (which also controls the default of as.is in
>> read.table).  More experience will be needed as to whether it is safe to
>> work with the global option set to FALSE, so that aspect should be
>> regarded as experimental until 2.4.0 is released or it is withdrawn.
>
> Splus's data.frame() and as.data.frame() have had the 'stringsAsFactors'
> argument to data.frame and as.data.frame since version 6.0 (2001).  Their
> default values come from options("stringsAsFactors").  read.table() and
> a few other data.frame-oriented functions have the same argument.
> It looks like stringsAsFactors has the same functionality as your
> new charToFactor.  Would it be feasible to change its name to stringsAsFactors?

It would, but then I think we would want to ensure it did precisely the 
same thing.  If there a description of what exactly 
options("stringsAsFactors") affects?  (?options suggests it is data.frame, 
read.table and importData, and nothing else).

>
> Splus> help(data.frame)
>                     Construct a Data Frame Object
>
> USAGE:
>
> data.frame(..., row.names, check.rows=F, check.names=T,
>           na.strings="NA", dup.row.names=F, stringsAsFactors=<<see below>>)
> data.frameAux(x, ...)
> as.data.frame(x, row.names=NULL,  stringsAsFactors=<<see below>>, ...)
> is.data.frame(x)
> ...
>   stringsAsFactors
>          a logical flag; if TRUE then convert character arguments
>          to factors whose levels are the unique strings in the
>          argument. This may save time and space if there a many
>          repeated values in the strings and may make the
>          statistical modelling functions easier to use. The
>          default is TRUE, unless one sets options(stringsAsFactors=FALSE).
> ...
>
>
> ----------------------------------------------------------------------------
> Bill Dunlap
> Insightful Corporation
> bill at insightful dot com
> 360-428-8146
>
> "All statements in this message represent the opinions of the author and do
> not necessarily reflect Insightful Corporation policy or position."
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Mon May 22 18:14:06 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 22 May 2006 17:14:06 +0100 (BST)
Subject: [Rd] Sys.setlocale upsets windows graphics device (PR#8887)
In-Reply-To: <dc41e1260605220701u5cbe3d1r6742a7e85b48c272@mail.gmail.com>
References: <20060522080131.A0A2619A4F@slim.kubism.ku.dk>
	<dc41e1260605220701u5cbe3d1r6742a7e85b48c272@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0605221708150.10069@gannet.stats.ox.ac.uk>

On Mon, 22 May 2006, Ei-ji Nakama wrote:

> If a return value of locale does not have a period, a function of libmingwex
> gives back NULL in strchr and refers to NULL pointer in atoi.
>
> But it will be right to fix mingw...
>
> --- locales.R.orig      Mon Apr 10 07:19:19 2006
> +++ locales.R   Mon May 22 22:55:21 2006
> @@ -10,6 +10,7 @@
> {
>     category <- match(category, c("LC_ALL", "LC_COLLATE", "LC_CTYPE",
>                                   "LC_MONETARY", "LC_NUMERIC", "LC_TIME"))
> +    if(locale == "C") locale = "English_United States.1252");
>     if(is.na(category)) stop("invalid 'category' argument")
>     .Internal(setlocale(category, locale))
> }

Unfortunately that does not affect e.g. 'Rgui LC_ALL=C' so a more 
comprehensive C-level fix would be needed.

I did wonder if mingwex was the problem, but in theory at least it knows 
about the C locale (cp = 0), and the crash was coming from MSVCRT.dll, in 
the conversion of an ASCII string to wchar.  Since it works in other 
Windows base locales it did seem specific to Thai (which is still a 
single-byte locale).


> 2006/5/22, ripley at stats.ox.ac.uk <ripley at stats.ox.ac.uk>:
>> On Mon, 22 May 2006, Edward wrote:
>>
>>> Hi,
>>> We tried it on 3 separate windows XP computers using version 2.3.0.
>>> The original locale is set for Thailand on all 3.
>>> So how do we fix it? Is there another patch?
>>
>> Don't try to do graphics in the C locale on your computer?
>>
>> I suspect this is a font problem in Windows, in that your fonts may be
>> specific to the Thai localization.  But without a means of reproducing
>> this, I can only guess.
>>
>> If you can set up a debugger (see the rw-FAQ), you may be able to give us
>> some additional clues as the where the crash is occuring.
>>
>>> And why does the crash not happen with earlier R versions (eg. 2.2.1) on the
>>> same computer?
>>
>> Because of the issue mentioned in the CHANGES file, the change to the C
>> locale was reverted by opening a graphics window.
>>
>>>
>>> ---
>>>> Sys.getlocale()
>>> [1]
>>> "LC_COLLATE=Thai_Thailand.874;LC_CTYPE=Thai_Thailand.874;LC_MONETARY=Thai_Thailand.874;LC_NUMERIC=C;LC_TIME=Thai_Thailand.874"
>>> ---
>>>
>>> Thanks
>>> Edward
>>>
>>> ----- Original Message ----- From: "Prof Brian Ripley"
>>> <ripley at stats.ox.ac.uk>
>>> To: <edward.m at psu.ac.th>
>>> Cc: <R-bugs at biostat.ku.dk>
>>> Sent: Monday, May 22, 2006 2:32 PM
>>> Subject: Re: [Rd] Sys.setlocale upsets windows graphics device (PR#8887)
>>>
>>>
>>>> Works perfectly for me.  There was a bug in 2.2.1, but it was fixed in
>>>> 2.2.1 patched (see CHANGES).
>>>>
>>>> What locale were you changing from?  (This might be a Windows problem
>>>> specific to your locale.)
>>>>
>>>> On Mon, 22 May 2006, edward.m at psu.ac.th wrote:
>>>>
>>>>> Full_Name: Edward McNeil
>>>>> Version: 2.3.0
>>>>> OS: Widows XP
>>>>> Submission from: (NULL) (203.170.234.5)
>>>>>
>>>>>
>>>>> Type the following:
>>>>>
>>>>>> Sys.setlocale("LC_ALL","C")
>>>>>> hist(1:10)
>>>>>
>>>>> CRASH
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>>>
>>>>
>>>> --
>>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>>> University of Oxford,             Tel:  +44 1865 272861 (self)
>>>> 1 South Parks Road,                     +44 1865 272866 (PA)
>>>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>>
>>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Robert.McGehee at geodecapital.com  Mon May 22 18:49:04 2006
From: Robert.McGehee at geodecapital.com (McGehee, Robert)
Date: Mon, 22 May 2006 12:49:04 -0400
Subject: [Rd] Wishlist: Vignettes on CRAN
Message-ID: <67DCA285A2D7754280D3B8E88EB548020C946838@MSGBOSCLB2WIN.DMN1.FMR.COM>

I was recently browsing through CRAN's Finance task view to remind
myself of the publicly available packages relevant to my work. As the
reference manuals are all online, I am able to flip through the
available functions to get an idea of the package's scope before
downloading. 

That said, many authors have taken the time to additionally provide a
useful vignette which provides a better overview to complicated
packages. However, as far as I can tell, the only way to read or even
know if a package has a vignette is to first download and unpack the
package source, which is inconvenient when one wants to understand a
package _before_ installing.

Perhaps an easy way to make vignettes more accessible to the end user
would be to link the vignette PDF directly to the download page so that
one could download it just as one can download the reference manual or
package source. This both publicizes the vignette (since many users may
even be unaware that a package has a vignette) and facilitates browsing.

Just a thought!

Best,
Robert

Robert McGehee
Quantitative Analyst
Geode Capital Management, LLC
53 State Street, 5th Floor | Boston, MA | 02109
Tel: 617/392-8396    Fax:617/476-6389
mailto:robert.mcgehee at geodecapital.com



This e-mail, and any attachments hereto, are intended for us...{{dropped}}


From spencer.graves at pdf.com  Mon May 22 19:11:57 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 22 May 2006 10:11:57 -0700
Subject: [Rd] Wishlist: Vignettes on CRAN
In-Reply-To: <67DCA285A2D7754280D3B8E88EB548020C946838@MSGBOSCLB2WIN.DMN1.FMR.COM>
References: <67DCA285A2D7754280D3B8E88EB548020C946838@MSGBOSCLB2WIN.DMN1.FMR.COM>
Message-ID: <4471F0DD.4080009@pdf.com>

Might it be feasible to just bundle any vignettes with the help file? 
Wouldn't this make them more accessible to, e.g., RSiteSearch?

Just a thought.  Spencer Graves

McGehee, Robert wrote:
> I was recently browsing through CRAN's Finance task view to remind
> myself of the publicly available packages relevant to my work. As the
> reference manuals are all online, I am able to flip through the
> available functions to get an idea of the package's scope before
> downloading. 
> 
> That said, many authors have taken the time to additionally provide a
> useful vignette which provides a better overview to complicated
> packages. However, as far as I can tell, the only way to read or even
> know if a package has a vignette is to first download and unpack the
> package source, which is inconvenient when one wants to understand a
> package _before_ installing.
> 
> Perhaps an easy way to make vignettes more accessible to the end user
> would be to link the vignette PDF directly to the download page so that
> one could download it just as one can download the reference manual or
> package source. This both publicizes the vignette (since many users may
> even be unaware that a package has a vignette) and facilitates browsing.
> 
> Just a thought!
> 
> Best,
> Robert
> 
> Robert McGehee
> Quantitative Analyst
> Geode Capital Management, LLC
> 53 State Street, 5th Floor | Boston, MA | 02109
> Tel: 617/392-8396    Fax:617/476-6389
> mailto:robert.mcgehee at geodecapital.com
> 
> 
> 
> This e-mail, and any attachments hereto, are intended for us...{{dropped}}
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From bill at insightful.com  Mon May 22 19:16:22 2006
From: bill at insightful.com (Bill Dunlap)
Date: Mon, 22 May 2006 10:16:22 -0700 (PDT)
Subject: [Rd] Changing the generic of as.data.frame
In-Reply-To: <Pine.LNX.4.64.0605221652260.10069@gannet.stats.ox.ac.uk>
References: <Pine.LNX.4.64.0605221128030.14394@gannet.stats.ox.ac.uk>
	<Pine.GSO.4.56.0605220839170.25139@octopus>
	<Pine.LNX.4.64.0605221652260.10069@gannet.stats.ox.ac.uk>
Message-ID: <Pine.GSO.4.56.0605220938410.25139@octopus>

On Mon, 22 May 2006, Prof Brian Ripley wrote:

> On Mon, 22 May 2006, Bill Dunlap wrote:
>
> > On Mon, 22 May 2006, Prof Brian Ripley wrote:
> >
> >> The other motivation was to allow the option to not convert character
> >> vectors to factors, which needed an additional argument to
> >> as.data.frame.character.  So data.frame now has an argument 'charToFactor'
> >> controlled by a global option (which also controls the default of as.is in
> >> read.table).  More experience will be needed as to whether it is safe to
> >> work with the global option set to FALSE, so that aspect should be
> >> regarded as experimental until 2.4.0 is released or it is withdrawn.
> >
> > Splus's data.frame() and as.data.frame() have had the 'stringsAsFactors'
> > argument to data.frame and as.data.frame since version 6.0 (2001).  Their
> > default values come from options("stringsAsFactors").  read.table() and
> > a few other data.frame-oriented functions have the same argument.
> > It looks like stringsAsFactors has the same functionality as your
> > new charToFactor.  Would it be feasible to change its name to stringsAsFactors?
>
> It would, but then I think we would want to ensure it did precisely the
> same thing.  If there a description of what exactly
> options("stringsAsFactors") affects?  (?options suggests it is data.frame,
> read.table and importData, and nothing else).

I just noticed that data.frame accepts a vector of logicals for
stringsAsFactors: one element per ... argument.  This is not in
the help file.

   Splus> data.frame
   function(..., row.names = NULL, check.rows = F, check.names = T, na.strings =
           "NA", dup.row.names = F, stringsAsFactors = default.stringsAsFactors(
           ))
   {
           dots <- match.call(expand.dots = F)$...
           n <- length(dots) - 1
           ...
           stringsAsFactors <- rep(stringsAsFactors, len = n)
           for(i in seq(length = n)) {
                   xi <- data.frameAux(eval(as.name(paste("..", i, sep = ""))),
                           na.strings = na.strings, stringsAsFactors =
                           stringsAsFactors[i])


Splus's importData(), which outputs a data.frame from a various other
file formats or database connections, also uses stringsAsFactors.

It also affects as.data.frame() and the character method for data.frameAux()
(which is not expected to be called directly -- it is a support function for
data.frame() and as.data.frame()).

In the bigdata library bdFrame() uses it in the same way that data.frame()
does.

There may be a few stray functions that pass their ... arguments
to data.frame, but I cannot think of any now.

Its default value should always be default.stringsAsFactors(),
but I see the bdFrame() uses just FALSE.  default.stringsAsFactors()
looks at options("stringsAsFactor") and maps NULL and TRUE to TRUE.
    Splus> default.stringsAsFactors
    function()
    {
            val <- .Options$stringsAsFactors
            if(is.null(val))
                    val <- T
            if(!is.logical(val) || is.na(val) || length(val) != 1)
                    stop("options('stringsAsFactors') not set to T or F")
            val
    }

I believe that Terry Therneau has been using Splus with
options(stringsAsFactors=FALSE) for quite a while and hasn't reported
any problems.

>
> >
> > Splus> help(data.frame)
> >                     Construct a Data Frame Object
> >
> > USAGE:
> >
> > data.frame(..., row.names, check.rows=F, check.names=T,
> >           na.strings="NA", dup.row.names=F, stringsAsFactors=<<see below>>)
> > data.frameAux(x, ...)
> > as.data.frame(x, row.names=NULL,  stringsAsFactors=<<see below>>, ...)
> > is.data.frame(x)
> > ...
> >   stringsAsFactors
> >          a logical flag; if TRUE then convert character arguments
> >          to factors whose levels are the unique strings in the
> >          argument. This may save time and space if there a many
> >          repeated values in the strings and may make the
> >          statistical modelling functions easier to use. The
> >          default is TRUE, unless one sets options(stringsAsFactors=FALSE).
> > ...
> >
> >
> > ----------------------------------------------------------------------------
> > Bill Dunlap
> > Insightful Corporation
> > bill at insightful dot com
> > 360-428-8146
> >
> > "All statements in this message represent the opinions of the author and do
> > not necessarily reflect Insightful Corporation policy or position."
> >
> >
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>

----------------------------------------------------------------------------
Bill Dunlap
Insightful Corporation
bill at insightful dot com
360-428-8146

 "All statements in this message represent the opinions of the author and do
 not necessarily reflect Insightful Corporation policy or position."


From henrikb at braju.com  Mon May 22 19:36:54 2006
From: henrikb at braju.com (Henrik Bengtsson)
Date: Mon, 22 May 2006 10:36:54 -0700
Subject: [Rd] UseMethod infelicity
In-Reply-To: <Pine.LNX.4.64.0605201620420.28607@gannet.stats.ox.ac.uk>
References: <Pine.LNX.4.64.0605191348300.6158@gannet.stats.ox.ac.uk>
	<Pine.LNX.4.64.0605201620420.28607@gannet.stats.ox.ac.uk>
Message-ID: <59d7961d0605221036r78ac6dmb6b5316dc88b1c96@mail.gmail.com>

On 5/20/06, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> Here are three examples where this matters, and I think the bug is
> elsewhere!
>
> 1) Package accuracy does
>
> ZeligHooks<-function (...) {
>     if (exists(".simHooked",envir=.GlobalEnv)) {
>          return(TRUE)
>     }
>     origsim=get("sim",envir=as.environment("package:Zelig"))
>     sim.replacement=function (object, x, ...) {
>      if  (inherits(object,"sensitivity")) {
>         psim(object,x,...)
>      } else {
>        origsim(object,x,...)
>      }
>     }
>     assignInNamespace("sim",sim.replacement,"Zelig")
>     unlockBinding("sim",as.environment("package:Zelig"))
>     assign("sim",sim.replacement, envir=as.environment("package:Zelig"))
>     assign("sim",sim.replacement, envir=.GlobalEnv)
>     assign(".simHooked",TRUE,envir=.GlobalEnv)
> }
>
> Now, origsim() becomes a generic calling "sim", with defining environment
> namespace:Zelig.  However, sim in namespace:Zelig has been altered to be a
> new function, whose enclosure is not namespace:Zelig and hence cannot see
> the methods registered on the original sim() in namespace:Zelig.  I think
> that is the correct behaviour (the new sim might have nothing to do with
> the old one).  The fix would appear to be to set the environment of the
> replacement to namespace:Zelig, but then origsim will not be visible from
> sim.
>
> Note that the package writes in the workspace and clobbers any object
> called 'sim' there.  Surely a less intrusive solution is needed?
>
> There's a similar (maybe the same) problem in package VDCutil.
>
>
> 2) Package arules fails its tests.  The problem is in Matrix:
>
> > base::as.matrix
> function (x)
> UseMethod("as.matrix")
> <environment: namespace:base>
> > library(Matrix)
> > base::as.matrix
> standardGeneric for "as.matrix" defined from package "base"
>
> function (x)
> standardGeneric("as.matrix")
> <environment: 0x1453cc8>
> Methods may be defined for arguments: x
>
> Now is converting to an S4 generic *not* supposed to alter the function in
> the original package/namespace? It does not do it if I do it by hand:
>
> > setClass("foo", "numeric")
> [1] "foo"
> > setMethod("as.matrix", "foo", function(x) x)
> Creating a new generic function for 'as.matrix' in '.GlobalEnv'
> [1] "as.matrix"
> > base::as.matrix
> function (x)
> UseMethod("as.matrix")
> <environment: namespace:base>
>
> and this looks like a bug.
>
>
> 3) Package R.oo has things like UseMethod("$") whereas this is documented
> to work for functions (not operators).  This is unnecessary ($ does
> internal dispatch) and the existing code is getting the wrong defining
> environment (and although I've reinstated this as a workaround, I think it
> should be an error).

First, when coding I treat operators as being functions. I think this
is valid, cf. "Except for the syntax, there is no difference between
applying an operator and calling a function. In fact, x + y can
equivalently be written "+"(x, y). Notice that since + is a
non-standard function name, it needs to be quoted." (R Language
Definition).

Second, I went to look at my code, and I found an old note of mine
saying "get("$")(x, name)" won't work.  At the time, I never tried to
figure out why.  However, if I try that, or "$"(x, name) the name of
the 'name' argument becomes "name" (through some internal substitute()
I believe).  Example in R v2.3.0 patched (2006-04-28) on WinXP:

o <- structure(1, class="A")

"$.A" <- function(x, name) { cat("$.A(x,", name, ")\n") }
"[[.A" <- function(x, name) { UseMethod("$") }
o[["a"]]  # gives $.A(x, a ) as wanted

But
"[[.A" <- function(x, name) { "$"(x, name) }
o[["a"]]  # gives $.A(x, name )!

Same for:
"[[.A" <- function(x, name) { .Primitive("$")(x, name) }
o[["a"]]  # $.A(x, name )

and
"[[.A" <- function(x, name) { get("$")(x, name) }
o[["a"]]  # $.A(x, name )

I expected/hoped that 'name' would equal "a".  Bug?

A workaround is to use do.call();
"[[.A" <- function(x, name) { do.call("$", arg=list(x, name)) }
o[["a"]]   # $.A(x, a )

However, I would prefer not use do.call() because that adds quite a
extra overhead.

I guess I didn't understand the problem last time, which is also why I
went for UseMethod("$").

 >
> Aargh ... fixing one bug is not supposed to uncover three others.

One less for your update, but a new one in the old code.

Thanks

Henrik

>
> On Fri, 19 May 2006, Prof Brian Ripley wrote:
>
> > If I do
> >
> >> example(lm)
> > ...
> >> mycoef <- function(object, ...) UseMethod("coef", object)
> >> mycoef(lm.D9)
> > Error in mycoef(lm.D9) : no applicable method for "coef"
> >
> > which is pretty surprising, as coef has a default method.
> >
> > After a bit of digging, this comes from do_usemethod having
> >
> >        defenv = environment where the generic was defined */
> >     defenv = ENCLOS(env);
> >
> > so it is assuming that UseMethod() is called within the defining generic
> > for its first argument.  That plainly does not need to be true, e.g.
> >
> >> coefficients
> > function (object, ...)
> > UseMethod("coef")
> > <environment: namespace:stats>
> >
> > It is clear to me that we need to search for 'generic' and find its
> > defining environment rather than that of the current caller.  It is not
> > entirely clear where to search from as I think we need to avoid
> >
> > mycoef <- function(x)
> > {
> >    mycoef <- function(x) stop("not this one")
> >    UseMethod("mycoef")
> > }
> >
> > so I used ENCLOS(env).
> >
> > This adds some overhead, hopefully no more than searching for methods.
> >
> > BTW, I noticed that R_LookupMethod uses findVar, that is looks for any
> > object not for functions: that must be another infelicity.
> >
> >
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Peter.Ruckdeschel at uni-bayreuth.de  Mon May 22 22:26:17 2006
From: Peter.Ruckdeschel at uni-bayreuth.de (Peter Ruckdeschel)
Date: Mon, 22 May 2006 22:26:17 +0200
Subject: [Rd] confused by inheritance...
Message-ID: <44721E69.4070305@uni-bayreuth.de>

Hi r-devels,

I am stuck in some S4 inheritance problem:

setClass("A",representation(a="numeric"))
setClass("A1",representation(b="numeric"),contains="A")
setClass("A2",representation(c="numeric"),contains="A1")

if(!isGeneric("foo")){
    setGeneric("foo", function(x,y,z, ...) standardGeneric("foo"))
}

setMethod("foo",signature(x = "A", y = "missing", z = "missing"),
    function(x)x at a )
setMethod("foo",signature(x = "A1", y = "missing", z = "missing"),
    function(x)x at b )
setMethod("foo",signature(x = "A2", y = "missing", z = "missing"),
    function(x)x at c )
setMethod("foo",signature(x = "A1", y = "numeric", z = "missing"),
    function(x,y)c(x at b,y) )


x2 <- new("A2", a=1, b=2, c=3)

foo(x2)      ## gives 3 as it should
foo(x2,y=2)  ## casts to "A1" and gives (2,2) as it should
foo(x2)      ## now gives 2 as if x2 were permanently cast to "A1"
## However:
x2  ## of class "A2" as it should
getMethod("foo",signature(x = "A2", y = "missing", z = "missing"))
    ## function(x)x at c

### What has happened in the dispatching mechanism between
## in the line           foo(x2,y=2)             ?

I would appreciate any help.
Thanks for listening
Peter


From ggrothendieck at gmail.com  Tue May 23 05:24:55 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 22 May 2006 23:24:55 -0400
Subject: [Rd] Wishlist: Vignettes on CRAN
In-Reply-To: <67DCA285A2D7754280D3B8E88EB548020C946838@MSGBOSCLB2WIN.DMN1.FMR.COM>
References: <67DCA285A2D7754280D3B8E88EB548020C946838@MSGBOSCLB2WIN.DMN1.FMR.COM>
Message-ID: <971536df0605222024v3dc65986q5df8a8c370a03e18@mail.gmail.com>

This would certainly be nice.

Note that the BioConductor package vignettes are online:
   http://www.bioconductor.org/docs/vignettes.html
but there is nothing comparable for CRAN.

In some cases the package has a home page mentioned in the
URL field of the DESCRIPTION file and following that can sometimes
get vignette or other information although I agree we really need
a standardized way to discover that a vignette exists and to access
it without installing the package.

It would also be nice to be able to access the ChangeLog or NEWS
file online as well as from the installed package.  Currently one has
to download and unpack the source to get it in many cases and even
then one can't even be sure that it exists.  That's even worse than
the sitution with vignettes.

On 5/22/06, McGehee, Robert <Robert.McGehee at geodecapital.com> wrote:
> I was recently browsing through CRAN's Finance task view to remind
> myself of the publicly available packages relevant to my work. As the
> reference manuals are all online, I am able to flip through the
> available functions to get an idea of the package's scope before
> downloading.
>
> That said, many authors have taken the time to additionally provide a
> useful vignette which provides a better overview to complicated
> packages. However, as far as I can tell, the only way to read or even
> know if a package has a vignette is to first download and unpack the
> package source, which is inconvenient when one wants to understand a
> package _before_ installing.
>
> Perhaps an easy way to make vignettes more accessible to the end user
> would be to link the vignette PDF directly to the download page so that
> one could download it just as one can download the reference manual or
> package source. This both publicizes the vignette (since many users may
> even be unaware that a package has a vignette) and facilitates browsing.
>
> Just a thought!
>
> Best,
> Robert
>
> Robert McGehee
> Quantitative Analyst
> Geode Capital Management, LLC
> 53 State Street, 5th Floor | Boston, MA | 02109
> Tel: 617/392-8396    Fax:617/476-6389
> mailto:robert.mcgehee at geodecapital.com
>
>
>
> This e-mail, and any attachments hereto, are intended for us...{{dropped}}
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From edd at debian.org  Tue May 23 05:37:10 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 22 May 2006 22:37:10 -0500
Subject: [Rd] Wishlist: Vignettes on CRAN
In-Reply-To: <971536df0605222024v3dc65986q5df8a8c370a03e18@mail.gmail.com>
References: <67DCA285A2D7754280D3B8E88EB548020C946838@MSGBOSCLB2WIN.DMN1.FMR.COM>
	<971536df0605222024v3dc65986q5df8a8c370a03e18@mail.gmail.com>
Message-ID: <17522.33638.203005.805926@basebud.nulle.part>


On 22 May 2006 at 23:24, Gabor Grothendieck wrote:
| This would certainly be nice.
| 
| Note that the BioConductor package vignettes are online:
|    http://www.bioconductor.org/docs/vignettes.html
| but there is nothing comparable for CRAN.
| 
| In some cases the package has a home page mentioned in the
| URL field of the DESCRIPTION file and following that can sometimes
| get vignette or other information although I agree we really need
| a standardized way to discover that a vignette exists and to access
| it without installing the package.
| 
| It would also be nice to be able to access the ChangeLog or NEWS
| file online as well as from the installed package.  Currently one has
| to download and unpack the source to get it in many cases and even
| then one can't even be sure that it exists.  That's even worse than
| the sitution with vignettes.

If we agreed on a (voluntary, of course) format and location for NEWS and/or
ChangeLog, then it would be easy to parse these from freshly uploaded files
and do value-added tricks like RSS feeds of changes, new uploads, ...

Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From ggrothendieck at gmail.com  Tue May 23 06:21:18 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 23 May 2006 00:21:18 -0400
Subject: [Rd] Wishlist: Vignettes on CRAN
In-Reply-To: <17522.33638.203005.805926@basebud.nulle.part>
References: <67DCA285A2D7754280D3B8E88EB548020C946838@MSGBOSCLB2WIN.DMN1.FMR.COM>
	<971536df0605222024v3dc65986q5df8a8c370a03e18@mail.gmail.com>
	<17522.33638.203005.805926@basebud.nulle.part>
Message-ID: <971536df0605222121t22a932c7p29339d16b62d88d7@mail.gmail.com>

I currently put my NEWS file in ./inst as the build procedure will
automatically copy that to the main directory of the built distribution.
Thus it appears in
the installed distribution so at least one can get it without
also downloading and unpacking the source.  I also put a note in
mypkg-package.Rd that one can access it via:

   file.show(system.file("NEWS", package = "mypkg"))

where mypkg is the name of the package in this example.  Ditto
for THANKS, README and WISHLIST.   As an example:

library(dyn)
package?dyn

If the build procedure would not delete NEWS files from the
main directory of a package then they could be put there.
One idea might be to not delete any file that is all in caps.

On 5/22/06, Dirk Eddelbuettel <edd at debian.org> wrote:
>
> On 22 May 2006 at 23:24, Gabor Grothendieck wrote:
> | This would certainly be nice.
> |
> | Note that the BioConductor package vignettes are online:
> |    http://www.bioconductor.org/docs/vignettes.html
> | but there is nothing comparable for CRAN.
> |
> | In some cases the package has a home page mentioned in the
> | URL field of the DESCRIPTION file and following that can sometimes
> | get vignette or other information although I agree we really need
> | a standardized way to discover that a vignette exists and to access
> | it without installing the package.
> |
> | It would also be nice to be able to access the ChangeLog or NEWS
> | file online as well as from the installed package.  Currently one has
> | to download and unpack the source to get it in many cases and even
> | then one can't even be sure that it exists.  That's even worse than
> | the sitution with vignettes.
>
> If we agreed on a (voluntary, of course) format and location for NEWS and/or
> ChangeLog, then it would be easy to parse these from freshly uploaded files
> and do value-added tricks like RSS feeds of changes, new uploads, ...
>
> Dirk
>
> --
> Hell, there are no rules here - we're trying to accomplish something.
>                                                  -- Thomas A. Edison
>


From sfalcon at fhcrc.org  Tue May 23 06:42:34 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Mon, 22 May 2006 21:42:34 -0700
Subject: [Rd] Wishlist: Vignettes on CRAN
In-Reply-To: <971536df0605222024v3dc65986q5df8a8c370a03e18@mail.gmail.com>
	(Gabor Grothendieck's message of "Mon,
	22 May 2006 23:24:55 -0400")
References: <67DCA285A2D7754280D3B8E88EB548020C946838@MSGBOSCLB2WIN.DMN1.FMR.COM>
	<971536df0605222024v3dc65986q5df8a8c370a03e18@mail.gmail.com>
Message-ID: <m21wulxsg5.fsf@ziti.fhcrc.org>

"Gabor Grothendieck" <ggrothendieck at gmail.com> writes:

> This would certainly be nice.
>
> Note that the BioConductor package vignettes are online:
>    http://www.bioconductor.org/docs/vignettes.html
> but there is nothing comparable for CRAN.

That page is actually out of date (we'll be updating it real soon
now).  However, we are producing links to package vingnettes in the
automatically generated package summary pages.  For example, take a
look at the summary page for the Biobase package:

http://bioconductor.org/packages/1.8/bioc/html/Biobase.html

This was fairly easy to setup.  I would be happy to share the code,
etc.

Cheers,

+ seth


From khansen at stat.Berkeley.EDU  Tue May 23 08:39:31 2006
From: khansen at stat.Berkeley.EDU (Kasper Daniel Hansen)
Date: Mon, 22 May 2006 23:39:31 -0700
Subject: [Rd] protect
Message-ID: <35168A7B-DFA1-42F7-8763-7769B449005B@stat.berkeley.edu>

I have a few simple questions about the usage of PROTECT, more  
specifically how careful one needs to be. Simple yes/no answers are  
fine.

Most of the uses I have seen do protection when memory is allocated.  
But what if one just want to assign a value of another function to a  
variable. Say eg. that foo is a function that returns a SEXP. Would  
the following code be fine?

SEXP bar;
PROTECT(bar = foo());

Also, basically in one use case I would want to return the value of  
foo immediately, but I need to do some cleaning up first, which has  
nothing to do with R (more specifically, I need to close various  
files). Would I then need to protect foo, as in

SEXP bar;
bar = foo();
"close the file in C++"
return bar;

Finally, I am also assigning values to the components of a list.  
Would the following be ok

SEXP bar;
PROTECT(bar = NEW_LIST(2));
SET_VECTOR_ELT(bar, 0, ScalarInteger(test());

(where test is a function returning int, which again has nothing to  
do with R - it interfaces to an extern library), or do I need to  
hedge myself against garbage collection in the SET_VECTOR_ELT macro?

/Kasper


From ripley at stats.ox.ac.uk  Tue May 23 09:22:19 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 23 May 2006 08:22:19 +0100 (BST)
Subject: [Rd] protect
In-Reply-To: <35168A7B-DFA1-42F7-8763-7769B449005B@stat.berkeley.edu>
References: <35168A7B-DFA1-42F7-8763-7769B449005B@stat.berkeley.edu>
Message-ID: <Pine.LNX.4.64.0605230814250.17904@gannet.stats.ox.ac.uk>

On Mon, 22 May 2006, Kasper Daniel Hansen wrote:

> I have a few simple questions about the usage of PROTECT, more
> specifically how careful one needs to be. Simple yes/no answers are
> fine.

(Except that in the last case they would be misleading.)

> Most of the uses I have seen do protection when memory is allocated.
> But what if one just want to assign a value of another function to a
> variable. Say eg. that foo is a function that returns a SEXP. Would
> the following code be fine?
>
> SEXP bar;
> PROTECT(bar = foo());

It would be fine but may be unnecessary.  It is objects and not pointers 
which are protected, and a SEXP is a pointer.  So protection is needed 
only if foo() might return a pointer to an unprotected object.

> Also, basically in one use case I would want to return the value of
> foo immediately, but I need to do some cleaning up first, which has
> nothing to do with R (more specifically, I need to close various
> files). Would I then need to protect foo, as in
>
> SEXP bar;
> bar = foo();
> "close the file in C++"
> return bar;

Fine, as PROTECT protects against R garbage collection, and that can only 
happen if R's functions are called.

> Finally, I am also assigning values to the components of a list.
> Would the following be ok
>
> SEXP bar;
> PROTECT(bar = NEW_LIST(2));
> SET_VECTOR_ELT(bar, 0, ScalarInteger(test());
>
> (where test is a function returning int, which again has nothing to
> do with R - it interfaces to an extern library), or do I need to
> hedge myself against garbage collection in the SET_VECTOR_ELT macro?

You do need to protect but elsewhere in this call, as ScalarInteger does 
memory allocation:

INLINE_FUN SEXP ScalarInteger(int x)
{
     SEXP ans = allocVector(INTSXP, 1);
     INTEGER(ans)[0] = x;
     return ans;
}

but SET_VECTOR_ELT does not.  So you need

SEXP bar, tmp;
PROTECT(bar = NEW_LIST(2));
PROTECT(tmp = test());
SET_VECTOR_ELT(bar, 0, ScalarInteger(tmp);
UNPROTECT(1);


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Kurt.Hornik at wu-wien.ac.at  Tue May 23 09:38:50 2006
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Tue, 23 May 2006 09:38:50 +0200
Subject: [Rd] Wishlist: Vignettes on CRAN
In-Reply-To: <17522.33638.203005.805926@basebud.nulle.part>
References: <67DCA285A2D7754280D3B8E88EB548020C946838@MSGBOSCLB2WIN.DMN1.FMR.COM>
	<971536df0605222024v3dc65986q5df8a8c370a03e18@mail.gmail.com>
	<17522.33638.203005.805926@basebud.nulle.part>
Message-ID: <17522.48138.724818.96939@mithrandir.hornik.net>

>>>>> Dirk Eddelbuettel writes:

> On 22 May 2006 at 23:24, Gabor Grothendieck wrote:
> | This would certainly be nice.
> | 
> | Note that the BioConductor package vignettes are online:
> |    http://www.bioconductor.org/docs/vignettes.html
> | but there is nothing comparable for CRAN.
> | 
> | In some cases the package has a home page mentioned in the
> | URL field of the DESCRIPTION file and following that can sometimes
> | get vignette or other information although I agree we really need
> | a standardized way to discover that a vignette exists and to access
> | it without installing the package.
> | 
> | It would also be nice to be able to access the ChangeLog or NEWS
> | file online as well as from the installed package.  Currently one has
> | to download and unpack the source to get it in many cases and even
> | then one can't even be sure that it exists.  That's even worse than
> | the sitution with vignettes.

> If we agreed on a (voluntary, of course) format and location for NEWS
> and/or ChangeLog, then it would be easy to parse these from freshly
> uploaded files and do value-added tricks like RSS feeds of changes,
> new uploads, ...

I still don't think there can be one format to agree upon.  Imho it
would be better to have package (DESCRIPTION) metadata pointing to the
changelog/news db and maybe also providing an indication of its format.

-k


From Kurt.Hornik at wu-wien.ac.at  Tue May 23 09:42:07 2006
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Tue, 23 May 2006 09:42:07 +0200
Subject: [Rd] Wishlist: Vignettes on CRAN
In-Reply-To: <67DCA285A2D7754280D3B8E88EB548020C946838@MSGBOSCLB2WIN.DMN1.FMR.COM>
References: <67DCA285A2D7754280D3B8E88EB548020C946838@MSGBOSCLB2WIN.DMN1.FMR.COM>
Message-ID: <17522.48335.219086.433310@mithrandir.hornik.net>

>>>>> McGehee, Robert writes:

> I was recently browsing through CRAN's Finance task view to remind
> myself of the publicly available packages relevant to my work. As the
> reference manuals are all online, I am able to flip through the
> available functions to get an idea of the package's scope before
> downloading. 

> That said, many authors have taken the time to additionally provide a
> useful vignette which provides a better overview to complicated
> packages. However, as far as I can tell, the only way to read or even
> know if a package has a vignette is to first download and unpack the
> package source, which is inconvenient when one wants to understand a
> package _before_ installing.

> Perhaps an easy way to make vignettes more accessible to the end user
> would be to link the vignette PDF directly to the download page so
> that one could download it just as one can download the reference
> manual or package source. This both publicizes the vignette (since
> many users may even be unaware that a package has a vignette) and
> facilitates browsing.

Yes, that would be very useful.

Will have a look, but this looks like something for the summer break.

Best
-k


From nakama at ki.rim.or.jp  Tue May 23 09:54:12 2006
From: nakama at ki.rim.or.jp (Ei-ji Nakama)
Date: Tue, 23 May 2006 16:54:12 +0900
Subject: [Rd] Sys.setlocale upsets windows graphics device (PR#8887)
In-Reply-To: <Pine.LNX.4.64.0605221708150.10069@gannet.stats.ox.ac.uk>
References: <20060522080131.A0A2619A4F@slim.kubism.ku.dk>
	<dc41e1260605220701u5cbe3d1r6742a7e85b48c272@mail.gmail.com>
	<Pine.LNX.4.64.0605221708150.10069@gannet.stats.ox.ac.uk>
Message-ID: <dc41e1260605230054y1fda3723s59181042d2b23018@mail.gmail.com>

It clash similarly in the Japanese locale.

localeCP!= GetACP() .
It dies from msvcrt (mb*) the case where NULL is specified.

diff -ruN R-2.3.0.orig/src/gnuwin32/graphapp/buttons.c
R-2.3.0/src/gnuwin32/graphapp/buttons.c
--- R-2.3.0.orig/src/gnuwin32/graphapp/buttons.c        Mon Apr 10 07:20:00 2006
+++ R-2.3.0/src/gnuwin32/graphapp/buttons.c     Tue May 23 16:26:51 2006
@@ -132,9 +132,16 @@

        if(is_NT && (localeCP != GetACP())) {
            wchar_t wkind[100], wc[1000];
-           mbstowcs(wkind, kind, 100);
-           mbstowcs(wc, text, 1000);
-           hwnd = CreateWindowW(wkind, wc,
+           wchar_t *wkindp=wkind, *wcp=wc;
+           if(kind)
+               mbstowcs(wkindp, kind, 100);
+           else
+               wkindp=NULL;
+           if(text)
+               mbstowcs(wcp, text, 1000);
+           else
+               wcp=NULL;
+           hwnd = CreateWindowW(wkindp, wcp,
                                 (WS_CHILD | WS_VISIBLE) | style,
                                 r.x, r.y, r.width, r.height,
                                 current_window->handle,
diff -ruN R-2.3.0.orig/src/gnuwin32/graphapp/menus.c
R-2.3.0/src/gnuwin32/graphapp/menus.c
--- R-2.3.0.orig/src/gnuwin32/graphapp/menus.c  Mon Apr 10 07:20:00 2006
+++ R-2.3.0/src/gnuwin32/graphapp/menus.c       Tue May 23 15:36:14 2006
@@ -302,9 +302,12 @@
 BOOL myAppendMenu(HMENU h, UINT flags, UINT id, LPCTSTR name)
 {
     if(is_NT && (localeCP != GetACP())) {
-       wchar_t wc[100];
-       mbstowcs(wc, name, 100);
-       return AppendMenuW(h, flags, id, wc);
+       wchar_t wc[100], *wcp=wc;
+       if (name)
+         mbstowcs(wcp, name, 100);
+       else
+         wcp=NULL;
+       return AppendMenuW(h, flags, id, wcp);
     } else
        return AppendMenuA(h, flags, id, name);
 }
diff -ruN R-2.3.0.orig/src/gnuwin32/graphapp/windows.c
R-2.3.0/src/gnuwin32/graphapp/windows.c
--- R-2.3.0.orig/src/gnuwin32/graphapp/windows.c        Mon Apr 10 07:20:00 2006
+++ R-2.3.0/src/gnuwin32/graphapp/windows.c     Tue May 23 16:39:23 2006
@@ -455,13 +455,21 @@

                if(is_NT && (localeCP != GetACP())) {
                    wchar_t wkind[100], wc[1000];
-                   mbstowcs(wkind, (flags & Workspace) ? work_class_name
-                            : win_class_name, 100);
-                   mbstowcs(wc, name, 1000);
+                   wchar_t *wkindp=wkind, *wcp=wc;
+                   if((flags & Workspace) ? work_class_name
+                      : win_class_name)
+                       mbstowcs(wkindp, (flags & Workspace) ? work_class_name
+                                : win_class_name, 100);
+                   else
+                     wkindp=NULL;
+                   if(name)
+                       mbstowcs(wcp, name, 1000);
+                   else
+                       wcp=NULL;
                    hwnd = CreateWindowExW(
                        ex_style,
-                       wkind,
-                       wc, win_style,
+                       wkindp,
+                       wcp, win_style,
                        r.x, r.y, r.width, r.height,
                        (HWND) ((flags & ChildWindow) ?
                                current_window->handle : 0),


2006/5/23, Prof Brian Ripley <ripley at stats.ox.ac.uk>:
> On Mon, 22 May 2006, Ei-ji Nakama wrote:
>
> > If a return value of locale does not have a period, a function of libmingwex
> > gives back NULL in strchr and refers to NULL pointer in atoi.
> >
> > But it will be right to fix mingw...
> >
> > --- locales.R.orig      Mon Apr 10 07:19:19 2006
> > +++ locales.R   Mon May 22 22:55:21 2006
> > @@ -10,6 +10,7 @@
> > {
> >     category <- match(category, c("LC_ALL", "LC_COLLATE", "LC_CTYPE",
> >                                   "LC_MONETARY", "LC_NUMERIC", "LC_TIME"))
> > +    if(locale == "C") locale = "English_United States.1252");
> >     if(is.na(category)) stop("invalid 'category' argument")
> >     .Internal(setlocale(category, locale))
> > }
>
> Unfortunately that does not affect e.g. 'Rgui LC_ALL=C' so a more
> comprehensive C-level fix would be needed.
>
> I did wonder if mingwex was the problem, but in theory at least it knows
> about the C locale (cp = 0), and the crash was coming from MSVCRT.dll, in
> the conversion of an ASCII string to wchar.  Since it works in other
> Windows base locales it did seem specific to Thai (which is still a
> single-byte locale).
>
>
> > 2006/5/22, ripley at stats.ox.ac.uk <ripley at stats.ox.ac.uk>:
> >> On Mon, 22 May 2006, Edward wrote:
> >>
> >>> Hi,
> >>> We tried it on 3 separate windows XP computers using version 2.3.0.
> >>> The original locale is set for Thailand on all 3.
> >>> So how do we fix it? Is there another patch?
> >>
> >> Don't try to do graphics in the C locale on your computer?
> >>
> >> I suspect this is a font problem in Windows, in that your fonts may be
> >> specific to the Thai localization.  But without a means of reproducing
> >> this, I can only guess.
> >>
> >> If you can set up a debugger (see the rw-FAQ), you may be able to give us
> >> some additional clues as the where the crash is occuring.
> >>
> >>> And why does the crash not happen with earlier R versions (eg. 2.2.1) on the
> >>> same computer?
> >>
> >> Because of the issue mentioned in the CHANGES file, the change to the C
> >> locale was reverted by opening a graphics window.
> >>
> >>>
> >>> ---
> >>>> Sys.getlocale()
> >>> [1]
> >>> "LC_COLLATE=Thai_Thailand.874;LC_CTYPE=Thai_Thailand.874;LC_MONETARY=Thai_Thailand.874;LC_NUMERIC=C;LC_TIME=Thai_Thailand.874"
> >>> ---
> >>>
> >>> Thanks
> >>> Edward
> >>>
> >>> ----- Original Message ----- From: "Prof Brian Ripley"
> >>> <ripley at stats.ox.ac.uk>
> >>> To: <edward.m at psu.ac.th>
> >>> Cc: <R-bugs at biostat.ku.dk>
> >>> Sent: Monday, May 22, 2006 2:32 PM
> >>> Subject: Re: [Rd] Sys.setlocale upsets windows graphics device (PR#8887)
> >>>
> >>>
> >>>> Works perfectly for me.  There was a bug in 2.2.1, but it was fixed in
> >>>> 2.2.1 patched (see CHANGES).
> >>>>
> >>>> What locale were you changing from?  (This might be a Windows problem
> >>>> specific to your locale.)
> >>>>
> >>>> On Mon, 22 May 2006, edward.m at psu.ac.th wrote:
> >>>>
> >>>>> Full_Name: Edward McNeil
> >>>>> Version: 2.3.0
> >>>>> OS: Widows XP
> >>>>> Submission from: (NULL) (203.170.234.5)
> >>>>>
> >>>>>
> >>>>> Type the following:
> >>>>>
> >>>>>> Sys.setlocale("LC_ALL","C")
> >>>>>> hist(1:10)
> >>>>>
> >>>>> CRASH
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-devel at r-project.org mailing list
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>>>
> >>>>>
> >>>>
> >>>> --
> >>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> >>>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> >>>> University of Oxford,             Tel:  +44 1865 272861 (self)
> >>>> 1 South Parks Road,                     +44 1865 272866 (PA)
> >>>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >>>
> >>>
> >>
> >> --
> >> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> >> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> >> University of Oxford,             Tel:  +44 1865 272861 (self)
> >> 1 South Parks Road,                     +44 1865 272866 (PA)
> >> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >
> >
> >
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>


-- 
EI-JI Nakama  <nakama at ki.rim.or.jp>
"\u4e2d\u9593\u6804\u6cbb"  <nakama at ki.rim.or.jp>


From ripley at stats.ox.ac.uk  Tue May 23 09:55:42 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 23 May 2006 08:55:42 +0100 (BST)
Subject: [Rd] protect
In-Reply-To: <Pine.LNX.4.64.0605230814250.17904@gannet.stats.ox.ac.uk>
References: <35168A7B-DFA1-42F7-8763-7769B449005B@stat.berkeley.edu>
	<Pine.LNX.4.64.0605230814250.17904@gannet.stats.ox.ac.uk>
Message-ID: <Pine.LNX.4.64.0605230852590.23195@gannet.stats.ox.ac.uk>

On Tue, 23 May 2006, Prof Brian Ripley wrote:

> On Mon, 22 May 2006, Kasper Daniel Hansen wrote:
>
>> I have a few simple questions about the usage of PROTECT, more
>> specifically how careful one needs to be. Simple yes/no answers are
>> fine.
>
> (Except that in the last case they would be misleading.)
>
>> Most of the uses I have seen do protection when memory is allocated.
>> But what if one just want to assign a value of another function to a
>> variable. Say eg. that foo is a function that returns a SEXP. Would
>> the following code be fine?
>>
>> SEXP bar;
>> PROTECT(bar = foo());
>
> It would be fine but may be unnecessary.  It is objects and not pointers
> which are protected, and a SEXP is a pointer.  So protection is needed
> only if foo() might return a pointer to an unprotected object.
>
>> Also, basically in one use case I would want to return the value of
>> foo immediately, but I need to do some cleaning up first, which has
>> nothing to do with R (more specifically, I need to close various
>> files). Would I then need to protect foo, as in
>>
>> SEXP bar;
>> bar = foo();
>> "close the file in C++"
>> return bar;
>
> Fine, as PROTECT protects against R garbage collection, and that can only
> happen if R's functions are called.
>
>> Finally, I am also assigning values to the components of a list.
>> Would the following be ok
>>
>> SEXP bar;
>> PROTECT(bar = NEW_LIST(2));
>> SET_VECTOR_ELT(bar, 0, ScalarInteger(test());
>>
>> (where test is a function returning int, which again has nothing to
>> do with R - it interfaces to an extern library), or do I need to
>> hedge myself against garbage collection in the SET_VECTOR_ELT macro?
>
> You do need to protect but elsewhere in this call, as ScalarInteger does
> memory allocation:
>
> INLINE_FUN SEXP ScalarInteger(int x)
> {
>     SEXP ans = allocVector(INTSXP, 1);
>     INTEGER(ans)[0] = x;
>     return ans;
> }
>
> but SET_VECTOR_ELT does not.  So you need
>
> SEXP bar, tmp;
> PROTECT(bar = NEW_LIST(2));
> PROTECT(tmp = test());
> SET_VECTOR_ELT(bar, 0, ScalarInteger(tmp));
> UNPROTECT(1);

Or a design that uses fewer PROTECTs

SEXP bar, tmp;
PROTECT(bar = allocVector(VECSXP, 2));
tmp = allocVector(INTSXP, 1);
SET_VECTOR_ELT(bar, 0, tmp);
INTEGER(tmp)[0] = test();

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Tue May 23 10:45:45 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 23 May 2006 09:45:45 +0100 (BST)
Subject: [Rd] Sys.setlocale upsets windows graphics device (PR#8887)
In-Reply-To: <dc41e1260605230054y1fda3723s59181042d2b23018@mail.gmail.com>
References: <20060522080131.A0A2619A4F@slim.kubism.ku.dk>
	<dc41e1260605220701u5cbe3d1r6742a7e85b48c272@mail.gmail.com>
	<Pine.LNX.4.64.0605221708150.10069@gannet.stats.ox.ac.uk>
	<dc41e1260605230054y1fda3723s59181042d2b23018@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0605230944210.26756@gannet.stats.ox.ac.uk>

Is this necessary to avoid LC_CTYPE="C"?  If so, I stopped that at C level 
yesterday (it was already disallowed when starting R).

On Tue, 23 May 2006, Ei-ji Nakama wrote:

> It clash similarly in the Japanese locale.
>
> localeCP!= GetACP() .
> It dies from msvcrt (mb*) the case where NULL is specified.
>
> diff -ruN R-2.3.0.orig/src/gnuwin32/graphapp/buttons.c
> R-2.3.0/src/gnuwin32/graphapp/buttons.c
> --- R-2.3.0.orig/src/gnuwin32/graphapp/buttons.c        Mon Apr 10 07:20:00 2006
> +++ R-2.3.0/src/gnuwin32/graphapp/buttons.c     Tue May 23 16:26:51 2006
> @@ -132,9 +132,16 @@
>
>        if(is_NT && (localeCP != GetACP())) {
>            wchar_t wkind[100], wc[1000];
> -           mbstowcs(wkind, kind, 100);
> -           mbstowcs(wc, text, 1000);
> -           hwnd = CreateWindowW(wkind, wc,
> +           wchar_t *wkindp=wkind, *wcp=wc;
> +           if(kind)
> +               mbstowcs(wkindp, kind, 100);
> +           else
> +               wkindp=NULL;
> +           if(text)
> +               mbstowcs(wcp, text, 1000);
> +           else
> +               wcp=NULL;
> +           hwnd = CreateWindowW(wkindp, wcp,
>                                 (WS_CHILD | WS_VISIBLE) | style,
>                                 r.x, r.y, r.width, r.height,
>                                 current_window->handle,
> diff -ruN R-2.3.0.orig/src/gnuwin32/graphapp/menus.c
> R-2.3.0/src/gnuwin32/graphapp/menus.c
> --- R-2.3.0.orig/src/gnuwin32/graphapp/menus.c  Mon Apr 10 07:20:00 2006
> +++ R-2.3.0/src/gnuwin32/graphapp/menus.c       Tue May 23 15:36:14 2006
> @@ -302,9 +302,12 @@
> BOOL myAppendMenu(HMENU h, UINT flags, UINT id, LPCTSTR name)
> {
>     if(is_NT && (localeCP != GetACP())) {
> -       wchar_t wc[100];
> -       mbstowcs(wc, name, 100);
> -       return AppendMenuW(h, flags, id, wc);
> +       wchar_t wc[100], *wcp=wc;
> +       if (name)
> +         mbstowcs(wcp, name, 100);
> +       else
> +         wcp=NULL;
> +       return AppendMenuW(h, flags, id, wcp);
>     } else
>        return AppendMenuA(h, flags, id, name);
> }
> diff -ruN R-2.3.0.orig/src/gnuwin32/graphapp/windows.c
> R-2.3.0/src/gnuwin32/graphapp/windows.c
> --- R-2.3.0.orig/src/gnuwin32/graphapp/windows.c        Mon Apr 10 07:20:00 2006
> +++ R-2.3.0/src/gnuwin32/graphapp/windows.c     Tue May 23 16:39:23 2006
> @@ -455,13 +455,21 @@
>
>                if(is_NT && (localeCP != GetACP())) {
>                    wchar_t wkind[100], wc[1000];
> -                   mbstowcs(wkind, (flags & Workspace) ? work_class_name
> -                            : win_class_name, 100);
> -                   mbstowcs(wc, name, 1000);
> +                   wchar_t *wkindp=wkind, *wcp=wc;
> +                   if((flags & Workspace) ? work_class_name
> +                      : win_class_name)
> +                       mbstowcs(wkindp, (flags & Workspace) ? work_class_name
> +                                : win_class_name, 100);
> +                   else
> +                     wkindp=NULL;
> +                   if(name)
> +                       mbstowcs(wcp, name, 1000);
> +                   else
> +                       wcp=NULL;
>                    hwnd = CreateWindowExW(
>                        ex_style,
> -                       wkind,
> -                       wc, win_style,
> +                       wkindp,
> +                       wcp, win_style,
>                        r.x, r.y, r.width, r.height,
>                        (HWND) ((flags & ChildWindow) ?
>                                current_window->handle : 0),
>
>
> 2006/5/23, Prof Brian Ripley <ripley at stats.ox.ac.uk>:
>> On Mon, 22 May 2006, Ei-ji Nakama wrote:
>>
>>> If a return value of locale does not have a period, a function of libmingwex
>>> gives back NULL in strchr and refers to NULL pointer in atoi.
>>>
>>> But it will be right to fix mingw...
>>>
>>> --- locales.R.orig      Mon Apr 10 07:19:19 2006
>>> +++ locales.R   Mon May 22 22:55:21 2006
>>> @@ -10,6 +10,7 @@
>>> {
>>>     category <- match(category, c("LC_ALL", "LC_COLLATE", "LC_CTYPE",
>>>                                   "LC_MONETARY", "LC_NUMERIC", "LC_TIME"))
>>> +    if(locale == "C") locale = "English_United States.1252");
>>>     if(is.na(category)) stop("invalid 'category' argument")
>>>     .Internal(setlocale(category, locale))
>>> }
>>
>> Unfortunately that does not affect e.g. 'Rgui LC_ALL=C' so a more
>> comprehensive C-level fix would be needed.
>>
>> I did wonder if mingwex was the problem, but in theory at least it knows
>> about the C locale (cp = 0), and the crash was coming from MSVCRT.dll, in
>> the conversion of an ASCII string to wchar.  Since it works in other
>> Windows base locales it did seem specific to Thai (which is still a
>> single-byte locale).
>>
>>
>>> 2006/5/22, ripley at stats.ox.ac.uk <ripley at stats.ox.ac.uk>:
>>>> On Mon, 22 May 2006, Edward wrote:
>>>>
>>>>> Hi,
>>>>> We tried it on 3 separate windows XP computers using version 2.3.0.
>>>>> The original locale is set for Thailand on all 3.
>>>>> So how do we fix it? Is there another patch?
>>>>
>>>> Don't try to do graphics in the C locale on your computer?
>>>>
>>>> I suspect this is a font problem in Windows, in that your fonts may be
>>>> specific to the Thai localization.  But without a means of reproducing
>>>> this, I can only guess.
>>>>
>>>> If you can set up a debugger (see the rw-FAQ), you may be able to give us
>>>> some additional clues as the where the crash is occuring.
>>>>
>>>>> And why does the crash not happen with earlier R versions (eg. 2.2.1) on the
>>>>> same computer?
>>>>
>>>> Because of the issue mentioned in the CHANGES file, the change to the C
>>>> locale was reverted by opening a graphics window.
>>>>
>>>>>
>>>>> ---
>>>>>> Sys.getlocale()
>>>>> [1]
>>>>> "LC_COLLATE=Thai_Thailand.874;LC_CTYPE=Thai_Thailand.874;LC_MONETARY=Thai_Thailand.874;LC_NUMERIC=C;LC_TIME=Thai_Thailand.874"
>>>>> ---
>>>>>
>>>>> Thanks
>>>>> Edward
>>>>>
>>>>> ----- Original Message ----- From: "Prof Brian Ripley"
>>>>> <ripley at stats.ox.ac.uk>
>>>>> To: <edward.m at psu.ac.th>
>>>>> Cc: <R-bugs at biostat.ku.dk>
>>>>> Sent: Monday, May 22, 2006 2:32 PM
>>>>> Subject: Re: [Rd] Sys.setlocale upsets windows graphics device (PR#8887)
>>>>>
>>>>>
>>>>>> Works perfectly for me.  There was a bug in 2.2.1, but it was fixed in
>>>>>> 2.2.1 patched (see CHANGES).
>>>>>>
>>>>>> What locale were you changing from?  (This might be a Windows problem
>>>>>> specific to your locale.)
>>>>>>
>>>>>> On Mon, 22 May 2006, edward.m at psu.ac.th wrote:
>>>>>>
>>>>>>> Full_Name: Edward McNeil
>>>>>>> Version: 2.3.0
>>>>>>> OS: Widows XP
>>>>>>> Submission from: (NULL) (203.170.234.5)
>>>>>>>
>>>>>>>
>>>>>>> Type the following:
>>>>>>>
>>>>>>>> Sys.setlocale("LC_ALL","C")
>>>>>>>> hist(1:10)
>>>>>>>
>>>>>>> CRASH
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-devel at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>>
>>>>>>>
>>>>>>
>>>>>> --
>>>>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>>>>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>>>>> University of Oxford,             Tel:  +44 1865 272861 (self)
>>>>>> 1 South Parks Road,                     +44 1865 272866 (PA)
>>>>>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>>>>
>>>>>
>>>>
>>>> --
>>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>>> University of Oxford,             Tel:  +44 1865 272861 (self)
>>>> 1 South Parks Road,                     +44 1865 272866 (PA)
>>>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>>
>>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jmc at r-project.org  Tue May 23 15:12:24 2006
From: jmc at r-project.org (John Chambers)
Date: Tue, 23 May 2006 09:12:24 -0400
Subject: [Rd] confused by inheritance...
In-Reply-To: <44721E69.4070305@uni-bayreuth.de>
References: <44721E69.4070305@uni-bayreuth.de>
Message-ID: <44730A38.50301@r-project.org>

This may be related to the problems with "greedy" search for inherited 
methods discussed previously on this list (or may not, it's a bit 
different).

In any case, the likely fix will be a substantial cleaning up of generic 
functions hoped for in the next release.

Meanwhile, "Keep it simple" is the best advice (and a good idea 
anyway).  If you remove the irrelevant z= part of the signatures, the 
anomalous result goes away.

By the way, the getMethod() in your example tells us nothing, since it 
does not use inheritance.  See its documentation.  If you use 
selectMethod() you see the same result as the method dispatch.

Peter Ruckdeschel wrote:

>Hi r-devels,
>
>I am stuck in some S4 inheritance problem:
>
>setClass("A",representation(a="numeric"))
>setClass("A1",representation(b="numeric"),contains="A")
>setClass("A2",representation(c="numeric"),contains="A1")
>
>if(!isGeneric("foo")){
>    setGeneric("foo", function(x,y,z, ...) standardGeneric("foo"))
>}
>
>setMethod("foo",signature(x = "A", y = "missing", z = "missing"),
>    function(x)x at a )
>setMethod("foo",signature(x = "A1", y = "missing", z = "missing"),
>    function(x)x at b )
>setMethod("foo",signature(x = "A2", y = "missing", z = "missing"),
>    function(x)x at c )
>setMethod("foo",signature(x = "A1", y = "numeric", z = "missing"),
>    function(x,y)c(x at b,y) )
>
>
>x2 <- new("A2", a=1, b=2, c=3)
>
>foo(x2)      ## gives 3 as it should
>foo(x2,y=2)  ## casts to "A1" and gives (2,2) as it should
>foo(x2)      ## now gives 2 as if x2 were permanently cast to "A1"
>## However:
>x2  ## of class "A2" as it should
>getMethod("foo",signature(x = "A2", y = "missing", z = "missing"))
>    ## function(x)x at c
>
>### What has happened in the dispatching mechanism between
>## in the line           foo(x2,y=2)             ?
>
>I would appreciate any help.
>Thanks for listening
>Peter
>
>______________________________________________
>R-devel at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel
>
>  
>


From edd at debian.org  Tue May 23 16:22:41 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 23 May 2006 09:22:41 -0500
Subject: [Rd] Wishlist: Vignettes on CRAN
In-Reply-To: <971536df0605222121t22a932c7p29339d16b62d88d7@mail.gmail.com>
References: <67DCA285A2D7754280D3B8E88EB548020C946838@MSGBOSCLB2WIN.DMN1.FMR.COM>
	<971536df0605222024v3dc65986q5df8a8c370a03e18@mail.gmail.com>
	<17522.33638.203005.805926@basebud.nulle.part>
	<971536df0605222121t22a932c7p29339d16b62d88d7@mail.gmail.com>
Message-ID: <20060523142241.GA25197@eddelbuettel.com>

On Tue, May 23, 2006 at 12:21:18AM -0400, Gabor Grothendieck wrote:
> I currently put my NEWS file in ./inst as the build procedure will

Yes, but for what I suggested we need standardized location as well as
format to permit automatic extraction, formatting, processing, ... off-line. 
For just one glimpse at that consider Debian's changelog site at
changelog.debian.net (NB .net not .org as it is a contributed site), and
eg 
	     http://changelog.debian.net/r-base
for a nine-year maintenance history of R within Debian.

I really want summaries to pop up in my rss reader to glance at what was
updated on CRAN.  But as Kurt pointed out, that may be Quixotic. Too bad.

Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From nakama at ki.rim.or.jp  Tue May 23 16:27:21 2006
From: nakama at ki.rim.or.jp (Ei-ji Nakama)
Date: Tue, 23 May 2006 23:27:21 +0900
Subject: [Rd] Sys.setlocale upsets windows graphics device (PR#8887)
In-Reply-To: <Pine.LNX.4.64.0605230944210.26756@gannet.stats.ox.ac.uk>
References: <20060522080131.A0A2619A4F@slim.kubism.ku.dk>
	<dc41e1260605220701u5cbe3d1r6742a7e85b48c272@mail.gmail.com>
	<Pine.LNX.4.64.0605221708150.10069@gannet.stats.ox.ac.uk>
	<dc41e1260605230054y1fda3723s59181042d2b23018@mail.gmail.com>
	<Pine.LNX.4.64.0605230944210.26756@gannet.stats.ox.ac.uk>
Message-ID: <dc41e1260605230727s15240302g86f490a3ddd59ec8@mail.gmail.com>

 Yes, if this processing does not exist on japanese locale
will fall.

2006/5/23, Prof Brian Ripley <ripley at stats.ox.ac.uk>:
> Is this necessary to avoid LC_CTYPE="C"?  If so, I stopped that at C level
> yesterday (it was already disallowed when starting R).
>
> On Tue, 23 May 2006, Ei-ji Nakama wrote:
>
> > It clash similarly in the Japanese locale.
> >
> > localeCP!= GetACP() .
> > It dies from msvcrt (mb*) the case where NULL is specified.
> >
> > diff -ruN R-2.3.0.orig/src/gnuwin32/graphapp/buttons.c
> > R-2.3.0/src/gnuwin32/graphapp/buttons.c
> > --- R-2.3.0.orig/src/gnuwin32/graphapp/buttons.c        Mon Apr 10 07:20:00 2006
> > +++ R-2.3.0/src/gnuwin32/graphapp/buttons.c     Tue May 23 16:26:51 2006
> > @@ -132,9 +132,16 @@
> >
> >        if(is_NT && (localeCP != GetACP())) {
> >            wchar_t wkind[100], wc[1000];
> > -           mbstowcs(wkind, kind, 100);
> > -           mbstowcs(wc, text, 1000);
> > -           hwnd = CreateWindowW(wkind, wc,
> > +           wchar_t *wkindp=wkind, *wcp=wc;
> > +           if(kind)
> > +               mbstowcs(wkindp, kind, 100);
> > +           else
> > +               wkindp=NULL;
> > +           if(text)
> > +               mbstowcs(wcp, text, 1000);
> > +           else
> > +               wcp=NULL;
> > +           hwnd = CreateWindowW(wkindp, wcp,
> >                                 (WS_CHILD | WS_VISIBLE) | style,
> >                                 r.x, r.y, r.width, r.height,
> >                                 current_window->handle,
> > diff -ruN R-2.3.0.orig/src/gnuwin32/graphapp/menus.c
> > R-2.3.0/src/gnuwin32/graphapp/menus.c
> > --- R-2.3.0.orig/src/gnuwin32/graphapp/menus.c  Mon Apr 10 07:20:00 2006
> > +++ R-2.3.0/src/gnuwin32/graphapp/menus.c       Tue May 23 15:36:14 2006
> > @@ -302,9 +302,12 @@
> > BOOL myAppendMenu(HMENU h, UINT flags, UINT id, LPCTSTR name)
> > {
> >     if(is_NT && (localeCP != GetACP())) {
> > -       wchar_t wc[100];
> > -       mbstowcs(wc, name, 100);
> > -       return AppendMenuW(h, flags, id, wc);
> > +       wchar_t wc[100], *wcp=wc;
> > +       if (name)
> > +         mbstowcs(wcp, name, 100);
> > +       else
> > +         wcp=NULL;
> > +       return AppendMenuW(h, flags, id, wcp);
> >     } else
> >        return AppendMenuA(h, flags, id, name);
> > }
> > diff -ruN R-2.3.0.orig/src/gnuwin32/graphapp/windows.c
> > R-2.3.0/src/gnuwin32/graphapp/windows.c
> > --- R-2.3.0.orig/src/gnuwin32/graphapp/windows.c        Mon Apr 10 07:20:00 2006
> > +++ R-2.3.0/src/gnuwin32/graphapp/windows.c     Tue May 23 16:39:23 2006
> > @@ -455,13 +455,21 @@
> >
> >                if(is_NT && (localeCP != GetACP())) {
> >                    wchar_t wkind[100], wc[1000];
> > -                   mbstowcs(wkind, (flags & Workspace) ? work_class_name
> > -                            : win_class_name, 100);
> > -                   mbstowcs(wc, name, 1000);
> > +                   wchar_t *wkindp=wkind, *wcp=wc;
> > +                   if((flags & Workspace) ? work_class_name
> > +                      : win_class_name)
> > +                       mbstowcs(wkindp, (flags & Workspace) ? work_class_name
> > +                                : win_class_name, 100);
> > +                   else
> > +                     wkindp=NULL;
> > +                   if(name)
> > +                       mbstowcs(wcp, name, 1000);
> > +                   else
> > +                       wcp=NULL;
> >                    hwnd = CreateWindowExW(
> >                        ex_style,
> > -                       wkind,
> > -                       wc, win_style,
> > +                       wkindp,
> > +                       wcp, win_style,
> >                        r.x, r.y, r.width, r.height,
> >                        (HWND) ((flags & ChildWindow) ?
> >                                current_window->handle : 0),
> >
> >
> > 2006/5/23, Prof Brian Ripley <ripley at stats.ox.ac.uk>:
> >> On Mon, 22 May 2006, Ei-ji Nakama wrote:
> >>
> >>> If a return value of locale does not have a period, a function of libmingwex
> >>> gives back NULL in strchr and refers to NULL pointer in atoi.
> >>>
> >>> But it will be right to fix mingw...
> >>>
> >>> --- locales.R.orig      Mon Apr 10 07:19:19 2006
> >>> +++ locales.R   Mon May 22 22:55:21 2006
> >>> @@ -10,6 +10,7 @@
> >>> {
> >>>     category <- match(category, c("LC_ALL", "LC_COLLATE", "LC_CTYPE",
> >>>                                   "LC_MONETARY", "LC_NUMERIC", "LC_TIME"))
> >>> +    if(locale == "C") locale = "English_United States.1252");
> >>>     if(is.na(category)) stop("invalid 'category' argument")
> >>>     .Internal(setlocale(category, locale))
> >>> }
> >>
> >> Unfortunately that does not affect e.g. 'Rgui LC_ALL=C' so a more
> >> comprehensive C-level fix would be needed.
> >>
> >> I did wonder if mingwex was the problem, but in theory at least it knows
> >> about the C locale (cp = 0), and the crash was coming from MSVCRT.dll, in
> >> the conversion of an ASCII string to wchar.  Since it works in other
> >> Windows base locales it did seem specific to Thai (which is still a
> >> single-byte locale).
> >>
> >>
> >>> 2006/5/22, ripley at stats.ox.ac.uk <ripley at stats.ox.ac.uk>:
> >>>> On Mon, 22 May 2006, Edward wrote:
> >>>>
> >>>>> Hi,
> >>>>> We tried it on 3 separate windows XP computers using version 2.3.0.
> >>>>> The original locale is set for Thailand on all 3.
> >>>>> So how do we fix it? Is there another patch?
> >>>>
> >>>> Don't try to do graphics in the C locale on your computer?
> >>>>
> >>>> I suspect this is a font problem in Windows, in that your fonts may be
> >>>> specific to the Thai localization.  But without a means of reproducing
> >>>> this, I can only guess.
> >>>>
> >>>> If you can set up a debugger (see the rw-FAQ), you may be able to give us
> >>>> some additional clues as the where the crash is occuring.
> >>>>
> >>>>> And why does the crash not happen with earlier R versions (eg. 2.2.1) on the
> >>>>> same computer?
> >>>>
> >>>> Because of the issue mentioned in the CHANGES file, the change to the C
> >>>> locale was reverted by opening a graphics window.
> >>>>
> >>>>>
> >>>>> ---
> >>>>>> Sys.getlocale()
> >>>>> [1]
> >>>>> "LC_COLLATE=Thai_Thailand.874;LC_CTYPE=Thai_Thailand.874;LC_MONETARY=Thai_Thailand.874;LC_NUMERIC=C;LC_TIME=Thai_Thailand.874"
> >>>>> ---
> >>>>>
> >>>>> Thanks
> >>>>> Edward
> >>>>>
> >>>>> ----- Original Message ----- From: "Prof Brian Ripley"
> >>>>> <ripley at stats.ox.ac.uk>
> >>>>> To: <edward.m at psu.ac.th>
> >>>>> Cc: <R-bugs at biostat.ku.dk>
> >>>>> Sent: Monday, May 22, 2006 2:32 PM
> >>>>> Subject: Re: [Rd] Sys.setlocale upsets windows graphics device (PR#8887)
> >>>>>
> >>>>>
> >>>>>> Works perfectly for me.  There was a bug in 2.2.1, but it was fixed in
> >>>>>> 2.2.1 patched (see CHANGES).
> >>>>>>
> >>>>>> What locale were you changing from?  (This might be a Windows problem
> >>>>>> specific to your locale.)
> >>>>>>
> >>>>>> On Mon, 22 May 2006, edward.m at psu.ac.th wrote:
> >>>>>>
> >>>>>>> Full_Name: Edward McNeil
> >>>>>>> Version: 2.3.0
> >>>>>>> OS: Widows XP
> >>>>>>> Submission from: (NULL) (203.170.234.5)
> >>>>>>>
> >>>>>>>
> >>>>>>> Type the following:
> >>>>>>>
> >>>>>>>> Sys.setlocale("LC_ALL","C")
> >>>>>>>> hist(1:10)
> >>>>>>>
> >>>>>>> CRASH
> >>>>>>>
> >>>>>>> ______________________________________________
> >>>>>>> R-devel at r-project.org mailing list
> >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>>>>>
> >>>>>>>
> >>>>>>
> >>>>>> --
> >>>>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> >>>>>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> >>>>>> University of Oxford,             Tel:  +44 1865 272861 (self)
> >>>>>> 1 South Parks Road,                     +44 1865 272866 (PA)
> >>>>>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >>>>>
> >>>>>
> >>>>
> >>>> --
> >>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> >>>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> >>>> University of Oxford,             Tel:  +44 1865 272861 (self)
> >>>> 1 South Parks Road,                     +44 1865 272866 (PA)
> >>>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >>>>
> >>>> ______________________________________________
> >>>> R-devel at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>>
> >>>
> >>>
> >>>
> >>
> >> --
> >> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> >> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> >> University of Oxford,             Tel:  +44 1865 272861 (self)
> >> 1 South Parks Road,                     +44 1865 272866 (PA)
> >> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >>
> >
> >
> >
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>


-- 
EI-JI Nakama  <nakama at ki.rim.or.jp>
"\u4e2d\u9593\u6804\u6cbb"  <nakama at ki.rim.or.jp>


From Peter.Ruckdeschel at uni-bayreuth.de  Tue May 23 17:50:30 2006
From: Peter.Ruckdeschel at uni-bayreuth.de (Peter Ruckdeschel)
Date: Tue, 23 May 2006 17:50:30 +0200
Subject: [Rd] confused by inheritance...
Message-ID: <44732F46.7030109@uni-bayreuth.de>

> This may be related to the problems with "greedy" search for inherited 
> methods discussed previously on this list (or may not, it's a bit 
> different).

Thank you very much for your explanation --- at least this is not a silly
fault from our side!

> In any case, the likely fix will be a substantial cleaning up of generic 
> functions hoped for in the next release.
> 
> Meanwhile, "Keep it simple" is the best advice (and a good idea 
> anyway).  If you remove the irrelevant z= part of the signatures, the 
> anomalous result goes away.

Well, as you might have guessed, the z= part is only irrelevant in
the code sniplet I have posted to r-devel as an example...

In our application, 'foo' is an expectation function E() which may be called
as follows:

E(x)          ## returns the expectation of a r.v. X distributed
              ## according to distribution x
E(x,fun)      ## returns the expectation of a r.v. fun(X) where X is distributed
              ## according to distribution x
E(x,cond)     ## returns the expectation of a r.v. X given condition 'cond' is
              ## in force and where X is distributed according to distribution x
E(x,fun,cond) ## returns the expectation of a r.v. fun(X) given condition 'cond' is
              ## in force and where X is distributed according to distribution x

Would you have any suggestion how to organize this in a simpler way than
with signatures

"Distribution", "missing", "missing"
"Distribution", "function", "missing"
"Distribution", "missing", "numeric"
"Distribution", "function", "numeric"

respectively?

--------------------------------------------------------------------------------


> By the way, the getMethod() in your example tells us nothing, 
> since it does not use inheritance.  See its documentation.

Yes, but since 'target' and 'defined' are identical---

Signatures:
        x    y         z
target  "A2" "missing" "missing"
defined "A2" "missing" "missing"

---I would have guessed that the dispatching mechanism would
use this method.

> If you use selectMethod() you see the same result as the method dispatch.

...but this would have made me think that somehow
(perhaps by an unintended call to removeMethod())
during the dispatching mechanism, the registration of  my
("A2","missing","missing")-method would have been deleted.

This is not the case, and could be excluded after
having a look at getMethod() --- so at least for me,
getMethod() did provide some information ...

This idea of a registration being deleted may sound silly to you,
but it was my first guess after the following code (in the setup
of my posted example):

foo(x2)      ## gives 3 as it should
foo(x2,y=2)  ## casts to "A1" and gives (2,2) as it should
foo(x2)      ## now gives 2 as if x2 were permanently cast to "A1"
setMethod("foo",signature(x = "A2", y = "missing", z = "missing"),
   function(x)x at c )
foo(x2)      ## again gives 3 as it should

Thanks again

Peter

---------------------------------------------------------------------------
> Peter Ruckdeschel wrote:
> 
>>Hi r-devels,
>>
>>I am stuck in some S4 inheritance problem:
>>
>>setClass("A",representation(a="numeric"))
>>setClass("A1",representation(b="numeric"),contains="A")
>>setClass("A2",representation(c="numeric"),contains="A1")
>>
>>if(!isGeneric("foo")){
>>    setGeneric("foo", function(x,y,z, ...) standardGeneric("foo"))
>>}
>>
>>setMethod("foo",signature(x = "A", y = "missing", z = "missing"),
>>    function(x)x at a )
>>setMethod("foo",signature(x = "A1", y = "missing", z = "missing"),
>>    function(x)x at b )
>>setMethod("foo",signature(x = "A2", y = "missing", z = "missing"),
>>    function(x)x at c )
>>setMethod("foo",signature(x = "A1", y = "numeric", z = "missing"),
>>    function(x,y)c(x at b,y) )
>>
>>
>>x2 <- new("A2", a=1, b=2, c=3)
>>
>>foo(x2)      ## gives 3 as it should
>>foo(x2,y=2)  ## casts to "A1" and gives (2,2) as it should
>>foo(x2)      ## now gives 2 as if x2 were permanently cast to "A1"
>>## However:
>>x2  ## of class "A2" as it should
>>getMethod("foo",signature(x = "A2", y = "missing", z = "missing"))
>>    ## function(x)x at c
>>
>>### What has happened in the dispatching mechanism between
>>## in the line           foo(x2,y=2)             ?


From KjetilBrinchmannHalvorsen at gmail.com  Tue May 23 18:37:40 2006
From: KjetilBrinchmannHalvorsen at gmail.com (KjetilBrinchmannHalvorsen at gmail.com)
Date: Tue, 23 May 2006 18:37:40 +0200 (CEST)
Subject: [Rd] bug in ccf (PR#8893)
Message-ID: <20060523163740.678BA20783@slim.kubism.ku.dk>

This is R 2.3.0 from CRAN, windows XP.

The following looks like a bug in ccf():

 > x <- ts(rnorm(100), start=1)
 > y <- ts(rnorm(120), start=3)
 > ccf(x,y)
Erro en na.fail.default(ts.union(as.ts(x), as.ts(y))) :
         missing values in object
 > ccf(x,y, na.action=na.pass)
Erro en na.fail.default(as.ts(x)) : missing values in object


 > sessionInfo()
Version 2.3.0 (2006-04-24)
i386-pc-mingw32

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils" 
"datasets"  "base"

other attached packages:
       zoo clim.pact     akima      ncdf
   "1.0-6"   "2.2-1"   "0.5-1"     "1.5"

Kjetil


From ripley at stats.ox.ac.uk  Tue May 23 19:21:35 2006
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Tue, 23 May 2006 19:21:35 +0200 (CEST)
Subject: [Rd] bug in ccf (PR#8893)
Message-ID: <20060523172135.068AE24783@slim.kubism.ku.dk>

In time-aligning the two series there will be missing values, and you 
cannot compute a ccf for series with missing values, hence the problem.

ccf(x, y, na.action=na.contiguous) works.

I guess that using ts.intersect rather than ts.union would be a simple
workaround for this by automatically trimming the ends.


On Tue, 23 May 2006, KjetilBrinchmannHalvorsen at gmail.com wrote:

> This is R 2.3.0 from CRAN, windows XP.
>
> The following looks like a bug in ccf():
>
> > x <- ts(rnorm(100), start=1)
> > y <- ts(rnorm(120), start=3)
> > ccf(x,y)
> Erro en na.fail.default(ts.union(as.ts(x), as.ts(y))) :
>         missing values in object
> > ccf(x,y, na.action=na.pass)
> Erro en na.fail.default(as.ts(x)) : missing values in object
>
>
> > sessionInfo()
> Version 2.3.0 (2006-04-24)
> i386-pc-mingw32
>
> attached base packages:
> [1] "methods"   "stats"     "graphics"  "grDevices" "utils"
> "datasets"  "base"
>
> other attached packages:
>       zoo clim.pact     akima      ncdf
>   "1.0-6"   "2.2-1"   "0.5-1"     "1.5"
>
> Kjetil
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From khansen at stat.Berkeley.EDU  Wed May 24 02:15:36 2006
From: khansen at stat.Berkeley.EDU (Kasper Daniel Hansen)
Date: Tue, 23 May 2006 17:15:36 -0700
Subject: [Rd] protect
In-Reply-To: <Pine.LNX.4.64.0605230852590.23195@gannet.stats.ox.ac.uk>
References: <35168A7B-DFA1-42F7-8763-7769B449005B@stat.berkeley.edu>
	<Pine.LNX.4.64.0605230814250.17904@gannet.stats.ox.ac.uk>
	<Pine.LNX.4.64.0605230852590.23195@gannet.stats.ox.ac.uk>
Message-ID: <41698F04-2224-457D-8A9A-9613A7A03F84@stat.Berkeley.EDU>

Thank you very much. I think I do have a clearer understanding, but I  
have a few questions

On May 23, 2006, at 12:55 AM, Prof Brian Ripley wrote:

> On Tue, 23 May 2006, Prof Brian Ripley wrote:
>
>> On Mon, 22 May 2006, Kasper Daniel Hansen wrote:
>>
>>> I have a few simple questions about the usage of PROTECT, more
>>> specifically how careful one needs to be. Simple yes/no answers are
>>> fine.
>>
>> (Except that in the last case they would be misleading.)
>>
>>> Most of the uses I have seen do protection when memory is allocated.
>>> But what if one just want to assign a value of another function to a
>>> variable. Say eg. that foo is a function that returns a SEXP. Would
>>> the following code be fine?
>>>
>>> SEXP bar;
>>> PROTECT(bar = foo());
>>
>> It would be fine but may be unnecessary.  It is objects and not  
>> pointers
>> which are protected, and a SEXP is a pointer.  So protection is  
>> needed
>> only if foo() might return a pointer to an unprotected object.

Ok. I have been coding foo in such a way that I unprotect everything  
in foo just before returning its value. I thought that was the  
"standard" way to do - is that true? Or should I leave the return  
value protected and then unprotect in the function calling foo?

>>> Also, basically in one use case I would want to return the value of
>>> foo immediately, but I need to do some cleaning up first, which has
>>> nothing to do with R (more specifically, I need to close various
>>> files). Would I then need to protect foo, as in
>>>
>>> SEXP bar;
>>> bar = foo();
>>> "close the file in C++"
>>> return bar;
>>
>> Fine, as PROTECT protects against R garbage collection, and that  
>> can only
>> happen if R's functions are called.
>>
>>> Finally, I am also assigning values to the components of a list.
>>> Would the following be ok
>>>
>>> SEXP bar;
>>> PROTECT(bar = NEW_LIST(2));
>>> SET_VECTOR_ELT(bar, 0, ScalarInteger(test());
>>>
>>> (where test is a function returning int, which again has nothing to
>>> do with R - it interfaces to an extern library), or do I need to
>>> hedge myself against garbage collection in the SET_VECTOR_ELT macro?
>>
>> You do need to protect but elsewhere in this call, as  
>> ScalarInteger does
>> memory allocation:
>>
>> INLINE_FUN SEXP ScalarInteger(int x)
>> {
>>     SEXP ans = allocVector(INTSXP, 1);
>>     INTEGER(ans)[0] = x;
>>     return ans;
>> }
>>
>> but SET_VECTOR_ELT does not.  So you need
>>
>> SEXP bar, tmp;
>> PROTECT(bar = NEW_LIST(2));
>> PROTECT(tmp = test());
>> SET_VECTOR_ELT(bar, 0, ScalarInteger(tmp));
>> UNPROTECT(1);
>
> Or a design that uses fewer PROTECTs
>
> SEXP bar, tmp;
> PROTECT(bar = allocVector(VECSXP, 2));
> tmp = allocVector(INTSXP, 1);
> SET_VECTOR_ELT(bar, 0, tmp);
> INTEGER(tmp)[0] = test();

I thought I got this. Then I grepped the sources and found this in  
main/platform.c:

     PROTECT(ans = allocVector(VECSXP, 18));
     PROTECT(nms = allocVector(STRSXP, 18));
     SET_STRING_ELT(nms, 0, mkChar("double.eps"));
     SET_VECTOR_ELT(ans, 0, ScalarReal(R_AccuracyInfo.eps));

This looks very similar to what I did above. In my case "test" was a C 
++ function coming from outside of R returning an int. That was  
perhaps not clear from my original mail, since the first suggested  
correction had
PROTECT(tmp = test());
indicating that the return value for test is a SEXP. Or am I  
completely of?

I have tried running my original suggestion with gctorture(TRUE) and  
it did not give any errors. But neither did the second suggested  
correction.

Thanks, Kasper


> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Wed May 24 06:03:10 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 24 May 2006 05:03:10 +0100 (BST)
Subject: [Rd] protect
In-Reply-To: <41698F04-2224-457D-8A9A-9613A7A03F84@stat.Berkeley.EDU>
References: <35168A7B-DFA1-42F7-8763-7769B449005B@stat.berkeley.edu>
	<Pine.LNX.4.64.0605230814250.17904@gannet.stats.ox.ac.uk>
	<Pine.LNX.4.64.0605230852590.23195@gannet.stats.ox.ac.uk>
	<41698F04-2224-457D-8A9A-9613A7A03F84@stat.Berkeley.EDU>
Message-ID: <Pine.LNX.4.64.0605240458050.6058@gannet.stats.ox.ac.uk>

On Tue, 23 May 2006, Kasper Daniel Hansen wrote:

> Thank you very much. I think I do have a clearer understanding, but I have a 
> few questions
>
> On May 23, 2006, at 12:55 AM, Prof Brian Ripley wrote:
>
>> On Tue, 23 May 2006, Prof Brian Ripley wrote:
>> 
>>> On Mon, 22 May 2006, Kasper Daniel Hansen wrote:
>>> 
>>>> I have a few simple questions about the usage of PROTECT, more
>>>> specifically how careful one needs to be. Simple yes/no answers are
>>>> fine.
>>> 
>>> (Except that in the last case they would be misleading.)
>>> 
>>>> Most of the uses I have seen do protection when memory is allocated.
>>>> But what if one just want to assign a value of another function to a
>>>> variable. Say eg. that foo is a function that returns a SEXP. Would
>>>> the following code be fine?
>>>> 
>>>> SEXP bar;
>>>> PROTECT(bar = foo());
>>> 
>>> It would be fine but may be unnecessary.  It is objects and not pointers
>>> which are protected, and a SEXP is a pointer.  So protection is needed
>>> only if foo() might return a pointer to an unprotected object.
>
> Ok. I have been coding foo in such a way that I unprotect everything in foo 
> just before returning its value. I thought that was the "standard" way to do 
> - is that true? Or should I leave the return value protected and then 
> unprotect in the function calling foo?

That is indeed standard.  The issue is rather that if say foo() extracts 
an element of a list which has an R-level name, you know that it is 
already protected.

>>>> Also, basically in one use case I would want to return the value of
>>>> foo immediately, but I need to do some cleaning up first, which has
>>>> nothing to do with R (more specifically, I need to close various
>>>> files). Would I then need to protect foo, as in
>>>> 
>>>> SEXP bar;
>>>> bar = foo();
>>>> "close the file in C++"
>>>> return bar;
>>> 
>>> Fine, as PROTECT protects against R garbage collection, and that can only
>>> happen if R's functions are called.
>>> 
>>>> Finally, I am also assigning values to the components of a list.
>>>> Would the following be ok
>>>> 
>>>> SEXP bar;
>>>> PROTECT(bar = NEW_LIST(2));
>>>> SET_VECTOR_ELT(bar, 0, ScalarInteger(test());
>>>> 
>>>> (where test is a function returning int, which again has nothing to
>>>> do with R - it interfaces to an extern library), or do I need to
>>>> hedge myself against garbage collection in the SET_VECTOR_ELT macro?
>>> 
>>> You do need to protect but elsewhere in this call, as ScalarInteger does
>>> memory allocation:
>>> 
>>> INLINE_FUN SEXP ScalarInteger(int x)
>>> {
>>>    SEXP ans = allocVector(INTSXP, 1);
>>>    INTEGER(ans)[0] = x;
>>>    return ans;
>>> }
>>> 
>>> but SET_VECTOR_ELT does not.  So you need
>>> 
>>> SEXP bar, tmp;
>>> PROTECT(bar = NEW_LIST(2));
>>> PROTECT(tmp = test());
>>> SET_VECTOR_ELT(bar, 0, ScalarInteger(tmp));
>>> UNPROTECT(1);
>> 
>> Or a design that uses fewer PROTECTs
>> 
>> SEXP bar, tmp;
>> PROTECT(bar = allocVector(VECSXP, 2));
>> tmp = allocVector(INTSXP, 1);
>> SET_VECTOR_ELT(bar, 0, tmp);
>> INTEGER(tmp)[0] = test();
>
> I thought I got this. Then I grepped the sources and found this in 
> main/platform.c:
>
>   PROTECT(ans = allocVector(VECSXP, 18));
>   PROTECT(nms = allocVector(STRSXP, 18));
>   SET_STRING_ELT(nms, 0, mkChar("double.eps"));
>   SET_VECTOR_ELT(ans, 0, ScalarReal(R_AccuracyInfo.eps));
>
> This looks very similar to what I did above. In my case "test" was a C++ 
> function coming from outside of R returning an int. That was perhaps not 
> clear from my original mail, since the first suggested correction had
> PROTECT(tmp = test());
> indicating that the return value for test is a SEXP. Or am I completely of?

If test() iself does not use anthing from R (that it is C++ is enough of 
the story), then you do not need to protect it.  Or as in the platform.c 
example, if it is a constant.  Sorry, the caveats were not clear to me, 
and I tend not to rely on them as people do sometimes change functions.

> I have tried running my original suggestion with gctorture(TRUE) and it did 
> not give any errors. But neither did the second suggested correction.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From khansen at stat.Berkeley.EDU  Wed May 24 07:21:38 2006
From: khansen at stat.Berkeley.EDU (Kasper Daniel Hansen)
Date: Tue, 23 May 2006 22:21:38 -0700
Subject: [Rd] protect
In-Reply-To: <Pine.LNX.4.64.0605240458050.6058@gannet.stats.ox.ac.uk>
References: <35168A7B-DFA1-42F7-8763-7769B449005B@stat.berkeley.edu>
	<Pine.LNX.4.64.0605230814250.17904@gannet.stats.ox.ac.uk>
	<Pine.LNX.4.64.0605230852590.23195@gannet.stats.ox.ac.uk>
	<41698F04-2224-457D-8A9A-9613A7A03F84@stat.Berkeley.EDU>
	<Pine.LNX.4.64.0605240458050.6058@gannet.stats.ox.ac.uk>
Message-ID: <365EF47A-A95F-4054-9F15-31F4E2CC34D9@stat.Berkeley.EDU>

Thank you very much, that was very helpful. Now I think I understand  
(parts of) the protection mechanism.

/Kasper

On May 23, 2006, at 9:03 PM, Prof Brian Ripley wrote:

> On Tue, 23 May 2006, Kasper Daniel Hansen wrote:
>
>> Thank you very much. I think I do have a clearer understanding,  
>> but I have a few questions
>>
>> On May 23, 2006, at 12:55 AM, Prof Brian Ripley wrote:
>>
>>> On Tue, 23 May 2006, Prof Brian Ripley wrote:
>>>> On Mon, 22 May 2006, Kasper Daniel Hansen wrote:
>>>>> I have a few simple questions about the usage of PROTECT, more
>>>>> specifically how careful one needs to be. Simple yes/no answers  
>>>>> are
>>>>> fine.
>>>> (Except that in the last case they would be misleading.)
>>>>> Most of the uses I have seen do protection when memory is  
>>>>> allocated.
>>>>> But what if one just want to assign a value of another function  
>>>>> to a
>>>>> variable. Say eg. that foo is a function that returns a SEXP.  
>>>>> Would
>>>>> the following code be fine?
>>>>> SEXP bar;
>>>>> PROTECT(bar = foo());
>>>> It would be fine but may be unnecessary.  It is objects and not  
>>>> pointers
>>>> which are protected, and a SEXP is a pointer.  So protection is  
>>>> needed
>>>> only if foo() might return a pointer to an unprotected object.
>>
>> Ok. I have been coding foo in such a way that I unprotect  
>> everything in foo just before returning its value. I thought that  
>> was the "standard" way to do - is that true? Or should I leave the  
>> return value protected and then unprotect in the function calling  
>> foo?
>
> That is indeed standard.  The issue is rather that if say foo()  
> extracts an element of a list which has an R-level name, you know  
> that it is already protected.
>
>>>>> Also, basically in one use case I would want to return the  
>>>>> value of
>>>>> foo immediately, but I need to do some cleaning up first, which  
>>>>> has
>>>>> nothing to do with R (more specifically, I need to close various
>>>>> files). Would I then need to protect foo, as in
>>>>> SEXP bar;
>>>>> bar = foo();
>>>>> "close the file in C++"
>>>>> return bar;
>>>> Fine, as PROTECT protects against R garbage collection, and that  
>>>> can only
>>>> happen if R's functions are called.
>>>>> Finally, I am also assigning values to the components of a list.
>>>>> Would the following be ok
>>>>> SEXP bar;
>>>>> PROTECT(bar = NEW_LIST(2));
>>>>> SET_VECTOR_ELT(bar, 0, ScalarInteger(test());
>>>>> (where test is a function returning int, which again has  
>>>>> nothing to
>>>>> do with R - it interfaces to an extern library), or do I need to
>>>>> hedge myself against garbage collection in the SET_VECTOR_ELT  
>>>>> macro?
>>>> You do need to protect but elsewhere in this call, as  
>>>> ScalarInteger does
>>>> memory allocation:
>>>> INLINE_FUN SEXP ScalarInteger(int x)
>>>> {
>>>>    SEXP ans = allocVector(INTSXP, 1);
>>>>    INTEGER(ans)[0] = x;
>>>>    return ans;
>>>> }
>>>> but SET_VECTOR_ELT does not.  So you need
>>>> SEXP bar, tmp;
>>>> PROTECT(bar = NEW_LIST(2));
>>>> PROTECT(tmp = test());
>>>> SET_VECTOR_ELT(bar, 0, ScalarInteger(tmp));
>>>> UNPROTECT(1);
>>> Or a design that uses fewer PROTECTs
>>> SEXP bar, tmp;
>>> PROTECT(bar = allocVector(VECSXP, 2));
>>> tmp = allocVector(INTSXP, 1);
>>> SET_VECTOR_ELT(bar, 0, tmp);
>>> INTEGER(tmp)[0] = test();
>>
>> I thought I got this. Then I grepped the sources and found this in  
>> main/platform.c:
>>
>>   PROTECT(ans = allocVector(VECSXP, 18));
>>   PROTECT(nms = allocVector(STRSXP, 18));
>>   SET_STRING_ELT(nms, 0, mkChar("double.eps"));
>>   SET_VECTOR_ELT(ans, 0, ScalarReal(R_AccuracyInfo.eps));
>>
>> This looks very similar to what I did above. In my case "test" was  
>> a C++ function coming from outside of R returning an int. That was  
>> perhaps not clear from my original mail, since the first suggested  
>> correction had
>> PROTECT(tmp = test());
>> indicating that the return value for test is a SEXP. Or am I  
>> completely of?
>
> If test() iself does not use anthing from R (that it is C++ is  
> enough of the story), then you do not need to protect it.  Or as in  
> the platform.c example, if it is a constant.  Sorry, the caveats  
> were not clear to me, and I tend not to rely on them as people do  
> sometimes change functions.
>
>> I have tried running my original suggestion with gctorture(TRUE)  
>> and it did not give any errors. But neither did the second  
>> suggested correction.
>
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Wed May 24 07:35:20 2006
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Wed, 24 May 2006 07:35:20 +0200 (CEST)
Subject: [Rd] (PR#8877) predict.lm does not have a weights argument for
Message-ID: <20060524053520.1ABA5CD41@slim.kubism.ku.dk>

I am more than 'a little disappointed' that you expect a detailed 
explanation of the problems with your 'bug' report, especially as you did 
not provide any explanation yourself as to your reasoning (nor did you 
provide any credentials nor references).

Note that

1) Your report did not make clear that this was only relevant to 
prediction intervals, which are not commonly used.

2) Only in some rather special circumstances do weights enter into 
prediction intervals, and definitely not necessarily the weights used for 
fitting.  Indeed, it seems that to label the variances that do enter as 
inverse weights would be rather misleading.

3) In a later message you referenced Brown's book, which is dealing with a 
different model.

The model fitted by lm is

 	y = x\beta + \epsilon, \epsilon \sim N(0, \sigma^2)

(Row vector x, column vector \beta.)

If the observations are from the model, OLS is appropriate, but weighting 
is used in several scenarios, including:

(a) case weights:  w_i = 3 means `I have three observations like (y, x)'

(b) inverse-variance weights, most often an indication that w_i = 1/3 
means that y_i is actually the average of 3 observations at x_i.

(c) multiple imputation, where a case with missing values in x is split 
into say 5 parts, with case weights less than and summing to one.

(d) Heteroscedasticity, where the model is rather

         y = x\beta + \epsilon, \epsilon \sim N(0, \sigma^2(x))

And there may well be other scenarios, but those are the most common (in 
decreasing order) in my experience.


Now, consider prediction intervals.  It would be perverse to consider 
these to be for other than a single future observation at x.  In scenarios 
(a) to (c), R's current behaviour is what is commonly accepted to be 
correct (and you provide no arguments otherwise). If a future observation 
has missing values, predict.lm would only be a starting point for multiple 
imputation.

Even if 'newdata' is not supplied, prediction intervals must apply to new 
observations, not the existing ones (or the formula used is wrong: perhaps 
to avoid your confusion they should not be allowed in that case).

Only in case (d), which is a different model, is it appropriate to supply 
error variances (not weights) for prediction intervals.  This is why I 
marked it for the wishlist.  Equally, one might want to specify
\sigma^2 for all future observations as being different from the model 
fitting, as the training data may include other components of variance in 
their error variances.


On Sat, 20 May 2006, jranke at uni-bremen.de wrote:

> Dear R developers,
>
> I am a little disappointed that my bug report only made it to the
> wishlist, with the argument:
>
> 	Well, it does not say it has.
> 	Only relevant to prediction intervals.
>
> predict.lm does calculate prediction intervals for linear models from
> weighted regression, so they should be correct, right?
>
> As far as I can see they are bound to be wrong in almost all cases, if
> no weights for newdata can be given. So the point is that predict.lm
> needs such an argument in order to give correct prediction intervals for
> models from weighted linear regression.
>
> Also, it strikes me that in the absence of a "newdata" argument, the
> weights from the "lm" object need to be taken into account for
> constructing prediction intervals.

Where are the references and arguments?

> My updated proposal fixing both points as well as the help file can be found at:
>
> 	http://www.uft.uni-bremen.de/chemie/ranke/r-patches/lm.predict.patch

Not found.

> and I wrote up a small demonstration of the problem and my proposed solution:
>
> 	http://www.uft.uni-bremen.de/chemie/ranke/r-patches/lm.predict.pdf

That example is not a valid use of WLS, as you have the weights depending 
on the data you are fitting.

> Kind regards,
>
> Johannes Ranke
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.dalgaard at biostat.ku.dk  Wed May 24 10:14:23 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 24 May 2006 10:14:23 +0200
Subject: [Rd] (PR#8877) predict.lm does not have a weights argument for
In-Reply-To: <20060524053520.1ABA5CD41@slim.kubism.ku.dk>
References: <20060524053520.1ABA5CD41@slim.kubism.ku.dk>
Message-ID: <x2k68bdelc.fsf@viggo.kubism.ku.dk>

ripley at stats.ox.ac.uk writes:

> (a) case weights:  w_i = 3 means `I have three observations like (y, x)'
> 
> (b) inverse-variance weights, most often an indication that w_i = 1/3 
> means that y_i is actually the average of 3 observations at x_i.
> 
> (c) multiple imputation, where a case with missing values in x is split 
> into say 5 parts, with case weights less than and summing to one.
> 
> (d) Heteroscedasticity, where the model is rather
> 
>          y = x\beta + \epsilon, \epsilon \sim N(0, \sigma^2(x))
> 
> And there may well be other scenarios, but those are the most common (in 
> decreasing order) in my experience.

I'd have (d) higher on the list, but never mind. There's also

(e) Inverse probability weights: Knowing that part of the population
is undersampled and wanting results that are compatible with what you
would have gotten in a balanced sample. Prototypically: You sample X,
taking only a third of those with X > c; find population mean of X,
(or univariate regression on some other variable, which is only
recorded in the subsample).

(R-bugs stripped from recipients since this doesn't really have
anything to do with the purported bug.)

       
-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From friedrich.leisch at stat.uni-muenchen.de  Wed May 24 10:14:48 2006
From: friedrich.leisch at stat.uni-muenchen.de (Friedrich Leisch)
Date: Wed, 24 May 2006 10:14:48 +0200
Subject: [Rd] Suggesting changes to HELP files?
In-Reply-To: <971536df0605210902u3810b9a4nf4f7c4d967e98e5@mail.gmail.com>
References: <44708B0A.1050409@pdf.com>
	<971536df0605210902u3810b9a4nf4f7c4d967e98e5@mail.gmail.com>
Message-ID: <17524.5624.101433.444863@celebrian.ci.tuwien.ac.at>

  > On 5/21/06, Spencer Graves <spencer.graves at pdf.com> wrote:
  >> Is there a procedure for suggesting changes to HELP files of the core
  >> R distribution?  If yes, what is it?  If it would be considered a
  >> friendly gesture, I could find the relevant *.Rd file and submit a
  >> suggested modification to it someplace.  Alternatively, I could just
  >> send suggestions someplace if they would receive appropriate
  >> consideration.
  >>

As Duncan Murdoch already pointed out the easiest way of finding out
who in R core is responsible for which part of R is looking at the
subversion logs to see who has been working on a particular file, for
most Sweave & Vignette-related parts that would be me.

  >> 
  >> Second, I think the description of 'vignette' could be enhanced to
  >> include some version of my 'p.s.' to
  >> 'http://finzi.psych.upenn.edu/R/Rhelp02a/archive/73494.html' and other
  >> similar posts.  In particular, I see that the 'edit' method is described
  >> there, but I didn't understand what it said until I already knew how to
  >> use it.  Also, 'edit' doesn't work for me under ESS / Emacs.  For that,
  >> I use Stangle (as Sundar Dorai-Raj taught me).

Done in r-devel, pls have a look.

Best,
Fritz


From adisalvatore at hotmail.it  Wed May 24 10:26:01 2006
From: adisalvatore at hotmail.it (Antonietta di Salvatore)
Date: Wed, 24 May 2006 10:26:01 +0200
Subject: [Rd] the computation of exact p-value for the nonparametric
	cor-test with ties
Message-ID: <BAY105-F1398A94CD92287CA925334BA980@phx.gbl>

Hello,

I wuold like to propose my modifications of the original cor.test to you : I 
tried to calcolate the correct p-value for Spearman and Kendall's test with 
ties.
Let me know what you think.

Thanks you for your time.

Antonietta di Salvatore


test <- function(x, ...) UseMethod("test")

test.default <-
function(x, y, alternative = c("two.sided", "less", "greater"),
         method = c("pearson", "newkendall", "newspearman"), exact = NULL,
         conf.level = 0.95, ...)
{
    alternative <- match.arg(alternative)
    method <- match.arg(method)
    DNAME <- paste(deparse(substitute(x)), "and", deparse(substitute(y)))

    if(length(x) != length(y))
	stop("x and y must have the same length")
    OK <- complete.cases(x, y)
    x <- x[OK]
    y <- y[OK]
    n <- length(x)

    PVAL <- NULL
    NVAL <- 0
    conf.int <- FALSE
if(method == "pearson") {
	if(n < 3)
	    stop("not enough finite observations")
	method <- "Pearson's product-moment correlation"
	names(NVAL) <- "correlation"
	r <- cor(x, y)
        df <- n - 2
	ESTIMATE <- c(cor = r)
	PARAMETER <- c(df = df)
	STATISTIC <- c(t = sqrt(df) * r / sqrt(1 - r^2))
	p <- pt(STATISTIC, df)
        if(n > 3) { ## confidence int.
            if(!missing(conf.level) &&
               (length(conf.level) != 1 || !is.finite(conf.level) ||
                conf.level < 0 || conf.level > 1))
                stop(paste("conf.level must be a single number",
                           "between 0 and 1"))
            conf.int <- TRUE
            z <- atanh(r)
            sigma <- 1 / sqrt(n - 3)
            cint <-
                switch(alternative,
                       less = c(-Inf, z + sigma * qnorm(conf.level)),
                       greater = c(z - sigma * qnorm(conf.level), Inf),
                       two.sided = z +
                       c(-1, 1) * sigma * qnorm((1 + conf.level) / 2))
            cint <- tanh(cint)
            attr(cint, "conf.level") <- conf.level
        }
    }
    else {
	if(n < 2)
	    stop("not enough finite observations")
	PARAMETER <- NULL

	if(method == "newkendall") {
	    method <- "Kendall's rank correlation tau"
	    names(NVAL) <- "tau"
	    r <- cor(x,y, method = "kendall")
            ESTIMATE <- c(tau = r)

            if(!is.finite(ESTIMATE)) {  # all x or all y the same
                ESTIMATE[] <- NA
                STATISTIC <- c(T = NA)
                PVAL <- NA
            }
            else {
                if(is.null(exact))
                    exact <- (n < 50)
                if(exact) {
                    xr<-rank(x)
                    yr<-rank(y)
                     Gx<-table(xr)
                     Gx<-Gx[Gx>1]
                     Gx<-sum(Gx^2-Gx)
#Gx is null when x variable is without ties
                     Gy<-table(yr)
                     Gy<-Gy[Gy>1]
                     Gy<-sum(Gy^2-Gy)
Gy is null when y variable is without ties
                    q <- round((r + 1)*sqrt(n^2-n-Gx)*sqrt(n^2-n-Gy)/4)
                    pkendall <- function(q, n) {
                        .C("pkendall",
                           length(q),
                           p = as.double(q),
                           as.integer(n),
                           PACKAGE = "stats")$p
                    }
                    PVAL <-
                        switch(alternative,
                               "two.sided" = {
                                   if(q > sqrt(n^2-n-Gx)*sqrt(n^2-n-Gy)/4)
                                       p <- 1 - pkendall(q - 1, n)
                                   else
                                       p <- pkendall(q, n)
                                   min(2 * p, 1)
                               },
                               "greater" = 1 - pkendall(q - 1, n),
                               "less" = pkendall(q, n))
                    STATISTIC <- c(T = q)
                } else {
                    STATISTIC <- c(z = r / sqrt((4 * n + 10) / (9 * 
n*(n-1))))
                    p <- pnorm(STATISTIC)

                }
            }
	} else {
          method<- "Spearman's rank correlation rho"
	    names(NVAL) <- "rho"
	    r <- cor(x,y,method="spearman")
	    ESTIMATE <- c(rho = r)
            if(!is.finite(ESTIMATE)) {  # all x or all y the same
                ESTIMATE[] <- NA
                STATISTIC <- c(S = NA)
                PVAL <- NA
            }

            else {
                ## Use the test statistic S = sum(rank(x) - rank(y))^2
                ## and AS 89 for obtaining better p-values than via the
                ## simple normal approximation.
                ## In the case of no ties, S = (1-rho) * (n^3-n)/6.
                pspearman <- function(q, n, lower.tail = TRUE) {
                    if(n <= 1290) # n*(n^2 - 1) does not overflow
                        .C("prho",
                           as.integer(n),
                           as.double(q + 1),
                           p = double(1),
                           integer(1),
                           as.logical(lower.tail),
                           PACKAGE = "stats")$p
                    else { # for large n: aymptotic t_{n-2}
                        r <- 1 - 6 * q / (n*(n*n - 1))
                        pt(r / sqrt((1 - r^2)/(n-2)), df = n-2,
                           lower.tail= !lower.tail)
                    }
                }
           xr<-rank(x)
           yr<-rank(y)
             Gx<-table(xr)
             Gx<-Gx[Gx>1]
             Gx<-sum(Gx^3-Gx)
             Gy<-table(yr)
             Gy<-Gy[Gy>1]
             Gy<-sum(Gy^3-Gy)
q <-round(1/6*((n^3-n)-(Gx+Gy)/2-r*sqrt((n^3-n)^2-(Gx+Gy)*(n^3-n)+Gx*Gy)))


                STATISTIC <- c(S = q)
                PVAL <-
                    switch(alternative,
                           "two.sided" = {
                               p <- if(q > (n^3 - n) / 6)
                                   pspearman(q - 1, n, lower.tail = FALSE)
                               else
				   pspearman(q, n, lower.tail = TRUE)
			       min(2 * p, 1)
			   },
			   "greater" = pspearman(q, n, lower.tail = TRUE),
			   "less" = pspearman(q - 1, n, lower.tail = FALSE))

            }
        }
    }

    if(is.null(PVAL)) # for "pearson" only, currently
	PVAL <- switch(alternative,
		       "less" = p,
		       "greater" = 1 - p,
		       "two.sided" = 2 * min(p, 1 - p))

    RVAL <- list(statistic = STATISTIC,
                 parameter = PARAMETER,
                 p.value = as.numeric(PVAL),
                 estimate = ESTIMATE,
                 null.value = NVAL,
                 alternative = alternative,
                 method = method,
                 data.name = DNAME)
    if(conf.int)
        RVAL <- c(RVAL, list(conf.int = cint))
    class(RVAL) <- "htest"
    RVAL
}

test.formula <-
function(formula, data, subset, na.action, ...)
{
    if(missing(formula)
       || !inherits(formula, "formula")
       || length(formula) != 2)
        stop("formula missing or invalid")
    m <- match.call(expand.dots = FALSE)
    if(is.matrix(eval(m$data, parent.frame())))
        m$data <- as.data.frame(data)
    m[[1]] <- as.name("model.frame")
    m$... <- NULL
    mf <- eval(m, environment(formula))
    if(length(mf) != 2)
        stop("invalid formula")
    DNAME <- paste(names(mf), collapse = " and ")
    names(mf) <- c("x", "y")
    y <- do.call("test", c(mf, list(...)))
    y$data.name <- DNAME
    y
}


From friedrich.leisch at stat.uni-muenchen.de  Wed May 24 10:58:25 2006
From: friedrich.leisch at stat.uni-muenchen.de (Friedrich Leisch)
Date: Wed, 24 May 2006 10:58:25 +0200
Subject: [Rd] Wishlist: Vignettes on CRAN
In-Reply-To: <m21wulxsg5.fsf@ziti.fhcrc.org>
References: <67DCA285A2D7754280D3B8E88EB548020C946838@MSGBOSCLB2WIN.DMN1.FMR.COM>
	<971536df0605222024v3dc65986q5df8a8c370a03e18@mail.gmail.com>
	<m21wulxsg5.fsf@ziti.fhcrc.org>
Message-ID: <17524.8241.904957.145823@celebrian.ci.tuwien.ac.at>

>>>>> On Mon, 22 May 2006 21:42:34 -0700,
>>>>> Seth Falcon (SF) wrote:

  > "Gabor Grothendieck" <ggrothendieck at gmail.com> writes:
  >> This would certainly be nice.
  >> 
  >> Note that the BioConductor package vignettes are online:
  >> http://www.bioconductor.org/docs/vignettes.html
  >> but there is nothing comparable for CRAN.

  > That page is actually out of date (we'll be updating it real soon
  > now).  However, we are producing links to package vingnettes in the
  > automatically generated package summary pages.  For example, take a
  > look at the summary page for the Biobase package:

  > http://bioconductor.org/packages/1.8/bioc/html/Biobase.html

  > This was fairly easy to setup.  I would be happy to share the code,
  > etc.

That looks excellent, I would be happy to use somethink like that for
CRAN. But as Kurt already said: looks more like a summer project
(currently I am swamped with teaching).

.f


From ripley at stats.ox.ac.uk  Wed May 24 11:36:11 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 24 May 2006 10:36:11 +0100 (BST)
Subject: [Rd] (PR#8877) predict.lm does not have a weights argument for
In-Reply-To: <x2k68bdelc.fsf@viggo.kubism.ku.dk>
References: <20060524053520.1ABA5CD41@slim.kubism.ku.dk>
	<x2k68bdelc.fsf@viggo.kubism.ku.dk>
Message-ID: <Pine.LNX.4.64.0605240918180.9937@gannet.stats.ox.ac.uk>

On Wed, 24 May 2006, Peter Dalgaard wrote:

> ripley at stats.ox.ac.uk writes:
>
>> (a) case weights:  w_i = 3 means `I have three observations like (y, x)'
>>
>> (b) inverse-variance weights, most often an indication that w_i = 1/3
>> means that y_i is actually the average of 3 observations at x_i.
>>
>> (c) multiple imputation, where a case with missing values in x is split
>> into say 5 parts, with case weights less than and summing to one.
>>
>> (d) Heteroscedasticity, where the model is rather
>>
>>          y = x\beta + \epsilon, \epsilon \sim N(0, \sigma^2(x))
>>
>> And there may well be other scenarios, but those are the most common (in
>> decreasing order) in my experience.
>
> I'd have (d) higher on the list, but never mind. There's also

I find that if you detect heteroscedasticity, then one of the following 
applies:

- a transformation of y would be beneficial

- a non-normal model, e.g. a Poisson regression, is more appropriate

- the error variance really depends on y or Ey not x, as in most
   measurement-error scenarios (and the example in ?nls and the example
   in the addendum to the bug report).

- in analytical chemistry as in the example on the addendum to the bug
   report, there are errors in both y and x to consider, and a functional
   relationship model is better.

So I very rarely actually get as far as predicting from a heteroscedastic 
regression model.

> (e) Inverse probability weights: Knowing that part of the population
> is undersampled and wanting results that are compatible with what you
> would have gotten in a balanced sample. Prototypically: You sample X,
> taking only a third of those with X > c; find population mean of X,
> (or univariate regression on some other variable, which is only
> recorded in the subsample).

I would call this an example of case weights (you are just weighting cases 
and saying `I have 1/p like this', and in rlm there is a difference 
between (a) and (b) and you would want to use wt.method="case" for (e)).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Wed May 24 14:16:12 2006
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Wed, 24 May 2006 14:16:12 +0200 (CEST)
Subject: [Rd] optim "CG" bug w/patch proposal (PR#8786)
Message-ID: <20060524121612.A97D149FDD@slim.kubism.ku.dk>

On Wed, 17 May 2006, Prof Brian Ripley wrote:

> On Wed, 17 May 2006, maechler at stat.math.ethz.ch wrote:
>
>> 
>>>>>>> "Duncan" == Duncan Murdoch <murdoch at stats.uwo.ca>
>>>>>>>     on Tue, 16 May 2006 08:34:06 -0400 writes:
>>
>>    Duncan> On 5/16/2006 4:56 AM, westfeld at inf.tu-dresden.de
>>    Duncan> wrote:
>>    >> Probably I included too much at once in my bug report. I
>>    >> can live with an unfulfilled wishlist and thank you for
>>    >> thinking about it. The "badly-behaved" function is just
>>    >> an example to demonstrate the bug I reported. I think it
>>    >> is a bug if optim returns (without any warning) an
>>    >> unmatching pair of par and value: f(par) != value. And it
>>    >> is easily fixed.
>>
>>    >>  Andreas
>>
>>    Duncan> I agree with you that on return f(par) should be
>>    Duncan> value.  I agree with Brian that changes to the
>>    Duncan> underlying strategy need much more thought.
>> 
>> I agree (to both).
>> However, isn't Andreas' patch just fixing the problem
>> and not changing the underlying strategy at all?
>> [No, I did not study the code in very much detail ...]
>
> The (minor) issue is that x is updated but not f(x).  I think the intended 
> stategy was to update neither, so Andreas' patch was a change of stategy. In 
> particular, a question is if this should be marked as a convergence failure. 
> But people really need to read the reference before commenting,
> and I at least need to find the time to do so in more detail.

Having spent some time with the reference and a debugger, as far as I can 
see what is happening here is that the second phase of the line search 
fails. That can only happen (in exactly this way) for a discontinuous 
function where the first phase has jumped over a discontinuity to an 
essentially flat region.  In those circumstances updating *Fmin seems 
sensible: probably ideally one should detect the lack of near-quadratic 
and force a restart.  But I don't think it is worth much effort to detect 
examples that are a very long way from the assumptions.  So we'll just 
update *Fmin.

>
>> Martin Maechler
>>
>>    >> Prof Brian Ripley wrote:
>>    >>
>>    >>> [Sorry for the belated reply: this came in just as I was leaving for 
>> a
>>    >>> trip.]
>>    >>>
>>    >>> I've checked the original source, and the C code in optim does
>>    >>> accurately reflect the published algorithm.
>>    >>>
>>    >>> Since your example is a discontinuous function, I don't see why you
>>    >>> expect CG to work on it.  John Nash reports on his extensive
>>    >>> experience that method 3 is the worst, and I don't think we should 
>> let
>>    >>> a single 2D example of a badly-behaved function override that.
>>    >>>
>>    >>> Note that no other optim method copes with the discontiuity here: 
>> had
>>    >>> your reported that it would have been clear that the problem was 
>> with
>>    >>> the example.
>>    >>>
>>    >>> On Fri, 21 Apr 2006, westfeld at inf.tu-dresden.de wrote:
>>    >>>
>>    >>>> Dear R team,
>>    >>>>
>>    >>>> when using optim with method "CG" I got the wrong $value for the
>>    >>>> reported $par.
>>    >>>>
>>    >>>> Example:
>>    >>>> f<-function(p) {
>>    >>>> if (!all(p>-.7)) return(2)
>>    >>>> if (!all(p<.7)) return(2)
>>    >>>> sin((p[1])^2)*sin(p[2])
>>    >>>> }
>>    >>>> optim(c(0.1,-0.1),f,method="CG",control=list(trace=0,type=1))
>>    >>>> $par 19280.68 -10622.32
>>    >>>> $value -0.2346207 # should be 2!
>>    >>>>
>>    >>>> optim(c(0.1,-0.1),f,method="CG",control=list(trace=0,type=2))
>>    >>>> $par 3834.021 -2718.958
>>    >>>> $value -0.0009983175 # should be 2!
>>    >>>>
>>    >>>> Fix:
>>    >>>> --- optim.c     (Revision 37878)
>>    >>>> +++ optim.c     (Arbeitskopie)
>>    >>>> @@ -970,7 +970,8 @@
>>    >>>> if (!accpoint) {
>>    >>>> steplength *= stepredn;
>>    >>>> if (trace) Rprintf("*");
>>    >>>> -                           }
>>    >>>> +                           } else
>>    >>>> +                               *Fmin = f;
>>    >>>> }
>>    >>>> } while (!(count == n || accpoint));
>>    >>>> if (count < n) {
>>    >>>>
>>    >>>> After fix:
>>    >>>> optim(c(0.1,-0.1),f,method="CG",control=list(trace=0,type=1))
>>    >>>> $par 0.6993467 -0.4900145
>>    >>>> $value -0.2211150
>>    >>>> optim(c(0.1,-0.1),f,method="CG",control=list(trace=0,type=2))
>>    >>>> $par 3834.021 -2718.958
>>    >>>> $value 2
>>    >>>>
>>    >>>> Wishlist:
>>    >>>
>>    >> [wishlist deleted]
>>    >>
>>    >>
>>
>>    Duncan> ______________________________________________
>>    Duncan> R-devel at r-project.org mailing list
>>    Duncan> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> 
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From john.little at dunelm.org.uk  Wed May 24 15:11:04 2006
From: john.little at dunelm.org.uk (john.little at dunelm.org.uk)
Date: Wed, 24 May 2006 15:11:04 +0200 (CEST)
Subject: [Rd] Problem with pasteing formulas (PR#8897)
Message-ID: <20060524131104.32D7922158@slim.kubism.ku.dk>

Hi,
If I create a formula with say 100 terms and then paste it:

xnam <- paste("x", 1:100, sep="")
fmla <- as.formula(paste("y ~ ", paste(xnam, collapse= "+")))
paste(fmla)

The result seems to cut off everything after the first 500 characters 
and gives no warning message.

I have the most recent version of R from the R website and the problem 
occurs on both Unix and Windows machines

Thanks

John
-- 
John Little
Department of Mathematical Sciences
Durham University
Durham
UK


From ripley at stats.ox.ac.uk  Wed May 24 15:29:42 2006
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Wed, 24 May 2006 15:29:42 +0200 (CEST)
Subject: [Rd] Problem with pasteing formulas (PR#8897)
Message-ID: <20060524132942.16E6324E9B@slim.kubism.ku.dk>

See ?as.character (which paste effectively calls on non-character objects, 
as ?paste says):

Note:

      'as.character' truncates components of language objects to 500
      characters (was about 70 before 1.3.1).

so it is working as documented.  Not then a bug.

You can (and probably should) use a construct like that in terms.formula:

         else paste(deparse(form[[2]]), collapse = "")

to convert a formula to a complete character string.


On Wed, 24 May 2006, john.little at dunelm.org.uk wrote:

> Hi,
> If I create a formula with say 100 terms and then paste it:
>
> xnam <- paste("x", 1:100, sep="")
> fmla <- as.formula(paste("y ~ ", paste(xnam, collapse= "+")))
> paste(fmla)
>
> The result seems to cut off everything after the first 500 characters
> and gives no warning message.
>
> I have the most recent version of R from the R website and the problem
> occurs on both Unix and Windows machines
>
> Thanks
>
> John
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pinard at iro.umontreal.ca  Wed May 24 19:35:12 2006
From: pinard at iro.umontreal.ca (=?iso-8859-1?Q?Fran=E7ois?= Pinard)
Date: Wed, 24 May 2006 13:35:12 -0400
Subject: [Rd] Problem with pasteing formulas (PR#8897)
In-Reply-To: <20060524132942.16E6324E9B@slim.kubism.ku.dk>
References: <20060524132942.16E6324E9B@slim.kubism.ku.dk>
Message-ID: <20060524173512.GA13155@alcyon.progiciels-bpi.ca>

[Brian Ripley]

>Note:

>      'as.character' truncates components of language objects to 500
>      characters (was about 70 before 1.3.1).

>so it is working as documented.  Not then a bug.

Wrong reasoning.  Bugs may well be documented :-)

-- 
Fran?ois Pinard   http://pinard.progiciels-bpi.ca


From ryan at stat.Berkeley.EDU  Wed May 24 22:42:06 2006
From: ryan at stat.Berkeley.EDU (Ryan Lovett)
Date: Wed, 24 May 2006 13:42:06 -0700
Subject: [Rd] 2.3 issues on Mac
Message-ID: <20060524204206.GC22118@stat.berkeley.edu>

/Library/Frameworks/R.framework/Versions/2.3/Resources/etc/ppc/Renviron and
/Library/Frameworks/R.framework/Versions/2.3/Resources/etc/i386/Renviron
both use /usr/local/teTeX/bin/powerpc-apple-darwin-current for LaTeX
related variables. Could this be updated for i386 to take into account the
teTeX intel binaries?

Also, Makeconf is not setup to create universal binary libraries. Will this
be done at some point?

Lastly, R.mpkg crashes Apple's Remote Desktop 2.2 when installing on a
client. I was wondering if anyone else sees this?

Thanks,
Ryan


From jranke at uni-bremen.de  Thu May 25 00:53:00 2006
From: jranke at uni-bremen.de (jranke at uni-bremen.de)
Date: Thu, 25 May 2006 00:53:00 +0200 (CEST)
Subject: [Rd] (PR#8877) predict.lm does not have a weights argument for
	newdata
Message-ID: <20060524225300.05C46CA6D@slim.kubism.ku.dk>

Prof. Ripley,

thank you for being more explicit now! Thank you also for the fix to
the wish that you derived from my bug report. Here comes the rationale
for my updated patch, which I *humbly* propose as a more general
solution to the problem.

I have spent several days now on this problem, but I am no statistician,
so please excuse my ignorance of any notational or other conventions
that I might disregard below. I tried hard to do it right.

Judging from the documentation to lm, I find that lm has only *one*
perspective on weights which I propose is reasonable and sufficient. It
minimises  "sum(w*e^2))", more clearly expressed as 

	sum(w_i * e_i^2)

I infer that the point is to construct the weights such that 
the errors

	\epsilon = sqrt(w_k) * \epsilon_k 
	
are from a normal distribution N(0, \sigma^2), where index k covers all
observations, past as well as future ones, the model is

	y = x\beta + \epsilon_k

with 

	\epsilon_k \sim N(0, \sigma_k^2)
	
and

	\sigma_k^2 = \sigma^2 / w_k

This is my view on this, it might be naive, it might be wrong, but
if so, I can't see my mistake.

An estimator for \sigma^2 is then

	sum(w_i * e_i^2) / df

which is called res.var in the R code to predict.lm. An estimator
for \sigma_k^2, the variance for observation k, is therefore

	res.var / w_k

which is what my proposed patch, which can now be found in an updated
form under

	 http://www.uft.uni-bremen.de/chemie/ranke/r-patches/predict.lm.patch.r38195

implements. I removed the first version called lm.predict.patch because
it did not correctly deal with prediction intervals for old data, sorry
for the inconvenience ("Not found"). Meanwhile you disabled prediction
intervals for old data, which the above patch reverts (no offense,
please, I just think if predict.lm does confidence intervals for the
regression line at the location of old data points, it might as well do
illustrative prediction intervals at these locations. At least for the
old data, the weights are known from the model object.)

I tested my solution with the script

	http://www.uft.uni-bremen.de/chemie/ranke/r-patches/test.predict.lm.R

* Prof Brian Ripley <ripley at stats.ox.ac.uk> [060524 07:50]:
> I am more than 'a little disappointed' that you expect a detailed 
> explanation of the problems with your 'bug' report, especially as you did 
> not provide any explanation yourself as to your reasoning (nor did you 
> provide any credentials nor references).

I am sorry for this, and I worked hard to supply the information in the
followups including this one.
 
> Note that
> 
> 1) Your report did not make clear that this was only relevant to 
> prediction intervals, which are not commonly used.

I am not really sure if confidence intervals couldn't be improved
in scenario (d). 
 
> 2) Only in some rather special circumstances do weights enter into 
> prediction intervals, and definitely not necessarily the weights used for 
> fitting.  

Yes, under these circumstances R would then need weights from the user
in order to construct prediction intervals. 

> Indeed, it seems that to label the variances that do enter as 
> inverse weights would be rather misleading.

Possibly. I assume it can be correctly done and documented (see my patch
for a proposal).

> 3) In a later message you referenced Brown's book, which is dealing with a 
> different model.
> 
> The model fitted by lm is
> 
> 	y = x\beta + \epsilon, \epsilon \sim N(0, \sigma^2)
> 
> (Row vector x, column vector \beta.)

I assumed that the model in Brown's book is a special case of the model
fitted by lm, the only difference being that x is a row vector (1,
x_B), where x_B is Brown's random variable X, and \beta contains
\alpha_B and \beta_B.
 
> If the observations are from the model, OLS is appropriate, but weighting 
> is used in several scenarios, including:
> 
> (a) case weights:  w_i = 3 means `I have three observations like (y, x)'

I am not sure what you mean by this. Do you mean you have three exactly
equal observations? In this case this could be regarded as a special
case of (b) and w_i = 1/3 would be used as input for lm.

What does the "'" mean in (y, x)'?

> (b) inverse-variance weights, most often an indication that w_i = 1/3 
> means that y_i is actually the average of 3 observations at x_i.

Yes, and I take the reasoning for this to be as follows: An estimator
for the variance of the means of n observations is 1/n times the
variance of the single observations. Why shouldn't this apply to the
means of multiple future observations?

> (c) multiple imputation, where a case with missing values in x is split 
> into say 5 parts, with case weights less than and summing to one.

I don't understand this, but I suppose lm works in the same way for
weights w_i derived from such a procedure.
 
> (d) Heteroscedasticity, where the model is rather
> 
>         y = x\beta + \epsilon, \epsilon \sim N(0, \sigma^2(x))
> 
> And there may well be other scenarios, but those are the most common (in 
> decreasing order) in my experience.

Let me illustrate what my proposal would mean for the different
scenarios:

For scenario (b) we have pairs of n_i and x_i, where n_i is the
number of observations made on case i. I postulate that w_k = 1/n_k,
where n_k is the number of replicate measurements done at sample k, be
it for old or for new data. I don't see what's perverse in assuming 
n_j > 1 for future observations j.

pred.var which you introduced becomes pred.var/n_k, which is equal to
res.var if n_k = 1. If the user has the chance to use weights.newdata,
he can give 1/n_k explicitly and arrive at the correct estimate for
\sigma_k^2 even without knowing the estimate for \sigma^2.

For scenario (d), we can write

	\sigma_k^2 = \sigma^2 / w(x)

with w(x) = w_k. This means, if the weights w_i were calculated using
a function w(x), the same function would need to be applied to get
the weights for newdata w_j = w(x_j).

> Now, consider prediction intervals. 

Yes.

> It would be perverse to consider these to be for other than a single
> future observation at x. 

I can't follow you here. If the weights are 1/n_i and y_i are means from n_i 
observations as in scenario (b), it is of practical interest to be able to
give prediction intervals for the means of n_j new observations on cases j.
I can give an example, if you like.

> In scenarios 
> (a) to (c), R's current behaviour is what is commonly accepted to be 
> correct (and you provide no arguments otherwise). 

I don't see how weights according to (a) would give meaningful answers,
except if they are inversed as I propose above. 

I see that R provides meaningful results for scenario (b), given
prediction intervals are not sought for means from multiple observations.

For scenario (c), I suspect that w_j for future observations should be
mean(w_i), except if you have downweighted cases by w_i that are not
expected to happen in future observations any more. In that case, w_j 
would be 1, which is equivalent to the behaviour of R with or without 
my patch.

> If a future observation 
> has missing values, predict.lm would only be a starting point for multiple 
> imputation.

I can't follow you here.
 
> Even if 'newdata' is not supplied, prediction intervals must apply to new 
> observations, not the existing ones (or the formula used is wrong:

I think that the formula used in the R implementation is wrong, since
the manual says it gives prediction intervals for the existing
observations, so their weights have to be considered in order to arrive
at the correct variance \sigma_k^2.

> perhaps to avoid your confusion they should not be allowed in that
> case).

It is not necessary to disallow them.

> Only in case (d), which is a different model, 

I strongly object. According to the documentation, there is only one
way of treating weighted regression in lm. And I think this is 
reasonable.

> is it appropriate to supply 
> error variances (not weights) for prediction intervals.  

This possibility is conserved applying my patch proposed for r38195.

However, if w(x) is known as in case (d), it is easier to give w(x_j)
for newdata x_j.

At current, the default values for the variances for new data are taken
to be all equal and are defined by 

	res.var <-
	    if (is.null(scale)) {
		r <- object$residuals
		w <- object$weights
		rss <- sum(if(is.null(w)) r^2 else r^2 * w)
		df <- n - p
		rss/df
	    } else scale^2

which becomes pred.var by your latest change.

This means that sum(r^2 * w) / df is used as an estimator for the
variance of future observations \sigma_k^2. However, it follows from the
above that pred.var should be calculated from

	pred.var = res.var / weights.newdata

which forms the basis for my updated patch.

> This is why I 
> marked it for the wishlist.  Equally, one might want to specify
> \sigma^2 for all future observations as being different from the model 
> fitting, as the training data may include other components of variance in 
> their error variances.
> 
> 
> On Sat, 20 May 2006, jranke at uni-bremen.de wrote:
> 
> >Dear R developers,
> >
> >I am a little disappointed that my bug report only made it to the
> >wishlist, with the argument:
> >
> >	Well, it does not say it has.
> >	Only relevant to prediction intervals.
> >
> >predict.lm does calculate prediction intervals for linear models from
> >weighted regression, so they should be correct, right?
> >
> >As far as I can see they are bound to be wrong in almost all cases, if
> >no weights for newdata can be given. So the point is that predict.lm
> >needs such an argument in order to give correct prediction intervals for
> >models from weighted linear regression.
> >
> >Also, it strikes me that in the absence of a "newdata" argument, the
> >weights from the "lm" object need to be taken into account for
> >constructing prediction intervals.
> 
> Where are the references and arguments?
> 
> >My updated proposal fixing both points as well as the help file can be 
> >found at:
> >
> >	http://www.uft.uni-bremen.de/chemie/ranke/r-patches/lm.predict.patch
> 
> Not found.
> 
> >and I wrote up a small demonstration of the problem and my proposed 
> >solution:
> >
> >	http://www.uft.uni-bremen.de/chemie/ranke/r-patches/lm.predict.pdf
> 
> That example is not a valid use of WLS, as you have the weights depending 
> on the data you are fitting.

I don't understand. I estimated the variance function from the data,
what's wrong with that?

Thank you for your attention!

Johannes Ranke
 
> >Kind regards,
> >
> >Johannes Ranke
> >
> >
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-- 
Dr. Johannes Ranke                 jranke at uni-bremen.de
UFT Bremen, Leobenerstr. 1         +49 421 218 8971 
D-28359 Bremen                     http://www.uft.uni-bremen.de/chemie/ranke


From hb at stat.berkeley.edu  Thu May 25 09:19:28 2006
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Thu, 25 May 2006 00:19:28 -0700
Subject: [Rd] save() saves extra stuff if object is not evaluated
Message-ID: <59d7961d0605250019x37e8da24id38e13f98e41f9ae@mail.gmail.com>

Hi,

it looks like save() is saving all contents of the calling
environments if the object to be saved is *not* evaluated, although it
is not that simple either.  After many hours of troubleshooting, I'm
still confused.  Here is a reproducible example (also attached) with
output.  I let the code and the output talk for itself:

peek <- function(file, from=1, to=500) {
  cat("--------------------------------------\n")
  cat(sprintf("%s: %d bytes\n", file, file.info(file)$size))
  bfr <- suppressWarnings(readBin(file, what="character", n=to))
  bfr <- gsub("(\001|\002|\003|\004|\005|\016|\020|\036|\a|\n|\t)", "", bfr);
  bfr <- bfr[nchar(bfr) > 0];
  cat(bfr, sep="", "\n");
}

saveCache <- function(file, y, sources=NULL, eval=FALSE) {
  if (eval)
    dummy <- is.null(sources)
  base::save(file=file, sources, compress=FALSE)
}

aVariableNotSaved <- double(1e6)

main <- function() {
  # This 'big' variable is saved in case 1 below!
  big <- rep(letters, length.out=1e5)
  identifier <- "This string will be saved too!"

  y <- 1

  file <- "a.RData"
  saveCache(y, file=file)
  peek(file)

  file <- "a-eval.RData"
  saveCache(y, file=file, eval=TRUE)
  peek(file)

  file <- "b-noy.RData"
  saveCache(file=file)
  peek(file)

  file <- "b-noy-eval.RData"
  saveCache(file=file, eval=TRUE)
  peek(file)
}


# 1. Call saveCache() outside main()
eval(body(main))
# --------------------------------------
# a.RData: 238 bytes
# RDX2Xsources?filea.RData y?n $  n?$eval???n?
# --------------------------------------
# a-eval.RData: 58 bytes
# RDX2Xsources??
# --------------------------------------
# b-noy.RData: 230 bytes
# RDX2Xsources?file?b-noy.RData ?yv$  n?$eval???n?
# --------------------------------------
# b-noy-eval.RData: 58 bytes
# RDX2Xsources??

# 2. Call saveCache() from within main()
main()
# --------------------------------------
# a.RData: 900412 bytes
# RDX2Xsources?filea.RData y? a.RData ?=identifierThis
# string will be saved too!big??abcdefghijklmnopqrstuv
# wxyzabcdefghijklmnopqrstuvwxyzabcdefg
# --------------------------------------
# a-eval.RData: 58 bytes
# RDX2Xsources??
# --------------------------------------
# b-noy.RData: 230 bytes
# RDX2Xsources?file?b-noy.RData ?yv$  n?$eval???n?
# --------------------------------------
# b-noy-eval.RData: 58 bytes
# RDX2Xsources??

What is going on?

I get this on both R v2.3.0 patched (2006-04-28 r37936) and R v2.3.1
beta (2006-05-23 r38179) on my WinXP (with Rterm --vanilla).

From luke at stat.uiowa.edu  Thu May 25 11:56:05 2006
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Thu, 25 May 2006 04:56:05 -0500 (CDT)
Subject: [Rd] save() saves extra stuff if object is not evaluated
In-Reply-To: <59d7961d0605250019x37e8da24id38e13f98e41f9ae@mail.gmail.com>
References: <59d7961d0605250019x37e8da24id38e13f98e41f9ae@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0605250412530.18683@itasca2.wildberry.org>

On Thu, 25 May 2006, Henrik Bengtsson wrote:

> Hi,
>
> it looks like save() is saving all contents of the calling
> environments if the object to be saved is *not* evaluated, although it
> is not that simple either.

No, it's exactly that simple.  Serialization follows and writes out
all reachable environments.  Unevaluated promises contain the
environments in which their evaluations are to occur; evaluated ones
have this field set to R_NilValue to eliminate this no longer needed
reference.

There are two environments involved: the calling environment in which
saveCache is called and the callee environment of the call to
saveCache where the body of saveCache is evaluated.  Because of
lexical scope the enclosing environment of the callee environment is
the closure environment of saveCache, which is .GlobalEnv.

The call to saveCache creates a promise for evaluating the default
value for 'source' _in the callee environment_. In the case with y the
callee environment includes a value of y which is a promise
referencing the calling environment (either .GlobalENv or the
environment of the call to main).  In the calls without y the value of
y in the calling environment is the missing value indicator, not a
promise.  So only with y and no eval is there a reference to the
calling environment that serialization then has to write out.

Best,

luke


> After many hours of troubleshooting, I'm
> still confused.  Here is a reproducible example (also attached) with
> output.  I let the code and the output talk for itself:
>
> peek <- function(file, from=1, to=500) {
> cat("--------------------------------------\n")
> cat(sprintf("%s: %d bytes\n", file, file.info(file)$size))
> bfr <- suppressWarnings(readBin(file, what="character", n=to))
> bfr <- gsub("(\001|\002|\003|\004|\005|\016|\020|\036|\a|\n|\t)", "", bfr);
> bfr <- bfr[nchar(bfr) > 0];
> cat(bfr, sep="", "\n");
> }
>
> saveCache <- function(file, y, sources=NULL, eval=FALSE) {
> if (eval)
>   dummy <- is.null(sources)
> base::save(file=file, sources, compress=FALSE)
> }
>
> aVariableNotSaved <- double(1e6)
>
> main <- function() {
> # This 'big' variable is saved in case 1 below!
> big <- rep(letters, length.out=1e5)
> identifier <- "This string will be saved too!"
>
> y <- 1
>
> file <- "a.RData"
> saveCache(y, file=file)
> peek(file)
>
> file <- "a-eval.RData"
> saveCache(y, file=file, eval=TRUE)
> peek(file)
>
> file <- "b-noy.RData"
> saveCache(file=file)
> peek(file)
>
> file <- "b-noy-eval.RData"
> saveCache(file=file, eval=TRUE)
> peek(file)
> }
>
>
> # 1. Call saveCache() outside main()
> eval(body(main))
> # --------------------------------------
> # a.RData: 238 bytes
> # RDX2Xsources?filea.RData y?n $  n?$eval???n?
> # --------------------------------------
> # a-eval.RData: 58 bytes
> # RDX2Xsources??
> # --------------------------------------
> # b-noy.RData: 230 bytes
> # RDX2Xsources?file?b-noy.RData ?yv$  n?$eval???n?
> # --------------------------------------
> # b-noy-eval.RData: 58 bytes
> # RDX2Xsources??
>
> # 2. Call saveCache() from within main()
> main()
> # --------------------------------------
> # a.RData: 900412 bytes
> # RDX2Xsources?filea.RData y? a.RData ?=identifierThis
> # string will be saved too!big??abcdefghijklmnopqrstuv
> # wxyzabcdefghijklmnopqrstuvwxyzabcdefg
> # --------------------------------------
> # a-eval.RData: 58 bytes
> # RDX2Xsources??
> # --------------------------------------
> # b-noy.RData: 230 bytes
> # RDX2Xsources?file?b-noy.RData ?yv$  n?$eval???n?
> # --------------------------------------
> # b-noy-eval.RData: 58 bytes
> # RDX2Xsources??
>
> What is going on?
>
> I get this on both R v2.3.0 patched (2006-04-28 r37936) and R v2.3.1
> beta (2006-05-23 r38179) on my WinXP (with Rterm --vanilla).
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From bates at stat.wisc.edu  Thu May 25 18:16:12 2006
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 25 May 2006 11:16:12 -0500
Subject: [Rd] R Project accepted for the Google Summer of Code
Message-ID: <40e66e0b0605250916q6841ae76hfce21cd33acf5bb6@mail.gmail.com>

We are very pleased that an R project has been selected as one of the GNU
projects for the Google Summer of Code 2006 (http://code.google.com/soc/).

Miguel Angel R. Manese, an M.S. Statistics student at the University of
the Philippines, will be working with Douglas Bates and Brian Ripley on a
project entitled `SQLite Data Frames for R' to let R store very large
datasets in an SQLite database transparently, implementing primitive
operations for data stored in SQLite so that they behave exactly like
ordinary data frames to the users.  It is likely that the project will
result in the first instance in an R package (which may in due course
become part of the tarball).

Congratulations, Miguel!


From ostrouchovg at ornl.gov  Thu May 25 22:06:51 2006
From: ostrouchovg at ornl.gov (George Ostrouchov)
Date: Thu, 25 May 2006 16:06:51 -0400
Subject: [Rd] compiling tests/Embedding
Message-ID: <44760E5B.4060608@ornl.gov>

I am compiling the Embedding examples in the tests directory and get an 
undefined reference. I include the make output as well as grep'd output 
of nm on libR.so and compiler and arch information. Do I have an 
improperly built R shared library or is there a problem with the 
Embedding tests or something else I am not seeing?

Thanks for any help!
George


ost at hawk0:/data5/ost/R/R-2.3.0/tests/Embedding> make
../../bin/R CMD LINK gcc -o Rtest Rtest.o embeddedRCall.o -L`cd ../.. && 
/bin/pwd`/lib -lR
gcc -o Rtest Rtest.o embeddedRCall.o  
-L/autofs/tewa_data5/ost/R/R-2.3.0/lib -lR -Wl,--rpath 
-Wl,/data5/ost/R/R-2.3.0/lib
embeddedRCall.o(.text+0x1e): In function `Test_tryEval':
/autofs/tewa_data5/ost/R/R-2.3.0/tests/Embedding/embeddedRCall.c:81: 
undefined reference to `R_ToplevelExec'
collect2: ld returned 1 exit status
make: *** [Rtest] Error 1
ost at hawk0:/data5/ost/R/R-2.3.0/tests/Embedding> cd 
/autofs/tewa_data5/ost/R/R-2.3.0/lib
ost at hawk0:/autofs/tewa_data5/ost/R/R-2.3.0/lib> nm libR.so | grep R_Top
000000000042c920 B R_Toplevel
000000000042cae8 B R_ToplevelContext
000000000007a7b0 t R_ToplevelExec
ost at hawk0:/autofs/tewa_data5/ost/R/R-2.3.0/lib> gcc --version
gcc (GCC) 3.3.4 (pre 3.3.5 20040809)
Copyright (C) 2003 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

ost at hawk0:/autofs/tewa_data5/ost/R/R-2.3.0/lib> arch
x86_64
ost at hawk0:/autofs/tewa_data5/ost/R/R-2.3.0/lib>


-- 
George Ostrouchov
Statistics and Data Sciences Group
Computer Science and Mathematics Division
Oak Ridge National Laboratory
http://www.csm.ornl.gov/~ost

Register for the JRC 2006?
http://2006jointresearch.bus.utk.edu/
Conference starts June 6, 2006.


From ripley at stats.ox.ac.uk  Thu May 25 22:29:52 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 25 May 2006 21:29:52 +0100 (BST)
Subject: [Rd] compiling tests/Embedding
In-Reply-To: <44760E5B.4060608@ornl.gov>
References: <44760E5B.4060608@ornl.gov>
Message-ID: <Pine.LNX.4.64.0605252113210.20127@gannet.stats.ox.ac.uk>

What system is this?

It should work under gcc-3.3.4, as the issue is visibility attributes and 
they are not supposed to be supported on that compiler.  (I suspect from 
the message that this is not a version of gcc released by GNU, a common 
source of problems.)  I happen to have an i686 FC3 system with a gcc 3.3.5 
compiled from the GNU sources (to help track down a bug in code generated 
by that compiler), and that does work in tests/Embedding.

In src/main/context.c you will find

context.c:Rboolean attribute_hidden R_ToplevelExec(void (*fun)(void *), 
void *data)

and you need to remove 'attribute_hidden' and recompile.

(There is a known problem here with gcc >= 4.0.0, with this fix in the 
pre-2.3.1 sources.  We know that certain RedHat systems have gcc3's that 
support visibility, not always completely.)


On Thu, 25 May 2006, George Ostrouchov wrote:

> I am compiling the Embedding examples in the tests directory and get an
> undefined reference. I include the make output as well as grep'd output
> of nm on libR.so and compiler and arch information. Do I have an
> improperly built R shared library or is there a problem with the
> Embedding tests or something else I am not seeing?
>
> Thanks for any help!
> George
>
>
> ost at hawk0:/data5/ost/R/R-2.3.0/tests/Embedding> make
> ../../bin/R CMD LINK gcc -o Rtest Rtest.o embeddedRCall.o -L`cd ../.. &&
> /bin/pwd`/lib -lR
> gcc -o Rtest Rtest.o embeddedRCall.o
> -L/autofs/tewa_data5/ost/R/R-2.3.0/lib -lR -Wl,--rpath
> -Wl,/data5/ost/R/R-2.3.0/lib
> embeddedRCall.o(.text+0x1e): In function `Test_tryEval':
> /autofs/tewa_data5/ost/R/R-2.3.0/tests/Embedding/embeddedRCall.c:81:
> undefined reference to `R_ToplevelExec'
> collect2: ld returned 1 exit status
> make: *** [Rtest] Error 1
> ost at hawk0:/data5/ost/R/R-2.3.0/tests/Embedding> cd
> /autofs/tewa_data5/ost/R/R-2.3.0/lib
> ost at hawk0:/autofs/tewa_data5/ost/R/R-2.3.0/lib> nm libR.so | grep R_Top
> 000000000042c920 B R_Toplevel
> 000000000042cae8 B R_ToplevelContext
> 000000000007a7b0 t R_ToplevelExec
> ost at hawk0:/autofs/tewa_data5/ost/R/R-2.3.0/lib> gcc --version
> gcc (GCC) 3.3.4 (pre 3.3.5 20040809)
> Copyright (C) 2003 Free Software Foundation, Inc.
> This is free software; see the source for copying conditions.  There is NO
> warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
>
> ost at hawk0:/autofs/tewa_data5/ost/R/R-2.3.0/lib> arch
> x86_64
> ost at hawk0:/autofs/tewa_data5/ost/R/R-2.3.0/lib>
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hb at stat.berkeley.edu  Fri May 26 03:03:27 2006
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Thu, 25 May 2006 18:03:27 -0700
Subject: [Rd] save() saves extra stuff if object is not evaluated
In-Reply-To: <Pine.LNX.4.64.0605250412530.18683@itasca2.wildberry.org>
References: <59d7961d0605250019x37e8da24id38e13f98e41f9ae@mail.gmail.com>
	<Pine.LNX.4.64.0605250412530.18683@itasca2.wildberry.org>
Message-ID: <59d7961d0605251803h73a0844fje48c044c461fa020@mail.gmail.com>

On 5/25/06, Luke Tierney <luke at stat.uiowa.edu> wrote:
> On Thu, 25 May 2006, Henrik Bengtsson wrote:
>
> > Hi,
> >
> > it looks like save() is saving all contents of the calling
> > environments if the object to be saved is *not* evaluated, although it
> > is not that simple either.
>
> No, it's exactly that simple.  Serialization follows and writes out
> all reachable environments.  Unevaluated promises contain the
> environments in which their evaluations are to occur; evaluated ones
> have this field set to R_NilValue to eliminate this no longer needed
> reference.
>
> There are two environments involved: the calling environment in which
> saveCache is called and the callee environment of the call to
> saveCache where the body of saveCache is evaluated.  Because of
> lexical scope the enclosing environment of the callee environment is
> the closure environment of saveCache, which is .GlobalEnv.
>
> The call to saveCache creates a promise for evaluating the default
> value for 'source' _in the callee environment_. In the case with y the
> callee environment includes a value of y which is a promise
> referencing the calling environment (either .GlobalENv or the
> environment of the call to main).  In the calls without y the value of
> y in the calling environment is the missing value indicator, not a
> promise.  So only with y and no eval is there a reference to the
> calling environment that serialization then has to write out.

Thank you very much for this sharp explanation.  It is now much
clearer to me what is going on.  Would it make sense to make save()
evaluate all non-evaluated arguments, e.g. is.null(list(...))?  ...or,
add an argument making this optional/default?

Best wishes,

Henrik

> Best,
>
> luke
>
>
> > After many hours of troubleshooting, I'm
> > still confused.  Here is a reproducible example (also attached) with
> > output.  I let the code and the output talk for itself:
> >
> > peek <- function(file, from=1, to=500) {
> > cat("--------------------------------------\n")
> > cat(sprintf("%s: %d bytes\n", file, file.info(file)$size))
> > bfr <- suppressWarnings(readBin(file, what="character", n=to))
> > bfr <- gsub("(\001|\002|\003|\004|\005|\016|\020|\036|\a|\n|\t)", "", bfr);
> > bfr <- bfr[nchar(bfr) > 0];
> > cat(bfr, sep="", "\n");
> > }
> >
> > saveCache <- function(file, y, sources=NULL, eval=FALSE) {
> > if (eval)
> >   dummy <- is.null(sources)
> > base::save(file=file, sources, compress=FALSE)
> > }
> >
> > aVariableNotSaved <- double(1e6)
> >
> > main <- function() {
> > # This 'big' variable is saved in case 1 below!
> > big <- rep(letters, length.out=1e5)
> > identifier <- "This string will be saved too!"
> >
> > y <- 1
> >
> > file <- "a.RData"
> > saveCache(y, file=file)
> > peek(file)
> >
> > file <- "a-eval.RData"
> > saveCache(y, file=file, eval=TRUE)
> > peek(file)
> >
> > file <- "b-noy.RData"
> > saveCache(file=file)
> > peek(file)
> >
> > file <- "b-noy-eval.RData"
> > saveCache(file=file, eval=TRUE)
> > peek(file)
> > }
> >
> >
> > # 1. Call saveCache() outside main()
> > eval(body(main))
> > # --------------------------------------
> > # a.RData: 238 bytes
> > # RDX2Xsources?ilea.RData y? $  n?eval???> # --------------------------------------
> > # a-eval.RData: 58 bytes
> > # RDX2Xsources?
> > # --------------------------------------
> > # b-noy.RData: 230 bytes
> > # RDX2Xsources?ile?b-noy.RData ?v$  n?eval???> # --------------------------------------
> > # b-noy-eval.RData: 58 bytes
> > # RDX2Xsources?
> >
> > # 2. Call saveCache() from within main()
> > main()
> > # --------------------------------------
> > # a.RData: 900412 bytes
> > # RDX2Xsources?ilea.RData y?a.RData ?=identifierThis
> > # string will be saved too!big?abcdefghijklmnopqrstuv
> > # wxyzabcdefghijklmnopqrstuvwxyzabcdefg
> > # --------------------------------------
> > # a-eval.RData: 58 bytes
> > # RDX2Xsources?
> > # --------------------------------------
> > # b-noy.RData: 230 bytes
> > # RDX2Xsources?ile?b-noy.RData ?v$  n?eval???> # --------------------------------------
> > # b-noy-eval.RData: 58 bytes
> > # RDX2Xsources?
> >
> > What is going on?
> >
> > I get this on both R v2.3.0 patched (2006-04-28 r37936) and R v2.3.1
> > beta (2006-05-23 r38179) on my WinXP (with Rterm --vanilla).
> >
>
> --
> Luke Tierney
> Chair, Statistics and Actuarial Science
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>     Actuarial Science
> 241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>


From ifetzer at gmx.net  Fri May 26 12:19:53 2006
From: ifetzer at gmx.net (ifetzer at gmx.net)
Date: Fri, 26 May 2006 12:19:53 +0200 (CEST)
Subject: [Rd] cpu usage stays at 100% (PR#8903)
Message-ID: <20060526101953.279BB29D3D@slim.kubism.ku.dk>

Full_Name: Ingo Fetzer
Version: 2.3.0
OS: Win XP
Submission from: (NULL) (141.65.192.22)


I realised after working on the RGUI with R 2.3.0 on my laptop (Intel Pentium M
1.6 Ghz,512MB RAM) R raises my CPU usage to 100% constantly. Also when exiting
RGUI some R processes remain active in the system and CPU usage is still at
100%. 
When killing RGui processes in taskmanager manually, CPU usage goes down to
normal.


From ligges at statistik.uni-dortmund.de  Fri May 26 12:47:36 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 26 May 2006 12:47:36 +0200
Subject: [Rd] cpu usage stays at 100% (PR#8903)
In-Reply-To: <20060526101953.279BB29D3D@slim.kubism.ku.dk>
References: <20060526101953.279BB29D3D@slim.kubism.ku.dk>
Message-ID: <4476DCC8.3050009@statistik.uni-dortmund.de>

ifetzer at gmx.net wrote:

> Full_Name: Ingo Fetzer
> Version: 2.3.0
> OS: Win XP
> Submission from: (NULL) (141.65.192.22)
> 
> 
> I realised after working on the RGUI with R 2.3.0 on my laptop (Intel Pentium M
> 1.6 Ghz,512MB RAM) R raises my CPU usage to 100% constantly. Also when exiting
> RGUI some R processes remain active in the system and CPU usage is still at
> 100%. 
> When killing RGui processes in taskmanager manually, CPU usage goes down to
> normal.


Please, can you specify a reproducible example that causes the descibed 
problem (even better using R-2.3.1 beta)? We have not had any other 
report on such a behaviour so far.

Uwe Ligges

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From rpeng at jhsph.edu  Fri May 26 14:22:42 2006
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Fri, 26 May 2006 08:22:42 -0400
Subject: [Rd] memory profiling
Message-ID: <4476F312.4090902@jhsph.edu>

I'm interested in playing around with memory profiling in R-devel (as described 
at http://developer.r-project.org/memory-profiling.html) and was trying to 
figure out how to compile R-devel so that I can use the 'tracemem()' function. 
But I can't figure out how/where to set R_MEMORY_PROFILING.  Is it on the 
configure command line?

Thanks for any help,
-roger
-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/


From duncan at wald.ucdavis.edu  Fri May 26 15:43:44 2006
From: duncan at wald.ucdavis.edu (Duncan Temple Lang)
Date: Fri, 26 May 2006 06:43:44 -0700
Subject: [Rd] compiling tests/Embedding
In-Reply-To: <Pine.LNX.4.64.0605252113210.20127@gannet.stats.ox.ac.uk>
References: <44760E5B.4060608@ornl.gov>
	<Pine.LNX.4.64.0605252113210.20127@gannet.stats.ox.ac.uk>
Message-ID: <44770610.2010802@wald.ucdavis.edu>


In addition to the compiler issues, the test should also be changed.
It should use R_tryEval() directly rather than Test_tryEval().  The test 
preceeds the existence
of that exported routine that was motivated by the same
usage that gave rise to this test.

I'll commit an update when I get a few minutes.

  D.

Prof Brian Ripley wrote:
> What system is this?
> 
> It should work under gcc-3.3.4, as the issue is visibility attributes and 
> they are not supposed to be supported on that compiler.  (I suspect from 
> the message that this is not a version of gcc released by GNU, a common 
> source of problems.)  I happen to have an i686 FC3 system with a gcc 3.3.5 
> compiled from the GNU sources (to help track down a bug in code generated 
> by that compiler), and that does work in tests/Embedding.
> 
> In src/main/context.c you will find
> 
> context.c:Rboolean attribute_hidden R_ToplevelExec(void (*fun)(void *), 
> void *data)
> 
> and you need to remove 'attribute_hidden' and recompile.
> 
> (There is a known problem here with gcc >= 4.0.0, with this fix in the 
> pre-2.3.1 sources.  We know that certain RedHat systems have gcc3's that 
> support visibility, not always completely.)
> 
> 
> On Thu, 25 May 2006, George Ostrouchov wrote:
> 
>> I am compiling the Embedding examples in the tests directory and get an
>> undefined reference. I include the make output as well as grep'd output
>> of nm on libR.so and compiler and arch information. Do I have an
>> improperly built R shared library or is there a problem with the
>> Embedding tests or something else I am not seeing?
>>
>> Thanks for any help!
>> George
>>
>>
>> ost at hawk0:/data5/ost/R/R-2.3.0/tests/Embedding> make
>> ../../bin/R CMD LINK gcc -o Rtest Rtest.o embeddedRCall.o -L`cd ../.. &&
>> /bin/pwd`/lib -lR
>> gcc -o Rtest Rtest.o embeddedRCall.o
>> -L/autofs/tewa_data5/ost/R/R-2.3.0/lib -lR -Wl,--rpath
>> -Wl,/data5/ost/R/R-2.3.0/lib
>> embeddedRCall.o(.text+0x1e): In function `Test_tryEval':
>> /autofs/tewa_data5/ost/R/R-2.3.0/tests/Embedding/embeddedRCall.c:81:
>> undefined reference to `R_ToplevelExec'
>> collect2: ld returned 1 exit status
>> make: *** [Rtest] Error 1
>> ost at hawk0:/data5/ost/R/R-2.3.0/tests/Embedding> cd
>> /autofs/tewa_data5/ost/R/R-2.3.0/lib
>> ost at hawk0:/autofs/tewa_data5/ost/R/R-2.3.0/lib> nm libR.so | grep R_Top
>> 000000000042c920 B R_Toplevel
>> 000000000042cae8 B R_ToplevelContext
>> 000000000007a7b0 t R_ToplevelExec
>> ost at hawk0:/autofs/tewa_data5/ost/R/R-2.3.0/lib> gcc --version
>> gcc (GCC) 3.3.4 (pre 3.3.5 20040809)
>> Copyright (C) 2003 Free Software Foundation, Inc.
>> This is free software; see the source for copying conditions.  There is NO
>> warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
>>
>> ost at hawk0:/autofs/tewa_data5/ost/R/R-2.3.0/lib> arch
>> x86_64
>> ost at hawk0:/autofs/tewa_data5/ost/R/R-2.3.0/lib>
>>
>>
>>
>


From tobias.verbeke at telenet.be  Fri May 26 16:42:24 2006
From: tobias.verbeke at telenet.be (Tobias Verbeke)
Date: Fri, 26 May 2006 16:42:24 +0200
Subject: [Rd] typo in ?dimnames
Message-ID: <447713D0.40305@telenet.be>

Dear list,

In ?dimnames, section `Value' I read:

 For the '"data.frame"' method both dimnames must be non-null, and
     the rownames must be contain no duplicates nor missing values.
                    ^^^^^^^

Best regards,
Tobias

 > version
              
platform       i486-pc-linux-gnu
arch           i486
os             linux-gnu
system         i486, linux-gnu
status
major          2
minor          3.0
year           2006
month          04
day            24
svn rev        37909
language       R
version.string Version 2.3.0 (2006-04-24)


From ripley at stats.ox.ac.uk  Fri May 26 16:48:33 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 26 May 2006 15:48:33 +0100 (BST)
Subject: [Rd] memory profiling
In-Reply-To: <4476F312.4090902@jhsph.edu>
References: <4476F312.4090902@jhsph.edu>
Message-ID: <Pine.LNX.4.64.0605261544530.26987@gannet.stats.ox.ac.uk>

On Fri, 26 May 2006, Roger D. Peng wrote:

> I'm interested in playing around with memory profiling in R-devel (as described
> at http://developer.r-project.org/memory-profiling.html) and was trying to
> figure out how to compile R-devel so that I can use the 'tracemem()' function.
> But I can't figure out how/where to set R_MEMORY_PROFILING.  Is it on the
> configure command line?

I added -DR_MEMORY_PROFILING to CFLAGS in config.site.  An alternative is 
to add this to DEFS in Makeconf after configuring.

Probably in due course there will be a way to do it via configure and 
config.h, but I do not see one.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.dalgaard at biostat.ku.dk  Fri May 26 17:11:47 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 26 May 2006 17:11:47 +0200
Subject: [Rd] (PR#8877) predict.lm does not have a weights argument for
In-Reply-To: <Pine.LNX.4.64.0605240918180.9937@gannet.stats.ox.ac.uk>
References: <20060524053520.1ABA5CD41@slim.kubism.ku.dk>
	<x2k68bdelc.fsf@viggo.kubism.ku.dk>
	<Pine.LNX.4.64.0605240918180.9937@gannet.stats.ox.ac.uk>
Message-ID: <x2lkso253g.fsf@turmalin.kubism.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> > (e) Inverse probability weights: Knowing that part of the population
> > is undersampled and wanting results that are compatible with what you
> > would have gotten in a balanced sample. Prototypically: You sample X,
> > taking only a third of those with X > c; find population mean of X,
> > (or univariate regression on some other variable, which is only
> > recorded in the subsample).
> 
> I would call this an example of case weights (you are just weighting
> cases and saying `I have 1/p like this', and in rlm there is a
> difference between (a) and (b) and you would want to use
> wt.method="case" for (e)).

No it's not quite the same. One is "I have 3 of these", the other is
"I have looked at one case, but it comes from a population that I know
is undersampled by a factor of 3". Standard error of estimates will be
considerably different.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From p.dalgaard at biostat.ku.dk  Fri May 26 17:47:22 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 26 May 2006 17:47:22 +0200
Subject: [Rd] R 2.3.1 release candidates starting tomorrow
Message-ID: <x2d5e023g5.fsf@turmalin.kubism.ku.dk>


Starting with tomorrow's build, the beta designation will be replaced
by RC. This also implies that we are in "hard" code freeze, and that
we're not going to change anything unless it is critical. If you do
not want such critical bugs to slip into the final release, please
check the release candidates on your platform and report back if you
find problems. 

The directory for prereleases is

http://cran.r-project.org/src/base-prerelease/

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From antonio.fabio at gmail.com  Fri May 26 18:26:49 2006
From: antonio.fabio at gmail.com (Antonio, Fabio Di Narzo)
Date: Fri, 26 May 2006 18:26:49 +0200
Subject: [Rd] compiling tests/Embedding
In-Reply-To: <44770610.2010802@wald.ucdavis.edu>
References: <44760E5B.4060608@ornl.gov>
	<Pine.LNX.4.64.0605252113210.20127@gannet.stats.ox.ac.uk>
	<44770610.2010802@wald.ucdavis.edu>
Message-ID: <b0808fdc0605260926oec6d0c9qba216058359c453e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060526/7f7b5ff7/attachment.pl 

From ripley at stats.ox.ac.uk  Fri May 26 18:34:03 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 26 May 2006 17:34:03 +0100 (BST)
Subject: [Rd] compiling tests/Embedding
In-Reply-To: <b0808fdc0605260926oec6d0c9qba216058359c453e@mail.gmail.com>
References: <44760E5B.4060608@ornl.gov>
	<Pine.LNX.4.64.0605252113210.20127@gannet.stats.ox.ac.uk>
	<44770610.2010802@wald.ucdavis.edu>
	<b0808fdc0605260926oec6d0c9qba216058359c453e@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0605261731290.28241@gannet.stats.ox.ac.uk>

On Fri, 26 May 2006, Antonio, Fabio Di Narzo wrote:

> Hi all.
> The same compiler problem appears on my gcc-4.0.2 shipped with ubuntu
> breezy. Well fixed with B.R. indication.

Note: I already said

> > (There is a known problem here with gcc >= 4.0.0, with this fix in the
> > pre-2.3.1 sources.  We know that certain RedHat systems have gcc3's that
> > support visibility, not always completely.)

and it is believed to be fixed in the 2.3.1 RC versions now under test.

So we don't need any reports on gcc4 for 2.3.0: please try the current 
test version.  (That this appeared on gcc 3.3.4 was a surprise, given it 
does not on 3.3.5.)

>
> Antonio.
>
> 2006/5/26, Duncan Temple Lang <duncan at wald.ucdavis.edu>:
>>
>>
>> In addition to the compiler issues, the test should also be changed.
>> It should use R_tryEval() directly rather than Test_tryEval().  The test
>> preceeds the existence
>> of that exported routine that was motivated by the same
>> usage that gave rise to this test.
>>
>> I'll commit an update when I get a few minutes.
>>
>>   D.
>>
>> Prof Brian Ripley wrote:
>>> What system is this?
>>>
>>> It should work under gcc-3.3.4, as the issue is visibility attributes
>> and
>>> they are not supposed to be supported on that compiler.  (I suspect from
>>> the message that this is not a version of gcc released by GNU, a common
>>> source of problems.)  I happen to have an i686 FC3 system with a gcc
>> 3.3.5
>>> compiled from the GNU sources (to help track down a bug in code
>> generated
>>> by that compiler), and that does work in tests/Embedding.
>>>
>>> In src/main/context.c you will find
>>>
>>> context.c:Rboolean attribute_hidden R_ToplevelExec(void (*fun)(void *),
>>> void *data)
>>>
>>> and you need to remove 'attribute_hidden' and recompile.
>>>
>>> (There is a known problem here with gcc >= 4.0.0, with this fix in the
>>> pre-2.3.1 sources.  We know that certain RedHat systems have gcc3's that
>>> support visibility, not always completely.)
>
>>
>>>
>>> On Thu, 25 May 2006, George Ostrouchov wrote:
>>>
>>>> I am compiling the Embedding examples in the tests directory and get an
>>>> undefined reference. I include the make output as well as grep'd output
>>>> of nm on libR.so and compiler and arch information. Do I have an
>>>> improperly built R shared library or is there a problem with the
>>>> Embedding tests or something else I am not seeing?
>>>>
>>>> Thanks for any help!
>>>> George
>>>>
>>>>
>>>> ost at hawk0:/data5/ost/R/R-2.3.0/tests/Embedding> make
>>>> ../../bin/R CMD LINK gcc -o Rtest Rtest.o embeddedRCall.o -L`cd ../..
>> &&
>>>> /bin/pwd`/lib -lR
>>>> gcc -o Rtest Rtest.o embeddedRCall.o
>>>> -L/autofs/tewa_data5/ost/R/R-2.3.0/lib -lR -Wl,--rpath
>>>> -Wl,/data5/ost/R/R-2.3.0/lib
>>>> embeddedRCall.o(.text+0x1e): In function `Test_tryEval':
>>>> /autofs/tewa_data5/ost/R/R-2.3.0/tests/Embedding/embeddedRCall.c:81:
>>>> undefined reference to `R_ToplevelExec'
>>>> collect2: ld returned 1 exit status
>>>> make: *** [Rtest] Error 1
>>>> ost at hawk0:/data5/ost/R/R-2.3.0/tests/Embedding> cd
>>>> /autofs/tewa_data5/ost/R/R-2.3.0/lib
>>>> ost at hawk0:/autofs/tewa_data5/ost/R/R-2.3.0/lib> nm libR.so | grep R_Top
>>>> 000000000042c920 B R_Toplevel
>>>> 000000000042cae8 B R_ToplevelContext
>>>> 000000000007a7b0 t R_ToplevelExec
>>>> ost at hawk0:/autofs/tewa_data5/ost/R/R-2.3.0/lib> gcc --version
>>>> gcc (GCC) 3.3.4 (pre 3.3.5 20040809)
>>>> Copyright (C) 2003 Free Software Foundation, Inc.
>>>> This is free software; see the source for copying conditions.  There is
>> NO
>>>> warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR
>> PURPOSE.
>>>>
>>>> ost at hawk0:/autofs/tewa_data5/ost/R/R-2.3.0/lib> arch
>>>> x86_64
>>>> ost at hawk0:/autofs/tewa_data5/ost/R/R-2.3.0/lib>
>>>>
>>>>
>>>>
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> Antonio, Fabio Di Narzo.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ostrouchovg at ornl.gov  Fri May 26 18:35:47 2006
From: ostrouchovg at ornl.gov (George Ostrouchov)
Date: Fri, 26 May 2006 12:35:47 -0400
Subject: [Rd] compiling tests/Embedding
In-Reply-To: <44770610.2010802@wald.ucdavis.edu>
References: <44760E5B.4060608@ornl.gov>
	<Pine.LNX.4.64.0605252113210.20127@gannet.stats.ox.ac.uk>
	<44770610.2010802@wald.ucdavis.edu>
Message-ID: <44772E63.9070808@ornl.gov>

Thanks for helping me understand what is going on. Understanding is 
really my reason for the compile. I took the R_tryEval() route to fixing 
the problem.

I am running SuSE Linux 9.2 on that machine, which might support 
visibility under gcc3 as Brian points out.

Thanks again,
George

Duncan Temple Lang wrote:
>
> In addition to the compiler issues, the test should also be changed.
> It should use R_tryEval() directly rather than Test_tryEval().  The 
> test preceeds the existence
> of that exported routine that was motivated by the same
> usage that gave rise to this test.
>
> I'll commit an update when I get a few minutes.
>
>  D.
>
> Prof Brian Ripley wrote:
>> What system is this?
>>
>> It should work under gcc-3.3.4, as the issue is visibility attributes 
>> and they are not supposed to be supported on that compiler.  (I 
>> suspect from the message that this is not a version of gcc released 
>> by GNU, a common source of problems.)  I happen to have an i686 FC3 
>> system with a gcc 3.3.5 compiled from the GNU sources (to help track 
>> down a bug in code generated by that compiler), and that does work in 
>> tests/Embedding.
>>
>> In src/main/context.c you will find
>>
>> context.c:Rboolean attribute_hidden R_ToplevelExec(void (*fun)(void 
>> *), void *data)
>>
>> and you need to remove 'attribute_hidden' and recompile.
>>
>> (There is a known problem here with gcc >= 4.0.0, with this fix in 
>> the pre-2.3.1 sources.  We know that certain RedHat systems have 
>> gcc3's that support visibility, not always completely.)
>>
>>
>> On Thu, 25 May 2006, George Ostrouchov wrote:
>>
>>> I am compiling the Embedding examples in the tests directory and get an
>>> undefined reference. I include the make output as well as grep'd output
>>> of nm on libR.so and compiler and arch information. Do I have an
>>> improperly built R shared library or is there a problem with the
>>> Embedding tests or something else I am not seeing?
>>>
>>> Thanks for any help!
>>> George
>>>
>>>
>>> ost at hawk0:/data5/ost/R/R-2.3.0/tests/Embedding> make
>>> ../../bin/R CMD LINK gcc -o Rtest Rtest.o embeddedRCall.o -L`cd 
>>> ../.. &&
>>> /bin/pwd`/lib -lR
>>> gcc -o Rtest Rtest.o embeddedRCall.o
>>> -L/autofs/tewa_data5/ost/R/R-2.3.0/lib -lR -Wl,--rpath
>>> -Wl,/data5/ost/R/R-2.3.0/lib
>>> embeddedRCall.o(.text+0x1e): In function `Test_tryEval':
>>> /autofs/tewa_data5/ost/R/R-2.3.0/tests/Embedding/embeddedRCall.c:81:
>>> undefined reference to `R_ToplevelExec'
>>> collect2: ld returned 1 exit status
>>> make: *** [Rtest] Error 1
>>> ost at hawk0:/data5/ost/R/R-2.3.0/tests/Embedding> cd
>>> /autofs/tewa_data5/ost/R/R-2.3.0/lib
>>> ost at hawk0:/autofs/tewa_data5/ost/R/R-2.3.0/lib> nm libR.so | grep R_Top
>>> 000000000042c920 B R_Toplevel
>>> 000000000042cae8 B R_ToplevelContext
>>> 000000000007a7b0 t R_ToplevelExec
>>> ost at hawk0:/autofs/tewa_data5/ost/R/R-2.3.0/lib> gcc --version
>>> gcc (GCC) 3.3.4 (pre 3.3.5 20040809)
>>> Copyright (C) 2003 Free Software Foundation, Inc.
>>> This is free software; see the source for copying conditions.  There 
>>> is NO
>>> warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR 
>>> PURPOSE.
>>>
>>> ost at hawk0:/autofs/tewa_data5/ost/R/R-2.3.0/lib> arch
>>> x86_64
>>> ost at hawk0:/autofs/tewa_data5/ost/R/R-2.3.0/lib>
>>>
>>>
>>>
>>

-- 
George Ostrouchov
Statistics and Data Sciences Group
Computer Science and Mathematics Division
Oak Ridge National Laboratory
http://www.csm.ornl.gov/~ost

Register for the JRC 2006?
http://2006jointresearch.bus.utk.edu/
Conference starts June 6, 2006.


From A.Robinson at ms.unimelb.edu.au  Sat May 27 01:27:28 2006
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Sat, 27 May 2006 09:27:28 +1000
Subject: [Rd] R 2.3.1 release candidates starting tomorrow
In-Reply-To: <x2d5e023g5.fsf@turmalin.kubism.ku.dk>
References: <x2d5e023g5.fsf@turmalin.kubism.ku.dk>
Message-ID: <20060526232728.GQ75157@ms.unimelb.edu.au>

Hi all,

it builds just fine, but I get a warning on FreeBSD 6.1

less /usr/local/testing/R-beta/tests/survival.Rcheck/00check.log
* using log directory
'/usr/local/testing/R-beta/tests/survival.Rcheck'
* using Version 2.3.1 beta (2006-05-25 r38197)
* checking for file 'survival/DESCRIPTION' ... OK
* this is package 'survival' version '2.26'
* checking package dependencies ... OK
* checking if this is a source package ... OK
* skipping installation test
* checking package directory ... OK
* checking for portable file names ... OK
* checking for sufficient/correct file permissions ... OK
* checking DESCRIPTION meta-information ... OK
* checking top-level files ... OK
* checking index information ... OK
* checking package subdirectories ... OK
* checking R files for syntax errors ... OK
* checking R files for library.dynam ... OK
* checking S3 generic/method consistency ... OK
* checking replacement functions ... OK
* checking foreign function calls ... OK
* checking Rd files ... OK
* checking for missing documentation entries ... OK
* checking for code/documentation mismatches ... WARNING
Codoc mismatches from documentation object 'survival-internal':
as.data.frame.difftime
  Code: function(x, row.names = NULL, optional = FALSE)
  Docs: function(x, row.names = NULL, optional = FALSE, ...)

* checking Rd \usage sections ... OK
* checking for CRLF line endings in C/C++/Fortran sources/headers
* ... OK
* creating survival-Ex.R ... OK
* checking examples ... OK
* creating survival-manual.tex ... OK
* checking survival-manual.tex ... OK


This is: 

> version  
               _                                     
platform       i386-unknown-freebsd6.1               
arch           i386                                  
os             freebsd6.1                            
system         i386, freebsd6.1                      
status         beta                                  
major          2                                     
minor          3.1                                   
year           2006                                  
month          05                                    
day            25                                    
svn rev        38197                                 
language       R                                     
version.string Version 2.3.1 beta (2006-05-25 r38197)


Cheers

Andrew


On Fri, May 26, 2006 at 05:47:22PM +0200, Peter Dalgaard wrote:
> 
> Starting with tomorrow's build, the beta designation will be replaced
> by RC. This also implies that we are in "hard" code freeze, and that
> we're not going to change anything unless it is critical. If you do
> not want such critical bugs to slip into the final release, please
> check the release candidates on your platform and report back if you
> find problems. 
> 
> The directory for prereleases is
> 
> http://cran.r-project.org/src/base-prerelease/
> 
> -- 
>    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
Email: a.robinson at ms.unimelb.edu.au         http://www.ms.unimelb.edu.au


From edd at debian.org  Sat May 27 02:44:38 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 26 May 2006 19:44:38 -0500
Subject: [Rd] R 2.3.1 release candidates starting tomorrow
In-Reply-To: <x2d5e023g5.fsf@turmalin.kubism.ku.dk>
References: <x2d5e023g5.fsf@turmalin.kubism.ku.dk>
Message-ID: <17527.41206.254624.65723@basebud.nulle.part>


On 26 May 2006 at 17:47, Peter Dalgaard wrote:
| 
| Starting with tomorrow's build, the beta designation will be replaced
| by RC. This also implies that we are in "hard" code freeze, and that
| we're not going to change anything unless it is critical. If you do
| not want such critical bugs to slip into the final release, please
| check the release candidates on your platform and report back if you
| find problems. 
| 
| The directory for prereleases is
| 
| http://cran.r-project.org/src/base-prerelease/

FWIW I started a week ago with pre-releases in Debian unstable and added
another one today. So if you're on Debian, these are easy to test.
I guess I had my lingo wrong as I already called these beta. Sorry, my bad.

r-base (2.3.0.svn38197-1) unstable; urgency=low

  * Second beta release of the upcoming R 2.3.1 scheduled for June 1

 -- Dirk Eddelbuettel <edd at debian.org>  Fri, 26 May 2006 06:09:03 -0500

r-base (2.3.0.svn38119-1) unstable; urgency=low

  * First beta release of the upcoming R 2.3.1 scheduled for June 1

  * debian/control: Standards-Version: increased to 3.7.2
  
  * debian/r-cran.mk: Small improvements 

 -- Dirk Eddelbuettel <edd at debian.org>  Fri, 19 May 2006 20:15:30 -0500


(FYI r-cran.mk is a all we now need for debian/rules in the many r-cran-*
packages. It centralises the debian/rules logic; each of those packages
reduces its debian/rules to

	include /usr/share/R/debian/r-cran.mk

which is pretty sweet. Kudos to Rafael Laboissiere who gently nudged me to
try Debian's cdbs for these.)

Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From ripley at stats.ox.ac.uk  Sat May 27 08:31:23 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 27 May 2006 07:31:23 +0100 (BST)
Subject: [Rd] R 2.3.1 release candidates starting tomorrow
In-Reply-To: <20060526232728.GQ75157@ms.unimelb.edu.au>
References: <x2d5e023g5.fsf@turmalin.kubism.ku.dk>
	<20060526232728.GQ75157@ms.unimelb.edu.au>
Message-ID: <Pine.LNX.4.64.0605270728040.19522@gannet.stats.ox.ac.uk>

On Sat, 27 May 2006, Andrew Robinson wrote:

> Hi all,
>
> it builds just fine, but I get a warning on FreeBSD 6.1

That is a warning in a contributed package. It stems from

date.POSIXdate.R:as.data.frame.difftime <-as.data.frame.vector

and as.data.frame.vector differs by R version.  So it's just unfortunate
that a contributed package is in effect documenting a function in base.

Nothing worth attending to,

>
> less /usr/local/testing/R-beta/tests/survival.Rcheck/00check.log
> * using log directory
> '/usr/local/testing/R-beta/tests/survival.Rcheck'
> * using Version 2.3.1 beta (2006-05-25 r38197)
> * checking for file 'survival/DESCRIPTION' ... OK
> * this is package 'survival' version '2.26'
> * checking package dependencies ... OK
> * checking if this is a source package ... OK
> * skipping installation test
> * checking package directory ... OK
> * checking for portable file names ... OK
> * checking for sufficient/correct file permissions ... OK
> * checking DESCRIPTION meta-information ... OK
> * checking top-level files ... OK
> * checking index information ... OK
> * checking package subdirectories ... OK
> * checking R files for syntax errors ... OK
> * checking R files for library.dynam ... OK
> * checking S3 generic/method consistency ... OK
> * checking replacement functions ... OK
> * checking foreign function calls ... OK
> * checking Rd files ... OK
> * checking for missing documentation entries ... OK
> * checking for code/documentation mismatches ... WARNING
> Codoc mismatches from documentation object 'survival-internal':
> as.data.frame.difftime
>  Code: function(x, row.names = NULL, optional = FALSE)
>  Docs: function(x, row.names = NULL, optional = FALSE, ...)
>
> * checking Rd \usage sections ... OK
> * checking for CRLF line endings in C/C++/Fortran sources/headers
> * ... OK
> * creating survival-Ex.R ... OK
> * checking examples ... OK
> * creating survival-manual.tex ... OK
> * checking survival-manual.tex ... OK
>
>
> This is:
>
>> version
>               _
> platform       i386-unknown-freebsd6.1
> arch           i386
> os             freebsd6.1
> system         i386, freebsd6.1
> status         beta
> major          2
> minor          3.1
> year           2006
> month          05
> day            25
> svn rev        38197
> language       R
> version.string Version 2.3.1 beta (2006-05-25 r38197)
>
>
> Cheers
>
> Andrew
>
>
> On Fri, May 26, 2006 at 05:47:22PM +0200, Peter Dalgaard wrote:
>>
>> Starting with tomorrow's build, the beta designation will be replaced
>> by RC. This also implies that we are in "hard" code freeze, and that
>> we're not going to change anything unless it is critical. If you do
>> not want such critical bugs to slip into the final release, please
>> check the release candidates on your platform and report back if you
>> find problems.
>>
>> The directory for prereleases is
>>
>> http://cran.r-project.org/src/base-prerelease/
>>
>> --
>>    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
>> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From berwin at maths.uwa.edu.au  Sat May 27 13:07:57 2006
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Sat, 27 May 2006 19:07:57 +0800
Subject: [Rd] Patch proposal for match.fun()
Message-ID: <17528.13069.242669.464930@bossiaea.maths.uwa.edu.au>

G'day all,

some time ago I sent an email regarding the following behaviour of
match.fun():

> x <- matrix(rnorm(200), ncol=2)
> var <- "fred"
> apply(x, 2, var)
Error in get(x, envir, mode, inherits) : variable "fred" of mode "function" was not found

and asked whether it would be desirable to change this behaviour such
that the function var would be found and no error would be produced.
I also asked whether there are arguments against such a change.

As I did not receive any arguments against such a change, I looked
into changing match.fun() such that the example above would work.  The
result is the patch attached below.  On my machine, r-devel passes
"make check FORCE=FORCE" with this patch applied.  Thus, hopefully
this change to match.fun() does not break anything.

I realise that there is now a lot of code replication in the function,
but was not sure whether it would be worthwile to write a small helper
function to reduce this replication.  (In particular, I was not sure
whether that would then involve using substitute thrice.  Since I
rarely use this command I am not so sure about its proper use.)

Also, I presume it is debatable whether a warning should be issued if
the lookup using get() fails if the argument was a character string of
length one.  Personally, I like it because the user still gets some
feedback that he used an (important) function name as variable name:

   > x <- matrix(rnorm(200), ncol=2)
   > var <- "foo"
   > apply(x, 2, var)
   [1] 1.055595 1.098397
   Warning message:
   Error in get(x, envir, mode, inherits) : variable "foo" of mode "function" was not found
    in: match.fun(FUN) 

and the combination of warning + error should make it really easy to
track down situations like this:

   > foo <- "bar"
   > apply(x, 2, foo)
   Error in get(x, envir, mode, inherits) : variable "foo" of mode "function" was not found
   In addition: Warning message:
   Error in get(x, envir, mode, inherits) : variable "bar" of mode "function" was not found
    in: match.fun(FUN) 

Of course, other people might have other tastes. :)

Please consider applying this patch (or a variation) to r-devel.

Thanks.

Cheers,

        Berwin

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: R-patch
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060527/71da1900/attachment.pl 

From pinard at iro.umontreal.ca  Sat May 27 14:29:21 2006
From: pinard at iro.umontreal.ca (pinard at iro.umontreal.ca)
Date: Sat, 27 May 2006 14:29:21 +0200 (CEST)
Subject: [Rd] Correction to ?alist (PR#8904)
Message-ID: <20060527122921.27EACCCD6@slim.kubism.ku.dk>

Hi, people.  ?alist says:

     'alist' is like 'list', except in the handling of tagged arguments
     with no value.

As written, this description is misleading.  For example:

    > list(e=3+5)
    $e
    [1] 8

    > alist(e=3+5)
    $e
    3 + 5

We are not in the situation of tagged arguments with no value, and then,
clearly, 'list' and 'alist' behave differently.  The 'alist' documentation
probably needs to be amended, or clarified.

--please do not edit the information below--

Version:
 platform = i686-pc-linux-gnu
 arch = i686
 os = linux-gnu
 system = i686, linux-gnu
 status = Under development (unstable)
 major = 2
 minor = 4.0
 year = 2006
 month = 05
 day = 13
 svn rev = 38058
 language = R
 version.string = R version 2.4.0 Under development (unstable) (2006-05-13 r38058)

Locale:
LC_CTYPE=fr_CA.UTF-8;LC_NUMERIC=C;LC_TIME=fr_CA.UTF-8;LC_COLLATE=fr_CA.UTF-8;LC_MONETARY=fr_CA.UTF-8;LC_MESSAGES=fr_CA.UTF-8;LC_PAPER=fr_CA.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=fr_CA.UTF-8;LC_IDENTIFICATION=C

Search Path:
 .GlobalEnv, package:methods, package:stats, package:utils, package:datasets, fp.etc, package:graphics, package:grDevices, Autoloads, package:base

-- 
Fran??ois Pinard   http://pinard.progiciels-bpi.ca


From renaud.lancelot at cirad.fr  Sat May 27 16:19:52 2006
From: renaud.lancelot at cirad.fr (renaud.lancelot at cirad.fr)
Date: Sat, 27 May 2006 16:19:52 +0200 (CEST)
Subject: [Rd] Recommended package nlme: bug in predict.lme when an
	independent variable is a polynomial (PR#8905)
Message-ID: <20060527141952.0818A103FE@slim.kubism.ku.dk>

Full_Name: Renaud Lancelot
Version: Version 2.3.0 (2006-04-24)
OS: MS Windows XP Pro SP2
Submission from: (NULL) (82.239.219.108)


I think there is a bug in predict.lme, when a polynomial generated by poly() is
used as an explanatory variable, and a new data.frame is used for predictions. I
guess this is related to * not * using, for predictions, the coefs used in
constructing the orthogonal polynomials before fitting the model:

> fm <- lme(distance ~ poly(age, 3) + Sex, data = Orthodont, random = ~ 1)
> 
> # data for predictions
> Newdata <- head(Orthodont)
> Newdata$Sex <- factor(Newdata$Sex, levels = levels(Orthodont$Sex))
> 
> # "naive" model matrix for predictions
> mm1 <- model.matrix(~ poly(age, 3) + Sex, data = Newdata)
> 
> # "correct" model matrix for predictions
> p <- poly(Orthodont$age, 3)
> mm2 <- model.matrix(~ poly(age, 3, coefs = attr(p, "coefs")) + Sex, data =
Newdata)
> 
> data.frame(pred1 = predict(fm, level = 0, newdata = Newdata),
+            pred2 = mm1 %*% fixef(fm),
+            pred3 = head(predict(fm, level = 0)),
+            pred4 = mm2 %*% fixef(fm))
     pred1    pred2    pred3    pred4
1 18.61469 18.61469 23.13079 23.13079
2 23.23968 23.23968 24.11227 24.11227
3 29.90620 29.90620 25.59375 25.59375
4 36.19756 36.19756 27.03819 27.03819
5 18.61469 18.61469 23.13079 23.13079
6 23.23968 23.23968 24.11227 24.11227

Best regards,

Renaud


From maechler at stat.math.ethz.ch  Sat May 27 21:53:28 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 27 May 2006 21:53:28 +0200
Subject: [Rd] typo in ?dimnames
In-Reply-To: <447713D0.40305@telenet.be>
References: <447713D0.40305@telenet.be>
Message-ID: <17528.44600.821845.793123@stat.math.ethz.ch>

>>>>> "Tobias" == Tobias Verbeke <tobias.verbeke at telenet.be>
>>>>>     on Fri, 26 May 2006 16:42:24 +0200 writes:

    Tobias> Dear list,

    Tobias> In ?dimnames, section `Value' I read:

    Tobias> For the '"data.frame"' method both dimnames must be non-null, and
    Tobias> the rownames must be contain no duplicates nor missing values.
    Tobias>             ^^^^^^^

Thank you, Tobias.  I've fixed this - even for the release candidate.
{so completely trivial, it can't have any adverse effect}

Martin


From diez at kuicr.kyoto-u.ac.jp  Mon May 29 06:09:19 2006
From: diez at kuicr.kyoto-u.ac.jp (=?ISO-8859-1?Q?Diego_D=EDez?=)
Date: Mon, 29 May 2006 13:09:19 +0900
Subject: [Rd] R-2.3 macosx segfault
Message-ID: <BF8D24E0-1A5A-4183-8125-00385E4B884F@kuicr.kyoto-u.ac.jp>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20060529/af2bbcad/attachment.pl 

From g_lukas at freesurf.ch  Mon May 29 11:52:00 2006
From: g_lukas at freesurf.ch (g_lukas at freesurf.ch)
Date: Mon, 29 May 2006 11:52:00 +0200 (CEST)
Subject: [Rd] misspelling of "Mauchly" (PR#8908)
Message-ID: <20060529095200.37C9A3F036@slim.kubism.ku.dk>

Hi there,

The word "Mauchly" is still misspelled as *"Mauchley", at least in 
some /output/ of mauchly.test() and in the SSD() help page.

Sincerely,
Lukas Giesinger


From p.dalgaard at biostat.ku.dk  Mon May 29 12:07:28 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 29 May 2006 12:07:28 +0200
Subject: [Rd] misspelling of "Mauchly" (PR#8908)
In-Reply-To: <20060529095200.37C9A3F036@slim.kubism.ku.dk>
References: <20060529095200.37C9A3F036@slim.kubism.ku.dk>
Message-ID: <x24pz916vz.fsf@viggo.kubism.ku.dk>

g_lukas at freesurf.ch writes:

> Hi there,
> 
> The word "Mauchly" is still misspelled as *"Mauchley", at least in 
> some /output/ of mauchly.test() and in the SSD() help page.
> 
> Sincerely,
> Lukas Giesinger

Fixed for 2.3.1 

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From tlumley at u.washington.edu  Mon May 29 17:27:18 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 29 May 2006 08:27:18 -0700 (PDT)
Subject: [Rd] memory profiling
In-Reply-To: <Pine.LNX.4.64.0605261544530.26987@gannet.stats.ox.ac.uk>
References: <4476F312.4090902@jhsph.edu>
	<Pine.LNX.4.64.0605261544530.26987@gannet.stats.ox.ac.uk>
Message-ID: <Pine.LNX.4.64.0605290823400.8687@homer23.u.washington.edu>

On Fri, 26 May 2006, Prof Brian Ripley wrote:
> On Fri, 26 May 2006, Roger D. Peng wrote:
>
>> I'm interested in playing around with memory profiling in R-devel (as described
>> at http://developer.r-project.org/memory-profiling.html) and was trying to
>> figure out how to compile R-devel so that I can use the 'tracemem()' function.
>> But I can't figure out how/where to set R_MEMORY_PROFILING.  Is it on the
>> configure command line?
>
> I added -DR_MEMORY_PROFILING to CFLAGS in config.site.  An alternative is
> to add this to DEFS in Makeconf after configuring.
>
> Probably in due course there will be a way to do it via configure and
> config.h, but I do not see one.
>

Yes, adding the -DR_MEMORY_PROFILING to CFLAGS is the intended way to do 
it at the moment. In due course there will be a configure option, but 
definitely not until after useR.

 	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From teck.lim at imperial.ac.uk  Mon May 29 18:22:20 2006
From: teck.lim at imperial.ac.uk (teck.lim at imperial.ac.uk)
Date: Mon, 29 May 2006 18:22:20 +0200 (CEST)
Subject: [Rd] Numerical error in R (win32) (PR#8909)
Message-ID: <20060529162220.E2ADE3F045@slim.kubism.ku.dk>

Hi
    I had observed the following problem in R (also C, Matlab, and Python).
sprintf('%1.2g\n', 3.15)
give 3.1 instead of 3.2 whereas an input of 3.75 gives 3.8.
Java's System.out.printf is ok though.  
 
> round(3.75,1)
[1] 3.8
> round(3.15,1)
[1] 3.1
 
Similar outcome with sprintf in R.


However, the right answer should be 3.2
 
Regards
Teckpor
 

	[[alternative HTML version deleted]]


From murdoch at stats.uwo.ca  Mon May 29 18:40:51 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 29 May 2006 12:40:51 -0400
Subject: [Rd] Numerical error in R (win32) (PR#8909)
In-Reply-To: <20060529162220.E2ADE3F045@slim.kubism.ku.dk>
References: <20060529162220.E2ADE3F045@slim.kubism.ku.dk>
Message-ID: <447B2413.1@stats.uwo.ca>

On 5/29/2006 12:22 PM, teck.lim at imperial.ac.uk wrote:
> Hi
>     I had observed the following problem in R (also C, Matlab, and Python).
> sprintf('%1.2g\n', 3.15)
> give 3.1 instead of 3.2 whereas an input of 3.75 gives 3.8.
> Java's System.out.printf is ok though.  
>  
>> round(3.75,1)
> [1] 3.8
>> round(3.15,1)
> [1] 3.1
>  
> Similar outcome with sprintf in R.
> 
> 
> However, the right answer should be 3.2

This is not a bug.  There is no way to represent 3.15 exactly in double 
precision, so it is hard to predict whether it will round up or down. 
Apparently on the machine you were using it is represented as a number 
slightly less than 3.15, which rounds down.

Duncan Murdoch


From ligges at statistik.uni-dortmund.de  Mon May 29 18:44:31 2006
From: ligges at statistik.uni-dortmund.de (ligges at statistik.uni-dortmund.de)
Date: Mon, 29 May 2006 18:44:31 +0200 (CEST)
Subject: [Rd] Numerical error in R (win32) (PR#8909)
Message-ID: <20060529164431.186753F036@slim.kubism.ku.dk>

teck.lim at imperial.ac.uk wrote:

> Hi
>     I had observed the following problem in R (also C, Matlab, and Python).
> sprintf('%1.2g\n', 3.15)
> give 3.1 instead of 3.2 whereas an input of 3.75 gives 3.8.
> Java's System.out.printf is ok though.  
>  
> 
>>round(3.75,1)
> 
> [1] 3.8
> 
>>round(3.15,1)
> 
> [1] 3.1
>  
> Similar outcome with sprintf in R.
> 
> 
> However, the right answer should be 3.2

This is not a bug.

Please read the R FAQ "Why doesn't R think these numbers are equal?" and 
after that note that *numerically* the following inaqualities are TRUE:
(3.2 - 3.15) > 0.05
(3.15 - 3.1) < 0.05

Uwe Ligges


> Regards
> Teckpor
>  
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ehlers at math.ucalgary.ca  Mon May 29 18:44:36 2006
From: ehlers at math.ucalgary.ca (Peter Ehlers)
Date: Mon, 29 May 2006 10:44:36 -0600
Subject: [Rd] Numerical error in R (win32) (PR#8909)
In-Reply-To: <20060529162220.E2ADE3F045@slim.kubism.ku.dk>
References: <20060529162220.E2ADE3F045@slim.kubism.ku.dk>
Message-ID: <447B24F4.6090303@math.ucalgary.ca>

Did you check the Details section of the help page for round()?

Peter Ehlers

teck.lim at imperial.ac.uk wrote:

> Hi
>     I had observed the following problem in R (also C, Matlab, and Python).
> sprintf('%1.2g\n', 3.15)
> give 3.1 instead of 3.2 whereas an input of 3.75 gives 3.8.
> Java's System.out.printf is ok though.  
>  
> 
>>round(3.75,1)
> 
> [1] 3.8
> 
>>round(3.15,1)
> 
> [1] 3.1
>  
> Similar outcome with sprintf in R.
> 
> 
> However, the right answer should be 3.2
>  
> Regards
> Teckpor
>  
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From p.dalgaard at biostat.ku.dk  Mon May 29 18:49:09 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 29 May 2006 18:49:09 +0200
Subject: [Rd] Numerical error in R (win32) (PR#8909)
In-Reply-To: <20060529162220.E2ADE3F045@slim.kubism.ku.dk>
References: <20060529162220.E2ADE3F045@slim.kubism.ku.dk>
Message-ID: <x2k684ojy2.fsf@turmalin.kubism.ku.dk>

teck.lim at imperial.ac.uk writes:

> Hi
>     I had observed the following problem in R (also C, Matlab, and Python).
> sprintf('%1.2g\n', 3.15)
> give 3.1 instead of 3.2 whereas an input of 3.75 gives 3.8.
> Java's System.out.printf is ok though.  
>  
> > round(3.75,1)
> [1] 3.8
> > round(3.15,1)
> [1] 3.1
>  
> Similar outcome with sprintf in R.
> 
> 
> However, the right answer should be 3.2

According to what? Remember that we're dealing with finite precision
binary arithmetic here:

>  (3.15 - 3.1)<.05
[1] TRUE
>  abs(3.15 - 3.2)>.05
[1] TRUE

See also FAQ 7.31.
  
> Regards
> Teckpor
> 

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From tzotchev at euv-frankfurt-o.de  Tue May 30 10:01:53 2006
From: tzotchev at euv-frankfurt-o.de (tzotchev at euv-frankfurt-o.de)
Date: Tue, 30 May 2006 10:01:53 +0200 (CEST)
Subject: [Rd] R Regression Routines called in C/C++
Message-ID: <51288.160.79.240.156.1148976113.squirrel@webmail.euv-ffo.de>

I would like to call the R regression routines in C/C++. I have seen that
it is possible to call distribution function, optimisation routines etc,
but is it possible to call a simple OLS and which is the relevant header
file?

Thanks.


From ripley at stats.ox.ac.uk  Tue May 30 10:24:59 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 30 May 2006 09:24:59 +0100 (BST)
Subject: [Rd] R Regression Routines called in C/C++
In-Reply-To: <51288.160.79.240.156.1148976113.squirrel@webmail.euv-ffo.de>
References: <51288.160.79.240.156.1148976113.squirrel@webmail.euv-ffo.de>
Message-ID: <Pine.LNX.4.64.0605300919250.661@gannet.stats.ox.ac.uk>

On Tue, 30 May 2006, tzotchev at euv-frankfurt-o.de wrote:

> I would like to call the R regression routines in C/C++. I have seen that
> it is possible to call distribution function, optimisation routines etc,
> but is it possible to call a simple OLS and which is the relevant header
> file?

Regression is done in Fortran and is not part of the standalone nmath (nor 
are the optimization routines).  If you meant from C/C++ code in an R 
package, take a look at e.g. lqs in MASS which does this via the routines 
declared in R_ext/Applic.h.  Similar routines are called by lm.fit.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Tue May 30 10:52:46 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 30 May 2006 09:52:46 +0100 (BST)
Subject: [Rd] (PR#8905) Recommended package nlme: bug in predict.lme
 when an independent variable is a polynomial
In-Reply-To: <20060527141952.0818A103FE@slim.kubism.ku.dk>
References: <20060527141952.0818A103FE@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.64.0605300947120.801@gannet.stats.ox.ac.uk>

This is not really a bug.  See

http://developer.r-project.org/model-fitting-functions.txt

for how this is handled in other packages. All model-fitting in R used to 
do this (and it is described in the White Book and MASS1-3).

predict.lme does not use model.frame as described in that URL.  Dr Bates' 
recent response to another query applies here: lmer is more standard and I 
suggest you try it instead.   (I don't think anyone is going to be 
rewriting lme to use model.frame: it is essentially in maintainence mode.)

On Sat, 27 May 2006, renaud.lancelot at cirad.fr wrote:

> Full_Name: Renaud Lancelot
> Version: Version 2.3.0 (2006-04-24)
> OS: MS Windows XP Pro SP2
> Submission from: (NULL) (82.239.219.108)
>
>
> I think there is a bug in predict.lme, when a polynomial generated by poly() is
> used as an explanatory variable, and a new data.frame is used for predictions. I
> guess this is related to * not * using, for predictions, the coefs used in
> constructing the orthogonal polynomials before fitting the model:
>
>> fm <- lme(distance ~ poly(age, 3) + Sex, data = Orthodont, random = ~ 1)
>>
>> # data for predictions
>> Newdata <- head(Orthodont)
>> Newdata$Sex <- factor(Newdata$Sex, levels = levels(Orthodont$Sex))
>>
>> # "naive" model matrix for predictions
>> mm1 <- model.matrix(~ poly(age, 3) + Sex, data = Newdata)
>>
>> # "correct" model matrix for predictions
>> p <- poly(Orthodont$age, 3)
>> mm2 <- model.matrix(~ poly(age, 3, coefs = attr(p, "coefs")) + Sex, data =
> Newdata)
>>
>> data.frame(pred1 = predict(fm, level = 0, newdata = Newdata),
> +            pred2 = mm1 %*% fixef(fm),
> +            pred3 = head(predict(fm, level = 0)),
> +            pred4 = mm2 %*% fixef(fm))
>     pred1    pred2    pred3    pred4
> 1 18.61469 18.61469 23.13079 23.13079
> 2 23.23968 23.23968 24.11227 24.11227
> 3 29.90620 29.90620 25.59375 25.59375
> 4 36.19756 36.19756 27.03819 27.03819
> 5 18.61469 18.61469 23.13079 23.13079
> 6 23.23968 23.23968 24.11227 24.11227
>
> Best regards,
>
> Renaud
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Tue May 30 11:03:50 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 30 May 2006 10:03:50 +0100 (BST)
Subject: [Rd] (PR#8905) Recommended package nlme: bug in predict.lme
 when an independent variable is a polynomial
In-Reply-To: <Pine.LNX.4.64.0605300947120.801@gannet.stats.ox.ac.uk>
References: <20060527141952.0818A103FE@slim.kubism.ku.dk>
	<Pine.LNX.4.64.0605300947120.801@gannet.stats.ox.ac.uk>
Message-ID: <Pine.LNX.4.64.0605300958350.857@gannet.stats.ox.ac.uk>

On Tue, 30 May 2006, Prof Brian Ripley wrote:

> This is not really a bug.  See
>
> http://developer.r-project.org/model-fitting-functions.txt
>
> for how this is handled in other packages. All model-fitting in R used to
> do this (and it is described in the White Book and MASS1-3).
>
> predict.lme does not use model.frame as described in that URL.  Dr Bates'
> recent response to another query applies here: lmer is more standard and I
> suggest you try it instead.   (I don't think anyone is going to be
> rewriting lme to use model.frame: it is essentially in maintainence mode.)

Another workaround is to use poly(..., raw=TRUE).  I don't actually see 
anything in this report using predict.lme, but compare

> predict(fm, Newdata)
      M01      M01      M01      M01      M02      M02
21.01353 25.63852 32.30504 38.59640 17.24007 21.86507
attr(,"label")
[1] "Predicted values (mm)"
> fm <- lme(distance ~ poly(age, 3, raw=TRUE) + Sex, data = Orthodont,
             random = ~1)
> predict(fm, Newdata)
      M01      M01      M01      M01      M02      M02
25.52963 26.51111 27.99259 29.43703 21.75617 22.73765
attr(,"label")
[1] "Predicted values (mm)"


> On Sat, 27 May 2006, renaud.lancelot at cirad.fr wrote:
>
>> Full_Name: Renaud Lancelot
>> Version: Version 2.3.0 (2006-04-24)
>> OS: MS Windows XP Pro SP2
>> Submission from: (NULL) (82.239.219.108)
>>
>>
>> I think there is a bug in predict.lme, when a polynomial generated by poly() is
>> used as an explanatory variable, and a new data.frame is used for predictions. I
>> guess this is related to * not * using, for predictions, the coefs used in
>> constructing the orthogonal polynomials before fitting the model:
>>
>>> fm <- lme(distance ~ poly(age, 3) + Sex, data = Orthodont, random = ~ 1)
>>>
>>> # data for predictions
>>> Newdata <- head(Orthodont)
>>> Newdata$Sex <- factor(Newdata$Sex, levels = levels(Orthodont$Sex))
>>>
>>> # "naive" model matrix for predictions
>>> mm1 <- model.matrix(~ poly(age, 3) + Sex, data = Newdata)
>>>
>>> # "correct" model matrix for predictions
>>> p <- poly(Orthodont$age, 3)
>>> mm2 <- model.matrix(~ poly(age, 3, coefs = attr(p, "coefs")) + Sex, data =
>> Newdata)
>>>
>>> data.frame(pred1 = predict(fm, level = 0, newdata = Newdata),
>> +            pred2 = mm1 %*% fixef(fm),
>> +            pred3 = head(predict(fm, level = 0)),
>> +            pred4 = mm2 %*% fixef(fm))
>>     pred1    pred2    pred3    pred4
>> 1 18.61469 18.61469 23.13079 23.13079
>> 2 23.23968 23.23968 24.11227 24.11227
>> 3 29.90620 29.90620 25.59375 25.59375
>> 4 36.19756 36.19756 27.03819 27.03819
>> 5 18.61469 18.61469 23.13079 23.13079
>> 6 23.23968 23.23968 24.11227 24.11227
>>
>> Best regards,
>>
>> Renaud
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From renaud.lancelot at gmail.com  Tue May 30 12:06:02 2006
From: renaud.lancelot at gmail.com (Renaud Lancelot)
Date: Tue, 30 May 2006 12:06:02 +0200
Subject: [Rd] (PR#8905) Recommended package nlme: bug in predict.lme
	when an independent variable is a polynomial
In-Reply-To: <Pine.LNX.4.64.0605300958350.857@gannet.stats.ox.ac.uk>
References: <20060527141952.0818A103FE@slim.kubism.ku.dk>
	<Pine.LNX.4.64.0605300947120.801@gannet.stats.ox.ac.uk>
	<Pine.LNX.4.64.0605300958350.857@gannet.stats.ox.ac.uk>
Message-ID: <c2ee56800605300306u4b06ee06h3a51b8482342f264@mail.gmail.com>

Many thanks for your very useful comments and suggestions.

Renaud

2006/5/30, Prof Brian Ripley <ripley at stats.ox.ac.uk>:
> On Tue, 30 May 2006, Prof Brian Ripley wrote:
>
> > This is not really a bug.  See
> >
> > http://developer.r-project.org/model-fitting-functions.txt
> >
> > for how this is handled in other packages. All model-fitting in R used to
> > do this (and it is described in the White Book and MASS1-3).
> >
> > predict.lme does not use model.frame as described in that URL.  Dr Bates'
> > recent response to another query applies here: lmer is more standard and I
> > suggest you try it instead.   (I don't think anyone is going to be
> > rewriting lme to use model.frame: it is essentially in maintainence mode.)
>
> Another workaround is to use poly(..., raw=TRUE).  I don't actually see
> anything in this report using predict.lme, but compare
>
> > predict(fm, Newdata)
>       M01      M01      M01      M01      M02      M02
> 21.01353 25.63852 32.30504 38.59640 17.24007 21.86507
> attr(,"label")
> [1] "Predicted values (mm)"
> > fm <- lme(distance ~ poly(age, 3, raw=TRUE) + Sex, data = Orthodont,
>              random = ~1)
> > predict(fm, Newdata)
>       M01      M01      M01      M01      M02      M02
> 25.52963 26.51111 27.99259 29.43703 21.75617 22.73765
> attr(,"label")
> [1] "Predicted values (mm)"
>
>
> > On Sat, 27 May 2006, renaud.lancelot at cirad.fr wrote:
> >
> >> Full_Name: Renaud Lancelot
> >> Version: Version 2.3.0 (2006-04-24)
> >> OS: MS Windows XP Pro SP2
> >> Submission from: (NULL) (82.239.219.108)
> >>
> >>
> >> I think there is a bug in predict.lme, when a polynomial generated by poly() is
> >> used as an explanatory variable, and a new data.frame is used for predictions. I
> >> guess this is related to * not * using, for predictions, the coefs used in
> >> constructing the orthogonal polynomials before fitting the model:
> >>
> >>> fm <- lme(distance ~ poly(age, 3) + Sex, data = Orthodont, random = ~ 1)
> >>>
> >>> # data for predictions
> >>> Newdata <- head(Orthodont)
> >>> Newdata$Sex <- factor(Newdata$Sex, levels = levels(Orthodont$Sex))
> >>>
> >>> # "naive" model matrix for predictions
> >>> mm1 <- model.matrix(~ poly(age, 3) + Sex, data = Newdata)
> >>>
> >>> # "correct" model matrix for predictions
> >>> p <- poly(Orthodont$age, 3)
> >>> mm2 <- model.matrix(~ poly(age, 3, coefs = attr(p, "coefs")) + Sex, data =
> >> Newdata)
> >>>
> >>> data.frame(pred1 = predict(fm, level = 0, newdata = Newdata),
> >> +            pred2 = mm1 %*% fixef(fm),
> >> +            pred3 = head(predict(fm, level = 0)),
> >> +            pred4 = mm2 %*% fixef(fm))
> >>     pred1    pred2    pred3    pred4
> >> 1 18.61469 18.61469 23.13079 23.13079
> >> 2 23.23968 23.23968 24.11227 24.11227
> >> 3 29.90620 29.90620 25.59375 25.59375
> >> 4 36.19756 36.19756 27.03819 27.03819
> >> 5 18.61469 18.61469 23.13079 23.13079
> >> 6 23.23968 23.23968 24.11227 24.11227
> >>
> >> Best regards,
> >>
> >> Renaud
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >>
> >
> >
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Renaud LANCELOT
D?partement Elevage et M?decine V?t?rinaire (EMVT) du CIRAD
Directeur adjoint charg? des affaires scientifiques

CIRAD, Animal Production and Veterinary Medicine Department
Deputy director for scientific affairs

Campus international de Baillarguet
TA 30 / B (B?t. B, Bur. 214)
34398 Montpellier Cedex 5 - France
T?l   +33 (0)4 67 59 37 17
Secr. +33 (0)4 67 59 39 04
Fax   +33 (0)4 67 59 37 95


From renaud.lancelot at gmail.com  Tue May 30 12:06:13 2006
From: renaud.lancelot at gmail.com (renaud.lancelot at gmail.com)
Date: Tue, 30 May 2006 12:06:13 +0200 (CEST)
Subject: [Rd] (PR#8905) Recommended package nlme: bug in predict.lme
	when an independent variable is a polynomial
Message-ID: <20060530100613.9C331C757@slim.kubism.ku.dk>

Many thanks for your very useful comments and suggestions.

Renaud

2006/5/30, Prof Brian Ripley <ripley at stats.ox.ac.uk>:
> On Tue, 30 May 2006, Prof Brian Ripley wrote:
>
> > This is not really a bug.  See
> >
> > http://developer.r-project.org/model-fitting-functions.txt
> >
> > for how this is handled in other packages. All model-fitting in R used =
to
> > do this (and it is described in the White Book and MASS1-3).
> >
> > predict.lme does not use model.frame as described in that URL.  Dr Bate=
s'
> > recent response to another query applies here: lmer is more standard an=
d I
> > suggest you try it instead.   (I don't think anyone is going to be
> > rewriting lme to use model.frame: it is essentially in maintainence mod=
e.)
>
> Another workaround is to use poly(..., raw=3DTRUE).  I don't actually see
> anything in this report using predict.lme, but compare
>
> > predict(fm, Newdata)
>       M01      M01      M01      M01      M02      M02
> 21.01353 25.63852 32.30504 38.59640 17.24007 21.86507
> attr(,"label")
> [1] "Predicted values (mm)"
> > fm <- lme(distance ~ poly(age, 3, raw=3DTRUE) + Sex, data =3D Orthodont=
,
>              random =3D ~1)
> > predict(fm, Newdata)
>       M01      M01      M01      M01      M02      M02
> 25.52963 26.51111 27.99259 29.43703 21.75617 22.73765
> attr(,"label")
> [1] "Predicted values (mm)"
>
>
> > On Sat, 27 May 2006, renaud.lancelot at cirad.fr wrote:
> >
> >> Full_Name: Renaud Lancelot
> >> Version: Version 2.3.0 (2006-04-24)
> >> OS: MS Windows XP Pro SP2
> >> Submission from: (NULL) (82.239.219.108)
> >>
> >>
> >> I think there is a bug in predict.lme, when a polynomial generated by =
poly() is
> >> used as an explanatory variable, and a new data.frame is used for pred=
ictions. I
> >> guess this is related to * not * using, for predictions, the coefs use=
d in
> >> constructing the orthogonal polynomials before fitting the model:
> >>
> >>> fm <- lme(distance ~ poly(age, 3) + Sex, data =3D Orthodont, random =
=3D ~ 1)
> >>>
> >>> # data for predictions
> >>> Newdata <- head(Orthodont)
> >>> Newdata$Sex <- factor(Newdata$Sex, levels =3D levels(Orthodont$Sex))
> >>>
> >>> # "naive" model matrix for predictions
> >>> mm1 <- model.matrix(~ poly(age, 3) + Sex, data =3D Newdata)
> >>>
> >>> # "correct" model matrix for predictions
> >>> p <- poly(Orthodont$age, 3)
> >>> mm2 <- model.matrix(~ poly(age, 3, coefs =3D attr(p, "coefs")) + Sex,=
 data =3D
> >> Newdata)
> >>>
> >>> data.frame(pred1 =3D predict(fm, level =3D 0, newdata =3D Newdata),
> >> +            pred2 =3D mm1 %*% fixef(fm),
> >> +            pred3 =3D head(predict(fm, level =3D 0)),
> >> +            pred4 =3D mm2 %*% fixef(fm))
> >>     pred1    pred2    pred3    pred4
> >> 1 18.61469 18.61469 23.13079 23.13079
> >> 2 23.23968 23.23968 24.11227 24.11227
> >> 3 29.90620 29.90620 25.59375 25.59375
> >> 4 36.19756 36.19756 27.03819 27.03819
> >> 5 18.61469 18.61469 23.13079 23.13079
> >> 6 23.23968 23.23968 24.11227 24.11227
> >>
> >> Best regards,
> >>
> >> Renaud
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >>
> >
> >
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


--=20
Renaud LANCELOT
D=E9partement Elevage et M=E9decine V=E9t=E9rinaire (EMVT) du CIRAD
Directeur adjoint charg=E9 des affaires scientifiques

CIRAD, Animal Production and Veterinary Medicine Department
Deputy director for scientific affairs

Campus international de Baillarguet
TA 30 / B (B=E2t. B, Bur. 214)
34398 Montpellier Cedex 5 - France
T=E9l   +33 (0)4 67 59 37 17
Secr. +33 (0)4 67 59 39 04
Fax   +33 (0)4 67 59 37 95


From teck.lim at imperial.ac.uk  Tue May 30 14:41:49 2006
From: teck.lim at imperial.ac.uk (ltp)
Date: Tue, 30 May 2006 13:41:49 +0100
Subject: [Rd] Numerical error in R (win32) (PR#8909)
In-Reply-To: <x2k684ojy2.fsf@turmalin.kubism.ku.dk>
Message-ID: <002c01c683e6$6bfc6e60$f9bec69b@ltpfujitsu>

Hi

	Thanks for the quick reply. However, I am not satisfied, as
> round(3.15000000, 1)
[1] 3.1
> round(3.75000000, 1)
[1] 3.8

	I think the problem is really more of an error in the rounding off
algorithm than finite precision.

Thanks
Teckpor

-----Original Message-----
From: pd at pubhealth.ku.dk [mailto:pd at pubhealth.ku.dk] On Behalf Of Peter
Dalgaard
Sent: Monday, May 29, 2006 17:49
To: teck.lim at imperial.ac.uk
Cc: r-devel at stat.math.ethz.ch; R-bugs at biostat.ku.dk
Subject: Re: [Rd] Numerical error in R (win32) (PR#8909)

teck.lim at imperial.ac.uk writes:

> Hi
>     I had observed the following problem in R (also C, Matlab, and
Python).
> sprintf('%1.2g\n', 3.15)
> give 3.1 instead of 3.2 whereas an input of 3.75 gives 3.8.
> Java's System.out.printf is ok though.  
>  
> > round(3.75,1)
> [1] 3.8
> > round(3.15,1)
> [1] 3.1
>  
> Similar outcome with sprintf in R.
> 
> 
> However, the right answer should be 3.2

According to what? Remember that we're dealing with finite precision binary
arithmetic here:

>  (3.15 - 3.1)<.05
[1] TRUE
>  abs(3.15 - 3.2)>.05
[1] TRUE

See also FAQ 7.31.
  
> Regards
> Teckpor
> 

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From teck.lim at imperial.ac.uk  Tue May 30 14:43:06 2006
From: teck.lim at imperial.ac.uk (teck.lim at imperial.ac.uk)
Date: Tue, 30 May 2006 14:43:06 +0200 (CEST)
Subject: [Rd] Numerical error in R (win32) (PR#8909)
Message-ID: <20060530124306.C0DBE3F045@slim.kubism.ku.dk>

Hi

	Thanks for the quick reply. However, I am not satisfied, as
> round(3.15000000, 1)
[1] 3.1
> round(3.75000000, 1)
[1] 3.8

	I think the problem is really more of an error in the rounding off
algorithm than finite precision.

Thanks
Teckpor 

-----Original Message-----
From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de] 
Sent: Monday, May 29, 2006 17:45
To: teck.lim at imperial.ac.uk
Cc: R-bugs at biostat.ku.dk
Subject: Re: [Rd] Numerical error in R (win32) (PR#8909)

teck.lim at imperial.ac.uk wrote:

> Hi
>     I had observed the following problem in R (also C, Matlab, and
Python).
> sprintf('%1.2g\n', 3.15)
> give 3.1 instead of 3.2 whereas an input of 3.75 gives 3.8.
> Java's System.out.printf is ok though.  
>  
> 
>>round(3.75,1)
> 
> [1] 3.8
> 
>>round(3.15,1)
> 
> [1] 3.1
>  
> Similar outcome with sprintf in R.
> 
> 
> However, the right answer should be 3.2

This is not a bug.

Please read the R FAQ "Why doesn't R think these numbers are equal?" and
after that note that *numerically* the following inaqualities are TRUE:
(3.2 - 3.15) > 0.05
(3.15 - 3.1) < 0.05

Uwe Ligges


> Regards
> Teckpor
>  
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From teck.lim at imperial.ac.uk  Tue May 30 14:42:43 2006
From: teck.lim at imperial.ac.uk (ltp)
Date: Tue, 30 May 2006 13:42:43 +0100
Subject: [Rd] Numerical error in R (win32) (PR#8909)
In-Reply-To: <447B2413.1@stats.uwo.ca>
Message-ID: <002f01c683e6$8b9ac2d0$f9bec69b@ltpfujitsu>

Hi

	Thanks for the quick reply. However, I am not satisfied, as
> round(3.15000000, 1)
[1] 3.1
> round(3.75000000, 1)
[1] 3.8

	I think the problem is really more of an error in the rounding off
algorithm than finite precision.

Thanks
Teckpor 

-----Original Message-----
From: Duncan Murdoch [mailto:murdoch at stats.uwo.ca] 
Sent: Monday, May 29, 2006 17:41
To: teck.lim at imperial.ac.uk
Cc: r-devel at stat.math.ethz.ch; R-bugs at biostat.ku.dk
Subject: Re: [Rd] Numerical error in R (win32) (PR#8909)

On 5/29/2006 12:22 PM, teck.lim at imperial.ac.uk wrote:
> Hi
>     I had observed the following problem in R (also C, Matlab, and
Python).
> sprintf('%1.2g\n', 3.15)
> give 3.1 instead of 3.2 whereas an input of 3.75 gives 3.8.
> Java's System.out.printf is ok though.  
>  
>> round(3.75,1)
> [1] 3.8
>> round(3.15,1)
> [1] 3.1
>  
> Similar outcome with sprintf in R.
> 
> 
> However, the right answer should be 3.2

This is not a bug.  There is no way to represent 3.15 exactly in double
precision, so it is hard to predict whether it will round up or down. 
Apparently on the machine you were using it is represented as a number
slightly less than 3.15, which rounds down.

Duncan Murdoch


From teck.lim at imperial.ac.uk  Tue May 30 14:42:13 2006
From: teck.lim at imperial.ac.uk (ltp)
Date: Tue, 30 May 2006 13:42:13 +0100
Subject: [Rd] Numerical error in R (win32) (PR#8909)
In-Reply-To: <447B24F4.6090303@math.ucalgary.ca>
Message-ID: <002d01c683e6$7a304ba0$f9bec69b@ltpfujitsu>

Hi

	Thanks for the quick reply. However, I am not satisfied, as
> round(3.15000000, 1)
[1] 3.1
> round(3.75000000, 1)
[1] 3.8

	I think the problem is really more of an error in the rounding off
algorithm than finite precision.

Thanks
Teckpor 

-----Original Message-----
From: Peter Ehlers [mailto:ehlers at math.ucalgary.ca] 
Sent: Monday, May 29, 2006 17:45
To: teck.lim at imperial.ac.uk
Cc: r-devel at stat.math.ethz.ch
Subject: Re: [Rd] Numerical error in R (win32) (PR#8909)

Did you check the Details section of the help page for round()?

Peter Ehlers

teck.lim at imperial.ac.uk wrote:

> Hi
>     I had observed the following problem in R (also C, Matlab, and
Python).
> sprintf('%1.2g\n', 3.15)
> give 3.1 instead of 3.2 whereas an input of 3.75 gives 3.8.
> Java's System.out.printf is ok though.  
>  
> 
>>round(3.75,1)
> 
> [1] 3.8
> 
>>round(3.15,1)
> 
> [1] 3.1
>  
> Similar outcome with sprintf in R.
> 
> 
> However, the right answer should be 3.2
>  
> Regards
> Teckpor
>  
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From p.dalgaard at biostat.ku.dk  Tue May 30 15:05:07 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 30 May 2006 15:05:07 +0200
Subject: [Rd] Numerical error in R (win32) (PR#8909)
In-Reply-To: <002c01c683e6$6bfc6e60$f9bec69b@ltpfujitsu>
References: <002c01c683e6$6bfc6e60$f9bec69b@ltpfujitsu>
Message-ID: <x2odxfacjg.fsf@viggo.kubism.ku.dk>

"ltp" <teck.lim at imperial.ac.uk> writes:

> Hi
> 
> 	Thanks for the quick reply. However, I am not satisfied, as
> > round(3.15000000, 1)
> [1] 3.1
> > round(3.75000000, 1)
> [1] 3.8
> 
> 	I think the problem is really more of an error in the rounding off
> algorithm than finite precision.

It isn't, and adding zeros doesn't change anything. The issue is that
3.15 has a nonterminating binary expansion, just like 1/7 has a
nonterminating decimal one. Please do read the references that have
already been provided to you.
 
3.15 (dec) == 11.0010011001100110011... (bin)
3.75 (dec) == 11.11 (bin)

> Thanks
> Teckpor
> 
> -----Original Message-----
> From: pd at pubhealth.ku.dk [mailto:pd at pubhealth.ku.dk] On Behalf Of Peter
> Dalgaard
> Sent: Monday, May 29, 2006 17:49
> To: teck.lim at imperial.ac.uk
> Cc: r-devel at stat.math.ethz.ch; R-bugs at biostat.ku.dk
> Subject: Re: [Rd] Numerical error in R (win32) (PR#8909)
> 
> teck.lim at imperial.ac.uk writes:
> 
> > Hi
> >     I had observed the following problem in R (also C, Matlab, and
> Python).
> > sprintf('%1.2g\n', 3.15)
> > give 3.1 instead of 3.2 whereas an input of 3.75 gives 3.8.
> > Java's System.out.printf is ok though.  
> >  
> > > round(3.75,1)
> > [1] 3.8
> > > round(3.15,1)
> > [1] 3.1
> >  
> > Similar outcome with sprintf in R.
> > 
> > 
> > However, the right answer should be 3.2
> 
> According to what? Remember that we're dealing with finite precision binary
> arithmetic here:
> 
> >  (3.15 - 3.1)<.05
> [1] TRUE
> >  abs(3.15 - 3.2)>.05
> [1] TRUE
> 
> See also FAQ 7.31.
>   
> > Regards
> > Teckpor
> > 
> 
> -- 
>    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907
> 
> 

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From p.dalgaard at biostat.ku.dk  Tue May 30 15:05:36 2006
From: p.dalgaard at biostat.ku.dk (p.dalgaard at biostat.ku.dk)
Date: Tue, 30 May 2006 15:05:36 +0200 (CEST)
Subject: [Rd] Numerical error in R (win32) (PR#8909)
Message-ID: <20060530130536.7765C3F04C@slim.kubism.ku.dk>

"ltp" <teck.lim at imperial.ac.uk> writes:

> Hi
> 
> 	Thanks for the quick reply. However, I am not satisfied, as
> > round(3.15000000, 1)
> [1] 3.1
> > round(3.75000000, 1)
> [1] 3.8
> 
> 	I think the problem is really more of an error in the rounding off
> algorithm than finite precision.

It isn't, and adding zeros doesn't change anything. The issue is that
3.15 has a nonterminating binary expansion, just like 1/7 has a
nonterminating decimal one. Please do read the references that have
already been provided to you.
 
3.15 (dec) == 11.0010011001100110011... (bin)
3.75 (dec) == 11.11 (bin)

> Thanks
> Teckpor
> 
> -----Original Message-----
> From: pd at pubhealth.ku.dk [mailto:pd at pubhealth.ku.dk] On Behalf Of Peter
> Dalgaard
> Sent: Monday, May 29, 2006 17:49
> To: teck.lim at imperial.ac.uk
> Cc: r-devel at stat.math.ethz.ch; R-bugs at biostat.ku.dk
> Subject: Re: [Rd] Numerical error in R (win32) (PR#8909)
> 
> teck.lim at imperial.ac.uk writes:
> 
> > Hi
> >     I had observed the following problem in R (also C, Matlab, and
> Python).
> > sprintf('%1.2g\n', 3.15)
> > give 3.1 instead of 3.2 whereas an input of 3.75 gives 3.8.
> > Java's System.out.printf is ok though.  
> >  
> > > round(3.75,1)
> > [1] 3.8
> > > round(3.15,1)
> > [1] 3.1
> >  
> > Similar outcome with sprintf in R.
> > 
> > 
> > However, the right answer should be 3.2
> 
> According to what? Remember that we're dealing with finite precision binary
> arithmetic here:
> 
> >  (3.15 - 3.1)<.05
> [1] TRUE
> >  abs(3.15 - 3.2)>.05
> [1] TRUE
> 
> See also FAQ 7.31.
>   
> > Regards
> > Teckpor
> > 
> 
> -- 
>    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907
> 
> 

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From berwin at maths.uwa.edu.au  Tue May 30 16:20:49 2006
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Tue, 30 May 2006 22:20:49 +0800
Subject: [Rd] Numerical error in R (win32) (PR#8909)
In-Reply-To: <20060530124306.C0DBE3F045@slim.kubism.ku.dk>
References: <20060530124306.C0DBE3F045@slim.kubism.ku.dk>
Message-ID: <17532.21697.711240.959472@bossiaea.maths.uwa.edu.au>

G'day Teck,

I am taking R-bugs out of the recipient list because, as other have
pointed out to you, it definitely is not a bug and doesn't belong
there.

I was about to answer your e-mail yesterday, but then decided that my
reply was overly sarcastic, cancelled it and went home instead.  In
the morning, I noticed that you got four sound, polite answers that
were all explaining to you want was going on and, though they
contributed to filling up my mailbox I thought that this was o.k. and
would settle the matter.

But I really take offence of you continuing to fill up my mailbox with
the same nonsense answer to all four e-mails.  Since you seem to be so
desperate to get my opinion, here it is:

>>>>> "TL" == teck lim <teck.lim at imperial.ac.uk> writes:

    TL> Thanks for the quick reply.
On behalf of the others, no problems.  We wished that you had taken
time to digest the answers and didn't feel the urge to immediately
reply to them again.

    TL> However, I am not satisfied, [...]
I am very sorry to hear that you are not satisfied, but what you
describe is a matter of finite precision arithmetic.  And silicon
chips don't care what you think or whether you are satisfied.

    TL> I think the problem is really more of an error in the rounding
    TL> off algorithm than finite precision.
I think the problem is rather that you are not willing to listen to
the advice and the information given to you.  My pet gripes these days
are:
a) the general level of innumeracy.
b) the level of numerical innumeracy among numerate people that start
   to do some computing. 
c) the unwillingness of people to read up on material pointed out to
   them.

And there are a few more.  b) and c) seem to apply to you and, in
particular in respect to c), I find this highly worrying since you seem
to be at an academic institution.  I have actually quite some respect
for the work done at Imperial College, but if I see posts like this I
start to ask myself which direction it is exactly in which they are
leading science. :)

    TL> -----Original Message-----
    TL> From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de]
    TL> Sent: Monday, May 29, 2006 17:45 

    UL> teck.lim at imperial.ac.uk wrote:

    TL> Hi I had observed the following problem in R (also C, Matlab,
    TL> and Python).  sprintf('%1.2g\n', 3.15) give 3.1 instead of 3.2
    TL> whereas an input of 3.75 gives 3.8.  Java's System.out.printf
    TL> is ok though.
I don't see why this is a problem, and it seems that Java is out-voted
4 to 1.  Thus, while Java's output might find your approval, I think
you should, in true democratic fashion, accept the majority vote.  I
really wonder why you believe that the answer that you think is the
correct answer should be the correct answer just because one system
gives, for whatever reasons, the answer you expect.  On the other
hand, you might always try to persuade some American law makers to
legislate that 3.1 is the correct answer to settle the matter.  After
all, it seems Indiana once legislated that pi is equal to 3. :)

    >> However, the right answer should be 3.2
Says who?  So far, it seems it is you and Java against the
overwhelming majority.  And, even if this realisation might hurt you,
silicon chips give a stuff about what you or Java think the correct
answer should be.  For them the correct answer is governed by IEEE 754
and other such standards.

Furthermore, in the numerical analysis community the early versions of
Java were infamous for their implementation of finite precision
arithmetic, thus creating all kind of numerical precision problems
that were actually well known, well understood and avoidable.  My
understanding is that these days these problems are fixed, but it is
actually very hard to find a publication that says so.  It is very
easy to find publications that point out to problems with the
implementation of finite precision arithmetic in (early versions of)
Java.  So do not expect us to take Java's behaviour as being definite
proof for correct behaviour of finite precision arithmetic.

    UL> This is not a bug.

    UL> Please read the R FAQ "Why doesn't R think these numbers are
    UL> equal?"
I completely agree with Uwe and this is very good advice that you have
received.  Did you read up on that question?  To make it easier for
you to find it, it is R FAQ 7.31.  Did you read up on the references
given in the answer?  If so, you might have learned something instead
of continuing to waste bandwidth and fill other people mail-boxes.

    UL> and after that note that *numerically* the following
    UL> inaqualities are TRUE: (3.2 - 3.15) > 0.05 (3.15 - 3.1) < 0.05
Also, after reading the answer to the above FAQ, the literature cited
in the answer and trying out the code mentioned above (and that in
other replies), you might have realised what is going on.  Big hint,
think about how 3.15 and how 3.75 are represented inside a computer
and whether they can be represented exactly.  Then you may also
realise that specifying additional zeros in the literal constant that
you use doesn't make a iota difference.

If this is still too much effort for you to do, try the following
commands and reflect on their output.

> sprintf('%1.20g\n', 3.75)
[1] "3.75\n"
> sprintf('%1.20g\n', 3.15)
[1] "3.1499999999999999112\n"
> sprintf('%1.20g\n', 3.75000000)
[1] "3.75\n"
> sprintf('%1.20g\n', 3.15000000)
[1] "3.1499999999999999112\n"

I know, I should probably do the same thing as I did yesterday and hit
the delete button and go home instead of hitting the sent button.  But
this time I won't.  If anybody feels offended, my apologies.  

Cheers,

        Berwin

========================== Full address ============================
Berwin A Turlach                      Tel.: +61 (8) 6488 3338 (secr)   
School of Mathematics and Statistics        +61 (8) 6488 3383 (self)      
The University of Western Australia   FAX : +61 (8) 6488 1028
35 Stirling Highway                   
Crawley WA 6009                e-mail: berwin at maths.uwa.edu.au
Australia                        http://www.maths.uwa.edu.au/~berwin


From tplate at acm.org  Tue May 30 20:23:42 2006
From: tplate at acm.org (Tony Plate)
Date: Tue, 30 May 2006 12:23:42 -0600
Subject: [Rd] Numerical error in R (win32) (PR#8909)
In-Reply-To: <20060530124306.C0DBE3F045@slim.kubism.ku.dk>
References: <20060530124306.C0DBE3F045@slim.kubism.ku.dk>
Message-ID: <447C8DAE.5070609@acm.org>

Beyond the R FAQ 7.31 the article "What Every Computer Scientist Should 
Know About Floating-Point Arithmetic, by David Goldberg" 
(http://docs.sun.com/source/806-3568/ncg_goldberg.html) is very 
informative, but it is rather long (this topic has many subtleties). 
Wikipedia has a shorter page on "Floating point arithmetic", 
(http://en.wikipedia.org/wiki/Floating_point) which covers some of the 
most important points for scientists who are not computer scientists, 
and also has many links.

If it's really important to have exact representation for decimal 
fractions, then look at the draft IEEE proposal for "General Decimal 
Arithmetic" (http://www2.hursley.ibm.com/decimal/ ) which states:  "Most 
computers today support binary floating-point in hardware.  While 
suitable for many purposes, binary floating-point arithmetic should not 
be used for financial, commercial, and user-centric applications or web 
services because the decimal data used in these applications cannot be 
represented exactly using binary floating-point. (See the Frequently 
Asked Questions pages for more explanation and examples.)"

(I would quibble with the blanket statement that "binary floating-point 
arithmetic should not be used for financial [...] applications" -- it 
all depends on the needs of the particular financial application.)

I don't believe that there are any facilities in R for doing decimal 
arithmetic, but I would guess that some accounting applications might 
offer some.

-- Tony Plate

(I removed R-bugs from the cc list because it's not a bug, as has 
already been noted.)

teck.lim at imperial.ac.uk wrote:
> Hi
> 
> 	Thanks for the quick reply. However, I am not satisfied, as
> 
>>round(3.15000000, 1)
> 
> [1] 3.1
> 
>>round(3.75000000, 1)
> 
> [1] 3.8
> 
> 	I think the problem is really more of an error in the rounding off
> algorithm than finite precision.
> 
> Thanks
> Teckpor 
> 
> -----Original Message-----
> From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de] 
> Sent: Monday, May 29, 2006 17:45
> To: teck.lim at imperial.ac.uk
> Cc: R-bugs at biostat.ku.dk
> Subject: Re: [Rd] Numerical error in R (win32) (PR#8909)
> 
> teck.lim at imperial.ac.uk wrote:
> 
> 
>>Hi
>>    I had observed the following problem in R (also C, Matlab, and
> 
> Python).
> 
>>sprintf('%1.2g\n', 3.15)
>>give 3.1 instead of 3.2 whereas an input of 3.75 gives 3.8.
>>Java's System.out.printf is ok though.  
>> 
>>
>>
>>>round(3.75,1)
>>
>>[1] 3.8
>>
>>
>>>round(3.15,1)
>>
>>[1] 3.1
>> 
>>Similar outcome with sprintf in R.
>>
>>
>>However, the right answer should be 3.2
> 
> 
> This is not a bug.
> 
> Please read the R FAQ "Why doesn't R think these numbers are equal?" and
> after that note that *numerically* the following inaqualities are TRUE:
> (3.2 - 3.15) > 0.05
> (3.15 - 3.1) < 0.05
> 
> Uwe Ligges
> 
> 
> 
>>Regards
>>Teckpor
>> 
>>
>>	[[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-devel at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From bpeyser at jhmi.edu  Tue May 30 23:03:50 2006
From: bpeyser at jhmi.edu (bpeyser at jhmi.edu)
Date: Tue, 30 May 2006 23:03:50 +0200 (CEST)
Subject: [Rd] Documentation error for par(lty) (PR#8914)
Message-ID: <20060530210350.A9BA929D36@slim.kubism.ku.dk>

Full_Name: Brian D. Peyser
Version: 2.1 (also 2.3)
OS: Windows XP Pro
Submission from: (NULL) (162.129.236.18)


In the documentation for par() (both on-line and manual) there is an error
regarding line type specification (lty). It actually omits a feature. The
documentation states that a string up to 8 NON-ZERO hexadecimal digits may be
used to specify on/off lengths, i.e. "44" = "dashed".

However, lty DOES accept zero:

plot(NA, NA, xlim=c(-2,2), ylim=c(-2,2))
abline(h=1, lwd=2, col="black", lty="0880")
abline(h=1, lwd=2, col="gray", lty="88")

This will produce a plot with a horizontal line that is alternately gray and
black. The first number is length "on", then length "off", so that the black
line starts with zero length on, then 8 off, then 8 on, then zero off, such that
the zeroes effectively swap the "on" and "off" positions. The gray line starts
"on" for 8 units then "off" for 8.

-Brian Peyser


From ryan at stat.Berkeley.EDU  Tue May 30 23:06:49 2006
From: ryan at stat.Berkeley.EDU (ryan at stat.Berkeley.EDU)
Date: Tue, 30 May 2006 23:06:49 +0200 (CEST)
Subject: [Rd] 2.3 issues on Mac (PR#8915)
Message-ID: <20060530210649.115FF29D35@slim.kubism.ku.dk>

/Library/Frameworks/R.framework/Versions/2.3/Resources/etc/ppc/Renviron and
/Library/Frameworks/R.framework/Versions/2.3/Resources/etc/i386/Renviron
both use /usr/local/teTeX/bin/powerpc-apple-darwin-current for LaTeX
related variables. Could this be updated for i386 to take into account the
teTeX intel binaries?

Also, Makeconf is not setup to create universal binary libraries. Will this
be done at some point?

Lastly, R.mpkg crashes Apple's Remote Desktop 2.2 when installing on a
client. I was wondering if anyone else sees this?

Thanks,
Ryan


From ryan at stat.berkeley.edu  Tue May 30 23:08:20 2006
From: ryan at stat.berkeley.edu (ryan at stat.berkeley.edu)
Date: Tue, 30 May 2006 23:08:20 +0200 (CEST)
Subject: [Rd] 2.3 issues on Mac (PR#8916)
Message-ID: <20060530210820.A09A129D35@slim.kubism.ku.dk>

Full_Name: Ryan Lovett
Version: 2.3.0
OS: Mac OS X 10.4
Submission from: (NULL) (128.32.135.41)


/Library/Frameworks/R.framework/Versions/2.3/Resources/etc/ppc/Renviron and
/Library/Frameworks/R.framework/Versions/2.3/Resources/etc/i386/Renviron
both use /usr/local/teTeX/bin/powerpc-apple-darwin-current for LaTeX
related variables. Could this be updated for i386 to take into account the
teTeX intel binaries?

Also, Makeconf is not setup to create universal binary libraries. Will this
be done at some point?

Lastly, R.mpkg crashes Apple's Remote Desktop 2.2 when installing on a
client. I was wondering if anyone else sees this?


From ripley at stats.ox.ac.uk  Tue May 30 23:38:53 2006
From: ripley at stats.ox.ac.uk (ripley at stats.ox.ac.uk)
Date: Tue, 30 May 2006 23:38:53 +0200 (CEST)
Subject: [Rd] Documentation error for par(lty) (PR#8914)
Message-ID: <20060530213853.8C72F29D37@slim.kubism.ku.dk>

Whether this works or not depends on the graphics device.  The description 
in the driver sources says

  *      Line textures are stored as an array of 4-bit integers within
  *      a single 32-bit word.  These integers contain the lengths of
  *      lines to be drawn with the pen alternately down and then up.

  *      An integer containing a zero terminates the pattern.

Your example does not work on the pdf() device, for example.
So the documentation accurately describes what is guaranteed to work.
(On Windows the GDI is used and that accepts more possibilities, it 
seems.  We may well alter that.)

On Tue, 30 May 2006, bpeyser at jhmi.edu wrote:

> Full_Name: Brian D. Peyser
> Version: 2.1 (also 2.3)

There are no such versions: please do note what the posting guide says 
about this (and reporting on current versions, now 2.3.1 RC)

> OS: Windows XP Pro
> Submission from: (NULL) (162.129.236.18)
>
>
> In the documentation for par() (both on-line and manual) there is an error
> regarding line type specification (lty). It actually omits a feature. The
> documentation states that a string up to 8 NON-ZERO hexadecimal digits may be
> used to specify on/off lengths, i.e. "44" = "dashed".
>
> However, lty DOES accept zero:
>
> plot(NA, NA, xlim=c(-2,2), ylim=c(-2,2))
> abline(h=1, lwd=2, col="black", lty="0880")
> abline(h=1, lwd=2, col="gray", lty="88")
>
> This will produce a plot with a horizontal line that is alternately gray 
> and black. The first number is length "on", then length "off", so that 
> the black line starts with zero length on, then 8 off, then 8 on, then 
> zero off, such that the zeroes effectively swap the "on" and "off" 
> positions. The gray line starts "on" for 8 units then "off" for 8.
>
> -Brian Peyser

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From simon.urbanek at r-project.org  Wed May 31 00:24:34 2006
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 30 May 2006 18:24:34 -0400
Subject: [Rd] 2.3 issues on Mac (PR#8915)
In-Reply-To: <20060530210649.115FF29D35@slim.kubism.ku.dk>
References: <20060530210649.115FF29D35@slim.kubism.ku.dk>
Message-ID: <0756F233-67AF-4B11-A9B0-CEE7A75E9239@r-project.org>

Ryan,

On May 30, 2006, at 5:06 PM, ryan at stat.berkeley.edu wrote:

> /Library/Frameworks/R.framework/Versions/2.3/Resources/etc/ppc/ 
> Renviron and
> /Library/Frameworks/R.framework/Versions/2.3/Resources/etc/i386/ 
> Renviron
> both use /usr/local/teTeX/bin/powerpc-apple-darwin-current for  
> LaTeX related variables. Could this be updated for i386 to take  
> into account the
> teTeX intel binaries?
>

Thanks, fixed for the next build.


> Also, Makeconf is not setup to create universal binary libraries.  
> Will this be done at some point?
>

It is (see "2.5 Sub-architectures" in R-admin).


> Lastly, R.mpkg crashes Apple's Remote Desktop 2.2 when installing  
> on a client. I was wondering if anyone else sees this?
>

I don't have ARD, but since R.mpkg was created using PM and there are  
no binaries involved, I'd guess this is an ARD bug. (Installation  
using both command line and Installer.app works fine). Unless someone  
donates an ARD license (it's rather costly) I can't do much - but if  
you find the cause feel free to share it with us.

Cheers,
Simon

(PS: please don't open two bug-reports on the same issue[s])


From phgrosjean at sciviews.org  Wed May 31 11:57:50 2006
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Wed, 31 May 2006 11:57:50 +0200
Subject: [Rd] Presentation of R at RMLL 2006
Message-ID: <447D689E.2080502@sciviews.org>

Hello all,

Sorry for this slightly out-of-topic thread. There is a theme on 
scientific software at the RMLL ("Rencontres Mondiales du Logiciel 
Libre", 4-8 July at Nancy, France). The organizing commitee is seeking 
for a presenter, in English preferrably, or in French, for R. Could 
someone do such a presentation? I would be a pitty that R would not be 
represented in that session. You will find more info here: 
http://prog.rmll.info/wakka.php?wiki=ThemeScienceAppelEn.

Best,

Philippe Grosjean

P.S.: I send this to Rdevel instead of the R mailing list, since we 
obviously need a knowledgeable people about R.
-- 
..............................................<?}))><........
  ) ) ) ) )
( ( ( ( (    Prof. Philippe Grosjean
  ) ) ) ) )
( ( ( ( (    Numerical Ecology of Aquatic Systems
  ) ) ) ) )   Mons-Hainaut University, Pentagone (3D08)
( ( ( ( (    Academie Universitaire Wallonie-Bruxelles
  ) ) ) ) )   8, av du Champ de Mars, 7000 Mons, Belgium
( ( ( ( (
  ) ) ) ) )   phone: + 32.65.37.34.97, fax: + 32.65.37.30.54
( ( ( ( (    email: Philippe.Grosjean at umh.ac.be
  ) ) ) ) )
( ( ( ( (    web:   http://www.umh.ac.be/~econum
  ) ) ) ) )          http://www.sciviews.org
( ( ( ( (
..............................................................


From dreibh at iem.uni-due.de  Wed May 31 14:42:39 2006
From: dreibh at iem.uni-due.de (Thomas Dreibholz)
Date: Wed, 31 May 2006 14:42:39 +0200
Subject: [Rd] Patch: context stack size in gram.y
Message-ID: <200605311442.50544.dreibh@iem.uni-due.de>

Hi!

Attached to this mail, you find a patch for gram.y setting a #define 
CONTEXT_STACK_SIZE for the context stack size and replacing the following 
constants 50 and 49 by CONTEXT_STACK_SIZE and CONTEXT_STACK_SIZE-1. The new 
#define makes setting the stack size much more easy; I also have increased it 
to 500, because 50 is too small (we use R to iterate through sets of 
simulation parameters, which requires a context stack size of around 100).

I have also discovered that yacc is only invoked when R is configured with 
"--enable-maintainer-mode", i.e. the redundant output file gram.c is part of 
the source distribution. Would is not be better to always generate gram.c 
from gram.y instead of providing gram.y and gram.c?


Best regards
-- 
=======================================================================
 Dipl.-Inform. Thomas Dreibholz

 University of Essen,                            Room ES210
 Inst. for Experimental Mathematics              Ellernstra?e 29
 Computer Networking Technology Group            D-45326 Essen/Germany
-----------------------------------------------------------------------
 E-Mail:     dreibh at exp-math.uni-essen.de
 Homepage:   http://www.exp-math.uni-essen.de/~dreibh
=======================================================================
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 191 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20060531/2fc8a345/attachment.bin 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: gram.y.diff.gz
Type: application/x-gzip
Size: 2070 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20060531/2fc8a345/attachment.gz 

From sgiannerini at gmail.com  Wed May 31 14:51:00 2006
From: sgiannerini at gmail.com (Simone Giannerini)
Date: Wed, 31 May 2006 14:51:00 +0200
Subject: [Rd] Inconsistent behaviour when subsetting a ts object with
	frequency = 12 or 4
Message-ID: <3c12769c0605310551u4f48c3f5l94727c0408eee978@mail.gmail.com>

Dear All,

I found the following  under R 2.3.0 on WINXP (tested on 2 PCs, I do
not have access to the  to Linux from this PC, sorry ... )

> set.seed(10)
> x <- ts(rnorm(6),frequency=7)
> x
Time Series:
Start = c(1, 1)
End = c(1, 6)
Frequency = 7
[1]  0.01874617 -0.18425254 -1.37133055 -0.59916772  0.29454513  0.38979430
> x[24] <- NA
> x
Time Series:
Start = c(1, 1)
End = c(1, 6)
Frequency = 7
 [1]  0.01874617 -0.18425254 -1.37133055 -0.59916772  0.29454513
0.38979430          NA          NA          NA          NA          NA
[12]          NA          NA          NA          NA          NA
   NA          NA          NA          NA          NA          NA
[23]
## OK ********************

> x <- ts(rnorm(6),frequency=12) # THE SAME BUT WITH frequency = 12
> x
         Jan        Feb        Mar        Apr        May        Jun
1 -1.2080762 -0.3636760 -1.6266727 -0.2564784  1.1017795  0.7557815
> x[24] <- NA
> x
Error in matrix(c(rep.int("", start.pad), format(x, ...), rep.int("",  :
        length of 'dimnames' [1] not equal to array extent
In addition: Warning message:
data length [30] is not a sub-multiple or multiple of the number of
columns [12] in matrix

> x <- ts(rnorm(6),frequency=4) # THE SAME BUT WITH frequency = 4
> x
         Qtr1        Qtr2        Qtr3        Qtr4
1 -0.23823356  0.98744470  0.74139013  0.08934727
2 -0.95494386 -0.19515038
> x[24] <- NA
> x
Error in matrix(c(rep.int("", start.pad), format(x, ...), rep.int("",  :
        length of 'dimnames' [1] not equal to array extent
In addition: Warning message:
data length [26] is not a sub-multiple or multiple of the number of
rows [7] in matrix


Is this behaviour expected for frequencies 12 and 4?

Thank you

Simone

***************************************************
platform       i386-pc-mingw32
arch           i386
os             mingw32
system         i386, mingw32
status
major          2
minor          3.0
year           2006
month          04
day            24
svn rev        37909
language       R
version.string Version 2.3.0 (2006-04-24)
______________________________________________________

Simone Giannerini
Dipartimento di Scienze Statistiche "Paolo Fortunati"
Universita' di Bologna
Via delle belle arti 41 - 40126  Bologna,  ITALY
Tel: +39 051 2098248  Fax: +39 051 232153


From ripley at stats.ox.ac.uk  Wed May 31 15:26:26 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 31 May 2006 14:26:26 +0100 (BST)
Subject: [Rd] Patch: context stack size in gram.y
In-Reply-To: <200605311442.50544.dreibh@iem.uni-due.de>
References: <200605311442.50544.dreibh@iem.uni-due.de>
Message-ID: <Pine.LNX.4.64.0605311418560.3564@gannet.stats.ox.ac.uk>

On Wed, 31 May 2006, Thomas Dreibholz wrote:

> Hi!
>
> Attached to this mail, you find a patch for gram.y setting a #define
> CONTEXT_STACK_SIZE for the context stack size and replacing the following
> constants 50 and 49 by CONTEXT_STACK_SIZE and CONTEXT_STACK_SIZE-1. The new
> #define makes setting the stack size much more easy; I also have increased it
> to 500, because 50 is too small (we use R to iterate through sets of
> simulation parameters, which requires a context stack size of around 100).

I think you will have to explain in detail why you need this, when for a 
decade R users have not reported a need for it.  It is not related to 
iteration in R, rather to the depth of recursion needed to parse R code.

> I have also discovered that yacc is only invoked when R is configured with
> "--enable-maintainer-mode", i.e. the redundant output file gram.c is part of
> the source distribution. Would is not be better to always generate gram.c
> from gram.y instead of providing gram.y and gram.c?

We do not require end users to have yacc, and Windows users definitely do 
not have it.  Nor do those of lots of other platforms, e.g. Solaris. 
Please read the R-admin manual to discover the requirements (it is always 
a good idea to read the manual before posting).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From sgiannerini at gmail.com  Wed May 31 15:41:40 2006
From: sgiannerini at gmail.com (Simone Giannerini)
Date: Wed, 31 May 2006 15:41:40 +0200
Subject: [Rd] Inconsistent behaviour when manipulating a ts object with
	frequency = 12 or 4
Message-ID: <3c12769c0605310641r61bf60fbl3d82e2364bd2dc5d@mail.gmail.com>

Dear All,

I found the following  under R 2.3.0 on WINXP (tested on 2 PCs, I do
not have access to Linux from this PC, sorry ... )

> set.seed(10)
> x <- ts(rnorm(6),frequency=7)
> x
Time Series:
Start = c(1, 1)
End = c(1, 6)
Frequency = 7
[1]  0.01874617 -0.18425254 -1.37133055 -0.59916772  0.29454513  0.38979430
> x[24] <- NA
> x
Time Series:
Start = c(1, 1)
End = c(1, 6)
Frequency = 7
 [1]  0.01874617 -0.18425254 -1.37133055 -0.59916772  0.29454513
0.38979430          NA          NA          NA          NA          NA
[12]          NA          NA          NA          NA          NA
   NA          NA          NA          NA          NA          NA
[23]
## OK ********************

> x <- ts(rnorm(6),frequency=12) # THE SAME BUT WITH frequency = 12
> x
         Jan        Feb        Mar        Apr        May        Jun
1 -1.2080762 -0.3636760 -1.6266727 -0.2564784  1.1017795  0.7557815
> x[24] <- NA
> x
Error in matrix(c(rep.int("", start.pad), format(x, ...), rep.int("",  :
        length of 'dimnames' [1] not equal to array extent
In addition: Warning message:
data length [30] is not a sub-multiple or multiple of the number of
columns [12] in matrix

> x <- ts(rnorm(6),frequency=4) # THE SAME BUT WITH frequency = 4
> x
         Qtr1        Qtr2        Qtr3        Qtr4
1 -0.23823356  0.98744470  0.74139013  0.08934727
2 -0.95494386 -0.19515038
> x[24] <- NA
> x
Error in matrix(c(rep.int("", start.pad), format(x, ...), rep.int("",  :
        length of 'dimnames' [1] not equal to array extent
In addition: Warning message:
data length [26] is not a sub-multiple or multiple of the number of
rows [7] in matrix


Is this behaviour expected for frequencies 12 and 4?

Thank you

Simone

***************************************************
platform       i386-pc-mingw32
arch           i386
os             mingw32
system         i386, mingw32
status
major          2
minor          3.0
year           2006
month          04
day            24
svn rev        37909
language       R
version.string Version 2.3.0 (2006-04-24)

> Sys.getlocale()
[1] "LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
States.1252;LC_MONETARY=English_United
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252"

______________________________________________________

Simone Giannerini
Dipartimento di Scienze Statistiche "Paolo Fortunati"
Universita' di Bologna
Via delle belle arti 41 - 40126  Bologna,  ITALY
Tel: +39 051 2098248  Fax: +39 051 232153


From dreibh at iem.uni-due.de  Wed May 31 15:53:25 2006
From: dreibh at iem.uni-due.de (Thomas Dreibholz)
Date: Wed, 31 May 2006 15:53:25 +0200
Subject: [Rd] Patch: context stack size in gram.y
In-Reply-To: <Pine.LNX.4.64.0605311418560.3564@gannet.stats.ox.ac.uk>
References: <200605311442.50544.dreibh@iem.uni-due.de>
	<Pine.LNX.4.64.0605311418560.3564@gannet.stats.ox.ac.uk>
Message-ID: <200605311553.30722.dreibh@iem.uni-due.de>

On Wednesday 31 May 2006 15:26, Prof Brian Ripley wrote:
> On Wed, 31 May 2006, Thomas Dreibholz wrote:
> > Hi!
> >
> > Attached to this mail, you find a patch for gram.y setting a #define
> > CONTEXT_STACK_SIZE for the context stack size and replacing the following
> > constants 50 and 49 by CONTEXT_STACK_SIZE and CONTEXT_STACK_SIZE-1. The
> > new #define makes setting the stack size much more easy; I also have
> > increased it to 500, because 50 is too small (we use R to iterate through
> > sets of simulation parameters, which requires a context stack size of
> > around 100).
>
> I think you will have to explain in detail why you need this, when for a
> decade R users have not reported a need for it.  It is not related to
> iteration in R, rather to the depth of recursion needed to parse R code.

We use R to create input files for OMNeT++ simulations. The simulation 
parameters are defined like this:
param01Set <- c(...)
param02Set <- c(...)
...
paramXYSet <- c(...)
Most of these sets only contain a single element.

The input file generation, which should be usable for all simulations, works 
as follows:
for(param01 in param01Set) {
 for(param02 in param02Set) {
  ...
   for(paramXY in paramXYSet) {
     Generate input file for these parameter settings
   }
  ...
 }
}

The simulation has more than 50 different parameters, so a "contextstack 
overflow" error will be the result. Increasing the context stack size in 
gram.y solves this problem. (Clearly, only using "for" iterations for sets 
consisting of more than one element would solve the problem - but this 
requires a special version of the parameter generation function for every 
simulation.)


Best regards
-- 
=======================================================================
 Dipl.-Inform. Thomas Dreibholz

 University of Essen,                            Room ES210
 Inst. for Experimental Mathematics              Ellernstra?e 29
 Computer Networking Technology Group            D-45326 Essen/Germany
-----------------------------------------------------------------------
 E-Mail:     dreibh at exp-math.uni-essen.de
 Homepage:   http://www.exp-math.uni-essen.de/~dreibh
=======================================================================
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 191 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-devel/attachments/20060531/138dbfbd/attachment.bin 

From ripley at stats.ox.ac.uk  Wed May 31 16:30:55 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 31 May 2006 15:30:55 +0100 (BST)
Subject: [Rd] Inconsistent behaviour when manipulating a ts object with
 frequency = 12 or 4
In-Reply-To: <3c12769c0605310641r61bf60fbl3d82e2364bd2dc5d@mail.gmail.com>
References: <3c12769c0605310641r61bf60fbl3d82e2364bd2dc5d@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0605311528130.4180@gannet.stats.ox.ac.uk>

Attempting to change element 24 of a length 6 time series is inconsistent!
You end up with an invalid series, and the print methods are different for 
different frequencies, hence different error messages.

Please do not send the same post repeatedly!

On Wed, 31 May 2006, Simone Giannerini wrote:

> Dear All,
>
> I found the following  under R 2.3.0 on WINXP (tested on 2 PCs, I do
> not have access to Linux from this PC, sorry ... )
>
>> set.seed(10)
>> x <- ts(rnorm(6),frequency=7)
>> x
> Time Series:
> Start = c(1, 1)
> End = c(1, 6)
> Frequency = 7
> [1]  0.01874617 -0.18425254 -1.37133055 -0.59916772  0.29454513  0.38979430
>> x[24] <- NA
>> x
> Time Series:
> Start = c(1, 1)
> End = c(1, 6)
> Frequency = 7
> [1]  0.01874617 -0.18425254 -1.37133055 -0.59916772  0.29454513
> 0.38979430          NA          NA          NA          NA          NA
> [12]          NA          NA          NA          NA          NA
>   NA          NA          NA          NA          NA          NA
> [23]
> ## OK ********************
>
>> x <- ts(rnorm(6),frequency=12) # THE SAME BUT WITH frequency = 12
>> x
>         Jan        Feb        Mar        Apr        May        Jun
> 1 -1.2080762 -0.3636760 -1.6266727 -0.2564784  1.1017795  0.7557815
>> x[24] <- NA
>> x
> Error in matrix(c(rep.int("", start.pad), format(x, ...), rep.int("",  :
>        length of 'dimnames' [1] not equal to array extent
> In addition: Warning message:
> data length [30] is not a sub-multiple or multiple of the number of
> columns [12] in matrix
>
>> x <- ts(rnorm(6),frequency=4) # THE SAME BUT WITH frequency = 4
>> x
>         Qtr1        Qtr2        Qtr3        Qtr4
> 1 -0.23823356  0.98744470  0.74139013  0.08934727
> 2 -0.95494386 -0.19515038
>> x[24] <- NA
>> x
> Error in matrix(c(rep.int("", start.pad), format(x, ...), rep.int("",  :
>        length of 'dimnames' [1] not equal to array extent
> In addition: Warning message:
> data length [26] is not a sub-multiple or multiple of the number of
> rows [7] in matrix
>
>
> Is this behaviour expected for frequencies 12 and 4?
>
> Thank you
>
> Simone
>
> ***************************************************
> platform       i386-pc-mingw32
> arch           i386
> os             mingw32
> system         i386, mingw32
> status
> major          2
> minor          3.0
> year           2006
> month          04
> day            24
> svn rev        37909
> language       R
> version.string Version 2.3.0 (2006-04-24)
>
>> Sys.getlocale()
> [1] "LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
> States.1252;LC_MONETARY=English_United
> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252"
>
> ______________________________________________________
>
> Simone Giannerini
> Dipartimento di Scienze Statistiche "Paolo Fortunati"
> Universita' di Bologna
> Via delle belle arti 41 - 40126  Bologna,  ITALY
> Tel: +39 051 2098248  Fax: +39 051 232153
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Max.Kuhn at pfizer.com  Wed May 31 16:57:54 2006
From: Max.Kuhn at pfizer.com (Kuhn, Max)
Date: Wed, 31 May 2006 10:57:54 -0400
Subject: [Rd] Bitmap device available for R CMD check?
Message-ID: <71257D09F114DA4A8E134DEAC70F25D3053486CE@groamrexm03.amer.pfizer.com>

Hi,

I have a package that I'd like to submit to CRAN that does Sweave-like
processing on Open Document format files from Open Office. 

If I remember correctly, there is a machine that automatically R CMD
checks CRAN packages. I have two questions about how that system is set
up:

1. Is the bitmap device available? The example produces a file using
this device and I'd like it to pass R CMD check on your system (as it
does on my machines).

2. Are there any restrictions on the Latex packages called in the
vignette? This is not a big deal, but it would be good to know how much
flexibility I have in producing that document.

Thanks,

Max
----------------------------------------------------------------------
LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}


From ggrothendieck at gmail.com  Wed May 31 17:11:08 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 31 May 2006 11:11:08 -0400
Subject: [Rd] Bitmap device available for R CMD check?
In-Reply-To: <71257D09F114DA4A8E134DEAC70F25D3053486CE@groamrexm03.amer.pfizer.com>
References: <71257D09F114DA4A8E134DEAC70F25D3053486CE@groamrexm03.amer.pfizer.com>
Message-ID: <971536df0605310811k7aed3471vd668cf7efa5568d4@mail.gmail.com>

Others may have better ideas but
if you have a problem getting your vignette to pass R CMD check
then you could process it yourself using Sweave to create a .tex
file and then have a mypkg.Rnw file that just contains the SweaveOpt,
%Vignette statements and an \input statement to input the .tex file that you
generated yourself.  That way you can generate it in a known
environment.



On 5/31/06, Kuhn, Max <Max.Kuhn at pfizer.com> wrote:
> Hi,
>
> I have a package that I'd like to submit to CRAN that does Sweave-like
> processing on Open Document format files from Open Office.
>
> If I remember correctly, there is a machine that automatically R CMD
> checks CRAN packages. I have two questions about how that system is set
> up:
>
> 1. Is the bitmap device available? The example produces a file using
> this device and I'd like it to pass R CMD check on your system (as it
> does on my machines).
>
> 2. Are there any restrictions on the Latex packages called in the
> vignette? This is not a big deal, but it would be good to know how much
> flexibility I have in producing that document.
>
> Thanks,
>
> Max
> ----------------------------------------------------------------------
> LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From duncan at wald.ucdavis.edu  Wed May 31 18:20:47 2006
From: duncan at wald.ucdavis.edu (Duncan Temple Lang)
Date: Wed, 31 May 2006 09:20:47 -0700
Subject: [Rd] iSPlots paper
Message-ID: <447DC25F.2040609@wald.ucdavis.edu>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Thanks for incorporating the changes. It looks much shorter on the lead
in which is good, I think.

I should be able to read through it rapidly on the train and I
expect it is all great at this point.  I'll let you know if
I spot anything that might need minor tweaking, or else I'll just say
great, go ahead and send it.


The only thing that is obviously missing - from the copy I just printed,
at least - is an abstract.

- --
Duncan Temple Lang                    duncan at wald.ucdavis.edu
Department of Statistics              work:  (530) 752-4782
4210 Mathematical Sciences Building   fax:   (530) 752-7099
One Shields Ave.
University of California at Davis
Davis,
CA 95616,
USA
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.3 (Darwin)

iD8DBQFEfcJf9p/Jzwa2QP4RAvQJAJ0d1YgTuZGwEan2jSj1zzBBDNrBUwCeNBUa
nKPd07g8qzOihhSI4E68CJc=
=tT1w
-----END PGP SIGNATURE-----


From sgiannerini at gmail.com  Wed May 31 19:29:43 2006
From: sgiannerini at gmail.com (Simone Giannerini)
Date: Wed, 31 May 2006 19:29:43 +0200
Subject: [Rd] Inconsistent behaviour when manipulating a ts object with
	frequency = 12 or 4
In-Reply-To: <Pine.LNX.4.64.0605311528130.4180@gannet.stats.ox.ac.uk>
References: <3c12769c0605310641r61bf60fbl3d82e2364bd2dc5d@mail.gmail.com>
	<Pine.LNX.4.64.0605311528130.4180@gannet.stats.ox.ac.uk>
Message-ID: <3c12769c0605311029x3452c677ga87177e6179dafda@mail.gmail.com>

many thanks for the reply,

On 5/31/06, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> Attempting to change element 24 of a length 6 time series is inconsistent!

of course it is, my post was also motivated by the fact that you
obtain different answers also  within the same frequency, depending on
the index,  for instance:

> x <- ts(rnorm(6),frequency=12)
> x
         Jan        Feb        Mar        Apr        May        Jun
1  0.9255213  0.4829785 -0.5963106 -2.1852868 -0.6748659 -2.1190612
> x[7] <- NA
> x
         Jan        Feb        Mar        Apr        May        Jun        Jul
1  0.9255213  0.4829785 -0.5963106 -2.1852868 -0.6748659 -2.1190612         NA

so that I thought maybe it was worth pointing this out even if the
series are invalid.

> You end up with an invalid series, and the print methods are different for
> different frequencies, hence different error messages.
>
> Please do not send the same post repeatedly!

I apologize, I thought there was a problem with the first post.
Regards,

Simone


>
> On Wed, 31 May 2006, Simone Giannerini wrote:
>
> > Dear All,
> >
> > I found the following  under R 2.3.0 on WINXP (tested on 2 PCs, I do
> > not have access to Linux from this PC, sorry ... )
> >
> >> set.seed(10)
> >> x <- ts(rnorm(6),frequency=7)
> >> x
> > Time Series:
> > Start = c(1, 1)
> > End = c(1, 6)
> > Frequency = 7
> > [1]  0.01874617 -0.18425254 -1.37133055 -0.59916772  0.29454513  0.38979430
> >> x[24] <- NA
> >> x
> > Time Series:
> > Start = c(1, 1)
> > End = c(1, 6)
> > Frequency = 7
> > [1]  0.01874617 -0.18425254 -1.37133055 -0.59916772  0.29454513
> > 0.38979430          NA          NA          NA          NA          NA
> > [12]          NA          NA          NA          NA          NA
> >   NA          NA          NA          NA          NA          NA
> > [23]
> > ## OK ********************
> >
> >> x <- ts(rnorm(6),frequency=12) # THE SAME BUT WITH frequency = 12
> >> x
> >         Jan        Feb        Mar        Apr        May        Jun
> > 1 -1.2080762 -0.3636760 -1.6266727 -0.2564784  1.1017795  0.7557815
> >> x[24] <- NA
> >> x
> > Error in matrix(c(rep.int("", start.pad), format(x, ...), rep.int("",  :
> >        length of 'dimnames' [1] not equal to array extent
> > In addition: Warning message:
> > data length [30] is not a sub-multiple or multiple of the number of
> > columns [12] in matrix
> >
> >> x <- ts(rnorm(6),frequency=4) # THE SAME BUT WITH frequency = 4
> >> x
> >         Qtr1        Qtr2        Qtr3        Qtr4
> > 1 -0.23823356  0.98744470  0.74139013  0.08934727
> > 2 -0.95494386 -0.19515038
> >> x[24] <- NA
> >> x
> > Error in matrix(c(rep.int("", start.pad), format(x, ...), rep.int("",  :
> >        length of 'dimnames' [1] not equal to array extent
> > In addition: Warning message:
> > data length [26] is not a sub-multiple or multiple of the number of
> > rows [7] in matrix
> >
> >
> > Is this behaviour expected for frequencies 12 and 4?
> >
> > Thank you
> >
> > Simone
> >
> > ***************************************************
> > platform       i386-pc-mingw32
> > arch           i386
> > os             mingw32
> > system         i386, mingw32
> > status
> > major          2
> > minor          3.0
> > year           2006
> > month          04
> > day            24
> > svn rev        37909
> > language       R
> > version.string Version 2.3.0 (2006-04-24)
> >
> >> Sys.getlocale()
> > [1] "LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
> > States.1252;LC_MONETARY=English_United
> > States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252"
> >
> > ______________________________________________________
> >
> > Simone Giannerini
> > Dipartimento di Scienze Statistiche "Paolo Fortunati"
> > Universita' di Bologna
> > Via delle belle arti 41 - 40126  Bologna,  ITALY
> > Tel: +39 051 2098248  Fax: +39 051 232153
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>


-- 
______________________________________________________

Simone Giannerini
Dipartimento di Scienze Statistiche "Paolo Fortunati"
Universita' di Bologna
Via delle belle arti 41 - 40126  Bologna,  ITALY
Tel: +39 051 2098248  Fax: +39 051 232153


From Account_aggregation_apollo at gmail.com  Wed May 31 19:35:08 2006
From: Account_aggregation_apollo at gmail.com (Account_aggregation_apollo at gmail.com)
Date: Wed, 31 May 2006 19:35:08 +0200 (CEST)
Subject: [Rd] CT unit to drill on Mars,
	Revenue Up 200% - Ref. jh010 (PR#8918)
Message-ID: <20060531173508.22CA23F043@slim.kubism.ku.dk>

esteeming
Coiled tubing units are so compact and have such great potential, the Mars Drilling Project is evaluating a coiled tubing unit to drill for water on Mars. fells
disseverance
SPRING, TX--(MARKET WIRE)-- Coil Tubing Technology, Inc. (CTBG) announces the delivery of the first group of 8 Rotating Tools to oil and gas well service companies operating in Mexico and Oklahoma. Designed for use in "fishing" applications utilizing 2" coiled tubing strings, these tools were delivered and "in the field" the week of May 1, 2006 subducted
flytrap
In addition, CTBG has received orders for ten more of these 2 7/8" Rotating Tool units, plus five 2 1/8" Rotating Tools, all of which are scheduled for delivery to customers before the end of the month of May. cosmogonical
CTBG offers the only fully rotating tool for well fishing applications," stated Jerry Swinford, President of Coil Tubing Technology, Inc. "Other tools in the marketplace only 'index' or 'turn' in 90 degree increments without fully rotating, which is an inefficient means of latching a fish. We are delighted by the overwhelming response from customers regarding the capabilities of these tools."  avenging
The Rotating Tool is a device that attaches to the end of a coiled tube to assist with "latching a fish," or removing production kits or undesired obstructions from the well by introducing rotation under mechanical pressure. The design and action of the tool is similar to a "Yankee screwdriver." If, for example, during normal operations, a piece of coiled tube is broken off and remains lodged in the wellbore, it can be difficult to get the new coiled tubing line past the obstruction. By introducing rotation to the "overshot," or latching mechanism at the end of the tool, obstructions can be cleared without the need to manually work the tool through the well head. lonesomeness
Coil Tubing Technology was established in 1998 by an innovative founder that has over thirty years experience in the design of oil-field tools in general and fifteen years of experience in the design of proprietary tools for the coiled tubing industry in particular. With more than fifteen patents either granted or pending, CTBG is the leader in providing new technology to the coiled tubing industry. CTBG has become a one stop rental tool company supplying a full line of standard as well as propietary coiled tubing downhole tools. scorify
knottily
COILED TUBING DRILLING TOOLS
The Jet Motor maximizes torque and RPM combinations. This motor has the capability to establish bit hydraulics. The long life bearing package allows the tool to stay in the hole longer than average. It can be jarred without damaging the tool which is ideal for drilling through shale. The Jet Motor has been used successfully with MWD and steering tools in drilling applications. The nitrogen power source permits underbalanced drilling. preadapt
The Pulsator allows the weight on the bit to be maximized without stalling the motor as the torsional and axial torque are retained within the tool. The maximum tensible strength allows high energy jarring impact while the tool prevents spike loading from migrating up into the generic tool strings. god
The HeavyHitter, when used on the upstroke only, provides variable tensible overpull due to its hydraulic metered detent system. The minimum axial drag at detent release provides high velocity of the hammer mass to the anvil. gyros
exceed
THE COIL TUBING BUSINESS
The coiled tubing industry continues to be one of the fastest growing segments of the oilfield services sector, and for good reason. CT growth has been driven by attractive economics, continual advances in technology, and utilization of CT to perform an ever-growing list of field operations. Coiled tubing today is a global, multi billion dollar industry in the mainstream of energy extraction technology. lymphatolysis
culminations
FUTURE TRENDS IN COIL TUBING SERVICES
According to Andy Rike, President of Technicoil USA Corp., a CT service company with operations in Canada and the US, "We see market growth for coiled tubing services to independent producers in three areas: fracturing, particularly multiple interval completions; re-entry drilling of horizontal laterals or vertical extensions in older wells; and "grassroots" drilling of shallower wells, including many coalbed methane wells." surveyable
Rike adds that one of the most important reasons for growth of coiled tubing drilling services has been the development of more integrated units. "In past years, coiled tubing units were not able to provide the sort of integrated set of equipment capabilities needed for drilling and completion operations. This led to an amalgamation of service company systems cobbled together on site and a situation where the safety, speed and size advantages of CT were being lost." Now, Technicoil as well as a few other companies have designed and built integrated CT units that incorporate everything needed to drill a well into four trailer loads. When rigged up these units fill a 20,000 sq ft footprint, less than 1/3 the size of a conventional rig. These newer units can also drill with conventional pipe, so they can drill a surface hole and set surface pipe with conventional equipment and then drill with coiled tubing. stalkers
In addition to the small footprint, the primary drivers for wider use of these units are very tight control of well discharges and speed. "We've drilled 400 feet per hour in some situations," says Rike. The combination of a smaller hole, lack of connections, faster trip time, and the higher drilling rates inherent to downhole motors leads to very rapid drilling rates. Last year, in the San Juan Basin of New Mexico, Technicoil drilled 26 wells to around 3000 feet for Burlington Resources over a four month period with one standard CT system (Figure 1). recompose
Another area of growth is in fracturing, particularly multiple interval fracturing.  One recent example is a five well project in Virginia's Buchanan County where as many as nineteen intervals were fractured using coiled tubing and a bottom-hole packer assembly (Rodvelt, 2001). These wells, part of a CONSOL Energy Inc. coalbed methane project, were part of a pilot to determine if individually fracturing each of the zones would result in better recovery. Prior efforts had evolved from single-stage, limited entry treatments to multiple-stage treatments with composite frac plugs and frac baffles. microelectrophoretically
Core tests on offset acreage had revealed that 3 of 10 coal seams had not been stimulated by these treatments and, on average, ten feet of coal was not being effectively stimulated. If the CT fracturing approach is successful in improving this situation, CONSOL calculated that an additional net present value of 1 million could be added per 160-acre lease, based on a gas price of 2.50. The CT fracturing procedure was a technical success, and hopefully, when the wells are dewatered and fully evaluated, it will be shown to be an economic success as well. Other CBM areas have seen similar success. For example, Barrett Resources experienced a 1.5 fold increase in gas production from 14 CBM wells in the Raton Basin following stimulation with coiled tubing versus conventional treatments. "Fracturing is probably the area with the greatest growth potential," says Rike, "and coalbed methane is about a third of that market." lepromata
banishers
NEW COIL TUBING MARKETS / FIELD APPLICATIONS
CT first established it's niche in the marketplace as a cost-effective well cleanout tool. In recent years, these conventional wellbore cleanouts and acid stimulation jobs accounted for more than three quarters of total CT revenue. However, CT use has continued to expand as it is adopted for use in additional field operations. Most recently, CT fracturing and drilling applications have emerged as two of the fastest growth areas. Revenue from these two CT applications has grown from almost zero 10 years ago, to approximately 15 percent in more recent times. lysate
homophyly
GROWTH OF THE service FLEET
In January 2004, slightly more than 1,050 CT units were estimated to be available on a worldwide basis. The total number of working CT units is up sharply from the roughly 850 units reported in February 2001. At present, the International market accounts for the bulk of the currently available CT fleet with more than 425 units. Canada and the U.S. are estimated to contribute an additional 239 and 253 units, respectively.
sternad
THE ENVIRONMENTAL AND SAFETY BENEFITS OF USING COILED TUBING UNITS FOR DRILLING INCLUDE:
The units require about half the space that a conventional drilling rig requires. The units require less power so there is less fuel consumption and emissions during drilling. Noise levels are 18 percent lower than with conventional rigs. tanagers
There is less visual impact as the units are small with no large derrick tower. kidvid
disuniters
All of this means that coiled tubing units are more cost effective, energy efficient, have a much smaller environmental footprint, and create less waste. In certain drilling operations, coiled tubing units cost approximately half of what a conventional drill rig would cost. haystack
trailingly
In fact, coiled tubing units are so compact and have such great potential, the Mars Drilling Project is evaluating modifying, miniaturizing and fully automating a coiled tubing unit to drill for water on Mars. Realistically, it will be years before the unit is developed and sent to by rocket to Mars, but it would be an important first step before Mars could be colonized. And coiled tubing technology will be be greatly improved by the research. pomiferous
obtuseness
For more information on CTBG, please visit Yahoo Finance - CTBG  phthisiotherapy
href="http://finance.yahoo.com/q?s=CTBG.PK
tutti
The BottomLine Report is not liable for any decisions by its readers or subscribers. The information contained herein has been provided as an information service only. isonomy
The BottomLine Report purchased 270,000 shares at 0.15.  We may close our positions at any time. pedestrians
squiffy


	[[alternative HTML version deleted]]


