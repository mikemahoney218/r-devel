From antonio at piccolboni.info  Tue May  1 01:28:04 2012
From: antonio at piccolboni.info (Antonio Piccolboni)
Date: Mon, 30 Apr 2012 16:28:04 -0700
Subject: [Rd] fast version of split.data.frame or conversion from data.frame
 to list of its rows
Message-ID: <CA+VDHFUj=mkk4gUySHZejq1VipZmcGeK0+1GAg25sEsGwQ=bhQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120430/555fbd02/attachment.pl>

From mdowle at mdowle.plus.com  Tue May  1 11:26:31 2012
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Tue, 1 May 2012 09:26:31 +0000
Subject: [Rd] fast version of split.data.frame or conversion from
	data.frame to list of its rows
References: <CA+VDHFUj=mkk4gUySHZejq1VipZmcGeK0+1GAg25sEsGwQ=bhQ@mail.gmail.com>
Message-ID: <loom.20120501T104055-153@post.gmane.org>


Antonio Piccolboni <antonio <at> piccolboni.info> writes:
> Hi,
> I was wondering if there is anything more efficient than split to do the
> kind of conversion in the subject. If I create a data frame as in
> 
> system.time({fd =  data.frame(x=1:2000, y = rnorm(2000), id = paste("x",
> 1:2000, sep =""))})
>   user  system elapsed
>   0.004   0.000   0.004
> 
> and then I try to split it
> 
> > system.time(split(fd, 1:nrow(fd)))
>    user  system elapsed
>   0.333   0.031   0.415
> 
> You will be quick to notice the roughly two orders of magnitude difference
> in time between creation and conversion. Granted, it's not written anywhere
> that they should be similar but the latter seems interpreter-slow to me
> (split is implemented with a lapply in the data frame case) There is also a
> memory issue when I hit about 20000 elements (allocating 3GB when
> interrupted). So before I resort to Rcpp, despite the electrifying feeling
> of approaching the bare metal and for the sake of getting things done, I
> thought I would ask the experts. Thanks
> 
> Antonio

Perhaps r-help or Stack Overflow would have been more appropriate to try first, 
before r-devel. If you did, please say so.

Answering anyway. Do you really want to split every single row? What's the 
bigger picture? Perhaps you don't need to split at all.

On the off chance that the example was just for exposition, and applying some 
(biased) guesswork, have you seen the data.table package? It doesn't use the 
split-apply-combine paradigm because, as your (extreme) example shows, that 
doesn't scale. When you use the 'by' argument of [.data.table, it allocates 
memory once for the largest group. Then it reuses that same memory for each 
group. That's one reason it's fast and memory efficient at grouping (an order 
of magnitude faster than tapply).

Independent timings :
http://www.r-bloggers.com/comparison-of-ave-ddply-and-data-table/

If you really do want to split every single row, then
    DT[,<something>,by=1:nrow(DT)]
will give perhaps two orders of magnitude speedup, but that's an unfair example 
because it isn't very realistic. Scaling applies to the size of the data.frame, 
and, how much you want to split it up. Your example is extreme in the latter 
but not the former. data.table scales in both.

It's nothing to do with the interpreter, btw, just memory usage.

Matthew


From ripley at stats.ox.ac.uk  Tue May  1 14:46:50 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 01 May 2012 13:46:50 +0100
Subject: [Rd] fast version of split.data.frame or conversion from
 data.frame to list of its rows
In-Reply-To: <CA+VDHFUj=mkk4gUySHZejq1VipZmcGeK0+1GAg25sEsGwQ=bhQ@mail.gmail.com>
References: <CA+VDHFUj=mkk4gUySHZejq1VipZmcGeK0+1GAg25sEsGwQ=bhQ@mail.gmail.com>
Message-ID: <4F9FDB3A.50604@stats>

On 01/05/2012 00:28, Antonio Piccolboni wrote:
> Hi,
> I was wondering if there is anything more efficient than split to do the
> kind of conversion in the subject. If I create a data frame as in
>
> system.time({fd =  data.frame(x=1:2000, y = rnorm(2000), id = paste("x",
> 1:2000, sep =""))})
>    user  system elapsed
>    0.004   0.000   0.004
>
> and then I try to split it
>
>> system.time(split(fd, 1:nrow(fd)))
>     user  system elapsed
>    0.333   0.031   0.415
>
>
> You will be quick to notice the roughly two orders of magnitude difference
> in time between creation and conversion. Granted, it's not written anywhere

Unsurprising when you create three orders of magnitude more data frames, 
is it?  That's a list of 2000 data frames.  Try

system.time(for(i in 1:2000) data.frame(x = i, y = rnorm(1), id = 
paste0("x", i)))


> that they should be similar but the latter seems interpreter-slow to me
> (split is implemented with a lapply in the data frame case) There is also a
> memory issue when I hit about 20000 elements (allocating 3GB when
> interrupted). So before I resort to Rcpp, despite the electrifying feeling
> of approaching the bare metal and for the sake of getting things done, I
> thought I would ask the experts. Thanks

You need to re-think your data structures: 1-row data frames are not 
sensible.


>
>
> Antonio
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rvaradhan at jhmi.edu  Tue May  1 15:51:07 2012
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Tue, 1 May 2012 13:51:07 +0000
Subject: [Rd] The constant part of the log-likelihood in StructTS
In-Reply-To: <CAGW7bkyFDeRzfUR91x79VrChvCf5py9ErYbs58eJ0fCOQnZ9Mw@mail.gmail.com>
References: <CAGW7bkyFDeRzfUR91x79VrChvCf5py9ErYbs58eJ0fCOQnZ9Mw@mail.gmail.com>
Message-ID: <2F9EA67EF9AE1C48A147CB41BE2E15C31DF461@DOM-EB-MAIL2.win.ad.jhu.edu>

This is not a problem at all.  The log likelihood function is a function of the model parameters and the data, but it is defined up to an additive arbitrary constant, i.e. L(\theta) and L(\theta) + k are completely equivalent, for any k. This does not affect model comparisons or hypothesis tests.

Ravi
________________________________________
From: r-devel-bounces at r-project.org [r-devel-bounces at r-project.org] on behalf of Jouni Helske [jounihelske at gmail.com]
Sent: Monday, April 30, 2012 7:37 AM
To: r-devel at r-project.org
Subject: [Rd] The constant part of the log-likelihood in StructTS

Dear all,

I'd like to discuss about a possible bug in function StructTS of stats
package. It seems that the function returns wrong value of the
log-likelihood, as the added constant to the relevant part of the
log-likelihood is misspecified. Here is an simple example:

> data(Nile)
> fit <- StructTS(Nile, type = "level")
> fit$loglik
[1] -367.5194

When computing the log-likelihood with other packages such as KFAS and FKF,
the loglikelihood value is around -645.

For the local level model, the likelihood is defined by -0.5*n*log(2*pi) -
0.5*sum(log(F_t) + v_t^2/sqrt(F_t)) (see for example  Durbin and Koopman
(2001, page 30). But in StructTS, the likelihood is computed like this:

loglik <- -length(y) * res$value + length(y) * log(2 * pi),

where the first part coincides with the last part of the definition, but
the constant part has wrong sign and it is not multiplied by 0.5. Also in
case of missing observations, I think there should be sum(!is.na(y))
instead of length(y) in the constant term, as the likelihood is only
computed for those y which are observed.

This does not affect in estimation of model parameters, but it could have
effects in model comparison or some other cases.

Is there some reason for this kind of constant, or is it just a bug?

Best regards,

Jouni Helske
PhD student in Statistics
University of Jyv?skyl?
Finland

        [[alternative HTML version deleted]]

From antonio at piccolboni.info  Tue May  1 19:26:32 2012
From: antonio at piccolboni.info (Antonio Piccolboni)
Date: Tue, 1 May 2012 10:26:32 -0700
Subject: [Rd] fast version of split.data.frame or conversion from
 data.frame to list of its rows
In-Reply-To: <4F9FDB3A.50604@stats>
References: <CA+VDHFUj=mkk4gUySHZejq1VipZmcGeK0+1GAg25sEsGwQ=bhQ@mail.gmail.com>
	<4F9FDB3A.50604@stats>
Message-ID: <CA+VDHFXz2n2vCbiYTCy764ct8HTRFrpC-G0oKtd4YqtG6mOTEw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120501/0be9e372/attachment.pl>

From jounihelske at gmail.com  Tue May  1 20:16:41 2012
From: jounihelske at gmail.com (Jouni Helske)
Date: Tue, 1 May 2012 21:16:41 +0300
Subject: [Rd] The constant part of the log-likelihood in StructTS
In-Reply-To: <2F9EA67EF9AE1C48A147CB41BE2E15C31DF461@DOM-EB-MAIL2.win.ad.jhu.edu>
References: <CAGW7bkyFDeRzfUR91x79VrChvCf5py9ErYbs58eJ0fCOQnZ9Mw@mail.gmail.com>
	<2F9EA67EF9AE1C48A147CB41BE2E15C31DF461@DOM-EB-MAIL2.win.ad.jhu.edu>
Message-ID: <CAGW7bkxKdPQQ_xdVuhWCMFq0HVuaoZJe6h9ycgEcmUpKSTyuUg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120501/72853f6f/attachment.pl>

From simon.urbanek at r-project.org  Tue May  1 20:29:18 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 1 May 2012 14:29:18 -0400
Subject: [Rd] fast version of split.data.frame or conversion from
	data.frame to list of its rows
In-Reply-To: <CA+VDHFXz2n2vCbiYTCy764ct8HTRFrpC-G0oKtd4YqtG6mOTEw@mail.gmail.com>
References: <CA+VDHFUj=mkk4gUySHZejq1VipZmcGeK0+1GAg25sEsGwQ=bhQ@mail.gmail.com>
	<4F9FDB3A.50604@stats>
	<CA+VDHFXz2n2vCbiYTCy764ct8HTRFrpC-G0oKtd4YqtG6mOTEw@mail.gmail.com>
Message-ID: <DA49C0C2-C3A5-455D-A278-6CF9E971797C@r-project.org>


On May 1, 2012, at 1:26 PM, Antonio Piccolboni <antonio at piccolboni.info> wrote:

> It seems like people need to hear more context, happy to provide it. I am
> implementing a serialization format (typedbytes, HADOOP-1722 if people want
> the gory details) to make R and Hadoop interoperate better (RHadoop
> project, package rmr). It is a row first format and it's already
> implemented as a C extension for R for lists and atomic vectors, where each
> element  of a vector is a row. I need to extend it to accept data frames
> and I was wondering if I can use the existing C code by converting a data
> frame to a list of its rows. It sounds like the answer is that it is not a
> good idea,

Just think about it -- data frames are lists of *columns* because the type of each column is fixed. Treating them row-wise is extremely inefficient, because you can't use any vector type to represent such thing (other than a generic vector containing vectors of length 1).


> that's helpful too in a way because it restricts the options. I
> thought I may be missing a simple primitive, like a t() for data frames
> (that doesn't coerce to matrix).

See above - I think you are misunderstanding data frames - t() makes no sense for data frames.

Cheers,
Simon



> On Tue, May 1, 2012 at 5:46 AM, Prof Brian Ripley <ripley at stats.ox.ac.uk>wrote:
> 
>> On 01/05/2012 00:28, Antonio Piccolboni wrote:
>> 
>>> Hi,
>>> I was wondering if there is anything more efficient than split to do the
>>> kind of conversion in the subject. If I create a data frame as in
>>> 
>>> system.time({fd =  data.frame(x=1:2000, y = rnorm(2000), id = paste("x",
>>> 1:2000, sep =""))})
>>>  user  system elapsed
>>>  0.004   0.000   0.004
>>> 
>>> and then I try to split it
>>> 
>>> system.time(split(fd, 1:nrow(fd)))
>>>> 
>>>   user  system elapsed
>>>  0.333   0.031   0.415
>>> 
>>> 
>>> You will be quick to notice the roughly two orders of magnitude difference
>>> in time between creation and conversion. Granted, it's not written
>>> anywhere
>>> 
>> 
>> Unsurprising when you create three orders of magnitude more data frames,
>> is it?  That's a list of 2000 data frames.  Try
>> 
>> system.time(for(i in 1:2000) data.frame(x = i, y = rnorm(1), id =
>> paste0("x", i)))
>> 
>> 
>> 
>> that they should be similar but the latter seems interpreter-slow to me
>>> (split is implemented with a lapply in the data frame case) There is also
>>> a
>>> memory issue when I hit about 20000 elements (allocating 3GB when
>>> interrupted). So before I resort to Rcpp, despite the electrifying feeling
>>> of approaching the bare metal and for the sake of getting things done, I
>>> thought I would ask the experts. Thanks
>>> 
>> 
>> You need to re-think your data structures: 1-row data frames are not
>> sensible.
>> 
>> 
>> 
>>> 
>>> Antonio
>>> 
>>>       [[alternative HTML version deleted]]
>>> 
>>> 
>>> ______________________________**________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/**listinfo/r-devel<https://stat.ethz.ch/mailman/listinfo/r-devel>
>>> 
>> 
>> 
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~**ripley/<http://www.stats.ox.ac.uk/~ripley/>
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From phgrosjean at sciviews.org  Tue May  1 22:21:43 2012
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Tue, 01 May 2012 22:21:43 +0200
Subject: [Rd] A doubt about substitute() after delayedAssign()
In-Reply-To: <4F9D2AED.3020701@gmail.com>
References: <4F9CEE2B.4080507@sciviews.org> <4F9D2AED.3020701@gmail.com>
Message-ID: <4FA045D7.9020604@sciviews.org>

On 29/04/12 13:50, Duncan Murdoch wrote:
> On 12-04-29 3:30 AM, Philippe Grosjean wrote:
>  > Hello,
>  >
>  > ?delayedAssign presents substitute() as a way to look at the expression
>  > in the promise. However,
>  >
>  > msg<- "old"
>  > delayedAssign("x", msg)
>  > msg<- "new!"
>  > x #- new!
>  > substitute(x) #- x (was 'msg' ?)
>  >
>  > Here, we just got 'x'... shouldn't we got 'msg'?
>  >
>  > Same result when the promise is not evaluated yet:
>  >
>  > delayedAssign("x", msg)
>  > substitute(x)
>  >
>  > In a function, that works:
>  >
>  > foo<- function (x = msg) substitute(x)
>  > foo()
>  >
>  > Did I misunderstood something? It seems to me that substitute() does not
>  > behaves as documented for promises created using delayedAssign().
>
> I don't think this is well documented, but substitute() doesn't act the
> same when its "env" argument is the global environment. So this works
> the way you'd expect:
>
> e <- new.env()
> msg <- "old"
> delayedAssign("x", msg, assign=e)
> msg <- "new"
> e$x
> substitute(x, e)
>
> I forget what the motivation was for special-casing globalenv().
>
> Duncan Murdoch

In the corresponding C code, there is a comment telling that it is for 
"historical reasons". Are these historical reasons that important that 
there is no way using R code (not C code) to know if a symbol is bind to 
a promise in .GlobalEnv? Anyway, I have filled a bug report because, at 
least the documentation of ?delayedAssign and ?substitute should be 
clarified, as well as, the example for delayedAssign... But, unless for 
a good reason, it would be better to perform substitution, even in 
.GlobalEnv, or alternatively, to provide a function like promiseExpr() 
to get it.

Here are a couple of potentially useful functions (using the inline 
package for convenience, and also note that I had to use a trick of 
passing the substituted name of the variable to get the promise at the C 
level... which would be unnecessary if these would be special base 
functions that pass unevaluated arguments):

## is.promise(): check if a name is bind to a promise
require(inline)
code <- '
   SEXP obj;
   if (!isString(name) || length(name) != 1)
     error("name is not a single string");
   if (!isEnvironment(envir))
     error("envir should be an environment");
   obj = findVar(install(CHAR(STRING_ELT(name, 0))), envir);
   return ScalarLogical(TYPEOF(obj) == PROMSXP);
'
is.promise <- cfunction(signature(name = "character", envir = 
"environment"),
	code)
formals(is.promise) <- alist(x =, name = deparse(substitute(x)),
	envir = parent.frame(1))

## isEvaluated(), determine if a promise has already been evaluated
## return always TRUE is the name is bind to something else
## than a promise
code <- '
   SEXP obj;
   if (!isString(name) || length(name) != 1)
     error("name is not a single string");
   if (!isEnvironment(envir))
     error("envir should be an environment");
   obj = findVar(install(CHAR(STRING_ELT(name, 0))), envir);
   if (TYPEOF(obj) == PROMSXP && PRVALUE(obj) == R_UnboundValue) {
	return ScalarLogical(FALSE);
   } else {
	/* if it is not a promise, it is always evaluated! */
	return ScalarLogical(TRUE);
   }
'	
isEvaluated <- cfunction(signature(name = "character", envir = 
"environment"),
	code)
formals(isEvaluated) <- alist(x =, name = deparse(substitute(x)),
	envir = parent.frame(1))
	
## promiseExpr() retrieve the expression associated with a promise...
## even if it is in .GlobalEnv, what subsitute() does not!
code <- '
   SEXP obj;
   if (!isString(name) || length(name) != 1)
     error("name is not a single string");
   if (!isEnvironment(envir))
     error("envir should be an environment");
   obj = findVar(install(CHAR(STRING_ELT(name, 0))), envir);
   if (TYPEOF(obj) == PROMSXP) {
	return PREXPR(obj);
   } else {
	return R_NilValue;
   }
'	
promiseExpr <- cfunction(signature(name = "character", envir = 
"environment"),
	code)
formals(promiseExpr) <- alist(x =, name = deparse(substitute(x)),
	envir = parent.frame(1))

## promiseEnv() get the evaluation environment associated with a promise
code <- '
   SEXP obj;
   if (!isString(name) || length(name) != 1)
     error("name is not a single string");
   if (!isEnvironment(envir))
     error("envir should be an environment");
   obj = findVar(install(CHAR(STRING_ELT(name, 0))), envir);
   if (TYPEOF(obj) == PROMSXP) {
	return PRENV(obj);
   } else {
	return R_NilValue;
   }
'	
promiseEnv <- cfunction(signature(name = "character", envir = 
"environment"),
	code)
formals(promiseEnv) <- alist(x =, name = deparse(substitute(x)),
	envir = parent.frame(1))
	
## reeval() reavaluate a promise that has been already evaluated,
## An environment for the evaluation is required since PRENV is set
## to NULL on promise evaluation
code <- '
   SEXP obj;
   if (!isString(name) || length(name) != 1)
     error("name is not a single string");
   if (!isEnvironment(envir))
     error("envir should be an environment");
   if (!isEnvironment(evalenv))
     error("evalenv should be an environment");
   obj = findVar(install(CHAR(STRING_ELT(name, 0))), envir);
   if (TYPEOF(obj) == PROMSXP) {
	/* TODO: should we use the same precautions as in forcePromise(), line 
297 of eval.c? */
	/* TODO: what to do here, if not evaluated yet?*/
	SEXP val;
	val = eval(PRCODE(obj), evalenv);
	SET_PRVALUE(obj, val);
	return PRVALUE(obj);
   } else {
	return R_NilValue;
   }
'	
reeval <- cfunction(signature(name = "character", envir = "environment",
	evalenv = "environment"), code)
formals(reeval) <- alist(x =, name = deparse(substitute(x)),
	envir = parent.frame(1), evalenv = parent.frame(1))
rm(code)

msg <- "old"
delayedAssign("x", msg)
y <- msg
is.promise(x) # TRUE
isEvaluated(x) # FALSE, promise not evaluated yet!
is.promise(y) # FALSE
isEvaluated(y) # TRUE (always when not a promise)
msg <- "new"
x
y
is.promise(x) # Still TRUE
isEvaluated(x) # Now TRUE, the promise is evaluated
promiseExpr(x) # Also work in .GlobalEnv, on the contrary to 
substitute()! For "historical" reasons!
promiseExpr(y) # NULL because it is not a promise
promiseEnv(x) # It becomes NULL once the promise is evaluated!
msg <- "brand new message..."
x
reeval(x)
x

Best,

Philippe Grosjean


From murdoch.duncan at gmail.com  Tue May  1 22:32:18 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 01 May 2012 16:32:18 -0400
Subject: [Rd] A doubt about substitute() after delayedAssign()
In-Reply-To: <4FA045D7.9020604@sciviews.org>
References: <4F9CEE2B.4080507@sciviews.org> <4F9D2AED.3020701@gmail.com>
	<4FA045D7.9020604@sciviews.org>
Message-ID: <4FA04852.1060809@gmail.com>

On 12-05-01 4:21 PM, Philippe Grosjean wrote:
> On 29/04/12 13:50, Duncan Murdoch wrote:
>> On 12-04-29 3:30 AM, Philippe Grosjean wrote:
>>   >  Hello,
>>   >
>>   >  ?delayedAssign presents substitute() as a way to look at the expression
>>   >  in the promise. However,
>>   >
>>   >  msg<- "old"
>>   >  delayedAssign("x", msg)
>>   >  msg<- "new!"
>>   >  x #- new!
>>   >  substitute(x) #- x (was 'msg' ?)
>>   >
>>   >  Here, we just got 'x'... shouldn't we got 'msg'?
>>   >
>>   >  Same result when the promise is not evaluated yet:
>>   >
>>   >  delayedAssign("x", msg)
>>   >  substitute(x)
>>   >
>>   >  In a function, that works:
>>   >
>>   >  foo<- function (x = msg) substitute(x)
>>   >  foo()
>>   >
>>   >  Did I misunderstood something? It seems to me that substitute() does not
>>   >  behaves as documented for promises created using delayedAssign().
>>
>> I don't think this is well documented, but substitute() doesn't act the
>> same when its "env" argument is the global environment. So this works
>> the way you'd expect:
>>
>> e<- new.env()
>> msg<- "old"
>> delayedAssign("x", msg, assign=e)
>> msg<- "new"
>> e$x
>> substitute(x, e)
>>
>> I forget what the motivation was for special-casing globalenv().
>>
>> Duncan Murdoch
>
> In the corresponding C code, there is a comment telling that it is for
> "historical reasons". Are these historical reasons that important that
> there is no way using R code (not C code) to know if a symbol is bind to
> a promise in .GlobalEnv?

I don't know.  I believe I lost an argument similar to yours a few years 
ago, so I won't spend time on this again.

Duncan Murdoch

Anyway, I have filled a bug report because, at
> least the documentation of ?delayedAssign and ?substitute should be
> clarified, as well as, the example for delayedAssign... But, unless for
> a good reason, it would be better to perform substitution, even in
> .GlobalEnv, or alternatively, to provide a function like promiseExpr()
> to get it.
>
> Here are a couple of potentially useful functions (using the inline
> package for convenience, and also note that I had to use a trick of
> passing the substituted name of the variable to get the promise at the C
> level... which would be unnecessary if these would be special base
> functions that pass unevaluated arguments):
>
> ## is.promise(): check if a name is bind to a promise
> require(inline)
> code<- '
>     SEXP obj;
>     if (!isString(name) || length(name) != 1)
>       error("name is not a single string");
>     if (!isEnvironment(envir))
>       error("envir should be an environment");
>     obj = findVar(install(CHAR(STRING_ELT(name, 0))), envir);
>     return ScalarLogical(TYPEOF(obj) == PROMSXP);
> '
> is.promise<- cfunction(signature(name = "character", envir =
> "environment"),
> 	code)
> formals(is.promise)<- alist(x =, name = deparse(substitute(x)),
> 	envir = parent.frame(1))
>
> ## isEvaluated(), determine if a promise has already been evaluated
> ## return always TRUE is the name is bind to something else
> ## than a promise
> code<- '
>     SEXP obj;
>     if (!isString(name) || length(name) != 1)
>       error("name is not a single string");
>     if (!isEnvironment(envir))
>       error("envir should be an environment");
>     obj = findVar(install(CHAR(STRING_ELT(name, 0))), envir);
>     if (TYPEOF(obj) == PROMSXP&&  PRVALUE(obj) == R_UnboundValue) {
> 	return ScalarLogical(FALSE);
>     } else {
> 	/* if it is not a promise, it is always evaluated! */
> 	return ScalarLogical(TRUE);
>     }
> '	
> isEvaluated<- cfunction(signature(name = "character", envir =
> "environment"),
> 	code)
> formals(isEvaluated)<- alist(x =, name = deparse(substitute(x)),
> 	envir = parent.frame(1))
> 	
> ## promiseExpr() retrieve the expression associated with a promise...
> ## even if it is in .GlobalEnv, what subsitute() does not!
> code<- '
>     SEXP obj;
>     if (!isString(name) || length(name) != 1)
>       error("name is not a single string");
>     if (!isEnvironment(envir))
>       error("envir should be an environment");
>     obj = findVar(install(CHAR(STRING_ELT(name, 0))), envir);
>     if (TYPEOF(obj) == PROMSXP) {
> 	return PREXPR(obj);
>     } else {
> 	return R_NilValue;
>     }
> '	
> promiseExpr<- cfunction(signature(name = "character", envir =
> "environment"),
> 	code)
> formals(promiseExpr)<- alist(x =, name = deparse(substitute(x)),
> 	envir = parent.frame(1))
>
> ## promiseEnv() get the evaluation environment associated with a promise
> code<- '
>     SEXP obj;
>     if (!isString(name) || length(name) != 1)
>       error("name is not a single string");
>     if (!isEnvironment(envir))
>       error("envir should be an environment");
>     obj = findVar(install(CHAR(STRING_ELT(name, 0))), envir);
>     if (TYPEOF(obj) == PROMSXP) {
> 	return PRENV(obj);
>     } else {
> 	return R_NilValue;
>     }
> '	
> promiseEnv<- cfunction(signature(name = "character", envir =
> "environment"),
> 	code)
> formals(promiseEnv)<- alist(x =, name = deparse(substitute(x)),
> 	envir = parent.frame(1))
> 	
> ## reeval() reavaluate a promise that has been already evaluated,
> ## An environment for the evaluation is required since PRENV is set
> ## to NULL on promise evaluation
> code<- '
>     SEXP obj;
>     if (!isString(name) || length(name) != 1)
>       error("name is not a single string");
>     if (!isEnvironment(envir))
>       error("envir should be an environment");
>     if (!isEnvironment(evalenv))
>       error("evalenv should be an environment");
>     obj = findVar(install(CHAR(STRING_ELT(name, 0))), envir);
>     if (TYPEOF(obj) == PROMSXP) {
> 	/* TODO: should we use the same precautions as in forcePromise(), line
> 297 of eval.c? */
> 	/* TODO: what to do here, if not evaluated yet?*/
> 	SEXP val;
> 	val = eval(PRCODE(obj), evalenv);
> 	SET_PRVALUE(obj, val);
> 	return PRVALUE(obj);
>     } else {
> 	return R_NilValue;
>     }
> '	
> reeval<- cfunction(signature(name = "character", envir = "environment",
> 	evalenv = "environment"), code)
> formals(reeval)<- alist(x =, name = deparse(substitute(x)),
> 	envir = parent.frame(1), evalenv = parent.frame(1))
> rm(code)
>
> msg<- "old"
> delayedAssign("x", msg)
> y<- msg
> is.promise(x) # TRUE
> isEvaluated(x) # FALSE, promise not evaluated yet!
> is.promise(y) # FALSE
> isEvaluated(y) # TRUE (always when not a promise)
> msg<- "new"
> x
> y
> is.promise(x) # Still TRUE
> isEvaluated(x) # Now TRUE, the promise is evaluated
> promiseExpr(x) # Also work in .GlobalEnv, on the contrary to
> substitute()! For "historical" reasons!
> promiseExpr(y) # NULL because it is not a promise
> promiseEnv(x) # It becomes NULL once the promise is evaluated!
> msg<- "brand new message..."
> x
> reeval(x)
> x
>
> Best,
>
> Philippe Grosjean
>
>
>
>
>


From antonio at piccolboni.info  Tue May  1 20:44:16 2012
From: antonio at piccolboni.info (Antonio Piccolboni)
Date: Tue, 1 May 2012 11:44:16 -0700
Subject: [Rd] fast version of split.data.frame or conversion from
 data.frame to list of its rows
In-Reply-To: <DA49C0C2-C3A5-455D-A278-6CF9E971797C@r-project.org>
References: <CA+VDHFUj=mkk4gUySHZejq1VipZmcGeK0+1GAg25sEsGwQ=bhQ@mail.gmail.com>
	<4F9FDB3A.50604@stats>
	<CA+VDHFXz2n2vCbiYTCy764ct8HTRFrpC-G0oKtd4YqtG6mOTEw@mail.gmail.com>
	<DA49C0C2-C3A5-455D-A278-6CF9E971797C@r-project.org>
Message-ID: <CA+VDHFUE9biU0596aqA50GtD6_FCmqKkE-qvzTOCsj_dpYPF3w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120501/f3dc76e6/attachment.pl>

From mauricio.zambrano at jrc.ec.europa.eu  Wed May  2 12:06:13 2012
From: mauricio.zambrano at jrc.ec.europa.eu (Mauricio Zambrano-Bigiarini)
Date: Wed, 02 May 2012 12:06:13 +0200
Subject: [Rd] --as-cran error
Message-ID: <4FA10715.9040405@jrc.ec.europa.eu>

Dear List,

While using the --as-cran option for checking one of my packages:

R CMD check --as-cran hydroGOF_0.3-3.tar.gz


I got the following error message:

pkgname <- "hydroGOF"
 > source(file.path(R.home("share"), "R", "examples-header.R"))
 > options(warn = 1)
 > library('hydroGOF')
Error in loadNamespace(i[[1L]], c(lib.loc, .libPaths())) :
   there is no package called ?class?

However, I don't get any error message when the checking is done without 
the --as-cran option.

Could somebody give me a hint about how to solve this error before 
submission to CRAN ?


sessionInfo()
R version 2.15.0 (2012-03-30)
Platform: x86_64-redhat-linux-gnu (64-bit)

locale:
  [1] LC_CTYPE=en_GB.utf8       LC_NUMERIC=C
  [3] LC_TIME=en_GB.utf8        LC_COLLATE=en_GB.utf8
  [5] LC_MONETARY=en_GB.utf8    LC_MESSAGES=en_GB.utf8
  [7] LC_PAPER=C                LC_NAME=C
  [9] LC_ADDRESS=C              LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_GB.utf8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


Thanks in advance,

Mauricio Zambrano-Bigiarini
-- 
====================================================
Water Resources Unit
Institute for Environment and Sustainability (IES)
Joint Research Centre (JRC), European Commission
webinfo    : http://floods.jrc.ec.europa.eu/
====================================================
DISCLAIMER:
"The views expressed are purely those of the writer
and may not in any circumstances be regarded as sta-
ting an official position of the European Commission"
====================================================
Linux user #454569 -- Ubuntu user #17469
====================================================
"A strong man and a waterfall always
channel their own path." (Unknown)


From murdoch.duncan at gmail.com  Wed May  2 13:27:16 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 02 May 2012 07:27:16 -0400
Subject: [Rd] --as-cran error
In-Reply-To: <4FA10715.9040405@jrc.ec.europa.eu>
References: <4FA10715.9040405@jrc.ec.europa.eu>
Message-ID: <4FA11A14.4040602@gmail.com>

On 12-05-02 6:06 AM, Mauricio Zambrano-Bigiarini wrote:
> Dear List,
>
> While using the --as-cran option for checking one of my packages:
>
> R CMD check --as-cran hydroGOF_0.3-3.tar.gz
>
>
> I got the following error message:
>
> pkgname<- "hydroGOF"
>   >  source(file.path(R.home("share"), "R", "examples-header.R"))
>   >  options(warn = 1)
>   >  library('hydroGOF')
> Error in loadNamespace(i[[1L]], c(lib.loc, .libPaths())) :
>     there is no package called ?class?
>
> However, I don't get any error message when the checking is done without
> the --as-cran option.
>
> Could somebody give me a hint about how to solve this error before
> submission to CRAN ?


There was a bug in 2.15.0:  if your package used a package that used a 
recommended package (where "used" means listed as Depends, Suggests, 
Imports...), then you could get this error.

R-patched has this fixed, so you could update to that.  If you don't 
want to update, the workaround is to list "class" explicitly as a 
dependency of your package.

Duncan Murdoch

>
>
> sessionInfo()
> R version 2.15.0 (2012-03-30)
> Platform: x86_64-redhat-linux-gnu (64-bit)
>
> locale:
>    [1] LC_CTYPE=en_GB.utf8       LC_NUMERIC=C
>    [3] LC_TIME=en_GB.utf8        LC_COLLATE=en_GB.utf8
>    [5] LC_MONETARY=en_GB.utf8    LC_MESSAGES=en_GB.utf8
>    [7] LC_PAPER=C                LC_NAME=C
>    [9] LC_ADDRESS=C              LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_GB.utf8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
>
> Thanks in advance,
>
> Mauricio Zambrano-Bigiarini


From hadley at rice.edu  Wed May  2 15:24:21 2012
From: hadley at rice.edu (Hadley Wickham)
Date: Wed, 2 May 2012 13:24:21 +0000
Subject: [Rd] Decompressing raw vectors in memory
Message-ID: <CABdHhvHZLaGEcmuqLN-pzd_oGfJt8O_doU9JT8wvHwn=_pMyZw@mail.gmail.com>

Hi all,

I'm struggling to decompress a gzip'd raw vector in memory:

content <- readBin("http://httpbin.org/gzip", "raw", 1000)

memDecompress(content, type = "gzip")
# Error in memDecompress(content, type = "gzip") :
#  internal error -3 in memDecompress(2)

I'm reasonably certain that the file is correctly compressed, because
if I save it out to a file, I can read the uncompressed data:

tmp <- tempfile()
writeBin(content, tmp)
readLines(tmp)

So that suggests I'm using memDecompress incorrectly.  Any hints?

Thanks!

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From rvaradhan at jhmi.edu  Wed May  2 17:19:43 2012
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Wed, 2 May 2012 15:19:43 +0000
Subject: [Rd] The constant part of the log-likelihood in StructTS
In-Reply-To: <CAGW7bkxKdPQQ_xdVuhWCMFq0HVuaoZJe6h9ycgEcmUpKSTyuUg@mail.gmail.com>
References: <CAGW7bkyFDeRzfUR91x79VrChvCf5py9ErYbs58eJ0fCOQnZ9Mw@mail.gmail.com>
	<2F9EA67EF9AE1C48A147CB41BE2E15C31DF461@DOM-EB-MAIL2.win.ad.jhu.edu>
	<CAGW7bkxKdPQQ_xdVuhWCMFq0HVuaoZJe6h9ycgEcmUpKSTyuUg@mail.gmail.com>
Message-ID: <2F9EA67EF9AE1C48A147CB41BE2E15C31DF8B1@DOM-EB-MAIL2.win.ad.jhu.edu>

Comparing such disparate, non-nested models can be quite problematic.  I am not sure what AIC/BIC comparisons mean in such cases.  The issue of different constants should be the least of your worries.

Ravi

-----Original Message-----
From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of Jouni Helske
Sent: Tuesday, May 01, 2012 2:17 PM
To: r-devel at r-project.org
Subject: Re: [Rd] The constant part of the log-likelihood in StructTS

Ok, it seems that R's AIC and BIC functions warn about different constants, so that's probably enough. The constants are not irrelevant though, if you compute the log-likelihood of one model using StructTS, and then fit alternative model using other functions such as arima(), which do take account the constant term, and use those loglikelihoods for computing for example BIC, you get wrong results when checking which model gives lower BIC value. Hadn't though about it before, have to be more careful in future when checking results from different packages etc.

Jouni


On Tue, May 1, 2012 at 4:51 PM, Ravi Varadhan <rvaradhan at jhmi.edu> wrote:

> This is not a problem at all.  The log likelihood function is a 
> function of the model parameters and the data, but it is defined up to 
> an additive arbitrary constant, i.e. L(\theta) and L(\theta) + k are 
> completely equivalent, for any k. This does not affect model 
> comparisons or hypothesis tests.
>
> Ravi
> ________________________________________
> From: r-devel-bounces at r-project.org [r-devel-bounces at r-project.org] on 
> behalf of Jouni Helske [jounihelske at gmail.com]
> Sent: Monday, April 30, 2012 7:37 AM
> To: r-devel at r-project.org
> Subject: [Rd] The constant part of the log-likelihood in StructTS
>
> Dear all,
>
> I'd like to discuss about a possible bug in function StructTS of stats 
> package. It seems that the function returns wrong value of the 
> log-likelihood, as the added constant to the relevant part of the 
> log-likelihood is misspecified. Here is an simple example:
>
> > data(Nile)
> > fit <- StructTS(Nile, type = "level") fit$loglik
> [1] -367.5194
>
> When computing the log-likelihood with other packages such as KFAS and 
> FKF, the loglikelihood value is around -645.
>
> For the local level model, the likelihood is defined by 
> -0.5*n*log(2*pi) -
> 0.5*sum(log(F_t) + v_t^2/sqrt(F_t)) (see for example  Durbin and 
> Koopman (2001, page 30). But in StructTS, the likelihood is computed like this:
>
> loglik <- -length(y) * res$value + length(y) * log(2 * pi),
>
> where the first part coincides with the last part of the definition, 
> but the constant part has wrong sign and it is not multiplied by 0.5. 
> Also in case of missing observations, I think there should be 
> sum(!is.na(y)) instead of length(y) in the constant term, as the 
> likelihood is only computed for those y which are observed.
>
> This does not affect in estimation of model parameters, but it could 
> have effects in model comparison or some other cases.
>
> Is there some reason for this kind of constant, or is it just a bug?
>
> Best regards,
>
> Jouni Helske
> PhD student in Statistics
> University of Jyv?skyl?
> Finland
>
>         [[alternative HTML version deleted]]

	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Wed May  2 17:21:08 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 02 May 2012 16:21:08 +0100
Subject: [Rd] Decompressing raw vectors in memory
In-Reply-To: <CABdHhvHZLaGEcmuqLN-pzd_oGfJt8O_doU9JT8wvHwn=_pMyZw@mail.gmail.com>
References: <CABdHhvHZLaGEcmuqLN-pzd_oGfJt8O_doU9JT8wvHwn=_pMyZw@mail.gmail.com>
Message-ID: <4FA150E4.3090907@stats.ox.ac.uk>

On 02/05/2012 14:24, Hadley Wickham wrote:
> Hi all,
>
> I'm struggling to decompress a gzip'd raw vector in memory:
>
> content<- readBin("http://httpbin.org/gzip", "raw", 1000)
>
> memDecompress(content, type = "gzip")
> # Error in memDecompress(content, type = "gzip") :
> #  internal error -3 in memDecompress(2)
>
> I'm reasonably certain that the file is correctly compressed, because
> if I save it out to a file, I can read the uncompressed data:
>
> tmp<- tempfile()
> writeBin(content, tmp)
> readLines(tmp)
>
> So that suggests I'm using memDecompress incorrectly.  Any hints?

Headers.

> Thanks!
>
> Hadley
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From markleeds2 at gmail.com  Wed May  2 17:36:37 2012
From: markleeds2 at gmail.com (Mark Leeds)
Date: Wed, 2 May 2012 11:36:37 -0400
Subject: [Rd] The constant part of the log-likelihood in StructTS
In-Reply-To: <2F9EA67EF9AE1C48A147CB41BE2E15C31DF8B1@DOM-EB-MAIL2.win.ad.jhu.edu>
References: <CAGW7bkyFDeRzfUR91x79VrChvCf5py9ErYbs58eJ0fCOQnZ9Mw@mail.gmail.com>
	<2F9EA67EF9AE1C48A147CB41BE2E15C31DF461@DOM-EB-MAIL2.win.ad.jhu.edu>
	<CAGW7bkxKdPQQ_xdVuhWCMFq0HVuaoZJe6h9ycgEcmUpKSTyuUg@mail.gmail.com>
	<2F9EA67EF9AE1C48A147CB41BE2E15C31DF8B1@DOM-EB-MAIL2.win.ad.jhu.edu>
Message-ID: <CAHz+bWYiMpbeQtcsrpcJDuvZyzV6C9T+xOdP8SYmHbhGjHdwCQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120502/683df624/attachment.pl>

From hadley at rice.edu  Wed May  2 17:43:22 2012
From: hadley at rice.edu (Hadley Wickham)
Date: Wed, 2 May 2012 10:43:22 -0500
Subject: [Rd] Decompressing raw vectors in memory
In-Reply-To: <4FA150E4.3090907@stats.ox.ac.uk>
References: <CABdHhvHZLaGEcmuqLN-pzd_oGfJt8O_doU9JT8wvHwn=_pMyZw@mail.gmail.com>
	<4FA150E4.3090907@stats.ox.ac.uk>
Message-ID: <CABdHhvEdSD=yJLDJwM+Cht+uh0aBjpuGDTzZmPyaKKdPDBOjOQ@mail.gmail.com>

>> I'm struggling to decompress a gzip'd raw vector in memory:
>>
>> content<- readBin("http://httpbin.org/gzip", "raw", 1000)
>>
>> memDecompress(content, type = "gzip")
>> # Error in memDecompress(content, type = "gzip") :
>> # ?internal error -3 in memDecompress(2)
>>
>> I'm reasonably certain that the file is correctly compressed, because
>> if I save it out to a file, I can read the uncompressed data:
>>
>> tmp<- tempfile()
>> writeBin(content, tmp)
>> readLines(tmp)
>>
>> So that suggests I'm using memDecompress incorrectly. ?Any hints?
>
> Headers.

Looking at http://tools.ietf.org/html/rfc1952:

* the first two bytes are id1 and id2, which are 1f 8b as expected

* the third byte is the compression: deflate (as.integer(content[3]))

* the fourth byte is the flag

  rawToBits(content[4])
  [1] 00 00 00 00 00 00 00 00

  which indicates no extra header fields are present

So the header looks ok to me (with my limited knowledge of gzip)

Stripping off the header doesn't seem to help either:

memDecompress(content[-(1:10)], type = "gzip")
# Error in memDecompress(content[-(1:10)], type = "gzip") :
#  internal error -3 in memDecompress(2)

I've read the help for memDecompress but I don't see anything there to help me.

Any more hints?

Thanks!

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From ripley at stats.ox.ac.uk  Wed May  2 18:16:29 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 02 May 2012 17:16:29 +0100
Subject: [Rd] Decompressing raw vectors in memory
In-Reply-To: <CABdHhvEdSD=yJLDJwM+Cht+uh0aBjpuGDTzZmPyaKKdPDBOjOQ@mail.gmail.com>
References: <CABdHhvHZLaGEcmuqLN-pzd_oGfJt8O_doU9JT8wvHwn=_pMyZw@mail.gmail.com>
	<4FA150E4.3090907@stats.ox.ac.uk>
	<CABdHhvEdSD=yJLDJwM+Cht+uh0aBjpuGDTzZmPyaKKdPDBOjOQ@mail.gmail.com>
Message-ID: <4FA15DDD.4040607@stats.ox.ac.uk>

On 02/05/2012 16:43, Hadley Wickham wrote:
>>> I'm struggling to decompress a gzip'd raw vector in memory:
>>>
>>> content<- readBin("http://httpbin.org/gzip", "raw", 1000)
>>>
>>> memDecompress(content, type = "gzip")
>>> # Error in memDecompress(content, type = "gzip") :
>>> #  internal error -3 in memDecompress(2)
>>>
>>> I'm reasonably certain that the file is correctly compressed, because
>>> if I save it out to a file, I can read the uncompressed data:
>>>
>>> tmp<- tempfile()
>>> writeBin(content, tmp)
>>> readLines(tmp)
>>>
>>> So that suggests I'm using memDecompress incorrectly.  Any hints?
>>
>> Headers.
>
> Looking at http://tools.ietf.org/html/rfc1952:
>
> * the first two bytes are id1 and id2, which are 1f 8b as expected
>
> * the third byte is the compression: deflate (as.integer(content[3]))
>
> * the fourth byte is the flag
>
>    rawToBits(content[4])
>    [1] 00 00 00 00 00 00 00 00
>
>    which indicates no extra header fields are present
>
> So the header looks ok to me (with my limited knowledge of gzip)
>
> Stripping off the header doesn't seem to help either:
>
> memDecompress(content[-(1:10)], type = "gzip")
> # Error in memDecompress(content[-(1:10)], type = "gzip") :
> #  internal error -3 in memDecompress(2)
>
> I've read the help for memDecompress but I don't see anything there to help me.
>
> Any more hints?

Well, it seems what you get there depends on the client, but I did

tystie% curl -o foo "http://httpbin.org/gzip"
tystie% file foo
foo: gzip compressed data, last modified: Wed May  2 17:06:24 2012, max 
compression

and the final part worried me: I do not know if memDecompress() knows 
about that format.  The help page does not claim it can do anything 
other than de-compress the results of memCompress() (although past 
experience has shown that it can in some cases).  gzfile() supports a 
much wider range of formats.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hadley at rice.edu  Wed May  2 18:27:04 2012
From: hadley at rice.edu (Hadley Wickham)
Date: Wed, 2 May 2012 11:27:04 -0500
Subject: [Rd] Decompressing raw vectors in memory
In-Reply-To: <4FA15DDD.4040607@stats.ox.ac.uk>
References: <CABdHhvHZLaGEcmuqLN-pzd_oGfJt8O_doU9JT8wvHwn=_pMyZw@mail.gmail.com>
	<4FA150E4.3090907@stats.ox.ac.uk>
	<CABdHhvEdSD=yJLDJwM+Cht+uh0aBjpuGDTzZmPyaKKdPDBOjOQ@mail.gmail.com>
	<4FA15DDD.4040607@stats.ox.ac.uk>
Message-ID: <CABdHhvGYjNavx695yz32NBYw0Er_6oN60KnVXKQU=Vu8F724yA@mail.gmail.com>

> Well, it seems what you get there depends on the client, but I did
>
> tystie% curl -o foo "http://httpbin.org/gzip"
> tystie% file foo
> foo: gzip compressed data, last modified: Wed May ?2 17:06:24 2012, max
> compression
>
> and the final part worried me: I do not know if memDecompress() knows about
> that format. ?The help page does not claim it can do anything other than
> de-compress the results of memCompress() (although past experience has shown
> that it can in some cases). ?gzfile() supports a much wider range of
> formats.

Ah, ok.  Thanks.  Then in that case it's probably just as easy to save
it to a temp file and read that.

  con <- file(tmp) # R automatically detects compression
  open(con, "rb")
  on.exit(close(con), TRUE)

  readBin(con, raw(), file.info(tmp)$size * 10)

The only challenge is figuring out what n to give readBin. Is there a
good general strategy for this?  Guess based on the file size and then
iterate until result of readBin has length less than n?

  n <- file.info(tmp)$size * 2
  content <- readBin(con, raw(),  n)
  n_read <- length(content)
  while(n_read == n) {
    more <- readBin(con, raw(),  n)
    content <- c(content, more)
    n_read <- length(more)
  }

Which is not great style, but there shouldn't be many reads.

Hadley


-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From duncan at wald.ucdavis.edu  Wed May  2 18:47:07 2012
From: duncan at wald.ucdavis.edu (Duncan Temple Lang)
Date: Wed, 2 May 2012 09:47:07 -0700
Subject: [Rd] Decompressing raw vectors in memory
In-Reply-To: <CABdHhvGYjNavx695yz32NBYw0Er_6oN60KnVXKQU=Vu8F724yA@mail.gmail.com>
References: <CABdHhvHZLaGEcmuqLN-pzd_oGfJt8O_doU9JT8wvHwn=_pMyZw@mail.gmail.com>
	<4FA150E4.3090907@stats.ox.ac.uk>
	<CABdHhvEdSD=yJLDJwM+Cht+uh0aBjpuGDTzZmPyaKKdPDBOjOQ@mail.gmail.com>
	<4FA15DDD.4040607@stats.ox.ac.uk>
	<CABdHhvGYjNavx695yz32NBYw0Er_6oN60KnVXKQU=Vu8F724yA@mail.gmail.com>
Message-ID: <20120502164706.GA24386@wald.ucdavis.edu>

I understand the desire not to have any dependency on additional
packages, and I have no desire to engage in any "mine's better" exchanges.
So write this just for the record. 
The gzunzip() function handle this.

> library(RCurl); library(Rcompression)
> val = getURLContent("http://httpbin.org/gzip")
> cat(gunzip(val))
{
  "origin": "24.5.119.171",
  "headers": {
    "Content-Length": "",
    "Host": "httpbin.org",
    "Content-Type": "",
    "Connection": "keep-alive",
    "Accept": "*/*"
  },
  "gzipped": true,
  "method": "GET"
}


Just FWIW, as I really don't like writing to temporary files,
most so that we might move towards security in R.

   D.


Hadley Wickham wrote:
> > Well, it seems what you get there depends on the client, but I did
> >
> > tystie% curl -o foo "http://httpbin.org/gzip"
> > tystie% file foo
> > foo: gzip compressed data, last modified: Wed May ?2 17:06:24 2012, max
> > compression
> >
> > and the final part worried me: I do not know if memDecompress() knows about
> > that format. ?The help page does not claim it can do anything other than
> > de-compress the results of memCompress() (although past experience has shown
> > that it can in some cases). ?gzfile() supports a much wider range of
> > formats.
> 
> Ah, ok.  Thanks.  Then in that case it's probably just as easy to save
> it to a temp file and read that.
> 
>   con <- file(tmp) # R automatically detects compression
>   open(con, "rb")
>   on.exit(close(con), TRUE)
> 
>   readBin(con, raw(), file.info(tmp)$size * 10)
> 
> The only challenge is figuring out what n to give readBin. Is there a
> good general strategy for this?  Guess based on the file size and then
> iterate until result of readBin has length less than n?
> 
>   n <- file.info(tmp)$size * 2
>   content <- readBin(con, raw(),  n)
>   n_read <- length(content)
>   while(n_read == n) {
>     more <- readBin(con, raw(),  n)
>     content <- c(content, more)
>     n_read <- length(more)
>   }
> 
> Which is not great style, but there shouldn't be many reads.
> 
> Hadley
> 
> 
> -- 
> Assistant Professor / Dobelman Family Junior Chair
> Department of Statistics / Rice University
> http://had.co.nz/
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120502/9fddbfc5/attachment.bin>

From hadley at rice.edu  Wed May  2 18:53:44 2012
From: hadley at rice.edu (Hadley Wickham)
Date: Wed, 2 May 2012 11:53:44 -0500
Subject: [Rd] Decompressing raw vectors in memory
In-Reply-To: <20120502164706.GA24386@wald.ucdavis.edu>
References: <CABdHhvHZLaGEcmuqLN-pzd_oGfJt8O_doU9JT8wvHwn=_pMyZw@mail.gmail.com>
	<4FA150E4.3090907@stats.ox.ac.uk>
	<CABdHhvEdSD=yJLDJwM+Cht+uh0aBjpuGDTzZmPyaKKdPDBOjOQ@mail.gmail.com>
	<4FA15DDD.4040607@stats.ox.ac.uk>
	<CABdHhvGYjNavx695yz32NBYw0Er_6oN60KnVXKQU=Vu8F724yA@mail.gmail.com>
	<20120502164706.GA24386@wald.ucdavis.edu>
Message-ID: <CABdHhvH-S++mX_ZD3AQUnDLTTw=z9rXobZ5TQCNG64VuJ1hhuA@mail.gmail.com>

> I understand the desire not to have any dependency on additional
> packages, and I have no desire to engage in any "mine's better" exchanges.
> So write this just for the record.
> The gzunzip() function handle this.

Funnily enough I just discovered that RCurl already handles this: you
just need to set encoding = "gzip".  No extra dependencies, and yours
is better ;)

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From hvemhva at gmail.com  Wed May  2 17:51:35 2012
From: hvemhva at gmail.com (wuffmeister)
Date: Wed, 2 May 2012 08:51:35 -0700 (PDT)
Subject: [Rd] Problem using RBloomberg blpConnect
Message-ID: <1335973895595-4603615.post@n4.nabble.com>

I am using StatET/Eclipse successfully, but RBloomberg does not want to play
ball:

> conn <- blpConnect(log.level="finest")
R version 2.14.2 (2012-02-29) 
rJava Version 0.9-3 
RBloomberg Version 0.4-151 
Java environment initialized successfully.
Looking for most recent blpapi3.jar file...
Adding C:\blp\API\APIv3\JavaAPI\v3.4.6.6\lib\blpapi3.jar to Java classpath
Error in .jcall("RJavaTools", "Z", "classHasField", x, name, static) : 
  RcallMethod: cannot determine object class

Anyone got a clue about this one? Can't seem to find the same error message
elsewhere.

--
View this message in context: http://r.789695.n4.nabble.com/Problem-using-RBloomberg-blpConnect-tp4603615.html
Sent from the R devel mailing list archive at Nabble.com.


From ruipbarradas at sapo.pt  Thu May  3 14:55:22 2012
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 3 May 2012 05:55:22 -0700 (PDT)
Subject: [Rd] How to create data frame column name in a function
In-Reply-To: <1336032104058-4605358.post@n4.nabble.com>
References: <1336032104058-4605358.post@n4.nabble.com>
Message-ID: <1336049722102-4605939.post@n4.nabble.com>

Hello,


pvshankar wrote
> 
> Hello all,
> 
> I have a data frame with column names s1, s2, s3....s11
> 
> I have a function that gets two parameters, one is used as a subscript for
> the column names  and another is used as an index into the chosen column.
> 
> For example:
> 
> my_func <- function(subscr, index)
> {
>   if (subscr == 1)
>   {
>     df$s1[index] <- some value
>   }
> }
> 
> The problem is, I do not want to create a bunch of if statements (one for
> each 1:11 column names)). 
> Instead, I want to "create" the column name in run time based on subscr
> value.
> 
> I tried eval(as.name(paste("df$s",subscr,sep="")))[index] <- some value
> 
> and it complains that object df$s1 is not found.
> 
> Could someone please help me with this?
> (Needless to say, I have just started programing in R)
> 
> Thanks,
> Shankar
> 

Instead of operator '$' use function`[<-` with the right indexes.


cname <- paste("s", subscr, sep="")
DF[index, cname] <- value

See
?"[<-.data.frame"

(And df is the name of an R function, use something else, it can be
confusing.)

Hope this helps,

Rui Barradas


--
View this message in context: http://r.789695.n4.nabble.com/How-to-create-data-frame-column-name-in-a-function-tp4605358p4605939.html
Sent from the R devel mailing list archive at Nabble.com.


From pauljohn32 at gmail.com  Thu May  3 17:51:51 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Thu, 3 May 2012 10:51:51 -0500
Subject: [Rd] Proposal: model.data
Message-ID: <CAErODj8fUQW85O6hMzU40ACH3Nvzk7fBa2OnV=mx_MnNwqDC5A@mail.gmail.com>

Greetings:

I'm still working on functions to make it easier for students to
interpret regression predictions.  I am working out a scheme to
more easily create "newdata" objects (for use in predict functions).
This has been done before in packages like Zelig, Effects,
rms, and others. Nothing is "exactly right," though. Stata users keep
flashing their "predicted probabity tables" at me and I'd like
something like that to use with R.

I'm proposing here a function model.data that receives a regression
and creates a dataframe of raw data from which newdata objects
can be constructed. This follows a suggestion that Bill Dunlap made
to me in response to a question I posted in r-help.

While studying termplot code, I saw the "carrier" function approach
to deducing the "raw" predictors.  However, it does not always work.

Here is one problem. termplot mistakes 10 in log(10 + x1) for a variable

Example:

dat <- data.frame(x1 = rnorm(100), x2 = rpois(100, lambda=7))
STDE <- 10
dat$y <- 1.2 * log(10 + dat$x1) + 2.3 * dat$x2 + rnorm(100, sd = STDE)

m1 <- lm( y ~ log(10 + x1)  + x2, data=dat)
termplot(m1)

## See the trouble? termplot thinks 10 is the term to plot.

Another problem is that predict( type="terms") does not behave
sensibly sometimes. RHS of formula that have nonlinear transformations
are misunderstood as separate terms.

##Example:
dat$y2 <- 1.2 * log(10 + dat$x1) + 2.3 * dat$x1^2 + rnorm(100, sd = STDE)

m2 <- lm( y2 ~ log(10 + x1)  + sin(x1), data=dat)
summary(m2)

predict(m2, type="terms")

## Output:
## log(10 + x1)     sin(x1)
## 1     1.50051781 -2.04871711
## 2    -0.14707391  0.31131124

What I wish would happen instead is one "correct" prediction
for each value of x1. This should be the output:

predict(m2, newdata = data.frame(x1 = dat$x1))

## > predict(m2, newdata = data.frame(x1 = dat$x1))
##       1        2        3        4        5        6        7        8
## 17.78563 18.49806 17.50719 19.70093 17.45071 19.69718 18.84137 18.89971

The "fix" I'm testing now is the following new function, "model.data".
which tries to re-create the data object that would be
consistent with a fitted model. This follows a suggestion from
Bill Dunlap in r-help on 2012-04-22



##' Creates a "raw" (UNTRANSFORMED) data frame equivalent
##' to the input data that would be required to fit the given model.
##'
##' Unlike model.frame and model.matrix, this does not return transformed
##' variables.
##'
##' @param model A fitted regression model in which the data argument
##' is specified. This function will fail if the model was not fit
##' with the data option.
##' @return A data frame
##' @export
##' @author Paul E. Johnson <pauljohn@@ku.edu>
##' @example inst/examples/model.data-ex.R
model.data <- function(model){
    fmla <- formula(model)
    allnames <- all.vars(fmla) ## all variable names
    ## indep variables, includes d in poly(x,d)
    ivnames <- all.vars(formula(delete.response(terms(model))))
    ## datOrig: original data frame
    datOrig <-  eval(model$call$data, environment(formula(model)))
    if (is.null(datOrig))stop("model.data: input model has no data frame")
    ## datOrig: almost right, but includes d in poly(x, d)
    dat <- get_all_vars(fmla, datOrig)
    ## Get rid of "d" and other "non variable" variable names that are
not in datOrig:
    keepnames <- intersect(names(dat), names(datOrig))
    ## Keep only rows actually used in model fit, and the correct columns
    dat <- dat[ row.names(model$model) , keepnames]
    ## keep ivnames that exist in datOrig
    attr(dat, "ivnames") <- intersect(ivnames, names(datOrig))
    invisible(dat)
}


This works for the test cases like log(10+x) and so forth:

## Examples:

head(m1.data <- model.data(m1))

head(m2.data <- model.data(m2))

## > head(m1.data <- model.data(m1))
##          y          x1 x2
## 1 18.53846  0.46176539  8
## 2 28.24759  0.09720934  7
## 3 23.88184  0.67602556  9
## 4 23.50130 -0.74877054  8
## 5 25.81714  1.02555255  5
## 6 24.75052 -0.69659539  6
## > head(m2.data <- model.data(m2))
##          y          x1
## 1 18.53846  0.46176539
## 2 28.24759  0.09720934
## 3 23.88184  0.67602556
## 4 23.50130 -0.74877054
## 5 25.81714  1.02555255
## 6 24.75052 -0.69659539


d <- 2
m4 <- lm(y ~ poly(x1,d), data=dat)

head(m4.data <- model.data(m4))

##          y          x1
## 1 18.53846  0.46176539
## 2 28.24759  0.09720934
## 3 23.88184  0.67602556

Another strength of this approach is that the return object has an
attribute "ivnames".  If R's termplot used model.dat instead of the
carrier functions, this would make for a much tighter set of code.

What flaws do you see in this?

One flaw is that I did not know how to re-construct data from the
parent environment, so I insist the regression model has to have a
data argument. Is this necessary, or can one of the R experts help.

Another possible flaw: I'm keeping the columns from the data frame
that are needed to re-construct the model.frame, and to match
the rows, I'm using row.names for the model.frame.

Are there other formulae that will confuse this scheme?

If somebody in R Core would like this and think about putting it, or
something like it, into the base, then many chores involving predicted
values would become much easier.

PJ
-- 
Paul E. Johnson
Professor, Political Science ? ?Assoc. Director
1541 Lilac Lane, Room 504 ? ? Center for Research Methods
University of Kansas ? ? ? ? ? ? ? University of Kansas
http://pj.freefaculty.org ? ? ? ? ? ?http://quant.ku.edu


From brian at braverock.com  Thu May  3 18:36:49 2012
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 03 May 2012 11:36:49 -0500
Subject: [Rd] Proposal: model.data
In-Reply-To: <CAErODj8fUQW85O6hMzU40ACH3Nvzk7fBa2OnV=mx_MnNwqDC5A@mail.gmail.com>
References: <CAErODj8fUQW85O6hMzU40ACH3Nvzk7fBa2OnV=mx_MnNwqDC5A@mail.gmail.com>
Message-ID: <1336063009.29163.39.camel@brian-rcg>

On Thu, 2012-05-03 at 10:51 -0500, Paul Johnson wrote:
> If somebody in R Core would like this and think about putting it, or
> something like it, into the base, then many chores involving predicted
> values would become much easier.
> 
Why does this need to be in base?  Implement it in a package.
> 
If it works, and is additive, people will use it.  Look at 'reshape' or
'xts' or 'Matrix' just to name a few examples of widely used packages.

Regards,

   - Brian


From pauljohn32 at gmail.com  Thu May  3 19:09:08 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Thu, 3 May 2012 12:09:08 -0500
Subject: [Rd] Proposal: model.data
In-Reply-To: <1336063009.29163.39.camel@brian-rcg>
References: <CAErODj8fUQW85O6hMzU40ACH3Nvzk7fBa2OnV=mx_MnNwqDC5A@mail.gmail.com>
	<1336063009.29163.39.camel@brian-rcg>
Message-ID: <CAErODj8DhfYfn7y0kwWcUfKWCRVc-MZbEBTAuW_mEfQhnwfLSg@mail.gmail.com>

Greetings:

On Thu, May 3, 2012 at 11:36 AM, Brian G. Peterson <brian at braverock.com> wrote:
> On Thu, 2012-05-03 at 10:51 -0500, Paul Johnson wrote:
>> If somebody in R Core would like this and think about putting it, or
>> something like it, into the base, then many chores involving predicted
>> values would become much easier.
>>
> Why does this need to be in base? ?Implement it in a package.
>>
> If it works, and is additive, people will use it. ?Look at 'reshape' or
> 'xts' or 'Matrix' just to name a few examples of widely used packages.
>

I can't use it to fix termplot unless it is in base.

Or are you suggesting I create my own "termplot" replacement?


> Regards,
>
> ? - Brian
>
>



-- 
Paul E. Johnson
Professor, Political Science ? ?Assoc. Director
1541 Lilac Lane, Room 504 ? ? Center for Research Methods
University of Kansas ? ? ? ? ? ? ? University of Kansas
http://pj.freefaculty.org ? ? ? ? ? ?http://quant.ku.edu


From brian at braverock.com  Thu May  3 19:19:21 2012
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 03 May 2012 12:19:21 -0500
Subject: [Rd] Proposal: model.data
In-Reply-To: <CAErODj8DhfYfn7y0kwWcUfKWCRVc-MZbEBTAuW_mEfQhnwfLSg@mail.gmail.com>
References: <CAErODj8fUQW85O6hMzU40ACH3Nvzk7fBa2OnV=mx_MnNwqDC5A@mail.gmail.com>
	<1336063009.29163.39.camel@brian-rcg>
	<CAErODj8DhfYfn7y0kwWcUfKWCRVc-MZbEBTAuW_mEfQhnwfLSg@mail.gmail.com>
Message-ID: <1336065561.29163.42.camel@brian-rcg>

On Thu, 2012-05-03 at 12:09 -0500, Paul Johnson wrote:
> Greetings:
> 
> On Thu, May 3, 2012 at 11:36 AM, Brian G. Peterson <brian at braverock.com> wrote:
> > On Thu, 2012-05-03 at 10:51 -0500, Paul Johnson wrote:
> >> If somebody in R Core would like this and think about putting it, or
> >> something like it, into the base, then many chores involving predicted
> >> values would become much easier.
> >>
> > Why does this need to be in base?  Implement it in a package.
> >>
> > If it works, and is additive, people will use it.  Look at 'reshape' or
> > 'xts' or 'Matrix' just to name a few examples of widely used packages.
> >
> 
> I can't use it to fix termplot unless it is in base.
> 
> Or are you suggesting I create my own "termplot" replacement?

I was suggesting that you create a package that has all the features
that you think it needs.  

If you have a *patch* for termplot that would fix what you perceive to
be its problems, and not break existing code, then the usual method
would be to propose that.  It seems, though, that you are proposing more
significant changes to functionality, and it seems as though that would
run a risk of breaking backwards compatibility, which is usually a bad
idea.

Regards,

   - Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From betabandido at gmail.com  Thu May  3 20:07:43 2012
From: betabandido at gmail.com (victor jimenez)
Date: Thu, 3 May 2012 20:07:43 +0200
Subject: [Rd] loading multiple CSV files into a single data frame
Message-ID: <CAE8=ebPYxFxrL3veAsm8aAHM=h5rA0ORsVdw5ntnuBBCtEP+Eg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120503/2e26f665/attachment.pl>

From ggrothendieck at gmail.com  Thu May  3 20:54:58 2012
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 3 May 2012 14:54:58 -0400
Subject: [Rd] loading multiple CSV files into a single data frame
In-Reply-To: <CAE8=ebPYxFxrL3veAsm8aAHM=h5rA0ORsVdw5ntnuBBCtEP+Eg@mail.gmail.com>
References: <CAE8=ebPYxFxrL3veAsm8aAHM=h5rA0ORsVdw5ntnuBBCtEP+Eg@mail.gmail.com>
Message-ID: <CAP01uRk3nNQPuKe-waUyUnJmUiWA2OKqjemZVsJnmoc-8Tue+w@mail.gmail.com>

On Thu, May 3, 2012 at 2:07 PM, victor jimenez <betabandido at gmail.com> wrote:
> Sometimes I have hundreds of CSV files scattered in a directory tree,
> resulting from experiments' executions. For instance, giving an example
> from my field, I may want to collect the performance of a processor for
> several design parameters such as "cache size" (possible values: 2, 4, 8
> and 16) and "cache associativity" (possible values: direct-mapped, 4-way,
> fully-associative). The results of all these experiments will be stored in
> a directory tree like:
>
> results
> ?|-- direct-mapped
> ?| ? ? ? |-- 2 -- data.csv
> ?| ? ? ? |-- 4 -- data.csv
> ?| ? ? ? |-- 8 -- data.csv
> ?| ? ? ? |-- 16 -- data.csv
> ?|-- 4-way
> ?| ? ? ? |-- 2 -- data.csv
> ?| ? ? ? |-- 4 -- data.csv
> ...
> ?|-- fully-associative
> ?| ? ? ? |-- 2 -- data.csv
> ?| ? ? ? |-- 4 -- data.csv
> ...
>
> I am developing a package that would allow me to gather all those CSV into
> a single data frame. Currently, I just need to execute the following
> statement:
>
> dframe <- gather("results/@ASSOC@/@SIZE@/data.csv")
>
> and this command returns a data frame containing the columns ASSOC, SIZE
> and all the remaining columns inside the CSV files (in my case the
> processor performance), effectively loading all the CSV files into a single
> data frame. So, I would get something like:
>
> ASSOC, ? ? ? ? ?SIZE, PERF
> direct-mapped, ? ? ? 2, ? ? 1.4
> direct-mapped, ? ? ? 4, ? ? 1.6
> direct-mapped, ? ? ? 8, ? ? 1.7
> direct-mapped, ? ? 16, ? ? 1.7
> 4-way, ? ? ? ? ? ? ? ? ? 2, ? ? 1.4
> 4-way, ? ? ? ? ? ? ? ? ? 4, ? ? 1.5
> ...
>
> I would like to ask whether there is any similar functionality already
> implemented in R. If so, there is no need to reinvent the wheel :)
> If it is not implemented and the R community believes that this feature
> would be useful, I would be glad to contribute my code.
>

If your csv files all have the same columns and represent time series
then read.zoo in the zoo package can read multiple csv files in at
once using a single read.zoo command producing a single zoo object.

library(zoo)
?read.zoo
vignette("zoo-read")

Also see the other zoo vignettes and help files.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From tlumley at uw.edu  Thu May  3 22:41:09 2012
From: tlumley at uw.edu (Thomas Lumley)
Date: Fri, 4 May 2012 08:41:09 +1200
Subject: [Rd] The constant part of the log-likelihood in StructTS
In-Reply-To: <CAHz+bWYiMpbeQtcsrpcJDuvZyzV6C9T+xOdP8SYmHbhGjHdwCQ@mail.gmail.com>
References: <CAGW7bkyFDeRzfUR91x79VrChvCf5py9ErYbs58eJ0fCOQnZ9Mw@mail.gmail.com>
	<2F9EA67EF9AE1C48A147CB41BE2E15C31DF461@DOM-EB-MAIL2.win.ad.jhu.edu>
	<CAGW7bkxKdPQQ_xdVuhWCMFq0HVuaoZJe6h9ycgEcmUpKSTyuUg@mail.gmail.com>
	<2F9EA67EF9AE1C48A147CB41BE2E15C31DF8B1@DOM-EB-MAIL2.win.ad.jhu.edu>
	<CAHz+bWYiMpbeQtcsrpcJDuvZyzV6C9T+xOdP8SYmHbhGjHdwCQ@mail.gmail.com>
Message-ID: <CAJ55+dLJQzysfseZOCkZ_d63RgM6oDkmc82vB+ct5PhgiOAKYw@mail.gmail.com>

On Thu, May 3, 2012 at 3:36 AM, Mark Leeds <markleeds2 at gmail.com> wrote:
> Hi Ravi: As far as I know ( well , really read ) and Bert et al can say
> more , the AIC is not dependent on the models being nested as long as the
> sample sizes used are the same when comparing. In some cases, say comparing
> MA(2), AR(1), you have to be careful with sample size usage but there is no
> nesting requirement for AIC atleast, I'm pretty sure.

This is only partly true.  The expected value of the AIC will behave
correctly even if models are non-nested, but there is no general
guarantee that the standard deviation is small,  so AIC need not even
asymptotically lead to optimal model choice for prediction in
arbitrary non-nested models.

Having said that, 'nearly' nested models like these are probably ok.
I believe it's sufficient that all your models are nested in a common
model, with a bound on the degree of freedom difference, but my copy
of Claeskens & Hjort's book on model selection and model averaging is
currently with a student so I can't be definitive.


   -thomas

-- 
Thomas Lumley
Professor of Biostatistics
University of Auckland


From betabandido at gmail.com  Thu May  3 23:40:42 2012
From: betabandido at gmail.com (victor jimenez)
Date: Thu, 3 May 2012 23:40:42 +0200
Subject: [Rd] loading multiple CSV files into a single data frame
In-Reply-To: <CAP01uRk3nNQPuKe-waUyUnJmUiWA2OKqjemZVsJnmoc-8Tue+w@mail.gmail.com>
References: <CAE8=ebPYxFxrL3veAsm8aAHM=h5rA0ORsVdw5ntnuBBCtEP+Eg@mail.gmail.com>
	<CAP01uRk3nNQPuKe-waUyUnJmUiWA2OKqjemZVsJnmoc-8Tue+w@mail.gmail.com>
Message-ID: <CAE8=ebNSJBbYMq=d2yx4DdQqNLaexum=H_yk8Z1XzpT0Foya7A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120503/28be71b2/attachment.pl>

From oliver at first.in-berlin.de  Thu May  3 23:54:09 2012
From: oliver at first.in-berlin.de (oliver)
Date: Thu, 3 May 2012 23:54:09 +0200
Subject: [Rd] loading multiple CSV files into a single data frame
In-Reply-To: <CAE8=ebNSJBbYMq=d2yx4DdQqNLaexum=H_yk8Z1XzpT0Foya7A@mail.gmail.com>
References: <CAE8=ebPYxFxrL3veAsm8aAHM=h5rA0ORsVdw5ntnuBBCtEP+Eg@mail.gmail.com>
	<CAP01uRk3nNQPuKe-waUyUnJmUiWA2OKqjemZVsJnmoc-8Tue+w@mail.gmail.com>
	<CAE8=ebNSJBbYMq=d2yx4DdQqNLaexum=H_yk8Z1XzpT0Foya7A@mail.gmail.com>
Message-ID: <20120503215409.GA2752@siouxsie>

On Thu, May 03, 2012 at 11:40:42PM +0200, victor jimenez wrote:
> First of all, thank you for the answers. I did not know about zoo. However,
> it seems that none approach can do what I exactly want (please, correct me
> if I am wrong).
> 
> Probably, it was not clear in my original question. The CSV files only
> contain the performance values. The other two columns (ASSOC and SIZE) are
> obtained from the existing values in the directory tree. So, in my opinion,
> none of the proposed solutions would work, unless every single "data.csv"
> file contained all the three columns (ASSOC, SIZE and PERF).
[...]

Maybe things will be clearer if you would provide an example
with the tree and some example data, which you provide as a*.zip file.

As I undertand your question, you have a some variables' values
stored in the csv-files, and other values of your variables
are given as directory structure.

So you need to convert the structure of your directory
into values fo your dataframe.

You need to have a dataframe that contains all possible values that are of
interest to you.
Some of them are loaded via the csv-load and others are just picked
from the directory structure.

You just have to fill in the data from the csv into the dataframe,
and the values/variables that are implictly given via the directory structure,
you just set when importing.

Maybe just read in the csv-files and add the missing values.

So if the variable on the cahcing mechanism is
encode as part of the path to the file, e.g. "direct-mapped",
then just set the chace value to "direct-mapped".


Ciao,
   Oliver

P.S.: In my understandiung this would be rather r-users instead of r-devel,
      because I think r-devel seems to be more focussed on internals and
      package stuff, while your problem is rather a user problem
      (any R user needs some kind of "programming" to get things done).


From MEC at stowers.org  Fri May  4 00:09:03 2012
From: MEC at stowers.org (Cook, Malcolm)
Date: Thu, 3 May 2012 17:09:03 -0500
Subject: [Rd] loading multiple CSV files into a single data frame
In-Reply-To: <CAE8=ebNSJBbYMq=d2yx4DdQqNLaexum=H_yk8Z1XzpT0Foya7A@mail.gmail.com>
Message-ID: <CBC86935.20BFD%mec@stowers.org>

Victor,

I understand you as follows

	The first two columns of the desired combined dataframe are the last two
levels of the pathname to the csv file.

	The columns in all the data.csv files are the same, namely, there is only
one column, and it is named PERF.

If so, the following should work (on unix)

do.call(rbind,lapply(Sys.glob('results/*/*/data.csv'),function(path)
{within(read.csv(path),{ SIZE<-basename(dirname(path));
ASSOC<-basename(dirname(dirname(path)))})}))


On 5/3/12 4:40 PM, "victor jimenez" <betabandido at gmail.com> wrote:

>First of all, thank you for the answers. I did not know about zoo.
>However,
>it seems that none approach can do what I exactly want (please, correct me
>if I am wrong).
>
>Probably, it was not clear in my original question. The CSV files only
>contain the performance values. The other two columns (ASSOC and SIZE) are
>obtained from the existing values in the directory tree. So, in my
>opinion,
>none of the proposed solutions would work, unless every single "data.csv"
>file contained all the three columns (ASSOC, SIZE and PERF).
>
>In my case, my experimentation framework basically outputs a CSV with some
>values read from the processor's performance counters (PMCs). For each
>cache size and associativity I conduct an experiment, creating a CSV file,
>and placing that file into its own directory. I could modify the
>experimentation framework, so that it also outputs the cache size and
>associativity, but that may not be ideal in some circumstances and I also
>have a significant amount of old results and I want keep using them
>without
>manually fixing the CSV files.
>
>Has anyone else faced such a situation? Any good solutions?
>
>Thank you,
>Victor
>
>On Thu, May 3, 2012 at 8:54 PM, Gabor Grothendieck
><ggrothendieck at gmail.com>wrote:
>
>> On Thu, May 3, 2012 at 2:07 PM, victor jimenez <betabandido at gmail.com>
>> wrote:
>> > Sometimes I have hundreds of CSV files scattered in a directory tree,
>> > resulting from experiments' executions. For instance, giving an
>>example
>> > from my field, I may want to collect the performance of a processor
>>for
>> > several design parameters such as "cache size" (possible values: 2,
>>4, 8
>> > and 16) and "cache associativity" (possible values: direct-mapped,
>>4-way,
>> > fully-associative). The results of all these experiments will be
>>stored
>> in
>> > a directory tree like:
>> >
>> > results
>> >  |-- direct-mapped
>> >  |       |-- 2 -- data.csv
>> >  |       |-- 4 -- data.csv
>> >  |       |-- 8 -- data.csv
>> >  |       |-- 16 -- data.csv
>> >  |-- 4-way
>> >  |       |-- 2 -- data.csv
>> >  |       |-- 4 -- data.csv
>> > ...
>> >  |-- fully-associative
>> >  |       |-- 2 -- data.csv
>> >  |       |-- 4 -- data.csv
>> > ...
>> >
>> > I am developing a package that would allow me to gather all those CSV
>> into
>> > a single data frame. Currently, I just need to execute the following
>> > statement:
>> >
>> > dframe <- gather("results/@ASSOC@/@SIZE@/data.csv")
>> >
>> > and this command returns a data frame containing the columns ASSOC,
>>SIZE
>> > and all the remaining columns inside the CSV files (in my case the
>> > processor performance), effectively loading all the CSV files into a
>> single
>> > data frame. So, I would get something like:
>> >
>> > ASSOC,          SIZE, PERF
>> > direct-mapped,       2,     1.4
>> > direct-mapped,       4,     1.6
>> > direct-mapped,       8,     1.7
>> > direct-mapped,     16,     1.7
>> > 4-way,                   2,     1.4
>> > 4-way,                   4,     1.5
>> > ...
>> >
>> > I would like to ask whether there is any similar functionality already
>> > implemented in R. If so, there is no need to reinvent the wheel :)
>> > If it is not implemented and the R community believes that this
>>feature
>> > would be useful, I would be glad to contribute my code.
>> >
>>
>> If your csv files all have the same columns and represent time series
>> then read.zoo in the zoo package can read multiple csv files in at
>> once using a single read.zoo command producing a single zoo object.
>>
>> library(zoo)
>> ?read.zoo
>> vignette("zoo-read")
>>
>> Also see the other zoo vignettes and help files.
>>
>> --
>> Statistics & Software Consulting
>> GKX Group, GKX Associates Inc.
>> tel: 1-877-GKX-GROUP
>> email: ggrothendieck at gmail.com
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-devel at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel


From simon.urbanek at r-project.org  Fri May  4 00:09:36 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 3 May 2012 18:09:36 -0400
Subject: [Rd] loading multiple CSV files into a single data frame
In-Reply-To: <CAE8=ebNSJBbYMq=d2yx4DdQqNLaexum=H_yk8Z1XzpT0Foya7A@mail.gmail.com>
References: <CAE8=ebPYxFxrL3veAsm8aAHM=h5rA0ORsVdw5ntnuBBCtEP+Eg@mail.gmail.com>
	<CAP01uRk3nNQPuKe-waUyUnJmUiWA2OKqjemZVsJnmoc-8Tue+w@mail.gmail.com>
	<CAE8=ebNSJBbYMq=d2yx4DdQqNLaexum=H_yk8Z1XzpT0Foya7A@mail.gmail.com>
Message-ID: <FBED619B-6684-46F2-BED1-877FE35D6F3D@r-project.org>


On May 3, 2012, at 5:40 PM, victor jimenez wrote:

> First of all, thank you for the answers. I did not know about zoo. However,
> it seems that none approach can do what I exactly want (please, correct me
> if I am wrong).
> 
> Probably, it was not clear in my original question. The CSV files only
> contain the performance values. The other two columns (ASSOC and SIZE) are
> obtained from the existing values in the directory tree. So, in my opinion,
> none of the proposed solutions would work, unless every single "data.csv"
> file contained all the three columns (ASSOC, SIZE and PERF).
> 
> In my case, my experimentation framework basically outputs a CSV with some
> values read from the processor's performance counters (PMCs). For each
> cache size and associativity I conduct an experiment, creating a CSV file,
> and placing that file into its own directory. I could modify the
> experimentation framework, so that it also outputs the cache size and
> associativity, but that may not be ideal in some circumstances and I also
> have a significant amount of old results and I want keep using them without
> manually fixing the CSV files.
> 

You don't need to touch the CSV files, simply add values at load time - this is all easily doable in one line ;)

> do.call("rbind",lapply(Sys.glob("*/*/data.csv"),function(d) cbind(read.csv(d),as.data.frame(t(strsplit(d,"/")[[1]])))))
  A B V1 V2       V3
1 1 2  1  a data.csv
2 3 4  1  a data.csv
3 1 2  1  b data.csv
4 3 4  1  b data.csv
5 1 2  2  a data.csv
6 3 4  2  a data.csv


> Has anyone else faced such a situation? Any good solutions?
> 
> Thank you,
> Victor
> 
> On Thu, May 3, 2012 at 8:54 PM, Gabor Grothendieck
> <ggrothendieck at gmail.com>wrote:
> 
>> On Thu, May 3, 2012 at 2:07 PM, victor jimenez <betabandido at gmail.com>
>> wrote:
>>> Sometimes I have hundreds of CSV files scattered in a directory tree,
>>> resulting from experiments' executions. For instance, giving an example
>>> from my field, I may want to collect the performance of a processor for
>>> several design parameters such as "cache size" (possible values: 2, 4, 8
>>> and 16) and "cache associativity" (possible values: direct-mapped, 4-way,
>>> fully-associative). The results of all these experiments will be stored
>> in
>>> a directory tree like:
>>> 
>>> results
>>> |-- direct-mapped
>>> |       |-- 2 -- data.csv
>>> |       |-- 4 -- data.csv
>>> |       |-- 8 -- data.csv
>>> |       |-- 16 -- data.csv
>>> |-- 4-way
>>> |       |-- 2 -- data.csv
>>> |       |-- 4 -- data.csv
>>> ...
>>> |-- fully-associative
>>> |       |-- 2 -- data.csv
>>> |       |-- 4 -- data.csv
>>> ...
>>> 
>>> I am developing a package that would allow me to gather all those CSV
>> into
>>> a single data frame. Currently, I just need to execute the following
>>> statement:
>>> 
>>> dframe <- gather("results/@ASSOC@/@SIZE@/data.csv")
>>> 
>>> and this command returns a data frame containing the columns ASSOC, SIZE
>>> and all the remaining columns inside the CSV files (in my case the
>>> processor performance), effectively loading all the CSV files into a
>> single
>>> data frame. So, I would get something like:
>>> 
>>> ASSOC,          SIZE, PERF
>>> direct-mapped,       2,     1.4
>>> direct-mapped,       4,     1.6
>>> direct-mapped,       8,     1.7
>>> direct-mapped,     16,     1.7
>>> 4-way,                   2,     1.4
>>> 4-way,                   4,     1.5
>>> ...
>>> 
>>> I would like to ask whether there is any similar functionality already
>>> implemented in R. If so, there is no need to reinvent the wheel :)
>>> If it is not implemented and the R community believes that this feature
>>> would be useful, I would be glad to contribute my code.
>>> 
>> 
>> If your csv files all have the same columns and represent time series
>> then read.zoo in the zoo package can read multiple csv files in at
>> once using a single read.zoo command producing a single zoo object.
>> 
>> library(zoo)
>> ?read.zoo
>> vignette("zoo-read")
>> 
>> Also see the other zoo vignettes and help files.
>> 
>> --
>> Statistics & Software Consulting
>> GKX Group, GKX Associates Inc.
>> tel: 1-877-GKX-GROUP
>> email: ggrothendieck at gmail.com
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From list at econinfo.de  Fri May  4 00:07:02 2012
From: list at econinfo.de (Owe Jessen)
Date: Fri, 04 May 2012 00:07:02 +0200
Subject: [Rd] Setting up a windows system for rcpp
Message-ID: <4FA30186.9070406@econinfo.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120504/a655cb9f/attachment.pl>

From edd at debian.org  Fri May  4 00:38:58 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 3 May 2012 17:38:58 -0500
Subject: [Rd] Setting up a windows system for rcpp
In-Reply-To: <4FA30186.9070406@econinfo.de>
References: <4FA30186.9070406@econinfo.de>
Message-ID: <20387.2306.179116.670364@max.nulle.part>


On 4 May 2012 at 00:07, Owe Jessen wrote:
| I am running into a wall getting my system to work with rcpp and inline. 
| Following Dirk's advice on stackoverflow, I hope someone is able to help 
| me.

There is a dedicated mailing list for Rcpp:  rcpp-devel.   

Please let us try to continue the discussion over there. Subscription is
required as on some other R lists, so please subscribe before posting.


In general, you need Rtools correctly set up. If and when you compile a basic
R package (also containing C or C++ files) from sources, you should be fine.

A decent 60+ page tutorial is available at:

  http://howtomakeanrpackage.pbworks.com/f/How_To_Make_An_R_Package-v1.14-01-11-10.pdf
 
Once you have that sorted out, working with Rcpp and inline should "just
work" as it does on other operating systems.

| My steps were to install MinGW 32 bit first, then installing Rtools, I 
| disabled MinGW's entry in the PATH.

What do you mean by "MinGW's path entry disabled" ?  You need mingw.
 
| I am trying to get the following code to work:
| 
| library(Rcpp)
| library(inline)
| 
| body <- '
| NumericVector xx(x);
| return wrap( std::accumulate( xx.begin(), xx.end(), 0.0));'
| 
| add <- cxxfunction(signature(x = "numeric"), body, plugin = "Rcpp", 
| verbose=T)
| 
| x <- 1
| y <- 2
| res <- add(c(x, y))
| res
| 
| 
| I get the following error messages:
| 
|   >>  setting environment variables:
| PKG_LIBS =  C:/Users/Owe/Documents/R/win-library/2.15/Rcpp/lib/x64/libRcpp.a
| 
|   >>  LinkingTo : Rcpp
| CLINK_CPPFLAGS =  -I"C:/Users/Owe/Documents/R/win-library/2.15/Rcpp/include"
| 
|   >>  Program source :
| 
|     1 :
|     2 : // includes from the plugin
|     3 :
|     4 : #include<Rcpp.h>
|     5 :
|     6 :
|     7 : #ifndef BEGIN_RCPP
|     8 : #define BEGIN_RCPP
|     9 : #endif
|    10 :
|    11 : #ifndef END_RCPP
|    12 : #define END_RCPP
|    13 : #endif
|    14 :
|    15 : using namespace Rcpp;
|    16 :
|    17 :
|    18 : // user includes
|    19 :
|    20 :
|    21 : // declarations
|    22 : extern "C" {
|    23 : SEXP file10bc7da0783e( SEXP x) ;
|    24 : }
|    25 :
|    26 : // definition
|    27 :
|    28 : SEXP file10bc7da0783e( SEXP x ){
|    29 : BEGIN_RCPP
|    30 :
|    31 : NumericVector xx(x);
|    32 : return wrap( std::accumulate( xx.begin(), xx.end(), 0.0));
|    33 : END_RCPP
|    34 : }
|    35 :
|    36 :
| Compilation argument:
|   C:/R_curr/R_2_15_0/bin/x64/R CMD SHLIB file10bc7da0783e.cpp 2>  file10bc7da0783e.cpp.err.txt
| g++ -m64 -I"C:/R_curr/R_2_15_0/include" -DNDEBUG    -I"C:/Users/Owe/Documents/R/win-library/2.15/Rcpp/include" -I"d:/RCompile/CRANpkg/extralibs64/local/include"     -O2 -Wall  -mtune=core2 -c file10bc7da0783e.cpp -o file10bc7da0783e.o

Looks like compilation worked.

| g++ -m64 -shared -s -static-libgcc -o file10bc7da0783e.dll tmp.def file10bc7da0783e.o C:/Users/Owe/Documents/R/win-library/2.15/Rcpp/lib/x64/libRcpp.a -Ld:/RCompile/CRANpkg/extralibs64/local/lib/x64 -Ld:/RCompile/CRANpkg/extralibs64/local/lib -LC:/R_curr/R_2_15_0/bin/x64 -lR
| cygwin warning:
|    MS-DOS style path detected: C:/R_curr/R_2_15_0/etc/x64/Makeconf
|    Preferred POSIX equivalent is: /cygdrive/c/R_curr/R_2_15_0/etc/x64/Makeconf
|    CYGWIN environment variable option "nodosfilewarning" turns off this warning.
|    Consult the user's guide for more details about POSIX paths:
|      http://cygwin.com/cygwin-ug-net/using.html#using-pathnames

That is just noise and can be ignored.

The rest is bad:

| Cannot export Rcpp::Vector<14>::update(): symbol not defined
| Cannot export Rcpp::Vector<14>::~Vector(): symbol not defined
| Cannot export Rcpp::Vector<14>::~Vector(): symbol not defined
| Cannot export typeinfo for Rcpp::VectorBase<14, true, Rcpp::Vector<14>  >: symbol not defined
| Cannot export typeinfo for Rcpp::Vector<14>: symbol not defined
| Cannot export typeinfo for Rcpp::traits::expands_to_logical__impl<14>: symbol not defined
| Cannot export typeinfo for Rcpp::RObject: symbol not defined
| Cannot export typeinfo for Rcpp::internal::eval_methods<14>: symbol not defined
| Cannot export typeinfo for std::exception: symbol not defined
| Cannot export typeinfo name for Rcpp::VectorBase<14, true, Rcpp::Vector<14>  >: symbol not defined
| Cannot export typeinfo name for Rcpp::Vector<14>: symbol not defined
| Cannot export typeinfo name for Rcpp::traits::expands_to_logical__impl<14>: symbol not defined
| Cannot export typeinfo name for Rcpp::RObject: symbol not defined
| Cannot export typeinfo name for Rcpp::internal::eval_methods<14>: symbol not defined
| Cannot export typeinfo name for std::exception: symbol not defined
| Cannot export vtable for Rcpp::Vector<14>: symbol not defined
| Cannot export _file10bc7da0783e: symbol not defined
| file10bc7da0783e.o:file10bc7da0783e.cpp:(.text+0x1a4): undefined reference to `SEXPREC* Rcpp::internal::r_true_cast<14>(SEXPREC*)'
| file10bc7da0783e.o:file10bc7da0783e.cpp:(.text+0x1c9): undefined reference to `Rcpp::RObject::setSEXP(SEXPREC*)'
| file10bc7da0783e.o:file10bc7da0783e.cpp:(.text+0x244): undefined reference to `double* Rcpp::internal::r_vector_start<14, double>(SEXPREC*)'
| file10bc7da0783e.o:file10bc7da0783e.cpp:(.text+0x27c): undefined reference to `Rcpp::RObject::~RObject()'
| file10bc7da0783e.o:file10bc7da0783e.cpp:(.text+0x389): undefined reference to `Rcpp::RObject::~RObject()'
| file10bc7da0783e.o:file10bc7da0783e.cpp:(.text+0x420): undefined reference to `forward_exception_to_r(std::exception const&)'
| file10bc7da0783e.o:file10bc7da0783e.cpp:(.text$_ZN4Rcpp6VectorILi14EED1Ev[Rcpp::Vector<14>::~Vector()]+0x13): undefined reference to `Rcpp::RObject::~RObject()'
| file10bc7da0783e.o:file10bc7da0783e.cpp:(.text$_ZN4Rcpp6VectorILi14EE6updateEv[Rcpp::Vector<14>::update()]+0xd): undefined reference to `double* Rcpp::internal::r_vector_start<14, double>(SEXPREC*)'
| file10bc7da0783e.o:file10bc7da0783e.cpp:(.text$_ZN4Rcpp6VectorILi14EED0Ev[Rcpp::Vector<14>::~Vector()]+0x13): undefined reference to `Rcpp::RObject::~RObject()'
| collect2: ld returned 1 exit status

Linking failed. Something is wrong with your static Rcpp library. I cannot
tell why this fails.

You could check your package by submitting it to http://win-builder.r-project.org.   
If it builds there, your local setup is wrong.  If it fails there, your
package is wrong.
 
Cheers, Dirk

| ERROR(s) during compilation: source code errors or compiler configuration errors!
| 
| Program source:
|    1:
|    2: // includes from the plugin
|    3:
|    4: #include<Rcpp.h>
|    5:
|    6:
|    7: #ifndef BEGIN_RCPP
|    8: #define BEGIN_RCPP
|    9: #endif
|   10:
|   11: #ifndef END_RCPP
|   12: #define END_RCPP
|   13: #endif
|   14:
|   15: using namespace Rcpp;
|   16:
|   17:
|   18: // user includes
|   19:
|   20:
|   21: // declarations
|   22: extern "C" {
|   23: SEXP file10bc7da0783e( SEXP x) ;
|   24: }
|   25:
|   26: // definition
|   27:
|   28: SEXP file10bc7da0783e( SEXP x ){
|   29: BEGIN_RCPP
|   30:
|   31: NumericVector xx(x);
|   32: return wrap( std::accumulate( xx.begin(), xx.end(), 0.0));
|   33: END_RCPP
|   34: }
|   35:
|   36:
| 
| sessionInfo() provides the following data:
| 
| 
| >  sessionInfo()
| R version 2.15.0 (2012-03-30)
| Platform: x86_64-pc-mingw32/x64 (64-bit)
| 
| locale:
| [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252    LC_MONETARY=German_Germany.1252
| [4] LC_NUMERIC=C                    LC_TIME=German_Germany.1252
| 
| attached base packages:
| [1] stats     graphics  grDevices utils     datasets  methods   base
| 
| other attached packages:
| [1] RcppExamples_0.1.3 RcppClassic_0.9.1  inline_0.3.8       Rcpp_0.9.10
| 
| loaded via a namespace (and not attached):
| [1] tools_2.15.0
| 
| 
| 
| Thanks in advance
| 
| 
| -- 
| Owe Jessen
| http://privat.owejessen.de
| 
| 
| 
| 	[[alternative HTML version deleted]]
| 
| ______________________________________________
| R-devel at r-project.org mailing list
| https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
R/Finance 2012 Conference on May 11 and 12, 2012 at UIC in Chicago, IL
See agenda, registration details and more at http://www.RinFinance.com


From rvaradhan at jhmi.edu  Fri May  4 03:50:46 2012
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Fri, 4 May 2012 01:50:46 +0000
Subject: [Rd] The constant part of the log-likelihood in StructTS
In-Reply-To: <CAJ55+dLJQzysfseZOCkZ_d63RgM6oDkmc82vB+ct5PhgiOAKYw@mail.gmail.com>
References: <CAGW7bkyFDeRzfUR91x79VrChvCf5py9ErYbs58eJ0fCOQnZ9Mw@mail.gmail.com>
	<2F9EA67EF9AE1C48A147CB41BE2E15C31DF461@DOM-EB-MAIL2.win.ad.jhu.edu>
	<CAGW7bkxKdPQQ_xdVuhWCMFq0HVuaoZJe6h9ycgEcmUpKSTyuUg@mail.gmail.com>
	<2F9EA67EF9AE1C48A147CB41BE2E15C31DF8B1@DOM-EB-MAIL2.win.ad.jhu.edu>
	<CAHz+bWYiMpbeQtcsrpcJDuvZyzV6C9T+xOdP8SYmHbhGjHdwCQ@mail.gmail.com>,
	<CAJ55+dLJQzysfseZOCkZ_d63RgM6oDkmc82vB+ct5PhgiOAKYw@mail.gmail.com>
Message-ID: <2F9EA67EF9AE1C48A147CB41BE2E15C31DFEEB@DOM-EB-MAIL2.win.ad.jhu.edu>

Thanks, Tom, for the reply as well as to the reference to Claeskens & Hjort.

Ravi
________________________________________
From: Thomas Lumley [tlumley at uw.edu]
Sent: Thursday, May 03, 2012 4:41 PM
To: Mark Leeds
Cc: Ravi Varadhan; r-devel at r-project.org
Subject: Re: [Rd] The constant part of the log-likelihood in StructTS

On Thu, May 3, 2012 at 3:36 AM, Mark Leeds <markleeds2 at gmail.com> wrote:
> Hi Ravi: As far as I know ( well , really read ) and Bert et al can say
> more , the AIC is not dependent on the models being nested as long as the
> sample sizes used are the same when comparing. In some cases, say comparing
> MA(2), AR(1), you have to be careful with sample size usage but there is no
> nesting requirement for AIC atleast, I'm pretty sure.

This is only partly true.  The expected value of the AIC will behave
correctly even if models are non-nested, but there is no general
guarantee that the standard deviation is small,  so AIC need not even
asymptotically lead to optimal model choice for prediction in
arbitrary non-nested models.

Having said that, 'nearly' nested models like these are probably ok.
I believe it's sufficient that all your models are nested in a common
model, with a bound on the degree of freedom difference, but my copy
of Claeskens & Hjort's book on model selection and model averaging is
currently with a student so I can't be definitive.


   -thomas

--
Thomas Lumley
Professor of Biostatistics
University of Auckland

From jeff.a.ryan at gmail.com  Fri May  4 04:20:50 2012
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Thu, 3 May 2012 21:20:50 -0500
Subject: [Rd] fast version of split.data.frame or conversion from
	data.frame to list of its rows
In-Reply-To: <CA+VDHFUE9biU0596aqA50GtD6_FCmqKkE-qvzTOCsj_dpYPF3w@mail.gmail.com>
References: <CA+VDHFUj=mkk4gUySHZejq1VipZmcGeK0+1GAg25sEsGwQ=bhQ@mail.gmail.com>
	<4F9FDB3A.50604@stats>
	<CA+VDHFXz2n2vCbiYTCy764ct8HTRFrpC-G0oKtd4YqtG6mOTEw@mail.gmail.com>
	<DA49C0C2-C3A5-455D-A278-6CF9E971797C@r-project.org>
	<CA+VDHFUE9biU0596aqA50GtD6_FCmqKkE-qvzTOCsj_dpYPF3w@mail.gmail.com>
Message-ID: <E292C045-F954-430F-B438-2E85DCF13D61@gmail.com>

A bit late and possibly tangential. 

The mmap package has something called struct() which is really a row-wise array of heterogenous columns.

As Simon and others have pointed out, R has no way to handle this natively, but mmap does provide a very measurable performance gain by orienting rows together in memory (mapped memory to be specific).  Since it is all "outside of R" so to speak, it (mmap) even supports many non-native types, from bit vectors to 64 bit ints with conversion caveats applicable. 

example(struct) shows some performance gains with this approach. 

There are even some crude methods to convert as is data.frames to mmap struct object directly (hint: as.mmap)

Again, likely not enough to shoehorn into your effort, but worth a look to see if it might be useful, and/or see the C design underlying it. 

Best,
Jeff

Jeffrey Ryan    |    Founder    |    jeffrey.ryan at lemnica.com

www.lemnica.com

On May 1, 2012, at 1:44 PM, Antonio Piccolboni <antonio at piccolboni.info> wrote:

> On Tue, May 1, 2012 at 11:29 AM, Simon Urbanek
> <simon.urbanek at r-project.org>wrote:
> 
>> 
>> On May 1, 2012, at 1:26 PM, Antonio Piccolboni <antonio at piccolboni.info>
>> wrote:
>> 
>>> It seems like people need to hear more context, happy to provide it. I am
>>> implementing a serialization format (typedbytes, HADOOP-1722 if people
>> want
>>> the gory details) to make R and Hadoop interoperate better (RHadoop
>>> project, package rmr). It is a row first format and it's already
>>> implemented as a C extension for R for lists and atomic vectors, where
>> each
>>> element  of a vector is a row. I need to extend it to accept data frames
>>> and I was wondering if I can use the existing C code by converting a data
>>> frame to a list of its rows. It sounds like the answer is that it is not
>> a
>>> good idea,
>> 
>> Just think about it -- data frames are lists of *columns* because the type
>> of each column is fixed. Treating them row-wise is extremely inefficient,
>> because you can't use any vector type to represent such thing (other than a
>> generic vector containing vectors of length 1).
>> 
> 
> Thanks, let's say this together with the experiments and other converging
> opinions lays the question to rest.
> 
> 
>>> that's helpful too in a way because it restricts the options. I
>>> thought I may be missing a simple primitive, like a t() for data frames
>>> (that doesn't coerce to matrix).
>> 
>> See above - I think you are misunderstanding data frames - t() makes no
>> sense for data frames.
>> 
> 
> I think you are misunderstanding my use of t(). Thanks
> 
> 
> Antonio
> 
> 
>> 
>> Cheers,
>> Simon
>> 
>> 
>> 
>>> On Tue, May 1, 2012 at 5:46 AM, Prof Brian Ripley <ripley at stats.ox.ac.uk
>>> wrote:
>>> 
>>>> On 01/05/2012 00:28, Antonio Piccolboni wrote:
>>>> 
>>>>> Hi,
>>>>> I was wondering if there is anything more efficient than split to do
>> the
>>>>> kind of conversion in the subject. If I create a data frame as in
>>>>> 
>>>>> system.time({fd =  data.frame(x=1:2000, y = rnorm(2000), id =
>> paste("x",
>>>>> 1:2000, sep =""))})
>>>>> user  system elapsed
>>>>> 0.004   0.000   0.004
>>>>> 
>>>>> and then I try to split it
>>>>> 
>>>>> system.time(split(fd, 1:nrow(fd)))
>>>>>> 
>>>>> user  system elapsed
>>>>> 0.333   0.031   0.415
>>>>> 
>>>>> 
>>>>> You will be quick to notice the roughly two orders of magnitude
>> difference
>>>>> in time between creation and conversion. Granted, it's not written
>>>>> anywhere
>>>>> 
>>>> 
>>>> Unsurprising when you create three orders of magnitude more data frames,
>>>> is it?  That's a list of 2000 data frames.  Try
>>>> 
>>>> system.time(for(i in 1:2000) data.frame(x = i, y = rnorm(1), id =
>>>> paste0("x", i)))
>>>> 
>>>> 
>>>> 
>>>> that they should be similar but the latter seems interpreter-slow to me
>>>>> (split is implemented with a lapply in the data frame case) There is
>> also
>>>>> a
>>>>> memory issue when I hit about 20000 elements (allocating 3GB when
>>>>> interrupted). So before I resort to Rcpp, despite the electrifying
>> feeling
>>>>> of approaching the bare metal and for the sake of getting things done,
>> I
>>>>> thought I would ask the experts. Thanks
>>>>> 
>>>> 
>>>> You need to re-think your data structures: 1-row data frames are not
>>>> sensible.
>>>> 
>>>> 
>>>> 
>>>>> 
>>>>> Antonio
>>>>> 
>>>>>     [[alternative HTML version deleted]]
>>>>> 
>>>>> 
>>>>> ______________________________**________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/**listinfo/r-devel<
>> https://stat.ethz.ch/mailman/listinfo/r-devel>
>>>>> 
>>>> 
>>>> 
>>>> --
>>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~**ripley/<
>> http://www.stats.ox.ac.uk/~ripley/>
>>>> University of Oxford,             Tel:  +44 1865 272861 (self)
>>>> 1 South Parks Road,                     +44 1865 272866 (PA)
>>>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>>> 
>>> 
>>>     [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>> 
>> 
>> 
> 
>   [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From rflight79 at gmail.com  Fri May  4 18:09:02 2012
From: rflight79 at gmail.com (Robert M. Flight)
Date: Fri, 4 May 2012 12:09:02 -0400
Subject: [Rd] add sessionInfo() option to "save"
Message-ID: <CAJLyBTUXmqrC8Adu4gb_aFbNaMCWfPYnJAZfby2YaprXxaXoLQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120504/40877b8a/attachment.pl>

From pauljohn32 at gmail.com  Fri May  4 18:25:58 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Fri, 4 May 2012 11:25:58 -0500
Subject: [Rd] Proposal: model.data
In-Reply-To: <1336065561.29163.42.camel@brian-rcg>
References: <CAErODj8fUQW85O6hMzU40ACH3Nvzk7fBa2OnV=mx_MnNwqDC5A@mail.gmail.com>
	<1336063009.29163.39.camel@brian-rcg>
	<CAErODj8DhfYfn7y0kwWcUfKWCRVc-MZbEBTAuW_mEfQhnwfLSg@mail.gmail.com>
	<1336065561.29163.42.camel@brian-rcg>
Message-ID: <CAErODj8EH_Ht9LD7_UWtRsSHgGsaHhn3fZ2zOu4wnYsTk8eQ1Q@mail.gmail.com>

On Thu, May 3, 2012 at 12:19 PM, Brian G. Peterson <brian at braverock.com> wrote:
> On Thu, 2012-05-03 at 12:09 -0500, Paul Johnson wrote:
>> Greetings:
>>
>> On Thu, May 3, 2012 at 11:36 AM, Brian G. Peterson <brian at braverock.com> wrote:
>> > On Thu, 2012-05-03 at 10:51 -0500, Paul Johnson wrote:
>> >> If somebody in R Core would like this and think about putting it, or
>> >> something like it, into the base, then many chores involving predicted
>> >> values would become much easier.
>> >>
>> > Why does this need to be in base? ?Implement it in a package.
>> >>

So, nobody agrees with me that R base should have model.data?  Too
bad!  You could save us a lot of effort.  I've found different efforts
to get the same work done in termplot and all of the implementations
of predict. And just about every regression related package has its
own approach.

If there were one good way that would always work, just think how
convenient it would be for all those function & package writers.  Oh,
well. I'm not saying that my model.data is perfect, just that I wish
there were a perfect one :)

Yesterday, I realized that predict.nls probably has to deal with this
problem so I studied that and have yet another version of model.data
to propose to you.  I'm using this in my regression-support package
rockchalk, so you don't need to give me Brian Peterson's advice to
"put it in a package".

The idea here is to take variables from a fitted model's data if it
can find them, and then grab variables from the parent environment IF
they have the correct length.  This means we ignore variables like d
in poly(x, d) because the variable d is not of the same length as the
variables in the model.

##' Creates a "raw" (UNTRANSFORMED) data frame equivalent
##' to the input data that would be required to fit the given model.
##'
##' Unlike model.frame and model.matrix, this does not return transformed
##' variables.
##'
##' @param model A fitted regression model in which the data argument
##' is specified. This function will fail if the model was not fit
##' with the data option.
##' @return A data frame
##' @export
##' @author Paul E. Johnson <pauljohn@@ku.edu>
##' @example inst/examples/model.data-ex.R
model.data <- function(model){
    #from nls, returns -1 for missing variables
    lenVar <- function(var, data) tryCatch(length(eval(as.name(var),
                         data, env)), error = function(e) -1)
    fmla <- formula(model)
    varNames <- all.vars(fmla) ## all variable names
    ## varNames includes d in poly(x,d), possibly other "constants"
    ## varNamesRHS <- all.vars(formula(delete.response(terms(model))))
    ## previous same as nls way?
    fmla2 <- fmla
    fmla2[[2L]] <- 0
    varNamesRHS <- all.vars(fmla2)
    varNamesLHS <- setdiff(varNames, varNamesRHS)
    env <- environment(fmla)
    if (is.null(env))
        env <- parent.frame()

    dataOrig <-  eval(model$call$data, environment(formula(model)))
    rndataOrig <- row.names(dataOrig)
    n <- sapply(varNames, lenVar, data=dataOrig)
    targetLength <- length(eval(as.name(varNamesLHS[1]), dataOrig, env))
    varNames <- varNames[ n == targetLength ]
    ldata <- lapply(varNames, function(x) eval(as.name(x), dataOrig, env))
    names(ldata) <- varNames
    data <- data.frame(ldata[varNames])
    if (!is.null(rndataOrig)) row.names(data) <- rndataOrig
    ## remove rows listed in model's na.action
    ## TODO: question: what else besides OMIT might be called for?
    if ( !is.null(model$na.action)){
        data <- data[ -as.vector(model$na.action),  ]
    }
    ## keep varNamesRHS that exist in datOrig
    attr(data, "varNamesRHS") <- setdiff(colnames(data), varNamesLHS)
    invisible(data)
}

And some example output:
> ## check if model.data works when there is no data argument
> set.seed(12345)
> x1 <- rpois(100, l=6)
> x2 <- rnorm(100, m=50, s=10)
> x3 <- rnorm(100)
> y <- rnorm(100)
> m0 <- lm(y ~ x1 + x2 + x3)
> m0.data <- model.data(m0)
> x1[4:5] <- NA
> m0 <- lm(y ~ x1 + x2 + x3)
> m0.data <- model.data(m0)
> head(m0.data)
           y x1       x2         x3
1 -0.8086741  7 44.59614 -1.6193283
2  1.0011198  9 69.47693  0.5483979
3  0.4560525  8 50.53590  0.1952822
6  0.6417692  4 52.77954 -0.2509466
7 -0.4150210  5 56.91171  1.6993467
8 -0.4595757  6 58.23795 -0.3442988
> x1 <- rpois(100, l=6)
> x2 <- rnorm(100, m=50, s=10)
> x3 <- rnorm(100)
> xcat1 <- gl(2,50, labels=c("M","F"))
> xcat2 <- cut(rnorm(100), breaks=c(-Inf, 0, 0.4, 0.9, 1, Inf), labels=c("R", "M", "D", "P", "G"))
> dat <- data.frame(x1, x2, x3, xcat1, xcat2)
> rm(x1, x2, x3, xcat1, xcat2)
> xcat1n <- with(dat, contrasts(xcat1)[xcat1, ,drop=FALSE])
> xcat2n <- with(dat, contrasts(xcat2)[xcat2, ])
> STDE <- 20
> dat$y <- 0.03 + 0.8*dat$x1 + 0.1*dat$x2 + 0.7*dat$x3 + xcat1n %*% c(2) + xcat2n %*% c(0.1,-2,0.3, 0.1) + STDE*rnorm(100)
> rownames(dat$y) <- NULL
> m1 <- lm(y ~ poly(x1, 2), data=dat)
> m1.data <- model.data(m1)
> head(m1.data)
           y x1
1  56.336279  7
2  47.823205  5
3   9.296108  6
4  16.213508  5
5 -16.922331  3
6  10.639724  7
> attr(m1.data, "varNamesRHS")
[1] "x1"
> d <- 2
> m2 <- lm(y ~ poly(x1, d), data=dat)
> m2.data <- model.data(m2)
> head(m2.data)
           y x1
1  56.336279  7
2  47.823205  5
3   9.296108  6
4  16.213508  5
5 -16.922331  3
6  10.639724  7
> attr(m2.data, "varNamesRHS")
[1] "x1"
> m3 <- lm(y ~ log(10 + x1) + poly(x1, d) + sin(x2), data=dat)
> m3.data <- model.data(m3)
> head(m3.data)
           y x1       x2
1  56.336279  7 56.27965
2  47.823205  5 50.02144
3   9.296108  6 52.84378
4  16.213508  5 39.98221
5 -16.922331  3 43.82778
6  10.639724  7 58.28194
> attr(m3.data, "varNamesRHS")
[1] "x1" "x2"
> m4 <- lm(log(50+y) ~ log(d+10+x1) + poly(x1, 2), data=dat)
> m4.data <- model.data(m4)
> head(m4.data)
           y x1
1  56.336279  7
2  47.823205  5
3   9.296108  6
4  16.213508  5
5 -16.922331  3
6  10.639724  7
> attr(m4.data, "varNamesRHS")
[1] "x1"
> m4 <- lm(y ~ x1*x1, data=dat)
> m4.data <- model.data(m4)
> head(m4.data)
           y x1
1  56.336279  7
2  47.823205  5
3   9.296108  6
4  16.213508  5
5 -16.922331  3
6  10.639724  7
> attr(m4.data, "varNamesRHS")
[1] "x1"
> m4 <- lm(y ~ x1 + I(x1^2), data=dat)
> m4.data <- model.data(m4)
> head(m4.data)
           y x1
1  56.336279  7
2  47.823205  5
3   9.296108  6
4  16.213508  5
5 -16.922331  3
6  10.639724  7
> attr(m4.data, "varNamesRHS")
[1] "x1"
> dat$x1[sample(100, 5)] <- NA
> dat$y[sample(100, 5)] <- NA
> dat$x2[sample(100, 5)] <- NA
> dat$x3[sample(100,10)] <- NA
> m1 <- lm(y ~ log(10 + x1), data=dat)
> m1.data <- model.data(m1)
> head(m1.data)
           y x1
1  56.336279  7
2  47.823205  5
3   9.296108  6
4  16.213508  5
5 -16.922331  3
6  10.639724  7
> summarize(m1.data)
$numerics
         x1        y
0%    1.000 -31.9800
25%   5.000   0.9636
50%   6.000  13.8400
75%   7.000  27.5300
100% 12.000  71.1100
mean  5.933  14.8400
sd    2.336  20.4300
var   5.456 417.3000
NA's  0.000   0.0000
N    90.000  90.0000

$factors
NULL

> attr(m1.data, "varNamesRHS")
[1] "x1"
> m2 <- lm(y ~ log(x1 + 10), data=dat)
> m1.data <- model.data(m1)
> head(m1.data)
           y x1
1  56.336279  7
2  47.823205  5
3   9.296108  6
4  16.213508  5
5 -16.922331  3
6  10.639724  7
> summarize(m1.data)
$numerics
         x1        y
0%    1.000 -31.9800
25%   5.000   0.9636
50%   6.000  13.8400
75%   7.000  27.5300
100% 12.000  71.1100
mean  5.933  14.8400
sd    2.336  20.4300
var   5.456 417.3000
NA's  0.000   0.0000
N    90.000  90.0000

$factors
NULL

> attr(m1.data, "varNamesRHS")
[1] "x1"
> d <- 2
> m3 <- lm(log(50+y) ~ log(d+10+x1) + x2 + sin(x3), data=dat)
> m3.data <- model.data(m3)
> head(m3.data)
           y x1       x2         x3
2  47.823205  5 50.02144 -2.4669386
3   9.296108  6 52.84378  0.4847158
4  16.213508  5 39.98221 -0.9379723
5 -16.922331  3 43.82778  3.3307333
7  26.084587  3 49.15181  0.2204558
8   4.392061  8 45.65280  0.8762108
> summarize(m3.data)
$numerics
         x1     x2       x3        y
0%    1.000 27.630 -2.55600 -31.9800
25%   4.000 42.370 -0.52690   0.7905
50%   6.000 49.150  0.04162  11.5800
75%   7.000 54.390  0.71310  26.8900
100% 12.000 72.390  3.33100  71.1100
mean  5.883 48.800  0.02186  13.2300
sd    2.362  8.847  1.08900  20.0400
var   5.578 78.270  1.18700 401.8000
NA's  0.000  0.000  0.00000   0.0000
N    77.000 77.000 77.00000  77.0000

$factors
NULL

> attr(m3.data, "varNamesRHS")
[1] "x1" "x2" "x3"
> m4 <- lm(y ~ x1^3 + log(x2), data=dat)
> m4.data <- model.data(m4)
> summarize(m4.data)
$numerics
         x1     x2        y
0%    1.000 27.630 -31.9800
25%   4.000 42.630   0.8032
50%   6.000 49.710  12.2500
75%   7.000 54.910  27.2300
100% 12.000 72.390  71.1100
mean  5.918 49.220  14.0800
sd    2.372  8.808  20.0000
var   5.624 77.590 399.9000
NA's  0.000  0.000   0.0000
N    85.000 85.000  85.0000

$factors
NULL

> attr(m4.data, "varNamesRHS")
[1] "x1" "x2"
> m5 <- lm(y ~ x1 + I(x1^2) + cos(x2), data=dat)
> m5.data <- model.data(m5)
> head(m5.data)
           y x1       x2
1  56.336279  7 56.27965
2  47.823205  5 50.02144
3   9.296108  6 52.84378
4  16.213508  5 39.98221
5 -16.922331  3 43.82778
7  26.084587  3 49.15181
> summarize(m5.data)
$numerics
         x1     x2        y
0%    1.000 27.630 -31.9800
25%   4.000 42.630   0.8032
50%   6.000 49.710  12.2500
75%   7.000 54.910  27.2300
100% 12.000 72.390  71.1100
mean  5.918 49.220  14.0800
sd    2.372  8.808  20.0000
var   5.624 77.590 399.9000
NA's  0.000  0.000   0.0000
N    85.000 85.000  85.0000

$factors
NULL

> attr(m5.data, "varNamesRHS")
[1] "x1" "x2"
> x10 <- rnorm(100)
> x11 <- rnorm(100)
> m6 <- lm(y ~ x1 + I(x1^2) + cos(x2) + log(10 + x10) + sin(x11) + x10*x11, data=dat)
> m6.data <- model.data(m6)
> head(m6.data)
           y x1       x2        x10         x11
1  56.336279  7 56.27965 -0.4562360 -0.27005578
2  47.823205  5 50.02144 -1.4031737 -1.11355194
3   9.296108  6 52.84378 -0.2816067 -0.08319405
4  16.213508  5 39.98221  0.3353308  0.17284191
5 -16.922331  3 43.82778 -0.5184262  0.61754378
7  26.084587  3 49.15181  0.9037821  0.02170007
> dim(m6.data)
[1] 85  5
> summarize(m5.data)
$numerics
         x1     x2        y
0%    1.000 27.630 -31.9800
25%   4.000 42.630   0.8032
50%   6.000 49.710  12.2500
75%   7.000 54.910  27.2300
100% 12.000 72.390  71.1100
mean  5.918 49.220  14.0800
sd    2.372  8.808  20.0000
var   5.624 77.590 399.9000
NA's  0.000  0.000   0.0000
N    85.000 85.000  85.0000

$factors
NULL

> attr(m6.data, "varNamesRHS")
[1] "x1"  "x2"  "x10" "x11"
>




-- 
Paul E. Johnson
Professor, Political Science ? ?Assoc. Director
1541 Lilac Lane, Room 504 ? ? Center for Research Methods
University of Kansas ? ? ? ? ? ? ? University of Kansas
http://pj.freefaculty.org ? ? ? ? ? ?http://quant.ku.edu


From maechler at stat.math.ethz.ch  Fri May  4 18:56:56 2012
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 4 May 2012 18:56:56 +0200
Subject: [Rd] Proposal: model.data
In-Reply-To: <CAErODj8DhfYfn7y0kwWcUfKWCRVc-MZbEBTAuW_mEfQhnwfLSg@mail.gmail.com>
References: <CAErODj8fUQW85O6hMzU40ACH3Nvzk7fBa2OnV=mx_MnNwqDC5A@mail.gmail.com>
	<1336063009.29163.39.camel@brian-rcg>
	<CAErODj8DhfYfn7y0kwWcUfKWCRVc-MZbEBTAuW_mEfQhnwfLSg@mail.gmail.com>
Message-ID: <20388.2648.664958.975228@stat.math.ethz.ch>

>>>>> "PJ" == Paul Johnson <pauljohn32 at gmail.com>
>>>>>     on Thu, 3 May 2012 12:09:08 -0500 writes:

    PJ> Greetings: On Thu, May 3, 2012 at 11:36 AM, Brian
    PJ> G. Peterson <brian at braverock.com> wrote:
    >> On Thu, 2012-05-03 at 10:51 -0500, Paul Johnson wrote:
    >>> If somebody in R Core would like this and think about
    >>> putting it, or something like it, into the base, then
    >>> many chores involving predicted values would become much
    >>> easier.
    >>> 
    >> Why does this need to be in base? ?Implement it in a
    >> package.
    >>> 
    >> If it works, and is additive, people will use it. ?Look
    >> at 'reshape' or 'xts' or 'Matrix' just to name a few
    >> examples of widely used packages.
    >> 

    PJ> I can't use it to fix termplot unless it is in base.

Indeed.  I think it would be useful to "branch this topic"
into one part where it is about fixing
     termplot()  and  predict(*, type = "terms")
because -- as it happens -- I've got this on my todo list to
look at, for a couple of weeks now.
I also think there are "infelicities" in there
that could/should be improved.

    PJ> Or are you suggesting I create my own "termplot"
    PJ> replacement?

not necessarily.. ;-)

Martin


From xie at yihui.name  Fri May  4 19:02:54 2012
From: xie at yihui.name (Yihui Xie)
Date: Fri, 4 May 2012 12:02:54 -0500
Subject: [Rd] add sessionInfo() option to "save"
In-Reply-To: <CAJLyBTUXmqrC8Adu4gb_aFbNaMCWfPYnJAZfby2YaprXxaXoLQ@mail.gmail.com>
References: <CAJLyBTUXmqrC8Adu4gb_aFbNaMCWfPYnJAZfby2YaprXxaXoLQ@mail.gmail.com>
Message-ID: <CANROs4e5RbkE4JDSQC4zoJFqewCiXHMV+teOK-2tanDa--5fww@mail.gmail.com>

My 2 cents in the last section of this page: http://yihui.name/knitr/demo/cache/

You can set something like opts_knit$set(cache.extra =
sapply(c('boot', 'ggplot2', 'splines'), packageVersion)) so that each
time these packages are updated, the cache of your document will be
rebuilt.

That is not exactly the same as what you mentioned, however, with the
knitr package, you can easily leave a chunk like this in your Rnw
document:

<<sessioninfo, cache=TRUE, include=FALSE>>=
.sessioninfo = sessionInfo()
@

and the variable .sesioninfo will be saved to the cache database,
which you can load into your R session by lazyLoad() and examine it. I
think it might be better than manually save() objects.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 515-294-2465 Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


On Fri, May 4, 2012 at 11:09 AM, Robert M. Flight <rflight79 at gmail.com> wrote:
> Hi All,
>
> I was wondering if there would be any interest in adding an option to the
> "save" function in R that I think would be useful. I was thinking that it
> might be useful to have an option that would generate a ".sessionInfo"
> variable that contains the output of "sessionInfo()", and adds it to the
> list of objects to be saved. This way, whenever an RData object is loaded,
> all the information about the R version, and attached packages present
> would be available for query.
>
> I know I have been bitten by the problem of generating results using
> different versions of packages and different versions of R. I know that
> this is partly the idea behind Sweave (and other report generation
> measures), and perhaps I am at fault for not keeping better track of these
> types of things, but this seems like it would be useful to a lot of other
> people besides just me.
>
> Thoughts?
>
> -Robert
>
> Robert M. Flight, Ph.D.
> University of Louisville Bioinformatics Laboratory
> University of Louisville
> Louisville, KY
>
> PH 502-852-1809 (HSC)
> PH 502-852-0467 (Belknap)
> EM robert.flight at louisville.edu
> EM rflight79 at gmail.com
> robertmflight.blogspot.com
> bioinformatics.louisville.edu/lab
> github.com/rmflight/general/wiki
>
> The most exciting phrase to hear in science, the one that heralds new
> discoveries, is not "Eureka!" (I found it!) but "That's funny ..." - Isaac
> Asimov
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From info.shankar at gmail.com  Fri May  4 15:50:05 2012
From: info.shankar at gmail.com (pvshankar)
Date: Fri, 4 May 2012 06:50:05 -0700 (PDT)
Subject: [Rd] How to create data frame column name in a function
In-Reply-To: <1336049722102-4605939.post@n4.nabble.com>
References: <1336032104058-4605358.post@n4.nabble.com>
	<1336049722102-4605939.post@n4.nabble.com>
Message-ID: <1336139405316-4608663.post@n4.nabble.com>

Thank you. It worked beautifully :)

--
View this message in context: http://r.789695.n4.nabble.com/How-to-create-data-frame-column-name-in-a-function-tp4605358p4608663.html
Sent from the R devel mailing list archive at Nabble.com.


From krivitsky at stat.psu.edu  Fri May  4 19:42:36 2012
From: krivitsky at stat.psu.edu (Pavel N. Krivitsky)
Date: Fri, 04 May 2012 13:42:36 -0400
Subject: [Rd] [patch] Behavior of .C() and .Fortran() when given double(0)
 or integer(0).
Message-ID: <1336153356.24356.332.camel@Navi.krivitsky.homeip.net>

Dear R-devel,

While tracking down some hard-to-reproduce bugs in a package I maintain,
I stumbled on a behavior change between R 2.15.0 and the current R-devel
(or SVN trunk).

In 2.15.0 and earlier, if you passed an 0-length vector of the right
mode (e.g., double(0) or integer(0)) as one of the arguments in a .C()
call with DUP=TRUE (the default), the C routine would be passed NULL
(the C pointer, not R NULL) in the corresponding argument. The current
development version instead passes it a pointer to what appears to be
memory location immediately following the the SEXP that holds the
metadata for the argument. If the argument has length 0, this is often
memory belonging to a different R object. (DUP=FALSE in 2.15.0
appears to have the same behavior as R-devel.)

.C() documentation and Writing R Extensions don't explicitly specify a
behavior for 0-length vectors, so I don't know if this change is
intentional, or whether it was a side-effect of the following news item:

      .C() and .Fortran() do less copying: arguments which are raw,
      logical, integer, real or complex vectors and are unnamed are not
      copied before the call, and (named or not) are not copied after
      the call.  Lists are no longer copied (they are supposed to be
      used read-only in the C code).

Was the change in the empty vector behavior intentional?

It seems to me that standardizing on the behavior of giving the C
routine NULL is safer, more consistent with other memory-related
routines, and more convenient: whereas dereferencing a NULL pointer is
an immediate (and therefore easily traced) segfault, dereferencing an
invalid pointer that is nevertheless in the general memory area
allocated to the program often causes subtle errors down the line;
R_alloc asked to allocate 0 bytes returns NULL, at least on my platform;
and the C routine can easily check if a pointer is NULL, but with the
R-devel behavior, the programmer has to add an explicit way of telling
that an empty vector was passed.

I've attached a small test case (dotC_NULL.* files) that shows the
difference. The C file should be built with R CMD SHLIB, and the R file
calls the functions in the library with a variety of arguments. Output I
get from running
R CMD BATCH --no-timing --vanilla --slave dotC_NULL.R
on R 2.15.0, R trunk, and R trunk with my patch (described below) are attached.

The attached patch (dotC_NULL.patch) against the current trunk
(affecting src/main/dotcode.c) restores the old behavior for DUP=TRUE
(i.e., 0-length vector -> NULL pointer) and extends it to the DUP=FALSE
case. It does so by checking if an argument --- if it's of mode raw,
integer, real, or complex --- to a .C() or .Fortran() call has length 0,
and, if so, sets the pointer to be passed to NULL and then skips the
copying of the C routine's changes back to the R object for that
argument. The additional computing cost should be negligible (i.e.,
checking if vector length equals 0 and break-ing out of a switch
statement if so).

The patch appears to work, at least for my package, and R CMD check
passes for all recommended packages (on my 64-bit Linux system), but
this is my first time working with R's internals, so handle with care.

                                   Best,
                                   Pavel Krivitsky

-------------- next part --------------
R version 2.15.0 (2012-03-30)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=C                 LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

R_alloc asked to allocate 1 byte: 
Pointer to output from R_alloc() of 1 bytes: 0x211c470.
Return value: [1] 1

R_alloc asked to allocate 0 bytes: 
Pointer to output from R_alloc() of 0 bytes: (nil).
Return value: [1] 0

Integer vector with 1 element: 
Pointer to arg: 0x2123b00.
Return value: [1] 0

Integer vector with 0 elements: 
Pointer to arg: (nil).
Return value: integer(0)

Integer vector with 1 element and DUP=FALSE: 
Pointer to arg: 0x2132940.
Return value: [1] 0

Integer vector with 0 elements and DUP=FALSE: 
Pointer to arg: 0x2134a80.
Return value: integer(0)

-------------- next part --------------
R Under development (unstable) (2012-05-04 r59314)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=C                 LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

R_alloc asked to allocate 1 byte: 
Pointer to output from R_alloc() of 1 bytes: 0x1e56270.
Return value: [1] 1

R_alloc asked to allocate 0 bytes: 
Pointer to output from R_alloc() of 0 bytes: (nil).
Return value: [1] 0

Integer vector with 1 element: 
Pointer to arg: 0x1e60db0.
Return value: [1] 0

Integer vector with 0 elements: 
Pointer to arg: 0x1e75188.
Return value: integer(0)

Integer vector with 1 element and DUP=FALSE: 
Pointer to arg: 0x1e6ad90.
Return value: [1] 0

Integer vector with 0 elements and DUP=FALSE: 
Pointer to arg: 0x1e7dc10.
Return value: integer(0)

-------------- next part --------------
R Under development (unstable) (2012-05-04 r59314)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=C                 LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

R_alloc asked to allocate 1 byte: 
Pointer to output from R_alloc() of 1 bytes: 0x27495c0.
Return value: [1] 1

R_alloc asked to allocate 0 bytes: 
Pointer to output from R_alloc() of 0 bytes: (nil).
Return value: [1] 0

Integer vector with 1 element: 
Pointer to arg: 0x2754100.
Return value: [1] 0

Integer vector with 0 elements: 
Pointer to arg: (nil).
Return value: integer(0)

Integer vector with 1 element and DUP=FALSE: 
Pointer to arg: 0x275e0e0.
Return value: [1] 0

Integer vector with 0 elements and DUP=FALSE: 
Pointer to arg: (nil).
Return value: integer(0)

-------------- next part --------------
sessionInfo()
cat("\n")
dyn.load("dotC_NULL.so")
run_test<-function(desc,Cfun,args){
  cat(desc,"\n")
  out <- do.call(".C",c(list(Cfun),args))
  cat("Return value: ")
  print(out[[1]])
  cat("\n")
}


run_test("R_alloc asked to allocate 1 byte:", "R_alloc_test",list(nbytes=as.integer(1)))
run_test("R_alloc asked to allocate 0 bytes:", "R_alloc_test",list(nbytes=as.integer(0)))

run_test("Integer vector with 1 element:", "dotC_NULL",list(arg=integer(1)))
run_test("Integer vector with 0 elements:", "dotC_NULL",list(arg=integer(0)))
run_test("Integer vector with 1 element and DUP=FALSE:", "dotC_NULL",list(arg=integer(1), DUP=FALSE))
run_test("Integer vector with 0 elements and DUP=FALSE:", "dotC_NULL",list(arg=integer(0), DUP=FALSE))
-------------- next part --------------
A non-text attachment was scrubbed...
Name: dotC_NULL.patch
Type: text/x-patch
Size: 2473 bytes
Desc: 
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120504/ab68095c/attachment.bin>

From spencer.graves at prodsyse.com  Sat May  5 02:48:36 2012
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Fri, 04 May 2012 17:48:36 -0700
Subject: [Rd] f951.exe: sorry, unimplemented: 64-bit mode not compiled
Message-ID: <4FA478E4.8070803@prodsyse.com>

Hello:


       Under my Windows 7 system, "R CMD check 
DiercxkSpline_1.1-5.tar.gz" fails because:


f951.exe: sorry, unimplemented: 64-bit mode not compiled in

make: *** [bispev.o] Error 1
gfortran -m64     -O2  -mtune=core2 -c bispev.f -o bispev.o
f951.exe: sorry, unimplemented: 64-bit mode not compiled in

make: *** [bispev.o] Error 1
ERROR: compilation failed for package 'DierckxSpline'


       A similar problem was reported for package "glmnet" 
(http://stackoverflow.com/questions/10291189/compiling-glmnet-failed-in-windows) 
plus one with R 2.14.2 
(http://r.789695.n4.nabble.com/Problems-when-building-a-package-for-Windows-64-td4464488.html).  
However, I get this with R 2.15.0 and the latest R tools (reinstalled 
earlier today).  On R-Forge, DierckxSpline has "Build status:  Current", 
which suggests that R-Forge does NOT have this problem.  I read through 
the two replies to these two earlier questions without seeing how to fix 
my problem.


       Thanks in advance for any suggestions.


       Spencer Graves


From andre.zege at gmail.com  Sat May  5 03:50:22 2012
From: andre.zege at gmail.com (andre zege)
Date: Fri, 4 May 2012 21:50:22 -0400
Subject: [Rd] looking for adice on bigmemory framework with C++ and java
	interoperability
Message-ID: <CACU3EkNUmcq58ui=fnjOmH65SgsRdDUvHyG50Cm3UKCz8m7FuA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120504/a2ebf055/attachment.pl>

From simon.urbanek at r-project.org  Sat May  5 03:58:19 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 4 May 2012 21:58:19 -0400
Subject: [Rd] f951.exe: sorry, unimplemented: 64-bit mode not compiled
In-Reply-To: <4FA478E4.8070803@prodsyse.com>
References: <4FA478E4.8070803@prodsyse.com>
Message-ID: <2574D55A-B3CE-4759-BD89-BC6B1E936F5F@r-project.org>


On May 4, 2012, at 8:48 PM, Spencer Graves wrote:

> Hello:
> 
> 
>      Under my Windows 7 system, "R CMD check DiercxkSpline_1.1-5.tar.gz" fails because:
> 
> 
> f951.exe: sorry, unimplemented: 64-bit mode not compiled in
> 

This typically means that you're using the wrong (old) compiler. The new MinGW compilers support both -m32 and -m64. You have to set the PATH to the new compilers (in the gcc-4.6.3 subdirectory of Rtools) *before* any old compilers in Rtools.

Cheers,
Simon


> make: *** [bispev.o] Error 1
> gfortran -m64     -O2  -mtune=core2 -c bispev.f -o bispev.o
> f951.exe: sorry, unimplemented: 64-bit mode not compiled in
> 
> make: *** [bispev.o] Error 1
> ERROR: compilation failed for package 'DierckxSpline'
> 
> 
>      A similar problem was reported for package "glmnet" (http://stackoverflow.com/questions/10291189/compiling-glmnet-failed-in-windows) plus one with R 2.14.2 (http://r.789695.n4.nabble.com/Problems-when-building-a-package-for-Windows-64-td4464488.html).  However, I get this with R 2.15.0 and the latest R tools (reinstalled earlier today).  On R-Forge, DierckxSpline has "Build status:  Current", which suggests that R-Forge does NOT have this problem.  I read through the two replies to these two earlier questions without seeing how to fix my problem.
> 



> 
>      Thanks in advance for any suggestions.
> 
> 
>      Spencer Graves
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From simon.urbanek at r-project.org  Sat May  5 04:10:49 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 4 May 2012 22:10:49 -0400
Subject: [Rd] looking for adice on bigmemory framework with C++ and java
	interoperability
In-Reply-To: <CACU3EkNUmcq58ui=fnjOmH65SgsRdDUvHyG50Cm3UKCz8m7FuA@mail.gmail.com>
References: <CACU3EkNUmcq58ui=fnjOmH65SgsRdDUvHyG50Cm3UKCz8m7FuA@mail.gmail.com>
Message-ID: <78CABC11-F4FA-4BE9-8310-D4894A72C540@r-project.org>

Andre,

On May 4, 2012, at 9:50 PM, andre zege wrote:

> I work with problems that have rather large data requirements -- typically
> a bunch of multigig arrays. Given how generous R is with using memory, the
> only way for me to work with R has been to use bigmatrices from bigmemory
> package. One thing that is missing a bit is interoperability of bigmatrices
> with C++ and possibly java. What i mean by that is API that would allow
> read and write filebacked matrices from C++, and ideally java without being
> called from R. Having ability to save armadillo matrices into filebacked
> matrices and load them back into armadillo would be another very useful
> thing. This would allow really smooth cooperation between various pieces of
> software. I would prefer to avoid using Rinside for that.
> 
> I guess i could hack bigmemory C++ code a bit, compile it into a C++ shared
> library and it'll do. I guess i could hack it a bit to work with armadillo
> matrices as well. I don't want however to reinvent the wheel and if there
> is something like that already somewhere i would rather use it for the
> moment. Looking very much for suggestions. If there is truly nothing like
> that and someone with C++ or especially java development experience is
> interested and want to cooperate on this, let me know too.
> 

bigmemory matrices are simply arrays of native types (typically doubles, but bm supports other types, too) so they are trivially readable/writable from both C++ (just read into memory and cast to the array type) and Java (e.g, DoubleBuffer view on a ByteBuffer). So the question is what exactly is the problem?

Cheers,
Simon


> Best
> Andre
> 
> NB. I guess something like what i want -- access to the same disc caches
> from R, C++, and java (and python) exists in HDF world. I, however, don't
> know how performance of HDF compares with bigmemory matrices, which i come
> to like and appreciate a lot. If there is someone who could address
> simplicity of use and performance of HDF vs bigmemory, it'd be very
> interesting.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From andre.zege at gmail.com  Sat May  5 04:31:15 2012
From: andre.zege at gmail.com (andre zege)
Date: Fri, 4 May 2012 22:31:15 -0400
Subject: [Rd] looking for adice on bigmemory framework with C++ and java
	interoperability
In-Reply-To: <78CABC11-F4FA-4BE9-8310-D4894A72C540@r-project.org>
References: <CACU3EkNUmcq58ui=fnjOmH65SgsRdDUvHyG50Cm3UKCz8m7FuA@mail.gmail.com>
	<78CABC11-F4FA-4BE9-8310-D4894A72C540@r-project.org>
Message-ID: <CACU3EkOM7xAa94w4KXb04S7p9SHk9bL5do1K2kMECUV0goXJmw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120504/2fbedf0e/attachment.pl>

From edd at debian.org  Sat May  5 05:26:16 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 4 May 2012 22:26:16 -0500
Subject: [Rd] looking for adice on bigmemory framework with C++ and
	java	interoperability
In-Reply-To: <CACU3EkOM7xAa94w4KXb04S7p9SHk9bL5do1K2kMECUV0goXJmw@mail.gmail.com>
References: <CACU3EkNUmcq58ui=fnjOmH65SgsRdDUvHyG50Cm3UKCz8m7FuA@mail.gmail.com>
	<78CABC11-F4FA-4BE9-8310-D4894A72C540@r-project.org>
	<CACU3EkOM7xAa94w4KXb04S7p9SHk9bL5do1K2kMECUV0goXJmw@mail.gmail.com>
Message-ID: <20388.40408.462391.469944@max.nulle.part>


On 4 May 2012 at 22:31, andre zege wrote:
| Simon,  thanks for your comment. I guess there is no problem, i am
| apparently being lazy/busy and wondered if there is ready code that does
| it. You are right, i suppose -- i'll look at the c++ code for bigmatrix and
| will try to hack a solution.

You may want to look at the documentation for 'external pointers' in the
"Writing R Extensions" manual, and then consider at Rcpp::XPtr which provides
an Rcpp-based route to using external pointers.

Dirk

-- 
R/Finance 2012 Conference on May 11 and 12, 2012 at UIC in Chicago, IL
See agenda, registration details and more at http://www.RinFinance.com


From jayemerson at gmail.com  Sat May  5 14:44:59 2012
From: jayemerson at gmail.com (Jay Emerson)
Date: Sat, 5 May 2012 08:44:59 -0400
Subject: [Rd] looking for adice on bigmemory framework with C++ and java
	interoperability
Message-ID: <CALbRwZYeBM+3Si3_etw2f=gwaAqCmTWAxaToYRYTWX=ObsaYBA@mail.gmail.com>

On 4 May 2012 at 22:31, andre zege wrote:
| Simon,  thanks for your comment. I guess there is no problem, i am
| apparently being lazy/busy and wondered if there is ready code that does
| it. You are right, i suppose -- i'll look at the c++ code for bigmatrix and
| will try to hack a solution.

> You may want to look at the documentation for 'external pointers' in the
> "Writing R Extensions" manual, and then consider at Rcpp::XPtr which > provides
> an Rcpp-based route to using external pointers.

It's nice having others answering our questions before we can -- many
thanks Simon/Dirk!

A big.matrix of dimension RxC is a column-major binary file of R*C
elements of size 1, 2, 4, or 8 bytes, depending on the type of atomic
element.  Period, end of story, no header to worry about.  So you can
use it as you like from any language.  Whether you can mmap it
conveniently (if needed in shared memory or larger-than-RAM
applications) is another story.  We make use of the BOOST interprocess
library for this.

For working in R, the existing R API should be sufficient (though
could always be expanded).

For working in C++, the C++ API is pretty low-level and of course
could benefit from ultimately being Rpp-ified, for example.  There are
plenty of examples of working in C++ inside
bigmemory/biganalytics/bigtabulate.

For Java... well, I don't code in Java.  You can certainly make use of
the data structure easily enough, but whether you can make use of the
existing C++ API is something I simply can't answer.

I note that one really cool trick is when you have data from another
source (e.g. many satellite images) which is already a simple binary
file.  You can do a trivial hack to create a big.matrix descriptor
file, and attach.big.matrix() to it immediately.  No traditional
read.*() is necessary, and it is super fast.

Jay

-- 
John W. Emerson (Jay)
Associate Professor of Statistics
Department of Statistics
Yale University
http://www.stat.yale.edu/~jay


From spencer.graves at prodsyse.com  Sun May  6 01:05:27 2012
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Sat, 05 May 2012 16:05:27 -0700
Subject: [Rd] f951.exe: sorry, unimplemented: 64-bit mode not compiled
In-Reply-To: <2574D55A-B3CE-4759-BD89-BC6B1E936F5F@r-project.org>
References: <4FA478E4.8070803@prodsyse.com>
	<2574D55A-B3CE-4759-BD89-BC6B1E936F5F@r-project.org>
Message-ID: <4FA5B237.60400@prodsyse.com>

On 5/4/2012 6:58 PM, Simon Urbanek wrote:
> On May 4, 2012, at 8:48 PM, Spencer Graves wrote:
>
>> Hello:
>>
>>
>>       Under my Windows 7 system, "R CMD check DiercxkSpline_1.1-5.tar.gz" fails because:
>>
>>
>> f951.exe: sorry, unimplemented: 64-bit mode not compiled in
>>
> This typically means that you're using the wrong (old) compiler. The new MinGW compilers support both -m32 and -m64. You have to set the PATH to the new compilers (in the gcc-4.6.3 subdirectory of Rtools) *before* any old compilers in Rtools.


Simon:  That was it:  I had installed several recent versions of Rtools 
without deleting the old ones and without properly updating the path.  I 
deleted what I had, then reinstalled Rtools215.exe (downloaded 
yesterday) while being careful to have the installer help me edit the 
path.  The problem disappeared.  Thanks very much.  Spencer
>
> Cheers,
> Simon
>
>
>> make: *** [bispev.o] Error 1
>> gfortran -m64     -O2  -mtune=core2 -c bispev.f -o bispev.o
>> f951.exe: sorry, unimplemented: 64-bit mode not compiled in
>>
>> make: *** [bispev.o] Error 1
>> ERROR: compilation failed for package 'DierckxSpline'
>>
>>
>>       A similar problem was reported for package "glmnet" (http://stackoverflow.com/questions/10291189/compiling-glmnet-failed-in-windows) plus one with R 2.14.2 (http://r.789695.n4.nabble.com/Problems-when-building-a-package-for-Windows-64-td4464488.html).  However, I get this with R 2.15.0 and the latest R tools (reinstalled earlier today).  On R-Forge, DierckxSpline has "Build status:  Current", which suggests that R-Forge does NOT have this problem.  I read through the two replies to these two earlier questions without seeing how to fix my problem.
>>
>
>
>>       Thanks in advance for any suggestions.
>>
>>
>>       Spencer Graves
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
>


-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567
web:  www.structuremonitoring.com


From josh.m.ulrich at gmail.com  Sun May  6 04:39:31 2012
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sat, 5 May 2012 21:39:31 -0500
Subject: [Rd] unlist crashes 32-bit R on WinXP when use.names=TRUE
Message-ID: <CAPPM_gTSU1+YnCpcHL3JFPv4y7R7eFFOfrTXrEAnCPdJfzdgZQ@mail.gmail.com>

Hi all,

I experienced a crash in R-2.15.0 on 32-bit Windows XP (sessionInfo
below) when running the piece of code below.  I cannot replicate the
error on 64-bit Linux, 64-bit Windows, or 32-bit R running under
64-bit Windows.  I do not have, and could not find, a 32-bit version
of Linux to test this.

> NOW <- Sys.time()
> FUTURE <- NOW+1:1e7
> crash <- as.character(FUTURE)
Error in unlist(unclass(x)[1L:3L]) :
  promise already under evaluation: recursive default argument
reference or earlier problems?
> traceback()
Error: C stack usage is too close to the limit
> # evaluating an expression at this point would cause R to exit ungracefully

Here's an example that avoids a lot of unnecessary code:

L1 <- list(one=1:1e6, two=1:1e6, three=1:1e6)
# no issue with smaller list elements
U1 <- unlist(L1, recursive=TRUE, use.names=TRUE)
C1 <- c(L1, recursive=TRUE, use.names=TRUE)

L2 <- list(one=1:1e7, two=1:1e7, three=1:1e7)
# crashes after ~2min with error above
U2 <- unlist(L2, recursive=TRUE, use.names=TRUE)
C2 <- c(L2, recursive=TRUE, use.names=TRUE)
# no issue if use.names=FALSE
U3 <- unlist(L2, recursive=TRUE, use.names=FALSE)
C3 <- c(L2, recursive=TRUE, use.names=FALSE)

I took a look at do_unlist and do_c_dflt in bind.c, but I stopped at
NewExtractNames because it is a bit beyond my current understanding.
Any thoughts?

> sessionInfo()
R version 2.15.0 (2012-03-30)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

Please let me know if I forgot anything or if there's anything I can do to help.

Best,
--
Joshua Ulrich  |  FOSS Trading: www.fosstrading.com

R/Finance 2012: Applied Finance with R
www.RinFinance.com


From murdoch.duncan at gmail.com  Sun May  6 12:43:58 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 06 May 2012 06:43:58 -0400
Subject: [Rd] unlist crashes 32-bit R on WinXP when use.names=TRUE
In-Reply-To: <CAPPM_gTSU1+YnCpcHL3JFPv4y7R7eFFOfrTXrEAnCPdJfzdgZQ@mail.gmail.com>
References: <CAPPM_gTSU1+YnCpcHL3JFPv4y7R7eFFOfrTXrEAnCPdJfzdgZQ@mail.gmail.com>
Message-ID: <4FA655EE.5090201@gmail.com>

On 12-05-05 10:39 PM, Joshua Ulrich wrote:
> Hi all,
>
> I experienced a crash in R-2.15.0 on 32-bit Windows XP (sessionInfo
> below) when running the piece of code below.  I cannot replicate the
> error on 64-bit Linux, 64-bit Windows, or 32-bit R running under
> 64-bit Windows.  I do not have, and could not find, a 32-bit version
> of Linux to test this.
>
>> NOW<- Sys.time()
>> FUTURE<- NOW+1:1e7
>> crash<- as.character(FUTURE)
> Error in unlist(unclass(x)[1L:3L]) :
>    promise already under evaluation: recursive default argument
> reference or earlier problems?
>> traceback()
> Error: C stack usage is too close to the limit
>> # evaluating an expression at this point would cause R to exit ungracefully
>
> Here's an example that avoids a lot of unnecessary code:
>
> L1<- list(one=1:1e6, two=1:1e6, three=1:1e6)
> # no issue with smaller list elements
> U1<- unlist(L1, recursive=TRUE, use.names=TRUE)
> C1<- c(L1, recursive=TRUE, use.names=TRUE)
>
> L2<- list(one=1:1e7, two=1:1e7, three=1:1e7)
> # crashes after ~2min with error above
> U2<- unlist(L2, recursive=TRUE, use.names=TRUE)
> C2<- c(L2, recursive=TRUE, use.names=TRUE)
> # no issue if use.names=FALSE
> U3<- unlist(L2, recursive=TRUE, use.names=FALSE)
> C3<- c(L2, recursive=TRUE, use.names=FALSE)
>
> I took a look at do_unlist and do_c_dflt in bind.c, but I stopped at
> NewExtractNames because it is a bit beyond my current understanding.
> Any thoughts?

I would guess that some loop in the C code is using alloca to allocate 
temporary storage on the stack, and it's running out of stack space. 
I'll take a look...

Duncan Murdoch

>
>> sessionInfo()
> R version 2.15.0 (2012-03-30)
> Platform: i386-pc-mingw32/i386 (32-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> Please let me know if I forgot anything or if there's anything I can do to help.
>
> Best,
> --
> Joshua Ulrich  |  FOSS Trading: www.fosstrading.com
>
> R/Finance 2012: Applied Finance with R
> www.RinFinance.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Sun May  6 13:53:07 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 06 May 2012 07:53:07 -0400
Subject: [Rd] unlist crashes 32-bit R on WinXP when use.names=TRUE
In-Reply-To: <4FA655EE.5090201@gmail.com>
References: <CAPPM_gTSU1+YnCpcHL3JFPv4y7R7eFFOfrTXrEAnCPdJfzdgZQ@mail.gmail.com>
	<4FA655EE.5090201@gmail.com>
Message-ID: <4FA66623.8070707@gmail.com>

On 12-05-06 6:43 AM, Duncan Murdoch wrote:
> On 12-05-05 10:39 PM, Joshua Ulrich wrote:
>> Hi all,
>>
>> I experienced a crash in R-2.15.0 on 32-bit Windows XP (sessionInfo
>> below) when running the piece of code below.  I cannot replicate the
>> error on 64-bit Linux, 64-bit Windows, or 32-bit R running under
>> 64-bit Windows.  I do not have, and could not find, a 32-bit version
>> of Linux to test this.
>>
>>> NOW<- Sys.time()
>>> FUTURE<- NOW+1:1e7
>>> crash<- as.character(FUTURE)
>> Error in unlist(unclass(x)[1L:3L]) :
>>     promise already under evaluation: recursive default argument
>> reference or earlier problems?
>>> traceback()
>> Error: C stack usage is too close to the limit
>>> # evaluating an expression at this point would cause R to exit ungracefully
>>
>> Here's an example that avoids a lot of unnecessary code:
>>
>> L1<- list(one=1:1e6, two=1:1e6, three=1:1e6)
>> # no issue with smaller list elements
>> U1<- unlist(L1, recursive=TRUE, use.names=TRUE)
>> C1<- c(L1, recursive=TRUE, use.names=TRUE)
>>
>> L2<- list(one=1:1e7, two=1:1e7, three=1:1e7)
>> # crashes after ~2min with error above
>> U2<- unlist(L2, recursive=TRUE, use.names=TRUE)
>> C2<- c(L2, recursive=TRUE, use.names=TRUE)
>> # no issue if use.names=FALSE
>> U3<- unlist(L2, recursive=TRUE, use.names=FALSE)
>> C3<- c(L2, recursive=TRUE, use.names=FALSE)
>>
>> I took a look at do_unlist and do_c_dflt in bind.c, but I stopped at
>> NewExtractNames because it is a bit beyond my current understanding.
>> Any thoughts?
>
> I would guess that some loop in the C code is using alloca to allocate
> temporary storage on the stack, and it's running out of stack space.
> I'll take a look...

I couldn't spot this anywhere.  I'm not sure what's happening, except 
maybe you're just running out of memory:  you're trying to allocate 3e7 
different names.

Duncan Murdoch

>
> Duncan Murdoch
>
>>
>>> sessionInfo()
>> R version 2.15.0 (2012-03-30)
>> Platform: i386-pc-mingw32/i386 (32-bit)
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252
>> [2] LC_CTYPE=English_United States.1252
>> [3] LC_MONETARY=English_United States.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> Please let me know if I forgot anything or if there's anything I can do to help.
>>
>> Best,
>> --
>> Joshua Ulrich  |  FOSS Trading: www.fosstrading.com
>>
>> R/Finance 2012: Applied Finance with R
>> www.RinFinance.com
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From edd at debian.org  Sun May  6 14:17:18 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 6 May 2012 07:17:18 -0500
Subject: [Rd] unlist crashes 32-bit R on WinXP when use.names=TRUE
In-Reply-To: <4FA66623.8070707@gmail.com>
References: <CAPPM_gTSU1+YnCpcHL3JFPv4y7R7eFFOfrTXrEAnCPdJfzdgZQ@mail.gmail.com>
	<4FA655EE.5090201@gmail.com> <4FA66623.8070707@gmail.com>
Message-ID: <20390.27598.121500.674478@max.nulle.part>


On 6 May 2012 at 07:53, Duncan Murdoch wrote:
| On 12-05-06 6:43 AM, Duncan Murdoch wrote:
| > On 12-05-05 10:39 PM, Joshua Ulrich wrote:
| >> Hi all,
| >>
| >> I experienced a crash in R-2.15.0 on 32-bit Windows XP (sessionInfo
| >> below) when running the piece of code below.  I cannot replicate the
| >> error on 64-bit Linux, 64-bit Windows, or 32-bit R running under
| >> 64-bit Windows.  I do not have, and could not find, a 32-bit version
| >> of Linux to test this.

On 32bit Linux with limited ram, it just swaps away ...

| >>> NOW<- Sys.time()
| >>> FUTURE<- NOW+1:1e7
| >>> crash<- as.character(FUTURE)
| >> Error in unlist(unclass(x)[1L:3L]) :
| >>     promise already under evaluation: recursive default argument
| >> reference or earlier problems?
| >>> traceback()
| >> Error: C stack usage is too close to the limit
| >>> # evaluating an expression at this point would cause R to exit ungracefully
| >>
| >> Here's an example that avoids a lot of unnecessary code:
| >>
| >> L1<- list(one=1:1e6, two=1:1e6, three=1:1e6)
| >> # no issue with smaller list elements
| >> U1<- unlist(L1, recursive=TRUE, use.names=TRUE)
| >> C1<- c(L1, recursive=TRUE, use.names=TRUE)
| >>
| >> L2<- list(one=1:1e7, two=1:1e7, three=1:1e7)
| >> # crashes after ~2min with error above
| >> U2<- unlist(L2, recursive=TRUE, use.names=TRUE)
| >> C2<- c(L2, recursive=TRUE, use.names=TRUE)
| >> # no issue if use.names=FALSE
| >> U3<- unlist(L2, recursive=TRUE, use.names=FALSE)
| >> C3<- c(L2, recursive=TRUE, use.names=FALSE)
| >>
| >> I took a look at do_unlist and do_c_dflt in bind.c, but I stopped at
| >> NewExtractNames because it is a bit beyond my current understanding.
| >> Any thoughts?
| >
| > I would guess that some loop in the C code is using alloca to allocate
| > temporary storage on the stack, and it's running out of stack space.
| > I'll take a look...
| 
| I couldn't spot this anywhere.  I'm not sure what's happening, except 
| maybe you're just running out of memory:  you're trying to allocate 3e7 
| different names.

... but it is working steadily on it which an R session with more VIRT ram
(per htop) than physical memory. 

Dirk

| 
| Duncan Murdoch
| 
| >
| > Duncan Murdoch
| >
| >>
| >>> sessionInfo()
| >> R version 2.15.0 (2012-03-30)
| >> Platform: i386-pc-mingw32/i386 (32-bit)
| >>
| >> locale:
| >> [1] LC_COLLATE=English_United States.1252
| >> [2] LC_CTYPE=English_United States.1252
| >> [3] LC_MONETARY=English_United States.1252
| >> [4] LC_NUMERIC=C
| >> [5] LC_TIME=English_United States.1252
| >>
| >> attached base packages:
| >> [1] stats     graphics  grDevices utils     datasets  methods   base
| >>
| >> Please let me know if I forgot anything or if there's anything I can do to help.
| >>
| >> Best,
| >> --
| >> Joshua Ulrich  |  FOSS Trading: www.fosstrading.com
| >>
| >> R/Finance 2012: Applied Finance with R
| >> www.RinFinance.com
| >>
| >> ______________________________________________
| >> R-devel at r-project.org mailing list
| >> https://stat.ethz.ch/mailman/listinfo/r-devel
| >
| 
| ______________________________________________
| R-devel at r-project.org mailing list
| https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
R/Finance 2012 Conference on May 11 and 12, 2012 at UIC in Chicago, IL
See agenda, registration details and more at http://www.RinFinance.com


From murdoch.duncan at gmail.com  Sun May  6 14:37:33 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 06 May 2012 08:37:33 -0400
Subject: [Rd] unlist crashes 32-bit R on WinXP when use.names=TRUE
In-Reply-To: <4FA66623.8070707@gmail.com>
References: <CAPPM_gTSU1+YnCpcHL3JFPv4y7R7eFFOfrTXrEAnCPdJfzdgZQ@mail.gmail.com>
	<4FA655EE.5090201@gmail.com> <4FA66623.8070707@gmail.com>
Message-ID: <4FA6708D.7070003@gmail.com>

On 12-05-06 7:53 AM, Duncan Murdoch wrote:
> On 12-05-06 6:43 AM, Duncan Murdoch wrote:
>> On 12-05-05 10:39 PM, Joshua Ulrich wrote:
>>> Hi all,
>>>
>>> I experienced a crash in R-2.15.0 on 32-bit Windows XP (sessionInfo
>>> below) when running the piece of code below.  I cannot replicate the
>>> error on 64-bit Linux, 64-bit Windows, or 32-bit R running under
>>> 64-bit Windows.  I do not have, and could not find, a 32-bit version
>>> of Linux to test this.
>>>
>>>> NOW<- Sys.time()
>>>> FUTURE<- NOW+1:1e7
>>>> crash<- as.character(FUTURE)
>>> Error in unlist(unclass(x)[1L:3L]) :
>>>      promise already under evaluation: recursive default argument
>>> reference or earlier problems?
>>>> traceback()
>>> Error: C stack usage is too close to the limit
>>>> # evaluating an expression at this point would cause R to exit ungracefully
>>>
>>> Here's an example that avoids a lot of unnecessary code:
>>>
>>> L1<- list(one=1:1e6, two=1:1e6, three=1:1e6)
>>> # no issue with smaller list elements
>>> U1<- unlist(L1, recursive=TRUE, use.names=TRUE)
>>> C1<- c(L1, recursive=TRUE, use.names=TRUE)
>>>
>>> L2<- list(one=1:1e7, two=1:1e7, three=1:1e7)
>>> # crashes after ~2min with error above
>>> U2<- unlist(L2, recursive=TRUE, use.names=TRUE)
>>> C2<- c(L2, recursive=TRUE, use.names=TRUE)
>>> # no issue if use.names=FALSE
>>> U3<- unlist(L2, recursive=TRUE, use.names=FALSE)
>>> C3<- c(L2, recursive=TRUE, use.names=FALSE)
>>>
>>> I took a look at do_unlist and do_c_dflt in bind.c, but I stopped at
>>> NewExtractNames because it is a bit beyond my current understanding.
>>> Any thoughts?
>>
>> I would guess that some loop in the C code is using alloca to allocate
>> temporary storage on the stack, and it's running out of stack space.
>> I'll take a look...
>
> I couldn't spot this anywhere.  I'm not sure what's happening, except
> maybe you're just running out of memory:  you're trying to allocate 3e7
> different names.

Yes, I think that's it.  I get a similar error from this code:

one <- paste0("one", 1:1e7) # okay
two <- paste0("two", 1:1e7) # gives error

So I think the error handling should be improved somewhere in the string 
allocation code ("out of memory" would be a better message!), but it 
probably has nothing to do with unlist.

Duncan Murdoch

>
> Duncan Murdoch
>
>>
>> Duncan Murdoch
>>
>>>
>>>> sessionInfo()
>>> R version 2.15.0 (2012-03-30)
>>> Platform: i386-pc-mingw32/i386 (32-bit)
>>>
>>> locale:
>>> [1] LC_COLLATE=English_United States.1252
>>> [2] LC_CTYPE=English_United States.1252
>>> [3] LC_MONETARY=English_United States.1252
>>> [4] LC_NUMERIC=C
>>> [5] LC_TIME=English_United States.1252
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> Please let me know if I forgot anything or if there's anything I can do to help.
>>>
>>> Best,
>>> --
>>> Joshua Ulrich  |  FOSS Trading: www.fosstrading.com
>>>
>>> R/Finance 2012: Applied Finance with R
>>> www.RinFinance.com
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From murdoch.duncan at gmail.com  Sun May  6 18:22:30 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 06 May 2012 12:22:30 -0400
Subject: [Rd] unlist crashes 32-bit R on WinXP when use.names=TRUE
In-Reply-To: <CAPPM_gTSU1+YnCpcHL3JFPv4y7R7eFFOfrTXrEAnCPdJfzdgZQ@mail.gmail.com>
References: <CAPPM_gTSU1+YnCpcHL3JFPv4y7R7eFFOfrTXrEAnCPdJfzdgZQ@mail.gmail.com>
Message-ID: <4FA6A546.7090304@gmail.com>

On 12-05-05 10:39 PM, Joshua Ulrich wrote:
> Hi all,
>
> I experienced a crash in R-2.15.0 on 32-bit Windows XP (sessionInfo
> below) when running the piece of code below.  I cannot replicate the
> error on 64-bit Linux, 64-bit Windows, or 32-bit R running under
> 64-bit Windows.  I do not have, and could not find, a 32-bit version
> of Linux to test this.
>
>> NOW<- Sys.time()
>> FUTURE<- NOW+1:1e7
>> crash<- as.character(FUTURE)
> Error in unlist(unclass(x)[1L:3L]) :
>    promise already under evaluation: recursive default argument
> reference or earlier problems?
>> traceback()
> Error: C stack usage is too close to the limit
>> # evaluating an expression at this point would cause R to exit ungracefully

I think what's happening is this:

R tries to allocate one of those names, and fails.

It tries to display an error message, but that fails too, because it 
needs memory for the message.

You get a strange error, and R is left unstable.

In R-devel, R appears to go into an infinite loop.

I'm not sure we'll fix R 2.15.x unless it's a relatively easy fix, but 
I'll try to get R-devel to at least report an error.

Duncan Murdoch


>
> Here's an example that avoids a lot of unnecessary code:
>
> L1<- list(one=1:1e6, two=1:1e6, three=1:1e6)
> # no issue with smaller list elements
> U1<- unlist(L1, recursive=TRUE, use.names=TRUE)
> C1<- c(L1, recursive=TRUE, use.names=TRUE)
>
> L2<- list(one=1:1e7, two=1:1e7, three=1:1e7)
> # crashes after ~2min with error above
> U2<- unlist(L2, recursive=TRUE, use.names=TRUE)
> C2<- c(L2, recursive=TRUE, use.names=TRUE)
> # no issue if use.names=FALSE
> U3<- unlist(L2, recursive=TRUE, use.names=FALSE)
> C3<- c(L2, recursive=TRUE, use.names=FALSE)
>
> I took a look at do_unlist and do_c_dflt in bind.c, but I stopped at
> NewExtractNames because it is a bit beyond my current understanding.
> Any thoughts?
>
>> sessionInfo()
> R version 2.15.0 (2012-03-30)
> Platform: i386-pc-mingw32/i386 (32-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> Please let me know if I forgot anything or if there's anything I can do to help.
>
> Best,
> --
> Joshua Ulrich  |  FOSS Trading: www.fosstrading.com
>
> R/Finance 2012: Applied Finance with R
> www.RinFinance.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From krivitsky at stat.psu.edu  Sun May  6 21:54:13 2012
From: krivitsky at stat.psu.edu (Pavel N. Krivitsky)
Date: Sun, 06 May 2012 15:54:13 -0400
Subject: [Rd] [patch] Behavior of .C() and .Fortran() when given
 double(0) or integer(0).
In-Reply-To: <1336153356.24356.332.camel@Navi.krivitsky.homeip.net>
References: <1336153356.24356.332.camel@Navi.krivitsky.homeip.net>
Message-ID: <1336334053.24356.337.camel@Navi.krivitsky.homeip.net>

Oops... Forgot to attach the dotC_NULL.c, the C source file for the test
case.

                  Pavel Krivitsky

On Fri, 2012-05-04 at 13:42 -0400, Pavel N. Krivitsky wrote:
> Dear R-devel,
> 
> While tracking down some hard-to-reproduce bugs in a package I maintain,
> I stumbled on a behavior change between R 2.15.0 and the current R-devel
> (or SVN trunk).
> 
> In 2.15.0 and earlier, if you passed an 0-length vector of the right
> mode (e.g., double(0) or integer(0)) as one of the arguments in a .C()
> call with DUP=TRUE (the default), the C routine would be passed NULL
> (the C pointer, not R NULL) in the corresponding argument. The current
> development version instead passes it a pointer to what appears to be
> memory location immediately following the the SEXP that holds the
> metadata for the argument. If the argument has length 0, this is often
> memory belonging to a different R object. (DUP=FALSE in 2.15.0
> appears to have the same behavior as R-devel.)
> 
> .C() documentation and Writing R Extensions don't explicitly specify a
> behavior for 0-length vectors, so I don't know if this change is
> intentional, or whether it was a side-effect of the following news item:
> 
>       .C() and .Fortran() do less copying: arguments which are raw,
>       logical, integer, real or complex vectors and are unnamed are not
>       copied before the call, and (named or not) are not copied after
>       the call.  Lists are no longer copied (they are supposed to be
>       used read-only in the C code).
> 
> Was the change in the empty vector behavior intentional?
> 
> It seems to me that standardizing on the behavior of giving the C
> routine NULL is safer, more consistent with other memory-related
> routines, and more convenient: whereas dereferencing a NULL pointer is
> an immediate (and therefore easily traced) segfault, dereferencing an
> invalid pointer that is nevertheless in the general memory area
> allocated to the program often causes subtle errors down the line;
> R_alloc asked to allocate 0 bytes returns NULL, at least on my platform;
> and the C routine can easily check if a pointer is NULL, but with the
> R-devel behavior, the programmer has to add an explicit way of telling
> that an empty vector was passed.
> 
> I've attached a small test case (dotC_NULL.* files) that shows the
> difference. The C file should be built with R CMD SHLIB, and the R file
> calls the functions in the library with a variety of arguments. Output I
> get from running
> R CMD BATCH --no-timing --vanilla --slave dotC_NULL.R
> on R 2.15.0, R trunk, and R trunk with my patch (described below) are attached.
> 
> The attached patch (dotC_NULL.patch) against the current trunk
> (affecting src/main/dotcode.c) restores the old behavior for DUP=TRUE
> (i.e., 0-length vector -> NULL pointer) and extends it to the DUP=FALSE
> case. It does so by checking if an argument --- if it's of mode raw,
> integer, real, or complex --- to a .C() or .Fortran() call has length 0,
> and, if so, sets the pointer to be passed to NULL and then skips the
> copying of the C routine's changes back to the R object for that
> argument. The additional computing cost should be negligible (i.e.,
> checking if vector length equals 0 and break-ing out of a switch
> statement if so).
> 
> The patch appears to work, at least for my package, and R CMD check
> passes for all recommended packages (on my 64-bit Linux system), but
> this is my first time working with R's internals, so handle with care.
> 
>                                    Best,
>                                    Pavel Krivitsky
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From krivitsky at stat.psu.edu  Mon May  7 21:16:29 2012
From: krivitsky at stat.psu.edu (Pavel N. Krivitsky)
Date: Mon, 07 May 2012 15:16:29 -0400
Subject: [Rd] [patch] Behavior of .C() and .Fortran() when given
 double(0) or integer(0). --- Missing C file.
In-Reply-To: <1336153356.24356.332.camel@Navi.krivitsky.homeip.net>
References: <1336153356.24356.332.camel@Navi.krivitsky.homeip.net>
Message-ID: <1336418189.24356.378.camel@Navi.krivitsky.homeip.net>

Hi,

It looks like I didn't forget to attach it after all, but R-devel strips
C source code files. Remove the ".txt" from the attached file to compile
the test case.

                         Best,
                         Pavel

On Fri, 2012-05-04 at 13:42 -0400, Pavel N. Krivitsky wrote:
> Dear R-devel,
> 
> While tracking down some hard-to-reproduce bugs in a package I maintain,
> I stumbled on a behavior change between R 2.15.0 and the current R-devel
> (or SVN trunk).
> 
> In 2.15.0 and earlier, if you passed an 0-length vector of the right
> mode (e.g., double(0) or integer(0)) as one of the arguments in a .C()
> call with DUP=TRUE (the default), the C routine would be passed NULL
> (the C pointer, not R NULL) in the corresponding argument. The current
> development version instead passes it a pointer to what appears to be
> memory location immediately following the the SEXP that holds the
> metadata for the argument. If the argument has length 0, this is often
> memory belonging to a different R object. (DUP=FALSE in 2.15.0
> appears to have the same behavior as R-devel.)
> 
> .C() documentation and Writing R Extensions don't explicitly specify a
> behavior for 0-length vectors, so I don't know if this change is
> intentional, or whether it was a side-effect of the following news item:
> 
>       .C() and .Fortran() do less copying: arguments which are raw,
>       logical, integer, real or complex vectors and are unnamed are not
>       copied before the call, and (named or not) are not copied after
>       the call.  Lists are no longer copied (they are supposed to be
>       used read-only in the C code).
> 
> Was the change in the empty vector behavior intentional?
> 
> It seems to me that standardizing on the behavior of giving the C
> routine NULL is safer, more consistent with other memory-related
> routines, and more convenient: whereas dereferencing a NULL pointer is
> an immediate (and therefore easily traced) segfault, dereferencing an
> invalid pointer that is nevertheless in the general memory area
> allocated to the program often causes subtle errors down the line;
> R_alloc asked to allocate 0 bytes returns NULL, at least on my platform;
> and the C routine can easily check if a pointer is NULL, but with the
> R-devel behavior, the programmer has to add an explicit way of telling
> that an empty vector was passed.
> 
> I've attached a small test case (dotC_NULL.* files) that shows the
> difference. The C file should be built with R CMD SHLIB, and the R file
> calls the functions in the library with a variety of arguments. Output I
> get from running
> R CMD BATCH --no-timing --vanilla --slave dotC_NULL.R
> on R 2.15.0, R trunk, and R trunk with my patch (described below) are attached.
> 
> The attached patch (dotC_NULL.patch) against the current trunk
> (affecting src/main/dotcode.c) restores the old behavior for DUP=TRUE
> (i.e., 0-length vector -> NULL pointer) and extends it to the DUP=FALSE
> case. It does so by checking if an argument --- if it's of mode raw,
> integer, real, or complex --- to a .C() or .Fortran() call has length 0,
> and, if so, sets the pointer to be passed to NULL and then skips the
> copying of the C routine's changes back to the R object for that
> argument. The additional computing cost should be negligible (i.e.,
> checking if vector length equals 0 and break-ing out of a switch
> statement if so).
> 
> The patch appears to work, at least for my package, and R CMD check
> passes for all recommended packages (on my 64-bit Linux system), but
> this is my first time working with R's internals, so handle with care.
> 
>                                    Best,
>                                    Pavel Krivitsky
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-------------- next part --------------
#include <R.h>

void dotC_NULL(int *arg){
  Rprintf("Pointer to arg: %p.\n",(void *) arg);
}

void R_alloc_test(int *nbytes){
  char *p = (char *) R_alloc(*nbytes,sizeof(char));
  Rprintf("Pointer to output from R_alloc() of %d byte(s): %p.\n",*nbytes,(void *) p);
}

From jwiley.psych at gmail.com  Tue May  8 07:46:51 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Mon, 7 May 2012 22:46:51 -0700
Subject: [Rd] file 2 is not in sorted order error building unsuffered
	consequences
Message-ID: <CANz9Z_JT0O52UXm0px1U2=KLxg=QHKLz6_1=xFSFs+Un5odE3w@mail.gmail.com>

Hi All,

I just downloaded the source tar ball (Revision: 59324 Last Changed
Date: 2012-05-07) and tried to compile on a Win x64 system.  I am
using Rtools version 2.15.0.1919.  The only change I make is changing
MkRules.dist -> MkRules.local and setting Multi=64  I have previously
compiled unsuffered consquences without issue, but on the current
version, I get this error


windres -F pe-x86-64  -I../include -i dllversion.rc -o dllversion.o
comm: file 2 is not in sorted order
make[3]: *** [R.dll] Error 1
make[2]: *** [../../bin/x64/R.dll] Error 2
make[1]: *** [rbuild] Error 2
make: *** [all] Error 2

I did not note any other errors or warnings earlier on, though I may
have missed some.  I can provide the full log if requested.  Any
ideas?

Thanks,

Josh


-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From murdoch.duncan at gmail.com  Tue May  8 12:48:17 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 08 May 2012 06:48:17 -0400
Subject: [Rd] file 2 is not in sorted order error building unsuffered
 consequences
In-Reply-To: <CANz9Z_JT0O52UXm0px1U2=KLxg=QHKLz6_1=xFSFs+Un5odE3w@mail.gmail.com>
References: <CANz9Z_JT0O52UXm0px1U2=KLxg=QHKLz6_1=xFSFs+Un5odE3w@mail.gmail.com>
Message-ID: <4FA8F9F1.8090706@gmail.com>

On 12-05-08 1:46 AM, Joshua Wiley wrote:
> Hi All,
>
> I just downloaded the source tar ball (Revision: 59324 Last Changed
> Date: 2012-05-07) and tried to compile on a Win x64 system.  I am
> using Rtools version 2.15.0.1919.  The only change I make is changing
> MkRules.dist ->  MkRules.local and setting Multi=64  I have previously
> compiled unsuffered consquences without issue, but on the current
> version, I get this error
>
>
> windres -F pe-x86-64  -I../include -i dllversion.rc -o dllversion.o
> comm: file 2 is not in sorted order
> make[3]: *** [R.dll] Error 1
> make[2]: *** [../../bin/x64/R.dll] Error 2
> make[1]: *** [rbuild] Error 2
> make: *** [all] Error 2
>
> I did not note any other errors or warnings earlier on, though I may
> have missed some.  I can provide the full log if requested.  Any
> ideas?

I believe that message is about the file src/gnuwin32/Rdll.hide.  It is 
supposed to be sorted, using ASCII collation order.  I believe the 
version in the repository is sorted properly; can you check yours?

We've had some problems with recent versions of Cygwin not sorting 
properly.  The last instance had it put names in the order

  BZ2_bzWriteClose at 20
  BZ2_bzWriteClose64 at 28

but ASCII order should put @ after 6.  Are you using the comm and Cygwin 
dlls from Rtools, or have you got newer ones?

Duncan Murdoch


From lunds at iastate.edu  Mon May  7 19:24:28 2012
From: lunds at iastate.edu (Steven Lund)
Date: Mon, 7 May 2012 13:24:28 -0400
Subject: [Rd] How to list package dependency on a Bioconductor package?
In-Reply-To: <4F02F7BF.4040606@statistik.tu-dortmund.de>
References: <CAMe5z5nqAOk7hWXZ8ePs8XsPv=cSk8zO1vrm3doDZA4k+buhFQ@mail.gmail.com>
	<4F02F7BF.4040606@statistik.tu-dortmund.de>
Message-ID: <CAMe5z5m=6=hdN8Ne4+p3XquTRYFZZAHWQovHjkgZKmV2oYzaiA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120507/59ebd9d7/attachment.pl>

From jwiley.psych at gmail.com  Tue May  8 17:20:20 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Tue, 8 May 2012 08:20:20 -0700
Subject: [Rd] file 2 is not in sorted order error building unsuffered
	consequences
In-Reply-To: <4FA8F9F1.8090706@gmail.com>
References: <CANz9Z_JT0O52UXm0px1U2=KLxg=QHKLz6_1=xFSFs+Un5odE3w@mail.gmail.com>
	<4FA8F9F1.8090706@gmail.com>
Message-ID: <CANz9Z_KsoyU_ym0xUbRV30Rn-_=h2+--bX6crDZ0hmLXdnCN8w@mail.gmail.com>

On Tue, May 8, 2012 at 3:48 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 12-05-08 1:46 AM, Joshua Wiley wrote:
>>
>> Hi All,
>>
>> I just downloaded the source tar ball (Revision: 59324 Last Changed
>> Date: 2012-05-07) and tried to compile on a Win x64 system. ?I am
>> using Rtools version 2.15.0.1919. ?The only change I make is changing
>> MkRules.dist -> ?MkRules.local and setting Multi=64 ?I have previously
>> compiled unsuffered consquences without issue, but on the current
>> version, I get this error
>>
>>
>> windres -F pe-x86-64 ?-I../include -i dllversion.rc -o dllversion.o
>> comm: file 2 is not in sorted order
>> make[3]: *** [R.dll] Error 1
>> make[2]: *** [../../bin/x64/R.dll] Error 2
>> make[1]: *** [rbuild] Error 2
>> make: *** [all] Error 2
>>
>> I did not note any other errors or warnings earlier on, though I may
>> have missed some. ?I can provide the full log if requested. ?Any
>> ideas?
>
>
> I believe that message is about the file src/gnuwin32/Rdll.hide. ?It is
> supposed to be sorted, using ASCII collation order. ?I believe the version
> in the repository is sorted properly; can you check yours?

Thanks for your reply.  It looks sorted correctly and explicitly
sorting prior to running make does not change the error.  here is a
bit of output:

BZ2_bzBuffToBuffCompress at 28
BZ2_bzBuffToBuffDecompress at 24
BZ2_bzCompress at 8
BZ2_bzCompressEnd at 4
BZ2_bzCompressInit at 16
BZ2_bzDecompress at 4
BZ2_bzDecompressEnd at 4
BZ2_bzDecompressInit at 12
BZ2_bzRead at 16
BZ2_bzReadClose at 8
BZ2_bzReadGetUnused at 16
BZ2_bzReadOpen at 24
BZ2_bzWrite at 16
BZ2_bzWriteClose64 at 28
BZ2_bzWriteClose at 20

>
> We've had some problems with recent versions of Cygwin not sorting properly.
> ?The last instance had it put names in the order
>
> ?BZ2_bzWriteClose at 20
> ?BZ2_bzWriteClose64 at 28
>
> but ASCII order should put @ after 6. ?Are you using the comm and Cygwin
> dlls from Rtools, or have you got newer ones?

As far as I know I should only be using the dlls from Rtools.  It is
the first thing on my path environment variable, and although cygwin
is installed, I do not even have it on my path.  Interestingly, there
are no problems if set MULTI=32 instead of 64 in MkRules.

Thanks again,

Josh

>
> Duncan Murdoch



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From simon.urbanek at r-project.org  Tue May  8 17:44:02 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 8 May 2012 11:44:02 -0400
Subject: [Rd] How to list package dependency on a Bioconductor package?
In-Reply-To: <CAMe5z5m=6=hdN8Ne4+p3XquTRYFZZAHWQovHjkgZKmV2oYzaiA@mail.gmail.com>
References: <CAMe5z5nqAOk7hWXZ8ePs8XsPv=cSk8zO1vrm3doDZA4k+buhFQ@mail.gmail.com>
	<4F02F7BF.4040606@statistik.tu-dortmund.de>
	<CAMe5z5m=6=hdN8Ne4+p3XquTRYFZZAHWQovHjkgZKmV2oYzaiA@mail.gmail.com>
Message-ID: <02FFE7E8-4543-4368-9028-BA04EB893322@r-project.org>

Steven,

On May 7, 2012, at 1:24 PM, Steven Lund wrote:

> I recently submit a package called QuasiSeq.  The package source and
> Windows binary worked fine, but the MacOS X binary failed. The bottom of
> the CRAN page for QuasiSeq shows
> 
> Downloads:
>  Package source:     QuasiSeq_1.0-1.tar.gz
>  MacOS X binary:     not available, see check log.
>  Windows binary:     QuasiSeq-1.0-1.zip
>  Reference manual:  QuasiSeq.pdf
> 
> 
> The log for the MacOS X binary shows
>   - using R version 2.15.0 (2012-03-30)
>   - using platform: i386-apple-darwin9.8.0 (32-bit)
>   -  using session charset: ASCII
>   -  checking for file 'QuasiSeq/DESCRIPTION' ... OK
>   -  this is package 'QuasiSeq' version '1.0-1'
>   -  checking package namespace information ... OK
>   -  checking package dependencies ... ERROR
>           Package required but not available: 'edgeR'
> 
>           See the information on DESCRIPTION files in the chapter
> 'Creating R
>           packages' of the 'Writing R Extensions' manual.
>   -  elapsed time (check, wall clock): 0:01
> 
> Is there a simple remedy to the problems caused by the dependency on edgeR,
> or would you advise that I put a work-around into my source code using
> 'require' so I can list edgeR under Suggests instead of Depends or Includes?
> 

Well, if your package doesn't depend on it, it should certainly not be in Depends. But that is a design decision (depending on packages outside CRAN is somewhat tricky because in general you cannot guarantee availability, but it is legal ;)).

If you need any additional non-CRAN dependencies on Mac OS X, they can be installed if there are working self-sufficient binaries, you just need to tell me.

Cheers,
Simon


> 
> On Tue, Jan 3, 2012 at 7:42 AM, Uwe Ligges
> <ligges at statistik.tu-dortmund.de>wrote:
> 
>> 
>> 
>> On 03.01.2012 00:16, Steven Lund wrote:
>> 
>>> I know others have asked similar questions to the R developers, but I
>>> could not find the solution to this question.  Please forgive me if I
>>> have missed a crucial point in a previous post.
>>> 
>>> I would like to submit a package to CRAN that depends on the
>>> bioconductor package "edgeR".  Listing "edgeR" under the Depends or
>>> Imports lines in the DESCRIPTION file for my package causes an error
>>> when running the `R CMD check' command on my package's 'tar.gz' file:
>>> 
>>> * checking package dependencies ... ERROR
>>> Package required but not available: ?edgeR?
>>> 
>>> 
>>> Is there documentation or an example anywhere of how to handle
>>> dependencies on Bioconductor packages when creating a package for
>>> CRAN?
>>> 
>> 
>> 
>> Same as for CRAN packages. The CRAN check farm will automatically install
>> the dependency from BioConductor if available for the corresponding
>> platform / R version.
>> 
>> Uwe Ligges
>> 
>> 
>> 
>> 
>> 
>>> Thank you!
>>> 
>>> -Steve
>>> 
>>> ______________________________**________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/**listinfo/r-devel<https://stat.ethz.ch/mailman/listinfo/r-devel>
>>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From mtmorgan at fhcrc.org  Tue May  8 17:56:20 2012
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Tue, 8 May 2012 08:56:20 -0700
Subject: [Rd] How to list package dependency on a Bioconductor package?
In-Reply-To: <02FFE7E8-4543-4368-9028-BA04EB893322@r-project.org>
References: <CAMe5z5nqAOk7hWXZ8ePs8XsPv=cSk8zO1vrm3doDZA4k+buhFQ@mail.gmail.com>
	<4F02F7BF.4040606@statistik.tu-dortmund.de>
	<CAMe5z5m=6=hdN8Ne4+p3XquTRYFZZAHWQovHjkgZKmV2oYzaiA@mail.gmail.com>
	<02FFE7E8-4543-4368-9028-BA04EB893322@r-project.org>
Message-ID: <4FA94224.8060908@fhcrc.org>

On 5/8/2012 8:44 AM, Simon Urbanek wrote:
> Steven,
>
> On May 7, 2012, at 1:24 PM, Steven Lund wrote:
>
>> I recently submit a package called QuasiSeq.  The package source and
>> Windows binary worked fine, but the MacOS X binary failed. The bottom of
>> the CRAN page for QuasiSeq shows
>>
>> Downloads:
>>   Package source:     QuasiSeq_1.0-1.tar.gz
>>   MacOS X binary:     not available, see check log.
>>   Windows binary:     QuasiSeq-1.0-1.zip
>>   Reference manual:  QuasiSeq.pdf
>>
>>
>> The log for the MacOS X binary shows
>>    - using R version 2.15.0 (2012-03-30)
>>    - using platform: i386-apple-darwin9.8.0 (32-bit)
>>    -  using session charset: ASCII
>>    -  checking for file 'QuasiSeq/DESCRIPTION' ... OK
>>    -  this is package 'QuasiSeq' version '1.0-1'
>>    -  checking package namespace information ... OK
>>    -  checking package dependencies ... ERROR
>>            Package required but not available: 'edgeR'
>>
>>            See the information on DESCRIPTION files in the chapter
>> 'Creating R
>>            packages' of the 'Writing R Extensions' manual.
>>    -  elapsed time (check, wall clock): 0:01
>>
>> Is there a simple remedy to the problems caused by the dependency on edgeR,
>> or would you advise that I put a work-around into my source code using
>> 'require' so I can list edgeR under Suggests instead of Depends or Includes?
>>
> Well, if your package doesn't depend on it, it should certainly not be in Depends. But that is a design decision (depending on packages outside CRAN is somewhat tricky because in general you cannot guarantee availability, but it is legal ;)).
>
> If you need any additional non-CRAN dependencies on Mac OS X, they can be installed if there are working self-sufficient binaries, you just need to tell me.

We're talking about a Bioconductor package here; the Mac binaries are 
available for R-2-15 
http://bioconductor.org/packages/release/bioc/html/edgeR.html in the 
usual way; the Windows binaries are apparently discovered by the CRAN 
build system, so it sounds like CRAN's Mac builds are mis-configured, or 
Bioconductor's binary builds are inadequate?

Martin
>
> Cheers,
> Simon
>
>
>> On Tue, Jan 3, 2012 at 7:42 AM, Uwe Ligges
>> <ligges at statistik.tu-dortmund.de>wrote:
>>
>>>
>>> On 03.01.2012 00:16, Steven Lund wrote:
>>>
>>>> I know others have asked similar questions to the R developers, but I
>>>> could not find the solution to this question.  Please forgive me if I
>>>> have missed a crucial point in a previous post.
>>>>
>>>> I would like to submit a package to CRAN that depends on the
>>>> bioconductor package "edgeR".  Listing "edgeR" under the Depends or
>>>> Imports lines in the DESCRIPTION file for my package causes an error
>>>> when running the `R CMD check' command on my package's 'tar.gz' file:
>>>>
>>>> * checking package dependencies ... ERROR
>>>> Package required but not available: ?edgeR?
>>>>
>>>>
>>>> Is there documentation or an example anywhere of how to handle
>>>> dependencies on Bioconductor packages when creating a package for
>>>> CRAN?
>>>>
>>>
>>> Same as for CRAN packages. The CRAN check farm will automatically install
>>> the dependency from BioConductor if available for the corresponding
>>> platform / R version.
>>>
>>> Uwe Ligges
>>>
>>>
>>>
>>>
>>>
>>>> Thank you!
>>>>
>>>> -Steve
>>>>
>>>> ______________________________**________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/**listinfo/r-devel<https://stat.ethz.ch/mailman/listinfo/r-devel>
>>>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Dr. Martin Morgan, PhD
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109


From murdoch.duncan at gmail.com  Tue May  8 18:35:40 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 08 May 2012 12:35:40 -0400
Subject: [Rd] file 2 is not in sorted order error building unsuffered
 consequences
In-Reply-To: <CANz9Z_KsoyU_ym0xUbRV30Rn-_=h2+--bX6crDZ0hmLXdnCN8w@mail.gmail.com>
References: <CANz9Z_JT0O52UXm0px1U2=KLxg=QHKLz6_1=xFSFs+Un5odE3w@mail.gmail.com>
	<4FA8F9F1.8090706@gmail.com>
	<CANz9Z_KsoyU_ym0xUbRV30Rn-_=h2+--bX6crDZ0hmLXdnCN8w@mail.gmail.com>
Message-ID: <4FA94B5C.9000503@gmail.com>

This time it was a similar error on a different file.  Now fixed.

Duncan Murdoch

On 08/05/2012 11:20 AM, Joshua Wiley wrote:
> On Tue, May 8, 2012 at 3:48 AM, Duncan Murdoch<murdoch.duncan at gmail.com>  wrote:
> >  On 12-05-08 1:46 AM, Joshua Wiley wrote:
> >>
> >>  Hi All,
> >>
> >>  I just downloaded the source tar ball (Revision: 59324 Last Changed
> >>  Date: 2012-05-07) and tried to compile on a Win x64 system.  I am
> >>  using Rtools version 2.15.0.1919.  The only change I make is changing
> >>  MkRules.dist ->    MkRules.local and setting Multi=64  I have previously
> >>  compiled unsuffered consquences without issue, but on the current
> >>  version, I get this error
> >>
> >>
> >>  windres -F pe-x86-64  -I../include -i dllversion.rc -o dllversion.o
> >>  comm: file 2 is not in sorted order
> >>  make[3]: *** [R.dll] Error 1
> >>  make[2]: *** [../../bin/x64/R.dll] Error 2
> >>  make[1]: *** [rbuild] Error 2
> >>  make: *** [all] Error 2
> >>
> >>  I did not note any other errors or warnings earlier on, though I may
> >>  have missed some.  I can provide the full log if requested.  Any
> >>  ideas?
> >
> >
> >  I believe that message is about the file src/gnuwin32/Rdll.hide.  It is
> >  supposed to be sorted, using ASCII collation order.  I believe the version
> >  in the repository is sorted properly; can you check yours?
>
> Thanks for your reply.  It looks sorted correctly and explicitly
> sorting prior to running make does not change the error.  here is a
> bit of output:
>
> BZ2_bzBuffToBuffCompress at 28
> BZ2_bzBuffToBuffDecompress at 24
> BZ2_bzCompress at 8
> BZ2_bzCompressEnd at 4
> BZ2_bzCompressInit at 16
> BZ2_bzDecompress at 4
> BZ2_bzDecompressEnd at 4
> BZ2_bzDecompressInit at 12
> BZ2_bzRead at 16
> BZ2_bzReadClose at 8
> BZ2_bzReadGetUnused at 16
> BZ2_bzReadOpen at 24
> BZ2_bzWrite at 16
> BZ2_bzWriteClose64 at 28
> BZ2_bzWriteClose at 20
>
> >
> >  We've had some problems with recent versions of Cygwin not sorting properly.
> >    The last instance had it put names in the order
> >
> >    BZ2_bzWriteClose at 20
> >    BZ2_bzWriteClose64 at 28
> >
> >  but ASCII order should put @ after 6.  Are you using the comm and Cygwin
> >  dlls from Rtools, or have you got newer ones?
>
> As far as I know I should only be using the dlls from Rtools.  It is
> the first thing on my path environment variable, and although cygwin
> is installed, I do not even have it on my path.  Interestingly, there
> are no problems if set MULTI=32 instead of 64 in MkRules.
>
> Thanks again,
>
> Josh
>
> >
> >  Duncan Murdoch
>
>
>


From simon.urbanek at r-project.org  Tue May  8 18:52:27 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 8 May 2012 12:52:27 -0400
Subject: [Rd] How to list package dependency on a Bioconductor package?
In-Reply-To: <4FA94224.8060908@fhcrc.org>
References: <CAMe5z5nqAOk7hWXZ8ePs8XsPv=cSk8zO1vrm3doDZA4k+buhFQ@mail.gmail.com>
	<4F02F7BF.4040606@statistik.tu-dortmund.de>
	<CAMe5z5m=6=hdN8Ne4+p3XquTRYFZZAHWQovHjkgZKmV2oYzaiA@mail.gmail.com>
	<02FFE7E8-4543-4368-9028-BA04EB893322@r-project.org>
	<4FA94224.8060908@fhcrc.org>
Message-ID: <16E942D4-07FC-4B05-8C08-DE72C31518CA@r-project.org>


On May 8, 2012, at 11:56 AM, Martin Morgan wrote:

> On 5/8/2012 8:44 AM, Simon Urbanek wrote:
>> Steven,
>> 
>> On May 7, 2012, at 1:24 PM, Steven Lund wrote:
>> 
>>> I recently submit a package called QuasiSeq.  The package source and
>>> Windows binary worked fine, but the MacOS X binary failed. The bottom of
>>> the CRAN page for QuasiSeq shows
>>> 
>>> Downloads:
>>>  Package source:     QuasiSeq_1.0-1.tar.gz
>>>  MacOS X binary:     not available, see check log.
>>>  Windows binary:     QuasiSeq-1.0-1.zip
>>>  Reference manual:  QuasiSeq.pdf
>>> 
>>> 
>>> The log for the MacOS X binary shows
>>>   - using R version 2.15.0 (2012-03-30)
>>>   - using platform: i386-apple-darwin9.8.0 (32-bit)
>>>   -  using session charset: ASCII
>>>   -  checking for file 'QuasiSeq/DESCRIPTION' ... OK
>>>   -  this is package 'QuasiSeq' version '1.0-1'
>>>   -  checking package namespace information ... OK
>>>   -  checking package dependencies ... ERROR
>>>           Package required but not available: 'edgeR'
>>> 
>>>           See the information on DESCRIPTION files in the chapter
>>> 'Creating R
>>>           packages' of the 'Writing R Extensions' manual.
>>>   -  elapsed time (check, wall clock): 0:01
>>> 
>>> Is there a simple remedy to the problems caused by the dependency on edgeR,
>>> or would you advise that I put a work-around into my source code using
>>> 'require' so I can list edgeR under Suggests instead of Depends or Includes?
>>> 
>> Well, if your package doesn't depend on it, it should certainly not be in Depends. But that is a design decision (depending on packages outside CRAN is somewhat tricky because in general you cannot guarantee availability, but it is legal ;)).
>> 
>> If you need any additional non-CRAN dependencies on Mac OS X, they can be installed if there are working self-sufficient binaries, you just need to tell me.
> 
> We're talking about a Bioconductor package here; the Mac binaries are available for R-2-15 http://bioconductor.org/packages/release/bioc/html/edgeR.html in the usual way; the Windows binaries are apparently discovered by the CRAN build system, so it sounds like CRAN's Mac builds are mis-configured, or Bioconductor's binary builds are inadequate?
> 

Neither, nor. 


>> 
>> Cheers,
>> Simon
>> 
>> 
>>> On Tue, Jan 3, 2012 at 7:42 AM, Uwe Ligges
>>> <ligges at statistik.tu-dortmund.de>wrote:
>>> 
>>>> 
>>>> On 03.01.2012 00:16, Steven Lund wrote:
>>>> 
>>>>> I know others have asked similar questions to the R developers, but I
>>>>> could not find the solution to this question.  Please forgive me if I
>>>>> have missed a crucial point in a previous post.
>>>>> 
>>>>> I would like to submit a package to CRAN that depends on the
>>>>> bioconductor package "edgeR".  Listing "edgeR" under the Depends or
>>>>> Imports lines in the DESCRIPTION file for my package causes an error
>>>>> when running the `R CMD check' command on my package's 'tar.gz' file:
>>>>> 
>>>>> * checking package dependencies ... ERROR
>>>>> Package required but not available: ?edgeR?
>>>>> 
>>>>> 
>>>>> Is there documentation or an example anywhere of how to handle
>>>>> dependencies on Bioconductor packages when creating a package for
>>>>> CRAN?
>>>>> 
>>>> 
>>>> Same as for CRAN packages. The CRAN check farm will automatically install
>>>> the dependency from BioConductor if available for the corresponding
>>>> platform / R version.
>>>> 
>>>> Uwe Ligges
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>>> Thank you!
>>>>> 
>>>>> -Steve
>>>>> 
>>>>> ______________________________**________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/**listinfo/r-devel<https://stat.ethz.ch/mailman/listinfo/r-devel>
>>>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> -- 
> Dr. Martin Morgan, PhD
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N.
> PO Box 19024 Seattle, WA 98109
> 
> 


From naras at stanford.edu  Tue May  8 21:13:45 2012
From: naras at stanford.edu (Balasubramanian Narasimhan)
Date: Tue, 08 May 2012 12:13:45 -0700
Subject: [Rd] f951.exe: sorry, unimplemented: 64-bit mode not compiled
In-Reply-To: <2574D55A-B3CE-4759-BD89-BC6B1E936F5F@r-project.org>
References: <4FA478E4.8070803@prodsyse.com>
	<2574D55A-B3CE-4759-BD89-BC6B1E936F5F@r-project.org>
Message-ID: <4FA97069.7010909@stanford.edu>

The original post below refers to an issue that arose with glmnet. It 
has since been fixed but the underlying problem (I believe) is a bug in 
gcc/gfortran 2.6.3 toolchain.  Here is a reproducible example, test.f90.

program dblbug
   real :: x, y
   x=2
   y=exp(dble(x))
end program dblbug

Compile with gfortran -fdefault-real-8 -o test test.f90.

The program will crash on Windows but not on i386 or x86_64 linux (same 
version of toolchain) but I think that says nothing.

Note: The glmnet code was originally written for single precision and 
hence the flag -fdefault-real-8. The fix was to just to remove the "dble."

-Naras



On 5/4/12 6:58 PM, Simon Urbanek wrote:
> On May 4, 2012, at 8:48 PM, Spencer Graves wrote:
>
>> Hello:
>>
>>
>>       Under my Windows 7 system, "R CMD check DiercxkSpline_1.1-5.tar.gz" fails because:
>>
>>
>> f951.exe: sorry, unimplemented: 64-bit mode not compiled in
>>
> This typically means that you're using the wrong (old) compiler. The new MinGW compilers support both -m32 and -m64. You have to set the PATH to the new compilers (in the gcc-4.6.3 subdirectory of Rtools) *before* any old compilers in Rtools.
>
> Cheers,
> Simon
>
>
>> make: *** [bispev.o] Error 1
>> gfortran -m64     -O2  -mtune=core2 -c bispev.f -o bispev.o
>> f951.exe: sorry, unimplemented: 64-bit mode not compiled in
>>
>> make: *** [bispev.o] Error 1
>> ERROR: compilation failed for package 'DierckxSpline'
>>
>>
>>       A similar problem was reported for package "glmnet" (http://stackoverflow.com/questions/10291189/compiling-glmnet-failed-in-windows) plus one with R 2.14.2 (http://r.789695.n4.nabble.com/Problems-when-building-a-package-for-Windows-64-td4464488.html).  However, I get this with R 2.15.0 and the latest R tools (reinstalled earlier today).  On R-Forge, DierckxSpline has "Build status:  Current", which suggests that R-Forge does NOT have this problem.  I read through the two replies to these two earlier questions without seeing how to fix my problem.
>>
>
>
>>       Thanks in advance for any suggestions.
>>
>>
>>       Spencer Graves
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From zalan.szakolci at gmail.com  Wed May  9 00:35:26 2012
From: zalan.szakolci at gmail.com (Zalan Szakolci)
Date: Wed, 9 May 2012 00:35:26 +0200
Subject: [Rd] R CMD check linking errors, when interfacing c++
Message-ID: <CANgFBQK1Qn8EjSd3XsV_8NQka6X23WV_g+97mX7qWRrwtam3MA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120509/7778ef45/attachment.pl>

From edd at debian.org  Wed May  9 14:11:24 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 9 May 2012 07:11:24 -0500
Subject: [Rd] R CMD check linking errors, when interfacing c++
In-Reply-To: <CANgFBQK1Qn8EjSd3XsV_8NQka6X23WV_g+97mX7qWRrwtam3MA@mail.gmail.com>
References: <CANgFBQK1Qn8EjSd3XsV_8NQka6X23WV_g+97mX7qWRrwtam3MA@mail.gmail.com>
Message-ID: <20394.24300.191419.4870@max.nulle.part>


On 9 May 2012 at 00:35, Zalan Szakolci wrote:
| Hi there,
| 
| I am trying to interface c++ code in R and make a package. With R CMD SHLIB
| the dll was created, but when I try R CMD check, I am getting 'undefined
| reference to..' linkage error messages.
| 
| The relevant c++ source from conf-infomap.cpp:

[...]
 
| Now when I run R CMD check, in file 00install.out I am getting the
| following linking errors:
| 
| * installing *source* package ?DyA? ...
| ** libs
| ** arch -
| g++ -I/usr/share/R/include -DNDEBUG      -fpic  -I -Wall -O3 -funroll-loops
| -pipe -c conf-infomap.cpp -o conf-infomap.o
| g++ -I/usr/share/R/include -DNDEBUG      -fpic  -I -Wall -O3 -funroll-loops
| -pipe -c GreedyBase.cpp -o GreedyBase.o
| g++ -I/usr/share/R/include -DNDEBUG      -fpic  -I -Wall -O3 -funroll-loops
| -pipe -c Greedy.cpp -o Greedy.o
| g++ -I/usr/share/R/include -DNDEBUG      -fpic  -I -Wall -O3 -funroll-loops
| -pipe -c Node.cc -o Node.o
| g++ conf-infomap.o GreedyBase.o Greedy.o Node.o mersenne.cpp stoc1.cpp
| userintf.cpp -lm -o conf-infomap

What is your src/Makevars file?  

This looks very wrong as you are obviously not linking against R itself.

I would recommend a good long look at both the 'Writing R Extensions' manual
as well as some of the existing CRAN packages uses C++ sources.

You can (and should) also try

    R CMD COMPILE ...

    R CMD SHLIB ...

    R CMD INSTALL ...

etc as 'R CMD check' is really only the final bit.

Dirk

-- 
R/Finance 2012 Conference on May 11 and 12, 2012 at UIC in Chicago, IL
See agenda, registration details and more at http://www.RinFinance.com


From zalan.szakolci at gmail.com  Wed May  9 15:10:52 2012
From: zalan.szakolci at gmail.com (Zalan Szakolci)
Date: Wed, 9 May 2012 15:10:52 +0200
Subject: [Rd] R CMD check linking errors, when interfacing c++
In-Reply-To: <20394.24300.191419.4870@max.nulle.part>
References: <CANgFBQK1Qn8EjSd3XsV_8NQka6X23WV_g+97mX7qWRrwtam3MA@mail.gmail.com>
	<20394.24300.191419.4870@max.nulle.part>
Message-ID: <CANgFBQL05eVBZwM_BUnUpKiT_sJ3aWwiq6fc02HebMRW-4kO7w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120509/192dbc28/attachment.pl>

From simon.urbanek at r-project.org  Wed May  9 15:16:38 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 9 May 2012 09:16:38 -0400
Subject: [Rd] R CMD check linking errors, when interfacing c++
In-Reply-To: <CANgFBQL05eVBZwM_BUnUpKiT_sJ3aWwiq6fc02HebMRW-4kO7w@mail.gmail.com>
References: <CANgFBQK1Qn8EjSd3XsV_8NQka6X23WV_g+97mX7qWRrwtam3MA@mail.gmail.com>
	<20394.24300.191419.4870@max.nulle.part>
	<CANgFBQL05eVBZwM_BUnUpKiT_sJ3aWwiq6fc02HebMRW-4kO7w@mail.gmail.com>
Message-ID: <B74D4D2C-E572-483F-819B-649C724EC351@r-project.org>


On May 9, 2012, at 9:10 AM, Zalan Szakolci wrote:

> Hi,
> 
> Thanks for the suggestions. I've forgotten to  point out, that
> 
> R CMD COMPILE and
> R CMD SHLIB
> 
> works fine, the dll file was indeed created. I get these undefined
> references when I'm trying to run R CMD INSTALL.
> 

... which means you are probably doing something silly in Makevars or Makefile (ideally, you should not have either) -- and that's why Dirk was asking you.


> I've read through the "Writing R extensions" and the archives, but I really
> don't know what am I doing wrong.
> 
> More suprising, when I run the same package in windows with R CMD check,
> the dll for src-i386 was created, but not the 64 -bit, i'm getting: sorry,
> 64 bit compilation not supported (or someting similar)
> 

You have the wrong toolchain on your PATH (see recent question here).

Cheers,
Simon



> If anyone have an idea, comments welcome.
> 
> Thanks,
> 
> Zalan
> 
> On 9 May 2012 14:11, Dirk Eddelbuettel <edd at debian.org> wrote:
> 
>> 
>> On 9 May 2012 at 00:35, Zalan Szakolci wrote:
>> | Hi there,
>> |
>> | I am trying to interface c++ code in R and make a package. With R CMD
>> SHLIB
>> | the dll was created, but when I try R CMD check, I am getting 'undefined
>> | reference to..' linkage error messages.
>> |
>> | The relevant c++ source from conf-infomap.cpp:
>> 
>> [...]
>> 
>> | Now when I run R CMD check, in file 00install.out I am getting the
>> | following linking errors:
>> |
>> | * installing *source* package ?DyA? ...
>> | ** libs
>> | ** arch -
>> | g++ -I/usr/share/R/include -DNDEBUG      -fpic  -I -Wall -O3
>> -funroll-loops
>> | -pipe -c conf-infomap.cpp -o conf-infomap.o
>> | g++ -I/usr/share/R/include -DNDEBUG      -fpic  -I -Wall -O3
>> -funroll-loops
>> | -pipe -c GreedyBase.cpp -o GreedyBase.o
>> | g++ -I/usr/share/R/include -DNDEBUG      -fpic  -I -Wall -O3
>> -funroll-loops
>> | -pipe -c Greedy.cpp -o Greedy.o
>> | g++ -I/usr/share/R/include -DNDEBUG      -fpic  -I -Wall -O3
>> -funroll-loops
>> | -pipe -c Node.cc -o Node.o
>> | g++ conf-infomap.o GreedyBase.o Greedy.o Node.o mersenne.cpp stoc1.cpp
>> | userintf.cpp -lm -o conf-infomap
>> 
>> What is your src/Makevars file?
>> 
>> This looks very wrong as you are obviously not linking against R itself.
>> 
>> I would recommend a good long look at both the 'Writing R Extensions'
>> manual
>> as well as some of the existing CRAN packages uses C++ sources.
>> 
>> You can (and should) also try
>> 
>>   R CMD COMPILE ...
>> 
>>   R CMD SHLIB ...
>> 
>>   R CMD INSTALL ...
>> 
>> etc as 'R CMD check' is really only the final bit.
>> 
>> Dirk
>> 
>> --
>> R/Finance 2012 Conference on May 11 and 12, 2012 at UIC in Chicago, IL
>> See agenda, registration details and more at http://www.RinFinance.com
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From szakolci at petabyte-research.org  Wed May  9 15:28:56 2012
From: szakolci at petabyte-research.org (Zalan Szakolci)
Date: Wed, 9 May 2012 15:28:56 +0200
Subject: [Rd] R CMD check linking errors, when interfacing c++
In-Reply-To: <B74D4D2C-E572-483F-819B-649C724EC351@r-project.org>
References: <CANgFBQK1Qn8EjSd3XsV_8NQka6X23WV_g+97mX7qWRrwtam3MA@mail.gmail.com>
	<20394.24300.191419.4870@max.nulle.part>
	<CANgFBQL05eVBZwM_BUnUpKiT_sJ3aWwiq6fc02HebMRW-4kO7w@mail.gmail.com>
	<B74D4D2C-E572-483F-819B-649C724EC351@r-project.org>
Message-ID: <CANgFBQL-bkdUzUeF03bTN1GT9x+qkehU9tcHGkY2-YfAN9H45g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120509/5b6a9886/attachment.pl>

From Avraham.Adler at guycarp.com  Wed May  9 20:54:17 2012
From: Avraham.Adler at guycarp.com (Adler, Avraham)
Date: Wed, 9 May 2012 13:54:17 -0500
Subject: [Rd] R Installation Manual - ATLAS BLAS guidance that is not in the
 current version
Message-ID: <93A2161604A30C4ABE14AC35CAFC8422B63CF2F4@USDFW11XM32.mercer.com>

Good afternoon.

I am trying to compile a version of Rblas.dll based on ATLAS for the Corei7. I had remembered that there was mention of which file to adjust and that "xerbla" needed to be removed from one of the outputs from the last time I tried a few years ago. The most recent version of the R Installation manual does not say anything about this. An older version (2.10 I believe) has the following text:

      Optionally, you can install a version of ATLAS
      (`math-atlas.sourceforge.net'
      (http://math-atlas.sourceforge.net/)) tuned to your system for
      fast linear algebra routines. Pre-built `Rblas.dll' for various
      Pentium and AthlonXP chips are available in the
      `windows/contrib/ATLAS' area on CRAN.  If you are building R from
      source, there are macros `USE_ATLAS' and `ATLAS_PATH' in the file
      `MkRules'.  Set `USE_ATLAS = YES' and `ATLAS_PATH' to where the
      ATLAS libraries are located.  You will need to make the libraries
      yourself(1): none of the binaries we have seen are compiled for
      the correct compiler.  Since R has its own `xerbla' it is best to
      delete that in ATLAS by
 
           ar d /path/to/libf77blas.a xerbla.o

Would it be possible to restore the above information to the next version of the manual for future reference, please?
 
Thank you,

Avraham Adler

From renaud at mancala.cbio.uct.ac.za  Thu May 10 10:25:05 2012
From: renaud at mancala.cbio.uct.ac.za (Renaud Gaujoux)
Date: Thu, 10 May 2012 10:25:05 +0200
Subject: [Rd] url, readLines, source behind a proxy
In-Reply-To: <CAFDcVCQ4y=1wjz-mc0KUjhyTvgBW929Ja3qFHk2W615rSyeARw@mail.gmail.com>
References: <4F8D234E.1070709@cbio.uct.ac.za>
	<CAFDcVCQx1R7gJYnOPC3yzayJxi-Ts9zzaQd5T0bFSnLcOv8nCg@mail.gmail.com>
	<Pine.LNX.4.64.1204180705060.27275@mancala.cbio.uct.ac.za>
	<CAPPM_gS7LA-rv=__y_QbUi4ketxT9dn3PU=6dm+Sv9q5nU8nkw@mail.gmail.com>
	<4F957794.5090806@stats.ox.ac.uk> <4F96A0B9.4090108@cbio.uct.ac.za>
	<CAFDcVCQ4y=1wjz-mc0KUjhyTvgBW929Ja3qFHk2W615rSyeARw@mail.gmail.com>
Message-ID: <4FAB7B61.6090106@cbio.uct.ac.za>

Thanks Henrik for the work around.
It worked perfectly and save me lots of check time.

Renaud

-- 
Renaud Gaujoux
Computational Biology - University of Cape Town
South Africa


On 24/04/2012 17:57, Henrik Bengtsson wrote:
> Looking at the source code (src/library/tools/R/check.R and
> src/library/tools/R/QC.R), I found that...
>
> WORKAROUND:
> You can trick 'R CMD check' to quickly skip the
> "check_package_CRAN_incoming" test by providing it with invalid URLs
> to repositories by setting system environment
> '_R_CHECK_XREFS_REPOSITORIES_' to a non-empty URL. For example:
>
> % export _R_CHECK_XREFS_REPOSITORIES_="invalidURL"
> % R CMD check --as-cran ...
>
> gives:
>
> * checking CRAN incoming feasibility ...NB: need Internet access to
> use CRAN incoming checks
>   OK
>
> /Henrik
>
> On Tue, Apr 24, 2012 at 5:46 AM, Renaud Gaujoux
> <renaud at mancala.cbio.uct.ac.za>  wrote:
>> On 23/04/2012 17:39, Prof Brian Ripley wrote:
>>> On 18/04/2012 16:04, Joshua Ulrich wrote:
>>>> Hi Renaud,
>>>>
>>>> On Wed, Apr 18, 2012 at 12:22 AM, Renaud Gaujoux
>>>> <renaud at mancala.cbio.uct.ac.za>    wrote:
>>>>> Hi Henrik,
>>>>>
>>>> <snip>
>>>>>
>>>>> Could anybody behind a proxy check if the issue can be reproduced?
>>>>> My proxy is in fact provided by cntml, which acts as a local proxy that
>>>>> takes care of tricky authentication protocols with the actual university
>>>>> proxy, not natively supported by my system (Ubuntu). Anybody in this
>>>>> case?
>>>>>
>>>> I can replicate this on a WinXP system, where I normally have to use
>>>> the --internet2 flag to get internet access through a proxy.
>>>>
>>>> ?download.file has a section on "Setting Proxies", which describes how
>>>> to use environment variables to set proxy information.  Setting
>>>> http_proxy='http://my.proxy.com/' was enough for me to get R CMD
>>>> check to run successfully with the --as-cran flag.
>>>
>>> I guess that the simplest way on Windows is to ensure that --internet2 is
>>> set.  In R-patched there is a new environment variable R_WIN_INTERNET2 which
>>> lets you do that (set it in ~/.R/check.Renviron).
>>>
>>> [Setting proxies is so 20th century -- even moderately competent sysadmins
>>> worked out how to use transparent caching proxies ca 1995. Which is why the
>>> R developers give it a low priority.]
>> I completely understand the low priority -- fast-illimited-internet based --
>>   point of view. I wish I could live without such a fussy proxy, but I have
>> not much choice.
>> I like to understand why things work and do not work though.
>> Is there any special feature my proxy should have to allow readLines/source
>> to correctly read remote data? What makes its access different from wget?
>>
>> Thank you for your insights on this.
>>
>>
>>>
>>>>> Thanks.
>>>>> Renaud
>>>>>
>>>> Best,
>>>> --
>>>> Joshua Ulrich  |  FOSS Trading: www.fosstrading.com
>>>>
>>>> R/Finance 2012: Applied Finance with R
>>>> www.RinFinance.com
>>>>
>>>>
>>>>> On Tue, 17 Apr 2012, Henrik Bengtsson wrote:
>>>>>
>>>>>> On Tue, Apr 17, 2012 at 1:01 AM, Renaud Gaujoux
>>>>>> <renaud at mancala.cbio.uct.ac.za>    wrote:
>>>>>>> Hi,
>>>>>>>
>>>>>>> when I run R CMD check with flag --as-cran, the process hangs at
>>>>>>> stage:
>>>>>>>
>>>>>>> * checking CRAN incoming feasibility ...
>>>>>>
>>>>>> Doesn't it time-out eventually?  I'm not behind a proxy but when I've
>>>>>> been running 'R CMD check' whenon very poor 3G connection, it had
>>>>>> eventually timed out.
>>>>>>
>>>>>> /Henrik
>>>>>>
>>>>>>> I am pretty sure it is a proxy issue.
>>>>>>> I looked at the check code in the tools package and it seems that the
>>>>>>> issue
>>>>>>> is in the local function `.repository_db()` (defined in
>>>>>>> `tools:::.check_package_CRAN_incoming()`), which eventually calls
>>>>>>> `url()`
>>>>>>> with argument open="rb", that hangs probably because it does not use
>>>>>>> the
>>>>>>> proxy settings.
>>>>>>> I had a similar issue with `source()`, which apparently uses internal
>>>>>>> network functions (not as download.file), but is supposed to work
>>>>>>> behind a
>>>>>>> proxy (correct?).
>>>>>>> Does anybody else have this problem?
>>>>>>>
>>>>>>> I was wondering if there is a way around, as I would like to be able
>>>>>>> to use
>>>>>>> --as-cran for my checks.
>>>>>>> Thank you.
>>>>>>>
>>>>>>> Renaud
>>>>>>>
>>>>>>> --
>>>>>>> Renaud Gaujoux
>>>>>>> Computational Biology - University of Cape Town
>>>>>>> South Africa
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-devel at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From Avraham.Adler at guycarp.com  Thu May 10 01:25:14 2012
From: Avraham.Adler at guycarp.com (Adler, Avraham)
Date: Wed, 9 May 2012 18:25:14 -0500
Subject: [Rd] Compiling R on Windows XP - Rgui crashes yet Rterm works
Message-ID: <93A2161604A30C4ABE14AC35CAFC8422B63CF5A2@USDFW11XM32.mercer.com>

Hello.

I am trying to build R on Windows. It appears that my build passes the various "make checks" (unless I missed some error) and running Rterm seems to work fine whereas Rgui has an immediate error stating "

	AppName: rgui.exe AppVer: 2.150.58871.0 ModName: rzlib.dll

	ModVer: 0.0.0.0 Offset: 0000a9e5

The taskbar still works, but the console window has nothing in it, and trying to open a script drops me back to Windows.

Even though it seemingly passing make check-all, I ran 'testInstalledBasic ("both")' in the terminal and received the same error that was addressed here in 2010 <https://stat.ethz.ch/pipermail/r-help/2010-May/237947.html> and was not addressed here in 2011 <https://stat.ethz.ch/pipermail/r-help/2011-June/282354.html>: that primitives fail on >=.

I'm not certain if this affects anything, as in Rterm, the >= comparison works fine (4 >= 5 returns FALSE and 4 >= 1 returns TRUE).

Be that as it may, it would be very helpful to find out what would cause the compiled R to have Rgui not work properly yet pass all the checks? I'd rather use the gui than the terminal, for what it is worth.

If it helps, I have been using the following:

Tarball - R-2.15.0.tar.gz
Rtools - 2.15
	CYGWIN 1.7 already installed (for ATLAS) so Rtools CYGWIN dlls NOT installed
	Tcl/tk, libjpeg, libpng, libtiff all installed
cairo-current-win.tar.gz

The only other change I made was to set EOPTS=-march=corei7 as the GCC included in the toolchain in 4.6.3 which recognizes the i7 (as opposed to Cygwin which is using 4.5.3 and only recognizes the core2).

My computer is a Lenovo W520 with a Core i7 2760QM running Windows XP Professional.

If there is any other information that would be helpful in uncovering why this is happening, please let me know.


Thank you very much,

Avraham Adler

PS: Copying the compiled Rblas.dll over to my regular R install (binary from the CRAN) seems to work just fine and provides a significant speedup in matrix operations in the few tests that I have done.

From sanre6 at gmail.com  Thu May 10 11:07:22 2012
From: sanre6 at gmail.com (sanre6)
Date: Thu, 10 May 2012 02:07:22 -0700 (PDT)
Subject: [Rd] Can two RConnection's  interact with one another ?
Message-ID: <1336640842643-4622951.post@n4.nabble.com>

Hi ,

     Can two R connections(may be instantiated on the same Rserve Server or
on different servers) communicate with each other ? is something like JAVA
RMI is possible between two R sessions    


thanks
sanre6

--
View this message in context: http://r.789695.n4.nabble.com/Can-two-RConnection-s-interact-with-one-another-tp4622951.html
Sent from the R devel mailing list archive at Nabble.com.


From jwiley.psych at gmail.com  Thu May 10 14:36:10 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Thu, 10 May 2012 05:36:10 -0700
Subject: [Rd] file 2 is not in sorted order error building unsuffered
	consequences
In-Reply-To: <4FA94B5C.9000503@gmail.com>
References: <CANz9Z_JT0O52UXm0px1U2=KLxg=QHKLz6_1=xFSFs+Un5odE3w@mail.gmail.com>
	<4FA8F9F1.8090706@gmail.com>
	<CANz9Z_KsoyU_ym0xUbRV30Rn-_=h2+--bX6crDZ0hmLXdnCN8w@mail.gmail.com>
	<4FA94B5C.9000503@gmail.com>
Message-ID: <CANz9Z_LgQUKF6f_UKf7_DOOPbNEUr-Fvhg94VS_Bc-j3KNFKAg@mail.gmail.com>

On Tue, May 8, 2012 at 9:35 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> This time it was a similar error on a different file. ?Now fixed.

Works wonderfully now, thank you so much, Duncan!

>
> Duncan Murdoch
>
>
> On 08/05/2012 11:20 AM, Joshua Wiley wrote:
>>
>> On Tue, May 8, 2012 at 3:48 AM, Duncan Murdoch<murdoch.duncan at gmail.com>
>> ?wrote:
>> > ?On 12-05-08 1:46 AM, Joshua Wiley wrote:
>> >>
>> >> ?Hi All,
>> >>
>> >> ?I just downloaded the source tar ball (Revision: 59324 Last Changed
>> >> ?Date: 2012-05-07) and tried to compile on a Win x64 system. ?I am
>> >> ?using Rtools version 2.15.0.1919. ?The only change I make is changing
>> >> ?MkRules.dist -> ? ?MkRules.local and setting Multi=64 ?I have
>> >> previously
>> >> ?compiled unsuffered consquences without issue, but on the current
>> >> ?version, I get this error
>> >>
>> >>
>> >> ?windres -F pe-x86-64 ?-I../include -i dllversion.rc -o dllversion.o
>> >> ?comm: file 2 is not in sorted order
>> >> ?make[3]: *** [R.dll] Error 1
>> >> ?make[2]: *** [../../bin/x64/R.dll] Error 2
>> >> ?make[1]: *** [rbuild] Error 2
>> >> ?make: *** [all] Error 2
>> >>
>> >> ?I did not note any other errors or warnings earlier on, though I may
>> >> ?have missed some. ?I can provide the full log if requested. ?Any
>> >> ?ideas?
>> >
>> >
>> > ?I believe that message is about the file src/gnuwin32/Rdll.hide. ?It is
>> > ?supposed to be sorted, using ASCII collation order. ?I believe the
>> > version
>> > ?in the repository is sorted properly; can you check yours?
>>
>> Thanks for your reply. ?It looks sorted correctly and explicitly
>> sorting prior to running make does not change the error. ?here is a
>> bit of output:
>>
>> BZ2_bzBuffToBuffCompress at 28
>> BZ2_bzBuffToBuffDecompress at 24
>> BZ2_bzCompress at 8
>> BZ2_bzCompressEnd at 4
>> BZ2_bzCompressInit at 16
>> BZ2_bzDecompress at 4
>> BZ2_bzDecompressEnd at 4
>> BZ2_bzDecompressInit at 12
>> BZ2_bzRead at 16
>> BZ2_bzReadClose at 8
>> BZ2_bzReadGetUnused at 16
>> BZ2_bzReadOpen at 24
>> BZ2_bzWrite at 16
>> BZ2_bzWriteClose64 at 28
>> BZ2_bzWriteClose at 20
>>
>> >
>> > ?We've had some problems with recent versions of Cygwin not sorting
>> > properly.
>> > ? ?The last instance had it put names in the order
>> >
>> > ? ?BZ2_bzWriteClose at 20
>> > ? ?BZ2_bzWriteClose64 at 28
>> >
>> > ?but ASCII order should put @ after 6. ?Are you using the comm and
>> > Cygwin
>> > ?dlls from Rtools, or have you got newer ones?
>>
>> As far as I know I should only be using the dlls from Rtools. ?It is
>> the first thing on my path environment variable, and although cygwin
>> is installed, I do not even have it on my path. ?Interestingly, there
>> are no problems if set MULTI=32 instead of 64 in MkRules.
>>
>> Thanks again,
>>
>> Josh
>>
>> >
>> > ?Duncan Murdoch
>>
>>
>>
>



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From friendly at yorku.ca  Thu May 10 15:59:10 2012
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 10 May 2012 09:59:10 -0400
Subject: [Rd] setting global options for a package
Message-ID: <4FABC9AE.20103@yorku.ca>

This may be elementary, but I can't find an answer: How can I set up 
global options for
some specific arguments to functions in a package which can be easily 
changed by the user?

This question relates to the selection of colors used in functions in 
several packages (heplots,
genridge), where I want to provide reasonable default values for plots, 
but allow users to
change those defaults globally for all plots produced with my functions.

One solution is to use palette() for the default, as in

foo <- function(x, col=palette(), ...)  {}
but the standard palette is not appropriate for my use, and I'd rather 
not hijack more typical uses

Another is to use an explicit list of colors for default, as in

bar <- function(x, col=c('red', 'blue', 'brown', 'darkgreen', ...), ...)  {}
but this must be overridden each time by someone to wants to change the 
defaults.

options() seems like the way to go, but I'm not sure how to implement 
this.  If I use
a .onLoad function to set some options, will these be created in the 
global environment?
If not, how to make them so?

.onLoad <- function() {
   options(heplot.colors =
   c("red", "blue", "black", "darkgreen", "darkcyan","magenta", 
"brown","darkgray"))
}

My function could then use

foo <- function(x, getOption("heplot.colors"), ...)  {}


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From kw.stat at gmail.com  Thu May 10 18:48:16 2012
From: kw.stat at gmail.com (Kevin Wright)
Date: Thu, 10 May 2012 11:48:16 -0500
Subject: [Rd] setting global options for a package
In-Reply-To: <4FABC9AE.20103@yorku.ca>
References: <4FABC9AE.20103@yorku.ca>
Message-ID: <CAKFxdiRBti4ZeBX9wpXbW_Jx1CxqgQm6EXny_ikdZ-YLTJ-bWA@mail.gmail.com>

Have you considered the lattice package?  The defaults can be
accessed/changed via trellis.par.get(), but also passed as arguments
into the functions.

Kevin


On Thu, May 10, 2012 at 8:59 AM, Michael Friendly <friendly at yorku.ca> wrote:
> This may be elementary, but I can't find an answer: How can I set up global
> options for
> some specific arguments to functions in a package which can be easily
> changed by the user?
>
> This question relates to the selection of colors used in functions in
> several packages (heplots,
> genridge), where I want to provide reasonable default values for plots, but
> allow users to
> change those defaults globally for all plots produced with my functions.
>
> One solution is to use palette() for the default, as in
>
> foo <- function(x, col=palette(), ...) ?{}
> but the standard palette is not appropriate for my use, and I'd rather not
> hijack more typical uses
>
> Another is to use an explicit list of colors for default, as in
>
> bar <- function(x, col=c('red', 'blue', 'brown', 'darkgreen', ...), ...) ?{}
> but this must be overridden each time by someone to wants to change the
> defaults.
>
> options() seems like the way to go, but I'm not sure how to implement this.
> ?If I use
> a .onLoad function to set some options, will these be created in the global
> environment?
> If not, how to make them so?
>
> .onLoad <- function() {
> ?options(heplot.colors =
> ?c("red", "blue", "black", "darkgreen", "darkcyan","magenta",
> "brown","darkgray"))
> }
>
> My function could then use
>
> foo <- function(x, getOption("heplot.colors"), ...) ?{}
>
>
> --
> Michael Friendly ? ? Email: friendly AT yorku DOT ca
> Professor, Psychology Dept.
> York University ? ? ?Voice: 416 736-5115 x66249 Fax: 416 736-5814
> 4700 Keele Street ? ?Web: ? http://www.datavis.ca
> Toronto, ONT ?M3J 1P3 CANADA
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Kevin Wright


From simon.urbanek at r-project.org  Thu May 10 19:09:45 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 10 May 2012 13:09:45 -0400
Subject: [Rd] setting global options for a package
In-Reply-To: <4FABC9AE.20103@yorku.ca>
References: <4FABC9AE.20103@yorku.ca>
Message-ID: <A487C006-8AA8-4914-A304-61729300C906@r-project.org>


On May 10, 2012, at 9:59 AM, Michael Friendly wrote:

> This may be elementary, but I can't find an answer: How can I set up global options for
> some specific arguments to functions in a package which can be easily changed by the user?
> 
> This question relates to the selection of colors used in functions in several packages (heplots,
> genridge), where I want to provide reasonable default values for plots, but allow users to
> change those defaults globally for all plots produced with my functions.
> 
> One solution is to use palette() for the default, as in
> 
> foo <- function(x, col=palette(), ...)  {}
> but the standard palette is not appropriate for my use, and I'd rather not hijack more typical uses
> 
> Another is to use an explicit list of colors for default, as in
> 
> bar <- function(x, col=c('red', 'blue', 'brown', 'darkgreen', ...), ...)  {}
> but this must be overridden each time by someone to wants to change the defaults.
> 
> options() seems like the way to go, but I'm not sure how to implement this.  If I use
> a .onLoad function to set some options, will these be created in the global environment?
> If not, how to make them so?
> 
> .onLoad <- function() {
>  options(heplot.colors =
>  c("red", "blue", "black", "darkgreen", "darkcyan","magenta", "brown","darkgray"))

You certainly don't want to do that - it would override user's setting and thus defeat the whole purpose of options.


> }
> 
> My function could then use
> 
> foo <- function(x, getOption("heplot.colors"), ...)  {}
> 

You can always do that:

foo <- function(x, heplot.colors = getOption("heplot.colors"), ...)  {
  if (is.null(heplot.colors)) heplot.colors <- c("red", "blue", "black", "darkgreen", "darkcyan","magenta", "brown","darkgray")

Cheers,
Simon


> 
> -- 
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept.
> York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:   http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From duncan at wald.ucdavis.edu  Thu May 10 19:53:25 2012
From: duncan at wald.ucdavis.edu (Duncan Temple Lang)
Date: Thu, 10 May 2012 10:53:25 -0700
Subject: [Rd] setting global options for a package
In-Reply-To: <A487C006-8AA8-4914-A304-61729300C906@r-project.org>
References: <4FABC9AE.20103@yorku.ca>
	<A487C006-8AA8-4914-A304-61729300C906@r-project.org>
Message-ID: <4FAC0095.10802@wald.ucdavis.edu>


Or slightly more conveniently, use the default value of getOption() to return the vector
of color names if the option is not set, e.g.

 foo <- function(x, heplot.colors = getOption("heplot.colors",
                                               c("red", "blue", "black", "darkgreen", "brown", "darkgray")), ...)  {


   D.

On 5/10/12 10:09 AM, Simon Urbanek wrote:
> 
> On May 10, 2012, at 9:59 AM, Michael Friendly wrote:
> 
>> This may be elementary, but I can't find an answer: How can I set up global options for
>> some specific arguments to functions in a package which can be easily changed by the user?
>>
>> This question relates to the selection of colors used in functions in several packages (heplots,
>> genridge), where I want to provide reasonable default values for plots, but allow users to
>> change those defaults globally for all plots produced with my functions.
>>
>> One solution is to use palette() for the default, as in
>>
>> foo <- function(x, col=palette(), ...)  {}
>> but the standard palette is not appropriate for my use, and I'd rather not hijack more typical uses
>>
>> Another is to use an explicit list of colors for default, as in
>>
>> bar <- function(x, col=c('red', 'blue', 'brown', 'darkgreen', ...), ...)  {}
>> but this must be overridden each time by someone to wants to change the defaults.
>>
>> options() seems like the way to go, but I'm not sure how to implement this.  If I use
>> a .onLoad function to set some options, will these be created in the global environment?
>> If not, how to make them so?
>>
>> .onLoad <- function() {
>>  options(heplot.colors =
>>  c("red", "blue", "black", "darkgreen", "darkcyan","magenta", "brown","darkgray"))
> 
> You certainly don't want to do that - it would override user's setting and thus defeat the whole purpose of options.
> 
> 
>> }
>>
>> My function could then use
>>
>> foo <- function(x, getOption("heplot.colors"), ...)  {}
>>
> 
> You can always do that:
> 
> foo <- function(x, heplot.colors = getOption("heplot.colors"), ...)  {
>   if (is.null(heplot.colors)) heplot.colors <- c("red", "blue", "black", "darkgreen", "darkcyan","magenta", "brown","darkgray")
> 
> Cheers,
> Simon
> 
> 
>>
>> -- 
>> Michael Friendly     Email: friendly AT yorku DOT ca
>> Professor, Psychology Dept.
>> York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
>> 4700 Keele Street    Web:   http://www.datavis.ca
>> Toronto, ONT  M3J 1P3 CANADA
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Thu May 10 20:10:47 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 10 May 2012 14:10:47 -0400
Subject: [Rd] setting global options for a package
In-Reply-To: <4FAC0095.10802@wald.ucdavis.edu>
References: <4FABC9AE.20103@yorku.ca>
	<A487C006-8AA8-4914-A304-61729300C906@r-project.org>
	<4FAC0095.10802@wald.ucdavis.edu>
Message-ID: <4FAC04A7.7020703@gmail.com>

On 10/05/2012 1:53 PM, Duncan Temple Lang wrote:
> Or slightly more conveniently, use the default value of getOption() to return the vector
> of color names if the option is not set, e.g.
>
>   foo<- function(x, heplot.colors = getOption("heplot.colors",
>                                                 c("red", "blue", "black", "darkgreen", "brown", "darkgray")), ...)  {

If each option is only used in a small number of places, that's the 
easiest solution.  If they are used more widely, you have the problem of 
keeping the defaults consistent.  Several packages do their own 
home-brewed solutions to this.  In rgl it's done by having a package 
global variable r3dDefaults.  If a user changes it, they get their own 
copy in the global environment.  This means functions within rgl
need to use

get("r3dDefaults", envir=.GlobalEnv)

to do the lookups in the right place.

The igraph package also handles defaults for graph colors; I haven't 
really looked into how they did it.

You can do it using lexical scoping:  something like

myOptions <- local({
    opt1 <- default1
    opt2 <- default2
    function(...) {
       # If ... has no names, it's asking for values; if it has names, 
then change
       # the parents.  Or just create two functions, one for setting, 
one for getting.
   }
)

Duncan Murdoch


>
>     D.
>
> On 5/10/12 10:09 AM, Simon Urbanek wrote:
> >
> >  On May 10, 2012, at 9:59 AM, Michael Friendly wrote:
> >
> >>  This may be elementary, but I can't find an answer: How can I set up global options for
> >>  some specific arguments to functions in a package which can be easily changed by the user?
> >>
> >>  This question relates to the selection of colors used in functions in several packages (heplots,
> >>  genridge), where I want to provide reasonable default values for plots, but allow users to
> >>  change those defaults globally for all plots produced with my functions.
> >>
> >>  One solution is to use palette() for the default, as in
> >>
> >>  foo<- function(x, col=palette(), ...)  {}
> >>  but the standard palette is not appropriate for my use, and I'd rather not hijack more typical uses
> >>
> >>  Another is to use an explicit list of colors for default, as in
> >>
> >>  bar<- function(x, col=c('red', 'blue', 'brown', 'darkgreen', ...), ...)  {}
> >>  but this must be overridden each time by someone to wants to change the defaults.
> >>
> >>  options() seems like the way to go, but I'm not sure how to implement this.  If I use
> >>  a .onLoad function to set some options, will these be created in the global environment?
> >>  If not, how to make them so?
> >>
> >>  .onLoad<- function() {
> >>   options(heplot.colors =
> >>   c("red", "blue", "black", "darkgreen", "darkcyan","magenta", "brown","darkgray"))
> >
> >  You certainly don't want to do that - it would override user's setting and thus defeat the whole purpose of options.
> >
> >
> >>  }
> >>
> >>  My function could then use
> >>
> >>  foo<- function(x, getOption("heplot.colors"), ...)  {}
> >>
> >
> >  You can always do that:
> >
> >  foo<- function(x, heplot.colors = getOption("heplot.colors"), ...)  {
> >    if (is.null(heplot.colors)) heplot.colors<- c("red", "blue", "black", "darkgreen", "darkcyan","magenta", "brown","darkgray")
> >
> >  Cheers,
> >  Simon
> >
> >
> >>
> >>  -- 
> >>  Michael Friendly     Email: friendly AT yorku DOT ca
> >>  Professor, Psychology Dept.
> >>  York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
> >>  4700 Keele Street    Web:   http://www.datavis.ca
> >>  Toronto, ONT  M3J 1P3 CANADA
> >>
> >>  ______________________________________________
> >>  R-devel at r-project.org mailing list
> >>  https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >>
> >
> >  ______________________________________________
> >  R-devel at r-project.org mailing list
> >  https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Avraham.Adler at guycarp.com  Thu May 10 19:55:32 2012
From: Avraham.Adler at guycarp.com (Adler, Avraham)
Date: Thu, 10 May 2012 12:55:32 -0500
Subject: [Rd] Compiling R on Windows XP - Rgui crashes yet Rterm works
In-Reply-To: <E2263553A9D87A41A3E0E1B6FA4F19CACA9608B3@USDFW11XM32.mercer.com>
References: <E2263553A9D87A41A3E0E1B6FA4F19CACA9608B3@USDFW11XM32.mercer.com>
Message-ID: <93A2161604A30C4ABE14AC35CAFC8422B63CFA66@USDFW11XM32.mercer.com>

 
I think I found the issue (through blind luck). When I recompiled without using -march=corei7 and instead leaving it as -mtune=core2 allows the gui to load properly. Now it seems to pass the tools library tests as well.

Thank you.

--Avraham Adler



-----Original Message-----
From: Adler, Avraham 
Sent: Wednesday, May 09, 2012 7:25 PM
To: 'r-devel at r-project.org'
Subject: Compiling R on Windows XP - Rgui crashes yet Rterm works

Hello.

I am trying to build R on Windows. It appears that my build passes the various "make checks" (unless I missed some error) and running Rterm seems to work fine whereas Rgui has an immediate error stating "

	AppName: rgui.exe AppVer: 2.150.58871.0 ModName: rzlib.dll

	ModVer: 0.0.0.0 Offset: 0000a9e5

The taskbar still works, but the console window has nothing in it, and trying to open a script drops me back to Windows.

Even though it seemingly passing make check-all, I ran 'testInstalledBasic ("both")' in the terminal and received the same error that was addressed here in 2010 <https://stat.ethz.ch/pipermail/r-help/2010-May/237947.html> and was not addressed here in 2011 <https://stat.ethz.ch/pipermail/r-help/2011-June/282354.html>: that primitives fail on >=.

I'm not certain if this affects anything, as in Rterm, the >= comparison works fine (4 >= 5 returns FALSE and 4 >= 1 returns TRUE).

Be that as it may, it would be very helpful to find out what would cause the compiled R to have Rgui not work properly yet pass all the checks? I'd rather use the gui than the terminal, for what it is worth.

If it helps, I have been using the following:

Tarball - R-2.15.0.tar.gz
Rtools - 2.15
	CYGWIN 1.7 already installed (for ATLAS) so Rtools CYGWIN dlls NOT installed
	Tcl/tk, libjpeg, libpng, libtiff all installed cairo-current-win.tar.gz

The only other change I made was to set EOPTS=-march=corei7 as the GCC included in the toolchain in 4.6.3 which recognizes the i7 (as opposed to Cygwin which is using 4.5.3 and only recognizes the core2).

My computer is a Lenovo W520 with a Core i7 2760QM running Windows XP Professional.

If there is any other information that would be helpful in uncovering why this is happening, please let me know.


Thank you very much,

Avraham Adler

PS: Copying the compiled Rblas.dll over to my regular R install (binary from the CRAN) seems to work just fine and provides a significant speedup in matrix operations in the few tests that I have done.

From mtalbert at usgs.gov  Thu May 10 20:07:27 2012
From: mtalbert at usgs.gov (Marian K Talbert)
Date: Thu, 10 May 2012 12:07:27 -0600
Subject: [Rd] Problems with 64bit dll compile in R-2.15.0
Message-ID: <OF817781D6.31E3D867-ON872579FA.0062E276-872579FA.00638F6D@usgs.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120510/7b39a37c/attachment.pl>

From murdoch.duncan at gmail.com  Fri May 11 13:38:11 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 11 May 2012 07:38:11 -0400
Subject: [Rd] Problems with 64bit dll compile in R-2.15.0
In-Reply-To: <OF817781D6.31E3D867-ON872579FA.0062E276-872579FA.00638F6D@usgs.gov>
References: <OF817781D6.31E3D867-ON872579FA.0062E276-872579FA.00638F6D@usgs.gov>
Message-ID: <4FACFA23.3080509@gmail.com>

On 12-05-10 2:07 PM, Marian K Talbert wrote:
> I built my package under the R version 2.14.1 on windows without any
> problems by first checking for issues using R CMD check (no warnings) and
> then R CMD build to build the tar.gz.  I can install this on version
> 2.14.1 using install.packages(...).  I next tested to see if I could also
> install on version 2.15.0 (also on my computer) using install.packages()
> with the version 2.14.1 tar.gz this failed  with the error message
>
> sorry, unimplemented: 64-bit mode not compiled in
> make: *** [InternalFcts.o] Error 1
> ERROR: compilation failed for package 'Blossom'

The make files have been changed to be compatible with a newer version 
of gcc.  You should update your Rtools installation to get the new one.

Duncan Murdoch

> I then tried to check the package using the 2.15.0 version (after changing
> my path to specify this version).  The R CMD check  reports the following:
> warning:  Clock skew detected.  Your build may be incomplete.
> installing to H:/Desktop/PkgBuild/BlossomPkg.Rcheck/Blossom/libs/i386
>
> *** arch - x64
> make: Warning: File `InternalFcts.f90' has modification time 0.52 s in the
> future
> gfortran -m64   -O2  -mtune=core2 -c  InternalFcts.f90 -o InternalFcts.o
> f951.exe: sorry, unimplemented: 64-bit mode not compiled in
> make: *** [InternalFcts.o] Error 1
> gfortran -m64   -O2  -mtune=core2 -c  InternalFcts.f90 -o InternalFcts.o
> f951.exe: sorry, unimplemented: 64-bit mode not compiled in
> make: *** [InternalFcts.o] Error 1
> ERROR: compilation failed for package 'Blossom'
> * removing
>
> I'm not sure why this issue would come up only on the newest version of R.
>   I'm working on Windows 7 64bit.  My package has some internal code
> written in Fortran and C.  I don't have a makefile in my src but this
> didn't affect anything before so I'm not sure why it would under the new
> version.  Other thoughts I've had are a possible mismatch between some of
> the Rtools and the newer version or R or might there possibly be more
> rigorous checks on the dll build for newer versions?  Anyway, if anyone
> has any insight into what might cause this to break under the new version
> or R, it would be greatly appreciated.   Also when I do build the package
> (using 2.14.1)  it won't install using install.packages() on another
> computer.  Might this be because the other compute lacks the tools
> required to build the dll?  If so, what's the best way to build a tarball
> that can be installed by anyone on their computer which might not have the
> tools require for building packages on windows.
>
> Thanks,
>
> Marian Talbert
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From whorfin at pixar.com  Fri May 11 23:20:13 2012
From: whorfin at pixar.com (Rick Sayre)
Date: Fri, 11 May 2012 14:20:13 -0700
Subject: [Rd] Passing externalptr to .C()
Message-ID: <4FAD828D.1040707@pixar.com>

Greetings.

2.15.0 added this behavior
http://developer.r-project.org/blosxom.cgi/R-devel/NEWS/2012/03/29#n2012-03-29

     o Passing R objects other than atomic vectors, functions, lists and
       environments to .C() is now deprecated and will give a warning.
       Most cases (especially NULL) are actually coding errors.  NULL
       will be disallowed in future.


This seems to make sense, except that this case includes externalptrs.

I have quite a bit of code, designed to interface with various
external hardware devices, which uses this sort of idiom:

# for example
getDeviceInfo <- function(handle) {
     .C("groovyDevice_getDeviceInfo", PACKAGE="groovyDevice",
	handle,			
	status = as.integer(0))[-1]	# skip handle
}

where "handle" was the result of a .Call to a routine which
returned a SEXP which was the result of a R_MakeExternalPtr() call

The "c" routine looked like:
void
groovyDevice_getDeviceInfo(SEXP handle, int *status)
{
     groovyHandle *gh = R_ExternalPtrAddr(handle);
     *status = GroovyStatus(gh);
}

This all used to work fine.  As of 2.15.0, I now get this:
Warning message:
In getDeviceInfo() :
   passing an object of type 'externalptr' to .C (arg 1) is deprecated

Passing the same handle to a .Call() does [of course] work fine.

I thought my usage was exactly as designed.  How then should I be
passing an externalptr to a .C() call?

Cheers


From david.c.sterratt at ed.ac.uk  Fri May 11 23:36:39 2012
From: david.c.sterratt at ed.ac.uk (David Sterratt)
Date: Fri, 11 May 2012 22:36:39 +0100
Subject: [Rd] Replacements for stdout and stderr guaranteed to be open in
 all versions of R
Message-ID: <1336772199.2290.27.camel@mabel>

I maintain the geometry package, which integrates the Qhull C library
(http://qhull.org) into R. The Qhull function I hook into requires an
open FILE handle as one of its arguments. I had set this file handle to
stdout, but now R check NOTEs the presence of stdout, and the CRAN
maintainers asked me to get rid of these NOTEs.

Including the following defines means the checks are passed on CRAN:

#ifdef WIN32
extern FILE * R_Consolefile;
extern FILE * R_Outputfile;
#else
#include <Rinterface.h>
#fi
#undef stderr
#define stderr R_Consolefile
#undef stdout
#define stdout R_Outputfile

However, this does not work on Rgui.exe, when the above leads to a
crash. Looking at
http://svn.r-project.org/R/trunk/src/gnuwin32/system.c
it would appear that R_Consolefile and R_Outputfile only point to open
files when CharacterMode == RTerm, not in GUI mode.

Therefore my question is, are there any replacements for stdout and
stderr that work across all versions of R?

All the best,

David.
-- 
David C Sterratt, Research Fellow. Tel: (+44) 131 651 1739
Institute for Adaptive and Neural Computation
School of Informatics, University of Edinburgh
Informatics Forum, 10 Crichton Street, Edinburgh EH8 9AB, Scotland, UK


From murdoch.duncan at gmail.com  Sat May 12 00:34:25 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 11 May 2012 18:34:25 -0400
Subject: [Rd] Passing externalptr to .C()
In-Reply-To: <4FAD828D.1040707@pixar.com>
References: <4FAD828D.1040707@pixar.com>
Message-ID: <4FAD93F1.5070803@gmail.com>

On 12-05-11 5:20 PM, Rick Sayre wrote:
> Greetings.
>
> 2.15.0 added this behavior
> http://developer.r-project.org/blosxom.cgi/R-devel/NEWS/2012/03/29#n2012-03-29
>
>       o Passing R objects other than atomic vectors, functions, lists and
>         environments to .C() is now deprecated and will give a warning.
>         Most cases (especially NULL) are actually coding errors.  NULL
>         will be disallowed in future.
>
>
> This seems to make sense, except that this case includes externalptrs.
>
> I have quite a bit of code, designed to interface with various
> external hardware devices, which uses this sort of idiom:
>
> # for example
> getDeviceInfo<- function(handle) {
>       .C("groovyDevice_getDeviceInfo", PACKAGE="groovyDevice",
> 	handle,			
> 	status = as.integer(0))[-1]	# skip handle
> }
>
> where "handle" was the result of a .Call to a routine which
> returned a SEXP which was the result of a R_MakeExternalPtr() call
>
> The "c" routine looked like:
> void
> groovyDevice_getDeviceInfo(SEXP handle, int *status)
> {
>       groovyHandle *gh = R_ExternalPtrAddr(handle);
>       *status = GroovyStatus(gh);
> }
>
> This all used to work fine.  As of 2.15.0, I now get this:
> Warning message:
> In getDeviceInfo() :
>     passing an object of type 'externalptr' to .C (arg 1) is deprecated
>
> Passing the same handle to a .Call() does [of course] work fine.
>
> I thought my usage was exactly as designed.  How then should I be
> passing an externalptr to a .C() call?

I think you shouldn't be doing that.  You should be using .Call.

If your code can handle external pointer objects (as in the example), 
this should be an easy transition.  I haven't tested this, but I think 
the conversion to the .Call interface (less error checking) is simply

  SEXP_getDeviceInfo(SEXP handle, SEXP status)
  {
        groovyHandle *gh = R_ExternalPtrAddr(handle);
        INTEGER(Sstatus)[0] = GroovyStatus(gh);
        return R_NilValue;
  }


If your code is using the pointer just as an opaque handle, I'd suggest 
keeping an array of them, and pass an index into that array:  then .C 
will be fine.

Duncan Murdoch


From murdoch.duncan at gmail.com  Sat May 12 00:36:35 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 11 May 2012 18:36:35 -0400
Subject: [Rd] Replacements for stdout and stderr guaranteed to be open
 in all versions of R
In-Reply-To: <1336772199.2290.27.camel@mabel>
References: <1336772199.2290.27.camel@mabel>
Message-ID: <4FAD9473.8030306@gmail.com>

On 12-05-11 5:36 PM, David Sterratt wrote:
> I maintain the geometry package, which integrates the Qhull C library
> (http://qhull.org) into R. The Qhull function I hook into requires an
> open FILE handle as one of its arguments. I had set this file handle to
> stdout, but now R check NOTEs the presence of stdout, and the CRAN
> maintainers asked me to get rid of these NOTEs.
>
> Including the following defines means the checks are passed on CRAN:
>
> #ifdef WIN32
> extern FILE * R_Consolefile;
> extern FILE * R_Outputfile;
> #else
> #include<Rinterface.h>
> #fi
> #undef stderr
> #define stderr R_Consolefile
> #undef stdout
> #define stdout R_Outputfile
>
> However, this does not work on Rgui.exe, when the above leads to a
> crash. Looking at
> http://svn.r-project.org/R/trunk/src/gnuwin32/system.c
> it would appear that R_Consolefile and R_Outputfile only point to open
> files when CharacterMode == RTerm, not in GUI mode.
>
> Therefore my question is, are there any replacements for stdout and
> stderr that work across all versions of R?

I'm pretty sure the answer is "no".  What you can do is have your 
initialization code open a new handle (pointing to something that is not 
stdout, e.g. a file), and then pass that to the Qhull function.

Duncan Murdoch


From krivitsky at stat.psu.edu  Sat May 12 01:36:51 2012
From: krivitsky at stat.psu.edu (Pavel N. Krivitsky)
Date: Fri, 11 May 2012 19:36:51 -0400
Subject: [Rd] [patch] Behavior of .C() and .Fortran() when given double(0)
 or integer(0) (repost).
Message-ID: <1336779411.4894.252.camel@krivitsky.heinz.win.cmu.edu>

Dear R-devel,

Duncan Murdoch suggested that I repost this if I don't get a response in
a week, so here it is. The tests and the patches were on/against
revision 59314, but I don't think that any of the commits since then
affected the code in question.

While tracking down some hard-to-reproduce bugs in a package I maintain,
I stumbled on a behavior change between R 2.15.0 and the current R-devel
(or SVN trunk).

In 2.15.0 and earlier, if you passed an 0-length vector of the right
mode (e.g., double(0) or integer(0)) as one of the arguments in a .C()
call with DUP=TRUE (the default), the C routine would be passed NULL
(the C pointer, not R NULL) in the corresponding argument. The current
development version instead passes it a pointer to what appears to be
memory location immediately following the the SEXP that holds the
metadata for the argument. If the argument has length 0, this is often
memory belonging to a different R object. (DUP=FALSE in 2.15.0
appears to have the same behavior as R-devel.)

.C() documentation and Writing R Extensions don't explicitly specify a
behavior for 0-length vectors, so I don't know if this change is
intentional, or whether it was a side-effect of the following news item:

      .C() and .Fortran() do less copying: arguments which are raw,
      logical, integer, real or complex vectors and are unnamed are not
      copied before the call, and (named or not) are not copied after
      the call.  Lists are no longer copied (they are supposed to be
      used read-only in the C code).

Was the change in the empty vector behavior intentional?

It seems to me that standardizing on the behavior of giving the C
routine NULL is safer, more consistent with other memory-related
routines, and more convenient: whereas dereferencing a NULL pointer is
an immediate (and therefore easily traced) segfault, dereferencing an
invalid pointer that is nevertheless in the general memory area
allocated to the program often causes subtle errors down the line;
R_alloc asked to allocate 0 bytes returns NULL, at least on my platform;
and the C routine can easily check if a pointer is NULL, but with the
R-devel behavior, the programmer has to add an explicit way of telling
that an empty vector was passed.

I've attached a small test case (dotC_NULL.[Rc] files) that shows the
difference. The C file should be built with R CMD SHLIB, and the R file
calls the functions in the library with a variety of arguments. Output I
get from running
R CMD BATCH --no-timing --vanilla --slave dotC_NULL.R
on R 2.15.0, R trunk, and R trunk with my patch (described below) is
attached.

The attached patch (dotC_NULL.patch) against the current trunk
(affecting src/main/dotcode.c) restores the old behavior for DUP=TRUE
(i.e., 0-length vector -> NULL pointer) and extends it to the DUP=FALSE
case. It does so by checking if an argument --- if it's of mode raw,
integer, real, or complex --- to a .C() or .Fortran() call has length 0,
and, if so, sets the pointer to be passed to NULL and then skips the
copying of the C routine's changes back to the R object for that
argument. The additional computing cost should be negligible (i.e.,
checking if vector length equals 0 and break-ing out of a switch
statement if so).

The patch appears to work, at least for my package, and R CMD check
passes for all recommended packages (on my 64-bit Linux system), but
this is my first time working with R's internals, so handle with care.

                                   Best,
                                   Pavel Krivitsky
-------------- next part --------------
R version 2.15.0 (2012-03-30)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=C                 LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

R_alloc asked to allocate 1 byte: 
Pointer to output from R_alloc() of 1 bytes: 0x211c470.
Return value: [1] 1

R_alloc asked to allocate 0 bytes: 
Pointer to output from R_alloc() of 0 bytes: (nil).
Return value: [1] 0

Integer vector with 1 element: 
Pointer to arg: 0x2123b00.
Return value: [1] 0

Integer vector with 0 elements: 
Pointer to arg: (nil).
Return value: integer(0)

Integer vector with 1 element and DUP=FALSE: 
Pointer to arg: 0x2132940.
Return value: [1] 0

Integer vector with 0 elements and DUP=FALSE: 
Pointer to arg: 0x2134a80.
Return value: integer(0)

-------------- next part --------------
R Under development (unstable) (2012-05-04 r59314)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=C                 LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

R_alloc asked to allocate 1 byte: 
Pointer to output from R_alloc() of 1 bytes: 0x1e56270.
Return value: [1] 1

R_alloc asked to allocate 0 bytes: 
Pointer to output from R_alloc() of 0 bytes: (nil).
Return value: [1] 0

Integer vector with 1 element: 
Pointer to arg: 0x1e60db0.
Return value: [1] 0

Integer vector with 0 elements: 
Pointer to arg: 0x1e75188.
Return value: integer(0)

Integer vector with 1 element and DUP=FALSE: 
Pointer to arg: 0x1e6ad90.
Return value: [1] 0

Integer vector with 0 elements and DUP=FALSE: 
Pointer to arg: 0x1e7dc10.
Return value: integer(0)

-------------- next part --------------
R Under development (unstable) (2012-05-04 r59314)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=C                 LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

R_alloc asked to allocate 1 byte: 
Pointer to output from R_alloc() of 1 bytes: 0x27495c0.
Return value: [1] 1

R_alloc asked to allocate 0 bytes: 
Pointer to output from R_alloc() of 0 bytes: (nil).
Return value: [1] 0

Integer vector with 1 element: 
Pointer to arg: 0x2754100.
Return value: [1] 0

Integer vector with 0 elements: 
Pointer to arg: (nil).
Return value: integer(0)

Integer vector with 1 element and DUP=FALSE: 
Pointer to arg: 0x275e0e0.
Return value: [1] 0

Integer vector with 0 elements and DUP=FALSE: 
Pointer to arg: (nil).
Return value: integer(0)

-------------- next part --------------
sessionInfo()
cat("\n")
dyn.load("dotC_NULL.so")
run_test<-function(desc,Cfun,args){
  cat(desc,"\n")
  out <- do.call(".C",c(list(Cfun),args))
  cat("Return value: ")
  print(out[[1]])
  cat("\n")
}


run_test("R_alloc asked to allocate 1 byte:", "R_alloc_test",list(nbytes=as.integer(1)))
run_test("R_alloc asked to allocate 0 bytes:", "R_alloc_test",list(nbytes=as.integer(0)))

run_test("Integer vector with 1 element:", "dotC_NULL",list(arg=integer(1)))
run_test("Integer vector with 0 elements:", "dotC_NULL",list(arg=integer(0)))
run_test("Integer vector with 1 element and DUP=FALSE:", "dotC_NULL",list(arg=integer(1), DUP=FALSE))
run_test("Integer vector with 0 elements and DUP=FALSE:", "dotC_NULL",list(arg=integer(0), DUP=FALSE))
-------------- next part --------------
A non-text attachment was scrubbed...
Name: dotC_NULL.c
Type: text/x-csrc
Size: 267 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120511/e0a6f452/attachment.bin>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: dotC_NULL.patch
Type: text/x-patch
Size: 2473 bytes
Desc: 
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120511/e0a6f452/attachment-0001.bin>

From david.c.sterratt at ed.ac.uk  Sat May 12 23:40:21 2012
From: david.c.sterratt at ed.ac.uk (David Sterratt)
Date: Sat, 12 May 2012 22:40:21 +0100
Subject: [Rd] Replacements for stdout and stderr guaranteed to be open
 in all versions of R
In-Reply-To: <4FAD9473.8030306@gmail.com>
References: <1336772199.2290.27.camel@mabel>  <4FAD9473.8030306@gmail.com>
Message-ID: <1336858821.2294.39.camel@mabel>

On Fri, 2012-05-11 at 18:36 -0400, Duncan Murdoch wrote:
> On 12-05-11 5:36 PM, David Sterratt wrote:
> > Looking at
> > http://svn.r-project.org/R/trunk/src/gnuwin32/system.c
> > it would appear that R_Consolefile and R_Outputfile only point to open
> > files when CharacterMode == RTerm, not in GUI mode.
> >
> > Therefore my question is, are there any replacements for stdout and
> > stderr that work across all versions of R?
> 
> I'm pretty sure the answer is "no".  What you can do is have your 
> initialization code open a new handle (pointing to something that is not 
> stdout, e.g. a file), and then pass that to the Qhull function.

Thanks for your answer Duncan - it's lead me to the following solution,
which seems to work even with mcapply() in the multicore package, which
I thought might prove problematic.

In every file that refers to stdout, include (via

PKG_CPPFLAGS = -include myheader.h 

in the Makevars file):

        /* myheader.h */
        FILE * tmpstdout;
        #undef stdout
        #define stdout tmpstdout

Then in the file in which the function_requiring_FILE(double arg, FILE *
fp) is called:

        /* myfile.h */
        #include <Rembedded.h>          /* For R_tmpnam() */
        #include <unistd.h>             /* For unlink() */
        
        void my_function(double arg) {
          const char *name;
          name = R_tmpnam("Rf", R_TempDir);
          tmpstdout = fopen(name, "w");
          exitcode = function_requiring_FILE(arg, tmpstdout);
          fclose(tmpstdout);
          unlink(name);
          free((char *) name); 
        }

It's not exactly elegant, but it works for Linux, Mac and Windows (Rterm
and Rgui). I suppose I could use defines to use R_Consolefile for
platforms with Rinterface.h, but unless the above code is dangerous when
there are multiple threads, I will stick with it.

David.

-- 
David C Sterratt, Research Fellow. Tel: (+44) 131 651 1739
Institute for Adaptive and Neural Computation
School of Informatics, University of Edinburgh
Informatics Forum, 10 Crichton Street, Edinburgh EH8 9AB, Scotland, UK


From murdoch.duncan at gmail.com  Sun May 13 02:17:07 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 12 May 2012 20:17:07 -0400
Subject: [Rd] Replacements for stdout and stderr guaranteed to be open
 in all versions of R
In-Reply-To: <1336858821.2294.39.camel@mabel>
References: <1336772199.2290.27.camel@mabel> <4FAD9473.8030306@gmail.com>
	<1336858821.2294.39.camel@mabel>
Message-ID: <4FAEFD83.3070400@gmail.com>

On 12-05-12 5:40 PM, David Sterratt wrote:
> On Fri, 2012-05-11 at 18:36 -0400, Duncan Murdoch wrote:
>> On 12-05-11 5:36 PM, David Sterratt wrote:
>>> Looking at
>>> http://svn.r-project.org/R/trunk/src/gnuwin32/system.c
>>> it would appear that R_Consolefile and R_Outputfile only point to open
>>> files when CharacterMode == RTerm, not in GUI mode.
>>>
>>> Therefore my question is, are there any replacements for stdout and
>>> stderr that work across all versions of R?
>>
>> I'm pretty sure the answer is "no".  What you can do is have your
>> initialization code open a new handle (pointing to something that is not
>> stdout, e.g. a file), and then pass that to the Qhull function.
>
> Thanks for your answer Duncan - it's lead me to the following solution,
> which seems to work even with mcapply() in the multicore package, which
> I thought might prove problematic.
>
> In every file that refers to stdout, include (via
>
> PKG_CPPFLAGS = -include myheader.h
>
> in the Makevars file):
>
>          /* myheader.h */
>          FILE * tmpstdout;
>          #undef stdout
>          #define stdout tmpstdout
>
> Then in the file in which the function_requiring_FILE(double arg, FILE *
> fp) is called:
>
>          /* myfile.h */
>          #include<Rembedded.h>           /* For R_tmpnam() */
>          #include<unistd.h>              /* For unlink() */
>
>          void my_function(double arg) {
>            const char *name;
>            name = R_tmpnam("Rf", R_TempDir);
>            tmpstdout = fopen(name, "w");
>            exitcode = function_requiring_FILE(arg, tmpstdout);
>            fclose(tmpstdout);
>            unlink(name);
>            free((char *) name);
>          }
>
> It's not exactly elegant, but it works for Linux, Mac and Windows (Rterm
> and Rgui). I suppose I could use defines to use R_Consolefile for
> platforms with Rinterface.h, but unless the above code is dangerous when
> there are multiple threads, I will stick with it.

I'm afraid I don't know enough about C++ to know if that's safe (or even 
sufficient).

Duncan Murdoch


From jeroen.ooms at stat.ucla.edu  Sun May 13 09:15:25 2012
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Sun, 13 May 2012 00:15:25 -0700
Subject: [Rd] R package dependency issues when namespace is not attached
Message-ID: <CABFfbXuLstmkNWg3gG3cJmo=Kw33+B=8EoXK9kE9D82HA9oBLg@mail.gmail.com>

I have always assumed that having a package in the 'Depends' field
would automatically also?import?the namespace. However, it seems that
in R 2.15, dependencies do not become available until the package is
actually?attached?to the searchpath. Is this intended behavior?

The problem appears as follows: Suppose there is a package 'Child'
which?Depends, but does not explicitly import?a package called
'Parent' and contains a function that calls out to an object in the
namespace of 'Parent'. When this function is called without attaching
'Child' to the search path, the function in 'Parent' cannot be found.

Here an example from the manual of the?bigdata?package, but the
problem is very widespread:

x = matrix(rnorm(50*80),50,80)
beta = c(3,2,1.5,rep(0,77))
y = rnorm(50) + x%*%beta
z1 = bigdata::lasso.stars(x,y)

The example fails because lasso.stars depends on 'glmnet' which is not
loaded until?bigdata?is attached. The only way to be able to call
lasso.stars?is to actually attach the?bigdata?package:

library(bigdata)
z1 = bigdata::lasso.stars(x,y)

Now to further complicate things, it seems that this problem is
inherited to any 'grandchild' package that?imports, in this case, the
lasso.stars function. I have a hard time finding a good example but I
am sure they are out there.

Is this a bug? I know that it can be avoided by asking package authors
to use Imports instead of Depends, but in practice the majority of the
packages on CRAN still use Depends. It seems like the problem is
easily fixed if R would automatically import the namespace of any
Depends packages into to the child package namespace?


From murdoch.duncan at gmail.com  Sun May 13 10:59:08 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 13 May 2012 04:59:08 -0400
Subject: [Rd] R package dependency issues when namespace is not attached
In-Reply-To: <CABFfbXuLstmkNWg3gG3cJmo=Kw33+B=8EoXK9kE9D82HA9oBLg@mail.gmail.com>
References: <CABFfbXuLstmkNWg3gG3cJmo=Kw33+B=8EoXK9kE9D82HA9oBLg@mail.gmail.com>
Message-ID: <4FAF77DC.4040801@gmail.com>

On 12-05-13 3:15 AM, Jeroen Ooms wrote:
> I have always assumed that having a package in the 'Depends' field
> would automatically also import the namespace. However, it seems that
> in R 2.15, dependencies do not become available until the package is
> actually attached to the searchpath. Is this intended behavior?
>
> The problem appears as follows: Suppose there is a package 'Child'
> which Depends, but does not explicitly import a package called
> 'Parent' and contains a function that calls out to an object in the
> namespace of 'Parent'. When this function is called without attaching
> 'Child' to the search path, the function in 'Parent' cannot be found.
>
> Here an example from the manual of the bigdata package, but the
> problem is very widespread:
>
> x = matrix(rnorm(50*80),50,80)
> beta = c(3,2,1.5,rep(0,77))
> y = rnorm(50) + x%*%beta
> z1 = bigdata::lasso.stars(x,y)
>
> The example fails because lasso.stars depends on 'glmnet' which is not
> loaded until bigdata is attached. The only way to be able to call
> lasso.stars is to actually attach the bigdata package:
>
> library(bigdata)
> z1 = bigdata::lasso.stars(x,y)
>
> Now to further complicate things, it seems that this problem is
> inherited to any 'grandchild' package that imports, in this case, the
> lasso.stars function. I have a hard time finding a good example but I
> am sure they are out there.
>
> Is this a bug? I know that it can be avoided by asking package authors
> to use Imports instead of Depends, but in practice the majority of the
> packages on CRAN still use Depends. It seems like the problem is
> easily fixed if R would automatically import the namespace of any
> Depends packages into to the child package namespace?

Not sure if it's a bug, but the correct solution in bigdata is to import 
the glmnet function in its NAMESPACE.  Then the namespace that gets 
loaded when you type bigdata::lasso.stars will be able to see the glmnet 
function.

Perhaps Depends in the DESCRIPTION file should do the import 
automatically, but it will be faster to import just one function than 
everything from a package that has a lot of exports.  So maybe it's a 
bug because we don't do that, but I think there would be complaints if 
we did.

On the other hand, if bigdata::lasso.stars loaded glmnet onto the search 
path, I think that would be a bug.  The search path belongs to the user, 
not to R, and the user might have used the :: notation to avoid messing 
with it.

Duncan Murdoch


From ripley at stats.ox.ac.uk  Sun May 13 11:24:42 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 13 May 2012 10:24:42 +0100
Subject: [Rd] R Installation Manual - ATLAS BLAS guidance that is not in
 the current version
In-Reply-To: <93A2161604A30C4ABE14AC35CAFC8422B63CF2F4@USDFW11XM32.mercer.com>
References: <93A2161604A30C4ABE14AC35CAFC8422B63CF2F4@USDFW11XM32.mercer.com>
Message-ID: <4FAF7DDA.5010606@stats.ox.ac.uk>

On 09/05/2012 19:54, Adler, Avraham wrote:
> Good afternoon.
>
> I am trying to compile a version of Rblas.dll based on ATLAS for the
Corei7. I had remembered that there was mention of which file to adjust
and that "xerbla" needed to be removed from one of the outputs from the
last time I tried a few years ago. The most recent version of the R
Installation manual does not say anything about this. An older version
(2.10 I believe) has the following text:
>
>        Optionally, you can install a version of ATLAS
>        (`math-atlas.sourceforge.net'
>        (http://math-atlas.sourceforge.net/)) tuned to your system for
>        fast linear algebra routines. Pre-built `Rblas.dll' for various
>        Pentium and AthlonXP chips are available in the
>        `windows/contrib/ATLAS' area on CRAN.  If you are building R from
>        source, there are macros `USE_ATLAS' and `ATLAS_PATH' in the file
>        `MkRules'.  Set `USE_ATLAS = YES' and `ATLAS_PATH' to where the
>        ATLAS libraries are located.  You will need to make the libraries
>        yourself(1): none of the binaries we have seen are compiled for
>        the correct compiler.  Since R has its own `xerbla' it is best to
>        delete that in ATLAS by
>
>             ar d /path/to/libf77blas.a xerbla.o
>
> Would it be possible to restore the above information to the next version of the manual for future reference, please?

No, as this is no longer supported (and various attempts to make it work 
have failed with incorrect results/segfaults).

We do support the use of the legacy Goto BLAS these days (64-bit only, 
but anyone who cares about performance will be using 64-bit).

As you have found in another thread, avoid over-optimizing code: the 
risk of incorrect answers is serious and the performance gains small.

> Thank you,
>
> Avraham Adler
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ligges at statistik.tu-dortmund.de  Sun May 13 19:14:12 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 13 May 2012 19:14:12 +0200
Subject: [Rd] R package dependency issues when namespace is not attached
In-Reply-To: <4FAF77DC.4040801@gmail.com>
References: <CABFfbXuLstmkNWg3gG3cJmo=Kw33+B=8EoXK9kE9D82HA9oBLg@mail.gmail.com>
	<4FAF77DC.4040801@gmail.com>
Message-ID: <4FAFEBE4.5020403@statistik.tu-dortmund.de>



On 13.05.2012 10:59, Duncan Murdoch wrote:
> On 12-05-13 3:15 AM, Jeroen Ooms wrote:
>> I have always assumed that having a package in the 'Depends' field
>> would automatically also import the namespace. However, it seems that
>> in R 2.15, dependencies do not become available until the package is
>> actually attached to the searchpath. Is this intended behavior?
>>
>> The problem appears as follows: Suppose there is a package 'Child'
>> which Depends, but does not explicitly import a package called
>> 'Parent' and contains a function that calls out to an object in the
>> namespace of 'Parent'. When this function is called without attaching
>> 'Child' to the search path, the function in 'Parent' cannot be found.
>>
>> Here an example from the manual of the bigdata package, but the
>> problem is very widespread:
>>
>> x = matrix(rnorm(50*80),50,80)
>> beta = c(3,2,1.5,rep(0,77))
>> y = rnorm(50) + x%*%beta
>> z1 = bigdata::lasso.stars(x,y)
>>
>> The example fails because lasso.stars depends on 'glmnet' which is not
>> loaded until bigdata is attached. The only way to be able to call
>> lasso.stars is to actually attach the bigdata package:
>>
>> library(bigdata)
>> z1 = bigdata::lasso.stars(x,y)
>>
>> Now to further complicate things, it seems that this problem is
>> inherited to any 'grandchild' package that imports, in this case, the
>> lasso.stars function. I have a hard time finding a good example but I
>> am sure they are out there.
>>
>> Is this a bug? I know that it can be avoided by asking package authors
>> to use Imports instead of Depends, but in practice the majority of the
>> packages on CRAN still use Depends. It seems like the problem is
>> easily fixed if R would automatically import the namespace of any
>> Depends packages into to the child package namespace?
>
> Not sure if it's a bug, but the correct solution in bigdata is to import
> the glmnet function in its NAMESPACE. Then the namespace that gets
> loaded when you type bigdata::lasso.stars will be able to see the glmnet
> function.
>
> Perhaps Depends in the DESCRIPTION file should do the import
> automatically, but it will be faster to import just one function than
> everything from a package that has a lot of exports. So maybe it's a bug
> because we don't do that, but I think there would be complaints if we did.
>
> On the other hand, if bigdata::lasso.stars loaded glmnet onto the search
> path, I think that would be a bug. The search path belongs to the user,
> not to R, and the user might have used the :: notation to avoid messing
> with it.

I do not see any problem in R. If someone is going to import a 
Namespace, he or she has to do that via import directives in the 
NAMESPACE file. If someone is going to have a package on the search 
path, he or she has to require() it. The DESCRIPTION file is used to 
derive the dependency structures among packages for installation order, 
check order etc.

Best,
Uwe




> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jeroen.ooms at stat.ucla.edu  Sun May 13 21:14:40 2012
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Sun, 13 May 2012 12:14:40 -0700
Subject: [Rd] R package dependency issues when namespace is not attached
In-Reply-To: <4FAFEBE4.5020403@statistik.tu-dortmund.de>
References: <CABFfbXuLstmkNWg3gG3cJmo=Kw33+B=8EoXK9kE9D82HA9oBLg@mail.gmail.com>
	<4FAF77DC.4040801@gmail.com>
	<4FAFEBE4.5020403@statistik.tu-dortmund.de>
Message-ID: <CABFfbXt-LnGONFUSxqCWEi6Rkz1Yp62=ao=RN-n_pgJ-xWEpNA@mail.gmail.com>

On Sun, May 13, 2012 at 10:14 AM, Uwe Ligges
<ligges at statistik.tu-dortmund.de> wrote:

> I do not see any problem in R. If someone is going to import a Namespace, he
> or she has to do that via import directives in the NAMESPACE file. If
> someone is going to have a package on the search path, he or she has to
> require() it. The DESCRIPTION file is used to derive the dependency
> structures among packages for installation order, check order etc.

I am not sure everyone is aware of this. Many package authors seem to
be assuming that having a package in the Depends field of the
DESCRIPTION is a sufficient condition for having the dependency
package available at runtime, regardless of how the function is
invoked by the user. I think this is the usual meaning of a
dependency. There are a lot of packages on CRAN that use Depends and
are not explicitly importing anything. Among others, this holds for
any package without a NAMESPACE file.

Also looking at the definition of the 'Depends' field in the 'writing
r extensions' manual there is not a single hint that Depends is not
sufficient for having the package available at runtime, and any
function that is used should still be manually imported or required()
as you suggest.


From jwiley.psych at gmail.com  Sun May 13 21:16:13 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Sun, 13 May 2012 12:16:13 -0700
Subject: [Rd] R package dependency issues when namespace is not attached
In-Reply-To: <4FAFEBE4.5020403@statistik.tu-dortmund.de>
References: <CABFfbXuLstmkNWg3gG3cJmo=Kw33+B=8EoXK9kE9D82HA9oBLg@mail.gmail.com>
	<4FAF77DC.4040801@gmail.com>
	<4FAFEBE4.5020403@statistik.tu-dortmund.de>
Message-ID: <CANz9Z_K0UtNzqbyx1UZu5LiHJ5Tq4BVq0wtbVRFuG+ihzY08_w@mail.gmail.com>

On Sun, May 13, 2012 at 10:14 AM, Uwe Ligges
<ligges at statistik.tu-dortmund.de> wrote:
>
>
> On 13.05.2012 10:59, Duncan Murdoch wrote:
>>
>> On 12-05-13 3:15 AM, Jeroen Ooms wrote:
>>>
>>> I have always assumed that having a package in the 'Depends' field
>>> would automatically also import the namespace. However, it seems that
>>> in R 2.15, dependencies do not become available until the package is
>>> actually attached to the searchpath. Is this intended behavior?
>>>
>>> The problem appears as follows: Suppose there is a package 'Child'
>>> which Depends, but does not explicitly import a package called
>>> 'Parent' and contains a function that calls out to an object in the
>>> namespace of 'Parent'. When this function is called without attaching
>>> 'Child' to the search path, the function in 'Parent' cannot be found.
>>>
>>> Here an example from the manual of the bigdata package, but the
>>> problem is very widespread:
>>>
>>> x = matrix(rnorm(50*80),50,80)
>>> beta = c(3,2,1.5,rep(0,77))
>>> y = rnorm(50) + x%*%beta
>>> z1 = bigdata::lasso.stars(x,y)
>>>
>>> The example fails because lasso.stars depends on 'glmnet' which is not
>>> loaded until bigdata is attached. The only way to be able to call
>>> lasso.stars is to actually attach the bigdata package:
>>>
>>> library(bigdata)
>>> z1 = bigdata::lasso.stars(x,y)
>>>
>>> Now to further complicate things, it seems that this problem is
>>> inherited to any 'grandchild' package that imports, in this case, the
>>> lasso.stars function. I have a hard time finding a good example but I
>>> am sure they are out there.
>>>
>>> Is this a bug? I know that it can be avoided by asking package authors
>>> to use Imports instead of Depends, but in practice the majority of the
>>> packages on CRAN still use Depends. It seems like the problem is
>>> easily fixed if R would automatically import the namespace of any
>>> Depends packages into to the child package namespace?
>>
>>
>> Not sure if it's a bug, but the correct solution in bigdata is to import
>> the glmnet function in its NAMESPACE. Then the namespace that gets
>> loaded when you type bigdata::lasso.stars will be able to see the glmnet
>> function.
>>
>> Perhaps Depends in the DESCRIPTION file should do the import
>> automatically, but it will be faster to import just one function than
>> everything from a package that has a lot of exports. So maybe it's a bug
>> because we don't do that, but I think there would be complaints if we did.
>>
>> On the other hand, if bigdata::lasso.stars loaded glmnet onto the search
>> path, I think that would be a bug. The search path belongs to the user,
>> not to R, and the user might have used the :: notation to avoid messing
>> with it.
>
>
> I do not see any problem in R. If someone is going to import a Namespace, he
> or she has to do that via import directives in the NAMESPACE file. If
> someone is going to have a package on the search path, he or she has to
> require() it. The DESCRIPTION file is used to derive the dependency
> structures among packages for installation order, check order etc.

So should package authors both list a package in the depends of
DESCRIPTION and explicitly import what is needed so if someone else
uses their code without loading the package, everything needed is
available?

>
> Best,
> Uwe
>
>
>
>
>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From murdoch.duncan at gmail.com  Sun May 13 21:28:36 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 13 May 2012 15:28:36 -0400
Subject: [Rd] R package dependency issues when namespace is not attached
In-Reply-To: <CABFfbXt-LnGONFUSxqCWEi6Rkz1Yp62=ao=RN-n_pgJ-xWEpNA@mail.gmail.com>
References: <CABFfbXuLstmkNWg3gG3cJmo=Kw33+B=8EoXK9kE9D82HA9oBLg@mail.gmail.com>
	<4FAF77DC.4040801@gmail.com>
	<4FAFEBE4.5020403@statistik.tu-dortmund.de>
	<CABFfbXt-LnGONFUSxqCWEi6Rkz1Yp62=ao=RN-n_pgJ-xWEpNA@mail.gmail.com>
Message-ID: <4FB00B64.80404@gmail.com>

On 12-05-13 3:14 PM, Jeroen Ooms wrote:
> On Sun, May 13, 2012 at 10:14 AM, Uwe Ligges
> <ligges at statistik.tu-dortmund.de>  wrote:
>
>> I do not see any problem in R. If someone is going to import a Namespace, he
>> or she has to do that via import directives in the NAMESPACE file. If
>> someone is going to have a package on the search path, he or she has to
>> require() it. The DESCRIPTION file is used to derive the dependency
>> structures among packages for installation order, check order etc.
>
> I am not sure everyone is aware of this. Many package authors seem to
> be assuming that having a package in the Depends field of the
> DESCRIPTION is a sufficient condition for having the dependency
> package available at runtime, regardless of how the function is
> invoked by the user. I think this is the usual meaning of a
> dependency. There are a lot of packages on CRAN that use Depends and
> are not explicitly importing anything. Among others, this holds for
> any package without a NAMESPACE file.
>
> Also looking at the definition of the 'Depends' field in the 'writing
> r extensions' manual there is not a single hint that Depends is not
> sufficient for having the package available at runtime, and any
> function that is used should still be manually imported or required()
> as you suggest.

What do you suggest as the solution?

Duncan Murdoch


From mtmorgan at fhcrc.org  Sun May 13 22:06:16 2012
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Sun, 13 May 2012 13:06:16 -0700
Subject: [Rd] R package dependency issues when namespace is not attached
In-Reply-To: <CABFfbXt-LnGONFUSxqCWEi6Rkz1Yp62=ao=RN-n_pgJ-xWEpNA@mail.gmail.com>
References: <CABFfbXuLstmkNWg3gG3cJmo=Kw33+B=8EoXK9kE9D82HA9oBLg@mail.gmail.com>	<4FAF77DC.4040801@gmail.com>	<4FAFEBE4.5020403@statistik.tu-dortmund.de>
	<CABFfbXt-LnGONFUSxqCWEi6Rkz1Yp62=ao=RN-n_pgJ-xWEpNA@mail.gmail.com>
Message-ID: <4FB01438.9030907@fhcrc.org>

On 05/13/2012 12:14 PM, Jeroen Ooms wrote:
> On Sun, May 13, 2012 at 10:14 AM, Uwe Ligges
> <ligges at statistik.tu-dortmund.de>  wrote:
>
>> I do not see any problem in R. If someone is going to import a Namespace, he
>> or she has to do that via import directives in the NAMESPACE file. If
>> someone is going to have a package on the search path, he or she has to
>> require() it. The DESCRIPTION file is used to derive the dependency
>> structures among packages for installation order, check order etc.
>
> I am not sure everyone is aware of this. Many package authors seem to
> be assuming that having a package in the Depends field of the
> DESCRIPTION is a sufficient condition for having the dependency
> package available at runtime, regardless of how the function is
> invoked by the user. I think this is the usual meaning of a

I think this is because name spaces are relatively new, so authors are 
yet to realize the consequences of not importing the definitions their 
package uses.

As a package developer, I want to have the code my package sees be 
exactly what is needed, and no more. There are many good reasons for 
this, including isolating as much as possible my code from changes in 
other packages and minimizing the costs of symbol look-up. These issues 
become increasing important as the hierarchy of package relationships 
becomes deep.

The best practice is for authors to import all necessary symbols, but no 
more!

Martin

> dependency. There are a lot of packages on CRAN that use Depends and
> are not explicitly importing anything. Among others, this holds for
> any package without a NAMESPACE file.
>
> Also looking at the definition of the 'Depends' field in the 'writing
> r extensions' manual there is not a single hint that Depends is not
> sufficient for having the package available at runtime, and any
> function that is used should still be manually imported or required()
> as you suggest.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From murdoch.duncan at gmail.com  Sun May 13 22:39:10 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 13 May 2012 16:39:10 -0400
Subject: [Rd] R package dependency issues when namespace is not attached
In-Reply-To: <4FB01438.9030907@fhcrc.org>
References: <CABFfbXuLstmkNWg3gG3cJmo=Kw33+B=8EoXK9kE9D82HA9oBLg@mail.gmail.com>	<4FAF77DC.4040801@gmail.com>	<4FAFEBE4.5020403@statistik.tu-dortmund.de>
	<CABFfbXt-LnGONFUSxqCWEi6Rkz1Yp62=ao=RN-n_pgJ-xWEpNA@mail.gmail.com>
	<4FB01438.9030907@fhcrc.org>
Message-ID: <4FB01BEE.8090601@gmail.com>

On 12-05-13 4:06 PM, Martin Morgan wrote:
> On 05/13/2012 12:14 PM, Jeroen Ooms wrote:
>> On Sun, May 13, 2012 at 10:14 AM, Uwe Ligges
>> <ligges at statistik.tu-dortmund.de>   wrote:
>>
>>> I do not see any problem in R. If someone is going to import a Namespace, he
>>> or she has to do that via import directives in the NAMESPACE file. If
>>> someone is going to have a package on the search path, he or she has to
>>> require() it. The DESCRIPTION file is used to derive the dependency
>>> structures among packages for installation order, check order etc.
>>
>> I am not sure everyone is aware of this. Many package authors seem to
>> be assuming that having a package in the Depends field of the
>> DESCRIPTION is a sufficient condition for having the dependency
>> package available at runtime, regardless of how the function is
>> invoked by the user. I think this is the usual meaning of a
>
> I think this is because name spaces are relatively new, so authors are
> yet to realize the consequences of not importing the definitions their
> package uses.

They aren't that new, but I think our efforts at back-compatibility have 
slowed adoption.  If we were more demanding of package developers, we 
wouldn't have this problem; but I think we'd have a lot fewer packages. 
  Even with our current policy of aiming for back-compatibility we get a 
lot of complaints that we are asking too much.

>
> As a package developer, I want to have the code my package sees be
> exactly what is needed, and no more. There are many good reasons for
> this, including isolating as much as possible my code from changes in
> other packages and minimizing the costs of symbol look-up. These issues
> become increasing important as the hierarchy of package relationships
> becomes deep.
>
> The best practice is for authors to import all necessary symbols, but no
> more!

I agree, but many authors don't want to think about things that way.

Duncan Murdoch

>
> Martin
>
>> dependency. There are a lot of packages on CRAN that use Depends and
>> are not explicitly importing anything. Among others, this holds for
>> any package without a NAMESPACE file.
>>
>> Also looking at the definition of the 'Depends' field in the 'writing
>> r extensions' manual there is not a single hint that Depends is not
>> sufficient for having the package available at runtime, and any
>> function that is used should still be manually imported or required()
>> as you suggest.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From jeroen.ooms at stat.ucla.edu  Sun May 13 22:53:49 2012
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Sun, 13 May 2012 13:53:49 -0700
Subject: [Rd] R package dependency issues when namespace is not attached
In-Reply-To: <4FB01438.9030907@fhcrc.org>
References: <CABFfbXuLstmkNWg3gG3cJmo=Kw33+B=8EoXK9kE9D82HA9oBLg@mail.gmail.com>
	<4FAF77DC.4040801@gmail.com>
	<4FAFEBE4.5020403@statistik.tu-dortmund.de>
	<CABFfbXt-LnGONFUSxqCWEi6Rkz1Yp62=ao=RN-n_pgJ-xWEpNA@mail.gmail.com>
	<4FB01438.9030907@fhcrc.org>
Message-ID: <CABFfbXsBgV4-qpFDOkT9nK5z=EKa2P+S+2aqX93Vwf=OcCO8Jg@mail.gmail.com>

On Sun, May 13, 2012 at 1:06 PM, Martin Morgan <mtmorgan at fhcrc.org> wrote:
> On 05/13/2012 12:14 PM, Jeroen Ooms wrote:
> As a package developer, I want to have the code my package sees be exactly
> what is needed, and no more.

Exactly. That is why you probably don't use Depends, but Imports in
combination with a NAMESPACE file. Which is great, and we should
encourage that practice. But as long as 'Depends' is also supported,
this should be working properly as well.

Here a quote from
http://cran.r-project.org/doc/contrib/Leisch-CreatingPackages.pdf: "A
stronger form of dependency can be specified in the optional Depends
field listing packages which are necessary to run our code."

It think it seems reasonable to assume that when a package author
decides to use 'Depends' (for whatever reason), they want the
namespace to be available to their package. Hence I think R should
import the full namespace of packages in the Depends field. I don't
think this will generate too much overhead, because in most
circumstances, the package will be loaded and attached anyway.
Furthermore this will not slow down or affect packages that use the
better practice of specifying 'Imports' instead of 'Depends' and
explicitly import only required symbols.


From mtmorgan at fhcrc.org  Mon May 14 00:06:04 2012
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Sun, 13 May 2012 15:06:04 -0700
Subject: [Rd] R package dependency issues when namespace is not attached
In-Reply-To: <4FB01BEE.8090601@gmail.com>
References: <CABFfbXuLstmkNWg3gG3cJmo=Kw33+B=8EoXK9kE9D82HA9oBLg@mail.gmail.com>	<4FAF77DC.4040801@gmail.com>	<4FAFEBE4.5020403@statistik.tu-dortmund.de>
	<CABFfbXt-LnGONFUSxqCWEi6Rkz1Yp62=ao=RN-n_pgJ-xWEpNA@mail.gmail.com>
	<4FB01438.9030907@fhcrc.org> <4FB01BEE.8090601@gmail.com>
Message-ID: <4FB0304C.4080402@fhcrc.org>

On 05/13/2012 01:39 PM, Duncan Murdoch wrote:
> On 12-05-13 4:06 PM, Martin Morgan wrote:
>> On 05/13/2012 12:14 PM, Jeroen Ooms wrote:
>>> On Sun, May 13, 2012 at 10:14 AM, Uwe Ligges
>>> <ligges at statistik.tu-dortmund.de> wrote:
>>>
>>>> I do not see any problem in R. If someone is going to import a
>>>> Namespace, he
>>>> or she has to do that via import directives in the NAMESPACE file. If
>>>> someone is going to have a package on the search path, he or she has to
>>>> require() it. The DESCRIPTION file is used to derive the dependency
>>>> structures among packages for installation order, check order etc.
>>>
>>> I am not sure everyone is aware of this. Many package authors seem to
>>> be assuming that having a package in the Depends field of the
>>> DESCRIPTION is a sufficient condition for having the dependency
>>> package available at runtime, regardless of how the function is
>>> invoked by the user. I think this is the usual meaning of a
>>
>> I think this is because name spaces are relatively new, so authors are
>> yet to realize the consequences of not importing the definitions their
>> package uses.
>
> They aren't that new, but I think our efforts at back-compatibility have
> slowed adoption. If we were more demanding of package developers, we
> wouldn't have this problem; but I think we'd have a lot fewer packages.
> Even with our current policy of aiming for back-compatibility we get a
> lot of complaints that we are asking too much.

perhaps it would be easy to provide a check (I realize this is close on 
the heels of the undefined global variables thread), along the lines of

 > library(codetools)
 > checkUsageEnv(getNamespace("bigdata"), suppressLocal=TRUE)
lasso.stars: no visible global function definition for 'glmnet'
lasso.stars: no visible global function definition for 'glmnet'

or to suggest a NAMESPACE, done imperfectly by

https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/codetoolsBioC

(username / password: readonly)

 > library(codetoolsBioC)
 > library(bigdata)
 > deps <- writeNamespaceImports("bigdata", file=stdout())
#Generated by codetoolsBioC version 0.0.16
#Timestamp: Sun May 13 15:01:12 2012

#Imports: glmnet, graphics, Matrix

importMethodsFrom(Matrix, mean, t)

importFrom(glmnet, glmnet)

importFrom(graphics, lines, par, plot)

>
>>
>> As a package developer, I want to have the code my package sees be
>> exactly what is needed, and no more. There are many good reasons for
>> this, including isolating as much as possible my code from changes in
>> other packages and minimizing the costs of symbol look-up. These issues
>> become increasing important as the hierarchy of package relationships
>> becomes deep.
>>
>> The best practice is for authors to import all necessary symbols, but no
>> more!
>
> I agree, but many authors don't want to think about things that way.
>
> Duncan Murdoch
>
>>
>> Martin
>>
>>> dependency. There are a lot of packages on CRAN that use Depends and
>>> are not explicitly importing anything. Among others, this holds for
>>> any package without a NAMESPACE file.
>>>
>>> Also looking at the definition of the 'Depends' field in the 'writing
>>> r extensions' manual there is not a single hint that Depends is not
>>> sufficient for having the package available at runtime, and any
>>> function that is used should still be manually imported or required()
>>> as you suggest.
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From e4gutier at ucsd.edu  Sun May 13 11:11:04 2012
From: e4gutier at ucsd.edu (E.D. Gutierrez)
Date: Sun, 13 May 2012 02:11:04 -0700
Subject: [Rd] Problem compiling package LogicReg - make Error 255
Message-ID: <CAE9iQuo0gZyD7io7MTWEeBj1hMLHx3bNCwVKe8VWFuetZFczQg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120513/d995e67e/attachment.pl>

From ligges at statistik.tu-dortmund.de  Mon May 14 14:40:14 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 14 May 2012 14:40:14 +0200
Subject: [Rd] Problem compiling package LogicReg - make Error 255
In-Reply-To: <CAE9iQuo0gZyD7io7MTWEeBj1hMLHx3bNCwVKe8VWFuetZFczQg@mail.gmail.com>
References: <CAE9iQuo0gZyD7io7MTWEeBj1hMLHx3bNCwVKe8VWFuetZFczQg@mail.gmail.com>
Message-ID: <4FB0FD2E.7020801@statistik.tu-dortmund.de>

It works for us, and hence

install.packages("LogicRec")

will install the precompiled binary for you.

Best,
Uwe Ligges

On 13.05.2012 11:11, E.D. Gutierrez wrote:
> Hello all,
>
> I've been using the R package LogicReg, but ended up having to change a
> certain parameter in the Fortran 77 code (namely, I had to change LGCntrMax
> to 25 in the file slogic.f).
>
> I am using a 64-bit Windows 7 machine.  When I tried to compile, I got the
> following error:
> -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
> C:\Program Files\R\R-2.14.2\bin>R CMD INSTALL --build LogicReg.tar.gz
> * installing to library 'C:/Users/user/Documents/R/win-library/2.14'
> * installing *source* package 'LogicReg' ...
> file 'src/slogic.f' has the wrong MD5 checksum
> ** libs
>
> *** arch - i386
> C:/PROGRA~1/R/R-214~1.2/etc/i386/Makeconf:194: warning: overriding recipe
> for
> target `.m.o'
> C:/PROGRA~1/R/R-214~1.2/etc/i386/Makeconf:187: warning: ignoring old recipe
> for
> target `.m.o'
> gfortran      -O3  -mtune=core2 -c My_own_scoring.f -o My_own_scoring.o
> gfortran      -O3  -mtune=core2 -c external.f -o external.o
> gfortran      -O3  -mtune=core2 -c slogic.f -o slogic.o
> gcc  -I"C:/PROGRA~1/R/R-214~1.2/include"          -O3 -Wall  -std=gnu99
> -mtune
> ore2 -c swrite.c -o swrite.o
> "zMy_own_scoring.o external.o slogic.o swrite.o" was unexpected at this
> time.
> make: *** [LogicReg.dll] Error 255
> ERROR: compilation failed for package 'LogicReg'
> * removing 'C:/Users/user/Documents/R/win-library/2.14/LogicReg'
> * restoring previous 'C:/Users/user/Documents/R/win-library/2.14/LogicReg'
> -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
> Unfortunately I have several gfortran compilers installed, and I'm not sure
> if this is what is giving me trouble.
>
> Below are the values for my PATH environment variables.  I've been fiddling
> around with them for hours with no luck:
>
> -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
> PATH = C:\Program Files\Rtools\gcc-4.6.3\bin; C:\Program Files\Rtools\bin;
> C:\Program Files\Rtools\perl\bin; C:\Program Files\Rtools\gcc-4.6.3\bin;
> C:\Program Files\Rtools\gcc-4.6.3\bin32; C:\Program
> Files\Rtools\gcc-4.6.3\i686-w64-mingw32; C:\Program
> Files\Rtools\gcc-4.6.3\i686-w64-mingw32\bin; C:\Program Files\Rtools\bin;
> C:\Program Files\R\R-2.14.2\bin; C:\Program Files\R\R-2.14.2\;  C:\Program
> Files\R\R-2.14.2\bin; C:\Program
> Files\R\R-2.14.2\bin\x64;%SystemRoot%\system32;
> %SystemRoot%;%SystemRoot%\System32\Wbem;%SYSTEMROOT%\System32\WindowsPowerShell\v1.0\;C:\Program
> Files\MATLAB\R2011a\runtime\win64;C:\Program
> Files\MATLAB\R2011a\bin;C:\Python27;C:\Python27\DLLs;C:\Python27\Scripts;C:\Python27\Lib\site-packages\PyQt4;C:\Python27\Lib\site-packages\vtk;C:\Python27\gnuplot\binary;C:\Program
> Files (x86)\pythonxy\SciTE-3.0.3.2;C:\Program Files
> (x86)\pythonxy\console;C:\MinGW32-xy;C:\MinGW32-xy\bin; C:\F\G77\bin;
> -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
>
> Please  let me know if you have any insights!  Thanks in advance.
>
> E.D. Gutierrez
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.tu-dortmund.de  Mon May 14 14:51:13 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 14 May 2012 14:51:13 +0200
Subject: [Rd] Problem compiling package LogicReg - make Error 255
In-Reply-To: <CAE9iQupbiUwOOZjMoKoCYz9t9M9U0YeSe+=Zi-5QREpZP27+PA@mail.gmail.com>
References: <CAE9iQuo0gZyD7io7MTWEeBj1hMLHx3bNCwVKe8VWFuetZFczQg@mail.gmail.com>
	<4FB0FD2E.7020801@statistik.tu-dortmund.de>
	<CAE9iQupbiUwOOZjMoKoCYz9t9M9U0YeSe+=Zi-5QREpZP27+PA@mail.gmail.com>
Message-ID: <4FB0FFC1.8040109@statistik.tu-dortmund.de>

Not sure what else is causing the problem.
Hard to tell from the output.

You may want to

1. clean up your path and only have the Rttols and R releated entries 
left (seems fine as is, but you never know).

2. make the changed package available, perhaps a glitch when changing 
the package?

Uwe Ligges







On 14.05.2012 14:47, E.D. Gutierrez wrote:
> Thanks for your reply, Uwe.  Unfortunately there is a hard-coded parameter
> in the Fortran code of the package that I must change in order to perform
> my analysis, so the pre-compiled package can't solve my problem.  The
> pre-compiled package does work flawlessly on my machines, though.
>
> On Mon, May 14, 2012 at 5:40 AM, Uwe Ligges<ligges at statistik.tu-dortmund.de
>> wrote:
>
>> It works for us, and hence
>>
>> install.packages("LogicRec")
>>
>> will install the precompiled binary for you.
>>
>> Best,
>> Uwe Ligges
>>
>>
>> On 13.05.2012 11:11, E.D. Gutierrez wrote:
>>
>>> Hello all,
>>>
>>> I've been using the R package LogicReg, but ended up having to change a
>>> certain parameter in the Fortran 77 code (namely, I had to change
>>> LGCntrMax
>>> to 25 in the file slogic.f).
>>>
>>> I am using a 64-bit Windows 7 machine.  When I tried to compile, I got the
>>> following error:
>>> -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+**-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+**
>>> -+-+-+-+-+-+-+-+-+-+
>>> C:\Program Files\R\R-2.14.2\bin>R CMD INSTALL --build LogicReg.tar.gz
>>> * installing to library 'C:/Users/user/Documents/R/**win-library/2.14'
>>> * installing *source* package 'LogicReg' ...
>>> file 'src/slogic.f' has the wrong MD5 checksum
>>> ** libs
>>>
>>> *** arch - i386
>>> C:/PROGRA~1/R/R-214~1.2/etc/**i386/Makeconf:194: warning: overriding
>>> recipe
>>> for
>>> target `.m.o'
>>> C:/PROGRA~1/R/R-214~1.2/etc/**i386/Makeconf:187: warning: ignoring old
>>> recipe
>>> for
>>> target `.m.o'
>>> gfortran      -O3  -mtune=core2 -c My_own_scoring.f -o My_own_scoring.o
>>> gfortran      -O3  -mtune=core2 -c external.f -o external.o
>>> gfortran      -O3  -mtune=core2 -c slogic.f -o slogic.o
>>> gcc  -I"C:/PROGRA~1/R/R-214~1.2/**include"          -O3 -Wall  -std=gnu99
>>> -mtune
>>> ore2 -c swrite.c -o swrite.o
>>> "zMy_own_scoring.o external.o slogic.o swrite.o" was unexpected at this
>>> time.
>>> make: *** [LogicReg.dll] Error 255
>>> ERROR: compilation failed for package 'LogicReg'
>>> * removing 'C:/Users/user/Documents/R/**win-library/2.14/LogicReg'
>>> * restoring previous 'C:/Users/user/Documents/R/**
>>> win-library/2.14/LogicReg'
>>> -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+**-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+**
>>> -+-+-+-+-+-+-+-+-+-+
>>> Unfortunately I have several gfortran compilers installed, and I'm not
>>> sure
>>> if this is what is giving me trouble.
>>>
>>> Below are the values for my PATH environment variables.  I've been
>>> fiddling
>>> around with them for hours with no luck:
>>>
>>> -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+**-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+**
>>> -+-+-+-+-+-+-+-+-+-+
>>> PATH = C:\Program Files\Rtools\gcc-4.6.3\bin; C:\Program Files\Rtools\bin;
>>> C:\Program Files\Rtools\perl\bin; C:\Program Files\Rtools\gcc-4.6.3\bin;
>>> C:\Program Files\Rtools\gcc-4.6.3\bin32; C:\Program
>>> Files\Rtools\gcc-4.6.3\i686-**w64-mingw32; C:\Program
>>> Files\Rtools\gcc-4.6.3\i686-**w64-mingw32\bin; C:\Program
>>> Files\Rtools\bin;
>>> C:\Program Files\R\R-2.14.2\bin; C:\Program Files\R\R-2.14.2\;  C:\Program
>>> Files\R\R-2.14.2\bin; C:\Program
>>> Files\R\R-2.14.2\bin\x64;%**SystemRoot%\system32;
>>> %SystemRoot%;%SystemRoot%\**System32\Wbem;%SYSTEMROOT%\**
>>> System32\WindowsPowerShell\v1.**0\;C:\Program
>>> Files\MATLAB\R2011a\runtime\**win64;C:\Program
>>> Files\MATLAB\R2011a\bin;C:\**Python27;C:\Python27\DLLs;C:\**
>>> Python27\Scripts;C:\Python27\**Lib\site-packages\PyQt4;C:\**
>>> Python27\Lib\site-packages\**vtk;C:\Python27\gnuplot\**binary;C:\Program
>>> Files (x86)\pythonxy\SciTE-3.0.3.2;**C:\Program Files
>>> (x86)\pythonxy\console;C:\**MinGW32-xy;C:\MinGW32-xy\bin; C:\F\G77\bin;
>>> -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+**-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+**
>>> -+-+-+-+-+-+-+-+-+-+
>>>
>>> Please  let me know if you have any insights!  Thanks in advance.
>>>
>>> E.D. Gutierrez
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________**________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/**listinfo/r-devel<https://stat.ethz.ch/mailman/listinfo/r-devel>
>>>
>>
>>
>
>


From edg2103 at gmail.com  Mon May 14 14:47:27 2012
From: edg2103 at gmail.com (E.D. Gutierrez)
Date: Mon, 14 May 2012 05:47:27 -0700
Subject: [Rd] Problem compiling package LogicReg - make Error 255
In-Reply-To: <4FB0FD2E.7020801@statistik.tu-dortmund.de>
References: <CAE9iQuo0gZyD7io7MTWEeBj1hMLHx3bNCwVKe8VWFuetZFczQg@mail.gmail.com>
	<4FB0FD2E.7020801@statistik.tu-dortmund.de>
Message-ID: <CAE9iQupbiUwOOZjMoKoCYz9t9M9U0YeSe+=Zi-5QREpZP27+PA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120514/de887f0a/attachment.pl>

From therneau at mayo.edu  Mon May 14 19:28:52 2012
From: therneau at mayo.edu (Terry Therneau)
Date: Mon, 14 May 2012 12:28:52 -0500
Subject: [Rd] Vignette problem
Message-ID: <4FB140D4.5090405@mayo.edu>

I'm having a problem rebuilding a package, new to me in R 2.15.0 
(Linux)  It hits all that contain the line
\usepackage[pdftex]{graphics}

and leads to the following when running R CMD check on the directory.  
(I do this often; a final run on the tar.gz file will happen before 
submission.)
Since I float and resize my figures, removing the line is fatal in other 
ways.

----------------------------

* checking re-building of vignette PDFs ... NOTE
Error in re-building vignettes:
   ...
/usr/share/texmf-texlive/tex/latex/pdftex-def/pdftex.def:414: Package 
pdftex.de
f Error: PDF mode expected, but DVI mode detected!
(pdftex.def)                If you are using `latex', then call `pdflatex'.
(pdftex.def)                Otherwise check and correct the driver options.
(pdftex.def)                Error recovery by switching to PDF mode.

See the pdftex.def package documentation for explanation.
Type  H <return>  for immediate help.
  ...

l.414     }\@ehc

?
/usr/share/texmf-texlive/tex/latex/pdftex-def/pdftex.def:414: Emergency 
stop.
  ...

l.414     }\@ehc

No pages of output.
Transcript written on lmekin.log.
/usr/bin/texi2dvi: latex exited with bad status, quitting.
make: *** [lmekin.pdf] Error 1
Error in buildVignettes(dir = 
"/home/therneau/research/surv/Hg/coxme.Rcheck/vign_test/coxme") :
   running 'make' failed
Execution halted

-----------------------------------------

The resulting .tex file work just fine with pdflatex, however.  I 
haven't found any reference to this elsewhere, but my guess is that it 
is something simple that I've missed.

Terry T.


From murdoch.duncan at gmail.com  Mon May 14 20:19:55 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 14 May 2012 14:19:55 -0400
Subject: [Rd] Vignette problem
In-Reply-To: <4FB140D4.5090405@mayo.edu>
References: <4FB140D4.5090405@mayo.edu>
Message-ID: <4FB14CCB.2010508@gmail.com>

On 14/05/2012 1:28 PM, Terry Therneau wrote:
> I'm having a problem rebuilding a package, new to me in R 2.15.0
> (Linux)  It hits all that contain the line
> \usepackage[pdftex]{graphics}
>
> and leads to the following when running R CMD check on the directory.
> (I do this often; a final run on the tar.gz file will happen before
> submission.)
> Since I float and resize my figures, removing the line is fatal in other
> ways.
>
> ----------------------------
>
> * checking re-building of vignette PDFs ... NOTE
> Error in re-building vignettes:
>     ...
> /usr/share/texmf-texlive/tex/latex/pdftex-def/pdftex.def:414: Package
> pdftex.de
> f Error: PDF mode expected, but DVI mode detected!
> (pdftex.def)                If you are using `latex', then call `pdflatex'.
> (pdftex.def)                Otherwise check and correct the driver options.
> (pdftex.def)                Error recovery by switching to PDF mode.
>
> See the pdftex.def package documentation for explanation.
> Type  H<return>   for immediate help.
>    ...
>
> l.414     }\@ehc
>
> ?
> /usr/share/texmf-texlive/tex/latex/pdftex-def/pdftex.def:414: Emergency
> stop.
>    ...
>
> l.414     }\@ehc
>
> No pages of output.
> Transcript written on lmekin.log.
> /usr/bin/texi2dvi: latex exited with bad status, quitting.
> make: *** [lmekin.pdf] Error 1
> Error in buildVignettes(dir =
> "/home/therneau/research/surv/Hg/coxme.Rcheck/vign_test/coxme") :
>     running 'make' failed
> Execution halted
>
> -----------------------------------------
>
> The resulting .tex file work just fine with pdflatex, however.  I
> haven't found any reference to this elsewhere, but my guess is that it
> is something simple that I've missed.

Do you have an explicit \usepackage{Sweave} in your file?  If not, 
Sweave will add one, and that might explain the difference between your 
two tests.

Another possibility is that you have a copy of Sweave.sty that is not 
the same as the one being used in one run or the other.  The checks will 
try to tell pdflatex to use the one that comes with your R version, but 
other local ones can sometimes have higher precedence in pdflatex.

And one idea what the problem might be: Sweave.sty uses the graphicx 
package, and it may conflict with the graphics package.

Duncan Murdoch


From michael.weylandt at gmail.com  Tue May 15 04:31:39 2012
From: michael.weylandt at gmail.com (R. Michael Weylandt)
Date: Mon, 14 May 2012 22:31:39 -0400
Subject: [Rd] StructTS Examples
Message-ID: <CAAmySGM-NoqcfTEHSvJ3ixHQRyj8e8pqZOa881pz2Dz7hJvA3w@mail.gmail.com>

In the examples for StructTS -- ($RHOME)/library/stats/man/StructTS.Rd -- could

par(mfrow = c(4, 1))
plot(log10(UKgas))
plot(cbind(fitted(fit), resids=resid(fit)), main = "UK gas consumption")

become

plot(log10(UKgas))
par(mfrow = c(4, 1))
plot(cbind(fitted(fit), resids=resid(fit)), main = "UK gas consumption")

## Note that par was moved down

This makes the plot of UKgas use the whole plot screen (as opposed to
one small panel while three remain empty) which seems like an
improvement.

Best,
Michael


From isubirana at imim.es  Mon May 14 19:00:57 2012
From: isubirana at imim.es (isubirana)
Date: Mon, 14 May 2012 10:00:57 -0700 (PDT)
Subject: [Rd] update.formula simplify = FALSE
Message-ID: <1337014857583-4629964.post@n4.nabble.com>

Dear R users,

I am building a packaged where I want to use the "update.formula" function,
but modifying the option "simplify = TRUE" to "FALSE". Since this is not an
argument, I modified the code and created a new function as:

update.formula2 <- function (old, new, ...) {
    tmp <- .Internal(update.formula(as.formula(old), as.formula(new)))
    out <- formula(terms.formula(tmp, simplify = FALSE))
    return(out)
}

This works fine. But when creating and checking the package ("R CMD check
--as-cran mypackage"), I obtained a warning saying that ".Internal" function
cannot be used inside a package.

Does anyone know how to define an "update.formula" (or equivalent) setting
"simplify = FALSE"?

Thanks.


Isaac Subirana.
IMIM. Barcelona.

--
View this message in context: http://r.789695.n4.nabble.com/update-formula-simplify-FALSE-tp4629964.html
Sent from the R devel mailing list archive at Nabble.com.


From walcott3 at msu.edu  Mon May 14 20:37:00 2012
From: walcott3 at msu.edu (walcott3 at msu.edu)
Date: Mon, 14 May 2012 14:37:00 -0400
Subject: [Rd] Package does not have a NAMESPACE and should be re-installed
Message-ID: <20120514143700.864333z9i73pzcuk@mail.msu.edu>

I'm trying to load a package locally from a zip file. When I load the  
package, I first get this, which looks okay:

package ?IBGEPesq? successfully unpacked and MD5 sums checked

HOWEVER, when I try to use the package to use the data with
library(IBGEPesq)

I get this message:

  package ?IBGEPesq? does not have a NAMESPACE and should be re-installed

I've tried re-installing it, and I've tried following suggestions on  
similar posts, but with no success.

Help please.


From murdoch.duncan at gmail.com  Tue May 15 14:23:08 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 15 May 2012 08:23:08 -0400
Subject: [Rd] Package does not have a NAMESPACE and should be
	re-installed
In-Reply-To: <20120514143700.864333z9i73pzcuk@mail.msu.edu>
References: <20120514143700.864333z9i73pzcuk@mail.msu.edu>
Message-ID: <4FB24AAC.9040507@gmail.com>

On 12-05-14 2:37 PM, walcott3 at msu.edu wrote:
> I'm trying to load a package locally from a zip file. When I load the
> package, I first get this, which looks okay:
>
> package ?IBGEPesq? successfully unpacked and MD5 sums checked
>
> HOWEVER, when I try to use the package to use the data with
> library(IBGEPesq)
>
> I get this message:
>
>    package ?IBGEPesq? does not have a NAMESPACE and should be re-installed
>
> I've tried re-installing it, and I've tried following suggestions on
> similar posts, but with no success.

The .zip file was likely produced by an earlier version of R.  It is 
essentially a copy of an installed version of the package.  You need a 
new .zip file, produced by the same version of R as you are using.

Duncan Murdoch


From walcott3 at msu.edu  Tue May 15 14:57:35 2012
From: walcott3 at msu.edu (walcotteric)
Date: Tue, 15 May 2012 05:57:35 -0700 (PDT)
Subject: [Rd] Package does not have a NAMESPACE and should be
	re-installed
In-Reply-To: <4FB24AAC.9040507@gmail.com>
References: <20120514143700.864333z9i73pzcuk@mail.msu.edu>
	<4FB24AAC.9040507@gmail.com>
Message-ID: <1337086655934-4630070.post@n4.nabble.com>


Duncan Murdoch-2 wrote
> 
> On 12-05-14 2:37 PM, walcott3@ wrote:
>> I'm trying to load a package locally from a zip file. When I load the
>> package, I first get this, which looks okay:
>>
>> package ?IBGEPesq? successfully unpacked and MD5 sums checked
>>
>> HOWEVER, when I try to use the package to use the data with
>> library(IBGEPesq)
>>
>> I get this message:
>>
>>    package ?IBGEPesq? does not have a NAMESPACE and should be
>> re-installed
>>
>> I've tried re-installing it, and I've tried following suggestions on
>> similar posts, but with no success.
> 
> The .zip file was likely produced by an earlier version of R.  It is 
> essentially a copy of an installed version of the package.  You need a 
> new .zip file, produced by the same version of R as you are using.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel@ mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


I'm not sure I can get the newer version (it's census data from another
country). Is there a way to figure out which version of R was used and just
install that temporarily?

--
View this message in context: http://r.789695.n4.nabble.com/Package-does-not-have-a-NAMESPACE-and-should-be-re-installed-tp4630059p4630070.html
Sent from the R devel mailing list archive at Nabble.com.


From therneau at mayo.edu  Tue May 15 15:56:50 2012
From: therneau at mayo.edu (Terry Therneau)
Date: Tue, 15 May 2012 08:56:50 -0500
Subject: [Rd] Vignette problem
In-Reply-To: <4FB14CCB.2010508@gmail.com>
References: <4FB140D4.5090405@mayo.edu> <4FB14CCB.2010508@gmail.com>
Message-ID: <4FB260A2.7010301@mayo.edu>

Duncan,
   Thanks for the ideas.  I checked them out and none seem to be the 
culprit.  My original message was wrong in one detail BTW, as I was 
already using "graphicx" not graphics.
   I switched over to the central server machine (CENTOS) to finish up 
the coxme submission until I could figure this out.  Ran CMD check, 
tidied up the NAMESPACE, DESCRIPTION, NEWS files, fixed a missing $ sign 
in an Rnw, etc.  Submitted the final to CRAN, then updated all the files 
on the Linux box from which the error below came -- both boxes point to 
the same Mercurial master --- and then tried again.
   Now it works!  And I have no idea what could have prompted the 
change.  It will remain a mystery, since I'm not going to try to bring 
the error back. :-)

Terry T.

On 05/14/2012 01:19 PM, Duncan Murdoch wrote:
> On 14/05/2012 1:28 PM, Terry Therneau wrote:
>> I'm having a problem rebuilding a package, new to me in R 2.15.0
>> (Linux)  It hits all that contain the line
>> \usepackage[pdftex]{graphics}
>>
>> and leads to the following when running R CMD check on the directory.
>> (I do this often; a final run on the tar.gz file will happen before
>> submission.)
>> Since I float and resize my figures, removing the line is fatal in other
>> ways.
>>
>> ----------------------------
>>
>> * checking re-building of vignette PDFs ... NOTE
>> Error in re-building vignettes:
>>     ...
>> /usr/share/texmf-texlive/tex/latex/pdftex-def/pdftex.def:414: Package
>> pdftex.de
>> f Error: PDF mode expected, but DVI mode detected!
>> (pdftex.def)                If you are using `latex', then call 
>> `pdflatex'.
>> (pdftex.def)                Otherwise check and correct the driver 
>> options.
>> (pdftex.def)                Error recovery by switching to PDF mode.
>>
>> See the pdftex.def package documentation for explanation.
>> Type  H<return>   for immediate help.
>>    ...
>>
>> l.414     }\@ehc
>>
>> ?
>> /usr/share/texmf-texlive/tex/latex/pdftex-def/pdftex.def:414: Emergency
>> stop.
>>    ...
>>
>> l.414     }\@ehc
>>
>> No pages of output.
>> Transcript written on lmekin.log.
>> /usr/bin/texi2dvi: latex exited with bad status, quitting.
>> make: *** [lmekin.pdf] Error 1
>> Error in buildVignettes(dir =
>> "/home/therneau/research/surv/Hg/coxme.Rcheck/vign_test/coxme") :
>>     running 'make' failed
>> Execution halted
>>
>> -----------------------------------------
>>
>> The resulting .tex file work just fine with pdflatex, however.  I
>> haven't found any reference to this elsewhere, but my guess is that it
>> is something simple that I've missed.
>
> Do you have an explicit \usepackage{Sweave} in your file?  If not, 
> Sweave will add one, and that might explain the difference between 
> your two tests.
>
> Another possibility is that you have a copy of Sweave.sty that is not 
> the same as the one being used in one run or the other.  The checks 
> will try to tell pdflatex to use the one that comes with your R 
> version, but other local ones can sometimes have higher precedence in 
> pdflatex.
>
> And one idea what the problem might be: Sweave.sty uses the graphicx 
> package, and it may conflict with the graphics package.
>
> Duncan Murdoch


From nashjc at uottawa.ca  Tue May 15 16:16:02 2012
From: nashjc at uottawa.ca (John C Nash)
Date: Tue, 15 May 2012 10:16:02 -0400
Subject: [Rd] How to set up an object to share data across diverse functions
In-Reply-To: <mailman.21.1337076008.29272.r-devel@r-project.org>
References: <mailman.21.1337076008.29272.r-devel@r-project.org>
Message-ID: <4FB26522.3060100@uottawa.ca>

In the past 6 months I've been struggling with an issue that has been raised periodically
on the lists. This is the need to share information across a group of functions, possibly
from different packages. So far I've found solutions that are either quite clumsy or else
don't work as have (likely incorrectly) read the manuals.

I'll be writing up my experiences as a way to help others, but am wondering if there is an
accepted way to establish an object that can be read and written by a number of functions.
I'm currently using list2env to create a list under the "umbrella" function, and if
necessary pass this to other functions by name through the dot arguments, though
preferably I'd rather use a pre-arranged and fixed name (this does not seem to work unless
the object is in the global environment, and then I've occasionally had locked bindings
errors, which I'll freely admit I don't understand at all). I also have to be very careful
with dot arguments, especially if they are matrices.

I've a couple of examples, but they are pretty long, so I'll save for off-list transmission.

JN


From alfredonaim at gmail.com  Tue May 15 15:55:08 2012
From: alfredonaim at gmail.com (Alfredo Naime)
Date: Tue, 15 May 2012 09:25:08 -0430
Subject: [Rd] Object-oriented programming (OOP)
Message-ID: <CANk6ovHqFRC5WcEcsMa2-h5TJzscbBvTw1ow+U+szBeH6g_k_w@mail.gmail.com>

Hello everybody, please excuse my bad English. I am Alfredo Naime and
I'm from to Venezuela.

I want to make a lib with tools for simulation (queues, inventories,
factory, etc.) using object-oriented programming (OOP).

You have any manuals on the handling of data types, classes,
inheritance, etc. in R with examples and how to make a R lib.

Thank you, very much.

Alfredo


From jthetzel at gmail.com  Tue May 15 15:57:08 2012
From: jthetzel at gmail.com (jthetzel)
Date: Tue, 15 May 2012 06:57:08 -0700 (PDT)
Subject: [Rd] Package does not have a NAMESPACE and should be
	re-installed
In-Reply-To: <20120514143700.864333z9i73pzcuk@mail.msu.edu>
References: <20120514143700.864333z9i73pzcuk@mail.msu.edu>
Message-ID: <1337090228021-4630093.post@n4.nabble.com>

If you do not have access to the package's source code, you can try unzipping
the the zip file, adding a NAMESPACE file, and re-zipping the package.  
It's not ideal, but it should work.  This post from Stack Overflow has some
more details:
http://stackoverflow.com/questions/8012596/error-with-asreml-d-package-in-r-2-14-0/8014357#8014357
.

Jeremy


Jeremy Hetzel
Boston University



walcotteric wrote
> 
> I'm trying to load a package locally from a zip file. When I load the  
> package, I first get this, which looks okay:
> 
> package ?IBGEPesq? successfully unpacked and MD5 sums checked
> 
> HOWEVER, when I try to use the package to use the data with
> library(IBGEPesq)
> 
> I get this message:
> 
>   package ?IBGEPesq? does not have a NAMESPACE and should be re-installed
> 
> I've tried re-installing it, and I've tried following suggestions on  
> similar posts, but with no success.
> 
> 

-----
Jeremy T. Hetzel
Boston University
--
View this message in context: http://r.789695.n4.nabble.com/Package-does-not-have-a-NAMESPACE-and-should-be-re-installed-tp4630059p4630093.html
Sent from the R devel mailing list archive at Nabble.com.


From michael.weylandt at gmail.com  Tue May 15 16:29:00 2012
From: michael.weylandt at gmail.com (R. Michael Weylandt)
Date: Tue, 15 May 2012 10:29:00 -0400
Subject: [Rd] Object-oriented programming (OOP)
In-Reply-To: <CANk6ovHqFRC5WcEcsMa2-h5TJzscbBvTw1ow+U+szBeH6g_k_w@mail.gmail.com>
References: <CANk6ovHqFRC5WcEcsMa2-h5TJzscbBvTw1ow+U+szBeH6g_k_w@mail.gmail.com>
Message-ID: <CAAmySGN=4fJDep3C10LSy451mmUPcrLvZUOsQDreEXFg6jqrLw@mail.gmail.com>

R has multiple OO paradigms, but since you're starting from a point of
"I want object oriented," I'd guess you would be interested in the S4
paradigm which is stricter rather than the far more sane S3 system.

If S4 is for you, there are some good links here:
http://stackoverflow.com/questions/4143611/sources-on-s4-objects-methods-and-programming-in-r

See also the relatively new "Reference Classes" -- I don't have much
documentation on those, but you could start here:
http://www.bioconductor.org/help/course-materials/2010/HeidelbergNovember2010/ReferenceClasses-Morgan.pdf

Best,
Michael

On Tue, May 15, 2012 at 9:55 AM, Alfredo Naime <alfredonaim at gmail.com> wrote:
> Hello everybody, please excuse my bad English. I am Alfredo Naime and
> I'm from to Venezuela.
>
> I want to make a lib with tools for simulation (queues, inventories,
> factory, etc.) using object-oriented programming (OOP).
>
> You have any manuals on the handling of data types, classes,
> inheritance, etc. in R with examples and how to make a R lib.
>
> Thank you, very much.
>
> Alfredo
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From walcott3 at msu.edu  Tue May 15 18:22:46 2012
From: walcott3 at msu.edu (walcotteric)
Date: Tue, 15 May 2012 09:22:46 -0700 (PDT)
Subject: [Rd] Package does not have a NAMESPACE and should be
	re-installed
In-Reply-To: <1337090228021-4630093.post@n4.nabble.com>
References: <20120514143700.864333z9i73pzcuk@mail.msu.edu>
	<1337090228021-4630093.post@n4.nabble.com>
Message-ID: <1337098966619-4630132.post@n4.nabble.com>


jthetzel wrote
> 
> If you do not have access to the package's source code, you can try
> unzipping the the zip file, adding a NAMESPACE file, and re-zipping the
> package.   It's not ideal, but it should work.  This post from Stack
> Overflow has some more details:
> http://stackoverflow.com/questions/8012596/error-with-asreml-d-package-in-r-2-14-0/8014357#8014357
> .
> 
> Jeremy
> 
> 
> Jeremy Hetzel
> Boston University
> 
> 
> 


Thanks! That worked and the package and library are loaded, and it shows
that there is data there when I used

data()

However, now when I try to load the data to work with it, I get the
following:

Error in data(ocupacao2005) : invalid 'setTime' argument
In addition: Warning message:
In data(ocupacao2005) : zipped data found for package ?IBGEPesq?.
That is defunct, so please re-install the package.

I'm playing around with it trying to fix it, but not sure exactly what it
means. Any suggestions?


--
View this message in context: http://r.789695.n4.nabble.com/Package-does-not-have-a-NAMESPACE-and-should-be-re-installed-tp4630059p4630132.html
Sent from the R devel mailing list archive at Nabble.com.


From rhurlin at gwdg.de  Tue May 15 19:05:44 2012
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Tue, 15 May 2012 19:05:44 +0200
Subject: [Rd] R-devel on FreeBSD: new C99 functions don't build
Message-ID: <4FB28CE8.5010303@gwdg.de>

About April 25th, there had been some changes within R-devel's 
src/nmath/pnbeta.c (and probably some other relevant places) and now 
building R-devel on FreeBSD 10.0-CURRENT (amd64) with gcc-4.6.4 and 
math/R-devel (selfmade forked port from math/R) fails like this:

[..snip..]
mkdir /usr/ports/math/R-devel/work/R-devel/bin/exec
gcc46 -std=gnu99     -I../../src/extra   -I. -I../../src/include 
-I../../src/include -I/usr/local/include -DHAVE_CONFIG_H  -fopenmp -fpic 
    -O2 -pipe -O2 -fno-strict-aliasing -pipe -msse3 
-Wl,-rpath=/usr/local/lib/gcc46 -c Rmain.c -o Rmain.o
gcc46 -std=gnu99 -export-dynamic -fopenmp -L/usr/local/lib 
-Wl,-rpath=/usr/local/lib/gcc46 -o R.bin Rmain.o -L../../lib -lR -lRblas
../../lib/libR.so: undefined reference to `log1pl'
collect2: ld returned 1 exit status
*** [R.bin] Error code 1
Stop in /usr/ports/math/R-devel/work/R-devel/src/main.
*** [R] Error code 1
Stop in /usr/ports/math/R-devel/work/R-devel/src/main.
*** [R] Error code 1
Stop in /usr/ports/math/R-devel/work/R-devel/src.
*** [R] Error code 1
Stop in /usr/ports/math/R-devel/work/R-devel.
*** [do-build] Error code 1
Stop in /usr/ports/math/R-devel.
*** [build] Error code 1
Stop in /usr/ports/math/R-devel.
===>>> make failed for math/R-devel


It seems, that at least one new C99 function (log1pl) is introduced in 
R-devel, see

src/nmath/pnbeta.c:l95
return (double) (log_p ? log1pl(-ans) : (1 - ans));

for which there is only a declaration in FreeBSDs math.h, but no full 
implementation in libm (see http://wiki.freebsd.org/MissingMathStuff).

Is there any chance to get at least rudimentary replacement functions in 
R-devel for systems with missing or defective C99 math functions?

(For example, in the similar case of log1p(), see the RMATH_HAVE_LOG1P 
and RMATH_HAVE_WORKING_LOG1P bits in the configure script, 
src/include/Rmath.h0.in, and src/nmath/log1p.c; thanks to b.f. for 
pointing me out to this).

Thanks for any help,
Rainer Hurling


CC'ed to b.f. as the maintainer of the math/R port on FreeBSD.


From jthetzel at gmail.com  Tue May 15 20:23:05 2012
From: jthetzel at gmail.com (jthetzel)
Date: Tue, 15 May 2012 11:23:05 -0700 (PDT)
Subject: [Rd] Package does not have a NAMESPACE and should be
	re-installed
In-Reply-To: <1337098966619-4630132.post@n4.nabble.com>
References: <20120514143700.864333z9i73pzcuk@mail.msu.edu>
	<1337090228021-4630093.post@n4.nabble.com>
	<1337098966619-4630132.post@n4.nabble.com>
Message-ID: <1337106185977-4630162.post@n4.nabble.com>



> Thanks! That worked and the package and library are loaded, and it shows
> that there is data there when I used
> 
> data()
> 
> However, now when I try to load the data to work with it, I get the
> following:
> 
> Error in data(ocupacao2005) : invalid 'setTime' argument
> In addition: Warning message:
> In data(ocupacao2005) : zipped data found for package ?IBGEPesq?.
> That is defunct, so please re-install the package.
> 
> I'm playing around with it trying to fix it, but not sure exactly what it
> means. Any suggestions?
> 

1) Does traceback() give any hints as to where the "setTime" error is coming
from?

2) Zipping data sets in packages was made defunct in R 2.13.0.  However, I
believe R 2.15 will still load data sets that were zipped using older
versions of R, albeit with the warning that you see.  As you are not the
package maintainer, you can ignore it.


-----
Jeremy T. Hetzel
Boston University
--
View this message in context: http://r.789695.n4.nabble.com/Package-does-not-have-a-NAMESPACE-and-should-be-re-installed-tp4630059p4630162.html
Sent from the R devel mailing list archive at Nabble.com.


From murray at stokely.org  Tue May 15 20:49:44 2012
From: murray at stokely.org (Murray Stokely)
Date: Tue, 15 May 2012 11:49:44 -0700
Subject: [Rd] R-devel on FreeBSD: new C99 functions don't build
In-Reply-To: <4FB28CE8.5010303@gwdg.de>
References: <4FB28CE8.5010303@gwdg.de>
Message-ID: <CAECWziL1+tna1WwA-Qk_D6BavJyEDmrJkSa_QBEyj9+2BdoSqQ@mail.gmail.com>

On Tue, May 15, 2012 at 10:05 AM, Rainer Hurling <rhurlin at gwdg.de> wrote:
> About April 25th, there had been some changes within R-devel's
> src/nmath/pnbeta.c (and probably some other relevant places) and now
> building R-devel on FreeBSD 10.0-CURRENT (amd64) with gcc-4.6.4 and
> math/R-devel (selfmade forked port from math/R) fails like this:

> It seems, that at least one new C99 function (log1pl) is introduced in
> R-devel, see
>
> src/nmath/pnbeta.c:l95
> return (double) (log_p ? log1pl(-ans) : (1 - ans));

AFAIK, Bruce Evans is not happy with the numerical accuracy of other
open-source implementations of log1pl and so has blocked their
inclusion in FreeBSD pending work on a better implementation.

Can you put a conditional FreeBSD check here and use log1p instead of
log1pl instead as a workaround?

I can admire the insistence on correctness from the FreeBSD libm
maintainers for their technical purity, but it can be a bit of a pain
for things like this.

         - Murray


From rhurlin at gwdg.de  Tue May 15 21:45:13 2012
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Tue, 15 May 2012 21:45:13 +0200
Subject: [Rd] R-devel on FreeBSD: new C99 functions don't build
In-Reply-To: <CAECWziL1+tna1WwA-Qk_D6BavJyEDmrJkSa_QBEyj9+2BdoSqQ@mail.gmail.com>
References: <4FB28CE8.5010303@gwdg.de>
	<CAECWziL1+tna1WwA-Qk_D6BavJyEDmrJkSa_QBEyj9+2BdoSqQ@mail.gmail.com>
Message-ID: <4FB2B249.6030700@gwdg.de>

On 15.05.2012 20:49 (UTC+1), Murray Stokely wrote:
> On Tue, May 15, 2012 at 10:05 AM, Rainer Hurling<rhurlin at gwdg.de>  wrote:
>> About April 25th, there had been some changes within R-devel's
>> src/nmath/pnbeta.c (and probably some other relevant places) and now
>> building R-devel on FreeBSD 10.0-CURRENT (amd64) with gcc-4.6.4 and
>> math/R-devel (selfmade forked port from math/R) fails like this:
>
>> It seems, that at least one new C99 function (log1pl) is introduced in
>> R-devel, see
>>
>> src/nmath/pnbeta.c:l95
>> return (double) (log_p ? log1pl(-ans) : (1 - ans));
>
> AFAIK, Bruce Evans is not happy with the numerical accuracy of other
> open-source implementations of log1pl and so has blocked their
> inclusion in FreeBSD pending work on a better implementation.
>
> Can you put a conditional FreeBSD check here and use log1p instead of
> log1pl instead as a workaround?
>
> I can admire the insistence on correctness from the FreeBSD libm
> maintainers for their technical purity, but it can be a bit of a pain
> for things like this.
>
>           - Murray

I read about this discussion and in principle I concur with your 
opinion. As a scientist I tend to expect greatest possible correctness 
from a statistical routine, especially when it uses long double format.

As a quick and dirty workaround I applied the following patch:


--- src/nmath/pnbeta.c.orig     2012-04-25 17:55:14.000000000 +0200
+++ src/nmath/pnbeta.c  2012-05-15 20:58:26.000000000 +0200
@@ -92,7 +92,11 @@
      else {
         if(ans > 1 - 1e-10) ML_ERROR(ME_PRECISION, "pnbeta");
         if (ans > 1.0) ans = 1.0;  /* Precaution */
+#if !defined(__FreeBSD__)
         return (double) (log_p ? log1pl(-ans) : (1 - ans));
+#else
+        return (double) (log_p ? log1p(-ans) : (1 - ans));
+#endif /* FreeBSD */
      }
  }


It builds and installs fine now and I hope there are no side effects ...

Thank you for the quick answer and your advice,
Rainer


From rtp at google.com  Wed May 16 18:27:11 2012
From: rtp at google.com (Tyler Pirtle)
Date: Wed, 16 May 2012 09:27:11 -0700
Subject: [Rd] Ghost RefClasses
Message-ID: <CAH9pPRo9vjOhJa453hahSxjOSqqgQy+pV_7zYHPdXzG81SWyig@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120516/320b8eab/attachment.pl>

From therneau at mayo.edu  Wed May 16 22:59:56 2012
From: therneau at mayo.edu (Terry Therneau)
Date: Wed, 16 May 2012 15:59:56 -0500
Subject: [Rd] Evaluation without using the parent frame
Message-ID: <4FB4154C.1070406@mayo.edu>

I've been tracking down a survival problem from R-help today.  A short 
version of the primary issue is reconstructed by the following simple 
example:

library(survival)
attach(lung)
fit <- coxph(Surv(time, status) ~ log(age))
predict(fit, newdata=data.frame(abe=45))

Note the typo in the last line of "abe" instead of "age".  Instead of an 
error message, this returns predictions for all the subjects since 
model.frame matches "age" by searching more widely.   I'd prefer the error.
I suspect this is hard -- I'd like it to not see the attached lung data 
set, but still be able to find the log function.
Is there a not-horribly-complex solution?

I also tried to change the primary function to lm instead of coxph.  It 
has the same problem, but does print a warning that the newdata and 
results have different lengths (which I will incorporate).

Terry T.


From walcott3 at msu.edu  Wed May 16 23:29:40 2012
From: walcott3 at msu.edu (walcotteric)
Date: Wed, 16 May 2012 14:29:40 -0700 (PDT)
Subject: [Rd] Package does not have a NAMESPACE and should be
	re-installed
In-Reply-To: <1337106185977-4630162.post@n4.nabble.com>
References: <20120514143700.864333z9i73pzcuk@mail.msu.edu>
	<1337090228021-4630093.post@n4.nabble.com>
	<1337098966619-4630132.post@n4.nabble.com>
	<1337106185977-4630162.post@n4.nabble.com>
Message-ID: <1337203780730-4630313.post@n4.nabble.com>


jthetzel wrote
> 
> 1) Does traceback() give any hints as to where the "setTime" error is
> coming from?
> 
> 2) Zipping data sets in packages was made defunct in R 2.13.0.  However, I
> believe R 2.15 will still load data sets that were zipped using older
> versions of R, albeit with the warning that you see.  As you are not the
> package maintainer, you can ignore it.
> 

Traceback doesn't help.  Also, I can't just ignore the warning because the
warning/error isn't letting me load the object.

--
View this message in context: http://r.789695.n4.nabble.com/Package-does-not-have-a-NAMESPACE-and-should-be-re-installed-tp4630059p4630313.html
Sent from the R devel mailing list archive at Nabble.com.


From murdoch.duncan at gmail.com  Wed May 16 23:59:55 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 16 May 2012 17:59:55 -0400
Subject: [Rd] Evaluation without using the parent frame
In-Reply-To: <4FB4154C.1070406@mayo.edu>
References: <4FB4154C.1070406@mayo.edu>
Message-ID: <4FB4235B.5080003@gmail.com>

On 12-05-16 4:59 PM, Terry Therneau wrote:
> I've been tracking down a survival problem from R-help today.  A short
> version of the primary issue is reconstructed by the following simple
> example:
>
> library(survival)
> attach(lung)
> fit<- coxph(Surv(time, status) ~ log(age))
> predict(fit, newdata=data.frame(abe=45))
>
> Note the typo in the last line of "abe" instead of "age".  Instead of an
> error message, this returns predictions for all the subjects since
> model.frame matches "age" by searching more widely.   I'd prefer the error.
> I suspect this is hard -- I'd like it to not see the attached lung data
> set, but still be able to find the log function.
> Is there a not-horribly-complex solution?

The best solution is to not use attach(), use data=lung in the fit.

I think if you want to use attach but limit the search, you need 
something like

predict(fit, newdata=list2env(data.frame(abe=45), parent=baseenv()))

but I don't think that meets your "not horribly complex" criterion.

Duncan Murdoch

>
> I also tried to change the primary function to lm instead of coxph.  It
> has the same problem, but does print a warning that the newdata and
> results have different lengths (which I will incorporate).
>
> Terry T.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Thu May 17 11:46:40 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 17 May 2012 10:46:40 +0100
Subject: [Rd] [patch] Behavior of .C() and .Fortran() when given
 double(0) or integer(0).
In-Reply-To: <1336153356.24356.332.camel@Navi.krivitsky.homeip.net>
References: <1336153356.24356.332.camel@Navi.krivitsky.homeip.net>
Message-ID: <4FB4C900.6070204@stats.ox.ac.uk>

On 04/05/2012 18:42, Pavel N. Krivitsky wrote:
> Dear R-devel,
>
> While tracking down some hard-to-reproduce bugs in a package I maintain,
> I stumbled on a behavior change between R 2.15.0 and the current R-devel
> (or SVN trunk).
>
> In 2.15.0 and earlier, if you passed an 0-length vector of the right
> mode (e.g., double(0) or integer(0)) as one of the arguments in a .C()
> call with DUP=TRUE (the default), the C routine would be passed NULL
> (the C pointer, not R NULL) in the corresponding argument. The current

Where did you get that from?  The documentation says it passes an (e.g.) 
double* pointer to a copy of the data area of the R vector.  There is no 
change in the documented behaviour ....  Now, of course a zero-length 
area can be at any address, but none is stated anywhere that I am aware of.

> development version instead passes it a pointer to what appears to be
> memory location immediately following the the SEXP that holds the
> metadata for the argument. If the argument has length 0, this is often
> memory belonging to a different R object. (DUP=FALSE in 2.15.0
> appears to have the same behavior as R-devel.)
>
> .C() documentation and Writing R Extensions don't explicitly specify a
> behavior for 0-length vectors, so I don't know if this change is
> intentional, or whether it was a side-effect of the following news item:
>
>        .C() and .Fortran() do less copying: arguments which are raw,
>        logical, integer, real or complex vectors and are unnamed are not
>        copied before the call, and (named or not) are not copied after
>        the call.  Lists are no longer copied (they are supposed to be
>        used read-only in the C code).
>
> Was the change in the empty vector behavior intentional?
>
> It seems to me that standardizing on the behavior of giving the C
> routine NULL is safer, more consistent with other memory-related
> routines, and more convenient: whereas dereferencing a NULL pointer is
> an immediate (and therefore easily traced) segfault, dereferencing an

That's not true, in general.

> invalid pointer that is nevertheless in the general memory area
> allocated to the program often causes subtle errors down the line;
> R_alloc asked to allocate 0 bytes returns NULL, at least on my platform;

Again, undocumented and should not be relied on.

> and the C routine can easily check if a pointer is NULL, but with the
> R-devel behavior, the programmer has to add an explicit way of telling
> that an empty vector was passed.

It's no different from any other vector length: it is easy for careless 
programmers to read/write off the ends of the allocated area, and this 
is why in R-devel we have an option to check for that (and of course 
also what valgrind is good at finding in an instrumented version of R).

> I've attached a small test case (dotC_NULL.* files) that shows the
> difference. The C file should be built with R CMD SHLIB, and the R file
> calls the functions in the library with a variety of arguments. Output I
> get from running
> R CMD BATCH --no-timing --vanilla --slave dotC_NULL.R
> on R 2.15.0, R trunk, and R trunk with my patch (described below) are attached.
>
> The attached patch (dotC_NULL.patch) against the current trunk
> (affecting src/main/dotcode.c) restores the old behavior for DUP=TRUE
> (i.e., 0-length vector ->  NULL pointer) and extends it to the DUP=FALSE
> case. It does so by checking if an argument --- if it's of mode raw,
> integer, real, or complex --- to a .C() or .Fortran() call has length 0,
> and, if so, sets the pointer to be passed to NULL and then skips the
> copying of the C routine's changes back to the R object for that
> argument. The additional computing cost should be negligible (i.e.,
> checking if vector length equals 0 and break-ing out of a switch
> statement if so).
>
> The patch appears to work, at least for my package, and R CMD check
> passes for all recommended packages (on my 64-bit Linux system), but
> this is my first time working with R's internals, so handle with care.

That's easy: we will not be changing this.  In particular, the new 
checks I refer to above rely on passing the address of an in-process 
memory area with guard bytes.

>                                     Best,
>                                     Pavel Krivitsky
>
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu May 17 11:50:22 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 17 May 2012 10:50:22 +0100
Subject: [Rd] StructTS Examples
In-Reply-To: <CAAmySGM-NoqcfTEHSvJ3ixHQRyj8e8pqZOa881pz2Dz7hJvA3w@mail.gmail.com>
References: <CAAmySGM-NoqcfTEHSvJ3ixHQRyj8e8pqZOa881pz2Dz7hJvA3w@mail.gmail.com>
Message-ID: <4FB4C9DE.5090009@stats.ox.ac.uk>

On 15/05/2012 03:31, R. Michael Weylandt wrote:
> In the examples for StructTS -- ($RHOME)/library/stats/man/StructTS.Rd -- could
>
> par(mfrow = c(4, 1))
> plot(log10(UKgas))
> plot(cbind(fitted(fit), resids=resid(fit)), main = "UK gas consumption")
>
> become
>
> plot(log10(UKgas))
> par(mfrow = c(4, 1))
> plot(cbind(fitted(fit), resids=resid(fit)), main = "UK gas consumption")
>
> ## Note that par was moved down
>
> This makes the plot of UKgas use the whole plot screen (as opposed to
> one small panel while three remain empty) which seems like an
> improvement.

But isn't.  The intention is to use an aspect ratio that gives roughly 
45degree banking, as recommended by Cleveland.

>
> Best,
> Michael
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu May 17 13:12:06 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 17 May 2012 12:12:06 +0100
Subject: [Rd] The constant part of the log-likelihood in StructTS
In-Reply-To: <CAGW7bkyFDeRzfUR91x79VrChvCf5py9ErYbs58eJ0fCOQnZ9Mw@mail.gmail.com>
References: <CAGW7bkyFDeRzfUR91x79VrChvCf5py9ErYbs58eJ0fCOQnZ9Mw@mail.gmail.com>
Message-ID: <4FB4DD06.2030403@stats.ox.ac.uk>

On 30/04/2012 12:37, Jouni Helske wrote:
> Dear all,
>
> I'd like to discuss about a possible bug in function StructTS of stats
> package. It seems that the function returns wrong value of the
> log-likelihood, as the added constant to the relevant part of the
> log-likelihood is misspecified. Here is an simple example:
>
>> data(Nile)
>> fit<- StructTS(Nile, type = "level")
>> fit$loglik
> [1] -367.5194
>
> When computing the log-likelihood with other packages such as KFAS and FKF,
> the loglikelihood value is around -645.
>
> For the local level model, the likelihood is defined by -0.5*n*log(2*pi) -
> 0.5*sum(log(F_t) + v_t^2/sqrt(F_t)) (see for example  Durbin and Koopman
> (2001, page 30). But in StructTS, the likelihood is computed like this:
>
> loglik<- -length(y) * res$value + length(y) * log(2 * pi),
>
> where the first part coincides with the last part of the definition, but
> the constant part has wrong sign and it is not multiplied by 0.5. Also in
> case of missing observations, I think there should be sum(!is.na(y))
> instead of length(y) in the constant term, as the likelihood is only
> computed for those y which are observed.
>
> This does not affect in estimation of model parameters, but it could have
> effects in model comparison or some other cases.
>
> Is there some reason for this kind of constant, or is it just a bug?
>
> Best regards,
>
> Jouni Helske
> PhD student in Statistics
> University of Jyv?skyl?
> Finland

I think you missed the following on the help page:

   loglik: the maximized log-likelihood.  Note that as all these models
           are non-stationary this includes a diffuse prior for some
           observations and hence is not comparable with ?arima? nor
           different types of structural models.

It is explicitly not valid for almost all model comparisons, and those 
few that are valid will use the differences of the quoted values.

Yes, it was an error, but the constant in log-likelihoods is always 
arbitrary and here there is even more indeterminancy.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From whorfin at pixar.com  Thu May 17 00:30:37 2012
From: whorfin at pixar.com (Rick Sayre)
Date: Wed, 16 May 2012 15:30:37 -0700
Subject: [Rd] Passing externalptr to .C()
In-Reply-To: <4FAD93F1.5070803@gmail.com>
References: <4FAD828D.1040707@pixar.com> <4FAD93F1.5070803@gmail.com>
Message-ID: <4FB42A8D.1090903@pixar.com>

Thanks very much for the quick reply.

I'd like to avoid static state in the .so, which is why I'm using
the opaque pointer.  It is indeed possible to convert everything to
.Call(), but the work seems unnecessary given that it used to work
just fine and I am going out of my way to pass things with correct
type conversion and semantics.  Again, this seems like exactly the
usage externalptr was designed for, doesn't it?

It seems I can avoid the warnings by putting the externalptr in
a list:

getDeviceInfo<- function(handle) {
     .C("groovyDevice_getDeviceInfo", PACKAGE="groovyDevice",
	list(handle),	# Avoid pedantic warnings via encapsulation
	status = as.integer(0))[-1] # skip handle
}

void
groovyDevice_getDeviceInfo(SEXP *handle, int *status)
{
     groovyHandle *gh = R_ExternalPtrAddr(*handle);
     *status = GroovyStatus(gh);
}

Perhaps this will help others in the same boat in which I find myself.

Cheers

	--Rick

On 05/11/2012 03:34 PM, Duncan Murdoch wrote:
> On 12-05-11 5:20 PM, Rick Sayre wrote:
>> Greetings.
>>
>> 2.15.0 added this behavior
>> http://developer.r-project.org/blosxom.cgi/R-devel/NEWS/2012/03/29#n2012-03-29
>>
>>
>> o Passing R objects other than atomic vectors, functions, lists and
>> environments to .C() is now deprecated and will give a warning.
>> Most cases (especially NULL) are actually coding errors. NULL
>> will be disallowed in future.
>>
>>
>> This seems to make sense, except that this case includes externalptrs.
>>
>> I have quite a bit of code, designed to interface with various
>> external hardware devices, which uses this sort of idiom:
>>
>> # for example
>> getDeviceInfo<- function(handle) {
>> .C("groovyDevice_getDeviceInfo", PACKAGE="groovyDevice",
>> handle,
>> status = as.integer(0))[-1] # skip handle
>> }
>>
>> where "handle" was the result of a .Call to a routine which
>> returned a SEXP which was the result of a R_MakeExternalPtr() call
>>
>> The "c" routine looked like:
>> void
>> groovyDevice_getDeviceInfo(SEXP handle, int *status)
>> {
>> groovyHandle *gh = R_ExternalPtrAddr(handle);
>> *status = GroovyStatus(gh);
>> }
>>
>> This all used to work fine. As of 2.15.0, I now get this:
>> Warning message:
>> In getDeviceInfo() :
>> passing an object of type 'externalptr' to .C (arg 1) is deprecated
>>
>> Passing the same handle to a .Call() does [of course] work fine.
>>
>> I thought my usage was exactly as designed. How then should I be
>> passing an externalptr to a .C() call?
>
> I think you shouldn't be doing that. You should be using .Call.
>
> If your code can handle external pointer objects (as in the example),
> this should be an easy transition. I haven't tested this, but I think
> the conversion to the .Call interface (less error checking) is simply
>
> SEXP_getDeviceInfo(SEXP handle, SEXP status)
> {
> groovyHandle *gh = R_ExternalPtrAddr(handle);
> INTEGER(Sstatus)[0] = GroovyStatus(gh);
> return R_NilValue;
> }
>
>
> If your code is using the pointer just as an opaque handle, I'd suggest
> keeping an array of them, and pass an index into that array: then .C
> will be fine.
>
> Duncan Murdoch


From therneau at mayo.edu  Thu May 17 14:27:55 2012
From: therneau at mayo.edu (Terry Therneau)
Date: Thu, 17 May 2012 07:27:55 -0500
Subject: [Rd] Evaluation without the parent frame
In-Reply-To: <mailman.27.1337248808.23610.r-devel@r-project.org>
References: <mailman.27.1337248808.23610.r-devel@r-project.org>
Message-ID: <4FB4EECB.3010309@mayo.edu>

Duncan,
   I agree completely with "don't use attach"; if I could get all the 
users of the survival package to agree as well the problem in question 
would go away :-)  I'm thinking about ways to add more effective error 
surveillance.
   Your suggestion was not horribly complex and I'll look into it 
further.  My first foray failed because what I want (I think) is the 
environment that they had when the first ">" came up.  I tried baseenv 
in a spot, but then my code couldn't find the model.frame function.

Terry T.



On 05/17/2012 05:00 AM, Duncan wrote:
> On 12-05-16 4:59 PM, Terry Therneau wrote:
>> >  I've been tracking down a survival problem from R-help today.  A short
>> >  version of the primary issue is reconstructed by the following simple
>> >  example:
>> >
>> >  library(survival)
>> >  attach(lung)
>> >  fit<- coxph(Surv(time, status) ~ log(age))
>> >  predict(fit, newdata=data.frame(abe=45))
>> >
>> >  Note the typo in the last line of "abe" instead of "age".  Instead of an
>> >  error message, this returns predictions for all the subjects since
>> >  model.frame matches "age" by searching more widely.   I'd prefer the error.
>> >  I suspect this is hard -- I'd like it to not see the attached lung data
>> >  set, but still be able to find the log function.
>> >  Is there a not-horribly-complex solution?
> The best solution is to not use attach(), use data=lung in the fit.
>
> I think if you want to use attach but limit the search, you need
> something like
>
> predict(fit, newdata=list2env(data.frame(abe=45), parent=baseenv()))
>
> but I don't think that meets your "not horribly complex" criterion.
>
> Duncan Murdoch
>
>> >
>> >  I also tried to change the primary function to lm instead of coxph.  It
>> >  has the same problem, but does print a warning that the newdata and
>> >  results have different lengths (which I will incorporate).
>> >
>> >  Terry T.
>> >
>> >


From ripley at stats.ox.ac.uk  Thu May 17 14:37:25 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 17 May 2012 13:37:25 +0100
Subject: [Rd] Passing externalptr to .C()
In-Reply-To: <4FB42A8D.1090903@pixar.com>
References: <4FAD828D.1040707@pixar.com> <4FAD93F1.5070803@gmail.com>
	<4FB42A8D.1090903@pixar.com>
Message-ID: <4FB4F105.40504@stats.ox.ac.uk>

On 16/05/2012 23:30, Rick Sayre wrote:
> Thanks very much for the quick reply.
>
> I'd like to avoid static state in the .so, which is why I'm using
> the opaque pointer. It is indeed possible to convert everything to
> .Call(), but the work seems unnecessary given that it used to work
> just fine and I am going out of my way to pass things with correct
> type conversion and semantics. Again, this seems like exactly the
> usage externalptr was designed for, doesn't it?
>
> It seems I can avoid the warnings by putting the externalptr in
> a list:

Actually, 'Writing R Extensions' says:

  .. external pointers should only be used as part of an object with 
normal semantics, for example an attribute or an element of a list.

so that *is* the 'correct semantics' ....

> getDeviceInfo<- function(handle) {
> .C("groovyDevice_getDeviceInfo", PACKAGE="groovyDevice",
> list(handle), # Avoid pedantic warnings via encapsulation
> status = as.integer(0))[-1] # skip handle
> }

> void
> groovyDevice_getDeviceInfo(SEXP *handle, int *status)
> {
> groovyHandle *gh = R_ExternalPtrAddr(*handle);
> *status = GroovyStatus(gh);
> }

> Perhaps this will help others in the same boat in which I find myself.

As has been said here many times recently, .C is an old (some say 
obselete) interface, and pre-dates objects such as external pointers. 
It was chance that this ever worked: it was never designed to.

If you find yourself with C[++] code which uses Rinternals.h it should 
use the .Call/.External interfaces, and there is no guarantee that using 
.C for such things will continue to work (as it is all too easy to break 
R's copying semantics and corrupt loaded R code).

> Cheers
>
> --Rick
>
> On 05/11/2012 03:34 PM, Duncan Murdoch wrote:
>> On 12-05-11 5:20 PM, Rick Sayre wrote:
>>> Greetings.
>>>
>>> 2.15.0 added this behavior
>>> http://developer.r-project.org/blosxom.cgi/R-devel/NEWS/2012/03/29#n2012-03-29
>>>
>>>
>>>
>>> o Passing R objects other than atomic vectors, functions, lists and
>>> environments to .C() is now deprecated and will give a warning.
>>> Most cases (especially NULL) are actually coding errors. NULL
>>> will be disallowed in future.
>>>
>>>
>>> This seems to make sense, except that this case includes externalptrs.
>>>
>>> I have quite a bit of code, designed to interface with various
>>> external hardware devices, which uses this sort of idiom:
>>>
>>> # for example
>>> getDeviceInfo<- function(handle) {
>>> .C("groovyDevice_getDeviceInfo", PACKAGE="groovyDevice",
>>> handle,
>>> status = as.integer(0))[-1] # skip handle
>>> }
>>>
>>> where "handle" was the result of a .Call to a routine which
>>> returned a SEXP which was the result of a R_MakeExternalPtr() call
>>>
>>> The "c" routine looked like:
>>> void
>>> groovyDevice_getDeviceInfo(SEXP handle, int *status)
>>> {
>>> groovyHandle *gh = R_ExternalPtrAddr(handle);
>>> *status = GroovyStatus(gh);
>>> }
>>>
>>> This all used to work fine. As of 2.15.0, I now get this:
>>> Warning message:
>>> In getDeviceInfo() :
>>> passing an object of type 'externalptr' to .C (arg 1) is deprecated
>>>
>>> Passing the same handle to a .Call() does [of course] work fine.
>>>
>>> I thought my usage was exactly as designed. How then should I be
>>> passing an externalptr to a .C() call?
>>
>> I think you shouldn't be doing that. You should be using .Call.
>>
>> If your code can handle external pointer objects (as in the example),
>> this should be an easy transition. I haven't tested this, but I think
>> the conversion to the .Call interface (less error checking) is simply
>>
>> SEXP_getDeviceInfo(SEXP handle, SEXP status)
>> {
>> groovyHandle *gh = R_ExternalPtrAddr(handle);
>> INTEGER(Sstatus)[0] = GroovyStatus(gh);
>> return R_NilValue;
>> }
>>
>>
>> If your code is using the pointer just as an opaque handle, I'd suggest
>> keeping an array of them, and pass an index into that array: then .C
>> will be fine.
>>
>> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ligges at statistik.tu-dortmund.de  Thu May 17 14:42:51 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 17 May 2012 14:42:51 +0200
Subject: [Rd] Package does not have a NAMESPACE and should be
	re-installed
In-Reply-To: <1337203780730-4630313.post@n4.nabble.com>
References: <20120514143700.864333z9i73pzcuk@mail.msu.edu>
	<1337090228021-4630093.post@n4.nabble.com>
	<1337098966619-4630132.post@n4.nabble.com>
	<1337106185977-4630162.post@n4.nabble.com>
	<1337203780730-4630313.post@n4.nabble.com>
Message-ID: <4FB4F24B.3030607@statistik.tu-dortmund.de>



On 16.05.2012 23:29, walcotteric wrote:
>
> jthetzel wrote
>>
>> 1) Does traceback() give any hints as to where the "setTime" error is
>> coming from?
>>
>> 2) Zipping data sets in packages was made defunct in R 2.13.0.  However, I
>> believe R 2.15 will still load data sets that were zipped using older
>> versions of R, albeit with the warning that you see.  As you are not the
>> package maintainer, you can ignore it.
>>
>
> Traceback doesn't help.  Also, I can't just ignore the warning because the
> warning/error isn't letting me load the object.

So easiest solution:
Upgrade to R-2.15.0 and install the package from its source version.

Uwe Ligges



>
> --
> View this message in context: http://r.789695.n4.nabble.com/Package-does-not-have-a-NAMESPACE-and-should-be-re-installed-tp4630059p4630313.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From kasperdanielhansen at gmail.com  Thu May 17 14:52:10 2012
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Thu, 17 May 2012 08:52:10 -0400
Subject: [Rd] r-devel fails tests for parallel
Message-ID: <CAC2h7uufm-iL4PHv9HToCqHyFk1HOSZz+s00JQmoY_juuu7rkA@mail.gmail.com>

I have been building R-devel daily for years.  In the last week or so,
R-devel has failed make check with the error in
  tests/Examples/parallel-Ex.R

The specific error is
> pkgname <- "parallel"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> library('parallel')
Error in dyn.load(file, DLLpath = DLLpath, ...) :
  unable to load shared object
'/hpscc/usr/local/gcc-4.1.2/build/R/R-devel-build/library/parallel/libs/parallel.so':
  /hpscc/usr/local/gcc-4.1.2/build/R/R-devel-build/library/parallel/libs/parallel.so:
undefined symbol: CPU_COUNT
Error: package/namespace load failed for ?parallel?
Execution halted

I am building on Red Hat Enterprise Linux version 4, using
# gcc --version
gcc (GCC) 4.1.2 20080704 (Red Hat 4.1.2-51)
Copyright (C) 2006 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

The specifics of the distro is
# cat /proc/version
Linux version 2.6.18-274.12.1.el5
(mockbuild at x86-001.build.bos.redhat.com) (gcc version 4.1.2 20080704
(Red Hat 4.1.2-51)) #1 SMP Tue Nov 8 21:37:35 EST 2011

I am happy to provide any additional information

Best,
Kasper


From ripley at stats.ox.ac.uk  Thu May 17 15:04:08 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 17 May 2012 14:04:08 +0100
Subject: [Rd] r-devel fails tests for parallel
In-Reply-To: <CAC2h7uufm-iL4PHv9HToCqHyFk1HOSZz+s00JQmoY_juuu7rkA@mail.gmail.com>
References: <CAC2h7uufm-iL4PHv9HToCqHyFk1HOSZz+s00JQmoY_juuu7rkA@mail.gmail.com>
Message-ID: <4FB4F748.6080800@stats.ox.ac.uk>

Seems your ancient OS (that compiler has a 6-year-old copyright date) 
has a broken implementation of affinity with CPU_ZERO but not CPU_COUNT.

I've added some checks which should catch this.

On 17/05/2012 13:52, Kasper Daniel Hansen wrote:
> I have been building R-devel daily for years.  In the last week or so,
> R-devel has failed make check with the error in
>    tests/Examples/parallel-Ex.R
>
> The specific error is
>> pkgname<- "parallel"
>> source(file.path(R.home("share"), "R", "examples-header.R"))
>> options(warn = 1)
>> library('parallel')
> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>    unable to load shared object
> '/hpscc/usr/local/gcc-4.1.2/build/R/R-devel-build/library/parallel/libs/parallel.so':
>    /hpscc/usr/local/gcc-4.1.2/build/R/R-devel-build/library/parallel/libs/parallel.so:
> undefined symbol: CPU_COUNT
> Error: package/namespace load failed for ?parallel?
> Execution halted
>
> I am building on Red Hat Enterprise Linux version 4, using

Hmm, it says .el5: RHEL5 is ancient but RHEL4 is pre-historic!

> # gcc --version
> gcc (GCC) 4.1.2 20080704 (Red Hat 4.1.2-51)
> Copyright (C) 2006 Free Software Foundation, Inc.
> This is free software; see the source for copying conditions.  There is NO
> warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
>
> The specifics of the distro is
> # cat /proc/version
> Linux version 2.6.18-274.12.1.el5
> (mockbuild at x86-001.build.bos.redhat.com) (gcc version 4.1.2 20080704
> (Red Hat 4.1.2-51)) #1 SMP Tue Nov 8 21:37:35 EST 2011
>
> I am happy to provide any additional information
>
> Best,
> Kasper
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From armstrong.whit at gmail.com  Thu May 17 16:10:34 2012
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Thu, 17 May 2012 10:10:34 -0400
Subject: [Rd] test suites for packages
Message-ID: <CAMi=pg6MRN9BxGQz4C=t6x=s1nGKGp_nLRyRwe6zSmKfs1_whA@mail.gmail.com>

Can anyone share some opinions on test suites for R packages?

I'm looking at testthat and RUnit. Does anyone have strong opinions on
either of those.

Any additional packages I should consider?

Thanks,
Whit


From ligges at statistik.tu-dortmund.de  Thu May 17 16:32:34 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 17 May 2012 16:32:34 +0200
Subject: [Rd] test suites for packages
In-Reply-To: <CAMi=pg6MRN9BxGQz4C=t6x=s1nGKGp_nLRyRwe6zSmKfs1_whA@mail.gmail.com>
References: <CAMi=pg6MRN9BxGQz4C=t6x=s1nGKGp_nLRyRwe6zSmKfs1_whA@mail.gmail.com>
Message-ID: <4FB50C02.5050803@statistik.tu-dortmund.de>



On 17.05.2012 16:10, Whit Armstrong wrote:
> Can anyone share some opinions on test suites for R packages?
>
> I'm looking at testthat and RUnit. Does anyone have strong opinions on
> either of those.
>
> Any additional packages I should consider?

Yes: R CMD check does the trick. See Writing R Extension and read about 
a package's test directory. I prefer frameworks that do not obfuscate 
failing test results on the CRAN check farm (as most other frameworks I 
have seen).

Best,
Uwe Ligges




>
> Thanks,
> Whit
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From kasperdanielhansen at gmail.com  Thu May 17 16:48:04 2012
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Thu, 17 May 2012 10:48:04 -0400
Subject: [Rd] r-devel fails tests for parallel
In-Reply-To: <4FB4F748.6080800@stats.ox.ac.uk>
References: <CAC2h7uufm-iL4PHv9HToCqHyFk1HOSZz+s00JQmoY_juuu7rkA@mail.gmail.com>
	<4FB4F748.6080800@stats.ox.ac.uk>
Message-ID: <CAC2h7usyprG4XQfRnr1ucingmdj3ezPxtwz2t+DodT1sAh3Ggw@mail.gmail.com>

On Thu, May 17, 2012 at 9:04 AM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> Seems your ancient OS (that compiler has a 6-year-old copyright date) has a
> broken implementation of affinity with CPU_ZERO but not CPU_COUNT.
>
> I've added some checks which should catch this.

Thanks a lot.

And I apologize for mixing up the red hat version.  I am using EL 5.4.

FInally, while GCC 4.2 is pretty old, it is still the newest release
under GPL 2.  And (more importantly to me), it is the system compiler
on our cluster.

Kasper

>
>
> On 17/05/2012 13:52, Kasper Daniel Hansen wrote:
>>
>> I have been building R-devel daily for years. ?In the last week or so,
>> R-devel has failed make check with the error in
>> ? tests/Examples/parallel-Ex.R
>>
>> The specific error is
>>>
>>> pkgname<- "parallel"
>>> source(file.path(R.home("share"), "R", "examples-header.R"))
>>> options(warn = 1)
>>> library('parallel')
>>
>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>> ? unable to load shared object
>>
>> '/hpscc/usr/local/gcc-4.1.2/build/R/R-devel-build/library/parallel/libs/parallel.so':
>>
>> /hpscc/usr/local/gcc-4.1.2/build/R/R-devel-build/library/parallel/libs/parallel.so:
>> undefined symbol: CPU_COUNT
>> Error: package/namespace load failed for ?parallel?
>> Execution halted
>>
>> I am building on Red Hat Enterprise Linux version 4, using
>
>
> Hmm, it says .el5: RHEL5 is ancient but RHEL4 is pre-historic!
>
>> # gcc --version
>> gcc (GCC) 4.1.2 20080704 (Red Hat 4.1.2-51)
>> Copyright (C) 2006 Free Software Foundation, Inc.
>> This is free software; see the source for copying conditions. ?There is NO
>> warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR
>> PURPOSE.
>>
>> The specifics of the distro is
>> # cat /proc/version
>> Linux version 2.6.18-274.12.1.el5
>> (mockbuild at x86-001.build.bos.redhat.com) (gcc version 4.1.2 20080704
>> (Red Hat 4.1.2-51)) #1 SMP Tue Nov 8 21:37:35 EST 2011
>>
>> I am happy to provide any additional information
>>
>> Best,
>> Kasper
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
> --
> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595


From brian at braverock.com  Thu May 17 16:52:53 2012
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 17 May 2012 09:52:53 -0500
Subject: [Rd] test suites for packages
In-Reply-To: <4FB50C02.5050803@statistik.tu-dortmund.de>
References: <CAMi=pg6MRN9BxGQz4C=t6x=s1nGKGp_nLRyRwe6zSmKfs1_whA@mail.gmail.com>
	<4FB50C02.5050803@statistik.tu-dortmund.de>
Message-ID: <1337266373.18928.2.camel@brian-rcg>

On Thu, 2012-05-17 at 16:32 +0200, Uwe Ligges wrote:
> Yes: R CMD check does the trick. See Writing R Extension and read
> about a package's test directory. I prefer frameworks that do not
> obfuscate failing test results on the CRAN check farm (as most other
> frameworks I have seen).

Uwe:  I don't think that's completely fair.  RUnit and testthat tests
can be configured to be called from the R package tests directory, so
that they are run during R CMD check.

They don't *need* to be configured that way, so perhaps that's what
you're talking about.

-- 
Brian


From ligges at statistik.tu-dortmund.de  Thu May 17 16:59:13 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 17 May 2012 16:59:13 +0200
Subject: [Rd] test suites for packages
In-Reply-To: <1337266373.18928.2.camel@brian-rcg>
References: <CAMi=pg6MRN9BxGQz4C=t6x=s1nGKGp_nLRyRwe6zSmKfs1_whA@mail.gmail.com>
	<4FB50C02.5050803@statistik.tu-dortmund.de>
	<1337266373.18928.2.camel@brian-rcg>
Message-ID: <4FB51241.90209@statistik.tu-dortmund.de>



On 17.05.2012 16:52, Brian G. Peterson wrote:
> On Thu, 2012-05-17 at 16:32 +0200, Uwe Ligges wrote:
>> Yes: R CMD check does the trick. See Writing R Extension and read
>> about a package's test directory. I prefer frameworks that do not
>> obfuscate failing test results on the CRAN check farm (as most other
>> frameworks I have seen).
>
> Uwe:  I don't think that's completely fair.  RUnit and testthat tests
> can be configured to be called from the R package tests directory, so
> that they are run during R CMD check.
>
> They don't *need* to be configured that way, so perhaps that's what
> you're talking about.


I am talking about the problem that relevant output of test failures 
that may help to identify the problem is frequently not shown in the 
output of R CMD check when such frameworks are used - that is a major 
nuisance for CRAN automatisms.

If additional configuration steps are required, fine, but then package 
maintainers seem to forget about that step. We do not have the time to 
tell hundreds of package maintainers how to configure their preferred 
test framework (whatever it is).

Best,
Uwe


From ripley at stats.ox.ac.uk  Thu May 17 17:09:16 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 17 May 2012 16:09:16 +0100
Subject: [Rd] r-devel fails tests for parallel
In-Reply-To: <CAC2h7usyprG4XQfRnr1ucingmdj3ezPxtwz2t+DodT1sAh3Ggw@mail.gmail.com>
References: <CAC2h7uufm-iL4PHv9HToCqHyFk1HOSZz+s00JQmoY_juuu7rkA@mail.gmail.com>
	<4FB4F748.6080800@stats.ox.ac.uk>
	<CAC2h7usyprG4XQfRnr1ucingmdj3ezPxtwz2t+DodT1sAh3Ggw@mail.gmail.com>
Message-ID: <4FB5149C.8060107@stats.ox.ac.uk>

On 17/05/2012 15:48, Kasper Daniel Hansen wrote:
> On Thu, May 17, 2012 at 9:04 AM, Prof Brian Ripley
> <ripley at stats.ox.ac.uk>  wrote:
>> Seems your ancient OS (that compiler has a 6-year-old copyright date) has a
>> broken implementation of affinity with CPU_ZERO but not CPU_COUNT.
>>
>> I've added some checks which should catch this.
>
> Thanks a lot.
>
> And I apologize for mixing up the red hat version.  I am using EL 5.4.
>
> FInally, while GCC 4.2 is pretty old, it is still the newest release

But yours is 4.1.2 (Feb 2007).  Apple seems to have stuck at 4.2.1 for 
the GPL reason.

> under GPL 2.  And (more importantly to me), it is the system compiler
> on our cluster.

This is getting increasingly difficult.  GCC 4.6.x and 4.7.x detect a 
lot of errors (especially C++ errors) that earlier versions did not -- 
and that means CRAN gets a fair number of submissions that we cannot 
compile.  And there have been a lot of optimization advances since 4.1.x.

>
> Kasper
>
>>
>>
>> On 17/05/2012 13:52, Kasper Daniel Hansen wrote:
>>>
>>> I have been building R-devel daily for years.  In the last week or so,
>>> R-devel has failed make check with the error in
>>>    tests/Examples/parallel-Ex.R
>>>
>>> The specific error is
>>>>
>>>> pkgname<- "parallel"
>>>> source(file.path(R.home("share"), "R", "examples-header.R"))
>>>> options(warn = 1)
>>>> library('parallel')
>>>
>>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>>    unable to load shared object
>>>
>>> '/hpscc/usr/local/gcc-4.1.2/build/R/R-devel-build/library/parallel/libs/parallel.so':
>>>
>>> /hpscc/usr/local/gcc-4.1.2/build/R/R-devel-build/library/parallel/libs/parallel.so:
>>> undefined symbol: CPU_COUNT
>>> Error: package/namespace load failed for ?parallel?
>>> Execution halted
>>>
>>> I am building on Red Hat Enterprise Linux version 4, using
>>
>>
>> Hmm, it says .el5: RHEL5 is ancient but RHEL4 is pre-historic!
>>
>>> # gcc --version
>>> gcc (GCC) 4.1.2 20080704 (Red Hat 4.1.2-51)
>>> Copyright (C) 2006 Free Software Foundation, Inc.
>>> This is free software; see the source for copying conditions.  There is NO
>>> warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR
>>> PURPOSE.
>>>
>>> The specifics of the distro is
>>> # cat /proc/version
>>> Linux version 2.6.18-274.12.1.el5
>>> (mockbuild at x86-001.build.bos.redhat.com) (gcc version 4.1.2 20080704
>>> (Red Hat 4.1.2-51)) #1 SMP Tue Nov 8 21:37:35 EST 2011
>>>
>>> I am happy to provide any additional information
>>>
>>> Best,
>>> Kasper
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From mdowle at mdowle.plus.com  Thu May 17 17:56:11 2012
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Thu, 17 May 2012 15:56:11 +0000
Subject: [Rd] test suites for packages
References: <CAMi=pg6MRN9BxGQz4C=t6x=s1nGKGp_nLRyRwe6zSmKfs1_whA@mail.gmail.com>
	<4FB50C02.5050803@statistik.tu-dortmund.de>
	<1337266373.18928.2.camel@brian-rcg>
	<4FB51241.90209@statistik.tu-dortmund.de>
Message-ID: <loom.20120517T174345-994@post.gmane.org>

Uwe Ligges <ligges <at> statistik.tu-dortmund.de> writes:
> 
> On 17.05.2012 16:52, Brian G. Peterson wrote:
> > On Thu, 2012-05-17 at 16:32 +0200, Uwe Ligges wrote:
> >> Yes: R CMD check does the trick. See Writing R Extension and read
> >> about a package's test directory. I prefer frameworks that do not
> >> obfuscate failing test results on the CRAN check farm (as most other
> >> frameworks I have seen).
> >
> > Uwe:  I don't think that's completely fair.  RUnit and testthat tests
> > can be configured to be called from the R package tests directory, so
> > that they are run during R CMD check.
> >
> > They don't *need* to be configured that way, so perhaps that's what
> > you're talking about.
> 
> I am talking about the problem that relevant output of test failures 
> that may help to identify the problem is frequently not shown in the 
> output of R CMD check when such frameworks are used - that is a major 
> nuisance for CRAN automatisms.

Not sure, but could it be that in some cases the output of test failures is 
there, but chopped off since CRAN displays the 13 line tail? At least that's 
what I've experienced, and reported, and asked to be increased in the past. 
Often the first error causes a cascade, so it's the head you need to see, not 
the tail. If I've got that right, how about a much larger limit than 13, say 
1000. Or the first 50 and last 50 lines of output.

Matthew


From ligges at statistik.tu-dortmund.de  Thu May 17 18:08:47 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 17 May 2012 18:08:47 +0200
Subject: [Rd] test suites for packages
In-Reply-To: <loom.20120517T174345-994@post.gmane.org>
References: <CAMi=pg6MRN9BxGQz4C=t6x=s1nGKGp_nLRyRwe6zSmKfs1_whA@mail.gmail.com>
	<4FB50C02.5050803@statistik.tu-dortmund.de>
	<1337266373.18928.2.camel@brian-rcg>
	<4FB51241.90209@statistik.tu-dortmund.de>
	<loom.20120517T174345-994@post.gmane.org>
Message-ID: <4FB5228F.6000506@statistik.tu-dortmund.de>



On 17.05.2012 17:56, Matthew Dowle wrote:
> Uwe Ligges<ligges<at>  statistik.tu-dortmund.de>  writes:
>>
>> On 17.05.2012 16:52, Brian G. Peterson wrote:
>>> On Thu, 2012-05-17 at 16:32 +0200, Uwe Ligges wrote:
>>>> Yes: R CMD check does the trick. See Writing R Extension and read
>>>> about a package's test directory. I prefer frameworks that do not
>>>> obfuscate failing test results on the CRAN check farm (as most other
>>>> frameworks I have seen).
>>>
>>> Uwe:  I don't think that's completely fair.  RUnit and testthat tests
>>> can be configured to be called from the R package tests directory, so
>>> that they are run during R CMD check.
>>>
>>> They don't *need* to be configured that way, so perhaps that's what
>>> you're talking about.
>>
>> I am talking about the problem that relevant output of test failures
>> that may help to identify the problem is frequently not shown in the
>> output of R CMD check when such frameworks are used - that is a major
>> nuisance for CRAN automatisms.
>
> Not sure, but could it be that in some cases the output of test failures is
> there, but chopped off since CRAN displays the 13 line tail? At least that's
> what I've experienced, and reported, and asked to be increased in the past.
> Often the first error causes a cascade, so it's the head you need to see, not
> the tail. If I've got that right, how about a much larger limit than 13, say
> 1000. Or the first 50 and last 50 lines of output.

R always reports the whole diffs of the tests.

Uwe



>
> Matthew
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From kasperdanielhansen at gmail.com  Thu May 17 23:48:11 2012
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Thu, 17 May 2012 17:48:11 -0400
Subject: [Rd] r-devel fails tests for parallel
In-Reply-To: <4FB5149C.8060107@stats.ox.ac.uk>
References: <CAC2h7uufm-iL4PHv9HToCqHyFk1HOSZz+s00JQmoY_juuu7rkA@mail.gmail.com>
	<4FB4F748.6080800@stats.ox.ac.uk>
	<CAC2h7usyprG4XQfRnr1ucingmdj3ezPxtwz2t+DodT1sAh3Ggw@mail.gmail.com>
	<4FB5149C.8060107@stats.ox.ac.uk>
Message-ID: <CAC2h7uvQ=Wnd5HV45xmHGHA2y=BFtR0jdCBUnORYAO9_453Vhg@mail.gmail.com>

I am happy to report that R-devel (r59358) passes make check on my platform.

And sorry for the complete mixup today el4/el5 and 4.1.2 vs 4.2.1

Thanks,
Kasper

On Thu, May 17, 2012 at 11:09 AM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> On 17/05/2012 15:48, Kasper Daniel Hansen wrote:
>>
>> On Thu, May 17, 2012 at 9:04 AM, Prof Brian Ripley
>> <ripley at stats.ox.ac.uk> ?wrote:
>>>
>>> Seems your ancient OS (that compiler has a 6-year-old copyright date) has
>>> a
>>> broken implementation of affinity with CPU_ZERO but not CPU_COUNT.
>>>
>>> I've added some checks which should catch this.
>>
>>
>> Thanks a lot.
>>
>> And I apologize for mixing up the red hat version. ?I am using EL 5.4.
>>
>> FInally, while GCC 4.2 is pretty old, it is still the newest release
>
>
> But yours is 4.1.2 (Feb 2007). ?Apple seems to have stuck at 4.2.1 for the
> GPL reason.
>
>
>> under GPL 2. ?And (more importantly to me), it is the system compiler
>> on our cluster.
>
>
> This is getting increasingly difficult. ?GCC 4.6.x and 4.7.x detect a lot of
> errors (especially C++ errors) that earlier versions did not -- and that
> means CRAN gets a fair number of submissions that we cannot compile. ?And
> there have been a lot of optimization advances since 4.1.x.
>
>
>>
>> Kasper
>>
>>>
>>>
>>> On 17/05/2012 13:52, Kasper Daniel Hansen wrote:
>>>>
>>>>
>>>> I have been building R-devel daily for years. ?In the last week or so,
>>>> R-devel has failed make check with the error in
>>>> ? tests/Examples/parallel-Ex.R
>>>>
>>>> The specific error is
>>>>>
>>>>>
>>>>> pkgname<- "parallel"
>>>>> source(file.path(R.home("share"), "R", "examples-header.R"))
>>>>> options(warn = 1)
>>>>> library('parallel')
>>>>
>>>>
>>>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>>>> ? unable to load shared object
>>>>
>>>>
>>>> '/hpscc/usr/local/gcc-4.1.2/build/R/R-devel-build/library/parallel/libs/parallel.so':
>>>>
>>>>
>>>> /hpscc/usr/local/gcc-4.1.2/build/R/R-devel-build/library/parallel/libs/parallel.so:
>>>> undefined symbol: CPU_COUNT
>>>> Error: package/namespace load failed for ?parallel?
>>>> Execution halted
>>>>
>>>> I am building on Red Hat Enterprise Linux version 4, using
>>>
>>>
>>>
>>> Hmm, it says .el5: RHEL5 is ancient but RHEL4 is pre-historic!
>>>
>>>> # gcc --version
>>>> gcc (GCC) 4.1.2 20080704 (Red Hat 4.1.2-51)
>>>> Copyright (C) 2006 Free Software Foundation, Inc.
>>>> This is free software; see the source for copying conditions. ?There is
>>>> NO
>>>> warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR
>>>> PURPOSE.
>>>>
>>>> The specifics of the distro is
>>>> # cat /proc/version
>>>> Linux version 2.6.18-274.12.1.el5
>>>> (mockbuild at x86-001.build.bos.redhat.com) (gcc version 4.1.2 20080704
>>>> (Red Hat 4.1.2-51)) #1 SMP Tue Nov 8 21:37:35 EST 2011
>>>>
>>>> I am happy to provide any additional information
>>>>
>>>> Best,
>>>> Kasper
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>>
>>>
>>> --
>>> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
>>> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
>>> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
>>> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
>>> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595
>
>
>
> --
> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595


From murray at stokely.org  Fri May 18 00:08:20 2012
From: murray at stokely.org (Murray Stokely)
Date: Thu, 17 May 2012 15:08:20 -0700
Subject: [Rd] r-devel fails tests for parallel
In-Reply-To: <4FB5149C.8060107@stats.ox.ac.uk>
References: <CAC2h7uufm-iL4PHv9HToCqHyFk1HOSZz+s00JQmoY_juuu7rkA@mail.gmail.com>
	<4FB4F748.6080800@stats.ox.ac.uk>
	<CAC2h7usyprG4XQfRnr1ucingmdj3ezPxtwz2t+DodT1sAh3Ggw@mail.gmail.com>
	<4FB5149C.8060107@stats.ox.ac.uk>
Message-ID: <CAECWzi+jUaATVLZKy7W11qK9bjPsyTC=EDqAvFmY-zKuodfwmg@mail.gmail.com>

On Thu, May 17, 2012 at 8:09 AM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> This is getting increasingly difficult. ?GCC 4.6.x and 4.7.x detect a lot of
> errors (especially C++ errors) that earlier versions did not -- and that
> means CRAN gets a fair number of submissions that we cannot compile. ?And
> there have been a lot of optimization advances since 4.1.x.

I would also point out that clang has significantly better error
detection and diagnostics compared to current GCC.  Installations
stuck with old GCC releases for GPL3 reasons should really migrate to
clang / llvm.

                - Murray


From simon.urbanek at r-project.org  Fri May 18 00:14:24 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 17 May 2012 18:14:24 -0400
Subject: [Rd] r-devel fails tests for parallel
In-Reply-To: <CAECWzi+jUaATVLZKy7W11qK9bjPsyTC=EDqAvFmY-zKuodfwmg@mail.gmail.com>
References: <CAC2h7uufm-iL4PHv9HToCqHyFk1HOSZz+s00JQmoY_juuu7rkA@mail.gmail.com>
	<4FB4F748.6080800@stats.ox.ac.uk>
	<CAC2h7usyprG4XQfRnr1ucingmdj3ezPxtwz2t+DodT1sAh3Ggw@mail.gmail.com>
	<4FB5149C.8060107@stats.ox.ac.uk>
	<CAECWzi+jUaATVLZKy7W11qK9bjPsyTC=EDqAvFmY-zKuodfwmg@mail.gmail.com>
Message-ID: <F2B26510-2143-4772-9603-4B19FBF6F59D@r-project.org>


On May 17, 2012, at 6:08 PM, Murray Stokely wrote:

> On Thu, May 17, 2012 at 8:09 AM, Prof Brian Ripley
> <ripley at stats.ox.ac.uk> wrote:
>> This is getting increasingly difficult.  GCC 4.6.x and 4.7.x detect a lot of
>> errors (especially C++ errors) that earlier versions did not -- and that
>> means CRAN gets a fair number of submissions that we cannot compile.  And
>> there have been a lot of optimization advances since 4.1.x.
> 
> I would also point out that clang has significantly better error detection and diagnostics compared to current GCC.  Installations stuck with old GCC releases for GPL3 reasons should really migrate to clang / llvm.
> 

The problem is that unfortunately clang is too incomplete for that -- it lacks Fortran and OpenMP support - both are quite important for R so migrating to clang is not realistic so far.

Cheers,
Simon


From stephen.pederson at adelaide.edu.au  Fri May 18 08:55:26 2012
From: stephen.pederson at adelaide.edu.au (Steve Pederson)
Date: Fri, 18 May 2012 16:25:26 +0930
Subject: [Rd] Cannot Install Custom Package On Windows7 64-bit
Message-ID: <000001cd34c3$34e8ee00$9ebaca00$@pederson@adelaide.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120518/64c4c2ab/attachment.pl>

From ligges at statistik.tu-dortmund.de  Fri May 18 09:57:19 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 18 May 2012 09:57:19 +0200
Subject: [Rd] Cannot Install Custom Package On Windows7 64-bit
In-Reply-To: <000001cd34c3$34e8ee00$9ebaca00$@pederson@adelaide.edu.au>
References: <000001cd34c3$34e8ee00$9ebaca00$@pederson@adelaide.edu.au>
Message-ID: <4FB600DF.3010006@statistik.tu-dortmund.de>



On 18.05.2012 08:55, Steve Pederson wrote:
> Hi,
>
>
>
> After uninstalling Rtools 2.14.0, I have installed the latest version of
> Rtools 2.15.0 which gives the two folders
>
> C:\Rtools\bin
>
> C:\Rtools\gcc-4.6.3
>
>
>
> R is installed in the directory
>
> C:\R\R-2.15.0
>
>
>
> I have set the Environment Variable
>
> PATH=c:\Rtools\bin;c:\Rtools\gcc-4.6.3\bin;c:\R\R-2.15.0\bin;<others>
>
>
>
> I am trying to install a custom package (BMEA_0.2.1) which is exactly as
> written&  built successfully on R-2.14.0
>
>
>
> When I use R CMD INSTALL BMEA_0.2.1.tar.gz, I get the following output
>
> * installing to library 'C:/R/R-2.15.0/library'
>
> * installing *source* package 'BMEA' ...
>
> ** libs
>
> cygwin warning:
>
>    MS-DOS style path detected: C:/R/R-2.15.0/etc/x64/Makeconf
>
>    Preferred POSIX equivalent is: /cygdrive/c/R/R-2.15.0/etc/x64/Makeconf
>
>    CYGWIN environment variable option "nodosfilewarning" turns off this
> warning


1. Do what it says and

set CYGWIN=nodosfilewarning

to avoid lots of warnings.



>    Consult the user's guide for more details about POSIX paths:
>
>       http://cygwin.com/cygwin-ug-net/using.html#using-pathnames
>
> gcc -m64 -I"C:/R/R-2.15.0/include" -DNDEBUG
> -I"d:/RCompile/CRANpkg/extralibs64/local/include"       -02 -Wall
> -std=gnu99 -mtune-core2 -c getLogFC.c -o getLogFC.o
>
> gcc: not found

2. So far your PATH look good, but it may be messed up later on, hence 
tell us what

echo %PATH%

returns and be sure you started a new Windows command shell after 
changing the PATH environment variable.

Best,
Uwe Ligges





> make: *** [getLogFC.o] Error 127
>
> ERROR: compilation failed for package 'BMEA'
>
> * removing 'C:/R/R-2.15.0/library/BMEA'
>
>
>
> It looks to me like it can't find the compiler, but I'm stumped as to how to
> make that happen. I can see the gcc.exe file in "C:\Rtools\gcc-4.6.3\bin" so
> it does seem to be there (if that's what it's trying to look for)
>
>
>
> Thanks in advance,
>
>
>
> Steve
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From stephen.pederson at adelaide.edu.au  Fri May 18 10:25:03 2012
From: stephen.pederson at adelaide.edu.au (Steve Pederson)
Date: Fri, 18 May 2012 17:55:03 +0930
Subject: [Rd] Cannot Install Custom Package On Windows7 64-bit
In-Reply-To: <4FB600DF.3010006@statistik.tu-dortmund.de>
References: <000001cd34c3$34e8ee00$9ebaca00$@pederson@adelaide.edu.au>
	<4FB600DF.3010006@statistik.tu-dortmund.de>
Message-ID: <000301cd34cf$ba1d4f10$2e57ed30$@pederson@adelaide.edu.au>

Thank you for the look with fresh eyes Uwe.

It was just the simple solution of opening a new command shell window. I
thought I'd tried that along with the multiple reboots, but it must have
been before I figured out the correct PATH settings.

And thanks for the CYGWIN reminder too. :)

All the best,

Steve

-----Original Message-----
From: Uwe Ligges [mailto:ligges at statistik.tu-dortmund.de] 
Sent: Friday, 18 May 2012 5:27 PM
To: stephen.pederson at adelaide.edu.au
Cc: r-devel at r-project.org
Subject: Re: [Rd] Cannot Install Custom Package On Windows7 64-bit



On 18.05.2012 08:55, Steve Pederson wrote:
> Hi,
>
>
>
> After uninstalling Rtools 2.14.0, I have installed the latest version 
> of Rtools 2.15.0 which gives the two folders
>
> C:\Rtools\bin
>
> C:\Rtools\gcc-4.6.3
>
>
>
> R is installed in the directory
>
> C:\R\R-2.15.0
>
>
>
> I have set the Environment Variable
>
> PATH=c:\Rtools\bin;c:\Rtools\gcc-4.6.3\bin;c:\R\R-2.15.0\bin;<others>
>
>
>
> I am trying to install a custom package (BMEA_0.2.1) which is exactly 
> as written&  built successfully on R-2.14.0
>
>
>
> When I use R CMD INSTALL BMEA_0.2.1.tar.gz, I get the following output
>
> * installing to library 'C:/R/R-2.15.0/library'
>
> * installing *source* package 'BMEA' ...
>
> ** libs
>
> cygwin warning:
>
>    MS-DOS style path detected: C:/R/R-2.15.0/etc/x64/Makeconf
>
>    Preferred POSIX equivalent is: 
> /cygdrive/c/R/R-2.15.0/etc/x64/Makeconf
>
>    CYGWIN environment variable option "nodosfilewarning" turns off 
> this warning


1. Do what it says and

set CYGWIN=nodosfilewarning

to avoid lots of warnings.



>    Consult the user's guide for more details about POSIX paths:
>
>       http://cygwin.com/cygwin-ug-net/using.html#using-pathnames
>
> gcc -m64 -I"C:/R/R-2.15.0/include" -DNDEBUG
> -I"d:/RCompile/CRANpkg/extralibs64/local/include"       -02 -Wall
> -std=gnu99 -mtune-core2 -c getLogFC.c -o getLogFC.o
>
> gcc: not found

2. So far your PATH look good, but it may be messed up later on, hence tell
us what

echo %PATH%

returns and be sure you started a new Windows command shell after changing
the PATH environment variable.

Best,
Uwe Ligges





> make: *** [getLogFC.o] Error 127
>
> ERROR: compilation failed for package 'BMEA'
>
> * removing 'C:/R/R-2.15.0/library/BMEA'
>
>
>
> It looks to me like it can't find the compiler, but I'm stumped as to 
> how to make that happen. I can see the gcc.exe file in 
> "C:\Rtools\gcc-4.6.3\bin" so it does seem to be there (if that's what 
> it's trying to look for)
>
>
>
> Thanks in advance,
>
>
>
> Steve
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Fri May 18 16:15:48 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 18 May 2012 15:15:48 +0100
Subject: [Rd] R-devel on FreeBSD: new C99 functions don't build
In-Reply-To: <4FB2B249.6030700@gwdg.de>
References: <4FB28CE8.5010303@gwdg.de>
	<CAECWziL1+tna1WwA-Qk_D6BavJyEDmrJkSa_QBEyj9+2BdoSqQ@mail.gmail.com>
	<4FB2B249.6030700@gwdg.de>
Message-ID: <4FB65994.6010308@stats.ox.ac.uk>

On 15/05/2012 20:45, Rainer Hurling wrote:
> On 15.05.2012 20:49 (UTC+1), Murray Stokely wrote:
>> On Tue, May 15, 2012 at 10:05 AM, Rainer Hurling<rhurlin at gwdg.de> wrote:
>>> About April 25th, there had been some changes within R-devel's
>>> src/nmath/pnbeta.c (and probably some other relevant places) and now
>>> building R-devel on FreeBSD 10.0-CURRENT (amd64) with gcc-4.6.4 and
>>> math/R-devel (selfmade forked port from math/R) fails like this:
>>
>>> It seems, that at least one new C99 function (log1pl) is introduced in
>>> R-devel, see
>>>
>>> src/nmath/pnbeta.c:l95
>>> return (double) (log_p ? log1pl(-ans) : (1 - ans));
>>
>> AFAIK, Bruce Evans is not happy with the numerical accuracy of other
>> open-source implementations of log1pl and so has blocked their
>> inclusion in FreeBSD pending work on a better implementation.
>>
>> Can you put a conditional FreeBSD check here and use log1p instead of
>> log1pl instead as a workaround?
>>
>> I can admire the insistence on correctness from the FreeBSD libm
>> maintainers for their technical purity, but it can be a bit of a pain
>> for things like this.
>>
>> - Murray
>
> I read about this discussion and in principle I concur with your
> opinion. As a scientist I tend to expect greatest possible correctness
> from a statistical routine, especially when it uses long double format.
>
> As a quick and dirty workaround I applied the following patch:
>
>
> --- src/nmath/pnbeta.c.orig 2012-04-25 17:55:14.000000000 +0200
> +++ src/nmath/pnbeta.c 2012-05-15 20:58:26.000000000 +0200
> @@ -92,7 +92,11 @@
> else {
> if(ans > 1 - 1e-10) ML_ERROR(ME_PRECISION, "pnbeta");
> if (ans > 1.0) ans = 1.0; /* Precaution */
> +#if !defined(__FreeBSD__)
> return (double) (log_p ? log1pl(-ans) : (1 - ans));
> +#else
> + return (double) (log_p ? log1p(-ans) : (1 - ans));
> +#endif /* FreeBSD */
> }
> }
>
>
> It builds and installs fine now and I hope there are no side effects ...

Note though that R has *required* C99 compliance for quite a while, and 
that is not now even the current C standard.  Using an OS that fails to 
comply to a 12-year-old standard is your own choice ... and you get the 
choice of using an equally old version of R.

I've added log1pl to the depressing list of FreeBSD workarounds: 
untested as I currently don't have access to a FreeBSD setup.

However, I think this has to come to an end: if a project such as 
Mingw-w64 can make the effort to supply a great deal of the C99 
functions missing from their OS then we must expect FreeBSD to do likewise.

> Thank you for the quick answer and your advice,
> Rainer


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From drf28 at cornell.edu  Fri May 18 17:11:20 2012
From: drf28 at cornell.edu (Daniel Fuka)
Date: Fri, 18 May 2012 11:11:20 -0400
Subject: [Rd] Distributing Executables.
Message-ID: <CAB9w6XzTeMZdVmEis57YNzMnmqV2-Re-h5F+cRsuCJ5esBuvLw@mail.gmail.com>

Sorry for this intrusion, but I am confused by two statements that
appear to conflict at some level in Writing R Extensions, and wanted
to make sure I understand the answer to:
Can we distribute a portable executable compiled from source by CRAN in CRAN?

The following section of Writing R Extensions appears to not be
addressing this issue, as in this case we are discussing portable CRAN
compiled binaries, and not binaries that are submitted to CRAN:
"A source package if possible should not contain binary executable
files: they are not portable, and a security risk if they are of the
appropriate architecture. R CMD check will warn about them unless they
are listed (one filepath per line) in a file BinaryFiles at the top
level of the package. Note that CRAN will no longer accept submissions
containing binary files even if they are listed."

The following section seems to indicate special cases in which
packages can create binary files:
"In very special cases packages may create binary files other than the
shared objects/DLLs in the src directory. Such files will not be
installed in multi-arch setting since R CMD INSTALL --libs-only is
used to merge multiple architectures and it only copies shared
objects/DLLs. If a package wants to install other binaries (for
example executable programs), it should to provide an R script
src/install.libs.R which will be run as part of the installation in
the src build directory instead of copying the shared objects/DLLs."

Once again, sorry for my confusion on this point. I just have what I
might consider a special case where it would be very handy to
distribute a cran compiled executable.

Thanks!
Daniel Fuka


From simon.urbanek at r-project.org  Fri May 18 17:24:41 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 18 May 2012 11:24:41 -0400
Subject: [Rd] Distributing Executables.
In-Reply-To: <CAB9w6XzTeMZdVmEis57YNzMnmqV2-Re-h5F+cRsuCJ5esBuvLw@mail.gmail.com>
References: <CAB9w6XzTeMZdVmEis57YNzMnmqV2-Re-h5F+cRsuCJ5esBuvLw@mail.gmail.com>
Message-ID: <D492442B-CC91-4C99-8212-E63637829FAF@r-project.org>


On May 18, 2012, at 11:11 AM, Daniel Fuka wrote:

> Sorry for this intrusion, but I am confused by two statements that
> appear to conflict at some level in Writing R Extensions, and wanted
> to make sure I understand the answer to:
> Can we distribute a portable executable compiled from source by CRAN in CRAN?
> 
> The following section of Writing R Extensions appears to not be
> addressing this issue, as in this case we are discussing portable CRAN
> compiled binaries, and not binaries that are submitted to CRAN:
> "A source package if possible should not contain binary executable
> files: they are not portable, and a security risk if they are of the
> appropriate architecture. R CMD check will warn about them unless they
> are listed (one filepath per line) in a file BinaryFiles at the top
> level of the package. Note that CRAN will no longer accept submissions
> containing binary files even if they are listed."
> 
> The following section seems to indicate special cases in which
> packages can create binary files:
> "In very special cases packages may create binary files other than the
> shared objects/DLLs in the src directory. Such files will not be
> installed in multi-arch setting since R CMD INSTALL --libs-only is
> used to merge multiple architectures and it only copies shared
> objects/DLLs. If a package wants to install other binaries (for
> example executable programs), it should to provide an R script
> src/install.libs.R which will be run as part of the installation in
> the src build directory instead of copying the shared objects/DLLs."
> 
> Once again, sorry for my confusion on this point. I just have what I
> might consider a special case where it would be very handy to
> distribute a cran compiled executable.

I don't quite follow - CARN obviously distributes binaries compiled by CRAN and those are called binary packages. Can you be more specific as of what you are asking about?  The two paragraphs you are quoting are about entirely different things - the first states that you can't include binaries in *source* packages and the second describes how you can build executables beside dynamic objects in packages so that CRAN can include them in *binary* packages. It doesn't cover distribution.

What you refer to are rules for *source* packages which can't distribute binaries, but you can always use a binary package (which contains binaries). Note that the issue in question is not who built the binary but whether it could have been injected by 3rd party or not (hence all binaries are disallowed in source packages since there is no way to tell).

Cheers,
Simon


From ripley at stats.ox.ac.uk  Fri May 18 17:28:05 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 18 May 2012 16:28:05 +0100
Subject: [Rd] Distributing Executables.
In-Reply-To: <CAB9w6XzTeMZdVmEis57YNzMnmqV2-Re-h5F+cRsuCJ5esBuvLw@mail.gmail.com>
References: <CAB9w6XzTeMZdVmEis57YNzMnmqV2-Re-h5F+cRsuCJ5esBuvLw@mail.gmail.com>
Message-ID: <4FB66A85.5000401@stats.ox.ac.uk>

On 18/05/2012 16:11, Daniel Fuka wrote:
> Sorry for this intrusion, but I am confused by two statements that
> appear to conflict at some level in Writing R Extensions,

You may be confused, but the documentation does not conflict.

 > and wanted
> to make sure I understand the answer to:
> Can we distribute a portable executable compiled from source by CRAN in CRAN?

Yes.  Take a look at e.g. package Rserve (and there are others which do 
this via src/Makefile.win).

> The following section of Writing R Extensions appears to not be
> addressing this issue, as in this case we are discussing portable CRAN
> compiled binaries, and not binaries that are submitted to CRAN:

Note that by definition a binary is not portable: it is tied to one OS 
and perhaps one architecture on that OS.  The following is about source 
packages.

> "A source package if possible should not contain binary executable
> files: they are not portable, and a security risk if they are of the
> appropriate architecture. R CMD check will warn about them unless they
> are listed (one filepath per line) in a file BinaryFiles at the top
> level of the package. Note that CRAN will no longer accept submissions
> containing binary files even if they are listed."
>
> The following section seems to indicate special cases in which
> packages can create binary files:
> "In very special cases packages may create binary files other than the
> shared objects/DLLs in the src directory. Such files will not be
> installed in multi-arch setting since R CMD INSTALL --libs-only is
> used to merge multiple architectures and it only copies shared
> objects/DLLs. If a package wants to install other binaries (for
> example executable programs), it should to provide an R script
> src/install.libs.R which will be run as part of the installation in
> the src build directory instead of copying the shared objects/DLLs."
>
> Once again, sorry for my confusion on this point. I just have what I
> might consider a special case where it would be very handy to
> distribute a cran compiled executable.

You need to discuss that with CRAN, not here.

>
> Thanks!
> Daniel Fuka
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From MEC at stowers.org  Fri May 18 17:28:41 2012
From: MEC at stowers.org (Cook, Malcolm)
Date: Fri, 18 May 2012 10:28:41 -0500
Subject: [Rd] test suites for packages
In-Reply-To: <CAMi=pg6MRN9BxGQz4C=t6x=s1nGKGp_nLRyRwe6zSmKfs1_whA@mail.gmail.com>
Message-ID: <CBDBD265.22343%mec@stowers.org>

svUnit - is Runit compatible and provides some  IDE integration and report
generation and easy syntax for defining tests.

I find it works a treat, and fits very nicely with my R coding/packaging
style (which also uses inlinedocs for easy package creation).

--Malcolm Cook


On 5/17/12 9:10 AM, "Whit Armstrong" <armstrong.whit at gmail.com> wrote:

>Can anyone share some opinions on test suites for R packages?
>
>I'm looking at testthat and RUnit. Does anyone have strong opinions on
>either of those.
>
>Any additional packages I should consider?
>
>Thanks,
>Whit
>
>______________________________________________
>R-devel at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel


From drf28 at cornell.edu  Fri May 18 17:32:22 2012
From: drf28 at cornell.edu (Daniel Fuka)
Date: Fri, 18 May 2012 11:32:22 -0400
Subject: [Rd] Distributing Executables.
In-Reply-To: <D492442B-CC91-4C99-8212-E63637829FAF@r-project.org>
References: <CAB9w6XzTeMZdVmEis57YNzMnmqV2-Re-h5F+cRsuCJ5esBuvLw@mail.gmail.com>
	<D492442B-CC91-4C99-8212-E63637829FAF@r-project.org>
Message-ID: <CAB9w6XyZ1B4Bp68+MdL73iV1MK+AJV3XQXTWDH-mkBp5MzcfNQ@mail.gmail.com>

Thanks Simon,

In this case, I am talking specifically about allowing CRAN to compile
source into an executable to be distributed, as discussed in the
second paragraphs "very special cases .. for example executable
programs". So, when someone runs install.packages("mypackage"), they
get a package that contains an executable that can be run from outside
of R.

Can I submit a package to CRAN that will compile source into an executable?

I hope this clears the mud on my first post.

Thanks!
dan

On Fri, May 18, 2012 at 11:24 AM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
>
> On May 18, 2012, at 11:11 AM, Daniel Fuka wrote:
>
>> Sorry for this intrusion, but I am confused by two statements that
>> appear to conflict at some level in Writing R Extensions, and wanted
>> to make sure I understand the answer to:
>> Can we distribute a portable executable compiled from source by CRAN in CRAN?
>>
>> The following section of Writing R Extensions appears to not be
>> addressing this issue, as in this case we are discussing portable CRAN
>> compiled binaries, and not binaries that are submitted to CRAN:
>> "A source package if possible should not contain binary executable
>> files: they are not portable, and a security risk if they are of the
>> appropriate architecture. R CMD check will warn about them unless they
>> are listed (one filepath per line) in a file BinaryFiles at the top
>> level of the package. Note that CRAN will no longer accept submissions
>> containing binary files even if they are listed."
>>
>> The following section seems to indicate special cases in which
>> packages can create binary files:
>> "In very special cases packages may create binary files other than the
>> shared objects/DLLs in the src directory. Such files will not be
>> installed in multi-arch setting since R CMD INSTALL --libs-only is
>> used to merge multiple architectures and it only copies shared
>> objects/DLLs. If a package wants to install other binaries (for
>> example executable programs), it should to provide an R script
>> src/install.libs.R which will be run as part of the installation in
>> the src build directory instead of copying the shared objects/DLLs."
>>
>> Once again, sorry for my confusion on this point. I just have what I
>> might consider a special case where it would be very handy to
>> distribute a cran compiled executable.
>
> I don't quite follow - CARN obviously distributes binaries compiled by CRAN and those are called binary packages. Can you be more specific as of what you are asking about? ?The two paragraphs you are quoting are about entirely different things - the first states that you can't include binaries in *source* packages and the second describes how you can build executables beside dynamic objects in packages so that CRAN can include them in *binary* packages. It doesn't cover distribution.
>
> What you refer to are rules for *source* packages which can't distribute binaries, but you can always use a binary package (which contains binaries). Note that the issue in question is not who built the binary but whether it could have been injected by 3rd party or not (hence all binaries are disallowed in source packages since there is no way to tell).
>
> Cheers,
> Simon
>
>


From simon.urbanek at r-project.org  Fri May 18 17:39:35 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 18 May 2012 11:39:35 -0400
Subject: [Rd] Distributing Executables.
In-Reply-To: <CAB9w6XyZ1B4Bp68+MdL73iV1MK+AJV3XQXTWDH-mkBp5MzcfNQ@mail.gmail.com>
References: <CAB9w6XzTeMZdVmEis57YNzMnmqV2-Re-h5F+cRsuCJ5esBuvLw@mail.gmail.com>
	<D492442B-CC91-4C99-8212-E63637829FAF@r-project.org>
	<CAB9w6XyZ1B4Bp68+MdL73iV1MK+AJV3XQXTWDH-mkBp5MzcfNQ@mail.gmail.com>
Message-ID: <35F2C70C-8C92-4986-841F-AB9806ADDDFF@r-project.org>

On May 18, 2012, at 11:32 AM, Daniel Fuka wrote:

> Thanks Simon,
> 
> In this case, I am talking specifically about allowing CRAN to compile
> source into an executable to be distributed, as discussed in the
> second paragraphs "very special cases .. for example executable
> programs". So, when someone runs install.packages("mypackage"), they
> get a package that contains an executable that can be run from outside
> of R.
> 
> Can I submit a package to CRAN that will compile source into an executable?
> 

Yes - that is what the second paragraph describes (and as Brian pointed out there are examples on CRAN like Rserve).

Cheers,
Simon


> I hope this clears the mud on my first post.
> 
> Thanks!
> dan
> 
> On Fri, May 18, 2012 at 11:24 AM, Simon Urbanek
> <simon.urbanek at r-project.org> wrote:
>> 
>> On May 18, 2012, at 11:11 AM, Daniel Fuka wrote:
>> 
>>> Sorry for this intrusion, but I am confused by two statements that
>>> appear to conflict at some level in Writing R Extensions, and wanted
>>> to make sure I understand the answer to:
>>> Can we distribute a portable executable compiled from source by CRAN in CRAN?
>>> 
>>> The following section of Writing R Extensions appears to not be
>>> addressing this issue, as in this case we are discussing portable CRAN
>>> compiled binaries, and not binaries that are submitted to CRAN:
>>> "A source package if possible should not contain binary executable
>>> files: they are not portable, and a security risk if they are of the
>>> appropriate architecture. R CMD check will warn about them unless they
>>> are listed (one filepath per line) in a file BinaryFiles at the top
>>> level of the package. Note that CRAN will no longer accept submissions
>>> containing binary files even if they are listed."
>>> 
>>> The following section seems to indicate special cases in which
>>> packages can create binary files:
>>> "In very special cases packages may create binary files other than the
>>> shared objects/DLLs in the src directory. Such files will not be
>>> installed in multi-arch setting since R CMD INSTALL --libs-only is
>>> used to merge multiple architectures and it only copies shared
>>> objects/DLLs. If a package wants to install other binaries (for
>>> example executable programs), it should to provide an R script
>>> src/install.libs.R which will be run as part of the installation in
>>> the src build directory instead of copying the shared objects/DLLs."
>>> 
>>> Once again, sorry for my confusion on this point. I just have what I
>>> might consider a special case where it would be very handy to
>>> distribute a cran compiled executable.
>> 
>> I don't quite follow - CARN obviously distributes binaries compiled by CRAN and those are called binary packages. Can you be more specific as of what you are asking about?  The two paragraphs you are quoting are about entirely different things - the first states that you can't include binaries in *source* packages and the second describes how you can build executables beside dynamic objects in packages so that CRAN can include them in *binary* packages. It doesn't cover distribution.
>> 
>> What you refer to are rules for *source* packages which can't distribute binaries, but you can always use a binary package (which contains binaries). Note that the issue in question is not who built the binary but whether it could have been injected by 3rd party or not (hence all binaries are disallowed in source packages since there is no way to tell).
>> 
>> Cheers,
>> Simon
>> 
>> 
> 
> 


From ronggui.huang at gmail.com  Sat May 19 07:22:41 2012
From: ronggui.huang at gmail.com (Wincent)
Date: Sat, 19 May 2012 13:22:41 +0800
Subject: [Rd] bug in R version 2.15.0 (2012-03-30)?
Message-ID: <CANQBBMtODn-_EENH5v-aHOcBSBLUNGQpWJVjj+cXNJj1ne-Q5g@mail.gmail.com>

The returned text by license() says,

This can be displayed by RShowDoc("COPYING.LIB"),
or obtained at the URI given.

However,
> RShowDoc("COPYING.LIB")
Error in RShowDoc("COPYING.LIB") : document not found

Also, is URI a typo of URL?

-- 
Wincent Ronggui HUANG
Sociology Department of Fudan University
PhD of City University of Hong Kong
http://homepage.fudan.edu.cn/rghuang/cv/


From ligges at statistik.tu-dortmund.de  Sat May 19 15:32:00 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 19 May 2012 15:32:00 +0200
Subject: [Rd] bug in R version 2.15.0 (2012-03-30)?
In-Reply-To: <CANQBBMtODn-_EENH5v-aHOcBSBLUNGQpWJVjj+cXNJj1ne-Q5g@mail.gmail.com>
References: <CANQBBMtODn-_EENH5v-aHOcBSBLUNGQpWJVjj+cXNJj1ne-Q5g@mail.gmail.com>
Message-ID: <4FB7A0D0.9020209@statistik.tu-dortmund.de>



On 19.05.2012 07:22, Wincent wrote:
> The returned text by license() says,
>
> This can be displayed by RShowDoc("COPYING.LIB"),
> or obtained at the URI given.
>
> However,
>> RShowDoc("COPYING.LIB")
> Error in RShowDoc("COPYING.LIB") : document not found
>
> Also, is URI a typo of URL?
>


Thanks.
It was forgotten to update this part of the text, will do shortly.

Uwe Ligges


From rhurlin at gwdg.de  Mon May 21 08:26:23 2012
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Mon, 21 May 2012 08:26:23 +0200
Subject: [Rd] R-devel on FreeBSD: new C99 functions don't build
In-Reply-To: <4FB65994.6010308@stats.ox.ac.uk>
References: <4FB28CE8.5010303@gwdg.de>
	<CAECWziL1+tna1WwA-Qk_D6BavJyEDmrJkSa_QBEyj9+2BdoSqQ@mail.gmail.com>
	<4FB2B249.6030700@gwdg.de> <4FB65994.6010308@stats.ox.ac.uk>
Message-ID: <4FB9E00F.1010402@gwdg.de>

On 18.05.2012 16:15 (UTC+1), Prof Brian Ripley wrote:
> On 15/05/2012 20:45, Rainer Hurling wrote:
>> On 15.05.2012 20:49 (UTC+1), Murray Stokely wrote:
>>> On Tue, May 15, 2012 at 10:05 AM, Rainer Hurling<rhurlin at gwdg.de> wrote:
>>>> About April 25th, there had been some changes within R-devel's
>>>> src/nmath/pnbeta.c (and probably some other relevant places) and now
>>>> building R-devel on FreeBSD 10.0-CURRENT (amd64) with gcc-4.6.4 and
>>>> math/R-devel (selfmade forked port from math/R) fails like this:
>>>
>>>> It seems, that at least one new C99 function (log1pl) is introduced in
>>>> R-devel, see
>>>>
>>>> src/nmath/pnbeta.c:l95
>>>> return (double) (log_p ? log1pl(-ans) : (1 - ans));
>>>
>>> AFAIK, Bruce Evans is not happy with the numerical accuracy of other
>>> open-source implementations of log1pl and so has blocked their
>>> inclusion in FreeBSD pending work on a better implementation.
>>>
>>> Can you put a conditional FreeBSD check here and use log1p instead of
>>> log1pl instead as a workaround?
>>>
>>> I can admire the insistence on correctness from the FreeBSD libm
>>> maintainers for their technical purity, but it can be a bit of a pain
>>> for things like this.
>>>
>>> - Murray
>>
>> I read about this discussion and in principle I concur with your
>> opinion. As a scientist I tend to expect greatest possible correctness
>> from a statistical routine, especially when it uses long double format.
>>
>> As a quick and dirty workaround I applied the following patch:
>>
>>
>> --- src/nmath/pnbeta.c.orig 2012-04-25 17:55:14.000000000 +0200
>> +++ src/nmath/pnbeta.c 2012-05-15 20:58:26.000000000 +0200
>> @@ -92,7 +92,11 @@
>> else {
>> if(ans > 1 - 1e-10) ML_ERROR(ME_PRECISION, "pnbeta");
>> if (ans > 1.0) ans = 1.0; /* Precaution */
>> +#if !defined(__FreeBSD__)
>> return (double) (log_p ? log1pl(-ans) : (1 - ans));
>> +#else
>> + return (double) (log_p ? log1p(-ans) : (1 - ans));
>> +#endif /* FreeBSD */
>> }
>> }
>>
>>
>> It builds and installs fine now and I hope there are no side effects ...
>
> Note though that R has *required* C99 compliance for quite a while, and
> that is not now even the current C standard. Using an OS that fails to
> comply to a 12-year-old standard is your own choice ... and you get the
> choice of using an equally old version of R.

Of course you are right with C99 compliance on FreeBSD. It is a long 
outstanding issue to get these long double functions in.

For me personally there are *many* reasons to use FreeBSD and at the 
moment R is one of only very few software packages we have serious 
trouble with C99 functions.

As you know, using an old version of R is not a real options. Because of 
that, we are looking at R-devel to find problems with FreeBSD in good time.

> I've added log1pl to the depressing list of FreeBSD workarounds:
> untested as I currently don't have access to a FreeBSD setup.

Many thanks for the patch. I built it and it is much more elegant than 
my workaround (HAVE_LOG1PL, log1p with double). And yes, the list is 
depressing.

> However, I think this has to come to an end: if a project such as
> Mingw-w64 can make the effort to supply a great deal of the C99
> functions missing from their OS then we must expect FreeBSD to do likewise.

As I said before, I agree with this point of view. But I am not a 
developer and a am not standing for the FreeBSD project. I am only an 
interested user and a maintainer for a few small FreeBSD ports 
(adaptions of third party software).

I will ask the FreeBSD people again for better C99 compliance ...

I really appreciate your help on this annoying issues and hope we will 
find a solution on FreeBSD in the near future.

Regards,
Rainer Hurling


From j.maspons at creaf.uab.cat  Tue May 22 12:14:58 2012
From: j.maspons at creaf.uab.cat (Joan Maspons)
Date: Tue, 22 May 2012 12:14:58 +0200
Subject: [Rd] Patch to add Beta binomial distribution. Mentor needed!
Message-ID: <CANF72pNnfRHOBr_4mvwsk1o1J52hz6LPLEQP6sMjkWOCYX5cOA@mail.gmail.com>

Hello,

I implemented the Beta binomial distribution following the patterns of the
binomial distribution code and inspired by JAGS' code [1]. I have studied
the code carefully but it's my first run in the R internals.

Can somebody review the code and if everything it's ok commit to the
repository?

[1]
http://mcmc-jags.hg.sourceforge.net/hgweb/mcmc-jags/mcmc-jags/file/15af65a4be29/src/modules/bugs/distributions/DBetaBin.cc


-- 
Joan Maspons
CREAF (Centre de Recerca Ecol?gica i Aplicacions Forestals)
Universitat Aut?noma de Barcelona, 08193 Bellaterra (Barcelona), Catalonia
Tel +34 93 581 2915            j.maspons at creaf.uab.cat
http://www.creaf.uab.cat

From dutangc at gmail.com  Tue May 22 13:59:15 2012
From: dutangc at gmail.com (Christophe Dutang)
Date: Tue, 22 May 2012 13:59:15 +0200
Subject: [Rd] Patch to add Beta binomial distribution. Mentor needed!
In-Reply-To: <CANF72pNnfRHOBr_4mvwsk1o1J52hz6LPLEQP6sMjkWOCYX5cOA@mail.gmail.com>
References: <CANF72pNnfRHOBr_4mvwsk1o1J52hz6LPLEQP6sMjkWOCYX5cOA@mail.gmail.com>
Message-ID: <A1056BE4-973C-4883-864C-AC1DC800CF7F@gmail.com>

Dear Joan,

Are you aware of this page http://cran.r-project.org/web/views/Distributions.html ?

If you want to contribute to R, you should write a package and submit it to CRAN. See http://cran.r-project.org/doc/manuals/R-exts.html

Regards

Christophe

--
Christophe Dutang
Ph.D. student at ISFA, Lyon, France
website: http://dutangc.free.fr

Le 22 mai 2012 ? 12:14, Joan Maspons a ?crit :

> Hello,
> 
> I implemented the Beta binomial distribution following the patterns of the
> binomial distribution code and inspired by JAGS' code [1]. I have studied
> the code carefully but it's my first run in the R internals.
> 
> Can somebody review the code and if everything it's ok commit to the
> repository?
> 
> [1]
> http://mcmc-jags.hg.sourceforge.net/hgweb/mcmc-jags/mcmc-jags/file/15af65a4be29/src/modules/bugs/distributions/DBetaBin.cc
> 
> 
> -- 
> Joan Maspons
> CREAF (Centre de Recerca Ecol?gica i Aplicacions Forestals)
> Universitat Aut?noma de Barcelona, 08193 Bellaterra (Barcelona), Catalonia
> Tel +34 93 581 2915            j.maspons at creaf.uab.cat
> http://www.creaf.uab.cat
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From j.maspons at creaf.uab.cat  Tue May 22 15:27:42 2012
From: j.maspons at creaf.uab.cat (Joan Maspons)
Date: Tue, 22 May 2012 15:27:42 +0200
Subject: [Rd] Patch to add Beta binomial distribution. Mentor needed!
In-Reply-To: <A1056BE4-973C-4883-864C-AC1DC800CF7F@gmail.com>
References: <CANF72pNnfRHOBr_4mvwsk1o1J52hz6LPLEQP6sMjkWOCYX5cOA@mail.gmail.com>
	<A1056BE4-973C-4883-864C-AC1DC800CF7F@gmail.com>
Message-ID: <CANF72pMfLuFdmanqWJpjy5gORo7yDTO8qDgXSc4sXjeYcFrpXw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120522/e925cac0/attachment.pl>

From josh.m.ulrich at gmail.com  Tue May 22 16:59:25 2012
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Tue, 22 May 2012 09:59:25 -0500
Subject: [Rd] Patch to add Beta binomial distribution. Mentor needed!
In-Reply-To: <CANF72pMfLuFdmanqWJpjy5gORo7yDTO8qDgXSc4sXjeYcFrpXw@mail.gmail.com>
References: <CANF72pNnfRHOBr_4mvwsk1o1J52hz6LPLEQP6sMjkWOCYX5cOA@mail.gmail.com>
	<A1056BE4-973C-4883-864C-AC1DC800CF7F@gmail.com>
	<CANF72pMfLuFdmanqWJpjy5gORo7yDTO8qDgXSc4sXjeYcFrpXw@mail.gmail.com>
Message-ID: <CAPPM_gQPMR8Je8JcGeKjTxHKNKnt0=RNgYaP+9k-MEi2aLsbOw@mail.gmail.com>

On Tue, May 22, 2012 at 8:27 AM, Joan Maspons <j.maspons at creaf.uab.cat> wrote:
> Hello,
>
> 2012/5/22 Christophe Dutang <dutangc at gmail.com>
>
>> Dear Joan,
>>
<snip>
>> If you want to contribute to R, you should write a package and submit it
>> to CRAN. See http://cran.r-project.org/doc/manuals/R-exts.html
>>
>
> It's necessary to develop a package before to add the functions to R-base?
> I just want to add beta binomial and beta negative binomial distributions
> which from my point of view are not more strange than distributions
> included in R-base. I think they are quite common in order to simulate a
> binomial or negative binomial process in an stochastic environment.
>
In order to add functions to the main R distribution, you have to
convince someone on R-core to maintain the code.

> In the other hand I have no experience in writing packages so it would take
> me more time.
>
The actuar package contains many additional distributions.  You might
see if the maintainer(s) would be interested in incorporating your
code (if they don't have that functionality already).

> Yours,
> Joan
>
> Regards
>>
>> Christophe
>>
>> --
>> Christophe Dutang
>> Ph.D. student at ISFA, Lyon, France
>> website: http://dutangc.free.fr
>>
>> Le 22 mai 2012 ? 12:14, Joan Maspons a ?crit :
>>
>> > Hello,
>> >
>> > I implemented the Beta binomial distribution following the patterns of
>> the
>> > binomial distribution code and inspired by JAGS' code [1]. I have studied
>> > the code carefully but it's my first run in the R internals.
>> >
>> > Can somebody review the code and if everything it's ok commit to the
>> > repository?
>> >
>> > [1]
>> >
>> http://mcmc-jags.hg.sourceforge.net/hgweb/mcmc-jags/mcmc-jags/file/15af65a4be29/src/modules/bugs/distributions/DBetaBin.cc
>> >
>> >
>> > --
>> > Joan Maspons
>> > CREAF (Centre de Recerca Ecol?gica i Aplicacions Forestals)
>> > Universitat Aut?noma de Barcelona, 08193 Bellaterra (Barcelona),
>> Catalonia
>> > Tel +34 93 581 2915 ? ? ? ? ? ?j.maspons at creaf.uab.cat
>> > http://www.creaf.uab.cat
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
>
> --
> Joan Maspons
> CREAF (Centre de Recerca Ecol?gica i Aplicacions Forestals)
> Universitat Aut?noma de Barcelona, 08193 Bellaterra (Barcelona), Catalonia
> Tel +34 93 581 2915 ? ? ? ? ? ?j.maspons at creaf.uab.cat
> http://www.creaf.uab.cat
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From tim.triche at gmail.com  Tue May 22 17:39:28 2012
From: tim.triche at gmail.com (Tim Triche, Jr.)
Date: Tue, 22 May 2012 08:39:28 -0700
Subject: [Rd] Patch to add Beta binomial distribution. Mentor needed!
In-Reply-To: <CAPPM_gQPMR8Je8JcGeKjTxHKNKnt0=RNgYaP+9k-MEi2aLsbOw@mail.gmail.com>
References: <CANF72pNnfRHOBr_4mvwsk1o1J52hz6LPLEQP6sMjkWOCYX5cOA@mail.gmail.com>
	<A1056BE4-973C-4883-864C-AC1DC800CF7F@gmail.com>
	<CANF72pMfLuFdmanqWJpjy5gORo7yDTO8qDgXSc4sXjeYcFrpXw@mail.gmail.com>
	<CAPPM_gQPMR8Je8JcGeKjTxHKNKnt0=RNgYaP+9k-MEi2aLsbOw@mail.gmail.com>
Message-ID: <CAC+N9BWVtdfV4c4Pm0Ev-6e0Zq3CneQ2XptMid0wgBcLRy9eUQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120522/7ddebb7d/attachment.pl>

From richierocks at gmail.com  Tue May 22 18:26:52 2012
From: richierocks at gmail.com (Richard Cotton)
Date: Tue, 22 May 2012 17:26:52 +0100
Subject: [Rd] Codoc mismatch for roxygen-documented foo<- functions
Message-ID: <CAPp_+=f0-bgiXOENpqjhr_ZXs+yPyu9OO410Qx-qF5LBoiNt+g@mail.gmail.com>

I have a roxygen2 documented package with functions for getting and
setting an attribute.

#' Get or set the foo attribute.
#'
#' Dummy function!
#'
#' @param x Object to hold the attribute.
#' @param value Value to set the attribute to.
#' @return The get function returns the "foo" attribute of \code{x}.
#' @export
foo <- function(x)
{
? attr(x, "foo")
}

#' @rdname foo
#' @export
`foo<-` <- function(x, value)
{
? attr(x, "foo") <- value
}

If I save the above to foo.R and then do

library(roxygen2)
library(devtools)
package.skeleton("foo", code_files="foo.R")
roxygenize("foo")
check("foo")

then the package checker gives me the warning

Codoc mismatches from documentation object 'foo':
foo<-
  Code: function(x, value)
  Docs: function(x, value, value)

How should I be documenting this sort of setter function?

--
Regards,
Richie

live-analytics.com
4dpiecharts.com


From bbolker at gmail.com  Tue May 22 19:30:09 2012
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 22 May 2012 17:30:09 +0000
Subject: [Rd] Patch to add Beta binomial distribution. Mentor needed!
References: <CANF72pNnfRHOBr_4mvwsk1o1J52hz6LPLEQP6sMjkWOCYX5cOA@mail.gmail.com>
	<A1056BE4-973C-4883-864C-AC1DC800CF7F@gmail.com>
	<CANF72pMfLuFdmanqWJpjy5gORo7yDTO8qDgXSc4sXjeYcFrpXw@mail.gmail.com>
	<CAPPM_gQPMR8Je8JcGeKjTxHKNKnt0=RNgYaP+9k-MEi2aLsbOw@mail.gmail.com>
	<CAC+N9BWVtdfV4c4Pm0Ev-6e0Zq3CneQ2XptMid0wgBcLRy9eUQ@mail.gmail.com>
Message-ID: <loom.20120522T190546-850@post.gmane.org>

Tim Triche, Jr. <tim.triche <at> gmail.com> writes:

 
> it's already in the VGAM package
> 
> http://www.stat.auckland.ac.nz/~yee/VGAM/
> 

[various snippage]

also see 

library("sos")
findFn("dbetabin*")

and 

http://stackoverflow.com/questions/8065835/
   proposing-feature-requests-to-the-r-core-team/8066062#8066062
[url broken]

  for some context on why you should build a package instead
of trying to get a patch accepted in base R ...

  Ben Bolker

 
> > On Tue, May 22, 2012 at 8:27 AM, Joan Maspons 
> > wrote:
> > > Hello,
> > >
> > > 2012/5/22 Christophe Dutang <dutangc <at> gmail.com>
> > >
> > >> Dear Joan,
> > >>
> > <snip>
> > >> If you want to contribute to R, you should write a package and submit it
> > >> to CRAN. See http://cran.r-project.org/doc/manuals/R-exts.html
> > >>
> > >
> > > It's necessary to develop a package before to add the functions to
> > R-base?
> > > I just want to add beta binomial and beta negative binomial distributions
> > > which from my point of view are not more strange than distributions
> > > included in R-base. I think they are quite common in order to simulate a
> > > binomial or negative binomial process in an stochastic environment.
> > >
> > In order to add functions to the main R distribution, you have to
> > convince someone on R-core to maintain the code.


From hb at biostat.ucsf.edu  Tue May 22 19:34:45 2012
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Tue, 22 May 2012 10:34:45 -0700
Subject: [Rd] Best way to locate R executable from within R?
Message-ID: <CAFDcVCSbqCrF2hepKGC1n4BpdekBQcBg2B6+hSQFOZP9cgxq-g@mail.gmail.com>

Hi,

I'd like to spawn of a new R process from within R using system(),
e.g. system("R -f myScript.R").  However, just specifying "R" as in
that example is not guaranteed to work, because "R" may not be on the
OS's search path.

 What is the best way, from within a running R, to infer the command
(basename or full path) for launching R in way that it works on any
OS?  I came up with the following alternatives, but I'm not sure if
they'll work everywhere or not:

1. Rbin <- commandArgs()[1];

2. Rbin <- file.path(R.home(), "bin", "R");

Other suggestions that are better?

/Henrik


From dtenenba at fhcrc.org  Tue May 22 19:47:47 2012
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Tue, 22 May 2012 10:47:47 -0700
Subject: [Rd] Best way to locate R executable from within R?
In-Reply-To: <CAFDcVCSbqCrF2hepKGC1n4BpdekBQcBg2B6+hSQFOZP9cgxq-g@mail.gmail.com>
References: <CAFDcVCSbqCrF2hepKGC1n4BpdekBQcBg2B6+hSQFOZP9cgxq-g@mail.gmail.com>
Message-ID: <CAF42j23wDpZ4TMPXk1eankBS7tcxETHaP-Bd4dvX9pvKR+sreA@mail.gmail.com>

On Tue, May 22, 2012 at 10:34 AM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> Hi,
>
> I'd like to spawn of a new R process from within R using system(),
> e.g. system("R -f myScript.R"). ?However, just specifying "R" as in
> that example is not guaranteed to work, because "R" may not be on the
> OS's search path.
>
> ?What is the best way, from within a running R, to infer the command
> (basename or full path) for launching R in way that it works on any
> OS? ?I came up with the following alternatives, but I'm not sure if
> they'll work everywhere or not:
>
> 1. Rbin <- commandArgs()[1];
>
> 2. Rbin <- file.path(R.home(), "bin", "R");
>
> Other suggestions that are better?

Rbin <- file.path(Sys.getenv("R_HOME"), "bin", "R")

Dan


>
> /Henrik
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hb at biostat.ucsf.edu  Tue May 22 20:03:28 2012
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Tue, 22 May 2012 11:03:28 -0700
Subject: [Rd] Best way to locate R executable from within R?
In-Reply-To: <CAF42j23wDpZ4TMPXk1eankBS7tcxETHaP-Bd4dvX9pvKR+sreA@mail.gmail.com>
References: <CAFDcVCSbqCrF2hepKGC1n4BpdekBQcBg2B6+hSQFOZP9cgxq-g@mail.gmail.com>
	<CAF42j23wDpZ4TMPXk1eankBS7tcxETHaP-Bd4dvX9pvKR+sreA@mail.gmail.com>
Message-ID: <CAFDcVCTpjzGEkUknOp0KHQO6dV4EC27gK_o=f6Xq+ZXup8r-=w@mail.gmail.com>

On Tue, May 22, 2012 at 10:47 AM, Dan Tenenbaum <dtenenba at fhcrc.org> wrote:
> On Tue, May 22, 2012 at 10:34 AM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>> Hi,
>>
>> I'd like to spawn of a new R process from within R using system(),
>> e.g. system("R -f myScript.R"). ?However, just specifying "R" as in
>> that example is not guaranteed to work, because "R" may not be on the
>> OS's search path.
>>
>> ?What is the best way, from within a running R, to infer the command
>> (basename or full path) for launching R in way that it works on any
>> OS? ?I came up with the following alternatives, but I'm not sure if
>> they'll work everywhere or not:
>>
>> 1. Rbin <- commandArgs()[1];
>>
>> 2. Rbin <- file.path(R.home(), "bin", "R");
>>
>> Other suggestions that are better?
>
> Rbin <- file.path(Sys.getenv("R_HOME"), "bin", "R")

I don't see how Sys.getenv("R_HOME") would be better than R.home() -
any reasons?

Your reply triggered me to read up on help("R.home"), where I noticed
the passage:

"A character string giving the R home directory or path to a
particular component. Normally the components are all subdirectories
of the R home directory, but this may not be the case in a Unix-like
installation.  [...] The return value for "modules" and on Windows
"bin" is to a sub-architecture-specific location."

So, now I'd say that:

4. Rbin <- file.path(R.home("bin"), "R");

is better than (2).  I'm still not sure whether to use (1) or (4), though.

/Henrik

>
> Dan
>
>
>>
>> /Henrik
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From simon.urbanek at r-project.org  Tue May 22 20:07:55 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 22 May 2012 14:07:55 -0400
Subject: [Rd] Best way to locate R executable from within R?
In-Reply-To: <CAF42j23wDpZ4TMPXk1eankBS7tcxETHaP-Bd4dvX9pvKR+sreA@mail.gmail.com>
References: <CAFDcVCSbqCrF2hepKGC1n4BpdekBQcBg2B6+hSQFOZP9cgxq-g@mail.gmail.com>
	<CAF42j23wDpZ4TMPXk1eankBS7tcxETHaP-Bd4dvX9pvKR+sreA@mail.gmail.com>
Message-ID: <CFEA7CD6-4B8C-479A-872E-3F5D958CB763@r-project.org>

On May 22, 2012, at 1:47 PM, Dan Tenenbaum <dtenenba at fhcrc.org> wrote:

> On Tue, May 22, 2012 at 10:34 AM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>> Hi,
>> 
>> I'd like to spawn of a new R process from within R using system(),
>> e.g. system("R -f myScript.R").  However, just specifying "R" as in
>> that example is not guaranteed to work, because "R" may not be on the
>> OS's search path.
>> 
>>  What is the best way, from within a running R, to infer the command
>> (basename or full path) for launching R in way that it works on any
>> OS?  I came up with the following alternatives, but I'm not sure if
>> they'll work everywhere or not:
>> 
>> 1. Rbin <- commandArgs()[1];
>> 
>> 2. Rbin <- file.path(R.home(), "bin", "R");
>> 
>> Other suggestions that are better?
> 
> Rbin <- file.path(Sys.getenv("R_HOME"), "bin", "R")
> 

That is certainly worse, not better.

1. doesn't work because it may be a relative path.

2. Sounds pretty good - since the environment will be set by the current R.


> Dan
> 
> 
>> 
>> /Henrik
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From proebuck at mdanderson.org  Tue May 22 20:26:50 2012
From: proebuck at mdanderson.org (Roebuck,Paul L)
Date: Tue, 22 May 2012 13:26:50 -0500
Subject: [Rd] bug in R version 2.15.0 (2012-03-30)?
In-Reply-To: <CANQBBMtODn-_EENH5v-aHOcBSBLUNGQpWJVjj+cXNJj1ne-Q5g@mail.gmail.com>
Message-ID: <CBE1449A.2E958%proebuck@mdanderson.org>

On 5/19/12 12:22 AM, "Wincent" <ronggui.huang at gmail.com> wrote:

> [SNIP]
> Also, is URI a typo of URL?

No. It is not.
<http://www.w3.org/TR/uri-clarification/#uri-partitioning>


From ggrothendieck at gmail.com  Tue May 22 20:39:22 2012
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 22 May 2012 14:39:22 -0400
Subject: [Rd] Best way to locate R executable from within R?
In-Reply-To: <CAFDcVCSbqCrF2hepKGC1n4BpdekBQcBg2B6+hSQFOZP9cgxq-g@mail.gmail.com>
References: <CAFDcVCSbqCrF2hepKGC1n4BpdekBQcBg2B6+hSQFOZP9cgxq-g@mail.gmail.com>
Message-ID: <CAP01uRm6PbqeKGUEM_rnTfWUbiZSpsfkE3Lqev30ATYEma5RNg@mail.gmail.com>

On Tue, May 22, 2012 at 1:34 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> Hi,
>
> I'd like to spawn of a new R process from within R using system(),
> e.g. system("R -f myScript.R"). ?However, just specifying "R" as in
> that example is not guaranteed to work, because "R" may not be on the
> OS's search path.
>
> ?What is the best way, from within a running R, to infer the command
> (basename or full path) for launching R in way that it works on any
> OS? ?I came up with the following alternatives, but I'm not sure if
> they'll work everywhere or not:
>
> 1. Rbin <- commandArgs()[1];
>
> 2. Rbin <- file.path(R.home(), "bin", "R");
>
> Other suggestions that are better?
>

At least on Windows one could run R via R.exe, Rterm.exe or Rgui.exe
amd #2 would not pick up the differences.  On the other hand if I do
this on the Windows command line on my Vista system with R 2.15.0
patched:

cd \program files\R\R-2.15.x\bin\i386
Rterm.exe

and then enter commandArgs() into R, the output is "Rterm.exe" with no path.

The fact that one can have 32 bit and 64 bit R executables on the same
system complicates things too.

Thus, on Windows something like this might work:

   file.path(R.home("bin"), R.version$arch, basename(commandArgs()[[1]]))

If there are cases that I missed then this might pick up those too:

   R <- commandArgs()[[1]]
   if (R == basename(R)) R <- file.path(R.home("bin"), R.version$arch, R)

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From simon.urbanek at r-project.org  Tue May 22 20:47:53 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 22 May 2012 14:47:53 -0400
Subject: [Rd] Best way to locate R executable from within R?
In-Reply-To: <CAP01uRm6PbqeKGUEM_rnTfWUbiZSpsfkE3Lqev30ATYEma5RNg@mail.gmail.com>
References: <CAFDcVCSbqCrF2hepKGC1n4BpdekBQcBg2B6+hSQFOZP9cgxq-g@mail.gmail.com>
	<CAP01uRm6PbqeKGUEM_rnTfWUbiZSpsfkE3Lqev30ATYEma5RNg@mail.gmail.com>
Message-ID: <9B9C28F6-39C5-45E6-96F0-960AB9E29B6A@r-project.org>


On May 22, 2012, at 2:39 PM, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:

> On Tue, May 22, 2012 at 1:34 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>> Hi,
>> 
>> I'd like to spawn of a new R process from within R using system(),
>> e.g. system("R -f myScript.R").  However, just specifying "R" as in
>> that example is not guaranteed to work, because "R" may not be on the
>> OS's search path.
>> 
>>  What is the best way, from within a running R, to infer the command
>> (basename or full path) for launching R in way that it works on any
>> OS?  I came up with the following alternatives, but I'm not sure if
>> they'll work everywhere or not:
>> 
>> 1. Rbin <- commandArgs()[1];
>> 
>> 2. Rbin <- file.path(R.home(), "bin", "R");
>> 
>> Other suggestions that are better?
>> 
> 
> At least on Windows one could run R via R.exe, Rterm.exe or Rgui.exe
> amd #2 would not pick up the differences.  On the other hand if I do
> this on the Windows command line on my Vista system with R 2.15.0
> patched:
> 
> cd \program files\R\R-2.15.x\bin\i386
> Rterm.exe
> 
> and then enter commandArgs() into R, the output is "Rterm.exe" with no path.
> 
> The fact that one can have 32 bit and 64 bit R executables on the same
> system complicates things too.
> 
> Thus, on Windows something like this might work:
> 
>   file.path(R.home("bin"), R.version$arch, basename(commandArgs()[[1]]))
> 
> If there are cases that I missed then this might pick up those too:
> 
>   R <- commandArgs()[[1]]
>   if (R == basename(R)) R <- file.path(R.home("bin"), R.version$arch, R)
> 

Typically, when you want another subprocess of R it is not the same as the process you're in - e.g. you certainly don't want to use Rgui to run a script, so the above is not useful for Henrik's purpose.
Besides, it won't even work since arg1 can as well be a symlink in a completely different place.

Cheers,
Simon


> -- 
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From hb at biostat.ucsf.edu  Tue May 22 21:05:31 2012
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Tue, 22 May 2012 12:05:31 -0700
Subject: [Rd] Best way to locate R executable from within R?
In-Reply-To: <CAP01uRm6PbqeKGUEM_rnTfWUbiZSpsfkE3Lqev30ATYEma5RNg@mail.gmail.com>
References: <CAFDcVCSbqCrF2hepKGC1n4BpdekBQcBg2B6+hSQFOZP9cgxq-g@mail.gmail.com>
	<CAP01uRm6PbqeKGUEM_rnTfWUbiZSpsfkE3Lqev30ATYEma5RNg@mail.gmail.com>
Message-ID: <CAFDcVCSYxQgUTELOWG5DTFkMWhC1T5+6axem1ZzhV+EXinrhSQ@mail.gmail.com>

On Tue, May 22, 2012 at 11:39 AM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> On Tue, May 22, 2012 at 1:34 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>> Hi,
>>
>> I'd like to spawn of a new R process from within R using system(),
>> e.g. system("R -f myScript.R"). ?However, just specifying "R" as in
>> that example is not guaranteed to work, because "R" may not be on the
>> OS's search path.
>>
>> ?What is the best way, from within a running R, to infer the command
>> (basename or full path) for launching R in way that it works on any
>> OS? ?I came up with the following alternatives, but I'm not sure if
>> they'll work everywhere or not:
>>
>> 1. Rbin <- commandArgs()[1];
>>
>> 2. Rbin <- file.path(R.home(), "bin", "R");
>>
>> Other suggestions that are better?
>>
>
> At least on Windows one could run R via R.exe, Rterm.exe or Rgui.exe
> amd #2 would not pick up the differences. ?On the other hand if I do
> this on the Windows command line on my Vista system with R 2.15.0
> patched:
>
> cd \program files\R\R-2.15.x\bin\i386
> Rterm.exe
>
> and then enter commandArgs() into R, the output is "Rterm.exe" with no path.

Thanks, I overlooked this need.  For my particular use case, I'm
interested in launching R in "batch" mode, so "R" will do (but not
"Rgui").

>
> The fact that one can have 32 bit and 64 bit R executables on the same
> system complicates things too.
>
> Thus, on Windows something like this might work:
>
> ? file.path(R.home("bin"), R.version$arch, basename(commandArgs()[[1]]))
>
> If there are cases that I missed then this might pick up those too:
>
> ? R <- commandArgs()[[1]]
> ? if (R == basename(R)) R <- file.path(R.home("bin"), R.version$arch, R)

FYI, R.home("bin") is not the same as file.path(R.home(), "bin"), cf.
help("R.home").  R.home("bin") will pick up the current architecture
directory (by using .Platform$r_arch), e.g.

> R.home("bin")
[1] "C:/PROGRA~1/R/R-2.15.0patched/bin/x64"

/Henrik

>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ggrothendieck at gmail.com  Tue May 22 21:28:26 2012
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 22 May 2012 15:28:26 -0400
Subject: [Rd] Best way to locate R executable from within R?
In-Reply-To: <CAFDcVCSYxQgUTELOWG5DTFkMWhC1T5+6axem1ZzhV+EXinrhSQ@mail.gmail.com>
References: <CAFDcVCSbqCrF2hepKGC1n4BpdekBQcBg2B6+hSQFOZP9cgxq-g@mail.gmail.com>
	<CAP01uRm6PbqeKGUEM_rnTfWUbiZSpsfkE3Lqev30ATYEma5RNg@mail.gmail.com>
	<CAFDcVCSYxQgUTELOWG5DTFkMWhC1T5+6axem1ZzhV+EXinrhSQ@mail.gmail.com>
Message-ID: <CAP01uRkaWr9jzYrkNLAGZMWwB75WCCf3rb6OQJxGA34gayYiYg@mail.gmail.com>

On Tue, May 22, 2012 at 3:05 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> On Tue, May 22, 2012 at 11:39 AM, Gabor Grothendieck
> <ggrothendieck at gmail.com> wrote:
>> On Tue, May 22, 2012 at 1:34 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>>> Hi,
>>>
>>> I'd like to spawn of a new R process from within R using system(),
>>> e.g. system("R -f myScript.R"). ?However, just specifying "R" as in
>>> that example is not guaranteed to work, because "R" may not be on the
>>> OS's search path.
>>>
>>> ?What is the best way, from within a running R, to infer the command
>>> (basename or full path) for launching R in way that it works on any
>>> OS? ?I came up with the following alternatives, but I'm not sure if
>>> they'll work everywhere or not:
>>>
>>> 1. Rbin <- commandArgs()[1];
>>>
>>> 2. Rbin <- file.path(R.home(), "bin", "R");
>>>
>>> Other suggestions that are better?
>>>
>>
>> At least on Windows one could run R via R.exe, Rterm.exe or Rgui.exe
>> amd #2 would not pick up the differences. ?On the other hand if I do
>> this on the Windows command line on my Vista system with R 2.15.0
>> patched:
>>
>> cd \program files\R\R-2.15.x\bin\i386
>> Rterm.exe
>>
>> and then enter commandArgs() into R, the output is "Rterm.exe" with no path.
>
> Thanks, I overlooked this need. ?For my particular use case, I'm
> interested in launching R in "batch" mode, so "R" will do (but not
> "Rgui").
>
>>
>> The fact that one can have 32 bit and 64 bit R executables on the same
>> system complicates things too.
>>
>> Thus, on Windows something like this might work:
>>
>> ? file.path(R.home("bin"), R.version$arch, basename(commandArgs()[[1]]))
>>
>> If there are cases that I missed then this might pick up those too:
>>
>> ? R <- commandArgs()[[1]]
>> ? if (R == basename(R)) R <- file.path(R.home("bin"), R.version$arch, R)
>
> FYI, R.home("bin") is not the same as file.path(R.home(), "bin"), cf.
> help("R.home"). ?R.home("bin") will pick up the current architecture
> directory (by using .Platform$r_arch), e.g.
>
>> R.home("bin")
> [1] "C:/PROGRA~1/R/R-2.15.0patched/bin/x64"
>
> /Henrik
>

Then perhaps something like this which is still not 100% foolproof but
should work most of the time:

Find(file.exists, c(
   commandArgs()[[1]],
   file.path(R.home("bin"), commandArgs()[[1]]),
   file.path(R.home("bin"), "R")
))

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From ggrothendieck at gmail.com  Tue May 22 21:34:02 2012
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 22 May 2012 15:34:02 -0400
Subject: [Rd] Best way to locate R executable from within R?
In-Reply-To: <CAP01uRkaWr9jzYrkNLAGZMWwB75WCCf3rb6OQJxGA34gayYiYg@mail.gmail.com>
References: <CAFDcVCSbqCrF2hepKGC1n4BpdekBQcBg2B6+hSQFOZP9cgxq-g@mail.gmail.com>
	<CAP01uRm6PbqeKGUEM_rnTfWUbiZSpsfkE3Lqev30ATYEma5RNg@mail.gmail.com>
	<CAFDcVCSYxQgUTELOWG5DTFkMWhC1T5+6axem1ZzhV+EXinrhSQ@mail.gmail.com>
	<CAP01uRkaWr9jzYrkNLAGZMWwB75WCCf3rb6OQJxGA34gayYiYg@mail.gmail.com>
Message-ID: <CAP01uRnftUBUOYpSZFkcTUgTpxKEQpvq23n8voC-K-r-F+8FBA@mail.gmail.com>

On Tue, May 22, 2012 at 3:28 PM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> On Tue, May 22, 2012 at 3:05 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>> On Tue, May 22, 2012 at 11:39 AM, Gabor Grothendieck
>> <ggrothendieck at gmail.com> wrote:
>>> On Tue, May 22, 2012 at 1:34 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>>>> Hi,
>>>>
>>>> I'd like to spawn of a new R process from within R using system(),
>>>> e.g. system("R -f myScript.R"). ?However, just specifying "R" as in
>>>> that example is not guaranteed to work, because "R" may not be on the
>>>> OS's search path.
>>>>
>>>> ?What is the best way, from within a running R, to infer the command
>>>> (basename or full path) for launching R in way that it works on any
>>>> OS? ?I came up with the following alternatives, but I'm not sure if
>>>> they'll work everywhere or not:
>>>>
>>>> 1. Rbin <- commandArgs()[1];
>>>>
>>>> 2. Rbin <- file.path(R.home(), "bin", "R");
>>>>
>>>> Other suggestions that are better?
>>>>
>>>
>>> At least on Windows one could run R via R.exe, Rterm.exe or Rgui.exe
>>> amd #2 would not pick up the differences. ?On the other hand if I do
>>> this on the Windows command line on my Vista system with R 2.15.0
>>> patched:
>>>
>>> cd \program files\R\R-2.15.x\bin\i386
>>> Rterm.exe
>>>
>>> and then enter commandArgs() into R, the output is "Rterm.exe" with no path.
>>
>> Thanks, I overlooked this need. ?For my particular use case, I'm
>> interested in launching R in "batch" mode, so "R" will do (but not
>> "Rgui").
>>
>>>
>>> The fact that one can have 32 bit and 64 bit R executables on the same
>>> system complicates things too.
>>>
>>> Thus, on Windows something like this might work:
>>>
>>> ? file.path(R.home("bin"), R.version$arch, basename(commandArgs()[[1]]))
>>>
>>> If there are cases that I missed then this might pick up those too:
>>>
>>> ? R <- commandArgs()[[1]]
>>> ? if (R == basename(R)) R <- file.path(R.home("bin"), R.version$arch, R)
>>
>> FYI, R.home("bin") is not the same as file.path(R.home(), "bin"), cf.
>> help("R.home"). ?R.home("bin") will pick up the current architecture
>> directory (by using .Platform$r_arch), e.g.
>>
>>> R.home("bin")
>> [1] "C:/PROGRA~1/R/R-2.15.0patched/bin/x64"
>>
>> /Henrik
>>
>
> Then perhaps something like this which is still not 100% foolproof but
> should work most of the time:
>
> Find(file.exists, c(
> ? commandArgs()[[1]],
> ? file.path(R.home("bin"), commandArgs()[[1]]),
> ? file.path(R.home("bin"), "R")
> ))

So that the last one tried works on Windows too it should be:

Find(file.exists, c(
 ? commandArgs()[[1]],
 ? file.path(R.home("bin"), commandArgs()[[1]]),
 ? file.path(R.home("bin"), "R"),
   file.path(R.home("bin"), "R.exe")
))



> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From jeff.a.ryan at gmail.com  Tue May 22 22:31:07 2012
From: jeff.a.ryan at gmail.com (Jeffrey Ryan)
Date: Tue, 22 May 2012 15:31:07 -0500
Subject: [Rd] Capturing signals from within external libs
Message-ID: <CBE161BB.3E916%jeff.a.ryan@gmail.com>

I have a continuous loop running in an external library that I am calling
from C (R API).  This loop is processing events in real time with the
possibility of significant lag between events.

When processing an event, I can make use of R_CheckUserInterrupt, but
while the external library code is waiting on a new event, I don't have an
opportunity to call this - my entry points are only on events.

I can capture a SIGINT by redefining signal(SIGINT, myhandler) before
calling the lib, but I am somewhat at a loss in terms of what I can do
within the handler that would let me pass control back to R.

void myhandler (int s) {
  error("interrupt caught!");
}

Works, but I am sure it isn't supposed to.  In fact I know it is wrong,
since after interrupting once SIGINTs are subsequently ignored, even if I
reset the signal to the original one (as returned by the first call to
signal).

Currently I can exit(1) of course, but that is tragically bad form IMO,
though will work in my situation.

In short, what is the proper way to handle SIGINT in external code that is
called from R, that allows R to handle the signal.  Thoughts or
suggestions appreciated.

Thanks,
Jeff


From simon.urbanek at r-project.org  Tue May 22 23:45:34 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 22 May 2012 17:45:34 -0400
Subject: [Rd] Capturing signals from within external libs
In-Reply-To: <CBE161BB.3E916%jeff.a.ryan@gmail.com>
References: <CBE161BB.3E916%jeff.a.ryan@gmail.com>
Message-ID: <AA1BCD64-CEDC-423D-8F51-50195EF2BF48@r-project.org>

Jeff,

On May 22, 2012, at 4:31 PM, Jeffrey Ryan wrote:

> I have a continuous loop running in an external library that I am calling
> from C (R API).  This loop is processing events in real time with the
> possibility of significant lag between events.
> 
> When processing an event, I can make use of R_CheckUserInterrupt, but
> while the external library code is waiting on a new event, I don't have an
> opportunity to call this - my entry points are only on events.
> 

Assuming that while in the library there are no R calls (important!), you can use setjmp/longjmp to branch your code depending on whether you raise an interrupt or not (see below). This also makes sure that you process things on the R side properly

Another alternative is to run your library call on a separate thread and have R wait for the result. In that case you don't need to mess with interrupts since your library code will run separately from R. The downside is that you need to mess with threads which may or may not be an issue depending on the complexity of your code and whether you want it to be cross-platform or not.

Cheers,
Simon


Example code:

#include <signal.h>
#include <setjmp.h>
#include <unistd.h>

#include <Rinternals.h>
#include <R_ext/GraphicsEngine.h> /* only needed if you use R_interrupts_pending */

static jmp_buf jenv;

static void my_int(int sig) {
  longjmp(jenv, 1); /* this also restores the interrupt handlers */
}

SEXP my_R_function(...) {

if (setjmp(jenv) == 0) { /* enter your protected code */
  void (*old_sig)(int);
  old_sig = signal(SIGINT, my_int);
  /* call your library here */
  /* restore original INT handler */
 signal(SIGINT, old_sig);
} else { /* this will get called on interrupt */
  /* you can do what you want - you're back to R-safe code here, so you can either raise an error or return from your function */
  /* if you want to trigger regular R interrupt handling, use this: */
   R_interrupts_pending = 1;
   R_CheckUserInterrupt();
  /* the above should not return */
}



> I can capture a SIGINT by redefining signal(SIGINT, myhandler) before
> calling the lib, but I am somewhat at a loss in terms of what I can do
> within the handler that would let me pass control back to R.
> 
> void myhandler (int s) {
>  error("interrupt caught!");
> }
> 
> Works, but I am sure it isn't supposed to.  In fact I know it is wrong,
> since after interrupting once SIGINTs are subsequently ignored, even if I
> reset the signal to the original one (as returned by the first call to
> signal).
> 
> Currently I can exit(1) of course, but that is tragically bad form IMO,
> though will work in my situation.
> 
> In short, what is the proper way to handle SIGINT in external code that is
> called from R, that allows R to handle the signal.  Thoughts or
> suggestions appreciated.
> 
> Thanks,
> Jeff
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From simon.urbanek at r-project.org  Wed May 23 00:04:15 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 22 May 2012 18:04:15 -0400
Subject: [Rd] Best way to locate R executable from within R?
In-Reply-To: <CAP01uRnftUBUOYpSZFkcTUgTpxKEQpvq23n8voC-K-r-F+8FBA@mail.gmail.com>
References: <CAFDcVCSbqCrF2hepKGC1n4BpdekBQcBg2B6+hSQFOZP9cgxq-g@mail.gmail.com>
	<CAP01uRm6PbqeKGUEM_rnTfWUbiZSpsfkE3Lqev30ATYEma5RNg@mail.gmail.com>
	<CAFDcVCSYxQgUTELOWG5DTFkMWhC1T5+6axem1ZzhV+EXinrhSQ@mail.gmail.com>
	<CAP01uRkaWr9jzYrkNLAGZMWwB75WCCf3rb6OQJxGA34gayYiYg@mail.gmail.com>
	<CAP01uRnftUBUOYpSZFkcTUgTpxKEQpvq23n8voC-K-r-F+8FBA@mail.gmail.com>
Message-ID: <4F9A8836-54E7-4E57-941C-39523B0CAD98@r-project.org>


On May 22, 2012, at 3:34 PM, Gabor Grothendieck wrote:

> On Tue, May 22, 2012 at 3:28 PM, Gabor Grothendieck
> <ggrothendieck at gmail.com> wrote:
>> On Tue, May 22, 2012 at 3:05 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>>> On Tue, May 22, 2012 at 11:39 AM, Gabor Grothendieck
>>> <ggrothendieck at gmail.com> wrote:
>>>> On Tue, May 22, 2012 at 1:34 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>>>>> Hi,
>>>>> 
>>>>> I'd like to spawn of a new R process from within R using system(),
>>>>> e.g. system("R -f myScript.R").  However, just specifying "R" as in
>>>>> that example is not guaranteed to work, because "R" may not be on the
>>>>> OS's search path.
>>>>> 
>>>>>  What is the best way, from within a running R, to infer the command
>>>>> (basename or full path) for launching R in way that it works on any
>>>>> OS?  I came up with the following alternatives, but I'm not sure if
>>>>> they'll work everywhere or not:
>>>>> 
>>>>> 1. Rbin <- commandArgs()[1];
>>>>> 
>>>>> 2. Rbin <- file.path(R.home(), "bin", "R");
>>>>> 
>>>>> Other suggestions that are better?
>>>>> 
>>>> 
>>>> At least on Windows one could run R via R.exe, Rterm.exe or Rgui.exe
>>>> amd #2 would not pick up the differences.  On the other hand if I do
>>>> this on the Windows command line on my Vista system with R 2.15.0
>>>> patched:
>>>> 
>>>> cd \program files\R\R-2.15.x\bin\i386
>>>> Rterm.exe
>>>> 
>>>> and then enter commandArgs() into R, the output is "Rterm.exe" with no path.
>>> 
>>> Thanks, I overlooked this need.  For my particular use case, I'm
>>> interested in launching R in "batch" mode, so "R" will do (but not
>>> "Rgui").
>>> 
>>>> 
>>>> The fact that one can have 32 bit and 64 bit R executables on the same
>>>> system complicates things too.
>>>> 
>>>> Thus, on Windows something like this might work:
>>>> 
>>>>   file.path(R.home("bin"), R.version$arch, basename(commandArgs()[[1]]))
>>>> 
>>>> If there are cases that I missed then this might pick up those too:
>>>> 
>>>>   R <- commandArgs()[[1]]
>>>>   if (R == basename(R)) R <- file.path(R.home("bin"), R.version$arch, R)
>>> 
>>> FYI, R.home("bin") is not the same as file.path(R.home(), "bin"), cf.
>>> help("R.home").  R.home("bin") will pick up the current architecture
>>> directory (by using .Platform$r_arch), e.g.
>>> 
>>>> R.home("bin")
>>> [1] "C:/PROGRA~1/R/R-2.15.0patched/bin/x64"
>>> 
>>> /Henrik
>>> 
>> 
>> Then perhaps something like this which is still not 100% foolproof but
>> should work most of the time:
>> 
>> Find(file.exists, c(
>>   commandArgs()[[1]],
>>   file.path(R.home("bin"), commandArgs()[[1]]),
>>   file.path(R.home("bin"), "R")
>> ))
> 
> So that the last one tried works on Windows too it should be:
> 
> Find(file.exists, c(
>   commandArgs()[[1]],
>   file.path(R.home("bin"), commandArgs()[[1]]),
>   file.path(R.home("bin"), "R"),
>   file.path(R.home("bin"), "R.exe")
> ))
> 

Obviously, you don't want to do that for reasons discussed previously.



> 
> 
>> --
>> Statistics & Software Consulting
>> GKX Group, GKX Associates Inc.
>> tel: 1-877-GKX-GROUP
>> email: ggrothendieck at gmail.com
> 
> 
> 
> -- 
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From simon.urbanek at r-project.org  Wed May 23 00:07:07 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 22 May 2012 18:07:07 -0400
Subject: [Rd] Best way to locate R executable from within R?
In-Reply-To: <CAFDcVCSYxQgUTELOWG5DTFkMWhC1T5+6axem1ZzhV+EXinrhSQ@mail.gmail.com>
References: <CAFDcVCSbqCrF2hepKGC1n4BpdekBQcBg2B6+hSQFOZP9cgxq-g@mail.gmail.com>
	<CAP01uRm6PbqeKGUEM_rnTfWUbiZSpsfkE3Lqev30ATYEma5RNg@mail.gmail.com>
	<CAFDcVCSYxQgUTELOWG5DTFkMWhC1T5+6axem1ZzhV+EXinrhSQ@mail.gmail.com>
Message-ID: <2374E708-F3FF-4414-B730-6D157CBD12F6@r-project.org>

I think the most reliable solution is something like

system(paste(shQuote(file.path(R.home("bin"),"R")), ...))

it supports spaces in paths and works both on unix and Windows, picking the proper architecture.

Cheers,
Simon



On May 22, 2012, at 3:05 PM, Henrik Bengtsson wrote:

> On Tue, May 22, 2012 at 11:39 AM, Gabor Grothendieck
> <ggrothendieck at gmail.com> wrote:
>> On Tue, May 22, 2012 at 1:34 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>>> Hi,
>>> 
>>> I'd like to spawn of a new R process from within R using system(),
>>> e.g. system("R -f myScript.R").  However, just specifying "R" as in
>>> that example is not guaranteed to work, because "R" may not be on the
>>> OS's search path.
>>> 
>>>  What is the best way, from within a running R, to infer the command
>>> (basename or full path) for launching R in way that it works on any
>>> OS?  I came up with the following alternatives, but I'm not sure if
>>> they'll work everywhere or not:
>>> 
>>> 1. Rbin <- commandArgs()[1];
>>> 
>>> 2. Rbin <- file.path(R.home(), "bin", "R");
>>> 
>>> Other suggestions that are better?
>>> 
>> 
>> At least on Windows one could run R via R.exe, Rterm.exe or Rgui.exe
>> amd #2 would not pick up the differences.  On the other hand if I do
>> this on the Windows command line on my Vista system with R 2.15.0
>> patched:
>> 
>> cd \program files\R\R-2.15.x\bin\i386
>> Rterm.exe
>> 
>> and then enter commandArgs() into R, the output is "Rterm.exe" with no path.
> 
> Thanks, I overlooked this need.  For my particular use case, I'm
> interested in launching R in "batch" mode, so "R" will do (but not
> "Rgui").
> 
>> 
>> The fact that one can have 32 bit and 64 bit R executables on the same
>> system complicates things too.
>> 
>> Thus, on Windows something like this might work:
>> 
>>   file.path(R.home("bin"), R.version$arch, basename(commandArgs()[[1]]))
>> 
>> If there are cases that I missed then this might pick up those too:
>> 
>>   R <- commandArgs()[[1]]
>>   if (R == basename(R)) R <- file.path(R.home("bin"), R.version$arch, R)
> 
> FYI, R.home("bin") is not the same as file.path(R.home(), "bin"), cf.
> help("R.home").  R.home("bin") will pick up the current architecture
> directory (by using .Platform$r_arch), e.g.
> 
>> R.home("bin")
> [1] "C:/PROGRA~1/R/R-2.15.0patched/bin/x64"
> 
> /Henrik
> 
>> 
>> --
>> Statistics & Software Consulting
>> GKX Group, GKX Associates Inc.
>> tel: 1-877-GKX-GROUP
>> email: ggrothendieck at gmail.com
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From ggrothendieck at gmail.com  Wed May 23 01:37:02 2012
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 22 May 2012 19:37:02 -0400
Subject: [Rd] Best way to locate R executable from within R?
In-Reply-To: <4F9A8836-54E7-4E57-941C-39523B0CAD98@r-project.org>
References: <CAFDcVCSbqCrF2hepKGC1n4BpdekBQcBg2B6+hSQFOZP9cgxq-g@mail.gmail.com>
	<CAP01uRm6PbqeKGUEM_rnTfWUbiZSpsfkE3Lqev30ATYEma5RNg@mail.gmail.com>
	<CAFDcVCSYxQgUTELOWG5DTFkMWhC1T5+6axem1ZzhV+EXinrhSQ@mail.gmail.com>
	<CAP01uRkaWr9jzYrkNLAGZMWwB75WCCf3rb6OQJxGA34gayYiYg@mail.gmail.com>
	<CAP01uRnftUBUOYpSZFkcTUgTpxKEQpvq23n8voC-K-r-F+8FBA@mail.gmail.com>
	<4F9A8836-54E7-4E57-941C-39523B0CAD98@r-project.org>
Message-ID: <CAP01uR=Yd_ngxVD6oF+AVSpy-i8Yg6d-HJA5L3Bfibb-YppU2A@mail.gmail.com>

On Tue, May 22, 2012 at 6:04 PM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
>
> On May 22, 2012, at 3:34 PM, Gabor Grothendieck wrote:
>
>> On Tue, May 22, 2012 at 3:28 PM, Gabor Grothendieck
>> <ggrothendieck at gmail.com> wrote:
>>> On Tue, May 22, 2012 at 3:05 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>>>> On Tue, May 22, 2012 at 11:39 AM, Gabor Grothendieck
>>>> <ggrothendieck at gmail.com> wrote:
>>>>> On Tue, May 22, 2012 at 1:34 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>>>>>> Hi,
>>>>>>
>>>>>> I'd like to spawn of a new R process from within R using system(),
>>>>>> e.g. system("R -f myScript.R"). ?However, just specifying "R" as in
>>>>>> that example is not guaranteed to work, because "R" may not be on the
>>>>>> OS's search path.
>>>>>>
>>>>>> ?What is the best way, from within a running R, to infer the command
>>>>>> (basename or full path) for launching R in way that it works on any
>>>>>> OS? ?I came up with the following alternatives, but I'm not sure if
>>>>>> they'll work everywhere or not:
>>>>>>
>>>>>> 1. Rbin <- commandArgs()[1];
>>>>>>
>>>>>> 2. Rbin <- file.path(R.home(), "bin", "R");
>>>>>>
>>>>>> Other suggestions that are better?
>>>>>>
>>>>>
>>>>> At least on Windows one could run R via R.exe, Rterm.exe or Rgui.exe
>>>>> amd #2 would not pick up the differences. ?On the other hand if I do
>>>>> this on the Windows command line on my Vista system with R 2.15.0
>>>>> patched:
>>>>>
>>>>> cd \program files\R\R-2.15.x\bin\i386
>>>>> Rterm.exe
>>>>>
>>>>> and then enter commandArgs() into R, the output is "Rterm.exe" with no path.
>>>>
>>>> Thanks, I overlooked this need. ?For my particular use case, I'm
>>>> interested in launching R in "batch" mode, so "R" will do (but not
>>>> "Rgui").
>>>>
>>>>>
>>>>> The fact that one can have 32 bit and 64 bit R executables on the same
>>>>> system complicates things too.
>>>>>
>>>>> Thus, on Windows something like this might work:
>>>>>
>>>>> ? file.path(R.home("bin"), R.version$arch, basename(commandArgs()[[1]]))
>>>>>
>>>>> If there are cases that I missed then this might pick up those too:
>>>>>
>>>>> ? R <- commandArgs()[[1]]
>>>>> ? if (R == basename(R)) R <- file.path(R.home("bin"), R.version$arch, R)
>>>>
>>>> FYI, R.home("bin") is not the same as file.path(R.home(), "bin"), cf.
>>>> help("R.home"). ?R.home("bin") will pick up the current architecture
>>>> directory (by using .Platform$r_arch), e.g.
>>>>
>>>>> R.home("bin")
>>>> [1] "C:/PROGRA~1/R/R-2.15.0patched/bin/x64"
>>>>
>>>> /Henrik
>>>>
>>>
>>> Then perhaps something like this which is still not 100% foolproof but
>>> should work most of the time:
>>>
>>> Find(file.exists, c(
>>> ? commandArgs()[[1]],
>>> ? file.path(R.home("bin"), commandArgs()[[1]]),
>>> ? file.path(R.home("bin"), "R")
>>> ))
>>
>> So that the last one tried works on Windows too it should be:
>>
>> Find(file.exists, c(
>> ? commandArgs()[[1]],
>> ? file.path(R.home("bin"), commandArgs()[[1]]),
>> ? file.path(R.home("bin"), "R"),
>> ? file.path(R.home("bin"), "R.exe")
>> ))
>>
>
> Obviously, you don't want to do that for reasons discussed previously.
>

In most cases with a link the complete path would be passed in which
case the first arg of Find would be chosen and be correct. If not it
would fail through to further choices one of which would likely be
correct and if none of them are then its likely that
file.path(R.home("bin"), "R")  isn't either since that is already one
of the choices.  While its not 100% foolproof the cases where it does
not work are quite pathological whereas the cases where
file.path(R.home("bin"), "R") fails to use the same executable include
common cases such as R being called as Rterm or Rscript.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From simon.urbanek at r-project.org  Wed May 23 01:50:58 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 22 May 2012 19:50:58 -0400
Subject: [Rd] Best way to locate R executable from within R?
In-Reply-To: <CAP01uR=Yd_ngxVD6oF+AVSpy-i8Yg6d-HJA5L3Bfibb-YppU2A@mail.gmail.com>
References: <CAFDcVCSbqCrF2hepKGC1n4BpdekBQcBg2B6+hSQFOZP9cgxq-g@mail.gmail.com>
	<CAP01uRm6PbqeKGUEM_rnTfWUbiZSpsfkE3Lqev30ATYEma5RNg@mail.gmail.com>
	<CAFDcVCSYxQgUTELOWG5DTFkMWhC1T5+6axem1ZzhV+EXinrhSQ@mail.gmail.com>
	<CAP01uRkaWr9jzYrkNLAGZMWwB75WCCf3rb6OQJxGA34gayYiYg@mail.gmail.com>
	<CAP01uRnftUBUOYpSZFkcTUgTpxKEQpvq23n8voC-K-r-F+8FBA@mail.gmail.com>
	<4F9A8836-54E7-4E57-941C-39523B0CAD98@r-project.org>
	<CAP01uR=Yd_ngxVD6oF+AVSpy-i8Yg6d-HJA5L3Bfibb-YppU2A@mail.gmail.com>
Message-ID: <3B9DF90B-60C4-4809-BB51-3660F5569A50@r-project.org>


On May 22, 2012, at 7:37 PM, Gabor Grothendieck wrote:

> On Tue, May 22, 2012 at 6:04 PM, Simon Urbanek
> <simon.urbanek at r-project.org> wrote:
>> 
>> On May 22, 2012, at 3:34 PM, Gabor Grothendieck wrote:
>> 
>>> On Tue, May 22, 2012 at 3:28 PM, Gabor Grothendieck
>>> <ggrothendieck at gmail.com> wrote:
>>>> On Tue, May 22, 2012 at 3:05 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>>>>> On Tue, May 22, 2012 at 11:39 AM, Gabor Grothendieck
>>>>> <ggrothendieck at gmail.com> wrote:
>>>>>> On Tue, May 22, 2012 at 1:34 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>>>>>>> Hi,
>>>>>>> 
>>>>>>> I'd like to spawn of a new R process from within R using system(),
>>>>>>> e.g. system("R -f myScript.R").  However, just specifying "R" as in
>>>>>>> that example is not guaranteed to work, because "R" may not be on the
>>>>>>> OS's search path.
>>>>>>> 
>>>>>>>  What is the best way, from within a running R, to infer the command
>>>>>>> (basename or full path) for launching R in way that it works on any
>>>>>>> OS?  I came up with the following alternatives, but I'm not sure if
>>>>>>> they'll work everywhere or not:
>>>>>>> 
>>>>>>> 1. Rbin <- commandArgs()[1];
>>>>>>> 
>>>>>>> 2. Rbin <- file.path(R.home(), "bin", "R");
>>>>>>> 
>>>>>>> Other suggestions that are better?
>>>>>>> 
>>>>>> 
>>>>>> At least on Windows one could run R via R.exe, Rterm.exe or Rgui.exe
>>>>>> amd #2 would not pick up the differences.  On the other hand if I do
>>>>>> this on the Windows command line on my Vista system with R 2.15.0
>>>>>> patched:
>>>>>> 
>>>>>> cd \program files\R\R-2.15.x\bin\i386
>>>>>> Rterm.exe
>>>>>> 
>>>>>> and then enter commandArgs() into R, the output is "Rterm.exe" with no path.
>>>>> 
>>>>> Thanks, I overlooked this need.  For my particular use case, I'm
>>>>> interested in launching R in "batch" mode, so "R" will do (but not
>>>>> "Rgui").
>>>>> 
>>>>>> 
>>>>>> The fact that one can have 32 bit and 64 bit R executables on the same
>>>>>> system complicates things too.
>>>>>> 
>>>>>> Thus, on Windows something like this might work:
>>>>>> 
>>>>>>   file.path(R.home("bin"), R.version$arch, basename(commandArgs()[[1]]))
>>>>>> 
>>>>>> If there are cases that I missed then this might pick up those too:
>>>>>> 
>>>>>>   R <- commandArgs()[[1]]
>>>>>>   if (R == basename(R)) R <- file.path(R.home("bin"), R.version$arch, R)
>>>>> 
>>>>> FYI, R.home("bin") is not the same as file.path(R.home(), "bin"), cf.
>>>>> help("R.home").  R.home("bin") will pick up the current architecture
>>>>> directory (by using .Platform$r_arch), e.g.
>>>>> 
>>>>>> R.home("bin")
>>>>> [1] "C:/PROGRA~1/R/R-2.15.0patched/bin/x64"
>>>>> 
>>>>> /Henrik
>>>>> 
>>>> 
>>>> Then perhaps something like this which is still not 100% foolproof but
>>>> should work most of the time:
>>>> 
>>>> Find(file.exists, c(
>>>>   commandArgs()[[1]],
>>>>   file.path(R.home("bin"), commandArgs()[[1]]),
>>>>   file.path(R.home("bin"), "R")
>>>> ))
>>> 
>>> So that the last one tried works on Windows too it should be:
>>> 
>>> Find(file.exists, c(
>>>   commandArgs()[[1]],
>>>   file.path(R.home("bin"), commandArgs()[[1]]),
>>>   file.path(R.home("bin"), "R"),
>>>   file.path(R.home("bin"), "R.exe")
>>> ))
>>> 
>> 
>> Obviously, you don't want to do that for reasons discussed previously.
>> 
> 
> In most cases with a link the complete path would be passed in which
> case the first arg of Find would be chosen and be correct. If not it
> would fail through to further choices one of which would likely be
> correct and if none of them are then its likely that
> file.path(R.home("bin"), "R")  isn't either since that is already one
> of the choices.  While its not 100% foolproof the cases where it does
> not work are quite pathological whereas the cases where
> file.path(R.home("bin"), "R") fails to use the same executable include
> common cases such as R being called as Rterm or Rscript.
> 

Except that you may not have noticed that no one asked about that since that makes no sense (arguments differ etc.). The question was how to start R and your suggestions make it only worse and unusable - fortunately Henrik asked about better solutions so we can safely close this discussion.

Cheers,
Simon


From ggrothendieck at gmail.com  Wed May 23 02:50:25 2012
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 22 May 2012 20:50:25 -0400
Subject: [Rd] Best way to locate R executable from within R?
In-Reply-To: <3B9DF90B-60C4-4809-BB51-3660F5569A50@r-project.org>
References: <CAFDcVCSbqCrF2hepKGC1n4BpdekBQcBg2B6+hSQFOZP9cgxq-g@mail.gmail.com>
	<CAP01uRm6PbqeKGUEM_rnTfWUbiZSpsfkE3Lqev30ATYEma5RNg@mail.gmail.com>
	<CAFDcVCSYxQgUTELOWG5DTFkMWhC1T5+6axem1ZzhV+EXinrhSQ@mail.gmail.com>
	<CAP01uRkaWr9jzYrkNLAGZMWwB75WCCf3rb6OQJxGA34gayYiYg@mail.gmail.com>
	<CAP01uRnftUBUOYpSZFkcTUgTpxKEQpvq23n8voC-K-r-F+8FBA@mail.gmail.com>
	<4F9A8836-54E7-4E57-941C-39523B0CAD98@r-project.org>
	<CAP01uR=Yd_ngxVD6oF+AVSpy-i8Yg6d-HJA5L3Bfibb-YppU2A@mail.gmail.com>
	<3B9DF90B-60C4-4809-BB51-3660F5569A50@r-project.org>
Message-ID: <CAP01uRnEd=6=T2zYCTSxK2SoKvj+k6f+Z3Ab8CUd8roiODpTtg@mail.gmail.com>

On Tue, May 22, 2012 at 7:50 PM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
>
> On May 22, 2012, at 7:37 PM, Gabor Grothendieck wrote:
>
>> On Tue, May 22, 2012 at 6:04 PM, Simon Urbanek
>> <simon.urbanek at r-project.org> wrote:
>>>
>>> On May 22, 2012, at 3:34 PM, Gabor Grothendieck wrote:
>>>
>>>> On Tue, May 22, 2012 at 3:28 PM, Gabor Grothendieck
>>>> <ggrothendieck at gmail.com> wrote:
>>>>> On Tue, May 22, 2012 at 3:05 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>>>>>> On Tue, May 22, 2012 at 11:39 AM, Gabor Grothendieck
>>>>>> <ggrothendieck at gmail.com> wrote:
>>>>>>> On Tue, May 22, 2012 at 1:34 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>>>>>>>> Hi,
>>>>>>>>
>>>>>>>> I'd like to spawn of a new R process from within R using system(),
>>>>>>>> e.g. system("R -f myScript.R"). ?However, just specifying "R" as in
>>>>>>>> that example is not guaranteed to work, because "R" may not be on the
>>>>>>>> OS's search path.
>>>>>>>>
>>>>>>>> ?What is the best way, from within a running R, to infer the command
>>>>>>>> (basename or full path) for launching R in way that it works on any
>>>>>>>> OS? ?I came up with the following alternatives, but I'm not sure if
>>>>>>>> they'll work everywhere or not:
>>>>>>>>
>>>>>>>> 1. Rbin <- commandArgs()[1];
>>>>>>>>
>>>>>>>> 2. Rbin <- file.path(R.home(), "bin", "R");
>>>>>>>>
>>>>>>>> Other suggestions that are better?
>>>>>>>>
>>>>>>>
>>>>>>> At least on Windows one could run R via R.exe, Rterm.exe or Rgui.exe
>>>>>>> amd #2 would not pick up the differences. ?On the other hand if I do
>>>>>>> this on the Windows command line on my Vista system with R 2.15.0
>>>>>>> patched:
>>>>>>>
>>>>>>> cd \program files\R\R-2.15.x\bin\i386
>>>>>>> Rterm.exe
>>>>>>>
>>>>>>> and then enter commandArgs() into R, the output is "Rterm.exe" with no path.
>>>>>>
>>>>>> Thanks, I overlooked this need. ?For my particular use case, I'm
>>>>>> interested in launching R in "batch" mode, so "R" will do (but not
>>>>>> "Rgui").
>>>>>>
>>>>>>>
>>>>>>> The fact that one can have 32 bit and 64 bit R executables on the same
>>>>>>> system complicates things too.
>>>>>>>
>>>>>>> Thus, on Windows something like this might work:
>>>>>>>
>>>>>>> ? file.path(R.home("bin"), R.version$arch, basename(commandArgs()[[1]]))
>>>>>>>
>>>>>>> If there are cases that I missed then this might pick up those too:
>>>>>>>
>>>>>>> ? R <- commandArgs()[[1]]
>>>>>>> ? if (R == basename(R)) R <- file.path(R.home("bin"), R.version$arch, R)
>>>>>>
>>>>>> FYI, R.home("bin") is not the same as file.path(R.home(), "bin"), cf.
>>>>>> help("R.home"). ?R.home("bin") will pick up the current architecture
>>>>>> directory (by using .Platform$r_arch), e.g.
>>>>>>
>>>>>>> R.home("bin")
>>>>>> [1] "C:/PROGRA~1/R/R-2.15.0patched/bin/x64"
>>>>>>
>>>>>> /Henrik
>>>>>>
>>>>>
>>>>> Then perhaps something like this which is still not 100% foolproof but
>>>>> should work most of the time:
>>>>>
>>>>> Find(file.exists, c(
>>>>> ? commandArgs()[[1]],
>>>>> ? file.path(R.home("bin"), commandArgs()[[1]]),
>>>>> ? file.path(R.home("bin"), "R")
>>>>> ))
>>>>
>>>> So that the last one tried works on Windows too it should be:
>>>>
>>>> Find(file.exists, c(
>>>> ? commandArgs()[[1]],
>>>> ? file.path(R.home("bin"), commandArgs()[[1]]),
>>>> ? file.path(R.home("bin"), "R"),
>>>> ? file.path(R.home("bin"), "R.exe")
>>>> ))
>>>>
>>>
>>> Obviously, you don't want to do that for reasons discussed previously.
>>>
>>
>> In most cases with a link the complete path would be passed in which
>> case the first arg of Find would be chosen and be correct. If not it
>> would fail through to further choices one of which would likely be
>> correct and if none of them are then its likely that
>> file.path(R.home("bin"), "R") ?isn't either since that is already one
>> of the choices. ?While its not 100% foolproof the cases where it does
>> not work are quite pathological whereas the cases where
>> file.path(R.home("bin"), "R") fails to use the same executable include
>> common cases such as R being called as Rterm or Rscript.
>>
>
> Except that you may not have noticed that no one asked about that since that makes no sense (arguments differ etc.). The question was how to start R and your suggestions make it only worse and unusable - fortunately Henrik asked about better solutions so we can safely close this discussion.
>
> Cheers,
> Simon
>

So far he has excluded Rgui but that still leaves Rterm, Rscript and R
(and littler on UNIX) -- all of which are valid ways to launch R.  If
its sufficient to always launch it as R then your solution is briefer
but it is subsumed in the one I posted which handles it in full
generality.  Its really a matter of usage case at this point.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From mdowle at mdowle.plus.com  Wed May 23 10:37:36 2012
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Wed, 23 May 2012 09:37:36 +0100
Subject: [Rd] Expected behaviour of is.unsorted?
Message-ID: <e1647ee6a646d7b2339189dfeffe994d.squirrel@webmail.plus.net>


Hi,

I've read ?is.unsorted and searched. Have found a few items but nothing
close, yet. Is the following expected?

> is.unsorted(data.frame(1:2))
[1] FALSE
> is.unsorted(data.frame(2:1))
[1] FALSE
> is.unsorted(data.frame(1:2,3:4))
[1] TRUE
> is.unsorted(data.frame(2:1,4:3))
[1] TRUE

IIUC, is.unsorted is intended for atomic vectors only (description of x in
?is.unsorted). Indeed the C source (src/main/sort.c) contains an error
message "only atomic vectors can be tested to be sorted". So that is the
error message I expected to see in all cases above, since I know that
data.frame is not an atomic vector. But there is also this in
?is.unsorted: "except for atomic vectors and objects with a class (where
the >= or > method is used)" which I don't understand. Where >= or > is
used by what, and where?

I understand why the first two are FALSE (1 item of anything must be
sorted). I don't understand the 3rd and 4th cases where length is 2:
do_isunsorted seems to call lang3(install(".gtn"), x, CADR(args))). Does
that fall back to TRUE for some reason?

Matthew

> sessionInfo()
R version 2.15.0 (2012-03-30)
Platform: x86_64-pc-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United
Kingdom.1252
[3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C
[5] LC_TIME=English_United Kingdom.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] data.table_1.8.0

loaded via a namespace (and not attached):
[1] tools_2.15.0


From stephane.champely at univ-lyon1.fr  Wed May 23 07:47:59 2012
From: stephane.champely at univ-lyon1.fr (CHAMPELY STEPHANE)
Date: Wed, 23 May 2012 05:47:59 +0000
Subject: [Rd] giving a datasets list
Message-ID: <425A6492A642764EB65EC0479C4F7D450268C493@BV2010TMP.univ-lyon1.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120523/9dd1aa5b/attachment.pl>

From richierocks at gmail.com  Wed May 23 12:23:39 2012
From: richierocks at gmail.com (Richard Cotton)
Date: Wed, 23 May 2012 11:23:39 +0100
Subject: [Rd] Expected behaviour of is.unsorted?
In-Reply-To: <e1647ee6a646d7b2339189dfeffe994d.squirrel@webmail.plus.net>
References: <e1647ee6a646d7b2339189dfeffe994d.squirrel@webmail.plus.net>
Message-ID: <CAPp_+=fQb=5_rimK3fYYzMKaACj1KSuOrQhWWs1P1yUq95hAdA@mail.gmail.com>

>> is.unsorted(data.frame(1:2))
> [1] FALSE
>> is.unsorted(data.frame(2:1))
> [1] FALSE
>> is.unsorted(data.frame(1:2,3:4))
> [1] TRUE
>> is.unsorted(data.frame(2:1,4:3))
> [1] TRUE
>
> IIUC, is.unsorted is intended for atomic vectors only (description of x in
> ?is.unsorted). Indeed the C source (src/main/sort.c) contains an error
> message "only atomic vectors can be tested to be sorted". So that is the
> error message I expected to see in all cases above, since I know that
> data.frame is not an atomic vector. But there is also this in
> ?is.unsorted: "except for atomic vectors and objects with a class (where
> the >= or > method is used)" which I don't understand. Where >= or > is
> used by what, and where?
>
> I understand why the first two are FALSE (1 item of anything must be
> sorted). I don't understand the 3rd and 4th cases where length is 2:
> do_isunsorted seems to call lang3(install(".gtn"), x, CADR(args))). Does
> that fall back to TRUE for some reason?

I've just been having similar worries with this today.  The odd
behaviour seems to be particular to data.frames.  Compare for example,

is.unsorted(list(1, 3, 2))              #NA
is.unsorted(data.frame(1, 3, 2)) #FALSE
is.unsorted(data.frame(1, 2, 3)) #TRUE

IMHO, it would be clearer if is.unsorted either always returned NA for
recursive objects of length 2 or more, or it called unlist to make it
atomic.  Either way, it should really provide some sort of warning
about non-standard input.

-- 
Regards,
Richie

live-analytics.com
4dpiecharts.com


From jari.oksanen at oulu.fi  Wed May 23 12:49:19 2012
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Wed, 23 May 2012 10:49:19 +0000
Subject: [Rd] prcomp with previously scaled data: predict with 'newdata'
	wrong
Message-ID: <66C03CD1145C95448A4D73676DD9C2ED2C9B3A@nippu2.univ.yo.oulu.fi>

Hello folks,

it may be regarded as a user error to scale() your data prior to prcomp() instead of using its 'scale.' argument. However, it is a user thing that may happen and sounds a legitimate thing to do, but in that case predict() with 'newdata' can give wrong results:

x <- scale(USArrests)
sol <- prcomp(x)
all.equal(predict(sol), predict(sol, newdata=x))
## [1] "Mean relative difference: 0.9033485"

Predicting with the same data gives different results than the original PCA of the data.

The reason of this behaviour seems to be in these first lines of stats:::prcomp.default():

    x <- scale(x, center = center, scale = scale.)
    cen <- attr(x, "scaled:center")
    sc <- attr(x, "scaled:scale")

If input data 'x' have 'scaled:scale' attribute, it will be retained if scale() is called with argument "scale = FALSE" like is the case with default options in prcomp(). So scale(scale(x, scale = TRUE), scale = FALSE) will have the 'scaled:center' of the outer scale() (i.e, numerical zero), but the 'scaled:scale' of the inner scale(). 

Function princomp  finds the 'scale' directly instead of looking at the attributes of the input data, and works like expected:

 sol <- princomp(x)
all.equal(predict(sol), predict(sol, newdata=x))
## [1] TRUE

I don't have any nifty solution to this -- only checking the 'scale.' attribute and acting accordingly:

sc <- if (scale.) attr(x, "scaled:scale") else FALSE

Cheers, Jari Oksanen



From murdoch.duncan at gmail.com  Wed May 23 12:52:50 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 23 May 2012 06:52:50 -0400
Subject: [Rd] Expected behaviour of is.unsorted?
In-Reply-To: <e1647ee6a646d7b2339189dfeffe994d.squirrel@webmail.plus.net>
References: <e1647ee6a646d7b2339189dfeffe994d.squirrel@webmail.plus.net>
Message-ID: <4FBCC182.8020007@gmail.com>

On 12-05-23 4:37 AM, Matthew Dowle wrote:
>
> Hi,
>
> I've read ?is.unsorted and searched. Have found a few items but nothing
> close, yet. Is the following expected?
>
>> is.unsorted(data.frame(1:2))
> [1] FALSE
>> is.unsorted(data.frame(2:1))
> [1] FALSE
>> is.unsorted(data.frame(1:2,3:4))
> [1] TRUE
>> is.unsorted(data.frame(2:1,4:3))
> [1] TRUE
>
> IIUC, is.unsorted is intended for atomic vectors only (description of x in
> ?is.unsorted). Indeed the C source (src/main/sort.c) contains an error
> message "only atomic vectors can be tested to be sorted". So that is the
> error message I expected to see in all cases above, since I know that
> data.frame is not an atomic vector. But there is also this in
> ?is.unsorted: "except for atomic vectors and objects with a class (where
> the>= or>  method is used)" which I don't understand. Where>= or>  is
> used by what, and where?

If you look at the source, you will see that the basic test for classed 
objects is

all(x[-1L] >= x[-length(x)])

(in the function base:::.gtn).

This comparison doesn't really makes sense for dataframes, but it does 
seem to be backwards:  that tests that x[2] >= x[1], x[3] >= x[2], etc., 
returning TRUE if all comparisons are TRUE:  but that sounds like it 
should be is.sorted(), not is.unsorted().  Or is it my brain that is 
backwards?

Duncan Murdoch


>
> I understand why the first two are FALSE (1 item of anything must be
> sorted). I don't understand the 3rd and 4th cases where length is 2:
> do_isunsorted seems to call lang3(install(".gtn"), x, CADR(args))). Does
> that fall back to TRUE for some reason?
>
> Matthew
>
>> sessionInfo()
> R version 2.15.0 (2012-03-30)
> Platform: x86_64-pc-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United
> Kingdom.1252
> [3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C
> [5] LC_TIME=English_United Kingdom.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] data.table_1.8.0
>
> loaded via a namespace (and not attached):
> [1] tools_2.15.0
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jari.oksanen at oulu.fi  Wed May 23 13:02:17 2012
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Wed, 23 May 2012 11:02:17 +0000
Subject: [Rd] prcomp with previously scaled data: predict with
	'newdata'	wrong
In-Reply-To: <66C03CD1145C95448A4D73676DD9C2ED2C9B3A@nippu2.univ.yo.oulu.fi>
References: <66C03CD1145C95448A4D73676DD9C2ED2C9B3A@nippu2.univ.yo.oulu.fi>
Message-ID: <66C03CD1145C95448A4D73676DD9C2ED2C9BC3@nippu2.univ.yo.oulu.fi>

To fix myself: the stupid solution I suggested won't work as 'scale.' need not be TRUE or FALSE, but it can be a vector of scales. The following looks like being able to handle this, but is not transparent nor elegant:

sc <- if (isTRUE(scale.)) attr(x, "scaled:scale") else scale.

I trust you find an elegant solution (if you think this is worth fixing).

Cheers, Jari Oksanen

PS. Sorry for the top posting: cannot help with the email system I have in my work desktop.
________________________________________
From: r-devel-bounces at r-project.org [r-devel-bounces at r-project.org] on behalf of Jari Oksanen [jari.oksanen at oulu.fi]
Sent: 23 May 2012 13:51
To: r-devel at stat.math.ethz.ch
Subject: [Rd] prcomp with previously scaled data: predict with 'newdata'        wrong

Hello folks,

it may be regarded as a user error to scale() your data prior to prcomp() instead of using its 'scale.' argument. However, it is a user thing that may happen and sounds a legitimate thing to do, but in that case predict() with 'newdata' can give wrong results:

x <- scale(USArrests)
sol <- prcomp(x)
all.equal(predict(sol), predict(sol, newdata=x))
## [1] "Mean relative difference: 0.9033485"

Predicting with the same data gives different results than the original PCA of the data.

The reason of this behaviour seems to be in these first lines of stats:::prcomp.default():

    x <- scale(x, center = center, scale = scale.)
    cen <- attr(x, "scaled:center")
    sc <- attr(x, "scaled:scale")

If input data 'x' have 'scaled:scale' attribute, it will be retained if scale() is called with argument "scale = FALSE" like is the case with default options in prcomp(). So scale(scale(x, scale = TRUE), scale = FALSE) will have the 'scaled:center' of the outer scale() (i.e, numerical zero), but the 'scaled:scale' of the inner scale().

Function princomp  finds the 'scale' directly instead of looking at the attributes of the input data, and works like expected:

 sol <- princomp(x)
all.equal(predict(sol), predict(sol, newdata=x))
## [1] TRUE

I don't have any nifty solution to this -- only checking the 'scale.' attribute and acting accordingly:

sc <- if (scale.) attr(x, "scaled:scale") else FALSE

Cheers, Jari Oksanen


______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From xie at yihui.name  Wed May 23 17:41:04 2012
From: xie at yihui.name (Yihui Xie)
Date: Wed, 23 May 2012 10:41:04 -0500
Subject: [Rd] [R] how to remove the 'promise' attribute of an R object
	(.Random.seed)?
In-Reply-To: <4FBC7DB3.4020809@stats.ox.ac.uk>
References: <CANROs4cWDYJyWCQwbWmaxg1GOFD8fuSMewZp6A6n9AUrx0qvjQ@mail.gmail.com>
	<alpine.LFD.2.02.1205221245280.1888@nokomis.stat.uiowa.edu>
	<CANROs4c=gCOt6CJwywJhuJoX3zGHSoGLZ+4eGQUrAGB47iPYjA@mail.gmail.com>
	<4FBC7DB3.4020809@stats.ox.ac.uk>
Message-ID: <CANROs4c3GxODPwuYO+Yv89jAtML95As66kFPc2PG6EoHXgHoaQ@mail.gmail.com>

OK, I switched to r-devel.

I'm caching the random seed by saving and lazy loading .Random.seed,
so I think it should always be valid (except that it becomes a promise
which is essentially an integer vector).

The complete process is as follows:

set.seed(1)  # R generates .Random.seed now
tools:::makeLazyLoadDB(globalenv(), 'random_db', variables = '.Random.seed')
lazyLoad('random_db')
rnorm(1)
# Error in rnorm(1) :
#  .Random.seed is not an integer vector but of type 'promise'

As I explained earlier, the purpose is for caching when an Sweave
document involves with RNG; instead of running set.seed() again, I
just lazy-load the seed. I'm not sure if this is a convincing enough
application. You might frown on the use of :::, though.

Thanks!

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 515-294-2465 Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


On Wed, May 23, 2012 at 1:03 AM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> On 22/05/2012 22:26, Yihui Xie wrote:
>>
>> I did not use delayedAssign() directly; I was using lazyLoad() and
>> .Random.seed was saved in a database. The real story out there is the
>> caching of my knitr package -- lazyLoad() was used to speed up the
>> compilation of Sweave documents.
>>
>> I know lazyLoad() is supposed to be used only by R itself, but it is
>> very helpful for the purpose of caching as well.
>>
>> Or is it possible to change the code in src/main/RNG.c so that the
>> seed is force()d if it is a promise?
>
>
> It is possible, but we need to be convinced that it is desirable. ?The main
> point is that you should not be setting .Random.seed (see its help page),
> and all the ways R itself sets it create a object of the correct internal
> type. ?The test is there because of people who failed to follow the advice
> and set it incorrectly (usually as a double vector).
>
> If you want to make a case for a change, R-devel would be the appropriate
> list and you would need to explain in detail why you thinking setting
> .Random.seed is appropriate and exactly how you do it.
>
>
>> Anyway, I can use save() and load() in this case instead of lazyLoad()
>> if the above is not going to happen. Thanks a lot!
>>
>> Regards,
>> Yihui
>> --
>> Yihui Xie<xieyihui at gmail.com>
>> Phone: 515-294-2465 Web: http://yihui.name
>> Department of Statistics, Iowa State University
>> 2215 Snedecor Hall, Ames, IA
>>
>>
>> On Tue, May 22, 2012 at 12:49 PM,<luke-tierney at uiowa.edu> ?wrote:
>>>
>>> On Tue, 22 May 2012, Yihui Xie wrote:
>>>
>>>> Hi,
>>>>
>>>> The problem arises when I lazyLoad() the .Random.seed from a
>>>> previously saved database. To simplify the process of reproducing the
>>>> problem, see the example below:
>>>>
>>>> ## this assignment may not really make sense, but illustrates the
>>>> problem
>>>> delayedAssign('.Random.seed', 1L)
>>>>
>>>> typeof(.Random.seed)
>>>> # [1] "integer"
>>>>
>>>> rnorm(1)
>>>> # Error in rnorm(1) :
>>>> # ?.Random.seed is not an integer vector but of type 'promise'
>>>>
>>>> typeof(.Random.seed)
>>>> # [1] "integer"
>>>>
>>>> So there must be an "attribute" "promise" somewhere attached to
>>>> .Random.seed, and I cannot find it. The R function typeof() does not
>>>> reveal it, but the TYPEOF() function in src/main/RNG.c says it is a
>>>> 'promise'.
>>>>
>>>> My question is, how to make R use the real value of .Random.seed
>>>> instead of complaining about the promise? Thanks!
>>>
>>>
>>>
>>> Siple answer: Don't creat the promise in the first place, i.e. don't
>>> use delayedAssign.
>>>
>>> What is the real context where this arises? Knowing that may help us
>>> decide whether the internals should address this possibility.
>>>
>>> Best,
>>>
>>> luke
>>>
>>>>
>>>> Regards,
>>>> Yihui
>>>> --
>>>> Yihui Xie<xieyihui at gmail.com>
>>>> Phone: 515-294-2465 Web: http://yihui.name
>>>> Department of Statistics, Iowa State University
>>>> 2215 Snedecor Hall, Ames, IA
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>> --
>>> Luke Tierney
>>> Chair, Statistics and Actuarial Science
>>> Ralph E. Wareham Professor of Mathematical Sciences
>>> University of Iowa ? ? ? ? ? ? ? ? ?Phone: ? ? ? ? ? ? 319-335-3386
>>> Department of Statistics and ? ? ? ?Fax: ? ? ? ? ? ? ? 319-335-3017
>>> ? Actuarial Science
>>> 241 Schaeffer Hall ? ? ? ? ? ? ? ? ?email: ? luke-tierney at uiowa.edu
>>> Iowa City, IA 52242 ? ? ? ? ? ? ? ? WWW: ?http://www.stat.uiowa.edu
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595


From luke-tierney at uiowa.edu  Wed May 23 18:22:25 2012
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Wed, 23 May 2012 11:22:25 -0500
Subject: [Rd] [R] how to remove the 'promise' attribute of an R object
 (.Random.seed)?
In-Reply-To: <CANROs4c3GxODPwuYO+Yv89jAtML95As66kFPc2PG6EoHXgHoaQ@mail.gmail.com>
References: <CANROs4cWDYJyWCQwbWmaxg1GOFD8fuSMewZp6A6n9AUrx0qvjQ@mail.gmail.com>
	<alpine.LFD.2.02.1205221245280.1888@nokomis.stat.uiowa.edu>
	<CANROs4c=gCOt6CJwywJhuJoX3zGHSoGLZ+4eGQUrAGB47iPYjA@mail.gmail.com>
	<4FBC7DB3.4020809@stats.ox.ac.uk>
	<CANROs4c3GxODPwuYO+Yv89jAtML95As66kFPc2PG6EoHXgHoaQ@mail.gmail.com>
Message-ID: <alpine.LFD.2.02.1205231118050.1888@nokomis.stat.uiowa.edu>

I'm not persuaded at this point that we want to support use of the
lazy loading infrastructure outside the core as we might want to
change it in the future. But the principle that promises are an
internal implementation detail that should be as invisible at possible
at the user level suggest that this should be changed, so R-devel and
R-patched now force promises in this case.

There are a number of other cases in the sources that may have
similar issues. It would be good to check them over and handle any
that need handling in a systematic way. I don't have time to do that
now but I'll put it in my queue.

luke

On Wed, 23 May 2012, Yihui Xie wrote:

> OK, I switched to r-devel.
>
> I'm caching the random seed by saving and lazy loading .Random.seed,
> so I think it should always be valid (except that it becomes a promise
> which is essentially an integer vector).
>
> The complete process is as follows:
>
> set.seed(1)  # R generates .Random.seed now
> tools:::makeLazyLoadDB(globalenv(), 'random_db', variables = '.Random.seed')
> lazyLoad('random_db')
> rnorm(1)
> # Error in rnorm(1) :
> #  .Random.seed is not an integer vector but of type 'promise'
>
> As I explained earlier, the purpose is for caching when an Sweave
> document involves with RNG; instead of running set.seed() again, I
> just lazy-load the seed. I'm not sure if this is a convincing enough
> application. You might frown on the use of :::, though.
>
> Thanks!
>
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Phone: 515-294-2465 Web: http://yihui.name
> Department of Statistics, Iowa State University
> 2215 Snedecor Hall, Ames, IA
>
>
> On Wed, May 23, 2012 at 1:03 AM, Prof Brian Ripley
> <ripley at stats.ox.ac.uk> wrote:
>> On 22/05/2012 22:26, Yihui Xie wrote:
>>>
>>> I did not use delayedAssign() directly; I was using lazyLoad() and
>>> .Random.seed was saved in a database. The real story out there is the
>>> caching of my knitr package -- lazyLoad() was used to speed up the
>>> compilation of Sweave documents.
>>>
>>> I know lazyLoad() is supposed to be used only by R itself, but it is
>>> very helpful for the purpose of caching as well.
>>>
>>> Or is it possible to change the code in src/main/RNG.c so that the
>>> seed is force()d if it is a promise?
>>
>>
>> It is possible, but we need to be convinced that it is desirable. ?The main
>> point is that you should not be setting .Random.seed (see its help page),
>> and all the ways R itself sets it create a object of the correct internal
>> type. ?The test is there because of people who failed to follow the advice
>> and set it incorrectly (usually as a double vector).
>>
>> If you want to make a case for a change, R-devel would be the appropriate
>> list and you would need to explain in detail why you thinking setting
>> .Random.seed is appropriate and exactly how you do it.
>>
>>
>>> Anyway, I can use save() and load() in this case instead of lazyLoad()
>>> if the above is not going to happen. Thanks a lot!
>>>
>>> Regards,
>>> Yihui
>>> --
>>> Yihui Xie<xieyihui at gmail.com>
>>> Phone: 515-294-2465 Web: http://yihui.name
>>> Department of Statistics, Iowa State University
>>> 2215 Snedecor Hall, Ames, IA
>>>
>>>
>>> On Tue, May 22, 2012 at 12:49 PM,<luke-tierney at uiowa.edu> ?wrote:
>>>>
>>>> On Tue, 22 May 2012, Yihui Xie wrote:
>>>>
>>>>> Hi,
>>>>>
>>>>> The problem arises when I lazyLoad() the .Random.seed from a
>>>>> previously saved database. To simplify the process of reproducing the
>>>>> problem, see the example below:
>>>>>
>>>>> ## this assignment may not really make sense, but illustrates the
>>>>> problem
>>>>> delayedAssign('.Random.seed', 1L)
>>>>>
>>>>> typeof(.Random.seed)
>>>>> # [1] "integer"
>>>>>
>>>>> rnorm(1)
>>>>> # Error in rnorm(1) :
>>>>> # ?.Random.seed is not an integer vector but of type 'promise'
>>>>>
>>>>> typeof(.Random.seed)
>>>>> # [1] "integer"
>>>>>
>>>>> So there must be an "attribute" "promise" somewhere attached to
>>>>> .Random.seed, and I cannot find it. The R function typeof() does not
>>>>> reveal it, but the TYPEOF() function in src/main/RNG.c says it is a
>>>>> 'promise'.
>>>>>
>>>>> My question is, how to make R use the real value of .Random.seed
>>>>> instead of complaining about the promise? Thanks!
>>>>
>>>>
>>>>
>>>> Siple answer: Don't creat the promise in the first place, i.e. don't
>>>> use delayedAssign.
>>>>
>>>> What is the real context where this arises? Knowing that may help us
>>>> decide whether the internals should address this possibility.
>>>>
>>>> Best,
>>>>
>>>> luke
>>>>
>>>>>
>>>>> Regards,
>>>>> Yihui
>>>>> --
>>>>> Yihui Xie<xieyihui at gmail.com>
>>>>> Phone: 515-294-2465 Web: http://yihui.name
>>>>> Department of Statistics, Iowa State University
>>>>> 2215 Snedecor Hall, Ames, IA
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>> --
>>>> Luke Tierney
>>>> Chair, Statistics and Actuarial Science
>>>> Ralph E. Wareham Professor of Mathematical Sciences
>>>> University of Iowa ? ? ? ? ? ? ? ? ?Phone: ? ? ? ? ? ? 319-335-3386
>>>> Department of Statistics and ? ? ? ?Fax: ? ? ? ? ? ? ? 319-335-3017
>>>> ? Actuarial Science
>>>> 241 Schaeffer Hall ? ? ? ? ? ? ? ? ?email: ? luke-tierney at uiowa.edu
>>>> Iowa City, IA 52242 ? ? ? ? ? ? ? ? WWW: ?http://www.stat.uiowa.edu
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
>> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
>> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From jeff.a.ryan at gmail.com  Wed May 23 18:40:59 2012
From: jeff.a.ryan at gmail.com (Jeffrey Ryan)
Date: Wed, 23 May 2012 11:40:59 -0500
Subject: [Rd] Capturing signals from within external libs
In-Reply-To: <AA1BCD64-CEDC-423D-8F51-50195EF2BF48@r-project.org>
Message-ID: <CBE27CF4.3E95F%jeff.a.ryan@gmail.com>

Simon,

Thanks for the clarifying example.  I fear my current set up fails the
test for 'no R calls', so I think I am stuck on the ugly variant for my
current challenge, but I will be able to use this in other places.

Thanks again,
Jeff

On 5/22/12 4:45 PM, "Simon Urbanek" <simon.urbanek at r-project.org> wrote:

>Jeff,
>
>On May 22, 2012, at 4:31 PM, Jeffrey Ryan wrote:
>
>> I have a continuous loop running in an external library that I am
>>calling
>> from C (R API).  This loop is processing events in real time with the
>> possibility of significant lag between events.
>> 
>> When processing an event, I can make use of R_CheckUserInterrupt, but
>> while the external library code is waiting on a new event, I don't have
>>an
>> opportunity to call this - my entry points are only on events.
>> 
>
>Assuming that while in the library there are no R calls (important!), you
>can use setjmp/longjmp to branch your code depending on whether you raise
>an interrupt or not (see below). This also makes sure that you process
>things on the R side properly
>
>Another alternative is to run your library call on a separate thread and
>have R wait for the result. In that case you don't need to mess with
>interrupts since your library code will run separately from R. The
>downside is that you need to mess with threads which may or may not be an
>issue depending on the complexity of your code and whether you want it to
>be cross-platform or not.
>
>Cheers,
>Simon
>
>
>Example code:
>
>#include <signal.h>
>#include <setjmp.h>
>#include <unistd.h>
>
>#include <Rinternals.h>
>#include <R_ext/GraphicsEngine.h> /* only needed if you use
>R_interrupts_pending */
>
>static jmp_buf jenv;
>
>static void my_int(int sig) {
>  longjmp(jenv, 1); /* this also restores the interrupt handlers */
>}
>
>SEXP my_R_function(...) {
>
>if (setjmp(jenv) == 0) { /* enter your protected code */
>  void (*old_sig)(int);
>  old_sig = signal(SIGINT, my_int);
>  /* call your library here */
>  /* restore original INT handler */
> signal(SIGINT, old_sig);
>} else { /* this will get called on interrupt */
>  /* you can do what you want - you're back to R-safe code here, so you
>can either raise an error or return from your function */
>  /* if you want to trigger regular R interrupt handling, use this: */
>   R_interrupts_pending = 1;
>   R_CheckUserInterrupt();
>  /* the above should not return */
>}
>
>
>
>> I can capture a SIGINT by redefining signal(SIGINT, myhandler) before
>> calling the lib, but I am somewhat at a loss in terms of what I can do
>> within the handler that would let me pass control back to R.
>> 
>> void myhandler (int s) {
>>  error("interrupt caught!");
>> }
>> 
>> Works, but I am sure it isn't supposed to.  In fact I know it is wrong,
>> since after interrupting once SIGINTs are subsequently ignored, even if
>>I
>> reset the signal to the original one (as returned by the first call to
>> signal).
>> 
>> Currently I can exit(1) of course, but that is tragically bad form IMO,
>> though will work in my situation.
>> 
>> In short, what is the proper way to handle SIGINT in external code that
>>is
>> called from R, that allows R to handle the signal.  Thoughts or
>> suggestions appreciated.
>> 
>> Thanks,
>> Jeff
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> 
>


From claudia.beleites at ipht-jena.de  Wed May 23 18:47:04 2012
From: claudia.beleites at ipht-jena.de (Claudia Beleites)
Date: Wed, 23 May 2012 18:47:04 +0200
Subject: [Rd] test suites for packages
In-Reply-To: <CBDBD265.22343%mec@stowers.org>
References: <CBDBD265.22343%mec@stowers.org>
Message-ID: <4FBD1488.4050608@ipht-jena.de>

I use svUnit, too.

I put a kind of standard skeleton into my packages that has a
packagename.unittest () function that will run all svUnit tests (if
svUnit is available). This function returns NA if svUnit is not
available, invisible (TRUE) if all tests are passed and  stops
otherwise. Which will cause R CMD check to fail.

My test directory contains one single tests.R file with the two lines:

library (packagename)
packagename.unittest ()


which gives me e.g.:

Running the tests in ?tests/tests.R? failed.
Last 13 lines of output:
    only logical matrix subscripts are allowed in replacement

  * :     ...) ... **ERROR**
  Error in `[<-.data.frame`(`*tmp*`, x.na, value = NA) :
    only logical matrix subscripts are allowed in replacement
                           kind timing                time unit msg
  test(kernelpls.fit)        OK  0.009 2012-05-23 14:38:49
  test(scale)                OK  0.009 2012-05-23 14:38:49
  test(.ldapreproc)   **ERROR**  0.007 2012-05-23 14:38:49
  test(pcalda)               OK  0.003 2012-05-23 14:38:49
  Error in errorLog(summarize = FALSE) : 0 failure(s) and 1 error(s)
  Calls: cbmodels.unittest -> errorLog
  Execution halted


While the 13 lines may not be enough if there are lots of tests, I can
easily run packagename.unittest () in an interactive session and start
tracking down the problem from there.


Claudia


Am 18.05.2012 17:28, schrieb Cook, Malcolm:
> svUnit - is Runit compatible and provides some  IDE integration and report
> generation and easy syntax for defining tests.
> 
> I find it works a treat, and fits very nicely with my R coding/packaging
> style (which also uses inlinedocs for easy package creation).
> 
> --Malcolm Cook
> 
> 
> On 5/17/12 9:10 AM, "Whit Armstrong" <armstrong.whit at gmail.com> wrote:
> 
>> Can anyone share some opinions on test suites for R packages?
>>
>> I'm looking at testthat and RUnit. Does anyone have strong opinions on
>> either of those.
>>
>> Any additional packages I should consider?
>>
>> Thanks,
>> Whit
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Claudia Beleites
Spectroscopy/Imaging
Institute of Photonic Technology
Albert-Einstein-Str. 9
07745 Jena
Germany

email: claudia.beleites at ipht-jena.de
phone: +49 3641 206-133
fax:   +49 2641 206-399


From simon.urbanek at r-project.org  Wed May 23 18:49:33 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 23 May 2012 12:49:33 -0400
Subject: [Rd] Capturing signals from within external libs
In-Reply-To: <CBE27CF4.3E95F%jeff.a.ryan@gmail.com>
References: <CBE27CF4.3E95F%jeff.a.ryan@gmail.com>
Message-ID: <4A62F5CE-4E9A-4FA1-A5EA-40DE2A41DD7B@r-project.org>


On May 23, 2012, at 12:40 PM, Jeffrey Ryan wrote:

> Simon,
> 
> Thanks for the clarifying example.  I fear my current set up fails the
> test for 'no R calls',

Well, but in that case you already have interrupt points so I'm not sure what is the problem? I thought the whole point is that you have long processing in some 3rd party library where you can't call R API so that's why you need the hack in the first place ...


> so I think I am stuck on the ugly variant for my
> current challenge, but I will be able to use this in other places.
> 
> Thanks again,
> Jeff
> 
> On 5/22/12 4:45 PM, "Simon Urbanek" <simon.urbanek at r-project.org> wrote:
> 
>> Jeff,
>> 
>> On May 22, 2012, at 4:31 PM, Jeffrey Ryan wrote:
>> 
>>> I have a continuous loop running in an external library that I am
>>> calling
>>> from C (R API).  This loop is processing events in real time with the
>>> possibility of significant lag between events.
>>> 
>>> When processing an event, I can make use of R_CheckUserInterrupt, but
>>> while the external library code is waiting on a new event, I don't have
>>> an
>>> opportunity to call this - my entry points are only on events.
>>> 
>> 
>> Assuming that while in the library there are no R calls (important!), you
>> can use setjmp/longjmp to branch your code depending on whether you raise
>> an interrupt or not (see below). This also makes sure that you process
>> things on the R side properly
>> 
>> Another alternative is to run your library call on a separate thread and
>> have R wait for the result. In that case you don't need to mess with
>> interrupts since your library code will run separately from R. The
>> downside is that you need to mess with threads which may or may not be an
>> issue depending on the complexity of your code and whether you want it to
>> be cross-platform or not.
>> 
>> Cheers,
>> Simon
>> 
>> 
>> Example code:
>> 
>> #include <signal.h>
>> #include <setjmp.h>
>> #include <unistd.h>
>> 
>> #include <Rinternals.h>
>> #include <R_ext/GraphicsEngine.h> /* only needed if you use
>> R_interrupts_pending */
>> 
>> static jmp_buf jenv;
>> 
>> static void my_int(int sig) {
>> longjmp(jenv, 1); /* this also restores the interrupt handlers */
>> }
>> 
>> SEXP my_R_function(...) {
>> 
>> if (setjmp(jenv) == 0) { /* enter your protected code */
>> void (*old_sig)(int);
>> old_sig = signal(SIGINT, my_int);
>> /* call your library here */
>> /* restore original INT handler */
>> signal(SIGINT, old_sig);
>> } else { /* this will get called on interrupt */
>> /* you can do what you want - you're back to R-safe code here, so you
>> can either raise an error or return from your function */
>> /* if you want to trigger regular R interrupt handling, use this: */
>>  R_interrupts_pending = 1;
>>  R_CheckUserInterrupt();
>> /* the above should not return */
>> }
>> 
>> 
>> 
>>> I can capture a SIGINT by redefining signal(SIGINT, myhandler) before
>>> calling the lib, but I am somewhat at a loss in terms of what I can do
>>> within the handler that would let me pass control back to R.
>>> 
>>> void myhandler (int s) {
>>> error("interrupt caught!");
>>> }
>>> 
>>> Works, but I am sure it isn't supposed to.  In fact I know it is wrong,
>>> since after interrupting once SIGINTs are subsequently ignored, even if
>>> I
>>> reset the signal to the original one (as returned by the first call to
>>> signal).
>>> 
>>> Currently I can exit(1) of course, but that is tragically bad form IMO,
>>> though will work in my situation.
>>> 
>>> In short, what is the proper way to handle SIGINT in external code that
>>> is
>>> called from R, that allows R to handle the signal.  Thoughts or
>>> suggestions appreciated.
>>> 
>>> Thanks,
>>> Jeff
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>> 
>> 
> 
> 
> 


From jeff.a.ryan at gmail.com  Wed May 23 19:23:31 2012
From: jeff.a.ryan at gmail.com (Jeffrey Ryan)
Date: Wed, 23 May 2012 12:23:31 -0500
Subject: [Rd] Capturing signals from within external libs
In-Reply-To: <4A62F5CE-4E9A-4FA1-A5EA-40DE2A41DD7B@r-project.org>
Message-ID: <CBE282B5.3E96B%jeff.a.ryan@gmail.com>

Simon,

Very likely butchered my initial problem explanation. The issue is that I
make a call to a library, something like:

SEXP my_fun() {
...
CB = MyCallback("XYZ");  /* this contains callback functions that in turn
use R */
externalLibCall(CB);     /* infinite loop that won't return as it is
capturing streaming data */

/* we never get here */

Return(R_NilValue);
}

My callbacks look something like

on_event_A () {
  R_CheckUserInterrupt():
  evalRFunctionFromC();
}

But event_A only gets called when a new message arrives.  When a new
message arrives the on_event_A gets called from within the external
library code (hence calling R), but only when a message arrives.

At this point R_CheckUserInterrupt() works just fine.  The problem is when
the external process is waiting on a new message.  I have no entry to
check whether or not a message is available, nothing akin to select().
Basically I only get control in my callback when a new message happens.
So if there is no new message (in the context above it is a message/tick
from an exchange), the process spins/waits/not too sure what happens
internally, but the net result is I don't see anything.  I am waiting.  It
is at this point that I want to force an interrupt.

My current solution is just to redefine as my SIGINT handler before the
externalLibCall call, with an ungraceful exit() internal to it.  Dirty,
but lets me break. In the ideal world I would be returned to the R prompt,
but it isn't overly critical in this application since it is being run
more or less headless as is.

The other problem, which makes me cringe of course, is that this is all
further complicated by the fact that it is not just C, but C++ and running
on Win64 ;-)   I tried not to mention that of course ...

Your insights are very appreciated, and I now have further knowledge into
making this work in other applications, but my hope for this one is
dwindling.

Best,
Jeff


On 5/23/12 11:49 AM, "Simon Urbanek" <simon.urbanek at r-project.org> wrote:

>
>On May 23, 2012, at 12:40 PM, Jeffrey Ryan wrote:
>
>> Simon,
>> 
>> Thanks for the clarifying example.  I fear my current set up fails the
>> test for 'no R calls',
>
>Well, but in that case you already have interrupt points so I'm not sure
>what is the problem? I thought the whole point is that you have long
>processing in some 3rd party library where you can't call R API so that's
>why you need the hack in the first place ...
>
>
>> so I think I am stuck on the ugly variant for my
>> current challenge, but I will be able to use this in other places.
>> 
>> Thanks again,
>> Jeff
>> 
>> On 5/22/12 4:45 PM, "Simon Urbanek" <simon.urbanek at r-project.org> wrote:
>> 
>>> Jeff,
>>> 
>>> On May 22, 2012, at 4:31 PM, Jeffrey Ryan wrote:
>>> 
>>>> I have a continuous loop running in an external library that I am
>>>> calling
>>>> from C (R API).  This loop is processing events in real time with the
>>>> possibility of significant lag between events.
>>>> 
>>>> When processing an event, I can make use of R_CheckUserInterrupt, but
>>>> while the external library code is waiting on a new event, I don't
>>>>have
>>>> an
>>>> opportunity to call this - my entry points are only on events.
>>>> 
>>> 
>>> Assuming that while in the library there are no R calls (important!),
>>>you
>>> can use setjmp/longjmp to branch your code depending on whether you
>>>raise
>>> an interrupt or not (see below). This also makes sure that you process
>>> things on the R side properly
>>> 
>>> Another alternative is to run your library call on a separate thread
>>>and
>>> have R wait for the result. In that case you don't need to mess with
>>> interrupts since your library code will run separately from R. The
>>> downside is that you need to mess with threads which may or may not be
>>>an
>>> issue depending on the complexity of your code and whether you want it
>>>to
>>> be cross-platform or not.
>>> 
>>> Cheers,
>>> Simon
>>> 
>>> 
>>> Example code:
>>> 
>>> #include <signal.h>
>>> #include <setjmp.h>
>>> #include <unistd.h>
>>> 
>>> #include <Rinternals.h>
>>> #include <R_ext/GraphicsEngine.h> /* only needed if you use
>>> R_interrupts_pending */
>>> 
>>> static jmp_buf jenv;
>>> 
>>> static void my_int(int sig) {
>>> longjmp(jenv, 1); /* this also restores the interrupt handlers */
>>> }
>>> 
>>> SEXP my_R_function(...) {
>>> 
>>> if (setjmp(jenv) == 0) { /* enter your protected code */
>>> void (*old_sig)(int);
>>> old_sig = signal(SIGINT, my_int);
>>> /* call your library here */
>>> /* restore original INT handler */
>>> signal(SIGINT, old_sig);
>>> } else { /* this will get called on interrupt */
>>> /* you can do what you want - you're back to R-safe code here, so you
>>> can either raise an error or return from your function */
>>> /* if you want to trigger regular R interrupt handling, use this: */
>>>  R_interrupts_pending = 1;
>>>  R_CheckUserInterrupt();
>>> /* the above should not return */
>>> }
>>> 
>>> 
>>> 
>>>> I can capture a SIGINT by redefining signal(SIGINT, myhandler) before
>>>> calling the lib, but I am somewhat at a loss in terms of what I can do
>>>> within the handler that would let me pass control back to R.
>>>> 
>>>> void myhandler (int s) {
>>>> error("interrupt caught!");
>>>> }
>>>> 
>>>> Works, but I am sure it isn't supposed to.  In fact I know it is
>>>>wrong,
>>>> since after interrupting once SIGINTs are subsequently ignored, even
>>>>if
>>>> I
>>>> reset the signal to the original one (as returned by the first call to
>>>> signal).
>>>> 
>>>> Currently I can exit(1) of course, but that is tragically bad form
>>>>IMO,
>>>> though will work in my situation.
>>>> 
>>>> In short, what is the proper way to handle SIGINT in external code
>>>>that
>>>> is
>>>> called from R, that allows R to handle the signal.  Thoughts or
>>>> suggestions appreciated.
>>>> 
>>>> Thanks,
>>>> Jeff
>>>> 
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> 
>>>> 
>>> 
>> 
>> 
>> 
>


From jon.skoien at jrc.ec.europa.eu  Thu May 24 11:38:00 2012
From: jon.skoien at jrc.ec.europa.eu (Jon Olav Skoien)
Date: Thu, 24 May 2012 11:38:00 +0200
Subject: [Rd] New S3 methods for optional package
Message-ID: <4FBE0178.50109@jrc.ec.europa.eu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120524/593626a7/attachment.pl>

From ripley at stats.ox.ac.uk  Thu May 24 12:01:34 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 24 May 2012 11:01:34 +0100
Subject: [Rd] New S3 methods for optional package
In-Reply-To: <4FBE0178.50109@jrc.ec.europa.eu>
References: <4FBE0178.50109@jrc.ec.europa.eu>
Message-ID: <4FBE06FE.7010000@stats.ox.ac.uk>

On 24/05/2012 10:38, Jon Olav Skoien wrote:
> Hi,
>
> I have asked this question before, but the solution I ended up with (see
> below) creates a note when running R CMD check. So I am trying again...
>
> I am developing a package B that, among other things, also offers some
> extra S3-methods for functions in package A if the user has installed A.
> I do not want to list A under Depends of B, as the dependency list of A
> is rather long, and most potential users of B will not be interested in
> package A and what it depends on. Unfortunately I struggle with doing
> this right. After asking on the list some time ago, I have listed A
> under Suggests, and have a .onLoad function in B with
> if (require(A)) registerS3methods(newMethodsMatrix, package = A, env =
> environment(B))

You are not supposed to be calling registerS3methods .... it is only 
visible because of the nature of the base namespace and its 
documentation says

'Not intended to be called directly.'

And require() is the wrong thing here; you want to register methods on a 
namespace.   The logic seems to be that you should do that only if A's 
namespace is already loaded, but you could load it pre-emptively with 
requireNamespace().

> But starting with R 2.13 or R 2.14, R CMD check creates a note:
> "Package startup functions should not change the search path.
> See section 'Good practice' in ?.onAttach."
> I have understood that packages with notes can be uploaded to CRAN, but
> that they tend to create extra work for the maintainers and hence I am
> trying to find another solution.

Most likely a call to requireNamespace() would work without any NOTE.

> So far I have tried:
> List A under Suggest of B, with a conditional import in NAMESPACE.
> If I build a Windows-binary from this when A is installed, this package
> can be installed but not loaded on computers where A is not installed.

That will happen.  But that's the price for the convenience of binary 
packages.

> List A under Enhances of B.
> This seems to be the right thing, as the R extensions manual says: "the
> 'Enhances' field lists packages "enhanced" by the package at hand, e.g.,
> by providing methods for classes from these packages".
> However, although it seems I can install and load package B when I
> conditionally import package A in the NAMESPACE, R CMD check stops with
> the error: Namespace dependency not required: A
> If I remove the import, R CMD check is happier, but I cannot load the
> package after installing.
>
> I have read about the use of "Suggest", "Enhances" etc in "Writing R
> Extensions", but could not figure out the right way to do this. I am
> sure there is something I am missing here.
>
> If anyone wants to check possible solutions, package A is "intamap",
> available from CRAN, whereas B is "rtop", available from Rforge:
> **|install.packages("rtop", repos="http://R-Forge.R-project.org")|**

I guess the problem is that you are trying to do too much with package 
rtop.  I would consider creating a separate package depending on intamap 
(and most likely rtop) which adds the S3 methods for intamap.

> Thanks,
> Jon

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From yikelu.home at gmail.com  Wed May 23 21:53:25 2012
From: yikelu.home at gmail.com (Yike Lu)
Date: Wed, 23 May 2012 12:53:25 -0700 (PDT)
Subject: [Rd] Curry: proposed new functional programming, er, function.
In-Reply-To: <BANLkTik-1s+Af541ZkM+mDVkjRx94WM_4w@mail.gmail.com>
References: <7098abec0711011200va3851o811f60bb100616ce@mail.gmail.com>
	<BANLkTi=jud5hhis5y-veQKZHzSYYoPqnBw@mail.gmail.com>
	<79F23BA7BB084E4FA01A8B93904CD02CF669FAA4C9@WIGGUMVS.win.ad.jhu.edu>
	<4DC16917.5090206@gmail.com>
	<BANLkTikuy3OP8j5aymKuE_zmHtYLCkBZWg@mail.gmail.com>
	<79F23BA7BB084E4FA01A8B93904CD02CF669FAA4D7@WIGGUMVS.win.ad.jhu.edu>
	<BANLkTikvfsyZaW4wDB8sA-Z7G-rMQ+11Tg@mail.gmail.com>
	<BANLkTikGcviLYfFska4vkf5GpuCpmKTdJw@mail.gmail.com>
	<BANLkTik-1s+Af541ZkM+mDVkjRx94WM_4w@mail.gmail.com>
Message-ID: <1337802805327-4631127.post@n4.nabble.com>


Hadley Wickham-2 wrote
> 
>     Curry <- function(FUN, ...) {
>       args <- match.call(expand.dots = FALSE)$...
>       args$... <- as.name("...")
> 
>       env <- parent.frame()
> 
>       if (is.name(FUN)) {
>         fname <- FUN
>       } else if (is.character(FUN)) {
>         fname <- as.name(FUN)
>       } else if (is.function(FUN)){
>         fname <- as.name("FUN")
>         env$FUN <- FUN
>       } else {
>         stop("FUN not function or name of function")
>       }
>       curry_call <- as.call(c(list(fname), args))
> 
>       f <- eval(call("function", as.pairlist(alist(... = )), curry_call))
>       environment(f) <- env
>       f
>     }
> 
> But I've probably forgotten something else.  Hopefully Luke will chime
> in if I'm proceeding down a path that can never be made to work
> completely correctly.
> 
I've been playing around with this for a while. One flaw I found - it
doesn't handle nested Curries very well (the naive implementation in
roxygen/functional does).

e.g.:

foo=function(x,y,z) x+y+z
Curry(Curry("foo",3),4)(3)
# 10

Curry(Curry(foo,3),4)(3)
# hangs

foo4=function(a,b,c,d)
Curry(Curry(Curry("foo4",3),4),1)(3)
# hangs

I was also curious if there was some trick to force a function eval when the
list of arguments got exhausted (for example, a triple Curry on foo above
would leave no arguments so would trigger eval into 10).

--
View this message in context: http://r.789695.n4.nabble.com/Curry-proposed-new-functional-programming-er-function-tp917654p4631127.html
Sent from the R devel mailing list archive at Nabble.com.


From mdowle at mdowle.plus.com  Thu May 24 13:39:10 2012
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Thu, 24 May 2012 11:39:10 +0000
Subject: [Rd] Expected behaviour of is.unsorted?
References: <e1647ee6a646d7b2339189dfeffe994d.squirrel@webmail.plus.net>
	<4FBCC182.8020007@gmail.com>
Message-ID: <loom.20120524T122752-447@post.gmane.org>

Duncan Murdoch <murdoch.duncan <at> gmail.com> writes:
> 
> On 12-05-23 4:37 AM, Matthew Dowle wrote:
> >
> > Hi,
> >
> > I've read ?is.unsorted and searched. Have found a few items but nothing
> > close, yet. Is the following expected?
> >
> >> is.unsorted(data.frame(1:2))
> > [1] FALSE
> >> is.unsorted(data.frame(2:1))
> > [1] FALSE
> >> is.unsorted(data.frame(1:2,3:4))
> > [1] TRUE
> >> is.unsorted(data.frame(2:1,4:3))
> > [1] TRUE
> >
> > IIUC, is.unsorted is intended for atomic vectors only (description of x in
> > ?is.unsorted). Indeed the C source (src/main/sort.c) contains an error
> > message "only atomic vectors can be tested to be sorted". So that is the
> > error message I expected to see in all cases above, since I know that
> > data.frame is not an atomic vector. But there is also this in
> > ?is.unsorted: "except for atomic vectors and objects with a class (where
> > the>= or>  method is used)" which I don't understand. Where>= or>  is
> > used by what, and where?
> 
> If you look at the source, you will see that the basic test for classed 
> objects is
> 
> all(x[-1L] >= x[-length(x)])
> 
> (in the function base:::.gtn).
> 
> This comparison doesn't really makes sense for dataframes, but it does 
> seem to be backwards:  that tests that x[2] >= x[1], x[3] >= x[2], etc., 
> returning TRUE if all comparisons are TRUE:  but that sounds like it 
> should be is.sorted(), not is.unsorted().  Or is it my brain that is 
> backwards?

Thanks. Yes you're right. So is.unsorted() on a data.frame is trying to tell us 
if there exists any unsorted row, it seems.

> DF = data.frame(a=c(1,3,5),b=c(1,3,5))
> DF
  a b
1 1 1               # this row is sorted
2 3 3               # this row is sorted
3 5 5               # this row is sorted
> is.unsorted(DF)   # going by row but should be !.gtn
[1] TRUE
> with(DF,is.unsorted(order(a,b)))  # most people's natural expectation I guess
[1] FALSE
> DF[2,2]=2
> DF
  a b
1 1 1               # this row is sorted
2 3 2               # this row isn't sorted
3 5 5               # this row is sorted
> is.unsorted(DF)   # going by row but should be !.gtn
[1] FALSE
> with(DF,is.unsorted(order(a,b)))  # most people's natural expectation I guess
[1] FALSE

Since it seems to have a bug anyway (and if so, can't be correct in anyone's 
use of it), could either is.unsorted on a data.frame return the error that's in 
the C code already: "only atomic vectors can be tested to be sorted", for 
safety and to lessen confusion, or be changed to return the natural expectation 
proposed above? The easiest quick fix would be to negate the result of the .gtn 
call of course, but then you could never go back.

Matthew

> Duncan Murdoch
> 
> >
> > I understand why the first two are FALSE (1 item of anything must be
> > sorted). I don't understand the 3rd and 4th cases where length is 2:
> > do_isunsorted seems to call lang3(install(".gtn"), x, CADR(args))). Does
> > that fall back to TRUE for some reason?
> >
> > Matthew
> >
> >> sessionInfo()
> > R version 2.15.0 (2012-03-30)
> > Platform: x86_64-pc-mingw32/x64 (64-bit)
> >
> > locale:
> > [1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United
> > Kingdom.1252
> > [3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C
> > [5] LC_TIME=English_United Kingdom.1252
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > other attached packages:
> > [1] data.table_1.8.0
> >
> > loaded via a namespace (and not attached):
> > [1] tools_2.15.0
> >
> > ______________________________________________
> > R-devel <at> r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From murdoch.duncan at gmail.com  Thu May 24 14:20:23 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 24 May 2012 08:20:23 -0400
Subject: [Rd] Expected behaviour of is.unsorted?
In-Reply-To: <loom.20120524T122752-447@post.gmane.org>
References: <e1647ee6a646d7b2339189dfeffe994d.squirrel@webmail.plus.net>
	<4FBCC182.8020007@gmail.com>
	<loom.20120524T122752-447@post.gmane.org>
Message-ID: <4FBE2787.8060309@gmail.com>

On 12-05-24 7:39 AM, Matthew Dowle wrote:
> Duncan Murdoch<murdoch.duncan<at>  gmail.com>  writes:
>>
>> On 12-05-23 4:37 AM, Matthew Dowle wrote:
>>>
>>> Hi,
>>>
>>> I've read ?is.unsorted and searched. Have found a few items but nothing
>>> close, yet. Is the following expected?
>>>
>>>> is.unsorted(data.frame(1:2))
>>> [1] FALSE
>>>> is.unsorted(data.frame(2:1))
>>> [1] FALSE
>>>> is.unsorted(data.frame(1:2,3:4))
>>> [1] TRUE
>>>> is.unsorted(data.frame(2:1,4:3))
>>> [1] TRUE
>>>
>>> IIUC, is.unsorted is intended for atomic vectors only (description of x in
>>> ?is.unsorted). Indeed the C source (src/main/sort.c) contains an error
>>> message "only atomic vectors can be tested to be sorted". So that is the
>>> error message I expected to see in all cases above, since I know that
>>> data.frame is not an atomic vector. But there is also this in
>>> ?is.unsorted: "except for atomic vectors and objects with a class (where
>>> the>= or>   method is used)" which I don't understand. Where>= or>   is
>>> used by what, and where?
>>
>> If you look at the source, you will see that the basic test for classed
>> objects is
>>
>> all(x[-1L]>= x[-length(x)])
>>
>> (in the function base:::.gtn).
>>
>> This comparison doesn't really makes sense for dataframes, but it does
>> seem to be backwards:  that tests that x[2]>= x[1], x[3]>= x[2], etc.,
>> returning TRUE if all comparisons are TRUE:  but that sounds like it
>> should be is.sorted(), not is.unsorted().  Or is it my brain that is
>> backwards?
>
> Thanks. Yes you're right. So is.unsorted() on a data.frame is trying to tell us
> if there exists any unsorted row, it seems.

I would guess that it was never intended to be used this way.  It is 
intended for to test x[1] < x[2] < x[3] ... for objects where this is a 
sensible calculation; it isn't really sensible for dataframes.

>
>> DF = data.frame(a=c(1,3,5),b=c(1,3,5))
>> DF
>    a b
> 1 1 1               # this row is sorted
> 2 3 3               # this row is sorted
> 3 5 5               # this row is sorted
>> is.unsorted(DF)   # going by row but should be !.gtn
> [1] TRUE
>> with(DF,is.unsorted(order(a,b)))  # most people's natural expectation I guess
> [1] FALSE
>> DF[2,2]=2
>> DF
>    a b
> 1 1 1               # this row is sorted
> 2 3 2               # this row isn't sorted
> 3 5 5               # this row is sorted
>> is.unsorted(DF)   # going by row but should be !.gtn
> [1] FALSE
>> with(DF,is.unsorted(order(a,b)))  # most people's natural expectation I guess
> [1] FALSE
>
> Since it seems to have a bug anyway (and if so, can't be correct in anyone's
> use of it), could either is.unsorted on a data.frame return the error that's in
> the C code already: "only atomic vectors can be tested to be sorted", for
> safety and to lessen confusion, or be changed to return the natural expectation
> proposed above? The easiest quick fix would be to negate the result of the .gtn
> call of course, but then you could never go back.

I don't follow the last sentence.  If the .gtn call needs to be negated, 
why would you want to go back?

Duncan Murdoch

>
> Matthew
>
>> Duncan Murdoch
>>
>>>
>>> I understand why the first two are FALSE (1 item of anything must be
>>> sorted). I don't understand the 3rd and 4th cases where length is 2:
>>> do_isunsorted seems to call lang3(install(".gtn"), x, CADR(args))). Does
>>> that fall back to TRUE for some reason?
>>>
>>> Matthew
>>>
>>>> sessionInfo()
>>> R version 2.15.0 (2012-03-30)
>>> Platform: x86_64-pc-mingw32/x64 (64-bit)
>>>
>>> locale:
>>> [1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United
>>> Kingdom.1252
>>> [3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C
>>> [5] LC_TIME=English_United Kingdom.1252
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>> [1] data.table_1.8.0
>>>
>>> loaded via a namespace (and not attached):
>>> [1] tools_2.15.0
>>>
>>> ______________________________________________
>>> R-devel<at>  r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jon.skoien at jrc.ec.europa.eu  Thu May 24 15:00:48 2012
From: jon.skoien at jrc.ec.europa.eu (Jon Olav Skoien)
Date: Thu, 24 May 2012 15:00:48 +0200
Subject: [Rd] New S3 methods for optional package
In-Reply-To: <4FBE06FE.7010000@stats.ox.ac.uk>
References: <4FBE0178.50109@jrc.ec.europa.eu> <4FBE06FE.7010000@stats.ox.ac.uk>
Message-ID: <4FBE3100.3000802@jrc.ec.europa.eu>

Dear Prof. Ripley,
Thanks a lot for your answers!
See inline comments below.

On 24-May-12 12:01, Prof Brian Ripley wrote:
> On 24/05/2012 10:38, Jon Olav Skoien wrote:
>> I have listed A
>> under Suggests, and have a .onLoad function in B with
>> if (require(A)) registerS3methods(newMethodsMatrix, package = A, env =
>> environment(B))
>
> You are not supposed to be calling registerS3methods .... it is only 
> visible because of the nature of the base namespace and its 
> documentation says
>
> 'Not intended to be called directly.'
>
> And require() is the wrong thing here; you want to register methods on 
> a namespace.   The logic seems to be that you should do that only if 
> A's namespace is already loaded, but you could load it pre-emptively 
> with requireNamespace().

Replacing require with requireNamespace does not seem to work for this 
case, it fails with the error:
Error: object 'estimateParameters' not found whilst loading namespace 
'intamap'
This comes from registerS3methods which cannot find the generic 
estimateParameters from parent.env of B (rtop). Is this because 
loadNamespace does not attach the namespace to the search path?

>
>
>> List A under Enhances of B.
>> This seems to be the right thing, as the R extensions manual says: "the
>> 'Enhances' field lists packages "enhanced" by the package at hand, e.g.,
>> by providing methods for classes from these packages".
>> However, although it seems I can install and load package B when I
>> conditionally import package A in the NAMESPACE, R CMD check stops with
>> the error: Namespace dependency not required: A
>> If I remove the import, R CMD check is happier, but I cannot load the
>> package after installing.
>>
>> I have read about the use of "Suggest", "Enhances" etc in "Writing R
>> Extensions", but could not figure out the right way to do this. I am
>> sure there is something I am missing here.
>>
>> If anyone wants to check possible solutions, package A is "intamap",
>> available from CRAN, whereas B is "rtop", available from Rforge:
>> **|install.packages("rtop", repos="http://R-Forge.R-project.org")|**
>
> I guess the problem is that you are trying to do too much with package 
> rtop.  I would consider creating a separate package depending on 
> intamap (and most likely rtop) which adds the S3 methods for intamap.

I really hoped that would not be necessary, but you are probably right 
that it is the only solution if I want to get rid of the note. The 
disadvantage is then that I have to clutter the package repository of 
CRAN with one more package, which only purpose is to load two other 
packages. For me that does not appear as a better solution than having a 
package with a note and use of a function that is not intended. But then 
I am also not sure how much extra work my current solution would give 
the CRAN-maintainers, so if you think an extra package is better I will 
follow your advice.

Thanks,
Jon

-- 
Jon Olav Sk?ien
Joint Research Centre - European Commission
Institute for Environment and Sustainability (IES)
Land Resource Management Unit

Via Fermi 2749, TP 440,  I-21027 Ispra (VA), ITALY

jon.skoien at jrc.ec.europa.eu
Tel:  +39 0332 789206

Disclaimer: Views expressed in this email are those of the individual and do not necessarily represent official views of the European Commission.


From mdowle at mdowle.plus.com  Thu May 24 15:15:32 2012
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Thu, 24 May 2012 13:15:32 +0000
Subject: [Rd] Expected behaviour of is.unsorted?
References: <e1647ee6a646d7b2339189dfeffe994d.squirrel@webmail.plus.net>
	<4FBCC182.8020007@gmail.com>
	<loom.20120524T122752-447@post.gmane.org>
	<4FBE2787.8060309@gmail.com>
Message-ID: <loom.20120524T145457-742@post.gmane.org>

Duncan Murdoch <murdoch.duncan <at> gmail.com> writes:
> 
> On 12-05-24 7:39 AM, Matthew Dowle wrote:
> > Duncan Murdoch<murdoch.duncan<at>  gmail.com>  writes:
> >>
> >> On 12-05-23 4:37 AM, Matthew Dowle wrote:
> > Since it seems to have a bug anyway (and if so, can't be correct in anyone's
> > use of it), could either is.unsorted on a data.frame return the error 
that's in
> > the C code already: "only atomic vectors can be tested to be sorted", for
> > safety and to lessen confusion, or be changed to return the natural 
expectation
> > proposed above? The easiest quick fix would be to negate the result of 
the .gtn
> > call of course, but then you could never go back.
> 
> I don't follow the last sentence.  If the .gtn call needs to be negated, 
> why would you want to go back?

Because then is.unsorted(DF) would work, but go by row, which you guessed above 
wasn't intended and isn't sensible. But once it worked in that way, users might 
start to depend on it; e.g., by writing is.unsorted(t(DF)). If I came 
along in future and suggested that was inefficient and wouldn't it be more 
natural and efficient if is.unsorted(DF) went by column, returning the same as 
with(DF,is.unsorted(order(a,b))) but implemented efficiently, you would fear 
that user code now depended on it going by row and say it was too late. I'd 
persist and highlight that it didn't seem in keeping with the spirit of 
is.unsorted()'s speed since it short circuits on the first unsorted item, which 
is why we love it. You'd reply that's not documented. Which it isn't. And that 
would be the end of that.

> Duncan Murdoch
> 
> >
> > Matthew
> >
> >> Duncan Murdoch
> >>
> >>>
> >>> I understand why the first two are FALSE (1 item of anything must be
> >>> sorted). I don't understand the 3rd and 4th cases where length is 2:
> >>> do_isunsorted seems to call lang3(install(".gtn"), x, CADR(args))). Does
> >>> that fall back to TRUE for some reason?
> >>>
> >>> Matthew
> >>>
> >>>> sessionInfo()
> >>> R version 2.15.0 (2012-03-30)
> >>> Platform: x86_64-pc-mingw32/x64 (64-bit)
> >>>
> >>> locale:
> >>> [1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United
> >>> Kingdom.1252
> >>> [3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C
> >>> [5] LC_TIME=English_United Kingdom.1252
> >>>
> >>> attached base packages:
> >>> [1] stats     graphics  grDevices utils     datasets  methods   base
> >>>
> >>> other attached packages:
> >>> [1] data.table_1.8.0
> >>>
> >>> loaded via a namespace (and not attached):
> >>> [1] tools_2.15.0
> >>>
> >>> ______________________________________________
> >>> R-devel<at>  r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >>
> >
> > ______________________________________________
> > R-devel <at> r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From murdoch.duncan at gmail.com  Thu May 24 15:57:29 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 24 May 2012 09:57:29 -0400
Subject: [Rd] Expected behaviour of is.unsorted?
In-Reply-To: <loom.20120524T145457-742@post.gmane.org>
References: <e1647ee6a646d7b2339189dfeffe994d.squirrel@webmail.plus.net>
	<4FBCC182.8020007@gmail.com>
	<loom.20120524T122752-447@post.gmane.org>
	<4FBE2787.8060309@gmail.com>
	<loom.20120524T145457-742@post.gmane.org>
Message-ID: <4FBE3E49.3050303@gmail.com>

On 24/05/2012 9:15 AM, Matthew Dowle wrote:
> Duncan Murdoch<murdoch.duncan<at>  gmail.com>  writes:
> >
> >  On 12-05-24 7:39 AM, Matthew Dowle wrote:
> >  >  Duncan Murdoch<murdoch.duncan<at>   gmail.com>   writes:
> >  >>
> >  >>  On 12-05-23 4:37 AM, Matthew Dowle wrote:
> >  >  Since it seems to have a bug anyway (and if so, can't be correct in anyone's
> >  >  use of it), could either is.unsorted on a data.frame return the error
> that's in
> >  >  the C code already: "only atomic vectors can be tested to be sorted", for
> >  >  safety and to lessen confusion, or be changed to return the natural
> expectation
> >  >  proposed above? The easiest quick fix would be to negate the result of
> the .gtn
> >  >  call of course, but then you could never go back.
> >
> >  I don't follow the last sentence.  If the .gtn call needs to be negated,
> >  why would you want to go back?
>
> Because then is.unsorted(DF) would work, but go by row, which you guessed above
> wasn't intended and isn't sensible. But once it worked in that way, users might
> start to depend on it; e.g., by writing is.unsorted(t(DF)). If I came
> along in future and suggested that was inefficient and wouldn't it be more
> natural and efficient if is.unsorted(DF) went by column, returning the same as
> with(DF,is.unsorted(order(a,b))) but implemented efficiently, you would fear
> that user code now depended on it going by row and say it was too late. I'd
> persist and highlight that it didn't seem in keeping with the spirit of
> is.unsorted()'s speed since it short circuits on the first unsorted item, which
> is why we love it. You'd reply that's not documented. Which it isn't. And that
> would be the end of that.

Okay, I'm going to fix the handling of .gtn results, and document the 
unsuitability of this
function for dataframes and arrays.

Duncan Murdoch

>
> >  Duncan Murdoch
> >
> >  >
> >  >  Matthew
> >  >
> >  >>  Duncan Murdoch
> >  >>
> >  >>>
> >  >>>  I understand why the first two are FALSE (1 item of anything must be
> >  >>>  sorted). I don't understand the 3rd and 4th cases where length is 2:
> >  >>>  do_isunsorted seems to call lang3(install(".gtn"), x, CADR(args))). Does
> >  >>>  that fall back to TRUE for some reason?
> >  >>>
> >  >>>  Matthew
> >  >>>
> >  >>>>  sessionInfo()
> >  >>>  R version 2.15.0 (2012-03-30)
> >  >>>  Platform: x86_64-pc-mingw32/x64 (64-bit)
> >  >>>
> >  >>>  locale:
> >  >>>  [1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United
> >  >>>  Kingdom.1252
> >  >>>  [3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C
> >  >>>  [5] LC_TIME=English_United Kingdom.1252
> >  >>>
> >  >>>  attached base packages:
> >  >>>  [1] stats     graphics  grDevices utils     datasets  methods   base
> >  >>>
> >  >>>  other attached packages:
> >  >>>  [1] data.table_1.8.0
> >  >>>
> >  >>>  loaded via a namespace (and not attached):
> >  >>>  [1] tools_2.15.0
> >  >>>
> >  >>>  ______________________________________________
> >  >>>  R-devel<at>   r-project.org mailing list
> >  >>>  https://stat.ethz.ch/mailman/listinfo/r-devel
> >  >>
> >  >>
> >  >
> >  >  ______________________________________________
> >  >  R-devel<at>  r-project.org mailing list
> >  >  https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From mdowle at mdowle.plus.com  Thu May 24 17:10:07 2012
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Thu, 24 May 2012 16:10:07 +0100
Subject: [Rd] Expected behaviour of is.unsorted?
In-Reply-To: <4FBE3E49.3050303@gmail.com>
References: <e1647ee6a646d7b2339189dfeffe994d.squirrel@webmail.plus.net>
	<4FBCC182.8020007@gmail.com> <loom.20120524T122752-447@post.gmane.org>
	<4FBE2787.8060309@gmail.com> <loom.20120524T145457-742@post.gmane.org>
	<4FBE3E49.3050303@gmail.com>
Message-ID: <b3232ea9721b0446dcad1d6f60a57f85.squirrel@webmail.plus.net>

> On 24/05/2012 9:15 AM, Matthew Dowle wrote:
>> Duncan Murdoch<murdoch.duncan<at>  gmail.com>  writes:
>> >
>> >  On 12-05-24 7:39 AM, Matthew Dowle wrote:
>> >  >  Duncan Murdoch<murdoch.duncan<at>   gmail.com>   writes:
>> >  >>
>> >  >>  On 12-05-23 4:37 AM, Matthew Dowle wrote:
>> >  >  Since it seems to have a bug anyway (and if so, can't be correct
>> in anyone's
>> >  >  use of it), could either is.unsorted on a data.frame return the
>> error
>> that's in
>> >  >  the C code already: "only atomic vectors can be tested to be
>> sorted", for
>> >  >  safety and to lessen confusion, or be changed to return the
>> natural
>> expectation
>> >  >  proposed above? The easiest quick fix would be to negate the
>> result of
>> the .gtn
>> >  >  call of course, but then you could never go back.
>> >
>> >  I don't follow the last sentence.  If the .gtn call needs to be
>> negated,
>> >  why would you want to go back?
>>
>> Because then is.unsorted(DF) would work, but go by row, which you
>> guessed above
>> wasn't intended and isn't sensible. But once it worked in that way,
>> users might
>> start to depend on it; e.g., by writing is.unsorted(t(DF)). If I came
>> along in future and suggested that was inefficient and wouldn't it be
>> more
>> natural and efficient if is.unsorted(DF) went by column, returning the
>> same as
>> with(DF,is.unsorted(order(a,b))) but implemented efficiently, you would
>> fear
>> that user code now depended on it going by row and say it was too late.
>> I'd
>> persist and highlight that it didn't seem in keeping with the spirit of
>> is.unsorted()'s speed since it short circuits on the first unsorted
>> item, which
>> is why we love it. You'd reply that's not documented. Which it isn't.
>> And that
>> would be the end of that.
>
> Okay, I'm going to fix the handling of .gtn results, and document the
> unsuitability of this
> function for dataframes and arrays.

But that leaves the door open to confusion later, whilst closing the door
to a better solution: making is.unsorted() work by column for data.frame;
i.e., making is.unsorted _suitable_ for data.frame. If you just do the
quick fix for .gtn result you can never go back. If making is.unsorted(DF)
work by column is too hard for now, then leaving the door open would be
better by returning the error message already in the C code: "only atomic
vectors can be tested to be sorted". That would be a better quick fix
since it leaves options for the future.

> Duncan Murdoch
>
>>
>> >  Duncan Murdoch
>> >
>> >  >
>> >  >  Matthew
>> >  >
>> >  >>  Duncan Murdoch
>> >  >>
>> >  >>>
>> >  >>>  I understand why the first two are FALSE (1 item of anything
>> must be
>> >  >>>  sorted). I don't understand the 3rd and 4th cases where length
>> is 2:
>> >  >>>  do_isunsorted seems to call lang3(install(".gtn"), x,
>> CADR(args))). Does
>> >  >>>  that fall back to TRUE for some reason?
>> >  >>>
>> >  >>>  Matthew
>> >  >>>
>> >  >>>>  sessionInfo()
>> >  >>>  R version 2.15.0 (2012-03-30)
>> >  >>>  Platform: x86_64-pc-mingw32/x64 (64-bit)
>> >  >>>
>> >  >>>  locale:
>> >  >>>  [1] LC_COLLATE=English_United Kingdom.1252
>> LC_CTYPE=English_United
>> >  >>>  Kingdom.1252
>> >  >>>  [3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C
>> >  >>>  [5] LC_TIME=English_United Kingdom.1252
>> >  >>>
>> >  >>>  attached base packages:
>> >  >>>  [1] stats     graphics  grDevices utils     datasets  methods
>> base
>> >  >>>
>> >  >>>  other attached packages:
>> >  >>>  [1] data.table_1.8.0
>> >  >>>
>> >  >>>  loaded via a namespace (and not attached):
>> >  >>>  [1] tools_2.15.0
>> >  >>>
>> >  >>>  ______________________________________________
>> >  >>>  R-devel<at>   r-project.org mailing list
>> >  >>>  https://stat.ethz.ch/mailman/listinfo/r-devel
>> >  >>
>> >  >>
>> >  >
>> >  >  ______________________________________________
>> >  >  R-devel<at>  r-project.org mailing list
>> >  >  https://stat.ethz.ch/mailman/listinfo/r-devel
>> >
>> >
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From murdoch.duncan at gmail.com  Thu May 24 17:25:33 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 24 May 2012 11:25:33 -0400
Subject: [Rd] Expected behaviour of is.unsorted?
In-Reply-To: <b3232ea9721b0446dcad1d6f60a57f85.squirrel@webmail.plus.net>
References: <e1647ee6a646d7b2339189dfeffe994d.squirrel@webmail.plus.net>
	<4FBCC182.8020007@gmail.com>
	<loom.20120524T122752-447@post.gmane.org>
	<4FBE2787.8060309@gmail.com>
	<loom.20120524T145457-742@post.gmane.org>
	<4FBE3E49.3050303@gmail.com>
	<b3232ea9721b0446dcad1d6f60a57f85.squirrel@webmail.plus.net>
Message-ID: <4FBE52ED.5010807@gmail.com>

On 24/05/2012 11:10 AM, Matthew Dowle wrote:
> >  On 24/05/2012 9:15 AM, Matthew Dowle wrote:
> >>  Duncan Murdoch<murdoch.duncan<at>   gmail.com>   writes:
> >>  >
> >>  >   On 12-05-24 7:39 AM, Matthew Dowle wrote:
> >>  >   >   Duncan Murdoch<murdoch.duncan<at>    gmail.com>    writes:
> >>  >   >>
> >>  >   >>   On 12-05-23 4:37 AM, Matthew Dowle wrote:
> >>  >   >   Since it seems to have a bug anyway (and if so, can't be correct
> >>  in anyone's
> >>  >   >   use of it), could either is.unsorted on a data.frame return the
> >>  error
> >>  that's in
> >>  >   >   the C code already: "only atomic vectors can be tested to be
> >>  sorted", for
> >>  >   >   safety and to lessen confusion, or be changed to return the
> >>  natural
> >>  expectation
> >>  >   >   proposed above? The easiest quick fix would be to negate the
> >>  result of
> >>  the .gtn
> >>  >   >   call of course, but then you could never go back.
> >>  >
> >>  >   I don't follow the last sentence.  If the .gtn call needs to be
> >>  negated,
> >>  >   why would you want to go back?
> >>
> >>  Because then is.unsorted(DF) would work, but go by row, which you
> >>  guessed above
> >>  wasn't intended and isn't sensible. But once it worked in that way,
> >>  users might
> >>  start to depend on it; e.g., by writing is.unsorted(t(DF)). If I came
> >>  along in future and suggested that was inefficient and wouldn't it be
> >>  more
> >>  natural and efficient if is.unsorted(DF) went by column, returning the
> >>  same as
> >>  with(DF,is.unsorted(order(a,b))) but implemented efficiently, you would
> >>  fear
> >>  that user code now depended on it going by row and say it was too late.
> >>  I'd
> >>  persist and highlight that it didn't seem in keeping with the spirit of
> >>  is.unsorted()'s speed since it short circuits on the first unsorted
> >>  item, which
> >>  is why we love it. You'd reply that's not documented. Which it isn't.
> >>  And that
> >>  would be the end of that.
> >
> >  Okay, I'm going to fix the handling of .gtn results, and document the
> >  unsuitability of this
> >  function for dataframes and arrays.
>
> But that leaves the door open to confusion later, whilst closing the door
> to a better solution: making is.unsorted() work by column for data.frame;
> i.e., making is.unsorted _suitable_ for data.frame. If you just do the
> quick fix for .gtn result you can never go back. If making is.unsorted(DF)
> work by column is too hard for now, then leaving the door open would be
> better by returning the error message already in the C code: "only atomic
> vectors can be tested to be sorted". That would be a better quick fix
> since it leaves options for the future.

I don't see why saying this function is unsuitable for dataframes 
implies that it will never be made suitable for dataframes.

The fix handles the case is.unsorted was designed for:  it checks 
whether x[1] < x[2] < x[3] etc., which it doesn't currently do properly 
for non-atomic objects.

Duncan Murdoch
>
> >  Duncan Murdoch
> >
> >>
> >>  >   Duncan Murdoch
> >>  >
> >>  >   >
> >>  >   >   Matthew
> >>  >   >
> >>  >   >>   Duncan Murdoch
> >>  >   >>
> >>  >   >>>
> >>  >   >>>   I understand why the first two are FALSE (1 item of anything
> >>  must be
> >>  >   >>>   sorted). I don't understand the 3rd and 4th cases where length
> >>  is 2:
> >>  >   >>>   do_isunsorted seems to call lang3(install(".gtn"), x,
> >>  CADR(args))). Does
> >>  >   >>>   that fall back to TRUE for some reason?
> >>  >   >>>
> >>  >   >>>   Matthew
> >>  >   >>>
> >>  >   >>>>   sessionInfo()
> >>  >   >>>   R version 2.15.0 (2012-03-30)
> >>  >   >>>   Platform: x86_64-pc-mingw32/x64 (64-bit)
> >>  >   >>>
> >>  >   >>>   locale:
> >>  >   >>>   [1] LC_COLLATE=English_United Kingdom.1252
> >>  LC_CTYPE=English_United
> >>  >   >>>   Kingdom.1252
> >>  >   >>>   [3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C
> >>  >   >>>   [5] LC_TIME=English_United Kingdom.1252
> >>  >   >>>
> >>  >   >>>   attached base packages:
> >>  >   >>>   [1] stats     graphics  grDevices utils     datasets  methods
> >>  base
> >>  >   >>>
> >>  >   >>>   other attached packages:
> >>  >   >>>   [1] data.table_1.8.0
> >>  >   >>>
> >>  >   >>>   loaded via a namespace (and not attached):
> >>  >   >>>   [1] tools_2.15.0
> >>  >   >>>
> >>  >   >>>   ______________________________________________
> >>  >   >>>   R-devel<at>    r-project.org mailing list
> >>  >   >>>   https://stat.ethz.ch/mailman/listinfo/r-devel
> >>  >   >>
> >>  >   >>
> >>  >   >
> >>  >   >   ______________________________________________
> >>  >   >   R-devel<at>   r-project.org mailing list
> >>  >   >   https://stat.ethz.ch/mailman/listinfo/r-devel
> >>  >
> >>  >
> >>
> >>  ______________________________________________
> >>  R-devel at r-project.org mailing list
> >>  https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
>
>


From deter088 at umn.edu  Thu May 24 18:25:41 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Thu, 24 May 2012 11:25:41 -0500
Subject: [Rd] modifying some package code
Message-ID: <CAOLJphnqTt-Dut24cShJ4iZQ5NwAy1WkmL9bKSn7dm3yEDmc_w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120524/60ed8013/attachment.pl>

From simon.urbanek at r-project.org  Thu May 24 18:58:15 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 24 May 2012 12:58:15 -0400
Subject: [Rd] modifying some package code
In-Reply-To: <CAOLJphnqTt-Dut24cShJ4iZQ5NwAy1WkmL9bKSn7dm3yEDmc_w@mail.gmail.com>
References: <CAOLJphnqTt-Dut24cShJ4iZQ5NwAy1WkmL9bKSn7dm3yEDmc_w@mail.gmail.com>
Message-ID: <60EE8CD6-1214-47D8-ADF3-3E6B5F125C2A@r-project.org>


On May 24, 2012, at 12:25 PM, Charles Determan Jr wrote:

> Greetings,
> 
> I am working on modifying some code from the nlme package.  I have had many
> discussions on the mixed models mailing list and have been directed to
> simply 'hack' the source code to have the degrees of freedom generated by
> one function to use in the output of another function that doesn't generate
> them.  My current holdup is an error regarding a .c file called
> 'inner_perc_table' called by the .C function.  The error states that the
> object 'inner_perc_table' is not found.  My confusion lies in the fact that
> when I run the original script, it recognizes the part just fine.  At no
> point is the object defined and I cannot currently find such a code in the
> package's source.  Perhaps someone here is familiar with the nlme package
> and could assist me in some form.  If you need further information, please
> ask as I don't know if there is a general answer for this type of question
> or if you will need the actual code.
> 

The (unexported) object contains cached reference to the native function (see ?getNativeSymbolInfo) and is defined by R_registerRoutines in src/init.c. This is a typical optimization in R packages to avoid costly lookup of symbols and to provide check for native arguments.

Cheers,
Simon


From deter088 at umn.edu  Thu May 24 19:26:30 2012
From: deter088 at umn.edu (Charles Determan Jr)
Date: Thu, 24 May 2012 12:26:30 -0500
Subject: [Rd] modifying some package code
In-Reply-To: <60EE8CD6-1214-47D8-ADF3-3E6B5F125C2A@r-project.org>
References: <CAOLJphnqTt-Dut24cShJ4iZQ5NwAy1WkmL9bKSn7dm3yEDmc_w@mail.gmail.com>
	<60EE8CD6-1214-47D8-ADF3-3E6B5F125C2A@r-project.org>
Message-ID: <CAOLJphmC+xL2MPL1rt9gM_+S6WQ9uyRUTorraifgnXHh7QR7wQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120524/6dd70f9b/attachment.pl>

From mdowle at mdowle.plus.com  Thu May 24 19:33:04 2012
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Thu, 24 May 2012 18:33:04 +0100
Subject: [Rd] Expected behaviour of is.unsorted?
In-Reply-To: <4FBE52ED.5010807@gmail.com>
References: <e1647ee6a646d7b2339189dfeffe994d.squirrel@webmail.plus.net>
	<4FBCC182.8020007@gmail.com> <loom.20120524T122752-447@post.gmane.org>
	<4FBE2787.8060309@gmail.com> <loom.20120524T145457-742@post.gmane.org>
	<4FBE3E49.3050303@gmail.com>
	<b3232ea9721b0446dcad1d6f60a57f85.squirrel@webmail.plus.net>
	<4FBE52ED.5010807@gmail.com>
Message-ID: <6081304928f51b416f978fb62eab6aea.squirrel@webmail.plus.net>

> On 24/05/2012 11:10 AM, Matthew Dowle wrote:
>> >  On 24/05/2012 9:15 AM, Matthew Dowle wrote:
>> >>  Duncan Murdoch<murdoch.duncan<at>   gmail.com>   writes:
>> >>  >
>> >>  >   On 12-05-24 7:39 AM, Matthew Dowle wrote:
>> >>  >   >   Duncan Murdoch<murdoch.duncan<at>    gmail.com>    writes:
>> >>  >   >>
>> >>  >   >>   On 12-05-23 4:37 AM, Matthew Dowle wrote:
>> >>  >   >   Since it seems to have a bug anyway (and if so, can't be
>> correct
>> >>  in anyone's
>> >>  >   >   use of it), could either is.unsorted on a data.frame return
>> the
>> >>  error
>> >>  that's in
>> >>  >   >   the C code already: "only atomic vectors can be tested to be
>> >>  sorted", for
>> >>  >   >   safety and to lessen confusion, or be changed to return the
>> >>  natural
>> >>  expectation
>> >>  >   >   proposed above? The easiest quick fix would be to negate the
>> >>  result of
>> >>  the .gtn
>> >>  >   >   call of course, but then you could never go back.
>> >>  >
>> >>  >   I don't follow the last sentence.  If the .gtn call needs to be
>> >>  negated,
>> >>  >   why would you want to go back?
>> >>
>> >>  Because then is.unsorted(DF) would work, but go by row, which you
>> >>  guessed above
>> >>  wasn't intended and isn't sensible. But once it worked in that way,
>> >>  users might
>> >>  start to depend on it; e.g., by writing is.unsorted(t(DF)). If I
>> came
>> >>  along in future and suggested that was inefficient and wouldn't it
>> be
>> >>  more
>> >>  natural and efficient if is.unsorted(DF) went by column, returning
>> the
>> >>  same as
>> >>  with(DF,is.unsorted(order(a,b))) but implemented efficiently, you
>> would
>> >>  fear
>> >>  that user code now depended on it going by row and say it was too
>> late.
>> >>  I'd
>> >>  persist and highlight that it didn't seem in keeping with the spirit
>> of
>> >>  is.unsorted()'s speed since it short circuits on the first unsorted
>> >>  item, which
>> >>  is why we love it. You'd reply that's not documented. Which it
>> isn't.
>> >>  And that
>> >>  would be the end of that.
>> >
>> >  Okay, I'm going to fix the handling of .gtn results, and document the
>> >  unsuitability of this
>> >  function for dataframes and arrays.
>>
>> But that leaves the door open to confusion later, whilst closing the
>> door
>> to a better solution: making is.unsorted() work by column for
>> data.frame;
>> i.e., making is.unsorted _suitable_ for data.frame. If you just do the
>> quick fix for .gtn result you can never go back. If making
>> is.unsorted(DF)
>> work by column is too hard for now, then leaving the door open would be
>> better by returning the error message already in the C code: "only
>> atomic
>> vectors can be tested to be sorted". That would be a better quick fix
>> since it leaves options for the future.
>
> I don't see why saying this function is unsuitable for dataframes
> implies that it will never be made suitable for dataframes.

If user code or packages start to depend on is.unsorted(t(DF)) it would be
harder to change, no? Why provide something that is unsuitable and allow
that possibility to happen? It's more user friendly to return "not
implemented", "unsuitable", or the nicer message already in the C code,
than leave the door open for confusion and errors. Or in other words, it's
even more user friendly to return a warning or error to the user at the
prompt, than the user friendliness of writing in the help file that it's
unsuitable for data.frame.

Matthew


From simon.urbanek at r-project.org  Thu May 24 20:14:08 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 24 May 2012 14:14:08 -0400
Subject: [Rd] modifying some package code
In-Reply-To: <CAOLJphmC+xL2MPL1rt9gM_+S6WQ9uyRUTorraifgnXHh7QR7wQ@mail.gmail.com>
References: <CAOLJphnqTt-Dut24cShJ4iZQ5NwAy1WkmL9bKSn7dm3yEDmc_w@mail.gmail.com>
	<60EE8CD6-1214-47D8-ADF3-3E6B5F125C2A@r-project.org>
	<CAOLJphmC+xL2MPL1rt9gM_+S6WQ9uyRUTorraifgnXHh7QR7wQ@mail.gmail.com>
Message-ID: <499C64C3-9D55-46E2-ACB2-07C3CD929037@r-project.org>

On May 24, 2012, at 1:26 PM, Charles Determan Jr wrote:

> Simon,
> 
> Thank you for this valuable information.  However, you must forgive some ignorance on my part.  If R-registerRoutines defines the native function, how should I go about fixing this issue?  Would I copy the init.c to the base package (where I have the new function)?
> 

I'm not sure what *is* your issue. nlms:::inner_perc_table is defined (automatically), so it just works. If you are re-using just the .C part of nlme somewhere else that you dyn-load manually then you can simply use "inner_perc_table" instead.

Cheers,
Simon


> On Thu, May 24, 2012 at 11:58 AM, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> 
> On May 24, 2012, at 12:25 PM, Charles Determan Jr wrote:
> 
> > Greetings,
> >
> > I am working on modifying some code from the nlme package.  I have had many
> > discussions on the mixed models mailing list and have been directed to
> > simply 'hack' the source code to have the degrees of freedom generated by
> > one function to use in the output of another function that doesn't generate
> > them.  My current holdup is an error regarding a .c file called
> > 'inner_perc_table' called by the .C function.  The error states that the
> > object 'inner_perc_table' is not found.  My confusion lies in the fact that
> > when I run the original script, it recognizes the part just fine.  At no
> > point is the object defined and I cannot currently find such a code in the
> > package's source.  Perhaps someone here is familiar with the nlme package
> > and could assist me in some form.  If you need further information, please
> > ask as I don't know if there is a general answer for this type of question
> > or if you will need the actual code.
> >
> 
> The (unexported) object contains cached reference to the native function (see ?getNativeSymbolInfo) and is defined by R_registerRoutines in src/init.c. This is a typical optimization in R packages to avoid costly lookup of symbols and to provide check for native arguments.
> 
> Cheers,
> Simon
> 
> 
> 
> 


From murdoch.duncan at gmail.com  Thu May 24 20:42:52 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 24 May 2012 14:42:52 -0400
Subject: [Rd] Expected behaviour of is.unsorted?
In-Reply-To: <6081304928f51b416f978fb62eab6aea.squirrel@webmail.plus.net>
References: <e1647ee6a646d7b2339189dfeffe994d.squirrel@webmail.plus.net>
	<4FBCC182.8020007@gmail.com>
	<loom.20120524T122752-447@post.gmane.org>
	<4FBE2787.8060309@gmail.com>
	<loom.20120524T145457-742@post.gmane.org>
	<4FBE3E49.3050303@gmail.com>
	<b3232ea9721b0446dcad1d6f60a57f85.squirrel@webmail.plus.net>
	<4FBE52ED.5010807@gmail.com>
	<6081304928f51b416f978fb62eab6aea.squirrel@webmail.plus.net>
Message-ID: <4FBE812C.50504@gmail.com>

On 24/05/2012 1:33 PM, Matthew Dowle wrote:
> >  On 24/05/2012 11:10 AM, Matthew Dowle wrote:
> >>  >   On 24/05/2012 9:15 AM, Matthew Dowle wrote:
> >>  >>   Duncan Murdoch<murdoch.duncan<at>    gmail.com>    writes:
> >>  >>   >
> >>  >>   >    On 12-05-24 7:39 AM, Matthew Dowle wrote:
> >>  >>   >    >    Duncan Murdoch<murdoch.duncan<at>     gmail.com>     writes:
> >>  >>   >    >>
> >>  >>   >    >>    On 12-05-23 4:37 AM, Matthew Dowle wrote:
> >>  >>   >    >    Since it seems to have a bug anyway (and if so, can't be
> >>  correct
> >>  >>   in anyone's
> >>  >>   >    >    use of it), could either is.unsorted on a data.frame return
> >>  the
> >>  >>   error
> >>  >>   that's in
> >>  >>   >    >    the C code already: "only atomic vectors can be tested to be
> >>  >>   sorted", for
> >>  >>   >    >    safety and to lessen confusion, or be changed to return the
> >>  >>   natural
> >>  >>   expectation
> >>  >>   >    >    proposed above? The easiest quick fix would be to negate the
> >>  >>   result of
> >>  >>   the .gtn
> >>  >>   >    >    call of course, but then you could never go back.
> >>  >>   >
> >>  >>   >    I don't follow the last sentence.  If the .gtn call needs to be
> >>  >>   negated,
> >>  >>   >    why would you want to go back?
> >>  >>
> >>  >>   Because then is.unsorted(DF) would work, but go by row, which you
> >>  >>   guessed above
> >>  >>   wasn't intended and isn't sensible. But once it worked in that way,
> >>  >>   users might
> >>  >>   start to depend on it; e.g., by writing is.unsorted(t(DF)). If I
> >>  came
> >>  >>   along in future and suggested that was inefficient and wouldn't it
> >>  be
> >>  >>   more
> >>  >>   natural and efficient if is.unsorted(DF) went by column, returning
> >>  the
> >>  >>   same as
> >>  >>   with(DF,is.unsorted(order(a,b))) but implemented efficiently, you
> >>  would
> >>  >>   fear
> >>  >>   that user code now depended on it going by row and say it was too
> >>  late.
> >>  >>   I'd
> >>  >>   persist and highlight that it didn't seem in keeping with the spirit
> >>  of
> >>  >>   is.unsorted()'s speed since it short circuits on the first unsorted
> >>  >>   item, which
> >>  >>   is why we love it. You'd reply that's not documented. Which it
> >>  isn't.
> >>  >>   And that
> >>  >>   would be the end of that.
> >>  >
> >>  >   Okay, I'm going to fix the handling of .gtn results, and document the
> >>  >   unsuitability of this
> >>  >   function for dataframes and arrays.
> >>
> >>  But that leaves the door open to confusion later, whilst closing the
> >>  door
> >>  to a better solution: making is.unsorted() work by column for
> >>  data.frame;
> >>  i.e., making is.unsorted _suitable_ for data.frame. If you just do the
> >>  quick fix for .gtn result you can never go back. If making
> >>  is.unsorted(DF)
> >>  work by column is too hard for now, then leaving the door open would be
> >>  better by returning the error message already in the C code: "only
> >>  atomic
> >>  vectors can be tested to be sorted". That would be a better quick fix
> >>  since it leaves options for the future.
> >
> >  I don't see why saying this function is unsuitable for dataframes
> >  implies that it will never be made suitable for dataframes.
>
> If user code or packages start to depend on is.unsorted(t(DF)) it would be
> harder to change, no?

I don't see why.  t(DF) is not a dataframe, so it will give surprising 
answers in a different way.  If people rely on using code in ways that 
are documented to give unexpected results, they deserve what they get.
>   Why provide something that is unsuitable and allow
> that possibility to happen? It's more user friendly to return "not
> implemented", "unsuitable", or the nicer message already in the C code,
> than leave the door open for confusion and errors. Or in other words, it's
> even more user friendly to return a warning or error to the user at the
> prompt, than the user friendliness of writing in the help file that it's
> unsuitable for data.frame.

I disagree.  I think it is most friendly to implement the function in 
the way it has been documented (even if it hasn't always been behaving 
as documented).

Duncan Murdoch


From hankin.robin at gmail.com  Fri May 25 06:25:30 2012
From: hankin.robin at gmail.com (robin hankin)
Date: Fri, 25 May 2012 16:25:30 +1200
Subject: [Rd] columnames changes behaviour of formula
Message-ID: <CAHHjBM7u86wbiuO-uBje8si5NiEbj=WzktCK9MmtFEthaS374g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120525/10d734ea/attachment.pl>

From jwiley.psych at gmail.com  Fri May 25 06:46:46 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Thu, 24 May 2012 21:46:46 -0700
Subject: [Rd] columnames changes behaviour of formula
In-Reply-To: <CAHHjBM7u86wbiuO-uBje8si5NiEbj=WzktCK9MmtFEthaS374g@mail.gmail.com>
References: <CAHHjBM7u86wbiuO-uBje8si5NiEbj=WzktCK9MmtFEthaS374g@mail.gmail.com>
Message-ID: <CANz9Z_+A8xJNdLHhh=1qN_QXAvhqy00s6cSPq+Knog-YSbd-EQ@mail.gmail.com>

Hi Robin,

Seems like the intended behavior to me.  From the docs:
"There are two special interpretations of '.' in a formula.  The usual
one is in the context of a 'data' argument of model fitting functions
and means 'all columns not otherwise in the formula' "

d is in the formula so the only column not in the formula is nd.  the
(.)^2 asks for all two way interactions, but with only one variable,
there are none.

What were you expecting?

Josh

On Thu, May 24, 2012 at 9:25 PM, robin hankin <hankin.robin at gmail.com> wrote:
> Hello. precompiled R-2.15.0, svn58871, macosx 10.7.4.
>
>
> I have discovered that defining column names of a dataframe can alter the
> behaviour of lm():
>
>
> d <- c(4,7,6,4)
> x <- data.frame(cbind(0:3,5:2))
> coef(lm(d~ -1 + (.)^2,data=x))
> ? X1 ? ?X2 X1:X2
> -1.77 ?0.83 ?1.25
> R>
> R>
>
>
> OK, so far so good. ?But change the column names of 'x' and the behaviour
> changes:
>
>
> colnames(x) <- c("d","nd") ? # 'd' == 'death' and 'nd' == 'no death'
> coef(lm(d~ -1 + (.)^2,data=x))
> ? ? ? nd
> 0.2962963
>
>
>
> I am not sure if this is consistent with the special meaning of '.'
> described under ?formula.
>
> Is this the intended behaviour?
>
>
> --
> Robin Hankin
> Uncertainty Analyst
> hankin.robin at gmail.com
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From jwiley.psych at gmail.com  Fri May 25 06:52:07 2012
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Thu, 24 May 2012 21:52:07 -0700
Subject: [Rd] columnames changes behaviour of formula
In-Reply-To: <CANz9Z_+A8xJNdLHhh=1qN_QXAvhqy00s6cSPq+Knog-YSbd-EQ@mail.gmail.com>
References: <CAHHjBM7u86wbiuO-uBje8si5NiEbj=WzktCK9MmtFEthaS374g@mail.gmail.com>
	<CANz9Z_+A8xJNdLHhh=1qN_QXAvhqy00s6cSPq+Knog-YSbd-EQ@mail.gmail.com>
Message-ID: <CANz9Z_JMt6JF_0LNQGbbuaSCB-ocWVvDpB36U6Za+2zTbAJsWg@mail.gmail.com>

P.S. It really is sloppy code to mix variables from the global
environment with those inside a data frame. I.e.:

coef(lm(d ~ -1 + (.)^2, data = x))

the only time I think it makes sense to have different objects for the
outcome and predictors are when for speed purposes, you are using a
low level function, such as lm.fit or fastLmPure from the RcppEigen
package.


On Thu, May 24, 2012 at 9:46 PM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
> Hi Robin,
>
> Seems like the intended behavior to me. ?From the docs:
> "There are two special interpretations of '.' in a formula. ?The usual
> one is in the context of a 'data' argument of model fitting functions
> and means 'all columns not otherwise in the formula' "
>
> d is in the formula so the only column not in the formula is nd. ?the
> (.)^2 asks for all two way interactions, but with only one variable,
> there are none.
>
> What were you expecting?
>
> Josh
>
> On Thu, May 24, 2012 at 9:25 PM, robin hankin <hankin.robin at gmail.com> wrote:
>> Hello. precompiled R-2.15.0, svn58871, macosx 10.7.4.
>>
>>
>> I have discovered that defining column names of a dataframe can alter the
>> behaviour of lm():
>>
>>
>> d <- c(4,7,6,4)
>> x <- data.frame(cbind(0:3,5:2))
>> coef(lm(d~ -1 + (.)^2,data=x))
>> ? X1 ? ?X2 X1:X2
>> -1.77 ?0.83 ?1.25
>> R>
>> R>
>>
>>
>> OK, so far so good. ?But change the column names of 'x' and the behaviour
>> changes:
>>
>>
>> colnames(x) <- c("d","nd") ? # 'd' == 'death' and 'nd' == 'no death'
>> coef(lm(d~ -1 + (.)^2,data=x))
>> ? ? ? nd
>> 0.2962963
>>
>>
>>
>> I am not sure if this is consistent with the special meaning of '.'
>> described under ?formula.
>>
>> Is this the intended behaviour?
>>
>>
>> --
>> Robin Hankin
>> Uncertainty Analyst
>> hankin.robin at gmail.com
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
> --
> Joshua Wiley
> Ph.D. Student, Health Psychology
> Programmer Analyst II, Statistical Consulting Group
> University of California, Los Angeles
> https://joshuawiley.com/



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From hadley at rice.edu  Fri May 25 15:49:28 2012
From: hadley at rice.edu (Hadley Wickham)
Date: Fri, 25 May 2012 06:49:28 -0700
Subject: [Rd] Curry: proposed new functional programming, er, function.
In-Reply-To: <1337802805327-4631127.post@n4.nabble.com>
References: <7098abec0711011200va3851o811f60bb100616ce@mail.gmail.com>
	<BANLkTi=jud5hhis5y-veQKZHzSYYoPqnBw@mail.gmail.com>
	<79F23BA7BB084E4FA01A8B93904CD02CF669FAA4C9@WIGGUMVS.win.ad.jhu.edu>
	<4DC16917.5090206@gmail.com>
	<BANLkTikuy3OP8j5aymKuE_zmHtYLCkBZWg@mail.gmail.com>
	<79F23BA7BB084E4FA01A8B93904CD02CF669FAA4D7@WIGGUMVS.win.ad.jhu.edu>
	<BANLkTikvfsyZaW4wDB8sA-Z7G-rMQ+11Tg@mail.gmail.com>
	<BANLkTikGcviLYfFska4vkf5GpuCpmKTdJw@mail.gmail.com>
	<BANLkTik-1s+Af541ZkM+mDVkjRx94WM_4w@mail.gmail.com>
	<1337802805327-4631127.post@n4.nabble.com>
Message-ID: <CABdHhvF1zJpDYXo3i7N30r5OQ0_Qj99_Rzpg-2oNRkdDNJFDfw@mail.gmail.com>

> I've been playing around with this for a while. One flaw I found - it
> doesn't handle nested Curries very well (the naive implementation in
> roxygen/functional does).

That's easily fixed:

Curry <- function(FUN, ...) {
  args <- match.call(expand.dots = FALSE)$...
  args$... <- as.name("...")

  env <- parent.frame()

  if (is.name(FUN)) {
    fname <- FUN
  } else if (is.character(FUN)) {
    fname <- as.name(FUN)
  } else if (is.function(FUN)){
    fname <- FUN
    # env$FUN <- FUN
  } else {
    stop("FUN not function or name of function")
  }
  curry_call <- as.call(c(list(fname), args))

  f <- eval(call("function", as.pairlist(alist(... = )), curry_call))
  environment(f) <- env
  f
}


Curry(Curry(foo,3),4)

> e.g.:
>
> foo=function(x,y,z) x+y+z
> Curry(Curry("foo",3),4)(3)
> # 10
>
> Curry(Curry(foo,3),4)(3)
> # hangs
>
> foo4=function(a,b,c,d)
> Curry(Curry(Curry("foo4",3),4),1)(3)
> # hangs
>
> I was also curious if there was some trick to force a function eval when the
> list of arguments got exhausted (for example, a triple Curry on foo above
> would leave no arguments so would trigger eval into 10).

I don't think that would be a good idea - there's a big difference
between a function with no arguments and the result of calling that
function.

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From whao at princeton.edu  Fri May 25 21:33:04 2012
From: whao at princeton.edu (Wei Hao)
Date: Fri, 25 May 2012 15:33:04 -0400
Subject: [Rd] equivalent to source() inside a package
Message-ID: <CADhXZziobLnoQpSmkVLg55gkcFdnk-2NbZQUTizXr+edX1DPJg@mail.gmail.com>

Hi all:

I'm working on a project that I have packaged for ease of
distribution. The different simulations in the package share code, so
obviously I have those parts organized as functions. Now, I want to
show people my code, but the structure with the internal functions
might be a little confusing to follow. One thing I tried was to have
the code of the functions as their own R files in the R/ folder, and
then using source() instead of calling the functions (with consistent
variable names and such) but this didn't work. The goal is for the
user to be able to see the entirety of the code in the interactive R
session, i.e. with a standard package implementation:

> library(wei.simulations)
> sim1
function (seed=5555)
{
    [stuff]
    a = internal_function1(data)
    [stuff]
}



I would like the user to see:

> sim1
function (seed=5555)
{
    [stuff]
    tmp = apply(data,1,mean)
    a = sum(tmp) #or whatever, this is just an example
    [stuff]
}

where I can change those two lines in their own file, and have the
changes apply for all the simulation functions. I know this seems like
a weird question to ask, but it would be useful for me to make it as
foolproof as possible for the user to see all the simulation code (I'm
presuming the user is a casual R user and not familiar with looking
through package sources).

Thanks
Wei


From yikelu.home at gmail.com  Fri May 25 22:14:08 2012
From: yikelu.home at gmail.com (Yike Lu)
Date: Fri, 25 May 2012 16:14:08 -0400
Subject: [Rd] Curry: proposed new functional programming, er, function.
In-Reply-To: <CABdHhvF1zJpDYXo3i7N30r5OQ0_Qj99_Rzpg-2oNRkdDNJFDfw@mail.gmail.com>
References: <7098abec0711011200va3851o811f60bb100616ce@mail.gmail.com>
	<BANLkTi=jud5hhis5y-veQKZHzSYYoPqnBw@mail.gmail.com>
	<79F23BA7BB084E4FA01A8B93904CD02CF669FAA4C9@WIGGUMVS.win.ad.jhu.edu>
	<4DC16917.5090206@gmail.com>
	<BANLkTikuy3OP8j5aymKuE_zmHtYLCkBZWg@mail.gmail.com>
	<79F23BA7BB084E4FA01A8B93904CD02CF669FAA4D7@WIGGUMVS.win.ad.jhu.edu>
	<BANLkTikvfsyZaW4wDB8sA-Z7G-rMQ+11Tg@mail.gmail.com>
	<BANLkTikGcviLYfFska4vkf5GpuCpmKTdJw@mail.gmail.com>
	<BANLkTik-1s+Af541ZkM+mDVkjRx94WM_4w@mail.gmail.com>
	<1337802805327-4631127.post@n4.nabble.com>
	<CABdHhvF1zJpDYXo3i7N30r5OQ0_Qj99_Rzpg-2oNRkdDNJFDfw@mail.gmail.com>
Message-ID: <4FBFE810.5070405@gmail.com>

So here's the way I'm reading this:

Original:
curry_call is the function body you're constructing, which is itself 
just a one liner which calls the symbol FUN with the appropriate 
substitutions.

call("function", [...]) calls the "function" function, which itself 
takes 2 arguments: the list of formal args and the function body.
eval of this call returns the newly constructed function, which you 
assign to f. Then you assign the parent.frame() as the environment of f, 
except with the symbol FUN assigned as the original argument FUN.

However, upon looking at the debugger, I find that env$FUN<-FUN assigns 
FUN in Global Scope if Curry is called from the top level.
A nested Curry call then creates FUN=function(...) FUN([...]), a 
recursive infinite loop.

New:
The recursion is obviously removed now, but what's the new version do?

As far as I can tell, it returns  a structure like...

function(...){function(...) {original_function_body(curried_arg, ...=...)}}

Comparing and contrasting to the version in "functional" package:
1) quotes work (can do Curry(quote(foo), 2) where the "functional" 
version can't)
2) environment capture works in both constructions
3) Your new version is exceptionally transparent, as the function body 
gets stored so that when you print the body later, you can see the original

As far as 0 argument functions, I understand the difference, that idea 
came from a programming language (q/kdb+) I know that supports a neat 
compact syntax for this:

Suppose in R the function was f(x,y,z) x + y + z

In q, one could do:
f[1;2] // returns the curried form
f[1;2] each (1 2 3 4 5) // equivalent to Map(function(z) f(1,2,z), 1:5) 
or Map(Curry(f, 1, 2), 1:5)
f[1;2;3] // returns 6
f[1;2][3] // returns 6


Probably a slightly different but related concept - elided arguments, 
just a curry with automatic eval when all argument slots are filled.

Thanks, this has been very enlightening.

Yike

On 5/25/2012 9:49 AM, Hadley Wickham wrote:
>
> That's easily fixed:
>
> Curry<- function(FUN, ...) {
>    args<- match.call(expand.dots = FALSE)$...
>    args$...<- as.name("...")
>
>    env<- parent.frame()
>
>    if (is.name(FUN)) {
>      fname<- FUN
>    } else if (is.character(FUN)) {
>      fname<- as.name(FUN)
>    } else if (is.function(FUN)){
>      fname<- FUN
>      # env$FUN<- FUN
>    } else {
>      stop("FUN not function or name of function")
>    }
>    curry_call<- as.call(c(list(fname), args))
>
>    f<- eval(call("function", as.pairlist(alist(... = )), curry_call))
>    environment(f)<- env
>    f
> }
>
>
> Curry(Curry(foo,3),4)
>
>> e.g.:
>>
>> foo=function(x,y,z) x+y+z
>> Curry(Curry("foo",3),4)(3)
>> # 10
>>
>> Curry(Curry(foo,3),4)(3)
>> # hangs
>>
>> foo4=function(a,b,c,d)
>> Curry(Curry(Curry("foo4",3),4),1)(3)
>> # hangs
>>
>> I was also curious if there was some trick to force a function eval when the
>> list of arguments got exhausted (for example, a triple Curry on foo above
>> would leave no arguments so would trigger eval into 10).
>
> I don't think that would be a good idea - there's a big difference
> between a function with no arguments and the result of calling that
> function.
>
> Hadley
>


From pgilbert902 at gmail.com  Fri May 25 23:24:34 2012
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Fri, 25 May 2012 17:24:34 -0400
Subject: [Rd] equivalent to source() inside a package
In-Reply-To: <CADhXZziobLnoQpSmkVLg55gkcFdnk-2NbZQUTizXr+edX1DPJg@mail.gmail.com>
References: <CADhXZziobLnoQpSmkVLg55gkcFdnk-2NbZQUTizXr+edX1DPJg@mail.gmail.com>
Message-ID: <4FBFF892.1030203@gmail.com>

Is there a reason for not using a vignette or putting a file in the 
demo/  directory?  This seems like the sort of thing for which they are 
intended.

Paul

On 12-05-25 03:33 PM, Wei Hao wrote:
> Hi all:
>
> I'm working on a project that I have packaged for ease of
> distribution. The different simulations in the package share code, so
> obviously I have those parts organized as functions. Now, I want to
> show people my code, but the structure with the internal functions
> might be a little confusing to follow. One thing I tried was to have
> the code of the functions as their own R files in the R/ folder, and
> then using source() instead of calling the functions (with consistent
> variable names and such) but this didn't work. The goal is for the
> user to be able to see the entirety of the code in the interactive R
> session, i.e. with a standard package implementation:
>
>> library(wei.simulations)
>> sim1
> function (seed=5555)
> {
>      [stuff]
>      a = internal_function1(data)
>      [stuff]
> }
>
>
>
> I would like the user to see:
>
>> sim1
> function (seed=5555)
> {
>      [stuff]
>      tmp = apply(data,1,mean)
>      a = sum(tmp) #or whatever, this is just an example
>      [stuff]
> }
>
> where I can change those two lines in their own file, and have the
> changes apply for all the simulation functions. I know this seems like
> a weird question to ask, but it would be useful for me to make it as
> foolproof as possible for the user to see all the simulation code (I'm
> presuming the user is a casual R user and not familiar with looking
> through package sources).
>
> Thanks
> Wei
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hadley at rice.edu  Fri May 25 23:23:59 2012
From: hadley at rice.edu (Hadley Wickham)
Date: Fri, 25 May 2012 16:23:59 -0500
Subject: [Rd] Curry: proposed new functional programming, er, function.
In-Reply-To: <4FBFE810.5070405@gmail.com>
References: <7098abec0711011200va3851o811f60bb100616ce@mail.gmail.com>
	<BANLkTi=jud5hhis5y-veQKZHzSYYoPqnBw@mail.gmail.com>
	<79F23BA7BB084E4FA01A8B93904CD02CF669FAA4C9@WIGGUMVS.win.ad.jhu.edu>
	<4DC16917.5090206@gmail.com>
	<BANLkTikuy3OP8j5aymKuE_zmHtYLCkBZWg@mail.gmail.com>
	<79F23BA7BB084E4FA01A8B93904CD02CF669FAA4D7@WIGGUMVS.win.ad.jhu.edu>
	<BANLkTikvfsyZaW4wDB8sA-Z7G-rMQ+11Tg@mail.gmail.com>
	<BANLkTikGcviLYfFska4vkf5GpuCpmKTdJw@mail.gmail.com>
	<BANLkTik-1s+Af541ZkM+mDVkjRx94WM_4w@mail.gmail.com>
	<1337802805327-4631127.post@n4.nabble.com>
	<CABdHhvF1zJpDYXo3i7N30r5OQ0_Qj99_Rzpg-2oNRkdDNJFDfw@mail.gmail.com>
	<4FBFE810.5070405@gmail.com>
Message-ID: <CABdHhvHzLj_BAjx+pMeP2YT9QQEV=_wVw8c3NqTBfp2XHLt6Eg@mail.gmail.com>

On Fri, May 25, 2012 at 3:14 PM, Yike Lu <yikelu.home at gmail.com> wrote:
> So here's the way I'm reading this:
>
> Original:
> curry_call is the function body you're constructing, which is itself just a
> one liner which calls the symbol FUN with the appropriate substitutions.

Yup.  With a bit more infrastructure you could probably modify it so
that multiple curries collapsed into the equivalent single curry.

> call("function", [...]) calls the "function" function, which itself takes 2
> arguments: the list of formal args and the function body.
> eval of this call returns the newly constructed function, which you assign
> to f. Then you assign the parent.frame() as the environment of f, except
> with the symbol FUN assigned as the original argument FUN.
>
> However, upon looking at the debugger, I find that env$FUN<-FUN assigns FUN
> in Global Scope if Curry is called from the top level.
> A nested Curry call then creates FUN=function(...) FUN([...]), a recursive
> infinite loop.

Yes, that was a really bad idea - not sure why I didn't see the
problems when I first wrote it.

> New:
> The recursion is obviously removed now, but what's the new version do?
>
> As far as I can tell, it returns ?a structure like...
>
> function(...){function(...) {original_function_body(curried_arg, ...=...)}}
>
> Comparing and contrasting to the version in "functional" package:
> 1) quotes work (can do Curry(quote(foo), 2) where the "functional" version
> can't)
> 2) environment capture works in both constructions
> 3) Your new version is exceptionally transparent, as the function body gets
> stored so that when you print the body later, you can see the original
>
> As far as 0 argument functions, I understand the difference, that idea came
> from a programming language (q/kdb+) I know that supports a neat compact
> syntax for this:
>
> Suppose in R the function was f(x,y,z) x + y + z
>
> In q, one could do:
> f[1;2] // returns the curried form
> f[1;2] each (1 2 3 4 5) // equivalent to Map(function(z) f(1,2,z), 1:5) or
> Map(Curry(f, 1, 2), 1:5)
> f[1;2;3] // returns 6
> f[1;2][3] // returns 6

I can see why that's useful at the language level, but I think it
would be confusing to do so in R.

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From yikelu.home at gmail.com  Sat May 26 18:30:05 2012
From: yikelu.home at gmail.com (Yike Lu)
Date: Sat, 26 May 2012 12:30:05 -0400
Subject: [Rd] Curry: proposed new functional programming, er, function.
In-Reply-To: <CABdHhvHzLj_BAjx+pMeP2YT9QQEV=_wVw8c3NqTBfp2XHLt6Eg@mail.gmail.com>
References: <7098abec0711011200va3851o811f60bb100616ce@mail.gmail.com>
	<BANLkTi=jud5hhis5y-veQKZHzSYYoPqnBw@mail.gmail.com>
	<79F23BA7BB084E4FA01A8B93904CD02CF669FAA4C9@WIGGUMVS.win.ad.jhu.edu>
	<4DC16917.5090206@gmail.com>
	<BANLkTikuy3OP8j5aymKuE_zmHtYLCkBZWg@mail.gmail.com>
	<79F23BA7BB084E4FA01A8B93904CD02CF669FAA4D7@WIGGUMVS.win.ad.jhu.edu>
	<BANLkTikvfsyZaW4wDB8sA-Z7G-rMQ+11Tg@mail.gmail.com>
	<BANLkTikGcviLYfFska4vkf5GpuCpmKTdJw@mail.gmail.com>
	<BANLkTik-1s+Af541ZkM+mDVkjRx94WM_4w@mail.gmail.com>
	<1337802805327-4631127.post@n4.nabble.com>
	<CABdHhvF1zJpDYXo3i7N30r5OQ0_Qj99_Rzpg-2oNRkdDNJFDfw@mail.gmail.com>
	<4FBFE810.5070405@gmail.com>
	<CABdHhvHzLj_BAjx+pMeP2YT9QQEV=_wVw8c3NqTBfp2XHLt6Eg@mail.gmail.com>
Message-ID: <4FC1050D.3080306@gmail.com>

On 5/25/12 5:23 PM, Hadley Wickham wrote:
> On Fri, May 25, 2012 at 3:14 PM, Yike Lu<yikelu.home at gmail.com>  wrote:
>> So here's the way I'm reading this:
>>
>> Original:
>> curry_call is the function body you're constructing, which is itself just a
>> one liner which calls the symbol FUN with the appropriate substitutions.
>
> Yup.  With a bit more infrastructure you could probably modify it so
> that multiple curries collapsed into the equivalent single curry.
>
Yes I could see how one would do that - if the match.call detects a 
Curry as the first function being called, we would short circuit the 
usual evaluation into a different path which properly collapses all the 
nesting.

It's interesting how R offers these facilities to override the usual 
evaluation order, but if one does that too much it could easily become 
confusing. I was looking at Rpipe the other day 
(https://github.com/slycoder/Rpipe) and the way he implements it is by 
defining his own Eval.

Cheers,


From krivitsky at stat.psu.edu  Sat May 26 19:02:34 2012
From: krivitsky at stat.psu.edu (Pavel N. Krivitsky)
Date: Sat, 26 May 2012 13:02:34 -0400
Subject: [Rd] [patch] Behavior of .C() and .Fortran() when given
 double(0) or integer(0).
In-Reply-To: <4FB4C900.6070204@stats.ox.ac.uk>
References: <1336153356.24356.332.camel@Navi.krivitsky.homeip.net>
	<4FB4C900.6070204@stats.ox.ac.uk>
Message-ID: <1338051754.4646.165.camel@Navi.krivitsky.homeip.net>

Dear Professor Ripley and R-devel,

Thank you for taking the time to look into this. I understand that the
2.15.0 behavior in question was undocumented and ambiguous (at least as
of that release), and it should not have been relied upon, intuitiveness
or not. My suggestion is that in the next release, it ought to be the
standard, documented behavior, not just because it's historical, but
because it's more convenient and safer.

>From the point of view of programmer convenience, a having a 0-length
vector on the R side always map to a NULL pointer on the C side provides
a useful bit of information that the programmer can use, while a
non-NULL pointer to no data isn't useful, and the current R-devel
behavior requires the programmer to pass the information about whether
it's empty through an additional argument (of which there is an upper
limit). For example, if a procedure implemented in C takes optional
weights, passing a double(0) that was translated to NULL could be used
to signal that there are no weights. Also, while the .Call() interface
allows an R vector passed to it to be resized, the .C() and .Fortran()
interfaces don't, so a 0-length R vector passed via .C() or .Fortran()
can be neither read nor written to, and nothing is lost by passing it as
NULL.

On the issue of safety, while dereferencing a NULL pointer is not an
instant segfault on absolutely every system, it is the case for the
overwhelming majority of modern systems on which anyone is likely to run
a recent version of R. For those systems for which it is not the case,
the behavior is no worse than dereferencing a non-NULL pointer to no
data. On the contrary, while it's easy to check if a pointer is NULL,
there is no general way to check whether a non-NULL pointer is valid, so
if the 0-length->NULL behavior is made the standard and documented,
package developers may be more likely to make use of it to check.

On the issue of instrumentation and debugging, again, I think it comes
down to programmer convenience. Segmentation faults caused by NULL
dereferencing can be caught and debugged interactively with a debugger
like GDB, while non-NULL memory errors have less predictable
consequences and require tools like the slower and non-interactive
Valgrind. Perhaps R's new guard bytes will change that somewhat, but,
from what I've read, they only check for invalid writes, not invalid
reads, which can cause almost as much trouble. On the other hand, both
trying to read from a NULL pointer and trying to write to it will be
detected on most systems. And, having 0-length vectors be passed as NULL
does not preclude using guard bytes on non-0-length vectors.

To summarize, I think that on both safety and convenience, standardizing
on the 0-length->NULL behavior dominates the 0-length->invalid-pointer
behavior: in each scenario that either of us has brought up so far, it
behaves no worse and often better. My patch does not include changes to
documentation, and, if you like, I am willing to write one that does. If
my patch can be improved in some other way, please let me know and I
will try to improve it.

                            Sincerely,
                            Pavel Krivitsky



On Thu, 2012-05-17 at 10:46 +0100, Prof Brian Ripley wrote:
> On 04/05/2012 18:42, Pavel N. Krivitsky wrote:
> > Dear R-devel,
> >
> > While tracking down some hard-to-reproduce bugs in a package I maintain,
> > I stumbled on a behavior change between R 2.15.0 and the current R-devel
> > (or SVN trunk).
> >
> > In 2.15.0 and earlier, if you passed an 0-length vector of the right
> > mode (e.g., double(0) or integer(0)) as one of the arguments in a .C()
> > call with DUP=TRUE (the default), the C routine would be passed NULL
> > (the C pointer, not R NULL) in the corresponding argument. The current
> 
> Where did you get that from?  The documentation says it passes an (e.g.) 
> double* pointer to a copy of the data area of the R vector.  There is no 
> change in the documented behaviour ....  Now, of course a zero-length 
> area can be at any address, but none is stated anywhere that I am aware of.
> 
> > development version instead passes it a pointer to what appears to be
> > memory location immediately following the the SEXP that holds the
> > metadata for the argument. If the argument has length 0, this is often
> > memory belonging to a different R object. (DUP=FALSE in 2.15.0
> > appears to have the same behavior as R-devel.)
> >
> > .C() documentation and Writing R Extensions don't explicitly specify a
> > behavior for 0-length vectors, so I don't know if this change is
> > intentional, or whether it was a side-effect of the following news item:
> >
> >        .C() and .Fortran() do less copying: arguments which are raw,
> >        logical, integer, real or complex vectors and are unnamed are not
> >        copied before the call, and (named or not) are not copied after
> >        the call.  Lists are no longer copied (they are supposed to be
> >        used read-only in the C code).
> >
> > Was the change in the empty vector behavior intentional?
> >
> > It seems to me that standardizing on the behavior of giving the C
> > routine NULL is safer, more consistent with other memory-related
> > routines, and more convenient: whereas dereferencing a NULL pointer is
> > an immediate (and therefore easily traced) segfault, dereferencing an
> 
> That's not true, in general.
> 
> > invalid pointer that is nevertheless in the general memory area
> > allocated to the program often causes subtle errors down the line;
> > R_alloc asked to allocate 0 bytes returns NULL, at least on my platform;
> 
> Again, undocumented and should not be relied on.
> 
> > and the C routine can easily check if a pointer is NULL, but with the
> > R-devel behavior, the programmer has to add an explicit way of telling
> > that an empty vector was passed.
> 
> It's no different from any other vector length: it is easy for careless 
> programmers to read/write off the ends of the allocated area, and this 
> is why in R-devel we have an option to check for that (and of course 
> also what valgrind is good at finding in an instrumented version of R).
> 
> > I've attached a small test case (dotC_NULL.* files) that shows the
> > difference. The C file should be built with R CMD SHLIB, and the R file
> > calls the functions in the library with a variety of arguments. Output I
> > get from running
> > R CMD BATCH --no-timing --vanilla --slave dotC_NULL.R
> > on R 2.15.0, R trunk, and R trunk with my patch (described below) are attached.
> >
> > The attached patch (dotC_NULL.patch) against the current trunk
> > (affecting src/main/dotcode.c) restores the old behavior for DUP=TRUE
> > (i.e., 0-length vector ->  NULL pointer) and extends it to the DUP=FALSE
> > case. It does so by checking if an argument --- if it's of mode raw,
> > integer, real, or complex --- to a .C() or .Fortran() call has length 0,
> > and, if so, sets the pointer to be passed to NULL and then skips the
> > copying of the C routine's changes back to the R object for that
> > argument. The additional computing cost should be negligible (i.e.,
> > checking if vector length equals 0 and break-ing out of a switch
> > statement if so).
> >
> > The patch appears to work, at least for my package, and R CMD check
> > passes for all recommended packages (on my 64-bit Linux system), but
> > this is my first time working with R's internals, so handle with care.
> 
> That's easy: we will not be changing this.  In particular, the new 
> checks I refer to above rely on passing the address of an in-process 
> memory area with guard bytes.
> 
> >                                     Best,
> >                                     Pavel Krivitsky
> >
> >
> >
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From ggrothendieck at gmail.com  Sat May 26 19:07:41 2012
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 26 May 2012 13:07:41 -0400
Subject: [Rd] Curry: proposed new functional programming, er, function.
In-Reply-To: <4FC1050D.3080306@gmail.com>
References: <7098abec0711011200va3851o811f60bb100616ce@mail.gmail.com>
	<BANLkTi=jud5hhis5y-veQKZHzSYYoPqnBw@mail.gmail.com>
	<79F23BA7BB084E4FA01A8B93904CD02CF669FAA4C9@WIGGUMVS.win.ad.jhu.edu>
	<4DC16917.5090206@gmail.com>
	<BANLkTikuy3OP8j5aymKuE_zmHtYLCkBZWg@mail.gmail.com>
	<79F23BA7BB084E4FA01A8B93904CD02CF669FAA4D7@WIGGUMVS.win.ad.jhu.edu>
	<BANLkTikvfsyZaW4wDB8sA-Z7G-rMQ+11Tg@mail.gmail.com>
	<BANLkTikGcviLYfFska4vkf5GpuCpmKTdJw@mail.gmail.com>
	<BANLkTik-1s+Af541ZkM+mDVkjRx94WM_4w@mail.gmail.com>
	<1337802805327-4631127.post@n4.nabble.com>
	<CABdHhvF1zJpDYXo3i7N30r5OQ0_Qj99_Rzpg-2oNRkdDNJFDfw@mail.gmail.com>
	<4FBFE810.5070405@gmail.com>
	<CABdHhvHzLj_BAjx+pMeP2YT9QQEV=_wVw8c3NqTBfp2XHLt6Eg@mail.gmail.com>
	<4FC1050D.3080306@gmail.com>
Message-ID: <CAP01uRkeawBJWgeMez8DYy5fOAOzQE2XE-=7vd=z26WybikRFA@mail.gmail.com>

On Sat, May 26, 2012 at 12:30 PM, Yike Lu <yikelu.home at gmail.com> wrote:
> On 5/25/12 5:23 PM, Hadley Wickham wrote:
>>
>> On Fri, May 25, 2012 at 3:14 PM, Yike Lu<yikelu.home at gmail.com> ?wrote:
>>>
>>> So here's the way I'm reading this:
>>>
>>> Original:
>>> curry_call is the function body you're constructing, which is itself just
>>> a
>>> one liner which calls the symbol FUN with the appropriate substitutions.
>>
>>
>> Yup. ?With a bit more infrastructure you could probably modify it so
>> that multiple curries collapsed into the equivalent single curry.
>>
> Yes I could see how one would do that - if the match.call detects a Curry as
> the first function being called, we would short circuit the usual evaluation
> into a different path which properly collapses all the nesting.
>
> It's interesting how R offers these facilities to override the usual
> evaluation order, but if one does that too much it could easily become
> confusing. I was looking at Rpipe the other day
> (https://github.com/slycoder/Rpipe) and the way he implements it is by
> defining his own Eval.
>

The proto package does currying on proto methods by defining $.proto
appropriately:

library(proto)
p <- proto(a = 1, b = 2)

# same as ls(p) - output is c("a", "b")
p$ls()

Here ls() is _not_ a special proto method but is just the ordinary
ls() provided by R.  $.proto calls ls() sticking in p as the first
argument.  A proto object is an environment and ls with a first
argument that is an environment lists the names of the objects in that
environment.  Similarly:

p$as.list()
p$str()
p$parent.env()
p$print()
p$eapply(length)

are the same as as.list(p), str(p), parent.env(p), print(p) and
eapply(p, length).

Although this might seem like its just syntax in proto it does allow
one to override the method.  For example,

p2 <- proto(a = 1, b = 2, print = function(.) with(., cat("a:", a,
"b:", b, "\n")) )

p2$print() # uses p2's print

print(p2) # uses R's print

etc.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From simon.urbanek at r-project.org  Sat May 26 20:00:32 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 26 May 2012 14:00:32 -0400
Subject: [Rd] [patch] Behavior of .C() and .Fortran() when given
	double(0) or integer(0).
In-Reply-To: <1338051754.4646.165.camel@Navi.krivitsky.homeip.net>
References: <1336153356.24356.332.camel@Navi.krivitsky.homeip.net>
	<4FB4C900.6070204@stats.ox.ac.uk>
	<1338051754.4646.165.camel@Navi.krivitsky.homeip.net>
Message-ID: <D2C9AAAD-4B59-43DE-ACD8-3F722216EE89@r-project.org>

On May 26, 2012, at 1:02 PM, Pavel N. Krivitsky wrote:

> Dear Professor Ripley and R-devel,
> 
> Thank you for taking the time to look into this. I understand that the
> 2.15.0 behavior in question was undocumented and ambiguous (at least as
> of that release), and it should not have been relied upon, intuitiveness
> or not. My suggestion is that in the next release, it ought to be the
> standard, documented behavior, not just because it's historical, but
> because it's more convenient and safer.
> 

That is bogus - .C is inherently unsafe wrt vector lengths so talking about safety here is IMHO nonsensical. Your "safety" relies on bombing the program - that is arguably much less safe than using checks that Brian was talking about because they are recoverable. You can argue either way, but there is no winner - the real answer is use .Call() instead.


>> From the point of view of programmer convenience, a having a 0-length
> vector on the R side always map to a NULL pointer on the C side provides
> a useful bit of information that the programmer can use, while a
> non-NULL pointer to no data isn't useful, and the current R-devel
> behavior requires the programmer to pass the information about whether
> it's empty through an additional argument (of which there is an upper
> limit). For example, if a procedure implemented in C takes optional
> weights, passing a double(0) that was translated to NULL could be used
> to signal that there are no weights.

That would be just plain wrong use that certainly should not be encouraged - you *have* to pass the length along with any vectors passed to .C (that's why you should not be even thinking of using .C in the first place!) so it is much safer to check that the length you passed is 0 rather than relying on special-casing into NULL pointers.

Cheers,
Simon


> Also, while the .Call() interface
> allows an R vector passed to it to be resized, the .C() and .Fortran()
> interfaces don't, so a 0-length R vector passed via .C() or .Fortran()
> can be neither read nor written to, and nothing is lost by passing it as
> NULL.
> 
> On the issue of safety, while dereferencing a NULL pointer is not an
> instant segfault on absolutely every system, it is the case for the
> overwhelming majority of modern systems on which anyone is likely to run
> a recent version of R. For those systems for which it is not the case,
> the behavior is no worse than dereferencing a non-NULL pointer to no
> data. On the contrary, while it's easy to check if a pointer is NULL,
> there is no general way to check whether a non-NULL pointer is valid, so
> if the 0-length->NULL behavior is made the standard and documented,
> package developers may be more likely to make use of it to check.
> 
> On the issue of instrumentation and debugging, again, I think it comes
> down to programmer convenience. Segmentation faults caused by NULL
> dereferencing can be caught and debugged interactively with a debugger
> like GDB, while non-NULL memory errors have less predictable
> consequences and require tools like the slower and non-interactive
> Valgrind. Perhaps R's new guard bytes will change that somewhat, but,
> from what I've read, they only check for invalid writes, not invalid
> reads, which can cause almost as much trouble. On the other hand, both
> trying to read from a NULL pointer and trying to write to it will be
> detected on most systems. And, having 0-length vectors be passed as NULL
> does not preclude using guard bytes on non-0-length vectors.
> 
> To summarize, I think that on both safety and convenience, standardizing
> on the 0-length->NULL behavior dominates the 0-length->invalid-pointer
> behavior: in each scenario that either of us has brought up so far, it
> behaves no worse and often better. My patch does not include changes to
> documentation, and, if you like, I am willing to write one that does. If
> my patch can be improved in some other way, please let me know and I
> will try to improve it.
> 
>                            Sincerely,
>                            Pavel Krivitsky
> 
> 
> 
> On Thu, 2012-05-17 at 10:46 +0100, Prof Brian Ripley wrote:
>> On 04/05/2012 18:42, Pavel N. Krivitsky wrote:
>>> Dear R-devel,
>>> 
>>> While tracking down some hard-to-reproduce bugs in a package I maintain,
>>> I stumbled on a behavior change between R 2.15.0 and the current R-devel
>>> (or SVN trunk).
>>> 
>>> In 2.15.0 and earlier, if you passed an 0-length vector of the right
>>> mode (e.g., double(0) or integer(0)) as one of the arguments in a .C()
>>> call with DUP=TRUE (the default), the C routine would be passed NULL
>>> (the C pointer, not R NULL) in the corresponding argument. The current
>> 
>> Where did you get that from?  The documentation says it passes an (e.g.) 
>> double* pointer to a copy of the data area of the R vector.  There is no 
>> change in the documented behaviour ....  Now, of course a zero-length 
>> area can be at any address, but none is stated anywhere that I am aware of.
>> 
>>> development version instead passes it a pointer to what appears to be
>>> memory location immediately following the the SEXP that holds the
>>> metadata for the argument. If the argument has length 0, this is often
>>> memory belonging to a different R object. (DUP=FALSE in 2.15.0
>>> appears to have the same behavior as R-devel.)
>>> 
>>> .C() documentation and Writing R Extensions don't explicitly specify a
>>> behavior for 0-length vectors, so I don't know if this change is
>>> intentional, or whether it was a side-effect of the following news item:
>>> 
>>>       .C() and .Fortran() do less copying: arguments which are raw,
>>>       logical, integer, real or complex vectors and are unnamed are not
>>>       copied before the call, and (named or not) are not copied after
>>>       the call.  Lists are no longer copied (they are supposed to be
>>>       used read-only in the C code).
>>> 
>>> Was the change in the empty vector behavior intentional?
>>> 
>>> It seems to me that standardizing on the behavior of giving the C
>>> routine NULL is safer, more consistent with other memory-related
>>> routines, and more convenient: whereas dereferencing a NULL pointer is
>>> an immediate (and therefore easily traced) segfault, dereferencing an
>> 
>> That's not true, in general.
>> 
>>> invalid pointer that is nevertheless in the general memory area
>>> allocated to the program often causes subtle errors down the line;
>>> R_alloc asked to allocate 0 bytes returns NULL, at least on my platform;
>> 
>> Again, undocumented and should not be relied on.
>> 
>>> and the C routine can easily check if a pointer is NULL, but with the
>>> R-devel behavior, the programmer has to add an explicit way of telling
>>> that an empty vector was passed.
>> 
>> It's no different from any other vector length: it is easy for careless 
>> programmers to read/write off the ends of the allocated area, and this 
>> is why in R-devel we have an option to check for that (and of course 
>> also what valgrind is good at finding in an instrumented version of R).
>> 
>>> I've attached a small test case (dotC_NULL.* files) that shows the
>>> difference. The C file should be built with R CMD SHLIB, and the R file
>>> calls the functions in the library with a variety of arguments. Output I
>>> get from running
>>> R CMD BATCH --no-timing --vanilla --slave dotC_NULL.R
>>> on R 2.15.0, R trunk, and R trunk with my patch (described below) are attached.
>>> 
>>> The attached patch (dotC_NULL.patch) against the current trunk
>>> (affecting src/main/dotcode.c) restores the old behavior for DUP=TRUE
>>> (i.e., 0-length vector ->  NULL pointer) and extends it to the DUP=FALSE
>>> case. It does so by checking if an argument --- if it's of mode raw,
>>> integer, real, or complex --- to a .C() or .Fortran() call has length 0,
>>> and, if so, sets the pointer to be passed to NULL and then skips the
>>> copying of the C routine's changes back to the R object for that
>>> argument. The additional computing cost should be negligible (i.e.,
>>> checking if vector length equals 0 and break-ing out of a switch
>>> statement if so).
>>> 
>>> The patch appears to work, at least for my package, and R CMD check
>>> passes for all recommended packages (on my 64-bit Linux system), but
>>> this is my first time working with R's internals, so handle with care.
>> 
>> That's easy: we will not be changing this.  In particular, the new 
>> checks I refer to above rely on passing the address of an in-process 
>> memory area with guard bytes.
>> 
>>>                                    Best,
>>>                                    Pavel Krivitsky
>>> 
>>> 
>>> 
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From edd at debian.org  Sat May 26 21:15:54 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 26 May 2012 14:15:54 -0500
Subject: [Rd] [patch] Behavior of .C() and .Fortran() when
	given	double(0) or integer(0).
In-Reply-To: <D2C9AAAD-4B59-43DE-ACD8-3F722216EE89@r-project.org>
References: <1336153356.24356.332.camel@Navi.krivitsky.homeip.net>
	<4FB4C900.6070204@stats.ox.ac.uk>
	<1338051754.4646.165.camel@Navi.krivitsky.homeip.net>
	<D2C9AAAD-4B59-43DE-ACD8-3F722216EE89@r-project.org>
Message-ID: <20417.11242.289932.173647@max.nulle.part>


On 26 May 2012 at 14:00, Simon Urbanek wrote:
| [...] the real answer is use .Call() instead.

Maybe Kurt could add something to that extent to the R FAQ ?

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From krivitsky at stat.psu.edu  Sat May 26 21:53:17 2012
From: krivitsky at stat.psu.edu (Pavel N. Krivitsky)
Date: Sat, 26 May 2012 15:53:17 -0400
Subject: [Rd] [patch] Behavior of .C() and .Fortran() when given
 double(0) or integer(0).
In-Reply-To: <D2C9AAAD-4B59-43DE-ACD8-3F722216EE89@r-project.org>
References: <1336153356.24356.332.camel@Navi.krivitsky.homeip.net>
	<4FB4C900.6070204@stats.ox.ac.uk>
	<1338051754.4646.165.camel@Navi.krivitsky.homeip.net>
	<D2C9AAAD-4B59-43DE-ACD8-3F722216EE89@r-project.org>
Message-ID: <1338061997.25240.49.camel@Navi.krivitsky.homeip.net>

Dear Simon,

On Sat, 2012-05-26 at 14:00 -0400, Simon Urbanek wrote:
> > My suggestion is that in the next release, it ought to be the
> > standard, documented behavior, not just because it's historical, but
> > because it's more convenient and safer.
> 
> That is bogus - .C is inherently unsafe wrt vector lengths so talking
> about safety here is IMHO nonsensical. Your "safety" relies on bombing
> the program - 

IMHO, not all memory errors are created equal. From the safety
perspective, an error that immediately bombs the program is preferable
to one that corrupts the memory, producing subtle problems much later or
one that reads the wrong memory area and goes into an infinite loop or
allocates gigabytes of RAM, etc..

> that is arguably much less safe than using checks that Brian was
> talking about because they are recoverable. 

While undoubtedly useful for debugging, I don't think they are
particularly recoverable in practice. At best, they tell you that some
memory before or after that allocated has been overwritten. They cannot
tell you how much memory or whether R is now in an inconsistent state
(which may occur if the write is off by more than 64 bytes, I believe),
and should be restarted immediately, only taking the time to save the
data and history --- which is what a caught segfault in R does anyway,
at least on UNIX-alikes.

Furthermore, the guard bytes only trigger after the C routine exits, so
the error is only caught some time after it occurs, which makes
debugging it more difficult. (In contrast, a debugger like GDB can tell
exactly which C statement caused a segmentation fault.)

The one advantage guard bytes might have over NULL (for a 0-length
vector) is that an error caught by a guard byte might allow the
developer to browse (via options(error=recover)) the R function that
made the .C() call, but even that relies on the bug not overwriting more
than a few bytes, and it cannot detect improper reads. 

> You can argue either way, but there is no winner - the real answer is
> use .Call() instead.

It seems to me that the 0-length->NULL approach still dominates on the
matter of safety and debugging, with a possible exception in what I am
pretty sure is a relatively rare scenario when the developer has passed
a 0-length vector via .C() _and_ it was written to _and_ the developer
wants to browse (using error=recover()) the R code leading up to the
problematic .C() call, rather than browse (via GDB) the C code that
triggered the segfault. In that scenario, the developer can still easily
infer what argument was passed as an empty vector and via what .C()
call. (Standardizing on 0-length->NULL does not preclude putting guard
bytes on non-empty vectors, of course.)

> > From the point of view of programmer convenience, a having a 0-length
> > vector on the R side always map to a NULL pointer on the C side provides
> > a useful bit of information that the programmer can use, while a
> > non-NULL pointer to no data isn't useful, and the current R-devel
> > behavior requires the programmer to pass the information about whether
> > it's empty through an additional argument (of which there is an upper
> > limit). For example, if a procedure implemented in C takes optional
> > weights, passing a double(0) that was translated to NULL could be used
> > to signal that there are no weights.
> 
> That would be just plain wrong use that certainly should not be
> encouraged - you *have* to pass the length along with any vectors
> passed to .C (that's why you should not be even thinking of using .C
> in the first place!) so it is much safer to check that the length you
> passed is 0 rather than relying on special-casing into NULL pointers.

Not necessarily. In the weighted data scenario, the length of the data
vector would, presumably, be passed in a different argument, and, if
weights exist, their length would equal to that. The NULL here could be
a binary signal not to use weights.

While I understand that .Call() interface has many advantages
over .C(), .C() remains a simple and convenient interface that doesn't
require the developer to learn too much about R's internals, and, either
way, as long as the .C() interface is not being deprecated, I think that
it ought to be made as safe and as useful as possible.

                                 Best,
                                 Pavel


From alon.was.cran at gmail.com  Tue May 29 10:57:38 2012
From: alon.was.cran at gmail.com (Alon Wasserman)
Date: Tue, 29 May 2012 11:57:38 +0300
Subject: [Rd] Slow do.call when having an error
Message-ID: <CAAg8eg1mbWEFBuzjrv7aLnDrx_vvzvAOvgoh4Ca3pNd8EvBxag@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120529/20eab9ea/attachment.pl>

From ripley at stats.ox.ac.uk  Tue May 29 15:15:20 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 29 May 2012 14:15:20 +0100
Subject: [Rd] Slow do.call when having an error
In-Reply-To: <CAAg8eg1mbWEFBuzjrv7aLnDrx_vvzvAOvgoh4Ca3pNd8EvBxag@mail.gmail.com>
References: <CAAg8eg1mbWEFBuzjrv7aLnDrx_vvzvAOvgoh4Ca3pNd8EvBxag@mail.gmail.com>
Message-ID: <4FC4CBE8.2040408@stats.ox.ac.uk>

On 29/05/2012 09:57, Alon Wasserman wrote:
> Hi,
> We've encountered a difference in running time between a straight function
> call and the same call using do.call when the called function generated an
> error. We've isolated the problem to the following small reproducible
> example:
>
> Consider the following function:
> foo<- function(nr = 2e6, nc=3, use.do.call = FALSE) {
>    nn<- paste("V", 1:nc, sep="")
>    z<- data.frame(matrix(rnorm(nr*nc), nrow=nr, ncol = nc, dimnames =
> list(NULL, nn)))
>
>    foo2<- function(x) x[,"V1"] + x[,"V0"]
>    if (use.do.call)
>      do.call(foo2, list(z))
>    else
>      foo2(z)
> }
>
> foo2, when called, generates an error because it accesses the V0 column
> which does not exist. When use.do.call==FALSE, foo2 is called directly.
> When use.do.call==TRUE, foo2 is called with the same arguments but using
> do.call. Calling foo() takes about 1 second. Calling
> foo(use.do.call=TRUE)takes about 20 seconds. Does anybody know what
> could explain the difference
> in running time? The difference seems to be related to error handling,
> since try(foo(use.do.call=TRUE)) takes just 1 second.
>
> We used the latest R version (2.15.0) for the test.
>
> Any insight will be appreciated,

Try traceback(max.lines = 10) after each.

With do.call it gives the error equally soon: there is deparsing to be 
done in reporting the calls.  That is because you passed the object z 
and not the symbol z: see the help for do.call.

There are better ways to construct calls: including as here not doing so 
but presumably not in the real problem.  See e.g. ?call and ?substitute

I don't really see why you did not post this on R-help: it is entirely 
about R programming.

> Thanks,
> Alon


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From idfah at cs.colostate.edu  Tue May 29 22:10:54 2012
From: idfah at cs.colostate.edu (Elliott Forney)
Date: Tue, 29 May 2012 14:10:54 -0600
Subject: [Rd] Out of date instructions to build R using MKL
In-Reply-To: <1328886941.2325.23.camel@milan>
References: <1328886941.2325.23.camel@milan>
Message-ID: <CAMTFtYLT978dRYpqN0s1sKu5-RoHofjToMNF9wnY-v=HtGTwhQ@mail.gmail.com>

Yes, these instructions are no longer valid as there has been some
reorganization of the mkl libraries.  The path
/opt/intel/mkl/10.0.3.020/lib/em64t/ is now
/opt/intel/mkl/lib/intel64.  Also, the only libraries that need to be
included are:

-lmkl_gf_lp64 -lmkl_gnu_thread -lmkl_core

The trick to getting rid of the "double complex BLAS" error is to use
only the gnu compatible libraries (i.e. use mkl_gnu_thread instead of
iomp5).  I believe the intel-only libraries use a different convention
to pass complex numbers between libraries built with fortran?
Thankfully this check detects the error instead of crashing at run
time.

I used the following to build R-2.14.1 with MKL:

export LD_LIBRARY_PATH=/opt/intel/mkl/lib/intel64
./configure --prefix=/opt/R-2.14.1 --enable-threads=posix
--with-lapack --with-blas="-I/opt/intel/mkl/include
-L/opt/intel/mkl/lib/intel64 -lmkl_gf_lp64
-lmkl_gnu_thread -lmkl_core -fopenmp -lpthread -lm"

Although a highly tuned BLAS may not help much for many applications,
I have seen several orders of magnitude performance improvement in
some of my work that uses matrix operations heavily and others in my
lab have experienced the same.  Having R linked against MKL has been
HUGELY important for me personally.

A custom tuned ATLAS works well too but I find it frustrating that it
needs to be re-tuned for each architecture I use (I tend to distribute
jobs in a heterogeneous environment).

Thanks!
  Elliott Forney

On Fri, Feb 10, 2012 at 8:15 AM, Milan Bouchet-Valat <nalimilan at club.fr> wrote:
> Hi!
>
> I've been playing with MKL for a few days and I noticed the instructions
> in the R Installation Administration manual [1] no longer apply. It
> seems that since version 10.0 (the one used by the manual),
> libmkl_lapack.so has been renamed/split (although the official
> explanations seem to imply this was already the case in 10.0 [2]).
>
> As a consequence, the instructions for dynamic linking no longer work
> with the last version (2011-sp1). This is also the case of what is
> explained on several sites like [3] or [4]. The manual's instructions to
> link statically to MKL still work fine, though.
>
> I'm merely signaling this fact to more clued people, since I've not been
> able to get R to dynamically link to MKL. I'm always getting this notice
> during ./configure:
>> checking whether double complex BLAS can be used... no
>
> Anyways, one of the problems is also that it's no longer possible to
> make libRblas.so and libRlapack.so symlinks to the Intel libs, as they
> are split into several files.
>
> If nobody knows how or cares about to fix this ATM, a simple warning
> that the instructions are outdated would already improve the situation,
> as it took me some time to understand things had changed and I wasn't
> just being silly. ;-)
>
> (That said, I'm not convinced using an external BLAS/LAPACK is really
> interesting for standard desktops. Performances gains compared to
> default packages are incredible in benchmarks, but for real use cases
> multi-threading often makes things slower - at least for me, using gnm.
> I guess this is mostly interesting for very larges matrices, and not for
> many repeated small operations.)
>
> Regards
>
>
> 1: http://cran.r-project.org/doc/manuals/R-admin.html#MKL
> 2: http://software.intel.com/en-us/forums/showthread.php?t=81302
> 3:
> http://www.r-bloggers.com/compiling-64-bit-r-2-10-1-with-mkl-in-linux/
> 4: http://www.rd.dnc.ac.jp/~otsu/lecture/RwithMKL.html
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From kranstauber at orn.mpg.de  Tue May 29 23:37:55 2012
From: kranstauber at orn.mpg.de (Bart)
Date: Tue, 29 May 2012 23:37:55 +0200
Subject: [Rd] virtual superclasses
Message-ID: <4FC541B3.5000702@orn.mpg.de>

Dear List,

I'm exploring the use of class inheritance for a package were 
developing. I want to try to build on existing a class, i first want to 
extend this a bit using a virtual class and then extend this virtual 
class in multiple other classes. This would be similar to bar3 in the 
example below. Since there are nice functions for creating an object of 
the first superclass i would like to use that object for the 
initialization but somehow that fails with the error :"node stack 
overflow". How could i resolve this problem

Thanks in advance

Bart

 > setClass("foo", representation(a="numeric"),prototype = list( a = 
integer(0)))
 > setClass("bar", representation(b="numeric"))
 > setClass("foo2",contains=c("foo") )
 > setClass("foo3",contains=c("foo", "VIRTUAL") )
 > setClass("foo4",contains=c("foo", "bar") )
 > setClass("bar2",contains=c("foo2") )
 > setClass("bar3",contains=c("foo3") )
 > setClass("bar4",contains=c("foo4") )
 > i<-new("foo",a=1)
 > new("bar2", i)
An object of class "bar2"
Slot "a":
[1] 1

 > new("bar3", i)
Error in tryCatch(expr, error = function(e) { : node stack overflow
 > new("bar4", i)
An object of class "bar4"
Slot "a":
[1] 1

Slot "b":
numeric(0)
 > sessionInfo()
R version 2.15.0 (2012-03-30)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=C                 LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_2.15.0


From ripley at stats.ox.ac.uk  Wed May 30 10:02:27 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 30 May 2012 09:02:27 +0100
Subject: [Rd] Out of date instructions to build R using MKL
In-Reply-To: <CAMTFtYLT978dRYpqN0s1sKu5-RoHofjToMNF9wnY-v=HtGTwhQ@mail.gmail.com>
References: <1328886941.2325.23.camel@milan>
	<CAMTFtYLT978dRYpqN0s1sKu5-RoHofjToMNF9wnY-v=HtGTwhQ@mail.gmail.com>
Message-ID: <4FC5D413.9090004@stats.ox.ac.uk>

Hmm, you replied to a message from February and there has been an R 
release since with a revised manual.  That does say (even more clearly) 
that it refers to version 10.0 of MKL and there have been changes.  And 
since than there had been a change (notified by an Intel engineer) about 
which version of OpenMP to use.

In short, please always check the current documentation before posting 
(as the posting guide required of you).

On 29/05/2012 21:10, Elliott Forney wrote:
> Yes, these instructions are no longer valid as there has been some
> reorganization of the mkl libraries.  The path
> /opt/intel/mkl/10.0.3.020/lib/em64t/ is now
> /opt/intel/mkl/lib/intel64.  Also, the only libraries that need to be
> included are:
>
> -lmkl_gf_lp64 -lmkl_gnu_thread -lmkl_core
>
> The trick to getting rid of the "double complex BLAS" error is to use
> only the gnu compatible libraries (i.e. use mkl_gnu_thread instead of
> iomp5).  I believe the intel-only libraries use a different convention
> to pass complex numbers between libraries built with fortran?
> Thankfully this check detects the error instead of crashing at run
> time.
>
> I used the following to build R-2.14.1 with MKL:
>
> export LD_LIBRARY_PATH=/opt/intel/mkl/lib/intel64
> ./configure --prefix=/opt/R-2.14.1 --enable-threads=posix
> --with-lapack --with-blas="-I/opt/intel/mkl/include
> -L/opt/intel/mkl/lib/intel64 -lmkl_gf_lp64
> -lmkl_gnu_thread -lmkl_core -fopenmp -lpthread -lm"
>
> Although a highly tuned BLAS may not help much for many applications,
> I have seen several orders of magnitude performance improvement in
> some of my work that uses matrix operations heavily and others in my
> lab have experienced the same.  Having R linked against MKL has been
> HUGELY important for me personally.
>
> A custom tuned ATLAS works well too but I find it frustrating that it
> needs to be re-tuned for each architecture I use (I tend to distribute
> jobs in a heterogeneous environment).
>
> Thanks!
>    Elliott Forney
>
> On Fri, Feb 10, 2012 at 8:15 AM, Milan Bouchet-Valat<nalimilan at club.fr>  wrote:
>> Hi!
>>
>> I've been playing with MKL for a few days and I noticed the instructions
>> in the R Installation Administration manual [1] no longer apply. It
>> seems that since version 10.0 (the one used by the manual),
>> libmkl_lapack.so has been renamed/split (although the official
>> explanations seem to imply this was already the case in 10.0 [2]).
>>
>> As a consequence, the instructions for dynamic linking no longer work
>> with the last version (2011-sp1). This is also the case of what is
>> explained on several sites like [3] or [4]. The manual's instructions to
>> link statically to MKL still work fine, though.
>>
>> I'm merely signaling this fact to more clued people, since I've not been
>> able to get R to dynamically link to MKL. I'm always getting this notice
>> during ./configure:
>>> checking whether double complex BLAS can be used... no
>>
>> Anyways, one of the problems is also that it's no longer possible to
>> make libRblas.so and libRlapack.so symlinks to the Intel libs, as they
>> are split into several files.
>>
>> If nobody knows how or cares about to fix this ATM, a simple warning
>> that the instructions are outdated would already improve the situation,
>> as it took me some time to understand things had changed and I wasn't
>> just being silly. ;-)
>>
>> (That said, I'm not convinced using an external BLAS/LAPACK is really
>> interesting for standard desktops. Performances gains compared to
>> default packages are incredible in benchmarks, but for real use cases
>> multi-threading often makes things slower - at least for me, using gnm.
>> I guess this is mostly interesting for very larges matrices, and not for
>> many repeated small operations.)

And that is well-attested, including in the R manuals.

>>
>> Regards
>>
>>
>> 1: http://cran.r-project.org/doc/manuals/R-admin.html#MKL
>> 2: http://software.intel.com/en-us/forums/showthread.php?t=81302
>> 3:
>> http://www.r-bloggers.com/compiling-64-bit-r-2-10-1-with-mkl-in-linux/
>> 4: http://www.rd.dnc.ac.jp/~otsu/lecture/RwithMKL.html
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From spluque at gmail.com  Wed May 30 20:15:31 2012
From: spluque at gmail.com (Sebastian P. Luque)
Date: Wed, 30 May 2012 13:15:31 -0500
Subject: [Rd] fractional seconds in POSIXct
Message-ID: <87k3ztpmbg.fsf@kolob.subpolar.dyndns.org>

Hi,

Using the following simple character vector representing a time series
with fractional seconds:

datetime <- c("20/09/2011 13:00:59.00", "20/09/2011 13:00:59.02",
              "20/09/2011 13:00:59.04")

Conversion to POSIXct runs into problems; the second element is not
interpreted correctly:

---<--------------------cut here---------------start------------------->---
R> as.POSIXct(strptime(datetime, format="%d/%m/%Y %H:%M:%OS"), tz="GMT")
[1] "2011-09-20 13:00:59.00 GMT" "2011-09-20 13:00:59.01 GMT" "2011-09-20 13:00:59.03 GMT"
R> sessionInfo()
R version 2.15.0 (2012-03-30)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C               LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8     LC_MONETARY=en_CA.UTF-8   
 [6] LC_MESSAGES=en_CA.UTF-8    LC_PAPER=C                 LC_NAME=C                  LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats4    stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] diveMove_1.3.4      caTools_1.12        bitops_1.0-4.1      slmisc_0.9.2        latticeExtra_0.6-19 RColorBrewer_1.0-5  lattice_0.20-6     

loaded via a namespace (and not attached):
[1] compiler_2.15.0 grid_2.15.0     tools_2.15.0   
---<--------------------cut here---------------end--------------------->---

Is this expected?  Thanks.

Cheers,

-- 
Seb


From yikelu.home at gmail.com  Wed May 30 20:43:41 2012
From: yikelu.home at gmail.com (Yike Lu)
Date: Wed, 30 May 2012 14:43:41 -0400
Subject: [Rd] Curry: proposed new functional programming, er, function.
In-Reply-To: <CABdHhvHzLj_BAjx+pMeP2YT9QQEV=_wVw8c3NqTBfp2XHLt6Eg@mail.gmail.com>
References: <7098abec0711011200va3851o811f60bb100616ce@mail.gmail.com>
	<BANLkTi=jud5hhis5y-veQKZHzSYYoPqnBw@mail.gmail.com>
	<79F23BA7BB084E4FA01A8B93904CD02CF669FAA4C9@WIGGUMVS.win.ad.jhu.edu>
	<4DC16917.5090206@gmail.com>
	<BANLkTikuy3OP8j5aymKuE_zmHtYLCkBZWg@mail.gmail.com>
	<79F23BA7BB084E4FA01A8B93904CD02CF669FAA4D7@WIGGUMVS.win.ad.jhu.edu>
	<BANLkTikvfsyZaW4wDB8sA-Z7G-rMQ+11Tg@mail.gmail.com>
	<BANLkTikGcviLYfFska4vkf5GpuCpmKTdJw@mail.gmail.com>
	<BANLkTik-1s+Af541ZkM+mDVkjRx94WM_4w@mail.gmail.com>
	<1337802805327-4631127.post@n4.nabble.com>
	<CABdHhvF1zJpDYXo3i7N30r5OQ0_Qj99_Rzpg-2oNRkdDNJFDfw@mail.gmail.com>
	<4FBFE810.5070405@gmail.com>
	<CABdHhvHzLj_BAjx+pMeP2YT9QQEV=_wVw8c3NqTBfp2XHLt6Eg@mail.gmail.com>
Message-ID: <4FC66A5D.7030403@gmail.com>

I just realized that even in the non-nested case, calling from top level 
"broke" some of my code "inexplicably", since the globally stored 
function call gets overridden if you call Curry again. So old Curried 
functions break.

Glad to have this fix.

On 5/25/2012 5:23 PM, Hadley Wickham wrote:
>
>> call("function", [...]) calls the "function" function, which itself takes 2
>> arguments: the list of formal args and the function body.
>> eval of this call returns the newly constructed function, which you assign
>> to f. Then you assign the parent.frame() as the environment of f, except
>> with the symbol FUN assigned as the original argument FUN.
>>
>> However, upon looking at the debugger, I find that env$FUN<-FUN assigns FUN
>> in Global Scope if Curry is called from the top level.
>> A nested Curry call then creates FUN=function(...) FUN([...]), a recursive
>> infinite loop.
> Yes, that was a really bad idea - not sure why I didn't see the
> problems when I first wrote it.


From simon.urbanek at r-project.org  Wed May 30 20:51:48 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 30 May 2012 14:51:48 -0400
Subject: [Rd] fractional seconds in POSIXct
In-Reply-To: <87k3ztpmbg.fsf@kolob.subpolar.dyndns.org>
References: <87k3ztpmbg.fsf@kolob.subpolar.dyndns.org>
Message-ID: <700C7C6F-4F54-417F-83BB-87EBC6072236@r-project.org>


On May 30, 2012, at 2:15 PM, Sebastian P. Luque wrote:

> Hi,
> 
> Using the following simple character vector representing a time series
> with fractional seconds:
> 
> datetime <- c("20/09/2011 13:00:59.00", "20/09/2011 13:00:59.02",
>              "20/09/2011 13:00:59.04")
> 
> Conversion to POSIXct runs into problems; the second element is not
> interpreted correctly:
> 
> ---<--------------------cut here---------------start------------------->---
> R> as.POSIXct(strptime(datetime, format="%d/%m/%Y %H:%M:%OS"), tz="GMT")
> [1] "2011-09-20 13:00:59.00 GMT" "2011-09-20 13:00:59.01 GMT" "2011-09-20 13:00:59.03 GMT"
> R> sessionInfo()
> R version 2.15.0 (2012-03-30)
> Platform: x86_64-pc-linux-gnu (64-bit)
> 
> locale:
> [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C               LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8     LC_MONETARY=en_CA.UTF-8   
> [6] LC_MESSAGES=en_CA.UTF-8    LC_PAPER=C                 LC_NAME=C                  LC_ADDRESS=C               LC_TELEPHONE=C            
> [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C       
> 
> attached base packages:
> [1] stats4    stats     graphics  grDevices utils     datasets  methods   base     
> 
> other attached packages:
> [1] diveMove_1.3.4      caTools_1.12        bitops_1.0-4.1      slmisc_0.9.2        latticeExtra_0.6-19 RColorBrewer_1.0-5  lattice_0.20-6     
> 
> loaded via a namespace (and not attached):
> [1] compiler_2.15.0 grid_2.15.0     tools_2.15.0   
> ---<--------------------cut here---------------end--------------------->---
> 
> Is this expected?

Yes, your dates are not exactly representable in FP and you are implicitly using %OS2 for display, so your values get truncated - to see it more clearly:

> t <- as.POSIXct(strptime(datetime, format="%d/%m/%Y %H:%M:%OS"), tz="GMT")
> format(t, "%d/%m/%Y %H:%M:%OS5")
[1] "20/09/2011 13:00:59.00000" "20/09/2011 13:00:59.01999" "20/09/2011 13:00:59.03999"
> format(t, "%d/%m/%Y %H:%M:%OS2")
[1] "20/09/2011 13:00:59.00" "20/09/2011 13:00:59.01" "20/09/2011 13:00:59.03"

If you round them you'll get what you expected:

> as.numeric(t) %% 60
[1] 59.00 59.02 59.04

or if you add a half fraction (effectively forcing rounding):

> format(t + 0.005, "%d/%m/%Y %H:%M:%OS2")
[1] "20/09/2011 13:00:59.00" "20/09/2011 13:00:59.02" "20/09/2011 13:00:59.04"

Cheers,
Simon



>  Thanks.
> 
> Cheers,
> 
> -- 
> Seb
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From elliott.forney at gmail.com  Thu May 31 00:32:32 2012
From: elliott.forney at gmail.com (Elliott Forney)
Date: Wed, 30 May 2012 16:32:32 -0600
Subject: [Rd] Out of date instructions to build R using MKL
In-Reply-To: <4FC5D413.9090004@stats.ox.ac.uk>
References: <1328886941.2325.23.camel@milan>
	<CAMTFtYLT978dRYpqN0s1sKu5-RoHofjToMNF9wnY-v=HtGTwhQ@mail.gmail.com>
	<4FC5D413.9090004@stats.ox.ac.uk>
Message-ID: <CAMTFtYLVKdU-UXC4AbcGFwyr7q4TDF+3nNw7w25ZsERO4B8oUw@mail.gmail.com>

My apologies!  I was looking at the current documentation and was
unable to find anything related to this topic in the mailing list
after Milan's question but you are correct.  I moved to the latest MKL
and from R-2.14.2 to R-2.15.0 this morning and it appears to build
fine now.

A few months ago I had to link against the GNU OpenMP library
(libgomp) instead of the intel OpenMP library (libiomp5) to avoid the
"double complex BLAS" error and I thought it would be worthwhile to
share this insight.

I do still think that

     MKL_LIB_PATH=/opt/intel/mkl/10.0.3.020/lib/em64t/

should be changed to

     MKL_LIB_PATH=/opt/intel/mkl/lib/intel64/

Looks like a lot can change in just a few months :)  Sorry again, next
time I will be sure to try the latest version.

Thanks,
  Elliott Forney

On Wed, May 30, 2012 at 2:02 AM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> Hmm, you replied to a message from February and there has been an R release
> since with a revised manual. ?That does say (even more clearly) that it
> refers to version 10.0 of MKL and there have been changes. ?And since than
> there had been a change (notified by an Intel engineer) about which version
> of OpenMP to use.
>
> In short, please always check the current documentation before posting (as
> the posting guide required of you).
>
>
> On 29/05/2012 21:10, Elliott Forney wrote:
>>
>> Yes, these instructions are no longer valid as there has been some
>> reorganization of the mkl libraries. ?The path
>> /opt/intel/mkl/10.0.3.020/lib/em64t/ is now
>> /opt/intel/mkl/lib/intel64. ?Also, the only libraries that need to be
>> included are:
>>
>> -lmkl_gf_lp64 -lmkl_gnu_thread -lmkl_core
>>
>> The trick to getting rid of the "double complex BLAS" error is to use
>> only the gnu compatible libraries (i.e. use mkl_gnu_thread instead of
>> iomp5). ?I believe the intel-only libraries use a different convention
>> to pass complex numbers between libraries built with fortran?
>> Thankfully this check detects the error instead of crashing at run
>> time.
>>
>> I used the following to build R-2.14.1 with MKL:
>>
>> export LD_LIBRARY_PATH=/opt/intel/mkl/lib/intel64
>> ./configure --prefix=/opt/R-2.14.1 --enable-threads=posix
>> --with-lapack --with-blas="-I/opt/intel/mkl/include
>> -L/opt/intel/mkl/lib/intel64 -lmkl_gf_lp64
>> -lmkl_gnu_thread -lmkl_core -fopenmp -lpthread -lm"
>>
>> Although a highly tuned BLAS may not help much for many applications,
>> I have seen several orders of magnitude performance improvement in
>> some of my work that uses matrix operations heavily and others in my
>> lab have experienced the same. ?Having R linked against MKL has been
>> HUGELY important for me personally.
>>
>> A custom tuned ATLAS works well too but I find it frustrating that it
>> needs to be re-tuned for each architecture I use (I tend to distribute
>> jobs in a heterogeneous environment).
>>
>> Thanks!
>> ? Elliott Forney
>>
>> On Fri, Feb 10, 2012 at 8:15 AM, Milan Bouchet-Valat<nalimilan at club.fr>
>> ?wrote:
>>>
>>> Hi!
>>>
>>> I've been playing with MKL for a few days and I noticed the instructions
>>> in the R Installation Administration manual [1] no longer apply. It
>>> seems that since version 10.0 (the one used by the manual),
>>> libmkl_lapack.so has been renamed/split (although the official
>>> explanations seem to imply this was already the case in 10.0 [2]).
>>>
>>> As a consequence, the instructions for dynamic linking no longer work
>>> with the last version (2011-sp1). This is also the case of what is
>>> explained on several sites like [3] or [4]. The manual's instructions to
>>> link statically to MKL still work fine, though.
>>>
>>> I'm merely signaling this fact to more clued people, since I've not been
>>> able to get R to dynamically link to MKL. I'm always getting this notice
>>> during ./configure:
>>>>
>>>> checking whether double complex BLAS can be used... no
>>>
>>>
>>> Anyways, one of the problems is also that it's no longer possible to
>>> make libRblas.so and libRlapack.so symlinks to the Intel libs, as they
>>> are split into several files.
>>>
>>> If nobody knows how or cares about to fix this ATM, a simple warning
>>> that the instructions are outdated would already improve the situation,
>>> as it took me some time to understand things had changed and I wasn't
>>> just being silly. ;-)
>>>
>>> (That said, I'm not convinced using an external BLAS/LAPACK is really
>>> interesting for standard desktops. Performances gains compared to
>>> default packages are incredible in benchmarks, but for real use cases
>>> multi-threading often makes things slower - at least for me, using gnm.
>>> I guess this is mostly interesting for very larges matrices, and not for
>>> many repeated small operations.)
>
>
> And that is well-attested, including in the R manuals.
>
>
>>>
>>> Regards
>>>
>>>
>>> 1: http://cran.r-project.org/doc/manuals/R-admin.html#MKL
>>> 2: http://software.intel.com/en-us/forums/showthread.php?t=81302
>>> 3:
>>> http://www.r-bloggers.com/compiling-64-bit-r-2-10-1-with-mkl-in-linux/
>>> 4: http://www.rd.dnc.ac.jp/~otsu/lecture/RwithMKL.html
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
> --
> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595


From hb at biostat.ucsf.edu  Thu May 31 00:34:16 2012
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Wed, 30 May 2012 15:34:16 -0700
Subject: [Rd] R CMD check: Sys.getenv("R_GSCMD") cannot contain full
 pathname (contrary to docs)
In-Reply-To: <CAFDcVCTR0YdHxRBQ+YOt=YzLSmj5g27HpvPF1Jk9R9LQ47vLXA@mail.gmail.com>
References: <CAFDcVCTR0YdHxRBQ+YOt=YzLSmj5g27HpvPF1Jk9R9LQ47vLXA@mail.gmail.com>
Message-ID: <CAFDcVCSox=E7Srr=AQ=oL8Bw+MpgLKYJH5ZkMvgFPih4Srx6pw@mail.gmail.com>

Bump, in case it was missed.  This is also the case with R Under
development (unstable) (2012-05-25 r59443).  /Henrik

On Fri, Apr 20, 2012 at 2:00 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> Hi,
>
> in help("R_GSCMD") it says "R_GSCMD: Optional. The path to
> Ghostscript, used by dev2bitmap, bitmap and embedFonts. Consulted when
> those functions are invoked.". ?However, if 'R_GSCMD' contains a full
> pathname to the Ghostscript executable (as above "path" indicates),
> e.g.
>
>> Sys.getenv("R_GSCMD")
> [1] "C:\\Program Files\\gs\\gs8.71\\bin\\gswin32c.exe"
>
> then 'R CMD check' will report
>
> * checking sizes of PDF files under 'inst/doc' ... NOTE
> Unable to find GhostScript executable to run checks on size reduction
>
> Setting 'R_GSCMD' to "gswin32c.exe" and asserting that it is the PATH
> (this is on Windows), it works.
>
>
> TROUBLESHOOTING:
> In the local function check_doc_size() of tools:::.check_packages()
> [cf. http://svn.r-project.org/R/trunk/src/library/tools/R/check.R],
> the Ghostscript executable is retrieved as:
>
> ?gs_cmd <- find_gs_cmd(Sys.getenv("R_GSCMD", ""))
>
> and if nzchar(gs_cmd) is FALSE, then the 'R CMD check' NOTE appears.
> Inspecting tools:::find_gs_cmd, this corresponds to
>
> ?gs_cmd <- Sys.which(Sys.getenv("R_GSCMD", ""))
>
> iff 'R_GSCMD' is set. ?In other words, tools:::find_gs_cmd() assumes a
> basename not a full pathname.
>
>
> SUGGESTIONS:
> Update tools:::find_gs_cmd() to test for file existence before turning
> to Sys.which(), e.g.
>
> find_gs_cmd <- function (gs_cmd)
> {
> ? ?if (!nzchar(gs_cmd)) {
> ? ? ? ?if (.Platform$OS.type == "windows") {
> ? ? ? ? ? ?gs_cmd <- Sys.which("gswin64c")
> ? ? ? ? ? ?if (!nzchar(gs_cmd))
> ? ? ? ? ? ? ? ?gs_cmd <- Sys.which("gswin32c")
> ? ? ? ? ? ?gs_cmd
> ? ? ? ?}
> ? ? ? ?else Sys.which("gs")
> ? ?} else {
> ? ? ?if (file.exists(gs_cmd) && !file.info(gs_cmd)$isdir)
> ? ? ? ?gs_cmd
> ? ? ?else
> ? ? ? ?Sys.which(gs_cmd)
> ? }
> }
>
>
> /Henrik
>
>> sessionInfo()
> R version 2.15.0 Patched (2012-04-08 r58935)
> Platform: x86_64-pc-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
> loaded via a namespace (and not attached):
> [1] R.methodsS3_1.4.0 tools_2.15.0


From ronggui.huang at gmail.com  Thu May 31 08:04:59 2012
From: ronggui.huang at gmail.com (Wincent)
Date: Thu, 31 May 2012 14:04:59 +0800
Subject: [Rd] possible bug in "R Editor"
Message-ID: <CANQBBMuPcZKJHs2+UtSQtNbq9gHXzEg28O7+=TuxHUYOzmPobQ@mail.gmail.com>

Dear all,

I clicked "File-New Script" to open a R Editor, typed some commands in
it and then saved it to a file. If the location where I tried to save
the script contained Chinese Character, R Editor complained,

Error: invalid input 'E:\Some.Chinese.Characters\new_file.R' in 'utf8towcs'


> sessionInfo()
R version 2.15.0 (2012-03-30)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=Chinese (Simplified)_People's Republic of China.936
[2] LC_CTYPE=Chinese (Simplified)_People's Republic of China.936
[3] LC_MONETARY=Chinese (Simplified)_People's Republic of China.936
[4] LC_NUMERIC=C
[5] LC_TIME=Chinese (Simplified)_People's Republic of China.936

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_2.15.0

-- 
Wincent Ronggui HUANG
Sociology Department of Fudan University
PhD of City University of Hong Kong
http://homepage.fudan.edu.cn/rghuang/cv/


From ripley at stats.ox.ac.uk  Thu May 31 18:50:29 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 31 May 2012 17:50:29 +0100
Subject: [Rd] possible bug in "R Editor"
In-Reply-To: <CANQBBMuPcZKJHs2+UtSQtNbq9gHXzEg28O7+=TuxHUYOzmPobQ@mail.gmail.com>
References: <CANQBBMuPcZKJHs2+UtSQtNbq9gHXzEg28O7+=TuxHUYOzmPobQ@mail.gmail.com>
Message-ID: <4FC7A155.1090504@stats.ox.ac.uk>

On 31/05/2012 07:04, Wincent wrote:
> Dear all,
>
> I clicked "File-New Script" to open a R Editor, typed some commands in
> it and then saved it to a file. If the location where I tried to save
> the script contained Chinese Character, R Editor complained,
>
> Error: invalid input 'E:\Some.Chinese.Characters\new_file.R' in 'utf8towcs'
>
>
>> sessionInfo()
> R version 2.15.0 (2012-03-30)
> Platform: i386-pc-mingw32/i386 (32-bit)
>
> locale:
> [1] LC_COLLATE=Chinese (Simplified)_People's Republic of China.936
> [2] LC_CTYPE=Chinese (Simplified)_People's Republic of China.936
> [3] LC_MONETARY=Chinese (Simplified)_People's Republic of China.936
> [4] LC_NUMERIC=C
> [5] LC_TIME=Chinese (Simplified)_People's Republic of China.936
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_2.15.0

It is not a bug in the editor. It may be a bug in iconv or other parts 
of the handling of wide characters in the save routine.  I can see how 
the code can be simplified, but we really need to be able to reproduce 
this, and surely that was not the real example.  (One of the problems is 
that the editor title has to be in the native encoding, so this has to 
be done in a Chinese version of Windows.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Avraham.Adler at guycarp.com  Thu May 31 18:44:51 2012
From: Avraham.Adler at guycarp.com (Adler, Avraham)
Date: Thu, 31 May 2012 11:44:51 -0500
Subject: [Rd] R Installation Manual - ATLAS BLAS guidance that is not in
 the current version
In-Reply-To: <E2263553A9D87A41A3E0E1B6FA4F19CACA9608AF@USDFW11XM32.mercer.com>
References: <E2263553A9D87A41A3E0E1B6FA4F19CACA9608AF@USDFW11XM32.mercer.com>
Message-ID: <93A2161604A30C4ABE14AC35CAFC8422B9DD43BA@USDFW11XM32.mercer.com>

I apologize for the late response, but I missed Professor Ripley's reply. For what it is worth, I have successfully compiled a 32-bit ATLAS-based BLAS for Windows for the Core-i7 that passes the make checks and library tools tests (which may be found at <http://lib.stat.cmu.edu/R/CRAN/bin/windows/contrib/ATLAS/C2i7/> for those interested in either testing or using it). Using this BLAS, I find a speedup of around 500% for matrix multiplications of 1000x1000 dense matrices. Unfortunately, in the environment in which I operate, I am currently constrained to a 32-bit operating system. If and when the transition is made to 64bit, I will gladly use  Professor Nakama's versions, although none of them are optimized for Core i7 (Sandy Bridge or otherwise) CPUs. 

As the necessity to remove the xerbla remains, and implementing it does allow for the proper compilation of R under Windows, I will just have to archive that information myself and use it the next time I need to update the BLAS. I am thankful that the Windows-based MAKEFILE still allows for the compilation of Rblas.dll linking to an ATLAS-based BLAS, and although I regret that the manuals will no longer contain that information, I certainly defer to the expertise and experience of those much more knowledgeable than I in matters programming, compilation, and R.

Thank you,

Avraham Adler


