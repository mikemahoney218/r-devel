From maechler at stat.math.ethz.ch  Tue Nov  1 00:12:24 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 1 Nov 2011 00:12:24 +0100
Subject: [Rd] R CMD check and error in an \Sexpr in an Rd file
In-Reply-To: <CAC2h7uu+NPQA9FcapcvnNk9Ao4mRT0vNg6yderVB_Yf_9uCfsw@mail.gmail.com>
References: <4EAAC0DF.7060704@cbio.uct.ac.za> <4EAAC1F3.8020505@gmail.com>
	<4EAAC96A.2020803@gmail.com> <4EAE90FC.7010200@cbio.uct.ac.za>
	<4EAE926B.6040102@statistik.tu-dortmund.de>
	<4EAE9345.5000209@cbio.uct.ac.za>
	<alpine.LFD.2.02.1110311225400.19333@gannet.stats.ox.ac.uk>
	<4EAE981B.2090101@cbio.uct.ac.za>
	<20142.49614.800768.930561@stat.math.ethz.ch>
	<CAC2h7uu+NPQA9FcapcvnNk9Ao4mRT0vNg6yderVB_Yf_9uCfsw@mail.gmail.com>
Message-ID: <CAPRP4-ezHh4_zmpPi4NmX1zy_bnp7_TTSLm9jiKbfTQhnLM_3A@mail.gmail.com>

Hi Kasper,

On Mon, Oct 31, 2011 at 16:55, Kasper Daniel Hansen
<kasperdanielhansen at gmail.com> wrote:
>
> Martin,
>
> I am pretty sure (but I will probably be proven wrong) that when
> r-announce was created it was stated that every email got sent to both
> r-help and r-devel,

Hmm, I don't believe you.? To the contrary, I'd even bet a bit on
that.?? Always to R-help, but not to R-devel,...
If you have real proof please "present" it..
(but this *is* getting off-topic...? we should probably continue off-R-devel ..)

Martin

>
> and I see I have received emails from r-announce
> in the past despite only being subscribed to r-devel and not r-help.
> For example, I can find the announcement of R-2.13.0 (posted by P
> Dalgaard) (and many earlier versions), but not R-2.13.1. ?While I am
> pretty sure I have only subscribed to r-help for a brief period many
> years ago, I did switch my r-devel subscription from one email address
> to another.
>
> I infer from your email that r-announce emails are no longer sent to
> r-devel subscribers (which is consistent with the text on
> ?https://stat.ethz.ch/mailman/listinfo/r-announce
> ).
>
> Kasper
>
>
> On Mon, Oct 31, 2011 at 11:42 AM, Martin Maechler
> <maechler at stat.math.ethz.ch> wrote:
> >
> > ? ?> Thank you very much Duncan, Uwe and Peter. ?Sorry if I
> > ? ?> missed the announcement, I follow more r-devel than
> > ? ?> r-help, which I find a bit hard to quickly read.
> >
> > But please --- this concerns every one on R-devel ---
> > if you do not subscribe to R-help,
> > then do subscribe to R-announce -- that one has about
> > one posting *per month* and is really only for important
> > announcements (and basically reserved for R-core to post).
> >
> > See a list of *all* ?R-announce postings of ?2011 :
> >
> > ?https://stat.ethz.ch/pipermail/r-announce/2011/date.html
> >
> > with the 2.14.0 announcement at the end.
> >
> > Martin Maechler, ETH Zurich
> >
> >
> > ? ?> Will try now on the 2.14.0.
> >
> > ? ?> Renaud
> >
> > ? ?> On 31/10/2011 14:28, Prof Brian Ripley wrote:
> > ? ?>> On Mon, 31 Oct 2011, Renaud Gaujoux wrote:
> > ? ?>>
> > ? ?>>> I do not see it on main CRAN home page.
> > ? ?>>
> > ? ?>> No, but see the announcement on R-announce this morning:
> > ? ?>> https://stat.ethz.ch/pipermail/r-help/2011-October/294203.html
> > ? ?>>
> > ? ?>> Things which need human intervention can take some hours:
> > ? ?>> the CRAN front page and binary distributions are two of
> > ? ?>> those.
> > ? ?>>
> > ? ?>>> Do you mean
> > ? ?>>> http://cran.r-project.org/src/base-prerelease/R-latest.tar.gz
> > ? ?>>> ?
> > ? ?>>>
> > ? ?>>> On 31/10/2011 14:19, Uwe Ligges wrote:
> > ? ?>>>>
> > ? ?>>>>
> > ? ?>>>> On 31.10.2011 13:13, Renaud Gaujoux wrote:
> > ? ?>>>>> Thank you Duncan.
> > ? ?>>>>>
> > ? ?>>>>> I tried with: * using R version 2.14.0 RC (2011-10-24
> > ? ?>>>>> r57417) * using platform: x86_64-unknown-linux-gnu
> > ? ?>>>>> (64-bit)
> > ? ?>>>>>
> > ? ?>>>>> But I still get the errors for verbatim multiline and
> > ? ?>>>>> the strange error if an error occurs in \Sexpr. ?Is
> > ? ?>>>>> your patch included in this version? I will try now
> > ? ?>>>>> with R-rc_2011-10-27_r57452.tar.gz.
> > ? ?>>>>
> > ? ?>>>> Try R-2.14.0, it is already released. Or R-devel.
> > ? ?>>>>
> > ? ?>>>> Best, Uwe Ligges
> > ? ?>>>>
> > ? ?>>>>
> > ? ?>>>>>
> >>>>> Renaud
> >>>>>
> >>>>> On 28/10/2011 17:25, Duncan Murdoch wrote:
> >>>>>> On 28/10/2011 10:53 AM, Duncan Murdoch wrote:
> >>>>>>> On 28/10/2011 10:49 AM, Renaud Gaujoux wrote:
> >>>>>>> > Hi,
> >>>>>>> >
> >>>>>>> > another Rd related issue I encountered is that if an error occurs
> >>>>>>> in an
> >>>>>>> > \Sexpr in an Rd file, then on get the following error:
> >>>>>>> >
> >>>>>>> > * checking for portable compilation flags in Makevars ... OK
> >>>>>>> > * checking for portable use of $(BLAS_LIBS) and $(LAPACK_LIBS)
> >>>>>>> ... OK
> >>>>>>> > * checking examples ... ERROR
> >>>>>>> > Error in paste(before, x, after, sep = "") : object 'exfile'
> >>>>>>> not found
> >>>>>>> > Execution halted
> >>>>>>> >
> >>>>>>> > To reproduce, put a call like this in an Rd section:
> >>>>>>> >
> >>>>>>> > \Sexpr[results=verbatim, stage=render]{x<- 1; stop("sexpr error")}
> >>>>>>> >
> >>>>>>> > The strange thing is that it occurs at the example checking step.
> >>>>>>> > Not sure why it does not break before.
> >>>>>>> >
> >>>>>>> > Thank you.
> >>>>>>> >
> >>>>>>> > Renaud
> >>>>>>> >
> >>>>>>> > PS: I am on R version 2.13.2 (2011-09-30) - x86_64-pc-linux-gnu
> >>>>>>> (64-bit)
> >>>>>>> >
> >>>>>>>
> >>>>>>> I would update to 2.13.2 patched, or the release candidate of
> >>>>>>> 2.14.0.
> >>>>>>
> >>>>>> Oops, sorry, 2.13.2 is "final", so I didn't backport the patch.
> >>>>>> 2.14.0
> >>>>>> is what you should get.
> >>>>>>
> >>>>>> Duncan Murdoch
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-devel at r-project.org mailing list
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>
> >>> ______________________________________________
> >>> R-devel at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>
> >>
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>


From hintak_leung at yahoo.co.uk  Tue Nov  1 00:52:43 2011
From: hintak_leung at yahoo.co.uk (Hin-Tak Leung)
Date: Mon, 31 Oct 2011 23:52:43 +0000 (GMT)
Subject: [Rd] Sweave, cairo_pdf, xetex, CJK (Re:  Sweave, cairo_pdf, CJK,
	ghostscript)
In-Reply-To: <1F45FA64-761D-432C-A523-8FE402FE127F@r-project.org>
Message-ID: <1320105163.3506.YahooMailClassic@web29504.mail.ird.yahoo.com>

--- On Mon, 31/10/11, Simon Urbanek <simon.urbanek at r-project.org> wrote:

> On Oct 31, 2011, at 5:56 PM, Hin-Tak Leung wrote:
> 
> > I am still doing some cosmetic things (adding
> annotations with some of the really minority languages in
> Sichuan), but here are a few misc tips and quirks so far:
> > 
> > - cairo_pdf() behaves differently via "R CMD Sweave
> <file>" vs Sweave("file") within R. The former
> produces a lot of warnings about not being able to determine
> strwidth and have to substitute. Probably understandable,
> but still annoying.
> > 
> > - It generates pdf 1.5 - when used in combination with
> xetex, - which uses xdvipdfmx for pdf generation, and
> xdvipdfmx has the rather disturbing behavior of *silently*
> *skipping* included pdf's that's higher than the default
> (instead of do it with warning like pdfTeX) so no graphics
> will be included, unless xetex is run with
> -output-driver="xdvipdfmx -V 5"... to declare to output pdf
> 1.5 .
> > 
> > - xetex needs noae in \usepackage{SWeave}. FWIW,
> Werner Lemberg's CJK (the LaTeX package) can work without
> declaring noae, so that's my preferred choice at the moment,
> although I have got both of them working, for doing Chinese
> in a LaTeX document.
> > 
> > I think some of these information should go into the
> man page of cairo_pdf()...
> > 
> 
> Well, I don't see how most of the above is in any way
> relevant. What PDF gets generated really depends on the
> cairo version you are using, not on R. Only most recent
> versions of Cairo (1.10.x) switched the format to PDF-1.5
> and added format restriction functions, they are not
> available in general. In addition, PDF-1.5 is 8 years old,
> so whatever tools can't deal with it are seriously out of
> date.

That's ignorant. In terms of visual elements and desktop publishing, the last major change in the pdf specification was 1.4, which introduces transparency. Most open-source pdf rendering capbalities are based on either ghostscript or xpdf/libpoppler . (TexLive/xetex/xdvipdfmx in the latter camp). Granted the developer od xdivpdfmx made a strange decision - the pdf specification explicitly state that renderers/readers should ignore features they don't understand and make "best effort" rather than abort, but what you claimed - "whatever tools cannot cannot deal with [PDF-1.5] are seriously out of date" is utterly wrong: neither ghostscript nor libpopper supports that fully. And I wonder what "tools" you use (other than Acrobat) are not based on those two.

FWIW, have a look at ghostscript's bug database, and search for "cairo".


From simon.urbanek at r-project.org  Tue Nov  1 01:37:12 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 31 Oct 2011 20:37:12 -0400
Subject: [Rd] Sweave, cairo_pdf, xetex, CJK (Re:  Sweave, cairo_pdf, CJK,
	ghostscript)
In-Reply-To: <1320105163.3506.YahooMailClassic@web29504.mail.ird.yahoo.com>
References: <1320105163.3506.YahooMailClassic@web29504.mail.ird.yahoo.com>
Message-ID: <CDE936C4-192F-4362-AAD9-CA2A88788297@r-project.org>


On Oct 31, 2011, at 7:52 PM, Hin-Tak Leung wrote:

> --- On Mon, 31/10/11, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> 
>> On Oct 31, 2011, at 5:56 PM, Hin-Tak Leung wrote:
>> 
>>> I am still doing some cosmetic things (adding
>> annotations with some of the really minority languages in
>> Sichuan), but here are a few misc tips and quirks so far:
>>> 
>>> - cairo_pdf() behaves differently via "R CMD Sweave
>> <file>" vs Sweave("file") within R. The former
>> produces a lot of warnings about not being able to determine
>> strwidth and have to substitute. Probably understandable,
>> but still annoying.
>>> 
>>> - It generates pdf 1.5 - when used in combination with
>> xetex, - which uses xdvipdfmx for pdf generation, and
>> xdvipdfmx has the rather disturbing behavior of *silently*
>> *skipping* included pdf's that's higher than the default
>> (instead of do it with warning like pdfTeX) so no graphics
>> will be included, unless xetex is run with
>> -output-driver="xdvipdfmx -V 5"... to declare to output pdf
>> 1.5 .
>>> 
>>> - xetex needs noae in \usepackage{SWeave}. FWIW,
>> Werner Lemberg's CJK (the LaTeX package) can work without
>> declaring noae, so that's my preferred choice at the moment,
>> although I have got both of them working, for doing Chinese
>> in a LaTeX document.
>>> 
>>> I think some of these information should go into the
>> man page of cairo_pdf()...
>>> 
>> 
>> Well, I don't see how most of the above is in any way
>> relevant. What PDF gets generated really depends on the
>> cairo version you are using, not on R. Only most recent
>> versions of Cairo (1.10.x) switched the format to PDF-1.5
>> and added format restriction functions, they are not
>> available in general. In addition, PDF-1.5 is 8 years old,
>> so whatever tools can't deal with it are seriously out of
>> date.
> 
> That's ignorant.

Oh, really? I'll leave it to you to verify the canonical source (Adobe) which lists PDF 1.5 as released in August 2003, more than 8 years ago. Please check you facts before making such obviously incorrect statements.

Cheers,
Simon


> In terms of visual elements and desktop publishing, the last major change in the pdf specification was 1.4, which introduces transparency. Most open-source pdf rendering capbalities are based on either ghostscript or xpdf/libpoppler . (TexLive/xetex/xdvipdfmx in the latter camp). Granted the developer od xdivpdfmx made a strange decision - the pdf specification explicitly state that renderers/readers should ignore features they don't understand and make "best effort" rather than abort, but what you claimed - "whatever tools cannot cannot deal with [PDF-1.5] are seriously out of date" is utterly wrong: neither ghostscript nor libpopper supports that fully. And I wonder what "tools" you use (other than Acrobat) are not based on those two.
> 
> FWIW, have a look at ghostscript's bug database, and search for "cairo".
> 
> 


From hintak_leung at yahoo.co.uk  Tue Nov  1 02:13:07 2011
From: hintak_leung at yahoo.co.uk (Hin-Tak Leung)
Date: Tue, 1 Nov 2011 01:13:07 +0000 (GMT)
Subject: [Rd] Sweave, cairo_pdf, xetex, CJK (Re:  Sweave, cairo_pdf, CJK,
	ghostscript)
In-Reply-To: <1F45FA64-761D-432C-A523-8FE402FE127F@r-project.org>
Message-ID: <1320109987.83892.YahooMailClassic@web29511.mail.ird.yahoo.com>

--- On Mon, 31/10/11, Simon Urbanek <simon.urbanek at r-project.org> wrote:

> Well, I don't see how most of the above is in any way
> relevant. What PDF gets generated really depends on the
> cairo version you are using, not on R. Only most recent
> versions of Cairo (1.10.x) switched the format to PDF-1.5
> and added format restriction functions, they are not
> available in general. In addition, PDF-1.5 is 8 years old,
> so whatever tools can't deal with it are seriously out of
> date.

You have completely missed the point. Have a look at both ghostscript's and libpoppler's bug database: neither's support of PDF *1.4* is complete, and that's what, over 10 years old. And I hope you do not used either of them in any form. TeXLive/Evince/xpdf/kpdf/okular used the latter, and linux-based printing used the former.


From moshersteven at gmail.com  Tue Nov  1 04:36:56 2011
From: moshersteven at gmail.com (steven mosher)
Date: Mon, 31 Oct 2011 20:36:56 -0700
Subject: [Rd] weird error
Message-ID: <CAFFLneTS_v2atQ3jbYJDFcVS-Xiad1YSUYHUxxozbr_eLpHmYw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111031/141b3f67/attachment.pl>

From moshersteven at gmail.com  Tue Nov  1 04:47:58 2011
From: moshersteven at gmail.com (steven mosher)
Date: Mon, 31 Oct 2011 20:47:58 -0700
Subject: [Rd] weird error
In-Reply-To: <CAFFLneTS_v2atQ3jbYJDFcVS-Xiad1YSUYHUxxozbr_eLpHmYw@mail.gmail.com>
References: <CAFFLneTS_v2atQ3jbYJDFcVS-Xiad1YSUYHUxxozbr_eLpHmYw@mail.gmail.com>
Message-ID: <CAFFLneTCQYxoe2BQ953Hz5UxVORPjy-F_FxT9ssFHBp9TZdqdQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111031/6cd61c85/attachment.pl>

From renaud at mancala.cbio.uct.ac.za  Tue Nov  1 11:22:30 2011
From: renaud at mancala.cbio.uct.ac.za (Renaud Gaujoux)
Date: Tue, 01 Nov 2011 12:22:30 +0200
Subject: [Rd] R CMD check and error in an \Sexpr in an Rd file
In-Reply-To: <4EAAC96A.2020803@gmail.com>
References: <4EAAC0DF.7060704@cbio.uct.ac.za> <4EAAC1F3.8020505@gmail.com>
	<4EAAC96A.2020803@gmail.com>
Message-ID: <4EAFC866.6040803@cbio.uct.ac.za>

Getting back to the \Sexpr issue, I tried with R-2.14.0 and I still see 
the following issues:

- verbatim multiline is not shown properly on PDF 
(\Sexpr[results=verbatim, stage=render]{cat("line\nnext line")})
- verbatim with empty lines breaks PDF generation 
(\Sexpr[results=verbatim, stage=render]{cat("line\nnext line\n\nyet 
another line")}). Would there be an issue in using a plain Latex 
verbatim environment for \Sexpr[results=verbatim]?

- an error in an \Sexpr (\Sexpr[results=verbatim, 
stage=render]{stop("error in sexpr")}) gives the following in R CMD check:

* checking examples ... ERROR
Error in paste(before, x, after, sep = "") : object 'exfile' not found
Execution halted

The two first issues can be reproduced with a call to R CMD Rd2pdf on 
the Rd code below.

Thank you.
Renaud.

%%%%%%%%%%%
\name{Sexpr}
\alias{Sexpr}
\title{Error and verbatim in Sexpr}
\description{
   Testing Sexpr in Rd files

   %\Sexpr[results=verbatim, stage=render]{stop("error in sexpr")}

   \Sexpr[results=verbatim, stage=render]{cat("line\nnext line")}

   %\Sexpr[results=verbatim, stage=render]{cat("line\nnext line\n\nyet 
another line")}
}
%%%%%%%%%%%



-- 
Renaud Gaujoux
Computational Biology - University of Cape Town
South Africa


On 28/10/2011 17:25, Duncan Murdoch wrote:
> On 28/10/2011 10:53 AM, Duncan Murdoch wrote:
>> On 28/10/2011 10:49 AM, Renaud Gaujoux wrote:
>> >  Hi,
>> >
>> >  another Rd related issue I encountered is that if an error occurs 
>> in an
>> >  \Sexpr in an Rd file, then on get the following error:
>> >
>> >  * checking for portable compilation flags in Makevars ... OK
>> >  * checking for portable use of $(BLAS_LIBS) and $(LAPACK_LIBS) ... OK
>> >  * checking examples ... ERROR
>> >  Error in paste(before, x, after, sep = "") : object 'exfile' not 
>> found
>> >  Execution halted
>> >
>> >  To reproduce, put a call like this in an Rd section:
>> >
>> >  \Sexpr[results=verbatim, stage=render]{x<- 1; stop("sexpr error")}
>> >
>> >  The strange thing is that it occurs at the example checking step.
>> >  Not sure why it does not break before.
>> >
>> >  Thank you.
>> >
>> >  Renaud
>> >
>> >  PS: I am on R version 2.13.2 (2011-09-30) - x86_64-pc-linux-gnu 
>> (64-bit)
>> >
>>
>> I would update to 2.13.2 patched, or the release candidate of 2.14.0.
>
> Oops, sorry, 2.13.2 is "final", so I didn't backport the patch.  
> 2.14.0 is what you should get.
>
> Duncan Murdoch


From georgi.boshnakov at manchester.ac.uk  Tue Nov  1 12:36:22 2011
From: georgi.boshnakov at manchester.ac.uk (Georgi Boshnakov)
Date: Tue, 1 Nov 2011 11:36:22 +0000
Subject: [Rd] R CMD check and error in an \Sexpr in an Rd file
Message-ID: <438D2EC9EAFE5946B2D5864670EA468E0823F6@MBXP01.ds.man.ac.uk>

Dear Renaud,

> Getting back to the \Sexpr issue, I tried with R-2.14.0 and I still see
> the following issues:
>
> - verbatim multiline is not shown properly on PDF
> (\Sexpr[results=verbatim, stage=render]{cat("line\nnext line")})

You probably meant to use `paste', not `cat'. 
The latter sends its output  somewhere and returns NULL, not the string. 

Best,
Georgi



--
Dr Georgi Boshnakov               tel: (+44) (0)161 306 3684
School of Mathematics             fax: (+44) (0)161 306 3669
Alan Turing Building 1.125
The University of Manchester      email: Georgi.Boshnakov at manchester.ac.uk
Oxford Road
Manchester M13 9PL
UK


------------------------------

Message: 18
Date: Tue, 01 Nov 2011 12:22:30 +0200
From: Renaud Gaujoux <renaud at mancala.cbio.uct.ac.za>
To: Duncan Murdoch <murdoch.duncan at gmail.com>
Cc: Renaud Gaujoux <renaud at mancala.cbio.uct.ac.za>,
        "r-devel at r-project.org" <r-devel at r-project.org>
Subject: Re: [Rd] R CMD check and error in an \Sexpr in an Rd file
Message-ID: <4EAFC866.6040803 at cbio.uct.ac.za>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed

Getting back to the \Sexpr issue, I tried with R-2.14.0 and I still see
the following issues:

- verbatim multiline is not shown properly on PDF
(\Sexpr[results=verbatim, stage=render]{cat("line\nnext line")})
- verbatim with empty lines breaks PDF generation
(\Sexpr[results=verbatim, stage=render]{cat("line\nnext line\n\nyet
another line")}). Would there be an issue in using a plain Latex
verbatim environment for \Sexpr[results=verbatim]?

- an error in an \Sexpr (\Sexpr[results=verbatim,
stage=render]{stop("error in sexpr")}) gives the following in R CMD check:

* checking examples ... ERROR
Error in paste(before, x, after, sep = "") : object 'exfile' not found
Execution halted

The two first issues can be reproduced with a call to R CMD Rd2pdf on
the Rd code below.

Thank you.
Renaud.

%%%%%%%%%%%
\name{Sexpr}
\alias{Sexpr}
\title{Error and verbatim in Sexpr}
\description{
   Testing Sexpr in Rd files

   %\Sexpr[results=verbatim, stage=render]{stop("error in sexpr")}

   \Sexpr[results=verbatim, stage=render]{cat("line\nnext line")}

   %\Sexpr[results=verbatim, stage=render]{cat("line\nnext line\n\nyet
another line")}
}
%%%%%%%%%%%



--
Renaud Gaujoux
Computational Biology - University of Cape Town
South Africa


On 28/10/2011 17:25, Duncan Murdoch wrote:
> On 28/10/2011 10:53 AM, Duncan Murdoch wrote:
>> On 28/10/2011 10:49 AM, Renaud Gaujoux wrote:
>> >  Hi,
>> >
>> >  another Rd related issue I encountered is that if an error occurs
>> in an
>> >  \Sexpr in an Rd file, then on get the following error:
>> >
>> >  * checking for portable compilation flags in Makevars ... OK
>> >  * checking for portable use of $(BLAS_LIBS) and $(LAPACK_LIBS) ... OK
>> >  * checking examples ... ERROR
>> >  Error in paste(before, x, after, sep = "") : object 'exfile' not
>> found
>> >  Execution halted
>> >
>> >  To reproduce, put a call like this in an Rd section:
>> >
>> >  \Sexpr[results=verbatim, stage=render]{x<- 1; stop("sexpr error")}
>> >
>> >  The strange thing is that it occurs at the example checking step.
>> >  Not sure why it does not break before.
>> >
>> >  Thank you.
>> >
>> >  Renaud
>> >
>> >  PS: I am on R version 2.13.2 (2011-09-30) - x86_64-pc-linux-gnu
>> (64-bit)
>> >
>>
>> I would update to 2.13.2 patched, or the release candidate of 2.14.0.
>
> Oops, sorry, 2.13.2 is "final", so I didn't backport the patch.
> 2.14.0 is what you should get.
>
> Duncan Murdoch



------------------------------

_______________________________________________
R-devel at r-project.org mailing list  DIGESTED
https://stat.ethz.ch/mailman/listinfo/r-devel


End of R-devel Digest, Vol 105, Issue 1
***************************************


From mtmorgan at fhcrc.org  Tue Nov  1 14:37:07 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Tue, 01 Nov 2011 06:37:07 -0700
Subject: [Rd] Question about copying reference objects using the
 initialize method
In-Reply-To: <CAGnmr57=uxTf+7POZ6=gOOuu5h4RmLJ_4VD1SvuhR1NtAaXuFQ@mail.gmail.com>
References: <CAGnmr57=uxTf+7POZ6=gOOuu5h4RmLJ_4VD1SvuhR1NtAaXuFQ@mail.gmail.com>
Message-ID: <4EAFF603.80902@fhcrc.org>

On 10/31/2011 08:53 AM, Aleix Ruiz de Villa wrote:
> Dears,
>
> I have a question about copying reference objects using the initialize method.
>
> 1) If the latter has no arguments, there is no problem to copy an object.
>
> myClass = setRefClass("myClass", fields = list(value = "numeric") )
>
> myClass$methods(initialize = function(...){
>
>    value<<- 1
>
>    callSuper(...)
> })
>
> newObject = myClass$new()
> newObject$value = 2
> copyObject = newObject$copy()
> copyObject$value = 3
> print(newObject$value)
> print(copyObject$value)
>
>
> 2) However, if the initialize method has arguments, I get an error:
>
> myClass = setRefClass("myClass", fields = list(value = "numeric") )
> myClass$methods(initialize = function(extValue, ...){
>
>    value<<- extValue
>
>    callSuper(...)
> })
> newObject = myClass$new(extValue = 2)
> copyObject = newObject$copy()
>
> Error in .Object$initialize(...) :
>    argument "extValue" is missing, with no default
>
>
> I understand that copy() first builds another instance of the object
> and then copies the fields. But it calls new without arguments...
>
> 3) One solution would be the initialize values by default
>
> myClass = setRefClass("myClass", fields = list(value = "numeric") )
>
> myClass$methods(initialize = function(extValue = 1, ...){
>
>    value<<- extValue
>
>    callSuper(...)
> })
>
> newObject = myClass$new(extValue = 2)
> copyObject = newObject$copy()
>
>
> But I have a long list of arguments, so this way would be a little
> uncomfortable. On the other hand, I've been told that in OOP, the idea
> of the initialise method is to use the minimum information to build
> the oject. So passing a long list of arguments is not a good idea.
>
>
> 4) Another option is to first build the object and then set the parameters
>
> myClass = setRefClass("myClass", fields = list(value = "numeric") )
>
> myClass$methods(setPar = function(extValue = 1, ...){
>
>    value<<- extValue
>
>    return()
> })
>
> newObject = myClass$new()
> newObject$setPar(extValue = 2)
> copyObject = newObject$copy()
>
>
> It works fine.
>
> Anyway I am curious to know if there is any way to use the initialize
> method with arguments that is not a problem with copy().

Hi Aleix --

 From ?setRefClass

           Initialization methods
           need some care in design, as they do for S4 classes. In
           particular, remember that others may subclass your class and
           pass through field assignments or other arguments.
           Therefore, your method should normally include ... as an
           argument, all other arguments should have defaults or check
           for missingness, and your method should pass all initialized
           values on via '$callSuper()' or '$initFields()' if you know
           that your superclasses have no initialization methods.

so it sounds like your initialize method arguments are expected to have 
default values. My preferred signature would place the '...' first, so 
that unnamed arguments (super-classes) are not unintentionally matched 
to named arguments.

Martin

>
>
> Thank!
>
> Aleix Ruiz de Villa
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From sdirkse at gams.com  Tue Nov  1 21:29:51 2011
From: sdirkse at gams.com (Steven Dirkse)
Date: Tue, 1 Nov 2011 16:29:51 -0400
Subject: [Rd] reducing a too-large matrix obtained with allocMatrix()
Message-ID: <CAHiA-Znafaz78EG6gFo9+0ohbXsDpjQ+pyfPhmwC3RZ8KU9ZCQ@mail.gmail.com>

Hello,

I have some C code (for a shared lib called via .External)  that uses

PROTECT(w= allocMatrix(REALSXP, m, n));

mostly successfully.  In rare cases, though, the row count m will be
an overestimate.  Is there a way to reallocate the matrix in-place,
something like

reAllocMatrix (w,m-excess,n)    /* where excess is > 0 */

to chop off the last excess rows of w?  I only find out about the
excess rows during the single pass over the data made to copy it from
its source to w.

Short of this, all I know to do is allocate a matrix of the proper
size and copy the values.  Any other ways to do this?

-- 
Steve Dirkse


From andre.zege at gmail.com  Wed Nov  2 02:08:04 2011
From: andre.zege at gmail.com (andre zege)
Date: Tue, 1 Nov 2011 21:08:04 -0400
Subject: [Rd] can one modify array in R memory from C++ without copying it?
Message-ID: <CACU3EkOh8jAsQi9OyKAkhR37o9E7XgJV4x+CoLT5PHLF_YttOQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111101/06860667/attachment.pl>

From simon.urbanek at r-project.org  Wed Nov  2 02:14:54 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 1 Nov 2011 21:14:54 -0400
Subject: [Rd] reducing a too-large matrix obtained with allocMatrix()
In-Reply-To: <CAHiA-Znafaz78EG6gFo9+0ohbXsDpjQ+pyfPhmwC3RZ8KU9ZCQ@mail.gmail.com>
References: <CAHiA-Znafaz78EG6gFo9+0ohbXsDpjQ+pyfPhmwC3RZ8KU9ZCQ@mail.gmail.com>
Message-ID: <DFAE0F8A-F0A8-445D-9223-18CAC23C1875@r-project.org>


On Nov 1, 2011, at 4:29 PM, Steven Dirkse wrote:

> Hello,
> 
> I have some C code (for a shared lib called via .External)  that uses
> 
> PROTECT(w= allocMatrix(REALSXP, m, n));
> 
> mostly successfully.  In rare cases, though, the row count m will be
> an overestimate.  Is there a way to reallocate the matrix in-place,
> something like
> 
> reAllocMatrix (w,m-excess,n)    /* where excess is > 0 */
> 
> to chop off the last excess rows of w?  I only find out about the
> excess rows during the single pass over the data made to copy it from
> its source to w.
> 
> Short of this, all I know to do is allocate a matrix of the proper
> size and copy the values.  Any other ways to do this?
> 

No.

In theory you could use SETLENGTH, and then adjust the dimensions, but since you are talking about rows you'll need to re-arrange the whole matrix anyway so you would a) waste  memory in the result and b) still need to essentially copy in place in an additional pass.

Cheers,
Simon


From simon.urbanek at r-project.org  Wed Nov  2 02:29:41 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 1 Nov 2011 21:29:41 -0400
Subject: [Rd] can one modify array in R memory from C++ without copying
	it?
In-Reply-To: <CACU3EkOh8jAsQi9OyKAkhR37o9E7XgJV4x+CoLT5PHLF_YttOQ@mail.gmail.com>
References: <CACU3EkOh8jAsQi9OyKAkhR37o9E7XgJV4x+CoLT5PHLF_YttOQ@mail.gmail.com>
Message-ID: <B2CFAEA7-9CE3-46C4-9753-2C34AFF15F3E@r-project.org>


On Nov 1, 2011, at 9:08 PM, andre zege wrote:

> Hi, guys. I posted this by accident at rcpp-dev, although it meant to
> be only to r-dev, so don't flame me here please, rcpp guys will
> do it there, i am sure :).
> I have some pretty large arrays in R and i wanted to do some time
> consuming modifications of these arrays in C++ without actually copying
> them, just by passing pointers to them. Since i don't know internal data
> structures of R, i am not sure it's possible, but i thought it was. Here is
> some toy code that i thought should work, but doesn't. Maybe someone could
> point out the error i am making
> 
> i have the following in the passptr.cpp to multiply array elements by 2
> ===============================
> extern "C"{
> void modify(double *mem, int *nr, int *nc){
>  for(int i=0; i< (*nr)*(*nc); i++)
>    mem[i]=2*mem[i];
>   }
> }
> 
> ----------------------------------------------
> I compile it into a shared library using
> R CMD SHLIB passptr.cpp
> load and run from R as follows
> 
> --------------------------------
> 
>> dyn.load("/home/az05625/testarma/passptr.so")
> 
>> m<-matrix(1:10,nr=2)
> 
>> .C("modify", as.double(m), as.integer(2), as.integer(5), DUP=FALSE)
> 
>> From reading docs i thought that DUP=FALSE would ensure that R matrix is
> not copied and is multiplied by 2 in place. However, it's not the case,
> matrix m is the same after calling .C("modify"...)
> 

Since you called as.double() you created another copy that was modified, you are not passing m to the C code. The result of the .C() call will have the modified version.

See recent discussion on this list - .C is always less efficient than .Call anyway.


> as it was before. Am i calling incorrectly, or is it just impossible to
> modify R matrix in place from C++? Would greatly appreciate any pointers.
> 

The real answer it you don't want to do it. It is technically possible with .Call in some instances, but it is extremely dangerous, because you may modify other, unrelated (other than by value) objects. Note that R uses pass-by-value semantics throughout, so it should not be possible. For example foo(x) takes the value of x, the function foo() has absolutely no idea that the value comes from the binding of x, it is just the value, so it can't modify x. It is technically possible only because R does some optimizations and doesn't copy x if not needed, but it assumes that everyone plays along. However, exploiting that can have unwanted effects:

> library(inline)
> foo = cfunction(signature(x="integer"), "INTEGER(x)[0]=1; return x;")
> a=0L
> b=a
> foo(a)
[1] 1
> a
[1] 1
> b
[1] 1

As you can see "b" is modified even though it was not involved in the call at all! Tracing such issues can be a nightmare, so the answer is "you don't want to do it".

Cheers,
Simon


From slava.razbash at gmail.com  Wed Nov  2 11:27:36 2011
From: slava.razbash at gmail.com (Slava Razbash)
Date: Wed, 2 Nov 2011 21:27:36 +1100
Subject: [Rd] How do I use the new 'ByteCompile' field in R-2.14?
Message-ID: <CANYYcsJn2BE+vPkQ-aZgZvEwHYx85fteJwL+QQ-rsy1ZhOZa2Q@mail.gmail.com>

Hello,


I would like to the use the 'ByteCompile' field in R 2.14. However,
"Writing R Extensions" only describes this field, but does not say
what value it should be set to. How should i use it? Do you have
examples?

Is it the same as "LazyData: yes"?

Thank you,

Slava


From pgilbert at bank-banque-canada.ca  Wed Nov  2 15:13:21 2011
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Wed, 2 Nov 2011 14:13:21 +0000
Subject: [Rd] vignettes/
Message-ID: <6441154A9FF1CD4386AF4ABF141A056D2A773C86@WMEXOSCD2-N1.bocad.bank-banque-canada.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111102/db0fef20/attachment.pl>

From pchausse at uwaterloo.ca  Wed Nov  2 15:55:58 2011
From: pchausse at uwaterloo.ca (Pierre Chausse)
Date: Wed, 02 Nov 2011 10:55:58 -0400
Subject: [Rd] kernapply.ts
Message-ID: <4EB159FE.5080101@mailservices.uwaterloo.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111102/82f9454c/attachment.pl>

From aleixrvr.info at gmail.com  Wed Nov  2 16:16:31 2011
From: aleixrvr.info at gmail.com (Aleix Ruiz de Villa)
Date: Wed, 2 Nov 2011 16:16:31 +0100
Subject: [Rd] Question about copying reference objects using the
 initialize method
In-Reply-To: <4EAFF603.80902@fhcrc.org>
References: <CAGnmr57=uxTf+7POZ6=gOOuu5h4RmLJ_4VD1SvuhR1NtAaXuFQ@mail.gmail.com>
	<4EAFF603.80902@fhcrc.org>
Message-ID: <CAGnmr56m4iYpAr9hU9bCMpdk5fNqmC2ap5k84At8bEs9eMeDKA@mail.gmail.com>

Martin,

thanks. So then I should use options (3) or (4). That's all. Is there
an efficient way to initialize arguments if I have a long list of
arguments? maybe using a 'list'? so that the header of the function is
displayed in a friendly style?

Thanks again!

2011/11/1 Martin Morgan <mtmorgan at fhcrc.org>:
> On 10/31/2011 08:53 AM, Aleix Ruiz de Villa wrote:
>>
>> Dears,
>>
>> I have a question about copying reference objects using the initialize
>> method.
>>
>> 1) If the latter has no arguments, there is no problem to copy an object.
>>
>> myClass = setRefClass("myClass", fields = list(value = "numeric") )
>>
>> myClass$methods(initialize = function(...){
>>
>> ? value<<- 1
>>
>> ? callSuper(...)
>> })
>>
>> newObject = myClass$new()
>> newObject$value = 2
>> copyObject = newObject$copy()
>> copyObject$value = 3
>> print(newObject$value)
>> print(copyObject$value)
>>
>>
>> 2) However, if the initialize method has arguments, I get an error:
>>
>> myClass = setRefClass("myClass", fields = list(value = "numeric") )
>> myClass$methods(initialize = function(extValue, ...){
>>
>> ? value<<- extValue
>>
>> ? callSuper(...)
>> })
>> newObject = myClass$new(extValue = 2)
>> copyObject = newObject$copy()
>>
>> Error in .Object$initialize(...) :
>> ? argument "extValue" is missing, with no default
>>
>>
>> I understand that copy() first builds another instance of the object
>> and then copies the fields. But it calls new without arguments...
>>
>> 3) One solution would be the initialize values by default
>>
>> myClass = setRefClass("myClass", fields = list(value = "numeric") )
>>
>> myClass$methods(initialize = function(extValue = 1, ...){
>>
>> ? value<<- extValue
>>
>> ? callSuper(...)
>> })
>>
>> newObject = myClass$new(extValue = 2)
>> copyObject = newObject$copy()
>>
>>
>> But I have a long list of arguments, so this way would be a little
>> uncomfortable. On the other hand, I've been told that in OOP, the idea
>> of the initialise method is to use the minimum information to build
>> the oject. So passing a long list of arguments is not a good idea.
>>
>>
>> 4) Another option is to first build the object and then set the parameters
>>
>> myClass = setRefClass("myClass", fields = list(value = "numeric") )
>>
>> myClass$methods(setPar = function(extValue = 1, ...){
>>
>> ? value<<- extValue
>>
>> ? return()
>> })
>>
>> newObject = myClass$new()
>> newObject$setPar(extValue = 2)
>> copyObject = newObject$copy()
>>
>>
>> It works fine.
>>
>> Anyway I am curious to know if there is any way to use the initialize
>> method with arguments that is not a problem with copy().
>
> Hi Aleix --
>
> From ?setRefClass
>
> ? ? ? ? ?Initialization methods
> ? ? ? ? ?need some care in design, as they do for S4 classes. In
> ? ? ? ? ?particular, remember that others may subclass your class and
> ? ? ? ? ?pass through field assignments or other arguments.
> ? ? ? ? ?Therefore, your method should normally include ... as an
> ? ? ? ? ?argument, all other arguments should have defaults or check
> ? ? ? ? ?for missingness, and your method should pass all initialized
> ? ? ? ? ?values on via '$callSuper()' or '$initFields()' if you know
> ? ? ? ? ?that your superclasses have no initialization methods.
>
> so it sounds like your initialize method arguments are expected to have
> default values. My preferred signature would place the '...' first, so that
> unnamed arguments (super-classes) are not unintentionally matched to named
> arguments.
>
> Martin
>
>>
>>
>> Thank!
>>
>> Aleix Ruiz de Villa
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
> --
> Computational Biology
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109
>
> Location: M1-B861
> Telephone: 206 667-2793
>


From jwiley.psych at gmail.com  Wed Nov  2 17:13:27 2011
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Wed, 2 Nov 2011 09:13:27 -0700
Subject: [Rd] How do I use the new 'ByteCompile' field in R-2.14?
In-Reply-To: <CANYYcsJn2BE+vPkQ-aZgZvEwHYx85fteJwL+QQ-rsy1ZhOZa2Q@mail.gmail.com>
References: <CANYYcsJn2BE+vPkQ-aZgZvEwHYx85fteJwL+QQ-rsy1ZhOZa2Q@mail.gmail.com>
Message-ID: <CANz9Z_KVC1VGWNBz3ZYU3pd7G-KHW2Oh+3iMLRbsy5g0WKJ2=g@mail.gmail.com>

Hi Slava,

Here is what I have in my DESCRIPTION:

ByteCompile: true

seems to work for me.

Cheers,

Josh

On Wed, Nov 2, 2011 at 3:27 AM, Slava Razbash <slava.razbash at gmail.com> wrote:
> Hello,
>
>
> I would like to the use the 'ByteCompile' field in R 2.14. However,
> "Writing R Extensions" only describes this field, but does not say
> what value it should be set to. How should i use it? Do you have
> examples?
>
> Is it the same as "LazyData: yes"?
>
> Thank you,
>
> Slava
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, ATS Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From ripley at stats.ox.ac.uk  Wed Nov  2 17:20:48 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 2 Nov 2011 16:20:48 +0000 (GMT)
Subject: [Rd] kernapply.ts
In-Reply-To: <4EB159FE.5080101@mailservices.uwaterloo.ca>
References: <4EB159FE.5080101@mailservices.uwaterloo.ca>
Message-ID: <alpine.LFD.2.02.1111021611360.1458@gannet.stats.ox.ac.uk>

On Wed, 2 Nov 2011, Pierre Chausse wrote:

> I have a suggestion for kernapply for ts objects. When we choose the
> option circular=F, the returned series don't have the correct dates. The

That's a matter of opinion.  A kernel is applied in the same way as an 
MA filter, to historical data.

> removed dates are all at the beginning instead of half at the beginning
> and half at the end. It is particularly useful when we need to smooth
> the series (or remove a trend using a filter) before estimating a model
> (like in macroeconomics) or simply to plot the  original series with the
> smoothed one. Of course, there is always the option of doing it by hand
> of the use circular=T and trim the series but I thought it would be
> nicer that way.
>
> Here is my suggestion (maybe not the nicest way to do it but it works)
>
>
> kernapply.ts <- function (x, k, circular = FALSE, ...)
> {
>     if (!is.matrix(x))
>     {
>         y <- kernapply.vector(as.vector(x), k, circular=circular)
>         ts (y, end=end(x), frequency=frequency(x))
>     }
>     else
>         y <- apply(x, MARGIN=2L, FUN=kernapply, k, circular=circular)
>
>     if(circular)
>         ts (y, end=end(x), frequency=frequency(x))
>     else
>     {
>     y <- as.ts(y)
>         t1 <- tsp(x)[1]+(length(k[[1]])-1)/tsp(x)[3]
>         t2 <- tsp(x)[2]-(length(k[[1]])-1)/tsp(x)[3]
>         tsp(y) <- c(t1,t2,tsp(x)[3])
>         return(y)
>     }
> }
>
> -- 
> *Pierre Chauss?*
> Assistant Professor
> Department of Economics
> University of Waterloo
>
> 	[[alternative HTML version deleted]]
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pauljohn32 at gmail.com  Wed Nov  2 17:24:33 2011
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Wed, 2 Nov 2011 11:24:33 -0500
Subject: [Rd] extra & in some lines of R KEYWORDS file
Message-ID: <CAErODj92TqZHiNHWR20hmWqpXPygWLvHCvioQ5fVit_gB5Avyw@mail.gmail.com>

The KEYWORDS file (on R 2.13.1 anyway) , seems to have some extra "&" symbols.
Look below at "&" before "character" "complex" "category" and "NA"

?intentional or mistaken? If not mistaken, what do the & mean?

Basics
        sysdata         &       Basic System Variables          [!= S]
        datasets        &       Datasets available by data(.)   [!= S]
        data            &       Environments, Scoping, Packages [~= S]
        manip           &       Data Manipulation
        attribute       &       Data Attributes
        classes         &       Data Types (not OO)
            & character &       Character Data ("String") Operations
            & complex   &       Complex Numbers
            & category  &       Categorical Data
            & NA        &       Missing Values                  [!= S]
        list            &       Lists
        chron           &       Dates and Times
        package         &       Package Summaries


-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas


From ripley at stats.ox.ac.uk  Wed Nov  2 17:59:33 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 2 Nov 2011 16:59:33 +0000 (GMT)
Subject: [Rd] extra & in some lines of R KEYWORDS file
In-Reply-To: <CAErODj92TqZHiNHWR20hmWqpXPygWLvHCvioQ5fVit_gB5Avyw@mail.gmail.com>
References: <CAErODj92TqZHiNHWR20hmWqpXPygWLvHCvioQ5fVit_gB5Avyw@mail.gmail.com>
Message-ID: <alpine.LFD.2.02.1111021653420.31204@gannet.stats.ox.ac.uk>

On Wed, 2 Nov 2011, Paul Johnson wrote:

> The KEYWORDS file (on R 2.13.1 anyway) , seems to have some extra "&" symbols.
> Look below at "&" before "character" "complex" "category" and "NA"
>
> ?intentional or mistaken? If not mistaken, what do the & mean?

Both!  The mistake is all yours, however.

Compare with the KEYWORDS.db file or the keyword listing on the HTML 
search page.

>
> Basics
>        sysdata         &       Basic System Variables          [!= S]
>        datasets        &       Datasets available by data(.)   [!= S]
>        data            &       Environments, Scoping, Packages [~= S]
>        manip           &       Data Manipulation
>        attribute       &       Data Attributes
>        classes         &       Data Types (not OO)
>            & character &       Character Data ("String") Operations
>            & complex   &       Complex Numbers
>            & category  &       Categorical Data
>            & NA        &       Missing Values                  [!= S]
>        list            &       Lists
>        chron           &       Dates and Times
>        package         &       Package Summaries
>
>
> -- 
> Paul E. Johnson
> Professor, Political Science
> 1541 Lilac Lane, Room 504
> University of Kansas
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pchausse at uwaterloo.ca  Wed Nov  2 18:00:16 2011
From: pchausse at uwaterloo.ca (Pierre Chausse)
Date: Wed, 02 Nov 2011 13:00:16 -0400
Subject: [Rd] kernapply.ts
In-Reply-To: <alpine.LFD.2.02.1111021611360.1458@gannet.stats.ox.ac.uk>
References: <4EB159FE.5080101@mailservices.uwaterloo.ca>
	<alpine.LFD.2.02.1111021611360.1458@gannet.stats.ox.ac.uk>
Message-ID: <4EB17720.9060704@mailservices.uwaterloo.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111102/f7363837/attachment.pl>

From max at naviasystems.com  Wed Nov  2 19:57:36 2011
From: max at naviasystems.com (Max Gasner)
Date: Wed, 2 Nov 2011 11:57:36 -0700
Subject: [Rd] Writing new methods for `names<-`
Message-ID: <CABGWS5EtH6qFfxmusTD8gKAZ7q3KbbpFSNHzQJD4yHnpnAW+cA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111102/04775bde/attachment.pl>

From nashjc at uottawa.ca  Wed Nov  2 19:58:16 2011
From: nashjc at uottawa.ca (John C Nash)
Date: Wed, 02 Nov 2011 14:58:16 -0400
Subject: [Rd] overly long lines in pdf output of manual from package
Message-ID: <4EB192C8.8070301@uottawa.ca>

In re-factoring my optimx package, I'm finding that the pdf output has some lines that are
outside the margins (and there are warnings in R CMD check optimx). Clearly I can fix this
by editing the tex file that is generated, but the build infrastructure would still get
things wrong in automatic processing. So that gives rise to 3 questions:

1) How do I adjust the DESCRIPTION file to avoid too long a line (optimx uses a lot of
other packages). I can add \cr elements to the Rd files to control those lines, but
DESCRIPTION doesn't allow this.

2) Is there an option control that does the job? I've not found one in searching, but
could easily have chosen poor search terms.

3) To avoid running the whole of R CMD check to rebuild the manual, do I need to dig into
R CMD check to find the bits that just build the manual, or is there an option to Rd2pdf
to do this? I've found how to process a list of files with Rd2pdf, but need to add the
DESCRIPTION stuff.

Best

John Nash


From hintak_leung at yahoo.co.uk  Wed Nov  2 20:18:15 2011
From: hintak_leung at yahoo.co.uk (Hin-Tak Leung)
Date: Wed, 2 Nov 2011 19:18:15 +0000 (GMT)
Subject: [Rd] Sweave, cairo_pdf, xetex, CJK (Re:  Sweave, cairo_pdf, CJK,
	ghostscript)
In-Reply-To: <1320098185.89713.YahooMailClassic@web29515.mail.ird.yahoo.com>
Message-ID: <1320261495.40684.YahooMailClassic@web29515.mail.ird.yahoo.com>

FWIW, this is the final outcome: Chinese, Tibetan, Arabic, Liangshan Yi (basically Chinese + 3 other languages used in Nw and Sw china). Arabic is interesting, it using a right-to-left layout - and it works in R graphics.

http://sourceforge.net/projects/outmodedbonsai/files/snpMatrix%20next/1.19.0.11/China_Geographical_Distribution_Maps.pdf/download



From mtmorgan at fhcrc.org  Wed Nov  2 20:21:50 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Wed, 02 Nov 2011 12:21:50 -0700
Subject: [Rd] Writing new methods for `names<-`
In-Reply-To: <CABGWS5EtH6qFfxmusTD8gKAZ7q3KbbpFSNHzQJD4yHnpnAW+cA@mail.gmail.com>
References: <CABGWS5EtH6qFfxmusTD8gKAZ7q3KbbpFSNHzQJD4yHnpnAW+cA@mail.gmail.com>
Message-ID: <4EB1984E.80607@fhcrc.org>

On 11/02/2011 11:57 AM, Max Gasner wrote:
> Hi there,
>
> I'm working with an object whose internal data representation is very
> different from a data.frame (data is stored as a list of big.matrix objects
> from the bigmemory package) but to which I'd like to give users
> data.frame-like access. I've implemented names very easily as follows:
>
> setMethod("names", signature = "my.dataset", definition = function (x) {
>    x at colnames
> })
>
> Now I'd like to implement `names<-` analogously.
>
> Of course the following does not work, because only the local copy of the
> dataset is changed:
>
> setMethod("names<-", signature = "my.dataset", definition = function (x,
> value) {
>    x at colnames<- value
> })
>
> Following a suggestion I found in the list archives, I thought it might be
> worthwhile to try something like the following:
>
> setMethod("names<-", signature = "my.dataset", definition = function (x,
> value, env = parent.frame()) {
>    with(parent.frame(), x at colnames<- value)
> })
>
> But of course because `names<-` is primitive, if I try to redefine the
> generic function as follows so I can pass it another argument:
>
> setGeneric("names<-", def = function (x, value, ...) {
> standardGeneric("names<-") })
>
> Then I get the following error:
>
> Error in setGeneric("names<-", def = function(x, value, ...) { :
>    ?names<-? is a primitive function;  methods can be defined, but the
> generic function is implicit, and cannot be changed.
>
> Any advice on ways around this, or other approaches to the problem, would
> be very welcome!

Hi Max --

'names<-' is already a generic

 > getGeneric("names<-")
standardGeneric for "names<-" defined from package "base"

function (x, value)
standardGeneric("names<-", .Primitive("names<-"))
<environment: 0x8f0a48>
Methods may be defined for arguments: x, value
Use  showMethods("names<-")  for currently available ones.

so write a 'replacement' method

setReplaceMethod("names", "my.dataset", function(x, value) {
     x at colnames <- value
     x
})

Hope that helps,

Martin

>
> Thanks,
>
> Max
>
>
>
> Max Gasner
> Navia Systems | 415 413 3821
>
> 	[[alternative HTML version deleted]]
>
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From mtmorgan at fhcrc.org  Wed Nov  2 20:27:55 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Wed, 02 Nov 2011 12:27:55 -0700
Subject: [Rd] Question about copying reference objects using the
 initialize method
In-Reply-To: <CAGnmr56m4iYpAr9hU9bCMpdk5fNqmC2ap5k84At8bEs9eMeDKA@mail.gmail.com>
References: <CAGnmr57=uxTf+7POZ6=gOOuu5h4RmLJ_4VD1SvuhR1NtAaXuFQ@mail.gmail.com>	<4EAFF603.80902@fhcrc.org>
	<CAGnmr56m4iYpAr9hU9bCMpdk5fNqmC2ap5k84At8bEs9eMeDKA@mail.gmail.com>
Message-ID: <4EB199BB.70801@fhcrc.org>

On 11/02/2011 08:16 AM, Aleix Ruiz de Villa wrote:
> Martin,
>
> thanks. So then I should use options (3) or (4). That's all. Is there
> an efficient way to initialize arguments if I have a long list of
> arguments? maybe using a 'list'? so that the header of the function is
> displayed in a friendly style?

Hi -- I'm not really understanding your question.

Martin

>
> Thanks again!
>
> 2011/11/1 Martin Morgan<mtmorgan at fhcrc.org>:
>> On 10/31/2011 08:53 AM, Aleix Ruiz de Villa wrote:
>>>
>>> Dears,
>>>
>>> I have a question about copying reference objects using the initialize
>>> method.
>>>
>>> 1) If the latter has no arguments, there is no problem to copy an object.
>>>
>>> myClass = setRefClass("myClass", fields = list(value = "numeric") )
>>>
>>> myClass$methods(initialize = function(...){
>>>
>>>    value<<- 1
>>>
>>>    callSuper(...)
>>> })
>>>
>>> newObject = myClass$new()
>>> newObject$value = 2
>>> copyObject = newObject$copy()
>>> copyObject$value = 3
>>> print(newObject$value)
>>> print(copyObject$value)
>>>
>>>
>>> 2) However, if the initialize method has arguments, I get an error:
>>>
>>> myClass = setRefClass("myClass", fields = list(value = "numeric") )
>>> myClass$methods(initialize = function(extValue, ...){
>>>
>>>    value<<- extValue
>>>
>>>    callSuper(...)
>>> })
>>> newObject = myClass$new(extValue = 2)
>>> copyObject = newObject$copy()
>>>
>>> Error in .Object$initialize(...) :
>>>    argument "extValue" is missing, with no default
>>>
>>>
>>> I understand that copy() first builds another instance of the object
>>> and then copies the fields. But it calls new without arguments...
>>>
>>> 3) One solution would be the initialize values by default
>>>
>>> myClass = setRefClass("myClass", fields = list(value = "numeric") )
>>>
>>> myClass$methods(initialize = function(extValue = 1, ...){
>>>
>>>    value<<- extValue
>>>
>>>    callSuper(...)
>>> })
>>>
>>> newObject = myClass$new(extValue = 2)
>>> copyObject = newObject$copy()
>>>
>>>
>>> But I have a long list of arguments, so this way would be a little
>>> uncomfortable. On the other hand, I've been told that in OOP, the idea
>>> of the initialise method is to use the minimum information to build
>>> the oject. So passing a long list of arguments is not a good idea.
>>>
>>>
>>> 4) Another option is to first build the object and then set the parameters
>>>
>>> myClass = setRefClass("myClass", fields = list(value = "numeric") )
>>>
>>> myClass$methods(setPar = function(extValue = 1, ...){
>>>
>>>    value<<- extValue
>>>
>>>    return()
>>> })
>>>
>>> newObject = myClass$new()
>>> newObject$setPar(extValue = 2)
>>> copyObject = newObject$copy()
>>>
>>>
>>> It works fine.
>>>
>>> Anyway I am curious to know if there is any way to use the initialize
>>> method with arguments that is not a problem with copy().
>>
>> Hi Aleix --
>>
>>  From ?setRefClass
>>
>>           Initialization methods
>>           need some care in design, as they do for S4 classes. In
>>           particular, remember that others may subclass your class and
>>           pass through field assignments or other arguments.
>>           Therefore, your method should normally include ... as an
>>           argument, all other arguments should have defaults or check
>>           for missingness, and your method should pass all initialized
>>           values on via '$callSuper()' or '$initFields()' if you know
>>           that your superclasses have no initialization methods.
>>
>> so it sounds like your initialize method arguments are expected to have
>> default values. My preferred signature would place the '...' first, so that
>> unnamed arguments (super-classes) are not unintentionally matched to named
>> arguments.
>>
>> Martin
>>
>>>
>>>
>>> Thank!
>>>
>>> Aleix Ruiz de Villa
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>> --
>> Computational Biology
>> Fred Hutchinson Cancer Research Center
>> 1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109
>>
>> Location: M1-B861
>> Telephone: 206 667-2793
>>


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From ripley at stats.ox.ac.uk  Wed Nov  2 20:54:37 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 2 Nov 2011 19:54:37 +0000 (GMT)
Subject: [Rd] overly long lines in pdf output of manual from package
In-Reply-To: <4EB192C8.8070301@uottawa.ca>
References: <4EB192C8.8070301@uottawa.ca>
Message-ID: <alpine.LFD.2.02.1111021952001.29136@gannet.stats.ox.ac.uk>

On Wed, 2 Nov 2011, John C Nash wrote:

> In re-factoring my optimx package, I'm finding that the pdf output has some lines that are
> outside the margins (and there are warnings in R CMD check optimx). Clearly I can fix this
> by editing the tex file that is generated, but the build infrastructure would still get
> things wrong in automatic processing. So that gives rise to 3 questions:
>
> 1) How do I adjust the DESCRIPTION file to avoid too long a line (optimx uses a lot of
> other packages). I can add \cr elements to the Rd files to control those lines, but
> DESCRIPTION doesn't allow this.

Wrap lines?  And is this R 2.14.0, as the issues are easier with 
the fonts used there?

> 2) Is there an option control that does the job? I've not found one 
> in searching, but could easily have chosen poor search terms.

R has ways to reformat description files.  See ?write.dcf.

>
> 3) To avoid running the whole of R CMD check to rebuild the manual, 
> do I need to dig into R CMD check to find the bits that just build 
> the manual, or is there an option to Rd2pdf to do this? I've found 
> how to process a list of files with Rd2pdf, but need to add the 
> DESCRIPTION stuff.

R CMD R2pdf on a package source directory is what R CMD check uses.

>
> Best
>
> John Nash
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From nashjc at uottawa.ca  Wed Nov  2 21:45:42 2011
From: nashjc at uottawa.ca (John C Nash)
Date: Wed, 02 Nov 2011 16:45:42 -0400
Subject: [Rd] overly long lines in pdf output of manual from package
In-Reply-To: <alpine.LFD.2.02.1111021952001.29136@gannet.stats.ox.ac.uk>
References: <4EB192C8.8070301@uottawa.ca>
	<alpine.LFD.2.02.1111021952001.29136@gannet.stats.ox.ac.uk>
Message-ID: <4EB1ABF6.5090505@uottawa.ca>

Thanks for quick reply.

To help others I'll put in short comments in edited thread.

On 11/02/2011 03:54 PM, Prof Brian Ripley wrote:
> On Wed, 2 Nov 2011, John C Nash wrote:
> 
>> In re-factoring my optimx package, I'm finding that the pdf output has some lines that are
>> outside the margins (and there are warnings in R CMD check optimx). 

>> 1) How do I adjust the DESCRIPTION file to avoid too long a line. I can add \cr elements to the Rd...
> 
> Wrap lines?  And is this R 2.14.0, as the issues are easier with the fonts used there?

R 2.14.0 -- installed from M Rutter repository today. I don't know why it wraps sometimes
and not others, but have occasionally seen similar over-long lines with other TEX files
with the TeXlive I'm using, even with the texlive-fonts-extra installed.

> 
>> 2) Is there an option control that does the job? I've not found one in searching, but
>> could easily have chosen poor search terms.
> 
> R has ways to reformat description files.  See ?write.dcf.

Thanks. I would not have found that! Hence example lines would be

Depends: pkg1, pkg2, pkg3,
    pkg4, pkg5, pkg6.

i.e., spaces on second line.

>> 3) To avoid running the whole of R CMD check ...
> 
> R CMD R2pdf on a package source directory is what R CMD check uses.
> 
When in directory just above that with optimx package in it:

   R CMD Rd2pdf optimx

works quickly and well. Note Rd2pdf not R2pdf (I only noticed just now). I had
misunderstood the Rd2pdf manual about directories. My bad.

JN


From hb at biostat.ucsf.edu  Thu Nov  3 03:40:26 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Wed, 2 Nov 2011 19:40:26 -0700
Subject: [Rd] Call function only when running via R CMD check?
Message-ID: <CAFDcVCR+KazDBc-b0jhn8HkXSC6kPZrVg++0uw_tMtH-V5FB5Q@mail.gmail.com>

I'd like to be able to change some default settings only in the case
when checking a package with 'R CMD check'.  More precisely, I'd like
to execute a piece of R code before the Rd examples and/or test
scripts are evaluated by 'R CMD check'.  Is there a mechanism in 'R
CMD check' that makes this possible?  If not, is there a way to detect
that you are running via 'R CMD check', e.g. an R or an environment
variable being set?

The background for this is that some of my packages' examples are
using memoization to cache computational expensive results (via the
'R.cache' package).  These are cached to files which are by default
stored under ~/.Rcache/.   It turns out that these files live beyond
the check cycle of the CRAN check servers, meaning that the next time
the package is checked memoized results will be picked up.  If I could
detect that we're running via 'R CMD check', then I could change the
default cache directory to a temporary directory (e.g. tempdir()) that
will be clean out automatically.

This is not a critical problem, because for now I could explicitly
turn off the memoization in the code of my examples/regression tests,
but the above would be a more generic solution.

Thanks

Henrik


From renaud at mancala.cbio.uct.ac.za  Thu Nov  3 12:58:44 2011
From: renaud at mancala.cbio.uct.ac.za (Renaud Gaujoux)
Date: Thu, 03 Nov 2011 13:58:44 +0200
Subject: [Rd] R CMD check and error in an \Sexpr in an Rd file
Message-ID: <4EB281F4.3060109@cbio.uct.ac.za>

Georgi, I tried with paste() instead of cat(), but I then get the 
following in my PDF manual:

[1] "line\nnext line"

i.e. what would be printed in the R console, which is not what I want.
I would like to get something like this in the Latex code:

\begin{verbatim}
line
next line
\end{verbatim}

Using cat() I get the following in the Latex code:

\AsIs{
line
next line}

which does not render as a new line in the PDF and breaks if empty lines 
are present in the output text.
Besides it will also break on \Sexpr[results=verbatim, 
stage=render]{list("text", 3)}.

But maybe this is not what 'results=verbatim' is supposed to do nor to 
be used for?

Renaud

Another test Rd file.

%%%%%%%%%
\name{Sexpr}
\alias{Sexpr}
\title{Error and verbatim in Sexpr}
\description{
    Testing Sexpr in Rd files

    %\Sexpr[results=verbatim, stage=render]{stop("error in sexpr")}

    Verbatim:

    1: \Sexpr[results=verbatim, stage=render]{cat("line\nnext line\n")}

    2: \Sexpr[results=verbatim, stage=render]{"line\nnext line\n"}

    3: \Sexpr[results=verbatim, stage=render]{list("line\nnext line", 3)}

    Text:

    1: \Sexpr[results=text, stage=render]{cat("line\nnext line\n")}

    2: \Sexpr[results=text, stage=render]{"line\nnext line\n"}

    3: \Sexpr[results=text, stage=render]{list("line\nnext line", 3)}

}
%%%%%


From murdoch.duncan at gmail.com  Thu Nov  3 13:19:44 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 03 Nov 2011 08:19:44 -0400
Subject: [Rd] R CMD check and error in an \Sexpr in an Rd file
In-Reply-To: <4EB281F4.3060109@cbio.uct.ac.za>
References: <4EB281F4.3060109@cbio.uct.ac.za>
Message-ID: <4EB286E0.7070504@gmail.com>

On 11-11-03 7:58 AM, Renaud Gaujoux wrote:
> Georgi, I tried with paste() instead of cat(), but I then get the
> following in my PDF manual:
>
> [1] "line\nnext line"
>
> i.e. what would be printed in the R console, which is not what I want.
> I would like to get something like this in the Latex code:
>
> \begin{verbatim}
> line
> next line
> \end{verbatim}

I don't think you want that:  it forces display mode.  You might want 
verbatim text displayed inline, like \verb does.

>
> Using cat() I get the following in the Latex code:
>
> \AsIs{
> line
> next line}
>
> which does not render as a new line in the PDF and breaks if empty lines
> are present in the output text.

So the problem is with the \AsIs macro.  You can see the definition in 
the Rd.sty file in R_HOME/share/texmf/tex/latex.  Can you suggest an 
improvement?

Duncan Murdoch

> Besides it will also break on \Sexpr[results=verbatim,
> stage=render]{list("text", 3)}.
>
> But maybe this is not what 'results=verbatim' is supposed to do nor to
> be used for?
>
> Renaud
>
> Another test Rd file.
>
> %%%%%%%%%
> \name{Sexpr}
> \alias{Sexpr}
> \title{Error and verbatim in Sexpr}
> \description{
>      Testing Sexpr in Rd files
>
>      %\Sexpr[results=verbatim, stage=render]{stop("error in sexpr")}
>
>      Verbatim:
>
>      1: \Sexpr[results=verbatim, stage=render]{cat("line\nnext line\n")}
>
>      2: \Sexpr[results=verbatim, stage=render]{"line\nnext line\n"}
>
>      3: \Sexpr[results=verbatim, stage=render]{list("line\nnext line", 3)}
>
>      Text:
>
>      1: \Sexpr[results=text, stage=render]{cat("line\nnext line\n")}
>
>      2: \Sexpr[results=text, stage=render]{"line\nnext line\n"}
>
>      3: \Sexpr[results=text, stage=render]{list("line\nnext line", 3)}
>
> }
> %%%%%
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From renaud at mancala.cbio.uct.ac.za  Thu Nov  3 14:50:12 2011
From: renaud at mancala.cbio.uct.ac.za (Renaud Gaujoux)
Date: Thu, 03 Nov 2011 15:50:12 +0200
Subject: [Rd] R CMD check and error in an \Sexpr in an Rd file
In-Reply-To: <4EB286E0.7070504@gmail.com>
References: <4EB281F4.3060109@cbio.uct.ac.za> <4EB286E0.7070504@gmail.com>
Message-ID: <4EB29C14.70201@cbio.uct.ac.za>

Although I use Latex quite a lot, I am not literate in Latex macro 
languages (e.g. the definition of AsIs).
Is there (I am sure there is) a reason why a plain verbatim environment 
is not used in this case?


On 03/11/2011 14:19, Duncan Murdoch wrote:
> On 11-11-03 7:58 AM, Renaud Gaujoux wrote:
>> Georgi, I tried with paste() instead of cat(), but I then get the
>> following in my PDF manual:
>>
>> [1] "line\nnext line"
>>
>> i.e. what would be printed in the R console, which is not what I want.
>> I would like to get something like this in the Latex code:
>>
>> \begin{verbatim}
>> line
>> next line
>> \end{verbatim}
>
> I don't think you want that:  it forces display mode.  You might want 
> verbatim text displayed inline, like \verb does.
>
>>
>> Using cat() I get the following in the Latex code:
>>
>> \AsIs{
>> line
>> next line}
>>
>> which does not render as a new line in the PDF and breaks if empty lines
>> are present in the output text.
>
> So the problem is with the \AsIs macro.  You can see the definition in 
> the Rd.sty file in R_HOME/share/texmf/tex/latex.  Can you suggest an 
> improvement?
>
> Duncan Murdoch
>
>> Besides it will also break on \Sexpr[results=verbatim,
>> stage=render]{list("text", 3)}.
>>
>> But maybe this is not what 'results=verbatim' is supposed to do nor to
>> be used for?
>>
>> Renaud
>>
>> Another test Rd file.
>>
>> %%%%%%%%%
>> \name{Sexpr}
>> \alias{Sexpr}
>> \title{Error and verbatim in Sexpr}
>> \description{
>>      Testing Sexpr in Rd files
>>
>>      %\Sexpr[results=verbatim, stage=render]{stop("error in sexpr")}
>>
>>      Verbatim:
>>
>>      1: \Sexpr[results=verbatim, stage=render]{cat("line\nnext line\n")}
>>
>>      2: \Sexpr[results=verbatim, stage=render]{"line\nnext line\n"}
>>
>>      3: \Sexpr[results=verbatim, stage=render]{list("line\nnext 
>> line", 3)}
>>
>>      Text:
>>
>>      1: \Sexpr[results=text, stage=render]{cat("line\nnext line\n")}
>>
>>      2: \Sexpr[results=text, stage=render]{"line\nnext line\n"}
>>
>>      3: \Sexpr[results=text, stage=render]{list("line\nnext line", 3)}
>>
>> }
>> %%%%%
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From georgi.boshnakov at manchester.ac.uk  Thu Nov  3 14:50:40 2011
From: georgi.boshnakov at manchester.ac.uk (Georgi Boshnakov)
Date: Thu, 3 Nov 2011 13:50:40 +0000
Subject: [Rd] R CMD check and error in an \Sexpr in an Rd file
In-Reply-To: <4EB286E0.7070504@gmail.com>
References: <4EB281F4.3060109@cbio.uct.ac.za>,<4EB286E0.7070504@gmail.com>
Message-ID: <438D2EC9EAFE5946B2D5864670EA468E08896B@MBXP01.ds.man.ac.uk>

Dear Duncan and Renauld,


The error caused by the empty line(s) can be removed by prefixin the macro with \long
in Rd.sty:

\long\def\Rd at AsIsX#1{\normalfont #1\egroup}

but the slash-n's come up in the output. 

In "text mode" this seems not to be a problem. Following normal TeX rules one needs to enter an empty line, e.g. by \n\n.

Having written that, I tried putting two \n's in the verbatim text and it seems to work (see below).

I need to consult the TeX book to be sure but the
problem with AsIs seems to be that by the time it starts processing its argument it has been tokenized by TeX
(hence single newlines have become spaces). 

Further thought may be needed about the new lines in verbatim. 
I may have missed again something but it seems that the observed output is consistent with the 
documentation, which states:

    "results=verbatim Print the results of the code just as if it was executed at the
    console, and include the printed results verbatim. (Invisible results will not print.)"

And the examples print on the console as they appear in output (with print, not cat).

Do we need exception from the general rule? 

An alternative would be to introduce results=verbatimLines option. 


Georgi

\name{Sexpr}
\alias{Sexpr}
\title{Error and verbatim in Sexpr}
\description{
    Testing Sexpr in Rd files

    %\Sexpr[results=verbatim, stage=render]{stop("error in sexpr")}

    Verbatim:

    1: \Sexpr[results=verbatim, stage=render]{cat("line\n\nnext line\n\n and another")}

%    1a: \Sexpr[results=text, stage=render]{capture.output(cat(c("line", "next line\n"),sep="\n", collapse="\n"))}

    2: \Sexpr[results=verbatim, stage=render]{"line\nnext line\n"}

    3: \Sexpr[results=verbatim, stage=render]{list("line\nnext line", 3)}

    4: \Sexpr[results=verbatim, stage=render]{list(c("line", "next line"), 3)}

    Text:

    1: \Sexpr[results=text, stage=render]{cat("line\nnext line\n")}

    2: \Sexpr[results=text, stage=render]{"line\nnext line\n"}

    3: \Sexpr[results=text, stage=render]{list("line\n\nnext  line\\\\\\\\ \\\\newline and another", 3)}

}



--
Dr Georgi Boshnakov               tel: (+44) (0)161 306 3684
School of Mathematics             fax: (+44) (0)161 306 3669
Alan Turing Building 1.125
The University of Manchester      email: Georgi.Boshnakov at manchester.ac.uk
Oxford Road
Manchester M13 9PL
UK


________________________________________
From: Duncan Murdoch [murdoch.duncan at gmail.com]
Sent: 03 November 2011 12:19
To: Renaud Gaujoux
Cc: Georgi Boshnakov; r-devel at r-project.org
Subject: Re: [Rd] R CMD check and error in an \Sexpr in an Rd file

On 11-11-03 7:58 AM, Renaud Gaujoux wrote:
> Georgi, I tried with paste() instead of cat(), but I then get the
> following in my PDF manual:
>
> [1] "line\nnext line"
>
> i.e. what would be printed in the R console, which is not what I want.
> I would like to get something like this in the Latex code:
>
> \begin{verbatim}
> line
> next line
> \end{verbatim}

I don't think you want that:  it forces display mode.  You might want
verbatim text displayed inline, like \verb does.

>
> Using cat() I get the following in the Latex code:
>
> \AsIs{
> line
> next line}
>
> which does not render as a new line in the PDF and breaks if empty lines
> are present in the output text.

So the problem is with the \AsIs macro.  You can see the definition in
the Rd.sty file in R_HOME/share/texmf/tex/latex.  Can you suggest an
improvement?

Duncan Murdoch

> Besides it will also break on \Sexpr[results=verbatim,
> stage=render]{list("text", 3)}.
>
> But maybe this is not what 'results=verbatim' is supposed to do nor to
> be used for?
>
> Renaud
>
> Another test Rd file.
>
> %%%%%%%%%
> \name{Sexpr}
> \alias{Sexpr}
> \title{Error and verbatim in Sexpr}
> \description{
>      Testing Sexpr in Rd files
>
>      %\Sexpr[results=verbatim, stage=render]{stop("error in sexpr")}
>
>      Verbatim:
>
>      1: \Sexpr[results=verbatim, stage=render]{cat("line\nnext line\n")}
>
>      2: \Sexpr[results=verbatim, stage=render]{"line\nnext line\n"}
>
>      3: \Sexpr[results=verbatim, stage=render]{list("line\nnext line", 3)}
>
>      Text:
>
>      1: \Sexpr[results=text, stage=render]{cat("line\nnext line\n")}
>
>      2: \Sexpr[results=text, stage=render]{"line\nnext line\n"}
>
>      3: \Sexpr[results=text, stage=render]{list("line\nnext line", 3)}
>
> }
> %%%%%
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



From lists at revelle.net  Thu Nov  3 14:54:36 2011
From: lists at revelle.net (William Revelle)
Date: Thu, 3 Nov 2011 08:54:36 -0500
Subject: [Rd] How to test package on Solaris
Message-ID: <16752AAC-377F-483E-85B6-1CAA83ACF1FE@revelle.net>

Dear R developers,

Is there a way to pretest a package on the Solaris-sparc and solaris-x86 systems equivalent to the win-builder check?

My psych package (1.1.10 and 1.1.11) passes all checks for the Mac on my system, on the win-builder checking system supported by Uwe, and then passes Kurt's tests to install on CRAN.  But it then fails when being built for the solaris systems.  

Rather than burden Kurt and Uwe and the whole CRAN distribution process with frequent attempts to fix the problem, it would be preferable if I could pretest on a solaris system and then upload the final result.

I note from reading past queries to the list that this question has been asked before and the solution seems to have been some nice soul  volunteering to test a particular package.  A more general solution would seem preferred, if this is possible.

Thanks.

Bill



William Revelle		           http://personality-project.org/revelle.html
Professor			           http://personality-project.org
Department of Psychology   http://www.wcas.northwestern.edu/psych/
Northwestern University	   http://www.northwestern.edu/
Use R for psychology             http://personality-project.org/r
It is 6 minutes to midnight	   http://www.thebulletin.org


From renaud at mancala.cbio.uct.ac.za  Thu Nov  3 15:21:53 2011
From: renaud at mancala.cbio.uct.ac.za (Renaud Gaujoux)
Date: Thu, 03 Nov 2011 16:21:53 +0200
Subject: [Rd] R CMD check and error in an \Sexpr in an Rd file
In-Reply-To: <438D2EC9EAFE5946B2D5864670EA468E08896B@MBXP01.ds.man.ac.uk>
References: <4EB281F4.3060109@cbio.uct.ac.za>, <4EB286E0.7070504@gmail.com>
	<438D2EC9EAFE5946B2D5864670EA468E08896B@MBXP01.ds.man.ac.uk>
Message-ID: <4EB2A381.60403@cbio.uct.ac.za>

Thank you Georgi.
With the fix \long the output is indeed consistent with the documentation.
I think my use of cat() worked by luck as its output should not have 
been rendered.

Would a 'results=tex' (html, text) be possible? or 'results=source' that 
could be combined with \if{format}{text}?
This would allow to generate custom Latex, or HTML code, but it might 
also be is hazardous...

Renaud

-- 
Renaud Gaujoux
Computational Biology - University of Cape Town
South Africa


On 03/11/2011 15:50, Georgi Boshnakov wrote:
> Dear Duncan and Renauld,
>
>
> The error caused by the empty line(s) can be removed by prefixin the macro with \long
> in Rd.sty:
>
> \long\def\Rd at AsIsX#1{\normalfont #1\egroup}
>
> but the slash-n's come up in the output.
>
> In "text mode" this seems not to be a problem. Following normal TeX rules one needs to enter an empty line, e.g. by \n\n.
>
> Having written that, I tried putting two \n's in the verbatim text and it seems to work (see below).
>
> I need to consult the TeX book to be sure but the
> problem with AsIs seems to be that by the time it starts processing its argument it has been tokenized by TeX
> (hence single newlines have become spaces).
>
> Further thought may be needed about the new lines in verbatim.
> I may have missed again something but it seems that the observed output is consistent with the
> documentation, which states:
>
>      "results=verbatim Print the results of the code just as if it was executed at the
>      console, and include the printed results verbatim. (Invisible results will not print.)"
>
> And the examples print on the console as they appear in output (with print, not cat).
>
> Do we need exception from the general rule?
>
> An alternative would be to introduce results=verbatimLines option.
>
>
> Georgi
>
> \name{Sexpr}
> \alias{Sexpr}
> \title{Error and verbatim in Sexpr}
> \description{
>      Testing Sexpr in Rd files
>
>      %\Sexpr[results=verbatim, stage=render]{stop("error in sexpr")}
>
>      Verbatim:
>
>      1: \Sexpr[results=verbatim, stage=render]{cat("line\n\nnext line\n\n and another")}
>
> %    1a: \Sexpr[results=text, stage=render]{capture.output(cat(c("line", "next line\n"),sep="\n", collapse="\n"))}
>
>      2: \Sexpr[results=verbatim, stage=render]{"line\nnext line\n"}
>
>      3: \Sexpr[results=verbatim, stage=render]{list("line\nnext line", 3)}
>
>      4: \Sexpr[results=verbatim, stage=render]{list(c("line", "next line"), 3)}
>
>      Text:
>
>      1: \Sexpr[results=text, stage=render]{cat("line\nnext line\n")}
>
>      2: \Sexpr[results=text, stage=render]{"line\nnext line\n"}
>
>      3: \Sexpr[results=text, stage=render]{list("line\n\nnext  line\\\\\\\\ \\\\newline and another", 3)}
>
> }
>
>
>
> --
> Dr Georgi Boshnakov               tel: (+44) (0)161 306 3684
> School of Mathematics             fax: (+44) (0)161 306 3669
> Alan Turing Building 1.125
> The University of Manchester      email: Georgi.Boshnakov at manchester.ac.uk
> Oxford Road
> Manchester M13 9PL
> UK
>
>
> ________________________________________
> From: Duncan Murdoch [murdoch.duncan at gmail.com]
> Sent: 03 November 2011 12:19
> To: Renaud Gaujoux
> Cc: Georgi Boshnakov; r-devel at r-project.org
> Subject: Re: [Rd] R CMD check and error in an \Sexpr in an Rd file
>
> On 11-11-03 7:58 AM, Renaud Gaujoux wrote:
>> Georgi, I tried with paste() instead of cat(), but I then get the
>> following in my PDF manual:
>>
>> [1] "line\nnext line"
>>
>> i.e. what would be printed in the R console, which is not what I want.
>> I would like to get something like this in the Latex code:
>>
>> \begin{verbatim}
>> line
>> next line
>> \end{verbatim}
> I don't think you want that:  it forces display mode.  You might want
> verbatim text displayed inline, like \verb does.
>
>> Using cat() I get the following in the Latex code:
>>
>> \AsIs{
>> line
>> next line}
>>
>> which does not render as a new line in the PDF and breaks if empty lines
>> are present in the output text.
> So the problem is with the \AsIs macro.  You can see the definition in
> the Rd.sty file in R_HOME/share/texmf/tex/latex.  Can you suggest an
> improvement?
>
> Duncan Murdoch
>
>> Besides it will also break on \Sexpr[results=verbatim,
>> stage=render]{list("text", 3)}.
>>
>> But maybe this is not what 'results=verbatim' is supposed to do nor to
>> be used for?
>>
>> Renaud
>>
>> Another test Rd file.
>>
>> %%%%%%%%%
>> \name{Sexpr}
>> \alias{Sexpr}
>> \title{Error and verbatim in Sexpr}
>> \description{
>>       Testing Sexpr in Rd files
>>
>>       %\Sexpr[results=verbatim, stage=render]{stop("error in sexpr")}
>>
>>       Verbatim:
>>
>>       1: \Sexpr[results=verbatim, stage=render]{cat("line\nnext line\n")}
>>
>>       2: \Sexpr[results=verbatim, stage=render]{"line\nnext line\n"}
>>
>>       3: \Sexpr[results=verbatim, stage=render]{list("line\nnext line", 3)}
>>
>>       Text:
>>
>>       1: \Sexpr[results=text, stage=render]{cat("line\nnext line\n")}
>>
>>       2: \Sexpr[results=text, stage=render]{"line\nnext line\n"}
>>
>>       3: \Sexpr[results=text, stage=render]{list("line\nnext line", 3)}
>>
>> }
>> %%%%%
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Thu Nov  3 15:28:36 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 03 Nov 2011 10:28:36 -0400
Subject: [Rd] R CMD check and error in an \Sexpr in an Rd file
In-Reply-To: <4EB2A381.60403@cbio.uct.ac.za>
References: <4EB281F4.3060109@cbio.uct.ac.za>, <4EB286E0.7070504@gmail.com>
	<438D2EC9EAFE5946B2D5864670EA468E08896B@MBXP01.ds.man.ac.uk>
	<4EB2A381.60403@cbio.uct.ac.za>
Message-ID: <4EB2A514.30208@gmail.com>

On 03/11/2011 10:21 AM, Renaud Gaujoux wrote:
> Thank you Georgi.
> With the fix \long the output is indeed consistent with the documentation.
> I think my use of cat() worked by luck as its output should not have
> been rendered.
>
> Would a 'results=tex' (html, text) be possible? or 'results=source' that
> could be combined with \if{format}{text}?
> This would allow to generate custom Latex, or HTML code, but it might
> also be is hazardous...

Yes, that's possible.  See the manual, especially the section "2.12 
conditional text".

Duncan Murdoch


From edd at debian.org  Thu Nov  3 15:32:47 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 3 Nov 2011 09:32:47 -0500
Subject: [Rd] How to test package on Solaris
In-Reply-To: <16752AAC-377F-483E-85B6-1CAA83ACF1FE@revelle.net>
References: <16752AAC-377F-483E-85B6-1CAA83ACF1FE@revelle.net>
Message-ID: <20146.42511.868165.392516@max.nulle.part>


On 3 November 2011 at 08:54, William Revelle wrote:
| Dear R developers,
| 
| Is there a way to pretest a package on the Solaris-sparc and solaris-x86 systems equivalent to the win-builder check?

Nope, not as far as I know.  For Rcpp we are very much in the same boot. 
 
There was word of an upcoming 'bin-builder' similar to win-builder, but it
hasn't materialized.  You and I don't have a vote in that matter, but I think
this is a well definied task for which monies from the R Foundation would be
well spent.  Or a motivated company from the R universe could earn some
decent and recurrent karma points...

| My psych package (1.1.10 and 1.1.11) passes all checks for the Mac on my system, on the win-builder checking system supported by Uwe, and then passes Kurt's tests to install on CRAN.  But it then fails when being built for the solaris systems.  
| 
| Rather than burden Kurt and Uwe and the whole CRAN distribution process with frequent attempts to fix the problem, it would be preferable if I could pretest on a solaris system and then upload the final result.
| 
| I note from reading past queries to the list that this question has been asked before and the solution seems to have been some nice soul  volunteering to test a particular package.  A more general solution would seem preferred, if this is possible.

Correct. Matryn helped us recently with a patch for the solaris/x86 side of
things bringing the failure down to solaris/sparc only.  But our (ie Romain
and I) hands are tied as are yours. 

Cheers, Dirk

| Thanks.
| 
| Bill
| 
| 
| 
| William Revelle		           http://personality-project.org/revelle.html
| Professor			           http://personality-project.org
| Department of Psychology   http://www.wcas.northwestern.edu/psych/
| Northwestern University	   http://www.northwestern.edu/
| Use R for psychology             http://personality-project.org/r
| It is 6 minutes to midnight	   http://www.thebulletin.org
| 
| ______________________________________________
| R-devel at r-project.org mailing list
| https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
"Outside of a dog, a book is a man's best friend. Inside of a dog, it is too
dark to read." -- Groucho Marx


From georgi.boshnakov at manchester.ac.uk  Thu Nov  3 15:33:22 2011
From: georgi.boshnakov at manchester.ac.uk (Georgi Boshnakov)
Date: Thu, 3 Nov 2011 14:33:22 +0000
Subject: [Rd] R CMD check and error in an \Sexpr in an Rd file
In-Reply-To: <4EB2A381.60403@cbio.uct.ac.za>
References: <4EB281F4.3060109@cbio.uct.ac.za>,<4EB286E0.7070504@gmail.com>
	<438D2EC9EAFE5946B2D5864670EA468E08896B@MBXP01.ds.man.ac.uk>,
	<4EB2A381.60403@cbio.uct.ac.za>
Message-ID: <438D2EC9EAFE5946B2D5864670EA468E0899A8@MBXP01.ds.man.ac.uk>

Dear Renalud,, 

> Would a 'results=tex' (html, text) be possible? or 'results=source' that
> could be combined with \if{format}{text}?

This may well be a clean approach. 

After my previous email, I looked again at the definition of thr \AsIs macro. 
Its purpose seems to be to typeset text containing special characters in normal text mode 
and thus its purpose is different from \verb and ``verbatm'  macros/environments in LaTeX.

Georgi

--
Dr Georgi Boshnakov               tel: (+44) (0)161 306 3684
School of Mathematics             fax: (+44) (0)161 306 3669
Alan Turing Building 1.125
The University of Manchester      email: Georgi.Boshnakov at manchester.ac.uk
Oxford Road
Manchester M13 9PL
UK


________________________________________
From: Renaud Gaujoux [renaud at cbio.uct.ac.za]
Sent: 03 November 2011 14:21
To: Georgi Boshnakov
Cc: Duncan Murdoch; Renaud Gaujoux; r-devel at r-project.org
Subject: Re: [Rd] R CMD check and error in an \Sexpr in an Rd file

Thank you Georgi.
With the fix \long the output is indeed consistent with the documentation.
I think my use of cat() worked by luck as its output should not have
been rendered.

Would a 'results=tex' (html, text) be possible? or 'results=source' that
could be combined with \if{format}{text}?
This would allow to generate custom Latex, or HTML code, but it might
also be is hazardous...

Renaud

--
Renaud Gaujoux
Computational Biology - University of Cape Town
South Africa


On 03/11/2011 15:50, Georgi Boshnakov wrote:
> Dear Duncan and Renauld,
>
>
> The error caused by the empty line(s) can be removed by prefixin the macro with \long
> in Rd.sty:
>
> \long\def\Rd at AsIsX#1{\normalfont #1\egroup}
>
> but the slash-n's come up in the output.
>
> In "text mode" this seems not to be a problem. Following normal TeX rules one needs to enter an empty line, e.g. by \n\n.
>
> Having written that, I tried putting two \n's in the verbatim text and it seems to work (see below).
>
> I need to consult the TeX book to be sure but the
> problem with AsIs seems to be that by the time it starts processing its argument it has been tokenized by TeX
> (hence single newlines have become spaces).
>
> Further thought may be needed about the new lines in verbatim.
> I may have missed again something but it seems that the observed output is consistent with the
> documentation, which states:
>
>      "results=verbatim Print the results of the code just as if it was executed at the
>      console, and include the printed results verbatim. (Invisible results will not print.)"
>
> And the examples print on the console as they appear in output (with print, not cat).
>
> Do we need exception from the general rule?
>
> An alternative would be to introduce results=verbatimLines option.
>
>
> Georgi
>
> \name{Sexpr}
> \alias{Sexpr}
> \title{Error and verbatim in Sexpr}
> \description{
>      Testing Sexpr in Rd files
>
>      %\Sexpr[results=verbatim, stage=render]{stop("error in sexpr")}
>
>      Verbatim:
>
>      1: \Sexpr[results=verbatim, stage=render]{cat("line\n\nnext line\n\n and another")}
>
> %    1a: \Sexpr[results=text, stage=render]{capture.output(cat(c("line", "next line\n"),sep="\n", collapse="\n"))}
>
>      2: \Sexpr[results=verbatim, stage=render]{"line\nnext line\n"}
>
>      3: \Sexpr[results=verbatim, stage=render]{list("line\nnext line", 3)}
>
>      4: \Sexpr[results=verbatim, stage=render]{list(c("line", "next line"), 3)}
>
>      Text:
>
>      1: \Sexpr[results=text, stage=render]{cat("line\nnext line\n")}
>
>      2: \Sexpr[results=text, stage=render]{"line\nnext line\n"}
>
>      3: \Sexpr[results=text, stage=render]{list("line\n\nnext  line\\\\\\\\ \\\\newline and another", 3)}
>
> }
>
>
>
> --
> Dr Georgi Boshnakov               tel: (+44) (0)161 306 3684
> School of Mathematics             fax: (+44) (0)161 306 3669
> Alan Turing Building 1.125
> The University of Manchester      email: Georgi.Boshnakov at manchester.ac.uk
> Oxford Road
> Manchester M13 9PL
> UK
>
>
> ________________________________________
> From: Duncan Murdoch [murdoch.duncan at gmail.com]
> Sent: 03 November 2011 12:19
> To: Renaud Gaujoux
> Cc: Georgi Boshnakov; r-devel at r-project.org
> Subject: Re: [Rd] R CMD check and error in an \Sexpr in an Rd file
>
> On 11-11-03 7:58 AM, Renaud Gaujoux wrote:
>> Georgi, I tried with paste() instead of cat(), but I then get the
>> following in my PDF manual:
>>
>> [1] "line\nnext line"
>>
>> i.e. what would be printed in the R console, which is not what I want.
>> I would like to get something like this in the Latex code:
>>
>> \begin{verbatim}
>> line
>> next line
>> \end{verbatim}
> I don't think you want that:  it forces display mode.  You might want
> verbatim text displayed inline, like \verb does.
>
>> Using cat() I get the following in the Latex code:
>>
>> \AsIs{
>> line
>> next line}
>>
>> which does not render as a new line in the PDF and breaks if empty lines
>> are present in the output text.
> So the problem is with the \AsIs macro.  You can see the definition in
> the Rd.sty file in R_HOME/share/texmf/tex/latex.  Can you suggest an
> improvement?
>
> Duncan Murdoch
>
>> Besides it will also break on \Sexpr[results=verbatim,
>> stage=render]{list("text", 3)}.
>>
>> But maybe this is not what 'results=verbatim' is supposed to do nor to
>> be used for?
>>
>> Renaud
>>
>> Another test Rd file.
>>
>> %%%%%%%%%
>> \name{Sexpr}
>> \alias{Sexpr}
>> \title{Error and verbatim in Sexpr}
>> \description{
>>       Testing Sexpr in Rd files
>>
>>       %\Sexpr[results=verbatim, stage=render]{stop("error in sexpr")}
>>
>>       Verbatim:
>>
>>       1: \Sexpr[results=verbatim, stage=render]{cat("line\nnext line\n")}
>>
>>       2: \Sexpr[results=verbatim, stage=render]{"line\nnext line\n"}
>>
>>       3: \Sexpr[results=verbatim, stage=render]{list("line\nnext line", 3)}
>>
>>       Text:
>>
>>       1: \Sexpr[results=text, stage=render]{cat("line\nnext line\n")}
>>
>>       2: \Sexpr[results=text, stage=render]{"line\nnext line\n"}
>>
>>       3: \Sexpr[results=text, stage=render]{list("line\nnext line", 3)}
>>
>> }
>> %%%%%
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From renaud at mancala.cbio.uct.ac.za  Thu Nov  3 15:49:26 2011
From: renaud at mancala.cbio.uct.ac.za (Renaud Gaujoux)
Date: Thu, 03 Nov 2011 16:49:26 +0200
Subject: [Rd] R CMD check and error in an \Sexpr in an Rd file
In-Reply-To: <4EB2A514.30208@gmail.com>
References: <4EB281F4.3060109@cbio.uct.ac.za>, <4EB286E0.7070504@gmail.com>
	<438D2EC9EAFE5946B2D5864670EA468E08896B@MBXP01.ds.man.ac.uk>
	<4EB2A381.60403@cbio.uct.ac.za> <4EB2A514.30208@gmail.com>
Message-ID: <4EB2A9F6.2060501@cbio.uct.ac.za>


On 03/11/2011 16:28, Duncan Murdoch wrote:
> On 03/11/2011 10:21 AM, Renaud Gaujoux wrote:
>> Thank you Georgi.
>> With the fix \long the output is indeed consistent with the 
>> documentation.
>> I think my use of cat() worked by luck as its output should not have
>> been rendered.
>>
>> Would a 'results=tex' (html, text) be possible? or 'results=source' that
>> could be combined with \if{format}{text}?
>> This would allow to generate custom Latex, or HTML code, but it might
>> also be is hazardous...
>
> Yes, that's possible.  See the manual, especially the section "2.12 
> conditional text".
>
> Duncan Murdoch

Conditional text is possible, but latex or html code seem to be 
preprocessed and escaped, or maybe I am not doing the right things.

To test:

%%%%%%%%
\name{Sexpr}
\alias{Sexpr}
\title{Error and verbatim in Sexpr}
\description{
     Testing Sexpr in Rd files

     \if{html}{\Sexpr[results=text, stage=render]{"<bold>text in 
bold</bold>"}}
     \if{text}{\Sexpr[results=text, stage=render]{"_text in bold_"}}
     \if{latex}{\Sexpr[results=text, stage=render]{"\\\\textbf{text in 
bold}"}}



}
%%%%%%%


From renaud at mancala.cbio.uct.ac.za  Thu Nov  3 15:51:53 2011
From: renaud at mancala.cbio.uct.ac.za (Renaud Gaujoux)
Date: Thu, 03 Nov 2011 16:51:53 +0200
Subject: [Rd] R CMD check and error in an \Sexpr in an Rd file
In-Reply-To: <438D2EC9EAFE5946B2D5864670EA468E0899A8@MBXP01.ds.man.ac.uk>
References: <4EB281F4.3060109@cbio.uct.ac.za>, <4EB286E0.7070504@gmail.com>
	<438D2EC9EAFE5946B2D5864670EA468E08896B@MBXP01.ds.man.ac.uk>,
	<4EB2A381.60403@cbio.uct.ac.za>
	<438D2EC9EAFE5946B2D5864670EA468E0899A8@MBXP01.ds.man.ac.uk>
Message-ID: <4EB2AA89.7020607@cbio.uct.ac.za>


On 03/11/2011 16:33, Georgi Boshnakov wrote:
> Dear Renalud,,
>
>> Would a 'results=tex' (html, text) be possible? or 'results=source' that
>> could be combined with \if{format}{text}?
> This may well be a clean approach.
>
> After my previous email, I looked again at the definition of thr \AsIs macro.
> Its purpose seems to be to typeset text containing special characters in normal text mode
> and thus its purpose is different from \verb and ``verbatm'  macros/environments in LaTeX.
>
Maybe using an environment such as Verbatim defined in fancyvrb would 
solve the problem?
I think you can control the font, etc... still keeping the "no 
formatting" of plain verbatim.


From murdoch.duncan at gmail.com  Thu Nov  3 17:28:56 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 03 Nov 2011 12:28:56 -0400
Subject: [Rd] R CMD check and error in an \Sexpr in an Rd file
In-Reply-To: <4EB2A9F6.2060501@cbio.uct.ac.za>
References: <4EB281F4.3060109@cbio.uct.ac.za>, <4EB286E0.7070504@gmail.com>
	<438D2EC9EAFE5946B2D5864670EA468E08896B@MBXP01.ds.man.ac.uk>
	<4EB2A381.60403@cbio.uct.ac.za> <4EB2A514.30208@gmail.com>
	<4EB2A9F6.2060501@cbio.uct.ac.za>
Message-ID: <4EB2C148.5030107@gmail.com>

On 03/11/2011 10:49 AM, Renaud Gaujoux wrote:
> On 03/11/2011 16:28, Duncan Murdoch wrote:
> >  On 03/11/2011 10:21 AM, Renaud Gaujoux wrote:
> >>  Thank you Georgi.
> >>  With the fix \long the output is indeed consistent with the
> >>  documentation.
> >>  I think my use of cat() worked by luck as its output should not have
> >>  been rendered.
> >>
> >>  Would a 'results=tex' (html, text) be possible? or 'results=source' that
> >>  could be combined with \if{format}{text}?
> >>  This would allow to generate custom Latex, or HTML code, but it might
> >>  also be is hazardous...
> >
> >  Yes, that's possible.  See the manual, especially the section "2.12
> >  conditional text".
> >
> >  Duncan Murdoch
>
> Conditional text is possible, but latex or html code seem to be
> preprocessed and escaped, or maybe I am not doing the right things.

Not if you ask it not to do that.  See the example in that section of 
the manual.

Duncan Murdoch

> To test:
>
> %%%%%%%%
> \name{Sexpr}
> \alias{Sexpr}
> \title{Error and verbatim in Sexpr}
> \description{
>       Testing Sexpr in Rd files
>
>       \if{html}{\Sexpr[results=text, stage=render]{"<bold>text in
> bold</bold>"}}
>       \if{text}{\Sexpr[results=text, stage=render]{"_text in bold_"}}
>       \if{latex}{\Sexpr[results=text, stage=render]{"\\\\textbf{text in
> bold}"}}
>
>
>
> }
> %%%%%%%


From vqnguyen at uci.edu  Thu Nov  3 19:52:44 2011
From: vqnguyen at uci.edu (Vinh Nguyen)
Date: Thu, 3 Nov 2011 11:52:44 -0700
Subject: [Rd] build 32-bit R on x86_64?
In-Reply-To: <CA+2DmwgERWB+m_JsstpmQgbtYnHJVM66fKLDjXoCdGicpmVmxw@mail.gmail.com>
References: <CA+2Dmwget5gngXcUDU96GuTPFAu42weTm0TSV3HcDuMBQMF1ew@mail.gmail.com>
	<20033.52450.484029.887948@max.nulle.part>
	<44C7902F-1807-4873-877C-8CF3CC5D110B@r-project.org>
	<CA+2DmwgERWB+m_JsstpmQgbtYnHJVM66fKLDjXoCdGicpmVmxw@mail.gmail.com>
Message-ID: <CA+2DmwjLbT8CQW25qnhhjbhaX4xq01qG4jGpXn9O_9qxCtzFBg@mail.gmail.com>

Hi everyone,

I was trying to reproduce building a 32 bit version of R on a 64 bit
Ubuntu 11.04 machine (which worked before) with the latest version of
R in SVN but am getting this error:

make[3]: Leaving directory `/home/vinh/Downloads/R/trunk/src/modules/lapack'
/usr/bin/ld: skipping incompatible /usr/lib/x86_64-linux-gnu/libSM.so
when searching for -lSM
/usr/bin/ld: skipping incompatible /usr/lib/x86_64-linux-gnu/libSM.a
when searching for -lSM
/usr/bin/ld: skipping incompatible /usr/lib/x86_64-linux-gnu/libICE.so
when searching for -lICE
/usr/bin/ld: skipping incompatible /usr/lib/x86_64-linux-gnu/libICE.a
when searching for -lICE
/usr/bin/ld: skipping incompatible
/usr/lib/x86_64-linux-gnu/libpangocairo-1.0.so when searching for
-lpangocairo-1.0
...


It should be looking in /usr/lib32, not /usr/lib.  I did the following
to arrive at these messages:

sudo apt-get install ia32-libs lib32readline6-dev lib32ncurses5-dev
lib32icu-dev gcc-multilib gfortran-multilib ## ubuntu does not have
ia32-libs-dev
./configure r_arch=i386 CC='gcc -std=gnu99 -m32' CXX='g++ -m32'
FC='gfortran -m32' F77='gfortran -m32'
make -j24

Any suggestions on how to fix this?  Thanks.

-- Vinh

On Wed, Aug 10, 2011 at 8:37 AM, Vinh Nguyen <vqnguyen at uci.edu> wrote:
> On Tue, Aug 9, 2011 at 6:24 PM, Simon Urbanek
> <simon.urbanek at r-project.org> wrote:
>> It actually works ;) I'm using it for testing on my RForge.net machine and yes, it's Debian - everything just works there :).
>>
>> But back to the original question. First a minor detail, don't set environment variables use configure variables instead. Second, don't build in the source directory, always create an object directory. Third, r_arch is simply a name you set for the architecture, it has no meaning other than that it's a label.
>>
>> So now to the real stuff. If you want 32-bit build, you'll need 32-bit runtime of everything important in your system and the multilib compilers. In Debian (and thus likely in Ubuntu too) that can be achieved by something like
>>
>> sudo apt-get install ?ia32-libs-dev lib32readline6-dev lib32ncurses5-dev lib32icu-dev gcc-multilib gfortran-multilib
>>
>> Then you can build both 64-bit and 32-bit R, the difference will be in the all compiler flags -- for 64-bit you'll use -m64 (or nothing since it's the default) and for 32-bit you'll use -m32.
>>
>> So roughly something like
>>
>> tar fxz R-2.13.1.tar.gz
>> mkdir obj-32
>> cd obj-32
>> ../R-2.13.1/configure r_arch=i386 CC='gcc -std=gnu99 -m32' CXX='g++ -m32' FC='gfortran -m32' F77='gfortran -m32'
>> make -j24 && sudo make install rhome=/usr/local/R/2.13
>> cd ..
>> mkdir obj-64
>> cd obj-64
>> ../R-2.13.1/configure r_arch=amd64
>> make -j24 && sudo make install rhome=/usr/local/R/2.13
>>
>> That will leave you with multi-arch R that you can run with
>> R --arch=i386 # 32-bit
>> R --arch=amd64 # 64-bit
>> Packages will be also built as multi-libs. Good luck :)
>> [BTW the rhome=... setting is entirely optional, I just like to keep my R versions organized?]
>>
>> Cheers,
>> Simon
>>
>
> Thanks Simon! ?Confirm that these instructions work. ?ia32-libs-dev
> was not available for Ubuntu Natty, so I installed ia32-libs instead,
> and the compilation works!
>
> -- Vinh


From htl10 at users.sourceforge.net  Thu Nov  3 20:59:43 2011
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Thu, 3 Nov 2011 19:59:43 +0000 (GMT)
Subject: [Rd] non-ascii vignettes
Message-ID: <1320350383.14034.YahooMailClassic@web29503.mail.ird.yahoo.com>

Hi,

just saw "require vignettes to declare their encoding (trunk at 57560)". Having played with non-ascii vignettes (well, a lot of Chinese...) on-and-off for almost two weeks, I noticed it was a bit odd that a *commented* \usepackage[utf8]{inputenc} had any effort at all on R's Sweave behavior - while it is understandable (probably no check is made whether a "%" is before \usepackage), it is probably wrong.

Besides commented statements having an effect, I found parsing \usepackage for encoding a bit disturbing - because at one point I was considering adding non-ascii's to one of the \usepackage options (hyperref can takes non-ascii for options), and it is possible, or may be even necessary, for \usepackage's to be in a particular order. There is also another drawback: if a latex document is multi-language, it is quite customary to have different encoding in different parts - one reason is to switch fonts and the availability of glyphs. 

FWIW, I noticed it because I was adding/removing \usepackage{}'s and switching between CJK and XeTeX a fair bit to see which gives me better results. They have different font selection mechanisms and different compatible/conflicted TeX packages; CJK on TexLive uses postscript Type 1 fonts while XeTeX uses Truetype/Opentype - the typeface is the same (both using a Arphic derivative) but the visual result is different.

HTH,
Hin-Tak



From rmh at temple.edu  Fri Nov  4 01:00:43 2011
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 3 Nov 2011 20:00:43 -0400
Subject: [Rd] [R] any updates w.r.t. lapply, sapply,
	apply retaining classes
In-Reply-To: <CAKfbWjv8Zt-JSd=XSHy-HhNSsARp-ZDWH712NuLM3V6dEkQuMA@mail.gmail.com>
References: <CAKfbWjtiSziUMh3sETk6JqDKz2GsrhugGkLcWs=AKSMN+r4_kA@mail.gmail.com>
	<CANz9Z_Js6vQ3VCUG8zXwoSbLfxkhQYzpre=W6pN1TC23pqi8Yw@mail.gmail.com>
	<CAKfbWjv8Zt-JSd=XSHy-HhNSsARp-ZDWH712NuLM3V6dEkQuMA@mail.gmail.com>
Message-ID: <CAGx1TMCH+hAgxea1bZXqnhNsd+mdZNC+u7+1VsHvpBqngLXseA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111103/87e661be/attachment.pl>

From hadley at rice.edu  Fri Nov  4 01:36:07 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Fri, 4 Nov 2011 13:36:07 +1300
Subject: [Rd] [R] any updates w.r.t. lapply, sapply,
	apply retaining classes
In-Reply-To: <CAKfbWjv8Zt-JSd=XSHy-HhNSsARp-ZDWH712NuLM3V6dEkQuMA@mail.gmail.com>
References: <CAKfbWjtiSziUMh3sETk6JqDKz2GsrhugGkLcWs=AKSMN+r4_kA@mail.gmail.com>
	<CANz9Z_Js6vQ3VCUG8zXwoSbLfxkhQYzpre=W6pN1TC23pqi8Yw@mail.gmail.com>
	<CAKfbWjv8Zt-JSd=XSHy-HhNSsARp-ZDWH712NuLM3V6dEkQuMA@mail.gmail.com>
Message-ID: <CABdHhvFqwxkM8_DjUdGiB9ympzPFtj8VoviWDyfKbft7LKEMdA@mail.gmail.com>

> ? ?I agree that it is non-trivial to solve the cases you & I have posed.
> ?However, I would wholeheartedly support having an error spit back for any
> function that does not explicitly support a class. ?In this case, if I
> attempt to do ? sapply(x, class), and 'x' is of class "difftime", then I
> should receive an error "sapply cannot function upon class 'difftime' ".
> ?Why do I take this stance? ?There are at least 2 strong reasons:

I don't see why that command should be a problem because class()
returns a string.

A better example might be sapply(x, identity) which in general you
would hope to be identical to x:

x <- structure(1:10, class = "blah")
identical(x, sapply(x, identity))
# [1] FALSE

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From hb at biostat.ucsf.edu  Fri Nov  4 02:36:50 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Thu, 3 Nov 2011 18:36:50 -0700
Subject: [Rd] Call function only when running via R CMD check?
In-Reply-To: <CAFDcVCR+KazDBc-b0jhn8HkXSC6kPZrVg++0uw_tMtH-V5FB5Q@mail.gmail.com>
References: <CAFDcVCR+KazDBc-b0jhn8HkXSC6kPZrVg++0uw_tMtH-V5FB5Q@mail.gmail.com>
Message-ID: <CAFDcVCTmCRCnqpLbawE9DNRf78wYXHzjkeS5HKh1PYf0B6EVUA@mail.gmail.com>

On Wed, Nov 2, 2011 at 7:40 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> I'd like to be able to change some default settings only in the case
> when checking a package with 'R CMD check'. ?More precisely, I'd like
> to execute a piece of R code before the Rd examples and/or test
> scripts are evaluated by 'R CMD check'. ?Is there a mechanism in 'R
> CMD check' that makes this possible? ?If not, is there a way to detect
> that you are running via 'R CMD check', e.g. an R or an environment
> variable being set?
>
> The background for this is that some of my packages' examples are
> using memoization to cache computational expensive results (via the
> 'R.cache' package). ?These are cached to files which are by default
> stored under ~/.Rcache/. ? It turns out that these files live beyond
> the check cycle of the CRAN check servers, meaning that the next time
> the package is checked memoized results will be picked up. ?If I could
> detect that we're running via 'R CMD check', then I could change the
> default cache directory to a temporary directory (e.g. tempdir()) that
> will be clean out automatically.
>
> This is not a critical problem, because for now I could explicitly
> turn off the memoization in the code of my examples/regression tests,
> but the above would be a more generic solution.

I've got a few off-line suggestions (thanks).  It seems that there is
no certain way of doing this, but one can look for various evidences
available in the current R session, such as looking at the content of
commandArgs(), search() and getwd().  Trying to infer whether 'R CMD
check' runs and if it checks examples or tests based on this won't be
100% safe, but probably good enough.  Best would be if 'R CMD check'
would pass a environment variable (or a command argument) to the R
session reporting on its state (that's a wish), e.g.

R R_CMD_CHECK_STATE="checkingExamples" LANGUAGE=en --vanilla -f MyPackage-Ex.R
R R_CMD_CHECK_STATE="checkingTest" -f myTest.R --restore --save --vanilla

/Henrik

>
> Thanks
>
> Henrik
>


From this.is.mvw at gmail.com  Fri Nov  4 00:49:06 2011
From: this.is.mvw at gmail.com (Mike Williamson)
Date: Thu, 3 Nov 2011 16:49:06 -0700
Subject: [Rd] [R] any updates w.r.t. lapply, sapply,
	apply retaining classes
In-Reply-To: <CANz9Z_Js6vQ3VCUG8zXwoSbLfxkhQYzpre=W6pN1TC23pqi8Yw@mail.gmail.com>
References: <CAKfbWjtiSziUMh3sETk6JqDKz2GsrhugGkLcWs=AKSMN+r4_kA@mail.gmail.com>
	<CANz9Z_Js6vQ3VCUG8zXwoSbLfxkhQYzpre=W6pN1TC23pqi8Yw@mail.gmail.com>
Message-ID: <CAKfbWjv8Zt-JSd=XSHy-HhNSsARp-ZDWH712NuLM3V6dEkQuMA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111103/7107337a/attachment.pl>

From renaud at mancala.cbio.uct.ac.za  Fri Nov  4 11:12:44 2011
From: renaud at mancala.cbio.uct.ac.za (Renaud Gaujoux)
Date: Fri, 04 Nov 2011 12:12:44 +0200
Subject: [Rd] R CMD check and error in an \Sexpr in an Rd file
In-Reply-To: <4EB2C148.5030107@gmail.com>
References: <4EB281F4.3060109@cbio.uct.ac.za>, <4EB286E0.7070504@gmail.com>
	<438D2EC9EAFE5946B2D5864670EA468E08896B@MBXP01.ds.man.ac.uk>
	<4EB2A381.60403@cbio.uct.ac.za> <4EB2A514.30208@gmail.com>
	<4EB2A9F6.2060501@cbio.uct.ac.za> <4EB2C148.5030107@gmail.com>
Message-ID: <4EB3BA9C.2020000@cbio.uct.ac.za>

Thank you Duncan for pointing this out. I did have tried using the 
command \out with no success, but I finally manage to do what I want with:

\if{html}{\Sexpr[results=rd, 
stage=render]{"\\\\out{<pre>line\nnewline\n\nother line</pre>}"}}
\if{text}{\Sexpr[results=rd, 
stage=render]{"\\\\out{line\nnewline\n\nother line}"}}
\if{latex}{\Sexpr[results=rd, 
stage=render]{"\\\\out{\\\\begin{verbatim}line\nnewline\n\nother 
line\\\\end{verbatim}}"}}

The only remaining issue is with format 'text', that does not show 
single break lines. Double break lines are shown correctly with an empty 
line.
This can be put in a macro:

\newcommand{\rdVerb}{\if{html}{\Sexpr[results=rd, 
stage=render]{paste("\\\\\\out{<pre>",#1,"</pre>}", 
sep='')}}\if{text}{\Sexpr[results=rd, 
stage=render]{paste("\\\\\\out{",#1,"}", 
sep='')}}\if{latex}{\Sexpr[results=rd,stage=render]{paste("\\\\\\out{\\\\\\\\begin{verbatim}",#1,"\\\\\\\\end{verbatim}}", 
sep='')}}
}


which can be used as:

\rdVerb{"line\nnew line\n\nother paragraph"}

Dynamic code works as well:

\rdVerb{paste("This is the result of tools:::Rd_expr_PR(1234):", 
tools:::Rd_expr_PR(1234), sep="")}
\rdVerb{paste("This is the result of tools:::Rd_expr_PR(1234):", 
tools:::Rd_expr_PR(1234), sep="\n")}

But backslashes must be escaped twice:

\rdVerb{"\\\\\begin{section}\ntest\nsd\n\n\\\\\end{section}"}

Note that on the text version generated by the second \VERBATIM actually 
correctly shows the new line. Not sure why (?).

Renaud

-- 
Renaud Gaujoux
Computational Biology - University of Cape Town
South Africa


On 03/11/2011 18:28, Duncan Murdoch wrote:
> On 03/11/2011 10:49 AM, Renaud Gaujoux wrote:
>> On 03/11/2011 16:28, Duncan Murdoch wrote:
>> >  On 03/11/2011 10:21 AM, Renaud Gaujoux wrote:
>> >>  Thank you Georgi.
>> >>  With the fix \long the output is indeed consistent with the
>> >>  documentation.
>> >>  I think my use of cat() worked by luck as its output should not have
>> >>  been rendered.
>> >>
>> >>  Would a 'results=tex' (html, text) be possible? or 
>> 'results=source' that
>> >>  could be combined with \if{format}{text}?
>> >>  This would allow to generate custom Latex, or HTML code, but it 
>> might
>> >>  also be is hazardous...
>> >
>> >  Yes, that's possible.  See the manual, especially the section "2.12
>> >  conditional text".
>> >
>> >  Duncan Murdoch
>>
>> Conditional text is possible, but latex or html code seem to be
>> preprocessed and escaped, or maybe I am not doing the right things.
>
> Not if you ask it not to do that.  See the example in that section of 
> the manual.
>
> Duncan Murdoch
>
>> To test:
>>
>> %%%%%%%%
>> \name{Sexpr}
>> \alias{Sexpr}
>> \title{Error and verbatim in Sexpr}
>> \description{
>>       Testing Sexpr in Rd files
>>
>>       \if{html}{\Sexpr[results=text, stage=render]{"<bold>text in
>> bold</bold>"}}
>>       \if{text}{\Sexpr[results=text, stage=render]{"_text in bold_"}}
>>       \if{latex}{\Sexpr[results=text, stage=render]{"\\\\textbf{text in
>> bold}"}}
>>
>>
>>
>> }
>> %%%%%%%
>


From r.m.krug at gmail.com  Fri Nov  4 13:11:26 2011
From: r.m.krug at gmail.com (Rainer M Krug)
Date: Fri, 4 Nov 2011 13:11:26 +0100
Subject: [Rd] Error in documentation of "merge"
Message-ID: <CAGhLh6HUVje5z23wQ4wgQpKn21hcNaZD6gwqTH2LtFYB+h76iA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111104/74903cdb/attachment.pl>

From pdalgd at gmail.com  Fri Nov  4 13:20:48 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 4 Nov 2011 13:20:48 +0100
Subject: [Rd] Error in documentation of "merge"
In-Reply-To: <CAGhLh6HUVje5z23wQ4wgQpKn21hcNaZD6gwqTH2LtFYB+h76iA@mail.gmail.com>
References: <CAGhLh6HUVje5z23wQ4wgQpKn21hcNaZD6gwqTH2LtFYB+h76iA@mail.gmail.com>
Message-ID: <F4535FD0-AA00-44E1-8671-A707867E8F32@gmail.com>


On Nov 4, 2011, at 13:11 , Rainer M Krug wrote:

> Hi
> 
> there seems to be an error in the documentation of the "merge" function:
> 
> Arguments:
> 
>    x, y: data frames, or objects to be coerced to one.
> 
>  by, by.x, by.y: specifications of the common columns.  See ?Details?.
> 
>     all: logical; ?all = L? is shorthand for ?all.x = L? and ?all.y =
>          L?.
> 
> 
> The "L" should be a T or a TRUE.


I think it's on purpose: L indicates a logical value, TRUE _or_ FALSE.

-pd
-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From r.m.krug at gmail.com  Fri Nov  4 13:24:01 2011
From: r.m.krug at gmail.com (Rainer M Krug)
Date: Fri, 4 Nov 2011 13:24:01 +0100
Subject: [Rd] Error in documentation of "merge"
In-Reply-To: <F4535FD0-AA00-44E1-8671-A707867E8F32@gmail.com>
References: <CAGhLh6HUVje5z23wQ4wgQpKn21hcNaZD6gwqTH2LtFYB+h76iA@mail.gmail.com>
	<F4535FD0-AA00-44E1-8671-A707867E8F32@gmail.com>
Message-ID: <CAGhLh6GqkL6obnC_CHBHFezH2prhQKmE+P+1RkJGfxw91hz53g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111104/49709c6f/attachment.pl>

From kasperdanielhansen at gmail.com  Fri Nov  4 13:26:10 2011
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Fri, 4 Nov 2011 08:26:10 -0400
Subject: [Rd] Error in documentation of "merge"
In-Reply-To: <F4535FD0-AA00-44E1-8671-A707867E8F32@gmail.com>
References: <CAGhLh6HUVje5z23wQ4wgQpKn21hcNaZD6gwqTH2LtFYB+h76iA@mail.gmail.com>
	<F4535FD0-AA00-44E1-8671-A707867E8F32@gmail.com>
Message-ID: <CAC2h7utGdryG7fYuBSZVzBV5U1GB2ukWTVV8xQhvucqnEWwbYw@mail.gmail.com>

On Fri, Nov 4, 2011 at 8:20 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>
> On Nov 4, 2011, at 13:11 , Rainer M Krug wrote:
>
>> Hi
>>
>> there seems to be an error in the documentation of the "merge" function:
>>
>> Arguments:
>>
>> ? ?x, y: data frames, or objects to be coerced to one.
>>
>> ?by, by.x, by.y: specifications of the common columns. ?See ?Details?.
>>
>> ? ? all: logical; ?all = L? is shorthand for ?all.x = L? and ?all.y =
>> ? ? ? ? ?L?.
>>
>>
>> The "L" should be a T or a TRUE.
>
>
> I think it's on purpose: L indicates a logical value, TRUE _or_ FALSE.

I agree with Peter here.  But it did make me pause the first time I
read it on the help page years ago and furthermore, I think this is at
least the second time where this particular formulation has been
questioned on R-devel.  I am not an index of R help pages, but I
cannot recall seeing the 'L' as shorthand for logical.  I suggest
changing the formulation since it seems that several people have been
confused, for example by writing out 'logical' instead of 'L'.

Kasper


From michael.yan at oicr.on.ca  Fri Nov  4 21:37:21 2011
From: michael.yan at oicr.on.ca (Michael Yan)
Date: Fri, 4 Nov 2011 16:37:21 -0400
Subject: [Rd] Static R Build
Message-ID: <4EB44D01.308@oicr.on.ca>

Hello,

I am trying to build a statically linked R linux binary that can be 
shipped around to different unknown linux environments without having to 
rely on its local shared libraries.  However, it seems like the 
configure flag

--enable-static

doesn't produce the desired effect.  How may I do this?

Thank you for your help,
Michael


From daniel.cegielka at gmail.com  Fri Nov  4 22:20:40 2011
From: daniel.cegielka at gmail.com (=?ISO-8859-2?Q?Daniel_Cegie=B3ka?=)
Date: Fri, 4 Nov 2011 22:20:40 +0100
Subject: [Rd] Static R Build
In-Reply-To: <4EB44D01.308@oicr.on.ca>
References: <4EB44D01.308@oicr.on.ca>
Message-ID: <CAPLrYEQjjQ1+XR1GxsL4L3YttyhCu9cK3Ak9qy8wRzPu4X3=dg@mail.gmail.com>

I'm not sure, but this option applies to Rblas and Rlapack. If you
want R statically linked you need to add the "-static" to
CFLAGS/FFLAGS etc.

regards,
daniel


2011/11/4 Michael Yan <michael.yan at oicr.on.ca>:
> Hello,
>
> I am trying to build a statically linked R linux binary that can be shipped
> around to different unknown linux environments without having to rely on its
> local shared libraries. ?However, it seems like the configure flag
>
> --enable-static
>
> doesn't produce the desired effect. ?How may I do this?
>
> Thank you for your help,
> Michael
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From simon.urbanek at r-project.org  Fri Nov  4 22:32:22 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 4 Nov 2011 17:32:22 -0400
Subject: [Rd] Static R Build
In-Reply-To: <4EB44D01.308@oicr.on.ca>
References: <4EB44D01.308@oicr.on.ca>
Message-ID: <FC1AF58B-455B-4F3C-A09A-43E9689B0779@r-project.org>


On Nov 4, 2011, at 4:37 PM, Michael Yan wrote:

> Hello,
> 
> I am trying to build a statically linked R linux binary that can be shipped around to different unknown linux environments without having to rely on its local shared libraries.  However, it seems like the configure flag
> 
> --enable-static
> 
> doesn't produce the desired effect.

That flag has nothing to do with that - it governs how R library will be built, not what it links against.


>  How may I do this?
> 

Make sure you link against static libraries, but you must make sure they have PIC (if relevant for your platform). How you do that depends heavily on your system setup (and it gets really hard if you want to have things like Tcl/Tk,  ..). The easiest is to simply install static libraries only so the linker picks them up automatically. Alternatively, you can specify static libraries directly as files (remmebr that you'll need to inslude dependecies, though, since static libraries don't have dependency chain resolution). Also depending on your compiler and/or how far you want to go, you may want to use -static-libgcc and friends (but, again, you must make sure they are PIC since they will be used from shared objects: packages).

Alternative route is to put dependent shared objects into $R_HOME/lib - that's in fact by far the easiest.

Cheers,
Simon



> Thank you for your help,
> Michael
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From macrakis at alum.mit.edu  Sat Nov  5 00:19:33 2011
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Fri, 4 Nov 2011 19:19:33 -0400
Subject: [Rd] Efficiency of factor objects
Message-ID: <CACLVabVigMZ-YNr2NP_wmbs6YQhMr-LVULetnEgs8yLGPheftA@mail.gmail.com>

R factors are the natural way to represent factors -- and should be
efficient since they use small integers.  But in fact, for many (but
not all) operations, R factors are considerably slower than integers,
or even character strings.  This appears to be because whenever a
factor vector is subsetted, the entire levels vector is copied.  For
example:

> i1 <- sample(1e4,1e6,replace=T)
> c1 <- paste('x',i1)
> f1 <- factor(c1)
> system.time(replicate(1e4,{q1<-i1[100:200];1}))
   user  system elapsed
   0.03    0.00    0.04
> system.time(replicate(1e4,{q1<-c1[100:200];1}))
   user  system elapsed
   0.04    0.00    0.04
> system.time(replicate(1e4,{q1<-f1[100:200];1}))
   user  system elapsed
   0.67    0.00    0.68

Putting the levels vector in an environment speeds up subsetting:

myfactor <- function(...) {
     f <- factor(...)
     g <- unclass(f)
     class(g) <- "myfactor"
     attr(g,"mylevels") <- as.environment(list(levels=attr(f,"mylevels")))
     g }
`[.myfactor` <-
function (x, ...)
{
    y <- NextMethod("[")
    attributes(y) <- attributes(x)
    y
}

> m1 <- myfactor(f1)
> system.time(replicate(1e4,{q1<-m1[100:200];1}))
   user  system elapsed
   0.05    0.00    0.04

Given R's value semantics, I believe this approach can be extended to
most of class factor's functionality without problems, copying the
environment if necessary.  Some quick tests seem to show that this is
no slower than ordinary factors even for very small numbers of levels.
 To do this, appropriate methods for this class (print, [<-, levels<-,
etc.) would have to be written. Perhaps some core R functions also
have to be changed?

Am I missing some obvious flaw in this approach?  Has anyone already
implemented a factors package using this or some similar approach?

Thanks,

             -s


From smckinney at bccrc.ca  Sat Nov  5 02:28:03 2011
From: smckinney at bccrc.ca (Steven McKinney)
Date: Fri, 4 Nov 2011 18:28:03 -0700
Subject: [Rd] Error in documentation of "merge"
In-Reply-To: <17182_1320409602_1320409602_CAC2h7utGdryG7fYuBSZVzBV5U1GB2ukWTVV8xQhvucqnEWwbYw@mail.gmail.com>
References: <CAGhLh6HUVje5z23wQ4wgQpKn21hcNaZD6gwqTH2LtFYB+h76iA@mail.gmail.com>
	<F4535FD0-AA00-44E1-8671-A707867E8F32@gmail.com>
	<17182_1320409602_1320409602_CAC2h7utGdryG7fYuBSZVzBV5U1GB2ukWTVV8xQhvucqnEWwbYw@mail.gmail.com>
Message-ID: <DCE81E14EB74504B971DAD4D2DB0356B0892A70791@crcmail4.BCCRC.CA>



> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
> On Behalf Of Kasper Daniel Hansen
> Sent: November-04-11 5:26 AM
> To: peter dalgaard
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] Error in documentation of "merge"
> 
> On Fri, Nov 4, 2011 at 8:20 AM, peter dalgaard <pdalgd at gmail.com> wrote:
> >
> > On Nov 4, 2011, at 13:11 , Rainer M Krug wrote:
> >
> >> Hi
> >>
> >> there seems to be an error in the documentation of the "merge" function:
> >>
> >> Arguments:
> >>
> >> ? ?x, y: data frames, or objects to be coerced to one.
> >>
> >> ?by, by.x, by.y: specifications of the common columns. ?See ?Details?.
> >>
> >> ? ? all: logical; ?all = L? is shorthand for ?all.x = L? and ?all.y =
> >> ? ? ? ? ?L?.
> >>
> >>
> >> The "L" should be a T or a TRUE.
> >
> >
> > I think it's on purpose: L indicates a logical value, TRUE _or_ FALSE.
> 
> I agree with Peter here.  But it did make me pause the first time I
> read it on the help page years ago and furthermore, I think this is at
> least the second time where this particular formulation has been
> questioned on R-devel.  I am not an index of R help pages, but I
> cannot recall seeing the 'L' as shorthand for logical.  I suggest
> changing the formulation since it seems that several people have been
> confused, for example by writing out 'logical' instead of 'L'.

Seconded, as L does have another use as well now in numeric constants

> 1L
[1] 1



Steven McKinney


> 
> Kasper
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From renaud at mancala.cbio.uct.ac.za  Sat Nov  5 09:36:07 2011
From: renaud at mancala.cbio.uct.ac.za (Renaud Gaujoux)
Date: Sat, 05 Nov 2011 10:36:07 +0200
Subject: [Rd]  Identify \Sexpr call?
Message-ID: <4EB4F577.6050907@cbio.uct.ac.za>

More or less in the same vein as Henrik's post, is it possible to detect 
that a function is being called in an \Sexpr when generating an Rd file?

Thank you

-- 
Renaud Gaujoux
Computational Biology - University of Cape Town
South Africa


From murdoch.duncan at gmail.com  Sat Nov  5 16:39:13 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 05 Nov 2011 11:39:13 -0400
Subject: [Rd] Identify \Sexpr call?
In-Reply-To: <4EB4F577.6050907@cbio.uct.ac.za>
References: <4EB4F577.6050907@cbio.uct.ac.za>
Message-ID: <4EB558A1.7050403@gmail.com>

On 11-11-05 4:36 AM, Renaud Gaujoux wrote:
> More or less in the same vein as Henrik's post, is it possible to detect
> that a function is being called in an \Sexpr when generating an Rd file?
>
> Thank you
>

Sure:  have it check for a variable (or option or environment setting, 
or whatever) that was created in an earlier \Sexpr.

Or take your life in your hands, and look back up the call stack.

Duncan Murdoch


From nalimilan at club.fr  Sat Nov  5 17:30:26 2011
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Sat, 05 Nov 2011 17:30:26 +0100
Subject: [Rd] Efficiency of factor objects
In-Reply-To: <CACLVabVigMZ-YNr2NP_wmbs6YQhMr-LVULetnEgs8yLGPheftA@mail.gmail.com>
References: <CACLVabVigMZ-YNr2NP_wmbs6YQhMr-LVULetnEgs8yLGPheftA@mail.gmail.com>
Message-ID: <1320510627.31269.26.camel@milan>

Le vendredi 04 novembre 2011 ? 19:19 -0400, Stavros Macrakis a ?crit :
> R factors are the natural way to represent factors -- and should be
> efficient since they use small integers.  But in fact, for many (but
> not all) operations, R factors are considerably slower than integers,
> or even character strings.  This appears to be because whenever a
> factor vector is subsetted, the entire levels vector is copied.
Is it so common for a factor to have so many levels? One can probably
argue that, in that case, using a numeric or character vector is
preferred - factors are no longer the "natural way" of representing this
kind of data.

Adding code to fix a completely theoretical problem is generally not a
good idea. I think you'd have to come up with a real use case to hope
convincing the developers a change is needed. There are probably many
more interesting areas where speedups can be gained than that.


Regards


From jeffrey.ryan at lemnica.com  Sat Nov  5 17:45:14 2011
From: jeffrey.ryan at lemnica.com (Jeffrey Ryan)
Date: Sat, 5 Nov 2011 11:45:14 -0500
Subject: [Rd] Efficiency of factor objects
In-Reply-To: <1320510627.31269.26.camel@milan>
References: <CACLVabVigMZ-YNr2NP_wmbs6YQhMr-LVULetnEgs8yLGPheftA@mail.gmail.com>
	<1320510627.31269.26.camel@milan>
Message-ID: <CABDUZc8n8CV8LgsUbm2UUaUGfu7wfNqVjbAiZOW7-UwJczaHsw@mail.gmail.com>

Or better still, extend R via the mechanisms in place.  Something akin
to a fast factor package.  Any change to R causes downstream issues in
(hundreds of?) millions of lines of deployed code.

It almost seems hard to fathom that a package for this doesn't already
exist. Have you searched CRAN?

Jeff



On Sat, Nov 5, 2011 at 11:30 AM, Milan Bouchet-Valat <nalimilan at club.fr> wrote:
> Le vendredi 04 novembre 2011 ? 19:19 -0400, Stavros Macrakis a ?crit :
>> R factors are the natural way to represent factors -- and should be
>> efficient since they use small integers. ?But in fact, for many (but
>> not all) operations, R factors are considerably slower than integers,
>> or even character strings. ?This appears to be because whenever a
>> factor vector is subsetted, the entire levels vector is copied.
> Is it so common for a factor to have so many levels? One can probably
> argue that, in that case, using a numeric or character vector is
> preferred - factors are no longer the "natural way" of representing this
> kind of data.
>
> Adding code to fix a completely theoretical problem is generally not a
> good idea. I think you'd have to come up with a real use case to hope
> convincing the developers a change is needed. There are probably many
> more interesting areas where speedups can be gained than that.
>
>
> Regards
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Jeffrey Ryan
jeffrey.ryan at lemnica.com

www.lemnica.com
www.esotericR.com


From pburns at pburns.seanet.com  Sat Nov  5 19:12:56 2011
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Sat, 05 Nov 2011 18:12:56 +0000
Subject: [Rd] Efficiency of factor objects
In-Reply-To: <CABDUZc8n8CV8LgsUbm2UUaUGfu7wfNqVjbAiZOW7-UwJczaHsw@mail.gmail.com>
References: <CACLVabVigMZ-YNr2NP_wmbs6YQhMr-LVULetnEgs8yLGPheftA@mail.gmail.com>
	<1320510627.31269.26.camel@milan>
	<CABDUZc8n8CV8LgsUbm2UUaUGfu7wfNqVjbAiZOW7-UwJczaHsw@mail.gmail.com>
Message-ID: <4EB57CA8.3000404@pburns.seanet.com>

Perhaps 'data.table' would be a package
on CRAN that would be acceptable.

On 05/11/2011 16:45, Jeffrey Ryan wrote:
> Or better still, extend R via the mechanisms in place.  Something akin
> to a fast factor package.  Any change to R causes downstream issues in
> (hundreds of?) millions of lines of deployed code.
>
> It almost seems hard to fathom that a package for this doesn't already
> exist. Have you searched CRAN?
>
> Jeff
>
>
>
> On Sat, Nov 5, 2011 at 11:30 AM, Milan Bouchet-Valat<nalimilan at club.fr>  wrote:
>> Le vendredi 04 novembre 2011 ? 19:19 -0400, Stavros Macrakis a ?crit :
>>> R factors are the natural way to represent factors -- and should be
>>> efficient since they use small integers.  But in fact, for many (but
>>> not all) operations, R factors are considerably slower than integers,
>>> or even character strings.  This appears to be because whenever a
>>> factor vector is subsetted, the entire levels vector is copied.
>> Is it so common for a factor to have so many levels? One can probably
>> argue that, in that case, using a numeric or character vector is
>> preferred - factors are no longer the "natural way" of representing this
>> kind of data.
>>
>> Adding code to fix a completely theoretical problem is generally not a
>> good idea. I think you'd have to come up with a real use case to hope
>> convincing the developers a change is needed. There are probably many
>> more interesting areas where speedups can be gained than that.
>>
>>
>> Regards
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>

-- 
Patrick Burns
pburns at pburns.seanet.com
twitter: @portfolioprobe
http://www.portfolioprobe.com/blog
http://www.burns-stat.com
(home of 'Some hints for the R beginner'
and 'The R Inferno')


From hb at biostat.ucsf.edu  Sat Nov  5 23:08:48 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sat, 5 Nov 2011 15:08:48 -0700
Subject: [Rd] How to infer default width and height for a device?
Message-ID: <CAFDcVCRGOwoTe7KR1O4erRagTG0xwrrf2+SfrRV=WwW1W=YrDg@mail.gmail.com>

Hi.

GENERAL:
Is there a general method for inferring default device settings,
particularly 'width' and 'height', that works for all devices?  AFAIK,
the answer is no, but there might be functions out there that I don't
know of.


POSTSCRIPT SPECIFIC:
If not, I'm considering implementing such a method myself.  Is it
possible for R to infer the default 'width' and 'height' for the
*postscript* device, or is this defined outside of R?  I've noticed
that they are not defined by the arguments to postcript():

> args(grDevices::postscript)
function (file = ifelse(onefile, "Rplots.ps", "Rplot%03d.ps"),
    onefile, family, title, fonts, encoding, bg, fg, width, height,
    horizontal, pointsize, paper, pagecentre, print.it, command,
    colormodel, useKerning, fillOddEven)

and in the list of predefined device options they are zero:

> ps.options()[c("width", "height")]
$width
[1] 0
$height
[1] 0

and debugging postcript() they are indeed passed as zeros to
.External(PostScript, ...).


> sessionInfo()
R version 2.14.0 Patched (2011-11-03 r57560)
Platform: x86_64-pc-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] R.utils_1.9.0     R.oo_1.8.3        R.methodsS3_1.2.1

loaded via a namespace (and not attached):
[1] tools_2.14.0

Thanks

Henrik


From hb at biostat.ucsf.edu  Sat Nov  5 23:35:38 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sat, 5 Nov 2011 15:35:38 -0700
Subject: [Rd] How to infer default width and height for a device?
In-Reply-To: <CAFDcVCRGOwoTe7KR1O4erRagTG0xwrrf2+SfrRV=WwW1W=YrDg@mail.gmail.com>
References: <CAFDcVCRGOwoTe7KR1O4erRagTG0xwrrf2+SfrRV=WwW1W=YrDg@mail.gmail.com>
Message-ID: <CAFDcVCR8OwBVVDuuqO+pz0wBBmz2PpGd8rMvKhxwCztz=hjitA@mail.gmail.com>

On Sat, Nov 5, 2011 at 3:08 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> Hi.
>
> GENERAL:
> Is there a general method for inferring default device settings,
> particularly 'width' and 'height', that works for all devices? ?AFAIK,
> the answer is no, but there might be functions out there that I don't
> know of.
>
>
> POSTSCRIPT SPECIFIC:
> If not, I'm considering implementing such a method myself. ?Is it
> possible for R to infer the default 'width' and 'height' for the
> *postscript* device, or is this defined outside of R? ?I've noticed
> that they are not defined by the arguments to postcript():
>
>> args(grDevices::postscript)
> function (file = ifelse(onefile, "Rplots.ps", "Rplot%03d.ps"),
> ? ?onefile, family, title, fonts, encoding, bg, fg, width, height,
> ? ?horizontal, pointsize, paper, pagecentre, print.it, command,
> ? ?colormodel, useKerning, fillOddEven)
>
> and in the list of predefined device options they are zero:
>
>> ps.options()[c("width", "height")]
> $width
> [1] 0
> $height
> [1] 0
>
> and debugging postcript() they are indeed passed as zeros to
> .External(PostScript, ...).

I've already got one reply offline (thanks) pointing me to
help("postcript") and its argument 'paper':

<quote>the size of paper in the printer. The choices are "a4",
"letter" (or "us"), "legal" and "executive" (and these can be
capitalized). Also, "special" can be used, when arguments width and
height specify the paper size. A further choice is "default" (the
default): If this is selected, the papersize is taken from the option
"papersize" if that is set and to "a4" if it is unset or
empty.</quote>

which in code becomes:

  getPSDimensions <- function(options=ps.options(), ...) {
    knownDimensions <- list(
      executive=c(7.25,10.5),
      legal=c(8.5,14),
      letter=c(8.5,11),
      a4=c(8.27, 11.69)
    );

    # See argument 'paper' in help("postcript").
    paper <- tolower(options$paper);

    if (paper == "default") {
      paper <- getOption("papersize", "a4");
    }

    knownDimensions[[paper]];
  } # getPSDimensions()

/Henrik


>
>
>> sessionInfo()
> R version 2.14.0 Patched (2011-11-03 r57560)
> Platform: x86_64-pc-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
> other attached packages:
> [1] R.utils_1.9.0 ? ? R.oo_1.8.3 ? ? ? ?R.methodsS3_1.2.1
>
> loaded via a namespace (and not attached):
> [1] tools_2.14.0
>
> Thanks
>
> Henrik
>


From patrick.giraudoux at univ-fcomte.fr  Sun Nov  6 18:46:47 2011
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sun, 06 Nov 2011 18:46:47 +0100
Subject: [Rd] Error in gzfile(file,
 mode) when checking a package with rcmd check
In-Reply-To: <CANz9Z_Le2kOxm6GkGmeMnWjtB0DexLq6jSvQOJdCvNwHsSkzZQ@mail.gmail.com>
References: <4E9A8CDF.70801@univ-fcomte.fr> <4E9A9D8E.1090304@univ-fcomte.fr>
	<4E9AA386.7010008@univ-fcomte.fr>
	<CANz9Z_Le2kOxm6GkGmeMnWjtB0DexLq6jSvQOJdCvNwHsSkzZQ@mail.gmail.com>
Message-ID: <4EB6C807.30601@univ-fcomte.fr>

Following Uwe Ligges' instructions (off list) I have updated Duncan 
Murdoch's toolchain, with no effect. The trouble was solved when I moved 
the package to a directory with a shorter path (U:\Documents and 
Settings\pgiraudo\Bureau instead of U:\Documents and 
Settings\pgiraudo\Mes documents\R\pgir_arch\pgirmess_arch\On work) and 
then things went trough smoothly.

What puzzles me is that the "long" path did not make a problem until R 
2.13.1 (this is the directory in which I worked since years for package 
development) and that something seems to have happened after upgrading 
to R 2.13.2

Anyway. The main thing: I have a way to package now.

Patrick







Le 16/10/2011 17:54, Joshua Wiley a ?crit :
> Hmm, I have not had any difficulty with 2.13.2 on
> x86_64-pc-mingw32/x64, but I do have trouble with R CMD check on R
> devel, as has another user now.  It is never with building or
> installing, just the checking.  In my case, the error comes when
> building the manual.
>
> 2011/10/16 Patrick Giraudoux<patrick.giraudoux at univ-fcomte.fr>:
>> Also have just tried to build the package with no preliminary check. The
>> package apparently builds OK, tar.gz as well as binary .zip. Really looks
>> like the error has to do with the rcmd check command specifically... May it
>> be a bug ? Suppose I am not the only one to have checked a package since R
>> 2.13.2 has been delivered ?
>>
>> Patrick
>>
>>
>> Le 16/10/2011 11:02, Patrick Giraudoux a ?crit :
>>> PS: looks like if it has something to do with moving from R 2.13.1 to R
>>> 2.13.2, since I cannot even check earlier versions of the pgirmess package
>>> that where well checked and compiled under earlier R versions.
>>>
>>>
>>> Le 16/10/2011 09:50, Patrick Giraudoux a ?crit :
>>>> Hi,
>>>>
>>>> For the first time I have a strange behaviour when checking a package
>>>> before 'packaging' the code. Looks like a file cannot be read.
>>>>
>>>> rcmd check pgirmess
>>>>
>>>> * using log directory 'U:/Documents and Settings/pgiraudo/Mes
>>>> documents/R/pgir_arch/pgirmess_arch/On work/pgirmess.Rcheck'
>>>> * using R version 2.13.2 (2011-09-30)
>>>> * using platform: i386-pc-mingw32 (32-bit)
>>>> * using session charset: ISO8859-1
>>>> * checking for file 'pgirmess/DESCRIPTION' ... OK
>>>> * this is package 'pgirmess' version '1.5.2'
>>>> * checking package dependencies ... OK
>>>> * checking if this is a source package ... OK
>>>> * checking for .dll and .exe files ... OK
>>>> * checking whether package 'pgirmess' can be installed ... ERROR
>>>> Installation failed.
>>>> See 'U:/Documents and Settings/pgiraudo/Mes
>>>> documents/R/pgir_arch/pgirmess_arch/On work/pgirmess.Rcheck/00install.out'
>>>> for details.
>>>>
>>>>
>>>> In '00install.out',  I get:
>>>>
>>>> * installing *source* package 'pgirmess' ...
>>>> ** R
>>>> ** data
>>>> ** preparing package for lazy loading
>>>> ** help
>>>> *** installing help indices
>>>> ** building package indices ...
>>>> ** testing if installed package can be loaded Error in gzfile(file, mode)
>>>> : cannot open the connection
>>>> Calls: %in% ->  match ->  installed.packages ->  saveRDS ->  gzfile
>>>> In addition: Warning message:
>>>> In gzfile(file, mode) :
>>>>   cannot open compressed file
>>>> 'U:\DOCUME~1\Admin\LOCALS~1\Temp\RtmpwWcmem/libloc_U%3a%2fDocuments%20and%20Settings%2fpgiraudo%2fMes%20documents%2fR%2fpgir_arch%2fpgirmess_arch%2fOn%20work%2fpgirmess.RcheckVersion,Priority,Depends,Imports,LinkingTo,Suggests,Enhances,OS_type,License,Archs,Built.rds',
>>>> probable reason 'No such file or directory'
>>>> Execution halted
>>>> ERROR: loading failed
>>>> * removing
>>>> 'U:/DOCUME~1/pgiraudo/MESDOC~1/R/PGIR_A~1/PGIRME~1/ONWORK~1/PGIRME~1.RCH/pgirmess'
>>>>
>>>> Any hint welcome ! I am stuck on that.
>>>>
>>>> Patrick
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>


From ligges at statistik.tu-dortmund.de  Sun Nov  6 18:57:06 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 06 Nov 2011 18:57:06 +0100
Subject: [Rd] Error in gzfile(file,
 mode) when checking a package with rcmd check
In-Reply-To: <4EB6C807.30601@univ-fcomte.fr>
References: <4E9A8CDF.70801@univ-fcomte.fr> <4E9A9D8E.1090304@univ-fcomte.fr>
	<4E9AA386.7010008@univ-fcomte.fr>
	<CANz9Z_Le2kOxm6GkGmeMnWjtB0DexLq6jSvQOJdCvNwHsSkzZQ@mail.gmail.com>
	<4EB6C807.30601@univ-fcomte.fr>
Message-ID: <4EB6CA72.4090609@statistik.tu-dortmund.de>

On 06.11.2011 18:46, Patrick Giraudoux wrote:
> Following Uwe Ligges' instructions (off list) I have updated Duncan
> Murdoch's toolchain, with no effect. The trouble was solved when I moved
> the package to a directory with a shorter path (U:\Documents and
> Settings\pgiraudo\Bureau instead of U:\Documents and
> Settings\pgiraudo\Mes documents\R\pgir_arch\pgirmess_arch\On work) and
> then things went trough smoothly.


It is really "Mes documents" or just what Microsoft translates this way 
in the Windows Explorer? It may help to use the correct names then.

Anyway, I have seen another problem where non ASCII characters matter 
and will digg...

Best,
Uwe Ligges


> What puzzles me is that the "long" path did not make a problem until R
> 2.13.1 (this is the directory in which I worked since years for package
> development) and that something seems to have happened after upgrading
> to R 2.13.2
>
> Anyway. The main thing: I have a way to package now.
>
> Patrick
>
>
>
>
>
>
>
> Le 16/10/2011 17:54, Joshua Wiley a ?crit :
>> Hmm, I have not had any difficulty with 2.13.2 on
>> x86_64-pc-mingw32/x64, but I do have trouble with R CMD check on R
>> devel, as has another user now. It is never with building or
>> installing, just the checking. In my case, the error comes when
>> building the manual.
>>
>> 2011/10/16 Patrick Giraudoux<patrick.giraudoux at univ-fcomte.fr>:
>>> Also have just tried to build the package with no preliminary check. The
>>> package apparently builds OK, tar.gz as well as binary .zip. Really
>>> looks
>>> like the error has to do with the rcmd check command specifically...
>>> May it
>>> be a bug ? Suppose I am not the only one to have checked a package
>>> since R
>>> 2.13.2 has been delivered ?
>>>
>>> Patrick
>>>
>>>
>>> Le 16/10/2011 11:02, Patrick Giraudoux a ?crit :
>>>> PS: looks like if it has something to do with moving from R 2.13.1 to R
>>>> 2.13.2, since I cannot even check earlier versions of the pgirmess
>>>> package
>>>> that where well checked and compiled under earlier R versions.
>>>>
>>>>
>>>> Le 16/10/2011 09:50, Patrick Giraudoux a ?crit :
>>>>> Hi,
>>>>>
>>>>> For the first time I have a strange behaviour when checking a package
>>>>> before 'packaging' the code. Looks like a file cannot be read.
>>>>>
>>>>> rcmd check pgirmess
>>>>>
>>>>> * using log directory 'U:/Documents and Settings/pgiraudo/Mes
>>>>> documents/R/pgir_arch/pgirmess_arch/On work/pgirmess.Rcheck'
>>>>> * using R version 2.13.2 (2011-09-30)
>>>>> * using platform: i386-pc-mingw32 (32-bit)
>>>>> * using session charset: ISO8859-1
>>>>> * checking for file 'pgirmess/DESCRIPTION' ... OK
>>>>> * this is package 'pgirmess' version '1.5.2'
>>>>> * checking package dependencies ... OK
>>>>> * checking if this is a source package ... OK
>>>>> * checking for .dll and .exe files ... OK
>>>>> * checking whether package 'pgirmess' can be installed ... ERROR
>>>>> Installation failed.
>>>>> See 'U:/Documents and Settings/pgiraudo/Mes
>>>>> documents/R/pgir_arch/pgirmess_arch/On
>>>>> work/pgirmess.Rcheck/00install.out'
>>>>> for details.
>>>>>
>>>>>
>>>>> In '00install.out', I get:
>>>>>
>>>>> * installing *source* package 'pgirmess' ...
>>>>> ** R
>>>>> ** data
>>>>> ** preparing package for lazy loading
>>>>> ** help
>>>>> *** installing help indices
>>>>> ** building package indices ...
>>>>> ** testing if installed package can be loaded Error in gzfile(file,
>>>>> mode)
>>>>> : cannot open the connection
>>>>> Calls: %in% -> match -> installed.packages -> saveRDS -> gzfile
>>>>> In addition: Warning message:
>>>>> In gzfile(file, mode) :
>>>>> cannot open compressed file
>>>>> 'U:\DOCUME~1\Admin\LOCALS~1\Temp\RtmpwWcmem/libloc_U%3a%2fDocuments%20and%20Settings%2fpgiraudo%2fMes%20documents%2fR%2fpgir_arch%2fpgirmess_arch%2fOn%20work%2fpgirmess.RcheckVersion,Priority,Depends,Imports,LinkingTo,Suggests,Enhances,OS_type,License,Archs,Built.rds',
>>>>>
>>>>> probable reason 'No such file or directory'
>>>>> Execution halted
>>>>> ERROR: loading failed
>>>>> * removing
>>>>> 'U:/DOCUME~1/pgiraudo/MESDOC~1/R/PGIR_A~1/PGIRME~1/ONWORK~1/PGIRME~1.RCH/pgirmess'
>>>>>
>>>>>
>>>>> Any hint welcome ! I am stuck on that.
>>>>>
>>>>> Patrick
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From patrick.giraudoux at univ-fcomte.fr  Sun Nov  6 19:31:13 2011
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sun, 06 Nov 2011 19:31:13 +0100
Subject: [Rd] Error in gzfile(file,
 mode) when checking a package with rcmd check
In-Reply-To: <4EB6CA72.4090609@statistik.tu-dortmund.de>
References: <4E9A8CDF.70801@univ-fcomte.fr> <4E9A9D8E.1090304@univ-fcomte.fr>
	<4E9AA386.7010008@univ-fcomte.fr>
	<CANz9Z_Le2kOxm6GkGmeMnWjtB0DexLq6jSvQOJdCvNwHsSkzZQ@mail.gmail.com>
	<4EB6C807.30601@univ-fcomte.fr>
	<4EB6CA72.4090609@statistik.tu-dortmund.de>
Message-ID: <4EB6D271.1070300@univ-fcomte.fr>

Le 06/11/2011 18:57, Uwe Ligges a ?crit :
> On 06.11.2011 18:46, Patrick Giraudoux wrote:
>> Following Uwe Ligges' instructions (off list) I have updated Duncan
>> Murdoch's toolchain, with no effect. The trouble was solved when I moved
>> the package to a directory with a shorter path (U:\Documents and
>> Settings\pgiraudo\Bureau instead of U:\Documents and
>> Settings\pgiraudo\Mes documents\R\pgir_arch\pgirmess_arch\On work) and
>> then things went trough smoothly.
>
>
> It is really "Mes documents" or just what Microsoft translates this 
> way in the Windows Explorer? It may help to use the correct names then.

Looks like being "Mes documents" although I don't know how to check if 
it is translated or not on the system level. Actually the French 
translation of the English original "My Documents".

However I have tried moving the folder pgirmess one level up to

U:\Documents and Settings\pgiraudo\Bureau instead of U:\Documents and 
Settings\pgiraudo\Mes documents\R\pgir_arch\pgirmess_arch\

and then running rcmd check..... and.... it works (tried twice, both 
OK). Means "Mes documents" seems not to be the real cause, but the "On 
Work" directory. However, replacing "On Work" by "On_work" gives a 
failure as before. Conclusion: looks like if the "space" character is 
not the problem, but the length of the path or the number of embedded 
directories (?).

Patrick









>
> Anyway, I have seen another problem where non ASCII characters matter 
> and will digg...
>
> Best,
> Uwe Ligges
>
>
>> What puzzles me is that the "long" path did not make a problem until R
>> 2.13.1 (this is the directory in which I worked since years for package
>> development) and that something seems to have happened after upgrading
>> to R 2.13.2
>>
>> Anyway. The main thing: I have a way to package now.
>>
>> Patrick
>>
>>
>>
>>
>>
>>
>>
>> Le 16/10/2011 17:54, Joshua Wiley a ?crit :
>>> Hmm, I have not had any difficulty with 2.13.2 on
>>> x86_64-pc-mingw32/x64, but I do have trouble with R CMD check on R
>>> devel, as has another user now. It is never with building or
>>> installing, just the checking. In my case, the error comes when
>>> building the manual.
>>>
>>> 2011/10/16 Patrick Giraudoux<patrick.giraudoux at univ-fcomte.fr>:
>>>> Also have just tried to build the package with no preliminary 
>>>> check. The
>>>> package apparently builds OK, tar.gz as well as binary .zip. Really
>>>> looks
>>>> like the error has to do with the rcmd check command specifically...
>>>> May it
>>>> be a bug ? Suppose I am not the only one to have checked a package
>>>> since R
>>>> 2.13.2 has been delivered ?
>>>>
>>>> Patrick
>>>>
>>>>
>>>> Le 16/10/2011 11:02, Patrick Giraudoux a ?crit :
>>>>> PS: looks like if it has something to do with moving from R 2.13.1 
>>>>> to R
>>>>> 2.13.2, since I cannot even check earlier versions of the pgirmess
>>>>> package
>>>>> that where well checked and compiled under earlier R versions.
>>>>>
>>>>>
>>>>> Le 16/10/2011 09:50, Patrick Giraudoux a ?crit :
>>>>>> Hi,
>>>>>>
>>>>>> For the first time I have a strange behaviour when checking a 
>>>>>> package
>>>>>> before 'packaging' the code. Looks like a file cannot be read.
>>>>>>
>>>>>> rcmd check pgirmess
>>>>>>
>>>>>> * using log directory 'U:/Documents and Settings/pgiraudo/Mes
>>>>>> documents/R/pgir_arch/pgirmess_arch/On work/pgirmess.Rcheck'
>>>>>> * using R version 2.13.2 (2011-09-30)
>>>>>> * using platform: i386-pc-mingw32 (32-bit)
>>>>>> * using session charset: ISO8859-1
>>>>>> * checking for file 'pgirmess/DESCRIPTION' ... OK
>>>>>> * this is package 'pgirmess' version '1.5.2'
>>>>>> * checking package dependencies ... OK
>>>>>> * checking if this is a source package ... OK
>>>>>> * checking for .dll and .exe files ... OK
>>>>>> * checking whether package 'pgirmess' can be installed ... ERROR
>>>>>> Installation failed.
>>>>>> See 'U:/Documents and Settings/pgiraudo/Mes
>>>>>> documents/R/pgir_arch/pgirmess_arch/On
>>>>>> work/pgirmess.Rcheck/00install.out'
>>>>>> for details.
>>>>>>
>>>>>>
>>>>>> In '00install.out', I get:
>>>>>>
>>>>>> * installing *source* package 'pgirmess' ...
>>>>>> ** R
>>>>>> ** data
>>>>>> ** preparing package for lazy loading
>>>>>> ** help
>>>>>> *** installing help indices
>>>>>> ** building package indices ...
>>>>>> ** testing if installed package can be loaded Error in gzfile(file,
>>>>>> mode)
>>>>>> : cannot open the connection
>>>>>> Calls: %in% -> match -> installed.packages -> saveRDS -> gzfile
>>>>>> In addition: Warning message:
>>>>>> In gzfile(file, mode) :
>>>>>> cannot open compressed file
>>>>>> 'U:\DOCUME~1\Admin\LOCALS~1\Temp\RtmpwWcmem/libloc_U%3a%2fDocuments%20and%20Settings%2fpgiraudo%2fMes%20documents%2fR%2fpgir_arch%2fpgirmess_arch%2fOn%20work%2fpgirmess.RcheckVersion,Priority,Depends,Imports,LinkingTo,Suggests,Enhances,OS_type,License,Archs,Built.rds', 
>>>>>>
>>>>>>
>>>>>> probable reason 'No such file or directory'
>>>>>> Execution halted
>>>>>> ERROR: loading failed
>>>>>> * removing
>>>>>> 'U:/DOCUME~1/pgiraudo/MESDOC~1/R/PGIR_A~1/PGIRME~1/ONWORK~1/PGIRME~1.RCH/pgirmess' 
>>>>>>
>>>>>>
>>>>>>
>>>>>> Any hint welcome ! I am stuck on that.
>>>>>>
>>>>>> Patrick
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From nalimilan at club.fr  Sun Nov  6 19:47:59 2011
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Sun, 06 Nov 2011 19:47:59 +0100
Subject: [Rd] Error in gzfile(file,
 mode) when checking a package with rcmd check
In-Reply-To: <4EB6D271.1070300@univ-fcomte.fr>
References: <4E9A8CDF.70801@univ-fcomte.fr>
	<4E9A9D8E.1090304@univ-fcomte.fr> <4E9AA386.7010008@univ-fcomte.fr>
	<CANz9Z_Le2kOxm6GkGmeMnWjtB0DexLq6jSvQOJdCvNwHsSkzZQ@mail.gmail.com>
	<4EB6C807.30601@univ-fcomte.fr>
	<4EB6CA72.4090609@statistik.tu-dortmund.de>
	<4EB6D271.1070300@univ-fcomte.fr>
Message-ID: <1320605279.30493.8.camel@milan>

Le dimanche 06 novembre 2011 ? 19:31 +0100, Patrick Giraudoux a ?crit :
> Means "Mes documents" seems not to be the real cause, but the "On 
> Work" directory. However, replacing "On Work" by "On_work" gives a 
> failure as before. Conclusion: looks like if the "space" character is 
> not the problem, but the length of the path or the number of embedded 
> directories (?).
Is "On Work" the actual name, or a translation? Accentuated characters
are often the cause of bugs in filenames.


Cheers


From patrick.giraudoux at univ-fcomte.fr  Sun Nov  6 19:59:01 2011
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sun, 06 Nov 2011 19:59:01 +0100
Subject: [Rd] Error in gzfile(file,
 mode) when checking a package with rcmd check
In-Reply-To: <1320605279.30493.8.camel@milan>
References: <4E9A8CDF.70801@univ-fcomte.fr> <4E9A9D8E.1090304@univ-fcomte.fr>
	<4E9AA386.7010008@univ-fcomte.fr>
	<CANz9Z_Le2kOxm6GkGmeMnWjtB0DexLq6jSvQOJdCvNwHsSkzZQ@mail.gmail.com>
	<4EB6C807.30601@univ-fcomte.fr>
	<4EB6CA72.4090609@statistik.tu-dortmund.de>
	<4EB6D271.1070300@univ-fcomte.fr> <1320605279.30493.8.camel@milan>
Message-ID: <4EB6D8F5.5040200@univ-fcomte.fr>

Le 06/11/2011 19:47, Milan Bouchet-Valat a ?crit :
> Le dimanche 06 novembre 2011 ? 19:31 +0100, Patrick Giraudoux a ?crit :
>> Means "Mes documents" seems not to be the real cause, but the "On
>> Work" directory. However, replacing "On Work" by "On_work" gives a
>> failure as before. Conclusion: looks like if the "space" character is
>> not the problem, but the length of the path or the number of embedded
>> directories (?).
> Is "On Work" the actual name, or a translation? Accentuated characters
> are often the cause of bugs in filenames.
>
>
> Cheers
>

Yes. There is no accent just a space as in "Documents and settings" or 
"My Documents" or "Mes documents". To check if there was really a 
'space' problem, I have renamed "On Work" to "On_work" (with no space), 
and rcmd check does not work better.

Rcmd check works fine only when the pgirmess folder is moved one 
directory up (so still on a path that still have 'space' in directory 
names, e.g. "Documents and Settings" and "Mes documents".

Quite strange.


From murdoch.duncan at gmail.com  Sun Nov  6 20:27:03 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 06 Nov 2011 14:27:03 -0500
Subject: [Rd] Error in gzfile(file,
 mode) when checking a package with rcmd check
In-Reply-To: <4EB6D8F5.5040200@univ-fcomte.fr>
References: <4E9A8CDF.70801@univ-fcomte.fr> <4E9A9D8E.1090304@univ-fcomte.fr>
	<4E9AA386.7010008@univ-fcomte.fr>
	<CANz9Z_Le2kOxm6GkGmeMnWjtB0DexLq6jSvQOJdCvNwHsSkzZQ@mail.gmail.com>
	<4EB6C807.30601@univ-fcomte.fr>
	<4EB6CA72.4090609@statistik.tu-dortmund.de>
	<4EB6D271.1070300@univ-fcomte.fr> <1320605279.30493.8.camel@milan>
	<4EB6D8F5.5040200@univ-fcomte.fr>
Message-ID: <4EB6DF87.8030505@gmail.com>

On 11-11-06 1:59 PM, Patrick Giraudoux wrote:
> Le 06/11/2011 19:47, Milan Bouchet-Valat a ?crit :
>> Le dimanche 06 novembre 2011 ? 19:31 +0100, Patrick Giraudoux a ?crit :
>>> Means "Mes documents" seems not to be the real cause, but the "On
>>> Work" directory. However, replacing "On Work" by "On_work" gives a
>>> failure as before. Conclusion: looks like if the "space" character is
>>> not the problem, but the length of the path or the number of embedded
>>> directories (?).
>> Is "On Work" the actual name, or a translation? Accentuated characters
>> are often the cause of bugs in filenames.
>>
>>
>> Cheers
>>
>
> Yes. There is no accent just a space as in "Documents and settings" or
> "My Documents" or "Mes documents". To check if there was really a
> 'space' problem, I have renamed "On Work" to "On_work" (with no space),
> and rcmd check does not work better.
>
> Rcmd check works fine only when the pgirmess folder is moved one
> directory up (so still on a path that still have 'space' in directory
> names, e.g. "Documents and Settings" and "Mes documents".
>
> Quite strange.

Windows historically had quite a short limit on pathnames (something 
like 260 characters, or bytes), and also on command lines.  I don't know 
what the current limits are, but R has the 260 limit coded into it, and 
likely some of our other tools do too.  Your paths don't approach that 
limit, but once you put several copies of them into one command line, 
you would.  I suspect that's what is catching you.

Duncan Murdoch


From hb at biostat.ucsf.edu  Sun Nov  6 20:57:06 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sun, 6 Nov 2011 11:57:06 -0800
Subject: [Rd] Error in gzfile(file,
 mode) when checking a package with rcmd check
In-Reply-To: <4EB6DF87.8030505@gmail.com>
References: <4E9A8CDF.70801@univ-fcomte.fr> <4E9A9D8E.1090304@univ-fcomte.fr>
	<4E9AA386.7010008@univ-fcomte.fr>
	<CANz9Z_Le2kOxm6GkGmeMnWjtB0DexLq6jSvQOJdCvNwHsSkzZQ@mail.gmail.com>
	<4EB6C807.30601@univ-fcomte.fr>
	<4EB6CA72.4090609@statistik.tu-dortmund.de>
	<4EB6D271.1070300@univ-fcomte.fr> <1320605279.30493.8.camel@milan>
	<4EB6D8F5.5040200@univ-fcomte.fr> <4EB6DF87.8030505@gmail.com>
Message-ID: <CAFDcVCShAuEOX0WjWnzGDFBD6QVMDc7KPf_k0qdGc6dJ7G7RwQ@mail.gmail.com>

On Sun, Nov 6, 2011 at 11:27 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 11-11-06 1:59 PM, Patrick Giraudoux wrote:
>>
>> Le 06/11/2011 19:47, Milan Bouchet-Valat a ?crit :
>>>
>>> Le dimanche 06 novembre 2011 ? 19:31 +0100, Patrick Giraudoux a ?crit :
>>>>
>>>> Means "Mes documents" seems not to be the real cause, but the "On
>>>> Work" directory. However, replacing "On Work" by "On_work" gives a
>>>> failure as before. Conclusion: looks like if the "space" character is
>>>> not the problem, but the length of the path or the number of embedded
>>>> directories (?).
>>>
>>> Is "On Work" the actual name, or a translation? Accentuated characters
>>> are often the cause of bugs in filenames.
>>>
>>>
>>> Cheers
>>>
>>
>> Yes. There is no accent just a space as in "Documents and settings" or
>> "My Documents" or "Mes documents". To check if there was really a
>> 'space' problem, I have renamed "On Work" to "On_work" (with no space),
>> and rcmd check does not work better.
>>
>> Rcmd check works fine only when the pgirmess folder is moved one
>> directory up (so still on a path that still have 'space' in directory
>> names, e.g. "Documents and Settings" and "Mes documents".
>>
>> Quite strange.
>
> Windows historically had quite a short limit on pathnames (something like
> 260 characters, or bytes), and also on command lines. ?I don't know what the
> current limits are, but R has the 260 limit coded into it, and likely some
> of our other tools do too. ?Your paths don't approach that limit, but once
> you put several copies of them into one command line, you would. ?I suspect
> that's what is catching you.

The below page with references explains that issue further:

 http://aroma-project.org/howtos/UseLongFilenamesOnWindows

/Henrik

>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From macrakis at alum.mit.edu  Mon Nov  7 01:00:02 2011
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Sun, 6 Nov 2011 19:00:02 -0500
Subject: [Rd] Efficiency of factor objects
Message-ID: <CACLVabW52=nin_7_FDnAPQK=WWGhShnuz-SSdsqKi-0iMMom4A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111106/d90a99e5/attachment.pl>

From hb at biostat.ucsf.edu  Mon Nov  7 01:41:22 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sun, 6 Nov 2011 16:41:22 -0800
Subject: [Rd] CRAN: How to list a non-Sweave doc under "Vignettes:" on
	package page?
Message-ID: <CAFDcVCRfVN6KnMDdN1Je49nCTPV3+xZUaWCBKbFpJmXRzZ2Qvw@mail.gmail.com>

Hi,

is it possible to have non-Sweave vignettes(*) in inst/doc/ be listed
under 'Downloads' on CRAN package pages?  For instance, in my R.rsp
package I have a inst/doc/report.pdf (part of the source *.tar.gz)
that is not detected/listed.  The PDF is not based on a Sweave
vignette but an *.tex.rsp vignette that is dynamically created via
inst/doc/Makefile.  It is listed

(*) BTW, can the term "vignette" be used for any inst/doc/ document,
or should it be reserved for Sweave+LaTeX-based documents?

Thanks

Henrik


From xie at yihui.name  Mon Nov  7 02:14:38 2011
From: xie at yihui.name (Yihui Xie)
Date: Sun, 6 Nov 2011 19:14:38 -0600
Subject: [Rd] CRAN: How to list a non-Sweave doc under "Vignettes:" on
 package page?
In-Reply-To: <CAFDcVCRfVN6KnMDdN1Je49nCTPV3+xZUaWCBKbFpJmXRzZ2Qvw@mail.gmail.com>
References: <CAFDcVCRfVN6KnMDdN1Je49nCTPV3+xZUaWCBKbFpJmXRzZ2Qvw@mail.gmail.com>
Message-ID: <CANROs4dEo_AHYtC68ruwSvzoskqwCy+KZVJH92R0Qe4fSafcqA@mail.gmail.com>

I have the same question. I wish vignettes which are shown in CRAN and
the package documentation are not restricted to Sweave (or I missed
something in the R-exts manual?). What I did in the past was to cheat
Sweave by putting an Rnw document which is essentially a tex document
(I used my own functions to compile Rnw to tex).

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 515-294-2465 Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA



On Sun, Nov 6, 2011 at 6:41 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> Hi,
>
> is it possible to have non-Sweave vignettes(*) in inst/doc/ be listed
> under 'Downloads' on CRAN package pages? ?For instance, in my R.rsp
> package I have a inst/doc/report.pdf (part of the source *.tar.gz)
> that is not detected/listed. ?The PDF is not based on a Sweave
> vignette but an *.tex.rsp vignette that is dynamically created via
> inst/doc/Makefile. ?It is listed
>
> (*) BTW, can the term "vignette" be used for any inst/doc/ document,
> or should it be reserved for Sweave+LaTeX-based documents?
>
> Thanks
>
> Henrik
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From hb at biostat.ucsf.edu  Mon Nov  7 02:51:23 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sun, 6 Nov 2011 17:51:23 -0800
Subject: [Rd] CRAN: How to list a non-Sweave doc under "Vignettes:" on
 package page?
In-Reply-To: <CANROs4dEo_AHYtC68ruwSvzoskqwCy+KZVJH92R0Qe4fSafcqA@mail.gmail.com>
References: <CAFDcVCRfVN6KnMDdN1Je49nCTPV3+xZUaWCBKbFpJmXRzZ2Qvw@mail.gmail.com>
	<CANROs4dEo_AHYtC68ruwSvzoskqwCy+KZVJH92R0Qe4fSafcqA@mail.gmail.com>
Message-ID: <CAFDcVCSLe0vGfeQht_dt61RrhM-k2_MOHvL47aQfnhBbAkDXsg@mail.gmail.com>

Hi.

On Sun, Nov 6, 2011 at 5:14 PM, Yihui Xie <xie at yihui.name> wrote:
> I have the same question. I wish vignettes which are shown in CRAN and
> the package documentation are not restricted to Sweave (or I missed
> something in the R-exts manual?). What I did in the past was to cheat
> Sweave by putting an Rnw document which is essentially a tex document
> (I used my own functions to compile Rnw to tex).

How CRAN behaves and how the help package system behaves may be two
different problems.  My question is specifically on how CRAN works.

To have inst/doc/ documents to be listed on the package's help page,
you can add an inst/doc/index.html file, cf. Section 'Writing package
vignettes' in 'Writing R Extensions'. You can use the following
index.html file as a template:

help.start();
url <- sprintf("http://127.0.0.1:%s/library/utils/doc/index.html",
tools:::httpdPort);
download.file(url, basename(url));
browseURL(url);

/Henrik

>
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Phone: 515-294-2465 Web: http://yihui.name
> Department of Statistics, Iowa State University
> 2215 Snedecor Hall, Ames, IA
>
>
>
> On Sun, Nov 6, 2011 at 6:41 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>> Hi,
>>
>> is it possible to have non-Sweave vignettes(*) in inst/doc/ be listed
>> under 'Downloads' on CRAN package pages? ?For instance, in my R.rsp
>> package I have a inst/doc/report.pdf (part of the source *.tar.gz)
>> that is not detected/listed. ?The PDF is not based on a Sweave
>> vignette but an *.tex.rsp vignette that is dynamically created via
>> inst/doc/Makefile. ?It is listed
>>
>> (*) BTW, can the term "vignette" be used for any inst/doc/ document,
>> or should it be reserved for Sweave+LaTeX-based documents?
>>
>> Thanks
>>
>> Henrik
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From xie at yihui.name  Mon Nov  7 03:09:09 2011
From: xie at yihui.name (Yihui Xie)
Date: Sun, 6 Nov 2011 20:09:09 -0600
Subject: [Rd] CRAN: How to list a non-Sweave doc under "Vignettes:" on
 package page?
In-Reply-To: <CAFDcVCSLe0vGfeQht_dt61RrhM-k2_MOHvL47aQfnhBbAkDXsg@mail.gmail.com>
References: <CAFDcVCRfVN6KnMDdN1Je49nCTPV3+xZUaWCBKbFpJmXRzZ2Qvw@mail.gmail.com>
	<CANROs4dEo_AHYtC68ruwSvzoskqwCy+KZVJH92R0Qe4fSafcqA@mail.gmail.com>
	<CAFDcVCSLe0vGfeQht_dt61RrhM-k2_MOHvL47aQfnhBbAkDXsg@mail.gmail.com>
Message-ID: <CANROs4fLzw0hkfbUgtzbfzCodow3eeEDj5tDgpwuh9h68AVUMg@mail.gmail.com>

Thanks, and sorry for hijacking. I tried it once and gave up later
because I do not want hard-coded files (may be good or bad, though).
My point is that both CRAN and the package documentation are
restricted to Sweave for automatic generation of the vignette list. I
was hoping that vigettes could be like demos, which are listed in
demo/00Index by package authors and will show up in demo(package =
xxx). I apologize if this is irrelavent to your question.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 515-294-2465 Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA



On Sun, Nov 6, 2011 at 7:51 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> Hi.
>
> On Sun, Nov 6, 2011 at 5:14 PM, Yihui Xie <xie at yihui.name> wrote:
>> I have the same question. I wish vignettes which are shown in CRAN and
>> the package documentation are not restricted to Sweave (or I missed
>> something in the R-exts manual?). What I did in the past was to cheat
>> Sweave by putting an Rnw document which is essentially a tex document
>> (I used my own functions to compile Rnw to tex).
>
> How CRAN behaves and how the help package system behaves may be two
> different problems. ?My question is specifically on how CRAN works.
>
> To have inst/doc/ documents to be listed on the package's help page,
> you can add an inst/doc/index.html file, cf. Section 'Writing package
> vignettes' in 'Writing R Extensions'. You can use the following
> index.html file as a template:
>
> help.start();
> url <- sprintf("http://127.0.0.1:%s/library/utils/doc/index.html",
> tools:::httpdPort);
> download.file(url, basename(url));
> browseURL(url);
>
> /Henrik
>
>>
>> Regards,
>> Yihui
>> --
>> Yihui Xie <xieyihui at gmail.com>
>> Phone: 515-294-2465 Web: http://yihui.name
>> Department of Statistics, Iowa State University
>> 2215 Snedecor Hall, Ames, IA
>>
>>
>>
>> On Sun, Nov 6, 2011 at 6:41 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>>> Hi,
>>>
>>> is it possible to have non-Sweave vignettes(*) in inst/doc/ be listed
>>> under 'Downloads' on CRAN package pages? ?For instance, in my R.rsp
>>> package I have a inst/doc/report.pdf (part of the source *.tar.gz)
>>> that is not detected/listed. ?The PDF is not based on a Sweave
>>> vignette but an *.tex.rsp vignette that is dynamically created via
>>> inst/doc/Makefile. ?It is listed
>>>
>>> (*) BTW, can the term "vignette" be used for any inst/doc/ document,
>>> or should it be reserved for Sweave+LaTeX-based documents?
>>>
>>> Thanks
>>>
>>> Henrik
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From hb at biostat.ucsf.edu  Mon Nov  7 05:45:50 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sun, 6 Nov 2011 20:45:50 -0800
Subject: [Rd] CRAN: How to list a non-Sweave doc under "Vignettes:" on
 package page?
In-Reply-To: <CANROs4fLzw0hkfbUgtzbfzCodow3eeEDj5tDgpwuh9h68AVUMg@mail.gmail.com>
References: <CAFDcVCRfVN6KnMDdN1Je49nCTPV3+xZUaWCBKbFpJmXRzZ2Qvw@mail.gmail.com>
	<CANROs4dEo_AHYtC68ruwSvzoskqwCy+KZVJH92R0Qe4fSafcqA@mail.gmail.com>
	<CAFDcVCSLe0vGfeQht_dt61RrhM-k2_MOHvL47aQfnhBbAkDXsg@mail.gmail.com>
	<CANROs4fLzw0hkfbUgtzbfzCodow3eeEDj5tDgpwuh9h68AVUMg@mail.gmail.com>
Message-ID: <CAFDcVCTSr3pCY02sKAyh995BryUHykCuEaUWtqX0X58=v7CGDw@mail.gmail.com>

On Sun, Nov 6, 2011 at 6:09 PM, Yihui Xie <xie at yihui.name> wrote:
> Thanks, and sorry for hijacking. I tried it once and gave up later
> because I do not want hard-coded files (may be good or bad, though).
> My point is that both CRAN and the package documentation are
> restricted to Sweave for automatic generation of the vignette list. I
> was hoping that vigettes could be like demos, which are listed in
> demo/00Index by package authors and will show up in demo(package =
> xxx). I apologize if this is irrelavent to your question.

No worries - I just wanted to clarify.  I second your wishlist.

FYI, you can achieve some automation by using inst/doc/Makefile that
processes your own inst/doc/00Index.dcf file.  You'll still need some
kind of index.html template though.  (In the R.rsp package I'm using
an index.html.rsp template this way).

/H

>
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Phone: 515-294-2465 Web: http://yihui.name
> Department of Statistics, Iowa State University
> 2215 Snedecor Hall, Ames, IA
>
>
>
> On Sun, Nov 6, 2011 at 7:51 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>> Hi.
>>
>> On Sun, Nov 6, 2011 at 5:14 PM, Yihui Xie <xie at yihui.name> wrote:
>>> I have the same question. I wish vignettes which are shown in CRAN and
>>> the package documentation are not restricted to Sweave (or I missed
>>> something in the R-exts manual?). What I did in the past was to cheat
>>> Sweave by putting an Rnw document which is essentially a tex document
>>> (I used my own functions to compile Rnw to tex).
>>
>> How CRAN behaves and how the help package system behaves may be two
>> different problems. ?My question is specifically on how CRAN works.
>>
>> To have inst/doc/ documents to be listed on the package's help page,
>> you can add an inst/doc/index.html file, cf. Section 'Writing package
>> vignettes' in 'Writing R Extensions'. You can use the following
>> index.html file as a template:
>>
>> help.start();
>> url <- sprintf("http://127.0.0.1:%s/library/utils/doc/index.html",
>> tools:::httpdPort);
>> download.file(url, basename(url));
>> browseURL(url);
>>
>> /Henrik
>>
>>>
>>> Regards,
>>> Yihui
>>> --
>>> Yihui Xie <xieyihui at gmail.com>
>>> Phone: 515-294-2465 Web: http://yihui.name
>>> Department of Statistics, Iowa State University
>>> 2215 Snedecor Hall, Ames, IA
>>>
>>>
>>>
>>> On Sun, Nov 6, 2011 at 6:41 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>>>> Hi,
>>>>
>>>> is it possible to have non-Sweave vignettes(*) in inst/doc/ be listed
>>>> under 'Downloads' on CRAN package pages? ?For instance, in my R.rsp
>>>> package I have a inst/doc/report.pdf (part of the source *.tar.gz)
>>>> that is not detected/listed. ?The PDF is not based on a Sweave
>>>> vignette but an *.tex.rsp vignette that is dynamically created via
>>>> inst/doc/Makefile. ?It is listed
>>>>
>>>> (*) BTW, can the term "vignette" be used for any inst/doc/ document,
>>>> or should it be reserved for Sweave+LaTeX-based documents?
>>>>
>>>> Thanks
>>>>
>>>> Henrik
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From patrick.giraudoux at univ-fcomte.fr  Mon Nov  7 08:32:01 2011
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Mon, 07 Nov 2011 08:32:01 +0100
Subject: [Rd] Error in gzfile(file,
 mode) when checking a package with rcmd check
In-Reply-To: <CAFDcVCShAuEOX0WjWnzGDFBD6QVMDc7KPf_k0qdGc6dJ7G7RwQ@mail.gmail.com>
References: <4E9A8CDF.70801@univ-fcomte.fr> <4E9A9D8E.1090304@univ-fcomte.fr>
	<4E9AA386.7010008@univ-fcomte.fr>
	<CANz9Z_Le2kOxm6GkGmeMnWjtB0DexLq6jSvQOJdCvNwHsSkzZQ@mail.gmail.com>
	<4EB6C807.30601@univ-fcomte.fr>
	<4EB6CA72.4090609@statistik.tu-dortmund.de>
	<4EB6D271.1070300@univ-fcomte.fr> <1320605279.30493.8.camel@milan>
	<4EB6D8F5.5040200@univ-fcomte.fr> <4EB6DF87.8030505@gmail.com>
	<CAFDcVCShAuEOX0WjWnzGDFBD6QVMDc7KPf_k0qdGc6dJ7G7RwQ@mail.gmail.com>
Message-ID: <4EB78971.5020904@univ-fcomte.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111107/384f74f5/attachment.pl>

From rkjandra at gmail.com  Mon Nov  7 11:24:23 2011
From: rkjandra at gmail.com (Rob Anderson)
Date: Mon, 7 Nov 2011 05:24:23 -0500
Subject: [Rd] Accessing ENVSXP and CLOSXP while processing parsed R code
Message-ID: <CAApt6DK3YD9sf8+Vzx2hoYTMpMzyrttiHxVem3tDR0oF6Tms_A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111107/72d084e9/attachment.pl>

From murdoch.duncan at gmail.com  Mon Nov  7 12:49:05 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 07 Nov 2011 06:49:05 -0500
Subject: [Rd] Accessing ENVSXP and CLOSXP while processing parsed R code
In-Reply-To: <CAApt6DK3YD9sf8+Vzx2hoYTMpMzyrttiHxVem3tDR0oF6Tms_A@mail.gmail.com>
References: <CAApt6DK3YD9sf8+Vzx2hoYTMpMzyrttiHxVem3tDR0oF6Tms_A@mail.gmail.com>
Message-ID: <4EB7C5B1.5020705@gmail.com>

On 11-11-07 5:24 AM, Rob Anderson wrote:
> Hello Guys,
>
> Following up my earlier mail where I am trying to write an alternative
> front-end for R,  I had a question about accessing the closures and
> environments in R code.
>
> Here's the function taken  and modified a little from "*Lexical Scope and
> Statistical Computing*"
>
> =====================================================================
> f<-function(){
>    Rmlfun<-function(x){
>      sumx<-  sum(x)
>      n<-  length(x)
>      function(mu)
>        n*log(mu)-mu*sumx
>    }
>    efun<-Rmlfun(1:10)
>    y1<-  efun(3)
>    print(y1)
>    efun2<-  Rmlfun(20:30)
>    y2<-  efun2(3)
>    print(y2)
> }
> =====================================================================
>
> Now assignment efun<-Rmlfun(1:10) creates a closure where
> *function(mu) n*log(mu)-mu*sumx *is returned and *sumx* and *n *are added
> to the existing environment.

That's not correct.  When you call Rmlfun, an evaluation frame 
(environment) is created.  It contains the argument x.  Then sumx and n 
are added to it.  Then the anonymous closure is created, with body 
n*log(mu)-mu*sumx, and the closure's environment is the evaluation frame 
from the call to Rmlfun.


>
> I can parse the code using *PROTECT(e =
> R_ParseVector(tmp,1,&status,R_NilValue));* where tmp is the buffer
> containing the same source. I can walk the resultant parser output and
> build and alternative Abstract syntax tree(AST).
>
> I would like to include the information about closure/environments in my
> AST so that I can possibly do some optimizations.

It's not there, except potentially.  When you call the function 
"function" to create the closure, that's when the closure is created. 
That doesn't happen at parse time.  Rmlfun is created when you evaluate 
f() and then the anonymous function is created when you call Rmlfun() 
within it.

>
> My question is, how can I get hold of this information?
>
> One thing I noticed while 'walking' through the parser output, I never
> encounter a CLOSXP (which I check using TYPEOF()) , even though in the
> above code, closure is created. Is it the case that this information is
> meant just for the internal "eval*" function and not exposed application
> writers?

No, there's nothing hidden, it just didn't exist at the time you were 
looking for it.

Duncan Murdoch


From mdowle at mdowle.plus.com  Mon Nov  7 18:48:29 2011
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Mon, 7 Nov 2011 17:48:29 +0000
Subject: [Rd] Efficiency of factor objects
References: <CACLVabW52=nin_7_FDnAPQK=WWGhShnuz-SSdsqKi-0iMMom4A@mail.gmail.com>
Message-ID: <loom.20111107T175928-544@post.gmane.org>

Stavros Macrakis <macrakis <at> alum.mit.edu> writes:
> 
> data.table certainly has some useful mechanisms, and I've been
> experimenting with it as an implementation mechanism, though it's not a
> drop-in substitute for factors.  Also, though it is efficient for set
> operations between small sets and large sets, it is not very efficient for
> operations between two large sets

As a general statement that could do with some clarification ;) data.table 
likes keys consisting of multiple ordered columns, e.g. (id,date). It is (I 
believe) efficient for joining two large 2+ column keyed data sets because the 
upper bound of each row's one-sided binary search is localised in that case (by 
group of the previous key column).

As I understand it, Stavros has a different type of 'two large datasets' : 
English language website data. Each set is one large vector of uniformly 
distributed unique strings. That appears to be quite a different problem to 
multiple columns of many times duplicated data.

Matthew

> Thanks everyone, and if you do come across a relevant CRAN package, I'd be
> very interested in hearing about it.
> 
>           -s
>


From nalimilan at club.fr  Mon Nov  7 19:03:38 2011
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Mon, 07 Nov 2011 19:03:38 +0100
Subject: [Rd] Efficiency of factor objects
In-Reply-To: <CACLVabW52=nin_7_FDnAPQK=WWGhShnuz-SSdsqKi-0iMMom4A@mail.gmail.com>
References: <CACLVabW52=nin_7_FDnAPQK=WWGhShnuz-SSdsqKi-0iMMom4A@mail.gmail.com>
Message-ID: <1320689019.1816.10.camel@milan>

Le dimanche 06 novembre 2011 ? 19:00 -0500, Stavros Macrakis a ?crit :
> Milan, Jeff, Patrick,
> 
> 
> Thank you for your comments and suggestions.
> 
> 
> Milan,
> 
> 
> This is far from a "completely theoretical problem".  I am performing
> text analytics on a corpus of about 2m documents.  There are tens of
> thousands of distinct words (lemmata).  It seems to me that the
> natural representation of words is as an "enumeration type" -- in R
> terms, a "factor".
Interesting. What does your data look like? I've used the tm package,
and for me there are only two representations of text corpora: a list of
texts, which are basically a character string with attributes; a
document-term matrix, with documents as rows, terms as columns, and
counts at their intersection.


So I wonder how you're using factors. Do you have a factor containing
words for each text?

> Why do I think factors are the "natural way" of representing such
> things?  Because for most kinds of analysis, only their identity
> matters (not their spelling as words), but the human user would like
> to see names, not numbers. That is pretty much the definition of an
> enumeration type. In terms of R implementation, R is very efficient in
> dealing with integer identities and indexing (e.g. tabulate) and not
> very efficient in dealing with character identities -- indeed, 'table'
> first converts strings into factors.  Of course I could represent the
> lemmata as integers, and perform the translation between integers and
> strings myself, but that would just be duplicating the function of an
> enumeration type.
My point was that the efficiency of factors is due to the redundancy of
their levels. You usually have very few levels, and many observations
(in my work, often 10 levels and 100,000s of observations). If each
level only appears a few times on average, you don't save that much
memory by using a factor.

Since you have a real use case for that, I withdraw my criticism of your
suggestion being useless. ;-) But I'm still not sure R core devs would
like to follow it, since your application can be considered
non-standard, and worth a specialized class.


Cheers


From friendly at yorku.ca  Mon Nov  7 23:22:27 2011
From: friendly at yorku.ca (Michael Friendly)
Date: Mon, 07 Nov 2011 17:22:27 -0500
Subject: [Rd] CRAN: How to list a non-Sweave doc under "Vignettes:" on
 package page?
In-Reply-To: <CAFDcVCRfVN6KnMDdN1Je49nCTPV3+xZUaWCBKbFpJmXRzZ2Qvw@mail.gmail.com>
References: <CAFDcVCRfVN6KnMDdN1Je49nCTPV3+xZUaWCBKbFpJmXRzZ2Qvw@mail.gmail.com>
Message-ID: <4EB85A23.9050209@yorku.ca>

On 11/6/2011 7:41 PM, Henrik Bengtsson wrote:
> Hi,
>
> is it possible to have non-Sweave vignettes(*) in inst/doc/ be listed
> under 'Downloads' on CRAN package pages?  For instance, in my R.rsp
> package I have a inst/doc/report.pdf (part of the source *.tar.gz)
> that is not detected/listed.  The PDF is not based on a Sweave
> vignette but an *.tex.rsp vignette that is dynamically created via
> inst/doc/Makefile.  It is listed
>
> (*) BTW, can the term "vignette" be used for any inst/doc/ document,
> or should it be reserved for Sweave+LaTeX-based documents?
>

I have a related problem/question and a request to R-Core to consider 
relaxing the requirements for vignettes when, for one reason or another,
they cannot be built entirely via Sweave.  In such cases, perhaps 
package authors can provide alternative metadata in the form of an
00index.html or something similar to allow such vignettes to be
more visible.

Those who face this problem would then be able to figure out a
Makefile or manual way to maintain the metadata file. What would be
required to implement this?

In my case, my Guerry package has a vignette, inst/doc/MultiSpat.pdf, 
originally built entirely with Sweave.  However, the vignette require()d 
a package only on R-Forge, which the author does not wish
to release to CRAN.  At some point, ~ R 2.10, this triggered a 
WARNING/ERROR from the CRAN check daemon, in spite of the fact that the
vignette .Rnw file contained the following hack designed to make sure 
that all necessary packages were available anywhere:

\subsection{Installation and loading of required packages}
Several packages must be installed to run the different analyses:
<<ni0, fig=F, eval=TRUE, echo=TRUE, debug=TRUE, results=hide, include 
=FALSE, width=7, height=7>>=
pkg <- c("maptools","spdep","ade4","Guerry","spacemakeR")
inst.pkg <- row.names(installed.packages())
pkg2inst <- pmatch(pkg,inst.pkg)
if(any(is.na(pkg2inst[1:4]))) 
install.packages(pkg[which(is.na(pkg2inst[1:4]))],repos="http://cran.at.r-project.org")
if(is.na(pkg2inst[5]))
   install.packages("spacemakeR", repos="http://R-Forge.R-project.org")

library(maptools)
library(ade4)
library(spdep)
library(spacemakeR)
library(Guerry)
@

However, this hack was deemed unacceptable for a CRAN package vignette.
In the end, the only solution that would satisfy the CRAN check daemon 
was to delete the source inst/doc/MultiSpat.Rnw file from the package.

Consequently, the .pdf vignette remains in the package, but it is not 
listed as a vignette on CRAN, nor found via vignette()

best,
-Michael


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From macrakis at alum.mit.edu  Tue Nov  8 00:14:48 2011
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Mon, 7 Nov 2011 18:14:48 -0500
Subject: [Rd] Efficiency of factor objects
In-Reply-To: <loom.20111107T175928-544@post.gmane.org>
References: <CACLVabW52=nin_7_FDnAPQK=WWGhShnuz-SSdsqKi-0iMMom4A@mail.gmail.com>
	<loom.20111107T175928-544@post.gmane.org>
Message-ID: <CACLVabUnsXLKnWNDMH2-VDvN+5rz_zHBp63TfLeDUovK-MFmdw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111107/a2ba800c/attachment.pl>

From Berwin.Turlach at gmail.com  Tue Nov  8 04:36:45 2011
From: Berwin.Turlach at gmail.com (Berwin A Turlach)
Date: Tue, 8 Nov 2011 11:36:45 +0800
Subject: [Rd] CRAN: How to list a non-Sweave doc under "Vignettes:" on
 package page?
In-Reply-To: <CAFDcVCRfVN6KnMDdN1Je49nCTPV3+xZUaWCBKbFpJmXRzZ2Qvw@mail.gmail.com>
References: <CAFDcVCRfVN6KnMDdN1Je49nCTPV3+xZUaWCBKbFpJmXRzZ2Qvw@mail.gmail.com>
Message-ID: <20111108113645.503308a2@bossiaea>

G'day Henrik,

On Sun, 6 Nov 2011 16:41:22 -0800
Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:

> is it possible to have non-Sweave vignettes(*) in inst/doc/ be listed
> under 'Downloads' on CRAN package pages?  

As far as I know, only by a little trick.  Create an Sweave based
vignette that uses the pdfpages package to include the .pdf file that
you want to have listed.  This dummy vignette should then be listed on
CRAN.

See the lasso2 package for an example.

The vignette in inst/doc/ in that package is actually a bit more
complicated than necessary.  As I think there is no point of having two
nearly identical copies of PDF files in a package, I use .buildignores
to have the original PDF file not included in the source package.  This
started to create a problem when R decided to rebuild vignettes during
the checking process and pdfpages decided to hang if the PDF file to be
included was missing.  

HTH.

Cheers,

	Berwin


From hadley at rice.edu  Tue Nov  8 05:23:51 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Mon, 7 Nov 2011 22:23:51 -0600
Subject: [Rd] CRAN: How to list a non-Sweave doc under "Vignettes:" on
 package page?
In-Reply-To: <CAFDcVCSLe0vGfeQht_dt61RrhM-k2_MOHvL47aQfnhBbAkDXsg@mail.gmail.com>
References: <CAFDcVCRfVN6KnMDdN1Je49nCTPV3+xZUaWCBKbFpJmXRzZ2Qvw@mail.gmail.com>
	<CANROs4dEo_AHYtC68ruwSvzoskqwCy+KZVJH92R0Qe4fSafcqA@mail.gmail.com>
	<CAFDcVCSLe0vGfeQht_dt61RrhM-k2_MOHvL47aQfnhBbAkDXsg@mail.gmail.com>
Message-ID: <CABdHhvFwtw+kwDe32FKi+sN8bCjP+uT-zVJtREEnw45mPNzAEg@mail.gmail.com>

> How CRAN behaves and how the help package system behaves may be two
> different problems. ?My question is specifically on how CRAN works.
>
> To have inst/doc/ documents to be listed on the package's help page,
> you can add an inst/doc/index.html file, cf. Section 'Writing package
> vignettes' in 'Writing R Extensions'. You can use the following
> index.html file as a template:

But they still won't be listed under vignette() - I see this solution
as a temporary hack until non-Sweave vignettes become first class
citizens.

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From eschen at alumni.princeton.edu  Tue Nov  8 10:49:21 2011
From: eschen at alumni.princeton.edu (Art Eschenlauer)
Date: Tue, 8 Nov 2011 03:49:21 -0600
Subject: [Rd] NAMESPACE file generation issue R 2.14.0 on Debian Squeeze
Message-ID: <CACb17F4vRs0_VtHG+NvPkhu6ho6T3Qh9qgpLu8vN+Dy2N4Ti+w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111108/e411560b/attachment.pl>

From ligges at statistik.tu-dortmund.de  Tue Nov  8 16:25:11 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 08 Nov 2011 16:25:11 +0100
Subject: [Rd] NAMESPACE file generation issue R 2.14.0 on Debian Squeeze
In-Reply-To: <CACb17F4vRs0_VtHG+NvPkhu6ho6T3Qh9qgpLu8vN+Dy2N4Ti+w@mail.gmail.com>
References: <CACb17F4vRs0_VtHG+NvPkhu6ho6T3Qh9qgpLu8vN+Dy2N4Ti+w@mail.gmail.com>
Message-ID: <4EB949D7.80507@statistik.tu-dortmund.de>

I think many people like to help, but we cannot:

You say you are under R-2.14.0 and whn you R CMD INSTALL a package with 
that version of R, it does not have a NAMESPACE in the end?
Then

  - your R installation is broken or
  - you are looking into a library where you have old versios of the 
packages or
  - you belive you are using R-2.14.0 but you are actually using an 
older version.

Uwe ligges


On 08.11.2011 10:49, Art Eschenlauer wrote:
> When I did install.packages("sqldf") on Windows and Mac OSX, it installed
> fine.
> However, when I did it on my Debian Squeeze box under R 2.14.0, it failed.
> I discovered that three of the dependent packages, chron, proto, and
> gsubfn, do not include a NAMESPACE file in their distribution tar.gz files.
> I contacted the developer, who told me that, for packages without a
> NAMESPACE file, R 2.14 (but not early versions of R) generates a NAMESPACE
> file.
>
> My workaround to get sqldf installed was to copy the generated NAMESPACE
> files from my Mac to my Debian squeeze box and use R CMD INSTALL to install
> the packages.
>
> Although I read
>     "As from R 2.14.0 all packages will be installed with a namespace:
>     rather than relying on this mechanism authors are strongly
>     encouraged to add a namespace for themselves."
> on
>     http://cran.r-project.org/doc/manuals/R-exts.html#Package-namespaces
> it nevertheless appears to me that this behavior (not generating NAMESPACE
> files) is peculiar to my Debian installation (since it worked on the
> Windows and Mac machines).
>
> Please let me know if you need more details or further research.
>
> R totally ROCKS!
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ggrothendieck at gmail.com  Tue Nov  8 16:31:52 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 8 Nov 2011 10:31:52 -0500
Subject: [Rd] NAMESPACE file generation issue R 2.14.0 on Debian Squeeze
In-Reply-To: <4EB949D7.80507@statistik.tu-dortmund.de>
References: <CACb17F4vRs0_VtHG+NvPkhu6ho6T3Qh9qgpLu8vN+Dy2N4Ti+w@mail.gmail.com>
	<4EB949D7.80507@statistik.tu-dortmund.de>
Message-ID: <CAP01uRnQVcOK4uv61Y2p1Yz4wcF0Og-X_1oN6bLdNBDhP54pvA@mail.gmail.com>

2011/11/8 Uwe Ligges <ligges at statistik.tu-dortmund.de>:
> I think many people like to help, but we cannot:
>
> You say you are under R-2.14.0 and whn you R CMD INSTALL a package with that
> version of R, it does not have a NAMESPACE in the end?
> Then
>
> ?- your R installation is broken or
> ?- you are looking into a library where you have old versios of the packages
> or
> ?- you belive you are using R-2.14.0 but you are actually using an older
> version.
>

This is even reproduced on CRAN.  All platforms work except one:

http://cran.r-project.org/web/checks/check_results_sqldf.html


-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From ggrothendieck at gmail.com  Tue Nov  8 16:34:39 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 8 Nov 2011 10:34:39 -0500
Subject: [Rd] NAMESPACE file generation issue R 2.14.0 on Debian Squeeze
In-Reply-To: <CAP01uRnQVcOK4uv61Y2p1Yz4wcF0Og-X_1oN6bLdNBDhP54pvA@mail.gmail.com>
References: <CACb17F4vRs0_VtHG+NvPkhu6ho6T3Qh9qgpLu8vN+Dy2N4Ti+w@mail.gmail.com>
	<4EB949D7.80507@statistik.tu-dortmund.de>
	<CAP01uRnQVcOK4uv61Y2p1Yz4wcF0Og-X_1oN6bLdNBDhP54pvA@mail.gmail.com>
Message-ID: <CAP01uRm_ZPte5DHX1Q11Dxg1gqJPNzYbrPvOJ2pCCJsc_Oy8gQ@mail.gmail.com>

On Tue, Nov 8, 2011 at 10:31 AM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> 2011/11/8 Uwe Ligges <ligges at statistik.tu-dortmund.de>:
>> I think many people like to help, but we cannot:
>>
>> You say you are under R-2.14.0 and whn you R CMD INSTALL a package with that
>> version of R, it does not have a NAMESPACE in the end?
>> Then
>>
>> ?- your R installation is broken or
>> ?- you are looking into a library where you have old versios of the packages
>> or
>> ?- you belive you are using R-2.14.0 but you are actually using an older
>> version.
>>
>
> This is even reproduced on CRAN. ?All platforms work except one:
>
> http://cran.r-project.org/web/checks/check_results_sqldf.html
>

HIt send by mistake.

I understand that its being fixed already on CRAN for that platform.


-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From ligges at statistik.tu-dortmund.de  Tue Nov  8 16:36:26 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 08 Nov 2011 16:36:26 +0100
Subject: [Rd] NAMESPACE file generation issue R 2.14.0 on Debian Squeeze
In-Reply-To: <CAP01uRnQVcOK4uv61Y2p1Yz4wcF0Og-X_1oN6bLdNBDhP54pvA@mail.gmail.com>
References: <CACb17F4vRs0_VtHG+NvPkhu6ho6T3Qh9qgpLu8vN+Dy2N4Ti+w@mail.gmail.com>
	<4EB949D7.80507@statistik.tu-dortmund.de>
	<CAP01uRnQVcOK4uv61Y2p1Yz4wcF0Og-X_1oN6bLdNBDhP54pvA@mail.gmail.com>
Message-ID: <4EB94C7A.5070207@statistik.tu-dortmund.de>



On 08.11.2011 16:31, Gabor Grothendieck wrote:
> 2011/11/8 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>> I think many people like to help, but we cannot:
>>
>> You say you are under R-2.14.0 and whn you R CMD INSTALL a package with that
>> version of R, it does not have a NAMESPACE in the end?
>> Then
>>
>>   - your R installation is broken or
>>   - you are looking into a library where you have old versios of the packages
>> or
>>   - you belive you are using R-2.14.0 but you are actually using an older
>> version.
>>
>
> This is even reproduced on CRAN.  All platforms work except one:
>
> http://cran.r-project.org/web/checks/check_results_sqldf.html

No, that one is completely unrelated (and already solved, but not yet 
synced to CRAN master) to the original question you have removed in your 
reply.

The essential part of the question was: "However, when I did it on my 
Debian Squeeze box under R 2.14.0, it failed." and it does not fail 
under any R-2.14.0 if you look at the page you cited above.

Best,
Uwe Ligges


From ggrothendieck at gmail.com  Tue Nov  8 17:04:52 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 8 Nov 2011 11:04:52 -0500
Subject: [Rd] NAMESPACE file generation issue R 2.14.0 on Debian Squeeze
In-Reply-To: <4EB94C7A.5070207@statistik.tu-dortmund.de>
References: <CACb17F4vRs0_VtHG+NvPkhu6ho6T3Qh9qgpLu8vN+Dy2N4Ti+w@mail.gmail.com>
	<4EB949D7.80507@statistik.tu-dortmund.de>
	<CAP01uRnQVcOK4uv61Y2p1Yz4wcF0Og-X_1oN6bLdNBDhP54pvA@mail.gmail.com>
	<4EB94C7A.5070207@statistik.tu-dortmund.de>
Message-ID: <CAP01uR=mrt-Avnbv+UZ9_CKwj4cLcnGuyF-J4KLxt=nwvU2TdQ@mail.gmail.com>

2011/11/8 Uwe Ligges <ligges at statistik.tu-dortmund.de>:
>
>
> On 08.11.2011 16:31, Gabor Grothendieck wrote:
>>
>> 2011/11/8 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>>
>>> I think many people like to help, but we cannot:
>>>
>>> You say you are under R-2.14.0 and whn you R CMD INSTALL a package with
>>> that
>>> version of R, it does not have a NAMESPACE in the end?
>>> Then
>>>
>>> ?- your R installation is broken or
>>> ?- you are looking into a library where you have old versios of the
>>> packages
>>> or
>>> ?- you belive you are using R-2.14.0 but you are actually using an older
>>> version.
>>>
>>
>> This is even reproduced on CRAN. ?All platforms work except one:
>>
>> http://cran.r-project.org/web/checks/check_results_sqldf.html
>
> No, that one is completely unrelated (and already solved, but not yet synced
> to CRAN master) to the original question you have removed in your reply.
>

OK.  One would have thought that the checks on CRAN would be
consistent with the package pages which link to them.  The summary
table at check_results_sqldf.html does not actually give the version
that is being tested so its only by clicking each of the links on the
summary table that one would uncover this inconsistency.

Regarding quoting, the mail server seems to reject posts from gmail
for all sorts of unknown reasons and quoting large posts very well
might be one of them so one has to be extremely careful.  For a while
(this is some time ago) I was unable to post at all but over time
learned that if I was sure to bottom rather than top post and not
quote too much then it would get through.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From claudia.beleites at ipht-jena.de  Tue Nov  8 17:09:23 2011
From: claudia.beleites at ipht-jena.de (Claudia Beleites)
Date: Tue, 8 Nov 2011 17:09:23 +0100
Subject: [Rd] CRAN: How to list a non-Sweave doc under "Vignettes:" on
 package page?
In-Reply-To: <CABdHhvFwtw+kwDe32FKi+sN8bCjP+uT-zVJtREEnw45mPNzAEg@mail.gmail.com>
References: <CAFDcVCRfVN6KnMDdN1Je49nCTPV3+xZUaWCBKbFpJmXRzZ2Qvw@mail.gmail.com>
	<CANROs4dEo_AHYtC68ruwSvzoskqwCy+KZVJH92R0Qe4fSafcqA@mail.gmail.com>
	<CAFDcVCSLe0vGfeQht_dt61RrhM-k2_MOHvL47aQfnhBbAkDXsg@mail.gmail.com>
	<CABdHhvFwtw+kwDe32FKi+sN8bCjP+uT-zVJtREEnw45mPNzAEg@mail.gmail.com>
Message-ID: <4EB95433.3090303@ipht-jena.de>

Hi,

here's what I do:

I have two vignettes that are actually proper .Rnw files but the size of 
the data used is not acceptable for CRAN nor polite to any unsuspecting 
user.

So
- (I provide the original .Rnw and the data for download at r-forge)
- produce a .pdf from there in a directory external to the package
- have a "fake" .Rnw in the vignettes directory (actually still 
inst/doc) that provides the keywords for the vignette listing:
--- beginning of chondro.Rnw ---
% for the real source, see http://hyperspec.r-forge.r-project.org/


% \VignetteIndexEntry{Vignette on the chondro data set. Shows common 
Preprocessing tasks for Raman spectra, principal component analysis 
(PCA), and hierarchical cluster analysis.}
% \VignetteKeywords{chondro, hyperSpec, cluster analysis, preprocessing, 
Raman, principal component analysis, PCA}
% \VignettePackage{hyperSpec}

--- end of chondro.Rnw ---

- and have a Makefile in the directory with the relevant parts:

chondro.pdf:
	rm -f chondro.tex

%.pdf: %.Rnw
	$(R_HOME)/bin/Rscript -e "library (tools); Sweave(\"$(<F)\"); 
texi2dvi(\"$(basename $(<F)).tex\", pdf = TRUE, clean = TRUE);"
	gs -sDEVICE=pdfwrite -dCompatibilityLevel=1.4 -dPDFSETTINGS=/screen 
-dAutoRotatePages=/None \
	-dDownsampleColorImages=false -dNOPAUSE -dQUIET -dBATCH 
-dDownsampleColorImages=false \
	-sOutputFile=tmp.pdf $@ && qpdf tmp.pdf $@
	rm tmp.pdf
	rm -rf fig
	rm -f $(basename $(<F)).tex
	rm -f Rplots.pdf

It is important that the .Rnw actually works - the Makefile is used only 
_after_ Sweaving. But the makefile ensures that the .pdf of 
corresponding name is not destroyed during the attempt to build it from 
the .Rnw.

You can find the complete directory at:
https://r-forge.r-project.org/scm/viewvc.php/src/hyperSpec/inst/doc/?root=hyperspec

This way the vignette is listed correctly and I ship the .pdf only once. 
So in priciple, everything that is a pdf is not far from being first 
class citizen. The second class solution for non-pdf documents would be 
a pdf containing the link to the actual file.

I don't remember where I got the idea, but I think it was one of Dirk 
Eddelb?ttel's packages. So: thanks, Dirk!


Best,

Claudia


Am 08.11.2011 05:23, schrieb Hadley Wickham:
>> How CRAN behaves and how the help package system behaves may be two
>> different problems.  My question is specifically on how CRAN works.
>>
>> To have inst/doc/ documents to be listed on the package's help page,
>> you can add an inst/doc/index.html file, cf. Section 'Writing package
>> vignettes' in 'Writing R Extensions'. You can use the following
>> index.html file as a template:
>
> But they still won't be listed under vignette() - I see this solution
> as a temporary hack until non-Sweave vignettes become first class
> citizens.
>
> Hadley
>


-- 
Claudia Beleites
Spectroscopy/Imaging
Institute of Photonic Technology
Albert-Einstein-Str. 9
07745 Jena
Germany

email: claudia.beleites at ipht-jena.de
phone: +49 3641 206-133
fax:   +49 2641 206-399


From ligges at statistik.tu-dortmund.de  Tue Nov  8 17:30:24 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 08 Nov 2011 17:30:24 +0100
Subject: [Rd] NAMESPACE file generation issue R 2.14.0 on Debian Squeeze
In-Reply-To: <CAP01uR=mrt-Avnbv+UZ9_CKwj4cLcnGuyF-J4KLxt=nwvU2TdQ@mail.gmail.com>
References: <CACb17F4vRs0_VtHG+NvPkhu6ho6T3Qh9qgpLu8vN+Dy2N4Ti+w@mail.gmail.com>
	<4EB949D7.80507@statistik.tu-dortmund.de>
	<CAP01uRnQVcOK4uv61Y2p1Yz4wcF0Og-X_1oN6bLdNBDhP54pvA@mail.gmail.com>
	<4EB94C7A.5070207@statistik.tu-dortmund.de>
	<CAP01uR=mrt-Avnbv+UZ9_CKwj4cLcnGuyF-J4KLxt=nwvU2TdQ@mail.gmail.com>
Message-ID: <4EB95920.1090304@statistik.tu-dortmund.de>



On 08.11.2011 17:04, Gabor Grothendieck wrote:
> 2011/11/8 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>
>>
>> On 08.11.2011 16:31, Gabor Grothendieck wrote:
>>>
>>> 2011/11/8 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>>>
>>>> I think many people like to help, but we cannot:
>>>>
>>>> You say you are under R-2.14.0 and whn you R CMD INSTALL a package with
>>>> that
>>>> version of R, it does not have a NAMESPACE in the end?
>>>> Then
>>>>
>>>>   - your R installation is broken or
>>>>   - you are looking into a library where you have old versios of the
>>>> packages
>>>> or
>>>>   - you belive you are using R-2.14.0 but you are actually using an older
>>>> version.
>>>>
>>>
>>> This is even reproduced on CRAN.  All platforms work except one:
>>>
>>> http://cran.r-project.org/web/checks/check_results_sqldf.html
>>
>> No, that one is completely unrelated (and already solved, but not yet synced
>> to CRAN master) to the original question you have removed in your reply.
>>
>
> OK.  One would have thought that the checks on CRAN would be
> consistent with the package pages which link to them.

I only see consistent information on that page.

And it should be like that within few hours after a change. Syncing the 
logs from at least 4 different sources and regenerating the overview 
page has to happen sometime and you can always visit between two updates 
so you may have seen an inconsistency that is no longer there.



> The summary
> table at check_results_sqldf.html does not actually give the version
> that is being tested

It does, that's what the "Version" column contains. And the R version is 
also reported in the first column. You see check fro R-devel, R-release 
and R-oldrelease.

uwe



> so its only by clicking each of the links on the
> summary table that one would uncover this inconsistency.
 >
> Regarding quoting, the mail server seems to reject posts from gmail
> for all sorts of unknown reasons and quoting large posts very well
> might be one of them so one has to be extremely careful.  For a while
> (this is some time ago) I was unable to post at all but over time
> learned that if I was sure to bottom rather than top post and not
> quote too much then it would get through.
>


From ggrothendieck at gmail.com  Tue Nov  8 17:56:58 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 8 Nov 2011 11:56:58 -0500
Subject: [Rd] NAMESPACE file generation issue R 2.14.0 on Debian Squeeze
In-Reply-To: <4EB95920.1090304@statistik.tu-dortmund.de>
References: <CACb17F4vRs0_VtHG+NvPkhu6ho6T3Qh9qgpLu8vN+Dy2N4Ti+w@mail.gmail.com>
	<4EB949D7.80507@statistik.tu-dortmund.de>
	<CAP01uRnQVcOK4uv61Y2p1Yz4wcF0Og-X_1oN6bLdNBDhP54pvA@mail.gmail.com>
	<4EB94C7A.5070207@statistik.tu-dortmund.de>
	<CAP01uR=mrt-Avnbv+UZ9_CKwj4cLcnGuyF-J4KLxt=nwvU2TdQ@mail.gmail.com>
	<4EB95920.1090304@statistik.tu-dortmund.de>
Message-ID: <CAP01uRknbTxRg1+dL501c6GPp81jEKwGkGUxmre2ZX5ii22Jwg@mail.gmail.com>

2011/11/8 Uwe Ligges <ligges at statistik.tu-dortmund.de>:
>
>
> On 08.11.2011 17:04, Gabor Grothendieck wrote:
>>
>> 2011/11/8 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>>
>>>
>>> On 08.11.2011 16:31, Gabor Grothendieck wrote:
>>>>
>>>> 2011/11/8 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>>>>
>>>>> I think many people like to help, but we cannot:
>>>>>
>>>>> You say you are under R-2.14.0 and whn you R CMD INSTALL a package with
>>>>> that
>>>>> version of R, it does not have a NAMESPACE in the end?
>>>>> Then
>>>>>
>>>>> ?- your R installation is broken or
>>>>> ?- you are looking into a library where you have old versios of the
>>>>> packages
>>>>> or
>>>>> ?- you belive you are using R-2.14.0 but you are actually using an
>>>>> older
>>>>> version.
>>>>>
>>>>
>>>> This is even reproduced on CRAN. ?All platforms work except one:
>>>>
>>>> http://cran.r-project.org/web/checks/check_results_sqldf.html
>>>
>>> No, that one is completely unrelated (and already solved, but not yet
>>> synced
>>> to CRAN master) to the original question you have removed in your reply.
>>>
>>
>> OK. ?One would have thought that the checks on CRAN would be
>> consistent with the package pages which link to them.
>
> I only see consistent information on that page.

If you go to:

http://cran.r-project.org/web/packages/sqldf/index.html

then the tar.gz file was created using R-2.14.0 but if you then click
on the  check results  link on the same page it takes you to this:

http://cran.r-project.org/web/checks/check_results_sqldf.html

On the last link on that page it says ERROR and if click on that it
takes you to the output of the check which reveals that it was run
with R 2.13.2.

The Version column on check_results_sqldf.html page refers to the
package's version, not the R version.  To get the R version you must
know to click on each link.

If its feasible in terms of effort and run time to add the R version
used in a column on the check_results_sqldf.html page then that would
make the summary page more useful since it would be immediately
apparent not only what version of the package is being used but also
what version of R is being used in each case.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From friendly at yorku.ca  Tue Nov  8 18:11:42 2011
From: friendly at yorku.ca (Michael Friendly)
Date: Tue, 08 Nov 2011 12:11:42 -0500
Subject: [Rd] NAMESPACES for data only packages
Message-ID: <4EB962CE.6020707@yorku.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111108/16897e67/attachment.pl>

From ligges at statistik.tu-dortmund.de  Tue Nov  8 18:13:27 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 08 Nov 2011 18:13:27 +0100
Subject: [Rd] NAMESPACE file generation issue R 2.14.0 on Debian Squeeze
In-Reply-To: <CAP01uRknbTxRg1+dL501c6GPp81jEKwGkGUxmre2ZX5ii22Jwg@mail.gmail.com>
References: <CACb17F4vRs0_VtHG+NvPkhu6ho6T3Qh9qgpLu8vN+Dy2N4Ti+w@mail.gmail.com>
	<4EB949D7.80507@statistik.tu-dortmund.de>
	<CAP01uRnQVcOK4uv61Y2p1Yz4wcF0Og-X_1oN6bLdNBDhP54pvA@mail.gmail.com>
	<4EB94C7A.5070207@statistik.tu-dortmund.de>
	<CAP01uR=mrt-Avnbv+UZ9_CKwj4cLcnGuyF-J4KLxt=nwvU2TdQ@mail.gmail.com>
	<4EB95920.1090304@statistik.tu-dortmund.de>
	<CAP01uRknbTxRg1+dL501c6GPp81jEKwGkGUxmre2ZX5ii22Jwg@mail.gmail.com>
Message-ID: <4EB96337.2060005@statistik.tu-dortmund.de>



On 08.11.2011 17:56, Gabor Grothendieck wrote:
> 2011/11/8 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>
>>
>> On 08.11.2011 17:04, Gabor Grothendieck wrote:
>>>
>>> 2011/11/8 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>>>
>>>>
>>>> On 08.11.2011 16:31, Gabor Grothendieck wrote:
>>>>>
>>>>> 2011/11/8 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>>>>>
>>>>>> I think many people like to help, but we cannot:
>>>>>>
>>>>>> You say you are under R-2.14.0 and whn you R CMD INSTALL a package with
>>>>>> that
>>>>>> version of R, it does not have a NAMESPACE in the end?
>>>>>> Then
>>>>>>
>>>>>>   - your R installation is broken or
>>>>>>   - you are looking into a library where you have old versios of the
>>>>>> packages
>>>>>> or
>>>>>>   - you belive you are using R-2.14.0 but you are actually using an
>>>>>> older
>>>>>> version.
>>>>>>
>>>>>
>>>>> This is even reproduced on CRAN.  All platforms work except one:
>>>>>
>>>>> http://cran.r-project.org/web/checks/check_results_sqldf.html
>>>>
>>>> No, that one is completely unrelated (and already solved, but not yet
>>>> synced
>>>> to CRAN master) to the original question you have removed in your reply.
>>>>
>>>
>>> OK.  One would have thought that the checks on CRAN would be
>>> consistent with the package pages which link to them.
>>
>> I only see consistent information on that page.
>
> If you go to:
>
> http://cran.r-project.org/web/packages/sqldf/index.html
>
> then the tar.gz file was created using R-2.14.0 but if you then click
> on the  check results  link on the same page it takes you to this:


Yes. the tar.gz was created with R-2.14.0.


> http://cran.r-project.org/web/checks/check_results_sqldf.html
>
> On the last link on that page it says ERROR and if click on that it
> takes you to the output of the check which reveals that it was run
> with R 2.13.2.

Yes, ince it is checked with different flavors of R, R-oldrelease, 
R-release, R-devel. See the first column!

A source package can be created with an version of R and checked under 
another version. There is onlyone source package on CRAN, but - just as 
an exmaple - binaries for R-2.13.x and R-2.14.x. Of course, the checks 
are applied with the versions stated on the check page. I think you 
haven't got the whole point of checking with different versions of R.



> The Version column on check_results_sqldf.html page refers to the
> package's version, not the R version.  To get the R version you must
> know to click on each link.

No, no, no, no! See the first column!
It definitely states if R-olrelease, R-release, R-pacthed or R-devel is 
used!

Uwe



>
> If its feasible in terms of effort and run time to add the R version
> used in a column on the check_results_sqldf.html page then that would
> make the summary page more useful since it would be immediately
> apparent not only what version of the package is being used but also
> what version of R is being used in each case.
>


From jwiley.psych at gmail.com  Tue Nov  8 18:49:21 2011
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Tue, 8 Nov 2011 09:49:21 -0800
Subject: [Rd] NAMESPACES for data only packages
In-Reply-To: <4EB962CE.6020707@yorku.ca>
References: <4EB962CE.6020707@yorku.ca>
Message-ID: <CANz9Z_JH5ss-NvkfywHx1uiiE41YFXfxEEOKFfG27Uy3aamuzg@mail.gmail.com>

Hi Michael,

You are correct that data does not *have* to be exported.  For
example, here is the contents of NAMESPACE for the datasets package
from a recent devel version:

# This package exports nothing (it uses lazydata)
# exportPattern(".")

Cheers,

Josh

On Tue, Nov 8, 2011 at 9:11 AM, Michael Friendly <friendly at yorku.ca> wrote:
> the NEWS file for R-devel says
>
> ?*
>
> ? ?Even data-only packages without *R* code need a namespace and so may
> ? ?need to be installed under *R* 2.14.0 or later.
>
>
> but what should this contain? ?Can it simply be an empty NAMESPACE
> file? ?I assume that data does not have to
> be exported.
>
> -Michael
>
> --
> Michael Friendly ? ? Email: friendly AT yorku DOT ca
> Professor, Psychology Dept.
> York University ? ? ?Voice: 416 736-5115 x66249 Fax: 416 736-5814
> 4700 Keele Street ? ?Web: ? http://www.datavis.ca
> Toronto, ONT ?M3J 1P3 CANADA
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, ATS Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From ripley at stats.ox.ac.uk  Tue Nov  8 19:08:23 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 8 Nov 2011 18:08:23 +0000 (GMT)
Subject: [Rd] NAMESPACES for data only packages
In-Reply-To: <CANz9Z_JH5ss-NvkfywHx1uiiE41YFXfxEEOKFfG27Uy3aamuzg@mail.gmail.com>
References: <4EB962CE.6020707@yorku.ca>
	<CANz9Z_JH5ss-NvkfywHx1uiiE41YFXfxEEOKFfG27Uy3aamuzg@mail.gmail.com>
Message-ID: <alpine.LFD.2.02.1111081805240.17110@gannet.stats.ox.ac.uk>

Can we clarify:

As the NEWS says, to install a data-only package under 2.14.0 you need 
a namespace.  And if you do not give one installation will create one.

However, you can use an already-installed data-only package without a 
namespace under 2.14.x, but not under R-devel.  This is to allow a 
transition (e.g. many of the BioC 2.9 binary data-only packages did 
not have a namespace at the time).

On Tue, 8 Nov 2011, Joshua Wiley wrote:

> Hi Michael,
>
> You are correct that data does not *have* to be exported.  For
> example, here is the contents of NAMESPACE for the datasets package
> from a recent devel version:
>
> # This package exports nothing (it uses lazydata)
> # exportPattern(".")
>
> Cheers,
>
> Josh
>
> On Tue, Nov 8, 2011 at 9:11 AM, Michael Friendly <friendly at yorku.ca> wrote:
>> the NEWS file for R-devel says
>>
>> ?*
>>
>> ? ?Even data-only packages without *R* code need a namespace and so may
>> ? ?need to be installed under *R* 2.14.0 or later.
>>
>>
>> but what should this contain? ?Can it simply be an empty NAMESPACE
>> file? ?I assume that data does not have to
>> be exported.
>>
>> -Michael
>>
>> --
>> Michael Friendly ? ? Email: friendly AT yorku DOT ca
>> Professor, Psychology Dept.
>> York University ? ? ?Voice: 416 736-5115 x66249 Fax: 416 736-5814
>> 4700 Keele Street ? ?Web: ? http://www.datavis.ca
>> Toronto, ONT ?M3J 1P3 CANADA
>>
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>
> -- 
> Joshua Wiley
> Ph.D. Student, Health Psychology
> Programmer Analyst II, ATS Statistical Consulting Group
> University of California, Los Angeles
> https://joshuawiley.com/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ggrothendieck at gmail.com  Tue Nov  8 19:08:50 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 8 Nov 2011 13:08:50 -0500
Subject: [Rd] NAMESPACE file generation issue R 2.14.0 on Debian Squeeze
In-Reply-To: <4EB96337.2060005@statistik.tu-dortmund.de>
References: <CACb17F4vRs0_VtHG+NvPkhu6ho6T3Qh9qgpLu8vN+Dy2N4Ti+w@mail.gmail.com>
	<4EB949D7.80507@statistik.tu-dortmund.de>
	<CAP01uRnQVcOK4uv61Y2p1Yz4wcF0Og-X_1oN6bLdNBDhP54pvA@mail.gmail.com>
	<4EB94C7A.5070207@statistik.tu-dortmund.de>
	<CAP01uR=mrt-Avnbv+UZ9_CKwj4cLcnGuyF-J4KLxt=nwvU2TdQ@mail.gmail.com>
	<4EB95920.1090304@statistik.tu-dortmund.de>
	<CAP01uRknbTxRg1+dL501c6GPp81jEKwGkGUxmre2ZX5ii22Jwg@mail.gmail.com>
	<4EB96337.2060005@statistik.tu-dortmund.de>
Message-ID: <CAP01uRkHBRHW5FuqoQE60vEgyhSEvnKeE5SQ0Oux1CNr9_aOPA@mail.gmail.com>

2011/11/8 Uwe Ligges <ligges at statistik.tu-dortmund.de>:
>
>
> On 08.11.2011 17:56, Gabor Grothendieck wrote:
>>
>> 2011/11/8 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>>
>>>
>>> On 08.11.2011 17:04, Gabor Grothendieck wrote:
>>>>
>>>> 2011/11/8 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>>>>
>>>>>
>>>>> On 08.11.2011 16:31, Gabor Grothendieck wrote:
>>>>>>
>>>>>> 2011/11/8 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>>>>>>
>>>>>>> I think many people like to help, but we cannot:
>>>>>>>
>>>>>>> You say you are under R-2.14.0 and whn you R CMD INSTALL a package
>>>>>>> with
>>>>>>> that
>>>>>>> version of R, it does not have a NAMESPACE in the end?
>>>>>>> Then
>>>>>>>
>>>>>>> ?- your R installation is broken or
>>>>>>> ?- you are looking into a library where you have old versios of the
>>>>>>> packages
>>>>>>> or
>>>>>>> ?- you belive you are using R-2.14.0 but you are actually using an
>>>>>>> older
>>>>>>> version.
>>>>>>>
>>>>>>
>>>>>> This is even reproduced on CRAN. ?All platforms work except one:
>>>>>>
>>>>>> http://cran.r-project.org/web/checks/check_results_sqldf.html
>>>>>
>>>>> No, that one is completely unrelated (and already solved, but not yet
>>>>> synced
>>>>> to CRAN master) to the original question you have removed in your
>>>>> reply.
>>>>>
>>>>
>>>> OK. ?One would have thought that the checks on CRAN would be
>>>> consistent with the package pages which link to them.
>>>
>>> I only see consistent information on that page.
>>
>> If you go to:
>>
>> http://cran.r-project.org/web/packages/sqldf/index.html
>>
>> then the tar.gz file was created using R-2.14.0 but if you then click
>> on the ?check results ?link on the same page it takes you to this:
>
>
> Yes. the tar.gz was created with R-2.14.0.
>
>
>> http://cran.r-project.org/web/checks/check_results_sqldf.html
>>
>> On the last link on that page it says ERROR and if click on that it
>> takes you to the output of the check which reveals that it was run
>> with R 2.13.2.
>
> Yes, ince it is checked with different flavors of R, R-oldrelease,
> R-release, R-devel. See the first column!
>
> A source package can be created with an version of R and checked under
> another version. There is onlyone source package on CRAN, but - just as an
> exmaple - binaries for R-2.13.x and R-2.14.x. Of course, the checks are
> applied with the versions stated on the check page. I think you haven't got
> the whole point of checking with different versions of R.
>
>
>
>> The Version column on check_results_sqldf.html page refers to the
>> package's version, not the R version. ?To get the R version you must
>> know to click on each link.
>
> No, no, no, no! See the first column!
> It definitely states if R-olrelease, R-release, R-pacthed or R-devel is
> used!
>

OK. That wasn't clear. It would be better if it actually identified
the release as R 2.13.2, etc.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From ligges at statistik.tu-dortmund.de  Tue Nov  8 19:11:57 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 08 Nov 2011 19:11:57 +0100
Subject: [Rd] NAMESPACE file generation issue R 2.14.0 on Debian Squeeze
In-Reply-To: <CAP01uRkHBRHW5FuqoQE60vEgyhSEvnKeE5SQ0Oux1CNr9_aOPA@mail.gmail.com>
References: <CACb17F4vRs0_VtHG+NvPkhu6ho6T3Qh9qgpLu8vN+Dy2N4Ti+w@mail.gmail.com>
	<4EB949D7.80507@statistik.tu-dortmund.de>
	<CAP01uRnQVcOK4uv61Y2p1Yz4wcF0Og-X_1oN6bLdNBDhP54pvA@mail.gmail.com>
	<4EB94C7A.5070207@statistik.tu-dortmund.de>
	<CAP01uR=mrt-Avnbv+UZ9_CKwj4cLcnGuyF-J4KLxt=nwvU2TdQ@mail.gmail.com>
	<4EB95920.1090304@statistik.tu-dortmund.de>
	<CAP01uRknbTxRg1+dL501c6GPp81jEKwGkGUxmre2ZX5ii22Jwg@mail.gmail.com>
	<4EB96337.2060005@statistik.tu-dortmund.de>
	<CAP01uRkHBRHW5FuqoQE60vEgyhSEvnKeE5SQ0Oux1CNr9_aOPA@mail.gmail.com>
Message-ID: <4EB970ED.6080206@statistik.tu-dortmund.de>



On 08.11.2011 19:08, Gabor Grothendieck wrote:
> 2011/11/8 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>
>>
>> On 08.11.2011 17:56, Gabor Grothendieck wrote:
>>>
>>> 2011/11/8 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>>>
>>>>
>>>> On 08.11.2011 17:04, Gabor Grothendieck wrote:
>>>>>
>>>>> 2011/11/8 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>>>>>
>>>>>>
>>>>>> On 08.11.2011 16:31, Gabor Grothendieck wrote:
>>>>>>>
>>>>>>> 2011/11/8 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>>>>>>>
>>>>>>>> I think many people like to help, but we cannot:
>>>>>>>>
>>>>>>>> You say you are under R-2.14.0 and whn you R CMD INSTALL a package
>>>>>>>> with
>>>>>>>> that
>>>>>>>> version of R, it does not have a NAMESPACE in the end?
>>>>>>>> Then
>>>>>>>>
>>>>>>>>   - your R installation is broken or
>>>>>>>>   - you are looking into a library where you have old versios of the
>>>>>>>> packages
>>>>>>>> or
>>>>>>>>   - you belive you are using R-2.14.0 but you are actually using an
>>>>>>>> older
>>>>>>>> version.
>>>>>>>>
>>>>>>>
>>>>>>> This is even reproduced on CRAN.  All platforms work except one:
>>>>>>>
>>>>>>> http://cran.r-project.org/web/checks/check_results_sqldf.html
>>>>>>
>>>>>> No, that one is completely unrelated (and already solved, but not yet
>>>>>> synced
>>>>>> to CRAN master) to the original question you have removed in your
>>>>>> reply.
>>>>>>
>>>>>
>>>>> OK.  One would have thought that the checks on CRAN would be
>>>>> consistent with the package pages which link to them.
>>>>
>>>> I only see consistent information on that page.
>>>
>>> If you go to:
>>>
>>> http://cran.r-project.org/web/packages/sqldf/index.html
>>>
>>> then the tar.gz file was created using R-2.14.0 but if you then click
>>> on the  check results  link on the same page it takes you to this:
>>
>>
>> Yes. the tar.gz was created with R-2.14.0.
>>
>>
>>> http://cran.r-project.org/web/checks/check_results_sqldf.html
>>>
>>> On the last link on that page it says ERROR and if click on that it
>>> takes you to the output of the check which reveals that it was run
>>> with R 2.13.2.
>>
>> Yes, ince it is checked with different flavors of R, R-oldrelease,
>> R-release, R-devel. See the first column!
>>
>> A source package can be created with an version of R and checked under
>> another version. There is onlyone source package on CRAN, but - just as an
>> exmaple - binaries for R-2.13.x and R-2.14.x. Of course, the checks are
>> applied with the versions stated on the check page. I think you haven't got
>> the whole point of checking with different versions of R.
>>
>>
>>
>>> The Version column on check_results_sqldf.html page refers to the
>>> package's version, not the R version.  To get the R version you must
>>> know to click on each link.
>>
>> No, no, no, no! See the first column!
>> It definitely states if R-olrelease, R-release, R-pacthed or R-devel is
>> used!
>>
>
> OK. That wasn't clear. It would be better if it actually identified
> the release as R 2.13.2, etc.

We do not want to change those fields daily: R-devel and R-patched 
typically change from day to day - and then things will really become 
inconsistent in some place.

Uwe


From krunal.rao78 at gmail.com  Tue Nov  8 20:42:07 2011
From: krunal.rao78 at gmail.com (KR)
Date: Tue, 8 Nov 2011 19:42:07 +0000
Subject: [Rd] Question on parsing R code from C
Message-ID: <loom.20111108T203022-872@post.gmane.org>

Hi all,

I am facing the necessity to parse R code from C-side. As a first approximation 
the goal would be a re-implementation of the R shell (not Rgui).

I read the document at http://cran.r-project.org/doc/manuals/R-exts.html section 
5.12, and the related source code example. 

I have some questions:

1. I need to declare the types and function signatures that I am going to use 
for this task without having to actually include the R headers. Can I safely 
declare SEXP according to the following ?
typedef struct SEXP *unknwn_handle;
More in general, is there a reference document for the C API (listing function 
signatures, and type definitions) ?

2. If the parsed R code of the working implementation contain commands like 
plot(), will the opportune windows pop-up as if I were using the R shell (on 
both windows and unix systems) ?

3. What initialization do I need to perform to be in exactly the same starting 
state as if I had executed the R shell with the --vanilla option?


Any help or feedback is appreciated.

Thank you.

Kind regard


From simon.urbanek at r-project.org  Tue Nov  8 21:18:48 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 8 Nov 2011 15:18:48 -0500
Subject: [Rd] Question on parsing R code from C
In-Reply-To: <loom.20111108T203022-872@post.gmane.org>
References: <loom.20111108T203022-872@post.gmane.org>
Message-ID: <9465BE63-EA88-4BE2-8D1C-9E33BE8AA45D@r-project.org>


On Nov 8, 2011, at 2:42 PM, KR wrote:

> Hi all,
> 
> I am facing the necessity to parse R code from C-side. As a first approximation 
> the goal would be a re-implementation of the R shell (not Rgui).
> 
> I read the document at http://cran.r-project.org/doc/manuals/R-exts.html section 
> 5.12, and the related source code example. 
> 
> I have some questions:
> 
> 1. I need to declare the types and function signatures that I am going to use 
> for this task without having to actually include the R headers. Can I safely 
> declare SEXP according to the following ?
> typedef struct SEXP *unknwn_handle;

I'm not sure I understand this really - it doesn't define SEXP. I would expect something like

typedef void *SEXP;

Which may work for declarations. Note, however, that for the actual code you'll need to include the headers anyway.


> More in general, is there a reference document for the C API (listing function 
> signatures, and type definitions) ?
> 

http://r.research.att.com/man/R-exts.html is the documentation and the headers (Rinternals.h mainly) is the canonical reference.


> 2. If the parsed R code of the working implementation contain commands like 
> plot(), will the opportune windows pop-up as if I were using the R shell (on 
> both windows and unix systems) ?
> 

It depends on your settings - plot() uses whatever graphics device you tell it to use, so plot() doesn't decide about that. If you use the proper interactive graphics device *and* make sure you're serving the REPL then it may work. Beware of interactions with your other parts, though, since you are responsible for ensuring that it works. 


> 3. What initialization do I need to perform to be in exactly the same starting 
> state as if I had executed the R shell with the --vanilla option?
> 

It depends on the OS and the way you are initializing R. In the simple case pass the "--vanilla" as the argument when initializing R. Please read the section about embedding, it has examples. Also see the other R GUIs to understand the complexities involved.

BTW: you subject has absolutely nothing to do with your question - your'e asking about embedding R ;)

Cheers,
Simon



> 
> Any help or feedback is appreciated.
> 
> Thank you.
> 
> Kind regard
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From krunal.rao78 at gmail.com  Tue Nov  8 22:57:01 2011
From: krunal.rao78 at gmail.com (KR)
Date: Tue, 8 Nov 2011 21:57:01 +0000
Subject: [Rd] Question on parsing R code from C
References: <loom.20111108T203022-872@post.gmane.org>
	<9465BE63-EA88-4BE2-8D1C-9E33BE8AA45D@r-project.org>
Message-ID: <loom.20111108T224700-655@post.gmane.org>

Simon Urbanek <simon.urbanek <at> r-project.org> writes:
> I'm not sure I understand this really - it doesn't define SEXP. I would expect 
something like
> 
> typedef void *SEXP;
> 
> Which may work for declarations. Note, however, that for the actual code 
you'll need to include the headers anyway.

Thanks for the prompt reply!

It's my understanding that using opaque pointers to hide implementation is fine 
(as long as they are not de-referenced nor the size of the actual struct is 
needed). I actually come out with the tentative typedef by looking at the 
sources, but I got confused by some conditional pre-processor directives so I 
was searching for confirmation.

For the actual code I can just declare the types (even opaques depending on the 
use) and function signatures that I strictly need by hand as long as I am doing 
it correctly (after all that's what is inside the headers, among with the stuff 
I don't need).

> http://r.research.att.com/man/R-exts.html is the documentation and the headers 
(Rinternals.h
> mainly) is the canonical reference.

Understood, thanks.

> > 2. If the parsed R code of the working implementation contain commands like 
> > plot(), will the opportune windows pop-up as if I were using the R shell (on 
> > both windows and unix systems) ?
> > 
> 
> It depends on your settings - plot() uses whatever graphics device you tell it 
to use, so plot() doesn't
> decide about that. If you use the proper interactive graphics device *and* 
make sure you're serving the
> REPL then it may work. Beware of interactions with your other parts, though, 
since you are responsible for
> ensuring that it works. 

I admit I am quite lost here, is there any code I can look at for examples? :P

> BTW: you subject has absolutely nothing to do with your question - your'e 
asking about embedding R ;)

Hmmmm I may be excused because I copy and pasted the title of section 5.12 
(which seemed most relevant for what I wanted to achieve) :-)


Cheers


From simon.urbanek at r-project.org  Tue Nov  8 23:39:42 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 8 Nov 2011 17:39:42 -0500
Subject: [Rd] Question on parsing R code from C
In-Reply-To: <loom.20111108T224700-655@post.gmane.org>
References: <loom.20111108T203022-872@post.gmane.org>
	<9465BE63-EA88-4BE2-8D1C-9E33BE8AA45D@r-project.org>
	<loom.20111108T224700-655@post.gmane.org>
Message-ID: <3D4F776D-4D5D-4C39-90B3-12DF09C5C6BA@r-project.org>


On Nov 8, 2011, at 4:57 PM, KR wrote:

> Simon Urbanek <simon.urbanek <at> r-project.org> writes:
>> I'm not sure I understand this really - it doesn't define SEXP. I would expect 
> something like
>> 
>> typedef void *SEXP;
>> 
>> Which may work for declarations. Note, however, that for the actual code 
> you'll need to include the headers anyway.
> 
> Thanks for the prompt reply!
> 
> It's my understanding that using opaque pointers to hide implementation is fine 


Except that you don't know what are macros, inlined functions and actual functions. If you are careful you can possibly fall back to external functions but, obviously, your code will be less efficient. I would still prefer including Rinternals.h - you must have a *really* good reason to not do so ;).


> (as long as they are not de-referenced nor the size of the actual struct is 
> needed). I actually come out with the tentative typedef by looking at the 
> sources, but I got confused by some conditional pre-processor directives so I 
> was searching for confirmation.
> 
> For the actual code I can just declare the types (even opaques depending on the 
> use) and function signatures that I strictly need by hand as long as I am doing 
> it correctly (after all that's what is inside the headers, among with the stuff 
> I don't need).
> 
>> http://r.research.att.com/man/R-exts.html is the documentation and the headers 
> (Rinternals.h
>> mainly) is the canonical reference.
> 
> Understood, thanks.
> 
>>> 2. If the parsed R code of the working implementation contain commands like 
>>> plot(), will the opportune windows pop-up as if I were using the R shell (on 
>>> both windows and unix systems) ?
>>> 
>> 
>> It depends on your settings - plot() uses whatever graphics device you tell it 
> to use, so plot() doesn't
>> decide about that. If you use the proper interactive graphics device *and* 
> make sure you're serving the
>> REPL then it may work. Beware of interactions with your other parts, though, 
> since you are responsible for
>> ensuring that it works. 
> 
> I admit I am quite lost here, is there any code I can look at for examples? :P
> 

The embedding code examples and existing GUIs.

It's not a trivial topic and you should be really familiar with R in order to venture there. Embedding R to perform computations is reasonably easy, but the moment you want to run it interactively like console R, you have to implement a bunch of callbacks and run the even loop (REPL). It is more tricky than it sounds, because you need to synchronize your app with the event loop, make sure you process system events etc. (Simple command line R is not that hard - there are examples in the R sources with stub implementations of the callbacks, but the complexity increases considerably the moment you start using any UI features in your app)



>> BTW: you subject has absolutely nothing to do with your question - your'e 
> asking about embedding R ;)
> 
> Hmmmm I may be excused because I copy and pasted the title of section 5.12 
> (which seemed most relevant for what I wanted to achieve) :-)
> 

;)

Cheers,
Simon


From krunal.rao78 at gmail.com  Wed Nov  9 00:53:01 2011
From: krunal.rao78 at gmail.com (KR)
Date: Tue, 8 Nov 2011 23:53:01 +0000
Subject: [Rd] Question on parsing R code from C
References: <loom.20111108T203022-872@post.gmane.org>
	<9465BE63-EA88-4BE2-8D1C-9E33BE8AA45D@r-project.org>
	<loom.20111108T224700-655@post.gmane.org>
	<3D4F776D-4D5D-4C39-90B3-12DF09C5C6BA@r-project.org>
Message-ID: <loom.20111109T001139-68@post.gmane.org>

Simon Urbanek <simon.urbanek <at> r-project.org> writes:
> Except that you don't know what are macros, inlined functions and actual 
functions. If you are careful you
> can possibly fall back to external functions but, obviously, your code will be 
less efficient. I would
> still prefer including Rinternals.h - you must have a *really* good reason to 
not do so ;)

Hmmm yes there are good motives (I am not completely unreasonable, yet :P) but I 
could probably cope with it if there is no other way.

Regarding the rest of the e-mail, please let me be clearer on what my goal is. I 
would need a function to create and initialize an R state, a function to close 
the state, and a function (R_ParseVector?) that takes as input the R state and a 
string (containing R code), evaluates the code and return an "error code" 
(error, incomplete, done) plus (eventually) a string containing the output of 
the computation.

In my application I do not have any UI elements (it's console based), but I 
would like calls to plot in R (and other functions using the graphic device) to 
function as they would under R.exe (on windows), i.e. have persistent windows 
popped up which you can resize ecc ecc. I naively thought that these graphic 
capabilities came automatically with the R_ParseVector via some threading 
techniques.

Thanks for all your comments!


Cheers


From rkjandra at gmail.com  Wed Nov  9 02:02:31 2011
From: rkjandra at gmail.com (Rob Anderson)
Date: Tue, 8 Nov 2011 20:02:31 -0500
Subject: [Rd] Question on parsing R code from C
In-Reply-To: <loom.20111109T001139-68@post.gmane.org>
References: <loom.20111108T203022-872@post.gmane.org>
	<9465BE63-EA88-4BE2-8D1C-9E33BE8AA45D@r-project.org>
	<loom.20111108T224700-655@post.gmane.org>
	<3D4F776D-4D5D-4C39-90B3-12DF09C5C6BA@r-project.org>
	<loom.20111109T001139-68@post.gmane.org>
Message-ID: <CAApt6DK+NDmyb_QoVboV2n1aAEj7MfJMm5L9bt516Rjrr-F-KQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111108/6ae6fc26/attachment.pl>

From rkjandra at gmail.com  Wed Nov  9 02:03:08 2011
From: rkjandra at gmail.com (Rob Anderson)
Date: Tue, 8 Nov 2011 20:03:08 -0500
Subject: [Rd] Accessing ENVSXP and CLOSXP while processing parsed R code
In-Reply-To: <4EB7C5B1.5020705@gmail.com>
References: <CAApt6DK3YD9sf8+Vzx2hoYTMpMzyrttiHxVem3tDR0oF6Tms_A@mail.gmail.com>
	<4EB7C5B1.5020705@gmail.com>
Message-ID: <CAApt6D+5eDZbWKbzFU1-csuwN5v+Rttckm_MntRPkvy7U8+kCQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111108/bc38b8d8/attachment.pl>

From simon.urbanek at r-project.org  Wed Nov  9 02:28:41 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 8 Nov 2011 20:28:41 -0500
Subject: [Rd] Question on parsing R code from C
In-Reply-To: <loom.20111109T001139-68@post.gmane.org>
References: <loom.20111108T203022-872@post.gmane.org>
	<9465BE63-EA88-4BE2-8D1C-9E33BE8AA45D@r-project.org>
	<loom.20111108T224700-655@post.gmane.org>
	<3D4F776D-4D5D-4C39-90B3-12DF09C5C6BA@r-project.org>
	<loom.20111109T001139-68@post.gmane.org>
Message-ID: <AF0744B1-C119-4BF1-99D0-9DBA31E734F9@r-project.org>


On Nov 8, 2011, at 6:53 PM, KR wrote:

> Simon Urbanek <simon.urbanek <at> r-project.org> writes:
>> Except that you don't know what are macros, inlined functions and actual 
> functions. If you are careful you
>> can possibly fall back to external functions but, obviously, your code will be 
> less efficient. I would
>> still prefer including Rinternals.h - you must have a *really* good reason to 
> not do so ;)
> 
> Hmmm yes there are good motives (I am not completely unreasonable, yet :P) but I 
> could probably cope with it if there is no other way.
> 
> Regarding the rest of the e-mail, please let me be clearer on what my goal is. I 
> would need a function to create and initialize an R state, a function to close 
> the state, and a function (R_ParseVector?) that takes as input the R state and a 
> string (containing R code), evaluates the code and return an "error code" 
> (error, incomplete, done) plus (eventually) a string containing the output of 
> the computation.
> 

That itself is quite simple - there is an example in R-ext 5.12.


> In my application I do not have any UI elements (it's console based), but I 
> would like calls to plot in R (and other functions using the graphic device) to 
> function as they would under R.exe (on windows), i.e. have persistent windows 
> popped up which you can resize ecc ecc. I naively thought that these graphic 
> capabilities came automatically with the R_ParseVector via some threading 
> techniques.
> 

R_ParseVector doesn't evaluate anything so it's innocent here. Rf_eval() will run the actual code and it will create a window (if you use an interactive device) but the window won't respond to anything, because the moment Rf_eval() returns R has lost control and everything is up to your code. R is not threaded* (and the R API is not thread-safe) so the only way to continue is for you to run the run loop, i.e. you have to return control back to R so it can process events. 

Now the hard part is that running the event loop is system-dependent. You will see it discussed in R-ext 8.1 (unix) and 8.2 (Windows).

Cheers,
Simon


* - on unix R itself doesn't use threads because it's problematic (other than OpenMP); the Windows Rgui actually uses threads cautiously so that the UI stays responsive while R is busy, but this is not done by R but the GUI. Similarly R.app GUI uses threads to monitor I/O pipes but the system loop is meshed into R.


From ggrothendieck at gmail.com  Wed Nov  9 13:52:39 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 9 Nov 2011 07:52:39 -0500
Subject: [Rd] NAMESPACE file generation issue R 2.14.0 on Debian Squeeze
In-Reply-To: <4EB970ED.6080206@statistik.tu-dortmund.de>
References: <CACb17F4vRs0_VtHG+NvPkhu6ho6T3Qh9qgpLu8vN+Dy2N4Ti+w@mail.gmail.com>
	<4EB949D7.80507@statistik.tu-dortmund.de>
	<CAP01uRnQVcOK4uv61Y2p1Yz4wcF0Og-X_1oN6bLdNBDhP54pvA@mail.gmail.com>
	<4EB94C7A.5070207@statistik.tu-dortmund.de>
	<CAP01uR=mrt-Avnbv+UZ9_CKwj4cLcnGuyF-J4KLxt=nwvU2TdQ@mail.gmail.com>
	<4EB95920.1090304@statistik.tu-dortmund.de>
	<CAP01uRknbTxRg1+dL501c6GPp81jEKwGkGUxmre2ZX5ii22Jwg@mail.gmail.com>
	<4EB96337.2060005@statistik.tu-dortmund.de>
	<CAP01uRkHBRHW5FuqoQE60vEgyhSEvnKeE5SQ0Oux1CNr9_aOPA@mail.gmail.com>
	<4EB970ED.6080206@statistik.tu-dortmund.de>
Message-ID: <CAP01uRkXKy7n6tLmSyKveh9B3qG0O+ieZcg7sH6Jcy+JMMXH1Q@mail.gmail.com>

2011/11/8 Uwe Ligges <ligges at statistik.tu-dortmund.de>:
>
>
> On 08.11.2011 19:08, Gabor Grothendieck wrote:
>>
>> 2011/11/8 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>>
>>>
>>> On 08.11.2011 17:56, Gabor Grothendieck wrote:
>>>>
>>>> 2011/11/8 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>>>>
>>>>>
>>>>> On 08.11.2011 17:04, Gabor Grothendieck wrote:
>>>>>>
>>>>>> 2011/11/8 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>>>>>>
>>>>>>>
>>>>>>> On 08.11.2011 16:31, Gabor Grothendieck wrote:
>>>>>>>>
>>>>>>>> 2011/11/8 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>>>>>>>>
>>>>>>>>> I think many people like to help, but we cannot:
>>>>>>>>>
>>>>>>>>> You say you are under R-2.14.0 and whn you R CMD INSTALL a package
>>>>>>>>> with
>>>>>>>>> that
>>>>>>>>> version of R, it does not have a NAMESPACE in the end?
>>>>>>>>> Then
>>>>>>>>>
>>>>>>>>> ?- your R installation is broken or
>>>>>>>>> ?- you are looking into a library where you have old versios of the
>>>>>>>>> packages
>>>>>>>>> or
>>>>>>>>> ?- you belive you are using R-2.14.0 but you are actually using an
>>>>>>>>> older
>>>>>>>>> version.
>>>>>>>>>
>>>>>>>>
>>>>>>>> This is even reproduced on CRAN. ?All platforms work except one:
>>>>>>>>
>>>>>>>> http://cran.r-project.org/web/checks/check_results_sqldf.html
>>>>>>>
>>>>>>> No, that one is completely unrelated (and already solved, but not yet
>>>>>>> synced
>>>>>>> to CRAN master) to the original question you have removed in your
>>>>>>> reply.
>>>>>>>
>>>>>>
>>>>>> OK. ?One would have thought that the checks on CRAN would be
>>>>>> consistent with the package pages which link to them.
>>>>>
>>>>> I only see consistent information on that page.
>>>>
>>>> If you go to:
>>>>
>>>> http://cran.r-project.org/web/packages/sqldf/index.html
>>>>
>>>> then the tar.gz file was created using R-2.14.0 but if you then click
>>>> on the ?check results ?link on the same page it takes you to this:
>>>
>>>
>>> Yes. the tar.gz was created with R-2.14.0.
>>>
>>>
>>>> http://cran.r-project.org/web/checks/check_results_sqldf.html
>>>>
>>>> On the last link on that page it says ERROR and if click on that it
>>>> takes you to the output of the check which reveals that it was run
>>>> with R 2.13.2.
>>>
>>> Yes, ince it is checked with different flavors of R, R-oldrelease,
>>> R-release, R-devel. See the first column!
>>>
>>> A source package can be created with an version of R and checked under
>>> another version. There is onlyone source package on CRAN, but - just as
>>> an
>>> exmaple - binaries for R-2.13.x and R-2.14.x. Of course, the checks are
>>> applied with the versions stated on the check page. I think you haven't
>>> got
>>> the whole point of checking with different versions of R.
>>>
>>>
>>>
>>>> The Version column on check_results_sqldf.html page refers to the
>>>> package's version, not the R version. ?To get the R version you must
>>>> know to click on each link.
>>>
>>> No, no, no, no! See the first column!
>>> It definitely states if R-olrelease, R-release, R-pacthed or R-devel is
>>> used!
>>>
>>
>> OK. That wasn't clear. It would be better if it actually identified
>> the release as R 2.13.2, etc.
>
> We do not want to change those fields daily: R-devel and R-patched typically
> change from day to day - and then things will really become inconsistent in
> some place.
>

The inconsistencies are less important if they are obvious but more
important if they are not.

How about indicating R-2.14.0 but not the (2011-09-30 r57179) part.
That only changes a few times a year.

Also it would be helpful if the R version number that was used to
build the .tar.gz file and the .zip file were shown right on the
package's CRAN page.

This entire discussion and all the associated confusion probably would
not have occurred since it would be much clearer which versions were
involved.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From ligges at statistik.tu-dortmund.de  Wed Nov  9 15:02:48 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 09 Nov 2011 15:02:48 +0100
Subject: [Rd] NAMESPACE file generation issue R 2.14.0 on Debian Squeeze
In-Reply-To: <CAP01uRkXKy7n6tLmSyKveh9B3qG0O+ieZcg7sH6Jcy+JMMXH1Q@mail.gmail.com>
References: <CACb17F4vRs0_VtHG+NvPkhu6ho6T3Qh9qgpLu8vN+Dy2N4Ti+w@mail.gmail.com>
	<4EB949D7.80507@statistik.tu-dortmund.de>
	<CAP01uRnQVcOK4uv61Y2p1Yz4wcF0Og-X_1oN6bLdNBDhP54pvA@mail.gmail.com>
	<4EB94C7A.5070207@statistik.tu-dortmund.de>
	<CAP01uR=mrt-Avnbv+UZ9_CKwj4cLcnGuyF-J4KLxt=nwvU2TdQ@mail.gmail.com>
	<4EB95920.1090304@statistik.tu-dortmund.de>
	<CAP01uRknbTxRg1+dL501c6GPp81jEKwGkGUxmre2ZX5ii22Jwg@mail.gmail.com>
	<4EB96337.2060005@statistik.tu-dortmund.de>
	<CAP01uRkHBRHW5FuqoQE60vEgyhSEvnKeE5SQ0Oux1CNr9_aOPA@mail.gmail.com>
	<4EB970ED.6080206@statistik.tu-dortmund.de>
	<CAP01uRkXKy7n6tLmSyKveh9B3qG0O+ieZcg7sH6Jcy+JMMXH1Q@mail.gmail.com>
Message-ID: <4EBA8808.905@statistik.tu-dortmund.de>



On 09.11.2011 13:52, Gabor Grothendieck wrote:
> 2011/11/8 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>
>>
>> On 08.11.2011 19:08, Gabor Grothendieck wrote:
>>>
>>> 2011/11/8 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>>>
>>>>
>>>> On 08.11.2011 17:56, Gabor Grothendieck wrote:
>>>>>
>>>>> 2011/11/8 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>>>>>
>>>>>>
>>>>>> On 08.11.2011 17:04, Gabor Grothendieck wrote:
>>>>>>>
>>>>>>> 2011/11/8 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>>>>>>>
>>>>>>>>
>>>>>>>> On 08.11.2011 16:31, Gabor Grothendieck wrote:
>>>>>>>>>
>>>>>>>>> 2011/11/8 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>>>>>>>>>
>>>>>>>>>> I think many people like to help, but we cannot:
>>>>>>>>>>
>>>>>>>>>> You say you are under R-2.14.0 and whn you R CMD INSTALL a package
>>>>>>>>>> with
>>>>>>>>>> that
>>>>>>>>>> version of R, it does not have a NAMESPACE in the end?
>>>>>>>>>> Then
>>>>>>>>>>
>>>>>>>>>>   - your R installation is broken or
>>>>>>>>>>   - you are looking into a library where you have old versios of the
>>>>>>>>>> packages
>>>>>>>>>> or
>>>>>>>>>>   - you belive you are using R-2.14.0 but you are actually using an
>>>>>>>>>> older
>>>>>>>>>> version.
>>>>>>>>>>
>>>>>>>>>
>>>>>>>>> This is even reproduced on CRAN.  All platforms work except one:
>>>>>>>>>
>>>>>>>>> http://cran.r-project.org/web/checks/check_results_sqldf.html
>>>>>>>>
>>>>>>>> No, that one is completely unrelated (and already solved, but not yet
>>>>>>>> synced
>>>>>>>> to CRAN master) to the original question you have removed in your
>>>>>>>> reply.
>>>>>>>>
>>>>>>>
>>>>>>> OK.  One would have thought that the checks on CRAN would be
>>>>>>> consistent with the package pages which link to them.
>>>>>>
>>>>>> I only see consistent information on that page.
>>>>>
>>>>> If you go to:
>>>>>
>>>>> http://cran.r-project.org/web/packages/sqldf/index.html
>>>>>
>>>>> then the tar.gz file was created using R-2.14.0 but if you then click
>>>>> on the  check results  link on the same page it takes you to this:
>>>>
>>>>
>>>> Yes. the tar.gz was created with R-2.14.0.
>>>>
>>>>
>>>>> http://cran.r-project.org/web/checks/check_results_sqldf.html
>>>>>
>>>>> On the last link on that page it says ERROR and if click on that it
>>>>> takes you to the output of the check which reveals that it was run
>>>>> with R 2.13.2.
>>>>
>>>> Yes, ince it is checked with different flavors of R, R-oldrelease,
>>>> R-release, R-devel. See the first column!
>>>>
>>>> A source package can be created with an version of R and checked under
>>>> another version. There is onlyone source package on CRAN, but - just as
>>>> an
>>>> exmaple - binaries for R-2.13.x and R-2.14.x. Of course, the checks are
>>>> applied with the versions stated on the check page. I think you haven't
>>>> got
>>>> the whole point of checking with different versions of R.
>>>>
>>>>
>>>>
>>>>> The Version column on check_results_sqldf.html page refers to the
>>>>> package's version, not the R version.  To get the R version you must
>>>>> know to click on each link.
>>>>
>>>> No, no, no, no! See the first column!
>>>> It definitely states if R-olrelease, R-release, R-pacthed or R-devel is
>>>> used!
>>>>
>>>
>>> OK. That wasn't clear. It would be better if it actually identified
>>> the release as R 2.13.2, etc.
>>
>> We do not want to change those fields daily: R-devel and R-patched typically
>> change from day to day - and then things will really become inconsistent in
>> some place.
>>
>
> The inconsistencies are less important if they are obvious but more
> important if they are not.
>
> How about indicating R-2.14.0 but not the (2011-09-30 r57179) part.

Honestly, that (svn revision) is the only part that we do not have on 
the front pages but they are given in the log files.

Uwe


> That only changes a few times a year.
>
> Also it would be helpful if the R version number that was used to
> build the .tar.gz file
> and the .zip file were shown right on the
> package's CRAN page.


> This entire discussion and all the associated confusion probably would
> not have occurred since it would be much clearer which versions were
> involved.
>


From ggrothendieck at gmail.com  Wed Nov  9 15:23:45 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 9 Nov 2011 09:23:45 -0500
Subject: [Rd] NAMESPACE file generation issue R 2.14.0 on Debian Squeeze
In-Reply-To: <4EBA8808.905@statistik.tu-dortmund.de>
References: <CACb17F4vRs0_VtHG+NvPkhu6ho6T3Qh9qgpLu8vN+Dy2N4Ti+w@mail.gmail.com>
	<4EB949D7.80507@statistik.tu-dortmund.de>
	<CAP01uRnQVcOK4uv61Y2p1Yz4wcF0Og-X_1oN6bLdNBDhP54pvA@mail.gmail.com>
	<4EB94C7A.5070207@statistik.tu-dortmund.de>
	<CAP01uR=mrt-Avnbv+UZ9_CKwj4cLcnGuyF-J4KLxt=nwvU2TdQ@mail.gmail.com>
	<4EB95920.1090304@statistik.tu-dortmund.de>
	<CAP01uRknbTxRg1+dL501c6GPp81jEKwGkGUxmre2ZX5ii22Jwg@mail.gmail.com>
	<4EB96337.2060005@statistik.tu-dortmund.de>
	<CAP01uRkHBRHW5FuqoQE60vEgyhSEvnKeE5SQ0Oux1CNr9_aOPA@mail.gmail.com>
	<4EB970ED.6080206@statistik.tu-dortmund.de>
	<CAP01uRkXKy7n6tLmSyKveh9B3qG0O+ieZcg7sH6Jcy+JMMXH1Q@mail.gmail.com>
	<4EBA8808.905@statistik.tu-dortmund.de>
Message-ID: <CAP01uRm8NTy7-=mX4jgx-7FbTd=0u-151o0UFvMbtBN7vf8EVg@mail.gmail.com>

2011/11/9 Uwe Ligges <ligges at statistik.tu-dortmund.de>:
>
>
> On 09.11.2011 13:52, Gabor Grothendieck wrote:
>>
>> 2011/11/8 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>>
>>>
>>> On 08.11.2011 19:08, Gabor Grothendieck wrote:
>>>>
>>>> 2011/11/8 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>>>>
>>>>>
>>>>> On 08.11.2011 17:56, Gabor Grothendieck wrote:
>>>>>>
>>>>>> 2011/11/8 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>>>>>>
>>>>>>>
>>>>>>> On 08.11.2011 17:04, Gabor Grothendieck wrote:
>>>>>>>>
>>>>>>>> 2011/11/8 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> On 08.11.2011 16:31, Gabor Grothendieck wrote:
>>>>>>>>>>
>>>>>>>>>> 2011/11/8 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>>>>>>>>>>
>>>>>>>>>>> I think many people like to help, but we cannot:
>>>>>>>>>>>
>>>>>>>>>>> You say you are under R-2.14.0 and whn you R CMD INSTALL a
>>>>>>>>>>> package
>>>>>>>>>>> with
>>>>>>>>>>> that
>>>>>>>>>>> version of R, it does not have a NAMESPACE in the end?
>>>>>>>>>>> Then
>>>>>>>>>>>
>>>>>>>>>>> ?- your R installation is broken or
>>>>>>>>>>> ?- you are looking into a library where you have old versios of
>>>>>>>>>>> the
>>>>>>>>>>> packages
>>>>>>>>>>> or
>>>>>>>>>>> ?- you belive you are using R-2.14.0 but you are actually using
>>>>>>>>>>> an
>>>>>>>>>>> older
>>>>>>>>>>> version.
>>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> This is even reproduced on CRAN. ?All platforms work except one:
>>>>>>>>>>
>>>>>>>>>> http://cran.r-project.org/web/checks/check_results_sqldf.html
>>>>>>>>>
>>>>>>>>> No, that one is completely unrelated (and already solved, but not
>>>>>>>>> yet
>>>>>>>>> synced
>>>>>>>>> to CRAN master) to the original question you have removed in your
>>>>>>>>> reply.
>>>>>>>>>
>>>>>>>>
>>>>>>>> OK. ?One would have thought that the checks on CRAN would be
>>>>>>>> consistent with the package pages which link to them.
>>>>>>>
>>>>>>> I only see consistent information on that page.
>>>>>>
>>>>>> If you go to:
>>>>>>
>>>>>> http://cran.r-project.org/web/packages/sqldf/index.html
>>>>>>
>>>>>> then the tar.gz file was created using R-2.14.0 but if you then click
>>>>>> on the ?check results ?link on the same page it takes you to this:
>>>>>
>>>>>
>>>>> Yes. the tar.gz was created with R-2.14.0.
>>>>>
>>>>>
>>>>>> http://cran.r-project.org/web/checks/check_results_sqldf.html
>>>>>>
>>>>>> On the last link on that page it says ERROR and if click on that it
>>>>>> takes you to the output of the check which reveals that it was run
>>>>>> with R 2.13.2.
>>>>>
>>>>> Yes, ince it is checked with different flavors of R, R-oldrelease,
>>>>> R-release, R-devel. See the first column!
>>>>>
>>>>> A source package can be created with an version of R and checked under
>>>>> another version. There is onlyone source package on CRAN, but - just as
>>>>> an
>>>>> exmaple - binaries for R-2.13.x and R-2.14.x. Of course, the checks are
>>>>> applied with the versions stated on the check page. I think you haven't
>>>>> got
>>>>> the whole point of checking with different versions of R.
>>>>>
>>>>>
>>>>>
>>>>>> The Version column on check_results_sqldf.html page refers to the
>>>>>> package's version, not the R version. ?To get the R version you must
>>>>>> know to click on each link.
>>>>>
>>>>> No, no, no, no! See the first column!
>>>>> It definitely states if R-olrelease, R-release, R-pacthed or R-devel is
>>>>> used!
>>>>>
>>>>
>>>> OK. That wasn't clear. It would be better if it actually identified
>>>> the release as R 2.13.2, etc.
>>>
>>> We do not want to change those fields daily: R-devel and R-patched
>>> typically
>>> change from day to day - and then things will really become inconsistent
>>> in
>>> some place.
>>>
>>
>> The inconsistencies are less important if they are obvious but more
>> important if they are not.
>>
>> How about indicating R-2.14.0 but not the (2011-09-30 r57179) part.
>
> Honestly, that (svn revision) is the only part that we do not have on the
> front pages but they are given in the log files.

The R version is not on the package's CRAN page, e.g.
http://cran.r-project.org/web/packages/sqldf/index.html  I was
thinking of something like this for the Package source line:

Package built source:	 sqldf_0.4-3.tar.gz (built with R version 2.14.0
Patched (2011-10-10 r12345)

This seems important since that line truly is not the source but is
the built source.  The actual source is not uploaded to CRAN or shown.
A transformation has been applied to it so rightfully that should be
tracked back via the R version.

This would make it very clear not only which version of the R package
you are dealing with but which version of R built it and that can in
certain circumstances be important for precisely identifying it.  This
could also be done for the .zip file, etc. shown on that page.

If that level of detail is not feasible then this would be next best
(just showing the R x.y.z version):
Package built source:   sqldf_0.4-3.tar.gz (built with R version 2.14.0)


-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From ligges at statistik.tu-dortmund.de  Wed Nov  9 15:42:15 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 09 Nov 2011 15:42:15 +0100
Subject: [Rd] NAMESPACE file generation issue R 2.14.0 on Debian Squeeze
In-Reply-To: <CAP01uRm8NTy7-=mX4jgx-7FbTd=0u-151o0UFvMbtBN7vf8EVg@mail.gmail.com>
References: <CACb17F4vRs0_VtHG+NvPkhu6ho6T3Qh9qgpLu8vN+Dy2N4Ti+w@mail.gmail.com>
	<4EB949D7.80507@statistik.tu-dortmund.de>
	<CAP01uRnQVcOK4uv61Y2p1Yz4wcF0Og-X_1oN6bLdNBDhP54pvA@mail.gmail.com>
	<4EB94C7A.5070207@statistik.tu-dortmund.de>
	<CAP01uR=mrt-Avnbv+UZ9_CKwj4cLcnGuyF-J4KLxt=nwvU2TdQ@mail.gmail.com>
	<4EB95920.1090304@statistik.tu-dortmund.de>
	<CAP01uRknbTxRg1+dL501c6GPp81jEKwGkGUxmre2ZX5ii22Jwg@mail.gmail.com>
	<4EB96337.2060005@statistik.tu-dortmund.de>
	<CAP01uRkHBRHW5FuqoQE60vEgyhSEvnKeE5SQ0Oux1CNr9_aOPA@mail.gmail.com>
	<4EB970ED.6080206@statistik.tu-dortmund.de>
	<CAP01uRkXKy7n6tLmSyKveh9B3qG0O+ieZcg7sH6Jcy+JMMXH1Q@mail.gmail.com>
	<4EBA8808.905@statistik.tu-dortmund.de>
	<CAP01uRm8NTy7-=mX4jgx-7FbTd=0u-151o0UFvMbtBN7vf8EVg@mail.gmail.com>
Message-ID: <4EBA9147.3030408@statistik.tu-dortmund.de>



On 09.11.2011 15:23, Gabor Grothendieck wrote:
> 2011/11/9 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>
>>
>> On 09.11.2011 13:52, Gabor Grothendieck wrote:
>>>
>>> 2011/11/8 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>>>
>>>>
>>>> On 08.11.2011 19:08, Gabor Grothendieck wrote:
>>>>>
>>>>> 2011/11/8 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>>>>>
>>>>>>
>>>>>> On 08.11.2011 17:56, Gabor Grothendieck wrote:
>>>>>>>
>>>>>>> 2011/11/8 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>>>>>>>
>>>>>>>>
>>>>>>>> On 08.11.2011 17:04, Gabor Grothendieck wrote:
>>>>>>>>>
>>>>>>>>> 2011/11/8 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> On 08.11.2011 16:31, Gabor Grothendieck wrote:
>>>>>>>>>>>
>>>>>>>>>>> 2011/11/8 Uwe Ligges<ligges at statistik.tu-dortmund.de>:
>>>>>>>>>>>>
>>>>>>>>>>>> I think many people like to help, but we cannot:
>>>>>>>>>>>>
>>>>>>>>>>>> You say you are under R-2.14.0 and whn you R CMD INSTALL a
>>>>>>>>>>>> package
>>>>>>>>>>>> with
>>>>>>>>>>>> that
>>>>>>>>>>>> version of R, it does not have a NAMESPACE in the end?
>>>>>>>>>>>> Then
>>>>>>>>>>>>
>>>>>>>>>>>>   - your R installation is broken or
>>>>>>>>>>>>   - you are looking into a library where you have old versios of
>>>>>>>>>>>> the
>>>>>>>>>>>> packages
>>>>>>>>>>>> or
>>>>>>>>>>>>   - you belive you are using R-2.14.0 but you are actually using
>>>>>>>>>>>> an
>>>>>>>>>>>> older
>>>>>>>>>>>> version.
>>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> This is even reproduced on CRAN.  All platforms work except one:
>>>>>>>>>>>
>>>>>>>>>>> http://cran.r-project.org/web/checks/check_results_sqldf.html
>>>>>>>>>>
>>>>>>>>>> No, that one is completely unrelated (and already solved, but not
>>>>>>>>>> yet
>>>>>>>>>> synced
>>>>>>>>>> to CRAN master) to the original question you have removed in your
>>>>>>>>>> reply.
>>>>>>>>>>
>>>>>>>>>
>>>>>>>>> OK.  One would have thought that the checks on CRAN would be
>>>>>>>>> consistent with the package pages which link to them.
>>>>>>>>
>>>>>>>> I only see consistent information on that page.
>>>>>>>
>>>>>>> If you go to:
>>>>>>>
>>>>>>> http://cran.r-project.org/web/packages/sqldf/index.html
>>>>>>>
>>>>>>> then the tar.gz file was created using R-2.14.0 but if you then click
>>>>>>> on the  check results  link on the same page it takes you to this:
>>>>>>
>>>>>>
>>>>>> Yes. the tar.gz was created with R-2.14.0.
>>>>>>
>>>>>>
>>>>>>> http://cran.r-project.org/web/checks/check_results_sqldf.html
>>>>>>>
>>>>>>> On the last link on that page it says ERROR and if click on that it
>>>>>>> takes you to the output of the check which reveals that it was run
>>>>>>> with R 2.13.2.
>>>>>>
>>>>>> Yes, ince it is checked with different flavors of R, R-oldrelease,
>>>>>> R-release, R-devel. See the first column!
>>>>>>
>>>>>> A source package can be created with an version of R and checked under
>>>>>> another version. There is onlyone source package on CRAN, but - just as
>>>>>> an
>>>>>> exmaple - binaries for R-2.13.x and R-2.14.x. Of course, the checks are
>>>>>> applied with the versions stated on the check page. I think you haven't
>>>>>> got
>>>>>> the whole point of checking with different versions of R.
>>>>>>
>>>>>>
>>>>>>
>>>>>>> The Version column on check_results_sqldf.html page refers to the
>>>>>>> package's version, not the R version.  To get the R version you must
>>>>>>> know to click on each link.
>>>>>>
>>>>>> No, no, no, no! See the first column!
>>>>>> It definitely states if R-olrelease, R-release, R-pacthed or R-devel is
>>>>>> used!
>>>>>>
>>>>>
>>>>> OK. That wasn't clear. It would be better if it actually identified
>>>>> the release as R 2.13.2, etc.
>>>>
>>>> We do not want to change those fields daily: R-devel and R-patched
>>>> typically
>>>> change from day to day - and then things will really become inconsistent
>>>> in
>>>> some place.
>>>>
>>>
>>> The inconsistencies are less important if they are obvious but more
>>> important if they are not.
>>>
>>> How about indicating R-2.14.0 but not the (2011-09-30 r57179) part.
>>
>> Honestly, that (svn revision) is the only part that we do not have on the
>> front pages but they are given in the log files.
>
> The R version is not on the package's CRAN page, e.g.
> http://cran.r-project.org/web/packages/sqldf/index.html  I was
> thinking of something like this for the Package source line:
>
> Package built source:	 sqldf_0.4-3.tar.gz (built with R version 2.14.0
> Patched (2011-10-10 r12345)

Not relevant for the majority of cases. Version number of the package is 
relevant, not the R used to build it (well, there are cornercases, e.g. 
for knowing which version was used to generate the vignette).

And in addition, we to not have the information. Where do you think we 
can get that from? Even if we change R to provide the information now, 
we'd only know if it was built with R <= 2.14.0 or later.


> This seems important since that line truly is not the source but is
> the built source.  The actual source is not uploaded to CRAN or shown.

He? What is the difference between "the source" and "the built source"? 
  A source package has always undergone R CMD build on the submitters 
machine. We do only have only one kind of source packages on CRAN.


> A transformation has been applied to it

Where and why do you want to apply transformations?


> so rightfully that should be
> tracked back via the R version.
>
> This would make it very clear not only which version of the R package
> you are dealing with but which version of R built it and that can in
> certain circumstances be important for precisely identifying it.  This
> could also be done for the .zip file, etc. shown on that page.

The zip file shown *there* is always R-release or R-patched (hence 
currently R-2.14.0 given your request) for ALL packages. We do not list 
zip files for non R-release *there*. I thought you were still talking 
about the check page.


>
> If that level of detail is not feasible then this would be next best
> (just showing the R x.y.z version):
> Package built source:   sqldf_0.4-3.tar.gz (built with R version 2.14.0)
>
>

I give up.

uwe


From ggrothendieck at gmail.com  Wed Nov  9 15:57:38 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 9 Nov 2011 09:57:38 -0500
Subject: [Rd] NAMESPACE file generation issue R 2.14.0 on Debian Squeeze
In-Reply-To: <4EBA9147.3030408@statistik.tu-dortmund.de>
References: <CACb17F4vRs0_VtHG+NvPkhu6ho6T3Qh9qgpLu8vN+Dy2N4Ti+w@mail.gmail.com>
	<4EB949D7.80507@statistik.tu-dortmund.de>
	<CAP01uRnQVcOK4uv61Y2p1Yz4wcF0Og-X_1oN6bLdNBDhP54pvA@mail.gmail.com>
	<4EB94C7A.5070207@statistik.tu-dortmund.de>
	<CAP01uR=mrt-Avnbv+UZ9_CKwj4cLcnGuyF-J4KLxt=nwvU2TdQ@mail.gmail.com>
	<4EB95920.1090304@statistik.tu-dortmund.de>
	<CAP01uRknbTxRg1+dL501c6GPp81jEKwGkGUxmre2ZX5ii22Jwg@mail.gmail.com>
	<4EB96337.2060005@statistik.tu-dortmund.de>
	<CAP01uRkHBRHW5FuqoQE60vEgyhSEvnKeE5SQ0Oux1CNr9_aOPA@mail.gmail.com>
	<4EB970ED.6080206@statistik.tu-dortmund.de>
	<CAP01uRkXKy7n6tLmSyKveh9B3qG0O+ieZcg7sH6Jcy+JMMXH1Q@mail.gmail.com>
	<4EBA8808.905@statistik.tu-dortmund.de>
	<CAP01uRm8NTy7-=mX4jgx-7FbTd=0u-151o0UFvMbtBN7vf8EVg@mail.gmail.com>
	<4EBA9147.3030408@statistik.tu-dortmund.de>
Message-ID: <CAP01uRmwS=+wbqJ=ZCBFOdhhcXf5jW7w9nbb2hDbJ4W4jqnq=A@mail.gmail.com>

2011/11/9 Uwe Ligges <ligges at statistik.tu-dortmund.de>:
>>>
>>> Honestly, that (svn revision) is the only part that we do not have on the
>>> front pages but they are given in the log files.
>>
>> The R version is not on the package's CRAN page, e.g.
>> http://cran.r-project.org/web/packages/sqldf/index.html ?I was
>> thinking of something like this for the Package source line:
>>
>> Package built source: ? ?sqldf_0.4-3.tar.gz (built with R version 2.14.0
>> Patched (2011-10-10 r12345)
>
> Not relevant for the majority of cases. Version number of the package is
> relevant, not the R used to build it (well, there are cornercases, e.g. for
> knowing which version was used to generate the vignette).

The point is that the answer to the poster's question does not really
resolve it except for that one person.  To really solve the problem
the process needs to be changed so that its unlikely to occur again.

>
> And in addition, we to not have the information. Where do you think we can
> get that from? Even if we change R to provide the information now, we'd only
> know if it was built with R <= 2.14.0 or later.

Yes, I realize that but it would have to be added during the build
process in the same way that certain other information is added
already.

>
>
>> This seems important since that line truly is not the source but is
>> the built source. ?The actual source is not uploaded to CRAN or shown.
>
> He? What is the difference between "the source" and "the built source"? ?A
> source package has always undergone R CMD build on the submitters machine.
> We do only have only one kind of source packages on CRAN.

The built source has been processed by R CMD build and the true source
has not.  What CRAN labels the source is not the true source but is
really the built source. There has been a transformation applied to
the true source to get the built source and some version of R was used
to do that.  Furthermore, what the result looks like can depend on
what version of R was used for this.  That its different for different
versions of R was one of the things that precipitated this entire
thread.

>
>
>> A transformation has been applied to it
>
> Where and why do you want to apply transformations?

By transformation I am referring to the existing process of
transforming the true source to the built source.  I was not
suggesting other transformations (other than the fact that it implies
that it would be necessary to identify the R version that built any
given built source in the built source itself).

>
>
>> so rightfully that should be
>> tracked back via the R version.
>>
>> This would make it very clear not only which version of the R package
>> you are dealing with but which version of R built it and that can in
>> certain circumstances be important for precisely identifying it. ?This
>> could also be done for the .zip file, etc. shown on that page.
>
> The zip file shown *there* is always R-release or R-patched (hence currently
> R-2.14.0 given your request) for ALL packages. We do not list zip files for
> non R-release *there*. I thought you were still talking about the check
> page.

Originally I was referring to the check page but then expanded it to
the main page as well since it seemed relevant in both places.  I find
this whole area is confusing (and clearly I am not the only one hence
this thread) and it could use some clarification right on the web
pages themselves to avoid these sorts of problems.  I think the most
desirable from a user's viewpoint is to actually stick the R version
right there but if its not feasible some other way of addressing this
would be nice.

>
>
>>
>> If that level of detail is not feasible then this would be next best
>> (just showing the R x.y.z version):
>> Package built source: ? sqldf_0.4-3.tar.gz (built with R version 2.14.0)
>>
>>
>
> I give up.
>
> uwe
>



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From cgenolin at u-paris10.fr  Wed Nov  9 19:08:56 2011
From: cgenolin at u-paris10.fr (cgenolin)
Date: Wed, 9 Nov 2011 10:08:56 -0800 (PST)
Subject: [Rd] Define S4 methods for 'plot'
Message-ID: <1320862136986-4020750.post@n4.nabble.com>

Hi the list
I am creating a package and I have a problem to define a S4 method for plot.
I define a class 'A' and a class 'B'. I want to define a function plot for
signature c(A,missing) and another method plot for signature c(A,B). My code
is the following :

In /package/R/ directory:
--- main.R ---
setGeneric("plot",function(x,y,...){standardGeneric("plot")})
Aplot <- function(x,paramTraj=3){. . . .}
setMethod("plot",signature=c(x="A",y="missing"),Aplot)

ABplot <- function(x,y,paramTraj=5){. . . .}
setMethod("plot",signature=c(x="A",y="B"),ABplot)
---------------

In the root directory /package/
--- NAMESPACE ---
exportMethods("plot",. . . .)
exportClasses("A","B")
------
When I run the code (source("main.r")), every thinks works fine, either plot
on object of class 'A', on 'A,B' or on numeric plot(3). 

The R CMD check bug on an example using plot(3).
The R CMD build works just fine. But if I try to install the package from
the builded file, I get the message:
The following object(s) are masked from 'package:graphics':
    plot.

And then, I cannot use the classical function plot: plot on object 'A'
works, but plot(1) does not.

I try, reading some recent post on r-devel to remove the line 'setGeneric'
but it does not works (which does not surprise me since getGeneric("plot")
gives a NULL results).
 
Any idea of what goes wrong?

Christophe


--
View this message in context: http://r.789695.n4.nabble.com/Define-S4-methods-for-plot-tp4020750p4020750.html
Sent from the R devel mailing list archive at Nabble.com.


From michael.m.spiegel at gmail.com  Wed Nov  9 20:18:09 2011
From: michael.m.spiegel at gmail.com (Michael Spiegel)
Date: Wed, 9 Nov 2011 14:18:09 -0500
Subject: [Rd] exporting isChild in package parallel
Message-ID: <CANwu5-rtUGatfE90RZTtrCMy_6xG-cufuJbi-E30UFvt9LCU9w@mail.gmail.com>

I was wondering if there is any interest in making the function
isChild() exported from the package parallel? This would be of great
help to anyone writing R packages that use thread-level parallelism,
and would like to throttle the spawning of threads whenever the R
process is detected to be a child process that was constructed by
mcfork().

Cheers,
--Michael


From kevin.r.coombes at gmail.com  Wed Nov  9 20:49:56 2011
From: kevin.r.coombes at gmail.com (Kevin R. Coombes)
Date: Wed, 09 Nov 2011 13:49:56 -0600
Subject: [Rd] Define S4 methods for 'plot'
In-Reply-To: <1320862136986-4020750.post@n4.nabble.com>
References: <1320862136986-4020750.post@n4.nabble.com>
Message-ID: <4EBAD964.5020804@gmail.com>

You probably need the directive
     importFrom(graphics, "plot")
in your NAMESPACE file.  This lets the system know that you are using 
the same "plot" function that it already knows about. And your code 
should be careful not to trash a previous conversion of plot to an S4 
generic function, usually by something like

    if (!isGeneric("plot"))
      setGeneric("plot", function(x, y, ...) standardGeneric("plot"))

Best,
     Kevin

On 11/9/2011 12:08 PM, cgenolin wrote:
> Hi the list
> I am creating a package and I have a problem to define a S4 method for plot.
> I define a class 'A' and a class 'B'. I want to define a function plot for
> signature c(A,missing) and another method plot for signature c(A,B). My code
> is the following :
>
> In /package/R/ directory:
> --- main.R ---
> setGeneric("plot",function(x,y,...){standardGeneric("plot")})
> Aplot<- function(x,paramTraj=3){. . . .}
> setMethod("plot",signature=c(x="A",y="missing"),Aplot)
>
> ABplot<- function(x,y,paramTraj=5){. . . .}
> setMethod("plot",signature=c(x="A",y="B"),ABplot)
> ---------------
>
> In the root directory /package/
> --- NAMESPACE ---
> exportMethods("plot",. . . .)
> exportClasses("A","B")
> ------
> When I run the code (source("main.r")), every thinks works fine, either plot
> on object of class 'A', on 'A,B' or on numeric plot(3).
>
> The R CMD check bug on an example using plot(3).
> The R CMD build works just fine. But if I try to install the package from
> the builded file, I get the message:
> The following object(s) are masked from 'package:graphics':
>      plot.
>
> And then, I cannot use the classical function plot: plot on object 'A'
> works, but plot(1) does not.
>
> I try, reading some recent post on r-devel to remove the line 'setGeneric'
> but it does not works (which does not surprise me since getGeneric("plot")
> gives a NULL results).
>
> Any idea of what goes wrong?
>
> Christophe
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Define-S4-methods-for-plot-tp4020750p4020750.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From dhinds at sonic.net  Thu Nov 10 07:12:11 2011
From: dhinds at sonic.net (dhinds at sonic.net)
Date: Thu, 10 Nov 2011 06:12:11 +0000
Subject: [Rd] Moderating consequences of garbage collection when in C
References: <4E8BD4EB.60802@fhcrc.org>
Message-ID: <j9fpvr$ad$1@dough.gmane.org>

Martin Morgan <mtmorgan at fhcrc.org> wrote:
> Allocating many small objects triggers numerous garbage collections as R 
> grows its memory, seriously degrading performance. The specific use case 
> is in creating a STRSXP of several 1,000,000's of elements of 60-100 
> characters each; a simplified illustration understating the effects 
> (because there is initially little to garbage collect, in contrast to an 
> R session with several packages loaded) is below.

What a coincidence -- I was just going to post a question about why it
is so slow to create a STRSXP of ~10,000,000 unique elements, each ~10
characters long.  I had noticed that this seemed to show much worse
than linear scaling.  I had not thought of garbage collection as the
culprit -- but indeed it is.  By manipulating the GC trigger, I can
make this operation take as little as 3 seconds (with no GC) or as
long as 76 seconds (with 31 garbage collections).

-- Dave


From mike.dahman at gmail.com  Thu Nov 10 08:13:50 2011
From: mike.dahman at gmail.com (Mike Dahman)
Date: Wed, 9 Nov 2011 23:13:50 -0800
Subject: [Rd] assistance building R on RHEL5
Message-ID: <CAMoFUrU+1+DB5hHUjnF7iPgR2sQxvjY1XJ7XstC4J4PP=Vm+_A@mail.gmail.com>

I have gotten this error while attempting to build R-2.13.2 and
R-2.14.0 using ./configure --with-x=no --enable-R-shlib, and
./configure --with-x=no


Red Hat Enterprise Linux Server release 5.6 (Tikanga)

=========================

Warning in solve.default(rgb) :
  unable to load shared object '/users/home/mked/R-2.13.2/modules//lapack.so':
  /users/home/mked/R-2.13.2/lib/libRlapack.so: undefined symbol:
_gfortran_concat_string
Error in solve.default(rgb) : lapack routines cannot be loaded
Error: unable to load R code in package 'grDevices'

=========================

I'm not sure how to rectify this issue.

Note: I ran 'configure' with an updated configure script to point to
the fortran version that is installed.

  F77=
  F95_compilers="f95 fort xlf95 ifort ifc efc pgf95 lf95 gfortran
gcc44-gfortran ftn g95"     # <== gcc44-gfortran added
  F90_compilers="f90 xlf90 pgf90 pghpf epcf90"
  case "${host_os}" in
    hpux*)
      F77_compilers="g77 fort77 f77 xlf frt pgf77 cf77 fl32 af77" ;;
    *)
      F77_compilers="g77 f77 xlf frt pgf77 cf77 fort77 fl32 af77" ;;
  esac
  GCC_Fortran_compiler=
  if test "${GCC}" = yes; then
    case "${CC_VERSION}" in
      3.*) GCC_Fortran_compiler=g77 ;;
      4.*) GCC_Fortran_compiler=gcc44 ;;   # <== updated to gcc44
    esac
  fi

thanks in advance -

-mike


From cgenolin at u-paris10.fr  Thu Nov 10 13:56:55 2011
From: cgenolin at u-paris10.fr (cgenolin)
Date: Thu, 10 Nov 2011 04:56:55 -0800 (PST)
Subject: [Rd] Define S4 methods for 'plot'
In-Reply-To: <4EBAD964.5020804@gmail.com>
References: <1320862136986-4020750.post@n4.nabble.com>
	<4EBAD964.5020804@gmail.com>
Message-ID: <1320929815098-4023508.post@n4.nabble.com>

I works, thank you very much.

--
View this message in context: http://r.789695.n4.nabble.com/Define-S4-methods-for-plot-tp4020750p4023508.html
Sent from the R devel mailing list archive at Nabble.com.


From ripley at stats.ox.ac.uk  Thu Nov 10 14:43:59 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 10 Nov 2011 13:43:59 +0000 (GMT)
Subject: [Rd] assistance building R on RHEL5
In-Reply-To: <CAMoFUrU+1+DB5hHUjnF7iPgR2sQxvjY1XJ7XstC4J4PP=Vm+_A@mail.gmail.com>
References: <CAMoFUrU+1+DB5hHUjnF7iPgR2sQxvjY1XJ7XstC4J4PP=Vm+_A@mail.gmail.com>
Message-ID: <alpine.LFD.2.02.1111101337260.27740@toucan.stats.ox.ac.uk>

On Wed, 9 Nov 2011, Mike Dahman wrote:

> I have gotten this error while attempting to build R-2.13.2 and
> R-2.14.0 using ./configure --with-x=no --enable-R-shlib, and
> ./configure --with-x=no

Hmm, gcc44 is unlikely to be a Fortran compiler.  You should not be 
patching the configure script, rather setting precious variables like 
F77 (see the R-admin manual).

The problem is in your Fortran setup. At a guess, it has a static 
libgfortran (unusual with gcc 4.x).  Take a look at 
src/library/modules/lapack/Makefile . You most likely have a line

Rlapack_la_LIBADD = # $(FLIBS) $(LIBR)

and need

Rlapack_la_LIBADD = $(FLIBS) # $(LIBR)

Either that, or your compiler and your dynamic libgfortran.so are 
mis-matched.


>
>
> Red Hat Enterprise Linux Server release 5.6 (Tikanga)
>
> =========================
>
> Warning in solve.default(rgb) :
>  unable to load shared object '/users/home/mked/R-2.13.2/modules//lapack.so':
>  /users/home/mked/R-2.13.2/lib/libRlapack.so: undefined symbol:
> _gfortran_concat_string
> Error in solve.default(rgb) : lapack routines cannot be loaded
> Error: unable to load R code in package 'grDevices'
>
> =========================
>
> I'm not sure how to rectify this issue.
>
> Note: I ran 'configure' with an updated configure script to point to
> the fortran version that is installed.
>
>  F77=
>  F95_compilers="f95 fort xlf95 ifort ifc efc pgf95 lf95 gfortran
> gcc44-gfortran ftn g95"     # <== gcc44-gfortran added
>  F90_compilers="f90 xlf90 pgf90 pghpf epcf90"
>  case "${host_os}" in
>    hpux*)
>      F77_compilers="g77 fort77 f77 xlf frt pgf77 cf77 fl32 af77" ;;
>    *)
>      F77_compilers="g77 f77 xlf frt pgf77 cf77 fort77 fl32 af77" ;;
>  esac
>  GCC_Fortran_compiler=
>  if test "${GCC}" = yes; then
>    case "${CC_VERSION}" in
>      3.*) GCC_Fortran_compiler=g77 ;;
>      4.*) GCC_Fortran_compiler=gcc44 ;;   # <== updated to gcc44
>    esac
>  fi
>
> thanks in advance -
>
> -mike
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From lawrence.michael at gene.com  Thu Nov 10 15:15:27 2011
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Thu, 10 Nov 2011 06:15:27 -0800
Subject: [Rd] url() does not decode when writing local files
Message-ID: <CAOQ5NyfyLH7VwsZCrp4ra7tOpjjrOazo4TJtpwWjoWjwi0F=JQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111110/7d0ff6b5/attachment.pl>

From mike.dahman at gmail.com  Thu Nov 10 17:01:51 2011
From: mike.dahman at gmail.com (Mike Dahman)
Date: Thu, 10 Nov 2011 08:01:51 -0800
Subject: [Rd] assistance building R on RHEL5
In-Reply-To: <alpine.LFD.2.02.1111101337260.27740@toucan.stats.ox.ac.uk>
References: <CAMoFUrU+1+DB5hHUjnF7iPgR2sQxvjY1XJ7XstC4J4PP=Vm+_A@mail.gmail.com>
	<alpine.LFD.2.02.1111101337260.27740@toucan.stats.ox.ac.uk>
Message-ID: <CAMoFUrXZ=pJNbehst7CfVZGpWsyCywB_depRaPUzRvxX+Yzh3g@mail.gmail.com>

Thanks for the tips. It appears as the root cause was indeed the
fortran/gcc packages.

There was a mix of the gcc packages and gcc 44 packages. I removed the
gcc44s and installed the gcc-fortran, put the original configure
script back and compilation completed.

gcc.x86_64
gcc-c++.x86_64
gcc-gfortran.x86_64 (this was missing)

and

gcc44.x86_64
gcc44-c++.x86_64   (this was missing)
gcc44-gfortran.x86_64

You were also correct about the Rlapack_la_LIBADD syntax. I initially
changed it, but had the same result prior to fixing the gcc packages.
The compilation seemed to progress fine with the original makefile
after the gcc packages were cleaned up.

Rlapack_la_LIBADD = # $(FLIBS) $(LIBR)

'make check' just completed successfully so I'm hoping all is well.

Thanks again.

-mike

On Thu, Nov 10, 2011 at 5:43 AM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> On Wed, 9 Nov 2011, Mike Dahman wrote:
>
>> I have gotten this error while attempting to build R-2.13.2 and
>> R-2.14.0 using ./configure --with-x=no --enable-R-shlib, and
>> ./configure --with-x=no
>
> Hmm, gcc44 is unlikely to be a Fortran compiler. ?You should not be patching
> the configure script, rather setting precious variables like F77 (see the
> R-admin manual).
>
> The problem is in your Fortran setup. At a guess, it has a static
> libgfortran (unusual with gcc 4.x). ?Take a look at
> src/library/modules/lapack/Makefile . You most likely have a line
>
> Rlapack_la_LIBADD = # $(FLIBS) $(LIBR)
>
> and need
>
> Rlapack_la_LIBADD = $(FLIBS) # $(LIBR)
>
> Either that, or your compiler and your dynamic libgfortran.so are
> mis-matched.
>
>
>>
>>
>> Red Hat Enterprise Linux Server release 5.6 (Tikanga)
>>
>> =========================
>>
>> Warning in solve.default(rgb) :
>> ?unable to load shared object
>> '/users/home/mked/R-2.13.2/modules//lapack.so':
>> ?/users/home/mked/R-2.13.2/lib/libRlapack.so: undefined symbol:
>> _gfortran_concat_string
>> Error in solve.default(rgb) : lapack routines cannot be loaded
>> Error: unable to load R code in package 'grDevices'
>>
>> =========================
>>
>> I'm not sure how to rectify this issue.
>>
>> Note: I ran 'configure' with an updated configure script to point to
>> the fortran version that is installed.
>>
>> ?F77=
>> ?F95_compilers="f95 fort xlf95 ifort ifc efc pgf95 lf95 gfortran
>> gcc44-gfortran ftn g95" ? ? # <== gcc44-gfortran added
>> ?F90_compilers="f90 xlf90 pgf90 pghpf epcf90"
>> ?case "${host_os}" in
>> ? hpux*)
>> ? ? F77_compilers="g77 fort77 f77 xlf frt pgf77 cf77 fl32 af77" ;;
>> ? *)
>> ? ? F77_compilers="g77 f77 xlf frt pgf77 cf77 fort77 fl32 af77" ;;
>> ?esac
>> ?GCC_Fortran_compiler=
>> ?if test "${GCC}" = yes; then
>> ? case "${CC_VERSION}" in
>> ? ? 3.*) GCC_Fortran_compiler=g77 ;;
>> ? ? 4.*) GCC_Fortran_compiler=gcc44 ;; ? # <== updated to gcc44
>> ? esac
>> ?fi
>>
>> thanks in advance -
>>
>> -mike
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> --
> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595
>


From jeffrey.horner at gmail.com  Fri Nov 11 05:54:09 2011
From: jeffrey.horner at gmail.com (Jeffrey Horner)
Date: Thu, 10 Nov 2011 22:54:09 -0600
Subject: [Rd] When collected warnings exceeds 50
Message-ID: <CAD+yNFjt51Jch5XnnX-mXjzeAW7Qeqemha97SdmpL=qS2hgfMQ@mail.gmail.com>

Hi,

I've been tracking down a memory leak in an rApache application,
http://data.vanderbilt.edu/rapache/bbplot. The code was deployed in
2007 and has survived numerous upgrades of both R and rApache
(including upgrades and bugs in RMySQL). It's written in such a way so
that web crawlers will download every possible URL the app will
create. It's not a high-traffic app, but just about every line of code
is executed at some point during a crawl by Google, Bing, etc.

Here's the salient point: the app (well, just about all rApache apps)
sets option warn to 0 to collect all warnings until a request is
completed. It turns out that some requests will collect more than 50
warnings, and the result is an apache process that leaks memory until
finally seg faulting somewhere in one of R's extra packages, if I
recall correctly.

After what seems like a month working on this problem, I think I've
narrowed it down to a simple test case. I'm testing with R-devel
r57624 on ubuntu linux. Running the following under valgrind:

R -d valgrind
> options(warn=0)
> for (i in 1:51) factor(1,levels=c(1,1) # duplicate level warningcall

and you should see "Invalid read" messages. I've narrowed it down to
vwarningcall_dflt starting a new R context via begincontext()  but
returning early without calling endcontext() in errors.c:

 svn diff src/main/errors.c
Index: src/main/errors.c
===================================================================
--- src/main/errors.c	(revision 57624)
+++ src/main/errors.c	(working copy)
@@ -333,8 +333,11 @@
 	char *tr; int nc;
 	if(!R_CollectWarnings)
 	    setupwarnings();
-	if( R_CollectWarnings > 49 )
+	if( R_CollectWarnings > 49 ) {
+	    endcontext(&cntxt);
+	    inWarning = 0;
 	    return;
+	}
 	SET_VECTOR_ELT(R_Warnings, R_CollectWarnings, call);
 	Rvsnprintf(buf, min(BUFSIZE, R_WarnLength+1), format, ap);
 	if(R_WarnLength < BUFSIZE - 20 && strlen(buf) == R_WarnLength)

This fix eliminates the "Invalid read" errors, but I'm unsure if it
fixes my application. I'll find out tomorrow.

Jeff


From jeffrey.horner at gmail.com  Fri Nov 11 06:00:22 2011
From: jeffrey.horner at gmail.com (Jeffrey Horner)
Date: Thu, 10 Nov 2011 23:00:22 -0600
Subject: [Rd] When collected warnings exceeds 50
In-Reply-To: <CAD+yNFjt51Jch5XnnX-mXjzeAW7Qeqemha97SdmpL=qS2hgfMQ@mail.gmail.com>
References: <CAD+yNFjt51Jch5XnnX-mXjzeAW7Qeqemha97SdmpL=qS2hgfMQ@mail.gmail.com>
Message-ID: <CAD+yNFip_PJd18ZJZVNeVJ3bMB-2uNm_cuKsUna39S8mtgwU+A@mail.gmail.com>

On Thu, Nov 10, 2011 at 10:54 PM, Jeffrey Horner
<jeffrey.horner at gmail.com> wrote:
> Hi,
>
> I've been tracking down a memory leak in an rApache application,
> http://data.vanderbilt.edu/rapache/bbplot. The code was deployed in
> 2007 and has survived numerous upgrades of both R and rApache
> (including upgrades and bugs in RMySQL). It's written in such a way so
> that web crawlers will download every possible URL the app will
> create. It's not a high-traffic app, but just about every line of code
> is executed at some point during a crawl by Google, Bing, etc.
>
> Here's the salient point: the app (well, just about all rApache apps)
> sets option warn to 0 to collect all warnings until a request is
> completed. It turns out that some requests will collect more than 50
> warnings, and the result is an apache process that leaks memory until
> finally seg faulting somewhere in one of R's extra packages, if I
> recall correctly.
>
> After what seems like a month working on this problem, I think I've
> narrowed it down to a simple test case. I'm testing with R-devel
> r57624 on ubuntu linux. Running the following under valgrind:
>
> R -d valgrind
>> options(warn=0)
>> for (i in 1:51) factor(1,levels=c(1,1) # duplicate level warningcall

Missed a closing parenthesis. should be :

> options(warn=0)
> for (i in 1:51) factor(1,levels=c(1,1)) # duplicate level warningcall

>
> and you should see "Invalid read" messages. I've narrowed it down to
> vwarningcall_dflt starting a new R context via begincontext() ?but
> returning early without calling endcontext() in errors.c:
>
> ?svn diff src/main/errors.c
> Index: src/main/errors.c
> ===================================================================
> --- src/main/errors.c ? (revision 57624)
> +++ src/main/errors.c ? (working copy)
> @@ -333,8 +333,11 @@
> ? ? ? ?char *tr; int nc;
> ? ? ? ?if(!R_CollectWarnings)
> ? ? ? ? ? ?setupwarnings();
> - ? ? ? if( R_CollectWarnings > 49 )
> + ? ? ? if( R_CollectWarnings > 49 ) {
> + ? ? ? ? ? endcontext(&cntxt);
> + ? ? ? ? ? inWarning = 0;
> ? ? ? ? ? ?return;
> + ? ? ? }
> ? ? ? ?SET_VECTOR_ELT(R_Warnings, R_CollectWarnings, call);
> ? ? ? ?Rvsnprintf(buf, min(BUFSIZE, R_WarnLength+1), format, ap);
> ? ? ? ?if(R_WarnLength < BUFSIZE - 20 && strlen(buf) == R_WarnLength)
>
> This fix eliminates the "Invalid read" errors, but I'm unsure if it
> fixes my application. I'll find out tomorrow.
>
> Jeff
>


From timothy.c.bates at gmail.com  Fri Nov 11 12:19:59 2011
From: timothy.c.bates at gmail.com (Timothy Bates)
Date: Fri, 11 Nov 2011 11:19:59 +0000
Subject: [Rd] use() might take a list of packages
Message-ID: <1B5E1D00-397B-429B-B20C-0FBA060841A9@gmail.com>

I heard that a function called use() had been mooted as being more intuitively named than library()

If so, it might be handy if this worked

use(c("MASS","car?))

currently this fails?

library(c("MASS","car"))

From krunal.rao78 at gmail.com  Fri Nov 11 00:24:10 2011
From: krunal.rao78 at gmail.com (KR)
Date: Thu, 10 Nov 2011 23:24:10 +0000
Subject: [Rd] Question on parsing R code from C
References: <loom.20111108T203022-872@post.gmane.org>
	<9465BE63-EA88-4BE2-8D1C-9E33BE8AA45D@r-project.org>
	<loom.20111108T224700-655@post.gmane.org>
	<3D4F776D-4D5D-4C39-90B3-12DF09C5C6BA@r-project.org>
	<loom.20111109T001139-68@post.gmane.org>
	<AF0744B1-C119-4BF1-99D0-9DBA31E734F9@r-project.org>
Message-ID: <loom.20111111T000844-348@post.gmane.org>

First of all thanks a lot to you both for all the replies, they have been of 
great help to me!

I got the basic embedding running, however I still have some issues to solve in 
order to complete the interface to R I am working on:

1. I initialize with Rf_initEmbeddR().
- Is there a way to have more than one R "state" (per single thread)? Or is 
everything necessarily global?
- I also read somewhere that the fpu settings may be touched. Is there a way to 
make sure that this is not the case? Is this related to fpu_setup()?

2. I create a string and parse it via Rf_mkString() and R_parseVector() (yes I 
protect/un-protect the SEXPs).
- Is it possible to obtain the precise error message, like "unexpected symbol 
in..." (as would be reported by R.exe) in case of error as a const char* string?
- If I pass a wrongly escaped string (for instance 'ggsave("C:\gtest.png")', 
please notice the missing \) I get on stderr: Error '\g' is an unrecognized 
escape and I get a crash. This does not happen if for instance i try to parse 
'rnorm(10a10)' in which case I get the error flag and the NULL ptr return. I 
suspect I need to initialize something / set a callback to avoid this but I am 
not sure...

3. I eval with R_tryEvalSilent().
- Again, is it possible to obtain the precise error message in case of 
evaluation error as would be reported from R.exe?

4. Regarding the returned result of evaluation.
- What is the correct way to obtain a const char* string representing the result 
as would be "printed" in the R shell by executing a command (for instance 
"summary(c(1,2,3))") ?
- Why is the return type (as reported from typeof in R and TYPEOF in C) of 
"summary(c(1,2,3))" a double?

Any help / feedback on these issues would be greatly appreciated.

Thanks again.


From k.jewell at campden.co.uk  Fri Nov 11 14:32:45 2011
From: k.jewell at campden.co.uk (Keith Jewell)
Date: Fri, 11 Nov 2011 13:32:45 +0000
Subject: [Rd] use() might take a list of packages
References: <1B5E1D00-397B-429B-B20C-0FBA060841A9@gmail.com>
Message-ID: <j9j85v$5hp$1@dough.gmane.org>


"Timothy Bates" <timothy.c.bates at gmail.com> wrote in message 
news:1B5E1D00-397B-429B-B20C-0FBA060841A9 at gmail.com...
I heard that a function called use() had been mooted as being more 
intuitively named than library()

If so, it might be handy if this worked

use(c("MASS","car?))

currently this fails?

library(c("MASS","car"))
--------------------------------------------
This seems to work, and doesn't seem much effort

> sapply(c("MASS","car"), library, character.only = TRUE)

KJ


From simon.urbanek at r-project.org  Fri Nov 11 16:08:53 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 11 Nov 2011 10:08:53 -0500
Subject: [Rd] Question on parsing R code from C
In-Reply-To: <loom.20111111T000844-348@post.gmane.org>
References: <loom.20111108T203022-872@post.gmane.org>
	<9465BE63-EA88-4BE2-8D1C-9E33BE8AA45D@r-project.org>
	<loom.20111108T224700-655@post.gmane.org>
	<3D4F776D-4D5D-4C39-90B3-12DF09C5C6BA@r-project.org>
	<loom.20111109T001139-68@post.gmane.org>
	<AF0744B1-C119-4BF1-99D0-9DBA31E734F9@r-project.org>
	<loom.20111111T000844-348@post.gmane.org>
Message-ID: <84A85DE6-2914-4C8D-834A-07DE5820B5AD@r-project.org>


On Nov 10, 2011, at 6:24 PM, KR wrote:

> First of all thanks a lot to you both for all the replies, they have been of 
> great help to me!
> 
> I got the basic embedding running, however I still have some issues to solve in 
> order to complete the interface to R I am working on:
> 
> 1. I initialize with Rf_initEmbeddR().
> - Is there a way to have more than one R "state" (per single thread)? Or is 
> everything necessarily global?

There are no threads in R. You have only one, global instance of R.


> - I also read somewhere that the fpu settings may be touched. Is there a way to 
> make sure that this is not the case? Is this related to fpu_setup()?
> 

All following answers assume that you're not running REPL. If you did, you would get all the errors on the console callback, so I'm assuming that's not what you want.


> 2. I create a string and parse it via Rf_mkString() and R_parseVector() (yes I 
> protect/un-protect the SEXPs).
> - Is it possible to obtain the precise error message, like "unexpected symbol 
> in..." (as would be reported by R.exe) in case of error as a const char* string?

AFAIR you have to evaluate parse(text=...) for that, there is no C-level access to parser errors.


> - If I pass a wrongly escaped string (for instance 'ggsave("C:\gtest.png")', 
> please notice the missing \) I get on stderr: Error '\g' is an unrecognized 
> escape and I get a crash. This does not happen if for instance i try to parse 
> 'rnorm(10a10)' in which case I get the error flag and the NULL ptr return. I 
> suspect I need to initialize something / set a callback to avoid this but I am 
> not sure...
> 

If you get a crash, you're not setting up you R correctly. If your R quits then you are in non-interactive mode and you didn't setup an error handler.


> 3. I eval with R_tryEvalSilent().
> - Again, is it possible to obtain the precise error message in case of 
> evaluation error as would be reported from R.exe?
> 

I prefer using Rf_eval() and try(..., silent=TRUE) - you can check on the class of the result to see if there was an error.


> 4. Regarding the returned result of evaluation.
> - What is the correct way to obtain a const char* string representing the result 
> as would be "printed" in the R shell by executing a command (for instance 
> "summary(c(1,2,3))") ?

See ?capture.output


> - Why is the return type (as reported from typeof in R and TYPEOF in C) of 
> "summary(c(1,2,3))" a double?
> 

Because the constants 1, 2 and 3 are all doubles. For example 1L is an integer and "1" is a string.

BTW: you are asking a lot of questions the are answered in the Rserve FAQ (since what you do is exactly what Rserve provides) so you may want to have a quick look:
http://rforge.net/Rserve/faq.html

Cheers,
Simon



> Any help / feedback on these issues would be greatly appreciated.
> 
> Thanks again.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From simon.urbanek at r-project.org  Fri Nov 11 16:14:51 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 11 Nov 2011 10:14:51 -0500
Subject: [Rd] Question on parsing R code from C
In-Reply-To: <84A85DE6-2914-4C8D-834A-07DE5820B5AD@r-project.org>
References: <loom.20111108T203022-872@post.gmane.org>
	<9465BE63-EA88-4BE2-8D1C-9E33BE8AA45D@r-project.org>
	<loom.20111108T224700-655@post.gmane.org>
	<3D4F776D-4D5D-4C39-90B3-12DF09C5C6BA@r-project.org>
	<loom.20111109T001139-68@post.gmane.org>
	<AF0744B1-C119-4BF1-99D0-9DBA31E734F9@r-project.org>
	<loom.20111111T000844-348@post.gmane.org>
	<84A85DE6-2914-4C8D-834A-07DE5820B5AD@r-project.org>
Message-ID: <7A934540-5829-425C-AA9B-ABE760F38B58@r-project.org>


On Nov 11, 2011, at 10:08 AM, Simon Urbanek wrote:

> 
> On Nov 10, 2011, at 6:24 PM, KR wrote:
> 
>> First of all thanks a lot to you both for all the replies, they have been of 
>> great help to me!
>> 
>> I got the basic embedding running, however I still have some issues to solve in 
>> order to complete the interface to R I am working on:
>> 
>> 1. I initialize with Rf_initEmbeddR().
>> - Is there a way to have more than one R "state" (per single thread)? Or is 
>> everything necessarily global?
> 
> There are no threads in R. You have only one, global instance of R.
> 
> 
>> - I also read somewhere that the fpu settings may be touched. Is there a way to 
>> make sure that this is not the case? Is this related to fpu_setup()?
>> 
> 
> All following answers assume that you're not running REPL. If you did, you would get all the errors on the console callback, so I'm assuming that's not what you want.
> 
> 
>> 2. I create a string and parse it via Rf_mkString() and R_parseVector() (yes I 
>> protect/un-protect the SEXPs).
>> - Is it possible to obtain the precise error message, like "unexpected symbol 
>> in..." (as would be reported by R.exe) in case of error as a const char* string?
> 
> AFAIR you have to evaluate parse(text=...) for that, there is no C-level access to parser errors.
> 
> 
>> - If I pass a wrongly escaped string (for instance 'ggsave("C:\gtest.png")', 
>> please notice the missing \) I get on stderr: Error '\g' is an unrecognized 
>> escape and I get a crash. This does not happen if for instance i try to parse 
>> 'rnorm(10a10)' in which case I get the error flag and the NULL ptr return. I 
>> suspect I need to initialize something / set a callback to avoid this but I am 
>> not sure...
>> 
> 
> If you get a crash, you're not setting up you R correctly. If your R quits then you are in non-interactive mode and you didn't setup an error handler.
> 
> 
>> 3. I eval with R_tryEvalSilent().
>> - Again, is it possible to obtain the precise error message in case of 
>> evaluation error as would be reported from R.exe?
>> 
> 

For completeness: geterrmessage() R function returns the last error message 


> I prefer using Rf_eval() and try(..., silent=TRUE) - you can check on the class of the result to see if there was an error.
> 
> 
>> 4. Regarding the returned result of evaluation.
>> - What is the correct way to obtain a const char* string representing the result 
>> as would be "printed" in the R shell by executing a command (for instance 
>> "summary(c(1,2,3))") ?
> 
> See ?capture.output
> 
> 
>> - Why is the return type (as reported from typeof in R and TYPEOF in C) of 
>> "summary(c(1,2,3))" a double?
>> 
> 
> Because the constants 1, 2 and 3 are all doubles. For example 1L is an integer and "1" is a string.
> 
> BTW: you are asking a lot of questions the are answered in the Rserve FAQ (since what you do is exactly what Rserve provides) so you may want to have a quick look:
> http://rforge.net/Rserve/faq.html
> 
> Cheers,
> Simon
> 
> 
> 
>> Any help / feedback on these issues would be greatly appreciated.
>> 
>> Thanks again.
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> 
> 


From pauljohn32 at gmail.com  Fri Nov 11 16:25:02 2011
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Fri, 11 Nov 2011 09:25:02 -0600
Subject: [Rd] One step way to create data frame with variable "variable
	names"?
Message-ID: <CAErODj9qO+8AruqRjdLTGcWaNgR8ptP3TUv-Y6hOv20r1eTtUg@mail.gmail.com>

Suppose

plotx <- "someName"
modx <- "otherName"
plotxRange <- c(10,20)
modxVals <- c(1,2,3)

It often happens I want to create a dataframe or object with plotx or
modx as the variable names.  But can't understand syntax to do that.

I can get this done in 2 steps, creating the data frame and then
assigning names, as in

newdf <- data.frame( c(1, 2, 3, 4), c(4, 4, 4, 4))
colnames(newdf) <- c(plotx, modx)

I was trying to hit this in one step, but can't find how.  If I could
get this in one step, it would simplify some book keeping, because
this current method requires me to build up the name vector to match
newdf, and sometimes I make mistakes.

After the data.frame already exists, I understand I can insert new
variables using the variable names with syntax like

newdf[[plotx]] <- c(23, 23, 23, 23)

PJ

-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas


From ggrothendieck at gmail.com  Fri Nov 11 16:31:50 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 11 Nov 2011 10:31:50 -0500
Subject: [Rd] One step way to create data frame with variable "variable
	names"?
In-Reply-To: <CAErODj9qO+8AruqRjdLTGcWaNgR8ptP3TUv-Y6hOv20r1eTtUg@mail.gmail.com>
References: <CAErODj9qO+8AruqRjdLTGcWaNgR8ptP3TUv-Y6hOv20r1eTtUg@mail.gmail.com>
Message-ID: <CAP01uRkBab+e3__pdP+F+e8d3TJPi84OD_UvdSWD7e7aEJFFDA@mail.gmail.com>

On Fri, Nov 11, 2011 at 10:25 AM, Paul Johnson <pauljohn32 at gmail.com> wrote:
> Suppose
>
> plotx <- "someName"
> modx <- "otherName"
> plotxRange <- c(10,20)
> modxVals <- c(1,2,3)
>
> It often happens I want to create a dataframe or object with plotx or
> modx as the variable names. ?But can't understand syntax to do that.
>
> I can get this done in 2 steps, creating the data frame and then
> assigning names, as in
>
> newdf <- data.frame( c(1, 2, 3, 4), c(4, 4, 4, 4))
> colnames(newdf) <- c(plotx, modx)
>
> I was trying to hit this in one step, but can't find how. ?If I could
> get this in one step, it would simplify some book keeping, because
> this current method requires me to build up the name vector to match
> newdf, and sometimes I make mistakes.
>
> After the data.frame already exists, I understand I can insert new
> variables using the variable names with syntax like
>
> newdf[[plotx]] <- c(23, 23, 23, 23)
>


Try this:

newdf <- setNames(data.frame( c(1, 2, 3, 4), c(4, 4, 4, 4)), c(plotx, modx))

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From wdunlap at tibco.com  Fri Nov 11 17:09:40 2011
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 11 Nov 2011 16:09:40 +0000
Subject: [Rd] One step way to create data frame with variable
	"variable	names"?
In-Reply-To: <CAErODj9qO+8AruqRjdLTGcWaNgR8ptP3TUv-Y6hOv20r1eTtUg@mail.gmail.com>
References: <CAErODj9qO+8AruqRjdLTGcWaNgR8ptP3TUv-Y6hOv20r1eTtUg@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B9323FB70@PA-MBX03.na.tibco.com>

> plotx <- "someName"
> modx <- "otherName"
> data.frame( structure(list(c(1, 2, 3, 4)), names=plotx), structure(list(c(4, 4, 4, 4)), names=modx))
  someName otherName
1        1         4
2        2         4
3        3         4
4        4         4

(I think this is more of an R-help question.)

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com 

> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of Paul Johnson
> Sent: Friday, November 11, 2011 7:25 AM
> To: R Devel List
> Subject: [Rd] One step way to create data frame with variable "variable names"?
> 
> Suppose
> 
> plotx <- "someName"
> modx <- "otherName"
> plotxRange <- c(10,20)
> modxVals <- c(1,2,3)
> 
> It often happens I want to create a dataframe or object with plotx or
> modx as the variable names.  But can't understand syntax to do that.
> 
> I can get this done in 2 steps, creating the data frame and then
> assigning names, as in
> 
> newdf <- data.frame( c(1, 2, 3, 4), c(4, 4, 4, 4))
> colnames(newdf) <- c(plotx, modx)
> 
> I was trying to hit this in one step, but can't find how.  If I could
> get this in one step, it would simplify some book keeping, because
> this current method requires me to build up the name vector to match
> newdf, and sometimes I make mistakes.
> 
> After the data.frame already exists, I understand I can insert new
> variables using the variable names with syntax like
> 
> newdf[[plotx]] <- c(23, 23, 23, 23)
> 
> PJ
> 
> --
> Paul E. Johnson
> Professor, Political Science
> 1541 Lilac Lane, Room 504
> University of Kansas
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From blewis at illposed.net  Sat Nov 12 01:12:53 2011
From: blewis at illposed.net (Bryan W. Lewis)
Date: Fri, 11 Nov 2011 19:12:53 -0500
Subject: [Rd] Use of Matrix within packages in R-2.14.0
Message-ID: <CAD3tZGjtsc2=DqghktnxGhX-L2EJk122Oph+xTFkUwWurd+D0Q@mail.gmail.com>

Dear R-devel readers:

  I am really stuck trying resolving an issue with the use of the
Matrix in one of my packages, irlba, with R-2.14.0. When I use
crossprod with at least one sparse argument in the packaged code I
receive the error:

Error in crossprod(x, y) :
  requires numeric/complex matrix/vector arguments

However, when I run the code outside of the context of the package it
works fine.

I have constructed the following trivial dummy package to replicate
the problem, the contents of which follow:

DESCRIPTION file:
Package: dummy
Type: Package
Title: Dummy package for testing
Version: 0.0.0
Date: 2011-10-15
Author: B. W. Lewis <blewis at illposed.net>
Maintainer: B. W. Lewis <blewis at illposed.net>
Description: A bogus test package
Depends: Matrix
License: GPL

NAMESPACE file:
export("test")

R/test.R file:
`test` <- function(A)
{
  x = crossprod(A)
  return(0)
}


To replicate the problem, create a package called "dummy" from the
above three files, install it, and run from R-2.14.0:

library("dummy")
A = Matrix(0,10,10)
test(A)

I have tested this with Ubuntu 10.10 GNU/Linux (64-bit), and 32-bit
Windows versions of R-2.14.0.

Any help in resolving this issue is greatly appreciated!

Thanks,

Bryan


From bates at stat.wisc.edu  Sat Nov 12 01:19:50 2011
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 11 Nov 2011 18:19:50 -0600
Subject: [Rd] Use of Matrix within packages in R-2.14.0
In-Reply-To: <CAD3tZGjtsc2=DqghktnxGhX-L2EJk122Oph+xTFkUwWurd+D0Q@mail.gmail.com>
References: <CAD3tZGjtsc2=DqghktnxGhX-L2EJk122Oph+xTFkUwWurd+D0Q@mail.gmail.com>
Message-ID: <CAO7JsnSPq8bXcqWUQVb0BzA8UX6A2=j3H9YupewGKxkHsK6SqA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111111/716e8cb2/attachment.pl>

From rtp at google.com  Sat Nov 12 01:55:38 2011
From: rtp at google.com (Tyler Pirtle)
Date: Fri, 11 Nov 2011 16:55:38 -0800
Subject: [Rd] Including multiple third party libraries in an extension
Message-ID: <CAH9pPRonO_4_SztaDm476xZoDg8wdFnNkKAUas1AZ83C_XJ5yg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111111/ce5ec048/attachment.pl>

From xuwang762 at gmail.com  Fri Nov 11 21:24:35 2011
From: xuwang762 at gmail.com (Xu Wang)
Date: Fri, 11 Nov 2011 12:24:35 -0800 (PST)
Subject: [Rd] use() might take a list of packages
In-Reply-To: <j9j85v$5hp$1@dough.gmane.org>
References: <1B5E1D00-397B-429B-B20C-0FBA060841A9@gmail.com>
	<j9j85v$5hp$1@dough.gmane.org>
Message-ID: <1321043075268-4032622.post@n4.nabble.com>

I agree that it would be nice if library took an argument that is a vector of
packages. I don't think one should need to use sapply here.

--
View this message in context: http://r.789695.n4.nabble.com/use-might-take-a-list-of-packages-tp4031097p4032622.html
Sent from the R devel mailing list archive at Nabble.com.


From simon.urbanek at r-project.org  Sat Nov 12 15:14:47 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 12 Nov 2011 09:14:47 -0500
Subject: [Rd] Including multiple third party libraries in an extension
In-Reply-To: <CAH9pPRonO_4_SztaDm476xZoDg8wdFnNkKAUas1AZ83C_XJ5yg@mail.gmail.com>
References: <CAH9pPRonO_4_SztaDm476xZoDg8wdFnNkKAUas1AZ83C_XJ5yg@mail.gmail.com>
Message-ID: <8F790125-88C4-42FA-9FB5-A60E924940B2@r-project.org>

Tyler,

On Nov 11, 2011, at 7:55 PM, Tyler Pirtle wrote:

> Hi,
> 
> I've got a C extension structured roughly like:
> 
> package/
>  src/
>    Makevars
>    foo.c
>    some-lib/...
>    some-other-lib/..
> 
> where foo.c and Makevars define dependencies on some-lib and
> some-other-lib. Currently I'm having
> Makevars configure;make install some-lib and some-other-lib into a local
> build directory, which produces
> shard libraries that ultimately I reference for foo.o in PKG_LIBS.
> 
> I'm concerned about distribution. I've setup the appropriate magic with
> rpath for the packages .so

That is certainly non-portable and won't work for a vast majority of users.


> (meaning
> that when the final .so is produced the dynamic libraries dependencies on
> some-lib and some-other-lib
> will prefer the location built in src/some-lib/... and
> src/some-other-lib/... But does this preclude me from
> being able to distribute a binary package?

Yes. And I doubt the package will work the way you described it at all, because the "deep" .so won't be even installed. Also there are potential issues in multi-arch R (please consider testing that as well).


> If I do want to build a binary
> distribution, is there a way I can
> package up everything needed, not just the resulting .so?
> 
> Or, are there better ways to bundle extension-specific third party
> dependencies? ;) I'd rather not have
> my users have to install obscure libraries globally on their systems.
> 

Typically the best solution is to compile the dependencies as --disable-shared --enable-static --with-pic (in autoconf speak - you don't need to actually use autoconf). That way your .so has all its dependencies inside and you avoid all run-time hassle. Note that it is very unlikely that you can take advantage of the dynamic nature of the dependencies (since no one else knows about them anyway) so there is not real point to build them dynamically.

Also note that typically you want to use the package-level configure to run subconfigures, and *not* Makevars. (There may be reasons for an exception to that convention, but you need to be aware of the differences in multi-arch builds since Makevars builds all architectures at once from separate copies of the src directories whereas the presence of configure allows you to treat your package as one architecture at a time and you can pass-though parameters).

Cheers,
Simon


From mcturra2000 at yahoo.co.uk  Sat Nov 12 15:25:23 2011
From: mcturra2000 at yahoo.co.uk (Mark Carter)
Date: Sat, 12 Nov 2011 14:25:23 +0000 (GMT)
Subject: [Rd] cygwin R-2.14.0 build fail
Message-ID: <1321107923.21160.YahooMailNeo@web27002.mail.ukl.yahoo.com>

I tried to build R-2.14.0 on cygwin using the commands:
./configure --with-x=no
make

I started to get a whole lot of errors starting with:
/cygdrive/c/Users/mcarter/src/R-2.14.0/src/modules/internet/Rhttpd.c:275: undefined reference to `_R_InputHandlers'
which I have pasted at 

http://pastebin.com/GFb2pq92

I'm aware that there is a cygwinports ports, but it seems outdated, and when I tried installing it, it was very lengthy and seemed more trouble that it was worth. I abandoned the installation attempt.


Any tips on a way forward?


From pdalgd at gmail.com  Sat Nov 12 21:28:46 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 12 Nov 2011 21:28:46 +0100
Subject: [Rd] cygwin R-2.14.0 build fail
In-Reply-To: <1321107923.21160.YahooMailNeo@web27002.mail.ukl.yahoo.com>
References: <1321107923.21160.YahooMailNeo@web27002.mail.ukl.yahoo.com>
Message-ID: <71B2E00F-BEFE-471E-B74B-8E0D7C164457@gmail.com>


On Nov 12, 2011, at 15:25 , Mark Carter wrote:

> I tried to build R-2.14.0 on cygwin using the commands:
> ./configure --with-x=no
> make
> 
> I started to get a whole lot of errors starting with:
> /cygdrive/c/Users/mcarter/src/R-2.14.0/src/modules/internet/Rhttpd.c:275: undefined reference to `_R_InputHandlers'
> which I have pasted at 
> 
> http://pastebin.com/GFb2pq92
> 
> I'm aware that there is a cygwinports ports, but it seems outdated, and when I tried installing it, it was very lengthy and seemed more trouble that it was worth. I abandoned the installation attempt.
> 
> 
> Any tips on a way forward?
> 

As far as I can tell, what is happening to you is that cygwin needs special configuration to build .dll libraries and ./configure does not know how to set that up.

R is not officially supported under Cygwin. Basically, we - er, Brian, mostly, I think - tried it several years ago, and it broke so many times that patience ran out. 

Others seem to be having better luck with recent versions (Google finds something that looks like ports of 2.13.2, so you might just need a little patience to get 2.14.0), but I think you're altogether better off over on

https://lists.sourceforge.net/lists/listinfo/cygwin-ports-general

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ligges at statistik.tu-dortmund.de  Sat Nov 12 21:51:54 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 12 Nov 2011 21:51:54 +0100
Subject: [Rd] cygwin R-2.14.0 build fail
In-Reply-To: <71B2E00F-BEFE-471E-B74B-8E0D7C164457@gmail.com>
References: <1321107923.21160.YahooMailNeo@web27002.mail.ukl.yahoo.com>
	<71B2E00F-BEFE-471E-B74B-8E0D7C164457@gmail.com>
Message-ID: <4EBEDC6A.5040008@statistik.tu-dortmund.de>



On 12.11.2011 21:28, peter dalgaard wrote:
>
> On Nov 12, 2011, at 15:25 , Mark Carter wrote:
>
>> I tried to build R-2.14.0 on cygwin using the commands:
>> ./configure --with-x=no
>> make
>>
>> I started to get a whole lot of errors starting with:
>> /cygdrive/c/Users/mcarter/src/R-2.14.0/src/modules/internet/Rhttpd.c:275: undefined reference to `_R_InputHandlers'
>> which I have pasted at
>>
>> http://pastebin.com/GFb2pq92
>>
>> I'm aware that there is a cygwinports ports, but it seems outdated, and when I tried installing it, it was very lengthy and seemed more trouble that it was worth. I abandoned the installation attempt.
>>
>>
>> Any tips on a way forward?
>>
>
> As far as I can tell, what is happening to you is that cygwin needs special configuration to build .dll libraries and ./configure does not know how to set that up.
>
> R is not officially supported under Cygwin. Basically, we - er, Brian, mostly, I think - tried it several years ago, and it broke so many times that patience ran out.
>
> Others seem to be having better luck with recent versions (Google finds something that looks like ports of 2.13.2, so you might just need a little patience to get 2.14.0), but I think you're altogether better off over on
>
> https://lists.sourceforge.net/lists/listinfo/cygwin-ports-general

Or much simpler: use the native version.

Uwe Ligges



>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From rtp at google.com  Sun Nov 13 05:08:06 2011
From: rtp at google.com (Tyler Pirtle)
Date: Sat, 12 Nov 2011 20:08:06 -0800
Subject: [Rd] Including multiple third party libraries in an extension
In-Reply-To: <8F790125-88C4-42FA-9FB5-A60E924940B2@r-project.org>
References: <CAH9pPRonO_4_SztaDm476xZoDg8wdFnNkKAUas1AZ83C_XJ5yg@mail.gmail.com>
	<8F790125-88C4-42FA-9FB5-A60E924940B2@r-project.org>
Message-ID: <CAH9pPRpz219J4bHC=p8FGY0JJEbmxau_j3N4Lp-kphWCGRgPbg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111112/a9570d5d/attachment.pl>

From rtp at google.com  Sun Nov 13 05:22:14 2011
From: rtp at google.com (Tyler Pirtle)
Date: Sat, 12 Nov 2011 20:22:14 -0800
Subject: [Rd] Including multiple third party libraries in an extension
In-Reply-To: <CAH9pPRpz219J4bHC=p8FGY0JJEbmxau_j3N4Lp-kphWCGRgPbg@mail.gmail.com>
References: <CAH9pPRonO_4_SztaDm476xZoDg8wdFnNkKAUas1AZ83C_XJ5yg@mail.gmail.com>
	<8F790125-88C4-42FA-9FB5-A60E924940B2@r-project.org>
	<CAH9pPRpz219J4bHC=p8FGY0JJEbmxau_j3N4Lp-kphWCGRgPbg@mail.gmail.com>
Message-ID: <CAH9pPRo=GxwjbcuiPT6PLoP97bJq9y3N+fRTN2R+61sbvwb2kA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111112/863eff04/attachment.pl>

From ripley at stats.ox.ac.uk  Sun Nov 13 08:37:59 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 13 Nov 2011 07:37:59 +0000 (GMT)
Subject: [Rd] cygwin R-2.14.0 build fail
In-Reply-To: <71B2E00F-BEFE-471E-B74B-8E0D7C164457@gmail.com>
References: <1321107923.21160.YahooMailNeo@web27002.mail.ukl.yahoo.com>
	<71B2E00F-BEFE-471E-B74B-8E0D7C164457@gmail.com>
Message-ID: <alpine.LFD.2.02.1111130731300.4099@gannet.stats.ox.ac.uk>

On Sat, 12 Nov 2011, peter dalgaard wrote:

>
> On Nov 12, 2011, at 15:25 , Mark Carter wrote:
>
>> I tried to build R-2.14.0 on cygwin using the commands:
>> ./configure --with-x=no
>> make
>>
>> I started to get a whole lot of errors starting with:
>> /cygdrive/c/Users/mcarter/src/R-2.14.0/src/modules/internet/Rhttpd.c:275: undefined reference to `_R_InputHandlers'
>> which I have pasted at
>>
>> http://pastebin.com/GFb2pq92
>>
>> I'm aware that there is a cygwinports ports, but it seems outdated, and when I tried installing it, it was very lengthy and seemed more trouble that it was worth. I abandoned the installation attempt.
>>
>>
>> Any tips on a way forward?
>>
>
> As far as I can tell, what is happening to you is that cygwin needs 
> special configuration to build .dll libraries and ./configure does 
> not know how to set that up.

It does.  Currently R can be built under Cygwin, and how to do so is 
documented in the R-admin manual.  But that was not the case a few 
weeks ago, so you need to look in R-patched/R-devel (and Cygwin might 
change again ...).

> R is not officially supported under Cygwin. Basically, we - er, 
> Brian, mostly, I think - tried it several years ago, and it broke so 
> many times that patience ran out.

It was broken from most of 2011 too, for three separate reasons.

Even when it 'works', it is far slower than the native Windows port 
and it fails 'make check' (not handling CR-delimited files, problems 
with wide-characters as Cygwin does not have proper locales).

> Others seem to be having better luck with recent versions (Google 
> finds something that looks like ports of 2.13.2, so you might just 
> need a little patience to get 2.14.0), but I think you're altogether 
> better off over on
>
> https://lists.sourceforge.net/lists/listinfo/cygwin-ports-general
>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From simon.urbanek at r-project.org  Sun Nov 13 15:47:52 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sun, 13 Nov 2011 09:47:52 -0500
Subject: [Rd] Including multiple third party libraries in an extension
In-Reply-To: <CAH9pPRpz219J4bHC=p8FGY0JJEbmxau_j3N4Lp-kphWCGRgPbg@mail.gmail.com>
References: <CAH9pPRonO_4_SztaDm476xZoDg8wdFnNkKAUas1AZ83C_XJ5yg@mail.gmail.com>
	<8F790125-88C4-42FA-9FB5-A60E924940B2@r-project.org>
	<CAH9pPRpz219J4bHC=p8FGY0JJEbmxau_j3N4Lp-kphWCGRgPbg@mail.gmail.com>
Message-ID: <15B2C9B1-C2DB-440C-85B7-2DBEF2146519@r-project.org>

Tyler,

On Nov 12, 2011, at 11:08 PM, Tyler Pirtle wrote:

> Thanks Simon, a few replies...
> 
> On Sat, Nov 12, 2011 at 6:14 AM, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> Tyler,
> 
> On Nov 11, 2011, at 7:55 PM, Tyler Pirtle wrote:
> 
> > Hi,
> >
> > I've got a C extension structured roughly like:
> >
> > package/
> >  src/
> >    Makevars
> >    foo.c
> >    some-lib/...
> >    some-other-lib/..
> >
> > where foo.c and Makevars define dependencies on some-lib and
> > some-other-lib. Currently I'm having
> > Makevars configure;make install some-lib and some-other-lib into a local
> > build directory, which produces
> > shard libraries that ultimately I reference for foo.o in PKG_LIBS.
> >
> > I'm concerned about distribution. I've setup the appropriate magic with
> > rpath for the packages .so
> 
> That is certainly non-portable and won't work for a vast majority of users.
> 
> Yea I figured, but apparently I have other, more pressing problems.. ;)
> 

Lucky you ;)


>  > (meaning
> > that when the final .so is produced the dynamic libraries dependencies on
> > some-lib and some-other-lib
> > will prefer the location built in src/some-lib/... and
> > src/some-other-lib/... But does this preclude me from
> > being able to distribute a binary package?
> 
> Yes. And I doubt the package will work the way you described it at all, because the "deep" .so won't be even installed. Also there are potential issues in multi-arch R (please consider testing that as well).
> 
> 
> Understood. I wasn't a fan of any of the potential solutions I'd seen (one of wich included source-only availability).
> I've seen some other folks using the inst/ or data/ dirs for purposes like this, but I agree it's ugly and has
> issues. You raise a great point, too, about multi-arch R. I have potential users that are definitely on
> heterogeneous architectures, I noticed that when I R CMD INSTALL --build . to check my current build,
> I end up with a src-${ARCH} for both x86_64 and i386 - is there more explicit multiarch testing I should be
> doing? 
>  

No, that's fine - as long so you check with some multi-arch R (which you apparently did, so I'm happy :)).


> 
> > If I do want to build a binary
> > distribution, is there a way I can
> > package up everything needed, not just the resulting .so?
> >
> > Or, are there better ways to bundle extension-specific third party
> > dependencies? ;) I'd rather not have
> > my users have to install obscure libraries globally on their systems.
> >
> 
> Typically the best solution is to compile the dependencies as --disable-shared --enable-static --with-pic (in autoconf speak - you don't need to actually use autoconf). That way your .so has all its dependencies inside and you avoid all run-time hassle. Note that it is very unlikely that you can take advantage of the dynamic nature of the dependencies (since no one else knows about them anyway) so there is not real point to build them dynamically.
> 
> 
> That is a much better solution and the one I've been looking for! I was afraid I'd have to manually specific all the dependency objects but if I just disable
> shared than that makes much more sense, I can let the compiler and linker do the work for me.
>  
> Also note that typically you want to use the package-level configure to run subconfigures, and *not* Makevars. (There may be reasons for an exception to that convention, but you need to be aware of the differences in multi-arch builds since Makevars builds all architectures at once from separate copies of the src directories whereas the presence of configure allows you to treat your package as one architecture at a time and you can pass-though parameters).
> 
> 
> Understood. Is src/ still the appropriate directory then for my third party packages?

Yes, in fact src is the only place that is safe.


> Also, do you happen to know of any packages off-hand that I can use
> as a reference? 
> 

Not on top of my head ... I may dig out something tomorrow ...


> Thanks Simon! Your insights here are invaluable. I really appreciate it.
> 

Sure, you're welcome.

Cheers,
Simon


> 
> 
> Tyler
> 
> 
>  
> Cheers,
> Simon
> 
> 
> 


From ligges at statistik.tu-dortmund.de  Sun Nov 13 16:27:00 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 13 Nov 2011 16:27:00 +0100
Subject: [Rd] Including multiple third party libraries in an extension
In-Reply-To: <CAH9pPRo=GxwjbcuiPT6PLoP97bJq9y3N+fRTN2R+61sbvwb2kA@mail.gmail.com>
References: <CAH9pPRonO_4_SztaDm476xZoDg8wdFnNkKAUas1AZ83C_XJ5yg@mail.gmail.com>
	<8F790125-88C4-42FA-9FB5-A60E924940B2@r-project.org>
	<CAH9pPRpz219J4bHC=p8FGY0JJEbmxau_j3N4Lp-kphWCGRgPbg@mail.gmail.com>
	<CAH9pPRo=GxwjbcuiPT6PLoP97bJq9y3N+fRTN2R+61sbvwb2kA@mail.gmail.com>
Message-ID: <4EBFE1C4.9090407@statistik.tu-dortmund.de>



On 13.11.2011 05:22, Tyler Pirtle wrote:
> On Sat, Nov 12, 2011 at 8:08 PM, Tyler Pirtle<rtp at google.com>  wrote:
>
>> Thanks Simon, a few replies...
>>
>> On Sat, Nov 12, 2011 at 6:14 AM, Simon Urbanek<
>> simon.urbanek at r-project.org>  wrote:
>>
>>> Tyler,
>>>
>>> On Nov 11, 2011, at 7:55 PM, Tyler Pirtle wrote:
>>>
>>>> Hi,
>>>>
>>>> I've got a C extension structured roughly like:
>>>>
>>>> package/
>>>>   src/
>>>>     Makevars
>>>>     foo.c
>>>>     some-lib/...
>>>>     some-other-lib/..
>>>>
>>>> where foo.c and Makevars define dependencies on some-lib and
>>>> some-other-lib. Currently I'm having
>>>> Makevars configure;make install some-lib and some-other-lib into a local
>>>> build directory, which produces
>>>> shard libraries that ultimately I reference for foo.o in PKG_LIBS.
>>>>
>>>> I'm concerned about distribution. I've setup the appropriate magic with
>>>> rpath for the packages .so
>>>
>>> That is certainly non-portable and won't work for a vast majority of
>>> users.
>>
>>
>> Yea I figured, but apparently I have other, more pressing problems.. ;)
>>
>>
>>
>>>> (meaning
>>>> that when the final .so is produced the dynamic libraries dependencies
>>> on
>>>> some-lib and some-other-lib
>>>> will prefer the location built in src/some-lib/... and
>>>> src/some-other-lib/... But does this preclude me from
>>>> being able to distribute a binary package?
>>>
>>> Yes. And I doubt the package will work the way you described it at all,
>>> because the "deep" .so won't be even installed. Also there are potential
>>> issues in multi-arch R (please consider testing that as well).
>>>
>>>
>> Understood. I wasn't a fan of any of the potential solutions I'd seen (one
>> of wich included source-only availability).
>> I've seen some other folks using the inst/ or data/ dirs for purposes like
>> this, but I agree it's ugly and has
>> issues. You raise a great point, too, about multi-arch R. I have potential
>> users that are definitely on
>> heterogeneous architectures, I noticed that when I R CMD INSTALL --build .
>> to check my current build,
>> I end up with a src-${ARCH} for both x86_64 and i386 - is there more
>> explicit multiarch testing I should be
>> doing?
>>
>>
>>>
>>>> If I do want to build a binary
>>>> distribution, is there a way I can
>>>> package up everything needed, not just the resulting .so?
>>>>
>>>> Or, are there better ways to bundle extension-specific third party
>>>> dependencies? ;) I'd rather not have
>>>> my users have to install obscure libraries globally on their systems.
>>>>
>>>
>>> Typically the best solution is to compile the dependencies as
>>> --disable-shared --enable-static --with-pic (in autoconf speak - you don't
>>> need to actually use autoconf). That way your .so has all its dependencies
>>> inside and you avoid all run-time hassle. Note that it is very unlikely
>>> that you can take advantage of the dynamic nature of the dependencies
>>> (since no one else knows about them anyway) so there is not real point to
>>> build them dynamically.
>>>
>>>
>> That is a much better solution and the one I've been looking for! I was
>> afraid I'd have to manually specific all the dependency objects but if I
>> just disable
>> shared than that makes much more sense, I can let the compiler and linker
>> do the work for me.
>>
>>
>>> Also note that typically you want to use the package-level configure to
>>> run subconfigures, and *not* Makevars. (There may be reasons for an
>>> exception to that convention, but you need to be aware of the differences
>>> in multi-arch builds since Makevars builds all architectures at once from
>>> separate copies of the src directories whereas the presence of configure
>>> allows you to treat your package as one architecture at a time and you can
>>> pass-though parameters).
>>>
>>>
>> Understood. Is src/ still the appropriate directory then for my third
>> party packages? Also, do you happen to know of any packages off-hand that I
>> can use
>> as a reference?
>>
>> Thanks Simon! Your insights here are invaluable. I really appreciate it.
>>
>>
>>
>> Tyler
>>
>>
>
> Ah, also a few more questions...
>
> I don't really understand the flow for developing multi-arch extensions.
> Does configure run only once?

Depends on the platform. For example: If you are on Windows and have a 
configure.win, you can tell R to run it for each architecture: See the R 
Installation and Administration manual  and also

R CMD INSTALL --help which has, e.g., under Windows:

   --force-biarch    attempt to build both architectures
                     even if there is a non-empty configure.win


> Once per arch? What is the state of
> src-${ARCH} by the time the src/Makevars or Makefile is executed? Is any of
> this actually in the manual and am I just missing it? ;)

The Makevars/-file is executed for each architecture.

>
> And why does R_ARCH start with a '/'? ;)

It is typically used as part of a path's name.

Uwe Ligges



>
> thanks again!
>
>
> Tyler
>
>
>
>>
>>
>>
>>> Cheers,
>>> Simon
>>>
>>>
>>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From rtp at google.com  Mon Nov 14 00:48:39 2011
From: rtp at google.com (Tyler Pirtle)
Date: Sun, 13 Nov 2011 15:48:39 -0800
Subject: [Rd] Including multiple third party libraries in an extension
In-Reply-To: <4EBFE1C4.9090407@statistik.tu-dortmund.de>
References: <CAH9pPRonO_4_SztaDm476xZoDg8wdFnNkKAUas1AZ83C_XJ5yg@mail.gmail.com>
	<8F790125-88C4-42FA-9FB5-A60E924940B2@r-project.org>
	<CAH9pPRpz219J4bHC=p8FGY0JJEbmxau_j3N4Lp-kphWCGRgPbg@mail.gmail.com>
	<CAH9pPRo=GxwjbcuiPT6PLoP97bJq9y3N+fRTN2R+61sbvwb2kA@mail.gmail.com>
	<4EBFE1C4.9090407@statistik.tu-dortmund.de>
Message-ID: <CAH9pPRr9GoXx9pxsjTmg_T5eBK841+5bF7Lvddjb0Fb6hUZ+pQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111113/8053cb91/attachment.pl>

From simon.urbanek at r-project.org  Mon Nov 14 03:25:38 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sun, 13 Nov 2011 21:25:38 -0500
Subject: [Rd] Including multiple third party libraries in an extension
In-Reply-To: <CAH9pPRr9GoXx9pxsjTmg_T5eBK841+5bF7Lvddjb0Fb6hUZ+pQ@mail.gmail.com>
References: <CAH9pPRonO_4_SztaDm476xZoDg8wdFnNkKAUas1AZ83C_XJ5yg@mail.gmail.com>
	<8F790125-88C4-42FA-9FB5-A60E924940B2@r-project.org>
	<CAH9pPRpz219J4bHC=p8FGY0JJEbmxau_j3N4Lp-kphWCGRgPbg@mail.gmail.com>
	<CAH9pPRo=GxwjbcuiPT6PLoP97bJq9y3N+fRTN2R+61sbvwb2kA@mail.gmail.com>
	<4EBFE1C4.9090407@statistik.tu-dortmund.de>
	<CAH9pPRr9GoXx9pxsjTmg_T5eBK841+5bF7Lvddjb0Fb6hUZ+pQ@mail.gmail.com>
Message-ID: <3E4D572D-011C-4B52-9797-B0E19D891178@r-project.org>


On Nov 13, 2011, at 6:48 PM, Tyler Pirtle wrote:

> 
> 
> On Sun, Nov 13, 2011 at 7:27 AM, Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:
> 
> 
> On 13.11.2011 05:22, Tyler Pirtle wrote:
> On Sat, Nov 12, 2011 at 8:08 PM, Tyler Pirtle<rtp at google.com>  wrote:
> 
> Thanks Simon, a few replies...
> 
> On Sat, Nov 12, 2011 at 6:14 AM, Simon Urbanek<
> simon.urbanek at r-project.org>  wrote:
> 
> Tyler,
> 
> On Nov 11, 2011, at 7:55 PM, Tyler Pirtle wrote:
> 
> Hi,
> 
> I've got a C extension structured roughly like:
> 
> package/
>  src/
>    Makevars
>    foo.c
>    some-lib/...
>    some-other-lib/..
> 
> where foo.c and Makevars define dependencies on some-lib and
> some-other-lib. Currently I'm having
> Makevars configure;make install some-lib and some-other-lib into a local
> build directory, which produces
> shard libraries that ultimately I reference for foo.o in PKG_LIBS.
> 
> I'm concerned about distribution. I've setup the appropriate magic with
> rpath for the packages .so
> 
> That is certainly non-portable and won't work for a vast majority of
> users.
> 
> 
> Yea I figured, but apparently I have other, more pressing problems.. ;)
> 
> 
> 
> (meaning
> that when the final .so is produced the dynamic libraries dependencies
> on
> some-lib and some-other-lib
> will prefer the location built in src/some-lib/... and
> src/some-other-lib/... But does this preclude me from
> being able to distribute a binary package?
> 
> Yes. And I doubt the package will work the way you described it at all,
> because the "deep" .so won't be even installed. Also there are potential
> issues in multi-arch R (please consider testing that as well).
> 
> 
> Understood. I wasn't a fan of any of the potential solutions I'd seen (one
> of wich included source-only availability).
> I've seen some other folks using the inst/ or data/ dirs for purposes like
> this, but I agree it's ugly and has
> issues. You raise a great point, too, about multi-arch R. I have potential
> users that are definitely on
> heterogeneous architectures, I noticed that when I R CMD INSTALL --build .
> to check my current build,
> I end up with a src-${ARCH} for both x86_64 and i386 - is there more
> explicit multiarch testing I should be
> doing?
> 
> 
> 
> If I do want to build a binary
> distribution, is there a way I can
> package up everything needed, not just the resulting .so?
> 
> Or, are there better ways to bundle extension-specific third party
> dependencies? ;) I'd rather not have
> my users have to install obscure libraries globally on their systems.
> 
> 
> Typically the best solution is to compile the dependencies as
> --disable-shared --enable-static --with-pic (in autoconf speak - you don't
> need to actually use autoconf). That way your .so has all its dependencies
> inside and you avoid all run-time hassle. Note that it is very unlikely
> that you can take advantage of the dynamic nature of the dependencies
> (since no one else knows about them anyway) so there is not real point to
> build them dynamically.
> 
> 
> That is a much better solution and the one I've been looking for! I was
> afraid I'd have to manually specific all the dependency objects but if I
> just disable
> shared than that makes much more sense, I can let the compiler and linker
> do the work for me.
> 
> 
> Also note that typically you want to use the package-level configure to
> run subconfigures, and *not* Makevars. (There may be reasons for an
> exception to that convention, but you need to be aware of the differences
> in multi-arch builds since Makevars builds all architectures at once from
> separate copies of the src directories whereas the presence of configure
> allows you to treat your package as one architecture at a time and you can
> pass-though parameters).
> 
> 
> Understood. Is src/ still the appropriate directory then for my third
> party packages? Also, do you happen to know of any packages off-hand that I
> can use
> as a reference?
> 
> Thanks Simon! Your insights here are invaluable. I really appreciate it.
> 
> 
> 
> Tyler
> 
> 
> 
> Ah, also a few more questions...
> 
> I don't really understand the flow for developing multi-arch extensions.
> Does configure run only once?
> 
> Depends on the platform. For example: If you are on Windows and have a configure.win, you can tell R to run it for each architecture: See the R Installation and Administration manual  and also
> 
> R CMD INSTALL --help which has, e.g., under Windows:
> 
>  --force-biarch    attempt to build both architectures
>                    even if there is a non-empty configure.win
> 
> 
> 
> Once per arch? What is the state of
> src-${ARCH} by the time the src/Makevars or Makefile is executed? Is any of
> this actually in the manual and am I just missing it? ;)
> 
> The Makevars/-file is executed for each architecture.
> 
> 
> 
> And why does R_ARCH start with a '/'? ;)
> 
> It is typically used as part of a path's name.
> 
> Uwe Ligges
> 
> 
> Thanks Uwe, very helpful stuff. I have the problem that I can't configure all my
> third party packages at once since they're inter-dependent, so I have to deal with
> R_ARCH in my Makefile.
> 

You should not need to since it's irrelevant for you as a package author, it is used internally by R. (Also note that Makevars are preferred to Makefile since it is much more fragile to re-create the R build process in the latter and thus the latter is only used in very special circumstances)


> I'm afraid I don't understand at all how portability is managed with respect to packages. I mean,
> I'm not sure how multi-arch and CRAN all sort of fit together to make my package ultimately
> available via binary distribution to users an all sorts of platforms. How does all this work?
> 

As long as your code is portable and you use R's facilities (instead of creating your own), it's all automatic. Packages are built on each platform separately and then distributed on CRAN. To answer your previous question: for multi-arch platforms (on CRAN that is Windows and Mac OS X) the package is built separately for each architecture if your package contains configure or Makefile. Otherwise it is built in one go (see R-admin 6.3.4).


> Say I can test and am willing to support certain architectures and certain OS distributions,
> say Mac OS X, Linux, Windows, etc. and I can verify that my package builds in those
> environments (under some minimal set of conditions). What is CRAN's purpose then?
> 
> Am I meant to submit a binary build for each arch/OS as separate packages? 
> 

You're not supposed to supply any binaries. CRAN builds them from the sources you provide.

Cheers,
Simon


> My apologies for these questions, I'm quite new to this community, and all of your
> help has been amazing, I really do appreciate it. Please point me at any relevant
> documentation as well, I'm happy to go read. 
> 
> Hopefully I can contribute something back in a timely fashion here that will be 
> helpful to a wider audience ;)
> 
> 
> Thanks,
> 
> 
> Tyler
> 
> 
> 
> 
> thanks again!
> 
> 
> Tyler
> 
> 
> 
> 
> 
> 
> Cheers,
> Simon
> 
> 
> 
> 
> 
>        [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From rtp at google.com  Mon Nov 14 03:55:19 2011
From: rtp at google.com (Tyler Pirtle)
Date: Sun, 13 Nov 2011 18:55:19 -0800
Subject: [Rd] Including multiple third party libraries in an extension
In-Reply-To: <3E4D572D-011C-4B52-9797-B0E19D891178@r-project.org>
References: <CAH9pPRonO_4_SztaDm476xZoDg8wdFnNkKAUas1AZ83C_XJ5yg@mail.gmail.com>
	<8F790125-88C4-42FA-9FB5-A60E924940B2@r-project.org>
	<CAH9pPRpz219J4bHC=p8FGY0JJEbmxau_j3N4Lp-kphWCGRgPbg@mail.gmail.com>
	<CAH9pPRo=GxwjbcuiPT6PLoP97bJq9y3N+fRTN2R+61sbvwb2kA@mail.gmail.com>
	<4EBFE1C4.9090407@statistik.tu-dortmund.de>
	<CAH9pPRr9GoXx9pxsjTmg_T5eBK841+5bF7Lvddjb0Fb6hUZ+pQ@mail.gmail.com>
	<3E4D572D-011C-4B52-9797-B0E19D891178@r-project.org>
Message-ID: <CAH9pPRoZQwRvkw1YvnTjNLKcvpKA43OteZ2x-_LMM+fshWti6g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111113/7b6ea463/attachment.pl>

From ligges at statistik.tu-dortmund.de  Mon Nov 14 09:40:37 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 14 Nov 2011 09:40:37 +0100
Subject: [Rd] Including multiple third party libraries in an extension
In-Reply-To: <CAH9pPRoZQwRvkw1YvnTjNLKcvpKA43OteZ2x-_LMM+fshWti6g@mail.gmail.com>
References: <CAH9pPRonO_4_SztaDm476xZoDg8wdFnNkKAUas1AZ83C_XJ5yg@mail.gmail.com>
	<8F790125-88C4-42FA-9FB5-A60E924940B2@r-project.org>
	<CAH9pPRpz219J4bHC=p8FGY0JJEbmxau_j3N4Lp-kphWCGRgPbg@mail.gmail.com>
	<CAH9pPRo=GxwjbcuiPT6PLoP97bJq9y3N+fRTN2R+61sbvwb2kA@mail.gmail.com>
	<4EBFE1C4.9090407@statistik.tu-dortmund.de>
	<CAH9pPRr9GoXx9pxsjTmg_T5eBK841+5bF7Lvddjb0Fb6hUZ+pQ@mail.gmail.com>
	<3E4D572D-011C-4B52-9797-B0E19D891178@r-project.org>
	<CAH9pPRoZQwRvkw1YvnTjNLKcvpKA43OteZ2x-_LMM+fshWti6g@mail.gmail.com>
Message-ID: <4EC0D405.7050500@statistik.tu-dortmund.de>



On 14.11.2011 03:55, Tyler Pirtle wrote:
> On Sun, Nov 13, 2011 at 6:25 PM, Simon Urbanek
> <simon.urbanek at r-project.org>wrote:
>
>>
>> On Nov 13, 2011, at 6:48 PM, Tyler Pirtle wrote:
>>
>>>
>>>
>>> On Sun, Nov 13, 2011 at 7:27 AM, Uwe Ligges<
>> ligges at statistik.tu-dortmund.de>  wrote:
>>>
>>>
>>> On 13.11.2011 05:22, Tyler Pirtle wrote:
>>> On Sat, Nov 12, 2011 at 8:08 PM, Tyler Pirtle<rtp at google.com>   wrote:
>>>
>>> Thanks Simon, a few replies...
>>>
>>> On Sat, Nov 12, 2011 at 6:14 AM, Simon Urbanek<
>>> simon.urbanek at r-project.org>   wrote:
>>>
>>> Tyler,
>>>
>>> On Nov 11, 2011, at 7:55 PM, Tyler Pirtle wrote:
>>>
>>> Hi,
>>>
>>> I've got a C extension structured roughly like:
>>>
>>> package/
>>>   src/
>>>     Makevars
>>>     foo.c
>>>     some-lib/...
>>>     some-other-lib/..
>>>
>>> where foo.c and Makevars define dependencies on some-lib and
>>> some-other-lib. Currently I'm having
>>> Makevars configure;make install some-lib and some-other-lib into a local
>>> build directory, which produces
>>> shard libraries that ultimately I reference for foo.o in PKG_LIBS.
>>>
>>> I'm concerned about distribution. I've setup the appropriate magic with
>>> rpath for the packages .so
>>>
>>> That is certainly non-portable and won't work for a vast majority of
>>> users.
>>>
>>>
>>> Yea I figured, but apparently I have other, more pressing problems.. ;)
>>>
>>>
>>>
>>> (meaning
>>> that when the final .so is produced the dynamic libraries dependencies
>>> on
>>> some-lib and some-other-lib
>>> will prefer the location built in src/some-lib/... and
>>> src/some-other-lib/... But does this preclude me from
>>> being able to distribute a binary package?
>>>
>>> Yes. And I doubt the package will work the way you described it at all,
>>> because the "deep" .so won't be even installed. Also there are potential
>>> issues in multi-arch R (please consider testing that as well).
>>>
>>>
>>> Understood. I wasn't a fan of any of the potential solutions I'd seen
>> (one
>>> of wich included source-only availability).
>>> I've seen some other folks using the inst/ or data/ dirs for purposes
>> like
>>> this, but I agree it's ugly and has
>>> issues. You raise a great point, too, about multi-arch R. I have
>> potential
>>> users that are definitely on
>>> heterogeneous architectures, I noticed that when I R CMD INSTALL --build
>> .
>>> to check my current build,
>>> I end up with a src-${ARCH} for both x86_64 and i386 - is there more
>>> explicit multiarch testing I should be
>>> doing?
>>>
>>>
>>>
>>> If I do want to build a binary
>>> distribution, is there a way I can
>>> package up everything needed, not just the resulting .so?
>>>
>>> Or, are there better ways to bundle extension-specific third party
>>> dependencies? ;) I'd rather not have
>>> my users have to install obscure libraries globally on their systems.
>>>
>>>
>>> Typically the best solution is to compile the dependencies as
>>> --disable-shared --enable-static --with-pic (in autoconf speak - you
>> don't
>>> need to actually use autoconf). That way your .so has all its
>> dependencies
>>> inside and you avoid all run-time hassle. Note that it is very unlikely
>>> that you can take advantage of the dynamic nature of the dependencies
>>> (since no one else knows about them anyway) so there is not real point to
>>> build them dynamically.
>>>
>>>
>>> That is a much better solution and the one I've been looking for! I was
>>> afraid I'd have to manually specific all the dependency objects but if I
>>> just disable
>>> shared than that makes much more sense, I can let the compiler and linker
>>> do the work for me.
>>>
>>>
>>> Also note that typically you want to use the package-level configure to
>>> run subconfigures, and *not* Makevars. (There may be reasons for an
>>> exception to that convention, but you need to be aware of the differences
>>> in multi-arch builds since Makevars builds all architectures at once from
>>> separate copies of the src directories whereas the presence of configure
>>> allows you to treat your package as one architecture at a time and you
>> can
>>> pass-though parameters).
>>>
>>>
>>> Understood. Is src/ still the appropriate directory then for my third
>>> party packages? Also, do you happen to know of any packages off-hand
>> that I
>>> can use
>>> as a reference?
>>>
>>> Thanks Simon! Your insights here are invaluable. I really appreciate it.
>>>
>>>
>>>
>>> Tyler
>>>
>>>
>>>
>>> Ah, also a few more questions...
>>>
>>> I don't really understand the flow for developing multi-arch extensions.
>>> Does configure run only once?
>>>
>>> Depends on the platform. For example: If you are on Windows and have a
>> configure.win, you can tell R to run it for each architecture: See the R
>> Installation and Administration manual  and also
>>>
>>> R CMD INSTALL --help which has, e.g., under Windows:
>>>
>>>   --force-biarch    attempt to build both architectures
>>>                     even if there is a non-empty configure.win
>>>
>>>
>>>
>>> Once per arch? What is the state of
>>> src-${ARCH} by the time the src/Makevars or Makefile is executed? Is any
>> of
>>> this actually in the manual and am I just missing it? ;)
>>>
>>> The Makevars/-file is executed for each architecture.
>>>
>>>
>>>
>>> And why does R_ARCH start with a '/'? ;)
>>>
>>> It is typically used as part of a path's name.
>>>
>>> Uwe Ligges
>>>
>>>
>>> Thanks Uwe, very helpful stuff. I have the problem that I can't
>> configure all my
>>> third party packages at once since they're inter-dependent, so I have to
>> deal with
>>> R_ARCH in my Makefile.
>>>
>>
>> You should not need to since it's irrelevant for you as a package author,
>> it is used internally by R. (Also note that Makevars are preferred to
>> Makefile since it is much more fragile to re-create the R build process in
>> the latter and thus the latter is only used in very special circumstances)
>>
>>
> That explains a few details then, I thought I was ultimately responsible
> for producing binaries, but as you pointed out below
> thats not the case...
>   And I misspoke - I'm using a Makevars, I saw the warning elsewhere as
> well.
>
>
>>> I'm afraid I don't understand at all how portability is managed with
>> respect to packages. I mean,
>>> I'm not sure how multi-arch and CRAN all sort of fit together to make my
>> package ultimately
>>> available via binary distribution to users an all sorts of platforms.
>> How does all this work?
>>>
>>
>> As long as your code is portable and you use R's facilities (instead of
>> creating your own), it's all automatic. Packages are built on each platform
>> separately and then distributed on CRAN. To answer your previous question:
>> for multi-arch platforms (on CRAN that is Windows and Mac OS X) the package
>> is built separately for each architecture if your package contains
>> configure or Makefile. Otherwise it is built in one go (see R-admin 6.3.4).
>>
>>
> I guess thats the interesting question, is my code portable? Thats
> something else that I don't fully understand, why are all architectures
> built
> if configure or Makefile are missing?

Since then it is easy to do so and no 2 runs are required. With a 
configure the automagical processes cannot guess enough and need to to 
stuff separately.

> I guess I don't really understand the
> purpose of multiple sub-architectures (maybe, for example, if I were
> on windows and building both natively and with cygwin?

No. Natively 32-bit and natively 64-bit architectures. We do not provide 
any cygwin binaries (which is another platform anyway).

The difference is just in the compiled code. Hence the package is almost 
the same, it just ships with two libs subdirectories ./x64 and ./i386 
each containing the right dll(s) for the corresponding platform.


> Is that the
> purpose?). I'm not sure I get you when you say its "built in one go" - what
> is? My package? It seems to be building just my (guessed) arch as well.

In one go means:
- for packages without compiled code, it is really only one go, since 
everything should already be portable.
- for packages with compiled code, the libraries (e.g. dlls on Windows) 
are compiled separately but within the same installation procedure. The 
whole rest is only done once.

Best,
Uwe Ligges


>
>
>
>
>>> Say I can test and am willing to support certain architectures and
>> certain OS distributions,
>>> say Mac OS X, Linux, Windows, etc. and I can verify that my package
>> builds in those
>>> environments (under some minimal set of conditions). What is CRAN's
>> purpose then?
>>>
>>> Am I meant to submit a binary build for each arch/OS as separate
>> packages?
>>>
>>
>> You're not supposed to supply any binaries. CRAN builds them from the
>> sources you provide.
>>
>>
> Thanks for the clarification.
>
>
>
>
>> Cheers,
>> Simon
>>
>>
>>> My apologies for these questions, I'm quite new to this community, and
>> all of your
>>> help has been amazing, I really do appreciate it. Please point me at any
>> relevant
>>> documentation as well, I'm happy to go read.
>>>
>>> Hopefully I can contribute something back in a timely fashion here that
>> will be
>>> helpful to a wider audience ;)
>>>
>>>
>>> Thanks,
>>>
>>>
>>> Tyler
>>>
>>>
>>>
>>>
>>> thanks again!
>>>
>>>
>>> Tyler
>>>
>>>
>>>
>>>
>>>
>>>
>>> Cheers,
>>> Simon
>>>
>>>
>>>
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>
>


From simon.urbanek at r-project.org  Mon Nov 14 16:01:52 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 14 Nov 2011 10:01:52 -0500
Subject: [Rd] Including multiple third party libraries in an extension
In-Reply-To: <CAH9pPRoZQwRvkw1YvnTjNLKcvpKA43OteZ2x-_LMM+fshWti6g@mail.gmail.com>
References: <CAH9pPRonO_4_SztaDm476xZoDg8wdFnNkKAUas1AZ83C_XJ5yg@mail.gmail.com>
	<8F790125-88C4-42FA-9FB5-A60E924940B2@r-project.org>
	<CAH9pPRpz219J4bHC=p8FGY0JJEbmxau_j3N4Lp-kphWCGRgPbg@mail.gmail.com>
	<CAH9pPRo=GxwjbcuiPT6PLoP97bJq9y3N+fRTN2R+61sbvwb2kA@mail.gmail.com>
	<4EBFE1C4.9090407@statistik.tu-dortmund.de>
	<CAH9pPRr9GoXx9pxsjTmg_T5eBK841+5bF7Lvddjb0Fb6hUZ+pQ@mail.gmail.com>
	<3E4D572D-011C-4B52-9797-B0E19D891178@r-project.org>
	<CAH9pPRoZQwRvkw1YvnTjNLKcvpKA43OteZ2x-_LMM+fshWti6g@mail.gmail.com>
Message-ID: <48B7E470-A8E3-492D-ACF9-357993B6E6D0@r-project.org>


On Nov 13, 2011, at 9:55 PM, Tyler Pirtle wrote:

> 
> 
> On Sun, Nov 13, 2011 at 6:25 PM, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> 
> On Nov 13, 2011, at 6:48 PM, Tyler Pirtle wrote:
> 
> >
> >
> > On Sun, Nov 13, 2011 at 7:27 AM, Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:
> >
> >
> > On 13.11.2011 05:22, Tyler Pirtle wrote:
> > On Sat, Nov 12, 2011 at 8:08 PM, Tyler Pirtle<rtp at google.com>  wrote:
> >
> > Thanks Simon, a few replies...
> >
> > On Sat, Nov 12, 2011 at 6:14 AM, Simon Urbanek<
> > simon.urbanek at r-project.org>  wrote:
> >
> > Tyler,
> >
> > On Nov 11, 2011, at 7:55 PM, Tyler Pirtle wrote:
> >
> > Hi,
> >
> > I've got a C extension structured roughly like:
> >
> > package/
> >  src/
> >    Makevars
> >    foo.c
> >    some-lib/...
> >    some-other-lib/..
> >
> > where foo.c and Makevars define dependencies on some-lib and
> > some-other-lib. Currently I'm having
> > Makevars configure;make install some-lib and some-other-lib into a local
> > build directory, which produces
> > shard libraries that ultimately I reference for foo.o in PKG_LIBS.
> >
> > I'm concerned about distribution. I've setup the appropriate magic with
> > rpath for the packages .so
> >
> > That is certainly non-portable and won't work for a vast majority of
> > users.
> >
> >
> > Yea I figured, but apparently I have other, more pressing problems.. ;)
> >
> >
> >
> > (meaning
> > that when the final .so is produced the dynamic libraries dependencies
> > on
> > some-lib and some-other-lib
> > will prefer the location built in src/some-lib/... and
> > src/some-other-lib/... But does this preclude me from
> > being able to distribute a binary package?
> >
> > Yes. And I doubt the package will work the way you described it at all,
> > because the "deep" .so won't be even installed. Also there are potential
> > issues in multi-arch R (please consider testing that as well).
> >
> >
> > Understood. I wasn't a fan of any of the potential solutions I'd seen (one
> > of wich included source-only availability).
> > I've seen some other folks using the inst/ or data/ dirs for purposes like
> > this, but I agree it's ugly and has
> > issues. You raise a great point, too, about multi-arch R. I have potential
> > users that are definitely on
> > heterogeneous architectures, I noticed that when I R CMD INSTALL --build .
> > to check my current build,
> > I end up with a src-${ARCH} for both x86_64 and i386 - is there more
> > explicit multiarch testing I should be
> > doing?
> >
> >
> >
> > If I do want to build a binary
> > distribution, is there a way I can
> > package up everything needed, not just the resulting .so?
> >
> > Or, are there better ways to bundle extension-specific third party
> > dependencies? ;) I'd rather not have
> > my users have to install obscure libraries globally on their systems.
> >
> >
> > Typically the best solution is to compile the dependencies as
> > --disable-shared --enable-static --with-pic (in autoconf speak - you don't
> > need to actually use autoconf). That way your .so has all its dependencies
> > inside and you avoid all run-time hassle. Note that it is very unlikely
> > that you can take advantage of the dynamic nature of the dependencies
> > (since no one else knows about them anyway) so there is not real point to
> > build them dynamically.
> >
> >
> > That is a much better solution and the one I've been looking for! I was
> > afraid I'd have to manually specific all the dependency objects but if I
> > just disable
> > shared than that makes much more sense, I can let the compiler and linker
> > do the work for me.
> >
> >
> > Also note that typically you want to use the package-level configure to
> > run subconfigures, and *not* Makevars. (There may be reasons for an
> > exception to that convention, but you need to be aware of the differences
> > in multi-arch builds since Makevars builds all architectures at once from
> > separate copies of the src directories whereas the presence of configure
> > allows you to treat your package as one architecture at a time and you can
> > pass-though parameters).
> >
> >
> > Understood. Is src/ still the appropriate directory then for my third
> > party packages? Also, do you happen to know of any packages off-hand that I
> > can use
> > as a reference?
> >
> > Thanks Simon! Your insights here are invaluable. I really appreciate it.
> >
> >
> >
> > Tyler
> >
> >
> >
> > Ah, also a few more questions...
> >
> > I don't really understand the flow for developing multi-arch extensions.
> > Does configure run only once?
> >
> > Depends on the platform. For example: If you are on Windows and have a configure.win, you can tell R to run it for each architecture: See the R Installation and Administration manual  and also
> >
> > R CMD INSTALL --help which has, e.g., under Windows:
> >
> >  --force-biarch    attempt to build both architectures
> >                    even if there is a non-empty configure.win
> >
> >
> >
> > Once per arch? What is the state of
> > src-${ARCH} by the time the src/Makevars or Makefile is executed? Is any of
> > this actually in the manual and am I just missing it? ;)
> >
> > The Makevars/-file is executed for each architecture.
> >
> >
> >
> > And why does R_ARCH start with a '/'? ;)
> >
> > It is typically used as part of a path's name.
> >
> > Uwe Ligges
> >
> >
> > Thanks Uwe, very helpful stuff. I have the problem that I can't configure all my
> > third party packages at once since they're inter-dependent, so I have to deal with
> > R_ARCH in my Makefile.
> >
> 
> You should not need to since it's irrelevant for you as a package author, it is used internally by R. (Also note that Makevars are preferred to Makefile since it is much more fragile to re-create the R build process in the latter and thus the latter is only used in very special circumstances)
> 
> 
> That explains a few details then, I thought I was ultimately responsible for producing binaries, but as you pointed out below
> thats not the case...
>  And I misspoke - I'm using a Makevars, I saw the warning elsewhere as well. 
>  
> > I'm afraid I don't understand at all how portability is managed with respect to packages. I mean,
> > I'm not sure how multi-arch and CRAN all sort of fit together to make my package ultimately
> > available via binary distribution to users an all sorts of platforms. How does all this work?
> >
> 
> As long as your code is portable and you use R's facilities (instead of creating your own), it's all automatic. Packages are built on each platform separately and then distributed on CRAN. To answer your previous question: for multi-arch platforms (on CRAN that is Windows and Mac OS X) the package is built separately for each architecture if your package contains configure or Makefile. Otherwise it is built in one go (see R-admin 6.3.4).
> 
> 
> I guess thats the interesting question, is my code portable? Thats something else that I don't fully understand, why are all architectures built
> if configure or Makefile are missing? I guess I don't really understand the purpose of multiple sub-architectures (maybe, for example, if I were
> on windows and building both natively and with cygwin? Is that the purpose?).

No. Several OSes support multiple architectures, for example Mac OS X 10.5 supports PowerPC and Intel, each of them with 32-bit or 64-bit. That gives a total of 4 architectures: i386, x86_64, ppc and ppc64. Therefore R binary for that platform has to support multiple architectures so the way this is done is to keep only one set of non-binary files and several sets of binary files, each for one architecture. On Windows there are 32-bit and 64-bit binaries (i386 and x64) so there are two sets of binary files - 32-bit and for 64-bit. This allows common distribution without the mess of having multiple builds for each architecture.


> I'm not sure I get you when you say its "built in one go" - what is? My package? It seems to be building just my (guessed) arch as well.
> 

No, if you don't have configure and Makefile, R will build every architecture it supports, e.g.:

* installing *source* package 'fastmatch' ...
** package 'fastmatch' successfully unpacked and MD5 sums checked
** libs
*** arch - i386
gcc-4.2 -arch i386 -std=gnu99 -I/Library/Frameworks/R.framework/Resources/include -I/Library/Frameworks/R.framework/Resources/include/i386  -I/usr/local/include    -fPIC  -g -O2 -c fastmatch.c -o fastmatch.o
gcc-4.2 -arch i386 -std=gnu99 -dynamiclib -Wl,-headerpad_max_install_names -undefined dynamic_lookup -single_module -multiply_defined suppress -L/usr/local/lib -o fastmatch.so fastmatch.o -F/Library/Frameworks/R.framework/.. -framework R -Wl,-framework -Wl,CoreFoundation
installing to /private/tmp/rl/fastmatch/libs/i386
*** arch - ppc
gcc-4.2 -arch ppc -std=gnu99 -I/Library/Frameworks/R.framework/Resources/include -I/Library/Frameworks/R.framework/Resources/include/ppc  -I/usr/local/include    -fPIC  -g -O2 -c fastmatch.c -o fastmatch.o
gcc-4.2 -arch ppc -std=gnu99 -dynamiclib -Wl,-headerpad_max_install_names -undefined dynamic_lookup -single_module -multiply_defined suppress -L/usr/local/lib -o fastmatch.so fastmatch.o -F/Library/Frameworks/R.framework/.. -framework R -Wl,-framework -Wl,CoreFoundation
installing to /private/tmp/rl/fastmatch/libs/ppc
*** arch - x86_64
gcc-4.2 -arch x86_64 -std=gnu99 -I/Library/Frameworks/R.framework/Resources/include -I/Library/Frameworks/R.framework/Resources/include/x86_64  -I/usr/local/include    -fPIC  -g -O2 -c fastmatch.c -o fastmatch.o
gcc-4.2 -arch x86_64 -std=gnu99 -dynamiclib -Wl,-headerpad_max_install_names -undefined dynamic_lookup -single_module -multiply_defined suppress -L/usr/local/lib -o fastmatch.so fastmatch.o -F/Library/Frameworks/R.framework/.. -framework R -Wl,-framework -Wl,CoreFoundation
installing to /private/tmp/rl/fastmatch/libs/x86_64
** R
** preparing package for lazy loading
** help
*** installing help indices
** building package indices ...
** testing if installed package can be loaded

* DONE (fastmatch)


As you can see, it compiled and installed the binaries for all three architectures (Intel 32-bit, PowerPC 32-bin and Intel 64-bit -- we don't support ppc64 anymore). That is possible since R is taking care of all the building so it can do the right thing with me even having to specify what yo do.

Cheers,
Simon


>  
> > Say I can test and am willing to support certain architectures and certain OS distributions,
> > say Mac OS X, Linux, Windows, etc. and I can verify that my package builds in those
> > environments (under some minimal set of conditions). What is CRAN's purpose then?
> >
> > Am I meant to submit a binary build for each arch/OS as separate packages?
> >
> 
> You're not supposed to supply any binaries. CRAN builds them from the sources you provide.
> 
> 
> Thanks for the clarification.
> 
> 
>  
> Cheers,
> Simon
> 
> 
> > My apologies for these questions, I'm quite new to this community, and all of your
> > help has been amazing, I really do appreciate it. Please point me at any relevant
> > documentation as well, I'm happy to go read.
> >
> > Hopefully I can contribute something back in a timely fashion here that will be
> > helpful to a wider audience ;)
> >
> >
> > Thanks,
> >
> >
> > Tyler
> >
> >
> >
> >
> > thanks again!
> >
> >
> > Tyler
> >
> >
> >
> >
> >
> >
> > Cheers,
> > Simon
> >
> >
> >
> >
> >
> >        [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> 


From dhinds at sonic.net  Mon Nov 14 20:47:35 2011
From: dhinds at sonic.net (dhinds at sonic.net)
Date: Mon, 14 Nov 2011 19:47:35 +0000
Subject: [Rd] Moderating consequences of garbage collection when in C
References: <4E8BD4EB.60802@fhcrc.org> <j9fpvr$ad$1@dough.gmane.org>
Message-ID: <j9rr8m$kk5$1@dough.gmane.org>

dhinds at sonic.net wrote:
> Martin Morgan <mtmorgan at fhcrc.org> wrote:
> > Allocating many small objects triggers numerous garbage collections as R 
> > grows its memory, seriously degrading performance. The specific use case 
> > is in creating a STRSXP of several 1,000,000's of elements of 60-100 
> > characters each; a simplified illustration understating the effects 
> > (because there is initially little to garbage collect, in contrast to an 
> > R session with several packages loaded) is below.

> What a coincidence -- I was just going to post a question about why it
> is so slow to create a STRSXP of ~10,000,000 unique elements, each ~10
> characters long.  I had noticed that this seemed to show much worse
> than linear scaling.  I had not thought of garbage collection as the
> culprit -- but indeed it is.  By manipulating the GC trigger, I can
> make this operation take as little as 3 seconds (with no GC) or as
> long as 76 seconds (with 31 garbage collections).

I had done some google searches on this issue, since it seemed like it
should not be too uncommon, but the only other hit I could come up
with was a thread from 2006:

https://stat.ethz.ch/pipermail/r-devel/2006-November/043446.html

In any case, one issue with your suggested workaround is that it
requires knowing how much additional storage is needed, which may be
an expensive operation to determine.  I've just tried implementing a
different approach, which is to define two new functions to either
disable or enable GC.  The function to disable GC first invokes
R_gc_full() to shrink the heap as much as possible, then sets a flag.
Then in R_gc_internal(), I first check that flag, and if it is set, I
call AdjustHeapSize(size_needed) and exit immediately.

These calls could be used to bracket any code section that expects to
make lots of calls to R's memory allocator.  The down side is that
this approach requires that all paths out of such a code section
(including error handling) need to take care to unset the GC-disabled
flag.  I think I would want to hear from someone on the R team about
whether they think this is a good idea.

A final alternative might be to provide a vectorized version of mkChar
that would accept a char ** and use one of these methods internally,
rather than exporting the underlying methods as part of R's API.  I
don't know if there are other clear use cases where GC is a serious
bottleneck, besides constructing large vectors of mostly unique
strings.  Such a function would be less generally useful since it 
would require that the full vector of C strings be assembled at one
time.

-- Dave


From tlumley at uw.edu  Mon Nov 14 21:00:10 2011
From: tlumley at uw.edu (Thomas Lumley)
Date: Tue, 15 Nov 2011 09:00:10 +1300
Subject: [Rd] Moderating consequences of garbage collection when in C
In-Reply-To: <j9rr8m$kk5$1@dough.gmane.org>
References: <4E8BD4EB.60802@fhcrc.org> <j9fpvr$ad$1@dough.gmane.org>
	<j9rr8m$kk5$1@dough.gmane.org>
Message-ID: <CAJ55+dL0-TRdLc7QP79JsQJ3e0Xz-aRt6sky2O2s+_f=0t_CKA@mail.gmail.com>

On Tue, Nov 15, 2011 at 8:47 AM,  <dhinds at sonic.net> wrote:
> dhinds at sonic.net wrote:
>> Martin Morgan <mtmorgan at fhcrc.org> wrote:
>> > Allocating many small objects triggers numerous garbage collections as R
>> > grows its memory, seriously degrading performance. The specific use case
>> > is in creating a STRSXP of several 1,000,000's of elements of 60-100
>> > characters each; a simplified illustration understating the effects
>> > (because there is initially little to garbage collect, in contrast to an
>> > R session with several packages loaded) is below.
>
>> What a coincidence -- I was just going to post a question about why it
>> is so slow to create a STRSXP of ~10,000,000 unique elements, each ~10
>> characters long. ?I had noticed that this seemed to show much worse
>> than linear scaling. ?I had not thought of garbage collection as the
>> culprit -- but indeed it is. ?By manipulating the GC trigger, I can
>> make this operation take as little as 3 seconds (with no GC) or as
>> long as 76 seconds (with 31 garbage collections).
>
> I had done some google searches on this issue, since it seemed like it
> should not be too uncommon, but the only other hit I could come up
> with was a thread from 2006:
>
> https://stat.ethz.ch/pipermail/r-devel/2006-November/043446.html
>
> In any case, one issue with your suggested workaround is that it
> requires knowing how much additional storage is needed, which may be
> an expensive operation to determine. ?I've just tried implementing a
> different approach, which is to define two new functions to either
> disable or enable GC. ?The function to disable GC first invokes
> R_gc_full() to shrink the heap as much as possible, then sets a flag.
> Then in R_gc_internal(), I first check that flag, and if it is set, I
> call AdjustHeapSize(size_needed) and exit immediately.
>
> These calls could be used to bracket any code section that expects to
> make lots of calls to R's memory allocator. ?The down side is that
> this approach requires that all paths out of such a code section
> (including error handling) need to take care to unset the GC-disabled
> flag. ?I think I would want to hear from someone on the R team about
> whether they think this is a good idea.

If .Call and .C re-enabled the GC on return from compiled code (and
threw some sort of error) that would help contain the potential
damage.

You'd might also  want to re-enable GC if malloc() returned NULL,
rather than giving an out-of-memory error.

  -thomas

-- 
Thomas Lumley
Professor of Biostatistics
University of Auckland


From mtmorgan at fhcrc.org  Mon Nov 14 21:08:24 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Mon, 14 Nov 2011 12:08:24 -0800
Subject: [Rd] Moderating consequences of garbage collection when in C
In-Reply-To: <j9rr8m$kk5$1@dough.gmane.org>
References: <4E8BD4EB.60802@fhcrc.org> <j9fpvr$ad$1@dough.gmane.org>
	<j9rr8m$kk5$1@dough.gmane.org>
Message-ID: <4EC17538.1000400@fhcrc.org>

On 11/14/2011 11:47 AM, dhinds at sonic.net wrote:
> dhinds at sonic.net wrote:
>> Martin Morgan<mtmorgan at fhcrc.org>  wrote:
>>> Allocating many small objects triggers numerous garbage collections as R
>>> grows its memory, seriously degrading performance. The specific use case
>>> is in creating a STRSXP of several 1,000,000's of elements of 60-100
>>> characters each; a simplified illustration understating the effects
>>> (because there is initially little to garbage collect, in contrast to an
>>> R session with several packages loaded) is below.
>
>> What a coincidence -- I was just going to post a question about why it
>> is so slow to create a STRSXP of ~10,000,000 unique elements, each ~10
>> characters long.  I had noticed that this seemed to show much worse
>> than linear scaling.  I had not thought of garbage collection as the
>> culprit -- but indeed it is.  By manipulating the GC trigger, I can
>> make this operation take as little as 3 seconds (with no GC) or as
>> long as 76 seconds (with 31 garbage collections).
>
> I had done some google searches on this issue, since it seemed like it
> should not be too uncommon, but the only other hit I could come up
> with was a thread from 2006:
>
> https://stat.ethz.ch/pipermail/r-devel/2006-November/043446.html
>
> In any case, one issue with your suggested workaround is that it
> requires knowing how much additional storage is needed, which may be
> an expensive operation to determine.  I've just tried implementing a
> different approach, which is to define two new functions to either
> disable or enable GC.  The function to disable GC first invokes
> R_gc_full() to shrink the heap as much as possible, then sets a flag.
> Then in R_gc_internal(), I first check that flag, and if it is set, I
> call AdjustHeapSize(size_needed) and exit immediately.

I think this is a better approach; mine seriously understated the 
complexity of figuring out required size.

> These calls could be used to bracket any code section that expects to
> make lots of calls to R's memory allocator.  The down side is that
> this approach requires that all paths out of such a code section
> (including error handling) need to take care to unset the GC-disabled
> flag.  I think I would want to hear from someone on the R team about
> whether they think this is a good idea.
>
> A final alternative might be to provide a vectorized version of mkChar
> that would accept a char ** and use one of these methods internally,
> rather than exporting the underlying methods as part of R's API.  I
> don't know if there are other clear use cases where GC is a serious
> bottleneck, besides constructing large vectors of mostly unique
> strings.  Such a function would be less generally useful since it
> would require that the full vector of C strings be assembled at one
> time.

Another place where this comes up is during package load, especially for 
packages with many S4 instances.

   > gcinfo(TRUE)
   > library(Matrix)
   Garbage collection 2 = 1+0+1 (level 0) ...
   7.6 Mbytes of cons cells used (40%)
   1.1 Mbytes of vectors used (18%)
   ...
   Garbage collection 58 = 39+9+10 (level 2) ...
   39.4 Mbytes of cons cells used (75%)
   2.9 Mbytes of vectors used (47%)

and continuing

   > library(IRanges)
   ...
   Garbage collection 89 = 60+14+15 (level 1) ...
   63.1 Mbytes of cons cells used (80%)
   4.3 Mbytes of vectors used (53%)

Also, something like

   > system.time(as.character(1:10000000))
   ...
   Garbage collection 124 = 60+14+50 (level 2) ...
   596.1 Mbytes of cons cells used (95%)
   226.3 Mbytes of vectors used (69%)
      user  system elapsed
   61.908   0.297  62.303

might be an R-level manifestation of the same problem.

Being able to disable / enable the GC seems like a useful patch, and I 
hope this is interesting enough for the R-core team.

A more fundamental issue seems to be garbage collection when there are a 
lot of SEXP in play

   > system.time(gc())
      user  system elapsed
     0.236   0.000   0.236

There's a hierarchy of CHARSXP / STRSXP, so maybe that could be 
exploited in the mark phase?

Martin


> -- Dave
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From edzer.pebesma at uni-muenster.de  Mon Nov 14 21:43:11 2011
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 14 Nov 2011 21:43:11 +0100
Subject: [Rd] R Development Center(s)
Message-ID: <4EC17D5F.5010603@uni-muenster.de>

A while ago our institute was approached by a large company, say XXX,
who asked whether we would like to become an Xxx development center, as
we are active in the same area. After some negotation we did, believing
there will be mutual benefits.

Some time later, after putting up the Xxx development center logo on
the institute home page, my feeling grew that we are also, and probably
to a larger extent, an R development center. However, this information
is very hard to find out from the institute web site, particularly for
prospective students who may not start off by looking at publication
records. Identity, marketing, and logos are important these days.

I realize there are many R Development Centers around the world. I wrote
about what we (now) think makes us an R Development Center, at:

http://giv-wikis.uni-muenster.de/agp/bin/view/Main/RDevelopmentCenter

and I asked someone to develop a logo (two actually, one with CENTER,
one with CENTRE). I believe it would be good for R if more R Development
Centers would make explicit somehow that they are R Development Center,
and maybe that a list of such centers can be found somewhere. We could
use http://pad.ifgi.de/rdc as a start. Open source style, please feel
free to reuse or modify the logo or ideas, and take the concept lightly.

Next thing, when I'm concerned, would be to organize an RDC student of
the year award.

Any reactions welcome. With best wishes,
-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From dhinds at sonic.net  Mon Nov 14 22:12:32 2011
From: dhinds at sonic.net (dhinds at sonic.net)
Date: Mon, 14 Nov 2011 21:12:32 +0000
Subject: [Rd] Moderating consequences of garbage collection when in C
References: <4E8BD4EB.60802@fhcrc.org> <j9fpvr$ad$1@dough.gmane.org>
	<j9rr8m$kk5$1@dough.gmane.org> <4EC17538.1000400@fhcrc.org>
Message-ID: <j9s07v$rpu$1@dough.gmane.org>

Martin Morgan <mtmorgan at fhcrc.org> wrote:
> On 11/14/2011 11:47 AM, dhinds at sonic.net wrote:
> > dhinds at sonic.net wrote:
> >> Martin Morgan<mtmorgan at fhcrc.org>  wrote:
> >
> > I had done some google searches on this issue, since it seemed like it
> > should not be too uncommon, but the only other hit I could come up
> > with was a thread from 2006:
> >
> > https://stat.ethz.ch/pipermail/r-devel/2006-November/043446.html
> >
> > In any case, one issue with your suggested workaround is that it
> > requires knowing how much additional storage is needed, which may be
> > an expensive operation to determine.  I've just tried implementing a
> > different approach, which is to define two new functions to either
> > disable or enable GC.  The function to disable GC first invokes
> > R_gc_full() to shrink the heap as much as possible, then sets a flag.
> > Then in R_gc_internal(), I first check that flag, and if it is set, I
> > call AdjustHeapSize(size_needed) and exit immediately.

> I think this is a better approach; mine seriously understated the 
> complexity of figuring out required size.

> > These calls could be used to bracket any code section that expects to
> > make lots of calls to R's memory allocator.  The down side is that
> > this approach requires that all paths out of such a code section
> > (including error handling) need to take care to unset the GC-disabled
> > flag.  I think I would want to hear from someone on the R team about
> > whether they think this is a good idea.
> >

> Another place where this comes up is during package load, especially for 
> packages with many S4 instances.

Do you know if this is all happening inside a C function that could
handle disabling and enabling GC?  Or would it require doing this at
the R level?  For testing, I am turning GC on and off at the R level
but I am thinking about where we would need to check for failures to
re-enable GC.  I suppose one approach would be to provide an R wrapper
that would evaluate an expression with GC disabled using tryCatch to
guarantee that it would exit with GC enabled.

>    > system.time(as.character(1:10000000))
>       user  system elapsed
>    61.908   0.297  62.303

I get 6 seconds for this with GC disabled.

> There's a hierarchy of CHARSXP / STRSXP, so maybe that could be 
> exploited in the mark phase?

I haven't explored whether GC could be made smarter so that this isn't
as big of a hit.  I don't really understand the GC process.

-- Dave


From mtmorgan at fhcrc.org  Mon Nov 14 22:28:55 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Mon, 14 Nov 2011 13:28:55 -0800
Subject: [Rd] Moderating consequences of garbage collection when in C
In-Reply-To: <j9s07v$rpu$1@dough.gmane.org>
References: <4E8BD4EB.60802@fhcrc.org>
	<j9fpvr$ad$1@dough.gmane.org>	<j9rr8m$kk5$1@dough.gmane.org>
	<4EC17538.1000400@fhcrc.org> <j9s07v$rpu$1@dough.gmane.org>
Message-ID: <4EC18817.3060501@fhcrc.org>

On 11/14/2011 01:12 PM, dhinds at sonic.net wrote:
> Martin Morgan<mtmorgan at fhcrc.org>  wrote:
>> >  On 11/14/2011 11:47 AM,dhinds at sonic.net  wrote:
>>> >  >  dhinds at sonic.net  wrote:
>>>> >  >>  Martin Morgan<mtmorgan at fhcrc.org>   wrote:
>>> >  >
>>> >  >  I had done some google searches on this issue, since it seemed like it
>>> >  >  should not be too uncommon, but the only other hit I could come up
>>> >  >  with was a thread from 2006:
>>> >  >
>>> >  >  https://stat.ethz.ch/pipermail/r-devel/2006-November/043446.html
>>> >  >
>>> >  >  In any case, one issue with your suggested workaround is that it
>>> >  >  requires knowing how much additional storage is needed, which may be
>>> >  >  an expensive operation to determine.  I've just tried implementing a
>>> >  >  different approach, which is to define two new functions to either
>>> >  >  disable or enable GC.  The function to disable GC first invokes
>>> >  >  R_gc_full() to shrink the heap as much as possible, then sets a flag.
>>> >  >  Then in R_gc_internal(), I first check that flag, and if it is set, I
>>> >  >  call AdjustHeapSize(size_needed) and exit immediately.
>> >  I think this is a better approach; mine seriously understated the
>> >  complexity of figuring out required size.
>>> >  >  These calls could be used to bracket any code section that expects to
>>> >  >  make lots of calls to R's memory allocator.  The down side is that
>>> >  >  this approach requires that all paths out of such a code section
>>> >  >  (including error handling) need to take care to unset the GC-disabled
>>> >  >  flag.  I think I would want to hear from someone on the R team about
>>> >  >  whether they think this is a good idea.
>>> >  >
>> >  Another place where this comes up is during package load, especially for
>> >  packages with many S4 instances.
> Do you know if this is all happening inside a C function that could
> handle disabling and enabling GC?  Or would it require doing this at
> the R level?  For testing, I am turning GC on and off at the R level

Generally complicated operations across multiple function calls. 
Something like

   f = function() {
     state <- gcdisable(TRUE)
     on.exit(gcdisable(state))
     as.character(1:10000000)
   }

might be used.

Martin
-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From dhinds at sonic.net  Tue Nov 15 00:33:36 2011
From: dhinds at sonic.net (dhinds at sonic.net)
Date: Mon, 14 Nov 2011 23:33:36 +0000
Subject: [Rd] Moderating consequences of garbage collection when in C
References: <4E8BD4EB.60802@fhcrc.org> <j9fpvr$ad$1@dough.gmane.org>
	<j9rr8m$kk5$1@dough.gmane.org> <4EC17538.1000400@fhcrc.org>
	<j9s07v$rpu$1@dough.gmane.org> <4EC18817.3060501@fhcrc.org>
Message-ID: <j9s8gg$r6h$1@dough.gmane.org>

Martin Morgan <mtmorgan at fhcrc.org> wrote:

> > Do you know if this is all happening inside a C function that could
> > handle disabling and enabling GC?  Or would it require doing this at
> > the R level?  For testing, I am turning GC on and off at the R level

> Generally complicated operations across multiple function calls. 
> Something like

>    f = function() {
>      state <- gcdisable(TRUE)
>      on.exit(gcdisable(state))
>      as.character(1:10000000)
>    }

> might be used.

Here is how I've implemented the core part of this (for discussion,
not a complete patch)

-- Dave




--- memory.c.orig       2011-04-04 15:05:04.000000000 -0700
+++ memory.c    2011-11-14 15:21:42.000000000 -0800
@@ -98,6 +98,7 @@
 */
 
 static int gc_reporting = 0;
+static int gc_disabled = 0;
 static int gc_count = 0;
 
 #ifdef TESTING_WRITE_BARRIER
@@ -2467,6 +2468,17 @@
     R_gc_internal(size_needed);
 }
 
+SEXP attribute_hidden do_gcdisable(SEXP call, SEXP op, SEXP args,
SEXP rho)
+{
+    int i;
+    SEXP old = ScalarLogical(gc_disabled);
+    checkArity(op, args);
+    i = asLogical(CAR(args));
+    if (i != NA_LOGICAL)
+	gc_disabled = i;
+    return old;
+}
+
 #ifdef _R_HAVE_TIMING_
 double R_getClockIncrement(void);
 void R_getProcTime(double *data);
@@ -2541,6 +2553,14 @@
     SEXP first_bad_sexp_type_sexp = NULL;
     int first_bad_sexp_type_line = 0;
 
+    if (gc_disabled) {
+	AdjustHeapSize(size_needed);
+	if (NO_FREE_NODES() || VHEAP_FREE() < size_needed) {
+	    gc_disabled = 0;
+	    error("Heap adjustment failed -- enabling GC");
+	} else return;
+    }
+
  again:
 
     gc_count++;


From therneau at mayo.edu  Tue Nov 15 20:10:04 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Tue, 15 Nov 2011 13:10:04 -0600
Subject: [Rd] Small nit in Sweave
Message-ID: <1321384204.24088.140.camel@nemo>

Two small Sweave issues.

1. I had the following line in my code
   <<echo=FALSE, results="hide">>

resulting in the message
Error in match.arg(options$results, c("verbatim", "tex", "hide")) : 
  'arg' should be one of ?verbatim?, ?tex?, ?hide?

  I puzzled on this a bit since my argument exactly matched the message,
until I thought of trying it without the quotes.

2. Where should I have reported this?  Sweave is not on CRAN so I
couldn't find the maintainer email there.  Perhaps I'm missing something
obvious though....

Terry T.


From marc_schwartz at me.com  Tue Nov 15 20:30:59 2011
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 15 Nov 2011 13:30:59 -0600
Subject: [Rd] Small nit in Sweave
In-Reply-To: <1321384204.24088.140.camel@nemo>
References: <1321384204.24088.140.camel@nemo>
Message-ID: <75246AA6-758E-44BA-8B5F-29492A48526E@me.com>

On Nov 15, 2011, at 1:10 PM, Terry Therneau wrote:

> Two small Sweave issues.
> 
> 1. I had the following line in my code
>   <<echo=FALSE, results="hide">>
> 
> resulting in the message
> Error in match.arg(options$results, c("verbatim", "tex", "hide")) : 
>  'arg' should be one of ?verbatim?, ?tex?, ?hide?
> 
>  I puzzled on this a bit since my argument exactly matched the message,
> until I thought of trying it without the quotes.
> 
> 2. Where should I have reported this?  Sweave is not on CRAN so I
> couldn't find the maintainer email there.  Perhaps I'm missing something
> obvious though....
> 
> Terry T.


Interesting. I never thought of using the 'results' options as quoted character vectors, even though in ?RweaveLatex, the description for the 'results' options indicates:

character string ("verbatim"). If "verbatim", the output of R commands is included in the verbatim-like Soutput environment. If "tex", the output is taken to be already proper LaTeX markup and included as is. If "hide" then all output is completely suppressed (but the code executed during the weave).


I can see how that could be confusing. All examples of the chunk headers I have seen do not use quoted values. Perhaps the above should state "Non-quoted character values" or similar verbiage.

In terms of reporting Terry, Sweave is in the 'utils' package, which is part of "Base R", therefore under the copyright of The R Foundation. So here is fine.

Regards,

Marc Schwartz


From krunal.rao78 at gmail.com  Tue Nov 15 23:39:09 2011
From: krunal.rao78 at gmail.com (KR)
Date: Tue, 15 Nov 2011 22:39:09 +0000
Subject: [Rd] Question on parsing R code from C
References: <loom.20111108T203022-872@post.gmane.org>
	<9465BE63-EA88-4BE2-8D1C-9E33BE8AA45D@r-project.org>
	<loom.20111108T224700-655@post.gmane.org>
	<3D4F776D-4D5D-4C39-90B3-12DF09C5C6BA@r-project.org>
	<loom.20111109T001139-68@post.gmane.org>
	<AF0744B1-C119-4BF1-99D0-9DBA31E734F9@r-project.org>
	<loom.20111111T000844-348@post.gmane.org>
	<84A85DE6-2914-4C8D-834A-07DE5820B5AD@r-project.org>
Message-ID: <loom.20111115T225950-180@post.gmane.org>

Simon Urbanek <simon.urbanek <at> r-project.org> writes:
> AFAIR you have to evaluate parse(text=...) for that, there is no C-level 
access to parser errors.

Yes that did it, thanks!
 
> If you get a crash, you're not setting up you R correctly. If your R quits 
then you are in non-interactive mode
> and you didn't setup an error handler.

I am really getting a crash for strings with incorrect escapes like when 
evaluating:
parse(text='ggsave("C:\test.png")')
Using R.exe does not result in a crash.
It's really puzzling that all the other parse errors (like rnorm(10a10)) or 
evaluation errors (like idontexists(10)) correctly results in an error string an 
no crash. Code that executes correctly works fine as well.
Do you have any suggestion on what may be causing the issue? 

I am initializing R with:
Rf_initEmbeddedR passing progsname, --vanilla and --slave

And I am parsing/evaluating with:
Rf_mkString (protected) passing capture.output(eval(parse(text="<code>")))
(I also tried with allocVector + Rf_mkChar with no difference)
Followed by:
R_ParseVector(r_cmd, -1, parse_err, R_NilValue) (protected) with r_cmd given by 
the SEXP returned above
And by:
R_tryEvalSilent(VECTOR_ELT(r_expr,i), R_GlobalEnv, eval_err) (protected) 
iterating along r_expr which is given by the SEXP returned above.

I don't perform any other operation at all. R_Interactive is true.

> I prefer using Rf_eval() and try(..., silent=TRUE) - you can check on the 
class of the result to see if there
> was an error.

I actually find it easier (less code) to use R_tryEvalSilent followed by 
R_curErrorBuf in case of error. Are they going to be deprecated?

> BTW: you are asking a lot of questions the are answered in the Rserve FAQ 
(since what you do is exactly what
> Rserve provides) so you may want to have a quick look:
> http://rforge.net/Rserve/faq.html

Thanks a lot, that helped as well!

Plotting works as well but after the window is created it "freezes", cannot be 
closed without passing "dev.off()" command. I understand this is expected 
behavior and that it cannot be changed using Rf_initEmbeddedR and 
Rf_endEmbeddedR.

The only problem I am having (aside from the wrongly escaped string crashes) is 
that if I call:
Rf_initEmbeddedR (to open the global R state) followed by Rf_endEmbeddedR (to 
close the global R state) and then I try to open the global state again with 
Rf_initEmbeddedR I get:
"Lost warning messages" on stderr and calling other R functions result in hang.
What am I doing wrong?

Thanks a lot for all the suggestions so far, I have made a lot of progress.


From jeffrey.horner at gmail.com  Tue Nov 15 23:52:31 2011
From: jeffrey.horner at gmail.com (Jeffrey Horner)
Date: Tue, 15 Nov 2011 16:52:31 -0600
Subject: [Rd] When collected warnings exceeds 50
In-Reply-To: <CAD+yNFip_PJd18ZJZVNeVJ3bMB-2uNm_cuKsUna39S8mtgwU+A@mail.gmail.com>
References: <CAD+yNFjt51Jch5XnnX-mXjzeAW7Qeqemha97SdmpL=qS2hgfMQ@mail.gmail.com>
	<CAD+yNFip_PJd18ZJZVNeVJ3bMB-2uNm_cuKsUna39S8mtgwU+A@mail.gmail.com>
Message-ID: <CAD+yNFgeQtjFNgU6QOx0S1zVMrGwN2BKbPuLt6t9niDtM_bNag@mail.gmail.com>

On Thu, Nov 10, 2011 at 11:00 PM, Jeffrey Horner
<jeffrey.horner at gmail.com> wrote:
> On Thu, Nov 10, 2011 at 10:54 PM, Jeffrey Horner
> <jeffrey.horner at gmail.com> wrote:
>> Hi,
>>
>> I've been tracking down a memory leak in an rApache application,
>> http://data.vanderbilt.edu/rapache/bbplot. The code was deployed in
>> 2007 and has survived numerous upgrades of both R and rApache
>> (including upgrades and bugs in RMySQL). It's written in such a way so
>> that web crawlers will download every possible URL the app will
>> create. It's not a high-traffic app, but just about every line of code
>> is executed at some point during a crawl by Google, Bing, etc.
>>
>> Here's the salient point: the app (well, just about all rApache apps)
>> sets option warn to 0 to collect all warnings until a request is
>> completed. It turns out that some requests will collect more than 50
>> warnings, and the result is an apache process that leaks memory until
>> finally seg faulting somewhere in one of R's extra packages, if I
>> recall correctly.
>>
>> After what seems like a month working on this problem, I think I've
>> narrowed it down to a simple test case. I'm testing with R-devel
>> r57624 on ubuntu linux. Running the following under valgrind:
>>
>> R -d valgrind
>>> options(warn=0)
>>> for (i in 1:51) factor(1,levels=c(1,1) # duplicate level warningcall
>
> Missed a closing parenthesis. should be :
>
>> options(warn=0)
>> for (i in 1:51) factor(1,levels=c(1,1)) # duplicate level warningcall
>
>>
>> and you should see "Invalid read" messages. I've narrowed it down to
>> vwarningcall_dflt starting a new R context via begincontext() ?but
>> returning early without calling endcontext() in errors.c:
>>
>> ?svn diff src/main/errors.c
>> Index: src/main/errors.c
>> ===================================================================
>> --- src/main/errors.c ? (revision 57624)
>> +++ src/main/errors.c ? (working copy)
>> @@ -333,8 +333,11 @@
>> ? ? ? ?char *tr; int nc;
>> ? ? ? ?if(!R_CollectWarnings)
>> ? ? ? ? ? ?setupwarnings();
>> - ? ? ? if( R_CollectWarnings > 49 )
>> + ? ? ? if( R_CollectWarnings > 49 ) {
>> + ? ? ? ? ? endcontext(&cntxt);
>> + ? ? ? ? ? inWarning = 0;
>> ? ? ? ? ? ?return;
>> + ? ? ? }
>> ? ? ? ?SET_VECTOR_ELT(R_Warnings, R_CollectWarnings, call);
>> ? ? ? ?Rvsnprintf(buf, min(BUFSIZE, R_WarnLength+1), format, ap);
>> ? ? ? ?if(R_WarnLength < BUFSIZE - 20 && strlen(buf) == R_WarnLength)
>>
>> This fix eliminates the "Invalid read" errors, but I'm unsure if it
>> fixes my application. I'll find out tomorrow.

The memory leak was occurring in the Cairo package and it is fixed
now, but the issue I spelled out above is still a concern.

Jeff


From simon.urbanek at r-project.org  Wed Nov 16 00:45:03 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 15 Nov 2011 18:45:03 -0500
Subject: [Rd] Question on parsing R code from C
In-Reply-To: <loom.20111115T225950-180@post.gmane.org>
References: <loom.20111108T203022-872@post.gmane.org>
	<9465BE63-EA88-4BE2-8D1C-9E33BE8AA45D@r-project.org>
	<loom.20111108T224700-655@post.gmane.org>
	<3D4F776D-4D5D-4C39-90B3-12DF09C5C6BA@r-project.org>
	<loom.20111109T001139-68@post.gmane.org>
	<AF0744B1-C119-4BF1-99D0-9DBA31E734F9@r-project.org>
	<loom.20111111T000844-348@post.gmane.org>
	<84A85DE6-2914-4C8D-834A-07DE5820B5AD@r-project.org>
	<loom.20111115T225950-180@post.gmane.org>
Message-ID: <F4E5DACB-DBAC-46AE-B647-6A93CAA8FAB2@r-project.org>


On Nov 15, 2011, at 5:39 PM, KR wrote:

> Simon Urbanek <simon.urbanek <at> r-project.org> writes:
>> AFAIR you have to evaluate parse(text=...) for that, there is no C-level 
> access to parser errors.
> 
> Yes that did it, thanks!
> 
>> If you get a crash, you're not setting up you R correctly. If your R quits 
> then you are in non-interactive mode
>> and you didn't setup an error handler.
> 
> I am really getting a crash for strings with incorrect escapes like when 
> evaluating:
> parse(text='ggsave("C:\test.png")')
> Using R.exe does not result in a crash.
> It's really puzzling that all the other parse errors (like rnorm(10a10)) or 
> evaluation errors (like idontexists(10)) correctly results in an error string an 
> no crash. Code that executes correctly works fine as well.
> Do you have any suggestion on what may be causing the issue? 
> 

Not without seeing the actual code. (And details such as which platform you're on).
Note that setup_Rmainloop() is the last to set the SETJMP context target so you should make sure the stack is still present after it finished (i.e. you can't call it from a sub-function - which Rf_initEmbeddedR does) otherwise error without an enclosing context will crash. Or to put it other way round, create a context around your parse/eval code (probably the easiest way to do that is to use R_ToplevelExec).


> I am initializing R with:
> Rf_initEmbeddedR passing progsname, --vanilla and --slave
> 
> And I am parsing/evaluating with:
> Rf_mkString (protected) passing capture.output(eval(parse(text="<code>")))
> (I also tried with allocVector + Rf_mkChar with no difference)
> Followed by:
> R_ParseVector(r_cmd, -1, parse_err, R_NilValue) (protected) with r_cmd given by 
> the SEXP returned above
> And by:
> R_tryEvalSilent(VECTOR_ELT(r_expr,i), R_GlobalEnv, eval_err) (protected) 
> iterating along r_expr which is given by the SEXP returned above.
> 
> I don't perform any other operation at all. R_Interactive is true.
> 
>> I prefer using Rf_eval() and try(..., silent=TRUE) - you can check on the 
> class of the result to see if there
>> was an error.
> 
> I actually find it easier (less code) to use R_tryEvalSilent followed by 
> R_curErrorBuf in case of error. Are they going to be deprecated?
> 
>> BTW: you are asking a lot of questions the are answered in the Rserve FAQ 
> (since what you do is exactly what
>> Rserve provides) so you may want to have a quick look:
>> http://rforge.net/Rserve/faq.html
> 
> Thanks a lot, that helped as well!
> 
> Plotting works as well but after the window is created it "freezes", cannot be 
> closed without passing "dev.off()" command. I understand this is expected 
> behavior and that it cannot be changed using Rf_initEmbeddedR and 
> Rf_endEmbeddedR.
> 
> The only problem I am having (aside from the wrongly escaped string crashes) is 
> that if I call:
> Rf_initEmbeddedR (to open the global R state) followed by Rf_endEmbeddedR (to 
> close the global R state) and then I try to open the global state again with 
> Rf_initEmbeddedR I get:
> "Lost warning messages" on stderr and calling other R functions result in hang.
> What am I doing wrong?
> 

Nothing. You can initialize R only once.

Cheers,
Simon


> Thanks a lot for all the suggestions so far, I have made a lot of progress.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From ripley at stats.ox.ac.uk  Wed Nov 16 09:22:10 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 16 Nov 2011 08:22:10 +0000 (GMT)
Subject: [Rd] When collected warnings exceeds 50
In-Reply-To: <CAD+yNFip_PJd18ZJZVNeVJ3bMB-2uNm_cuKsUna39S8mtgwU+A@mail.gmail.com>
References: <CAD+yNFjt51Jch5XnnX-mXjzeAW7Qeqemha97SdmpL=qS2hgfMQ@mail.gmail.com>
	<CAD+yNFip_PJd18ZJZVNeVJ3bMB-2uNm_cuKsUna39S8mtgwU+A@mail.gmail.com>
Message-ID: <alpine.LFD.2.02.1111160821530.29353@gannet.stats.ox.ac.uk>

Fixed (in a different way) in R-devel/R-patched.

On Thu, 10 Nov 2011, Jeffrey Horner wrote:

> On Thu, Nov 10, 2011 at 10:54 PM, Jeffrey Horner
> <jeffrey.horner at gmail.com> wrote:
>> Hi,
>>
>> I've been tracking down a memory leak in an rApache application,
>> http://data.vanderbilt.edu/rapache/bbplot. The code was deployed in
>> 2007 and has survived numerous upgrades of both R and rApache
>> (including upgrades and bugs in RMySQL). It's written in such a way so
>> that web crawlers will download every possible URL the app will
>> create. It's not a high-traffic app, but just about every line of code
>> is executed at some point during a crawl by Google, Bing, etc.
>>
>> Here's the salient point: the app (well, just about all rApache apps)
>> sets option warn to 0 to collect all warnings until a request is
>> completed. It turns out that some requests will collect more than 50
>> warnings, and the result is an apache process that leaks memory until
>> finally seg faulting somewhere in one of R's extra packages, if I
>> recall correctly.
>>
>> After what seems like a month working on this problem, I think I've
>> narrowed it down to a simple test case. I'm testing with R-devel
>> r57624 on ubuntu linux. Running the following under valgrind:
>>
>> R -d valgrind
>>> options(warn=0)
>>> for (i in 1:51) factor(1,levels=c(1,1) # duplicate level warningcall
>
> Missed a closing parenthesis. should be :
>
>> options(warn=0)
>> for (i in 1:51) factor(1,levels=c(1,1)) # duplicate level warningcall
>
>>
>> and you should see "Invalid read" messages. I've narrowed it down to
>> vwarningcall_dflt starting a new R context via begincontext() ?but
>> returning early without calling endcontext() in errors.c:
>>
>> ?svn diff src/main/errors.c
>> Index: src/main/errors.c
>> ===================================================================
>> --- src/main/errors.c ? (revision 57624)
>> +++ src/main/errors.c ? (working copy)
>> @@ -333,8 +333,11 @@
>> ? ? ? ?char *tr; int nc;
>> ? ? ? ?if(!R_CollectWarnings)
>> ? ? ? ? ? ?setupwarnings();
>> - ? ? ? if( R_CollectWarnings > 49 )
>> + ? ? ? if( R_CollectWarnings > 49 ) {
>> + ? ? ? ? ? endcontext(&cntxt);
>> + ? ? ? ? ? inWarning = 0;
>> ? ? ? ? ? ?return;
>> + ? ? ? }
>> ? ? ? ?SET_VECTOR_ELT(R_Warnings, R_CollectWarnings, call);
>> ? ? ? ?Rvsnprintf(buf, min(BUFSIZE, R_WarnLength+1), format, ap);
>> ? ? ? ?if(R_WarnLength < BUFSIZE - 20 && strlen(buf) == R_WarnLength)
>>
>> This fix eliminates the "Invalid read" errors, but I'm unsure if it
>> fixes my application. I'll find out tomorrow.
>>
>> Jeff
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From marco.atzeri at gmail.com  Wed Nov 16 16:11:57 2011
From: marco.atzeri at gmail.com (marco atzeri)
Date: Wed, 16 Nov 2011 16:11:57 +0100
Subject: [Rd] cygwin R-2.14.0 build fail
In-Reply-To: <1321107923.21160.YahooMailNeo@web27002.mail.ukl.yahoo.com>
References: <1321107923.21160.YahooMailNeo@web27002.mail.ukl.yahoo.com>
Message-ID: <4EC3D2BD.8070008@gmail.com>

On 11/12/2011 3:25 PM, Mark Carter wrote:
> I tried to build R-2.14.0 on cygwin using the commands:
> ./configure --with-x=no
> make
>
> I started to get a whole lot of errors starting with:
> /cygdrive/c/Users/mcarter/src/R-2.14.0/src/modules/internet/Rhttpd.c:275: undefined reference to `_R_InputHandlers'
> which I have pasted at
>
> http://pastebin.com/GFb2pq92
>
> I'm aware that there is a cygwinports ports, but it seems outdated, and when I tried installing it, it was very lengthy and seemed more trouble that it was worth. I abandoned the installation attempt.
>
>
> Any tips on a way forward?
>

just built R-2.14.0 deriving from R-2.13.1-1 of cygport.

   configure     --with-blas="$(pkg-config --libs blas)" \
                 --with-lapack \
                 --enable-R-shlib \
                 TCLTK_LIBS="-ltcl84 -ltk84"  \
                 --with-system-zlib \
                 --with-system-bzlib \
                 --with-system-pcre \
                 --with-system-xz \
                 --disable-openmp


almost all test passed

$ grep OK  R-2.14.0-1-check.log |wc -l
57

only 3 minor failures

$ find ../build/ -name *fail
../build/tests/Examples/parallel-Ex.Rout.fail
../build/tests/reg-BLAS.Rout.fail
../build/tests/reg-IO.Rout.fail

If you are interested I can provide you the binary package.

Regards
Marco


From spinuvit at gmail.com  Wed Nov 16 17:18:33 2011
From: spinuvit at gmail.com (Vitalie Spinu)
Date: Wed, 16 Nov 2011 17:18:33 +0100
Subject: [Rd] Injecting source reference from external editors (emacs).
Message-ID: <CAAQMm-8Zm6j5+BBwq9SdEDrZKJc5=yUWogEYWrA54WQcpoUHjg@mail.gmail.com>

Hi  everyone,

I would like to inject source reference into R objects from external editor.  In
my case it's  emacs with ESS and ess-tracebug
(http://code.google.com/p/ess-tracebug/).

Currently the user has to source the file before the src references become
available. I would like to spare her, and insert the source references "on-line"
during normal interaction (i.e. sending chunks of code from emacs buffers)

With new additions in R-14 I started looking into it and discovered that an
encapsulation

eval(parse(text = "tf <- function(a){a^5
  b <- a;
  return(b)
}", srcfile = srcfile("@buffer@")))

does quite a good job, and the debugger  would display something like:

Browse[2]> debug at @buffer@#2: b <- a
Browse[2]> debug at @buffer@#3: return(b)

which is great, and could be used for what I want.

The problem is that I have to interfere with the user's input, which might not
be a good idea always. Is there (will be?) a more direct way of doing
this without encapsulation?

Currently when a function "tf<-function(a){a^5}" is created at R
prompt, R associates
with it a srcref with empty srcfile reference.

I wonder if it would be possible to instruct R that next evaluation will be from
buffer "Xbuf" at line N, something like

setSrcSource(srcobject="buffX", srcline=45)

so that any input that follows, would get a srcref pointing to "buffX" starting
from line 45 instead of just empty reference?

At the end of the evaluation I would just reset R with

setSrcSource(NULL)

Thanks,
Vitalie.


From krunal.rao78 at gmail.com  Wed Nov 16 20:48:28 2011
From: krunal.rao78 at gmail.com (KR)
Date: Wed, 16 Nov 2011 19:48:28 +0000
Subject: [Rd] Question on parsing R code from C
References: <loom.20111108T203022-872@post.gmane.org>
	<9465BE63-EA88-4BE2-8D1C-9E33BE8AA45D@r-project.org>
	<loom.20111108T224700-655@post.gmane.org>
	<3D4F776D-4D5D-4C39-90B3-12DF09C5C6BA@r-project.org>
	<loom.20111109T001139-68@post.gmane.org>
	<AF0744B1-C119-4BF1-99D0-9DBA31E734F9@r-project.org>
	<loom.20111111T000844-348@post.gmane.org>
	<84A85DE6-2914-4C8D-834A-07DE5820B5AD@r-project.org>
	<loom.20111115T225950-180@post.gmane.org>
	<F4E5DACB-DBAC-46AE-B647-6A93CAA8FAB2@r-project.org>
Message-ID: <loom.20111116T203740-838@post.gmane.org>

Simon Urbanek <simon.urbanek <at> r-project.org> writes:
> Not without seeing the actual code. (And details such as which platform you're 
on).
> Note that setup_Rmainloop() is the last to set the SETJMP context target so 
you should make sure the stack is
> still present after it finished (i.e. you can't call it from a sub-function - 
which Rf_initEmbeddedR
> does) otherwise error without an enclosing context will crash. Or to put it 
other way round, create a
> context around your parse/eval code (probably the easiest way to do that is to 
use R_ToplevelExec).

I will try to produce the exact code I am using (at the moment it embedded in
other code you would not be interested in), platforms are Windows XP and
Windows7-64. Some points:

1. Actually R_tryEvalSilent (and R_tryEval) calls R_ToplevelExec. Moreover if 
the problem is linked to the SETJMP (which I do not know much about 
unfortunately, my background is C++) it's my understanding that it should 
manifest itself even for other parse and evaluation errors. Instead the problem
arise if and only if I pass a wrongly escaped string. I.e. rnorm(10a10) does not 
result in a crash.
Is the R code doing something differently in this specific case?

2. My code is almost exactly the same as:
http://stackoverflow.com/questions/2463437/r-from-c-simplest-possible-
helloworld/2464479#2464479
skipping the EXAMPLE 1 part and passing the capture.output(eval(parse(text="
<code>"))) string to R_tryEval in EXAMPLE 2.

Cheers,


From simon.urbanek at r-project.org  Wed Nov 16 20:59:51 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 16 Nov 2011 14:59:51 -0500
Subject: [Rd] Question on parsing R code from C
In-Reply-To: <loom.20111116T203740-838@post.gmane.org>
References: <loom.20111108T203022-872@post.gmane.org>
	<9465BE63-EA88-4BE2-8D1C-9E33BE8AA45D@r-project.org>
	<loom.20111108T224700-655@post.gmane.org>
	<3D4F776D-4D5D-4C39-90B3-12DF09C5C6BA@r-project.org>
	<loom.20111109T001139-68@post.gmane.org>
	<AF0744B1-C119-4BF1-99D0-9DBA31E734F9@r-project.org>
	<loom.20111111T000844-348@post.gmane.org>
	<84A85DE6-2914-4C8D-834A-07DE5820B5AD@r-project.org>
	<loom.20111115T225950-180@post.gmane.org>
	<F4E5DACB-DBAC-46AE-B647-6A93CAA8FAB2@r-project.org>
	<loom.20111116T203740-838@post.gmane.org>
Message-ID: <303AC369-BDB4-438A-99C6-E604E04A7D20@r-project.org>


On Nov 16, 2011, at 2:48 PM, KR wrote:

> Simon Urbanek <simon.urbanek <at> r-project.org> writes:
>> Not without seeing the actual code. (And details such as which platform you're 
> on).
>> Note that setup_Rmainloop() is the last to set the SETJMP context target so 
> you should make sure the stack is
>> still present after it finished (i.e. you can't call it from a sub-function - 
> which Rf_initEmbeddedR
>> does) otherwise error without an enclosing context will crash. Or to put it 
> other way round, create a
>> context around your parse/eval code (probably the easiest way to do that is to 
> use R_ToplevelExec).
> 
> I will try to produce the exact code I am using (at the moment it embedded in
> other code you would not be interested in), platforms are Windows XP and
> Windows7-64. Some points:
> 
> 1. Actually R_tryEvalSilent (and R_tryEval) calls R_ToplevelExec.

Yes, but that's not where you get the crash.


> Moreover if 
> the problem is linked to the SETJMP (which I do not know much about 
> unfortunately, my background is C++) it's my understanding that it should 
> manifest itself even for other parse and evaluation errors. Instead the problem
> arise if and only if I pass a wrongly escaped string. I.e. rnorm(10a10) does not 
> result in a crash.
> Is the R code doing something differently in this specific case?
> 

Your crash is in the parsing step, not in the evaluator (if I understand you correctly) and the parsing step is not wrapped in a context - that's my guess based on what you told us.

Cheers,
Simon


> 2. My code is almost exactly the same as:
> http://stackoverflow.com/questions/2463437/r-from-c-simplest-possible-
> helloworld/2464479#2464479
> skipping the EXAMPLE 1 part and passing the capture.output(eval(parse(text="
> <code>"))) string to R_tryEval in EXAMPLE 2.
> 
> Cheers,
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From ripley at stats.ox.ac.uk  Wed Nov 16 21:32:02 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 16 Nov 2011 20:32:02 +0000 (GMT)
Subject: [Rd] cygwin R-2.14.0 build fail
In-Reply-To: <4EC3D2BD.8070008@gmail.com>
References: <1321107923.21160.YahooMailNeo@web27002.mail.ukl.yahoo.com>
	<4EC3D2BD.8070008@gmail.com>
Message-ID: <alpine.LFD.2.02.1111162027520.28593@gannet.stats.ox.ac.uk>

The failures are *not* minor.  Please don't distribute an R linked to 
a broken BLAS library.  Those tests are not for fun: they came from 
real errors on real problems.

On Wed, 16 Nov 2011, marco atzeri wrote:

> On 11/12/2011 3:25 PM, Mark Carter wrote:
>> I tried to build R-2.14.0 on cygwin using the commands:
>> ./configure --with-x=no
>> make
>> 
>> I started to get a whole lot of errors starting with:
>> /cygdrive/c/Users/mcarter/src/R-2.14.0/src/modules/internet/Rhttpd.c:275: 
>> undefined reference to `_R_InputHandlers'
>> which I have pasted at
>> 
>> http://pastebin.com/GFb2pq92
>> 
>> I'm aware that there is a cygwinports ports, but it seems outdated, and 
>> when I tried installing it, it was very lengthy and seemed more trouble 
>> that it was worth. I abandoned the installation attempt.
>> 
>> 
>> Any tips on a way forward?
>> 
>
> just built R-2.14.0 deriving from R-2.13.1-1 of cygport.
>
>  configure     --with-blas="$(pkg-config --libs blas)" \
>                --with-lapack \
>                --enable-R-shlib \
>                TCLTK_LIBS="-ltcl84 -ltk84"  \
>                --with-system-zlib \
>                --with-system-bzlib \
>                --with-system-pcre \
>                --with-system-xz \
>                --disable-openmp
>
>
> almost all test passed
>
> $ grep OK  R-2.14.0-1-check.log |wc -l
> 57
>
> only 3 minor failures
>
> $ find ../build/ -name *fail
> ../build/tests/Examples/parallel-Ex.Rout.fail
> ../build/tests/reg-BLAS.Rout.fail
> ../build/tests/reg-IO.Rout.fail
>
> If you are interested I can provide you the binary package.
>
> Regards
> Marco
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From marco.atzeri at gmail.com  Wed Nov 16 22:08:38 2011
From: marco.atzeri at gmail.com (marco atzeri)
Date: Wed, 16 Nov 2011 22:08:38 +0100
Subject: [Rd] cygwin R-2.14.0 build fail
In-Reply-To: <alpine.LFD.2.02.1111162027520.28593@gannet.stats.ox.ac.uk>
References: <1321107923.21160.YahooMailNeo@web27002.mail.ukl.yahoo.com>
	<4EC3D2BD.8070008@gmail.com>
	<alpine.LFD.2.02.1111162027520.28593@gannet.stats.ox.ac.uk>
Message-ID: <4EC42656.6010704@gmail.com>

On 11/16/2011 9:32 PM, Prof Brian Ripley wrote:
> The failures are *not* minor. Please don't distribute an R linked to a
> broken BLAS library. Those tests are not for fun: they came from real
> errors on real problems.
>

Dear Brian,
I am reasonable sure that the cygwin blas library are fine, have
you any evidence that they are broken ?

The R test log just reports an issue handling NA that could be
related to cygwin difference to others platform.
I already noted similar difference on cygwin octave package.

Here is the log:
--------------------------------------------------
 > ## PR#4582 %*% with NAs
 > stopifnot(is.na(NA %*% 0), is.na(0 %*% NA))
 > ## depended on the BLAS in use.
 >
 >
 > ## found from fallback test in slam 0.1-15
 > ## most likely indicates an inaedquate BLAS.
 > x <- matrix(c(1, 0, NA, 1), 2, 2)
 > y <- matrix(c(1, 0, 0, 2, 1, 0), 3, 2)
 > (z <- tcrossprod(x, y))
      [,1] [,2] [,3]
[1,]   NA   NA    0
[2,]    2    1    0
 > stopifnot(identical(z, x %*% t(y)))
Error: identical(z, x %*% t(y)) is not TRUE
Execution halted
tests/reg-BLAS.Rout.fail (END)
--------------------------------------------------

Regards
Marco


From bbolker at gmail.com  Wed Nov 16 22:38:46 2011
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 16 Nov 2011 16:38:46 -0500
Subject: [Rd] strange behavior from cex="*"
Message-ID: <4EC42D66.502@gmail.com>

  Someone inquired on StackOverflow about apparently non-deterministic
graphics behaviour in R.  I noticed that they were using cex="*" and
discovered some potentially weird behavior.

   On repeated runs of the same code I can get different PNGs.  If I set
the number of runs high enough, I seem to be able to get R to hang.
If I do a single version plotting to an interactive graphics window I
can get the point sizes to jump around as I resize the window (someone
reported being able to reproduce that behaviour in the Windows GUI as well).

  This is clearly a user error, but non-deterministic behaviour (and
hanging) are a little disturbing.

  I haven't had a chance yet to try to dig in and see what's happening
but thought I would report to see if anyone else could reproduce/figure
it out.

  Ben Bolker


########################
## n <- 100  ## hangs R

n <- 33

fn <- paste("tmp",seq(n),"png",sep=".")
for (i in seq(n)) {
    png(fn[i])
    plot(1:10,1:10,cex="*");
    dev.off()
}

ff <- subset(file.info(fn),select=size)
ff <- ff[!duplicated(ff$size),,drop=FALSE]
table(ff$size)
require(png)
pngs <- lapply(rownames(ff),readPNG)

png.to.img <- function(x) matrix(rgb(x[,,1],x[,,2],x[,,3]),
                                 nrow=dim(x)[1],ncol=dim(x)[2])

imgs <- lapply(pngs,png.to.img)

par(mfrow=c(2,2))
lapply(imgs,function(x) {
  plot(0:1,0:1,type="n",ann=FALSE,axes=FALSE)
  rasterImage(x,0,0,1,1)
})

#########################

> sessionInfo()
R Under development (unstable) (2011-10-06 r57181)
Platform: i686-pc-linux-gnu (32-bit)

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] glmmADMB_0.6.5 MASS_7.3-14    png_0.1-3

loaded via a namespace (and not attached):
[1] grid_2.15.0     lattice_0.19-33 nlme_3.1-102    tools_2.15.0


From pdalgd at gmail.com  Wed Nov 16 23:04:45 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 16 Nov 2011 23:04:45 +0100
Subject: [Rd] cygwin R-2.14.0 build fail
In-Reply-To: <4EC42656.6010704@gmail.com>
References: <1321107923.21160.YahooMailNeo@web27002.mail.ukl.yahoo.com>
	<4EC3D2BD.8070008@gmail.com>
	<alpine.LFD.2.02.1111162027520.28593@gannet.stats.ox.ac.uk>
	<4EC42656.6010704@gmail.com>
Message-ID: <5B230290-335A-4825-9C2A-D30E54028A43@gmail.com>


On Nov 16, 2011, at 22:08 , marco atzeri wrote:

> On 11/16/2011 9:32 PM, Prof Brian Ripley wrote:
>> The failures are *not* minor. Please don't distribute an R linked to a
>> broken BLAS library. Those tests are not for fun: they came from real
>> errors on real problems.
>> 
> 
> Dear Brian,
> I am reasonable sure that the cygwin blas library are fine, have
> you any evidence that they are broken ?
> 
> The R test log just reports an issue handling NA that could be
> related to cygwin difference to others platform.
> I already noted similar difference on cygwin octave package.
> 


Well, on other platforms we have

> tcrossprod(x,y)
     [,1] [,2] [,3]
[1,]   NA   NA   NA
[2,]    2    1    0
> x %*% t(y)
     [,1] [,2] [,3]
[1,]   NA   NA   NA
[2,]    2    1    0

so the Cygwin tcrossprod is implicitly letting 0*NA==0 (in the DGEMM BLAS routine). 

This is not what should happen according to the standards, and there are people whose code relies on standards compliance (and that's why the test is there).

It's also plain wrong, because in extended arithmetic, the missing value could be Inf, and 0*Inf == NaN, so assuming that 0*anything==0 doesn't work.

-pd

> Here is the log:
> --------------------------------------------------
> > ## PR#4582 %*% with NAs
> > stopifnot(is.na(NA %*% 0), is.na(0 %*% NA))
> > ## depended on the BLAS in use.
> >
> >
> > ## found from fallback test in slam 0.1-15
> > ## most likely indicates an inaedquate BLAS.
> > x <- matrix(c(1, 0, NA, 1), 2, 2)
> > y <- matrix(c(1, 0, 0, 2, 1, 0), 3, 2)
> > (z <- tcrossprod(x, y))
>     [,1] [,2] [,3]
> [1,]   NA   NA    0
> [2,]    2    1    0
> > stopifnot(identical(z, x %*% t(y)))
> Error: identical(z, x %*% t(y)) is not TRUE
> Execution halted
> tests/reg-BLAS.Rout.fail (END)
> --------------------------------------------------
> 
> Regards
> Marco
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From kevin.r.coombes at gmail.com  Wed Nov 16 23:15:29 2011
From: kevin.r.coombes at gmail.com (Kevin R. Coombes)
Date: Wed, 16 Nov 2011 16:15:29 -0600
Subject: [Rd] strange behavior from cex="*"
In-Reply-To: <4EC42D66.502@gmail.com>
References: <4EC42D66.502@gmail.com>
Message-ID: <4EC43601.5030604@gmail.com>

Hi Ben,

Just a few things to add.

First, the same phenomenon occurs when you use any character string as 
the value of cex; there is nothing special about "*".

Second, you cannot get this phenomenon by trying to do something like
     par(cex="*")
because the par function actually checks if the value is a nonnegative 
number.

Finally, producing the different graphs is clearly occuring inside the 
"plot.xy" function, although I have not yet caused R2.14 to hang. This 
at least suggests a fix: make sure that plot.xy checks the type of the 
cex argument in the same way that par does.

     Kevin

#######################
  xy <- xy.coords(1:10, 1:10)
  plot(xy)
  for(i in seq(100)) plot.xy(xy, "p", cex="*", col=i)
#######################

 > sessionInfo()
R version 2.14.0 (2011-10-31)
Platform: x86_64-pc-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] png_0.1-3

loaded via a namespace (and not attached):
[1] tools_2.14.0


On 11/16/2011 3:38 PM, Ben Bolker wrote:
>    Someone inquired on StackOverflow about apparently non-deterministic
> graphics behaviour in R.  I noticed that they were using cex="*" and
> discovered some potentially weird behavior.
>
>     On repeated runs of the same code I can get different PNGs.  If I set
> the number of runs high enough, I seem to be able to get R to hang.
> If I do a single version plotting to an interactive graphics window I
> can get the point sizes to jump around as I resize the window (someone
> reported being able to reproduce that behaviour in the Windows GUI as well).
>
>    This is clearly a user error, but non-deterministic behaviour (and
> hanging) are a little disturbing.
>
>    I haven't had a chance yet to try to dig in and see what's happening
> but thought I would report to see if anyone else could reproduce/figure
> it out.
>
>    Ben Bolker
>
>
> ########################
> ## n<- 100  ## hangs R
>
> n<- 33
>
> fn<- paste("tmp",seq(n),"png",sep=".")
> for (i in seq(n)) {
>      png(fn[i])
>      plot(1:10,1:10,cex="*");
>      dev.off()
> }
>
> ff<- subset(file.info(fn),select=size)
> ff<- ff[!duplicated(ff$size),,drop=FALSE]
> table(ff$size)
> require(png)
> pngs<- lapply(rownames(ff),readPNG)
>
> png.to.img<- function(x) matrix(rgb(x[,,1],x[,,2],x[,,3]),
>                                   nrow=dim(x)[1],ncol=dim(x)[2])
>
> imgs<- lapply(pngs,png.to.img)
>
> par(mfrow=c(2,2))
> lapply(imgs,function(x) {
>    plot(0:1,0:1,type="n",ann=FALSE,axes=FALSE)
>    rasterImage(x,0,0,1,1)
> })
>
> #########################
>
>> sessionInfo()
> R Under development (unstable) (2011-10-06 r57181)
> Platform: i686-pc-linux-gnu (32-bit)
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] glmmADMB_0.6.5 MASS_7.3-14    png_0.1-3
>
> loaded via a namespace (and not attached):
> [1] grid_2.15.0     lattice_0.19-33 nlme_3.1-102    tools_2.15.0
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From pdalgd at gmail.com  Wed Nov 16 23:18:43 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 16 Nov 2011 23:18:43 +0100
Subject: [Rd] strange behavior from cex="*"
In-Reply-To: <4EC42D66.502@gmail.com>
References: <4EC42D66.502@gmail.com>
Message-ID: <1C6B85B4-9803-407B-83BB-19159CCB2778@gmail.com>


On Nov 16, 2011, at 22:38 , Ben Bolker wrote:

>  Someone inquired on StackOverflow about apparently non-deterministic
> graphics behaviour in R.  I noticed that they were using cex="*" and
> discovered some potentially weird behavior.

It can be reproduced much more simply (well, not the hang, but bad enough):

In a plain R application console (OSX Snow Leopard),

for (i in 1:100) plot(1:10,cex="*")

will _sometimes_ show big circles, indicating random data being picked up. 

The "cex" is by definition numeric, so you can't expect to be able to pass a character string, but the code should check.

> 
>   On repeated runs of the same code I can get different PNGs.  If I set
> the number of runs high enough, I seem to be able to get R to hang.
> If I do a single version plotting to an interactive graphics window I
> can get the point sizes to jump around as I resize the window (someone
> reported being able to reproduce that behaviour in the Windows GUI as well).
> 
>  This is clearly a user error, but non-deterministic behaviour (and
> hanging) are a little disturbing.
> 
>  I haven't had a chance yet to try to dig in and see what's happening
> but thought I would report to see if anyone else could reproduce/figure
> it out.
> 
>  Ben Bolker
> 
> 
> ########################
> ## n <- 100  ## hangs R
> 
> n <- 33
> 
> fn <- paste("tmp",seq(n),"png",sep=".")
> for (i in seq(n)) {
>    png(fn[i])
>    plot(1:10,1:10,cex="*");
>    dev.off()
> }
> 
> ff <- subset(file.info(fn),select=size)
> ff <- ff[!duplicated(ff$size),,drop=FALSE]
> table(ff$size)
> require(png)
> pngs <- lapply(rownames(ff),readPNG)
> 
> png.to.img <- function(x) matrix(rgb(x[,,1],x[,,2],x[,,3]),
>                                 nrow=dim(x)[1],ncol=dim(x)[2])
> 
> imgs <- lapply(pngs,png.to.img)
> 
> par(mfrow=c(2,2))
> lapply(imgs,function(x) {
>  plot(0:1,0:1,type="n",ann=FALSE,axes=FALSE)
>  rasterImage(x,0,0,1,1)
> })
> 
> #########################
> 
>> sessionInfo()
> R Under development (unstable) (2011-10-06 r57181)
> Platform: i686-pc-linux-gnu (32-bit)
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] glmmADMB_0.6.5 MASS_7.3-14    png_0.1-3
> 
> loaded via a namespace (and not attached):
> [1] grid_2.15.0     lattice_0.19-33 nlme_3.1-102    tools_2.15.0
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From bbolker at gmail.com  Wed Nov 16 23:26:18 2011
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 16 Nov 2011 17:26:18 -0500
Subject: [Rd] strange behavior from cex="*"
In-Reply-To: <1C6B85B4-9803-407B-83BB-19159CCB2778@gmail.com>
References: <4EC42D66.502@gmail.com>
	<1C6B85B4-9803-407B-83BB-19159CCB2778@gmail.com>
Message-ID: <4EC4388A.6070502@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 11-11-16 05:18 PM, peter dalgaard wrote:
> 
> On Nov 16, 2011, at 22:38 , Ben Bolker wrote:
> 
>>  Someone inquired on StackOverflow about apparently non-deterministic
>> graphics behaviour in R.  I noticed that they were using cex="*" and
>> discovered some potentially weird behavior.
> 
> It can be reproduced much more simply (well, not the hang, but bad enough):
> 
> In a plain R application console (OSX Snow Leopard),
> 
> for (i in 1:100) plot(1:10,cex="*")
> 
> will _sometimes_ show big circles, indicating random data being picked up. 
> 
> The "cex" is by definition numeric, so you can't expect to be able to pass a character string, but the code should check.

 Looks (?) like the check could go in FixupCex (which already tests for
isReal, isInteger, and isLogical) in src/main/plot.c , unless there is a
wish to catch it earlier/in R code.

  It's mildly surprising to me that people can continue to find odd
cases like this after more than 10 years (and imagine how many
cumulative hours of R use ...) [I'm assuming that this hole has been
present for a log time: I don't have the patience to do the SVN
archaeology to find out how long.]

> 
>>
>>   On repeated runs of the same code I can get different PNGs.  If I set
>> the number of runs high enough, I seem to be able to get R to hang.
>> If I do a single version plotting to an interactive graphics window I
>> can get the point sizes to jump around as I resize the window (someone
>> reported being able to reproduce that behaviour in the Windows GUI as well).
>>
>>  This is clearly a user error, but non-deterministic behaviour (and
>> hanging) are a little disturbing.
>>
>>  I haven't had a chance yet to try to dig in and see what's happening
>> but thought I would report to see if anyone else could reproduce/figure
>> it out.
>>
>>  Ben Bolker
>>
>>
>> ########################
>> ## n <- 100  ## hangs R
>>
>> n <- 33
>>
>> fn <- paste("tmp",seq(n),"png",sep=".")
>> for (i in seq(n)) {
>>    png(fn[i])
>>    plot(1:10,1:10,cex="*");
>>    dev.off()
>> }
>>
>> ff <- subset(file.info(fn),select=size)
>> ff <- ff[!duplicated(ff$size),,drop=FALSE]
>> table(ff$size)
>> require(png)
>> pngs <- lapply(rownames(ff),readPNG)
>>
>> png.to.img <- function(x) matrix(rgb(x[,,1],x[,,2],x[,,3]),
>>                                 nrow=dim(x)[1],ncol=dim(x)[2])
>>
>> imgs <- lapply(pngs,png.to.img)
>>
>> par(mfrow=c(2,2))
>> lapply(imgs,function(x) {
>>  plot(0:1,0:1,type="n",ann=FALSE,axes=FALSE)
>>  rasterImage(x,0,0,1,1)
>> })
>>
>> #########################
>>
>>> sessionInfo()
>> R Under development (unstable) (2011-10-06 r57181)
>> Platform: i686-pc-linux-gnu (32-bit)
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] glmmADMB_0.6.5 MASS_7.3-14    png_0.1-3
>>
>> loaded via a namespace (and not attached):
>> [1] grid_2.15.0     lattice_0.19-33 nlme_3.1-102    tools_2.15.0
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iQEcBAEBAgAGBQJOxDiKAAoJED2whTVMEyK9ThoIAIjyMpzZqsjUpJVbAb9K8IrL
LbSFh8zb+cZb90ABkFwJaZ2FNTKCjPrUzOYzxxHuU9AY0bdPQGbIm2hvQfzcuMlc
urS/ILIMzZEFSYkqkj0mWI9SADyJ+W0YeN/t3EuWy8nZqUkYQZ8M0GsuXjhtUL/i
hVJU0uuIWCOCHpeI3SQKoxviTE6MQFRXXWhCAJx01h8ee/5UQ5GSGB7Er2Zilld3
0sLI6dmoF7gbeYqz33MaEpQ7geJoW3tfnVbQWUlF86+jGGv5trIqWYIp33OYIxMO
u2YUq51vB+4uIRPFJ4Oyr+nJF0Z9NH4IJBipp/bF6wQ5u6JdXFqKTPeQ1V6m5qk=
=YajM
-----END PGP SIGNATURE-----


From jorismeys at gmail.com  Wed Nov 16 23:39:39 2011
From: jorismeys at gmail.com (Joris Meys)
Date: Wed, 16 Nov 2011 23:39:39 +0100
Subject: [Rd] strange behavior from cex="*"
In-Reply-To: <4EC4388A.6070502@gmail.com>
References: <4EC42D66.502@gmail.com>
	<1C6B85B4-9803-407B-83BB-19159CCB2778@gmail.com>
	<4EC4388A.6070502@gmail.com>
Message-ID: <CAO1zAVZDfTZOS6PrK7Fnc0bDhQv4SOBJ6WE9GTXhxe9U00iMgA@mail.gmail.com>

On Wed, Nov 16, 2011 at 11:26 PM, Ben Bolker <bbolker at gmail.com> wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
> ?It's mildly surprising to me that people can continue to find odd
> cases like this after more than 10 years (and imagine how many
> cumulative hours of R use ...)

Mildly surprising? It's astonishing once you realize that for more
than 10 years people were actually using the cex argument as intended.
There is hope for mankind after all... :-)
-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From marco.atzeri at gmail.com  Thu Nov 17 00:34:01 2011
From: marco.atzeri at gmail.com (marco atzeri)
Date: Thu, 17 Nov 2011 00:34:01 +0100
Subject: [Rd] cygwin R-2.14.0 build fail
In-Reply-To: <5B230290-335A-4825-9C2A-D30E54028A43@gmail.com>
References: <1321107923.21160.YahooMailNeo@web27002.mail.ukl.yahoo.com>
	<4EC3D2BD.8070008@gmail.com>
	<alpine.LFD.2.02.1111162027520.28593@gannet.stats.ox.ac.uk>
	<4EC42656.6010704@gmail.com>
	<5B230290-335A-4825-9C2A-D30E54028A43@gmail.com>
Message-ID: <4EC44869.3040206@gmail.com>

On 11/16/2011 11:04 PM, peter dalgaard wrote:
>
> On Nov 16, 2011, at 22:08 , marco atzeri wrote:
>
>> On 11/16/2011 9:32 PM, Prof Brian Ripley wrote:
>>> The failures are *not* minor. Please don't distribute an R linked to a
>>> broken BLAS library. Those tests are not for fun: they came from real
>>> errors on real problems.
>>>
>>
>> Dear Brian,
>> I am reasonable sure that the cygwin blas library are fine, have
>> you any evidence that they are broken ?
>>
>> The R test log just reports an issue handling NA that could be
>> related to cygwin difference to others platform.
>> I already noted similar difference on cygwin octave package.
>>
>
>
> Well, on other platforms we have
>
>> tcrossprod(x,y)
>       [,1] [,2] [,3]
> [1,]   NA   NA   NA
> [2,]    2    1    0
>> x %*% t(y)
>       [,1] [,2] [,3]
> [1,]   NA   NA   NA
> [2,]    2    1    0
>
> so the Cygwin tcrossprod is implicitly letting 0*NA==0 (in the DGEMM BLAS routine).
>
> This is not what should happen according to the standards, and there are people whose code relies on standards compliance (and that's why the test is there).
>
> It's also plain wrong, because in extended arithmetic, the missing value could be Inf, and 0*Inf == NaN, so assuming that 0*anything==0 doesn't work.
>
> -pd
>

I presume it is a netlib DGEMM issue and not a specific cygwin port issue.

There is an optimization on the reference implementation:
http://www.netlib.org/lapack/explore-html/d7/d2b/dgemm_8f_source.html

00314                       IF (B(L,J).NE.ZERO) THEN

that fool any 0*NaN or 0*Inf case


I noticed it was highlighted on octave mailing list long time ago:
http://octave.1599824.n4.nabble.com/NaN-problem-td1662846.html

Time to rise the bug with netlib guys ?

Regards
Marco


From murdoch.duncan at gmail.com  Thu Nov 17 01:29:34 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 16 Nov 2011 19:29:34 -0500
Subject: [Rd] strange behavior from cex="*"
In-Reply-To: <4EC4388A.6070502@gmail.com>
References: <4EC42D66.502@gmail.com>
	<1C6B85B4-9803-407B-83BB-19159CCB2778@gmail.com>
	<4EC4388A.6070502@gmail.com>
Message-ID: <4EC4556E.4050507@gmail.com>

On 11-11-16 5:26 PM, Ben Bolker wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> On 11-11-16 05:18 PM, peter dalgaard wrote:
>>
>> On Nov 16, 2011, at 22:38 , Ben Bolker wrote:
>>
>>>   Someone inquired on StackOverflow about apparently non-deterministic
>>> graphics behaviour in R.  I noticed that they were using cex="*" and
>>> discovered some potentially weird behavior.
>>
>> It can be reproduced much more simply (well, not the hang, but bad enough):
>>
>> In a plain R application console (OSX Snow Leopard),
>>
>> for (i in 1:100) plot(1:10,cex="*")
>>
>> will _sometimes_ show big circles, indicating random data being picked up.
>>
>> The "cex" is by definition numeric, so you can't expect to be able to pass a character string, but the code should check.
>
>   Looks (?) like the check could go in FixupCex (which already tests for
> isReal, isInteger, and isLogical) in src/main/plot.c , unless there is a
> wish to catch it earlier/in R code.

Yes, that's where the check was missed.  I'll fix it.  The other 
parameters appear to have been checked properly.

>    It's mildly surprising to me that people can continue to find odd
> cases like this after more than 10 years (and imagine how many
> cumulative hours of R use ...) [I'm assuming that this hole has been
> present for a log time: I don't have the patience to do the SVN
> archaeology to find out how long.]

So now you can prove me wrong about the other parameters...

Duncan Murdoch


>
>>
>>>
>>>    On repeated runs of the same code I can get different PNGs.  If I set
>>> the number of runs high enough, I seem to be able to get R to hang.
>>> If I do a single version plotting to an interactive graphics window I
>>> can get the point sizes to jump around as I resize the window (someone
>>> reported being able to reproduce that behaviour in the Windows GUI as well).
>>>
>>>   This is clearly a user error, but non-deterministic behaviour (and
>>> hanging) are a little disturbing.
>>>
>>>   I haven't had a chance yet to try to dig in and see what's happening
>>> but thought I would report to see if anyone else could reproduce/figure
>>> it out.
>>>
>>>   Ben Bolker
>>>
>>>
>>> ########################
>>> ## n<- 100  ## hangs R
>>>
>>> n<- 33
>>>
>>> fn<- paste("tmp",seq(n),"png",sep=".")
>>> for (i in seq(n)) {
>>>     png(fn[i])
>>>     plot(1:10,1:10,cex="*");
>>>     dev.off()
>>> }
>>>
>>> ff<- subset(file.info(fn),select=size)
>>> ff<- ff[!duplicated(ff$size),,drop=FALSE]
>>> table(ff$size)
>>> require(png)
>>> pngs<- lapply(rownames(ff),readPNG)
>>>
>>> png.to.img<- function(x) matrix(rgb(x[,,1],x[,,2],x[,,3]),
>>>                                  nrow=dim(x)[1],ncol=dim(x)[2])
>>>
>>> imgs<- lapply(pngs,png.to.img)
>>>
>>> par(mfrow=c(2,2))
>>> lapply(imgs,function(x) {
>>>   plot(0:1,0:1,type="n",ann=FALSE,axes=FALSE)
>>>   rasterImage(x,0,0,1,1)
>>> })
>>>
>>> #########################
>>>
>>>> sessionInfo()
>>> R Under development (unstable) (2011-10-06 r57181)
>>> Platform: i686-pc-linux-gnu (32-bit)
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>> [1] glmmADMB_0.6.5 MASS_7.3-14    png_0.1-3
>>>
>>> loaded via a namespace (and not attached):
>>> [1] grid_2.15.0     lattice_0.19-33 nlme_3.1-102    tools_2.15.0
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.10 (GNU/Linux)
> Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/
>
> iQEcBAEBAgAGBQJOxDiKAAoJED2whTVMEyK9ThoIAIjyMpzZqsjUpJVbAb9K8IrL
> LbSFh8zb+cZb90ABkFwJaZ2FNTKCjPrUzOYzxxHuU9AY0bdPQGbIm2hvQfzcuMlc
> urS/ILIMzZEFSYkqkj0mWI9SADyJ+W0YeN/t3EuWy8nZqUkYQZ8M0GsuXjhtUL/i
> hVJU0uuIWCOCHpeI3SQKoxviTE6MQFRXXWhCAJx01h8ee/5UQ5GSGB7Er2Zilld3
> 0sLI6dmoF7gbeYqz33MaEpQ7geJoW3tfnVbQWUlF86+jGGv5trIqWYIp33OYIxMO
> u2YUq51vB+4uIRPFJ4Oyr+nJF0Z9NH4IJBipp/bF6wQ5u6JdXFqKTPeQ1V6m5qk=
> =YajM
> -----END PGP SIGNATURE-----
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hpages at fhcrc.org  Thu Nov 17 07:40:23 2011
From: hpages at fhcrc.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Wed, 16 Nov 2011 22:40:23 -0800
Subject: [Rd] inaccuracy in man page for duplicated() + anyDuplicated() not
 working with MARGIN=0
Message-ID: <4EC4AC57.5030007@fhcrc.org>

Hi,

In man page for duplicated:

   Value:

      ?duplicated()?: For a vector input, a logical vector of the same
      length as ?x?.  For a data frame, a logical vector with one
      element for each row.  For a matrix or array, a logical array with
      the same dimensions and dimnames.

When 'x' is a matrix or array, the returned value is NOT a logical
array:

   > m <- matrix(c(3,2,7,6,2,7), nrow=3)
   > m
        [,1] [,2]
   [1,]    3    6
   [2,]    2    2
   [3,]    7    7
   > duplicated(m)
   [1] FALSE FALSE FALSE

Only if MARGIN=0 it seems:

   > duplicated(m, MARGIN=0)
         [,1]  [,2]
   [1,] FALSE FALSE
   [2,] FALSE  TRUE
   [3,] FALSE  TRUE

Also, any reason why this doesn't work?

   > anyDuplicated(m, MARGIN=0)
   Error in dim(newX) <- c(prod(d.call), d2) :
     dims [product 1] do not match the length of object [6]

May be it could be equivalent to:

   > anyDuplicated(as.vector(m))
   [1] 5

Thanks,
H.

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From ligges at statistik.tu-dortmund.de  Thu Nov 17 10:11:30 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 17 Nov 2011 10:11:30 +0100
Subject: [Rd] cygwin R-2.14.0 build fail
In-Reply-To: <4EC44869.3040206@gmail.com>
References: <1321107923.21160.YahooMailNeo@web27002.mail.ukl.yahoo.com>
	<4EC3D2BD.8070008@gmail.com>
	<alpine.LFD.2.02.1111162027520.28593@gannet.stats.ox.ac.uk>
	<4EC42656.6010704@gmail.com>
	<5B230290-335A-4825-9C2A-D30E54028A43@gmail.com>
	<4EC44869.3040206@gmail.com>
Message-ID: <4EC4CFC2.7040407@statistik.tu-dortmund.de>



On 17.11.2011 00:34, marco atzeri wrote:
> On 11/16/2011 11:04 PM, peter dalgaard wrote:
>>
>> On Nov 16, 2011, at 22:08 , marco atzeri wrote:
>>
>>> On 11/16/2011 9:32 PM, Prof Brian Ripley wrote:
>>>> The failures are *not* minor. Please don't distribute an R linked to a
>>>> broken BLAS library. Those tests are not for fun: they came from real
>>>> errors on real problems.
>>>>
>>>
>>> Dear Brian,
>>> I am reasonable sure that the cygwin blas library are fine, have
>>> you any evidence that they are broken ?
>>>
>>> The R test log just reports an issue handling NA that could be
>>> related to cygwin difference to others platform.
>>> I already noted similar difference on cygwin octave package.
>>>
>>
>>
>> Well, on other platforms we have
>>
>>> tcrossprod(x,y)
>> [,1] [,2] [,3]
>> [1,] NA NA NA
>> [2,] 2 1 0
>>> x %*% t(y)
>> [,1] [,2] [,3]
>> [1,] NA NA NA
>> [2,] 2 1 0
>>
>> so the Cygwin tcrossprod is implicitly letting 0*NA==0 (in the DGEMM
>> BLAS routine).
>>
>> This is not what should happen according to the standards, and there
>> are people whose code relies on standards compliance (and that's why
>> the test is there).
>>
>> It's also plain wrong, because in extended arithmetic, the missing
>> value could be Inf, and 0*Inf == NaN, so assuming that 0*anything==0
>> doesn't work.
>>
>> -pd
>>
>
> I presume it is a netlib DGEMM issue and not a specific cygwin port issue.
>
> There is an optimization on the reference implementation:
> http://www.netlib.org/lapack/explore-html/d7/d2b/dgemm_8f_source.html
>
> 00314 IF (B(L,J).NE.ZERO) THEN
>
> that fool any 0*NaN or 0*Inf case
>
>
> I noticed it was highlighted on octave mailing list long time ago:
> http://octave.1599824.n4.nabble.com/NaN-problem-td1662846.html
>
> Time to rise the bug with netlib guys ?

Everybody in this discussion invested too much time on it already. If 
you want to provide cygwin support for others, go ahead and tackle the 
problems, but don't distribute incorrectly working versions of R.

Best,
Uwe Ligges



> Regards
> Marco
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Thu Nov 17 12:20:21 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 17 Nov 2011 12:20:21 +0100
Subject: [Rd] inaccuracy in man page for duplicated() + anyDuplicated()
 not working with MARGIN=0
In-Reply-To: <4EC4AC57.5030007@fhcrc.org>
References: <4EC4AC57.5030007@fhcrc.org>
Message-ID: <20164.60917.946391.189174@stat.math.ethz.ch>


> Hi,
> In man page for duplicated:

>    Value:

>       ?duplicated()?: For a vector input, a logical vector of the same
>       length as ?x?.  For a data frame, a logical vector with one
>       element for each row.  For a matrix or array, a logical array with
>       the same dimensions and dimnames.

> When 'x' is a matrix or array, the returned value is NOT a logical
> array:

>    > m <- matrix(c(3,2,7,6,2,7), nrow=3)
>    > m
>         [,1] [,2]
>    [1,]    3    6
>    [2,]    2    2
>    [3,]    7    7
>    > duplicated(m)
>    [1] FALSE FALSE FALSE

> Only if MARGIN=0 it seems:

>    > duplicated(m, MARGIN=0)
>          [,1]  [,2]
>    [1,] FALSE FALSE
>    [2,] FALSE  TRUE
>    [3,] FALSE  TRUE

Indeed. Thank you for pointing this out.
I'll definitely fix that part of the help file.

> Also, any reason why this doesn't work?

>    > anyDuplicated(m, MARGIN=0)
>    Error in dim(newX) <- c(prod(d.call), d2) :
>      dims [product 1] do not match the length of object [6]

well, because the R core colleague enhanced duplicated.array()
to work with MARGIN 0 (and similar cases) did not
update the parallel code in anyDuplicated.array() correspondingly.

> May be it could be equivalent to:

>    > anyDuplicated(as.vector(m))
>    [1] 5

Yes, that's what will happen after I've committed my fixes.

Thank you very much, Herv?!
Martin

[...]

> -- 
> Herv? Pag?s
[...]

(*) having authored anyDuplicated()


From marco.atzeri at gmail.com  Thu Nov 17 12:33:02 2011
From: marco.atzeri at gmail.com (marco atzeri)
Date: Thu, 17 Nov 2011 12:33:02 +0100
Subject: [Rd] cygwin R-2.14.0 build fail
In-Reply-To: <4EC4CFC2.7040407@statistik.tu-dortmund.de>
References: <1321107923.21160.YahooMailNeo@web27002.mail.ukl.yahoo.com>
	<4EC3D2BD.8070008@gmail.com>
	<alpine.LFD.2.02.1111162027520.28593@gannet.stats.ox.ac.uk>
	<4EC42656.6010704@gmail.com>
	<5B230290-335A-4825-9C2A-D30E54028A43@gmail.com>
	<4EC44869.3040206@gmail.com>
	<4EC4CFC2.7040407@statistik.tu-dortmund.de>
Message-ID: <4EC4F0EE.2040508@gmail.com>

On 11/17/2011 10:11 AM, Uwe Ligges wrote:

> Everybody in this discussion invested too much time on it already. If
> you want to provide cygwin support for others, go ahead and tackle the
> problems, but don't distribute incorrectly working versions of R.
>
Dear Uwe,

first test versions are always by definition incorrectly
working versions.

Reading
http://cran.r-project.org/doc/manuals/R-admin.html#BLAS
http://cran.r-project.org/doc/manuals/R-admin.html#LAPACK

it is clear that R relies with its internal BLAS and Lapack 
implementation, differently from a lot of other packages.
May I suggest to add an additional note that also
external BLAS is not recommended as done for LAPACK.

It will be also worth to add a "not recommended" on the
   configure --help
output

   --with-blas             use system BLAS library (if available),
                           or specify it [no]
   --with-lapack           use system LAPACK library (if available),
                           or specify it [no]

as it is not obvious and it could mislead newcomers like me.

> Best,
> Uwe Ligges

Best Regards
Marco


From murdoch.duncan at gmail.com  Thu Nov 17 13:18:36 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 17 Nov 2011 07:18:36 -0500
Subject: [Rd] strange behavior from cex="*"
In-Reply-To: <4EC4556E.4050507@gmail.com>
References: <4EC42D66.502@gmail.com>
	<1C6B85B4-9803-407B-83BB-19159CCB2778@gmail.com>
	<4EC4388A.6070502@gmail.com> <4EC4556E.4050507@gmail.com>
Message-ID: <4EC4FB9C.8000308@gmail.com>

On 11-11-16 7:29 PM, Duncan Murdoch wrote:
> On 11-11-16 5:26 PM, Ben Bolker wrote:
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA1
>>
>> On 11-11-16 05:18 PM, peter dalgaard wrote:
>>>
>>> On Nov 16, 2011, at 22:38 , Ben Bolker wrote:
>>>
>>>>    Someone inquired on StackOverflow about apparently non-deterministic
>>>> graphics behaviour in R.  I noticed that they were using cex="*" and
>>>> discovered some potentially weird behavior.
>>>
>>> It can be reproduced much more simply (well, not the hang, but bad enough):
>>>
>>> In a plain R application console (OSX Snow Leopard),
>>>
>>> for (i in 1:100) plot(1:10,cex="*")
>>>
>>> will _sometimes_ show big circles, indicating random data being picked up.
>>>
>>> The "cex" is by definition numeric, so you can't expect to be able to pass a character string, but the code should check.
>>
>>    Looks (?) like the check could go in FixupCex (which already tests for
>> isReal, isInteger, and isLogical) in src/main/plot.c , unless there is a
>> wish to catch it earlier/in R code.
>
> Yes, that's where the check was missed.  I'll fix it.  The other
> parameters appear to have been checked properly.

Now fixed in R-devel and R-patched.

Duncan Murdoch


From ligges at statistik.tu-dortmund.de  Thu Nov 17 14:12:34 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 17 Nov 2011 14:12:34 +0100
Subject: [Rd] cygwin R-2.14.0 build fail
In-Reply-To: <4EC4F0EE.2040508@gmail.com>
References: <1321107923.21160.YahooMailNeo@web27002.mail.ukl.yahoo.com>
	<4EC3D2BD.8070008@gmail.com>
	<alpine.LFD.2.02.1111162027520.28593@gannet.stats.ox.ac.uk>
	<4EC42656.6010704@gmail.com>
	<5B230290-335A-4825-9C2A-D30E54028A43@gmail.com>
	<4EC44869.3040206@gmail.com>
	<4EC4CFC2.7040407@statistik.tu-dortmund.de>
	<4EC4F0EE.2040508@gmail.com>
Message-ID: <4EC50842.6040006@statistik.tu-dortmund.de>



On 17.11.2011 12:33, marco atzeri wrote:
> On 11/17/2011 10:11 AM, Uwe Ligges wrote:
>
>> Everybody in this discussion invested too much time on it already. If
>> you want to provide cygwin support for others, go ahead and tackle the
>> problems, but don't distribute incorrectly working versions of R.
>>
> Dear Uwe,
>
> first test versions are always by definition incorrectly
> working versions.
>
> Reading
> http://cran.r-project.org/doc/manuals/R-admin.html#BLAS
> http://cran.r-project.org/doc/manuals/R-admin.html#LAPACK
>
> it is clear that R relies with its internal BLAS and Lapack
> implementation, differently from a lot of other packages.
> May I suggest to add an additional note that also
> external BLAS is not recommended as done for LAPACK.
>
> It will be also worth to add a "not recommended" on the
> configure --help
> output
>
> --with-blas use system BLAS library (if available),
> or specify it [no]
> --with-lapack use system LAPACK library (if available),
> or specify it [no]
>
> as it is not obvious and it could mislead newcomers like me.

External BLASs work for me perfectly on other platforms than cygwin. 
Hence it is cygwin that I would not recommend given the native Windows 
version is both faster and passes the checks.

Uwe Ligges



>> Best,
>> Uwe Ligges
>
> Best Regards
> Marco
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From marco.atzeri at gmail.com  Thu Nov 17 15:53:57 2011
From: marco.atzeri at gmail.com (marco atzeri)
Date: Thu, 17 Nov 2011 15:53:57 +0100
Subject: [Rd] cygwin R-2.14.0 build fail
In-Reply-To: <4EC50842.6040006@statistik.tu-dortmund.de>
References: <1321107923.21160.YahooMailNeo@web27002.mail.ukl.yahoo.com>
	<4EC3D2BD.8070008@gmail.com>
	<alpine.LFD.2.02.1111162027520.28593@gannet.stats.ox.ac.uk>
	<4EC42656.6010704@gmail.com>
	<5B230290-335A-4825-9C2A-D30E54028A43@gmail.com>
	<4EC44869.3040206@gmail.com>
	<4EC4CFC2.7040407@statistik.tu-dortmund.de>
	<4EC4F0EE.2040508@gmail.com>
	<4EC50842.6040006@statistik.tu-dortmund.de>
Message-ID: <4EC52005.6090609@gmail.com>

On 11/17/2011 2:12 PM, Uwe Ligges wrote:

>
> External BLASs work for me perfectly on other platforms than cygwin.
> Hence it is cygwin that I would not recommend given the native Windows
> version is both faster and passes the checks.
>
> Uwe Ligges
>

Yeah,
I am almost sure that your view as R developer and mine as
package maintainer for several math packages in cygwin do not match.

If speed was the only parameter for a solution choice ,
we should all only use Linux for math and Windows for games.

From
http://bugs.r-project.org/bugzilla3/show_bug.cgi?id=4582

it is clear that R expectation from a BLAS library is different from
the netlib BLAS reference implementation and I presume it happens also
on any Linux using the netlib BLAS, so I do not see it as a specific
cygwin bug.


Regards and Thanks for your time
Marco


From hpages at fhcrc.org  Thu Nov 17 19:10:45 2011
From: hpages at fhcrc.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Thu, 17 Nov 2011 10:10:45 -0800
Subject: [Rd] inaccuracy in man page for duplicated() + anyDuplicated()
 not working with MARGIN=0
In-Reply-To: <20164.60917.946391.189174@stat.math.ethz.ch>
References: <4EC4AC57.5030007@fhcrc.org>
	<20164.60917.946391.189174@stat.math.ethz.ch>
Message-ID: <4EC54E25.7090504@fhcrc.org>

Sounds good. Thanks Martin!  H.

On 11-11-17 03:20 AM, Martin Maechler wrote:
>
>> Hi,
>> In man page for duplicated:
>
>>     Value:
>
>>        ?duplicated()?: For a vector input, a logical vector of the same
>>        length as ?x?.  For a data frame, a logical vector with one
>>        element for each row.  For a matrix or array, a logical array with
>>        the same dimensions and dimnames.
>
>> When 'x' is a matrix or array, the returned value is NOT a logical
>> array:
>
>>     >  m<- matrix(c(3,2,7,6,2,7), nrow=3)
>>     >  m
>>          [,1] [,2]
>>     [1,]    3    6
>>     [2,]    2    2
>>     [3,]    7    7
>>     >  duplicated(m)
>>     [1] FALSE FALSE FALSE
>
>> Only if MARGIN=0 it seems:
>
>>     >  duplicated(m, MARGIN=0)
>>           [,1]  [,2]
>>     [1,] FALSE FALSE
>>     [2,] FALSE  TRUE
>>     [3,] FALSE  TRUE
>
> Indeed. Thank you for pointing this out.
> I'll definitely fix that part of the help file.
>
>> Also, any reason why this doesn't work?
>
>>     >  anyDuplicated(m, MARGIN=0)
>>     Error in dim(newX)<- c(prod(d.call), d2) :
>>       dims [product 1] do not match the length of object [6]
>
> well, because the R core colleague enhanced duplicated.array()
> to work with MARGIN 0 (and similar cases) did not
> update the parallel code in anyDuplicated.array() correspondingly.
>
>> May be it could be equivalent to:
>
>>     >  anyDuplicated(as.vector(m))
>>     [1] 5
>
> Yes, that's what will happen after I've committed my fixes.
>
> Thank you very much, Herv?!
> Martin
>
> [...]
>
>> --
>> Herv? Pag?s
> [...]
>
> (*) having authored anyDuplicated()
>


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From gwgc5 at mail.missouri.edu  Thu Nov 17 18:09:30 2011
From: gwgc5 at mail.missouri.edu (Raymond)
Date: Thu, 17 Nov 2011 09:09:30 -0800 (PST)
Subject: [Rd] .Call in R
Message-ID: <1321549770463-4080721.post@n4.nabble.com>

Hi R developers,

    I am new to this forum and hope someone can help me with .Call in R.
Greatly appreciate any help!

    Say, I have a vector called "vecA" of length 10000, I generate a vector
called "vecR" with elements randomly generated from Uniform[0,1]. Both vecA
and vecR are of double type. I want to replace elements vecA by elements in
vecR only if sum of elements in vecR is greater than or equal to 5000.
Otherwise, vecR remain unchanged. This is easy to do in R, which reads
    vecA<-something;
    vecR<-runif(10000);
    if (sum(vecR)>=5000)){
       vecA<-vecR;
    }


    Now my question is, if I am going to do the same thing in R using .Call.
How can I achieve it in a more efficient way (i.e. less computation time
compared with pure R code above.).  My c code (called "change_vecA.c") using
.Call is like this:

    SEXP change_vecA(SEXP vecA){
         int i,vecA_len;
         double sum,*res_ptr,*vecR_ptr,*vecA_ptr;

         vecA_ptr=REAL(vecA);
         vecA_len=length(vecA);
         SEXP res_vec,vecR;

         PROTECT(res_vec=allocVector(REALSXP, vec_len));
         PROTECT(vecR=allocVector(REALSXP, vec_len));
         res_ptr=REAL(res_vec);
         vecR_ptr=REAL(vecR);
         GetRNGstate();
         sum=0.0;
         for (i=0;i<vecA_len;i++){
              vecR_ptr[i]=runif(0,1);
              sum+=vecR_ptr[i];
         }
         if (sum>=5000){
            /*copy vecR to the vector to be returned*/
            for (i=0;i<vecA_len;i++){
                  res_ptr[i]=vecR_ptr[i];
            }
         }
         else{
                /*copy vecA to the vector to be returned*/
                for (i=0;i<vecA_len;i++){
                      res_ptr[i]=vecA_ptr[i];
                }
         }

         PutRNGstate();
         UNPROTECT(2);
         resturn(res);
}
My R wrapper function is
        change_vecA<-function(vecA){
              dyn.load("change_vecA.so");
              .Call("change_vecA",vecA);
        }
   
         Now my question is, due to two loops (one generates the random
vector and one determines the vector to be returned), can .Call still be
faster than pure R code (only one loop to copy vecR to vecA given condition
is met)? Or, how can I improve my c code to avoid redundant loops if any. My
concern is if vecA is large (say of length 1000000 or even bigger), loops in
C code can slow things down.  Thanks for any help!  

          



--
View this message in context: http://r.789695.n4.nabble.com/Call-in-R-tp4080721p4080721.html
Sent from the R devel mailing list archive at Nabble.com.


From jordigh at octave.org  Thu Nov 17 19:06:32 2011
From: jordigh at octave.org (=?UTF-8?Q?Jordi_Guti=C3=A9rrez_Hermoso?=)
Date: Thu, 17 Nov 2011 13:06:32 -0500
Subject: [Rd] Non-free packages in CRAN
Message-ID: <CAPHS2gwarCZPEVha2e6+tXx2WnA3Ys41ZFvZZgYYcstQk73Cmg@mail.gmail.com>

Hello.

This is in relation to the discussion below:

    http://sourceforge.net/mailarchive/forum.php?thread_name=CAPHS2gwmxJGF9Cy8%3DSEGasQcVRg_Lqu-ndCdVhO-r1LJsRQGuA%40mail.gmail.com&forum_name=octave-dev

If this is the wrong place to discuss this issue, I would be thankful
for a redirection to the appropriate forum.

As Henrik says, R or some organisation that acts in R's name, has
accepted his non-free plugin:

    http://rmosek.r-forge.r-project.org/

Yes, it is non-free, even if it's LGPL, because it's linking to both R
and MOSEK, which is a GPL+proprietary whole. There is no actual GPL
violation because it's avoiding binary distribution. However, I'm
concerned with the overall message this sends.

I was under the impression that R is part of the GNU project, and as
an Octave developer, I have thought of R as being a fellow GNU-in-arms
comrade. I have proudly recommended R to people, both on technical
merits and sound philosophical principles. I don't see R as a
competitor to Octave, but as an esteemed colleague.

I am, however, a little concerned that R seems to be endorsing a
project that is in turn endorsing non-free software. This seems to be
against what an important aspect of what GNU should do: promote free
software and discourage the proliferation of non-free software. While
you may argue that the plugin is free, it is absolutely useless
without the non-free package, so R is ultimately recommending its
users to use a non-free package. This seems like a problem to me.

I see several possible solutions:

    1) R could stop calling itself part of the GNU project. This would
       make me very sad, and I hope R doesn't take this route. As I
       said, I'm proud to be part of the same organisation that R is
       currently part of.

    2) R could stop endorsing R-Forge. This obviously seems like a
       much worse alternative.

    3) R-Forge could remove the offending package. I also hope it
       doesn't come to this.

    4) The authors of MOSEK could make it free. Note: "free" does not
       mean "money is forbidden". One option for MOSEK could be to
       dual-license it: MOSEK is GPL, but anyone who wants to lock it
       up has to pay for alternative license terms. FFTW and Qt are
       two prominent free commercial packages that have followed this
       route.

I really would much prefer (4), or if it can't be achieved, (3). But I
encourage the R users and contributors to support the aims of the GNU
project and to stand together with the Octave community in this
regard.

Thank you for your time,
- Jordi G. H.


From edd at debian.org  Thu Nov 17 22:04:58 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 17 Nov 2011 15:04:58 -0600
Subject: [Rd] .Call in R
In-Reply-To: <1321549770463-4080721.post@n4.nabble.com>
References: <1321549770463-4080721.post@n4.nabble.com>
Message-ID: <20165.30458.587277.817354@max.nulle.part>


On 17 November 2011 at 09:09, Raymond wrote:
| Hi R developers,
| 
|     I am new to this forum and hope someone can help me with .Call in R.
| Greatly appreciate any help!
| 
|     Say, I have a vector called "vecA" of length 10000, I generate a vector
| called "vecR" with elements randomly generated from Uniform[0,1]. Both vecA
| and vecR are of double type. I want to replace elements vecA by elements in
| vecR only if sum of elements in vecR is greater than or equal to 5000.
| Otherwise, vecR remain unchanged. This is easy to do in R, which reads
|     vecA<-something;
|     vecR<-runif(10000);
|     if (sum(vecR)>=5000)){
|        vecA<-vecR;
|     }
| 
| 
|     Now my question is, if I am going to do the same thing in R using .Call.
| How can I achieve it in a more efficient way (i.e. less computation time
| compared with pure R code above.).  My c code (called "change_vecA.c") using
| .Call is like this:

Here is my take on it, using about the same number of commands in C++ thanks
to Rcpp and its vectorised sum() and runif() commands (which mimick the R
commands):

R> library(inline)
R> library(Rcpp)
R> 
R> set.seed(42)         # fix RNG seed
R> vecA <- rt(10000, 6) # 'something' in vecA: t-dist with 6 df
R> 
R> fun <- cxxfunction(signature(va="numeric"), # pass in a vector
+                    plugin="Rcpp",      # use Rcpp, and code below
+                    body='
+ 
+    Rcpp::NumericVector vA(va);
+    Rcpp::RNGScope tmp;                     // make sure RNG is set up
+    Rcpp::NumericVector vR = runif(10000);  // 10k of a U(0,1)
+ 
+    if (sum(vR) >= 5000) {                  // sum is an Rcpp sugar op.
+       vA = vR;                             // swap vR into vA 
+    }
+    return(vA);                             // return vA
+ ')
R> 
R> sum( fun( vecA ) )
[1] 5033
R> sum( fun( vecA ) )
[1] 5015
R> sum( fun( vecA ) )
[1] 66
R> sum( fun( vecA ) )
[1] 66
R> sum( fun( vecA ) )
[1] 5015
R> sum( fun( vecA ) )
[1] 5024
R> sum( fun( vecA ) )
[1] 5020
R>
R> sum(vecA)
[1] 66
R> 

You can learn about Rcpp from the vignettes in the package, at my page at
http://dirk.eddelbuettel.com/code/rcpp.html as well different posts on my
blog, and of course the rcpp-devel mailing list.  The example above uses
cxxfunction() from the wonderful inline package you may find useful too as it
compiles, links and loads your C or C++ snippets.

Dirk

-- 
"Outside of a dog, a book is a man's best friend. Inside of a dog, it is too
dark to read." -- Groucho Marx


From mathieu.ribatet at math.univ-montp2.fr  Thu Nov 17 23:39:45 2011
From: mathieu.ribatet at math.univ-montp2.fr (Mathieu Ribatet)
Date: Thu, 17 Nov 2011 23:39:45 +0100
Subject: [Rd] Small inconsistency with boxplot
Message-ID: <20C3C05D-872C-43D2-80C6-24FAEBADC7E3@math.univ-montp2.fr>

Dear R-core team,

I think I found a small inconsistency in the boxplot function. I don't want to post it as a bug since I'm not sure this might be considered as one according to the FAQ --- and this is not a major problem. Don't hesitate to tell me if I'm wrong.

If you try to do a boxplot on a matrix and set the "at" argument to some vector different from 1:n, n is the number of columns of your matrix, then some boxplots will be hidden since the default "xlim" value will be set to c(0.5, n + 0.5) during the call of the bxp function.

Currently you can easily bypass this problem by setting "xlim" appropriately when calling the boxplot function.

I think it will be better if all boxplots were always shown unless the "xlim" argument is specified. (I realized this behavior when I tried to do boxplots on conditional simulations of a stochastic process ; in which case the suggested behavior might be useful.)

Here's an example

par(mfrow = c(1, 3))
data <- matrix(rnorm(10 * 50), 50)
colnames(data) <- letters[1:10]
x.pos <- seq(-10, 10, length = 10)
boxplot(data, at = x.pos) ## only the last 5 boxplots will appear
boxplot(data, at = 1:10) ## all boxplots will appear
boxplot(data, at = x.pos, xlim = range(x.pos) + c(-0.5, 0.5)) ## all boxplots will be shown

I tried to do a patch if you want to change the current behavior --- note this is my first patch ever so maybe I'm doing it wrong.

*** Downloads/R-2.14.0/src/library/graphics/R/boxplot.R	Mon Oct  3 00:02:21 2011
--- boxplot.R	Thu Nov 17 23:02:45 2011
***************
*** 203,209 ****
      }
  
      if(is.null(pars$xlim))
!         xlim <- c(0.5, n + 0.5)
      else {
  	xlim <- pars$xlim
  	pars$xlim <- NULL
--- 203,209 ----
      }
  
      if(is.null(pars$xlim))
!         xlim <- c(min(at) - 0.5, max(at) + 0.5)
      else {
  	xlim <- pars$xlim
  	pars$xlim <- NULL


----------------------------------------------------------------- 
I3M, UMR CNRS 5149
Universite Montpellier II,
4 place Eugene Bataillon
34095 Montpellier cedex 5   France
http://www.math.univ-montp2.fr/~ribatet
Tel: + 33 (0)4 67 14 41 98


From maechler at stat.math.ethz.ch  Fri Nov 18 09:44:36 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 18 Nov 2011 09:44:36 +0100
Subject: [Rd] Small inconsistency with boxplot
In-Reply-To: <20C3C05D-872C-43D2-80C6-24FAEBADC7E3@math.univ-montp2.fr>
References: <20C3C05D-872C-43D2-80C6-24FAEBADC7E3@math.univ-montp2.fr>
Message-ID: <20166.6900.536577.79040@stat.math.ethz.ch>


> Dear R-core team,
> I think I found a small inconsistency in the boxplot function. I don't want to post it as a bug since I'm not sure this might be considered as one according to the FAQ --- and this is not a major problem. Don't hesitate to tell me if I'm wrong.

> If you try to do a boxplot on a matrix and set the "at" argument to some vector different from 1:n, n is the number of columns of your matrix, then some boxplots will be hidden since the default "xlim" value will be set to c(0.5, n + 0.5) during the call of the bxp function.

> Currently you can easily bypass this problem by setting "xlim" appropriately when calling the boxplot function.

Yes.  And the help page for  bxp  even has the following note:

 \note{
   if \code{add = FALSE}, the default is \code{xlim = c(0.5, n +0.5)}.
   It will usually be a good idea to specify the latter if the "x" axis
   has a log scale or \code{at} is specified or \code{width} is far from
   uniform.
 }

which clearly documents the current behavior.
(and one could say also ``excuses'' the current behavior)

In this sense, there's really no bug ... ;-) and you were 
very wise (or at least cautious :-) *not* to post it as bug  .. 

> I think it will be better if all boxplots were always shown unless the "xlim" argument is specified. (I realized this behavior when I tried to do boxplots on conditional simulations of a stochastic process ; in which case the suggested behavior might be useful.)

I do agree that such a change would be more ``logical'' i.e.,
according to  "The Rule of Least Surprise"
(a good software design principle of providing a default behavior
 of "least surprise" to the user).

> Here's an example

> par(mfrow = c(1, 3))
> data <- matrix(rnorm(10 * 50), 50)
> colnames(data) <- letters[1:10]
> x.pos <- seq(-10, 10, length = 10)
> boxplot(data, at = x.pos) ## only the last 5 boxplots will appear
> boxplot(data, at = 1:10) ## all boxplots will appear
> boxplot(data, at = x.pos, xlim = range(x.pos) + c(-0.5, 0.5)) ## all boxplots will be shown


> I tried to do a patch if you want to change the current behavior --- note this is my first patch ever so maybe I'm doing it wrong.

it looks good.
In the end, I would use

	xlim <- range(at, finite=TRUE) + c(-0.5, 0.5)

There's one ***BIG*** question though:  

How probable is it that it breaks someone else's code.
Note that boxplot() and bxp() are  *REALLY*  old traditional S
functions
(and for all the young guys:  Boxplots where invented/proposed
 by the famous  John W Tukey, co-inventor of the FFT, the word
 "bit"; "exploratory data analysis", etc etc.
 Then (partly) at Bell Labs, who via John Chambers and
 co-workers also "donated" the S language and hence R to the world !)

and therefore you can expect many many uses of boxplot() in
other code...
and hence, it could well be that some code has (probably
implicitly) *relied* on the current "more surprising" behavior.

I'd still advocate to the change the default here,
but we really have to discuss this, as a change also may have
adverse consequences.

Martin Maechler, ETH Zurich (and R Core)

> *** Downloads/R-2.14.0/src/library/graphics/R/boxplot.R	Mon Oct  3 00:02:21 2011
> --- boxplot.R	Thu Nov 17 23:02:45 2011
> ***************
> *** 203,209 ****
>       }
  
>       if(is.null(pars$xlim))
> !         xlim <- c(0.5, n + 0.5)
>       else {
>   	xlim <- pars$xlim
>   	pars$xlim <- NULL
> --- 203,209 ----
>       }
  
>       if(is.null(pars$xlim))
> !         xlim <- c(min(at) - 0.5, max(at) + 0.5)
>       else {
>   	xlim <- pars$xlim
>   	pars$xlim <- NULL


From pburns at pburns.seanet.com  Fri Nov 18 10:14:00 2011
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Fri, 18 Nov 2011 09:14:00 +0000
Subject: [Rd] strange behavior from cex="*"
In-Reply-To: <4EC4556E.4050507@gmail.com>
References: <4EC42D66.502@gmail.com>
	<1C6B85B4-9803-407B-83BB-19159CCB2778@gmail.com>
	<4EC4388A.6070502@gmail.com> <4EC4556E.4050507@gmail.com>
Message-ID: <4EC621D8.7020100@pburns.seanet.com>

Someone ambitious could find problems like
this using random input testing like I talked
about at useR last summer.

http://www.burns-stat.com/pages/Present/random_input_test_annotated.pdf

Testing graphics would be more labor intensive
than the testing I do, but you could think of it
as a video game.

On 17/11/2011 00:29, Duncan Murdoch wrote:
> On 11-11-16 5:26 PM, Ben Bolker wrote:
> > -----BEGIN PGP SIGNED MESSAGE-----
> > Hash: SHA1
> >
> > On 11-11-16 05:18 PM, peter dalgaard wrote:
> >>
> >> On Nov 16, 2011, at 22:38 , Ben Bolker wrote:
> >>
> >>> Someone inquired on StackOverflow about apparently non-deterministic
> >>> graphics behaviour in R. I noticed that they were using cex="*" and
> >>> discovered some potentially weird behavior.
> >>
> >> It can be reproduced much more simply (well, not the hang, but bad
> >> enough):
> >>
> >> In a plain R application console (OSX Snow Leopard),
> >>
> >> for (i in 1:100) plot(1:10,cex="*")
> >>
> >> will _sometimes_ show big circles, indicating random data being
> >> picked up.
> >>
> >> The "cex" is by definition numeric, so you can't expect to be able to
> >> pass a character string, but the code should check.
> >
> > Looks (?) like the check could go in FixupCex (which already tests for
> > isReal, isInteger, and isLogical) in src/main/plot.c , unless there is a
> > wish to catch it earlier/in R code.
>
> Yes, that's where the check was missed. I'll fix it. The other
> parameters appear to have been checked properly.
>
> > It's mildly surprising to me that people can continue to find odd
> > cases like this after more than 10 years (and imagine how many
> > cumulative hours of R use ...) [I'm assuming that this hole has been
> > present for a log time: I don't have the patience to do the SVN
> > archaeology to find out how long.]
>
> So now you can prove me wrong about the other parameters...
>
> Duncan Murdoch
>
>
> >
> >>
> >>>
> >>> On repeated runs of the same code I can get different PNGs. If I set
> >>> the number of runs high enough, I seem to be able to get R to hang.
> >>> If I do a single version plotting to an interactive graphics window I
> >>> can get the point sizes to jump around as I resize the window (someone
> >>> reported being able to reproduce that behaviour in the Windows GUI
> >>> as well).
> >>>
> >>> This is clearly a user error, but non-deterministic behaviour (and
> >>> hanging) are a little disturbing.
> >>>
> >>> I haven't had a chance yet to try to dig in and see what's happening
> >>> but thought I would report to see if anyone else could 
> reproduce/figure
> >>> it out.
> >>>
> >>> Ben Bolker
> >>>
> >>>
> >>> ########################
> >>> ## n<- 100 ## hangs R
> >>>
> >>> n<- 33
> >>>
> >>> fn<- paste("tmp",seq(n),"png",sep=".")
> >>> for (i in seq(n)) {
> >>> png(fn[i])
> >>> plot(1:10,1:10,cex="*");
> >>> dev.off()
> >>> }
> >>>
> >>> ff<- subset(file.info(fn),select=size)
> >>> ff<- ff[!duplicated(ff$size),,drop=FALSE]
> >>> table(ff$size)
> >>> require(png)
> >>> pngs<- lapply(rownames(ff),readPNG)
> >>>
> >>> png.to.img<- function(x) matrix(rgb(x[,,1],x[,,2],x[,,3]),
> >>> nrow=dim(x)[1],ncol=dim(x)[2])
> >>>
> >>> imgs<- lapply(pngs,png.to.img)
> >>>
> >>> par(mfrow=c(2,2))
> >>> lapply(imgs,function(x) {
> >>> plot(0:1,0:1,type="n",ann=FALSE,axes=FALSE)
> >>> rasterImage(x,0,0,1,1)
> >>> })
> >>>
> >>> #########################
> >>>
> >>>> sessionInfo()
> >>> R Under development (unstable) (2011-10-06 r57181)
> >>> Platform: i686-pc-linux-gnu (32-bit)
> >>>
> >>> attached base packages:
> >>> [1] stats graphics grDevices utils datasets methods base
> >>>
> >>> other attached packages:
> >>> [1] glmmADMB_0.6.5 MASS_7.3-14 png_0.1-3
> >>>
> >>> loaded via a namespace (and not attached):
> >>> [1] grid_2.15.0 lattice_0.19-33 nlme_3.1-102 tools_2.15.0
> >>>
> >>> ______________________________________________
> >>> R-devel at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >
> > -----BEGIN PGP SIGNATURE-----
> > Version: GnuPG v1.4.10 (GNU/Linux)
> > Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/
> >
> > iQEcBAEBAgAGBQJOxDiKAAoJED2whTVMEyK9ThoIAIjyMpzZqsjUpJVbAb9K8IrL
> > LbSFh8zb+cZb90ABkFwJaZ2FNTKCjPrUzOYzxxHuU9AY0bdPQGbIm2hvQfzcuMlc
> > urS/ILIMzZEFSYkqkj0mWI9SADyJ+W0YeN/t3EuWy8nZqUkYQZ8M0GsuXjhtUL/i
> > hVJU0uuIWCOCHpeI3SQKoxviTE6MQFRXXWhCAJx01h8ee/5UQ5GSGB7Er2Zilld3
> > 0sLI6dmoF7gbeYqz33MaEpQ7geJoW3tfnVbQWUlF86+jGGv5trIqWYIp33OYIxMO
> > u2YUq51vB+4uIRPFJ4Oyr+nJF0Z9NH4IJBipp/bF6wQ5u6JdXFqKTPeQ1V6m5qk=
> > =YajM
> > -----END PGP SIGNATURE-----
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Patrick Burns
pburns at pburns.seanet.com
twitter: @portfolioprobe
http://www.portfolioprobe.com/blog
http://www.burns-stat.com
(home of 'Some hints for the R beginner'
and 'The R Inferno')


From andreas.borg at unimedizin-mainz.de  Fri Nov 18 10:42:29 2011
From: andreas.borg at unimedizin-mainz.de (Andreas Borg)
Date: Fri, 18 Nov 2011 10:42:29 +0100
Subject: [Rd] R CMD check: "Undocumented class" for class created with
	setOldClass()
Message-ID: <4EC62885.1060509@unimedizin-mainz.de>

Hi all,

in a package, I register two S3 classes (namely ff_vector and ffdf) by 
calling setOldClass() in order to use them as slots in S4 classes. Now, 
R CMD check gives me the warning:

Undocumented S4 classes:
  'ff_vector' 'ffdf'

Is there a way to avoid having to document classes I did not write? Or 
is this intended behaviour?

Best regards,

Andreas

-- 
Andreas Borg
Abteilung Medizinische Informatik

Universit?tsmedizin der Johannes Gutenberg-Universit?t Mainz
Institut f?r Med. Biometrie, Epidemiologie und Informatik (IMBEI)
Obere Zahlbacher Stra?e 69, 55131 Mainz

Tel:  +49 (0) 6131 17-5062

E-Mail: andreas.borg at uni-mainz.de


From karl.forner at gmail.com  Fri Nov 18 16:08:20 2011
From: karl.forner at gmail.com (Karl Forner)
Date: Fri, 18 Nov 2011 16:08:20 +0100
Subject: [Rd] .Call in R
In-Reply-To: <1321549770463-4080721.post@n4.nabble.com>
References: <1321549770463-4080721.post@n4.nabble.com>
Message-ID: <CAMd4_Acq=iyx-AxaSSNn1Ya20xZAURAg4girh=FSUSnhd5S_CA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111118/4f717538/attachment.pl>

From mtmorgan at fhcrc.org  Fri Nov 18 16:40:06 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Fri, 18 Nov 2011 07:40:06 -0800
Subject: [Rd] .Call in R
In-Reply-To: <CAMd4_Acq=iyx-AxaSSNn1Ya20xZAURAg4girh=FSUSnhd5S_CA@mail.gmail.com>
References: <1321549770463-4080721.post@n4.nabble.com>
	<CAMd4_Acq=iyx-AxaSSNn1Ya20xZAURAg4girh=FSUSnhd5S_CA@mail.gmail.com>
Message-ID: <4EC67C56.30504@fhcrc.org>

On 11/18/2011 07:08 AM, Karl Forner wrote:
> Hi,
>
> A probably very naive remark, but I believe that the probability of sum(
> runif(10000) )>= 50000 is exactly 0.5. So why not just test that, and
> generate the uniform values only if needed ?

My thought as well, but actually the deviates need to have mean > .5 so 
you'd do something like

   repeat {
      vecA <- runif(10000)
      if (mean(vecA) > .5) break
   }

You'd do this 1/2 the time, and you'd have to itearte on average 1 / 
(1/2) = 2 times before getting the vector satisfying the constraint, so 
the expected number of iterations is 1/2 * 2 = 1, the same as in the 
original implementation!

It does suggest that there is only one allocation required, if this were 
coded at the C level. But since sum(), mean(), and runif() all go more 
or less directly to C anyway it doesn't seem like this is the right 
problem for a C solution.

Martin

>
>
> Karl Forner
>
> On Thu, Nov 17, 2011 at 6:09 PM, Raymond<gwgc5 at mail.missouri.edu>  wrote:
>
>> Hi R developers,
>>
>>     I am new to this forum and hope someone can help me with .Call in R.
>> Greatly appreciate any help!
>>
>>     Say, I have a vector called "vecA" of length 10000, I generate a vector
>> called "vecR" with elements randomly generated from Uniform[0,1]. Both vecA
>> and vecR are of double type. I want to replace elements vecA by elements in
>> vecR only if sum of elements in vecR is greater than or equal to 5000.
>> Otherwise, vecR remain unchanged. This is easy to do in R, which reads
>>     vecA<-something;
>>     vecR<-runif(10000);
>>     if (sum(vecR)>=5000)){
>>        vecA<-vecR;
>>     }
>>
>>
>>     Now my question is, if I am going to do the same thing in R using .Call.
>> How can I achieve it in a more efficient way (i.e. less computation time
>> compared with pure R code above.).  My c code (called "change_vecA.c")
>> using
>> .Call is like this:
>>
>>     SEXP change_vecA(SEXP vecA){
>>          int i,vecA_len;
>>          double sum,*res_ptr,*vecR_ptr,*vecA_ptr;
>>
>>          vecA_ptr=REAL(vecA);
>>          vecA_len=length(vecA);
>>          SEXP res_vec,vecR;
>>
>>          PROTECT(res_vec=allocVector(REALSXP, vec_len));
>>          PROTECT(vecR=allocVector(REALSXP, vec_len));
>>          res_ptr=REAL(res_vec);
>>          vecR_ptr=REAL(vecR);
>>          GetRNGstate();
>>          sum=0.0;
>>          for (i=0;i<vecA_len;i++){
>>               vecR_ptr[i]=runif(0,1);
>>               sum+=vecR_ptr[i];
>>          }
>>          if (sum>=5000){
>>             /*copy vecR to the vector to be returned*/
>>             for (i=0;i<vecA_len;i++){
>>                   res_ptr[i]=vecR_ptr[i];
>>             }
>>          }
>>          else{
>>                 /*copy vecA to the vector to be returned*/
>>                 for (i=0;i<vecA_len;i++){
>>                       res_ptr[i]=vecA_ptr[i];
>>                 }
>>          }
>>
>>          PutRNGstate();
>>          UNPROTECT(2);
>>          resturn(res);
>> }
>> My R wrapper function is
>>         change_vecA<-function(vecA){
>>               dyn.load("change_vecA.so");
>>               .Call("change_vecA",vecA);
>>         }
>>
>>          Now my question is, due to two loops (one generates the random
>> vector and one determines the vector to be returned), can .Call still be
>> faster than pure R code (only one loop to copy vecR to vecA given condition
>> is met)? Or, how can I improve my c code to avoid redundant loops if any.
>> My
>> concern is if vecA is large (say of length 1000000 or even bigger), loops
>> in
>> C code can slow things down.  Thanks for any help!
>>
>>
>>
>>
>>
>> --
>> View this message in context:
>> http://r.789695.n4.nabble.com/Call-in-R-tp4080721p4080721.html
>> Sent from the R devel mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From jorismeys at gmail.com  Fri Nov 18 16:43:05 2011
From: jorismeys at gmail.com (Joris Meys)
Date: Fri, 18 Nov 2011 16:43:05 +0100
Subject: [Rd] round() ignores missing arguments if it is used inside another
 function where some arguments are missing.
Message-ID: <CAO1zAVaS6YN=7V7tciOpgDA98haDY3wPYyuQt-cxkcsqXGsz=A@mail.gmail.com>

I have stumbled across some behaviour in R that I really can't place,
and that makes coding a bit tricky. I know that I can work around it
when explicitly checking for missing arguments, but still...
I have two functions. I have a first function based on paste

? ? fun1 <- function(x,y){
? ? ? print(missing(y))
? ? ? paste(x,'X',sep=y)
? ? }

If I try this function without specifying `y`, I get the (expected)
error message:

? ? > fun1(letters[1:6])
? ? [1] TRUE
? ? Error in paste(x, "X", sep = y) :
? ? ? argument "y" is missing, with no default

The second one with round :
? ? fun2 <- function(x,y){? ? ? print(missing(y))? ? ? round(x,digits=y)? ? }
If I try this function without specifying `y`, it works unexpectedly
whereas it shouldn't :
? ? > fun2(100.1)? ? [1] TRUE? ? [1] 100
In my view, fun1 should definitely give the error message as well, as
it is not intended to have a default behaviour when y is missing.
Still, the round() function ignores the fact y is missing. Is this by
design, is there a check missing in round, or is something else going
on that I am overlooking?

Cheers
Joris
> sessionInfo()
R version 2.14.0 (2011-10-31)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United Kingdom.1252
[2] LC_CTYPE=English_United Kingdom.1252
[3] LC_MONETARY=English_United Kingdom.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United Kingdom.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods
[7] base

loaded via a namespace (and not attached):
[1] tools_2.14.0

-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From jorismeys at gmail.com  Fri Nov 18 16:45:41 2011
From: jorismeys at gmail.com (Joris Meys)
Date: Fri, 18 Nov 2011 16:45:41 +0100
Subject: [Rd] .Call in R
In-Reply-To: <CAMd4_Acq=iyx-AxaSSNn1Ya20xZAURAg4girh=FSUSnhd5S_CA@mail.gmail.com>
References: <1321549770463-4080721.post@n4.nabble.com>
	<CAMd4_Acq=iyx-AxaSSNn1Ya20xZAURAg4girh=FSUSnhd5S_CA@mail.gmail.com>
Message-ID: <CAO1zAVbz7vQW6xgQ-LKAqf3+QMGKkSWwJ5fwHVBQyHLrS6KPRQ@mail.gmail.com>

Because if you calculate the probability and then make uniform values,
nothing guarantees that the sum of those uniform values actually is
larger than 50,000. You only have 50% chance it is, in fact...
Cheers
Joris

On Fri, Nov 18, 2011 at 4:08 PM, Karl Forner <karl.forner at gmail.com> wrote:
> Hi,
>
> A probably very naive remark, but I believe that the probability of sum(
> runif(10000) ) >= 50000 is exactly 0.5. So why not just test that, and
> generate the uniform values only if needed ?
>
>
> Karl Forner
>
> On Thu, Nov 17, 2011 at 6:09 PM, Raymond <gwgc5 at mail.missouri.edu> wrote:
>
>> Hi R developers,
>>
>> ? ?I am new to this forum and hope someone can help me with .Call in R.
>> Greatly appreciate any help!
>>
>> ? ?Say, I have a vector called "vecA" of length 10000, I generate a vector
>> called "vecR" with elements randomly generated from Uniform[0,1]. Both vecA
>> and vecR are of double type. I want to replace elements vecA by elements in
>> vecR only if sum of elements in vecR is greater than or equal to 5000.
>> Otherwise, vecR remain unchanged. This is easy to do in R, which reads
>> ? ?vecA<-something;
>> ? ?vecR<-runif(10000);
>> ? ?if (sum(vecR)>=5000)){
>> ? ? ? vecA<-vecR;
>> ? ?}
>>
>>
>> ? ?Now my question is, if I am going to do the same thing in R using .Call.
>> How can I achieve it in a more efficient way (i.e. less computation time
>> compared with pure R code above.). ?My c code (called "change_vecA.c")
>> using
>> .Call is like this:
>>
>> ? ?SEXP change_vecA(SEXP vecA){
>> ? ? ? ? int i,vecA_len;
>> ? ? ? ? double sum,*res_ptr,*vecR_ptr,*vecA_ptr;
>>
>> ? ? ? ? vecA_ptr=REAL(vecA);
>> ? ? ? ? vecA_len=length(vecA);
>> ? ? ? ? SEXP res_vec,vecR;
>>
>> ? ? ? ? PROTECT(res_vec=allocVector(REALSXP, vec_len));
>> ? ? ? ? PROTECT(vecR=allocVector(REALSXP, vec_len));
>> ? ? ? ? res_ptr=REAL(res_vec);
>> ? ? ? ? vecR_ptr=REAL(vecR);
>> ? ? ? ? GetRNGstate();
>> ? ? ? ? sum=0.0;
>> ? ? ? ? for (i=0;i<vecA_len;i++){
>> ? ? ? ? ? ? ?vecR_ptr[i]=runif(0,1);
>> ? ? ? ? ? ? ?sum+=vecR_ptr[i];
>> ? ? ? ? }
>> ? ? ? ? if (sum>=5000){
>> ? ? ? ? ? ?/*copy vecR to the vector to be returned*/
>> ? ? ? ? ? ?for (i=0;i<vecA_len;i++){
>> ? ? ? ? ? ? ? ? ?res_ptr[i]=vecR_ptr[i];
>> ? ? ? ? ? ?}
>> ? ? ? ? }
>> ? ? ? ? else{
>> ? ? ? ? ? ? ? ?/*copy vecA to the vector to be returned*/
>> ? ? ? ? ? ? ? ?for (i=0;i<vecA_len;i++){
>> ? ? ? ? ? ? ? ? ? ? ?res_ptr[i]=vecA_ptr[i];
>> ? ? ? ? ? ? ? ?}
>> ? ? ? ? }
>>
>> ? ? ? ? PutRNGstate();
>> ? ? ? ? UNPROTECT(2);
>> ? ? ? ? resturn(res);
>> }
>> My R wrapper function is
>> ? ? ? ?change_vecA<-function(vecA){
>> ? ? ? ? ? ? ?dyn.load("change_vecA.so");
>> ? ? ? ? ? ? ?.Call("change_vecA",vecA);
>> ? ? ? ?}
>>
>> ? ? ? ? Now my question is, due to two loops (one generates the random
>> vector and one determines the vector to be returned), can .Call still be
>> faster than pure R code (only one loop to copy vecR to vecA given condition
>> is met)? Or, how can I improve my c code to avoid redundant loops if any.
>> My
>> concern is if vecA is large (say of length 1000000 or even bigger), loops
>> in
>> C code can slow things down. ?Thanks for any help!
>>
>>
>>
>>
>>
>> --
>> View this message in context:
>> http://r.789695.n4.nabble.com/Call-in-R-tp4080721p4080721.html
>> Sent from the R devel mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From simon.urbanek at r-project.org  Fri Nov 18 17:09:18 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 18 Nov 2011 11:09:18 -0500
Subject: [Rd] round() ignores missing arguments if it is used inside
	another function where some arguments are missing.
In-Reply-To: <CAO1zAVaS6YN=7V7tciOpgDA98haDY3wPYyuQt-cxkcsqXGsz=A@mail.gmail.com>
References: <CAO1zAVaS6YN=7V7tciOpgDA98haDY3wPYyuQt-cxkcsqXGsz=A@mail.gmail.com>
Message-ID: <315E603C-9F37-497D-BB0F-49D27A8899E6@r-project.org>


On Nov 18, 2011, at 10:43 AM, Joris Meys wrote:

> I have stumbled across some behaviour in R that I really can't place,
> and that makes coding a bit tricky. I know that I can work around it
> when explicitly checking for missing arguments, but still...
> I have two functions. I have a first function based on paste
> 
>     fun1 <- function(x,y){
>       print(missing(y))
>       paste(x,'X',sep=y)
>     }
> 
> If I try this function without specifying `y`, I get the (expected)
> error message:
> 
>     > fun1(letters[1:6])
>     [1] TRUE
>     Error in paste(x, "X", sep = y) :
>       argument "y" is missing, with no default
> 
> The second one with round :
>     fun2 <- function(x,y){      print(missing(y))      round(x,digits=y)    }
> If I try this function without specifying `y`, it works unexpectedly
> whereas it shouldn't :
>     > fun2(100.1)    [1] TRUE    [1] 100
> In my view, fun1 should definitely give the error message as well, as
> it is not intended to have a default behaviour when y is missing.
> Still, the round() function ignores the fact y is missing. Is this by
> design, is there a check missing in round, or is something else going
> on that I am overlooking?
> 

> round
function (x, digits = 0)  .Primitive("round")

it has a default so it is fine for digits to be missing since it will have value 0 in that case ...

Cheers,
S


> Cheers
> Joris
>> sessionInfo()
> R version 2.14.0 (2011-10-31)
> Platform: i386-pc-mingw32/i386 (32-bit)
> 
> locale:
> [1] LC_COLLATE=English_United Kingdom.1252
> [2] LC_CTYPE=English_United Kingdom.1252
> [3] LC_MONETARY=English_United Kingdom.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United Kingdom.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods
> [7] base
> 
> loaded via a namespace (and not attached):
> [1] tools_2.14.0
> 
> -- 
> Joris Meys
> Statistical consultant
> 
> Ghent University
> Faculty of Bioscience Engineering
> Department of Mathematical Modelling, Statistics and Bio-Informatics
> 
> tel : +32 9 264 59 87
> Joris.Meys at Ugent.be
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From gavin.simpson at ucl.ac.uk  Fri Nov 18 17:10:20 2011
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Fri, 18 Nov 2011 16:10:20 +0000
Subject: [Rd] round() ignores missing arguments if it is used inside
 another function where some arguments are missing.
In-Reply-To: <CAO1zAVaS6YN=7V7tciOpgDA98haDY3wPYyuQt-cxkcsqXGsz=A@mail.gmail.com>
References: <CAO1zAVaS6YN=7V7tciOpgDA98haDY3wPYyuQt-cxkcsqXGsz=A@mail.gmail.com>
Message-ID: <1321632620.17906.68.camel@prometheus.geog.ucl.ac.uk>

On Fri, 2011-11-18 at 16:43 +0100, Joris Meys wrote:
> I have stumbled across some behaviour in R that I really can't place,
> and that makes coding a bit tricky. I know that I can work around it
> when explicitly checking for missing arguments, but still...
> I have two functions. I have a first function based on paste
> 
>     fun1 <- function(x,y){
>       print(missing(y))
>       paste(x,'X',sep=y)
>     }
> 
> If I try this function without specifying `y`, I get the (expected)
> error message:
> 
>     > fun1(letters[1:6])
>     [1] TRUE
>     Error in paste(x, "X", sep = y) :
>       argument "y" is missing, with no default
> 
> The second one with round :
>     fun2 <- function(x,y){      print(missing(y))      round(x,digits=y)    }
> If I try this function without specifying `y`, it works unexpectedly
> whereas it shouldn't :
>     > fun2(100.1)    [1] TRUE    [1] 100

round() is implemented as:

> round
function (x, digits = 0)  .Primitive("round")

using the .Primitive means of calling C code. `?.Primitve` refers you to
the R Internals manual, which basically states that how the compiled
functions should be called and number of arguments etc is stored in a
table. This table is given here:

http://svn.r-project.org/R/trunk/src/main/names.c

The relevant part of which is:

/* printname	c-entry		offset	eval	arity	pp-kind	     precedence	rightassoc
 * ---------	-------		------	----	-----	-------      ----------	----------*/
....
/* Mathematical Functions */
/* primitives: these are group generic and so need to eval args (possibly internally) */
{"round",	do_Math2,	10001,	0,	-1,	{PP_FUNCALL, PREC_FN,	0}},


the eval column indicates features of how arguments are evaluated and
what have you. A value of 0 equates to 000 and the last 0 indicates
whether arguments are to be evaluated with 0 indicating no evaluation
and 1 evaluation.

round is indicated to not evaluate its arguments. I don't follow the C
code well enough to know if it should be catching the missing argument
further on - it must be because it is falling back to the default, but
the above explains that the not evaluating arguments is intended.

G

> In my view, fun1 should definitely give the error message as well, as
> it is not intended to have a default behaviour when y is missing.
> Still, the round() function ignores the fact y is missing. Is this by
> design, is there a check missing in round, or is something else going
> on that I am overlooking?
> 
> Cheers
> Joris
> > sessionInfo()
> R version 2.14.0 (2011-10-31)
> Platform: i386-pc-mingw32/i386 (32-bit)
> 
> locale:
> [1] LC_COLLATE=English_United Kingdom.1252
> [2] LC_CTYPE=English_United Kingdom.1252
> [3] LC_MONETARY=English_United Kingdom.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United Kingdom.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods
> [7] base
> 
> loaded via a namespace (and not attached):
> [1] tools_2.14.0
> 

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From simon.urbanek at r-project.org  Fri Nov 18 17:10:49 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 18 Nov 2011 11:10:49 -0500
Subject: [Rd] Non-free packages in CRAN
In-Reply-To: <CAPHS2gwarCZPEVha2e6+tXx2WnA3Ys41ZFvZZgYYcstQk73Cmg@mail.gmail.com>
References: <CAPHS2gwarCZPEVha2e6+tXx2WnA3Ys41ZFvZZgYYcstQk73Cmg@mail.gmail.com>
Message-ID: <02D869B4-DDC4-47DE-93DB-B5C897A130F0@r-project.org>

Jordi,

I think you are misunderstanding a few things here. First, "R" doesn't endorse anything - it is a program, it does what you tell it to do. Second, whoever runs R-forge doesn't endorse the packages hosted on it, either. It's just an infrastructure, with no claim about endorsement of the package hosted there (just like github, sourceforge etc. don't say anything about the software hosted there). Third, LGPL is a GNU license and also a open source license (in fact far more free than GPL - see "Software Licenses" on GNU pages). If anyone shared your interpretation, there would be no GNU/Linux since glibc is LGPL licensed and so are parts of gcc (and hence according to your argument neither can be a GNU project). Note that a lot of GNU libraries are licensed under LGPL.

The fact that you personally may not like licenses other than GPL is completely irrelevant. There are many other open source licenses and there is nothing wrong with using them. It is entirely up to the developer to decide how they feel about their code - whether they want it to be restricted by GPL or more free with some other open source license. Instead of forcing our views on users, we are empowering them to filter packages according to the license they feel comfortable with.

As for giving access to proprietary software - I think the argument is the exact opposite of what you are saying. By having the ability to leverage functionality (be it proprietary) that doesn't exist in R/Octave/.., you are making the free software stronger. If people realize that it is a desirable functionality, then they will create a free alternative since only a part of the community can use it. However, if such link did not exist, then users may choose to abandon the free software and use a commercial product instead (AFAIR in your example it was Matlab that has a link to Mosek). That would also weaken the possibility of a free alternative for the package.

Cheers,
Simon



On Nov 17, 2011, at 1:06 PM, Jordi Guti?rrez Hermoso wrote:

> Hello.
> 
> This is in relation to the discussion below:
> 
>    http://sourceforge.net/mailarchive/forum.php?thread_name=CAPHS2gwmxJGF9Cy8%3DSEGasQcVRg_Lqu-ndCdVhO-r1LJsRQGuA%40mail.gmail.com&forum_name=octave-dev
> 
> If this is the wrong place to discuss this issue, I would be thankful
> for a redirection to the appropriate forum.
> 
> As Henrik says, R or some organisation that acts in R's name, has
> accepted his non-free plugin:
> 
>    http://rmosek.r-forge.r-project.org/
> 
> Yes, it is non-free, even if it's LGPL, because it's linking to both R
> and MOSEK, which is a GPL+proprietary whole. There is no actual GPL
> violation because it's avoiding binary distribution. However, I'm
> concerned with the overall message this sends.
> 
> I was under the impression that R is part of the GNU project, and as
> an Octave developer, I have thought of R as being a fellow GNU-in-arms
> comrade. I have proudly recommended R to people, both on technical
> merits and sound philosophical principles. I don't see R as a
> competitor to Octave, but as an esteemed colleague.
> 
> I am, however, a little concerned that R seems to be endorsing a
> project that is in turn endorsing non-free software. This seems to be
> against what an important aspect of what GNU should do: promote free
> software and discourage the proliferation of non-free software. While
> you may argue that the plugin is free, it is absolutely useless
> without the non-free package, so R is ultimately recommending its
> users to use a non-free package. This seems like a problem to me.
> 
> I see several possible solutions:
> 
>    1) R could stop calling itself part of the GNU project. This would
>       make me very sad, and I hope R doesn't take this route. As I
>       said, I'm proud to be part of the same organisation that R is
>       currently part of.
> 
>    2) R could stop endorsing R-Forge. This obviously seems like a
>       much worse alternative.
> 
>    3) R-Forge could remove the offending package. I also hope it
>       doesn't come to this.
> 
>    4) The authors of MOSEK could make it free. Note: "free" does not
>       mean "money is forbidden". One option for MOSEK could be to
>       dual-license it: MOSEK is GPL, but anyone who wants to lock it
>       up has to pay for alternative license terms. FFTW and Qt are
>       two prominent free commercial packages that have followed this
>       route.
> 
> I really would much prefer (4), or if it can't be achieved, (3). But I
> encourage the R users and contributors to support the aims of the GNU
> project and to stand together with the Octave community in this
> regard.
> 
> Thank you for your time,
> - Jordi G. H.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From jorismeys at gmail.com  Fri Nov 18 17:19:02 2011
From: jorismeys at gmail.com (Joris Meys)
Date: Fri, 18 Nov 2011 17:19:02 +0100
Subject: [Rd] round() ignores missing arguments if it is used inside
 another function where some arguments are missing.
In-Reply-To: <1321632620.17906.68.camel@prometheus.geog.ucl.ac.uk>
References: <CAO1zAVaS6YN=7V7tciOpgDA98haDY3wPYyuQt-cxkcsqXGsz=A@mail.gmail.com>
	<1321632620.17906.68.camel@prometheus.geog.ucl.ac.uk>
Message-ID: <CAO1zAVYLrLFLdPQkm8Wt=dTAoijqHP83a2tVRBaTXybPWNv8wA@mail.gmail.com>

On Fri, Nov 18, 2011 at 5:10 PM, Gavin Simpson <gavin.simpson at ucl.ac.uk> wrote:
>
> round is indicated to not evaluate its arguments. I don't follow the C
> code well enough to know if it should be catching the missing argument
> further on - it must be because it is falling back to the default, but
> the above explains that the not evaluating arguments is intended.
>
> G

So if I understand it right, the y argument is not evaluated in the
fun2 function but deeper in the C code. that explains the lack of the
error message, thanks! I keep on learning every day.
Cheers

Joris

-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From karl.forner at gmail.com  Fri Nov 18 18:09:32 2011
From: karl.forner at gmail.com (Karl Forner)
Date: Fri, 18 Nov 2011 18:09:32 +0100
Subject: [Rd] .Call in R
In-Reply-To: <CAO1zAVbz7vQW6xgQ-LKAqf3+QMGKkSWwJ5fwHVBQyHLrS6KPRQ@mail.gmail.com>
References: <1321549770463-4080721.post@n4.nabble.com>
	<CAMd4_Acq=iyx-AxaSSNn1Ya20xZAURAg4girh=FSUSnhd5S_CA@mail.gmail.com>
	<CAO1zAVbz7vQW6xgQ-LKAqf3+QMGKkSWwJ5fwHVBQyHLrS6KPRQ@mail.gmail.com>
Message-ID: <CAMd4_Ae9TjS2UND3J0c6mwMQYX15Digg5VGuomctOiV=8fj5eg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111118/82653c83/attachment.pl>

From jordigh at octave.org  Fri Nov 18 18:34:25 2011
From: jordigh at octave.org (=?UTF-8?Q?Jordi_Guti=C3=A9rrez_Hermoso?=)
Date: Fri, 18 Nov 2011 12:34:25 -0500
Subject: [Rd] Non-free packages in CRAN
In-Reply-To: <02D869B4-DDC4-47DE-93DB-B5C897A130F0@r-project.org>
References: <CAPHS2gwarCZPEVha2e6+tXx2WnA3Ys41ZFvZZgYYcstQk73Cmg@mail.gmail.com>
	<02D869B4-DDC4-47DE-93DB-B5C897A130F0@r-project.org>
Message-ID: <CAPHS2gy0qcUfyr+H5vV_n8p-RkgwrtpnLbLE+eMB8iAS+pYyVg@mail.gmail.com>

2011/11/18 Simon Urbanek <simon.urbanek at r-project.org>:
> I think you are misunderstanding a few things here. First, "R"
> doesn't endorse anything - it is a program,

It is also an organisation and that organisation has a website.
Someone is responsible for the contents of that website and the views
espoused in it. Saying that "R" was just a shorthand for the
organisation built around R

Software isn't amoral. Software is deeply related to what we people
can and should be able to do. People are responsible for what their
software does.

> it does what you tell it to do. Second, whoever runs R-forge doesn't
> endorse the packages hosted on it, either. It's just an
> infrastructure, with no claim about endorsement of the package
> hosted there

The R organisation is referring to that website, it's hosted at the
same top-level domain, it looks like the R organisation is endorsing R
Forge, and R-Forge is endorsing non-free software.

> Third, LGPL is a GNU license and also a open source license

I'm a little sad by members of GNU using the term "open source". More
importantly than open source, it's a free license.

And this is besides the point. The wrapper is LGPL, but it's a wrapper
for a non-free library.

> If anyone shared your interpretation, there would be no GNU/Linux
> since glibc is LGPL licensed and so are parts of gcc (and hence
> according to your argument neither can be a GNU project). Note that
> a lot of GNU libraries are licensed under LGPL.

This is a strawman. I'm not saying the LGPL is non-free. I'm saying
the combination of that wrapper with MOSEK is non-free.

> The fact that you personally may not like licenses other than GPL

This is another strawman. I didn't say I disliked licenses other than
the GPL. I said R shouldn't endorse a project that endorses non-free
software.

> As for giving access to proprietary software - I think the argument
> is the exact opposite of what you are saying. By having the ability
> to leverage functionality (be it proprietary) that doesn't exist in
> R/Octave/.., you are making the free software stronger.

I don't see how MOSEK is making free software stronger. It's not
encouraging the usage of more free software. It's encouraging the use
of MOSEK. MOSEK should not be endorsed by an organisation that is
supposed to promote free software.

If these really are your views and they're representative of the R
project, then the solution seems to be to make R stop calling itself
part of the GNU project. I hope it doesn't do this.

- Jordi G. H.


From kevin.r.coombes at gmail.com  Fri Nov 18 18:34:56 2011
From: kevin.r.coombes at gmail.com (Kevin R. Coombes)
Date: Fri, 18 Nov 2011 11:34:56 -0600
Subject: [Rd] round() ignores missing arguments if it is used inside
 another function where some arguments are missing.
In-Reply-To: <CAO1zAVYLrLFLdPQkm8Wt=dTAoijqHP83a2tVRBaTXybPWNv8wA@mail.gmail.com>
References: <CAO1zAVaS6YN=7V7tciOpgDA98haDY3wPYyuQt-cxkcsqXGsz=A@mail.gmail.com>
	<1321632620.17906.68.camel@prometheus.geog.ucl.ac.uk>
	<CAO1zAVYLrLFLdPQkm8Wt=dTAoijqHP83a2tVRBaTXybPWNv8wA@mail.gmail.com>
Message-ID: <4EC69740.6010405@gmail.com>

You can also see the odd behavior without wrapping round in another 
function:

 > round(100.1, digits=)
[1] 100

On 11/18/2011 10:19 AM, Joris Meys wrote:
> On Fri, Nov 18, 2011 at 5:10 PM, Gavin Simpson<gavin.simpson at ucl.ac.uk>  wrote:
>> round is indicated to not evaluate its arguments. I don't follow the C
>> code well enough to know if it should be catching the missing argument
>> further on - it must be because it is falling back to the default, but
>> the above explains that the not evaluating arguments is intended.
>>
>> G
> So if I understand it right, the y argument is not evaluated in the
> fun2 function but deeper in the C code. that explains the lack of the
> error message, thanks! I keep on learning every day.
> Cheers
>
> Joris
>


From jordigh at octave.org  Fri Nov 18 19:00:31 2011
From: jordigh at octave.org (=?UTF-8?Q?Jordi_Guti=C3=A9rrez_Hermoso?=)
Date: Fri, 18 Nov 2011 13:00:31 -0500
Subject: [Rd] Non-free packages in R-Forge
Message-ID: <CAPHS2gwxcdpyYPms1DeeTQYALZBTF1KsSN+8Y_Ayf0_Rt71OUg@mail.gmail.com>

I'm sorry about the tone of my previous email. Let me try again in a
cleaner way.

The problem is: R or the organisation behind R via its infrastructure
seems to be endorsing R-Forge, and R-Forge is hosting at least one
project whose sole purpose is to link R with non-free software. This
looks like endorsement of non-free software, which is contrary to the
aims of the GNU project, of which R today claims to be a part.

There are several solutions, but the only workable ones I see are to
either sever ties with the GNU project, clearly remove the endorsement
of the non-free project, or to make the non-free project free. Of
these, it is my sincere hope that the last one happens.

That is all.

- Jordi G. H.


From dwinsemius at comcast.net  Fri Nov 18 19:17:46 2011
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 18 Nov 2011 13:17:46 -0500
Subject: [Rd] Non-free packages in R-Forge
In-Reply-To: <CAPHS2gwxcdpyYPms1DeeTQYALZBTF1KsSN+8Y_Ayf0_Rt71OUg@mail.gmail.com>
References: <CAPHS2gwxcdpyYPms1DeeTQYALZBTF1KsSN+8Y_Ayf0_Rt71OUg@mail.gmail.com>
Message-ID: <89F1DF2A-59DB-4429-9CDB-1411B92C013E@comcast.net>


On Nov 18, 2011, at 1:00 PM, Jordi Guti?rrez Hermoso wrote:

> I'm sorry about the tone of my previous email. Let me try again in a
> cleaner way.
>
> The problem is: R or the organisation behind R via its infrastructure
> seems to be endorsing R-Forge, and R-Forge is hosting at least one
> project whose sole purpose is to link R with non-free software. This
> looks like endorsement of non-free software, which is contrary to the
> aims of the GNU project, of which R today claims to be a part.

Are you aware that R has two other major trunks besides the Linux one?  
Those of us with Mac or Windows hardware/software devices might be  
threatened with discontinuation of our access to R if your logic  
prevails.

> There are several solutions, but the only workable ones I see are to
> either sever ties with the GNU project, clearly remove the endorsement
> of the non-free project, or to make the non-free project free. Of
> these, it is my sincere hope that the last one happens.

This entire argument seems quasi-religious. You seem to be claiming  
that there is a "non-free" moral and legal sinfulness that is passed  
by way of links on websites. There do not seem to be any boundaries to  
this process that are discernable from your writings.

>
> That is all.
>
> - Jordi G. H.
>


David Winsemius, MD
West Hartford, CT


From marc_schwartz at me.com  Fri Nov 18 19:20:02 2011
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 18 Nov 2011 12:20:02 -0600
Subject: [Rd] Non-free packages in R-Forge
In-Reply-To: <CAPHS2gwxcdpyYPms1DeeTQYALZBTF1KsSN+8Y_Ayf0_Rt71OUg@mail.gmail.com>
References: <CAPHS2gwxcdpyYPms1DeeTQYALZBTF1KsSN+8Y_Ayf0_Rt71OUg@mail.gmail.com>
Message-ID: <6E7527BF-9E39-47AC-A2EA-53D432905793@me.com>


On Nov 18, 2011, at 12:00 PM, Jordi Guti?rrez Hermoso wrote:

> I'm sorry about the tone of my previous email. Let me try again in a
> cleaner way.
> 
> The problem is: R or the organisation behind R via its infrastructure
> seems to be endorsing R-Forge, and R-Forge is hosting at least one
> project whose sole purpose is to link R with non-free software. This
> looks like endorsement of non-free software, which is contrary to the
> aims of the GNU project, of which R today claims to be a part.
> 
> There are several solutions, but the only workable ones I see are to
> either sever ties with the GNU project, clearly remove the endorsement
> of the non-free project, or to make the non-free project free. Of
> these, it is my sincere hope that the last one happens.
> 
> That is all.
> 
> - Jordi G. H.


It seems to me that you have a rather RMS-like mindset, as opposed to Simon's more pragmatic approach, which frankly, as a FOSS supporter and useR of R for 10 years, I prefer.

If you feel so strongly about your position, then take it up with the FSF and pursue it there!

This is degenerating into a philosophical debate, based on your opinion alone, which is not going to be resolved in this forum.

Move on.

Marc Schwartz


From jordigh at octave.org  Fri Nov 18 19:32:18 2011
From: jordigh at octave.org (=?UTF-8?Q?Jordi_Guti=C3=A9rrez_Hermoso?=)
Date: Fri, 18 Nov 2011 13:32:18 -0500
Subject: [Rd] Non-free packages in R-Forge
In-Reply-To: <89F1DF2A-59DB-4429-9CDB-1411B92C013E@comcast.net>
References: <CAPHS2gwxcdpyYPms1DeeTQYALZBTF1KsSN+8Y_Ayf0_Rt71OUg@mail.gmail.com>
	<89F1DF2A-59DB-4429-9CDB-1411B92C013E@comcast.net>
Message-ID: <CAPHS2gwym6W0zQL+zikaEBytjdWBdZJ=mDdrpBQ1KMRkt0nR0A@mail.gmail.com>

Let me give a little more context of why this is important.

As you can read in this thread:

    http://sourceforge.net/mailarchive/forum.php?thread_name=CAPHS2gwmxJGF9Cy8%3DSEGasQcVRg_Lqu-
ndCdVhO-r1LJsRQGuA%40mail.gmail.com&forum_name=octave-dev

The author of MOSEK basically created a non-free library and wants to
link it to both Octave and R. Normally this would be a GPL violation;
however the author of MOSEK has worked around the GPL by making a
wrapper and making the user do the linking, effectively neutering the
copyleft of the GPL (and yes, the GPL is not nice, and this
non-niceness of the GPL is a feature).

I am trying to reject this in Octave. We do not want to condone the
proliferation of non-free software. Instead, I invite the makers of
MOSEK to make the library free. However, the author has pointed out
that R has accepted his plugin, why can't Octave?

And this is why I appeal to the GNUness of R, if it still has it. If
Octave and R are part of the same organisation, we have to stand
together on this, and together pressure the maker of MOSEK to release
MOSEK as free software and stop trying to work around the GPL with
wrappers and avoiding binary distribution.

I am inviting R to work together with Octave on this. If we are both
using the GPL and both part of GNU, what good is it if the GPL can be
worked around and if we don't both stand for the same principles?

This isn't about prohibiting R from running on Windows or Mac (Octave
also runs on both because it's the only way to reach those users), nor
about meaningless ideology, but about bringing about a very practical
result: more free software for the community, more source for
everyone.

So, please, users and developers and overseers of R, work with us. If
we are on the same team, can we work towards the same goals?

- Jordi G. H.


From kevin.r.coombes at gmail.com  Fri Nov 18 19:52:12 2011
From: kevin.r.coombes at gmail.com (Kevin R. Coombes)
Date: Fri, 18 Nov 2011 12:52:12 -0600
Subject: [Rd] Non-free packages in R-Forge
In-Reply-To: <CAPHS2gwxcdpyYPms1DeeTQYALZBTF1KsSN+8Y_Ayf0_Rt71OUg@mail.gmail.com>
References: <CAPHS2gwxcdpyYPms1DeeTQYALZBTF1KsSN+8Y_Ayf0_Rt71OUg@mail.gmail.com>
Message-ID: <4EC6A95C.5010304@gmail.com>

You are, of course, missing the obvious solution, which is to do nothing.

The "endorsement" of a non-free project seems to me to reside only in 
your imagination.  The primary product produced by "The R Project for 
Statistical Computing" is the statistical software environment R, which 
is released under the GPL.  It is free software under anyone's 
definition.  One can safely infer that members of the R Project clearly 
endorse the goals of the GNU Project (as you can see, for example, from 
the fact that the only hyperlinks from the "What is R?" web page point 
to FSF or GNU).  I think that there is no chance that members of the R 
project would voluntarily "sever its ties with GNU" over this issue.

It's also not clear that there is any formal process for something 
becoming "a GNU project". If there were, you could then go to the GNU 
organization or to FSF and convince them to take some action to force 
the R project to stop calling itself a GNU project.  (I strongly suspect 
that there are neither copyright nor trademark nor other enforceable 
agreements to cause anything to happen in that regard.)

Now, the web site for the R project does point from its "related 
projects" page to R-Forge as a framework where packages that work with R 
can be developed.  It also displays prominent links to CRAN and to 
Bioconductor as locations where users can obtain R packages.  In that 
sense, I would be willing to agree that the R project "endorses" 
R-Rorge, CRAN, and Bioconductor.

However, I strongly object to the idea that this includes an endorsement 
of all (or even *any*) of the packages developed or hosted on those 
three other sites.  There are plenty of R packages in all of those 
locations that are provided under licenses other than GPL, LGPL, or 
PAL.  Some of those licenses are clearly non-free (in both the liberty 
and dollar senses).

For example, I use the mclust package (available from CRAN) all the 
time.  The license for this package requires an annual payment of a 
licensing fee for non-academic use, which limits modification and 
redistribution.  I have developed my own packages that depend on 
mclust.  The code that I wrote is available under the Perl Artistic 
License.  But if anyone wants to use my pacakge, they still have to 
conform to the terms of use defined by the license for mclust, on which 
my package depends.  I don't think that the University of Washington 
shoudl be prevented from specifying the license terms it wants for 
mclust.  And I don't think users (academic or otherwise) would get any 
beenfits if mclust was prevented from being made available through CRAN.

As far as I can tell, the situation with mclust is directly analogous to 
the situation you are complaining about with MOSEK being hosted at R-Forge.

Here's my suggestion. Stop trying to prevent users who want to talk to 
MOSEK from R from getting a package that will accomplish that task. Your 
real problem seems to be that MOSEK is not free.  So do what Stallman 
did when he objected to the fact that UNIX was not free. (Or MOTIF. Or 
lots of other stuff.) Get some developers together, work in a clean 
environment where they won't violate any copyright in the existing code, 
and develop a free alternative.

     Kevin

On 11/18/2011 12:00 PM, Jordi Guti?rrez Hermoso wrote:
> I'm sorry about the tone of my previous email. Let me try again in a
> cleaner way.
>
> The problem is: R or the organisation behind R via its infrastructure
> seems to be endorsing R-Forge, and R-Forge is hosting at least one
> project whose sole purpose is to link R with non-free software. This
> looks like endorsement of non-free software, which is contrary to the
> aims of the GNU project, of which R today claims to be a part.
>
> There are several solutions, but the only workable ones I see are to
> either sever ties with the GNU project, clearly remove the endorsement
> of the non-free project, or to make the non-free project free. Of
> these, it is my sincere hope that the last one happens.
>
> That is all.
>
> - Jordi G. H.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From spencer.graves at prodsyse.com  Fri Nov 18 21:28:27 2011
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Fri, 18 Nov 2011 12:28:27 -0800
Subject: [Rd] Non-free packages in R-Forge
In-Reply-To: <CAPHS2gwym6W0zQL+zikaEBytjdWBdZJ=mDdrpBQ1KMRkt0nR0A@mail.gmail.com>
References: <CAPHS2gwxcdpyYPms1DeeTQYALZBTF1KsSN+8Y_Ayf0_Rt71OUg@mail.gmail.com>
	<89F1DF2A-59DB-4429-9CDB-1411B92C013E@comcast.net>
	<CAPHS2gwym6W0zQL+zikaEBytjdWBdZJ=mDdrpBQ1KMRkt0nR0A@mail.gmail.com>
Message-ID: <4EC6BFEB.6090004@prodsyse.com>

Jordi:


       Why do you want to reduce demand for Octave by forcing people who 
want to link to a commercial product to abandon Octave?


       Are you familiar with Shapiro and Varian (1998) Information 
Rules:  A Strategic Guide to the Network Economy (Harvard Bus. Sch. 
Pr.)?  Varian is now the Chief Economist at Google, and his ideas seem 
to have contributed substantially to their success.  The book explains 
that if you want to increase the market for your product, you need to 
make it as easy as possible for potential users to use (for as many 
different purposes).


       I've used Matlab, and I want to start using Octave.  If I can 
connect from only one of these products to some third party software 
that I'd like also to use, that's a reason to use the more flexible 
product.


       Spencer


On 11/18/2011 10:32 AM, Jordi Guti?rrez Hermoso wrote:
> Let me give a little more context of why this is important.
>
> As you can read in this thread:
>
>      http://sourceforge.net/mailarchive/forum.php?thread_name=CAPHS2gwmxJGF9Cy8%3DSEGasQcVRg_Lqu-
> ndCdVhO-r1LJsRQGuA%40mail.gmail.com&forum_name=octave-dev
>
> The author of MOSEK basically created a non-free library and wants to
> link it to both Octave and R. Normally this would be a GPL violation;
> however the author of MOSEK has worked around the GPL by making a
> wrapper and making the user do the linking, effectively neutering the
> copyleft of the GPL (and yes, the GPL is not nice, and this
> non-niceness of the GPL is a feature).
>
> I am trying to reject this in Octave. We do not want to condone the
> proliferation of non-free software. Instead, I invite the makers of
> MOSEK to make the library free. However, the author has pointed out
> that R has accepted his plugin, why can't Octave?
>
> And this is why I appeal to the GNUness of R, if it still has it. If
> Octave and R are part of the same organisation, we have to stand
> together on this, and together pressure the maker of MOSEK to release
> MOSEK as free software and stop trying to work around the GPL with
> wrappers and avoiding binary distribution.
>
> I am inviting R to work together with Octave on this. If we are both
> using the GPL and both part of GNU, what good is it if the GPL can be
> worked around and if we don't both stand for the same principles?
>
> This isn't about prohibiting R from running on Windows or Mac (Octave
> also runs on both because it's the only way to reach those users), nor
> about meaningless ideology, but about bringing about a very practical
> result: more free software for the community, more source for
> everyone.
>
> So, please, users and developers and overseers of R, work with us. If
> we are on the same team, can we work towards the same goals?
>
> - Jordi G. H.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hadley at rice.edu  Fri Nov 18 23:07:36 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Fri, 18 Nov 2011 16:07:36 -0600
Subject: [Rd] DSC?
Message-ID: <CABdHhvHFsjGNwT8kann7HL252pD4is5UtBvt_CebbgKEtUMo_Q@mail.gmail.com>

Could whoever is in charge of the next DSC contact me?  We might be
able to co-host it with interface in Houston, May 16-18 2012.

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From hb at biostat.ucsf.edu  Sat Nov 19 00:30:12 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Fri, 18 Nov 2011 15:30:12 -0800
Subject: [Rd] Windows binaries: Version and revision strings show
	"(2006-00-00 r00000)"
Message-ID: <CAFDcVCQn6XbJkbrGvWcpmDEAS8Ugn8fEmy1z7kiFqSxWOE_tYA@mail.gmail.com>

FYI,

for the last few revision the version string for both R v2.14.0
patched and R devel are not correct for the Windows binaries.  This is
what R --version and sessionInfo() report since a couple of days:

R version 2.14.0 Patched (2006-00-00 r00000)
R Under development (unstable) (2006-00-00 r00000)

Also, "r00000" is listed as the revision on:

http://cran.r-project.org/bin/windows/base/rdevel.html
http://cran.r-project.org/bin/windows/base/rpatched.html

/Henrik


From jorismeys at gmail.com  Sat Nov 19 00:50:27 2011
From: jorismeys at gmail.com (Joris Meys)
Date: Sat, 19 Nov 2011 00:50:27 +0100
Subject: [Rd] Non-free packages in CRAN
In-Reply-To: <CAPHS2gy0qcUfyr+H5vV_n8p-RkgwrtpnLbLE+eMB8iAS+pYyVg@mail.gmail.com>
References: <CAPHS2gwarCZPEVha2e6+tXx2WnA3Ys41ZFvZZgYYcstQk73Cmg@mail.gmail.com>
	<02D869B4-DDC4-47DE-93DB-B5C897A130F0@r-project.org>
	<CAPHS2gy0qcUfyr+H5vV_n8p-RkgwrtpnLbLE+eMB8iAS+pYyVg@mail.gmail.com>
Message-ID: <CAO1zAVYKY9sqPWO1itOL93s+z21mXr4aQ2TMgOuGP5ar4PBWmQ@mail.gmail.com>

2011/11/18 Jordi Guti?rrez Hermoso <jordigh at octave.org>:
>
> I don't see how MOSEK is making free software stronger. It's not
> encouraging the usage of more free software. It's encouraging the use
> of MOSEK. MOSEK should not be endorsed by an organisation that is
> supposed to promote free software.
>
> If these really are your views and they're representative of the R
> project, then the solution seems to be to make R stop calling itself
> part of the GNU project. I hope it doesn't do this.
>
> - Jordi G. H.
>
I'm not going into the discussion about which license represents what.
I hate politics and ideological discussions because of all the blabla.
I'm a statistician. I work with facts.

Fact : Simon is not the R-project, the R-core or the R community. He's
one guy, and a pretty smart one that is.
Fact : At my department several people use R only because they have
access to non-GPL programs through R: because they can load Excel and
SPSS files if they have to, connect to SQLServer and Access, ...
Fact : They often don't use Octave for exactly the same reason: They
don't have access to the tools they need. They're using Matlab
instead. We do have SPlus on the servers too. Guess how many people
are using that...
Fact : I get paid for statistical advice. I pay for a hammer. I pay
for a bike. If I have to pay for a tool I need on my computer, I pay
for it. If there's a free alternative that can get me as far, I use
that one and support their community with a gift if I care enough
about the tool. Which reminds me...
Fact : If I see too many quasi-religious statements, tool goes out and
I leave the building.

You're not doing your cause a favor here.

Cheers
Joris

Being religious about free software never helped the cause. And by
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From hb at biostat.ucsf.edu  Sat Nov 19 04:35:06 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Fri, 18 Nov 2011 19:35:06 -0800
Subject: [Rd] round() ignores missing arguments if it is used inside
 another function where some arguments are missing.
In-Reply-To: <4EC69740.6010405@gmail.com>
References: <CAO1zAVaS6YN=7V7tciOpgDA98haDY3wPYyuQt-cxkcsqXGsz=A@mail.gmail.com>
	<1321632620.17906.68.camel@prometheus.geog.ucl.ac.uk>
	<CAO1zAVYLrLFLdPQkm8Wt=dTAoijqHP83a2tVRBaTXybPWNv8wA@mail.gmail.com>
	<4EC69740.6010405@gmail.com>
Message-ID: <CAFDcVCRJ9xxpCQxo3sk+_97c6gpFq5WvpLpf08MT0j8T=hpPuA@mail.gmail.com>

On Fri, Nov 18, 2011 at 9:34 AM, Kevin R. Coombes
<kevin.r.coombes at gmail.com> wrote:
> You can also see the odd behavior without wrapping round in another
> function:
>
>> round(100.1, digits=)
> [1] 100

Hmm... is there a reason for why the parser accepts that construct?
Some example:

> parse(text="f(a=)")
expression(f(a=))

> parse(text="f[a=]")
expression(f[a=])

> parse(text="(a=)")
Error in parse.default(text = "(a=)") : <text>:1:4: unexpected ')'
1: (a=)

/Henrik

>
> On 11/18/2011 10:19 AM, Joris Meys wrote:
>>
>> On Fri, Nov 18, 2011 at 5:10 PM, Gavin Simpson<gavin.simpson at ucl.ac.uk>
>> ?wrote:
>>>
>>> round is indicated to not evaluate its arguments. I don't follow the C
>>> code well enough to know if it should be catching the missing argument
>>> further on - it must be because it is falling back to the default, but
>>> the above explains that the not evaluating arguments is intended.
>>>
>>> G
>>
>> So if I understand it right, the y argument is not evaluated in the
>> fun2 function but deeper in the C code. that explains the lack of the
>> error message, thanks! I keep on learning every day.
>> Cheers
>>
>> Joris
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ripley at stats.ox.ac.uk  Sat Nov 19 07:47:29 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 19 Nov 2011 06:47:29 +0000 (GMT)
Subject: [Rd] Windows binaries: Version and revision strings show
 "(2006-00-00 r00000)"
In-Reply-To: <CAFDcVCQn6XbJkbrGvWcpmDEAS8Ugn8fEmy1z7kiFqSxWOE_tYA@mail.gmail.com>
References: <CAFDcVCQn6XbJkbrGvWcpmDEAS8Ugn8fEmy1z7kiFqSxWOE_tYA@mail.gmail.com>
Message-ID: <alpine.LFD.2.02.1111190646060.8716@gannet.stats.ox.ac.uk>

Which 'Windows binaries'?

Mine are correct, so you need to take this up with the builder (named 
on CRAN).  No one else on R-devel can do anything about this.

On Fri, 18 Nov 2011, Henrik Bengtsson wrote:

> FYI,
>
> for the last few revision the version string for both R v2.14.0
> patched and R devel are not correct for the Windows binaries.  This is
> what R --version and sessionInfo() report since a couple of days:
>
> R version 2.14.0 Patched (2006-00-00 r00000)
> R Under development (unstable) (2006-00-00 r00000)
>
> Also, "r00000" is listed as the revision on:
>
> http://cran.r-project.org/bin/windows/base/rdevel.html
> http://cran.r-project.org/bin/windows/base/rpatched.html
>
> /Henrik
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pdalgd at gmail.com  Sat Nov 19 09:13:15 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 19 Nov 2011 09:13:15 +0100
Subject: [Rd] round() ignores missing arguments if it is used inside
	another function where some arguments are missing.
In-Reply-To: <CAFDcVCRJ9xxpCQxo3sk+_97c6gpFq5WvpLpf08MT0j8T=hpPuA@mail.gmail.com>
References: <CAO1zAVaS6YN=7V7tciOpgDA98haDY3wPYyuQt-cxkcsqXGsz=A@mail.gmail.com>
	<1321632620.17906.68.camel@prometheus.geog.ucl.ac.uk>
	<CAO1zAVYLrLFLdPQkm8Wt=dTAoijqHP83a2tVRBaTXybPWNv8wA@mail.gmail.com>
	<4EC69740.6010405@gmail.com>
	<CAFDcVCRJ9xxpCQxo3sk+_97c6gpFq5WvpLpf08MT0j8T=hpPuA@mail.gmail.com>
Message-ID: <0C855C67-A6E6-4B6B-84EB-F64AF363E1AF@gmail.com>


On Nov 19, 2011, at 04:35 , Henrik Bengtsson wrote:

> On Fri, Nov 18, 2011 at 9:34 AM, Kevin R. Coombes
> <kevin.r.coombes at gmail.com> wrote:
>> You can also see the odd behavior without wrapping round in another
>> function:
>> 
>>> round(100.1, digits=)
>> [1] 100
> 
> Hmm... is there a reason for why the parser accepts that construct?

Yes. See e.g. help(alist) for actual usage. 

It can also be used to pass empty arguments to FUN in apply-constructs:

a <- matrix(1:12, 3, 4)
f <- function(i, j) a[i,j]
lapply(1:4, f, i=)


> Some example:
> 
>> parse(text="f(a=)")
> expression(f(a=))
> 
>> parse(text="f[a=]")
> expression(f[a=])
> 
>> parse(text="(a=)")
> Error in parse.default(text = "(a=)") : <text>:1:4: unexpected ')'
> 1: (a=)
> 
> /Henrik
> 
>> 
>> On 11/18/2011 10:19 AM, Joris Meys wrote:
>>> 
>>> On Fri, Nov 18, 2011 at 5:10 PM, Gavin Simpson<gavin.simpson at ucl.ac.uk>
>>>  wrote:
>>>> 
>>>> round is indicated to not evaluate its arguments. I don't follow the C
>>>> code well enough to know if it should be catching the missing argument
>>>> further on - it must be because it is falling back to the default, but
>>>> the above explains that the not evaluating arguments is intended.
>>>> 
>>>> G
>>> 
>>> So if I understand it right, the y argument is not evaluated in the
>>> fun2 function but deeper in the C code. that explains the lack of the
>>> error message, thanks! I keep on learning every day.
>>> Cheers
>>> 
>>> Joris
>>> 
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From spinuvit at gmail.com  Sat Nov 19 12:28:15 2011
From: spinuvit at gmail.com (Vitalie Spinu)
Date: Sat, 19 Nov 2011 12:28:15 +0100
Subject: [Rd] Problems with new srcref warnings in R 2.14 (development)
Message-ID: <CAAQMm-_oCbiKWj56+un8tMjNemNuYJxPSwUfpQag25Ltv3zdRQ@mail.gmail.com>

Dear R developers,

Print method for function now tries to open the source file associated
with srcref of the function.

It outputs only the warning, if file cannot be open,  and forgets to
print the function definition.

Example:

eval(parse(text = "tf <- function(a){
    b <- a^4
    b
}",  srcfile = srcfile("xxx at 17")))

> tf
<srcref: file "xxx at 17" chars 1:7 to 4:1>
Warning message:
In file(srcfile$filename, open = "rt", encoding = encoding) :
  cannot open file 'xxx at 17': No such file or directory

First, the function definition is not printed and I assume it's a bug.
Second, the warning might not be appropriate.
For example ESS with the latest  ess-tracebug
(http://code.google.com/p/ess-tracebug/) inserts srcref into the
function on the fly.
Srcfile is of the form file_name at index where index is used to find the
function definition afterwards.

This is useful for two reasons:
-- the visual debugger knows about the reference and  jumps through
the function even if the file was not sourced
-- any typos/errors in the code are reported by R with the source
reference, so that the  editor can automatically jump to the error
location.

Can please an option to suppress the warnings or even better suppress
the srcfile validity checks  be implemented?

Thanks,
Vitalie.

sessionInfo()
R Under development (unstable) (2011-11-15 r57665)
Platform: i686-pc-linux-gnu (32-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
LC_TIME=en_US.UTF-8
 [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-8
LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=C                 LC_NAME=C
LC_ADDRESS=C
[10] LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8
LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base
>


From brian at braverock.com  Sat Nov 19 15:33:28 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Sat, 19 Nov 2011 08:33:28 -0600
Subject: [Rd] Windows binaries: Version and revision strings show
 "(2006-00-00 r00000)"
In-Reply-To: <CAFDcVCQn6XbJkbrGvWcpmDEAS8Ugn8fEmy1z7kiFqSxWOE_tYA@mail.gmail.com>
References: <CAFDcVCQn6XbJkbrGvWcpmDEAS8Ugn8fEmy1z7kiFqSxWOE_tYA@mail.gmail.com>
Message-ID: <1321713208.29526.12.camel@brian-rcg>

On Fri, 2011-11-18 at 15:30 -0800, Henrik Bengtsson wrote:
> Also, "r00000" is listed as the revision on:
> 
> http://cran.r-project.org/bin/windows/base/rdevel.html
> http://cran.r-project.org/bin/windows/base/rpatched.html
> 
I see these as 2011-11-18 r00000 and as built by Duncan Murdoch, who is
on the r-devel list.

> 
-- 
Brian G. Peterson


From octave at phaselockedsystems.com  Sat Nov 19 02:16:25 2011
From: octave at phaselockedsystems.com (Robert T. Short)
Date: Fri, 18 Nov 2011 17:16:25 -0800
Subject: [Rd] [OctDev]  Non-free packages in CRAN
In-Reply-To: <CAO1zAVYKY9sqPWO1itOL93s+z21mXr4aQ2TMgOuGP5ar4PBWmQ@mail.gmail.com>
References: <CAPHS2gwarCZPEVha2e6+tXx2WnA3Ys41ZFvZZgYYcstQk73Cmg@mail.gmail.com>	<02D869B4-DDC4-47DE-93DB-B5C897A130F0@r-project.org>	<CAPHS2gy0qcUfyr+H5vV_n8p-RkgwrtpnLbLE+eMB8iAS+pYyVg@mail.gmail.com>
	<CAO1zAVYKY9sqPWO1itOL93s+z21mXr4aQ2TMgOuGP5ar4PBWmQ@mail.gmail.com>
Message-ID: <4EC70369.8000306@phaselockedsystems.com>

Where is the "like" button when you need it?

Joris Meys wrote:
> 2011/11/18 Jordi Guti?rrez Hermoso<jordigh at octave.org>:
>    
>> I don't see how MOSEK is making free software stronger. It's not
>> encouraging the usage of more free software. It's encouraging the use
>> of MOSEK. MOSEK should not be endorsed by an organisation that is
>> supposed to promote free software.
>>
>> If these really are your views and they're representative of the R
>> project, then the solution seems to be to make R stop calling itself
>> part of the GNU project. I hope it doesn't do this.
>>
>> - Jordi G. H.
>>
>>      
> I'm not going into the discussion about which license represents what.
> I hate politics and ideological discussions because of all the blabla.
> I'm a statistician. I work with facts.
>
> Fact : Simon is not the R-project, the R-core or the R community. He's
> one guy, and a pretty smart one that is.
> Fact : At my department several people use R only because they have
> access to non-GPL programs through R: because they can load Excel and
> SPSS files if they have to, connect to SQLServer and Access, ...
> Fact : They often don't use Octave for exactly the same reason: They
> don't have access to the tools they need. They're using Matlab
> instead. We do have SPlus on the servers too. Guess how many people
> are using that...
> Fact : I get paid for statistical advice. I pay for a hammer. I pay
> for a bike. If I have to pay for a tool I need on my computer, I pay
> for it. If there's a free alternative that can get me as far, I use
> that one and support their community with a gift if I care enough
> about the tool. Which reminds me...
> Fact : If I see too many quasi-religious statements, tool goes out and
> I leave the building.
>
> You're not doing your cause a favor here.
>
> Cheers
> Joris
>
> Being religious about free software never helped the cause. And by
>    
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>      
>
>
>


From ligges at statistik.tu-dortmund.de  Sat Nov 19 18:04:11 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 19 Nov 2011 18:04:11 +0100
Subject: [Rd] strange behavior from cex="*"
In-Reply-To: <4EC621D8.7020100@pburns.seanet.com>
References: <4EC42D66.502@gmail.com>
	<1C6B85B4-9803-407B-83BB-19159CCB2778@gmail.com>
	<4EC4388A.6070502@gmail.com> <4EC4556E.4050507@gmail.com>
	<4EC621D8.7020100@pburns.seanet.com>
Message-ID: <4EC7E18B.7030001@statistik.tu-dortmund.de>



On 18.11.2011 10:14, Patrick Burns wrote:
> Someone ambitious could find problems like
> this using random input testing like I talked
> about at useR last summer.
>
> http://www.burns-stat.com/pages/Present/random_input_test_annotated.pdf
>
> Testing graphics would be more labor intensive
> than the testing I do, but you could think of it
> as a video game.

See also the graphicsQC package.

Uwe

> On 17/11/2011 00:29, Duncan Murdoch wrote:
>> On 11-11-16 5:26 PM, Ben Bolker wrote:
>> > -----BEGIN PGP SIGNED MESSAGE-----
>> > Hash: SHA1
>> >
>> > On 11-11-16 05:18 PM, peter dalgaard wrote:
>> >>
>> >> On Nov 16, 2011, at 22:38 , Ben Bolker wrote:
>> >>
>> >>> Someone inquired on StackOverflow about apparently non-deterministic
>> >>> graphics behaviour in R. I noticed that they were using cex="*" and
>> >>> discovered some potentially weird behavior.
>> >>
>> >> It can be reproduced much more simply (well, not the hang, but bad
>> >> enough):
>> >>
>> >> In a plain R application console (OSX Snow Leopard),
>> >>
>> >> for (i in 1:100) plot(1:10,cex="*")
>> >>
>> >> will _sometimes_ show big circles, indicating random data being
>> >> picked up.
>> >>
>> >> The "cex" is by definition numeric, so you can't expect to be able to
>> >> pass a character string, but the code should check.
>> >
>> > Looks (?) like the check could go in FixupCex (which already tests for
>> > isReal, isInteger, and isLogical) in src/main/plot.c , unless there
>> is a
>> > wish to catch it earlier/in R code.
>>
>> Yes, that's where the check was missed. I'll fix it. The other
>> parameters appear to have been checked properly.
>>
>> > It's mildly surprising to me that people can continue to find odd
>> > cases like this after more than 10 years (and imagine how many
>> > cumulative hours of R use ...) [I'm assuming that this hole has been
>> > present for a log time: I don't have the patience to do the SVN
>> > archaeology to find out how long.]
>>
>> So now you can prove me wrong about the other parameters...
>>
>> Duncan Murdoch
>>
>>
>> >
>> >>
>> >>>
>> >>> On repeated runs of the same code I can get different PNGs. If I set
>> >>> the number of runs high enough, I seem to be able to get R to hang.
>> >>> If I do a single version plotting to an interactive graphics window I
>> >>> can get the point sizes to jump around as I resize the window
>> (someone
>> >>> reported being able to reproduce that behaviour in the Windows GUI
>> >>> as well).
>> >>>
>> >>> This is clearly a user error, but non-deterministic behaviour (and
>> >>> hanging) are a little disturbing.
>> >>>
>> >>> I haven't had a chance yet to try to dig in and see what's happening
>> >>> but thought I would report to see if anyone else could
>> reproduce/figure
>> >>> it out.
>> >>>
>> >>> Ben Bolker
>> >>>
>> >>>
>> >>> ########################
>> >>> ## n<- 100 ## hangs R
>> >>>
>> >>> n<- 33
>> >>>
>> >>> fn<- paste("tmp",seq(n),"png",sep=".")
>> >>> for (i in seq(n)) {
>> >>> png(fn[i])
>> >>> plot(1:10,1:10,cex="*");
>> >>> dev.off()
>> >>> }
>> >>>
>> >>> ff<- subset(file.info(fn),select=size)
>> >>> ff<- ff[!duplicated(ff$size),,drop=FALSE]
>> >>> table(ff$size)
>> >>> require(png)
>> >>> pngs<- lapply(rownames(ff),readPNG)
>> >>>
>> >>> png.to.img<- function(x) matrix(rgb(x[,,1],x[,,2],x[,,3]),
>> >>> nrow=dim(x)[1],ncol=dim(x)[2])
>> >>>
>> >>> imgs<- lapply(pngs,png.to.img)
>> >>>
>> >>> par(mfrow=c(2,2))
>> >>> lapply(imgs,function(x) {
>> >>> plot(0:1,0:1,type="n",ann=FALSE,axes=FALSE)
>> >>> rasterImage(x,0,0,1,1)
>> >>> })
>> >>>
>> >>> #########################
>> >>>
>> >>>> sessionInfo()
>> >>> R Under development (unstable) (2011-10-06 r57181)
>> >>> Platform: i686-pc-linux-gnu (32-bit)
>> >>>
>> >>> attached base packages:
>> >>> [1] stats graphics grDevices utils datasets methods base
>> >>>
>> >>> other attached packages:
>> >>> [1] glmmADMB_0.6.5 MASS_7.3-14 png_0.1-3
>> >>>
>> >>> loaded via a namespace (and not attached):
>> >>> [1] grid_2.15.0 lattice_0.19-33 nlme_3.1-102 tools_2.15.0
>> >>>
>> >>> ______________________________________________
>> >>> R-devel at r-project.org mailing list
>> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >>
>> >
>> > -----BEGIN PGP SIGNATURE-----
>> > Version: GnuPG v1.4.10 (GNU/Linux)
>> > Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/
>> >
>> > iQEcBAEBAgAGBQJOxDiKAAoJED2whTVMEyK9ThoIAIjyMpzZqsjUpJVbAb9K8IrL
>> > LbSFh8zb+cZb90ABkFwJaZ2FNTKCjPrUzOYzxxHuU9AY0bdPQGbIm2hvQfzcuMlc
>> > urS/ILIMzZEFSYkqkj0mWI9SADyJ+W0YeN/t3EuWy8nZqUkYQZ8M0GsuXjhtUL/i
>> > hVJU0uuIWCOCHpeI3SQKoxviTE6MQFRXXWhCAJx01h8ee/5UQ5GSGB7Er2Zilld3
>> > 0sLI6dmoF7gbeYqz33MaEpQ7geJoW3tfnVbQWUlF86+jGGv5trIqWYIp33OYIxMO
>> > u2YUq51vB+4uIRPFJ4Oyr+nJF0Z9NH4IJBipp/bF6wQ5u6JdXFqKTPeQ1V6m5qk=
>> > =YajM
>> > -----END PGP SIGNATURE-----
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From murdoch.duncan at gmail.com  Sun Nov 20 12:07:44 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 20 Nov 2011 06:07:44 -0500
Subject: [Rd] Windows binaries: Version and revision strings show
 "(2006-00-00 r00000)"
In-Reply-To: <CAFDcVCQn6XbJkbrGvWcpmDEAS8Ugn8fEmy1z7kiFqSxWOE_tYA@mail.gmail.com>
References: <CAFDcVCQn6XbJkbrGvWcpmDEAS8Ugn8fEmy1z7kiFqSxWOE_tYA@mail.gmail.com>
Message-ID: <4EC8DF80.9010007@gmail.com>

On 11-11-18 6:30 PM, Henrik Bengtsson wrote:
> FYI,
>
> for the last few revision the version string for both R v2.14.0
> patched and R devel are not correct for the Windows binaries.  This is
> what R --version and sessionInfo() report since a couple of days:
>
> R version 2.14.0 Patched (2006-00-00 r00000)
> R Under development (unstable) (2006-00-00 r00000)
>
> Also, "r00000" is listed as the revision on:
>
> http://cran.r-project.org/bin/windows/base/rdevel.html
> http://cran.r-project.org/bin/windows/base/rpatched.html
>

Thanks, I believe this is now fixed.  It may take a day or two for the 
new builds to work their way through the system.

Duncan Murdoch


From gwgc5 at mail.missouri.edu  Sat Nov 19 21:33:27 2011
From: gwgc5 at mail.missouri.edu (Raymond)
Date: Sat, 19 Nov 2011 12:33:27 -0800 (PST)
Subject: [Rd] .Call in R
In-Reply-To: <4EC67C56.30504@fhcrc.org>
References: <1321549770463-4080721.post@n4.nabble.com>
	<CAMd4_Acq=iyx-AxaSSNn1Ya20xZAURAg4girh=FSUSnhd5S_CA@mail.gmail.com>
	<4EC67C56.30504@fhcrc.org>
Message-ID: <1321734807334-4087141.post@n4.nabble.com>

 I agree with Martin that this might not be suitable for a C solution.

--
View this message in context: http://r.789695.n4.nabble.com/Call-in-R-tp4080721p4087141.html
Sent from the R devel mailing list archive at Nabble.com.


From tal.galili at gmail.com  Sun Nov 20 17:53:38 2011
From: tal.galili at gmail.com (Tal Galili)
Date: Sun, 20 Nov 2011 18:53:38 +0200
Subject: [Rd] Adding a "description" meta-tag to the R homepage (bump)
Message-ID: <CANdJ3dW6sKrPj9HrDKnfnW-oDoK_YB4hPh4-590ySxymyTu_kw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111120/556d9c03/attachment.pl>

From Zwang at ccmckids.org  Mon Nov 21 03:09:27 2011
From: Zwang at ccmckids.org (Zhu Wang)
Date: Sun, 20 Nov 2011 21:09:27 -0500
Subject: [Rd] Fortran runtime error with package cts on CRAN/Mac
Message-ID: <4EC96C87020000DD00022CC4@gwmail3.harthosp.org>

Hello,
 
As the author of package cts, I hope somebody on this list can kindly help (perhaps off-list)
to resolve the build/check issue with package cts for Mac. The error occurred on Mac machines only: 
http://cran.r-project.org/web/checks/check_results_cts.html.
 
Here is the error message:
 
At line 10 of file machine.f
Fortran runtime error: Range error during floating point read 
 
The source file machine.f is to read machine dependent parameters stored in machine.txt, which was saved from R function .Machine. For convenience, the source file machine.f is listed below, along with machine.txt from a non Mac system (the last line NA was added for a test version of cts).
 
CCC READ MACHINE INFORMATION SAVED WITH R CODE
      SUBROUTINE MACHINE(EPS, BASE, T, EMIN, RMIN)
      DOUBLE PRECISION EPS, RMIN
      INTEGER BASE, T, EMIN
      OPEN(UNIT=3,FILE='machine.txt',STATUS='OLD')
      READ(3,*)EPS      
      READ(3,*)BASE
      READ(3,*)T
      READ(3,*)EMIN
      READ(3,*)RMIN
      CLOSE(UNIT=3)
      RETURN
      END
 
machine.txt:
 
1.11022302462516e-16
2
53
-1022
2.2250738585072e-308
NA
 
Another question is whether there is a way to submit a test to just one platform. I know this can be done for Windows, but I'm not sure for Mac. 
 
Thanks in advance.
 
Zhu Wang
 
Department of Research
Connecticut Children's Medical Center
Hartford, CT 06106
 
 

From ripley at stats.ox.ac.uk  Mon Nov 21 08:49:39 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 21 Nov 2011 07:49:39 +0000 (GMT)
Subject: [Rd] Fortran runtime error with package cts on CRAN/Mac
In-Reply-To: <4EC96C87020000DD00022CC4@gwmail3.harthosp.org>
References: <4EC96C87020000DD00022CC4@gwmail3.harthosp.org>
Message-ID: <alpine.LFD.2.02.1111210741490.14975@gannet.stats.ox.ac.uk>

Well, as Writing R Extensions says, packages should do no Fortran I/O 
at all.  So please pass the binary value to your code from R.

You cannot expect to write out extreme values without some 
representation error, and adjacent values cannot be read in again.

In any case, these values are essentially the same for all R 
platforms, being mandated by IEC60559.

On Sun, 20 Nov 2011, Zhu Wang wrote:

> Hello,
>
> As the author of package cts, I hope somebody on this list can kindly help (perhaps off-list)
> to resolve the build/check issue with package cts for Mac. The error occurred on Mac machines only:
> http://cran.r-project.org/web/checks/check_results_cts.html.
>
> Here is the error message:
>
> At line 10 of file machine.f
> Fortran runtime error: Range error during floating point read
>
> The source file machine.f is to read machine dependent parameters stored in machine.txt, which was saved from R function .Machine. For convenience, the source file machine.f is listed below, along with machine.txt from a non Mac system (the last line NA was added for a test version of cts).
>
> CCC READ MACHINE INFORMATION SAVED WITH R CODE
>      SUBROUTINE MACHINE(EPS, BASE, T, EMIN, RMIN)
>      DOUBLE PRECISION EPS, RMIN
>      INTEGER BASE, T, EMIN
>      OPEN(UNIT=3,FILE='machine.txt',STATUS='OLD')
>      READ(3,*)EPS
>      READ(3,*)BASE
>      READ(3,*)T
>      READ(3,*)EMIN
>      READ(3,*)RMIN
>      CLOSE(UNIT=3)
>      RETURN
>      END
>
> machine.txt:
>
> 1.11022302462516e-16
> 2
> 53
> -1022
> 2.2250738585072e-308
> NA
>
> Another question is whether there is a way to submit a test to just 
> one platform. I know this can be done for Windows, but I'm not sure 
> for Mac.

What does 'submit a test mean'?  Any test you write can check the 
value of Sys.info()["sysname"]: it is "Darwin" on Mac OS X.
Or R.version$platform, which will be something like 
i386-apple-darwin9.8.0.

>
> Thanks in advance.
>
> Zhu Wang
>
> Department of Research
> Connecticut Children's Medical Center
> Hartford, CT 06106
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From romain at r-enthusiasts.com  Mon Nov 21 10:59:49 2011
From: romain at r-enthusiasts.com (=?ISO-8859-1?Q?Romain_Fran=E7ois?=)
Date: Mon, 21 Nov 2011 10:59:49 +0100
Subject: [Rd] extending the colClasses argument in read.table
Message-ID: <4ECA2115.9080803@r-enthusiasts.com>

Hello,

We've released the int64 package to CRAN a few days ago. The package 
provides S4 classes "int64" and "uint64" that represent signed and 
unsigned 64 bit integer vectors.

One further development of the package is to facilitate reading 64 bit 
integer data from csv, etc ... files.

I have this function that wraps a call to read.csv to:
- read the "int64" and "uint64" columns as "character"
- converts them afterwards to the appropriate type


read.csv.int64 <- function (file, ...){
     dots <- list( file, ... )
     if( "colClasses" %in% names(dots) ){
         colClasses <- dots[["colClasses"]]
         idx.int64 <- colClasses == "int64"
         idx.uint64 <- colClasses == "uint64"

         colClasses[ idx.int64 | idx.uint64 ] <- "character"
         dots[["colClasses" ]] <- colClasses

         df <- do.call( "read.csv", dots )
         if( any( idx.int64 ) ){
             df[ idx.int64 ] <- lapply( df[ idx.int64 ], as.int64 )
         }
         if( any( idx.uint64 ) ){
             df[ idx.uint64 ] <- lapply( df[ idx.uint64 ], as.uint64 )
         }
         df


     } else {
         read.csv( file, ... )
     }
}

I was wondering if it would make sense to extend the colClasses argument 
so that other package can provide drivers, so that we could let the 
users just use read.csv, read.table, etc ...

Before I start digging into the internals of read.table, I wanted to 
have opinions about whether this would be a good idea, etc ...

Best Regards,

Romain

-- 
Romain Francois
Professional R Enthusiast
http://romainfrancois.blog.free.fr


From spinuvit at gmail.com  Mon Nov 21 12:04:54 2011
From: spinuvit at gmail.com (Vitalie Spinu)
Date: Mon, 21 Nov 2011 12:04:54 +0100
Subject: [Rd] Efficient development of NAMESPACEd packages.
Message-ID: <CAAQMm-9wuJyUbZX9JCWgmHpBgEgS-qyot49yGW4bHWGa4cTcmg@mail.gmail.com>

Dear R-devel,

How are the package authors supposed to develop their own NAMESPACEd
packages efficiently? And what are the directions R is taking in order to
facilitate the development cycle?

This questions are in the context of the recent thread on ESS-help
(http://thread.gmane.org/gmane.emacs.ess.general/5528/focus=5575) which
triggered the development of new ess-developer mode. In lay words, when
ess-developer mode is on, the evaluation of the code chunks is
"redirected" into the namespace:pkg and package:pkg, i.e. functions,
classes and methods are assigned in package namespace and package
environment, in the spirit of insertSource and assignInNamespace.

How does the above approach fit with the direction R is taking, in the
light of recent restrictions on "assignInNamespace" and the fact that R
does not have an unlockEnvironmnet function to unlock the package
namespace? Particularly are there any plans to restrict the use of
"unlockBinding" and "assign" functions?

Thanks,
Vitalie.

PS:
>From the NEWS file:

? assignInNamespace() has further restrictions on use apart from at
top-level, as its help page has warned.  Expect it to be disabled from
programmatic use in the future.


From nashjc at uottawa.ca  Mon Nov 21 14:17:54 2011
From: nashjc at uottawa.ca (John C Nash)
Date: Mon, 21 Nov 2011 08:17:54 -0500
Subject: [Rd] testing on platforms, was Fortran error
In-Reply-To: <mailman.21.1321873206.17473.r-devel@r-project.org>
References: <mailman.21.1321873206.17473.r-devel@r-project.org>
Message-ID: <4ECA4F82.4090701@uottawa.ca>

I think the poster is interested in being able to try the build/check on a Mac in the
fashion that Winbuilder does. That is, rather than have CRAN do all the platform checks,
is there a way to submit a package to be tested for just one platform?

It may be useful to have such a facility so package builders can test before submission,
and from my own experience I believe would help to render packages more platform neutral.

I suspect that all the pieces are in place to do this, but perhaps a nice front end is
needed. Is that something for a Google Summer of Code task?

Best,

JN

On 11/21/2011 06:00 AM, r-devel-request at r-project.org wrote:
> What does 'submit a test mean'?  Any test you write can check the 
> value of Sys.info()["sysname"]: it is "Darwin" on Mac OS X.
> Or R.version$platform, which will be something like 
> i386-apple-darwin9.8.0.


From jorismeys at gmail.com  Mon Nov 21 14:25:11 2011
From: jorismeys at gmail.com (Joris Meys)
Date: Mon, 21 Nov 2011 14:25:11 +0100
Subject: [Rd] Patched R build available today is missing some info (data and
 release number)
Message-ID: <CAO1zAVZ7KJ_oerY7=DuTNXKyQBkCLpA7aMUkSbmVghmw=89AiQ@mail.gmail.com>

Hi all,

The R version 2.14.0 Pacthed build from today, including patches up to
2011-11-20, is showing the following when started up :

R version 2.14.0 Patched (2006-00-00 r00000)
...
Isn't something missing here, like a correct date and a release
number? On the page
http://cran.r-project.org/bin/windows/base/rpatched.html the release
number is r00000 as well.

Cheers
Joris

-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From ligges at statistik.tu-dortmund.de  Mon Nov 21 14:39:10 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 21 Nov 2011 14:39:10 +0100
Subject: [Rd] Patched R build available today is missing some info (data
 and release number)
In-Reply-To: <CAO1zAVZ7KJ_oerY7=DuTNXKyQBkCLpA7aMUkSbmVghmw=89AiQ@mail.gmail.com>
References: <CAO1zAVZ7KJ_oerY7=DuTNXKyQBkCLpA7aMUkSbmVghmw=89AiQ@mail.gmail.com>
Message-ID: <4ECA547E.1090001@statistik.tu-dortmund.de>



On 21.11.2011 14:25, Joris Meys wrote:
> Hi all,
>
> The R version 2.14.0 Pacthed build from today, including patches up to
> 2011-11-20, is showing the following when started up :
>
> R version 2.14.0 Patched (2006-00-00 r00000)
> ...
> Isn't something missing here, like a correct date and a release
> number? On the page
> http://cran.r-project.org/bin/windows/base/rpatched.html the release
> number is r00000 as well.
>
> Cheers
> Joris
>


Duncan Murdoch wrote yesterday he fixed this. So please just wait until 
the new binary is propagated to the master / mirrors.

Uwe Ligges


From murdoch.duncan at gmail.com  Mon Nov 21 15:22:59 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 21 Nov 2011 09:22:59 -0500
Subject: [Rd] Patched R build available today is missing some info (data
 and release number)
In-Reply-To: <4ECA547E.1090001@statistik.tu-dortmund.de>
References: <CAO1zAVZ7KJ_oerY7=DuTNXKyQBkCLpA7aMUkSbmVghmw=89AiQ@mail.gmail.com>
	<4ECA547E.1090001@statistik.tu-dortmund.de>
Message-ID: <4ECA5EC3.7020504@gmail.com>

On 21/11/2011 8:39 AM, Uwe Ligges wrote:
>
> On 21.11.2011 14:25, Joris Meys wrote:
> >  Hi all,
> >
> >  The R version 2.14.0 Pacthed build from today, including patches up to
> >  2011-11-20, is showing the following when started up :
> >
> >  R version 2.14.0 Patched (2006-00-00 r00000)
> >  ...
> >  Isn't something missing here, like a correct date and a release
> >  number? On the page
> >  http://cran.r-project.org/bin/windows/base/rpatched.html the release
> >  number is r00000 as well.
> >
> >  Cheers
> >  Joris
> >
>
>
> Duncan Murdoch wrote yesterday he fixed this. So please just wait until
> the new binary is propagated to the master / mirrors.

Yesterday's fix wasn't sufficient, but I think today's is.

Duncan Murdoch


From Martyn.Byng at nag.co.uk  Mon Nov 21 15:41:36 2011
From: Martyn.Byng at nag.co.uk (Martyn Byng)
Date: Mon, 21 Nov 2011 14:41:36 -0000
Subject: [Rd] a^b when a is large and b < 1 (64bit R on windows 7)
Message-ID: <49E76DF37649DC48A4CE882BC8CE51C901F44592@nagmail2.nag.co.uk>

Hi,

I'm getting some strange behaviour when trying to use the power operator
(a^b) when a is large and b is less than one:

big <- .Machine$double.xmax
big
big^0.5
sqrt(big)

> big <- 1.797693134862315708384e+308
> big^0.5
[1] Inf
> sqrt(big)
[1] 1.340781e+154


I'm guessing that this behaviour is not expected, or am I missing
something about ^?

Cheers

Martyn



> sessionInfo()
R version 2.14.0 (2011-10-31)
Platform: x86_64-pc-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United Kingdom.1252
[2] LC_CTYPE=English_United Kingdom.1252
[3] LC_MONETARY=English_United Kingdom.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United Kingdom.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

________________________________________________________________________
The Numerical Algorithms Group Ltd is a company registered in England
and Wales with company number 1249803. The registered office is:
Wilkinson House, Jordan Hill Road, Oxford OX2 8DR, United Kingdom.

This e-mail has been scanned for all viruses by Star. Th...{{dropped:4}}


From jorismeys at gmail.com  Mon Nov 21 15:54:54 2011
From: jorismeys at gmail.com (Joris Meys)
Date: Mon, 21 Nov 2011 15:54:54 +0100
Subject: [Rd] a^b when a is large and b < 1 (64bit R on windows 7)
In-Reply-To: <49E76DF37649DC48A4CE882BC8CE51C901F44592@nagmail2.nag.co.uk>
References: <49E76DF37649DC48A4CE882BC8CE51C901F44592@nagmail2.nag.co.uk>
Message-ID: <CAO1zAVax2LL=wBmXHZFDGXrD_EnUU=06BmGJ-w_befQ=NYMKxQ@mail.gmail.com>

I can reproduce on the latest patched build, but this is specific for
the 64bit version of R. On a 32bit it works as expected:

> big <- 1.797693134862315708385e+308
> sqrt(big)
[1] 1.340781e+154
> big^0.5
[1] 1.340781e+154

The 64bit part might have something to do with it, and now move out of
the way for people that actually know what they're talking about...

Cheers
Joris


On Mon, Nov 21, 2011 at 3:41 PM, Martyn Byng <Martyn.Byng at nag.co.uk> wrote:
> Hi,
>
> I'm getting some strange behaviour when trying to use the power operator
> (a^b) when a is large and b is less than one:
>
> big <- .Machine$double.xmax
> big
> big^0.5
> sqrt(big)
>
>> big <- 1.797693134862315708384e+308
>> big^0.5
> [1] Inf
>> sqrt(big)
> [1] 1.340781e+154
>
>
> I'm guessing that this behaviour is not expected, or am I missing
> something about ^?
>
> Cheers
>
> Martyn
>
>
>
>> sessionInfo()
> R version 2.14.0 (2011-10-31)
> Platform: x86_64-pc-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=English_United Kingdom.1252
> [2] LC_CTYPE=English_United Kingdom.1252
> [3] LC_MONETARY=English_United Kingdom.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United Kingdom.1252
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
> ________________________________________________________________________
> The Numerical Algorithms Group Ltd is a company registered in England
> and Wales with company number 1249803. The registered office is:
> Wilkinson House, Jordan Hill Road, Oxford OX2 8DR, United Kingdom.
>
> This e-mail has been scanned for all viruses by Star. Th...{{dropped:4}}
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From brian at braverock.com  Mon Nov 21 15:58:01 2011
From: brian at braverock.com (Brian G. Peterson)
Date: Mon, 21 Nov 2011 08:58:01 -0600
Subject: [Rd] a^b when a is large and b < 1 (64bit R on windows 7)
In-Reply-To: <49E76DF37649DC48A4CE882BC8CE51C901F44592@nagmail2.nag.co.uk>
References: <49E76DF37649DC48A4CE882BC8CE51C901F44592@nagmail2.nag.co.uk>
Message-ID: <1321887481.29526.14.camel@brian-rcg>

On Mon, 2011-11-21 at 14:41 +0000, Martyn Byng wrote:
> I'm getting some strange behaviour when trying to use the power
> operator
> (a^b) when a is large and b is less than one:
> 
> big <- .Machine$double.xmax
> big
> big^0.5
> sqrt(big)
> 
> > big <- 1.797693134862315708384e+308
> > big^0.5
> [1] Inf
> > sqrt(big)
> [1] 1.340781e+154
> 
> 
> I'm guessing that this behaviour is not expected, or am I missing
> something about ^? 

On a recent Ubuntu 64bit install with R2.14.0 from the repositories, I
get:

> big <- .Machine$double.xmax
> big
[1] 1.797693e+308
> big^0.5
[1] 1.340781e+154
> sqrt(big)
[1] 1.340781e+154

so it does seem to be specific either to your environment.

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From jorismeys at gmail.com  Mon Nov 21 16:03:52 2011
From: jorismeys at gmail.com (Joris Meys)
Date: Mon, 21 Nov 2011 16:03:52 +0100
Subject: [Rd] a^b when a is large and b < 1 (64bit R on windows 7)
In-Reply-To: <1321887481.29526.14.camel@brian-rcg>
References: <49E76DF37649DC48A4CE882BC8CE51C901F44592@nagmail2.nag.co.uk>
	<1321887481.29526.14.camel@brian-rcg>
Message-ID: <CAO1zAVa7sZhY2KgDQbVT18nW12zfgeCB25c=JXJmRkqtOdHANw@mail.gmail.com>

Should have specified I only checked on Windows. So: On Windows 7
64bit, the R-32bit works fine, the R-64bit gives the behaviour Martyn
reported.

Cheers
Joris

On Mon, Nov 21, 2011 at 3:58 PM, Brian G. Peterson <brian at braverock.com> wrote:
> On Mon, 2011-11-21 at 14:41 +0000, Martyn Byng wrote:
>> I'm getting some strange behaviour when trying to use the power
>> operator
>> (a^b) when a is large and b is less than one:
>>
>> big <- .Machine$double.xmax
>> big
>> big^0.5
>> sqrt(big)
>>
>> > big <- 1.797693134862315708384e+308
>> > big^0.5
>> [1] Inf
>> > sqrt(big)
>> [1] 1.340781e+154
>>
>>
>> I'm guessing that this behaviour is not expected, or am I missing
>> something about ^?
>
> On a recent Ubuntu 64bit install with R2.14.0 from the repositories, I
> get:
>
>> big <- .Machine$double.xmax
>> big
> [1] 1.797693e+308
>> big^0.5
> [1] 1.340781e+154
>> sqrt(big)
> [1] 1.340781e+154
>
> so it does seem to be specific either to your environment.
>
> --
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From ggrothendieck at gmail.com  Mon Nov 21 16:31:10 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 21 Nov 2011 10:31:10 -0500
Subject: [Rd] extending the colClasses argument in read.table
In-Reply-To: <4ECA2115.9080803@r-enthusiasts.com>
References: <4ECA2115.9080803@r-enthusiasts.com>
Message-ID: <CAP01uRkQA3zPqCPK03q28j4xbeWxNsbRdKRP1F7bA9j=Vhjdmg@mail.gmail.com>

2011/11/21 Romain Fran?ois <romain at r-enthusiasts.com>:
> Hello,
>
> We've released the int64 package to CRAN a few days ago. The package
> provides S4 classes "int64" and "uint64" that represent signed and unsigned
> 64 bit integer vectors.
>
> One further development of the package is to facilitate reading 64 bit
> integer data from csv, etc ... files.
>
> I have this function that wraps a call to read.csv to:
> - read the "int64" and "uint64" columns as "character"
> - converts them afterwards to the appropriate type
>

Try this:

> library(int64)
> Lines <- "A\n12\n"
>
> setAs("character", "int64", function(from) as.int64(from))
>
> DF <- read.csv(textConnection(Lines), colClasses = "int64")
>
> str(DF)
'data.frame':   1 obs. of  1 variable:
 $ A:Formal class 'int64' [package "int64"] with 2 slots
  .. ..@ .Data:List of 1
  .. .. ..$ : int  0 12
  .. ..@ NAMES: NULL

To convince ourselves that its translating from character to int64:

> setAs("character", "int64", function(from) {print(class(from)); as.int64(from)})
> DF <- read.csv(textConnection(Lines), colClasses = "int64")
[1] "character"


-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From simon.urbanek at r-project.org  Mon Nov 21 16:35:25 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 21 Nov 2011 10:35:25 -0500
Subject: [Rd] testing on platforms, was Fortran error
In-Reply-To: <4ECA4F82.4090701@uottawa.ca>
References: <mailman.21.1321873206.17473.r-devel@r-project.org>
	<4ECA4F82.4090701@uottawa.ca>
Message-ID: <085E3F1E-6FAF-47C3-ABB0-DBFFFD5B6201@r-project.org>

John,

On Nov 21, 2011, at 8:17 AM, John C Nash wrote:

> I think the poster is interested in being able to try the build/check on a Mac in the
> fashion that Winbuilder does. That is, rather than have CRAN do all the platform checks,
> is there a way to submit a package to be tested for just one platform?
> 
> It may be useful to have such a facility so package builders can test before submission,
> and from my own experience I believe would help to render packages more platform neutral.
> 

It has been discussed and there was a tentative plan (which involves getting a dedicated machine for this and R-forge builds), but nothing happened so far.


> I suspect that all the pieces are in place to do this, but perhaps a nice front end is
> needed. Is that something for a Google Summer of Code task?
> 

Software infrastructure is not a problem. For example I have full multi-platform submission system in place for my RForge.net (since I'm building Linux, OS X and Windows).

Personally, my view is that developers should be using the existing package-based build systems (like R-forge or RForge.net). I am paranoid and thus reluctant to perform builds on my own systems for packages that have no source provenance (i.e. if I don't have an accountable registered user) - for security reasons.

Cheers,
Simon



> Best,
> 
> JN
> 
> On 11/21/2011 06:00 AM, r-devel-request at r-project.org wrote:
>> What does 'submit a test mean'?  Any test you write can check the 
>> value of Sys.info()["sysname"]: it is "Darwin" on Mac OS X.
>> Or R.version$platform, which will be something like 
>> i386-apple-darwin9.8.0.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From Zwang at ccmckids.org  Mon Nov 21 16:54:41 2011
From: Zwang at ccmckids.org (Zhu Wang)
Date: Mon, 21 Nov 2011 10:54:41 -0500
Subject: [Rd] Fortran runtime error with package cts on CRAN/Mac
In-Reply-To: <alpine.LFD.2.02.1111210741490.14975@gannet.stats.ox.ac.uk>
References: <4EC96C87020000DD00022CC4@gwmail3.harthosp.org>
	<alpine.LFD.2.02.1111210741490.14975@gannet.stats.ox.ac.uk>
Message-ID: <4ECA2DF1020000DD00022D05@gwmail3.harthosp.org>

Thanks Prof Ripley.  Here is what I meant for "submit a test". I can build and check R source packages for Windows at http://win-builder.r-project.org/, but I am not aware of a link for Mac. I thought this can be useful for those without access to Mac machines. 
 
Regards,
 
Zhu Wang

>>> Prof Brian Ripley <ripley at stats.ox.ac.uk> 11/21/2011 2:49 AM >>>
Well, as Writing R Extensions says, packages should do no Fortran I/O 
at all.  So please pass the binary value to your code from R.

You cannot expect to write out extreme values without some 
representation error, and adjacent values cannot be read in again.

In any case, these values are essentially the same for all R 
platforms, being mandated by IEC60559.

On Sun, 20 Nov 2011, Zhu Wang wrote:

> Hello,
>
> As the author of package cts, I hope somebody on this list can kindly help (perhaps off-list)
> to resolve the build/check issue with package cts for Mac. The error occurred on Mac machines only:
> http://cran.r-project.org/web/checks/check_results_cts.html.
>
> Here is the error message:
>
> At line 10 of file machine.f
> Fortran runtime error: Range error during floating point read
>
> The source file machine.f is to read machine dependent parameters stored in machine.txt, which was saved from R function .Machine. For convenience, the source file machine.f is listed below, along with machine.txt from a non Mac system (the last line NA was added for a test version of cts).
>
> CCC READ MACHINE INFORMATION SAVED WITH R CODE
>      SUBROUTINE MACHINE(EPS, BASE, T, EMIN, RMIN)
>      DOUBLE PRECISION EPS, RMIN
>      INTEGER BASE, T, EMIN
>      OPEN(UNIT=3,FILE='machine.txt',STATUS='OLD')
>      READ(3,*)EPS
>      READ(3,*)BASE
>      READ(3,*)T
>      READ(3,*)EMIN
>      READ(3,*)RMIN
>      CLOSE(UNIT=3)
>      RETURN
>      END
>
> machine.txt:
>
> 1.11022302462516e-16
> 2
> 53
> -1022
> 2.2250738585072e-308
> NA
>
> Another question is whether there is a way to submit a test to just 
> one platform. I know this can be done for Windows, but I'm not sure 
> for Mac.

What does 'submit a test mean'?  Any test you write can check the 
value of Sys.info()["sysname"]: it is "Darwin" on Mac OS X.
Or R.version$platform, which will be something like 
i386-apple-darwin9.8.0.

>
> Thanks in advance.
>
> Zhu Wang
>
> Department of Research
> Connecticut Children's Medical Center
> Hartford, CT 06106
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From romain at r-enthusiasts.com  Mon Nov 21 17:42:03 2011
From: romain at r-enthusiasts.com (romain at r-enthusiasts.com)
Date: Mon, 21 Nov 2011 17:42:03 +0100
Subject: [Rd] extending the colClasses argument in read.table
In-Reply-To: <CAP01uRkQA3zPqCPK03q28j4xbeWxNsbRdKRP1F7bA9j=Vhjdmg@mail.gmail.com>
References: <4ECA2115.9080803@r-enthusiasts.com>
	<CAP01uRkQA3zPqCPK03q28j4xbeWxNsbRdKRP1F7bA9j=Vhjdmg@mail.gmail.com>
Message-ID: <1A78F656-B93B-4466-A52E-FFBA9EE76C09@r-enthusiasts.com>

Thanks gabor, 

I will implement this and publish an updated package later. 

Cheers, 

Romain



Le 21 nov. 2011 ? 16:31, Gabor Grothendieck <ggrothendieck at gmail.com> a ?crit :

> 2011/11/21 Romain Fran?ois <romain at r-enthusiasts.com>:
>> Hello,
>> 
>> We've released the int64 package to CRAN a few days ago. The package
>> provides S4 classes "int64" and "uint64" that represent signed and unsigned
>> 64 bit integer vectors.
>> 
>> One further development of the package is to facilitate reading 64 bit
>> integer data from csv, etc ... files.
>> 
>> I have this function that wraps a call to read.csv to:
>> - read the "int64" and "uint64" columns as "character"
>> - converts them afterwards to the appropriate type
>> 
> 
> Try this:
> 
>> library(int64)
>> Lines <- "A\n12\n"
>> 
>> setAs("character", "int64", function(from) as.int64(from))
>> 
>> DF <- read.csv(textConnection(Lines), colClasses = "int64")
>> 
>> str(DF)
> 'data.frame':   1 obs. of  1 variable:
> $ A:Formal class 'int64' [package "int64"] with 2 slots
>  .. ..@ .Data:List of 1
>  .. .. ..$ : int  0 12
>  .. ..@ NAMES: NULL
> 
> To convince ourselves that its translating from character to int64:
> 
>> setAs("character", "int64", function(from) {print(class(from)); as.int64(from)})
>> DF <- read.csv(textConnection(Lines), colClasses = "int64")
> [1] "character"
> 
> 
> -- 
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com


From rocket at google.com  Mon Nov 21 17:41:43 2011
From: rocket at google.com (Tim Hesterberg)
Date: Mon, 21 Nov 2011 08:41:43 -0800
Subject: [Rd] Suggested improvement for src/library/base/man/qraux.Rd
In-Reply-To: <4198E7E5-07AE-4B75-B584-A10E3DD68795@r-project.org>
References: <20111119234713.C670F120176@rocket3.sea.corp.google.com>
	<4198E7E5-07AE-4B75-B584-A10E3DD68795@r-project.org>
Message-ID: <CAFDn683gZ6daHh0PE_BYvq+ZJ-zYS=ri4goLjwrLj+YJ4CePHw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111121/5cf1e048/attachment.pl>

From xie at yihui.name  Mon Nov 21 20:14:54 2011
From: xie at yihui.name (Yihui Xie)
Date: Mon, 21 Nov 2011 13:14:54 -0600
Subject: [Rd] links to package vignettes on CRAN after R 2.14.0
Message-ID: <CANROs4eB8vipN0WSqQq=gRut=60uQ1Qf+ncPiXeY1gdZ8J-tzg@mail.gmail.com>

Hi,

I noticed the links to my package vignettes on CRAN were gone after I
started using ./vignettes instead of ./inst/doc, as suggested by the
R-exts manual in R 2.14.0. For example,

http://cran.r-project.org/web/packages/formatR/index.html
http://cran.r-project.org/web/packages/Rd2roxygen/index.html

I have put %\VignetteIndexEntry in the Rnw file, but I do not
understand why CRAN does not create the link in the package webpage
any more. In the past, my vignettes were under ./inst/doc, and the
links appeared as expected.

Thanks!

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 515-294-2465 Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


From blewis at illposed.net  Tue Nov 22 00:47:25 2011
From: blewis at illposed.net (Bryan W. Lewis)
Date: Mon, 21 Nov 2011 18:47:25 -0500
Subject: [Rd] a^b when a is large and b < 1 (64bit R on windows 7)
In-Reply-To: <CAO1zAVa7sZhY2KgDQbVT18nW12zfgeCB25c=JXJmRkqtOdHANw@mail.gmail.com>
References: <49E76DF37649DC48A4CE882BC8CE51C901F44592@nagmail2.nag.co.uk>
	<1321887481.29526.14.camel@brian-rcg>
	<CAO1zAVa7sZhY2KgDQbVT18nW12zfgeCB25c=JXJmRkqtOdHANw@mail.gmail.com>
Message-ID: <CAD3tZGhpwczp80bsV7JrNQke4VczdyR60mwPBDB6_fdJrCwv_Q@mail.gmail.com>

Although it does not solve the issue, the INF result is due to the
MinGW gcc math library on 64-bit Windows that R links to. One can
easily see this by compiling just machar.c and checking pow and sqrt
on xmax.

Note that on any platform the results are likely to be quite different
between pow and sqrt for edge case numerical examples.

For example, on a 32-bit Ubuntu box with R-2.14.0, I get:
x = .Machine$double.xmax
y = sqrt(x)
z = x^0.5
y-z
[1] 1.488566e+138


There is also a long discussion about this here:

http://sourceforge.net/mailarchive/forum.php?forum_name=mingw-users&max_rows=25&style=nested&viewmonth=201104


--Bryan


On Mon, Nov 21, 2011 at 10:03 AM, Joris Meys <jorismeys at gmail.com> wrote:
> Should have specified I only checked on Windows. So: On Windows 7
> 64bit, the R-32bit works fine, the R-64bit gives the behaviour Martyn
> reported.
>
> Cheers
> Joris
>
> On Mon, Nov 21, 2011 at 3:58 PM, Brian G. Peterson <brian at braverock.com> wrote:
>> On Mon, 2011-11-21 at 14:41 +0000, Martyn Byng wrote:
>>> I'm getting some strange behaviour when trying to use the power
>>> operator
>>> (a^b) when a is large and b is less than one:
>>>
>>> big <- .Machine$double.xmax
>>> big
>>> big^0.5
>>> sqrt(big)
>>>
>>> > big <- 1.797693134862315708384e+308
>>> > big^0.5
>>> [1] Inf
>>> > sqrt(big)
>>> [1] 1.340781e+154
>>>
>>>
>>> I'm guessing that this behaviour is not expected, or am I missing
>>> something about ^?
>>
>> On a recent Ubuntu 64bit install with R2.14.0 from the repositories, I
>> get:
>>
>>> big <- .Machine$double.xmax
>>> big
>> [1] 1.797693e+308
>>> big^0.5
>> [1] 1.340781e+154
>>> sqrt(big)
>> [1] 1.340781e+154
>>
>> so it does seem to be specific either to your environment.
>>
>> --
>> Brian G. Peterson
>> http://braverock.com/brian/
>> Ph: 773-459-4973
>> IM: bgpbraverock
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>
> --
> Joris Meys
> Statistical consultant
>
> Ghent University
> Faculty of Bioscience Engineering
> Department of Mathematical Modelling, Statistics and Bio-Informatics
>
> tel : +32 9 264 59 87
> Joris.Meys at Ugent.be
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From Kurt.Hornik at wu.ac.at  Tue Nov 22 08:29:12 2011
From: Kurt.Hornik at wu.ac.at (Kurt Hornik)
Date: Tue, 22 Nov 2011 08:29:12 +0100
Subject: [Rd] links to package vignettes on CRAN after R 2.14.0
In-Reply-To: <CANROs4eB8vipN0WSqQq=gRut=60uQ1Qf+ncPiXeY1gdZ8J-tzg@mail.gmail.com>
References: <CANROs4eB8vipN0WSqQq=gRut=60uQ1Qf+ncPiXeY1gdZ8J-tzg@mail.gmail.com>
Message-ID: <20171.20296.823904.398055@fangorn.hornik.net>

>>>>> Yihui Xie writes:

> Hi,
> I noticed the links to my package vignettes on CRAN were gone after I
> started using ./vignettes instead of ./inst/doc, as suggested by the
> R-exts manual in R 2.14.0. For example,

> http://cran.r-project.org/web/packages/formatR/index.html
> http://cran.r-project.org/web/packages/Rd2roxygen/index.html

> I have put %\VignetteIndexEntry in the Rnw file, but I do not
> understand why CRAN does not create the link in the package webpage
> any more. In the past, my vignettes were under ./inst/doc, and the
> links appeared as expected.

Should be fixed now.

-k

> Thanks!

> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Phone: 515-294-2465 Web: http://yihui.name
> Department of Statistics, Iowa State University
> 2215 Snedecor Hall, Ames, IA

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Martyn.Byng at nag.co.uk  Tue Nov 22 11:46:24 2011
From: Martyn.Byng at nag.co.uk (Martyn Byng)
Date: Tue, 22 Nov 2011 10:46:24 -0000
Subject: [Rd] a^b when a is large and b < 1 (64bit R on windows 7)
References: <49E76DF37649DC48A4CE882BC8CE51C901F44592@nagmail2.nag.co.uk><1321887481.29526.14.camel@brian-rcg><CAO1zAVa7sZhY2KgDQbVT18nW12zfgeCB25c=JXJmRkqtOdHANw@mail.gmail.com>
	<CAD3tZGhpwczp80bsV7JrNQke4VczdyR60mwPBDB6_fdJrCwv_Q@mail.gmail.com>
Message-ID: <49E76DF37649DC48A4CE882BC8CE51C901F44647@nagmail2.nag.co.uk>

Hi,

The problem here appears to be due to 

                          29: #define MAXNUM 1.7976931348623158E308

(from
http://cygwin.com/cgi-bin/cvsweb.cgi/src/winsup/mingw/mingwex/math/cephe
s_mconf.h?annotate=1.5&cvsroot=src)

and

                         468: if( x >= MAXNUM )
                         469:        {
                         470: #if INFINITIES
                         471:        if( y > 0.0 )
                         472:                return( INFINITY );
(from
http://cygwin.com/cgi-bin/cvsweb.cgi/src/winsup/mingw/mingwex/math/pow.c
?annotate=1.1.10.1&cvsroot=src)


And so on 64bit Windows R build
.Machine$double.xmax = MAXMUM from above.

This is kind of confirmed as 

(.Machine$double.xmax*(1 - .Machine$double.eps))^0.5

works as expected 

Martyn


-----Original Message-----
From: r-devel-bounces at r-project.org
[mailto:r-devel-bounces at r-project.org] On Behalf Of Bryan W. Lewis
Sent: 21 November 2011 23:47
To: Joris Meys
Cc: r-devel at r-project.org
Subject: Re: [Rd] a^b when a is large and b < 1 (64bit R on windows 7)

Although it does not solve the issue, the INF result is due to the
MinGW gcc math library on 64-bit Windows that R links to. One can
easily see this by compiling just machar.c and checking pow and sqrt
on xmax.

Note that on any platform the results are likely to be quite different
between pow and sqrt for edge case numerical examples.

For example, on a 32-bit Ubuntu box with R-2.14.0, I get:
x = .Machine$double.xmax
y = sqrt(x)
z = x^0.5
y-z
[1] 1.488566e+138


There is also a long discussion about this here:

http://sourceforge.net/mailarchive/forum.php?forum_name=mingw-users&max_
rows=25&style=nested&viewmonth=201104


--Bryan


On Mon, Nov 21, 2011 at 10:03 AM, Joris Meys <jorismeys at gmail.com>
wrote:
> Should have specified I only checked on Windows. So: On Windows 7
> 64bit, the R-32bit works fine, the R-64bit gives the behaviour Martyn
> reported.
>
> Cheers
> Joris
>
> On Mon, Nov 21, 2011 at 3:58 PM, Brian G. Peterson
<brian at braverock.com> wrote:
>> On Mon, 2011-11-21 at 14:41 +0000, Martyn Byng wrote:
>>> I'm getting some strange behaviour when trying to use the power
>>> operator
>>> (a^b) when a is large and b is less than one:
>>>
>>> big <- .Machine$double.xmax
>>> big
>>> big^0.5
>>> sqrt(big)
>>>
>>> > big <- 1.797693134862315708384e+308
>>> > big^0.5
>>> [1] Inf
>>> > sqrt(big)
>>> [1] 1.340781e+154
>>>
>>>
>>> I'm guessing that this behaviour is not expected, or am I missing
>>> something about ^?
>>
>> On a recent Ubuntu 64bit install with R2.14.0 from the repositories,
I
>> get:
>>
>>> big <- .Machine$double.xmax
>>> big
>> [1] 1.797693e+308
>>> big^0.5
>> [1] 1.340781e+154
>>> sqrt(big)
>> [1] 1.340781e+154
>>
>> so it does seem to be specific either to your environment.
>>
>> --
>> Brian G. Peterson
>> http://braverock.com/brian/
>> Ph: 773-459-4973
>> IM: bgpbraverock
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>
> --
> Joris Meys
> Statistical consultant
>
> Ghent University
> Faculty of Bioscience Engineering
> Department of Mathematical Modelling, Statistics and Bio-Informatics
>
> tel : +32 9 264 59 87
> Joris.Meys at Ugent.be
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

________________________________________________________________________
This e-mail has been scanned for all viruses by Star.\ _...{{dropped:12}}


From therneau at mayo.edu  Tue Nov 22 15:32:45 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Tue, 22 Nov 2011 08:32:45 -0600
Subject: [Rd] R-devel Digest, Vol 105, Issue 22
In-Reply-To: <mailman.19.1321959606.14620.r-devel@r-project.org>
References: <mailman.19.1321959606.14620.r-devel@r-project.org>
Message-ID: <1321972365.28427.11.camel@nemo>


On Tue, 2011-11-22 at 12:00 +0100, r-devel-request at r-project.org wrote:
> How are the package authors supposed to develop their own NAMESPACEd
> packages efficiently? And what are the directions R is taking in order
> to
> facilitate the development cycle?
> 

This is my strategy.
I have a separate directory "test.local" in my tree, not exported to
Rforge.  It has a Makefile which loads all the sources from ../R, copies
the C files from ../src and makes a local loadable S.so.  I then do all
my development there, without a name space.  I can overwrite functions,
trace, add browser() calls --- all the things you want to do --- with
standard semantics. I obviously don't "load" my package.
  
I think this is the simplest route.  Namespaces are a great idea, but
during testing I don't want all those protections.  It took me a half
hour to set up the Makefile; I've recouped that effort many times over.

Terry Therneau


From s2partheni at gmail.com  Tue Nov 22 16:08:20 2011
From: s2partheni at gmail.com (savina partheni)
Date: Tue, 22 Nov 2011 17:08:20 +0200
Subject: [Rd] Generate Simulation
Message-ID: <CAK54zZeuuszy7dkF_hp1WoNFFj1EtYhQgg260nptVaxrGXqnUg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111122/cb22e7b4/attachment.pl>

From jorismeys at gmail.com  Tue Nov 22 16:31:58 2011
From: jorismeys at gmail.com (Joris Meys)
Date: Tue, 22 Nov 2011 16:31:58 +0100
Subject: [Rd] Generate Simulation
In-Reply-To: <CAK54zZeuuszy7dkF_hp1WoNFFj1EtYhQgg260nptVaxrGXqnUg@mail.gmail.com>
References: <CAK54zZeuuszy7dkF_hp1WoNFFj1EtYhQgg260nptVaxrGXqnUg@mail.gmail.com>
Message-ID: <CAO1zAVbLPMxBeHD2QwMY21uurLU20fRG26bdD8dKZhUZaPML0w@mail.gmail.com>

Not to be rude, but I'd suggest you first read the posting guide for
the mailing lists again. The r-devel list is not meant to be used as a
help forum.

https://stat.ethz.ch/mailman/listinfo/r-devel

This said, look at ?replicate.

Cheers
Joris

On Tue, Nov 22, 2011 at 4:08 PM, savina partheni <s2partheni at gmail.com> wrote:
> Hallo everybody,
>
> I'm new in r and I"ll appreciate some help!
>
> I have a matrix of nrow=30 and ncoll=54,and I would like to generate 50
> simulations with tha same size of the matrix!!!That is to say that I want
> to generate 50 matrices -for my 50 simulations - with the same dimensions!
> I took my 1st matrix according to the formula that I want to implement:
> D<-mean_m + U_i*mat_DELTA
> mean_m:vector
> U_I:vector
> mat_Delta:matrix(54,30)
>
> Here is the loop:
> #Define Simulations(IS)
> ?#Define Time Step(IT)
>
> vec_IS<-c(1:50)
> vec_IT<-c(1:30)
> mat_delta<-matrix(nrow=54, ncol=30)
> mat_DELTA<-matrix(nrow=54, ncol=30)
> mat_Yr_m<-matrix(nrow=54, ncol=30)
> D<-matrix(nrow=30, ncol=54)
> DELTA<-(matrix(nrow=30,ncol=54))*50
>
> for (i in 1:length(vec_IS)){
> ? ? ? ?for (j in 1:length(vec_IT)){
> ? ? ? ? ? ? ? ?Yr_m<-rnorm(54,m=0,sd=1)
> ? ? ? ? ? ? ? ?mat_Yr_m[,j]<-Yr_m
> ? ? ? ? ? ? ? ?delta_i<-lower_m%*%mat_Yr_m[,j]
> ? ? ? ? ? ? ? ?mat_delta[,j]<-as.vector(delta_i)
> ? ? ? ?}
> ? ? ? ?DELTA_1<-mat_delta[,1]
> ? ? ? ?DELTA_2<-mat_delta[,2]-a_1*mat_delta[,1]
> ? ? ? ? ? ? ? ?for (t in 3:length(vec_IT)){
> ? ? ? ? ? ? ? ? ? ? ? ?mat_DELTA[,t]<-mat_delta[,t] - a_1*mat_delta[,t-1]
> - a_2*mat_delta[,t-2]
> ? ? ? ? ? ? ? ?}
> ? ? ? ? ? ? ? ?mat_DELTA[,1]<-DELTA_1
> ? ? ? ? ? ? ? ?mat_DELTA[,2]<-DELTA_2
> ? ? ? ? ? ? ? ? ? ? ? ?for (k in 1:length(nmesh)){
> ? ? ? ? ? ? ? ? ? ? ? ?mean_m<-as.numeric(vec_mean_col)
> ? ? ? ? ? ? ? ? ? ? ? ?DELTA<-U_i*mat_DELTA
> ? ? ? ? ? ? ? ? ? ? ? ?D<-mean_m + t(DELTA)
> ? ? ? ? ? ? ? ?}
>
> ? ? ? ?}
>
> I want to implement this formula for 50 simulations!
>
> any idea?
>
> Thanks a lot!
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From xie at yihui.name  Tue Nov 22 16:33:17 2011
From: xie at yihui.name (Yihui Xie)
Date: Tue, 22 Nov 2011 09:33:17 -0600
Subject: [Rd] links to package vignettes on CRAN after R 2.14.0
In-Reply-To: <20171.20296.823904.398055@fangorn.hornik.net>
References: <CANROs4eB8vipN0WSqQq=gRut=60uQ1Qf+ncPiXeY1gdZ8J-tzg@mail.gmail.com>
	<20171.20296.823904.398055@fangorn.hornik.net>
Message-ID: <CANROs4dNowcw72BHgUJQcCGzSeBYZ1En=U=WqO=8wMb6O2vxXw@mail.gmail.com>

Thanks so much! I thought I misunderstood something new in R 2.14.0.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 515-294-2465 Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA



On Tue, Nov 22, 2011 at 1:29 AM, Kurt Hornik <Kurt.Hornik at wu.ac.at> wrote:
>>>>>> Yihui Xie writes:
>
>> Hi,
>> I noticed the links to my package vignettes on CRAN were gone after I
>> started using ./vignettes instead of ./inst/doc, as suggested by the
>> R-exts manual in R 2.14.0. For example,
>
>> http://cran.r-project.org/web/packages/formatR/index.html
>> http://cran.r-project.org/web/packages/Rd2roxygen/index.html
>
>> I have put %\VignetteIndexEntry in the Rnw file, but I do not
>> understand why CRAN does not create the link in the package webpage
>> any more. In the past, my vignettes were under ./inst/doc, and the
>> links appeared as expected.
>
> Should be fixed now.
>
> -k
>
>> Thanks!
>
>> Regards,
>> Yihui
>> --
>> Yihui Xie <xieyihui at gmail.com>
>> Phone: 515-294-2465 Web: http://yihui.name
>> Department of Statistics, Iowa State University
>> 2215 Snedecor Hall, Ames, IA
>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From hpages at fhcrc.org  Wed Nov 23 07:02:58 2011
From: hpages at fhcrc.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 22 Nov 2011 22:02:58 -0800
Subject: [Rd] (>= x.y.z) in Imports field is ignored
Message-ID: <4ECC8C92.10007@fhcrc.org>

Hi,

I have IRanges 1.13.8 installed:

   > sessionInfo()
   R Under development (unstable) (2011-11-21 r57721)
   Platform: x86_64-unknown-linux-gnu (64-bit)

   locale:
    [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
    [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
    [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
    [7] LC_PAPER=C                 LC_NAME=C
    [9] LC_ADDRESS=C               LC_TELEPHONE=C
   [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C

   attached base packages:
   [1] stats     graphics  grDevices utils     datasets  methods   base

   other attached packages:
   [1] IRanges_1.13.8     BiocGenerics_0.1.3

And, surprisingly, I have no problem installing a package that
requires IRanges >= 1.13.9 (thru the Imports field):

   hpages at rhino1:~/HTSeqGenie/svn> grep IRanges RNASeqGenie/DESCRIPTION
   Imports: BiocGenerics (>= 0.1.3), IRanges (>= 1.13.9),

   hpages at rhino1:~/HTSeqGenie/svn> R-2.15 CMD INSTALL RNASeqGenie
   * installing to library ?/home/hpages/R-2.15/library?
   * installing *source* package ?RNASeqGenie? ...
   ** R
   ** inst
   ** preparing package for lazy loading
   ** help
   *** installing help indices
   ** building package indices ...
   *** tangling vignette sources ...
      ?RNASeqGenie.Rnw?
   ** testing if installed package can be loaded

   * DONE (RNASeqGenie)

Thanks!
H.

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From djsamperi at gmail.com  Wed Nov 23 21:37:22 2011
From: djsamperi at gmail.com (Dominick Samperi)
Date: Wed, 23 Nov 2011 15:37:22 -0500
Subject: [Rd] Non-free packages in R-Forge
In-Reply-To: <4EC6BFEB.6090004@prodsyse.com>
References: <CAPHS2gwxcdpyYPms1DeeTQYALZBTF1KsSN+8Y_Ayf0_Rt71OUg@mail.gmail.com>
	<89F1DF2A-59DB-4429-9CDB-1411B92C013E@comcast.net>
	<CAPHS2gwym6W0zQL+zikaEBytjdWBdZJ=mDdrpBQ1KMRkt0nR0A@mail.gmail.com>
	<4EC6BFEB.6090004@prodsyse.com>
Message-ID: <CADUbQ5h9XpFC17AiFT_-92+Vc4WkDd3aYeNwULyicNR2mGV8Og@mail.gmail.com>

2011/11/18 Spencer Graves <spencer.graves at prodsyse.com>:
> Jordi:
>
>
> ? ? ?Why do you want to reduce demand for Octave by forcing people who want
> to link to a commercial product to abandon Octave?
>
>
> ? ? ?Are you familiar with Shapiro and Varian (1998) Information Rules: ?A
> Strategic Guide to the Network Economy (Harvard Bus. Sch. Pr.)? ?Varian is
> now the Chief Economist at Google, and his ideas seem to have contributed
> substantially to their success. ?The book explains that if you want to
> increase the market for your product, you need to make it as easy as
> possible for potential users to use (for as many different purposes).

The book focuses on penetration pricing and lock-in as tools to
maximize profit, not as a means to support the free software community.
In a paper written a few years later the same authors note: "The very idea
of having "conditions" accompanying a "free" good
confuses some people, and opponents of open source software have done
their best to amplify that confusion." (See Linux Adoption
in the Public Sector: An Economic Analysis, Dec. 2003.)

I think what the original poster (Jordi) is concerned about is that there
are conditions (spelled out by FSF/GPL) that do not seem to be followed
in practice. See, for example,
http://www.gnu.org/licenses/gpl-faq.html#GPLInProprietarySystem

It is important to remember that the FSF/GPL conditions are in addition
to Copyright law, that Copyleft is an extension of Copyright, not in
opposition to it. In particular, the Copyright holders of software released
under GPL are free to release the same software (possibly with a
few extensions) as a proprietary product, without including any
source code. The Copyright holders are also free to permit others
to violate the terms of the FSF/GPL, because only the Copyright
holders are in a legal position to enforce those terms. (In practice
things are complicated by the viral nature of GPL and by the
growing set of Copyright holders over time.)

This may not seem "fair" to some, but I think it is legal (check with
a lawyer to be sure).

Dominick

> ? ? ?I've used Matlab, and I want to start using Octave. ?If I can connect
> from only one of these products to some third party software that I'd like
> also to use, that's a reason to use the more flexible product.
>
>
> ? ? ?Spencer
>
>
> On 11/18/2011 10:32 AM, Jordi Guti?rrez Hermoso wrote:
>>
>> Let me give a little more context of why this is important.
>>
>> As you can read in this thread:
>>
>>
>> http://sourceforge.net/mailarchive/forum.php?thread_name=CAPHS2gwmxJGF9Cy8%3DSEGasQcVRg_Lqu-
>> ndCdVhO-r1LJsRQGuA%40mail.gmail.com&forum_name=octave-dev
>>
>> The author of MOSEK basically created a non-free library and wants to
>> link it to both Octave and R. Normally this would be a GPL violation;
>> however the author of MOSEK has worked around the GPL by making a
>> wrapper and making the user do the linking, effectively neutering the
>> copyleft of the GPL (and yes, the GPL is not nice, and this
>> non-niceness of the GPL is a feature).
>>
>> I am trying to reject this in Octave. We do not want to condone the
>> proliferation of non-free software. Instead, I invite the makers of
>> MOSEK to make the library free. However, the author has pointed out
>> that R has accepted his plugin, why can't Octave?
>>
>> And this is why I appeal to the GNUness of R, if it still has it. If
>> Octave and R are part of the same organisation, we have to stand
>> together on this, and together pressure the maker of MOSEK to release
>> MOSEK as free software and stop trying to work around the GPL with
>> wrappers and avoiding binary distribution.
>>
>> I am inviting R to work together with Octave on this. If we are both
>> using the GPL and both part of GNU, what good is it if the GPL can be
>> worked around and if we don't both stand for the same principles?
>>
>> This isn't about prohibiting R from running on Windows or Mac (Octave
>> also runs on both because it's the only way to reach those users), nor
>> about meaningless ideology, but about bringing about a very practical
>> result: more free software for the community, more source for
>> everyone.
>>
>> So, please, users and developers and overseers of R, work with us. If
>> we are on the same team, can we work towards the same goals?
>>
>> - Jordi G. H.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From hadley at rice.edu  Thu Nov 24 00:48:16 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Wed, 23 Nov 2011 17:48:16 -0600
Subject: [Rd] gsub, utf-8 replacements and the C-locale
Message-ID: <CABdHhvGQ8XQ=0Pd=JK3S+xrWY0w3=7M4So4rCPW4C6EjvhTdsQ@mail.gmail.com>

Hi all,

I'd like to discuss a infelicity/possible bug with gsub.  Take the
following function:

f <- function(x) {
  gsub("\u{A0}", " ", gsub(" ", "\u{A0}", x))
}

As you might expect, in utf-8 locales it is idempotent:

Sys.setlocale("LC_ALL", "UTF-8")
f("x y")
# [1] "x y"

But in the C locale it is not:

Sys.setlocale("LC_ALL", "C")
f("x y")
# [1] "x\302\240y"

This seems weird to me. (And caused a bug in a package because I
didn't realise some windows users have a non-utf8 locale)

I'm not sure what the correct resolution is.  Should the encoding of
the output of gsub be utf-8 if either the input or replacement is
utf-8?  In non-utf-8 locales should the encoding of "\u{A0}" be bytes?

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From simon.urbanek at r-project.org  Thu Nov 24 01:06:17 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 23 Nov 2011 19:06:17 -0500
Subject: [Rd] gsub, utf-8 replacements and the C-locale
In-Reply-To: <CABdHhvGQ8XQ=0Pd=JK3S+xrWY0w3=7M4So4rCPW4C6EjvhTdsQ@mail.gmail.com>
References: <CABdHhvGQ8XQ=0Pd=JK3S+xrWY0w3=7M4So4rCPW4C6EjvhTdsQ@mail.gmail.com>
Message-ID: <173D9C49-3382-4AB8-B85D-13EA7D413165@r-project.org>


On Nov 23, 2011, at 6:48 PM, Hadley Wickham wrote:

> Hi all,
> 
> I'd like to discuss a infelicity/possible bug with gsub.  Take the
> following function:
> 
> f <- function(x) {
>  gsub("\u{A0}", " ", gsub(" ", "\u{A0}", x))
> }
> 
> As you might expect, in utf-8 locales it is idempotent:
> 
> Sys.setlocale("LC_ALL", "UTF-8")
> f("x y")
> # [1] "x y"
> 
> But in the C locale it is not:
> 
> Sys.setlocale("LC_ALL", "C")
> f("x y")
> # [1] "x\302\240y"
> 
> This seems weird to me. (And caused a bug in a package because I
> didn't realise some windows users have a non-utf8 locale)
> 
> I'm not sure what the correct resolution is.  Should the encoding of the output of gsub be utf-8 if either the input or replacement is utf-8?

It is if the input is UTF-8 but only then - that is what is causing the asymmetry. Part of the problem is that you cannot declare 7-bit string as UTF-8 (even though it is valid) so you can't work around it by forcing the encoding.


>  In non-utf-8 locales should the encoding of "\u{A0}" be bytes?
> 

No, because the whole point of the encoding is to define the content. "\ua0" defines one unicode character whereas "\302\240" defines two bytes with unknown meaning. The meaning of UTF-8 encoded strings is still valid in non-UTF-8 locales and the reason why your can work with UTF-8 strings in R irrespective of the locale (very useful thing).

I would suggest to handle the special case of 7-bit input and UTF-8 replacement such that it results in UTF-8 output (as opposed to bytes output with happens now). The relevant code is somewhat convoluted (and more so in R-devel) so I'm not volunteering to do it, though.

Just to make things more clear - the current result (in C locale):

> gsub(" ","\ua0", "foo bar")
[1] "foo\302\240bar"

Possibly desired result:

> gsub(" ","\ua0", "foo bar")
[1] "foo<U+00A0>bar"

Cheers,
Simon


From hb at biostat.ucsf.edu  Thu Nov 24 03:36:38 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Wed, 23 Nov 2011 18:36:38 -0800
Subject: [Rd] capture.output(eval(...,
	envir)) not evaluate in the expected(?) environment
Message-ID: <CAFDcVCS=OPW_HYfh9BM_ddaXQdLv6hSiD6Bd==pois8jYEc6wg@mail.gmail.com>

I've noticed the following oddity where capture.output() prevents
eval() from evaluating an expression in the specified environment.
I'm not sure if it is an undocumented feature or a bug.  It caused me
many hours of troubleshooting.  By posting it here, it might save
someone else from doing the same exercise.

Start by defining foo() which evaluates an expression locally in a
given environment and catches the output via capture.output():

foo <- function(..., envir=parent.frame()) {
  capture.output({
    eval(substitute({x <- 1}), envir=envir)
  })
} # foo()

Then call:

> suppressWarnings(rm(x)); foo(envir=globalenv()); print(x);
character(0)
[1] 1

This works as expected.  However, if argument 'envir' is not specified
explicitly, you get:

> suppressWarnings(rm(x)); foo(); str(x);
character(0)
Error in str(x) : object 'x' not found

which shows that the internal expression of foo() is *not* evaluated
in the parent.frame(), i.e. the caller of foo(), which here should be
globalenv().   It appears that capture.output() prevents this, because
by dropping the latter:

foo <- function(..., envir=parent.frame()) {
  eval(substitute({x <- 1}), envir=envir)
} # foo()

it works:

> suppressWarnings(rm(x)); foo(); str(x);
[1] 1

The workaround when still using capture.output() is to force an
explicit evaluation of argument 'envir' inside of foo() before:

foo <- function(..., envir=parent.frame()) {
  stopifnot(is.environment(envir))  # Workaround
  capture.output({
    eval(substitute({x <- 1}), envir=envir)
  })
} # foo()

which gives:
> suppressWarnings(rm(x)); foo(); str(x);
character(0)
 num 1

This occurs with R v2.14.0 patched and R devel:

> sessionInfo()
R version 2.14.0 Patched (2011-11-20 r57720)
Platform: x86_64-pc-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

> sessionInfo()
R Under development (unstable) (2011-11-20 r57720)
Platform: x86_64-pc-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

/Henrik


From simon.urbanek at r-project.org  Thu Nov 24 03:56:55 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 23 Nov 2011 21:56:55 -0500
Subject: [Rd] capture.output(eval(...,
	envir)) not evaluate in the expected(?) environment
In-Reply-To: <CAFDcVCS=OPW_HYfh9BM_ddaXQdLv6hSiD6Bd==pois8jYEc6wg@mail.gmail.com>
References: <CAFDcVCS=OPW_HYfh9BM_ddaXQdLv6hSiD6Bd==pois8jYEc6wg@mail.gmail.com>
Message-ID: <62B71EB4-EAE3-40BA-BB29-769E9C4C1A2D@r-project.org>

IMHO this has nothing to do with capture.output() per se - it's simply lazy evaluation that gets you. Add force(envir) before capture.output and it works as you expected - the parent.frame() will be different inside capture.output than outside.

Cheers,
Simon


On Nov 23, 2011, at 9:36 PM, Henrik Bengtsson wrote:

> I've noticed the following oddity where capture.output() prevents
> eval() from evaluating an expression in the specified environment.
> I'm not sure if it is an undocumented feature or a bug.  It caused me
> many hours of troubleshooting.  By posting it here, it might save
> someone else from doing the same exercise.
> 
> Start by defining foo() which evaluates an expression locally in a
> given environment and catches the output via capture.output():
> 
> foo <- function(..., envir=parent.frame()) {
>  capture.output({
>    eval(substitute({x <- 1}), envir=envir)
>  })
> } # foo()
> 
> Then call:
> 
>> suppressWarnings(rm(x)); foo(envir=globalenv()); print(x);
> character(0)
> [1] 1
> 
> This works as expected.  However, if argument 'envir' is not specified
> explicitly, you get:
> 
>> suppressWarnings(rm(x)); foo(); str(x);
> character(0)
> Error in str(x) : object 'x' not found
> 
> which shows that the internal expression of foo() is *not* evaluated
> in the parent.frame(), i.e. the caller of foo(), which here should be
> globalenv().   It appears that capture.output() prevents this, because
> by dropping the latter:
> 
> foo <- function(..., envir=parent.frame()) {
>  eval(substitute({x <- 1}), envir=envir)
> } # foo()
> 
> it works:
> 
>> suppressWarnings(rm(x)); foo(); str(x);
> [1] 1
> 
> The workaround when still using capture.output() is to force an
> explicit evaluation of argument 'envir' inside of foo() before:
> 
> foo <- function(..., envir=parent.frame()) {
>  stopifnot(is.environment(envir))  # Workaround
>  capture.output({
>    eval(substitute({x <- 1}), envir=envir)
>  })
> } # foo()
> 
> which gives:
>> suppressWarnings(rm(x)); foo(); str(x);
> character(0)
> num 1
> 
> This occurs with R v2.14.0 patched and R devel:
> 
>> sessionInfo()
> R version 2.14.0 Patched (2011-11-20 r57720)
> Platform: x86_64-pc-mingw32/x64 (64-bit)
> 
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
>> sessionInfo()
> R Under development (unstable) (2011-11-20 r57720)
> Platform: x86_64-pc-mingw32/x64 (64-bit)
> 
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> /Henrik
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From hb at biostat.ucsf.edu  Thu Nov 24 05:06:17 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Wed, 23 Nov 2011 20:06:17 -0800
Subject: [Rd] capture.output(eval(...,
 envir)) not evaluate in the expected(?) environment
In-Reply-To: <62B71EB4-EAE3-40BA-BB29-769E9C4C1A2D@r-project.org>
References: <CAFDcVCS=OPW_HYfh9BM_ddaXQdLv6hSiD6Bd==pois8jYEc6wg@mail.gmail.com>
	<62B71EB4-EAE3-40BA-BB29-769E9C4C1A2D@r-project.org>
Message-ID: <CAFDcVCR5r=jiEDV-Ga5PYrLDwvmd8oW59VKdG1R5moTKq6KfqQ@mail.gmail.com>

Thanks for the quick answer.  I didn't know about force() function.

Cheers,

Henrik

On Wed, Nov 23, 2011 at 6:56 PM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
> IMHO this has nothing to do with capture.output() per se - it's simply lazy evaluation that gets you. Add force(envir) before capture.output and it works as you expected - the parent.frame() will be different inside capture.output than outside.
>
> Cheers,
> Simon
>
>
> On Nov 23, 2011, at 9:36 PM, Henrik Bengtsson wrote:
>
>> I've noticed the following oddity where capture.output() prevents
>> eval() from evaluating an expression in the specified environment.
>> I'm not sure if it is an undocumented feature or a bug. ?It caused me
>> many hours of troubleshooting. ?By posting it here, it might save
>> someone else from doing the same exercise.
>>
>> Start by defining foo() which evaluates an expression locally in a
>> given environment and catches the output via capture.output():
>>
>> foo <- function(..., envir=parent.frame()) {
>> ?capture.output({
>> ? ?eval(substitute({x <- 1}), envir=envir)
>> ?})
>> } # foo()
>>
>> Then call:
>>
>>> suppressWarnings(rm(x)); foo(envir=globalenv()); print(x);
>> character(0)
>> [1] 1
>>
>> This works as expected. ?However, if argument 'envir' is not specified
>> explicitly, you get:
>>
>>> suppressWarnings(rm(x)); foo(); str(x);
>> character(0)
>> Error in str(x) : object 'x' not found
>>
>> which shows that the internal expression of foo() is *not* evaluated
>> in the parent.frame(), i.e. the caller of foo(), which here should be
>> globalenv(). ? It appears that capture.output() prevents this, because
>> by dropping the latter:
>>
>> foo <- function(..., envir=parent.frame()) {
>> ?eval(substitute({x <- 1}), envir=envir)
>> } # foo()
>>
>> it works:
>>
>>> suppressWarnings(rm(x)); foo(); str(x);
>> [1] 1
>>
>> The workaround when still using capture.output() is to force an
>> explicit evaluation of argument 'envir' inside of foo() before:
>>
>> foo <- function(..., envir=parent.frame()) {
>> ?stopifnot(is.environment(envir)) ?# Workaround
>> ?capture.output({
>> ? ?eval(substitute({x <- 1}), envir=envir)
>> ?})
>> } # foo()
>>
>> which gives:
>>> suppressWarnings(rm(x)); foo(); str(x);
>> character(0)
>> num 1
>>
>> This occurs with R v2.14.0 patched and R devel:
>>
>>> sessionInfo()
>> R version 2.14.0 Patched (2011-11-20 r57720)
>> Platform: x86_64-pc-mingw32/x64 (64-bit)
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252
>> [2] LC_CTYPE=English_United States.1252
>> [3] LC_MONETARY=English_United States.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>
>>> sessionInfo()
>> R Under development (unstable) (2011-11-20 r57720)
>> Platform: x86_64-pc-mingw32/x64 (64-bit)
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252
>> [2] LC_CTYPE=English_United States.1252
>> [3] LC_MONETARY=English_United States.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>
>> /Henrik
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
>


From mathieu.ribatet at math.univ-montp2.fr  Thu Nov 24 09:54:36 2011
From: mathieu.ribatet at math.univ-montp2.fr (Mathieu Ribatet)
Date: Thu, 24 Nov 2011 09:54:36 +0100
Subject: [Rd] Changing graphic titles when using bquote and resizing the
	graphic window
Message-ID: <4A8ABA2F-933A-495A-9990-E4258965838A@math.univ-montp2.fr>

Dear list,

I found a strange behavior of the graphic display when using bquote to set a title to a plot. The problem arise when you manually resize the graphic window using the mouse. It happens on both quartz and x11 devices. Here's a reproducible example:

par(mfrow = c(1,3))
for (i in 1:3){
  title <- as.expression(bquote(gamma[.(i)]))
  plot(1:10, main = title)
}

Once you ran the code, the figure displays as expected --- each title is $\gamma_i$, $i=1, 2, 3$. Now if you resize manually the graphic window using the mouse all the titles will be set to $\gamma_3$.

In case this is useful, here's the ouput of sessionInfo().

> sessionInfo()
R version 2.14.0 (2011-10-31)
Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base    

Best,
Mathieu

----------------------------------------------------------------- 
I3M, UMR CNRS 5149
Universite Montpellier II,
4 place Eugene Bataillon
34095 Montpellier cedex 5   France
http://www.math.univ-montp2.fr/~ribatet
Tel: + 33 (0)4 67 14 41 98


From mdowle at mdowle.plus.com  Thu Nov 24 11:13:10 2011
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Thu, 24 Nov 2011 10:13:10 -0000
Subject: [Rd] Confused about NAMED
Message-ID: <719cbc60d789ea0d3bf1d6a18309a216.squirrel@webmail.plus.net>

Hi,

I expected NAMED to be 1 in all these three cases. It is for one of them,
but not the other two?

> R --vanilla
R version 2.14.0 (2011-10-31)
Platform: i386-pc-mingw32/i386 (32-bit)

> x = 1L
> .Internal(inspect(x))   # why NAM(2)? expected NAM(1)
@2514aa0 13 INTSXP g0c1 [NAM(2)] (len=1, tl=0) 1

> y = 1:10
> .Internal(inspect(y))   # NAM(1) as expected but why different to x?
@272f788 13 INTSXP g0c4 [NAM(1)] (len=10, tl=0) 1,2,3,4,5,...

> z = data.frame()
> .Internal(inspect(z))   # why NAM(2)? expected NAM(1)
@24fc28c 19 VECSXP g0c0 [OBJ,NAM(2),ATT] (len=0, tl=0)
ATTRIB:
  @24fc270 02 LISTSXP g0c0 []
    TAG: @3f2120 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
    @24fc334 16 STRSXP g0c0 [] (len=0, tl=0)
    TAG: @3f2040 01 SYMSXP g0c0 [MARK,gp=0x4000] "row.names"
    @24fc318 13 INTSXP g0c0 [] (len=0, tl=0)
    TAG: @3f2388 01 SYMSXP g0c0 [MARK,gp=0x4000] "class"
    @25be500 16 STRSXP g0c1 [] (len=1, tl=0)
      @1d38af0 09 CHARSXP g0c2 [MARK,gp=0x21,ATT] "data.frame"

It's a little difficult to search for the word "named" but I tried and
found this in R-ints :

    "Note that optimizing NAMED = 1 is only effective within a primitive
(as the closure wrapper of a .Internal will set NAMED = 2 when the
promise to the argument is evaluated)"

So might it be that just looking at NAMED using .Internal(inspect()) is
setting NAMED=2?  But if so, why does y have NAMED==1?

Thanks!
Matthew


From pdalgd at gmail.com  Thu Nov 24 12:07:28 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 24 Nov 2011 12:07:28 +0100
Subject: [Rd] Confused about NAMED
In-Reply-To: <719cbc60d789ea0d3bf1d6a18309a216.squirrel@webmail.plus.net>
References: <719cbc60d789ea0d3bf1d6a18309a216.squirrel@webmail.plus.net>
Message-ID: <090530A4-BBC5-48B3-9EC0-2D965C200729@gmail.com>


On Nov 24, 2011, at 11:13 , Matthew Dowle wrote:

> Hi,
> 
> I expected NAMED to be 1 in all these three cases. It is for one of them,
> but not the other two?
> 
>> R --vanilla
> R version 2.14.0 (2011-10-31)
> Platform: i386-pc-mingw32/i386 (32-bit)
> 
>> x = 1L
>> .Internal(inspect(x))   # why NAM(2)? expected NAM(1)
> @2514aa0 13 INTSXP g0c1 [NAM(2)] (len=1, tl=0) 1
> 
>> y = 1:10
>> .Internal(inspect(y))   # NAM(1) as expected but why different to x?
> @272f788 13 INTSXP g0c4 [NAM(1)] (len=10, tl=0) 1,2,3,4,5,...
> 
>> z = data.frame()
>> .Internal(inspect(z))   # why NAM(2)? expected NAM(1)
> @24fc28c 19 VECSXP g0c0 [OBJ,NAM(2),ATT] (len=0, tl=0)
> ATTRIB:
>  @24fc270 02 LISTSXP g0c0 []
>    TAG: @3f2120 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
>    @24fc334 16 STRSXP g0c0 [] (len=0, tl=0)
>    TAG: @3f2040 01 SYMSXP g0c0 [MARK,gp=0x4000] "row.names"
>    @24fc318 13 INTSXP g0c0 [] (len=0, tl=0)
>    TAG: @3f2388 01 SYMSXP g0c0 [MARK,gp=0x4000] "class"
>    @25be500 16 STRSXP g0c1 [] (len=1, tl=0)
>      @1d38af0 09 CHARSXP g0c2 [MARK,gp=0x21,ATT] "data.frame"
> 
> It's a little difficult to search for the word "named" but I tried and
> found this in R-ints :
> 
>    "Note that optimizing NAMED = 1 is only effective within a primitive
> (as the closure wrapper of a .Internal will set NAMED = 2 when the
> promise to the argument is evaluated)"
> 
> So might it be that just looking at NAMED using .Internal(inspect()) is
> setting NAMED=2?  But if so, why does y have NAMED==1?

This is tricky business... I'm not quite sure I'll get it right, but let's try

When you are assigning a constant, the value you assign is already part of the assignment expression, so if you want to modify it, you must duplicate. So NAMED==2 on z <- 1 is basically to prevent you from accidentally "changing the value of 1". If it weren't, then you could get bitten by code like for(i in 1:2) {z <- 1; if(i==1) z[1] <- 2}.

If you're assigning the result of a computation, then the object only exists once, so 
z <- 0+1  gets NAMED==1.

However, if the computation is done by returning a named value from within a function, as in

> f <- function(){v <- 1+0; v}
> z <- f()

then again NAMED==2. This is because the side effects of the function _might_ result in something having a hold on the function environment, e.g. if we had 

e <- NULL
f <- function(){e <<-environment(); v <- 1+0; v}
z <- f()

then z[1] <- 5 would change e$v too. As it happens, there aren't any side effects in the forme case, but R loses track and assumes the worst.


> 
> Thanks!
> Matthew
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From mdowle at mdowle.plus.com  Thu Nov 24 12:34:55 2011
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Thu, 24 Nov 2011 11:34:55 -0000
Subject: [Rd] Confused about NAMED
In-Reply-To: <090530A4-BBC5-48B3-9EC0-2D965C200729@gmail.com>
References: <719cbc60d789ea0d3bf1d6a18309a216.squirrel@webmail.plus.net>
	<090530A4-BBC5-48B3-9EC0-2D965C200729@gmail.com>
Message-ID: <2573e1d2e510477135f6246e60d53aef.squirrel@webmail.plus.net>

>
> On Nov 24, 2011, at 11:13 , Matthew Dowle wrote:
>
>> Hi,
>>
>> I expected NAMED to be 1 in all these three cases. It is for one of
>> them,
>> but not the other two?
>>
>>> R --vanilla
>> R version 2.14.0 (2011-10-31)
>> Platform: i386-pc-mingw32/i386 (32-bit)
>>
>>> x = 1L
>>> .Internal(inspect(x))   # why NAM(2)? expected NAM(1)
>> @2514aa0 13 INTSXP g0c1 [NAM(2)] (len=1, tl=0) 1
>>
>>> y = 1:10
>>> .Internal(inspect(y))   # NAM(1) as expected but why different to x?
>> @272f788 13 INTSXP g0c4 [NAM(1)] (len=10, tl=0) 1,2,3,4,5,...
>>
>>> z = data.frame()
>>> .Internal(inspect(z))   # why NAM(2)? expected NAM(1)
>> @24fc28c 19 VECSXP g0c0 [OBJ,NAM(2),ATT] (len=0, tl=0)
>> ATTRIB:
>>  @24fc270 02 LISTSXP g0c0 []
>>    TAG: @3f2120 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
>>    @24fc334 16 STRSXP g0c0 [] (len=0, tl=0)
>>    TAG: @3f2040 01 SYMSXP g0c0 [MARK,gp=0x4000] "row.names"
>>    @24fc318 13 INTSXP g0c0 [] (len=0, tl=0)
>>    TAG: @3f2388 01 SYMSXP g0c0 [MARK,gp=0x4000] "class"
>>    @25be500 16 STRSXP g0c1 [] (len=1, tl=0)
>>      @1d38af0 09 CHARSXP g0c2 [MARK,gp=0x21,ATT] "data.frame"
>>
>> It's a little difficult to search for the word "named" but I tried and
>> found this in R-ints :
>>
>>    "Note that optimizing NAMED = 1 is only effective within a primitive
>> (as the closure wrapper of a .Internal will set NAMED = 2 when the
>> promise to the argument is evaluated)"
>>
>> So might it be that just looking at NAMED using .Internal(inspect()) is
>> setting NAMED=2?  But if so, why does y have NAMED==1?
>
> This is tricky business... I'm not quite sure I'll get it right, but let's
> try
>
> When you are assigning a constant, the value you assign is already part of
> the assignment expression, so if you want to modify it, you must
> duplicate. So NAMED==2 on z <- 1 is basically to prevent you from
> accidentally "changing the value of 1". If it weren't, then you could get
> bitten by code like for(i in 1:2) {z <- 1; if(i==1) z[1] <- 2}.
>
> If you're assigning the result of a computation, then the object only
> exists once, so
> z <- 0+1  gets NAMED==1.
>
> However, if the computation is done by returning a named value from within
> a function, as in
>
>> f <- function(){v <- 1+0; v}
>> z <- f()
>
> then again NAMED==2. This is because the side effects of the function
> _might_ result in something having a hold on the function environment,
> e.g. if we had
>
> e <- NULL
> f <- function(){e <<-environment(); v <- 1+0; v}
> z <- f()
>
> then z[1] <- 5 would change e$v too. As it happens, there aren't any side
> effects in the forme case, but R loses track and assumes the worst.
>

Thanks a lot, think I follow. That explains x vs y, but why is z NAMED==2?
The result of data.frame() is an object that exists once (similar to 1:10)
so shouldn't it be NAMED==1 too?  Or, R loses track and assumes the worst
even on its own functions such as data.frame()?

>>
>> Thanks!
>> Matthew
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> --
> Peter Dalgaard, Professor
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>


From ripley at stats.ox.ac.uk  Thu Nov 24 12:48:34 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 24 Nov 2011 11:48:34 +0000
Subject: [Rd] Changing graphic titles when using bquote and resizing the
 graphic window
In-Reply-To: <4A8ABA2F-933A-495A-9990-E4258965838A@math.univ-montp2.fr>
References: <4A8ABA2F-933A-495A-9990-E4258965838A@math.univ-montp2.fr>
Message-ID: <4ECE2F12.1030903@stats.ox.ac.uk>

(Why is this an R-devel topic?)

When you resize a plot (and sometimes when the graph is repainted), the 
display list is replay-ed.  So if you force delayed evaluation, you get 
evaluation when the list is replay-ed.  So the 'strange' thing is that 
you think delaying evaluation is a good idea.  Use substitute, as the R 
help pages advise.  E.g.

par(mfrow = c(1,3))
for (i in 1:3){
   title <- substitute(gamma[j], list(j=i))
   plot(1:10, main = title)
}


On 24/11/2011 08:54, Mathieu Ribatet wrote:
> Dear list,
>
> I found a strange behavior of the graphic display when using bquote to set a title to a plot. The problem arise when you manually resize the graphic window using the mouse. It happens on both quartz and x11 devices. Here's a reproducible example:
>
> par(mfrow = c(1,3))
> for (i in 1:3){
>    title<- as.expression(bquote(gamma[.(i)]))
>    plot(1:10, main = title)
> }
>
> Once you ran the code, the figure displays as expected --- each title is $\gamma_i$, $i=1, 2, 3$. Now if you resize manually the graphic window using the mouse all the titles will be set to $\gamma_3$.
>
> In case this is useful, here's the ouput of sessionInfo().
>
>> sessionInfo()
> R version 2.14.0 (2011-10-31)
> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>
> locale:
> [1] C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> Best,
> Mathieu
>
> -----------------------------------------------------------------
> I3M, UMR CNRS 5149
> Universite Montpellier II,
> 4 place Eugene Bataillon
> 34095 Montpellier cedex 5   France
> http://www.math.univ-montp2.fr/~ribatet
> Tel: + 33 (0)4 67 14 41 98
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch.duncan at gmail.com  Thu Nov 24 13:04:03 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 24 Nov 2011 07:04:03 -0500
Subject: [Rd] Confused about NAMED
In-Reply-To: <2573e1d2e510477135f6246e60d53aef.squirrel@webmail.plus.net>
References: <719cbc60d789ea0d3bf1d6a18309a216.squirrel@webmail.plus.net>
	<090530A4-BBC5-48B3-9EC0-2D965C200729@gmail.com>
	<2573e1d2e510477135f6246e60d53aef.squirrel@webmail.plus.net>
Message-ID: <4ECE32B3.1080508@gmail.com>

On 11-11-24 6:34 AM, Matthew Dowle wrote:
>>
>> On Nov 24, 2011, at 11:13 , Matthew Dowle wrote:
>>
>>> Hi,
>>>
>>> I expected NAMED to be 1 in all these three cases. It is for one of
>>> them,
>>> but not the other two?
>>>
>>>> R --vanilla
>>> R version 2.14.0 (2011-10-31)
>>> Platform: i386-pc-mingw32/i386 (32-bit)
>>>
>>>> x = 1L
>>>> .Internal(inspect(x))   # why NAM(2)? expected NAM(1)
>>> @2514aa0 13 INTSXP g0c1 [NAM(2)] (len=1, tl=0) 1
>>>
>>>> y = 1:10
>>>> .Internal(inspect(y))   # NAM(1) as expected but why different to x?
>>> @272f788 13 INTSXP g0c4 [NAM(1)] (len=10, tl=0) 1,2,3,4,5,...
>>>
>>>> z = data.frame()
>>>> .Internal(inspect(z))   # why NAM(2)? expected NAM(1)
>>> @24fc28c 19 VECSXP g0c0 [OBJ,NAM(2),ATT] (len=0, tl=0)
>>> ATTRIB:
>>>   @24fc270 02 LISTSXP g0c0 []
>>>     TAG: @3f2120 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
>>>     @24fc334 16 STRSXP g0c0 [] (len=0, tl=0)
>>>     TAG: @3f2040 01 SYMSXP g0c0 [MARK,gp=0x4000] "row.names"
>>>     @24fc318 13 INTSXP g0c0 [] (len=0, tl=0)
>>>     TAG: @3f2388 01 SYMSXP g0c0 [MARK,gp=0x4000] "class"
>>>     @25be500 16 STRSXP g0c1 [] (len=1, tl=0)
>>>       @1d38af0 09 CHARSXP g0c2 [MARK,gp=0x21,ATT] "data.frame"
>>>
>>> It's a little difficult to search for the word "named" but I tried and
>>> found this in R-ints :
>>>
>>>     "Note that optimizing NAMED = 1 is only effective within a primitive
>>> (as the closure wrapper of a .Internal will set NAMED = 2 when the
>>> promise to the argument is evaluated)"
>>>
>>> So might it be that just looking at NAMED using .Internal(inspect()) is
>>> setting NAMED=2?  But if so, why does y have NAMED==1?
>>
>> This is tricky business... I'm not quite sure I'll get it right, but let's
>> try
>>
>> When you are assigning a constant, the value you assign is already part of
>> the assignment expression, so if you want to modify it, you must
>> duplicate. So NAMED==2 on z<- 1 is basically to prevent you from
>> accidentally "changing the value of 1". If it weren't, then you could get
>> bitten by code like for(i in 1:2) {z<- 1; if(i==1) z[1]<- 2}.
>>
>> If you're assigning the result of a computation, then the object only
>> exists once, so
>> z<- 0+1  gets NAMED==1.
>>
>> However, if the computation is done by returning a named value from within
>> a function, as in
>>
>>> f<- function(){v<- 1+0; v}
>>> z<- f()
>>
>> then again NAMED==2. This is because the side effects of the function
>> _might_ result in something having a hold on the function environment,
>> e.g. if we had
>>
>> e<- NULL
>> f<- function(){e<<-environment(); v<- 1+0; v}
>> z<- f()
>>
>> then z[1]<- 5 would change e$v too. As it happens, there aren't any side
>> effects in the forme case, but R loses track and assumes the worst.
>>
>
> Thanks a lot, think I follow. That explains x vs y, but why is z NAMED==2?
> The result of data.frame() is an object that exists once (similar to 1:10)
> so shouldn't it be NAMED==1 too?  Or, R loses track and assumes the worst
> even on its own functions such as data.frame()?

R has several types of functions -- see the R Internals manual for 
details.  data.frame() is a plain R function, so it is treated no 
differently than any user-written function.  On the other hand, the 
internal function that implements the : operator is a "primitive", so it 
has complete control over its return value, and it can set NAMED in the 
most efficient way.

So you might think that returning a value as an evaluation of a 
primitive adds efficiency, e.g. in Peter's example

f<- function(){v<- 1+0; v + 0}

will return NAMED == 1.  But that's because internally it had to make a 
copy of v before adding 0 to it, so you've probably really made it less 
efficient:  the original version might never modify the result, so it 
might never make a copy.

Duncan Murdoch


From pdalgd at gmail.com  Thu Nov 24 13:18:00 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 24 Nov 2011 13:18:00 +0100
Subject: [Rd] Confused about NAMED
In-Reply-To: <2573e1d2e510477135f6246e60d53aef.squirrel@webmail.plus.net>
References: <719cbc60d789ea0d3bf1d6a18309a216.squirrel@webmail.plus.net>
	<090530A4-BBC5-48B3-9EC0-2D965C200729@gmail.com>
	<2573e1d2e510477135f6246e60d53aef.squirrel@webmail.plus.net>
Message-ID: <A46434F9-309A-4D83-A5F1-54472DE36FDE@gmail.com>


On Nov 24, 2011, at 12:34 , Matthew Dowle wrote:

>> 
>> On Nov 24, 2011, at 11:13 , Matthew Dowle wrote:
>> 
>>> Hi,
>>> 
>>> I expected NAMED to be 1 in all these three cases. It is for one of
>>> them,
>>> but not the other two?
>>> 
>>>> R --vanilla
>>> R version 2.14.0 (2011-10-31)
>>> Platform: i386-pc-mingw32/i386 (32-bit)
>>> 
>>>> x = 1L
>>>> .Internal(inspect(x))   # why NAM(2)? expected NAM(1)
>>> @2514aa0 13 INTSXP g0c1 [NAM(2)] (len=1, tl=0) 1
>>> 
>>>> y = 1:10
>>>> .Internal(inspect(y))   # NAM(1) as expected but why different to x?
>>> @272f788 13 INTSXP g0c4 [NAM(1)] (len=10, tl=0) 1,2,3,4,5,...
>>> 
>>>> z = data.frame()
>>>> .Internal(inspect(z))   # why NAM(2)? expected NAM(1)
>>> @24fc28c 19 VECSXP g0c0 [OBJ,NAM(2),ATT] (len=0, tl=0)
>>> ATTRIB:
>>> @24fc270 02 LISTSXP g0c0 []
>>>   TAG: @3f2120 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
>>>   @24fc334 16 STRSXP g0c0 [] (len=0, tl=0)
>>>   TAG: @3f2040 01 SYMSXP g0c0 [MARK,gp=0x4000] "row.names"
>>>   @24fc318 13 INTSXP g0c0 [] (len=0, tl=0)
>>>   TAG: @3f2388 01 SYMSXP g0c0 [MARK,gp=0x4000] "class"
>>>   @25be500 16 STRSXP g0c1 [] (len=1, tl=0)
>>>     @1d38af0 09 CHARSXP g0c2 [MARK,gp=0x21,ATT] "data.frame"
>>> 
>>> It's a little difficult to search for the word "named" but I tried and
>>> found this in R-ints :
>>> 
>>>   "Note that optimizing NAMED = 1 is only effective within a primitive
>>> (as the closure wrapper of a .Internal will set NAMED = 2 when the
>>> promise to the argument is evaluated)"
>>> 
>>> So might it be that just looking at NAMED using .Internal(inspect()) is
>>> setting NAMED=2?  But if so, why does y have NAMED==1?
>> 
>> This is tricky business... I'm not quite sure I'll get it right, but let's
>> try
>> 
>> When you are assigning a constant, the value you assign is already part of
>> the assignment expression, so if you want to modify it, you must
>> duplicate. So NAMED==2 on z <- 1 is basically to prevent you from
>> accidentally "changing the value of 1". If it weren't, then you could get
>> bitten by code like for(i in 1:2) {z <- 1; if(i==1) z[1] <- 2}.
>> 
>> If you're assigning the result of a computation, then the object only
>> exists once, so
>> z <- 0+1  gets NAMED==1.
>> 
>> However, if the computation is done by returning a named value from within
>> a function, as in
>> 
>>> f <- function(){v <- 1+0; v}
>>> z <- f()
>> 
>> then again NAMED==2. This is because the side effects of the function
>> _might_ result in something having a hold on the function environment,
>> e.g. if we had
>> 
>> e <- NULL
>> f <- function(){e <<-environment(); v <- 1+0; v}
>> z <- f()
>> 
>> then z[1] <- 5 would change e$v too. As it happens, there aren't any side
>> effects in the forme case, but R loses track and assumes the worst.
>> 
> 
> Thanks a lot, think I follow. That explains x vs y, but why is z NAMED==2?
> The result of data.frame() is an object that exists once (similar to 1:10)
> so shouldn't it be NAMED==1 too?  Or, R loses track and assumes the worst
> even on its own functions such as data.frame()?

R loses track. I suspect that is really all it can do without actual reference counting. The function data.frame is more than 150 lines of code, and if any of those end up invoking user code, possibly via a class method, you can't tell definitively whether or not the evaluation environment dies at the return. 

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From mdowle at mdowle.plus.com  Thu Nov 24 14:05:43 2011
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Thu, 24 Nov 2011 13:05:43 -0000
Subject: [Rd] Confused about NAMED
In-Reply-To: <A46434F9-309A-4D83-A5F1-54472DE36FDE@gmail.com>
References: <719cbc60d789ea0d3bf1d6a18309a216.squirrel@webmail.plus.net>
	<090530A4-BBC5-48B3-9EC0-2D965C200729@gmail.com>
	<2573e1d2e510477135f6246e60d53aef.squirrel@webmail.plus.net>
	<A46434F9-309A-4D83-A5F1-54472DE36FDE@gmail.com>
Message-ID: <0feab74fdda903967fff2f6868d8cf75.squirrel@webmail.plus.net>

>
> On Nov 24, 2011, at 12:34 , Matthew Dowle wrote:
>
>>>
>>> On Nov 24, 2011, at 11:13 , Matthew Dowle wrote:
>>>
>>>> Hi,
>>>>
>>>> I expected NAMED to be 1 in all these three cases. It is for one of
>>>> them,
>>>> but not the other two?
>>>>
>>>>> R --vanilla
>>>> R version 2.14.0 (2011-10-31)
>>>> Platform: i386-pc-mingw32/i386 (32-bit)
>>>>
>>>>> x = 1L
>>>>> .Internal(inspect(x))   # why NAM(2)? expected NAM(1)
>>>> @2514aa0 13 INTSXP g0c1 [NAM(2)] (len=1, tl=0) 1
>>>>
>>>>> y = 1:10
>>>>> .Internal(inspect(y))   # NAM(1) as expected but why different to x?
>>>> @272f788 13 INTSXP g0c4 [NAM(1)] (len=10, tl=0) 1,2,3,4,5,...
>>>>
>>>>> z = data.frame()
>>>>> .Internal(inspect(z))   # why NAM(2)? expected NAM(1)
>>>> @24fc28c 19 VECSXP g0c0 [OBJ,NAM(2),ATT] (len=0, tl=0)
>>>> ATTRIB:
>>>> @24fc270 02 LISTSXP g0c0 []
>>>>   TAG: @3f2120 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
>>>>   @24fc334 16 STRSXP g0c0 [] (len=0, tl=0)
>>>>   TAG: @3f2040 01 SYMSXP g0c0 [MARK,gp=0x4000] "row.names"
>>>>   @24fc318 13 INTSXP g0c0 [] (len=0, tl=0)
>>>>   TAG: @3f2388 01 SYMSXP g0c0 [MARK,gp=0x4000] "class"
>>>>   @25be500 16 STRSXP g0c1 [] (len=1, tl=0)
>>>>     @1d38af0 09 CHARSXP g0c2 [MARK,gp=0x21,ATT] "data.frame"
>>>>
>>>> It's a little difficult to search for the word "named" but I tried and
>>>> found this in R-ints :
>>>>
>>>>   "Note that optimizing NAMED = 1 is only effective within a primitive
>>>> (as the closure wrapper of a .Internal will set NAMED = 2 when the
>>>> promise to the argument is evaluated)"
>>>>
>>>> So might it be that just looking at NAMED using .Internal(inspect())
>>>> is
>>>> setting NAMED=2?  But if so, why does y have NAMED==1?
>>>
>>> This is tricky business... I'm not quite sure I'll get it right, but
>>> let's
>>> try
>>>
>>> When you are assigning a constant, the value you assign is already part
>>> of
>>> the assignment expression, so if you want to modify it, you must
>>> duplicate. So NAMED==2 on z <- 1 is basically to prevent you from
>>> accidentally "changing the value of 1". If it weren't, then you could
>>> get
>>> bitten by code like for(i in 1:2) {z <- 1; if(i==1) z[1] <- 2}.
>>>
>>> If you're assigning the result of a computation, then the object only
>>> exists once, so
>>> z <- 0+1  gets NAMED==1.
>>>
>>> However, if the computation is done by returning a named value from
>>> within
>>> a function, as in
>>>
>>>> f <- function(){v <- 1+0; v}
>>>> z <- f()
>>>
>>> then again NAMED==2. This is because the side effects of the function
>>> _might_ result in something having a hold on the function environment,
>>> e.g. if we had
>>>
>>> e <- NULL
>>> f <- function(){e <<-environment(); v <- 1+0; v}
>>> z <- f()
>>>
>>> then z[1] <- 5 would change e$v too. As it happens, there aren't any
>>> side
>>> effects in the forme case, but R loses track and assumes the worst.
>>>
>>
>> Thanks a lot, think I follow. That explains x vs y, but why is z
>> NAMED==2?
>> The result of data.frame() is an object that exists once (similar to
>> 1:10)
>> so shouldn't it be NAMED==1 too?  Or, R loses track and assumes the
>> worst
>> even on its own functions such as data.frame()?
>
> R loses track. I suspect that is really all it can do without actual
> reference counting. The function data.frame is more than 150 lines of
> code, and if any of those end up invoking user code, possibly via a class
> method, you can't tell definitively whether or not the evaluation
> environment dies at the return.

Ohhh, think I see now. After Duncan's reply I was going to ask if it was
possible to change data.frame() to be primitive so it could set NAMED=1.
But it seems primitive functions can't use R code so data.frame() would
need to be ported to C. Ok! - not quick or easy, and not without
consideable risk. And, data.frame() can invoke user code inside it anyway
then.

Since list() is primitive I tried to construct a data.frame starting with
list() [since structure() isn't primitive], but then merely adding an
attribute seems to set NAMED==2 too ?

> DF = list(a=1:3,b=4:6)
> .Internal(inspect(DF))     # so far so good: NAM(1)
@25149e0 19 VECSXP g0c1 [NAM(1),ATT] (len=2, tl=0)
  @263ea50 13 INTSXP g0c2 [] (len=3, tl=0) 1,2,3
  @263eaa0 13 INTSXP g0c2 [] (len=3, tl=0) 4,5,6
ATTRIB:
  @2457984 02 LISTSXP g0c0 []
    TAG: @3f2120 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
    @25149c0 16 STRSXP g0c1 [] (len=2, tl=0)
      @1e987d8 09 CHARSXP g0c1 [MARK,gp=0x21] "a"
      @1e56948 09 CHARSXP g0c1 [MARK,gp=0x21] "b"
>
> attr(DF,"foo") <- "bar"    # just adding an attribute sets NAM(2) ?
> .Internal(inspect(DF))
@25149e0 19 VECSXP g0c1 [NAM(2),ATT] (len=2, tl=0)
  @263ea50 13 INTSXP g0c2 [] (len=3, tl=0) 1,2,3
  @263eaa0 13 INTSXP g0c2 [] (len=3, tl=0) 4,5,6
ATTRIB:
  @2457984 02 LISTSXP g0c0 []
    TAG: @3f2120 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
    @25149c0 16 STRSXP g0c1 [] (len=2, tl=0)
      @1e987d8 09 CHARSXP g0c1 [MARK,gp=0x21] "a"
      @1e56948 09 CHARSXP g0c1 [MARK,gp=0x21] "b"
    TAG: @245732c 01 SYMSXP g0c0 [] "foo"
    @25148a0 16 STRSXP g0c1 [NAM(1)] (len=1, tl=0)
      @2514920 09 CHARSXP g0c1 [gp=0x20] "bar"


Matthew


> --
> Peter Dalgaard, Professor
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>


From simon.urbanek at r-project.org  Thu Nov 24 15:21:33 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 24 Nov 2011 09:21:33 -0500
Subject: [Rd] capture.output(eval(...,
	envir)) not evaluate in the expected(?) environment
In-Reply-To: <CAFDcVCR5r=jiEDV-Ga5PYrLDwvmd8oW59VKdG1R5moTKq6KfqQ@mail.gmail.com>
References: <CAFDcVCS=OPW_HYfh9BM_ddaXQdLv6hSiD6Bd==pois8jYEc6wg@mail.gmail.com>
	<62B71EB4-EAE3-40BA-BB29-769E9C4C1A2D@r-project.org>
	<CAFDcVCR5r=jiEDV-Ga5PYrLDwvmd8oW59VKdG1R5moTKq6KfqQ@mail.gmail.com>
Message-ID: <CA55943D-D720-4114-B509-AE271D9231CA@r-project.org>


On Nov 23, 2011, at 11:06 PM, Henrik Bengtsson wrote:

> Thanks for the quick answer.  I didn't know about force() function.
> 

It doesn't matter how you force the argument, anything - e.g. if(is.environment(envir)) capture.output(...) would do - I used force() just to make the point that it is what is causing it.

A more simple example illustrating what happens here:

> f = function(e=parent.frame()) local(print(e))
> f()
<environment: 0x102f1f470>

> f = function(e=parent.frame()) { force(e); local(print(e)) }
> f()
<environment: R_GlobalEnv>

> f = function(e=parent.frame()) if (is.environment(e)) local(print(e))
> f()
<environment: R_GlobalEnv>

Cheers,
Simon


> Cheers,
> 
> Henrik
> 
> On Wed, Nov 23, 2011 at 6:56 PM, Simon Urbanek
> <simon.urbanek at r-project.org> wrote:
>> IMHO this has nothing to do with capture.output() per se - it's simply lazy evaluation that gets you. Add force(envir) before capture.output and it works as you expected - the parent.frame() will be different inside capture.output than outside.
>> 
>> Cheers,
>> Simon
>> 
>> 
>> On Nov 23, 2011, at 9:36 PM, Henrik Bengtsson wrote:
>> 
>>> I've noticed the following oddity where capture.output() prevents
>>> eval() from evaluating an expression in the specified environment.
>>> I'm not sure if it is an undocumented feature or a bug.  It caused me
>>> many hours of troubleshooting.  By posting it here, it might save
>>> someone else from doing the same exercise.
>>> 
>>> Start by defining foo() which evaluates an expression locally in a
>>> given environment and catches the output via capture.output():
>>> 
>>> foo <- function(..., envir=parent.frame()) {
>>>  capture.output({
>>>    eval(substitute({x <- 1}), envir=envir)
>>>  })
>>> } # foo()
>>> 
>>> Then call:
>>> 
>>>> suppressWarnings(rm(x)); foo(envir=globalenv()); print(x);
>>> character(0)
>>> [1] 1
>>> 
>>> This works as expected.  However, if argument 'envir' is not specified
>>> explicitly, you get:
>>> 
>>>> suppressWarnings(rm(x)); foo(); str(x);
>>> character(0)
>>> Error in str(x) : object 'x' not found
>>> 
>>> which shows that the internal expression of foo() is *not* evaluated
>>> in the parent.frame(), i.e. the caller of foo(), which here should be
>>> globalenv().   It appears that capture.output() prevents this, because
>>> by dropping the latter:
>>> 
>>> foo <- function(..., envir=parent.frame()) {
>>>  eval(substitute({x <- 1}), envir=envir)
>>> } # foo()
>>> 
>>> it works:
>>> 
>>>> suppressWarnings(rm(x)); foo(); str(x);
>>> [1] 1
>>> 
>>> The workaround when still using capture.output() is to force an
>>> explicit evaluation of argument 'envir' inside of foo() before:
>>> 
>>> foo <- function(..., envir=parent.frame()) {
>>>  stopifnot(is.environment(envir))  # Workaround
>>>  capture.output({
>>>    eval(substitute({x <- 1}), envir=envir)
>>>  })
>>> } # foo()
>>> 
>>> which gives:
>>>> suppressWarnings(rm(x)); foo(); str(x);
>>> character(0)
>>> num 1
>>> 
>>> This occurs with R v2.14.0 patched and R devel:
>>> 
>>>> sessionInfo()
>>> R version 2.14.0 Patched (2011-11-20 r57720)
>>> Platform: x86_64-pc-mingw32/x64 (64-bit)
>>> 
>>> locale:
>>> [1] LC_COLLATE=English_United States.1252
>>> [2] LC_CTYPE=English_United States.1252
>>> [3] LC_MONETARY=English_United States.1252
>>> [4] LC_NUMERIC=C
>>> [5] LC_TIME=English_United States.1252
>>> 
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>> 
>>>> sessionInfo()
>>> R Under development (unstable) (2011-11-20 r57720)
>>> Platform: x86_64-pc-mingw32/x64 (64-bit)
>>> 
>>> locale:
>>> [1] LC_COLLATE=English_United States.1252
>>> [2] LC_CTYPE=English_United States.1252
>>> [3] LC_MONETARY=English_United States.1252
>>> [4] LC_NUMERIC=C
>>> [5] LC_TIME=English_United States.1252
>>> 
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>> 
>>> /Henrik
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>> 
>> 
>> 
> 
> 


From pdalgd at gmail.com  Thu Nov 24 15:45:38 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 24 Nov 2011 15:45:38 +0100
Subject: [Rd] Confused about NAMED
In-Reply-To: <0feab74fdda903967fff2f6868d8cf75.squirrel@webmail.plus.net>
References: <719cbc60d789ea0d3bf1d6a18309a216.squirrel@webmail.plus.net>
	<090530A4-BBC5-48B3-9EC0-2D965C200729@gmail.com>
	<2573e1d2e510477135f6246e60d53aef.squirrel@webmail.plus.net>
	<A46434F9-309A-4D83-A5F1-54472DE36FDE@gmail.com>
	<0feab74fdda903967fff2f6868d8cf75.squirrel@webmail.plus.net>
Message-ID: <4372BFDD-E75E-4459-B662-534D5521979C@gmail.com>


On Nov 24, 2011, at 14:05 , Matthew Dowle wrote:

> Since list() is primitive I tried to construct a data.frame starting with
> list() [since structure() isn't primitive], but then merely adding an
> attribute seems to set NAMED==2 too ?

Yes. As soon as there is the slightest risk of having (had) two references to the same object NAMED==2 and it is never reduced. While your mind is boggling, I might boggle it a bit more:

> z <- 1:10
> .Internal(inspect(z))
@116e11788 13 INTSXP g0c4 [NAM(1)] (len=10, tl=0) 1,2,3,4,5,...
> m <- mean(z)
> .Internal(inspect(z))
@116e11788 13 INTSXP g0c4 [NAM(2)] (len=10, tl=0) 1,2,3,4,5,...

This happens because while mean() is running, there is a second reference to z, namely mean's argument x. (With languages like R, you have no insurance that there will be no changes to the global environment while a function call is being evaluated, so bugs can bite in both places -- z or x.)

There are many of these cases where you might pragmatically want to override the default NAMED logic, but you'd be stepping into treacherous waters. Luke has probably been giving these matters quite some thought in connection with his compiler project.

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From mdowle at mdowle.plus.com  Thu Nov 24 16:56:45 2011
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Thu, 24 Nov 2011 15:56:45 -0000
Subject: [Rd] Confused about NAMED
In-Reply-To: <4372BFDD-E75E-4459-B662-534D5521979C@gmail.com>
References: <719cbc60d789ea0d3bf1d6a18309a216.squirrel@webmail.plus.net>
	<090530A4-BBC5-48B3-9EC0-2D965C200729@gmail.com>
	<2573e1d2e510477135f6246e60d53aef.squirrel@webmail.plus.net>
	<A46434F9-309A-4D83-A5F1-54472DE36FDE@gmail.com>
	<0feab74fdda903967fff2f6868d8cf75.squirrel@webmail.plus.net>
	<4372BFDD-E75E-4459-B662-534D5521979C@gmail.com>
Message-ID: <7a32d6c690bcb77862375b2791888047.squirrel@webmail.plus.net>

>
> On Nov 24, 2011, at 14:05 , Matthew Dowle wrote:
>
>> Since list() is primitive I tried to construct a data.frame starting
>> with
>> list() [since structure() isn't primitive], but then merely adding an
>> attribute seems to set NAMED==2 too ?
>
> Yes. As soon as there is the slightest risk of having (had) two references
> to the same object NAMED==2 and it is never reduced. While your mind is
> boggling, I might boggle it a bit more:
>
>> z <- 1:10
>> .Internal(inspect(z))
> @116e11788 13 INTSXP g0c4 [NAM(1)] (len=10, tl=0) 1,2,3,4,5,...
>> m <- mean(z)
>> .Internal(inspect(z))
> @116e11788 13 INTSXP g0c4 [NAM(2)] (len=10, tl=0) 1,2,3,4,5,...
>
> This happens because while mean() is running, there is a second reference
> to z, namely mean's argument x. (With languages like R, you have no
> insurance that there will be no changes to the global environment while a
> function call is being evaluated, so bugs can bite in both places -- z or
> x.)
>
> There are many of these cases where you might pragmatically want to
> override the default NAMED logic, but you'd be stepping into treacherous
> waters. Luke has probably been giving these matters quite some thought in
> connection with his compiler project.

Ok, very interesting. Think I'm there.
Thanks for all the info.

Matthew


From simon.urbanek at r-project.org  Thu Nov 24 18:11:19 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 24 Nov 2011 12:11:19 -0500
Subject: [Rd] Confused about NAMED
In-Reply-To: <0feab74fdda903967fff2f6868d8cf75.squirrel@webmail.plus.net>
References: <719cbc60d789ea0d3bf1d6a18309a216.squirrel@webmail.plus.net>
	<090530A4-BBC5-48B3-9EC0-2D965C200729@gmail.com>
	<2573e1d2e510477135f6246e60d53aef.squirrel@webmail.plus.net>
	<A46434F9-309A-4D83-A5F1-54472DE36FDE@gmail.com>
	<0feab74fdda903967fff2f6868d8cf75.squirrel@webmail.plus.net>
Message-ID: <6377C1B0-6D16-4EE1-A86A-7B0EA353BF41@r-project.org>


On Nov 24, 2011, at 8:05 AM, Matthew Dowle wrote:

>> 
>> On Nov 24, 2011, at 12:34 , Matthew Dowle wrote:
>> 
>>>> 
>>>> On Nov 24, 2011, at 11:13 , Matthew Dowle wrote:
>>>> 
>>>>> Hi,
>>>>> 
>>>>> I expected NAMED to be 1 in all these three cases. It is for one of
>>>>> them,
>>>>> but not the other two?
>>>>> 
>>>>>> R --vanilla
>>>>> R version 2.14.0 (2011-10-31)
>>>>> Platform: i386-pc-mingw32/i386 (32-bit)
>>>>> 
>>>>>> x = 1L
>>>>>> .Internal(inspect(x))   # why NAM(2)? expected NAM(1)
>>>>> @2514aa0 13 INTSXP g0c1 [NAM(2)] (len=1, tl=0) 1
>>>>> 
>>>>>> y = 1:10
>>>>>> .Internal(inspect(y))   # NAM(1) as expected but why different to x?
>>>>> @272f788 13 INTSXP g0c4 [NAM(1)] (len=10, tl=0) 1,2,3,4,5,...
>>>>> 
>>>>>> z = data.frame()
>>>>>> .Internal(inspect(z))   # why NAM(2)? expected NAM(1)
>>>>> @24fc28c 19 VECSXP g0c0 [OBJ,NAM(2),ATT] (len=0, tl=0)
>>>>> ATTRIB:
>>>>> @24fc270 02 LISTSXP g0c0 []
>>>>>  TAG: @3f2120 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
>>>>>  @24fc334 16 STRSXP g0c0 [] (len=0, tl=0)
>>>>>  TAG: @3f2040 01 SYMSXP g0c0 [MARK,gp=0x4000] "row.names"
>>>>>  @24fc318 13 INTSXP g0c0 [] (len=0, tl=0)
>>>>>  TAG: @3f2388 01 SYMSXP g0c0 [MARK,gp=0x4000] "class"
>>>>>  @25be500 16 STRSXP g0c1 [] (len=1, tl=0)
>>>>>    @1d38af0 09 CHARSXP g0c2 [MARK,gp=0x21,ATT] "data.frame"
>>>>> 
>>>>> It's a little difficult to search for the word "named" but I tried and
>>>>> found this in R-ints :
>>>>> 
>>>>>  "Note that optimizing NAMED = 1 is only effective within a primitive
>>>>> (as the closure wrapper of a .Internal will set NAMED = 2 when the
>>>>> promise to the argument is evaluated)"
>>>>> 
>>>>> So might it be that just looking at NAMED using .Internal(inspect())
>>>>> is
>>>>> setting NAMED=2?  But if so, why does y have NAMED==1?
>>>> 
>>>> This is tricky business... I'm not quite sure I'll get it right, but
>>>> let's
>>>> try
>>>> 
>>>> When you are assigning a constant, the value you assign is already part
>>>> of
>>>> the assignment expression, so if you want to modify it, you must
>>>> duplicate. So NAMED==2 on z <- 1 is basically to prevent you from
>>>> accidentally "changing the value of 1". If it weren't, then you could
>>>> get
>>>> bitten by code like for(i in 1:2) {z <- 1; if(i==1) z[1] <- 2}.
>>>> 
>>>> If you're assigning the result of a computation, then the object only
>>>> exists once, so
>>>> z <- 0+1  gets NAMED==1.
>>>> 
>>>> However, if the computation is done by returning a named value from
>>>> within
>>>> a function, as in
>>>> 
>>>>> f <- function(){v <- 1+0; v}
>>>>> z <- f()
>>>> 
>>>> then again NAMED==2. This is because the side effects of the function
>>>> _might_ result in something having a hold on the function environment,
>>>> e.g. if we had
>>>> 
>>>> e <- NULL
>>>> f <- function(){e <<-environment(); v <- 1+0; v}
>>>> z <- f()
>>>> 
>>>> then z[1] <- 5 would change e$v too. As it happens, there aren't any
>>>> side
>>>> effects in the forme case, but R loses track and assumes the worst.
>>>> 
>>> 
>>> Thanks a lot, think I follow. That explains x vs y, but why is z
>>> NAMED==2?
>>> The result of data.frame() is an object that exists once (similar to
>>> 1:10)
>>> so shouldn't it be NAMED==1 too?  Or, R loses track and assumes the
>>> worst
>>> even on its own functions such as data.frame()?
>> 
>> R loses track. I suspect that is really all it can do without actual
>> reference counting. The function data.frame is more than 150 lines of
>> code, and if any of those end up invoking user code, possibly via a class
>> method, you can't tell definitively whether or not the evaluation
>> environment dies at the return.
> 
> Ohhh, think I see now. After Duncan's reply I was going to ask if it was
> possible to change data.frame() to be primitive so it could set NAMED=1.
> But it seems primitive functions can't use R code so data.frame() would
> need to be ported to C. Ok! - not quick or easy, and not without
> consideable risk. And, data.frame() can invoke user code inside it anyway
> then.
> 
> Since list() is primitive I tried to construct a data.frame starting with
> list() [since structure() isn't primitive], but then merely adding an
> attribute seems to set NAMED==2 too ?
> 

Yes, because attr(x,y) <- z is the same as

`*tmp*` <- x
x <- `attr<-`(`*tmp*`, y, z)
rm(`*tmp*`)

so there are two references to the data frame: one in DF and one in `*tmp*`. It is the first line that causes the NAMED bump. And, yes, it's real:

> `f<-`=function(x,value) { print(ls(parent.frame())); x<-value }
> x=1
> f(x)=1
[1] "*tmp*" "f<-"   "x"    

You could skip that by using the function directly (I don't think it's recommended, though):

> .Internal(inspect(l <- list(a=1)))
@1028c82f8 19 VECSXP g0c1 [NAM(1),ATT] (len=1, tl=0)
  @1028c8268 14 REALSXP g0c1 [] (len=1, tl=0) 1
ATTRIB:
  @100b6e748 02 LISTSXP g0c0 [] 
    TAG: @100843878 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
    @1028c82c8 16 STRSXP g0c1 [] (len=1, tl=0)
      @1009cd388 09 CHARSXP g0c1 [MARK,gp=0x21] "a"
> .Internal(inspect(`names<-`(l, "b")))
@1028c82f8 19 VECSXP g0c1 [NAM(1),ATT] (len=1, tl=0)
  @1028c8268 14 REALSXP g0c1 [] (len=1, tl=0) 1
ATTRIB:
  @100b6e748 02 LISTSXP g0c0 [] 
    TAG: @100843878 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
    @1028c8178 16 STRSXP g0c1 [NAM(1)] (len=1, tl=0)
      @100967af8 09 CHARSXP g0c1 [MARK,gp=0x20] "b"
> .Internal(inspect(l))
@1028c82f8 19 VECSXP g0c1 [NAM(1),ATT] (len=1, tl=0)
  @1028c8268 14 REALSXP g0c1 [] (len=1, tl=0) 1
ATTRIB:
  @100b6e748 02 LISTSXP g0c0 [] 
    TAG: @100843878 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
    @1028c8178 16 STRSXP g0c1 [NAM(1)] (len=1, tl=0)
      @100967af8 09 CHARSXP g0c1 [MARK,gp=0x20] "b"

Cheers,
Simon



>> DF = list(a=1:3,b=4:6)
>> .Internal(inspect(DF))     # so far so good: NAM(1)
> @25149e0 19 VECSXP g0c1 [NAM(1),ATT] (len=2, tl=0)
>  @263ea50 13 INTSXP g0c2 [] (len=3, tl=0) 1,2,3
>  @263eaa0 13 INTSXP g0c2 [] (len=3, tl=0) 4,5,6
> ATTRIB:
>  @2457984 02 LISTSXP g0c0 []
>    TAG: @3f2120 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
>    @25149c0 16 STRSXP g0c1 [] (len=2, tl=0)
>      @1e987d8 09 CHARSXP g0c1 [MARK,gp=0x21] "a"
>      @1e56948 09 CHARSXP g0c1 [MARK,gp=0x21] "b"
>> 
>> attr(DF,"foo") <- "bar"    # just adding an attribute sets NAM(2) ?
>> .Internal(inspect(DF))
> @25149e0 19 VECSXP g0c1 [NAM(2),ATT] (len=2, tl=0)
>  @263ea50 13 INTSXP g0c2 [] (len=3, tl=0) 1,2,3
>  @263eaa0 13 INTSXP g0c2 [] (len=3, tl=0) 4,5,6
> ATTRIB:
>  @2457984 02 LISTSXP g0c0 []
>    TAG: @3f2120 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
>    @25149c0 16 STRSXP g0c1 [] (len=2, tl=0)
>      @1e987d8 09 CHARSXP g0c1 [MARK,gp=0x21] "a"
>      @1e56948 09 CHARSXP g0c1 [MARK,gp=0x21] "b"
>    TAG: @245732c 01 SYMSXP g0c0 [] "foo"
>    @25148a0 16 STRSXP g0c1 [NAM(1)] (len=1, tl=0)
>      @2514920 09 CHARSXP g0c1 [gp=0x20] "bar"
> 
> 
> Matthew
> 
> 
>> --
>> Peter Dalgaard, Professor
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>> 
>> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From luke-tierney at uiowa.edu  Thu Nov 24 19:16:44 2011
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Thu, 24 Nov 2011 12:16:44 -0600
Subject: [Rd] Confused about NAMED
In-Reply-To: <6377C1B0-6D16-4EE1-A86A-7B0EA353BF41@r-project.org>
References: <719cbc60d789ea0d3bf1d6a18309a216.squirrel@webmail.plus.net>
	<090530A4-BBC5-48B3-9EC0-2D965C200729@gmail.com>
	<2573e1d2e510477135f6246e60d53aef.squirrel@webmail.plus.net>
	<A46434F9-309A-4D83-A5F1-54472DE36FDE@gmail.com>
	<0feab74fdda903967fff2f6868d8cf75.squirrel@webmail.plus.net>
	<6377C1B0-6D16-4EE1-A86A-7B0EA353BF41@r-project.org>
Message-ID: <alpine.OSX.2.02.1111241209560.8637@lukes-macbook-air.local>

The details of complex assignment expressions are fairly intricate.  I
wrote up some notes ont his a couple of months back and have meant to
get them into the internals manual but have not gotten around to it
yet.  I'll see if I can get to it in the next week or two and will
send a note to this thread wehen I do. In terms of the issues
discussed so far

   Calling a foo<- function directly is not a good idea unless you
   really undestand what is going on in the assignment mechanism in
   general and in the particular foo<- function. It is definitely not
   something to be done in routine programming unless you like
   unpleasant surprises.

   attr<- could probably be modified to avine the NAMED increment in
   this example, but I'd want to think that through fairly carefully
   before making such a change.  (Most foo<- functions that are
   primitives are written to that they avoid a NAMED increment when
   used in an assignment expression, but a few are not -- I believe
   these are almost all, maybe even all, oversights, but again I
   wouldn't want to make any changes without ceareful review.)

Best,

luke

On Thu, 24 Nov 2011, Simon Urbanek wrote:

>
> On Nov 24, 2011, at 8:05 AM, Matthew Dowle wrote:
>
>>>
>>> On Nov 24, 2011, at 12:34 , Matthew Dowle wrote:
>>>
>>>>>
>>>>> On Nov 24, 2011, at 11:13 , Matthew Dowle wrote:
>>>>>
>>>>>> Hi,
>>>>>>
>>>>>> I expected NAMED to be 1 in all these three cases. It is for one of
>>>>>> them,
>>>>>> but not the other two?
>>>>>>
>>>>>>> R --vanilla
>>>>>> R version 2.14.0 (2011-10-31)
>>>>>> Platform: i386-pc-mingw32/i386 (32-bit)
>>>>>>
>>>>>>> x = 1L
>>>>>>> .Internal(inspect(x))   # why NAM(2)? expected NAM(1)
>>>>>> @2514aa0 13 INTSXP g0c1 [NAM(2)] (len=1, tl=0) 1
>>>>>>
>>>>>>> y = 1:10
>>>>>>> .Internal(inspect(y))   # NAM(1) as expected but why different to x?
>>>>>> @272f788 13 INTSXP g0c4 [NAM(1)] (len=10, tl=0) 1,2,3,4,5,...
>>>>>>
>>>>>>> z = data.frame()
>>>>>>> .Internal(inspect(z))   # why NAM(2)? expected NAM(1)
>>>>>> @24fc28c 19 VECSXP g0c0 [OBJ,NAM(2),ATT] (len=0, tl=0)
>>>>>> ATTRIB:
>>>>>> @24fc270 02 LISTSXP g0c0 []
>>>>>>  TAG: @3f2120 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
>>>>>>  @24fc334 16 STRSXP g0c0 [] (len=0, tl=0)
>>>>>>  TAG: @3f2040 01 SYMSXP g0c0 [MARK,gp=0x4000] "row.names"
>>>>>>  @24fc318 13 INTSXP g0c0 [] (len=0, tl=0)
>>>>>>  TAG: @3f2388 01 SYMSXP g0c0 [MARK,gp=0x4000] "class"
>>>>>>  @25be500 16 STRSXP g0c1 [] (len=1, tl=0)
>>>>>>    @1d38af0 09 CHARSXP g0c2 [MARK,gp=0x21,ATT] "data.frame"
>>>>>>
>>>>>> It's a little difficult to search for the word "named" but I tried and
>>>>>> found this in R-ints :
>>>>>>
>>>>>>  "Note that optimizing NAMED = 1 is only effective within a primitive
>>>>>> (as the closure wrapper of a .Internal will set NAMED = 2 when the
>>>>>> promise to the argument is evaluated)"
>>>>>>
>>>>>> So might it be that just looking at NAMED using .Internal(inspect())
>>>>>> is
>>>>>> setting NAMED=2?  But if so, why does y have NAMED==1?
>>>>>
>>>>> This is tricky business... I'm not quite sure I'll get it right, but
>>>>> let's
>>>>> try
>>>>>
>>>>> When you are assigning a constant, the value you assign is already part
>>>>> of
>>>>> the assignment expression, so if you want to modify it, you must
>>>>> duplicate. So NAMED==2 on z <- 1 is basically to prevent you from
>>>>> accidentally "changing the value of 1". If it weren't, then you could
>>>>> get
>>>>> bitten by code like for(i in 1:2) {z <- 1; if(i==1) z[1] <- 2}.
>>>>>
>>>>> If you're assigning the result of a computation, then the object only
>>>>> exists once, so
>>>>> z <- 0+1  gets NAMED==1.
>>>>>
>>>>> However, if the computation is done by returning a named value from
>>>>> within
>>>>> a function, as in
>>>>>
>>>>>> f <- function(){v <- 1+0; v}
>>>>>> z <- f()
>>>>>
>>>>> then again NAMED==2. This is because the side effects of the function
>>>>> _might_ result in something having a hold on the function environment,
>>>>> e.g. if we had
>>>>>
>>>>> e <- NULL
>>>>> f <- function(){e <<-environment(); v <- 1+0; v}
>>>>> z <- f()
>>>>>
>>>>> then z[1] <- 5 would change e$v too. As it happens, there aren't any
>>>>> side
>>>>> effects in the forme case, but R loses track and assumes the worst.
>>>>>
>>>>
>>>> Thanks a lot, think I follow. That explains x vs y, but why is z
>>>> NAMED==2?
>>>> The result of data.frame() is an object that exists once (similar to
>>>> 1:10)
>>>> so shouldn't it be NAMED==1 too?  Or, R loses track and assumes the
>>>> worst
>>>> even on its own functions such as data.frame()?
>>>
>>> R loses track. I suspect that is really all it can do without actual
>>> reference counting. The function data.frame is more than 150 lines of
>>> code, and if any of those end up invoking user code, possibly via a class
>>> method, you can't tell definitively whether or not the evaluation
>>> environment dies at the return.
>>
>> Ohhh, think I see now. After Duncan's reply I was going to ask if it was
>> possible to change data.frame() to be primitive so it could set NAMED=1.
>> But it seems primitive functions can't use R code so data.frame() would
>> need to be ported to C. Ok! - not quick or easy, and not without
>> consideable risk. And, data.frame() can invoke user code inside it anyway
>> then.
>>
>> Since list() is primitive I tried to construct a data.frame starting with
>> list() [since structure() isn't primitive], but then merely adding an
>> attribute seems to set NAMED==2 too ?
>>
>
> Yes, because attr(x,y) <- z is the same as
>
> `*tmp*` <- x
> x <- `attr<-`(`*tmp*`, y, z)
> rm(`*tmp*`)
>
> so there are two references to the data frame: one in DF and one in `*tmp*`. It is the first line that causes the NAMED bump. And, yes, it's real:
>
>> `f<-`=function(x,value) { print(ls(parent.frame())); x<-value }
>> x=1
>> f(x)=1
> [1] "*tmp*" "f<-"   "x"
>
> You could skip that by using the function directly (I don't think it's recommended, though):
>
>> .Internal(inspect(l <- list(a=1)))
> @1028c82f8 19 VECSXP g0c1 [NAM(1),ATT] (len=1, tl=0)
>  @1028c8268 14 REALSXP g0c1 [] (len=1, tl=0) 1
> ATTRIB:
>  @100b6e748 02 LISTSXP g0c0 []
>    TAG: @100843878 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
>    @1028c82c8 16 STRSXP g0c1 [] (len=1, tl=0)
>      @1009cd388 09 CHARSXP g0c1 [MARK,gp=0x21] "a"
>> .Internal(inspect(`names<-`(l, "b")))
> @1028c82f8 19 VECSXP g0c1 [NAM(1),ATT] (len=1, tl=0)
>  @1028c8268 14 REALSXP g0c1 [] (len=1, tl=0) 1
> ATTRIB:
>  @100b6e748 02 LISTSXP g0c0 []
>    TAG: @100843878 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
>    @1028c8178 16 STRSXP g0c1 [NAM(1)] (len=1, tl=0)
>      @100967af8 09 CHARSXP g0c1 [MARK,gp=0x20] "b"
>> .Internal(inspect(l))
> @1028c82f8 19 VECSXP g0c1 [NAM(1),ATT] (len=1, tl=0)
>  @1028c8268 14 REALSXP g0c1 [] (len=1, tl=0) 1
> ATTRIB:
>  @100b6e748 02 LISTSXP g0c0 []
>    TAG: @100843878 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
>    @1028c8178 16 STRSXP g0c1 [NAM(1)] (len=1, tl=0)
>      @100967af8 09 CHARSXP g0c1 [MARK,gp=0x20] "b"
>
> Cheers,
> Simon
>
>
>
>>> DF = list(a=1:3,b=4:6)
>>> .Internal(inspect(DF))     # so far so good: NAM(1)
>> @25149e0 19 VECSXP g0c1 [NAM(1),ATT] (len=2, tl=0)
>>  @263ea50 13 INTSXP g0c2 [] (len=3, tl=0) 1,2,3
>>  @263eaa0 13 INTSXP g0c2 [] (len=3, tl=0) 4,5,6
>> ATTRIB:
>>  @2457984 02 LISTSXP g0c0 []
>>    TAG: @3f2120 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
>>    @25149c0 16 STRSXP g0c1 [] (len=2, tl=0)
>>      @1e987d8 09 CHARSXP g0c1 [MARK,gp=0x21] "a"
>>      @1e56948 09 CHARSXP g0c1 [MARK,gp=0x21] "b"
>>>
>>> attr(DF,"foo") <- "bar"    # just adding an attribute sets NAM(2) ?
>>> .Internal(inspect(DF))
>> @25149e0 19 VECSXP g0c1 [NAM(2),ATT] (len=2, tl=0)
>>  @263ea50 13 INTSXP g0c2 [] (len=3, tl=0) 1,2,3
>>  @263eaa0 13 INTSXP g0c2 [] (len=3, tl=0) 4,5,6
>> ATTRIB:
>>  @2457984 02 LISTSXP g0c0 []
>>    TAG: @3f2120 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
>>    @25149c0 16 STRSXP g0c1 [] (len=2, tl=0)
>>      @1e987d8 09 CHARSXP g0c1 [MARK,gp=0x21] "a"
>>      @1e56948 09 CHARSXP g0c1 [MARK,gp=0x21] "b"
>>    TAG: @245732c 01 SYMSXP g0c0 [] "foo"
>>    @25148a0 16 STRSXP g0c1 [NAM(1)] (len=1, tl=0)
>>      @2514920 09 CHARSXP g0c1 [gp=0x20] "bar"
>>
>>
>> Matthew
>>
>>
>>> --
>>> Peter Dalgaard, Professor
>>> Center for Statistics, Copenhagen Business School
>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>> Phone: (+45)38153501
>>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>>
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From mdowle at mdowle.plus.com  Thu Nov 24 19:48:09 2011
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Thu, 24 Nov 2011 18:48:09 -0000
Subject: [Rd] Confused about NAMED
In-Reply-To: <6377C1B0-6D16-4EE1-A86A-7B0EA353BF41@r-project.org>
References: <719cbc60d789ea0d3bf1d6a18309a216.squirrel@webmail.plus.net>
	<090530A4-BBC5-48B3-9EC0-2D965C200729@gmail.com>
	<2573e1d2e510477135f6246e60d53aef.squirrel@webmail.plus.net>
	<A46434F9-309A-4D83-A5F1-54472DE36FDE@gmail.com>
	<0feab74fdda903967fff2f6868d8cf75.squirrel@webmail.plus.net>
	<6377C1B0-6D16-4EE1-A86A-7B0EA353BF41@r-project.org>
Message-ID: <6947729232d60e81d72f6a6074566ce2.squirrel@webmail.plus.net>

>
> On Nov 24, 2011, at 8:05 AM, Matthew Dowle wrote:
>
>>>
>>> On Nov 24, 2011, at 12:34 , Matthew Dowle wrote:
>>>
>>>>>
>>>>> On Nov 24, 2011, at 11:13 , Matthew Dowle wrote:
>>>>>
>>>>>> Hi,
>>>>>>
>>>>>> I expected NAMED to be 1 in all these three cases. It is for one of
>>>>>> them,
>>>>>> but not the other two?
>>>>>>
>>>>>>> R --vanilla
>>>>>> R version 2.14.0 (2011-10-31)
>>>>>> Platform: i386-pc-mingw32/i386 (32-bit)
>>>>>>
>>>>>>> x = 1L
>>>>>>> .Internal(inspect(x))   # why NAM(2)? expected NAM(1)
>>>>>> @2514aa0 13 INTSXP g0c1 [NAM(2)] (len=1, tl=0) 1
>>>>>>
>>>>>>> y = 1:10
>>>>>>> .Internal(inspect(y))   # NAM(1) as expected but why different to
>>>>>>> x?
>>>>>> @272f788 13 INTSXP g0c4 [NAM(1)] (len=10, tl=0) 1,2,3,4,5,...
>>>>>>
>>>>>>> z = data.frame()
>>>>>>> .Internal(inspect(z))   # why NAM(2)? expected NAM(1)
>>>>>> @24fc28c 19 VECSXP g0c0 [OBJ,NAM(2),ATT] (len=0, tl=0)
>>>>>> ATTRIB:
>>>>>> @24fc270 02 LISTSXP g0c0 []
>>>>>>  TAG: @3f2120 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
>>>>>>  @24fc334 16 STRSXP g0c0 [] (len=0, tl=0)
>>>>>>  TAG: @3f2040 01 SYMSXP g0c0 [MARK,gp=0x4000] "row.names"
>>>>>>  @24fc318 13 INTSXP g0c0 [] (len=0, tl=0)
>>>>>>  TAG: @3f2388 01 SYMSXP g0c0 [MARK,gp=0x4000] "class"
>>>>>>  @25be500 16 STRSXP g0c1 [] (len=1, tl=0)
>>>>>>    @1d38af0 09 CHARSXP g0c2 [MARK,gp=0x21,ATT] "data.frame"
>>>>>>
>>>>>> It's a little difficult to search for the word "named" but I tried
>>>>>> and
>>>>>> found this in R-ints :
>>>>>>
>>>>>>  "Note that optimizing NAMED = 1 is only effective within a
>>>>>> primitive
>>>>>> (as the closure wrapper of a .Internal will set NAMED = 2 when the
>>>>>> promise to the argument is evaluated)"
>>>>>>
>>>>>> So might it be that just looking at NAMED using .Internal(inspect())
>>>>>> is
>>>>>> setting NAMED=2?  But if so, why does y have NAMED==1?
>>>>>
>>>>> This is tricky business... I'm not quite sure I'll get it right, but
>>>>> let's
>>>>> try
>>>>>
>>>>> When you are assigning a constant, the value you assign is already
>>>>> part
>>>>> of
>>>>> the assignment expression, so if you want to modify it, you must
>>>>> duplicate. So NAMED==2 on z <- 1 is basically to prevent you from
>>>>> accidentally "changing the value of 1". If it weren't, then you could
>>>>> get
>>>>> bitten by code like for(i in 1:2) {z <- 1; if(i==1) z[1] <- 2}.
>>>>>
>>>>> If you're assigning the result of a computation, then the object only
>>>>> exists once, so
>>>>> z <- 0+1  gets NAMED==1.
>>>>>
>>>>> However, if the computation is done by returning a named value from
>>>>> within
>>>>> a function, as in
>>>>>
>>>>>> f <- function(){v <- 1+0; v}
>>>>>> z <- f()
>>>>>
>>>>> then again NAMED==2. This is because the side effects of the function
>>>>> _might_ result in something having a hold on the function
>>>>> environment,
>>>>> e.g. if we had
>>>>>
>>>>> e <- NULL
>>>>> f <- function(){e <<-environment(); v <- 1+0; v}
>>>>> z <- f()
>>>>>
>>>>> then z[1] <- 5 would change e$v too. As it happens, there aren't any
>>>>> side
>>>>> effects in the forme case, but R loses track and assumes the worst.
>>>>>
>>>>
>>>> Thanks a lot, think I follow. That explains x vs y, but why is z
>>>> NAMED==2?
>>>> The result of data.frame() is an object that exists once (similar to
>>>> 1:10)
>>>> so shouldn't it be NAMED==1 too?  Or, R loses track and assumes the
>>>> worst
>>>> even on its own functions such as data.frame()?
>>>
>>> R loses track. I suspect that is really all it can do without actual
>>> reference counting. The function data.frame is more than 150 lines of
>>> code, and if any of those end up invoking user code, possibly via a
>>> class
>>> method, you can't tell definitively whether or not the evaluation
>>> environment dies at the return.
>>
>> Ohhh, think I see now. After Duncan's reply I was going to ask if it was
>> possible to change data.frame() to be primitive so it could set NAMED=1.
>> But it seems primitive functions can't use R code so data.frame() would
>> need to be ported to C. Ok! - not quick or easy, and not without
>> consideable risk. And, data.frame() can invoke user code inside it
>> anyway
>> then.
>>
>> Since list() is primitive I tried to construct a data.frame starting
>> with
>> list() [since structure() isn't primitive], but then merely adding an
>> attribute seems to set NAMED==2 too ?
>>
>
> Yes, because attr(x,y) <- z is the same as
>
> `*tmp*` <- x
> x <- `attr<-`(`*tmp*`, y, z)
> rm(`*tmp*`)
>
> so there are two references to the data frame: one in DF and one in
> `*tmp*`. It is the first line that causes the NAMED bump. And, yes, it's
> real:
>
>> `f<-`=function(x,value) { print(ls(parent.frame())); x<-value }
>> x=1
>> f(x)=1
> [1] "*tmp*" "f<-"   "x"
>
> You could skip that by using the function directly (I don't think it's
> recommended, though):
>
>> .Internal(inspect(l <- list(a=1)))
> @1028c82f8 19 VECSXP g0c1 [NAM(1),ATT] (len=1, tl=0)
>   @1028c8268 14 REALSXP g0c1 [] (len=1, tl=0) 1
> ATTRIB:
>   @100b6e748 02 LISTSXP g0c0 []
>     TAG: @100843878 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
>     @1028c82c8 16 STRSXP g0c1 [] (len=1, tl=0)
>       @1009cd388 09 CHARSXP g0c1 [MARK,gp=0x21] "a"
>> .Internal(inspect(`names<-`(l, "b")))
> @1028c82f8 19 VECSXP g0c1 [NAM(1),ATT] (len=1, tl=0)
>   @1028c8268 14 REALSXP g0c1 [] (len=1, tl=0) 1
> ATTRIB:
>   @100b6e748 02 LISTSXP g0c0 []
>     TAG: @100843878 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
>     @1028c8178 16 STRSXP g0c1 [NAM(1)] (len=1, tl=0)
>       @100967af8 09 CHARSXP g0c1 [MARK,gp=0x20] "b"
>> .Internal(inspect(l))
> @1028c82f8 19 VECSXP g0c1 [NAM(1),ATT] (len=1, tl=0)
>   @1028c8268 14 REALSXP g0c1 [] (len=1, tl=0) 1
> ATTRIB:
>   @100b6e748 02 LISTSXP g0c0 []
>     TAG: @100843878 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
>     @1028c8178 16 STRSXP g0c1 [NAM(1)] (len=1, tl=0)
>       @100967af8 09 CHARSXP g0c1 [MARK,gp=0x20] "b"
>

Interesting, I tried it. I found that setting the "row.names" attribute
that way keeps NAMED==1 ok, and that setting "class" attribute keeps
NAMED==1 ok too. Fantastic! But, it seems that merely printing it on the
console (when the class is set) bumps NAMED to 2. Here is the output :

> DF = list(a=1:3,b=4:6)
> `attr<-`(DF,"row.names",.set_row_names(3))
$a
[1] 1 2 3

$b
[1] 4 5 6

attr(,"row.names")
[1] 1 2 3
> .Internal(inspect(DF))    # great, NAM(1)
@261e730 19 VECSXP g0c1 [NAM(1),ATT] (len=2, tl=0)
  @2abd088 13 INTSXP g0c2 [] (len=3, tl=0) 1,2,3
  @2abd060 13 INTSXP g0c2 [] (len=3, tl=0) 4,5,6
ATTRIB:
  @258d4f4 02 LISTSXP g0c0 []
    TAG: @1612120 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
    @261e710 16 STRSXP g0c1 [NAM(2)] (len=2, tl=0)
      @17a86f8 09 CHARSXP g0c1 [MARK,gp=0x21] "a"
      @1766868 09 CHARSXP g0c1 [MARK,gp=0x21] "b"
    TAG: @1612040 01 SYMSXP g0c0 [MARK,gp=0x4000] "row.names"
    @261e5d0 13 INTSXP g0c1 [NAM(2)] (len=2, tl=0) -2147483648,-3
> .Internal(inspect(`attr<-`(DF,"class","data.frame")))
@261e730 19 VECSXP g0c1 [OBJ,NAM(1),ATT] (len=2, tl=0)  # great, NAM(1)
  @2abd088 13 INTSXP g0c2 [] (len=3, tl=0) 1,2,3
  @2abd060 13 INTSXP g0c2 [] (len=3, tl=0) 4,5,6
ATTRIB:
  @258d4f4 02 LISTSXP g0c0 []
    TAG: @1612120 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
    @261e710 16 STRSXP g0c1 [NAM(2)] (len=2, tl=0)
      @17a86f8 09 CHARSXP g0c1 [MARK,gp=0x21] "a"
      @1766868 09 CHARSXP g0c1 [MARK,gp=0x21] "b"
    TAG: @1612040 01 SYMSXP g0c0 [MARK,gp=0x4000] "row.names"
    @261e5d0 13 INTSXP g0c1 [NAM(2)] (len=2, tl=0) -2147483648,-3
    TAG: @1612388 01 SYMSXP g0c0 [MARK,gp=0x4000] "class"
    @2a758e8 16 STRSXP g0c1 [NAM(1)] (len=1, tl=0)
      @1647f38 09 CHARSXP g0c2 [MARK,gp=0x21,ATT] "data.frame"
> .Internal(inspect(DF))         # Great, NAM(1) still
@261e730 19 VECSXP g0c1 [OBJ,NAM(1),ATT] (len=2, tl=0)
  @2abd088 13 INTSXP g0c2 [] (len=3, tl=0) 1,2,3
  @2abd060 13 INTSXP g0c2 [] (len=3, tl=0) 4,5,6
ATTRIB:
  @258d4f4 02 LISTSXP g0c0 []
    TAG: @1612120 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
    @261e710 16 STRSXP g0c1 [NAM(2)] (len=2, tl=0)
      @17a86f8 09 CHARSXP g0c1 [MARK,gp=0x21] "a"
      @1766868 09 CHARSXP g0c1 [MARK,gp=0x21] "b"
    TAG: @1612040 01 SYMSXP g0c0 [MARK,gp=0x4000] "row.names"
    @261e5d0 13 INTSXP g0c1 [NAM(2)] (len=2, tl=0) -2147483648,-3
    TAG: @1612388 01 SYMSXP g0c0 [MARK,gp=0x4000] "class"
    @2a758e8 16 STRSXP g0c1 [NAM(1)] (len=1, tl=0)
      @1647f38 09 CHARSXP g0c2 [MARK,gp=0x21,ATT] "data.frame"
> DF
  a b
1 1 4
2 2 5
3 3 6
> .Internal(inspect(DF))  # just looking at it changes NAMED to 2 ?
@261e730 19 VECSXP g0c1 [OBJ,MARK,NAM(2),ATT] (len=2, tl=0)
  @2abd088 13 INTSXP g0c2 [MARK,NAM(2)] (len=3, tl=0) 1,2,3
  @2abd060 13 INTSXP g0c2 [MARK,NAM(2)] (len=3, tl=0) 4,5,6
ATTRIB:
  @258d4f4 02 LISTSXP g0c0 [MARK]
    TAG: @1612120 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
    @261e710 16 STRSXP g0c1 [MARK,NAM(2)] (len=2, tl=0)
      @17a86f8 09 CHARSXP g0c1 [MARK,gp=0x21] "a"
      @1766868 09 CHARSXP g0c1 [MARK,gp=0x21] "b"
    TAG: @1612040 01 SYMSXP g0c0 [MARK,gp=0x4000] "row.names"
    @261e5d0 13 INTSXP g0c1 [MARK,NAM(2)] (len=2, tl=0) -2147483648,-3
    TAG: @1612388 01 SYMSXP g0c0 [MARK,gp=0x4000] "class"
    @2a758e8 16 STRSXP g0c1 [MARK,NAM(2)] (len=1, tl=0)
      @1647f38 09 CHARSXP g0c2 [MARK,gp=0x21,ATT] "data.frame"

> identical(DF, data.frame(a=1:3,b=4:6))
[1] TRUE

Matthew


From ripley at stats.ox.ac.uk  Thu Nov 24 19:48:30 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 24 Nov 2011 18:48:30 +0000 (GMT)
Subject: [Rd] Confused about NAMED
In-Reply-To: <6377C1B0-6D16-4EE1-A86A-7B0EA353BF41@r-project.org>
References: <719cbc60d789ea0d3bf1d6a18309a216.squirrel@webmail.plus.net>
	<090530A4-BBC5-48B3-9EC0-2D965C200729@gmail.com>
	<2573e1d2e510477135f6246e60d53aef.squirrel@webmail.plus.net>
	<A46434F9-309A-4D83-A5F1-54472DE36FDE@gmail.com>
	<0feab74fdda903967fff2f6868d8cf75.squirrel@webmail.plus.net>
	<6377C1B0-6D16-4EE1-A86A-7B0EA353BF41@r-project.org>
Message-ID: <alpine.LFD.2.02.1111241723290.6970@gannet.stats.ox.ac.uk>

On Thu, 24 Nov 2011, Simon Urbanek wrote:

>
> On Nov 24, 2011, at 8:05 AM, Matthew Dowle wrote:
>
>>>
>>> On Nov 24, 2011, at 12:34 , Matthew Dowle wrote:
>>>
>>>>>
>>>>> On Nov 24, 2011, at 11:13 , Matthew Dowle wrote:
>>>>>
>>>>>> Hi,
>>>>>>
>>>>>> I expected NAMED to be 1 in all these three cases. It is for one of
>>>>>> them,
>>>>>> but not the other two?
>>>>>>
>>>>>>> R --vanilla
>>>>>> R version 2.14.0 (2011-10-31)
>>>>>> Platform: i386-pc-mingw32/i386 (32-bit)
>>>>>>
>>>>>>> x = 1L
>>>>>>> .Internal(inspect(x))   # why NAM(2)? expected NAM(1)
>>>>>> @2514aa0 13 INTSXP g0c1 [NAM(2)] (len=1, tl=0) 1
>>>>>>
>>>>>>> y = 1:10
>>>>>>> .Internal(inspect(y))   # NAM(1) as expected but why different to x?
>>>>>> @272f788 13 INTSXP g0c4 [NAM(1)] (len=10, tl=0) 1,2,3,4,5,...
>>>>>>
>>>>>>> z = data.frame()
>>>>>>> .Internal(inspect(z))   # why NAM(2)? expected NAM(1)
>>>>>> @24fc28c 19 VECSXP g0c0 [OBJ,NAM(2),ATT] (len=0, tl=0)
>>>>>> ATTRIB:
>>>>>> @24fc270 02 LISTSXP g0c0 []
>>>>>>  TAG: @3f2120 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
>>>>>>  @24fc334 16 STRSXP g0c0 [] (len=0, tl=0)
>>>>>>  TAG: @3f2040 01 SYMSXP g0c0 [MARK,gp=0x4000] "row.names"
>>>>>>  @24fc318 13 INTSXP g0c0 [] (len=0, tl=0)
>>>>>>  TAG: @3f2388 01 SYMSXP g0c0 [MARK,gp=0x4000] "class"
>>>>>>  @25be500 16 STRSXP g0c1 [] (len=1, tl=0)
>>>>>>    @1d38af0 09 CHARSXP g0c2 [MARK,gp=0x21,ATT] "data.frame"
>>>>>>
>>>>>> It's a little difficult to search for the word "named" but I tried and
>>>>>> found this in R-ints :
>>>>>>
>>>>>>  "Note that optimizing NAMED = 1 is only effective within a primitive
>>>>>> (as the closure wrapper of a .Internal will set NAMED = 2 when the
>>>>>> promise to the argument is evaluated)"
>>>>>>
>>>>>> So might it be that just looking at NAMED using .Internal(inspect())
>>>>>> is
>>>>>> setting NAMED=2?  But if so, why does y have NAMED==1?
>>>>>
>>>>> This is tricky business... I'm not quite sure I'll get it right, but
>>>>> let's
>>>>> try
>>>>>
>>>>> When you are assigning a constant, the value you assign is already part
>>>>> of
>>>>> the assignment expression, so if you want to modify it, you must
>>>>> duplicate. So NAMED==2 on z <- 1 is basically to prevent you from
>>>>> accidentally "changing the value of 1". If it weren't, then you could
>>>>> get
>>>>> bitten by code like for(i in 1:2) {z <- 1; if(i==1) z[1] <- 2}.
>>>>>
>>>>> If you're assigning the result of a computation, then the object only
>>>>> exists once, so
>>>>> z <- 0+1  gets NAMED==1.
>>>>>
>>>>> However, if the computation is done by returning a named value from
>>>>> within
>>>>> a function, as in
>>>>>
>>>>>> f <- function(){v <- 1+0; v}
>>>>>> z <- f()
>>>>>
>>>>> then again NAMED==2. This is because the side effects of the function
>>>>> _might_ result in something having a hold on the function environment,
>>>>> e.g. if we had
>>>>>
>>>>> e <- NULL
>>>>> f <- function(){e <<-environment(); v <- 1+0; v}
>>>>> z <- f()
>>>>>
>>>>> then z[1] <- 5 would change e$v too. As it happens, there aren't any
>>>>> side
>>>>> effects in the forme case, but R loses track and assumes the worst.
>>>>>
>>>>
>>>> Thanks a lot, think I follow. That explains x vs y, but why is z
>>>> NAMED==2?
>>>> The result of data.frame() is an object that exists once (similar to
>>>> 1:10)
>>>> so shouldn't it be NAMED==1 too?  Or, R loses track and assumes the
>>>> worst
>>>> even on its own functions such as data.frame()?
>>>
>>> R loses track. I suspect that is really all it can do without actual
>>> reference counting. The function data.frame is more than 150 lines of
>>> code, and if any of those end up invoking user code, possibly via a class
>>> method, you can't tell definitively whether or not the evaluation
>>> environment dies at the return.
>>
>> Ohhh, think I see now. After Duncan's reply I was going to ask if it was
>> possible to change data.frame() to be primitive so it could set NAMED=1.
>> But it seems primitive functions can't use R code so data.frame() would
>> need to be ported to C. Ok! - not quick or easy, and not without
>> consideable risk. And, data.frame() can invoke user code inside it anyway
>> then.

Maybe some review of the 'R Internals' manual about what a primitive 
function is would be desirable.  Converting such a function to C would 
ossify it, which is the major reason it has not been done (it has been 
contemplated).

>> Since list() is primitive I tried to construct a data.frame starting with
>> list() [since structure() isn't primitive], but then merely adding an
>> attribute seems to set NAMED==2 too ?
>>
>
> Yes, because attr(x,y) <- z is the same as
>
> `*tmp*` <- x
> x <- `attr<-`(`*tmp*`, y, z)
> rm(`*tmp*`)

Only if it were an interpreted function.

> so there are two references to the data frame: one in DF and one in 
> `*tmp*`. It is the first line that causes the NAMED bump. And, yes, 
> it's real:
>
>> `f<-`=function(x,value) { print(ls(parent.frame())); x<-value }
>> x=1
>> f(x)=1
> [1] "*tmp*" "f<-"   "x"

You have just explained why interpreted replacement functions set 
NAMED=2, but this does not apply to primitives.

To help convince you, consider

> d <- 1:2
> attributes(d) <- list(x=13)
> d
[1] 1 2
attr(,"x")
[1] 13
> .Internal(inspect(d))
@11be748 13 INTSXP g0c1 [NAM(1),ATT] (len=2, tl=0) 1,2
ATTRIB:
   @1552054 02 LISTSXP g0c0 []
     TAG: @102b1c0 01 SYMSXP g0c0 [MARK,NAM(2)] "x"
     @11be768 14 REALSXP g0c1 [] (len=1, tl=0) 13

Now, as to why attr<- (which is primitive) does what it does you will 
need to read (and understand) the code.

>
> You could skip that by using the function directly (I don't think it's recommended, though):
>
>> .Internal(inspect(l <- list(a=1)))
> @1028c82f8 19 VECSXP g0c1 [NAM(1),ATT] (len=1, tl=0)
>  @1028c8268 14 REALSXP g0c1 [] (len=1, tl=0) 1
> ATTRIB:
>  @100b6e748 02 LISTSXP g0c0 []
>    TAG: @100843878 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
>    @1028c82c8 16 STRSXP g0c1 [] (len=1, tl=0)
>      @1009cd388 09 CHARSXP g0c1 [MARK,gp=0x21] "a"
>> .Internal(inspect(`names<-`(l, "b")))
> @1028c82f8 19 VECSXP g0c1 [NAM(1),ATT] (len=1, tl=0)
>  @1028c8268 14 REALSXP g0c1 [] (len=1, tl=0) 1
> ATTRIB:
>  @100b6e748 02 LISTSXP g0c0 []
>    TAG: @100843878 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
>    @1028c8178 16 STRSXP g0c1 [NAM(1)] (len=1, tl=0)
>      @100967af8 09 CHARSXP g0c1 [MARK,gp=0x20] "b"
>> .Internal(inspect(l))
> @1028c82f8 19 VECSXP g0c1 [NAM(1),ATT] (len=1, tl=0)
>  @1028c8268 14 REALSXP g0c1 [] (len=1, tl=0) 1
> ATTRIB:
>  @100b6e748 02 LISTSXP g0c0 []
>    TAG: @100843878 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
>    @1028c8178 16 STRSXP g0c1 [NAM(1)] (len=1, tl=0)
>      @100967af8 09 CHARSXP g0c1 [MARK,gp=0x20] "b"
>
> Cheers,
> Simon
>
>
>
>>> DF = list(a=1:3,b=4:6)
>>> .Internal(inspect(DF))     # so far so good: NAM(1)
>> @25149e0 19 VECSXP g0c1 [NAM(1),ATT] (len=2, tl=0)
>>  @263ea50 13 INTSXP g0c2 [] (len=3, tl=0) 1,2,3
>>  @263eaa0 13 INTSXP g0c2 [] (len=3, tl=0) 4,5,6
>> ATTRIB:
>>  @2457984 02 LISTSXP g0c0 []
>>    TAG: @3f2120 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
>>    @25149c0 16 STRSXP g0c1 [] (len=2, tl=0)
>>      @1e987d8 09 CHARSXP g0c1 [MARK,gp=0x21] "a"
>>      @1e56948 09 CHARSXP g0c1 [MARK,gp=0x21] "b"
>>>
>>> attr(DF,"foo") <- "bar"    # just adding an attribute sets NAM(2) ?
>>> .Internal(inspect(DF))
>> @25149e0 19 VECSXP g0c1 [NAM(2),ATT] (len=2, tl=0)
>>  @263ea50 13 INTSXP g0c2 [] (len=3, tl=0) 1,2,3
>>  @263eaa0 13 INTSXP g0c2 [] (len=3, tl=0) 4,5,6
>> ATTRIB:
>>  @2457984 02 LISTSXP g0c0 []
>>    TAG: @3f2120 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
>>    @25149c0 16 STRSXP g0c1 [] (len=2, tl=0)
>>      @1e987d8 09 CHARSXP g0c1 [MARK,gp=0x21] "a"
>>      @1e56948 09 CHARSXP g0c1 [MARK,gp=0x21] "b"
>>    TAG: @245732c 01 SYMSXP g0c0 [] "foo"
>>    @25148a0 16 STRSXP g0c1 [NAM(1)] (len=1, tl=0)
>>      @2514920 09 CHARSXP g0c1 [gp=0x20] "bar"
>>
>>
>> Matthew
>>
>>
>>> --
>>> Peter Dalgaard, Professor
>>> Center for Statistics, Copenhagen Business School
>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>> Phone: (+45)38153501
>>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>>
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From simon.urbanek at r-project.org  Thu Nov 24 20:31:20 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 24 Nov 2011 14:31:20 -0500
Subject: [Rd] Confused about NAMED
In-Reply-To: <alpine.LFD.2.02.1111241723290.6970@gannet.stats.ox.ac.uk>
References: <719cbc60d789ea0d3bf1d6a18309a216.squirrel@webmail.plus.net>
	<090530A4-BBC5-48B3-9EC0-2D965C200729@gmail.com>
	<2573e1d2e510477135f6246e60d53aef.squirrel@webmail.plus.net>
	<A46434F9-309A-4D83-A5F1-54472DE36FDE@gmail.com>
	<0feab74fdda903967fff2f6868d8cf75.squirrel@webmail.plus.net>
	<6377C1B0-6D16-4EE1-A86A-7B0EA353BF41@r-project.org>
	<alpine.LFD.2.02.1111241723290.6970@gannet.stats.ox.ac.uk>
Message-ID: <E24ED922-757A-4C03-BB05-5037F07A248C@r-project.org>

On Nov 24, 2011, at 1:48 PM, Prof Brian Ripley wrote:

> On Thu, 24 Nov 2011, Simon Urbanek wrote:
> 
>> 
>> On Nov 24, 2011, at 8:05 AM, Matthew Dowle wrote:
>> 
>>>> 
>>>> On Nov 24, 2011, at 12:34 , Matthew Dowle wrote:
>>>> 
>>>>>> 
>>>>>> On Nov 24, 2011, at 11:13 , Matthew Dowle wrote:
>>>>>> 
>>>>>>> Hi,
>>>>>>> 
>>>>>>> I expected NAMED to be 1 in all these three cases. It is for one of
>>>>>>> them,
>>>>>>> but not the other two?
>>>>>>> 
>>>>>>>> R --vanilla
>>>>>>> R version 2.14.0 (2011-10-31)
>>>>>>> Platform: i386-pc-mingw32/i386 (32-bit)
>>>>>>> 
>>>>>>>> x = 1L
>>>>>>>> .Internal(inspect(x))   # why NAM(2)? expected NAM(1)
>>>>>>> @2514aa0 13 INTSXP g0c1 [NAM(2)] (len=1, tl=0) 1
>>>>>>> 
>>>>>>>> y = 1:10
>>>>>>>> .Internal(inspect(y))   # NAM(1) as expected but why different to x?
>>>>>>> @272f788 13 INTSXP g0c4 [NAM(1)] (len=10, tl=0) 1,2,3,4,5,...
>>>>>>> 
>>>>>>>> z = data.frame()
>>>>>>>> .Internal(inspect(z))   # why NAM(2)? expected NAM(1)
>>>>>>> @24fc28c 19 VECSXP g0c0 [OBJ,NAM(2),ATT] (len=0, tl=0)
>>>>>>> ATTRIB:
>>>>>>> @24fc270 02 LISTSXP g0c0 []
>>>>>>> TAG: @3f2120 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
>>>>>>> @24fc334 16 STRSXP g0c0 [] (len=0, tl=0)
>>>>>>> TAG: @3f2040 01 SYMSXP g0c0 [MARK,gp=0x4000] "row.names"
>>>>>>> @24fc318 13 INTSXP g0c0 [] (len=0, tl=0)
>>>>>>> TAG: @3f2388 01 SYMSXP g0c0 [MARK,gp=0x4000] "class"
>>>>>>> @25be500 16 STRSXP g0c1 [] (len=1, tl=0)
>>>>>>>   @1d38af0 09 CHARSXP g0c2 [MARK,gp=0x21,ATT] "data.frame"
>>>>>>> 
>>>>>>> It's a little difficult to search for the word "named" but I tried and
>>>>>>> found this in R-ints :
>>>>>>> 
>>>>>>> "Note that optimizing NAMED = 1 is only effective within a primitive
>>>>>>> (as the closure wrapper of a .Internal will set NAMED = 2 when the
>>>>>>> promise to the argument is evaluated)"
>>>>>>> 
>>>>>>> So might it be that just looking at NAMED using .Internal(inspect())
>>>>>>> is
>>>>>>> setting NAMED=2?  But if so, why does y have NAMED==1?
>>>>>> 
>>>>>> This is tricky business... I'm not quite sure I'll get it right, but
>>>>>> let's
>>>>>> try
>>>>>> 
>>>>>> When you are assigning a constant, the value you assign is already part
>>>>>> of
>>>>>> the assignment expression, so if you want to modify it, you must
>>>>>> duplicate. So NAMED==2 on z <- 1 is basically to prevent you from
>>>>>> accidentally "changing the value of 1". If it weren't, then you could
>>>>>> get
>>>>>> bitten by code like for(i in 1:2) {z <- 1; if(i==1) z[1] <- 2}.
>>>>>> 
>>>>>> If you're assigning the result of a computation, then the object only
>>>>>> exists once, so
>>>>>> z <- 0+1  gets NAMED==1.
>>>>>> 
>>>>>> However, if the computation is done by returning a named value from
>>>>>> within
>>>>>> a function, as in
>>>>>> 
>>>>>>> f <- function(){v <- 1+0; v}
>>>>>>> z <- f()
>>>>>> 
>>>>>> then again NAMED==2. This is because the side effects of the function
>>>>>> _might_ result in something having a hold on the function environment,
>>>>>> e.g. if we had
>>>>>> 
>>>>>> e <- NULL
>>>>>> f <- function(){e <<-environment(); v <- 1+0; v}
>>>>>> z <- f()
>>>>>> 
>>>>>> then z[1] <- 5 would change e$v too. As it happens, there aren't any
>>>>>> side
>>>>>> effects in the forme case, but R loses track and assumes the worst.
>>>>>> 
>>>>> 
>>>>> Thanks a lot, think I follow. That explains x vs y, but why is z
>>>>> NAMED==2?
>>>>> The result of data.frame() is an object that exists once (similar to
>>>>> 1:10)
>>>>> so shouldn't it be NAMED==1 too?  Or, R loses track and assumes the
>>>>> worst
>>>>> even on its own functions such as data.frame()?
>>>> 
>>>> R loses track. I suspect that is really all it can do without actual
>>>> reference counting. The function data.frame is more than 150 lines of
>>>> code, and if any of those end up invoking user code, possibly via a class
>>>> method, you can't tell definitively whether or not the evaluation
>>>> environment dies at the return.
>>> 
>>> Ohhh, think I see now. After Duncan's reply I was going to ask if it was
>>> possible to change data.frame() to be primitive so it could set NAMED=1.
>>> But it seems primitive functions can't use R code so data.frame() would
>>> need to be ported to C. Ok! - not quick or easy, and not without
>>> consideable risk. And, data.frame() can invoke user code inside it anyway
>>> then.
> 
> Maybe some review of the 'R Internals' manual about what a primitive function is would be desirable.  Converting such a function to C would ossify it, which is the major reason it has not been done (it has been contemplated).
> 
>>> Since list() is primitive I tried to construct a data.frame starting with
>>> list() [since structure() isn't primitive], but then merely adding an
>>> attribute seems to set NAMED==2 too ?
>>> 
>> 
>> Yes, because attr(x,y) <- z is the same as
>> 
>> `*tmp*` <- x
>> x <- `attr<-`(`*tmp*`, y, z)
>> rm(`*tmp*`)
> 
> Only if it were an interpreted function.
> 
>> so there are two references to the data frame: one in DF and one in `*tmp*`. It is the first line that causes the NAMED bump. And, yes, it's real:
>> 
>>> `f<-`=function(x,value) { print(ls(parent.frame())); x<-value }
>>> x=1
>>> f(x)=1
>> [1] "*tmp*" "f<-"   "x"
> 
> You have just explained why interpreted replacement functions set NAMED=2, but this does not apply to primitives.
> 

It does - see eval.c l1680-2 which causes it to go through do_set which is turn bumps NAMED. I have responded only to Luke but I guess I should have included everyone..


> To help convince you, consider
> 
>> d <- 1:2
>> attributes(d) <- list(x=13)
>> d
> [1] 1 2
> attr(,"x")
> [1] 13
>> .Internal(inspect(d))
> @11be748 13 INTSXP g0c1 [NAM(1),ATT] (len=2, tl=0) 1,2
> ATTRIB:
>  @1552054 02 LISTSXP g0c0 []
>    TAG: @102b1c0 01 SYMSXP g0c0 [MARK,NAM(2)] "x"
>    @11be768 14 REALSXP g0c1 [] (len=1, tl=0) 13
> 
> Now, as to why attr<- (which is primitive) does what it does you will need to read (and understand) the code.
> 

Because do_attributesgets duplicates (attrib.c l1178) which you can easily see:

> d <- 1:2
> .Internal(inspect(d))
@155aba8 13 INTSXP g0c1 [NAM(1)] (len=2, tl=0) 1,2
> attributes(d) <- list(x=13)
> .Internal(inspect(d))
@15dbe28 13 INTSXP g0c1 [NAM(1),ATT] (len=2, tl=0) 1,2
ATTRIB:
  @16da5a8 02 LISTSXP g0c0 [] 
    TAG: @660008 01 SYMSXP g0c0 [MARK,NAM(2)] "x"
    @15dbe58 14 REALSXP g0c1 [] (len=1, tl=0) 13

Note the different pointer of the value of d now -- do_attributesgets returns a duplicate with NAMED=0 so do_set assignment bumps it to 1.

Cheers,
Simon



>> 
>> You could skip that by using the function directly (I don't think it's recommended, though):
>> 
>>> .Internal(inspect(l <- list(a=1)))
>> @1028c82f8 19 VECSXP g0c1 [NAM(1),ATT] (len=1, tl=0)
>> @1028c8268 14 REALSXP g0c1 [] (len=1, tl=0) 1
>> ATTRIB:
>> @100b6e748 02 LISTSXP g0c0 []
>>   TAG: @100843878 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
>>   @1028c82c8 16 STRSXP g0c1 [] (len=1, tl=0)
>>     @1009cd388 09 CHARSXP g0c1 [MARK,gp=0x21] "a"
>>> .Internal(inspect(`names<-`(l, "b")))
>> @1028c82f8 19 VECSXP g0c1 [NAM(1),ATT] (len=1, tl=0)
>> @1028c8268 14 REALSXP g0c1 [] (len=1, tl=0) 1
>> ATTRIB:
>> @100b6e748 02 LISTSXP g0c0 []
>>   TAG: @100843878 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
>>   @1028c8178 16 STRSXP g0c1 [NAM(1)] (len=1, tl=0)
>>     @100967af8 09 CHARSXP g0c1 [MARK,gp=0x20] "b"
>>> .Internal(inspect(l))
>> @1028c82f8 19 VECSXP g0c1 [NAM(1),ATT] (len=1, tl=0)
>> @1028c8268 14 REALSXP g0c1 [] (len=1, tl=0) 1
>> ATTRIB:
>> @100b6e748 02 LISTSXP g0c0 []
>>   TAG: @100843878 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
>>   @1028c8178 16 STRSXP g0c1 [NAM(1)] (len=1, tl=0)
>>     @100967af8 09 CHARSXP g0c1 [MARK,gp=0x20] "b"
>> 
>> Cheers,
>> Simon
>> 
>> 
>> 
>>>> DF = list(a=1:3,b=4:6)
>>>> .Internal(inspect(DF))     # so far so good: NAM(1)
>>> @25149e0 19 VECSXP g0c1 [NAM(1),ATT] (len=2, tl=0)
>>> @263ea50 13 INTSXP g0c2 [] (len=3, tl=0) 1,2,3
>>> @263eaa0 13 INTSXP g0c2 [] (len=3, tl=0) 4,5,6
>>> ATTRIB:
>>> @2457984 02 LISTSXP g0c0 []
>>>   TAG: @3f2120 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
>>>   @25149c0 16 STRSXP g0c1 [] (len=2, tl=0)
>>>     @1e987d8 09 CHARSXP g0c1 [MARK,gp=0x21] "a"
>>>     @1e56948 09 CHARSXP g0c1 [MARK,gp=0x21] "b"
>>>> 
>>>> attr(DF,"foo") <- "bar"    # just adding an attribute sets NAM(2) ?
>>>> .Internal(inspect(DF))
>>> @25149e0 19 VECSXP g0c1 [NAM(2),ATT] (len=2, tl=0)
>>> @263ea50 13 INTSXP g0c2 [] (len=3, tl=0) 1,2,3
>>> @263eaa0 13 INTSXP g0c2 [] (len=3, tl=0) 4,5,6
>>> ATTRIB:
>>> @2457984 02 LISTSXP g0c0 []
>>>   TAG: @3f2120 01 SYMSXP g0c0 [MARK,gp=0x4000] "names"
>>>   @25149c0 16 STRSXP g0c1 [] (len=2, tl=0)
>>>     @1e987d8 09 CHARSXP g0c1 [MARK,gp=0x21] "a"
>>>     @1e56948 09 CHARSXP g0c1 [MARK,gp=0x21] "b"
>>>   TAG: @245732c 01 SYMSXP g0c0 [] "foo"
>>>   @25148a0 16 STRSXP g0c1 [NAM(1)] (len=1, tl=0)
>>>     @2514920 09 CHARSXP g0c1 [gp=0x20] "bar"
>>> 
>>> 
>>> Matthew
>>> 
>>> 
>>>> --
>>>> Peter Dalgaard, Professor
>>>> Center for Statistics, Copenhagen Business School
>>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>>> Phone: (+45)38153501
>>>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>>> 
>>>> 
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>> 
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> 


From friendly at yorku.ca  Thu Nov 24 22:44:05 2011
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 24 Nov 2011 16:44:05 -0500
Subject: [Rd] How to deal with package conflicts
Message-ID: <4ECEBAA5.3030403@yorku.ca>

In my genridge package, I define a function ridge() for ridge 
regression, creating objects of class 'ridge'
that I intend to enhance.

In a documentation example, I want to use some functions from the car 
package. However, that package
requires survival, which also includes a ridge() function, for coxph 
models. So, once I require(car)
my ridge() function is masked, which means I have to use the awkward 
form below in my .Rd files.

ridgemod <- genridge::ridge(...)

I tried to detach survival, but that doesn't work:

 > detach("package:survival")
Error: package ?survival? is required by ?car? so will not be detached

I don't see any solution to this, other than
(a) renaming my ridge() to something else -- don't want to do this
(b) use \dontrun{} for the examples that use car

Or, is there some other way?

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From murdoch.duncan at gmail.com  Fri Nov 25 02:09:08 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 24 Nov 2011 20:09:08 -0500
Subject: [Rd] How to deal with package conflicts
In-Reply-To: <4ECEBAA5.3030403@yorku.ca>
References: <4ECEBAA5.3030403@yorku.ca>
Message-ID: <4ECEEAB4.2020201@gmail.com>

On 11-11-24 4:44 PM, Michael Friendly wrote:
> In my genridge package, I define a function ridge() for ridge
> regression, creating objects of class 'ridge'
> that I intend to enhance.
>
> In a documentation example, I want to use some functions from the car
> package. However, that package
> requires survival, which also includes a ridge() function, for coxph
> models. So, once I require(car)
> my ridge() function is masked, which means I have to use the awkward
> form below in my .Rd files.
>
> ridgemod<- genridge::ridge(...)
>
> I tried to detach survival, but that doesn't work:
>
>   >  detach("package:survival")
> Error: package ?survival? is required by ?car? so will not be detached
>
> I don't see any solution to this, other than
> (a) renaming my ridge() to something else -- don't want to do this
> (b) use \dontrun{} for the examples that use car
>
> Or, is there some other way?

Not really.  I'd say the renaming is the preferred way to go, but you 
might also be able to convince Terry Therneau (survival author) to make 
ridge() a generic, so your method is called for your objects, and his is 
called for others.

Duncan Murdoch


From nick.sabbe at ugent.be  Fri Nov 25 11:13:18 2011
From: nick.sabbe at ugent.be (Nick Sabbe)
Date: Fri, 25 Nov 2011 11:13:18 +0100
Subject: [Rd] plot(.xy) and add
Message-ID: <054f01ccab5a$da6fad20$8f4f0760$@sabbe@ugent.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111125/608d3b71/attachment.pl>

From Bernhard_Pfaff at fra.invesco.com  Fri Nov 25 11:56:43 2011
From: Bernhard_Pfaff at fra.invesco.com (Pfaff, Bernhard Dr.)
Date: Fri, 25 Nov 2011 10:56:43 +0000
Subject: [Rd] Case: package removed from CRAN, but not orphaned
Message-ID: <FCD9A33C859ACC469587CB09DD5C6C71230C6D@GBLONXMB11.corp.amvescap.net>

Dear R-Devel subscriber,

I would like to raise a topic and ask for your advice, guidance. 
Today on R-help an issue with a certain package popped up that has been removed from CRAN, because it failed the checks and/or the dependencies are not any longer available. The package maintainer has been alerted to this issue a couple of times and kindly asked to fix the code, such that it fullfills the CRAN requirements. However, neither a fix is applied, nor has the package been orphaned such that someone else could take over the ownership and rectify the package.
In principal, and if I am not mistaken, one could simply take the code, fix it and release it (the package is under GPL-2). However, I would consider this as a rather rude approach. Hence, my question would be, if the R Core team can take the initiative, to declare the package as being orphaned after a 'warning period' has been elapsed in which the current maintainer is kindly asked to fix his package. Would it be feasible to ask R Core to orphan a package?

Best,
Bernhard   

ps: Incidentally, I am aware of the new 'orphaned package rules', in particular under the rubrique 'Possible reasons for orphanizing a package', point 2). In the case of the package in question, the maintainer does respond to emails, but either seems to lack action and/or has a different time scale and awareness of time.  


*****************************************************************
Confidentiality Note: The information contained in this ...{{dropped:10}}


From murdoch.duncan at gmail.com  Fri Nov 25 14:53:40 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 25 Nov 2011 08:53:40 -0500
Subject: [Rd] Case: package removed from CRAN, but not orphaned
In-Reply-To: <FCD9A33C859ACC469587CB09DD5C6C71230C6D@GBLONXMB11.corp.amvescap.net>
References: <FCD9A33C859ACC469587CB09DD5C6C71230C6D@GBLONXMB11.corp.amvescap.net>
Message-ID: <4ECF9DE4.20905@gmail.com>

On 11-11-25 5:56 AM, Pfaff, Bernhard Dr. wrote:
> Dear R-Devel subscriber,
>
> I would like to raise a topic and ask for your advice, guidance.
> Today on R-help an issue with a certain package popped up that has been removed from CRAN, because it failed the checks and/or the dependencies are not any longer available. The package maintainer has been alerted to this issue a couple of times and kindly asked to fix the code, such that it fullfills the CRAN requirements. However, neither a fix is applied, nor has the package been orphaned such that someone else could take over the ownership and rectify the package.
> In principal, and if I am not mistaken, one could simply take the code, fix it and release it (the package is under GPL-2). However, I would consider this as a rather rude approach. Hence, my question would be, if the R Core team can take the initiative, to declare the package as being orphaned after a 'warning period' has been elapsed in which the current maintainer is kindly asked to fix his package. Would it be feasible to ask R Core to orphan a package?
>

Not to comment on your main point, but just to clarify a small one: 
CRAN is not run by the R Core Team.  There's a lot of overlap between 
the groups, but they are separate.

Duncan Murdoch

> Best,
> Bernhard
>
> ps: Incidentally, I am aware of the new 'orphaned package rules', in particular under the rubrique 'Possible reasons for orphanizing a package', point 2). In the case of the package in question, the maintainer does respond to emails, but either seems to lack action and/or has a different time scale and awareness of time.
>
>
> *****************************************************************
> Confidentiality Note: The information contained in this ...{{dropped:10}}
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From therneau at mayo.edu  Fri Nov 25 15:10:52 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Fri, 25 Nov 2011 08:10:52 -0600
Subject: [Rd] How to deal with package conflicts
In-Reply-To: <mailman.21.1322218808.15358.r-devel@r-project.org>
References: <mailman.21.1322218808.15358.r-devel@r-project.org>
Message-ID: <1322230252.5806.15.camel@nemo>

The ridge() function was put into the survival package as a simple
example of what a user could do with penalized functions.  It's not a
"serious" function, and I'd be open to any suggestions for change. 

Actually, for any L2 penalty + Cox model one is now better off using
coxme as the maximization process is much better thought out there.  I'd
be happy to remove ridge from survival -- except that there are bound to
be lots of folks using the function and any such changes (even good
ones) to the survival package are fraught with peril.

Duncan: this raises a larger point.  I've often wished that I could have
"namespace" like rules apply to formulas.  Using survival again, when I
implemented gam-like smooths I had to create "pspline" rather than use
the more natural "s()" notation.  In survival, it would be good to do
this for ridge, cluster, pspline, and frailty; all of whom depend deeply
on a coxph context.  It would also solve a frailty() problem of long
standing, that when used in survreg only a subset of the frailty options
make sense; this is documented in the help file but catches users again
and again.

Terry Therneau



On Fri, 2011-11-25 at 12:00 +0100, r-devel-request at r-project.org wrote:
> > In my genridge package, I define a function ridge() for ridge
> > regression, creating objects of class 'ridge'
> > that I intend to enhance.
> >
> > In a documentation example, I want to use some functions from the
> car
> > package. However, that package
> > requires survival, which also includes a ridge() function, for coxph
> > models. So, once I require(car)
> > my ridge() function is masked, which means I have to use the awkward
> > form below in my .Rd files.
> >
> > ridgemod<- genridge::ridge(...)
> >
> > I tried to detach survival, but that doesn't work:
> >
> >   >  detach("package:survival")
> > Error: package ?survival? is required by ?car? so will not be
> detached
> >
> > I don't see any solution to this, other than
> > (a) renaming my ridge() to something else -- don't want to do this
> > (b) use \dontrun{} for the examples that use car
> >
> > Or, is there some other way?
> 
> Not really.  I'd say the renaming is the preferred way to go, but you 
> might also be able to convince Terry Therneau (survival author) to
> make 
> ridge() a generic, so your method is called for your objects, and his
> is 
> called for others.
> 
> Duncan Murdoch
>


From ligges at statistik.tu-dortmund.de  Fri Nov 25 15:33:57 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 25 Nov 2011 15:33:57 +0100
Subject: [Rd] Case: package removed from CRAN, but not orphaned
In-Reply-To: <FCD9A33C859ACC469587CB09DD5C6C71230C6D@GBLONXMB11.corp.amvescap.net>
References: <FCD9A33C859ACC469587CB09DD5C6C71230C6D@GBLONXMB11.corp.amvescap.net>
Message-ID: <4ECFA755.9020204@statistik.tu-dortmund.de>

On 25.11.2011 11:56, Pfaff, Bernhard Dr. wrote:
> Dear R-Devel subscriber,
>
> I would like to raise a topic and ask for your advice, guidance.
> Today on R-help an issue with a certain package popped up that has been removed from CRAN, because it failed the checks and/or the dependencies are not any longer available. The package maintainer has been alerted to this issue a couple of times and kindly asked to fix the code, such that it fullfills the CRAN requirements. However, neither a fix is applied, nor has the package been orphaned such that someone else could take over the ownership and rectify the package.
> In principal, and if I am not mistaken, one could simply take the code, fix it and release it (the package is under GPL-2). However, I would consider this as a rather rude approach. Hence, my question would be, if the R Core team can take the initiative, to declare the package as being orphaned after a 'warning period' has been elapsed in which the current maintainer is kindly asked to fix his package. Would it be feasible to ask R Core to orphan a package?
>
> Best,
> Bernhard
>
> ps: Incidentally, I am aware of the new 'orphaned package rules', in particular under the rubrique 'Possible reasons for orphanizing a package', point 2). In the case of the package in question, the maintainer does respond to emails, but either seems to lack action and/or has a different time scale and awareness of time.


As Duncan wrote already, CRAN is not run by R-core - as you probably 
know, I have already maintained parts of CRAN for quite some time before 
I became core member.

Let me as one of the CRAN maintainers add:

We know that orphaning would be a nice hint to the community, but it 
takes some work and given we have >> 3000 packages, many of them not 
well maintained, we have to archive or orphan many packages a year 
nowadays. Due the already huge amount of work CRAN maintenance 
generates, we simply cannot invest more time given the time constraints.

Note that we archive packages if a maintainer asks us to do so or if the 
maintainer is unresponsive on our requests to fix the package. Since we 
as CRAN maintainers were unsuccessful to contact or convince the 
maintainer to fix, we typically won't invest more time/work on such a 
package.

Of course, if someone wants to take over an archived package and cannot 
get a response from the maintainer (but first try to do so yourself!) 
then a request to take over as maintainer can be sent to CRAN.

Currently we are working on a new CRAN policy document that will soon be 
published. This document may clarify some further questions and 
establishes some stricter policies to reduce the workload of CRAN 
maintainers.

Best wishes,
Uwe Ligges




>
> *****************************************************************
> Confidentiality Note: The information contained in this ...{{dropped:10}}
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Fri Nov 25 15:50:04 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 25 Nov 2011 09:50:04 -0500
Subject: [Rd] How to deal with package conflicts
In-Reply-To: <1322230252.5806.15.camel@nemo>
References: <mailman.21.1322218808.15358.r-devel@r-project.org>
	<1322230252.5806.15.camel@nemo>
Message-ID: <4ECFAB1C.7040607@gmail.com>

On 25/11/2011 9:10 AM, Terry Therneau wrote:
> The ridge() function was put into the survival package as a simple
> example of what a user could do with penalized functions.  It's not a
> "serious" function, and I'd be open to any suggestions for change.
>
> Actually, for any L2 penalty + Cox model one is now better off using
> coxme as the maximization process is much better thought out there.  I'd
> be happy to remove ridge from survival -- except that there are bound to
> be lots of folks using the function and any such changes (even good
> ones) to the survival package are fraught with peril.
>
> Duncan: this raises a larger point.  I've often wished that I could have
> "namespace" like rules apply to formulas.  Using survival again, when I
> implemented gam-like smooths I had to create "pspline" rather than use
> the more natural "s()" notation.  In survival, it would be good to do
> this for ridge, cluster, pspline, and frailty; all of whom depend deeply
> on a coxph context.  It would also solve a frailty() problem of long
> standing, that when used in survreg only a subset of the frailty options
> make sense; this is documented in the help file but catches users again
> and again.

I think the general idea in formulas is that it is up to the user to 
define the meaning of functions used in them.  Normally the user has 
attached the package that is working on the formula, so the package 
author can provide useful things like s(), but if a user wanted to 
redefine s() to their own function, that should be possible.  Formulas 
do have environments attached, so both variables and functions should be 
looked up there.

This not perfectly applied, of course.  It is generally up to the 
function interpreting the formula to define what "+" means, for example.
You could also have the function treat s() and other functions 
specially, but this is likely to be a little risky.  (I'm in the process 
of putting together a small package for displaying tables; it treats +, 
*, and a few other function-like things specially:  Format, .Format, 
Heading and Justify.  I chose capital letters for those to hopefully 
avoid conflicts with a user's own functions.  Perhaps I should have used 
dots on all of them.)

Duncan Murdoch
> Terry Therneau
>
>
>
> On Fri, 2011-11-25 at 12:00 +0100, r-devel-request at r-project.org wrote:
> >  >  In my genridge package, I define a function ridge() for ridge
> >  >  regression, creating objects of class 'ridge'
> >  >  that I intend to enhance.
> >  >
> >  >  In a documentation example, I want to use some functions from the
> >  car
> >  >  package. However, that package
> >  >  requires survival, which also includes a ridge() function, for coxph
> >  >  models. So, once I require(car)
> >  >  my ridge() function is masked, which means I have to use the awkward
> >  >  form below in my .Rd files.
> >  >
> >  >  ridgemod<- genridge::ridge(...)
> >  >
> >  >  I tried to detach survival, but that doesn't work:
> >  >
> >  >    >   detach("package:survival")
> >  >  Error: package ?survival? is required by ?car? so will not be
> >  detached
> >  >
> >  >  I don't see any solution to this, other than
> >  >  (a) renaming my ridge() to something else -- don't want to do this
> >  >  (b) use \dontrun{} for the examples that use car
> >  >
> >  >  Or, is there some other way?
> >
> >  Not really.  I'd say the renaming is the preferred way to go, but you
> >  might also be able to convince Terry Therneau (survival author) to
> >  make
> >  ridge() a generic, so your method is called for your objects, and his
> >  is
> >  called for others.
> >
> >  Duncan Murdoch
> >
>


From r.m.krug at gmail.com  Fri Nov 25 16:04:03 2011
From: r.m.krug at gmail.com (Rainer M Krug)
Date: Fri, 25 Nov 2011 16:04:03 +0100
Subject: [Rd] Case: package removed from CRAN, but not orphaned
In-Reply-To: <4ECFA755.9020204@statistik.tu-dortmund.de>
References: <FCD9A33C859ACC469587CB09DD5C6C71230C6D@GBLONXMB11.corp.amvescap.net>
	<4ECFA755.9020204@statistik.tu-dortmund.de>
Message-ID: <CAGhLh6HT4sF_Qqe9TmmXTHLdwEZZa_C0mTfcHa7r=wtLZEGLLw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111125/3ad74b14/attachment.pl>

From ligges at statistik.tu-dortmund.de  Fri Nov 25 16:13:42 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 25 Nov 2011 16:13:42 +0100
Subject: [Rd] Case: package removed from CRAN, but not orphaned
In-Reply-To: <CAGhLh6HT4sF_Qqe9TmmXTHLdwEZZa_C0mTfcHa7r=wtLZEGLLw@mail.gmail.com>
References: <FCD9A33C859ACC469587CB09DD5C6C71230C6D@GBLONXMB11.corp.amvescap.net>
	<4ECFA755.9020204@statistik.tu-dortmund.de>
	<CAGhLh6HT4sF_Qqe9TmmXTHLdwEZZa_C0mTfcHa7r=wtLZEGLLw@mail.gmail.com>
Message-ID: <4ECFB0A6.30504@statistik.tu-dortmund.de>



On 25.11.2011 16:04, Rainer M Krug wrote:
> 2011/11/25 Uwe Ligges<ligges at statistik.tu-dortmund.de>
>
>> On 25.11.2011 11:56, Pfaff, Bernhard Dr. wrote:
>>
>>> Dear R-Devel subscriber,
>>>
>>> I would like to raise a topic and ask for your advice, guidance.
>>> Today on R-help an issue with a certain package popped up that has been
>>> removed from CRAN, because it failed the checks and/or the dependencies are
>>> not any longer available. The package maintainer has been alerted to this
>>> issue a couple of times and kindly asked to fix the code, such that it
>>> fullfills the CRAN requirements. However, neither a fix is applied, nor has
>>> the package been orphaned such that someone else could take over the
>>> ownership and rectify the package.
>>> In principal, and if I am not mistaken, one could simply take the code,
>>> fix it and release it (the package is under GPL-2). However, I would
>>> consider this as a rather rude approach. Hence, my question would be, if
>>> the R Core team can take the initiative, to declare the package as being
>>> orphaned after a 'warning period' has been elapsed in which the current
>>> maintainer is kindly asked to fix his package. Would it be feasible to ask
>>> R Core to orphan a package?
>>>
>>> Best,
>>> Bernhard
>>>
>>> ps: Incidentally, I am aware of the new 'orphaned package rules', in
>>> particular under the rubrique 'Possible reasons for orphanizing a package',
>>> point 2). In the case of the package in question, the maintainer does
>>> respond to emails, but either seems to lack action and/or has a different
>>> time scale and awareness of time.
>>>
>>
>>
>> As Duncan wrote already, CRAN is not run by R-core - as you probably know,
>> I have already maintained parts of CRAN for quite some time before I became
>> core member.
>>
>> Let me as one of the CRAN maintainers add:
>>
>> We know that orphaning would be a nice hint to the community, but it takes
>> some work and given we have>>  3000 packages, many of them not well
>> maintained, we have to archive or orphan many packages a year nowadays. Due
>> the already huge amount of work CRAN maintenance generates, we simply
>> cannot invest more time given the time constraints.
>>
>> Note that we archive packages if a maintainer asks us to do so or if the
>> maintainer is unresponsive on our requests to fix the package. Since we as
>> CRAN maintainers were unsuccessful to contact or convince the maintainer to
>> fix, we typically won't invest more time/work on such a package.
>>
>> Of course, if someone wants to take over an archived package and cannot
>> get a response from the maintainer (but first try to do so yourself!) then
>> a request to take over as maintainer can be sent to CRAN.
>>
>> Currently we are working on a new CRAN policy document that will soon be
>> published. This document may clarify some further questions and establishes
>> some stricter policies to reduce the workload of CRAN maintainers.
>>
>
> Just as an idea to make sure that CRAN only contains maintained packages
> with a maintainer who feels responsible: Would it be feasible to introduce
> a system, so that each year (or for each release of a new version of R) the
> maintainers are automatically contacted via email and must reply to have
> their packages included in the new spring cleaned version of CRAN?
> This
> process could be automated, including the email confirmations (like mailing
> list subscriptions) and the non-maintained packages could be relocated to a
> second CRAN or marked as "will be removed at next springclean"? This would
> make sure that CRAN contains only "active" packages.

1. There is no reason to remove well working packages.
2. Removing packages with many reverse dependencies just because the 
maintainers are not reacting on auto-messages is not feasible: it 
multiplies the work.

Best wishes,
Uwe Ligges



> Cheers,
>
> Rainer
>
>
>>
>> Best wishes,
>> Uwe Ligges
>>
>>
>>
>>
>>
>>
>>> *********************************************************************
>>> Confidentiality Note: The information contained in this ...{{dropped:10}}
>>>
>>> ______________________________**________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/**listinfo/r-devel<https://stat.ethz.ch/mailman/listinfo/r-devel>
>>>
>>
>> ______________________________**________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/**listinfo/r-devel<https://stat.ethz.ch/mailman/listinfo/r-devel>
>>
>
>
>


From Bernhard_Pfaff at fra.invesco.com  Fri Nov 25 16:24:12 2011
From: Bernhard_Pfaff at fra.invesco.com (Pfaff, Bernhard Dr.)
Date: Fri, 25 Nov 2011 15:24:12 +0000
Subject: [Rd] Case: package removed from CRAN, but not orphaned
In-Reply-To: <4ECFA755.9020204@statistik.tu-dortmund.de>
References: <FCD9A33C859ACC469587CB09DD5C6C71230C6D@GBLONXMB11.corp.amvescap.net>
	<4ECFA755.9020204@statistik.tu-dortmund.de>
Message-ID: <FCD9A33C859ACC469587CB09DD5C6C71230D76@GBLONXMB11.corp.amvescap.net>


On 25.11.2011 11:56, Pfaff, Bernhard Dr. wrote:
> Dear R-Devel subscriber,
>
> I would like to raise a topic and ask for your advice, guidance.
> Today on R-help an issue with a certain package popped up that has been removed from CRAN, because it failed the checks and/or the dependencies are not any longer available. The package maintainer has been alerted to this issue a couple of times and kindly asked to fix the code, such that it fullfills the CRAN requirements. However, neither a fix is applied, nor has the package been orphaned such that someone else could take over the ownership and rectify the package.
> In principal, and if I am not mistaken, one could simply take the code, fix it and release it (the package is under GPL-2). However, I would consider this as a rather rude approach. Hence, my question would be, if the R Core team can take the initiative, to declare the package as being orphaned after a 'warning period' has been elapsed in which the current maintainer is kindly asked to fix his package. Would it be feasible to ask R Core to orphan a package?
>
> Best,
> Bernhard
>
> ps: Incidentally, I am aware of the new 'orphaned package rules', in particular under the rubrique 'Possible reasons for orphanizing a package', point 2). In the case of the package in question, the maintainer does respond to emails, but either seems to lack action and/or has a different time scale and awareness of time.


As Duncan wrote already, CRAN is not run by R-core - as you probably know, I have already maintained parts of CRAN for quite some time before I became core member.

Let me as one of the CRAN maintainers add:

We know that orphaning would be a nice hint to the community, but it takes some work and given we have >> 3000 packages, many of them not well maintained, we have to archive or orphan many packages a year nowadays. Due the already huge amount of work CRAN maintenance generates, we simply cannot invest more time given the time constraints.

Note that we archive packages if a maintainer asks us to do so or if the maintainer is unresponsive on our requests to fix the package. Since we as CRAN maintainers were unsuccessful to contact or convince the maintainer to fix, we typically won't invest more time/work on such a package.

Of course, if someone wants to take over an archived package and cannot get a response from the maintainer (but first try to do so yourself!) then a request to take over as maintainer can be sent to CRAN.

Currently we are working on a new CRAN policy document that will soon be published. This document may clarify some further questions and establishes some stricter policies to reduce the workload of CRAN maintainers.

Best wishes,
Uwe Ligges

[bp>] Hello Uwe and Duncan,
[bp>]  many thanks for your swift replies and please take my sincere apologies for mixing up R Core and CRAN maintainers, both are accomplishing a great job. Given the immense workload that the ones involved in keeping CRAN up and running, it is more than fair enough that measures for economizing on this burden are taken.  So I will be patiently but eagerly await the new CRAN policy.
[bp>] 

Best,
Bernhard


>
> *****************************************************************
> Confidentiality Note: The information contained in this 
> ...{{dropped:10}}
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From therneau at mayo.edu  Fri Nov 25 16:37:04 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Fri, 25 Nov 2011 09:37:04 -0600
Subject: [Rd] How to deal with package conflicts
In-Reply-To: <4ECFAB1C.7040607@gmail.com>
References: <mailman.21.1322218808.15358.r-devel@r-project.org>
	<1322230252.5806.15.camel@nemo>  <4ECFAB1C.7040607@gmail.com>
Message-ID: <1322235424.5806.80.camel@nemo>


On Fri, 2011-11-25 at 09:50 -0500, Duncan Murdoch wrote:
> I think the general idea in formulas is that it is up to the user to 
> define the meaning of functions used in them.  Normally the user has 
> attached the package that is working on the formula, so the package 
> author can provide useful things like s(), but if a user wanted to 
> redefine s() to their own function, that should be possible.
> Formulas 
> do have environments attached, so both variables and functions should
> be 
> looked up there.
> 

I don't agree that this is the best way.  A function like coxph could
easily have in its documentation a list of the "formula specials" that
it defines internally.  If the user want something of their own they can
easily use a different word.  In fact, I would strongly recommend that
they don't use one of these key names.  For things that work across
mutiple packages like ns(), what user in his right mind would redefine
it?
  So I re-raise the question.  Is there a reasonably simple way to make
the survival ridge() function specific to survival formulas?  It sets up
structures that have no meaning anywhere else, and its global definition
stands in the way of other sensible uses.  Having it be not exported +
obey namespace type sematics would be a plus all around.   

Philosophical aside:
  I have discovered to my dismay that formulas do have environments
attached, and that variables/functions are looked up there.  This made
sensible semantics for predict() within a function impossible for some
of the survival functions, unless I were to change all the routines to a
model=TRUE default.  (And a change of that magnitude to survival, with
its long list of dependencies, is not fun to contemplate.  A very quick
survey reveals several dependent packages will break.) So I don't agree
nearly so fully with the "should" part of your last sentence.  The out
of context evaluations allowed by environments are, I find, always
tricky and often lead to intricate special cases. 
  Thus, moving back and forth between how it seems that a formula should
work, and how it actually does work, sometimes leaves my head
spinning.  

Terry T.


Terry Therneau


From friendly at yorku.ca  Fri Nov 25 16:42:43 2011
From: friendly at yorku.ca (Michael Friendly)
Date: Fri, 25 Nov 2011 10:42:43 -0500
Subject: [Rd] How to deal with package conflicts
In-Reply-To: <1322230252.5806.15.camel@nemo>
References: <mailman.21.1322218808.15358.r-devel@r-project.org>
	<1322230252.5806.15.camel@nemo>
Message-ID: <4ECFB773.2060106@yorku.ca>

On 11/25/2011 9:10 AM, Terry Therneau wrote:
> The ridge() function was put into the survival package as a simple
> example of what a user could do with penalized functions.  It's not a
> "serious" function, and I'd be open to any suggestions for change.
>
> Actually, for any L2 penalty + Cox model one is now better off using
> coxme as the maximization process is much better thought out there.  I'd
> be happy to remove ridge from survival -- except that there are bound to
> be lots of folks using the function and any such changes (even good
> ones) to the survival package are fraught with peril.
Duncan provided one suggestion:  make ridge() an S3 generic, and rename 
ridge()
to ridge.coxph(), but this won't work, since you use ridge() inside 
coxph() and
survreg() to add a penalty term in the model formula.
Another idea might be simply to not export ridge(), but I have the 
feeling this will break
your R CMD checks.

Alternatively, my particular problem (wanting to use car::vif in my 
package documentation) would
be solved if John Fox considered making making survival a Suggests: 
package rather than a
Depends: one.  This might work, since survival is only referenced in car 
by providing Anova()
methods for coxph models.

I think all of this raises a general issue of unintended consequences of 
"package bloat," where
(a) Depends: packages are forced to load by require()/library(), whether 
they are really needed or not;
(b) There is nothing like require(car, depends=FALSE) to circumvent this;
(c) Once a require()'d package is loaded, it cannot be unloaded;
(d) AFAIK, there is no way for a package author to override the masking 
of functions or data
provided by other other packages, except by using mypackage::myfun() calls.

To me this seems to be a flaw in the namespace mechanism.

best,
-Michael







-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From jorismeys at gmail.com  Fri Nov 25 16:47:36 2011
From: jorismeys at gmail.com (Joris Meys)
Date: Fri, 25 Nov 2011 16:47:36 +0100
Subject: [Rd] Case: package removed from CRAN, but not orphaned
In-Reply-To: <4ECFB0A6.30504@statistik.tu-dortmund.de>
References: <FCD9A33C859ACC469587CB09DD5C6C71230C6D@GBLONXMB11.corp.amvescap.net>
	<4ECFA755.9020204@statistik.tu-dortmund.de>
	<CAGhLh6HT4sF_Qqe9TmmXTHLdwEZZa_C0mTfcHa7r=wtLZEGLLw@mail.gmail.com>
	<4ECFB0A6.30504@statistik.tu-dortmund.de>
Message-ID: <CAO1zAVZxYfKVCNgXBAgGc45XXkBS9Vg8Rkvbyj0bU=T59goLQQ@mail.gmail.com>

I agree completely with Uwe on this one. Yet, the idea of Rainer is
useful if you replace "remove the package" by "orphan the package".
Some sort of automated orphanization. The package remains available
that way if I understood it right, and can more easily be adopted by
another developer that feels responsible. It might also make the
manual cleanup (i.e. detecting poorly maintained packages without a
responsive developer) a bit easier. After all, clicking a link once
every so often to indicate you're still following the package isn't
too much work for a package developer, and it could help the CRAN
maintainers. Or am I completely off here?

Cheers
Joris

2011/11/25 Uwe Ligges <ligges at statistik.tu-dortmund.de>:
>
>
> On 25.11.2011 16:04, Rainer M Krug wrote:
>>
>> 2011/11/25 Uwe Ligges<ligges at statistik.tu-dortmund.de>
>>
>>> On 25.11.2011 11:56, Pfaff, Bernhard Dr. wrote:
>>>
>>>> Dear R-Devel subscriber,
>>>>
>>>> I would like to raise a topic and ask for your advice, guidance.
>>>> Today on R-help an issue with a certain package popped up that has been
>>>> removed from CRAN, because it failed the checks and/or the dependencies
>>>> are
>>>> not any longer available. The package maintainer has been alerted to
>>>> this
>>>> issue a couple of times and kindly asked to fix the code, such that it
>>>> fullfills the CRAN requirements. However, neither a fix is applied, nor
>>>> has
>>>> the package been orphaned such that someone else could take over the
>>>> ownership and rectify the package.
>>>> In principal, and if I am not mistaken, one could simply take the code,
>>>> fix it and release it (the package is under GPL-2). However, I would
>>>> consider this as a rather rude approach. Hence, my question would be, if
>>>> the R Core team can take the initiative, to declare the package as being
>>>> orphaned after a 'warning period' has been elapsed in which the current
>>>> maintainer is kindly asked to fix his package. Would it be feasible to
>>>> ask
>>>> R Core to orphan a package?
>>>>
>>>> Best,
>>>> Bernhard
>>>>
>>>> ps: Incidentally, I am aware of the new 'orphaned package rules', in
>>>> particular under the rubrique 'Possible reasons for orphanizing a
>>>> package',
>>>> point 2). In the case of the package in question, the maintainer does
>>>> respond to emails, but either seems to lack action and/or has a
>>>> different
>>>> time scale and awareness of time.
>>>>
>>>
>>>
>>> As Duncan wrote already, CRAN is not run by R-core - as you probably
>>> know,
>>> I have already maintained parts of CRAN for quite some time before I
>>> became
>>> core member.
>>>
>>> Let me as one of the CRAN maintainers add:
>>>
>>> We know that orphaning would be a nice hint to the community, but it
>>> takes
>>> some work and given we have>> ?3000 packages, many of them not well
>>> maintained, we have to archive or orphan many packages a year nowadays.
>>> Due
>>> the already huge amount of work CRAN maintenance generates, we simply
>>> cannot invest more time given the time constraints.
>>>
>>> Note that we archive packages if a maintainer asks us to do so or if the
>>> maintainer is unresponsive on our requests to fix the package. Since we
>>> as
>>> CRAN maintainers were unsuccessful to contact or convince the maintainer
>>> to
>>> fix, we typically won't invest more time/work on such a package.
>>>
>>> Of course, if someone wants to take over an archived package and cannot
>>> get a response from the maintainer (but first try to do so yourself!)
>>> then
>>> a request to take over as maintainer can be sent to CRAN.
>>>
>>> Currently we are working on a new CRAN policy document that will soon be
>>> published. This document may clarify some further questions and
>>> establishes
>>> some stricter policies to reduce the workload of CRAN maintainers.
>>>
>>
>> Just as an idea to make sure that CRAN only contains maintained packages
>> with a maintainer who feels responsible: Would it be feasible to introduce
>> a system, so that each year (or for each release of a new version of R)
>> the
>> maintainers are automatically contacted via email and must reply to have
>> their packages included in the new spring cleaned version of CRAN?
>> This
>> process could be automated, including the email confirmations (like
>> mailing
>> list subscriptions) and the non-maintained packages could be relocated to
>> a
>> second CRAN or marked as "will be removed at next springclean"? This would
>> make sure that CRAN contains only "active" packages.
>
> 1. There is no reason to remove well working packages.
> 2. Removing packages with many reverse dependencies just because the
> maintainers are not reacting on auto-messages is not feasible: it multiplies
> the work.
>
> Best wishes,
> Uwe Ligges
>
>
>
>> Cheers,
>>
>> Rainer
>>
>>
>>>
>>> Best wishes,
>>> Uwe Ligges
>>>
>>>
>>>
>>>
>>>
>>>
>>>> *********************************************************************
>>>> Confidentiality Note: The information contained in this
>>>> ...{{dropped:10}}
>>>>
>>>> ______________________________**________________
>>>> R-devel at r-project.org mailing list
>>>>
>>>> https://stat.ethz.ch/mailman/**listinfo/r-devel<https://stat.ethz.ch/mailman/listinfo/r-devel>
>>>>
>>>
>>> ______________________________**________________
>>> R-devel at r-project.org mailing list
>>>
>>> https://stat.ethz.ch/mailman/**listinfo/r-devel<https://stat.ethz.ch/mailman/listinfo/r-devel>
>>>
>>
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Joris Meys
Statistical consultant

Ghent University
Faculty of Bioscience Engineering
Department of Mathematical Modelling, Statistics and Bio-Informatics

tel : +32 9 264 59 87
Joris.Meys at Ugent.be
-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From therneau at mayo.edu  Fri Nov 25 17:08:26 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Fri, 25 Nov 2011 10:08:26 -0600
Subject: [Rd] How to deal with package conflicts
In-Reply-To: <4ECFB773.2060106@yorku.ca>
References: <mailman.21.1322218808.15358.r-devel@r-project.org>
	<1322230252.5806.15.camel@nemo>  <4ECFB773.2060106@yorku.ca>
Message-ID: <1322237306.5806.92.camel@nemo>


On Fri, 2011-11-25 at 10:42 -0500, Michael Friendly wrote:
> Duncan provided one suggestion:  make ridge() an S3 generic, and
> rename ridge()
> to ridge.coxph(), but this won't work, since you use ridge() inside 
> coxph() and survreg() to add a penalty term in the model formula.
> Another idea might be simply to not export ridge(), but I have the 
> feeling this will break your R CMD checks.
> 

The S3 generic idea won't work.  The argument inside ridge(x) is an
ordinary variable, and it's the argument inside that a generic uses for
dispatch.  I want to dispatch based on the context, which is what the
namespace mechanism does for a call to for instance coxpenal.fit, a non
exported survival function.  
  
I suspect that not exporting ridge would work for
	coxph(Surv(time, status) ~ ph.ecog + ridge(age), data=lung)
but not for
      myform <-Surv(time, status) ~ ph.ecog + ridge(age)
      coxph(myform, data=lung)

(I haven't test this)  This is because formulas are treated rather like
functions, with bindings coming into play when they are first defined,
not when they are first used. 

> Alternatively, my particular problem (wanting to use car::vif in my 
> package documentation) would
> be solved if John Fox considered making making survival a Suggests: 
> package rather than a
> Depends: one.  This might work, since survival is only referenced in
> car 
> by providing Anova()
> methods for coxph models.
> 
> I think all of this raises a general issue of unintended consequences
> of 
> "package bloat," where
> (a) Depends: packages are forced to load by require()/library(),
> whether 
> they are really needed or not;
> (b) There is nothing like require(car, depends=FALSE) to circumvent
> this;
> (c) Once a require()'d package is loaded, it cannot be unloaded;
> (d) AFAIK, there is no way for a package author to override the
> masking 
> of functions or data
> provided by other other packages, except by using mypackage::myfun()
> calls.
> 
> To me this seems to be a flaw in the namespace mechanism.
> 
> 
 I will say that the long list of "reverse depends" on the survival
package does give me pause when making changes.

Terry T.


From ggrothendieck at gmail.com  Fri Nov 25 17:28:34 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 25 Nov 2011 11:28:34 -0500
Subject: [Rd] How to deal with package conflicts
In-Reply-To: <1322235424.5806.80.camel@nemo>
References: <mailman.21.1322218808.15358.r-devel@r-project.org>
	<1322230252.5806.15.camel@nemo> <4ECFAB1C.7040607@gmail.com>
	<1322235424.5806.80.camel@nemo>
Message-ID: <CAP01uRmcQ16A9r0npH_XNXFD-racQ91NOyqj72jzhwVTBWV=eg@mail.gmail.com>

On Fri, Nov 25, 2011 at 10:37 AM, Terry Therneau <therneau at mayo.edu> wrote:
>
> On Fri, 2011-11-25 at 09:50 -0500, Duncan Murdoch wrote:
>> I think the general idea in formulas is that it is up to the user to
>> define the meaning of functions used in them. ?Normally the user has
>> attached the package that is working on the formula, so the package
>> author can provide useful things like s(), but if a user wanted to
>> redefine s() to their own function, that should be possible.
>> Formulas
>> do have environments attached, so both variables and functions should
>> be
>> looked up there.
>>
>
> I don't agree that this is the best way. ?A function like coxph could
> easily have in its documentation a list of the "formula specials" that
> it defines internally. ?If the user want something of their own they can
> easily use a different word. ?In fact, I would strongly recommend that
> they don't use one of these key names. ?For things that work across
> mutiple packages like ns(), what user in his right mind would redefine
> it?
> ?So I re-raise the question. ?Is there a reasonably simple way to make
> the survival ridge() function specific to survival formulas? ?It sets up
> structures that have no meaning anywhere else, and its global definition
> stands in the way of other sensible uses. ?Having it be not exported +
> obey namespace type sematics would be a plus all around.
>
> Philosophical aside:
> ?I have discovered to my dismay that formulas do have environments
> attached, and that variables/functions are looked up there. ?This made
> sensible semantics for predict() within a function impossible for some
> of the survival functions, unless I were to change all the routines to a
> model=TRUE default. ?(And a change of that magnitude to survival, with
> its long list of dependencies, is not fun to contemplate. ?A very quick
> survey reveals several dependent packages will break.) So I don't agree
> nearly so fully with the "should" part of your last sentence. ?The out
> of context evaluations allowed by environments are, I find, always
> tricky and often lead to intricate special cases.
> ?Thus, moving back and forth between how it seems that a formula should
> work, and how it actually does work, sometimes leaves my head
> spinning.
>

The dynlm package uses formula functions which are specific to it.
Look at its code.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From murdoch.duncan at gmail.com  Fri Nov 25 17:37:51 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 25 Nov 2011 11:37:51 -0500
Subject: [Rd] How to deal with package conflicts
In-Reply-To: <1322235424.5806.80.camel@nemo>
References: <mailman.21.1322218808.15358.r-devel@r-project.org>	
	<1322230252.5806.15.camel@nemo> <4ECFAB1C.7040607@gmail.com>
	<1322235424.5806.80.camel@nemo>
Message-ID: <4ECFC45F.8040209@gmail.com>

On 25/11/2011 10:37 AM, Terry Therneau wrote:
> On Fri, 2011-11-25 at 09:50 -0500, Duncan Murdoch wrote:
> >  I think the general idea in formulas is that it is up to the user to
> >  define the meaning of functions used in them.  Normally the user has
> >  attached the package that is working on the formula, so the package
> >  author can provide useful things like s(), but if a user wanted to
> >  redefine s() to their own function, that should be possible.
> >  Formulas
> >  do have environments attached, so both variables and functions should
> >  be
> >  looked up there.
> >
>
> I don't agree that this is the best way.  A function like coxph could
> easily have in its documentation a list of the "formula specials" that
> it defines internally.  If the user want something of their own they can
> easily use a different word.  In fact, I would strongly recommend that
> they don't use one of these key names.  For things that work across
> mutiple packages like ns(), what user in his right mind would redefine
> it?

Yes, that's what I described in the second part of my answer, and you 
can do it too in coxph.  It requires some work to do special processing 
of symbols in a formula, but it is already being done for + and : and *, 
so doing it as well for some other functions would be reasonable.  If 
you don't mind some programming on the formula object, it's not even 
very hard.

As to a user defining their own ns() function:  that seems like it's not 
something we should disallow, especially if it was done in a context 
where natural splines weren't being used.  It might have nothing to do 
with the ns() function in the splines package, but it might mean 
something to the user in terms of his own data.  The splines package is 
a base package so it's not a great idea to re-use the name, but many 
users would not have splines attached, and wouldn't notice that they had 
just masked the splines::ns function.

>    So I re-raise the question.  Is there a reasonably simple way to make
> the survival ridge() function specific to survival formulas?  It sets up
> structures that have no meaning anywhere else, and its global definition
> stands in the way of other sensible uses.  Having it be not exported +
> obey namespace type sematics would be a plus all around.

Yes, there is a way to do what you want.  Don't export the function from 
the package, but preprocess formulas coming into coxph to substitute 
things that look like calls to ridge() with calls to something local.

For example, this does the substitution.  I haven't checked it much, so 
it might mess up something else (and there might be
more elegant ways to write it, using e.g. rapply).  It is definitely 
slightly more elaborate than it needs to be (no need for the separate 
local function), but that's so you can make the outer function do a bit 
more than the recursive part does.

fixRidge <- function( formula ) {

   recurse <- function( e ) {
     if (length(e) == 1) {
        if (as.character(e) == "ridge") e <- quote(survival:::ridge)
     }  else for (i in seq_along(e))
           e[[i]] <- recurse(e[[i]])
    e
   }

   recurse(formula)
}

This replace calls to ridge in the formula with calls to survival:::ridge.


> Philosophical aside:
>    I have discovered to my dismay that formulas do have environments
> attached, and that variables/functions are looked up there.  This made
> sensible semantics for predict() within a function impossible for some
> of the survival functions, unless I were to change all the routines to a
> model=TRUE default.  (And a change of that magnitude to survival, with
> its long list of dependencies, is not fun to contemplate.  A very quick
> survey reveals several dependent packages will break.) So I don't agree
> nearly so fully with the "should" part of your last sentence.  The out
> of context evaluations allowed by environments are, I find, always
> tricky and often lead to intricate special cases.
>    Thus, moving back and forth between how it seems that a formula should
> work, and how it actually does work, sometimes leaves my head
> spinning.
>

It all comes down to the question:  who owns the name?  Generally the 
caller owns the name.  So you should look it up in the context of the 
caller.  In R, that means you need to carry along the environment of the 
caller.

Duncan Murdoch

> Terry T.
>
>
> Terry Therneau
>


From jfox at mcmaster.ca  Fri Nov 25 17:46:41 2011
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 25 Nov 2011 11:46:41 -0500
Subject: [Rd] How to deal with package conflicts
In-Reply-To: <4ECFB773.2060106@yorku.ca>
References: <mailman.21.1322218808.15358.r-devel@r-project.org>
	<1322230252.5806.15.camel@nemo> <4ECFB773.2060106@yorku.ca>
Message-ID: <000501ccab91$d0092690$701b73b0$@mcmaster.ca>

Hi Michael,

I'll look into moving survival to suggests (this weekend, if I have time),
but that doesn't address the more general issue.

Best,
 John

> -----Original Message-----
> From: Michael Friendly [mailto:friendly at yorku.ca]
> Sent: November-25-11 10:43 AM
> To: Terry Therneau
> Cc: r-devel at r-project.org; John Fox; Duncan Murdoch
> Subject: Re: [Rd] How to deal with package conflicts
> 
> On 11/25/2011 9:10 AM, Terry Therneau wrote:
> > The ridge() function was put into the survival package as a simple
> > example of what a user could do with penalized functions.  It's not a
> > "serious" function, and I'd be open to any suggestions for change.
> >
> > Actually, for any L2 penalty + Cox model one is now better off using
> > coxme as the maximization process is much better thought out there.
> > I'd be happy to remove ridge from survival -- except that there are
> > bound to be lots of folks using the function and any such changes
> > (even good
> > ones) to the survival package are fraught with peril.
> Duncan provided one suggestion:  make ridge() an S3 generic, and rename
> ridge()
> to ridge.coxph(), but this won't work, since you use ridge() inside
> coxph() and
> survreg() to add a penalty term in the model formula.
> Another idea might be simply to not export ridge(), but I have the
> feeling this will break your R CMD checks.
> 
> Alternatively, my particular problem (wanting to use car::vif in my
> package documentation) would be solved if John Fox considered making
> making survival a Suggests:
> package rather than a
> Depends: one.  This might work, since survival is only referenced in
> car by providing Anova() methods for coxph models.
> 
> I think all of this raises a general issue of unintended consequences
> of "package bloat," where
> (a) Depends: packages are forced to load by require()/library(),
> whether they are really needed or not;
> (b) There is nothing like require(car, depends=FALSE) to circumvent
> this;
> (c) Once a require()'d package is loaded, it cannot be unloaded;
> (d) AFAIK, there is no way for a package author to override the masking
> of functions or data provided by other other packages, except by using
> mypackage::myfun() calls.
> 
> To me this seems to be a flaw in the namespace mechanism.
> 
> best,
> -Michael
> 
> 
> 
> 
> 
> 
> 
> --
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept.
> York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:   http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA


From therneau at mayo.edu  Fri Nov 25 18:12:29 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Fri, 25 Nov 2011 11:12:29 -0600
Subject: [Rd] How to deal with package conflicts
In-Reply-To: <4ECFB773.2060106@yorku.ca>
References: <mailman.21.1322218808.15358.r-devel@r-project.org>
	<1322230252.5806.15.camel@nemo>  <4ECFB773.2060106@yorku.ca>
Message-ID: <1322241149.5806.120.camel@nemo>

 I like the idea of making the functions local, and will persue it.
This issue has bothered me for a long time -- I had real misgivings when
I introduced "cluster" to the package, but did not at that time see any
way other than making it global.  
 I might make this change soon in the ridge function, since it's a good
test case -- less likely to cause downstream troubles.

Here is another possible approach:
 Inside coxph, just before calling eval with the formula, create a new
environment "tempenv" which consists of my handful of special functions
(ridge, frailty, cluster, pspline) who have meaning only inside a coxph
call, with a parent environment of the tempenv being the current
environment of the formula. Then set the environment of the formula to
tempenv, then eval.  Would this work?

 Two small further questions:
1. Any special rules for the documentation?  We need a page for
"cluster", but want to mark it almost like a method in the sense of
applying only in a one context.

2. Does one scheme or another work best for downstream functions like
predict or model.matrix?  Duncan's idea of direct modification might
have an advantage (?) in that the terms object would be permanently
changed.

Terry T.


From murdoch.duncan at gmail.com  Fri Nov 25 19:37:18 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 25 Nov 2011 13:37:18 -0500
Subject: [Rd] How to deal with package conflicts
In-Reply-To: <1322241149.5806.120.camel@nemo>
References: <mailman.21.1322218808.15358.r-devel@r-project.org>	
	<1322230252.5806.15.camel@nemo> <4ECFB773.2060106@yorku.ca>
	<1322241149.5806.120.camel@nemo>
Message-ID: <4ECFE05E.9050103@gmail.com>

On 25/11/2011 12:12 PM, Terry Therneau wrote:
>   I like the idea of making the functions local, and will persue it.
> This issue has bothered me for a long time -- I had real misgivings when
> I introduced "cluster" to the package, but did not at that time see any
> way other than making it global.
>   I might make this change soon in the ridge function, since it's a good
> test case -- less likely to cause downstream troubles.
>
> Here is another possible approach:
>   Inside coxph, just before calling eval with the formula, create a new
> environment "tempenv" which consists of my handful of special functions
> (ridge, frailty, cluster, pspline) who have meaning only inside a coxph
> call, with a parent environment of the tempenv being the current
> environment of the formula. Then set the environment of the formula to
> tempenv, then eval.  Would this work?

It should.
>   Two small further questions:
> 1. Any special rules for the documentation?  We need a page for
> "cluster", but want to mark it almost like a method in the sense of
> applying only in a one context.

I would list those special functions as aliases of the coxph topic, and 
document them there.

> 2. Does one scheme or another work best for downstream functions like
> predict or model.matrix?  Duncan's idea of direct modification might
> have an advantage (?) in that the terms object would be permanently
> changed.

As long as you attach your new temporary environment to copies of the 
formula that you pass elsewhere, it should mostly work.  It may confuse 
someone who did  ls(environment(formula)) (because they'd only see your 
functions, not the user's), but I don't think that's a very common thing 
to want to do.

Duncan Murdoch


From gray.calhoun at gmail.com  Sat Nov 26 00:12:03 2011
From: gray.calhoun at gmail.com (Gray Calhoun)
Date: Fri, 25 Nov 2011 18:12:03 -0500
Subject: [Rd] Problem with & question about \preformatted in .Rd
Message-ID: <CAGLwjoxLJdLDL+ax7sC5_yoCdbvtrJHwsmM65zNQ9=Aty8UXHw@mail.gmail.com>

Hi,

The "\preformatted" environment in Rd files doesn't seem to escape
long sequences of backslashes properly when converted to pdf (LaTeX)
documentation.  I'm running R version 2.14 (from subversion, revision
57751) on Linux (RHEL).  Here's an example from the command line:

echo "\title{test}\name{test}\section{problems}{\preformatted{print('\\\\\\\\begin\\\\\{block\\\\\}')}}"
> temp.Rd
R CMD Rdconv --type=latex temp.Rd

which outputs:

\inputencoding{utf8}
\HeaderA{test}{test}{test}
%
\begin{Section}{problems}
\begin{alltt}print('\\\\begin\\{block\\}')\end{alltt}
\end{Section}

and the double backslashes become newlines when this text is embedded
in a complete document and converted to pdf.  I expected from the
documentation to get this:

\inputencoding{utf8}
\HeaderA{test}{test}{test}
%
\begin{Section}{problems}
\begin{alltt}print('\bsl{}\bsl{}\bsl{}\begin\bsl{}\bsl{}\{block\bsl{}\bsl{}\}')\end{alltt}
\end{Section}

The problem seems to come from tools:::Rd2latex as this R code indicates:

library(tools)
tools:::Rd2latex(textConnection("\\title{test}\\name{test}
\\section{problems}{
\\preformatted{
print('\\\\\\\\\\\\\\\\begin\\\\\\\\\\{block\\\\\\\\\\}')
}}"))

(the output is the same as from the command line above)

I can get the behavior that I want by removing a few lines from the
relevant part of tools:::Rd2latex and I provide a patch below, but I
assume that the code that I removed was put there for a good reason so
this isn't a good fix.  make check-devel didn't find any errors,
though.

I'm happy to fill out a bug report for this if that's the next appropriate step.

A question: why is there special code to handle "\var" inside
\preformatted environments?  The documentation reads:

"\preformatted{text}
    Indicate text that is a literal example of a piece of a program.
Text is displayed using typewriter font if possible. Formatting, e.g.
line breaks, is preserved.

    Due to limitations in LaTeX as of this writing, this macro may not
be nested within other markup macros other than \dQuote and \sQuote,
as errors or bad formatting may result."

which doesn't indicate that \var should be handled any differently
than any other macro, but the code makes me think that R is trying to
pass the macro through to LaTeX.

Thanks!

--Gray

-- 
Gray Calhoun

Assistant Professor of Economics, Iowa State University
http://www.econ.iastate.edu/~gcalhoun

patch:

Index: src/library/tools/R/Rd2latex.R
===================================================================
--- src/library/tools/R/Rd2latex.R      (revision 57751)
+++ src/library/tools/R/Rd2latex.R      (working copy)
@@ -163,10 +163,7 @@
                BSL = '@BSL@';
                BSL2 = '@BSLBSL@';
                #x <- fsub("\\dots", "...", x)
-               ## escape any odd \, e.g. \n
-               x <- fsub("\\\\", BSL, x) # change even ones
                x <- fsub("\\", BSL2, x)  # odd ones
-               x <- fsub(BSL, "\\\\", x) # change back
                x <- psub("(?<!\\\\)\\{", "\\\\{", x)
                x <- psub("(?<!\\\\)}", "\\\\}", x)
                x <- fsub(BSL2, "\\bsl{}", x)library(tools)


From therneau at mayo.edu  Sat Nov 26 05:20:22 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Fri, 25 Nov 2011 22:20:22 -0600
Subject: [Rd] 32 vs 64 bit difference?
Message-ID: <201111260420.pAQ4KMRa005363@nemo.mayo.edu>

I've spent the last few hours baffled by a test suite inconsistency.

The exact same library code gives slightly different answers on the home 
and work machines  - found in my R CMD check run.  I've recopied the entire
directory to make sure it's really identical code. 
  The data set and fit in question has a pretty flat "top" to the likelihood.
I put print statements in to the "f()" function called by optim, and the
two parameters and the likelihood track perfectly for 48 iterations, then
start to drift ever so slightly:
< theta= -3.254176 -6.201119 ilik= -16.64806 
> theta= -3.254176 -6.201118 ilik= -16.64806 

And at the end of the iteration:
< theta= -3.207488 -8.583329 ilik= -16.70139 
> theta= -3.207488 -8.583333 ilik= -16.70139 

As you can see, they get to the same max, but with just a slightly
different path.

  The work machine is running 64 bit Unix (CentOS) and the home one 32 bit
Ubuntu.
Could this be enough to cause the difference?  Most of my tests are
based on all.equal, but I also print out 1 or 2 full solutions; perhaps 
I'll have to modify that?

Terry Therneau


From pdalgd at gmail.com  Sat Nov 26 10:23:42 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 26 Nov 2011 10:23:42 +0100
Subject: [Rd] 32 vs 64 bit difference?
In-Reply-To: <201111260420.pAQ4KMRa005363@nemo.mayo.edu>
References: <201111260420.pAQ4KMRa005363@nemo.mayo.edu>
Message-ID: <49A4CBB9-37D2-4D42-A444-A9529125813B@gmail.com>


On Nov 26, 2011, at 05:20 , Terry Therneau wrote:

> I've spent the last few hours baffled by a test suite inconsistency.
> 
> The exact same library code gives slightly different answers on the home 
> and work machines  - found in my R CMD check run.  I've recopied the entire
> directory to make sure it's really identical code. 
>  The data set and fit in question has a pretty flat "top" to the likelihood.
> I put print statements in to the "f()" function called by optim, and the
> two parameters and the likelihood track perfectly for 48 iterations, then
> start to drift ever so slightly:
> < theta= -3.254176 -6.201119 ilik= -16.64806 
>> theta= -3.254176 -6.201118 ilik= -16.64806 
> 
> And at the end of the iteration:
> < theta= -3.207488 -8.583329 ilik= -16.70139 
>> theta= -3.207488 -8.583333 ilik= -16.70139 
> 
> As you can see, they get to the same max, but with just a slightly
> different path.
> 
>  The work machine is running 64 bit Unix (CentOS) and the home one 32 bit
> Ubuntu.
> Could this be enough to cause the difference?  Most of my tests are
> based on all.equal, but I also print out 1 or 2 full solutions; perhaps 
> I'll have to modify that?

We do see quite a lot of that, yes; even running 32 and 64 bit builds on the same machine, an sometimes to the extent that an algorithm diverges on one architecture and diverges on the other (just peek over on R-sig-ME). The comparisons by "make check" on R itself also give off quite a bit of "last decimal chatter" when the architecture is switched. For some reason, OSX builds seem more consistent than Windows and Linux, although I have only anecdotal evidence of that. 

However, the basic point is that compilers don't define the sequence of FPU operations down to the last detail, an internal extended-precision register may or may not be used, the order of terms in a sum may be changed, etc. Since 64 bit code has different performance characteristics from 32 bit code (since you shift more data around for pointers), the FPU instructions may be differently optimized too. 

> 
> Terry Therneau
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ripley at stats.ox.ac.uk  Sat Nov 26 12:37:09 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 26 Nov 2011 11:37:09 +0000
Subject: [Rd] 32 vs 64 bit difference?
In-Reply-To: <49A4CBB9-37D2-4D42-A444-A9529125813B@gmail.com>
References: <201111260420.pAQ4KMRa005363@nemo.mayo.edu>
	<49A4CBB9-37D2-4D42-A444-A9529125813B@gmail.com>
Message-ID: <4ED0CF65.4030802@stats.ox.ac.uk>

On 26/11/2011 09:23, peter dalgaard wrote:
>
> On Nov 26, 2011, at 05:20 , Terry Therneau wrote:
>
>> I've spent the last few hours baffled by a test suite inconsistency.
>>
>> The exact same library code gives slightly different answers on the home
>> and work machines  - found in my R CMD check run.  I've recopied the entire
>> directory to make sure it's really identical code.
>>   The data set and fit in question has a pretty flat "top" to the likelihood.
>> I put print statements in to the "f()" function called by optim, and the
>> two parameters and the likelihood track perfectly for 48 iterations, then
>> start to drift ever so slightly:
>> <  theta= -3.254176 -6.201119 ilik= -16.64806
>>> theta= -3.254176 -6.201118 ilik= -16.64806
>>
>> And at the end of the iteration:
>> <  theta= -3.207488 -8.583329 ilik= -16.70139
>>> theta= -3.207488 -8.583333 ilik= -16.70139
>>
>> As you can see, they get to the same max, but with just a slightly
>> different path.
>>
>>   The work machine is running 64 bit Unix (CentOS) and the home one 32 bit
>> Ubuntu.
>> Could this be enough to cause the difference?  Most of my tests are
>> based on all.equal, but I also print out 1 or 2 full solutions; perhaps
>> I'll have to modify that?
>
> We do see quite a lot of that, yes; even running 32 and 64 bit builds on the same machine, an sometimes to the extent that an algorithm diverges on one architecture and diverges on the other (just peek over on R-sig-ME). The comparisons by "make check" on R itself also give off quite a bit of "last decimal chatter" when the architecture is switched. For some reason, OSX builds seem more consistent than Windows and Linux, although I have only anecdotal evidence of that.
>
> However, the basic point is that compilers don't define the sequence of FPU operations down to the last detail, an internal extended-precision register may or may not be used, the order of terms in a sum may be changed, etc. Since 64 bit code has different performance characteristics from 32 bit code (since you shift more data around for pointers), the FPU instructions may be differently optimized too.

However, the main difference is that all x86_64 chips have SSE2 
registers, and so gcc makes use of them.  Not all i686 chips do, so 
32-bit builds on Linux and Windows only use the FPU registers.

This matters at ABI level: arguments get passed and values returned in 
SSE registers: so we can't decide to only support later i686 cpus and 
make use of SSE2 without re-compiling all the system libraries (but a 
Linux distributor could).

And the FPU registers are 80-bit and use extended precision (the way we 
set up Windows and on every Linux system I have seen): the SSE* 
registers are 2x64-bit.

I believe that all Intel Macs are 'Core' or later and so do have SSE2, 
although I don't know how much Apple relies on that.

(The reason I know that this is the 'main difference' is that you can 
often turn off the use of SSE2 on x86_64 and reproduce the i686 results. 
  But because of the ABI differences, you may get crashes: in R this 
matters most often for complex numbers which are 128-bit C99 double 
complex and passed around in an SSE register.)

>>
>> Terry Therneau
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From bbolker at gmail.com  Sat Nov 26 23:58:22 2011
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 26 Nov 2011 22:58:22 +0000
Subject: [Rd] Case: package removed from CRAN, but not orphaned
References: <FCD9A33C859ACC469587CB09DD5C6C71230C6D@GBLONXMB11.corp.amvescap.net>
	<4ECFA755.9020204@statistik.tu-dortmund.de>
	<CAGhLh6HT4sF_Qqe9TmmXTHLdwEZZa_C0mTfcHa7r=wtLZEGLLw@mail.gmail.com>
	<4ECFB0A6.30504@statistik.tu-dortmund.de>
	<CAO1zAVZxYfKVCNgXBAgGc45XXkBS9Vg8Rkvbyj0bU=T59goLQQ@mail.gmail.com>
Message-ID: <loom.20111126T233913-971@post.gmane.org>

Joris Meys <jorismeys <at> gmail.com> writes:

> 
> I agree completely with Uwe on this one. Yet, the idea of Rainer is
> useful if you replace "remove the package" by "orphan the package".
> Some sort of automated orphanization. The package remains available
> that way if I understood it right, and can more easily be adopted by
> another developer that feels responsible. It might also make the
> manual cleanup (i.e. detecting poorly maintained packages without a
> responsive developer) a bit easier. After all, clicking a link once
> every so often to indicate you're still following the package isn't
> too much work for a package developer, and it could help the CRAN
> maintainers. Or am I completely off here?
> 

  Just a tiny update: 

  Thanks to the great new "packdep" package, it's very easy
to find out how many of the packages on CRAN have *no* reverse
dependencies:

library(packdep)
d1 <- map.depends()
c <- dependencies(d1)
sum(c$reverse==0)/nrow(c)

  66%.  Furthermore, I would guess that orphaned packages would be
more likely to be in this 66%.  What about exempting packages with
any reverse dependencies from the auto-orphanization process?

  Ben Bolker


From gray.calhoun at gmail.com  Sun Nov 27 06:34:26 2011
From: gray.calhoun at gmail.com (Gray Calhoun)
Date: Sun, 27 Nov 2011 00:34:26 -0500
Subject: [Rd] Problem with & question about \preformatted in .Rd
In-Reply-To: <CAGLwjoxLJdLDL+ax7sC5_yoCdbvtrJHwsmM65zNQ9=Aty8UXHw@mail.gmail.com>
References: <CAGLwjoxLJdLDL+ax7sC5_yoCdbvtrJHwsmM65zNQ9=Aty8UXHw@mail.gmail.com>
Message-ID: <CAGLwjozhVrGi3BcVOGttyA+LFfQksHLqBO_yrgKZJ0T2SO3NtQ@mail.gmail.com>

I need to correct one minor typo below:

On Fri, Nov 25, 2011 at 6:12 PM, Gray Calhoun <gray.calhoun at gmail.com> wrote:
(cut a lot)
> ?I expected from the documentation to get this:
>
> \inputencoding{utf8}
> \HeaderA{test}{test}{test}
> %
> \begin{Section}{problems}
> \begin{alltt}print('\bsl{}\bsl{}\bsl{}\begin\bsl{}\bsl{}\{block\bsl{}\bsl{}\}')\end{alltt}
> \end{Section}

The second to last line should read:
\begin{alltt}print('\bsl{}\bsl{}\bsl{}\bsl{}begin\bsl{}\bsl{}\{block\bsl{}\bsl{}\}')\end{alltt}
Sorry about that.

--Gray


-- 
Gray Calhoun

Assistant Professor of Economics, Iowa State University
http://www.econ.iastate.edu/~gcalhoun


From pdbailey at umd.edu  Sun Nov 27 22:46:48 2011
From: pdbailey at umd.edu (Paul Bailey)
Date: Sun, 27 Nov 2011 16:46:48 -0500
Subject: [Rd] Error in Rd[[which]] : subscript out of bounds
Message-ID: <399BD3B0-8276-4A8F-9F6D-C69E3E068FED@umd.edu>

I'm getting the following form R CMD CHECK mypackage
-----------
* checking Rd files ... WARNING
Error in Rd[[which]] : subscript out of bounds

problem found in ?myfunction.Rd?
---------
This is... not the most helpful error.

I'd be happy to make a minimal .Rd example file if someone can point me to what a minimal .Rd file has in it.

The file is already pretty minimal, so it's possible I've already gone to small and that is the reason for the error.

Best,
Paul Bailey

From hb at biostat.ucsf.edu  Sun Nov 27 23:17:10 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sun, 27 Nov 2011 14:17:10 -0800
Subject: [Rd] Error in Rd[[which]] : subscript out of bounds
In-Reply-To: <399BD3B0-8276-4A8F-9F6D-C69E3E068FED@umd.edu>
References: <399BD3B0-8276-4A8F-9F6D-C69E3E068FED@umd.edu>
Message-ID: <CAFDcVCRKKzY60EP4r-i9249-CRYF5-LXJSu6RRmf4ZLuWH2xdA@mail.gmail.com>

sessionInfo()?  If not R v2.14.0, try with that version first.  Then
have a look checkRd() of the 'tools' package, cf. help("checkRd",
package="tools").  That function allows you to check your Rd file from
within R so that you get more information/so that you can use
traceback() etc.

My $.02

/Henrik

On Sun, Nov 27, 2011 at 1:46 PM, Paul Bailey <pdbailey at umd.edu> wrote:
> I'm getting the following form R CMD CHECK mypackage
> -----------
> * checking Rd files ... WARNING
> Error in Rd[[which]] : subscript out of bounds
>
> problem found in ?myfunction.Rd?
> ---------
> This is... not the most helpful error.
>
> I'd be happy to make a minimal .Rd example file if someone can point me to what a minimal .Rd file has in it.
>
> The file is already pretty minimal, so it's possible I've already gone to small and that is the reason for the error.
>
> Best,
> Paul Bailey
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From pdbailey at umd.edu  Sun Nov 27 23:31:16 2011
From: pdbailey at umd.edu (Paul Bailey)
Date: Sun, 27 Nov 2011 17:31:16 -0500
Subject: [Rd] Error in Rd[[which]] : subscript out of bounds
In-Reply-To: <CAFDcVCRKKzY60EP4r-i9249-CRYF5-LXJSu6RRmf4ZLuWH2xdA@mail.gmail.com>
References: <399BD3B0-8276-4A8F-9F6D-C69E3E068FED@umd.edu>
	<CAFDcVCRKKzY60EP4r-i9249-CRYF5-LXJSu6RRmf4ZLuWH2xdA@mail.gmail.com>
Message-ID: <87082443-CE9A-400F-98B1-BBD1881C580E@umd.edu>

> sessionInfo()?  If not R v2.14.0, try with that version first.  Then
> have a look checkRd() of the 'tools' package, cf. help("checkRd",
> package="tools").  That function allows you to check your Rd file from
> within R so that you get more information/so that you can use
> traceback() etc.
> 

Sorry, should have said this is in 2.14.0.

Using traceback() as you suggested solved this problem for me, thanks. this made it pretty obvious:

2: checkUnique("\\description")

looks like I typed description when I wanted details.

Thanks!

Best,
Paul Bailey


From jfox at mcmaster.ca  Mon Nov 28 00:57:29 2011
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 27 Nov 2011 18:57:29 -0500
Subject: [Rd] How to deal with package conflicts
In-Reply-To: <7366_1322239705_pAPGm4IM009763_000501ccab91$d0092690$701b73b0$@mcmaster.ca>
References: <mailman.21.1322218808.15358.r-devel@r-project.org>	<1322230252.5806.15.camel@nemo>
	<4ECFB773.2060106@yorku.ca>
	<7366_1322239705_pAPGm4IM009763_000501ccab91$d0092690$701b73b0$@mcmaster.ca>
Message-ID: <003001ccad60$52bd5ff0$f8381fd0$@mcmaster.ca>

Hi Michael,

As promised, I've moved survival to Suggests in the development version of
the car package on R-Forge. AFAICS, this doesn't cause any problems (and
should solve your problem). 

I incidentally added Anova() and linearHypothesis() methods for svyglm
objects, and placed the survey package under Suggests.

Best,
 John

> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
> project.org] On Behalf Of John Fox
> Sent: November-25-11 11:47 AM
> To: 'Michael Friendly'
> Cc: 'Terry Therneau'; r-devel at r-project.org
> Subject: Re: [Rd] How to deal with package conflicts
> 
> Hi Michael,
> 
> I'll look into moving survival to suggests (this weekend, if I have
> time), but that doesn't address the more general issue.
> 
> Best,
>  John
> 
> > -----Original Message-----
> > From: Michael Friendly [mailto:friendly at yorku.ca]
> > Sent: November-25-11 10:43 AM
> > To: Terry Therneau
> > Cc: r-devel at r-project.org; John Fox; Duncan Murdoch
> > Subject: Re: [Rd] How to deal with package conflicts
> >
> > On 11/25/2011 9:10 AM, Terry Therneau wrote:
> > > The ridge() function was put into the survival package as a simple
> > > example of what a user could do with penalized functions.  It's not
> > > a "serious" function, and I'd be open to any suggestions for
> change.
> > >
> > > Actually, for any L2 penalty + Cox model one is now better off
> using
> > > coxme as the maximization process is much better thought out there.
> > > I'd be happy to remove ridge from survival -- except that there are
> > > bound to be lots of folks using the function and any such changes
> > > (even good
> > > ones) to the survival package are fraught with peril.
> > Duncan provided one suggestion:  make ridge() an S3 generic, and
> > rename
> > ridge()
> > to ridge.coxph(), but this won't work, since you use ridge() inside
> > coxph() and
> > survreg() to add a penalty term in the model formula.
> > Another idea might be simply to not export ridge(), but I have the
> > feeling this will break your R CMD checks.
> >
> > Alternatively, my particular problem (wanting to use car::vif in my
> > package documentation) would be solved if John Fox considered making
> > making survival a Suggests:
> > package rather than a
> > Depends: one.  This might work, since survival is only referenced in
> > car by providing Anova() methods for coxph models.
> >
> > I think all of this raises a general issue of unintended consequences
> > of "package bloat," where
> > (a) Depends: packages are forced to load by require()/library(),
> > whether they are really needed or not;
> > (b) There is nothing like require(car, depends=FALSE) to circumvent
> > this;
> > (c) Once a require()'d package is loaded, it cannot be unloaded;
> > (d) AFAIK, there is no way for a package author to override the
> > masking of functions or data provided by other other packages, except
> > by using
> > mypackage::myfun() calls.
> >
> > To me this seems to be a flaw in the namespace mechanism.
> >
> > best,
> > -Michael
> >
> >
> >
> >
> >
> >
> >
> > --
> > Michael Friendly     Email: friendly AT yorku DOT ca
> > Professor, Psychology Dept.
> > York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
> > 4700 Keele Street    Web:   http://www.datavis.ca
> > Toronto, ONT  M3J 1P3 CANADA
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From sachin.abeywardana at gmail.com  Mon Nov 28 00:07:12 2011
From: sachin.abeywardana at gmail.com (Sachinthaka Abeywardana)
Date: Mon, 28 Nov 2011 10:07:12 +1100
Subject: [Rd] Holding back on source code
Message-ID: <CAGuusR-xhP3Tdyg_Pr3sc_D=L7zAR5W4UT6hcDeU=aPKRB8Sfg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111128/927c1244/attachment.pl>

From ripley at stats.ox.ac.uk  Mon Nov 28 08:17:17 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 28 Nov 2011 07:17:17 +0000
Subject: [Rd] Holding back on source code
In-Reply-To: <CAGuusR-xhP3Tdyg_Pr3sc_D=L7zAR5W4UT6hcDeU=aPKRB8Sfg@mail.gmail.com>
References: <CAGuusR-xhP3Tdyg_Pr3sc_D=L7zAR5W4UT6hcDeU=aPKRB8Sfg@mail.gmail.com>
Message-ID: <4ED3357D.4090106@stats.ox.ac.uk>

On 27/11/2011 23:07, Sachinthaka Abeywardana wrote:
> Hi All,
>
> A few years back when I was a CSIRO (an Australian research centre) intern
> I developed a BLAS package for R that uses the GPU. I believe that there is
> something similar right now, except it uses a few CuBLAS (Nvidia BLAS)
> routines, but doesnt replace them.

We haven't much idea what 'something similar' refers to.

> My question is, is it technically illegal to hold back on source code?

It depends entirely on the licenses involved.  Nothing prevents Adobe 
distributing Acrobat without source code, for example.

This is the R development list: questions not specific to R are best 
asked elsewhere (and, to take a recent example, that includes questions 
about licenses of packages on R-forge or CRAN).  'Elsewhere' may mean an 
IP lawyer.

> Thanks,
> Sachin
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From therneau at mayo.edu  Mon Nov 28 14:55:33 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Mon, 28 Nov 2011 07:55:33 -0600
Subject: [Rd] 32 vs 64 bit difference?
In-Reply-To: <4ED0CF65.4030802@stats.ox.ac.uk>
References: <201111260420.pAQ4KMRa005363@nemo.mayo.edu>
	<49A4CBB9-37D2-4D42-A444-A9529125813B@gmail.com>
	<4ED0CF65.4030802@stats.ox.ac.uk>
Message-ID: <1322488533.8752.5.camel@nemo>

Thank you both for the nice explanation.  I added "digits=4" to my
print statements to shorten the display.  
 Mixed effects Cox models can have difficult numerical issues, as it
turns out; I've added this to my collection of things to watch for.

Terry Therneau



On Sat, 2011-11-26 at 11:37 +0000, Prof Brian Ripley wrote:
> On 26/11/2011 09:23, peter dalgaard wrote:
> >
> > On Nov 26, 2011, at 05:20 , Terry Therneau wrote:
> >
> >> I've spent the last few hours baffled by a test suite inconsistency.
> >>
> >> The exact same library code gives slightly different answers on the home
> >> and work machines  - found in my R CMD check run.  I've recopied the entire
> >> directory to make sure it's really identical code.
> >>   The data set and fit in question has a pretty flat "top" to the likelihood.
> >> I put print statements in to the "f()" function called by optim, and the
> >> two parameters and the likelihood track perfectly for 48 iterations, then
> >> start to drift ever so slightly:
> >> <  theta= -3.254176 -6.201119 ilik= -16.64806
> >>> theta= -3.254176 -6.201118 ilik= -16.64806
> >>
> >> And at the end of the iteration:
> >> <  theta= -3.207488 -8.583329 ilik= -16.70139
> >>> theta= -3.207488 -8.583333 ilik= -16.70139
> >>
> >> As you can see, they get to the same max, but with just a slightly
> >> different path.
> >>
> >>   The work machine is running 64 bit Unix (CentOS) and the home one 32 bit
> >> Ubuntu.
> >> Could this be enough to cause the difference?  Most of my tests are
> >> based on all.equal, but I also print out 1 or 2 full solutions; perhaps
> >> I'll have to modify that?
> >
> > We do see quite a lot of that, yes; even running 32 and 64 bit builds on the same machine, an sometimes to the extent that an algorithm diverges on one architecture and diverges on the other (just peek over on R-sig-ME). The comparisons by "make check" on R itself also give off quite a bit of "last decimal chatter" when the architecture is switched. For some reason, OSX builds seem more consistent than Windows and Linux, although I have only anecdotal evidence of that.
> >
> > However, the basic point is that compilers don't define the sequence of FPU operations down to the last detail, an internal extended-precision register may or may not be used, the order of terms in a sum may be changed, etc. Since 64 bit code has different performance characteristics from 32 bit code (since you shift more data around for pointers), the FPU instructions may be differently optimized too.
> 
> However, the main difference is that all x86_64 chips have SSE2 
> registers, and so gcc makes use of them.  Not all i686 chips do, so 
> 32-bit builds on Linux and Windows only use the FPU registers.
> 
> This matters at ABI level: arguments get passed and values returned in 
> SSE registers: so we can't decide to only support later i686 cpus and 
> make use of SSE2 without re-compiling all the system libraries (but a 
> Linux distributor could).
> 
> And the FPU registers are 80-bit and use extended precision (the way we 
> set up Windows and on every Linux system I have seen): the SSE* 
> registers are 2x64-bit.
> 
> I believe that all Intel Macs are 'Core' or later and so do have SSE2, 
> although I don't know how much Apple relies on that.
> 
> (The reason I know that this is the 'main difference' is that you can 
> often turn off the use of SSE2 on x86_64 and reproduce the i686 results. 
>   But because of the ABI differences, you may get crashes: in R this 
> matters most often for complex numbers which are 128-bit C99 double 
> complex and passed around in an SSE register.)
> 
> >>
> >> Terry Therneau
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
>


From Rau at demogr.mpg.de  Mon Nov 28 16:39:12 2011
From: Rau at demogr.mpg.de (Rau, Roland)
Date: Mon, 28 Nov 2011 16:39:12 +0100
Subject: [Rd] Avoid package in build process when not supported on OS
Message-ID: <5B2F2CD24AD2764D898AF5A7B9A2ABBF01FB13EC@hermes.demogr.mpg.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111128/1d5fef52/attachment.pl>

From hb at biostat.ucsf.edu  Mon Nov 28 18:10:52 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Mon, 28 Nov 2011 09:10:52 -0800
Subject: [Rd] Avoid package in build process when not supported on OS
In-Reply-To: <5B2F2CD24AD2764D898AF5A7B9A2ABBF01FB13EC@hermes.demogr.mpg.de>
References: <5B2F2CD24AD2764D898AF5A7B9A2ABBF01FB13EC@hermes.demogr.mpg.de>
Message-ID: <CAFDcVCTKskYAycP-jrp8xGCoT83EtuugQ2WzdM-O6ayeVhmSqg@mail.gmail.com>

Move doMC from Requests: to Suggests: and load it in the code when
needed, e.g. library("doMC").

BTW, make sure you are aware of the new 'parallel' package that comes
with R v2.14.0.

/H

On Mon, Nov 28, 2011 at 7:39 AM, Rau, Roland <Rau at demogr.mpg.de> wrote:
> Dear all,
>
> I am currently working on a package which involves some simulation where no current simulation run depends on a previous simulation run.
> That is why I decided to parallelize the computation using the doMC package (which exists only for unix-like OS).
>
> I can create a package without any R CMD check and R CMD build errors on my computers (Ubuntu Linux 32bit & 64 bit).
>
> The problem that I have is: I would like to make the package platform-independent. In this case, this should not be difficult. A simple:
>
> if (!(.Platform$OS.type=="unix")) {
> ?....
> }
>
> allows me to specify a different execution path on non unix-like operating systems (i.e. not using doMC-code, resulting in running the code not in parallel).
>
> I just tried it out and uploaded the source package to http://win-builder.r-project.org/
>
> Unfortunately, I get the following result:
> [...]
> * checking package dependencies ... ERROR
> Package required but not available: 'doMC'
> [...]
>
> I interpret it as such: Even if the package will never be required (for a particular OS) the build process nevertheless checks whether the packages exists for the respective platform.
> What would you suggest? Create two packages (mypackage vs. mypackageNONUNIX)? Release only for unix-like systems? ...?
>
> Thank you in advance,
> Roland
>
>
>
> ----------
> This mail has been sent through the MPI for Demographic ...{{dropped:10}}
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From Rau at demogr.mpg.de  Mon Nov 28 19:34:19 2011
From: Rau at demogr.mpg.de (Rau, Roland)
Date: Mon, 28 Nov 2011 19:34:19 +0100
Subject: [Rd] Avoid package in build process when not supported on OS
References: <5B2F2CD24AD2764D898AF5A7B9A2ABBF01FB13EC@hermes.demogr.mpg.de> 
	<CAFDcVCTKskYAycP-jrp8xGCoT83EtuugQ2WzdM-O6ayeVhmSqg@mail.gmail.com>
Message-ID: <5B2F2CD24AD2764D898AF5A7B9A2ABBF01FB13ED@hermes.demogr.mpg.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111128/8edd5c86/attachment.pl>

From hb at biostat.ucsf.edu  Mon Nov 28 20:16:46 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Mon, 28 Nov 2011 11:16:46 -0800
Subject: [Rd] R CMD <custom>?
Message-ID: <CAFDcVCSuR6159QO=0J8Xe9icY9AOLDnSUvMF=w7=r5+jaL=uZg@mail.gmail.com>

Hi,

is it possible to add a custom script such that it is called via R CMD
<custom>?  Is R CMD searching for it elsewhere than R_HOME/bin/?  I'm
looking for an non-admin alternative, so copying the script to
R_HOME/bin/ will not do (in case the user don't have enough permission
to write there).

/Henrik


From hadley at rice.edu  Mon Nov 28 20:48:32 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Mon, 28 Nov 2011 13:48:32 -0600
Subject: [Rd] R CMD <custom>?
In-Reply-To: <CAFDcVCSuR6159QO=0J8Xe9icY9AOLDnSUvMF=w7=r5+jaL=uZg@mail.gmail.com>
References: <CAFDcVCSuR6159QO=0J8Xe9icY9AOLDnSUvMF=w7=r5+jaL=uZg@mail.gmail.com>
Message-ID: <CABdHhvGnCtK-D6QoiGUjBt0oygMZq_BTbqC_brqUAF7AnLu2tQ@mail.gmail.com>

It'd be cool if R CMD was user extensible through packages, so that (e.g.)

R CMD mypackage::mycommand

would do something like:

path <- system.file("cmd", paste(command, ".r"), package = package)
if (!file.exists(path)) {
  stop("Command ", command, " in ", package, " does not exist")
} else {
  source(path)
}

And maybe `R CMD mypackage` would look in mypackcage/cmd/default.r.

Hadley

On Mon, Nov 28, 2011 at 1:16 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> Hi,
>
> is it possible to add a custom script such that it is called via R CMD
> <custom>? ?Is R CMD searching for it elsewhere than R_HOME/bin/? ?I'm
> looking for an non-admin alternative, so copying the script to
> R_HOME/bin/ will not do (in case the user don't have enough permission
> to write there).
>
> /Henrik
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From xie at yihui.name  Mon Nov 28 20:57:13 2011
From: xie at yihui.name (Yihui Xie)
Date: Mon, 28 Nov 2011 13:57:13 -0600
Subject: [Rd] R CMD <custom>?
In-Reply-To: <CABdHhvGnCtK-D6QoiGUjBt0oygMZq_BTbqC_brqUAF7AnLu2tQ@mail.gmail.com>
References: <CAFDcVCSuR6159QO=0J8Xe9icY9AOLDnSUvMF=w7=r5+jaL=uZg@mail.gmail.com>
	<CABdHhvGnCtK-D6QoiGUjBt0oygMZq_BTbqC_brqUAF7AnLu2tQ@mail.gmail.com>
Message-ID: <CANROs4fFnezjE77B6NvgD-hohn1-u0znL9fp2i8-q9Z5GF5bVg@mail.gmail.com>

I strongly support this proposal. This will be a fantastic feature!

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 515-294-2465 Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA



On Mon, Nov 28, 2011 at 1:48 PM, Hadley Wickham <hadley at rice.edu> wrote:
> It'd be cool if R CMD was user extensible through packages, so that (e.g.)
>
> R CMD mypackage::mycommand
>
> would do something like:
>
> path <- system.file("cmd", paste(command, ".r"), package = package)
> if (!file.exists(path)) {
> ?stop("Command ", command, " in ", package, " does not exist")
> } else {
> ?source(path)
> }
>
> And maybe `R CMD mypackage` would look in mypackcage/cmd/default.r.
>
> Hadley
>
> On Mon, Nov 28, 2011 at 1:16 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>> Hi,
>>
>> is it possible to add a custom script such that it is called via R CMD
>> <custom>? ?Is R CMD searching for it elsewhere than R_HOME/bin/? ?I'm
>> looking for an non-admin alternative, so copying the script to
>> R_HOME/bin/ will not do (in case the user don't have enough permission
>> to write there).
>>
>> /Henrik
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>
> --
> Assistant Professor / Dobelman Family Junior Chair
> Department of Statistics / Rice University
> http://had.co.nz/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From murdoch.duncan at gmail.com  Mon Nov 28 21:04:41 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 28 Nov 2011 15:04:41 -0500
Subject: [Rd] R CMD <custom>?
In-Reply-To: <CAFDcVCSuR6159QO=0J8Xe9icY9AOLDnSUvMF=w7=r5+jaL=uZg@mail.gmail.com>
References: <CAFDcVCSuR6159QO=0J8Xe9icY9AOLDnSUvMF=w7=r5+jaL=uZg@mail.gmail.com>
Message-ID: <4ED3E959.3020806@gmail.com>

On 28/11/2011 2:16 PM, Henrik Bengtsson wrote:
> Hi,
>
> is it possible to add a custom script such that it is called via R CMD
> <custom>?  Is R CMD searching for it elsewhere than R_HOME/bin/?  I'm
> looking for an non-admin alternative, so copying the script to
> R_HOME/bin/ will not do (in case the user don't have enough permission
> to write there).

I don't remember if this is platform independent,  but

R CMD foo

on Windows will set up standard environment variables then try to 
execute "foo".  If "foo" isn't one of the internal commands listed by

R CMD --help

then it will just go looking for it like any other command in the path.  
(This is why "R CMD install" gives a funny error message:  the internal 
command is "INSTALL", so "R CMD install" just tries to execute "install".)

Duncan Murdoch


From murdoch.duncan at gmail.com  Mon Nov 28 21:16:15 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 28 Nov 2011 15:16:15 -0500
Subject: [Rd] R CMD <custom>?
In-Reply-To: <CABdHhvGnCtK-D6QoiGUjBt0oygMZq_BTbqC_brqUAF7AnLu2tQ@mail.gmail.com>
References: <CAFDcVCSuR6159QO=0J8Xe9icY9AOLDnSUvMF=w7=r5+jaL=uZg@mail.gmail.com>
	<CABdHhvGnCtK-D6QoiGUjBt0oygMZq_BTbqC_brqUAF7AnLu2tQ@mail.gmail.com>
Message-ID: <4ED3EC0F.4030407@gmail.com>

On 28/11/2011 2:48 PM, Hadley Wickham wrote:
> It'd be cool if R CMD was user extensible through packages, so that (e.g.)
>
> R CMD mypackage::mycommand
>
> would do something like:
>
> path<- system.file("cmd", paste(command, ".r"), package = package)
> if (!file.exists(path)) {
>    stop("Command ", command, " in ", package, " does not exist")
> } else {
>    source(path)
> }
>
> And maybe `R CMD mypackage` would look in mypackcage/cmd/default.r.
>

That does seem to mix up namespaces quite a bit.  But what does it get 
you that "Rscript -e" doesn't already give you?  You can set up your 
package so that

R CMD mypackage::mycommand

executes a function, using delayedAssign or some of the more exotic 
features (like external pointers and finalizers).

Duncan Murdoch


From hadley at rice.edu  Mon Nov 28 21:19:43 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Mon, 28 Nov 2011 14:19:43 -0600
Subject: [Rd] R CMD <custom>?
In-Reply-To: <4ED3EC0F.4030407@gmail.com>
References: <CAFDcVCSuR6159QO=0J8Xe9icY9AOLDnSUvMF=w7=r5+jaL=uZg@mail.gmail.com>
	<CABdHhvGnCtK-D6QoiGUjBt0oygMZq_BTbqC_brqUAF7AnLu2tQ@mail.gmail.com>
	<4ED3EC0F.4030407@gmail.com>
Message-ID: <CABdHhvF7LkvmMVUw0V06pEYJb=_L-FHO=kj-FbijYcRFLp_6+g@mail.gmail.com>

> That does seem to mix up namespaces quite a bit.

That was just a proposal - equally

R CMD mypackage::mycommand

could just run

mypackage::mycommand()

but then passing argument might get a bit confusing.

> But what does it get you
> that "Rscript -e" doesn't already give you? ?You can set up your package so
> that
>
> R CMD mypackage::mycommand
>
> executes a function, using delayedAssign or some of the more exotic features
> (like external pointers and finalizers).

Because you have to specify the path to that package?  R CMD roxygen2
is much easier to type, remember and is portable, compared to
~/R/roxygen2/something.r.  It also makes R CMD scripts extensible by
packages in a consistent manner.

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From wdunlap at tibco.com  Mon Nov 28 21:31:33 2011
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 28 Nov 2011 20:31:33 +0000
Subject: [Rd] R CMD <custom>?
In-Reply-To: <CABdHhvGnCtK-D6QoiGUjBt0oygMZq_BTbqC_brqUAF7AnLu2tQ@mail.gmail.com>
References: <CAFDcVCSuR6159QO=0J8Xe9icY9AOLDnSUvMF=w7=r5+jaL=uZg@mail.gmail.com>
	<CABdHhvGnCtK-D6QoiGUjBt0oygMZq_BTbqC_brqUAF7AnLu2tQ@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B93247BF0@PA-MBX03.na.tibco.com>

The shell command
  R CMD something
currently acts as though it puts R_HOME/bin on the front
of PATH, looks for an executable file called 'something'
in PATH, and then executes it.  The executable may call R
or it may not.

I think that running an R script file is sufficiently different
from running an executable file that the operation should
not also be called 'CMD'.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com 

> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of Hadley Wickham
> Sent: Monday, November 28, 2011 11:49 AM
> To: Henrik Bengtsson
> Cc: R-devel
> Subject: Re: [Rd] R CMD <custom>?
> 
> It'd be cool if R CMD was user extensible through packages, so that (e.g.)
> 
> R CMD mypackage::mycommand
> 
> would do something like:
> 
> path <- system.file("cmd", paste(command, ".r"), package = package)
> if (!file.exists(path)) {
>   stop("Command ", command, " in ", package, " does not exist")
> } else {
>   source(path)
> }
> 
> And maybe `R CMD mypackage` would look in mypackcage/cmd/default.r.
> 
> Hadley
> 
> On Mon, Nov 28, 2011 at 1:16 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> > Hi,
> >
> > is it possible to add a custom script such that it is called via R CMD
> > <custom>? ?Is R CMD searching for it elsewhere than R_HOME/bin/? ?I'm
> > looking for an non-admin alternative, so copying the script to
> > R_HOME/bin/ will not do (in case the user don't have enough permission
> > to write there).
> >
> > /Henrik
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> 
> 
> --
> Assistant Professor / Dobelman Family Junior Chair
> Department of Statistics / Rice University
> http://had.co.nz/
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hadley at rice.edu  Mon Nov 28 21:38:46 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Mon, 28 Nov 2011 14:38:46 -0600
Subject: [Rd] R CMD <custom>?
In-Reply-To: <E66794E69CFDE04D9A70842786030B93247BF0@PA-MBX03.na.tibco.com>
References: <CAFDcVCSuR6159QO=0J8Xe9icY9AOLDnSUvMF=w7=r5+jaL=uZg@mail.gmail.com>
	<CABdHhvGnCtK-D6QoiGUjBt0oygMZq_BTbqC_brqUAF7AnLu2tQ@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B93247BF0@PA-MBX03.na.tibco.com>
Message-ID: <CABdHhvHpjzKn==7aDrcGe8SHBbB6MHmPJe8edaCxWVWLd5CA2Q@mail.gmail.com>

> The shell command
> ?R CMD something
> currently acts as though it puts R_HOME/bin on the front
> of PATH, looks for an executable file called 'something'
> in PATH, and then executes it. ?The executable may call R
> or it may not.
>
> I think that running an R script file is sufficiently different
> from running an executable file that the operation should
> not also be called 'CMD'.

Fair enough. But it would still be extremely useful to have an R
"command" which did run R scripts (which naively you would expect R
CMD to do do).  Maybe R SCRIPT ?

Or R CMD package::script could look for an arbitrary script and
execute it - I suspect this would be trickier cross-platform though.

One could also consider eliminating R CMD and the bin directory, given
that most of the scripts there now just call an R function.  Perhaps a
general syntax for calling R scripts in an package could subsume these
important scripts in a consistent and package-extensible manner.

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From hb at biostat.ucsf.edu  Mon Nov 28 21:41:48 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Mon, 28 Nov 2011 12:41:48 -0800
Subject: [Rd] R CMD <custom>?
In-Reply-To: <CABdHhvF7LkvmMVUw0V06pEYJb=_L-FHO=kj-FbijYcRFLp_6+g@mail.gmail.com>
References: <CAFDcVCSuR6159QO=0J8Xe9icY9AOLDnSUvMF=w7=r5+jaL=uZg@mail.gmail.com>
	<CABdHhvGnCtK-D6QoiGUjBt0oygMZq_BTbqC_brqUAF7AnLu2tQ@mail.gmail.com>
	<4ED3EC0F.4030407@gmail.com>
	<CABdHhvF7LkvmMVUw0V06pEYJb=_L-FHO=kj-FbijYcRFLp_6+g@mail.gmail.com>
Message-ID: <CAFDcVCQj3wTsF7rv2PuBOAgp2t9N8HiHE2XyeMGWi3ryZGy6mQ@mail.gmail.com>

On Mon, Nov 28, 2011 at 12:19 PM, Hadley Wickham <hadley at rice.edu> wrote:
>> That does seem to mix up namespaces quite a bit.
>
> That was just a proposal - equally
>
> R CMD mypackage::mycommand
>
> could just run
>
> mypackage::mycommand()
>
> but then passing argument might get a bit confusing.
>
>> But what does it get you
>> that "Rscript -e" doesn't already give you? ?You can set up your package so
>> that
>>
>> R CMD mypackage::mycommand
>>
>> executes a function, using delayedAssign or some of the more exotic features
>> (like external pointers and finalizers).
>
> Because you have to specify the path to that package? ?R CMD roxygen2
> is much easier to type, remember and is portable, compared to
> ~/R/roxygen2/something.r. ?It also makes R CMD scripts extensible by
> packages in a consistent manner.

When people run R CMD build, R CMD INSTALL, R CMD check etc, they are
in a well defined working directory.  It can be assumed that R CMD
roxygen2 will be executed in the same directory.  As so as you enter
the R prompt, you cannot assume this working directory, and you have
to document/specify which directory the command should be executed on.
 Because of this, I favor an 'R CMD roxygen2' solution.

My use case/wish is to be able to provide 'R CMD Rdoc' (similar to 'R
CMD roxygen2') and 'R CMD rsp' (similar to 'R CMD Sweave').

/Henrik

>
> Hadley
>
> --
> Assistant Professor / Dobelman Family Junior Chair
> Department of Statistics / Rice University
> http://had.co.nz/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From hpages at fhcrc.org  Mon Nov 28 21:54:32 2011
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Mon, 28 Nov 2011 12:54:32 -0800
Subject: [Rd] extend validObject to validate any object (shallow and deep
	validation)
Message-ID: <4ED3F508.7000404@fhcrc.org>

Hi,

It would be nice if there was a tool for checking the validity of any
object. validObject() is of course the natural candidate for this but
right now it doesn't work on S3 objects:

   df <- data.frame(aa=1:4, bb=letters[4:1])
   attributes(df)$row.names <- c("A", "B", "C", "A")

'df' is an invalid data frame instance:

   > df
   Error in data.frame(aa = c("1", "2", "3", "4"), bb = c("d", "c", "b",  :
     duplicate row.names: A

However:

   > validObject(df)
   [1] TRUE
   > validObject(df, complete=TRUE)
   [1] TRUE

Also, here is another (typical) situation where it would be nice to be
able to (recursively) check the validity of the object:

   setClass("Collection", representation(things="list"))
   mycollection <- new("Collection", things=list(object1, object2, object3))

The problem is that 'validObject(mycollection, complete=TRUE)'
will return TRUE, even if one of the 3 objects stored in 'mycollection'
is invalid. I could implement my own validity method for Collection
objects but that's not a satisfactory solution because it would always
do a deep check (validity methods don't handle the 'complete' argument).

Would it make sense to modify validObject() so that, when called with
'complete=TRUE', it recursively validates the components of a list or
environment?

Thanks,
H.

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From dtenenba at fhcrc.org  Mon Nov 28 23:20:28 2011
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Mon, 28 Nov 2011 14:20:28 -0800
Subject: [Rd] Bug in Sys.which()?
Message-ID: <CAF42j21Be80gVe3s3UVqz4cFSC54_kB_Co9TVfrfQBz+NHpEZQ@mail.gmail.com>

At a Windows command prompt:
C:\>which ls
/cygdrive/c/Rtools215/bin/ls

C:\>which perl
/cygdrive/c/perl/bin/perl

In R:
> Sys.which(c("ls", "perl"))
                         ls                        perl
"c:\\RTOOLS~3\\bin\\ls.exe"                          ""

Is this expected behavior?

> sessionInfo()
R Under development (unstable) (2011-10-28 r57459)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_2.15.0


Thanks,
Dan


From murdoch.duncan at gmail.com  Mon Nov 28 23:26:27 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 28 Nov 2011 17:26:27 -0500
Subject: [Rd] R CMD <custom>?
In-Reply-To: <CABdHhvF7LkvmMVUw0V06pEYJb=_L-FHO=kj-FbijYcRFLp_6+g@mail.gmail.com>
References: <CAFDcVCSuR6159QO=0J8Xe9icY9AOLDnSUvMF=w7=r5+jaL=uZg@mail.gmail.com>
	<CABdHhvGnCtK-D6QoiGUjBt0oygMZq_BTbqC_brqUAF7AnLu2tQ@mail.gmail.com>
	<4ED3EC0F.4030407@gmail.com>
	<CABdHhvF7LkvmMVUw0V06pEYJb=_L-FHO=kj-FbijYcRFLp_6+g@mail.gmail.com>
Message-ID: <4ED40A93.7080701@gmail.com>

On 11-11-28 3:19 PM, Hadley Wickham wrote:
>> That does seem to mix up namespaces quite a bit.
>
> That was just a proposal - equally
>
> R CMD mypackage::mycommand
>
> could just run
>
> mypackage::mycommand()
>
> but then passing argument might get a bit confusing.
>
>> But what does it get you
>> that "Rscript -e" doesn't already give you?  You can set up your package so
>> that
>>
>> R CMD mypackage::mycommand
>>
>> executes a function, using delayedAssign or some of the more exotic features
>> (like external pointers and finalizers).
>
> Because you have to specify the path to that package?

Sorry, I was in a rush and typed the wrong thing.  I meant to type

Rscript -e mypackage::mycommand

which needs no path.

R CMD roxygen2
> is much easier to type, remember and is portable, compared to
> ~/R/roxygen2/something.r.  It also makes R CMD scripts extensible by
> packages in a consistent manner.

"Easier to type" is not a good argument, since any reasonable command 
line shell would allow you to abbreviate whatever you wanted.  "rox" is 
easier to type than R CMD roxygen2, and is easy enough to make happen.

Duncan Murdoch



>
> Hadley
>


From murdoch.duncan at gmail.com  Mon Nov 28 23:34:12 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 28 Nov 2011 17:34:12 -0500
Subject: [Rd] Bug in Sys.which()?
In-Reply-To: <CAF42j21Be80gVe3s3UVqz4cFSC54_kB_Co9TVfrfQBz+NHpEZQ@mail.gmail.com>
References: <CAF42j21Be80gVe3s3UVqz4cFSC54_kB_Co9TVfrfQBz+NHpEZQ@mail.gmail.com>
Message-ID: <4ED40C64.9060406@gmail.com>

On 11-11-28 5:20 PM, Dan Tenenbaum wrote:
> At a Windows command prompt:
> C:\>which ls
> /cygdrive/c/Rtools215/bin/ls
>
> C:\>which perl
> /cygdrive/c/perl/bin/perl
>
> In R:
>> Sys.which(c("ls", "perl"))
>                           ls                        perl
> "c:\\RTOOLS~3\\bin\\ls.exe"                          ""
>
> Is this expected behavior?

R doesn't necessarily have the same search path as your command prompt. 
  (Look at PATH in your command line, and Sys.getenv("PATH") in R, to 
compare.) When I try Sys.which() that with two things known to be on the 
path that R uses, it finds both.

Duncan Murdoch

>
>> sessionInfo()
> R Under development (unstable) (2011-10-28 r57459)
> Platform: i386-pc-mingw32/i386 (32-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_2.15.0
>
>
> Thanks,
> Dan
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From dtenenba at fhcrc.org  Tue Nov 29 00:15:52 2011
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Mon, 28 Nov 2011 15:15:52 -0800
Subject: [Rd] Bug in Sys.which()?
In-Reply-To: <4ED40C64.9060406@gmail.com>
References: <CAF42j21Be80gVe3s3UVqz4cFSC54_kB_Co9TVfrfQBz+NHpEZQ@mail.gmail.com>
	<4ED40C64.9060406@gmail.com>
Message-ID: <CAF42j23NtZ__UFLU5HeB=U=QN1qkt+3T+Nn4sf0NOsw4GVycmg@mail.gmail.com>

On Mon, Nov 28, 2011 at 2:34 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 11-11-28 5:20 PM, Dan Tenenbaum wrote:
>>
>> At a Windows command prompt:
>> C:\>which ls
>> /cygdrive/c/Rtools215/bin/ls
>>
>> C:\>which perl
>> /cygdrive/c/perl/bin/perl
>>
>> In R:
>>>
>>> Sys.which(c("ls", "perl"))
>>
>> ? ? ? ? ? ? ? ? ? ? ? ? ?ls ? ? ? ? ? ? ? ? ? ? ? ?perl
>> "c:\\RTOOLS~3\\bin\\ls.exe" ? ? ? ? ? ? ? ? ? ? ? ? ?""
>>
>> Is this expected behavior?
>
> R doesn't necessarily have the same search path as your command prompt.
> ?(Look at PATH in your command line, and Sys.getenv("PATH") in R, to
> compare.) When I try Sys.which() that with two things known to be on the
> path that R uses, it finds both.

Thanks.
PEBKAC.

Dan

>
> Duncan Murdoch
>
>>
>>> sessionInfo()
>>
>> R Under development (unstable) (2011-10-28 r57459)
>> Platform: i386-pc-mingw32/i386 (32-bit)
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252
>> [2] LC_CTYPE=English_United States.1252
>> [3] LC_MONETARY=English_United States.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>
>> loaded via a namespace (and not attached):
>> [1] tools_2.15.0
>>
>>
>> Thanks,
>> Dan
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From djsamperi at gmail.com  Tue Nov 29 04:21:33 2011
From: djsamperi at gmail.com (Dominick Samperi)
Date: Mon, 28 Nov 2011 22:21:33 -0500
Subject: [Rd] Holding back on source code
In-Reply-To: <4ED3357D.4090106@stats.ox.ac.uk>
References: <CAGuusR-xhP3Tdyg_Pr3sc_D=L7zAR5W4UT6hcDeU=aPKRB8Sfg@mail.gmail.com>
	<4ED3357D.4090106@stats.ox.ac.uk>
Message-ID: <CADUbQ5hpjumOVG85ZRZx6=CCutf4nGjO0YfSNxyLcOyoTRqr0A@mail.gmail.com>

On Mon, Nov 28, 2011 at 2:17 AM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> On 27/11/2011 23:07, Sachinthaka Abeywardana wrote:
>>
>> Hi All,
>>
>> A few years back when I was a CSIRO (an Australian research centre) intern
>> I developed a BLAS package for R that uses the GPU. I believe that there
>> is
>> something similar right now, except it uses a few CuBLAS (Nvidia BLAS)
>> routines, but doesnt replace them.
>
> We haven't much idea what 'something similar' refers to.
>
>> My question is, is it technically illegal to hold back on source code?
>
> It depends entirely on the licenses involved. ?Nothing prevents Adobe
> distributing Acrobat without source code, for example.
>
> This is the R development list: questions not specific to R are best asked
> elsewhere (and, to take a recent example, that includes questions about
> licenses of packages on R-forge or CRAN). ?'Elsewhere' may mean an IP
> lawyer.

One side-effect of R's GPL-based license is that there are many
Copyright holders
if you include members of the R core, R Foundation, R package
contributors, etc., and
any discussion (with an IP lawyer, say) about possible violation of
license terms would
require input from each of these groups.

Perhaps a new mailing list R-license-policy would be helpful...

Dominick

>> Thanks,
>> Sachin
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
> --
> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From sachin.abeywardana at gmail.com  Tue Nov 29 04:37:43 2011
From: sachin.abeywardana at gmail.com (Sachinthaka Abeywardana)
Date: Tue, 29 Nov 2011 14:37:43 +1100
Subject: [Rd] Holding back on source code
In-Reply-To: <4ED3357D.4090106@stats.ox.ac.uk>
References: <CAGuusR-xhP3Tdyg_Pr3sc_D=L7zAR5W4UT6hcDeU=aPKRB8Sfg@mail.gmail.com>
	<4ED3357D.4090106@stats.ox.ac.uk>
Message-ID: <CAGuusR-ygQjazpjNyD4VuO4AuGbdQ_5ZWysVYze0sW9xJb-_4w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111129/9ffaa477/attachment.pl>

From ripley at stats.ox.ac.uk  Tue Nov 29 08:56:21 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 29 Nov 2011 07:56:21 +0000 (GMT)
Subject: [Rd] Updated Windows toolchain
Message-ID: <alpine.LFD.2.02.1111281109480.16728@toucan.stats.ox.ac.uk>

An updated toolchain is now being used for Windows' builds of R-devel: 
details are in the R-admin manual and at
http://www.murdoch-sutherland.com/Rtools/ and
http://www.stats.ox.ac.uk/pub/Rtools/

Both 32- and 64-bit parts of the toolchain use v2.0.1 of the Mingw-w64 
project's runtime and a beta of gcc 4.5.4: the Mingw.org project's 
builds are no longer used.  This should mean that code which compiles 
for 64-bit Windows also compiles for 32-bit Windows, and v.v. unless 
code makes (incorrect but common) assumptions that pointers fit into 
longs.

A very few packages will need modifications because they contain 
declarations which clash with the headers in this toolchain: where we 
are aware of problems the maintainers have been informed.

At DLL level different Windows' toolchains should be compatible: at C 
level they mostly are but at C++ level they are pretty much 
incompatible (so that for example GDAL has to be re-compiled for every 
toolchain: and Rcpp users need to be careful to use only one toolchain 
for Rcpp and their packages).  All the external software previously 
made available (and more) is made available at 
http://www.stats.ox.ac.uk/pub/Rtools .

The toolchain has support for OpenMP and pthreads: however OpenMP 
support is not enabled by default in R (it is too slow to be much 
use).  If you do make use of it in your packages, be aware that you 
will need to ship the appropriate pthreads DLL(s).

It is expected that there will be several further minor updates prior 
to the release of 2.15.0 in ca 4 months, but this step is the major 
one.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From htl10 at users.sourceforge.net  Tue Nov 29 22:43:03 2011
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Tue, 29 Nov 2011 21:43:03 +0000 (GMT)
Subject: [Rd] a couple Sweave buglets
Message-ID: <1322602983.97061.YahooMailClassic@web29511.mail.ird.yahoo.com>

Just a couple of small bug-lets/stuffs in Sweave:

- It stripes off the two lines starting with @ (this is a verbatim section showing plink's start-up message):

=======================================

@----------------------------------------------------------@
|         PLINK!       |    v0.99p     |   17/Dec/2006     |
|----------------------------------------------------------|
|  (C) 2006 Shaun Purcell, GNU General Public License, v2  |
|----------------------------------------------------------|
|       http://pngu.mgh.harvard.edu/purcell/plink/         |
@----------------------------------------------------------@

========================================

- XeTeX definitely does not like having any \usepackage[whatever]{inputenc}
(it assumes inputs are always utf-8)


While both of these can be worked around - using \input{} for anything Sweave might mess with, and put a % in front of \userpackage[inputenc] (Sweave seems to read LaTeX comments as real; but that's probaby a mis-feature...); SWeave probably should not stripe @ without a starting <<>>= noweb marker.

Had a couple of discussion elsewhere - it seems that international stuff in LaTeX, XeTeX and/or LuaTeX are the main ones to use, but for most parts people still stick to regional encodings (e.g. iso 8859-11 for Thai) so dependences on inputenc is not really useful.

FWIW.


From hadley at rice.edu  Wed Nov 30 15:28:51 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Wed, 30 Nov 2011 08:28:51 -0600
Subject: [Rd] Bug in URLencode?
Message-ID: <CABdHhvHPXCTHzWE5m_ZC7Wz94fbBt8WNWLAwa-FyXzsUUWdh5Q@mail.gmail.com>

Hi all,

I think I've spotted a small bug in URLencode: + is not listed as a
reserved character (and hence not percent encoded) even though it is
listed as a reserved character in rfc3986
(http://tools.ietf.org/html/rfc3986#section-2.2).  The documentation
for URLencode cites rfc1738, which rfc3986 makes obsolete.

Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From dlyzxl at yahoo.com  Wed Nov 30 21:47:41 2011
From: dlyzxl at yahoo.com (Justin)
Date: Wed, 30 Nov 2011 12:47:41 -0800 (PST)
Subject: [Rd] sma installation error
Message-ID: <1322686061.66590.YahooMailNeo@web112304.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20111130/6aa3a825/attachment.pl>

From hb at biostat.ucsf.edu  Wed Nov 30 23:02:11 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Wed, 30 Nov 2011 14:02:11 -0800
Subject: [Rd] sma installation error
In-Reply-To: <1322686061.66590.YahooMailNeo@web112304.mail.gq1.yahoo.com>
References: <1322686061.66590.YahooMailNeo@web112304.mail.gq1.yahoo.com>
Message-ID: <CAFDcVCQjcoKDHMxBJAqfD6KLrOnfGRrCOJPhbcJopYbE-KsTxA@mail.gmail.com>

The sma package is deprecated since many years...

...however, by request from collaborators last year, I recompiled it
to fix that error you are mention (see below).  I just added a
namespace (required in R 2.14.0).  You can download it from:

  http://braju.com/R/repos/sma_0.5.17.tar.gz
  http://braju.com/R/repos/sma_0.5.17.zip

It pass R CMD check without ERRORs but there are heaps of WARNINGs.
It comes with all possible disclaimers, including that you're on your
own trying to get the package to work.  I will *not* help you/anyone
troubleshoot etc - I'm not using it myself and I'm just making it
available as is.

Package: sma
============

Version: 0.5.17 [2011-11-30]
o Added a namespace.
o Compressed example data using 'R CMD build --resave-data'.

Version: 0.5.16 [2010-12-03]
o PARSE ERROR: A '#' was incorrectly escaped as '\#' in a string.
o The sma package is no longer supported/maintained.  The last
  official release was v0.5.15 in Nov 2005, cf.
  http://cran.r-project.org/src/contrib/Archive/sma/.
  The only reason for v0.5.16 is so that it can be used by
  users who still use the aroma package.

Version: 0.5.15 [2005-11--16]
o See http://cran.r-project.org/src/contrib/Archive/sma/

/Henrik

On Wed, Nov 30, 2011 at 12:47 PM, Justin <dlyzxl at yahoo.com> wrote:
> I tried different versions of sma**.tar.gz file either with "R CMD INSTALL -l packagepath sma**.tar.gz", "R INSTALL -l path sma**.tar.gz" and under R windows by "install.packages("sma_0.5.15.tar.gz",repos=NULL)"
>
> .
> I got same error
>
>
> ======
> * installing *source* package 'sma' ...
> ** Creating default NAMESPACE file
> Warning in .write_description(db, ldpath) :
> ? Unknown encoding with non-ASCII data: converting to ASCII
> ** R
> Error : '\#' is an unrecognized escape in character string starting "but the suffixes must be integers 1,2, ..., \#"
> ERROR: unable to collate and parse R files for package 'sma'
> * removing '/home/psgendb/local/pkg/R_language/lib64/R/library/sma'
> Warning message:
> In install.packages("sma_0.5.15.tar.gz", repos = NULL) :
> ? installation of package 'sma_0.5.15.tar.gz' had non-zero exit status
>
>
>
> ======
> My system is Linux cc01 2.6.18-238.19.1.el5 #1 SMP Fri Jul 15 07:31:24 EDT 2011 x86_64 x86_64 x86_64 GNU/Linux
>
> Can anyone help?
>
>
> Thanks,
>
>
> Justin
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From jordigh at octave.org  Wed Nov 30 23:43:12 2011
From: jordigh at octave.org (=?UTF-8?Q?Jordi_Guti=C3=A9rrez_Hermoso?=)
Date: Wed, 30 Nov 2011 17:43:12 -0500
Subject: [Rd] Holding back on source code
In-Reply-To: <CAGuusR-ygQjazpjNyD4VuO4AuGbdQ_5ZWysVYze0sW9xJb-_4w@mail.gmail.com>
References: <CAGuusR-xhP3Tdyg_Pr3sc_D=L7zAR5W4UT6hcDeU=aPKRB8Sfg@mail.gmail.com>
	<4ED3357D.4090106@stats.ox.ac.uk>
	<CAGuusR-ygQjazpjNyD4VuO4AuGbdQ_5ZWysVYze0sW9xJb-_4w@mail.gmail.com>
Message-ID: <CAPHS2gzORqrOe50hoPqTRzmwY_xAXvSWRHy3HEJ6bajb8MVbqA@mail.gmail.com>

On 28 November 2011 22:37, Sachinthaka Abeywardana
<sachin.abeywardana at gmail.com> wrote:
> What I want to do is release the code and implement the package, and not
> get in trouble considering I was with CSIRO when I did it.

I am not an internet protocol lawyer, etc...

Did you sign a contract that says the work you did under them is
theirs? If you did, you might get in trouble for releasing the code.
You chould be asking CSIRO, not us. Recoding the work may not be wise,
because perhaps it could breach the terms of your contract too.

Regrettably, the terms of the license you choose (GPL, whatever) are
not relevant, because if you signed a contract, and depending on what
contract says, the choice may fall upon CSIRO, not you.

Also, in general beware of treating the law like an algorithm or a
puzzle ("if (method_a && procedure_b && ! bad_thing) return success;
"). Programmers tend to think algorithmically about the law, but
everything is very fuzzy, vague, open to interpretation and frequently
"unintuitive". Consult a lawyer if possible. The Software Freedom Law
Centre might offer you pro-bono advice on this issue:

    http://www.softwarefreedom.org/about/contact/

HTH,
- Jordi G. H.


