From pd@|gd @end|ng |rom gm@||@com  Mon Nov  1 09:35:49 2021
From: pd@|gd @end|ng |rom gm@||@com (Peter Dalgaard)
Date: Mon, 1 Nov 2021 09:35:49 +0100
Subject: [Rd] R 4.1.2 is released
Message-ID: <C893C950-C99E-4931-9481-095FB0115737@gmail.com>

The build system rolled up R-4.1.2.tar.gz (codename "Bird Hippie") this morning.

The list below details the changes in this release. 

You can get the source code from

https://cran.r-project.org/src/base/R-4/R-4.1.2.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course.


For the R Core Team,

Peter Dalgaard

These are the checksums (md5 and SHA-256) for the freshly created files, in case you wish
to check that they are uncorrupted:

MD5 (AUTHORS) = 320967884b547734d6279dedbc739dd4
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = ade6a3d38fe5e6a456929cae2b94d568
MD5 (INSTALL) = 7893f754308ca31f1ccf62055090ad7b
MD5 (NEWS) = 924e68decbf327f538a09afb1838506b
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
MD5 (NEWS.2) = a767f7809324c73c49eaff47d14bce81
MD5 (NEWS.3) = e55ed2c8a547b827b46e08eb7137ba23
MD5 (R-latest.tar.gz) = 6e28db9d02c6d3dae51a149b8e261ab1
MD5 (README) = f468f281c919665e276a1b691decbbe6
MD5 (RESOURCES) = a79b9b338cab09bd665f6b62ac6f455b
MD5 (THANKS) = 251d20510bfc3cc93b82c5a99f7efcc6
MD5 (VERSION-INFO.dcf) = a72a49578a254b9163f0f10322a3eecc
MD5 (R-4/R-4.1.2.tar.gz) = 6e28db9d02c6d3dae51a149b8e261ab1

60a0d150e6fc1f424be76ad7b645d236b56e747692a4679f81ce6536c550e949  AUTHORS
e6d6a009505e345fe949e1310334fcb0747f28dae2856759de102ab66b722cb4  COPYING
6095e9ffa777dd22839f7801aa845b31c9ed07f3d6bf8a26dc5d2dec8ccc0ef3  COPYING.LIB
e84c67931e9b925abb9142d4a6b4ef03b7605948bbf384d7e3d2401823c7f1fe  FAQ
f87461be6cbaecc4dce44ac58e5bd52364b0491ccdadaf846cb9b452e9550f31  INSTALL
73d5bfb8711bb7833ce8fe7a1359566d48001d13cd32affbd800d759f0b3232a  NEWS
4e21b62f515b749f80997063fceab626d7258c7d650e81a662ba8e0640f12f62  NEWS.0
12b30c724117b1b2b11484673906a6dcd48a361f69fc420b36194f9218692d01  NEWS.1
ba74618bc3f4c0e336dca13d472402a1863d12ba6f7f91a1782bc469ee986f6d  NEWS.2
1910a2405300b9bc7c76beeb0753a5249cf799afe175ce28f8d782fab723e012  NEWS.3
2036225e9f7207d4ce097e54972aecdaa8b40d7d9911cd26491fac5a0fab38af  R-latest.tar.gz
2fdd3e90f23f32692d4b3a0c0452f2c219a10882033d1774f8cadf25886c3ddc  README
8b7d3856100220f4555d4d57140829f2e81c27eccec5b441f5dce616e9ec9061  RESOURCES
c9c7cb32308b4e560a22c858819ade9de524a602abd4e92d1c328c89f8037d73  THANKS
1e74ef089b526538bbb658dc189bc3d34d931839e9933415fb2f267fd57b0b69  VERSION-INFO.dcf
2036225e9f7207d4ce097e54972aecdaa8b40d7d9911cd26491fac5a0fab38af  R-4/R-4.1.2.tar.gz

This is the relevant part of the NEWS file

CHANGES IN R 4.1.2:

  C-LEVEL FACILITIES:

    * The workaround in headers R.h and Rmath.h (using namespace std;)
      for the Oracle Developer Studio compiler is no longer needed now
      C++11 is required so has been removed.  A couple more usages of
      log() (which should have been std::log()) with an int argument
      are reported on Solaris.

    * The undocumented limit of 4095 bytes on messages from the
      S-compatibility macros PROBLEM and MESSAGE is now documented and
      longer messages will be silently truncated rather than
      potentially causing segfaults.

    * If the R_NO_SEGV_HANDLER environment variable is non-empty, the
      signal handler for SEGV/ILL/BUS signals (which offers recovery
      user interface) is not set. This allows more reliable debugging
      of crashes that involve the console.

  DEPRECATED AND DEFUNCT:

    * The legacy S-compatibility macros PROBLEM, MESSAGE, ERROR, WARN,
      WARNING, RECOVER, ... are deprecated and will be hidden in R
      4.2.0. R's native interface of Rf_error and Rf_warning has long
      been preferred.

  BUG FIXES:

    * .mapply(F, dots, .) no longer segfaults when dots is not a list
      and uses match.fun(F) as always documented; reported by Andrew
      Simmons in PR#18164.

    * hist(<Date>, ...) and hist(<POSIXt>, ...)  no longer pass
      arguments for rect() (such as col and density) to axis().
      (Thanks to Sebastian Meyer's PR#18171.)

    * \Sexpr{ch} now preserves Encoding(ch). (Thanks to report and
      patch by Jeroen Ooms in PR#18152.)

    * Setting the RNG to "Marsaglia-Multicarry" e.g., by RNGkind(), now
      warns in more places, thanks to Andr'e Gillibert's report and
      patch in PR#18168.

    * gray(numeric(), alpha=1/2) no longer segfaults, fixing PR#18183,
      reported by Till Krenz.

    * Fixed dnbinom(x, size=<very_small>, .., log=TRUE) regression,
      reported by Martin Morgan.

    * as.Date.POSIXlt(x) now keeps names(x), thanks to Davis Vaughan's
      report and patch in PR#18188.

    * model.response() now strips an "AsIs" class typically, thanks to
      Duncan Murdoch's report and other discussants in PR#18190.

    * try() is considerably faster in case of an error and long call,
      as e.g., from some do.call().  Thanks to Alexander Kaever's
      suggestion posted to R-devel.

    * qqline(y = <object>) such as y=I(.), now works, see also
      PR#18190.

    * Non-integer mgp par() settings are now handled correctly in
      axis() and mtext(), thanks to Mikael Jagan and Duncan Murdoch's
      report and suggestion in PR#18194.

    * formatC(x) returns length zero character() now, rather than ""
      when x is of length zero, as documented, thanks to Davis
      Vaughan's post to R-devel.

    * removeSource(fn) now retains (other) attributes(fn).

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Nov  1 11:36:17 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 1 Nov 2021 06:36:17 -0400
Subject: [Rd] Wrong number of names?
Message-ID: <3b0ce089-f83b-3f58-93b4-51922178f4c1@stats.uwo.ca>

The StackOverflow post https://stackoverflow.com/a/69767361/2554330 
discusses a dataframe which has a named numeric column of length 1488 
that has 744 names. I don't think this is ever legal, but am I wrong 
about that?

The `dat.rds` file mentioned in the post is temporarily available online 
in case anyone else wants to examine it.

Assuming that the file contains a badly formed object, I wonder if 
readRDS() should do some sanity checks as it reads.

Duncan Murdoch


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Mon Nov  1 14:10:08 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Mon, 1 Nov 2021 14:10:08 +0100
Subject: [Rd] Wrong number of names?
In-Reply-To: <3b0ce089-f83b-3f58-93b4-51922178f4c1@stats.uwo.ca>
References: <3b0ce089-f83b-3f58-93b4-51922178f4c1@stats.uwo.ca>
Message-ID: <24959.59184.879532.448761@stat.math.ethz.ch>

>>>>> Duncan Murdoch 
>>>>>     on Mon, 1 Nov 2021 06:36:17 -0400 writes:

    > The StackOverflow post
    > https://stackoverflow.com/a/69767361/2554330 discusses a
    > dataframe which has a named numeric column of length 1488
    > that has 744 names. I don't think this is ever legal, but
    > am I wrong about that?

    > The `dat.rds` file mentioned in the post is temporarily
    > available online in case anyone else wants to examine it.

    > Assuming that the file contains a badly formed object, I
    > wonder if readRDS() should do some sanity checks as it
    > reads.

    > Duncan Murdoch

Good question.

In the mean time, I've also added a bit on the SO page
above.. e.g.

---------------------------------------------------------------------------

d <- readRDS("<.....>dat.rds")
str(d)
## 'data.frame':	1488 obs. of  4 variables:
##  $ facet_var: chr  "AUT" "AUT" "AUT" "AUT" ...
##  $ date     : Date, format: "2020-04-26" "2020-04-27" ...
##  $ variable : Factor w/ 2 levels "arima","prophet": 1 1 1 1 1 1 1 1 1 1 ...
##  $ score    : Named num  2.74e-06 2.41e-06 2.48e-06 2.39e-06 2.79e-06 ...
##   ..- attr(*, "names")= chr [1:744] "new_confirmed10" "new_confirmed10" "new_confirmed10" "new_confirmed10" ...

ds <- d$score
c(length(ds), length(names(ds)))
## 1488   744

dput(ds) # -> 

##  *** caught segfault ***
## address (nil), cause 'memory not mapped'

---------------------------------------------------------------------------

Hence  "proving" that the dat.rds  really contains an invalid object,
when simple  dput(.) directly gives a segmentation fault.

I think we are aware that using C code and say .Call(..)  one
can create all kinds of invalid objects "easily".. and I think
it's clear that it's not feasible to check for validity of such
objects "everwhere".

Your proposal to have at least our deserialization code used in
readRDS() do (at least *some*) validity checks seems good, but
maybe we should think of more cases, and / or  do such validity
checks already during serialization { <-> saveRDS() here } ?

.. Such questions then really are for those who understand more than
me about (de)serialization in R, its performance bottlenecks etc.
Given the speed impact we should probably have such checks *optional*
but have them *on* by default e.g., at least for saveRDS() ?

Martin


From pd@|gd @end|ng |rom gm@||@com  Mon Nov  1 15:55:15 2021
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Mon, 1 Nov 2021 15:55:15 +0100
Subject: [Rd] Wrong number of names?
In-Reply-To: <3b0ce089-f83b-3f58-93b4-51922178f4c1@stats.uwo.ca>
References: <3b0ce089-f83b-3f58-93b4-51922178f4c1@stats.uwo.ca>
Message-ID: <D8FC0C8F-77F4-40D2-AD46-54DBA99E7749@gmail.com>



> On 1 Nov 2021, at 11:36 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> The StackOverflow post https://stackoverflow.com/a/69767361/2554330 discusses a dataframe which has a named numeric column of length 1488 that has 744 names. I don't think this is ever legal, but am I wrong about that?
> 

It is certainly not easy to create such objects at the R level, e.g.:

> x <- 1:10 
> names(x) <- 1:10 
> length(names(x)) <- 5
> x
   1    2    3    4    5 <NA> <NA> <NA> <NA> <NA> 
   1    2    3    4    5    6    7    8    9   10 
> names(x)
 [1] "1" "2" "3" "4" "5" NA  NA  NA  NA  NA 

or even

> x <- 1:10 
> attributes(x)$foo <- 1:5
> x
 [1]  1  2  3  4  5  6  7  8  9 10
attr(,"foo")
[1] 1 2 3 4 5
> names(attributes(x)) <- "names"
> x
   1    2    3    4    5 <NA> <NA> <NA> <NA> <NA> 
   1    2    3    4    5    6    7    8    9   10 
> dput(x)
structure(1:10, .Names = c("1", "2", "3", "4", "5", NA, NA, NA, 
NA, NA))

of course, at the C level, everything is possible...




> The `dat.rds` file mentioned in the post is temporarily available online in case anyone else wants to examine it.
> 
> Assuming that the file contains a badly formed object, I wonder if readRDS() should do some sanity checks as it reads.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Nov  1 16:31:54 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 1 Nov 2021 11:31:54 -0400
Subject: [Rd] Wrong number of names?
In-Reply-To: <24959.59184.879532.448761@stat.math.ethz.ch>
References: <3b0ce089-f83b-3f58-93b4-51922178f4c1@stats.uwo.ca>
 <24959.59184.879532.448761@stat.math.ethz.ch>
Message-ID: <52632258-82f4-ee95-1121-7d0867689070@gmail.com>

On 01/11/2021 9:10 a.m., Martin Maechler wrote:
>>>>>> Duncan Murdoch
>>>>>>      on Mon, 1 Nov 2021 06:36:17 -0400 writes:
> 
>      > The StackOverflow post
>      > https://stackoverflow.com/a/69767361/2554330 discusses a
>      > dataframe which has a named numeric column of length 1488
>      > that has 744 names. I don't think this is ever legal, but
>      > am I wrong about that?
> 
>      > The `dat.rds` file mentioned in the post is temporarily
>      > available online in case anyone else wants to examine it.
> 
>      > Assuming that the file contains a badly formed object, I
>      > wonder if readRDS() should do some sanity checks as it
>      > reads.
> 
>      > Duncan Murdoch
> 
> Good question.
> 
> In the mean time, I've also added a bit on the SO page
> above.. e.g.
> 
> ---------------------------------------------------------------------------
> 
> d <- readRDS("<.....>dat.rds")
> str(d)
> ## 'data.frame':	1488 obs. of  4 variables:
> ##  $ facet_var: chr  "AUT" "AUT" "AUT" "AUT" ...
> ##  $ date     : Date, format: "2020-04-26" "2020-04-27" ...
> ##  $ variable : Factor w/ 2 levels "arima","prophet": 1 1 1 1 1 1 1 1 1 1 ...
> ##  $ score    : Named num  2.74e-06 2.41e-06 2.48e-06 2.39e-06 2.79e-06 ...
> ##   ..- attr(*, "names")= chr [1:744] "new_confirmed10" "new_confirmed10" "new_confirmed10" "new_confirmed10" ...
> 
> ds <- d$score
> c(length(ds), length(names(ds)))
> ## 1488   744
> 
> dput(ds) # ->
> 
> ##  *** caught segfault ***
> ## address (nil), cause 'memory not mapped'
> 
> ---------------------------------------------------------------------------
> 
> Hence  "proving" that the dat.rds  really contains an invalid object,
> when simple  dput(.) directly gives a segmentation fault.
> 
> I think we are aware that using C code and say .Call(..)  one
> can create all kinds of invalid objects "easily".. and I think
> it's clear that it's not feasible to check for validity of such
> objects "everwhere".
> 
> Your proposal to have at least our deserialization code used in
> readRDS() do (at least *some*) validity checks seems good, but
> maybe we should think of more cases, and / or  do such validity
> checks already during serialization { <-> saveRDS() here } ?
> 
> .. Such questions then really are for those who understand more than
> me about (de)serialization in R, its performance bottlenecks etc.
> Given the speed impact we should probably have such checks *optional*
> but have them *on* by default e.g., at least for saveRDS() ?

It might make sense to start with a contributed package.  It could 
include lots of checks without worrying about how expensive they are; if 
some of them prove to be cost-effective, they could be moved into base 
functions.

Duncan Murdoch


From je|| @end|ng |rom vtke||er@@com  Tue Nov  2 00:45:32 2021
From: je|| @end|ng |rom vtke||er@@com (Jeff Keller)
Date: Mon, 1 Nov 2021 19:45:32 -0400 (EDT)
Subject: [Rd] parallel PSOCK connection latency is greater on Linux?
In-Reply-To: <CALEXWq0QnKiKyVNqfx9zCtpVLRomrygFcEDPvaOaQNnx-8jBsQ@mail.gmail.com>
References: <JQG4JQ.RSMMA5AL6E0M3@vtkellers.com>
 <6B25B60C-EF8D-4CAF-856F-E948C27BD5CA@R-project.org>
 <CALEXWq3SXK5_=JTQ3ZfXN+upU=NLrMaqZdzzCuXBumMmyvVDMg@mail.gmail.com>
 <7486JQ.F60K6EHKGCP02@vtkellers.com>
 <6867535C-28A7-4F14-A703-6028EC46513F@r-project.org>
 <CALEXWq0QnKiKyVNqfx9zCtpVLRomrygFcEDPvaOaQNnx-8jBsQ@mail.gmail.com>
Message-ID: <402481886.602574.1635810332917@privateemail.com>

Hi Simon,

I see there may have been some changes to address the TCP_NODELAY issue on Linux in https://github.com/wch/r-source/commit/82369f73fc297981e64cac8c9a696d05116f0797.

I gave this a try with R 4.1.1, but I still see a 40ms compute floor. Am I misunderstanding these changes or how socketOptions is intended to be used?

-Jeff

library(parallel)
library(microbenchmark)
options(socketOptions = "no-delay")
cl <- makeCluster(1)
(x <- microbenchmark(clusterEvalQ(cl, iris), times = 100, unit = "us"))
# Unit: microseconds
#                   expr  min       lq     mean   median       uq     max neval
# clusterEvalQ(cl, iris) 96.9 43986.73 40535.93 43999.59 44012.79 48046.6   100

> On 11/04/2020 5:41 AM I?aki Ucar <iucar at fedoraproject.org> wrote:
> 
>  
> Please, check a tcpdump session on localhost while running the following script:
> 
> library(parallel)
> library(tictoc)
> cl <- makeCluster(1)
> Sys.sleep(1)
> 
> for (i in 1:10) {
>   tic()
>   x <- clusterEvalQ(cl, iris)
>   toc()
> }
> 
> The initialization phase comprises 7 packets. Then, the 1-second sleep
> will help you see where the evaluation starts. Each clusterEvalQ
> generates 6 packets:
> 
> 1. main -> worker PSH, ACK 1026 bytes
> 2. worker -> main ACK 66 bytes
> 3. worker -> main PSH, ACK 3758 bytes
> 4. main -> worker ACK 66 bytes
> 5. worker -> main PSH, ACK 2484 bytes
> 6. main -> worker ACK 66 bytes
> 
> The first two are the command and its ACK, the following are the data
> back and their ACKs. In the first 4-5 iterations, I see no delay at
> all. Then, in the following iterations, a 40 ms delay starts to happen
> between packets 3 and 4, that is: the main process delays the ACK to
> the first packet of the incoming result.
> 
> So I'd say Nagle is hardly to blame for this. It would be interesting
> to see how many packets are generated with TCP_NODELAY on. If there
> are still 6 packets, then we are fine. If we suddenly see a gazillion
> packets, then TCP_NODELAY does more harm than good. On the other hand,
> TCP_QUICKACK would surely solve the issue without any drawback. As
> Nagle himself put it once, "set TCP_QUICKACK. If you find a case where
> that makes things worse, let me know."
> 
> I?aki
> 
> On Wed, 4 Nov 2020 at 04:34, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> >
> > I'm not sure the user would know ;). This is very system-specific issue just because the Linux network stack behaves so differently from other OSes (for purely historical reasons). That makes it hard to abstract as a "feature" for the R sockets that are supposed to be platform-independent. At least TCP_NODELAY is actually part of POSIX so it is on better footing, and disabling delayed ACK is practically only useful to work around the other side having Nagle on, so I would expect it to be rarely used.
> >
> > This is essentially RFC since we don't have a mechanism for socket options (well, almost, there is timeout and blocking already...) and I don't think we want to expose low-level details so perhaps one idea would be to add something like delay=NA to socketConnection() in order to not touch (NA), enable (TRUE) or disable (FALSE) TCP_NODELAY. I wonder if there is any other way we could infer the intention of the user to try to choose the right approach...
> >
> > Cheers,
> > Simon
> >
> >
> > > On Nov 3, 2020, at 02:28, Jeff <jeff at vtkellers.com> wrote:
> > >
> > > Could TCP_NODELAY and TCP_QUICKACK be exposed to the R user so that they might determine what is best for their potentially latency- or throughput-sensitive application?
> > >
> > > Best,
> > > Jeff
> > >
> > > On Mon, Nov 2, 2020 at 14:05, I?aki Ucar <iucar at fedoraproject.org> wrote:
> > >> On Mon, 2 Nov 2020 at 02:22, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> > >>> It looks like R sockets on Linux could do with TCP_NODELAY -- without (status quo):
> > >> How many network packets are generated with and without it? If there
> > >> are many small writes and thus setting TCP_NODELAY causes many small
> > >> packets to be sent, it might make more sense to set TCP_QUICKACK
> > >> instead.
> > >> I?aki
> > >>> Unit: microseconds
> > >>>                    expr      min       lq     mean  median       uq      max
> > >>>  clusterEvalQ(cl, iris) 1449.997 43991.99 43975.21 43997.1 44001.91 48027.83
> > >>>  neval
> > >>>   1000
> > >>> exactly the same machine + R but with TCP_NODELAY enabled in R_SockConnect():
> > >>> Unit: microseconds
> > >>>                    expr     min     lq     mean  median      uq      max neval
> > >>>  clusterEvalQ(cl, iris) 156.125 166.41 180.8806 170.247 174.298 5322.234  1000
> > >>> Cheers,
> > >>> Simon
> > >>> > On 2/11/2020, at 3:39 AM, Jeff <jeff at vtkellers.com> wrote:
> > >>> >
> > >>> > I'm exploring latency overhead of parallel PSOCK workers and noticed that serializing/unserializing data back to the main R session is significantly slower on Linux than it is on Windows/MacOS with similar hardware. Is there a reason for this difference and is there a way to avoid the apparent additional Linux overhead?
> > >>> >
> > >>> > I attempted to isolate the behavior with a test that simply returns an existing object from the worker back to the main R session.
> > >>> >
> > >>> > library(parallel)
> > >>> > library(microbenchmark)
> > >>> > gcinfo(TRUE)
> > >>> > cl <- makeCluster(1)
> > >>> > (x <- microbenchmark(clusterEvalQ(cl, iris), times = 1000, unit = "us"))
> > >>> > plot(x$time, ylab = "microseconds")
> > >>> > head(x$time, n = 10)
> > >>> >
> > >>> > On Windows/MacOS, the test runs in 300-500 microseconds depending on hardware. A few of the 1000 runs are an order of magnitude slower but this can probably be attributed to garbage collection on the worker.
> > >>> >
> > >>> > On Linux, the first 5 or so executions run at comparable speeds but all subsequent executions are two orders of magnitude slower (~40 milliseconds).
> > >>> >
> > >>> > I see this behavior across various platforms and hardware combinations:
> > >>> >
> > >>> > Ubuntu 18.04 (Intel Xeon Platinum 8259CL)
> > >>> > Linux Mint 19.3 (AMD Ryzen 7 1800X)
> > >>> > Linux Mint 20 (AMD Ryzen 7 3700X)
> > >>> > Windows 10 (AMD Ryzen 7 4800H)
> > >>> > MacOS 10.15.7 (Intel Core i7-8850H)
> > >>> >
> > >>> > ______________________________________________
> > >>> > R-devel at r-project.org mailing list
> > >>> > https://stat.ethz.ch/mailman/listinfo/r-devel
> > >>> >
> > >>> ______________________________________________
> > >>> R-devel at r-project.org mailing list
> > >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> > >> --
> > >> I?aki ?car
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > >
> >
> 
> 
> -- 
> I?aki ?car


From g@bembecker @end|ng |rom gm@||@com  Tue Nov  2 01:55:45 2021
From: g@bembecker @end|ng |rom gm@||@com (Gabriel Becker)
Date: Mon, 1 Nov 2021 17:55:45 -0700
Subject: [Rd] parallel PSOCK connection latency is greater on Linux?
In-Reply-To: <402481886.602574.1635810332917@privateemail.com>
References: <JQG4JQ.RSMMA5AL6E0M3@vtkellers.com>
 <6B25B60C-EF8D-4CAF-856F-E948C27BD5CA@R-project.org>
 <CALEXWq3SXK5_=JTQ3ZfXN+upU=NLrMaqZdzzCuXBumMmyvVDMg@mail.gmail.com>
 <7486JQ.F60K6EHKGCP02@vtkellers.com>
 <6867535C-28A7-4F14-A703-6028EC46513F@r-project.org>
 <CALEXWq0QnKiKyVNqfx9zCtpVLRomrygFcEDPvaOaQNnx-8jBsQ@mail.gmail.com>
 <402481886.602574.1635810332917@privateemail.com>
Message-ID: <CAD4oTHFy0Mkmt4TCD+Yj_VZuEiOo742qAYZN4gs=Vuxg2XQuow@mail.gmail.com>

Jeff,

Perhaps I'm just missing something here, but ms is generally milliseconds,
not microseconds (which are much smaller), right?

Also, this seems to just be how long it takes to roundtrip serialize iris
(in 4.1.0  on mac osx, as thats what I have handy right this moment):

> microbenchmark({x <- unserialize(serialize(iris, connection = NULL))})

Unit: microseconds

                                                         expr    min      lq

 {     x <- unserialize(serialize(iris, connection = NULL)) } 35.378 36.0085

     mean  median     uq   max neval

 40.26888 36.4345 43.641 80.39   100



> res <- system.time(replicate(10000, {x <- unserialize(serialize(iris,
connection = NULL))}))

> res/10000

    user   system  elapsed

4.58e-05 2.90e-06 4.88e-05


Thus the overhead appears to be extremely minimal in your results above,
right? In fact it seems to be comparable or lower than replicate.

~G





On Mon, Nov 1, 2021 at 5:20 PM Jeff Keller <jeff at vtkellers.com> wrote:

> Hi Simon,
>
> I see there may have been some changes to address the TCP_NODELAY issue on
> Linux in
> https://github.com/wch/r-source/commit/82369f73fc297981e64cac8c9a696d05116f0797
> .
>
> I gave this a try with R 4.1.1, but I still see a 40ms compute floor. Am I
> misunderstanding these changes or how socketOptions is intended to be used?
>
> -Jeff
>
> library(parallel)
> library(microbenchmark)
> options(socketOptions = "no-delay")
> cl <- makeCluster(1)
> (x <- microbenchmark(clusterEvalQ(cl, iris), times = 100, unit = "us"))
> # Unit: microseconds
> #                   expr  min       lq     mean   median       uq     max
> neval
> # clusterEvalQ(cl, iris) 96.9 43986.73 40535.93 43999.59 44012.79 48046.6
>  100
>
> > On 11/04/2020 5:41 AM I?aki Ucar <iucar at fedoraproject.org> wrote:
> >
> >
> > Please, check a tcpdump session on localhost while running the following
> script:
> >
> > library(parallel)
> > library(tictoc)
> > cl <- makeCluster(1)
> > Sys.sleep(1)
> >
> > for (i in 1:10) {
> >   tic()
> >   x <- clusterEvalQ(cl, iris)
> >   toc()
> > }
> >
> > The initialization phase comprises 7 packets. Then, the 1-second sleep
> > will help you see where the evaluation starts. Each clusterEvalQ
> > generates 6 packets:
> >
> > 1. main -> worker PSH, ACK 1026 bytes
> > 2. worker -> main ACK 66 bytes
> > 3. worker -> main PSH, ACK 3758 bytes
> > 4. main -> worker ACK 66 bytes
> > 5. worker -> main PSH, ACK 2484 bytes
> > 6. main -> worker ACK 66 bytes
> >
> > The first two are the command and its ACK, the following are the data
> > back and their ACKs. In the first 4-5 iterations, I see no delay at
> > all. Then, in the following iterations, a 40 ms delay starts to happen
> > between packets 3 and 4, that is: the main process delays the ACK to
> > the first packet of the incoming result.
> >
> > So I'd say Nagle is hardly to blame for this. It would be interesting
> > to see how many packets are generated with TCP_NODELAY on. If there
> > are still 6 packets, then we are fine. If we suddenly see a gazillion
> > packets, then TCP_NODELAY does more harm than good. On the other hand,
> > TCP_QUICKACK would surely solve the issue without any drawback. As
> > Nagle himself put it once, "set TCP_QUICKACK. If you find a case where
> > that makes things worse, let me know."
> >
> > I?aki
> >
> > On Wed, 4 Nov 2020 at 04:34, Simon Urbanek <simon.urbanek at r-project.org>
> wrote:
> > >
> > > I'm not sure the user would know ;). This is very system-specific
> issue just because the Linux network stack behaves so differently from
> other OSes (for purely historical reasons). That makes it hard to abstract
> as a "feature" for the R sockets that are supposed to be
> platform-independent. At least TCP_NODELAY is actually part of POSIX so it
> is on better footing, and disabling delayed ACK is practically only useful
> to work around the other side having Nagle on, so I would expect it to be
> rarely used.
> > >
> > > This is essentially RFC since we don't have a mechanism for socket
> options (well, almost, there is timeout and blocking already...) and I
> don't think we want to expose low-level details so perhaps one idea would
> be to add something like delay=NA to socketConnection() in order to not
> touch (NA), enable (TRUE) or disable (FALSE) TCP_NODELAY. I wonder if there
> is any other way we could infer the intention of the user to try to choose
> the right approach...
> > >
> > > Cheers,
> > > Simon
> > >
> > >
> > > > On Nov 3, 2020, at 02:28, Jeff <jeff at vtkellers.com> wrote:
> > > >
> > > > Could TCP_NODELAY and TCP_QUICKACK be exposed to the R user so that
> they might determine what is best for their potentially latency- or
> throughput-sensitive application?
> > > >
> > > > Best,
> > > > Jeff
> > > >
> > > > On Mon, Nov 2, 2020 at 14:05, I?aki Ucar <iucar at fedoraproject.org>
> wrote:
> > > >> On Mon, 2 Nov 2020 at 02:22, Simon Urbanek <
> simon.urbanek at r-project.org> wrote:
> > > >>> It looks like R sockets on Linux could do with TCP_NODELAY --
> without (status quo):
> > > >> How many network packets are generated with and without it? If there
> > > >> are many small writes and thus setting TCP_NODELAY causes many small
> > > >> packets to be sent, it might make more sense to set TCP_QUICKACK
> > > >> instead.
> > > >> I?aki
> > > >>> Unit: microseconds
> > > >>>                    expr      min       lq     mean  median
>  uq      max
> > > >>>  clusterEvalQ(cl, iris) 1449.997 43991.99 43975.21 43997.1
> 44001.91 48027.83
> > > >>>  neval
> > > >>>   1000
> > > >>> exactly the same machine + R but with TCP_NODELAY enabled in
> R_SockConnect():
> > > >>> Unit: microseconds
> > > >>>                    expr     min     lq     mean  median      uq
>   max neval
> > > >>>  clusterEvalQ(cl, iris) 156.125 166.41 180.8806 170.247 174.298
> 5322.234  1000
> > > >>> Cheers,
> > > >>> Simon
> > > >>> > On 2/11/2020, at 3:39 AM, Jeff <jeff at vtkellers.com> wrote:
> > > >>> >
> > > >>> > I'm exploring latency overhead of parallel PSOCK workers and
> noticed that serializing/unserializing data back to the main R session is
> significantly slower on Linux than it is on Windows/MacOS with similar
> hardware. Is there a reason for this difference and is there a way to avoid
> the apparent additional Linux overhead?
> > > >>> >
> > > >>> > I attempted to isolate the behavior with a test that simply
> returns an existing object from the worker back to the main R session.
> > > >>> >
> > > >>> > library(parallel)
> > > >>> > library(microbenchmark)
> > > >>> > gcinfo(TRUE)
> > > >>> > cl <- makeCluster(1)
> > > >>> > (x <- microbenchmark(clusterEvalQ(cl, iris), times = 1000, unit
> = "us"))
> > > >>> > plot(x$time, ylab = "microseconds")
> > > >>> > head(x$time, n = 10)
> > > >>> >
> > > >>> > On Windows/MacOS, the test runs in 300-500 microseconds
> depending on hardware. A few of the 1000 runs are an order of magnitude
> slower but this can probably be attributed to garbage collection on the
> worker.
> > > >>> >
> > > >>> > On Linux, the first 5 or so executions run at comparable speeds
> but all subsequent executions are two orders of magnitude slower (~40
> milliseconds).
> > > >>> >
> > > >>> > I see this behavior across various platforms and hardware
> combinations:
> > > >>> >
> > > >>> > Ubuntu 18.04 (Intel Xeon Platinum 8259CL)
> > > >>> > Linux Mint 19.3 (AMD Ryzen 7 1800X)
> > > >>> > Linux Mint 20 (AMD Ryzen 7 3700X)
> > > >>> > Windows 10 (AMD Ryzen 7 4800H)
> > > >>> > MacOS 10.15.7 (Intel Core i7-8850H)
> > > >>> >
> > > >>> > ______________________________________________
> > > >>> > R-devel at r-project.org mailing list
> > > >>> > https://stat.ethz.ch/mailman/listinfo/r-devel
> > > >>> >
> > > >>> ______________________________________________
> > > >>> R-devel at r-project.org mailing list
> > > >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> > > >> --
> > > >> I?aki ?car
> > > >
> > > > ______________________________________________
> > > > R-devel at r-project.org mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > > >
> > >
> >
> >
> > --
> > I?aki ?car
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From n@r@@ @end|ng |rom @t@n|ord@edu  Tue Nov  2 03:03:02 2021
From: n@r@@ @end|ng |rom @t@n|ord@edu (Balasubramanian Narasimhan)
Date: Mon, 1 Nov 2021 19:03:02 -0700
Subject: [Rd] FLIBS in MacOS M1 binary at odds with documentation for
 optional libraries/tools
Message-ID: <3764f301-bcec-d654-508c-d23a0242b521@stanford.edu>

The Mac OS M1 pre-built binary arrives with a 
/Library/Frameworks/R.framework/Resources/etc/Makevars containing

FLIBS =? -L/Volumes/Builds/opt/R/arm64/gfortran/lib/gcc/aarch64-apple-darwin20.2.0/11.0.0 -L/Volumes/Builds/opt/R/arm64/gfortran/lib/gcc -L/Volumes/Builds/opt/R/arm64/gfortran/lib -lgfortran -lemutls_w -lm

This is inconsistent with what is at said at the top of 
https://mac.r-project.org/libs-arm64/: that all binaries live in 
/opt/R/arm64, not /Volumes/Builds/opt/R/arm64.

So no one would be able to build a source package containing Fortran 
without either modifying Makevars or creating symbolic links.

-Naras


	[[alternative HTML version deleted]]


From g@bembecker @end|ng |rom gm@||@com  Tue Nov  2 03:07:56 2021
From: g@bembecker @end|ng |rom gm@||@com (Gabriel Becker)
Date: Mon, 1 Nov 2021 19:07:56 -0700
Subject: [Rd] parallel PSOCK connection latency is greater on Linux?
In-Reply-To: <SV8X1R.X05C3QT4GJ2Y@vtkellers.com>
References: <JQG4JQ.RSMMA5AL6E0M3@vtkellers.com>
 <6B25B60C-EF8D-4CAF-856F-E948C27BD5CA@R-project.org>
 <CALEXWq3SXK5_=JTQ3ZfXN+upU=NLrMaqZdzzCuXBumMmyvVDMg@mail.gmail.com>
 <7486JQ.F60K6EHKGCP02@vtkellers.com>
 <6867535C-28A7-4F14-A703-6028EC46513F@r-project.org>
 <CALEXWq0QnKiKyVNqfx9zCtpVLRomrygFcEDPvaOaQNnx-8jBsQ@mail.gmail.com>
 <402481886.602574.1635810332917@privateemail.com>
 <CAD4oTHFy0Mkmt4TCD+Yj_VZuEiOo742qAYZN4gs=Vuxg2XQuow@mail.gmail.com>
 <SV8X1R.X05C3QT4GJ2Y@vtkellers.com>
Message-ID: <CAD4oTHFcFsmjXVPJSSkO-dop8-=+sy4-ozirLsha9_Nd1OUgDw@mail.gmail.com>

Hi all,

Please disregard my previous email as I misread the pasted output. Sorry
for the noise.

Best,
~G

On Mon, Nov 1, 2021 at 6:45 PM Jeff <jeff at vtkellers.com> wrote:

> Hi Gabriel,
>
> Yes, 40 milliseconds (ms) == 40,000 microseconds (us). My benchmarking
> output is reporting the latter, which is considerably higher than the 40us
> you are seeing. If I benchmark just the serialization round trip as you
> did, I get comparable results: 14us median on my Linux system. So at least
> on Linux, there is something else contributing the remaining 39,986us. The
> conclusion from earlier in this thread was that the culprit was TCP
> behavior unique to the Linux network stack.
>
> Jeff
>
> On Mon, Nov 1 2021 at 05:55:45 PM -0700, Gabriel Becker <
> gabembecker at gmail.com> wrote:
>
> Jeff,
>
> Perhaps I'm just missing something here, but ms is generally milliseconds,
> not microseconds (which are much smaller), right?
>
> Also, this seems to just be how long it takes to roundtrip serialize iris
> (in 4.1.0  on mac osx, as thats what I have handy right this moment):
>
> > microbenchmark({x <- unserialize(serialize(iris, connection = NULL))})
>
> Unit: microseconds
>
>                                                          expr    min
> lq
>
>  {     x <- unserialize(serialize(iris, connection = NULL)) } 35.378
> 36.0085
>
>      mean  median     uq   max neval
>
>  40.26888 36.4345 43.641 80.39   100
>
>
>
> > res <- system.time(replicate(10000, {x <- unserialize(serialize(iris,
> connection = NULL))}))
>
> > res/10000
>
>     user   system  elapsed
>
> 4.58e-05 2.90e-06 4.88e-05
>
>
> Thus the overhead appears to be extremely minimal in your results above,
> right? In fact it seems to be comparable or lower than replicate.
>
> ~G
>
>
>
>
>
> On Mon, Nov 1, 2021 at 5:20 PM Jeff Keller <jeff at vtkellers.com> wrote:
>
>> Hi Simon,
>>
>> I see there may have been some changes to address the TCP_NODELAY issue
>> on Linux in
>> https://github.com/wch/r-source/commit/82369f73fc297981e64cac8c9a696d05116f0797
>> .
>>
>> I gave this a try with R 4.1.1, but I still see a 40ms compute floor. Am
>> I misunderstanding these changes or how socketOptions is intended to be
>> used?
>>
>> -Jeff
>>
>> library(parallel)
>> library(microbenchmark)
>> options(socketOptions = "no-delay")
>> cl <- makeCluster(1)
>> (x <- microbenchmark(clusterEvalQ(cl, iris), times = 100, unit = "us"))
>> # Unit: microseconds
>> #                   expr  min       lq     mean   median       uq     max
>> neval
>> # clusterEvalQ(cl, iris) 96.9 43986.73 40535.93 43999.59 44012.79
>> 48046.6   100
>>
>> > On 11/04/2020 5:41 AM I?aki Ucar <iucar at fedoraproject.org> wrote:
>> >
>> >
>> > Please, check a tcpdump session on localhost while running the
>> following script:
>> >
>> > library(parallel)
>> > library(tictoc)
>> > cl <- makeCluster(1)
>> > Sys.sleep(1)
>> >
>> > for (i in 1:10) {
>> >   tic()
>> >   x <- clusterEvalQ(cl, iris)
>> >   toc()
>> > }
>> >
>> > The initialization phase comprises 7 packets. Then, the 1-second sleep
>> > will help you see where the evaluation starts. Each clusterEvalQ
>> > generates 6 packets:
>> >
>> > 1. main -> worker PSH, ACK 1026 bytes
>> > 2. worker -> main ACK 66 bytes
>> > 3. worker -> main PSH, ACK 3758 bytes
>> > 4. main -> worker ACK 66 bytes
>> > 5. worker -> main PSH, ACK 2484 bytes
>> > 6. main -> worker ACK 66 bytes
>> >
>> > The first two are the command and its ACK, the following are the data
>> > back and their ACKs. In the first 4-5 iterations, I see no delay at
>> > all. Then, in the following iterations, a 40 ms delay starts to happen
>> > between packets 3 and 4, that is: the main process delays the ACK to
>> > the first packet of the incoming result.
>> >
>> > So I'd say Nagle is hardly to blame for this. It would be interesting
>> > to see how many packets are generated with TCP_NODELAY on. If there
>> > are still 6 packets, then we are fine. If we suddenly see a gazillion
>> > packets, then TCP_NODELAY does more harm than good. On the other hand,
>> > TCP_QUICKACK would surely solve the issue without any drawback. As
>> > Nagle himself put it once, "set TCP_QUICKACK. If you find a case where
>> > that makes things worse, let me know."
>> >
>> > I?aki
>> >
>> > On Wed, 4 Nov 2020 at 04:34, Simon Urbanek <simon.urbanek at r-project.org>
>> wrote:
>> > >
>> > > I'm not sure the user would know ;). This is very system-specific
>> issue just because the Linux network stack behaves so differently from
>> other OSes (for purely historical reasons). That makes it hard to abstract
>> as a "feature" for the R sockets that are supposed to be
>> platform-independent. At least TCP_NODELAY is actually part of POSIX so it
>> is on better footing, and disabling delayed ACK is practically only useful
>> to work around the other side having Nagle on, so I would expect it to be
>> rarely used.
>> > >
>> > > This is essentially RFC since we don't have a mechanism for socket
>> options (well, almost, there is timeout and blocking already...) and I
>> don't think we want to expose low-level details so perhaps one idea would
>> be to add something like delay=NA to socketConnection() in order to not
>> touch (NA), enable (TRUE) or disable (FALSE) TCP_NODELAY. I wonder if there
>> is any other way we could infer the intention of the user to try to choose
>> the right approach...
>> > >
>> > > Cheers,
>> > > Simon
>> > >
>> > >
>> > > > On Nov 3, 2020, at 02:28, Jeff <jeff at vtkellers.com> wrote:
>> > > >
>> > > > Could TCP_NODELAY and TCP_QUICKACK be exposed to the R user so that
>> they might determine what is best for their potentially latency- or
>> throughput-sensitive application?
>> > > >
>> > > > Best,
>> > > > Jeff
>> > > >
>> > > > On Mon, Nov 2, 2020 at 14:05, I?aki Ucar <iucar at fedoraproject.org>
>> wrote:
>> > > >> On Mon, 2 Nov 2020 at 02:22, Simon Urbanek <
>> simon.urbanek at r-project.org> wrote:
>> > > >>> It looks like R sockets on Linux could do with TCP_NODELAY --
>> without (status quo):
>> > > >> How many network packets are generated with and without it? If
>> there
>> > > >> are many small writes and thus setting TCP_NODELAY causes many
>> small
>> > > >> packets to be sent, it might make more sense to set TCP_QUICKACK
>> > > >> instead.
>> > > >> I?aki
>> > > >>> Unit: microseconds
>> > > >>>                    expr      min       lq     mean  median
>>  uq      max
>> > > >>>  clusterEvalQ(cl, iris) 1449.997 43991.99 43975.21 43997.1
>> 44001.91 48027.83
>> > > >>>  neval
>> > > >>>   1000
>> > > >>> exactly the same machine + R but with TCP_NODELAY enabled in
>> R_SockConnect():
>> > > >>> Unit: microseconds
>> > > >>>                    expr     min     lq     mean  median      uq
>>     max neval
>> > > >>>  clusterEvalQ(cl, iris) 156.125 166.41 180.8806 170.247 174.298
>> 5322.234  1000
>> > > >>> Cheers,
>> > > >>> Simon
>> > > >>> > On 2/11/2020, at 3:39 AM, Jeff <jeff at vtkellers.com> wrote:
>> > > >>> >
>> > > >>> > I'm exploring latency overhead of parallel PSOCK workers and
>> noticed that serializing/unserializing data back to the main R session is
>> significantly slower on Linux than it is on Windows/MacOS with similar
>> hardware. Is there a reason for this difference and is there a way to avoid
>> the apparent additional Linux overhead?
>> > > >>> >
>> > > >>> > I attempted to isolate the behavior with a test that simply
>> returns an existing object from the worker back to the main R session.
>> > > >>> >
>> > > >>> > library(parallel)
>> > > >>> > library(microbenchmark)
>> > > >>> > gcinfo(TRUE)
>> > > >>> > cl <- makeCluster(1)
>> > > >>> > (x <- microbenchmark(clusterEvalQ(cl, iris), times = 1000, unit
>> = "us"))
>> > > >>> > plot(x$time, ylab = "microseconds")
>> > > >>> > head(x$time, n = 10)
>> > > >>> >
>> > > >>> > On Windows/MacOS, the test runs in 300-500 microseconds
>> depending on hardware. A few of the 1000 runs are an order of magnitude
>> slower but this can probably be attributed to garbage collection on the
>> worker.
>> > > >>> >
>> > > >>> > On Linux, the first 5 or so executions run at comparable speeds
>> but all subsequent executions are two orders of magnitude slower (~40
>> milliseconds).
>> > > >>> >
>> > > >>> > I see this behavior across various platforms and hardware
>> combinations:
>> > > >>> >
>> > > >>> > Ubuntu 18.04 (Intel Xeon Platinum 8259CL)
>> > > >>> > Linux Mint 19.3 (AMD Ryzen 7 1800X)
>> > > >>> > Linux Mint 20 (AMD Ryzen 7 3700X)
>> > > >>> > Windows 10 (AMD Ryzen 7 4800H)
>> > > >>> > MacOS 10.15.7 (Intel Core i7-8850H)
>> > > >>> >
>> > > >>> > ______________________________________________
>> > > >>> > R-devel at r-project.org mailing list
>> > > >>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>> > > >>> >
>> > > >>> ______________________________________________
>> > > >>> R-devel at r-project.org mailing list
>> > > >>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> > > >> --
>> > > >> I?aki ?car
>> > > >
>> > > > ______________________________________________
>> > > > R-devel at r-project.org mailing list
>> > > > https://stat.ethz.ch/mailman/listinfo/r-devel
>> > > >
>> > >
>> >
>> >
>> > --
>> > I?aki ?car
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>

	[[alternative HTML version deleted]]


From @|mon@urb@nek @end|ng |rom R-project@org  Tue Nov  2 04:04:54 2021
From: @|mon@urb@nek @end|ng |rom R-project@org (Simon Urbanek)
Date: Tue, 2 Nov 2021 16:04:54 +1300
Subject: [Rd] parallel PSOCK connection latency is greater on Linux?
In-Reply-To: <402481886.602574.1635810332917@privateemail.com>
References: <JQG4JQ.RSMMA5AL6E0M3@vtkellers.com>
 <6B25B60C-EF8D-4CAF-856F-E948C27BD5CA@R-project.org>
 <CALEXWq3SXK5_=JTQ3ZfXN+upU=NLrMaqZdzzCuXBumMmyvVDMg@mail.gmail.com>
 <7486JQ.F60K6EHKGCP02@vtkellers.com>
 <6867535C-28A7-4F14-A703-6028EC46513F@r-project.org>
 <CALEXWq0QnKiKyVNqfx9zCtpVLRomrygFcEDPvaOaQNnx-8jBsQ@mail.gmail.com>
 <402481886.602574.1635810332917@privateemail.com>
Message-ID: <395401B6-9659-4B2C-943B-50F8A19E664B@R-project.org>


Jeff,

you are not setting the option on the server side, only on the client side, so the worker will still wait (which is where it matters). If you set it on the server (worker) side then it works as expected:

> cl <- makeCluster(1, rscript_args="-e 'options(socketOptions=\"no-delay\")'")
>  (x <- microbenchmark(clusterEvalQ(cl, iris), times = 100, unit = "us"))
Unit: microseconds
                   expr    min     lq     mean   median       uq     max neval
 clusterEvalQ(cl, iris) 112.41 115.33 128.9988 117.3065 120.5385 348.702   100

Cheers,
Simon



> On Nov 2, 2021, at 12:45 PM, Jeff Keller <jeff at vtkellers.com> wrote:
> 
> Hi Simon,
> 
> I see there may have been some changes to address the TCP_NODELAY issue on Linux in https://github.com/wch/r-source/commit/82369f73fc297981e64cac8c9a696d05116f0797.
> 
> I gave this a try with R 4.1.1, but I still see a 40ms compute floor. Am I misunderstanding these changes or how socketOptions is intended to be used?
> 
> -Jeff
> 
> library(parallel)
> library(microbenchmark)
> options(socketOptions = "no-delay")
> cl <- makeCluster(1)
> (x <- microbenchmark(clusterEvalQ(cl, iris), times = 100, unit = "us"))
> # Unit: microseconds
> #                   expr  min       lq     mean   median       uq     max neval
> # clusterEvalQ(cl, iris) 96.9 43986.73 40535.93 43999.59 44012.79 48046.6   100
> 
>> On 11/04/2020 5:41 AM I?aki Ucar <iucar at fedoraproject.org> wrote:
>> 
>> 
>> Please, check a tcpdump session on localhost while running the following script:
>> 
>> library(parallel)
>> library(tictoc)
>> cl <- makeCluster(1)
>> Sys.sleep(1)
>> 
>> for (i in 1:10) {
>>  tic()
>>  x <- clusterEvalQ(cl, iris)
>>  toc()
>> }
>> 
>> The initialization phase comprises 7 packets. Then, the 1-second sleep
>> will help you see where the evaluation starts. Each clusterEvalQ
>> generates 6 packets:
>> 
>> 1. main -> worker PSH, ACK 1026 bytes
>> 2. worker -> main ACK 66 bytes
>> 3. worker -> main PSH, ACK 3758 bytes
>> 4. main -> worker ACK 66 bytes
>> 5. worker -> main PSH, ACK 2484 bytes
>> 6. main -> worker ACK 66 bytes
>> 
>> The first two are the command and its ACK, the following are the data
>> back and their ACKs. In the first 4-5 iterations, I see no delay at
>> all. Then, in the following iterations, a 40 ms delay starts to happen
>> between packets 3 and 4, that is: the main process delays the ACK to
>> the first packet of the incoming result.
>> 
>> So I'd say Nagle is hardly to blame for this. It would be interesting
>> to see how many packets are generated with TCP_NODELAY on. If there
>> are still 6 packets, then we are fine. If we suddenly see a gazillion
>> packets, then TCP_NODELAY does more harm than good. On the other hand,
>> TCP_QUICKACK would surely solve the issue without any drawback. As
>> Nagle himself put it once, "set TCP_QUICKACK. If you find a case where
>> that makes things worse, let me know."
>> 
>> I?aki
>> 
>> On Wed, 4 Nov 2020 at 04:34, Simon Urbanek <simon.urbanek at r-project.org> wrote:
>>> 
>>> I'm not sure the user would know ;). This is very system-specific issue just because the Linux network stack behaves so differently from other OSes (for purely historical reasons). That makes it hard to abstract as a "feature" for the R sockets that are supposed to be platform-independent. At least TCP_NODELAY is actually part of POSIX so it is on better footing, and disabling delayed ACK is practically only useful to work around the other side having Nagle on, so I would expect it to be rarely used.
>>> 
>>> This is essentially RFC since we don't have a mechanism for socket options (well, almost, there is timeout and blocking already...) and I don't think we want to expose low-level details so perhaps one idea would be to add something like delay=NA to socketConnection() in order to not touch (NA), enable (TRUE) or disable (FALSE) TCP_NODELAY. I wonder if there is any other way we could infer the intention of the user to try to choose the right approach...
>>> 
>>> Cheers,
>>> Simon
>>> 
>>> 
>>>> On Nov 3, 2020, at 02:28, Jeff <jeff at vtkellers.com> wrote:
>>>> 
>>>> Could TCP_NODELAY and TCP_QUICKACK be exposed to the R user so that they might determine what is best for their potentially latency- or throughput-sensitive application?
>>>> 
>>>> Best,
>>>> Jeff
>>>> 
>>>> On Mon, Nov 2, 2020 at 14:05, I?aki Ucar <iucar at fedoraproject.org> wrote:
>>>>> On Mon, 2 Nov 2020 at 02:22, Simon Urbanek <simon.urbanek at r-project.org> wrote:
>>>>>> It looks like R sockets on Linux could do with TCP_NODELAY -- without (status quo):
>>>>> How many network packets are generated with and without it? If there
>>>>> are many small writes and thus setting TCP_NODELAY causes many small
>>>>> packets to be sent, it might make more sense to set TCP_QUICKACK
>>>>> instead.
>>>>> I?aki
>>>>>> Unit: microseconds
>>>>>>                   expr      min       lq     mean  median       uq      max
>>>>>> clusterEvalQ(cl, iris) 1449.997 43991.99 43975.21 43997.1 44001.91 48027.83
>>>>>> neval
>>>>>>  1000
>>>>>> exactly the same machine + R but with TCP_NODELAY enabled in R_SockConnect():
>>>>>> Unit: microseconds
>>>>>>                   expr     min     lq     mean  median      uq      max neval
>>>>>> clusterEvalQ(cl, iris) 156.125 166.41 180.8806 170.247 174.298 5322.234  1000
>>>>>> Cheers,
>>>>>> Simon
>>>>>>> On 2/11/2020, at 3:39 AM, Jeff <jeff at vtkellers.com> wrote:
>>>>>>> 
>>>>>>> I'm exploring latency overhead of parallel PSOCK workers and noticed that serializing/unserializing data back to the main R session is significantly slower on Linux than it is on Windows/MacOS with similar hardware. Is there a reason for this difference and is there a way to avoid the apparent additional Linux overhead?
>>>>>>> 
>>>>>>> I attempted to isolate the behavior with a test that simply returns an existing object from the worker back to the main R session.
>>>>>>> 
>>>>>>> library(parallel)
>>>>>>> library(microbenchmark)
>>>>>>> gcinfo(TRUE)
>>>>>>> cl <- makeCluster(1)
>>>>>>> (x <- microbenchmark(clusterEvalQ(cl, iris), times = 1000, unit = "us"))
>>>>>>> plot(x$time, ylab = "microseconds")
>>>>>>> head(x$time, n = 10)
>>>>>>> 
>>>>>>> On Windows/MacOS, the test runs in 300-500 microseconds depending on hardware. A few of the 1000 runs are an order of magnitude slower but this can probably be attributed to garbage collection on the worker.
>>>>>>> 
>>>>>>> On Linux, the first 5 or so executions run at comparable speeds but all subsequent executions are two orders of magnitude slower (~40 milliseconds).
>>>>>>> 
>>>>>>> I see this behavior across various platforms and hardware combinations:
>>>>>>> 
>>>>>>> Ubuntu 18.04 (Intel Xeon Platinum 8259CL)
>>>>>>> Linux Mint 19.3 (AMD Ryzen 7 1800X)
>>>>>>> Linux Mint 20 (AMD Ryzen 7 3700X)
>>>>>>> Windows 10 (AMD Ryzen 7 4800H)
>>>>>>> MacOS 10.15.7 (Intel Core i7-8850H)
>>>>>>> 
>>>>>>> ______________________________________________
>>>>>>> R-devel at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>> --
>>>>> I?aki ?car
>>>> 
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> 
>>> 
>> 
>> 
>> -- 
>> I?aki ?car
> 


From @|mon@urb@nek @end|ng |rom R-project@org  Tue Nov  2 04:22:39 2021
From: @|mon@urb@nek @end|ng |rom R-project@org (Simon Urbanek)
Date: Tue, 2 Nov 2021 16:22:39 +1300
Subject: [Rd] FLIBS in MacOS M1 binary at odds with documentation for
 optional libraries/tools
In-Reply-To: <3764f301-bcec-d654-508c-d23a0242b521@stanford.edu>
References: <3764f301-bcec-d654-508c-d23a0242b521@stanford.edu>
Message-ID: <42F051E9-6DEA-452A-8E65-D822DE0A7D3C@R-project.org>


Naras,

thanks. It seems that the FLIBS check resolves symlinks, unfortunately (all others are fine).

I would like to remind people that reports are a lot more useful *before* the release - that's why we publish RCs.

Thanks,
Simon


> On Nov 2, 2021, at 3:03 PM, Balasubramanian Narasimhan <naras at stanford.edu> wrote:
> 
> The Mac OS M1 pre-built binary arrives with a 
> /Library/Frameworks/R.framework/Resources/etc/Makevars containing
> 
> FLIBS =  -L/Volumes/Builds/opt/R/arm64/gfortran/lib/gcc/aarch64-apple-darwin20.2.0/11.0.0 -L/Volumes/Builds/opt/R/arm64/gfortran/lib/gcc -L/Volumes/Builds/opt/R/arm64/gfortran/lib -lgfortran -lemutls_w -lm
> 
> This is inconsistent with what is at said at the top of 
> https://mac.r-project.org/libs-arm64/: that all binaries live in 
> /opt/R/arm64, not /Volumes/Builds/opt/R/arm64.
> 
> So no one would be able to build a source package containing Fortran 
> without either modifying Makevars or creating symbolic links.
> 
> -Naras
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From je|| @end|ng |rom vtke||er@@com  Tue Nov  2 02:45:28 2021
From: je|| @end|ng |rom vtke||er@@com (Jeff)
Date: Mon, 01 Nov 2021 21:45:28 -0400
Subject: [Rd] parallel PSOCK connection latency is greater on Linux?
In-Reply-To: <CAD4oTHFy0Mkmt4TCD+Yj_VZuEiOo742qAYZN4gs=Vuxg2XQuow@mail.gmail.com>
References: <JQG4JQ.RSMMA5AL6E0M3@vtkellers.com>
 <6B25B60C-EF8D-4CAF-856F-E948C27BD5CA@R-project.org>
 <CALEXWq3SXK5_=JTQ3ZfXN+upU=NLrMaqZdzzCuXBumMmyvVDMg@mail.gmail.com>
 <7486JQ.F60K6EHKGCP02@vtkellers.com>
 <6867535C-28A7-4F14-A703-6028EC46513F@r-project.org>
 <CALEXWq0QnKiKyVNqfx9zCtpVLRomrygFcEDPvaOaQNnx-8jBsQ@mail.gmail.com>
 <402481886.602574.1635810332917@privateemail.com>
 <CAD4oTHFy0Mkmt4TCD+Yj_VZuEiOo742qAYZN4gs=Vuxg2XQuow@mail.gmail.com>
Message-ID: <SV8X1R.X05C3QT4GJ2Y@vtkellers.com>

Hi Gabriel,

Yes, 40 milliseconds (ms) == 40,000 microseconds (us). My benchmarking 
output is reporting the latter, which is considerably higher than the 
40us you are seeing. If I benchmark just the serialization round trip 
as you did, I get comparable results: 14us median on my Linux system. 
So at least on Linux, there is something else contributing the 
remaining 39,986us. The conclusion from earlier in this thread was that 
the culprit was TCP behavior unique to the Linux network stack.

Jeff

On Mon, Nov 1 2021 at 05:55:45 PM -0700, Gabriel Becker 
<gabembecker at gmail.com> wrote:
> Jeff,
> 
> Perhaps I'm just missing something here, but ms is generally 
> milliseconds, not microseconds (which are much smaller), right?
> 
> Also, this seems to just be how long it takes to roundtrip serialize 
> iris (in 4.1.0  on mac osx, as thats what I have handy right this 
> moment):
> 
>> > microbenchmark({x <- unserialize(serialize(iris, connection = 
>> NULL))})
>> 
>> Unit: microseconds
>> 
>>                                                         expr   min   
>>   lq
>> 
>>  {    x <- unserialize(serialize(iris, connection = NULL)) } 35.378 
>> 36.0085
>> 
>>     mean median    uq  max neval
>> 
>>  40.26888 36.4345 43.641 80.39  100
>> 
>> 
> 
>> > res <- system.time(replicate(10000, {x <- 
>> unserialize(serialize(iris, connection = NULL))}))
>> 
>> > res/10000
>> 
>>    user  system elapsed
>> 
>> 4.58e-05 2.90e-06 4.88e-05
>> 
> 
> Thus the overhead appears to be extremely minimal in your results 
> above, right? In fact it seems to be comparable or lower than 
> replicate.
> 
> ~G
> 
> 
> 
> 
> 
> On Mon, Nov 1, 2021 at 5:20 PM Jeff Keller <jeff at vtkellers.com 
> <mailto:jeff at vtkellers.com>> wrote:
>> Hi Simon,
>> 
>>  I see there may have been some changes to address the TCP_NODELAY 
>> issue on Linux in 
>> <https://github.com/wch/r-source/commit/82369f73fc297981e64cac8c9a696d05116f0797>.
>> 
>>  I gave this a try with R 4.1.1, but I still see a 40ms compute 
>> floor. Am I misunderstanding these changes or how socketOptions is 
>> intended to be used?
>> 
>>  -Jeff
>> 
>>  library(parallel)
>>  library(microbenchmark)
>>  options(socketOptions = "no-delay")
>>  cl <- makeCluster(1)
>>  (x <- microbenchmark(clusterEvalQ(cl, iris), times = 100, unit = 
>> "us"))
>>  # Unit: microseconds
>>  #                   expr  min       lq     mean   median       uq   
>>   max neval
>>  # clusterEvalQ(cl, iris) 96.9 43986.73 40535.93 43999.59 44012.79 
>> 48046.6   100
>> 
>>  > On 11/04/2020 5:41 AM I?aki Ucar <iucar at fedoraproject.org 
>> <mailto:iucar at fedoraproject.org>> wrote:
>>  >
>>  >
>>  > Please, check a tcpdump session on localhost while running the 
>> following script:
>>  >
>>  > library(parallel)
>>  > library(tictoc)
>>  > cl <- makeCluster(1)
>>  > Sys.sleep(1)
>>  >
>>  > for (i in 1:10) {
>>  >   tic()
>>  >   x <- clusterEvalQ(cl, iris)
>>  >   toc()
>>  > }
>>  >
>>  > The initialization phase comprises 7 packets. Then, the 1-second 
>> sleep
>>  > will help you see where the evaluation starts. Each clusterEvalQ
>>  > generates 6 packets:
>>  >
>>  > 1. main -> worker PSH, ACK 1026 bytes
>>  > 2. worker -> main ACK 66 bytes
>>  > 3. worker -> main PSH, ACK 3758 bytes
>>  > 4. main -> worker ACK 66 bytes
>>  > 5. worker -> main PSH, ACK 2484 bytes
>>  > 6. main -> worker ACK 66 bytes
>>  >
>>  > The first two are the command and its ACK, the following are the 
>> data
>>  > back and their ACKs. In the first 4-5 iterations, I see no delay 
>> at
>>  > all. Then, in the following iterations, a 40 ms delay starts to 
>> happen
>>  > between packets 3 and 4, that is: the main process delays the ACK 
>> to
>>  > the first packet of the incoming result.
>>  >
>>  > So I'd say Nagle is hardly to blame for this. It would be 
>> interesting
>>  > to see how many packets are generated with TCP_NODELAY on. If 
>> there
>>  > are still 6 packets, then we are fine. If we suddenly see a 
>> gazillion
>>  > packets, then TCP_NODELAY does more harm than good. On the other 
>> hand,
>>  > TCP_QUICKACK would surely solve the issue without any drawback. As
>>  > Nagle himself put it once, "set TCP_QUICKACK. If you find a case 
>> where
>>  > that makes things worse, let me know."
>>  >
>>  > I?aki
>>  >
>>  > On Wed, 4 Nov 2020 at 04:34, Simon Urbanek 
>> <simon.urbanek at r-project.org <mailto:simon.urbanek at r-project.org>> 
>> wrote:
>>  > >
>>  > > I'm not sure the user would know ;). This is very 
>> system-specific issue just because the Linux network stack behaves 
>> so differently from other OSes (for purely historical reasons). That 
>> makes it hard to abstract as a "feature" for the R sockets that are 
>> supposed to be platform-independent. At least TCP_NODELAY is 
>> actually part of POSIX so it is on better footing, and disabling 
>> delayed ACK is practically only useful to work around the other side 
>> having Nagle on, so I would expect it to be rarely used.
>>  > >
>>  > > This is essentially RFC since we don't have a mechanism for 
>> socket options (well, almost, there is timeout and blocking 
>> already...) and I don't think we want to expose low-level details so 
>> perhaps one idea would be to add something like delay=NA to 
>> socketConnection() in order to not touch (NA), enable (TRUE) or 
>> disable (FALSE) TCP_NODELAY. I wonder if there is any other way we 
>> could infer the intention of the user to try to choose the right 
>> approach...
>>  > >
>>  > > Cheers,
>>  > > Simon
>>  > >
>>  > >
>>  > > > On Nov 3, 2020, at 02:28, Jeff <jeff at vtkellers.com 
>> <mailto:jeff at vtkellers.com>> wrote:
>>  > > >
>>  > > > Could TCP_NODELAY and TCP_QUICKACK be exposed to the R user 
>> so that they might determine what is best for their potentially 
>> latency- or throughput-sensitive application?
>>  > > >
>>  > > > Best,
>>  > > > Jeff
>>  > > >
>>  > > > On Mon, Nov 2, 2020 at 14:05, I?aki Ucar 
>> <iucar at fedoraproject.org <mailto:iucar at fedoraproject.org>> wrote:
>>  > > >> On Mon, 2 Nov 2020 at 02:22, Simon Urbanek 
>> <simon.urbanek at r-project.org <mailto:simon.urbanek at r-project.org>> 
>> wrote:
>>  > > >>> It looks like R sockets on Linux could do with TCP_NODELAY 
>> -- without (status quo):
>>  > > >> How many network packets are generated with and without it? 
>> If there
>>  > > >> are many small writes and thus setting TCP_NODELAY causes 
>> many small
>>  > > >> packets to be sent, it might make more sense to set 
>> TCP_QUICKACK
>>  > > >> instead.
>>  > > >> I?aki
>>  > > >>> Unit: microseconds
>>  > > >>>                    expr      min       lq     mean  median  
>>      uq      max
>>  > > >>>  clusterEvalQ(cl, iris) 1449.997 43991.99 43975.21 43997.1 
>> 44001.91 48027.83
>>  > > >>>  neval
>>  > > >>>   1000
>>  > > >>> exactly the same machine + R but with TCP_NODELAY enabled 
>> in R_SockConnect():
>>  > > >>> Unit: microseconds
>>  > > >>>                    expr     min     lq     mean  median     
>>  uq      max neval
>>  > > >>>  clusterEvalQ(cl, iris) 156.125 166.41 180.8806 170.247 
>> 174.298 5322.234  1000
>>  > > >>> Cheers,
>>  > > >>> Simon
>>  > > >>> > On 2/11/2020, at 3:39 AM, Jeff <jeff at vtkellers.com 
>> <mailto:jeff at vtkellers.com>> wrote:
>>  > > >>> >
>>  > > >>> > I'm exploring latency overhead of parallel PSOCK workers 
>> and noticed that serializing/unserializing data back to the main R 
>> session is significantly slower on Linux than it is on Windows/MacOS 
>> with similar hardware. Is there a reason for this difference and is 
>> there a way to avoid the apparent additional Linux overhead?
>>  > > >>> >
>>  > > >>> > I attempted to isolate the behavior with a test that 
>> simply returns an existing object from the worker back to the main R 
>> session.
>>  > > >>> >
>>  > > >>> > library(parallel)
>>  > > >>> > library(microbenchmark)
>>  > > >>> > gcinfo(TRUE)
>>  > > >>> > cl <- makeCluster(1)
>>  > > >>> > (x <- microbenchmark(clusterEvalQ(cl, iris), times = 
>> 1000, unit = "us"))
>>  > > >>> > plot(x$time, ylab = "microseconds")
>>  > > >>> > head(x$time, n = 10)
>>  > > >>> >
>>  > > >>> > On Windows/MacOS, the test runs in 300-500 microseconds 
>> depending on hardware. A few of the 1000 runs are an order of 
>> magnitude slower but this can probably be attributed to garbage 
>> collection on the worker.
>>  > > >>> >
>>  > > >>> > On Linux, the first 5 or so executions run at comparable 
>> speeds but all subsequent executions are two orders of magnitude 
>> slower (~40 milliseconds).
>>  > > >>> >
>>  > > >>> > I see this behavior across various platforms and hardware 
>> combinations:
>>  > > >>> >
>>  > > >>> > Ubuntu 18.04 (Intel Xeon Platinum 8259CL)
>>  > > >>> > Linux Mint 19.3 (AMD Ryzen 7 1800X)
>>  > > >>> > Linux Mint 20 (AMD Ryzen 7 3700X)
>>  > > >>> > Windows 10 (AMD Ryzen 7 4800H)
>>  > > >>> > MacOS 10.15.7 (Intel Core i7-8850H)
>>  > > >>> >
>>  > > >>> > ______________________________________________
>>  > > >>> > R-devel at r-project.org <mailto:R-devel at r-project.org> 
>> mailing list
>>  > > >>> > <https://stat.ethz.ch/mailman/listinfo/r-devel>
>>  > > >>> >
>>  > > >>> ______________________________________________
>>  > > >>> R-devel at r-project.org <mailto:R-devel at r-project.org> 
>> mailing list
>>  > > >>> <https://stat.ethz.ch/mailman/listinfo/r-devel>
>>  > > >> --
>>  > > >> I?aki ?car
>>  > > >
>>  > > > ______________________________________________
>>  > > > R-devel at r-project.org <mailto:R-devel at r-project.org> mailing 
>> list
>>  > > > <https://stat.ethz.ch/mailman/listinfo/r-devel>
>>  > > >
>>  > >
>>  >
>>  >
>>  > --
>>  > I?aki ?car
>> 
>>  ______________________________________________
>> R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>> <https://stat.ethz.ch/mailman/listinfo/r-devel>


	[[alternative HTML version deleted]]


From n@r@@ @end|ng |rom @t@n|ord@edu  Tue Nov  2 17:36:16 2021
From: n@r@@ @end|ng |rom @t@n|ord@edu (Balasubramanian Narasimhan)
Date: Tue, 2 Nov 2021 09:36:16 -0700
Subject: [Rd] FLIBS in MacOS M1 binary at odds with documentation for
 optional libraries/tools
In-Reply-To: <42F051E9-6DEA-452A-8E65-D822DE0A7D3C@R-project.org>
References: <3764f301-bcec-d654-508c-d23a0242b521@stanford.edu>
 <42F051E9-6DEA-452A-8E65-D822DE0A7D3C@R-project.org>
Message-ID: <b90e6a22-751e-0ac1-c2d6-176545cc9a2e@stanford.edu>

Thanks, Simon.? I only had sporadic access to a M1 laptop but now 
actually have one. Will try to do my part.

Best,

-Naras

On 11/1/21 8:22 PM, Simon Urbanek wrote:
> Naras,
>
> thanks. It seems that the FLIBS check resolves symlinks, unfortunately (all others are fine).
>
> I would like to remind people that reports are a lot more useful *before* the release - that's why we publish RCs.
>
> Thanks,
> Simon
>
>
>> On Nov 2, 2021, at 3:03 PM, Balasubramanian Narasimhan <naras at stanford.edu> wrote:
>>
>> The Mac OS M1 pre-built binary arrives with a
>> /Library/Frameworks/R.framework/Resources/etc/Makevars containing
>>
>> FLIBS =  -L/Volumes/Builds/opt/R/arm64/gfortran/lib/gcc/aarch64-apple-darwin20.2.0/11.0.0 -L/Volumes/Builds/opt/R/arm64/gfortran/lib/gcc -L/Volumes/Builds/opt/R/arm64/gfortran/lib -lgfortran -lemutls_w -lm
>>
>> This is inconsistent with what is at said at the top of
>> https://mac.r-project.org/libs-arm64/: that all binaries live in
>> /opt/R/arm64, not /Volumes/Builds/opt/R/arm64.
>>
>> So no one would be able to build a source package containing Fortran
>> without either modifying Makevars or creating symbolic links.
>>
>> -Naras
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>


From iuke-tier@ey m@iii@g oii uiow@@edu  Tue Nov  2 19:39:24 2021
From: iuke-tier@ey m@iii@g oii uiow@@edu (iuke-tier@ey m@iii@g oii uiow@@edu)
Date: Tue, 2 Nov 2021 13:39:24 -0500 (CDT)
Subject: [Rd] [External] Re:  Wrong number of names?
In-Reply-To: <24959.59184.879532.448761@stat.math.ethz.ch>
References: <3b0ce089-f83b-3f58-93b4-51922178f4c1@stats.uwo.ca>
 <24959.59184.879532.448761@stat.math.ethz.ch>
Message-ID: <alpine.DEB.2.22.394.2111021338140.3134@luke-Latitude-7480>

On Mon, 1 Nov 2021, Martin Maechler wrote:

>>>>>> Duncan Murdoch
>>>>>>     on Mon, 1 Nov 2021 06:36:17 -0400 writes:
>
>    > The StackOverflow post
>    > https://stackoverflow.com/a/69767361/2554330 discusses a
>    > dataframe which has a named numeric column of length 1488
>    > that has 744 names. I don't think this is ever legal, but
>    > am I wrong about that?
>
>    > The `dat.rds` file mentioned in the post is temporarily
>    > available online in case anyone else wants to examine it.
>
>    > Assuming that the file contains a badly formed object, I
>    > wonder if readRDS() should do some sanity checks as it
>    > reads.
>
>    > Duncan Murdoch
>
> Good question.
>
> In the mean time, I've also added a bit on the SO page
> above.. e.g.
>
> ---------------------------------------------------------------------------
>
> d <- readRDS("<.....>dat.rds")
> str(d)
> ## 'data.frame':	1488 obs. of  4 variables:
> ##  $ facet_var: chr  "AUT" "AUT" "AUT" "AUT" ...
> ##  $ date     : Date, format: "2020-04-26" "2020-04-27" ...
> ##  $ variable : Factor w/ 2 levels "arima","prophet": 1 1 1 1 1 1 1 1 1 1 ...
> ##  $ score    : Named num  2.74e-06 2.41e-06 2.48e-06 2.39e-06 2.79e-06 ...
> ##   ..- attr(*, "names")= chr [1:744] "new_confirmed10" "new_confirmed10" "new_confirmed10" "new_confirmed10" ...
>
> ds <- d$score
> c(length(ds), length(names(ds)))
> ## 1488   744
>
> dput(ds) # ->
>
> ##  *** caught segfault ***
> ## address (nil), cause 'memory not mapped'

If I'm reading this right then dput is where the segfault is
happening, so that could use some more bulletproofing.

Best,

luke


>
> ---------------------------------------------------------------------------
>
> Hence  "proving" that the dat.rds  really contains an invalid object,
> when simple  dput(.) directly gives a segmentation fault.
>
> I think we are aware that using C code and say .Call(..)  one
> can create all kinds of invalid objects "easily".. and I think
> it's clear that it's not feasible to check for validity of such
> objects "everwhere".
>
> Your proposal to have at least our deserialization code used in
> readRDS() do (at least *some*) validity checks seems good, but
> maybe we should think of more cases, and / or  do such validity
> checks already during serialization { <-> saveRDS() here } ?
>
> .. Such questions then really are for those who understand more than
> me about (de)serialization in R, its performance bottlenecks etc.
> Given the speed impact we should probably have such checks *optional*
> but have them *on* by default e.g., at least for saveRDS() ?
>
> Martin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From henr|k@bengt@@on @end|ng |rom gm@||@com  Wed Nov  3 01:37:26 2021
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Tue, 2 Nov 2021 17:37:26 -0700
Subject: [Rd] Fwd: Using existing envars in Renviron on friendly Windows
In-Reply-To: <87e89990-ebc4-6879-a34e-4301c3b83563@gmail.com>
References: <CAByPayHQ33kLY+S6U6NGAzHRuMZJQhaoPhbCDGt6EpgAU9aB5w@mail.gmail.com>
 <CAByPayFCM72e32p6aBshSa0oD0wijUkRQ-vKKT9Aq2YD5rKrpg@mail.gmail.com>
 <20211015194037.595b389f@Tarkus>
 <CAByPayFOobioF-W6Xt=6vkEw2srbg1xc9p6YvyO+r-yu=4doTg@mail.gmail.com>
 <CAByPayEZskmsn1bsFACYvxUC+ENaDfyoJsvbxwxLKc8gNyRgzQ@mail.gmail.com>
 <3ec44e42-f7af-575c-1b69-fe7e2bda00b2@gmail.com>
 <CAByPayH4dzWOqnaFg0z=UxjgHp6BSNrP17DP3RJ4qLPfw6q33A@mail.gmail.com>
 <24945.33990.369010.718929@stat.math.ethz.ch>
 <38f36d15-c08e-d57c-41f7-31dcc9449e84@gmail.com>
 <CAFDcVCSmQO43H7Jpj132ba13Lg0GfyFQoa+ev0st5kH3bhZL4A@mail.gmail.com>
 <87e89990-ebc4-6879-a34e-4301c3b83563@gmail.com>
Message-ID: <CAFDcVCRn1kKeEPCqzjMrcCN=38GZa_ODHRvO6Oq8GccoaxX7bg@mail.gmail.com>

Oh, I see, I misunderstood.  Thanks for clarifying.

One more thing, to mix-and-match environment variables and strings
with escaped characters, while mimicking how POSIX shells does it, by
using strings with double and single quotes. For example, with:

$ cat .Renviron
APPDATA='C:\Users\foobar\AppData\Roaming'
R_LIBS_USER="${APPDATA}"'\R-library'

we get:

$ Rscript --no-init-file --quiet -e 'cat(sprintf("R_LIBS_USER=[%s]\n",
Sys.getenv("R_LIBS_USER")))'
R_LIBS_USER=[C:\Users\foobar\AppData\Roaming\R-library]

and

$ source .Renviron
$ echo "R_LIBS_USER=[${R_LIBS_USER}]"
R_LIBS_USER=[C:\Users\foobar\AppData\Roaming\R-library]

/Henrik

On Sun, Oct 31, 2021 at 2:59 AM Tomas Kalibera <tomas.kalibera at gmail.com> wrote:
>
>
> On 10/31/21 2:55 AM, Henrik Bengtsson wrote:
> >> ... If one still needed backslashes,
> >> they could then be entered in single quotes, e.g. VAR='c:\users'.
> > I don't think it matters whether you use single or double quotes -
> > both will work.  Here's a proof of concept on Linux with R 4.1.1:
> >
> > $ cat ./.Renviron
> > A=C:\users
> > B='C:\users'
> > C="C:\users"
> >
> > $ Rscript -e "Sys.getenv(c('A', 'B', 'C'))"
> >            A           B           C
> >    "C:users" "C:\\users" "C:\\users"
>
> Yes, but as I wrote "I think the Renviron files should be written in a
> way so that they would work the same in a POSIX shell". This is why
> single quotes. With double quotes, backslashes are interpreted
> differently from a POSIX shell.
>
> Tomas
>
>
> >
> > /Henrik
> >
> > On Wed, Oct 27, 2021 at 11:45 AM Tomas Kalibera
> > <tomas.kalibera at gmail.com> wrote:
> >>
> >> On 10/21/21 5:18 PM, Martin Maechler wrote:
> >>>>>>>> Micha? Bojanowski
> >>>>>>>>       on Wed, 20 Oct 2021 16:31:08 +0200 writes:
> >>>       > Hello Tomas,
> >>>       > Yes, that's accurate although rather terse, which is perhaps the
> >>>       > reason why I did not realize it applies to my case.
> >>>
> >>>       > How about adding something in the direction of:
> >>>
> >>>       > 1. Continuing the cited paragraph with:
> >>>       > In particular, on Windows it may be necessary to quote references to
> >>>       > existing environment variables, especially those containing file paths
> >>>       > (which include backslashes). For example: `"${WINVAR}"`.
> >>>
> >>>       > 2. Add an example (not run):
> >>>
> >>>       > # On Windows do quote references to variables containing paths, e.g.:
> >>>       > # If APPDATA=C:\Users\foobar\AppData\Roaming
> >>>       > # to point to a library tree inside APPDATA in .Renviron use
> >>>       > R_LIBS_USER="${APPDATA}"/R-library
> >>>
> >>>       > Incidentally the last example is on backslashes too.
> >>>
> >>>
> >>>       > What do you think?
> >>>
> >>> I agree that adding an example really helps a lot in such cases,
> >>> in my experience, notably if it's precise enough to be used +/- directly.
> >> Yes, I agree as well. I think the Renviron files should be written in a
> >> way so that they would work the same in a POSIX shell, so e.g.
> >> VAR="${VAR0}" or VAR="${VAR0}/subdir" are the recommended ways to
> >> preserve backslashes in VAR0. It is better to use forward slashes in
> >> string literals, e.g. VAR="c:/users". If one still needed backslashes,
> >> they could then be entered in single quotes, e.g. VAR='c:\users'.
> >>
> >> The currently implemented parsing of Renviron files differs in a number
> >> of details from POSIX shells, some are documented and some are not.
> >> Relying only on the documented behavior that is the same as in POSIX
> >> shells is the best choice for future compatibility.
> >>
> >> Tomas
> >>
> >>>
> >>>       > On Mon, Oct 18, 2021 at 5:02 PM Tomas Kalibera <tomas.kalibera at gmail.com> wrote:
> >>>       >>
> >>>       >>
> >>>       >> On 10/15/21 6:44 PM, Micha? Bojanowski wrote:
> >>>       >> > Perhaps a small update to ?.Renviron would be in order to mention that...
> >>>       >>
> >>>       >> Would you have a more specific suggestion how to update the
> >>>       >> documentation? Please note that it already says
> >>>       >>
> >>>       >> "?value? is then processed in a similar way to a Unix shell: in
> >>>       >> particular the outermost level of (single or double) quotes is stripped,
> >>>       >> and backslashes are removed except inside quotes."
> >>>       >>
> >>>       >> Thanks,
> >>>       >> Tomas
> >>>       >>
> >>>       >> > On Fri, Oct 15, 2021 at 6:43 PM Micha? Bojanowski <michal2992 at gmail.com> wrote:
> >>>       >> >> Indeed quoting works! Kevin suggested the same, but he didnt reply to the list.
> >>>       >> >> Thank you all!
> >>>       >> >> Michal
> >>>       >> >>
> >>>       >> >> On Fri, Oct 15, 2021 at 6:40 PM Ivan Krylov <krylov.r00t at gmail.com> wrote:
> >>>       >> >>> Sorry for the noise! I wasn't supposed to send my previous message.
> >>>       >> >>>
> >>>       >> >>> On Fri, 15 Oct 2021 16:44:28 +0200
> >>>       >> >>> Micha? Bojanowski <michal2992 at gmail.com> wrote:
> >>>       >> >>>
> >>>       >> >>>> AVAR=${APPDATA}/foo/bar
> >>>       >> >>>>
> >>>       >> >>>> Which is a documented way of referring to existing environment
> >>>       >> >>>> variables. Now, with that in R I'm getting:
> >>>       >> >>>>
> >>>       >> >>>> Sys.getenv("APPDATA")    # That works OK
> >>>       >> >>>> [1] "C:\\Users\\mbojanowski\\AppData\\Roaming"
> >>>       >> >>>>
> >>>       >> >>>> so OK, but:
> >>>       >> >>>>
> >>>       >> >>>> Sys.getenv("AVAR")
> >>>       >> >>>> [1] "C:UsersmbojanowskiAppDataRoaming/foo/bar"
> >>>       >> >>> Hmm, a function called by readRenviron does seem to remove backslashes,
> >>>       >> >>> but not if they are encountered inside quotes:
> >>>       >> >>>
> >>>       >> >>> https://github.com/r-devel/r-svn/blob/3f8b75857fb1397f9f3ceab6c75554e1a5386adc/src/main/Renviron.c#L149
> >>>       >> >>>
> >>>       >> >>> Would AVAR="${APPDATA}"/foo/bar work?
> >>>       >> >>>
> >>>       >> >>> --
> >>>       >> >>> Best regards,
> >>>       >> >>> Ivan
> >>>       >> > ______________________________________________
> >>>       >> > R-devel at r-project.org mailing list
> >>>       >> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>
> >>>       > ______________________________________________
> >>>       > R-devel at r-project.org mailing list
> >>>       > https://stat.ethz.ch/mailman/listinfo/r-devel
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel


From henr|k@bengt@@on @end|ng |rom gm@||@com  Wed Nov  3 01:52:29 2021
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Tue, 2 Nov 2021 17:52:29 -0700
Subject: [Rd] 
 BUG?: R CMD check with --as-cran *disables* checks for unused
 imports otherwise performed
In-Reply-To: <CANBtttbbDsSkgvDseywE3vi7jxcPG6V4Es_JfP7tWZQm4LTyoA@mail.gmail.com>
References: <CAFDcVCQtwySG8HpbOABqoKJ=B7kiQpj57SaU_hzQ=hSWDDa_GA@mail.gmail.com>
 <CANBtttbbDsSkgvDseywE3vi7jxcPG6V4Es_JfP7tWZQm4LTyoA@mail.gmail.com>
Message-ID: <CAFDcVCRtii3+EbXH=rPrvgYF1pGsVdeWApG749r-B8Kmku2OeA@mail.gmail.com>

I've just posted this to BugZilla as PR18229
(https://bugs.r-project.org/show_bug.cgi?id=18229) to make sure it's
tracked.

/Henrik

On Wed, Oct 20, 2021 at 8:08 PM Jeffrey Dick <j3ffdick at gmail.com> wrote:
>
> FWIW, I also encountered this issue and posted on R-pkg-devel about it, with no resolution at the time (May 2020). See "Dependencies NOTE lost with --as-cran" (https://stat.ethz.ch/pipermail/r-package-devel/2020q2/005467.html)
>
> On Wed, Oct 20, 2021 at 11:55 PM Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:
>>
>> ISSUE:
>>
>> Using 'R CMD check' with --as-cran,
>> set_R_CHECK_PACKAGES_USED_IGNORE_UNUSED_IMPORTS_=TRUE, whereas the
>> default is FALSE, which you get if you don't add --as-cran.
>> I would expect --as-cran to check more things and more be conservative
>> than without.  So, is this behavior a mistake?  Could it be a thinko
>> around the negating "IGNORE", and the behavior is meant to be vice
>> verse?
>>
>> Example:
>>
>> $ R CMD check QDNAseq_1.29.4.tar.gz
>> ...
>> * using R version 4.1.1 (2021-08-10)
>> * using platform: x86_64-pc-linux-gnu (64-bit)
>> ...
>> * checking dependencies in R code ... NOTE
>> Namespace in Imports field not imported from: ?future?
>>   All declared Imports should be used.
>>
>> whereas, if I run with --as-cran, I don't get that NOTE;
>>
>> $ R CMD check --as-cran QDNAseq_1.29.4.tar.gz
>> ...
>> * checking dependencies in R code ... OK
>>
>>
>> TROUBLESHOOTING:
>>
>> In src/library/tools/R/check.R [1], the following is set if --as-cran is used:
>>
>>   Sys.setenv("_R_CHECK_PACKAGES_USED_IGNORE_UNUSED_IMPORTS_" = "TRUE")
>>
>> whereas, if not set, the default is:
>>
>> ignore_unused_imports <-
>> config_val_to_logical(Sys.getenv("_R_CHECK_PACKAGES_USED_IGNORE_UNUSED_IMPORTS_",
>> "FALSE"))
>>
>> [1] https://github.com/wch/r-source/blob/b50e3f755674cbb697a4a7395b766647a5cfeea2/src/library/tools/R/check.R#L6335
>> [2] https://github.com/wch/r-source/blob/b50e3f755674cbb697a4a7395b766647a5cfeea2/src/library/tools/R/QC.R#L5954-L5956
>>
>> /Henrik
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From tom@@@k@||ber@ @end|ng |rom gm@||@com  Wed Nov  3 11:30:37 2021
From: tom@@@k@||ber@ @end|ng |rom gm@||@com (Tomas Kalibera)
Date: Wed, 3 Nov 2021 11:30:37 +0100
Subject: [Rd] Fwd: Using existing envars in Renviron on friendly Windows
In-Reply-To: <CAFDcVCRn1kKeEPCqzjMrcCN=38GZa_ODHRvO6Oq8GccoaxX7bg@mail.gmail.com>
References: <CAByPayHQ33kLY+S6U6NGAzHRuMZJQhaoPhbCDGt6EpgAU9aB5w@mail.gmail.com>
 <CAByPayFCM72e32p6aBshSa0oD0wijUkRQ-vKKT9Aq2YD5rKrpg@mail.gmail.com>
 <20211015194037.595b389f@Tarkus>
 <CAByPayFOobioF-W6Xt=6vkEw2srbg1xc9p6YvyO+r-yu=4doTg@mail.gmail.com>
 <CAByPayEZskmsn1bsFACYvxUC+ENaDfyoJsvbxwxLKc8gNyRgzQ@mail.gmail.com>
 <3ec44e42-f7af-575c-1b69-fe7e2bda00b2@gmail.com>
 <CAByPayH4dzWOqnaFg0z=UxjgHp6BSNrP17DP3RJ4qLPfw6q33A@mail.gmail.com>
 <24945.33990.369010.718929@stat.math.ethz.ch>
 <38f36d15-c08e-d57c-41f7-31dcc9449e84@gmail.com>
 <CAFDcVCSmQO43H7Jpj132ba13Lg0GfyFQoa+ev0st5kH3bhZL4A@mail.gmail.com>
 <87e89990-ebc4-6879-a34e-4301c3b83563@gmail.com>
 <CAFDcVCRn1kKeEPCqzjMrcCN=38GZa_ODHRvO6Oq8GccoaxX7bg@mail.gmail.com>
Message-ID: <a85d0f84-413f-944a-ed8f-1a3420a231b4@gmail.com>


On 11/3/21 1:37 AM, Henrik Bengtsson wrote:
> Oh, I see, I misunderstood.  Thanks for clarifying.
>
> One more thing, to mix-and-match environment variables and strings
> with escaped characters, while mimicking how POSIX shells does it, by
> using strings with double and single quotes. For example, with:
>
> $ cat .Renviron
> APPDATA='C:\Users\foobar\AppData\Roaming'
> R_LIBS_USER="${APPDATA}"'\R-library'
>
> we get:
>
> $ Rscript --no-init-file --quiet -e 'cat(sprintf("R_LIBS_USER=[%s]\n",
> Sys.getenv("R_LIBS_USER")))'
> R_LIBS_USER=[C:\Users\foobar\AppData\Roaming\R-library]
>
> and
>
> $ source .Renviron
> $ echo "R_LIBS_USER=[${R_LIBS_USER}]"
> R_LIBS_USER=[C:\Users\foobar\AppData\Roaming\R-library]
Yes, that could be mentioned explicitly as well.

Tomas


>
> /Henrik
>
> On Sun, Oct 31, 2021 at 2:59 AM Tomas Kalibera <tomas.kalibera at gmail.com> wrote:
>>
>> On 10/31/21 2:55 AM, Henrik Bengtsson wrote:
>>>> ... If one still needed backslashes,
>>>> they could then be entered in single quotes, e.g. VAR='c:\users'.
>>> I don't think it matters whether you use single or double quotes -
>>> both will work.  Here's a proof of concept on Linux with R 4.1.1:
>>>
>>> $ cat ./.Renviron
>>> A=C:\users
>>> B='C:\users'
>>> C="C:\users"
>>>
>>> $ Rscript -e "Sys.getenv(c('A', 'B', 'C'))"
>>>             A           B           C
>>>     "C:users" "C:\\users" "C:\\users"
>> Yes, but as I wrote "I think the Renviron files should be written in a
>> way so that they would work the same in a POSIX shell". This is why
>> single quotes. With double quotes, backslashes are interpreted
>> differently from a POSIX shell.
>>
>> Tomas
>>
>>
>>> /Henrik
>>>
>>> On Wed, Oct 27, 2021 at 11:45 AM Tomas Kalibera
>>> <tomas.kalibera at gmail.com> wrote:
>>>> On 10/21/21 5:18 PM, Martin Maechler wrote:
>>>>>>>>>> Micha? Bojanowski
>>>>>>>>>>        on Wed, 20 Oct 2021 16:31:08 +0200 writes:
>>>>>        > Hello Tomas,
>>>>>        > Yes, that's accurate although rather terse, which is perhaps the
>>>>>        > reason why I did not realize it applies to my case.
>>>>>
>>>>>        > How about adding something in the direction of:
>>>>>
>>>>>        > 1. Continuing the cited paragraph with:
>>>>>        > In particular, on Windows it may be necessary to quote references to
>>>>>        > existing environment variables, especially those containing file paths
>>>>>        > (which include backslashes). For example: `"${WINVAR}"`.
>>>>>
>>>>>        > 2. Add an example (not run):
>>>>>
>>>>>        > # On Windows do quote references to variables containing paths, e.g.:
>>>>>        > # If APPDATA=C:\Users\foobar\AppData\Roaming
>>>>>        > # to point to a library tree inside APPDATA in .Renviron use
>>>>>        > R_LIBS_USER="${APPDATA}"/R-library
>>>>>
>>>>>        > Incidentally the last example is on backslashes too.
>>>>>
>>>>>
>>>>>        > What do you think?
>>>>>
>>>>> I agree that adding an example really helps a lot in such cases,
>>>>> in my experience, notably if it's precise enough to be used +/- directly.
>>>> Yes, I agree as well. I think the Renviron files should be written in a
>>>> way so that they would work the same in a POSIX shell, so e.g.
>>>> VAR="${VAR0}" or VAR="${VAR0}/subdir" are the recommended ways to
>>>> preserve backslashes in VAR0. It is better to use forward slashes in
>>>> string literals, e.g. VAR="c:/users". If one still needed backslashes,
>>>> they could then be entered in single quotes, e.g. VAR='c:\users'.
>>>>
>>>> The currently implemented parsing of Renviron files differs in a number
>>>> of details from POSIX shells, some are documented and some are not.
>>>> Relying only on the documented behavior that is the same as in POSIX
>>>> shells is the best choice for future compatibility.
>>>>
>>>> Tomas
>>>>
>>>>>        > On Mon, Oct 18, 2021 at 5:02 PM Tomas Kalibera <tomas.kalibera at gmail.com> wrote:
>>>>>        >>
>>>>>        >>
>>>>>        >> On 10/15/21 6:44 PM, Micha? Bojanowski wrote:
>>>>>        >> > Perhaps a small update to ?.Renviron would be in order to mention that...
>>>>>        >>
>>>>>        >> Would you have a more specific suggestion how to update the
>>>>>        >> documentation? Please note that it already says
>>>>>        >>
>>>>>        >> "?value? is then processed in a similar way to a Unix shell: in
>>>>>        >> particular the outermost level of (single or double) quotes is stripped,
>>>>>        >> and backslashes are removed except inside quotes."
>>>>>        >>
>>>>>        >> Thanks,
>>>>>        >> Tomas
>>>>>        >>
>>>>>        >> > On Fri, Oct 15, 2021 at 6:43 PM Micha? Bojanowski <michal2992 at gmail.com> wrote:
>>>>>        >> >> Indeed quoting works! Kevin suggested the same, but he didnt reply to the list.
>>>>>        >> >> Thank you all!
>>>>>        >> >> Michal
>>>>>        >> >>
>>>>>        >> >> On Fri, Oct 15, 2021 at 6:40 PM Ivan Krylov <krylov.r00t at gmail.com> wrote:
>>>>>        >> >>> Sorry for the noise! I wasn't supposed to send my previous message.
>>>>>        >> >>>
>>>>>        >> >>> On Fri, 15 Oct 2021 16:44:28 +0200
>>>>>        >> >>> Micha? Bojanowski <michal2992 at gmail.com> wrote:
>>>>>        >> >>>
>>>>>        >> >>>> AVAR=${APPDATA}/foo/bar
>>>>>        >> >>>>
>>>>>        >> >>>> Which is a documented way of referring to existing environment
>>>>>        >> >>>> variables. Now, with that in R I'm getting:
>>>>>        >> >>>>
>>>>>        >> >>>> Sys.getenv("APPDATA")    # That works OK
>>>>>        >> >>>> [1] "C:\\Users\\mbojanowski\\AppData\\Roaming"
>>>>>        >> >>>>
>>>>>        >> >>>> so OK, but:
>>>>>        >> >>>>
>>>>>        >> >>>> Sys.getenv("AVAR")
>>>>>        >> >>>> [1] "C:UsersmbojanowskiAppDataRoaming/foo/bar"
>>>>>        >> >>> Hmm, a function called by readRenviron does seem to remove backslashes,
>>>>>        >> >>> but not if they are encountered inside quotes:
>>>>>        >> >>>
>>>>>        >> >>> https://github.com/r-devel/r-svn/blob/3f8b75857fb1397f9f3ceab6c75554e1a5386adc/src/main/Renviron.c#L149
>>>>>        >> >>>
>>>>>        >> >>> Would AVAR="${APPDATA}"/foo/bar work?
>>>>>        >> >>>
>>>>>        >> >>> --
>>>>>        >> >>> Best regards,
>>>>>        >> >>> Ivan
>>>>>        >> > ______________________________________________
>>>>>        >> > R-devel at r-project.org mailing list
>>>>>        >> > https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>>>        > ______________________________________________
>>>>>        > R-devel at r-project.org mailing list
>>>>>        > https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel


From dmedri m@iii@g oii gm@ii@com  Wed Nov  3 12:36:12 2021
From: dmedri m@iii@g oii gm@ii@com (dmedri m@iii@g oii gm@ii@com)
Date: Wed, 03 Nov 2021 12:36:12 +0100
Subject: [Rd] R 4.1.2 is released
In-Reply-To: <C893C950-C99E-4931-9481-095FB0115737@gmail.com>
References: <C893C950-C99E-4931-9481-095FB0115737@gmail.com>
Message-ID: <73bd5b0043565985e353662cd4655905d1fc090f.camel@gmail.com>

Il giorno lun, 01/11/2021 alle 09.35 +0100, Peter Dalgaard ha scritto:
> The build system rolled up R-4.1.2.tar.gz (codename "Bird Hippie") this
> morning.

Dear Peter Dalgaard,
thank you very much for you work.

The italian translation in codebase should be already up-to sync, but
latest updated version is in my github repo:

https://github.com/dmedri/R-italian-lang/releases/tag/R4.1.2


To update R and test latest translations in an unusual way:

# get the latest Roaster release

git clone https://www.github.com/dmedri/roaster
cd roaster/

# select your build configuration on Linux:
# 1. standard build in system (--build-standard)
# 2. virtual environment (--build-virtualenv)
# 3. server (--build-server)

./roaster --build-virtualenv

# get the latest Italian translation:

git clone https://www.github.com/dmedri/R-italian-lang
cd R-italian-lang/
./repo.roaster


HTH

Best Regards
--
DM


From r-deve| @end|ng |rom @ker@t|ng@de  Wed Nov  3 12:51:43 2021
From: r-deve| @end|ng |rom @ker@t|ng@de (Andreas Kersting)
Date: Wed, 03 Nov 2021 12:51:43 +0100 (CET)
Subject: [Rd] GC: speeding-up the CHARSXP cache maintenance, 2nd try
Message-ID: <E1miEnv-0003jj-HB@rmmprod05.runbox>

Hi,

In https://stat.ethz.ch/pipermail/r-devel/2021-October/081147.html I proposed to speed up the CHARSXP cache maintenance during GC using threading. This was rejected by Luke in https://stat.ethz.ch/pipermail/r-devel/2021-October/081172.html.

Here I want to propose an alternative approach to significantly speed up CHARSXP cache maintenance during partial GCs. A patch which passes `make check-devel` is attached. Compared to R devel (revision 81110) I get the following performance improvements on my system:

Elapsed time for five non-full gc in a session after

x <- as.character(runif(5e7))[]
gc(full = TRUE)

+20sec -> ~1sec.


This patch introduces (theoretical) overheads to mkCharLenCE() and full GCs. However, I did not measure dramatic differences:

y <- "old_CHARSXP" 

after

x <- "old_CHARSXP"; gc(); gc()

takes a median 32 nanoseconds with and without the patch.


gc(full = TRUE)

in a new session takes a median 16 milliseconds with and 14 without the patch.


The basic idea is to maintain the CHARSXP cache using subtables in R_StringHash, one for each of the (NUM_GC_GENERATIONS := NUM_OLD_GENERATIONS + 1) GC generations. New CHARSXPs are added by mkCharLenCE() to the subtable of the youngest generation. After a partial GC, only the chains anchored at the subtables of the youngest (num_old_gens_to_collect + 1) generations need to be searched for and cleaned of unmarked nodes. Afterwards, these chains need to be merged into those of the respective next generation, if any. This approach relies on the fact that an object/CHARSXP can never become younger again. It is OK though if an object/CHARSXP "skips" a GC generation.

R_StringHash, which is now of length (NUM_GC_GENERATIONS * char_hash_size), is structured such that the chains for the same hashcode but for different generations are anchored at slots of R_StringHash which are next to each other in memory. This is because we often need to access two or more (i.e. currently all three) of them for one operation and this avoids cache misses.

HASHPRI, i.e. the number of occupied primary slots, is computed and stored as NUM_GC_GENERATIONS times the number of slots which are occupied in at least one of the subtables. This is done because in mkCharLenCE() we need to iterate through one or more chains if and only if there is a chain for the particular hashcode in at least one subtable.

I tried to keep the patch as minimal as possible. In particular, I did not add long vector support to R_StringHash. I rather reduced the max value of char_hash_size from 2^30 to 2^29, assuming that NUM_OLD_GENERATIONS is (not larger than) 2. I also did not yet adjust do_show_cache() and do_write_cache(), but I could do so if the patch is accepted.

Thanks for your consideration and feedback.

Regards,
Andreas


P.S. I had a hard time to get the indentation right in the patch due the mix of tabs and spaces. Sorry, if I screwed this up.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: r_stringhash.diff
Type: text/x-patch
Size: 8495 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20211103/078ff701/attachment.bin>

From tom@@@k@||ber@ @end|ng |rom gm@||@com  Thu Nov  4 15:24:09 2021
From: tom@@@k@||ber@ @end|ng |rom gm@||@com (Tomas Kalibera)
Date: Thu, 4 Nov 2021 15:24:09 +0100
Subject: [Rd] Fwd: Using existing envars in Renviron on friendly Windows
In-Reply-To: <a85d0f84-413f-944a-ed8f-1a3420a231b4@gmail.com>
References: <CAByPayHQ33kLY+S6U6NGAzHRuMZJQhaoPhbCDGt6EpgAU9aB5w@mail.gmail.com>
 <CAByPayFCM72e32p6aBshSa0oD0wijUkRQ-vKKT9Aq2YD5rKrpg@mail.gmail.com>
 <20211015194037.595b389f@Tarkus>
 <CAByPayFOobioF-W6Xt=6vkEw2srbg1xc9p6YvyO+r-yu=4doTg@mail.gmail.com>
 <CAByPayEZskmsn1bsFACYvxUC+ENaDfyoJsvbxwxLKc8gNyRgzQ@mail.gmail.com>
 <3ec44e42-f7af-575c-1b69-fe7e2bda00b2@gmail.com>
 <CAByPayH4dzWOqnaFg0z=UxjgHp6BSNrP17DP3RJ4qLPfw6q33A@mail.gmail.com>
 <24945.33990.369010.718929@stat.math.ethz.ch>
 <38f36d15-c08e-d57c-41f7-31dcc9449e84@gmail.com>
 <CAFDcVCSmQO43H7Jpj132ba13Lg0GfyFQoa+ev0st5kH3bhZL4A@mail.gmail.com>
 <87e89990-ebc4-6879-a34e-4301c3b83563@gmail.com>
 <CAFDcVCRn1kKeEPCqzjMrcCN=38GZa_ODHRvO6Oq8GccoaxX7bg@mail.gmail.com>
 <a85d0f84-413f-944a-ed8f-1a3420a231b4@gmail.com>
Message-ID: <25766be5-137b-e8e2-292a-e43f77b042c4@gmail.com>

Thanks for the suggestions, I've updated the documentation.
Tomas

On 11/3/21 11:30 AM, Tomas Kalibera wrote:
>
> On 11/3/21 1:37 AM, Henrik Bengtsson wrote:
>> Oh, I see, I misunderstood.? Thanks for clarifying.
>>
>> One more thing, to mix-and-match environment variables and strings
>> with escaped characters, while mimicking how POSIX shells does it, by
>> using strings with double and single quotes. For example, with:
>>
>> $ cat .Renviron
>> APPDATA='C:\Users\foobar\AppData\Roaming'
>> R_LIBS_USER="${APPDATA}"'\R-library'
>>
>> we get:
>>
>> $ Rscript --no-init-file --quiet -e 'cat(sprintf("R_LIBS_USER=[%s]\n",
>> Sys.getenv("R_LIBS_USER")))'
>> R_LIBS_USER=[C:\Users\foobar\AppData\Roaming\R-library]
>>
>> and
>>
>> $ source .Renviron
>> $ echo "R_LIBS_USER=[${R_LIBS_USER}]"
>> R_LIBS_USER=[C:\Users\foobar\AppData\Roaming\R-library]
> Yes, that could be mentioned explicitly as well.
>
> Tomas
>
>
>>
>> /Henrik
>>
>> On Sun, Oct 31, 2021 at 2:59 AM Tomas Kalibera 
>> <tomas.kalibera at gmail.com> wrote:
>>>
>>> On 10/31/21 2:55 AM, Henrik Bengtsson wrote:
>>>>> ... If one still needed backslashes,
>>>>> they could then be entered in single quotes, e.g. VAR='c:\users'.
>>>> I don't think it matters whether you use single or double quotes -
>>>> both will work.? Here's a proof of concept on Linux with R 4.1.1:
>>>>
>>>> $ cat ./.Renviron
>>>> A=C:\users
>>>> B='C:\users'
>>>> C="C:\users"
>>>>
>>>> $ Rscript -e "Sys.getenv(c('A', 'B', 'C'))"
>>>> ??????????? A?????????? B?????????? C
>>>> ??? "C:users" "C:\\users" "C:\\users"
>>> Yes, but as I wrote "I think the Renviron files should be written in a
>>> way so that they would work the same in a POSIX shell". This is why
>>> single quotes. With double quotes, backslashes are interpreted
>>> differently from a POSIX shell.
>>>
>>> Tomas
>>>
>>>
>>>> /Henrik
>>>>
>>>> On Wed, Oct 27, 2021 at 11:45 AM Tomas Kalibera
>>>> <tomas.kalibera at gmail.com> wrote:
>>>>> On 10/21/21 5:18 PM, Martin Maechler wrote:
>>>>>>>>>>> Micha? Bojanowski
>>>>>>>>>>> ?????? on Wed, 20 Oct 2021 16:31:08 +0200 writes:
>>>>>> ?????? > Hello Tomas,
>>>>>> ?????? > Yes, that's accurate although rather terse, which is 
>>>>>> perhaps the
>>>>>> ?????? > reason why I did not realize it applies to my case.
>>>>>>
>>>>>> ?????? > How about adding something in the direction of:
>>>>>>
>>>>>> ?????? > 1. Continuing the cited paragraph with:
>>>>>> ?????? > In particular, on Windows it may be necessary to quote 
>>>>>> references to
>>>>>> ?????? > existing environment variables, especially those 
>>>>>> containing file paths
>>>>>> ?????? > (which include backslashes). For example: `"${WINVAR}"`.
>>>>>>
>>>>>> ?????? > 2. Add an example (not run):
>>>>>>
>>>>>> ?????? > # On Windows do quote references to variables containing 
>>>>>> paths, e.g.:
>>>>>> ?????? > # If APPDATA=C:\Users\foobar\AppData\Roaming
>>>>>> ?????? > # to point to a library tree inside APPDATA in .Renviron 
>>>>>> use
>>>>>> ?????? > R_LIBS_USER="${APPDATA}"/R-library
>>>>>>
>>>>>> ?????? > Incidentally the last example is on backslashes too.
>>>>>>
>>>>>>
>>>>>> ?????? > What do you think?
>>>>>>
>>>>>> I agree that adding an example really helps a lot in such cases,
>>>>>> in my experience, notably if it's precise enough to be used +/- 
>>>>>> directly.
>>>>> Yes, I agree as well. I think the Renviron files should be written 
>>>>> in a
>>>>> way so that they would work the same in a POSIX shell, so e.g.
>>>>> VAR="${VAR0}" or VAR="${VAR0}/subdir" are the recommended ways to
>>>>> preserve backslashes in VAR0. It is better to use forward slashes in
>>>>> string literals, e.g. VAR="c:/users". If one still needed 
>>>>> backslashes,
>>>>> they could then be entered in single quotes, e.g. VAR='c:\users'.
>>>>>
>>>>> The currently implemented parsing of Renviron files differs in a 
>>>>> number
>>>>> of details from POSIX shells, some are documented and some are not.
>>>>> Relying only on the documented behavior that is the same as in POSIX
>>>>> shells is the best choice for future compatibility.
>>>>>
>>>>> Tomas
>>>>>
>>>>>> ?????? > On Mon, Oct 18, 2021 at 5:02 PM Tomas Kalibera 
>>>>>> <tomas.kalibera at gmail.com> wrote:
>>>>>> ?????? >>
>>>>>> ?????? >>
>>>>>> ?????? >> On 10/15/21 6:44 PM, Micha? Bojanowski wrote:
>>>>>> ?????? >> > Perhaps a small update to ?.Renviron would be in 
>>>>>> order to mention that...
>>>>>> ?????? >>
>>>>>> ?????? >> Would you have a more specific suggestion how to update 
>>>>>> the
>>>>>> ?????? >> documentation? Please note that it already says
>>>>>> ?????? >>
>>>>>> ?????? >> "?value? is then processed in a similar way to a Unix 
>>>>>> shell: in
>>>>>> ?????? >> particular the outermost level of (single or double) 
>>>>>> quotes is stripped,
>>>>>> ?????? >> and backslashes are removed except inside quotes."
>>>>>> ?????? >>
>>>>>> ?????? >> Thanks,
>>>>>> ?????? >> Tomas
>>>>>> ?????? >>
>>>>>> ?????? >> > On Fri, Oct 15, 2021 at 6:43 PM Micha? Bojanowski 
>>>>>> <michal2992 at gmail.com> wrote:
>>>>>> ?????? >> >> Indeed quoting works! Kevin suggested the same, but 
>>>>>> he didnt reply to the list.
>>>>>> ?????? >> >> Thank you all!
>>>>>> ?????? >> >> Michal
>>>>>> ?????? >> >>
>>>>>> ?????? >> >> On Fri, Oct 15, 2021 at 6:40 PM Ivan Krylov 
>>>>>> <krylov.r00t at gmail.com> wrote:
>>>>>> ?????? >> >>> Sorry for the noise! I wasn't supposed to send my 
>>>>>> previous message.
>>>>>> ?????? >> >>>
>>>>>> ?????? >> >>> On Fri, 15 Oct 2021 16:44:28 +0200
>>>>>> ?????? >> >>> Micha? Bojanowski <michal2992 at gmail.com> wrote:
>>>>>> ?????? >> >>>
>>>>>> ?????? >> >>>> AVAR=${APPDATA}/foo/bar
>>>>>> ?????? >> >>>>
>>>>>> ?????? >> >>>> Which is a documented way of referring to existing 
>>>>>> environment
>>>>>> ?????? >> >>>> variables. Now, with that in R I'm getting:
>>>>>> ?????? >> >>>>
>>>>>> ?????? >> >>>> Sys.getenv("APPDATA")??? # That works OK
>>>>>> ?????? >> >>>> [1] "C:\\Users\\mbojanowski\\AppData\\Roaming"
>>>>>> ?????? >> >>>>
>>>>>> ?????? >> >>>> so OK, but:
>>>>>> ?????? >> >>>>
>>>>>> ?????? >> >>>> Sys.getenv("AVAR")
>>>>>> ?????? >> >>>> [1] "C:UsersmbojanowskiAppDataRoaming/foo/bar"
>>>>>> ?????? >> >>> Hmm, a function called by readRenviron does seem to 
>>>>>> remove backslashes,
>>>>>> ?????? >> >>> but not if they are encountered inside quotes:
>>>>>> ?????? >> >>>
>>>>>> ?????? >> >>> 
>>>>>> https://github.com/r-devel/r-svn/blob/3f8b75857fb1397f9f3ceab6c75554e1a5386adc/src/main/Renviron.c#L149
>>>>>> ?????? >> >>>
>>>>>> ?????? >> >>> Would AVAR="${APPDATA}"/foo/bar work?
>>>>>> ?????? >> >>>
>>>>>> ?????? >> >>> --
>>>>>> ?????? >> >>> Best regards,
>>>>>> ?????? >> >>> Ivan
>>>>>> ?????? >> > ______________________________________________
>>>>>> ?????? >> > R-devel at r-project.org mailing list
>>>>>> ?????? >> > https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>
>>>>>> ?????? > ______________________________________________
>>>>>> ?????? > R-devel at r-project.org mailing list
>>>>>> ?????? > https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel


From iuke-tier@ey m@iii@g oii uiow@@edu  Thu Nov  4 17:04:18 2021
From: iuke-tier@ey m@iii@g oii uiow@@edu (iuke-tier@ey m@iii@g oii uiow@@edu)
Date: Thu, 4 Nov 2021 11:04:18 -0500 (CDT)
Subject: [Rd] [External]  GC: speeding-up the CHARSXP cache maintenance,
 2nd try
In-Reply-To: <E1miEnv-0003jj-HB@rmmprod05.runbox>
References: <E1miEnv-0003jj-HB@rmmprod05.runbox>
Message-ID: <alpine.DEB.2.22.394.2111041100400.388953@luke-Latitude-7480>

Can you please submit this as a wishlist item to bugzilla? it is
easier to keep track of there. You could also submit your threads
based suggestion there, again to keep it easier to keep track of and
possibly get back to in the future.

I will have a look at your approach when I get a chance, but I am
exploring a different approach to avoid scanning old generations that
may be simpler.

Best,

luke

On Wed, 3 Nov 2021, Andreas Kersting wrote:

> Hi,
>
> In https://stat.ethz.ch/pipermail/r-devel/2021-October/081147.html I proposed to speed up the CHARSXP cache maintenance during GC using threading. This was rejected by Luke in https://stat.ethz.ch/pipermail/r-devel/2021-October/081172.html.
>
> Here I want to propose an alternative approach to significantly speed up CHARSXP cache maintenance during partial GCs. A patch which passes `make check-devel` is attached. Compared to R devel (revision 81110) I get the following performance improvements on my system:
>
> Elapsed time for five non-full gc in a session after
>
> x <- as.character(runif(5e7))[]
> gc(full = TRUE)
>
> +20sec -> ~1sec.
>
>
> This patch introduces (theoretical) overheads to mkCharLenCE() and full GCs. However, I did not measure dramatic differences:
>
> y <- "old_CHARSXP"
>
> after
>
> x <- "old_CHARSXP"; gc(); gc()
>
> takes a median 32 nanoseconds with and without the patch.
>
>
> gc(full = TRUE)
>
> in a new session takes a median 16 milliseconds with and 14 without the patch.
>
>
> The basic idea is to maintain the CHARSXP cache using subtables in R_StringHash, one for each of the (NUM_GC_GENERATIONS := NUM_OLD_GENERATIONS + 1) GC generations. New CHARSXPs are added by mkCharLenCE() to the subtable of the youngest generation. After a partial GC, only the chains anchored at the subtables of the youngest (num_old_gens_to_collect + 1) generations need to be searched for and cleaned of unmarked nodes. Afterwards, these chains need to be merged into those of the respective next generation, if any. This approach relies on the fact that an object/CHARSXP can never become younger again. It is OK though if an object/CHARSXP "skips" a GC generation.
>
> R_StringHash, which is now of length (NUM_GC_GENERATIONS * char_hash_size), is structured such that the chains for the same hashcode but for different generations are anchored at slots of R_StringHash which are next to each other in memory. This is because we often need to access two or more (i.e. currently all three) of them for one operation and this avoids cache misses.
>
> HASHPRI, i.e. the number of occupied primary slots, is computed and stored as NUM_GC_GENERATIONS times the number of slots which are occupied in at least one of the subtables. This is done because in mkCharLenCE() we need to iterate through one or more chains if and only if there is a chain for the particular hashcode in at least one subtable.
>
> I tried to keep the patch as minimal as possible. In particular, I did not add long vector support to R_StringHash. I rather reduced the max value of char_hash_size from 2^30 to 2^29, assuming that NUM_OLD_GENERATIONS is (not larger than) 2. I also did not yet adjust do_show_cache() and do_write_cache(), but I could do so if the patch is accepted.
>
> Thanks for your consideration and feedback.
>
> Regards,
> Andreas
>
>
> P.S. I had a hard time to get the indentation right in the patch due the mix of tabs and spaces. Sorry, if I screwed this up.

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From ch|r|com @end|ng |rom goog|e@com  Thu Nov  4 19:50:04 2021
From: ch|r|com @end|ng |rom goog|e@com (Michael Chirico)
Date: Thu, 4 Nov 2021 11:50:04 -0700
Subject: [Rd] .onLoad, packageStartupMessage, and R CMD check
Message-ID: <CAD7Bkx9ySNzwwbnADzA3k=AA8gvW-jMdO+C_w9eHOAXR5pCeOg@mail.gmail.com>

I wrote a linter to stop users from using packageStartupMessage() in
their .onLoad() hook because of the R CMD check warning it triggers:

https://github.com/wch/r-source/blob/8b6625e39cd62424dc23399dade37f20fa8afa91/src/library/tools/R/QC.R#L5167

However, this received some pushback which I ultimately agree with,
and moreover ?.onLoad seems to agree as well:

> Loading a namespace should where possible be silent, with startup
messages given by \code{.onAttach}. These messages (**and any essential
ones from \code{.onLoad}**) should use \code{\link{packageStartupMessage}}
so they can be silenced where they would be a distraction.

**emphasis** mine. That is, if we think some message is _essential_ to
print during loadNamespace(), we are told to use
packageStartupMessage().

Should we remove this R CMD check warning?


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Nov  4 20:37:01 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 4 Nov 2021 15:37:01 -0400
Subject: [Rd] .onLoad, packageStartupMessage, and R CMD check
In-Reply-To: <CAD7Bkx9ySNzwwbnADzA3k=AA8gvW-jMdO+C_w9eHOAXR5pCeOg@mail.gmail.com>
References: <CAD7Bkx9ySNzwwbnADzA3k=AA8gvW-jMdO+C_w9eHOAXR5pCeOg@mail.gmail.com>
Message-ID: <c364a4c7-4db5-71e9-9079-0c694043a37f@gmail.com>

On 04/11/2021 2:50 p.m., Michael Chirico via R-devel wrote:
> I wrote a linter to stop users from using packageStartupMessage() in
> their .onLoad() hook because of the R CMD check warning it triggers:
> 
> https://github.com/wch/r-source/blob/8b6625e39cd62424dc23399dade37f20fa8afa91/src/library/tools/R/QC.R#L5167
> 
> However, this received some pushback which I ultimately agree with,
> and moreover ?.onLoad seems to agree as well:
> 
>> Loading a namespace should where possible be silent, with startup
> messages given by \code{.onAttach}. These messages (**and any essential
> ones from \code{.onLoad}**) should use \code{\link{packageStartupMessage}}
> so they can be silenced where they would be a distraction.
> 
> **emphasis** mine. That is, if we think some message is _essential_ to
> print during loadNamespace(), we are told to use
> packageStartupMessage().
> 
> Should we remove this R CMD check warning?

The help page doesn't define what an "essential" message would be, but I 
would assume it's a message about some dire condition, not just "Hi! I 
just got loaded!".  So I think a note or warning would be appropriate, 
but not an error.

Do you have an example of something that should routinely print, but 
that triggers a warning when checked?

Duncan Murdoch


From g@bembecker @end|ng |rom gm@||@com  Thu Nov  4 21:02:38 2021
From: g@bembecker @end|ng |rom gm@||@com (Gabriel Becker)
Date: Thu, 4 Nov 2021 13:02:38 -0700
Subject: [Rd] .onLoad, packageStartupMessage, and R CMD check
In-Reply-To: <c364a4c7-4db5-71e9-9079-0c694043a37f@gmail.com>
References: <CAD7Bkx9ySNzwwbnADzA3k=AA8gvW-jMdO+C_w9eHOAXR5pCeOg@mail.gmail.com>
 <c364a4c7-4db5-71e9-9079-0c694043a37f@gmail.com>
Message-ID: <CAD4oTHFAOdWPn2uORPRjQ_WACWVqWtb3kJDusfYRqBPRVMWDEQ@mail.gmail.com>

Hi Michael,

Indeed, just to elaborate further on what I believe Duncan's point is, can
you give any examples, "dire" or not, that are appropriate when the package
is loaded but not attached (ie none of its symbols are visible to the user
without using :::)?

The only things I can think of are a package that changes the behavior of
other, attached package code, such as conflicted. Doing so is very much an
anti-pattern imo generally, with something like conflicted being an
(arguable) exception. And that's assuming conflicted even works/does
anything when loaded but not attached (I have not confirmed whether thats
the case or not). That or a package that is at end-of-life and is or soon
will be unsupported entirely.

The examples don't need to be yours, per se, if you know what those pushing
back against your linter were using messages from .onLoad for...

Best,
~G



On Thu, Nov 4, 2021 at 12:37 PM Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 04/11/2021 2:50 p.m., Michael Chirico via R-devel wrote:
> > I wrote a linter to stop users from using packageStartupMessage() in
> > their .onLoad() hook because of the R CMD check warning it triggers:
> >
> >
> https://github.com/wch/r-source/blob/8b6625e39cd62424dc23399dade37f20fa8afa91/src/library/tools/R/QC.R#L5167
> >
> > However, this received some pushback which I ultimately agree with,
> > and moreover ?.onLoad seems to agree as well:
> >
> >> Loading a namespace should where possible be silent, with startup
> > messages given by \code{.onAttach}. These messages (**and any essential
> > ones from \code{.onLoad}**) should use
> \code{\link{packageStartupMessage}}
> > so they can be silenced where they would be a distraction.
> >
> > **emphasis** mine. That is, if we think some message is _essential_ to
> > print during loadNamespace(), we are told to use
> > packageStartupMessage().
> >
> > Should we remove this R CMD check warning?
>
> The help page doesn't define what an "essential" message would be, but I
> would assume it's a message about some dire condition, not just "Hi! I
> just got loaded!".  So I think a note or warning would be appropriate,
> but not an error.
>
> Do you have an example of something that should routinely print, but
> that triggers a warning when checked?
>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From ch|r|com @end|ng |rom goog|e@com  Fri Nov  5 06:08:51 2021
From: ch|r|com @end|ng |rom goog|e@com (Michael Chirico)
Date: Thu, 4 Nov 2021 22:08:51 -0700
Subject: [Rd] .onLoad, packageStartupMessage, and R CMD check
In-Reply-To: <CAD4oTHFAOdWPn2uORPRjQ_WACWVqWtb3kJDusfYRqBPRVMWDEQ@mail.gmail.com>
References: <CAD7Bkx9ySNzwwbnADzA3k=AA8gvW-jMdO+C_w9eHOAXR5pCeOg@mail.gmail.com>
 <c364a4c7-4db5-71e9-9079-0c694043a37f@gmail.com>
 <CAD4oTHFAOdWPn2uORPRjQ_WACWVqWtb3kJDusfYRqBPRVMWDEQ@mail.gmail.com>
Message-ID: <CAD7Bkx9idq2WjMXkp8jDNA5aWqmZhyTivfpQUNV==L9nfE0aiw@mail.gmail.com>

Examining more closely, it's a NOTE produced by R CMD check --
originally I had thought it was a WARNING, which I think would have
been too strong for this case. A NOTE actually seems fine, on second
thought.

For a tiny bit of context, it's common for us to issue messaging
around some state initialization, which has to happen after some
(ex-ante unknown) set of packages are loaded. It's important to do so
whether or not the package is attached, so the proviso in .onLoad()
indeed makes the most sense.

Thanks!

On Thu, Nov 4, 2021 at 1:02 PM Gabriel Becker <gabembecker at gmail.com> wrote:
>
> Hi Michael,
>
> Indeed, just to elaborate further on what I believe Duncan's point is, can you give any examples, "dire" or not, that are appropriate when the package is loaded but not attached (ie none of its symbols are visible to the user without using :::)?
>
> The only things I can think of are a package that changes the behavior of other, attached package code, such as conflicted. Doing so is very much an anti-pattern imo generally, with something like conflicted being an (arguable) exception. And that's assuming conflicted even works/does anything when loaded but not attached (I have not confirmed whether thats the case or not). That or a package that is at end-of-life and is or soon will be unsupported entirely.
>
> The examples don't need to be yours, per se, if you know what those pushing back against your linter were using messages from .onLoad for...
>
> Best,
> ~G
>
>
>
> On Thu, Nov 4, 2021 at 12:37 PM Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>
>> On 04/11/2021 2:50 p.m., Michael Chirico via R-devel wrote:
>> > I wrote a linter to stop users from using packageStartupMessage() in
>> > their .onLoad() hook because of the R CMD check warning it triggers:
>> >
>> > https://github.com/wch/r-source/blob/8b6625e39cd62424dc23399dade37f20fa8afa91/src/library/tools/R/QC.R#L5167
>> >
>> > However, this received some pushback which I ultimately agree with,
>> > and moreover ?.onLoad seems to agree as well:
>> >
>> >> Loading a namespace should where possible be silent, with startup
>> > messages given by \code{.onAttach}. These messages (**and any essential
>> > ones from \code{.onLoad}**) should use \code{\link{packageStartupMessage}}
>> > so they can be silenced where they would be a distraction.
>> >
>> > **emphasis** mine. That is, if we think some message is _essential_ to
>> > print during loadNamespace(), we are told to use
>> > packageStartupMessage().
>> >
>> > Should we remove this R CMD check warning?
>>
>> The help page doesn't define what an "essential" message would be, but I
>> would assume it's a message about some dire condition, not just "Hi! I
>> just got loaded!".  So I think a note or warning would be appropriate,
>> but not an error.
>>
>> Do you have an example of something that should routinely print, but
>> that triggers a warning when checked?
>>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From d@tr7320 @end|ng |rom un|@@ydney@edu@@u  Fri Nov  5 13:00:04 2021
From: d@tr7320 @end|ng |rom un|@@ydney@edu@@u (Dario Strbenac)
Date: Fri, 5 Nov 2021 12:00:04 +0000
Subject: [Rd] Data Frame Conversion and Table Input
Message-ID: <SYBPR01MB4761958F315F2D7ADA8FCDE7CD899@SYBPR01MB4761.ausprd01.prod.outlook.com>

Good day,

as.data.frame is documented on ?table and on ?as.data.frame (for list and matrix inputs). For inputs of list type and matrix type, there is an argument optional, which allows preservation of column names. If the input is a table, there is no such option. Could the API be made consistent for base data types?

--------------------------------------
Dario Strbenac
University of Sydney
Camperdown NSW 2050
Australia

From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Nov  5 13:38:06 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 5 Nov 2021 08:38:06 -0400
Subject: [Rd] Data Frame Conversion and Table Input
In-Reply-To: <SYBPR01MB4761958F315F2D7ADA8FCDE7CD899@SYBPR01MB4761.ausprd01.prod.outlook.com>
References: <SYBPR01MB4761958F315F2D7ADA8FCDE7CD899@SYBPR01MB4761.ausprd01.prod.outlook.com>
Message-ID: <e404ac41-c190-ccc0-a055-cc84fcecf6ec@gmail.com>

On 05/11/2021 8:00 a.m., Dario Strbenac via R-devel wrote:
> Good day,
> 
> as.data.frame is documented on ?table and on ?as.data.frame (for list and matrix inputs). For inputs of list type and matrix type, there is an argument optional, which allows preservation of column names. If the input is a table, there is no such option. Could the API be made consistent for base data types?

as.data.frame.character is also inconsistent with the generic.

Duncan Murdoch


From henr|k@bengt@@on @end|ng |rom gm@||@com  Fri Nov  5 15:51:22 2021
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Fri, 5 Nov 2021 15:51:22 +0100
Subject: [Rd] gettext(msgid, domain="R") doesn't work for some 'msgid':s
Message-ID: <CAFDcVCT0zPRGEG5ugr+yEbgKH57bo1MMwXRgh=q5y7OwAU1F0A@mail.gmail.com>

I'm trying to reuse some of the translations available in base R by using:

  gettext(msgid, domain="R")

This works great for most 'msgid's, e.g.

$ LANGUAGE=de Rscript -e 'gettext("cannot get working directory", domain="R")'
[1] "kann das Arbeitsverzeichnis nicht ermitteln"

However, it does not work for all.  For instance,

$ LANGUAGE=de Rscript -e 'gettext("Execution halted\n", domain="R")'
[1] "Execution halted\n"

This despite that 'msgid' existing in:

$ grep -C 2 -F 'Execution halted\n' src/library/base/po/de.po

#: src/main/main.c:342
msgid "Execution halted\n"
msgstr "Ausf?hrung angehalten\n"

It could be that the trailing newline causes problems, because the
same happens also for:

$ LANGUAGE=de Rscript --vanilla -e 'gettext("error during cleanup\n",
domain="R")'
[1] "error during cleanup\n"

Is this meant to work, and if so, how do I get it to work, or is it a bug?

Thanks,

Henrik


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Nov  5 16:12:20 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 5 Nov 2021 11:12:20 -0400
Subject: [Rd] gettext(msgid, domain="R") doesn't work for some 'msgid':s
In-Reply-To: <CAFDcVCT0zPRGEG5ugr+yEbgKH57bo1MMwXRgh=q5y7OwAU1F0A@mail.gmail.com>
References: <CAFDcVCT0zPRGEG5ugr+yEbgKH57bo1MMwXRgh=q5y7OwAU1F0A@mail.gmail.com>
Message-ID: <000f4e2a-684d-e26b-2b1c-fabc28880d55@gmail.com>

On 05/11/2021 10:51 a.m., Henrik Bengtsson wrote:
> I'm trying to reuse some of the translations available in base R by using:
> 
>    gettext(msgid, domain="R")
> 
> This works great for most 'msgid's, e.g.
> 
> $ LANGUAGE=de Rscript -e 'gettext("cannot get working directory", domain="R")'
> [1] "kann das Arbeitsverzeichnis nicht ermitteln"
> 
> However, it does not work for all.  For instance,
> 
> $ LANGUAGE=de Rscript -e 'gettext("Execution halted\n", domain="R")'
> [1] "Execution halted\n"
> 
> This despite that 'msgid' existing in:
> 
> $ grep -C 2 -F 'Execution halted\n' src/library/base/po/de.po
> 
> #: src/main/main.c:342
> msgid "Execution halted\n"
> msgstr "Ausf?hrung angehalten\n"
> 
> It could be that the trailing newline causes problems, because the
> same happens also for:
> 
> $ LANGUAGE=de Rscript --vanilla -e 'gettext("error during cleanup\n",
> domain="R")'
> [1] "error during cleanup\n"
> 
> Is this meant to work, and if so, how do I get it to work, or is it a bug?

I don't know the solution, but I think the cause is different than you 
think, because I also have the problem with other strings not including 
"\n":

$ LANGUAGE=de Rscript -e 'gettext("malformed version string", domain="R")'
[1] "malformed version string"

Duncan Murdoch


From @oko| @end|ng |rom |n@@-tou|ou@e@|r  Fri Nov  5 16:13:19 2021
From: @oko| @end|ng |rom |n@@-tou|ou@e@|r (Serguei Sokol)
Date: Fri, 5 Nov 2021 16:13:19 +0100
Subject: [Rd] gettext(msgid, domain="R") doesn't work for some 'msgid':s
In-Reply-To: <CAFDcVCT0zPRGEG5ugr+yEbgKH57bo1MMwXRgh=q5y7OwAU1F0A@mail.gmail.com>
References: <CAFDcVCT0zPRGEG5ugr+yEbgKH57bo1MMwXRgh=q5y7OwAU1F0A@mail.gmail.com>
Message-ID: <cbb50719-7151-0187-6bde-d45193cd0bd7@insa-toulouse.fr>

Le 05/11/2021 ? 15:51, Henrik Bengtsson a ?crit?:
> I'm trying to reuse some of the translations available in base R by using:
>
>    gettext(msgid, domain="R")
>
> This works great for most 'msgid's, e.g.
>
> $ LANGUAGE=de Rscript -e 'gettext("cannot get working directory", domain="R")'
> [1] "kann das Arbeitsverzeichnis nicht ermitteln"
>
> However, it does not work for all.  For instance,
>
> $ LANGUAGE=de Rscript -e 'gettext("Execution halted\n", domain="R")'
> [1] "Execution halted\n"
>
> This despite that 'msgid' existing in:
>
> $ grep -C 2 -F 'Execution halted\n' src/library/base/po/de.po
>
> #: src/main/main.c:342
> msgid "Execution halted\n"
> msgstr "Ausf?hrung angehalten\n"
>
> It could be that the trailing newline causes problems, because the
> same happens also for:
>
> $ LANGUAGE=de Rscript --vanilla -e 'gettext("error during cleanup\n",
> domain="R")'
> [1] "error during cleanup\n"
It happens also to:

$ LANGUAGE=de Rscript -e 'gettext("During startup - ", domain="R")'
[1] "During startup - "


#: src/main/main.c:1078
msgid "During startup - "
msgstr "Beim Start - "

which has not "\n" at the end.

Just a testimony with a hope it helps.

Best,
Serguei.

>
> Is this meant to work, and if so, how do I get it to work, or is it a bug?
>
> Thanks,
>
> Henrik
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Serguei Sokol
Ingenieur de recherche INRAE

Cellule Math?matiques
TBI, INSA/INRAE UMR 792, INSA/CNRS UMR 5504
135 Avenue de Rangueil
31077 Toulouse Cedex 04

tel: +33 5 61 55 98 49
email: sokol at insa-toulouse.fr
http://www.toulouse-biotechnology-institute.fr/en/technology_platforms/mathematics-cell.html


From tom@@@k@||ber@ @end|ng |rom gm@||@com  Fri Nov  5 16:15:19 2021
From: tom@@@k@||ber@ @end|ng |rom gm@||@com (Tomas Kalibera)
Date: Fri, 5 Nov 2021 16:15:19 +0100
Subject: [Rd] gettext(msgid, domain="R") doesn't work for some 'msgid':s
In-Reply-To: <000f4e2a-684d-e26b-2b1c-fabc28880d55@gmail.com>
References: <CAFDcVCT0zPRGEG5ugr+yEbgKH57bo1MMwXRgh=q5y7OwAU1F0A@mail.gmail.com>
 <000f4e2a-684d-e26b-2b1c-fabc28880d55@gmail.com>
Message-ID: <23255480-95fb-f5b0-4828-56aaace9b575@gmail.com>


On 11/5/21 4:12 PM, Duncan Murdoch wrote:
> On 05/11/2021 10:51 a.m., Henrik Bengtsson wrote:
>> I'm trying to reuse some of the translations available in base R by 
>> using:
>>
>> ?? gettext(msgid, domain="R")
>>
>> This works great for most 'msgid's, e.g.
>>
>> $ LANGUAGE=de Rscript -e 'gettext("cannot get working directory", 
>> domain="R")'
>> [1] "kann das Arbeitsverzeichnis nicht ermitteln"
>>
>> However, it does not work for all.? For instance,
>>
>> $ LANGUAGE=de Rscript -e 'gettext("Execution halted\n", domain="R")'
>> [1] "Execution halted\n"
>>
>> This despite that 'msgid' existing in:
>>
>> $ grep -C 2 -F 'Execution halted\n' src/library/base/po/de.po
>>
>> #: src/main/main.c:342
>> msgid "Execution halted\n"
>> msgstr "Ausf?hrung angehalten\n"
>>
>> It could be that the trailing newline causes problems, because the
>> same happens also for:
>>
>> $ LANGUAGE=de Rscript --vanilla -e 'gettext("error during cleanup\n",
>> domain="R")'
>> [1] "error during cleanup\n"
>>
>> Is this meant to work, and if so, how do I get it to work, or is it a 
>> bug?
>
> I don't know the solution, but I think the cause is different than you 
> think, because I also have the problem with other strings not 
> including "\n":
>
> $ LANGUAGE=de Rscript -e 'gettext("malformed version string", 
> domain="R")'
> [1] "malformed version string"

I can reproduce Henrik's report and the problem there is that the 
trailing \n is stripped by R before doing the lookup, in do_gettext


 ??????????? /* strip leading and trailing white spaces and
 ?????????????? add back after translation */
 ??????????? for(p = tmp;
 ??????????????? *p && (*p == ' ' || *p == '\t' || *p == '\n');
 ??????????????? p++, ihead++) ;

But, calling dgettext with the trailing \n does translate correctly for me.

I'd leave to translation experts how this should work (e.g. whether the 
.po files should have trailing newlines).

Tomas

>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Fri Nov  5 17:55:24 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 5 Nov 2021 17:55:24 +0100
Subject: [Rd] gettext(msgid, domain="R") doesn't work for some 'msgid':s
In-Reply-To: <23255480-95fb-f5b0-4828-56aaace9b575@gmail.com>
References: <CAFDcVCT0zPRGEG5ugr+yEbgKH57bo1MMwXRgh=q5y7OwAU1F0A@mail.gmail.com>
 <000f4e2a-684d-e26b-2b1c-fabc28880d55@gmail.com>
 <23255480-95fb-f5b0-4828-56aaace9b575@gmail.com>
Message-ID: <24965.25084.791480.520562@stat.math.ethz.ch>

>>>>> Tomas Kalibera 
>>>>>     on Fri, 5 Nov 2021 16:15:19 +0100 writes:

    > On 11/5/21 4:12 PM, Duncan Murdoch wrote:
    >> On 05/11/2021 10:51 a.m., Henrik Bengtsson wrote:
    >>> I'm trying to reuse some of the translations available in base R by 
    >>> using:
    >>> 
    >>> ?? gettext(msgid, domain="R")
    >>> 
    >>> This works great for most 'msgid's, e.g.
    >>> 
    >>> $ LANGUAGE=de Rscript -e 'gettext("cannot get working directory", 
    >>> domain="R")'
    >>> [1] "kann das Arbeitsverzeichnis nicht ermitteln"
    >>> 
    >>> However, it does not work for all.? For instance,
    >>> 
    >>> $ LANGUAGE=de Rscript -e 'gettext("Execution halted\n", domain="R")'
    >>> [1] "Execution halted\n"
    >>> 
    >>> This despite that 'msgid' existing in:
    >>> 
    >>> $ grep -C 2 -F 'Execution halted\n' src/library/base/po/de.po
    >>> 
    >>> #: src/main/main.c:342
    >>> msgid "Execution halted\n"
    >>> msgstr "Ausf?hrung angehalten\n"
    >>> 
    >>> It could be that the trailing newline causes problems, because the
    >>> same happens also for:
    >>> 
    >>> $ LANGUAGE=de Rscript --vanilla -e 'gettext("error during cleanup\n",
    >>> domain="R")'
    >>> [1] "error during cleanup\n"
    >>> 
    >>> Is this meant to work, and if so, how do I get it to work, or is it a 
    >>> bug?
    >> 
    >> I don't know the solution, but I think the cause is different than you 
    >> think, because I also have the problem with other strings not 
    >> including "\n":
    >> 
    >> $ LANGUAGE=de Rscript -e 'gettext("malformed version string", 
    >> domain="R")'
    >> [1] "malformed version string"

You need domain="R-base" for the  "malformed version "string"


    > I can reproduce Henrik's report and the problem there is that the 
    > trailing \n is stripped by R before doing the lookup, in do_gettext


    > ??????????? /* strip leading and trailing white spaces and
    > ?????????????? add back after translation */
    > ??????????? for(p = tmp;
    > ??????????????? *p && (*p == ' ' || *p == '\t' || *p == '\n');
    > ??????????????? p++, ihead++) ;

    > But, calling dgettext with the trailing \n does translate correctly for me.

    > I'd leave to translation experts how this should work (e.g. whether the 
    > .po files should have trailing newlines).

Thanks a lot, Tomas.
This is "interesting" .. and I think an R bug  one way or the
other (and I also note that Henrik's guess was also right on !).

We have the following:

- New translation *.po source files are to be made from the original *.pot  files.

  In our case it's our code that produce  R.pot and R-base.pot  
  (and more for the non-base packages, and more e.g. for
   Recommended packages 'Matrix' and 'cluster' I maintain).

And notably the R.pot (from all the "base" C error/warn/.. messages)
contains tons of msgid strings of the form  ".......\n"
i.e., ending in \n.
>From that automatically the translator's  *.po files should also
end in \n.

Additionally, the GNU gettext FAQ has
 (here :   https://www.gnu.org/software/gettext/FAQ.html#newline )

------------------------------------------------
Q: What does this mean: ?'msgid' and 'msgstr' entries do not both end with '\n'?

A: It means that when the original string ends in a newline, your translation must also end in a newline. And if the original string does not end in a newline, then your translation should likewise not have a newline at the end.
------------------------------------------------
 
>From all that I'd conclude that we (R base code) are the source
of the problem.
Given the above FAQ, it seems common in other projects also to
have such trailing \n  and so we should really change the C code
you cite above.

On the other hand, this is from almost the very beginning of
when Brian added translation to R,
------------------------------------------------------------------------
r32938 | ripley | 2005-01-30 20:24:04 +0100 (Sun, 30 Jan 2005) | 2 lines

include \n in whitespace ignored for R-level gettext
------------------------------------------------------------------------

I think this has been because simultaneously we had started to
emphasize to useRs  they should *not* end message/format strings
in stop() / warning()  by a new line, but rather stop() and
warning() would *add* the newlines(s) themselves.

Still, currently we have a few such cases in  R-base.pot,
but just these few and maybe they really are "in error", in the
sense we could drop the ending '\n' (and do the same in all the *.po files!),
and newlines would be appended later {{not just by Rstudio which
   graceously adds final newlines in its R console, even for say
   cat("abc") }}

However, this is quite different for all the message strings from C, as
used there in  error() or warn() e.g., and so in   R.pot
we see many many msg strings ending in "\n" (which must then
also be in the *.po files.

My current conclusion is we should try simplifying the
do_gettext() code and *not* remove and re-add the '\n' (nor the
'\t' I think ...)

Martin


    > Tomas

    >> 
    >> Duncan Murdoch


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Fri Nov  5 18:23:56 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 5 Nov 2021 18:23:56 +0100
Subject: [Rd] gettext(msgid, domain="R") doesn't work for some 'msgid':s
In-Reply-To: <24965.25084.791480.520562@stat.math.ethz.ch>
References: <CAFDcVCT0zPRGEG5ugr+yEbgKH57bo1MMwXRgh=q5y7OwAU1F0A@mail.gmail.com>
 <000f4e2a-684d-e26b-2b1c-fabc28880d55@gmail.com>
 <23255480-95fb-f5b0-4828-56aaace9b575@gmail.com>
 <24965.25084.791480.520562@stat.math.ethz.ch>
Message-ID: <24965.26796.249437.598189@stat.math.ethz.ch>

>>>>> Martin Maechler 
>>>>>     on Fri, 5 Nov 2021 17:55:24 +0100 writes:

>>>>> Tomas Kalibera 
>>>>>     on Fri, 5 Nov 2021 16:15:19 +0100 writes:

    >> On 11/5/21 4:12 PM, Duncan Murdoch wrote:
    >>> On 05/11/2021 10:51 a.m., Henrik Bengtsson wrote:
    >>>> I'm trying to reuse some of the translations available in base R by 
    >>>> using:
    >>>> 
    >>>> ?? gettext(msgid, domain="R")
    >>>> 
    >>>> This works great for most 'msgid's, e.g.
    >>>> 
    >>>> $ LANGUAGE=de Rscript -e 'gettext("cannot get working directory", 
    >>>> domain="R")'
    >>>> [1] "kann das Arbeitsverzeichnis nicht ermitteln"
    >>>> 
    >>>> However, it does not work for all.? For instance,
    >>>> 
    >>>> $ LANGUAGE=de Rscript -e 'gettext("Execution halted\n", domain="R")'
    >>>> [1] "Execution halted\n"
    >>>> 
    >>>> This despite that 'msgid' existing in:
    >>>> 
    >>>> $ grep -C 2 -F 'Execution halted\n' src/library/base/po/de.po
    >>>> 
    >>>> #: src/main/main.c:342
    >>>> msgid "Execution halted\n"
    >>>> msgstr "Ausf?hrung angehalten\n"
    >>>> 
    >>>> It could be that the trailing newline causes problems, because the
    >>>> same happens also for:
    >>>> 
    >>>> $ LANGUAGE=de Rscript --vanilla -e 'gettext("error during cleanup\n",
    >>>> domain="R")'
    >>>> [1] "error during cleanup\n"
    >>>> 
    >>>> Is this meant to work, and if so, how do I get it to work, or is it a 
    >>>> bug?
    >>> 
    >>> I don't know the solution, but I think the cause is different than you 
    >>> think, because I also have the problem with other strings not 
    >>> including "\n":
    >>> 
    >>> $ LANGUAGE=de Rscript -e 'gettext("malformed version string", 
    >>> domain="R")'
    >>> [1] "malformed version string"

    > You need domain="R-base" for the  "malformed version "string"


    >> I can reproduce Henrik's report and the problem there is that the 
    >> trailing \n is stripped by R before doing the lookup, in do_gettext


    >> ??????????? /* strip leading and trailing white spaces and
    >> ?????????????? add back after translation */
    >> ??????????? for(p = tmp;
    >> ??????????????? *p && (*p == ' ' || *p == '\t' || *p == '\n');
    >> ??????????????? p++, ihead++) ;

    >> But, calling dgettext with the trailing \n does translate correctly for me.

    >> I'd leave to translation experts how this should work (e.g. whether the 
    >> .po files should have trailing newlines).

    > Thanks a lot, Tomas.
    > This is "interesting" .. and I think an R bug  one way or the
    > other (and I also note that Henrik's guess was also right on !).

    > We have the following:

    > - New translation *.po source files are to be made from the original *.pot  files.

    > In our case it's our code that produce  R.pot and R-base.pot  
    > (and more for the non-base packages, and more e.g. for
    > Recommended packages 'Matrix' and 'cluster' I maintain).

    > And notably the R.pot (from all the "base" C error/warn/.. messages)
    > contains tons of msgid strings of the form  ".......\n"
    > i.e., ending in \n.
    >> From that automatically the translator's  *.po files should also
    > end in \n.

    > Additionally, the GNU gettext FAQ has
    > (here :   https://www.gnu.org/software/gettext/FAQ.html#newline )

    > ------------------------------------------------
    > Q: What does this mean: ?'msgid' and 'msgstr' entries do not both end with '\n'?

    > A: It means that when the original string ends in a newline, your translation must also end in a newline. And if the original string does not end in a newline, then your translation should likewise not have a newline at the end.
    > ------------------------------------------------
 
    >> From all that I'd conclude that we (R base code) are the source
    > of the problem.
    > Given the above FAQ, it seems common in other projects also to
    > have such trailing \n  and so we should really change the C code
    > you cite above.

    > On the other hand, this is from almost the very beginning of
    > when Brian added translation to R,
    > ------------------------------------------------------------------------
    > r32938 | ripley | 2005-01-30 20:24:04 +0100 (Sun, 30 Jan 2005) | 2 lines

    > include \n in whitespace ignored for R-level gettext
    > ------------------------------------------------------------------------

    > I think this has been because simultaneously we had started to
    > emphasize to useRs  they should *not* end message/format strings
    > in stop() / warning()  by a new line, but rather stop() and
    > warning() would *add* the newlines(s) themselves.

    > Still, currently we have a few such cases in  R-base.pot,
    > but just these few and maybe they really are "in error", in the
    > sense we could drop the ending '\n' (and do the same in all the *.po files!),
    > and newlines would be appended later {{not just by Rstudio which
    > graceously adds final newlines in its R console, even for say
    > cat("abc") }}

    > However, this is quite different for all the message strings from C, as
    > used there in  error() or warn() e.g., and so in   R.pot
    > we see many many msg strings ending in "\n" (which must then
    > also be in the *.po files.

    > My current conclusion is we should try simplifying the
    > do_gettext() code and *not* remove and re-add the '\n' (nor the
    > '\t' I think ...)

After such a change, I indeed  do see

$ LANGUAGE=de bin/Rscript --vanilla -e 'gettext("Execution halted\n", domain="R")'
[1] "Ausf?hrung angehalten\n"
$ LANGUAGE=de bin/Rscript --vanilla -e 'message("Execution halted\n", domain="R")'
Ausf?hrung angehalten

$ LANGUAGE=de bin/Rscript --vanilla -e 'warning("Execution halted\n", domain="R")'
Warnmeldung:
Ausf?hrung angehalten
 
$

(note the extra newline after the German translation!)
whereas before, not only using  gettext() directly did not work,
but also using warning() or message()  {with or without trailing \n} 
were never translated.



... and my simple  #ifdef .. #endif change around the head/tail
save and restor seems to pass make check-devel ...

so I will be looking into dropping all those "head" and "tail" add
and remove parts in do_gettext() as they really seem to harm given the current
translation data bases which indeed *are* full of final '\n' in
`msgid` and corresponding translated `msgstr` ....

So, no need for a bugzilla PR nor a patch, please.
Maybe further examples which add something interesting in
addition to the ones we have here.

Thank you again, Henrik, Duncan, and Tomas!


Martin


From @uh@rto_@nggono @end|ng |rom y@hoo@com  Sat Nov  6 09:07:58 2021
From: @uh@rto_@nggono @end|ng |rom y@hoo@com (Suharto Anggono Suharto Anggono)
Date: Sat, 6 Nov 2021 08:07:58 +0000 (UTC)
Subject: [Rd] gettext(msgid, domain="R") doesn't work for some 'msgid':s
References: <1741628426.1795842.1636186078866.ref@mail.yahoo.com>
Message-ID: <1741628426.1795842.1636186078866@mail.yahoo.com>

This issue has come up before: https://stat.ethz.ch/pipermail/r-help/2013-February/346721.html ("gettext wierdness"), https://stat.ethz.ch/pipermail/r-devel/2007-December/047893.html ("gettext() and messages in 'pkg' domain").

Using 'ngettext' is a workaround, like in https://rdrr.io/cran/svMisc/src/R/svMisc-internal.R .

It is documented: "For 'gettext', leading and trailing whitespace is ignored when looking for the translation."

------------
>> Martin Maechler
>>>>> on Fri, 5 Nov 2021 17:55:24 +0100 writes:

>>>>> Tomas Kalibera
>>>>> on Fri, 5 Nov 2021 16:15:19 +0100 writes:

 >> On 11/5/21 4:12 PM, Duncan Murdoch wrote:
 >>> On 05/11/2021 10:51 a.m., Henrik Bengtsson wrote:
 >>>> I'm trying to reuse some of the translations available in base R by
 >>>> using:
 >>>>
 >>>> ?? gettext(msgid, domain="R")
 >>>>
 >>>> This works great for most 'msgid's, e.g.
 >>>>
 >>>> $ LANGUAGE=de Rscript -e 'gettext("cannot get working directory",
 >>>> domain="R")'
 >>>> [1] "kann das Arbeitsverzeichnis nicht ermitteln"
 >>>>
 >>>> However, it does not work for all.? For instance,
 >>>>
 >>>> $ LANGUAGE=de Rscript -e 'gettext("Execution halted\n", domain="R")'
 >>>> [1] "Execution halted\n"
 >>>>
 >>>> This despite that 'msgid' existing in:
 >>>>
 >>>> $ grep -C 2 -F 'Execution halted\n' src/library/base/po/de.po
 >>>>
 >>>> #: src/main/main.c:342
 >>>> msgid "Execution halted\n"
 >>>> msgstr "Ausf?hrung angehalten\n"
 >>>>
 >>>> It could be that the trailing newline causes problems, because the
 >>>> same happens also for:
 >>>>
 >>>> $ LANGUAGE=de Rscript --vanilla -e 'gettext("error during cleanup\n",
 >>>> domain="R")'
 >>>> [1] "error during cleanup\n"
 >>>>
 >>>> Is this meant to work, and if so, how do I get it to work, or is it a
 >>>> bug?
 >>>
 >>> I don't know the solution, but I think the cause is different than you
 >>> think, because I also have the problem with other strings not
 >>> including "\n":
 >>>
 >>> $ LANGUAGE=de Rscript -e 'gettext("malformed version string",
 >>> domain="R")'
 >>> [1] "malformed version string"

 > You need domain="R-base" for the "malformed version "string"


 >> I can reproduce Henrik's report and the problem there is that the
 >> trailing \n is stripped by R before doing the lookup, in do_gettext


 >> ??????????? /* strip leading and trailing white spaces and
 >> ?????????????? add back after translation */
 >> ??????????? for(p = tmp;
 >> ??????????????? *p && (*p == ' ' || *p == '\t' || *p == '\n');
 >> ??????????????? p++, ihead++) ;

 >> But, calling dgettext with the trailing \n does translate correctly for me.

 >> I'd leave to translation experts how this should work (e.g. whether the
 >> .po files should have trailing newlines).

 > Thanks a lot, Tomas.
 > This is "interesting" .. and I think an R bug one way or the
 > other (and I also note that Henrik's guess was also right on !).

 > We have the following:

 > - New translation *.po source files are to be made from the original *.pot files.

 > In our case it's our code that produce R.pot and R-base.pot
 > (and more for the non-base packages, and more e.g. for
 > Recommended packages 'Matrix' and 'cluster' I maintain).

 > And notably the R.pot (from all the "base" C error/warn/.. messages)
 > contains tons of msgid strings of the form ".......\n"
 > i.e., ending in \n.
 >> From that automatically the translator's *.po files should also
 > end in \n.

 > Additionally, the GNU gettext FAQ has
 > (here : https://www.gnu.org/software/gettext/FAQ.html#newline )

 > ------------------------------------------------
 > Q: What does this mean: ?'msgid' and 'msgstr' entries do not both end with '\n'?

 > A: It means that when the original string ends in a newline, your translation must also end in a newline. And if the original string does not end in a newline, then your translation should likewise not have a newline at the end.
 > ------------------------------------------------

 >> From all that I'd conclude that we (R base code) are the source
 > of the problem.
 > Given the above FAQ, it seems common in other projects also to
 > have such trailing \n and so we should really change the C code
 > you cite above.

 > On the other hand, this is from almost the very beginning of
 > when Brian added translation to R,
 > ------------------------------------------------------------------------
 > r32938 | ripley | 2005-01-30 20:24:04 +0100 (Sun, 30 Jan 2005) | 2 lines

 > include \n in whitespace ignored for R-level gettext
 > ------------------------------------------------------------------------

 > I think this has been because simultaneously we had started to
 > emphasize to useRs they should *not* end message/format strings
 > in stop() / warning() by a new line, but rather stop() and
 > warning() would *add* the newlines(s) themselves.

 > Still, currently we have a few such cases in R-base.pot,
 > but just these few and maybe they really are "in error", in the
 > sense we could drop the ending '\n' (and do the same in all the *.po files!),
 > and newlines would be appended later {{not just by Rstudio which
 > graceously adds final newlines in its R console, even for say
 > cat("abc") }}

 > However, this is quite different for all the message strings from C, as
 > used there in error() or warn() e.g., and so in R.pot
 > we see many many msg strings ending in "\n" (which must then
 > also be in the *.po files.

 > My current conclusion is we should try simplifying the
 > do_gettext() code and *not* remove and re-add the '\n' (nor the
 > '\t' I think ...)

After such a change, I indeed do see

$ LANGUAGE=de bin/Rscript --vanilla -e 'gettext("Execution halted\n", domain="R")'
[1] "Ausf?hrung angehalten\n"
$ LANGUAGE=de bin/Rscript --vanilla -e 'message("Execution halted\n", domain="R")'
Ausf?hrung angehalten

$ LANGUAGE=de bin/Rscript --vanilla -e 'warning("Execution halted\n", domain="R")'
Warnmeldung:
Ausf?hrung angehalten

$

(note the extra newline after the German translation!)
whereas before, not only using gettext() directly did not work,
but also using warning() or message() {with or without trailing \n}
were never translated.



... and my simple #ifdef .. #endif change around the head/tail
save and restor seems to pass make check-devel ...

so I will be looking into dropping all those "head" and "tail" add
and remove parts in do_gettext() as they really seem to harm given the current
translation data bases which indeed *are* full of final '\n' in
`msgid` and corresponding translated `msgstr` ....

So, no need for a bugzilla PR nor a patch, please.
Maybe further examples which add something interesting in
addition to the ones we have here.

Thank you again, Henrik, Duncan, and Tomas!


Martin


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Sat Nov  6 11:39:58 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Sat, 6 Nov 2021 11:39:58 +0100
Subject: [Rd] gettext(msgid, domain="R") doesn't work for some 'msgid':s
In-Reply-To: <1741628426.1795842.1636186078866@mail.yahoo.com>
References: <1741628426.1795842.1636186078866.ref@mail.yahoo.com>
 <1741628426.1795842.1636186078866@mail.yahoo.com>
Message-ID: <24966.23422.259436.635908@stat.math.ethz.ch>

>>>>> Suharto Anggono Suharto Anggono via R-devel 
>>>>>     on Sat, 6 Nov 2021 08:07:58 +0000 (UTC) writes:

    > This issue has come up before: https://stat.ethz.ch/pipermail/r-help/2013-February/346721.html ("gettext wierdness"), https://stat.ethz.ch/pipermail/r-devel/2007-December/047893.html ("gettext() and messages in 'pkg' domain").
    > Using 'ngettext' is a workaround, like in https://rdrr.io/cran/svMisc/src/R/svMisc-internal.R .

Thank you for the pointers!

    > It is documented: "For 'gettext', leading and trailing whitespace is ignored when looking for the translation."

Indeed; and it *is* a feature  but really only valuable when the
msgid's (the original message strings) do *not* contain such
whitespace.
And, in fact, when xgettext() or xgettext2pot() from pkg 'tools'
are used to create the original *.pot files, they *also* trim
leading and trailing \n, \t and spaces.

So ideally there should not be any   end(or beginning)-of-line
"\n" in the R-base.pot (and hence corresponding  <LANG>-base.po )
and as I mentioned there *are* only a few, and
we could (should?) consider to remove them from there.

A "problem" is still in the many C-code msgid's  where
end-of-line-"\n" are common.

Yes, indeed, one can use the workaround Suharto mentions,
ngettext()  even though users will typically only look at
ngettext() if they want / need to learn about plural/singular
messages ...

I.e. in our case, this works, and Henrik could get what he wants

> Sys.setenv(LANGUAGE = "de")
> ngettext(1,"Execution halted\n", "", domain="R")
[1] "Ausf?hrung angehalten\n"

but it's still not so satisfactory, that you cannot use
gettext() itself to look at a considerable proportion of the
C/C++/.. level error messages just because they end with "\n".

One possibility would be to introduce an optional
`trim = TRUE` argument, so the above could be achieved (more
efficiently and naturally) by

   gettext("Execution halted\n", domain="R", trim=FALSE)

but in any case, to *not* do the trimming anymore in general,
as I proposed yesterday (see below) is not a good idea.

    > ------------
    >>> Martin Maechler
>>>>> on Fri, 5 Nov 2021 17:55:24 +0100 writes:

>>>>> Tomas Kalibera
>>>>> on Fri, 5 Nov 2021 16:15:19 +0100 writes:

    >>> On 11/5/21 4:12 PM, Duncan Murdoch wrote:
    >>>> On 05/11/2021 10:51 a.m., Henrik Bengtsson wrote:
    >>>>> I'm trying to reuse some of the translations available in base R by
    >>>>> using:
    >>>>> 
    >>>>> ?? gettext(msgid, domain="R")
    >>>>> 
    >>>>> This works great for most 'msgid's, e.g.
    >>>>> 
    >>>>> $ LANGUAGE=de Rscript -e 'gettext("cannot get working directory",
    >>>>> domain="R")'
    >>>>> [1] "kann das Arbeitsverzeichnis nicht ermitteln"
    >>>>> 
    >>>>> However, it does not work for all.? For instance,
    >>>>> 
    >>>>> $ LANGUAGE=de Rscript -e 'gettext("Execution halted\n", domain="R")'
    >>>>> [1] "Execution halted\n"
    >>>>> 
    >>>>> This despite that 'msgid' existing in:
    >>>>> 
    >>>>> $ grep -C 2 -F 'Execution halted\n' src/library/base/po/de.po
    >>>>> 
    >>>>> #: src/main/main.c:342
    >>>>> msgid "Execution halted\n"
    >>>>> msgstr "Ausf?hrung angehalten\n"
    >>>>> 
    >>>>> It could be that the trailing newline causes problems, because the
    >>>>> same happens also for:
    >>>>> 
    >>>>> $ LANGUAGE=de Rscript --vanilla -e 'gettext("error during cleanup\n",
    >>>>> domain="R")'
    >>>>> [1] "error during cleanup\n"
    >>>>> 
    >>>>> Is this meant to work, and if so, how do I get it to work, or is it a
    >>>>> bug?
    >>>> 
    >>>> I don't know the solution, but I think the cause is different than you
    >>>> think, because I also have the problem with other strings not
    >>>> including "\n":
    >>>> 
    >>>> $ LANGUAGE=de Rscript -e 'gettext("malformed version string",
    >>>> domain="R")'
    >>>> [1] "malformed version string"

    >> You need domain="R-base" for the "malformed version "string"


    >>> I can reproduce Henrik's report and the problem there is that the
    >>> trailing \n is stripped by R before doing the lookup, in do_gettext


    >>> ??????????? /* strip leading and trailing white spaces and
    >>> ?????????????? add back after translation */
    >>> ??????????? for(p = tmp;
    >>> ??????????????? *p && (*p == ' ' || *p == '\t' || *p == '\n');
    >>> ??????????????? p++, ihead++) ;

    >>> But, calling dgettext with the trailing \n does translate correctly for me.

    >>> I'd leave to translation experts how this should work (e.g. whether the
    >>> .po files should have trailing newlines).

    >> Thanks a lot, Tomas.
    >> This is "interesting" .. and I think an R bug one way or the
    >> other (and I also note that Henrik's guess was also right on !).

    >> We have the following:

    >> - New translation *.po source files are to be made from the original *.pot files.

    >> In our case it's our code that produce R.pot and R-base.pot
    >> (and more for the non-base packages, and more e.g. for
    >> Recommended packages 'Matrix' and 'cluster' I maintain).

    >> And notably the R.pot (from all the "base" C error/warn/.. messages)
    >> contains tons of msgid strings of the form ".......\n"
    >> i.e., ending in \n.
    >>> From that automatically the translator's *.po files should also
    >> end in \n.

    >> Additionally, the GNU gettext FAQ has
    >> (here : https://www.gnu.org/software/gettext/FAQ.html#newline )

    >> ------------------------------------------------
    >> Q: What does this mean: ?'msgid' and 'msgstr' entries do not both end with '\n'?

    >> A: It means that when the original string ends in a newline, your translation must also end in a newline. And if the original string does not end in a newline, then your translation should likewise not have a newline at the end.
    >> ------------------------------------------------

    >>> From all that I'd conclude that we (R base code) are the source
    >> of the problem.
    >> Given the above FAQ, it seems common in other projects also to
    >> have such trailing \n and so we should really change the C code
    >> you cite above.

    >> On the other hand, this is from almost the very beginning of
    >> when Brian added translation to R,
    >> ------------------------------------------------------------------------
    >> r32938 | ripley | 2005-01-30 20:24:04 +0100 (Sun, 30 Jan 2005) | 2 lines

    >> include \n in whitespace ignored for R-level gettext
    >> ------------------------------------------------------------------------

    >> I think this has been because simultaneously we had started to
    >> emphasize to useRs they should *not* end message/format strings
    >> in stop() / warning() by a new line, but rather stop() and
    >> warning() would *add* the newlines(s) themselves.

    >> Still, currently we have a few such cases in R-base.pot,
    >> but just these few and maybe they really are "in error", in the
    >> sense we could drop the ending '\n' (and do the same in all the *.po files!),
    >> and newlines would be appended later {{not just by Rstudio which
    >> graceously adds final newlines in its R console, even for say
    >> cat("abc") }}

    >> However, this is quite different for all the message strings from C, as
    >> used there in error() or warn() e.g., and so in R.pot
    >> we see many many msg strings ending in "\n" (which must then
    >> also be in the *.po files.

    >> My current conclusion is we should try simplifying the
    >> do_gettext() code and *not* remove and re-add the '\n' (nor the
    >> '\t' I think ...)

    > After such a change, I indeed do see

    > $ LANGUAGE=de bin/Rscript --vanilla -e 'gettext("Execution halted\n", domain="R")'
    > [1] "Ausf?hrung angehalten\n"
    > $ LANGUAGE=de bin/Rscript --vanilla -e 'message("Execution halted\n", domain="R")'
    > Ausf?hrung angehalten

    > $ LANGUAGE=de bin/Rscript --vanilla -e 'warning("Execution halted\n", domain="R")'
    > Warnmeldung:
    > Ausf?hrung angehalten

    > $

    > (note the extra newline after the German translation!)
    > whereas before, not only using gettext() directly did not work,
    > but also using warning() or message() {with or without trailing \n}
    > were never translated.



    > ... and my simple #ifdef .. #endif change around the head/tail
    > save and restor seems to pass make check-devel ...

    > so I will be looking into dropping all those "head" and "tail" add
    > and remove parts in do_gettext() as they really seem to harm given the current
    > translation data bases which indeed *are* full of final '\n' in
    > `msgid` and corresponding translated `msgstr` ....

    > So, no need for a bugzilla PR nor a patch, please.
    > Maybe further examples which add something interesting in
    > addition to the ones we have here.

    > Thank you again, Henrik, Duncan, and Tomas!


    > Martin

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From btyner @end|ng |rom gm@||@com  Sat Nov  6 14:51:31 2021
From: btyner @end|ng |rom gm@||@com (Benjamin Tyner)
Date: Sat, 6 Nov 2021 09:51:31 -0400
Subject: [Rd] S4 methods with default argument of NULL
Message-ID: <a6157cb1-fd0b-63dd-55eb-496933e1a61e@gmail.com>

Greetings,

I noticed that starting with R version 3.5.0, it is now possible to do, 
for example:

    setGeneric(name = "foo",
     ?????????? def = function(x, y, ...) standardGeneric("foo"),
     ?????????? valueClass = "fooResult"
     ?????????? )

    setMethod(f = "foo",
     ????????? signature = c("character", "character"),
     ????????? definition = function(x, y = NULL, z = NULL, ...) {

     ????????????? force(y)
     ????????????? message(sprintf("x is %s", x))

     ????????????? structure(list(), class = "fooResult")
     ????????? })

    foo("a", "b") # this works in R >= 3.5.0, but fails in R < 3.5.0

(Prior to R version 3.5.0, it gives "Error in force(y) : object 'y' not 
found")

I am curious to learn whether the change permitting this was:

    1. an intentional enhancement
    2. unintentional, but a "happy accident" (i.e., a desirable side
    effect of some other enhancement)
    3. unintentional, and perhaps undesirable (i.e., a loosening of
    standards)

For reference, this came up in the debugging of the following issue:

    https://github.com/DyfanJones/noctua/issues/170

Any comments to shed some light would be greatly appreciated.

Regards,

Ben


From r-deve| @end|ng |rom @ker@t|ng@de  Sun Nov  7 20:22:42 2021
From: r-deve| @end|ng |rom @ker@t|ng@de (Andreas Kersting)
Date: Sun, 07 Nov 2021 20:22:42 +0100 (CET)
Subject: [Rd] GC: parallelizing the CHARSXP cache maintenance
In-Reply-To: <E1mYNn6-0000cv-1M@rmmprod05.runbox>
Message-ID: <E1mjnkY-0007mK-Ld@rmmprod05.runbox>

I have now added this to the wishlist in Bugzilla: https://bugs.r-project.org/show_bug.cgi?id=18234

2021-10-07 09:26 GMT+02:00 "Andreas Kersting" <r-devel at akersting.de>:
> Hi all,
> 
> As part of RunGenCollect() (in src/main/memory.c), some maintenance on the CHARSXP cache is done, namely unmarked nodes/CHARSXPs are removed from the hash chains. This requires always touching all CHARSXP in the cache, irrespective of the number of generations which were just garbage collected. In a session with a big CHARSXP cache, this will significantly slow down gc also when just collecting the youngest generation.
> 
> However, this part of RunGenCollect() seems to be one of the few which can easily be parallelized without the need for thread synchronization. And it seems to be the one most profiting from parallelization.
> 
> Attached patch (?parallel_CHARSXP_cache.diff) implements parallelization over the elements of R_StringHash and gives the following performance improvements on my system when using 4 threads compared to R devel (revision 81008):
> 
> Elapsed time for 200 non-full gc in a session after
> 
> x <- as.character(runif(1e6))[]
> gc(full = TRUE)
> 
> 8sec -> 2.5sec.
> 
> AND
> 
> Elapsed time for five non-full gc in a session after
> 
> x <- as.character(runif(5e7))[]
> gc(full = TRUE)
> 
> 21sec -> 6sec.
> 
> In the patch, I dropped the two lines 
> 
> FORWARD_NODE(s);
> FORWARD_NODE(CXHEAD(s));
> 
> because they are currently both no-ops (and would require synchronization if they were not). They are no-ops because we have
> 
> ?# define CXHEAD(x) (x)  // in Defn.h
> 
> and hence FORWARD_NODE(s)/FORWARD_NODE(CXHEAD(s)) is only called when s is already marked, in which case FORWARD_NODE() does nothing.
> 
> I used OpenMP despite the known issues of some of its implementations with hanging after a fork, mostly because it was the easiest thing to do for a PoC. I worked around this similar to e.g. data.table by using only one thread in forked children.
> 
> It might be worth considering making the parallelization conditional on the size of the CHARSXP cache and use only the main thread if the cache is (still) small.
> 
> In the second attached patch (parallel_CHARSXP_cache_no_forward.diff) I additionally no longer call FORWARD_NODE(R_StringHash) because this will make the following call to PROCESS_NODES() iterate through all elements of R_StringHash again which is unnecessary since all elements are either R_NilValue or an already marked CHARSXP. I rather directly mark & snap R_StringHash. In contrast to the parallelization, this only affects full gcs since R_StringHash will quickly belong to the oldest generation.
> 
> Attached gc_test.R is the script I used to get the previously mentioned and more gc timings.
> 
> To me this looks like a significant performance improvement, especially given the little changeset. What do you think?
> 
> Best regards,
> Andreas
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

From r-deve| @end|ng |rom @ker@t|ng@de  Sun Nov  7 20:26:32 2021
From: r-deve| @end|ng |rom @ker@t|ng@de (Andreas Kersting)
Date: Sun, 07 Nov 2021 20:26:32 +0100 (CET)
Subject: [Rd] [External]  GC: speeding-up the CHARSXP cache maintenance,
 2nd try
In-Reply-To: <alpine.DEB.2.22.394.2111041100400.388953@luke-Latitude-7480>
Message-ID: <E1mjnoG-0008FN-UH@rmmprod05.runbox>

Hi Luke,

As proposed by you, I have just added this to the wishlist in Bugzilla: https://bugs.r-project.org/show_bug.cgi?id=18233

Best,
Andreas

2021-11-04 17:04 GMT+01:00 luke-tierney at uiowa.edu:
> Can you please submit this as a wishlist item to bugzilla? it is
> easier to keep track of there. You could also submit your threads
> based suggestion there, again to keep it easier to keep track of and
> possibly get back to in the future.
> 
> I will have a look at your approach when I get a chance, but I am
> exploring a different approach to avoid scanning old generations that
> may be simpler.
> 
> Best,
> 
> luke
> 
> On Wed, 3 Nov 2021, Andreas Kersting wrote:
> 
>> Hi,
>>
>> In https://stat.ethz.ch/pipermail/r-devel/2021-October/081147.html I proposed to speed up the CHARSXP cache maintenance during GC using threading. This was rejected by Luke in https://stat.ethz.ch/pipermail/r-devel/2021-October/081172.html.
>>
>> Here I want to propose an alternative approach to significantly speed up CHARSXP cache maintenance during partial GCs. A patch which passes `make check-devel` is attached. Compared to R devel (revision 81110) I get the following performance improvements on my system:
>>
>> Elapsed time for five non-full gc in a session after
>>
>> x <- as.character(runif(5e7))[]
>> gc(full = TRUE)
>>
>> +20sec -> ~1sec.
>>
>>
>> This patch introduces (theoretical) overheads to mkCharLenCE() and full GCs. However, I did not measure dramatic differences:
>>
>> y <- "old_CHARSXP"
>>
>> after
>>
>> x <- "old_CHARSXP"; gc(); gc()
>>
>> takes a median 32 nanoseconds with and without the patch.
>>
>>
>> gc(full = TRUE)
>>
>> in a new session takes a median 16 milliseconds with and 14 without the patch.
>>
>>
>> The basic idea is to maintain the CHARSXP cache using subtables in R_StringHash, one for each of the (NUM_GC_GENERATIONS := NUM_OLD_GENERATIONS + 1) GC generations. New CHARSXPs are added by mkCharLenCE() to the subtable of the youngest generation. After a partial GC, only the chains anchored at the subtables of the youngest (num_old_gens_to_collect + 1) generations need to be searched for and cleaned of unmarked nodes. Afterwards, these chains need to be merged into those of the respective next generation, if any. This approach relies on the fact that an object/CHARSXP can never become younger again. It is OK though if an object/CHARSXP "skips" a GC generation.
>>
>> R_StringHash, which is now of length (NUM_GC_GENERATIONS * char_hash_size), is structured such that the chains for the same hashcode but for different generations are anchored at slots of R_StringHash which are next to each other in memory. This is because we often need to access two or more (i.e. currently all three) of them for one operation and this avoids cache misses.
>>
>> HASHPRI, i.e. the number of occupied primary slots, is computed and stored as NUM_GC_GENERATIONS times the number of slots which are occupied in at least one of the subtables. This is done because in mkCharLenCE() we need to iterate through one or more chains if and only if there is a chain for the particular hashcode in at least one subtable.
>>
>> I tried to keep the patch as minimal as possible. In particular, I did not add long vector support to R_StringHash. I rather reduced the max value of char_hash_size from 2^30 to 2^29, assuming that NUM_OLD_GENERATIONS is (not larger than) 2. I also did not yet adjust do_show_cache() and do_write_cache(), but I could do so if the patch is accepted.
>>
>> Thanks for your consideration and feedback.
>>
>> Regards,
>> Andreas
>>
>>
>> P.S. I had a hard time to get the indentation right in the patch due the mix of tabs and spaces. Sorry, if I screwed this up.
> 
> -- 
> Luke Tierney
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>    Actuarial Science
> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
> 

From ezr@ @end|ng |rom |@ndtucker@com  Tue Nov  9 17:19:13 2021
From: ezr@ @end|ng |rom |@ndtucker@com (Ezra Tucker)
Date: Tue, 09 Nov 2021 16:19:13 +0000
Subject: [Rd] Using R to wrap NREL's SSC library
Message-ID: <3c61931340b0748a0d7f112d398e158e4098f265.camel@landtucker.com>

Hi all,

I'm attempting to write a package that wraps a pre-compiled library
which is part of the SAM application, put out by NREL, available here:
https://sam.nrel.gov/download.html
or the source for the library only, available here:
https://github.com/nrel/ssc
For a variety of reasons, I'd rather not recompile the library myself,
I'd rather use the precompiled version.

I'm using the linux version right now, for mac or windows some of the
paths might be different.

In linux, the installation of SAM goes into /opt/SAM/<version>. There's
a single .h file I'm concerned with, which is in
/opt/SAM/2020.11.29/linux_64/sscapi.h and the library itself
/opt/SAM/2020.11.29/linux_64/ssc.so.

Steps I have taken:
- I duplicated it in the same directory and renamed the duplicate
libssc.so
- New package with Rcpp entitled "ssc"
- in my Makevars file I put
PKG_CPPFLAGS=-I/opt/SAM/2020.11.29/linux_64
PKG_LIBS=-L/opt/SAM/2020.11.29/linux_64 -lssc

- my NAMESPCAE file has
importFrom(Rcpp,sourceCpp)
useDynLib(ssc, .register = TRUE)

- Single function to get the library's version from the library itself
(just to make sure things are working), in ssc_version.cpp:

#include <Rcpp.h>
#include "sscapi.h"
using namespace Rcpp;

// [[Rcpp::export]]
int R_ssc_version() {
  int version = ssc_version();
  return version;
}

I'm running into a problem actually installing the package though. When
running

> devtools::check("/path/to/ssc")

The output is:
?  installing *source* package ?ssc? ...
   ** using staged installation
   ** libs
   g++ -std=gnu++14 -I"/usr/share/R/include" -DNDEBUG -
I/opt/SAM/2020.11.29/linux_64 -I'/home/ezra/R/x86_64-pc-linux-gnu-
library/4.1/Rcpp/include'    -fpic  -g -O2 -fdebug-prefix-map=/build/r-
base-i2PIHO/r-base-4.1.2=. -fstack-protector-strong -Wformat -
Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g  -UNDEBUG -
Wall -pedantic -g -O0 -fdiagnostics-color=always -c RcppExports.cpp -o
RcppExports.o
   g++ -std=gnu++14 -I"/usr/share/R/include" -DNDEBUG -
I/opt/SAM/2020.11.29/linux_64 -I'/home/ezra/R/x86_64-pc-linux-gnu-
library/4.1/Rcpp/include'    -fpic  -g -O2 -fdebug-prefix-map=/build/r-
base-i2PIHO/r-base-4.1.2=. -fstack-protector-strong -Wformat -
Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g  -UNDEBUG -
Wall -pedantic -g -O0 -fdiagnostics-color=always -c ssc_info.cpp -o
ssc_info.o
   g++ -std=gnu++14 -shared -L/usr/lib/R/lib -Wl,-Bsymbolic-functions -
Wl,-z,relro -o ssc.so RcppExports.o ssc_info.o -
L/opt/SAM/2020.11.29/linux_64 -lssc -L/usr/lib/R/lib -lR
   installing to /tmp/RtmpfGwydd/devtools_install_d2f4f57cbec83/00LOCK-
ssc/00new/ssc/libs
   ** checking absolute paths in shared objects and dynamic libraries
?  DONE (ssc)
Error in dyn.load(dll_copy_file) :
  unable to load shared object
'/tmp/RtmpfGwydd/pkgloadd2f4f752bdb80/ssc.so':
  ssc.so: cannot open shared object file: No such file or directory

However:
> file.exists("/tmp/RtmpfGwydd/pkgloadd2f4f752bdb80/ssc.so")
[1] TRUE

(I'm using devtools::check because R CMD check deletes the package info
after running. Also I ran Rcpp::compileAttributes() before initiating
the check.)

My sessionInfo (before running devtools::check) is:

R version 4.1.2 (2021-11-01)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 21.10

Matrix products: default
BLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0
LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_4.1.2

Does anybody have any suggestions? Thank you!

-Ezra


From kry|ov@r00t @end|ng |rom gm@||@com  Tue Nov  9 17:56:34 2021
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Tue, 9 Nov 2021 19:56:34 +0300
Subject: [Rd] Using R to wrap NREL's SSC library
In-Reply-To: <3c61931340b0748a0d7f112d398e158e4098f265.camel@landtucker.com>
References: <3c61931340b0748a0d7f112d398e158e4098f265.camel@landtucker.com>
Message-ID: <20211109195634.34014fd1@Tarkus>

Sorry, this discussion is better continued at
https://stat.ethz.ch/mailman/listinfo/r-package-devel.

On Tue, 09 Nov 2021 16:19:13 +0000
Ezra Tucker <ezra at landtucker.com> wrote:

> PKG_LIBS=-L/opt/SAM/2020.11.29/linux_64

There's no good answer, but search "Writing R Extensions" for "rpath"
for potential ways of solving this problem: you'll need to specify the
runtime dynamic library path in addition to the link-time library path.

-- 
Best regards,
Ivan


From ezr@ @end|ng |rom |@ndtucker@com  Tue Nov  9 19:06:48 2021
From: ezr@ @end|ng |rom |@ndtucker@com (Ezra Tucker)
Date: Tue, 09 Nov 2021 18:06:48 +0000
Subject: [Rd] Using R to wrap NREL's SSC library
In-Reply-To: <20211109195634.34014fd1@Tarkus>
References: <3c61931340b0748a0d7f112d398e158e4098f265.camel@landtucker.com>
 <20211109195634.34014fd1@Tarkus>
Message-ID: <8eb0a75473acaa53b233d4a9c11cda211d3bf4d3.camel@landtucker.com>

Hi Ivan,

Sorry all-- wrong message board, embarrassed!
Also embarrassed I forgot the -Wl,-rpath flags. One quick fix, seems to
be working now.
Thanks!!

-Ezra

On Tue, 2021-11-09 at 19:56 +0300, Ivan Krylov wrote:
> Sorry, this discussion is better continued at
> https://stat.ethz.ch/mailman/listinfo/r-package-devel.
>
> On Tue, 09 Nov 2021 16:19:13 +0000
> Ezra Tucker <ezra at landtucker.com> wrote:
>
> > PKG_LIBS=-L/opt/SAM/2020.11.29/linux_64
>
> There's no good answer, but search "Writing R Extensions" for "rpath"
> for potential ways of solving this problem: you'll need to specify
> the
> runtime dynamic library path in addition to the link-time library
> path.
>
> --
> Best regards,
> Ivan


From z@gu @end|ng |rom dk|z-he|de|berg@de  Sat Nov 13 12:51:04 2021
From: z@gu @end|ng |rom dk|z-he|de|berg@de (Gu, Zuguang)
Date: Sat, 13 Nov 2021 11:51:04 +0000
Subject: [Rd] Converting width for a grob where graphics parameters have
 length 0 crashes R
Message-ID: <1636804264876.29489@dkfz-heidelberg.de>

Dear developers,


In grid::gpar(), graphic parameters are not allowed to have length 0, but this can be done by first creating a gpar object and later modifying it:


gp = gpar(fontsize = 10)

gp$fontsize = numeric(0)


when a grob has a gp where some parameters have length 0, converting the width or height of this grob will crash R.

?

A reproducible example is as follows:


> library(grid)

> gp = gpar(fontsize = 10)
> gp$fontsize = numeric(0)
> gb = textGrob("foo", gp = gp)
> convertWidth(grobWidth(gb), "mm")
[1]    21045 floating point exception  R??


Best regards,

Zuguang Gu


	[[alternative HTML version deleted]]


From p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz  Sun Nov 14 21:16:16 2021
From: p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz (Paul Murrell)
Date: Mon, 15 Nov 2021 09:16:16 +1300
Subject: [Rd] Converting width for a grob where graphics parameters have
 length 0 crashes R
In-Reply-To: <1636804264876.29489@dkfz-heidelberg.de>
References: <1636804264876.29489@dkfz-heidelberg.de>
Message-ID: <095f9e56-0182-28f9-2347-1d1bbfb20312@stat.auckland.ac.nz>

Hi

Thanks for bringing this (back) up.

It is still on my list, but now back nearer the top :)

Paul


On 14/11/2021 12:51 am, Gu, Zuguang wrote:
> Dear developers,
> 
> 
> In grid::gpar(), graphic parameters are not allowed to have length 0, 
> but this can be done by first creating a gpar object and later modifying it:
> 
> 
> gp = gpar(fontsize = 10)
> 
> gp$fontsize = numeric(0)
> 
> 
> when a grob has a gp where some parameters have length 0, converting the 
> width or height of this grob will crash R.
> 
> ?
> 
> A reproducible example is as follows:
> 
> 
>  > library(grid)
> 
>  > gp = gpar(fontsize = 10)
>  > gp$fontsize = numeric(0)
>  > gb = textGrob("foo", gp = gp)
>  > convertWidth(grobWidth(gb), "mm")
> [1] 21045 floating point exception R??
> 
> 
> Best regards,
> 
> Zuguang Gu
> 
> 
> [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel 
> <https://stat.ethz.ch/mailman/listinfo/r-devel>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From du@@@@dr|@n @end|ng |rom un|buc@ro  Mon Nov 15 18:18:23 2021
From: du@@@@dr|@n @end|ng |rom un|buc@ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Mon, 15 Nov 2021 19:18:23 +0200
Subject: [Rd] substitute
Message-ID: <CAJ=0CtB4wmXm5sgDk=TP0Cp=zGRfvxLt-XY02adTXT5z7W3_sg@mail.gmail.com>

Dear R wizards,

I have recently been informed about some build errors of my package QCA,
which I was able to trace down to the base function substitute(), with the
following replication example:

foo <- function(x) return(substitute(x))

In the stable R version 4.0.5, I get the expected result:
> foo(A + ~B + C~D)
A + ~B + C ~ D

A different result (the culprit for the build error) occurs under Fedora
with R devel:

> foo(A + ~B + C~D)
A + (~B + C) ~ D

The Fedora machine is the rhub docker image from:
https://hub.docker.com/r/rhub/fedora-gcc-devel

probably very similar to the one signalling the CRAN build error:
https://cran.r-project.org/web/checks/check_results_QCA.html

The first (expected) command is from the stable R version installed on the
same Fedora machine, and I get an identical result on Windows and MacOS.

For some reason, substitute() gives a different result on Debian using gcc,
and on both Fedora systems. I would be grateful for any hint, I am not
entirely certain what I should do about this.

Thank you very much in advance,
Adrian

-- 
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr. 90-92
050663 Bucharest sector 5
Romania
https://adriandusa.eu

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Nov 15 18:27:53 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 15 Nov 2021 12:27:53 -0500
Subject: [Rd] substitute
In-Reply-To: <CAJ=0CtB4wmXm5sgDk=TP0Cp=zGRfvxLt-XY02adTXT5z7W3_sg@mail.gmail.com>
References: <CAJ=0CtB4wmXm5sgDk=TP0Cp=zGRfvxLt-XY02adTXT5z7W3_sg@mail.gmail.com>
Message-ID: <b07eaaab-bd67-164f-cdcc-f40367511b4b@gmail.com>

This looks as though it is related to the recent patch in

   https://bugs.r-project.org/show_bug.cgi?id=18232

I think you should probably wait until that settles down before worrying 
about it.

Duncan Murdoch

On 15/11/2021 12:18 p.m., Adrian Du?a wrote:
> Dear R wizards,
> 
> I have recently been informed about some build errors of my package QCA,
> which I was able to trace down to the base function substitute(), with the
> following replication example:
> 
> foo <- function(x) return(substitute(x))
> 
> In the stable R version 4.0.5, I get the expected result:
>> foo(A + ~B + C~D)
> A + ~B + C ~ D
> 
> A different result (the culprit for the build error) occurs under Fedora
> with R devel:
> 
>> foo(A + ~B + C~D)
> A + (~B + C) ~ D
> 
> The Fedora machine is the rhub docker image from:
> https://hub.docker.com/r/rhub/fedora-gcc-devel
> 
> probably very similar to the one signalling the CRAN build error:
> https://cran.r-project.org/web/checks/check_results_QCA.html
> 
> The first (expected) command is from the stable R version installed on the
> same Fedora machine, and I get an identical result on Windows and MacOS.
> 
> For some reason, substitute() gives a different result on Debian using gcc,
> and on both Fedora systems. I would be grateful for any hint, I am not
> entirely certain what I should do about this.
> 
> Thank you very much in advance,
> Adrian
>


From du@@@@dr|@n @end|ng |rom un|buc@ro  Mon Nov 15 18:58:26 2021
From: du@@@@dr|@n @end|ng |rom un|buc@ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Mon, 15 Nov 2021 19:58:26 +0200
Subject: [Rd] substitute
In-Reply-To: <b07eaaab-bd67-164f-cdcc-f40367511b4b@gmail.com>
References: <CAJ=0CtB4wmXm5sgDk=TP0Cp=zGRfvxLt-XY02adTXT5z7W3_sg@mail.gmail.com>
 <b07eaaab-bd67-164f-cdcc-f40367511b4b@gmail.com>
Message-ID: <CAJ=0CtDbAZ+MY4oFmYo4BFXB4OEpp4p_YUpdxeNywGxOQ6ihqg@mail.gmail.com>

Thank you, I was given a deadline of two weeks to respond, hopefully this
will be settled by then.
Best wishes,
Adrian

On Mon, 15 Nov 2021 at 19:28, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> This looks as though it is related to the recent patch in
>
>    https://bugs.r-project.org/show_bug.cgi?id=18232
>
> I think you should probably wait until that settles down before worrying
> about it.
>
> Duncan Murdoch
>
> On 15/11/2021 12:18 p.m., Adrian Du?a wrote:
> > Dear R wizards,
> >
> > I have recently been informed about some build errors of my package QCA,
> > which I was able to trace down to the base function substitute(), with
> the
> > following replication example:
> >
> > foo <- function(x) return(substitute(x))
> >
> > In the stable R version 4.0.5, I get the expected result:
> >> foo(A + ~B + C~D)
> > A + ~B + C ~ D
> >
> > A different result (the culprit for the build error) occurs under Fedora
> > with R devel:
> >
> >> foo(A + ~B + C~D)
> > A + (~B + C) ~ D
> >
> > The Fedora machine is the rhub docker image from:
> > https://hub.docker.com/r/rhub/fedora-gcc-devel
> >
> > probably very similar to the one signalling the CRAN build error:
> > https://cran.r-project.org/web/checks/check_results_QCA.html
> >
> > The first (expected) command is from the stable R version installed on
> the
> > same Fedora machine, and I get an identical result on Windows and MacOS.
> >
> > For some reason, substitute() gives a different result on Debian using
> gcc,
> > and on both Fedora systems. I would be grateful for any hint, I am not
> > entirely certain what I should do about this.
> >
> > Thank you very much in advance,
> > Adrian
> >
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr. 90-92
050663 Bucharest sector 5
Romania
https://adriandusa.eu

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Nov 15 19:06:23 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 15 Nov 2021 13:06:23 -0500
Subject: [Rd] substitute
In-Reply-To: <CAJ=0CtDbAZ+MY4oFmYo4BFXB4OEpp4p_YUpdxeNywGxOQ6ihqg@mail.gmail.com>
References: <CAJ=0CtB4wmXm5sgDk=TP0Cp=zGRfvxLt-XY02adTXT5z7W3_sg@mail.gmail.com>
 <b07eaaab-bd67-164f-cdcc-f40367511b4b@gmail.com>
 <CAJ=0CtDbAZ+MY4oFmYo4BFXB4OEpp4p_YUpdxeNywGxOQ6ihqg@mail.gmail.com>
Message-ID: <cc022730-3c10-07db-deef-5c78c838ef46@gmail.com>

I'd recommend responding now with a pointer to that bug report: whoever 
at CRAN is dealing with your package doesn't necessarily know about the 
bug report.  You might or might not need to make a change in the end, 
but if you do, it could be hard to meet the two week deadline.

Duncan Murdoch

On 15/11/2021 12:58 p.m., Adrian Du?a wrote:
> Thank you, I was given a deadline of two weeks to respond, hopefully 
> this will be settled by then.
> Best wishes,
> Adrian
> 
> On Mon, 15 Nov 2021 at 19:28, Duncan Murdoch <murdoch.duncan at gmail.com 
> <mailto:murdoch.duncan at gmail.com>> wrote:
> 
>     This looks as though it is related to the recent patch in
> 
>     https://bugs.r-project.org/show_bug.cgi?id=18232
>     <https://bugs.r-project.org/show_bug.cgi?id=18232>
> 
>     I think you should probably wait until that settles down before
>     worrying
>     about it.
> 
>     Duncan Murdoch
> 
>     On 15/11/2021 12:18 p.m., Adrian Du?a wrote:
>      > Dear R wizards,
>      >
>      > I have recently been informed about some build errors of my
>     package QCA,
>      > which I was able to trace down to the base function substitute(),
>     with the
>      > following replication example:
>      >
>      > foo <- function(x) return(substitute(x))
>      >
>      > In the stable R version 4.0.5, I get the expected result:
>      >> foo(A + ~B + C~D)
>      > A + ~B + C ~ D
>      >
>      > A different result (the culprit for the build error) occurs under
>     Fedora
>      > with R devel:
>      >
>      >> foo(A + ~B + C~D)
>      > A + (~B + C) ~ D
>      >
>      > The Fedora machine is the rhub docker image from:
>      > https://hub.docker.com/r/rhub/fedora-gcc-devel
>     <https://hub.docker.com/r/rhub/fedora-gcc-devel>
>      >
>      > probably very similar to the one signalling the CRAN build error:
>      > https://cran.r-project.org/web/checks/check_results_QCA.html
>     <https://cran.r-project.org/web/checks/check_results_QCA.html>
>      >
>      > The first (expected) command is from the stable R version
>     installed on the
>      > same Fedora machine, and I get an identical result on Windows and
>     MacOS.
>      >
>      > For some reason, substitute() gives a different result on Debian
>     using gcc,
>      > and on both Fedora systems. I would be grateful for any hint, I
>     am not
>      > entirely certain what I should do about this.
>      >
>      > Thank you very much in advance,
>      > Adrian
>      >
> 
>     ______________________________________________
>     R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-devel
>     <https://stat.ethz.ch/mailman/listinfo/r-devel>
> 
> 
> 
> -- 
> Adrian Dusa
> University of Bucharest
> Romanian Social Data Archive
> Soseaua Panduri nr. 90-92
> 050663 Bucharest sector 5
> Romania
> https://adriandusa.eu <https://adriandusa.eu>


From @vr@h@m@@d|er @end|ng |rom gm@||@com  Tue Nov 16 03:35:56 2021
From: @vr@h@m@@d|er @end|ng |rom gm@||@com (Avraham Adler)
Date: Tue, 16 Nov 2021 02:35:56 +0000
Subject: [Rd] R-devel (r81196) hanging at dchisq(large) (PR#13309)
Message-ID: <CAL6gwn+-zy+RjX+toMptU6nyOc5bwQix4WDHbkgWAXwCTYEwqA@mail.gmail.com>

I am building r-devel on Windows 10 64bit using Jeroen's mingw system,
and I am finding that my make check-devel hangs on the above issue.
Everything is vanila except that I am using OpenBLAS 0.3.18. I have
been using OpenBLAS for over a decade and have not had this issue
before. Is there anything I can do to dig deeper into this issue from
my end? Could there be anything that changed in R-devel that may have
triggered this? The bugzilla report doesn't have any code attached to
it.

Thank you,

Avi

sessionInfo:
R Under development (unstable) (2021-11-15 r81196)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 19043)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_4.2.0 tools_4.2.0


From p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz  Tue Nov 16 07:54:42 2021
From: p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz (Paul Murrell)
Date: Tue, 16 Nov 2021 19:54:42 +1300
Subject: [Rd] Converting width for a grob where graphics parameters have
 length 0 crashes R
In-Reply-To: <095f9e56-0182-28f9-2347-1d1bbfb20312@stat.auckland.ac.nz>
References: <1636804264876.29489@dkfz-heidelberg.de>
 <095f9e56-0182-28f9-2347-1d1bbfb20312@stat.auckland.ac.nz>
Message-ID: <7d669c27-486b-78f3-8985-136ac16d339f@stat.auckland.ac.nz>

Hi

There is now a fix for this problem in r-devel (r81197).

Thanks for reporting the problem!

Paul

On 15/11/2021 9:16 am, Paul Murrell wrote:
> Hi
> 
> Thanks for bringing this (back) up.
> 
> It is still on my list, but now back nearer the top :)
> 
> Paul
> 
> 
> On 14/11/2021 12:51 am, Gu, Zuguang wrote:
>> Dear developers,
>>
>>
>> In grid::gpar(), graphic parameters are not allowed to have length 0, 
>> but this can be done by first creating a gpar object and later 
>> modifying it:
>>
>>
>> gp = gpar(fontsize = 10)
>>
>> gp$fontsize = numeric(0)
>>
>>
>> when a grob has a gp where some parameters have length 0, converting 
>> the width or height of this grob will crash R.
>>
>> ?
>>
>> A reproducible example is as follows:
>>
>>
>> ?> library(grid)
>>
>> ?> gp = gpar(fontsize = 10)
>> ?> gp$fontsize = numeric(0)
>> ?> gb = textGrob("foo", gp = gp)
>> ?> convertWidth(grobWidth(gb), "mm")
>> [1] 21045 floating point exception R??
>>
>>
>> Best regards,
>>
>> Zuguang Gu
>>
>>
>> [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel 
>> <https://stat.ethz.ch/mailman/listinfo/r-devel> 
>>
> 

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Tue Nov 16 09:43:43 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 16 Nov 2021 09:43:43 +0100
Subject: [Rd] R-devel (r81196) hanging at dchisq(large) (PR#13309)
In-Reply-To: <CAL6gwn+-zy+RjX+toMptU6nyOc5bwQix4WDHbkgWAXwCTYEwqA@mail.gmail.com>
References: <CAL6gwn+-zy+RjX+toMptU6nyOc5bwQix4WDHbkgWAXwCTYEwqA@mail.gmail.com>
Message-ID: <24979.28479.945404.466101@stat.math.ethz.ch>

>>>>> Avraham Adler 
>>>>>     on Tue, 16 Nov 2021 02:35:56 +0000 writes:

    > I am building r-devel on Windows 10 64bit using Jeroen's mingw system,
    > and I am finding that my make check-devel hangs on the above issue.
    > Everything is vanila except that I am using OpenBLAS 0.3.18. I have
    > been using OpenBLAS for over a decade and have not had this issue
    > before. Is there anything I can do to dig deeper into this issue from
    > my end? Could there be anything that changed in R-devel that may have
    > triggered this? The bugzilla report doesn't have any code attached to
    > it.

    > Thank you,
    > Avi

Hmm.. it would've be nice to tell a bit more, instead of having all
your readers to search links, etc.

In the bugzilla bug report PR#13309
https://bugs.r-project.org/show_bug.cgi?id=13309 ,the example was

 dchisq(x=Inf, df=10, ncp=1)

I had fixed the bug 13 years ago, in svn rev 47005
with regression test in <Rsrc>/tests/d-p-q-r-tests.R :


## Non-central Chi^2 density for large x
stopifnot(0 == dchisq(c(Inf, 1e80, 1e50, 1e40), df=10, ncp=1))
## did hang in 2.8.0 and earlier (PR#13309).


and you are seeing your version of R hanging at exactly this
location?


I'd bet quite a bit that the underlying code in these
non-central chi square computations *never* calls BLAS and hence
I cannot imagine how openBLAS could play a role.

However, there must be something peculiar in your compiler setup,
compilation options, ....
as of course the above regression test has been run 100s of
1000s of times also under Windows in the last 13 years ..

Last but not least (but really only vaguely related):
   There is still a FIXME in the source code (but not about
hanging, but rather of loosing some accuracy in border cases),
see e.g. https://svn.r-project.org/R/trunk/src/nmath/dnchisq.c
and for that reason I had written an R version of that C code
even back in 2008 which I've made available in  CRAN package
DPQ  a few years ago (together with many other D/P/Q
distribution computations/approximations).
	     -> https://cran.r-project.org/package=DPQ

Best,
Martin


    > sessionInfo:
    > R Under development (unstable) (2021-11-15 r81196)
    > Platform: x86_64-w64-mingw32/x64 (64-bit)
    > Running under: Windows 10 x64 (build 19043)

    > Matrix products: default

    > locale:
    > [1] LC_COLLATE=English_United States.1252
    > [2] LC_CTYPE=English_United States.1252
    > [3] LC_MONETARY=English_United States.1252
    > [4] LC_NUMERIC=C
    > [5] LC_TIME=English_United States.1252

    > attached base packages:
    > [1] stats     graphics  grDevices utils     datasets  methods   base

    > loaded via a namespace (and not attached):
    > [1] compiler_4.2.0 tools_4.2.0


From o|ek@h||on @end|ng |rom gm@||@com  Tue Nov 16 10:52:50 2021
From: o|ek@h||on @end|ng |rom gm@||@com (Ofek Shilon)
Date: Tue, 16 Nov 2021 11:52:50 +0200
Subject: [Rd] Inconsistent is.list results on 'by' objects
Message-ID: <CAAR4qE9KQ_JY2AzQVGLYcxrobo9C3QD8jeRYG82Scc7k3Uu-5Q@mail.gmail.com>

Take this toy code:
df       <- data.frame(a=seq(10), b=rep(1:2, 5))
df.empty <- subset(df, a>10)
byy       <- by(data=df,       INDICES=df$b, FUN=function(x) x[1,])
byy.empty <- by(data=df.empty, INDICES=df.empty$b, FUN=function(x) x[1,])

class(byy)       # "by"
class(byy.empty) # "by"

is.list(byy)        # TRUE
is.list(byy.empty)  # FALSE!


This behavior already messed up stuff elsewhere:
https://github.com/Rdatatable/data.table/issues/5258

I'd say any questions about the class of an object (whether 'class' or
indirectly by 'is.**')
should not have the answers depend on the specific contents of the object.

Does this qualify as an R bug? Am I missing something?

	[[alternative HTML version deleted]]


From @vr@h@m@@d|er @end|ng |rom gm@||@com  Tue Nov 16 14:11:37 2021
From: @vr@h@m@@d|er @end|ng |rom gm@||@com (Avraham Adler)
Date: Tue, 16 Nov 2021 13:11:37 +0000
Subject: [Rd] R-devel (r81196) hanging at dchisq(large) (PR#13309)
In-Reply-To: <24979.28479.945404.466101@stat.math.ethz.ch>
References: <CAL6gwn+-zy+RjX+toMptU6nyOc5bwQix4WDHbkgWAXwCTYEwqA@mail.gmail.com>
 <24979.28479.945404.466101@stat.math.ethz.ch>
Message-ID: <CAL6gwnJuPnwS9GXvd0O80H3rRXxAUWrmUncOkrDECB2B+X-+8w@mail.gmail.com>

On Tue, Nov 16, 2021 at 8:43 AM Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>
> >>>>> Avraham Adler
> >>>>>     on Tue, 16 Nov 2021 02:35:56 +0000 writes:
>
>     > I am building r-devel on Windows 10 64bit using Jeroen's mingw system,
>     > and I am finding that my make check-devel hangs on the above issue.
>     > Everything is vanila except that I am using OpenBLAS 0.3.18. I have
>     > been using OpenBLAS for over a decade and have not had this issue
>     > before. Is there anything I can do to dig deeper into this issue from
>     > my end? Could there be anything that changed in R-devel that may have
>     > triggered this? The bugzilla report doesn't have any code attached to
>     > it.
>
>     > Thank you,
>     > Avi
>
> Hmm.. it would've be nice to tell a bit more, instead of having all
> your readers to search links, etc.
>
> In the bugzilla bug report PR#13309
> https://bugs.r-project.org/show_bug.cgi?id=13309 ,the example was
>
>  dchisq(x=Inf, df=10, ncp=1)
>
> I had fixed the bug 13 years ago, in svn rev 47005
> with regression test in <Rsrc>/tests/d-p-q-r-tests.R :
>
>
> ## Non-central Chi^2 density for large x
> stopifnot(0 == dchisq(c(Inf, 1e80, 1e50, 1e40), df=10, ncp=1))
> ## did hang in 2.8.0 and earlier (PR#13309).
>
>
> and you are seeing your version of R hanging at exactly this
> location?
>
>
> I'd bet quite a bit that the underlying code in these
> non-central chi square computations *never* calls BLAS and hence
> I cannot imagine how openBLAS could play a role.
>
> However, there must be something peculiar in your compiler setup,
> compilation options, ....
> as of course the above regression test has been run 100s of
> 1000s of times also under Windows in the last 13 years ..
>
> Last but not least (but really only vaguely related):
>    There is still a FIXME in the source code (but not about
> hanging, but rather of loosing some accuracy in border cases),
> see e.g. https://svn.r-project.org/R/trunk/src/nmath/dnchisq.c
> and for that reason I had written an R version of that C code
> even back in 2008 which I've made available in  CRAN package
> DPQ  a few years ago (together with many other D/P/Q
> distribution computations/approximations).
>              -> https://cran.r-project.org/package=DPQ
>
> Best,
> Martin
>

Hello, Martin.

Apologies, I thought the PR # was sufficient. Yes, I am seeing this at
this exact location. This is what I saw in d-p-q-r-tst-2.Rout.fail and
I then ran d-p-q-r-tst.R line-by-line and R hung precisely after
`stopifnot(0 == dchisq(c(Inf, 1e80, 1e50, 1e40), df=10, ncp=1))`.

Is it at all possible that this has to do with the recent change from
bd0 to ebd0 (PR #15628) [1]?

For completeness, I ran all the code _beneath_ the call, and while
nothing else cause an infinite loop, I posted what I believe may be
unexpected results below,

Thank you,

Avi

[1]: https://bugs.r-project.org/show_bug.cgi?id=15628

> ## FIXME ?!:  MxM/2 seems +- ok ??
> (dLmM <- dnbinom(xL, mu = 1, size = MxM))  # all NaN but the last
Warning in dnbinom(xL, mu = 1, size = MxM) : NaNs produced
 [1] NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN
NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   0
> (dLpI <- dnbinom(xL, prob=1/2, size = Inf))#  ditto
Warning in dnbinom(xL, prob = 1/2, size = Inf) : NaNs produced
 [1] NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN
NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   0
> (dLpM <- dnbinom(xL, prob=1/2, size = MxM))#  ditto
Warning in dnbinom(xL, prob = 1/2, size = MxM) : NaNs produced
 [1] NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN
NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   0

> d <- dnbinom(x,  mu = mu, size = Inf) # gave NaN (for 0 and L), now all 0
Warning in dnbinom(x, mu = mu, size = Inf) : NaNs produced
> p <- pnbinom(x,  mu = mu, size = Inf) # gave all NaN, now uses ppois(x, mu)
Warning in pnbinom(x, mu = mu, size = Inf) : NaNs produced

> pp <- (0:16)/16
> q <- qnbinom(pp, mu = mu, size = Inf) # gave all NaN
> set.seed(1); NI <- rnbinom(32, mu = mu, size = Inf)# gave all NaN
> set.seed(1); N2 <- rnbinom(32, mu = mu, size = L  )
> stopifnot(exprs = {
+     all.equal(d, c(0.006737947, 0.033689735, 0.0842243375,
0.140373896, 0,0,0,0), tol = 9e-9)# 7.6e-10
+     all.equal(p, c(0.006737947, 0.040427682, 0.1246520195,
0.265025915, 1,1,1,1), tol = 9e-9)# 7.3e-10
+     all.equal(d, dpois(x, mu))# current implementation: even identical()
+     all.equal(p, ppois(x, mu))
+     q == c(0, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6, 6, 6, 7, 8, 9, Inf)
+     q == qpois(pp, mu)
+     identical(NI, N2)
+ })
Error: d and c(0.006737947, 0.033689735, 0.0842243375, 0.140373896, 0,
0,  .... are not equal:
  'is.NA' value mismatch: 0 in current 1 in target

> if(!(onWindows && arch == "x86")) {
+  ## This gave a practically infinite loop (on 64-bit Lnx, Windows;
not in 32-bit)
+     tools::assertWarning(p <- pchisq(1.00000012e200, df=1e200, ncp=100),
+                          "simpleWarning", verbose=TRUE)
+     stopifnot(p == 1)
+ }
Asserted warning: pnchisq(x=1e+200, f=1e+200, theta=100, ..): not
converged in 1000000 iter.

[This may be OK, AA]

> ## Show the (mostly) small differences :
> all.equal( qs, qpU, tol=0)
[1] "Mean relative difference: 1.572997e-16"
> all.equal(-qs, qp., tol=0)
[1] "Mean relative difference: 1.572997e-16"
> all.equal(-qp.,qpU, tol=0) # typically TRUE (<==> exact equality)
[1] "Mean relative difference: 4.710277e-16"
> stopifnot(exprs = {
+     all.equal( qs,  qpU, tol=1e-15)
+     all.equal(-qs,  qp., tol=1e-15)
+     all.equal(-qp., qpU, tol=1e-15)# diff of 4.71e-16 in 4.1.0 w/icc
(Eric Weese)
+ })
> ## both failed very badly in  R <= 4.0.x


From w||||@mwdun|@p @end|ng |rom gm@||@com  Tue Nov 16 19:21:02 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Tue, 16 Nov 2021 10:21:02 -0800
Subject: [Rd] Inconsistent is.list results on 'by' objects
In-Reply-To: <CAAR4qE9KQ_JY2AzQVGLYcxrobo9C3QD8jeRYG82Scc7k3Uu-5Q@mail.gmail.com>
References: <CAAR4qE9KQ_JY2AzQVGLYcxrobo9C3QD8jeRYG82Scc7k3Uu-5Q@mail.gmail.com>
Message-ID: <CAHqSRuS1Mh3zM3FLYpeQGvHWqcL-uad+L4OQ4qNuCzw9mJ62yQ@mail.gmail.com>

Try adding simplify=FALSE to the call to by().

-Bill

On Tue, Nov 16, 2021 at 4:04 AM Ofek Shilon <ofekshilon at gmail.com> wrote:

> Take this toy code:
> df       <- data.frame(a=seq(10), b=rep(1:2, 5))
> df.empty <- subset(df, a>10)
> byy       <- by(data=df,       INDICES=df$b, FUN=function(x) x[1,])
> byy.empty <- by(data=df.empty, INDICES=df.empty$b, FUN=function(x) x[1,])
>
> class(byy)       # "by"
> class(byy.empty) # "by"
>
> is.list(byy)        # TRUE
> is.list(byy.empty)  # FALSE!
>
>
> This behavior already messed up stuff elsewhere:
> https://github.com/Rdatatable/data.table/issues/5258
>
> I'd say any questions about the class of an object (whether 'class' or
> indirectly by 'is.**')
> should not have the answers depend on the specific contents of the object.
>
> Does this qualify as an R bug? Am I missing something?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From c@@rd|@g@bor @end|ng |rom gm@||@com  Tue Nov 16 23:16:25 2021
From: c@@rd|@g@bor @end|ng |rom gm@||@com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Tue, 16 Nov 2021 23:16:25 +0100
Subject: [Rd] LOGNAME env var in the check code
Message-ID: <CABtg=Kn59VtnH4pw2+JqYpO+K9BrBa0Ppuk3we3B4EqigMjG3g@mail.gmail.com>

While trying to reproduce a NOTE for

* checking for new files in some other directories ... NOTE

I noticed that the check code uses

Sys.getenv("LOGNAME")

to query the name of the current user. However on many systems this is
not set, so this is the empty string, and then no NOTE is shown. (Only
files owned by the current user generate a NOTE.)

An alternative would be to call `id -un` to query the username, or
create a file and then use `file.info()` to query its owner. Using one
of these alternatives would make this check more reproducible.

Thanks,
Gabor


From kev|nu@hey @end|ng |rom gm@||@com  Tue Nov 16 23:41:47 2021
From: kev|nu@hey @end|ng |rom gm@||@com (Kevin Ushey)
Date: Tue, 16 Nov 2021 14:41:47 -0800
Subject: [Rd] R-devel (r81196) hanging at dchisq(large) (PR#13309)
In-Reply-To: <CAL6gwnJuPnwS9GXvd0O80H3rRXxAUWrmUncOkrDECB2B+X-+8w@mail.gmail.com>
References: <CAL6gwn+-zy+RjX+toMptU6nyOc5bwQix4WDHbkgWAXwCTYEwqA@mail.gmail.com>
 <24979.28479.945404.466101@stat.math.ethz.ch>
 <CAL6gwnJuPnwS9GXvd0O80H3rRXxAUWrmUncOkrDECB2B+X-+8w@mail.gmail.com>
Message-ID: <CAJXgQP1Hz2eKBObhGzgO6iEo0k3AJetWiii4t86Xu3Gvir+6nw@mail.gmail.com>

Do you see this same hang in a build of R with debug symbols? Can you
try running R with GDB, or even WinDbg or another debugger, to see
what the call stack looks like when the hang occurs? Does the hang
depend on the number of threads used by OpenBLAS?

On the off chance it's relevant, I've seen hangs / crashes when using
a multithreaded OpenBLAS with R on some Linux systems before, but
never found the time to isolate a root cause.

Best,
Kevin

On Tue, Nov 16, 2021 at 5:12 AM Avraham Adler <avraham.adler at gmail.com> wrote:
>
> On Tue, Nov 16, 2021 at 8:43 AM Martin Maechler
> <maechler at stat.math.ethz.ch> wrote:
> >
> > >>>>> Avraham Adler
> > >>>>>     on Tue, 16 Nov 2021 02:35:56 +0000 writes:
> >
> >     > I am building r-devel on Windows 10 64bit using Jeroen's mingw system,
> >     > and I am finding that my make check-devel hangs on the above issue.
> >     > Everything is vanila except that I am using OpenBLAS 0.3.18. I have
> >     > been using OpenBLAS for over a decade and have not had this issue
> >     > before. Is there anything I can do to dig deeper into this issue from
> >     > my end? Could there be anything that changed in R-devel that may have
> >     > triggered this? The bugzilla report doesn't have any code attached to
> >     > it.
> >
> >     > Thank you,
> >     > Avi
> >
> > Hmm.. it would've be nice to tell a bit more, instead of having all
> > your readers to search links, etc.
> >
> > In the bugzilla bug report PR#13309
> > https://bugs.r-project.org/show_bug.cgi?id=13309 ,the example was
> >
> >  dchisq(x=Inf, df=10, ncp=1)
> >
> > I had fixed the bug 13 years ago, in svn rev 47005
> > with regression test in <Rsrc>/tests/d-p-q-r-tests.R :
> >
> >
> > ## Non-central Chi^2 density for large x
> > stopifnot(0 == dchisq(c(Inf, 1e80, 1e50, 1e40), df=10, ncp=1))
> > ## did hang in 2.8.0 and earlier (PR#13309).
> >
> >
> > and you are seeing your version of R hanging at exactly this
> > location?
> >
> >
> > I'd bet quite a bit that the underlying code in these
> > non-central chi square computations *never* calls BLAS and hence
> > I cannot imagine how openBLAS could play a role.
> >
> > However, there must be something peculiar in your compiler setup,
> > compilation options, ....
> > as of course the above regression test has been run 100s of
> > 1000s of times also under Windows in the last 13 years ..
> >
> > Last but not least (but really only vaguely related):
> >    There is still a FIXME in the source code (but not about
> > hanging, but rather of loosing some accuracy in border cases),
> > see e.g. https://svn.r-project.org/R/trunk/src/nmath/dnchisq.c
> > and for that reason I had written an R version of that C code
> > even back in 2008 which I've made available in  CRAN package
> > DPQ  a few years ago (together with many other D/P/Q
> > distribution computations/approximations).
> >              -> https://cran.r-project.org/package=DPQ
> >
> > Best,
> > Martin
> >
>
> Hello, Martin.
>
> Apologies, I thought the PR # was sufficient. Yes, I am seeing this at
> this exact location. This is what I saw in d-p-q-r-tst-2.Rout.fail and
> I then ran d-p-q-r-tst.R line-by-line and R hung precisely after
> `stopifnot(0 == dchisq(c(Inf, 1e80, 1e50, 1e40), df=10, ncp=1))`.
>
> Is it at all possible that this has to do with the recent change from
> bd0 to ebd0 (PR #15628) [1]?
>
> For completeness, I ran all the code _beneath_ the call, and while
> nothing else cause an infinite loop, I posted what I believe may be
> unexpected results below,
>
> Thank you,
>
> Avi
>
> [1]: https://bugs.r-project.org/show_bug.cgi?id=15628
>
> > ## FIXME ?!:  MxM/2 seems +- ok ??
> > (dLmM <- dnbinom(xL, mu = 1, size = MxM))  # all NaN but the last
> Warning in dnbinom(xL, mu = 1, size = MxM) : NaNs produced
>  [1] NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN
> NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   0
> > (dLpI <- dnbinom(xL, prob=1/2, size = Inf))#  ditto
> Warning in dnbinom(xL, prob = 1/2, size = Inf) : NaNs produced
>  [1] NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN
> NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   0
> > (dLpM <- dnbinom(xL, prob=1/2, size = MxM))#  ditto
> Warning in dnbinom(xL, prob = 1/2, size = MxM) : NaNs produced
>  [1] NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN
> NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   0
>
> > d <- dnbinom(x,  mu = mu, size = Inf) # gave NaN (for 0 and L), now all 0
> Warning in dnbinom(x, mu = mu, size = Inf) : NaNs produced
> > p <- pnbinom(x,  mu = mu, size = Inf) # gave all NaN, now uses ppois(x, mu)
> Warning in pnbinom(x, mu = mu, size = Inf) : NaNs produced
>
> > pp <- (0:16)/16
> > q <- qnbinom(pp, mu = mu, size = Inf) # gave all NaN
> > set.seed(1); NI <- rnbinom(32, mu = mu, size = Inf)# gave all NaN
> > set.seed(1); N2 <- rnbinom(32, mu = mu, size = L  )
> > stopifnot(exprs = {
> +     all.equal(d, c(0.006737947, 0.033689735, 0.0842243375,
> 0.140373896, 0,0,0,0), tol = 9e-9)# 7.6e-10
> +     all.equal(p, c(0.006737947, 0.040427682, 0.1246520195,
> 0.265025915, 1,1,1,1), tol = 9e-9)# 7.3e-10
> +     all.equal(d, dpois(x, mu))# current implementation: even identical()
> +     all.equal(p, ppois(x, mu))
> +     q == c(0, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6, 6, 6, 7, 8, 9, Inf)
> +     q == qpois(pp, mu)
> +     identical(NI, N2)
> + })
> Error: d and c(0.006737947, 0.033689735, 0.0842243375, 0.140373896, 0,
> 0,  .... are not equal:
>   'is.NA' value mismatch: 0 in current 1 in target
>
> > if(!(onWindows && arch == "x86")) {
> +  ## This gave a practically infinite loop (on 64-bit Lnx, Windows;
> not in 32-bit)
> +     tools::assertWarning(p <- pchisq(1.00000012e200, df=1e200, ncp=100),
> +                          "simpleWarning", verbose=TRUE)
> +     stopifnot(p == 1)
> + }
> Asserted warning: pnchisq(x=1e+200, f=1e+200, theta=100, ..): not
> converged in 1000000 iter.
>
> [This may be OK, AA]
>
> > ## Show the (mostly) small differences :
> > all.equal( qs, qpU, tol=0)
> [1] "Mean relative difference: 1.572997e-16"
> > all.equal(-qs, qp., tol=0)
> [1] "Mean relative difference: 1.572997e-16"
> > all.equal(-qp.,qpU, tol=0) # typically TRUE (<==> exact equality)
> [1] "Mean relative difference: 4.710277e-16"
> > stopifnot(exprs = {
> +     all.equal( qs,  qpU, tol=1e-15)
> +     all.equal(-qs,  qp., tol=1e-15)
> +     all.equal(-qp., qpU, tol=1e-15)# diff of 4.71e-16 in 4.1.0 w/icc
> (Eric Weese)
> + })
> > ## both failed very badly in  R <= 4.0.x
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From kev|nu@hey @end|ng |rom gm@||@com  Wed Nov 17 00:31:03 2021
From: kev|nu@hey @end|ng |rom gm@||@com (Kevin Ushey)
Date: Tue, 16 Nov 2021 15:31:03 -0800
Subject: [Rd] Inconsistent is.list results on 'by' objects
In-Reply-To: <CAHqSRuS1Mh3zM3FLYpeQGvHWqcL-uad+L4OQ4qNuCzw9mJ62yQ@mail.gmail.com>
References: <CAAR4qE9KQ_JY2AzQVGLYcxrobo9C3QD8jeRYG82Scc7k3Uu-5Q@mail.gmail.com>
 <CAHqSRuS1Mh3zM3FLYpeQGvHWqcL-uad+L4OQ4qNuCzw9mJ62yQ@mail.gmail.com>
Message-ID: <CAJXgQP15tETCqSfmxj-i9rZsXr9JbqPK+GS6oB1pZbBtjT2MmA@mail.gmail.com>

You can see this a bit more clearly with e.g.

> storage.mode(byy)
[1] "list"
> storage.mode(byy.empty)
[1] "logical"

So even though both objects have S3 class "by", they have a different
underlying internal storage mode (as simplifying the result of 'by'
has given you a 0-length logical, instead of a 0-length list).

Best,
Kevin

On Tue, Nov 16, 2021 at 10:21 AM Bill Dunlap <williamwdunlap at gmail.com> wrote:
>
> Try adding simplify=FALSE to the call to by().
>
> -Bill
>
> On Tue, Nov 16, 2021 at 4:04 AM Ofek Shilon <ofekshilon at gmail.com> wrote:
>
> > Take this toy code:
> > df       <- data.frame(a=seq(10), b=rep(1:2, 5))
> > df.empty <- subset(df, a>10)
> > byy       <- by(data=df,       INDICES=df$b, FUN=function(x) x[1,])
> > byy.empty <- by(data=df.empty, INDICES=df.empty$b, FUN=function(x) x[1,])
> >
> > class(byy)       # "by"
> > class(byy.empty) # "by"
> >
> > is.list(byy)        # TRUE
> > is.list(byy.empty)  # FALSE!
> >
> >
> > This behavior already messed up stuff elsewhere:
> > https://github.com/Rdatatable/data.table/issues/5258
> >
> > I'd say any questions about the class of an object (whether 'class' or
> > indirectly by 'is.**')
> > should not have the answers depend on the specific contents of the object.
> >
> > Does this qualify as an R bug? Am I missing something?
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From @vr@h@m@@d|er @end|ng |rom gm@||@com  Wed Nov 17 08:15:56 2021
From: @vr@h@m@@d|er @end|ng |rom gm@||@com (Avraham Adler)
Date: Wed, 17 Nov 2021 07:15:56 +0000
Subject: [Rd] R-devel (r81196) hanging at dchisq(large) (PR#13309)
In-Reply-To: <CAJXgQP1Hz2eKBObhGzgO6iEo0k3AJetWiii4t86Xu3Gvir+6nw@mail.gmail.com>
References: <CAL6gwn+-zy+RjX+toMptU6nyOc5bwQix4WDHbkgWAXwCTYEwqA@mail.gmail.com>
 <24979.28479.945404.466101@stat.math.ethz.ch>
 <CAL6gwnJuPnwS9GXvd0O80H3rRXxAUWrmUncOkrDECB2B+X-+8w@mail.gmail.com>
 <CAJXgQP1Hz2eKBObhGzgO6iEo0k3AJetWiii4t86Xu3Gvir+6nw@mail.gmail.com>
Message-ID: <CAL6gwnKMhbCZf7EnQ0pLKqxv5LSf1R=1zfLZXiZfitBPLsa_0Q@mail.gmail.com>

On Tue, Nov 16, 2021 at 10:42 PM Kevin Ushey <kevinushey at gmail.com> wrote:
>
> Do you see this same hang in a build of R with debug symbols? Can you
> try running R with GDB, or even WinDbg or another debugger, to see
> what the call stack looks like when the hang occurs? Does the hang
> depend on the number of threads used by OpenBLAS?
>
> On the off chance it's relevant, I've seen hangs / crashes when using
> a multithreaded OpenBLAS with R on some Linux systems before, but
> never found the time to isolate a root cause.
>


This last was a good thought, Kevin, as I had just compiled OpenBLAS
3.18 multi-threaded, but I recompiled it single threaded and it still
crashes. The version of R I built from source last time, (2021-05-20
r80347), does not hang when calling `dchisq(c(Inf, 1e80, 1e50, 1e40),
df=10, ncp=1)`. I think I built that with OpenBLAS 3.15. I can try
doing that here. As for building with debug symbols, I have never done
that before, so if you could provide some guidance (off-list if you
think it is inappropriate to keep it here) or point me in the
direction of some already posted advice, I would appreciate it!

Avi



> Best,
> Kevin
>
> On Tue, Nov 16, 2021 at 5:12 AM Avraham Adler <avraham.adler at gmail.com> wrote:
> >
> > On Tue, Nov 16, 2021 at 8:43 AM Martin Maechler
> > <maechler at stat.math.ethz.ch> wrote:
> > >
> > > >>>>> Avraham Adler
> > > >>>>>     on Tue, 16 Nov 2021 02:35:56 +0000 writes:
> > >
> > >     > I am building r-devel on Windows 10 64bit using Jeroen's mingw system,
> > >     > and I am finding that my make check-devel hangs on the above issue.
> > >     > Everything is vanila except that I am using OpenBLAS 0.3.18. I have
> > >     > been using OpenBLAS for over a decade and have not had this issue
> > >     > before. Is there anything I can do to dig deeper into this issue from
> > >     > my end? Could there be anything that changed in R-devel that may have
> > >     > triggered this? The bugzilla report doesn't have any code attached to
> > >     > it.
> > >
> > >     > Thank you,
> > >     > Avi
> > >
> > > Hmm.. it would've be nice to tell a bit more, instead of having all
> > > your readers to search links, etc.
> > >
> > > In the bugzilla bug report PR#13309
> > > https://bugs.r-project.org/show_bug.cgi?id=13309 ,the example was
> > >
> > >  dchisq(x=Inf, df=10, ncp=1)
> > >
> > > I had fixed the bug 13 years ago, in svn rev 47005
> > > with regression test in <Rsrc>/tests/d-p-q-r-tests.R :
> > >
> > >
> > > ## Non-central Chi^2 density for large x
> > > stopifnot(0 == dchisq(c(Inf, 1e80, 1e50, 1e40), df=10, ncp=1))
> > > ## did hang in 2.8.0 and earlier (PR#13309).
> > >
> > >
> > > and you are seeing your version of R hanging at exactly this
> > > location?
> > >
> > >
> > > I'd bet quite a bit that the underlying code in these
> > > non-central chi square computations *never* calls BLAS and hence
> > > I cannot imagine how openBLAS could play a role.
> > >
> > > However, there must be something peculiar in your compiler setup,
> > > compilation options, ....
> > > as of course the above regression test has been run 100s of
> > > 1000s of times also under Windows in the last 13 years ..
> > >
> > > Last but not least (but really only vaguely related):
> > >    There is still a FIXME in the source code (but not about
> > > hanging, but rather of loosing some accuracy in border cases),
> > > see e.g. https://svn.r-project.org/R/trunk/src/nmath/dnchisq.c
> > > and for that reason I had written an R version of that C code
> > > even back in 2008 which I've made available in  CRAN package
> > > DPQ  a few years ago (together with many other D/P/Q
> > > distribution computations/approximations).
> > >              -> https://cran.r-project.org/package=DPQ
> > >
> > > Best,
> > > Martin
> > >
> >
> > Hello, Martin.
> >
> > Apologies, I thought the PR # was sufficient. Yes, I am seeing this at
> > this exact location. This is what I saw in d-p-q-r-tst-2.Rout.fail and
> > I then ran d-p-q-r-tst.R line-by-line and R hung precisely after
> > `stopifnot(0 == dchisq(c(Inf, 1e80, 1e50, 1e40), df=10, ncp=1))`.
> >
> > Is it at all possible that this has to do with the recent change from
> > bd0 to ebd0 (PR #15628) [1]?
> >
> > For completeness, I ran all the code _beneath_ the call, and while
> > nothing else cause an infinite loop, I posted what I believe may be
> > unexpected results below,
> >
> > Thank you,
> >
> > Avi
> >
> > [1]: https://bugs.r-project.org/show_bug.cgi?id=15628
> >
> > > ## FIXME ?!:  MxM/2 seems +- ok ??
> > > (dLmM <- dnbinom(xL, mu = 1, size = MxM))  # all NaN but the last
> > Warning in dnbinom(xL, mu = 1, size = MxM) : NaNs produced
> >  [1] NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN
> > NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   0
> > > (dLpI <- dnbinom(xL, prob=1/2, size = Inf))#  ditto
> > Warning in dnbinom(xL, prob = 1/2, size = Inf) : NaNs produced
> >  [1] NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN
> > NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   0
> > > (dLpM <- dnbinom(xL, prob=1/2, size = MxM))#  ditto
> > Warning in dnbinom(xL, prob = 1/2, size = MxM) : NaNs produced
> >  [1] NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN
> > NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   0
> >
> > > d <- dnbinom(x,  mu = mu, size = Inf) # gave NaN (for 0 and L), now all 0
> > Warning in dnbinom(x, mu = mu, size = Inf) : NaNs produced
> > > p <- pnbinom(x,  mu = mu, size = Inf) # gave all NaN, now uses ppois(x, mu)
> > Warning in pnbinom(x, mu = mu, size = Inf) : NaNs produced
> >
> > > pp <- (0:16)/16
> > > q <- qnbinom(pp, mu = mu, size = Inf) # gave all NaN
> > > set.seed(1); NI <- rnbinom(32, mu = mu, size = Inf)# gave all NaN
> > > set.seed(1); N2 <- rnbinom(32, mu = mu, size = L  )
> > > stopifnot(exprs = {
> > +     all.equal(d, c(0.006737947, 0.033689735, 0.0842243375,
> > 0.140373896, 0,0,0,0), tol = 9e-9)# 7.6e-10
> > +     all.equal(p, c(0.006737947, 0.040427682, 0.1246520195,
> > 0.265025915, 1,1,1,1), tol = 9e-9)# 7.3e-10
> > +     all.equal(d, dpois(x, mu))# current implementation: even identical()
> > +     all.equal(p, ppois(x, mu))
> > +     q == c(0, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6, 6, 6, 7, 8, 9, Inf)
> > +     q == qpois(pp, mu)
> > +     identical(NI, N2)
> > + })
> > Error: d and c(0.006737947, 0.033689735, 0.0842243375, 0.140373896, 0,
> > 0,  .... are not equal:
> >   'is.NA' value mismatch: 0 in current 1 in target
> >
> > > if(!(onWindows && arch == "x86")) {
> > +  ## This gave a practically infinite loop (on 64-bit Lnx, Windows;
> > not in 32-bit)
> > +     tools::assertWarning(p <- pchisq(1.00000012e200, df=1e200, ncp=100),
> > +                          "simpleWarning", verbose=TRUE)
> > +     stopifnot(p == 1)
> > + }
> > Asserted warning: pnchisq(x=1e+200, f=1e+200, theta=100, ..): not
> > converged in 1000000 iter.
> >
> > [This may be OK, AA]
> >
> > > ## Show the (mostly) small differences :
> > > all.equal( qs, qpU, tol=0)
> > [1] "Mean relative difference: 1.572997e-16"
> > > all.equal(-qs, qp., tol=0)
> > [1] "Mean relative difference: 1.572997e-16"
> > > all.equal(-qp.,qpU, tol=0) # typically TRUE (<==> exact equality)
> > [1] "Mean relative difference: 4.710277e-16"
> > > stopifnot(exprs = {
> > +     all.equal( qs,  qpU, tol=1e-15)
> > +     all.equal(-qs,  qp., tol=1e-15)
> > +     all.equal(-qp., qpU, tol=1e-15)# diff of 4.71e-16 in 4.1.0 w/icc
> > (Eric Weese)
> > + })
> > > ## both failed very badly in  R <= 4.0.x
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel


From j@g@nmn2 @end|ng |rom gm@||@com  Wed Nov 17 06:13:57 2021
From: j@g@nmn2 @end|ng |rom gm@||@com (Mikael Jagan)
Date: Wed, 17 Nov 2021 00:13:57 -0500
Subject: [Rd] Subsetting "dspMatrix" without coercion to "matrix"
Message-ID: <559cc4d3-d729-8712-26d4-6e259de6e88d@gmail.com>

Currently, the class for dense symmetric matrices in packed storage, 
"dspMatrix", inherits its subset (i.e., `[`) methods from the "Matrix" 
class. As a result, subsetting "dspMatrix" requires coercion to 
"matrix". If memory cannot be allocated for this "matrix", then an error 
results.

n <- 30000L
x <- as.double(seq_len(choose(n + 1L, 2L)))
S <- new("dspMatrix", uplo = "L", x = x, Dim = c(n, n))

S[, 1L]
# Error: vector memory exhausted (limit reached?)

traceback()
# 10: .dsy2mat(dsp2dsy(from))
# 9: asMethod(object)
# 8: as(x, "matrix")
# 7: x[, j = j, drop = TRUE]
# 6: x[, j = j, drop = TRUE]
# 5: eval(call, parent.frame())
# 4: eval(call, parent.frame())
# 3: callGeneric(x, , j = j, drop = TRUE)
# 2: S[, 1L]
# 1: S[, 1L]

This seems entirely avoidable, given that there is a relatively simple 
formula for converting 2-ary indices [i,j] of S to 1-ary indices k of 
S[lower.tri(S, TRUE)]:

k <- i + round(0.5 * (2L * n - j) * (j - 1L)) # for i >= j

Has the implementation of `[` for class "dspMatrix" been discussed 
already elsewhere? If not, shall I report it to Bugzilla as a wishlist item?

FWIW, I encountered this problem while trying to coerce a large "dist" 
object to "dspMatrix", expecting that I would be able to safely subset 
the result:

setAs(from = "dist", to = "dspMatrix", function(from) {
   p <- length(from)
   if (p > 0L) {
     n <- as.integer(round(0.5 * (1 + sqrt(1 + 8 * p)))) # p = n*(n-1)/2
     x <- double(p + n)
     i <- 1L + c(0L, cumsum(n:2L))
     x[-i] <- from
   } else {
     n <- 1L
     x <- 0
   }
   new("dspMatrix", uplo = "L", x = x, Dim = c(n, n))
})

But that attempt failed for a entirely different reason. For large 
enough n, I would hit a memory limit at the line:

x[-i] <- from

So I guess my second question is: what is problematic about this 
benign-seeming subset-assignment?

Mikael


From Kurt@Horn|k @end|ng |rom wu@@c@@t  Wed Nov 17 13:51:17 2021
From: Kurt@Horn|k @end|ng |rom wu@@c@@t (Kurt Hornik)
Date: Wed, 17 Nov 2021 13:51:17 +0100
Subject: [Rd] LOGNAME env var in the check code
In-Reply-To: <CABtg=Kn59VtnH4pw2+JqYpO+K9BrBa0Ppuk3we3B4EqigMjG3g@mail.gmail.com>
References: <CABtg=Kn59VtnH4pw2+JqYpO+K9BrBa0Ppuk3we3B4EqigMjG3g@mail.gmail.com>
Message-ID: <24980.64197.146967.822849@hornik.net>

>>>>> G?bor Cs?rdi writes:

> While trying to reproduce a NOTE for
> * checking for new files in some other directories ... NOTE

> I noticed that the check code uses

> Sys.getenv("LOGNAME")

> to query the name of the current user. However on many systems this is
> not set, so this is the empty string, and then no NOTE is shown. (Only
> files owned by the current user generate a NOTE.)

> An alternative would be to call `id -un` to query the username, or
> create a file and then use `file.info()` to query its owner. Using one
> of these alternatives would make this check more reproducible.

Thanks, will try to get this improved (I like the "or" idea) ...

Best
-k

> Thanks,
> Gabor

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From o|ek@h||on @end|ng |rom gm@||@com  Wed Nov 17 15:42:13 2021
From: o|ek@h||on @end|ng |rom gm@||@com (Ofek Shilon)
Date: Wed, 17 Nov 2021 16:42:13 +0200
Subject: [Rd] Inconsistent is.list results on 'by' objects
In-Reply-To: <CAJXgQP15tETCqSfmxj-i9rZsXr9JbqPK+GS6oB1pZbBtjT2MmA@mail.gmail.com>
References: <CAAR4qE9KQ_JY2AzQVGLYcxrobo9C3QD8jeRYG82Scc7k3Uu-5Q@mail.gmail.com>
 <CAHqSRuS1Mh3zM3FLYpeQGvHWqcL-uad+L4OQ4qNuCzw9mJ62yQ@mail.gmail.com>
 <CAJXgQP15tETCqSfmxj-i9rZsXr9JbqPK+GS6oB1pZbBtjT2MmA@mail.gmail.com>
Message-ID: <CAAR4qE83pCWGGtD6myOUL7Qj8j=bh3jt5XG9SLB0zeGbP5PH+w@mail.gmail.com>

Thanks. 'by' is implemented by tapply, and it seems to behave rather
erratically for empty inputs:

> FUN = function(x) x[1,]
> FUNx <- function(x) FUN(df[x, , drop = FALSE])
> tapply(seq_len(10), df$b, FUNx) %>% storage.mode # array
> tapply(seq_len(0), c(), FUNx)   %>% storage.mode # logical
> tapply(seq_len(0), c(), NULL)   %>% storage.mode # integer

I think this warrants a fix, strictly in the tapply R code. WDYT?


On Wed, 17 Nov 2021 at 01:31, Kevin Ushey <kevinushey at gmail.com> wrote:

> You can see this a bit more clearly with e.g.
>
> > storage.mode(byy)
> [1] "list"
> > storage.mode(byy.empty)
> [1] "logical"
>
> So even though both objects have S3 class "by", they have a different
> underlying internal storage mode (as simplifying the result of 'by'
> has given you a 0-length logical, instead of a 0-length list).
>
> Best,
> Kevin
>
> On Tue, Nov 16, 2021 at 10:21 AM Bill Dunlap <williamwdunlap at gmail.com>
> wrote:
> >
> > Try adding simplify=FALSE to the call to by().
> >
> > -Bill
> >
> > On Tue, Nov 16, 2021 at 4:04 AM Ofek Shilon <ofekshilon at gmail.com>
> wrote:
> >
> > > Take this toy code:
> > > df       <- data.frame(a=seq(10), b=rep(1:2, 5))
> > > df.empty <- subset(df, a>10)
> > > byy       <- by(data=df,       INDICES=df$b, FUN=function(x) x[1,])
> > > byy.empty <- by(data=df.empty, INDICES=df.empty$b, FUN=function(x)
> x[1,])
> > >
> > > class(byy)       # "by"
> > > class(byy.empty) # "by"
> > >
> > > is.list(byy)        # TRUE
> > > is.list(byy.empty)  # FALSE!
> > >
> > >
> > > This behavior already messed up stuff elsewhere:
> > > https://github.com/Rdatatable/data.table/issues/5258
> > >
> > > I'd say any questions about the class of an object (whether 'class' or
> > > indirectly by 'is.**')
> > > should not have the answers depend on the specific contents of the
> object.
> > >
> > > Does this qualify as an R bug? Am I missing something?
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From c@@rd|@g@bor @end|ng |rom gm@||@com  Wed Nov 17 16:11:43 2021
From: c@@rd|@g@bor @end|ng |rom gm@||@com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Wed, 17 Nov 2021 16:11:43 +0100
Subject: [Rd] R-patched tarball at https://stat.ethz.ch/R/daily/ outdated
Message-ID: <CABtg=Kmfb+4r0_gVe2kG_YRuRhw4Z9KG6m4S99zN544m-gnYOQ@mail.gmail.com>

Hi all,

AFAICT https://stat.ethz.ch/R/daily/R-patched.tar.gz is still R 4.0.5 patched.

Probably needs a branch bump. FYI,
Gabor


From @vr@h@m@@d|er @end|ng |rom gm@||@com  Wed Nov 17 16:55:31 2021
From: @vr@h@m@@d|er @end|ng |rom gm@||@com (Avraham Adler)
Date: Wed, 17 Nov 2021 15:55:31 +0000
Subject: [Rd] R-devel (r81196) hanging at dchisq(large) (PR#13309)
In-Reply-To: <CAL6gwnKMhbCZf7EnQ0pLKqxv5LSf1R=1zfLZXiZfitBPLsa_0Q@mail.gmail.com>
References: <CAL6gwn+-zy+RjX+toMptU6nyOc5bwQix4WDHbkgWAXwCTYEwqA@mail.gmail.com>
 <24979.28479.945404.466101@stat.math.ethz.ch>
 <CAL6gwnJuPnwS9GXvd0O80H3rRXxAUWrmUncOkrDECB2B+X-+8w@mail.gmail.com>
 <CAJXgQP1Hz2eKBObhGzgO6iEo0k3AJetWiii4t86Xu3Gvir+6nw@mail.gmail.com>
 <CAL6gwnKMhbCZf7EnQ0pLKqxv5LSf1R=1zfLZXiZfitBPLsa_0Q@mail.gmail.com>
Message-ID: <CAL6gwnKG-vXqkfrnnbqbu2-VP_fPgVFX5yE5Svg0MNeYix_PQg@mail.gmail.com>

Hello, Martin et. al.

I apologize for top posting, but I believe I have tracked down the
difference why last time my build worked and now it hangs on
`dchisq(c(Inf, 1e80, 1e50, 1e40), df=10, ncp=1)`. and it's NOT the
BLAS. I built against both 3.15 AND R's vanilla and it hung both
times. The issue was passing "march=skylake". I own an i7-8700K which
gcc considers a skylake. When I pass mtune=skylake, it does not hang
and the make check-devel after the build completes.

Below is a list of the different flags passed when using mtune vs.
march. It stands to reason that at least one of them contributed to
the hanging issue which Martin fixed in
https://bugs.r-project.org/show_bug.cgi?id=13309. While I recognize
the obvious ones, I'm not an expert and do not understand which if any
may be the culprit. For reference, most of these flags are described
here: https://gcc.gnu.org/onlinedocs/gcc-8.3.0/gcc/x86-Options.html#x86-Options.

All the following flags are DISABLED for mtune=skylake (so
march=x86-64) and ENABLED when passing march-skylake. For the record,
I usually passed march in the past without problem:

madx, maes, mavx, mavx2, mbmi, mbmi2, mclflushopt, mcx16, mf16c, mfma,
mfsgsbase, mhle, mlzcnt, mmovbe, mpclmul, mpopcnt, mprfchw, mrdrnd,
mrdseed, msahf, msgx, msse3, msse4, msse4.1, msse4.2, mssse3, mxsave,
mxsavec, mxsaveopt, and mxsaves.

Inversely, mno-sse4 is enabled when using mtune and disabled when
using arch, of course.

For completeness, the following two are disabled on both mtune and
march but enabled when passing march=native, otherwise the latter is
the same as march=skylake: mabm and mrtm. Obviously these cannot
contribute to the hanging issue.

Any ideas, especially from the experts who understand how the flags
would address the code in dchisq, would be greatly appreciated.

Thank you,

Avi

On Wed, Nov 17, 2021 at 7:15 AM Avraham Adler <avraham.adler at gmail.com> wrote:
>
> On Tue, Nov 16, 2021 at 10:42 PM Kevin Ushey <kevinushey at gmail.com> wrote:
> >
> > Do you see this same hang in a build of R with debug symbols? Can you
> > try running R with GDB, or even WinDbg or another debugger, to see
> > what the call stack looks like when the hang occurs? Does the hang
> > depend on the number of threads used by OpenBLAS?
> >
> > On the off chance it's relevant, I've seen hangs / crashes when using
> > a multithreaded OpenBLAS with R on some Linux systems before, but
> > never found the time to isolate a root cause.
> >
>
>
> This last was a good thought, Kevin, as I had just compiled OpenBLAS
> 3.18 multi-threaded, but I recompiled it single threaded and it still
> crashes. The version of R I built from source last time, (2021-05-20
> r80347), does not hang when calling `dchisq(c(Inf, 1e80, 1e50, 1e40),
> df=10, ncp=1)`. I think I built that with OpenBLAS 3.15. I can try
> doing that here. As for building with debug symbols, I have never done
> that before, so if you could provide some guidance (off-list if you
> think it is inappropriate to keep it here) or point me in the
> direction of some already posted advice, I would appreciate it!
>
> Avi
>
>
>
> > Best,
> > Kevin
> >
> > On Tue, Nov 16, 2021 at 5:12 AM Avraham Adler <avraham.adler at gmail.com> wrote:
> > >
> > > On Tue, Nov 16, 2021 at 8:43 AM Martin Maechler
> > > <maechler at stat.math.ethz.ch> wrote:
> > > >
> > > > >>>>> Avraham Adler
> > > > >>>>>     on Tue, 16 Nov 2021 02:35:56 +0000 writes:
> > > >
> > > >     > I am building r-devel on Windows 10 64bit using Jeroen's mingw system,
> > > >     > and I am finding that my make check-devel hangs on the above issue.
> > > >     > Everything is vanila except that I am using OpenBLAS 0.3.18. I have
> > > >     > been using OpenBLAS for over a decade and have not had this issue
> > > >     > before. Is there anything I can do to dig deeper into this issue from
> > > >     > my end? Could there be anything that changed in R-devel that may have
> > > >     > triggered this? The bugzilla report doesn't have any code attached to
> > > >     > it.
> > > >
> > > >     > Thank you,
> > > >     > Avi
> > > >
> > > > Hmm.. it would've be nice to tell a bit more, instead of having all
> > > > your readers to search links, etc.
> > > >
> > > > In the bugzilla bug report PR#13309
> > > > https://bugs.r-project.org/show_bug.cgi?id=13309 ,the example was
> > > >
> > > >  dchisq(x=Inf, df=10, ncp=1)
> > > >
> > > > I had fixed the bug 13 years ago, in svn rev 47005
> > > > with regression test in <Rsrc>/tests/d-p-q-r-tests.R :
> > > >
> > > >
> > > > ## Non-central Chi^2 density for large x
> > > > stopifnot(0 == dchisq(c(Inf, 1e80, 1e50, 1e40), df=10, ncp=1))
> > > > ## did hang in 2.8.0 and earlier (PR#13309).
> > > >
> > > >
> > > > and you are seeing your version of R hanging at exactly this
> > > > location?
> > > >
> > > >
> > > > I'd bet quite a bit that the underlying code in these
> > > > non-central chi square computations *never* calls BLAS and hence
> > > > I cannot imagine how openBLAS could play a role.
> > > >
> > > > However, there must be something peculiar in your compiler setup,
> > > > compilation options, ....
> > > > as of course the above regression test has been run 100s of
> > > > 1000s of times also under Windows in the last 13 years ..
> > > >
> > > > Last but not least (but really only vaguely related):
> > > >    There is still a FIXME in the source code (but not about
> > > > hanging, but rather of loosing some accuracy in border cases),
> > > > see e.g. https://svn.r-project.org/R/trunk/src/nmath/dnchisq.c
> > > > and for that reason I had written an R version of that C code
> > > > even back in 2008 which I've made available in  CRAN package
> > > > DPQ  a few years ago (together with many other D/P/Q
> > > > distribution computations/approximations).
> > > >              -> https://cran.r-project.org/package=DPQ
> > > >
> > > > Best,
> > > > Martin
> > > >
> > >
> > > Hello, Martin.
> > >
> > > Apologies, I thought the PR # was sufficient. Yes, I am seeing this at
> > > this exact location. This is what I saw in d-p-q-r-tst-2.Rout.fail and
> > > I then ran d-p-q-r-tst.R line-by-line and R hung precisely after
> > > `stopifnot(0 == dchisq(c(Inf, 1e80, 1e50, 1e40), df=10, ncp=1))`.
> > >
> > > Is it at all possible that this has to do with the recent change from
> > > bd0 to ebd0 (PR #15628) [1]?
> > >
> > > For completeness, I ran all the code _beneath_ the call, and while
> > > nothing else cause an infinite loop, I posted what I believe may be
> > > unexpected results below,
> > >
> > > Thank you,
> > >
> > > Avi
> > >
> > > [1]: https://bugs.r-project.org/show_bug.cgi?id=15628
> > >
> > > > ## FIXME ?!:  MxM/2 seems +- ok ??
> > > > (dLmM <- dnbinom(xL, mu = 1, size = MxM))  # all NaN but the last
> > > Warning in dnbinom(xL, mu = 1, size = MxM) : NaNs produced
> > >  [1] NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN
> > > NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   0
> > > > (dLpI <- dnbinom(xL, prob=1/2, size = Inf))#  ditto
> > > Warning in dnbinom(xL, prob = 1/2, size = Inf) : NaNs produced
> > >  [1] NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN
> > > NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   0
> > > > (dLpM <- dnbinom(xL, prob=1/2, size = MxM))#  ditto
> > > Warning in dnbinom(xL, prob = 1/2, size = MxM) : NaNs produced
> > >  [1] NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN
> > > NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   0
> > >
> > > > d <- dnbinom(x,  mu = mu, size = Inf) # gave NaN (for 0 and L), now all 0
> > > Warning in dnbinom(x, mu = mu, size = Inf) : NaNs produced
> > > > p <- pnbinom(x,  mu = mu, size = Inf) # gave all NaN, now uses ppois(x, mu)
> > > Warning in pnbinom(x, mu = mu, size = Inf) : NaNs produced
> > >
> > > > pp <- (0:16)/16
> > > > q <- qnbinom(pp, mu = mu, size = Inf) # gave all NaN
> > > > set.seed(1); NI <- rnbinom(32, mu = mu, size = Inf)# gave all NaN
> > > > set.seed(1); N2 <- rnbinom(32, mu = mu, size = L  )
> > > > stopifnot(exprs = {
> > > +     all.equal(d, c(0.006737947, 0.033689735, 0.0842243375,
> > > 0.140373896, 0,0,0,0), tol = 9e-9)# 7.6e-10
> > > +     all.equal(p, c(0.006737947, 0.040427682, 0.1246520195,
> > > 0.265025915, 1,1,1,1), tol = 9e-9)# 7.3e-10
> > > +     all.equal(d, dpois(x, mu))# current implementation: even identical()
> > > +     all.equal(p, ppois(x, mu))
> > > +     q == c(0, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6, 6, 6, 7, 8, 9, Inf)
> > > +     q == qpois(pp, mu)
> > > +     identical(NI, N2)
> > > + })
> > > Error: d and c(0.006737947, 0.033689735, 0.0842243375, 0.140373896, 0,
> > > 0,  .... are not equal:
> > >   'is.NA' value mismatch: 0 in current 1 in target
> > >
> > > > if(!(onWindows && arch == "x86")) {
> > > +  ## This gave a practically infinite loop (on 64-bit Lnx, Windows;
> > > not in 32-bit)
> > > +     tools::assertWarning(p <- pchisq(1.00000012e200, df=1e200, ncp=100),
> > > +                          "simpleWarning", verbose=TRUE)
> > > +     stopifnot(p == 1)
> > > + }
> > > Asserted warning: pnchisq(x=1e+200, f=1e+200, theta=100, ..): not
> > > converged in 1000000 iter.
> > >
> > > [This may be OK, AA]
> > >
> > > > ## Show the (mostly) small differences :
> > > > all.equal( qs, qpU, tol=0)
> > > [1] "Mean relative difference: 1.572997e-16"
> > > > all.equal(-qs, qp., tol=0)
> > > [1] "Mean relative difference: 1.572997e-16"
> > > > all.equal(-qp.,qpU, tol=0) # typically TRUE (<==> exact equality)
> > > [1] "Mean relative difference: 4.710277e-16"
> > > > stopifnot(exprs = {
> > > +     all.equal( qs,  qpU, tol=1e-15)
> > > +     all.equal(-qs,  qp., tol=1e-15)
> > > +     all.equal(-qp., qpU, tol=1e-15)# diff of 4.71e-16 in 4.1.0 w/icc
> > > (Eric Weese)
> > > + })
> > > > ## both failed very badly in  R <= 4.0.x
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel


From j@g@nmn2 @end|ng |rom gm@||@com  Wed Nov 17 23:01:00 2021
From: j@g@nmn2 @end|ng |rom gm@||@com (Mikael Jagan)
Date: Wed, 17 Nov 2021 17:01:00 -0500
Subject: [Rd] Subsetting "dspMatrix" without coercion to "matrix"
In-Reply-To: <559cc4d3-d729-8712-26d4-6e259de6e88d@gmail.com>
References: <559cc4d3-d729-8712-26d4-6e259de6e88d@gmail.com>
Message-ID: <81f4217f-12f8-cb51-9333-61118a3ee72f@gmail.com>

> This seems entirely avoidable, given that there is a relatively simple 
> formula for converting 2-ary indices [i,j] of S to 1-ary indices k of 
> S[lower.tri(S, TRUE)]:
> 
> k <- i + round(0.5 * (2L * n - j) * (j - 1L)) # for i >= j

I ought to be slightly more precise here: _coercion_ is avoidable, 
because we can always map [i,j] to [k], but memory limits are not. 
Certainly S at x[k] cannot be arbitrarily long...

At the very least, it would be convenient if the subset were performed 
efficiently whenever dimensions would be dropped anyway:

* S[i, ] and S[, j] where i and j are vectors indexing exactly zero or 
one rows/columns
* S[i] where i is a matrix of the form cbind(i, j)

This would support, e.g., a memory-efficient 'apply' analogue without 
any need for MARGIN...

applySymmetric <- function(X, FUN, ..., simplify = TRUE, check = TRUE) {
   if (check && !isSymmetric(X)) {
     stop("'X' is not a symmetric matrix.")
   }
   ## preprocessing
   ans <- vector("list", n)
   for (i in seq_len(n)) {
     ans[[i]] <- forceAndCall(1L, FUN, S[i, ], ...)
   }
   ## postprocessing
   ans
}


From @vr@h@m@@d|er @end|ng |rom gm@||@com  Thu Nov 18 03:18:54 2021
From: @vr@h@m@@d|er @end|ng |rom gm@||@com (Avraham Adler)
Date: Thu, 18 Nov 2021 02:18:54 +0000
Subject: [Rd] R-devel (r81196) hanging at dchisq(large) (PR#13309)
In-Reply-To: <CAL6gwnKG-vXqkfrnnbqbu2-VP_fPgVFX5yE5Svg0MNeYix_PQg@mail.gmail.com>
References: <CAL6gwn+-zy+RjX+toMptU6nyOc5bwQix4WDHbkgWAXwCTYEwqA@mail.gmail.com>
 <24979.28479.945404.466101@stat.math.ethz.ch>
 <CAL6gwnJuPnwS9GXvd0O80H3rRXxAUWrmUncOkrDECB2B+X-+8w@mail.gmail.com>
 <CAJXgQP1Hz2eKBObhGzgO6iEo0k3AJetWiii4t86Xu3Gvir+6nw@mail.gmail.com>
 <CAL6gwnKMhbCZf7EnQ0pLKqxv5LSf1R=1zfLZXiZfitBPLsa_0Q@mail.gmail.com>
 <CAL6gwnKG-vXqkfrnnbqbu2-VP_fPgVFX5yE5Svg0MNeYix_PQg@mail.gmail.com>
Message-ID: <CAL6gwnLEKoAmzuaFFV0vo_XGOt6gnStnP=00ojHLNv4WYHvGHA@mail.gmail.com>

Hello.

I have isolated the issue: it is the fused-multiply-add instruction
set (FMA on Intel processors). Running -march=skylake -mno-fma not
only does not hang, but passes make check-all (using R's native BLAS).
My intuition remains that something in the new more precise ebd0 code
used in dpois_raw?called by dgamma, called by dchsq, called by
dnchisq?is hanging when the assembler uses FMA. Unfortunately, I have
come across other cases online where the extra precision and the
different assembler code of FMA vs. non-FMA has caused bugs, such as
[1]. Page 5 of this paper by Dr. William Kahan sheds some light on why
this may be happening [2] (PDF).

Martin & Morton, having written (PR#15628 [3]) and/or implemented the
ebd0 code that is now being used, can either of you think of any
reason why it would hang if compiled using FMA? Again, I'm not a
professional, but line 325 of the ebd0 function in bd0.c [4] has
"ADD1(-x * log1pmx ((M * fg - x) / x))" which looks like a
Multiply-Add to me, at least in the inner parenthesis. Is there
anything that can be, or should be, done with the code to prevent the
hang, or must we forbid the use of FMA instructions (and I guess FMA4
on AMD processors) when compiling R?

Also, What happens in the case where M/x neither over- nor
under-flowed, M_LN2 * ((double) -e) <= 1. + DBL_MAX / x, fg != 1, and
after 4 loops of lines 329 & 330, *yh is still finite? How does ebd0
exit in that case? There is no "return" after line 331. Am I missing
something? Could that be related to this issue?

As an aside, could ebd0 be enhanced by using FMA instructions on
processors which support them?

Thank you very much,

Avi

[1] https://flameeyes.blog/2014/10/27/the-subtlety-of-modern-cpus-or-the-search-for-the-phantom-bug/
[2] https://people.eecs.berkeley.edu/~wkahan/ieee754status/IEEE754.PDF
[3] https://bugs.r-project.org/show_bug.cgi?id=15628
[4] https://github.com/wch/r-source/blob/trunk/src/nmath/bd0.c

On Wed, Nov 17, 2021 at 3:55 PM Avraham Adler <avraham.adler at gmail.com> wrote:
>
> Hello, Martin et. al.
>
> I apologize for top posting, but I believe I have tracked down the
> difference why last time my build worked and now it hangs on
> `dchisq(c(Inf, 1e80, 1e50, 1e40), df=10, ncp=1)`. and it's NOT the
> BLAS. I built against both 3.15 AND R's vanilla and it hung both
> times. The issue was passing "march=skylake". I own an i7-8700K which
> gcc considers a skylake. When I pass mtune=skylake, it does not hang
> and the make check-devel after the build completes.
>
> Below is a list of the different flags passed when using mtune vs.
> march. It stands to reason that at least one of them contributed to
> the hanging issue which Martin fixed in
> https://bugs.r-project.org/show_bug.cgi?id=13309. While I recognize
> the obvious ones, I'm not an expert and do not understand which if any
> may be the culprit. For reference, most of these flags are described
> here: https://gcc.gnu.org/onlinedocs/gcc-8.3.0/gcc/x86-Options.html#x86-Options.
>
> All the following flags are DISABLED for mtune=skylake (so
> march=x86-64) and ENABLED when passing march-skylake. For the record,
> I usually passed march in the past without problem:
>
> madx, maes, mavx, mavx2, mbmi, mbmi2, mclflushopt, mcx16, mf16c, mfma,
> mfsgsbase, mhle, mlzcnt, mmovbe, mpclmul, mpopcnt, mprfchw, mrdrnd,
> mrdseed, msahf, msgx, msse3, msse4, msse4.1, msse4.2, mssse3, mxsave,
> mxsavec, mxsaveopt, and mxsaves.
>
> Inversely, mno-sse4 is enabled when using mtune and disabled when
> using arch, of course.
>
> For completeness, the following two are disabled on both mtune and
> march but enabled when passing march=native, otherwise the latter is
> the same as march=skylake: mabm and mrtm. Obviously these cannot
> contribute to the hanging issue.
>
> Any ideas, especially from the experts who understand how the flags
> would address the code in dchisq, would be greatly appreciated.
>
> Thank you,
>
> Avi
>
> On Wed, Nov 17, 2021 at 7:15 AM Avraham Adler <avraham.adler at gmail.com> wrote:
> >
> > On Tue, Nov 16, 2021 at 10:42 PM Kevin Ushey <kevinushey at gmail.com> wrote:
> > >
> > > Do you see this same hang in a build of R with debug symbols? Can you
> > > try running R with GDB, or even WinDbg or another debugger, to see
> > > what the call stack looks like when the hang occurs? Does the hang
> > > depend on the number of threads used by OpenBLAS?
> > >
> > > On the off chance it's relevant, I've seen hangs / crashes when using
> > > a multithreaded OpenBLAS with R on some Linux systems before, but
> > > never found the time to isolate a root cause.
> > >
> >
> >
> > This last was a good thought, Kevin, as I had just compiled OpenBLAS
> > 3.18 multi-threaded, but I recompiled it single threaded and it still
> > crashes. The version of R I built from source last time, (2021-05-20
> > r80347), does not hang when calling `dchisq(c(Inf, 1e80, 1e50, 1e40),
> > df=10, ncp=1)`. I think I built that with OpenBLAS 3.15. I can try
> > doing that here. As for building with debug symbols, I have never done
> > that before, so if you could provide some guidance (off-list if you
> > think it is inappropriate to keep it here) or point me in the
> > direction of some already posted advice, I would appreciate it!
> >
> > Avi
> >
> >
> >
> > > Best,
> > > Kevin
> > >
> > > On Tue, Nov 16, 2021 at 5:12 AM Avraham Adler <avraham.adler at gmail.com> wrote:
> > > >
> > > > On Tue, Nov 16, 2021 at 8:43 AM Martin Maechler
> > > > <maechler at stat.math.ethz.ch> wrote:
> > > > >
> > > > > >>>>> Avraham Adler
> > > > > >>>>>     on Tue, 16 Nov 2021 02:35:56 +0000 writes:
> > > > >
> > > > >     > I am building r-devel on Windows 10 64bit using Jeroen's mingw system,
> > > > >     > and I am finding that my make check-devel hangs on the above issue.
> > > > >     > Everything is vanila except that I am using OpenBLAS 0.3.18. I have
> > > > >     > been using OpenBLAS for over a decade and have not had this issue
> > > > >     > before. Is there anything I can do to dig deeper into this issue from
> > > > >     > my end? Could there be anything that changed in R-devel that may have
> > > > >     > triggered this? The bugzilla report doesn't have any code attached to
> > > > >     > it.
> > > > >
> > > > >     > Thank you,
> > > > >     > Avi
> > > > >
> > > > > Hmm.. it would've be nice to tell a bit more, instead of having all
> > > > > your readers to search links, etc.
> > > > >
> > > > > In the bugzilla bug report PR#13309
> > > > > https://bugs.r-project.org/show_bug.cgi?id=13309 ,the example was
> > > > >
> > > > >  dchisq(x=Inf, df=10, ncp=1)
> > > > >
> > > > > I had fixed the bug 13 years ago, in svn rev 47005
> > > > > with regression test in <Rsrc>/tests/d-p-q-r-tests.R :
> > > > >
> > > > >
> > > > > ## Non-central Chi^2 density for large x
> > > > > stopifnot(0 == dchisq(c(Inf, 1e80, 1e50, 1e40), df=10, ncp=1))
> > > > > ## did hang in 2.8.0 and earlier (PR#13309).
> > > > >
> > > > >
> > > > > and you are seeing your version of R hanging at exactly this
> > > > > location?
> > > > >
> > > > >
> > > > > I'd bet quite a bit that the underlying code in these
> > > > > non-central chi square computations *never* calls BLAS and hence
> > > > > I cannot imagine how openBLAS could play a role.
> > > > >
> > > > > However, there must be something peculiar in your compiler setup,
> > > > > compilation options, ....
> > > > > as of course the above regression test has been run 100s of
> > > > > 1000s of times also under Windows in the last 13 years ..
> > > > >
> > > > > Last but not least (but really only vaguely related):
> > > > >    There is still a FIXME in the source code (but not about
> > > > > hanging, but rather of loosing some accuracy in border cases),
> > > > > see e.g. https://svn.r-project.org/R/trunk/src/nmath/dnchisq.c
> > > > > and for that reason I had written an R version of that C code
> > > > > even back in 2008 which I've made available in  CRAN package
> > > > > DPQ  a few years ago (together with many other D/P/Q
> > > > > distribution computations/approximations).
> > > > >              -> https://cran.r-project.org/package=DPQ
> > > > >
> > > > > Best,
> > > > > Martin
> > > > >
> > > >
> > > > Hello, Martin.
> > > >
> > > > Apologies, I thought the PR # was sufficient. Yes, I am seeing this at
> > > > this exact location. This is what I saw in d-p-q-r-tst-2.Rout.fail and
> > > > I then ran d-p-q-r-tst.R line-by-line and R hung precisely after
> > > > `stopifnot(0 == dchisq(c(Inf, 1e80, 1e50, 1e40), df=10, ncp=1))`.
> > > >
> > > > Is it at all possible that this has to do with the recent change from
> > > > bd0 to ebd0 (PR #15628) [1]?
> > > >
> > > > For completeness, I ran all the code _beneath_ the call, and while
> > > > nothing else cause an infinite loop, I posted what I believe may be
> > > > unexpected results below,
> > > >
> > > > Thank you,
> > > >
> > > > Avi
> > > >
> > > > [1]: https://bugs.r-project.org/show_bug.cgi?id=15628
> > > >
> > > > > ## FIXME ?!:  MxM/2 seems +- ok ??
> > > > > (dLmM <- dnbinom(xL, mu = 1, size = MxM))  # all NaN but the last
> > > > Warning in dnbinom(xL, mu = 1, size = MxM) : NaNs produced
> > > >  [1] NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN
> > > > NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   0
> > > > > (dLpI <- dnbinom(xL, prob=1/2, size = Inf))#  ditto
> > > > Warning in dnbinom(xL, prob = 1/2, size = Inf) : NaNs produced
> > > >  [1] NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN
> > > > NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   0
> > > > > (dLpM <- dnbinom(xL, prob=1/2, size = MxM))#  ditto
> > > > Warning in dnbinom(xL, prob = 1/2, size = MxM) : NaNs produced
> > > >  [1] NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN
> > > > NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN   0
> > > >
> > > > > d <- dnbinom(x,  mu = mu, size = Inf) # gave NaN (for 0 and L), now all 0
> > > > Warning in dnbinom(x, mu = mu, size = Inf) : NaNs produced
> > > > > p <- pnbinom(x,  mu = mu, size = Inf) # gave all NaN, now uses ppois(x, mu)
> > > > Warning in pnbinom(x, mu = mu, size = Inf) : NaNs produced
> > > >
> > > > > pp <- (0:16)/16
> > > > > q <- qnbinom(pp, mu = mu, size = Inf) # gave all NaN
> > > > > set.seed(1); NI <- rnbinom(32, mu = mu, size = Inf)# gave all NaN
> > > > > set.seed(1); N2 <- rnbinom(32, mu = mu, size = L  )
> > > > > stopifnot(exprs = {
> > > > +     all.equal(d, c(0.006737947, 0.033689735, 0.0842243375,
> > > > 0.140373896, 0,0,0,0), tol = 9e-9)# 7.6e-10
> > > > +     all.equal(p, c(0.006737947, 0.040427682, 0.1246520195,
> > > > 0.265025915, 1,1,1,1), tol = 9e-9)# 7.3e-10
> > > > +     all.equal(d, dpois(x, mu))# current implementation: even identical()
> > > > +     all.equal(p, ppois(x, mu))
> > > > +     q == c(0, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6, 6, 6, 7, 8, 9, Inf)
> > > > +     q == qpois(pp, mu)
> > > > +     identical(NI, N2)
> > > > + })
> > > > Error: d and c(0.006737947, 0.033689735, 0.0842243375, 0.140373896, 0,
> > > > 0,  .... are not equal:
> > > >   'is.NA' value mismatch: 0 in current 1 in target
> > > >
> > > > > if(!(onWindows && arch == "x86")) {
> > > > +  ## This gave a practically infinite loop (on 64-bit Lnx, Windows;
> > > > not in 32-bit)
> > > > +     tools::assertWarning(p <- pchisq(1.00000012e200, df=1e200, ncp=100),
> > > > +                          "simpleWarning", verbose=TRUE)
> > > > +     stopifnot(p == 1)
> > > > + }
> > > > Asserted warning: pnchisq(x=1e+200, f=1e+200, theta=100, ..): not
> > > > converged in 1000000 iter.
> > > >
> > > > [This may be OK, AA]
> > > >
> > > > > ## Show the (mostly) small differences :
> > > > > all.equal( qs, qpU, tol=0)
> > > > [1] "Mean relative difference: 1.572997e-16"
> > > > > all.equal(-qs, qp., tol=0)
> > > > [1] "Mean relative difference: 1.572997e-16"
> > > > > all.equal(-qp.,qpU, tol=0) # typically TRUE (<==> exact equality)
> > > > [1] "Mean relative difference: 4.710277e-16"
> > > > > stopifnot(exprs = {
> > > > +     all.equal( qs,  qpU, tol=1e-15)
> > > > +     all.equal(-qs,  qp., tol=1e-15)
> > > > +     all.equal(-qp., qpU, tol=1e-15)# diff of 4.71e-16 in 4.1.0 w/icc
> > > > (Eric Weese)
> > > > + })
> > > > > ## both failed very badly in  R <= 4.0.x
> > > >
> > > > ______________________________________________
> > > > R-devel at r-project.org mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-devel


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Thu Nov 18 14:41:11 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 18 Nov 2021 14:41:11 +0100
Subject: [Rd] 
 R-patched tarball at https://stat.ethz.ch/R/daily/ outdated
In-Reply-To: <CABtg=Kmfb+4r0_gVe2kG_YRuRhw4Z9KG6m4S99zN544m-gnYOQ@mail.gmail.com>
References: <CABtg=Kmfb+4r0_gVe2kG_YRuRhw4Z9KG6m4S99zN544m-gnYOQ@mail.gmail.com>
Message-ID: <24982.22519.255119.220007@stat.math.ethz.ch>

>>>>> G?bor Cs?rdi 
>>>>>     on Wed, 17 Nov 2021 16:11:43 +0100 writes:

    > Hi all,

    > AFAICT https://stat.ethz.ch/R/daily/R-patched.tar.gz is
    > still R 4.0.5 patched.

    > Probably needs a branch bump. FYI, Gabor

Yes; this has been an oversight by me (back in March).
It's amazing nobody has seen the issue till now.
I've fixed it a bit more than 3 hours ago.

Thank you, G?bor !

Martin

--
Martin Maechler, ETH Zurich and R Core team


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Thu Nov 18 15:01:36 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 18 Nov 2021 15:01:36 +0100
Subject: [Rd] substitute
In-Reply-To: <cc022730-3c10-07db-deef-5c78c838ef46@gmail.com>
References: <CAJ=0CtB4wmXm5sgDk=TP0Cp=zGRfvxLt-XY02adTXT5z7W3_sg@mail.gmail.com>
 <b07eaaab-bd67-164f-cdcc-f40367511b4b@gmail.com>
 <CAJ=0CtDbAZ+MY4oFmYo4BFXB4OEpp4p_YUpdxeNywGxOQ6ihqg@mail.gmail.com>
 <cc022730-3c10-07db-deef-5c78c838ef46@gmail.com>
Message-ID: <24982.23744.364312.479581@stat.math.ethz.ch>

>>>>> Duncan Murdoch 
>>>>>     on Mon, 15 Nov 2021 13:06:23 -0500 writes:

    > I'd recommend responding now with a pointer to that bug
    > report: whoever at CRAN is dealing with your package
    > doesn't necessarily know about the bug report.  You might
    > or might not need to make a change in the end, but if you
    > do, it could be hard to meet the two week deadline.

    > Duncan Murdoch

With thanks to Duncan and Adrian:

Just in case, Adrian  hasn't been following R's bugzilla PR#18232
i.e.  https://bugs.r-project.org/show_bug.cgi?id=18232

There have been extra patches to fix more cases of deparsing
while being more back compatible than what's been in R-devel for
a couple of days.

Notably the changes do revert to previous behavior for the
example you give;  and indeed QCA  passes its own checks again,
after applying the patches.

The changes are under review currently, but the plan is to
commit the changes within a few days.
(read on)

    > On 15/11/2021 12:58 p.m., Adrian Du?a wrote:
    >> Thank you, I was given a deadline of two weeks to
    >> respond, hopefully this will be settled by then.  Best
    >> wishes, Adrian
    >> 
    >> On Mon, 15 Nov 2021 at 19:28, Duncan Murdoch
    >> <murdoch.duncan at gmail.com
    >> <mailto:murdoch.duncan at gmail.com>> wrote:
    >> 
    >> This looks as though it is related to the recent patch in
    >> 
    >> https://bugs.r-project.org/show_bug.cgi?id=18232
    >> <https://bugs.r-project.org/show_bug.cgi?id=18232>
    >> 
    >> I think you should probably wait until that settles down
    >> before worrying about it.
    >> 
    >> Duncan Murdoch
    >> 
    >> On 15/11/2021 12:18 p.m., Adrian Du?a wrote: > Dear R
    >> wizards,
    >> >
    >> > I have recently been informed about some build errors
    >> of my package QCA, > which I was able to trace down to
    >> the base function substitute(), with the > following
    >> replication example:

	foo <- function(x) return(substitute(x))

	## In the stable R version 4.0.5, I get the expected result:

	foo(A + ~B + C~D)
	## A + ~B + C ~ D

BTW: no need for foo()  {and even less for a return(.) in a 1-liner !}

Be assured that we agree that

    quote(A + ~B + C~D)

should not "gain" any parentheses, indeed, and what you've been
seeing can well be considered an intermediate step in iterations
to get to improved deparsing in subtle situations.


Thank you for the report, and best regards,
Martin


From henr|k@bengt@@on @end|ng |rom gm@||@com  Thu Nov 18 18:43:29 2021
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Thu, 18 Nov 2021 09:43:29 -0800
Subject: [Rd] DOCS: Exactly when, in the signaling process,
 is option 'warn' applied?
Message-ID: <CAFDcVCRgODxrxF-2zNW-td_2PuaA6cmHSjLNOhjy9WTnf5U79Q@mail.gmail.com>

Hi,

the following question sprung out of a package settings option warn=-1
to silence warnings, but those warnings were still caught by
withCallingHandlers(..., warning), which the package author did not
anticipate. The package has been updated to use suppressWarnings()
instead, but as I see a lot of packages on CRAN [1] use
options(warn=-1) to temporarily silence warnings, I wanted to bring
this one up. Even base R itself [2] does this, e.g.
utils::assignInMyNamespace().

Exactly when is the value of 'warn' options used when calling warning("boom")?

I think the docs, including ?options, would benefit from clarifying
that. To the best of my understanding, it should also mention that
options 'warn' is meant to be used by end-users, and not in package
code where suppressWarnings() should be used.

To clarify, if we do:

> options(warn = -1)
> tryCatch(warning("boom"), warning = function(w) stop("Caught warning: ", conditionMessage(w), call. = FALSE))
Error: Caught warning: boom

we see that the warning is indeed signaled.  However, in Section '8.2
warning' of the 'R Language Definition' [3], we can read:

"The function `warning` takes a single argument that is a character
string. The behaviour of a call to `warning` depends on the value of
the option `"warn"`. If `"warn"` is negative warnings are ignored.
[...]"

The way this is written, it may suggest that warnings are
ignored/silences already early on when calling warning(), but the
above example shows that that is not the case.

>From the same section, we can also read:

"[...] If it is zero, they are stored and printed after the top-level
function has completed. [...]"

which may hint at the 'warn' option is applied only when a warning
condition is allowed to "bubble up" all the way to the top level.
(FWIW, this is how always though it worked, but it's only now I looked
into the docs and see it's ambiguous on this).

/Henrik

[1] https://github.com/search?q=org%3Acran+language%3Ar+R%2F+in%3Afile%2Cpath+options+warn+%22-1%22&type=Code
[2] https://github.com/wch/r-source/blob/0a31ab2d1df247a4289efca5a235dc45b511d04a/src/library/utils/R/objects.R#L402-L405
[3] https://cran.r-project.org/doc/manuals/R-lang.html#warning


From iuke-tier@ey m@iii@g oii uiow@@edu  Thu Nov 18 19:22:34 2021
From: iuke-tier@ey m@iii@g oii uiow@@edu (iuke-tier@ey m@iii@g oii uiow@@edu)
Date: Thu, 18 Nov 2021 12:22:34 -0600 (CST)
Subject: [Rd] [External]  DOCS: Exactly when, in the signaling process,
 is option 'warn' applied?
In-Reply-To: <CAFDcVCRgODxrxF-2zNW-td_2PuaA6cmHSjLNOhjy9WTnf5U79Q@mail.gmail.com>
References: <CAFDcVCRgODxrxF-2zNW-td_2PuaA6cmHSjLNOhjy9WTnf5U79Q@mail.gmail.com>
Message-ID: <alpine.DEB.2.22.394.2111181220591.2838@luke-Latitude-7480>

On Thu, 18 Nov 2021, Henrik Bengtsson wrote:

> Hi,
>
> the following question sprung out of a package settings option warn=-1
> to silence warnings, but those warnings were still caught by
> withCallingHandlers(..., warning), which the package author did not
> anticipate. The package has been updated to use suppressWarnings()
> instead, but as I see a lot of packages on CRAN [1] use
> options(warn=-1) to temporarily silence warnings, I wanted to bring
> this one up. Even base R itself [2] does this, e.g.
> utils::assignInMyNamespace().
>
> Exactly when is the value of 'warn' options used when calling warning("boom")?
>

In the default handler; it doesn't affect signaling.

Much of the documentation pre-dates the condition system; happy to
consider patches.

Best,

luke

> I think the docs, including ?options, would benefit from clarifying
> that. To the best of my understanding, it should also mention that
> options 'warn' is meant to be used by end-users, and not in package
> code where suppressWarnings() should be used.
>
> To clarify, if we do:
>
>> options(warn = -1)
>> tryCatch(warning("boom"), warning = function(w) stop("Caught warning: ", conditionMessage(w), call. = FALSE))
> Error: Caught warning: boom
>
> we see that the warning is indeed signaled.  However, in Section '8.2
> warning' of the 'R Language Definition' [3], we can read:
>
> "The function `warning` takes a single argument that is a character
> string. The behaviour of a call to `warning` depends on the value of
> the option `"warn"`. If `"warn"` is negative warnings are ignored.
> [...]"
>
> The way this is written, it may suggest that warnings are
> ignored/silences already early on when calling warning(), but the
> above example shows that that is not the case.
>
> From the same section, we can also read:
>
> "[...] If it is zero, they are stored and printed after the top-level
> function has completed. [...]"
>
> which may hint at the 'warn' option is applied only when a warning
> condition is allowed to "bubble up" all the way to the top level.
> (FWIW, this is how always though it worked, but it's only now I looked
> into the docs and see it's ambiguous on this).
>
> /Henrik
>
> [1] https://github.com/search?q=org%3Acran+language%3Ar+R%2F+in%3Afile%2Cpath+options+warn+%22-1%22&type=Code
> [2] https://github.com/wch/r-source/blob/0a31ab2d1df247a4289efca5a235dc45b511d04a/src/library/utils/R/objects.R#L402-L405
> [3] https://cran.r-project.org/doc/manuals/R-lang.html#warning
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From Kurt@Horn|k @end|ng |rom wu@@c@@t  Thu Nov 18 21:25:34 2021
From: Kurt@Horn|k @end|ng |rom wu@@c@@t (Kurt Hornik)
Date: Thu, 18 Nov 2021 21:25:34 +0100
Subject: [Rd] LOGNAME env var in the check code
In-Reply-To: <CABtg=Kn59VtnH4pw2+JqYpO+K9BrBa0Ppuk3we3B4EqigMjG3g@mail.gmail.com>
References: <CABtg=Kn59VtnH4pw2+JqYpO+K9BrBa0Ppuk3we3B4EqigMjG3g@mail.gmail.com>
Message-ID: <24982.46782.138846.488506@hornik.net>

>>>>> G?bor Cs?rdi writes:

Thanks.  c81206 changes to use 

  user <- Sys.info()[["effective_user"]]

which afawct should always give the same  as the uname for files created
by the current user.  Pls check: if not, we can go for something like

foo <- function() {
    writeLines("ABC", tf <- tempfile())
    on.exit(unlink(tf))
    file.info(tf)$uname
}

Best
-k


> While trying to reproduce a NOTE for
> * checking for new files in some other directories ... NOTE

> I noticed that the check code uses

> Sys.getenv("LOGNAME")

> to query the name of the current user. However on many systems this is
> not set, so this is the empty string, and then no NOTE is shown. (Only
> files owned by the current user generate a NOTE.)

> An alternative would be to call `id -un` to query the username, or
> create a file and then use `file.info()` to query its owner. Using one
> of these alternatives would make this check more reproducible.

> Thanks,
> Gabor

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Thom@@@SOEIRO @end|ng |rom @p-hm@|r  Fri Nov 19 16:23:36 2021
From: Thom@@@SOEIRO @end|ng |rom @p-hm@|r (SOEIRO Thomas)
Date: Fri, 19 Nov 2021 15:23:36 +0000
Subject: [Rd] documentation of asplit
Message-ID: <14cd7dda14694be2b32fc3cb77def786@SCWPR-EXDAG1-6A.aphm.ap-hm.fr>

Dear list,

The documentation of `asplit` currently says (section Details): "apply *always* simplifies common length results, so attempting to split via apply(x, MARGIN, identity) does not work (as it simply gives x)."

This may be updated (e.g., by simply removing "always") since `apply` recently gained a `simplify` argument.

Best,

Thomas


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Sun Nov 21 22:43:02 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Sun, 21 Nov 2021 22:43:02 +0100
Subject: [Rd] Subsetting "dspMatrix" without coercion to "matrix"
In-Reply-To: <81f4217f-12f8-cb51-9333-61118a3ee72f@gmail.com>
References: <559cc4d3-d729-8712-26d4-6e259de6e88d@gmail.com>
 <81f4217f-12f8-cb51-9333-61118a3ee72f@gmail.com>
Message-ID: <24986.48486.167744.49214@stat.math.ethz.ch>

>>>>> Mikael Jagan 
>>>>>     on Wed, 17 Nov 2021 17:01:00 -0500 writes:

    >> This seems entirely avoidable, given that there is a relatively simple 
    >> formula for converting 2-ary indices [i,j] of S to 1-ary indices k of 
    >> S[lower.tri(S, TRUE)]:
    >> 
    >> k <- i + round(0.5 * (2L * n - j) * (j - 1L)) # for i >= j

    > I ought to be slightly more precise here: _coercion_ is avoidable, 
    > because we can always map [i,j] to [k], but memory limits are not. 
    > Certainly S at x[k] cannot be arbitrarily long...

    > At the very least, it would be convenient if the subset were performed 
    > efficiently whenever dimensions would be dropped anyway:

    > * S[i, ] and S[, j] where i and j are vectors indexing exactly zero or 
    > one rows/columns
    > * S[i] where i is a matrix of the form cbind(i, j)


I agree that this could be improved in the Matrix package;
One reason this never happened is probably that we (the Matrix
package authors) never had a relevant use case for speeding
these up.

Would you be interested in collaboration to improve the Matrix
package to achieve this?

Best regards,
Martin

    > This would support, e.g., a memory-efficient 'apply' analogue without 
    > any need for MARGIN...

    > applySymmetric <- function(X, FUN, ..., simplify = TRUE, check = TRUE) {
    >   if (check && !isSymmetric(X)) {
    >     stop("'X' is not a symmetric matrix.")
    >   }
    >   ## preprocessing
    >   ans <- vector("list", n)
    >   for (i in seq_len(n)) {
    >     ans[[i]] <- forceAndCall(1L, FUN, S[i, ], ...)
    >   }
    >   ## postprocessing
    >   ans
    > }

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From @zwj|08 @end|ng |rom gm@||@com  Mon Nov 22 17:46:19 2021
From: @zwj|08 @end|ng |rom gm@||@com (Jiefei Wang)
Date: Mon, 22 Nov 2021 11:46:19 -0500
Subject: [Rd] How is the environment variable "R_USER" defined?
Message-ID: <CAGiFhPN3vq509CE_WFoqRaqfc7__CZrCs5Uz0XFH9jNVEJ-5OA@mail.gmail.com>

Hi, I have a new win system and try to install R as usual. Somehow,
the environment variable "R_LIBS_USER" is incorrectly pointed to a
Onedrive folder. Since "R_LIBS_USER" depends on "R_USER", the root
problem then becomes why "R_USER" is the path to the Onedrive. I did
an exhausting search in the R directory and the only related message I
can find is from EnvVar.html, which states

R_USER: The user's ?home? directory. Set by R. (HOME will be set to
the same value if not already set.)

I guess that's another way to say "no document is available yet". I
also took a look at my system environment variables but there are only
two variables related to Onedrive, they are

OneDrive=C:\Users\wangj\OneDrive

OneDriveConsumer=C:\Users\wangj\OneDrive

so everything looks pretty normal, I know I can correct this issue by
manually adding Renviron but I just wonder where this default behavior
comes from...

Best,
Jiefei


From |reder|k @end|ng |rom o|b@net  Mon Nov 22 18:13:58 2021
From: |reder|k @end|ng |rom o|b@net (Frederick Eaton)
Date: Mon, 22 Nov 2021 09:13:58 -0800
Subject: [Rd] meaning of browser(skipCalls=)
Message-ID: <20211122171358.7rej26rdwpq5ywrm@localhost>

Dear R Devel,

I have been advised to use "options(error=recover)" to enable
debugging on errors. But sometimes it would seem more convenient to
override "stopifnot", for example:

     stopifnot = function(b) { if(!b) { browser(skipCalls=1); } }

However, this doesn't do what I expected. On looking closer I find
that the "skipCalls" argument seems to be ignored except when printing
the "Called from: " message; it does not affect the evaluation context
or the output of 'where':

     > var=2; f=function(){var=1; browser(skipCalls=0)}; f()
     Called from: f()
     Browse[1]> var
     [1] 1
     Browse[1]> where
     where 1: f()

     Browse[1]> Q
     > var=2; f=function(){var=1; browser(skipCalls=1)}; f()
     Called from: top level 
     Browse[1]> var
     [1] 1
     Browse[1]> where
     where 1: f()

     Browse[1]> Q
     > var=2; f=function(){var=1; browser(skipCalls=2)}; f()
     Called from: top level 
     Browse[1]> var
     [1] 1
     Browse[1]> where
     where 1: f()

     Browse[1]> Q

So it appears that the "browser()" API does not actually make it
possible to call this built-in function from within another R function
and thereby emulate the same behavior as calling browser() directly.

If this is the case, it might be good to have it fixed or documented.
I am aware of "browser(expr=)", but this requires editing the
particular call that failed. The documentation for "browser()" led me
to hope that my use case would be supported, if only because it admits
that users might want to build other debugging functions with
browser(): "The 'skipCalls' argument should be used when the
'browser()' call is nested within another debugging function". An
example where this 'skipCalls' parameter is used to build a useful
debugging function would help to clarify its English description in
the manual.

Also, from the browser() command line I could not find a way to step
*out* of the current function. This would have been a way to recover
from skipCalls not working as expected. Am I missing something? For
example is there some command other than "n", where the below
interaction could pause before "hi" and "bye"?

     > f=function(){browser(); message("in f"); message("out f")}; f(); message("hi"); message("bye")
     Called from: f()
     Browse[1]> n
     debug at #1: message("in f")
     Browse[2]> n
     in f
     debug at #1: message("out f")
     Browse[2]> n
     out f
     hi
     bye

If it is not possible for the R debugger to step out of a function, it
would be good to document that too, maybe after the list of browser
prompt commands in "?browser". Being confined within a single function
is not an obvious disability for a debugger to have.

I feel that R is an excellent tool, but sometimes I think that if the
shortcomings of the system were better documented, then this would
save users a lot of time in certain cases.

Thank you,

Frederick


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Nov 22 18:19:19 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 22 Nov 2021 12:19:19 -0500
Subject: [Rd] How is the environment variable "R_USER" defined?
In-Reply-To: <CAGiFhPN3vq509CE_WFoqRaqfc7__CZrCs5Uz0XFH9jNVEJ-5OA@mail.gmail.com>
References: <CAGiFhPN3vq509CE_WFoqRaqfc7__CZrCs5Uz0XFH9jNVEJ-5OA@mail.gmail.com>
Message-ID: <a488df52-afed-424b-555d-50e4075cf82d@gmail.com>

On 22/11/2021 11:46 a.m., Jiefei Wang wrote:
> Hi, I have a new win system and try to install R as usual. Somehow,
> the environment variable "R_LIBS_USER" is incorrectly pointed to a
> Onedrive folder. Since "R_LIBS_USER" depends on "R_USER", the root
> problem then becomes why "R_USER" is the path to the Onedrive. I did
> an exhausting search in the R directory and the only related message I
> can find is from EnvVar.html, which states
> 
> R_USER: The user's ?home? directory. Set by R. (HOME will be set to
> the same value if not already set.)
> 
> I guess that's another way to say "no document is available yet". I
> also took a look at my system environment variables but there are only
> two variables related to Onedrive, they are
> 
> OneDrive=C:\Users\wangj\OneDrive
> 
> OneDriveConsumer=C:\Users\wangj\OneDrive
> 
> so everything looks pretty normal, I know I can correct this issue by
> manually adding Renviron but I just wonder where this default behavior
> comes from...
> 


I think you want to look at the Windows FAQ. From question 2.14:

The home directory is set as follows: If environment variable R_USER is 
set, its value is used. Otherwise if environment variable HOME is set, 
its value is used. After those two user-controllable settings, R tries 
to find system-defined home directories. It first tries to use the 
Windows "personal" directory (typically C:\Users\username\Documents). If 
that fails, if both environment variables HOMEDRIVE and HOMEPATH are set 
(and they normally are), the value is ${HOMEDRIVE}${HOMEPATH}. If all of 
these fail, the current working directory is used.


Duncan Murdoch


From @eb@meyer @end|ng |rom |@u@de  Mon Nov 22 18:21:33 2021
From: @eb@meyer @end|ng |rom |@u@de (Sebastian Meyer)
Date: Mon, 22 Nov 2021 18:21:33 +0100
Subject: [Rd] How is the environment variable "R_USER" defined?
In-Reply-To: <CAGiFhPN3vq509CE_WFoqRaqfc7__CZrCs5Uz0XFH9jNVEJ-5OA@mail.gmail.com>
References: <CAGiFhPN3vq509CE_WFoqRaqfc7__CZrCs5Uz0XFH9jNVEJ-5OA@mail.gmail.com>
Message-ID: <ffcd8c94-4630-bd3f-b7f2-dea6f0337b33@fau.de>

Just a quick thought.
R for Windows FAQ 2.14 talks about the home directory:

https://cran.r-project.org/bin/windows/base/rw-FAQ.html#What-are-HOME-and-working-directories_003f

So maybe HOMEDRIVE and HOMEPATH are involved?

Hope this helps.

	Sebastian Meyer


Am 22.11.21 um 17:46 schrieb Jiefei Wang:
> Hi, I have a new win system and try to install R as usual. Somehow,
> the environment variable "R_LIBS_USER" is incorrectly pointed to a
> Onedrive folder. Since "R_LIBS_USER" depends on "R_USER", the root
> problem then becomes why "R_USER" is the path to the Onedrive. I did
> an exhausting search in the R directory and the only related message I
> can find is from EnvVar.html, which states
> 
> R_USER: The user's ?home? directory. Set by R. (HOME will be set to
> the same value if not already set.)
> 
> I guess that's another way to say "no document is available yet". I
> also took a look at my system environment variables but there are only
> two variables related to Onedrive, they are
> 
> OneDrive=C:\Users\wangj\OneDrive
> 
> OneDriveConsumer=C:\Users\wangj\OneDrive
> 
> so everything looks pretty normal, I know I can correct this issue by
> manually adding Renviron but I just wonder where this default behavior
> comes from...
> 
> Best,
> Jiefei
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From w||||@mwdun|@p @end|ng |rom gm@||@com  Mon Nov 22 18:32:16 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Mon, 22 Nov 2021 09:32:16 -0800
Subject: [Rd] How is the environment variable "R_USER" defined?
In-Reply-To: <CAGiFhPN3vq509CE_WFoqRaqfc7__CZrCs5Uz0XFH9jNVEJ-5OA@mail.gmail.com>
References: <CAGiFhPN3vq509CE_WFoqRaqfc7__CZrCs5Uz0XFH9jNVEJ-5OA@mail.gmail.com>
Message-ID: <CAHqSRuS+=j8-Zfh=x3dsh_odO8rmJWU40oTt51zySAP_UYnQXA@mail.gmail.com>

Is your C:\Users\yourname\Documents linked to OneDrive (either by your
choice or by some administrator setting a group policy)?  If so, ou could
unlink it using OneDrive's settings dialog.   Or you could set R_USER to
avoid using ...\Documents.

-Bill

On Mon, Nov 22, 2021 at 8:47 AM Jiefei Wang <szwjf08 at gmail.com> wrote:

> Hi, I have a new win system and try to install R as usual. Somehow,
> the environment variable "R_LIBS_USER" is incorrectly pointed to a
> Onedrive folder. Since "R_LIBS_USER" depends on "R_USER", the root
> problem then becomes why "R_USER" is the path to the Onedrive. I did
> an exhausting search in the R directory and the only related message I
> can find is from EnvVar.html, which states
>
> R_USER: The user's ?home? directory. Set by R. (HOME will be set to
> the same value if not already set.)
>
> I guess that's another way to say "no document is available yet". I
> also took a look at my system environment variables but there are only
> two variables related to Onedrive, they are
>
> OneDrive=C:\Users\wangj\OneDrive
>
> OneDriveConsumer=C:\Users\wangj\OneDrive
>
> so everything looks pretty normal, I know I can correct this issue by
> manually adding Renviron but I just wonder where this default behavior
> comes from...
>
> Best,
> Jiefei
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From @zwj|08 @end|ng |rom gm@||@com  Mon Nov 22 19:06:47 2021
From: @zwj|08 @end|ng |rom gm@||@com (Jiefei Wang)
Date: Mon, 22 Nov 2021 13:06:47 -0500
Subject: [Rd] How is the environment variable "R_USER" defined?
In-Reply-To: <CAHqSRuS+=j8-Zfh=x3dsh_odO8rmJWU40oTt51zySAP_UYnQXA@mail.gmail.com>
References: <CAGiFhPN3vq509CE_WFoqRaqfc7__CZrCs5Uz0XFH9jNVEJ-5OA@mail.gmail.com>
 <CAHqSRuS+=j8-Zfh=x3dsh_odO8rmJWU40oTt51zySAP_UYnQXA@mail.gmail.com>
Message-ID: <CAGiFhPMOBNfkkkCaG52LNAHAkJCyO+zq-nG1fF9s36Y2FsZRGg@mail.gmail.com>

Thanks for all your help!! It actually has nothing to do with the
environment variables. The issue is caused by the backup feature in
Onedrive as Bill suggested. I do not know what magic trick Onedrive
uses here but it misadvices R to use its directory, not my local
Document directory. The answer might be from Windows FAQ question 2.14
like Duncan posted

After those two user-controllable settings, R tries to find
system-defined home directories. It first tries to use the Windows
"personal" directory

This is confusing. First, this FAQ is not about how "R_USER" is
defined. Instead, it talks about how we find the home directory from
"R_USER". Second, it still did not answer what is "the Windows
personal directory". I think this is where the issue is. My Document
still has the path "C:\Users\wangj\Documents", but there is a backup
path in "C:\Users\wangj\OneDrive\Documents". Unfortunately, R believes
the latter one is the "personal directory". I hope this can be
clarified a little bit to avoid confusion.

Best,
Jiefei

On Mon, Nov 22, 2021 at 12:32 PM Bill Dunlap <williamwdunlap at gmail.com> wrote:
>
> Is your C:\Users\yourname\Documents linked to OneDrive (either by your choice or by some administrator setting a group policy)?  If so, ou could unlink it using OneDrive's settings dialog.   Or you could set R_USER to avoid using ...\Documents.
>
> -Bill
>
> On Mon, Nov 22, 2021 at 8:47 AM Jiefei Wang <szwjf08 at gmail.com> wrote:
>>
>> Hi, I have a new win system and try to install R as usual. Somehow,
>> the environment variable "R_LIBS_USER" is incorrectly pointed to a
>> Onedrive folder. Since "R_LIBS_USER" depends on "R_USER", the root
>> problem then becomes why "R_USER" is the path to the Onedrive. I did
>> an exhausting search in the R directory and the only related message I
>> can find is from EnvVar.html, which states
>>
>> R_USER: The user's ?home? directory. Set by R. (HOME will be set to
>> the same value if not already set.)
>>
>> I guess that's another way to say "no document is available yet". I
>> also took a look at my system environment variables but there are only
>> two variables related to Onedrive, they are
>>
>> OneDrive=C:\Users\wangj\OneDrive
>>
>> OneDriveConsumer=C:\Users\wangj\OneDrive
>>
>> so everything looks pretty normal, I know I can correct this issue by
>> manually adding Renviron but I just wonder where this default behavior
>> comes from...
>>
>> Best,
>> Jiefei
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From tom@@@k@||ber@ @end|ng |rom gm@||@com  Mon Nov 22 19:50:03 2021
From: tom@@@k@||ber@ @end|ng |rom gm@||@com (Tomas Kalibera)
Date: Mon, 22 Nov 2021 19:50:03 +0100
Subject: [Rd] How is the environment variable "R_USER" defined?
In-Reply-To: <CAGiFhPMOBNfkkkCaG52LNAHAkJCyO+zq-nG1fF9s36Y2FsZRGg@mail.gmail.com>
References: <CAGiFhPN3vq509CE_WFoqRaqfc7__CZrCs5Uz0XFH9jNVEJ-5OA@mail.gmail.com>
 <CAHqSRuS+=j8-Zfh=x3dsh_odO8rmJWU40oTt51zySAP_UYnQXA@mail.gmail.com>
 <CAGiFhPMOBNfkkkCaG52LNAHAkJCyO+zq-nG1fF9s36Y2FsZRGg@mail.gmail.com>
Message-ID: <954a676e-dc2f-128c-fba9-988891e6c54e@gmail.com>


On 11/22/21 7:06 PM, Jiefei Wang wrote:
> Thanks for all your help!! It actually has nothing to do with the
> environment variables. The issue is caused by the backup feature in
> Onedrive as Bill suggested. I do not know what magic trick Onedrive
> uses here but it misadvices R to use its directory, not my local
> Document directory. The answer might be from Windows FAQ question 2.14
> like Duncan posted
>
> After those two user-controllable settings, R tries to find
> system-defined home directories. It first tries to use the Windows
> "personal" directory
>
> This is confusing. First, this FAQ is not about how "R_USER" is
> defined. Instead, it talks about how we find the home directory from
> "R_USER".
My understanding of the text is that R_USER is defined as (one of the) 
environment variable(s) which one can set to override what R understands 
to be the R "home directory"
>   Second, it still did not answer what is "the Windows
> personal directory". I think this is where the issue is. My Document
> still has the path "C:\Users\wangj\Documents", but there is a backup
> path in "C:\Users\wangj\OneDrive\Documents". Unfortunately, R believes
> the latter one is the "personal directory". I hope this can be
> clarified a little bit to avoid confusion.

The "personal directory" is a Windows term. R obtains it via Windows API 
call SHGetSpecialFolderLocation with CSIDL_PERSONAL (which is now My 
Documents), this is why the wording in rw-FAQ:

"It first tries to use the Windows "personal" directory (typically 
@file{C:\Users\username \Documents}).", which gives a typical value.

Best
Tomas


>
> Best,
> Jiefei
>
> On Mon, Nov 22, 2021 at 12:32 PM Bill Dunlap <williamwdunlap at gmail.com> wrote:
>> Is your C:\Users\yourname\Documents linked to OneDrive (either by your choice or by some administrator setting a group policy)?  If so, ou could unlink it using OneDrive's settings dialog.   Or you could set R_USER to avoid using ...\Documents.
>>
>> -Bill
>>
>> On Mon, Nov 22, 2021 at 8:47 AM Jiefei Wang <szwjf08 at gmail.com> wrote:
>>> Hi, I have a new win system and try to install R as usual. Somehow,
>>> the environment variable "R_LIBS_USER" is incorrectly pointed to a
>>> Onedrive folder. Since "R_LIBS_USER" depends on "R_USER", the root
>>> problem then becomes why "R_USER" is the path to the Onedrive. I did
>>> an exhausting search in the R directory and the only related message I
>>> can find is from EnvVar.html, which states
>>>
>>> R_USER: The user's ?home? directory. Set by R. (HOME will be set to
>>> the same value if not already set.)
>>>
>>> I guess that's another way to say "no document is available yet". I
>>> also took a look at my system environment variables but there are only
>>> two variables related to Onedrive, they are
>>>
>>> OneDrive=C:\Users\wangj\OneDrive
>>>
>>> OneDriveConsumer=C:\Users\wangj\OneDrive
>>>
>>> so everything looks pretty normal, I know I can correct this issue by
>>> manually adding Renviron but I just wonder where this default behavior
>>> comes from...
>>>
>>> Best,
>>> Jiefei
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Nov 22 20:13:12 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 22 Nov 2021 14:13:12 -0500
Subject: [Rd] How is the environment variable "R_USER" defined?
In-Reply-To: <CAGiFhPMOBNfkkkCaG52LNAHAkJCyO+zq-nG1fF9s36Y2FsZRGg@mail.gmail.com>
References: <CAGiFhPN3vq509CE_WFoqRaqfc7__CZrCs5Uz0XFH9jNVEJ-5OA@mail.gmail.com>
 <CAHqSRuS+=j8-Zfh=x3dsh_odO8rmJWU40oTt51zySAP_UYnQXA@mail.gmail.com>
 <CAGiFhPMOBNfkkkCaG52LNAHAkJCyO+zq-nG1fF9s36Y2FsZRGg@mail.gmail.com>
Message-ID: <7b466637-c565-8cf6-bb49-39ff8406b20c@gmail.com>

On 22/11/2021 1:06 p.m., Jiefei Wang wrote:
> Thanks for all your help!! It actually has nothing to do with the
> environment variables. The issue is caused by the backup feature in
> Onedrive as Bill suggested. I do not know what magic trick Onedrive
> uses here but it misadvices R to use its directory, not my local
> Document directory. The answer might be from Windows FAQ question 2.14
> like Duncan posted
> 
> After those two user-controllable settings, R tries to find
> system-defined home directories. It first tries to use the Windows
> "personal" directory
> 
> This is confusing. First, this FAQ is not about how "R_USER" is
> defined.

R_USER is an optional environment variable that *you* can set.  If you 
do, it's taken to be the home directory.  If it is not set, the rest of 
the FAQ 2.14 entry is tried.

So if R is coming up with the wrong home directory, the solution is to 
set R_USER to be the directory you want to use.  You have to do this 
before starting R, you can't use Sys.setenv():  it's too late by then.

The easiest way to set an environment variable for R to use is to set it 
in the R_HOME/etc/Renviron.site file.  You can alternatively set it in 
the .Renviron file, but it may be a little mysterious in Windows where 
you should save that.

You can also set environment variables using Windows control panel 
settings, but I don't think I ever learned the details of this for 
Windows 10.  That can be global for all programs for one user, or global 
for all users, depending on how you set it.

Duncan Murdoch

  Instead, it talks about how we find the home directory from
> "R_USER". Second, it still did not answer what is "the Windows
> personal directory". I think this is where the issue is. My Document
> still has the path "C:\Users\wangj\Documents", but there is a backup
> path in "C:\Users\wangj\OneDrive\Documents". Unfortunately, R believes
> the latter one is the "personal directory". I hope this can be
> clarified a little bit to avoid confusion.
> 
> Best,
> Jiefei
> 
> On Mon, Nov 22, 2021 at 12:32 PM Bill Dunlap <williamwdunlap at gmail.com> wrote:
>>
>> Is your C:\Users\yourname\Documents linked to OneDrive (either by your choice or by some administrator setting a group policy)?  If so, ou could unlink it using OneDrive's settings dialog.   Or you could set R_USER to avoid using ...\Documents.
>>
>> -Bill
>>
>> On Mon, Nov 22, 2021 at 8:47 AM Jiefei Wang <szwjf08 at gmail.com> wrote:
>>>
>>> Hi, I have a new win system and try to install R as usual. Somehow,
>>> the environment variable "R_LIBS_USER" is incorrectly pointed to a
>>> Onedrive folder. Since "R_LIBS_USER" depends on "R_USER", the root
>>> problem then becomes why "R_USER" is the path to the Onedrive. I did
>>> an exhausting search in the R directory and the only related message I
>>> can find is from EnvVar.html, which states
>>>
>>> R_USER: The user's ?home? directory. Set by R. (HOME will be set to
>>> the same value if not already set.)
>>>
>>> I guess that's another way to say "no document is available yet". I
>>> also took a look at my system environment variables but there are only
>>> two variables related to Onedrive, they are
>>>
>>> OneDrive=C:\Users\wangj\OneDrive
>>>
>>> OneDriveConsumer=C:\Users\wangj\OneDrive
>>>
>>> so everything looks pretty normal, I know I can correct this issue by
>>> manually adding Renviron but I just wonder where this default behavior
>>> comes from...
>>>
>>> Best,
>>> Jiefei
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From d|pter|x@w@ng @end|ng |rom gm@||@com  Tue Nov 23 20:11:28 2021
From: d|pter|x@w@ng @end|ng |rom gm@||@com (Dipterix Wang)
Date: Tue, 23 Nov 2021 14:11:28 -0500
Subject: [Rd] How can a package be aware of whether it's on CRAN
Message-ID: <0F983A9D-937C-41DF-8FB4-4F4A20B17B1C@gmail.com>

Dear R wizards,

I recently received an email from Prof. Ripley. He pointed out that my package seriously violates the CRAN policy: "using 8 threads is a serious violation of the CRAN policy?. By default the number of cores my package uses is determined from system CPU cores. After carefully reading all the CRAN policies, now I understand that CRAN does not allow a package to use more than 2 CPU cores when checking a package. I can easily change my code to let my tests comply to that constraint. 

However, this warning worries me because my package uses OpenMP. I got ?caught" partially because I printed the number of cores used in the package startup message, and one of my test exceeded the time limit (which leads to manual inspection). However, what if I develop a package that imports on those openmp-dependent packages? (For example, data.table, fst?) These packages use more than 2 cores by default. If not carefully treated, it?ll be very easy to exceed that limit, and it?s very hard for CRAN to detect it. 

Is there any reliable way to let packages to know if they are on CRAN, so they can set omp cores to 2 by default?

Best,
- Dipterix

From edd @end|ng |rom deb|@n@org  Tue Nov 23 20:48:39 2021
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Tue, 23 Nov 2021 13:48:39 -0600
Subject: [Rd] How can a package be aware of whether it's on CRAN
In-Reply-To: <0F983A9D-937C-41DF-8FB4-4F4A20B17B1C@gmail.com>
References: <0F983A9D-937C-41DF-8FB4-4F4A20B17B1C@gmail.com>
Message-ID: <24989.17815.215492.548979@rob.eddelbuettel.com>


This may be more of a question for r-package-devel than for r-devel.

On 23 November 2021 at 14:11, Dipterix Wang wrote:
| I recently received an email from Prof. Ripley. He pointed out that my package seriously violates the CRAN policy: "using 8 threads is a serious violation of the CRAN policy?. By default the number of cores my package uses is determined from system CPU cores. After carefully reading all the CRAN policies, now I understand that CRAN does not allow a package to use more than 2 CPU cores when checking a package. I can easily change my code to let my tests comply to that constraint. 
| 
| However, this warning worries me because my package uses OpenMP. I got ?caught" partially because I printed the number of cores used in the package startup message, and one of my test exceeded the time limit (which leads to manual inspection). However, what if I develop a package that imports on those openmp-dependent packages? (For example, data.table, fst?) These packages use more than 2 cores by default. If not carefully treated, it?ll be very easy to exceed that limit, and it?s very hard for CRAN to detect it. 
| 
| Is there any reliable way to let packages to know if they are on CRAN, so they can set omp cores to 2 by default?

The question is valid (CRAN runs tests on many packages at once, we cannot
hog machines from a single package) and interesting: how can we give our
users all the horsepower they want and expect?

The available documentation (WRE, CRAN Policy, R source code, ...) offers
some hints so you could use n_threads = getOption("Ncpus", 1L) which means
that those who set this variable will get it.

For the tiledb package, we did something else and let the package do what the
underlying library does ("all cores", users expect perfomance), but also
added a function to throttle to what CRAN allows --- and then use that
function in all the examples, and the tests. There are a number of ways in
which the actual throttling is affected as it look at Ncpus (mentioned above)
as well as at OMP_THREAD_LIMIT which can be used to control OpenMP.

All that means that in the code CRAN runs -- via entry points from examples
and tests -- usage is throttled as CRAN desires. But all other ("normal") use
is "full throttle" and unlimited as users expect.

Hope this helps, Dirk

-- 
https://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From henr|k@bengt@@on @end|ng |rom gm@||@com  Tue Nov 23 20:49:11 2021
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Tue, 23 Nov 2021 11:49:11 -0800
Subject: [Rd] How can a package be aware of whether it's on CRAN
In-Reply-To: <0F983A9D-937C-41DF-8FB4-4F4A20B17B1C@gmail.com>
References: <0F983A9D-937C-41DF-8FB4-4F4A20B17B1C@gmail.com>
Message-ID: <CAFDcVCTzAoQt+yauvcbDYBMB7Tkn7zaAYRDOBTeSENtyToK5rw@mail.gmail.com>

> Is there any reliable way to let packages to know if they are on CRAN, so they can set omp cores to 2 by default?

Instead of testing for "on CRAN" or not, you can test for 'R CMD
check' running or not. 'R CMD check' sets environment variable
_R_CHECK_LIMIT_CORES_=TRUE. You can use that to limit your code to run
at most two (2) parallel threads or processes.

The parallelly::availableCores() function is agile to this and many
other settings, i.e. it'll return 2 when running via 'R CMD check'. As
the author, I obviously suggest using that function to query what
amount of CPU resources your R process is allowed to use. For more
info, see <https://parallelly.futureverse.org/index.html#availablecores-vs-paralleldetectcores>.

/Henrik

PS. I'm in the camp of *not* having R packages parallelize by default.
At least not until R and its community have figured out how to avoid
ending up with nested parallelization (e.g. via dependencies) by
mistake.  We would also need a standard for end-users (and the sysadms
on the machines they're running) to control the default number of CPU
cores the R session may use.  Right now we only have a few scattered
settings for separate purposes, e.g. option 'mc.cores'/env var
'MC_CORES', and option 'Ncpus', which is not enough for establishing a
de facto standard.

On Tue, Nov 23, 2021 at 11:11 AM Dipterix Wang <dipterix.wang at gmail.com> wrote:
>
> Dear R wizards,
>
> I recently received an email from Prof. Ripley. He pointed out that my package seriously violates the CRAN policy: "using 8 threads is a serious violation of the CRAN policy?. By default the number of cores my package uses is determined from system CPU cores. After carefully reading all the CRAN policies, now I understand that CRAN does not allow a package to use more than 2 CPU cores when checking a package. I can easily change my code to let my tests comply to that constraint.
>
> However, this warning worries me because my package uses OpenMP. I got ?caught" partially because I printed the number of cores used in the package startup message, and one of my test exceeded the time limit (which leads to manual inspection). However, what if I develop a package that imports on those openmp-dependent packages? (For example, data.table, fst?) These packages use more than 2 cores by default. If not carefully treated, it?ll be very easy to exceed that limit, and it?s very hard for CRAN to detect it.
>
> Is there any reliable way to let packages to know if they are on CRAN, so they can set omp cores to 2 by default?
>
> Best,
> - Dipterix
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From c@@rd|@g@bor @end|ng |rom gm@||@com  Tue Nov 23 21:05:50 2021
From: c@@rd|@g@bor @end|ng |rom gm@||@com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Tue, 23 Nov 2021 21:05:50 +0100
Subject: [Rd] How can a package be aware of whether it's on CRAN
In-Reply-To: <CAFDcVCTzAoQt+yauvcbDYBMB7Tkn7zaAYRDOBTeSENtyToK5rw@mail.gmail.com>
References: <0F983A9D-937C-41DF-8FB4-4F4A20B17B1C@gmail.com>
 <CAFDcVCTzAoQt+yauvcbDYBMB7Tkn7zaAYRDOBTeSENtyToK5rw@mail.gmail.com>
Message-ID: <CABtg=KmNAfMv0C-c97cUTGbVKKKrE-q50JBXj6pdgGKbBXBp4w@mail.gmail.com>

On Tue, Nov 23, 2021 at 8:49 PM Henrik Bengtsson
<henrik.bengtsson at gmail.com> wrote:
>
> > Is there any reliable way to let packages to know if they are on CRAN, so they can set omp cores to 2 by default?
>
> Instead of testing for "on CRAN" or not, you can test for 'R CMD
> check' running or not. 'R CMD check' sets environment variable
> _R_CHECK_LIMIT_CORES_=TRUE. You can use that to limit your code to run
> at most two (2) parallel threads or processes.

AFAICT this is only set with --as-cran and many CRAN machines don't
use that and I am fairly sure that some of them don't set this env var
manually, either.

Gabor

[...]


From hp@ge@@on@g|thub @end|ng |rom gm@||@com  Tue Nov 23 21:19:19 2021
From: hp@ge@@on@g|thub @end|ng |rom gm@||@com (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Tue, 23 Nov 2021 12:19:19 -0800
Subject: [Rd] How can a package be aware of whether it's on CRAN
In-Reply-To: <CABtg=KmNAfMv0C-c97cUTGbVKKKrE-q50JBXj6pdgGKbBXBp4w@mail.gmail.com>
References: <0F983A9D-937C-41DF-8FB4-4F4A20B17B1C@gmail.com>
 <CAFDcVCTzAoQt+yauvcbDYBMB7Tkn7zaAYRDOBTeSENtyToK5rw@mail.gmail.com>
 <CABtg=KmNAfMv0C-c97cUTGbVKKKrE-q50JBXj6pdgGKbBXBp4w@mail.gmail.com>
Message-ID: <608b7e02-3f47-f976-c973-5b28a3eb2c59@gmail.com>

But why would you need to check for anything in the first place?

If you only use 2 cores in your examples, vignettes, and unit tests, 'R 
CMD check' will run fine everywhere and not eat all the CPU power of the 
machine where it's running.

H.

On 23/11/2021 12:05, G?bor Cs?rdi wrote:
> On Tue, Nov 23, 2021 at 8:49 PM Henrik Bengtsson
> <henrik.bengtsson at gmail.com> wrote:
>>
>>> Is there any reliable way to let packages to know if they are on CRAN, so they can set omp cores to 2 by default?
>>
>> Instead of testing for "on CRAN" or not, you can test for 'R CMD
>> check' running or not. 'R CMD check' sets environment variable
>> _R_CHECK_LIMIT_CORES_=TRUE. You can use that to limit your code to run
>> at most two (2) parallel threads or processes.
> 
> AFAICT this is only set with --as-cran and many CRAN machines don't
> use that and I am fairly sure that some of them don't set this env var
> manually, either.
> 
> Gabor
> 
> [...]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Herv? Pag?s

Bioconductor Core Team
hpages.on.github at gmail.com


From edd @end|ng |rom deb|@n@org  Tue Nov 23 21:52:11 2021
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Tue, 23 Nov 2021 14:52:11 -0600
Subject: [Rd] How can a package be aware of whether it's on CRAN
In-Reply-To: <608b7e02-3f47-f976-c973-5b28a3eb2c59@gmail.com>
References: <0F983A9D-937C-41DF-8FB4-4F4A20B17B1C@gmail.com>
 <CAFDcVCTzAoQt+yauvcbDYBMB7Tkn7zaAYRDOBTeSENtyToK5rw@mail.gmail.com>
 <CABtg=KmNAfMv0C-c97cUTGbVKKKrE-q50JBXj6pdgGKbBXBp4w@mail.gmail.com>
 <608b7e02-3f47-f976-c973-5b28a3eb2c59@gmail.com>
Message-ID: <24989.21627.740021.682590@rob.eddelbuettel.com>


On 23 November 2021 at 12:19, Herv? Pag?s wrote:
| But why would you need to check for anything in the first place?
| 
| If you only use 2 cores in your examples, vignettes, and unit tests, 'R 
| CMD check' will run fine everywhere and not eat all the CPU power of the 
| machine where it's running.

Yes! That is, in fewer words, what I described, and what package tiledb does.

Dirk

-- 
https://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From henr|k@bengt@@on @end|ng |rom gm@||@com  Tue Nov 23 22:08:35 2021
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Tue, 23 Nov 2021 13:08:35 -0800
Subject: [Rd] How can a package be aware of whether it's on CRAN
In-Reply-To: <CABtg=KmNAfMv0C-c97cUTGbVKKKrE-q50JBXj6pdgGKbBXBp4w@mail.gmail.com>
References: <0F983A9D-937C-41DF-8FB4-4F4A20B17B1C@gmail.com>
 <CAFDcVCTzAoQt+yauvcbDYBMB7Tkn7zaAYRDOBTeSENtyToK5rw@mail.gmail.com>
 <CABtg=KmNAfMv0C-c97cUTGbVKKKrE-q50JBXj6pdgGKbBXBp4w@mail.gmail.com>
Message-ID: <CAFDcVCSQxZ=1h=CfvOJxqFE-cpd2Wz+uWW9fme5hW+6LzmduxA@mail.gmail.com>

On Tue, Nov 23, 2021 at 12:06 PM G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
>
> On Tue, Nov 23, 2021 at 8:49 PM Henrik Bengtsson
> <henrik.bengtsson at gmail.com> wrote:
> >
> > > Is there any reliable way to let packages to know if they are on CRAN, so they can set omp cores to 2 by default?
> >
> > Instead of testing for "on CRAN" or not, you can test for 'R CMD
> > check' running or not. 'R CMD check' sets environment variable
> > _R_CHECK_LIMIT_CORES_=TRUE. You can use that to limit your code to run
> > at most two (2) parallel threads or processes.
>
> AFAICT this is only set with --as-cran and many CRAN machines don't
> use that and I am fairly sure that some of them don't set this env var
> manually, either.

Oh my - yes & yes, especially on the second part - I totally forgot.
So, that alone is not sufficient. It's not meant to be easy, eh?

So, parallelly::availableCores() tries to account for this as well by
detecting that 'R CMD check' runs, cf.
https://github.com/HenrikBengtsson/parallelly/blob/3e403f600e7181423b9d77c739373d36b4fe34df/R/zzz.R#L42-L47

/Henrik

>
> Gabor
>
> [...]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Wed Nov 24 12:45:07 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Wed, 24 Nov 2021 12:45:07 +0100
Subject: [Rd] R-devel (r81196) hanging at dchisq(large) (PR#13309)
In-Reply-To: <CAL6gwnLEKoAmzuaFFV0vo_XGOt6gnStnP=00ojHLNv4WYHvGHA@mail.gmail.com>
References: <CAL6gwn+-zy+RjX+toMptU6nyOc5bwQix4WDHbkgWAXwCTYEwqA@mail.gmail.com>
 <24979.28479.945404.466101@stat.math.ethz.ch>
 <CAL6gwnJuPnwS9GXvd0O80H3rRXxAUWrmUncOkrDECB2B+X-+8w@mail.gmail.com>
 <CAJXgQP1Hz2eKBObhGzgO6iEo0k3AJetWiii4t86Xu3Gvir+6nw@mail.gmail.com>
 <CAL6gwnKMhbCZf7EnQ0pLKqxv5LSf1R=1zfLZXiZfitBPLsa_0Q@mail.gmail.com>
 <CAL6gwnKG-vXqkfrnnbqbu2-VP_fPgVFX5yE5Svg0MNeYix_PQg@mail.gmail.com>
 <CAL6gwnLEKoAmzuaFFV0vo_XGOt6gnStnP=00ojHLNv4WYHvGHA@mail.gmail.com>
Message-ID: <20211124114507.5B4DC1C1DB0@lynne.math.ethz.ch>

>>>>> Avraham Adler  on Thu, 18 Nov 2021 02:18:54 +0000 writes:

    > Hello.  I have isolated the issue: it is the
    > fused-multiply-add instruction set (FMA on Intel
    > processors). Running -march=skylake -mno-fma not only does
    > not hang, but passes make check-all (using R's native
    > BLAS).  My intuition remains that something in the new
    > more precise ebd0 code used in dpois_raw?called by dgamma,
    > called by dchsq, called by dnchisq?is hanging when the
    > assembler uses FMA. Unfortunately, I have come across
    > other cases online where the extra precision and the
    > different assembler code of FMA vs. non-FMA has caused
    > bugs, such as [1]. Page 5 of this paper by Dr. William
    > Kahan sheds some light on why this may be happening [2]
    > (PDF).

    > Martin & Morton, having written (PR#15628 [3]) and/or
    > implemented the ebd0 code that is now being used, can
    > either of you think of any reason why it would hang if
    > compiled using FMA? 

I vaguely remember I had a version of ebd0(), either Morton
Welinder's original, or a slight modification of it that needed some
mending, because in some border case, there was an out of
array-boundary indexing... but that's just a vague recollection.

I had investigated  ebd0()'s behavior quite a bit, also notably
the version -- together with a pure R code version --
in my CRAN package DPQ, yesterday updated to version 0.5-0 on CRAN
{written in Summer, but published to CRAN only yesterday}
where I have  dpois_raw() optionally using several experimental versions of
bd0(), and both 'pure R' and a C version of ebd0(),
as DPQ::ebd0() and DPQ::edb0C()
each with an option  'verbose' which shows you which branches are chosen
for the given arguments.

So, if you install this version (0.5-0 or newer) from the development
sources, using the *same* FMA configuration,
I hope you should see the same "hanging" but would be able to see some
more.. ?

Can you install it from R-forge

    install.packages("DPQ", type = "source",
                     repos="http://R-Forge.R-project.org")

and then experiment?
I'd be grateful  {and we maybe can move "off - mailing list"}

Thank you in advance,
Martin

Martin Maechler
ETH Zurich  and  R Core team


    > Again, I'm not a professional, but
    > line 325 of the ebd0 function in bd0.c [4] has "ADD1(-x *
    > log1pmx ((M * fg - x) / x))" which looks like a
    > Multiply-Add to me, at least in the inner parenthesis. Is
    > there anything that can be, or should be, done with the
    > code to prevent the hang, or must we forbid the use of FMA
    > instructions (and I guess FMA4 on AMD processors) when
    > compiling R?

    > Also, What happens in the case where M/x neither over- nor
    > under-flowed, M_LN2 * ((double) -e) <= 1. + DBL_MAX / x,
    > fg != 1, and after 4 loops of lines 329 & 330, *yh is
    > still finite? How does ebd0 exit in that case? There is no
    > "return" after line 331. Am I missing something? Could
    > that be related to this issue?

    > As an aside, could ebd0 be enhanced by using FMA
    > instructions on processors which support them?

    > Thank you very much,

    > Avi

    > [1]
    > https://flameeyes.blog/2014/10/27/the-subtlety-of-modern-cpus-or-the-search-for-the-phantom-bug/
    > [2]
    > https://people.eecs.berkeley.edu/~wkahan/ieee754status/IEEE754.PDF
    > [3] https://bugs.r-project.org/show_bug.cgi?id=15628 [4]
    > https://github.com/wch/r-source/blob/trunk/src/nmath/bd0.c

    > On Wed, Nov 17, 2021 at 3:55 PM Avraham Adler
    > <avraham.adler at gmail.com> wrote:
    >> 
    >> Hello, Martin et. al.
    >> 
    >> I apologize for top posting, but I believe I have tracked
    >> down the difference why last time my build worked and now
    >> it hangs on `dchisq(c(Inf, 1e80, 1e50, 1e40), df=10,
    >> ncp=1)`. and it's NOT the BLAS. I built against both 3.15
    >> AND R's vanilla and it hung both times. The issue was
    >> passing "march=skylake". I own an i7-8700K which gcc
    >> considers a skylake. When I pass mtune=skylake, it does
    >> not hang and the make check-devel after the build
    >> completes.
    >> 
    >> Below is a list of the different flags passed when using
    >> mtune vs.  march. It stands to reason that at least one
    >> of them contributed to the hanging issue which Martin
    >> fixed in
    >> https://bugs.r-project.org/show_bug.cgi?id=13309. While I
    >> recognize the obvious ones, I'm not an expert and do not
    >> understand which if any may be the culprit. For
    >> reference, most of these flags are described here:
    >> https://gcc.gnu.org/onlinedocs/gcc-8.3.0/gcc/x86-Options.html#x86-Options.
    >> 
    >> All the following flags are DISABLED for mtune=skylake
    >> (so march=x86-64) and ENABLED when passing
    >> march-skylake. For the record, I usually passed march in
    >> the past without problem:
    >> 
    >> madx, maes, mavx, mavx2, mbmi, mbmi2, mclflushopt, mcx16,
    >> mf16c, mfma, mfsgsbase, mhle, mlzcnt, mmovbe, mpclmul,
    >> mpopcnt, mprfchw, mrdrnd, mrdseed, msahf, msgx, msse3,
    >> msse4, msse4.1, msse4.2, mssse3, mxsave, mxsavec,
    >> mxsaveopt, and mxsaves.
    >> 
    >> Inversely, mno-sse4 is enabled when using mtune and
    >> disabled when using arch, of course.
    >> 
    >> For completeness, the following two are disabled on both
    >> mtune and march but enabled when passing march=native,
    >> otherwise the latter is the same as march=skylake: mabm
    >> and mrtm. Obviously these cannot contribute to the
    >> hanging issue.
    >> 
    >> Any ideas, especially from the experts who understand how
    >> the flags would address the code in dchisq, would be
    >> greatly appreciated.
    >> 
    >> Thank you,
    >> 
    >> Avi
    >> 
    >> On Wed, Nov 17, 2021 at 7:15 AM Avraham Adler
    >> <avraham.adler at gmail.com> wrote:
    >> >
    >> > On Tue, Nov 16, 2021 at 10:42 PM Kevin Ushey
    >> <kevinushey at gmail.com> wrote:
    >> > >
    >> > > Do you see this same hang in a build of R with debug
    >> symbols? Can you > > try running R with GDB, or even
    >> WinDbg or another debugger, to see > > what the call
    >> stack looks like when the hang occurs? Does the hang > >
    >> depend on the number of threads used by OpenBLAS?
    >> > >
    >> > > On the off chance it's relevant, I've seen hangs /
    >> crashes when using > > a multithreaded OpenBLAS with R on
    >> some Linux systems before, but > > never found the time
    >> to isolate a root cause.
    >> > >
    >> >
    >> >
    >> > This last was a good thought, Kevin, as I had just
    >> compiled OpenBLAS > 3.18 multi-threaded, but I recompiled
    >> it single threaded and it still > crashes. The version of
    >> R I built from source last time, (2021-05-20 > r80347),
    >> does not hang when calling `dchisq(c(Inf, 1e80, 1e50,
    >> 1e40), > df=10, ncp=1)`. I think I built that with
    >> OpenBLAS 3.15. I can try > doing that here. As for
    >> building with debug symbols, I have never done > that
    >> before, so if you could provide some guidance (off-list
    >> if you > think it is inappropriate to keep it here) or
    >> point me in the > direction of some already posted
    >> advice, I would appreciate it!
    >> >
    >> > Avi
    >> >
    >> >
    >> >
    >> > > Best, > > Kevin
    >> > >
    >> > > On Tue, Nov 16, 2021 at 5:12 AM Avraham Adler
    >> <avraham.adler at gmail.com> wrote:
    >> > > >
    >> > > > On Tue, Nov 16, 2021 at 8:43 AM Martin Maechler > >
    >> > <maechler at stat.math.ethz.ch> wrote:
    >> > > > >
    >> > > > > >>>>> Avraham Adler > > > > >>>>> on Tue, 16 Nov
    >> 2021 02:35:56 +0000 writes:
    >> > > > >
    >> > > > > > I am building r-devel on Windows 10 64bit using
    >> Jeroen's mingw system, > > > > > and I am finding that my
    >> make check-devel hangs on the above issue.  > > > > >
    >> Everything is vanila except that I am using OpenBLAS
    >> 0.3.18. I have > > > > > been using OpenBLAS for over a
    >> decade and have not had this issue > > > > > before. Is
    >> there anything I can do to dig deeper into this issue
    >> from > > > > > my end? Could there be anything that
    >> changed in R-devel that may have > > > > > triggered
    >> this? The bugzilla report doesn't have any code attached
    >> to > > > > > it.
    >> > > > >
    >> > > > > > Thank you, > > > > > Avi
    >> > > > >
    >> > > > > Hmm.. it would've be nice to tell a bit more,
    >> instead of having all > > > > your readers to search
    >> links, etc.
    >> > > > >
    >> > > > > In the bugzilla bug report PR#13309 > > > >
    >> https://bugs.r-project.org/show_bug.cgi?id=13309 ,the
    >> example was
    >> > > > >
    >> > > > > dchisq(x=Inf, df=10, ncp=1)
    >> > > > >
    >> > > > > I had fixed the bug 13 years ago, in svn rev
    >> 47005 > > > > with regression test in
    >> <Rsrc>/tests/d-p-q-r-tests.R :
    >> > > > >
    >> > > > >
    >> > > > > ## Non-central Chi^2 density for large x > > > >
    >> stopifnot(0 == dchisq(c(Inf, 1e80, 1e50, 1e40), df=10,
    >> ncp=1)) > > > > ## did hang in 2.8.0 and earlier
    >> (PR#13309).
    >> > > > >
    >> > > > >
    >> > > > > and you are seeing your version of R hanging at
    >> exactly this > > > > location?
    >> > > > >
    >> > > > >
    >> > > > > I'd bet quite a bit that the underlying code in
    >> these > > > > non-central chi square computations *never*
    >> calls BLAS and hence > > > > I cannot imagine how
    >> openBLAS could play a role.
    >> > > > >
    >> > > > > However, there must be something peculiar in your
    >> compiler setup, > > > > compilation options, ....  > > >
    >> > as of course the above regression test has been run
    >> 100s of > > > > 1000s of times also under Windows in the
    >> last 13 years ..
    >> > > > >
    >> > > > > Last but not least (but really only vaguely
    >> related): > > > > There is still a FIXME in the source
    >> code (but not about > > > > hanging, but rather of
    >> loosing some accuracy in border cases), > > > > see
    >> e.g. https://svn.r-project.org/R/trunk/src/nmath/dnchisq.c
    >> > > > > and for that reason I had written an R version of
    >> that C code > > > > even back in 2008 which I've made
    >> available in CRAN package > > > > DPQ a few years ago
    >> (together with many other D/P/Q > > > > distribution
    >> computations/approximations).  > > > > ->
    >> https://cran.r-project.org/package=DPQ
    >> > > > >
    >> > > > > Best, > > > > Martin
    >> > > > >
    >> > > >
    >> > > > Hello, Martin.
    >> > > >
    >> > > > Apologies, I thought the PR # was sufficient. Yes,
    >> I am seeing this at > > > this exact location. This is
    >> what I saw in d-p-q-r-tst-2.Rout.fail and > > > I then
    >> ran d-p-q-r-tst.R line-by-line and R hung precisely after
    >> > > > `stopifnot(0 == dchisq(c(Inf, 1e80, 1e50, 1e40),
    >> df=10, ncp=1))`.
    >> > > >
    >> > > > Is it at all possible that this has to do with the
    >> recent change from > > > bd0 to ebd0 (PR #15628) [1]?
    >> > > >
    >> > > > For completeness, I ran all the code _beneath_ the
    >> call, and while > > > nothing else cause an infinite
    >> loop, I posted what I believe may be > > > unexpected
    >> results below,
    >> > > >
    >> > > > Thank you,
    >> > > >
    >> > > > Avi
    >> > > >
    >> > > > [1]:
    >> https://bugs.r-project.org/show_bug.cgi?id=15628
    >> > > >
    >> > > > > ## FIXME ?!: MxM/2 seems +- ok ??  > > > > (dLmM
    >> <- dnbinom(xL, mu = 1, size = MxM)) # all NaN but the
    >> last > > > Warning in dnbinom(xL, mu = 1, size = MxM) :
    >> NaNs produced > > > [1] NaN NaN NaN NaN NaN NaN NaN NaN
    >> NaN NaN NaN NaN NaN NaN NaN NaN > > > NaN NaN NaN NaN NaN
    >> NaN NaN NaN NaN NaN NaN 0 > > > > (dLpI <- dnbinom(xL,
    >> prob=1/2, size = Inf))# ditto > > > Warning in
    >> dnbinom(xL, prob = 1/2, size = Inf) : NaNs produced > > >
    >> [1] NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN
    >> NaN NaN NaN > > > NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN
    >> NaN 0 > > > > (dLpM <- dnbinom(xL, prob=1/2, size =
    >> MxM))# ditto > > > Warning in dnbinom(xL, prob = 1/2,
    >> size = MxM) : NaNs produced > > > [1] NaN NaN NaN NaN NaN
    >> NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN > > > NaN NaN
    >> NaN NaN NaN NaN NaN NaN NaN NaN NaN 0
    >> > > >
    >> > > > > d <- dnbinom(x, mu = mu, size = Inf) # gave NaN
    >> (for 0 and L), now all 0 > > > Warning in dnbinom(x, mu =
    >> mu, size = Inf) : NaNs produced > > > > p <- pnbinom(x,
    >> mu = mu, size = Inf) # gave all NaN, now uses ppois(x,
    >> mu) > > > Warning in pnbinom(x, mu = mu, size = Inf) :
    >> NaNs produced
    >> > > >
    >> > > > > pp <- (0:16)/16 > > > > q <- qnbinom(pp, mu = mu,
    >> size = Inf) # gave all NaN > > > > set.seed(1); NI <-
    >> rnbinom(32, mu = mu, size = Inf)# gave all NaN > > > >
    >> set.seed(1); N2 <- rnbinom(32, mu = mu, size = L ) > > >
    >> > stopifnot(exprs = { > > > + all.equal(d, c(0.006737947,
    >> 0.033689735, 0.0842243375, > > > 0.140373896, 0,0,0,0),
    >> tol = 9e-9)# 7.6e-10 > > > + all.equal(p, c(0.006737947,
    >> 0.040427682, 0.1246520195, > > > 0.265025915, 1,1,1,1),
    >> tol = 9e-9)# 7.3e-10 > > > + all.equal(d, dpois(x, mu))#
    >> current implementation: even identical() > > > +
    >> all.equal(p, ppois(x, mu)) > > > + q == c(0, 2, 3, 3, 3,
    >> 4, 4, 4, 5, 5, 6, 6, 6, 7, 8, 9, Inf) > > > + q ==
    >> qpois(pp, mu) > > > + identical(NI, N2) > > > + }) > > >
    >> Error: d and c(0.006737947, 0.033689735, 0.0842243375,
    >> 0.140373896, 0, > > > 0, .... are not equal: > > >
    >> 'is.NA' value mismatch: 0 in current 1 in target
    >> > > >
    >> > > > > if(!(onWindows && arch == "x86")) { > > > + ##
    >> This gave a practically infinite loop (on 64-bit Lnx,
    >> Windows; > > > not in 32-bit) > > > +
    >> tools::assertWarning(p <- pchisq(1.00000012e200,
    >> df=1e200, ncp=100), > > > + "simpleWarning",
    >> verbose=TRUE) > > > + stopifnot(p == 1) > > > + } > > >
    >> Asserted warning: pnchisq(x=1e+200, f=1e+200, theta=100,
    >> ..): not > > > converged in 1000000 iter.
    >> > > >
    >> > > > [This may be OK, AA]
    >> > > >
    >> > > > > ## Show the (mostly) small differences : > > > >
    >> all.equal( qs, qpU, tol=0) > > > [1] "Mean relative
    >> difference: 1.572997e-16" > > > > all.equal(-qs, qp.,
    >> tol=0) > > > [1] "Mean relative difference: 1.572997e-16"
    >> > > > > all.equal(-qp.,qpU, tol=0) # typically TRUE (<==>
    >> exact equality) > > > [1] "Mean relative difference:
    >> 4.710277e-16" > > > > stopifnot(exprs = { > > > +
    >> all.equal( qs, qpU, tol=1e-15) > > > + all.equal(-qs,
    >> qp., tol=1e-15) > > > + all.equal(-qp., qpU, tol=1e-15)#
    >> diff of 4.71e-16 in 4.1.0 w/icc > > > (Eric Weese) > > >
    >> + }) > > > > ## both failed very badly in R <= 4.0.x
    >> > > >
    >> > > > ______________________________________________ > >
    >> > R-devel at r-project.org mailing list > > >
    >> https://stat.ethz.ch/mailman/listinfo/r-devel


From @vr@h@m@@d|er @end|ng |rom gm@||@com  Wed Nov 24 18:32:09 2021
From: @vr@h@m@@d|er @end|ng |rom gm@||@com (Avraham Adler)
Date: Wed, 24 Nov 2021 17:32:09 +0000
Subject: [Rd] R-devel (r81196) hanging at dchisq(large) (PR#13309)
In-Reply-To: <20211124114507.5B4DC1C1DB0@lynne.math.ethz.ch>
References: <CAL6gwn+-zy+RjX+toMptU6nyOc5bwQix4WDHbkgWAXwCTYEwqA@mail.gmail.com>
 <24979.28479.945404.466101@stat.math.ethz.ch>
 <CAL6gwnJuPnwS9GXvd0O80H3rRXxAUWrmUncOkrDECB2B+X-+8w@mail.gmail.com>
 <CAJXgQP1Hz2eKBObhGzgO6iEo0k3AJetWiii4t86Xu3Gvir+6nw@mail.gmail.com>
 <CAL6gwnKMhbCZf7EnQ0pLKqxv5LSf1R=1zfLZXiZfitBPLsa_0Q@mail.gmail.com>
 <CAL6gwnKG-vXqkfrnnbqbu2-VP_fPgVFX5yE5Svg0MNeYix_PQg@mail.gmail.com>
 <CAL6gwnLEKoAmzuaFFV0vo_XGOt6gnStnP=00ojHLNv4WYHvGHA@mail.gmail.com>
 <20211124114507.5B4DC1C1DB0@lynne.math.ethz.ch>
Message-ID: <CAL6gwnK_7FUgCFguv5qEaoRD9stSU3oyko23WvbL+O=FJ3OzUg@mail.gmail.com>

On Wed, Nov 24, 2021 at 11:45 AM Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>
> >>>>> Avraham Adler  on Thu, 18 Nov 2021 02:18:54 +0000 writes:
>
>     > Hello.  I have isolated the issue: it is the
>     > fused-multiply-add instruction set (FMA on Intel
>     > processors). Running -march=skylake -mno-fma not only does
>     > not hang, but passes make check-all (using R's native
>     > BLAS).  My intuition remains that something in the new
>     > more precise ebd0 code used in dpois_raw?called by dgamma,
>     > called by dchsq, called by dnchisq?is hanging when the
>     > assembler uses FMA. Unfortunately, I have come across
>     > other cases online where the extra precision and the
>     > different assembler code of FMA vs. non-FMA has caused
>     > bugs, such as [1]. Page 5 of this paper by Dr. William
>     > Kahan sheds some light on why this may be happening [2]
>     > (PDF).
>
>     > Martin & Morton, having written (PR#15628 [3]) and/or
>     > implemented the ebd0 code that is now being used, can
>     > either of you think of any reason why it would hang if
>     > compiled using FMA?
>
> I vaguely remember I had a version of ebd0(), either Morton
> Welinder's original, or a slight modification of it that needed some
> mending, because in some border case, there was an out of
> array-boundary indexing... but that's just a vague recollection.
>
> I had investigated  ebd0()'s behavior quite a bit, also notably
> the version -- together with a pure R code version --
> in my CRAN package DPQ, yesterday updated to version 0.5-0 on CRAN
> {written in Summer, but published to CRAN only yesterday}
> where I have  dpois_raw() optionally using several experimental versions of
> bd0(), and both 'pure R' and a C version of ebd0(),
> as DPQ::ebd0() and DPQ::edb0C()
> each with an option  'verbose' which shows you which branches are chosen
> for the given arguments.
>
> So, if you install this version (0.5-0 or newer) from the development
> sources, using the *same* FMA configuration,
> I hope you should see the same "hanging" but would be able to see some
> more.. ?
>
> Can you install it from R-forge
>
>     install.packages("DPQ", type = "source",
>                      repos="http://R-Forge.R-project.org")
>
> and then experiment?
> I'd be grateful  {and we maybe can move "off - mailing list"}
>
> Thank you in advance,
> Martin
>
> Martin Maechler
> ETH Zurich  and  R Core team

Sure. Responding here simply for closure. Will direct further
questions and output directly to you.

Thank yyou,

Avi


From Kurt@Horn|k @end|ng |rom wu@@c@@t  Fri Nov 26 08:56:41 2021
From: Kurt@Horn|k @end|ng |rom wu@@c@@t (Kurt Hornik)
Date: Fri, 26 Nov 2021 08:56:41 +0100
Subject: [Rd] documentation of asplit
In-Reply-To: <14cd7dda14694be2b32fc3cb77def786@SCWPR-EXDAG1-6A.aphm.ap-hm.fr>
References: <14cd7dda14694be2b32fc3cb77def786@SCWPR-EXDAG1-6A.aphm.ap-hm.fr>
Message-ID: <24992.37689.948900.352740@hornik.net>

>>>>> SOEIRO Thomas writes:

> Dear list,

> The documentation of `asplit` currently says (section Details): "apply
> *always* simplifies common length results, so attempting to split via
> apply(x, MARGIN, identity) does not work (as it simply gives x)."

> This may be updated (e.g., by simply removing "always") since `apply`
> recently gained a `simplify` argument.

Thanks.  Finally updated now.

Best
-k

> Best,

> Thomas

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From wewo|@k| @end|ng |rom gm@||@com  Fri Nov 26 14:40:18 2021
From: wewo|@k| @end|ng |rom gm@||@com (Witold E Wolski)
Date: Fri, 26 Nov 2021 14:40:18 +0100
Subject: [Rd] * checking CRAN incoming feasibility ... NOTE
Message-ID: <CAAjnpdiXjJd89dHXPsZdLoSu7mrNjyQAKzgPTEjAs89=iAvY1w@mail.gmail.com>

I am submitting a package to CRAN and I am asked to fix 2 NOTE's
I am not sure how I should ask the following NOTE?

<message>
* this is package 'sigora' version '3.0.9'
* checking CRAN incoming feasibility ... NOTE
Maintainer: 'Witold Wolski <wew at fgcz.ethz.ch>'

New submission

Package was archived on CRAN

License components with restrictions and base license permitting such:
  GPL-3 + file LICENSE
File 'LICENSE':
                      GNU GENERAL PUBLIC LICENSE
                         Version 3, 29 June 2007

   Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>
   Everyone is permitted to copy and distribute verbatim copies
   of this license document, but changing it is not allowed.
 <message/>

Best regards
Witold


-- 
Witold Eryk Wolski


From edd @end|ng |rom deb|@n@org  Fri Nov 26 16:00:54 2021
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Fri, 26 Nov 2021 09:00:54 -0600
Subject: [Rd] * checking CRAN incoming feasibility ... NOTE
In-Reply-To: <CAAjnpdiXjJd89dHXPsZdLoSu7mrNjyQAKzgPTEjAs89=iAvY1w@mail.gmail.com>
References: <CAAjnpdiXjJd89dHXPsZdLoSu7mrNjyQAKzgPTEjAs89=iAvY1w@mail.gmail.com>
Message-ID: <24992.63142.987837.745948@rob.eddelbuettel.com>


On 26 November 2021 at 14:40, Witold E Wolski wrote:
| I am submitting a package to CRAN and I am asked to fix 2 NOTE's
| I am not sure how I should ask the following NOTE?
| 
| <message>
| * this is package 'sigora' version '3.0.9'
| * checking CRAN incoming feasibility ... NOTE
| Maintainer: 'Witold Wolski <wew at fgcz.ethz.ch>'
| 
| New submission

Well, yes.
 
| Package was archived on CRAN

No idea. Was that your package too? If not are you trying to replace with new
functionality under old name?  Can you explain?
 
| License components with restrictions and base license permitting such:
|   GPL-3 + file LICENSE
| File 'LICENSE':
|                       GNU GENERAL PUBLIC LICENSE
|                          Version 3, 29 June 2007

That's wrong. You do not need a 'LICENSE', just use 'License: GPL-3' if that
is your preference.

Note that https://github.com/cran/ gives you an easy way to browse among the
sources of 18+ thousand packages and search.

Dirk

-- 
https://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From wewo|@k| @end|ng |rom gm@||@com  Fri Nov 26 17:09:04 2021
From: wewo|@k| @end|ng |rom gm@||@com (Witold E Wolski)
Date: Fri, 26 Nov 2021 17:09:04 +0100
Subject: [Rd] * checking CRAN incoming feasibility ... NOTE
In-Reply-To: <24992.63142.987837.745948@rob.eddelbuettel.com>
References: <CAAjnpdiXjJd89dHXPsZdLoSu7mrNjyQAKzgPTEjAs89=iAvY1w@mail.gmail.com>
 <24992.63142.987837.745948@rob.eddelbuettel.com>
Message-ID: <CAAjnpdgbq16vsXrZhaeTYn6ixNfR+vR=CADDx0R44DAbpETDTg@mail.gmail.com>

Dear Dirk,

We have been using the package at work since 2018. We made some
feature requests in 2019 to the maintainer and Author Amir B.K.
Foroushani and was so kind to
 implement them for us and release a new version in 2019. But then, in
April 2020, the package was archived on CRAN. Since then were are
installing it from the archived zip.
 Later I forked the github.com/cran/sigora repository.
 I did contact the previous maintainer several times during the last
(2020) and this year and did not get a reply.
Therefore, I would like to take over the Maintenance of the sigora
package and resubmit it to CRAN. I hope that this is OK.
I made only cosmetic changes to the documentation, e.g., I created a
vignette and removed the warnings and notes.


Best regards
Witold

On Fri, 26 Nov 2021 at 16:00, Dirk Eddelbuettel <edd at debian.org> wrote:
>
>
> On 26 November 2021 at 14:40, Witold E Wolski wrote:
> | I am submitting a package to CRAN and I am asked to fix 2 NOTE's
> | I am not sure how I should ask the following NOTE?
> |
> | <message>
> | * this is package 'sigora' version '3.0.9'
> | * checking CRAN incoming feasibility ... NOTE
> | Maintainer: 'Witold Wolski <wew at fgcz.ethz.ch>'
> |
> | New submission
>
> Well, yes.
>
> | Package was archived on CRAN
>
> No idea. Was that your package too? If not are you trying to replace with new
> functionality under old name?  Can you explain?
>
> | License components with restrictions and base license permitting such:
> |   GPL-3 + file LICENSE
> | File 'LICENSE':
> |                       GNU GENERAL PUBLIC LICENSE
> |                          Version 3, 29 June 2007
>
> That's wrong. You do not need a 'LICENSE', just use 'License: GPL-3' if that
> is your preference.
>
> Note that https://github.com/cran/ gives you an easy way to browse among the
> sources of 18+ thousand packages and search.
>
> Dirk
>
> --
> https://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org



-- 
Witold Eryk Wolski


From edd @end|ng |rom deb|@n@org  Fri Nov 26 19:13:36 2021
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Fri, 26 Nov 2021 12:13:36 -0600
Subject: [Rd] * checking CRAN incoming feasibility ... NOTE
In-Reply-To: <CAAjnpdgbq16vsXrZhaeTYn6ixNfR+vR=CADDx0R44DAbpETDTg@mail.gmail.com>
References: <CAAjnpdiXjJd89dHXPsZdLoSu7mrNjyQAKzgPTEjAs89=iAvY1w@mail.gmail.com>
 <24992.63142.987837.745948@rob.eddelbuettel.com>
 <CAAjnpdgbq16vsXrZhaeTYn6ixNfR+vR=CADDx0R44DAbpETDTg@mail.gmail.com>
Message-ID: <24993.9168.692517.446539@rob.eddelbuettel.com>


Hi Witold,

On 26 November 2021 at 17:09, Witold E Wolski wrote:
| We have been using the package at work since 2018. We made some
| feature requests in 2019 to the maintainer and Author Amir B.K.
| Foroushani and was so kind to
|  implement them for us and release a new version in 2019. But then, in
| April 2020, the package was archived on CRAN. Since then were are
| installing it from the archived zip.
|  Later I forked the github.com/cran/sigora repository.
|  I did contact the previous maintainer several times during the last
| (2020) and this year and did not get a reply.
| Therefore, I would like to take over the Maintenance of the sigora
| package and resubmit it to CRAN. I hope that this is OK.
| I made only cosmetic changes to the documentation, e.g., I created a
| vignette and removed the warnings and notes.

Thanks, that's very good. Make sure that CRAN knows that when you upload.

(And I would correct the License: field to 'GPL (>= 3)' removing the
reference to a file. I can't think off the top of my head of a good example
of an 'adopted' orphaned package, there are probably good ways to properly
credit the previous contributors. I have used inst/AUTHORS before, maybe that
would be a suitable for you too.)

Dirk

-- 
https://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


