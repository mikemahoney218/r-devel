From @purd|e@@ @end|ng |rom gm@||@com  Fri Aug  2 00:11:53 2019
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Fri, 2 Aug 2019 10:11:53 +1200
Subject: [Rd] Rtools contains Python interpreter(s), and six copies?
Message-ID: <CAB8pepzSxMapyHhgSLDfUUW0fWZ-pdYh0+WZC0r4coqQkSZyOg@mail.gmail.com>

I've just discovered that Rtools (on Windows) contains Python
interpreter(s).
I'm assuming that Python is required to build R packages, on all operating
systems.

I think this is a mistake.

Also, by my count, Rtools contains six Python interpreters.
I've miscounted, I hope...

	[[alternative HTML version deleted]]


From m|ch@e|ch|r|co4 @end|ng |rom gm@||@com  Fri Aug  2 09:29:34 2019
From: m|ch@e|ch|r|co4 @end|ng |rom gm@||@com (Michael Chirico)
Date: Fri, 2 Aug 2019 15:29:34 +0800
Subject: [Rd] bug: write.dcf converts hyphen in field name to period
Message-ID: <CAPRVBcwBTR+dPAzigA9OQvd-Vy3mX4KP+GJmP67m8quFsYHV9w@mail.gmail.com>

write.dcf(list('my-field' = 1L), tmp <- tempfile())

cat(readLines(tmp))
# my.field: 1

However there's nothing wrong with hyphenated fields per the Debian
standard:

https://www.debian.org/doc/debian-policy/ch-controlfields.html

And in fact we see them using hyphenated fields there, and indeed read.dcf
handles this just fine:

writeLines(gsub('.', '-', readLines(tmp), fixed = TRUE), tmp)
read.dcf(tmp)
#      my-field
# [1,] "1"

The guilty line is as.data.frame:

if(!is.data.frame(x)) x <- as.data.frame(x, stringsAsFactors = FALSE)

For my case, simply adding check.names=FALSE to this call would solve the
issue in my case, but I think not in general. Here's what I see in the
standard:

> The field name is composed of US-ASCII characters excluding control
characters, space, and colon (i.e., characters in the ranges U+0021 (!)
through U+0039 (9), and U+003B (;) through U+007E (~), inclusive). Field
names must not begin with the comment character (U+0023 #), nor with the
hyphen character (U+002D -).

This could be handled by an adjustment to the next line:

nmx <- names(x)

becomes

nmx <- gsub('^[#-]', '', gsub('[^\U{0021}-\U{0039}\U{003B}-\U{007E}]', '.',
names(x)))

(Or maybe errors for having invalid names)

Michael Chirico

	[[alternative HTML version deleted]]


From @uny|j|@ng @end|ng |rom gm@||@com  Fri Aug  2 10:23:00 2019
From: @uny|j|@ng @end|ng |rom gm@||@com (Sun Yijiang)
Date: Fri, 2 Aug 2019 16:23:00 +0800
Subject: [Rd] Infrequent but steady NULL-pointer caused segfault in
 as.POSIXlt.POSIXct (R 3.4.4)
Message-ID: <CAL109eM4576ye7Jo9LUfPqncMSLb1Bg4XzMiC7e=w+h7ig4usw@mail.gmail.com>

The R script I run daily for hours looks like this:

while (!finish) {
    Sys.sleep(0.1)
    time = as.integer(format(Sys.time(), "%H%M")) # always crash here
    if (new.data.timestamp() <= time)
        next
    # ... do some jobs for about 2 minutes ...
    gc()
}

Basically it waits for new data, which comes in every 10 minutes, and
do some jobs, then gc(), then loop again.  It works great most of the
time, but crashes strangely once a month or so.  Although infrequent,
it always crashes at the same place and gives the same error info,
like this:

 *** caught segfault ***
address (nil), cause 'memory not mapped'

Traceback:
 1: as.POSIXlt.POSIXct(x, tz)
 2: as.POSIXlt(x, tz)
 3: format.POSIXlt(as.POSIXlt(x, tz), format, usetz, ...)
 4: structure(format.POSIXlt(as.POSIXlt(x, tz), format, usetz, ...),
  names = names(x))
 5: format.POSIXct(Sys.time(), format = "%H%M")
 6: format(Sys.time(), format = "%H%M")
 7: format(Sys.time(), format = "%H%M")
? ?

I looked into the dumped core with gdb, and found something very strange:

gdb /usr/lib64/R/bin/exec/R ~/core.30387
(gdb) bt 5
#0  0x00007f1dca844ff1 in __strlen_sse2_pminub () from /lib64/libc.so.6
#1  0x00007f1dcb20e8f9 in Rf_mkChar (name=0x0) at envir.c:3725
#2  0x00007f1dcb1dc225 in do_asPOSIXlt (call=<optimized out>,
op=<optimized out>, args=<optimized out>,
    env=<optimized out>) at datetime.c:705
#3  0x00007f1dcb22197f in bcEval (body=body at entry=0x4064b28,
rho=rho at entry=0xc449d38, useCache=useCache at entry=TRUE)
    at eval.c:6473
#4  0x00007f1dcb230370 in Rf_eval (e=0x4064b28,
rho=rho at entry=0xc449d38) at eval.c:624
(More stack frames follow?)

Tracing into src/main/datetime.c:705, it?s a simple string-making code:
SET_STRING_ELT(tzone, 1, mkChar(R_tzname[0]));

mkChar function is defined in envir.c:3725:
3723  SEXP mkChar(const char *name)
3724  {
3725      size_t len =  strlen(name);
? ?

gdb shows that the string pointer (name=0x0) mkChar received is NULL,
and subsequently strlen(NULL) caused the segfault.  But quite
contradictorily, gdb shows the value passed to mkChar in the caller is
valid:

(gdb) frame 2
#2  0x00007f1dcb1dc225 in do_asPOSIXlt (call=<optimized out>,
op=<optimized out>, args=<optimized out>,
    env=<optimized out>) at datetime.c:705
705 datetime.c: No such file or directory.
(gdb) p tzname[0]
$1 = 0x4cf39c0 ?CST?

R_tzname is an alias of tzname. (#define R_tzname tzname in the same file.)

At first, I suspect that some library may have messed up the memory
and accidentally zeroed tzname (a global variable).  But with this gdb
trace, it shows that tzname is good, only that the pointer passed to
mkChar magically changed to zero.  Like this:

mkChar(tzname[0])  // tzname[0] is ?CST?, address 0x4cf39c
? ?
SEXP mkChar(const char *name)  // name should be 0x4cf39c, but gdb shows 0x0
{
    size_t len =  strlen(name);  // segfault, as name is NULL
? ?

The only theory I can think of so far is that, on calling mkChar, the
parameter passed on stack somehow got wiped out to zero by some buggy
code in R or library.  At a higher level, what I see is this:  If you
run format(Sys.time(), "%H%M?) a million times a day (together with
other codes of course), once in a month or so this simple line can
segfault.

I?m lost in this confusion, could someone please help me find the
right direction to further look into this problem?

Regards,
Steve


From tom@@@k@||ber@ @end|ng |rom gm@||@com  Fri Aug  2 10:59:02 2019
From: tom@@@k@||ber@ @end|ng |rom gm@||@com (Tomas Kalibera)
Date: Fri, 2 Aug 2019 10:59:02 +0200
Subject: [Rd] Infrequent but steady NULL-pointer caused segfault in
 as.POSIXlt.POSIXct (R 3.4.4)
In-Reply-To: <CAL109eM4576ye7Jo9LUfPqncMSLb1Bg4XzMiC7e=w+h7ig4usw@mail.gmail.com>
References: <CAL109eM4576ye7Jo9LUfPqncMSLb1Bg4XzMiC7e=w+h7ig4usw@mail.gmail.com>
Message-ID: <40fd99c8-2432-7239-f930-325706a887f0@gmail.com>

In an optimized build, debug info is just an approximation. It might 
help to debug in a build of R and packages without compiler 
optimizations (-O0), where the debug information is accurate. However, 
first I would try to modify the example to trigger more often, or try to 
find external ways to make it trigger more often (e.g. via gctorture). 
Then I would try to make the example smaller (not call gc() explicitly, 
not call any external code - e.g. the jobs, etc) - any time the example 
is reduced but still triggers the errors, the reasoning is made easier. 
Once you have a repeatable situation in a build with reliable debug 
symbols, debugging is easier too, e.g. sometimes a watchpoint helps to 
find memory corruption. Please feel free to ask more when you have more 
information/updates. If this ends up being a bug in R, please report 
(and with a reproducible example, if it is not obvious from the source 
code).

Best
Tomas


On 8/2/19 10:23 AM, Sun Yijiang wrote:
> The R script I run daily for hours looks like this:
>
> while (!finish) {
>      Sys.sleep(0.1)
>      time = as.integer(format(Sys.time(), "%H%M")) # always crash here
>      if (new.data.timestamp() <= time)
>          next
>      # ... do some jobs for about 2 minutes ...
>      gc()
> }
>
> Basically it waits for new data, which comes in every 10 minutes, and
> do some jobs, then gc(), then loop again.  It works great most of the
> time, but crashes strangely once a month or so.  Although infrequent,
> it always crashes at the same place and gives the same error info,
> like this:
>
>   *** caught segfault ***
> address (nil), cause 'memory not mapped'
>
> Traceback:
>   1: as.POSIXlt.POSIXct(x, tz)
>   2: as.POSIXlt(x, tz)
>   3: format.POSIXlt(as.POSIXlt(x, tz), format, usetz, ...)
>   4: structure(format.POSIXlt(as.POSIXlt(x, tz), format, usetz, ...),
>    names = names(x))
>   5: format.POSIXct(Sys.time(), format = "%H%M")
>   6: format(Sys.time(), format = "%H%M")
>   7: format(Sys.time(), format = "%H%M")
> ? ?
>
> I looked into the dumped core with gdb, and found something very strange:
>
> gdb /usr/lib64/R/bin/exec/R ~/core.30387
> (gdb) bt 5
> #0  0x00007f1dca844ff1 in __strlen_sse2_pminub () from /lib64/libc.so.6
> #1  0x00007f1dcb20e8f9 in Rf_mkChar (name=0x0) at envir.c:3725
> #2  0x00007f1dcb1dc225 in do_asPOSIXlt (call=<optimized out>,
> op=<optimized out>, args=<optimized out>,
>      env=<optimized out>) at datetime.c:705
> #3  0x00007f1dcb22197f in bcEval (body=body at entry=0x4064b28,
> rho=rho at entry=0xc449d38, useCache=useCache at entry=TRUE)
>      at eval.c:6473
> #4  0x00007f1dcb230370 in Rf_eval (e=0x4064b28,
> rho=rho at entry=0xc449d38) at eval.c:624
> (More stack frames follow?)
>
> Tracing into src/main/datetime.c:705, it?s a simple string-making code:
> SET_STRING_ELT(tzone, 1, mkChar(R_tzname[0]));
>
> mkChar function is defined in envir.c:3725:
> 3723  SEXP mkChar(const char *name)
> 3724  {
> 3725      size_t len =  strlen(name);
> ? ?
>
> gdb shows that the string pointer (name=0x0) mkChar received is NULL,
> and subsequently strlen(NULL) caused the segfault.  But quite
> contradictorily, gdb shows the value passed to mkChar in the caller is
> valid:
>
> (gdb) frame 2
> #2  0x00007f1dcb1dc225 in do_asPOSIXlt (call=<optimized out>,
> op=<optimized out>, args=<optimized out>,
>      env=<optimized out>) at datetime.c:705
> 705 datetime.c: No such file or directory.
> (gdb) p tzname[0]
> $1 = 0x4cf39c0 ?CST?
>
> R_tzname is an alias of tzname. (#define R_tzname tzname in the same file.)
>
> At first, I suspect that some library may have messed up the memory
> and accidentally zeroed tzname (a global variable).  But with this gdb
> trace, it shows that tzname is good, only that the pointer passed to
> mkChar magically changed to zero.  Like this:
>
> mkChar(tzname[0])  // tzname[0] is ?CST?, address 0x4cf39c
> ? ?
> SEXP mkChar(const char *name)  // name should be 0x4cf39c, but gdb shows 0x0
> {
>      size_t len =  strlen(name);  // segfault, as name is NULL
> ? ?
>
> The only theory I can think of so far is that, on calling mkChar, the
> parameter passed on stack somehow got wiped out to zero by some buggy
> code in R or library.  At a higher level, what I see is this:  If you
> run format(Sys.time(), "%H%M?) a million times a day (together with
> other codes of course), once in a month or so this simple line can
> segfault.
>
> I?m lost in this confusion, could someone please help me find the
> right direction to further look into this problem?
>
> Regards,
> Steve
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From S@E|||@on @end|ng |rom LGCGroup@com  Fri Aug  2 12:26:20 2019
From: S@E|||@on @end|ng |rom LGCGroup@com (Stephen Ellison)
Date: Fri, 2 Aug 2019 10:26:20 +0000
Subject: [Rd] R evolution suggestion request
In-Reply-To: <CAN--Dz29svNZJsJHmDCrBFB79+rFuk+7BmjQfhoLr8eupbRgtA@mail.gmail.com>
References: <CAN--Dz0HiEj3Up4SCTLng_VGP829fZsYyRDj5SKPO58XaqK62w@mail.gmail.com>
 <CAN--Dz29svNZJsJHmDCrBFB79+rFuk+7BmjQfhoLr8eupbRgtA@mail.gmail.com>
Message-ID: <ef92671d56c14343bf6f73e0f5c780ab@GBDCVPEXC08.corp.lgc-group.com>

> It is pure native R annotation, I mean ? la java. I wish to have an @
> operator available a R language level to create/embed real code
> annotations. Currently, the best I can get is to use a trick of hiding such
> thing behind a comment. Neither good, not the right way, as comments are
> comments, and annotations are annotations. They must be distinguished and
> distinguish-able immediately, both for humans and code parsers.

I can't comment on whether R can be extended in that way; that's R-core to answer. 
But @ is the slot extraction operator in S4 (see ?"@") so you'd need another operator symbol. 

But for faintly java-like annotation used for documentation and namespace management, you could look at the roxygen package; see 
https://cran.r-project.org/web/packages/roxygen2/vignettes/roxygen2.html

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From jeroenoom@ @end|ng |rom gm@||@com  Fri Aug  2 14:48:35 2019
From: jeroenoom@ @end|ng |rom gm@||@com (Jeroen Ooms)
Date: Fri, 2 Aug 2019 14:48:35 +0200
Subject: [Rd] Rtools contains Python interpreter(s), and six copies?
In-Reply-To: <CAB8pepzSxMapyHhgSLDfUUW0fWZ-pdYh0+WZC0r4coqQkSZyOg@mail.gmail.com>
References: <CAB8pepzSxMapyHhgSLDfUUW0fWZ-pdYh0+WZC0r4coqQkSZyOg@mail.gmail.com>
Message-ID: <CABFfbXtZm9E999opXzEBgwS6q5++GQXLd5zXmXhtcZtAcWPfXA@mail.gmail.com>

On Fri, Aug 2, 2019 at 12:12 AM Abby Spurdle <spurdle.a at gmail.com> wrote:
>
> I've just discovered that Rtools (on Windows) contains Python
> interpreter(s).

A minimal build of python was included as a dependency of gdb in
Rtools 3.3 and up.

> I'm assuming that Python is required to build R packages, on all operating
> systems.

Please don't assume but read the documentation (preferably before posting).

> Also, by my count, Rtools contains six Python interpreters.
> I've miscounted, I hope...

We have a dual toolchain so there is a 32 and a 64 bit build of
python2.7.exe. The other names (python.exe and python2.exe) are
symlinks that python automatically creates. These are not in any
location that is ever on the path so nothing to worry about.


From edd @end|ng |rom deb|@n@org  Fri Aug  2 16:24:07 2019
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Fri, 2 Aug 2019 09:24:07 -0500
Subject: [Rd] Infrequent but steady NULL-pointer caused segfault in
 as.POSIXlt.POSIXct (R 3.4.4)
In-Reply-To: <CAL109eM4576ye7Jo9LUfPqncMSLb1Bg4XzMiC7e=w+h7ig4usw@mail.gmail.com>
References: <CAL109eM4576ye7Jo9LUfPqncMSLb1Bg4XzMiC7e=w+h7ig4usw@mail.gmail.com>
Message-ID: <23876.18311.906487.977359@rob.eddelbuettel.com>


On 2 August 2019 at 16:23, Sun Yijiang wrote:
| The R script I run daily for hours looks like this:
| 
| while (!finish) {
|     Sys.sleep(0.1)
|     time = as.integer(format(Sys.time(), "%H%M")) # always crash here
|     if (new.data.timestamp() <= time)
|         next
|     # ... do some jobs for about 2 minutes ...
|     gc()
| }
| 
| Basically it waits for new data, which comes in every 10 minutes, and
| do some jobs, then gc(), then loop again.  It works great most of the
| time, but crashes strangely once a month or so.  Although infrequent,
| it always crashes at the same place and gives the same error info,
| like this:

A really long time ago in a galaxy not too far away I also shephearded such
jobs where the job were left running for a long time from a single "outer"
call, and aimed to control resources via gc(), Sys.sleep()and alike.

Doing that, I learned a different session.  As R is an fact _an environment_
taking care of a great many things, robustness can be had more easily via
fresh processes.  Since then I mostly control the jobs _from the outside_ via
cron, and aim to have well-defined taks (with few dependencies, a different
topic).  I do the same for e.g. package testing and loading/unloading of
shared libraries: hard to get right, easier to test in vanilla sessions.

These are also some of the reasons I joined Jeff Horner in his then-nascient
littler project, and continue to look after it. I run many (automated) jobs
with it from cron, and this generally works _great_.  Rscript came just a
little bit later, has also improved over time and is a fine alternative.

Lastly, I would recommend to take advantage of the fact that POSIXct is in
fact numeric internally and rewrite this as

     currentTime <- as.numeric(Sys.time())
     if (currentTime > prevTime + minDelta) {
        # do stuff ...
        prevTime <- currentTime
     }

That alone may help you as you no longer need all the temporary string
objects you were chasing through the debugger.

Good luck, and keep re-engineering your scripts. R can be a very, very
reliable tool when driven the right way.

Cheers, Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From wdun|@p @end|ng |rom t|bco@com  Fri Aug  2 16:50:52 2019
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Fri, 2 Aug 2019 07:50:52 -0700
Subject: [Rd] Infrequent but steady NULL-pointer caused segfault in
 as.POSIXlt.POSIXct (R 3.4.4)
In-Reply-To: <CAL109eM4576ye7Jo9LUfPqncMSLb1Bg4XzMiC7e=w+h7ig4usw@mail.gmail.com>
References: <CAL109eM4576ye7Jo9LUfPqncMSLb1Bg4XzMiC7e=w+h7ig4usw@mail.gmail.com>
Message-ID: <CAF8bMcbEHBNgj-eTcXZN21Hf+NrYk6_f0w4JdyMmLpMa1_n9FQ@mail.gmail.com>

If you can run things on LInux try running a few iterations of that loop
under valgrind, setting gctorture(TRUE) before the loop.

% R --debugger=valgrind --silent
> gctorture(TRUE)
> for(i in 1:5) { ... body of your loop ... }

valgrind can show memory misuse that eventually will cause R to crash.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Aug 2, 2019 at 1:23 AM Sun Yijiang <sunyijiang at gmail.com> wrote:

> The R script I run daily for hours looks like this:
>
> while (!finish) {
>     Sys.sleep(0.1)
>     time = as.integer(format(Sys.time(), "%H%M")) # always crash here
>     if (new.data.timestamp() <= time)
>         next
>     # ... do some jobs for about 2 minutes ...
>     gc()
> }
>
> Basically it waits for new data, which comes in every 10 minutes, and
> do some jobs, then gc(), then loop again.  It works great most of the
> time, but crashes strangely once a month or so.  Although infrequent,
> it always crashes at the same place and gives the same error info,
> like this:
>
>  *** caught segfault ***
> address (nil), cause 'memory not mapped'
>
> Traceback:
>  1: as.POSIXlt.POSIXct(x, tz)
>  2: as.POSIXlt(x, tz)
>  3: format.POSIXlt(as.POSIXlt(x, tz), format, usetz, ...)
>  4: structure(format.POSIXlt(as.POSIXlt(x, tz), format, usetz, ...),
>   names = names(x))
>  5: format.POSIXct(Sys.time(), format = "%H%M")
>  6: format(Sys.time(), format = "%H%M")
>  7: format(Sys.time(), format = "%H%M")
> ? ?
>
> I looked into the dumped core with gdb, and found something very strange:
>
> gdb /usr/lib64/R/bin/exec/R ~/core.30387
> (gdb) bt 5
> #0  0x00007f1dca844ff1 in __strlen_sse2_pminub () from /lib64/libc.so.6
> #1  0x00007f1dcb20e8f9 in Rf_mkChar (name=0x0) at envir.c:3725
> #2  0x00007f1dcb1dc225 in do_asPOSIXlt (call=<optimized out>,
> op=<optimized out>, args=<optimized out>,
>     env=<optimized out>) at datetime.c:705
> #3  0x00007f1dcb22197f in bcEval (body=body at entry=0x4064b28,
> rho=rho at entry=0xc449d38, useCache=useCache at entry=TRUE)
>     at eval.c:6473
> #4  0x00007f1dcb230370 in Rf_eval (e=0x4064b28,
> rho=rho at entry=0xc449d38) at eval.c:624
> (More stack frames follow?)
>
> Tracing into src/main/datetime.c:705, it?s a simple string-making code:
> SET_STRING_ELT(tzone, 1, mkChar(R_tzname[0]));
>
> mkChar function is defined in envir.c:3725:
> 3723  SEXP mkChar(const char *name)
> 3724  {
> 3725      size_t len =  strlen(name);
> ? ?
>
> gdb shows that the string pointer (name=0x0) mkChar received is NULL,
> and subsequently strlen(NULL) caused the segfault.  But quite
> contradictorily, gdb shows the value passed to mkChar in the caller is
> valid:
>
> (gdb) frame 2
> #2  0x00007f1dcb1dc225 in do_asPOSIXlt (call=<optimized out>,
> op=<optimized out>, args=<optimized out>,
>     env=<optimized out>) at datetime.c:705
> 705 datetime.c: No such file or directory.
> (gdb) p tzname[0]
> $1 = 0x4cf39c0 ?CST?
>
> R_tzname is an alias of tzname. (#define R_tzname tzname in the same file.)
>
> At first, I suspect that some library may have messed up the memory
> and accidentally zeroed tzname (a global variable).  But with this gdb
> trace, it shows that tzname is good, only that the pointer passed to
> mkChar magically changed to zero.  Like this:
>
> mkChar(tzname[0])  // tzname[0] is ?CST?, address 0x4cf39c
> ? ?
> SEXP mkChar(const char *name)  // name should be 0x4cf39c, but gdb shows
> 0x0
> {
>     size_t len =  strlen(name);  // segfault, as name is NULL
> ? ?
>
> The only theory I can think of so far is that, on calling mkChar, the
> parameter passed on stack somehow got wiped out to zero by some buggy
> code in R or library.  At a higher level, what I see is this:  If you
> run format(Sys.time(), "%H%M?) a million times a day (together with
> other codes of course), once in a month or so this simple line can
> segfault.
>
> I?m lost in this confusion, could someone please help me find the
> right direction to further look into this problem?
>
> Regards,
> Steve
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Sat Aug  3 00:36:19 2019
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sat, 3 Aug 2019 10:36:19 +1200
Subject: [Rd] Rtools contains Python interpreter(s), and six copies?
In-Reply-To: <CABFfbXtZm9E999opXzEBgwS6q5++GQXLd5zXmXhtcZtAcWPfXA@mail.gmail.com>
References: <CAB8pepzSxMapyHhgSLDfUUW0fWZ-pdYh0+WZC0r4coqQkSZyOg@mail.gmail.com>
 <CABFfbXtZm9E999opXzEBgwS6q5++GQXLd5zXmXhtcZtAcWPfXA@mail.gmail.com>
Message-ID: <CAB8pepzd29=95X25KWBFr6F+AibnQ9biev3YNEvByDd5YcQ76Q@mail.gmail.com>

(Excerpts only).
On Sat, Aug 3, 2019 at 12:48 AM Jeroen Ooms <jeroenooms at gmail.com> wrote:
> > I'm assuming that Python is required to build R packages, on all
operating
> > systems.
> Please don't assume but read the documentation (preferably before
posting).

I can't find one reference to Python in the documentation:

https://cran.r-project.org/bin/windows/Rtools/
https://cran.r-project.org/doc/manuals/R-admin.html#The-Windows-toolset

Please write documentation (preferably before changing R).
And I will read it.

	[[alternative HTML version deleted]]


From |uc@r @end|ng |rom |edor@project@org  Sat Aug  3 02:38:22 2019
From: |uc@r @end|ng |rom |edor@project@org (=?UTF-8?Q?I=C3=B1aki_Ucar?=)
Date: Sat, 3 Aug 2019 02:38:22 +0200
Subject: [Rd] Rtools contains Python interpreter(s), and six copies?
In-Reply-To: <CAB8pepzd29=95X25KWBFr6F+AibnQ9biev3YNEvByDd5YcQ76Q@mail.gmail.com>
References: <CAB8pepzSxMapyHhgSLDfUUW0fWZ-pdYh0+WZC0r4coqQkSZyOg@mail.gmail.com>
 <CABFfbXtZm9E999opXzEBgwS6q5++GQXLd5zXmXhtcZtAcWPfXA@mail.gmail.com>
 <CAB8pepzd29=95X25KWBFr6F+AibnQ9biev3YNEvByDd5YcQ76Q@mail.gmail.com>
Message-ID: <CALEXWq0aquFa_GSS5Qz8Cj6Q+99VO2Dr+oJ3iYo_5rDuNzoQXQ@mail.gmail.com>

On Sat, 3 Aug 2019 at 00:36, Abby Spurdle <spurdle.a at gmail.com> wrote:
>
> I can't find one reference to Python in the documentation:

Maybe because it's *not* needed? There's a note here though:
https://github.com/rwinlib/gcc-4.9.3

I?aki


From @purd|e@@ @end|ng |rom gm@||@com  Sat Aug  3 03:13:22 2019
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sat, 3 Aug 2019 13:13:22 +1200
Subject: [Rd] Rtools contains Python interpreter(s), and six copies?
In-Reply-To: <CALEXWq0aquFa_GSS5Qz8Cj6Q+99VO2Dr+oJ3iYo_5rDuNzoQXQ@mail.gmail.com>
References: <CAB8pepzSxMapyHhgSLDfUUW0fWZ-pdYh0+WZC0r4coqQkSZyOg@mail.gmail.com>
 <CABFfbXtZm9E999opXzEBgwS6q5++GQXLd5zXmXhtcZtAcWPfXA@mail.gmail.com>
 <CAB8pepzd29=95X25KWBFr6F+AibnQ9biev3YNEvByDd5YcQ76Q@mail.gmail.com>
 <CALEXWq0aquFa_GSS5Qz8Cj6Q+99VO2Dr+oJ3iYo_5rDuNzoQXQ@mail.gmail.com>
Message-ID: <CAB8pepzeWFvKrZGLjwZbdDnTA0KLdTYoDF_ey6k-CUmMh-UL4A@mail.gmail.com>

> > I can't find one reference to Python in the documentation:
> Maybe because it's *not* needed? There's a note here though:

Thank you.
I'm deleting it.

	[[alternative HTML version deleted]]


From rkoenker @end|ng |rom ||||no|@@edu  Sun Aug  4 08:48:06 2019
From: rkoenker @end|ng |rom ||||no|@@edu (Koenker, Roger W)
Date: Sun, 4 Aug 2019 06:48:06 +0000
Subject: [Rd] gfortran 9 quantreg bug
Message-ID: <F22FFF48-C157-4269-ACD4-3B58DD83FCCE@illinois.edu>

I?d like to solicit some advice on a debugging problem I have in the quantreg package.
Kurt and Brian have reported to me that on Debian machines with gfortran 9

library(quantreg)
f = summary(rq(foodexp ~ income, data = engel, tau = 1:4/5))
plot(f)

fails because summary() produces bogus estimates of the coefficient bounds.
This example has been around in my R package from the earliest days of R, and
before that in various incarnations of S.  The culprit is apparently rqbr.f which is
even more ancient, but must have something that gfortran 9 doesn?t approve of.

I note that in R-devel there have been some other issues with gfortran 9, but these seem
unrelated to my problem.  Not having access to a machine with an R/gfortran9
configuration, I can?t  apply my rudimentary debugging methods.  I?ve considered
trying to build gfortran on my mac air and then building R from source, but before
going down this road, I wondered whether others had other suggestions, or
advice about  my proposed route.  As far as I can see there are not yet
binaries for gfortran 9 for osx.

Thanks,
Roger

Roger Koenker
r.koenker at ucl.ac.uk<mailto:r.koenker at ucl.ac.uk>
Department of Economics, UCL
London  WC1H 0AX.



	[[alternative HTML version deleted]]


From @uny|j|@ng @end|ng |rom gm@||@com  Sun Aug  4 15:30:58 2019
From: @uny|j|@ng @end|ng |rom gm@||@com (Sun Yijiang)
Date: Sun, 4 Aug 2019 21:30:58 +0800
Subject: [Rd] Infrequent but steady NULL-pointer caused segfault in
 as.POSIXlt.POSIXct (R 3.4.4)
In-Reply-To: <40fd99c8-2432-7239-f930-325706a887f0@gmail.com>
References: <CAL109eM4576ye7Jo9LUfPqncMSLb1Bg4XzMiC7e=w+h7ig4usw@mail.gmail.com>
 <40fd99c8-2432-7239-f930-325706a887f0@gmail.com>
Message-ID: <CAL109eOnkcJjUm+8MW-fMoyy403Xor4SKjHRmXdS9gOnyVQWng@mail.gmail.com>

A reply from stackoverflow suggests I might have hit this bug:

https://sourceware.org/bugzilla/show_bug.cgi?id=14023

I can confirm that this glibc bug affects my system (latest CentOS 7).
However, as far as I know, R is not multithreaded in its core.  Is it
possible that some library triggered this?

Regards,
Steve

Tomas Kalibera <tomas.kalibera at gmail.com> ?2019?8?2??? ??4:59???
>
> In an optimized build, debug info is just an approximation. It might
> help to debug in a build of R and packages without compiler
> optimizations (-O0), where the debug information is accurate. However,
> first I would try to modify the example to trigger more often, or try to
> find external ways to make it trigger more often (e.g. via gctorture).
> Then I would try to make the example smaller (not call gc() explicitly,
> not call any external code - e.g. the jobs, etc) - any time the example
> is reduced but still triggers the errors, the reasoning is made easier.
> Once you have a repeatable situation in a build with reliable debug
> symbols, debugging is easier too, e.g. sometimes a watchpoint helps to
> find memory corruption. Please feel free to ask more when you have more
> information/updates. If this ends up being a bug in R, please report
> (and with a reproducible example, if it is not obvious from the source
> code).
>
> Best
> Tomas
>
>
> On 8/2/19 10:23 AM, Sun Yijiang wrote:
> > The R script I run daily for hours looks like this:
> >
> > while (!finish) {
> >      Sys.sleep(0.1)
> >      time = as.integer(format(Sys.time(), "%H%M")) # always crash here
> >      if (new.data.timestamp() <= time)
> >          next
> >      # ... do some jobs for about 2 minutes ...
> >      gc()
> > }
> >
> > Basically it waits for new data, which comes in every 10 minutes, and
> > do some jobs, then gc(), then loop again.  It works great most of the
> > time, but crashes strangely once a month or so.  Although infrequent,
> > it always crashes at the same place and gives the same error info,
> > like this:
> >
> >   *** caught segfault ***
> > address (nil), cause 'memory not mapped'
> >
> > Traceback:
> >   1: as.POSIXlt.POSIXct(x, tz)
> >   2: as.POSIXlt(x, tz)
> >   3: format.POSIXlt(as.POSIXlt(x, tz), format, usetz, ...)
> >   4: structure(format.POSIXlt(as.POSIXlt(x, tz), format, usetz, ...),
> >    names = names(x))
> >   5: format.POSIXct(Sys.time(), format = "%H%M")
> >   6: format(Sys.time(), format = "%H%M")
> >   7: format(Sys.time(), format = "%H%M")
> > ? ?
> >
> > I looked into the dumped core with gdb, and found something very strange:
> >
> > gdb /usr/lib64/R/bin/exec/R ~/core.30387
> > (gdb) bt 5
> > #0  0x00007f1dca844ff1 in __strlen_sse2_pminub () from /lib64/libc.so.6
> > #1  0x00007f1dcb20e8f9 in Rf_mkChar (name=0x0) at envir.c:3725
> > #2  0x00007f1dcb1dc225 in do_asPOSIXlt (call=<optimized out>,
> > op=<optimized out>, args=<optimized out>,
> >      env=<optimized out>) at datetime.c:705
> > #3  0x00007f1dcb22197f in bcEval (body=body at entry=0x4064b28,
> > rho=rho at entry=0xc449d38, useCache=useCache at entry=TRUE)
> >      at eval.c:6473
> > #4  0x00007f1dcb230370 in Rf_eval (e=0x4064b28,
> > rho=rho at entry=0xc449d38) at eval.c:624
> > (More stack frames follow?)
> >
> > Tracing into src/main/datetime.c:705, it?s a simple string-making code:
> > SET_STRING_ELT(tzone, 1, mkChar(R_tzname[0]));
> >
> > mkChar function is defined in envir.c:3725:
> > 3723  SEXP mkChar(const char *name)
> > 3724  {
> > 3725      size_t len =  strlen(name);
> > ? ?
> >
> > gdb shows that the string pointer (name=0x0) mkChar received is NULL,
> > and subsequently strlen(NULL) caused the segfault.  But quite
> > contradictorily, gdb shows the value passed to mkChar in the caller is
> > valid:
> >
> > (gdb) frame 2
> > #2  0x00007f1dcb1dc225 in do_asPOSIXlt (call=<optimized out>,
> > op=<optimized out>, args=<optimized out>,
> >      env=<optimized out>) at datetime.c:705
> > 705 datetime.c: No such file or directory.
> > (gdb) p tzname[0]
> > $1 = 0x4cf39c0 ?CST?
> >
> > R_tzname is an alias of tzname. (#define R_tzname tzname in the same file.)
> >
> > At first, I suspect that some library may have messed up the memory
> > and accidentally zeroed tzname (a global variable).  But with this gdb
> > trace, it shows that tzname is good, only that the pointer passed to
> > mkChar magically changed to zero.  Like this:
> >
> > mkChar(tzname[0])  // tzname[0] is ?CST?, address 0x4cf39c
> > ? ?
> > SEXP mkChar(const char *name)  // name should be 0x4cf39c, but gdb shows 0x0
> > {
> >      size_t len =  strlen(name);  // segfault, as name is NULL
> > ? ?
> >
> > The only theory I can think of so far is that, on calling mkChar, the
> > parameter passed on stack somehow got wiped out to zero by some buggy
> > code in R or library.  At a higher level, what I see is this:  If you
> > run format(Sys.time(), "%H%M?) a million times a day (together with
> > other codes of course), once in a month or so this simple line can
> > segfault.
> >
> > I?m lost in this confusion, could someone please help me find the
> > right direction to further look into this problem?
> >
> > Regards,
> > Steve
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From bhh @end|ng |rom x@4@||@n|  Sun Aug  4 16:26:40 2019
From: bhh @end|ng |rom x@4@||@n| (Berend Hasselman)
Date: Sun, 4 Aug 2019 16:26:40 +0200
Subject: [Rd] gfortran 9 quantreg bug
In-Reply-To: <F22FFF48-C157-4269-ACD4-3B58DD83FCCE@illinois.edu>
References: <F22FFF48-C157-4269-ACD4-3B58DD83FCCE@illinois.edu>
Message-ID: <01EC6670-8D56-44D7-8A2A-2FC156D76B83@xs4all.nl>

Roger,

I have run

	gfortran -c -fsyntax-only -fimplicit-none -Wall -pedantic rqbr.f

in the src folder of quantreg.

There are many warnings about defined but not used labels.
Also two errors such as "Symbol ?in? at (1) has no IMPLICIT type".
And warnings such as: Warning: "Possible change of value in conversion from REAL(8) to INTEGER(4)  at ..."

No offense intended but this fortran code is awful. I wouldn't want to debug this before an extensive cleanup by
getting rid of as many numerical labels as possible, indenting and doing something about the warnings "Possible change of value ...".

This is going to be very difficult.

Berend Hasselman

> On 4 Aug 2019, at 08:48, Koenker, Roger W <rkoenker at illinois.edu> wrote:
> 
> I?d like to solicit some advice on a debugging problem I have in the quantreg package.
> Kurt and Brian have reported to me that on Debian machines with gfortran 9
> 
> library(quantreg)
> f = summary(rq(foodexp ~ income, data = engel, tau = 1:4/5))
> plot(f)
> 
> fails because summary() produces bogus estimates of the coefficient bounds.
> This example has been around in my R package from the earliest days of R, and
> before that in various incarnations of S.  The culprit is apparently rqbr.f which is
> even more ancient, but must have something that gfortran 9 doesn?t approve of.
> 
> I note that in R-devel there have been some other issues with gfortran 9, but these seem
> unrelated to my problem.  Not having access to a machine with an R/gfortran9
> configuration, I can?t  apply my rudimentary debugging methods.  I?ve considered
> trying to build gfortran on my mac air and then building R from source, but before
> going down this road, I wondered whether others had other suggestions, or
> advice about  my proposed route.  As far as I can see there are not yet
> binaries for gfortran 9 for osx.
> 
> Thanks,
> Roger
> 
> Roger Koenker
> r.koenker at ucl.ac.uk<mailto:r.koenker at ucl.ac.uk>
> Department of Economics, UCL
> London  WC1H 0AX.
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From edd @end|ng |rom deb|@n@org  Sun Aug  4 16:41:00 2019
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Sun, 4 Aug 2019 09:41:00 -0500
Subject: [Rd] gfortran 9 quantreg bug
In-Reply-To: <F22FFF48-C157-4269-ACD4-3B58DD83FCCE@illinois.edu>
References: <F22FFF48-C157-4269-ACD4-3B58DD83FCCE@illinois.edu>
Message-ID: <23878.61052.305001.554120@rob.eddelbuettel.com>


Roger,

On 4 August 2019 at 06:48, Koenker, Roger W wrote:
| I?d like to solicit some advice on a debugging problem I have in the quantreg package.
| Kurt and Brian have reported to me that on Debian machines with gfortran 9
| 
| library(quantreg)
| f = summary(rq(foodexp ~ income, data = engel, tau = 1:4/5))
| plot(f)
| 
| fails because summary() produces bogus estimates of the coefficient bounds.
| This example has been around in my R package from the earliest days of R, and
| before that in various incarnations of S.  The culprit is apparently rqbr.f which is
| even more ancient, but must have something that gfortran 9 doesn?t approve of.
| 
| I note that in R-devel there have been some other issues with gfortran 9, but these seem
| unrelated to my problem.  Not having access to a machine with an R/gfortran9
| configuration, I can?t  apply my rudimentary debugging methods.  I?ve considered
| trying to build gfortran on my mac air and then building R from source, but before
| going down this road, I wondered whether others had other suggestions, or
| advice about  my proposed route.  As far as I can see there are not yet
| binaries for gfortran 9 for osx.

Maybe installing and running Docker on your mac is an alternative?

Minimally viable example using

  a) docker (on Linux, but it is portable) and
  
  b) the current official 'r-base' container (an alias to our Rocker r-base container)

r-base is begged to Debian testing, and also allows you to get Debian
unstable.  Below I fire up the container, tell it to use bash (not R) and update

  edd at rob:~/git$ docker run --rm -ti r-base bash
  root at 1307193fadf4:/# 
  root at 1307193fadf4:/# apt-get update
  Get:1 http://cdn-fastly.deb.debian.org/debian sid InRelease [149 kB]
  Get:2 http://cdn-fastly.deb.debian.org/debian testing InRelease [117 kB]
  Get:3 http://cdn-fastly.deb.debian.org/debian sid/main amd64 Packages [8,385 kB]
  Get:4 http://cdn-fastly.deb.debian.org/debian testing/main amd64 Packages [7,918 kB]
  Fetched 16.6 MB in 4s (4,649 kB/s)                           
  Reading package lists... Done
  root at 1307193fadf4:/# apt-cache policy gcc-9
  gcc-9:
    Installed: (none)
    Candidate: 9.1.0-10
    Version table:
       9.1.0-10 990
          990 http://deb.debian.org/debian testing/main amd64 Packages
          500 http://http.debian.net/debian sid/main amd64 Packages
  root at 1307193fadf4:/# apt-cache policy gfortran-9
  gfortran-9:
    Installed: (none)
    Candidate: 9.1.0-10
    Version table:
       9.1.0-10 990
          990 http://deb.debian.org/debian testing/main amd64 Packages
          500 http://http.debian.net/debian sid/main amd64 Packages
  root at 1307193fadf4:/# 

At this point it just a matter of actually installing gcc-9 and gfortran-9
(via apt-get install ...), and setting CC, FC, F77 and whichever other
environment variables the R build reflect to build quantreg.

That said, this will be Debian's standard gfortran-9.  What is at times a
little frustrating is that some of the builds used by some of the CRAN tests
use local modifications which make their behaviour a little harder to
reproduce.  I have an open issue with my (also old and stable) digest package
which goes belly-up on a clang-on-Fedora build and nowhere else -- and I have
been unable to reproduce this too.

For such cases, having Docker container would be one possible way of
giving access to the test environment to make it accessible to more users.

Best,  Dirk


| 
| Thanks,
| Roger
| 
| Roger Koenker
| r.koenker at ucl.ac.uk<mailto:r.koenker at ucl.ac.uk>
| Department of Economics, UCL
| London  WC1H 0AX.
| 
| 
| 
| 	[[alternative HTML version deleted]]
| 
| ______________________________________________
| R-devel at r-project.org mailing list
| https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From n@r@@ @end|ng |rom @t@n|ord@edu  Sun Aug  4 17:20:51 2019
From: n@r@@ @end|ng |rom @t@n|ord@edu (Balasubramanian Narasimhan)
Date: Sun, 4 Aug 2019 08:20:51 -0700
Subject: [Rd] gfortran 9 quantreg bug
In-Reply-To: <01EC6670-8D56-44D7-8A2A-2FC156D76B83@xs4all.nl>
References: <F22FFF48-C157-4269-ACD4-3B58DD83FCCE@illinois.edu>
 <01EC6670-8D56-44D7-8A2A-2FC156D76B83@xs4all.nl>
Message-ID: <8cfef3cb-1e08-ff21-29c2-b845ac6d0cc8@stanford.edu>


On 8/4/19 7:26 AM, Berend Hasselman wrote:
> Roger,
>
> I have run
>
> 	gfortran -c -fsyntax-only -fimplicit-none -Wall -pedantic rqbr.f
>
> in the src folder of quantreg.
>
> There are many warnings about defined but not used labels.
> Also two errors such as "Symbol ?in? at (1) has no IMPLICIT type".
> And warnings such as: Warning: "Possible change of value in conversion from REAL(8) to INTEGER(4)  at ..."
>
> No offense intended but this fortran code is awful. I wouldn't want to debug this before an extensive cleanup by
> getting rid of as many numerical labels as possible, indenting and doing something about the warnings "Possible change of value ...".

The unused labels at least can be removed automatically at least for 
fixed form along the lines shown in steps 8 and 9 of

https://bnaras.github.io/SUtools/articles/SUtools.html

which pertain to lines 261--281 of

https://github.com/bnaras/SUtools/blob/master/R/process.R

In fact, here it is, excerpted.

library(stringr)
code_lines  <- readLines(con = "rqbr.f")
cat("Running gfortran to detect warning lines on unused labels\n")
system2(command = "gfortran",
         args = c("-Wunused", "-c", "rqbr.f", "-o", "temp.o"),
         stderr = "gfortran.out")
cat("Scanning gfortran output for warnings on unusued labels\n")
warnings <- readLines("gfortran.out")
line_numbers <- grep('rqbr.f', warnings)
label_warning_line_numbers <- grep(pattern = "^Warning: Label [0-9]+ at", warnings)
just_warnings <- sum(grepl('Warning:', warnings))

nW <- length(label_warning_line_numbers)
for (i in seq_len(nW)) {
     offending_line <- as.integer(stringr::str_extract(warnings[line_numbers[i]], pattern = "([0-9]+)"))
     code_line <- code_lines[offending_line]
     offending_label <- stringr::str_extract(warnings[label_warning_line_numbers[i]],
                                             pattern = "([0-9]+)")
     code_lines[offending_line] <- sub(pattern = offending_label,
                                       replacement = str_pad("", width = nchar(offending_label)),
                                       x = code_lines[offending_line])
}
writeLines(code_lines, con = "rqbr-new.f")

-Naras

> This is going to be very difficult.
>
> Berend Hasselman
>
>> On 4 Aug 2019, at 08:48, Koenker, Roger W <rkoenker at illinois.edu> wrote:
>>
>> I?d like to solicit some advice on a debugging problem I have in the quantreg package.
>> Kurt and Brian have reported to me that on Debian machines with gfortran 9
>>
>> library(quantreg)
>> f = summary(rq(foodexp ~ income, data = engel, tau = 1:4/5))
>> plot(f)
>>
>> fails because summary() produces bogus estimates of the coefficient bounds.
>> This example has been around in my R package from the earliest days of R, and
>> before that in various incarnations of S.  The culprit is apparently rqbr.f which is
>> even more ancient, but must have something that gfortran 9 doesn?t approve of.
>>
>> I note that in R-devel there have been some other issues with gfortran 9, but these seem
>> unrelated to my problem.  Not having access to a machine with an R/gfortran9
>> configuration, I can?t  apply my rudimentary debugging methods.  I?ve considered
>> trying to build gfortran on my mac air and then building R from source, but before
>> going down this road, I wondered whether others had other suggestions, or
>> advice about  my proposed route.  As far as I can see there are not yet
>> binaries for gfortran 9 for osx.
>>
>> Thanks,
>> Roger
>>
>> Roger Koenker
>> r.koenker at ucl.ac.uk<mailto:r.koenker at ucl.ac.uk>
>> Department of Economics, UCL
>> London  WC1H 0AX.
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

	[[alternative HTML version deleted]]


From rkoenker @end|ng |rom ||||no|@@edu  Sun Aug  4 17:29:00 2019
From: rkoenker @end|ng |rom ||||no|@@edu (Koenker, Roger W)
Date: Sun, 4 Aug 2019 15:29:00 +0000
Subject: [Rd] gfortran 9 quantreg bug
In-Reply-To: <01EC6670-8D56-44D7-8A2A-2FC156D76B83@xs4all.nl>
References: <F22FFF48-C157-4269-ACD4-3B58DD83FCCE@illinois.edu>
 <01EC6670-8D56-44D7-8A2A-2FC156D76B83@xs4all.nl>
Message-ID: <E9DD3692-FF18-479C-97EC-A2388356F8B8@illinois.edu>

Thanks Berend,

Yes,  I know about these warnings, they are mostly a consequence of the automated
translation from the ancient Bell Labs dialect of fortran called ratfor.  It is easy to add
type declarations for ?in?  and the others, but it seems unlikely that this is going to fix
anything.  The extra labels are all attributable to the ratfor translation.  I agree that
the code is ugly ? the ratfor is somewhat better, but not much.  I fact the algorithm
is rather simple, but I?m reluctant to write it again from scratch, since there are few
fiddly details and I would worry somewhat about reproducibility.

Roger

Roger Koenker
r.koenker at ucl.ac.uk<mailto:r.koenker at ucl.ac.uk>
Department of Economics, UCL
London  WC1H 0AX.


On Aug 4, 2019, at 3:26 PM, Berend Hasselman <bhh at xs4all.nl<mailto:bhh at xs4all.nl>> wrote:

Roger,

I have run

gfortran -c -fsyntax-only -fimplicit-none -Wall -pedantic rqbr.f

in the src folder of quantreg.

There are many warnings about defined but not used labels.
Also two errors such as "Symbol ?in? at (1) has no IMPLICIT type".
And warnings such as: Warning: "Possible change of value in conversion from REAL(8) to INTEGER(4)  at ..."

No offense intended but this fortran code is awful. I wouldn't want to debug this before an extensive cleanup by
getting rid of as many numerical labels as possible, indenting and doing something about the warnings "Possible change of value ...".

This is going to be very difficult.

Berend Hasselman

On 4 Aug 2019, at 08:48, Koenker, Roger W <rkoenker at illinois.edu<mailto:rkoenker at illinois.edu>> wrote:

I?d like to solicit some advice on a debugging problem I have in the quantreg package.
Kurt and Brian have reported to me that on Debian machines with gfortran 9

library(quantreg)
f = summary(rq(foodexp ~ income, data = engel, tau = 1:4/5))
plot(f)

fails because summary() produces bogus estimates of the coefficient bounds.
This example has been around in my R package from the earliest days of R, and
before that in various incarnations of S.  The culprit is apparently rqbr.f which is
even more ancient, but must have something that gfortran 9 doesn?t approve of.

I note that in R-devel there have been some other issues with gfortran 9, but these seem
unrelated to my problem.  Not having access to a machine with an R/gfortran9
configuration, I can?t  apply my rudimentary debugging methods.  I?ve considered
trying to build gfortran on my mac air and then building R from source, but before
going down this road, I wondered whether others had other suggestions, or
advice about  my proposed route.  As far as I can see there are not yet
binaries for gfortran 9 for osx.

Thanks,
Roger

Roger Koenker
r.koenker at ucl.ac.uk<mailto:r.koenker at ucl.ac.uk><mailto:r.koenker at ucl.ac.uk>
Department of Economics, UCL
London  WC1H 0AX.



[[alternative HTML version deleted]]

______________________________________________
R-devel at r-project.org<mailto:R-devel at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


	[[alternative HTML version deleted]]


From tom@@@k@||ber@ @end|ng |rom gm@||@com  Mon Aug  5 10:16:37 2019
From: tom@@@k@||ber@ @end|ng |rom gm@||@com (Tomas Kalibera)
Date: Mon, 5 Aug 2019 10:16:37 +0200
Subject: [Rd] Infrequent but steady NULL-pointer caused segfault in
 as.POSIXlt.POSIXct (R 3.4.4)
In-Reply-To: <CAL109eOnkcJjUm+8MW-fMoyy403Xor4SKjHRmXdS9gOnyVQWng@mail.gmail.com>
References: <CAL109eM4576ye7Jo9LUfPqncMSLb1Bg4XzMiC7e=w+h7ig4usw@mail.gmail.com>
 <40fd99c8-2432-7239-f930-325706a887f0@gmail.com>
 <CAL109eOnkcJjUm+8MW-fMoyy403Xor4SKjHRmXdS9gOnyVQWng@mail.gmail.com>
Message-ID: <39d86f00-529d-0c17-e030-4e08a2b1b874@gmail.com>

On 8/4/19 3:30 PM, Sun Yijiang wrote:
> A reply from stackoverflow suggests I might have hit this bug:
>
> https://sourceware.org/bugzilla/show_bug.cgi?id=14023
>
> I can confirm that this glibc bug affects my system (latest CentOS 7).
> However, as far as I know, R is not multithreaded in its core.  Is it
> possible that some library triggered this?

Yes, R is single threaded in its core, but that does not rule out 
completely that this glibc bug has been triggered via say a bug in some 
package that uses threads, either directly or indirectly via an external 
library.

Best
Tomas

>
> Regards,
> Steve
>
> Tomas Kalibera <tomas.kalibera at gmail.com> ?2019?8?2??? ??4:59???
>> In an optimized build, debug info is just an approximation. It might
>> help to debug in a build of R and packages without compiler
>> optimizations (-O0), where the debug information is accurate. However,
>> first I would try to modify the example to trigger more often, or try to
>> find external ways to make it trigger more often (e.g. via gctorture).
>> Then I would try to make the example smaller (not call gc() explicitly,
>> not call any external code - e.g. the jobs, etc) - any time the example
>> is reduced but still triggers the errors, the reasoning is made easier.
>> Once you have a repeatable situation in a build with reliable debug
>> symbols, debugging is easier too, e.g. sometimes a watchpoint helps to
>> find memory corruption. Please feel free to ask more when you have more
>> information/updates. If this ends up being a bug in R, please report
>> (and with a reproducible example, if it is not obvious from the source
>> code).
>>
>> Best
>> Tomas
>>
>>
>> On 8/2/19 10:23 AM, Sun Yijiang wrote:
>>> The R script I run daily for hours looks like this:
>>>
>>> while (!finish) {
>>>       Sys.sleep(0.1)
>>>       time = as.integer(format(Sys.time(), "%H%M")) # always crash here
>>>       if (new.data.timestamp() <= time)
>>>           next
>>>       # ... do some jobs for about 2 minutes ...
>>>       gc()
>>> }
>>>
>>> Basically it waits for new data, which comes in every 10 minutes, and
>>> do some jobs, then gc(), then loop again.  It works great most of the
>>> time, but crashes strangely once a month or so.  Although infrequent,
>>> it always crashes at the same place and gives the same error info,
>>> like this:
>>>
>>>    *** caught segfault ***
>>> address (nil), cause 'memory not mapped'
>>>
>>> Traceback:
>>>    1: as.POSIXlt.POSIXct(x, tz)
>>>    2: as.POSIXlt(x, tz)
>>>    3: format.POSIXlt(as.POSIXlt(x, tz), format, usetz, ...)
>>>    4: structure(format.POSIXlt(as.POSIXlt(x, tz), format, usetz, ...),
>>>     names = names(x))
>>>    5: format.POSIXct(Sys.time(), format = "%H%M")
>>>    6: format(Sys.time(), format = "%H%M")
>>>    7: format(Sys.time(), format = "%H%M")
>>> ? ?
>>>
>>> I looked into the dumped core with gdb, and found something very strange:
>>>
>>> gdb /usr/lib64/R/bin/exec/R ~/core.30387
>>> (gdb) bt 5
>>> #0  0x00007f1dca844ff1 in __strlen_sse2_pminub () from /lib64/libc.so.6
>>> #1  0x00007f1dcb20e8f9 in Rf_mkChar (name=0x0) at envir.c:3725
>>> #2  0x00007f1dcb1dc225 in do_asPOSIXlt (call=<optimized out>,
>>> op=<optimized out>, args=<optimized out>,
>>>       env=<optimized out>) at datetime.c:705
>>> #3  0x00007f1dcb22197f in bcEval (body=body at entry=0x4064b28,
>>> rho=rho at entry=0xc449d38, useCache=useCache at entry=TRUE)
>>>       at eval.c:6473
>>> #4  0x00007f1dcb230370 in Rf_eval (e=0x4064b28,
>>> rho=rho at entry=0xc449d38) at eval.c:624
>>> (More stack frames follow?)
>>>
>>> Tracing into src/main/datetime.c:705, it?s a simple string-making code:
>>> SET_STRING_ELT(tzone, 1, mkChar(R_tzname[0]));
>>>
>>> mkChar function is defined in envir.c:3725:
>>> 3723  SEXP mkChar(const char *name)
>>> 3724  {
>>> 3725      size_t len =  strlen(name);
>>> ? ?
>>>
>>> gdb shows that the string pointer (name=0x0) mkChar received is NULL,
>>> and subsequently strlen(NULL) caused the segfault.  But quite
>>> contradictorily, gdb shows the value passed to mkChar in the caller is
>>> valid:
>>>
>>> (gdb) frame 2
>>> #2  0x00007f1dcb1dc225 in do_asPOSIXlt (call=<optimized out>,
>>> op=<optimized out>, args=<optimized out>,
>>>       env=<optimized out>) at datetime.c:705
>>> 705 datetime.c: No such file or directory.
>>> (gdb) p tzname[0]
>>> $1 = 0x4cf39c0 ?CST?
>>>
>>> R_tzname is an alias of tzname. (#define R_tzname tzname in the same file.)
>>>
>>> At first, I suspect that some library may have messed up the memory
>>> and accidentally zeroed tzname (a global variable).  But with this gdb
>>> trace, it shows that tzname is good, only that the pointer passed to
>>> mkChar magically changed to zero.  Like this:
>>>
>>> mkChar(tzname[0])  // tzname[0] is ?CST?, address 0x4cf39c
>>> ? ?
>>> SEXP mkChar(const char *name)  // name should be 0x4cf39c, but gdb shows 0x0
>>> {
>>>       size_t len =  strlen(name);  // segfault, as name is NULL
>>> ? ?
>>>
>>> The only theory I can think of so far is that, on calling mkChar, the
>>> parameter passed on stack somehow got wiped out to zero by some buggy
>>> code in R or library.  At a higher level, what I see is this:  If you
>>> run format(Sys.time(), "%H%M?) a million times a day (together with
>>> other codes of course), once in a month or so this simple line can
>>> segfault.
>>>
>>> I?m lost in this confusion, could someone please help me find the
>>> right direction to further look into this problem?
>>>
>>> Regards,
>>> Steve
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>


From br@unm @end|ng |rom m@||@@mu@edu  Sun Aug  4 05:59:52 2019
From: br@unm @end|ng |rom m@||@@mu@edu (Braun, Michael)
Date: Sun, 4 Aug 2019 03:59:52 +0000
Subject: [Rd] iconv:  embedded nulls when converting to  UTF-16
Message-ID: <A1486206-FF2C-4E14-93D3-01FFBE29180E@mail.smu.edu>

R-devel community:

I have encountered some unexpected behavior using iconv, which may be the source of errors I am getting when connecting to a UTF-16 -encoded SQL Server database.  A simple example is below. 

When researching this problem, I found r-devel reports of the same problem in threads from June 2010 and February, 2016, and that bug #16738 was posted to Bugzilla as a result.  However, I have not been able to determine if the error is mine, if there is a known workaround, or it truly is a bug in R?s iconv implementation.  Any additional help is appreciated.

Thanks,

Michael

??

sessionInfo()
#> R version 3.6.1 (2019-07-05).   ## and replicated on R 3.4.1 on a cluster running CentOS Linux 7.
#> Platform: x86_64-apple-darwin15.6.0 (64-bit)
#> Running under: macOS Mojave 10.14.6
# <snip>
#> locale:
#> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

#> attached base packages:
#> [1] stats     graphics  grDevices utils     datasets  methods   base     

#> loaded via a namespace (and not attached):
#> [1] compiler_3.6.1 

s <- "test"
iconv(s, to="UTF-8?)
#> [1] ?test"

iconv(s, to="UTF-16")
#> Error in iconv(s, to = "UTF-16"): embedded nul in string: '\xfe\xff\0t\0e\0s\0t?

iconv(s, to="UTF-16BE")
#> Error in iconv(s, to = "UTF-16BE"): embedded nul in string: '\0t\0e\0s\0t?

iconv(s, to="UTF-16LE")
#> Error in iconv(s, to = "UTF-16LE"): embedded nul in string: 't\0e\0s\0t\0?




--------------------------
Michael Braun, Ph.D.
Associate Professor of Marketing, and
  Corrigan Research Professor
Cox School of Business
Southern Methodist University
Dallas, TX 75275






From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Aug  5 14:29:16 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 5 Aug 2019 08:29:16 -0400
Subject: [Rd] iconv: embedded nulls when converting to UTF-16
In-Reply-To: <A1486206-FF2C-4E14-93D3-01FFBE29180E@mail.smu.edu>
References: <A1486206-FF2C-4E14-93D3-01FFBE29180E@mail.smu.edu>
Message-ID: <32c00eeb-b6ce-862d-a58b-2f60a6203f4e@gmail.com>

On 03/08/2019 11:59 p.m., Braun, Michael wrote:
> R-devel community:
> 
> I have encountered some unexpected behavior using iconv, which may be the source of errors I am getting when connecting to a UTF-16 -encoded SQL Server database.  A simple example is below.
> 
> When researching this problem, I found r-devel reports of the same problem in threads from June 2010 and February, 2016, and that bug #16738 was posted to Bugzilla as a result.  However, I have not been able to determine if the error is mine, if there is a known workaround, or it truly is a bug in R?s iconv implementation.  Any additional help is appreciated.

R does not support embedded nulls in character strings, so it can't 
handle UTF-16 strings as character vectors.

If you are using iconv(), you can set toRaw = TRUE, and you'll get a 
result containing the correct bytes.  For example,

 > s <- "test"
 > iconv(s, to="UTF-16",toRaw=TRUE)
[[1]]
  [1] fe ff 00 74 00 65 00 73 00 74


I don't know if SQL Server can handle raw vectors; I'd try to get it to 
accept UTF-8 input instead.

Duncan Murdoch
> 
> Thanks,
> 
> Michael
> 
> ??
> 
> sessionInfo()
> #> R version 3.6.1 (2019-07-05).   ## and replicated on R 3.4.1 on a cluster running CentOS Linux 7.
> #> Platform: x86_64-apple-darwin15.6.0 (64-bit)
> #> Running under: macOS Mojave 10.14.6
> # <snip>
> #> locale:
> #> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> 
> #> attached base packages:
> #> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> #> loaded via a namespace (and not attached):
> #> [1] compiler_3.6.1
> 
> s <- "test"
> iconv(s, to="UTF-8?)
> #> [1] ?test"
> 
> iconv(s, to="UTF-16")
> #> Error in iconv(s, to = "UTF-16"): embedded nul in string: '\xfe\xff\0t\0e\0s\0t?
> 
> iconv(s, to="UTF-16BE")
> #> Error in iconv(s, to = "UTF-16BE"): embedded nul in string: '\0t\0e\0s\0t?
> 
> iconv(s, to="UTF-16LE")
> #> Error in iconv(s, to = "UTF-16LE"): embedded nul in string: 't\0e\0s\0t\0?
> 
> 
> 
> 
> --------------------------
> Michael Braun, Ph.D.
> Associate Professor of Marketing, and
>    Corrigan Research Professor
> Cox School of Business
> Southern Methodist University
> Dallas, TX 75275
> 
> 
> 
> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de  Mon Aug  5 16:32:17 2019
From: ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de (Uwe Ligges)
Date: Mon, 5 Aug 2019 16:32:17 +0200
Subject: [Rd] CRAN incoming queue closed from Aug 09 to Aug 18
Message-ID: <4ee47980-5362-1ea8-ad71-312137583b77@statistik.tu-dortmund.de>

Dear package developers,

the CRAN incoming queue will be closed from Aug 09, 2019 to Aug 18, 
2019. Hence package submissions are only possible before and after that
period.

CRAN maintainance work and some work on a possibly forthcoming Windows 
toolchain will be pushed forward.

Best,
Uwe Ligges
(for the CRAN team)


From rkoenker @end|ng |rom ||||no|@@edu  Mon Aug  5 17:19:15 2019
From: rkoenker @end|ng |rom ||||no|@@edu (Koenker, Roger W)
Date: Mon, 5 Aug 2019 15:19:15 +0000
Subject: [Rd] gfortran 9 quantreg bug
In-Reply-To: <23878.61052.305001.554120@rob.eddelbuettel.com>
References: <F22FFF48-C157-4269-ACD4-3B58DD83FCCE@illinois.edu>
 <23878.61052.305001.554120@rob.eddelbuettel.com>
Message-ID: <358E8734-D9C4-4238-9532-24896126F3AD@illinois.edu>

With extensive help from Dirk Eddelbuettel I have installed 
docker on my mac mini from 

    https://hub.docker.com/editions/community/docker-ce-desktop-mac

which installs from a dmg in quite standard fashion.  This has allowed
me to simulate running R in a Debian environment with gfortran-9 and
begin the process of debugging my ancient rqbr.f code.

Some further details:

0.  After some initial testing, e.g.

    docker --version 
    docker run hello-world       

1.  Download r-base and test os

    docker pull r-base                       $ downloads r-base for us 
    docker run --rm -ti r-base R --version   # to check we have the R we want
    docker run --rm -ti r-base bash          # now in shell, Ctrl-d to exit

2.  Setup working directory -- tell Docker to run from the current directory
    and access

    cd projects/rq
    docker run --rm -ti -v ${PWD}:/work -w /work r-base bash

    This put the contents of projects/rq into the /work directory.

    root at 90521904fa86:/work# apt-get update
    Get:1 http://cdn-fastly.deb.debian.org/debian sid InRelease [149 kB]
    Get:2 http://cdn-fastly.deb.debian.org/debian testing InRelease [117 kB]
    Get:3 http://cdn-fastly.deb.debian.org/debian sid/main amd64 Packages [8,385 kB]
    Get:4 http://cdn-fastly.deb.debian.org/debian testing/main amd64 Packages [7,916 kB]
    Fetched 16.6 MB in 4s (4,411 kB/s)                           
    Reading package lists... Done
  
3.  Get gcc-9 and gfortran-9

    root at 90521904fa86:/work# apt-get install gcc-9 gfortran-9
    Reading package lists... Done
    Building dependency tree       
    Reading state information... Done
    The following additional packages will be installed:
    cpp-9 gcc-9-base libasan5 libatomic1 libcc1-0 libgcc-9-dev libgcc1 libgfortran-9-dev
    libgfortran5 libgomp1 libitm1 liblsan0 libquadmath0 libstdc++6 libtsan0 libubsan1
    Suggested packages:
    gcc-9-locales gcc-9-multilib gcc-9-doc libgcc1-dbg libgomp1-dbg libitm1-dbg libatomic1-dbg
    libasan5-dbg liblsan0-dbg libtsan0-dbg libubsan1-dbg libquadmath0-dbg gfortran-9-multilib
    gfortran-9-doc libgfortran5-dbg libcoarrays-dev
    The following NEW packages will be installed:
    cpp-9 gcc-9 gfortran-9 libgcc-9-dev libgfortran-9-dev
    The following packages will be upgraded:
    gcc-9-base libasan5 libatomic1 libcc1-0 libgcc1 libgfortran5 libgomp1 libitm1 liblsan0
    libquadmath0 libstdc++6 libtsan0 libubsan1
    13 upgraded, 5 newly installed, 0 to remove and 71 not upgraded.
    Need to get 35.6 MB of archives.
    After this operation, 107 MB of additional disk space will be used.
    Do you want to continue? [Y/n] Y
    Get:1 http://cdn-fastly.deb.debian.org/debian testing/main amd64 libasan5 amd64 9.1.0-10 [390 kB]
    Get:2 http://cdn-fastly.deb.debian.org/debian testing/main amd64 libubsan1 amd64 9.1.0-10 [128 kB]
    Get:3 http://cdn-fastly.deb.debian.org/debian testing/main amd64 libtsan0 amd64 9.1.0-10 [295 kB]
    Get:4 http://cdn-fastly.deb.debian.org/debian testing/main amd64 gcc-9-base amd64 9.1.0-10 [190 kB]
    Get:5 http://cdn-fastly.deb.debian.org/debian testing/main amd64 libstdc++6 amd64 9.1.0-10 [500 kB]
    Get:6 http://cdn-fastly.deb.debian.org/debian testing/main amd64 libquadmath0 amd64 9.1.0-10 [145 kB]
    Get:7 http://cdn-fastly.deb.debian.org/debian testing/main amd64 liblsan0 amd64 9.1.0-10 [137 kB]
    Get:8 http://cdn-fastly.deb.debian.org/debian testing/main amd64 libitm1 amd64 9.1.0-10 [27.6 kB]
    Get:9 http://cdn-fastly.deb.debian.org/debian testing/main amd64 libgomp1 amd64 9.1.0-10 [88.1 kB]
    Get:10 http://cdn-fastly.deb.debian.org/debian testing/main amd64 libgfortran5 amd64 9.1.0-10 [633 kB]
    Get:11 http://cdn-fastly.deb.debian.org/debian testing/main amd64 libcc1-0 amd64 9.1.0-10 [47.7 kB]
    Get:12 http://cdn-fastly.deb.debian.org/debian testing/main amd64 libatomic1 amd64 9.1.0-10 [9,012 B]
    Get:13 http://cdn-fastly.deb.debian.org/debian testing/main amd64 libgcc1 amd64 1:9.1.0-10 [40.5 kB]
    Get:14 http://cdn-fastly.deb.debian.org/debian testing/main amd64 cpp-9 amd64 9.1.0-10 [9,667 kB]
    Get:15 http://cdn-fastly.deb.debian.org/debian testing/main amd64 libgcc-9-dev amd64 9.1.0-10 [2,346 kB]
    Get:16 http://cdn-fastly.deb.debian.org/debian testing/main amd64 gcc-9 amd64 9.1.0-10 [9,945 kB]
    Get:17 http://cdn-fastly.deb.debian.org/debian testing/main amd64 libgfortran-9-dev amd64 9.1.0-10 [676 kB]
    Get:18 http://cdn-fastly.deb.debian.org/debian testing/main amd64 gfortran-9 amd64 9.1.0-10 [10.4 MB]
    Fetched 35.6 MB in 6s (6,216 kB/s)      
    debconf: delaying package configuration, since apt-utils is not installed
    (Reading database ... 17787 files and directories currently installed.)
    Preparing to unpack .../libasan5_9.1.0-10_amd64.deb ...
    Unpacking libasan5:amd64 (9.1.0-10) over (9.1.0-8) ...
    Preparing to unpack .../libubsan1_9.1.0-10_amd64.deb ...
    Unpacking libubsan1:amd64 (9.1.0-10) over (9.1.0-8) ...
    Preparing to unpack .../libtsan0_9.1.0-10_amd64.deb ...
    Unpacking libtsan0:amd64 (9.1.0-10) over (9.1.0-8) ...
    Preparing to unpack .../gcc-9-base_9.1.0-10_amd64.deb ...
    Unpacking gcc-9-base:amd64 (9.1.0-10) over (9.1.0-8) ...
    Setting up gcc-9-base:amd64 (9.1.0-10) ...
    (Reading database ... 17787 files and directories currently installed.)
    Preparing to unpack .../libstdc++6_9.1.0-10_amd64.deb ...
    Unpacking libstdc++6:amd64 (9.1.0-10) over (9.1.0-8) ...
    Setting up libstdc++6:amd64 (9.1.0-10) ...
    (Reading database ... 17787 files and directories currently installed.)
    Preparing to unpack .../0-libquadmath0_9.1.0-10_amd64.deb ...
    Unpacking libquadmath0:amd64 (9.1.0-10) over (9.1.0-8) ...
    Preparing to unpack .../1-liblsan0_9.1.0-10_amd64.deb ...
    Unpacking liblsan0:amd64 (9.1.0-10) over (9.1.0-8) ...
    Preparing to unpack .../2-libitm1_9.1.0-10_amd64.deb ...
    Unpacking libitm1:amd64 (9.1.0-10) over (9.1.0-8) ...
    Preparing to unpack .../3-libgomp1_9.1.0-10_amd64.deb ...
    Unpacking libgomp1:amd64 (9.1.0-10) over (9.1.0-8) ...
    Preparing to unpack .../4-libgfortran5_9.1.0-10_amd64.deb ...
    Unpacking libgfortran5:amd64 (9.1.0-10) over (9.1.0-8) ...
    Preparing to unpack .../5-libcc1-0_9.1.0-10_amd64.deb ...
    Unpacking libcc1-0:amd64 (9.1.0-10) over (9.1.0-8) ...
    Preparing to unpack .../6-libatomic1_9.1.0-10_amd64.deb ...
    Unpacking libatomic1:amd64 (9.1.0-10) over (9.1.0-8) ...
    Preparing to unpack .../7-libgcc1_1%3a9.1.0-10_amd64.deb ...
    Unpacking libgcc1:amd64 (1:9.1.0-10) over (1:9.1.0-8) ...
    Setting up libgcc1:amd64 (1:9.1.0-10) ...
    Selecting previously unselected package cpp-9.
    (Reading database ... 17787 files and directories currently installed.)
    Preparing to unpack .../cpp-9_9.1.0-10_amd64.deb ...
    Unpacking cpp-9 (9.1.0-10) ...
    Selecting previously unselected package libgcc-9-dev:amd64.
    Preparing to unpack .../libgcc-9-dev_9.1.0-10_amd64.deb ...
    Unpacking libgcc-9-dev:amd64 (9.1.0-10) ...
    Selecting previously unselected package gcc-9.
    Preparing to unpack .../gcc-9_9.1.0-10_amd64.deb ...
    Unpacking gcc-9 (9.1.0-10) ...
    Selecting previously unselected package libgfortran-9-dev:amd64.
    Preparing to unpack .../libgfortran-9-dev_9.1.0-10_amd64.deb ...
    Unpacking libgfortran-9-dev:amd64 (9.1.0-10) ...
    Selecting previously unselected package gfortran-9.
    Preparing to unpack .../gfortran-9_9.1.0-10_amd64.deb ...
    Unpacking gfortran-9 (9.1.0-10) ...
    Setting up libgomp1:amd64 (9.1.0-10) ...
    Setting up libasan5:amd64 (9.1.0-10) ...
    Setting up libquadmath0:amd64 (9.1.0-10) ...
    Setting up libatomic1:amd64 (9.1.0-10) ...
    Setting up libgfortran5:amd64 (9.1.0-10) ...
    Setting up libubsan1:amd64 (9.1.0-10) ...
    Setting up cpp-9 (9.1.0-10) ...
    Setting up libcc1-0:amd64 (9.1.0-10) ...
    Setting up liblsan0:amd64 (9.1.0-10) ...
    Setting up libitm1:amd64 (9.1.0-10) ...
    Setting up libtsan0:amd64 (9.1.0-10) ...
    Setting up libgcc-9-dev:amd64 (9.1.0-10) ...
    Setting up gcc-9 (9.1.0-10) ...
    Setting up libgfortran-9-dev:amd64 (9.1.0-10) ...
    Setting up gfortran-9 (9.1.0-10) ...
    Processing triggers for libc-bin (2.28-10) ...
    root at 90521904fa86:/work# pwd
    
4.  At this point I removed some dependencies from the package
    quantreg that I knew were not relevant to the debugging problem at
    hand. This included an attempt to set compiler flags in
    quantreg/src/Makevars, but this didn't work.

5.  Set compiler flags as follows:

    root at 90521904fa86:/work# mkdir ~/.R; vi ~/.R/Makevars 

	CC=gcc-9
	FC=gfortran-9
	F77=gfortran-9

    Alternatively, one can find the settings of CC, FC, CXX, ... in /etc/R/Makeconf
    and alter them there.
    
6.  At this point 

    R CMD INSTALL quantreg_5.43.tar.gz

    did use the gfortran-9  compiler and this version did reproduce the 
    error initially reported by Kurt and Brian.  

7.  Now it is (just!) a matter of finding the bug.
     
Roger Koenker
r.koenker at ucl.ac.uk
Department of Economics, UCL
London  WC1H 0AX.


> On Aug 4, 2019, at 3:41 PM, Dirk Eddelbuettel <edd at debian.org> wrote:
> 
> 
> Roger,
> 
> On 4 August 2019 at 06:48, Koenker, Roger W wrote:
> | I?d like to solicit some advice on a debugging problem I have in the quantreg package.
> | Kurt and Brian have reported to me that on Debian machines with gfortran 9
> | 
> | library(quantreg)
> | f = summary(rq(foodexp ~ income, data = engel, tau = 1:4/5))
> | plot(f)
> | 
> | fails because summary() produces bogus estimates of the coefficient bounds.
> | This example has been around in my R package from the earliest days of R, and
> | before that in various incarnations of S.  The culprit is apparently rqbr.f which is
> | even more ancient, but must have something that gfortran 9 doesn?t approve of.
> | 
> | I note that in R-devel there have been some other issues with gfortran 9, but these seem
> | unrelated to my problem.  Not having access to a machine with an R/gfortran9
> | configuration, I can?t  apply my rudimentary debugging methods.  I?ve considered
> | trying to build gfortran on my mac air and then building R from source, but before
> | going down this road, I wondered whether others had other suggestions, or
> | advice about  my proposed route.  As far as I can see there are not yet
> | binaries for gfortran 9 for osx.
> 
> Maybe installing and running Docker on your mac is an alternative?
> 
> Minimally viable example using
> 
>  a) docker (on Linux, but it is portable) and
> 
>  b) the current official 'r-base' container (an alias to our Rocker r-base container)
> 
> r-base is begged to Debian testing, and also allows you to get Debian
> unstable.  Below I fire up the container, tell it to use bash (not R) and update
> 
>  edd at rob:~/git$ docker run --rm -ti r-base bash
>  root at 1307193fadf4:/# 
>  root at 1307193fadf4:/# apt-get update
>  Get:1 http://cdn-fastly.deb.debian.org/debian sid InRelease [149 kB]
>  Get:2 http://cdn-fastly.deb.debian.org/debian testing InRelease [117 kB]
>  Get:3 http://cdn-fastly.deb.debian.org/debian sid/main amd64 Packages [8,385 kB]
>  Get:4 http://cdn-fastly.deb.debian.org/debian testing/main amd64 Packages [7,918 kB]
>  Fetched 16.6 MB in 4s (4,649 kB/s)                           
>  Reading package lists... Done
>  root at 1307193fadf4:/# apt-cache policy gcc-9
>  gcc-9:
>    Installed: (none)
>    Candidate: 9.1.0-10
>    Version table:
>       9.1.0-10 990
>          990 http://deb.debian.org/debian testing/main amd64 Packages
>          500 http://http.debian.net/debian sid/main amd64 Packages
>  root at 1307193fadf4:/# apt-cache policy gfortran-9
>  gfortran-9:
>    Installed: (none)
>    Candidate: 9.1.0-10
>    Version table:
>       9.1.0-10 990
>          990 http://deb.debian.org/debian testing/main amd64 Packages
>          500 http://http.debian.net/debian sid/main amd64 Packages
>  root at 1307193fadf4:/# 
> 
> At this point it just a matter of actually installing gcc-9 and gfortran-9
> (via apt-get install ...), and setting CC, FC, F77 and whichever other
> environment variables the R build reflect to build quantreg.
> 
> That said, this will be Debian's standard gfortran-9.  What is at times a
> little frustrating is that some of the builds used by some of the CRAN tests
> use local modifications which make their behaviour a little harder to
> reproduce.  I have an open issue with my (also old and stable) digest package
> which goes belly-up on a clang-on-Fedora build and nowhere else -- and I have
> been unable to reproduce this too.
> 
> For such cases, having Docker container would be one possible way of
> giving access to the test environment to make it accessible to more users.
> 
> Best,  Dirk
> 
> 
> | 
> | Thanks,
> | Roger
> | 
> | Roger Koenker
> | r.koenker at ucl.ac.uk<mailto:r.koenker at ucl.ac.uk>
> | Department of Economics, UCL
> | London  WC1H 0AX.
> | 
> | 
> | 
> | 	[[alternative HTML version deleted]]
> | 
> | ______________________________________________
> | R-devel at r-project.org mailing list
> | https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> -- 
> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From edd @end|ng |rom deb|@n@org  Mon Aug  5 17:42:52 2019
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Mon, 5 Aug 2019 10:42:52 -0500
Subject: [Rd] MKL with latest Rs
In-Reply-To: <CAC=0fxUgMfWf8Fd9AfLw2Uu+pmad+JAAwbxh2AnjM-wH-L4HOg@mail.gmail.com>
References: <CAC=0fxWBHsSvyFe4QAvk6db8YdJxB5YHUpowUoPRyNYuZku4vA@mail.gmail.com>
 <f1be26bc-9d44-43c2-3bb3-c2f4bbcafdfa@gmail.com>
 <CAC=0fxUgMfWf8Fd9AfLw2Uu+pmad+JAAwbxh2AnjM-wH-L4HOg@mail.gmail.com>
Message-ID: <23880.20092.619915.93794@rob.eddelbuettel.com>


On 26 July 2019 at 08:48, Robert B. Gramacy wrote:
| That does the trick, thanks!  In fact, I had those lines commented out in
| my Rmkl startup script but I can't remember why, since they're part of
| Intel's instructions.  Strange that things still worked for somewhat older
| Rs.  (Perhaps that's why I canceled them.)
| 
| Dirk, if you're listening, it might help to add a note to your blog post.
| I guess it's not as simple as "update-alternatives and done" because
| environment variables still need to be set.

Only if you want correct results :)

Will do, if I remember once home.  Thanks for the suggestion.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From m@tth|eu@@t|g|er @end|ng |rom gm@||@com  Mon Aug  5 20:12:31 2019
From: m@tth|eu@@t|g|er @end|ng |rom gm@||@com (Matthieu S)
Date: Mon, 5 Aug 2019 11:12:31 -0700
Subject: [Rd] R CMD check: should .Rout.save contain the new "Registered S3
 method overwritten by" message?
Message-ID: <CAEYvigL5LWD8CiMFxMW-FJoFE84XOe54Pwb5jHVx6hEymLsCNw@mail.gmail.com>

Hi

Since I believe 3.6, there is a message when loading a package that
overwrites S3 methods, reading like "Registered S3 method overwritten
by...". Should this message be included in the xxx.Rout.save files saved in
the tests/ folder of a package? It seems R CMD check is not happy about it?

I simply ran R CMD BATCH xxx.R xxx.Rout.save but running later on R CMD
check on the package complains about the presence of the "Registered S3
method overwritten..." text? Did I do something wrong? Is this the correct
way to do, and R CMD check should be updated? Or should I not include the
"Registered S3 method overwritten"  in the .Rout.save (and how can I do
that?)?

Thanks!

Matthieu

	[[alternative HTML version deleted]]


From p@u|@buerkner @end|ng |rom gm@||@com  Mon Aug  5 21:44:23 2019
From: p@u|@buerkner @end|ng |rom gm@||@com (Paul Buerkner)
Date: Mon, 5 Aug 2019 21:44:23 +0200
Subject: [Rd] Potential bug in update.formula when updating offsets
Message-ID: <CAGoSky9QAyfxW6bxzkVACQGX95SR2H-9rt2H2+EnF_Db_tDcLg@mail.gmail.com>

Hi all,

update.formula does not seem to correctly update (i.e. remove in my case)
offset terms.

Here is an example:

update(~x + offset(z), ~ . - offset(z))
> ~x + offset(z)

Also:
update(~x, ~ . - offset(z))
> ~x + offset(z)

In both cases, I would expect the result
> ~x

as  - <term>  should remove <term> from the formula as happens for instance
in:

update(~x + z, ~ . - z)
> ~x

I don't know if this behavior is intentional but I would say it is at least
unfortunate.

Paul

	[[alternative HTML version deleted]]


From pd@|gd @end|ng |rom gm@||@com  Tue Aug  6 10:21:22 2019
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Tue, 6 Aug 2019 10:21:22 +0200
Subject: [Rd] Potential bug in update.formula when updating offsets
In-Reply-To: <CAGoSky9QAyfxW6bxzkVACQGX95SR2H-9rt2H2+EnF_Db_tDcLg@mail.gmail.com>
References: <CAGoSky9QAyfxW6bxzkVACQGX95SR2H-9rt2H2+EnF_Db_tDcLg@mail.gmail.com>
Message-ID: <5F1A2594-68E6-4A5B-A4C7-AC964474966B@gmail.com>

Terry, Martin

Would this happen to be related to the "indexing term objects" issue that has been bothering you?

-pd

> On 5 Aug 2019, at 21:44 , Paul Buerkner <paul.buerkner at gmail.com> wrote:
> 
> Hi all,
> 
> update.formula does not seem to correctly update (i.e. remove in my case)
> offset terms.
> 
> Here is an example:
> 
> update(~x + offset(z), ~ . - offset(z))
>> ~x + offset(z)
> 
> Also:
> update(~x, ~ . - offset(z))
>> ~x + offset(z)
> 
> In both cases, I would expect the result
>> ~x
> 
> as  - <term>  should remove <term> from the formula as happens for instance
> in:
> 
> update(~x + z, ~ . - z)
>> ~x
> 
> I don't know if this behavior is intentional but I would say it is at least
> unfortunate.
> 
> Paul
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From therne@u @end|ng |rom m@yo@edu  Tue Aug  6 14:46:05 2019
From: therne@u @end|ng |rom m@yo@edu (Therneau, Terry M., Ph.D.)
Date: Tue, 06 Aug 2019 07:46:05 -0500
Subject: [Rd] 
 [EXTERNAL] Re: Potential bug in update.formula when updating offsets
In-Reply-To: <5F1A2594-68E6-4A5B-A4C7-AC964474966B@gmail.com>
References: <CAGoSky9QAyfxW6bxzkVACQGX95SR2H-9rt2H2+EnF_Db_tDcLg@mail.gmail.com>
 <5F1A2594-68E6-4A5B-A4C7-AC964474966B@gmail.com>
Message-ID: <771925$c60o2u@ironport10.mayo.edu>

Yes, it is almost certainly the same issue.? At useR I promised Martin that I would put 
together a clear example and fix for him and I have not yet done so.? I will try to do 
that this week.

 ? The heart of the issue is that in a terms object the offset expression will apear in 
the 'variables' attribute but not in the 'term.labels' or 'order' attributes, and the base 
code tries to use the same subscripting vector for all 3 if then. ? The same bit of code 
shows up in update.formula and in [.formula; a fix for one can be applied to both.

I had all this worked out, then had some problems logging into buzilla, then sent it to 
Martin about the same time 2-3 more urgent things got dumped on him, and then we've both 
let it lie. At useR he said (and I've no reason to disagree) that my prior note was 
unclear.? Let me recreate the example and fix, more carefully.

Terry T.


On 8/6/19 3:21 AM, peter dalgaard wrote:
> Terry, Martin
>
> Would this happen to be related to the "indexing term objects" issue that has been bothering you?
>
> -pd
>
>> On 5 Aug 2019, at 21:44 , Paul Buerkner <paul.buerkner at gmail.com> wrote:
>>
>> Hi all,
>>
>> update.formula does not seem to correctly update (i.e. remove in my case)
>> offset terms.
>>
>> Here is an example:
>>
>> update(~x + offset(z), ~ . - offset(z))
>>> ~x + offset(z)
>> Also:
>> update(~x, ~ . - offset(z))
>>> ~x + offset(z)
>> In both cases, I would expect the result
>>> ~x
>> as  - <term>  should remove <term> from the formula as happens for instance
>> in:
>>
>> update(~x + z, ~ . - z)
>>> ~x
>> I don't know if this behavior is intentional but I would say it is at least
>> unfortunate.
>>
>> Paul
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


	[[alternative HTML version deleted]]


From k@@perd@n|e|h@n@en @end|ng |rom gm@||@com  Tue Aug  6 16:33:49 2019
From: k@@perd@n|e|h@n@en @end|ng |rom gm@||@com (Kasper Daniel Hansen)
Date: Tue, 6 Aug 2019 10:33:49 -0400
Subject: [Rd] gfortran 9 quantreg bug
In-Reply-To: <23878.61052.305001.554120@rob.eddelbuettel.com>
References: <F22FFF48-C157-4269-ACD4-3B58DD83FCCE@illinois.edu>
 <23878.61052.305001.554120@rob.eddelbuettel.com>
Message-ID: <CAC2h7uvoTNzcMscNwgco-=x8sz545AvV39TQ9nZVUSbzbaCaBA@mail.gmail.com>

Dirk,

Thanks for the blog post on this, and the pointers in this email.

I have a question: it seems to me that you end up using a different
compiler for the package (quantreg) than was used to build R itself. As I
understand ABI changes, this is considered unsupported (ok, that depends on
what version of gcc/gfortran was used to build R, but there has been a lot
of ABI changes in GCC). Is that correct? I understand that this shortcut
makes it much easier to use different compilers, and might work for Roger's
usecase, but I was wondering about this issue of using a different compiler
for packages. Is this something I should worry about?

Best,
Kasper

On Sun, Aug 4, 2019 at 10:41 AM Dirk Eddelbuettel <edd at debian.org> wrote:

>
> Roger,
>
> On 4 August 2019 at 06:48, Koenker, Roger W wrote:
> | I?d like to solicit some advice on a debugging problem I have in the
> quantreg package.
> | Kurt and Brian have reported to me that on Debian machines with gfortran
> 9
> |
> | library(quantreg)
> | f = summary(rq(foodexp ~ income, data = engel, tau = 1:4/5))
> | plot(f)
> |
> | fails because summary() produces bogus estimates of the coefficient
> bounds.
> | This example has been around in my R package from the earliest days of
> R, and
> | before that in various incarnations of S.  The culprit is apparently
> rqbr.f which is
> | even more ancient, but must have something that gfortran 9 doesn?t
> approve of.
> |
> | I note that in R-devel there have been some other issues with gfortran
> 9, but these seem
> | unrelated to my problem.  Not having access to a machine with an
> R/gfortran9
> | configuration, I can?t  apply my rudimentary debugging methods.  I?ve
> considered
> | trying to build gfortran on my mac air and then building R from source,
> but before
> | going down this road, I wondered whether others had other suggestions, or
> | advice about  my proposed route.  As far as I can see there are not yet
> | binaries for gfortran 9 for osx.
>
> Maybe installing and running Docker on your mac is an alternative?
>
> Minimally viable example using
>
>   a) docker (on Linux, but it is portable) and
>
>   b) the current official 'r-base' container (an alias to our Rocker
> r-base container)
>
> r-base is begged to Debian testing, and also allows you to get Debian
> unstable.  Below I fire up the container, tell it to use bash (not R) and
> update
>
>   edd at rob:~/git$ docker run --rm -ti r-base bash
>   root at 1307193fadf4:/#
>   root at 1307193fadf4:/# apt-get update
>   Get:1 http://cdn-fastly.deb.debian.org/debian sid InRelease [149 kB]
>   Get:2 http://cdn-fastly.deb.debian.org/debian testing InRelease [117 kB]
>   Get:3 http://cdn-fastly.deb.debian.org/debian sid/main amd64 Packages
> [8,385 kB]
>   Get:4 http://cdn-fastly.deb.debian.org/debian testing/main amd64
> Packages [7,918 kB]
>   Fetched 16.6 MB in 4s (4,649 kB/s)
>   Reading package lists... Done
>   root at 1307193fadf4:/# apt-cache policy gcc-9
>   gcc-9:
>     Installed: (none)
>     Candidate: 9.1.0-10
>     Version table:
>        9.1.0-10 990
>           990 http://deb.debian.org/debian testing/main amd64 Packages
>           500 http://http.debian.net/debian sid/main amd64 Packages
>   root at 1307193fadf4:/# apt-cache policy gfortran-9
>   gfortran-9:
>     Installed: (none)
>     Candidate: 9.1.0-10
>     Version table:
>        9.1.0-10 990
>           990 http://deb.debian.org/debian testing/main amd64 Packages
>           500 http://http.debian.net/debian sid/main amd64 Packages
>   root at 1307193fadf4:/#
>
> At this point it just a matter of actually installing gcc-9 and gfortran-9
> (via apt-get install ...), and setting CC, FC, F77 and whichever other
> environment variables the R build reflect to build quantreg.
>
> That said, this will be Debian's standard gfortran-9.  What is at times a
> little frustrating is that some of the builds used by some of the CRAN
> tests
> use local modifications which make their behaviour a little harder to
> reproduce.  I have an open issue with my (also old and stable) digest
> package
> which goes belly-up on a clang-on-Fedora build and nowhere else -- and I
> have
> been unable to reproduce this too.
>
> For such cases, having Docker container would be one possible way of
> giving access to the test environment to make it accessible to more users.
>
> Best,  Dirk
>
>
> |
> | Thanks,
> | Roger
> |
> | Roger Koenker
> | r.koenker at ucl.ac.uk<mailto:r.koenker at ucl.ac.uk>
> | Department of Economics, UCL
> | London  WC1H 0AX.
> |
> |
> |
> |       [[alternative HTML version deleted]]
> |
> | ______________________________________________
> | R-devel at r-project.org mailing list
> | https://stat.ethz.ch/mailman/listinfo/r-devel
>
> --
> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Best,
Kasper

	[[alternative HTML version deleted]]


From edd @end|ng |rom deb|@n@org  Tue Aug  6 17:51:59 2019
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Tue, 6 Aug 2019 10:51:59 -0500
Subject: [Rd] gfortran 9 quantreg bug
In-Reply-To: <CAC2h7uvoTNzcMscNwgco-=x8sz545AvV39TQ9nZVUSbzbaCaBA@mail.gmail.com>
References: <F22FFF48-C157-4269-ACD4-3B58DD83FCCE@illinois.edu>
 <23878.61052.305001.554120@rob.eddelbuettel.com>
 <CAC2h7uvoTNzcMscNwgco-=x8sz545AvV39TQ9nZVUSbzbaCaBA@mail.gmail.com>
Message-ID: <23881.41503.904978.187323@rob.eddelbuettel.com>


Hi Kasper,

On 6 August 2019 at 10:33, Kasper Daniel Hansen wrote:
| Thanks for the blog post on this, and the pointers in this email.

My pleasure!  There wasn't much in there that was "new" but it often helps to
just tie it together with a valid and real example (as provided by Roger).
 
| I have a question: it seems to me that you end up using a different
| compiler for the package (quantreg) than was used to build R itself. As I
| understand ABI changes, this is considered unsupported (ok, that depends on

Are you thinking that because the 'number' increased to 9, the ABI must have
changed in some (presumably incompatible) ways?  Luckily that is not
generally the case or we'd be in much dire straits.

Every couple of years there is such a change but it is rare. I can't even
recall when g++ last forced us.  May have been the 3.3 to 4.0 change with 3.4
then providing compatibility with what came after. As for Fortran, can't
recall such a change.

| what version of gcc/gfortran was used to build R, but there has been a lot
| of ABI changes in GCC). Is that correct? I understand that this shortcut
| makes it much easier to use different compilers, and might work for Roger's
| usecase, but I was wondering about this issue of using a different compiler
| for packages. Is this something I should worry about?

No.

But don't take my word for it, but trust 'R CMD check'. If it tests, trust it.

Hth, Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From edd @end|ng |rom deb|@n@org  Tue Aug  6 18:09:32 2019
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Tue, 6 Aug 2019 11:09:32 -0500
Subject: [Rd] gfortran 9 quantreg bug
In-Reply-To: <23881.41503.904978.187323@rob.eddelbuettel.com>
References: <F22FFF48-C157-4269-ACD4-3B58DD83FCCE@illinois.edu>
 <23878.61052.305001.554120@rob.eddelbuettel.com>
 <CAC2h7uvoTNzcMscNwgco-=x8sz545AvV39TQ9nZVUSbzbaCaBA@mail.gmail.com>
 <23881.41503.904978.187323@rob.eddelbuettel.com>
Message-ID: <23881.42556.125160.78552@rob.eddelbuettel.com>


On 6 August 2019 at 10:51, Dirk Eddelbuettel wrote:
| then providing compatibility with what came after. As for Fortran, can't
| recall such a change.

Come to think about it we had it in Debian once or twice in the 20+ years I
contributed but I can't recall anymore when it was either.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From d@v|@ @end|ng |rom r@tud|o@com  Wed Aug  7 15:10:21 2019
From: d@v|@ @end|ng |rom r@tud|o@com (Davis Vaughan)
Date: Wed, 7 Aug 2019 09:10:21 -0400
Subject: [Rd] NextMethod() and argument laziness
Message-ID: <CABzLhzyY_HtAE-TuYrtVDyZyaEGxH3N5R=Cg862o29DECZXL8Q@mail.gmail.com>

Hi all, I'd like to ask if the following behavior is a bug. To me it
certainly feels surprising, at the very least. In this example, I would
like to call NextMethod() from my `child` object, have `cols` be left
untouched, and then substitute(cols) in the parent method. It works when
you use a `parent` object (as expected), but I would have also expected to
get `mpg` back when calling it from the `child` method.

my_generic <- function(x, cols) {
  UseMethod("my_generic")
}
my_generic.parent <- function(x, cols) {
  substitute(cols)
}
my_generic.child <- function(x, cols) {
  NextMethod()
}
obj_parent <- structure(mtcars, class = c("parent", class(mtcars)))
obj_child <- structure(obj_parent, class = c("child", class(obj_parent)))

my_generic(obj_parent, mpg)
#> mpg

my_generic(obj_child, mpg)
#> cols

Thanks,
Davis

	[[alternative HTML version deleted]]


From rkoenker @end|ng |rom ||||no|@@edu  Wed Aug  7 17:46:18 2019
From: rkoenker @end|ng |rom ||||no|@@edu (Koenker, Roger W)
Date: Wed, 7 Aug 2019 15:46:18 +0000
Subject: [Rd] #include_next <stdio.h>  not found
Message-ID: <390DEEEC-339B-4330-A0A1-E00ECA988719@illinois.edu>

Dear All,

Just when I thought I had the plague of gfortran-9 under control, I made the tactical error
of allowing my mac mini to ?upgrade? to macOS 10.14.6 which apparently also upgraded
Xcode to 10.3.  In consequence I?m having difficulty building my packages.  The current
symptom is:

/usr/local/clang7/bin/clang -I"/Library/Frameworks/R.framework/Resources/include" -DNDEBUG   -I/usr/local/clang7/include/c++/v1  -fPIC  -Wall -g -O2  -c mcmb.c -o mcmb.o
In file included from mcmb.c:11:
/usr/local/clang7/include/c++/v1/stdio.h:108:15: fatal error: 'stdio.h' file not found
#include_next <stdio.h>
              ^~~~~~~~~

My first thought was I should install Simon?s clang-7.0.0 and gfortran-6.1 packages
which I dutifully did.  The next thought was to update my ~/.R/Makevars file to:

CC=/usr/local/clang7/bin/clang
CXX=/usr/local/clang7/bin/clang++
LDFLAGS=-L/usr/local/clang7/lib
CPPFLAGS=-I/usr/local/clang7/include/c++/v1
FC=/usr/local/gfortran/bin/gfortran
FLIBS=-L/usr/local/gfortran/lib -lgfortran

Further googling has left me unenlightened?  oh, and I?m running
R version 3.6.1 (2019-07-05) -- "Action of the Toes"

Roger Koenker
r.koenker at ucl.ac.uk
Department of Economics, UCL
London  WC1H 0AX.



From roy@mende|@@ohn @end|ng |rom no@@@gov  Wed Aug  7 18:04:46 2019
From: roy@mende|@@ohn @end|ng |rom no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Wed, 7 Aug 2019 09:04:46 -0700
Subject: [Rd] #include_next <stdio.h>  not found
In-Reply-To: <390DEEEC-339B-4330-A0A1-E00ECA988719@illinois.edu>
References: <390DEEEC-339B-4330-A0A1-E00ECA988719@illinois.edu>
Message-ID: <5F17AFFE-C89D-4249-873C-206A15CB02EC@noaa.gov>

Hi Roger:

This came up in the r-sig-mac list.  Try removing the CPPFLAGS.   Updates to Xcode appear to erase the headers where you are pointing to.  The CRAN flags that Simon uses  point elsewhere. Look at the r-sig-mac under topic "Xcode 10.3 and header flles".

HTH,

-Roy


> On Aug 7, 2019, at 8:46 AM, Koenker, Roger W <rkoenker at illinois.edu> wrote:
> 
> Dear All,
> 
> Just when I thought I had the plague of gfortran-9 under control, I made the tactical error
> of allowing my mac mini to ?upgrade? to macOS 10.14.6 which apparently also upgraded
> Xcode to 10.3.  In consequence I?m having difficulty building my packages.  The current
> symptom is:
> 
> /usr/local/clang7/bin/clang -I"/Library/Frameworks/R.framework/Resources/include" -DNDEBUG   -I/usr/local/clang7/include/c++/v1  -fPIC  -Wall -g -O2  -c mcmb.c -o mcmb.o
> In file included from mcmb.c:11:
> /usr/local/clang7/include/c++/v1/stdio.h:108:15: fatal error: 'stdio.h' file not found
> #include_next <stdio.h>
>              ^~~~~~~~~
> 
> My first thought was I should install Simon?s clang-7.0.0 and gfortran-6.1 packages
> which I dutifully did.  The next thought was to update my ~/.R/Makevars file to:
> 
> CC=/usr/local/clang7/bin/clang
> CXX=/usr/local/clang7/bin/clang++
> LDFLAGS=-L/usr/local/clang7/lib
> CPPFLAGS=-I/usr/local/clang7/include/c++/v1
> FC=/usr/local/gfortran/bin/gfortran
> FLIBS=-L/usr/local/gfortran/lib -lgfortran
> 
> Further googling has left me unenlightened?  oh, and I?m running
> R version 3.6.1 (2019-07-05) -- "Action of the Toes"
> 
> Roger Koenker
> r.koenker at ucl.ac.uk
> Department of Economics, UCL
> London  WC1H 0AX.
> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From rkoenker @end|ng |rom ||||no|@@edu  Wed Aug  7 18:22:08 2019
From: rkoenker @end|ng |rom ||||no|@@edu (Koenker, Roger W)
Date: Wed, 7 Aug 2019 16:22:08 +0000
Subject: [Rd] #include_next <stdio.h> not found
In-Reply-To: <CAHiA-Z=wN+7=4E-01LuJ6i2X+Q01Uw9FJAjf9CNw-RN3maC5mw@mail.gmail.com>
References: <390DEEEC-339B-4330-A0A1-E00ECA988719@illinois.edu>
 <CAHiA-Z=wN+7=4E-01LuJ6i2X+Q01Uw9FJAjf9CNw-RN3maC5mw@mail.gmail.com>
Message-ID: <8C76D847-FC21-4B7E-8B55-ADE5C18C0250@illinois.edu>

Yes,  this did the trick, thanks very much!  I?m cc?ing r-devel  just for the record.


Roger Koenker
r.koenker at ucl.ac.uk<mailto:r.koenker at ucl.ac.uk>
Department of Economics, UCL
London  WC1H 0AX.


On Aug 7, 2019, at 4:55 PM, Steven Dirkse <sdirkse at gams.com<mailto:sdirkse at gams.com>> wrote:

Roger,

Updating Xcode has the unfortunate side effect of wiping out the std header files from /usr/include.  The fix - once you know about it - is mercifully easy.  Here's my notes on the subject, recorded only yesterday so I don't waste more time the next time.

Xcode 10.3
Aug 2019: we updated to Xcode 10.3. First, we did the update through the App Store. Next, we opened Xcode in the App Store and said yes to ?Install required additional components?? But that's not all! As admin, I did

sudo open /Library/Developer/CommandLineTools/Packages/macOS_SDK_headers_for_macOS_10.14.pkg

FYI, I needed an additional step to manually patch /usr/include/sys/ucred.h but it's not likely you'll need that.

-Steve

On Wed, Aug 7, 2019 at 11:46 AM Koenker, Roger W <rkoenker at illinois.edu<mailto:rkoenker at illinois.edu>> wrote:
Dear All,

Just when I thought I had the plague of gfortran-9 under control, I made the tactical error
of allowing my mac mini to ?upgrade? to macOS 10.14.6 which apparently also upgraded
Xcode to 10.3.  In consequence I?m having difficulty building my packages.  The current
symptom is:

/usr/local/clang7/bin/clang -I"/Library/Frameworks/R.framework/Resources/include" -DNDEBUG   -I/usr/local/clang7/include/c++/v1  -fPIC  -Wall -g -O2  -c mcmb.c -o mcmb.o
In file included from mcmb.c:11:
/usr/local/clang7/include/c++/v1/stdio.h:108:15: fatal error: 'stdio.h' file not found
#include_next <stdio.h>
              ^~~~~~~~~

My first thought was I should install Simon?s clang-7.0.0 and gfortran-6.1 packages
which I dutifully did.  The next thought was to update my ~/.R/Makevars file to:

CC=/usr/local/clang7/bin/clang
CXX=/usr/local/clang7/bin/clang++
LDFLAGS=-L/usr/local/clang7/lib
CPPFLAGS=-I/usr/local/clang7/include/c++/v1
FC=/usr/local/gfortran/bin/gfortran
FLIBS=-L/usr/local/gfortran/lib -lgfortran

Further googling has left me unenlightened?  oh, and I?m running
R version 3.6.1 (2019-07-05) -- "Action of the Toes"

Roger Koenker
r.koenker at ucl.ac.uk<mailto:r.koenker at ucl.ac.uk>
Department of Economics, UCL
London  WC1H 0AX.


______________________________________________
R-devel at r-project.org<mailto:R-devel at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


--
Steven Dirkse, Ph.D.
GAMS Development Corp.
office: 202.342.0180



	[[alternative HTML version deleted]]


From Liuis@Hurt@do m@iii@g oii uv@es  Thu Aug  8 11:38:42 2019
From: Liuis@Hurt@do m@iii@g oii uv@es (Liuis@Hurt@do m@iii@g oii uv@es)
Date: Thu, 8 Aug 2019 11:38:42 +0200 (CEST)
Subject: [Rd] Producing different text formats in R
Message-ID: <4455417873hurgil@uv.es>

Dear all,

I am facing a strange problem with text files formats.

I am currently using a C++ code named voro++ (http://math.lbl.gov/voro++/). This code accepts text files with four columns:

<id> <x> <y> <z>

where id is an identification number and x,y,z are the coordinates of a point in a 3D space.

The input file, name it myfile_cpp.txt, is generated by another C++ code written by myself (named quadscheme.cpp). So far, these calculations involve no R code and it works just fine.

However, now I am trying to replace my C++ code quadscheme.cpp by a R function. The four columns (id,x,y,z) are produced in a matrix or Data Frame and then saved in a file myfile_r.txt using write.table(). For example using the following function:

quadscheme <- function(window, ntile) {
  # Creates a grid of points in a 3D orthohedron. 
  # First point lies at the (mix,miny,miz) corner of the volume and the last one at (maxx,maxy,maxz)
  # window: vector. Contains the minimum and maximum values of a 3D orthohedron
  #       window <- c(minx, maxx, miny, maxy, minz, maxz)
  # ntile: vector. Number of points per dimension minus one. We manually add a extra row of points per dimension
  #       ntile <- c(nstepx, nstepy, nstepz)
  M <- prod(ntile+1) 
  mat <- matrix(NA,M,4)
  mat[,1] <- 1:M # id column
  
  # step length per dimension
  hi <- (window[2] - window[1])/ntile[1]
  hj <- (window[4] - window[3])/ntile[2]
  hk <- (window[6] - window[5])/ntile[3]
  
  c <- 1
  for(i in 0:ntile[1]) {
    x <- i*hi + window[1]
    for(j in 0:ntile[2]) {
      y <- hj*j + window[3]
      for(k in 0:ntile[3]) {
        z <- k*hk + window[5]
        mat[c,2:4] <- c(x,y,z) # Add a new point to the grid
        c <- c + 1
      }
    }
  }
  write.table(mat, file="myfile_r.txt", row.names=FALSE, col.names=FALSE)
}

And then calling:

> window <- c(18, 43, 171, 196, 95, 102)
> ntile <- c(100,100,28)
> quadscheme(window, ntile)

I see no difference between both myfile_*.txt files, one is created with C++ and the other one with R. However, function voro++ do not accept the later one (created with R and saved with write.table). I've also noted that voro++ usually accepts R generated files when they are small enough, but it accepts all C++ generated files, regardless the size.

I know this is more a C++ than a R question, but may be you can help me as well. I suspect that even if both files are *.txt they have some differences that I cannot see. Is there any way in R to produce different kinds of txt files? Like binary instead of text files? Could this be the problem?

I attach two identical files, one produced by C++ (myfile_cpp.txt) and another one by the previous R function (myfile_r.txt). I attach as well the C++ code used to generate myfile_cpp.txt.

Thank you in advance,

Llu?s Hurtado-Gil

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: myfile_cpp.txt
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20190808/465ee6d9/attachment-0002.txt>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: myfile_r.txt
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20190808/465ee6d9/attachment-0003.txt>

From e@ @end|ng |rom enr|co@chum@nn@net  Thu Aug  8 14:46:50 2019
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Thu, 08 Aug 2019 14:46:50 +0200
Subject: [Rd] Producing different text formats in R
In-Reply-To: <4455417873hurgil@uv.es> (Lluis Hurtado's message of "Thu, 8 Aug
 2019 11:38:42 +0200 (CEST)")
References: <4455417873hurgil@uv.es>
Message-ID: <87o90zomdh.fsf@enricoschumann.net>

>>>>> "Llu?s" ==   <Lluis.Hurtado at uv.es> writes:

    Llu?s> Dear all,
    Llu?s> I am facing a strange problem with text files formats.

    Llu?s> I am currently using a C++ code named voro++ (http://math.lbl.gov/voro++/). This code accepts text files with four columns:

    Llu?s> <id> <x> <y> <z>

    Llu?s> where id is an identification number and x,y,z are the coordinates of a point in a 3D space.

    Llu?s> The input file, name it myfile_cpp.txt, is generated by another C++ code written by myself (named quadscheme.cpp). So far, these calculations involve no R code and it works just fine.

    Llu?s> However, now I am trying to replace my C++ code quadscheme.cpp by a R function. The four columns (id,x,y,z) are produced in a matrix or Data Frame and then saved in a file myfile_r.txt using write.table(). For example using the following function:

    Llu?s> quadscheme <- function(window, ntile) {
    Llu?s>   # Creates a grid of points in a 3D orthohedron. 
    Llu?s>   # First point lies at the (mix,miny,miz) corner of the volume and the last one at (maxx,maxy,maxz)
    Llu?s>   # window: vector. Contains the minimum and maximum values of a 3D orthohedron
    Llu?s>   #       window <- c(minx, maxx, miny, maxy, minz, maxz)
    Llu?s>   # ntile: vector. Number of points per dimension minus one. We manually add a extra row of points per dimension
    Llu?s>   #       ntile <- c(nstepx, nstepy, nstepz)
    Llu?s>   M <- prod(ntile+1) 
    Llu?s>   mat <- matrix(NA,M,4)
    Llu?s>   mat[,1] <- 1:M # id column
  
    Llu?s>   # step length per dimension
    Llu?s>   hi <- (window[2] - window[1])/ntile[1]
    Llu?s>   hj <- (window[4] - window[3])/ntile[2]
    Llu?s>   hk <- (window[6] - window[5])/ntile[3]
  
    Llu?s>   c <- 1
    Llu?s>   for(i in 0:ntile[1]) {
    Llu?s>     x <- i*hi + window[1]
    Llu?s>     for(j in 0:ntile[2]) {
    Llu?s>       y <- hj*j + window[3]
    Llu?s>       for(k in 0:ntile[3]) {
    Llu?s>         z <- k*hk + window[5]
    Llu?s>         mat[c,2:4] <- c(x,y,z) # Add a new point to the grid
    Llu?s>         c <- c + 1
    Llu?s>       }
    Llu?s>     }
    Llu?s>   }
    Llu?s>   write.table(mat, file="myfile_r.txt", row.names=FALSE, col.names=FALSE)
    Llu?s> }

    Llu?s> And then calling:

    >> window <- c(18, 43, 171, 196, 95, 102)
    >> ntile <- c(100,100,28)
    >> quadscheme(window, ntile)

    Llu?s> I see no difference between both myfile_*.txt files,
    Llu?s> one is created with C++ and the other one with
    Llu?s> R. However, function voro++ do not accept the later one
    Llu?s> (created with R and saved with write.table). I've also
    Llu?s> noted that voro++ usually accepts R generated files
    Llu?s> when they are small enough, but it accepts all C++
    Llu?s> generated files, regardless the size.

    Llu?s> I know this is more a C++ than a R question, but may be
    Llu?s> you can help me as well. I suspect that even if both
    Llu?s> files are *.txt they have some differences that I
    Llu?s> cannot see. Is there any way in R to produce different
    Llu?s> kinds of txt files? Like binary instead of text files?
    Llu?s> Could this be the problem?

    Llu?s> I attach two identical files, one produced by C++
    Llu?s> (myfile_cpp.txt) and another one by the previous R
    Llu?s> function (myfile_r.txt). I attach as well the C++ code
    Llu?s> used to generate myfile_cpp.txt.

    Llu?s> Thank you in advance,

    Llu?s> Llu?s Hurtado-Gil

In your R file, scientific notation is used:

R:
  99999 26.5 174.5 96.5
  1e+05 26.5 174.5 96.75
  100001 26.5 174.5 97

cpp:
  99999 26.5 174.5 96.5
  100000 26.5 174.5 96.75
  100001 26.5 174.5 97

Try setting options(scipen = 20) before you write the
file in R.



-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From j@me@@|@he@ter @end|ng |rom gm@||@com  Thu Aug  8 16:31:49 2019
From: j@me@@|@he@ter @end|ng |rom gm@||@com (Jim Hester)
Date: Thu, 8 Aug 2019 10:31:49 -0400
Subject: [Rd] Underscores in package names
Message-ID: <CAD6tx94RYHAWCFVuMgMXLUUFG3BgKSCfs3Un=SStQ7rCtgAUSQ@mail.gmail.com>

Are there technical reasons that package names cannot be snake case?
This seems to be enforced by `.standard_regexps()$valid_package_name`
which currently returns

   "[[:alpha:]][[:alnum:].]*[[:alnum:]]"

Is there any technical reason this couldn't be altered to accept `_`
as well, e.g.

  "[[:alpha:]][[:alnum:]._]*[[:alnum:]]"

I realize that historically `_` has not always been valid in variable
names, but this has now been acceptable for 15+ years (since R 1.9.0 I
believe). Might we also allow underscores for package names?

Jim


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Aug  8 17:05:15 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 8 Aug 2019 11:05:15 -0400
Subject: [Rd] Underscores in package names
In-Reply-To: <CAD6tx94RYHAWCFVuMgMXLUUFG3BgKSCfs3Un=SStQ7rCtgAUSQ@mail.gmail.com>
References: <CAD6tx94RYHAWCFVuMgMXLUUFG3BgKSCfs3Un=SStQ7rCtgAUSQ@mail.gmail.com>
Message-ID: <4f049dfc-5e33-68d9-6946-19766b54eb44@gmail.com>

On 08/08/2019 10:31 a.m., Jim Hester wrote:
> Are there technical reasons that package names cannot be snake case?
> This seems to be enforced by `.standard_regexps()$valid_package_name`
> which currently returns
> 
>     "[[:alpha:]][[:alnum:].]*[[:alnum:]]"
> 
> Is there any technical reason this couldn't be altered to accept `_`
> as well, e.g.
> 
>    "[[:alpha:]][[:alnum:]._]*[[:alnum:]]"
> 
> I realize that historically `_` has not always been valid in variable
> names, but this has now been acceptable for 15+ years (since R 1.9.0 I
> believe). Might we also allow underscores for package names?

The tarball names separate the package name from the version number 
using an underscore.  There is code that is written to assume there is 
at most one underscore, e.g. .check_package_CRAN_incoming in 
src/library/tools/R/QC.r.

That code could be changed, but so could the proposed package name...

Duncan Murdoch


From edd @end|ng |rom deb|@n@org  Thu Aug  8 17:22:40 2019
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Thu, 8 Aug 2019 10:22:40 -0500
Subject: [Rd] Producing different text formats in R
In-Reply-To: <4455417873hurgil@uv.es>
References: <4455417873hurgil@uv.es>
Message-ID: <23884.15936.351247.596433@rob.eddelbuettel.com>


Llu?s,

You sent a 8+ mb file to a (I presume) 1000+ subscribers of this list. That
is not generally a good idea, and I am surprised this got past the mailman
software which (usually) filters at 100k (and for a reason).

In the future, please consider uploading the file somewhere (GitHub gists are
easy) and send a link.  We also often talk about "minimally complete
verifiable examples" (mcve) and the minimal is there for a reason.

Thanks for your consideration,  Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From ken@hoo @end|ng |rom gm@||@com  Fri Aug  9 00:37:38 2019
From: ken@hoo @end|ng |rom gm@||@com (Ken Williams)
Date: Thu, 8 Aug 2019 17:37:38 -0500
Subject: [Rd] Appetite for eliminating dependency on Perl
Message-ID: <CACrz-HtdcU_P6dL3Nvne5NJ-HJeTQNiooZXxZUxYL-VF8K7=ow@mail.gmail.com>

Preamble: I am in no way opposed to Perl in general - I love Perl and
probably always will.

R currently has Perl as both a build-time and run-time dependency.  This
adds about 200 Mb, give or take, to the required environment size (as
measured in CentOS - looks like it might be a bit smaller in Ubuntu?).

Not such a huge deal, really, but the actual benefit R gets from the
dependency is quite small.  From my poking around in the R sources (using
`git grep -P '\bperl\b(?! ?= ?(?:TRUE|FALSE))' ` as a filter), it looks
like it's only used in the following nooks & crannies:

* tools/help2man.pl
* tools/install-info.pl
* configure:      INSTALL_INFO="perl \$(top_srcdir)/tools/install-info.pl"
* m4/R.m4:      INSTALL_INFO="perl \$(top_srcdir)/tools/install-info.pl"

Ultimately that's only two scripts.  `help2man.pl` seems like it's part of
the build process, but not used at runtime.  `install-info.pl` seems like
maybe it's runnable at runtime, but requires user initiation to run, at
which point the user is expected to have perl installed.  Either one of
them could probably be ported to another language pretty easily, maybe even
R.

Anything else I missed?

If someone were to volunteer the porting work, would there be any appetite
for eliminating the dependency?

  -Ken

	[[alternative HTML version deleted]]


From pd@|gd @end|ng |rom gm@||@com  Fri Aug  9 10:37:54 2019
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Fri, 9 Aug 2019 10:37:54 +0200
Subject: [Rd] Appetite for eliminating dependency on Perl
In-Reply-To: <CACrz-HtdcU_P6dL3Nvne5NJ-HJeTQNiooZXxZUxYL-VF8K7=ow@mail.gmail.com>
References: <CACrz-HtdcU_P6dL3Nvne5NJ-HJeTQNiooZXxZUxYL-VF8K7=ow@mail.gmail.com>
Message-ID: <8ADEFAE0-B919-402F-80CD-766AEC68336F@gmail.com>

Dunno about runtime. We used to have much more - all the Rdconv stuff used to be based on pattern matching by Perl scripts, but they were converted to R scripts and later to use proper parsers. 

For building, if you ever need to regenerate a configure script or write your own for a package, notice that aclocal & friends are Perl scripts. 

-pd

> On 9 Aug 2019, at 00:37 , Ken Williams <kenahoo at gmail.com> wrote:
> 
> Preamble: I am in no way opposed to Perl in general - I love Perl and
> probably always will.
> 
> R currently has Perl as both a build-time and run-time dependency.  This
> adds about 200 Mb, give or take, to the required environment size (as
> measured in CentOS - looks like it might be a bit smaller in Ubuntu?).
> 
> Not such a huge deal, really, but the actual benefit R gets from the
> dependency is quite small.  From my poking around in the R sources (using
> `git grep -P '\bperl\b(?! ?= ?(?:TRUE|FALSE))' ` as a filter), it looks
> like it's only used in the following nooks & crannies:
> 
> * tools/help2man.pl
> * tools/install-info.pl
> * configure:      INSTALL_INFO="perl \$(top_srcdir)/tools/install-info.pl"
> * m4/R.m4:      INSTALL_INFO="perl \$(top_srcdir)/tools/install-info.pl"
> 
> Ultimately that's only two scripts.  `help2man.pl` seems like it's part of
> the build process, but not used at runtime.  `install-info.pl` seems like
> maybe it's runnable at runtime, but requires user initiation to run, at
> which point the user is expected to have perl installed.  Either one of
> them could probably be ported to another language pretty easily, maybe even
> R.
> 
> Anything else I missed?
> 
> If someone were to volunteer the porting work, would there be any appetite
> for eliminating the dependency?
> 
>  -Ken
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From Liuis@Hurt@do m@iii@g oii uv@es  Fri Aug  9 12:30:02 2019
From: Liuis@Hurt@do m@iii@g oii uv@es (Liuis@Hurt@do m@iii@g oii uv@es)
Date: Fri, 9 Aug 2019 12:30:02 +0200 (CEST)
Subject: [Rd] Producing different text formats in R
In-Reply-To: <87o90zomdh.fsf@enricoschumann.net>
References: <87o90zomdh.fsf@enricoschumann.net>
Message-ID: <4476463122hurgil@uv.es>

Thank you for your fast answer. It just works fine now.

And apologies for attaching heavy files.

Llu?s.

> >>>>> "Llu?s" ==   <Lluis.Hurtado at uv.es> writes:
> 
>     Llu?s> Dear all,
>     Llu?s> I am facing a strange problem with text files formats.
> 
>     Llu?s> I am currently using a C++ code named voro++ (http://mathlbl.gov/voro++/). This code accepts text files with four columns:
> 
>     Llu?s> <id> <x> <y> <z>
> 
>     Llu?s> where id is an identification number and x,y,z are the coordinates of a point in a 3D space.
> 
>     Llu?s> The input file, name it myfile_cpp.txt, is generated by another C++ code written by myself (named quadscheme.cpp). So far, these calculations involve no R code and it works just fine.
> 
>     Llu?s> However, now I am trying to replace my C++ code quadscheme.cpp by a R function. The four columns (id,x,y,z) are produced in a matrix or Data Frame and then saved in a file myfile_r.txt using write.table(). For example using the following function:
> 
>     Llu?s> quadscheme <- function(window, ntile) {
>     Llu?s>   # Creates a grid of points in a 3D orthohedron. 
>     Llu?s>   # First point lies at the (mix,miny,miz) corner of the volume and the last one at (maxx,maxy,maxz)
>     Llu?s>   # window: vector. Contains the minimum and maximum values of a 3D orthohedron
>     Llu?s>   #       window <- c(minx, maxx, miny, maxy, minz, maxz)
>     Llu?s>   # ntile: vector. Number of points per dimension minus one. We manually add a extra row of points per dimension
>     Llu?s>   #       ntile <- c(nstepx, nstepy, nstepz)
>     Llu?s>   M <- prod(ntile+1) 
>     Llu?s>   mat <- matrix(NA,M,4)
>     Llu?s>   mat[,1] <- 1:M # id column
>   
>     Llu?s>   # step length per dimension
>     Llu?s>   hi <- (window[2] - window[1])/ntile[1]
>     Llu?s>   hj <- (window[4] - window[3])/ntile[2]
>     Llu?s>   hk <- (window[6] - window[5])/ntile[3]
>   
>     Llu?s>   c <- 1
>     Llu?s>   for(i in 0:ntile[1]) {
>     Llu?s>     x <- i*hi + window[1]
>     Llu?s>     for(j in 0:ntile[2]) {
>     Llu?s>       y <- hj*j + window[3]
>     Llu?s>       for(k in 0:ntile[3]) {
>     Llu?s>         z <- k*hk + window[5]
>     Llu?s>         mat[c,2:4] <- c(x,y,z) # Add a new point to the grid
>     Llu?s>         c <- c + 1
>     Llu?s>       }
>     Llu?s>     }
>     Llu?s>   }
>     Llu?s>   write.table(mat, file="myfile_r.txt", row.names=FALSE, col.names=FALSE)
>     Llu?s> }
> 
>     Llu?s> And then calling:
> 
>     >> window <- c(18, 43, 171, 196, 95, 102)
>     >> ntile <- c(100,100,28)
>     >> quadscheme(window, ntile)
> 
>     Llu?s> I see no difference between both myfile_*.txt files,
>     Llu?s> one is created with C++ and the other one with
>     Llu?s> R. However, function voro++ do not accept the later one
>     Llu?s> (created with R and saved with write.table). I've also
>     Llu?s> noted that voro++ usually accepts R generated files
>     Llu?s> when they are small enough, but it accepts all C++
>     Llu?s> generated files, regardless the size.
> 
>     Llu?s> I know this is more a C++ than a R question, but may be
>     Llu?s> you can help me as well. I suspect that even if both
>     Llu?s> files are *.txt they have some differences that I
>     Llu?s> cannot see. Is there any way in R to produce different
>     Llu?s> kinds of txt files? Like binary instead of text files?
>     Llu?s> Could this be the problem?
> 
>     Llu?s> I attach two identical files, one produced by C++
>     Llu?s> (myfile_cpp.txt) and another one by the previous R
>     Llu?s> function (myfile_r.txt). I attach as well the C++ code
>     Llu?s> used to generate myfile_cpp.txt.
> 
>     Llu?s> Thank you in advance,
> 
>     Llu?s> Llu?s Hurtado-Gil
> 
> In your R file, scientific notation is used:
> 
> R:
>   99999 26.5 174.5 96.5
>   1e+05 26.5 174.5 96.75
>   100001 26.5 174.5 97
> 
> cpp:
>   99999 26.5 174.5 96.5
>   100000 26.5 174.5 96.75
>   100001 26.5 174.5 97
> 
> Try setting options(scipen = 20) before you write the
> file in R.
> 
> 
> 
> -- 
> Enrico Schumann
> Lucerne, Switzerland
> http://enricoschumann.net
> 


From j@me@@|@he@ter @end|ng |rom gm@||@com  Fri Aug  9 16:23:47 2019
From: j@me@@|@he@ter @end|ng |rom gm@||@com (Jim Hester)
Date: Fri, 9 Aug 2019 10:23:47 -0400
Subject: [Rd] Underscores in package names
In-Reply-To: <4f049dfc-5e33-68d9-6946-19766b54eb44@gmail.com>
References: <CAD6tx94RYHAWCFVuMgMXLUUFG3BgKSCfs3Un=SStQ7rCtgAUSQ@mail.gmail.com>
 <4f049dfc-5e33-68d9-6946-19766b54eb44@gmail.com>
Message-ID: <CAD6tx95E2cu2SE4-3JS8DJH+LMFwpNCXu1B-AZmde-mDB_Y_WA@mail.gmail.com>

To be clear, I'd be happy to contribute code to make this work, with
the changes mentioned by Duncan and elsewhere in the codebase, if
someone on R-core was interested in reviewing it.

Jim

On Thu, Aug 8, 2019 at 11:05 AM Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
> On 08/08/2019 10:31 a.m., Jim Hester wrote:
> > Are there technical reasons that package names cannot be snake case?
> > This seems to be enforced by `.standard_regexps()$valid_package_name`
> > which currently returns
> >
> >     "[[:alpha:]][[:alnum:].]*[[:alnum:]]"
> >
> > Is there any technical reason this couldn't be altered to accept `_`
> > as well, e.g.
> >
> >    "[[:alpha:]][[:alnum:]._]*[[:alnum:]]"
> >
> > I realize that historically `_` has not always been valid in variable
> > names, but this has now been acceptable for 15+ years (since R 1.9.0 I
> > believe). Might we also allow underscores for package names?
>
> The tarball names separate the package name from the version number
> using an underscore.  There is code that is written to assume there is
> at most one underscore, e.g. .check_package_CRAN_incoming in
> src/library/tools/R/QC.r.
>
> That code could be changed, but so could the proposed package name...
>
> Duncan Murdoch


From kw@@t@t @end|ng |rom gm@||@com  Fri Aug  9 18:39:56 2019
From: kw@@t@t @end|ng |rom gm@||@com (Kevin Wright)
Date: Fri, 9 Aug 2019 11:39:56 -0500
Subject: [Rd] Underscores in package names
In-Reply-To: <CAD6tx94RYHAWCFVuMgMXLUUFG3BgKSCfs3Un=SStQ7rCtgAUSQ@mail.gmail.com>
References: <CAD6tx94RYHAWCFVuMgMXLUUFG3BgKSCfs3Un=SStQ7rCtgAUSQ@mail.gmail.com>
Message-ID: <CAKFxdiRMmGwf1AWEBPvu4xtkhQpC6-Xoava2ZVwgxcz0jRkYyg@mail.gmail.com>

Please, no.  I'd also like to disallow uppercase letters in package names.
For instance, the cuteness of using a capital "R" in package names is
outweighed by the annoyance of trying to remember which packages use an
upper-case letter.

On Thu, Aug 8, 2019 at 9:32 AM Jim Hester <james.f.hester at gmail.com> wrote:

> Are there technical reasons that package names cannot be snake case?
> This seems to be enforced by `.standard_regexps()$valid_package_name`
> which currently returns
>
>    "[[:alpha:]][[:alnum:].]*[[:alnum:]]"
>
> Is there any technical reason this couldn't be altered to accept `_`
> as well, e.g.
>
>   "[[:alpha:]][[:alnum:]._]*[[:alnum:]]"
>
> I realize that historically `_` has not always been valid in variable
> names, but this has now been acceptable for 15+ years (since R 1.9.0 I
> believe). Might we also allow underscores for package names?
>
> Jim
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Kevin Wright

	[[alternative HTML version deleted]]


From g@bembecker @end|ng |rom gm@||@com  Fri Aug  9 19:55:28 2019
From: g@bembecker @end|ng |rom gm@||@com (Gabriel Becker)
Date: Fri, 9 Aug 2019 10:55:28 -0700
Subject: [Rd] Underscores in package names
In-Reply-To: <CAKFxdiRMmGwf1AWEBPvu4xtkhQpC6-Xoava2ZVwgxcz0jRkYyg@mail.gmail.com>
References: <CAD6tx94RYHAWCFVuMgMXLUUFG3BgKSCfs3Un=SStQ7rCtgAUSQ@mail.gmail.com>
 <CAKFxdiRMmGwf1AWEBPvu4xtkhQpC6-Xoava2ZVwgxcz0jRkYyg@mail.gmail.com>
Message-ID: <CAD4oTHEM+f0WUUsx1D7LqCUqn7AV+BThGg+Gmb46eYPTxqd3Dw@mail.gmail.com>

Hi Jim,

While its true that it wouldn't be *particularly *hard^^ to adapt the base
code to change this, there is certainly a non-zero amount of user/package
code that relies on the well-defined package tarball naming scheme as well.
I know because I've written some myself in switchr/GRAN* but I seriously
doubt I'm the only one. I would imagine there's also quite a bit of more if
you include DEVOPSy-style build/administration scripts and not just user R
code.

To me, the benefit of this change seems a pretty minor "nice-to-have" when
weighed against breaking even a moderate amount of existing code.

^^ making sure we found every place the tarball naming scheme/package name
constraints are implicitly assumed in the R sources might well be less
trivial than we think, though once found I agree the changes would likely
be *relatively* straightforward. For example, I happen to know that in
addition to the places Duncan pointed out,  tools::update_PACKAGES relies
heavily on code that extracts the name and version of a package from
something that "looks like a package tarball" as an optimization mechanism,
so that would need to be reworked. It seems likely  (almost certain?) that
write_PACKAGES also relies on matching the tarball-name patter when
determining which packages are present, though I remember less details
there because I didn't write most of it.

Best,
~G



On Fri, Aug 9, 2019 at 9:40 AM Kevin Wright <kw.stat at gmail.com> wrote:

> Please, no.  I'd also like to disallow uppercase letters in package names.
> For instance, the cuteness of using a capital "R" in package names is
> outweighed by the annoyance of trying to remember which packages use an
> upper-case letter.
>
> On Thu, Aug 8, 2019 at 9:32 AM Jim Hester <james.f.hester at gmail.com>
> wrote:
>
> > Are there technical reasons that package names cannot be snake case?
> > This seems to be enforced by `.standard_regexps()$valid_package_name`
> > which currently returns
> >
> >    "[[:alpha:]][[:alnum:].]*[[:alnum:]]"
> >
> > Is there any technical reason this couldn't be altered to accept `_`
> > as well, e.g.
> >
> >   "[[:alpha:]][[:alnum:]._]*[[:alnum:]]"
> >
> > I realize that historically `_` has not always been valid in variable
> > names, but this has now been acceptable for 15+ years (since R 1.9.0 I
> > believe). Might we also allow underscores for package names?
> >
> > Jim
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>
> --
> Kevin Wright
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From neon|r@ @end|ng |rom gm@||@com  Fri Aug  9 20:00:41 2019
From: neon|r@ @end|ng |rom gm@||@com (neonira Arinoem)
Date: Fri, 9 Aug 2019 20:00:41 +0200
Subject: [Rd] Underscores in package names
In-Reply-To: <CAKFxdiRMmGwf1AWEBPvu4xtkhQpC6-Xoava2ZVwgxcz0jRkYyg@mail.gmail.com>
References: <CAD6tx94RYHAWCFVuMgMXLUUFG3BgKSCfs3Un=SStQ7rCtgAUSQ@mail.gmail.com>
 <CAKFxdiRMmGwf1AWEBPvu4xtkhQpC6-Xoava2ZVwgxcz0jRkYyg@mail.gmail.com>
Message-ID: <CAN--Dz2=ScCo985xtKQrVbmkWEq4hq=q2QD5V-DKQxeCQdhNrw@mail.gmail.com>

Won't it be better to have a convention that allows lowercase, dash,
underscore and dot as only valid characters for new package names and keep
the ancient format validation scheme for older package names?

This could be implemented by a single function, taking a strictNaming_b_1
parameter which defaults to true. Easy to use, and compliance results will
vary according to the parameter value, allowing strict compliance for new
package names and lazy compliance for older ones.

Doing so allows to enforce a new package name convention while also
insuring continuity of compliance for already existing package names.

Fabien GELINEAU alias Neonira

Le ven. 9 ao?t 2019 ? 18:40, Kevin Wright <kw.stat at gmail.com> a ?crit :

> Please, no.  I'd also like to disallow uppercase letters in package names.
> For instance, the cuteness of using a capital "R" in package names is
> outweighed by the annoyance of trying to remember which packages use an
> upper-case letter.
>
> On Thu, Aug 8, 2019 at 9:32 AM Jim Hester <james.f.hester at gmail.com>
> wrote:
>
> > Are there technical reasons that package names cannot be snake case?
> > This seems to be enforced by `.standard_regexps()$valid_package_name`
> > which currently returns
> >
> >    "[[:alpha:]][[:alnum:].]*[[:alnum:]]"
> >
> > Is there any technical reason this couldn't be altered to accept `_`
> > as well, e.g.
> >
> >   "[[:alpha:]][[:alnum:]._]*[[:alnum:]]"
> >
> > I realize that historically `_` has not always been valid in variable
> > names, but this has now been acceptable for 15+ years (since R 1.9.0 I
> > believe). Might we also allow underscores for package names?
> >
> > Jim
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>
> --
> Kevin Wright
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Fri Aug  9 20:17:36 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 9 Aug 2019 14:17:36 -0400
Subject: [Rd] Underscores in package names
In-Reply-To: <CAN--Dz2=ScCo985xtKQrVbmkWEq4hq=q2QD5V-DKQxeCQdhNrw@mail.gmail.com>
References: <CAD6tx94RYHAWCFVuMgMXLUUFG3BgKSCfs3Un=SStQ7rCtgAUSQ@mail.gmail.com>
 <CAKFxdiRMmGwf1AWEBPvu4xtkhQpC6-Xoava2ZVwgxcz0jRkYyg@mail.gmail.com>
 <CAN--Dz2=ScCo985xtKQrVbmkWEq4hq=q2QD5V-DKQxeCQdhNrw@mail.gmail.com>
Message-ID: <39ab1460-08da-99a9-691e-6b4f05f67258@gmail.com>


  Creeping code complexity ...

  I like to think that the cuteR names will have a Darwinian
disadvantage in the long run. FWIW Hadley Wickham argues (rightly, I
think) against mixed-case names:
http://r-pkgs.had.co.nz/package.html#naming. I too am guilty of picking
mixed-case package names in the past.  Extra credit if the package name
and the standard function have different cases! e.g.
glmmADMB::glmmadmb(), although (a) that wasn't my choice and (b) at
least it was never on CRAN and (c) it wasn't one of the cuteR variety.

  Bonus points for the first analysis of case conventions in existing
CRAN package names ... I'll start.

> a1 <- rownames(available.packages())
> cute <- "[a-z]*R[a-z]*"
> table(grepl(cute,a1))

FALSE  TRUE
12565  2185


On 2019-08-09 2:00 p.m., neonira Arinoem wrote:
> Won't it be better to have a convention that allows lowercase, dash,
> underscore and dot as only valid characters for new package names and keep
> the ancient format validation scheme for older package names?
> 
> This could be implemented by a single function, taking a strictNaming_b_1
> parameter which defaults to true. Easy to use, and compliance results will
> vary according to the parameter value, allowing strict compliance for new
> package names and lazy compliance for older ones.
> 
> Doing so allows to enforce a new package name convention while also
> insuring continuity of compliance for already existing package names.
> 
> Fabien GELINEAU alias Neonira
> 
> Le ven. 9 ao?t 2019 ? 18:40, Kevin Wright <kw.stat at gmail.com> a ?crit :
> 
>> Please, no.  I'd also like to disallow uppercase letters in package names.
>> For instance, the cuteness of using a capital "R" in package names is
>> outweighed by the annoyance of trying to remember which packages use an
>> upper-case letter.
>>
>> On Thu, Aug 8, 2019 at 9:32 AM Jim Hester <james.f.hester at gmail.com>
>> wrote:
>>
>>> Are there technical reasons that package names cannot be snake case?
>>> This seems to be enforced by `.standard_regexps()$valid_package_name`
>>> which currently returns
>>>
>>>    "[[:alpha:]][[:alnum:].]*[[:alnum:]]"
>>>
>>> Is there any technical reason this couldn't be altered to accept `_`
>>> as well, e.g.
>>>
>>>   "[[:alpha:]][[:alnum:]._]*[[:alnum:]]"
>>>
>>> I realize that historically `_` has not always been valid in variable
>>> names, but this has now been acceptable for 15+ years (since R 1.9.0 I
>>> believe). Might we also allow underscores for package names?
>>>
>>> Jim
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>
>> --
>> Kevin Wright
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From tob|@@@verbeke @end|ng |rom open@n@|yt|c@@eu  Fri Aug  9 20:40:05 2019
From: tob|@@@verbeke @end|ng |rom open@n@|yt|c@@eu (Tobias Verbeke)
Date: Fri, 9 Aug 2019 20:40:05 +0200 (CEST)
Subject: [Rd] Underscores in package names
In-Reply-To: <39ab1460-08da-99a9-691e-6b4f05f67258@gmail.com>
References: <CAD6tx94RYHAWCFVuMgMXLUUFG3BgKSCfs3Un=SStQ7rCtgAUSQ@mail.gmail.com>
 <CAKFxdiRMmGwf1AWEBPvu4xtkhQpC6-Xoava2ZVwgxcz0jRkYyg@mail.gmail.com>
 <CAN--Dz2=ScCo985xtKQrVbmkWEq4hq=q2QD5V-DKQxeCQdhNrw@mail.gmail.com>
 <39ab1460-08da-99a9-691e-6b4f05f67258@gmail.com>
Message-ID: <148217872.129861.1565376005541.JavaMail.zimbra@openanalytics.eu>

> Creeping code complexity ...
> 
>  I like to think that the cuteR names will have a Darwinian
> disadvantage in the long run. FWIW Hadley Wickham argues (rightly, I
> think) against mixed-case names:
> http://r-pkgs.had.co.nz/package.html#naming.

Good development environments will offer content assist (or tab completion or similar) which will not be hindered by naming conventions (whether camel case, dromedary case or other forms that snaked into the R world). Talking about Darwinian advantages, Wikipedia[1] just taught me about the existence of 'darwin case' ?!

Best,
Tobias

[1] https://en.wikipedia.org/wiki/Camel_case

> On 2019-08-09 2:00 p.m., neonira Arinoem wrote:
>> Won't it be better to have a convention that allows lowercase, dash,
>> underscore and dot as only valid characters for new package names and keep
>> the ancient format validation scheme for older package names?
>> 
>> This could be implemented by a single function, taking a strictNaming_b_1
>> parameter which defaults to true. Easy to use, and compliance results will
>> vary according to the parameter value, allowing strict compliance for new
>> package names and lazy compliance for older ones.
>> 
>> Doing so allows to enforce a new package name convention while also
>> insuring continuity of compliance for already existing package names.
>> 
>> Fabien GELINEAU alias Neonira
>> 
>> Le ven. 9 ao?t 2019 ? 18:40, Kevin Wright <kw.stat at gmail.com> a ?crit :
>> 
>>> Please, no.  I'd also like to disallow uppercase letters in package names.
>>> For instance, the cuteness of using a capital "R" in package names is
>>> outweighed by the annoyance of trying to remember which packages use an
>>> upper-case letter.
>>>
>>> On Thu, Aug 8, 2019 at 9:32 AM Jim Hester <james.f.hester at gmail.com>
>>> wrote:
>>>
>>>> Are there technical reasons that package names cannot be snake case?
>>>> This seems to be enforced by `.standard_regexps()$valid_package_name`
>>>> which currently returns
>>>>
>>>>    "[[:alpha:]][[:alnum:].]*[[:alnum:]]"
>>>>
>>>> Is there any technical reason this couldn't be altered to accept `_`
>>>> as well, e.g.
>>>>
>>>>   "[[:alpha:]][[:alnum:]._]*[[:alnum:]]"
>>>>
>>>> I realize that historically `_` has not always been valid in variable
>>>> names, but this has now been acceptable for 15+ years (since R 1.9.0 I
>>>> believe). Might we also allow underscores for package names?
>>>>
>>>> Jim
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>>
>>> --
>>> Kevin Wright
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From g@bembecker @end|ng |rom gm@||@com  Fri Aug  9 20:41:15 2019
From: g@bembecker @end|ng |rom gm@||@com (Gabriel Becker)
Date: Fri, 9 Aug 2019 11:41:15 -0700
Subject: [Rd] Underscores in package names
In-Reply-To: <CAN--Dz2=ScCo985xtKQrVbmkWEq4hq=q2QD5V-DKQxeCQdhNrw@mail.gmail.com>
References: <CAD6tx94RYHAWCFVuMgMXLUUFG3BgKSCfs3Un=SStQ7rCtgAUSQ@mail.gmail.com>
 <CAKFxdiRMmGwf1AWEBPvu4xtkhQpC6-Xoava2ZVwgxcz0jRkYyg@mail.gmail.com>
 <CAN--Dz2=ScCo985xtKQrVbmkWEq4hq=q2QD5V-DKQxeCQdhNrw@mail.gmail.com>
Message-ID: <CAD4oTHHGvPDXg1uKhMO9KKjgPRDfYxUug8fTLLwj-sJdUw9Vfg@mail.gmail.com>

On Fri, Aug 9, 2019 at 11:05 AM neonira Arinoem <neonira at gmail.com> wrote:

> Won't it be better to have a convention that allows lowercase, dash,
> underscore and dot as only valid characters for new package names and keep
> the ancient format validation scheme for older package names?
>

Validation isn't the only thing we need to do wrt package names. we also
need to detect them, and particularly,  in at least one case, extract them
from package tarball filenames (which we also need to be able to
detect/find).

If we were writing a new language and people wanted to allow snake case in
package names, sure, but we're talking about about changing how a small but
package names and package tarballs have always (or at least a very long
time, I didn't check) had the same form, and it seems expressive enough to
me? I mean periods are allowed if you feel a strong need for something
other than a letter.

Note that this proposal would make mypackage_2.3.1 a valid *package name*,
whose corresponding tarball name might be mypackage_2.3.1_2.3.2 after a
patch. Yes its a silly example, but why allow that kind of ambiguity?



For the record @Ben Bolker <bbolker at gmail.com>

Packages that mix case anywhere in their package name:

> table(grepl("((^[a-z].*[A-Z])|(^[A-Z].*[a-z]))", row.names(a1)))


FALSE  TRUE

 8818  5932


Packages which start with lower case and have at least one upper

> table(grepl("((^[a-z].*[A-Z]))", row.names(a1)))


FALSE  TRUE

12315  2435


Packages which start with uppercase and have at least one lower

> table(grepl("((^[A-Z].*[a-z]))", row.names(a1)))


FALSE  TRUE

11253  3497

Packages which take advantage of the above-mentioned legality of periods

> table(grepl(".", row.names(a1), fixed=TRUE))


FALSE  TRUE

14259   491

Packages with pure lower-case alphabetic names

> table(grepl("^[a-z]+$", row.names(a1)))


FALSE  TRUE

 7712  7038


Packages with pure upper-case alphabetic names

> table(grepl("^[A-Z]+$", row.names(a1)))


FALSE  TRUE

13636  1114


Package with at least one numeric digit in their name

> table(grepl("[0-9]", row.names(a1)))


FALSE  TRUE

14208   542


It would be interesting to do an actual analysis of the changes in these
trends over time, but I Really should be working, so that will have to
either wait or be done by someone else.
Best,
~G



> This could be implemented by a single function, taking a strictNaming_b_1
> parameter which defaults to true. Easy to use, and compliance results will
> vary according to the parameter value, allowing strict compliance for new
> package names and lazy compliance for older ones.
>
> Doing so allows to enforce a new package name convention while also
> insuring continuity of compliance for already existing package names.
>
> Fabien GELINEAU alias Neonira
>
> Le ven. 9 ao?t 2019 ? 18:40, Kevin Wright <kw.stat at gmail.com> a ?crit :
>
> > Please, no.  I'd also like to disallow uppercase letters in package
> names.
> > For instance, the cuteness of using a capital "R" in package names is
> > outweighed by the annoyance of trying to remember which packages use an
> > upper-case letter.
> >
> > On Thu, Aug 8, 2019 at 9:32 AM Jim Hester <james.f.hester at gmail.com>
> > wrote:
> >
> > > Are there technical reasons that package names cannot be snake case?
> > > This seems to be enforced by `.standard_regexps()$valid_package_name`
> > > which currently returns
> > >
> > >    "[[:alpha:]][[:alnum:].]*[[:alnum:]]"
> > >
> > > Is there any technical reason this couldn't be altered to accept `_`
> > > as well, e.g.
> > >
> > >   "[[:alpha:]][[:alnum:]._]*[[:alnum:]]"
> > >
> > > I realize that historically `_` has not always been valid in variable
> > > names, but this has now been acceptable for 15+ years (since R 1.9.0 I
> > > believe). Might we also allow underscores for package names?
> > >
> > > Jim
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > >
> >
> >
> > --
> > Kevin Wright
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From neon|r@ @end|ng |rom gm@||@com  Fri Aug  9 21:27:32 2019
From: neon|r@ @end|ng |rom gm@||@com (neonira Arinoem)
Date: Fri, 9 Aug 2019 21:27:32 +0200
Subject: [Rd] Underscores in package names
In-Reply-To: <CAD4oTHHGvPDXg1uKhMO9KKjgPRDfYxUug8fTLLwj-sJdUw9Vfg@mail.gmail.com>
References: <CAD6tx94RYHAWCFVuMgMXLUUFG3BgKSCfs3Un=SStQ7rCtgAUSQ@mail.gmail.com>
 <CAKFxdiRMmGwf1AWEBPvu4xtkhQpC6-Xoava2ZVwgxcz0jRkYyg@mail.gmail.com>
 <CAN--Dz2=ScCo985xtKQrVbmkWEq4hq=q2QD5V-DKQxeCQdhNrw@mail.gmail.com>
 <CAD4oTHHGvPDXg1uKhMO9KKjgPRDfYxUug8fTLLwj-sJdUw9Vfg@mail.gmail.com>
Message-ID: <CAN--Dz2xQtdu19yeNqJJ2PaR8c20gzz6Ev=v7=KNPPhLgcBR2Q@mail.gmail.com>

I do not follow you Gabriel. Package name must not use digit numbers.
Tarbal will use them, taken from the DESCRIPTION file, version field.

That's why I consider the weird case name you presented as irrelevant, and
not to be considered.


Le ven. 9 ao?t 2019 ? 20:41, Gabriel Becker <gabembecker at gmail.com> a
?crit :

>
>
> On Fri, Aug 9, 2019 at 11:05 AM neonira Arinoem <neonira at gmail.com> wrote:
>
>> Won't it be better to have a convention that allows lowercase, dash,
>> underscore and dot as only valid characters for new package names and keep
>> the ancient format validation scheme for older package names?
>>
>
> Validation isn't the only thing we need to do wrt package names. we also
> need to detect them, and particularly,  in at least one case, extract them
> from package tarball filenames (which we also need to be able to
> detect/find).
>
> If we were writing a new language and people wanted to allow snake case in
> package names, sure, but we're talking about about changing how a small but
> package names and package tarballs have always (or at least a very long
> time, I didn't check) had the same form, and it seems expressive enough to
> me? I mean periods are allowed if you feel a strong need for something
> other than a letter.
>
> Note that this proposal would make mypackage_2.3.1 a valid *package name*,
> whose corresponding tarball name might be mypackage_2.3.1_2.3.2 after a
> patch. Yes its a silly example, but why allow that kind of ambiguity?
>
>
>
> For the record @Ben Bolker <bbolker at gmail.com>
>
> Packages that mix case anywhere in their package name:
>
> > table(grepl("((^[a-z].*[A-Z])|(^[A-Z].*[a-z]))", row.names(a1)))
>
>
> FALSE  TRUE
>
>  8818  5932
>
>
> Packages which start with lower case and have at least one upper
>
> > table(grepl("((^[a-z].*[A-Z]))", row.names(a1)))
>
>
> FALSE  TRUE
>
> 12315  2435
>
>
> Packages which start with uppercase and have at least one lower
>
> > table(grepl("((^[A-Z].*[a-z]))", row.names(a1)))
>
>
> FALSE  TRUE
>
> 11253  3497
>
> Packages which take advantage of the above-mentioned legality of periods
>
> > table(grepl(".", row.names(a1), fixed=TRUE))
>
>
> FALSE  TRUE
>
> 14259   491
>
> Packages with pure lower-case alphabetic names
>
> > table(grepl("^[a-z]+$", row.names(a1)))
>
>
> FALSE  TRUE
>
>  7712  7038
>
>
> Packages with pure upper-case alphabetic names
>
> > table(grepl("^[A-Z]+$", row.names(a1)))
>
>
> FALSE  TRUE
>
> 13636  1114
>
>
> Package with at least one numeric digit in their name
>
> > table(grepl("[0-9]", row.names(a1)))
>
>
> FALSE  TRUE
>
> 14208   542
>
>
> It would be interesting to do an actual analysis of the changes in these
> trends over time, but I Really should be working, so that will have to
> either wait or be done by someone else.
> Best,
> ~G
>
>
>
>> This could be implemented by a single function, taking a strictNaming_b_1
>> parameter which defaults to true. Easy to use, and compliance results will
>> vary according to the parameter value, allowing strict compliance for new
>> package names and lazy compliance for older ones.
>>
>> Doing so allows to enforce a new package name convention while also
>> insuring continuity of compliance for already existing package names.
>>
>> Fabien GELINEAU alias Neonira
>>
>> Le ven. 9 ao?t 2019 ? 18:40, Kevin Wright <kw.stat at gmail.com> a ?crit :
>>
>> > Please, no.  I'd also like to disallow uppercase letters in package
>> names.
>> > For instance, the cuteness of using a capital "R" in package names is
>> > outweighed by the annoyance of trying to remember which packages use an
>> > upper-case letter.
>> >
>> > On Thu, Aug 8, 2019 at 9:32 AM Jim Hester <james.f.hester at gmail.com>
>> > wrote:
>> >
>> > > Are there technical reasons that package names cannot be snake case?
>> > > This seems to be enforced by `.standard_regexps()$valid_package_name`
>> > > which currently returns
>> > >
>> > >    "[[:alpha:]][[:alnum:].]*[[:alnum:]]"
>> > >
>> > > Is there any technical reason this couldn't be altered to accept `_`
>> > > as well, e.g.
>> > >
>> > >   "[[:alpha:]][[:alnum:]._]*[[:alnum:]]"
>> > >
>> > > I realize that historically `_` has not always been valid in variable
>> > > names, but this has now been acceptable for 15+ years (since R 1.9.0 I
>> > > believe). Might we also allow underscores for package names?
>> > >
>> > > Jim
>> > >
>> > > ______________________________________________
>> > > R-devel at r-project.org mailing list
>> > > https://stat.ethz.ch/mailman/listinfo/r-devel
>> > >
>> >
>> >
>> > --
>> > Kevin Wright
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>

	[[alternative HTML version deleted]]


From br|@n @end|ng |rom br@verock@com  Fri Aug  9 21:35:03 2019
From: br|@n @end|ng |rom br@verock@com (Brian G. Peterson)
Date: Fri, 09 Aug 2019 14:35:03 -0500
Subject: [Rd] Underscores in package names
In-Reply-To: <CAN--Dz2xQtdu19yeNqJJ2PaR8c20gzz6Ev=v7=KNPPhLgcBR2Q@mail.gmail.com>
References: <CAD6tx94RYHAWCFVuMgMXLUUFG3BgKSCfs3Un=SStQ7rCtgAUSQ@mail.gmail.com>
 <CAKFxdiRMmGwf1AWEBPvu4xtkhQpC6-Xoava2ZVwgxcz0jRkYyg@mail.gmail.com>
 <CAN--Dz2=ScCo985xtKQrVbmkWEq4hq=q2QD5V-DKQxeCQdhNrw@mail.gmail.com>
 <CAD4oTHHGvPDXg1uKhMO9KKjgPRDfYxUug8fTLLwj-sJdUw9Vfg@mail.gmail.com>
 <CAN--Dz2xQtdu19yeNqJJ2PaR8c20gzz6Ev=v7=KNPPhLgcBR2Q@mail.gmail.com>
Message-ID: <e9e5bd1be9af7984ddccba187f9b72db@braverock.com>

On 2019-08-09 14:27, neonira Arinoem wrote:
> I do not follow you Gabriel. Package name must not use digit numbers.
> Tarbal will use them, taken from the DESCRIPTION file, version field.
> 
> That's why I consider the weird case name you presented as irrelevant, 
> and
> not to be considered.

ggplot2 ?

Numbers are allowed in package names right now.


> Le ven. 9 ao?t 2019 ? 20:41, Gabriel Becker <gabembecker at gmail.com> a
> ?crit :
> 
>> 
>> 
>> On Fri, Aug 9, 2019 at 11:05 AM neonira Arinoem <neonira at gmail.com> 
>> wrote:
>> 
>>> Won't it be better to have a convention that allows lowercase, dash,
>>> underscore and dot as only valid characters for new package names and 
>>> keep
>>> the ancient format validation scheme for older package names?
>>> 
>> 
>> Validation isn't the only thing we need to do wrt package names. we 
>> also
>> need to detect them, and particularly,  in at least one case, extract 
>> them
>> from package tarball filenames (which we also need to be able to
>> detect/find).
>> 
>> If we were writing a new language and people wanted to allow snake 
>> case in
>> package names, sure, but we're talking about about changing how a 
>> small but
>> package names and package tarballs have always (or at least a very 
>> long
>> time, I didn't check) had the same form, and it seems expressive 
>> enough to
>> me? I mean periods are allowed if you feel a strong need for something
>> other than a letter.
>> 
>> Note that this proposal would make mypackage_2.3.1 a valid *package 
>> name*,
>> whose corresponding tarball name might be mypackage_2.3.1_2.3.2 after 
>> a
>> patch. Yes its a silly example, but why allow that kind of ambiguity?
>> 
>> 
>> 
>> For the record @Ben Bolker <bbolker at gmail.com>
>> 
>> Packages that mix case anywhere in their package name:
>> 
>> > table(grepl("((^[a-z].*[A-Z])|(^[A-Z].*[a-z]))", row.names(a1)))
>> 
>> 
>> FALSE  TRUE
>> 
>>  8818  5932
>> 
>> 
>> Packages which start with lower case and have at least one upper
>> 
>> > table(grepl("((^[a-z].*[A-Z]))", row.names(a1)))
>> 
>> 
>> FALSE  TRUE
>> 
>> 12315  2435
>> 
>> 
>> Packages which start with uppercase and have at least one lower
>> 
>> > table(grepl("((^[A-Z].*[a-z]))", row.names(a1)))
>> 
>> 
>> FALSE  TRUE
>> 
>> 11253  3497
>> 
>> Packages which take advantage of the above-mentioned legality of 
>> periods
>> 
>> > table(grepl(".", row.names(a1), fixed=TRUE))
>> 
>> 
>> FALSE  TRUE
>> 
>> 14259   491
>> 
>> Packages with pure lower-case alphabetic names
>> 
>> > table(grepl("^[a-z]+$", row.names(a1)))
>> 
>> 
>> FALSE  TRUE
>> 
>>  7712  7038
>> 
>> 
>> Packages with pure upper-case alphabetic names
>> 
>> > table(grepl("^[A-Z]+$", row.names(a1)))
>> 
>> 
>> FALSE  TRUE
>> 
>> 13636  1114
>> 
>> 
>> Package with at least one numeric digit in their name
>> 
>> > table(grepl("[0-9]", row.names(a1)))
>> 
>> 
>> FALSE  TRUE
>> 
>> 14208   542
>> 
>> 
>> It would be interesting to do an actual analysis of the changes in 
>> these
>> trends over time, but I Really should be working, so that will have to
>> either wait or be done by someone else.
>> Best,
>> ~G
>> 
>> 
>> 
>>> This could be implemented by a single function, taking a 
>>> strictNaming_b_1
>>> parameter which defaults to true. Easy to use, and compliance results 
>>> will
>>> vary according to the parameter value, allowing strict compliance for 
>>> new
>>> package names and lazy compliance for older ones.
>>> 
>>> Doing so allows to enforce a new package name convention while also
>>> insuring continuity of compliance for already existing package names.
>>> 
>>> Fabien GELINEAU alias Neonira
>>> 
>>> Le ven. 9 ao?t 2019 ? 18:40, Kevin Wright <kw.stat at gmail.com> a ?crit 
>>> :
>>> 
>>> > Please, no.  I'd also like to disallow uppercase letters in package
>>> names.
>>> > For instance, the cuteness of using a capital "R" in package names is
>>> > outweighed by the annoyance of trying to remember which packages use an
>>> > upper-case letter.
>>> >
>>> > On Thu, Aug 8, 2019 at 9:32 AM Jim Hester <james.f.hester at gmail.com>
>>> > wrote:
>>> >
>>> > > Are there technical reasons that package names cannot be snake case?
>>> > > This seems to be enforced by `.standard_regexps()$valid_package_name`
>>> > > which currently returns
>>> > >
>>> > >    "[[:alpha:]][[:alnum:].]*[[:alnum:]]"
>>> > >
>>> > > Is there any technical reason this couldn't be altered to accept `_`
>>> > > as well, e.g.
>>> > >
>>> > >   "[[:alpha:]][[:alnum:]._]*[[:alnum:]]"
>>> > >
>>> > > I realize that historically `_` has not always been valid in variable
>>> > > names, but this has now been acceptable for 15+ years (since R 1.9.0 I
>>> > > believe). Might we also allow underscores for package names?
>>> > >
>>> > > Jim
>>> > >
>>> > > ______________________________________________
>>> > > R-devel at r-project.org mailing list
>>> > > https://stat.ethz.ch/mailman/listinfo/r-devel
>>> > >
>>> >
>>> >
>>> > --
>>> > Kevin Wright
>>> >
>>> >         [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-devel at r-project.org mailing list
>>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>>> >
>>> 
>>>         [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From neon|r@ @end|ng |rom gm@||@com  Fri Aug  9 21:39:19 2019
From: neon|r@ @end|ng |rom gm@||@com (neonira Arinoem)
Date: Fri, 9 Aug 2019 21:39:19 +0200
Subject: [Rd] Underscores in package names
In-Reply-To: <39ab1460-08da-99a9-691e-6b4f05f67258@gmail.com>
References: <CAD6tx94RYHAWCFVuMgMXLUUFG3BgKSCfs3Un=SStQ7rCtgAUSQ@mail.gmail.com>
 <CAKFxdiRMmGwf1AWEBPvu4xtkhQpC6-Xoava2ZVwgxcz0jRkYyg@mail.gmail.com>
 <CAN--Dz2=ScCo985xtKQrVbmkWEq4hq=q2QD5V-DKQxeCQdhNrw@mail.gmail.com>
 <39ab1460-08da-99a9-691e-6b4f05f67258@gmail.com>
Message-ID: <CAN--Dz1V4pX1Xm-Go_jqFn2g3mx71CSEcJFy+6Y3arWpPwi8rQ@mail.gmail.com>

Naming policies are always tricky. The one proposed by Hadley, as the one
proposed by Google, are usable but not optimal according to most common
needs, that are

1. Name a package
2. Name a class
3. Name a function
4. Name a parameter of a function
5. Name a variable


My approach is the following

1. Package names should be  made of lowercase characters, dash, dot and
underscore

2. Class names are UpperCamelCased

3. Function names are lowerCamelCased

4. Function parameters are semantic names resulting from underscore
separated lowerCamelCased function name, type acronym and length
specification.

5. Variable should be snake case


That way you can not confuse one for the other. This brings clear view,
ease reading and speeds up implementation.

As always, this could be applied to new packages and to some extends to
package upgrades

What do you think of a such approach?


Le ven. 9 ao?t 2019 ? 20:18, Ben Bolker <bbolker at gmail.com> a ?crit :

>
>   Creeping code complexity ...
>
>   I like to think that the cuteR names will have a Darwinian
> disadvantage in the long run. FWIW Hadley Wickham argues (rightly, I
> think) against mixed-case names:
> http://r-pkgs.had.co.nz/package.html#naming. I too am guilty of picking
> mixed-case package names in the past.  Extra credit if the package name
> and the standard function have different cases! e.g.
> glmmADMB::glmmadmb(), although (a) that wasn't my choice and (b) at
> least it was never on CRAN and (c) it wasn't one of the cuteR variety.
>
>   Bonus points for the first analysis of case conventions in existing
> CRAN package names ... I'll start.
>
> > a1 <- rownames(available.packages())
> > cute <- "[a-z]*R[a-z]*"
> > table(grepl(cute,a1))
>
> FALSE  TRUE
> 12565  2185
>
>
> On 2019-08-09 2:00 p.m., neonira Arinoem wrote:
> > Won't it be better to have a convention that allows lowercase, dash,
> > underscore and dot as only valid characters for new package names and
> keep
> > the ancient format validation scheme for older package names?
> >
> > This could be implemented by a single function, taking a strictNaming_b_1
> > parameter which defaults to true. Easy to use, and compliance results
> will
> > vary according to the parameter value, allowing strict compliance for new
> > package names and lazy compliance for older ones.
> >
> > Doing so allows to enforce a new package name convention while also
> > insuring continuity of compliance for already existing package names.
> >
> > Fabien GELINEAU alias Neonira
> >
> > Le ven. 9 ao?t 2019 ? 18:40, Kevin Wright <kw.stat at gmail.com> a ?crit :
> >
> >> Please, no.  I'd also like to disallow uppercase letters in package
> names.
> >> For instance, the cuteness of using a capital "R" in package names is
> >> outweighed by the annoyance of trying to remember which packages use an
> >> upper-case letter.
> >>
> >> On Thu, Aug 8, 2019 at 9:32 AM Jim Hester <james.f.hester at gmail.com>
> >> wrote:
> >>
> >>> Are there technical reasons that package names cannot be snake case?
> >>> This seems to be enforced by `.standard_regexps()$valid_package_name`
> >>> which currently returns
> >>>
> >>>    "[[:alpha:]][[:alnum:].]*[[:alnum:]]"
> >>>
> >>> Is there any technical reason this couldn't be altered to accept `_`
> >>> as well, e.g.
> >>>
> >>>   "[[:alpha:]][[:alnum:]._]*[[:alnum:]]"
> >>>
> >>> I realize that historically `_` has not always been valid in variable
> >>> names, but this has now been acceptable for 15+ years (since R 1.9.0 I
> >>> believe). Might we also allow underscores for package names?
> >>>
> >>> Jim
> >>>
> >>> ______________________________________________
> >>> R-devel at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>
> >>
> >>
> >> --
> >> Kevin Wright
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From g@bembecker @end|ng |rom gm@||@com  Fri Aug  9 21:40:34 2019
From: g@bembecker @end|ng |rom gm@||@com (Gabriel Becker)
Date: Fri, 9 Aug 2019 12:40:34 -0700
Subject: [Rd] Underscores in package names
In-Reply-To: <CAN--Dz2xQtdu19yeNqJJ2PaR8c20gzz6Ev=v7=KNPPhLgcBR2Q@mail.gmail.com>
References: <CAD6tx94RYHAWCFVuMgMXLUUFG3BgKSCfs3Un=SStQ7rCtgAUSQ@mail.gmail.com>
 <CAKFxdiRMmGwf1AWEBPvu4xtkhQpC6-Xoava2ZVwgxcz0jRkYyg@mail.gmail.com>
 <CAN--Dz2=ScCo985xtKQrVbmkWEq4hq=q2QD5V-DKQxeCQdhNrw@mail.gmail.com>
 <CAD4oTHHGvPDXg1uKhMO9KKjgPRDfYxUug8fTLLwj-sJdUw9Vfg@mail.gmail.com>
 <CAN--Dz2xQtdu19yeNqJJ2PaR8c20gzz6Ev=v7=KNPPhLgcBR2Q@mail.gmail.com>
Message-ID: <CAD4oTHHS+ViFjOx6CnwsJCFWQXQErq2kNnaye3BAJHqPOT5ReA@mail.gmail.com>

Neonira,

On Fri, Aug 9, 2019 at 12:27 PM neonira Arinoem <neonira at gmail.com> wrote:

> I do not follow you Gabriel. Package name must not use digit numbers.
> Tarbal will use them, taken from the DESCRIPTION file, version field.
>

I was referring to Jim Hester's original proposal, which AFAIU was just to
add "_" to the allowed characters. Yours goes much farther an also adds
dash but removes all numbers (which I admit I didn't notice) and upper case
letters. This is a much more radical change, and one I don't really
understand the justification for. I get forcing lowercase (Id rather the
machinery were just case insensitive, myself) but disallowing numbers,
given that one of the most popular contributed packages of all time -
ggplot2 - has a number in it, seems strange.  I also don't really grok the
desire for dashes on top of periods and underscores.


Best,

~G



> That's why I consider the weird case name you presented as irrelevant, and
> not to be considered.
>
>
> Le ven. 9 ao?t 2019 ? 20:41, Gabriel Becker <gabembecker at gmail.com> a
> ?crit :
>
>>
>>
>> On Fri, Aug 9, 2019 at 11:05 AM neonira Arinoem <neonira at gmail.com>
>> wrote:
>>
>>> Won't it be better to have a convention that allows lowercase, dash,
>>> underscore and dot as only valid characters for new package names and
>>> keep
>>> the ancient format validation scheme for older package names?
>>>
>>
>> Validation isn't the only thing we need to do wrt package names. we also
>> need to detect them, and particularly,  in at least one case, extract them
>> from package tarball filenames (which we also need to be able to
>> detect/find).
>>
>> If we were writing a new language and people wanted to allow snake case
>> in package names, sure, but we're talking about about changing how a small
>> but package names and package tarballs have always (or at least a very long
>> time, I didn't check) had the same form, and it seems expressive enough to
>> me? I mean periods are allowed if you feel a strong need for something
>> other than a letter.
>>
>> Note that this proposal would make mypackage_2.3.1 a valid *package name*,
>> whose corresponding tarball name might be mypackage_2.3.1_2.3.2 after a
>> patch. Yes its a silly example, but why allow that kind of ambiguity?
>>
>>
>>
>> For the record @Ben Bolker <bbolker at gmail.com>
>>
>> Packages that mix case anywhere in their package name:
>>
>> > table(grepl("((^[a-z].*[A-Z])|(^[A-Z].*[a-z]))", row.names(a1)))
>>
>>
>> FALSE  TRUE
>>
>>  8818  5932
>>
>>
>> Packages which start with lower case and have at least one upper
>>
>> > table(grepl("((^[a-z].*[A-Z]))", row.names(a1)))
>>
>>
>> FALSE  TRUE
>>
>> 12315  2435
>>
>>
>> Packages which start with uppercase and have at least one lower
>>
>> > table(grepl("((^[A-Z].*[a-z]))", row.names(a1)))
>>
>>
>> FALSE  TRUE
>>
>> 11253  3497
>>
>> Packages which take advantage of the above-mentioned legality of periods
>>
>> > table(grepl(".", row.names(a1), fixed=TRUE))
>>
>>
>> FALSE  TRUE
>>
>> 14259   491
>>
>> Packages with pure lower-case alphabetic names
>>
>> > table(grepl("^[a-z]+$", row.names(a1)))
>>
>>
>> FALSE  TRUE
>>
>>  7712  7038
>>
>>
>> Packages with pure upper-case alphabetic names
>>
>> > table(grepl("^[A-Z]+$", row.names(a1)))
>>
>>
>> FALSE  TRUE
>>
>> 13636  1114
>>
>>
>> Package with at least one numeric digit in their name
>>
>> > table(grepl("[0-9]", row.names(a1)))
>>
>>
>> FALSE  TRUE
>>
>> 14208   542
>>
>>
>> It would be interesting to do an actual analysis of the changes in these
>> trends over time, but I Really should be working, so that will have to
>> either wait or be done by someone else.
>> Best,
>> ~G
>>
>>
>>
>>> This could be implemented by a single function, taking a strictNaming_b_1
>>> parameter which defaults to true. Easy to use, and compliance results
>>> will
>>> vary according to the parameter value, allowing strict compliance for new
>>> package names and lazy compliance for older ones.
>>>
>>> Doing so allows to enforce a new package name convention while also
>>> insuring continuity of compliance for already existing package names.
>>>
>>> Fabien GELINEAU alias Neonira
>>>
>>> Le ven. 9 ao?t 2019 ? 18:40, Kevin Wright <kw.stat at gmail.com> a ?crit :
>>>
>>> > Please, no.  I'd also like to disallow uppercase letters in package
>>> names.
>>> > For instance, the cuteness of using a capital "R" in package names is
>>> > outweighed by the annoyance of trying to remember which packages use an
>>> > upper-case letter.
>>> >
>>> > On Thu, Aug 8, 2019 at 9:32 AM Jim Hester <james.f.hester at gmail.com>
>>> > wrote:
>>> >
>>> > > Are there technical reasons that package names cannot be snake case?
>>> > > This seems to be enforced by `.standard_regexps()$valid_package_name`
>>> > > which currently returns
>>> > >
>>> > >    "[[:alpha:]][[:alnum:].]*[[:alnum:]]"
>>> > >
>>> > > Is there any technical reason this couldn't be altered to accept `_`
>>> > > as well, e.g.
>>> > >
>>> > >   "[[:alpha:]][[:alnum:]._]*[[:alnum:]]"
>>> > >
>>> > > I realize that historically `_` has not always been valid in variable
>>> > > names, but this has now been acceptable for 15+ years (since R 1.9.0
>>> I
>>> > > believe). Might we also allow underscores for package names?
>>> > >
>>> > > Jim
>>> > >
>>> > > ______________________________________________
>>> > > R-devel at r-project.org mailing list
>>> > > https://stat.ethz.ch/mailman/listinfo/r-devel
>>> > >
>>> >
>>> >
>>> > --
>>> > Kevin Wright
>>> >
>>> >         [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-devel at r-project.org mailing list
>>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>

	[[alternative HTML version deleted]]


From neon|r@ @end|ng |rom gm@||@com  Fri Aug  9 21:42:09 2019
From: neon|r@ @end|ng |rom gm@||@com (neonira Arinoem)
Date: Fri, 9 Aug 2019 21:42:09 +0200
Subject: [Rd] Underscores in package names
In-Reply-To: <e9e5bd1be9af7984ddccba187f9b72db@braverock.com>
References: <CAD6tx94RYHAWCFVuMgMXLUUFG3BgKSCfs3Un=SStQ7rCtgAUSQ@mail.gmail.com>
 <CAKFxdiRMmGwf1AWEBPvu4xtkhQpC6-Xoava2ZVwgxcz0jRkYyg@mail.gmail.com>
 <CAN--Dz2=ScCo985xtKQrVbmkWEq4hq=q2QD5V-DKQxeCQdhNrw@mail.gmail.com>
 <CAD4oTHHGvPDXg1uKhMO9KKjgPRDfYxUug8fTLLwj-sJdUw9Vfg@mail.gmail.com>
 <CAN--Dz2xQtdu19yeNqJJ2PaR8c20gzz6Ev=v7=KNPPhLgcBR2Q@mail.gmail.com>
 <e9e5bd1be9af7984ddccba187f9b72db@braverock.com>
Message-ID: <CAN--Dz1yYhPOxg+2syaKUzV=4N5NceJAApgiX9uXYooWuBorpA@mail.gmail.com>

Yes Brian. That's currently possible.

I am not speaking of what is currently possible but of the rules we should
enforce, using both strict compliance for new rules and lazy compliance for
older packages

Le ven. 9 ao?t 2019 ? 21:35, Brian G. Peterson <brian at braverock.com> a
?crit :

> On 2019-08-09 14:27, neonira Arinoem wrote:
> > I do not follow you Gabriel. Package name must not use digit numbers.
> > Tarbal will use them, taken from the DESCRIPTION file, version field.
> >
> > That's why I consider the weird case name you presented as irrelevant,
> > and
> > not to be considered.
>
> ggplot2 ?
>
> Numbers are allowed in package names right now.
>
>
> > Le ven. 9 ao?t 2019 ? 20:41, Gabriel Becker <gabembecker at gmail.com> a
> > ?crit :
> >
> >>
> >>
> >> On Fri, Aug 9, 2019 at 11:05 AM neonira Arinoem <neonira at gmail.com>
> >> wrote:
> >>
> >>> Won't it be better to have a convention that allows lowercase, dash,
> >>> underscore and dot as only valid characters for new package names and
> >>> keep
> >>> the ancient format validation scheme for older package names?
> >>>
> >>
> >> Validation isn't the only thing we need to do wrt package names. we
> >> also
> >> need to detect them, and particularly,  in at least one case, extract
> >> them
> >> from package tarball filenames (which we also need to be able to
> >> detect/find).
> >>
> >> If we were writing a new language and people wanted to allow snake
> >> case in
> >> package names, sure, but we're talking about about changing how a
> >> small but
> >> package names and package tarballs have always (or at least a very
> >> long
> >> time, I didn't check) had the same form, and it seems expressive
> >> enough to
> >> me? I mean periods are allowed if you feel a strong need for something
> >> other than a letter.
> >>
> >> Note that this proposal would make mypackage_2.3.1 a valid *package
> >> name*,
> >> whose corresponding tarball name might be mypackage_2.3.1_2.3.2 after
> >> a
> >> patch. Yes its a silly example, but why allow that kind of ambiguity?
> >>
> >>
> >>
> >> For the record @Ben Bolker <bbolker at gmail.com>
> >>
> >> Packages that mix case anywhere in their package name:
> >>
> >> > table(grepl("((^[a-z].*[A-Z])|(^[A-Z].*[a-z]))", row.names(a1)))
> >>
> >>
> >> FALSE  TRUE
> >>
> >>  8818  5932
> >>
> >>
> >> Packages which start with lower case and have at least one upper
> >>
> >> > table(grepl("((^[a-z].*[A-Z]))", row.names(a1)))
> >>
> >>
> >> FALSE  TRUE
> >>
> >> 12315  2435
> >>
> >>
> >> Packages which start with uppercase and have at least one lower
> >>
> >> > table(grepl("((^[A-Z].*[a-z]))", row.names(a1)))
> >>
> >>
> >> FALSE  TRUE
> >>
> >> 11253  3497
> >>
> >> Packages which take advantage of the above-mentioned legality of
> >> periods
> >>
> >> > table(grepl(".", row.names(a1), fixed=TRUE))
> >>
> >>
> >> FALSE  TRUE
> >>
> >> 14259   491
> >>
> >> Packages with pure lower-case alphabetic names
> >>
> >> > table(grepl("^[a-z]+$", row.names(a1)))
> >>
> >>
> >> FALSE  TRUE
> >>
> >>  7712  7038
> >>
> >>
> >> Packages with pure upper-case alphabetic names
> >>
> >> > table(grepl("^[A-Z]+$", row.names(a1)))
> >>
> >>
> >> FALSE  TRUE
> >>
> >> 13636  1114
> >>
> >>
> >> Package with at least one numeric digit in their name
> >>
> >> > table(grepl("[0-9]", row.names(a1)))
> >>
> >>
> >> FALSE  TRUE
> >>
> >> 14208   542
> >>
> >>
> >> It would be interesting to do an actual analysis of the changes in
> >> these
> >> trends over time, but I Really should be working, so that will have to
> >> either wait or be done by someone else.
> >> Best,
> >> ~G
> >>
> >>
> >>
> >>> This could be implemented by a single function, taking a
> >>> strictNaming_b_1
> >>> parameter which defaults to true. Easy to use, and compliance results
> >>> will
> >>> vary according to the parameter value, allowing strict compliance for
> >>> new
> >>> package names and lazy compliance for older ones.
> >>>
> >>> Doing so allows to enforce a new package name convention while also
> >>> insuring continuity of compliance for already existing package names.
> >>>
> >>> Fabien GELINEAU alias Neonira
> >>>
> >>> Le ven. 9 ao?t 2019 ? 18:40, Kevin Wright <kw.stat at gmail.com> a ?crit
> >>> :
> >>>
> >>> > Please, no.  I'd also like to disallow uppercase letters in package
> >>> names.
> >>> > For instance, the cuteness of using a capital "R" in package names is
> >>> > outweighed by the annoyance of trying to remember which packages use
> an
> >>> > upper-case letter.
> >>> >
> >>> > On Thu, Aug 8, 2019 at 9:32 AM Jim Hester <james.f.hester at gmail.com>
> >>> > wrote:
> >>> >
> >>> > > Are there technical reasons that package names cannot be snake
> case?
> >>> > > This seems to be enforced by
> `.standard_regexps()$valid_package_name`
> >>> > > which currently returns
> >>> > >
> >>> > >    "[[:alpha:]][[:alnum:].]*[[:alnum:]]"
> >>> > >
> >>> > > Is there any technical reason this couldn't be altered to accept
> `_`
> >>> > > as well, e.g.
> >>> > >
> >>> > >   "[[:alpha:]][[:alnum:]._]*[[:alnum:]]"
> >>> > >
> >>> > > I realize that historically `_` has not always been valid in
> variable
> >>> > > names, but this has now been acceptable for 15+ years (since R
> 1.9.0 I
> >>> > > believe). Might we also allow underscores for package names?
> >>> > >
> >>> > > Jim
> >>> > >
> >>> > > ______________________________________________
> >>> > > R-devel at r-project.org mailing list
> >>> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> >>> > >
> >>> >
> >>> >
> >>> > --
> >>> > Kevin Wright
> >>> >
> >>> >         [[alternative HTML version deleted]]
> >>> >
> >>> > ______________________________________________
> >>> > R-devel at r-project.org mailing list
> >>> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >>> >
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-devel at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> --
> Brian G. Peterson
> http://braverock.com/brian/
> Ph: 773-459-4973
> IM: bgpbraverock
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Aug  9 22:02:02 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 9 Aug 2019 16:02:02 -0400
Subject: [Rd] Underscores in package names
In-Reply-To: <CAD6tx95E2cu2SE4-3JS8DJH+LMFwpNCXu1B-AZmde-mDB_Y_WA@mail.gmail.com>
References: <CAD6tx94RYHAWCFVuMgMXLUUFG3BgKSCfs3Un=SStQ7rCtgAUSQ@mail.gmail.com>
 <4f049dfc-5e33-68d9-6946-19766b54eb44@gmail.com>
 <CAD6tx95E2cu2SE4-3JS8DJH+LMFwpNCXu1B-AZmde-mDB_Y_WA@mail.gmail.com>
Message-ID: <ca53a1dd-7f85-9daa-853d-f111e174720c@gmail.com>

On 09/08/2019 10:23 a.m., Jim Hester wrote:
> To be clear, I'd be happy to contribute code to make this work, with
> the changes mentioned by Duncan and elsewhere in the codebase, if
> someone on R-core was interested in reviewing it.

You seem to have ignited a lot of discussion.

Just to add my own point of view:  I think removing a restriction on the 
allowed names is a generally bad idea.  I think Rasmus B??th gave a 
really valid complaint about the variety of naming conventions in R in a 
presentation I saw based on his article

https://journal.r-project.org/archive/2012/RJ-2012-018/index.html

Looking at the article now, it's not as entertaining as I remember his 
presentation was, but it makes good points about the value of consistency.

Duncan Murdoch


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Aug  9 22:17:46 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 9 Aug 2019 16:17:46 -0400
Subject: [Rd] Underscores in package names
In-Reply-To: <CAD4oTHHGvPDXg1uKhMO9KKjgPRDfYxUug8fTLLwj-sJdUw9Vfg@mail.gmail.com>
References: <CAD6tx94RYHAWCFVuMgMXLUUFG3BgKSCfs3Un=SStQ7rCtgAUSQ@mail.gmail.com>
 <CAKFxdiRMmGwf1AWEBPvu4xtkhQpC6-Xoava2ZVwgxcz0jRkYyg@mail.gmail.com>
 <CAN--Dz2=ScCo985xtKQrVbmkWEq4hq=q2QD5V-DKQxeCQdhNrw@mail.gmail.com>
 <CAD4oTHHGvPDXg1uKhMO9KKjgPRDfYxUug8fTLLwj-sJdUw9Vfg@mail.gmail.com>
Message-ID: <7c89e005-37a4-16f9-4ef7-f3f186213944@gmail.com>

On 09/08/2019 2:41 p.m., Gabriel Becker wrote:
> Note that this proposal would make mypackage_2.3.1 a valid *package name*,
> whose corresponding tarball name might be mypackage_2.3.1_2.3.2 after a
> patch. Yes its a silly example, but why allow that kind of ambiguity?
> 
CRAN already has a package named "FuzzyNumbers.Ext.2", whose tarball is 
FuzzyNumbers.Ext.2_3.2.tar.gz, so I think we've already lost that game.

Duncan Murdoch


From bbo|ker @end|ng |rom gm@||@com  Fri Aug  9 22:20:08 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 9 Aug 2019 16:20:08 -0400
Subject: [Rd] Underscores in package names
In-Reply-To: <7c89e005-37a4-16f9-4ef7-f3f186213944@gmail.com>
References: <CAD6tx94RYHAWCFVuMgMXLUUFG3BgKSCfs3Un=SStQ7rCtgAUSQ@mail.gmail.com>
 <CAKFxdiRMmGwf1AWEBPvu4xtkhQpC6-Xoava2ZVwgxcz0jRkYyg@mail.gmail.com>
 <CAN--Dz2=ScCo985xtKQrVbmkWEq4hq=q2QD5V-DKQxeCQdhNrw@mail.gmail.com>
 <CAD4oTHHGvPDXg1uKhMO9KKjgPRDfYxUug8fTLLwj-sJdUw9Vfg@mail.gmail.com>
 <7c89e005-37a4-16f9-4ef7-f3f186213944@gmail.com>
Message-ID: <a3770583-0131-6cca-f12b-80b0e139e079@gmail.com>


 Ugh, but not *as* ambiguous as the proposed example (you can still
split unambiguously on "_"; yes, you could split on "last _" in
Gabriel's example, but ...)

On 2019-08-09 4:17 p.m., Duncan Murdoch wrote:
> On 09/08/2019 2:41 p.m., Gabriel Becker wrote:
>> Note that this proposal would make mypackage_2.3.1 a valid *package
>> name*,
>> whose corresponding tarball name might be mypackage_2.3.1_2.3.2 after a
>> patch. Yes its a silly example, but why allow that kind of ambiguity?
>>
> CRAN already has a package named "FuzzyNumbers.Ext.2", whose tarball is
> FuzzyNumbers.Ext.2_3.2.tar.gz, so I think we've already lost that game.
> 
> Duncan Murdoch
>


From g@bembecker @end|ng |rom gm@||@com  Fri Aug  9 22:37:24 2019
From: g@bembecker @end|ng |rom gm@||@com (Gabriel Becker)
Date: Fri, 9 Aug 2019 13:37:24 -0700
Subject: [Rd] Underscores in package names
In-Reply-To: <7c89e005-37a4-16f9-4ef7-f3f186213944@gmail.com>
References: <CAD6tx94RYHAWCFVuMgMXLUUFG3BgKSCfs3Un=SStQ7rCtgAUSQ@mail.gmail.com>
 <CAKFxdiRMmGwf1AWEBPvu4xtkhQpC6-Xoava2ZVwgxcz0jRkYyg@mail.gmail.com>
 <CAN--Dz2=ScCo985xtKQrVbmkWEq4hq=q2QD5V-DKQxeCQdhNrw@mail.gmail.com>
 <CAD4oTHHGvPDXg1uKhMO9KKjgPRDfYxUug8fTLLwj-sJdUw9Vfg@mail.gmail.com>
 <7c89e005-37a4-16f9-4ef7-f3f186213944@gmail.com>
Message-ID: <CAD4oTHEAszVnHjGqxE2ooeYCE4R4K9mRaoKcqLxSfAO502NJcQ@mail.gmail.com>

Duncan,


On Fri, Aug 9, 2019 at 1:17 PM Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 09/08/2019 2:41 p.m., Gabriel Becker wrote:
> > Note that this proposal would make mypackage_2.3.1 a valid *package
> name*,
> > whose corresponding tarball name might be mypackage_2.3.1_2.3.2 after a
> > patch. Yes its a silly example, but why allow that kind of ambiguity?
> >
> CRAN already has a package named "FuzzyNumbers.Ext.2", whose tarball is
> FuzzyNumbers.Ext.2_3.2.tar.gz, so I think we've already lost that game.
>

I suppose technically 2 is a valid version number for a package (?) so I
suppose you have me there. But as Ben pointed out while I was writing this,
all I can really say is that in practice they read to me (as someone who
has administered R on a large cluster and written build-system software for
it) as substantially different levels of ambiguity. I do acknowledge, as
Ben does, that yes a more complex regular expression/splitting algorithm
can be written that would handle the more general package names. I just
don't personally see a motivation that justifies changing something this
fundamental (even if it is both narrow and was initially more or less
arbitrarily chosen) about R at this late date.

I guess at the end of the day, I guess what I'm saying is that breaking and
changing things is sometimes good, but if we're going to rock the boat
personally I'd want to do so going after bigger wins than this one. Thats
just my opinion though.

Best,
~G


> Duncan Murdoch
>
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Sat Aug 10 02:23:28 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 9 Aug 2019 20:23:28 -0400
Subject: [Rd] Underscores in package names
In-Reply-To: <CAD4oTHEAszVnHjGqxE2ooeYCE4R4K9mRaoKcqLxSfAO502NJcQ@mail.gmail.com>
References: <CAD6tx94RYHAWCFVuMgMXLUUFG3BgKSCfs3Un=SStQ7rCtgAUSQ@mail.gmail.com>
 <CAKFxdiRMmGwf1AWEBPvu4xtkhQpC6-Xoava2ZVwgxcz0jRkYyg@mail.gmail.com>
 <CAN--Dz2=ScCo985xtKQrVbmkWEq4hq=q2QD5V-DKQxeCQdhNrw@mail.gmail.com>
 <CAD4oTHHGvPDXg1uKhMO9KKjgPRDfYxUug8fTLLwj-sJdUw9Vfg@mail.gmail.com>
 <7c89e005-37a4-16f9-4ef7-f3f186213944@gmail.com>
 <CAD4oTHEAszVnHjGqxE2ooeYCE4R4K9mRaoKcqLxSfAO502NJcQ@mail.gmail.com>
Message-ID: <79a31832-848b-4d3c-7634-d7a6dd692d14@gmail.com>

On 09/08/2019 4:37 p.m., Gabriel Becker wrote:
> Duncan,
> 
> 
> On Fri, Aug 9, 2019 at 1:17 PM Duncan Murdoch <murdoch.duncan at gmail.com 
> <mailto:murdoch.duncan at gmail.com>> wrote:
> 
>     On 09/08/2019 2:41 p.m., Gabriel Becker wrote:
>      > Note that this proposal would make mypackage_2.3.1 a valid
>     *package name*,
>      > whose corresponding tarball name might be mypackage_2.3.1_2.3.2
>     after a
>      > patch. Yes its a silly example, but why allow that kind of ambiguity?
>      >
>     CRAN already has a package named "FuzzyNumbers.Ext.2", whose tarball is
>     FuzzyNumbers.Ext.2_3.2.tar.gz, so I think we've already lost that game.
> 
> 
> I suppose technically 2 is a valid version number for a package (?) so I 
> suppose you have me there. But as Ben pointed out while I was writing 
> this, all I can really say is that in practice they read to me (as 
> someone who has administered R on a large cluster and written 
> build-system software for it) as substantially different levels of 
> ambiguity. I do acknowledge, as Ben does, that yes a more complex 
> regular expression/splitting algorithm can be written that would handle 
> the more general package names. I just don't personally see a motivation 
> that justifies changing something this fundamental (even if it is both 
> narrow and was initially more or less arbitrarily chosen) about R at 
> this late date.
> 
> I guess at the end of the day, I guess what I'm saying is that breaking 
> and changing things is sometimes good, but if we're going to rock the 
> boat personally I'd want to do so going after bigger wins than this one. 
> Thats just my opinion though.

Sorry, I wasn't clear.  I agree with you.  I was just saying that the 
particular argument based on ugly tarball names isn't the reason.

Duncan Murdoch


From h@nk|n@rob|n @end|ng |rom gm@||@com  Sat Aug 10 06:45:01 2019
From: h@nk|n@rob|n @end|ng |rom gm@||@com (robin hankin)
Date: Sat, 10 Aug 2019 16:45:01 +1200
Subject: [Rd] Underscores in package names
In-Reply-To: <CAD4oTHHGvPDXg1uKhMO9KKjgPRDfYxUug8fTLLwj-sJdUw9Vfg@mail.gmail.com>
References: <CAD6tx94RYHAWCFVuMgMXLUUFG3BgKSCfs3Un=SStQ7rCtgAUSQ@mail.gmail.com>
 <CAKFxdiRMmGwf1AWEBPvu4xtkhQpC6-Xoava2ZVwgxcz0jRkYyg@mail.gmail.com>
 <CAN--Dz2=ScCo985xtKQrVbmkWEq4hq=q2QD5V-DKQxeCQdhNrw@mail.gmail.com>
 <CAD4oTHHGvPDXg1uKhMO9KKjgPRDfYxUug8fTLLwj-sJdUw9Vfg@mail.gmail.com>
Message-ID: <CAHHjBM63uZ0BJhMMjhi9=FGamzAJZ97jefXw5QiCGKKfu3r0pw@mail.gmail.com>

Having written the 'lorentz' ,'Davies' and 'schwarzschild' packages,
I'm interested in packages that are named for a particular person.
There are (by my count) 34 packages on CRAN like this, with names that
are the surname of a particular (real) person.  Of these 34,  only 7
are capitalized.

hankin.robin at gmail.com



hankin.robin at gmail.com




On Sat, Aug 10, 2019 at 6:50 AM Gabriel Becker <gabembecker at gmail.com> wrote:
>
> On Fri, Aug 9, 2019 at 11:05 AM neonira Arinoem <neonira at gmail.com> wrote:
>
> > Won't it be better to have a convention that allows lowercase, dash,
> > underscore and dot as only valid characters for new package names and keep
> > the ancient format validation scheme for older package names?
> >
>
> Validation isn't the only thing we need to do wrt package names. we also
> need to detect them, and particularly,  in at least one case, extract them
> from package tarball filenames (which we also need to be able to
> detect/find).
>
> If we were writing a new language and people wanted to allow snake case in
> package names, sure, but we're talking about about changing how a small but
> package names and package tarballs have always (or at least a very long
> time, I didn't check) had the same form, and it seems expressive enough to
> me? I mean periods are allowed if you feel a strong need for something
> other than a letter.
>
> Note that this proposal would make mypackage_2.3.1 a valid *package name*,
> whose corresponding tarball name might be mypackage_2.3.1_2.3.2 after a
> patch. Yes its a silly example, but why allow that kind of ambiguity?
>
>
>
> For the record @Ben Bolker <bbolker at gmail.com>
>
> Packages that mix case anywhere in their package name:
>
> > table(grepl("((^[a-z].*[A-Z])|(^[A-Z].*[a-z]))", row.names(a1)))
>
>
> FALSE  TRUE
>
>  8818  5932
>
>
> Packages which start with lower case and have at least one upper
>
> > table(grepl("((^[a-z].*[A-Z]))", row.names(a1)))
>
>
> FALSE  TRUE
>
> 12315  2435
>
>
> Packages which start with uppercase and have at least one lower
>
> > table(grepl("((^[A-Z].*[a-z]))", row.names(a1)))
>
>
> FALSE  TRUE
>
> 11253  3497
>
> Packages which take advantage of the above-mentioned legality of periods
>
> > table(grepl(".", row.names(a1), fixed=TRUE))
>
>
> FALSE  TRUE
>
> 14259   491
>
> Packages with pure lower-case alphabetic names
>
> > table(grepl("^[a-z]+$", row.names(a1)))
>
>
> FALSE  TRUE
>
>  7712  7038
>
>
> Packages with pure upper-case alphabetic names
>
> > table(grepl("^[A-Z]+$", row.names(a1)))
>
>
> FALSE  TRUE
>
> 13636  1114
>
>
> Package with at least one numeric digit in their name
>
> > table(grepl("[0-9]", row.names(a1)))
>
>
> FALSE  TRUE
>
> 14208   542
>
>
> It would be interesting to do an actual analysis of the changes in these
> trends over time, but I Really should be working, so that will have to
> either wait or be done by someone else.
> Best,
> ~G
>
>
>
> > This could be implemented by a single function, taking a strictNaming_b_1
> > parameter which defaults to true. Easy to use, and compliance results will
> > vary according to the parameter value, allowing strict compliance for new
> > package names and lazy compliance for older ones.
> >
> > Doing so allows to enforce a new package name convention while also
> > insuring continuity of compliance for already existing package names.
> >
> > Fabien GELINEAU alias Neonira
> >
> > Le ven. 9 ao?t 2019 ? 18:40, Kevin Wright <kw.stat at gmail.com> a ?crit :
> >
> > > Please, no.  I'd also like to disallow uppercase letters in package
> > names.
> > > For instance, the cuteness of using a capital "R" in package names is
> > > outweighed by the annoyance of trying to remember which packages use an
> > > upper-case letter.
> > >
> > > On Thu, Aug 8, 2019 at 9:32 AM Jim Hester <james.f.hester at gmail.com>
> > > wrote:
> > >
> > > > Are there technical reasons that package names cannot be snake case?
> > > > This seems to be enforced by `.standard_regexps()$valid_package_name`
> > > > which currently returns
> > > >
> > > >    "[[:alpha:]][[:alnum:].]*[[:alnum:]]"
> > > >
> > > > Is there any technical reason this couldn't be altered to accept `_`
> > > > as well, e.g.
> > > >
> > > >   "[[:alpha:]][[:alnum:]._]*[[:alnum:]]"
> > > >
> > > > I realize that historically `_` has not always been valid in variable
> > > > names, but this has now been acceptable for 15+ years (since R 1.9.0 I
> > > > believe). Might we also allow underscores for package names?
> > > >
> > > > Jim
> > > >
> > > > ______________________________________________
> > > > R-devel at r-project.org mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > > >
> > >
> > >
> > > --
> > > Kevin Wright
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From m@tth|eu@@t|g|er @end|ng |rom gm@||@com  Sat Aug 10 01:12:20 2019
From: m@tth|eu@@t|g|er @end|ng |rom gm@||@com (Matthieu S)
Date: Fri, 9 Aug 2019 16:12:20 -0700
Subject: [Rd] 
 R CMD check: should .Rout.save contain the new "Registered S3
 method overwritten by" message?
In-Reply-To: <CAEYvigL5LWD8CiMFxMW-FJoFE84XOe54Pwb5jHVx6hEymLsCNw@mail.gmail.com>
References: <CAEYvigL5LWD8CiMFxMW-FJoFE84XOe54Pwb5jHVx6hEymLsCNw@mail.gmail.com>
Message-ID: <CAEYvigKgnbQYHfmU+gW_3EPyOA3+DT0HqvFHRJU3+frcSZY23A@mail.gmail.com>

Hi

Following-up on this question. I don't understand why R CMD check creates
.Rout files that do not contain the message "Registered S3 method
overwritten by..." that I otherwise obtain with an interactive R session,
or with R CMD BATCH? Can I recreate the behaviour of R CMD check calling
directly R CMD BATCH?

Thanks!

Matthieu

Le lun. 5 ao?t 2019 ? 11:12, Matthieu S <matthieu.stigler at gmail.com> a
?crit :

> Hi
>
> Since I believe 3.6, there is a message when loading a package that
> overwrites S3 methods, reading like "Registered S3 method overwritten
> by...". Should this message be included in the xxx.Rout.save files saved in
> the tests/ folder of a package? It seems R CMD check is not happy about it?
>
> I simply ran R CMD BATCH xxx.R xxx.Rout.save but running later on R CMD
> check on the package complains about the presence of the "Registered S3
> method overwritten..." text? Did I do something wrong? Is this the correct
> way to do, and R CMD check should be updated? Or should I not include the
> "Registered S3 method overwritten"  in the .Rout.save (and how can I do
> that?)?
>
> Thanks!
>
> Matthieu
>

	[[alternative HTML version deleted]]


From tom@@@k@||ber@ @end|ng |rom gm@||@com  Mon Aug 12 12:05:52 2019
From: tom@@@k@||ber@ @end|ng |rom gm@||@com (Tomas Kalibera)
Date: Mon, 12 Aug 2019 12:05:52 +0200
Subject: [Rd] NextMethod() and argument laziness
In-Reply-To: <CABzLhzyY_HtAE-TuYrtVDyZyaEGxH3N5R=Cg862o29DECZXL8Q@mail.gmail.com>
References: <CABzLhzyY_HtAE-TuYrtVDyZyaEGxH3N5R=Cg862o29DECZXL8Q@mail.gmail.com>
Message-ID: <0af167f5-2d70-f136-1481-797b1eaa669a@gmail.com>


On 8/7/19 3:10 PM, Davis Vaughan wrote:
> Hi all, I'd like to ask if the following behavior is a bug. To me it
> certainly feels surprising, at the very least. In this example, I would
> like to call NextMethod() from my `child` object, have `cols` be left
> untouched, and then substitute(cols) in the parent method. It works when
> you use a `parent` object (as expected), but I would have also expected to
> get `mpg` back when calling it from the `child` method.
>
> my_generic <- function(x, cols) {
>    UseMethod("my_generic")
> }
> my_generic.parent <- function(x, cols) {
>    substitute(cols)
> }
> my_generic.child <- function(x, cols) {
>    NextMethod()
> }
> obj_parent <- structure(mtcars, class = c("parent", class(mtcars)))
> obj_child <- structure(obj_parent, class = c("child", class(obj_parent)))
>
> my_generic(obj_parent, mpg)
> #> mpg
>
> my_generic(obj_child, mpg)
> #> cols

This works as documented, see ?NextMethod:

"the arguments will be the same in number, order and name as those to 
the current method but their values will be promises to evaluate their 
name in the current method and environment"

Hence NextMethod needs to create a promise with a name matching the 
formal argument name of the function from which NextMethod is invoked. 
Note this is not the same as with UseMethod, and this is also why 
substitute() works differently with UseMethod.

Best
Tomas

>
> Thanks,
> Davis
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From S@E|||@on @end|ng |rom LGCGroup@com  Mon Aug 12 12:59:25 2019
From: S@E|||@on @end|ng |rom LGCGroup@com (Stephen Ellison)
Date: Mon, 12 Aug 2019 10:59:25 +0000
Subject: [Rd] Underscores in package names
In-Reply-To: <CAN--Dz1V4pX1Xm-Go_jqFn2g3mx71CSEcJFy+6Y3arWpPwi8rQ@mail.gmail.com>
References: <CAD6tx94RYHAWCFVuMgMXLUUFG3BgKSCfs3Un=SStQ7rCtgAUSQ@mail.gmail.com>
 <CAKFxdiRMmGwf1AWEBPvu4xtkhQpC6-Xoava2ZVwgxcz0jRkYyg@mail.gmail.com>
 <CAN--Dz2=ScCo985xtKQrVbmkWEq4hq=q2QD5V-DKQxeCQdhNrw@mail.gmail.com>
 <39ab1460-08da-99a9-691e-6b4f05f67258@gmail.com>
 <CAN--Dz1V4pX1Xm-Go_jqFn2g3mx71CSEcJFy+6Y3arWpPwi8rQ@mail.gmail.com>
Message-ID: <7a182fc4f9d64edfb50238ffe073c094@GBDCVPEXC08.corp.lgc-group.com>

To throw a very small pennyworth into this debate, the metRology package I maintain uses mixed case to highlight R for that community when I'm talking about, or citing it. R takeup in that community is not yet high and the visible reminder  seems to help. 

I'll obviously accept a consensus decision for some other case convention taken on sound technical grounds, but if this is essentially an aesthetic matter I'd prefer not to change it for someone else's idea of what looks pretty and what doesn?t. 

Steve Ellison

> -----Original Message-----
> From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of neonira
> Arinoem
> Sent: 09 August 2019 20:39
> To: Ben Bolker
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] Underscores in package names
> 
> 
> Naming policies are always tricky. The one proposed by Hadley, as the one
> proposed by Google, are usable but not optimal according to most common
> needs, that are
> 
> 1. Name a package
> 2. Name a class
> 3. Name a function
> 4. Name a parameter of a function
> 5. Name a variable
> 
> ...


*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From tom@@@k@||ber@ @end|ng |rom gm@||@com  Mon Aug 12 16:29:32 2019
From: tom@@@k@||ber@ @end|ng |rom gm@||@com (Tomas Kalibera)
Date: Mon, 12 Aug 2019 16:29:32 +0200
Subject: [Rd] MacOS parallel::makeCluster fails
In-Reply-To: <6F92DA87-472D-4621-A1AB-6AF981FF99D6@fh-muenster.de>
References: <BA251FC4-C0F3-4473-834C-72B147F63C26@contoso.com>
 <fedc97a1-e407-b427-a7f3-225a91fae27e@gmail.com>
 <6F92DA87-472D-4621-A1AB-6AF981FF99D6@fh-muenster.de>
Message-ID: <45f5c8d9-cf06-cfe9-c1b5-b6b594d3ce46@gmail.com>

For reference, in the end it turned out to be caused by that "localhost" 
could not be resolved. Thanks to Dominik for the report and debugging of 
the problem. To be robust against such problems in the future, R now 
falls back to the loopback device for localhost.

Best
Tomas

On 7/12/19 11:22 AM, Dominik Leutnant wrote:
> Hi Thomas,
>
> thanks for your reply (and thanks for your patience...).
> I am now  using the following minimal reprex:
>
>> library(parallel)
>> cl <- makeCluster(2L)
> I freshly started the machine and did not open any other app. Just R.app (3.6.1).
>
> After executing the second line of code, R seems to hang infinitely and does not respond.
> The R process itself uses almost no CPU.
>
> Unfortunately, I do not have any experience with neither "Sock_listen"  nor "dtruss".
> Is there an example somewhere available?
>
> Best
> Dominik
>
>
>
>
> ?Am 05.06.19, 10:18 schrieb "Tomas Kalibera" <tomas.kalibera at gmail.com>:
>
>      Hi Dominik,
>      
>      from the output, the master process could not "listen" on the port where
>      it expects a connection from the worker. We need to find out why. I'd
>      recommend first to create a minimal reproducible example (and one that
>      does not use future, only parallel, and a minimal number of threads,
>      ideally just 2). Then I'd recommend to check if the problem still exists
>      with R-devel. Then I'd check if the problem happens in all invocations,
>      even after reboots, on a clean system, without many running applications
>      - if it does, this is good news. Then you could post such example and we
>      could help more - if we can reproduce on our system indeed we could
>      debug, if not there could at least be more directed advice on how to
>      debug on your side. What I'd do myself if I could reproduce on my system
>      would be instrument R around Sock_listen in internet module to see
>      exactly what has failed with which error. Maybe dtruss would help too,
>      but instrumenting may be easier. The earlier problem you mention has
>      never been diagnosed (it was only intermittent on the reporter's
>      machine, we could not reproduce on our systems, and despite a lot of
>      effort on our side and on the reporter's, we could not reliably
>      diagnose). In principle, it could be some race condition in R (one has
>      been fixed since the previous report), but especially if it is
>      deterministic it would more likely be some OS limit on your system. You
>      could of course try playing with OS limits, on the number of open files,
>      etc, with changing the port number (port= option), etc, but I would
>      recommend the systematic approach of debugging the cause.
>      
>      Best
>      Tomas
>      
>      On 6/4/19 10:45 AM, Dominik Leutnant wrote:
>      > Hi all,
>      >
>      > The call parallel::makeCluster(1L) hangs infinitely on my MacOS machine which seems to be already reported by some people (e.g., https://stat.ethz.ch/pipermail/r-devel/2018-February/075565.html).
>      > However, the solutions posted on SO, GH or R-devel do not work in my case.
>      >
>      > So far, I unsuccessfully tested ?
>      >
>      >    1.  Couple of reboots
>      >    2.  Adding 192.0.0.1 to /etc/hosts
>      >    3.  Using R.app instead of RStudio.app
>      >    4.  Turn off the firewall
>      >
>      > Following Hendriks advice, ?cl <- future::makeClusterPSOCK(1L, verbose = TRUE, timeout = 60)? gives (note: without adding the timeout parameter, R just hangs):
>      >> Sys.setenv(LANGUAGE='en')
>      >> cl <- future::makeClusterPSOCK(1L, verbose = TRUE, timeout = 60)
>      > [local output] Workers: [n = 1] ?localhost?
>      > [local output] Base port: 11867
>      > [local output] Creating node 1 of 1 ...
>      > [local output] - setting up node
>      > Testing if worker's PID can be inferred: ?'/Library/Frameworks/R.framework/Resources/bin/Rscript' -e 'try(cat(Sys.getpid(),file="/var/folders/5s/kgm05t2s0_52gz1s445mnlgw0000gn/T//RtmpZp1RX6/future.parent=835.3434fe0c5c6.pid"), silent = TRUE)' -e "file.exists('/var/folders/5s/kgm05t2s0_52gz1s445mnlgw0000gn/T//RtmpZp1RX6/future.parent=835.3434fe0c5c6.pid')"?
>      > - Possible to infer worker's PID: TRUE
>      > [local output] Starting worker #1 on ?localhost?: '/Library/Frameworks/R.framework/Resources/bin/Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'try(cat(Sys.getpid(),file="/var/folders/5s/kgm05t2s0_52gz1s445mnlgw0000gn/T//RtmpZp1RX6/future.parent=835.3434fe0c5c6.pid"), silent = TRUE)' -e 'parallel:::.slaveRSOCK()' MASTER=localhost PORT=11867 OUT=/dev/null TIMEOUT=60 XDR=TRUE
>      > [local output] - Exit code of system() call: 0
>      > [local output] Waiting for worker #1 on ?localhost? to connect back
>      > [local output] Detected a warning from socketConnection(): ?problem in listening on this socket?
>      > Killing worker process (PID 903) if still alive
>      > Worker (PID 903) was successfully killed: TRUE
>      > Error in socketConnection("localhost", port = port, server = TRUE, blocking = TRUE,  :
>      >    Failed to launch and connect to R worker on local machine ?localhost? from local machine ?Dominiks-MBP.local?.
>      > * The error produced by socketConnection() was: ?cannot open the connection?
>      > * In addition, socketConnection() produced 1 warning(s):
>      >     - Warning #1: ?problem in listening on this socket?
>      > * The localhost socket connection that failed to connect to the R worker used port 11867 using a communication timeout of 60 seconds and a connection timeout of 120 seconds.
>      > * Worker launch call: '/Library/Frameworks/R.framework/Resources/bin/Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'try(cat(Sys.getpid(),file="/var/folders/5s/kgm05t2s0_52gz1s445mnlgw0000gn/T//RtmpZp1RX6/future.parent=835.3434fe0c5c6.pid"), silent = TRUE)' -e 'parallel:::.slaveRSOCK()' MASTER=localhost PORT=11867 OUT=/dev/null TIMEOUT=60 XDR=TRUE.
>      > * Worker (PID 903) was successfully killed: TRUE
>      > * Troubleshooting suggestions:
>      >     - Suggestion #1: Set 'outfile=NULL' to see output from worker.
>      > In addition: Warning message:
>      > In socketConnection("localhost", port = port, server = TRUE, blocking = TRUE,  :
>      >    problem in listening on this socket
>      >
>      > My session looks like:
>      >> sessionInfo()
>      > R version 3.6.0 (2019-04-26)
>      > Platform: x86_64-apple-darwin15.6.0 (64-bit)
>      > Running under: macOS Mojave 10.14.5
>      >
>      > Matrix products: default
>      > BLAS:   /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib
>      > LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib
>      >
>      > Random number generation:
>      > RNG:     Mersenne-Twister
>      >   Normal:  Inversion
>      >   Sample:  Rounding
>      >
>      > locale:
>      > [1] de_DE.UTF-8/de_DE.UTF-8/de_DE.UTF-8/C/de_DE.UTF-8/de_DE.UTF-8
>      >
>      > attached base packages:
>      > [1] stats     graphics  grDevices utils     datasets  methods   base
>      >
>      > loaded via a namespace (and not attached):
>      > [1] compiler_3.6.0
>      > Any help is greatly appreciated.
>      > Best regards
>      > Dominik
>      >
>      > Dr. Dominik Leutnant
>      >
>      > Muenster University of Applied Sciences
>      > Department of Civil Engineering
>      > Institute for Infrastucture?Water?Resources?Environment (IWARU)
>      > WG Urban Hydrology and Water Management
>      > Corrensstr. 25
>      > FRG-48149 M?nster, Germany
>      >
>      > Tel.:  +49 (0) 251/83-65274
>      > Fax:  +49 (0) 251/83-65915
>      > Mail:  leutnant at fh-muenster.de<mailto:leutnant at fh-muenster.de>
>      > Web: https://www.fh-muenster.de/
>      >
>      > 	[[alternative HTML version deleted]]
>      >
>      > ______________________________________________
>      > R-devel at r-project.org mailing list
>      > https://stat.ethz.ch/mailman/listinfo/r-devel
>      
>      
>      
>


From @zwj|08 @end|ng |rom gm@||@com  Mon Aug 12 18:56:34 2019
From: @zwj|08 @end|ng |rom gm@||@com (Wang Jiefei)
Date: Mon, 12 Aug 2019 12:56:34 -0400
Subject: [Rd] ALTREP package interaction with testthat
Message-ID: <CAGiFhPP7kyoXh7=k_7T3aPOk2eJ93X=Yc_ybRbras6Mn5BpCpw@mail.gmail.com>

Hi



I found a weird problem in testthat while working with an ALTREP package.
The package name is AltWrapper. My ALTREP serialize function is called even
when I'm trying to serialize a non-ALTREP object.  Here is an example



```

context("altrep")

length_func<-function(x){

    return(length(x))

}

setAltClass(className = "test", classType = "real")

setAltMethod(className = "test", getLength = length_func)

testData = runif(10)

myAltrep = makeAltrep("test", testData)



test_that("Auto serialize", {

    browser()

    A = 10

    A_serialized=serialize(A,NULL)

    B = new.env()

    B_serialized=serialize(B,NULL)

})

```

There is nothing but two variables A and B in the test function. I use
browser() to stop and debug the code. Here is the weird thing, my package
function is called when I?m trying to serialize *A* and *B*:

```

Browse[1]> A = 10

Browse[1]> A_serialized=serialize(A,NULL)

Browse[1]> B = new.env()

Browse[1]> B_serialized=serialize(B,NULL)

serializing data

Auto serializing data

[1] "Internal serialize altWrapper function"

```

The output indicates that my package function is called. The function is
designed for an ALTREP object. Since *B* is not an ALTREP, I don?t
understand why the ALTREP related function has been called. Also, variable
A works find. It seems like R dispatches the serialize function according
to the variable type, but I am not sure if there is any way to see the
dispatching rules. Here are the things I have tried:

1. if I comment out the code that defines an ALTREP in my example, the bug
will disappear, so it might relate to the implementation of ALTREP.

2. If I run the test script in the global environment, R wouldn?t call the
internal function, it only happens when I call `devtools::test()`.


I am stuck here. I do not know if it is a bug of my package or testthat or
the ALTREP implementation of R or possibly the interaction between them. I
will appreciate if anyone can shed light on it. Here is the link to my
package test file:

https://github.com/Jiefei-Wang/AltWrapper/blob/master/tests/testthat/test_test.R




Best,

Jiefei

	[[alternative HTML version deleted]]


From edd @end|ng |rom deb|@n@org  Mon Aug 12 19:51:01 2019
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Mon, 12 Aug 2019 12:51:01 -0500
Subject: [Rd] ALTREP package interaction with testthat
In-Reply-To: <CAGiFhPP7kyoXh7=k_7T3aPOk2eJ93X=Yc_ybRbras6Mn5BpCpw@mail.gmail.com>
References: <CAGiFhPP7kyoXh7=k_7T3aPOk2eJ93X=Yc_ybRbras6Mn5BpCpw@mail.gmail.com>
Message-ID: <23889.42757.43491.813668@rob.eddelbuettel.com>


On 12 August 2019 at 12:56, Wang Jiefei wrote:
| I am stuck here. I do not know if it is a bug of my package or testthat or
| the ALTREP implementation of R or possibly the interaction between them.

I don't have any concrete advice for your issue here but when I find myself
in similar debugging situations involving four or more moving parts, I
usually try to remove one or two. Once I am down to 'just base R and my
package' it tends to become much clearer where the issue is.

_Narrator: Base R usually wins._

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From m|ch@e|ch|r|co4 @end|ng |rom gm@||@com  Tue Aug 13 11:16:24 2019
From: m|ch@e|ch|r|co4 @end|ng |rom gm@||@com (Michael Chirico)
Date: Tue, 13 Aug 2019 17:16:24 +0800
Subject: [Rd] Why no tz argument for format.POSIXlt?
Message-ID: <CAPRVBcyK=Rv9=y+SgaJN57Rgf1OAwk359spXhPyLccMm6OJOtA@mail.gmail.com>

Was a bit surprised to see

oldtz = Sys.getenv('TZ')
Sys.setenv(TZ = 'Asia/Jakarta')
format(Sys.time())
# [1] "2019-08-13 16:05:03"
format(Sys.time(), tz = 'UTC') # all is well
# [1] "2019-08-13 09:05:03"
format(trunc(Sys.time(), 'hours')) # correctly truncated in local time
# [1] "2019-08-13 16:00:00"
format(trunc(Sys.time(), 'hours'), tz = 'UTC') # no effect!
[1] "2019-08-13 16:00:00"
Sys.setenv(TZ = oldtz)

The reason for the discrepancy is that trunc.POSIXt returns a POSIXlt
object (not POSIXct), whereas Sys.time() is POSIXct. And while
format.POSIXct has a tz argument, format.POSIXlt does not:

names(formals(format.POSIXct))
# [1] "x"      "format" "tz"     "usetz"  "..."
names(formals(format.POSIXlt))
# [1] "x"      "format" "usetz"  "..."

Is there any reason not to accept a tz argument for format.POSIXlt? It's
quite convenient to be able to specify an output timezone format on the fly
with format.POSIXct; in the case at hand, I'm trying to force UTC time on
input. format(as.POSIXct(x), tz = 'UTC') seems to work just fine, is there
a reason why this wouldn't be done internally?

Michael Chirico

	[[alternative HTML version deleted]]


From @pyqqqd|@ @end|ng |rom y@hoo@com  Tue Aug 13 13:48:34 2019
From: @pyqqqd|@ @end|ng |rom y@hoo@com (Michael Meyer)
Date: Tue, 13 Aug 2019 11:48:34 +0000 (UTC)
Subject: [Rd] behaviour and documentation of qr.solve
Message-ID: <1135336059.4169369.1565696914907@mail.yahoo.com>


Greetings,

In my opinion the documentation or behaviour of qr.solve, qr.coef, qr.resid, and qr.fitted is not easily comprehensible and unfortunate.
We all know that a linear system Ax=b can have 0, one or infinitely many solutions. To treat all these cases uniformly we can rephrase the problem
as 
                                    x = argmin_u||Au-b||,                                       

where ||.|| denotes the Euclidean norm. There is then exactly one natural and distinguished solution x, the minimizer x which is itself of minimal
Euclidean Norm. So if we want to return only one solution, I think we can agree that this should be it.

In fact this very solution can be computed from the QR-decomposition of either A (overdetermined system) or t(A) (underdetermined system).
I tried qr.solve on the underdetermined system Ax=b with  

b <- c(3,5,7)   
and
A <- rbind(
    c(1,1,1,1,1),
    c(1,2,2,2,2),
    c(1,2,3,3,3)
)
The system has infinitely many solutions. The minimal norm solution is x=c(1,0,2/3,2/3,2/3).
But qr.solve(A,b) yielded the solution x=(1,0,2,0,0) which is destinguished only by being sparse and I do not think qr.solve
tries to compute the sparsest solution. So what does qr.solve do in case of an underdetermined system? 
It is not documented.

Then I tried to figure out what qr.coef, qr.resid, and qr.fitted do. I had to do actual experiments to figure out that it seems to solve the
problem x=argmin_u||Au-y|| with
                                           qr.coef(A,y) = x     but which x when there are infinitely many?
                                           qr.fitted(A,y) = Ax
                                           qr.resid(A,y) = y-Ax 
but this is certainly not evident from the language in the documentation which conflates qr(x,...) with solving the system Ax=b then states:

"The functions qr.coef, qr.resid, and qr.fitted return the coefficients, residuals and fitted values obtained 
  when fitting y to the matrix with QR decomposition qr."

Since when do we call solving a system of equations "fitting the right hand side to the matrix ..." or call the solution x "the coefficients"
(which more usually are the elements of A) or introduce the "fitted values" with no definition?
Moreover the language does not fit the underdetermined case Ax=y, where we need the QR-decomposition of t(A) and not of A  to compute the
minimizer x = argmin_u||Au-y|| which is itself of minimal norm.

Or, maybe this is not at all what these functions are doing.
But then, what is it and should this not be evident from the documentation?

Sincerely,

Michael Meyer


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Wed Aug 14 11:16:11 2019
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Wed, 14 Aug 2019 11:16:11 +0200
Subject: [Rd] Underscores in package names
In-Reply-To: <79a31832-848b-4d3c-7634-d7a6dd692d14@gmail.com>
References: <CAD6tx94RYHAWCFVuMgMXLUUFG3BgKSCfs3Un=SStQ7rCtgAUSQ@mail.gmail.com>
 <CAKFxdiRMmGwf1AWEBPvu4xtkhQpC6-Xoava2ZVwgxcz0jRkYyg@mail.gmail.com>
 <CAN--Dz2=ScCo985xtKQrVbmkWEq4hq=q2QD5V-DKQxeCQdhNrw@mail.gmail.com>
 <CAD4oTHHGvPDXg1uKhMO9KKjgPRDfYxUug8fTLLwj-sJdUw9Vfg@mail.gmail.com>
 <7c89e005-37a4-16f9-4ef7-f3f186213944@gmail.com>
 <CAD4oTHEAszVnHjGqxE2ooeYCE4R4K9mRaoKcqLxSfAO502NJcQ@mail.gmail.com>
 <79a31832-848b-4d3c-7634-d7a6dd692d14@gmail.com>
Message-ID: <23891.53595.893103.326744@stat.math.ethz.ch>

>>>>> Duncan Murdoch 
>>>>>     on Fri, 9 Aug 2019 20:23:28 -0400 writes:

    > On 09/08/2019 4:37 p.m., Gabriel Becker wrote:
    >> Duncan,
    >> 
    >> 
    >> On Fri, Aug 9, 2019 at 1:17 PM Duncan Murdoch <murdoch.duncan at gmail.com 
    >> <mailto:murdoch.duncan at gmail.com>> wrote:
    >> 
    >> On 09/08/2019 2:41 p.m., Gabriel Becker wrote:
    >> > Note that this proposal would make mypackage_2.3.1 a valid
    >> *package name*,
    >> > whose corresponding tarball name might be mypackage_2.3.1_2.3.2
    >> after a
    >> > patch. Yes its a silly example, but why allow that kind of ambiguity?
    >> >
    >> CRAN already has a package named "FuzzyNumbers.Ext.2", whose tarball is
    >> FuzzyNumbers.Ext.2_3.2.tar.gz, so I think we've already lost that game.
    >> 
    >> 
    >> I suppose technically 2 is a valid version number for a package (?) so I 
    >> suppose you have me there. But as Ben pointed out while I was writing 
    >> this, all I can really say is that in practice they read to me (as 
    >> someone who has administered R on a large cluster and written 
    >> build-system software for it) as substantially different levels of 
    >> ambiguity. I do acknowledge, as Ben does, that yes a more complex 
    >> regular expression/splitting algorithm can be written that would handle 
    >> the more general package names. I just don't personally see a motivation 
    >> that justifies changing something this fundamental (even if it is both 
    >> narrow and was initially more or less arbitrarily chosen) about R at 
    >> this late date.
    >> 
    >> I guess at the end of the day, I guess what I'm saying is that breaking 
    >> and changing things is sometimes good, but if we're going to rock the 
    >> boat personally I'd want to do so going after bigger wins than this one. 
    >> Thats just my opinion though.

    > Sorry, I wasn't clear.  I agree with you.  I was just saying that the 
    > particular argument based on ugly tarball names isn't the reason.

    > Duncan Murdoch

Thank you (and Gabe).

We have had some R core internal "talk" about Jim Hester's
suggestion (of adding underscores to the allow characters in
package names).
Duncan had already given a good reason why such a change would be problematic
(the underscore being used as unique separator of package name
 and version in source and binary package archives),
and with Jim's offer to find and provide patches for all places
this is used in the R sources, we've convinced ourselves that
there is much more code "out there", notably 'devops' code in
scripts, which currently relies on the current package naming
rules and which could break, often only rarely and hence
possibly unnoticed for too long.

Also, we've not seen compelling arguments why the current scheme
would be too limited (people mentioned that if you must use a
separator, "." was available).

Consequence:  We stay with the stability principle and the
package naming scheme is _not_ going to be changed for now.

Martin Maechler
ETH Zurich and R Core Team


From cyc||cgroup-z1 @end|ng |rom y@hoo@com  Thu Aug 15 07:56:41 2019
From: cyc||cgroup-z1 @end|ng |rom y@hoo@com (Cyclic Group Z_1)
Date: Thu, 15 Aug 2019 05:56:41 +0000 (UTC)
Subject: [Rd] Feature request: non-dropping regmatches/strextract
References: <2012653205.221487.1565848601638.ref@mail.yahoo.com>
Message-ID: <2012653205.221487.1565848601638@mail.yahoo.com>

A very common use case for regmatches is to extract regex matches into a new column in a data.frame (or data.table, etc.) or otherwise use the extracted strings alongside the input. However, the default behavior is to drop empty matches, which results in mismatches in column length if reassignment is done without subsetting.

For consistency with other R functions and compatibility with this use case, it would be nice if regmatches did not automatically drop empty matches and would instead insert an NA_character_ value (similar to stringr::str_extract). This alternative regmatches could be implemented through an optional drop argument, a new function, or mentioned in the documentation (a la resample in ?sample).?

Alternatively, at the moment, there is a non-exported function strextract in utils which is very similar to stringr::str_extract. It would be great if this function, once exported, were to include a drop argument to prevent dropping positions with no matches.?

An example solution (last option):

strextract <- function(pattern, x, perl = FALSE, useBytes = FALSE, drop = T) {
 m <- regexec(pattern, x, perl=perl, useBytes=useBytes)
 result <- regmatches(x, m)
 
 if(isTRUE(drop)){
 unlist(result)
 } else if(isFALSE(drop)) {
 unlist({result[lengths(result)==0] <- NA_character_; result})
 } else {
 stop("Invalid argument for `drop`")
 }
}

Based on?Ricardo Saporta's response to?How to prevent regmatches drop non matches?

--CG


From j@me@@|@he@ter @end|ng |rom gm@||@com  Thu Aug 15 15:00:01 2019
From: j@me@@|@he@ter @end|ng |rom gm@||@com (Jim Hester)
Date: Thu, 15 Aug 2019 09:00:01 -0400
Subject: [Rd] Underscores in package names
In-Reply-To: <23891.53595.893103.326744@stat.math.ethz.ch>
References: <CAD6tx94RYHAWCFVuMgMXLUUFG3BgKSCfs3Un=SStQ7rCtgAUSQ@mail.gmail.com>
 <CAKFxdiRMmGwf1AWEBPvu4xtkhQpC6-Xoava2ZVwgxcz0jRkYyg@mail.gmail.com>
 <CAN--Dz2=ScCo985xtKQrVbmkWEq4hq=q2QD5V-DKQxeCQdhNrw@mail.gmail.com>
 <CAD4oTHHGvPDXg1uKhMO9KKjgPRDfYxUug8fTLLwj-sJdUw9Vfg@mail.gmail.com>
 <7c89e005-37a4-16f9-4ef7-f3f186213944@gmail.com>
 <CAD4oTHEAszVnHjGqxE2ooeYCE4R4K9mRaoKcqLxSfAO502NJcQ@mail.gmail.com>
 <79a31832-848b-4d3c-7634-d7a6dd692d14@gmail.com>
 <23891.53595.893103.326744@stat.math.ethz.ch>
Message-ID: <CAD6tx96AO4sf_DeMKsdcQ5Zkf817u=P07nfRJhZbAycM85ybAA@mail.gmail.com>

Martin,

Thank you for discussing this amongst R-core and for detailing the
R-core discussion here.

Some specific examples where having underscores available would have
been useful.

1. My primerTree package (2013) was originally primer_tree, but I had
to change the name to camelCase to comply with the check requirements.
Using camelCase in the package name makes reading code jarring, as the
functions all use snake_case.
2. The widely used testthat package would likely be called test_that,
like the corresponding function within the package. This also
highlights one of the drawbacks of the current situation, without
separators the package name is more difficult to read, does it have
two t's or three?
3. The assertive suite of packages use `.` for separation, e.g.
`assertive.base`, `assertive.datetimes` etc. but all functions within
the packages use `_` separators, again likely this was done out of
necessity rather than desire.

There are many more I am sure, these were some that came immediately
to mind. More important than the specific examples is the opportunity
cost of having this restriction, which we cannot really quantify.

Using dots for separators has a number of practical problems.
Functions using dots are ambiguous, e.g. is `as.data.frame()` a
regular function, an `as.data()` method for a `frame` object, or an
`as()` method for a `data.frame` object? And in fact regular functions
can be accidentally promoted to S3 methods by defining a S3 generic,
which does actually happen in real life, confusing users [1]. While
package names are not functions, using dots in package names
encourages the use of dots in functions, a dangerous practice. Dots in
names is also one of the common stones cast at R as a language, as
dots are used for object oriented method dispatch in other common
languages.

The prevalence of dotted functions is the only major naming convention
which is steadily decreasing over time. It now accounts for only
around 15% of all function names when looking at all 94 Million lines
of code currently available on CRAN (See Figure 2. from Yen et. al.
[2]).

Thanks again for the public discussion,

Jim

[1]: https://twitter.com/_ColinFay/status/1105579764797108230
[2]: https://osf.io/preprints/socarxiv/ts2wq/

On Wed, Aug 14, 2019 at 5:16 AM Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>
> >>>>> Duncan Murdoch
> >>>>>     on Fri, 9 Aug 2019 20:23:28 -0400 writes:
>
>     > On 09/08/2019 4:37 p.m., Gabriel Becker wrote:
>     >> Duncan,
>     >>
>     >>
>     >> On Fri, Aug 9, 2019 at 1:17 PM Duncan Murdoch <murdoch.duncan at gmail.com
>     >> <mailto:murdoch.duncan at gmail.com>> wrote:
>     >>
>     >> On 09/08/2019 2:41 p.m., Gabriel Becker wrote:
>     >> > Note that this proposal would make mypackage_2.3.1 a valid
>     >> *package name*,
>     >> > whose corresponding tarball name might be mypackage_2.3.1_2.3.2
>     >> after a
>     >> > patch. Yes its a silly example, but why allow that kind of ambiguity?
>     >> >
>     >> CRAN already has a package named "FuzzyNumbers.Ext.2", whose tarball is
>     >> FuzzyNumbers.Ext.2_3.2.tar.gz, so I think we've already lost that game.
>     >>
>     >>
>     >> I suppose technically 2 is a valid version number for a package (?) so I
>     >> suppose you have me there. But as Ben pointed out while I was writing
>     >> this, all I can really say is that in practice they read to me (as
>     >> someone who has administered R on a large cluster and written
>     >> build-system software for it) as substantially different levels of
>     >> ambiguity. I do acknowledge, as Ben does, that yes a more complex
>     >> regular expression/splitting algorithm can be written that would handle
>     >> the more general package names. I just don't personally see a motivation
>     >> that justifies changing something this fundamental (even if it is both
>     >> narrow and was initially more or less arbitrarily chosen) about R at
>     >> this late date.
>     >>
>     >> I guess at the end of the day, I guess what I'm saying is that breaking
>     >> and changing things is sometimes good, but if we're going to rock the
>     >> boat personally I'd want to do so going after bigger wins than this one.
>     >> Thats just my opinion though.
>
>     > Sorry, I wasn't clear.  I agree with you.  I was just saying that the
>     > particular argument based on ugly tarball names isn't the reason.
>
>     > Duncan Murdoch
>
> Thank you (and Gabe).
>
> We have had some R core internal "talk" about Jim Hester's
> suggestion (of adding underscores to the allow characters in
> package names).
> Duncan had already given a good reason why such a change would be problematic
> (the underscore being used as unique separator of package name
>  and version in source and binary package archives),
> and with Jim's offer to find and provide patches for all places
> this is used in the R sources, we've convinced ourselves that
> there is much more code "out there", notably 'devops' code in
> scripts, which currently relies on the current package naming
> rules and which could break, often only rarely and hence
> possibly unnoticed for too long.
>
> Also, we've not seen compelling arguments why the current scheme
> would be too limited (people mentioned that if you must use a
> separator, "." was available).
>
> Consequence:  We stay with the stability principle and the
> package naming scheme is _not_ going to be changed for now.
>
> Martin Maechler
> ETH Zurich and R Core Team


From wdun|@p @end|ng |rom t|bco@com  Thu Aug 15 17:08:23 2019
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Thu, 15 Aug 2019 08:08:23 -0700
Subject: [Rd] Feature request: non-dropping regmatches/strextract
In-Reply-To: <2012653205.221487.1565848601638@mail.yahoo.com>
References: <2012653205.221487.1565848601638.ref@mail.yahoo.com>
 <2012653205.221487.1565848601638@mail.yahoo.com>
Message-ID: <CAF8bMcaoxRZvQ0hJd_HygP2bOi-816UXybZEJDz3OWR6r56ZRA@mail.gmail.com>

Changing the default behavior of regmatches would break its use with
gregexpr, where
the number of matches per input element faries, so a zero-length character
vector
makes more sense than NA_character_.

> x <- c("John Doe", "e e cummings", "Juan de la Madrid")
> m <- gregexpr("[A-Z]", x)
> regmatches(x,m)
[[1]]
[1] "J" "D"

[[2]]
character(0)

[[3]]
[1] "J" "M"

> vapply(.Last.value, function(x)paste(paste0(x, "."),collapse=""), "")
[1] "J.D." "."    "J.M."

(We don't want e e cummings initials mapped to "NA.")

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Aug 15, 2019 at 12:15 AM Cyclic Group Z_1 via R-devel <
r-devel at r-project.org> wrote:

> A very common use case for regmatches is to extract regex matches into a
> new column in a data.frame (or data.table, etc.) or otherwise use the
> extracted strings alongside the input. However, the default behavior is to
> drop empty matches, which results in mismatches in column length if
> reassignment is done without subsetting.
>
> For consistency with other R functions and compatibility with this use
> case, it would be nice if regmatches did not automatically drop empty
> matches and would instead insert an NA_character_ value (similar to
> stringr::str_extract). This alternative regmatches could be implemented
> through an optional drop argument, a new function, or mentioned in the
> documentation (a la resample in ?sample).
>
> Alternatively, at the moment, there is a non-exported function strextract
> in utils which is very similar to stringr::str_extract. It would be great
> if this function, once exported, were to include a drop argument to prevent
> dropping positions with no matches.
>
> An example solution (last option):
>
> strextract <- function(pattern, x, perl = FALSE, useBytes = FALSE, drop =
> T) {
>  m <- regexec(pattern, x, perl=perl, useBytes=useBytes)
>  result <- regmatches(x, m)
>
>  if(isTRUE(drop)){
>  unlist(result)
>  } else if(isFALSE(drop)) {
>  unlist({result[lengths(result)==0] <- NA_character_; result})
>  } else {
>  stop("Invalid argument for `drop`")
>  }
> }
>
> Based on Ricardo Saporta's response to How to prevent regmatches drop non
> matches?
>
> --CG
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From wdun|@p @end|ng |rom t|bco@com  Thu Aug 15 19:12:46 2019
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Thu, 15 Aug 2019 10:12:46 -0700
Subject: [Rd] Rf_defineVar(symbol, R_UnboundValue, environment) questions
Message-ID: <CAF8bMcY0R8+3rFcdN29OahKjerCoPodzs2hMnCNXmrg2UTiNEg@mail.gmail.com>

While poking around the C++ code in the dplyr package I ran across the idiom
   Rf_defineVar(symbol, R_UnboundValue, environment)
to [sort of] remove 'symbol' from 'environment'

Using it makes the R-level functions objects(), exists(), and get()
somewhat inconsistent and I was wondering if that was intended.  E.g.,  use
SHLIB to make something from the following C code that dyn.load can load
into R

% cat defineVarAsUnboundValue.c
#include <R.h>
#include <Rinternals.h>

SEXP defineVarAsUnboundValue(SEXP name, SEXP envir)
{
    Rf_defineVar(name, R_UnboundValue, envir);
    return R_NilValue;
}
erratic:bill:292% R-3.6.1 CMD SHLIB defineVarAsUnboundValue.c
gcc -std=gnu99 -I"/home/R/R-3.6.1/lib64/R/include" -DNDEBUG
-I/usr/local/include  -fpic  -g -O2  -c defineVarAsUnboundValue.c -o
defineVarAsUnboundValue.o
gcc -std=gnu99 -shared -L/home/R/R-3.6.1/lib64/R/lib -L/usr/local/lib64 -o
defineVarAsUnboundValue.so defineVarAsUnboundValue.o
-L/home/R/R-3.6.1/lib64/R/lib -lR
erratic:bill:293% R-3.6.1 --quiet --vanilla
> dyn.load("defineVarAsUnboundValue.so")
> envir <- list2env(list(One=1, Two=2))
> objects(envir)
[1] "One" "Two"
>
> .Call("defineVarAsUnboundValue", quote(Two), envir)
NULL
> objects(envir)
[1] "One"
> objects(envir, all.names=TRUE) # is "Two" a 'hidden' object?
[1] "One" "Two"
> exists("Two", envir=envir, inherits=FALSE)
[1] TRUE
> get("Two", envir=envir, inherits=FALSE) # get fails when exists says ok
Error in get("Two", envir = envir, inherits = FALSE) :
  object 'Two' not found

Should Rf_defineVar(sym, R_UnboundValue, envir) remove sym from envir?

Bill Dunlap
TIBCO Software
wdunlap tibco.com

	[[alternative HTML version deleted]]


From cyc||cgroup-z1 @end|ng |rom y@hoo@com  Thu Aug 15 20:31:01 2019
From: cyc||cgroup-z1 @end|ng |rom y@hoo@com (Cyclic Group Z_1)
Date: Thu, 15 Aug 2019 18:31:01 +0000 (UTC)
Subject: [Rd] Feature request: non-dropping regmatches/strextract
In-Reply-To: <CAF8bMcaoxRZvQ0hJd_HygP2bOi-816UXybZEJDz3OWR6r56ZRA@mail.gmail.com>
References: <2012653205.221487.1565848601638.ref@mail.yahoo.com>
 <2012653205.221487.1565848601638@mail.yahoo.com>
 <CAF8bMcaoxRZvQ0hJd_HygP2bOi-816UXybZEJDz3OWR6r56ZRA@mail.gmail.com>
Message-ID: <261022177.555187.1565893861815@mail.yahoo.com>

I do think keeping the default behavior is desirable for backwards compatibility; my suggestion is not to change default behavior but to add an optional argument that allows a different behavior. Although this can be implemented in a user-defined function, retaining empty matches facilitates programmatic use, and seems to be something that should be available in base R. It is available, for example, in MATLAB, a comparable array language.

Alternatively, perhaps a nomatch (or maybe emptymatch) argument in the spirit of `[.data.table`? That is, an argument nomatch where nomatch = NULL (the default) results in drops for vector outputs and character(0) for list outputs and nomatch = NA results in insertion of NA_character_, and nomatch = '' results in insertion of empty string.

I can submit proposed patch code if others think this is a good idea.

What are your thoughts on the proposed alteration to (currently nonexported) strextract? I assume (maybe wrongly) that the plan is to eventually export that function.

Thank you,
CG


From wdun|@p @end|ng |rom t|bco@com  Thu Aug 15 22:04:11 2019
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Thu, 15 Aug 2019 13:04:11 -0700
Subject: [Rd] Feature request: non-dropping regmatches/strextract
In-Reply-To: <261022177.555187.1565893861815@mail.yahoo.com>
References: <2012653205.221487.1565848601638.ref@mail.yahoo.com>
 <2012653205.221487.1565848601638@mail.yahoo.com>
 <CAF8bMcaoxRZvQ0hJd_HygP2bOi-816UXybZEJDz3OWR6r56ZRA@mail.gmail.com>
 <261022177.555187.1565893861815@mail.yahoo.com>
Message-ID: <CAF8bMcZAuphcTQyLMw5+NbD_SJEmeSzihQ7AcjYLvLmGD_S-ww@mail.gmail.com>

I don't care much for regmatches and haven't tried strextract, but I think
replacing the character(0) by NA_character_ is almost always inappropriate
if the match information comes from gregexpr.

I think strcapture() does a pretty good job of what I think you are trying
to do.  Perhaps adding an argument to map no match to NA instead of ""
would give you just what you wanted.

> x <- c("Groucho <groucho at marx.com>", "<chico at marx.com>", "Harpo")
> d <- strcapture("([[:alpha:]]+)?( *<([[:alpha:]. ]+@[[:alpha:]. ]+)>)?",
x, proto=data.frame(Name=character(), Junk=character(),
Address=character(), stringsAsFactors=FALSE))
> d[c("Name", "Address")]
     Name          Address
1 Groucho groucho at marx.com
2           chico at marx.com
3   Harpo
> str(.Last.value)
'data.frame':   3 obs. of  2 variables:
 $ Name   : chr  "Groucho" "" "Harpo"
 $ Address: chr  "groucho at marx.com" "chico at marx.com" ""
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Aug 15, 2019 at 11:31 AM Cyclic Group Z_1 <cyclicgroup-z1 at yahoo.com>
wrote:

> I do think keeping the default behavior is desirable for backwards
> compatibility; my suggestion is not to change default behavior but to add
> an optional argument that allows a different behavior. Although this can be
> implemented in a user-defined function, retaining empty matches facilitates
> programmatic use, and seems to be something that should be available in
> base R. It is available, for example, in MATLAB, a comparable array
> language.
>
> Alternatively, perhaps a nomatch (or maybe emptymatch) argument in the
> spirit of `[.data.table`? That is, an argument nomatch where nomatch = NULL
> (the default) results in drops for vector outputs and character(0) for list
> outputs and nomatch = NA results in insertion of NA_character_, and nomatch
> = '' results in insertion of empty string.
>
> I can submit proposed patch code if others think this is a good idea.
>
> What are your thoughts on the proposed alteration to (currently
> nonexported) strextract? I assume (maybe wrongly) that the plan is to
> eventually export that function.
>
> Thank you,
> CG
>

	[[alternative HTML version deleted]]


From wdun|@p @end|ng |rom t|bco@com  Thu Aug 15 22:39:10 2019
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Thu, 15 Aug 2019 13:39:10 -0700
Subject: [Rd] Feature request: non-dropping regmatches/strextract
In-Reply-To: <CAF8bMcZAuphcTQyLMw5+NbD_SJEmeSzihQ7AcjYLvLmGD_S-ww@mail.gmail.com>
References: <2012653205.221487.1565848601638.ref@mail.yahoo.com>
 <2012653205.221487.1565848601638@mail.yahoo.com>
 <CAF8bMcaoxRZvQ0hJd_HygP2bOi-816UXybZEJDz3OWR6r56ZRA@mail.gmail.com>
 <261022177.555187.1565893861815@mail.yahoo.com>
 <CAF8bMcZAuphcTQyLMw5+NbD_SJEmeSzihQ7AcjYLvLmGD_S-ww@mail.gmail.com>
Message-ID: <CAF8bMcab68FXfx56vdOm=6mu-VH4bBwQuvdW_5pNC6etB1WASQ@mail.gmail.com>

Using a non-capturing group, "(?:...)" instead of "(...)", simplifies my
example a bit

> x <- c("Groucho <groucho at marx.com>", "<chico at marx.com>", "Harpo")
> strcapture("([[:alpha:]]+)?(?: *<([[:alpha:]. ]+@[[:alpha:]. ]+)>)?", x,
proto=data.frame(Name=character(), Address=character(),
stringsAsFactors=FALSE))
     Name          Address
1 Groucho groucho at marx.com
2           chico at marx.com
3   Harpo

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Aug 15, 2019 at 1:04 PM William Dunlap <wdunlap at tibco.com> wrote:

> I don't care much for regmatches and haven't tried strextract, but I think
> replacing the character(0) by NA_character_ is almost always inappropriate
> if the match information comes from gregexpr.
>
> I think strcapture() does a pretty good job of what I think you are trying
> to do.  Perhaps adding an argument to map no match to NA instead of ""
> would give you just what you wanted.
>
> > x <- c("Groucho <groucho at marx.com>", "<chico at marx.com>", "Harpo")
> > d <- strcapture("([[:alpha:]]+)?( *<([[:alpha:]. ]+@[[:alpha:]. ]+)>)?",
> x, proto=data.frame(Name=character(), Junk=character(),
> Address=character(), stringsAsFactors=FALSE))
> > d[c("Name", "Address")]
>      Name          Address
> 1 Groucho groucho at marx.com
> 2           chico at marx.com
> 3   Harpo
> > str(.Last.value)
> 'data.frame':   3 obs. of  2 variables:
>  $ Name   : chr  "Groucho" "" "Harpo"
>  $ Address: chr  "groucho at marx.com" "chico at marx.com" ""
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Thu, Aug 15, 2019 at 11:31 AM Cyclic Group Z_1 <
> cyclicgroup-z1 at yahoo.com> wrote:
>
>> I do think keeping the default behavior is desirable for backwards
>> compatibility; my suggestion is not to change default behavior but to add
>> an optional argument that allows a different behavior. Although this can be
>> implemented in a user-defined function, retaining empty matches facilitates
>> programmatic use, and seems to be something that should be available in
>> base R. It is available, for example, in MATLAB, a comparable array
>> language.
>>
>> Alternatively, perhaps a nomatch (or maybe emptymatch) argument in the
>> spirit of `[.data.table`? That is, an argument nomatch where nomatch = NULL
>> (the default) results in drops for vector outputs and character(0) for list
>> outputs and nomatch = NA results in insertion of NA_character_, and nomatch
>> = '' results in insertion of empty string.
>>
>> I can submit proposed patch code if others think this is a good idea.
>>
>> What are your thoughts on the proposed alteration to (currently
>> nonexported) strextract? I assume (maybe wrongly) that the plan is to
>> eventually export that function.
>>
>> Thank you,
>> CG
>>
>

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Fri Aug 16 01:20:42 2019
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Fri, 16 Aug 2019 11:20:42 +1200
Subject: [Rd] Underscores in package names
In-Reply-To: <CAD6tx96AO4sf_DeMKsdcQ5Zkf817u=P07nfRJhZbAycM85ybAA@mail.gmail.com>
References: <CAD6tx94RYHAWCFVuMgMXLUUFG3BgKSCfs3Un=SStQ7rCtgAUSQ@mail.gmail.com>
 <CAKFxdiRMmGwf1AWEBPvu4xtkhQpC6-Xoava2ZVwgxcz0jRkYyg@mail.gmail.com>
 <CAN--Dz2=ScCo985xtKQrVbmkWEq4hq=q2QD5V-DKQxeCQdhNrw@mail.gmail.com>
 <CAD4oTHHGvPDXg1uKhMO9KKjgPRDfYxUug8fTLLwj-sJdUw9Vfg@mail.gmail.com>
 <7c89e005-37a4-16f9-4ef7-f3f186213944@gmail.com>
 <CAD4oTHEAszVnHjGqxE2ooeYCE4R4K9mRaoKcqLxSfAO502NJcQ@mail.gmail.com>
 <79a31832-848b-4d3c-7634-d7a6dd692d14@gmail.com>
 <23891.53595.893103.326744@stat.math.ethz.ch>
 <CAD6tx96AO4sf_DeMKsdcQ5Zkf817u=P07nfRJhZbAycM85ybAA@mail.gmail.com>
Message-ID: <CAB8pepwkcD+Ewjze9NzpXC8EM5R2Z2n9eDsvoO7XjHtN+7pN+g@mail.gmail.com>

> While
> package names are not functions, using dots in package names
> encourages the use of dots in functions, a dangerous practice.

"dangerous"...?
I can't understand the necessity of RStudio and Tiny-Verse affiliated
persons to repeatedly use subjective and unscientific phrasing.

Elegant, Advanced, Dangerous...
At UseR, there was even "Advanced Use of your Favorite IDE".

This is not science.
This is marketing.

There's nothing dangerous about it other than your belief that it's
dangerous.
I note that many functions in the stats package use dots in function names.
Your statement implies that the stats package is badly designed, which it
is not.
Out of 14,800-ish packages on CRAN, very few of them are even close to the
standard set by the stats package, in my opinion.

And as noted by other people in this thread, changing naming policies could
interfere with a lot of software "out there", which is dangerous.

> Dots in
> names is also one of the common stones cast at R as a language, as
> dots are used for object oriented method dispatch in other common
> languages.

I don't think the goal is to copy other OOP systems.
Furthermore, some shells use dot as the current working directory and Java
uses dots in package namespaces.
And then there's regular expressions...

	[[alternative HTML version deleted]]


From j@goreck| @end|ng |rom w|t@edu@p|  Fri Aug 16 11:06:27 2019
From: j@goreck| @end|ng |rom w|t@edu@p| (Jan Gorecki)
Date: Fri, 16 Aug 2019 11:06:27 +0200
Subject: [Rd] Underscores in package names
In-Reply-To: <CAB8pepwkcD+Ewjze9NzpXC8EM5R2Z2n9eDsvoO7XjHtN+7pN+g@mail.gmail.com>
References: <CAD6tx94RYHAWCFVuMgMXLUUFG3BgKSCfs3Un=SStQ7rCtgAUSQ@mail.gmail.com>
 <CAKFxdiRMmGwf1AWEBPvu4xtkhQpC6-Xoava2ZVwgxcz0jRkYyg@mail.gmail.com>
 <CAN--Dz2=ScCo985xtKQrVbmkWEq4hq=q2QD5V-DKQxeCQdhNrw@mail.gmail.com>
 <CAD4oTHHGvPDXg1uKhMO9KKjgPRDfYxUug8fTLLwj-sJdUw9Vfg@mail.gmail.com>
 <7c89e005-37a4-16f9-4ef7-f3f186213944@gmail.com>
 <CAD4oTHEAszVnHjGqxE2ooeYCE4R4K9mRaoKcqLxSfAO502NJcQ@mail.gmail.com>
 <79a31832-848b-4d3c-7634-d7a6dd692d14@gmail.com>
 <23891.53595.893103.326744@stat.math.ethz.ch>
 <CAD6tx96AO4sf_DeMKsdcQ5Zkf817u=P07nfRJhZbAycM85ybAA@mail.gmail.com>
 <CAB8pepwkcD+Ewjze9NzpXC8EM5R2Z2n9eDsvoO7XjHtN+7pN+g@mail.gmail.com>
Message-ID: <CAOO9MKW3DNROYyTaQQi3hNt3yS6DSNW59uwWJ+kXhbjjk55qhQ@mail.gmail.com>

Thanks Abby and Martin,

In every company I worked using R - 3 in total - there was at least
one (up to ~10) processes designed (dev and implemented) to depend on
current package naming scheme, having underscore as separator of
package name and its version. From my experience I believe this is a
(very?) common practice. I also use it myself.
Arguments for having underscore in package names are simply weak.
Dot in function names is an entirely different issue caused by S3
dispatch. No need to look at other OOP languages, it is R.
Package name is not a function name.
There are no practical gains.
There is nothing wrong in having package "a.pkg" and function "a_pkg()".

Regards,
Jan Gorecki


On Fri, Aug 16, 2019 at 1:20 AM Abby Spurdle <spurdle.a at gmail.com> wrote:
>
> > While
> > package names are not functions, using dots in package names
> > encourages the use of dots in functions, a dangerous practice.
>
> "dangerous"...?
> I can't understand the necessity of RStudio and Tiny-Verse affiliated
> persons to repeatedly use subjective and unscientific phrasing.
>
> Elegant, Advanced, Dangerous...
> At UseR, there was even "Advanced Use of your Favorite IDE".
>
> This is not science.
> This is marketing.
>
> There's nothing dangerous about it other than your belief that it's
> dangerous.
> I note that many functions in the stats package use dots in function names.
> Your statement implies that the stats package is badly designed, which it
> is not.
> Out of 14,800-ish packages on CRAN, very few of them are even close to the
> standard set by the stats package, in my opinion.
>
> And as noted by other people in this thread, changing naming policies could
> interfere with a lot of software "out there", which is dangerous.
>
> > Dots in
> > names is also one of the common stones cast at R as a language, as
> > dots are used for object oriented method dispatch in other common
> > languages.
>
> I don't think the goal is to copy other OOP systems.
> Furthermore, some shells use dot as the current working directory and Java
> uses dots in package namespaces.
> And then there's regular expressions...
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From @tep@n@@|nde|@r @end|ng |rom or@c|e@com  Fri Aug 16 17:21:09 2019
From: @tep@n@@|nde|@r @end|ng |rom or@c|e@com (Stepan)
Date: Fri, 16 Aug 2019 17:21:09 +0200
Subject: [Rd] Deparsing raw vectors with names
Message-ID: <94968cc4-8943-0167-7e4b-f1dc544d1b33@oracle.com>

Hello,

deparse(structure(as.raw(1), .Names=c('a'))) gives "as.raw(c(a = 0x01))" 
in 3.5.1 and later (actually tested on 3.5.1, 3.6.1 and devel). If you 
execute as.raw(c(a = 0x01)), you get a raw vector without the names.

If the stripping of the names is the correct behavior of as.raw (I would 
think it is), then perhaps deparse should use the old behavior for raw 
vectors. On R-3.4.1 it gives: "structure(as.raw(0x01), .Names = 'a')".

Regards,
Stepan


From kw@@t@t @end|ng |rom gm@||@com  Fri Aug 16 17:36:36 2019
From: kw@@t@t @end|ng |rom gm@||@com (Kevin Wright)
Date: Fri, 16 Aug 2019 10:36:36 -0500
Subject: [Rd] Underscores in package names
In-Reply-To: <CAD6tx96AO4sf_DeMKsdcQ5Zkf817u=P07nfRJhZbAycM85ybAA@mail.gmail.com>
References: <CAD6tx94RYHAWCFVuMgMXLUUFG3BgKSCfs3Un=SStQ7rCtgAUSQ@mail.gmail.com>
 <CAKFxdiRMmGwf1AWEBPvu4xtkhQpC6-Xoava2ZVwgxcz0jRkYyg@mail.gmail.com>
 <CAN--Dz2=ScCo985xtKQrVbmkWEq4hq=q2QD5V-DKQxeCQdhNrw@mail.gmail.com>
 <CAD4oTHHGvPDXg1uKhMO9KKjgPRDfYxUug8fTLLwj-sJdUw9Vfg@mail.gmail.com>
 <7c89e005-37a4-16f9-4ef7-f3f186213944@gmail.com>
 <CAD4oTHEAszVnHjGqxE2ooeYCE4R4K9mRaoKcqLxSfAO502NJcQ@mail.gmail.com>
 <79a31832-848b-4d3c-7634-d7a6dd692d14@gmail.com>
 <23891.53595.893103.326744@stat.math.ethz.ch>
 <CAD6tx96AO4sf_DeMKsdcQ5Zkf817u=P07nfRJhZbAycM85ybAA@mail.gmail.com>
Message-ID: <CAKFxdiROQhkTa6_e+eScjbAG=0ndnnnnJ43MBgg5+qhvJQenAQ@mail.gmail.com>

I've heard the arguments against dots in names many times. The t.test and
data.frame examples have been repeated so often that it has become accepted
as gospel.  In my experience, evidence of any actual problems is fairly
limited (almost non-existent).  I've been happily using dots in function
names for 20 (sigh) years and only 1 time had an unanticipated S3 class
kick in.  I find the "." much easier to type than "_" because of the
proximity of the keys to the home-row on the keyboard.

On Thu, Aug 15, 2019 at 8:00 AM Jim Hester <james.f.hester at gmail.com> wrote:

> Martin,
>
> Thank you for discussing this amongst R-core and for detailing the
> R-core discussion here.
>
> Some specific examples where having underscores available would have
> been useful.
>
> 1. My primerTree package (2013) was originally primer_tree, but I had
> to change the name to camelCase to comply with the check requirements.
> Using camelCase in the package name makes reading code jarring, as the
> functions all use snake_case.
> 2. The widely used testthat package would likely be called test_that,
> like the corresponding function within the package. This also
> highlights one of the drawbacks of the current situation, without
> separators the package name is more difficult to read, does it have
> two t's or three?
> 3. The assertive suite of packages use `.` for separation, e.g.
> `assertive.base`, `assertive.datetimes` etc. but all functions within
> the packages use `_` separators, again likely this was done out of
> necessity rather than desire.
>
> There are many more I am sure, these were some that came immediately
> to mind. More important than the specific examples is the opportunity
> cost of having this restriction, which we cannot really quantify.
>
> Using dots for separators has a number of practical problems.
> Functions using dots are ambiguous, e.g. is `as.data.frame()` a
> regular function, an `as.data()` method for a `frame` object, or an
> `as()` method for a `data.frame` object? And in fact regular functions
> can be accidentally promoted to S3 methods by defining a S3 generic,
> which does actually happen in real life, confusing users [1]. While
> package names are not functions, using dots in package names
> encourages the use of dots in functions, a dangerous practice. Dots in
> names is also one of the common stones cast at R as a language, as
> dots are used for object oriented method dispatch in other common
> languages.
>
> The prevalence of dotted functions is the only major naming convention
> which is steadily decreasing over time. It now accounts for only
> around 15% of all function names when looking at all 94 Million lines
> of code currently available on CRAN (See Figure 2. from Yen et. al.
> [2]).
>
> Thanks again for the public discussion,
>
> Jim
>
> [1]: https://twitter.com/_ColinFay/status/1105579764797108230
> [2]: https://osf.io/preprints/socarxiv/ts2wq/
>
> On Wed, Aug 14, 2019 at 5:16 AM Martin Maechler
> <maechler at stat.math.ethz.ch> wrote:
> >
> > >>>>> Duncan Murdoch
> > >>>>>     on Fri, 9 Aug 2019 20:23:28 -0400 writes:
> >
> >     > On 09/08/2019 4:37 p.m., Gabriel Becker wrote:
> >     >> Duncan,
> >     >>
> >     >>
> >     >> On Fri, Aug 9, 2019 at 1:17 PM Duncan Murdoch <
> murdoch.duncan at gmail.com
> >     >> <mailto:murdoch.duncan at gmail.com>> wrote:
> >     >>
> >     >> On 09/08/2019 2:41 p.m., Gabriel Becker wrote:
> >     >> > Note that this proposal would make mypackage_2.3.1 a valid
> >     >> *package name*,
> >     >> > whose corresponding tarball name might be mypackage_2.3.1_2.3.2
> >     >> after a
> >     >> > patch. Yes its a silly example, but why allow that kind of
> ambiguity?
> >     >> >
> >     >> CRAN already has a package named "FuzzyNumbers.Ext.2", whose
> tarball is
> >     >> FuzzyNumbers.Ext.2_3.2.tar.gz, so I think we've already lost that
> game.
> >     >>
> >     >>
> >     >> I suppose technically 2 is a valid version number for a package
> (?) so I
> >     >> suppose you have me there. But as Ben pointed out while I was
> writing
> >     >> this, all I can really say is that in practice they read to me (as
> >     >> someone who has administered R on a large cluster and written
> >     >> build-system software for it) as substantially different levels of
> >     >> ambiguity. I do acknowledge, as Ben does, that yes a more complex
> >     >> regular expression/splitting algorithm can be written that would
> handle
> >     >> the more general package names. I just don't personally see a
> motivation
> >     >> that justifies changing something this fundamental (even if it is
> both
> >     >> narrow and was initially more or less arbitrarily chosen) about R
> at
> >     >> this late date.
> >     >>
> >     >> I guess at the end of the day, I guess what I'm saying is that
> breaking
> >     >> and changing things is sometimes good, but if we're going to rock
> the
> >     >> boat personally I'd want to do so going after bigger wins than
> this one.
> >     >> Thats just my opinion though.
> >
> >     > Sorry, I wasn't clear.  I agree with you.  I was just saying that
> the
> >     > particular argument based on ugly tarball names isn't the reason.
> >
> >     > Duncan Murdoch
> >
> > Thank you (and Gabe).
> >
> > We have had some R core internal "talk" about Jim Hester's
> > suggestion (of adding underscores to the allow characters in
> > package names).
> > Duncan had already given a good reason why such a change would be
> problematic
> > (the underscore being used as unique separator of package name
> >  and version in source and binary package archives),
> > and with Jim's offer to find and provide patches for all places
> > this is used in the R sources, we've convinced ourselves that
> > there is much more code "out there", notably 'devops' code in
> > scripts, which currently relies on the current package naming
> > rules and which could break, often only rarely and hence
> > possibly unnoticed for too long.
> >
> > Also, we've not seen compelling arguments why the current scheme
> > would be too limited (people mentioned that if you must use a
> > separator, "." was available).
> >
> > Consequence:  We stay with the stability principle and the
> > package naming scheme is _not_ going to be changed for now.
> >
> > Martin Maechler
> > ETH Zurich and R Core Team
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Kevin Wright

	[[alternative HTML version deleted]]


From k@bem|@ @end|ng |rom northe@@tern@edu  Fri Aug 16 17:50:18 2019
From: k@bem|@ @end|ng |rom northe@@tern@edu (Bemis, Kylie)
Date: Fri, 16 Aug 2019 15:50:18 -0000
Subject: [Rd] Any plans for ALTREP lists (VECSXP)?
In-Reply-To: <CAD4oTHGaJFWCLtVRVQ3oG6ws2hj+Cuo1krw0-VBjNCuhKQYThg@mail.gmail.com>
References: <61E11B6B-E70C-4B92-9AC2-A3FA6678D626@northeastern.edu>
 <CAOQ5NyfEaZL+Uy_Ncw=Yy5sRcc4iuR1=3c1vMEB2xPSrHn6cvw@mail.gmail.com>
 <CAD4oTHGaJFWCLtVRVQ3oG6ws2hj+Cuo1krw0-VBjNCuhKQYThg@mail.gmail.com>
Message-ID: <68D37BB5-B8F4-4705-A43B-D990ABD9410F-4877@northeastern.edu>

Thanks for the suggestions, everyone.

Is it not a pressing issue requiring alternatives, since the ?matter_list? object already behaves like a list, and I am just looking for a way to present a native R list (VECSXP) when a regular list is required.

In this case (in my typical use case), the ?matter_list? is homogenous and I use it like a ragged array; however, in general each element could be a different atomic vector type (specifically raw, logical, integer, or double).

Here, as.altrep() is an S4 method for converting my custom ?matter?-class out-of-memory objects into their native R representations using ALTREP.

Seems to work well for the ?matter' vectors, matrices, and arrays, where it just .Call()s my C function for making the corresponding ALTREP object, but the lists were giving me trouble because there I use lapply() to extract and uncompress the ?matter_list? metadata for each list element into a separate S4 ?matter_vec? out-of-memory vector, each of which is then used to create an ALTREP object for the corresponding list element. So it gets costly...

The cost is mostly in re-creating all of the metadata as regular R objects that end up occupying the R_altrep_data1() spot for all of the individual list elements. If I could make an ALTREP list, I could leave the metadata as-is and avoid all of that.

Anyway, not a pressing issue for me either, just something I noticed where having an ALTREP list could be useful, so I was wondering if it was in the plans, which Luke answered.

Thanks,

-Kylie

On Jul 23, 2019, at 8:27 PM, Gabriel Becker <gabembecker at gmail.com<mailto:gabembecker at gmail.com>> wrote:

Hi Kylie,

Is it a list with only numerics in it? (I only see REALSXPs there, but obviously inspect isn't showing all of them). If so, you could load it up into one big vector and then also keep partitioning information around. Bioconductor does this (see ?IRanges::CompressedList ). The potential benefit here being that the underlying large vector could then be a big out-of-memory altrep. How helpful this would be depends somewhat on what you want to do with it, of course, but it is something that comes to mind.

Also, I would expect some overhead but that seems like a lot (without having done super much in the way of benchmarking). What exactly is as.altrep doing?

Best,
~G

On Tue, Jul 23, 2019 at 9:54 AM Michael Lawrence via R-devel <r-devel at r-project.org<mailto:r-devel at r-project.org>> wrote:
Hi Kylie,

As an alternative in the short term, you could consider deriving from
S4Vector's List class, implementing the getListElement() method to
lazily create the objects.

Michael

On Tue, Jul 23, 2019 at 9:09 AM Bemis, Kylie <k.bemis at northeastern.edu<mailto:k.bemis at northeastern.edu>> wrote:
>
> Hello,
>
> I was wondering if there were any plans for ALTREP lists (VECSXP)?
>
> It seems to me that they could be supported in a similar way to how ALTSTRING works, with Elt() and Set_elt() methods, or would there be some problems with that I?m not seeing due to lists not being atomic vectors?
>
> I was taking an approach of converting each list element (of a file-based list data structure) to an ALTREP representation to build up an ?ALTREP list?.
>
> This seems fine for shorter lists with large elements, but I noticed that for longer lists with smaller elements, this could be far more time-consuming than simply reading the entire list into memory and returning a non-ALTREP list:
>
> > x
> <34840 length> matter_list :: out-of-memory list
> (1.1 MB real | 543.3 MB virtual)
>
> > system.time(y <- as.list(x))
>    user  system elapsed
>   1.116   2.175   5.053
>
> > system.time(z <- as.altrep(x))
>    user  system elapsed
>  36.295   4.717  41.216
>
> > .Internal(inspect(y))
> @108255000 19 VECSXP g1c7 [MARK,NAM(7)] (len=34840, tl=0)
>   @7f9044d9fc00 14 REALSXP g1c7 [MARK] (len=1129, tl=0) 404.093,404.096,404.099,404.102,404.105,...
>   @7f9044d25e00 14 REALSXP g1c7 [MARK] (len=890, tl=0) 409.924,409.927,409.931,409.934,409.937,...
>   @7f9044da6000 14 REALSXP g1c7 [MARK] (len=1878, tl=0) 400.3,400.303,400.306,400.309,400.312,...
>   @7f9031a6b000 14 REALSXP g1c7 [MARK] (len=2266, tl=0) 402.179,402.182,402.185,402.188,402.191,...
>   @7f9031a77a00 14 REALSXP g1c7 [MARK] (len=1981, tl=0) 403.021,403.024,403.027,403.03,403.033,...
>   ...
>
> > .Internal(inspect(z))
> @108210000 19 VECSXP g1c7 [MARK,NAM(7)] (len=34840, tl=0)
>   @7f904eea7660 14 REALSXP g1c0 [MARK,NAM(7)] matter vector (mode=4, len=1129, mem=0)
>   @7f9050347498 14 REALSXP g1c0 [MARK,NAM(7)] matter vector (mode=4, len=890, mem=0)
>   @7f904d286b20 14 REALSXP g1c0 [MARK,NAM(7)] matter vector (mode=4, len=1878, mem=0)
>   @7f904fd38820 14 REALSXP g1c0 [MARK,NAM(7)] matter vector (mode=4, len=2266, mem=0)
>   @7f904c75ce90 14 REALSXP g1c0 [MARK,NAM(7)] matter vector (mode=4, len=1981, mem=0)
>   ...
>
> In this situation, it would be much faster and simpler for me to return a theoretical ALTREP list that serves SEXP elements on-demand, similar to how ALTSTRING seems to be implemented.
>
> I don?t know how many other people would get a use out of ALTREP lists, but I certainly would.
>
> Are there any plans for this?
>
> Thanks!
>
> ~~~
> Kylie Ariel Bemis
> Khoury College of Computer Sciences
> Northeastern University
> kuwisdelu.github.io<https://nam05.safelinks.protection.outlook.com/?url=http%3A%2F%2Fkuwisdelu.github.io&data=02%7C01%7Ck.bemis%40northeastern.edu%7C30d98923a37f405b4c9908d70f9b6875%7Ca8eec281aaa34daeac9b9a398b9215e7%7C0%7C0%7C636995032467082904&sdata=QGe%2F4F1D%2B9Sz7LxkP9%2BsAXD2t5JDtLVkko450e5ecI4%3D&reserved=0><https://kuwisdelu.github.io<https://nam05.safelinks.protection.outlook.com/?url=https%3A%2F%2Fkuwisdelu.github.io&data=02%7C01%7Ck.bemis%40northeastern.edu%7C30d98923a37f405b4c9908d70f9b6875%7Ca8eec281aaa34daeac9b9a398b9215e7%7C0%7C0%7C636995032467092912&sdata=PZKJtQ1wh%2FCyJn44DdGBQ7dLLI6eAYt00lK0uO%2BOrzA%3D&reserved=0>>
>
>
>
>
>
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org<mailto:R-devel at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel<https://nam05.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-devel&data=02%7C01%7Ck.bemis%40northeastern.edu%7C30d98923a37f405b4c9908d70f9b6875%7Ca8eec281aaa34daeac9b9a398b9215e7%7C0%7C0%7C636995032467102920&sdata=3CNTeCYlKyul8JPFhVeEFKvKooGPSm16xU8UplfJJsA%3D&reserved=0>



--
Michael Lawrence
Scientist, Bioinformatics and Computational Biology
Genentech, A Member of the Roche Group
Office +1 (650) 225-7760
michafla at gene.com<mailto:michafla at gene.com>

Join Genentech on LinkedIn | Twitter | Facebook | Instagram | YouTube

______________________________________________
R-devel at r-project.org<mailto:R-devel at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel<https://nam05.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-devel&data=02%7C01%7Ck.bemis%40northeastern.edu%7C30d98923a37f405b4c9908d70f9b6875%7Ca8eec281aaa34daeac9b9a398b9215e7%7C0%7C0%7C636995032467102920&sdata=3CNTeCYlKyul8JPFhVeEFKvKooGPSm16xU8UplfJJsA%3D&reserved=0>


	[[alternative HTML version deleted]]


From k@bem|@ @end|ng |rom northe@@tern@edu  Fri Aug 16 17:50:20 2019
From: k@bem|@ @end|ng |rom northe@@tern@edu (Bemis, Kylie)
Date: Fri, 16 Aug 2019 15:50:20 -0000
Subject: [Rd] ALTREP wrappers and factors
In-Reply-To: <CAD4oTHHVLUZyVd6V8GWx2onN3xD8o9g3ji8tZ6LEu2OFU8jC_Q@mail.gmail.com>
References: <57621E9B-ADF6-4ED8-9C51-AFF01C2EA821@northeastern.edu>
 <CAGiFhPOWCorUaaGd4Wca4+5a3k8dzp3pAVffK8WmFkXy7rdmGg@mail.gmail.com>
 <CAD4oTHHVLUZyVd6V8GWx2onN3xD8o9g3ji8tZ6LEu2OFU8jC_Q@mail.gmail.com>
Message-ID: <67F5FF77-BF89-4DB4-8BDC-132E432E7675-1350@northeastern.edu>

Using R_tryWrap() at the C-level works perfectly and does what I need. Thanks, Gabe!

Yes, my reference count is maxed (I assume) because I am using MARK_NOT_MUTABLE().

Which makes me think I may want to return a wrapped matter/ALTREP object by default, so the user can set the names() and dim(), etc., without triggering a potentially-costly duplication. The data payload is intended to be immutable, but the attributes aren?t.

Decoupling the attributes and other metadata from the data payload seems like a good thing to have generally.

Are there any potential drawbacks of using R_tryWrap() that I should know about, besides an additional method dispatch happening somewhere?

Thanks again!

~~~
Kylie Ariel Bemis
Khoury College of Computer Sciences
Northeastern University
kuwisdelu.github.io<https://kuwisdelu.github.io>










On Jul 19, 2019, at 4:00 AM, Gabriel Becker <gabembecker at gmail.com<mailto:gabembecker at gmail.com>> wrote:

Hi Jiefei and Kylie,

Great to see people engaging with the ALTREP framework and identifying places we may need more tooling. Comments inline.

On Thu, Jul 18, 2019 at 12:22 PM King Jiefei <szwjf08 at gmail.com<mailto:szwjf08 at gmail.com>> wrote:

If that is the case and you are 100% sure the reference number should be 1
for your variable *y*, my solution is to call *SET_NAMED *in C++ to reset
the reference number. Note that you need to unbind your local variable
before you reset the number. To return an unbound SEXP,  the C++ function
should be placed at the end of your *matter:::as.altrep *function. I don't
know if there is any simpler way to do that and I'll be happy to see any
opinion.

So as far as I know, manually setting the NAMED value on any SEXP the garbage collector is aware of is a direct violation of C-API contract and not something that package code should ever be doing.

Its not at all clear to me that you can ever be 100% sure that the reference number should be 1 when it is not currently one for an R object that exists at the R-level (as opposed to only in pure C code). Sure, maybe the object is created within the body of your R function instead of being passed in, but what if someone is debugging your function and assigns the value to the global environment using <<-  for later inspection; now  you have an invalidly low NAMED value, ie you have a segfault coming. I know of no way for you to prevent this or even know it has happened.



On Thu, Jul 18, 2019 at 3:28 AM Bemis, Kylie <k.bemis at northeastern.edu<mailto:k.bemis at northeastern.edu>>
wrote:

> Hello,
>
> I?m experimenting with ALTREP and was wondering if there is a preferred
> way to create an ALTREP wrapper vector without using
> .Internal(wrap_meta(?)), which R CMD check doesn?t like since it uses an
> .Internal() function.

So there is the .doSortWrap  (and its currently inexplicably identical clone .doWrap) function in base, which is an R level function that calls down to .Internal(wrap_meta(...)), which you can use, but it doesn't look general enough for what  I think you need (it was written for things that have just been sorted, thus the name). Specifically, its not able to indicate that things are of unknown sortedness as currently written.  If matter vectors are guaranteed to be sorted for some reason, though, you can use this. I'll talk to Luke about whether we want to generalize this, it would be easy to have this support the full space of metadata for wrappers and be a general purpose wrapper-maker, but that isn't what it is right now.

At the C-level, it looks like we do make R_tryWrap available (it appears in Rinternals.h, and not within a USE_RINTERNALS section),so you can call that from your own C(++) code. This creates a wrapper that has no metadata on it (or rather it has metadata but  the metadata indicates that no special info is known about the vector).

>
> I was trying to create a factor that used an ALTREP integer, but
> attempting to set the class and levels attributes always ended up
> duplicating and materializing the integer vector. Using the wrapper avoided
> this issue.
>
> Here is my initial ALTREP integer vector:
>
> > fc0 <- factor(c("a", "a", "b"))
> >
> > y <- matter::as.matter(as.integer(fc0))
> > y <- matter:::as.altrep(y)
> >
> > .Internal(inspect(y))
> @7fb0ce78c0f0 13 INTSXP g0c0 [NAM(7)] matter vector (mode=3, len=3, mem=0)
>
> Here is what I get without a wrapper:
>
> > fc1 <- structure(y, class="factor", levels=levels(x))
> > .Internal(inspect(fc1))
> @7fb0cae66408 13 INTSXP g0c2 [OBJ,NAM(2),ATT] (len=3, tl=0) 1,1,2
> ATTRIB:
>   @7fb0ce771868 02 LISTSXP g0c0 []
>     TAG: @7fb0c80043d0 01 SYMSXP g1c0 [MARK,LCK,gp=0x4000] "class" (has
> value)
>     @7fb0c9fcbe90 16 STRSXP g0c1 [NAM(7)] (len=1, tl=0)
>       @7fb0c80841a0 09 CHARSXP g1c1 [MARK,gp=0x61] [ASCII] [cached]
> "factor"
>     TAG: @7fb0c8004050 01 SYMSXP g1c0 [MARK,NAM(7),LCK,gp=0x4000] "levels"
> (has value)
>     @7fb0d1dd58c8 16 STRSXP g0c2 [MARK,NAM(7)] (len=2, tl=0)
>       @7fb0c81bf4c0 09 CHARSXP g1c1 [MARK,gp=0x61] [ASCII] [cached] "a"
>       @7fb0c90ba728 09 CHARSXP g1c1 [MARK,gp=0x61] [ASCII] [cached] "b"
>
> Here is what I get with a wrapper:
>
> > fc2 <- structure(.Internal(wrap_meta(y, 0, 0)), class="factor",
> levels=levels(x))
> > .Internal(inspect(fc2))
> @7fb0ce764630 13 INTSXP g0c0 [OBJ,NAM(2),ATT]  wrapper [srt=0,no_na=0]
>   @7fb0ce78c0f0 13 INTSXP g0c0 [NAM(7)] matter vector (mode=3, len=3,
> mem=0)
> ATTRIB:
>   @7fb0ce764668 02 LISTSXP g0c0 []
>     TAG: @7fb0c80043d0 01 SYMSXP g1c0 [MARK,LCK,gp=0x4000] "class" (has
> value)
>     @7fb0c9fcb010 16 STRSXP g0c1 [NAM(7)] (len=1, tl=0)
>       @7fb0c80841a0 09 CHARSXP g1c1 [MARK,gp=0x61] [ASCII] [cached]
> "factor"
>     TAG: @7fb0c8004050 01 SYMSXP g1c0 [MARK,NAM(7),LCK,gp=0x4000] "levels"
> (has value)
>     @7fb0d1dd58c8 16 STRSXP g0c2 [MARK,NAM(7)] (len=2, tl=0)
>       @7fb0c81bf4c0 09 CHARSXP g1c1 [MARK,gp=0x61] [ASCII] [cached] "a"
>       @7fb0c90ba728 09 CHARSXP g1c1 [MARK,gp=0x61] [ASCII] [cached] "b"
>
> Is there a way to do this that doesn?t rely on .Internal() and won?t
> produce R CMD check warnings?
>
> ~~~
> Kylie Ariel Bemis
> Khoury College of Computer Sciences
> Northeastern University
> kuwisdelu.github.io<https://nam05.safelinks.protection.outlook.com/?url=http%3A%2F%2Fkuwisdelu.github.io&data=02%7C01%7Ck.bemis%40northeastern.edu%7C2941b0ace204410a4be508d70becd82e%7Ca8eec281aaa34daeac9b9a398b9215e7%7C0%7C0%7C636990984192834656&sdata=y%2F9QS%2B%2B5BV16kYaHD1U4luNjIv%2F0q4KIhupAH%2FeJIe4%3D&reserved=0><https://kuwisdelu.github.io<https://nam05.safelinks.protection.outlook.com/?url=https%3A%2F%2Fkuwisdelu.github.io&data=02%7C01%7Ck.bemis%40northeastern.edu%7C2941b0ace204410a4be508d70becd82e%7Ca8eec281aaa34daeac9b9a398b9215e7%7C0%7C0%7C636990984192834656&sdata=JnYrgz3NrgaYbkGSYwnDvIUhzf7DTsqph%2FKy15t%2BLZ4%3D&reserved=0>>
>
>
>
>
>
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org<mailto:R-devel at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel<https://nam05.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-devel&data=02%7C01%7Ck.bemis%40northeastern.edu%7C2941b0ace204410a4be508d70becd82e%7Ca8eec281aaa34daeac9b9a398b9215e7%7C0%7C0%7C636990984192844664&sdata=u5KvounmbXv%2ByahC7JLDzR4GMBPmds7dPcwx%2F01WLt8%3D&reserved=0>
>

        [[alternative HTML version deleted]]

______________________________________________
R-devel at r-project.org<mailto:R-devel at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel<https://nam05.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-devel&data=02%7C01%7Ck.bemis%40northeastern.edu%7C2941b0ace204410a4be508d70becd82e%7Ca8eec281aaa34daeac9b9a398b9215e7%7C0%7C0%7C636990984192854672&sdata=WpQxQv%2F4fcX6KbUKoACYHx8vcPsNyVZh%2BWL0dejrXeY%3D&reserved=0>


	[[alternative HTML version deleted]]


From hugh@p@r@on@ge @end|ng |rom gm@||@com  Fri Aug 16 18:36:39 2019
From: hugh@p@r@on@ge @end|ng |rom gm@||@com (Hugh Parsonage)
Date: Sat, 17 Aug 2019 02:36:39 +1000
Subject: [Rd] Documenting else's greed
Message-ID: <CAJmOi+O-3gUjdEmFJQhTfNxwUzQ86snSti_6yt26zJRDjgX7Ug@mail.gmail.com>

I was initially pretty shocked by the result in this question:
https://stackoverflow.com/questions/57527434/when-do-i-need-parentheses-around-an-if-statement-to-control-the-sequence-of-a-f

Briefly, the following returns 0, not 3 as might be expected:

if (TRUE) {
    0
} else {
    2
} + 3

At first I thought it the question was simply one of syntax
precedence, but I believe the result is too surprising to not warrant
note in the documentation of Control. I believe the documentation
should highlight that the `alt.expr` is demarcated by a semicolon or
newline and the end of a *statement*, not a closing brace per se.

Perhaps in the paragraph starting 'Note that it is a common mistake to
forget to put braces...' it should end with. "Note too that it is the
end of a *statement*, not a closing brace per se, that determines
where `alt.expr` ends. Thus if (cond) {0} else {2} + 2 means if (cond)
{0} else {2 + 2} not {if (cond) {0} else {2}} + 2."


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Aug 16 22:31:15 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 16 Aug 2019 16:31:15 -0400
Subject: [Rd] Documenting else's greed
In-Reply-To: <CAJmOi+O-3gUjdEmFJQhTfNxwUzQ86snSti_6yt26zJRDjgX7Ug@mail.gmail.com>
References: <CAJmOi+O-3gUjdEmFJQhTfNxwUzQ86snSti_6yt26zJRDjgX7Ug@mail.gmail.com>
Message-ID: <d0ead42a-24da-8bb6-b924-3f799efa04ac@gmail.com>

On 16/08/2019 12:36 p.m., Hugh Parsonage wrote:
> I was initially pretty shocked by the result in this question:
> https://stackoverflow.com/questions/57527434/when-do-i-need-parentheses-around-an-if-statement-to-control-the-sequence-of-a-f
> 
> Briefly, the following returns 0, not 3 as might be expected:
> 
> if (TRUE) {
>      0
> } else {
>      2
> } + 3
> 
> At first I thought it the question was simply one of syntax
> precedence, but I believe the result is too surprising to not warrant
> note in the documentation of Control. I believe the documentation
> should highlight that the `alt.expr` is demarcated by a semicolon or
> newline and the end of a *statement*, not a closing brace per se.
> 
> Perhaps in the paragraph starting 'Note that it is a common mistake to
> forget to put braces...' it should end with. "Note too that it is the
> end of a *statement*, not a closing brace per se, that determines
> where `alt.expr` ends. Thus if (cond) {0} else {2} + 2 means if (cond)
> {0} else {2 + 2} not {if (cond) {0} else {2}} + 2."



I agree this is surprising, and should perhaps be pointed out in the 
docs, but I don't think your suggestion is quite right.  { 2 } + 3 is a 
legal expression.  It doesn't have to be the end of a statement that 
limits the alt.expr, e.g. this could be one big statement:


  { if (TRUE) {
       0
     } else {
       2
     } + 3 }

What ends alt.expr is a token that isn't collected as part of alt.expr, 
not just a semicolon (which separates statements) or a newline.  I don't 
know how many of those there are, but the list would include at least
semicolon, newline, }, ), ], and maybe others.

Duncan Murdoch


From cyc||cgroup-z1 @end|ng |rom y@hoo@com  Sat Aug 17 00:16:26 2019
From: cyc||cgroup-z1 @end|ng |rom y@hoo@com (Cyclic Group Z_1)
Date: Fri, 16 Aug 2019 22:16:26 +0000 (UTC)
Subject: [Rd] Feature request: non-dropping regmatches/strextract
In-Reply-To: <CAF8bMcab68FXfx56vdOm=6mu-VH4bBwQuvdW_5pNC6etB1WASQ@mail.gmail.com>
References: <2012653205.221487.1565848601638.ref@mail.yahoo.com>
 <2012653205.221487.1565848601638@mail.yahoo.com>
 <CAF8bMcaoxRZvQ0hJd_HygP2bOi-816UXybZEJDz3OWR6r56ZRA@mail.gmail.com>
 <261022177.555187.1565893861815@mail.yahoo.com>
 <CAF8bMcZAuphcTQyLMw5+NbD_SJEmeSzihQ7AcjYLvLmGD_S-ww@mail.gmail.com>
 <CAF8bMcab68FXfx56vdOm=6mu-VH4bBwQuvdW_5pNC6etB1WASQ@mail.gmail.com>
Message-ID: <1383033528.1103803.1565993786333@mail.yahoo.com>

Using strcapture seems like a great workaround for use cases of this kind, at least in base R. I agree as well that filling with NA for regmatches(..., gregexpr(...)) makes less sense, given the outputs are lists and thus are retained in the list.??Also, I suppose in the meantime the stringr package can be used when non-dropping vector outputs are desired.

However, I do think that non-dropping regex string extraction/matching in vector outputs from regmatches(..., regexpr(...)) or strextract would be a great (optional) design feature to have in base R for sake of consistency with the rest of the language (missing values, denoted by NA, are generally not dropped from vectors elsewhere and seem to agree conceptually with empty matches) and would help R to reach greater feature parity with MATLAB and Pandas in this respect (granted, Pandas is not technically a language on its own).

Although I have written personal wrappers and used stringr to accomplish the non-dropping behavior in the past, I have nevertheless found the behavior of base R string operations mildly astonishing (in the sense of POLA) and think others may have as well. As the stringr documentation puts it, "they?lag behind the string operations in other programming languages, so that some things that are easy to do in languages like Ruby or Python are rather hard to do in R." Since consistent, robust string operations are often a standard base feature of other data science and scientific programming languages, I think this minor change would be a great improvement to the language and hopefully help promote adoption of R, especially given the surge in text-based data analysis in recent years.

Alternatively, although I generally don't use the Tidyverse packages very often, stringr seems like a great candidate for inclusion in base or recommended R if the R Core team and the package developer see it fitting (just a suggestion and probably a long shot).?

However, I will try not to belabor this point further.?In any case, thank you!

Best,CG
CG
	[[alternative HTML version deleted]]


From georg|@bo@hn@kov @end|ng |rom m@nche@ter@@c@uk  Sun Aug 18 17:34:22 2019
From: georg|@bo@hn@kov @end|ng |rom m@nche@ter@@c@uk (Georgi Boshnakov)
Date: Sun, 18 Aug 2019 15:34:22 +0000
Subject: [Rd] Documenting else's greed
Message-ID: <438D2EC9EAFE5946B2D5864670EA468E01CC775EA6@MBXP01.ds.man.ac.uk>

Indeed, an example in the documentation about this feature would be helpful, may be the one Hugh used. If an explanation is deemed appropriate, I would suggest including something along the lines of the following
(after the second paragraph of the Details section for if/while/etc.).

===============

In these constructs the opening braces, if any, are part of the expression to be evaluated, not syntax delimiters. 
In particular, the expression does not necessarily end with the closing brace. For example, '{2} + 3' and '2 + 3' are equivalent expressions, so the first command below gives 0, not 3.

> if(TRUE) 0 else {2} + 3
[1] 0
> if(TRUE) 0 else 2 + 3
[1] 0
================

In practice, this confusion appears mainly in the 'else' part of 'if' constructs. But it is not limited there. For example, this defines a function with body x^2 + 1, for the same reasons, although one might expect an error. 

> f <- function(x){x^2} + 1
> f(2)
[1] 5
> as.character(body(f))
[1] "+"             "{\n    x^2\n}" "1"            
> 

Georgi Boshnakov 

------------------------------

Message: 5
Date: Sat, 17 Aug 2019 02:36:39 +1000
From: Hugh Parsonage <hugh.parsonage at gmail.com>
To: R-devel <r-devel at r-project.org>
Subject: [Rd] Documenting else's greed
Message-ID:
        <CAJmOi+O-3gUjdEmFJQhTfNxwUzQ86snSti_6yt26zJRDjgX7Ug at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

I was initially pretty shocked by the result in this question:
https://stackoverflow.com/questions/57527434/when-do-i-need-parentheses-around-an-if-statement-to-control-the-sequence-of-a-f

Briefly, the following returns 0, not 3 as might be expected:

if (TRUE) {
    0
} else {
    2
} + 3> f
function(x){x^2} + 1
> body(f)
{
    x^2
} + 1
> f(2)
[1] 5

At first I thought it the question was simply one of syntax
precedence, but I believe the result is too surprising to not warrant
note in the documentation of Control. I believe the documentation
should highlight that the `alt.expr` is demarcated by a semicolon or
newline and the end of a *statement*, not a closing brace per se.

Perhaps in the paragraph starting 'Note that it is a common mistake to
forget to put braces...' it should end with. "Note too that it is the
end of a *statement*, not a closing brace per se, that determines
where `alt.expr` ends. Thus if (cond) {0} else {2} + 2 means if (cond)
{0} else {2 + 2} not {if (cond) {0} else {2}} + 2."




------------------------------

Message: 6
Date: Fri, 16 Aug 2019 16:31:15 -0400
From: Duncan Murdoch <murdoch.duncan at gmail.com>
To: Hugh Parsonage <hugh.parsonage at gmail.com>, R-devel
        <r-devel at r-project.org>
Subject: Re: [Rd] Documenting else's greed
Message-ID: <d0ead42a-24da-8bb6-b924-3f799efa04ac at gmail.com>
Content-Type: text/plain; charset="utf-8"; Format="flowed"

On 16/08/2019 12:36 p.m., Hugh Parsonage wrote:
> I was initially pretty shocked by the result in this question:
> https://stackoverflow.com/questions/57527434/when-do-i-need-parentheses-around-an-if-statement-to-control-the-sequence-of-a-f
>
> Briefly, the following returns 0, not 3 as might be expected:
>
> if (TRUE) {
>      0
> } else {
>      2
> } + 3
>
> At first I thought it the question was simply one of syntax
> precedence, but I believe the result is too surprising to not warrant
> note in the documentation of Control. I believe the documentation
> should highlight that the `alt.expr` is demarcated by a semicolon or
> newline and the end of a *statement*, not a closing brace per se.
>
> Perhaps in the paragraph starting 'Note that it is a common mistake to
> forget to put braces...' it should end with. "Note too that it is the
> end of a *statement*, not a closing brace per se, that determines
> where `alt.expr` ends. Thus if (cond) {0} else {2} + 2 means if (cond)
> {0} else {2 + 2} not {if (cond) {0} else {2}} + 2."



I agree this is surprising, and should perhaps be pointed out in the
docs, but I don't think your suggestion is quite right.  { 2 } + 3 is a
legal expression.  It doesn't have to be the end of a statement that
limits the alt.expr, e.g. this could be one big statement:


  { if (TRUE) {
       0
     } else {
       2
     } + 3 }

What ends alt.expr is a token that isn't collected as part of alt.expr,
not just a semicolon (which separates statements) or a newline.  I don't
know how many of those there are, but the list would include at least
semicolon, newline, }, ), ], and maybe others.

Duncan Murdoch



From kr|m|r+m| @end|ng |rom m@||box@org  Mon Aug 19 16:19:31 2019
From: kr|m|r+m| @end|ng |rom m@||box@org (=?UTF-8?Q?Kirill_M=c3=bcller?=)
Date: Mon, 19 Aug 2019 16:19:31 +0200
Subject: [Rd] Check length of logical vector also for operands of || and &&?
Message-ID: <da321aed-5d85-a206-e94f-92852da46cf9@mailbox.org>

Hi everyone


The following behavior (in R 3.6.1 and R-devel r77040) caught me by 
surprise today:

truthy <- c(TRUE, FALSE)
falsy <- c(FALSE, TRUE, FALSE)

if (truthy) "check"
#> Warning in if (truthy) "check": the condition has length > 1 and only the
#> first element will be used
#> [1] "check"
if (falsy) "check"
#> Warning in if (falsy) "check": the condition has length > 1 and only the
#> first element will be used
if (FALSE || truthy) "check"
#> [1] "check"
if (FALSE || falsy) "check"
if (truthy || FALSE) "check"
#> [1] "check"
if (falsy || FALSE) "check"

The || operator gobbles the warning about a length > 1 vector. I wonder 
if the existing checks for length 1 can be extended to the operands of 
the || and && operators. Thanks (and apologies if this has been raised 
before).


Best regards

Kirill


From henr|k@bengt@@on @end|ng |rom gm@||@com  Mon Aug 19 16:35:09 2019
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Mon, 19 Aug 2019 16:35:09 +0200
Subject: [Rd] 
 Check length of logical vector also for operands of || and &&?
In-Reply-To: <da321aed-5d85-a206-e94f-92852da46cf9@mailbox.org>
References: <da321aed-5d85-a206-e94f-92852da46cf9@mailbox.org>
Message-ID: <CAFDcVCQB9H4WWrRfZ6TG=-eX1at7CpCkXEkVMPTeu_An4+kPpQ@mail.gmail.com>

NEWS for R 3.6.0:

* Experimentally, setting environment variable
_R_CHECK_LENGTH_1_LOGIC2_ will lead to warnings (or errors if the
variable is set to a ?true? value) when && or || encounter and use
arguments of length more than one.

> Sys.setenv("_R_CHECK_LENGTH_1_LOGIC2_" = "TRUE")
> if (FALSE || truthy) "check"
Error in FALSE || truthy :
  'length(x) = 2 > 1' in coercion to 'logical(1)'

Some more info and breadcrumbs at
https://github.com/HenrikBengtsson/Wishlist-for-R/issues/48

/Henrik

On Mon, Aug 19, 2019 at 4:19 PM Kirill M?ller <krlmlr+ml at mailbox.org> wrote:
>
> Hi everyone
>
>
> The following behavior (in R 3.6.1 and R-devel r77040) caught me by
> surprise today:
>
> truthy <- c(TRUE, FALSE)
> falsy <- c(FALSE, TRUE, FALSE)
>
> if (truthy) "check"
> #> Warning in if (truthy) "check": the condition has length > 1 and only the
> #> first element will be used
> #> [1] "check"
> if (falsy) "check"
> #> Warning in if (falsy) "check": the condition has length > 1 and only the
> #> first element will be used
> if (FALSE || truthy) "check"
> #> [1] "check"
> if (FALSE || falsy) "check"
> if (truthy || FALSE) "check"
> #> [1] "check"
> if (falsy || FALSE) "check"
>
> The || operator gobbles the warning about a length > 1 vector. I wonder
> if the existing checks for length 1 can be extended to the operands of
> the || and && operators. Thanks (and apologies if this has been raised
> before).
>
>
> Best regards
>
> Kirill
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Aug 19 16:43:25 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 19 Aug 2019 10:43:25 -0400
Subject: [Rd] 
 Check length of logical vector also for operands of || and &&?
In-Reply-To: <da321aed-5d85-a206-e94f-92852da46cf9@mailbox.org>
References: <da321aed-5d85-a206-e94f-92852da46cf9@mailbox.org>
Message-ID: <025592ac-c6b2-84e0-c121-7905e9e22b1a@gmail.com>

On 19/08/2019 10:19 a.m., Kirill M?ller wrote:
> Hi everyone
> 
> 
> The following behavior (in R 3.6.1 and R-devel r77040) caught me by
> surprise today:
> 
> truthy <- c(TRUE, FALSE)
> falsy <- c(FALSE, TRUE, FALSE)
> 
> if (truthy) "check"
> #> Warning in if (truthy) "check": the condition has length > 1 and only the
> #> first element will be used
> #> [1] "check"
> if (falsy) "check"
> #> Warning in if (falsy) "check": the condition has length > 1 and only the
> #> first element will be used
> if (FALSE || truthy) "check"
> #> [1] "check"
> if (FALSE || falsy) "check"
> if (truthy || FALSE) "check"
> #> [1] "check"
> if (falsy || FALSE) "check"
> 
> The || operator gobbles the warning about a length > 1 vector. I wonder
> if the existing checks for length 1 can be extended to the operands of
> the || and && operators. Thanks (and apologies if this has been raised
> before).
> 

This seems to be an August topic.  It was discussed last year in a  long 
thread starting with this message:

https://stat.ethz.ch/pipermail/r-devel/2018-August/076678.html

I think there was general agreement that it would be a good idea to add 
some warnings.  News for R 3.6.0 includes this:

"Experimentally, setting environment variable _R_CHECK_LENGTH_1_LOGIC2_ 
will lead to warnings (or errors if the variable is set to a ?true? 
value) when && or || encounter and use arguments of length more than one."

You get a warning if you set that variable to "warn", you get an error 
if you set it to "true".

Duncan Murdoch


Duncan Murdoch


From hp@ge@ @end|ng |rom |redhutch@org  Tue Aug 20 01:23:25 2019
From: hp@ge@ @end|ng |rom |redhutch@org (Pages, Herve)
Date: Mon, 19 Aug 2019 23:23:25 +0000
Subject: [Rd] class() bug when used within a validity method
Message-ID: <8415ec8f-bbfe-3be2-72f0-4c2472f7575f@fredhutch.org>

Hi,

This is a long-standing bug where 'class(object)' does not
return the actual class of 'object' when used inside a validity
method. Instead it seems to return the class for which the validity
method is defined. For example:

   setClass("A", slots=c(stuff="ANY"))

   setValidity("A", function(object) {
     cat("validating an object of class:", class(object), "\n")
     TRUE
   })

Then:

   a <- new("A")

   validObject(a)
   # validating an object of class: A
   # [1] TRUE

which is OK. But trying to validate an object that belongs to a
subclass of A leads to a big surprise:

   setClass("B", contains="A")

   b <- new("B")

   class(b)
   # [1] "B"

   validObject(b)
   # validating an object of class: A
   # [1] TRUE

The class of object 'b' as seen by class() is wrong.

Note that this doesn't happen if A is defined as a VIRTUAL class.

Cheers,
H.

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319

From hp@ge@ @end|ng |rom |redhutch@org  Tue Aug 20 01:31:13 2019
From: hp@ge@ @end|ng |rom |redhutch@org (Pages, Herve)
Date: Mon, 19 Aug 2019 23:31:13 +0000
Subject: [Rd] class() bug when used within a validity method
In-Reply-To: <8415ec8f-bbfe-3be2-72f0-4c2472f7575f@fredhutch.org>
References: <8415ec8f-bbfe-3be2-72f0-4c2472f7575f@fredhutch.org>
Message-ID: <36c1de3f-601e-ef1f-6774-b6d1493771e0@fredhutch.org>

On 8/19/19 16:23, Pages, Herve wrote:
...
> Note that this doesn't happen if A is defined as a VIRTUAL class.

To be precise, when A is a VIRTUAL class, it requires at least
one additional level of class extension to break class():

   setClass("A", contains="VIRTUAL", slots=c(stuff="ANY"))
   setValidity("A", function(object) {
     cat("validating an object of class:", class(object), "\n")
     TRUE
   })
   setClass("B", contains="A")
   setClass("C", contains="B")

Then:

   c <- new("C")
   validObject(c)
   # validating an object of class: B
   # [1] TRUE

H.


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319

From t@@d@m| @end|ng |rom @tudent|@un|bg@|t  Wed Aug 21 01:48:20 2019
From: t@@d@m| @end|ng |rom @tudent|@un|bg@|t (TOMMASO ADAMI)
Date: Wed, 21 Aug 2019 01:48:20 +0200
Subject: [Rd] Fwd: Bug Reporting
In-Reply-To: <CAP=5aR+K9naCHtdmYOhR1AsAL9iL2bcCzHWDo-NPgH5mrh6MpQ@mail.gmail.com>
References: <CAP=5aR+fHcMvqrErOw6miysJ6SMXYwP=DHzsX=yN94kFU0Q7oA@mail.gmail.com>
 <CAP=5aR+K9naCHtdmYOhR1AsAL9iL2bcCzHWDo-NPgH5mrh6MpQ@mail.gmail.com>
Message-ID: <CAP=5aRKvy_KFy4x9fYxE8txuvnogfcB82owjLWvJ_OSfCXdLgQ@mail.gmail.com>

Hello,

  I would like to report this date/time bug that threatened me for a long
time,
   as I need correct date calculation in my computations.

If I add 1 day to the light saving switching day, it will incorrectly
subtract 1 hour from the date and missalign all my calculations.

You can see it runing (I am testing it with Rome, Italy (+1) TimeZone)

print(paste0("Horrible R Bug is present?
",strptime("20151025",format='%Y%m%d')+as.difftime(1, unit="days")));

As you can see the output says 11pm and not 12pm !

I do not know if it is a requested feature, but for me is unpleasant and
unexpected behaviour.

Thank you very much!

	[[alternative HTML version deleted]]


From tom@@@k@||ber@ @end|ng |rom gm@||@com  Wed Aug 21 09:47:50 2019
From: tom@@@k@||ber@ @end|ng |rom gm@||@com (Tomas Kalibera)
Date: Wed, 21 Aug 2019 09:47:50 +0200
Subject: [Rd] 
 What is the best way to determine the version of an `.rds`?
In-Reply-To: <CANe9BHFzp2oDnb===CyJcd_N0+paD9LQ9jZMUPg2kbci=UWs8g-3458@mail.gmail.com>
References: <CANe9BHFzp2oDnb===CyJcd_N0+paD9LQ9jZMUPg2kbci=UWs8g-3458@mail.gmail.com>
Message-ID: <62643da2-d853-45ad-9be7-c8560bab9518@gmail.com>

Now infoRDS() reports all the meta-data from 
.Internal(serializeInfoFromConn()).

Best
Tomas

On 7/15/19 12:01 PM, Jennifer Bryan wrote:
> Hi,
>
> I am writing a test that consults the serialization version of an `.rds`
> file.
>
> An attractive way to get this is:
>
> tools:::get_serialization_version() # reports just version
>
> which calls
>
> .Internal(serializeInfoFromConn() # reports much more
>
> but neither is truly exported for public use.
>
> Is there an official, exported way to get the serialization version? It is
> possible to get this information with R code yourself, but it doesn't feel
> very elegant.
>
> If not, could we have this? It's pretty easy these days to acquire a
> version 3 file, without real intent, which risks making the package require
> R >= 3.5.
>
> Thanks,
> Jenny
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From th|erry@onke||nx @end|ng |rom |nbo@be  Wed Aug 21 09:53:54 2019
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Wed, 21 Aug 2019 09:53:54 +0200
Subject: [Rd] Fwd: Bug Reporting
In-Reply-To: <CAP=5aRKvy_KFy4x9fYxE8txuvnogfcB82owjLWvJ_OSfCXdLgQ@mail.gmail.com>
References: <CAP=5aR+fHcMvqrErOw6miysJ6SMXYwP=DHzsX=yN94kFU0Q7oA@mail.gmail.com>
 <CAP=5aR+K9naCHtdmYOhR1AsAL9iL2bcCzHWDo-NPgH5mrh6MpQ@mail.gmail.com>
 <CAP=5aRKvy_KFy4x9fYxE8txuvnogfcB82owjLWvJ_OSfCXdLgQ@mail.gmail.com>
Message-ID: <CAJuCY5xAxcPeb1HJY5-QCo4ZT-1fUrkx8eXnqwR1iap7TeOVXg@mail.gmail.com>

Dear Tommaso,

This is not a bug. You asked for a difference of 1 day = 24 hours = 1440
minutes = 86400 seconds. And that is the difference you get.

> start <- as.POSIXct(strptime("20151025",format='%Y%m%d'))
> end <- start + as.difftime(1, unit="days")
> end - start
Time difference of 1 days
> as.integer(end) - as.integer(start)
[1] 86400

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op wo 21 aug. 2019 om 08:25 schreef TOMMASO ADAMI <t.adami at studenti.unibg.it
>:

> Hello,
>
>   I would like to report this date/time bug that threatened me for a long
> time,
>    as I need correct date calculation in my computations.
>
> If I add 1 day to the light saving switching day, it will incorrectly
> subtract 1 hour from the date and missalign all my calculations.
>
> You can see it runing (I am testing it with Rome, Italy (+1) TimeZone)
>
> print(paste0("Horrible R Bug is present?
> ",strptime("20151025",format='%Y%m%d')+as.difftime(1, unit="days")));
>
> As you can see the output says 11pm and not 12pm !
>
> I do not know if it is a requested feature, but for me is unpleasant and
> unexpected behaviour.
>
> Thank you very much!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From |uc@r @end|ng |rom |edor@project@org  Wed Aug 21 13:21:34 2019
From: |uc@r @end|ng |rom |edor@project@org (=?UTF-8?Q?I=C3=B1aki_Ucar?=)
Date: Wed, 21 Aug 2019 13:21:34 +0200
Subject: [Rd] Is R-devel broken?
Message-ID: <CALEXWq34140ojxdRPq2skyJsG9xNSdHrAT62HfhKhJu2u-zSFw@mail.gmail.com>

Hi,

I'm building r-devel using [1], and I see:

mv: './grid/vignettes/grid.Rnw-lattice' and
'./grid/vignettes/grid.Rnw' are the same file
make[1]: *** [Makefile:121: vignettes-no-lattice] Error 1

Regards,
I?aki

[1] https://hub.docker.com/r/rocker/r-devel/dockerfile


From |uc@r @end|ng |rom |edor@project@org  Wed Aug 21 13:43:17 2019
From: |uc@r @end|ng |rom |edor@project@org (=?UTF-8?Q?I=C3=B1aki_Ucar?=)
Date: Wed, 21 Aug 2019 13:43:17 +0200
Subject: [Rd] Is R-devel broken?
In-Reply-To: <CALEXWq34140ojxdRPq2skyJsG9xNSdHrAT62HfhKhJu2u-zSFw@mail.gmail.com>
References: <CALEXWq34140ojxdRPq2skyJsG9xNSdHrAT62HfhKhJu2u-zSFw@mail.gmail.com>
Message-ID: <CALEXWq3yc5oBY-UStgBrSRsFHuxJU7BVea4=+uBYyEcBznw6bQ@mail.gmail.com>

Don't mind. It seems to be a caching issue in the underlying
filesystem. Not sure how to solve it though.

I?aki

On Wed, 21 Aug 2019 at 13:21, I?aki Ucar <iucar at fedoraproject.org> wrote:
>
> Hi,
>
> I'm building r-devel using [1], and I see:
>
> mv: './grid/vignettes/grid.Rnw-lattice' and
> './grid/vignettes/grid.Rnw' are the same file
> make[1]: *** [Makefile:121: vignettes-no-lattice] Error 1
>
> Regards,
> I?aki
>
> [1] https://hub.docker.com/r/rocker/r-devel/dockerfile



-- 
I?aki ?car


From m|ch@e|ch|r|co4 @end|ng |rom gm@||@com  Wed Aug 21 14:40:10 2019
From: m|ch@e|ch|r|co4 @end|ng |rom gm@||@com (Michael Chirico)
Date: Wed, 21 Aug 2019 20:40:10 +0800
Subject: [Rd] --disable-long-double or --enable-long-double=no?
Message-ID: <CAPRVBcy3mCFSef_X37aA7UG6T9+CV5DRVSUjdkkyLYv8u80qMQ@mail.gmail.com>

There's a bit of confusion about how to disable long double support in an R
build.

I see --disable-long-double scattered about, e.g.

   - R-exts:
   https://cran.r-project.org/doc/manuals/r-release/R-exts.html#Writing-portable-packages
   - R-admin:
   https://cran.r-project.org/doc/manuals/r-release/R-admin.html#Solaris
   - CRAN noLD check description:
   https://www.stats.ox.ac.uk/pub/bdr/noLD/README.txt
   - ?capabilities:
   https://stat.ethz.ch/R-manual/R-devel/library/base/html/capabilities.html

However, it's *missing* from ./config (cd r-source && grep
"disable-long-double" configure). Instead there appears to be some code
built around enable-long-double:

./configure:1808:  --enable-long-double    use long double type [yes]

./configure:24723:# Check whether --enable-long-double was given.

I see the option apparently introduced here in 2012 & the ambiguity is
immediate -- the commit mentions disable-long-double but builds
enable-long-double.

https://github.com/wch/r-source/commit/fb8e36f8be0aaf47a9c54c9effb219dae34f0e41

Could someone please help to clear the confusion?

Thanks
Michael Chirico

	[[alternative HTML version deleted]]


From tom@@@k@||ber@ @end|ng |rom gm@||@com  Wed Aug 21 14:54:08 2019
From: tom@@@k@||ber@ @end|ng |rom gm@||@com (Tomas Kalibera)
Date: Wed, 21 Aug 2019 14:54:08 +0200
Subject: [Rd] --disable-long-double or --enable-long-double=no?
In-Reply-To: <CAPRVBcy3mCFSef_X37aA7UG6T9+CV5DRVSUjdkkyLYv8u80qMQ@mail.gmail.com>
References: <CAPRVBcy3mCFSef_X37aA7UG6T9+CV5DRVSUjdkkyLYv8u80qMQ@mail.gmail.com>
Message-ID: <92bb3813-214e-963e-095f-e723ddd8c908@gmail.com>


"--disable-long-double" is documented to work and works. 
"--enable-long-double=no" works as well.

Please refer to Autoconf documentation (section 15.3), 
"--disable-feature is equivalent to --enable-feature=no"

Best,
Tomas

On 8/21/19 2:40 PM, Michael Chirico wrote:
> There's a bit of confusion about how to disable long double support in an R
> build.
>
> I see --disable-long-double scattered about, e.g.
>
>     - R-exts:
>     https://cran.r-project.org/doc/manuals/r-release/R-exts.html#Writing-portable-packages
>     - R-admin:
>     https://cran.r-project.org/doc/manuals/r-release/R-admin.html#Solaris
>     - CRAN noLD check description:
>     https://www.stats.ox.ac.uk/pub/bdr/noLD/README.txt
>     - ?capabilities:
>     https://stat.ethz.ch/R-manual/R-devel/library/base/html/capabilities.html
>
> However, it's *missing* from ./config (cd r-source && grep
> "disable-long-double" configure). Instead there appears to be some code
> built around enable-long-double:
>
> ./configure:1808:  --enable-long-double    use long double type [yes]
>
> ./configure:24723:# Check whether --enable-long-double was given.
>
> I see the option apparently introduced here in 2012 & the ambiguity is
> immediate -- the commit mentions disable-long-double but builds
> enable-long-double.
>
> https://github.com/wch/r-source/commit/fb8e36f8be0aaf47a9c54c9effb219dae34f0e41
>
> Could someone please help to clear the confusion?
>
> Thanks
> Michael Chirico
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



	[[alternative HTML version deleted]]


From therne@u @end|ng |rom m@yo@edu  Fri Aug 23 20:19:08 2019
From: therne@u @end|ng |rom m@yo@edu (Therneau, Terry M., Ph.D.)
Date: Fri, 23 Aug 2019 13:19:08 -0500
Subject: [Rd] problem with R CMD check
Message-ID: <771925$c9e4e7@ironport10.mayo.edu>

For a new release of survival, I normally run? R CMD check for every one of the packages 
that depend on survival? (forewarned is forearmed).

I updated R-devel on the test machine this morning, and R CMD check --as-cran 
survival_3.0-9.tar.gz works as desired.

When I run the check routine on any other source file, however, downloaded from CRAN, it 
fails nearly immediately with a message like the following.

* installing *source* package ?addhazard? ...
** package ?addhazard? successfully unpacked and MD5 sums checked
** using staged installation
** R
** data
*** moving datasets to lazyload DB
** byte-compile and prepare package for lazy loading
==5550==ASan runtime does not come first in initial library list; you should eit
her link runtime to your application or manually preload it with LD_PRELOAD.
ERROR: lazy loading failed for package ?addhazard?
*

-------------------

Here is my Makevars file.? (The commented out lines are from an earlier date when I did 
use ASAN to find a memory leak.)
CFLAGS=? -g -O2 -Wall -pedantic -mtune=native

# Use the lines below for ASAN code
#CC= gcc -std=gnu99 -fsanitize=address -fno-omit-frame-pointer
#CFLAGS=? -fno-omit-frame-pointer -g -O2 -Wall -pedantic -mtune=native
#CXX = g++ -fsanitize=address -fno-omit-frame-pointer

-------
Any hints??? If all packages failed I would figure I had a global mistake, but why most?

Terry T.

 > sessionInfo()
R Under development (unstable) (2019-08-23 r77061)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 18.04.3 LTS

Matrix products: default
BLAS:?? /usr/local/src/R-devel/lib/libRblas.so
LAPACK: /usr/local/src/R-devel/lib/libRlapack.so

locale:
 ?[1] LC_CTYPE=en_US.UTF-8?????? LC_NUMERIC=C
 ?[3] LC_TIME=en_US.UTF-8??????? LC_COLLATE=C
 ?[5] LC_MONETARY=en_US.UTF-8??? LC_MESSAGES=en_US.UTF-8
 ?[7] LC_PAPER=en_US.UTF-8?????? LC_NAME=C
 ?[9] LC_ADDRESS=C?????????????? LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats???? graphics? grDevices utils???? datasets? methods base

loaded via a namespace (and not attached):
[1] compiler_3.7.0



	[[alternative HTML version deleted]]


From |uc@r @end|ng |rom |edor@project@org  Sat Aug 24 15:52:41 2019
From: |uc@r @end|ng |rom |edor@project@org (=?UTF-8?Q?I=C3=B1aki_Ucar?=)
Date: Sat, 24 Aug 2019 15:52:41 +0200
Subject: [Rd] Suggestions for improved checks on CRAN/R
Message-ID: <CALEXWq1LaUi7D__uc9pUppU_hRatg1ZmKZyFD6ZVqY2dRfViDg@mail.gmail.com>

Dear CRAN maintainers, R core team,

Here are some suggestions to prevent some issues I found in several
packages on CRAN. Some of these issues have been reported to their
maintainers, but still I believe it would be desirable to enforce
these on CRAN or in the corresponding R CMD.

- Checks for undeclared sysreqs. There are packages that do not
declare some system requirement. E.g., bioacoustics requires fftw and
soxr, but no sysreqs are declared; ijtiff links agains jpeg, but it's
not declared; there are a handful of packages linking against GSL and
not declaring it, such as BayesSAE, BayesVarSel, bnpmr...

Speaking of which... it would be *great* to have some standardization
in the way sysreqs are declared... But that's another story for
another day.

- Checks for buildroot path in the installed files. E.g., RUnit calls
system.file in man/checkFuncs.Rd, and as a result, the installed
manual contains the buildroot path, which should never happen. Another
example is TMB, but in this case the buildroot ends up in a binary
file, simple.so, that is compiled during the installation.

- Checks for incorrect NeedsCompilation. Some packages have this flag,
but nothing is compiled. E.g., reshape, analogueExtra, AGHmatrix...

- Checks for execution flags. The execution bit is enabled in many,
many files in many packages when it shouldn't (i.e., there's no
shebang). An example that comes to mind: Javascript files under "inst"
in shinyAce.

- Checks for incorrect versions in dependencies. E.g., rtweet depends
on magrittr >= 1.5.0, and abstractr depends on gridExtra >= 2.3.0. It
should be 1.5 and 2.3 respectively. This may not be important on CRAN,
because version comparisons still work in R, but this fails in other
systems, such as RPM packaging.

- Checks for top-level directories. I suppose there are some already
in place, but e.g., adapr has a zero-length file called "data" in the
sources. It seems that the installation command simply ignores it, but
it shouldn't be there.

Thanks for the already huge efforts to implement more thorough checks.
Hope this helps for the task.

Regards,
-- 
I?aki ?car


From @nto|ne@|@br| @end|ng |rom gm@||@com  Sat Aug 24 21:35:46 2019
From: @nto|ne@|@br| @end|ng |rom gm@||@com (Ant F)
Date: Sat, 24 Aug 2019 21:35:46 +0200
Subject: [Rd] Fwd: Document colon equals `:=` operator ?
In-Reply-To: <CAEKh8uggWvcHLkDUr-gRfbYUx8MUtxM2_zEF9hCHWYfhdsOXpQ@mail.gmail.com>
References: <CAEKh8uggWvcHLkDUr-gRfbYUx8MUtxM2_zEF9hCHWYfhdsOXpQ@mail.gmail.com>
Message-ID: <CAEKh8uh0xJyggb-kZLWwaFxXi_8=ATa1a8c1oNe5mZ1P3Xd0JQ@mail.gmail.com>

Dear all,

There was some discussion lately on twitter (
https://twitter.com/geospacedman/status/1164208293377691648 ) about the
status of the colon equal operator. I'm sure it has been discussed in the
past but I couldn't find anything, I'll start by clarifying all i can by
myself to have strong reference, and then ask a few questions at the bottom.

`:=` has been used by data table for a very long time and more recently by
tidyverse packages through rlang package, in both cases to parse
expressions (it's also defined and exported by data.table but just to
trigger an error). It was used in ggvis too, and I have myself designed the
package dotdot that defines it. I'm note aware of other uses in packages
though it pops up from time to time in Stack Overflow 's Q&A.

It has the same precedence as `<-`.

It is used by data.table and tidyverse to provide key / value pairs to
function arguments where `=` would trigger a failure.

It can also convenient at the top level because the rhs is NOT
evaluated/copied before entering the function, as it is with `=` and `<-`.

My understanding based on :

* John Chambers 2001 : https://developer.r-project.org/equalAssign.html
* Matt Dowle 2011 :
https://stackoverflow.com/questions/7033106/why-has-data-table-defined-rather-than-overloading

is that `:=` used to be an equivalent to `<-`, along with `_`. At some
point the decision was made to remove `_` and `:=`. BUT, and as I
understand it started as a mistake,  the `:=` operator was kept (without
definition).

Then Matt Dowle used it in data.table, which gained tremendous popularity,
and thus it was kept around, and later implemented by Hadley Wickham and
Lionel Henry in rlang as a central component of tidy evaluation.

?data.table::`:=` and ?rlang::`:=` describe how to use the operator in the
context of the package but don't refer to its undocumented status.

Some relevant chunks of source code :

*
https://github.com/wch/r-source/blob/tags/R-3-6-1/src/main/gram.y#L379-L381
*
https://github.com/wch/r-source/blob/tags/R-3-6-1/src/main/gram.y#L2999-L3002

Now for the questions :

Some R users worry that the use of `:=` is not safe, as it is
undocumented.  It would be good to be able for package authors to reassure
their users that the package won't break because R Core decides to remove
the operator at some point, or change its behavior.

* Could we have an official statement that the `:=` operator is NOT going
to be removed and can be used safely in packages ? OR could we have an
official statement that the use of the `:=` is discouraged and unsafe given
it might be removed at some point

* If we can have confirmation that the operator won't be removed (and thus
can be used for parsing), could we also have an official statement that it
will also remain possible to define it ? (which data.table and tidyverse
don't require for instance, but dotdot does) OR have a statement that
assuming this is not safe.

* Could we have these statements reflected in the doc ? Or why can't we ? I
believe that even if R Core discourages the use of `:=`, this should be
reflected in the doc. Users encountering it should still be able to
understand what's going on through the base documentation. Referencing it
in `?Syntax` along with a short note would go a long way.

Many thanks and apologies for the possible redundancy with previous threads,

Antoine

	[[alternative HTML version deleted]]


From cyc||cgroup-z1 @end|ng |rom y@hoo@com  Sun Aug 25 06:08:39 2019
From: cyc||cgroup-z1 @end|ng |rom y@hoo@com (Cyclic Group Z_1)
Date: Sun, 25 Aug 2019 04:08:39 +0000 (UTC)
Subject: [Rd] Conventions: Use of globals and main functions
References: <1118624909.2128031.1566706119596.ref@mail.yahoo.com>
Message-ID: <1118624909.2128031.1566706119596@mail.yahoo.com>

In R scripts (as opposed to packages), even in reproducible scripts, it seems fairly conventional to use the global workspace as a sort of main function, and thus R scripts often populate the global environment with many variables, which may be mutated. Although this makes sense given R has historically been used interactively and this practice is common for scripting languages, this appears to disagree with the software-engineering principle of avoiding a mutating global state. Although this is just a rule of thumb, in R scripts, the frequent use of global variables is much more pronounced than in other languages.

On the other hand, in Python, it is common to use a main function (through the `def main():` and? `if __name__ == "__main__":` idioms). This is mentioned both in the documentation as well as in the writing of Python's main creator. Although this is more beneficial in Python than in R because Python code is structured into modules, which serve as both scripts and packages, whereas R separates these conceptually, a similar practice of creating a main function would help avoid the issues from mutating global state common to other languages and facilitate maintainability, especially for longer scripts.

Although many great R texts (Advanced R, Art of R Programming, etc.) caution against assignment in a parent enclosure (e.g., using `<<-`, or `assign`), I have not seen many promote the use of a main function and avoiding mutating global variables from top level.

Would it be a good idea to promote use of main functions and limiting global-state mutation for longer scripts and dedicated applications (not one-off scripts)? Should these practices be mentioned in the standard documentation?

This question was motivated largely by this discussion on Reddit:?https://www.reddit.com/r/rstats/comments/cp3kva/is_mutating_global_state_acceptable_in_r/?. Apologies beforehand if any of these (partially subjective) assessments are in error.

Best,
CG


From c@@rd|@g@bor @end|ng |rom gm@||@com  Sun Aug 25 08:15:52 2019
From: c@@rd|@g@bor @end|ng |rom gm@||@com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Sun, 25 Aug 2019 08:15:52 +0200
Subject: [Rd] Conventions: Use of globals and main functions
In-Reply-To: <1118624909.2128031.1566706119596@mail.yahoo.com>
References: <1118624909.2128031.1566706119596.ref@mail.yahoo.com>
 <1118624909.2128031.1566706119596@mail.yahoo.com>
Message-ID: <CABtg=KnSVWAJ2_JNTODC5RZM+LxbZYNNJYMHzSsPiYzkHB3C8A@mail.gmail.com>

This is what I usually put in scripts:

if (is.null(sys.calls())) {
  main()
}

This is mostly equivalent to the Python idiom. It the script runs from
Rscript, then it will run main(). It also lets you source() the
script, and debug its functions, test them, etc. It works best if all
the code in the script is organized into functions.

Gabor

On Sun, Aug 25, 2019 at 6:11 AM Cyclic Group Z_1 via R-devel
<r-devel at r-project.org> wrote:
>
> In R scripts (as opposed to packages), even in reproducible scripts, it seems fairly conventional to use the global workspace as a sort of main function, and thus R scripts often populate the global environment with many variables, which may be mutated. Although this makes sense given R has historically been used interactively and this practice is common for scripting languages, this appears to disagree with the software-engineering principle of avoiding a mutating global state. Although this is just a rule of thumb, in R scripts, the frequent use of global variables is much more pronounced than in other languages.
>
> On the other hand, in Python, it is common to use a main function (through the `def main():` and  `if __name__ == "__main__":` idioms). This is mentioned both in the documentation as well as in the writing of Python's main creator. Although this is more beneficial in Python than in R because Python code is structured into modules, which serve as both scripts and packages, whereas R separates these conceptually, a similar practice of creating a main function would help avoid the issues from mutating global state common to other languages and facilitate maintainability, especially for longer scripts.
>
> Although many great R texts (Advanced R, Art of R Programming, etc.) caution against assignment in a parent enclosure (e.g., using `<<-`, or `assign`), I have not seen many promote the use of a main function and avoiding mutating global variables from top level.
>
> Would it be a good idea to promote use of main functions and limiting global-state mutation for longer scripts and dedicated applications (not one-off scripts)? Should these practices be mentioned in the standard documentation?
>
> This question was motivated largely by this discussion on Reddit: https://www.reddit.com/r/rstats/comments/cp3kva/is_mutating_global_state_acceptable_in_r/ . Apologies beforehand if any of these (partially subjective) assessments are in error.
>
> Best,
> CG
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Aug 25 13:29:16 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 25 Aug 2019 07:29:16 -0400
Subject: [Rd] Conventions: Use of globals and main functions
In-Reply-To: <1118624909.2128031.1566706119596@mail.yahoo.com>
References: <1118624909.2128031.1566706119596.ref@mail.yahoo.com>
 <1118624909.2128031.1566706119596@mail.yahoo.com>
Message-ID: <551feaef-9cf1-91d5-ff4a-0eeb36328bab@gmail.com>

On 25/08/2019 12:08 a.m., Cyclic Group Z_1 via R-devel wrote:
> In R scripts (as opposed to packages), even in reproducible scripts, it seems fairly conventional to use the global workspace as a sort of main function, and thus R scripts often populate the global environment with many variables, which may be mutated. Although this makes sense given R has historically been used interactively and this practice is common for scripting languages, this appears to disagree with the software-engineering principle of avoiding a mutating global state. Although this is just a rule of thumb, in R scripts, the frequent use of global variables is much more pronounced than in other languages.
> 
> On the other hand, in Python, it is common to use a main function (through the `def main():` and? `if __name__ == "__main__":` idioms). This is mentioned both in the documentation as well as in the writing of Python's main creator. Although this is more beneficial in Python than in R because Python code is structured into modules, which serve as both scripts and packages, whereas R separates these conceptually, a similar practice of creating a main function would help avoid the issues from mutating global state common to other languages and facilitate maintainability, especially for longer scripts.
> 
> Although many great R texts (Advanced R, Art of R Programming, etc.) caution against assignment in a parent enclosure (e.g., using `<<-`, or `assign`), I have not seen many promote the use of a main function and avoiding mutating global variables from top level.
> 
> Would it be a good idea to promote use of main functions and limiting global-state mutation for longer scripts and dedicated applications (not one-off scripts)? Should these practices be mentioned in the standard documentation?

Lexical scoping means that all of the problems of global variables are 
available to writers who use main().  You could treat the evaluation 
frame of your main function exactly like the global workspace:  define 
functions within it, read and modify local variables from those 
functions, etc.

The benefit of using main() if you avoid defining all the other 
functions within it is that other functions normally operate on their 
arguments with few side effects.  You achieve this in R by putting those 
other functions in packages, and running those functions in short 
scripts.  That's how I've always recommended large projects be 
organized.  You don't want a long script for anything, and you don't 
want multiple source files unless they're in a package.

Duncan Murdoch

> 
> This question was motivated largely by this discussion on Reddit:?https://www.reddit.com/r/rstats/comments/cp3kva/is_mutating_global_state_acceptable_in_r/?. Apologies beforehand if any of these (partially subjective) assessments are in error.
> 
> Best,
> CG
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From cyc||cgroup-z1 @end|ng |rom y@hoo@com  Sun Aug 25 23:46:14 2019
From: cyc||cgroup-z1 @end|ng |rom y@hoo@com (Cyclic Group Z_1)
Date: Sun, 25 Aug 2019 21:46:14 +0000 (UTC)
Subject: [Rd] Conventions: Use of globals and main functions
In-Reply-To: <CABtg=KnSVWAJ2_JNTODC5RZM+LxbZYNNJYMHzSsPiYzkHB3C8A@mail.gmail.com>
References: <1118624909.2128031.1566706119596.ref@mail.yahoo.com>
 <1118624909.2128031.1566706119596@mail.yahoo.com>
 <CABtg=KnSVWAJ2_JNTODC5RZM+LxbZYNNJYMHzSsPiYzkHB3C8A@mail.gmail.com>
Message-ID: <3413997.2322922.1566769574357@mail.yahoo.com>

 This seems like a nice idiom; I've seen others use? ? if(!interactive()){? ? ? ? main()? ? }to a similar effect.
Best,CG
    On Sunday, August 25, 2019, 01:16:06 AM CDT, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:  
 
 This is what I usually put in scripts:

if (is.null(sys.calls())) {
? main()
}

This is mostly equivalent to the Python idiom. It the script runs from
Rscript, then it will run main(). It also lets you source() the
script, and debug its functions, test them, etc. It works best if all
the code in the script is organized into functions.

Gabor

On Sun, Aug 25, 2019 at 6:11 AM Cyclic Group Z_1 via R-devel
<r-devel at r-project.org> wrote:
>
> In R scripts (as opposed to packages), even in reproducible scripts, it seems fairly conventional to use the global workspace as a sort of main function, and thus R scripts often populate the global environment with many variables, which may be mutated. Although this makes sense given R has historically been used interactively and this practice is common for scripting languages, this appears to disagree with the software-engineering principle of avoiding a mutating global state. Although this is just a rule of thumb, in R scripts, the frequent use of global variables is much more pronounced than in other languages.
>
> On the other hand, in Python, it is common to use a main function (through the `def main():` and? `if __name__ == "__main__":` idioms). This is mentioned both in the documentation as well as in the writing of Python's main creator. Although this is more beneficial in Python than in R because Python code is structured into modules, which serve as both scripts and packages, whereas R separates these conceptually, a similar practice of creating a main function would help avoid the issues from mutating global state common to other languages and facilitate maintainability, especially for longer scripts.
>
> Although many great R texts (Advanced R, Art of R Programming, etc.) caution against assignment in a parent enclosure (e.g., using `<<-`, or `assign`), I have not seen many promote the use of a main function and avoiding mutating global variables from top level.
>
> Would it be a good idea to promote use of main functions and limiting global-state mutation for longer scripts and dedicated applications (not one-off scripts)? Should these practices be mentioned in the standard documentation?
>
> This question was motivated largely by this discussion on Reddit: https://www.reddit.com/r/rstats/comments/cp3kva/is_mutating_global_state_acceptable_in_r/ . Apologies beforehand if any of these (partially subjective) assessments are in error.
>
> Best,
> CG
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel  
	[[alternative HTML version deleted]]


From cyc||cgroup-z1 @end|ng |rom y@hoo@com  Mon Aug 26 01:09:57 2019
From: cyc||cgroup-z1 @end|ng |rom y@hoo@com (Cyclic Group Z_1)
Date: Sun, 25 Aug 2019 23:09:57 +0000 (UTC)
Subject: [Rd] Conventions: Use of globals and main functions
In-Reply-To: <551feaef-9cf1-91d5-ff4a-0eeb36328bab@gmail.com>
References: <1118624909.2128031.1566706119596.ref@mail.yahoo.com>
 <1118624909.2128031.1566706119596@mail.yahoo.com>
 <551feaef-9cf1-91d5-ff4a-0eeb36328bab@gmail.com>
Message-ID: <1278224074.2337376.1566774597756@mail.yahoo.com>



This is a fair point; structuring functions into packages is probably ultimately the gold standard for code organization in R. However, lexical scoping in R is really not much different than in other languages, such as Python, in which use of main functions and defining other named functions outside of main are encouraged. For example, in Scheme, from which R derives its scoping rules, the community generally organizes code with almost exclusively functions and few non-function global variables at top level. The common use of globals in R seems to be mostly a consequence of historical interactive use and, relatedly, an inherited practice from S.

It is true, though, that since anonymous functions (such as in lapply) play a large part in idiomatic R code, as you put it, "[l]exical scoping means that all of the problems of global variables are available to writers who use main()." Nevertheless, using a main function with other functions defined outside it seems like a good quick alternative that offers similar advantages to making a package when functions are tightly coupled to the script and the project may not be large or generalizable enough to warrant making a package.

Best,
CG


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Aug 26 02:08:59 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 25 Aug 2019 20:08:59 -0400
Subject: [Rd] Conventions: Use of globals and main functions
In-Reply-To: <1278224074.2337376.1566774597756@mail.yahoo.com>
References: <1118624909.2128031.1566706119596.ref@mail.yahoo.com>
 <1118624909.2128031.1566706119596@mail.yahoo.com>
 <551feaef-9cf1-91d5-ff4a-0eeb36328bab@gmail.com>
 <1278224074.2337376.1566774597756@mail.yahoo.com>
Message-ID: <739a44fe-4fd4-ee75-cf93-ea32d8760de7@gmail.com>

On 25/08/2019 7:09 p.m., Cyclic Group Z_1 wrote:
> 
> 
> This is a fair point; structuring functions into packages is probably ultimately the gold standard for code organization in R. However, lexical scoping in R is really not much different than in other languages, such as Python, in which use of main functions and defining other named functions outside of main are encouraged. For example, in Scheme, from which R derives its scoping rules, the community generally organizes code with almost exclusively functions and few non-function global variables at top level. The common use of globals in R seems to be mostly a consequence of historical interactive use and, relatedly, an inherited practice from S.
> 
> It is true, though, that since anonymous functions (such as in lapply) play a large part in idiomatic R code, as you put it, "[l]exical scoping means that all of the problems of global variables are available to writers who use main()." Nevertheless, using a main function with other functions defined outside it seems like a good quick alternative that offers similar advantages to making a package when functions are tightly coupled to the script and the project may not be large or generalizable enough to warrant making a package.
> 

I think the idea that making a package is too hard is just wrong. 
Packages in R have lots of requirements, but nowadays there are tools 
that make them easy.  Eleven years ago at UseR in Dortmund I wrote a 
package during a 45 minute presentation, and things are much easier now.

If you make a complex project without putting most of the code into a 
package, you don't have something that you will be able to modify in a 
year or two, because you won't have proper documentation.

Scripts are for throwaways, not for anything worth keeping.

Duncan Murdoch


From c@@rd|@g@bor @end|ng |rom gm@||@com  Mon Aug 26 09:41:02 2019
From: c@@rd|@g@bor @end|ng |rom gm@||@com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Mon, 26 Aug 2019 09:41:02 +0200
Subject: [Rd] Conventions: Use of globals and main functions
In-Reply-To: <3413997.2322922.1566769574357@mail.yahoo.com>
References: <1118624909.2128031.1566706119596.ref@mail.yahoo.com>
 <1118624909.2128031.1566706119596@mail.yahoo.com>
 <CABtg=KnSVWAJ2_JNTODC5RZM+LxbZYNNJYMHzSsPiYzkHB3C8A@mail.gmail.com>
 <3413997.2322922.1566769574357@mail.yahoo.com>
Message-ID: <CABtg=KmXmOb3JJVubrf7xUp_nHW30HkOOWWbTnpU=LpuWQ2cUg@mail.gmail.com>

That is unfortunately wrong, though. Whether the script runs as "main"
and whether R is in interactive mode are independent properties. I
guess most of the time it works, because _usually_ you run the whole
script (main()) in non-interactive mode, and source() it in
interactive mode, but this is not necessarily always the case, e.g.
you might want to source() in non-interactive mode to run some tests,
or use the functions of the script in another script, in which cases
you don't want to run main().

G.

On Sun, Aug 25, 2019 at 11:47 PM Cyclic Group Z_1
<cyclicgroup-z1 at yahoo.com> wrote:
>
> This seems like a nice idiom; I've seen others use
>     if(!interactive()){
>         main()
>     }
> to a similar effect.
>
> Best,
> CG
>
> On Sunday, August 25, 2019, 01:16:06 AM CDT, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
>
>
> This is what I usually put in scripts:
>
> if (is.null(sys.calls())) {
>   main()
> }
>

[...]


From p@m|rnov2000 @end|ng |rom gm@||@com  Fri Aug 23 22:22:14 2019
From: p@m|rnov2000 @end|ng |rom gm@||@com (petr smirnov)
Date: Fri, 23 Aug 2019 16:22:14 -0400
Subject: [Rd] wrap_logical warning message when loading objects created in R
 3.6 in an R 3.5 session
Message-ID: <CABAj7xeN+Sp9Ovay+EwMw2_sDEV2vVovNw3rKRoaRCvx_1odEQ@mail.gmail.com>

Hi,

I am experiencing a warning message when I load a large R object
created in an R 3.6 session in R 3.5.* , as follows:

```
Warning message:
In load(?GDSCv2.RData?) :
 cannot unserialize ALTVEC object of class ?wrap_logical? from package
?base?; returning length zero vector
```
Of relevant information may be that the large R object (a data
structure defined in my Bioconductor package PharmacoGx), was in part
created including data frames which were cast from data.tables. I
noticed that the ALTVEC class had caused some errors previously in the
data.table package.

I have two questions:
1. Should I be concerned about this warning? I cannot seem to find
what effect it has on the data loaded.
2. Could you point me towards narrowing down the cause of this issue?
Ideally, everyone would upgrade R promptly, but even our own
institute's HPC cluster is still on 3.5, and the warning does not
inspire confidence for some of the less technical members of our group
who are using the datasets.


-- 
Petr Smirnov
PhD Candidate,
Benjamin Haibe-Kains Lab
Princess Margaret Cancer Centre
University of Toronto

psmirnov2000 at gmail.com


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Aug 26 12:30:31 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 26 Aug 2019 06:30:31 -0400
Subject: [Rd] 
 wrap_logical warning message when loading objects created in R
 3.6 in an R 3.5 session
In-Reply-To: <CABAj7xeN+Sp9Ovay+EwMw2_sDEV2vVovNw3rKRoaRCvx_1odEQ@mail.gmail.com>
References: <CABAj7xeN+Sp9Ovay+EwMw2_sDEV2vVovNw3rKRoaRCvx_1odEQ@mail.gmail.com>
Message-ID: <7aa574e9-3d8e-42e9-ffe3-d8bf0493bcda@gmail.com>

On 23/08/2019 4:22 p.m., petr smirnov wrote:
> Hi,
> 
> I am experiencing a warning message when I load a large R object
> created in an R 3.6 session in R 3.5.* , as follows:
> 
> ```
> Warning message:
> In load(?GDSCv2.RData?) :
>   cannot unserialize ALTVEC object of class ?wrap_logical? from package
> ?base?; returning length zero vector
> ```
> Of relevant information may be that the large R object (a data
> structure defined in my Bioconductor package PharmacoGx), was in part
> created including data frames which were cast from data.tables. I
> noticed that the ALTVEC class had caused some errors previously in the
> data.table package.
> 
> I have two questions:
> 1. Should I be concerned about this warning? I cannot seem to find
> what effect it has on the data loaded.

That object is not being loaded.  If the object is important to you, 
then you should be concerned.

> 2. Could you point me towards narrowing down the cause of this issue?

 From time to time the format of saved objects changes.  There was such 
a change in version 3.5.0 of R. Older versions cannot read files in a 
format that was invented after they were released.

I would have expected 3.5.0 to be able to read all the current formats, 
but it appears you have an object new to 3.6.0 that needs something that 
doesn't exist in 3.5.0.  The solution is probably to use 3.6.x to read 
that file, and then save it with "version=2" as an argument.  That 
should cause it to use the older format.

Duncan Murdoch


> Ideally, everyone would upgrade R promptly, but even our own
> institute's HPC cluster is still on 3.5, and the warning does not
> inspire confidence for some of the less technical members of our group
> who are using the datasets.


From cyc||cgroup-z1 @end|ng |rom y@hoo@com  Mon Aug 26 18:59:28 2019
From: cyc||cgroup-z1 @end|ng |rom y@hoo@com (Cyclic Group Z_1)
Date: Mon, 26 Aug 2019 16:59:28 +0000 (UTC)
Subject: [Rd] Conventions: Use of globals and main functions
In-Reply-To: <CABtg=KmXmOb3JJVubrf7xUp_nHW30HkOOWWbTnpU=LpuWQ2cUg@mail.gmail.com>
References: <1118624909.2128031.1566706119596.ref@mail.yahoo.com>
 <1118624909.2128031.1566706119596@mail.yahoo.com>
 <CABtg=KnSVWAJ2_JNTODC5RZM+LxbZYNNJYMHzSsPiYzkHB3C8A@mail.gmail.com>
 <3413997.2322922.1566769574357@mail.yahoo.com>
 <CABtg=KmXmOb3JJVubrf7xUp_nHW30HkOOWWbTnpU=LpuWQ2cUg@mail.gmail.com>
Message-ID: <1560143657.2707512.1566838768999@mail.yahoo.com>

Right, I did not mean to imply these tests are equivalent. Only that both similarly exclude execution of main() under some context.?

Best,
CG


From wdun|@p @end|ng |rom t|bco@com  Mon Aug 26 19:58:48 2019
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Mon, 26 Aug 2019 10:58:48 -0700
Subject: [Rd] Conventions: Use of globals and main functions
In-Reply-To: <739a44fe-4fd4-ee75-cf93-ea32d8760de7@gmail.com>
References: <1118624909.2128031.1566706119596.ref@mail.yahoo.com>
 <1118624909.2128031.1566706119596@mail.yahoo.com>
 <551feaef-9cf1-91d5-ff4a-0eeb36328bab@gmail.com>
 <1278224074.2337376.1566774597756@mail.yahoo.com>
 <739a44fe-4fd4-ee75-cf93-ea32d8760de7@gmail.com>
Message-ID: <CAF8bMcaU2ycRd7YA1ziZeoVyZ24uY1fTmV9131pbp2p3uM_qVQ@mail.gmail.com>

Duncan Murdoch wrote:
>  Scripts are for throwaways, not for anything worth keeping.

I totally agree and have a tangentially relevant question about the <<-
operator.  Currently 'name <<- value' means to look up the environment
stack until you find 'name'  and (a) if you find 'name' in some frame bind
it to a new value in that frame and (b) if you do not find it make a new
entry for it in .GlobalEnv.

Should R deprecate the second part of that and give an error if 'name' is
not already present in the environment stack?  This would catch misspelling
errors in functions that collect results from recursive calls.  E.g.,

collectStrings <- function(list) {
    strings <- character() # to be populated by .collect
    .collect <- function(x) {
        if (is.list(x)) {
            lapply(x, .collect)
        } else if (is.character(x)) {
            strings <<- c(strings, x)
        }
        misspelledStrings <<- c(strings, names(x)) # oops, would like to be
told about this error
        NULL
    }
    .collect(list)
    strings
}

This gives the incorrect:
> collectStrings(list(i="One", ii=list(a=1, b="Two")))
[1] "One" "Two"
> misspelledStrings
[1] "One" "Two" "i"   "ii"

instead of what we would get if 'misspelledStrings' were 'strings'.
> collectStrings(list(i="One", ii=list(a=1, b="Two")))
[1] "One" "Two" "a"   "b"   "i"   "ii"

If someone really wanted to assign into .GlobalEnv the assign() function is
available.

In S '<<-' only had meaning (b) and R added meaning (a).  Perhaps it is
time to drop meaning (b).  We could start by triggering a warning about it
if some environment variable were set, as is being done for non-scalar &&
and ||.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sun, Aug 25, 2019 at 5:09 PM Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 25/08/2019 7:09 p.m., Cyclic Group Z_1 wrote:
> >
> >
> > This is a fair point; structuring functions into packages is probably
> ultimately the gold standard for code organization in R. However, lexical
> scoping in R is really not much different than in other languages, such as
> Python, in which use of main functions and defining other named functions
> outside of main are encouraged. For example, in Scheme, from which R
> derives its scoping rules, the community generally organizes code with
> almost exclusively functions and few non-function global variables at top
> level. The common use of globals in R seems to be mostly a consequence of
> historical interactive use and, relatedly, an inherited practice from S.
> >
> > It is true, though, that since anonymous functions (such as in lapply)
> play a large part in idiomatic R code, as you put it, "[l]exical scoping
> means that all of the problems of global variables are available to writers
> who use main()." Nevertheless, using a main function with other functions
> defined outside it seems like a good quick alternative that offers similar
> advantages to making a package when functions are tightly coupled to the
> script and the project may not be large or generalizable enough to warrant
> making a package.
> >
>
> I think the idea that making a package is too hard is just wrong.
> Packages in R have lots of requirements, but nowadays there are tools
> that make them easy.  Eleven years ago at UseR in Dortmund I wrote a
> package during a 45 minute presentation, and things are much easier now.
>
> If you make a complex project without putting most of the code into a
> package, you don't have something that you will be able to modify in a
> year or two, because you won't have proper documentation.
>
> Scripts are for throwaways, not for anything worth keeping.
>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Aug 26 20:19:36 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 26 Aug 2019 14:19:36 -0400
Subject: [Rd] Conventions: Use of globals and main functions
In-Reply-To: <CAF8bMcaU2ycRd7YA1ziZeoVyZ24uY1fTmV9131pbp2p3uM_qVQ@mail.gmail.com>
References: <1118624909.2128031.1566706119596.ref@mail.yahoo.com>
 <1118624909.2128031.1566706119596@mail.yahoo.com>
 <551feaef-9cf1-91d5-ff4a-0eeb36328bab@gmail.com>
 <1278224074.2337376.1566774597756@mail.yahoo.com>
 <739a44fe-4fd4-ee75-cf93-ea32d8760de7@gmail.com>
 <CAF8bMcaU2ycRd7YA1ziZeoVyZ24uY1fTmV9131pbp2p3uM_qVQ@mail.gmail.com>
Message-ID: <ab5d1ccd-b971-4403-e328-db9bb3b23ec5@gmail.com>

On 26/08/2019 1:58 p.m., William Dunlap wrote:
> Duncan Murdoch wrote:
>  > Scripts are for throwaways, not for anything worth keeping.
> 
> I totally agree and have a tangentially relevant question about the <<- 
> operator.? Currently 'name <<- value' means to look up the environment 
> stack until you find 'name'? and (a) if you find 'name' in some frame 
> bind it to a new value in that frame and (b) if you do not find it make 
> a new entry for it in .GlobalEnv.
> 
> Should R deprecate the second part of that and give an error if 'name' 
> is not already present in the environment stack?? This would catch 
> misspelling errors in functions that collect results from recursive 
> calls.? E.g.,

I like that suggestion.  Package tests have been complaining about 
packages writing to .GlobalEnv for a while now, so there probably aren't 
many instances of b) in CRAN packages; that change might be relatively 
painless.

Duncan Murdoch

> 
> collectStrings <- function(list) {
>  ? ? strings <- character() # to be populated by .collect
>  ? ? .collect <- function(x) {
>  ? ? ? ? if (is.list(x)) {
>  ? ? ? ? ? ? lapply(x, .collect)
>  ? ? ? ? } else if (is.character(x)) {
>  ? ? ? ? ? ? strings <<- c(strings, x)
>  ? ? ? ? }
>  ? ? ? ? misspelledStrings <<- c(strings, names(x)) # oops, would like 
> to be told about this error
>  ? ? ? ? NULL
>  ? ? }
>  ? ? .collect(list)
>  ? ? strings
> }
> 
> This gives the incorrect:
>  > collectStrings(list(i="One", ii=list(a=1, b="Two")))
> [1] "One" "Two"
>  > misspelledStrings
> [1] "One" "Two" "i" ? "ii"
> 
> instead of what we would get if 'misspelledStrings' were 'strings'.
>  > collectStrings(list(i="One", ii=list(a=1, b="Two")))
> [1] "One" "Two" "a" ? "b" ? "i" ? "ii"
> 
> If someone really wanted to assign into .GlobalEnv the assign() function 
> is available.
> 
> In S '<<-' only had meaning (b) and R added meaning (a).? Perhaps it is 
> time to drop meaning (b).? We could start by triggering a warning about 
> it if some environment variable were set, as is being done for 
> non-scalar && and ||.
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com <http://tibco.com>
> 
> 
> On Sun, Aug 25, 2019 at 5:09 PM Duncan Murdoch <murdoch.duncan at gmail.com 
> <mailto:murdoch.duncan at gmail.com>> wrote:
> 
>     On 25/08/2019 7:09 p.m., Cyclic Group Z_1 wrote:
>      >
>      >
>      > This is a fair point; structuring functions into packages is
>     probably ultimately the gold standard for code organization in R.
>     However, lexical scoping in R is really not much different than in
>     other languages, such as Python, in which use of main functions and
>     defining other named functions outside of main are encouraged. For
>     example, in Scheme, from which R derives its scoping rules, the
>     community generally organizes code with almost exclusively functions
>     and few non-function global variables at top level. The common use
>     of globals in R seems to be mostly a consequence of historical
>     interactive use and, relatedly, an inherited practice from S.
>      >
>      > It is true, though, that since anonymous functions (such as in
>     lapply) play a large part in idiomatic R code, as you put it,
>     "[l]exical scoping means that all of the problems of global
>     variables are available to writers who use main()." Nevertheless,
>     using a main function with other functions defined outside it seems
>     like a good quick alternative that offers similar advantages to
>     making a package when functions are tightly coupled to the script
>     and the project may not be large or generalizable enough to warrant
>     making a package.
>      >
> 
>     I think the idea that making a package is too hard is just wrong.
>     Packages in R have lots of requirements, but nowadays there are tools
>     that make them easy.? Eleven years ago at UseR in Dortmund I wrote a
>     package during a 45 minute presentation, and things are much easier now.
> 
>     If you make a complex project without putting most of the code into a
>     package, you don't have something that you will be able to modify in a
>     year or two, because you won't have proper documentation.
> 
>     Scripts are for throwaways, not for anything worth keeping.
> 
>     Duncan Murdoch
> 
>     ______________________________________________
>     R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-devel
>


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Tue Aug 27 11:36:32 2019
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 27 Aug 2019 11:36:32 +0200
Subject: [Rd] Conventions: Use of globals and main functions
In-Reply-To: <ab5d1ccd-b971-4403-e328-db9bb3b23ec5@gmail.com>
References: <1118624909.2128031.1566706119596.ref@mail.yahoo.com>
 <1118624909.2128031.1566706119596@mail.yahoo.com>
 <551feaef-9cf1-91d5-ff4a-0eeb36328bab@gmail.com>
 <1278224074.2337376.1566774597756@mail.yahoo.com>
 <739a44fe-4fd4-ee75-cf93-ea32d8760de7@gmail.com>
 <CAF8bMcaU2ycRd7YA1ziZeoVyZ24uY1fTmV9131pbp2p3uM_qVQ@mail.gmail.com>
 <ab5d1ccd-b971-4403-e328-db9bb3b23ec5@gmail.com>
Message-ID: <23908.63904.114202.449706@stat.math.ethz.ch>

>>>>> Duncan Murdoch 
>>>>>     on Mon, 26 Aug 2019 14:19:36 -0400 writes:

    > On 26/08/2019 1:58 p.m., William Dunlap wrote:
    >> Duncan Murdoch wrote:
    >> > Scripts are for throwaways, not for anything worth keeping.
    >> 
    >> I totally agree and have a tangentially relevant question about the <<- 
    >> operator.? Currently 'name <<- value' means to look up the environment 
    >> stack until you find 'name'? and (a) if you find 'name' in some frame 
    >> bind it to a new value in that frame and (b) if you do not find it make 
    >> a new entry for it in .GlobalEnv.
    >> 
    >> Should R deprecate the second part of that and give an error if 'name' 
    >> is not already present in the environment stack?? This would catch 
    >> misspelling errors in functions that collect results from recursive 
    >> calls.? E.g.,

    > I like that suggestion.  Package tests have been complaining about 
    > packages writing to .GlobalEnv for a while now, so there probably aren't 
    > many instances of b) in CRAN packages; that change might be relatively 
    > painless.

    > Duncan Murdoch

I don't agree currently : AFAICS, there's no other case (in S or) R where an
assignment only works if there's no object with that name.

In addition: If I wanted such a functionality I'd rather have with a
function that has several arguments and this behavior was
switchable via  <argname> = TRUE/FALSE , rather than with
`<<-` which has always exactly 2 arguments.

[This is my personal opinion only; other R Core members may well
 think differently about this]

Martin

    >> collectStrings <- function(list) {
    >> ? ? strings <- character() # to be populated by .collect
    >> ? ? .collect <- function(x) {
    >> ? ? ? ? if (is.list(x)) {
    >> ? ? ? ? ? ? lapply(x, .collect)
    >> ? ? ? ? } else if (is.character(x)) {
    >> ? ? ? ? ? ? strings <<- c(strings, x)
    >> ? ? ? ? }
    >> ? ? ? ? misspelledStrings <<- c(strings, names(x)) # oops, would like 
    >> to be told about this error
    >> ? ? ? ? NULL
    >> ? ? }
    >> ? ? .collect(list)
    >> ? ? strings
    >> }
    >> 
    >> This gives the incorrect:
    >> > collectStrings(list(i="One", ii=list(a=1, b="Two")))
    >> [1] "One" "Two"
    >> > misspelledStrings
    >> [1] "One" "Two" "i" ? "ii"
    >> 
    >> instead of what we would get if 'misspelledStrings' were 'strings'.
    >> > collectStrings(list(i="One", ii=list(a=1, b="Two")))
    >> [1] "One" "Two" "a" ? "b" ? "i" ? "ii"
    >> 
    >> If someone really wanted to assign into .GlobalEnv the assign() function 
    >> is available.
    >> 
    >> In S '<<-' only had meaning (b) and R added meaning (a).? Perhaps it is 
    >> time to drop meaning (b).? We could start by triggering a warning about 
    >> it if some environment variable were set, as is being done for 
    >> non-scalar && and ||.
    >> 
    >> Bill Dunlap
    >> TIBCO Software
    >> wdunlap tibco.com <http://tibco.com>
    >> 
    >> 
    >> On Sun, Aug 25, 2019 at 5:09 PM Duncan Murdoch <murdoch.duncan at gmail.com 
    >> <mailto:murdoch.duncan at gmail.com>> wrote:
    >> 
    >> On 25/08/2019 7:09 p.m., Cyclic Group Z_1 wrote:
    >> >
    >> >
    >> > This is a fair point; structuring functions into packages is
    >> probably ultimately the gold standard for code organization in R.
    >> However, lexical scoping in R is really not much different than in
    >> other languages, such as Python, in which use of main functions and
    >> defining other named functions outside of main are encouraged. For
    >> example, in Scheme, from which R derives its scoping rules, the
    >> community generally organizes code with almost exclusively functions
    >> and few non-function global variables at top level. The common use
    >> of globals in R seems to be mostly a consequence of historical
    >> interactive use and, relatedly, an inherited practice from S.
    >> >
    >> > It is true, though, that since anonymous functions (such as in
    >> lapply) play a large part in idiomatic R code, as you put it,
    >> "[l]exical scoping means that all of the problems of global
    >> variables are available to writers who use main()." Nevertheless,
    >> using a main function with other functions defined outside it seems
    >> like a good quick alternative that offers similar advantages to
    >> making a package when functions are tightly coupled to the script
    >> and the project may not be large or generalizable enough to warrant
    >> making a package.
    >> >
    >> 
    >> I think the idea that making a package is too hard is just wrong.
    >> Packages in R have lots of requirements, but nowadays there are tools
    >> that make them easy.? Eleven years ago at UseR in Dortmund I wrote a
    >> package during a 45 minute presentation, and things are much easier now.
    >> 
    >> If you make a complex project without putting most of the code into a
    >> package, you don't have something that you will be able to modify in a
    >> year or two, because you won't have proper documentation.
    >> 
    >> Scripts are for throwaways, not for anything worth keeping.
    >> 
    >> Duncan Murdoch
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> 

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From retep@me|@@ner @end|ng |rom gm@||@com  Tue Aug 27 15:41:55 2019
From: retep@me|@@ner @end|ng |rom gm@||@com (Peter Meissner)
Date: Tue, 27 Aug 2019 15:41:55 +0200
Subject: [Rd] Conventions: Use of globals and main functions
In-Reply-To: <1118624909.2128031.1566706119596@mail.yahoo.com>
References: <1118624909.2128031.1566706119596.ref@mail.yahoo.com>
 <1118624909.2128031.1566706119596@mail.yahoo.com>
Message-ID: <CAB-BFRp=G1GKc8DTQ9N=haBBy1=7QHMUze5GYd6x92ZdXj59nA@mail.gmail.com>

Hey,

I always found it a strength of R compared to many other langaugas that
simple things (running a script, doing something interactive, writing a
function, using lambdas, installing packages, getting help, ...) are very
very simple.

R is a commandline statistics program that happens to be a very elegant,
simple and consistent programming language too.

That beeing said I think the main task of scripts is to get things done via
running them end to end in a fresh session. Now, it very well may happen
that a lot of stuff has to be done. Than splitting up scripts into
subscripts and sourcing them from a meta script is a straightforward
solution. It might also be that some functionality is put into functions to
be reused in other places. This can be done by putting those function
definitions into separate files. Than one cane use source wherever those
functions are needed. Now, putting stuff that runs code and scripts that
define/provovide functions into the same script is a bad idea. Using the
main()-idioms described might prevent this the problems stemming from
mixing functions and function execution. But it would also encourage this
mixing which is - I think, a bad idea anyways.

Therefore, I am against fostering a main()-idiom - it adds complexity and
encourages bad code structuring (putting application code and function
definition code into one file).

If one needs code to behave differenlty in interactive sessions than in
non-interactive sessions - if( interactive() ){ } is one way to solve this.

If more solid software developement is needed packages are the way to go.


Best, Peter


Am So., 25. Aug. 2019 um 06:11 Uhr schrieb Cyclic Group Z_1 via R-devel <
r-devel at r-project.org>:

> In R scripts (as opposed to packages), even in reproducible scripts, it
> seems fairly conventional to use the global workspace as a sort of main
> function, and thus R scripts often populate the global environment with
> many variables, which may be mutated. Although this makes sense given R has
> historically been used interactively and this practice is common for
> scripting languages, this appears to disagree with the software-engineering
> principle of avoiding a mutating global state. Although this is just a rule
> of thumb, in R scripts, the frequent use of global variables is much more
> pronounced than in other languages.
>
> On the other hand, in Python, it is common to use a main function (through
> the `def main():` and  `if __name__ == "__main__":` idioms). This is
> mentioned both in the documentation as well as in the writing of Python's
> main creator. Although this is more beneficial in Python than in R because
> Python code is structured into modules, which serve as both scripts and
> packages, whereas R separates these conceptually, a similar practice of
> creating a main function would help avoid the issues from mutating global
> state common to other languages and facilitate maintainability, especially
> for longer scripts.
>
> Although many great R texts (Advanced R, Art of R Programming, etc.)
> caution against assignment in a parent enclosure (e.g., using `<<-`, or
> `assign`), I have not seen many promote the use of a main function and
> avoiding mutating global variables from top level.
>
> Would it be a good idea to promote use of main functions and limiting
> global-state mutation for longer scripts and dedicated applications (not
> one-off scripts)? Should these practices be mentioned in the standard
> documentation?
>
> This question was motivated largely by this discussion on Reddit:
> https://www.reddit.com/r/rstats/comments/cp3kva/is_mutating_global_state_acceptable_in_r/ .
> Apologies beforehand if any of these (partially subjective) assessments are
> in error.
>
> Best,
> CG
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Wed Aug 28 00:19:21 2019
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Wed, 28 Aug 2019 10:19:21 +1200
Subject: [Rd] Conventions: Use of globals and main functions
In-Reply-To: <1118624909.2128031.1566706119596@mail.yahoo.com>
References: <1118624909.2128031.1566706119596.ref@mail.yahoo.com>
 <1118624909.2128031.1566706119596@mail.yahoo.com>
Message-ID: <CAB8pepy-b3v+fdTrT6=ZpkXCXPhV14_Oi5=h1AaOB_A=-F7E+A@mail.gmail.com>

> this appears to disagree with the software-engineering principle of avoiding a mutating global state

I disagree.
In embedded systems engineering, for example, it's customary to use
global variables to represent ports.

Also, I note that the use of global variables, is similar to using pen
and paper, to do mathematics and statistics.
(Which is good).
Whether that's consistent with software engineering principles or not,
I don't know.

However, I partly agree with you.
Given that there's interest from various parties in running R in
various ways, it may be good to document some of the options
available.

"Running R" (in "R Installation and Administration") links to
"Appendix B Invoking R" (in "An Introduction to R").
However, these sections do not cover the topics in this thread.


From @purd|e@@ @end|ng |rom gm@||@com  Wed Aug 28 00:29:25 2019
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Wed, 28 Aug 2019 10:29:25 +1200
Subject: [Rd] Conventions: Use of globals and main functions
In-Reply-To: <CAB8pepy-b3v+fdTrT6=ZpkXCXPhV14_Oi5=h1AaOB_A=-F7E+A@mail.gmail.com>
References: <1118624909.2128031.1566706119596.ref@mail.yahoo.com>
 <1118624909.2128031.1566706119596@mail.yahoo.com>
 <CAB8pepy-b3v+fdTrT6=ZpkXCXPhV14_Oi5=h1AaOB_A=-F7E+A@mail.gmail.com>
Message-ID: <CAB8pepwuWoKA-m+EGgXh5hxjxpD2G0LdEgJ=kYxjs2sN2LVgsg@mail.gmail.com>

> "Running R" (in "R Installation and Administration") links to
> "Appendix B Invoking R" (in "An Introduction to R").
> However, these sections do not cover the topics in this thread.

Sorry, I made a mistake.
It is in the documentation (B.4 Scripting with R)
e.g.

(excerpts only)
R CMD BATCH "--args arg1 arg2" foo.R &
args <- commandArgs(TRUE)
Rscript foo.R arg1 arg2


From henr|k@bengt@@on @end|ng |rom gm@||@com  Wed Aug 28 00:39:28 2019
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Tue, 27 Aug 2019 15:39:28 -0700
Subject: [Rd] Conventions: Use of globals and main functions
In-Reply-To: <CAB8pepy-b3v+fdTrT6=ZpkXCXPhV14_Oi5=h1AaOB_A=-F7E+A@mail.gmail.com>
References: <1118624909.2128031.1566706119596.ref@mail.yahoo.com>
 <1118624909.2128031.1566706119596@mail.yahoo.com>
 <CAB8pepy-b3v+fdTrT6=ZpkXCXPhV14_Oi5=h1AaOB_A=-F7E+A@mail.gmail.com>
Message-ID: <CAFDcVCQw8mKUJ2oYtBBGj-zjx5YwgvNLeu=YBYxfo0fuNE-67g@mail.gmail.com>

FWIW, one could imagine introducing a helper function global();

global <- function(expr) { eval(substitute(expr), envir = globalenv(),
enclos = baseenv()) }

to make it explicit that any assignments (and evaluation in general)
take place in the global environment, e.g.

> local({ global(a <- 2) })
> a
[1] 2

That "looks" nicer than assign("a", 2, envir = globalenv()) and it's
safer than assuming a <<- 2 will "reach" the global environment.

/Henrik

On Tue, Aug 27, 2019 at 3:19 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
>
> > this appears to disagree with the software-engineering principle of avoiding a mutating global state
>
> I disagree.
> In embedded systems engineering, for example, it's customary to use
> global variables to represent ports.
>
> Also, I note that the use of global variables, is similar to using pen
> and paper, to do mathematics and statistics.
> (Which is good).
> Whether that's consistent with software engineering principles or not,
> I don't know.
>
> However, I partly agree with you.
> Given that there's interest from various parties in running R in
> various ways, it may be good to document some of the options
> available.
>
> "Running R" (in "R Installation and Administration") links to
> "Appendix B Invoking R" (in "An Introduction to R").
> However, these sections do not cover the topics in this thread.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From @zwj|08 @end|ng |rom gm@||@com  Wed Aug 28 04:22:16 2019
From: @zwj|08 @end|ng |rom gm@||@com (Wang Jiefei)
Date: Tue, 27 Aug 2019 22:22:16 -0400
Subject: [Rd] What is the best way to loop over an ALTREP vector?
Message-ID: <CAGiFhPN+ncuPMY9UbEO+b0wis0EJ0R9AaWSB0By-CD3fNetO1A@mail.gmail.com>

Hi devel team,

I'm working on C/C++ level ALTREP compatibility for a package. The package
previously used pointers to access the data of a SEXP, so it would not work
for some ALTREP objects which do not have a pointer. I plan to rewrite the
code and use functions like get_elt, get_region, and get_subset to access
the values of a vector, so I have a few questions for ALTREP:

1. Since an ALTREP do not have to define all of the above
functions(element, region, subset), is there any way to check which
function has been defined for an ALTREP class? I did a search on
RInternal.h and altrep.c but did not find a solution for it. If not, will
it be added in the future?

2. Given the diversity of ALTREP classes, what is the best way to loop over
an ALTREP object? I hope there can be an all-in-one function which can get
the values from a vector as long as at least one of the above functions has
been defined, so package developers would not be bothered by tons of
`if-else` statement if they want their package to work with ALTREP. Since
it seems like there is no such function exist, what could be the best way
to do the loop under the current R version?

Best,
Jiefei

	[[alternative HTML version deleted]]


From cyc||cgroup-z1 @end|ng |rom y@hoo@com  Wed Aug 28 05:16:13 2019
From: cyc||cgroup-z1 @end|ng |rom y@hoo@com (Cyclic Group Z_1)
Date: Wed, 28 Aug 2019 03:16:13 +0000 (UTC)
Subject: [Rd] Conventions: Use of globals and main functions
In-Reply-To: <CAB8pepy-b3v+fdTrT6=ZpkXCXPhV14_Oi5=h1AaOB_A=-F7E+A@mail.gmail.com>
References: <1118624909.2128031.1566706119596.ref@mail.yahoo.com>
 <1118624909.2128031.1566706119596@mail.yahoo.com>
 <CAB8pepy-b3v+fdTrT6=ZpkXCXPhV14_Oi5=h1AaOB_A=-F7E+A@mail.gmail.com>
Message-ID: <1879879765.3690756.1566962173280@mail.yahoo.com>

Definitely, I agree that global variables have a place in programming. They play an especially important role in low-level software, such as embedded programming, as you mentioned, and?systems programming. I generally would disagree with anyone that says global variables should never be used, and they may be the best implementation option when something is "truly global."

However, in R scripting conventions, they are the default. I don't think it is controversial to say that in software engineering culture, there is a generally held principle that global variables should be minimized because they can be dangerous (granted, the original "Globals considered harmful" article is quite old, and many of the criticisms not applicable to modern languages). I do think it is equally important, though, to understand when to break this rule.

I like your suggestion of documenting this as an alternative option, though it seems the general sentiment is against this, which I respect.

Best,
CG


From cyc||cgroup-z1 @end|ng |rom y@hoo@com  Wed Aug 28 05:56:47 2019
From: cyc||cgroup-z1 @end|ng |rom y@hoo@com (Cyclic Group Z_1)
Date: Wed, 28 Aug 2019 03:56:47 +0000 (UTC)
Subject: [Rd] Conventions: Use of globals and main functions
In-Reply-To: <CAB-BFRp=G1GKc8DTQ9N=haBBy1=7QHMUze5GYd6x92ZdXj59nA@mail.gmail.com>
References: <1118624909.2128031.1566706119596.ref@mail.yahoo.com>
 <1118624909.2128031.1566706119596@mail.yahoo.com>
 <CAB-BFRp=G1GKc8DTQ9N=haBBy1=7QHMUze5GYd6x92ZdXj59nA@mail.gmail.com>
Message-ID: <1044532211.3694234.1566964607709@mail.yahoo.com>

>?That beeing said I think the main task of scripts is to get things done via running them end to end in a fresh session. Now, it very well may happen that a lot of stuff has to be done. Than splitting up scripts into subscripts and sourcing them from a meta script is a straightforward solution. It might also be that some functionality is put into functions to be reused in other places. This can be done by putting those function definitions into separate files. Than one cane use source wherever those functions?are needed. Now, putting stuff that runs code and scripts that define/provovide functions into the same script is a bad idea. Using the main()-idioms described might prevent this the problems stemming from mixing functions and function execution. But it would also encourage this mixing which is - I think, a bad idea anyways. 

I actually would agree entirely that files should not serve as both source files for re-used functions as well as application code. The suggestion for a main() idiom is merely to reduce variable scope and bring R practices more in line with generally recommended programming practices, not so that they can act as packages/modules/libraries. When I compared R scripts containing main functions to packages, I only mean in the sense that they help manage scope (the latter through package namespaces). Any other named functions besides main would be functions specifically tied to the script.?

I do see your point, though, that this could result in bad practice, namely the usage mixing you described.?

Best,
CG


From retep@me|@@ner @end|ng |rom gm@||@com  Wed Aug 28 09:24:43 2019
From: retep@me|@@ner @end|ng |rom gm@||@com (Peter Meissner)
Date: Wed, 28 Aug 2019 09:24:43 +0200
Subject: [Rd] Conventions: Use of globals and main functions
In-Reply-To: <1044532211.3694234.1566964607709@mail.yahoo.com>
References: <1118624909.2128031.1566706119596.ref@mail.yahoo.com>
 <1118624909.2128031.1566706119596@mail.yahoo.com>
 <CAB-BFRp=G1GKc8DTQ9N=haBBy1=7QHMUze5GYd6x92ZdXj59nA@mail.gmail.com>
 <1044532211.3694234.1566964607709@mail.yahoo.com>
Message-ID: <CAB-BFRqd0XXTKiiaqcFF+jJJU1Jjs8X+iJUdq1t0OT=uEAzbAQ@mail.gmail.com>

Firtst, I think that thinking about best practice advise and beeing able to
accomandate different usage scenarios is a good thing despite me arguing
against introducing the main()-idiom.

Let's have another turn on the global-environment is bad argument.

It has two parts:

(1) Glattering namespace. Glattering name space might become a problem
because you might end up having used all reasonable words already so one
has to extend the space for names with new namespaces. For scripting, this
usually should be no problem since one can always create more space through
the usage of environments - put code into a function, put objects into
environments, or write a package. Glattering name space might also become a
problem if things get complex. If your code base gets larger on name might
be overwritten by the other on accident. This is a problem that can be
solved by not simply extending the name space (more space) but by
structuring it - keeping related things together, hiding unused helpers
e.g. by putting them in a function, or an environment, or writing a
package.

Now, if we put everything into main() we have not solved much. Now instead
of 100 objects glattering the global environment we have e.g. 5 obejcts in
the global environment and 95 objects in the main()-function environment.

(2) Changing global state. A thing that is a little bit related to the
global environment is the idea of global state and the problems that arise
when changing global state. But the global environment in R is not the same
as a global state. First, all normal stuff in R (except environments, R6
objects, data.tables) are passed by copy (never mind how its implented
under the hood). So when I assign a value to a new name, this will behave
like if I made a copy - thus I simply do not care what happens to the value
of the original because my copy's value is independent. Next, it is
possible to misuse the global environment (or nay parent environment) as
global state via either explicitly using assign(..., ..., env =
globalenv()) or by using the <<- operator. Also, one has access to objects
of enclosing env?ronment when e.g. executing code in a function environment
but this is read only by default. Although this is possible and it is done
from time to time, this is not how things are done 99% of the time. The
common practice - and I would say best practice also - is to use pure
function that only depend on their inputs and do not change anything except
returing a value. Using pure functions mainly prevents 99% of the problems
with global state while using more name spaces does only chop these kind of
problems into smaller and thus more numerous problems.


Best, Peter

Am Mi., 28. Aug. 2019 um 05:56 Uhr schrieb Cyclic Group Z_1 <
cyclicgroup-z1 at yahoo.com>:

> > That beeing said I think the main task of scripts is to get things done
> via running them end to end in a fresh session. Now, it very well may
> happen that a lot of stuff has to be done. Than splitting up scripts into
> subscripts and sourcing them from a meta script is a straightforward
> solution. It might also be that some functionality is put into functions to
> be reused in other places. This can be done by putting those function
> definitions into separate files. Than one cane use source wherever those
> functions are needed. Now, putting stuff that runs code and scripts that
> define/provovide functions into the same script is a bad idea. Using the
> main()-idioms described might prevent this the problems stemming from
> mixing functions and function execution. But it would also encourage this
> mixing which is - I think, a bad idea anyways.
>
> I actually would agree entirely that files should not serve as both source
> files for re-used functions as well as application code. The suggestion for
> a main() idiom is merely to reduce variable scope and bring R practices
> more in line with generally recommended programming practices, not so that
> they can act as packages/modules/libraries. When I compared R scripts
> containing main functions to packages, I only mean in the sense that they
> help manage scope (the latter through package namespaces). Any other named
> functions besides main would be functions specifically tied to the script.
>
> I do see your point, though, that this could result in bad practice,
> namely the usage mixing you described.
>
> Best,
> CG
>

	[[alternative HTML version deleted]]


From g@bembecker @end|ng |rom gm@||@com  Wed Aug 28 13:36:49 2019
From: g@bembecker @end|ng |rom gm@||@com (Gabriel Becker)
Date: Wed, 28 Aug 2019 04:36:49 -0700
Subject: [Rd] What is the best way to loop over an ALTREP vector?
In-Reply-To: <CAGiFhPN+ncuPMY9UbEO+b0wis0EJ0R9AaWSB0By-CD3fNetO1A@mail.gmail.com>
References: <CAGiFhPN+ncuPMY9UbEO+b0wis0EJ0R9AaWSB0By-CD3fNetO1A@mail.gmail.com>
Message-ID: <CAD4oTHFhAoeRCu5g15DkLpdRr=PF9hLBHufOrh3CvF8E04qz=A@mail.gmail.com>

Jiefei,

I've been meaning to write up something about this so hopefully this will
be an impetus for me to actually do that, but until then, responses inline.


On Tue, Aug 27, 2019, 7:22 PM Wang Jiefei <szwjf08 at gmail.com> wrote:

> Hi devel team,
>
> I'm working on C/C++ level ALTREP compatibility for a package. The package
> previously used pointers to access the data of a SEXP, so it would not work
> for some ALTREP objects which do not have a pointer. I plan to rewrite the
> code and use functions like get_elt, get_region, and get_subset to access
> the values of a vector, so I have a few questions for ALTREP:
>
> 1. Since an ALTREP do not have to define all of the above
> functions(element, region, subset), is there any way to check which
> function has been defined for an ALTREP class? I did a search on
> RInternal.h and altrep.c but did not find a solution for it. If not, will
> it be added in the future?
>

Element and region are guaranteed to always be defined and work (for altrep
and non-altrep INTSXP, REALSXP, LGLSXPs, etc, we currently don't have
region for STRSXP or VECSXP, I believe). If the altrep class does not
provide them then default methods will be used, which may be inefficient in
some cases but will work. Subset is currently a forward looking stub, but
once implimented, that will also be guaranteed to work for all valid ALTREP
classes.


>
> 2. Given the diversity of ALTREP classes, what is the best way to loop over
> an ALTREP object? I hope there can be an all-in-one function which can get
> the values from a vector as long as at least one of the above functions has
> been defined, so package developers would not be bothered by tons of
> `if-else` statement if they want their package to work with ALTREP. Since
> it seems like there is no such function exist, what could be the best way
> to do the loop under the current R version?
>

The best way to loop over all SEXPs, which supports both altrep and
nonaltrep objects is, with the ITERATE_BY_REGION (which has been in R for a
number of released versions, at least since 3.5.0 I think) and the much
newer (devel only) ITERATE_BY_REGION_PARTIAL macros defined in
R_exts/Itermacros.h

The meaning of the arguments is as follows for ITERATE_BY_REGION_PARTIAL
are as follows (ITERATE_BY_REGION is the same except no strt, and nfull).


   - sx - C level variable name of the SEXP to iterate over
   - px - variable name to use for the pointer populated with data from a
   region of sx
   - idx - variable name to use for the "outer", batch counter in the for
   loop. This will contain the 0-indexed start position of the batch you're
   currently processing
   - nb - variable name to use for the current batch size. This will always
   either be GET_REGION_BUFFSIZE (512), or the number of elements remaining in
   the vector, whichever is smaller
   - etype - element (C) type, e.g., int, double, of the data
   - vtype - vector (access API) type, e.g, INTEGER, REAL
   - strt - the 0-indexed position in the vector to start iterating
   - nfull - the total number oif elements to iterate over from the vector
   - expr - the code to process a single batch (Which will do things to px,
   typically)


So code to perform badly implemented not good idea summing of REALSXP data
might look like

double sillysum(SEXP x) {

    double s = 0.0;

    ITERATE_BY_REGION(x, ptr, ind, nbatch, double, REAL,
        {

            for(int i = 0; i < nbatch; i++) { s = s + ptr[i];}
        })

     return s;
}

For meatier examples of ITERATE_BY_REGION's use in practice you can grep
the R sources. I know it is used in the implementations of the various
C-level summaries (summary.c), print and formatting functions, and anyNA.

Some things to remember

   - If you have an inner loop like the one above, your total position in
   the original vector is ind + i
   - ITERATE_BY_REGION always processes the whole vector, if you need to
   only do part of it yo'll either need custom breaking for both inner and
   outer loopsl, or in R-devel you can use ITERATE_BY_REGION_PARTIAL
   - Don't use the variants ending in 0, all they do is skip over things
   that are a good idea in the case of non-altreps (and some very specific
   altreps).

Hope that helps.

Best,
~G












> Best,
> Jiefei
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From therne@u @end|ng |rom m@yo@edu  Wed Aug 28 17:56:05 2019
From: therne@u @end|ng |rom m@yo@edu (Therneau, Terry M., Ph.D.)
Date: Wed, 28 Aug 2019 10:56:05 -0500
Subject: [Rd] R CMD check issue
Message-ID: <771925$ca6l3c@ironport10.mayo.edu>

I'm running "R CMD check" for 600+ of the packages that depend on survival, and at the end 
look for
 ??? grep Status *.Rcheck/00check.log? | grep ERROR

to find any that failed.?? But by accident I just looked at the log for the Greg package, 
which finishes with the lines found below.? Is the final note of WARNING rather than ERROR 
on purpose, or an error??? If the former, will adding a search for "Quitting from" suffice?

By the way, the failure shown was an (uncaught) bug in cox.zph wrt putting dimnames on one 
of the result matrices.

Terry T
----------------------

--- re-building ?timeSplitter.Rmd? using rmarkdown
Loading required package: forestplot
Loading required package: grid
Loading required package: checkmate
Loading required package: Gmisc
Loading required package: Rcpp
Loading required package: htmlTable

Attaching package: 'dplyr'

The following objects are masked from 'package:stats':

 ??? filter, lag

The following objects are masked from 'package:base':

 ??? intersect, setdiff, setequal, union

Quitting from lines 408-412 (timeSplitter.Rmd)
Error: processing vignette 'timeSplitter.Rmd' failed with diagnostics:
length of 'dimnames' [1] not equal to array extent
--- failed re-building ?timeSplitter.Rmd?

SUMMARY: processing the following file failed:
 ? ?timeSplitter.Rmd?

Error: Vignette re-building failed.
Execution halted

* checking PDF version of manual ... OK
* DONE

Status: 1 WARNING
See
?/home/therneau/research/surv/Hg/survsubmit/xtest/Greg.Rcheck/00check.log?
for details.



	[[alternative HTML version deleted]]


From cyc||cgroup-z1 @end|ng |rom y@hoo@com  Wed Aug 28 17:58:15 2019
From: cyc||cgroup-z1 @end|ng |rom y@hoo@com (Cyclic Group Z_1)
Date: Wed, 28 Aug 2019 15:58:15 +0000 (UTC)
Subject: [Rd] Conventions: Use of globals and main functions
In-Reply-To: <CAB-BFRqd0XXTKiiaqcFF+jJJU1Jjs8X+iJUdq1t0OT=uEAzbAQ@mail.gmail.com>
References: <1118624909.2128031.1566706119596.ref@mail.yahoo.com>
 <1118624909.2128031.1566706119596@mail.yahoo.com>
 <CAB-BFRp=G1GKc8DTQ9N=haBBy1=7QHMUze5GYd6x92ZdXj59nA@mail.gmail.com>
 <1044532211.3694234.1566964607709@mail.yahoo.com>
 <CAB-BFRqd0XXTKiiaqcFF+jJJU1Jjs8X+iJUdq1t0OT=uEAzbAQ@mail.gmail.com>
Message-ID: <2071959206.4006827.1567007895304@mail.yahoo.com>

I appreciate the well-thought-out comments.

To your first point, I am not sure what "glattering" means precisely (a Google search revealed nothing useful), but I assume it means something to the effect of overfilling the main namespace with too many names. Per Norm Matloff's counterpoint in The Art of R Programming regarding this issue, this is mostly avoided by well-defined, (sufficiently) long names. Also, when a program is properly modularized, one generally wouldn't have this many objects at the same time unless the complexity of a program demands it. You can, for example, use named function scope outside main or anonymous functions to limit variable scope to operations that need a given variable. Using main() with any named functions closely tied to a script defined outside it actually addresses this "glattering namespace" issue, since, if we treat the global scope as a main function instead of using a main() idiom, any functions that are defined in global scope will contain all global variables within its search path. Alternatively, one can put all named functions in a package; in some cases, however, it will make more sense to keep a function defined within the script. Unless you never modularize your code into functions and flatten everything out into a common namespace, using main would be helpful to avoid namespace-glattering. Maybe I'm missing something, but I'm not sure how namespace-glattering favors not using a main() idiom, since avoiding globals doesn't mean not structuring your code properly; it actually seems to favor using main(). Given any properly structured program (organizing functions as needed), the implementation that puts all variables into the global workspace (same as the top-level functions) will be less safe since all functions will contain all globals within its search path. (Unless, of course, every single function is put into a package).

To your second point, I agree that many of the issues associated with global state/environment are generally less problematic when using pure (or as pure as possible) functions. On a related note, lexically scoped functional languages (especially pure functional ones) generally encourage modularizing everything into functions, rather than having a lot of objects exposed to the top level (not to say that globals are not used, only that they are not the default choice). So the typical R way of doing this tends to disagree with how things are normally done in functional programming. Chopping our code into well-abstracted functions (and therefore namespaces) is the functional way to do things and helps to minimize the state to which any particular function has access. Organizing the functions we want to be pure so that they are not defined in the same environment in which they are called actually helps to ensure function purity in the input direction, since those functions will not have lexical-scope access to called variables. (That is, you may have written an impure function without realizing it; organizing functions so they are not defined in the same environment as when they are called helps to ensure purity.)

Perhaps I am mistaken, but in either case, your points actually favor a main() idiom, unless you take using main() to mean using main() with extra bits (e.g., flattening your code structure).

Admittedly, putting every single function into a package and not having any named functions in your script generally addresses all of these issues.?

Best,
CG


From retep@me|@@ner @end|ng |rom gm@||@com  Wed Aug 28 18:21:52 2019
From: retep@me|@@ner @end|ng |rom gm@||@com (Peter Meissner)
Date: Wed, 28 Aug 2019 18:21:52 +0200
Subject: [Rd] Conventions: Use of globals and main functions
In-Reply-To: <2071959206.4006827.1567007895304@mail.yahoo.com>
References: <1118624909.2128031.1566706119596.ref@mail.yahoo.com>
 <1118624909.2128031.1566706119596@mail.yahoo.com>
 <CAB-BFRp=G1GKc8DTQ9N=haBBy1=7QHMUze5GYd6x92ZdXj59nA@mail.gmail.com>
 <1044532211.3694234.1566964607709@mail.yahoo.com>
 <CAB-BFRqd0XXTKiiaqcFF+jJJU1Jjs8X+iJUdq1t0OT=uEAzbAQ@mail.gmail.com>
 <2071959206.4006827.1567007895304@mail.yahoo.com>
Message-ID: <CAB-BFRrp=UE6op-rOx=m9WdVL76G0p4qxVjRmofXLzUWxG8nwA@mail.gmail.com>

The point is, that there are several possible problems.

But.

One the one hand they are not really problematic in my opinion (I do not
care if my function has potential access to objects outside of its
environment because this access is read-only at worst and it's not common
practice to use this potential anyways).
On the other hand I am not sure what the main()-idiom would actually add to
the table other than allowing for the dual use of function definition and
function execution code in the same script - which we agreed upon is bad
practice.

Best, Peter

Am Mi., 28. Aug. 2019 um 17:58 Uhr schrieb Cyclic Group Z_1 <
cyclicgroup-z1 at yahoo.com>:

> I appreciate the well-thought-out comments.
>
> To your first point, I am not sure what "glattering" means precisely (a
> Google search revealed nothing useful), but I assume it means something to
> the effect of overfilling the main namespace with too many names. Per Norm
> Matloff's counterpoint in The Art of R Programming regarding this issue,
> this is mostly avoided by well-defined, (sufficiently) long names. Also,
> when a program is properly modularized, one generally wouldn't have this
> many objects at the same time unless the complexity of a program demands
> it. You can, for example, use named function scope outside main or
> anonymous functions to limit variable scope to operations that need a given
> variable. Using main() with any named functions closely tied to a script
> defined outside it actually addresses this "glattering namespace" issue,
> since, if we treat the global scope as a main function instead of using a
> main() idiom, any functions that are defined in global scope will contain
> all global variables within its search path. Alternatively, one can put all
> named functions in a package; in some cases, however, it will make more
> sense to keep a function defined within the script. Unless you never
> modularize your code into functions and flatten everything out into a
> common namespace, using main would be helpful to avoid
> namespace-glattering. Maybe I'm missing something, but I'm not sure how
> namespace-glattering favors not using a main() idiom, since avoiding
> globals doesn't mean not structuring your code properly; it actually seems
> to favor using main(). Given any properly structured program (organizing
> functions as needed), the implementation that puts all variables into the
> global workspace (same as the top-level functions) will be less safe since
> all functions will contain all globals within its search path. (Unless, of
> course, every single function is put into a package).
>
> To your second point, I agree that many of the issues associated with
> global state/environment are generally less problematic when using pure (or
> as pure as possible) functions. On a related note, lexically scoped
> functional languages (especially pure functional ones) generally encourage
> modularizing everything into functions, rather than having a lot of objects
> exposed to the top level (not to say that globals are not used, only that
> they are not the default choice). So the typical R way of doing this tends
> to disagree with how things are normally done in functional programming.
> Chopping our code into well-abstracted functions (and therefore namespaces)
> is the functional way to do things and helps to minimize the state to which
> any particular function has access. Organizing the functions we want to be
> pure so that they are not defined in the same environment in which they are
> called actually helps to ensure function purity in the input direction,
> since those functions will not have lexical-scope access to called
> variables. (That is, you may have written an impure function without
> realizing it; organizing functions so they are not defined in the same
> environment as when they are called helps to ensure purity.)
>
> Perhaps I am mistaken, but in either case, your points actually favor a
> main() idiom, unless you take using main() to mean using main() with extra
> bits (e.g., flattening your code structure).
>
> Admittedly, putting every single function into a package and not having
> any named functions in your script generally addresses all of these issues.
>
> Best,
> CG
>

	[[alternative HTML version deleted]]


From cyc||cgroup-z1 @end|ng |rom y@hoo@com  Wed Aug 28 18:31:48 2019
From: cyc||cgroup-z1 @end|ng |rom y@hoo@com (Cyclic Group Z_1)
Date: Wed, 28 Aug 2019 16:31:48 +0000 (UTC)
Subject: [Rd] Conventions: Use of globals and main functions
In-Reply-To: <CAB-BFRrp=UE6op-rOx=m9WdVL76G0p4qxVjRmofXLzUWxG8nwA@mail.gmail.com>
References: <1118624909.2128031.1566706119596.ref@mail.yahoo.com>
 <1118624909.2128031.1566706119596@mail.yahoo.com>
 <CAB-BFRp=G1GKc8DTQ9N=haBBy1=7QHMUze5GYd6x92ZdXj59nA@mail.gmail.com>
 <1044532211.3694234.1566964607709@mail.yahoo.com>
 <CAB-BFRqd0XXTKiiaqcFF+jJJU1Jjs8X+iJUdq1t0OT=uEAzbAQ@mail.gmail.com>
 <2071959206.4006827.1567007895304@mail.yahoo.com>
 <CAB-BFRrp=UE6op-rOx=m9WdVL76G0p4qxVjRmofXLzUWxG8nwA@mail.gmail.com>
Message-ID: <1800410709.4009163.1567009908005@mail.yahoo.com>

I meant that using a script both as a script and a library (sourcing into other files to serve as a package) is bad practice. I don't think having any functions in a script is necessarily bad practice.

Best,
CG


From hugh@p@r@on@ge @end|ng |rom gm@||@com  Wed Aug 28 18:36:38 2019
From: hugh@p@r@on@ge @end|ng |rom gm@||@com (Hugh Parsonage)
Date: Thu, 29 Aug 2019 02:36:38 +1000
Subject: [Rd] R CMD check issue
In-Reply-To: <771925$ca6l3c@ironport10.mayo.edu>
References: <771925$ca6l3c@ironport10.mayo.edu>
Message-ID: <CAJmOi+MKg97Qj0wTJZ+mTVNqxJFpt7KdhwR=CKdGxLjnsVkoog@mail.gmail.com>

The warning is that the vignette failed to be rebuilt due to an error in
its code. The error log was truncated.

Of course for practical purposes errors and warnings both constitute check
failures

On Thu, 29 Aug 2019 at 1:56 am, Therneau, Terry M., Ph.D. via R-devel <
r-devel at r-project.org> wrote:

> I'm running "R CMD check" for 600+ of the packages that depend on
> survival, and at the end
> look for
>      grep Status *.Rcheck/00check.log  | grep ERROR
>
> to find any that failed.   But by accident I just looked at the log for
> the Greg package,
> which finishes with the lines found below.  Is the final note of WARNING
> rather than ERROR
> on purpose, or an error?   If the former, will adding a search for
> "Quitting from" suffice?
>
> By the way, the failure shown was an (uncaught) bug in cox.zph wrt putting
> dimnames on one
> of the result matrices.
>
> Terry T
> ----------------------
>
> --- re-building ?timeSplitter.Rmd? using rmarkdown
> Loading required package: forestplot
> Loading required package: grid
> Loading required package: checkmate
> Loading required package: Gmisc
> Loading required package: Rcpp
> Loading required package: htmlTable
>
> Attaching package: 'dplyr'
>
> The following objects are masked from 'package:stats':
>
>      filter, lag
>
> The following objects are masked from 'package:base':
>
>      intersect, setdiff, setequal, union
>
> Quitting from lines 408-412 (timeSplitter.Rmd)
> Error: processing vignette 'timeSplitter.Rmd' failed with diagnostics:
> length of 'dimnames' [1] not equal to array extent
> --- failed re-building ?timeSplitter.Rmd?
>
> SUMMARY: processing the following file failed:
>    ?timeSplitter.Rmd?
>
> Error: Vignette re-building failed.
> Execution halted
>
> * checking PDF version of manual ... OK
> * DONE
>
> Status: 1 WARNING
> See
> ?/home/therneau/research/surv/Hg/survsubmit/xtest/Greg.Rcheck/00check.log?
> for details.
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From @nto|ne@|@br| @end|ng |rom gm@||@com  Thu Aug 29 13:05:59 2019
From: @nto|ne@|@br| @end|ng |rom gm@||@com (Ant F)
Date: Thu, 29 Aug 2019 13:05:59 +0200
Subject: [Rd] ?Syntax wrong about `?`'s precedence ?
Message-ID: <CAEKh8ugXyz4cmkGrVDc6wxtwR6E9HbEiS3H9qVHzPF7OGyzZ2Q@mail.gmail.com>

Dear all,

`?Syntax` documents that `?` has the lowest precedence, right under `=`.

Indeed it reads:

*The following unary and binary operators are defined. They are listed in
precedence groups, from highest to lowest.  *

and ends the list with

*<- <<-* *assignment (right to left)*
*=* *assignment (right to left)*
*?* *help (unary and binary)*
I believe it to be wrong, `=` has lower precedence than `?`.

See the following example :

    `?` <- `+`
    x = 2 ? 3
    x
    #> [1] 5

We see that `2 ? 3` is evaluated first, then the result is assigned to x,
showing
higher precedence for `?`.

Compare it to the similar code using `<-` :

    x <- 2 ? 3
    #> [1] 5
    x
    #> [1] 2

Here first `x <- 2` is evaluated, then its output is added to 3, and the
result
`5` is printed. and we verify that `x` is still `2`. Showing lower
precedence
for `?` consistent with the doc.

Hadley Wickham's package `lobstr` makes it easy to compare the parse trees:

    lobstr::ast({x = 2 ? 3})
    #> o-`{`
    #> \-o-`=`
    #>   +-x
    #>   \-o-`?`
    #>     +-2
    #>     \-3

    lobstr::ast({x <- 2 ? 3})
    #> o-`{`
    #> \-o-`?`
    #>   +-o-`<-`
    #>   | +-x
    #>   | \-2
    #>   \-3

Best regards,

Antoine

	[[alternative HTML version deleted]]


From tdhock5 @end|ng |rom gm@||@com  Thu Aug 29 23:00:18 2019
From: tdhock5 @end|ng |rom gm@||@com (Toby Hocking)
Date: Thu, 29 Aug 2019 14:00:18 -0700
Subject: [Rd] Feature request: non-dropping regmatches/strextract
In-Reply-To: <2012653205.221487.1565848601638@mail.yahoo.com>
References: <2012653205.221487.1565848601638.ref@mail.yahoo.com>
 <2012653205.221487.1565848601638@mail.yahoo.com>
Message-ID: <CALK03d2cCoAboDBmr5dhR9+kjGh5=Eg5QAHmKc-qJYm_iGO5mw@mail.gmail.com>

if you want "to extract regex matches into a new column in a data.frame"
then there are some package functions which do exactly that. three examples
are namedCapture::df_match_variable, rematch2::bind_re_match, and
tidyr::extract. For a more detailed discussion see my R journal submission
(under review) about regular expression packages,
https://raw.githubusercontent.com/tdhock/namedCapture-article/master/RJwrapper.pdf
Comments/suggestions welcome.

On Thu, Aug 15, 2019 at 12:15 AM Cyclic Group Z_1 via R-devel <
r-devel at r-project.org> wrote:

> A very common use case for regmatches is to extract regex matches into a
> new column in a data.frame (or data.table, etc.) or otherwise use the
> extracted strings alongside the input. However, the default behavior is to
> drop empty matches, which results in mismatches in column length if
> reassignment is done without subsetting.
>
> For consistency with other R functions and compatibility with this use
> case, it would be nice if regmatches did not automatically drop empty
> matches and would instead insert an NA_character_ value (similar to
> stringr::str_extract). This alternative regmatches could be implemented
> through an optional drop argument, a new function, or mentioned in the
> documentation (a la resample in ?sample).
>
> Alternatively, at the moment, there is a non-exported function strextract
> in utils which is very similar to stringr::str_extract. It would be great
> if this function, once exported, were to include a drop argument to prevent
> dropping positions with no matches.
>
> An example solution (last option):
>
> strextract <- function(pattern, x, perl = FALSE, useBytes = FALSE, drop =
> T) {
>  m <- regexec(pattern, x, perl=perl, useBytes=useBytes)
>  result <- regmatches(x, m)
>
>  if(isTRUE(drop)){
>  unlist(result)
>  } else if(isFALSE(drop)) {
>  unlist({result[lengths(result)==0] <- NA_character_; result})
>  } else {
>  stop("Invalid argument for `drop`")
>  }
> }
>
> Based on Ricardo Saporta's response to How to prevent regmatches drop non
> matches?
>
> --CG
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From cyc||cgroup-z1 @end|ng |rom y@hoo@com  Thu Aug 29 23:19:22 2019
From: cyc||cgroup-z1 @end|ng |rom y@hoo@com (Cyclic Group Z_1)
Date: Thu, 29 Aug 2019 21:19:22 +0000 (UTC)
Subject: [Rd] Feature request: non-dropping regmatches/strextract
In-Reply-To: <CALK03d2cCoAboDBmr5dhR9+kjGh5=Eg5QAHmKc-qJYm_iGO5mw@mail.gmail.com>
References: <2012653205.221487.1565848601638.ref@mail.yahoo.com>
 <2012653205.221487.1565848601638@mail.yahoo.com>
 <CALK03d2cCoAboDBmr5dhR9+kjGh5=Eg5QAHmKc-qJYm_iGO5mw@mail.gmail.com>
Message-ID: <102772513.32513.1567113562904@mail.yahoo.com>

Thank you, I am aware that there are packages that can accomplish this. I mentioned stringr::str_extract as a function that does not drop empty matches. I think that the behavior of regmatches(..., regexpr(...))?in base R should permit an option to prevent dropping of empty matches both for sake of consistency with the rest of the language (missing data does not yield a dropped index in other sorts of R functions, and an empty match conceptually corresponds with missing data) and facility of use in data.frames. The behavior of regmatches(..., gregexpr(...)) is not objectionable to me, as lists do not drop indices when they contain character(0) vectors. Alternatively, perhaps this should be reflected in the (currently non-exported) strextract.

Best,
CG


From |@wrence@m|ch@e| @end|ng |rom gene@com  Thu Aug 29 23:29:25 2019
From: |@wrence@m|ch@e| @end|ng |rom gene@com (Michael Lawrence)
Date: Thu, 29 Aug 2019 14:29:25 -0700
Subject: [Rd] Feature request: non-dropping regmatches/strextract
In-Reply-To: <102772513.32513.1567113562904@mail.yahoo.com>
References: <2012653205.221487.1565848601638.ref@mail.yahoo.com>
 <2012653205.221487.1565848601638@mail.yahoo.com>
 <CALK03d2cCoAboDBmr5dhR9+kjGh5=Eg5QAHmKc-qJYm_iGO5mw@mail.gmail.com>
 <102772513.32513.1567113562904@mail.yahoo.com>
Message-ID: <CAOQ5NydKtocPcz-3zVfZMo5K0jkbsF+R2iBvzzPO7fiP=+ZHQg@mail.gmail.com>

I'd be happy to entertain patches or at least more specific
suggestions to improve strextract() and strcapture(). I hadn't
exported strextract(), because I wasn't quite sure how it should
behave. This feedback should be helpful.

Thanks,
Michael

On Thu, Aug 29, 2019 at 2:20 PM Cyclic Group Z_1 via R-devel
<r-devel at r-project.org> wrote:
>
> Thank you, I am aware that there are packages that can accomplish this. I mentioned stringr::str_extract as a function that does not drop empty matches. I think that the behavior of regmatches(..., regexpr(...)) in base R should permit an option to prevent dropping of empty matches both for sake of consistency with the rest of the language (missing data does not yield a dropped index in other sorts of R functions, and an empty match conceptually corresponds with missing data) and facility of use in data.frames. The behavior of regmatches(..., gregexpr(...)) is not objectionable to me, as lists do not drop indices when they contain character(0) vectors. Alternatively, perhaps this should be reflected in the (currently non-exported) strextract.
>
> Best,
> CG
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Michael Lawrence
Scientist, Bioinformatics and Computational Biology
Genentech, A Member of the Roche Group
Office +1 (650) 225-7760
michafla at gene.com

Join Genentech on LinkedIn | Twitter | Facebook | Instagram | YouTube


From cyc||cgroup-z1 @end|ng |rom y@hoo@com  Fri Aug 30 00:26:57 2019
From: cyc||cgroup-z1 @end|ng |rom y@hoo@com (Cyclic Group Z_1)
Date: Thu, 29 Aug 2019 22:26:57 +0000 (UTC)
Subject: [Rd] Feature request: non-dropping regmatches/strextract
In-Reply-To: <CAOQ5NydKtocPcz-3zVfZMo5K0jkbsF+R2iBvzzPO7fiP=+ZHQg@mail.gmail.com>
References: <2012653205.221487.1565848601638.ref@mail.yahoo.com>
 <2012653205.221487.1565848601638@mail.yahoo.com>
 <CALK03d2cCoAboDBmr5dhR9+kjGh5=Eg5QAHmKc-qJYm_iGO5mw@mail.gmail.com>
 <102772513.32513.1567113562904@mail.yahoo.com>
 <CAOQ5NydKtocPcz-3zVfZMo5K0jkbsF+R2iBvzzPO7fiP=+ZHQg@mail.gmail.com>
Message-ID: <1828482902.51488.1567117617120@mail.yahoo.com>

Thank you! I greatly appreciate your consideration, though of course it is up to you. I think many people switch to stringr/stringi simply because functions in those packages have some consistent design choices, for example, they do not drop empty/missing matches, which facilitates array-based programming. For example, in the cases where one needs to make a new column in a data.frame (data.table, tibble, etc.) of regex extractions. Or in any other case where there needs to be an element-wise correspondence between input and output. I think insertion of NA_character_ to prevent dropping indices seems like the natural choice for an array language (which, I think, motivated the creation of stringr/stringi). While those are great packages and this behavior can be easily replicated with simple wrappers, string operations are normally easy to accomplish in base languages, so this seems like something that would be appropriate to have in base. For example, MATLAB and Pandas regex both allow non-dropping empty matches (though of course I acknowledge Pandas is not a base language).

Best,
CG


From |@wrence@m|ch@e| @end|ng |rom gene@com  Fri Aug 30 05:44:02 2019
From: |@wrence@m|ch@e| @end|ng |rom gene@com (Michael Lawrence)
Date: Thu, 29 Aug 2019 20:44:02 -0700
Subject: [Rd] Feature request: non-dropping regmatches/strextract
In-Reply-To: <1828482902.51488.1567117617120@mail.yahoo.com>
References: <2012653205.221487.1565848601638.ref@mail.yahoo.com>
 <2012653205.221487.1565848601638@mail.yahoo.com>
 <CALK03d2cCoAboDBmr5dhR9+kjGh5=Eg5QAHmKc-qJYm_iGO5mw@mail.gmail.com>
 <102772513.32513.1567113562904@mail.yahoo.com>
 <CAOQ5NydKtocPcz-3zVfZMo5K0jkbsF+R2iBvzzPO7fiP=+ZHQg@mail.gmail.com>
 <1828482902.51488.1567117617120@mail.yahoo.com>
Message-ID: <CAOQ5NycHctjtNee0uWFKDyGehzWBC6-WXJbe4QxTkOQZ=k=3Xg@mail.gmail.com>

Just started thinking about this. The name of regmatches() suggests
that it will only extract the matches but not return anything for the
non-matches. We might need another function that returns a value for
non-matches. Perhaps the value should be the empty string for
non-matches and NA for matches to NA. The rationale is that we
delegate to regexpr() (at least conceptually), and it returns a
"matching region" which would be empty when there is no match. We
could allow strcapture() to accept an atomic vector as a prototype,
which would do what you want for regexec() (NA on no match, empty
string on empty capture). Then we could call the regexpr()-based
function strextract().

What do you think?

Michael

On Thu, Aug 29, 2019 at 3:27 PM Cyclic Group Z_1
<cyclicgroup-z1 at yahoo.com> wrote:
>
> Thank you! I greatly appreciate your consideration, though of course it is up to you. I think many people switch to stringr/stringi simply because functions in those packages have some consistent design choices, for example, they do not drop empty/missing matches, which facilitates array-based programming. For example, in the cases where one needs to make a new column in a data.frame (data.table, tibble, etc.) of regex extractions. Or in any other case where there needs to be an element-wise correspondence between input and output. I think insertion of NA_character_ to prevent dropping indices seems like the natural choice for an array language (which, I think, motivated the creation of stringr/stringi). While those are great packages and this behavior can be easily replicated with simple wrappers, string operations are normally easy to accomplish in base languages, so this seems like something that would be appropriate to have in base. For example, MATLAB and Pandas regex both allow non-dropping empty matches (though of course I acknowledge Pandas is not a base language).
>
> Best,
> CG



-- 
Michael Lawrence
Scientist, Bioinformatics and Computational Biology
Genentech, A Member of the Roche Group
Office +1 (650) 225-7760
michafla at gene.com

Join Genentech on LinkedIn | Twitter | Facebook | Instagram | YouTube


From S@E|||@on @end|ng |rom LGCGroup@com  Fri Aug 30 13:40:58 2019
From: S@E|||@on @end|ng |rom LGCGroup@com (Stephen Ellison)
Date: Fri, 30 Aug 2019 11:40:58 +0000
Subject: [Rd] ?Syntax wrong about `?`'s precedence ?
In-Reply-To: <CAEKh8ugXyz4cmkGrVDc6wxtwR6E9HbEiS3H9qVHzPF7OGyzZ2Q@mail.gmail.com>
References: <CAEKh8ugXyz4cmkGrVDc6wxtwR6E9HbEiS3H9qVHzPF7OGyzZ2Q@mail.gmail.com>
Message-ID: <7d4a921ac2594ecf83944eb594cbfe97@GBDCVPEXC08.corp.lgc-group.com>

> From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of Ant F
> Sent: 29 August 2019 12:06
> To: r-devel at r-project.org
> Subject: [Rd] ?Syntax wrong about `?`'s precedence ?
> ...
> See the following example :
> 
>     `?` <- `+`

I'm curious; What did you expect to happen if you replace the function '?' with the operator '+' ?
? is surely now being evaluated as a user-defined function and not as an operator. 
Would you expect the results of doing that to be the same as evaluation without replacement?

S Ellison




*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From wdun|@p @end|ng |rom t|bco@com  Fri Aug 30 18:02:02 2019
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Fri, 30 Aug 2019 09:02:02 -0700
Subject: [Rd] ?Syntax wrong about `?`'s precedence ?
In-Reply-To: <7d4a921ac2594ecf83944eb594cbfe97@GBDCVPEXC08.corp.lgc-group.com>
References: <CAEKh8ugXyz4cmkGrVDc6wxtwR6E9HbEiS3H9qVHzPF7OGyzZ2Q@mail.gmail.com>
 <7d4a921ac2594ecf83944eb594cbfe97@GBDCVPEXC08.corp.lgc-group.com>
Message-ID: <CAF8bMcYxu+iuKyDZeYbtczimd+1nGBO-VjbTjkv9Va-eBnUhKw@mail.gmail.com>

Precedence is a property of the parser and has nothing to do with the
semantics assigned to various symbols.  Using just core R functions you can
see the precedence of '?' is between those of '=' and '<-'.

> # '=' has lower precedence than '?'
> str(as.list(parse(text="a ? b = c")[[1]]))
List of 3
 $ : symbol =
 $ : language `?`(a, b)
 $ : symbol c
> str(as.list(parse(text="a = b ? c")[[1]]))
List of 3
 $ : symbol =
 $ : symbol a
 $ : language `?`(b, c)
> # '<-' has higher precedence than '?'
> str(as.list(parse(text="a ? b <- c")[[1]]))
List of 3
 $ : symbol ?
 $ : symbol a
 $ : language b <- c
> str(as.list(parse(text="a <- b ? c")[[1]]))
List of 3
 $ : symbol ?
 $ : language a <- b
 $ : symbol c

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Aug 30, 2019 at 4:41 AM Stephen Ellison <S.Ellison at lgcgroup.com>
wrote:

> > From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of Ant F
> > Sent: 29 August 2019 12:06
> > To: r-devel at r-project.org
> > Subject: [Rd] ?Syntax wrong about `?`'s precedence ?
> > ...
> > See the following example :
> >
> >     `?` <- `+`
>
> I'm curious; What did you expect to happen if you replace the function '?'
> with the operator '+' ?
> ? is surely now being evaluated as a user-defined function and not as an
> operator.
> Would you expect the results of doing that to be the same as evaluation
> without replacement?
>
> S Ellison
>
>
>
>
> *******************************************************************
> This email and any attachments are confidential. Any u...{{dropped:10}}


From kev|nu@hey @end|ng |rom gm@||@com  Fri Aug 30 18:32:27 2019
From: kev|nu@hey @end|ng |rom gm@||@com (Kevin Ushey)
Date: Fri, 30 Aug 2019 09:32:27 -0700
Subject: [Rd] ?Syntax wrong about `?`'s precedence ?
In-Reply-To: <CAF8bMcYxu+iuKyDZeYbtczimd+1nGBO-VjbTjkv9Va-eBnUhKw@mail.gmail.com>
References: <CAEKh8ugXyz4cmkGrVDc6wxtwR6E9HbEiS3H9qVHzPF7OGyzZ2Q@mail.gmail.com>
 <7d4a921ac2594ecf83944eb594cbfe97@GBDCVPEXC08.corp.lgc-group.com>
 <CAF8bMcYxu+iuKyDZeYbtczimd+1nGBO-VjbTjkv9Va-eBnUhKw@mail.gmail.com>
Message-ID: <CAJXgQP187iVBz79ZJ+_VEGnteTs=WAtqwY=ZPoawLd1enWF+1A@mail.gmail.com>

See also: https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16710

On Fri, Aug 30, 2019 at 9:02 AM William Dunlap via R-devel
<r-devel at r-project.org> wrote:
>
> Precedence is a property of the parser and has nothing to do with the
> semantics assigned to various symbols.  Using just core R functions you can
> see the precedence of '?' is between those of '=' and '<-'.
>
> > # '=' has lower precedence than '?'
> > str(as.list(parse(text="a ? b = c")[[1]]))
> List of 3
>  $ : symbol =
>  $ : language `?`(a, b)
>  $ : symbol c
> > str(as.list(parse(text="a = b ? c")[[1]]))
> List of 3
>  $ : symbol =
>  $ : symbol a
>  $ : language `?`(b, c)
> > # '<-' has higher precedence than '?'
> > str(as.list(parse(text="a ? b <- c")[[1]]))
> List of 3
>  $ : symbol ?
>  $ : symbol a
>  $ : language b <- c
> > str(as.list(parse(text="a <- b ? c")[[1]]))
> List of 3
>  $ : symbol ?
>  $ : language a <- b
>  $ : symbol c
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Fri, Aug 30, 2019 at 4:41 AM Stephen Ellison <S.Ellison at lgcgroup.com>
> wrote:
>
> > > From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of Ant F
> > > Sent: 29 August 2019 12:06
> > > To: r-devel at r-project.org
> > > Subject: [Rd] ?Syntax wrong about `?`'s precedence ?
> > > ...
> > > See the following example :
> > >
> > >     `?` <- `+`
> >
> > I'm curious; What did you expect to happen if you replace the function '?'
> > with the operator '+' ?
> > ? is surely now being evaluated as a user-defined function and not as an
> > operator.
> > Would you expect the results of doing that to be the same as evaluation
> > without replacement?
> >
> > S Ellison
> >
> >
> >
> >
> > *******************************************************************
> > This email and any attachments are confidential. Any u...{{dropped:10}}
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From pd@|gd @end|ng |rom gm@||@com  Fri Aug 30 19:45:45 2019
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Fri, 30 Aug 2019 19:45:45 +0200
Subject: [Rd] ?Syntax wrong about `?`'s precedence ?
In-Reply-To: <CAJXgQP187iVBz79ZJ+_VEGnteTs=WAtqwY=ZPoawLd1enWF+1A@mail.gmail.com>
References: <CAEKh8ugXyz4cmkGrVDc6wxtwR6E9HbEiS3H9qVHzPF7OGyzZ2Q@mail.gmail.com>
 <7d4a921ac2594ecf83944eb594cbfe97@GBDCVPEXC08.corp.lgc-group.com>
 <CAF8bMcYxu+iuKyDZeYbtczimd+1nGBO-VjbTjkv9Va-eBnUhKw@mail.gmail.com>
 <CAJXgQP187iVBz79ZJ+_VEGnteTs=WAtqwY=ZPoawLd1enWF+1A@mail.gmail.com>
Message-ID: <334017CF-CAE8-4270-8A52-BDD8B02C3DB3@gmail.com>

...and 14955, which seems to have the explanation (but was marked as closed/fixed??). The parser does list '?' as lower precedence than '=', but '='-assignments are not normal 'expr's which can appear as arguments to '?'. (Presumably because of named arguments: f(a=b) differs from f(a<-b).)  

Other tokens which have lower precedence than assignments are flow-control items, IF ELSE WHILE FOR REPEAT, but I don't see any way to confuse them in the same way as '?'.

It might be possible to resolve the situation by specifying '?' syntax explicitly as
expr_or_assign '?' expr_or_assign, but, well, "There be Tygers here"...

-pd


> On 30 Aug 2019, at 18:32 , Kevin Ushey <kevinushey at gmail.com> wrote:
> 
> See also: https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16710
> 
> On Fri, Aug 30, 2019 at 9:02 AM William Dunlap via R-devel
> <r-devel at r-project.org> wrote:
>> 
>> Precedence is a property of the parser and has nothing to do with the
>> semantics assigned to various symbols.  Using just core R functions you can
>> see the precedence of '?' is between those of '=' and '<-'.
>> 
>>> # '=' has lower precedence than '?'
>>> str(as.list(parse(text="a ? b = c")[[1]]))
>> List of 3
>> $ : symbol =
>> $ : language `?`(a, b)
>> $ : symbol c
>>> str(as.list(parse(text="a = b ? c")[[1]]))
>> List of 3
>> $ : symbol =
>> $ : symbol a
>> $ : language `?`(b, c)
>>> # '<-' has higher precedence than '?'
>>> str(as.list(parse(text="a ? b <- c")[[1]]))
>> List of 3
>> $ : symbol ?
>> $ : symbol a
>> $ : language b <- c
>>> str(as.list(parse(text="a <- b ? c")[[1]]))
>> List of 3
>> $ : symbol ?
>> $ : language a <- b
>> $ : symbol c
>> 
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>> 
>> 
>> On Fri, Aug 30, 2019 at 4:41 AM Stephen Ellison <S.Ellison at lgcgroup.com>
>> wrote:
>> 
>>>> From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of Ant F
>>>> Sent: 29 August 2019 12:06
>>>> To: r-devel at r-project.org
>>>> Subject: [Rd] ?Syntax wrong about `?`'s precedence ?
>>>> ...
>>>> See the following example :
>>>> 
>>>>    `?` <- `+`
>>> 
>>> I'm curious; What did you expect to happen if you replace the function '?'
>>> with the operator '+' ?
>>> ? is surely now being evaluated as a user-defined function and not as an
>>> operator.
>>> Would you expect the results of doing that to be the same as evaluation
>>> without replacement?
>>> 
>>> S Ellison
>>> 
>>> 
>>> 
>>> 
>>> *******************************************************************
>>> This email and any attachments are confidential. Any u...{{dropped:10}}
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From j|ox @end|ng |rom mcm@@ter@c@  Fri Aug 30 20:11:29 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Fri, 30 Aug 2019 18:11:29 +0000
Subject: [Rd] inconsistent handling of factor, character,
 and logical predictors in lm()
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836CF0E5B@FHSDB2D11-2.csu.mcmaster.ca>

Dear R-devel list members,

I've discovered an inconsistency in how lm() and similar functions handle logical predictors as opposed to factor or character predictors. An "lm" object for a model that includes factor or character predictors includes the levels of a factor or unique values of a character predictor in the $xlevels component of the object, but not the FALSE/TRUE values for a logical predictor even though the latter is treated as a factor in the fit.

For example:

------------ snip --------------

> m1 <- lm(Sepal.Length ~ Sepal.Width + Species, data=iris)
> m1$xlevels
$Species
[1] "setosa"     "versicolor" "virginica" 
 
> m2 <- lm(Sepal.Length ~ Sepal.Width + as.character(Species), data=iris)
> m2$xlevels
$`as.character(Species)`
[1] "setosa"     "versicolor" "virginica" 

> m3 <- lm(Sepal.Length ~ Sepal.Width + I(Species == "setosa"), data=iris)
> m3$xlevels
named list()

> m3

Call:
lm(formula = Sepal.Length ~ Sepal.Width + I(Species == "setosa"), 
    data = iris)

Coefficients:
               (Intercept)                 Sepal.Width  I(Species == "setosa")TRUE  
                    3.5571                      0.9418                     -1.7797  

------------ snip --------------

I believe that the culprit is .getXlevels(), which makes provision for factor and character predictors but not for logical predictors:

------------ snip --------------

> .getXlevels
function (Terms, m) 
{
    xvars <- vapply(attr(Terms, "variables"), deparse2, 
        "")[-1L]
    if ((yvar <- attr(Terms, "response")) > 0) 
        xvars <- xvars[-yvar]
    if (length(xvars)) {
        xlev <- lapply(m[xvars], function(x) if (is.factor(x)) 
            levels(x)
        else if (is.character(x)) 
            levels(as.factor(x)))
        xlev[!vapply(xlev, is.null, NA)]
    }
}

------------ snip --------------

It would be simple to modify the last test in .getXlevels to 

	else if (is.character(x) || is.logical(x))

which would cause .getXlevels() to return c("FALSE", "TRUE") (assuming both values are present in the data). I'd find that sufficient, but alternatively there could be a separate test for logical predictors that returns c(FALSE, TRUE).

I discovered this issue when a function in the effects package failed for a model with a logical predictor. Although it's possible to program around the problem, I think that it would be better to handle factors, character predictors, and logical predictors consistently.

Best,
 John

--------------------------------------
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: socialsciences.mcmaster.ca/jfox/


From wdun|@p @end|ng |rom t|bco@com  Sat Aug 31 00:35:54 2019
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Fri, 30 Aug 2019 15:35:54 -0700
Subject: [Rd] New lazyload rdx key type: list(eagerKey=, lazyKeys=)
Message-ID: <CAF8bMcZ7RXPqcNZRXwzVsXNJcvEGiBHgDiOLjNGWod7a-x4kRQ@mail.gmail.com>

Prior to R-3.6.0 the keys in the lazyload key files, e.g.
pkg/data/Rdata.rdx or pkg/R/pkg.rdx, seemed to all be 2-long integer
vectors.  Now they can be lists.  The ones I have seen have two components,
"eagerKey" is a 2-long integer vector and "lazyKeys" is a named list of
2-long integer vectors.

> rdx <- readRDS(system.file(package="survival", "data", "Rdata.rdx"))
> str(Filter(is.list, rdx$references))
List of 2
 $ env::1:List of 2
  ..$ eagerKey: int [1:2] 273691 183
  ..$ lazyKeys:List of 1
  .. ..$ lines: int [1:2] 273874 284
 $ env::2:List of 2
  ..$ eagerKey: int [1:2] 473142 166
  ..$ lazyKeys:List of 1
  .. ..$ lines: int [1:2] 473308 310

or

>  rdx <- readRDS(system.file(package="lambda.r", "R", "lambda.r.rdx"))
> length(Filter(is.integer, rdx$references))
[1] 4
> str(Filter(Negate(is.integer), rdx$references))
List of 5
 $ env::5:List of 2
  ..$ eagerKey: int [1:2] 28278 328
  ..$ lazyKeys:List of 2
  .. ..$ lines    : int [1:2] 28606 80
  .. ..$ parseData: int [1:2] 28686 389
 $ env::6:List of 2
  ..$ eagerKey: int [1:2] 29075 327
  ..$ lazyKeys:List of 2
  .. ..$ lines    : int [1:2] 29402 71
  .. ..$ parseData: int [1:2] 29473 321
 $ env::7:List of 2
  ..$ eagerKey: int [1:2] 29794 325
  ..$ lazyKeys:List of 2
  .. ..$ lines    : int [1:2] 30119 117
  .. ..$ parseData: int [1:2] 30236 752
... many more ...

All the ones I've seen involve the environment in srcref attributes and
most packages do not keep that.  Will these be used for more sorts of
environments in the future?

What is the meaning of the lazyKeys?  Are these stored as promises until
needed or is there some special option to never or always load them?

Bill Dunlap
TIBCO Software
wdunlap tibco.com

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Sat Aug 31 02:20:33 2019
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sat, 31 Aug 2019 12:20:33 +1200
Subject: [Rd] inconsistent handling of factor, character,
 and logical predictors in lm()
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC836CF0E5B@FHSDB2D11-2.csu.mcmaster.ca>
References: <ACD1644AA6C67E4FBD0C350625508EC836CF0E5B@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CAB8pepxHcs6gzhkCQsHZh1ZUmPSXPQyTkYs=K+fmK=M1Zicr3Q@mail.gmail.com>

> I think that it would be better to handle factors, character predictors, and logical predictors consistently.

"logical predictors" can be regarded as categorical or continuous (i.e. 0 or 1).
And the model matrix should be the same, either way.

I think the first question to be asked is, which is the best approach,
categorical or continuous?
The continuous approach seems simpler and more efficient to me, but
output from the categorical approach may be more intuitive, for some
people.

I note that the use factors and characters, doesn't necessarily
produce consistent output, for $xlevels.
(Because factors can have their levels re-ordered).


From j|ox @end|ng |rom mcm@@ter@c@  Sat Aug 31 17:54:24 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Sat, 31 Aug 2019 15:54:24 +0000
Subject: [Rd] inconsistent handling of factor, character,
 and logical predictors in lm()
In-Reply-To: <CAB8pepxHcs6gzhkCQsHZh1ZUmPSXPQyTkYs=K+fmK=M1Zicr3Q@mail.gmail.com>
References: <ACD1644AA6C67E4FBD0C350625508EC836CF0E5B@FHSDB2D11-2.csu.mcmaster.ca>
 <CAB8pepxHcs6gzhkCQsHZh1ZUmPSXPQyTkYs=K+fmK=M1Zicr3Q@mail.gmail.com>
Message-ID: <6E6A225D-E514-4980-A454-1BD2D77FC04B@mcmaster.ca>

Dear Abby,

> On Aug 30, 2019, at 8:20 PM, Abby Spurdle <spurdle.a at gmail.com> wrote:
> 
>> I think that it would be better to handle factors, character predictors, and logical predictors consistently.
> 
> "logical predictors" can be regarded as categorical or continuous (i.e. 0 or 1).
> And the model matrix should be the same, either way.

I think that you're mistaking a coincidence for a principle. The coincidence is that FALSE/TRUE coerces to 0/1 and sorts to FALSE, TRUE. Functions like lm() treat logical predictors as factors, *not* as numerical variables. 

That one would get the same coefficient in either case is a consequence of the coincidence and the fact that the default contrasts for unordered factors are contr.treatment(). For example, if you changed the contrasts option, you'd get a different estimate (though of course a model with the same fit to the data and an equivalent interpretation):

------------ snip --------------

> options(contrasts=c("contr.sum", "contr.poly"))
> m3 <- lm(Sepal.Length ~ Sepal.Width + I(Species == "setosa"), data=iris)
> m3

Call:
lm(formula = Sepal.Length ~ Sepal.Width + I(Species == "setosa"), 
    data = iris)

Coefficients:
            (Intercept)              Sepal.Width  I(Species == "setosa")1  
                 2.6672                   0.9418                   0.8898  

> head(model.matrix(m3))
  (Intercept) Sepal.Width I(Species == "setosa")1
1           1         3.5                      -1
2           1         3.0                      -1
3           1         3.2                      -1
4           1         3.1                      -1
5           1         3.6                      -1
6           1         3.9                      -1
> tail(model.matrix(m3))
    (Intercept) Sepal.Width I(Species == "setosa")1
145           1         3.3                       1
146           1         3.0                       1
147           1         2.5                       1
148           1         3.0                       1
149           1         3.4                       1
150           1         3.0                       1

> lm(Sepal.Length ~ Sepal.Width + as.numeric(Species == "setosa"), data=iris)

Call:
lm(formula = Sepal.Length ~ Sepal.Width + as.numeric(Species == 
    "setosa"), data = iris)

Coefficients:
                    (Intercept)                      Sepal.Width  as.numeric(Species == "setosa")  
                         3.5571                           0.9418                          -1.7797  

> -2*coef(m3)[3]
I(Species == "setosa")1 
              -1.779657 

------------ snip --------------


> 
> I think the first question to be asked is, which is the best approach, 
> categorical or continuous?
> The continuous approach seems simpler and more efficient to me, but
> output from the categorical approach may be more intuitive, for some
> people.

I think that this misses the point I was trying to make: lm() et al. treat logical variables as factors, not as numerical predictors. One could argue about what's the better approach but not about what lm() does. BTW, I prefer treating a logical predictor as a factor because the predictor is essentially categorical.

> 
> I note that the use factors and characters, doesn't necessarily
> produce consistent output, for $xlevels.
> (Because factors can have their levels re-ordered).

Again, this misses the point: Both factors and character predictors produce elements in $xlevels; logical predictors do not, even though they are treated in the model as factors. That factors have levels that aren't necessarily ordered alphabetically is a reason that I prefer using factors to using character predictors, but this has nothing to do with the point I was trying to make about $xlevels.

Best,
 John

  -------------------------------------------------
  John Fox, Professor Emeritus
  McMaster University
  Hamilton, Ontario, Canada
  Web: http::/socserv.mcmaster.ca/jfox


From wdun|@p @end|ng |rom t|bco@com  Sat Aug 31 19:21:01 2019
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Sat, 31 Aug 2019 10:21:01 -0700
Subject: [Rd] inconsistent handling of factor, character,
 and logical predictors in lm()
In-Reply-To: <6E6A225D-E514-4980-A454-1BD2D77FC04B@mcmaster.ca>
References: <ACD1644AA6C67E4FBD0C350625508EC836CF0E5B@FHSDB2D11-2.csu.mcmaster.ca>
 <CAB8pepxHcs6gzhkCQsHZh1ZUmPSXPQyTkYs=K+fmK=M1Zicr3Q@mail.gmail.com>
 <6E6A225D-E514-4980-A454-1BD2D77FC04B@mcmaster.ca>
Message-ID: <CAF8bMca9CshpD8hjBydt7L59_wuYMombpED5-PZ7a5_uwvFHkQ@mail.gmail.com>

> Functions like lm() treat logical predictors as factors, *not* as
numerical variables.

Not quite.  A factor with all elements the same causes lm() to give an
error while a logical of all TRUEs or all FALSEs just omits it from the
model (it gets a coefficient of NA).  This is a fairly common situation
when you fit models to subsets of a big data.frame.  This is an argument
for fixing the single-valued-factor problem, which would become more
noticeable if logicals were treated as factors.

 > d <- data.frame(Age=c(2,4,6,8,10), Weight=c(878, 890, 930, 800, 750),
Diseased=c(FALSE,FALSE,FALSE,TRUE,TRUE))
> coef(lm(data=d, Weight ~ Age + Diseased))
 (Intercept)          Age DiseasedTRUE
    877.7333       5.4000    -151.3333
> coef(lm(data=d, Weight ~ Age + factor(Diseased)))
         (Intercept)                  Age factor(Diseased)TRUE
            877.7333               5.4000            -151.3333
> coef(lm(data=d, Weight ~ Age + Diseased, subset=Age<7))
 (Intercept)          Age DiseasedTRUE
    847.3333      13.0000           NA
> coef(lm(data=d, Weight ~ Age + factor(Diseased), subset=Age<7))
Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
  contrasts can be applied only to factors with 2 or more levels
> coef(lm(data=d, Weight ~ Age + factor(Diseased, levels=c(FALSE,TRUE)),
subset=Age<7))
Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
  contrasts can be applied only to factors with 2 or more levels

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sat, Aug 31, 2019 at 8:54 AM Fox, John <jfox at mcmaster.ca> wrote:

> Dear Abby,
>
> > On Aug 30, 2019, at 8:20 PM, Abby Spurdle <spurdle.a at gmail.com> wrote:
> >
> >> I think that it would be better to handle factors, character
> predictors, and logical predictors consistently.
> >
> > "logical predictors" can be regarded as categorical or continuous (i.e.
> 0 or 1).
> > And the model matrix should be the same, either way.
>
> I think that you're mistaking a coincidence for a principle. The
> coincidence is that FALSE/TRUE coerces to 0/1 and sorts to FALSE, TRUE.
> Functions like lm() treat logical predictors as factors, *not* as numerical
> variables.
>
> That one would get the same coefficient in either case is a consequence of
> the coincidence and the fact that the default contrasts for unordered
> factors are contr.treatment(). For example, if you changed the contrasts
> option, you'd get a different estimate (though of course a model with the
> same fit to the data and an equivalent interpretation):
>
> ------------ snip --------------
>
> > options(contrasts=c("contr.sum", "contr.poly"))
> > m3 <- lm(Sepal.Length ~ Sepal.Width + I(Species == "setosa"), data=iris)
> > m3
>
> Call:
> lm(formula = Sepal.Length ~ Sepal.Width + I(Species == "setosa"),
>     data = iris)
>
> Coefficients:
>             (Intercept)              Sepal.Width  I(Species == "setosa")1
>                  2.6672                   0.9418                   0.8898
>
> > head(model.matrix(m3))
>   (Intercept) Sepal.Width I(Species == "setosa")1
> 1           1         3.5                      -1
> 2           1         3.0                      -1
> 3           1         3.2                      -1
> 4           1         3.1                      -1
> 5           1         3.6                      -1
> 6           1         3.9                      -1
> > tail(model.matrix(m3))
>     (Intercept) Sepal.Width I(Species == "setosa")1
> 145           1         3.3                       1
> 146           1         3.0                       1
> 147           1         2.5                       1
> 148           1         3.0                       1
> 149           1         3.4                       1
> 150           1         3.0                       1
>
> > lm(Sepal.Length ~ Sepal.Width + as.numeric(Species == "setosa"),
> data=iris)
>
> Call:
> lm(formula = Sepal.Length ~ Sepal.Width + as.numeric(Species ==
>     "setosa"), data = iris)
>
> Coefficients:
>                     (Intercept)                      Sepal.Width
> as.numeric(Species == "setosa")
>                          3.5571                           0.9418
>                 -1.7797
>
> > -2*coef(m3)[3]
> I(Species == "setosa")1
>               -1.779657
>
> ------------ snip --------------
>
>
> >
> > I think the first question to be asked is, which is the best approach,
> > categorical or continuous?
> > The continuous approach seems simpler and more efficient to me, but
> > output from the categorical approach may be more intuitive, for some
> > people.
>
> I think that this misses the point I was trying to make: lm() et al. treat
> logical variables as factors, not as numerical predictors. One could argue
> about what's the better approach but not about what lm() does. BTW, I
> prefer treating a logical predictor as a factor because the predictor is
> essentially categorical.
>
> >
> > I note that the use factors and characters, doesn't necessarily
> > produce consistent output, for $xlevels.
> > (Because factors can have their levels re-ordered).
>
> Again, this misses the point: Both factors and character predictors
> produce elements in $xlevels; logical predictors do not, even though they
> are treated in the model as factors. That factors have levels that aren't
> necessarily ordered alphabetically is a reason that I prefer using factors
> to using character predictors, but this has nothing to do with the point I
> was trying to make about $xlevels.
>
> Best,
>  John
>
>   -------------------------------------------------
>   John Fox, Professor Emeritus
>   McMaster University
>   Hamilton, Ontario, Canada
>   Web: http::/socserv.mcmaster.ca/jfox
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Sat Aug 31 19:42:27 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Sat, 31 Aug 2019 17:42:27 +0000
Subject: [Rd] inconsistent handling of factor, character,
 and logical predictors in lm()
In-Reply-To: <14846_1567272085_x7VHLIMN009421_CAF8bMca9CshpD8hjBydt7L59_wuYMombpED5-PZ7a5_uwvFHkQ@mail.gmail.com>
References: <ACD1644AA6C67E4FBD0C350625508EC836CF0E5B@FHSDB2D11-2.csu.mcmaster.ca>
 <CAB8pepxHcs6gzhkCQsHZh1ZUmPSXPQyTkYs=K+fmK=M1Zicr3Q@mail.gmail.com>
 <6E6A225D-E514-4980-A454-1BD2D77FC04B@mcmaster.ca>
 <14846_1567272085_x7VHLIMN009421_CAF8bMca9CshpD8hjBydt7L59_wuYMombpED5-PZ7a5_uwvFHkQ@mail.gmail.com>
Message-ID: <ABDEBABF-D376-4F34-A391-B78A5BEABB8D@mcmaster.ca>

Dear Bill,

Thanks for pointing this difference out -- I was unaware of it.

I think that the difference occurs in model.matrix.default(), which coerces character variables but not logical variables to factors. Later it treats both factors and logical variables as "factors" in that it applies contrasts to both, but unused factor levels are dropped while an unused logical level is not.

I don't see why logical variables shouldn't be treated just as character variables are currently, both with respect to single levels (whether this is considered an error or as collinear with the intercept and thus gets an NA coefficient) and with respect to $levels.

Best,
 John

> On Aug 31, 2019, at 1:21 PM, William Dunlap via R-devel <r-devel at r-project.org> wrote:
> 
>> Functions like lm() treat logical predictors as factors, *not* as
> numerical variables.
> 
> Not quite.  A factor with all elements the same causes lm() to give an
> error while a logical of all TRUEs or all FALSEs just omits it from the
> model (it gets a coefficient of NA).  This is a fairly common situation
> when you fit models to subsets of a big data.frame.  This is an argument
> for fixing the single-valued-factor problem, which would become more
> noticeable if logicals were treated as factors.
> 
>> d <- data.frame(Age=c(2,4,6,8,10), Weight=c(878, 890, 930, 800, 750),
> Diseased=c(FALSE,FALSE,FALSE,TRUE,TRUE))
>> coef(lm(data=d, Weight ~ Age + Diseased))
> (Intercept)          Age DiseasedTRUE
>    877.7333       5.4000    -151.3333
>> coef(lm(data=d, Weight ~ Age + factor(Diseased)))
>         (Intercept)                  Age factor(Diseased)TRUE
>            877.7333               5.4000            -151.3333
>> coef(lm(data=d, Weight ~ Age + Diseased, subset=Age<7))
> (Intercept)          Age DiseasedTRUE
>    847.3333      13.0000           NA
>> coef(lm(data=d, Weight ~ Age + factor(Diseased), subset=Age<7))
> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
>  contrasts can be applied only to factors with 2 or more levels
>> coef(lm(data=d, Weight ~ Age + factor(Diseased, levels=c(FALSE,TRUE)),
> subset=Age<7))
> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
>  contrasts can be applied only to factors with 2 or more levels
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
> 
> On Sat, Aug 31, 2019 at 8:54 AM Fox, John <jfox at mcmaster.ca> wrote:
> 
>> Dear Abby,
>> 
>>> On Aug 30, 2019, at 8:20 PM, Abby Spurdle <spurdle.a at gmail.com> wrote:
>>> 
>>>> I think that it would be better to handle factors, character
>> predictors, and logical predictors consistently.
>>> 
>>> "logical predictors" can be regarded as categorical or continuous (i.e.
>> 0 or 1).
>>> And the model matrix should be the same, either way.
>> 
>> I think that you're mistaking a coincidence for a principle. The
>> coincidence is that FALSE/TRUE coerces to 0/1 and sorts to FALSE, TRUE.
>> Functions like lm() treat logical predictors as factors, *not* as numerical
>> variables.
>> 
>> That one would get the same coefficient in either case is a consequence of
>> the coincidence and the fact that the default contrasts for unordered
>> factors are contr.treatment(). For example, if you changed the contrasts
>> option, you'd get a different estimate (though of course a model with the
>> same fit to the data and an equivalent interpretation):
>> 
>> ------------ snip --------------
>> 
>>> options(contrasts=c("contr.sum", "contr.poly"))
>>> m3 <- lm(Sepal.Length ~ Sepal.Width + I(Species == "setosa"), data=iris)
>>> m3
>> 
>> Call:
>> lm(formula = Sepal.Length ~ Sepal.Width + I(Species == "setosa"),
>>    data = iris)
>> 
>> Coefficients:
>>            (Intercept)              Sepal.Width  I(Species == "setosa")1
>>                 2.6672                   0.9418                   0.8898
>> 
>>> head(model.matrix(m3))
>>  (Intercept) Sepal.Width I(Species == "setosa")1
>> 1           1         3.5                      -1
>> 2           1         3.0                      -1
>> 3           1         3.2                      -1
>> 4           1         3.1                      -1
>> 5           1         3.6                      -1
>> 6           1         3.9                      -1
>>> tail(model.matrix(m3))
>>    (Intercept) Sepal.Width I(Species == "setosa")1
>> 145           1         3.3                       1
>> 146           1         3.0                       1
>> 147           1         2.5                       1
>> 148           1         3.0                       1
>> 149           1         3.4                       1
>> 150           1         3.0                       1
>> 
>>> lm(Sepal.Length ~ Sepal.Width + as.numeric(Species == "setosa"),
>> data=iris)
>> 
>> Call:
>> lm(formula = Sepal.Length ~ Sepal.Width + as.numeric(Species ==
>>    "setosa"), data = iris)
>> 
>> Coefficients:
>>                    (Intercept)                      Sepal.Width
>> as.numeric(Species == "setosa")
>>                         3.5571                           0.9418
>>                -1.7797
>> 
>>> -2*coef(m3)[3]
>> I(Species == "setosa")1
>>              -1.779657
>> 
>> ------------ snip --------------
>> 
>> 
>>> 
>>> I think the first question to be asked is, which is the best approach,
>>> categorical or continuous?
>>> The continuous approach seems simpler and more efficient to me, but
>>> output from the categorical approach may be more intuitive, for some
>>> people.
>> 
>> I think that this misses the point I was trying to make: lm() et al. treat
>> logical variables as factors, not as numerical predictors. One could argue
>> about what's the better approach but not about what lm() does. BTW, I
>> prefer treating a logical predictor as a factor because the predictor is
>> essentially categorical.
>> 
>>> 
>>> I note that the use factors and characters, doesn't necessarily
>>> produce consistent output, for $xlevels.
>>> (Because factors can have their levels re-ordered).
>> 
>> Again, this misses the point: Both factors and character predictors
>> produce elements in $xlevels; logical predictors do not, even though they
>> are treated in the model as factors. That factors have levels that aren't
>> necessarily ordered alphabetically is a reason that I prefer using factors
>> to using character predictors, but this has nothing to do with the point I
>> was trying to make about $xlevels.
>> 
>> Best,
>> John
>> 
>>  -------------------------------------------------
>>  John Fox, Professor Emeritus
>>  McMaster University
>>  Hamilton, Ontario, Canada
>>  Web: http::/socserv.mcmaster.ca/jfox
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


