From pauljohn32 at gmail.com  Tue Mar  1 00:37:18 2011
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Mon, 28 Feb 2011 17:37:18 -0600
Subject: [Rd] function call overhead
In-Reply-To: <AANLkTikfe2Vq7u_rWbZ3idMrmO7tXEYrF7CDuvPC1G6F@mail.gmail.com>
References: <4d5b98ec.4c02cc0a.13fe.476c@mx.google.com>
	<AANLkTimdA=ExqfGGVuzk703PAs2eMcU_87rj1fydccx-@mail.gmail.com>
	<6441154A9FF1CD4386AF4ABF141A056D21525F40@WMEXOSCD2-N1.bocad.bank-banque-canada.ca>
	<AANLkTi=f0j5TXZ=pu6rsFUXLmrAYHWjdTDOy24MDUZ2w@mail.gmail.com>
	<AANLkTikfe2Vq7u_rWbZ3idMrmO7tXEYrF7CDuvPC1G6F@mail.gmail.com>
Message-ID: <AANLkTikB4d0NuoEbxR8n1vwGdeWCo=EZCOpZhPFt9iTJ@mail.gmail.com>

Snipping down to bare minimum history before comment:

On Wed, Feb 16, 2011 at 4:28 PM, Olaf Mersmann
<olafm at statistik.tu-dortmund.de> wrote:
> Dear Hadly, dear list,
>
> On Wed, Feb 16, 2011 at 9:53 PM, Hadley Wickham <hadley at rice.edu> wrote:
>
>>> system.time(replicate(1e4, base::print))
>> ? user ?system elapsed
>> ?0.539 ? 0.001 ? 0.541
>>> system.time(replicate(1e4, print))
>> ? user ?system elapsed
>> ?0.013 ? 0.000 ? 0.012

>> library("microbenchmark")
>> res <- microbenchmark(print, base::print, times=10000)
>> res
>> print(res, unit="eps")
> Unit: evaluations per second
> ? ? ? ? ? ? ? ? ? ?min ? ? ? ? ?lq ? ? ?median ? ? ? ? ?uq ? ? ? ?max
> print ? ? ? 17543859.65 15384615.38 14705882.35 14492753.62 20665.8538
> base::print ? ?23944.64 ? ?23064.33 ? ?22584.32 ? ?20659.88 ? 210.5329
>

I think it is important to say that this slowdown is not unique to R
and is unrelated to the fact that is R  interpreted.  The same happens
in compiled object-oriented languages like C++ or Objective-C. There
is an inherent cost in the runtime system to find a function or method
that is suitable to an object.

In agent-based modeling simulations, we call it the cost of "method
lookup" because the runtime system has to check for the existence of a
method each time it is called for a given object.   There is a
time-saving approach where one can cache the result of the lookup and
then call that result directly each time through the loop.
Implementing this is pretty complicated, however, and it is
discouraged unless you really need it.  It is especially dangerous
because this optimization throws-away the runtime benefit of matching
the correct method to the class of the object.  (See
http://www.mulle-kybernetik.com/artikel/Optimization/opti-3.html,
where it shows how one can even cache C library functions to avoid
lookup overhead. I'm told that the Obj-C 2.0 runtime will try to
optimize this automatically, I've not tested.)

The R solution is achieving that exact same kind of speed-up by saving
the function lookup in a local variable. The R approach, however, is
implemented much more easily than the Objective-C solution. There is
an obvious danger: if the saved method is not appropriate to an object
to which it applies, something unpredictable will happen.

The same is true in C++.  I was fiddling around with the C++ code that
is included with the R package Siena (awesome package, incidentally)
last year and noticed a similar slowdown with method lookup.  In C++,
I was surprised to find a slowdown inside a class using an instance
variable prefixed with  "this.".  For an IVAR, "this.x" and "x" are
the same thing, but to the runtime system, well, there's slowdown in
finding "this" class and getting x, compared to just using  x.  To the
programmer who is trying to be clear and careful, putting "this." on
the front of IVAR is tidy, but it also slows down the runtime a lot.

Hope this is not more confusing than when I started :)

pj
-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas


From djsamperi at gmail.com  Tue Mar  1 01:03:24 2011
From: djsamperi at gmail.com (Dominick Samperi)
Date: Mon, 28 Feb 2011 19:03:24 -0500
Subject: [Rd] function call overhead
In-Reply-To: <AANLkTikB4d0NuoEbxR8n1vwGdeWCo=EZCOpZhPFt9iTJ@mail.gmail.com>
References: <4d5b98ec.4c02cc0a.13fe.476c@mx.google.com>
	<AANLkTimdA=ExqfGGVuzk703PAs2eMcU_87rj1fydccx-@mail.gmail.com>
	<6441154A9FF1CD4386AF4ABF141A056D21525F40@WMEXOSCD2-N1.bocad.bank-banque-canada.ca>
	<AANLkTi=f0j5TXZ=pu6rsFUXLmrAYHWjdTDOy24MDUZ2w@mail.gmail.com>
	<AANLkTikfe2Vq7u_rWbZ3idMrmO7tXEYrF7CDuvPC1G6F@mail.gmail.com>
	<AANLkTikB4d0NuoEbxR8n1vwGdeWCo=EZCOpZhPFt9iTJ@mail.gmail.com>
Message-ID: <AANLkTimyzxA66nh6pMrvHWCKCOWKpztUVcoCMsKYTBc=@mail.gmail.com>

On Mon, Feb 28, 2011 at 6:37 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:
> Snipping down to bare minimum history before comment:
>
> On Wed, Feb 16, 2011 at 4:28 PM, Olaf Mersmann
> <olafm at statistik.tu-dortmund.de> wrote:
>> Dear Hadly, dear list,
>>
>> On Wed, Feb 16, 2011 at 9:53 PM, Hadley Wickham <hadley at rice.edu> wrote:
>>
>>>> system.time(replicate(1e4, base::print))
>>> ? user ?system elapsed
>>> ?0.539 ? 0.001 ? 0.541
>>>> system.time(replicate(1e4, print))
>>> ? user ?system elapsed
>>> ?0.013 ? 0.000 ? 0.012
>
>>> library("microbenchmark")
>>> res <- microbenchmark(print, base::print, times=10000)
>>> res
>>> print(res, unit="eps")
>> Unit: evaluations per second
>> ? ? ? ? ? ? ? ? ? ?min ? ? ? ? ?lq ? ? ?median ? ? ? ? ?uq ? ? ? ?max
>> print ? ? ? 17543859.65 15384615.38 14705882.35 14492753.62 20665.8538
>> base::print ? ?23944.64 ? ?23064.33 ? ?22584.32 ? ?20659.88 ? 210.5329
>>
>
> I think it is important to say that this slowdown is not unique to R
> and is unrelated to the fact that is R ?interpreted. ?The same happens
> in compiled object-oriented languages like C++ or Objective-C. There
> is an inherent cost in the runtime system to find a function or method
> that is suitable to an object.
>
> In agent-based modeling simulations, we call it the cost of "method
> lookup" because the runtime system has to check for the existence of a
> method each time it is called for a given object. ? There is a
> time-saving approach where one can cache the result of the lookup and
> then call that result directly each time through the loop.
> Implementing this is pretty complicated, however, and it is
> discouraged unless you really need it. ?It is especially dangerous
> because this optimization throws-away the runtime benefit of matching
> the correct method to the class of the object. ?(See
> http://www.mulle-kybernetik.com/artikel/Optimization/opti-3.html,
> where it shows how one can even cache C library functions to avoid
> lookup overhead. I'm told that the Obj-C 2.0 runtime will try to
> optimize this automatically, I've not tested.)
>
> The R solution is achieving that exact same kind of speed-up by saving
> the function lookup in a local variable. The R approach, however, is
> implemented much more easily than the Objective-C solution. There is
> an obvious danger: if the saved method is not appropriate to an object
> to which it applies, something unpredictable will happen.
>
> The same is true in C++. ?I was fiddling around with the C++ code that
> is included with the R package Siena (awesome package, incidentally)
> last year and noticed a similar slowdown with method lookup. ?In C++,
> I was surprised to find a slowdown inside a class using an instance
> variable prefixed with ?"this.". ?For an IVAR, "this.x" and "x" are
> the same thing, but to the runtime system, well, there's slowdown in
> finding "this" class and getting x, compared to just using ?x. ?To the
> programmer who is trying to be clear and careful, putting "this." on
> the front of IVAR is tidy, but it also slows down the runtime a lot.

In the case of namespace qualification (or template
metaprogramming) in C++ the qualification is resolved at
compile time, so there is no performance hit at runtime.

On the cost of this.x vs x, this probably becomes very small (or zero)
when a smart optimizer is used (one that knows that they are the same).

The performance hit results when what appears to be a field access (foo.x)
is really syntactic sugar for message dispatch (a function call), as is often
the case in agent-based modelling (and in languages that follow the Smalltalk
model, or the Actor model).

Dominick

> Hope this is not more confusing than when I started :)
>
> pj
> --
> Paul E. Johnson
> Professor, Political Science
> 1541 Lilac Lane, Room 504
> University of Kansas
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From mxkuhn at gmail.com  Tue Mar  1 02:14:40 2011
From: mxkuhn at gmail.com (Max Kuhn)
Date: Mon, 28 Feb 2011 20:14:40 -0500
Subject: [Rd] broken link on CRAN
In-Reply-To: <1885A1FE-F3AF-4751-B3D2-54CB5F58C1F5@r-project.org>
References: <AANLkTinr2UguUBOmtdF9Z6Po1RUKJ_MLQeAbgROp81n_@mail.gmail.com>
	<1885A1FE-F3AF-4751-B3D2-54CB5F58C1F5@r-project.org>
Message-ID: <AANLkTinzy1JauMW+fadV2O11dY9myCCGU14Nuxdg9KJ5@mail.gmail.com>

Peter and Simon,

That was the issue. Thanks,

Max

On Mon, Feb 28, 2011 at 3:48 PM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
>
> On Feb 28, 2011, at 3:22 PM, Max Kuhn wrote:
>
>> The link to
>>
>> ? http://cran.r-project.org/bin/macosx/R-2.12.1.pkg
>>
>> on the CRAN page
>>
>> ? http://cran.r-project.org/bin/macosx/
>>
>> is broken.
>
> There is no such link on the page - it's R-2.12.2.pkg now - I suspect you have a cached page in your browser - try reloading it.
>
> Cheers,
> Simon
>
>
>> Also, the email address for the webmaster is null (which is
>> why I'm emailing here).
>>
>> Thanks,
>>
>> Max
>>
>>
>
>



-- 

Max


From hankin.robin at gmail.com  Wed Mar  2 00:10:55 2011
From: hankin.robin at gmail.com (robin hankin)
Date: Wed, 2 Mar 2011 12:10:55 +1300
Subject: [Rd] vignette typesetting issue
Message-ID: <AANLkTimhK3UaLQgHs-nfCrX1Y38-7SzX_yKxVcd7N1Rg@mail.gmail.com>

Hi

I am preparing a vignette, and I am finding that LaTeX ties (that is,
the tilde symbol, "~", used to tell LaTeX not to make a newline
in the output), are appearing as actual tildes.  This is not desired behaviour
for me.  Thus the PDF includes things like this:


". . . taken directly from~Oakley (1999)....".

[this typeset as "taken directly from~\cite{oakley1999}..."].

I do not want the tilde to appear in the PDF file.
I do not want to remove the tilde symbols because then latex would
be free to make a line break between "from" and "Oakley", which
is poor form.

The issue does not arise on my Mac, and I expect that it is down
to some latex setting or style file.

Does anyone recognize this problem?

Can anyone advise?



-- 
Robin Hankin
Uncertainty Analyst
hankin.robin at gmail.com


From beniltoncarvalho at gmail.com  Wed Mar  2 00:19:41 2011
From: beniltoncarvalho at gmail.com (Benilton Carvalho)
Date: Tue, 1 Mar 2011 23:19:41 +0000
Subject: [Rd] changes in recent R-devel revisions?
Message-ID: <AANLkTi=UipvSvxCmzgORy=QAbgGW+2kA5eJw8DziBmsN@mail.gmail.com>

Hi,

I have a BioC infra-structure package that works fine (I can build,
check and load it successfully) on revision r53950. The very same
package fails on r54591 with the error below:

Error in loadNamespace(package, c(which.lib.loc, lib.loc), keep.source
= keep.source) :
  cyclic name space dependency detected when loading ?oligoClasses?,
already loading ?oligoClasses?

I don't see anything obvious in the name space that would indicate
cyclic dependency and I wonder:

a) if there were changes that were meant to affect this;

b) what is the recommended strategy to solve this issue.

Thank you very much for any suggestion,

benilton


From edd at debian.org  Wed Mar  2 00:36:47 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 1 Mar 2011 17:36:47 -0600
Subject: [Rd] vignette typesetting issue
In-Reply-To: <AANLkTimhK3UaLQgHs-nfCrX1Y38-7SzX_yKxVcd7N1Rg@mail.gmail.com>
References: <AANLkTimhK3UaLQgHs-nfCrX1Y38-7SzX_yKxVcd7N1Rg@mail.gmail.com>
Message-ID: <19821.33551.196013.391087@max.nulle.part>


On 2 March 2011 at 12:10, robin hankin wrote:
| Hi
| 
| I am preparing a vignette, and I am finding that LaTeX ties (that is,
| the tilde symbol, "~", used to tell LaTeX not to make a newline
| in the output), are appearing as actual tildes.  This is not desired behaviour
| for me.  Thus the PDF includes things like this:
| 
| 
| ". . . taken directly from~Oakley (1999)....".
| 
| [this typeset as "taken directly from~\cite{oakley1999}..."].
| 
| I do not want the tilde to appear in the PDF file.
| I do not want to remove the tilde symbols because then latex would
| be free to make a line break between "from" and "Oakley", which
| is poor form.
| 
| The issue does not arise on my Mac, and I expect that it is down
| to some latex setting or style file.
| 
| Does anyone recognize this problem?
| 
| Can anyone advise?

Yes. It's on Debian / Ubuntu, correct?  I have the same issue, and word is
that it should get fixed upstream at some point. It only bites when you call
via texi2dvi though, ie when Sweaving.  So for Rcpp, and directly in the
inst/doc/Makefile, we do the following test for my username -- in which case
we use pdflatex and no ugly tilde symbols creep into whitespace -- or else
use tools::texi2dvi() :

ifneq (,$(findstring edd,$(whoami)))
	pdflatex Rcpp-modules.tex
	pdflatex Rcpp-modules.tex
else
	$(RSCRIPT) -e "tools::texi2dvi( 'Rcpp-modules.tex', pdf = TRUE, clean = TRUE )"
endif

Hth, Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From mtmorgan at fhcrc.org  Wed Mar  2 04:36:47 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Tue, 01 Mar 2011 19:36:47 -0800
Subject: [Rd] changes in recent R-devel revisions?
In-Reply-To: <AANLkTi=UipvSvxCmzgORy=QAbgGW+2kA5eJw8DziBmsN@mail.gmail.com>
References: <AANLkTi=UipvSvxCmzgORy=QAbgGW+2kA5eJw8DziBmsN@mail.gmail.com>
Message-ID: <4D6DBB4F.7010009@fhcrc.org>

On 03/01/2011 03:19 PM, Benilton Carvalho wrote:
> Hi,
> 
> I have a BioC infra-structure package that works fine (I can build,
> check and load it successfully) on revision r53950. The very same
> package fails on r54591 with the error below:
> 
> Error in loadNamespace(package, c(which.lib.loc, lib.loc), keep.source
> = keep.source) :
>   cyclic name space dependency detected when loading ?oligoClasses?,
> already loading ?oligoClasses?
> 
> I don't see anything obvious in the name space that would indicate
> cyclic dependency and I wonder:

For what it's worth, saying

> trace(stop, recover)

prior to library(oligoClasses) leads to

 7: loadNamespace(package, c(which.lib.loc, lib.loc), keep.source =
keep.source
 8: methods:::cacheMetaData(ns, TRUE, ns)
 9: getGeneric(f, FALSE, searchWhere, fpkg)
10: tryCatch(loadNamespace(package), error = function(e) e)

where 'package' is oligoClasses in lines 7 and 10, and the 'f' in 9 is
'relocateObject'. Line 10 is evaluated when methods:::.getGeneric
returns NULL.

In oligoClasses we have

oligoClasses/R> grep relocateObject *
AllGenerics.R:setGeneric("relocateObject", function(object, ...)
standardGeneric("relocateObject"))
methods-CNSet.R:relocateObject <- function(object, to){

which I guess is not as intended.

My guess is that setGeneric adds the generic to a cache of some sort
when the name space is created, but doesn't remove it when the generic
is overwritten by a plain function.

No idea why this shows up in the current R revision.

Martin

> 
> a) if there were changes that were meant to affect this;
> 
> b) what is the recommended strategy to solve this issue.
> 
> Thank you very much for any suggestion,
> 
> benilton
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From hb at biostat.ucsf.edu  Wed Mar  2 05:41:53 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Tue, 1 Mar 2011 20:41:53 -0800
Subject: [Rd] file.rename(): Guaranteed to be complete or not at all?
Message-ID: <AANLkTimqGAiRiWdv8j1UjyXOZmSP-OhyLD_fWGu50N+R@mail.gmail.com>

Hi,

assume I have an existing file 'pathname' and I want to rename it to
'pathnameN' (which does not exist).  I use:

res <- file.rename(pathname, pathnameN);

Is it guaranteed that:

(1) if res == TRUE, the file now have name 'pathnameN' and there is no
file with name 'pathname'?
(2) if res == FALSE, nothing has changed?

or could it theoretically also be the case that

(3) there are say two identical files named 'pathname' and 'pathnameN',
(4) or worse, that neither exists?

I can see how (3) could happen if the file is renamed by first using
file.copy() and then file.remove() while there is lack of write/delete
permission for the latter.

Currently, my code asserts that (3) and (4) did not happen.  Is that
unnecessary - does file.rename() do that for me (regardless of OS)?

Thanks

Henrik


From ripley at stats.ox.ac.uk  Wed Mar  2 07:39:00 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 2 Mar 2011 06:39:00 +0000 (GMT)
Subject: [Rd] changes in recent R-devel revisions?
In-Reply-To: <4D6DBB4F.7010009@fhcrc.org>
References: <AANLkTi=UipvSvxCmzgORy=QAbgGW+2kA5eJw8DziBmsN@mail.gmail.com>
	<4D6DBB4F.7010009@fhcrc.org>
Message-ID: <alpine.LFD.2.02.1103020620020.29480@gannet.stats.ox.ac.uk>

On Tue, 1 Mar 2011, Martin Morgan wrote:

> On 03/01/2011 03:19 PM, Benilton Carvalho wrote:
>> Hi,
>>
>> I have a BioC infra-structure package that works fine (I can build,
>> check and load it successfully) on revision r53950. The very same
>> package fails on r54591 with the error below:
>>
>> Error in loadNamespace(package, c(which.lib.loc, lib.loc), keep.source
>> = keep.source) :
>>   cyclic name space dependency detected when loading ?oligoClasses?,
>> already loading ?oligoClasses?
>>
>> I don't see anything obvious in the name space that would indicate
>> cyclic dependency and I wonder:

The message is slightly misleading, which is why I added the 
additional information (in r54520, so this came in a litte before 
that) about what is being loaded.  'oligoClasses' is loading itself 
(which would be seen as a cycle on a graph).  I first saw it on a CRAN 
package which was loading oligoClasses via several other packages and 
it was not at all clear which namespaces were involved.

> For what it's worth, saying
>
>> trace(stop, recover)
>
> prior to library(oligoClasses) leads to
>
> 7: loadNamespace(package, c(which.lib.loc, lib.loc), keep.source =
> keep.source
> 8: methods:::cacheMetaData(ns, TRUE, ns)
> 9: getGeneric(f, FALSE, searchWhere, fpkg)
> 10: tryCatch(loadNamespace(package), error = function(e) e)
>
> where 'package' is oligoClasses in lines 7 and 10, and the 'f' in 9 is
> 'relocateObject'. Line 10 is evaluated when methods:::.getGeneric
> returns NULL.
>
> In oligoClasses we have
>
> oligoClasses/R> grep relocateObject *
> AllGenerics.R:setGeneric("relocateObject", function(object, ...)
> standardGeneric("relocateObject"))
> methods-CNSet.R:relocateObject <- function(object, to){
>
> which I guess is not as intended.
>
> My guess is that setGeneric adds the generic to a cache of some sort
> when the name space is created, but doesn't remove it when the generic
> is overwritten by a plain function.
>
> No idea why this shows up in the current R revision.

r54487 has caused some other changes in behaviour: I think the 
oligoClasses problem appeared about that time.


>
> Martin
>
>>
>> a) if there were changes that were meant to affect this;
>>
>> b) what is the recommended strategy to solve this issue.
>>
>> Thank you very much for any suggestion,
>>
>> benilton
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
> -- 
> Computational Biology
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109
>
> Location: M1-B861
> Telephone: 206 667-2793
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Wed Mar  2 08:01:45 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 2 Mar 2011 07:01:45 +0000 (GMT)
Subject: [Rd] file.rename(): Guaranteed to be complete or not at all?
In-Reply-To: <AANLkTimqGAiRiWdv8j1UjyXOZmSP-OhyLD_fWGu50N+R@mail.gmail.com>
References: <AANLkTimqGAiRiWdv8j1UjyXOZmSP-OhyLD_fWGu50N+R@mail.gmail.com>
Message-ID: <alpine.LFD.2.02.1103020639300.29480@gannet.stats.ox.ac.uk>

As the help says:

   This is subject to the limitations of the OS's corresponding system
   call: ....

E.g. on Fedora 14 'man 2 rename' says, inter alia,

'If newpath already exists it will be atomically replaced (subject to 
a few conditions; see ERRORS below), so that there is no point at 
which another process attempting to access newpath will find it 
missing.

However, when overwriting there will probably be a window in which 
both oldpath and newpath refer to the file being renamed.

BUGS

On NFS file systems, you can not assume that if the operation failed 
the file was not renamed.'

and for Windows see

http://msdn.microsoft.com/en-us/library/aa365240%28v=vs.85%29.aspx

where R uses flags (MOVEFILE_REPLACE_EXISTING | MOVEFILE_COPY_ALLOWED 
| MOVEFILE_WRITE_THROUGH)

Windows 95 was an example of an OS which could delete the 'to' file 
and fail to move 'from'.

On Tue, 1 Mar 2011, Henrik Bengtsson wrote:

> Hi,
>
> assume I have an existing file 'pathname' and I want to rename it to
> 'pathnameN' (which does not exist).  I use:
>
> res <- file.rename(pathname, pathnameN);
>
> Is it guaranteed that:
>
> (1) if res == TRUE, the file now have name 'pathnameN' and there is no
> file with name 'pathname'?
> (2) if res == FALSE, nothing has changed?
>
> or could it theoretically also be the case that
>
> (3) there are say two identical files named 'pathname' and 'pathnameN',
> (4) or worse, that neither exists?
>
> I can see how (3) could happen if the file is renamed by first using
> file.copy() and then file.remove() while there is lack of write/delete
> permission for the latter.
>
> Currently, my code asserts that (3) and (4) did not happen.  Is that
> unnecessary - does file.rename() do that for me (regardless of OS)?
>
> Thanks
>
> Henrik
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From beniltoncarvalho at gmail.com  Wed Mar  2 13:06:37 2011
From: beniltoncarvalho at gmail.com (Benilton Carvalho)
Date: Wed, 2 Mar 2011 12:06:37 +0000
Subject: [Rd] changes in recent R-devel revisions?
In-Reply-To: <alpine.LFD.2.02.1103020620020.29480@gannet.stats.ox.ac.uk>
References: <AANLkTi=UipvSvxCmzgORy=QAbgGW+2kA5eJw8DziBmsN@mail.gmail.com>
	<4D6DBB4F.7010009@fhcrc.org>
	<alpine.LFD.2.02.1103020620020.29480@gannet.stats.ox.ac.uk>
Message-ID: <AANLkTikzudDGdkL+FgqzeE6qTXjZ3n9KD+Ef-=ufx0Wt@mail.gmail.com>

Martin and Professor Ripley,

Thank you very much for your attention and time on this.

I've fixed the package accordingly.

benilton

On 2 March 2011 06:39, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> On Tue, 1 Mar 2011, Martin Morgan wrote:
>
>> On 03/01/2011 03:19 PM, Benilton Carvalho wrote:
>>>
>>> Hi,
>>>
>>> I have a BioC infra-structure package that works fine (I can build,
>>> check and load it successfully) on revision r53950. The very same
>>> package fails on r54591 with the error below:
>>>
>>> Error in loadNamespace(package, c(which.lib.loc, lib.loc), keep.source
>>> = keep.source) :
>>> ?cyclic name space dependency detected when loading ?oligoClasses?,
>>> already loading ?oligoClasses?
>>>
>>> I don't see anything obvious in the name space that would indicate
>>> cyclic dependency and I wonder:
>
> The message is slightly misleading, which is why I added the additional
> information (in r54520, so this came in a litte before that) about what is
> being loaded. ?'oligoClasses' is loading itself (which would be seen as a
> cycle on a graph). ?I first saw it on a CRAN package which was loading
> oligoClasses via several other packages and it was not at all clear which
> namespaces were involved.
>
>> For what it's worth, saying
>>
>>> trace(stop, recover)
>>
>> prior to library(oligoClasses) leads to
>>
>> 7: loadNamespace(package, c(which.lib.loc, lib.loc), keep.source =
>> keep.source
>> 8: methods:::cacheMetaData(ns, TRUE, ns)
>> 9: getGeneric(f, FALSE, searchWhere, fpkg)
>> 10: tryCatch(loadNamespace(package), error = function(e) e)
>>
>> where 'package' is oligoClasses in lines 7 and 10, and the 'f' in 9 is
>> 'relocateObject'. Line 10 is evaluated when methods:::.getGeneric
>> returns NULL.
>>
>> In oligoClasses we have
>>
>> oligoClasses/R> grep relocateObject *
>> AllGenerics.R:setGeneric("relocateObject", function(object, ...)
>> standardGeneric("relocateObject"))
>> methods-CNSet.R:relocateObject <- function(object, to){
>>
>> which I guess is not as intended.
>>
>> My guess is that setGeneric adds the generic to a cache of some sort
>> when the name space is created, but doesn't remove it when the generic
>> is overwritten by a plain function.
>>
>> No idea why this shows up in the current R revision.
>
> r54487 has caused some other changes in behaviour: I think the oligoClasses
> problem appeared about that time.
>
>
>>
>> Martin
>>
>>>
>>> a) if there were changes that were meant to affect this;
>>>
>>> b) what is the recommended strategy to solve this issue.
>>>
>>> Thank you very much for any suggestion,
>>>
>>> benilton
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>> --
>> Computational Biology
>> Fred Hutchinson Cancer Research Center
>> 1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109
>>
>> Location: M1-B861
>> Telephone: 206 667-2793
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> --
> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595


From ripley at stats.ox.ac.uk  Wed Mar  2 18:18:18 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 2 Mar 2011 17:18:18 +0000 (GMT)
Subject: [Rd] Small enhancement for CMD check
In-Reply-To: <alpine.LFD.2.02.1102281641400.19979@gannet.stats.ox.ac.uk>
References: <1298658255.4670.64.camel@punchbuggy>
	<alpine.LFD.2.02.1102281641400.19979@gannet.stats.ox.ac.uk>
Message-ID: <alpine.LFD.2.02.1103021715210.9393@gannet.stats.ox.ac.uk>

On Mon, 28 Feb 2011, Prof Brian Ripley wrote:

> Unfortunately it would need a major rewrite, and either piping output through 
> a pager (surely the standard Unix way to handle this) or redirecting to a 
> file is the simplest way to do this.
>
> R CMD check calls a process to run .runPackageTestsR, which calls further 
> processes to run each test and diff the results.  We could simply capture 
> stdout/stderr of .runPackageTestsR, but then one would have to wait until all 
> the tests had run before seeing any output, which may mean waiting hours -- 
> that was decided to be too undesirable.

I've implemented in R-devel something that copies the output on a 
per-test basis to 00check.log.  It may not be perfect (in particular 
if a test crashes its R process badly enough), but it will at least 
record a test-by-test summary of success/failure.

> On Fri, 25 Feb 2011, Terry Therneau wrote:
>
>> It would be nice if the 00check.log file also included this part of the
>> output:
>>  Running ?bladder.R?
>>  Comparing ?bladder.Rout? to ?bladder.Rout.save? ... OK
>>  Running ?book1.R?
>>  Comparing ?book1.Rout? to ?book1.Rout.save? ... OK
>>  Running ?book2.R?
>>  Comparing ?book2.Rout? to ?book2.Rout.save? ... OK
>> 
>> etc.
>>
>>  The survival package has enough test scripts that it exceeds my
>> terminal's scroll bar; I have to either watch closely or run
>> R CMD check survival >& mylog
>
> The most prolix are
> survival portfolio    matlab  kappalab  spatstat
>       68        36        32        30        28
>       BB    HSAUR2    fields     pcalg     aster
>       26        22        22        22        21
>
> The remedy seems to be to group the tests into larger units.
>
>> Terry Therneau
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From hb at biostat.ucsf.edu  Wed Mar  2 19:47:12 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Wed, 2 Mar 2011 10:47:12 -0800
Subject: [Rd] file.rename(): Guaranteed to be complete or not at all?
In-Reply-To: <alpine.LFD.2.02.1103020639300.29480@gannet.stats.ox.ac.uk>
References: <AANLkTimqGAiRiWdv8j1UjyXOZmSP-OhyLD_fWGu50N+R@mail.gmail.com>
	<alpine.LFD.2.02.1103020639300.29480@gannet.stats.ox.ac.uk>
Message-ID: <AANLkTinBD_ebJZxOSd_Gd=UKxLeUm4GaUKyBearZVbas@mail.gmail.com>

Thank you very much for these pointers.

In order to lower the risk for proceeding unknowingly with (3) or (4),
I'll keep my post-rename tests for them (understanding that it is
still not bullet proof).

/Henrik

On Tue, Mar 1, 2011 at 11:01 PM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> As the help says:
>
> ?This is subject to the limitations of the OS's corresponding system
> ?call: ....
>
> E.g. on Fedora 14 'man 2 rename' says, inter alia,
>
> 'If newpath already exists it will be atomically replaced (subject to a few
> conditions; see ERRORS below), so that there is no point at which another
> process attempting to access newpath will find it missing.
>
> However, when overwriting there will probably be a window in which both
> oldpath and newpath refer to the file being renamed.
>
> BUGS
>
> On NFS file systems, you can not assume that if the operation failed the
> file was not renamed.'
>
> and for Windows see
>
> http://msdn.microsoft.com/en-us/library/aa365240%28v=vs.85%29.aspx
>
> where R uses flags (MOVEFILE_REPLACE_EXISTING | MOVEFILE_COPY_ALLOWED |
> MOVEFILE_WRITE_THROUGH)
>
> Windows 95 was an example of an OS which could delete the 'to' file and fail
> to move 'from'.
>
> On Tue, 1 Mar 2011, Henrik Bengtsson wrote:
>
>> Hi,
>>
>> assume I have an existing file 'pathname' and I want to rename it to
>> 'pathnameN' (which does not exist). ?I use:
>>
>> res <- file.rename(pathname, pathnameN);
>>
>> Is it guaranteed that:
>>
>> (1) if res == TRUE, the file now have name 'pathnameN' and there is no
>> file with name 'pathname'?
>> (2) if res == FALSE, nothing has changed?
>>
>> or could it theoretically also be the case that
>>
>> (3) there are say two identical files named 'pathname' and 'pathnameN',
>> (4) or worse, that neither exists?
>>
>> I can see how (3) could happen if the file is renamed by first using
>> file.copy() and then file.remove() while there is lack of write/delete
>> permission for the latter.
>>
>> Currently, my code asserts that (3) and (4) did not happen. ?Is that
>> unnecessary - does file.rename() do that for me (regardless of OS)?
>>
>> Thanks
>>
>> Henrik
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> --
> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595
>


From andre.zege at gmail.com  Thu Mar  3 02:59:33 2011
From: andre.zege at gmail.com (A Zege)
Date: Wed, 2 Mar 2011 17:59:33 -0800 (PST)
Subject: [Rd] Newbie Rccp module question. "Failed to initialize
	module	pointer"???
In-Reply-To: <19805.29589.842345.489802@max.nulle.part>
References: <798847.76881.qm@web39321.mail.mud.yahoo.com>
	<19805.29589.842345.489802@max.nulle.part>
Message-ID: <1299117573953-3332652.post@n4.nabble.com>

Dirk, thanks for your reply. I posted my answer right away and went on
vacation. My post was pending since then. Still cannot post, so I opened
another profile -- maybe this time it gets through.

To answer your questions, I run  R-2.12.1 on 64 bit RedHat Linux on Xeon
machine.
What seems odd that the error message i am getting refers to .GlobalEnv
package. The symbol it is looking for, _rcpp_module_boot_mod, is in shared
library for my package, i checked it with nm. Is there any doc on how
modules are implemented? 

--
View this message in context: http://r.789695.n4.nabble.com/Newbie-Rccp-module-question-Failed-to-initialize-module-pointer-tp3311388p3332652.html
Sent from the R devel mailing list archive at Nabble.com.


From plfjohnson at emory.edu  Wed Mar  2 23:38:02 2011
From: plfjohnson at emory.edu (Philip Johnson)
Date: Wed, 02 Mar 2011 17:38:02 -0500
Subject: [Rd] axis, title & padj
Message-ID: <4D6EC6CA.3080204@emory.edu>

Hi,

I often use par(mex = 0.5) as an easy way to shrink space used for 
margins.  However, I recently noticed that this leads to an asymmetry in 
the positioning of the x vs. y axis labels and xlab / ylab -- the x-axis 
labels are pushed into the tic-marks, while the y-axis labels look fine.

A more extreme example:
dev.new()
par(mex=.1, mar=c(10,10,10,10))
plot(1:10)

Tracking this down in the code, this effect appears to be arising from:
   1) GMtext in graphics.c adjusts the margin line coordinate using 
dev->yLineBias.  After commenting out these adjustments, the x-axis text 
is clearly shifted up (i.e. the bottom of the text is aligned at the 
specified margin line) while the y-axis text is shifted left (i.e. the 
bottom of the text is still aligned with the specified margin line).
   2) This observation lead me to realize that do_axis and do_title in 
plot.c assume padj=0 most of the time (there are exceptions depending on 
par()$las).

I'm no expert in the R code base, but the yLineBias adjustments appears 
like they might have been intended to restore symmetry -- but it only 
works for mex=1.

Is there a reason why, instead of yLineBias, we can't either:
     1) center axis and title text by default (i.e. padj=0.5)
       -or-
     2) align side=1,3 with padj=1; side=2,4 with padj=0
?


Solution 1 is trivial to implement, but this would shift positioning 
slightly relative to the current code (even for mex=1).
Solution 2 is slightly trickier because we have to pay attention to side 
and las values, but would not change the output for mex=1.


I implemented drafts of both solutions, which work at least 
superficially.  Two questions:
   -Am I missing a larger purpose to yLineBias?
   -Thoughts about which solution is better / can I contribute a patch 
to fix this?

Regards,
Philip


From bbolker at gmail.com  Thu Mar  3 17:17:56 2011
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 3 Mar 2011 16:17:56 +0000
Subject: [Rd] read.csv trap
References: <4D559060.7050502@gmail.com>
	<AANLkTi=hT7h7yQyL-xuNZE4a9YtQeH99d=nuJ2MvzZf0@mail.gmail.com>
	<4D55B17E.4040509@gmail.com>
Message-ID: <loom.20110303T171531-451@post.gmane.org>

Ben Bolker <bbolker <at> gmail.com> writes:

> On 02/11/2011 03:37 PM, Laurent Gatto wrote:
> > On 11 February 2011 19:39, Ben Bolker <bbolker <at> gmail.com> wrote:
> >>
> > [snip]
> >>


  Bump.  Is there any opinion about this from R-core??
Will I be scolded if I submit this as a bug ... ??


> >> What is dangerous/confusing is that R silently **wraps** longer lines if
> >> fill=TRUE (which is the default for read.csv).  I encountered this when
> >> working with a colleague on a long, messy CSV file that had some phantom
> >> extra fields in some rows, which then turned into empty lines in the
> >> data frame.
> >>

  [snip snip]

> >>  Here is an example and a workaround that runs count.fields on the
> >> whole file to find the maximum column length and set col.names
> >> accordingly.  (It assumes you don't already have a file named "test.csv"
> >> in your working directory ...)
> >>
> >>  I haven't dug in to try to write a patch for this -- I wanted to test
> >> the waters and see what people thought first, and I realize that
> >> read.table() is a very complicated piece of code that embodies a lot of
> >> tradeoffs, so there could be lots of different approaches to trying to
> >> mitigate this problem. I appreciate very much how hard it is to write a
> >> robust and general function to read data files, but I also think it's
> >> really important to minimize the number of traps in read.table(), which
> >> will often be the first part of R that new users encounter ...
> >>
> >>  A quick fix for this might be to allow the number of lines analyzed
> >> for length to be settable by the user, or to allow a settable 'maxcols'
> >> parameter, although those would only help in the case where the user
> >> already knows there is a problem.
> >>
> >>  cheers
> >>    Ben Bolker
> >>
===============
writeLines(c("A,B,C,D",
            "1,a,b,c",
            "2,f,g,c",
            "3,a,i,j",
            "4,a,b,c",
            "5,d,e,f",
            "6,g,h,i,j,k,l,m,n"),
          con=file("test.csv"))
> >>
> >>
read.csv("test.csv")
try(read.csv("test.csv",fill=FALSE))
> >>
## assumes header=TRUE, fill=TRUE; should be a little more careful
##  with comment, quote arguments (possibly explicit)
## ... contains information about quote, comment.char, sep
Read.csv <- function(fn,sep=",",...) {
 colnames <- scan(fn,nlines=1,what="character",sep=sep,...)
 ncolnames <- length(colnames)
 maxcols <- max(count.fields(fn,sep=sep,...))
 if (maxcols>ncolnames) {
   colnames <- c(colnames,paste("V",(ncolnames+1):maxcols,sep=""))
 }
 ## assumes you don't have any other columns labeled "V[large number]"
 read.csv(fn,...,col.names=colnames)
}

Read.csv("test.csv")


From dtenenba at fhcrc.org  Thu Mar  3 19:50:23 2011
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Thu, 3 Mar 2011 10:50:23 -0800
Subject: [Rd] Problem building R-2.13 r54645 on Windows
Message-ID: <AANLkTi=LkowmuK9ZdKN+zDsVvjevJKT4K7Wiac3w0TPt@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110303/85170c7e/attachment.pl>

From H.C.Pumphrey at ed.ac.uk  Fri Mar  4 11:35:08 2011
From: H.C.Pumphrey at ed.ac.uk (H C Pumphrey)
Date: Fri, 04 Mar 2011 10:35:08 +0000
Subject: [Rd] Fixing the HDF5 package: the on.exit mystery
Message-ID: <4D70C05C.4040905@ed.ac.uk>

Dear all,

I'm trying to fix a subtle bug in the hdf5 package. This package provides an 
interfaces to the HDF5 library and hence allows one to load data into R from 
files in the HDF5 format. The bug appeared during a period in which R changed 
but the package did not.

I include below both the R and C code, stripped of everything except what is 
needed to show the bug. What is supposed to happen is

(*) the user calls R function hdf5load()
(*) hdf5load() calls C function do_hdf5load()
(*) do_hdf5load() opens the HDF5 file recording its HDF5 file id (fid)
(*) do_hdf5load() calls C function setup_onexit, passing fid to it
(*) setup_onexit sets up the on.exit call to be R function hdf5cleanup with 
fid as its argument
(*)  C function do_hdf5load() walks the HDF5 file's tree structure of groups 
of groups of [...] of datasets, mapping them to an R list of lists of [...] of 
array variables. This recursive procedure may have a variety of exit points 
buried inside itself.
(*) C function do_hdf5load() exits for some reason. R function hdf5load() 
therefore exits but before doing so it calls its on.exit code (which is 
hdf5cleanup(fid) with the right value of fid), closing the file.

The problem is that when do_hdf5load() and hdf5load() exit, hdf5cleanup() is 
usually not called, meaning that the file is left open. You might not notice 
this, but if you are processing a few year's worth of data, which is stored at 
1 file per day, you may end up with the system limit number of files open and 
be unable to open any more.

I have a suspicion that the problem dates to a change in R at 2.8.0. If you do 
  help(on.exit) it notes under "Details" that: "Where ?expr? was evaluated 
changed in R 2.8.0 ..." But it is not clear how I should modify the C code to 
force hdf5cleanup() to be reliably called when do_hdf5load() exits.

Any help appreciated.

Hugh (possibly the nearest thing to a maintainer that the hdf5 package 
currently has)

(R and C code follow)

#----------------------------------------------------------------
"hdf5load" <-  function (file, load = TRUE, verbosity = 0, tidy = FALSE)
{
   call <- sys.call()
   .External("do_hdf5load", call, sys.frame(sys.parent()), file, load,
             as.integer (verbosity), as.logical(tidy),
             PACKAGE="hdf5")
}

"hdf5cleanup" <- function (fid)
{
   call <- sys.call()
   print("In hdf5cleanup: calling do_hdf5cleanup")
   invisible(.External("do_hdf5cleanup", call, sys.frame(sys.parent()), fid,
             PACKAGE="hdf5"))
}
#----------------------------------------------------------------


/*---------------------------------------------------------------*/
SEXP do_hdf5load (SEXP args)
{
/* Code to process args snipped */
  if ((fid = H5Fopen (path, H5F_ACC_RDONLY, H5P_DEFAULT)) < 0)
     errorcall (call, "unable to open HDF file: %s", path);

   setup_onexit (fid, env);
   /* Messy code to walk tree structure of file snipped */
}

/* The following function shown in its entirety */
setup_onexit (hid_t fid, SEXP env)
{
   eval (lang2 (install ("on.exit"),
                lang2 (install ("hdf5cleanup"),
                       ScalarInteger (fid))),
         env);
}

SEXP
do_hdf5cleanup (SEXP args)
{
/* Code to process args snipped */
/* various cleanup things done including this: */
H5Fclose(fid)
}
/*---------------------------------------------------------------*/

-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From renaud at mancala.cbio.uct.ac.za  Fri Mar  4 12:30:02 2011
From: renaud at mancala.cbio.uct.ac.za (Renaud Gaujoux)
Date: Fri, 04 Mar 2011 13:30:02 +0200
Subject: [Rd] Extending type list: names and inherited methods issue
Message-ID: <4D70CD3A.5020804@cbio.uct.ac.za>

Hi,

I want to extend the type list, but it looks like the names are not 
handled properly (in the show method), not the [ method. See below for 
code example.
I imagine this comes from the S3/S4 mixing, but I would like to 
understand and the recommended work around (that avoid redefining all 
the list methods [, $, etc...).
Thank you.

Bests,
Renaud

# define S4 class that inherits from list
setClass('A', contains='list')

# nothing to say when one creates an object with an unnamed list
x <- new('A', list(1,2,3))
x

# set the names: seems ok but they are not printed
names(x) <- letters[1:3]
names(x)
x
# same thing if one put the S3 .Data slot
names(x at .Data) <- letters[4:6]
names(x)
x

# the subsetting works but returns a list instead of the expected object 
of class A
class(x[1])


 > sessionInfo()
R version 2.12.1 (2010-12-16)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
  [1] LC_CTYPE=en_ZA.utf8       LC_NUMERIC=C              
LC_TIME=en_ZA.utf8        LC_COLLATE=en_ZA.utf8     
LC_MONETARY=C             LC_MESSAGES=en_ZA.utf8    LC_PAPER=en_ZA.utf8
  [8] LC_NAME=C                 LC_ADDRESS=C              
LC_TELEPHONE=C            LC_MEASUREMENT=en_ZA.utf8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

-- 
Renaud Gaujoux
Computational Biology - University of Cape Town
South Africa


 

###
UNIVERSITY OF CAPE TOWN 

This e-mail is subject to the UCT ICT policies and e-mai...{{dropped:5}}


From kasperdanielhansen at gmail.com  Fri Mar  4 16:45:37 2011
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Fri, 4 Mar 2011 10:45:37 -0500
Subject: [Rd] removing files on windows as part of vignette building
Message-ID: <AANLkTinqaAeziz7B-eMS9XRTFZyj_+CY1a_DEM-N-yQ2@mail.gmail.com>

This is about the Bioconductor package Genominator.

As part of the vignette building process, we create two sizable
sqlite3 databases, in the vignette directory (inst/doc).  When we
build the source tarball, these databases are deleted, but when a
Windows binary is being made on the Bioconductor build servers the
file(s) are not removed (as far as I read the documentation/code they
ought to be).  If I try to remove them explicitly, by including a
Makefile with a target

clean:
          rm -rf Rplots.pdf my.db pmy.db

(there are two databases), it fails with the error message

 rm: cannot remove `Rplots.pdf': Device or resource busy
rm: cannot remove `my.db': Device or resource busy
rm: cannot remove `pmy.db': Device or resource busy
make: *** [all] Error 1
Error in tools::buildVignettes(dir = ".") : running 'make' failed
Execution halted

Note that
(1) This did not happen under R-2.11
(2) It does not happen under Linux or OS X.

I believe this is a general phenomenon of no cleanup on windows.  If I
look at the affy package from Bioconductor, the windows binary has a
file
  doc/Rplots.pdf
that is not present inside inst/doc in the source tarball.

I have not been able to find a package on CRAN with a vignette with
plots in it, that did also include the pdf version of the vignette or
where Rplots.pdf was not also included in the source tarball, so this
may be an issue specific to the Bioconductor build system.

I guess an alternative to creating the database inside inst/doc is to
use a tempfile.  Comments?

Kasper


From dtenenba at fhcrc.org  Fri Mar  4 19:53:25 2011
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Fri, 4 Mar 2011 10:53:25 -0800
Subject: [Rd] Problem building R-2.13 r54645 on Windows
In-Reply-To: <AANLkTi=LkowmuK9ZdKN+zDsVvjevJKT4K7Wiac3w0TPt@mail.gmail.com>
References: <AANLkTi=LkowmuK9ZdKN+zDsVvjevJKT4K7Wiac3w0TPt@mail.gmail.com>
Message-ID: <AANLkTinQiOHPrxHVdO9jnWGOt0rnJYKsVnsfabaM3AqS@mail.gmail.com>

On Thu, Mar 3, 2011 at 10:50 AM, Dan Tenenbaum <dtenenba at fhcrc.org> wrote:
> I am building R-2.13 r54645 from source as described here:
> http://cran.r-project.org/doc/manuals/R-admin.html#Building-from-source
> The "make all recommended" command ends as follows on both 32 and 64-bit
> Windows (Windows Server 2003 R2 Enterprise Edition Service Pack 2 and
> Windows Server 2008 R2 Enterprise):
> gcc -std=gnu99 -I../../include -DHAVE_CONFIG_H ?-O3 -Wall -pedantic ? -c
> zutil.c -o z
> o
> make[4]: *** No rule to make target `Rzlib.def', needed by `Rzlib.dll'.
> ?Stop.
> make[3]: *** [rlibs] Error 1
> make[2]: *** [../../bin/i386/R.dll] Error 2
> make[1]: *** [rbuild] Error 2
> make: *** [all] Error 2

It looks like somebody worked on this--thanks.
However, now I am getting:


--- Making recommended packages
make[1]: *** No rule to make target `MASS.ts', needed by
`stamp-recommended'.  Stop.
make: *** [recommended] Error 2

Can you help?
Thanks
Dan


> Thanks
> Dan
>


From dtenenba at fhcrc.org  Fri Mar  4 20:36:40 2011
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Fri, 4 Mar 2011 11:36:40 -0800
Subject: [Rd] Problem building R-2.13 r54645 on Windows
In-Reply-To: <AANLkTinQiOHPrxHVdO9jnWGOt0rnJYKsVnsfabaM3AqS@mail.gmail.com>
References: <AANLkTi=LkowmuK9ZdKN+zDsVvjevJKT4K7Wiac3w0TPt@mail.gmail.com>
	<AANLkTinQiOHPrxHVdO9jnWGOt0rnJYKsVnsfabaM3AqS@mail.gmail.com>
Message-ID: <AANLkTi=R1B7N3gnp+0YTdaokaTee_KTR3YTOQ=MPbK5i@mail.gmail.com>

On Fri, Mar 4, 2011 at 10:53 AM, Dan Tenenbaum <dtenenba at fhcrc.org> wrote:
> On Thu, Mar 3, 2011 at 10:50 AM, Dan Tenenbaum <dtenenba at fhcrc.org> wrote:
>> I am building R-2.13 r54645 from source as described here:
>> http://cran.r-project.org/doc/manuals/R-admin.html#Building-from-source
>> The "make all recommended" command ends as follows on both 32 and 64-bit
>> Windows (Windows Server 2003 R2 Enterprise Edition Service Pack 2 and
>> Windows Server 2008 R2 Enterprise):
>> gcc -std=gnu99 -I../../include -DHAVE_CONFIG_H ?-O3 -Wall -pedantic ? -c
>> zutil.c -o z
>> o
>> make[4]: *** No rule to make target `Rzlib.def', needed by `Rzlib.dll'.
>> ?Stop.
>> make[3]: *** [rlibs] Error 1
>> make[2]: *** [../../bin/i386/R.dll] Error 2
>> make[1]: *** [rbuild] Error 2
>> make: *** [all] Error 2
>
> It looks like somebody worked on this--thanks.
> However, now I am getting:
>
>
> --- Making recommended packages
> make[1]: *** No rule to make target `MASS.ts', needed by
> `stamp-recommended'. ?Stop.
> make: *** [recommended] Error 2
>
> Can you help?
>


Never mind, this last bit was my own fault--I overlooked a step in the
build process.

The original issue has been fixed, so I'm happy now. Thanks Brian!

Dan

 Thanks
> Dan
>
>
>> Thanks
>> Dan
>>
>


From ripley at stats.ox.ac.uk  Fri Mar  4 22:12:20 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 4 Mar 2011 21:12:20 +0000 (GMT)
Subject: [Rd] Fixing the HDF5 package: the on.exit mystery
In-Reply-To: <4D70C05C.4040905@ed.ac.uk>
References: <4D70C05C.4040905@ed.ac.uk>
Message-ID: <alpine.LFD.2.02.1103041305130.25090@toucan.stats.ox.ac.uk>

Looks like you should be using finalizers instead.  See the RODBC 
package for an example of this.

On Fri, 4 Mar 2011, H C Pumphrey wrote:

> Dear all,
>
> I'm trying to fix a subtle bug in the hdf5 package. This package provides an 
> interfaces to the HDF5 library and hence allows one to load data into R from 
> files in the HDF5 format. The bug appeared during a period in which R changed 
> but the package did not.
>
> I include below both the R and C code, stripped of everything except what is 
> needed to show the bug. What is supposed to happen is
>
> (*) the user calls R function hdf5load()
> (*) hdf5load() calls C function do_hdf5load()
> (*) do_hdf5load() opens the HDF5 file recording its HDF5 file id (fid)
> (*) do_hdf5load() calls C function setup_onexit, passing fid to it
> (*) setup_onexit sets up the on.exit call to be R function hdf5cleanup with 
> fid as its argument
> (*)  C function do_hdf5load() walks the HDF5 file's tree structure of groups 
> of groups of [...] of datasets, mapping them to an R list of lists of [...] 
> of array variables. This recursive procedure may have a variety of exit 
> points buried inside itself.
> (*) C function do_hdf5load() exits for some reason. R function hdf5load() 
> therefore exits but before doing so it calls its on.exit code (which is 
> hdf5cleanup(fid) with the right value of fid), closing the file.
>
> The problem is that when do_hdf5load() and hdf5load() exit, hdf5cleanup() is 
> usually not called, meaning that the file is left open. You might not notice 
> this, but if you are processing a few year's worth of data, which is stored 
> at 1 file per day, you may end up with the system limit number of files open 
> and be unable to open any more.
>
> I have a suspicion that the problem dates to a change in R at 2.8.0. If you 
> do  help(on.exit) it notes under "Details" that: "Where ?expr? was evaluated 
> changed in R 2.8.0 ..." But it is not clear how I should modify the C code to 
> force hdf5cleanup() to be reliably called when do_hdf5load() exits.
> Any help appreciated.
>
> Hugh (possibly the nearest thing to a maintainer that the hdf5 package 
> currently has)
>
> (R and C code follow)
>
> #----------------------------------------------------------------
> "hdf5load" <-  function (file, load = TRUE, verbosity = 0, tidy = FALSE)
> {
>  call <- sys.call()
>  .External("do_hdf5load", call, sys.frame(sys.parent()), file, load,
>            as.integer (verbosity), as.logical(tidy),
>            PACKAGE="hdf5")
> }
>
> "hdf5cleanup" <- function (fid)
> {
>  call <- sys.call()
>  print("In hdf5cleanup: calling do_hdf5cleanup")
>  invisible(.External("do_hdf5cleanup", call, sys.frame(sys.parent()), fid,
>            PACKAGE="hdf5"))
> }
> #----------------------------------------------------------------
>
>
> /*---------------------------------------------------------------*/
> SEXP do_hdf5load (SEXP args)
> {
> /* Code to process args snipped */
> if ((fid = H5Fopen (path, H5F_ACC_RDONLY, H5P_DEFAULT)) < 0)
>    errorcall (call, "unable to open HDF file: %s", path);
>
>  setup_onexit (fid, env);
>  /* Messy code to walk tree structure of file snipped */
> }
>
> /* The following function shown in its entirety */
> setup_onexit (hid_t fid, SEXP env)
> {
>  eval (lang2 (install ("on.exit"),
>               lang2 (install ("hdf5cleanup"),
>                      ScalarInteger (fid))),
>        env);
> }
>
> SEXP
> do_hdf5cleanup (SEXP args)
> {
> /* Code to process args snipped */
> /* various cleanup things done including this: */
> H5Fclose(fid)
> }
> /*---------------------------------------------------------------*/


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From diggsb at ohsu.edu  Sat Mar  5 00:09:34 2011
From: diggsb at ohsu.edu (Brian Diggs)
Date: Fri, 4 Mar 2011 15:09:34 -0800
Subject: [Rd] Minor typo in "Writing R Extensions"
Message-ID: <4D71712E.5020909@ohsu.edu>

In "Writing R Extensions", section 1.1.1, the paragraph talking about 
the Depends field has an extra right parenthesis at the end of the 
second sentence (or is missing a left parenthesis somewhere).  This is 
on line 392 of R-exts.texi (revision 54667). I have attached a diff, 
thought I don't know if it will go through.

I don't know if R-devel is the right place to send this, but I didn't 
see an email address to send corrections on the documentation.

-- 
Brian S. Diggs, PhD
Senior Research Associate, Department of Surgery
Oregon Health & Science University
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: R-exts.texi.diff
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110304/5f6e7b35/attachment.pl>

From david.kirkby at onetel.net  Sat Mar  5 00:18:15 2011
From: david.kirkby at onetel.net (Dr. David Kirkby)
Date: Fri, 04 Mar 2011 23:18:15 +0000
Subject: [Rd] Does R use "computed gotos" - a gcc extension of C?
Message-ID: <4D717337.8020806@onetel.net>

The R manual says R will not build with gcc on 64-bit Solaris x86 with gcc

http://cran.r-project.org/doc/manuals/R-admin.html#Solaris

"Tests with gcc32 on ?x86? and ?amd64? have been less successful: ?x86? builds 
have failed on tests using complex arithmetic33, whereas on ?amd64? the builds 
have failed to complete in several different ways, most recently with relocation 
errors for libRblas.so. "

I know what the "relocation errors" problem is. That library (and in fact two 
other R libraries) all have non-PIC code in them, despite the fact the source is 
compiled with the -fPIC option.

http://blogs.sun.com/rie/entry/my_relocations_don_t_fit

shows how to prove this. If one runs this command on Solaris:

$ elfdump -d libRblas.so | fgrep TEXTREL

there is some output showing that theres non-PIC code present in the R library.

R is compiled with -fPIC on Solaris, but certain things can cause non-PIC code 
to be generated even with that option. One is by the use of "computed gotos" 
which is a gcc extension. I'm wondering if R uses any of these.

I'd love to track down this problem, so R can build with gcc. R is used in the 
Sage maths project

http://www.sagemath.org/

and R is the only component of Sage which will not build with gcc on 64-bit 
Solaris x86. Many components will not build with Sun Studio, but this R issue 
means we need to have two compilers, not just one.

-- 
A: Because it messes up the order in which people normally read text.
Q: Why is top-posting such a bad thing?
A: Top-posting.
Q: What is the most annoying thing in e-mail?

Dave


From luke-tierney at uiowa.edu  Sat Mar  5 00:40:48 2011
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Fri, 4 Mar 2011 17:40:48 -0600
Subject: [Rd] Does R use "computed gotos" - a gcc extension of C?
In-Reply-To: <4D717337.8020806@onetel.net>
References: <4D717337.8020806@onetel.net>
Message-ID: <alpine.DEB.2.00.1103041739500.1796@luke-inspiron>

On Fri, 4 Mar 2011, Dr. David Kirkby wrote:

> The R manual says R will not build with gcc on 64-bit Solaris x86 with gcc
>
> http://cran.r-project.org/doc/manuals/R-admin.html#Solaris
>
> "Tests with gcc32 on ?x86? and ?amd64? have been less successful: ?x86? 
> builds have failed on tests using complex arithmetic33, whereas on ?amd64? 
> the builds have failed to complete in several different ways, most recently 
> with relocation errors for libRblas.so. "
>
> I know what the "relocation errors" problem is. That library (and in fact two 
> other R libraries) all have non-PIC code in them, despite the fact the source 
> is compiled with the -fPIC option.
>
> http://blogs.sun.com/rie/entry/my_relocations_don_t_fit
>
> shows how to prove this. If one runs this command on Solaris:
>
> $ elfdump -d libRblas.so | fgrep TEXTREL
>
> there is some output showing that theres non-PIC code present in the R 
> library.
>
> R is compiled with -fPIC on Solaris, but certain things can cause non-PIC 
> code to be generated even with that option. One is by the use of "computed 
> gotos" which is a gcc extension. I'm wondering if R uses any of these.

Yes -- in the byte code interpreter in eval.c

luke

>
> I'd love to track down this problem, so R can build with gcc. R is used in 
> the Sage maths project
>
> http://www.sagemath.org/
>
> and R is the only component of Sage which will not build with gcc on 64-bit 
> Solaris x86. Many components will not build with Sun Studio, but this R issue 
> means we need to have two compilers, not just one.
>
>

-- 
Luke Tierney
Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From HodgessE at uhd.edu  Sat Mar  5 18:36:08 2011
From: HodgessE at uhd.edu (Hodgess, Erin)
Date: Sat, 5 Mar 2011 11:36:08 -0600
Subject: [Rd] problem with building bitmapdll on Windows
Message-ID: <586A4828D7AAA04CA9B258C50A28DA206DB560@BALI.uhd.campus>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110305/ed0341b7/attachment.pl>

From ripley at stats.ox.ac.uk  Sat Mar  5 19:00:04 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 5 Mar 2011 18:00:04 +0000 (GMT)
Subject: [Rd] problem with building bitmapdll on Windows
In-Reply-To: <586A4828D7AAA04CA9B258C50A28DA206DB560@BALI.uhd.campus>
References: <586A4828D7AAA04CA9B258C50A28DA206DB560@BALI.uhd.campus>
Message-ID: <alpine.OSX.1.00.1103051757380.95710@tystie.local>

On Sat, 5 Mar 2011, Hodgess, Erin wrote:

> Dear R Development People:
>
> I was trying to build R-2.12.2 from source on a Windows XP machine.
>
> Doing the make all recommended works fine, but building the bitmap 
> dll is a problem.
>
> It seems to be in the libpng directory.  I got libpng-1.5.1, and 
> untarred it.  However, there is no makefile.mingw file in the 
> scripts directory.
>
> I then obtained a version of libpng-1.4.5, and the file is there. 
> The dll file builds fine.
>
> We might want to look at the libpng-1.5.1 directory.

libpng 1.5.1 is not supported for R 2.12.2: it will be for 2.13.0. 
The documentation does say so ...

You need libpng, jpeg and libtiff sources (available, e.g., from 
http://www.libpng.org/, http://www.ijg.org and 
ftp://ftp.remotesensing.org/pub/libtiff/). You will need files 
libpng-1.2.18.tar.gz (including ?1.4.x? but not ?1.5.x?), 
jpegsrc.v6b.tar.gz, tiff-3.8.0.tar.gz (but not ?4.0.0beta?) or later.

>
> Thanks for listening,
> Sincerely,
> Erin
>
>
> Erin M. Hodgess, PhD
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> mailto: hodgesse at uhd.edu
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From HodgessE at uhd.edu  Sat Mar  5 19:17:43 2011
From: HodgessE at uhd.edu (Hodgess, Erin)
Date: Sat, 5 Mar 2011 12:17:43 -0600
Subject: [Rd] problem with building bitmapdll on Windows
References: <586A4828D7AAA04CA9B258C50A28DA206DB560@BALI.uhd.campus>
	<alpine.OSX.1.00.1103051757380.95710@tystie.local>
Message-ID: <586A4828D7AAA04CA9B258C50A28DA206DB561@BALI.uhd.campus>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110305/fbd87290/attachment.pl>

From david.kirkby at onetel.net  Sat Mar  5 22:02:01 2011
From: david.kirkby at onetel.net (Dr. David Kirkby)
Date: Sat, 05 Mar 2011 21:02:01 +0000
Subject: [Rd] Does R use "computed gotos" - a gcc extension of C?
In-Reply-To: <alpine.DEB.2.00.1103041739500.1796@luke-inspiron>
References: <4D717337.8020806@onetel.net>
	<alpine.DEB.2.00.1103041739500.1796@luke-inspiron>
Message-ID: <4D72A4C9.9010000@onetel.net>

On 03/ 4/11 11:40 PM, luke-tierney at uiowa.edu wrote:
> On Fri, 4 Mar 2011, Dr. David Kirkby wrote:
>
>> The R manual says R will not build with gcc on 64-bit Solaris x86 with
>> gcc
>>
>> http://cran.r-project.org/doc/manuals/R-admin.html#Solaris
>>
>> "Tests with gcc32 on ?x86? and ?amd64? have been less successful:
>> ?x86? builds have failed on tests using complex arithmetic33, whereas
>> on ?amd64? the builds have failed to complete in several different
>> ways, most recently with relocation errors for libRblas.so. "
>>
>> I know what the "relocation errors" problem is. That library (and in
>> fact two other R libraries) all have non-PIC code in them, despite the
>> fact the source is compiled with the -fPIC option.
>>
>> http://blogs.sun.com/rie/entry/my_relocations_don_t_fit
>>
>> shows how to prove this. If one runs this command on Solaris:
>>
>> $ elfdump -d libRblas.so | fgrep TEXTREL
>>
>> there is some output showing that theres non-PIC code present in the R
>> library.
>>
>> R is compiled with -fPIC on Solaris, but certain things can cause
>> non-PIC code to be generated even with that option. One is by the use
>> of "computed gotos" which is a gcc extension. I'm wondering if R uses
>> any of these.
>
> Yes -- in the byte code interpreter in eval.c
>
> luke

Thank you Luke. Do you know if there may be any others?

Do you know if that bit of code gets compiled into all 3 of the R libraries? I 
tried replacing


#define NEXT() (__extension__ ({goto *(*pc++).v;}))


by a function which did absolutely nothing. The code built, but still had the 
library issues.

I'm almost certain that the definition of NEXT will cause problems, but I'm not 
convinced it is the only issue.

What happens if a non-GNU compiler is used? I assume these GNU extensions don't 
get used, so how comes the code builds? Is there any way I can disable the use 
of the GNU extensions, while still building with gcc.

It is rather annoying that the code has __extension__ in it, which disables the 
warnings about the use of GCC extensions.

http://gcc.gnu.org/onlinedocs/gcc/Alternate-Keywords.html

Why is there a need to hide the use of the extensions? I'd personally like to 
see just standard C used, without any extensions. Then problems like I'm having 
would be less likely to occur.


-- 
A: Because it messes up the order in which people normally read text.
Q: Why is top-posting such a bad thing?
A: Top-posting.
Q: What is the most annoying thing in e-mail?

Dave


From luke-tierney at uiowa.edu  Sat Mar  5 22:31:04 2011
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Sat, 5 Mar 2011 15:31:04 -0600
Subject: [Rd] Does R use "computed gotos" - a gcc extension of C?
In-Reply-To: <4D72A4C9.9010000@onetel.net>
References: <4D717337.8020806@onetel.net>
	<alpine.DEB.2.00.1103041739500.1796@luke-inspiron>
	<4D72A4C9.9010000@onetel.net>
Message-ID: <alpine.DEB.2.00.1103051522190.1796@luke-inspiron>

On Sat, 5 Mar 2011, Dr. David Kirkby wrote:

> On 03/ 4/11 11:40 PM, luke-tierney at uiowa.edu wrote:
>> On Fri, 4 Mar 2011, Dr. David Kirkby wrote:
>> 
>>> The R manual says R will not build with gcc on 64-bit Solaris x86 with
>>> gcc
>>> 
>>> http://cran.r-project.org/doc/manuals/R-admin.html#Solaris
>>> 
>>> "Tests with gcc32 on ?x86? and ?amd64? have been less successful:
>>> ?x86? builds have failed on tests using complex arithmetic33, whereas
>>> on ?amd64? the builds have failed to complete in several different
>>> ways, most recently with relocation errors for libRblas.so. "
>>> 
>>> I know what the "relocation errors" problem is. That library (and in
>>> fact two other R libraries) all have non-PIC code in them, despite the
>>> fact the source is compiled with the -fPIC option.
>>> 
>>> http://blogs.sun.com/rie/entry/my_relocations_don_t_fit
>>> 
>>> shows how to prove this. If one runs this command on Solaris:
>>> 
>>> $ elfdump -d libRblas.so | fgrep TEXTREL
>>> 
>>> there is some output showing that theres non-PIC code present in the R
>>> library.
>>> 
>>> R is compiled with -fPIC on Solaris, but certain things can cause
>>> non-PIC code to be generated even with that option. One is by the use
>>> of "computed gotos" which is a gcc extension. I'm wondering if R uses
>>> any of these.
>> 
>> Yes -- in the byte code interpreter in eval.c
>> 
>> luke
>
> Thank you Luke. Do you know if there may be any others?

I do not.

> Do you know if that bit of code gets compiled into all 3 of the R libraries? 
> I tried replacing

I do not know

> #define NEXT() (__extension__ ({goto *(*pc++).v;}))
>
>
> by a function which did absolutely nothing. The code built, but still had the 
> library issues.
>
> I'm almost certain that the definition of NEXT will cause problems, but I'm 
> not convinced it is the only issue.
>
> What happens if a non-GNU compiler is used? I assume these GNU extensions 
> don't get used, so how comes the code builds? Is there any way I can disable 
> the use of the GNU extensions, while still building with gcc.

This particular bit It only uses the gcc extensions for gcc compilers,
and this can be turned off by defining NO_THREADED_CODE.

>
> It is rather annoying that the code has __extension__ in it, which disables 
> the warnings about the use of GCC extensions.
>
> http://gcc.gnu.org/onlinedocs/gcc/Alternate-Keywords.html
>
> Why is there a need to hide the use of the extensions?

To avoid spurious warnings

> I'd personally like to 
> see just standard C used, without any extensions. Then problems like I'm 
> having would be less likely to occur.

This extention is very useful for implementing byte code interpreters,
which is why it is being used.  As mentioned above, its use can be
turned off.

luke

-- 
Luke Tierney
Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From david.kirkby at onetel.net  Sat Mar  5 23:06:44 2011
From: david.kirkby at onetel.net (Dr. David Kirkby)
Date: Sat, 05 Mar 2011 22:06:44 +0000
Subject: [Rd] Does R use "computed gotos" - a gcc extension of C?
In-Reply-To: <alpine.DEB.2.00.1103051522190.1796@luke-inspiron>
References: <4D717337.8020806@onetel.net>
	<alpine.DEB.2.00.1103041739500.1796@luke-inspiron>
	<4D72A4C9.9010000@onetel.net>
	<alpine.DEB.2.00.1103051522190.1796@luke-inspiron>
Message-ID: <4D72B3F4.9010408@onetel.net>

On 03/ 5/11 09:31 PM, luke-tierney at uiowa.edu wrote:
> On Sat, 5 Mar 2011, Dr. David Kirkby wrote:

>>> Yes -- in the byte code interpreter in eval.c
>>>
>>> luke
>>
>> Thank you Luke. Do you know if there may be any others?
>
> I do not.
>
>> Do you know if that bit of code gets compiled into all 3 of the R
>> libraries? I tried replacing
>
> I do not know
>
>> #define NEXT() (__extension__ ({goto *(*pc++).v;}))
>>
>>
>> by a function which did absolutely nothing. The code built, but still
>> had the library issues.
>>
>> I'm almost certain that the definition of NEXT will cause problems,
>> but I'm not convinced it is the only issue.
>>
>> What happens if a non-GNU compiler is used? I assume these GNU
>> extensions don't get used, so how comes the code builds? Is there any
>> way I can disable the use of the GNU extensions, while still building
>> with gcc.
>
> This particular bit It only uses the gcc extensions for gcc compilers,
> and this can be turned off by defining NO_THREADED_CODE.

Does that have a significant impact on performance? I would normally associate 
"threaded" with meaning doing things in parallel.

Could that be defined when compiling just this one file, or should it be done 
when building the whole of R?

>> It is rather annoying that the code has __extension__ in it, which
>> disables the warnings about the use of GCC extensions.
>>
>> http://gcc.gnu.org/onlinedocs/gcc/Alternate-Keywords.html
>>
>> Why is there a need to hide the use of the extensions?
>
> To avoid spurious warnings


>> I'd personally like to see just standard C used, without any
>> extensions. Then problems like I'm having would be less likely to occur.
>
> This extention is very useful for implementing byte code interpreters,
> which is why it is being used. As mentioned above, its use can be
> turned off.

If this does solve the Solaris problem, that would be worth mentioning in the R 
installation guide. I'll let you know of the result of that.

> luke

Thank you for your help Luke.

-- 
A: Because it messes up the order in which people normally read text.
Q: Why is top-posting such a bad thing?
A: Top-posting.
Q: What is the most annoying thing in e-mail?

Dave


From david.kirkby at onetel.net  Sun Mar  6 01:06:48 2011
From: david.kirkby at onetel.net (Dr. David Kirkby)
Date: Sun, 06 Mar 2011 00:06:48 +0000
Subject: [Rd] Does R use "computed gotos" - a gcc extension of C?
In-Reply-To: <alpine.DEB.2.00.1103051522190.1796@luke-inspiron>
References: <4D717337.8020806@onetel.net>
	<alpine.DEB.2.00.1103041739500.1796@luke-inspiron>
	<4D72A4C9.9010000@onetel.net>
	<alpine.DEB.2.00.1103051522190.1796@luke-inspiron>
Message-ID: <4D72D018.4050006@onetel.net>

On 03/ 5/11 09:31 PM, luke-tierney at uiowa.edu wrote:
> On Sat, 5 Mar 2011, Dr. David Kirkby wrote:
>
>> On 03/ 4/11 11:40 PM, luke-tierney at uiowa.edu wrote:
>>> On Fri, 4 Mar 2011, Dr. David Kirkby wrote:
>>>
>>>> The R manual says R will not build with gcc on 64-bit Solaris x86 with
>>>> gcc
>>>>
>>>> http://cran.r-project.org/doc/manuals/R-admin.html#Solaris
>>>>
>>>> "Tests with gcc32 on ?x86? and ?amd64? have been less successful:
>>>> ?x86? builds have failed on tests using complex arithmetic33, whereas
>>>> on ?amd64? the builds have failed to complete in several different
>>>> ways, most recently with relocation errors for libRblas.so. "
>>>>
>>>> I know what the "relocation errors" problem is. That library (and in
>>>> fact two other R libraries) all have non-PIC code in them, despite the
>>>> fact the source is compiled with the -fPIC option.
>>>>
>>>> http://blogs.sun.com/rie/entry/my_relocations_don_t_fit
>>>>
>>>> shows how to prove this. If one runs this command on Solaris:
>>>>
>>>> $ elfdump -d libRblas.so | fgrep TEXTREL
>>>>
>>>> there is some output showing that theres non-PIC code present in the R
>>>> library.
>>>>
>>>> R is compiled with -fPIC on Solaris, but certain things can cause
>>>> non-PIC code to be generated even with that option. One is by the use
>>>> of "computed gotos" which is a gcc extension. I'm wondering if R uses
>>>> any of these.
>>>
>>> Yes -- in the byte code interpreter in eval.c
>>>
>>> luke
>>
>> Thank you Luke. Do you know if there may be any others?
>
> I do not.
>
>> Do you know if that bit of code gets compiled into all 3 of the R
>> libraries? I tried replacing
>
> I do not know
>
>> #define NEXT() (__extension__ ({goto *(*pc++).v;}))
>>
>>
>> by a function which did absolutely nothing. The code built, but still
>> had the library issues.
>>
>> I'm almost certain that the definition of NEXT will cause problems,
>> but I'm not convinced it is the only issue.
>>
>> What happens if a non-GNU compiler is used? I assume these GNU
>> extensions don't get used, so how comes the code builds? Is there any
>> way I can disable the use of the GNU extensions, while still building
>> with gcc.
>
> This particular bit It only uses the gcc extensions for gcc compilers,
> and this can be turned off by defining NO_THREADED_CODE.
>
>>
>> It is rather annoying that the code has __extension__ in it, which
>> disables the warnings about the use of GCC extensions.
>>
>> http://gcc.gnu.org/onlinedocs/gcc/Alternate-Keywords.html
>>
>> Why is there a need to hide the use of the extensions?
>
> To avoid spurious warnings
>
>> I'd personally like to see just standard C used, without any
>> extensions. Then problems like I'm having would be less likely to occur.
>
> This extention is very useful for implementing byte code interpreters,
> which is why it is being used. As mentioned above, its use can be
> turned off.
>
> luke

That did not solve my problem. Every single shared library that R builds has 
this issue. I've no idea what the hell is causing it, though computed gotos are 
known as one possible source of the problems.

Is there any way to disable all GNU extensions for all files? It might be some 
other GNUim that's causing it.



-- 
A: Because it messes up the order in which people normally read text.
Q: Why is top-posting such a bad thing?
A: Top-posting.
Q: What is the most annoying thing in e-mail?

Dave


From jmc at r-project.org  Sun Mar  6 20:07:14 2011
From: jmc at r-project.org (John Chambers)
Date: Sun, 06 Mar 2011 11:07:14 -0800
Subject: [Rd] Extending type list: names and inherited methods issue
In-Reply-To: <4D70CD3A.5020804@cbio.uct.ac.za>
References: <4D70CD3A.5020804@cbio.uct.ac.za>
Message-ID: <4D73DB62.1080001@r-project.org>

The "names" slot is not part of the basic vector types/classes.

If you want to extend named lists, extend the class "namedList":

 > getClass("namedList")
Class "namedList" [package "methods"]

Slots:

Name:      .Data     names
Class:      list character

Extends:
Class "list", from data part
Class "vector", by class "list", distance 2

Known Subclasses: "listOfMethods"

 > setClass("myNamedList", contains = "namedList")
[1] "myNamedList"
 >
 > mm <- new("myNamedList", list(a=1,b=2))
 > mm
An object of class  "myNamedList"
$a
[1] 1

$b
[1] 2


On 3/4/11 3:30 AM, Renaud Gaujoux wrote:
> Hi,
>
> I want to extend the type list, but it looks like the names are not
> handled properly (in the show method), not the [ method. See below for
> code example.
> I imagine this comes from the S3/S4 mixing, but I would like to
> understand and the recommended work around (that avoid redefining all
> the list methods [, $, etc...).
> Thank you.
>
> Bests,
> Renaud
>
> # define S4 class that inherits from list
> setClass('A', contains='list')
>
> # nothing to say when one creates an object with an unnamed list
> x <- new('A', list(1,2,3))
> x
>
> # set the names: seems ok but they are not printed
> names(x) <- letters[1:3]
> names(x)
> x
> # same thing if one put the S3 .Data slot
> names(x at .Data) <- letters[4:6]
> names(x)
> x
>
> # the subsetting works but returns a list instead of the expected object
> of class A
> class(x[1])
>
>
>  > sessionInfo()
> R version 2.12.1 (2010-12-16)
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> locale:
> [1] LC_CTYPE=en_ZA.utf8 LC_NUMERIC=C LC_TIME=en_ZA.utf8
> LC_COLLATE=en_ZA.utf8 LC_MONETARY=C LC_MESSAGES=en_ZA.utf8
> LC_PAPER=en_ZA.utf8
> [8] LC_NAME=C LC_ADDRESS=C LC_TELEPHONE=C LC_MEASUREMENT=en_ZA.utf8
> LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats graphics grDevices utils datasets methods base
>


From xie at yihui.name  Sun Mar  6 22:08:47 2011
From: xie at yihui.name (Yihui Xie)
Date: Sun, 6 Mar 2011 15:08:47 -0600
Subject: [Rd] Fwd: file mode lost in file.copy()?
In-Reply-To: <AANLkTik7S5Baq25kLJhayo--hMt92SnfwM3QKc4PLOjW@mail.gmail.com>
References: <AANLkTik7S5Baq25kLJhayo--hMt92SnfwM3QKc4PLOjW@mail.gmail.com>
Message-ID: <AANLkTimyeHXynSw1v8hEz_qbke0mN1t1ci7LBEVZqVC=@mail.gmail.com>

Hi,

I was suggested that this question should be reported to r-devel.
Could you please make file.copy() preserve the file mode information?
I see from the source code that file.copy() is basically
file.append():

    if (any(okay)) {
        okay[okay] <- file.create(to[okay])
        if (any(okay))
            okay[okay] <- file.append(to[okay], from[okay])
    }

Maybe something like this should be added to file.copy():

Sys.chmod(to[okay], file.info(from[okay])$mode)

Thanks!

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 515-294-2465 Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA




---------- Forwarded message ----------
From: Yihui Xie <xie at yihui.name>
Date: Sat, Mar 5, 2011 at 5:31 PM
Subject: file mode lost in file.copy()?
To: R Help <r-help at r-project.org>


Hi,

Recently I noticed file.copy() would discard the file mode
information. Is this the expected behaviour or a bug for file.copy()?

> file.create('testfile')
[1] TRUE

> file.info('testfile')
? ? ? ? size isdir mode ? ? ? ? ? ? ? mtime ? ? ? ? ? ? ? ctime
testfile ? ?0 FALSE ?644 2011-03-05 17:06:39 2011-03-05 17:06:39
? ? ? ? ? ? ? ? ? ? ? atime ?uid ?gid uname grname
testfile 2011-03-05 17:06:40 1000 1000 yihui ?yihui

> Sys.chmod('testfile', '0755')

> file.info('testfile')
? ? ? ? size isdir mode ? ? ? ? ? ? ? mtime ? ? ? ? ? ? ? ctime
testfile ? ?0 FALSE ?755 2011-03-05 17:06:39 2011-03-05 17:06:59
? ? ? ? ? ? ? ? ? ? ? atime ?uid ?gid uname grname
testfile 2011-03-05 17:07:00 1000 1000 yihui ?yihui

> file.copy('testfile', 'testfile2')
[1] TRUE

> file.info('testfile2')
? ? ? ? ?size isdir mode ? ? ? ? ? ? ? mtime ? ? ? ? ? ? ? ctime
testfile2 ? ?0 FALSE ?644 2011-03-05 17:07:20 2011-03-05 17:07:20
? ? ? ? ? ? ? ? ? ? ? ?atime ?uid ?gid uname grname
testfile2 2011-03-05 17:07:21 1000 1000 yihui ?yihui

> sessionInfo()
R version 2.12.2 (2011-02-25)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
?[1] LC_CTYPE=en_US.utf8 ? ? ? LC_NUMERIC=C
?[3] LC_TIME=en_US.utf8 ? ? ? ?LC_COLLATE=en_US.utf8
?[5] LC_MONETARY=C ? ? ? ? ? ? LC_MESSAGES=en_US.utf8
?[7] LC_PAPER=en_US.utf8 ? ? ? LC_NAME=C
?[9] LC_ADDRESS=C ? ? ? ? ? ? ?LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C

attached base packages:
[1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base


Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 515-294-2465 Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


From hb at biostat.ucsf.edu  Mon Mar  7 05:26:22 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sun, 6 Mar 2011 20:26:22 -0800
Subject: [Rd] Fwd: file mode lost in file.copy()?
In-Reply-To: <AANLkTimyeHXynSw1v8hEz_qbke0mN1t1ci7LBEVZqVC=@mail.gmail.com>
References: <AANLkTik7S5Baq25kLJhayo--hMt92SnfwM3QKc4PLOjW@mail.gmail.com>
	<AANLkTimyeHXynSw1v8hEz_qbke0mN1t1ci7LBEVZqVC=@mail.gmail.com>
Message-ID: <AANLkTinF7-DTeKurzyBwMivMfOwjPrMbQ3a77tzBfYZ3@mail.gmail.com>

FYI,

this seems to be a known problem that has been address in the the
devel version.  From NEWS of R v2.13.0 devel:

NEW FEATURES:

- file.copy() now copies read/write/execute permissions on files (it
already did so for directories in recursive copies).

Source: http://cran.r-project.org/bin/windows/base/NEWS.R-2.13.0dev.html

/Henrik


On Sun, Mar 6, 2011 at 1:08 PM, Yihui Xie <xie at yihui.name> wrote:
> Hi,
>
> I was suggested that this question should be reported to r-devel.
> Could you please make file.copy() preserve the file mode information?
> I see from the source code that file.copy() is basically
> file.append():
>
> ? ?if (any(okay)) {
> ? ? ? ?okay[okay] <- file.create(to[okay])
> ? ? ? ?if (any(okay))
> ? ? ? ? ? ?okay[okay] <- file.append(to[okay], from[okay])
> ? ?}
>
> Maybe something like this should be added to file.copy():
>
> Sys.chmod(to[okay], file.info(from[okay])$mode)
>
> Thanks!
>
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Phone: 515-294-2465 Web: http://yihui.name
> Department of Statistics, Iowa State University
> 2215 Snedecor Hall, Ames, IA
>
>
>
>
> ---------- Forwarded message ----------
> From: Yihui Xie <xie at yihui.name>
> Date: Sat, Mar 5, 2011 at 5:31 PM
> Subject: file mode lost in file.copy()?
> To: R Help <r-help at r-project.org>
>
>
> Hi,
>
> Recently I noticed file.copy() would discard the file mode
> information. Is this the expected behaviour or a bug for file.copy()?
>
>> file.create('testfile')
> [1] TRUE
>
>> file.info('testfile')
> ? ? ? ? size isdir mode ? ? ? ? ? ? ? mtime ? ? ? ? ? ? ? ctime
> testfile ? ?0 FALSE ?644 2011-03-05 17:06:39 2011-03-05 17:06:39
> ? ? ? ? ? ? ? ? ? ? ? atime ?uid ?gid uname grname
> testfile 2011-03-05 17:06:40 1000 1000 yihui ?yihui
>
>> Sys.chmod('testfile', '0755')
>
>> file.info('testfile')
> ? ? ? ? size isdir mode ? ? ? ? ? ? ? mtime ? ? ? ? ? ? ? ctime
> testfile ? ?0 FALSE ?755 2011-03-05 17:06:39 2011-03-05 17:06:59
> ? ? ? ? ? ? ? ? ? ? ? atime ?uid ?gid uname grname
> testfile 2011-03-05 17:07:00 1000 1000 yihui ?yihui
>
>> file.copy('testfile', 'testfile2')
> [1] TRUE
>
>> file.info('testfile2')
> ? ? ? ? ?size isdir mode ? ? ? ? ? ? ? mtime ? ? ? ? ? ? ? ctime
> testfile2 ? ?0 FALSE ?644 2011-03-05 17:07:20 2011-03-05 17:07:20
> ? ? ? ? ? ? ? ? ? ? ? ?atime ?uid ?gid uname grname
> testfile2 2011-03-05 17:07:21 1000 1000 yihui ?yihui
>
>> sessionInfo()
> R version 2.12.2 (2011-02-25)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
> ?[1] LC_CTYPE=en_US.utf8 ? ? ? LC_NUMERIC=C
> ?[3] LC_TIME=en_US.utf8 ? ? ? ?LC_COLLATE=en_US.utf8
> ?[5] LC_MONETARY=C ? ? ? ? ? ? LC_MESSAGES=en_US.utf8
> ?[7] LC_PAPER=en_US.utf8 ? ? ? LC_NAME=C
> ?[9] LC_ADDRESS=C ? ? ? ? ? ? ?LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
>
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Phone: 515-294-2465 Web: http://yihui.name
> Department of Statistics, Iowa State University
> 2215 Snedecor Hall, Ames, IA
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From xie at yihui.name  Mon Mar  7 07:17:02 2011
From: xie at yihui.name (Yihui Xie)
Date: Mon, 7 Mar 2011 00:17:02 -0600
Subject: [Rd] Fwd: file mode lost in file.copy()?
In-Reply-To: <AANLkTinF7-DTeKurzyBwMivMfOwjPrMbQ3a77tzBfYZ3@mail.gmail.com>
References: <AANLkTik7S5Baq25kLJhayo--hMt92SnfwM3QKc4PLOjW@mail.gmail.com>
	<AANLkTimyeHXynSw1v8hEz_qbke0mN1t1ci7LBEVZqVC=@mail.gmail.com>
	<AANLkTinF7-DTeKurzyBwMivMfOwjPrMbQ3a77tzBfYZ3@mail.gmail.com>
Message-ID: <AANLkTim0G7BuyGj3GHrAhJuOqNNZFKqGYPUCQgdS_q4x@mail.gmail.com>

Great! Thanks a lot!

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 515-294-2465 Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA



On Sun, Mar 6, 2011 at 10:26 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> FYI,
>
> this seems to be a known problem that has been address in the the
> devel version. ?From NEWS of R v2.13.0 devel:
>
> NEW FEATURES:
>
> - file.copy() now copies read/write/execute permissions on files (it
> already did so for directories in recursive copies).
>
> Source: http://cran.r-project.org/bin/windows/base/NEWS.R-2.13.0dev.html
>
> /Henrik
>
>
> On Sun, Mar 6, 2011 at 1:08 PM, Yihui Xie <xie at yihui.name> wrote:
>> Hi,
>>
>> I was suggested that this question should be reported to r-devel.
>> Could you please make file.copy() preserve the file mode information?
>> I see from the source code that file.copy() is basically
>> file.append():
>>
>> ? ?if (any(okay)) {
>> ? ? ? ?okay[okay] <- file.create(to[okay])
>> ? ? ? ?if (any(okay))
>> ? ? ? ? ? ?okay[okay] <- file.append(to[okay], from[okay])
>> ? ?}
>>
>> Maybe something like this should be added to file.copy():
>>
>> Sys.chmod(to[okay], file.info(from[okay])$mode)
>>
>> Thanks!
>>
>> Regards,
>> Yihui
>> --
>> Yihui Xie <xieyihui at gmail.com>
>> Phone: 515-294-2465 Web: http://yihui.name
>> Department of Statistics, Iowa State University
>> 2215 Snedecor Hall, Ames, IA
>>
>>
>>
>>
>> ---------- Forwarded message ----------
>> From: Yihui Xie <xie at yihui.name>
>> Date: Sat, Mar 5, 2011 at 5:31 PM
>> Subject: file mode lost in file.copy()?
>> To: R Help <r-help at r-project.org>
>>
>>
>> Hi,
>>
>> Recently I noticed file.copy() would discard the file mode
>> information. Is this the expected behaviour or a bug for file.copy()?
>>
>>> file.create('testfile')
>> [1] TRUE
>>
>>> file.info('testfile')
>> ? ? ? ? size isdir mode ? ? ? ? ? ? ? mtime ? ? ? ? ? ? ? ctime
>> testfile ? ?0 FALSE ?644 2011-03-05 17:06:39 2011-03-05 17:06:39
>> ? ? ? ? ? ? ? ? ? ? ? atime ?uid ?gid uname grname
>> testfile 2011-03-05 17:06:40 1000 1000 yihui ?yihui
>>
>>> Sys.chmod('testfile', '0755')
>>
>>> file.info('testfile')
>> ? ? ? ? size isdir mode ? ? ? ? ? ? ? mtime ? ? ? ? ? ? ? ctime
>> testfile ? ?0 FALSE ?755 2011-03-05 17:06:39 2011-03-05 17:06:59
>> ? ? ? ? ? ? ? ? ? ? ? atime ?uid ?gid uname grname
>> testfile 2011-03-05 17:07:00 1000 1000 yihui ?yihui
>>
>>> file.copy('testfile', 'testfile2')
>> [1] TRUE
>>
>>> file.info('testfile2')
>> ? ? ? ? ?size isdir mode ? ? ? ? ? ? ? mtime ? ? ? ? ? ? ? ctime
>> testfile2 ? ?0 FALSE ?644 2011-03-05 17:07:20 2011-03-05 17:07:20
>> ? ? ? ? ? ? ? ? ? ? ? ?atime ?uid ?gid uname grname
>> testfile2 2011-03-05 17:07:21 1000 1000 yihui ?yihui
>>
>>> sessionInfo()
>> R version 2.12.2 (2011-02-25)
>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>
>> locale:
>> ?[1] LC_CTYPE=en_US.utf8 ? ? ? LC_NUMERIC=C
>> ?[3] LC_TIME=en_US.utf8 ? ? ? ?LC_COLLATE=en_US.utf8
>> ?[5] LC_MONETARY=C ? ? ? ? ? ? LC_MESSAGES=en_US.utf8
>> ?[7] LC_PAPER=en_US.utf8 ? ? ? LC_NAME=C
>> ?[9] LC_ADDRESS=C ? ? ? ? ? ? ?LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>>
>>
>> Regards,
>> Yihui
>> --
>> Yihui Xie <xieyihui at gmail.com>
>> Phone: 515-294-2465 Web: http://yihui.name
>> Department of Statistics, Iowa State University
>> 2215 Snedecor Hall, Ames, IA
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From rflight79 at gmail.com  Mon Mar  7 15:32:14 2011
From: rflight79 at gmail.com (Robert M. Flight)
Date: Mon, 7 Mar 2011 09:32:14 -0500
Subject: [Rd] visualizing data flow and function calls
Message-ID: <AANLkTikVrjUzKf131pSmFAatCsgfhqkDwRk9eQapLPA2@mail.gmail.com>

Hi All,

I don't know if such a thing exists, but I am looking for a way to
better keep track of where data is going, how it is being modified,
and what functions are acting upon it when I give the data over to a
function that calls many subfunctions (as happens in my current
package I am working on), or in an R script I am using to do multiple
processing steps on data. Currently I find it difficult to keep
straight sometimes what a function has done to my data, or what output
from another function is required now as input to my current internal
function as I navigate through my software (or when I make changes six
months later, and multiple objects are coming in).

>From what I can tell, I want to generate sequence diagrams of my
program (http://www.agilemodeling.com/artifacts/sequenceDiagram.htm).
Is there any way to generate these kinds of things automatically in R,
or to get the information easily from R? I know I could add code to
each function to spit out that it has been called with what input, but
I thought there might be a way to do it by calling the function within
some kind of wrapper function that would tell me what other functions
are being called.

I have tried searching for such a beast, but if it exists I cannot
seem to come up with the right search terms to find it.

Thanks in advance,

-Robert

Robert M. Flight, Ph.D.
University of Louisville Bioinformatics Laboratory
University of Louisville
Louisville, KY

PH 502-852-1809 (HSC)
PH 502-852-0467 (Belknap)
EM robert.flight at louisville.edu
EM rflight79 at gmail.com

Williams and Holland's Law:
? ? ?? If enough data is collected, anything may be proven by
statistical methods.


From maechler at stat.math.ethz.ch  Mon Mar  7 19:24:27 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 7 Mar 2011 19:24:27 +0100
Subject: [Rd] print(...,digits=2) behavior
In-Reply-To: <20110213121605.GA17004@cs.cas.cz>
References: <4D4DB9E1.4000306@mcmaster.ca>
	<19791.46002.901049.478712@stat.math.ethz.ch>
	<20110213121605.GA17004@cs.cas.cz>
Message-ID: <19829.8923.126517.870485@stat.math.ethz.ch>

Taking up the thread that Ben Bolker started on Feb.5 ...

In the mean time, with lots of contributions from Petr Savicky,
we have fixed the bug (and even related bugs that were not
reported).

The consequence is that a sizable fraction of all (numeric) R
outputs does change (very) slightly, typically using a digit
more or less than previously.
Several of the recommended packages, e.g., needed some adjustments
of their  tests/*.Rout.save files.

Here are the current NEWS entries related to that:

  SIGNIFICANT USER-VISIBLE CHANGES:
[ ........ ]

    ? Printing and formatting of floating point numbers is now using
      the correct number of digits, where it previously rarely differed
      by a few digits. (See ?scientific? entry below.)  This affects
      _many_ *.Rout.save checks in packages.

  NEW FEATURES:
[ ........ ]

    ? The internal (C) function scientific(), at the heart of R's
      format.info(x), format(x), print(x), etc, for numeric x, has been
      re-written in order to provide correct results, fixing PR#14491,
      notably in border cases, including when digits >= 16, thanks to
      substantial contributions (code and experiments) from Petr
      Savicky.  This affects a noticable amount of numeric output from
      R.

---------

Feedback is welcome, but  flames > /dev/null
Martin Maechler


From dtenenba at fhcrc.org  Mon Mar  7 20:00:12 2011
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Mon, 7 Mar 2011 11:00:12 -0800
Subject: [Rd] Problem building R-2.13 r54683 on Windows
Message-ID: <AANLkTikNATpOkRr8R87Xg8OtrpmQPkYRTrWM8R9uGWjA@mail.gmail.com>

Hi, Unfortunately it looks like this problem has somehow been reintroduced.

I am now trying to build R-devel 54683 from source, again following
the manual. I get the same error as below:

gcc -std=gnu99 -I../../include -DHAVE_CONFIG_H  -O3 -Wall -pedantic
-c zutil.c -o zutil.
o
make[4]: *** No rule to make target `Rzlib.def', needed by `Rzlib.dll'.  Stop.
make[3]: *** [rlibs] Error 1
make[2]: *** [../../bin/i386/R.dll] Error 2
make[1]: *** [rbuild] Error 2
make: *** [all] Error 2

Hope someone can have a look.
Thanks
Dan


On Thu, Mar 3, 2011 at 10:50 AM, Dan Tenenbaum <dtenenba at fhcrc.org> wrote:
> I am building R-2.13 r54645 from source as described here:
> http://cran.r-project.org/doc/manuals/R-admin.html#Building-from-source
> The "make all recommended" command ends as follows on both 32 and 64-bit
> Windows (Windows Server 2003 R2 Enterprise Edition Service Pack 2 and
> Windows Server 2008 R2 Enterprise):
> gcc -std=gnu99 -I../../include -DHAVE_CONFIG_H ?-O3 -Wall -pedantic ? -c
> zutil.c -o z
> o
> make[4]: *** No rule to make target `Rzlib.def', needed by `Rzlib.dll'.
> ?Stop.
> make[3]: *** [rlibs] Error 1
> make[2]: *** [../../bin/i386/R.dll] Error 2
> make[1]: *** [rbuild] Error 2
> make: *** [all] Error 2
> Thanks
> Dan
>


From therneau at mayo.edu  Tue Mar  8 13:59:57 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Tue, 08 Mar 2011 06:59:57 -0600
Subject: [Rd] print(...,digits=2) behavior
Message-ID: <1299589197.1839.8.camel@punchbuggy>

>> This affects _many_ *.Rout.save checks in packages.

  I assume this is in the R-devel branch.

 I've got an addition to survival nearly ready to go (faster concordance
calculation).  At what point should I should I switch over to the newer
version, fix up my .out files etc, to best mesh with the automatic
checks on CRAN?  

   It's a nuisance for me to update, but only a nuisance.  I've been
through it twice before (Splus version 4-> 5 and Splus -> R switch).  I
might as well time it so as to make life as easy as possible for you
folks. Thanks for all the hard work.

Terry T


From therneau at mayo.edu  Tue Mar  8 14:39:56 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Tue, 08 Mar 2011 07:39:56 -0600
Subject: [Rd] function local to a fit
Message-ID: <1299591596.1839.21.camel@punchbuggy>

  I've added a time-transform ability to coxph: here is an example

fit <- coxph(Surv(time, status) ~ age + tt(age) + sex, data=lung,
	tt=function(x, t, ...) x*log(t) )

The only role for tt() in the formula is to be noticed as a specials by
terms().  I currently have tt defined as a function
	tt <- function(x) 
It has to be exported in the namespace, documented, etc.

Is there a way to make tt() local to coxph, but still be found by
model.frame, so that it does not have to be global?   It would seem to
be neater to do a marker transform like s() in gam, cluster() in coxph,
etc in this way, where the meaning is local to the enclosing function.

Terry Therneau


From Wayne.Zhang at barclayscapital.com  Tue Mar  8 15:24:34 2011
From: Wayne.Zhang at barclayscapital.com (Wayne.Zhang at barclayscapital.com)
Date: Tue, 8 Mar 2011 09:24:34 -0500
Subject: [Rd] How to disable R's crash prompt
Message-ID: <A02FE3A5690A624994A6A0BC0DEEA920072D48316B@NYKPCMMGMB05.INTRANET.BARCAPINT.COM>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110308/64271af0/attachment.pl>

From ripley at stats.ox.ac.uk  Tue Mar  8 15:50:38 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 8 Mar 2011 14:50:38 +0000 (GMT)
Subject: [Rd] How to disable R's crash prompt
In-Reply-To: <A02FE3A5690A624994A6A0BC0DEEA920072D48316B@NYKPCMMGMB05.INTRANET.BARCAPINT.COM>
References: <A02FE3A5690A624994A6A0BC0DEEA920072D48316B@NYKPCMMGMB05.INTRANET.BARCAPINT.COM>
Message-ID: <alpine.LFD.2.02.1103081444360.23577@gannet.stats.ox.ac.uk>

On Tue, 8 Mar 2011, Wayne.Zhang at barclayscapital.com wrote:

> Dear R devel,
>
> I have a C++ app that calls into embedded R to perform some analytic 
> calculations.  When my app encounters a segmentation fault, R always 
> prints the following crash prompt and asks me to enter an action:
>
>
> *** caught segfault ***
> address 0x8, cause 'memory not mapped'
>
> Possible actions:
> 1: abort (with core dump, if enabled)
> 2: normal R exit
> 3: exit R without saving workspace
> 4: exit R saving workspace
>
>
>
> The problem is my app will be run in non-interactive mode, so there 
> is no way for me to enter the action.  Is there a way to disable the

R does not do that in 'non-interactive mode'. Take a look at the 
code: that section is conditional on R_Interactive.

> crash prompt and have R simply crash the whole app?  I have tried 
> using "-file=/dev/null", "-slave", "-vanilla", and pretty much all 
> other start options, to no avail.

They do not control if R is interactive: the front-end (yours, I 
presume since you mention embedding but do not otherwise give any 
details) does.

> Thanks in advance for your help,
>
> Wayne

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From edd at debian.org  Tue Mar  8 16:09:34 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 8 Mar 2011 09:09:34 -0600
Subject: [Rd] How to disable R's crash prompt
In-Reply-To: <A02FE3A5690A624994A6A0BC0DEEA920072D48316B@NYKPCMMGMB05.INTRANET.BARCAPINT.COM>
References: <A02FE3A5690A624994A6A0BC0DEEA920072D48316B@NYKPCMMGMB05.INTRANET.BARCAPINT.COM>
Message-ID: <19830.18094.367968.238222@max.nulle.part>


On 8 March 2011 at 09:24, Wayne.Zhang at barclayscapital.com wrote:
| Dear R devel,
| 
| I have a C++ app that calls into embedded R to perform some analytic calculations.  When my app encounters a segmentation fault, R always prints the following crash prompt and asks me to enter an action:
| 
| 
| *** caught segfault ***
| address 0x8, cause 'memory not mapped'
| 
| Possible actions:
| 1: abort (with core dump, if enabled)
| 2: normal R exit
| 3: exit R without saving workspace
| 4: exit R saving workspace
| 
| 
| 
| The problem is my app will be run in non-interactive mode, so there is no way for me to enter the action.  Is there a way to disable the crash prompt and have R simply crash the whole app?  I have tried using "-file=/dev/null", "-slave", "-vanilla", and pretty much all other start options, to no avail.

Are you using RInside?  You could try rebuilding it with the this (from
src/RInside.cpp) set to true

bool verbose = false;

as well as with possibly more debugging output added to the RInside
destructor (where I removed a few commented-out lines for brevity):

RInside::~RInside() {		// now empty as MemBuf is internal
    logTxt("RInside::dtor BEGIN", verbose);
    R_dot_Last();
    R_RunExitFinalizers();
    R_CleanTempDir();
    Rf_endEmbeddedR(0);
    logTxt("RInside::dtor END", verbose);
    instance_ = 0 ;
}

to at least confirm that you get here.  And if you really,really wanted to I
suppose you could try to do without some of these cleanup and finalizer
functions. But I think that would send you into somewhat uncharted territory,
so you probably want to do read Section 8.1 ("8.1 Embedding R under
Unix-alikes") of Writing R Extension carefully.  Best bet may still be to
avoid the segfault alltogether if you can.

Hope this helps, Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From b.rowlingson at lancaster.ac.uk  Tue Mar  8 17:37:31 2011
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 8 Mar 2011 16:37:31 +0000
Subject: [Rd] How to disable R's crash prompt
In-Reply-To: <A02FE3A5690A624994A6A0BC0DEEA920072D48316B@NYKPCMMGMB05.INTRANET.BARCAPINT.COM>
References: <A02FE3A5690A624994A6A0BC0DEEA920072D48316B@NYKPCMMGMB05.INTRANET.BARCAPINT.COM>
Message-ID: <AANLkTin8ShWDgbowSq8AYVcjz0PsnoJPSF5dgpbPwtTi@mail.gmail.com>

On Tue, Mar 8, 2011 at 2:24 PM,  <Wayne.Zhang at barclayscapital.com> wrote:
> Dear R devel,
>
> I have a C++ app that calls into embedded R to perform some analytic calculations. ?When my app encounters a segmentation fault, R always prints the following crash prompt and asks me to enter an action:
>
>
> *** caught segfault ***
> address 0x8, cause 'memory not mapped'
>
> Possible actions:
> 1: abort (with core dump, if enabled)
> 2: normal R exit
> 3: exit R without saving workspace
> 4: exit R saving workspace
>
>
>
> The problem is my app will be run in non-interactive mode, so there is no way for me to enter the action. ?Is there a way to disable the crash prompt and have R simply crash the whole app? ?I have tried using "-file=/dev/null", "-slave", "-vanilla", and pretty much all other start options, to no avail.

 If someone from Barclays Capital is writing programs that are being
allowed to seg fault and they want to *ignore* the seg fault then I'm
taking all my money away from Barclays Capital and keeping it away.
Barclays Capital, the bank that likes to say "seg fault".

 Your code can't possibly seg fault - our governments are always
telling us banks are too big to fail.

 That's enough banker bashing.

Barry


From dtenenba at fhcrc.org  Tue Mar  8 19:58:34 2011
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Tue, 8 Mar 2011 10:58:34 -0800
Subject: [Rd] Problem building R-2.13 r54683 on Windows
In-Reply-To: <AANLkTikNATpOkRr8R87Xg8OtrpmQPkYRTrWM8R9uGWjA@mail.gmail.com>
References: <AANLkTikNATpOkRr8R87Xg8OtrpmQPkYRTrWM8R9uGWjA@mail.gmail.com>
Message-ID: <AANLkTimTsos93kZefDhN4O9BoznPMm2tPL1heJbzNH8H@mail.gmail.com>

On Mon, Mar 7, 2011 at 11:00 AM, Dan Tenenbaum <dtenenba at fhcrc.org> wrote:
> Hi, Unfortunately it looks like this problem has somehow been reintroduced.
>

Looks like this has now been fixed. Many thanks!
Dan


> I am now trying to build R-devel 54683 from source, again following
> the manual. I get the same error as below:
>
> gcc -std=gnu99 -I../../include -DHAVE_CONFIG_H ?-O3 -Wall -pedantic
> -c zutil.c -o zutil.
> o
> make[4]: *** No rule to make target `Rzlib.def', needed by `Rzlib.dll'. ?Stop.
> make[3]: *** [rlibs] Error 1
> make[2]: *** [../../bin/i386/R.dll] Error 2
> make[1]: *** [rbuild] Error 2
> make: *** [all] Error 2
>
> Hope someone can have a look.
> Thanks
> Dan
>
>
> On Thu, Mar 3, 2011 at 10:50 AM, Dan Tenenbaum <dtenenba at fhcrc.org> wrote:
>> I am building R-2.13 r54645 from source as described here:
>> http://cran.r-project.org/doc/manuals/R-admin.html#Building-from-source
>> The "make all recommended" command ends as follows on both 32 and 64-bit
>> Windows (Windows Server 2003 R2 Enterprise Edition Service Pack 2 and
>> Windows Server 2008 R2 Enterprise):
>> gcc -std=gnu99 -I../../include -DHAVE_CONFIG_H ?-O3 -Wall -pedantic ? -c
>> zutil.c -o z
>> o
>> make[4]: *** No rule to make target `Rzlib.def', needed by `Rzlib.dll'.
>> ?Stop.
>> make[3]: *** [rlibs] Error 1
>> make[2]: *** [../../bin/i386/R.dll] Error 2
>> make[1]: *** [rbuild] Error 2
>> make: *** [all] Error 2
>> Thanks
>> Dan
>>
>


From Wayne.Zhang at barclayscapital.com  Tue Mar  8 16:01:45 2011
From: Wayne.Zhang at barclayscapital.com (Wayne.Zhang at barclayscapital.com)
Date: Tue, 8 Mar 2011 10:01:45 -0500
Subject: [Rd] How to disable R's crash prompt
In-Reply-To: <alpine.LFD.2.02.1103081444360.23577@gannet.stats.ox.ac.uk>
References: <A02FE3A5690A624994A6A0BC0DEEA920072D48316B@NYKPCMMGMB05.INTRANET.BARCAPINT.COM>
	<alpine.LFD.2.02.1103081444360.23577@gannet.stats.ox.ac.uk>
Message-ID: <A02FE3A5690A624994A6A0BC0DEEA920072D48316C@NYKPCMMGMB05.INTRANET.BARCAPINT.COM>

Thanks for your quick comment Mr. Ripley.  I'm a newbie in R so excuse me for not knowing the obvious.  Could you elaborate on what code I should look at, and what documentation I should go to?

This is my C++ code on calling embedded R (on redhat enterprise linux 4):

    char *localArgs[] = { "R", "--silent" };  // tried --slave, -f, --vanilla too
    Rf_initEmbeddedR(sizeof(localArgs)/sizeof(localArgs[0]), localArgs);

    PROTECT(load = lang2(install("source"), mkString(file.c_str())));	// file contains R code
    R_tryEval(load, R_GlobalEnv, &errorOccurred);

    PROTECT(call = lang2(install(entryPoint.c_str()), input));    // entry point is an R function defined in "file" above
    PROTECT(output = R_tryEval(call, R_GlobalEnv, &errorOccurred));

    UNPROTECT(3);


What should I do in C++ to make R non-interactive?

Thanks,
Wayne


-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
Sent: Tuesday, March 08, 2011 9:51 AM
To: Zhang, Wayne: IT (NYK)
Cc: r-devel at r-project.org
Subject: Re: [Rd] How to disable R's crash prompt

On Tue, 8 Mar 2011, Wayne.Zhang at barclayscapital.com wrote:

> Dear R devel,
>
> I have a C++ app that calls into embedded R to perform some analytic 
> calculations.  When my app encounters a segmentation fault, R always 
> prints the following crash prompt and asks me to enter an action:
>
>
> *** caught segfault ***
> address 0x8, cause 'memory not mapped'
>
> Possible actions:
> 1: abort (with core dump, if enabled)
> 2: normal R exit
> 3: exit R without saving workspace
> 4: exit R saving workspace
>
>
>
> The problem is my app will be run in non-interactive mode, so there 
> is no way for me to enter the action.  Is there a way to disable the

R does not do that in 'non-interactive mode'. Take a look at the 
code: that section is conditional on R_Interactive.

> crash prompt and have R simply crash the whole app?  I have tried 
> using "-file=/dev/null", "-slave", "-vanilla", and pretty much all 
> other start options, to no avail.

They do not control if R is interactive: the front-end (yours, I 
presume since you mention embedding but do not otherwise give any 
details) does.

> Thanks in advance for your help,
>
> Wayne

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595
_______________________________________________

This e-mail may contain information that is confidential, privileged or otherwise protected from disclosure. If you are not an intended recipient of this e-mail, do not duplicate or redistribute it by any means. Please delete it and any attachments and notify the sender that you have received it in error. Unless specifically indicated, this e-mail is not an offer to buy or sell or a solicitation to buy or sell any securities, investment products or other financial product or service, an official confirmation of any transaction, or an official statement of Barclays. Any views or opinions presented are solely those of the author and do not necessarily represent those of Barclays. This e-mail is subject to terms available at the following link: www.barcap.com/emaildisclaimer. By messaging with Barclays you consent to the foregoing.  Barclays Capital is the investment banking division of Barclays Bank PLC, a company registered in England (number 1026167) with its registered office at 1 Churchill Place, London, E14 5HP.  This email may relate to or be sent from other members of the Barclays Group.


From Wayne.Zhang at barclayscapital.com  Tue Mar  8 16:21:32 2011
From: Wayne.Zhang at barclayscapital.com (Wayne.Zhang at barclayscapital.com)
Date: Tue, 8 Mar 2011 10:21:32 -0500
Subject: [Rd] How to disable R's crash prompt
In-Reply-To: <19830.18094.367968.238222@max.nulle.part>
References: <A02FE3A5690A624994A6A0BC0DEEA920072D48316B@NYKPCMMGMB05.INTRANET.BARCAPINT.COM>
	<19830.18094.367968.238222@max.nulle.part>
Message-ID: <A02FE3A5690A624994A6A0BC0DEEA920072D48316E@NYKPCMMGMB05.INTRANET.BARCAPINT.COM>

Hi Dirk,

My code on calling embedded R from C++ is attached in the other mail.

As you see, I'm not using RInside.  My app already works (except when it seg faults) so I prefer not to change it.  

Thanks,
Wayne


-----Original Message-----
From: Dirk Eddelbuettel [mailto:edd at debian.org] 
Sent: Tuesday, March 08, 2011 10:10 AM
To: Zhang, Wayne: IT (NYK)
Cc: r-devel at r-project.org
Subject: Re: [Rd] How to disable R's crash prompt


On 8 March 2011 at 09:24, Wayne.Zhang at barclayscapital.com wrote:
| Dear R devel,
| 
| I have a C++ app that calls into embedded R to perform some analytic calculations.  When my app encounters a segmentation fault, R always prints the following crash prompt and asks me to enter an action:
| 
| 
| *** caught segfault ***
| address 0x8, cause 'memory not mapped'
| 
| Possible actions:
| 1: abort (with core dump, if enabled)
| 2: normal R exit
| 3: exit R without saving workspace
| 4: exit R saving workspace
| 
| 
| 
| The problem is my app will be run in non-interactive mode, so there is no way for me to enter the action.  Is there a way to disable the crash prompt and have R simply crash the whole app?  I have tried using "-file=/dev/null", "-slave", "-vanilla", and pretty much all other start options, to no avail.

Are you using RInside?  You could try rebuilding it with the this (from
src/RInside.cpp) set to true

bool verbose = false;

as well as with possibly more debugging output added to the RInside
destructor (where I removed a few commented-out lines for brevity):

RInside::~RInside() {		// now empty as MemBuf is internal
    logTxt("RInside::dtor BEGIN", verbose);
    R_dot_Last();
    R_RunExitFinalizers();
    R_CleanTempDir();
    Rf_endEmbeddedR(0);
    logTxt("RInside::dtor END", verbose);
    instance_ = 0 ;
}

to at least confirm that you get here.  And if you really,really wanted to I
suppose you could try to do without some of these cleanup and finalizer
functions. But I think that would send you into somewhat uncharted territory,
so you probably want to do read Section 8.1 ("8.1 Embedding R under
Unix-alikes") of Writing R Extension carefully.  Best bet may still be to
avoid the segfault alltogether if you can.

Hope this helps, Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com
_______________________________________________

This e-mail may contain information that is confidential, privileged or otherwise protected from disclosure. If you are not an intended recipient of this e-mail, do not duplicate or redistribute it by any means. Please delete it and any attachments and notify the sender that you have received it in error. Unless specifically indicated, this e-mail is not an offer to buy or sell or a solicitation to buy or sell any securities, investment products or other financial product or service, an official confirmation of any transaction, or an official statement of Barclays. Any views or opinions presented are solely those of the author and do not necessarily represent those of Barclays. This e-mail is subject to terms available at the following link: www.barcap.com/emaildisclaimer. By messaging with Barclays you consent to the foregoing.  Barclays Capital is the investment banking division of Barclays Bank PLC, a company registered in England (number 1026167) with its registered office at 1 Churchill Place, London, E14 5HP.  This email may relate to or be sent from other members of the Barclays Group.


From bogadelenka at mail.ru  Tue Mar  8 18:06:37 2011
From: bogadelenka at mail.ru (Olga Starunova)
Date: Tue, 8 Mar 2011 20:06:37 +0300
Subject: [Rd] Fatal error: unable to open the base package (R, C++,
	Windows 7)
Message-ID: <363ABE2CAF834D81B23D5A1A9E61A839@HP>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110308/2dec6d12/attachment.pl>

From simon.urbanek at r-project.org  Tue Mar  8 23:28:12 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 8 Mar 2011 17:28:12 -0500
Subject: [Rd] How to disable R's crash prompt
In-Reply-To: <A02FE3A5690A624994A6A0BC0DEEA920072D48316C@NYKPCMMGMB05.INTRANET.BARCAPINT.COM>
References: <A02FE3A5690A624994A6A0BC0DEEA920072D48316B@NYKPCMMGMB05.INTRANET.BARCAPINT.COM>
	<alpine.LFD.2.02.1103081444360.23577@gannet.stats.ox.ac.uk>
	<A02FE3A5690A624994A6A0BC0DEEA920072D48316C@NYKPCMMGMB05.INTRANET.BARCAPINT.COM>
Message-ID: <61F65E40-0906-460F-9953-E848AD913D80@r-project.org>


On Mar 8, 2011, at 10:01 AM, <Wayne.Zhang at barclayscapital.com> <Wayne.Zhang at barclayscapital.com> wrote:

> Thanks for your quick comment Mr. Ripley.  I'm a newbie in R so excuse me for not knowing the obvious.  Could you elaborate on what code I should look at, and what documentation I should go to?
> 
> This is my C++ code on calling embedded R (on redhat enterprise linux 4):
> 
>    char *localArgs[] = { "R", "--silent" };  // tried --slave, -f, --vanilla too
>    Rf_initEmbeddedR(sizeof(localArgs)/sizeof(localArgs[0]), localArgs);
> 

R_Interactive = FALSE;


>    PROTECT(load = lang2(install("source"), mkString(file.c_str())));	// file contains R code
>    R_tryEval(load, R_GlobalEnv, &errorOccurred);
> 
>    PROTECT(call = lang2(install(entryPoint.c_str()), input));    // entry point is an R function defined in "file" above
>    PROTECT(output = R_tryEval(call, R_GlobalEnv, &errorOccurred));
> 
>    UNPROTECT(3);
> 
> 
> What should I do in C++ to make R non-interactive?
> 
> Thanks,
> Wayne
> 
> 
> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
> Sent: Tuesday, March 08, 2011 9:51 AM
> To: Zhang, Wayne: IT (NYK)
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] How to disable R's crash prompt
> 
> On Tue, 8 Mar 2011, Wayne.Zhang at barclayscapital.com wrote:
> 
>> Dear R devel,
>> 
>> I have a C++ app that calls into embedded R to perform some analytic 
>> calculations.  When my app encounters a segmentation fault, R always 
>> prints the following crash prompt and asks me to enter an action:
>> 
>> 
>> *** caught segfault ***
>> address 0x8, cause 'memory not mapped'
>> 
>> Possible actions:
>> 1: abort (with core dump, if enabled)
>> 2: normal R exit
>> 3: exit R without saving workspace
>> 4: exit R saving workspace
>> 
>> 
>> 
>> The problem is my app will be run in non-interactive mode, so there 
>> is no way for me to enter the action.  Is there a way to disable the
> 
> R does not do that in 'non-interactive mode'. Take a look at the 
> code: that section is conditional on R_Interactive.
> 
>> crash prompt and have R simply crash the whole app?  I have tried 
>> using "-file=/dev/null", "-slave", "-vanilla", and pretty much all 
>> other start options, to no avail.
> 
> They do not control if R is interactive: the front-end (yours, I 
> presume since you mention embedding but do not otherwise give any 
> details) does.
> 
>> Thanks in advance for your help,
>> 
>> Wayne
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> _______________________________________________
> 
> This e-mail may contain information that is confidential, privileged or otherwise protected from disclosure. If you are not an intended recipient of this e-mail, do not duplicate or redistribute it by any means. Please delete it and any attachments and notify the sender that you have received it in error. Unless specifically indicated, this e-mail is not an offer to buy or sell or a solicitation to buy or sell any securities, investment products or other financial product or service, an official confirmation of any transaction, or an official statement of Barclays. Any views or opinions presented are solely those of the author and do not necessarily represent those of Barclays. This e-mail is subject to terms available at the following link: www.barcap.com/emaildisclaimer. By messaging with Barclays you consent to the foregoing.  Barclays Capital is the investment banking division of Barclays Bank PLC, a company registered in England (number 1026167) with its registered offi!
> ce at 1 Churchill Place, London, E14 5HP.  This email may relate to or be sent from other members of the Barclays Group.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From Wayne.Zhang at barclayscapital.com  Tue Mar  8 23:41:54 2011
From: Wayne.Zhang at barclayscapital.com (Wayne.Zhang at barclayscapital.com)
Date: Tue, 8 Mar 2011 17:41:54 -0500
Subject: [Rd] How to disable R's crash prompt
In-Reply-To: <61F65E40-0906-460F-9953-E848AD913D80@r-project.org>
References: <A02FE3A5690A624994A6A0BC0DEEA920072D48316B@NYKPCMMGMB05.INTRANET.BARCAPINT.COM>
	<alpine.LFD.2.02.1103081444360.23577@gannet.stats.ox.ac.uk>
	<A02FE3A5690A624994A6A0BC0DEEA920072D48316C@NYKPCMMGMB05.INTRANET.BARCAPINT.COM>
	<61F65E40-0906-460F-9953-E848AD913D80@r-project.org>
Message-ID: <A02FE3A5690A624994A6A0BC0DEEA920072D483175@NYKPCMMGMB05.INTRANET.BARCAPINT.COM>

That did the trick.  Thank you soooooo much Simon!

Wayne


-----Original Message-----
From: Simon Urbanek [mailto:simon.urbanek at r-project.org] 
Sent: Tuesday, March 08, 2011 5:28 PM
To: Zhang, Wayne: IT (NYK)
Cc: ripley at stats.ox.ac.uk; r-devel at r-project.org
Subject: Re: [Rd] How to disable R's crash prompt


On Mar 8, 2011, at 10:01 AM, <Wayne.Zhang at barclayscapital.com> <Wayne.Zhang at barclayscapital.com> wrote:

> Thanks for your quick comment Mr. Ripley.  I'm a newbie in R so excuse me for not knowing the obvious.  Could you elaborate on what code I should look at, and what documentation I should go to?
> 
> This is my C++ code on calling embedded R (on redhat enterprise linux 4):
> 
>    char *localArgs[] = { "R", "--silent" };  // tried --slave, -f, --vanilla too
>    Rf_initEmbeddedR(sizeof(localArgs)/sizeof(localArgs[0]), localArgs);
> 

R_Interactive = FALSE;


>    PROTECT(load = lang2(install("source"), mkString(file.c_str())));	// file contains R code
>    R_tryEval(load, R_GlobalEnv, &errorOccurred);
> 
>    PROTECT(call = lang2(install(entryPoint.c_str()), input));    // entry point is an R function defined in "file" above
>    PROTECT(output = R_tryEval(call, R_GlobalEnv, &errorOccurred));
> 
>    UNPROTECT(3);
> 
> 
> What should I do in C++ to make R non-interactive?
> 
> Thanks,
> Wayne
> 
> 
> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
> Sent: Tuesday, March 08, 2011 9:51 AM
> To: Zhang, Wayne: IT (NYK)
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] How to disable R's crash prompt
> 
> On Tue, 8 Mar 2011, Wayne.Zhang at barclayscapital.com wrote:
> 
>> Dear R devel,
>> 
>> I have a C++ app that calls into embedded R to perform some analytic 
>> calculations.  When my app encounters a segmentation fault, R always 
>> prints the following crash prompt and asks me to enter an action:
>> 
>> 
>> *** caught segfault ***
>> address 0x8, cause 'memory not mapped'
>> 
>> Possible actions:
>> 1: abort (with core dump, if enabled)
>> 2: normal R exit
>> 3: exit R without saving workspace
>> 4: exit R saving workspace
>> 
>> 
>> 
>> The problem is my app will be run in non-interactive mode, so there 
>> is no way for me to enter the action.  Is there a way to disable the
> 
> R does not do that in 'non-interactive mode'. Take a look at the 
> code: that section is conditional on R_Interactive.
> 
>> crash prompt and have R simply crash the whole app?  I have tried 
>> using "-file=/dev/null", "-slave", "-vanilla", and pretty much all 
>> other start options, to no avail.
> 
> They do not control if R is interactive: the front-end (yours, I 
> presume since you mention embedding but do not otherwise give any 
> details) does.
> 
>> Thanks in advance for your help,
>> 
>> Wayne
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> _______________________________________________
> 
> This e-mail may contain information that is confidential, privileged or otherwise protected from disclosure. If you are not an intended recipient of this e-mail, do not duplicate or redistribute it by any means. Please delete it and any attachments and notify the sender that you have received it in error. Unless specifically indicated, this e-mail is not an offer to buy or sell or a solicitation to buy or sell any securities, investment products or other financial product or service, an official confirmation of any transaction, or an official statement of Barclays. Any views or opinions presented are solely those of the author and do not necessarily represent those of Barclays. This e-mail is subject to terms available at the following link: www.barcap.com/emaildisclaimer. By messaging with Barclays you consent to the foregoing.  Barclays Capital is the investment banking division of Barclays Bank PLC, a company registered in England (number 1026167) with its registered offi!
> ce at 1 Churchill Place, London, E14 5HP.  This email may relate to or be sent from other members of the Barclays Group.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From D.Strbenac at garvan.org.au  Wed Mar  9 07:00:20 2011
From: D.Strbenac at garvan.org.au (Dario Strbenac)
Date: Wed,  9 Mar 2011 17:00:20 +1100 (EST)
Subject: [Rd] VennDiagram Bugs
Message-ID: <20110309170020.BLF11744@gimr.garvan.unsw.edu.au>

Hello,

Even though the documentation says that it is possible to have a scaled Euler diagram for three categories, this fails to happen. All of the circles are the same size.

My commands are :

library(VennDiagram)
A <- 1:10
B <- 9:18
C <- 15:500
venn.diagram(list(NameOne=A, NameTwo=B, NameThree=C), "example.tiff", euler.d = TRUE, scaled = TRUE, fill = c("red", "blue", "green"), cat.pos = 0)

I also notice that adjusting just one text label with cat.just = list(c(-1, 0), c(0, 0), c(0, 0)) actually moves all of them around. Why is that ?

Also, I have some real data I'm working on, where X, Y, Z are vectors of numbers. It has an error with an unhelpful error message. Can it be fixed ?

> summary(X)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
      1    3706    8340    8488   13070   17560 
> summary(Y)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
    219    4740    9815    9394   13550   17560 
> summary(Z)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   2184    4076    6266    5749    7940    8280 
> venn.diagram(list(A = X, B = Y, C = Z),"crash.tiff")
Error in if (max.x - min.x >= max.y - min.y) { : 
  missing value where TRUE/FALSE needed

> traceback()
5: adjust.venn(grob.list, ...)
4: draw.sp.case(area.list = c(a1, a2, a3, 0, 0, 0, a7), enabled.areas = c(1, 
       2, 3, 7), area.x = c(a1.x.pos, a2.x.pos, a3.x.pos, 0, 0, 
       0, a7.x.pos), area.y = c(a1.y.pos, a2.y.pos, a3.y.pos, 0, 
       0, 0, a7.y.pos), attach.label.to = c(1, 3, 7), x.centres = c(x.centre.1, 
       x.centre.2, x.centre.3), y.centres = c(y.centre.1, y.centre.2, 
       y.centre.3), a.list = c(r1, r2, r3), b.list = c(r1, r2, r3), 
       straight.reverse = TRUE, reverse = reflection, category = category, 
       cat.default.pos = cat.default.pos, lwd = lwd, lty = lty, 
       col = col, label.col = label.col, cex = cex, fontface = fontface, 
       fontfamily = fontfamily, cat.pos = cat.pos, cat.dist = cat.dist, 
       cat.col = cat.col, cat.cex = cat.cex, cat.fontface = cat.fontface, 
       cat.fontfamily = cat.fontfamily, cat.just = cat.just, fill = fill, 
       alpha = alpha, ...)
3: draw.120(a1, a2, a3, a4, a5, a6, a7, category = category, reverse = reverse, 
       cat.default.pos = cat.default.pos, lwd = lwd, lty = lty, 
       col = col, label.col = label.col, cex = cex, fontface = fontface, 
       fontfamily = fontfamily, cat.pos = cat.pos, cat.dist = cat.dist, 
       cat.col = cat.col, cat.cex = cat.cex, cat.fontface = cat.fontface, 
       cat.fontfamily = cat.fontfamily, cat.just = cat.just, cat.prompts = cat.prompts, 
       fill = fill, alpha = alpha, ...)
2: draw.triple.venn(length(a), length(b), length(c), length(nab), 
       length(nbc), length(nac), length(nabc), list.names, ind = FALSE, 
       list.order = 1:3, ...)
1: venn.diagram(list(A = X, B = Y, C = Z), "crash.tiff")

My setup is :

> sessionInfo()
R version 2.12.2 (2011-02-25)
Platform: x86_64-pc-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252    LC_MONETARY=English_Australia.1252 LC_NUMERIC=C                       LC_TIME=English_Australia.1252    

attached base packages:
[1] grid      stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] VennDiagram_1.0.0

--------------------------------------
Dario Strbenac
Research Assistant
Cancer Epigenetics
Garvan Institute of Medical Research
Darlinghurst NSW 2010
Australia


From b.rowlingson at lancaster.ac.uk  Wed Mar  9 11:25:49 2011
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 9 Mar 2011 10:25:49 +0000
Subject: [Rd] How to disable R's crash prompt
In-Reply-To: <A02FE3A5690A624994A6A0BC0DEEA920072D483175@NYKPCMMGMB05.INTRANET.BARCAPINT.COM>
References: <A02FE3A5690A624994A6A0BC0DEEA920072D48316B@NYKPCMMGMB05.INTRANET.BARCAPINT.COM>
	<alpine.LFD.2.02.1103081444360.23577@gannet.stats.ox.ac.uk>
	<A02FE3A5690A624994A6A0BC0DEEA920072D48316C@NYKPCMMGMB05.INTRANET.BARCAPINT.COM>
	<61F65E40-0906-460F-9953-E848AD913D80@r-project.org>
	<A02FE3A5690A624994A6A0BC0DEEA920072D483175@NYKPCMMGMB05.INTRANET.BARCAPINT.COM>
Message-ID: <AANLkTinAZcJK-FCfTX5r6fuB1S+q3to=Nn7_fa0za+0R@mail.gmail.com>

On Tue, Mar 8, 2011 at 10:41 PM,  <Wayne.Zhang at barclayscapital.com> wrote:
> That did the trick. ?Thank you soooooo much Simon!

 But really you *should* fix the segfault. Either you know why it
happens, in which case you should spot it before it happens and do
something sensible, or you don't know why it happens, in which case it
could be a serious bug in your code.

 Even if you *do* know why it happens, there may be other bugs in your
code that cause segfaults that you *dont* know about, and you'll miss
them because you are stupidly ignoring all segfaults.

 Fix the bugs.

Barry


From Wayne.Zhang at barclayscapital.com  Wed Mar  9 14:20:27 2011
From: Wayne.Zhang at barclayscapital.com (Wayne.Zhang at barclayscapital.com)
Date: Wed, 9 Mar 2011 08:20:27 -0500
Subject: [Rd] How to disable R's crash prompt
In-Reply-To: <AANLkTinAZcJK-FCfTX5r6fuB1S+q3to=Nn7_fa0za+0R@mail.gmail.com>
References: <A02FE3A5690A624994A6A0BC0DEEA920072D48316B@NYKPCMMGMB05.INTRANET.BARCAPINT.COM>
	<alpine.LFD.2.02.1103081444360.23577@gannet.stats.ox.ac.uk>
	<A02FE3A5690A624994A6A0BC0DEEA920072D48316C@NYKPCMMGMB05.INTRANET.BARCAPINT.COM>
	<61F65E40-0906-460F-9953-E848AD913D80@r-project.org>
	<A02FE3A5690A624994A6A0BC0DEEA920072D483175@NYKPCMMGMB05.INTRANET.BARCAPINT.COM>
	<AANLkTinAZcJK-FCfTX5r6fuB1S+q3to=Nn7_fa0za+0R@mail.gmail.com>
Message-ID: <A02FE3A5690A624994A6A0BC0DEEA920072D483179@NYKPCMMGMB05.INTRANET.BARCAPINT.COM>

I never said I wasn't going to fix the bug, and believe me big banks do want their apps to be of high quality, but until the bugs are fixed I want my app to die instead of becoming a zombie.  But thanks for your opinion and all others that offered help along the way.

Wayne


-----Original Message-----
From: b.rowlingson at googlemail.com [mailto:b.rowlingson at googlemail.com] On Behalf Of Barry Rowlingson
Sent: Wednesday, March 09, 2011 5:26 AM
To: Zhang, Wayne: IT (NYK)
Cc: simon.urbanek at r-project.org; ripley at stats.ox.ac.uk; r-devel at r-project.org
Subject: Re: [Rd] How to disable R's crash prompt

On Tue, Mar 8, 2011 at 10:41 PM,  <Wayne.Zhang at barclayscapital.com> wrote:
> That did the trick. ?Thank you soooooo much Simon!

 But really you *should* fix the segfault. Either you know why it
happens, in which case you should spot it before it happens and do
something sensible, or you don't know why it happens, in which case it
could be a serious bug in your code.

 Even if you *do* know why it happens, there may be other bugs in your
code that cause segfaults that you *dont* know about, and you'll miss
them because you are stupidly ignoring all segfaults.

 Fix the bugs.

Barry
_______________________________________________

This e-mail may contain information that is confidential, privileged or otherwise protected from disclosure. If you are not an intended recipient of this e-mail, do not duplicate or redistribute it by any means. Please delete it and any attachments and notify the sender that you have received it in error. Unless specifically indicated, this e-mail is not an offer to buy or sell or a solicitation to buy or sell any securities, investment products or other financial product or service, an official confirmation of any transaction, or an official statement of Barclays. Any views or opinions presented are solely those of the author and do not necessarily represent those of Barclays. This e-mail is subject to terms available at the following link: www.barcap.com/emaildisclaimer. By messaging with Barclays you consent to the foregoing.  Barclays Capital is the investment banking division of Barclays Bank PLC, a company registered in England (number 1026167) with its registered office at 1 Churchill Place, London, E14 5HP.  This email may relate to or be sent from other members of the Barclays Group.


From therneau at mayo.edu  Wed Mar  9 15:48:10 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Wed, 09 Mar 2011 08:48:10 -0600
Subject: [Rd] Anomaly with unique and match
Message-ID: <1299682090.12625.9.camel@punchbuggy>

I stumbled onto this working on an update to coxph.  The last 6 lines
below are the question, the rest create a test data set.

tmt585% R
R version 2.12.2 (2011-02-25)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

# Lines of code from survival/tests/singtest.R
> library(survival)
Loading required package: splines
> test1 <- data.frame(time=  c(4, 3,1,1,2,2,3),
+     status=c(1,NA,1,0,1,1,0),
+     x=     c(0, 2,1,1,1,0,0))
> 
> temp <- rep(0:3, rep(7,4))
> 
> stest <- data.frame(start  = 10*temp,
+     stop   = 10*temp + test1$time,
+     status = rep(test1$status,4),
+     x      = c(test1$x+ 1:7, rep(test1$x,3)),
+     epoch  = rep(1:4, rep(7,4)))
> 
> fit1 <- coxph(Surv(start, stop, status) ~ x * factor(epoch), stest)

## New lines
> temp1 <- fit1$linear.predictor
> temp2 <- as.matrix(temp1)
> match(temp1, unique(temp1))
 [1] 1 2 3 4 4 5 6 7 7 7 6 6 6 8 8 8 6 6 6 9 9 9 6 6
> match(temp2, unique(temp2))
 [1]  1  2  3  4  4  5  6  7  7  7  6  6  6 NA NA NA  6  6  6  8  8  8
6  6

-----------------------

 I've solved it for my code by not calling match on a 1 column vector.  
 In general, however, should I be using some other paradym for this "map
to unique" operation?  For example match(as.character(x),
unique(as.character(x)) ?

Terry T


From savicky at cs.cas.cz  Wed Mar  9 17:00:40 2011
From: savicky at cs.cas.cz (Petr Savicky)
Date: Wed, 9 Mar 2011 17:00:40 +0100
Subject: [Rd] Anomaly with unique and match
In-Reply-To: <1299682090.12625.9.camel@punchbuggy>
References: <1299682090.12625.9.camel@punchbuggy>
Message-ID: <20110309160040.GA6512@cs.cas.cz>

On Wed, Mar 09, 2011 at 08:48:10AM -0600, Terry Therneau wrote:
> I stumbled onto this working on an update to coxph.  The last 6 lines
> below are the question, the rest create a test data set.
> 
> tmt585% R
> R version 2.12.2 (2011-02-25)
> Copyright (C) 2011 The R Foundation for Statistical Computing
> ISBN 3-900051-07-0
> Platform: x86_64-unknown-linux-gnu (64-bit)
> 
> # Lines of code from survival/tests/singtest.R
> > library(survival)
> Loading required package: splines
> > test1 <- data.frame(time=  c(4, 3,1,1,2,2,3),
> +     status=c(1,NA,1,0,1,1,0),
> +     x=     c(0, 2,1,1,1,0,0))
> > 
> > temp <- rep(0:3, rep(7,4))
> > 
> > stest <- data.frame(start  = 10*temp,
> +     stop   = 10*temp + test1$time,
> +     status = rep(test1$status,4),
> +     x      = c(test1$x+ 1:7, rep(test1$x,3)),
> +     epoch  = rep(1:4, rep(7,4)))
> > 
> > fit1 <- coxph(Surv(start, stop, status) ~ x * factor(epoch), stest)
> 
> ## New lines
> > temp1 <- fit1$linear.predictor
> > temp2 <- as.matrix(temp1)
> > match(temp1, unique(temp1))
>  [1] 1 2 3 4 4 5 6 7 7 7 6 6 6 8 8 8 6 6 6 9 9 9 6 6
> > match(temp2, unique(temp2))
>  [1]  1  2  3  4  4  5  6  7  7  7  6  6  6 NA NA NA  6  6  6  8  8  8
> 6  6
> 
> -----------------------
> 
>  I've solved it for my code by not calling match on a 1 column vector.  
>  In general, however, should I be using some other paradym for this "map
> to unique" operation?  For example match(as.character(x),
> unique(as.character(x)) ?

Let me suggest an alternative, which is consistent with unique() on
numeric vectors and uses a transformation of the column using rank().
For example,

  temp3 <- as.matrix(rank(temp1, ties.method="max"))
  match(temp3, unique(temp3))

  [1] 1 2 3 4 4 5 6 7 7 7 6 6 6 8 8 8 6 6 6 9 9 9 6 6

Can this be used in your code?

Petr Savicky.


From simon.urbanek at r-project.org  Wed Mar  9 20:11:49 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 9 Mar 2011 14:11:49 -0500
Subject: [Rd] unique.matrix issue [Was: Anomaly with unique and match]
In-Reply-To: <1299682090.12625.9.camel@punchbuggy>
References: <1299682090.12625.9.camel@punchbuggy>
Message-ID: <FBB0B12A-E932-4320-81B5-5106A9698957@r-project.org>

match() is a red herring here -- it is really a very specific thing that has to do with the fact that you're running unique() on a matrix. Also it's much easier to reproduce:

> x=c(1,1+0.2e-15)
> x
[1] 1 1
> sprintf("%a",x)
[1] "0x1p+0"               "0x1.0000000000001p+0"
> unique(x)
[1] 1 1
> sprintf("%a",unique(x))
[1] "0x1p+0"               "0x1.0000000000001p+0"
> unique(matrix(x,2))
     [,1]
[1,]    1
 
and this comes from the fact that unique.matrix uses string representation since it has to take into account all values of a row/column so it pastes all values into one string, but for the two numbers that is the same:
> as.character(x)
[1] "1" "1"

Cheers,
Simon


On Mar 9, 2011, at 9:48 AM, Terry Therneau wrote:

> I stumbled onto this working on an update to coxph.  The last 6 lines
> below are the question, the rest create a test data set.
> 
> tmt585% R
> R version 2.12.2 (2011-02-25)
> Copyright (C) 2011 The R Foundation for Statistical Computing
> ISBN 3-900051-07-0
> Platform: x86_64-unknown-linux-gnu (64-bit)
> 
> # Lines of code from survival/tests/singtest.R
>> library(survival)
> Loading required package: splines
>> test1 <- data.frame(time=  c(4, 3,1,1,2,2,3),
> +     status=c(1,NA,1,0,1,1,0),
> +     x=     c(0, 2,1,1,1,0,0))
>> 
>> temp <- rep(0:3, rep(7,4))
>> 
>> stest <- data.frame(start  = 10*temp,
> +     stop   = 10*temp + test1$time,
> +     status = rep(test1$status,4),
> +     x      = c(test1$x+ 1:7, rep(test1$x,3)),
> +     epoch  = rep(1:4, rep(7,4)))
>> 
>> fit1 <- coxph(Surv(start, stop, status) ~ x * factor(epoch), stest)
> 
> ## New lines
>> temp1 <- fit1$linear.predictor
>> temp2 <- as.matrix(temp1)
>> match(temp1, unique(temp1))
> [1] 1 2 3 4 4 5 6 7 7 7 6 6 6 8 8 8 6 6 6 9 9 9 6 6
>> match(temp2, unique(temp2))
> [1]  1  2  3  4  4  5  6  7  7  7  6  6  6 NA NA NA  6  6  6  8  8  8
> 6  6
> 
> -----------------------
> 
> I've solved it for my code by not calling match on a 1 column vector.  
> In general, however, should I be using some other paradym for this "map
> to unique" operation?  For example match(as.character(x),
> unique(as.character(x)) ?
> 
> Terry T
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From adik-rdevel at ilovebacon.org  Wed Mar  9 23:34:23 2011
From: adik-rdevel at ilovebacon.org (Adam D. I. Kramer)
Date: Wed, 9 Mar 2011 14:34:23 -0800 (PST)
Subject: [Rd] R and ATLAS and distributing across boxes
Message-ID: <alpine.DEB.2.00.1103091409290.1699@parser.ilovebacon.org>

Hi,

 	If I have a cluster of heterogenous machines, each with their own
self-optimized ATLAS, do I need to compile R on each machine to tell it to
take advantage of the local ATLAS? Or is it sufficient to compile R once
with the appropriate --with-blas and --with-lapack flags, and then trust
that, once installed on a certain box, R will look in the right place and
find and use the local library? Or will I need to recompile R on each box?

 	Googling around has shown me how to have R use ATLAS instead of
native BLAS, but none of them note whether changing the BLAS library out
from under an R binary will change the code that R executes.

Thanks in advance,
Adam D. I. Kramer


From zepu.zhang at gmail.com  Thu Mar 10 03:15:15 2011
From: zepu.zhang at gmail.com (Zepu Zhang)
Date: Wed, 9 Mar 2011 17:15:15 -0900
Subject: [Rd] avoid copying big object passed into optimize()
Message-ID: <AANLkTimLO0q9EQheDZCew7h+6371RYUXQyqako2xu=Wx@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110309/e4243ef8/attachment.pl>

From matt at biostatmatt.com  Thu Mar 10 04:16:07 2011
From: matt at biostatmatt.com (Matt Shotwell)
Date: Wed, 09 Mar 2011 22:16:07 -0500
Subject: [Rd] avoid copying big object passed into optimize()
In-Reply-To: <AANLkTimLO0q9EQheDZCew7h+6371RYUXQyqako2xu=Wx@mail.gmail.com>
References: <AANLkTimLO0q9EQheDZCew7h+6371RYUXQyqako2xu=Wx@mail.gmail.com>
Message-ID: <1299726967.1758.53.camel@matt-laptop>

On Wed, 2011-03-09 at 17:15 -0900, Zepu Zhang wrote:
> Hello list,
> 
> I have the following scenario:
> 
> f1 <- function(a)
> {
>      .... # doing things; may need 'a', but does not change 'a'.
> 
>      g <- function(x)
>      {
>           sum(x + a)    # Say. Use 'a'; does not change 'a'.

The expression 'x + a' causes 'a' to be duplicated; 'x' is added to each
element of the duplicated vector, then returned. The sum occurs
afterward. To avoid this use an expression like: 'length(a) * x +
sum(a)'. Also, please see this recent thread regarding the
pass-by-value / pass-by-reference issue:
http://tolstoy.newcastle.edu.au/R/e13/help/11/03/6632.html

>      }
> 
>      optimize(f = g, lower = 0, upper = 1)
> }
> 
> 
> f2 <- function()
> {
>     b <- runif(100000000000)   # Create big object.
> 
>     f1(a = b)
> }
> 
> 
> My main concern is to reduce copying of the big object 'a'. Questions:
> 
> (1) In f1, 'a' never appears on the LHS of assignment. Is it passed by value
> or by reference? Say the situation is simpler and more general: no
> optimization call in f1.

'a' is passed by value, but not necessarily copied in memory.

> (2) Is there any difference, as far as copying of the big 'a' is concerned,
> if 'g' is changed to
>    g <- function(x, b)  { sum(x + b) }
> and called by
>     optimize(f = g, lower = 0, upper = 1, b = a)

No.

> (3) Is 'a' passed into the C optimization function one-off, or again and
> again across the C-R interface?

I don't think either is completely correct. But more to your point, 'a'
is not necessarily copied repeatedly. If you make the substitution I
suggested above for 'g', then 'a' is not repeatedly copied.

> (4) Does it help if I remove the argument 'a' of 'f1', and let 'g' look for
> it (of course it should be referred to as 'b' now) directly in the
> environment of 'f2'?

No. 'g' would then search and find 'a' farther down the environment
tree.

> (5) Any suggestions?

Avoid operations that necessitate a copy. Compile R with
--enable-memory-profiling and use the tracemem function to help in this.

> Many thanks for your help!
> 
> Zepu
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hb at biostat.ucsf.edu  Thu Mar 10 08:44:40 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Wed, 9 Mar 2011 23:44:40 -0800
Subject: [Rd] Create an environment and assign objects to it in one go?
Message-ID: <AANLkTi=n9v0ebCbcsqtZCGQEtUa2nN_rUpoM+0uf0shS@mail.gmail.com>

Hi,

I've just created:

newEnvEval <- function(..., hash=FALSE, parent=parent.frame(), size=29L) {
  envir <- new.env(hash=hash, parent=parent, size=size);
  evalq(..., envir=envir);
  envir;
} # newEnvEval()

so that I can create an environment and assign objects to it in one go, e.g.

env <- newEnvEval({ a <- 1; b <- 2; });
print(env$a);

Does this already exists somewhere?

/Henrik

PS.


From pdalgd at gmail.com  Thu Mar 10 08:53:08 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 10 Mar 2011 08:53:08 +0100
Subject: [Rd] Create an environment and assign objects to it in one go?
In-Reply-To: <AANLkTi=n9v0ebCbcsqtZCGQEtUa2nN_rUpoM+0uf0shS@mail.gmail.com>
References: <AANLkTi=n9v0ebCbcsqtZCGQEtUa2nN_rUpoM+0uf0shS@mail.gmail.com>
Message-ID: <E7DA099E-BF66-484D-B4EC-FAC4E79A4362@gmail.com>


On Mar 10, 2011, at 08:44 , Henrik Bengtsson wrote:

> Hi,
> 
> I've just created:
> 
> newEnvEval <- function(..., hash=FALSE, parent=parent.frame(), size=29L) {
>  envir <- new.env(hash=hash, parent=parent, size=size);
>  evalq(..., envir=envir);
>  envir;
> } # newEnvEval()
> 
> so that I can create an environment and assign objects to it in one go, e.g.
> 
> env <- newEnvEval({ a <- 1; b <- 2; });
> print(env$a);
> 
> Does this already exists somewhere?
> 

I think 

env <- local({ a <- 1; b <- 2; environment()})
env$a 

-pd

> /Henrik
> 
> PS.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From savicky at cs.cas.cz  Thu Mar 10 09:29:10 2011
From: savicky at cs.cas.cz (Petr Savicky)
Date: Thu, 10 Mar 2011 09:29:10 +0100
Subject: [Rd] unique.matrix issue [Was: Anomaly with unique and match]
In-Reply-To: <FBB0B12A-E932-4320-81B5-5106A9698957@r-project.org>
References: <1299682090.12625.9.camel@punchbuggy>
	<FBB0B12A-E932-4320-81B5-5106A9698957@r-project.org>
Message-ID: <20110310082910.GA23460@cs.cas.cz>

On Wed, Mar 09, 2011 at 02:11:49PM -0500, Simon Urbanek wrote:
> match() is a red herring here -- it is really a very specific thing that has to do with the fact that you're running unique() on a matrix. Also it's much easier to reproduce:
> 
> > x=c(1,1+0.2e-15)
> > x
> [1] 1 1
> > sprintf("%a",x)
> [1] "0x1p+0"               "0x1.0000000000001p+0"
> > unique(x)
> [1] 1 1
> > sprintf("%a",unique(x))
> [1] "0x1p+0"               "0x1.0000000000001p+0"
> > unique(matrix(x,2))
>      [,1]
> [1,]    1
>  
> and this comes from the fact that unique.matrix uses string representation since it has to take into account all values of a row/column so it pastes all values into one string, but for the two numbers that is the same:
> > as.character(x)
> [1] "1" "1"

I understand the use of match() in the original message by Terry Therneau
as an example of a situation, where the behavior of unique.matrix() becomes
visible even without looking at the last bits of the numbers.

Let me suggest to consider the following example.

  x <- 1 + c(1.1, 1.3, 1.7, 1.9)*1e-14
  a <- cbind(rep(x, each=2), 2)
  rownames(a) <- 1:nrow(a)

The correct set of rows may be obtained using

  unique(a - 1)

            [,1] [,2]
  1 1.110223e-14    1
  3 1.310063e-14    1
  5 1.709743e-14    1
  7 1.909584e-14    1

However, due to the use of paste(), which uses as.character(), in
unique.matrix(), we also have

  unique(a)

    [,1] [,2]
  1    1    2
  5    1    2

Let me suggest to consider a transformation of the numeric columns
by rank() before the use of paste(). For example

  unique.mat <- function(a)
  {
      temp <- apply(a, 2, rank, ties.method="max")
      temp <- apply(temp, 1, function(x) paste(x, collapse = "\r"))
      a[!duplicated(temp), , drop=FALSE]
  }

  unique.mat(a)

    [,1] [,2]
  1    1    2
  3    1    2
  5    1    2
  7    1    2

Petr Savicky.


From hb at biostat.ucsf.edu  Thu Mar 10 10:19:48 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Thu, 10 Mar 2011 01:19:48 -0800
Subject: [Rd] unique.matrix issue [Was: Anomaly with unique and match]
In-Reply-To: <20110310082910.GA23460@cs.cas.cz>
References: <1299682090.12625.9.camel@punchbuggy>
	<FBB0B12A-E932-4320-81B5-5106A9698957@r-project.org>
	<20110310082910.GA23460@cs.cas.cz>
Message-ID: <AANLkTikdtWO-LovpLaAZ6qtU1kQanxUtVF_kJ+z8BXk_@mail.gmail.com>

It should be possible to run unique()/duplicated() column by column
and incrementally update the set of unique/duplicated rows.  This
would avoid any coercing.  The benefit should be even greater for
data.frame():s.

My $.02

/Henrik

On Thu, Mar 10, 2011 at 12:29 AM, Petr Savicky <savicky at cs.cas.cz> wrote:
> On Wed, Mar 09, 2011 at 02:11:49PM -0500, Simon Urbanek wrote:
>> match() is a red herring here -- it is really a very specific thing that has to do with the fact that you're running unique() on a matrix. Also it's much easier to reproduce:
>>
>> > x=c(1,1+0.2e-15)
>> > x
>> [1] 1 1
>> > sprintf("%a",x)
>> [1] "0x1p+0" ? ? ? ? ? ? ? "0x1.0000000000001p+0"
>> > unique(x)
>> [1] 1 1
>> > sprintf("%a",unique(x))
>> [1] "0x1p+0" ? ? ? ? ? ? ? "0x1.0000000000001p+0"
>> > unique(matrix(x,2))
>> ? ? ?[,1]
>> [1,] ? ?1
>>
>> and this comes from the fact that unique.matrix uses string representation since it has to take into account all values of a row/column so it pastes all values into one string, but for the two numbers that is the same:
>> > as.character(x)
>> [1] "1" "1"
>
> I understand the use of match() in the original message by Terry Therneau
> as an example of a situation, where the behavior of unique.matrix() becomes
> visible even without looking at the last bits of the numbers.
>
> Let me suggest to consider the following example.
>
> ?x <- 1 + c(1.1, 1.3, 1.7, 1.9)*1e-14
> ?a <- cbind(rep(x, each=2), 2)
> ?rownames(a) <- 1:nrow(a)
>
> The correct set of rows may be obtained using
>
> ?unique(a - 1)
>
> ? ? ? ? ? ?[,1] [,2]
> ?1 1.110223e-14 ? ?1
> ?3 1.310063e-14 ? ?1
> ?5 1.709743e-14 ? ?1
> ?7 1.909584e-14 ? ?1
>
> However, due to the use of paste(), which uses as.character(), in
> unique.matrix(), we also have
>
> ?unique(a)
>
> ? ?[,1] [,2]
> ?1 ? ?1 ? ?2
> ?5 ? ?1 ? ?2
>
> Let me suggest to consider a transformation of the numeric columns
> by rank() before the use of paste(). For example
>
> ?unique.mat <- function(a)
> ?{
> ? ? ?temp <- apply(a, 2, rank, ties.method="max")
> ? ? ?temp <- apply(temp, 1, function(x) paste(x, collapse = "\r"))
> ? ? ?a[!duplicated(temp), , drop=FALSE]
> ?}
>
> ?unique.mat(a)
>
> ? ?[,1] [,2]
> ?1 ? ?1 ? ?2
> ?3 ? ?1 ? ?2
> ?5 ? ?1 ? ?2
> ?7 ? ?1 ? ?2
>
> Petr Savicky.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From mr.wangsong at hotmail.com  Thu Mar 10 11:20:05 2011
From: mr.wangsong at hotmail.com (WANGSONG)
Date: Thu, 10 Mar 2011 10:20:05 +0000
Subject: [Rd] about textConnection
Message-ID: <BLU159-w408CB0E72A7114BFA5D24F4C80@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110310/3255ddec/attachment.pl>

From edd at debian.org  Thu Mar 10 14:46:10 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 10 Mar 2011 07:46:10 -0600
Subject: [Rd] R and ATLAS and distributing across boxes
In-Reply-To: <alpine.DEB.2.00.1103091409290.1699@parser.ilovebacon.org>
References: <alpine.DEB.2.00.1103091409290.1699@parser.ilovebacon.org>
Message-ID: <19832.54818.658604.833141@max.nulle.part>


On 9 March 2011 at 14:34, Adam D. I. Kramer wrote:
|  	If I have a cluster of heterogenous machines, each with their own
| self-optimized ATLAS, do I need to compile R on each machine to tell it to
| take advantage of the local ATLAS? Or is it sufficient to compile R once
| with the appropriate --with-blas and --with-lapack flags, and then trust
| that, once installed on a certain box, R will look in the right place and
| find and use the local library? 

Correct. Shared libraries, well-defined interfaces, hence plug-and-play.

| Or will I need to recompile R on each box?

No. If they all have libblas and liblapack somewhere were ld.so finds them
you should be fine/
 
|  	Googling around has shown me how to have R use ATLAS instead of
| native BLAS, but none of them note whether changing the BLAS library out
| from under an R binary will change the code that R executes.

Blas etc use is discussed in Appendix A.3 Linear algebra of the R
Installation and Administration manual.

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From ggrothendieck at gmail.com  Thu Mar 10 14:53:53 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 10 Mar 2011 08:53:53 -0500
Subject: [Rd] Create an environment and assign objects to it in one go?
In-Reply-To: <AANLkTi=n9v0ebCbcsqtZCGQEtUa2nN_rUpoM+0uf0shS@mail.gmail.com>
References: <AANLkTi=n9v0ebCbcsqtZCGQEtUa2nN_rUpoM+0uf0shS@mail.gmail.com>
Message-ID: <AANLkTi=F5kYczLggA=4SFT8Qo87UQuWTO67dpV6u5y7z@mail.gmail.com>

On 3/10/11, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> Hi,
>
> I've just created:
>
> newEnvEval <- function(..., hash=FALSE, parent=parent.frame(), size=29L) {
>   envir <- new.env(hash=hash, parent=parent, size=size);
>   evalq(..., envir=envir);
>   envir;
> } # newEnvEval()
>
> so that I can create an environment and assign objects to it in one go, e.g.
>
> env <- newEnvEval({ a <- 1; b <- 2; });
> print(env$a);
>
> Does this already exists somewhere?
>
> /Henrik
>

You can do this:

   e <- as.environment(list(a = 1, b = 2))
   e$a; e$b

or since proto objects are environments (but the $ has slightly
different semantics when applied to functions):

   library(proto)
   p <- proto(a = 1, b = 2, expr = { c <- 3 })
   p$a; p$b; p$c




-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From jeffrey.horner at gmail.com  Thu Mar 10 16:40:04 2011
From: jeffrey.horner at gmail.com (Jeffrey Horner)
Date: Thu, 10 Mar 2011 09:40:04 -0600
Subject: [Rd] Testing for a reference class object
Message-ID: <AANLkTin4x5a3mWFqQBvcBgBmS5EFpi61uVet-Zda_rsZ@mail.gmail.com>

Hi all,

I've constructed the following function to test whether or not an
object was created from a reference class:

isRefClassObject <- function(x) isS4(x) &&
is.environment(attr(x,'.xData')) &&
exists('.refClassDef',attr(x,'.xData'))

but I'm unsure if it's a complete test or if there's a better way to
test. Regardless, It would be nice to have such a function in the
methods package.

I have a case where I'd like to ensure that an object is constructed
from a reference class AND that it implements a certain method:

if (isRefClassObject(x) && 'run' %in% getRefClass(x)$methods())
    x$run()

Thanks,

Jeff
-- 
http://biostat.mc.vanderbilt.edu/JeffreyHorner


From Thierry.ONKELINX at inbo.be  Thu Mar 10 17:21:12 2011
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 10 Mar 2011 16:21:12 +0000
Subject: [Rd] Problem with defining new method for residuals()
Message-ID: <AA818EAD2576BC488B4F623941DA74270336BD@inbomail.inbo.be>

Dear all,

I'm writing a package and I would like to reuse the residuals() function. When I use a function which calls the redefined residuals (for my custom class) I get an error (see below). It looks like the wrong method is used. The strange this is, that when it execute the code manually it get no error.

Any suggestions?

Best regards,

Thierry

The entire source code is at svn://scm.r-forge.r-project.org/svnroot/aflp

The code with the error.

> normalise(dummy)
Error in object$na.action : $ operator not defined for this S4 class
> traceback()
5: naresid(object$na.action, object$residuals) at normalise.R#30
4: residuals.default(outliers(data)) at normalise.R#30
3: residuals(outliers(data)) at normalise.R#30
2: nrow(residuals(outliers(data))) at normalise.R#30
1: normalise(dummy)
#This works fine
> data <- dummy
> nrow(residuals(outliers(data)))
[1] 0

NAMESPACE
importFrom(stats, residuals, resid, hclust, princomp)
exportPattern(".")

METHODS
setMethod("residuals", signature(object = "AFLP.outlier"), 
	function(object, ...){
		object at Residual
	}
)

setMethod("resid", signature(object = "AFLP.outlier"), 
	function(object, ...){
		object at Residual
	}
)

----------------------------------------------------------------------------
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
 

From hb at biostat.ucsf.edu  Thu Mar 10 18:21:55 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Thu, 10 Mar 2011 09:21:55 -0800
Subject: [Rd] Create an environment and assign objects to it in one go?
In-Reply-To: <AANLkTi=F5kYczLggA=4SFT8Qo87UQuWTO67dpV6u5y7z@mail.gmail.com>
References: <AANLkTi=n9v0ebCbcsqtZCGQEtUa2nN_rUpoM+0uf0shS@mail.gmail.com>
	<AANLkTi=F5kYczLggA=4SFT8Qo87UQuWTO67dpV6u5y7z@mail.gmail.com>
Message-ID: <AANLkTincWaugmuSDYUajjieaOLWDRmAhrtg7vHmBoaqH@mail.gmail.com>

Hi,

thanks to both of you.  My use case was actually to in-the-end create
a *list* in a cut'n'paste-friendly way, e.g.

env <- function(..., hash=FALSE, parent=parent.frame(), size=29L) {
  envir <- new.env(hash=hash, parent=parent, size=size);
  evalq(..., envir=envir);
? envir;
} # env()


x <- list();

x$case1 <- env({
  # Cut'n'pasted from elsewhere
  a <- 1;
  b <- 2;
});

x$case2 <- env({
  # Cut'n'pasted from elsewhere
  a <- 3;
  b <- 1;
});

x <- lapply(x, FUN=as.list);

> str(x)
List of 2
 $ case1:List of 2
  ..$ b: num 2
  ..$ a: num 1
 $ case2:List of 2
  ..$ b: num 1
  ..$ a: num 3

/Henrik


On Thu, Mar 10, 2011 at 5:53 AM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> On 3/10/11, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
>> Hi,
>>
>> I've just created:
>>
>> newEnvEval <- function(..., hash=FALSE, parent=parent.frame(), size=29L) {
>> ? envir <- new.env(hash=hash, parent=parent, size=size);
>> ? evalq(..., envir=envir);
>> ? envir;
>> } # newEnvEval()
>>
>> so that I can create an environment and assign objects to it in one go, e.g.
>>
>> env <- newEnvEval({ a <- 1; b <- 2; });
>> print(env$a);
>>
>> Does this already exists somewhere?
>>
>> /Henrik
>>
>
> You can do this:
>
> ? e <- as.environment(list(a = 1, b = 2))
> ? e$a; e$b
>
> or since proto objects are environments (but the $ has slightly
> different semantics when applied to functions):
>
> ? library(proto)
> ? p <- proto(a = 1, b = 2, expr = { c <- 3 })
> ? p$a; p$b; p$c
>
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From jmc at r-project.org  Thu Mar 10 18:47:29 2011
From: jmc at r-project.org (John Chambers)
Date: Thu, 10 Mar 2011 09:47:29 -0800
Subject: [Rd] Testing for a reference class object
In-Reply-To: <AANLkTin4x5a3mWFqQBvcBgBmS5EFpi61uVet-Zda_rsZ@mail.gmail.com>
References: <AANLkTin4x5a3mWFqQBvcBgBmS5EFpi61uVet-Zda_rsZ@mail.gmail.com>
Message-ID: <4D790EB1.9020205@r-project.org>

There is a virtual class "refClass" that all reference classes subclass, 
so is(x, "refClass") is the natural test, as in:

 > foo <- setRefClass("foo", fields = "bar")
 > x <- foo$new()
 > is(x, "refClass")
[1] TRUE


On 3/10/11 7:40 AM, Jeffrey Horner wrote:
> Hi all,
>
> I've constructed the following function to test whether or not an
> object was created from a reference class:
>
> isRefClassObject<- function(x) isS4(x)&&
> is.environment(attr(x,'.xData'))&&
> exists('.refClassDef',attr(x,'.xData'))
>
> but I'm unsure if it's a complete test or if there's a better way to
> test. Regardless, It would be nice to have such a function in the
> methods package.
>
> I have a case where I'd like to ensure that an object is constructed
> from a reference class AND that it implements a certain method:
>
> if (isRefClassObject(x)&&  'run' %in% getRefClass(x)$methods())
>      x$run()
>
> Thanks,
>
> Jeff


From therneau at mayo.edu  Thu Mar 10 20:39:56 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Thu, 10 Mar 2011 13:39:56 -0600
Subject: [Rd] unique.matrix issue [Was: Anomaly with unique and match]
Message-ID: <1299785996.17703.10.camel@punchbuggy>

Simon pointed out that the issue I observed was due to internal
behaviour of unique.matrix.

  I had looked carefully at the manual pages before posting the question
and this was not mentioned.  Perhaps an addition could be made?

Terry T.


From mtmorgan at fhcrc.org  Fri Mar 11 07:36:16 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Thu, 10 Mar 2011 22:36:16 -0800
Subject: [Rd] Problem with defining new method for residuals()
In-Reply-To: <AA818EAD2576BC488B4F623941DA74270336BD@inbomail.inbo.be>
References: <AA818EAD2576BC488B4F623941DA74270336BD@inbomail.inbo.be>
Message-ID: <4D79C2E0.5020703@fhcrc.org>

On 03/10/2011 08:21 AM, ONKELINX, Thierry wrote:
> Dear all,
> 
> I'm writing a package and I would like to reuse the residuals()
> function. When I use a function which calls the redefined residuals
> (for my custom class) I get an error (see below). It looks like the
> wrong method is used. The strange this is, that when it execute the
> code manually it get no error.

Hi Thierry --

I think this is a bug in the methods package.

Your package promotes stats::residuals to an S4 generic. Normally this
should work.

However, your package Depends: on lme4, which also promotes
stats::residuals to an S4 generic. Apparently, this interferes with your
own attempt to make a generic, even though you do not import lme4 into
your name space. As a consequence of the (putative) bug, your package
sees the original stats::residuals.

A work-around seems to be to importFrom(lme4, residuals) and do NOT
import residuals from stats, so that your own method is associated with
the generic defined in lme4.

Martin

> 
> Any suggestions?
> 
> Best regards,
> 
> Thierry
> 
> The entire source code is at
> svn://scm.r-forge.r-project.org/svnroot/aflp
> 
> The code with the error.
> 
>> normalise(dummy)
> Error in object$na.action : $ operator not defined for this S4 class
>> traceback()
> 5: naresid(object$na.action, object$residuals) at normalise.R#30 4:
> residuals.default(outliers(data)) at normalise.R#30 3:
> residuals(outliers(data)) at normalise.R#30 2:
> nrow(residuals(outliers(data))) at normalise.R#30 1:
> normalise(dummy) #This works fine
>> data <- dummy nrow(residuals(outliers(data)))
> [1] 0
> 
> NAMESPACE importFrom(stats, residuals, resid, hclust, princomp) 
> exportPattern(".")
> 
> METHODS setMethod("residuals", signature(object = "AFLP.outlier"), 
> function(object, ...){ object at Residual } )
> 
> setMethod("resid", signature(object = "AFLP.outlier"), 
> function(object, ...){ object at Residual } )
> 
> ----------------------------------------------------------------------------
>
> 
ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek team Biometrie &
> Kwaliteitszorg Gaverstraat 4 9500 Geraardsbergen Belgium
> 
> Research Institute for Nature and Forest team Biometrics & Quality
> Assurance Gaverstraat 4 9500 Geraardsbergen Belgium
> 
> tel. + 32 54/436 185 Thierry.Onkelinx at inbo.be www.inbo.be
> 
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> 
> The plural of anecdote is not data. ~ Roger Brinner
> 
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given
> body of data. ~ John Tukey
> 
> ______________________________________________ R-devel at r-project.org
> mailing list https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From Thierry.ONKELINX at inbo.be  Fri Mar 11 10:14:35 2011
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 11 Mar 2011 09:14:35 +0000
Subject: [Rd] Problem with defining new method for residuals()
In-Reply-To: <4D79C2E0.5020703@fhcrc.org>
References: <AA818EAD2576BC488B4F623941DA74270336BD@inbomail.inbo.be>
	<4D79C2E0.5020703@fhcrc.org>
Message-ID: <AA818EAD2576BC488B4F623941DA7427033B29@inbomail.inbo.be>

Dear Martin,

Thank you very much for your solution. It works fine.

Best regards,

Thierry

----------------------------------------------------------------------------
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
  

> -----Oorspronkelijk bericht-----
> Van: Martin Morgan [mailto:mtmorgan at fhcrc.org] 
> Verzonden: vrijdag 11 maart 2011 7:36
> Aan: ONKELINX, Thierry
> CC: r-devel at r-project.org; John Chambers
> Onderwerp: Re: [Rd] Problem with defining new method for residuals()
> 
> On 03/10/2011 08:21 AM, ONKELINX, Thierry wrote:
> > Dear all,
> > 
> > I'm writing a package and I would like to reuse the residuals() 
> > function. When I use a function which calls the redefined residuals 
> > (for my custom class) I get an error (see below). It looks like the 
> > wrong method is used. The strange this is, that when it execute the 
> > code manually it get no error.
> 
> Hi Thierry --
> 
> I think this is a bug in the methods package.
> 
> Your package promotes stats::residuals to an S4 generic. 
> Normally this should work.
> 
> However, your package Depends: on lme4, which also promotes 
> stats::residuals to an S4 generic. Apparently, this 
> interferes with your own attempt to make a generic, even 
> though you do not import lme4 into your name space. As a 
> consequence of the (putative) bug, your package sees the 
> original stats::residuals.
> 
> A work-around seems to be to importFrom(lme4, residuals) and 
> do NOT import residuals from stats, so that your own method 
> is associated with the generic defined in lme4.
> 
> Martin
> 
> > 
> > Any suggestions?
> > 
> > Best regards,
> > 
> > Thierry
> > 
> > The entire source code is at
> > svn://scm.r-forge.r-project.org/svnroot/aflp
> > 
> > The code with the error.
> > 
> >> normalise(dummy)
> > Error in object$na.action : $ operator not defined for this S4 class
> >> traceback()
> > 5: naresid(object$na.action, object$residuals) at normalise.R#30 4:
> > residuals.default(outliers(data)) at normalise.R#30 3:
> > residuals(outliers(data)) at normalise.R#30 2:
> > nrow(residuals(outliers(data))) at normalise.R#30 1:
> > normalise(dummy) #This works fine
> >> data <- dummy nrow(residuals(outliers(data)))
> > [1] 0
> > 
> > NAMESPACE importFrom(stats, residuals, resid, hclust, princomp)
> > exportPattern(".")
> > 
> > METHODS setMethod("residuals", signature(object = "AFLP.outlier"), 
> > function(object, ...){ object at Residual } )
> > 
> > setMethod("resid", signature(object = "AFLP.outlier"), 
> > function(object, ...){ object at Residual } )
> > 
> > 
> ----------------------------------------------------------------------
> > ------
> >
> > 
> ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek team Biometrie & 
> Kwaliteitszorg 
> > Gaverstraat 4 9500 Geraardsbergen Belgium
> > 
> > Research Institute for Nature and Forest team Biometrics & Quality 
> > Assurance Gaverstraat 4 9500 Geraardsbergen Belgium
> > 
> > tel. + 32 54/436 185 Thierry.Onkelinx at inbo.be www.inbo.be
> > 
> > To call in the statistician after the experiment is done may be no 
> > more than asking him to perform a post-mortem examination: 
> he may be 
> > able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > 
> > The plural of anecdote is not data. ~ Roger Brinner
> > 
> > The combination of some data and an aching desire for an 
> answer does 
> > not ensure that a reasonable answer can be extracted from a 
> given body 
> > of data. ~ John Tukey
> > 
> > ______________________________________________ 
> R-devel at r-project.org 
> > mailing list https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> --
> Computational Biology
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109
> 
> Location: M1-B861
> Telephone: 206 667-2793
> 

From andreas.borg at unimedizin-mainz.de  Fri Mar 11 11:07:00 2011
From: andreas.borg at unimedizin-mainz.de (Andreas Borg)
Date: Fri, 11 Mar 2011 11:07:00 +0100
Subject: [Rd] Using missing() in a S4 method with extra arguments
Message-ID: <4D79F444.4070904@unimedizin-mainz.de>

Hi all,

I have a function which makes use of missing() to determine which 
arguments are provided in the call - basically, there are two sets of 
arguments that map to different strategies the function uses to fulfill 
its task. After conversion to an S4 generic I've run into the problem 
that if a method uses extra arguments that are not in the signature of 
the generic, usage of missing() fails. The following example exemplifies 
this:

    setGeneric("fun", function(x=0, y=0, ...) standardGeneric("fun"))
    # both methods should output if the second argument is missing
    setMethod("fun", "character", function(x=0, y=0, ...) missing(y))
    setMethod("fun", "numeric", function(x=0, y=0, z=0, ...) missing(y))

    fun("a") # this works fine
    fun(1) # this gives "FALSE

I've understood so far that this is due to the fact that the "numeric" 
method in this example is rewritten to:

    function (x = 0, y = 0, ...)
    {
        .local <- function (x = 0, y = 0, z = 0, ...)
        missing(y)
        .local(x, y, ...)
    }

The call to .local evaluates y and it is no more missing.

Is there any alternative that works in this case? Or is there a chance 
that missing() might be changed to work in this case in the near future?

Of course I know I could set NA or NULL as default values and check for 
these, but there are reasons I want to have legal default values for all
arguments.

Best regards,

Andreas

Andreas Borg
Medizinische Informatik

UNIVERSIT?TSMEDIZIN
der Johannes Gutenberg-Universit?t
Institut f?r Medizinische Biometrie, Epidemiologie und Informatik
Obere Zahlbacher Stra?e 69, 55131 Mainz
www.imbei.uni-mainz.de

Telefon +49 (0) 6131 175062
E-Mail: borg at imbei.uni-mainz.de

Diese E-Mail enth?lt vertrauliche und/oder rechtlich gesch?tzte Informationen. Wenn Sie nicht der
richtige Adressat sind oder diese E-Mail irrt?mlich erhalten haben, informieren Sie bitte sofort den
Absender und l?schen Sie diese Mail. Das unerlaubte Kopieren sowie die unbefugte Weitergabe
dieser Mail und der darin enthaltenen Informationen ist nicht gestattet.


From mtmorgan at fhcrc.org  Fri Mar 11 15:00:11 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Fri, 11 Mar 2011 06:00:11 -0800
Subject: [Rd] Using missing() in a S4 method with extra arguments
In-Reply-To: <4D79F444.4070904@unimedizin-mainz.de>
References: <4D79F444.4070904@unimedizin-mainz.de>
Message-ID: <4D7A2AEB.5030404@fhcrc.org>

On 03/11/2011 02:07 AM, Andreas Borg wrote:
> Hi all,
> 
> I have a function which makes use of missing() to determine which
> arguments are provided in the call - basically, there are two sets of
> arguments that map to different strategies the function uses to fulfill
> its task. After conversion to an S4 generic I've run into the problem
> that if a method uses extra arguments that are not in the signature of
> the generic, usage of missing() fails. The following example exemplifies
> this:
> 
>    setGeneric("fun", function(x=0, y=0, ...) standardGeneric("fun"))
>    # both methods should output if the second argument is missing
>    setMethod("fun", "character", function(x=0, y=0, ...) missing(y))
>    setMethod("fun", "numeric", function(x=0, y=0, z=0, ...) missing(y))
> 
>    fun("a") # this works fine
>    fun(1) # this gives "FALSE

Hi Andreas --

if you're testing for the missing-ness of y, and y is in the function
signature, then use that for dispatch

   setMethod(fun, c("character", "missing"),
             function(x=0, y=0, z=0, ...) "missing")
   setMethod(fun, c("character", "ANY"),
             function(x=0, y=0, z=0, ...) "not missing")

Since you're dispatching on x and y, it doesn't really make sense (to me
;) to assign default values to them. Testing for missing-ness of z would
I think have to rely on NA / NULL or other sentinel.

Martin
> 
> I've understood so far that this is due to the fact that the "numeric"
> method in this example is rewritten to:
> 
>    function (x = 0, y = 0, ...)
>    {
>        .local <- function (x = 0, y = 0, z = 0, ...)
>        missing(y)
>        .local(x, y, ...)
>    }
> 
> The call to .local evaluates y and it is no more missing.
> 
> Is there any alternative that works in this case? Or is there a chance
> that missing() might be changed to work in this case in the near future?
> 
> Of course I know I could set NA or NULL as default values and check for
> these, but there are reasons I want to have legal default values for all
> arguments.
> 
> Best regards,
> 
> Andreas
> 
> Andreas Borg
> Medizinische Informatik
> 
> UNIVERSIT?TSMEDIZIN
> der Johannes Gutenberg-Universit?t
> Institut f?r Medizinische Biometrie, Epidemiologie und Informatik
> Obere Zahlbacher Stra?e 69, 55131 Mainz
> www.imbei.uni-mainz.de
> 
> Telefon +49 (0) 6131 175062
> E-Mail: borg at imbei.uni-mainz.de
> 
> Diese E-Mail enth?lt vertrauliche und/oder rechtlich gesch?tzte
> Informationen. Wenn Sie nicht der
> richtige Adressat sind oder diese E-Mail irrt?mlich erhalten haben,
> informieren Sie bitte sofort den
> Absender und l?schen Sie diese Mail. Das unerlaubte Kopieren sowie die
> unbefugte Weitergabe
> dieser Mail und der darin enthaltenen Informationen ist nicht gestattet.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From andreas.borg at unimedizin-mainz.de  Fri Mar 11 16:22:27 2011
From: andreas.borg at unimedizin-mainz.de (Andreas Borg)
Date: Fri, 11 Mar 2011 16:22:27 +0100
Subject: [Rd] Using missing() in a S4 method with extra arguments
In-Reply-To: <19290_1299852208_4D7A2BB0_19290_9495_1_4D7A2AEB.5030404@fhcrc.org>
References: <4D79F444.4070904@unimedizin-mainz.de>
	<19290_1299852208_4D7A2BB0_19290_9495_1_4D7A2AEB.5030404@fhcrc.org>
Message-ID: <4D7A3E33.7080901@unimedizin-mainz.de>

Hi Martin,

in the real function, I am not dispatching on the argument for which I 
test missingness, but it might be a good idea to do so - this way I 
could make the function tidier by relocating different branches to 
seperate methods. Thanks for the suggestion!

Andreas


> if you're testing for the missing-ness of y, and y is in the function
> signature, then use that for dispatch
>
>    setMethod(fun, c("character", "missing"),
>              function(x=0, y=0, z=0, ...) "missing")
>    setMethod(fun, c("character", "ANY"),
>              function(x=0, y=0, z=0, ...) "not missing")
>
> Since you're dispatching on x and y, it doesn't really make sense (to me
> ;) to assign default values to them. Testing for missing-ness of z would
> I think have to rely on NA / NULL or other sentinel.
>
> Martin
>   

-- 
Andreas Borg
Medizinische Informatik

UNIVERSIT?TSMEDIZIN
der Johannes Gutenberg-Universit?t
Institut f?r Medizinische Biometrie, Epidemiologie und Informatik
Obere Zahlbacher Stra?e 69, 55131 Mainz
www.imbei.uni-mainz.de

Telefon +49 (0) 6131 175062
E-Mail: borg at imbei.uni-mainz.de

Diese E-Mail enth?lt vertrauliche und/oder rechtlich gesch?tzte Informationen. Wenn Sie nicht der
richtige Adressat sind oder diese E-Mail irrt?mlich erhalten haben, informieren Sie bitte sofort den
Absender und l?schen Sie diese Mail. Das unerlaubte Kopieren sowie die unbefugte Weitergabe
dieser Mail und der darin enthaltenen Informationen ist nicht gestattet.


From lawrence.michael at gene.com  Fri Mar 11 19:08:01 2011
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Fri, 11 Mar 2011 10:08:01 -0800
Subject: [Rd] hook for when R quits
Message-ID: <AANLkTi=6WYeM-xfqWAxbFNDT83BadEL=mifG26t5ZacN@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110311/e6f2331d/attachment.pl>

From jeffrey.ryan at lemnica.com  Fri Mar 11 19:19:33 2011
From: jeffrey.ryan at lemnica.com (Jeffrey Ryan)
Date: Fri, 11 Mar 2011 12:19:33 -0600
Subject: [Rd] hook for when R quits
In-Reply-To: <AANLkTi=6WYeM-xfqWAxbFNDT83BadEL=mifG26t5ZacN@mail.gmail.com>
References: <AANLkTi=6WYeM-xfqWAxbFNDT83BadEL=mifG26t5ZacN@mail.gmail.com>
Message-ID: <AANLkTinJPXGWswSpQ-9d8UEzYJW_zU4hAjViNNXWtbUh@mail.gmail.com>

Take a look at reg.finalizer.  You'd have to create an object
internally that would persist until R exits - and a related function
to handle cleanup of course.

HTH
Jeff

On Fri, Mar 11, 2011 at 12:08 PM, Michael Lawrence
<lawrence.michael at gene.com> wrote:
> Hi,
>
> Is there any way that a package can listen for when R quits? The Qt stuff is
> hooking into platform-specific event loops and when those die unexpectedly
> (from the perspective of Qt), it aborts, causing an annoying error dialog.
> If we could catch when R is killed, we could cleanup, like we do with
> .onUnload.
>
> Thanks,
> Michael
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Jeffrey Ryan
jeffrey.ryan at lemnica.com

www.lemnica.com


From lawrence.michael at gene.com  Fri Mar 11 19:37:38 2011
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Fri, 11 Mar 2011 10:37:38 -0800
Subject: [Rd] hook for when R quits
In-Reply-To: <AANLkTinJPXGWswSpQ-9d8UEzYJW_zU4hAjViNNXWtbUh@mail.gmail.com>
References: <AANLkTi=6WYeM-xfqWAxbFNDT83BadEL=mifG26t5ZacN@mail.gmail.com>
	<AANLkTinJPXGWswSpQ-9d8UEzYJW_zU4hAjViNNXWtbUh@mail.gmail.com>
Message-ID: <AANLkTinRW0h_U_27g95RnkcsAdWJ1-vKzW5YJ3JTJ_f-@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110311/97998fc6/attachment.pl>

From hb at biostat.ucsf.edu  Fri Mar 11 19:49:17 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Fri, 11 Mar 2011 10:49:17 -0800
Subject: [Rd] hook for when R quits
In-Reply-To: <AANLkTinRW0h_U_27g95RnkcsAdWJ1-vKzW5YJ3JTJ_f-@mail.gmail.com>
References: <AANLkTi=6WYeM-xfqWAxbFNDT83BadEL=mifG26t5ZacN@mail.gmail.com>
	<AANLkTinJPXGWswSpQ-9d8UEzYJW_zU4hAjViNNXWtbUh@mail.gmail.com>
	<AANLkTinRW0h_U_27g95RnkcsAdWJ1-vKzW5YJ3JTJ_f-@mail.gmail.com>
Message-ID: <AANLkTimuYYj9Ag7D_MpRLx3zoUtdT3CqC0MSDqw3VdLr@mail.gmail.com>

See onSessionExit() in the R.utils package, e.g.

onSessionExit(function(...) {
  cat("Bye bye world!\n");
})

quit();

Please pay attention to the Details section of help(onSessionExit);
there are ways that R can exit that will not be detected/handled.

/Henrik

On Fri, Mar 11, 2011 at 10:37 AM, Michael Lawrence
<lawrence.michael at gene.com> wrote:
> Thanks for the suggestion, but I don't think that R finalizes all of its
> objects when it quits. At least a simple test suggests that on Linux.
>
> Michael
>
> On Fri, Mar 11, 2011 at 10:19 AM, Jeffrey Ryan <jeffrey.ryan at lemnica.com>wrote:
>
>> Take a look at reg.finalizer. ?You'd have to create an object
>> internally that would persist until R exits - and a related function
>> to handle cleanup of course.
>>
>> HTH
>> Jeff
>>
>> On Fri, Mar 11, 2011 at 12:08 PM, Michael Lawrence
>> <lawrence.michael at gene.com> wrote:
>> > Hi,
>> >
>> > Is there any way that a package can listen for when R quits? The Qt stuff
>> is
>> > hooking into platform-specific event loops and when those die
>> unexpectedly
>> > (from the perspective of Qt), it aborts, causing an annoying error
>> dialog.
>> > If we could catch when R is killed, we could cleanup, like we do with
>> > .onUnload.
>> >
>> > Thanks,
>> > Michael
>> >
>> > ? ? ? ?[[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>> >
>>
>>
>>
>> --
>> Jeffrey Ryan
>> jeffrey.ryan at lemnica.com
>>
>> www.lemnica.com
>>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From murdoch.duncan at gmail.com  Fri Mar 11 19:53:00 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 11 Mar 2011 13:53:00 -0500
Subject: [Rd] hook for when R quits
In-Reply-To: <AANLkTinRW0h_U_27g95RnkcsAdWJ1-vKzW5YJ3JTJ_f-@mail.gmail.com>
References: <AANLkTi=6WYeM-xfqWAxbFNDT83BadEL=mifG26t5ZacN@mail.gmail.com>	<AANLkTinJPXGWswSpQ-9d8UEzYJW_zU4hAjViNNXWtbUh@mail.gmail.com>
	<AANLkTinRW0h_U_27g95RnkcsAdWJ1-vKzW5YJ3JTJ_f-@mail.gmail.com>
Message-ID: <4D7A6F8C.5010904@gmail.com>

On 11/03/2011 1:37 PM, Michael Lawrence wrote:
> Thanks for the suggestion, but I don't think that R finalizes all of its
> objects when it quits. At least a simple test suggests that on Linux.

Did you use onexit=TRUE?  On Windows that appears to work...

Duncan Murdoch

> Michael
>
> On Fri, Mar 11, 2011 at 10:19 AM, Jeffrey Ryan<jeffrey.ryan at lemnica.com>wrote:
>
> >  Take a look at reg.finalizer.  You'd have to create an object
> >  internally that would persist until R exits - and a related function
> >  to handle cleanup of course.
> >
> >  HTH
> >  Jeff
> >
> >  On Fri, Mar 11, 2011 at 12:08 PM, Michael Lawrence
> >  <lawrence.michael at gene.com>  wrote:
> >  >  Hi,
> >  >
> >  >  Is there any way that a package can listen for when R quits? The Qt stuff
> >  is
> >  >  hooking into platform-specific event loops and when those die
> >  unexpectedly
> >  >  (from the perspective of Qt), it aborts, causing an annoying error
> >  dialog.
> >  >  If we could catch when R is killed, we could cleanup, like we do with
> >  >  .onUnload.
> >  >
> >  >  Thanks,
> >  >  Michael
> >  >
> >  >         [[alternative HTML version deleted]]
> >  >
> >  >  ______________________________________________
> >  >  R-devel at r-project.org mailing list
> >  >  https://stat.ethz.ch/mailman/listinfo/r-devel
> >  >
> >
> >
> >
> >  --
> >  Jeffrey Ryan
> >  jeffrey.ryan at lemnica.com
> >
> >  www.lemnica.com
> >
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Fri Mar 11 20:07:12 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 11 Mar 2011 19:07:12 +0000 (GMT)
Subject: [Rd] hook for when R quits
In-Reply-To: <4D7A6F8C.5010904@gmail.com>
References: <AANLkTi=6WYeM-xfqWAxbFNDT83BadEL=mifG26t5ZacN@mail.gmail.com>
	<AANLkTinJPXGWswSpQ-9d8UEzYJW_zU4hAjViNNXWtbUh@mail.gmail.com>
	<AANLkTinRW0h_U_27g95RnkcsAdWJ1-vKzW5YJ3JTJ_f-@mail.gmail.com>
	<4D7A6F8C.5010904@gmail.com>
Message-ID: <alpine.LFD.2.02.1103111905540.22619@gannet.stats.ox.ac.uk>

On Fri, 11 Mar 2011, Duncan Murdoch wrote:

> On 11/03/2011 1:37 PM, Michael Lawrence wrote:
>> Thanks for the suggestion, but I don't think that R finalizes all of its
>> objects when it quits. At least a simple test suggests that on Linux.
>
> Did you use onexit=TRUE?  On Windows that appears to work...

It does work: RODBC makes extensive use of it, for exactly the purpose 
you describe (or rather, the C_level equivalent of 'it').

>
> Duncan Murdoch
>
>> Michael
>> 
>> On Fri, Mar 11, 2011 at 10:19 AM, Jeffrey 
>> Ryan<jeffrey.ryan at lemnica.com>wrote:
>> 
>> >  Take a look at reg.finalizer.  You'd have to create an object
>> >  internally that would persist until R exits - and a related function
>> >  to handle cleanup of course.
>> >
>> >  HTH
>> >  Jeff
>> >
>> >  On Fri, Mar 11, 2011 at 12:08 PM, Michael Lawrence
>> >  <lawrence.michael at gene.com>  wrote:
>> >  >  Hi,
>> >  >
>> >  >  Is there any way that a package can listen for when R quits? The Qt 
>> stuff
>> >  is
>> >  >  hooking into platform-specific event loops and when those die
>> >  unexpectedly
>> >  >  (from the perspective of Qt), it aborts, causing an annoying error
>> >  dialog.
>> >  >  If we could catch when R is killed, we could cleanup, like we do with
>> >  >  .onUnload.
>> >  >
>> >  >  Thanks,
>> >  >  Michael
>> >  >
>> >  >         [[alternative HTML version deleted]]
>> >  >
>> >  >  ______________________________________________
>> >  >  R-devel at r-project.org mailing list
>> >  >  https://stat.ethz.ch/mailman/listinfo/r-devel
>> >  >
>> >
>> >
>> >
>> >  --
>> >  Jeffrey Ryan
>> >  jeffrey.ryan at lemnica.com
>> >
>> >  www.lemnica.com
>> >
>>
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hb at biostat.ucsf.edu  Fri Mar 11 21:11:35 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Fri, 11 Mar 2011 12:11:35 -0800
Subject: [Rd] hook for when R quits
In-Reply-To: <alpine.LFD.2.02.1103111905540.22619@gannet.stats.ox.ac.uk>
References: <AANLkTi=6WYeM-xfqWAxbFNDT83BadEL=mifG26t5ZacN@mail.gmail.com>
	<AANLkTinJPXGWswSpQ-9d8UEzYJW_zU4hAjViNNXWtbUh@mail.gmail.com>
	<AANLkTinRW0h_U_27g95RnkcsAdWJ1-vKzW5YJ3JTJ_f-@mail.gmail.com>
	<4D7A6F8C.5010904@gmail.com>
	<alpine.LFD.2.02.1103111905540.22619@gannet.stats.ox.ac.uk>
Message-ID: <AANLkTim_wWk63CTXjfvc85fB52M1OzhhkY1DAxx=74sP@mail.gmail.com>

On Fri, Mar 11, 2011 at 11:07 AM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> On Fri, 11 Mar 2011, Duncan Murdoch wrote:
>
>> On 11/03/2011 1:37 PM, Michael Lawrence wrote:
>>>
>>> Thanks for the suggestion, but I don't think that R finalizes all of its
>>> objects when it quits. At least a simple test suggests that on Linux.
>>
>> Did you use onexit=TRUE? ?On Windows that appears to work...

Agree - here an object finalizer is more appropriate (different from
an end-of-session hook).

>
> It does work: RODBC makes extensive use of it, for exactly the purpose you
> describe (or rather, the C_level equivalent of 'it').

In help(reg.finalizer) it says:

  'onexit': logical: should the finalizer be run if the object is
still uncollected at the end of the R session?

What environments, objects, search path etc are available when the
finalizer is called this way when R exits?  Is safe to always add
'onexit=TRUE' (which now defaults to FALSE), or should I expect an
"exceptional" R system that the finalizer needs to account for?

Is there any further documentation on what happens when an R session
shuts down and in which order?

/Henrik

>
>>
>> Duncan Murdoch
>>
>>> Michael
>>>
>>> On Fri, Mar 11, 2011 at 10:19 AM, Jeffrey
>>> Ryan<jeffrey.ryan at lemnica.com>wrote:
>>>
>>> > ?Take a look at reg.finalizer. ?You'd have to create an object
>>> > ?internally that would persist until R exits - and a related function
>>> > ?to handle cleanup of course.
>>> >
>>> > ?HTH
>>> > ?Jeff
>>> >
>>> > ?On Fri, Mar 11, 2011 at 12:08 PM, Michael Lawrence
>>> > ?<lawrence.michael at gene.com> ?wrote:
>>> > ?> ?Hi,
>>> > ?>
>>> > ?> ?Is there any way that a package can listen for when R quits? The Qt
>>> > stuff
>>> > ?is
>>> > ?> ?hooking into platform-specific event loops and when those die
>>> > ?unexpectedly
>>> > ?> ?(from the perspective of Qt), it aborts, causing an annoying error
>>> > ?dialog.
>>> > ?> ?If we could catch when R is killed, we could cleanup, like we do
>>> > with
>>> > ?> ?.onUnload.
>>> > ?>
>>> > ?> ?Thanks,
>>> > ?> ?Michael
>>> > ?>
>>> > ?> ? ? ? ? [[alternative HTML version deleted]]
>>> > ?>
>>> > ?> ?______________________________________________
>>> > ?> ?R-devel at r-project.org mailing list
>>> > ?> ?https://stat.ethz.ch/mailman/listinfo/r-devel
>>> > ?>
>>> >
>>> >
>>> >
>>> > ?--
>>> > ?Jeffrey Ryan
>>> > ?jeffrey.ryan at lemnica.com
>>> >
>>> > ?www.lemnica.com
>>> >
>>>
>>> ? ? ? ?[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> --
> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From cstrato at aon.at  Fri Mar 11 21:58:15 2011
From: cstrato at aon.at (cstrato)
Date: Fri, 11 Mar 2011 21:58:15 +0100
Subject: [Rd] WARNING Undocumented S4 methods 'initialize' - why?
Message-ID: <4D7A8CE7.4000004@aon.at>

Dear all,

I am just writing the documentation file for S4 class 'QualTreeSet' and 
get the following warning with R CMD check:

* checking for missing documentation entries ... WARNING
Undocumented S4 methods:
   generic 'initialize' and siglist 'QualTreeSet'
All user-level objects in a package (including S4 classes and methods)
should have documentation entries.
See the chapter 'Writing R documentation files' in manual 'Writing R
Extensions'.

All my S4 classes have a method 'initialize' and R CMD check has never 
complained. Thus, do you have any idea why I get suddenly this warning 
for method 'initialize'?


Here is the code for 'QualTreeSet':

setClass("QualTreeSet",
    representation(qualtype = "character",
                   qualopt  = "character"
    ),
    contains=c("ProcesSet"),
    prototype(qualtype = "rlm",
              qualopt  = "raw"
    )
)#QualTreeSet

setMethod("initialize", "QualTreeSet",
    function(.Object,
             qualtype = "rlm",
             qualopt  = "raw",
             ...)
    {
       if (qualtype == "") qualtype <- "rlm";
       if (qualopt  == "") qualopt  <- "raw";

       .Object <- callNextMethod(.Object,
                                 qualtype = qualtype,
                                 qualopt  = qualopt,
                                 ...);
       .Object at qualtype = qualtype;
       .Object at qualopt  = qualopt;
       .Object;
    }
)#initialize


However, here is my code for a similar class 'ExprTreeSet' (which is the 
class from where I have copied the code):

setClass("ExprTreeSet",
    representation(exprtype = "character",
                   normtype = "character"
    ),
    contains=c("ProcesSet"),
    prototype(exprtype = "none",
              normtype = "none"
    )
)#ExprTreeSet

setMethod("initialize", "ExprTreeSet",
    function(.Object,
             exprtype = "none",
             normtype = "none",
             ...)
    {
       if (exprtype == "") exprtype <- "none";
       if (normtype == "") normtype <- "none";

       .Object <- callNextMethod(.Object,
                                 exprtype = exprtype,
                                 normtype = normtype,
                                 ...);
       .Object at exprtype = exprtype;
       .Object at normtype = normtype;
       .Object;
    }
)#initialize

In this case R CMD check does not complain, so why does it in the case 
of 'QualTreeSet'?

Here is my:
 > sessionInfo()
R version 2.12.1 (2010-12-16)
Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] xps_1.11.4

Thank you in advance
Best regards
Christian
_._._._._._._._._._._._._._._._._._
C.h.r.i.s.t.i.a.n   S.t.r.a.t.o.w.a
V.i.e.n.n.a           A.u.s.t.r.i.a
e.m.a.i.l:        cstrato at aon.at
_._._._._._._._._._._._._._._._._._


From murdoch.duncan at gmail.com  Fri Mar 11 22:05:37 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 11 Mar 2011 16:05:37 -0500
Subject: [Rd] hook for when R quits
In-Reply-To: <AANLkTim_wWk63CTXjfvc85fB52M1OzhhkY1DAxx=74sP@mail.gmail.com>
References: <AANLkTi=6WYeM-xfqWAxbFNDT83BadEL=mifG26t5ZacN@mail.gmail.com>	<AANLkTinJPXGWswSpQ-9d8UEzYJW_zU4hAjViNNXWtbUh@mail.gmail.com>	<AANLkTinRW0h_U_27g95RnkcsAdWJ1-vKzW5YJ3JTJ_f-@mail.gmail.com>	<4D7A6F8C.5010904@gmail.com>	<alpine.LFD.2.02.1103111905540.22619@gannet.stats.ox.ac.uk>
	<AANLkTim_wWk63CTXjfvc85fB52M1OzhhkY1DAxx=74sP@mail.gmail.com>
Message-ID: <4D7A8EA1.1060402@gmail.com>

On 11/03/2011 3:11 PM, Henrik Bengtsson wrote:
> On Fri, Mar 11, 2011 at 11:07 AM, Prof Brian Ripley
> <ripley at stats.ox.ac.uk>  wrote:
> >  On Fri, 11 Mar 2011, Duncan Murdoch wrote:
> >
> >>  On 11/03/2011 1:37 PM, Michael Lawrence wrote:
> >>>
> >>>  Thanks for the suggestion, but I don't think that R finalizes all of its
> >>>  objects when it quits. At least a simple test suggests that on Linux.
> >>
> >>  Did you use onexit=TRUE?  On Windows that appears to work...
>
> Agree - here an object finalizer is more appropriate (different from
> an end-of-session hook).
>
> >
> >  It does work: RODBC makes extensive use of it, for exactly the purpose you
> >  describe (or rather, the C_level equivalent of 'it').
>
> In help(reg.finalizer) it says:
>
>    'onexit': logical: should the finalizer be run if the object is
> still uncollected at the end of the R session?
>
> What environments, objects, search path etc are available when the
> finalizer is called this way when R exits?  Is safe to always add
> 'onexit=TRUE' (which now defaults to FALSE), or should I expect an
> "exceptional" R system that the finalizer needs to account for?

To be very conservative, I would assume that nothing in R is available 
other than things that are stored in that environment.  That's probably 
not true, but it would be safe.  This mechanism is for finalizing things 
that R doesn't know about.

If you want to be less conservative, then you could look at the source 
code:  currently R_RunExitFinalizers is the very first
part of the cleanup.  I don't know if we guarantee this though.

Duncan Murdoch

> Is there any further documentation on what happens when an R session
> shuts down and in which order?
>
> /Henrik
>
> >
> >>
> >>  Duncan Murdoch
> >>
> >>>  Michael
> >>>
> >>>  On Fri, Mar 11, 2011 at 10:19 AM, Jeffrey
> >>>  Ryan<jeffrey.ryan at lemnica.com>wrote:
> >>>
> >>>  >    Take a look at reg.finalizer.  You'd have to create an object
> >>>  >    internally that would persist until R exits - and a related function
> >>>  >    to handle cleanup of course.
> >>>  >
> >>>  >    HTH
> >>>  >    Jeff
> >>>  >
> >>>  >    On Fri, Mar 11, 2011 at 12:08 PM, Michael Lawrence
> >>>  >    <lawrence.michael at gene.com>    wrote:
> >>>  >    >    Hi,
> >>>  >    >
> >>>  >    >    Is there any way that a package can listen for when R quits? The Qt
> >>>  >  stuff
> >>>  >    is
> >>>  >    >    hooking into platform-specific event loops and when those die
> >>>  >    unexpectedly
> >>>  >    >    (from the perspective of Qt), it aborts, causing an annoying error
> >>>  >    dialog.
> >>>  >    >    If we could catch when R is killed, we could cleanup, like we do
> >>>  >  with
> >>>  >    >    .onUnload.
> >>>  >    >
> >>>  >    >    Thanks,
> >>>  >    >    Michael
> >>>  >    >
> >>>  >    >           [[alternative HTML version deleted]]
> >>>  >    >
> >>>  >    >    ______________________________________________
> >>>  >    >    R-devel at r-project.org mailing list
> >>>  >    >    https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>  >    >
> >>>  >
> >>>  >
> >>>  >
> >>>  >    --
> >>>  >    Jeffrey Ryan
> >>>  >    jeffrey.ryan at lemnica.com
> >>>  >
> >>>  >    www.lemnica.com
> >>>  >
> >>>
> >>>          [[alternative HTML version deleted]]
> >>>
> >>>  ______________________________________________
> >>>  R-devel at r-project.org mailing list
> >>>  https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >>  ______________________________________________
> >>  R-devel at r-project.org mailing list
> >>  https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >
> >  --
> >  Brian D. Ripley,                  ripley at stats.ox.ac.uk
> >  Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> >  University of Oxford,             Tel:  +44 1865 272861 (self)
> >  1 South Parks Road,                     +44 1865 272866 (PA)
> >  Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >
> >  ______________________________________________
> >  R-devel at r-project.org mailing list
> >  https://stat.ethz.ch/mailman/listinfo/r-devel
> >


From savicky at cs.cas.cz  Sat Mar 12 09:09:02 2011
From: savicky at cs.cas.cz (Petr Savicky)
Date: Sat, 12 Mar 2011 09:09:02 +0100
Subject: [Rd] unique.matrix issue [Was: Anomaly with unique and match]
In-Reply-To: <AANLkTikdtWO-LovpLaAZ6qtU1kQanxUtVF_kJ+z8BXk_@mail.gmail.com>
References: <1299682090.12625.9.camel@punchbuggy>
	<FBB0B12A-E932-4320-81B5-5106A9698957@r-project.org>
	<20110310082910.GA23460@cs.cas.cz>
	<AANLkTikdtWO-LovpLaAZ6qtU1kQanxUtVF_kJ+z8BXk_@mail.gmail.com>
Message-ID: <20110312080902.GA29111@cs.cas.cz>

On Thu, Mar 10, 2011 at 01:19:48AM -0800, Henrik Bengtsson wrote:
> It should be possible to run unique()/duplicated() column by column
> and incrementally update the set of unique/duplicated rows.  This
> would avoid any coercing.  The benefit should be even greater for
> data.frame():s.

This is a good point. An implementation of this using sorting can
be done as follows

  Sort the data frame using function order().
  Determine the groups of consecutive equal rows in the sorted df.
  Map the first row of each group to the original order of the rows.
  Since sorting by the function order() is stable, we obtain the first
  in each group of equal rows also in the original order.

The coercion approach uses hashing for string comparison, but the 
efficiency of hashing seems to be overweighted by the inefficiency
of the coercion. So, we get the following comparison.

  a <- matrix(sample(c(1234, 5678), 12*10000, replace=TRUE), ncol=12)
  df <- data.frame(a)
  
  do.unique.sort <- function(df)
  {
  	i <- do.call(order, df)
  	n <- nrow(df)
  	u <- c(TRUE, rowSums(df[i[2:n], ] == df[i[1:(n-1)], ]) < ncol(df))
  	df[u[order(i)], ]
  }

  system.time(out1 <- do.unique.sort(df))
  system.time(out2 <- unique(df))
  identical(out1, out2)

The result may be, for example

     user  system elapsed 
    0.279   0.000   0.273 
     user  system elapsed 
    0.514   0.000   0.468 
  [1] TRUE

On another computer

     user  system elapsed 
    0.058   0.000   0.058 
     user  system elapsed 
    0.187   0.000   0.188 
  [1] TRUE

On Thu, Mar 10, 2011 at 01:39:56PM -0600, Terry Therneau wrote:
> Simon pointed out that the issue I observed was due to internal
> behaviour of unique.matrix.
> 
>   I had looked carefully at the manual pages before posting the question
> and this was not mentioned.  Perhaps an addition could be made?

According to the description of unique(), the user may expect that if
b is obtained using

  b <- unique(a)

then for every "i" there is "j", such that

  all(a[i, ] == b[j, ])

This is usually true, but not always, because among several numbers
in "a" with the same as.character() only one remains in "b". If this
is intended, then i support the suggestion to include a note in the
documentation.

Let me add an argument against using as.character() to determine,
whether two numbers are close. The maximum relative difference between
the numbers, which have the same 15 digit decimal representation, varies
by a factor up to 10 in different ranges. Due to this, we have

  x <- 1 + c(1.1, 1.3, 1.7, 1.9)*1e-14

  unique(as.character(x))
  [1] "1.00000000000001" "1.00000000000002"

  unique(as.character(9*x))
  [1] "9.0000000000001"  "9.00000000000012" "9.00000000000015" "9.00000000000017"

The relative differences between components of 9*x are the same as the
relative differences in x, but if the mantissa begins with 9, then
a smaller relative difference is sufficient to change 15-th digit.

In terms of unique(), this implies

  nrow(unique(cbind(x)))
  [1] 2

  nrow(unique(cbind(9*x)))
  [1] 4
  
Petr Savicky.


From janko.thyson.rstuff at googlemail.com  Sat Mar 12 14:06:58 2011
From: janko.thyson.rstuff at googlemail.com (Janko Thyson)
Date: Sat, 12 Mar 2011 14:06:58 +0100
Subject: [Rd] Run script automatically when package is loaded
Message-ID: <4d7b6ff0.4b07cc0a.055d.ffffb90e@mx.google.com>

Dear list,

is it possible to specify a script that is executed "automatically" when my
package is mounted via 'require(my.pkg)' or 'library(my.pkg)'?

Id' like to specify execute a small init function that creates some crucial
environment structures. As it's always the first thing to do when using the
package, I wanted to "hide" it from the user so he won't have to think about
this step.

Can I use the lazy-loading functionality of packages for that (Writing R
Extensions, Section 1.1.5 Data in packages, pp. 10)?

Thanks for any suggestions,
Janko


From cstrato at aon.at  Sat Mar 12 14:38:50 2011
From: cstrato at aon.at (cstrato)
Date: Sat, 12 Mar 2011 14:38:50 +0100
Subject: [Rd] WARNING Undocumented S4 methods 'initialize' - why?
In-Reply-To: <4D7A8CE7.4000004@aon.at>
References: <4D7A8CE7.4000004@aon.at>
Message-ID: <4D7B776A.3030603@aon.at>

Dear all,

Meanwhile I found my mistake.
I forgot to add class QualTreeSet to 'initialize-methods.Rd'.
However, I am not sure if I should make 'initialize' public at all.

Best regards
Christian

On 3/11/11 9:58 PM, cstrato wrote:
> Dear all,
>
> I am just writing the documentation file for S4 class 'QualTreeSet' and
> get the following warning with R CMD check:
>
> * checking for missing documentation entries ... WARNING
> Undocumented S4 methods:
> generic 'initialize' and siglist 'QualTreeSet'
> All user-level objects in a package (including S4 classes and methods)
> should have documentation entries.
> See the chapter 'Writing R documentation files' in manual 'Writing R
> Extensions'.
>
> All my S4 classes have a method 'initialize' and R CMD check has never
> complained. Thus, do you have any idea why I get suddenly this warning
> for method 'initialize'?
>
>
> Here is the code for 'QualTreeSet':
>
> setClass("QualTreeSet",
> representation(qualtype = "character",
> qualopt = "character"
> ),
> contains=c("ProcesSet"),
> prototype(qualtype = "rlm",
> qualopt = "raw"
> )
> )#QualTreeSet
>
> setMethod("initialize", "QualTreeSet",
> function(.Object,
> qualtype = "rlm",
> qualopt = "raw",
> ...)
> {
> if (qualtype == "") qualtype <- "rlm";
> if (qualopt == "") qualopt <- "raw";
>
> .Object <- callNextMethod(.Object,
> qualtype = qualtype,
> qualopt = qualopt,
> ...);
> .Object at qualtype = qualtype;
> .Object at qualopt = qualopt;
> .Object;
> }
> )#initialize
>
>
> However, here is my code for a similar class 'ExprTreeSet' (which is the
> class from where I have copied the code):
>
> setClass("ExprTreeSet",
> representation(exprtype = "character",
> normtype = "character"
> ),
> contains=c("ProcesSet"),
> prototype(exprtype = "none",
> normtype = "none"
> )
> )#ExprTreeSet
>
> setMethod("initialize", "ExprTreeSet",
> function(.Object,
> exprtype = "none",
> normtype = "none",
> ...)
> {
> if (exprtype == "") exprtype <- "none";
> if (normtype == "") normtype <- "none";
>
> .Object <- callNextMethod(.Object,
> exprtype = exprtype,
> normtype = normtype,
> ...);
> .Object at exprtype = exprtype;
> .Object at normtype = normtype;
> .Object;
> }
> )#initialize
>
> In this case R CMD check does not complain, so why does it in the case
> of 'QualTreeSet'?
>
> Here is my:
>  > sessionInfo()
> R version 2.12.1 (2010-12-16)
> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>
> locale:
> [1] C
>
> attached base packages:
> [1] stats graphics grDevices utils datasets methods base
>
> other attached packages:
> [1] xps_1.11.4
>
> Thank you in advance
> Best regards
> Christian
> _._._._._._._._._._._._._._._._._._
> C.h.r.i.s.t.i.a.n S.t.r.a.t.o.w.a
> V.i.e.n.n.a A.u.s.t.r.i.a
> e.m.a.i.l: cstrato at aon.at
> _._._._._._._._._._._._._._._._._._
>
>


From edd at debian.org  Sat Mar 12 15:15:21 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 12 Mar 2011 08:15:21 -0600
Subject: [Rd] Run script automatically when package is loaded
In-Reply-To: <4d7b6ff0.4b07cc0a.055d.ffffb90e@mx.google.com>
References: <4d7b6ff0.4b07cc0a.055d.ffffb90e@mx.google.com>
Message-ID: <19835.32761.811533.878297@max.nulle.part>


On 12 March 2011 at 14:06, Janko Thyson wrote:
| Dear list,
| 
| is it possible to specify a script that is executed "automatically" when my
| package is mounted via 'require(my.pkg)' or 'library(my.pkg)'?

That has been possible all along. See help(".onLoad") if you use a NAMESPACE
(as you should) or help(".First.lib") if you don't.

Dirk
 
| Id' like to specify execute a small init function that creates some crucial
| environment structures. As it's always the first thing to do when using the
| package, I wanted to "hide" it from the user so he won't have to think about
| this step.
| 
| Can I use the lazy-loading functionality of packages for that (Writing R
| Extensions, Section 1.1.5 Data in packages, pp. 10)?
| 
| Thanks for any suggestions,
| Janko
| 
| ______________________________________________
| R-devel at r-project.org mailing list
| https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From spencer.graves at structuremonitoring.com  Sat Mar 12 16:22:59 2011
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Sat, 12 Mar 2011 07:22:59 -0800
Subject: [Rd] par(ask=TRUE) in R CMD check?
Message-ID: <4D7B8FD3.1070702@structuremonitoring.com>

Hello:


       What happens in the auto-checks on R-Forge and CRAN with code 
using par(ask=TRUE)?


       Is this routine, or can it create problems?


       The fda package uses ask=TRUE to provide the user with a way to 
examine a group of plots.  In the past, I've marked those tests in 
\examples with \dontrun.  However, I wonder if that is necessary.  I 
tried it on Windows using R 2.12.0 and R Tools from that version, and R 
Tools seemed to supply all the mouse clicks required.  However, before I 
"SVN Commit" to R-Forge, I felt a need to ask.


       Thanks,
       Spencer


From ripley at stats.ox.ac.uk  Sat Mar 12 17:55:55 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 12 Mar 2011 16:55:55 +0000 (GMT)
Subject: [Rd] par(ask=TRUE) in R CMD check?
In-Reply-To: <4D7B8FD3.1070702@structuremonitoring.com>
References: <4D7B8FD3.1070702@structuremonitoring.com>
Message-ID: <alpine.LFD.2.02.1103121649330.11764@gannet.stats.ox.ac.uk>

On Sat, 12 Mar 2011, Spencer Graves wrote:

> Hello:
>
>      What happens in the auto-checks on R-Forge and CRAN with code using 
> par(ask=TRUE)?
>
>      Is this routine, or can it create problems?
>
>      The fda package uses ask=TRUE to provide the user with a way to examine 
> a group of plots.  In the past, I've marked those tests in \examples with 
> \dontrun.  However, I wonder if that is necessary.  I tried it on Windows 
> using R 2.12.0 and R Tools from that version, and R Tools seemed to supply 
> all the mouse clicks required.  However, before I "SVN Commit" to R-Forge, I 
> felt a need to ask.

No mouse clicks are needed!  par(ask=TRUE) is ignored on a pdf device 
(which is the non-interactive default device).  In any case, the help says

      ?ask? logical.  If ?TRUE? (and the R session is interactive) the
...
           This not really a graphics parameter, and its use is
           deprecated in favour of ?devAskNewPage?.

See also the 'ask' argument in ?example.  What you say you want to do 
is the default behaviour of example(), and has been for some years.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From hb at biostat.ucsf.edu  Sun Mar 13 06:45:44 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sat, 12 Mar 2011 21:45:44 -0800
Subject: [Rd] Excited about the near future...
Message-ID: <AANLkTi=+e4NCjjhsJUxQtegbT_=GUZ-BEFo+hftdkj3w@mail.gmail.com>

Some already know, but I think it deserves a bit of a attention here as well:

It looks like we're about to get new features in R that will be very powerful!

That should be a good enough teaser for now...

/Henrik

PS ...and thanks for making it available plus credits to similar
efforts by others.


From lebatsnok at gmail.com  Mon Mar 14 12:32:29 2011
From: lebatsnok at gmail.com (Kenn Konstabel)
Date: Mon, 14 Mar 2011 13:32:29 +0200
Subject: [Rd] about textConnection
In-Reply-To: <BLU159-w408CB0E72A7114BFA5D24F4C80@phx.gbl>
References: <BLU159-w408CB0E72A7114BFA5D24F4C80@phx.gbl>
Message-ID: <AANLkTi=vsFizrAshwTzGYYUm2G=Kt-9ArH5CJDVAkhtw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110314/bc580b5a/attachment.pl>

From simon.urbanek at r-project.org  Mon Mar 14 14:36:46 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 14 Mar 2011 09:36:46 -0400
Subject: [Rd] about textConnection
In-Reply-To: <AANLkTi=vsFizrAshwTzGYYUm2G=Kt-9ArH5CJDVAkhtw@mail.gmail.com>
References: <BLU159-w408CB0E72A7114BFA5D24F4C80@phx.gbl>
	<AANLkTi=vsFizrAshwTzGYYUm2G=Kt-9ArH5CJDVAkhtw@mail.gmail.com>
Message-ID: <FB725016-19BB-4A3D-9916-7301DAEAF7D9@r-project.org>

Kenn,

you might have had a point a while ago, but you may want to check most recent R and re-evaluate:

?textConnection
[...]
  object: character.  A description of the connection.  For an input
          this is an R character vector object, and for an output
          connection the name for the R character vector to receive the
          output, or 'NULL' (for none).
[...]

Details:

     An input text connection is opened and the character vector is
     copied at time the connection object is created, and 'close'
     destroys the copy.  'object' should be the name of a character
     vector: however, short expressions will be accepted provided they
     deparse to less than 60 bytes.

Cheers,
Simon



On Mar 14, 2011, at 7:32 AM, Kenn Konstabel wrote:

> Hello,
> 
> `textConnection`  prepares arguments for an internal function, and one of
> these arguments is "description" that must be a character vector of length 1
> (or so it seems).
> 
> Now the one and only argument you usually give to `textConnection` is
> called "object"; from the code you can see how this becomes a "description":
> 
>    .Internal(textConnection(deparse(substitute(object)), object,
>        open, env, type))
> 
> deparse(substitute(object)) -- which is intended to get the name of the
> object you supplied. Try
> 
>> obj <- "a 1\nb 2\nc 3"
>> deparse(substitute(obj))
> [1] "obj"
>> deparse(substitute("a 1\nb 2\nc 3"))
> [1] "\"a 1\\nb 2\\nc 3\""
> 
> This is called "non-standard evaluation" - in almost every other case it
> makes no difference whether you do some_fun(obj) or some_fun("a 1\nb 2\nc
> 3") but in this case it does.
> 
> Now for some reason (I'm not exactly sure why this happens) the result
> deparse+substitute of your gsub thing is a character vector of length 2.
> 
> ugly.string <-  deparse
> (substitute(gsub("&","\n",(strsplit('{"abc",{"def","X,1&Y,2&Z,3"}}','\\"')[[1]][6]))))
> 
> length( ugly.string)
> 
> Anyway, if the textConnection object has a "description" component then it
> is probably useful for something but something like "gsub(\"&\", \"\\n\",
> (strsplit(\"{\\\"abc\\\",{\\\"def\\\",\\\"X,1&Y,2&Z,3\\\"}}\" doesn't seem
> too useful. If you really hate the intermediate step (assignment) then a
> solution might be to use the internal textConnection function directly, or
> modify the code of `textConnection` e.g. like this:
> 
> tc <- function (object, open = "r", local = FALSE, encoding = c("",
>    "bytes", "UTF-8")) {
>    env <- if (local) parent.frame() else .GlobalEnv
>    type <- match(match.arg(encoding), c("", "bytes", "UTF-8"))
>    description <- deparse(substitute(object))
>    is.ugly <- function(x) length(x)>1
>    if(is.ugly(description)) description <- "a nice description"
>    .Internal(textConnection(description, object, open, env, type))
> }
> 
> # this will work with your examples
> 
> Bu the answer to your bug report was not particularly helpful (a simple
> "RTFC"  would have helped more) and from an ordinary mortal's  perspective
> it is also wrong.
> 
>>  your usage is incorrect.
>>     object: character.  A description of the connection.  For an input
>> this is an R character vector object ...
>> and you used an expression.  Some expressions work, but only
>> simple ones (and none are guaranteed to).
> 
> But what you actually used is "character" and not an expression:
> 
> is.character(gsub("&","\n",(strsplit('{"abc",{"def","X,1&Y,2&Z,3"}}','\\"')[[1]][6])))
> # TRUE
> is.expression(gsub("&","\n",(strsplit('{"abc",{"def","X,1&Y,2&Z,3"}}','\\"')[[1]][6])))
> # FALSE :-P
> 
> (Provided that standard evaluation is used which one would ordinarily
> expect.) So in my opinion, the documentation is not complete here: it should
> say explicitly that the object would better be a simple name and that
> otherwise the result is not guaranteed.
> 
> 
> Best regards,
> Kenn
> 
> 
> On Thu, Mar 10, 2011 at 12:20 PM, WANGSONG <mr.wangsong at hotmail.com> wrote:
> 
>> 
>> I need read a table in a string with special format. I used read.csv and
>> textConnection function.
>> But i am confuse about textConnection by follow code.
>> 
>> case A: It is OK??
>> str0 <- '{"abc",{"def","X,1&Y,2&Z,3"}}'
>> str1 <- strsplit(str0,'"')[[1]][6]
>> str2 <- gsub("&","\n", str1)
>> con  <- textConnection( str2 )
>> read.csv(con,header=F)
>> close(con)
>> 
>> case B: It is NOK!
>> con  <- textConnection(
>> gsub("&","\n",(strsplit('{"abc",{"def","X,1&Y,2&Z,3"}}','"')[[1]][6])) )
>> # Error in here
>> read.csv(con,header=F)
>> close(con)
>> 
>> case C: It is OK!
>> str0 <- '{"abc",{"def","X,1&Y,2&Z,3"}}'
>> con  <- textConnection( gsub("&","\n", (strsplit(str0,'"')[[1]][6])) )
>> read.csv(con,header=F)
>> close(con)
>> 
>> case D: It is OK!
>> str2 <- gsub("&","\n",
>> strsplit('{"abc",{"def","X,1&Y,2&Z,3"}}','"')[[1]][6])
>> con  <- textConnection( str2 )
>> read.csv(con,header=F)
>> close(con)
>> 
>> Except case B, textConnection report "invalid 'description' argument", in
>> other case, textConnection is OK.
>> 
>> I don't known, what is different?? I report it as [Bug 14527], But the
>> Answer is :
>>>  your usage is incorrect.
>>>     object: character.  A description of the connection.  For an input
>> this is an R character vector object ...
>>> and you used an expression.  Some expressions work, but only simple ones
>> (and none are guaranteed to).
>> 
>> I read the help carefully, but i don't known which usage is incorrect.
>> 
>> Would you help me?
>> 
>> 
>> WangSong
>> 
>> 
>>       [[alternative HTML version deleted]]
>> 
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From sigbert at wiwi.hu-berlin.de  Mon Mar 14 15:30:58 2011
From: sigbert at wiwi.hu-berlin.de (Sigbert Klinke)
Date: Mon, 14 Mar 2011 15:30:58 +0100
Subject: [Rd] Tinycore & error in memCompress() in make check
Message-ID: <4D7E26A2.4010909@wiwi.hu-berlin.de>

Hi,

I get the same error as mentioned in
http://r.789695.n4.nabble.com/error-in-memCompress-in-make-check-td3318922.html


I try to compile R 2.12.2 under Tinycore 3.5.1 running in VirtualBox 4.0.4.

Since first xz was not installed I must have used the internal version
which comes with the R source tar ball. But after installing the xz
5.0.0 extension the error remained. Any idea what else I could do?

Thanks Sigbert


From ripley at stats.ox.ac.uk  Mon Mar 14 17:00:09 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 14 Mar 2011 16:00:09 +0000 (GMT)
Subject: [Rd] Tinycore & error in memCompress() in make check
In-Reply-To: <4D7E26A2.4010909@wiwi.hu-berlin.de>
References: <4D7E26A2.4010909@wiwi.hu-berlin.de>
Message-ID: <alpine.LFD.2.02.1103141554090.14135@gannet.stats.ox.ac.uk>

On Mon, 14 Mar 2011, Sigbert Klinke wrote:

> Hi,
>
> I get the same error as mentioned in
> http://r.789695.n4.nabble.com/error-in-memCompress-in-make-check-td3318922.html
>
>
> I try to compile R 2.12.2 under Tinycore 3.5.1 running in VirtualBox 4.0.4.
>
> Since first xz was not installed I must have used the internal version
> which comes with the R source tar ball. But after installing the xz
> 5.0.0 extension the error remained. Any idea what else I could do?

Report the problem to your OS vendor or VM vendor?  I'd be almost 
certain that the 'minimal example' does not involve R.  Most likely 
the problem is with how the VM reports memory usage/availability to 
xz.

(FWIW I have built and tested R under several OSes under VirtualBox, 
including Fedora 12 i686 and FreeBSD 8.2 amd64.)

>
> Thanks Sigbert
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From therneau at mayo.edu  Mon Mar 14 17:42:04 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Mon, 14 Mar 2011 11:42:04 -0500
Subject: [Rd] coxph and drop1
Message-ID: <201103141642.p2EGg45V022656@punchbuggy.mayo.edu>

A recent question in r-help made me realize that I should add a drop1 method 
for coxph and survreg.  The default does not handle strata() or cluster()
properly.  
  However, for coxph the right options for the "test" argument would be 
likelihood-ratio, score, and Wald; not chisq and F.  All of them reference
a chi-square distribution.  My thought is use these arguments, and add an
error message "read the help file for drop1.coxph" when the defaults appear.

  Any better suggestions?

Terry Therneau


From jfox at mcmaster.ca  Mon Mar 14 17:52:54 2011
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 14 Mar 2011 12:52:54 -0400
Subject: [Rd] coxph and drop1
In-Reply-To: <201103141642.p2EGg45V022656@punchbuggy.mayo.edu>
References: <201103141642.p2EGg45V022656@punchbuggy.mayo.edu>
Message-ID: <web-346112498@cgpsrv2.cis.mcmaster.ca>

Dear Terry,

Possibly I'm missing something, but since the generic drop1() doesn't have a test argument, why is there a problem?

> args(drop1)
function (object, scope, ...) 

If you use match.arg() against test, then the error message should be informative if one of the prescribed values isn't supplied.

Best,
 John

------------------------------------------------
John Fox
Sen. William McMaster Prof. of Social Statistics
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/

On Mon, 14 Mar 2011 11:42:04 -0500
 Terry Therneau <therneau at mayo.edu> wrote:
> A recent question in r-help made me realize that I should add a drop1 method 
> for coxph and survreg.  The default does not handle strata() or cluster()
> properly.  
>   However, for coxph the right options for the "test" argument would be 
> likelihood-ratio, score, and Wald; not chisq and F.  All of them reference
> a chi-square distribution.  My thought is use these arguments, and add an
> error message "read the help file for drop1.coxph" when the defaults appear.
> 
>   Any better suggestions?
> 
> Terry Therneau
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From vogranovich at jumptrading.com  Mon Mar 14 18:36:42 2011
From: vogranovich at jumptrading.com (Vadim Ogranovich)
Date: Mon, 14 Mar 2011 12:36:42 -0500
Subject: [Rd] discrepancy between lm and MASS:rlm
Message-ID: <25C02255A75A684A9CF77F7D663B438F02A10A5188@chiexchange02.w2k.jumptrading.com>

Dear R-devel,

There seems to be a discrepancy in the order in which lm and rlm evaluate their arguments. This causes rlm to sometimes produce an error where lm is just fine.

Here is a little script that illustrate the issue:

> library(MASS)
> ## create data
> n <- 100
> dat <- data.frame(x=rep(c(-1,0,1), n), y=rnorm(3*n))
>
> ## call lm, works fine
> summary(lm(y ~ as.factor(x), data=dat, subset=x!=0))

Call:
lm(formula = y ~ as.factor(x), data = dat, subset = x != 0)

Residuals:
     Min       1Q   Median       3Q      Max
-2.60619 -0.82160  0.06307  0.65501  2.56677

Coefficients:
              Estimate Std. Error t value Pr(>|t|)
(Intercept)   0.061010   0.100027   0.610    0.543
as.factor(x)1 0.001332   0.141459   0.009    0.992

Residual standard error: 1 on 198 degrees of freedom
Multiple R-squared: 4.479e-07,  Adjusted R-squared: -0.00505
F-statistic: 8.868e-05 on 1 and 198 DF,  p-value: 0.9925

> ## call rlm, error
> summary(rlm(y ~ as.factor(x), data=dat, subset=x!=0))
Error in rlm.default(x, y, weights, method = method, wt.method = wt.method,  :
  'x' is singular: singular fits are not implemented in rlm
>


My guess is that rlm first converts x to a factor, which becomes a three-level factor, then subsets on x!=0, which effectively eliminates a level, and then creates a "regression" matrix, which becomes singular due to the absence of data for a level.

Is there a simple way to work around it. The simplest I could think of is
with(subset(dat, x!=0), rlm(y ~ as.factor(x))
which is ok, but most of my scripts make use of data arg to regressions and I'd like to stay consistent as much as practical.

Thanks,
Vadim


Note: This email is for the confidential use of the named addressee(s) only and may contain proprietary, confidential or privileged information. If you are not the intended recipient, you are hereby notified that any review, dissemination or copying of this email is strictly prohibited, and to please notify the sender immediately and destroy this email and any attachments.  Email transmission cannot be guaranteed to be secure or error-free.  Jump Trading, therefore, does not make any guarantees as to the completeness or accuracy of this email or any attachments.  This email is for informational purposes only and does not constitute a recommendation, offer, request or solicitation of any kind to buy, sell, subscribe, redeem or perform any type of transaction of a financial product.


From therneau at mayo.edu  Mon Mar 14 18:56:16 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Mon, 14 Mar 2011 12:56:16 -0500
Subject: [Rd] coxph and drop1
In-Reply-To: <web-346112498@cgpsrv2.cis.mcmaster.ca>
References: <201103141642.p2EGg45V022656@punchbuggy.mayo.edu>
	<web-346112498@cgpsrv2.cis.mcmaster.ca>
Message-ID: <1300125376.22943.3.camel@punchbuggy>


On Mon, 2011-03-14 at 12:52 -0400, John Fox wrote:
> Dear Terry,
> 
> Possibly I'm missing something, but since the generic drop1() doesn't have a test argument, why is there a problem?
> 
> > args(drop1)
> function (object, scope, ...) 
> 
> If you use match.arg() against test, then the error message should be informative if one of the prescribed values isn't supplied.
> 
> Best,
>  John
> 
> ------------------------------------------------
> John Fox

I stand corrected.  I was looking at the help page and focused my eyes
on the "default" and "lm" versions, both of which have the test argument
with options none and chisq.  I should have looked higher on the page.

Terry T.


From wdunlap at tibco.com  Mon Mar 14 19:38:34 2011
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 14 Mar 2011 11:38:34 -0700
Subject: [Rd] discrepancy between lm and MASS:rlm
In-Reply-To: <25C02255A75A684A9CF77F7D663B438F02A10A5188@chiexchange02.w2k.jumptrading.com>
References: <25C02255A75A684A9CF77F7D663B438F02A10A5188@chiexchange02.w2k.jumptrading.com>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D70003FF9768@NA-PA-VBE03.na.tibco.com>


> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Vadim Ogranovich
> Sent: Monday, March 14, 2011 10:37 AM
> To: 'r-devel at r-project.org'
> Subject: [Rd] discrepancy between lm and MASS:rlm
> 
> Dear R-devel,
> 
> There seems to be a discrepancy in the order in which lm and 
> rlm evaluate their arguments. This causes rlm to sometimes 
> produce an error where lm is just fine.

It may not be a problem with the order of evaluation.  rlm()
might not be calling model.frame() with drop.unused.levels=TRUE.
I've made that mistake before with similar symptoms.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com 

> 
> Here is a little script that illustrate the issue:
> 
> > library(MASS)
> > ## create data
> > n <- 100
> > dat <- data.frame(x=rep(c(-1,0,1), n), y=rnorm(3*n))
> >
> > ## call lm, works fine
> > summary(lm(y ~ as.factor(x), data=dat, subset=x!=0))
> 
> Call:
> lm(formula = y ~ as.factor(x), data = dat, subset = x != 0)
> 
> Residuals:
>      Min       1Q   Median       3Q      Max
> -2.60619 -0.82160  0.06307  0.65501  2.56677
> 
> Coefficients:
>               Estimate Std. Error t value Pr(>|t|)
> (Intercept)   0.061010   0.100027   0.610    0.543
> as.factor(x)1 0.001332   0.141459   0.009    0.992
> 
> Residual standard error: 1 on 198 degrees of freedom
> Multiple R-squared: 4.479e-07,  Adjusted R-squared: -0.00505
> F-statistic: 8.868e-05 on 1 and 198 DF,  p-value: 0.9925
> 
> > ## call rlm, error
> > summary(rlm(y ~ as.factor(x), data=dat, subset=x!=0))
> Error in rlm.default(x, y, weights, method = method, 
> wt.method = wt.method,  :
>   'x' is singular: singular fits are not implemented in rlm
> >
> 
> 
> My guess is that rlm first converts x to a factor, which 
> becomes a three-level factor, then subsets on x!=0, which 
> effectively eliminates a level, and then creates a 
> "regression" matrix, which becomes singular due to the 
> absence of data for a level.
> 
> Is there a simple way to work around it. The simplest I could 
> think of is
> with(subset(dat, x!=0), rlm(y ~ as.factor(x))
> which is ok, but most of my scripts make use of data arg to 
> regressions and I'd like to stay consistent as much as practical.
> 
> Thanks,
> Vadim
> 
> 
> Note: This email is for the confidential use of the named 
> addressee(s) only and may contain proprietary, confidential 
> or privileged information. If you are not the intended 
> recipient, you are hereby notified that any review, 
> dissemination or copying of this email is strictly 
> prohibited, and to please notify the sender immediately and 
> destroy this email and any attachments.  Email transmission 
> cannot be guaranteed to be secure or error-free.  Jump 
> Trading, therefore, does not make any guarantees as to the 
> completeness or accuracy of this email or any attachments.  
> This email is for informational purposes only and does not 
> constitute a recommendation, offer, request or solicitation 
> of any kind to buy, sell, subscribe, redeem or perform any 
> type of transaction of a financial product.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From lebatsnok at gmail.com  Mon Mar 14 19:40:27 2011
From: lebatsnok at gmail.com (Kenn Konstabel)
Date: Mon, 14 Mar 2011 18:40:27 +0000
Subject: [Rd] about textConnection
In-Reply-To: <FB725016-19BB-4A3D-9916-7301DAEAF7D9@r-project.org>
References: <BLU159-w408CB0E72A7114BFA5D24F4C80@phx.gbl>
	<AANLkTi=vsFizrAshwTzGYYUm2G=Kt-9ArH5CJDVAkhtw@mail.gmail.com>
	<FB725016-19BB-4A3D-9916-7301DAEAF7D9@r-project.org>
Message-ID: <AANLkTi=8yJvD+1giF9KN80JENJAEpFYM8jBFbDcpEjrT@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110314/846f3369/attachment.pl>

From vogranovich at jumptrading.com  Mon Mar 14 20:31:22 2011
From: vogranovich at jumptrading.com (Vadim Ogranovich)
Date: Mon, 14 Mar 2011 14:31:22 -0500
Subject: [Rd] discrepancy between lm and MASS:rlm
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D70003FF9768@NA-PA-VBE03.na.tibco.com>
References: <25C02255A75A684A9CF77F7D663B438F02A10A5188@chiexchange02.w2k.jumptrading.com>
	<77EB52C6DD32BA4D87471DCD70C8D70003FF9768@NA-PA-VBE03.na.tibco.com>
Message-ID: <25C02255A75A684A9CF77F7D663B438F02A10A518B@chiexchange02.w2k.jumptrading.com>

Indeed! I added the drop.unused.levels argument and it now works. Thank you Bill!

Here is a patch which one should use at one's own risk as it redefines rlm.formula as global object, i.e. rlm.formula is no longer in the MASS namespace and this is certainly not a good idea:

rlm.formula <- function (formula, data, weights, ..., subset, na.action, method = c("M",
    "MM", "model.frame"), wt.method = c("inv.var", "case"), model = TRUE,
    x.ret = TRUE, y.ret = FALSE, contrasts = NULL)
{
    mf <- match.call(expand.dots = FALSE)
    mf$method <- mf$wt.method <- mf$model <- mf$x.ret <- mf$y.ret <- mf$contrasts <- mf$... <- NULL
    mf$drop.unused.levels <- TRUE
    mf[[1L]] <- as.name("model.frame")
    mf <- eval.parent(mf)
    method <- match.arg(method)
    wt.method <- match.arg(wt.method)
    if (method == "model.frame")
        return(mf)
    mt <- attr(mf, "terms")
    y <- model.response(mf)
    offset <- model.offset(mf)
    if (!is.null(offset))
        y <- y - offset
    x <- model.matrix(mt, mf, contrasts)
    xvars <- as.character(attr(mt, "variables"))[-1L]
    if ((yvar <- attr(mt, "response")) > 0L)
        xvars <- xvars[-yvar]
    xlev <- if (length(xvars) > 0L) {
        xlev <- lapply(mf[xvars], levels)
        xlev[!sapply(xlev, is.null)]
    }
    weights <- model.weights(mf)
    if (!length(weights))
        weights <- rep(1, nrow(x))
    fit <- MASS:::rlm.default(x, y, weights, method = method, wt.method = wt.method,
        ...)
    fit$terms <- mt
    cl <- match.call()
    cl[[1L]] <- as.name("rlm")
    fit$call <- cl
    fit$contrasts <- attr(x, "contrasts")
    fit$xlevels <- .getXlevels(mt, mf)
    fit$na.action <- attr(mf, "na.action")
    if (model)
        fit$model <- mf
    if (!x.ret)
        fit$x <- NULL
    if (y.ret)
        fit$y <- y
    fit
}

-----Original Message-----
From: William Dunlap [mailto:wdunlap at tibco.com]
Sent: Monday, March 14, 2011 1:39 PM
To: Vadim Ogranovich; r-devel at r-project.org
Subject: RE: [Rd] discrepancy between lm and MASS:rlm


> -----Original Message-----
> From: r-devel-bounces at r-project.org
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Vadim Ogranovich
> Sent: Monday, March 14, 2011 10:37 AM
> To: 'r-devel at r-project.org'
> Subject: [Rd] discrepancy between lm and MASS:rlm
>
> Dear R-devel,
>
> There seems to be a discrepancy in the order in which lm and
> rlm evaluate their arguments. This causes rlm to sometimes
> produce an error where lm is just fine.

It may not be a problem with the order of evaluation.  rlm()
might not be calling model.frame() with drop.unused.levels=TRUE.
I've made that mistake before with similar symptoms.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com

>
> Here is a little script that illustrate the issue:
>
> > library(MASS)
> > ## create data
> > n <- 100
> > dat <- data.frame(x=rep(c(-1,0,1), n), y=rnorm(3*n))
> >
> > ## call lm, works fine
> > summary(lm(y ~ as.factor(x), data=dat, subset=x!=0))
>
> Call:
> lm(formula = y ~ as.factor(x), data = dat, subset = x != 0)
>
> Residuals:
>      Min       1Q   Median       3Q      Max
> -2.60619 -0.82160  0.06307  0.65501  2.56677
>
> Coefficients:
>               Estimate Std. Error t value Pr(>|t|)
> (Intercept)   0.061010   0.100027   0.610    0.543
> as.factor(x)1 0.001332   0.141459   0.009    0.992
>
> Residual standard error: 1 on 198 degrees of freedom
> Multiple R-squared: 4.479e-07,  Adjusted R-squared: -0.00505
> F-statistic: 8.868e-05 on 1 and 198 DF,  p-value: 0.9925
>
> > ## call rlm, error
> > summary(rlm(y ~ as.factor(x), data=dat, subset=x!=0))
> Error in rlm.default(x, y, weights, method = method,
> wt.method = wt.method,  :
>   'x' is singular: singular fits are not implemented in rlm
> >
>
>
> My guess is that rlm first converts x to a factor, which
> becomes a three-level factor, then subsets on x!=0, which
> effectively eliminates a level, and then creates a
> "regression" matrix, which becomes singular due to the
> absence of data for a level.
>
> Is there a simple way to work around it. The simplest I could
> think of is
> with(subset(dat, x!=0), rlm(y ~ as.factor(x))
> which is ok, but most of my scripts make use of data arg to
> regressions and I'd like to stay consistent as much as practical.
>
> Thanks,
> Vadim
>
>
> Note: This email is for the confidential use of the named
> addressee(s) only and may contain proprietary, confidential
> or privileged information. If you are not the intended
> recipient, you are hereby notified that any review,
> dissemination or copying of this email is strictly
> prohibited, and to please notify the sender immediately and
> destroy this email and any attachments.  Email transmission
> cannot be guaranteed to be secure or error-free.  Jump
> Trading, therefore, does not make any guarantees as to the
> completeness or accuracy of this email or any attachments.
> This email is for informational purposes only and does not
> constitute a recommendation, offer, request or solicitation
> of any kind to buy, sell, subscribe, redeem or perform any
> type of transaction of a financial product.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Note: This email is for the confidential use of the named addressee(s) only and may contain proprietary, confidential or privileged information. If you are not the intended recipient, you are hereby notified that any review, dissemination or copying of this email is strictly prohibited, and to please notify the sender immediately and destroy this email and any attachments.  Email transmission cannot be guaranteed to be secure or error-free.  Jump Trading, therefore, does not make any guarantees as to the completeness or accuracy of this email or any attachments.  This email is for informational purposes only and does not constitute a recommendation, offer, request or solicitation of any kind to buy, sell, subscribe, redeem or perform any type of transaction of a financial product.


From presnell at stat.ufl.edu  Mon Mar 14 22:25:21 2011
From: presnell at stat.ufl.edu (Brett Presnell)
Date: Mon, 14 Mar 2011 17:25:21 -0400
Subject: [Rd] Standardized Pearson residuals
Message-ID: <87pqpts8ce.fsf@stat.ufl.edu>


Is there any reason that rstandard.glm doesn't have a "pearson" option?
And if not, can it be added?

Background: I'm currently teaching an undergrad/grad-service course from
Agresti's "Introduction to Categorical Data Analysis (2nd edn)" and
deviance residuals are not used in the text.  For now I'll just provide
the students with a simple function to use, but I prefer to use R's
native capabilities whenever possible.

I think something along the following lines should do it:

rstandard.glm <-
  function(model,
           infl=influence(model, do.coef=FALSE),
           type=c("deviance", "pearson"), ...)
{
  res <- switch(type, pearson = infl$pear.res, infl$dev.res)
  res <- res/sqrt(1-infl$hat)
  res[is.infinite(res)] <- NaN
  res
}


From jgarcia at ija.csic.es  Mon Mar 14 22:59:05 2011
From: jgarcia at ija.csic.es (jgarcia at ija.csic.es)
Date: Mon, 14 Mar 2011 22:59:05 +0100 (CET)
Subject: [Rd] fortran 90 underscore error
In-Reply-To: <AANLkTi=8yJvD+1giF9KN80JENJAEpFYM8jBFbDcpEjrT@mail.gmail.com>
References: <BLU159-w408CB0E72A7114BFA5D24F4C80@phx.gbl>
	<AANLkTi=vsFizrAshwTzGYYUm2G=Kt-9ArH5CJDVAkhtw@mail.gmail.com>
	<FB725016-19BB-4A3D-9916-7301DAEAF7D9@r-project.org>
	<AANLkTi=8yJvD+1giF9KN80JENJAEpFYM8jBFbDcpEjrT@mail.gmail.com>
Message-ID: <1991.89.243.32.35.1300139945.squirrel@paleo.ija.csic.es>

Hi there,

I am preparing a package based on Fortran 90 code. I've put the main code
is a MODULE, and I'm having several error messages with the linker:

>R CMD SHLIB --output=mylib.so nrtype.f90 topbalmod.f90 runmodels.f90

The several error messages are related with the addition of an underscore
to function names (no problem with subroutine names). E.g.:

topbalmod.o:topbalmod.f90:<.text+0x357f>: undefined reference to 'runga_'

After some googling, AFAIK, it seems the addition of underscores (I'm
using gfortran) may be avoided by the option -fno-underscoring, but its
use is not recomended as it is not of general use by all compilers.

I'm just wondering if R developers just recommend not to use user defined
fortran functions at all to avoid this problem, or alternatively if you
could provided with some example about how to circumvent it (perhaps to
convert all fortran 90 functions into subroutines?).

Thanks and best regards.

Javier
---


> Thanks, but I'm using R 2.12.2(2011-02-25) and ?textConnection says
> everything you quoted except the last sentence ("'object' should be the
> name
> of a character  vector: however, short expressions will be accepted
> provided
> they     deparse to less than 60 bytes."). Can it be that the help file is
> different on different platforms (i'm a simple windows user) or are you
> referring to a still more recent version of R?
>
> But I still have mixed feelings about the new sentence (although I now
> understand better how it works) ...  for example, the following works
> fine:
>
> spam <- function(x) sub("a", "A", x)
> foo <- "qwerty uiop asdf ghjkl zxcvb nm"
> con <-
> textConnection(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(foo))))))))))))))))))))))))))))))))))))))))))))))))))
> # very loong, does it deparse to less than 60 bytes?
>
> But not this:
>
>> con <-
> textConnection(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(spam(foo)))))))))))))))))))))))))))))))))))))))))))))))))))
> # Error: contextstack overflow at line 1
>
> And then ....
>
> "%spam%" <- function(x,y) sub("y", toupper(y), x)
> "%s%" <- function(x,y) sub(y, toupper(y), x)
> textConnection(foo %spam% "a" %spam% "b" %spam% "c" %spam% "d" %spam% "e")
> # ok
> textConnection(foo %spam% "a" %spam% "b" %spam% "c" %spam% "d" %spam% "e"
> %spam% "f")
> # invalid 'description' argument
> textConnection(foo %s% "a" %s% "b" %s% "c" %s% "d" %s% "e" %s% "f" %s%
> "g")
> # ok
> textConnection(foo %s% "a" %s% "b" %s% "c" %s% "d" %s% "e" %s% "f" %s% "g"
> %s% "h")
> # invalid 'description' argument
>
> Wouldn't it be more straightforward to say that an "expression" works only
> if "deparse" (with default arguments) returns a length 1 vector.  Or maybe
> it would be worth considering substituting ...
>
>     .Internal(textConnection(deparse(substitute(object)), object,
>         open, env, type))
>
> ... for something like one of the following:
>
> # 1
> descr <- deparse(substitute(object))
> if(length(descr)>1) descr <- paste(descr, collapse="")
> .Internal(descr, object, open, env, type)
>
> #2
> descr <- deparse(substitute(object))
> if(length(descr)>1) descr <- paste("some nice description", date(), sep="
> -
> ")
> .Internal(descr, object, open, env, type)
>
> In addition, the error message "invalid description argument" can be
> confusing as there is no argument called "description" to textConnection
> and
> the user may not know about the internal function (without reading the
> code). Another point is that the object can be  a character vector itself
> (a
> "string literal")  and in that case it can be quite long
>
> scan(textConnection(paste(rep("a",100000), collapse=",")), what="",
> sep=",")
>
>
> Regards,
> Kenn
>
>
> On Mon, Mar 14, 2011 at 1:36 PM, Simon Urbanek
> <simon.urbanek at r-project.org>wrote:
>
>> Kenn,
>>
>> you might have had a point a while ago, but you may want to check most
>> recent R and re-evaluate:
>>
>> ?textConnection
>> [...]
>>   object: character.  A description of the connection.  For an input
>>           this is an R character vector object, and for an output
>>          connection the name for the R character vector to receive the
>>          output, or 'NULL' (for none).
>> [...]
>>
>> Details:
>>
>>     An input text connection is opened and the character vector is
>>     copied at time the connection object is created, and 'close'
>>     destroys the copy.  'object' should be the name of a character
>>     vector: however, short expressions will be accepted provided they
>>     deparse to less than 60 bytes.
>>
>> Cheers,
>> Simon
>>
>>
>>
>> On Mar 14, 2011, at 7:32 AM, Kenn Konstabel wrote:
>>
>> > Hello,
>> >
>> > `textConnection`  prepares arguments for an internal function, and one
>> of
>> > these arguments is "description" that must be a character vector of
>> length 1
>> > (or so it seems).
>> >
>> > Now the one and only argument you usually give to `textConnection` is
>> > called "object"; from the code you can see how this becomes a
>> "description":
>> >
>> >    .Internal(textConnection(deparse(substitute(object)), object,
>> >        open, env, type))
>> >
>> > deparse(substitute(object)) -- which is intended to get the name of
>> the
>> > object you supplied. Try
>> >
>> >> obj <- "a 1\nb 2\nc 3"
>> >> deparse(substitute(obj))
>> > [1] "obj"
>> >> deparse(substitute("a 1\nb 2\nc 3"))
>> > [1] "\"a 1\\nb 2\\nc 3\""
>> >
>> > This is called "non-standard evaluation" - in almost every other case
>> it
>> > makes no difference whether you do some_fun(obj) or some_fun("a 1\nb
>> 2\nc
>> > 3") but in this case it does.
>> >
>> > Now for some reason (I'm not exactly sure why this happens) the result
>> > deparse+substitute of your gsub thing is a character vector of length
>> 2.
>> >
>> > ugly.string <-  deparse
>> >
>> (substitute(gsub("&","\n",(strsplit('{"abc",{"def","X,1&Y,2&Z,3"}}','\\"')[[1]][6]))))
>> >
>> > length( ugly.string)
>> >
>> > Anyway, if the textConnection object has a "description" component
>> then
>> it
>> > is probably useful for something but something like "gsub(\"&\",
>> \"\\n\",
>> > (strsplit(\"{\\\"abc\\\",{\\\"def\\\",\\\"X,1&Y,2&Z,3\\\"}}\" doesn't
>> seem
>> > too useful. If you really hate the intermediate step (assignment) then
>> a
>> > solution might be to use the internal textConnection function
>> directly,
>> or
>> > modify the code of `textConnection` e.g. like this:
>> >
>> > tc <- function (object, open = "r", local = FALSE, encoding = c("",
>> >    "bytes", "UTF-8")) {
>> >    env <- if (local) parent.frame() else .GlobalEnv
>> >    type <- match(match.arg(encoding), c("", "bytes", "UTF-8"))
>> >    description <- deparse(substitute(object))
>> >    is.ugly <- function(x) length(x)>1
>> >    if(is.ugly(description)) description <- "a nice description"
>> >    .Internal(textConnection(description, object, open, env, type))
>> > }
>> >
>> > # this will work with your examples
>> >
>> > Bu the answer to your bug report was not particularly helpful (a
>> simple
>> > "RTFC"  would have helped more) and from an ordinary mortal's
>>  perspective
>> > it is also wrong.
>> >
>> >>  your usage is incorrect.
>> >>     object: character.  A description of the connection.  For an
>> input
>> >> this is an R character vector object ...
>> >> and you used an expression.  Some expressions work, but only
>> >> simple ones (and none are guaranteed to).
>> >
>> > But what you actually used is "character" and not an expression:
>> >
>> >
>> is.character(gsub("&","\n",(strsplit('{"abc",{"def","X,1&Y,2&Z,3"}}','\\"')[[1]][6])))
>> > # TRUE
>> >
>> is.expression(gsub("&","\n",(strsplit('{"abc",{"def","X,1&Y,2&Z,3"}}','\\"')[[1]][6])))
>> > # FALSE :-P
>> >
>> > (Provided that standard evaluation is used which one would ordinarily
>> > expect.) So in my opinion, the documentation is not complete here: it
>> should
>> > say explicitly that the object would better be a simple name and that
>> > otherwise the result is not guaranteed.
>> >
>> >
>> > Best regards,
>> > Kenn
>> >
>> >
>> > On Thu, Mar 10, 2011 at 12:20 PM, WANGSONG <mr.wangsong at hotmail.com>
>> wrote:
>> >
>> >>
>> >> I need read a table in a string with special format. I used read.csv
>> and
>> >> textConnection function.
>> >> But i am confuse about textConnection by follow code.
>> >>
>> >> case A: It is OK??
>> >> str0 <- '{"abc",{"def","X,1&Y,2&Z,3"}}'
>> >> str1 <- strsplit(str0,'"')[[1]][6]
>> >> str2 <- gsub("&","\n", str1)
>> >> con  <- textConnection( str2 )
>> >> read.csv(con,header=F)
>> >> close(con)
>> >>
>> >> case B: It is NOK!
>> >> con  <- textConnection(
>> >> gsub("&","\n",(strsplit('{"abc",{"def","X,1&Y,2&Z,3"}}','"')[[1]][6]))
>> )
>> >> # Error in here
>> >> read.csv(con,header=F)
>> >> close(con)
>> >>
>> >> case C: It is OK!
>> >> str0 <- '{"abc",{"def","X,1&Y,2&Z,3"}}'
>> >> con  <- textConnection( gsub("&","\n", (strsplit(str0,'"')[[1]][6]))
>> )
>> >> read.csv(con,header=F)
>> >> close(con)
>> >>
>> >> case D: It is OK!
>> >> str2 <- gsub("&","\n",
>> >> strsplit('{"abc",{"def","X,1&Y,2&Z,3"}}','"')[[1]][6])
>> >> con  <- textConnection( str2 )
>> >> read.csv(con,header=F)
>> >> close(con)
>> >>
>> >> Except case B, textConnection report "invalid 'description'
>> argument",
>> in
>> >> other case, textConnection is OK.
>> >>
>> >> I don't known, what is different?? I report it as [Bug 14527], But
>> the
>> >> Answer is :
>> >>>  your usage is incorrect.
>> >>>     object: character.  A description of the connection.  For an
>> input
>> >> this is an R character vector object ...
>> >>> and you used an expression.  Some expressions work, but only simple
>> ones
>> >> (and none are guaranteed to).
>> >>
>> >> I read the help carefully, but i don't known which usage is
>> incorrect.
>> >>
>> >> Would you help me?
>> >>
>> >>
>> >> WangSong
>> >>
>> >>
>> >>       [[alternative HTML version deleted]]
>> >>
>> >>
>> >> ______________________________________________
>> >> R-devel at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-devel
>> >>
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From presnell at stat.ufl.edu  Mon Mar 14 23:02:40 2011
From: presnell at stat.ufl.edu (Brett Presnell)
Date: Mon, 14 Mar 2011 18:02:40 -0400
Subject: [Rd] Standardized Pearson residuals
Message-ID: <87lj0hs6m7.fsf@stat.ufl.edu>


My apologies.  I guess it would help if I tried the code more than once
before posting.  That should have been:

rstandard.glm <-
  function(model,
           infl=influence(model, do.coef=FALSE),
           type=c("deviance", "pearson"), ...)
{
  type <- match.arg(type)
  res <- switch(type, pearson = infl$pear.res, infl$dev.res)
  res <- res/sqrt(1-infl$hat)
  res[is.infinite(res)] <- NaN
  res
}


From pdalgd at gmail.com  Mon Mar 14 23:32:49 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 14 Mar 2011 23:32:49 +0100
Subject: [Rd] Standardized Pearson residuals
In-Reply-To: <87pqpts8ce.fsf@stat.ufl.edu>
References: <87pqpts8ce.fsf@stat.ufl.edu>
Message-ID: <36057519-8DA6-4B60-99D6-A941595CB75B@gmail.com>


On Mar 14, 2011, at 22:25 , Brett Presnell wrote:

> 
> Is there any reason that rstandard.glm doesn't have a "pearson" option?
> And if not, can it be added?

Probably... I have been wondering about that too. I'm even puzzled why it isn't the default. Deviance residuals don't have quite the properties that one might expect, e.g. in this situation, the absolute residuals sum pairwise to zero, so you'd expect that the standardized residuals be identical in absolute value

> y <- 1:4
> r <- c(0,0,1,1)
> c <- c(0,1,0,1)
> rstandard(glm(y~r+c,poisson))
         1          2          3          4 
-0.2901432  0.2767287  0.2784603 -0.2839995 

in comparison,

> i <- influence(glm(y~r+c,poisson))
> i$pear.res/sqrt(1-i$hat)
         1          2          3          4 
-0.2817181  0.2817181  0.2817181 -0.2817181 

The only thing is that I'm always wary of tampering with this stuff, for fear of finding out the hard way why thing are the way they are....


> 
> Background: I'm currently teaching an undergrad/grad-service course from
> Agresti's "Introduction to Categorical Data Analysis (2nd edn)" and
> deviance residuals are not used in the text.  For now I'll just provide
> the students with a simple function to use, but I prefer to use R's
> native capabilities whenever possible.


Incidentally, chisq.test will have a stdres component in 2.13.0 for much the same reason. 

> 
> I think something along the following lines should do it:
> 
> rstandard.glm <-
>  function(model,
>           infl=influence(model, do.coef=FALSE),
>           type=c("deviance", "pearson"), ...)
> {
>  res <- switch(type, pearson = infl$pear.res, infl$dev.res)
>  res <- res/sqrt(1-infl$hat)
>  res[is.infinite(res)] <- NaN
>  res
> }
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From presnell at stat.ufl.edu  Tue Mar 15 04:40:29 2011
From: presnell at stat.ufl.edu (Brett Presnell)
Date: Mon, 14 Mar 2011 23:40:29 -0400
Subject: [Rd] Standardized Pearson residuals
In-Reply-To: <36057519-8DA6-4B60-99D6-A941595CB75B@gmail.com> (peter
	dalgaard's message of "Mon, 14 Mar 2011 23:32:49 +0100")
References: <87pqpts8ce.fsf@stat.ufl.edu>
	<36057519-8DA6-4B60-99D6-A941595CB75B@gmail.com>
Message-ID: <8739mp830y.fsf@stat.ufl.edu>


Thanks Peter.  I have just a couple of minor comments, and another
possible feature request, although it's one that I don't think will be
implemented.

peter dalgaard <pdalgd at gmail.com> writes:

> On Mar 14, 2011, at 22:25 , Brett Presnell wrote:
>
>> 
>> Is there any reason that rstandard.glm doesn't have a "pearson" option?
>> And if not, can it be added?
>
> Probably... I have been wondering about that too. I'm even puzzled why
> it isn't the default. Deviance residuals don't have quite the
> properties that one might expect, e.g. in this situation, the absolute
> residuals sum pairwise to zero, so you'd expect that the standardized
> residuals be identical in absolute value
>
>> y <- 1:4
>> r <- c(0,0,1,1)
>> c <- c(0,1,0,1)
>> rstandard(glm(y~r+c,poisson))
>          1          2          3          4 
> -0.2901432  0.2767287  0.2784603 -0.2839995 
>
> in comparison,
>
>> i <- influence(glm(y~r+c,poisson))
>> i$pear.res/sqrt(1-i$hat)
>          1          2          3          4 
> -0.2817181  0.2817181  0.2817181 -0.2817181 
> 
> The only thing is that I'm always wary of tampering with this stuff,
> for fear of finding out the hard way why thing are the way they
> are....

I'm sure that's wise, but it would be nice to get it in as an option,
even if it's not the default

>> Background: I'm currently teaching an undergrad/grad-service course from
>> Agresti's "Introduction to Categorical Data Analysis (2nd edn)" and
>> deviance residuals are not used in the text.  For now I'll just provide
>> the students with a simple function to use, but I prefer to use R's
>> native capabilities whenever possible.
>
> Incidentally, chisq.test will have a stdres component in 2.13.0 for
> much the same reason.

Thank you.  That's one more thing I won't have to provide code for
anymore.  Coincidentally, Agresti mentioned this to me a week or two ago
as something that he felt was missing, so that's at least two people who
will be happy to see this added.

It would also be nice for teaching purposes if glm or summary.glm had a
"pearsonchisq" component and a corresponding extractor function, but I
can imagine that there might be arguments against it that haven't
occured to me.  Plus, I doubt that anyone wants to touch glm unless it's
to repair a bug. If I'm wrong about all that though, ...

BTW, as I go along I'm trying to collect a lot of the datasets from the
examples and exercises in the text into an R package ("icda").  It's far
from complete and what is there needed tidying up, but I hope to
eventually to round it into shape and put it on CRAN, assuming that
Agresti approves and that there are no copyright issues.

>> I think something along the following lines should do it:
>> 
>> rstandard.glm <-
>>  function(model,
>>           infl=influence(model, do.coef=FALSE),
>>           type=c("deviance", "pearson"), ...)
>> {
>>  type <- match.arg(type)
>>  res <- switch(type, pearson = infl$pear.res, infl$dev.res)
>>  res <- res/sqrt(1-infl$hat)
>>  res[is.infinite(res)] <- NaN
>>  res
>> }


From ripley at stats.ox.ac.uk  Tue Mar 15 07:32:00 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 15 Mar 2011 06:32:00 +0000 (GMT)
Subject: [Rd] fortran 90 underscore error
In-Reply-To: <1991.89.243.32.35.1300139945.squirrel@paleo.ija.csic.es>
References: <BLU159-w408CB0E72A7114BFA5D24F4C80@phx.gbl>
	<AANLkTi=vsFizrAshwTzGYYUm2G=Kt-9ArH5CJDVAkhtw@mail.gmail.com>
	<FB725016-19BB-4A3D-9916-7301DAEAF7D9@r-project.org>
	<AANLkTi=8yJvD+1giF9KN80JENJAEpFYM8jBFbDcpEjrT@mail.gmail.com>
	<1991.89.243.32.35.1300139945.squirrel@paleo.ija.csic.es>
Message-ID: <alpine.LFD.2.02.1103150627550.2580@gannet.stats.ox.ac.uk>

We have no position about Fortran 90.  We provide the means to specify 
an F90 compiler and note that its use is not portable as not all 
platforms have one.  (A very few are still using gcc3 with g77.)

This simply is not an R issue, and seems specific to your unstated 
platform (*PLEASE* do follow the posting guide).

On Mon, 14 Mar 2011, jgarcia at ija.csic.es wrote:

> Hi there,
>
> I am preparing a package based on Fortran 90 code. I've put the main code
> is a MODULE, and I'm having several error messages with the linker:
>
>> R CMD SHLIB --output=mylib.so nrtype.f90 topbalmod.f90 runmodels.f90
>
> The several error messages are related with the addition of an underscore
> to function names (no problem with subroutine names). E.g.:
>
> topbalmod.o:topbalmod.f90:<.text+0x357f>: undefined reference to 'runga_'
>
> After some googling, AFAIK, it seems the addition of underscores (I'm
> using gfortran) may be avoided by the option -fno-underscoring, but its
> use is not recomended as it is not of general use by all compilers.
>
> I'm just wondering if R developers just recommend not to use user defined
> fortran functions at all to avoid this problem, or alternatively if you
> could provided with some example about how to circumvent it (perhaps to
> convert all fortran 90 functions into subroutines?).
>
> Thanks and best regards.
>
> Javier
> ---

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From andreas.borg at unimedizin-mainz.de  Tue Mar 15 11:37:21 2011
From: andreas.borg at unimedizin-mainz.de (Andreas Borg)
Date: Tue, 15 Mar 2011 11:37:21 +0100
Subject: [Rd] Feature request: txtProgressBar with ability to write to
 arbitrary stream
Message-ID: <4D7F4161.2070909@unimedizin-mainz.de>

Hi all,

I use txtProgressBar to monitor progress of large computations. What I 
miss is the ability to redirect the progress bar to a stream other than 
stdout, specifically to the message stream. This would be useful for 
running Sweave scripts: When redirected to stderr, the bar could be 
visible even though console output is diverted to the output file (and 
there would be no cluttering of the generated latex).

I'd suggest the following changes to txtProgressBar:
- a new argument 'file' (compare to 'cat') which defaults to stderr() 
(there might be reasons to use stdout(), but I believe a progress bar is 
mostly intended as a diagnostic tool and not for console output, which 
is printed or saved in some cases).
- the calls to 'cat' that update the progress bar get 'file = file' as 
additional argument so that output is redirected as desired.

In case anyone from the core team is willing to incorparate this idea, I 
attached the patch file for the necessary changes below.

Best regards,

Andreas

3c3
<              width = NA, title, label, style = 1)
---
 >              width = NA, title, label, style = 1, file=stderr())
23c23
<             cat(paste(rep.int(char, nb-.nb), collapse=""))
---
 >             cat(paste(rep.int(char, nb-.nb), collapse=""), file = file)
27c27
<                 "\r", paste(rep.int(char, nb), collapse=""), sep = "")
---
 >                 "\r", paste(rep.int(char, nb), collapse=""), sep = 
"", file = file)
38c38
<             cat("\r", paste(rep.int(char, nb), collapse=""), sep = "")
---
 >             cat("\r", paste(rep.int(char, nb), collapse=""), sep = 
"", file = file)
42c42
<                 "\r", paste(rep.int(char, nb), collapse=""), sep = "")
---
 >                 "\r", paste(rep.int(char, nb), collapse=""), sep = 
"", file = file)
54c54
<         cat(paste(c("\r  |", rep.int(" ", nw*width+6)), collapse=""))
---
 >         cat(paste(c("\r  |", rep.int(" ", nw*width+6)), collapse=""), 
file = file)
59c59
<                     ), collapse=""))
---
 >                     ), collapse=""), file = file)
68c68
<             cat("\n")
---
 >             cat("\n", file = file)

-- 
Andreas Borg
Medizinische Informatik

UNIVERSIT?TSMEDIZIN
der Johannes Gutenberg-Universit?t
Institut f?r Medizinische Biometrie, Epidemiologie und Informatik
Obere Zahlbacher Stra?e 69, 55131 Mainz
www.imbei.uni-mainz.de

Telefon +49 (0) 6131 175062
E-Mail: borg at imbei.uni-mainz.de

Diese E-Mail enth?lt vertrauliche und/oder rechtlich gesch?tzte Informationen. Wenn Sie nicht der
richtige Adressat sind oder diese E-Mail irrt?mlich erhalten haben, informieren Sie bitte sofort den
Absender und l?schen Sie diese Mail. Das unerlaubte Kopieren sowie die unbefugte Weitergabe
dieser Mail und der darin enthaltenen Informationen ist nicht gestattet.


From pdalgd at gmail.com  Tue Mar 15 12:17:46 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 15 Mar 2011 12:17:46 +0100
Subject: [Rd] Standardized Pearson residuals
In-Reply-To: <8739mp830y.fsf@stat.ufl.edu>
References: <87pqpts8ce.fsf@stat.ufl.edu>
	<36057519-8DA6-4B60-99D6-A941595CB75B@gmail.com>
	<8739mp830y.fsf@stat.ufl.edu>
Message-ID: <58393ED6-2E85-4C80-843B-51DA023274FF@gmail.com>


On Mar 15, 2011, at 04:40 , Brett Presnell wrote:

> 
>>> Background: I'm currently teaching an undergrad/grad-service course from
>>> Agresti's "Introduction to Categorical Data Analysis (2nd edn)" and
>>> deviance residuals are not used in the text.  For now I'll just provide
>>> the students with a simple function to use, but I prefer to use R's
>>> native capabilities whenever possible.
>> 
>> Incidentally, chisq.test will have a stdres component in 2.13.0 for
>> much the same reason.
> 
> Thank you.  That's one more thing I won't have to provide code for
> anymore.  Coincidentally, Agresti mentioned this to me a week or two ago
> as something that he felt was missing, so that's at least two people who
> will be happy to see this added.
> 

And of course, I was teaching a course based on Agresti & Franklin: "Statistics, The Art and Science of Learning from Data", when I realized that R was missing standardized residuals. 


> It would also be nice for teaching purposes if glm or summary.glm had a
> "pearsonchisq" component and a corresponding extractor function, but I
> can imagine that there might be arguments against it that haven't
> occured to me.  Plus, I doubt that anyone wants to touch glm unless it's
> to repair a bug. If I'm wrong about all that though, ...
> 

Hmm, how would that work? If there was one, I'd worry that people would start subtracting them which is usually not the right thing to do. I do miss having a test on the residual deviance occasionally (even though it is only sometimes meaningful), having to fit a saturated model explicitly can be a bit silly. E.g. in this case (homogeneity of birth rates):

> anova(glm(births~month,poisson,data=bb), test="Chisq")
...
      Df Deviance Resid. Df Resid. Dev P(>|Chi|)    
NULL                     11     225.98              
month 11   225.98         0       0.00 < 2.2e-16 ***
> anova(glm(births~1,poisson,data=bb), test="Chisq")
...
     Df Deviance Resid. Df Resid. Dev P(>|Chi|)
NULL                    11     225.98          

Notice that the latter version gives me the correct deviance but no p-value.


A better support for generic score tests could be desirable too. I suspect that this would actually be the Pearson Chi-square in the interesting cases.  

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From john.maindonald at anu.edu.au  Tue Mar 15 13:42:25 2011
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Tue, 15 Mar 2011 23:42:25 +1100
Subject: [Rd] Standardized Pearson residuals
In-Reply-To: <mailman.28.1300186808.4951.r-devel@r-project.org>
References: <mailman.28.1300186808.4951.r-devel@r-project.org>
Message-ID: <9E1DF5E9-0B03-441C-9157-B9A7A16A0F53@anu.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110315/79337026/attachment.pl>

From jari.oksanen at oulu.fi  Tue Mar 15 14:22:20 2011
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Tue, 15 Mar 2011 15:22:20 +0200
Subject: [Rd] Standardized Pearson residuals
In-Reply-To: <58393ED6-2E85-4C80-843B-51DA023274FF@gmail.com>
Message-ID: <C9A534AC.15BF4%jari.oksanen@oulu.fi>

On 15/03/11 13:17 PM, "peter dalgaard" <pdalgd at gmail.com> wrote:

> 
> On Mar 15, 2011, at 04:40 , Brett Presnell wrote:
> 
>> 
>>>> Background: I'm currently teaching an undergrad/grad-service course from
>>>> Agresti's "Introduction to Categorical Data Analysis (2nd edn)" and
>>>> deviance residuals are not used in the text.  For now I'll just provide
>>>> the students with a simple function to use, but I prefer to use R's
>>>> native capabilities whenever possible.
>>> 
>>> Incidentally, chisq.test will have a stdres component in 2.13.0 for
>>> much the same reason.
>> 
>> Thank you.  That's one more thing I won't have to provide code for
>> anymore.  Coincidentally, Agresti mentioned this to me a week or two ago
>> as something that he felt was missing, so that's at least two people who
>> will be happy to see this added.
>> 
> 
> And of course, I was teaching a course based on Agresti & Franklin:
> "Statistics, The Art and Science of Learning from Data", when I realized that
> R was missing standardized residuals.
> 
So nobody uses McCullagh & Nelder: "Generalized Linear Models" in teaching,
since they don't realize that R is missing Anscombe residuals, too?

Cheers, Jari Oksanen


From Matt.Shotwell at Vanderbilt.Edu  Tue Mar 15 13:46:18 2011
From: Matt.Shotwell at Vanderbilt.Edu (Matt Shotwell)
Date: Tue, 15 Mar 2011 07:46:18 -0500
Subject: [Rd] Feature request: txtProgressBar with ability to write to
 arbitrary stream
In-Reply-To: <4D7F4161.2070909@unimedizin-mainz.de>
References: <4D7F4161.2070909@unimedizin-mainz.de>
Message-ID: <4D7F5F9A.4040707@Vanderbilt.edu>

Here's a temporary fix; reassign 'cat' in the environment of 
'txtProgressBar':

tpbEnv <- new.env()
assign("cat", function(...) cat(file=stderr(),...), tpbEnv)
environment(txtProgressBar) <- tpbEnv

Best,
Matt


On 03/15/2011 05:37 AM, Andreas Borg wrote:
> Hi all,
>
> I use txtProgressBar to monitor progress of large computations. What I
> miss is the ability to redirect the progress bar to a stream other than
> stdout, specifically to the message stream. This would be useful for
> running Sweave scripts: When redirected to stderr, the bar could be
> visible even though console output is diverted to the output file (and
> there would be no cluttering of the generated latex).
>
> I'd suggest the following changes to txtProgressBar:
> - a new argument 'file' (compare to 'cat') which defaults to stderr()
> (there might be reasons to use stdout(), but I believe a progress bar is
> mostly intended as a diagnostic tool and not for console output, which
> is printed or saved in some cases).
> - the calls to 'cat' that update the progress bar get 'file = file' as
> additional argument so that output is redirected as desired.
>
> In case anyone from the core team is willing to incorparate this idea, I
> attached the patch file for the necessary changes below.
>
> Best regards,
>
> Andreas
>
> 3c3
> < width = NA, title, label, style = 1)
> ---
>  > width = NA, title, label, style = 1, file=stderr())
> 23c23
> < cat(paste(rep.int(char, nb-.nb), collapse=""))
> ---
>  > cat(paste(rep.int(char, nb-.nb), collapse=""), file = file)
> 27c27
> < "\r", paste(rep.int(char, nb), collapse=""), sep = "")
> ---
>  > "\r", paste(rep.int(char, nb), collapse=""), sep = "", file = file)
> 38c38
> < cat("\r", paste(rep.int(char, nb), collapse=""), sep = "")
> ---
>  > cat("\r", paste(rep.int(char, nb), collapse=""), sep = "", file = file)
> 42c42
> < "\r", paste(rep.int(char, nb), collapse=""), sep = "")
> ---
>  > "\r", paste(rep.int(char, nb), collapse=""), sep = "", file = file)
> 54c54
> < cat(paste(c("\r |", rep.int(" ", nw*width+6)), collapse=""))
> ---
>  > cat(paste(c("\r |", rep.int(" ", nw*width+6)), collapse=""), file =
> file)
> 59c59
> < ), collapse=""))
> ---
>  > ), collapse=""), file = file)
> 68c68
> < cat("\n")
> ---
>  > cat("\n", file = file)
>


-- 
Matthew S Shotwell   Assistant Professor           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From pdalgd at gmail.com  Tue Mar 15 14:41:20 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 15 Mar 2011 14:41:20 +0100
Subject: [Rd] Standardized Pearson residuals
In-Reply-To: <9E1DF5E9-0B03-441C-9157-B9A7A16A0F53@anu.edu.au>
References: <mailman.28.1300186808.4951.r-devel@r-project.org>
	<9E1DF5E9-0B03-441C-9157-B9A7A16A0F53@anu.edu.au>
Message-ID: <4DB19694-B58A-44BC-B779-CC086F223605@gmail.com>


On Mar 15, 2011, at 13:42 , John Maindonald wrote:

>> Peter Dalgaard: It would also be nice for teaching purposes if glm or summary.glm had a
>> "pearsonchisq" component and a corresponding extractor function, but I
>> can imagine that there might be arguments against it that haven't
>> occured to me.  Plus, I doubt that anyone wants to touch glm unless it's
>> to repair a bug. If I'm wrong about all that though, ...
> 

Umm, that was Brett, actually.

> This would remedy what I have long judged a deficiency in summary.glm().
> The information is important for diagnostic purposes.  One should not have
> to fit a model with a quasi error, or suss out how to calculate the Pearson
> chi square from the glm model object, to discover that the information in the
> model object is inconsistent with simple binomial or poisson assumptions.

It could be somewhere between useless and misleading in cases like binary logistic regression though. (Same thing goes for the test against the saturated model: Sometimes it makes sense and sometimes not.)

> 
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
> 
> On 15/03/2011, at 10:00 PM, r-devel-request at r-project.org wrote:
> 
>> From: Brett Presnell <presnell at stat.ufl.edu>
>> Date: 15 March 2011 2:40:29 PM AEDT
>> To: peter dalgaard <pdalgd at gmail.com>
>> Cc: r-devel at r-project.org
>> Subject: Re: [Rd] Standardized Pearson residuals
>> 
>> 
>> 
>> Thanks Peter.  I have just a couple of minor comments, and another
>> possible feature request, although it's one that I don't think will be
>> implemented.
>> 
>> peter dalgaard <pdalgd at gmail.com> writes:
>> 
>>> On Mar 14, 2011, at 22:25 , Brett Presnell wrote:
>>> 
>>>> 
>>>> Is there any reason that rstandard.glm doesn't have a "pearson" option?
>>>> And if not, can it be added?
>>> 
>>> Probably... I have been wondering about that too. I'm even puzzled why
>>> it isn't the default. Deviance residuals don't have quite the
>>> properties that one might expect, e.g. in this situation, the absolute
>>> residuals sum pairwise to zero, so you'd expect that the standardized
>>> residuals be identical in absolute value
>>> 
>>>> y <- 1:4
>>>> r <- c(0,0,1,1)
>>>> c <- c(0,1,0,1)
>>>> rstandard(glm(y~r+c,poisson))
>>>        1          2          3          4 
>>> -0.2901432  0.2767287  0.2784603 -0.2839995 
>>> 
>>> in comparison,
>>> 
>>>> i <- influence(glm(y~r+c,poisson))
>>>> i$pear.res/sqrt(1-i$hat)
>>>        1          2          3          4 
>>> -0.2817181  0.2817181  0.2817181 -0.2817181 
>>> 
>>> The only thing is that I'm always wary of tampering with this stuff,
>>> for fear of finding out the hard way why thing are the way they
>>> are....
>> 
>> I'm sure that's wise, but it would be nice to get it in as an option,
>> even if it's not the default
>> 
>>>> Background: I'm currently teaching an undergrad/grad-service course from
>>>> Agresti's "Introduction to Categorical Data Analysis (2nd edn)" and
>>>> deviance residuals are not used in the text.  For now I'll just provide
>>>> the students with a simple function to use, but I prefer to use R's
>>>> native capabilities whenever possible.
>>> 
>>> Incidentally, chisq.test will have a stdres component in 2.13.0 for
>>> much the same reason.
>> 
>> Thank you.  That's one more thing I won't have to provide code for
>> anymore.  Coincidentally, Agresti mentioned this to me a week or two ago
>> as something that he felt was missing, so that's at least two people who
>> will be happy to see this added.
>> 
>> It would also be nice for teaching purposes if glm or summary.glm had a
>> "pearsonchisq" component and a corresponding extractor function, but I
>> can imagine that there might be arguments against it that haven't
>> occured to me.  Plus, I doubt that anyone wants to touch glm unless it's
>> to repair a bug. If I'm wrong about all that though, ...
>> 
>> BTW, as I go along I'm trying to collect a lot of the datasets from the
>> examples and exercises in the text into an R package ("icda").  It's far
>> from complete and what is there needed tidying up, but I hope to
>> eventually to round it into shape and put it on CRAN, assuming that
>> Agresti approves and that there are no copyright issues.
>> 
>>>> I think something along the following lines should do it:
>>>> 
>>>> rstandard.glm <-
>>>> function(model,
>>>>         infl=influence(model, do.coef=FALSE),
>>>>         type=c("deviance", "pearson"), ...)
>>>> {
>>>> type <- match.arg(type)
>>>> res <- switch(type, pearson = infl$pear.res, infl$dev.res)
>>>> res <- res/sqrt(1-infl$hat)
>>>> res[is.infinite(res)] <- NaN
>>>> res
>>>> }
>> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pdalgd at gmail.com  Tue Mar 15 14:43:55 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 15 Mar 2011 14:43:55 +0100
Subject: [Rd] Standardized Pearson residuals
In-Reply-To: <C9A534AC.15BF4%jari.oksanen@oulu.fi>
References: <C9A534AC.15BF4%jari.oksanen@oulu.fi>
Message-ID: <5567E1A2-A02A-4286-9505-4C21B829984A@gmail.com>


On Mar 15, 2011, at 14:22 , Jari Oksanen wrote:

> On 15/03/11 13:17 PM, "peter dalgaard" <pdalgd at gmail.com> wrote:
> 
>> 
>> On Mar 15, 2011, at 04:40 , Brett Presnell wrote:
>> 
>>> 
>>>>> Background: I'm currently teaching an undergrad/grad-service course from
>>>>> Agresti's "Introduction to Categorical Data Analysis (2nd edn)" and
>>>>> deviance residuals are not used in the text.  For now I'll just provide
>>>>> the students with a simple function to use, but I prefer to use R's
>>>>> native capabilities whenever possible.
>>>> 
>>>> Incidentally, chisq.test will have a stdres component in 2.13.0 for
>>>> much the same reason.
>>> 
>>> Thank you.  That's one more thing I won't have to provide code for
>>> anymore.  Coincidentally, Agresti mentioned this to me a week or two ago
>>> as something that he felt was missing, so that's at least two people who
>>> will be happy to see this added.
>>> 
>> 
>> And of course, I was teaching a course based on Agresti & Franklin:
>> "Statistics, The Art and Science of Learning from Data", when I realized that
>> R was missing standardized residuals.
>> 
> So nobody uses McCullagh & Nelder: "Generalized Linear Models" in teaching,
> since they don't realize that R is missing Anscombe residuals, too?
> 
> Cheers, Jari Oksanen
> 

Well, if you can read the book, you can probably write the code...

The other books are for beginners who may need the convenience (and persuasion power) of standard software.

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From murdoch.duncan at gmail.com  Tue Mar 15 15:57:16 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 15 Mar 2011 10:57:16 -0400
Subject: [Rd] Feature request: txtProgressBar with ability to write to
 arbitrary stream
In-Reply-To: <4D7F5F9A.4040707@Vanderbilt.edu>
References: <4D7F4161.2070909@unimedizin-mainz.de>
	<4D7F5F9A.4040707@Vanderbilt.edu>
Message-ID: <4D7F7E4C.8070904@gmail.com>

On 15/03/2011 8:46 AM, Matt Shotwell wrote:
> Here's a temporary fix; reassign 'cat' in the environment of
> 'txtProgressBar':
>
> tpbEnv<- new.env()
> assign("cat", function(...) cat(file=stderr(),...), tpbEnv)
> environment(txtProgressBar)<- tpbEnv

I would suggest renaming the function as well.  What's done above 
creates a new function called txtProgressBar, it doesn't modify the 
original one, so depending on scoping issues it may appear to only work 
sometimes.  But if you did

stderrProgressBar <- txtProgressBar
environment(stderrProgressBar) <- tpbEnv

you'll get clear messages if it is out of scope when you try to use it.

Duncan Murdoch

> Best,
> Matt
>
>
> On 03/15/2011 05:37 AM, Andreas Borg wrote:
> >  Hi all,
> >
> >  I use txtProgressBar to monitor progress of large computations. What I
> >  miss is the ability to redirect the progress bar to a stream other than
> >  stdout, specifically to the message stream. This would be useful for
> >  running Sweave scripts: When redirected to stderr, the bar could be
> >  visible even though console output is diverted to the output file (and
> >  there would be no cluttering of the generated latex).
> >
> >  I'd suggest the following changes to txtProgressBar:
> >  - a new argument 'file' (compare to 'cat') which defaults to stderr()
> >  (there might be reasons to use stdout(), but I believe a progress bar is
> >  mostly intended as a diagnostic tool and not for console output, which
> >  is printed or saved in some cases).
> >  - the calls to 'cat' that update the progress bar get 'file = file' as
> >  additional argument so that output is redirected as desired.
> >
> >  In case anyone from the core team is willing to incorparate this idea, I
> >  attached the patch file for the necessary changes below.
> >
> >  Best regards,
> >
> >  Andreas
> >
> >  3c3
> >  <  width = NA, title, label, style = 1)
> >  ---
> >   >  width = NA, title, label, style = 1, file=stderr())
> >  23c23
> >  <  cat(paste(rep.int(char, nb-.nb), collapse=""))
> >  ---
> >   >  cat(paste(rep.int(char, nb-.nb), collapse=""), file = file)
> >  27c27
> >  <  "\r", paste(rep.int(char, nb), collapse=""), sep = "")
> >  ---
> >   >  "\r", paste(rep.int(char, nb), collapse=""), sep = "", file = file)
> >  38c38
> >  <  cat("\r", paste(rep.int(char, nb), collapse=""), sep = "")
> >  ---
> >   >  cat("\r", paste(rep.int(char, nb), collapse=""), sep = "", file = file)
> >  42c42
> >  <  "\r", paste(rep.int(char, nb), collapse=""), sep = "")
> >  ---
> >   >  "\r", paste(rep.int(char, nb), collapse=""), sep = "", file = file)
> >  54c54
> >  <  cat(paste(c("\r |", rep.int(" ", nw*width+6)), collapse=""))
> >  ---
> >   >  cat(paste(c("\r |", rep.int(" ", nw*width+6)), collapse=""), file =
> >  file)
> >  59c59
> >  <  ), collapse=""))
> >  ---
> >   >  ), collapse=""), file = file)
> >  68c68
> >  <  cat("\n")
> >  ---
> >   >  cat("\n", file = file)
> >
>
>


From Greg.Snow at imail.org  Tue Mar 15 20:18:42 2011
From: Greg.Snow at imail.org (Greg Snow)
Date: Tue, 15 Mar 2011 13:18:42 -0600
Subject: [Rd] Feature request: txtProgressBar with ability to write to
 arbitrary stream
In-Reply-To: <4D7F4161.2070909@unimedizin-mainz.de>
References: <4D7F4161.2070909@unimedizin-mainz.de>
Message-ID: <B37C0A15B8FB3C468B5BC7EBC7DA14CC63453A3337@LP-EXMBVS10.CO.IHC.COM>

You could use winProgressBar (windows only) or TkProgressBar (tcltk package required) instead, then nothing is output to the console/standard out but you still have a visual of your progress.

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
801.408.8111


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
> project.org] On Behalf Of Andreas Borg
> Sent: Tuesday, March 15, 2011 4:37 AM
> To: R-devel at r-project.org
> Subject: [Rd] Feature request: txtProgressBar with ability to write to
> arbitrary stream
> 
> Hi all,
> 
> I use txtProgressBar to monitor progress of large computations. What I
> miss is the ability to redirect the progress bar to a stream other than
> stdout, specifically to the message stream. This would be useful for
> running Sweave scripts: When redirected to stderr, the bar could be
> visible even though console output is diverted to the output file (and
> there would be no cluttering of the generated latex).
> 
> I'd suggest the following changes to txtProgressBar:
> - a new argument 'file' (compare to 'cat') which defaults to stderr()
> (there might be reasons to use stdout(), but I believe a progress bar
> is
> mostly intended as a diagnostic tool and not for console output, which
> is printed or saved in some cases).
> - the calls to 'cat' that update the progress bar get 'file = file' as
> additional argument so that output is redirected as desired.
> 
> In case anyone from the core team is willing to incorparate this idea,
> I
> attached the patch file for the necessary changes below.
> 
> Best regards,
> 
> Andreas
> 
> 3c3
> <              width = NA, title, label, style = 1)
> ---
>  >              width = NA, title, label, style = 1, file=stderr())
> 23c23
> <             cat(paste(rep.int(char, nb-.nb), collapse=""))
> ---
>  >             cat(paste(rep.int(char, nb-.nb), collapse=""), file =
> file)
> 27c27
> <                 "\r", paste(rep.int(char, nb), collapse=""), sep =
> "")
> ---
>  >                 "\r", paste(rep.int(char, nb), collapse=""), sep =
> "", file = file)
> 38c38
> <             cat("\r", paste(rep.int(char, nb), collapse=""), sep =
> "")
> ---
>  >             cat("\r", paste(rep.int(char, nb), collapse=""), sep =
> "", file = file)
> 42c42
> <                 "\r", paste(rep.int(char, nb), collapse=""), sep =
> "")
> ---
>  >                 "\r", paste(rep.int(char, nb), collapse=""), sep =
> "", file = file)
> 54c54
> <         cat(paste(c("\r  |", rep.int(" ", nw*width+6)), collapse=""))
> ---
>  >         cat(paste(c("\r  |", rep.int(" ", nw*width+6)),
> collapse=""),
> file = file)
> 59c59
> <                     ), collapse=""))
> ---
>  >                     ), collapse=""), file = file)
> 68c68
> <             cat("\n")
> ---
>  >             cat("\n", file = file)
> 
> --
> Andreas Borg
> Medizinische Informatik
> 
> UNIVERSIT?TSMEDIZIN
> der Johannes Gutenberg-Universit?t
> Institut f?r Medizinische Biometrie, Epidemiologie und Informatik
> Obere Zahlbacher Stra?e 69, 55131 Mainz
> www.imbei.uni-mainz.de
> 
> Telefon +49 (0) 6131 175062
> E-Mail: borg at imbei.uni-mainz.de
> 
> Diese E-Mail enth?lt vertrauliche und/oder rechtlich gesch?tzte
> Informationen. Wenn Sie nicht der
> richtige Adressat sind oder diese E-Mail irrt?mlich erhalten haben,
> informieren Sie bitte sofort den
> Absender und l?schen Sie diese Mail. Das unerlaubte Kopieren sowie die
> unbefugte Weitergabe
> dieser Mail und der darin enthaltenen Informationen ist nicht
> gestattet.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From mxkuhn at gmail.com  Wed Mar 16 02:48:07 2011
From: mxkuhn at gmail.com (Max Kuhn)
Date: Tue, 15 Mar 2011 21:48:07 -0400
Subject: [Rd] object not found whilst loading namespace
Message-ID: <AANLkTinPXqDcByoT3_pqjWcYnUqB50R-RrB-e_G2BSCB@mail.gmail.com>

I've been updating a package and, when installing a local devel
version, I get an error "object 'confusionMatrix' not found whilst
loading namespace". Looking around online, it appears that this might
be related to loading a specific RData file, but it doesn't seem to be
the case AFAICT.

I've installed the devel version in the last week without issues and
the confusionMatrix code has been touched in a while.

Thanks,

Max

> sessionInfo()
R version 2.11.1 (2010-05-31)
x86_64-apple-darwin9.8.0

locale:
[1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] caret_4.71     reshape_0.8.3  plyr_1.2.1     lattice_0.18-8

loaded via a namespace (and not attached):
[1] grid_2.11.1


pkg_kuhna03$ R CMD INSTALL caret
* installing to library ?/Library/Frameworks/R.framework/Resources/library?
* installing *source* package ?caret? ...
** libs
*** arch - i386
gcc -arch i386 -std=gnu99
-I/Library/Frameworks/R.framework/Resources/include
-I/Library/Frameworks/R.framework/Resources/include/i386
-I/usr/local/include    -fPIC  -g -O2 -c caret.c -o caret.o
gcc -arch i386 -std=gnu99 -dynamiclib -Wl,-headerpad_max_install_names
-undefined dynamic_lookup -single_module -multiply_defined suppress
-L/usr/local/lib -o caret.so caret.o
-F/Library/Frameworks/R.framework/.. -framework R -Wl,-framework
-Wl,CoreFoundation
installing to /Library/Frameworks/R.framework/Resources/library/caret/libs/i386
*** arch - x86_64
gcc -arch x86_64 -std=gnu99
-I/Library/Frameworks/R.framework/Resources/include
-I/Library/Frameworks/R.framework/Resources/include/x86_64
-I/usr/local/include    -fPIC  -g -O2 -c caret.c -o caret.o
gcc -arch x86_64 -std=gnu99 -dynamiclib
-Wl,-headerpad_max_install_names -undefined dynamic_lookup
-single_module -multiply_defined suppress -L/usr/local/lib -o caret.so
caret.o -F/Library/Frameworks/R.framework/.. -framework R
-Wl,-framework -Wl,CoreFoundation
installing to /Library/Frameworks/R.framework/Resources/library/caret/libs/x86_64
** R
** data
** inst
** preparing package for lazy loading
Loading required package: plyr

Attaching package: 'reshape'

The following object(s) are masked from 'package:plyr':

    round_any

** help
*** installing help indices
** building package indices ...
** testing if installed package can be loaded
Error : object 'confusionMatrix' not found whilst loading namespace 'caret'
ERROR: loading failed
* removing ?/Library/Frameworks/R.framework/Resources/library/caret?
* restoring previous ?/Library/Frameworks/R.framework/Resources/library/caret?


From mxkuhn at gmail.com  Wed Mar 16 02:59:31 2011
From: mxkuhn at gmail.com (Max Kuhn)
Date: Tue, 15 Mar 2011 21:59:31 -0400
Subject: [Rd] object not found whilst loading namespace
In-Reply-To: <AANLkTinPXqDcByoT3_pqjWcYnUqB50R-RrB-e_G2BSCB@mail.gmail.com>
References: <AANLkTinPXqDcByoT3_pqjWcYnUqB50R-RrB-e_G2BSCB@mail.gmail.com>
Message-ID: <AANLkTi=Ai_mZyfHcxgP-cnTecYmQQGGAzjxTaHW3v4y7@mail.gmail.com>

Please disregard the last email...

The issue was a syntactical error in a file that, alphabetically,
comes before confusionMatrix.R in the package.

The odd thing was that the problem in this file did not throw and
error (or I would have easily found it). I decided to source the R
files one by one to see if there were any issues and that showed the
problem:

> source("~/Code/caret/pkg/caret/R/classLevels.R")
Error in source("~/Code/caret/pkg/caret/R/classLevels.R") :
  ~/Code/caret/pkg/caret/R/classLevels.R:150:0: unexpected end of input

Thanks anyway,

Max



On Tue, Mar 15, 2011 at 9:48 PM, Max Kuhn <mxkuhn at gmail.com> wrote:
> I've been updating a package and, when installing a local devel
> version, I get an error "object 'confusionMatrix' not found whilst
> loading namespace". Looking around online, it appears that this might
> be related to loading a specific RData file, but it doesn't seem to be
> the case AFAICT.
>
> I've installed the devel version in the last week without issues and
> the confusionMatrix code has been touched in a while.
>
> Thanks,
>
> Max
>
>> sessionInfo()
> R version 2.11.1 (2010-05-31)
> x86_64-apple-darwin9.8.0
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
> other attached packages:
> [1] caret_4.71 ? ? reshape_0.8.3 ?plyr_1.2.1 ? ? lattice_0.18-8
>
> loaded via a namespace (and not attached):
> [1] grid_2.11.1
>
>
> pkg_kuhna03$ R CMD INSTALL caret
> * installing to library ?/Library/Frameworks/R.framework/Resources/library?
> * installing *source* package ?caret? ...
> ** libs
> *** arch - i386
> gcc -arch i386 -std=gnu99
> -I/Library/Frameworks/R.framework/Resources/include
> -I/Library/Frameworks/R.framework/Resources/include/i386
> -I/usr/local/include ? ?-fPIC ?-g -O2 -c caret.c -o caret.o
> gcc -arch i386 -std=gnu99 -dynamiclib -Wl,-headerpad_max_install_names
> -undefined dynamic_lookup -single_module -multiply_defined suppress
> -L/usr/local/lib -o caret.so caret.o
> -F/Library/Frameworks/R.framework/.. -framework R -Wl,-framework
> -Wl,CoreFoundation
> installing to /Library/Frameworks/R.framework/Resources/library/caret/libs/i386
> *** arch - x86_64
> gcc -arch x86_64 -std=gnu99
> -I/Library/Frameworks/R.framework/Resources/include
> -I/Library/Frameworks/R.framework/Resources/include/x86_64
> -I/usr/local/include ? ?-fPIC ?-g -O2 -c caret.c -o caret.o
> gcc -arch x86_64 -std=gnu99 -dynamiclib
> -Wl,-headerpad_max_install_names -undefined dynamic_lookup
> -single_module -multiply_defined suppress -L/usr/local/lib -o caret.so
> caret.o -F/Library/Frameworks/R.framework/.. -framework R
> -Wl,-framework -Wl,CoreFoundation
> installing to /Library/Frameworks/R.framework/Resources/library/caret/libs/x86_64
> ** R
> ** data
> ** inst
> ** preparing package for lazy loading
> Loading required package: plyr
>
> Attaching package: 'reshape'
>
> The following object(s) are masked from 'package:plyr':
>
> ? ?round_any
>
> ** help
> *** installing help indices
> ** building package indices ...
> ** testing if installed package can be loaded
> Error : object 'confusionMatrix' not found whilst loading namespace 'caret'
> ERROR: loading failed
> * removing ?/Library/Frameworks/R.framework/Resources/library/caret?
> * restoring previous ?/Library/Frameworks/R.framework/Resources/library/caret?
>


From murdoch.duncan at gmail.com  Wed Mar 16 03:15:36 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 15 Mar 2011 22:15:36 -0400
Subject: [Rd] object not found whilst loading namespace
In-Reply-To: <AANLkTi=Ai_mZyfHcxgP-cnTecYmQQGGAzjxTaHW3v4y7@mail.gmail.com>
References: <AANLkTinPXqDcByoT3_pqjWcYnUqB50R-RrB-e_G2BSCB@mail.gmail.com>
	<AANLkTi=Ai_mZyfHcxgP-cnTecYmQQGGAzjxTaHW3v4y7@mail.gmail.com>
Message-ID: <4D801D48.4090400@gmail.com>

On 11-03-15 9:59 PM, Max Kuhn wrote:
> Please disregard the last email...
>
> The issue was a syntactical error in a file that, alphabetically,
> comes before confusionMatrix.R in the package.
>
> The odd thing was that the problem in this file did not throw and
> error (or I would have easily found it). I decided to source the R
> files one by one to see if there were any issues and that showed the
> problem:
>
>> source("~/Code/caret/pkg/caret/R/classLevels.R")
> Error in source("~/Code/caret/pkg/caret/R/classLevels.R") :
>    ~/Code/caret/pkg/caret/R/classLevels.R:150:0: unexpected end of input
>

The files are concatenated into one big file which is sourced.  You've 
got an unclosed parenthesis/brace/bracket in this file, but some later 
file closed it -- so that file probably has an extra closing one.

Duncan Murdoch

> Thanks anyway,
>
> Max
>
>
>
> On Tue, Mar 15, 2011 at 9:48 PM, Max Kuhn<mxkuhn at gmail.com>  wrote:
>> I've been updating a package and, when installing a local devel
>> version, I get an error "object 'confusionMatrix' not found whilst
>> loading namespace". Looking around online, it appears that this might
>> be related to loading a specific RData file, but it doesn't seem to be
>> the case AFAICT.
>>
>> I've installed the devel version in the last week without issues and
>> the confusionMatrix code has been touched in a while.
>>
>> Thanks,
>>
>> Max
>>
>>> sessionInfo()
>> R version 2.11.1 (2010-05-31)
>> x86_64-apple-darwin9.8.0
>>
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] caret_4.71     reshape_0.8.3  plyr_1.2.1     lattice_0.18-8
>>
>> loaded via a namespace (and not attached):
>> [1] grid_2.11.1
>>
>>
>> pkg_kuhna03$ R CMD INSTALL caret
>> * installing to library ?/Library/Frameworks/R.framework/Resources/library?
>> * installing *source* package ?caret? ...
>> ** libs
>> *** arch - i386
>> gcc -arch i386 -std=gnu99
>> -I/Library/Frameworks/R.framework/Resources/include
>> -I/Library/Frameworks/R.framework/Resources/include/i386
>> -I/usr/local/include    -fPIC  -g -O2 -c caret.c -o caret.o
>> gcc -arch i386 -std=gnu99 -dynamiclib -Wl,-headerpad_max_install_names
>> -undefined dynamic_lookup -single_module -multiply_defined suppress
>> -L/usr/local/lib -o caret.so caret.o
>> -F/Library/Frameworks/R.framework/.. -framework R -Wl,-framework
>> -Wl,CoreFoundation
>> installing to /Library/Frameworks/R.framework/Resources/library/caret/libs/i386
>> *** arch - x86_64
>> gcc -arch x86_64 -std=gnu99
>> -I/Library/Frameworks/R.framework/Resources/include
>> -I/Library/Frameworks/R.framework/Resources/include/x86_64
>> -I/usr/local/include    -fPIC  -g -O2 -c caret.c -o caret.o
>> gcc -arch x86_64 -std=gnu99 -dynamiclib
>> -Wl,-headerpad_max_install_names -undefined dynamic_lookup
>> -single_module -multiply_defined suppress -L/usr/local/lib -o caret.so
>> caret.o -F/Library/Frameworks/R.framework/.. -framework R
>> -Wl,-framework -Wl,CoreFoundation
>> installing to /Library/Frameworks/R.framework/Resources/library/caret/libs/x86_64
>> ** R
>> ** data
>> ** inst
>> ** preparing package for lazy loading
>> Loading required package: plyr
>>
>> Attaching package: 'reshape'
>>
>> The following object(s) are masked from 'package:plyr':
>>
>>     round_any
>>
>> ** help
>> *** installing help indices
>> ** building package indices ...
>> ** testing if installed package can be loaded
>> Error : object 'confusionMatrix' not found whilst loading namespace 'caret'
>> ERROR: loading failed
>> * removing ?/Library/Frameworks/R.framework/Resources/library/caret?
>> * restoring previous ?/Library/Frameworks/R.framework/Resources/library/caret?
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hb at biostat.ucsf.edu  Wed Mar 16 04:13:01 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Tue, 15 Mar 2011 20:13:01 -0700
Subject: [Rd] .libPaths() on Windows may return duplicated paths
Message-ID: <AANLkTikU88Pm+4td3_skO8mNVkX8dVdd+gV=HfnA71sS@mail.gmail.com>

In R v2.12.2 patched (2011-03-13 r54787) and also in R v2.13.0 devel
(2011-03-15 r54806), .libPaths() may return the multiple paths
referring to the same "normalized" path name.  Here is an example from
Rterm --vanilla using R v2.12.2 patched:

> paths <- .libPaths(c("C:/", "C:\\"))
> paths
[1] "C:/"
[2] "C:\\"
[3] "C:/PROGRA~1/R/R-2.13.0dev/library"

The reason is that .libPaths() does not detect paths[1] and paths[2]
to be "equal";

> .libPaths
function (new)
{
    if (!missing(new)) {
        new <- Sys.glob(path.expand(new))
        paths <- unique(path.expand(c(new, .Library.site, .Library)))
        .lib.loc <<- paths[file.info(paths)$isdir %in% TRUE]
    }
    else .lib.loc
}

One solution would be to replace:

  paths <- unique(path.expand(c(new, .Library.site, .Library)))

with

  paths <- path.expand(c(new, .Library.site, .Library))
  paths <- utils::normalizePath(paths)
  paths <- unique(paths)

This would obviously not work because this would make .libPaths()
depend on the utils package as standing.  Migrating normalizePath() to
the 'base' package would be one solution.


Finally, this causes update.packages() to try to download and install
the same package multiple times, e.g.

> .libPaths()
[1] "C:\\Users\\hb/R/win-library/2.12"
[2] "C:/PROGRA~1/R/R-2.12.2patched/library"
[3] "C:\\Users\\hb\\R\\win-library\\2.12"

> update.packages()
digest :
 Version 0.4.1 installed in C:\Users\hb/R/win-library/2.12
 Version 0.4.2 available at http://cran.stat.ucla.edu
Update (y/N/c)?  y
digest :
 Version 0.4.1 installed in C:\Users\hb\R\win-library\2.12
 Version 0.4.2 available at http://cran.stat.ucla.edu
Update (y/N/c)?  y
...

Obviously, I know how to fix/avoid this myself, but I figured it is
more generic if .libPaths() does it for everyone.

/Henrik


From andreas.borg at unimedizin-mainz.de  Wed Mar 16 09:06:52 2011
From: andreas.borg at unimedizin-mainz.de (Andreas Borg)
Date: Wed, 16 Mar 2011 09:06:52 +0100
Subject: [Rd] Feature request: txtProgressBar with ability to write to
 arbitrary stream
In-Reply-To: <4D7F7E4C.8070904@gmail.com>
References: <4D7F4161.2070909@unimedizin-mainz.de>
	<4D7F5F9A.4040707@Vanderbilt.edu> <4D7F7E4C.8070904@gmail.com>
Message-ID: <4D806F9C.30106@unimedizin-mainz.de>

Thanks for all the suggestions. However, I was not really looking for a 
solution but I want to propose this (in my view useful) change to be 
included in a future version of R. For the time being I will include a 
modified version in my package.

Best regards,

Andreas


-- 
Andreas Borg
Medizinische Informatik

UNIVERSIT?TSMEDIZIN
der Johannes Gutenberg-Universit?t
Institut f?r Medizinische Biometrie, Epidemiologie und Informatik
Obere Zahlbacher Stra?e 69, 55131 Mainz
www.imbei.uni-mainz.de

Telefon +49 (0) 6131 175062
E-Mail: borg at imbei.uni-mainz.de

Diese E-Mail enth?lt vertrauliche und/oder rechtlich gesch?tzte Informationen. Wenn Sie nicht der
richtige Adressat sind oder diese E-Mail irrt?mlich erhalten haben, informieren Sie bitte sofort den
Absender und l?schen Sie diese Mail. Das unerlaubte Kopieren sowie die unbefugte Weitergabe
dieser Mail und der darin enthaltenen Informationen ist nicht gestattet.


From H.C.Pumphrey at ed.ac.uk  Tue Mar 15 17:55:23 2011
From: H.C.Pumphrey at ed.ac.uk (H C Pumphrey)
Date: Tue, 15 Mar 2011 16:55:23 +0000
Subject: [Rd] Fixing the HDF5 package: the on.exit mystery
In-Reply-To: <4D70C05C.4040905@ed.ac.uk>
References: <4D70C05C.4040905@ed.ac.uk>
Message-ID: <4D7F99FB.4010304@ed.ac.uk>

H C Pumphrey wrote:

> I'm trying to fix a subtle bug in the hdf5 package. This package 
> provides an interfaces to the HDF5 library and hence allows one to load 
> data into R from files in the HDF5 format. The bug appeared during a 
> period in which R changed but the package did not. [details snipped]

I considered Prof. Ripley's suggestion to use finalizers but I'm not a good 
enough C programmer and rapidly became bogged down. For the moment I have 
fixed the bug in a more crude and obvious manner, by putting the relevant 
clean-up code at the end of both hdf5save() and hdf5load() and removing all 
references to the on.exit mechanism. This now means that if things work 
properly you can open and close as many HDF5 files as you like. (I imagine 
that the downside is that your file may be left open if some sorts of errors 
occur.  But I think this was probably happening anyway, given the fact that 
the on.exit mechanism wasn't working. )

I have also altered the code behind hdf5load() so that it ignores soft links 
inside a HDF5 file that don't have a target. Ideally your file should not 
contain such things. But if it does, then it is better to skirt round them 
than to fail whenever you meet one.

I will try uploading the package to CRAN at some point, but I think I'll use 
it myself for a bit to see whether it has any other nasties. If anyone wants 
to try it in the meantime you can get it at http://xweb.geos.ed.ac.uk/~hcp 
(scroll down to the bottom). I'd be particularly interested to know if it can 
be built on Windows/MacOS and, if not, why not.

Hugh

-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From stefan.theussl at wu.ac.at  Wed Mar 16 17:54:15 2011
From: stefan.theussl at wu.ac.at (Stefan Theussl)
Date: Wed, 16 Mar 2011 17:54:15 +0100
Subject: [Rd] R-Forge down
In-Reply-To: <AANLkTi=Hr6mF7K=xRQ83VV_0t17JnUPVo0ZYTDKsAK7g@mail.gmail.com>
References: <AANLkTi=Hr6mF7K=xRQ83VV_0t17JnUPVo0ZYTDKsAK7g@mail.gmail.com>
Message-ID: <4D80EB37.5070100@wu.ac.at>

On 03/16/2011 05:43 PM, Max Kuhn wrote:
> Web page and svn, but you probably already know this.
>    
Thanks a lot for the note. This is due to a network system failure at 
WU. From the intranet we cannot connect to services outside and vice 
versa. I hope the guys at IT services will fix this soon.
CRAN and r-project.org in general might also be affected. Interestingly, 
we can access every service hosted by WU from the intranet but obviously 
not from outside...

Best,
st
> Thanks for all the hard work,
>
> Max
>
>


From dtenenba at fhcrc.org  Wed Mar 16 21:35:25 2011
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Wed, 16 Mar 2011 13:35:25 -0700
Subject: [Rd] tools::checkRd() output different from R CMD check
Message-ID: <AANLkTinXN2jtHcA-Yf+Mwj7MKg_L9cjiVvMA8CS10VVP@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110316/f5358019/attachment.pl>

From smyth at wehi.EDU.AU  Wed Mar 16 23:29:30 2011
From: smyth at wehi.EDU.AU (Gordon K Smyth)
Date: Thu, 17 Mar 2011 09:29:30 +1100 (AUS Eastern Daylight Time)
Subject: [Rd] Standardized Pearson residuals (and score tests)
In-Reply-To: <mailman.27.1300273207.30527.r-devel@r-project.org>
References: <mailman.27.1300273207.30527.r-devel@r-project.org>
Message-ID: <Pine.WNT.4.64.1103170923580.4296@PC765.wehi.edu.au>

Hi Peter and others,

If it helps, I wrote a small function glm.scoretest() for the statmod 
package on CRAN to compute score tests from glm fits.  The score test for 
adding a covariate, or any set of covariates, can be extracted very neatly 
from the standard glm output, although you probably already know that.

Regards
Gordon

---------------------------------------------
Professor Gordon K Smyth,
NHMRC Senior Research Fellow,
Bioinformatics Division,
Walter and Eliza Hall Institute of Medical Research,
1G Royal Parade, Parkville, Vic 3052, Australia.
smyth at wehi.edu.au
http://www.wehi.edu.au
http://www.statsci.org/smyth

> Date: Tue, 15 Mar 2011 12:17:46 +0100
> From: peter dalgaard <pdalgd at gmail.com>
> To: Brett Presnell <presnell at stat.ufl.edu>
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] Standardized Pearson residuals
>
>
> On Mar 15, 2011, at 04:40 , Brett Presnell wrote:
>
>>>> Background: I'm currently teaching an undergrad/grad-service course 
>>>> from Agresti's "Introduction to Categorical Data Analysis (2nd edn)" 
>>>> and deviance residuals are not used in the text.  For now I'll just 
>>>> provide the students with a simple function to use, but I prefer to 
>>>> use R's native capabilities whenever possible.
>>>
>>> Incidentally, chisq.test will have a stdres component in 2.13.0 for 
>>> much the same reason.
>>
>> Thank you.  That's one more thing I won't have to provide code for 
>> anymore.  Coincidentally, Agresti mentioned this to me a week or two 
>> ago as something that he felt was missing, so that's at least two 
>> people who will be happy to see this added.
>>
>
> And of course, I was teaching a course based on Agresti & Franklin: 
> "Statistics, The Art and Science of Learning from Data", when I realized 
> that R was missing standardized residuals.
>
>
>> It would also be nice for teaching purposes if glm or summary.glm had a 
>> "pearsonchisq" component and a corresponding extractor function, but I 
>> can imagine that there might be arguments against it that haven't 
>> occured to me.  Plus, I doubt that anyone wants to touch glm unless 
>> it's to repair a bug. If I'm wrong about all that though, ...
>>
> Hmm, how would that work? If there was one, I'd worry that people would 
> start subtracting them which is usually not the right thing to do. I do 
> miss having a test on the residual deviance occasionally (even though it 
> is only sometimes meaningful), having to fit a saturated model 
> explicitly can be a bit silly. E.g. in this case (homogeneity of birth 
> rates):
>
>> anova(glm(births~month,poisson,data=bb), test="Chisq")
> ...
>      Df Deviance Resid. Df Resid. Dev P(>|Chi|)
> NULL                     11     225.98
> month 11   225.98         0       0.00 < 2.2e-16 ***
>> anova(glm(births~1,poisson,data=bb), test="Chisq")
> ...
>     Df Deviance Resid. Df Resid. Dev P(>|Chi|)
> NULL                    11     225.98
>
> Notice that the latter version gives me the correct deviance but no 
> p-value.
>
>
> A better support for generic score tests could be desirable too. I 
> suspect that this would actually be the Pearson Chi-square in the 
> interesting cases.
>
> -- 
> Peter Dalgaard
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

______________________________________________________________________
The information in this email is confidential and intend...{{dropped:4}}


From john.maindonald at anu.edu.au  Wed Mar 16 23:34:44 2011
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Thu, 17 Mar 2011 09:34:44 +1100
Subject: [Rd] Standardized Pearson residuals
In-Reply-To: <4DB19694-B58A-44BC-B779-CC086F223605@gmail.com>
References: <mailman.28.1300186808.4951.r-devel@r-project.org>
	<9E1DF5E9-0B03-441C-9157-B9A7A16A0F53@anu.edu.au>
	<4DB19694-B58A-44BC-B779-CC086F223605@gmail.com>
Message-ID: <325E2604-06E3-4C1A-9D2B-08A42A894025@anu.edu.au>

One can easily test for the binary case and not give the statistic in that case.

A general point is that if one gave no output that was not open to abuse,
there'd be nothing given at all!  One would not be giving any output at all
from poisson or binomial models, given that data that really calls for 
quasi links (or a glmm with observation level random effects) is in my
experience the rule rather than the exception!

At the very least, why not a function dispersion() or pearsonchisquare()
that gives this information.

Apologies that I misattributed this.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 16/03/2011, at 12:41 AM, peter dalgaard wrote:

> 
> On Mar 15, 2011, at 13:42 , John Maindonald wrote:
> 
>>> Peter Dalgaard: It would also be nice for teaching purposes if glm or summary.glm had a
>>> "pearsonchisq" component and a corresponding extractor function, but I
>>> can imagine that there might be arguments against it that haven't
>>> occured to me.  Plus, I doubt that anyone wants to touch glm unless it's
>>> to repair a bug. If I'm wrong about all that though, ...
>> 
> 
> Umm, that was Brett, actually.

>> This would remedy what I have long judged a deficiency in summary.glm().
>> The information is important for diagnostic purposes.  One should not have
>> to fit a model with a quasi error, or suss out how to calculate the Pearson
>> chi square from the glm model object, to discover that the information in the
>> model object is inconsistent with simple binomial or poisson assumptions.
> 
> It could be somewhere between useless and misleading in cases like binary logistic regression though. (Same thing goes for the test against the saturated model: Sometimes it makes sense and sometimes not.)
> 
>> 
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics & Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>> http://www.maths.anu.edu.au/~johnm
>> 
>> On 15/03/2011, at 10:00 PM, r-devel-request at r-project.org wrote:
>> 
>>> From: Brett Presnell <presnell at stat.ufl.edu>
>>> Date: 15 March 2011 2:40:29 PM AEDT
>>> To: peter dalgaard <pdalgd at gmail.com>
>>> Cc: r-devel at r-project.org
>>> Subject: Re: [Rd] Standardized Pearson residuals
>>> 
>>> 
>>> 
>>> Thanks Peter.  I have just a couple of minor comments, and another
>>> possible feature request, although it's one that I don't think will be
>>> implemented.
>>> 
>>> peter dalgaard <pdalgd at gmail.com> writes:
>>> 
>>>> On Mar 14, 2011, at 22:25 , Brett Presnell wrote:
>>>> 
>>>>> 
>>>>> Is there any reason that rstandard.glm doesn't have a "pearson" option?
>>>>> And if not, can it be added?
>>>> 
>>>> Probably... I have been wondering about that too. I'm even puzzled why
>>>> it isn't the default. Deviance residuals don't have quite the
>>>> properties that one might expect, e.g. in this situation, the absolute
>>>> residuals sum pairwise to zero, so you'd expect that the standardized
>>>> residuals be identical in absolute value
>>>> 
>>>>> y <- 1:4
>>>>> r <- c(0,0,1,1)
>>>>> c <- c(0,1,0,1)
>>>>> rstandard(glm(y~r+c,poisson))
>>>>       1          2          3          4 
>>>> -0.2901432  0.2767287  0.2784603 -0.2839995 
>>>> 
>>>> in comparison,
>>>> 
>>>>> i <- influence(glm(y~r+c,poisson))
>>>>> i$pear.res/sqrt(1-i$hat)
>>>>       1          2          3          4 
>>>> -0.2817181  0.2817181  0.2817181 -0.2817181 
>>>> 
>>>> The only thing is that I'm always wary of tampering with this stuff,
>>>> for fear of finding out the hard way why thing are the way they
>>>> are....
>>> 
>>> I'm sure that's wise, but it would be nice to get it in as an option,
>>> even if it's not the default
>>> 
>>>>> Background: I'm currently teaching an undergrad/grad-service course from
>>>>> Agresti's "Introduction to Categorical Data Analysis (2nd edn)" and
>>>>> deviance residuals are not used in the text.  For now I'll just provide
>>>>> the students with a simple function to use, but I prefer to use R's
>>>>> native capabilities whenever possible.
>>>> 
>>>> Incidentally, chisq.test will have a stdres component in 2.13.0 for
>>>> much the same reason.
>>> 
>>> Thank you.  That's one more thing I won't have to provide code for
>>> anymore.  Coincidentally, Agresti mentioned this to me a week or two ago
>>> as something that he felt was missing, so that's at least two people who
>>> will be happy to see this added.
>>> 
>>> It would also be nice for teaching purposes if glm or summary.glm had a
>>> "pearsonchisq" component and a corresponding extractor function, but I
>>> can imagine that there might be arguments against it that haven't
>>> occured to me.  Plus, I doubt that anyone wants to touch glm unless it's
>>> to repair a bug. If I'm wrong about all that though, ...
>>> 
>>> BTW, as I go along I'm trying to collect a lot of the datasets from the
>>> examples and exercises in the text into an R package ("icda").  It's far
>>> from complete and what is there needed tidying up, but I hope to
>>> eventually to round it into shape and put it on CRAN, assuming that
>>> Agresti approves and that there are no copyright issues.
>>> 
>>>>> I think something along the following lines should do it:
>>>>> 
>>>>> rstandard.glm <-
>>>>> function(model,
>>>>>        infl=influence(model, do.coef=FALSE),
>>>>>        type=c("deviance", "pearson"), ...)
>>>>> {
>>>>> type <- match.arg(type)
>>>>> res <- switch(type, pearson = infl$pear.res, infl$dev.res)
>>>>> res <- res/sqrt(1-infl$hat)
>>>>> res[is.infinite(res)] <- NaN
>>>>> res
>>>>> }
>>> 
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> -- 
> Peter Dalgaard
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 


From dtenenba at fhcrc.org  Thu Mar 17 00:55:55 2011
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Wed, 16 Mar 2011 16:55:55 -0700
Subject: [Rd] Feature request: display file name in R CMD check warning
Message-ID: <AANLkTi=D483mk=SVgM5w4bd9gazMA2XeFS_ufLNHOTyL@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110316/ef87981a/attachment.pl>

From c.ryan.king at gmail.com  Wed Mar 16 21:14:04 2011
From: c.ryan.king at gmail.com (Ryan King)
Date: Wed, 16 Mar 2011 15:14:04 -0500
Subject: [Rd] Detecting bad lexical scoping
Message-ID: <AANLkTimpAMDo383a2D85OBg4JOhkxzFpyThT4cvt1-7i@mail.gmail.com>

I've recently hunted down a troublesome bug in my own code, and am
looking for an easy mechanism to detect this kind of error in other R
code.  The problem was an undefined variable inside of a function.
Unfortunately, R looked for that variable in the global environment
and found it since there was variable with that name in my testing
scripts (note to self: do not name things "x").

Is there an easy way to report all the non-local objects accessed in a
function?

Is there any easy way around the usual scoping rules?  I want to be
able to get to base functions, and am willing to namespace:: or :::
access all of my own functions (it's in a package) if necessary to
block the standard scoping rules.  The language def section on
environments made me hurt.

Thanks,
C Ryan King
Dept Health Studies
University of Chicago


From murdoch.duncan at gmail.com  Thu Mar 17 10:08:54 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 17 Mar 2011 05:08:54 -0400
Subject: [Rd] Detecting bad lexical scoping
In-Reply-To: <AANLkTimpAMDo383a2D85OBg4JOhkxzFpyThT4cvt1-7i@mail.gmail.com>
References: <AANLkTimpAMDo383a2D85OBg4JOhkxzFpyThT4cvt1-7i@mail.gmail.com>
Message-ID: <4D81CFA6.9020608@gmail.com>

On 16/03/2011 4:14 PM, Ryan King wrote:
> I've recently hunted down a troublesome bug in my own code, and am
> looking for an easy mechanism to detect this kind of error in other R
> code.  The problem was an undefined variable inside of a function.
> Unfortunately, R looked for that variable in the global environment
> and found it since there was variable with that name in my testing
> scripts (note to self: do not name things "x").
>
> Is there an easy way to report all the non-local objects accessed in a
> function?

The problem is that all base functions are non-local objects, so you 
probably don't want to do exactly that, but the codetools package can do 
it (using tools::findGlobals) and also provides help in identifying 
errors.  You say you keep your code in a package (which is a good idea) 
so you should run "R CMD check" on the package.  If your code is not in 
a package, use tools::checkUsage or related functions.

>
> Is there any easy way around the usual scoping rules?  I want to be
> able to get to base functions, and am willing to namespace:: or :::
> access all of my own functions (it's in a package) if necessary to
> block the standard scoping rules.  The language def section on
> environments made me hurt.

Quoting Uwe Ligges, "No".

Duncan Murdoch


From murdoch.duncan at gmail.com  Thu Mar 17 10:15:16 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 17 Mar 2011 05:15:16 -0400
Subject: [Rd] Feature request: display file name in R CMD check warning
In-Reply-To: <AANLkTi=D483mk=SVgM5w4bd9gazMA2XeFS_ufLNHOTyL@mail.gmail.com>
References: <AANLkTi=D483mk=SVgM5w4bd9gazMA2XeFS_ufLNHOTyL@mail.gmail.com>
Message-ID: <4D81D124.4070907@gmail.com>

On 16/03/2011 7:55 PM, Dan Tenenbaum wrote:
> Hi,
>
> I came across the following warning in R CMD check (it only occurred on
> Windows):
>
> The \usage entries for S3 methods should use the \method markup and not
>> their full name.
>> See the chapter 'Writing R documentation files' in manual 'Writing R
>> Extensions'.
>
>
> The package I'm looking at is one that I did not write which has 34 .Rd
> files. This warning does not tell me which file to look in. It would be very
> helpful if it did. Same goes for other warnings/errors produced by R CMD
> check.
>
> I also tried to narrow it down with tools:checkRd() but as I mentioned
> earlier, this function does not produce the same output as R CMD check and
> the same thing happens in the case of the warning above. I ran checkRd() on
> all 34 .Rd files and did not see the warning above.
>
> I'd worry that people might give up and not try and find the source of
> warnings if it proves too difficult.
> Thanks for considering this idea...

That sounds like a good idea.  It would be easier to experiment with if 
you provided the offending file.  (Yes, the lack of a name makes it hard 
to find that file, but it's easier for you than for almost anyone else.)

Duncan Murdoch


From murdoch.duncan at gmail.com  Thu Mar 17 10:36:54 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 17 Mar 2011 05:36:54 -0400
Subject: [Rd] Feature request: display file name in R CMD check warning
In-Reply-To: <AANLkTi=D483mk=SVgM5w4bd9gazMA2XeFS_ufLNHOTyL@mail.gmail.com>
References: <AANLkTi=D483mk=SVgM5w4bd9gazMA2XeFS_ufLNHOTyL@mail.gmail.com>
Message-ID: <4D81D636.2060209@gmail.com>

On 16/03/2011 7:55 PM, Dan Tenenbaum wrote:
> Hi,
>
> I came across the following warning in R CMD check (it only occurred on
> Windows):
>
> The \usage entries for S3 methods should use the \method markup and not
>> their full name.
>> See the chapter 'Writing R documentation files' in manual 'Writing R
>> Extensions'.
>
>
> The package I'm looking at is one that I did not write which has 34 .Rd
> files. This warning does not tell me which file to look in. It would be very
> helpful if it did. Same goes for other warnings/errors produced by R CMD
> check.

I was unable to duplicate this.  When I tried it by messing up one of 
the man pages in the ellipse package, I got this:

S3 methods shown with full name in documentation object 'ellipse.glm':
   ellipse.glm

The \usage entries for S3 methods should use the \method markup and not
their full name.
See the chapter 'Writing R documentation files' in manual 'Writing R
Extensions'.

"Documentation object 'ellipse.glm'" tells me the \name{} inside the .Rd 
file, which is enough to uniquely identify the file.  Are you not seeing 
this part of the message?

Duncan Murdoch


From ggrothendieck at gmail.com  Thu Mar 17 13:47:46 2011
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 17 Mar 2011 08:47:46 -0400
Subject: [Rd] Detecting bad lexical scoping
In-Reply-To: <AANLkTimpAMDo383a2D85OBg4JOhkxzFpyThT4cvt1-7i@mail.gmail.com>
References: <AANLkTimpAMDo383a2D85OBg4JOhkxzFpyThT4cvt1-7i@mail.gmail.com>
Message-ID: <AANLkTikTdA-ARMcetLivgetF9Gmqdq+fZbFr7igKmus4@mail.gmail.com>

On Wed, Mar 16, 2011 at 4:14 PM, Ryan King <c.ryan.king at gmail.com> wrote:
> I've recently hunted down a troublesome bug in my own code, and am
> looking for an easy mechanism to detect this kind of error in other R
> code. ?The problem was an undefined variable inside of a function.
> Unfortunately, R looked for that variable in the global environment
> and found it since there was variable with that name in my testing
> scripts (note to self: do not name things "x").
>
> Is there an easy way to report all the non-local objects accessed in a
> function?
>
> Is there any easy way around the usual scoping rules? ?I want to be
> able to get to base functions, and am willing to namespace:: or :::
> access all of my own functions (it's in a package) if necessary to
> block the standard scoping rules. ?The language def section on
> environments made me hurt.
>

One way is discussed in the Feb 27, 2010 news item on the proto home
page: http://r-proto.googlecode.com

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From pdalgd at gmail.com  Thu Mar 17 13:58:41 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 17 Mar 2011 13:58:41 +0100
Subject: [Rd] Standardized Pearson residuals (and score tests)
In-Reply-To: <Pine.WNT.4.64.1103170923580.4296@PC765.wehi.edu.au>
References: <mailman.27.1300273207.30527.r-devel@r-project.org>
	<Pine.WNT.4.64.1103170923580.4296@PC765.wehi.edu.au>
Message-ID: <1ED94EBF-B9D3-4763-AB82-17B540ED2FF1@gmail.com>


On Mar 16, 2011, at 23:29 , Gordon K Smyth wrote:

> Hi Peter and others,
> 
> If it helps, I wrote a small function glm.scoretest() for the statmod package on CRAN to compute score tests from glm fits.  The score test for adding a covariate, or any set of covariates, can be extracted very neatly from the standard glm output, although you probably already know that.

Thanks Gordon,

I'll have a look. It's the kind of think where you _strongly suspect_ that a neat solution exists, but where you can't just write it down immediately. Looks like your code needs some elaboration to handle factor terms and more general model reductions, though.

-pd

> 
> Regards
> Gordon
> 
> ---------------------------------------------
> Professor Gordon K Smyth,
> NHMRC Senior Research Fellow,
> Bioinformatics Division,
> Walter and Eliza Hall Institute of Medical Research,
> 1G Royal Parade, Parkville, Vic 3052, Australia.
> smyth at wehi.edu.au
> http://www.wehi.edu.au
> http://www.statsci.org/smyth
> 
>> Date: Tue, 15 Mar 2011 12:17:46 +0100
>> From: peter dalgaard <pdalgd at gmail.com>
>> To: Brett Presnell <presnell at stat.ufl.edu>
>> Cc: r-devel at r-project.org
>> Subject: Re: [Rd] Standardized Pearson residuals
>> 
>> 
>> On Mar 15, 2011, at 04:40 , Brett Presnell wrote:
>> 
>>>>> Background: I'm currently teaching an undergrad/grad-service course from Agresti's "Introduction to Categorical Data Analysis (2nd edn)" and deviance residuals are not used in the text.  For now I'll just provide the students with a simple function to use, but I prefer to use R's native capabilities whenever possible.
>>>> 
>>>> Incidentally, chisq.test will have a stdres component in 2.13.0 for much the same reason.
>>> 
>>> Thank you.  That's one more thing I won't have to provide code for anymore.  Coincidentally, Agresti mentioned this to me a week or two ago as something that he felt was missing, so that's at least two people who will be happy to see this added.
>>> 
>> 
>> And of course, I was teaching a course based on Agresti & Franklin: "Statistics, The Art and Science of Learning from Data", when I realized that R was missing standardized residuals.
>> 
>> 
>>> It would also be nice for teaching purposes if glm or summary.glm had a "pearsonchisq" component and a corresponding extractor function, but I can imagine that there might be arguments against it that haven't occured to me.  Plus, I doubt that anyone wants to touch glm unless it's to repair a bug. If I'm wrong about all that though, ...
>>> 
>> Hmm, how would that work? If there was one, I'd worry that people would start subtracting them which is usually not the right thing to do. I do miss having a test on the residual deviance occasionally (even though it is only sometimes meaningful), having to fit a saturated model explicitly can be a bit silly. E.g. in this case (homogeneity of birth rates):
>> 
>>> anova(glm(births~month,poisson,data=bb), test="Chisq")
>> ...
>>     Df Deviance Resid. Df Resid. Dev P(>|Chi|)
>> NULL                     11     225.98
>> month 11   225.98         0       0.00 < 2.2e-16 ***
>>> anova(glm(births~1,poisson,data=bb), test="Chisq")
>> ...
>>    Df Deviance Resid. Df Resid. Dev P(>|Chi|)
>> NULL                    11     225.98
>> 
>> Notice that the latter version gives me the correct deviance but no p-value.
>> 
>> 
>> A better support for generic score tests could be desirable too. I suspect that this would actually be the Pearson Chi-square in the interesting cases.
>> 
>> -- 
>> Peter Dalgaard
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> ______________________________________________________________________
> The information in this email is confidential and intended solely for the addressee.
> You must not disclose, forward, print or use it without the permission of the sender.
> ______________________________________________________________________

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From peter.ruckdeschel at itwm.fraunhofer.de  Thu Mar 17 15:26:57 2011
From: peter.ruckdeschel at itwm.fraunhofer.de (Dr. Peter Ruckdeschel)
Date: Thu, 17 Mar 2011 15:26:57 +0100
Subject: [Rd] New feature for download.packages(): optional resolution of
 package dependencies
Message-ID: <4D821A31.30500@itwm.fraunhofer.de>

Hi r-devels,

may I ask for an enhancement for download.packages()
to optionally resolve package dependencies similarly to
the respective functionality in install.packages() ?

This would be a major help in compiling a large number of
packages (e.g. by means of download.view() from pkg ctv)
for later offline installations.

Last November, I addressed Duncan Murdoch offline in this
issue, and Duncan then seconded me---so the idea might not
be this silly. He was pointing me to available.packages() which
already provides a dependency list, which though would have
to be parsed.

AFAICS in the svn, as of rev54842, he has not found the time
for looking deeper into this so far. Surely, like most of
you, he has had more urgent issues to work on,  but maybe
someone (else) of you has an idea for an easy but still
sustainable solution.

Any suggestions appreciated.

Cheers,
Peter


From pdalgd at gmail.com  Thu Mar 17 15:45:01 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 17 Mar 2011 15:45:01 +0100
Subject: [Rd] Standardized Pearson residuals
In-Reply-To: <325E2604-06E3-4C1A-9D2B-08A42A894025@anu.edu.au>
References: <mailman.28.1300186808.4951.r-devel@r-project.org>
	<9E1DF5E9-0B03-441C-9157-B9A7A16A0F53@anu.edu.au>
	<4DB19694-B58A-44BC-B779-CC086F223605@gmail.com>
	<325E2604-06E3-4C1A-9D2B-08A42A894025@anu.edu.au>
Message-ID: <C1D939A1-DBE7-4196-AC50-972B9E0B9B07@gmail.com>


On Mar 16, 2011, at 23:34 , John Maindonald wrote:

> One can easily test for the binary case and not give the statistic in that case.

Warning if expected cell counts < 5 would be another possibility. 

> 
> A general point is that if one gave no output that was not open to abuse,
> there'd be nothing given at all!  One would not be giving any output at all
> from poisson or binomial models, given that data that really calls for 
> quasi links (or a glmm with observation level random effects) is in my
> experience the rule rather than the exception!

Hmmm. Not sure I agree on that entirely, but that's a different discussion.


> At the very least, why not a function dispersion() or pearsonchisquare()
> that gives this information.

Lots of options here.... Offhand, my preference would go to something like
anova(..., test="score") and/or an extra line in summary(). It's not a computationally intensive item as far as I can see, it's more about "output real estate" -- how "SAS-like" do we want to become?

> Apologies that I misattributed this.

Never mind...

Back to the original question: 

The current rstandard() code reads

## FIXME ! -- make sure we are following "the literature":
rstandard.glm <- function(model, infl = lm.influence(model, do.coef=FALSE), ...)
{
    res <- infl$wt.res # = "dev.res"  really
    res <- res / sqrt(summary(model)$dispersion * (1 - infl$hat))
    res[is.infinite(res)] <- NaN
    res
}

which is "svn blame" to ripley but that is due to the 2003 code reorganization (except for the infinity check from 2005). So apparently, we have had that FIXME since forever... and finding its author appears to be awkward (Maechler, perhaps?).

I did try Bretts code in lieu of the above (with a mod to handle $dispersion) and even switched the default to use the Pearson residuals. Make check-devel sailed straight through apart from the obvious code/doc mismatch, so we don't have any checks in place nor any examples using rstandard(). I rather strongly suspect that there aren't many user codes using it either.

It is quite tempting simply to commit the change (after updating the docs). One thing holding me back though: I don't know what "the literature" refers to.


-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From maechler at stat.math.ethz.ch  Thu Mar 17 16:14:09 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 17 Mar 2011 16:14:09 +0100
Subject: [Rd] Standardized Pearson residuals
In-Reply-To: <C1D939A1-DBE7-4196-AC50-972B9E0B9B07@gmail.com>
References: <mailman.28.1300186808.4951.r-devel@r-project.org>
	<9E1DF5E9-0B03-441C-9157-B9A7A16A0F53@anu.edu.au>
	<4DB19694-B58A-44BC-B779-CC086F223605@gmail.com>
	<325E2604-06E3-4C1A-9D2B-08A42A894025@anu.edu.au>
	<C1D939A1-DBE7-4196-AC50-972B9E0B9B07@gmail.com>
Message-ID: <19842.9537.824806.962418@stat.math.ethz.ch>

>>>>> peter dalgaard <pdalgd at gmail.com>
>>>>>     on Thu, 17 Mar 2011 15:45:01 +0100 writes:

    > On Mar 16, 2011, at 23:34 , John Maindonald wrote:

    >> One can easily test for the binary case and not give the
    >> statistic in that case.

    > Warning if expected cell counts < 5 would be another
    > possibility.

    >> 
    >> A general point is that if one gave no output that was not open
    >> to abuse, there'd be nothing given at all!  One would not be
    >> giving any output at all from poisson or binomial models, given
    >> that data that really calls for quasi links (or a glmm with
    >> observation level random effects) is in my experience the rule
    >> rather than the exception!

    > Hmmm. Not sure I agree on that entirely, but that's a different
    > discussion.


    >> At the very least, why not a function dispersion() or
    >> pearsonchisquare() that gives this information.

    > Lots of options here.... Offhand, my preference would go to
    > something like anova(..., test="score") and/or an extra line in
    > summary(). It's not a computationally intensive item as far as I
    > can see, it's more about "output real estate" -- how "SAS-like"
    > do we want to become?

    >> Apologies that I misattributed this.

    > Never mind...

    > Back to the original question:

    > The current rstandard() code reads

## FIXME ! -- make sure we are following "the literature":
rstandard.glm <- function(model, infl = lm.influence(model, do.coef=FALSE), ...)
{
    res <- infl$wt.res # = "dev.res"  really
    res <- res / sqrt(summary(model)$dispersion * (1 - infl$hat))
    res[is.infinite(res)] <- NaN
    res
}

    > which is "svn blame" to ripley but that is due to the 2003
    > code reorganization (except for the infinity check from
    > 2005). So apparently, we have had that FIXME since
    > forever... and finding its author appears to be awkward
    > (Maechler, perhaps?).

yes, almost surely

    > I did try Bretts code in lieu of the above (with a mod to
    > handle $dispersion) and even switched the default to use
    > the Pearson residuals. Make check-devel sailed straight
    > through apart from the obvious code/doc mismatch, so we
    > don't have any checks in place nor any examples using
    > rstandard(). I rather strongly suspect that there aren't
    > many user codes using it either.

    > It is quite tempting simply to commit the change (after
    > updating the docs). One thing holding me back though: I
    > don't know what "the literature" refers to.

well, "the relevant publications on the topic" ...
and now define that (e.g. using the three 'References' on the
help page).
Really, that's what I think I meant when I (think I) wrote that FIXME.
The point then I think was that we had code "donations", and they
partly were clearly providing functionality that was (tested)
"correct" (according to e.g. McCoullagh & Nelder and probably
another one or two text books I would have consulted ... no
large Wikipedia back then), 
but also provided things for which there was nothing in "the
literature", but as the author provided them with other good
code, we would have put it in, as well....
== my vague recollection from the past

Martin

    > -- 
    > Peter Dalgaard Center for Statistics, Copenhagen Business
    > School Solbjerg Plads 3, 2000 Frederiksberg, Denmark
    > Phone: (+45)38153501 Email: pd.mes at cbs.dk Priv:
    > PDalgd at gmail.com

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From simon.urbanek at r-project.org  Thu Mar 17 17:09:53 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 17 Mar 2011 12:09:53 -0400
Subject: [Rd] New feature for download.packages(): optional resolution
	of package dependencies
In-Reply-To: <4D821A31.30500@itwm.fraunhofer.de>
References: <4D821A31.30500@itwm.fraunhofer.de>
Message-ID: <C4AB7D9F-BF0A-468A-963F-59CFF36AF1CD@r-project.org>


On Mar 17, 2011, at 10:26 AM, Dr. Peter Ruckdeschel wrote:

> Hi r-devels,
> 
> may I ask for an enhancement for download.packages()
> to optionally resolve package dependencies similarly to
> the respective functionality in install.packages() ?
> 
> This would be a major help in compiling a large number of
> packages (e.g. by means of download.view() from pkg ctv)
> for later offline installations.
> 
> Last November, I addressed Duncan Murdoch offline in this
> issue, and Duncan then seconded me---so the idea might not
> be this silly. He was pointing me to available.packages() which
> already provides a dependency list, which though would have
> to be parsed.
> 

But you don't have to do it yourself - the code is already there, try

utils:::getDependencies("foo",,available.packages())

That said, just adding something along the lines of

if (!missing(dependencies)) pkg <- getDependencies(pkg, dependencies, available)

might be simple enough and do the trick ...

Cheers,
Simon


> AFAICS in the svn, as of rev54842, he has not found the time
> for looking deeper into this so far. Surely, like most of
> you, he has had more urgent issues to work on,  but maybe
> someone (else) of you has an idea for an easy but still
> sustainable solution.
> 
> Any suggestions appreciated.
> 
> Cheers,
> Peter
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From dtenenba at fhcrc.org  Thu Mar 17 17:33:42 2011
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Thu, 17 Mar 2011 09:33:42 -0700
Subject: [Rd] Feature request: display file name in R CMD check warning
In-Reply-To: <4D81D636.2060209@gmail.com>
References: <AANLkTi=D483mk=SVgM5w4bd9gazMA2XeFS_ufLNHOTyL@mail.gmail.com>
	<4D81D636.2060209@gmail.com>
Message-ID: <AANLkTinuKBHZJoH5MKwqy91qoxKth3AK=T+ZxNkYuena@mail.gmail.com>

On Thu, Mar 17, 2011 at 2:36 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 16/03/2011 7:55 PM, Dan Tenenbaum wrote:
>>
>> Hi,
>>
>> I came across the following warning in R CMD check (it only occurred on
>> Windows):
>>
>> The \usage entries for S3 methods should use the \method markup and not
>>>
>>> their full name.
>>> See the chapter 'Writing R documentation files' in manual 'Writing R
>>> Extensions'.
>>
>>
>> The package I'm looking at is one that I did not write which has 34 .Rd
>> files. This warning does not tell me which file to look in. It would be
>> very
>> helpful if it did. Same goes for other warnings/errors produced by R CMD
>> check.
>
> I was unable to duplicate this. ?When I tried it by messing up one of the
> man pages in the ellipse package, I got this:
>
> S3 methods shown with full name in documentation object 'ellipse.glm':
> ?ellipse.glm
>
> The \usage entries for S3 methods should use the \method markup and not
> their full name.
> See the chapter 'Writing R documentation files' in manual 'Writing R
> Extensions'.
>
> "Documentation object 'ellipse.glm'" tells me the \name{} inside the .Rd
> file, which is enough to uniquely identify the file. ?Are you not seeing
> this part of the message?
>


No, I'm not.

I still can't identify the offending file, but you can download the
whole package:

svn --username readonly --password readonly export
https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/affyILM/

Then run R CMD check on this package. You may need to install dependencies.

Thanks
Dan


> Duncan Murdoch
>


From dtenenba at fhcrc.org  Thu Mar 17 17:35:23 2011
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Thu, 17 Mar 2011 09:35:23 -0700
Subject: [Rd] Feature request: display file name in R CMD check warning
In-Reply-To: <AANLkTinuKBHZJoH5MKwqy91qoxKth3AK=T+ZxNkYuena@mail.gmail.com>
References: <AANLkTi=D483mk=SVgM5w4bd9gazMA2XeFS_ufLNHOTyL@mail.gmail.com>
	<4D81D636.2060209@gmail.com>
	<AANLkTinuKBHZJoH5MKwqy91qoxKth3AK=T+ZxNkYuena@mail.gmail.com>
Message-ID: <AANLkTi=nRmV58+tjH5XNtEruGP5=s2dxnGWpDUnzpZob@mail.gmail.com>

On Thu, Mar 17, 2011 at 9:33 AM, Dan Tenenbaum <dtenenba at fhcrc.org> wrote:
> On Thu, Mar 17, 2011 at 2:36 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> On 16/03/2011 7:55 PM, Dan Tenenbaum wrote:
>>>
>>> Hi,
>>>
>>> I came across the following warning in R CMD check (it only occurred on
>>> Windows):
>>>
>>> The \usage entries for S3 methods should use the \method markup and not
>>>>
>>>> their full name.
>>>> See the chapter 'Writing R documentation files' in manual 'Writing R
>>>> Extensions'.
>>>
>>>
>>> The package I'm looking at is one that I did not write which has 34 .Rd
>>> files. This warning does not tell me which file to look in. It would be
>>> very
>>> helpful if it did. Same goes for other warnings/errors produced by R CMD
>>> check.
>>
>> I was unable to duplicate this. ?When I tried it by messing up one of the
>> man pages in the ellipse package, I got this:
>>
>> S3 methods shown with full name in documentation object 'ellipse.glm':
>> ?ellipse.glm
>>
>> The \usage entries for S3 methods should use the \method markup and not
>> their full name.
>> See the chapter 'Writing R documentation files' in manual 'Writing R
>> Extensions'.
>>
>> "Documentation object 'ellipse.glm'" tells me the \name{} inside the .Rd
>> file, which is enough to uniquely identify the file. ?Are you not seeing
>> this part of the message?
>>
>
>
> No, I'm not.
>
> I still can't identify the offending file, but you can download the
> whole package:
>
> svn --username readonly --password readonly export
> https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/affyILM/
>
> Then run R CMD check on this package. You may need to install dependencies.
>

Oops, sorry, this is the wrong package.
The one that produces this warning is:

svn --username readonly --password readonly export
https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/bgafun

This warning only occurs under windows.

Dan


> Thanks
> Dan
>
>
>> Duncan Murdoch
>>
>


From pdalgd at gmail.com  Thu Mar 17 18:08:18 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 17 Mar 2011 18:08:18 +0100
Subject: [Rd] Standardized Pearson residuals
In-Reply-To: <19842.9537.824806.962418@stat.math.ethz.ch>
References: <mailman.28.1300186808.4951.r-devel@r-project.org>
	<9E1DF5E9-0B03-441C-9157-B9A7A16A0F53@anu.edu.au>
	<4DB19694-B58A-44BC-B779-CC086F223605@gmail.com>
	<325E2604-06E3-4C1A-9D2B-08A42A894025@anu.edu.au>
	<C1D939A1-DBE7-4196-AC50-972B9E0B9B07@gmail.com>
	<19842.9537.824806.962418@stat.math.ethz.ch>
Message-ID: <6C41520B-D086-45C1-969D-7B79BAFC0D8B@gmail.com>


On Mar 17, 2011, at 16:14 , Martin Maechler wrote:

>>>>>> peter dalgaard <pdalgd at gmail.com>
>>>>>>    on Thu, 17 Mar 2011 15:45:01 +0100 writes:
>> 
> 
>> Back to the original question:
> 
>> The current rstandard() code reads
> 
> ## FIXME ! -- make sure we are following "the literature":
> rstandard.glm <- function(model, infl = lm.influence(model, do.coef=FALSE), ...)
> {
>    res <- infl$wt.res # = "dev.res"  really
>    res <- res / sqrt(summary(model)$dispersion * (1 - infl$hat))
>    res[is.infinite(res)] <- NaN
>    res
> }
> 
>> which is "svn blame" to ripley but that is due to the 2003
>> code reorganization (except for the infinity check from
>> 2005). So apparently, we have had that FIXME since
>> forever... and finding its author appears to be awkward
>> (Maechler, perhaps?).
> 
> yes, almost surely
> 
>> I did try Bretts code in lieu of the above (with a mod to
>> handle $dispersion) and even switched the default to use
>> the Pearson residuals. Make check-devel sailed straight
>> through apart from the obvious code/doc mismatch, so we
>> don't have any checks in place nor any examples using
>> rstandard(). I rather strongly suspect that there aren't
>> many user codes using it either.
> 
>> It is quite tempting simply to commit the change (after
>> updating the docs). One thing holding me back though: I
>> don't know what "the literature" refers to.
> 
> well, "the relevant publications on the topic" ...
> and now define that (e.g. using the three 'References' on the
> help page).

I count 5 actually... IIRC, the first two do not deal with glm diagnostics. The last two are by Fox, and, presumably, he is around to chime in if he wants. The middle one, by Williams, does define both standardized Pearson and standardized deviance residuals.

Or did you mean the three on ?glm.summaries? I would assume Davison and Snell to be the operative one, but I don't have it to hand.

Anyways, given that de default for residuals.glm is deviance residuals, I suppose that rstandard.glm should have the same default for consistency, and that is also the least disruptive variant. I see no reason not to make standardized Pearson residuals an option. 

> Really, that's what I think I meant when I (think I) wrote that FIXME.
> The point then I think was that we had code "donations", and they
> partly were clearly providing functionality that was (tested)
> "correct" (according to e.g. McCoullagh & Nelder and probably
> another one or two text books I would have consulted ... no
> large Wikipedia back then), 
> but also provided things for which there was nothing in "the
> literature", but as the author provided them with other good
> code, we would have put it in, as well....
> == my vague recollection from the past
> 
> Martin
> 
>> -- 
>> Peter Dalgaard Center for Statistics, Copenhagen Business
>> School Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501 Email: pd.mes at cbs.dk Priv:
>> PDalgd at gmail.com
> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jfox at mcmaster.ca  Thu Mar 17 20:22:08 2011
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 17 Mar 2011 15:22:08 -0400
Subject: [Rd] Standardized Pearson residuals
In-Reply-To: <6C41520B-D086-45C1-969D-7B79BAFC0D8B@gmail.com>
References: <mailman.28.1300186808.4951.r-devel@r-project.org>
	<9E1DF5E9-0B03-441C-9157-B9A7A16A0F53@anu.edu.au>
	<4DB19694-B58A-44BC-B779-CC086F223605@gmail.com>
	<325E2604-06E3-4C1A-9D2B-08A42A894025@anu.edu.au>
	<C1D939A1-DBE7-4196-AC50-972B9E0B9B07@gmail.com>
	<19842.9537.824806.962418@stat.math.ethz.ch>
	<6C41520B-D086-45C1-969D-7B79BAFC0D8B@gmail.com>
Message-ID: <web-346770472@cgpsrv2.cis.mcmaster.ca>

Dear Peter and Martin,

On Thu, 17 Mar 2011 18:08:18 +0100
 peter dalgaard <pdalgd at gmail.com> wrote:
> 
> On Mar 17, 2011, at 16:14 , Martin Maechler wrote:
> 
> >>>>>> peter dalgaard <pdalgd at gmail.com>
> >>>>>>    on Thu, 17 Mar 2011 15:45:01 +0100 writes:
> >> 
> > 
> >> Back to the original question:
> > 
> >> The current rstandard() code reads
> > 
> > ## FIXME ! -- make sure we are following "the literature":
> > rstandard.glm <- function(model, infl = lm.influence(model, do.coef=FALSE), ...)
> > {
> >    res <- infl$wt.res # = "dev.res"  really
> >    res <- res / sqrt(summary(model)$dispersion * (1 - infl$hat))
> >    res[is.infinite(res)] <- NaN
> >    res
> > }
> > 
> >> which is "svn blame" to ripley but that is due to the 2003
> >> code reorganization (except for the infinity check from
> >> 2005). So apparently, we have had that FIXME since
> >> forever... and finding its author appears to be awkward
> >> (Maechler, perhaps?).
> > 
> > yes, almost surely
> > 
> >> I did try Bretts code in lieu of the above (with a mod to
> >> handle $dispersion) and even switched the default to use
> >> the Pearson residuals. Make check-devel sailed straight
> >> through apart from the obvious code/doc mismatch, so we
> >> don't have any checks in place nor any examples using
> >> rstandard(). I rather strongly suspect that there aren't
> >> many user codes using it either.
> > 
> >> It is quite tempting simply to commit the change (after
> >> updating the docs). One thing holding me back though: I
> >> don't know what "the literature" refers to.
> > 
> > well, "the relevant publications on the topic" ...
> > and now define that (e.g. using the three 'References' on the
> > help page).
> 
> I count 5 actually... IIRC, the first two do not deal with glm diagnostics. The last two are by Fox, and, presumably, he is around to chime in if he wants. The middle one, by Williams, does define both standardized Pearson and standardized deviance residuals.

Though I don't have it in front of me, I recall that my Applied Regression text follows Williams and defines both standardized deviance and standardized Pearson residuals. As well, there are new editions of both these sources: 

Fox, J. (2008) Applied Regression Analysis and Generalized Linear Models, Second Edition (Sage)

Fox, J. and S. Weisberg (2011) An R Companion to Applied Regression, Second Edition (Sage)

I'd take Williams as the definitive reference. I'll send a follow-up message if my memory proves faulty.

Best,
 John

> 
> Or did you mean the three on ?glm.summaries? I would assume Davison and Snell to be the operative one, but I don't have it to hand.
>  
> Anyways, given that de default for residuals.glm is deviance residuals, I suppose that rstandard.glm should have the same default for consistency, and that is also the least disruptive variant. I see no reason not to make standardized Pearson residuals an option. 
> 
> > Really, that's what I think I meant when I (think I) wrote that FIXME.
> > The point then I think was that we had code "donations", and they
> > partly were clearly providing functionality that was (tested)
> > "correct" (according to e.g. McCoullagh & Nelder and probably
> > another one or two text books I would have consulted ... no
> > large Wikipedia back then), 
> > but also provided things for which there was nothing in "the
> > literature", but as the author provided them with other good
> > code, we would have put it in, as well....
> > == my vague recollection from the past
> > 
> > Martin
> > 
> >> -- 
> >> Peter Dalgaard Center for Statistics, Copenhagen Business
> >> School Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> >> Phone: (+45)38153501 Email: pd.mes at cbs.dk Priv:
> >> PDalgd at gmail.com
> > 
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> -- 
> Peter Dalgaard
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

------------------------------------------------
John Fox
Sen. William McMaster Prof. of Social Statistics
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/


From presnell at stat.ufl.edu  Thu Mar 17 20:46:41 2011
From: presnell at stat.ufl.edu (Brett Presnell)
Date: Thu, 17 Mar 2011 15:46:41 -0400
Subject: [Rd] Standardized Pearson residuals
In-Reply-To: <325E2604-06E3-4C1A-9D2B-08A42A894025@anu.edu.au> (John
	Maindonald's message of "Thu, 17 Mar 2011 09:34:44 +1100")
References: <325E2604-06E3-4C1A-9D2B-08A42A894025@anu.edu.au>
Message-ID: <87hbb1fs2m.fsf@stat.ufl.edu>


John Maindonald <john.maindonald at anu.edu.au> writes:

> One can easily test for the binary case and not give the statistic in
> that case.
>
> A general point is that if one gave no output that was not open to
> abuse, there'd be nothing given at all!

Thanks John.  I've been reluctant to push too hard for this on r-devel,
but this is more or less the point I made to Peter in a private email.
My example was the deviance, which is just as open to abuse as Pearson's
chi-square (except that differences of deviances for nested,
non-saturated models are usually ok), but which print.glm() and
summary.glm() proudly display at every opportunity.  If we were overly
concerned about preventing abuse, we might just provide the
(log-)likelihood so that users would at least have to take some
(trivial) action to compute the "dangerous" deviance statistic.

Obviously the question is one of balancing utility against the
likelihood of abuse, and apparently you and I would agree that the
utility of having Pearson's chi-square available as a matter of course
outweighs the dangers.  I don't think it would be too difficult to get
Peter to agree, but I suspect that there would likely be a strong
general reluctance to change glm() and/or summary.glm().  This could be
avoided by just providing a convenience function, as you suggest,
without necessarily changing any existing function.  This would put
Pearson's chi-square on a more nearly equal R-footing with the deviance
as a goodness-of-fit statistic, which I don't think anyone would argue
with, while still leaving the user with a bit to do to get a p-value,
say.

One of Peter's other posts suggests, perhaps unintentionally, a
functionality that would actually return the results of a
goodness-of-fit test, though possibly using only the deviance.  This
might indeed be useful, but I would still like to have an easy,
standardized way to just get Pearson's chi-square statistic.  Assuming a
situation in which either is appropriate, I tend to prefer Pearson's
chi-square over the deviance for testing goodness-of-fit, because I
think that in marginal cases its null distribution is usually better
approximated by the chi-square (if you think I'm wrong about this,
please let me know).  Pearson's chi-square also has the advantage of
being much easier to explain as a goodness-of-fit statistic than the
deviance, leaving everything else about the deviance to the realm of
likelihood-ratio tests, where it mostly belongs.  My original feature
request was, after all, mostly about having a simple, standardized way
in R for "naive users" (my students) to do some fairly standard things.


> One would not be giving any output at all from poisson or binomial
> models, given that data that really calls for quasi links (or a glmm
> with observation level random effects) is in my experience the rule
> rather than the exception!
>
> At the very least, why not a function dispersion() or pearsonchisquare()
> that gives this information.
>
> Apologies that I misattributed this.
>
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
>
> On 16/03/2011, at 12:41 AM, peter dalgaard wrote:
>
>> 
>> On Mar 15, 2011, at 13:42 , John Maindonald wrote:
>> 
>>>> Peter Dalgaard: It would also be nice for teaching purposes if glm or summary.glm had a
>>>> "pearsonchisq" component and a corresponding extractor function, but I
>>>> can imagine that there might be arguments against it that haven't
>>>> occured to me.  Plus, I doubt that anyone wants to touch glm unless it's
>>>> to repair a bug. If I'm wrong about all that though, ...
>>> 
>> 
>> Umm, that was Brett, actually.
>
>>> This would remedy what I have long judged a deficiency in summary.glm().
>>> The information is important for diagnostic purposes.  One should not have
>>> to fit a model with a quasi error, or suss out how to calculate the Pearson
>>> chi square from the glm model object, to discover that the information in the
>>> model object is inconsistent with simple binomial or poisson assumptions.
>> 
>> It could be somewhere between useless and misleading in cases like binary logistic regression though. (Same thing goes for the test against the saturated model: Sometimes it makes sense and sometimes not.)
>> 
>>> 
>>> John Maindonald             email: john.maindonald at anu.edu.au
>>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>>> Centre for Mathematics & Its Applications, Room 1194,
>>> John Dedman Mathematical Sciences Building (Building 27)
>>> Australian National University, Canberra ACT 0200.
>>> http://www.maths.anu.edu.au/~johnm
>>> 
>>> On 15/03/2011, at 10:00 PM, r-devel-request at r-project.org wrote:
>>> 
>>>> From: Brett Presnell <presnell at stat.ufl.edu>
>>>> Date: 15 March 2011 2:40:29 PM AEDT
>>>> To: peter dalgaard <pdalgd at gmail.com>
>>>> Cc: r-devel at r-project.org
>>>> Subject: Re: [Rd] Standardized Pearson residuals
>>>> 
>>>> 
>>>> 
>>>> Thanks Peter.  I have just a couple of minor comments, and another
>>>> possible feature request, although it's one that I don't think will be
>>>> implemented.
>>>> 
>>>> peter dalgaard <pdalgd at gmail.com> writes:
>>>> 
>>>>> On Mar 14, 2011, at 22:25 , Brett Presnell wrote:
>>>>> 
>>>>>> 
>>>>>> Is there any reason that rstandard.glm doesn't have a "pearson" option?
>>>>>> And if not, can it be added?
>>>>> 
>>>>> Probably... I have been wondering about that too. I'm even puzzled why
>>>>> it isn't the default. Deviance residuals don't have quite the
>>>>> properties that one might expect, e.g. in this situation, the absolute
>>>>> residuals sum pairwise to zero, so you'd expect that the standardized
>>>>> residuals be identical in absolute value
>>>>> 
>>>>>> y <- 1:4
>>>>>> r <- c(0,0,1,1)
>>>>>> c <- c(0,1,0,1)
>>>>>> rstandard(glm(y~r+c,poisson))
>>>>>       1          2          3          4 
>>>>> -0.2901432  0.2767287  0.2784603 -0.2839995 
>>>>> 
>>>>> in comparison,
>>>>> 
>>>>>> i <- influence(glm(y~r+c,poisson))
>>>>>> i$pear.res/sqrt(1-i$hat)
>>>>>       1          2          3          4 
>>>>> -0.2817181  0.2817181  0.2817181 -0.2817181 
>>>>> 
>>>>> The only thing is that I'm always wary of tampering with this stuff,
>>>>> for fear of finding out the hard way why thing are the way they
>>>>> are....
>>>> 
>>>> I'm sure that's wise, but it would be nice to get it in as an option,
>>>> even if it's not the default
>>>> 
>>>>>> Background: I'm currently teaching an undergrad/grad-service course from
>>>>>> Agresti's "Introduction to Categorical Data Analysis (2nd edn)" and
>>>>>> deviance residuals are not used in the text.  For now I'll just provide
>>>>>> the students with a simple function to use, but I prefer to use R's
>>>>>> native capabilities whenever possible.
>>>>> 
>>>>> Incidentally, chisq.test will have a stdres component in 2.13.0 for
>>>>> much the same reason.
>>>> 
>>>> Thank you.  That's one more thing I won't have to provide code for
>>>> anymore.  Coincidentally, Agresti mentioned this to me a week or two ago
>>>> as something that he felt was missing, so that's at least two people who
>>>> will be happy to see this added.
>>>> 
>>>> It would also be nice for teaching purposes if glm or summary.glm had a
>>>> "pearsonchisq" component and a corresponding extractor function, but I
>>>> can imagine that there might be arguments against it that haven't
>>>> occured to me.  Plus, I doubt that anyone wants to touch glm unless it's
>>>> to repair a bug. If I'm wrong about all that though, ...
>>>> 
>>>> BTW, as I go along I'm trying to collect a lot of the datasets from the
>>>> examples and exercises in the text into an R package ("icda").  It's far
>>>> from complete and what is there needed tidying up, but I hope to
>>>> eventually to round it into shape and put it on CRAN, assuming that
>>>> Agresti approves and that there are no copyright issues.
>>>> 
>>>>>> I think something along the following lines should do it:
>>>>>> 
>>>>>> rstandard.glm <-
>>>>>> function(model,
>>>>>>        infl=influence(model, do.coef=FALSE),
>>>>>>        type=c("deviance", "pearson"), ...)
>>>>>> {
>>>>>> type <- match.arg(type)
>>>>>> res <- switch(type, pearson = infl$pear.res, infl$dev.res)
>>>>>> res <- res/sqrt(1-infl$hat)
>>>>>> res[is.infinite(res)] <- NaN
>>>>>> res
>>>>>> }
>>>> 
>>> 
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> -- 
>> Peter Dalgaard
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From smyth at wehi.EDU.AU  Fri Mar 18 02:32:45 2011
From: smyth at wehi.EDU.AU (Gordon K Smyth)
Date: Fri, 18 Mar 2011 12:32:45 +1100 (AUS Eastern Daylight Time)
Subject: [Rd] Standardized Pearson residuals (and score tests)
In-Reply-To: <1ED94EBF-B9D3-4763-AB82-17B540ED2FF1@gmail.com>
References: <mailman.27.1300273207.30527.r-devel@r-project.org>
	<Pine.WNT.4.64.1103170923580.4296@PC765.wehi.edu.au>
	<1ED94EBF-B9D3-4763-AB82-17B540ED2FF1@gmail.com>
Message-ID: <Pine.WNT.4.64.1103181220450.5620@PC765.wehi.edu.au>

On Thu, 17 Mar 2011, peter dalgaard wrote:

> On Mar 16, 2011, at 23:29 , Gordon K Smyth wrote:
>
>> Hi Peter and others,
>>
>> If it helps, I wrote a small function glm.scoretest() for the statmod 
>> package on CRAN to compute score tests from glm fits.  The score test 
>> for adding a covariate, or any set of covariates, can be extracted very 
>> neatly from the standard glm output, although you probably already know 
>> that.
>
> Thanks Gordon,
>
> I'll have a look. It's the kind of think where you _strongly suspect_ 
> that a neat solution exists, but where you can't just write it down 
> immediately. Looks like your code needs some elaboration to handle 
> factor terms and more general model reductions, though.

Yes, the glm.scoretest() function is very basic.  At the moment it tests 
for adding a single covariate at a time, i.e., a 1 df test, or several 1 
df tests.  If you like, I could add a multiple column version that would 
work for factors etc, it would be only more line or so.  I figure you'd 
want to pull code out of glm.scoretest() rather than call it explicitly 
anyway.

Gordon

> -pd
>
>>
>> Regards
>> Gordon
>>
>> ---------------------------------------------
>> Professor Gordon K Smyth,
>> NHMRC Senior Research Fellow,
>> Bioinformatics Division,
>> Walter and Eliza Hall Institute of Medical Research,
>> 1G Royal Parade, Parkville, Vic 3052, Australia.
>> smyth at wehi.edu.au
>> http://www.wehi.edu.au
>> http://www.statsci.org/smyth

> -- 
> Peter Dalgaard
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>

______________________________________________________________________
The information in this email is confidential and intend...{{dropped:4}}


From murdoch.duncan at gmail.com  Fri Mar 18 02:49:56 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 17 Mar 2011 21:49:56 -0400
Subject: [Rd] Feature request: display file name in R CMD check warning
In-Reply-To: <AANLkTinuKBHZJoH5MKwqy91qoxKth3AK=T+ZxNkYuena@mail.gmail.com>
References: <AANLkTi=D483mk=SVgM5w4bd9gazMA2XeFS_ufLNHOTyL@mail.gmail.com>	<4D81D636.2060209@gmail.com>
	<AANLkTinuKBHZJoH5MKwqy91qoxKth3AK=T+ZxNkYuena@mail.gmail.com>
Message-ID: <4D82BA44.5000002@gmail.com>

On 11-03-17 12:33 PM, Dan Tenenbaum wrote:
> On Thu, Mar 17, 2011 at 2:36 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com>  wrote:
>> On 16/03/2011 7:55 PM, Dan Tenenbaum wrote:
>>>
>>> Hi,
>>>
>>> I came across the following warning in R CMD check (it only occurred on
>>> Windows):
>>>
>>> The \usage entries for S3 methods should use the \method markup and not
>>>>
>>>> their full name.
>>>> See the chapter 'Writing R documentation files' in manual 'Writing R
>>>> Extensions'.
>>>
>>>
>>> The package I'm looking at is one that I did not write which has 34 .Rd
>>> files. This warning does not tell me which file to look in. It would be
>>> very
>>> helpful if it did. Same goes for other warnings/errors produced by R CMD
>>> check.
>>
>> I was unable to duplicate this.  When I tried it by messing up one of the
>> man pages in the ellipse package, I got this:
>>
>> S3 methods shown with full name in documentation object 'ellipse.glm':
>>   ellipse.glm
>>
>> The \usage entries for S3 methods should use the \method markup and not
>> their full name.
>> See the chapter 'Writing R documentation files' in manual 'Writing R
>> Extensions'.
>>
>> "Documentation object 'ellipse.glm'" tells me the \name{} inside the .Rd
>> file, which is enough to uniquely identify the file.  Are you not seeing
>> this part of the message?
>>
>
>
> No, I'm not.
>
> I still can't identify the offending file, but you can download the
> whole package:
>
> svn --username readonly --password readonly export
> https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/affyILM/
>
> Then run R CMD check on this package. You may need to install dependencies.

I installed a lot of dependencies, but couldn't trust check because of 
this warning:

Found the following significant warnings:
   Warning: running command 'C:\WINDOWS\system32\cmd.exe /c ftype perl' 
had status 2

I'm not sure where this comes from; I don't think bgafun uses perl, so 
it's from one of the dependencies.  But I think the error message you 
are seeing is spurious:  something else is going wrong when check tries 
to check \usage sections, and so it reports that there was an error.

As a sort of confirmation of this, I removed the dependencies from the 
DESCRIPTION file and tried to run check; I got lots of errors because of 
the missing dependencies now, but the one about S3 methods went away.

Not sure what to suggest to diagnose this; I'm not familiar with most of 
those packages I just installed as dependencies.  But I think it's safe 
to say that you shouldn't worry about the \usage sections.

If you do figure out what's going wrong, please let us know because it 
would probably be a good idea to fix the usage checks so they give the 
right message.

Duncan Murdoch


From zepu.zhang at gmail.com  Fri Mar 18 03:51:45 2011
From: zepu.zhang at gmail.com (Zepu Zhang)
Date: Thu, 17 Mar 2011 18:51:45 -0800
Subject: [Rd] avoid copying big object passed into optimize()
In-Reply-To: <1299726967.1758.53.camel@matt-laptop>
References: <AANLkTimLO0q9EQheDZCew7h+6371RYUXQyqako2xu=Wx@mail.gmail.com>
	<1299726967.1758.53.camel@matt-laptop>
Message-ID: <AANLkTik+r=0LKt5FDpW9nnkzcN0+vqnuENatz1mnVvrX@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110317/9a6901fa/attachment.pl>

From pdalgd at gmail.com  Fri Mar 18 08:07:54 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 18 Mar 2011 08:07:54 +0100
Subject: [Rd] Standardized Pearson residuals
In-Reply-To: <87hbb1fs2m.fsf@stat.ufl.edu>
References: <325E2604-06E3-4C1A-9D2B-08A42A894025@anu.edu.au>
	<87hbb1fs2m.fsf@stat.ufl.edu>
Message-ID: <46A5CFAE-BD90-42D4-9ECF-EF6E81A57C27@gmail.com>


On Mar 17, 2011, at 20:46 , Brett Presnell wrote:

> 
> John Maindonald <john.maindonald at anu.edu.au> writes:
> 
>> One can easily test for the binary case and not give the statistic in
>> that case.
>> 
>> A general point is that if one gave no output that was not open to
>> abuse, there'd be nothing given at all!
> 
> Thanks John.  I've been reluctant to push too hard for this on r-devel,
> but this is more or less the point I made to Peter in a private email.

Well, r-devel is the discussion club. If you push people there, they can move away.... 

Anyways, I have committed the new rstandard(); to r-devel for now, if nothing falls on its face, we can move it to R 2.13.0 alpha before it goes to beta on March 30.

	-p
-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From presnell at stat.ufl.edu  Fri Mar 18 15:07:02 2011
From: presnell at stat.ufl.edu (Brett Presnell)
Date: Fri, 18 Mar 2011 10:07:02 -0400
Subject: [Rd] Standardized Pearson residuals
In-Reply-To: <46A5CFAE-BD90-42D4-9ECF-EF6E81A57C27@gmail.com> (peter
	dalgaard's message of "Fri, 18 Mar 2011 08:07:54 +0100")
References: <46A5CFAE-BD90-42D4-9ECF-EF6E81A57C27@gmail.com>
Message-ID: <87y64c7cah.fsf@stat.ufl.edu>


Thanks for putting in the rstandard() change Peter.  I'll keep my
fingers crossed that it doesn't break anything.

Meanwhile, I hope that you and all the core developers will take my
enormous appreciation for all that you do as implicit in any message
that I send.  You have changed and continue to change the world in a
very positive way.


From H.C.Pumphrey at ed.ac.uk  Fri Mar 18 17:49:52 2011
From: H.C.Pumphrey at ed.ac.uk (H C Pumphrey)
Date: Fri, 18 Mar 2011 16:49:52 +0000
Subject: [Rd] Fixing the HDF5 package: the on.exit mystery
In-Reply-To: <4D7F99FB.4010304@ed.ac.uk>
References: <4D70C05C.4040905@ed.ac.uk> <4D7F99FB.4010304@ed.ac.uk>
Message-ID: <4D838D30.6090109@ed.ac.uk>

H C Pumphrey wrote:
> H C Pumphrey wrote:
> 
>> I'm trying to fix a subtle bug in the hdf5 package. This package 
>> provides an interfaces to the HDF5 library and hence allows one to 
>> load data into R from files in the HDF5 format. The bug appeared 
>> during a period in which R changed but the package did not. [details 
>> snipped]

> I have fixed the bug in a more crude and obvious manner [...] 

> I will try uploading the package to CRAN at some point, but I think I'll 
> use it myself for a bit to see whether it has any other nasties. If 
> anyone wants to try it in the meantime you can get it at 
> [A URL which was not easy to find :-( ]

 > I'd be particularly interested to know if it can be built on Windows/MacOS
 > and, if not, why not.

Two users report that it installs OK in MacOSX: many thanks.
Two users report that it doesn't build on Windows. Brian Ripley provided fixes 
for this. I have incorporated these and bumped the package version to 1.7.1. 
(I'm afraid I don't know much about building R packages with compiled code on 
Windows: I am grateful for any help that others can provide on this.)

As the link I gave was rather buried in a long web page I have moved it to a 
shorter one that contains only relevant information: 
http://xweb.geos.ed.ac.uk/~hcp/Rhdf5.html

best wishes

Hugh

-- 

============S=u=p=p=o=r=t===D=e=b=i=a=n===http://www.debian.org =========
Dr. Hugh C. Pumphrey          | Tel. 0131-650-6026,Fax:0131-662-0478
School of GeoSciences         | Replace 0131 with +44-131 if outside UK
The University of Edinburgh   | Email: H.C.Pumphrey at ed.ac.uk
EDINBURGH EH9 3JN, Scotland   | web: www.geos.ed.ac.uk/homes/hcp
===================S=u=p=p=o=r=t==F=r=e=e==S=o=f=t=w=a=r=e===============

The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From edd at debian.org  Fri Mar 18 18:54:17 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 18 Mar 2011 12:54:17 -0500
Subject: [Rd] [Patch suggestion] Adding 3rd arg to tempfile() to set
	extension
Message-ID: <19843.40009.487479.883989@max.nulle.part>


The other day I was working on an example which used tempfile() to create
file for use by the graphics device. And while I love tempfile()---as it is
portable and clever and the files get cleaned by R and all that---I noticed
one missing feature I would like to see: beside a starting name pattern, and
an optional directory, an 'file extension' argument would be nice to have.
As e.g. in

      tmppdf  <- tempfile(fileext=".pdf")
      tmppng  <- tempfile(fileext=".png")
      tmpjpeg <- tempfile(fileext=".jpeg")

Below is a short and simple patch which extends tempfile() to three arguments
with the new one (fileext) defaulting to "".  If set, the extension is
appended to what we got from R_tmpnam().  I made this non-vectorised; this
could be changed. I left R_tmpnam() alone as its interface appears in a
header. I updated the manual page too.

I wrote this again current R-devel source from SVN, the patch reflects
that. The patch applies cleanly to R-alpha as well where 'make check' passes
(and I only tried this as make check had issues with R-devel but devel being
devel I am not sure that it was this patch).

Now, I understand that tempfile() is used in a large number of places so I
more or less expect to get stone silence or a resounding "don't even think
about it".  This end can always be achieved with a local function; but maybe
somebody else see merit in having this at the source.

Thanks for listening, and for considering this. 

Regards, Dirk

Index: src/library/base/R/temp.R
===================================================================
--- src/library/base/R/temp.R	(revision 54862)
+++ src/library/base/R/temp.R	(working copy)
@@ -14,7 +14,7 @@
 #  A copy of the GNU General Public License is available at
 #  http://www.r-project.org/Licenses/
 
-tempfile <- function(pattern = "file", tmpdir = tempdir())
-    .Internal(tempfile(pattern, tmpdir))
+tempfile <- function(pattern = "file", tmpdir = tempdir(), fileext = "")
+    .Internal(tempfile(pattern, tmpdir, fileext))
 
 tempdir <- function() .Internal(tempdir())
Index: src/library/base/man/tempfile.Rd
===================================================================
--- src/library/base/man/tempfile.Rd	(revision 54862)
+++ src/library/base/man/tempfile.Rd	(working copy)
@@ -12,13 +12,14 @@
   names for temporary files.
 }
 \usage{
-tempfile(pattern = "file", tmpdir = tempdir())
+tempfile(pattern = "file", tmpdir = tempdir(), fileext = "")
 tempdir()
 }
 \arguments{
   \item{pattern}{a non-empty character vector giving the initial part
     of the name.}
   \item{tmpdir}{a non-empty character vector giving the directory name}
+  \item{fileext}{an optional character object giving a file extension}
 }
 \value{
   For \code{tempfile} a character vector giving the names of possible
@@ -55,6 +56,11 @@
   contains a space in any of the components, the path returned will use
   the shortnames version of the path.
 #endif
+
+  The optional argument \code{fileext} can be use to supply a file
+  extension. This can be useful if the temporary file is for example use
+  with a graphics device as the file type can be signalled via the
+  extension; an example would be \code{fileext=".png"}.
 }
 \references{
   Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988)
Index: src/main/names.c
===================================================================
--- src/main/names.c	(revision 54862)
+++ src/main/names.c	(working copy)
@@ -786,7 +786,7 @@
 {"file.info",	do_fileinfo,	0,	11,	1,	{PP_FUNCALL, PREC_FN,	0}},
 {"file.access",	do_fileaccess,	0,	11,	2,	{PP_FUNCALL, PREC_FN,	0}},
 {"dir.create",	do_dircreate,	0,	11,	4,	{PP_FUNCALL, PREC_FN,	0}},
-{"tempfile",	do_tempfile,	0,	11,	2,	{PP_FUNCALL, PREC_FN,	0}},
+{"tempfile",	do_tempfile,	0,	11,	3,	{PP_FUNCALL, PREC_FN,	0}},
 {"tempdir",	do_tempdir,	0,	11,	0,	{PP_FUNCALL, PREC_FN,	0}},
 {"R.home",	do_Rhome,	0,	11,	0,	{PP_FUNCALL, PREC_FN,	0}},
 {"date",	do_date,	0,	11,	0,	{PP_FUNCALL, PREC_FN,	0}},
Index: src/main/sysutils.c
===================================================================
--- src/main/sysutils.c	(revision 54862)
+++ src/main/sysutils.c	(working copy)
@@ -233,30 +233,44 @@
 
 SEXP attribute_hidden do_tempfile(SEXP call, SEXP op, SEXP args, SEXP env)
 {
-    SEXP  ans, pattern, tempdir;
-    const char *tn, *td;
+    SEXP  ans, pattern, fileext, tempdir;
+    const char *tn, *td, *te;
     char *tm;
-    int i, n1, n2, slen;
+    int i, n1, n2, n3, slen;
+    char tmp1[PATH_MAX];
 
     checkArity(op, args);
-    pattern = CAR(args); n1 = length(pattern);
-    tempdir = CADR(args); n2 = length(tempdir);
+    pattern = CAR(args); n1 = length(pattern); args = CDR(args);
+    tempdir = CAR(args); n2 = length(tempdir); args = CDR(args);
+    fileext = CAR(args); n3 = length(fileext);
     if (!isString(pattern))
 	error(_("invalid filename pattern"));
     if (!isString(tempdir))
 	error(_("invalid '%s' value"), "tempdir");
+    if (!isString(fileext))
+	error(_("invalid pattern for end-of-filename"));
     if (n1 < 1)
 	error(_("no 'pattern'"));
     if (n2 < 1)
 	error(_("no 'tempdir'"));
+    /* fileext is optional and defaults to "" so no test for vector*/
+    if (n3 != 1)
+	error(_("only single argument for end-of-filename pattern supported"));
     slen = (n1 > n2) ? n1 : n2;
     PROTECT(ans = allocVector(STRSXP, slen));
     for(i = 0; i < slen; i++) {
 	tn = translateChar( STRING_ELT( pattern , i%n1 ) );
 	td = translateChar( STRING_ELT( tempdir , i%n2 ) );
+	te = translateChar( STRING_ELT( fileext , 0 ) );
 	/* try to get a new file name */
 	tm = R_tmpnam(tn, td);
-	SET_STRING_ELT(ans, i, mkChar(tm));
+	if (0 != strlen(te)) {
+	   /* append optional extension, or null string */
+	   snprintf(tmp1, PATH_MAX, "%s%s", tm, te);
+	   SET_STRING_ELT(ans, i, mkChar(tmp1));
+	} else {
+	   SET_STRING_ELT(ans, i, mkChar(tm));
+	}
 	if(tm) free(tm);
     }
     UNPROTECT(1);

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From jcg3441 at rit.edu  Fri Mar 18 18:52:04 2011
From: jcg3441 at rit.edu (jcg3441)
Date: Fri, 18 Mar 2011 10:52:04 -0700 (PDT)
Subject: [Rd] passing a 2D array from Java to R
Message-ID: <1300470724415-3387933.post@n4.nabble.com>

Hello, 

I have a 2D array of type double in java and I want to pass this data to R
in order to compute some statistics. Can anyone help me with this ? 

Jose

--
View this message in context: http://r.789695.n4.nabble.com/passing-a-2D-array-from-Java-to-R-tp3387933p3387933.html
Sent from the R devel mailing list archive at Nabble.com.


From murdoch.duncan at gmail.com  Fri Mar 18 19:41:35 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 18 Mar 2011 14:41:35 -0400
Subject: [Rd] [Patch suggestion] Adding 3rd arg to tempfile() to set
	extension
In-Reply-To: <19843.40009.487479.883989@max.nulle.part>
References: <19843.40009.487479.883989@max.nulle.part>
Message-ID: <4D83A75F.5090709@gmail.com>

I think this is a good idea; I'll put it into r-devel and possibly r-alpha.

Duncan Murdoch

On 18/03/2011 1:54 PM, Dirk Eddelbuettel wrote:
> The other day I was working on an example which used tempfile() to create
> file for use by the graphics device. And while I love tempfile()---as it is
> portable and clever and the files get cleaned by R and all that---I noticed
> one missing feature I would like to see: beside a starting name pattern, and
> an optional directory, an 'file extension' argument would be nice to have.
> As e.g. in
>
>        tmppdf<- tempfile(fileext=".pdf")
>        tmppng<- tempfile(fileext=".png")
>        tmpjpeg<- tempfile(fileext=".jpeg")
>
> Below is a short and simple patch which extends tempfile() to three arguments
> with the new one (fileext) defaulting to "".  If set, the extension is
> appended to what we got from R_tmpnam().  I made this non-vectorised; this
> could be changed. I left R_tmpnam() alone as its interface appears in a
> header. I updated the manual page too.
>
> I wrote this again current R-devel source from SVN, the patch reflects
> that. The patch applies cleanly to R-alpha as well where 'make check' passes
> (and I only tried this as make check had issues with R-devel but devel being
> devel I am not sure that it was this patch).
>
> Now, I understand that tempfile() is used in a large number of places so I
> more or less expect to get stone silence or a resounding "don't even think
> about it".  This end can always be achieved with a local function; but maybe
> somebody else see merit in having this at the source.
>
> Thanks for listening, and for considering this.
>
> Regards, Dirk
>
> Index: src/library/base/R/temp.R
> ===================================================================
> --- src/library/base/R/temp.R	(revision 54862)
> +++ src/library/base/R/temp.R	(working copy)
> @@ -14,7 +14,7 @@
>   #  A copy of the GNU General Public License is available at
>   #  http://www.r-project.org/Licenses/
>
> -tempfile<- function(pattern = "file", tmpdir = tempdir())
> -    .Internal(tempfile(pattern, tmpdir))
> +tempfile<- function(pattern = "file", tmpdir = tempdir(), fileext = "")
> +    .Internal(tempfile(pattern, tmpdir, fileext))
>
>   tempdir<- function() .Internal(tempdir())
> Index: src/library/base/man/tempfile.Rd
> ===================================================================
> --- src/library/base/man/tempfile.Rd	(revision 54862)
> +++ src/library/base/man/tempfile.Rd	(working copy)
> @@ -12,13 +12,14 @@
>     names for temporary files.
>   }
>   \usage{
> -tempfile(pattern = "file", tmpdir = tempdir())
> +tempfile(pattern = "file", tmpdir = tempdir(), fileext = "")
>   tempdir()
>   }
>   \arguments{
>     \item{pattern}{a non-empty character vector giving the initial part
>       of the name.}
>     \item{tmpdir}{a non-empty character vector giving the directory name}
> +  \item{fileext}{an optional character object giving a file extension}
>   }
>   \value{
>     For \code{tempfile} a character vector giving the names of possible
> @@ -55,6 +56,11 @@
>     contains a space in any of the components, the path returned will use
>     the shortnames version of the path.
>   #endif
> +
> +  The optional argument \code{fileext} can be use to supply a file
> +  extension. This can be useful if the temporary file is for example use
> +  with a graphics device as the file type can be signalled via the
> +  extension; an example would be \code{fileext=".png"}.
>   }
>   \references{
>     Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988)
> Index: src/main/names.c
> ===================================================================
> --- src/main/names.c	(revision 54862)
> +++ src/main/names.c	(working copy)
> @@ -786,7 +786,7 @@
>   {"file.info",	do_fileinfo,	0,	11,	1,	{PP_FUNCALL, PREC_FN,	0}},
>   {"file.access",	do_fileaccess,	0,	11,	2,	{PP_FUNCALL, PREC_FN,	0}},
>   {"dir.create",	do_dircreate,	0,	11,	4,	{PP_FUNCALL, PREC_FN,	0}},
> -{"tempfile",	do_tempfile,	0,	11,	2,	{PP_FUNCALL, PREC_FN,	0}},
> +{"tempfile",	do_tempfile,	0,	11,	3,	{PP_FUNCALL, PREC_FN,	0}},
>   {"tempdir",	do_tempdir,	0,	11,	0,	{PP_FUNCALL, PREC_FN,	0}},
>   {"R.home",	do_Rhome,	0,	11,	0,	{PP_FUNCALL, PREC_FN,	0}},
>   {"date",	do_date,	0,	11,	0,	{PP_FUNCALL, PREC_FN,	0}},
> Index: src/main/sysutils.c
> ===================================================================
> --- src/main/sysutils.c	(revision 54862)
> +++ src/main/sysutils.c	(working copy)
> @@ -233,30 +233,44 @@
>
>   SEXP attribute_hidden do_tempfile(SEXP call, SEXP op, SEXP args, SEXP env)
>   {
> -    SEXP  ans, pattern, tempdir;
> -    const char *tn, *td;
> +    SEXP  ans, pattern, fileext, tempdir;
> +    const char *tn, *td, *te;
>       char *tm;
> -    int i, n1, n2, slen;
> +    int i, n1, n2, n3, slen;
> +    char tmp1[PATH_MAX];
>
>       checkArity(op, args);
> -    pattern = CAR(args); n1 = length(pattern);
> -    tempdir = CADR(args); n2 = length(tempdir);
> +    pattern = CAR(args); n1 = length(pattern); args = CDR(args);
> +    tempdir = CAR(args); n2 = length(tempdir); args = CDR(args);
> +    fileext = CAR(args); n3 = length(fileext);
>       if (!isString(pattern))
>   	error(_("invalid filename pattern"));
>       if (!isString(tempdir))
>   	error(_("invalid '%s' value"), "tempdir");
> +    if (!isString(fileext))
> +	error(_("invalid pattern for end-of-filename"));
>       if (n1<  1)
>   	error(_("no 'pattern'"));
>       if (n2<  1)
>   	error(_("no 'tempdir'"));
> +    /* fileext is optional and defaults to "" so no test for vector*/
> +    if (n3 != 1)
> +	error(_("only single argument for end-of-filename pattern supported"));
>       slen = (n1>  n2) ? n1 : n2;
>       PROTECT(ans = allocVector(STRSXP, slen));
>       for(i = 0; i<  slen; i++) {
>   	tn = translateChar( STRING_ELT( pattern , i%n1 ) );
>   	td = translateChar( STRING_ELT( tempdir , i%n2 ) );
> +	te = translateChar( STRING_ELT( fileext , 0 ) );
>   	/* try to get a new file name */
>   	tm = R_tmpnam(tn, td);
> -	SET_STRING_ELT(ans, i, mkChar(tm));
> +	if (0 != strlen(te)) {
> +	   /* append optional extension, or null string */
> +	   snprintf(tmp1, PATH_MAX, "%s%s", tm, te);
> +	   SET_STRING_ELT(ans, i, mkChar(tmp1));
> +	} else {
> +	   SET_STRING_ELT(ans, i, mkChar(tm));
> +	}
>   	if(tm) free(tm);
>       }
>       UNPROTECT(1);
>


From dtenenba at fhcrc.org  Fri Mar 18 20:47:00 2011
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Fri, 18 Mar 2011 12:47:00 -0700
Subject: [Rd] Feature request: display file name in R CMD check warning
In-Reply-To: <4D82BA44.5000002@gmail.com>
References: <AANLkTi=D483mk=SVgM5w4bd9gazMA2XeFS_ufLNHOTyL@mail.gmail.com>
	<4D81D636.2060209@gmail.com>
	<AANLkTinuKBHZJoH5MKwqy91qoxKth3AK=T+ZxNkYuena@mail.gmail.com>
	<4D82BA44.5000002@gmail.com>
Message-ID: <AANLkTimW8CDnziKiknH7P4KpwDavBP88Xw5b9NHAmU-f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110318/a2737cd2/attachment.pl>

From simon.urbanek at r-project.org  Fri Mar 18 20:48:06 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 18 Mar 2011 15:48:06 -0400
Subject: [Rd] passing a 2D array from Java to R
In-Reply-To: <1300470724415-3387933.post@n4.nabble.com>
References: <1300470724415-3387933.post@n4.nabble.com>
Message-ID: <806F4C35-090C-448A-96CA-A1D3BD4CD5FE@r-project.org>

On Mar 18, 2011, at 1:52 PM, jcg3441 wrote:

> I have a 2D array of type double in java and I want to pass this data to R
> in order to compute some statistics. Can anyone help me with this ? 
> 

The best place would be the appropriate mailing list of the package that use use for R/Java communication. If it's rJava then stats-rosuda-devel mailing is the list to ask.

In R matrices are vectors of the length m*n so you can either create one array with the values in Java, assign it (let's say to A) and call matrix(A,m,n) or you can simply pull the array as-is to R and run something like sapply(a,.jevalArray).

Cheers,
Simon


From ripley at stats.ox.ac.uk  Fri Mar 18 22:22:04 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 18 Mar 2011 21:22:04 +0000 (GMT)
Subject: [Rd] Testing window for R 2.13.0
Message-ID: <alpine.LFD.2.02.1103182057380.4071@gannet.stats.ox.ac.uk>

We are now starting testing R 2.13.0/alpba/beta/RC and testing and 
feedback would be appreciated (whereas reports on problems immediately 
after release will try our patience).

Sources are available at
http://cran.r-project.org/src/base-prerelease/
Windows binaries at
http://cran.r-project.org/bin/windows/base/rtest.html
and Mac binaries at http://r.research.att.com/, specifically
http://r.research.att.com/R-2.13-branch-leopard.pkg
(and it is best to use the CRAN master rather than mirrors which will 
lag behind).

Please report (success as well as failure except on the most common 
platforms) here, R-windows at r-project.org or R-sig-mac at r-project.org. 
We probably have good coverage of Debian/Fedora i686/x86_64 Linux, Mac 
OS X, Windows, Solaris and x86_64 FreeBSD 8.2: reports on other 
platforms would be particularly welcome.

There have been a number of confused postings about 64-bit R on 
Solaris: the R-admin manual in this version contains detailed 
instructions on what works for us (Solaris Studio 12.2 and 12u1, and 
gcc4 on Sparc) and what doesn't (gcc on amd64) and why.

Package maintainers should review the results for their packages at
http://cran.r-project.org/web/checks/check_summary.html
and submit updates if needed as soon as possible and definitely well 
before April 13.  That page is in the process of migration to 
R-prerel: for now the most useful columns are r-devel (Fedora), 
r-devel (Windows, really R-prerel) and the Solaris x86 column.

Brian Ripley (for the R-core team)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From edd at debian.org  Fri Mar 18 22:38:17 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 18 Mar 2011 16:38:17 -0500
Subject: [Rd] Testing window for R 2.13.0
In-Reply-To: <alpine.LFD.2.02.1103182057380.4071@gannet.stats.ox.ac.uk>
References: <alpine.LFD.2.02.1103182057380.4071@gannet.stats.ox.ac.uk>
Message-ID: <19843.53449.352895.284706@max.nulle.part>


On 18 March 2011 at 21:22, Prof Brian Ripley wrote:
| We are now starting testing R 2.13.0/alpba/beta/RC and testing and 
| feedback would be appreciated (whereas reports on problems immediately 
| after release will try our patience).
| 
| Sources are available at
| http://cran.r-project.org/src/base-prerelease/
| Windows binaries at
| http://cran.r-project.org/bin/windows/base/rtest.html
| and Mac binaries at http://r.research.att.com/, specifically
| http://r.research.att.com/R-2.13-branch-leopard.pkg
| (and it is best to use the CRAN master rather than mirrors which will 
| lag behind).
| 
| Please report (success as well as failure except on the most common 
| platforms) here, R-windows at r-project.org or R-sig-mac at r-project.org. 
| We probably have good coverage of Debian/Fedora i686/x86_64 Linux, Mac 
| OS X, Windows, Solaris and x86_64 FreeBSD 8.2: reports on other 
| platforms would be particularly welcome.

Yup, see https://buildd.debian.org/build.cgi?pkg=r-base which reports details
on the build of the snapshot I uploaded yesterday. Summary state is:

Version	Architecture	Latest Build Time	Latest Build State
2.13.0~20110316-1	alpha  	     		Thu Mar 17 15:07:25 2011	maybe-successful
			amd64			Thu Mar 17 14:09:25 2011	maybe-successful
			armel			Thu Mar 17 15:15:10 2011	maybe-successful
			hppa			Fri Mar 18 12:41:58 2011	maybe-successful
			hurd-i386		Thu Mar 17 17:59:38 2011	maybe-successful
			ia64			Thu Mar 17 15:27:36 2011	maybe-successful
			kfreebsd-amd64		Thu Mar 17 14:28:18 2011	maybe-successful
			kfreebsd-i386		Thu Mar 17 14:27:10 2011	maybe-successful
			mips			Thu Mar 17 15:39:41 2011	maybe-successful
			mipsel			Thu Mar 17 23:18:13 2011	maybe-successful
			powerpc			Thu Mar 17 14:18:20 2011	maybe-successful
			s390			Thu Mar 17 14:13:31 2011	maybe-successful
			sparc			Thu Mar 17 14:35:22 2011	maybe-successful

(Intel 32-bit not listed as my local upload is not rebuilt on the build
servers; we will do that 'eventually' but so far we don't.)

(And 'maybe-successful' is the strongest wording here meaning absence of
failure which does not by itself presence of success ;-)

So for anyone running Debian testing and willing to fetch this from unstable,
especially on the more esoteric platforms (s390 anyone? ;-): please do so.

CRAN ports are usually not built; if you want Ubuntu or Debian backports
tweak Michael's or Johannes' arm...

Dirk (on behalf of Debian)

| There have been a number of confused postings about 64-bit R on 
| Solaris: the R-admin manual in this version contains detailed 
| instructions on what works for us (Solaris Studio 12.2 and 12u1, and 
| gcc4 on Sparc) and what doesn't (gcc on amd64) and why.
| 
| Package maintainers should review the results for their packages at
| http://cran.r-project.org/web/checks/check_summary.html
| and submit updates if needed as soon as possible and definitely well 
| before April 13.  That page is in the process of migration to 
| R-prerel: for now the most useful columns are r-devel (Fedora), 
| r-devel (Windows, really R-prerel) and the Solaris x86 column.
| 
| Brian Ripley (for the R-core team)
| 
| -- 
| Brian D. Ripley,                  ripley at stats.ox.ac.uk
| Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
| University of Oxford,             Tel:  +44 1865 272861 (self)
| 1 South Parks Road,                     +44 1865 272866 (PA)
| Oxford OX1 3TG, UK                Fax:  +44 1865 272595
| 
| ______________________________________________
| R-devel at r-project.org mailing list
| https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From smckinney at bccrc.ca  Sat Mar 19 00:39:43 2011
From: smckinney at bccrc.ca (Steven McKinney)
Date: Fri, 18 Mar 2011 16:39:43 -0700
Subject: [Rd] Testing window for R 2.13.0
In-Reply-To: <1381_1300483340_1300483340_alpine.LFD.2.02.1103182057380.4071@gannet.stats.ox.ac.uk>
References: <1381_1300483340_1300483340_alpine.LFD.2.02.1103182057380.4071@gannet.stats.ox.ac.uk>
Message-ID: <DCE81E14EB74504B971DAD4D2DB0356B0864727ECA@crcmail4.BCCRC.CA>


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of Prof Brian
> Ripley
> Sent: March-18-11 2:22 PM
> To: R-devel at r-project.org
> Subject: [Rd] Testing window for R 2.13.0
> 
> We are now starting testing R 2.13.0/alpha/beta/RC and testing and
> feedback would be appreciated (whereas reports on problems immediately
> after release will try our patience).

Thank you for another release and all of your hard work.

Hopefully your degree of impatience with reports immediately
after release is inversely proportional to the number
of reports before release.  Given some good pre-release feedback
it would be a shame to discourage reports immediately after
release :)

I'll install and start testing now...

Having worked for a commercial software company, I am
continuously amazed at how quickly bugs are fixed, feature
requests are implemented, and patched versions released by 
this open source group (this includes Bioconductor and
many of the package maintainers).

No commercial vendor that I know of can or will match this
response.


Steven McKinney

Statistician
Molecular Oncology and Breast Cancer Program
British Columbia Cancer Research Centre

> 
> Sources are available at
> http://cran.r-project.org/src/base-prerelease/
> Windows binaries at
> http://cran.r-project.org/bin/windows/base/rtest.html
> and Mac binaries at http://r.research.att.com/, specifically
> http://r.research.att.com/R-2.13-branch-leopard.pkg
> (and it is best to use the CRAN master rather than mirrors which will
> lag behind).
> 
> Please report (success as well as failure except on the most common
> platforms) here, R-windows at r-project.org or R-sig-mac at r-project.org.
> We probably have good coverage of Debian/Fedora i686/x86_64 Linux, Mac
> OS X, Windows, Solaris and x86_64 FreeBSD 8.2: reports on other
> platforms would be particularly welcome.
> 
> There have been a number of confused postings about 64-bit R on
> Solaris: the R-admin manual in this version contains detailed
> instructions on what works for us (Solaris Studio 12.2 and 12u1, and
> gcc4 on Sparc) and what doesn't (gcc on amd64) and why.
> 
> Package maintainers should review the results for their packages at
> http://cran.r-project.org/web/checks/check_summary.html
> and submit updates if needed as soon as possible and definitely well
> before April 13.  That page is in the process of migration to
> R-prerel: for now the most useful columns are r-devel (Fedora),
> r-devel (Windows, really R-prerel) and the Solaris x86 column.
> 
> Brian Ripley (for the R-core team)
> 
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From rhurlin at gwdg.de  Sat Mar 19 12:28:09 2011
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Sat, 19 Mar 2011 12:28:09 +0100
Subject: [Rd] Undefined symbol "Rf_pythag" while loading spatstat
Message-ID: <4D849349.80203@gwdg.de>

Today I installed the newest R develepment branch
R version 2.14.0 Under development (unstable) (2011-03-18 r54866)
on FreeBSD 9.0-CURRENT (amd64). All seems fine so far.

After that I updated my R packages with option 'checkBuilt=TRUE'. There 
are four packages (spatstat, pscl, adehabitatLT, adehabitatHR) which 
gives an error like this:

Error in dyn.load(file, DLLpath = DLLpath, ...) :
   kann shared object 
'/usr/local/lib/R/library/spatstat/libs/spatstat.so' nicht laden:
   /usr/local/lib/R/library/spatstat/libs/spatstat.so: Undefined symbol 
"Rf_pythag"
Fehler: loading failed
Ausf?hrung angehalten
Fehler: loading failed


Searching around I found a hint in 
http://developer.r-project.org/R_svnlog_2011 about upcoming changes with 
'Rf_pythag':

------------------------------------------------------------------------
r54767 | ripley | 2011-03-13 07:30:32 -0400 (Sun, 13 Mar 2011) | 1 line
Changed paths:
    M /trunk/doc/NEWS.Rd
    M /trunk/src/include/Rmath.h0.in
    M /trunk/src/nmath/imax2.c

keep Rf_pythag for a little longer
------------------------------------------------------------------------


R News of newest devel has three entries about the change:

CHANGES IN R VERSION 2.14.0:
   DEPRECATED AND DEFUNCT:
     o The entry point pythag formerly in Rmath.h is defunct: use
       instead the C99 function hypot.
CHANGES IN R VERSION 2.13.0:
   C-LEVEL FACILITIES:
     o pythag duplicated the C99 function hypot.  It is no longer
       provided, but is used a substitute for hypot in the very unlikely
       event that the latter is not available.
   DEPRECATED & DEFUNCT:
     o The entry point pythag in Rmath.h is deprecated in favour of the
       C99 function hypot.  A wrapper for hypot is provided for R 2.13.x
       only.


Because of that informations I attempted to change 'pythag' against 
'hypot' in spatstat/src/lookup.c and it works. Is this the only required 
adaption which has to be done on the four named packages?

Thanks in advance,
Rainer Hurling


From ripley at stats.ox.ac.uk  Sat Mar 19 15:52:55 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 19 Mar 2011 14:52:55 +0000 (GMT)
Subject: [Rd] Undefined symbol "Rf_pythag" while loading spatstat
In-Reply-To: <4D849349.80203@gwdg.de>
References: <4D849349.80203@gwdg.de>
Message-ID: <alpine.LFD.2.02.1103191447070.23276@gannet.stats.ox.ac.uk>

On Sat, 19 Mar 2011, Rainer Hurling wrote:

> Today I installed the newest R develepment branch
> R version 2.14.0 Under development (unstable) (2011-03-18 r54866)
> on FreeBSD 9.0-CURRENT (amd64). All seems fine so far.

But that is very raw: testing on 2.13.0 alpha would be more useful at 
this point.

> After that I updated my R packages with option 'checkBuilt=TRUE'. There are 
> four packages (spatstat, pscl, adehabitatLT, adehabitatHR) which gives an 
> error like this:
>
> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>  kann shared object '/usr/local/lib/R/library/spatstat/libs/spatstat.so' 
> nicht laden:
>  /usr/local/lib/R/library/spatstat/libs/spatstat.so: Undefined symbol 
> "Rf_pythag"
> Fehler: loading failed
> Ausf?hrung angehalten
> Fehler: loading failed
>
>
> Searching around I found a hint in 
> http://developer.r-project.org/R_svnlog_2011 about upcoming changes with 
> 'Rf_pythag':
>
> ------------------------------------------------------------------------
> r54767 | ripley | 2011-03-13 07:30:32 -0400 (Sun, 13 Mar 2011) | 1 line
> Changed paths:
>   M /trunk/doc/NEWS.Rd
>   M /trunk/src/include/Rmath.h0.in
>   M /trunk/src/nmath/imax2.c
>
> keep Rf_pythag for a little longer
> ------------------------------------------------------------------------
>
>
> R News of newest devel has three entries about the change:
>
> CHANGES IN R VERSION 2.14.0:
>  DEPRECATED AND DEFUNCT:
>    o The entry point pythag formerly in Rmath.h is defunct: use
>      instead the C99 function hypot.
> CHANGES IN R VERSION 2.13.0:
>  C-LEVEL FACILITIES:
>    o pythag duplicated the C99 function hypot.  It is no longer
>      provided, but is used a substitute for hypot in the very unlikely
>      event that the latter is not available.
>  DEPRECATED & DEFUNCT:
>    o The entry point pythag in Rmath.h is deprecated in favour of the
>      C99 function hypot.  A wrapper for hypot is provided for R 2.13.x
>      only.
>
>
> Because of that informations I attempted to change 'pythag' against 'hypot' 
> in spatstat/src/lookup.c and it works. Is this the only required adaption 
> which has to be done on the four named packages?

For adehabitatLT, adehabitatHR, simply update.  For pscl, spatstat, 
change pythag to hypot -- the maintainers have been asked for updates.

You can see CRAN R-devel test results on the CRAN check page.  There 
are a number of other failures due to deprecated -> defunct changes 
(we make them very early in the development cycle).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From rhurlin at gwdg.de  Sat Mar 19 17:02:27 2011
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Sat, 19 Mar 2011 17:02:27 +0100
Subject: [Rd] Undefined symbol "Rf_pythag" while loading spatstat
In-Reply-To: <alpine.LFD.2.02.1103191447070.23276@gannet.stats.ox.ac.uk>
References: <4D849349.80203@gwdg.de>
	<alpine.LFD.2.02.1103191447070.23276@gannet.stats.ox.ac.uk>
Message-ID: <4D84D393.4000009@gwdg.de>

On 19.03.2011 15:52 (UTC+1), Prof Brian Ripley wrote:
> On Sat, 19 Mar 2011, Rainer Hurling wrote:
>
>> Today I installed the newest R develepment branch
>> R version 2.14.0 Under development (unstable) (2011-03-18 r54866)
>> on FreeBSD 9.0-CURRENT (amd64). All seems fine so far.
>
> But that is very raw: testing on 2.13.0 alpha would be more useful at
> this point.

Yes, it is raw. But I need it for some reason.

Testing of 2.13.0 alpha (r54865) on FreeBSD 9.0-CURRENT (amd64) shows no 
problems so far. For testing purposes, I customized the port math/R from 
b.f. and built from that port, so R installed correct on FreeBSD with 
gcc45 and gfortran45.

As to be expected, I had no problems with R packages using pythag on 
2.13.0 alpha. All needed packages could beinstalled. Also, some of my 
more complicated R scripts (with database access, spatial computings and 
pdf production) work fine.

>> After that I updated my R packages with option 'checkBuilt=TRUE'.
>> There are four packages (spatstat, pscl, adehabitatLT, adehabitatHR)
>> which gives an error like this:
>>
>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>> kann shared object
>> '/usr/local/lib/R/library/spatstat/libs/spatstat.so' nicht laden:
>> /usr/local/lib/R/library/spatstat/libs/spatstat.so: Undefined symbol
>> "Rf_pythag"
>> Fehler: loading failed
>> Ausf?hrung angehalten
>> Fehler: loading failed
>>
>>
>> Searching around I found a hint in
>> http://developer.r-project.org/R_svnlog_2011 about upcoming changes
>> with 'Rf_pythag':
>>
>> ------------------------------------------------------------------------
>> r54767 | ripley | 2011-03-13 07:30:32 -0400 (Sun, 13 Mar 2011) | 1 line
>> Changed paths:
>> M /trunk/doc/NEWS.Rd
>> M /trunk/src/include/Rmath.h0.in
>> M /trunk/src/nmath/imax2.c
>>
>> keep Rf_pythag for a little longer
>> ------------------------------------------------------------------------
>>
>>
>> R News of newest devel has three entries about the change:
>>
>> CHANGES IN R VERSION 2.14.0:
>> DEPRECATED AND DEFUNCT:
>> o The entry point pythag formerly in Rmath.h is defunct: use
>> instead the C99 function hypot.
>> CHANGES IN R VERSION 2.13.0:
>> C-LEVEL FACILITIES:
>> o pythag duplicated the C99 function hypot. It is no longer
>> provided, but is used a substitute for hypot in the very unlikely
>> event that the latter is not available.
>> DEPRECATED & DEFUNCT:
>> o The entry point pythag in Rmath.h is deprecated in favour of the
>> C99 function hypot. A wrapper for hypot is provided for R 2.13.x
>> only.
>>
>>
>> Because of that informations I attempted to change 'pythag' against
>> 'hypot' in spatstat/src/lookup.c and it works. Is this the only
>> required adaption which has to be done on the four named packages?
>
> For adehabitatLT, adehabitatHR, simply update. For pscl, spatstat,
> change pythag to hypot -- the maintainers have been asked for updates.

Ok, as I suspected. You had been aware of these packages before ;-)

> You can see CRAN R-devel test results on the CRAN check page. There are
> a number of other failures due to deprecated -> defunct changes (we make
> them very early in the development cycle).

I know of this page. It is very useful for identifying problems with 
packages, especially on Windows, Linux, OSX and Solaris. Understandably 
it does not support my 'rare' platform FreeBSD directly ;-)

Thanks for anwsering and clearing up my request,
Rainer Hurling


From therneau at mayo.edu  Mon Mar 21 16:46:41 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Mon, 21 Mar 2011 10:46:41 -0500
Subject: [Rd] round, unique and factor
Message-ID: <1300722401.29826.24.camel@nemo>

 Survfit had a bug in some prior releases due to the use of both
unique(times) and table(times); I fixed it by rounding to 15 digits per
the manual page for as.character.  Yes, I should ferret out all the
usages instead, but this was fast and it cured the user's problem.
  The bug is back!  A data set from a local colleage triggers it.  
I can send the rda file to anyone who wishes.  

 The current code has
     digits <- floor((.Machine$double.digits) * 
                    logb(.Machine$double.base,10)) #base 10 digits
     Y[,1] <- signif(Y[,1], digits)

which gives 15 digits; should I subtract one more?
  
Should the documentation change?

In the meantime I'm looking at the more permanent fix of turning time
into a factor, then back at the very end.  Because it is a bigger change
the potential for breakage is higer, however.

Terry T.

tmt45% R --vanilla

R version 2.12.2 (2011-02-25)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

> load('test.rda')
> ls()
[1] "temp2"
> temp2 <- round(temp2, 15)
> length(unique(temp2))
[1] 954
> length(table(temp2))
[1] 942
> .Machine$double.eps
[1] 2.220446e-16
> range(temp2)
[1]  0.0000 26.0397

Terry T.


From savicky at cs.cas.cz  Mon Mar 21 17:15:01 2011
From: savicky at cs.cas.cz (Petr Savicky)
Date: Mon, 21 Mar 2011 17:15:01 +0100
Subject: [Rd] round, unique and factor
In-Reply-To: <1300722401.29826.24.camel@nemo>
References: <1300722401.29826.24.camel@nemo>
Message-ID: <20110321161501.GA30378@cs.cas.cz>

On Mon, Mar 21, 2011 at 10:46:41AM -0500, Terry Therneau wrote:
>  Survfit had a bug in some prior releases due to the use of both
> unique(times) and table(times); I fixed it by rounding to 15 digits per
> the manual page for as.character.  Yes, I should ferret out all the
> usages instead, but this was fast and it cured the user's problem.
>   The bug is back!  A data set from a local colleage triggers it.  
> I can send the rda file to anyone who wishes.  
> 
>  The current code has
>      digits <- floor((.Machine$double.digits) * 
>                     logb(.Machine$double.base,10)) #base 10 digits
>      Y[,1] <- signif(Y[,1], digits)
> 
> which gives 15 digits; should I subtract one more?
>   
> Should the documentation change?
> 
> In the meantime I'm looking at the more permanent fix of turning time
> into a factor, then back at the very end.  Because it is a bigger change
> the potential for breakage is higer, however.

Can you describe the error in more detail? Is it related to consistency
of converting a number to character and back?

Petr Savicky.


From wdunlap at tibco.com  Mon Mar 21 17:16:46 2011
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 21 Mar 2011 09:16:46 -0700
Subject: [Rd] split(factor,
	shortGroupVector) gives incorrect results in R 2.12.2
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D70004086330@NA-PA-VBE03.na.tibco.com>

When split's x argument has a class attribute and the
grouping vector, f, is shorter than x then split gives
the wrong result.  It appears to not extend f to the length
of x before doing the split.  E.g.,
   > split(factor(letters[1:3]), "Group one") # expect all 3 elements in
the single group
   $`Group one`
   [1] a
   Levels: a b c
   > split(factor(letters[1:3]), c("Group one", "Group two")) # expect
warning and Group one should contain "a" and "c".
   $`Group one`
   [1] a
   Levels: a b c

   $`Group two`
   [1] b
   Levels: a b c
We expect the above to act like the similar cases where x is
a character vector
   > split(letters[1:3], "Group one")
   $`Group one`
   [1] "a" "b" "c"

   > split(letters[1:3], c("Group one", "Group two"))
   $`Group one`
   [1] "a" "c"

   $`Group two`
   [1] "b"

   Warning message:
   In split.default(letters[1:3], c("Group one", "Group two")) :
     data length is not a multiple of split variable

We get a similar problem for other stray classes of x
   > split(structure(letters[1:3],class="no sUch cLaSs"), c("Group one",
"Group two"))
   $`Group one`
   [1] "a"
 
   $`Group two`
   [1] "b"

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com 


From thomas.k.roth at googlemail.com  Mon Mar 21 18:01:24 2011
From: thomas.k.roth at googlemail.com (Thomas Roth)
Date: Mon, 21 Mar 2011 18:01:24 +0100
Subject: [Rd] error in: testing if installed package can be loaded
Message-ID: <AANLkTin0WpppdN2-edDrCeFLOgR2i+QQr4Vj3tcW2x+B@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110321/f0afe3b8/attachment.pl>

From pdalgd at gmail.com  Mon Mar 21 18:13:29 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 21 Mar 2011 18:13:29 +0100
Subject: [Rd] split(factor,
	shortGroupVector) gives incorrect results in R 2.12.2
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D70004086330@NA-PA-VBE03.na.tibco.com>
References: <77EB52C6DD32BA4D87471DCD70C8D70004086330@NA-PA-VBE03.na.tibco.com>
Message-ID: <AAE93A2B-6866-40E8-81CF-CF4ACF0EA1AA@gmail.com>


On Mar 21, 2011, at 17:16 , William Dunlap wrote:

>> split(factor(letters[1:3]), c("Group one", "Group two"))

Yes, that's a bug (at the very least, it is against documented behavior)

The strong suspicion is that 

    ind <- .Internal(split(seq_along(f), f))

should have seq_along(x) , not f. But would that break for other reasons? 

(It would! Surv() objects to name one case. In general, we seem to be in trouble if "[" and length() methods are not compatible.)

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From tobias.verbeke at openanalytics.eu  Mon Mar 21 23:45:33 2011
From: tobias.verbeke at openanalytics.eu (Tobias Verbeke)
Date: Mon, 21 Mar 2011 23:45:33 +0100
Subject: [Rd] texi2dvi / egrep issue shows (a.o.) up in R-alpha
Message-ID: <4D87D50D.60506@openanalytics.eu>

L.S.

I noticed weird tools::texi2dvi behaviour on R-alpha
when specifying an absolute path to the .tex
file.

The same phenomenon also appears to occur on
R-2.12.2, so maybe the issue is independent
of R.

I hope I did not overlook any important information.

Best,
Tobias

 > require(tools)
Loading required package: tools
 > getwd()
[1] "/home/tobias"
 > texi2dvi("test.tex") # works OK
 > texi2dvi("/home/tobias/test.tex")
Error in texi2dvi("/home/tobias/test.tex") :
   Running 'texi2dvi' on '/home/tobias/test.tex' failed.
Messages:
egrep: Invalid range end
/usr/bin/texi2dvi: cannot read .//home/tobias/test.tex, skipping.
 > sessionInfo()
R version 2.13.0 alpha (2011-03-19 r54880)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
  [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
  [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
  [5] LC_MONETARY=C             LC_MESSAGES=en_US.utf8
  [7] LC_PAPER=en_US.utf8       LC_NAME=C
  [9] LC_ADDRESS=C              LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C

attached base packages:
[1] tools     stats     graphics  grDevices utils     datasets  methods
[8] base
 >

This is Ubuntu 10.10 with GNU grep 2.6.3 and
texi2dvi (GNU Texinfo 4.13) 1.135.

The test file is most simple:

\documentclass{article}
\begin{document}
Test document.
\end{document}


From dtenenba at fhcrc.org  Tue Mar 22 02:07:21 2011
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Mon, 21 Mar 2011 18:07:21 -0700
Subject: [Rd] R_HOME path getting munged in inst/doc/Makefile on Windows
Message-ID: <AANLkTimOzb6Y4biwP9dCaT6goxyjXB7rgLhsnv3SMxjA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110321/d2d62f27/attachment.pl>

From simon.urbanek at r-project.org  Tue Mar 22 03:22:26 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 21 Mar 2011 22:22:26 -0400
Subject: [Rd] R_HOME path getting munged in inst/doc/Makefile on Windows
In-Reply-To: <AANLkTimOzb6Y4biwP9dCaT6goxyjXB7rgLhsnv3SMxjA@mail.gmail.com>
References: <AANLkTimOzb6Y4biwP9dCaT6goxyjXB7rgLhsnv3SMxjA@mail.gmail.com>
Message-ID: <B6C2277E-8D69-491C-87B4-C8EF26C04D7D@r-project.org>


On Mar 21, 2011, at 9:07 PM, Dan Tenenbaum wrote:

> Hello,
> 
> I have come across two separate packages that have a Makefile in inst/doc
> which use the R_HOME variable.
> 
> In both cases, the path to R_HOME gets munged in such a way that commands
> that include R_HOME fail on Windows:
> 
> For example, one Makefile, for the xmapcore package (
> https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/xmapcore/username/password:
> readonly) has this:
> 
> R=${R_HOME}/bin/R
> SUITE=../cookbook/delia.R
> [...]
> ${R} --vanilla --verbose < ${SUITE}
> 
> the output of trying to build this package includes:
> 
> * creating vignettes ... ERROR
> E:\biocbld\BBS-2~1.8-B\R/bin/R --vanilla --verbose < ../cookbook/delia.R
> E:biocbldBBS-2~1.8-BR/bin/R: not found
> make: *** [pdf] Error 127
> Error in tools::buildVignettes(dir = ".") : running 'make' failed
> Execution halted
> 
> It seems R_HOME is not getting resolved to a valid path. That's strange
> because R CMD echo shows the right thing:
> 
> E:\sandbox>\biocbld\bbs-2.8-bioc\R\bin\R CMD echo %R_HOME%
> e:/biocbld/bbs-2.8-bioc/R
> 
> That's a nice path with all forward slashes and no funny 8.3 paths with
> tildes.  But it looks like when R_HOME is invoked in a Makefile, the
> resulting path has a mix of forward and backslashes,

Nope, at least not in R from CRAN:

Makevars:
all:
	echo R_HOME: $(R_HOME)

[...]
echo R_HOME: c:/PROGRA~1/R/R-212~1.2
R_HOME: c:/PROGRA~1/R/R-212~1.2

But I see that you have custom rhome setting (BBS...) so changes are that is the culprit - the rhome for that R build is set incorrectly to contain backslashes.

Cheers,
Simon




> and gets translated
> into 8.3 style, and the resulting path is not valid for finding R
> executables.
> 
> Note that R_HOME is defined within R; I don't also have it defined at the
> shell level:
> 
> E:\sandbox>echo %R_HOME%
> %R_HOME%
> 
> Any ideas?
> Thanks,
> Dan
> 
>> sessionInfo()
> R version 2.13.0 alpha (2011-03-18 r54865)
> Platform: i386-pc-mingw32/i386 (32-bit)
> 
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From dtenenba at fhcrc.org  Tue Mar 22 04:05:44 2011
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Mon, 21 Mar 2011 20:05:44 -0700
Subject: [Rd] R_HOME path getting munged in inst/doc/Makefile on Windows
In-Reply-To: <B6C2277E-8D69-491C-87B4-C8EF26C04D7D@r-project.org>
References: <AANLkTimOzb6Y4biwP9dCaT6goxyjXB7rgLhsnv3SMxjA@mail.gmail.com>
	<B6C2277E-8D69-491C-87B4-C8EF26C04D7D@r-project.org>
Message-ID: <AANLkTim+xv=UygYeDS0+O4CEgO3nf0Oqtypqm97fGTjm@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110321/fde435c2/attachment.pl>

From bbolker at gmail.com  Tue Mar 22 04:09:29 2011
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 21 Mar 2011 23:09:29 -0400
Subject: [Rd] R-alpha typo in ?replicate ?
Message-ID: <4D8812E9.5030801@ufl.edu>


  simplify: logical or character string; should the result be simplified
          to a vector, matrix or higher dimensional array if possible?
          The default, ?TRUE?, returns a vector or matrix if
          appropriate, whereas ?signify = "array"?, rather recommended
          typically, the result may be an ?array? of ?rank?
          (=?length(dim(.))?) one higher than the result of
          ?FUN(X[[i]])?.

  Should this read

   ...  whereas if 'simplify="array"', typically recommended, the result ...

  ?

  Also, ?scan says:

multi.line: logical. Only used if ?what? is a list.  If ?FALSE?, all of
          a record must appear on one line (but more than one record
          can appear on a single line).  Note that using ?fill = TRUE?
          implies that a record will terminated at the end of a line.

  I think a "be" is missing between "will" and "terminated"


From mtmorgan at fhcrc.org  Tue Mar 22 04:07:45 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Mon, 21 Mar 2011 20:07:45 -0700
Subject: [Rd] R_HOME path getting munged in inst/doc/Makefile on Windows
In-Reply-To: <B6C2277E-8D69-491C-87B4-C8EF26C04D7D@r-project.org>
References: <AANLkTimOzb6Y4biwP9dCaT6goxyjXB7rgLhsnv3SMxjA@mail.gmail.com>
	<B6C2277E-8D69-491C-87B4-C8EF26C04D7D@r-project.org>
Message-ID: <4D881281.309@fhcrc.org>

On 03/21/2011 07:22 PM, Simon Urbanek wrote:
>
> On Mar 21, 2011, at 9:07 PM, Dan Tenenbaum wrote:
>
>> Hello,
>>
>> I have come across two separate packages that have a Makefile in inst/doc
>> which use the R_HOME variable.
>>
>> In both cases, the path to R_HOME gets munged in such a way that commands
>> that include R_HOME fail on Windows:
>>
>> For example, one Makefile, for the xmapcore package (
>> https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/xmapcore/username/password:
>> readonly) has this:
>>
>> R=${R_HOME}/bin/R
>> SUITE=../cookbook/delia.R
>> [...]
>> ${R} --vanilla --verbose<  ${SUITE}
>>
>> the output of trying to build this package includes:
>>
>> * creating vignettes ... ERROR
>> E:\biocbld\BBS-2~1.8-B\R/bin/R --vanilla --verbose<  ../cookbook/delia.R
>> E:biocbldBBS-2~1.8-BR/bin/R: not found
>> make: *** [pdf] Error 127
>> Error in tools::buildVignettes(dir = ".") : running 'make' failed
>> Execution halted
>>
>> It seems R_HOME is not getting resolved to a valid path. That's strange
>> because R CMD echo shows the right thing:
>>
>> E:\sandbox>\biocbld\bbs-2.8-bioc\R\bin\R CMD echo %R_HOME%
>> e:/biocbld/bbs-2.8-bioc/R
>>
>> That's a nice path with all forward slashes and no funny 8.3 paths with
>> tildes.  But it looks like when R_HOME is invoked in a Makefile, the
>> resulting path has a mix of forward and backslashes,
>
> Nope, at least not in R from CRAN:
>
> Makevars:
> all:
> 	echo R_HOME: $(R_HOME)
>
> [...]
> echo R_HOME: c:/PROGRA~1/R/R-212~1.2
> R_HOME: c:/PROGRA~1/R/R-212~1.2
>
> But I see that you have custom rhome setting (BBS...) so changes are that is the culprit - the rhome for that R build is set incorrectly to contain backslashes.

Not sure about the Makefile, but see

https://stat.ethz.ch/pipermail/r-devel/2011-March/060260.html

also on my own machine

Z:\> R CMD INSTALL Biobase
* installing to library 'C:\Users\User\Documents/R/win-library/2.13'
* installing *source* package 'Biobase' ...
...

** testing if installed package can be loaded
Error: '\U' used without hex digits in character string starting "C:\U"
Execution halted
ERROR: loading failed
* removing 'C:\Users\User\Documents/R/win-library/2.13/Biobase'
* restoring previous 'C:\Users\User\Documents/R/win-library/2.13/Rsamtools'

whereas under 2.12

Z:\>R CMD INSTALL Biobase
* installing to library 'C:\Users\User\Documents/R/win-library/2.12'
* installing *source* package 'Biobase' ...

and everything is fine.

Z:\> R --version
R version 2.13.0 alpha (2011-03-17 r54849)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

>
> Cheers,
> Simon
>
>
>
>
>> and gets translated
>> into 8.3 style, and the resulting path is not valid for finding R
>> executables.
>>
>> Note that R_HOME is defined within R; I don't also have it defined at the
>> shell level:
>>
>> E:\sandbox>echo %R_HOME%
>> %R_HOME%
>>
>> Any ideas?
>> Thanks,
>> Dan
>>
>>> sessionInfo()
>> R version 2.13.0 alpha (2011-03-18 r54865)
>> Platform: i386-pc-mingw32/i386 (32-bit)
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252
>> [2] LC_CTYPE=English_United States.1252
>> [3] LC_MONETARY=English_United States.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From ripley at stats.ox.ac.uk  Tue Mar 22 07:19:34 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 22 Mar 2011 06:19:34 +0000 (GMT)
Subject: [Rd] R_HOME path getting munged in inst/doc/Makefile on Windows
In-Reply-To: <AANLkTimOzb6Y4biwP9dCaT6goxyjXB7rgLhsnv3SMxjA@mail.gmail.com>
References: <AANLkTimOzb6Y4biwP9dCaT6goxyjXB7rgLhsnv3SMxjA@mail.gmail.com>
Message-ID: <alpine.LFD.2.02.1103220614180.8567@gannet.stats.ox.ac.uk>

This is a bug in the package: you are required to quote paths in
Makefiles, e.g. to allow for spaces in the path.

And let's knock the issue of forward and backwards slashes on the 
head: they are equivalent on Windows.  Despite your perjorative 
comments, the supplied value of R_HOME is valid.

On Mon, 21 Mar 2011, Dan Tenenbaum wrote:

> Hello,
>
> I have come across two separate packages that have a Makefile in inst/doc
> which use the R_HOME variable.
>
> In both cases, the path to R_HOME gets munged in such a way that commands
> that include R_HOME fail on Windows:
>
> For example, one Makefile, for the xmapcore package (
> https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/xmapcore/username/password:
> readonly) has this:
>
> R=${R_HOME}/bin/R
> SUITE=../cookbook/delia.R
> [...]
> ${R} --vanilla --verbose < ${SUITE}
>
> the output of trying to build this package includes:
>
> * creating vignettes ... ERROR
> E:\biocbld\BBS-2~1.8-B\R/bin/R --vanilla --verbose < ../cookbook/delia.R
> E:biocbldBBS-2~1.8-BR/bin/R: not found
> make: *** [pdf] Error 127
> Error in tools::buildVignettes(dir = ".") : running 'make' failed
> Execution halted
>
> It seems R_HOME is not getting resolved to a valid path. That's strange
> because R CMD echo shows the right thing:
>
> E:\sandbox>\biocbld\bbs-2.8-bioc\R\bin\R CMD echo %R_HOME%
> e:/biocbld/bbs-2.8-bioc/R
>
> That's a nice path with all forward slashes and no funny 8.3 paths with
> tildes.  But it looks like when R_HOME is invoked in a Makefile, the
> resulting path has a mix of forward and backslashes, and gets translated
> into 8.3 style, and the resulting path is not valid for finding R
> executables.
>
> Note that R_HOME is defined within R; I don't also have it defined at the
> shell level:
>
> E:\sandbox>echo %R_HOME%
> %R_HOME%
>
> Any ideas?
> Thanks,
> Dan
>
>> sessionInfo()
> R version 2.13.0 alpha (2011-03-18 r54865)
> Platform: i386-pc-mingw32/i386 (32-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Tue Mar 22 08:41:48 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 22 Mar 2011 08:41:48 +0100
Subject: [Rd] texi2dvi / egrep issue shows (a.o.) up in R-alpha
In-Reply-To: <4D87D50D.60506@openanalytics.eu>
References: <4D87D50D.60506@openanalytics.eu>
Message-ID: <19848.21180.650010.979864@stat.math.ethz.ch>

>>>>> Tobias Verbeke <tobias.verbeke at openanalytics.eu>
>>>>>     on Mon, 21 Mar 2011 23:45:33 +0100 writes:

    > L.S.  I noticed weird tools::texi2dvi behaviour on R-alpha
    > when specifying an absolute path to the .tex file.

    > The same phenomenon also appears to occur on R-2.12.2, so
    > maybe the issue is independent of R.

Yes. I think it's independent of R.

In any case, there's been a bug in the (Unix/Linux/teTeX/....)
texi2dvi  sh script, 
a bug which I think typically only bites if you work in non-ASCII
locales -- as you and I, eg.

Here's the patch that I have had in place for quite a while :

MM at lynne$ diff -ubBw  /usr/bin/texi2dvi /usr/local/bin/scripts/texi2dvi
--- /usr/bin/texi2dvi	2011-01-11 15:33:52.000000000 +0100
+++ /usr/local/bin/scripts/texi2dvi	2010-07-09 08:32:36.000025000 +0200
@@ -33,7 +33,7 @@
 set -e
 
 # This string is expanded by rcs automatically when this file is checked out.
-rcs_revision='$Revision: 1.135 $'
+rcs_revision='$Revision: 1.135__mod.SfS_ETHZ $'
 rcs_version=`set - $rcs_revision; echo $2`
 program=`echo $0 | sed -e 's!.*/!!'`
 
@@ -1683,7 +1683,7 @@
 
   # If the COMMAND_LINE_FILENAME is not absolute (e.g., --debug.tex),
   # prepend `./' in order to avoid that the tools take it as an option.
-  echo "$command_line_filename" | $EGREP '^(/|[A-Za-z]:/)' >&6 \
+  echo "$command_line_filename" | $EGREP '^(/|[[:alpha:]]:/)' >&6 \
   || command_line_filename="./$command_line_filename"
 
   # See if the file exists.  If it doesn't we're in trouble since, even
MM at lynne$

Best regards,
Martin


From maechler at stat.math.ethz.ch  Tue Mar 22 09:07:45 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 22 Mar 2011 09:07:45 +0100
Subject: [Rd] R-alpha typo in ?replicate ?
In-Reply-To: <4D8812E9.5030801@ufl.edu>
References: <4D8812E9.5030801@ufl.edu>
Message-ID: <19848.22737.944413.878315@stat.math.ethz.ch>

Thank you, 
Ben.

I'm committing the fixes.
Martin

>>>>> Ben Bolker <bbolker at gmail.com>
>>>>>     on Mon, 21 Mar 2011 23:09:29 -0400 writes:

    >   simplify: logical or character string; should the result
    > be simplified to a vector, matrix or higher dimensional
    > array if possible?  The default, ?TRUE?, returns a vector
    > or matrix if appropriate, whereas ?signify = "array"?,
    > rather recommended typically, the result may be an ?array?
    > of ?rank? (=?length(dim(.))?) one higher than the result
    > of ?FUN(X[[i]])?.

    >   Should this read

    >    ...  whereas if 'simplify="array"', typically
    > recommended, the result ...

    >   ?

    >   Also, ?scan says:

    > multi.line: logical. Only used if ?what? is a list.  If
    > ?FALSE?, all of a record must appear on one line (but more
    > than one record can appear on a single line).  Note that
    > using ?fill = TRUE? implies that a record will terminated
    > at the end of a line.

    >   I think a "be" is missing between "will" and
    > "terminated"


From tobias.verbeke at openanalytics.eu  Tue Mar 22 09:40:08 2011
From: tobias.verbeke at openanalytics.eu (Tobias Verbeke)
Date: Tue, 22 Mar 2011 09:40:08 +0100
Subject: [Rd] texi2dvi / egrep issue shows (a.o.) up in R-alpha
In-Reply-To: <19848.21180.650010.979864@stat.math.ethz.ch>
References: <4D87D50D.60506@openanalytics.eu>
	<19848.21180.650010.979864@stat.math.ethz.ch>
Message-ID: <4D886068.1070907@openanalytics.eu>

On 03/22/2011 08:41 AM, Martin Maechler wrote:
>>>>>> Tobias Verbeke<tobias.verbeke at openanalytics.eu>
>>>>>>      on Mon, 21 Mar 2011 23:45:33 +0100 writes:
>
>      >  L.S.  I noticed weird tools::texi2dvi behaviour on R-alpha
>      >  when specifying an absolute path to the .tex file.
>
>      >  The same phenomenon also appears to occur on R-2.12.2, so
>      >  maybe the issue is independent of R.
>
> Yes. I think it's independent of R.
>
> In any case, there's been a bug in the (Unix/Linux/teTeX/....)
> texi2dvi  sh script,
> a bug which I think typically only bites if you work in non-ASCII
> locales -- as you and I, eg.
>
> Here's the patch that I have had in place for quite a while :
>
> MM at lynne$ diff -ubBw  /usr/bin/texi2dvi /usr/local/bin/scripts/texi2dvi
> --- /usr/bin/texi2dvi	2011-01-11 15:33:52.000000000 +0100
> +++ /usr/local/bin/scripts/texi2dvi	2010-07-09 08:32:36.000025000 +0200
> @@ -33,7 +33,7 @@
>   set -e
>
>   # This string is expanded by rcs automatically when this file is checked out.
> -rcs_revision='$Revision: 1.135 $'
> +rcs_revision='$Revision: 1.135__mod.SfS_ETHZ $'
>   rcs_version=`set - $rcs_revision; echo $2`
>   program=`echo $0 | sed -e 's!.*/!!'`
>
> @@ -1683,7 +1683,7 @@
>
>     # If the COMMAND_LINE_FILENAME is not absolute (e.g., --debug.tex),
>     # prepend `./' in order to avoid that the tools take it as an option.
> -  echo "$command_line_filename" | $EGREP '^(/|[A-Za-z]:/)'>&6 \
> +  echo "$command_line_filename" | $EGREP '^(/|[[:alpha:]]:/)'>&6 \
>     || command_line_filename="./$command_line_filename"
>
>     # See if the file exists.  If it doesn't we're in trouble since, even
> MM at lynne$

Many thanks, Martin. That was indeed the issue and the patch
works perfectly fine.

Kind regards,
Tobias


From ripley at stats.ox.ac.uk  Tue Mar 22 10:02:58 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 22 Mar 2011 09:02:58 +0000 (GMT)
Subject: [Rd] texi2dvi / egrep issue shows (a.o.) up in R-alpha
In-Reply-To: <4D886068.1070907@openanalytics.eu>
References: <4D87D50D.60506@openanalytics.eu>
	<19848.21180.650010.979864@stat.math.ethz.ch>
	<4D886068.1070907@openanalytics.eu>
Message-ID: <alpine.LFD.2.02.1103220901470.2593@gannet.stats.ox.ac.uk>

After some offline checks, another workaround is to set LC_COLLATE=C, 
and we'll arrange for tools::texi2dvi() to do that.

On Tue, 22 Mar 2011, Tobias Verbeke wrote:

> On 03/22/2011 08:41 AM, Martin Maechler wrote:
>>>>>>> Tobias Verbeke<tobias.verbeke at openanalytics.eu>
>>>>>>>      on Mon, 21 Mar 2011 23:45:33 +0100 writes:
>>
>>      >  L.S.  I noticed weird tools::texi2dvi behaviour on R-alpha
>>      >  when specifying an absolute path to the .tex file.
>>
>>      >  The same phenomenon also appears to occur on R-2.12.2, so
>>      >  maybe the issue is independent of R.
>> 
>> Yes. I think it's independent of R.
>> 
>> In any case, there's been a bug in the (Unix/Linux/teTeX/....)
>> texi2dvi  sh script,
>> a bug which I think typically only bites if you work in non-ASCII
>> locales -- as you and I, eg.
>> 
>> Here's the patch that I have had in place for quite a while :
>> 
>> MM at lynne$ diff -ubBw  /usr/bin/texi2dvi /usr/local/bin/scripts/texi2dvi
>> --- /usr/bin/texi2dvi	2011-01-11 15:33:52.000000000 +0100
>> +++ /usr/local/bin/scripts/texi2dvi	2010-07-09 08:32:36.000025000 +0200
>> @@ -33,7 +33,7 @@
>>   set -e
>>
>>   # This string is expanded by rcs automatically when this file is checked 
>> out.
>> -rcs_revision='$Revision: 1.135 $'
>> +rcs_revision='$Revision: 1.135__mod.SfS_ETHZ $'
>>   rcs_version=`set - $rcs_revision; echo $2`
>>   program=`echo $0 | sed -e 's!.*/!!'`
>> 
>> @@ -1683,7 +1683,7 @@
>>
>>     # If the COMMAND_LINE_FILENAME is not absolute (e.g., --debug.tex),
>>     # prepend `./' in order to avoid that the tools take it as an option.
>> -  echo "$command_line_filename" | $EGREP '^(/|[A-Za-z]:/)'>&6 \
>> +  echo "$command_line_filename" | $EGREP '^(/|[[:alpha:]]:/)'>&6 \
>>     || command_line_filename="./$command_line_filename"
>>
>>     # See if the file exists.  If it doesn't we're in trouble since, even
>> MM at lynne$
>
> Many thanks, Martin. That was indeed the issue and the patch
> works perfectly fine.
>
> Kind regards,
> Tobias
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From dtenenba at fhcrc.org  Tue Mar 22 16:02:01 2011
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Tue, 22 Mar 2011 08:02:01 -0700
Subject: [Rd] R_HOME path getting munged in inst/doc/Makefile on Windows
In-Reply-To: <alpine.LFD.2.02.1103220614180.8567@gannet.stats.ox.ac.uk>
References: <AANLkTimOzb6Y4biwP9dCaT6goxyjXB7rgLhsnv3SMxjA@mail.gmail.com>
	<alpine.LFD.2.02.1103220614180.8567@gannet.stats.ox.ac.uk>
Message-ID: <AANLkTimzcbU8zJiOcxZOZiCjcd17d5rrdUfZe7-cPYcV@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110322/8518e812/attachment.pl>

From lorang at gmail.com  Tue Mar 22 20:45:12 2011
From: lorang at gmail.com (Noah Lorang)
Date: Tue, 22 Mar 2011 15:45:12 -0400
Subject: [Rd] Suggestion: quote POSIXlt and POSIXct in write.table()
Message-ID: <07B73489-791C-44DA-8746-4C678C2DC52B@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110322/c1b21a56/attachment.pl>

From sbm at enfor.dk  Wed Mar 23 09:37:17 2011
From: sbm at enfor.dk (Stig B. Mortensen)
Date: Wed, 23 Mar 2011 09:37:17 +0100 (CET)
Subject: [Rd] Suggestion: "kill -USR1 pid" should respect --no-save option
Message-ID: <774849316.6707.1300869437772.JavaMail.root@external>

If R is killed with "kill -USR1 pid" it will terminate and save its workspace overwriting any exiting .RData-file even if R has been started with the --no-save option. Preferably R should always respect the --no-save option and this should thus be used to determine if the workspace is saved when receiving the USR1 signal.

The following change will adopt this behavior (based on R-2.12.2 source).

$RHOME/src/main/errors.c, line 147
-    R_CleanUp(SA_SAVE, 2, 1); /* quit, save,  .Last, status=2 */
+    R_CleanUp(SA_DEFAULT, 2, 1); /* quit, save,  .Last, status=2 */

$RHOME/src/main/errors.c, line 197
-    R_CleanUp(SA_NOSAVE, 0, 0);
+    R_CleanUp(SA_DEFAULT, 0, 0);

The documentation in $RHOME/src/library/base/man/unix/Signals.Rd should also be updated accordingly.

To my knowledge it is not possible to send a USR1/USR2 signal on windows so this issue is only relevant on POSIX compliant systems.

Best regards,
Stig B. Mortensen


From Sebastian.Meyer at med.uni-muenchen.de  Wed Mar 23 12:07:32 2011
From: Sebastian.Meyer at med.uni-muenchen.de (Meyer, Sebastian)
Date: Wed, 23 Mar 2011 12:07:32 +0100
Subject: [Rd] Sweave: multiple graphic formats, e.g. win.metafile
Message-ID: <36335A466E9D6641BC7260D521A9164A74CED57296@MITEX03N.helios.med.uni-muenchen.de>

Dear R devel,

being constrained to a windows environment at work and having colleagues being accustomed to the Microsoft Office Suite, I was looking for a way to have the RweaveLatex driver for Sweave automatically generating 'win.metafile's in addition to the pdf graphics.
Without this functionalilty, the generation of emf-graphics is quite laborious, I think:

<<>>=
plotit <- function () {
   # code which generates the graphic
}
win.metafile("foobar.emf")
plotit()
dev.off()
pdf("foobar.pdf")
plotit()
dev.off()
@
\includegraphics{foobar}


I would like to have something like:

<<foobar, fig=true, pdf=true, emf=true>>
# code which generates the graphic
@


SweaveHooks are not applicable for this feature. Therefore, I thought it would be best to extend the typical 'RweaveLatex' driver by an option 'emf' - like eps and pdf. So, here is the result of some handicrafts:

RweaveLatexEMF <- function ()
{
	# add option emf (= FALSE) and set default for eps to FALSE
	setup <- utils::RweaveLatexSetup
	setupsrc <- deparse(setup)
	epsline <- grep("eps", setupsrc)
	setupsrc[epsline] <- sub("eps = TRUE", "eps = FALSE, emf = FALSE", setupsrc[epsline])
	setup <- eval(parse(text=setupsrc))
	
	# 'makeRweaveLatexCodeRunner' function
	makeruncode <- function(evalFunc=utils::RweaveEvalWithOpt) {
		runcode <- utils:::RweaveLatexRuncode
		runcodesrc <- deparse(runcode)
		epsline1 <- grep("cat(.. eps..)", runcodesrc)
		runcodesrc <- append(runcodesrc, "            if (options$emf) cat(\" emf\")", after=epsline1)
		epsline2 <- grep("options\\$fig && options\\$eval", runcodesrc)
		runcodesrc <- append(runcodesrc, 
			deparse(quote(
				if (options$emf && .Platform$OS.type == "windows") {
		            grDevices::win.metafile(file=paste(chunkprefix, "emf", sep="."),
					                        width=options$width, height=options$height)
		            err <- try({SweaveHooks(options, run=TRUE)
		                        eval(chunkexps, envir=.GlobalEnv)})
		            grDevices::dev.off()
		            if(inherits(err, "try-error")) stop(err)
		        }
			))
		, after=epsline2)
		runcode <- eval(parse(text=runcodesrc))
	}
	runcode <- makeruncode()
	
	list(setup = setup, runcode = runcode, 
        writedoc = utils::RweaveLatexWritedoc, finish = utils::RweaveLatexFinish, 
        checkopts = utils::RweaveLatexOptions)
}


This enhanced Sweave driver works for me like a charm, but it is a very poor solution.
What about allowing for all available grDevices on the current platform - besides the standard eps and pdf devices? The only building block is the section "if (options$fig && options$eval)" in utils:::makeRweaveLatexCodeRunner. The TODO list of Seth Falcon's weaver package also states "For Sweave: multiple graphic formats besides just pdf and eps (perhaps
as a separate driver?)".
However, since so many packages depend on the basic Sweave implementation by Fritz Leisch, I don't know if there is an easy route to tackle.

Looking forward to your opinions and pointers.
Best regards,
  Sebastian Meyer


From ripley at stats.ox.ac.uk  Wed Mar 23 13:05:01 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 23 Mar 2011 12:05:01 +0000 (GMT)
Subject: [Rd] Sweave: multiple graphic formats, e.g. win.metafile
In-Reply-To: <36335A466E9D6641BC7260D521A9164A74CED57296@MITEX03N.helios.med.uni-muenchen.de>
References: <36335A466E9D6641BC7260D521A9164A74CED57296@MITEX03N.helios.med.uni-muenchen.de>
Message-ID: <alpine.LFD.2.02.1103231203450.22049@gannet.stats.ox.ac.uk>

We are currently in the process of implementing PNG and JPEG for 
2.13.0, and an extensible architecture is planned for 2.14.0.

On Wed, 23 Mar 2011, Meyer, Sebastian wrote:

> Dear R devel,
>
> being constrained to a windows environment at work and having colleagues being accustomed to the Microsoft Office Suite, I was looking for a way to have the RweaveLatex driver for Sweave automatically generating 'win.metafile's in addition to the pdf graphics.
> Without this functionalilty, the generation of emf-graphics is quite laborious, I think:
>
> <<>>=
> plotit <- function () {
>   # code which generates the graphic
> }
> win.metafile("foobar.emf")
> plotit()
> dev.off()
> pdf("foobar.pdf")
> plotit()
> dev.off()
> @
> \includegraphics{foobar}
>
>
> I would like to have something like:
>
> <<foobar, fig=true, pdf=true, emf=true>>
> # code which generates the graphic
> @
>
>
> SweaveHooks are not applicable for this feature. Therefore, I thought it would be best to extend the typical 'RweaveLatex' driver by an option 'emf' - like eps and pdf. So, here is the result of some handicrafts:
>
> RweaveLatexEMF <- function ()
> {
> 	# add option emf (= FALSE) and set default for eps to FALSE
> 	setup <- utils::RweaveLatexSetup
> 	setupsrc <- deparse(setup)
> 	epsline <- grep("eps", setupsrc)
> 	setupsrc[epsline] <- sub("eps = TRUE", "eps = FALSE, emf = FALSE", setupsrc[epsline])
> 	setup <- eval(parse(text=setupsrc))
>
> 	# 'makeRweaveLatexCodeRunner' function
> 	makeruncode <- function(evalFunc=utils::RweaveEvalWithOpt) {
> 		runcode <- utils:::RweaveLatexRuncode
> 		runcodesrc <- deparse(runcode)
> 		epsline1 <- grep("cat(.. eps..)", runcodesrc)
> 		runcodesrc <- append(runcodesrc, "            if (options$emf) cat(\" emf\")", after=epsline1)
> 		epsline2 <- grep("options\\$fig && options\\$eval", runcodesrc)
> 		runcodesrc <- append(runcodesrc,
> 			deparse(quote(
> 				if (options$emf && .Platform$OS.type == "windows") {
> 		            grDevices::win.metafile(file=paste(chunkprefix, "emf", sep="."),
> 					                        width=options$width, height=options$height)
> 		            err <- try({SweaveHooks(options, run=TRUE)
> 		                        eval(chunkexps, envir=.GlobalEnv)})
> 		            grDevices::dev.off()
> 		            if(inherits(err, "try-error")) stop(err)
> 		        }
> 			))
> 		, after=epsline2)
> 		runcode <- eval(parse(text=runcodesrc))
> 	}
> 	runcode <- makeruncode()
>
> 	list(setup = setup, runcode = runcode,
>        writedoc = utils::RweaveLatexWritedoc, finish = utils::RweaveLatexFinish,
>        checkopts = utils::RweaveLatexOptions)
> }
>
>
> This enhanced Sweave driver works for me like a charm, but it is a very poor solution.
> What about allowing for all available grDevices on the current platform - besides the standard eps and pdf devices? The only building block is the section "if (options$fig && options$eval)" in utils:::makeRweaveLatexCodeRunner. The TODO list of Seth Falcon's weaver package also states "For Sweave: multiple graphic formats besides just pdf and eps (perhaps
> as a separate driver?)".
> However, since so many packages depend on the basic Sweave implementation by Fritz Leisch, I don't know if there is an easy route to tackle.
>
> Looking forward to your opinions and pointers.
> Best regards,
>  Sebastian Meyer
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From cbeleites at units.it  Wed Mar 23 14:37:21 2011
From: cbeleites at units.it (Claudia Beleites)
Date: Wed, 23 Mar 2011 14:37:21 +0100
Subject: [Rd] Sweave: multiple graphic formats, e.g. win.metafile
In-Reply-To: <alpine.LFD.2.02.1103231203450.22049@gannet.stats.ox.ac.uk>
References: <36335A466E9D6641BC7260D521A9164A74CED57296@MITEX03N.helios.med.uni-muenchen.de>
	<alpine.LFD.2.02.1103231203450.22049@gannet.stats.ox.ac.uk>
Message-ID: <4D89F791.80901@units.it>

On 03/23/2011 01:05 PM, Prof Brian Ripley wrote:
> We are currently in the process of implementing PNG and JPEG for 2.13.0, and an
> extensible architecture is planned for 2.14.0.
:-) this is really good news :-)


Thank you!


-- 
Claudia Beleites
DI3
Universit? degli Studi di Trieste
Via Alfonso Valerio 6/a
I-34127 Trieste

phone: +39 0 40 5 58-37 68
email: cbeleites at units.it


From friendly at yorku.ca  Wed Mar 23 15:03:08 2011
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 23 Mar 2011 10:03:08 -0400
Subject: [Rd] system.file() to read a text file from a vignette
Message-ID: <4D89FD9C.7060906@yorku.ca>

[Env: R 2.12.2, WinXp]

In a vignette for the vcdExtra package, I had a text file, tv.dat under 
data/, that I used in the vignette as

<<tv1,results=verbatim>>=
tv.data<-read.table(system.file("data","tv.dat",package="vcdExtra"))
head(tv.data,5)
@

I was told that this now generates a warning for non-Rdata files in R 
CMD check. But I'm now confused about
where to put this and how to use system.file() in the vignette to read 
it. The R-exts.pdf says

The R working directory for all vignette tests in R CMD
check is the installed version of the ?doc? subdirectory. Make sure all 
files needed by the vignette
(data sets, . . . ) are accessible by either placing them in the 
?inst/doc? hierarchy of the source
package, or using calls to system.file().

So, I moved this file to inst/doc/extdata/tv.dat, and changed the 
vignette to

<<tv1,results=verbatim>>=
tv.data<-read.table(system.file("inst","doc","extdata","tv.dat",package="vcdExtra"))
head(tv.data,5)
@

But I get the error:
Error: processing vignette 'vcd-tutorial.Rnw' failed with diagnostics:
chunk 23 (label=tv1)
Error in read.table(system.file("inst", "doc", "extdata", "tv.dat", 
package = "vcdExtra")) :
no lines available in input

How can I fix this?

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From tobias.verbeke at openanalytics.eu  Wed Mar 23 15:20:23 2011
From: tobias.verbeke at openanalytics.eu (Tobias Verbeke)
Date: Wed, 23 Mar 2011 15:20:23 +0100
Subject: [Rd] system.file() to read a text file from a vignette
In-Reply-To: <4D89FD9C.7060906@yorku.ca>
References: <4D89FD9C.7060906@yorku.ca>
Message-ID: <4D8A01A7.2070303@openanalytics.eu>

Hi Michael,

On 03/23/2011 03:03 PM, Michael Friendly wrote:
> [Env: R 2.12.2, WinXp]
>
> In a vignette for the vcdExtra package, I had a text file, tv.dat under
> data/, that I used in the vignette as
>
> <<tv1,results=verbatim>>=
> tv.data<-read.table(system.file("data","tv.dat",package="vcdExtra"))
> head(tv.data,5)
> @
>
> I was told that this now generates a warning for non-Rdata files in R
> CMD check. But I'm now confused about
> where to put this and how to use system.file() in the vignette to read
> it. The R-exts.pdf says
>
> The R working directory for all vignette tests in R CMD
> check is the installed version of the ?doc? subdirectory. Make sure all
> files needed by the vignette
> (data sets, . . . ) are accessible by either placing them in the
> ?inst/doc? hierarchy of the source
> package, or using calls to system.file().
>
> So, I moved this file to inst/doc/extdata/tv.dat, and changed the
> vignette to
>
> <<tv1,results=verbatim>>=
> tv.data<-read.table(system.file("inst","doc","extdata","tv.dat",package="vcdExtra"))
>
> head(tv.data,5)
> @
>
> But I get the error:
> Error: processing vignette 'vcd-tutorial.Rnw' failed with diagnostics:
> chunk 23 (label=tv1)
> Error in read.table(system.file("inst", "doc", "extdata", "tv.dat",
> package = "vcdExtra")) :
> no lines available in input
>
> How can I fix this?

The inst/ will be removed once the package is installed, so you
would need

system.file("doc", "extdata", "tv.dat", package = "vcdExtra")

The warning on non Rdata files is probably due to the fact that
.dat is not supported, see Section 1.1.5 of Writing R Extensions
and ?data

Best,
Tobias


From murdoch.duncan at gmail.com  Wed Mar 23 15:21:53 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 23 Mar 2011 10:21:53 -0400
Subject: [Rd] system.file() to read a text file from a vignette
In-Reply-To: <4D89FD9C.7060906@yorku.ca>
References: <4D89FD9C.7060906@yorku.ca>
Message-ID: <4D8A0201.5030804@gmail.com>

On 23/03/2011 10:03 AM, Michael Friendly wrote:
> [Env: R 2.12.2, WinXp]
>
> In a vignette for the vcdExtra package, I had a text file, tv.dat under
> data/, that I used in the vignette as
>
> <<tv1,results=verbatim>>=
> tv.data<-read.table(system.file("data","tv.dat",package="vcdExtra"))
> head(tv.data,5)
> @
>
> I was told that this now generates a warning for non-Rdata files in R
> CMD check. But I'm now confused about
> where to put this and how to use system.file() in the vignette to read
> it. The R-exts.pdf says
>
> The R working directory for all vignette tests in R CMD
> check is the installed version of the ?doc? subdirectory. Make sure all
> files needed by the vignette
> (data sets, . . . ) are accessible by either placing them in the
> ?inst/doc? hierarchy of the source
> package, or using calls to system.file().
>
> So, I moved this file to inst/doc/extdata/tv.dat, and changed the
> vignette to
>
> <<tv1,results=verbatim>>=
> tv.data<-read.table(system.file("inst","doc","extdata","tv.dat",package="vcdExtra"))
> head(tv.data,5)
> @
>
> But I get the error:
> Error: processing vignette 'vcd-tutorial.Rnw' failed with diagnostics:
> chunk 23 (label=tv1)
> Error in read.table(system.file("inst", "doc", "extdata", "tv.dat",
> package = "vcdExtra")) :
> no lines available in input
>
> How can I fix this?

Everything in the "inst" directory is moved up a level when it is 
installed.  So you shouldn't mention "inst" in its path.

Duncan Murdoch


From friendly at yorku.ca  Wed Mar 23 15:35:47 2011
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 23 Mar 2011 10:35:47 -0400
Subject: [Rd] system.file() to read a text file from a vignette
In-Reply-To: <4D8A0201.5030804@gmail.com>
References: <4D89FD9C.7060906@yorku.ca> <4D8A0201.5030804@gmail.com>
Message-ID: <4D8A0543.4050401@yorku.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110323/2af83d8d/attachment.pl>

From m.c.vernon at warwick.ac.uk  Wed Mar 23 16:35:21 2011
From: m.c.vernon at warwick.ac.uk (Matthew Vernon)
Date: Wed, 23 Mar 2011 15:35:21 +0000
Subject: [Rd] argument handling in boot.ci
Message-ID: <4D8A1339.4070307@warwick.ac.uk>

Hi,

boot.ci fails to check if the "type" argument is valid or not. This 
tripped me up when I had a script that called boot.ci(type="normal",...) 
repeatedly - only later when I tried to do some further analysis did I 
realise I'd got nothing useful back from boot.ci.

It strikes me that this behaviour is probably incorrect, and that 
boot.ci should stop if the "type" argument (or, indeed, any other 
supplied argument) is invalid. Am I correct?

Regards,

Matthew

-- 
Matthew Vernon, Research Fellow
Ecology and Epidemiology Group,
University of Warwick
http://blogs.warwick.ac.uk/mcvernon


From murdoch.duncan at gmail.com  Wed Mar 23 19:00:55 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 23 Mar 2011 14:00:55 -0400
Subject: [Rd] argument handling in boot.ci
In-Reply-To: <4D8A1339.4070307@warwick.ac.uk>
References: <4D8A1339.4070307@warwick.ac.uk>
Message-ID: <4D8A3557.1000705@gmail.com>

On 23/03/2011 11:35 AM, Matthew Vernon wrote:
> Hi,
>
> boot.ci fails to check if the "type" argument is valid or not. This
> tripped me up when I had a script that called boot.ci(type="normal",...)
> repeatedly - only later when I tried to do some further analysis did I
> realise I'd got nothing useful back from boot.ci.
>
> It strikes me that this behaviour is probably incorrect, and that
> boot.ci should stop if the "type" argument (or, indeed, any other
> supplied argument) is invalid. Am I correct?


boot.ci is in a contributed package (it's "Recommended", which means 
that a copy is distributed with R, but it is not part of R), so 
suggestions should go to the maintainer.  But you need to put together a 
simple example to illustrate the problem.  When I modify the first 
example in example(boot.ci) to specify type="normal", I get an error 
message.

Duncan Murdoch


From Greg.Snow at imail.org  Wed Mar 23 19:08:49 2011
From: Greg.Snow at imail.org (Greg Snow)
Date: Wed, 23 Mar 2011 12:08:49 -0600
Subject: [Rd] Sweave: multiple graphic formats, e.g. win.metafile
In-Reply-To: <36335A466E9D6641BC7260D521A9164A74CED57296@MITEX03N.helios.med.uni-muenchen.de>
References: <36335A466E9D6641BC7260D521A9164A74CED57296@MITEX03N.helios.med.uni-muenchen.de>
Message-ID: <B37C0A15B8FB3C468B5BC7EBC7DA14CC63454A3CC9@LP-EXMBVS10.CO.IHC.COM>

You might consider using odfWeave, then you can create a single document, save it as a word doc, and send it to collaborators where they can then cut and paste from the word doc to whatever they are using.

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
801.408.8111


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
> project.org] On Behalf Of Meyer, Sebastian
> Sent: Wednesday, March 23, 2011 5:08 AM
> To: 'r-devel at r-project.org'
> Cc: 'Friedrich.Leisch at lmu.de'
> Subject: [Rd] Sweave: multiple graphic formats, e.g. win.metafile
> 
> Dear R devel,
> 
> being constrained to a windows environment at work and having
> colleagues being accustomed to the Microsoft Office Suite, I was
> looking for a way to have the RweaveLatex driver for Sweave
> automatically generating 'win.metafile's in addition to the pdf
> graphics.
> Without this functionalilty, the generation of emf-graphics is quite
> laborious, I think:
> 
> <<>>=
> plotit <- function () {
>    # code which generates the graphic
> }
> win.metafile("foobar.emf")
> plotit()
> dev.off()
> pdf("foobar.pdf")
> plotit()
> dev.off()
> @
> \includegraphics{foobar}
> 
> 
> I would like to have something like:
> 
> <<foobar, fig=true, pdf=true, emf=true>>
> # code which generates the graphic
> @
> 
> 
> SweaveHooks are not applicable for this feature. Therefore, I thought
> it would be best to extend the typical 'RweaveLatex' driver by an
> option 'emf' - like eps and pdf. So, here is the result of some
> handicrafts:
> 
> RweaveLatexEMF <- function ()
> {
> 	# add option emf (= FALSE) and set default for eps to FALSE
> 	setup <- utils::RweaveLatexSetup
> 	setupsrc <- deparse(setup)
> 	epsline <- grep("eps", setupsrc)
> 	setupsrc[epsline] <- sub("eps = TRUE", "eps = FALSE, emf =
> FALSE", setupsrc[epsline])
> 	setup <- eval(parse(text=setupsrc))
> 
> 	# 'makeRweaveLatexCodeRunner' function
> 	makeruncode <- function(evalFunc=utils::RweaveEvalWithOpt) {
> 		runcode <- utils:::RweaveLatexRuncode
> 		runcodesrc <- deparse(runcode)
> 		epsline1 <- grep("cat(.. eps..)", runcodesrc)
> 		runcodesrc <- append(runcodesrc, "            if
> (options$emf) cat(\" emf\")", after=epsline1)
> 		epsline2 <- grep("options\\$fig && options\\$eval",
> runcodesrc)
> 		runcodesrc <- append(runcodesrc,
> 			deparse(quote(
> 				if (options$emf && .Platform$OS.type ==
> "windows") {
> 		            grDevices::win.metafile(file=paste(chunkprefix,
> "emf", sep="."),
> 
> width=options$width, height=options$height)
> 		            err <- try({SweaveHooks(options, run=TRUE)
> 		                        eval(chunkexps, envir=.GlobalEnv)})
> 		            grDevices::dev.off()
> 		            if(inherits(err, "try-error")) stop(err)
> 		        }
> 			))
> 		, after=epsline2)
> 		runcode <- eval(parse(text=runcodesrc))
> 	}
> 	runcode <- makeruncode()
> 
> 	list(setup = setup, runcode = runcode,
>         writedoc = utils::RweaveLatexWritedoc, finish =
> utils::RweaveLatexFinish,
>         checkopts = utils::RweaveLatexOptions)
> }
> 
> 
> This enhanced Sweave driver works for me like a charm, but it is a very
> poor solution.
> What about allowing for all available grDevices on the current platform
> - besides the standard eps and pdf devices? The only building block is
> the section "if (options$fig && options$eval)" in
> utils:::makeRweaveLatexCodeRunner. The TODO list of Seth Falcon's
> weaver package also states "For Sweave: multiple graphic formats
> besides just pdf and eps (perhaps
> as a separate driver?)".
> However, since so many packages depend on the basic Sweave
> implementation by Fritz Leisch, I don't know if there is an easy route
> to tackle.
> 
> Looking forward to your opinions and pointers.
> Best regards,
>   Sebastian Meyer
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From lebatsnok at gmail.com  Wed Mar 23 20:21:32 2011
From: lebatsnok at gmail.com (Kenn Konstabel)
Date: Wed, 23 Mar 2011 19:21:32 +0000
Subject: [Rd] suggestions re trunc.POSIXt
Message-ID: <AANLkTinfd3jcNLTaz9Fb7wYP5=zEHUY3TK8XZN_Ho9FG@mail.gmail.com>

Dear all,

I hope this is a right place to post this; r-help might be appropriate
but it looks like I'm suggesting a change in base package, so I
decided to post here. (+ Apologies if that has been changed recently
-- the version I'm using is R.2.12.2 on Windows.)

I've noticed an unexpected behavior of trunc.POSIXt:

foo <- seq(as.POSIXct( "2009-10-23 22:00:00"), as.POSIXct("2009-10-26
22:00:00"), by="6 hours")
bar <- trunc(foo, "days")

Now class(bar)[1] returns "POSIXlt" although foo is POSIXct, and then
comes the following surprise:

length(foo)    # 13
length(as.POSIXlt(foo))  # still 13
length(bar)   # 1
length(as.POSIXct(bar))  # again 13

It would be nice if trunc would preserve the class as POSIXct, for
example, using
 trunc.POSIXct <- function(x, ...) as.POSIXct(trunc.POSIXt(x,...))

On the other hand, I noticed that

> sapply(bar, length)
#  sec   min  hour  mday   mon  year  wday  yday isdst
#   1     1     1    13    13    13    13    13     1

So trunc makes the first three elements shorter which also breaks
`[.POSIXlt` . This is also the reason why length(bar) returns 1 as it
just uses the length of first element. So I'd suggest changig this
too, replacing the lines like  x$sec <- 0  by x$sex[] <- 0 (the second
version would preserve the number of elements). (Changed version at
the end). It doesn't seem like this change could possibly break any
existing code.


Best regards,
Kenn

Kenn Konstabel
Department of Chronic Diseases
National Institute for Health Development
Hiiu 42
Tallinn, Estonia


######

trunc.POSIXt <- function (x, units = c("secs", "mins", "hours", "days"), ...)
{
# changed x$sec <- 0 to x$sec[]<-0 to preserve the number of elements
    units <- match.arg(units)
    x <- as.POSIXlt(x)
    if (length(x$sec))
        switch(units, secs = {
            x$sec <- trunc(x$sec)
        }, mins = {
            x$sec[] <- 0
        }, hours = {
            x$sec[] <- 0
            x$min[] <- 0L
        }, days = {
            x$sec[] <- 0
            x$min[] <- 0L
            x$hour[] <- 0L
            x$isdst <- -1L
        })
    x
}


From bbolker at gmail.com  Thu Mar 24 00:44:52 2011
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 23 Mar 2011 19:44:52 -0400
Subject: [Rd] import question
Message-ID: <4D8A85F4.1070507@gmail.com>


  I have been struggling all day to import a particular function/method
combination (ranef(), which extracts the random effects from a mixed
model fit) from the nlme package into another package ... so far without
success.

  The NAMESPACE for nlme contains the following lines:

export(..., ranef, ...)
S3method(ranef, lme)

  ranef is defined as a standard S3 generic,

function (object, ...)
   UseMethod("ranef")
<environment: namespace:nlme>

  I made up a minimal package, "raneftest" (which is available at
<http://www.math.mcmaster.ca/~bolker/misc/raneftest_0.001.tar.gz>)
that contains a single function, ranef.x(), which is supposed to be an
S3 method for class x ... its (trivial) definition is

ranef.x <- function(object, ...) {
   print("x")
}

the package has a NAMESPACE file:

-----------
exportPattern("^[^\\.]")

##importFrom(nlme,ranef)
import(nlme)
----------

(I've tried both import() and importFrom() -- I would prefer to use
importFrom() if I can ... I also tried importMethodsFrom(nlme,ranef) ,
but it fails -- it seems to be intended for S4 and not S3 methods?)

  The package also has a tests directory with a single file, which looks
like this:

  > library(raneftest)
  > x <- 1
  > class(x) <- "x"
  > ranef.x(x)
  [1] "x"
  > ranef(x)
  Error: could not find function "ranef"
  Execution halted

  I have read the relevant section of R-exts.pdf several times --
apologies in advance if I am doing something boneheaded.

  Does anyone have suggestions for what to try next ... ?

  cheers
    Ben Bolker


From bbolker at gmail.com  Thu Mar 24 01:20:40 2011
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 24 Mar 2011 00:20:40 +0000
Subject: [Rd] import question
References: <4D8A85F4.1070507@gmail.com>
Message-ID: <loom.20110324T011932-297@post.gmane.org>

Ben Bolker <bbolker <at> gmail.com> writes:

> 
> 
>   I have been struggling all day to import a particular function/method
> combination (ranef(), which extracts the random effects from a mixed
> model fit) from the nlme package into another package ... so far without
> success.
> 

  Answered my own question, finally.

  Apparently an explicit

export(ranef)

is required, even though there is also an

exportPattern("^[^\\.]")

in the NAMESPACE file, which I would have thought would
export 'ranef' along with everything else ... ?


From ripley at stats.ox.ac.uk  Thu Mar 24 05:30:31 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 24 Mar 2011 04:30:31 +0000
Subject: [Rd] import question
In-Reply-To: <loom.20110324T011932-297@post.gmane.org>
References: <4D8A85F4.1070507@gmail.com>
	<loom.20110324T011932-297@post.gmane.org>
Message-ID: <alpine.LFD.2.02.1103240417290.25247@gannet.stats.ox.ac.uk>

On Thu, 24 Mar 2011, Ben Bolker wrote:

> Ben Bolker <bbolker <at> gmail.com> writes:
>
>>
>>
>>   I have been struggling all day to import a particular function/method
>> combination (ranef(), which extracts the random effects from a mixed
>> model fit) from the nlme package into another package ... so far without
>> success.
>>
>
>  Answered my own question, finally.
>
>  Apparently an explicit
>
> export(ranef)
>
> is required, even though there is also an
>
> exportPattern("^[^\\.]")
>
> in the NAMESPACE file, which I would have thought would
> export 'ranef' along with everything else ... ?

It exports everything excpet dot-namesin the package's namespace. 
Imports are not in the namespace per se, but in the import environment 
(which is the enclosure of the namespace).  Here is the actual code:

         for (p in nsInfo$exportPatterns)
             exports <- c(ls(env, pattern = p, all.names = TRUE), exports)

So to re-export a function, you need to do so explicitly.

It is consdered good practice not to use exportPattern() (at least, 
not for broadly defined patterns) in production code: see the current 
'Writing R Extensions'.  Otherwise things may change under you (what 
nlme exports has changed recently, hence what import(nlme) brings it 
has).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rkjandra at gmail.com  Thu Mar 24 00:35:25 2011
From: rkjandra at gmail.com (Rob Anderson)
Date: Wed, 23 Mar 2011 19:35:25 -0400
Subject: [Rd] Standalone C++ application for processing R parser output(SEXP)
Message-ID: <AANLkTim2_zn4_w5WiovLF8O-FH=EAh2241AxkBiMAK0R@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110323/13fa0938/attachment.pl>

From murdoch.duncan at gmail.com  Thu Mar 24 13:08:03 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 24 Mar 2011 08:08:03 -0400
Subject: [Rd] Standalone C++ application for processing R parser
	output(SEXP)
In-Reply-To: <AANLkTim2_zn4_w5WiovLF8O-FH=EAh2241AxkBiMAK0R@mail.gmail.com>
References: <AANLkTim2_zn4_w5WiovLF8O-FH=EAh2241AxkBiMAK0R@mail.gmail.com>
Message-ID: <4D8B3423.9060904@gmail.com>

On 11-03-23 7:35 PM, Rob Anderson wrote:
> Hi All,
>
> I am trying to write a source-to-source compiler for R. I am trying to
> leverage the R parser code for the purpose. I am trying to transform the
> SEXP returned from the parser into an AST for our own Ruby embedded Domain
> specific language.
>
> I tried using R CMD SHBIN to compile a C function that parses arbitrary R
> expressions. But I think, the generated .so file can be used from within R
> and not be called from other C or Ruby programs(I get linker errors).
>
> My Idea  is to use the SEXP processing functions/MACROS (CAR, CDR, CADR,
> etc..) from within C code and transform it to our AST format. I tried
> linking to libR.a and other lib*.so's when I compile the C code using gcc
> but, it doesn't work.
>
> I read that R exposes only small number of functions for library/package
> writers and the compiled *.so can only from within R.
>
> Any ideas on what is wrong, or how I can go about it?

I think you need to think of your program as a new front end for R, even 
if you're only using a few R functions.  See Chapter 8 in the Writing R 
Extensions manual.

Duncan Murdoch


From edd at debian.org  Thu Mar 24 13:46:22 2011
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 24 Mar 2011 07:46:22 -0500
Subject: [Rd] Standalone C++ application for processing R
	parser	output(SEXP)
In-Reply-To: <4D8B3423.9060904@gmail.com>
References: <AANLkTim2_zn4_w5WiovLF8O-FH=EAh2241AxkBiMAK0R@mail.gmail.com>
	<4D8B3423.9060904@gmail.com>
Message-ID: <19851.15646.993475.458325@max.nulle.part>


On 24 March 2011 at 08:08, Duncan Murdoch wrote:
| On 11-03-23 7:35 PM, Rob Anderson wrote:
| > Hi All,
| >
| > I am trying to write a source-to-source compiler for R. I am trying to
| > leverage the R parser code for the purpose. I am trying to transform the
| > SEXP returned from the parser into an AST for our own Ruby embedded Domain
| > specific language.
| >
| > I tried using R CMD SHBIN to compile a C function that parses arbitrary R
| > expressions. But I think, the generated .so file can be used from within R
| > and not be called from other C or Ruby programs(I get linker errors).
| >
| > My Idea  is to use the SEXP processing functions/MACROS (CAR, CDR, CADR,
| > etc..) from within C code and transform it to our AST format. I tried
| > linking to libR.a and other lib*.so's when I compile the C code using gcc
| > but, it doesn't work.
| >
| > I read that R exposes only small number of functions for library/package
| > writers and the compiled *.so can only from within R.
| >
| > Any ideas on what is wrong, or how I can go about it?
| 
| I think you need to think of your program as a new front end for R, even 
| if you're only using a few R functions.  See Chapter 8 in the Writing R 
| Extensions manual.

Maybe also have a look at the parser package by Romain at

     https://r-forge.r-project.org/R/?group_id=384

(and scroll down sufficiently on that page) which has the description

     parser - Detailed R source code parser	  
 	
     detailed source code parser, based on the standard R parser but
     organizing the information differently 

which strikes me as close enough to what you describe. That said, Romain did
this for highlight so it may not be relevant.

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From djsamperi at gmail.com  Thu Mar 24 16:53:27 2011
From: djsamperi at gmail.com (Dominick Samperi)
Date: Thu, 24 Mar 2011 11:53:27 -0400
Subject: [Rd] Orthogonal polynomial ANOVA or polynomial regression?
Message-ID: <AANLkTik09f7cr7hz+fLTe6BRXOig+kWpFzoM8aXVt0bV@mail.gmail.com>

Hi,

I have not been able to find R tools that permit an orthogonal polynomial
ANOVA analysis: single degree of freedom F-test comparisons including
L, Q, C, etc. terms. Do such tools exist?

I guess you can accomplish something similar by doing straightforward
polynomial regression and removing powers manually, combined with
ANOVA model comparisons.

Thanks,
Dominick


From pdalgd at gmail.com  Thu Mar 24 17:09:45 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 24 Mar 2011 17:09:45 +0100
Subject: [Rd] Orthogonal polynomial ANOVA or polynomial regression?
In-Reply-To: <AANLkTik09f7cr7hz+fLTe6BRXOig+kWpFzoM8aXVt0bV@mail.gmail.com>
References: <AANLkTik09f7cr7hz+fLTe6BRXOig+kWpFzoM8aXVt0bV@mail.gmail.com>
Message-ID: <1C80B4F8-A00A-4F18-9454-3435BFEFACAF@gmail.com>


On Mar 24, 2011, at 16:53 , Dominick Samperi wrote:

> Hi,
> 
> I have not been able to find R tools that permit an orthogonal polynomial
> ANOVA analysis: single degree of freedom F-test comparisons including
> L, Q, C, etc. terms. Do such tools exist?
> 
> I guess you can accomplish something similar by doing straightforward
> polynomial regression and removing powers manually, combined with
> ANOVA model comparisons.

(Why R-devel? This is a plain R-help thing.)

Look up contr.poly(), and poly().

Notice that for unbalanced designs, you still need to remove terms one at a time.

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From bbolker at gmail.com  Thu Mar 24 19:47:05 2011
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 24 Mar 2011 18:47:05 +0000
Subject: [Rd] import question
References: <4D8A85F4.1070507@gmail.com>
	<loom.20110324T011932-297@post.gmane.org>
	<alpine.LFD.2.02.1103240417290.25247@gannet.stats.ox.ac.uk>
Message-ID: <loom.20110324T194207-571@post.gmane.org>

Prof Brian Ripley <ripley <at> stats.ox.ac.uk> writes:

> 
> On Thu, 24 Mar 2011, Ben Bolker wrote:
> 
> > Ben Bolker <bbolker <at> gmail.com> writes:
> >
> >>
> >>
> >>   I have been struggling all day to import a particular function/method
> >> combination (ranef(), which extracts the random effects from a mixed
> >> model fit) from the nlme package into another package ... so far without
> >> success.
> >>
> >
> >  Answered my own question, finally.
> >
> >  Apparently an explicit
> >
> > export(ranef)
> >
> > is required, even though there is also an
> >
> > exportPattern("^[^\\.]")
> >
> > in the NAMESPACE file, which I would have thought would
> > export 'ranef' along with everything else ... ?
> 
> It exports everything excpet dot-namesin the package's namespace. 
> Imports are not in the namespace per se, but in the import environment 
> (which is the enclosure of the namespace).  Here is the actual code:
> 
>          for (p in nsInfo$exportPatterns)
>              exports <- c(ls(env, pattern = p, all.names = TRUE), exports)
> 
> So to re-export a function, you need to do so explicitly.
> 
> It is consdered good practice not to use exportPattern() (at least, 
> not for broadly defined patterns) in production code: see the current 
> 'Writing R Extensions'.  Otherwise things may change under you (what 
> nlme exports has changed recently, hence what import(nlme) brings it 
> has).

  Thank you.
  I will transition away from using exportPattern (although it seemed
like a good quick and dirty solution to this testing problem).

  Please consider the following patch to R-exts ...

  thanks
    Ben Bolker

===================================================================
--- R-exts.texi	(revision 55002)
+++ R-exts.texi	(working copy)
@@ -2310,7 +2310,9 @@
 package @pkg{foo} are to be imported.
 
 It is possible to export variables from a name space that it has
-imported from other name spaces.
+imported from other name spaces (they need to be exported 
+using an explicit @code{export} directive;
+i.e. @code{exportPattern} will not work).
 
 If a package only needs a few objects from another package it can use a
 fully qualified variable reference in the code instead of a formal


From hadley at rice.edu  Thu Mar 24 20:03:18 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Thu, 24 Mar 2011 14:03:18 -0500
Subject: [Rd] import question
In-Reply-To: <loom.20110324T011932-297@post.gmane.org>
References: <4D8A85F4.1070507@gmail.com>
	<loom.20110324T011932-297@post.gmane.org>
Message-ID: <AANLkTikV_RHGTMgZjizwv7xNGyQpJQFR=P7w9swKTk2W@mail.gmail.com>

On Wed, Mar 23, 2011 at 7:20 PM, Ben Bolker <bbolker at gmail.com> wrote:
> Ben Bolker <bbolker <at> gmail.com> writes:
>
>>
>>
>> ? I have been struggling all day to import a particular function/method
>> combination (ranef(), which extracts the random effects from a mixed
>> model fit) from the nlme package into another package ... so far without
>> success.
>>
>
> ?Answered my own question, finally.
>
> ?Apparently an explicit
>
> export(ranef)

But why do you want to export this method out of your package? (If you
export it, you will need to document it) Can't you rely on nlme being
loaded?

i.e. your test should be

library(nlme)
library(raneftest)
x <- 1
class(x) <- "x"
ranef.x(x)
ranef(x)


Hadley

-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From bbolker at gmail.com  Thu Mar 24 20:12:55 2011
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 24 Mar 2011 15:12:55 -0400
Subject: [Rd] import question
In-Reply-To: <AANLkTikV_RHGTMgZjizwv7xNGyQpJQFR=P7w9swKTk2W@mail.gmail.com>
References: <4D8A85F4.1070507@gmail.com>
	<loom.20110324T011932-297@post.gmane.org>
	<AANLkTikV_RHGTMgZjizwv7xNGyQpJQFR=P7w9swKTk2W@mail.gmail.com>
Message-ID: <4D8B97B7.6030000@gmail.com>

On 03/24/2011 03:03 PM, Hadley Wickham wrote:
> On Wed, Mar 23, 2011 at 7:20 PM, Ben Bolker <bbolker at gmail.com> wrote:
>> Ben Bolker <bbolker <at> gmail.com> writes:
>>
>>>
>>>
>>>   I have been struggling all day to import a particular function/method
>>> combination (ranef(), which extracts the random effects from a mixed
>>> model fit) from the nlme package into another package ... so far without
>>> success.
>>>
>>
>>  Answered my own question, finally.
>>
>>  Apparently an explicit
>>
>> export(ranef)
> 
> But why do you want to export this method out of your package? (If you
> export it, you will need to document it) Can't you rely on nlme being
> loaded?
> 
> i.e. your test should be
> 
> library(nlme)
> library(raneftest)
> x <- 1
> class(x) <- "x"
> ranef.x(x)
> ranef(x)
>

  nlme and lme4 do not play nicely together (this may be
fixable/eventually be fixed, but it's the current state of affairs), and
I want this package to interoperate with lme4.  Thus I want to avoid
explicitly loading nlme.
  Sorry I didn't make this clear initially (someone else asked about
this off-list).


  cheers
    Ben


From hpages at fhcrc.org  Fri Mar 25 06:53:01 2011
From: hpages at fhcrc.org (Pages, Herve)
Date: Thu, 24 Mar 2011 22:53:01 -0700
Subject: [Rd] Namespace dependency not required
In-Reply-To: <855976773.839.1301032345000.JavaMail.root@zimbra4.fhcrc.org>
Message-ID: <746574105.841.1301032381329.JavaMail.root@zimbra4.fhcrc.org>

Hi,

  [hpages at localhost pkgreviews]$ R-2.13 CMD check qrqc_0.99.2.tar.gz
  * using log directory ?/home/hpages/pkgreviews/qrqc.Rcheck?
  * using R version 2.13.0 alpha (2011-03-24 r55004)
  * using platform: x86_64-unknown-linux-gnu (64-bit)
  * using session charset: UTF-8
  * checking for file ?qrqc/DESCRIPTION? ... OK
  * this is package ?qrqc? version ?0.99.2?
  * checking package name space information ... OK
  * checking package dependencies ... ERROR
  Namespace dependency not required: RColorBrewer

How I (somewhat naively) interpret this is: it is not required
that I have this namespace dependency. In other words, R CMD check
was able to figure out that my package doesn't use anything from
RColorBrewer internally so I don't need to have this
import(RColorBrewer) directive in my NAMESPACE file.

Which is of course not what 'R CMD check' is trying to tell me.

Couldn't the message say something a little bit less misleading
i.e. something like:

  Namespace dependency not in Imports field: RColorBrewer

Thanks!
H.


From andrew.c.stewart at gmail.com  Thu Mar 24 16:51:31 2011
From: andrew.c.stewart at gmail.com (andrew stewart)
Date: Thu, 24 Mar 2011 11:51:31 -0400
Subject: [Rd] datalist and data objects in R Package building
Message-ID: <AANLkTimqc_jF0RL2jEAWHYTNJVXStJzyv5gNbUszRGpH@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110324/196f7cd1/attachment.pl>

From drf28 at cornell.edu  Thu Mar 24 17:35:07 2011
From: drf28 at cornell.edu (Daniel Fuka)
Date: Thu, 24 Mar 2011 12:35:07 -0400
Subject: [Rd] .Fortran successful, R locks up.
Message-ID: <AANLkTikgcW_L1kYER3bDZJCsD8xC7BwJpMhRKUX8Xt8N@mail.gmail.com>

Howdy,

I am having a problem with a library compiled from some legacy fortran
code. I can call the library, it runs as it should, returns a list,
and gives a ">" prompt, but then locks up the R session. Functions
typed in return nothing. ctrl-c results in a new prompt that is still
locked up, and R overwhelms the processor. This happens on Mac,
Windows, and Linux exactly the same. I close all open files and
confirm nothing is still open with unix lsof. I also have added a
routine to deallocate all allocated variables.

Does anyone have any suggestions in how I might be able to debug this
further? I have included output from the R session, top -o CPU, and R
CMD INSTALL below.

Thanks for your time on my behalf!
dan

Ouput from R session with library "swat" and subroutine "junk":
> library.dynam("swat","EcoHydrology")
> .Fortran("junk")
                SWAT2005
      Soil & Water Assessment Tool
               PC Version
 Program reading from file.cio . . . executing

list()
>
^C
> q("n")
^C
> obejcts()


^C
> q()

^C
> ^Z
[1]+  Stopped                 r
DRF28:~/cornell/ecohydrology/swat_example/SJ_R_test_mac/Scenarios/Default/TxtInOut_R
dan$ killall R
[1]+  Terminated              r


Output from top during lockup:
  PID COMMAND      %CPU   TIME   #TH #PRTS #MREGS RPRVT  RSHRD  RSIZE  VSIZE
40750 R           96.6%  1:56.07   1    17     87   15M  1384K-   19M    49M

Output from R CMD INSTALL:
114 mirage5:fuka% R CMD INSTALL EcoHydrology
* installing to library
?/glade/home/fuka/R/x86_64-unknown-linux-gnu-library/2.12?
* installing *source* package ?EcoHydrology? ...
** libs
** arch -
Makefile:123: warning: overriding commands for target `.f.o'
/fs/local/apps/R-2.12.1/lib64/R/etc/Makeconf:132: warning: ignoring
old commands for target `.f.o'
gfortran -fPIC -g -O2   -c modparm.f
gfortran -fPIC -g -O2   -c addh.f
---SNIP successful gfortran output----
gfortran -fPIC -g -O2   -c zeroini.f
gfortran -fPIC -g -O2   -c closefiles.f
gfortran -shared  -o swat.so modparm.o addh.o albedo.o
allocate_parms.o alph.o analyse.o anfert.o apex_day.o apply.o ascrv.o
---SNIP successful link output----
writeaa.o writed.o writem.o writeswatfile.o writeswatmain.o xisquare.o
xiunc.o xmon.o ysed.o zero0.o zero1.o zero2.o zeroini.o closefiles.o
installing to /glade/home/fuka/R/x86_64-unknown-linux-gnu-library/2.12/EcoHydrology/libs
** R
** data
** preparing package for lazy loading
** help
*** installing help indices
** building package indices ...
** testing if installed package can be loaded

* DONE (EcoHydrology)


From tobias.erhardt at gmail.com  Fri Mar 25 09:23:59 2011
From: tobias.erhardt at gmail.com (Tobias Erhardt)
Date: Fri, 25 Mar 2011 09:23:59 +0100
Subject: [Rd] Rd2pdf and Rd2dvi don't find texi2dvi
Message-ID: <AF958FF9-6AE8-468F-B7A4-116B806D59CA@gmail.com>

Hello everybody

I'm am trying to build a pdf out of the Rd files that i wrote for a package, so that I can attach it to my thesis.

if i Run Rd2pdf (or Rd2dvi) I get this error massage:

Hmm ... looks like a package
Converting Rd files to LaTeX .
Creating pdf output from LaTeX ...
Error in texi2dvi("Rd2.tex", pdf = (out_ext == "pdf"), quiet = FALSE,  : 
  Running 'texi2dvi' on 'Rd2.tex' failed.
Output:
You don't have a working TeX binary (tex) installed anywhere in
your PATH, and texi2dvi cannot proceed without one.  If you want to use
this script, you'll need to install TeX (if you don't have it) or change
your PATH or TEX environment variable (if you do).  See the --help
output for more details.

For information about obtaining TeX, please see http://www.tug.org.  If
you happen to be using Debian, you can get it with this command:
  apt-get install tetex-bin
Error in running tools::texi2dvi

The problem is, that i have a valid Tex installation and I am able to call texi2dvi in the shell, as it is in my path.

In R getOption("texi2dvi") gives me the correct path to texi2dvi "/usr/bin/texi2dvi"

I am running R2.12.2 on MacOSX 10.6.7 and have TexLive 2010 installed

Thanks for your help

best regard
Tobias


From murdoch.duncan at gmail.com  Fri Mar 25 13:41:19 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 25 Mar 2011 08:41:19 -0400
Subject: [Rd] .Fortran successful, R locks up.
In-Reply-To: <AANLkTikgcW_L1kYER3bDZJCsD8xC7BwJpMhRKUX8Xt8N@mail.gmail.com>
References: <AANLkTikgcW_L1kYER3bDZJCsD8xC7BwJpMhRKUX8Xt8N@mail.gmail.com>
Message-ID: <4D8C8D6F.7040700@gmail.com>

On 24/03/2011 12:35 PM, Daniel Fuka wrote:
> Howdy,
>
> I am having a problem with a library compiled from some legacy fortran
> code. I can call the library, it runs as it should, returns a list,
> and gives a ">" prompt, but then locks up the R session. Functions
> typed in return nothing. ctrl-c results in a new prompt that is still
> locked up, and R overwhelms the processor. This happens on Mac,
> Windows, and Linux exactly the same. I close all open files and
> confirm nothing is still open with unix lsof. I also have added a
> routine to deallocate all allocated variables.
>
> Does anyone have any suggestions in how I might be able to debug this
> further? I have included output from the R session, top -o CPU, and R
> CMD INSTALL below.

I would guess that the Fortran is trying to do some Fortran-style I/O; 
that often causes problems.  See Writing R Extensions for alternatives 
(dblepr etc.).  Or it might be some other bug.

The best way to debug something like this is with gdb or gdb plus a 
front end like Insight, Xcode, Eclipse, etc., but if you haven't used 
them before, they are somewhat daunting.  If you're doing this on 
Windows you'll need to rebuild your library with the environment 
variable DEBUG set to T to get the debugging information compiled into 
it.  Not sure if you need to do anything on the other systems.

Duncan Murdoch

> Thanks for your time on my behalf!
> dan
>
> Ouput from R session with library "swat" and subroutine "junk":
> >  library.dynam("swat","EcoHydrology")
> >  .Fortran("junk")
>                  SWAT2005
>        Soil&  Water Assessment Tool
>                 PC Version
>   Program reading from file.cio . . . executing
>
> list()
> >
> ^C
> >  q("n")
> ^C
> >  obejcts()
>
>
> ^C
> >  q()
>
> ^C
> >  ^Z
> [1]+  Stopped                 r
> DRF28:~/cornell/ecohydrology/swat_example/SJ_R_test_mac/Scenarios/Default/TxtInOut_R
> dan$ killall R
> [1]+  Terminated              r
>
>
> Output from top during lockup:
>    PID COMMAND      %CPU   TIME   #TH #PRTS #MREGS RPRVT  RSHRD  RSIZE  VSIZE
> 40750 R           96.6%  1:56.07   1    17     87   15M  1384K-   19M    49M
>
> Output from R CMD INSTALL:
> 114 mirage5:fuka% R CMD INSTALL EcoHydrology
> * installing to library
> ?/glade/home/fuka/R/x86_64-unknown-linux-gnu-library/2.12?
> * installing *source* package ?EcoHydrology? ...
> ** libs
> ** arch -
> Makefile:123: warning: overriding commands for target `.f.o'
> /fs/local/apps/R-2.12.1/lib64/R/etc/Makeconf:132: warning: ignoring
> old commands for target `.f.o'
> gfortran -fPIC -g -O2   -c modparm.f
> gfortran -fPIC -g -O2   -c addh.f
> ---SNIP successful gfortran output----
> gfortran -fPIC -g -O2   -c zeroini.f
> gfortran -fPIC -g -O2   -c closefiles.f
> gfortran -shared  -o swat.so modparm.o addh.o albedo.o
> allocate_parms.o alph.o analyse.o anfert.o apex_day.o apply.o ascrv.o
> ---SNIP successful link output----
> writeaa.o writed.o writem.o writeswatfile.o writeswatmain.o xisquare.o
> xiunc.o xmon.o ysed.o zero0.o zero1.o zero2.o zeroini.o closefiles.o
> installing to /glade/home/fuka/R/x86_64-unknown-linux-gnu-library/2.12/EcoHydrology/libs
> ** R
> ** data
> ** preparing package for lazy loading
> ** help
> *** installing help indices
> ** building package indices ...
> ** testing if installed package can be loaded
>
> * DONE (EcoHydrology)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Fri Mar 25 13:47:47 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 25 Mar 2011 08:47:47 -0400
Subject: [Rd] Rd2pdf and Rd2dvi don't find texi2dvi
In-Reply-To: <AF958FF9-6AE8-468F-B7A4-116B806D59CA@gmail.com>
References: <AF958FF9-6AE8-468F-B7A4-116B806D59CA@gmail.com>
Message-ID: <4D8C8EF3.4000400@gmail.com>

On 25/03/2011 4:23 AM, Tobias Erhardt wrote:
> Hello everybody
>
> I'm am trying to build a pdf out of the Rd files that i wrote for a package, so that I can attach it to my thesis.
>
> if i Run Rd2pdf (or Rd2dvi) I get this error massage:
>
> Hmm ... looks like a package
> Converting Rd files to LaTeX .
> Creating pdf output from LaTeX ...
> Error in texi2dvi("Rd2.tex", pdf = (out_ext == "pdf"), quiet = FALSE,  :
>    Running 'texi2dvi' on 'Rd2.tex' failed.
> Output:
> You don't have a working TeX binary (tex) installed anywhere in
> your PATH, and texi2dvi cannot proceed without one.  If you want to use
> this script, you'll need to install TeX (if you don't have it) or change
> your PATH or TEX environment variable (if you do).  See the --help
> output for more details.
>
> For information about obtaining TeX, please see http://www.tug.org.  If
> you happen to be using Debian, you can get it with this command:
>    apt-get install tetex-bin
> Error in running tools::texi2dvi
>
> The problem is, that i have a valid Tex installation and I am able to call texi2dvi in the shell, as it is in my path.
>
> In R getOption("texi2dvi") gives me the correct path to texi2dvi "/usr/bin/texi2dvi"
>
> I am running R2.12.2 on MacOSX 10.6.7 and have TexLive 2010 installed

That message is coming from texi2dvi (the system command), not from R.  
So you might want to investigate why texi2dvi as invoked from R is 
different than texi2dvi as invoked from your shell.  I'd try

system("texi2dvi --version")

in R and compare the result to what you get outside, examine the 
environment variables PATH and TEX in both places (with 
Sys.getenv(c("PATH", "TEX")) in R) to look for differences, etc.

Duncan Murdoch


From wdunlap at tibco.com  Fri Mar 25 18:19:58 2011
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 25 Mar 2011 10:19:58 -0700
Subject: [Rd] two minor bugs in rowsum()
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D70004086C27@NA-PA-VBE03.na.tibco.com>

(a) In R 2.12.2 rowsum can overflow if given an integer input:
  > rowsum(c(2e9L, 2e9L), c("a", "a"))
          [,1]
  a -294967296
  > 2^32 + .Last.value
     [,1]
  a 4e+09
Should it be changed to coerce its x argument to numeric
(double precision) so it always returns a numeric output?

(b) When rowsum is given an x containing both NaN and NA it
appears to use the last of the NaN/NA entries to determine
if the output is NaN or NA while the `+` function uses the
first:
  > z <- cbind( c(NA,NA), c(NA,NaN), c(NaN,NA), c(NaN,NaN))
  > rowsum(z, c("a","a"))
    [,1] [,2] [,3] [,4]
  a   NA  NaN   NA  NaN
  > z[1,,drop=FALSE] + z[2,,drop=FALSE]
       [,1] [,2] [,3] [,4]
  [1,]   NA   NA  NaN  NaN

(The name rowsum is a metabug, since it may be confused
with the entirely different rowSums, but it has been around
for a long time.)

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com 


From tobias.erhardt at gmail.com  Fri Mar 25 15:11:10 2011
From: tobias.erhardt at gmail.com (Tobias Erhardt)
Date: Fri, 25 Mar 2011 15:11:10 +0100
Subject: [Rd] Rd2pdf and Rd2dvi don't find texi2dvi
In-Reply-To: <4D8C8EF3.4000400@gmail.com>
References: <AF958FF9-6AE8-468F-B7A4-116B806D59CA@gmail.com>
	<4D8C8EF3.4000400@gmail.com>
Message-ID: <A50D693C-C20C-4188-BF76-11F976832A9A@gmail.com>

Okay, i did compare  the versions of texi2dvi within R and the shell, they are both the same. 

Regarding the environmental variabels, this is what printenv gave me:

TERM_PROGRAM=iTerm.app
TERM=xterm
SHELL=/bin/bash
TMPDIR=/var/folders/3B/3BhLCRj+FISLJAbkj65bUU+++TI/-Tmp-/
Apple_PubSub_Socket_Render=/tmp/launch-N5Bzur/Render
COMMAND_MODE=unix2003
SSH_AUTH_SOCK=/tmp/launch-p1c1Db/Listeners
__CF_USER_TEXT_ENCODING=0x1F5:0:3
PATH=/Library/Frameworks/Python.framework/Versions/2.6/bin:/Library/Frameworks/Python.framework/Versions/2.7/bin:/Applications/Octave.app/Contents/Resources/bin/:/Applications/GMT//bin:/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin:/usr/X11/bin:/opt/local/bin:/usr/local/git/bin
PWD=/usr/bin
EDITOR=mate -w
NETCDFHOME=/usr/local/
LANG=de_DE.UTF-8
SHLVL=1
COLORFGBG=0;15
LC_CTYPE=en_US.UTF-8
DISPLAY=/tmp/launch-VKiS22/org.x:0
_=/usr/bin/printenv

and this is what Sys.getenv(c("PATH", "TEX")) gave me:

PATH 
"/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin:/usr/X11/bin:/opt/local/bin:/usr/local/git/bin:/usr/local/bin" 
TEX 
"" 

I dont't really know my way around system variables but i hope that this helps.

I'm open for any suggestions

From savicky at cs.cas.cz  Fri Mar 25 22:26:11 2011
From: savicky at cs.cas.cz (Petr Savicky)
Date: Fri, 25 Mar 2011 22:26:11 +0100
Subject: [Rd] testing presence of pdflatex in R CMD check
Message-ID: <20110325212611.GA2782@cs.cas.cz>

The nodes of our cluster do not have pdflatex installed. When
running R CMD check there on a package with no errors in documentation,
then R-2.13.0-alpha and R-2.12.2 report a possible error in Rd files,
while R-2.11.1 did not. The platform is 64 bit CentOS.

The output of

  R CMD check tree_1.0-28.tar.gz

under the above three versions of R contains the following.

R-2.11.1

stderr

  sh: pdflatex: command not found
  sh: latex: command not found

stdout

  * checking for working pdflatex ... NO

R-2.12.2

stderr

  sh: pdflatex: command not found
  Error in texi2dvi("Rd2.tex", pdf = (out_ext == "pdf"), quiet = FALSE,  :
    unable to run 'pdflatex' on 'Rd2.tex'
  Error in running tools::texi2dvi

stdout

  * checking PDF version of manual ... WARNING
  LaTeX errors when creating PDF version.
  This typically indicates Rd problems.
  * checking PDF version of manual without hyperrefs or index ... ERROR
  Re-running with no redirection of stdout/stderr.
  Hmm ... looks like a package
  You may want to clean up by 'rm -rf /tmp/RtmpgnWKRW/Rd2pdf3723367e'

2.13.0-alpha

stderr

  Error in texi2dvi("Rd2.tex", pdf = (out_ext == "pdf"), quiet = FALSE,  :
    pdflatex is not available
  Error in running tools::texi2dvi

stdout

  * checking PDF version of manual ... WARNING
  LaTeX errors when creating PDF version.
  This typically indicates Rd problems.
  * checking PDF version of manual without hyperrefs or index ... ERROR
  Re-running with no redirection of stdout/stderr.
  Hmm ... looks like a package
  You may want to clean up by 'rm -rf /tmp/RtmpQ0WawT/Rd2pdf41481e1'

Is it intentional not to test the presence of pdflatex during R CMD check?

Petr Savicky.


From drf28 at cornell.edu  Sat Mar 26 04:04:42 2011
From: drf28 at cornell.edu (Daniel Fuka)
Date: Fri, 25 Mar 2011 23:04:42 -0400
Subject: [Rd] .Fortran successful, R locks up.
In-Reply-To: <4D8C8D6F.7040700@gmail.com>
References: <AANLkTikgcW_L1kYER3bDZJCsD8xC7BwJpMhRKUX8Xt8N@mail.gmail.com>
	<4D8C8D6F.7040700@gmail.com>
Message-ID: <AANLkTim+f=i5DnNfaQNKQHwxnF4KBBcUNGrKkHMczRsm@mail.gmail.com>

Thanks Duncan for helping me along the way. I am working in OSX,
Linux, and Windows, and gdb is helping me trace it along to what
appears to be an endless processor intensive loop in sys-std.c .
Below, I have pasted the output. All files are closed as verified by
lsof. There is absolutely no stdio other than what I have put in a
call to R library's subroutine intpr, all other io is routed to files,
which are all successfully closed. The entire routine successfully
runs, and spits out the output from intpr. Is there supposed to be
something returned from the Fortran routine that Rstd_ReadConsole is
looking for? I have attached the final lines of the fortran
subroutine, as well as the gdb steps post fortran routine. Any
additional help is greatly appreciated!

Last few lines of fortran, where intrflag is :
---SNIP---
      call closefiles
      call deallocate_parms
      call intpr ("test", 4, intrflag, 1)
      return
      end

R debug walkthrough:

r -d gdb
----SNIP normal debug startup----
> library.dynam("swat","EcoHydrology")
Reading symbols for shared libraries ... done
> .Fortran("rswat",7)
test
[1] 0
[[1]]
[1] 7

>

^C
Program received signal SIGINT, Interrupt.
0x9172a2de in sigprocmask ()
(gdb) next
Single stepping until exit from function sigprocmask,
which has no line number information.
0x9172a23a in setjmp ()
(gdb)
Single stepping until exit from function setjmp,
which has no line number information.
0x9172a2f0 in sigaltstack ()
(gdb)
Single stepping until exit from function sigaltstack,
which has no line number information.
0x9172a25c in setjmp ()
(gdb)
Single stepping until exit from function setjmp,
which has no line number information.
0x91712fb8 in _setjmp ()
(gdb)
Single stepping until exit from function _setjmp,
which has no line number information.
R_SelectEx (n=1, readfds=0x6391a0, writefds=0x0, exceptfds=0x0,
timeout=0x0, intr=<value temporarily unavailable, due to
optimizations>) at ../../../../R-2.12.1/src/unix/sys-std.c:137
137     ../../../../R-2.12.1/src/unix/sys-std.c: No such file or directory.
        in ../../../../R-2.12.1/src/unix/sys-std.c
(gdb)
141     in ../../../../R-2.12.1/src/unix/sys-std.c
(gdb)
146     in ../../../../R-2.12.1/src/unix/sys-std.c
(gdb)
151     in ../../../../R-2.12.1/src/unix/sys-std.c
(gdb)
152     in ../../../../R-2.12.1/src/unix/sys-std.c
(gdb)
153     in ../../../../R-2.12.1/src/unix/sys-std.c
(gdb)
157     in ../../../../R-2.12.1/src/unix/sys-std.c
(gdb)
R_checkActivityEx (usec=-1, ignore_stdin=0, intr=0x4f68a0
<handleInterrupt>) at ../../../../R-2.12.1/src/unix/sys-std.c:330
330     in ../../../../R-2.12.1/src/unix/sys-std.c
(gdb)
Rstd_ReadConsole (prompt=0x10214e0 "> ", buf=0xbfffe288
".Fortran(\"rswat\",7)\n", len=4096, addtohistory=1) at
../../../../R-2.12.1/src/unix/sys-std.c:911
911     in ../../../../R-2.12.1/src/unix/sys-std.c
(gdb)
912     in ../../../../R-2.12.1/src/unix/sys-std.c
(gdb)
904     in ../../../../R-2.12.1/src/unix/sys-std.c
(gdb)
911     in ../../../../R-2.12.1/src/unix/sys-std.c
(gdb)
912     in ../../../../R-2.12.1/src/unix/sys-std.c
(gdb)
904     in ../../../../R-2.12.1/src/unix/sys-std.c
(gdb)
911     in ../../../../R-2.12.1/src/unix/sys-std.c
(gdb)
912     in ../../../../R-2.12.1/src/unix/sys-std.c
(gdb)
904     in ../../../../R-2.12.1/src/unix/sys-std.c
(gdb)
911     in ../../../../R-2.12.1/src/unix/sys-std.c
(gdb)
912     in ../../../../R-2.12.1/src/unix/sys-std.c
(gdb)
904     in ../../../../R-2.12.1/src/unix/sys-std.c
(gdb) bt
#0  Rstd_ReadConsole (prompt=0x10214e0 "> ", buf=0xbfffe288
".Fortran(\"rswat\",7)\n", len=4096, addtohistory=1) at
../../../../R-2.12.1/src/unix/sys-std.c:904
#1  0x004394e6 in Rf_ReplIteration (rho=0x102472c, savestack=0,
browselevel=0, state=0xbfffe27c) at
../../../../R-2.12.1/src/main/main.c:210
#2  0x00439650 in R_ReplConsole (rho=0x102472c, savestack=0,
browselevel=0) at ../../../../R-2.12.1/src/main/main.c:311
#3  0x00439bab in run_Rmainloop () at ../../../../R-2.12.1/src/main/main.c:1004
#4  0x00001ff0 in main ()
(gdb)


On Fri, Mar 25, 2011 at 8:41 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 24/03/2011 12:35 PM, Daniel Fuka wrote:
>>
>> Howdy,
>>
>> I am having a problem with a library compiled from some legacy fortran
>> code. I can call the library, it runs as it should, returns a list,
>> and gives a ">" prompt, but then locks up the R session. Functions
>> typed in return nothing. ctrl-c results in a new prompt that is still
>> locked up, and R overwhelms the processor. This happens on Mac,
>> Windows, and Linux exactly the same. I close all open files and
>> confirm nothing is still open with unix lsof. I also have added a
>> routine to deallocate all allocated variables.
>>
>> Does anyone have any suggestions in how I might be able to debug this
>> further? I have included output from the R session, top -o CPU, and R
>> CMD INSTALL below.
>
> I would guess that the Fortran is trying to do some Fortran-style I/O; that
> often causes problems. ?See Writing R Extensions for alternatives (dblepr
> etc.). ?Or it might be some other bug.
>
> The best way to debug something like this is with gdb or gdb plus a front
> end like Insight, Xcode, Eclipse, etc., but if you haven't used them before,
> they are somewhat daunting. ?If you're doing this on Windows you'll need to
> rebuild your library with the environment variable DEBUG set to T to get the
> debugging information compiled into it. ?Not sure if you need to do anything
> on the other systems.
>
> Duncan Murdoch
>
>> Thanks for your time on my behalf!
>> dan
>>
>> Ouput from R session with library "swat" and subroutine "junk":
>> > ?library.dynam("swat","EcoHydrology")
>> > ?.Fortran("junk")
>> ? ? ? ? ? ? ? ? SWAT2005
>> ? ? ? Soil& ?Water Assessment Tool
>> ? ? ? ? ? ? ? ?PC Version
>> ?Program reading from file.cio . . . executing
>>
>> list()
>> >
>> ^C
>> > ?q("n")
>> ^C
>> > ?obejcts()
>>
>>
>> ^C
>> > ?q()
>>
>> ^C
>> > ?^Z
>> [1]+ ?Stopped ? ? ? ? ? ? ? ? r
>>
>> DRF28:~/cornell/ecohydrology/swat_example/SJ_R_test_mac/Scenarios/Default/TxtInOut_R
>> dan$ killall R
>> [1]+ ?Terminated ? ? ? ? ? ? ?r
>>
>>
>> Output from top during lockup:
>> ? PID COMMAND ? ? ?%CPU ? TIME ? #TH #PRTS #MREGS RPRVT ?RSHRD ?RSIZE
>> ?VSIZE
>> 40750 R ? ? ? ? ? 96.6% ?1:56.07 ? 1 ? ?17 ? ? 87 ? 15M ?1384K- ? 19M
>> ?49M
>>
>> Output from R CMD INSTALL:
>> 114 mirage5:fuka% R CMD INSTALL EcoHydrology
>> * installing to library
>> ?/glade/home/fuka/R/x86_64-unknown-linux-gnu-library/2.12?
>> * installing *source* package ?EcoHydrology? ...
>> ** libs
>> ** arch -
>> Makefile:123: warning: overriding commands for target `.f.o'
>> /fs/local/apps/R-2.12.1/lib64/R/etc/Makeconf:132: warning: ignoring
>> old commands for target `.f.o'
>> gfortran -fPIC -g -O2 ? -c modparm.f
>> gfortran -fPIC -g -O2 ? -c addh.f
>> ---SNIP successful gfortran output----
>> gfortran -fPIC -g -O2 ? -c zeroini.f
>> gfortran -fPIC -g -O2 ? -c closefiles.f
>> gfortran -shared ?-o swat.so modparm.o addh.o albedo.o
>> allocate_parms.o alph.o analyse.o anfert.o apex_day.o apply.o ascrv.o
>> ---SNIP successful link output----
>> writeaa.o writed.o writem.o writeswatfile.o writeswatmain.o xisquare.o
>> xiunc.o xmon.o ysed.o zero0.o zero1.o zero2.o zeroini.o closefiles.o
>> installing to
>> /glade/home/fuka/R/x86_64-unknown-linux-gnu-library/2.12/EcoHydrology/libs
>> ** R
>> ** data
>> ** preparing package for lazy loading
>> ** help
>> *** installing help indices
>> ** building package indices ...
>> ** testing if installed package can be loaded
>>
>> * DONE (EcoHydrology)
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From rkjandra at gmail.com  Sat Mar 26 06:28:55 2011
From: rkjandra at gmail.com (Rob Anderson)
Date: Sat, 26 Mar 2011 01:28:55 -0400
Subject: [Rd] Standalone C++ application for processing R parser
	output(SEXP)
In-Reply-To: <19851.15646.993475.458325@max.nulle.part>
References: <AANLkTim2_zn4_w5WiovLF8O-FH=EAh2241AxkBiMAK0R@mail.gmail.com>
	<4D8B3423.9060904@gmail.com>
	<19851.15646.993475.458325@max.nulle.part>
Message-ID: <AANLkTinRjaxeTqL=YtEFow5Y-FwWuYm+0CGfi9rqPG_e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110326/c29d6b6a/attachment.pl>

From bbolker at gmail.com  Sat Mar 26 19:14:12 2011
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 26 Mar 2011 14:14:12 -0400
Subject: [Rd] another import puzzle
Message-ID: <4D8E2CF4.1030307@gmail.com>


  Dear list,

  I have another (again possibly boneheaded) puzzle about importing,
again encapsulated in a nearly trivial package.  (The package is posted
at <http://www.math.mcmaster.ca/bolker/misc/coefsumtest_0.001.tar.gz>.)

  The package consists (only) of the following S3 method definitions:

coeftab <- function(object, ...) UseMethod("coeftab",object)
coeftab.default <- function(object,...) {
  print(class(summary(object)))
  coef(summary(object))
}

  The NAMESPACE tries to pull in the necessary bits and pieces from lme4
to extract summaries and coefficients:

export("coeftab","coeftab.default")
importClassesFrom(lme4,"mer","summary.mer")
importMethodsFrom(lme4,"coef","summary","show","print")
exportMethods("coef","summary","show","print")
exportClasses("mer","summary.mer")
S3method(coeftab,default)

  The package passes the routine parts of R CMD check.  The following
test shows that, with lme4 loaded, coef(summary([object of class
"mer"])) works in the global environment, but not in a function defined
inside the namespace of the package.

  The output ends with:

> coeftab.default(gm1)
[1] "summaryDefault" "table"
Error in object$coefficients : $ operator is invalid for atomic vectors
Calls: coeftab.default -> coef -> coef -> coef.default

  which indicates that inside the function, summary() is calling
summary.default instead of seeing the summary method for "mer" objects ...


  I have (re-re-re-)read the appropriate R-exts section, without luck,
and tried various minor variations (e.g. import()ing all of lme4,
changing the order of the directive, ...).

  Help ... ?

  sincerely
    Ben Bolker

=====
test.R
=====

library(coefsumtest)
library(lme4)

gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
             family = binomial, data = cbpp)

coef(summary(gm1)) ## works

f <- function(g) {
  coef(summary(g))
}
f(gm1)  ## works

coeftab.default(gm1) ##


From mtmorgan at fhcrc.org  Sat Mar 26 19:52:28 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Sat, 26 Mar 2011 11:52:28 -0700
Subject: [Rd] another import puzzle
In-Reply-To: <4D8E2CF4.1030307@gmail.com>
References: <4D8E2CF4.1030307@gmail.com>
Message-ID: <4D8E35EC.20406@fhcrc.org>

On 03/26/2011 11:14 AM, Ben Bolker wrote:
>
>    Dear list,
>
>    I have another (again possibly boneheaded) puzzle about importing,
> again encapsulated in a nearly trivial package.  (The package is posted
> at<http://www.math.mcmaster.ca/bolker/misc/coefsumtest_0.001.tar.gz>.)
>
>    The package consists (only) of the following S3 method definitions:
>
> coeftab<- function(object, ...) UseMethod("coeftab",object)
> coeftab.default<- function(object,...) {
>    print(class(summary(object)))
>    coef(summary(object))
> }
>
>    The NAMESPACE tries to pull in the necessary bits and pieces from lme4
> to extract summaries and coefficients:
>
> export("coeftab","coeftab.default")
> importClassesFrom(lme4,"mer","summary.mer")
> importMethodsFrom(lme4,"coef","summary","show","print")

It 'turns out' that base::summary is an S3 generic. Matrix creates an S4 
generic that is distinct from base::summary (e.g., so that the default 
behavior of summary isn't altered for packages that want to have nothing 
to do with Matrix). Dispatch needs to go through the generic. lme4 has 
methods on Matrix::summary, not on base::summary, so without the 
Matrix::summary generic your object never sees the summary method for 
lme4 objects.

So you need to Import: Matrix and importFrom(Matrix, summary).

Martin Morgan

> exportMethods("coef","summary","show","print")
> exportClasses("mer","summary.mer")
> S3method(coeftab,default)
>
>    The package passes the routine parts of R CMD check.  The following
> test shows that, with lme4 loaded, coef(summary([object of class
> "mer"])) works in the global environment, but not in a function defined
> inside the namespace of the package.
>
>    The output ends with:
>
>> coeftab.default(gm1)
> [1] "summaryDefault" "table"
> Error in object$coefficients : $ operator is invalid for atomic vectors
> Calls: coeftab.default ->  coef ->  coef ->  coef.default
>
>    which indicates that inside the function, summary() is calling
> summary.default instead of seeing the summary method for "mer" objects ...
>
>
>    I have (re-re-re-)read the appropriate R-exts section, without luck,
> and tried various minor variations (e.g. import()ing all of lme4,
> changing the order of the directive, ...).
>
>    Help ... ?
>
>    sincerely
>      Ben Bolker
>
> =====
> test.R
> =====
>
> library(coefsumtest)
> library(lme4)
>
> gm1<- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
>               family = binomial, data = cbpp)
>
> coef(summary(gm1)) ## works
>
> f<- function(g) {
>    coef(summary(g))
> }
> f(gm1)  ## works
>
> coeftab.default(gm1) ##
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From bbolker at gmail.com  Sat Mar 26 20:19:37 2011
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 26 Mar 2011 15:19:37 -0400
Subject: [Rd] another import puzzle
In-Reply-To: <4D8E35EC.20406@fhcrc.org>
References: <4D8E2CF4.1030307@gmail.com> <4D8E35EC.20406@fhcrc.org>
Message-ID: <4D8E3C49.2030003@gmail.com>

On 11-03-26 02:52 PM, Martin Morgan wrote:
> On 03/26/2011 11:14 AM, Ben Bolker wrote:
>>
>>    Dear list,
>>
>>    I have another (again possibly boneheaded) puzzle about importing,
>> again encapsulated in a nearly trivial package.  (The package is posted
>> at<http://www.math.mcmaster.ca/bolker/misc/coefsumtest_0.001.tar.gz>.)
>>
>>    The package consists (only) of the following S3 method definitions:
>>
>> coeftab<- function(object, ...) UseMethod("coeftab",object)
>> coeftab.default<- function(object,...) {
>>    print(class(summary(object)))
>>    coef(summary(object))
>> }
>>
>>    The NAMESPACE tries to pull in the necessary bits and pieces from lme4
>> to extract summaries and coefficients:
>>
>> export("coeftab","coeftab.default")
>> importClassesFrom(lme4,"mer","summary.mer")
>> importMethodsFrom(lme4,"coef","summary","show","print")
> 
> It 'turns out' that base::summary is an S3 generic. Matrix creates an S4
> generic that is distinct from base::summary (e.g., so that the default
> behavior of summary isn't altered for packages that want to have nothing
> to do with Matrix). Dispatch needs to go through the generic. lme4 has
> methods on Matrix::summary, not on base::summary, so without the
> Matrix::summary generic your object never sees the summary method for
> lme4 objects.
> 
> So you need to Import: Matrix and importFrom(Matrix, summary).
> 
> Martin Morgan
> 

  Thank you!  The sun truly never sets on R-devel ...

  Did you know this from [painful] experience, or is there some sensible
diagnostic procedure I could have followed to track this down?

  (I will second the recent comment
<http://r.789695.n4.nabble.com/Namespace-dependency-not-required-td3404575.html>
that "Namespace dependency not required: lme4a" is not very clear.  In
the spirit of improvement I attach a proposed patch for
src/library/tools/R/QC.R ... I think "dependence" works better than
"dependency" in English, too: e.g.
<http://newsgroups.derkeiler.com/Archive/Alt/alt.usage.english/2007-07/msg03530.html>.)

  Ben Bolker

>> exportMethods("coef","summary","show","print")
>> exportClasses("mer","summary.mer")
>> S3method(coeftab,default)
>>
>>    The package passes the routine parts of R CMD check.  The following
>> test shows that, with lme4 loaded, coef(summary([object of class
>> "mer"])) works in the global environment, but not in a function defined
>> inside the namespace of the package.
>>
>>    The output ends with:
>>
>>> coeftab.default(gm1)
>> [1] "summaryDefault" "table"
>> Error in object$coefficients : $ operator is invalid for atomic vectors
>> Calls: coeftab.default ->  coef ->  coef ->  coef.default
>>
>>    which indicates that inside the function, summary() is calling
>> summary.default instead of seeing the summary method for "mer" objects
>> ...
>>
>>
>>    I have (re-re-re-)read the appropriate R-exts section, without luck,
>> and tried various minor variations (e.g. import()ing all of lme4,
>> changing the order of the directive, ...).
>>
>>    Help ... ?
>>
>>    sincerely
>>      Ben Bolker
>>
>> =====
>> test.R
>> =====
>>
>> library(coefsumtest)
>> library(lme4)
>>
>> gm1<- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
>>               family = binomial, data = cbpp)
>>
>> coef(summary(gm1)) ## works
>>
>> f<- function(g) {
>>    coef(summary(g))
>> }
>> f(gm1)  ## works
>>
>> coeftab.default(gm1) ##
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: QC_R.txt
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110326/0724c3b5/attachment.txt>

From gavin.simpson at ucl.ac.uk  Sat Mar 26 22:39:37 2011
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Sat, 26 Mar 2011 21:39:37 +0000
Subject: [Rd] rebuilding vignettes in 2.13-0-alpha fails if name of source
 dir is not package name
Message-ID: <1301175577.2723.24.camel@chrysothemis.geog.ucl.ac.uk>

Dear list,

I have been checking my package ('analogue') using R2.13-0-alpha
(details of exact svn version appended below) and the R CMD check
procedure is generating an error rebuilding a vignette in the package,
which raises a NOTE in the check.

The log printed to screen during check shows:

....
* checking re-building of vignettes ... NOTE
Error in re-building vignettes:
  ...
Error in pkgVignettes(package = package, dir = dir, lib.loc = lib.loc) : 
  directory '/home/gavin/work/R/packages/analogue/analogue_check/pkg.Rcheck/vign_test/analogue' does not exist
Calls: buildVignettes -> pkgVignettes
Execution halted

* checking PDF version of manual ... OK

The entire log is appended below the sessionInfo() output.

If I look in the directory where I am checking the package, I have
pkg.Rcheck and inside the I have vign_test. Inside that directory I have
a 'pkg' directory, but no 'analogue' directory.

My source is in a directory 'pkg' after the set-up provided by
r-forge.r-project.net.

It looks like the code expects a directory with the same name as the
package name in vign_test or the directory in vign_test is not being
named correctly.

R CMD check proceeds without this issue in R 2.12-patched.

If you need further information, let me know.

All the best,

Gavin

> sessionInfo()
R version 2.13.0 alpha (2011-03-26 r55068)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_GB.utf8       LC_NUMERIC=C             
 [3] LC_TIME=en_GB.utf8        LC_COLLATE=en_GB.utf8    
 [5] LC_MONETARY=C             LC_MESSAGES=en_GB.utf8   
 [7] LC_PAPER=en_GB.utf8       LC_NAME=C                
 [9] LC_ADDRESS=C              LC_TELEPHONE=C           
[11] LC_MEASUREMENT=en_GB.utf8 LC_IDENTIFICATION=C      

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods  
[7] base

00check.log - ignore the missing documentation and documentation
mismatch warnings - they are for code I am currently checking/working on
that only exists in my local source tree not in the R-forge repository
nor in the package sources on CRAN.

* using log directory ?/home/gavin/work/R/packages/analogue/analogue_check/pkg.Rcheck?
* using R version 2.13.0 alpha (2011-03-26 r55068)
* using platform: x86_64-unknown-linux-gnu (64-bit)
* using session charset: UTF-8
* checking for file ?pkg/DESCRIPTION? ... OK
* checking extension type ... Package
* this is package ?analogue? version ?0.7-0?
* checking package dependencies ... OK
* checking if this is a source package ... WARNING
Subdirectory ?analogue/src? contains object files.
* checking for executable files ... OK
* checking whether package ?analogue? can be installed ... OK
* checking installed package size ... OK
* checking package directory ... OK
* checking for portable file names ... OK
* checking for sufficient/correct file permissions ... OK
* checking DESCRIPTION meta-information ... OK
* checking top-level files ... OK
* checking index information ... OK
* checking package subdirectories ... OK
* checking R files for non-ASCII characters ... OK
* checking R files for syntax errors ... OK
* checking whether the package can be loaded ... OK
* checking whether the package can be loaded with stated dependencies ... OK
* checking whether the package can be unloaded cleanly ... OK
* checking for unstated dependencies in R code ... OK
* checking S3 generic/method consistency ... OK
* checking replacement functions ... OK
* checking foreign function calls ... OK
* checking R code for possible problems ... NOTE
prcurve: no visible global function definition for ?pcget.lam?
* checking Rd files ... NOTE
prepare_Rd: coreData.Rd:19-20: Dropping empty section \usage
prepare_Rd: coreData.Rd:21-22: Dropping empty section \arguments
prepare_Rd: coreData.Rd:23-24: Dropping empty section \details
* checking Rd metadata ... OK
* checking Rd cross-references ... OK
* checking for missing documentation entries ... WARNING
Undocumented code objects:
  OOB ageModel ageModel.coreData ageModel.default dates dates.coreData
  dates.default depths depths.coreData depths.default distance2
  distance2.default gradientDist gradientDist.cca gradientDist.default
  gradientDist.prcurve intervals intervals.coreData intervals.default
  lines.gradientDist metadata metadata.coreData plot.gradientDist
  points.gradientDist randomWA randomWA.default rbind.coreData varExpl
  varExpl.cca varExpl.default varExpl.prcurve waPred
All user-level objects in a package should have
documentation entries.
See the chapter 'Writing R documentation files' in manual
'Writing R Extensions'.
* checking for code/documentation mismatches ... WARNING
Codoc mismatches from documentation object 'prcurve':
prcurve
  Code: function(X, method = c("ca", "pca", "random"), smoother =
                 smoothSpline, complexity, vary = FALSE, maxComp,
                 finalCV = FALSE, axis = 1, rank = FALSE, stretch = 2,
                 maxit = 10, trace = FALSE, thresh = 0.001, plotit =
                 FALSE, fitFUN = c("princurve", "pcurve"), latent =
                 FALSE, ...)
  Docs: function(X, method = c("ca", "pca", "random"), smoother =
                 smoothSpline, complexity, vary = FALSE, maxComp,
                 finalCV = FALSE, axis = 1, rank = FALSE, stretch = 2,
                 maxit = 10, trace = FALSE, thresh = 0.001, plotit =
                 FALSE, ...)
  Argument names in code not in docs:
    fitFUN latent
  Mismatches in argument names:
    Position: 15 Code: fitFUN Docs: ...

* checking Rd \usage sections ... OK
* checking Rd contents ... OK
* checking for unstated dependencies in examples ... OK
* checking contents of 'data' directory ... OK
* checking data for non-ASCII characters ... OK
* checking data for ASCII and uncompressed saves ... OK
* checking line endings in C/C++/Fortran sources/headers ... OK
* checking line endings in Makefiles ... OK
* checking for portable use of $(BLAS_LIBS) and $(LAPACK_LIBS) ... OK
* checking examples ... OK
* checking for unstated dependencies in vignettes ... OK
* checking package vignettes in ?inst/doc? ... OK
* checking running R code from vignettes ... OK
* checking re-building of vignettes ... NOTE
Error in re-building vignettes:
  ...
Error in pkgVignettes(package = package, dir = dir, lib.loc = lib.loc) : 
  directory '/home/gavin/work/R/packages/analogue/analogue_check/pkg.Rcheck/vign_test/analogue' does not exist
Calls: buildVignettes -> pkgVignettes
Execution halted

* checking PDF version of manual ... OK
WARNING: There were 3 warnings, see
  ?/home/gavin/work/R/packages/analogue/analogue_check/pkg.Rcheck/00check.log?
for details

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From pauljohn32 at gmail.com  Sat Mar 26 23:07:58 2011
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Sat, 26 Mar 2011 17:07:58 -0500
Subject: [Rd] Standalone C++ application for processing R parser
	output(SEXP)
In-Reply-To: <AANLkTim2_zn4_w5WiovLF8O-FH=EAh2241AxkBiMAK0R@mail.gmail.com>
References: <AANLkTim2_zn4_w5WiovLF8O-FH=EAh2241AxkBiMAK0R@mail.gmail.com>
Message-ID: <AANLkTike7_WcP7Gqy6DvfrMtWvCw7rf640DoAtzOBDNi@mail.gmail.com>

On Wed, Mar 23, 2011 at 6:35 PM, Rob Anderson <rkjandra at gmail.com> wrote:
> Hi All,
>
> I am trying to write a source-to-source compiler for R. I am trying to
> leverage the R parser code for the purpose. I am trying to transform the
> SEXP returned from the parser into an AST for our own Ruby embedded Domain
> specific language.
>
> I tried using R CMD SHBIN to compile a C function that parses arbitrary R
> expressions. But I think, the generated .so file can be used from within R
> and not be called from other C or Ruby programs(I get linker errors).
>

I hope I am not telling you what you already know.   There are working
examples of "C Standalone" programs that link with R mathlib. I
learned from the examples here

http://www.math.ncu.edu.tw/~chenwc/R_note/index.php?item=standalone

and

http://www.stat.berkeley.edu/classes/s243/rmath.html

I can't say for sure if these give you access to all of the R stuff
you want, but you do get access to quite a bit.

PJ




> My Idea ?is to use the SEXP processing functions/MACROS (CAR, CDR, CADR,
> etc..) from within C code and transform it to our AST format. I tried
> linking to libR.a and other lib*.so's when I compile the C code using gcc
> but, it doesn't work.
>
> I read that R exposes only small number of functions for library/package
> writers and the compiled *.so can only from within R.
>
> Any ideas on what is wrong, or how I can go about it?
>
> Appreciate any help.
>
> Thanks
> RJ
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas


From hintak_leung at yahoo.co.uk  Sat Mar 26 23:21:52 2011
From: hintak_leung at yahoo.co.uk (Hin-Tak Leung)
Date: Sat, 26 Mar 2011 22:21:52 +0000 (GMT)
Subject: [Rd] core Matrix package segfaulted on R CMD check --use-gct
Message-ID: <255683.81856.qm@web29515.mail.ird.yahoo.com>

Current core/Recommended Matrix package (0.999375-48) has been segfaulting against R 2.13-alpha/2.14-trunk for the last week or so (since R-2.13 was branched, when I started trying) when "run with R CMD check --use-gct":

--------------
> pkgname <- "Matrix"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> gctorture(TRUE)
> options(warn = 1)
> library('Matrix')
Loading required package: lattice
Error : .onLoad failed in loadNamespace() for 'Matrix', details:
  call: fun(...)
  error: unprotected object (0x2768b18) encountered (was REALSXP)
Error: package/namespace load failed for 'Matrix'
Execution halted
---------------

I traced to this because "R CMD check --use-gct snpStats" (both 1.1.13 and 1.1.12) segfaults with the same message, and before that, the snpMatrix 1.15.8.4 which includes some of David's newly written ld() ( which depends on Matrix.)

If the Matrix package segfaults, David's new ld() isn't useable.



From matloff at cs.ucdavis.edu  Sun Mar 27 00:41:47 2011
From: matloff at cs.ucdavis.edu (Norm Matloff)
Date: Sat, 26 Mar 2011 16:41:47 -0700
Subject: [Rd] bug (or feature) in alpha 2.13?
Message-ID: <20110326234147.GA4559@laura>



The pattern (I can make a simple example if needed):

   > source("x.R")
   > options(error=recover)
   > x <- ...
   > f(x)  # f() from x.R 
      (subscript bounds error, now in recover())
   Selection: 1
   Browse[1]> where

In the output from "where," there should be information on the line
number at which the user code blew up.  It's there in 2.12, but not in
2.13, from what I can see.

Norm Matloff


From ripley at stats.ox.ac.uk  Sun Mar 27 05:49:05 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 27 Mar 2011 04:49:05 +0100 (BST)
Subject: [Rd] .Fortran successful, R locks up.
In-Reply-To: <AANLkTim+f=i5DnNfaQNKQHwxnF4KBBcUNGrKkHMczRsm@mail.gmail.com>
References: <AANLkTikgcW_L1kYER3bDZJCsD8xC7BwJpMhRKUX8Xt8N@mail.gmail.com>
	<4D8C8D6F.7040700@gmail.com>
	<AANLkTim+f=i5DnNfaQNKQHwxnF4KBBcUNGrKkHMczRsm@mail.gmail.com>
Message-ID: <alpine.LFD.2.02.1103270433380.15005@gannet.stats.ox.ac.uk>

You seem to have missed the force of the warning in 'Writing R 
Extensions'.

If you include *any* Fortrann I/O in your package code, you are at 
risk from it interfering with C I/O, whether or not that Fortran I/O 
is called.

On some platforms with gfortran, merely loading such a package's 
DSO/DLL calls the libgfortran initialization functions and they reset 
the process' stdin, causing the behaviour you saw.

You have not told us what compilers etc you are using.  On some 
versions of gfortran you can avoid this by setting the environment 
variables

GFORTRAN_STDOUT_UNIT
GFORTRAN_STDERR_UNIT

to -1: these tell gfortran not to use C stdout/stderr (and because of 
what I can only see is a bug, it was the use of those which resets 
stdin).


On Fri, 25 Mar 2011, Daniel Fuka wrote:

> Thanks Duncan for helping me along the way. I am working in OSX,
> Linux, and Windows, and gdb is helping me trace it along to what
> appears to be an endless processor intensive loop in sys-std.c .
> Below, I have pasted the output. All files are closed as verified by
> lsof. There is absolutely no stdio other than what I have put in a
> call to R library's subroutine intpr, all other io is routed to files,
> which are all successfully closed. The entire routine successfully
> runs, and spits out the output from intpr. Is there supposed to be
> something returned from the Fortran routine that Rstd_ReadConsole is
> looking for? I have attached the final lines of the fortran
> subroutine, as well as the gdb steps post fortran routine. Any
> additional help is greatly appreciated!

...

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch.duncan at gmail.com  Sun Mar 27 13:42:02 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 27 Mar 2011 07:42:02 -0400
Subject: [Rd] bug (or feature) in alpha 2.13?
In-Reply-To: <20110326234147.GA4559@laura>
References: <20110326234147.GA4559@laura>
Message-ID: <4D8F228A.7010100@gmail.com>

On 11-03-26 7:41 PM, Norm Matloff wrote:
>
>
> The pattern (I can make a simple example if needed):
>
>     >  source("x.R")
>     >  options(error=recover)
>     >  x<- ...
>     >  f(x)  # f() from x.R
>        (subscript bounds error, now in recover())
>     Selection: 1
>     Browse[1]>  where
>
> In the output from "where," there should be information on the line
> number at which the user code blew up.  It's there in 2.12, but not in
> 2.13, from what I can see.

That's not intentional.  I'll see what went wrong...

Duncan Murdoch


From gavin.simpson at ucl.ac.uk  Sun Mar 27 14:48:27 2011
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Sun, 27 Mar 2011 13:48:27 +0100
Subject: [Rd] Bug in tools::compactPDF() in 2.13-0-alpha
Message-ID: <1301230107.8781.7.camel@chrysothemis.geog.ucl.ac.uk>

Dear List,

There seems to be an bug in compactPDF() or at least an inconsistency
with the documented behaviour.

The documentations states:

Details:

     This by default makes use of ?qpdf?, available from <URL:
     http://qpdf.sourceforge.net/>, including a Windows binary.  If
     ?gs_cmd? is non-empty, GhostScript is used.

I don't have qpdf on my system so planned to use ghostscript. However,
the code for compactPDF() has as it's first few lines:

    if (!nzchar(Sys.which(qpdf))) 
        return()

So because I don't have qpdf, compactPDF() always returns NULL:

> nzchar(Sys.which(Sys.getenv("R_QPDF", "qpdf")))
[1] FALSE

> compactPDF("../analogue/pkg/inst/doc/analogue_methods.pdf", gs_cmd = "/usr/bin/")
NULL

no matter what I do.

This is with:

> sessionInfo()
R version 2.13.0 alpha (2011-03-27 r55077)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_GB.utf8       LC_NUMERIC=C             
 [3] LC_TIME=en_GB.utf8        LC_COLLATE=en_GB.utf8    
 [5] LC_MONETARY=C             LC_MESSAGES=en_GB.utf8   
 [7] LC_PAPER=en_GB.utf8       LC_NAME=C                
 [9] LC_ADDRESS=C              LC_TELEPHONE=C           
[11] LC_MEASUREMENT=en_GB.utf8 LC_IDENTIFICATION=C      

attached base packages:
[1] tools     stats     graphics  grDevices utils     datasets 
[7] methods   base 

Thanks,

Gavin
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From murdoch.duncan at gmail.com  Sun Mar 27 14:57:08 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 27 Mar 2011 08:57:08 -0400
Subject: [Rd] bug (or feature) in alpha 2.13?
In-Reply-To: <4D8F228A.7010100@gmail.com>
References: <20110326234147.GA4559@laura> <4D8F228A.7010100@gmail.com>
Message-ID: <4D8F3424.5030804@gmail.com>

On 11-03-27 7:42 AM, Duncan Murdoch wrote:
> On 11-03-26 7:41 PM, Norm Matloff wrote:
>>
>>
>> The pattern (I can make a simple example if needed):
>>
>>      >   source("x.R")
>>      >   options(error=recover)
>>      >   x<- ...
>>      >   f(x)  # f() from x.R
>>         (subscript bounds error, now in recover())
>>      Selection: 1
>>      Browse[1]>   where
>>
>> In the output from "where," there should be information on the line
>> number at which the user code blew up.  It's there in 2.12, but not in
>> 2.13, from what I can see.
>
> That's not intentional.  I'll see what went wrong...
>
> Duncan Murdoch

Fixed now.  Because of the internal change to srcref records

       \item \code{"srcref"} attributes now include two additional
       line number values, recording the line numbers in the order they
       were parsed.

the code that saved the current location didn't recognize the record, 
and skipped saving it.

Duncan Murdoch


From murdoch.duncan at gmail.com  Sun Mar 27 15:00:37 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 27 Mar 2011 09:00:37 -0400
Subject: [Rd] Bug in tools::compactPDF() in 2.13-0-alpha
In-Reply-To: <1301230107.8781.7.camel@chrysothemis.geog.ucl.ac.uk>
References: <1301230107.8781.7.camel@chrysothemis.geog.ucl.ac.uk>
Message-ID: <4D8F34F5.3030706@gmail.com>

On 11-03-27 8:48 AM, Gavin Simpson wrote:
> Dear List,
>
> There seems to be an bug in compactPDF() or at least an inconsistency
> with the documented behaviour.

Thanks, looks easy to fix.  I'll make the correction.  (A bit more below...)

>
> The documentations states:
>
> Details:
>
>       This by default makes use of ?qpdf?, available from<URL:
>       http://qpdf.sourceforge.net/>, including a Windows binary.  If
>       ?gs_cmd? is non-empty, GhostScript is used.
>
> I don't have qpdf on my system so planned to use ghostscript. However,
> the code for compactPDF() has as it's first few lines:
>
>      if (!nzchar(Sys.which(qpdf)))
>          return()
>
> So because I don't have qpdf, compactPDF() always returns NULL:
>
>> nzchar(Sys.which(Sys.getenv("R_QPDF", "qpdf")))
> [1] FALSE
>
>> compactPDF("../analogue/pkg/inst/doc/analogue_methods.pdf", gs_cmd = "/usr/bin/")

That won't work:  you need the full path to the gs_cmd, not just its 
home directory.

Duncan Murdoch

> NULL
>
> no matter what I do.
>
> This is with:
>
>> sessionInfo()
> R version 2.13.0 alpha (2011-03-27 r55077)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>   [1] LC_CTYPE=en_GB.utf8       LC_NUMERIC=C
>   [3] LC_TIME=en_GB.utf8        LC_COLLATE=en_GB.utf8
>   [5] LC_MONETARY=C             LC_MESSAGES=en_GB.utf8
>   [7] LC_PAPER=en_GB.utf8       LC_NAME=C
>   [9] LC_ADDRESS=C              LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_GB.utf8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] tools     stats     graphics  grDevices utils     datasets
> [7] methods   base
>
> Thanks,
>
> Gavin


From matloff at cs.ucdavis.edu  Sun Mar 27 18:42:23 2011
From: matloff at cs.ucdavis.edu (Norm Matloff)
Date: Sun, 27 Mar 2011 09:42:23 -0700
Subject: [Rd] bug (or feature) in alpha 2.13?
In-Reply-To: <4D8F3424.5030804@gmail.com>
References: <20110326234147.GA4559@laura> <4D8F228A.7010100@gmail.com>
	<4D8F3424.5030804@gmail.com>
Message-ID: <20110327164222.GA16056@laura>


Thanks very much, Duncan.

Norm

On Sun, Mar 27, 2011 at 08:57:08AM -0400, Duncan Murdoch wrote:

> Fixed now.  Because of the internal change to srcref records
>
>       \item \code{"srcref"} attributes now include two additional
>       line number values, recording the line numbers in the order they
>       were parsed.
>
> the code that saved the current location didn't recognize the record,  
> and skipped saving it.
>
> Duncan Murdoch


From gavin.simpson at ucl.ac.uk  Sun Mar 27 19:28:00 2011
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Sun, 27 Mar 2011 18:28:00 +0100
Subject: [Rd] Bug in tools::compactPDF() in 2.13-0-alpha
In-Reply-To: <4D8F34F5.3030706@gmail.com>
References: <1301230107.8781.7.camel@chrysothemis.geog.ucl.ac.uk>
	<4D8F34F5.3030706@gmail.com>
Message-ID: <1301246880.2781.9.camel@chrysothemis.geog.ucl.ac.uk>

On Sun, 2011-03-27 at 09:00 -0400, Duncan Murdoch wrote:
> On 11-03-27 8:48 AM, Gavin Simpson wrote:
> > Dear List,
> >
> > There seems to be an bug in compactPDF() or at least an inconsistency
> > with the documented behaviour.
> 
> Thanks, looks easy to fix.  I'll make the correction.  (A bit more below...)

Thanks Duncan,

<snip />

> >> compactPDF("../analogue/pkg/inst/doc/analogue_methods.pdf", gs_cmd = "/usr/bin/")
> 
> That won't work:  you need the full path to the gs_cmd, not just its 
> home directory.

Ah; I wasn't sure exactly what R expected here and tried several
versions including the full path before diving into the code to see what
the problem was. The call I included just happened to be the last one I
had tried in my R session.

All the best,

G

> Duncan Murdoch
> 
> > NULL
> >
> > no matter what I do.
> >
> > This is with:
> >
> >> sessionInfo()
> > R version 2.13.0 alpha (2011-03-27 r55077)
> > Platform: x86_64-unknown-linux-gnu (64-bit)
> >
> > locale:
> >   [1] LC_CTYPE=en_GB.utf8       LC_NUMERIC=C
> >   [3] LC_TIME=en_GB.utf8        LC_COLLATE=en_GB.utf8
> >   [5] LC_MONETARY=C             LC_MESSAGES=en_GB.utf8
> >   [7] LC_PAPER=en_GB.utf8       LC_NAME=C
> >   [9] LC_ADDRESS=C              LC_TELEPHONE=C
> > [11] LC_MEASUREMENT=en_GB.utf8 LC_IDENTIFICATION=C
> >
> > attached base packages:
> > [1] tools     stats     graphics  grDevices utils     datasets
> > [7] methods   base
> >
> > Thanks,
> >
> > Gavin
> 

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From drf28 at cornell.edu  Sun Mar 27 21:31:11 2011
From: drf28 at cornell.edu (Daniel Fuka)
Date: Sun, 27 Mar 2011 15:31:11 -0400
Subject: [Rd] .Fortran successful, R locks up.
In-Reply-To: <alpine.LFD.2.02.1103270433380.15005@gannet.stats.ox.ac.uk>
References: <AANLkTikgcW_L1kYER3bDZJCsD8xC7BwJpMhRKUX8Xt8N@mail.gmail.com>
	<4D8C8D6F.7040700@gmail.com>
	<AANLkTim+f=i5DnNfaQNKQHwxnF4KBBcUNGrKkHMczRsm@mail.gmail.com>
	<alpine.LFD.2.02.1103270433380.15005@gannet.stats.ox.ac.uk>
Message-ID: <AANLkTi=oUe9tvRhOdOH=Db2KwKs1deuQJX1e-GkoA7OM@mail.gmail.com>

Duncan and Brian,

Thanks again for the help with this. As it turns out the suggestion of
setting the GFORTRAN_STDIN_UNIT=-1 has the library working for Mac,
Linux, and Windows, so it appears to be in a STDIN read somewhere. Of
the 1100 read statements in the code, none are from stdin, or unit 5.
Oddly enough, without the environment variable set, everything runs
fine looping within a script called from command line (-f) which I
delve into a bit below. So, we are functional on repo binaries, and
standard linux distros, but intel fortran and xlf appear to have
issues still... not a big deal, but if anyone is willing to give me
suggestions on other things I can use to try to debug this issue, I
would love to clear it up.

Sorry for not giving all the background information. I am
working/testing on Mac OSX(gfortran 4.2.3, intel fortran 11), Linux
(gfortran 4.1.2, intel fortran 11) , WindowsXP (gfortran 4.5), and
AIX(xlf v12.1). Right now the environment variable will work I believe
since we are just trying to get the standard r-forge distro binaries
to work with the package, though I shall keep looking for the STDIN
that appears to have been opened.

> Sys.setenv(GFORTRAN_STDIN_UNIT=-1)
> library.dynam("rswat","EcoHydrology")
> .Fortran("junk",3)
SWAT Run Successful
[1] 0
[[1]]
[1] 3

>
>

Just a bit more information here on this issue. Without the
Sys.setenv(GFORTRAN_STDIN_UNIT=-1) function, the .Fortran call runs
fine in a loop when called from command line script file (-f) call.
When called from interactive session, it runs successfully, then gets
stuck in an endless loop of lines 911, 912, 904 in in
../../../../R-2.12.1/src/unix/sys-std.c . There appears to be no STDIO
in the routines, and to make sure, I am now closing all the stdio
units at the end of the run.

DRF28: dan$ cat test.R
library.dynam("rswat","EcoHydrology")
for (i in 0:5){
.Fortran("junk",i)
print(paste("success",i))
}
DRF28: dan$ r -q -f test.R
> library.dynam("rswat","EcoHydrology")
> for (i in 0:5){
+ .Fortran("junk",i)
+ print(paste("success",i))
+ }
SWAT Run Successful
[1] 0
[1] "success 0"
SWAT Run Successful
[1] 1
[1] "success 1"
SWAT Run Successful
[1] 2
[1] "success 2"
----SNIP----


On Sat, Mar 26, 2011 at 11:49 PM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> You seem to have missed the force of the warning in 'Writing R Extensions'.
>
> If you include *any* Fortrann I/O in your package code, you are at risk from
> it interfering with C I/O, whether or not that Fortran I/O is called.
>
> On some platforms with gfortran, merely loading such a package's DSO/DLL
> calls the libgfortran initialization functions and they reset the process'
> stdin, causing the behaviour you saw.
>
> You have not told us what compilers etc you are using. ?On some versions of
> gfortran you can avoid this by setting the environment variables
>
> GFORTRAN_STDOUT_UNIT
> GFORTRAN_STDERR_UNIT
>
> to -1: these tell gfortran not to use C stdout/stderr (and because of what I
> can only see is a bug, it was the use of those which resets stdin).
>
>
> On Fri, 25 Mar 2011, Daniel Fuka wrote:
>
>> Thanks Duncan for helping me along the way. I am working in OSX,
>> Linux, and Windows, and gdb is helping me trace it along to what
>> appears to be an endless processor intensive loop in sys-std.c .
>> Below, I have pasted the output. All files are closed as verified by
>> lsof. There is absolutely no stdio other than what I have put in a
>> call to R library's subroutine intpr, all other io is routed to files,
>> which are all successfully closed. The entire routine successfully
>> runs, and spits out the output from intpr. Is there supposed to be
>> something returned from the Fortran routine that Rstd_ReadConsole is
>> looking for? I have attached the final lines of the fortran
>> subroutine, as well as the gdb steps post fortran routine. Any
>> additional help is greatly appreciated!
>
> ...
>
> --
> Brian D. Ripley, ? ? ? ? ? ? ? ? ?ripley at stats.ox.ac.uk
> Professor of Applied Statistics, ?http://www.stats.ox.ac.uk/~ripley/
> University of Oxford, ? ? ? ? ? ? Tel: ?+44 1865 272861 (self)
> 1 South Parks Road, ? ? ? ? ? ? ? ? ? ? +44 1865 272866 (PA)
> Oxford OX1 3TG, UK ? ? ? ? ? ? ? ?Fax: ?+44 1865 272595
>


From cubranic at stat.ubc.ca  Mon Mar 28 00:05:58 2011
From: cubranic at stat.ubc.ca (Davor Cubranic)
Date: Sun, 27 Mar 2011 15:05:58 -0700
Subject: [Rd] another import puzzle
In-Reply-To: <4D8E3C49.2030003@gmail.com>
References: <4D8E2CF4.1030307@gmail.com> <4D8E35EC.20406@fhcrc.org>
	<4D8E3C49.2030003@gmail.com>
Message-ID: <201103271505.58688.cubranic@stat.ubc.ca>

On 03/26/2011 12:19 PM, Ben Bolker wrote:
> ["Namespace dependency not required: lme4a"]
> I think "dependence" works better than "dependency" in English, too

I'm not a native English speaker, but "dependency" is a pretty standard 
software engineering term for this kind of relationship. I.e., "lme4a" 
is the dependency, or rather has been declared as such, but it is not 
needed.

Davor


From S.Ellison at lgc.co.uk  Mon Mar 28 03:33:48 2011
From: S.Ellison at lgc.co.uk (S Ellison)
Date: Mon, 28 Mar 2011 02:33:48 +0100
Subject: [Rd] Windows build not running on r-forge
Message-ID: <sd8ff396.088@tedmail.lgc.co.uk>

Please forgive any mis-post, and do feel free to point me to a more
appropriate list if this isn't properly R-dev.

I have a package on R-forge that shows correct linux and other *nix
builds, but no windows build. The log for the patched version shows the
error below, which appears to be due to a lack of /src files, a problem
that does not halt the *nix builds.

The package contains no compiled code (src is intentionally empty).


Log as follows:
* installing to library 'R:/lib/R/CRAN/2.12'
* installing *source* package 'metRology' ...
** libs

*** arch - i386
Error in file.copy(Sys.glob("src/*"), ss, recursive = TRUE) : 
  no files to copy from
* removing 'R:/lib/R/CRAN/2.12/metRology'
Run time: 1.27 seconds.

Advice would be welcome on what I can do about it...?

Steve Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From mtmorgan at fhcrc.org  Mon Mar 28 06:06:40 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Sun, 27 Mar 2011 21:06:40 -0700
Subject: [Rd] R-2-13-alpha invalid subscript when checking for unstated
	dependencies
Message-ID: <4D900950.4040602@fhcrc.org>

R version 2.13.0 alpha (2011-03-27 r55091)

This error occurs when R CMD check'ing a Bioconductor package:

* checking for unstated dependencies in R code ... WARNING
Error in e[keep] : invalid subscript type 'list'
Execution halted
See the information on DESCRIPTION files in the chapter 'Creating R
packages' of the 'Writing R Extensions' manual.

It is because the author has a sub-expression to 'require' that exceeds 
the width.cutoff=60L default argument of deparse, e.g.,

require(gsub("onereallyquitelongstring",
              "anotherreallyquitelongstring",
               variablename),
         character.only=TRUE)

This results in a list rather than vector in (one of) tools::QC.R:4106 
or 4258.
-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From mtmorgan at fhcrc.org  Mon Mar 28 06:06:40 2011
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Sun, 27 Mar 2011 21:06:40 -0700
Subject: [Rd] R-2-13-alpha invalid subscript when checking for unstated
	dependencies
Message-ID: <4D900950.4040602@fhcrc.org>

R version 2.13.0 alpha (2011-03-27 r55091)

This error occurs when R CMD check'ing a Bioconductor package:

* checking for unstated dependencies in R code ... WARNING
Error in e[keep] : invalid subscript type 'list'
Execution halted
See the information on DESCRIPTION files in the chapter 'Creating R
packages' of the 'Writing R Extensions' manual.

It is because the author has a sub-expression to 'require' that exceeds 
the width.cutoff=60L default argument of deparse, e.g.,

require(gsub("onereallyquitelongstring",
              "anotherreallyquitelongstring",
               variablename),
         character.only=TRUE)

This results in a list rather than vector in (one of) tools::QC.R:4106 
or 4258.
-- 
Computational Biology
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N. PO Box 19024 Seattle, WA 98109

Location: M1-B861
Telephone: 206 667-2793


From ripley at stats.ox.ac.uk  Mon Mar 28 06:32:53 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 28 Mar 2011 05:32:53 +0100
Subject: [Rd] Windows build not running on r-forge
In-Reply-To: <sd8ff396.088@tedmail.lgc.co.uk>
References: <sd8ff396.088@tedmail.lgc.co.uk>
Message-ID: <alpine.LFD.2.02.1103280527170.2409@gannet.stats.ox.ac.uk>

On Mon, 28 Mar 2011, S Ellison wrote:

> Please forgive any mis-post, and do feel free to point me to a more
> appropriate list if this isn't properly R-dev.
>
> I have a package on R-forge that shows correct linux and other *nix
> builds, but no windows build. The log for the patched version shows the
> error below, which appears to be due to a lack of /src files, a problem
> that does not halt the *nix builds.
>
> The package contains no compiled code (src is intentionally empty).
>
>
> Log as follows:
> * installing to library 'R:/lib/R/CRAN/2.12'
> * installing *source* package 'metRology' ...
> ** libs
>
> *** arch - i386
> Error in file.copy(Sys.glob("src/*"), ss, recursive = TRUE) :
>  no files to copy from
> * removing 'R:/lib/R/CRAN/2.12/metRology'
> Run time: 1.27 seconds.
>
> Advice would be welcome on what I can do about it...?

Don't have an empty 'src' directory: that is not a valid source 
package.

And please do tell us the version of R as per the posting guide.  I am 
guessing 2.12.2 here.

>
> Steve Ellison
>
>
> *******************************************************************
> This email and any attachments are confidential. Any use...{{dropped:8}}
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From bates at stat.wisc.edu  Mon Mar 28 16:24:39 2011
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 28 Mar 2011 09:24:39 -0500
Subject: [Rd] core Matrix package segfaulted on R CMD check --use-gct
In-Reply-To: <255683.81856.qm@web29515.mail.ird.yahoo.com>
References: <255683.81856.qm@web29515.mail.ird.yahoo.com>
Message-ID: <AANLkTimDJbJ-u3wXOyvPB0EePf98AZ-R5duKVr+Guh-v@mail.gmail.com>

Can you provide the output from

sessionInfo()

so we can know the platform?  Also, did you configure R with
--enable-strict-barrier or set the C compilation flag
-DTESTING_WRITE_BARRIER?  I think that run-time error message can only
be thrown under those circumstances (not that it isn't an error, it's
just not checked for in other circumstances).

On Sat, Mar 26, 2011 at 5:21 PM, Hin-Tak Leung <hintak_leung at yahoo.co.uk> wrote:
> Current core/Recommended Matrix package (0.999375-48) has been segfaulting against R 2.13-alpha/2.14-trunk for the last week or so (since R-2.13 was branched, when I started trying) when "run with R CMD check --use-gct":
>
> --------------
>> pkgname <- "Matrix"
>> source(file.path(R.home("share"), "R", "examples-header.R"))
>> gctorture(TRUE)
>> options(warn = 1)
>> library('Matrix')
> Loading required package: lattice
> Error : .onLoad failed in loadNamespace() for 'Matrix', details:
> ?call: fun(...)
> ?error: unprotected object (0x2768b18) encountered (was REALSXP)
> Error: package/namespace load failed for 'Matrix'
> Execution halted
> ---------------
>
> I traced to this because "R CMD check --use-gct snpStats" (both 1.1.13 and 1.1.12) segfaults with the same message, and before that, the snpMatrix 1.15.8.4 which includes some of David's newly written ld() ( which depends on Matrix.)
>
> If the Matrix package segfaults, David's new ld() isn't useable.
>
>


From maechler at stat.math.ethz.ch  Mon Mar 28 16:47:05 2011
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 28 Mar 2011 16:47:05 +0200
Subject: [Rd] core Matrix package segfaulted on R CMD check --use-gct
In-Reply-To: <AANLkTimDJbJ-u3wXOyvPB0EePf98AZ-R5duKVr+Guh-v@mail.gmail.com>
References: <255683.81856.qm@web29515.mail.ird.yahoo.com>
	<AANLkTimDJbJ-u3wXOyvPB0EePf98AZ-R5duKVr+Guh-v@mail.gmail.com>
Message-ID: <19856.40809.236979.731769@stat.math.ethz.ch>

>>>>> Douglas Bates <bates at stat.wisc.edu>
>>>>>     on Mon, 28 Mar 2011 09:24:39 -0500 writes:

    > Can you provide the output from sessionInfo()

    > so we can know the platform?  Also, did you configure R
    > with --enable-strict-barrier or set the C compilation flag
    > -DTESTING_WRITE_BARRIER?  I think that run-time error
    > message can only be thrown under those circumstances (not
    > that it isn't an error, it's just not checked for in other
    > circumstances).

interesting.

In the mean time, I *did* run --- for several hours! ---
your code example below,
and it did *not* segfault for me (64-bit, Linux Fedora 13).

Martin

>>>>> Douglas Bates <bates at stat.wisc.edu>
>>>>>     on Mon, 28 Mar 2011 09:24:39 -0500 writes:

    > Can you provide the output from
    > sessionInfo()

    > so we can know the platform?  Also, did you configure R with
    > --enable-strict-barrier or set the C compilation flag
    > -DTESTING_WRITE_BARRIER?  I think that run-time error message can only
    > be thrown under those circumstances (not that it isn't an error, it's
    > just not checked for in other circumstances).

    > On Sat, Mar 26, 2011 at 5:21 PM, Hin-Tak Leung <hintak_leung at yahoo.co.uk> wrote:
    >> Current core/Recommended Matrix package (0.999375-48) has been segfaulting against R 2.13-alpha/2.14-trunk for the last week or so (since R-2.13 was branched, when I started trying) when "run with R CMD check --use-gct":
    >> 
    >> --------------
    >>> pkgname <- "Matrix"
    >>> source(file.path(R.home("share"), "R", "examples-header.R"))
    >>> gctorture(TRUE)
    >>> options(warn = 1)
    >>> library('Matrix')
    >> Loading required package: lattice
    >> Error : .onLoad failed in loadNamespace() for 'Matrix', details:
    >> ?call: fun(...)
    >> ?error: unprotected object (0x2768b18) encountered (was REALSXP)
    >> Error: package/namespace load failed for 'Matrix'
    >> Execution halted
    >> ---------------
    >> 
    >> I traced to this because "R CMD check --use-gct snpStats" (both 1.1.13 and 1.1.12) segfaults with the same message, and before that, the snpMatrix 1.15.8.4 which includes some of David's newly written ld() ( which depends on Matrix.)
    >> 
    >> If the Matrix package segfaults, David's new ld() isn't useable.
    >> 
    >>


From jochen.laubrock at gmail.com  Mon Mar 28 16:54:47 2011
From: jochen.laubrock at gmail.com (jochen laubrock)
Date: Mon, 28 Mar 2011 16:54:47 +0200
Subject: [Rd] unique.matrix issue [Was: Anomaly with unique and match]
In-Reply-To: <FBB0B12A-E932-4320-81B5-5106A9698957@r-project.org>
References: <1299682090.12625.9.camel@punchbuggy>
	<FBB0B12A-E932-4320-81B5-5106A9698957@r-project.org>
Message-ID: <99DCAB40-9953-4D23-B662-B47C9F0AB199@gmail.com>

Still, from a user's perspective this behavior is somewhat irritating. Wouldn't it be better to rewrite unique.matrix to use formatC or sprintf instead of as.character, on which paste in line 9 implicitly relies, at least in R version 2.12.2  (2011-02-25)?

For example, use

temp <- apply(x, MARGIN, formatC, digits=324, format="f")

instead of

temp <- apply(x, MARGIN, function(x) paste(x, collapse = "\r"))

Don't know whether this affects performance, though.

Sorry to chime in late. 
Cheers, 
Jochen


> sessionInfo()
R version 2.12.2 (2011-02-25)
Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8


On Mar 9, 2011, at 20:11 , Simon Urbanek wrote:

> match() is a red herring here -- it is really a very specific thing that has to do with the fact that you're running unique() on a matrix. Also it's much easier to reproduce:
> 
>> x=c(1,1+0.2e-15)
>> x
> [1] 1 1
>> sprintf("%a",x)
> [1] "0x1p+0"               "0x1.0000000000001p+0"
>> unique(x)
> [1] 1 1
>> sprintf("%a",unique(x))
> [1] "0x1p+0"               "0x1.0000000000001p+0"
>> unique(matrix(x,2))
>     [,1]
> [1,]    1
> 
> and this comes from the fact that unique.matrix uses string representation since it has to take into account all values of a row/column so it pastes all values into one string, but for the two numbers that is the same:
>> as.character(x)
> [1] "1" "1"
> 
> Cheers,
> Simon
> 
> 
> On Mar 9, 2011, at 9:48 AM, Terry Therneau wrote:
> 
>> I stumbled onto this working on an update to coxph.  The last 6 lines
>> below are the question, the rest create a test data set.
>> 
>> tmt585% R
>> R version 2.12.2 (2011-02-25)
>> Copyright (C) 2011 The R Foundation for Statistical Computing
>> ISBN 3-900051-07-0
>> Platform: x86_64-unknown-linux-gnu (64-bit)
>> 
>> # Lines of code from survival/tests/singtest.R
>>> library(survival)
>> Loading required package: splines
>>> test1 <- data.frame(time=  c(4, 3,1,1,2,2,3),
>> +     status=c(1,NA,1,0,1,1,0),
>> +     x=     c(0, 2,1,1,1,0,0))
>>> 
>>> temp <- rep(0:3, rep(7,4))
>>> 
>>> stest <- data.frame(start  = 10*temp,
>> +     stop   = 10*temp + test1$time,
>> +     status = rep(test1$status,4),
>> +     x      = c(test1$x+ 1:7, rep(test1$x,3)),
>> +     epoch  = rep(1:4, rep(7,4)))
>>> 
>>> fit1 <- coxph(Surv(start, stop, status) ~ x * factor(epoch), stest)
>> 
>> ## New lines
>>> temp1 <- fit1$linear.predictor
>>> temp2 <- as.matrix(temp1)
>>> match(temp1, unique(temp1))
>> [1] 1 2 3 4 4 5 6 7 7 7 6 6 6 8 8 8 6 6 6 9 9 9 6 6
>>> match(temp2, unique(temp2))
>> [1]  1  2  3  4  4  5  6  7  7  7  6  6  6 NA NA NA  6  6  6  8  8  8
>> 6  6
>> 
>> -----------------------
>> 
>> I've solved it for my code by not calling match on a 1 column vector.  
>> In general, however, should I be using some other paradym for this "map
>> to unique" operation?  For example match(as.character(x),
>> unique(as.character(x)) ?
>> 
>> Terry T
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Matt.Shotwell at Vanderbilt.Edu  Mon Mar 28 17:15:52 2011
From: Matt.Shotwell at Vanderbilt.Edu (Matt Shotwell)
Date: Mon, 28 Mar 2011 10:15:52 -0500
Subject: [Rd] Testing window for R 2.13.0
In-Reply-To: <alpine.LFD.2.02.1103182057380.4071@gannet.stats.ox.ac.uk>
References: <alpine.LFD.2.02.1103182057380.4071@gannet.stats.ox.ac.uk>
Message-ID: <4D90A628.4080303@Vanderbilt.edu>

Some very minor things:

- typo R-admin manual, section 2.8, fourth sentence beginning "This will 
find build...", should read "This will build..."?

- typo in src/library/compiler/man/compile.Rd, line 35: 
"\item{ascii}{logical; should the compiled file be saved with in ascii" 
should read "...saved in ascii..."?

My build and test was successful (on a very common platform 
x86-64/Ubuntu). Typescript here:
http://biostatmatt.com/temp/R-alpha-r54865-build-test.html

Cheers to another release,
Matt

On 03/18/2011 04:22 PM, Prof Brian Ripley wrote:
> We are now starting testing R 2.13.0/alpba/beta/RC and testing and
> feedback would be appreciated (whereas reports on problems immediately
> after release will try our patience).
>
> Sources are available at
> http://cran.r-project.org/src/base-prerelease/
> Windows binaries at
> http://cran.r-project.org/bin/windows/base/rtest.html
> and Mac binaries at http://r.research.att.com/, specifically
> http://r.research.att.com/R-2.13-branch-leopard.pkg
> (and it is best to use the CRAN master rather than mirrors which will
> lag behind).
>
> Please report (success as well as failure except on the most common
> platforms) here, R-windows at r-project.org or R-sig-mac at r-project.org. We
> probably have good coverage of Debian/Fedora i686/x86_64 Linux, Mac OS
> X, Windows, Solaris and x86_64 FreeBSD 8.2: reports on other platforms
> would be particularly welcome.
>
> There have been a number of confused postings about 64-bit R on Solaris:
> the R-admin manual in this version contains detailed instructions on
> what works for us (Solaris Studio 12.2 and 12u1, and gcc4 on Sparc) and
> what doesn't (gcc on amd64) and why.
>
> Package maintainers should review the results for their packages at
> http://cran.r-project.org/web/checks/check_summary.html
> and submit updates if needed as soon as possible and definitely well
> before April 13. That page is in the process of migration to R-prerel:
> for now the most useful columns are r-devel (Fedora), r-devel (Windows,
> really R-prerel) and the Solaris x86 column.
>
> Brian Ripley (for the R-core team)
>


-- 
Matthew S Shotwell   Assistant Professor           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From ligges at statistik.tu-dortmund.de  Mon Mar 28 17:37:13 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 28 Mar 2011 17:37:13 +0200
Subject: [Rd] error in: testing if installed package can be loaded
In-Reply-To: <AANLkTin0WpppdN2-edDrCeFLOgR2i+QQr4Vj3tcW2x+B@mail.gmail.com>
References: <AANLkTin0WpppdN2-edDrCeFLOgR2i+QQr4Vj3tcW2x+B@mail.gmail.com>
Message-ID: <4D90AB29.3030405@statistik.tu-dortmund.de>



On 21.03.2011 18:01, Thomas Roth wrote:
> hi,
>
> I am preparing my package for R 2.13
> build and check gives no warnings just OK's
>
> However when running R CMD INSTALL it gives me (nfortunately it is in
> german)
>



You can change to English by setting

set LANGUAGE=en

before running R CMD check.



> ** help
> *** installing help indices
> ** building package indices ...
> ** testing if installed package can be loaded
> Fehler: '\U' ohne Hex-Ziffern in der Zeichenkette beginnend mit "C:\U"
> genutzt
> Ausf?hrung angehalten
> Fehler: loading failed

Interesting. From which path are you testing. Using which command? 
What's the name of the package? Can we see the package? Do you have 
recent Rtools installed?

[Checking packages works on winbuilder with R-2.13.0 alpha for 64-bit 
Windows for all CRAN packages without such a message.]

Best,
Uwe Ligges



> Is this the packages fault? because i wouldn't know where to look...
>
> sessionInfo()  gives
>
> R version 2.13.0 alpha (2011-03-17 r54849)
> Platform: x86_64-pc-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
>   LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
> [5] LC_TIME=German_Germany.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] qualityTools_1.41
>
> loaded via a namespace (and not attached):
> [1] tools_2.13.0
>
> Best Whishes
>
> Thomas Roth
>
> 	[[alternative HTML version deleted]]
>
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.tu-dortmund.de  Mon Mar 28 17:39:43 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 28 Mar 2011 17:39:43 +0200
Subject: [Rd] datalist and data objects in R Package building
In-Reply-To: <AANLkTimqc_jF0RL2jEAWHYTNJVXStJzyv5gNbUszRGpH@mail.gmail.com>
References: <AANLkTimqc_jF0RL2jEAWHYTNJVXStJzyv5gNbUszRGpH@mail.gmail.com>
Message-ID: <4D90ABBF.8030302@statistik.tu-dortmund.de>



On 24.03.2011 16:51, andrew stewart wrote:
> Hello all,
>
> I have,say 4 R objects...  bar1, bar2, bar3, bar4.. that I'd like to include
> in an R package "foobar".
>
> The desired functionality would be:
>
>> library(foobar)
>> data(foo)
>> ls()
> [1] "bar1" "bar2" "bar3" "bar4"
>
> I've tried the following two approaches:
>
> 1) I created the file 'datalist' under pre-build directory 'foobar/data/'
> with the following contents:
> foo: bar1 bar2 bar3 bar4
>
> After package build and install, "data(foo)" reports that data set 'foo' not
> found (bar1, bar2, etc are all available individually, and are listed under
> data() as "bar1 (foo)".


If you want just one object "foo", then prpare a list

foo <- list(bar1,...)

that contains the 4 objects bar1, ... .
You can load that objects and access the list components afterwards.

I think you misunderstood the data concept: You can save objects and 
load them if the package is installed. That's it.

Best,
Uwe Ligges



> 2) I created an image via save.image resulting in foo.rda (containing bar1,
> bar2, etc).
>
> data(foo) now loads bar1 - bar4, but 'foo' doesn't appear in the list of
> available datasets displayed when trying to tab complete within data().
>
>
> So my question is, what's the correct approach for what I'm trying to do
> here?  Any advice welcome and appreciated.
>
> Thanks,
> Andrew
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.tu-dortmund.de  Mon Mar 28 17:51:53 2011
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 28 Mar 2011 17:51:53 +0200
Subject: [Rd] datalist and data objects in R Package building
In-Reply-To: <AANLkTi=9rQ5yU9pnW0vaRS-fRCMmmtCXhhPV8AUfHYzA@mail.gmail.com>
References: <AANLkTimqc_jF0RL2jEAWHYTNJVXStJzyv5gNbUszRGpH@mail.gmail.com>	<4D90ABBF.8030302@statistik.tu-dortmund.de>
	<AANLkTi=9rQ5yU9pnW0vaRS-fRCMmmtCXhhPV8AUfHYzA@mail.gmail.com>
Message-ID: <4D90AE99.5040401@statistik.tu-dortmund.de>



On 28.03.2011 17:49, andrew stewart wrote:
> Thank you for your response.
>
> Yes, using a call to data() after 1) building and 2) installing my own
> package is exactly what I'm trying to accomplish.  I am building a package.
>   I would like to load the data objects that are part of the custom package
> that I have created and installed on my machine.  Apologies if I wasn't
> clear about that part.

Then just apply data() on all data names in your package or bundle the 
data in lists. If you want to load all data object all the time you load 
your package, I'd recommend to enable lazy loading of the data, so you 
do not need to explicitly load by data are loaded on demand.

Best,
Uwe Ligges


>
>
> 2011/3/28 Uwe Ligges<ligges at statistik.tu-dortmund.de>
>
>>
>>
>> On 24.03.2011 16:51, andrew stewart wrote:
>>
>>> Hello all,
>>>
>>> I have,say 4 R objects...  bar1, bar2, bar3, bar4.. that I'd like to
>>> include
>>> in an R package "foobar".
>>>
>>> The desired functionality would be:
>>>
>>>   library(foobar)
>>>> data(foo)
>>>> ls()
>>>>
>>> [1] "bar1" "bar2" "bar3" "bar4"
>>>
>>> I've tried the following two approaches:
>>>
>>> 1) I created the file 'datalist' under pre-build directory 'foobar/data/'
>>> with the following contents:
>>> foo: bar1 bar2 bar3 bar4
>>>
>>> After package build and install, "data(foo)" reports that data set 'foo'
>>> not
>>> found (bar1, bar2, etc are all available individually, and are listed
>>> under
>>> data() as "bar1 (foo)".
>>>
>>
>>
>> If you want just one object "foo", then prpare a list
>>
>> foo<- list(bar1,...)
>>
>> that contains the 4 objects bar1, ... .
>> You can load that objects and access the list components afterwards.
>>
>> I think you misunderstood the data concept: You can save objects and load
>> them if the package is installed. That's it.
>>
>> Best,
>> Uwe Ligges
>>
>>
>>
>>   2) I created an image via save.image resulting in foo.rda (containing
>>> bar1,
>>> bar2, etc).
>>>
>>> data(foo) now loads bar1 - bar4, but 'foo' doesn't appear in the list of
>>> available datasets displayed when trying to tab complete within data().
>>>
>>>
>>> So my question is, what's the correct approach for what I'm trying to do
>>> here?  Any advice welcome and appreciated.
>>>
>>> Thanks,
>>> Andrew
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>


From andrew.c.stewart at gmail.com  Mon Mar 28 17:49:49 2011
From: andrew.c.stewart at gmail.com (andrew stewart)
Date: Mon, 28 Mar 2011 11:49:49 -0400
Subject: [Rd] datalist and data objects in R Package building
In-Reply-To: <4D90ABBF.8030302@statistik.tu-dortmund.de>
References: <AANLkTimqc_jF0RL2jEAWHYTNJVXStJzyv5gNbUszRGpH@mail.gmail.com>
	<4D90ABBF.8030302@statistik.tu-dortmund.de>
Message-ID: <AANLkTi=9rQ5yU9pnW0vaRS-fRCMmmtCXhhPV8AUfHYzA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110328/f4fdf403/attachment.pl>

From pdalgd at gmail.com  Mon Mar 28 18:18:21 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 28 Mar 2011 18:18:21 +0200
Subject: [Rd] Testing window for R 2.13.0
In-Reply-To: <4D90A628.4080303@Vanderbilt.edu>
References: <alpine.LFD.2.02.1103182057380.4071@gannet.stats.ox.ac.uk>
	<4D90A628.4080303@Vanderbilt.edu>
Message-ID: <417A58E0-F959-414A-AAE9-0EAC26E6E154@gmail.com>


On Mar 28, 2011, at 17:15 , Matt Shotwell wrote:

> - typo R-admin manual, section 2.8, fourth sentence beginning "This will find build...", should read "This will build..."?
> 
> - typo in src/library/compiler/man/compile.Rd, line 35: "\item{ascii}{logical; should the compiled file be saved with in ascii" should read "...saved in ascii..."?

Fixed (twice, even. Luke got there before me.)

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From S.Ellison at lgc.co.uk  Mon Mar 28 18:44:57 2011
From: S.Ellison at lgc.co.uk (S Ellison)
Date: Mon, 28 Mar 2011 17:44:57 +0100
Subject: [Rd] Windows build not running on r-forge
Message-ID: <sd90c92f.088@tedmail.lgc.co.uk>

Please forgive any mis-post, and do feel free to point me to a more
appropriate list if this isn't properly R-dev.

I have a package on R-forge that shows correct linux and other *nix
builds, but no windows build. The log for the patched version shows the
error below, which appears to be due to a lack of /src files, a problem
that does not halt the *nix builds.

The package contains no compiled code (src is intentionally empty).


Log as follows:
* installing to library 'R:/lib/R/CRAN/2.12'
* installing *source* package 'metRology' ...
** libs

*** arch - i386
Error in file.copy(Sys.glob("src/*"), ss, recursive = TRUE) : 
  no files to copy from
* removing 'R:/lib/R/CRAN/2.12/metRology'
Run time: 1.27 seconds.

Advice would be welcome on what I can do about it...?

Steve Ellison

*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From S.Ellison at lgc.co.uk  Mon Mar 28 19:07:35 2011
From: S.Ellison at lgc.co.uk (S Ellison)
Date: Mon, 28 Mar 2011 18:07:35 +0100
Subject: [Rd] Windows build not running on r-forge
Message-ID: <sd90ce75.023@tedmail.lgc.co.uk>

Thanks for the advice; blindingly simple. I was foxed by the fact that
the R-forge linux 'builds' ran successfully with warning but not error.

Regret that I couldn't provide R version detail, but the problem was
the build at the r-forge end and not my own installed version of R; I
could only tell you what the R-forge log told me. 


Steve Ellison


>>> Prof Brian Ripley <ripley at stats.ox.ac.uk> 28/03/2011 05:32 >>>
On Mon, 28 Mar 2011, S Ellison wrote:

> Please forgive any mis-post, and do feel free to point me to a more
> appropriate list if this isn't properly R-dev.
>
> I have a package on R-forge that shows correct linux and other *nix
> builds, but no windows build. The log for the patched version shows
the
> error below, which appears to be due to a lack of /src files, a
problem
> that does not halt the *nix builds.
>
> The package contains no compiled code (src is intentionally empty).
>
>
> Log as follows:
> * installing to library 'R:/lib/R/CRAN/2.12'
> * installing *source* package 'metRology' ...
> ** libs
>
> *** arch - i386
> Error in file.copy(Sys.glob("src/*"), ss, recursive = TRUE) :
>  no files to copy from
> * removing 'R:/lib/R/CRAN/2.12/metRology'
> Run time: 1.27 seconds.
>
> Advice would be welcome on what I can do about it...?

Don't have an empty 'src' directory: that is not a valid source 
package.

And please do tell us the version of R as per the posting guide.  I am

guessing 2.12.2 here.

>
> Steve Ellison
>
>
> *******************************************************************
> This email and any attachments are confidential. Any\ ...{{dropped:24}}


From arthur.charpentier at gmail.com  Mon Mar 28 20:24:31 2011
From: arthur.charpentier at gmail.com (Arthur Charpentier)
Date: Mon, 28 Mar 2011 14:24:31 -0400
Subject: [Rd] use scan("http://www.example.com/file.htm") with an
	hidden-fake IP adress
Message-ID: <AANLkTincyGO=tO9_0MA13++z2xpvAnHWPAU=dKH6B=9t@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110328/0c87a0fb/attachment.pl>

From simon.urbanek at r-project.org  Mon Mar 28 21:13:31 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 28 Mar 2011 15:13:31 -0400
Subject: [Rd] use scan("http://www.example.com/file.htm") with an
	hidden-fake IP adress
In-Reply-To: <AANLkTincyGO=tO9_0MA13++z2xpvAnHWPAU=dKH6B=9t@mail.gmail.com>
References: <AANLkTincyGO=tO9_0MA13++z2xpvAnHWPAU=dKH6B=9t@mail.gmail.com>
Message-ID: <B6EC6D95-0503-4276-B295-92A330F21248@r-project.org>


On Mar 28, 2011, at 2:24 PM, Arthur Charpentier wrote:

> Dear users,
> I am currently using scan(,what="character") to read - automacally - some
> html pages,
> I was wondering if there was an option to "hide" my IP-adress, or to use a
> "fake" one ?
> I would like to chek if the website is using my IP-adress to change the
> content of the page (it is the price of airline tickets actually)
> I want to see if it is possible to do a request with some fake IP, to
> compare the prices,
> thanks for your help
> 

You can't really change the IP address since that is where the server sends the result. That's why your request packet has your IP so the response can be delivered back to you. Obviously, you won't get anything if the IP doesn't match. The only way to make requests to a server from a different IP is to use another machine that has a different IP (e.g., a proxy server).

Cheers,
Simon


From ripley at stats.ox.ac.uk  Tue Mar 29 10:24:47 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 29 Mar 2011 09:24:47 +0100 (BST)
Subject: [Rd] two minor bugs in rowsum()
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D70004086C27@NA-PA-VBE03.na.tibco.com>
References: <77EB52C6DD32BA4D87471DCD70C8D70004086C27@NA-PA-VBE03.na.tibco.com>
Message-ID: <alpine.LFD.2.02.1103290921430.17109@gannet.stats.ox.ac.uk>

On Fri, 25 Mar 2011, William Dunlap wrote:

> (a) In R 2.12.2 rowsum can overflow if given an integer input:
>  > rowsum(c(2e9L, 2e9L), c("a", "a"))
>          [,1]
>  a -294967296
>  > 2^32 + .Last.value
>     [,1]
>  a 4e+09
> Should it be changed to coerce its x argument to numeric
> (double precision) so it always returns a numeric output?

No, I don't think so.  But it should return NA on overflow (as sum() 
does), and I've altered pre-2.13.0 to do so.

> (b) When rowsum is given an x containing both NaN and NA it
> appears to use the last of the NaN/NA entries to determine
> if the output is NaN or NA while the `+` function uses the
> first:
>  > z <- cbind( c(NA,NA), c(NA,NaN), c(NaN,NA), c(NaN,NaN))
>  > rowsum(z, c("a","a"))
>    [,1] [,2] [,3] [,4]
>  a   NA  NaN   NA  NaN
>  > z[1,,drop=FALSE] + z[2,,drop=FALSE]
>       [,1] [,2] [,3] [,4]
>  [1,]   NA   NA  NaN  NaN

Which is not a bug: R does not claim to be consistent about this 
(except for a few documented functions), and there are lots of 
instances of this.

> (The name rowsum is a metabug, since it may be confused
> with the entirely different rowSums, but it has been around
> for a long time.)

A lot longer than rowSums ...

> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From htl10 at users.sourceforge.net  Tue Mar 29 12:34:52 2011
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Tue, 29 Mar 2011 11:34:52 +0100
Subject: [Rd] core Matrix package segfaulted on R CMD check --use-gct
In-Reply-To: <19856.40809.236979.731769@stat.math.ethz.ch>
References: <255683.81856.qm@web29515.mail.ird.yahoo.com>	<AANLkTimDJbJ-u3wXOyvPB0EePf98AZ-R5duKVr+Guh-v@mail.gmail.com>
	<19856.40809.236979.731769@stat.math.ethz.ch>
Message-ID: <4D91B5CC.1040500@users.sourceforge.net>

Martin Maechler wrote:
>>>>>> Douglas Bates <bates at stat.wisc.edu>
>>>>>>     on Mon, 28 Mar 2011 09:24:39 -0500 writes:
> 
>     > Can you provide the output from sessionInfo()
> 
>     > so we can know the platform?  Also, did you configure R
>     > with --enable-strict-barrier or set the C compilation flag
>     > -DTESTING_WRITE_BARRIER?  I think that run-time error
>     > message can only be thrown under those circumstances (not
>     > that it isn't an error, it's just not checked for in other
>     > circumstances).
> 
> interesting.
> 
> In the mean time, I *did* run --- for several hours! ---
> your code example below,
> and it did *not* segfault for me (64-bit, Linux Fedora 13).
> 
> Martin

64-bit fedora 14. For building R svn (and checking soon-to-be-released R 
packages, rather than daily R-related work), I also have these, and indeed have 
"--enable-strict-barrier":

export DEFS='-DUSE_TYPE_CHECKING_STRICT -DR_MEMORY_PROFILING' \
./configure --enable-memory-profiling --enable-strict-barrier 
--enable-byte-compiled-packages --with-valgrind-instrumentation=2

 > sessionInfo()
R version 2.14.0 Under development (unstable) (--)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
  [1] LC_CTYPE=en_GB.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_GB.UTF-8        LC_COLLATE=en_GB.UTF-8
  [5] LC_MONETARY=C              LC_MESSAGES=en_GB.UTF-8
  [7] LC_PAPER=en_GB.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base
 >

> 
>>>>>> Douglas Bates <bates at stat.wisc.edu>
>>>>>>     on Mon, 28 Mar 2011 09:24:39 -0500 writes:
> 
>     > Can you provide the output from
>     > sessionInfo()
> 
>     > so we can know the platform?  Also, did you configure R with
>     > --enable-strict-barrier or set the C compilation flag
>     > -DTESTING_WRITE_BARRIER?  I think that run-time error message can only
>     > be thrown under those circumstances (not that it isn't an error, it's
>     > just not checked for in other circumstances).
> 
>     > On Sat, Mar 26, 2011 at 5:21 PM, Hin-Tak Leung <hintak_leung at yahoo.co.uk> wrote:
>     >> Current core/Recommended Matrix package (0.999375-48) has been segfaulting against R 2.13-alpha/2.14-trunk for the last week or so (since R-2.13 was branched, when I started trying) when "run with R CMD check --use-gct":
>     >> 
>     >> --------------
>     >>> pkgname <- "Matrix"
>     >>> source(file.path(R.home("share"), "R", "examples-header.R"))
>     >>> gctorture(TRUE)
>     >>> options(warn = 1)
>     >>> library('Matrix')
>     >> Loading required package: lattice
>     >> Error : .onLoad failed in loadNamespace() for 'Matrix', details:
>     >>  call: fun(...)
>     >>  error: unprotected object (0x2768b18) encountered (was REALSXP)
>     >> Error: package/namespace load failed for 'Matrix'
>     >> Execution halted
>     >> ---------------
>     >> 
>     >> I traced to this because "R CMD check --use-gct snpStats" (both 1.1.13 and 1.1.12) segfaults with the same message, and before that, the snpMatrix 1.15.8.4 which includes some of David's newly written ld() ( which depends on Matrix.)
>     >> 
>     >> If the Matrix package segfaults, David's new ld() isn't useable.
>     >> 
>     >> 
>


From jon.clayden at gmail.com  Tue Mar 29 14:46:25 2011
From: jon.clayden at gmail.com (Jon Clayden)
Date: Tue, 29 Mar 2011 13:46:25 +0100
Subject: [Rd] Reading 64-bit integers
Message-ID: <AANLkTinndjFuoV17Th4PRUdpbrY-7RjTbyXwY6T6n+cd@mail.gmail.com>

Dear all,

I see from some previous threads that support for 64-bit integers in R
may be an aim for future versions, but in the meantime I'm wondering
whether it is possible to read in integers of greater than 32 bits at
all. Judging from ?readBin, it should be possible to read 8-byte
integers to some degree, but it is clearly limited in practice by R's
internally 32-bit integer type:

> x <- as.raw(c(0,0,0,0,1,0,0,0))
> (readBin(x,"integer",n=1,size=8,signed=F,endian="big"))
[1] 16777216
> x <- as.raw(c(0,0,0,1,0,0,0,0))
> (readBin(x,"integer",n=1,size=8,signed=F,endian="big"))
[1] 0

For values that fit into 32 bits it works fine, but for larger values
it fails. (I'm a bit surprised by the zero - should the value not be
NA if it is out of range?) The value can be represented as a double,
though:

> 4294967296
[1] 4294967296

I wouldn't expect readBin() to return a double if an integer was
requested, but is there any way to get the correct value out of it? I
suppose one could read the bytes into a raw vector and then
reconstruct the number manually from that, but is there a more elegant
or built-in solution that I'm not aware of?

This is R 2.12.1 on Mac OS X.6.7 - .Machine$sizeof.long is 8.

Many thanks,
Jon


From therneau at mayo.edu  Tue Mar 29 14:56:35 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Tue, 29 Mar 2011 07:56:35 -0500
Subject: [Rd] rowsum
Message-ID: <201103291256.p2TCuZOi004855@nemo.mayo.edu>

    > with the entirely different rowSums, but it has been around
    > for a long time.)
    A lot longer than rowSums ...
    > Bill Dunlap
    > Spotfire, TIBCO Software
    ---
      This made me smile.  The rowsums function was originally an internal
    part of the survival package, used for fast computation of certain sums
    when there is a cluster() statement.  It was Statistical Sciences
    (S-Plus) who moved it to global status.  That is, they used it in enough
    other places that they decided to speed it up, took over the
    maintainance and ownership of the function (with my blessing), and
    ceased to label it as part of "survival" in the manual.  
      This "metabug" can't be laid at R's feet. 
    Terry Therneau


From simon.urbanek at r-project.org  Tue Mar 29 16:06:44 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 29 Mar 2011 10:06:44 -0400
Subject: [Rd] Reading 64-bit integers
In-Reply-To: <AANLkTinndjFuoV17Th4PRUdpbrY-7RjTbyXwY6T6n+cd@mail.gmail.com>
References: <AANLkTinndjFuoV17Th4PRUdpbrY-7RjTbyXwY6T6n+cd@mail.gmail.com>
Message-ID: <10962CE3-2F14-4BCE-8E78-AE18814C3F81@r-project.org>


On Mar 29, 2011, at 8:46 AM, Jon Clayden wrote:

> Dear all,
> 
> I see from some previous threads that support for 64-bit integers in R
> may be an aim for future versions, but in the meantime I'm wondering
> whether it is possible to read in integers of greater than 32 bits at
> all. Judging from ?readBin, it should be possible to read 8-byte
> integers to some degree, but it is clearly limited in practice by R's
> internally 32-bit integer type:
> 
>> x <- as.raw(c(0,0,0,0,1,0,0,0))
>> (readBin(x,"integer",n=1,size=8,signed=F,endian="big"))
> [1] 16777216
>> x <- as.raw(c(0,0,0,1,0,0,0,0))
>> (readBin(x,"integer",n=1,size=8,signed=F,endian="big"))
> [1] 0
> 
> For values that fit into 32 bits it works fine, but for larger values
> it fails. (I'm a bit surprised by the zero - should the value not be
> NA if it is out of range?

No, it's not out of range - int is only 4 bytes so only 4 first bytes (respecting endianness order, hence LSB) are used.


> ) The value can be represented as a double,
> though:
> 
>> 4294967296
> [1] 4294967296
> 
> I wouldn't expect readBin() to return a double if an integer was
> requested, but is there any way to get the correct value out of it?

Trivially (for your unsigned big-endian case):

y <- readBin(x, "integer", n=length(x)/4L, endian="big")
y <- ifelse(y < 0, 2^32 + y, y)
i <- seq(1,length(y),2)
y <- y[i] * 2^32 + y[i + 1L]

Cheers,
Simon


> I
> suppose one could read the bytes into a raw vector and then
> reconstruct the number manually from that, but is there a more elegant
> or built-in solution that I'm not aware of?
> 
> This is R 2.12.1 on Mac OS X.6.7 - .Machine$sizeof.long is 8.
> 
> Many thanks,
> Jon
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From hpages at fhcrc.org  Tue Mar 29 19:31:10 2011
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 29 Mar 2011 10:31:10 -0700
Subject: [Rd] Typo in tools:::format.check_Rd_metadata()
Message-ID: <4D92175E.40703@fhcrc.org>

Hi,

With R version 2.13.0 alpha (2011-03-24 r55004), 'R CMD check' will
produce the following output on some packages:

   * checking Rd metadata ... WARNING
   Error in is.function(FUN) : 'FUN' is missing
   Calls: print ... format.check_Rd_metadata -> unlist -> lapply -> 
match.fun
   Execution halted

This is happening on packages that contain duplicated \name or \alias
tags in their Rd files. 'R CMD check' is able to detect this situation
but is not able to display the warning message correctly because of
a typo in the tools:::format.check_Rd_metadata() function:

   format.check_Rd_metadata <-
   function(x, ...)
   {
     c(character(),
       if(length(bad <- x$files_with_duplicated_name)) {
           unlist(lapply(names(bad)),
                  function(nm) {
                      c(gettextf("Rd files with duplicated name '%s':",
                                 nm),
                        .pretty_format(bad[[nm]]))
                  })
       },
       if(length(bad <- x$files_with_duplicated_aliases)) {
           unlist(lapply(names(bad)),
                  function(nm) {
                      c(gettextf("Rd files with duplicated alias '%s':",
                                 nm),
                        .pretty_format(bad[[nm]]))
                  })
       })
   }

Note the closing parentesis for the lapply() calls? Looks like it
was intended to be something like:

           unlist(lapply(names(bad),
                         function(nm) {
                             c(gettextf("Rd files with duplicated name 
'%s':",
                                        nm),
                               .pretty_format(bad[[nm]]))
                         }))

Cheers,
H.


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From jon.clayden at gmail.com  Tue Mar 29 19:33:49 2011
From: jon.clayden at gmail.com (Jon Clayden)
Date: Tue, 29 Mar 2011 18:33:49 +0100
Subject: [Rd] Reading 64-bit integers
In-Reply-To: <10962CE3-2F14-4BCE-8E78-AE18814C3F81@r-project.org>
References: <AANLkTinndjFuoV17Th4PRUdpbrY-7RjTbyXwY6T6n+cd@mail.gmail.com>
	<10962CE3-2F14-4BCE-8E78-AE18814C3F81@r-project.org>
Message-ID: <AANLkTimSWMqXM90Zg7WKYPbddk9zfQZhXXQif6eeLaGX@mail.gmail.com>

Dear Simon,

Thank you for the response.

On 29 March 2011 15:06, Simon Urbanek <simon.urbanek at r-project.org> wrote:
>
> On Mar 29, 2011, at 8:46 AM, Jon Clayden wrote:
>
>> Dear all,
>>
>> I see from some previous threads that support for 64-bit integers in R
>> may be an aim for future versions, but in the meantime I'm wondering
>> whether it is possible to read in integers of greater than 32 bits at
>> all. Judging from ?readBin, it should be possible to read 8-byte
>> integers to some degree, but it is clearly limited in practice by R's
>> internally 32-bit integer type:
>>
>>> x <- as.raw(c(0,0,0,0,1,0,0,0))
>>> (readBin(x,"integer",n=1,size=8,signed=F,endian="big"))
>> [1] 16777216
>>> x <- as.raw(c(0,0,0,1,0,0,0,0))
>>> (readBin(x,"integer",n=1,size=8,signed=F,endian="big"))
>> [1] 0
>>
>> For values that fit into 32 bits it works fine, but for larger values
>> it fails. (I'm a bit surprised by the zero - should the value not be
>> NA if it is out of range?
>
> No, it's not out of range - int is only 4 bytes so only 4 first bytes (respecting endianness order, hence LSB) are used.

The fact remains that I ask for the value of an 8-byte integer and
don't get it. Pretending that it's really only four bytes because of
the limits of R's integer type isn't all that helpful. Perhaps a
warning should be put out if the cast will affect the value of the
result? It looks like the relevant lines in src/main/connections.c are
3689-3697 in the current alpha:

#if SIZEOF_LONG == 8
		    case sizeof(long):
			INTEGER(ans)[i] = (int)*((long *)buf);
			break;
#elif SIZEOF_LONG_LONG == 8
		    case sizeof(_lli_t):
			INTEGER(ans)[i] = (int)*((_lli_t *)buf);
			break;
#endif

>> ) The value can be represented as a double,
>> though:
>>
>>> 4294967296
>> [1] 4294967296
>>
>> I wouldn't expect readBin() to return a double if an integer was
>> requested, but is there any way to get the correct value out of it?
>
> Trivially (for your unsigned big-endian case):
>
> y <- readBin(x, "integer", n=length(x)/4L, endian="big")
> y <- ifelse(y < 0, 2^32 + y, y)
> i <- seq(1,length(y),2)
> y <- y[i] * 2^32 + y[i + 1L]

Thanks for the code, but I'm not sure I would call that trivial,
especially if one needs to cater for little endian and signed cases as
well! This is what I meant by reconstructing the number manually...

All the best,
Jon


From murdoch.duncan at gmail.com  Tue Mar 29 19:53:01 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 29 Mar 2011 13:53:01 -0400
Subject: [Rd] Typo in tools:::format.check_Rd_metadata()
In-Reply-To: <4D92175E.40703@fhcrc.org>
References: <4D92175E.40703@fhcrc.org>
Message-ID: <4D921C7D.4080503@gmail.com>

On 29/03/2011 1:31 PM, Herv? Pag?s wrote:
> Hi,
>
> With R version 2.13.0 alpha (2011-03-24 r55004), 'R CMD check' will
> produce the following output on some packages:
>
>     * checking Rd metadata ... WARNING
>     Error in is.function(FUN) : 'FUN' is missing
>     Calls: print ... format.check_Rd_metadata ->  unlist ->  lapply ->
> match.fun
>     Execution halted
>
> This is happening on packages that contain duplicated \name or \alias
> tags in their Rd files. 'R CMD check' is able to detect this situation
> but is not able to display the warning message correctly because of
> a typo in the tools:::format.check_Rd_metadata() function:
>
>     format.check_Rd_metadata<-
>     function(x, ...)
>     {
>       c(character(),
>         if(length(bad<- x$files_with_duplicated_name)) {
>             unlist(lapply(names(bad)),
>                    function(nm) {
>                        c(gettextf("Rd files with duplicated name '%s':",
>                                   nm),
>                          .pretty_format(bad[[nm]]))
>                    })
>         },
>         if(length(bad<- x$files_with_duplicated_aliases)) {
>             unlist(lapply(names(bad)),
>                    function(nm) {
>                        c(gettextf("Rd files with duplicated alias '%s':",
>                                   nm),
>                          .pretty_format(bad[[nm]]))
>                    })
>         })
>     }
>
> Note the closing parentesis for the lapply() calls? Looks like it
> was intended to be something like:
>
>             unlist(lapply(names(bad),
>                           function(nm) {
>                               c(gettextf("Rd files with duplicated name
> '%s':",
>                                          nm),
>                                 .pretty_format(bad[[nm]]))
>                           }))
>
> Cheers,
> H.
>
>

Thanks, will fix.

Duncan Murdoch


From hpages at fhcrc.org  Tue Mar 29 20:24:27 2011
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 29 Mar 2011 11:24:27 -0700
Subject: [Rd] two minor bugs in rowsum()
In-Reply-To: <alpine.LFD.2.02.1103290921430.17109@gannet.stats.ox.ac.uk>
References: <77EB52C6DD32BA4D87471DCD70C8D70004086C27@NA-PA-VBE03.na.tibco.com>
	<alpine.LFD.2.02.1103290921430.17109@gannet.stats.ox.ac.uk>
Message-ID: <4D9223DB.5040304@fhcrc.org>

Hi,

On 03/29/2011 01:24 AM, Prof Brian Ripley wrote:
> On Fri, 25 Mar 2011, William Dunlap wrote:
[...]
>
>> (The name rowsum is a metabug, since it may be confused
>> with the entirely different rowSums, but it has been around
>> for a long time.)
>
> A lot longer than rowSums ...

Another problem with the current naming is the inconsistent use of
the row/col prefixes, IMO:

 > x <- matrix(runif(100), ncol=5)
 > rowsum(x, rep(1, 20))
       [,1]     [,2]    [,3]     [,4]     [,5]
1 11.13374 10.50038 10.0258 11.04087 8.150401
 > colSums(x)
[1] 11.133738 10.500381 10.025805 11.040867  8.150401

and the fact that the See Also section points to rowSums and not
colSums, which adds to the confusion...

Cheers,
H.

>
>> Bill Dunlap
>> Spotfire, TIBCO Software
>> wdunlap tibco.com
>


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From bates at stat.wisc.edu  Tue Mar 29 21:17:54 2011
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 29 Mar 2011 14:17:54 -0500
Subject: [Rd] core Matrix package segfaulted on R CMD check --use-gct
In-Reply-To: <4D91B5CC.1040500@users.sourceforge.net>
References: <255683.81856.qm@web29515.mail.ird.yahoo.com>
	<AANLkTimDJbJ-u3wXOyvPB0EePf98AZ-R5duKVr+Guh-v@mail.gmail.com>
	<19856.40809.236979.731769@stat.math.ethz.ch>
	<4D91B5CC.1040500@users.sourceforge.net>
Message-ID: <AANLkTimuxb199-32D+043u9fNp7VsDjf5QD2qX3_Zjof@mail.gmail.com>

On Tue, Mar 29, 2011 at 5:34 AM, Hin-Tak Leung
<htl10 at users.sourceforge.net> wrote:
> Martin Maechler wrote:
>>>>>>>
>>>>>>> Douglas Bates <bates at stat.wisc.edu>
>>>>>>> ? ?on Mon, 28 Mar 2011 09:24:39 -0500 writes:
>>
>> ? ?> Can you provide the output from sessionInfo()
>>
>> ? ?> so we can know the platform? ?Also, did you configure R
>> ? ?> with --enable-strict-barrier or set the C compilation flag
>> ? ?> -DTESTING_WRITE_BARRIER? ?I think that run-time error
>> ? ?> message can only be thrown under those circumstances (not
>> ? ?> that it isn't an error, it's just not checked for in other
>> ? ?> circumstances).
>>
>> interesting.
>>
>> In the mean time, I *did* run --- for several hours! ---
>> your code example below,
>> and it did *not* segfault for me (64-bit, Linux Fedora 13).
>>
>> Martin
>
> 64-bit fedora 14. For building R svn (and checking soon-to-be-released R
> packages, rather than daily R-related work), I also have these, and indeed
> have "--enable-strict-barrier":
>
> export DEFS='-DUSE_TYPE_CHECKING_STRICT -DR_MEMORY_PROFILING' \
> ./configure --enable-memory-profiling --enable-strict-barrier
> --enable-byte-compiled-packages --with-valgrind-instrumentation=2
>
>> sessionInfo()
> R version 2.14.0 Under development (unstable) (--)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
> ?[1] LC_CTYPE=en_GB.UTF-8 ? ? ? LC_NUMERIC=C
> ?[3] LC_TIME=en_GB.UTF-8 ? ? ? ?LC_COLLATE=en_GB.UTF-8
> ?[5] LC_MONETARY=C ? ? ? ? ? ? ?LC_MESSAGES=en_GB.UTF-8
> ?[7] LC_PAPER=en_GB.UTF-8 ? ? ? LC_NAME=C
> ?[9] LC_ADDRESS=C ? ? ? ? ? ? ? LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base

Thanks for the information.  I can replicate the problem on a Red Hat
EL 5 64-bit system and will start to debug now.

>>>>>>> Douglas Bates <bates at stat.wisc.edu>
>>>>>>> ? ?on Mon, 28 Mar 2011 09:24:39 -0500 writes:
>>
>> ? ?> Can you provide the output from
>> ? ?> sessionInfo()
>>
>> ? ?> so we can know the platform? ?Also, did you configure R with
>> ? ?> --enable-strict-barrier or set the C compilation flag
>> ? ?> -DTESTING_WRITE_BARRIER? ?I think that run-time error message can
>> only
>> ? ?> be thrown under those circumstances (not that it isn't an error, it's
>> ? ?> just not checked for in other circumstances).
>>
>> ? ?> On Sat, Mar 26, 2011 at 5:21 PM, Hin-Tak Leung
>> <hintak_leung at yahoo.co.uk> wrote:
>> ? ?>> Current core/Recommended Matrix package (0.999375-48) has been
>> segfaulting against R 2.13-alpha/2.14-trunk for the last week or so (since
>> R-2.13 was branched, when I started trying) when "run with R CMD check
>> --use-gct":
>> ? ?>> ? ? >> --------------
>> ? ?>>> pkgname <- "Matrix"
>> ? ?>>> source(file.path(R.home("share"), "R", "examples-header.R"))
>> ? ?>>> gctorture(TRUE)
>> ? ?>>> options(warn = 1)
>> ? ?>>> library('Matrix')
>> ? ?>> Loading required package: lattice
>> ? ?>> Error : .onLoad failed in loadNamespace() for 'Matrix', details:
>> ? ?>> ?call: fun(...)
>> ? ?>> ?error: unprotected object (0x2768b18) encountered (was REALSXP)
>> ? ?>> Error: package/namespace load failed for 'Matrix'
>> ? ?>> Execution halted
>> ? ?>> ---------------
>> ? ?>> ? ? >> I traced to this because "R CMD check --use-gct snpStats"
>> (both 1.1.13 and 1.1.12) segfaults with the same message, and before that,
>> the snpMatrix 1.15.8.4 which includes some of David's newly written ld() (
>> which depends on Matrix.)
>> ? ?>> ? ? >> If the Matrix package segfaults, David's new ld() isn't
>> useable.
>> ? ?>> ? ? >>
>


From wdunlap at tibco.com  Tue Mar 29 21:33:01 2011
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 29 Mar 2011 12:33:01 -0700
Subject: [Rd] Reading 64-bit integers
In-Reply-To: <AANLkTinndjFuoV17Th4PRUdpbrY-7RjTbyXwY6T6n+cd@mail.gmail.com>
References: <AANLkTinndjFuoV17Th4PRUdpbrY-7RjTbyXwY6T6n+cd@mail.gmail.com>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D70004124869@NA-PA-VBE03.na.tibco.com>


> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Jon Clayden
> Sent: Tuesday, March 29, 2011 5:46 AM
> To: r-devel at r-project.org
> Subject: [Rd] Reading 64-bit integers
> 
> Dear all,
> 
> I see from some previous threads that support for 64-bit integers in R
> may be an aim for future versions, but in the meantime I'm wondering
> whether it is possible to read in integers of greater than 32 bits at
> all. Judging from ?readBin, it should be possible to read 8-byte
> integers to some degree, but it is clearly limited in practice by R's
> internally 32-bit integer type:
> 
> > x <- as.raw(c(0,0,0,0,1,0,0,0))
> > (readBin(x,"integer",n=1,size=8,signed=F,endian="big"))
> [1] 16777216
> > x <- as.raw(c(0,0,0,1,0,0,0,0))
> > (readBin(x,"integer",n=1,size=8,signed=F,endian="big"))
> [1] 0
> 
> For values that fit into 32 bits it works fine, but for larger values
> it fails. (I'm a bit surprised by the zero - should the value not be
> NA if it is out of range?) The value can be represented as a double,
> though:
> 
> > 4294967296
> [1] 4294967296
> 
> I wouldn't expect readBin() to return a double if an integer was
> requested, but is there any way to get the correct value out of it?

In S+'s readBin() you can use the argument output="double" to
read 8-byte integers from a file and to put the closest equivalent
value into a double precision vector.  It is also useful when reading
unsigned 4-byte integers that may be above 2^31.  The help file says
   output
          Like what but used when the type of data in the file is
          different than the type of S-PLUS vector used to store the
          data. what refers to the data in the file and output refers to
          the output of readBin. output=double() is useful for reading
          unsigned 4 byte integers (so integers bigger than 2^31 are not
          read as negative numbers) or even for 8 byte integers on
32-bit
          versions of Splus. In the latter case you may lose some
          precision, but reading it as 4 byte integers will omit the 4
          high order bytes.
 
> I
> suppose one could read the bytes into a raw vector and then
> reconstruct the number manually from that, but is there a more elegant
> or built-in solution that I'm not aware of?
> 
> This is R 2.12.1 on Mac OS X.6.7 - .Machine$sizeof.long is 8.
> 
> Many thanks,
> Jon
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From Matt.Shotwell at Vanderbilt.Edu  Tue Mar 29 21:40:30 2011
From: Matt.Shotwell at Vanderbilt.Edu (Matt Shotwell)
Date: Tue, 29 Mar 2011 14:40:30 -0500
Subject: [Rd] Broken link in R-exts.html
Message-ID: <4D9235AE.6030503@Vanderbilt.edu>

The HTML link 'Customizing package compilation' in 'Writing R 
Extensions' is broken. See the offending link near here:
http://cran.r-project.org/doc/manuals/R-exts.html#Submitting-a-package-to-CRAN

In R-exts.texi, it looks like a five-argument @xref was intended. Oddly, 
the PDF link works anyway. This fixes the HTML link for me; doesn't 
break the PDF link:

Index: doc/manual/R-exts.texi
===================================================================
--- doc/manual/R-exts.texi      (revision 55161)
+++ doc/manual/R-exts.texi      (working copy)
@@ -2104,7 +2104,7 @@
  Collection.  If @R{} was not configured accordingly, one can achieve
  this @emph{via} personal @file{Makevars} files.
  @ifset UseExternalXrefs
- at xref{Customizing package compilation,
+ at xref{Customizing package compilation, ,
  Customizing package compilation, R-admin,
  R Installation and Administration},
  @end ifset

-- 
Matthew S Shotwell   Assistant Professor           School of Medicine
                      Department of Biostatistics   Vanderbilt University


From simon.urbanek at r-project.org  Tue Mar 29 23:40:52 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 29 Mar 2011 17:40:52 -0400
Subject: [Rd] Reading 64-bit integers
In-Reply-To: <AANLkTimSWMqXM90Zg7WKYPbddk9zfQZhXXQif6eeLaGX@mail.gmail.com>
References: <AANLkTinndjFuoV17Th4PRUdpbrY-7RjTbyXwY6T6n+cd@mail.gmail.com>
	<10962CE3-2F14-4BCE-8E78-AE18814C3F81@r-project.org>
	<AANLkTimSWMqXM90Zg7WKYPbddk9zfQZhXXQif6eeLaGX@mail.gmail.com>
Message-ID: <5544174B-A567-4126-B99C-D39542260503@r-project.org>

Jon,

On Mar 29, 2011, at 1:33 PM, Jon Clayden wrote:

> Dear Simon,
> 
> Thank you for the response.
> 
> On 29 March 2011 15:06, Simon Urbanek <simon.urbanek at r-project.org> wrote:
>> 
>> On Mar 29, 2011, at 8:46 AM, Jon Clayden wrote:
>> 
>>> Dear all,
>>> 
>>> I see from some previous threads that support for 64-bit integers in R
>>> may be an aim for future versions, but in the meantime I'm wondering
>>> whether it is possible to read in integers of greater than 32 bits at
>>> all. Judging from ?readBin, it should be possible to read 8-byte
>>> integers to some degree, but it is clearly limited in practice by R's
>>> internally 32-bit integer type:
>>> 
>>>> x <- as.raw(c(0,0,0,0,1,0,0,0))
>>>> (readBin(x,"integer",n=1,size=8,signed=F,endian="big"))
>>> [1] 16777216
>>>> x <- as.raw(c(0,0,0,1,0,0,0,0))
>>>> (readBin(x,"integer",n=1,size=8,signed=F,endian="big"))
>>> [1] 0
>>> 
>>> For values that fit into 32 bits it works fine, but for larger values
>>> it fails. (I'm a bit surprised by the zero - should the value not be
>>> NA if it is out of range?
>> 
>> No, it's not out of range - int is only 4 bytes so only 4 first bytes (respecting endianness order, hence LSB) are used.
> 
> The fact remains that I ask for the value of an 8-byte integer and
> don't get it.

I think you're misinterpreting the documentation:

     If ?size? is specified and not the natural size of the object,
     each element of the vector is coerced to an appropriate type
     before being written or as it is read.

The "integer" object type is defined as signed 32-bit in R, so if you ask for "8 bytes into object type integer", you get a coercion into that object type -- 32-bit signed integer -- as documented. I think the issue may come from the confusion of the object type "integer" with general "integer number" in mathematical sense that has no representation restrictions. (FWIW in C the "integer" type is "int" and it is 32-bit on all modern OSes regardless of platform - that's where the limitation comes from, it's not something R has made up).


> Pretending that it's really only four bytes because of
> the limits of R's integer type isn't all that helpful. Perhaps a
> warning should be put out if the cast will affect the value of the
> result? It looks like the relevant lines in src/main/connections.c are
> 3689-3697 in the current alpha:
> 
> #if SIZEOF_LONG == 8
> 		    case sizeof(long):
> 			INTEGER(ans)[i] = (int)*((long *)buf);
> 			break;
> #elif SIZEOF_LONG_LONG == 8
> 		    case sizeof(_lli_t):
> 			INTEGER(ans)[i] = (int)*((_lli_t *)buf);
> 			break;
> #endif
> 
>>> ) The value can be represented as a double,
>>> though:
>>> 
>>>> 4294967296
>>> [1] 4294967296
>>> 
>>> I wouldn't expect readBin() to return a double if an integer was
>>> requested, but is there any way to get the correct value out of it?
>> 
>> Trivially (for your unsigned big-endian case):
>> 
>> y <- readBin(x, "integer", n=length(x)/4L, endian="big")
>> y <- ifelse(y < 0, 2^32 + y, y)
>> i <- seq(1,length(y),2)
>> y <- y[i] * 2^32 + y[i + 1L]
> 
> Thanks for the code, but I'm not sure I would call that trivial,
> especially if one needs to cater for little endian and signed cases as
> well!

I was saying for your case and it's trivial as in read as integers, convert to double precision and add.


> This is what I meant by reconstructing the number manually...
> 

You didn't say so - you were talking about reconstructing it from a raw vector which seems a lot more painful since you can't compute with enough precision on raw vectors.

Cheers,
Simon


From jon.clayden at gmail.com  Wed Mar 30 01:01:17 2011
From: jon.clayden at gmail.com (Jon Clayden)
Date: Wed, 30 Mar 2011 00:01:17 +0100
Subject: [Rd] Reading 64-bit integers
In-Reply-To: <5544174B-A567-4126-B99C-D39542260503@r-project.org>
References: <AANLkTinndjFuoV17Th4PRUdpbrY-7RjTbyXwY6T6n+cd@mail.gmail.com>
	<10962CE3-2F14-4BCE-8E78-AE18814C3F81@r-project.org>
	<AANLkTimSWMqXM90Zg7WKYPbddk9zfQZhXXQif6eeLaGX@mail.gmail.com>
	<5544174B-A567-4126-B99C-D39542260503@r-project.org>
Message-ID: <AANLkTinfH__3foy9oex9+Eq-84pr_i9M6PfKay8R4i9T@mail.gmail.com>

Dear Simon,

On 29 March 2011 22:40, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> Jon,
>
> On Mar 29, 2011, at 1:33 PM, Jon Clayden wrote:
>
>> Dear Simon,
>>
>> Thank you for the response.
>>
>> On 29 March 2011 15:06, Simon Urbanek <simon.urbanek at r-project.org> wrote:
>>>
>>> On Mar 29, 2011, at 8:46 AM, Jon Clayden wrote:
>>>
>>>> Dear all,
>>>>
>>>> I see from some previous threads that support for 64-bit integers in R
>>>> may be an aim for future versions, but in the meantime I'm wondering
>>>> whether it is possible to read in integers of greater than 32 bits at
>>>> all. Judging from ?readBin, it should be possible to read 8-byte
>>>> integers to some degree, but it is clearly limited in practice by R's
>>>> internally 32-bit integer type:
>>>>
>>>>> x <- as.raw(c(0,0,0,0,1,0,0,0))
>>>>> (readBin(x,"integer",n=1,size=8,signed=F,endian="big"))
>>>> [1] 16777216
>>>>> x <- as.raw(c(0,0,0,1,0,0,0,0))
>>>>> (readBin(x,"integer",n=1,size=8,signed=F,endian="big"))
>>>> [1] 0
>>>>
>>>> For values that fit into 32 bits it works fine, but for larger values
>>>> it fails. (I'm a bit surprised by the zero - should the value not be
>>>> NA if it is out of range?
>>>
>>> No, it's not out of range - int is only 4 bytes so only 4 first bytes (respecting endianness order, hence LSB) are used.
>>
>> The fact remains that I ask for the value of an 8-byte integer and
>> don't get it.
>
> I think you're misinterpreting the documentation:
>
> ? ? If ?size? is specified and not the natural size of the object,
> ? ? each element of the vector is coerced to an appropriate type
> ? ? before being written or as it is read.
>
> The "integer" object type is defined as signed 32-bit in R, so if you ask for "8 bytes into object type integer", you get a coercion into that object type -- 32-bit signed integer -- as documented. I think the issue may come from the confusion of the object type "integer" with general "integer number" in mathematical sense that has no representation restrictions. (FWIW in C the "integer" type is "int" and it is 32-bit on all modern OSes regardless of platform - that's where the limitation comes from, it's not something R has made up).

OK, but it still seems like there is a case for raising a warning. As
it is there is no way to tell when reading an 8-byte integer from a
file whether its value is really 0, or if it merely has 0 in its
least-significant 4 bytes. If 99% of such stored numbers are below
2^31, one is going to need some extra logic to catch the other 1%
where you (silently) get the wrong value. In essence, unless you're
certain that you will never come across a number that actually uses
the upper 4 bytes, you will always have to read it as two 4-byte
numbers and check that the high-order one (which is endianness
dependent, of course) is zero. A C-level sanity check seems more
efficient and more helpful to me.

>> Pretending that it's really only four bytes because of
>> the limits of R's integer type isn't all that helpful. Perhaps a
>> warning should be put out if the cast will affect the value of the
>> result? It looks like the relevant lines in src/main/connections.c are
>> 3689-3697 in the current alpha:
>>
>> #if SIZEOF_LONG == 8
>> ? ? ? ? ? ? ? ? ? case sizeof(long):
>> ? ? ? ? ? ? ? ? ? ? ? INTEGER(ans)[i] = (int)*((long *)buf);
>> ? ? ? ? ? ? ? ? ? ? ? break;
>> #elif SIZEOF_LONG_LONG == 8
>> ? ? ? ? ? ? ? ? ? case sizeof(_lli_t):
>> ? ? ? ? ? ? ? ? ? ? ? INTEGER(ans)[i] = (int)*((_lli_t *)buf);
>> ? ? ? ? ? ? ? ? ? ? ? break;
>> #endif
>>
>>>> ) The value can be represented as a double,
>>>> though:
>>>>
>>>>> 4294967296
>>>> [1] 4294967296
>>>>
>>>> I wouldn't expect readBin() to return a double if an integer was
>>>> requested, but is there any way to get the correct value out of it?
>>>
>>> Trivially (for your unsigned big-endian case):
>>>
>>> y <- readBin(x, "integer", n=length(x)/4L, endian="big")
>>> y <- ifelse(y < 0, 2^32 + y, y)
>>> i <- seq(1,length(y),2)
>>> y <- y[i] * 2^32 + y[i + 1L]
>>
>> Thanks for the code, but I'm not sure I would call that trivial,
>> especially if one needs to cater for little endian and signed cases as
>> well!
>
> I was saying for your case and it's trivial as in read as integers, convert to double precision and add.
>
>
>> This is what I meant by reconstructing the number manually...
>>
>
> You didn't say so - you were talking about reconstructing it from a raw vector which seems a lot more painful since you can't compute with enough precision on raw vectors.

True - I should have been more specific. Sorry.

Jon


From murdoch.duncan at gmail.com  Wed Mar 30 02:47:41 2011
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 29 Mar 2011 20:47:41 -0400
Subject: [Rd] Reading 64-bit integers
In-Reply-To: <AANLkTinfH__3foy9oex9+Eq-84pr_i9M6PfKay8R4i9T@mail.gmail.com>
References: <AANLkTinndjFuoV17Th4PRUdpbrY-7RjTbyXwY6T6n+cd@mail.gmail.com>	<10962CE3-2F14-4BCE-8E78-AE18814C3F81@r-project.org>	<AANLkTimSWMqXM90Zg7WKYPbddk9zfQZhXXQif6eeLaGX@mail.gmail.com>	<5544174B-A567-4126-B99C-D39542260503@r-project.org>
	<AANLkTinfH__3foy9oex9+Eq-84pr_i9M6PfKay8R4i9T@mail.gmail.com>
Message-ID: <4D927DAD.7070203@gmail.com>

On 29/03/2011 7:01 PM, Jon Clayden wrote:
> Dear Simon,
>
> On 29 March 2011 22:40, Simon Urbanek<simon.urbanek at r-project.org>  wrote:
>> Jon,
>>
>> On Mar 29, 2011, at 1:33 PM, Jon Clayden wrote:
>>
>>> Dear Simon,
>>>
>>> Thank you for the response.
>>>
>>> On 29 March 2011 15:06, Simon Urbanek<simon.urbanek at r-project.org>  wrote:
>>>>
>>>> On Mar 29, 2011, at 8:46 AM, Jon Clayden wrote:
>>>>
>>>>> Dear all,
>>>>>
>>>>> I see from some previous threads that support for 64-bit integers in R
>>>>> may be an aim for future versions, but in the meantime I'm wondering
>>>>> whether it is possible to read in integers of greater than 32 bits at
>>>>> all. Judging from ?readBin, it should be possible to read 8-byte
>>>>> integers to some degree, but it is clearly limited in practice by R's
>>>>> internally 32-bit integer type:
>>>>>
>>>>>> x<- as.raw(c(0,0,0,0,1,0,0,0))
>>>>>> (readBin(x,"integer",n=1,size=8,signed=F,endian="big"))
>>>>> [1] 16777216
>>>>>> x<- as.raw(c(0,0,0,1,0,0,0,0))
>>>>>> (readBin(x,"integer",n=1,size=8,signed=F,endian="big"))
>>>>> [1] 0
>>>>>
>>>>> For values that fit into 32 bits it works fine, but for larger values
>>>>> it fails. (I'm a bit surprised by the zero - should the value not be
>>>>> NA if it is out of range?
>>>>
>>>> No, it's not out of range - int is only 4 bytes so only 4 first bytes (respecting endianness order, hence LSB) are used.
>>>
>>> The fact remains that I ask for the value of an 8-byte integer and
>>> don't get it.
>>
>> I think you're misinterpreting the documentation:
>>
>>      If ?size? is specified and not the natural size of the object,
>>      each element of the vector is coerced to an appropriate type
>>      before being written or as it is read.
>>
>> The "integer" object type is defined as signed 32-bit in R, so if you ask for "8 bytes into object type integer", you get a coercion into that object type -- 32-bit signed integer -- as documented. I think the issue may come from the confusion of the object type "integer" with general "integer number" in mathematical sense that has no representation restrictions. (FWIW in C the "integer" type is "int" and it is 32-bit on all modern OSes regardless of platform - that's where the limitation comes from, it's not something R has made up).
>
> OK, but it still seems like there is a case for raising a warning. As
> it is there is no way to tell when reading an 8-byte integer from a
> file whether its value is really 0, or if it merely has 0 in its
> least-significant 4 bytes. If 99% of such stored numbers are below
> 2^31, one is going to need some extra logic to catch the other 1%
> where you (silently) get the wrong value. In essence, unless you're
> certain that you will never come across a number that actually uses
> the upper 4 bytes, you will always have to read it as two 4-byte
> numbers and check that the high-order one (which is endianness
> dependent, of course) is zero. A C-level sanity check seems more
> efficient and more helpful to me.

Seems to me that the S-PLUS solution (output="double") would be a lot 
more useful.  I'd commit that if you write it; I don't think I'd commit 
the warning.

Duncan Murdoch

>
>>> Pretending that it's really only four bytes because of
>>> the limits of R's integer type isn't all that helpful. Perhaps a
>>> warning should be put out if the cast will affect the value of the
>>> result? It looks like the relevant lines in src/main/connections.c are
>>> 3689-3697 in the current alpha:
>>>
>>> #if SIZEOF_LONG == 8
>>>                    case sizeof(long):
>>>                        INTEGER(ans)[i] = (int)*((long *)buf);
>>>                        break;
>>> #elif SIZEOF_LONG_LONG == 8
>>>                    case sizeof(_lli_t):
>>>                        INTEGER(ans)[i] = (int)*((_lli_t *)buf);
>>>                        break;
>>> #endif
>>>
>>>>> ) The value can be represented as a double,
>>>>> though:
>>>>>
>>>>>> 4294967296
>>>>> [1] 4294967296
>>>>>
>>>>> I wouldn't expect readBin() to return a double if an integer was
>>>>> requested, but is there any way to get the correct value out of it?
>>>>
>>>> Trivially (for your unsigned big-endian case):
>>>>
>>>> y<- readBin(x, "integer", n=length(x)/4L, endian="big")
>>>> y<- ifelse(y<  0, 2^32 + y, y)
>>>> i<- seq(1,length(y),2)
>>>> y<- y[i] * 2^32 + y[i + 1L]
>>>
>>> Thanks for the code, but I'm not sure I would call that trivial,
>>> especially if one needs to cater for little endian and signed cases as
>>> well!
>>
>> I was saying for your case and it's trivial as in read as integers, convert to double precision and add.
>>
>>
>>> This is what I meant by reconstructing the number manually...
>>>
>>
>> You didn't say so - you were talking about reconstructing it from a raw vector which seems a lot more painful since you can't compute with enough precision on raw vectors.
>
> True - I should have been more specific. Sorry.
>
> Jon
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From dtenenba at fhcrc.org  Wed Mar 30 03:10:09 2011
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Tue, 29 Mar 2011 18:10:09 -0700
Subject: [Rd] problem with png() and large dimensions on some 32-bit Windows
	machines
Message-ID: <AANLkTi=bOELzTYxWVNmi+osTSXCAEJ1gsxTqaX1Zdc5s@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110329/36eb047f/attachment.pl>

From simon.urbanek at r-project.org  Wed Mar 30 03:49:28 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 29 Mar 2011 21:49:28 -0400
Subject: [Rd] Reading 64-bit integers
In-Reply-To: <4D927DAD.7070203@gmail.com>
References: <AANLkTinndjFuoV17Th4PRUdpbrY-7RjTbyXwY6T6n+cd@mail.gmail.com>	<10962CE3-2F14-4BCE-8E78-AE18814C3F81@r-project.org>	<AANLkTimSWMqXM90Zg7WKYPbddk9zfQZhXXQif6eeLaGX@mail.gmail.com>	<5544174B-A567-4126-B99C-D39542260503@r-project.org>
	<AANLkTinfH__3foy9oex9+Eq-84pr_i9M6PfKay8R4i9T@mail.gmail.com>
	<4D927DAD.7070203@gmail.com>
Message-ID: <A1631B10-DB4D-4914-8FCA-C1A97178F02F@r-project.org>


On Mar 29, 2011, at 8:47 PM, Duncan Murdoch wrote:

> On 29/03/2011 7:01 PM, Jon Clayden wrote:
>> Dear Simon,
>> 
>> On 29 March 2011 22:40, Simon Urbanek<simon.urbanek at r-project.org>  wrote:
>>> Jon,
>>> 
>>> On Mar 29, 2011, at 1:33 PM, Jon Clayden wrote:
>>> 
>>>> Dear Simon,
>>>> 
>>>> Thank you for the response.
>>>> 
>>>> On 29 March 2011 15:06, Simon Urbanek<simon.urbanek at r-project.org>  wrote:
>>>>> 
>>>>> On Mar 29, 2011, at 8:46 AM, Jon Clayden wrote:
>>>>> 
>>>>>> Dear all,
>>>>>> 
>>>>>> I see from some previous threads that support for 64-bit integers in R
>>>>>> may be an aim for future versions, but in the meantime I'm wondering
>>>>>> whether it is possible to read in integers of greater than 32 bits at
>>>>>> all. Judging from ?readBin, it should be possible to read 8-byte
>>>>>> integers to some degree, but it is clearly limited in practice by R's
>>>>>> internally 32-bit integer type:
>>>>>> 
>>>>>>> x<- as.raw(c(0,0,0,0,1,0,0,0))
>>>>>>> (readBin(x,"integer",n=1,size=8,signed=F,endian="big"))
>>>>>> [1] 16777216
>>>>>>> x<- as.raw(c(0,0,0,1,0,0,0,0))
>>>>>>> (readBin(x,"integer",n=1,size=8,signed=F,endian="big"))
>>>>>> [1] 0
>>>>>> 
>>>>>> For values that fit into 32 bits it works fine, but for larger values
>>>>>> it fails. (I'm a bit surprised by the zero - should the value not be
>>>>>> NA if it is out of range?
>>>>> 
>>>>> No, it's not out of range - int is only 4 bytes so only 4 first bytes (respecting endianness order, hence LSB) are used.
>>>> 
>>>> The fact remains that I ask for the value of an 8-byte integer and
>>>> don't get it.
>>> 
>>> I think you're misinterpreting the documentation:
>>> 
>>>     If ?size? is specified and not the natural size of the object,
>>>     each element of the vector is coerced to an appropriate type
>>>     before being written or as it is read.
>>> 
>>> The "integer" object type is defined as signed 32-bit in R, so if you ask for "8 bytes into object type integer", you get a coercion into that object type -- 32-bit signed integer -- as documented. I think the issue may come from the confusion of the object type "integer" with general "integer number" in mathematical sense that has no representation restrictions. (FWIW in C the "integer" type is "int" and it is 32-bit on all modern OSes regardless of platform - that's where the limitation comes from, it's not something R has made up).
>> 
>> OK, but it still seems like there is a case for raising a warning. As
>> it is there is no way to tell when reading an 8-byte integer from a
>> file whether its value is really 0, or if it merely has 0 in its
>> least-significant 4 bytes. If 99% of such stored numbers are below
>> 2^31, one is going to need some extra logic to catch the other 1%
>> where you (silently) get the wrong value. In essence, unless you're
>> certain that you will never come across a number that actually uses
>> the upper 4 bytes, you will always have to read it as two 4-byte
>> numbers and check that the high-order one (which is endianness
>> dependent, of course) is zero. A C-level sanity check seems more
>> efficient and more helpful to me.
> 
> Seems to me that the S-PLUS solution (output="double") would be a lot more useful.  I'd commit that if you write it; I don't think I'd commit the warning.
> 

I was going to write some thing similar (idea = good, patch welcome ;)). My only worry is that the "output" argument is a bit misleading in that one could expect to use any combination of "input"/"output" which may be a maintenance nightmare. If I understand it correctly it's only a special case for integer input. I don't have S+ so can't say how they deal with that.

Cheers,
Simon


> 
>> 
>>>> Pretending that it's really only four bytes because of
>>>> the limits of R's integer type isn't all that helpful. Perhaps a
>>>> warning should be put out if the cast will affect the value of the
>>>> result? It looks like the relevant lines in src/main/connections.c are
>>>> 3689-3697 in the current alpha:
>>>> 
>>>> #if SIZEOF_LONG == 8
>>>>                   case sizeof(long):
>>>>                       INTEGER(ans)[i] = (int)*((long *)buf);
>>>>                       break;
>>>> #elif SIZEOF_LONG_LONG == 8
>>>>                   case sizeof(_lli_t):
>>>>                       INTEGER(ans)[i] = (int)*((_lli_t *)buf);
>>>>                       break;
>>>> #endif
>>>> 
>>>>>> ) The value can be represented as a double,
>>>>>> though:
>>>>>> 
>>>>>>> 4294967296
>>>>>> [1] 4294967296
>>>>>> 
>>>>>> I wouldn't expect readBin() to return a double if an integer was
>>>>>> requested, but is there any way to get the correct value out of it?
>>>>> 
>>>>> Trivially (for your unsigned big-endian case):
>>>>> 
>>>>> y<- readBin(x, "integer", n=length(x)/4L, endian="big")
>>>>> y<- ifelse(y<  0, 2^32 + y, y)
>>>>> i<- seq(1,length(y),2)
>>>>> y<- y[i] * 2^32 + y[i + 1L]
>>>> 
>>>> Thanks for the code, but I'm not sure I would call that trivial,
>>>> especially if one needs to cater for little endian and signed cases as
>>>> well!
>>> 
>>> I was saying for your case and it's trivial as in read as integers, convert to double precision and add.
>>> 
>>> 
>>>> This is what I meant by reconstructing the number manually...
>>>> 
>>> 
>>> You didn't say so - you were talking about reconstructing it from a raw vector which seems a lot more painful since you can't compute with enough precision on raw vectors.
>> 
>> True - I should have been more specific. Sorry.
>> 
>> Jon
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From dtenenba at fhcrc.org  Wed Mar 30 03:58:54 2011
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Tue, 29 Mar 2011 18:58:54 -0700
Subject: [Rd] problem with png() and large dimensions on some 32-bit
	Windows machines
In-Reply-To: <AANLkTi=bOELzTYxWVNmi+osTSXCAEJ1gsxTqaX1Zdc5s@mail.gmail.com>
References: <AANLkTi=bOELzTYxWVNmi+osTSXCAEJ1gsxTqaX1Zdc5s@mail.gmail.com>
Message-ID: <AANLkTin7eJ-hRL7Q1nQPn0+L+jYwkm9uhQreYvjq7t_c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20110329/96ae4430/attachment.pl>

From simon.urbanek at r-project.org  Wed Mar 30 04:03:56 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 29 Mar 2011 22:03:56 -0400
Subject: [Rd] problem with png() and large dimensions on some 32-bit
	Windows machines
In-Reply-To: <AANLkTi=bOELzTYxWVNmi+osTSXCAEJ1gsxTqaX1Zdc5s@mail.gmail.com>
References: <AANLkTi=bOELzTYxWVNmi+osTSXCAEJ1gsxTqaX1Zdc5s@mail.gmail.com>
Message-ID: <BE56B741-42E6-4417-9B9E-A2F8374778C1@r-project.org>

Dan,

the Windows build of R has no back-end choices, so the error essentially comes from a system call which means that Windows simply cannot provide the resources. Have you tried let's say Cairo alternative on the same machine? [If you want to test it, please use install.packages("Cairo",,"http://rforge.net") ] That doesn't depend on the OS resources, only on RAM so it may be in theory more scalable.

Cheers,
Simon



On Mar 29, 2011, at 9:10 PM, Dan Tenenbaum wrote:

> Hello,
> 
> I encountered this:
> 
>> png(file=tempfile(), width=1165, height=12983)
> Error in png(file = tempfile(), width = 1165, height = 12983) :
>  unable to start png() device
> In addition: Warning messages:
> 1: In png(file = tempfile(), width = 1165, height = 12983) :
>  Unable to allocate bitmap
> 2: In png(file = tempfile(), width = 1165, height = 12983) :
>  opening device failed
>> 
> 
> On the following system:
>> sessionInfo()
> R version 2.13.0 alpha (2011-03-18 r54865)
> Platform: i386-pc-mingw32/i386 (32-bit)
> 
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> This is a Windows Server 2003 R2 Enterprise Edition Service Pack 2 system
> with 3GB of RAM.
> 
> On another system, the command works fine. Info from that system:
> 
>> sessionInfo()
> R version 2.13.0 alpha (2011-03-27 r55091)
> Platform: i386-pc-mingw32/i386 (32-bit)
> 
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> Windows Server 2008 R2 Enterprise with 4GB of RAM.
> 
> The command also worked fine on a system with only 2GB of RAM, but I don't
> have further information about that system at the moment. It suggests though
> that the amount of RAM is not the sole factor involved.
> 
> Sorry this may not be the most reproducible problem, but I hope this is
> useful nonetheless.
> Dan
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From nakama at ki.rim.or.jp  Wed Mar 30 06:28:05 2011
From: nakama at ki.rim.or.jp (Ei-ji Nakama)
Date: Wed, 30 Mar 2011 13:28:05 +0900
Subject: [Rd] SurviveGotoBLAS2 for Win64 (RC release)
In-Reply-To: <AANLkTinYxjmGQvf-G8X1jBa3W7oF5N36d833jB6P7txz@mail.gmail.com>
References: <AANLkTinYxjmGQvf-G8X1jBa3W7oF5N36d833jB6P7txz@mail.gmail.com>
Message-ID: <AANLkTimTBmFvG1H+b4PPg=qfAQ8GJFHyRfPOjjqx_=Wu@mail.gmail.com>

Hi,

I made the GotoBLAS2 for OSX version.
two binaries are divided by kind of powerPC.
neither binaries are different on Intel.
because there is not PPC, I can't confirm it.

http://prs.ism.ac.jp/~nakama/SurviveGotoBLAS2/binary/OSX/

2011/2/10 Ei-ji Nakama <nakama at ki.rim.or.jp>:
> Hi,
>
> I put below Rblas.dll(GotoBLAS2 for Win64).
> http://prs.ism.ac.jp/~nakama/SurviveGotoBLAS2/binary/windows/x64/
> please choose the core-name of your CPU.
> The recognition of the CPU of DYNAMIC_ARCH is low.
>
> zdot[cu], zgemv came to calculate definitely.
>
> --
> EI-JI Nakama? <nakama (a) ki.rim.or.jp>
> "\u4e2d\u9593\u6804\u6cbb"? <nakama (a) ki.rim.or.jp>
>

--
EI-JI Nakama? <nakama (a) ki.rim.or.jp>
"\u4e2d\u9593\u6804\u6cbb"? <nakama (a) ki.rim.or.jp>


From hb at biostat.ucsf.edu  Wed Mar 30 08:20:43 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Tue, 29 Mar 2011 23:20:43 -0700
Subject: [Rd] R CMD build processes inst/doc/Makefile only if there are
	vignette files?
Message-ID: <BANLkTinYAyuKfHy74QKkqOBFfT3tiF8t5g@mail.gmail.com>

Hi,

in Section 'Writing package vignettes' of 'Writing R Extensions' it says:

"Whenever a Makefile is found, then R CMD build will try to run make
after the Sweave runs, so PDF manuals can be created from arbitrary
source formats (plain LaTeX files, ...). [...] Note that the make step
is executed even if there are no files in Sweave format, [...]".

In my package, inst/doc/ file contains two files: Makefile, and
report.tex.  However, when running 'Rcmd build' on Windows with R
v2.13.0 alpha (2011-03-27 r55091) I can only get 'make' to run
(process inst/doc/Makefile) if I add a inst/doc/dummy.Rnw file,
otherwise nothing happens.  My Makefile contains:

all: pdf

pdf: report.tex
	texi2dvi --pdf report.tex

clean:
	rm dummy.Rnw dummy.tex
	rm *.aux *.log *.toc

Is it really necessary to add dummy.Rnw?  Am I missing something?

/Henrik

> sessionInfo()
R version 2.13.0 alpha (2011-03-27 r55091)
Platform: x86_64-pc-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_2.13.0


From hpages at fhcrc.org  Wed Mar 30 08:56:47 2011
From: hpages at fhcrc.org (Pages, Herve)
Date: Tue, 29 Mar 2011 23:56:47 -0700 (PDT)
Subject: [Rd] R CMD build now removes empty dirs
In-Reply-To: <1705062143.2814.1301464854707.JavaMail.root@zimbra4.fhcrc.org>
Message-ID: <849792884.2828.1301468207385.JavaMail.root@zimbra4.fhcrc.org>

Hi,

It's unfortunate that with recent revisions of R 2.13 (this
appeared in revision 54640, March 2), 'R CMD build' now removes
empty dirs in the package. People might have good reasons for
having empty dirs in their packages. For example, in Bioconductor,
we have some tools to automatically generate annotation packages
and those tools are implemented in software packages that use
templates for the annotation packages to be generated. Those
package templates are stored under the inst/ folder of the
software package. One of those software packages is the
AnnotationDbi package: it contains 41 package templates under
inst/:

[hpages at latitude Rpacks]$ ls AnnotationDbi/inst/AnnDbPkg-templates/
AFFYHUEX.DB         CHIMP.DB       MALARIA.DB    WORM.DB
ANOPHELES.DB        COELICOLOR.DB  MOUSECHIP.DB  XENOPUSCHIP.DB
ARABIDOPSISCHIP.DB  ECOLICHIP.DB   MOUSE.DB      XENOPUS.DB
ARABIDOPSIS.DB      ECOLI.DB       ORGANISM.DB   YEASTCHIP.DB
BASEPKG.DB          FLYCHIP.DB     PFAM.DB       YEAST.DB
BOVINECHIP.DB       FLY.DB         PIGCHIP.DB    YEASTNCBI.DB
BOVINE.DB           GO.DB          PIG.DB        ZEBRAFISHCHIP.DB
CANINECHIP.DB       HUMANCHIP.DB   RATCHIP.DB    ZEBRAFISH.DB
CANINE.DB           HUMAN.DB       RAT.DB
CHICKENCHIP.DB      INPARANOID.DB  RHESUS.DB
CHICKEN.DB          KEGG.DB        WORMCHIP.DB

Those package templates are just the skeletons of the hundreds of
annotation packages that we generate. Of course, each of them contains
empty subfolders.

Having 'R CMD build' remove those empty subfolders breaks all the
tools that make use of those package templates.
 
Maybe I've missed it but I didn't see any mention of this "feature"
on this list and the fact that it was added only 6 weeks before the
next R and Bioconductor releases is only making this worse.

I hope this "feature" can be reverted. Why would people or our build
system need to start using R CMD build --keep-empty-dirs just to get
a source tarball right?

Thanks,
H.

PS: This page

  http://stat.ethz.ch/R-manual/R-devel/doc/html/NEWS.html

(referenced from http://developer.r-project.org/) has not been
updated for months.


From ripley at stats.ox.ac.uk  Wed Mar 30 10:55:33 2011
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 30 Mar 2011 09:55:33 +0100 (BST)
Subject: [Rd] R CMD build processes inst/doc/Makefile only if there are
 vignette files?
In-Reply-To: <BANLkTinYAyuKfHy74QKkqOBFfT3tiF8t5g@mail.gmail.com>
References: <BANLkTinYAyuKfHy74QKkqOBFfT3tiF8t5g@mail.gmail.com>
Message-ID: <alpine.LFD.2.02.1103300946510.20705@gannet.stats.ox.ac.uk>

What R CMD build (and check) does is to call tools::buildVignettes.
That has been true for a while, and buildVignettes() returns if no 
vignettes are found.  The docs are out-of-date.

My view is that you are misusing inst/doc: it is intended *only* for 
files which are going to be installed and hence report.tex should not 
really be there.  So you should be doing this in another source 
directory and copying report.pdf to inst/doc.  Use configure to 
arrange this.

Shortly vignettes to be built will be moved out of inst/doc.

On Tue, 29 Mar 2011, Henrik Bengtsson wrote:

> Hi,
>
> in Section 'Writing package vignettes' of 'Writing R Extensions' it says:
>
> "Whenever a Makefile is found, then R CMD build will try to run make
> after the Sweave runs, so PDF manuals can be created from arbitrary
> source formats (plain LaTeX files, ...). [...] Note that the make step
> is executed even if there are no files in Sweave format, [...]".
>
> In my package, inst/doc/ file contains two files: Makefile, and
> report.tex.  However, when running 'Rcmd build' on Windows with R
> v2.13.0 alpha (2011-03-27 r55091) I can only get 'make' to run
> (process inst/doc/Makefile) if I add a inst/doc/dummy.Rnw file,
> otherwise nothing happens.  My Makefile contains:
>
> all: pdf
>
> pdf: report.tex
> 	texi2dvi --pdf report.tex
>
> clean:
> 	rm dummy.Rnw dummy.tex
> 	rm *.aux *.log *.toc
>
> Is it really necessary to add dummy.Rnw?  Am I missing something?
>
> /Henrik
>
>> sessionInfo()
> R version 2.13.0 alpha (2011-03-27 r55091)
> Platform: x86_64-pc-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_2.13.0
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jon.clayden at gmail.com  Wed Mar 30 13:40:01 2011
From: jon.clayden at gmail.com (Jon Clayden)
Date: Wed, 30 Mar 2011 12:40:01 +0100
Subject: [Rd] Reading 64-bit integers
In-Reply-To: <A1631B10-DB4D-4914-8FCA-C1A97178F02F@r-project.org>
References: <AANLkTinndjFuoV17Th4PRUdpbrY-7RjTbyXwY6T6n+cd@mail.gmail.com>
	<10962CE3-2F14-4BCE-8E78-AE18814C3F81@r-project.org>
	<AANLkTimSWMqXM90Zg7WKYPbddk9zfQZhXXQif6eeLaGX@mail.gmail.com>
	<5544174B-A567-4126-B99C-D39542260503@r-project.org>
	<AANLkTinfH__3foy9oex9+Eq-84pr_i9M6PfKay8R4i9T@mail.gmail.com>
	<4D927DAD.7070203@gmail.com>
	<A1631B10-DB4D-4914-8FCA-C1A97178F02F@r-project.org>
Message-ID: <AANLkTimKCb8EE_MfbXeCvMuLaQSQ1haLB2Y+MckH9smw@mail.gmail.com>

On 30 March 2011 02:49, Simon Urbanek <simon.urbanek at r-project.org> wrote:
>
> On Mar 29, 2011, at 8:47 PM, Duncan Murdoch wrote:
>
>> On 29/03/2011 7:01 PM, Jon Clayden wrote:
>>> Dear Simon,
>>>
>>> On 29 March 2011 22:40, Simon Urbanek<simon.urbanek at r-project.org> ?wrote:
>>>> Jon,
>>>>
>>>> On Mar 29, 2011, at 1:33 PM, Jon Clayden wrote:
>>>>
>>>>> Dear Simon,
>>>>>
>>>>> Thank you for the response.
>>>>>
>>>>> On 29 March 2011 15:06, Simon Urbanek<simon.urbanek at r-project.org> ?wrote:
>>>>>>
>>>>>> On Mar 29, 2011, at 8:46 AM, Jon Clayden wrote:
>>>>>>
>>>>>>> Dear all,
>>>>>>>
>>>>>>> I see from some previous threads that support for 64-bit integers in R
>>>>>>> may be an aim for future versions, but in the meantime I'm wondering
>>>>>>> whether it is possible to read in integers of greater than 32 bits at
>>>>>>> all. Judging from ?readBin, it should be possible to read 8-byte
>>>>>>> integers to some degree, but it is clearly limited in practice by R's
>>>>>>> internally 32-bit integer type:
>>>>>>>
>>>>>>>> x<- as.raw(c(0,0,0,0,1,0,0,0))
>>>>>>>> (readBin(x,"integer",n=1,size=8,signed=F,endian="big"))
>>>>>>> [1] 16777216
>>>>>>>> x<- as.raw(c(0,0,0,1,0,0,0,0))
>>>>>>>> (readBin(x,"integer",n=1,size=8,signed=F,endian="big"))
>>>>>>> [1] 0
>>>>>>>
>>>>>>> For values that fit into 32 bits it works fine, but for larger values
>>>>>>> it fails. (I'm a bit surprised by the zero - should the value not be
>>>>>>> NA if it is out of range?
>>>>>>
>>>>>> No, it's not out of range - int is only 4 bytes so only 4 first bytes (respecting endianness order, hence LSB) are used.
>>>>>
>>>>> The fact remains that I ask for the value of an 8-byte integer and
>>>>> don't get it.
>>>>
>>>> I think you're misinterpreting the documentation:
>>>>
>>>> ? ? If ?size? is specified and not the natural size of the object,
>>>> ? ? each element of the vector is coerced to an appropriate type
>>>> ? ? before being written or as it is read.
>>>>
>>>> The "integer" object type is defined as signed 32-bit in R, so if you ask for "8 bytes into object type integer", you get a coercion into that object type -- 32-bit signed integer -- as documented. I think the issue may come from the confusion of the object type "integer" with general "integer number" in mathematical sense that has no representation restrictions. (FWIW in C the "integer" type is "int" and it is 32-bit on all modern OSes regardless of platform - that's where the limitation comes from, it's not something R has made up).
>>>
>>> OK, but it still seems like there is a case for raising a warning. As
>>> it is there is no way to tell when reading an 8-byte integer from a
>>> file whether its value is really 0, or if it merely has 0 in its
>>> least-significant 4 bytes. If 99% of such stored numbers are below
>>> 2^31, one is going to need some extra logic to catch the other 1%
>>> where you (silently) get the wrong value. In essence, unless you're
>>> certain that you will never come across a number that actually uses
>>> the upper 4 bytes, you will always have to read it as two 4-byte
>>> numbers and check that the high-order one (which is endianness
>>> dependent, of course) is zero. A C-level sanity check seems more
>>> efficient and more helpful to me.
>>
>> Seems to me that the S-PLUS solution (output="double") would be a lot more useful. ?I'd commit that if you write it; I don't think I'd commit the warning.
>>
>
> I was going to write some thing similar (idea = good, patch welcome ;)). My only worry is that the "output" argument is a bit misleading in that one could expect to use any combination of "input"/"output" which may be a maintenance nightmare. If I understand it correctly it's only a special case for integer input. I don't have S+ so can't say how they deal with that.

I don't have S+ either, but I agree that this is a better solution -
although, I would guess, more involved to implement. Depending on how
important compatibility with S+ is, I guess a more specific, logical,
"convert large integers to double" option would be clearer than
"output". I'm happy to try to draft a patch, but it may be a little
while before I have some time.

All the best,
Jon


From jon.clayden at gmail.com  Wed Mar 30 18:45:15 2011
From: jon.clayden at gmail.com (Jon Clayden)
Date: Wed, 30 Mar 2011 17:45:15 +0100
Subject: [Rd] Reading 64-bit integers
In-Reply-To: <A1631B10-DB4D-4914-8FCA-C1A97178F02F@r-project.org>
References: <AANLkTinndjFuoV17Th4PRUdpbrY-7RjTbyXwY6T6n+cd@mail.gmail.com>
	<10962CE3-2F14-4BCE-8E78-AE18814C3F81@r-project.org>
	<AANLkTimSWMqXM90Zg7WKYPbddk9zfQZhXXQif6eeLaGX@mail.gmail.com>
	<5544174B-A567-4126-B99C-D39542260503@r-project.org>
	<AANLkTinfH__3foy9oex9+Eq-84pr_i9M6PfKay8R4i9T@mail.gmail.com>
	<4D927DAD.7070203@gmail.com>
	<A1631B10-DB4D-4914-8FCA-C1A97178F02F@r-project.org>
Message-ID: <AANLkTi=psiib5=dwZqZcUn-fJGgYc_u5HAEksMe0RaHs@mail.gmail.com>

Draft patch attached. I haven't modified internal code before, so
there may be a mistake in how I handle the mechanics, but hopefully
this is a useful starting point. At any rate, the base package tests
still work and it seems to function as intended:

> x <- as.raw(c(0,0,0,1,0,0,0,0))
> (readBin(x,"integer",n=1,size=8,signed=F,endian="big"))
[1] 0
> (readBin(x,"integer",n=1,size=8,signed=F,endian="big",double.out=T))
[1] 4294967296
> storage.mode(readBin(x,"integer",n=1,size=8,signed=F,endian="big",double.out=T))
[1] "double"

The "double.out" argument is ignored unless "what" is integer. As far
as I can tell there is no definition of unsigned long long akin to the
one for long long (at the top of connections.c), so I have not handled
the unsigned case for that type.

The diff is against the current beta, but I can provide a SVN diff
against the trunk if that is preferable.

All the best,
Jon


On 30 March 2011 02:49, Simon Urbanek <simon.urbanek at r-project.org> wrote:
>
> On Mar 29, 2011, at 8:47 PM, Duncan Murdoch wrote:
>
>> On 29/03/2011 7:01 PM, Jon Clayden wrote:
>>> Dear Simon,
>>>
>>> On 29 March 2011 22:40, Simon Urbanek<simon.urbanek at r-project.org> ?wrote:
>>>> Jon,
>>>>
>>>> On Mar 29, 2011, at 1:33 PM, Jon Clayden wrote:
>>>>
>>>>> Dear Simon,
>>>>>
>>>>> Thank you for the response.
>>>>>
>>>>> On 29 March 2011 15:06, Simon Urbanek<simon.urbanek at r-project.org> ?wrote:
>>>>>>
>>>>>> On Mar 29, 2011, at 8:46 AM, Jon Clayden wrote:
>>>>>>
>>>>>>> Dear all,
>>>>>>>
>>>>>>> I see from some previous threads that support for 64-bit integers in R
>>>>>>> may be an aim for future versions, but in the meantime I'm wondering
>>>>>>> whether it is possible to read in integers of greater than 32 bits at
>>>>>>> all. Judging from ?readBin, it should be possible to read 8-byte
>>>>>>> integers to some degree, but it is clearly limited in practice by R's
>>>>>>> internally 32-bit integer type:
>>>>>>>
>>>>>>>> x<- as.raw(c(0,0,0,0,1,0,0,0))
>>>>>>>> (readBin(x,"integer",n=1,size=8,signed=F,endian="big"))
>>>>>>> [1] 16777216
>>>>>>>> x<- as.raw(c(0,0,0,1,0,0,0,0))
>>>>>>>> (readBin(x,"integer",n=1,size=8,signed=F,endian="big"))
>>>>>>> [1] 0
>>>>>>>
>>>>>>> For values that fit into 32 bits it works fine, but for larger values
>>>>>>> it fails. (I'm a bit surprised by the zero - should the value not be
>>>>>>> NA if it is out of range?
>>>>>>
>>>>>> No, it's not out of range - int is only 4 bytes so only 4 first bytes (respecting endianness order, hence LSB) are used.
>>>>>
>>>>> The fact remains that I ask for the value of an 8-byte integer and
>>>>> don't get it.
>>>>
>>>> I think you're misinterpreting the documentation:
>>>>
>>>> ? ? If ?size? is specified and not the natural size of the object,
>>>> ? ? each element of the vector is coerced to an appropriate type
>>>> ? ? before being written or as it is read.
>>>>
>>>> The "integer" object type is defined as signed 32-bit in R, so if you ask for "8 bytes into object type integer", you get a coercion into that object type -- 32-bit signed integer -- as documented. I think the issue may come from the confusion of the object type "integer" with general "integer number" in mathematical sense that has no representation restrictions. (FWIW in C the "integer" type is "int" and it is 32-bit on all modern OSes regardless of platform - that's where the limitation comes from, it's not something R has made up).
>>>
>>> OK, but it still seems like there is a case for raising a warning. As
>>> it is there is no way to tell when reading an 8-byte integer from a
>>> file whether its value is really 0, or if it merely has 0 in its
>>> least-significant 4 bytes. If 99% of such stored numbers are below
>>> 2^31, one is going to need some extra logic to catch the other 1%
>>> where you (silently) get the wrong value. In essence, unless you're
>>> certain that you will never come across a number that actually uses
>>> the upper 4 bytes, you will always have to read it as two 4-byte
>>> numbers and check that the high-order one (which is endianness
>>> dependent, of course) is zero. A C-level sanity check seems more
>>> efficient and more helpful to me.
>>
>> Seems to me that the S-PLUS solution (output="double") would be a lot more useful. ?I'd commit that if you write it; I don't think I'd commit the warning.
>>
>
> I was going to write some thing similar (idea = good, patch welcome ;)). My only worry is that the "output" argument is a bit misleading in that one could expect to use any combination of "input"/"output" which may be a maintenance nightmare. If I understand it correctly it's only a special case for integer input. I don't have S+ so can't say how they deal with that.
>
> Cheers,
> Simon
>
>
>>
>>>
>>>>> Pretending that it's really only four bytes because of
>>>>> the limits of R's integer type isn't all that helpful. Perhaps a
>>>>> warning should be put out if the cast will affect the value of the
>>>>> result? It looks like the relevant lines in src/main/connections.c are
>>>>> 3689-3697 in the current alpha:
>>>>>
>>>>> #if SIZEOF_LONG == 8
>>>>> ? ? ? ? ? ? ? ? ? case sizeof(long):
>>>>> ? ? ? ? ? ? ? ? ? ? ? INTEGER(ans)[i] = (int)*((long *)buf);
>>>>> ? ? ? ? ? ? ? ? ? ? ? break;
>>>>> #elif SIZEOF_LONG_LONG == 8
>>>>> ? ? ? ? ? ? ? ? ? case sizeof(_lli_t):
>>>>> ? ? ? ? ? ? ? ? ? ? ? INTEGER(ans)[i] = (int)*((_lli_t *)buf);
>>>>> ? ? ? ? ? ? ? ? ? ? ? break;
>>>>> #endif
>>>>>
>>>>>>> ) The value can be represented as a double,
>>>>>>> though:
>>>>>>>
>>>>>>>> 4294967296
>>>>>>> [1] 4294967296
>>>>>>>
>>>>>>> I wouldn't expect readBin() to return a double if an integer was
>>>>>>> requested, but is there any way to get the correct value out of it?
>>>>>>
>>>>>> Trivially (for your unsigned big-endian case):
>>>>>>
>>>>>> y<- readBin(x, "integer", n=length(x)/4L, endian="big")
>>>>>> y<- ifelse(y< ?0, 2^32 + y, y)
>>>>>> i<- seq(1,length(y),2)
>>>>>> y<- y[i] * 2^32 + y[i + 1L]
>>>>>
>>>>> Thanks for the code, but I'm not sure I would call that trivial,
>>>>> especially if one needs to cater for little endian and signed cases as
>>>>> well!
>>>>
>>>> I was saying for your case and it's trivial as in read as integers, convert to double precision and add.
>>>>
>>>>
>>>>> This is what I meant by reconstructing the number manually...
>>>>>
>>>>
>>>> You didn't say so - you were talking about reconstructing it from a raw vector which seems a lot more painful since you can't compute with enough precision on raw vectors.
>>>
>>> True - I should have been more specific. Sorry.
>>>
>>> Jon
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
>

From wdunlap at tibco.com  Wed Mar 30 19:38:06 2011
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 30 Mar 2011 10:38:06 -0700
Subject: [Rd] Reading 64-bit integers
In-Reply-To: <A1631B10-DB4D-4914-8FCA-C1A97178F02F@r-project.org>
References: <AANLkTinndjFuoV17Th4PRUdpbrY-7RjTbyXwY6T6n+cd@mail.gmail.com>	<10962CE3-2F14-4BCE-8E78-AE18814C3F81@r-project.org>	<AANLkTimSWMqXM90Zg7WKYPbddk9zfQZhXXQif6eeLaGX@mail.gmail.com>	<5544174B-A567-4126-B99C-D39542260503@r-project.org><AANLkTinfH__3foy9oex9+Eq-84pr_i9M6PfKay8R4i9T@mail.gmail.com><4D927DAD.7070203@gmail.com>
	<A1631B10-DB4D-4914-8FCA-C1A97178F02F@r-project.org>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D70004124A5D@NA-PA-VBE03.na.tibco.com>


> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Simon Urbanek
> Sent: Tuesday, March 29, 2011 6:49 PM
> To: Duncan Murdoch
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] Reading 64-bit integers
> 
> 
> On Mar 29, 2011, at 8:47 PM, Duncan Murdoch wrote:
> 
> > On 29/03/2011 7:01 PM, Jon Clayden wrote:
> >> Dear Simon,
> >> 
> >> On 29 March 2011 22:40, Simon 
> Urbanek<simon.urbanek at r-project.org>  wrote:
> >>> Jon,
> >>> 
> >>> On Mar 29, 2011, at 1:33 PM, Jon Clayden wrote:
> >>> 
> >>>> Dear Simon,
> >>>> 
> >>>> Thank you for the response.
> >>>> 
> >>>> On 29 March 2011 15:06, Simon 
> Urbanek<simon.urbanek at r-project.org>  wrote:
> >>>>> 
> >>>>> On Mar 29, 2011, at 8:46 AM, Jon Clayden wrote:
> >>>>> 
> >>>>>> Dear all,
> >>>>>> 
> >>>>>> I see from some previous threads that support for 
> 64-bit integers in R
> >>>>>> may be an aim for future versions, but in the meantime 
> I'm wondering
> >>>>>> whether it is possible to read in integers of greater 
> than 32 bits at
> >>>>>> all. Judging from ?readBin, it should be possible to 
> read 8-byte
> >>>>>> integers to some degree, but it is clearly limited in 
> practice by R's
> >>>>>> internally 32-bit integer type:
> >>>>>> 
> >>>>>>> x<- as.raw(c(0,0,0,0,1,0,0,0))
> >>>>>>> (readBin(x,"integer",n=1,size=8,signed=F,endian="big"))
> >>>>>> [1] 16777216
> >>>>>>> x<- as.raw(c(0,0,0,1,0,0,0,0))
> >>>>>>> (readBin(x,"integer",n=1,size=8,signed=F,endian="big"))
> >>>>>> [1] 0
> >>>>>> 
> >>>>>> For values that fit into 32 bits it works fine, but 
> for larger values
> >>>>>> it fails. (I'm a bit surprised by the zero - should 
> the value not be
> >>>>>> NA if it is out of range?
> >>>>> 
> >>>>> No, it's not out of range - int is only 4 bytes so only 
> 4 first bytes (respecting endianness order, hence LSB) are used.
> >>>> 
> >>>> The fact remains that I ask for the value of an 8-byte 
> integer and
> >>>> don't get it.
> >>> 
> >>> I think you're misinterpreting the documentation:
> >>> 
> >>>     If 'size' is specified and not the natural size of the object,
> >>>     each element of the vector is coerced to an appropriate type
> >>>     before being written or as it is read.
> >>> 
> >>> The "integer" object type is defined as signed 32-bit in 
> R, so if you ask for "8 bytes into object type integer", you 
> get a coercion into that object type -- 32-bit signed integer 
> -- as documented. I think the issue may come from the 
> confusion of the object type "integer" with general "integer 
> number" in mathematical sense that has no representation 
> restrictions. (FWIW in C the "integer" type is "int" and it 
> is 32-bit on all modern OSes regardless of platform - that's 
> where the limitation comes from, it's not something R has made up).
> >> 
> >> OK, but it still seems like there is a case for raising a 
> warning. As
> >> it is there is no way to tell when reading an 8-byte integer from a
> >> file whether its value is really 0, or if it merely has 0 in its
> >> least-significant 4 bytes. If 99% of such stored numbers are below
> >> 2^31, one is going to need some extra logic to catch the other 1%
> >> where you (silently) get the wrong value. In essence, unless you're
> >> certain that you will never come across a number that actually uses
> >> the upper 4 bytes, you will always have to read it as two 4-byte
> >> numbers and check that the high-order one (which is endianness
> >> dependent, of course) is zero. A C-level sanity check seems more
> >> efficient and more helpful to me.
> > 
> > Seems to me that the S-PLUS solution (output="double") 
> would be a lot more useful.  I'd commit that if you write it; 
> I don't think I'd commit the warning.
> > 
> 
> I was going to write some thing similar (idea = good, patch 
> welcome ;)). My only worry is that the "output" argument is a 
> bit misleading in that one could expect to use any 
> combination of "input"/"output" which may be a maintenance 
> nightmare. If I understand it correctly it's only a special 
> case for integer input. I don't have S+ so can't say how they 
> deal with that.

In S+'s readBin the output argument can be
only double() or single() when what is double()
or single() (S+ still  has a real single
precision storage mode) and can be any
numeric type or logical when what is integer().

The output=double() seemed like the only useful case.

It does not warn when precision is lost in the 8-byte
integer to double conversion.  Perhaps it should.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com  

> 
> Cheers,
> Simon
> 
> 
> > 
> >> 
> >>>> Pretending that it's really only four bytes because of
> >>>> the limits of R's integer type isn't all that helpful. Perhaps a
> >>>> warning should be put out if the cast will affect the 
> value of the
> >>>> result? It looks like the relevant lines in 
> src/main/connections.c are
> >>>> 3689-3697 in the current alpha:
> >>>> 
> >>>> #if SIZEOF_LONG == 8
> >>>>                   case sizeof(long):
> >>>>                       INTEGER(ans)[i] = (int)*((long *)buf);
> >>>>                       break;
> >>>> #elif SIZEOF_LONG_LONG == 8
> >>>>                   case sizeof(_lli_t):
> >>>>                       INTEGER(ans)[i] = (int)*((_lli_t *)buf);
> >>>>                       break;
> >>>> #endif
> >>>> 
> >>>>>> ) The value can be represented as a double,
> >>>>>> though:
> >>>>>> 
> >>>>>>> 4294967296
> >>>>>> [1] 4294967296
> >>>>>> 
> >>>>>> I wouldn't expect readBin() to return a double if an 
> integer was
> >>>>>> requested, but is there any way to get the correct 
> value out of it?
> >>>>> 
> >>>>> Trivially (for your unsigned big-endian case):
> >>>>> 
> >>>>> y<- readBin(x, "integer", n=length(x)/4L, endian="big")
> >>>>> y<- ifelse(y<  0, 2^32 + y, y)
> >>>>> i<- seq(1,length(y),2)
> >>>>> y<- y[i] * 2^32 + y[i + 1L]
> >>>> 
> >>>> Thanks for the code, but I'm not sure I would call that trivial,
> >>>> especially if one needs to cater for little endian and 
> signed cases as
> >>>> well!
> >>> 
> >>> I was saying for your case and it's trivial as in read as 
> integers, convert to double precision and add.
> >>> 
> >>> 
> >>>> This is what I meant by reconstructing the number manually...
> >>>> 
> >>> 
> >>> You didn't say so - you were talking about reconstructing 
> it from a raw vector which seems a lot more painful since you 
> can't compute with enough precision on raw vectors.
> >> 
> >> True - I should have been more specific. Sorry.
> >> 
> >> Jon
> >> 
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> > 
> > 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From simon.urbanek at r-project.org  Wed Mar 30 20:22:53 2011
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 30 Mar 2011 14:22:53 -0400
Subject: [Rd] Reading 64-bit integers
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D70004124A5D@NA-PA-VBE03.na.tibco.com>
References: <AANLkTinndjFuoV17Th4PRUdpbrY-7RjTbyXwY6T6n+cd@mail.gmail.com>	<10962CE3-2F14-4BCE-8E78-AE18814C3F81@r-project.org>	<AANLkTimSWMqXM90Zg7WKYPbddk9zfQZhXXQif6eeLaGX@mail.gmail.com>	<5544174B-A567-4126-B99C-D39542260503@r-project.org><AANLkTinfH__3foy9oex9+Eq-84pr_i9M6PfKay8R4i9T@mail.gmail.com><4D927DAD.7070203@gmail.com>
	<A1631B10-DB4D-4914-8FCA-C1A97178F02F@r-project.org>
	<77EB52C6DD32BA4D87471DCD70C8D70004124A5D@NA-PA-VBE03.na.tibco.com>
Message-ID: <ADCFBA31-C69C-4424-B55C-E130D91AE22F@r-project.org>

Bill,

thanks. I like that idea of the output parameter better, especially if we ever add different scalar vector types. Admittedly, what=integer() is the most useful case. What I was worried about is things like what=double(), output=integer() which could be legal, but are more conveniently dealt with via as.integer(readBin()) instead.
I won't have more time today, but I'll have a look tomorrow.

Thanks,
Simon


On Mar 30, 2011, at 1:38 PM, William Dunlap wrote:

> 
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org 
>> [mailto:r-devel-bounces at r-project.org] On Behalf Of Simon Urbanek
>> Sent: Tuesday, March 29, 2011 6:49 PM
>> To: Duncan Murdoch
>> Cc: r-devel at r-project.org
>> Subject: Re: [Rd] Reading 64-bit integers
>> 
>> 
>> On Mar 29, 2011, at 8:47 PM, Duncan Murdoch wrote:
>> 
>>> On 29/03/2011 7:01 PM, Jon Clayden wrote:
>>>> Dear Simon,
>>>> 
>>>> On 29 March 2011 22:40, Simon 
>> Urbanek<simon.urbanek at r-project.org>  wrote:
>>>>> Jon,
>>>>> 
>>>>> On Mar 29, 2011, at 1:33 PM, Jon Clayden wrote:
>>>>> 
>>>>>> Dear Simon,
>>>>>> 
>>>>>> Thank you for the response.
>>>>>> 
>>>>>> On 29 March 2011 15:06, Simon 
>> Urbanek<simon.urbanek at r-project.org>  wrote:
>>>>>>> 
>>>>>>> On Mar 29, 2011, at 8:46 AM, Jon Clayden wrote:
>>>>>>> 
>>>>>>>> Dear all,
>>>>>>>> 
>>>>>>>> I see from some previous threads that support for 
>> 64-bit integers in R
>>>>>>>> may be an aim for future versions, but in the meantime 
>> I'm wondering
>>>>>>>> whether it is possible to read in integers of greater 
>> than 32 bits at
>>>>>>>> all. Judging from ?readBin, it should be possible to 
>> read 8-byte
>>>>>>>> integers to some degree, but it is clearly limited in 
>> practice by R's
>>>>>>>> internally 32-bit integer type:
>>>>>>>> 
>>>>>>>>> x<- as.raw(c(0,0,0,0,1,0,0,0))
>>>>>>>>> (readBin(x,"integer",n=1,size=8,signed=F,endian="big"))
>>>>>>>> [1] 16777216
>>>>>>>>> x<- as.raw(c(0,0,0,1,0,0,0,0))
>>>>>>>>> (readBin(x,"integer",n=1,size=8,signed=F,endian="big"))
>>>>>>>> [1] 0
>>>>>>>> 
>>>>>>>> For values that fit into 32 bits it works fine, but 
>> for larger values
>>>>>>>> it fails. (I'm a bit surprised by the zero - should 
>> the value not be
>>>>>>>> NA if it is out of range?
>>>>>>> 
>>>>>>> No, it's not out of range - int is only 4 bytes so only 
>> 4 first bytes (respecting endianness order, hence LSB) are used.
>>>>>> 
>>>>>> The fact remains that I ask for the value of an 8-byte 
>> integer and
>>>>>> don't get it.
>>>>> 
>>>>> I think you're misinterpreting the documentation:
>>>>> 
>>>>>    If 'size' is specified and not the natural size of the object,
>>>>>    each element of the vector is coerced to an appropriate type
>>>>>    before being written or as it is read.
>>>>> 
>>>>> The "integer" object type is defined as signed 32-bit in 
>> R, so if you ask for "8 bytes into object type integer", you 
>> get a coercion into that object type -- 32-bit signed integer 
>> -- as documented. I think the issue may come from the 
>> confusion of the object type "integer" with general "integer 
>> number" in mathematical sense that has no representation 
>> restrictions. (FWIW in C the "integer" type is "int" and it 
>> is 32-bit on all modern OSes regardless of platform - that's 
>> where the limitation comes from, it's not something R has made up).
>>>> 
>>>> OK, but it still seems like there is a case for raising a 
>> warning. As
>>>> it is there is no way to tell when reading an 8-byte integer from a
>>>> file whether its value is really 0, or if it merely has 0 in its
>>>> least-significant 4 bytes. If 99% of such stored numbers are below
>>>> 2^31, one is going to need some extra logic to catch the other 1%
>>>> where you (silently) get the wrong value. In essence, unless you're
>>>> certain that you will never come across a number that actually uses
>>>> the upper 4 bytes, you will always have to read it as two 4-byte
>>>> numbers and check that the high-order one (which is endianness
>>>> dependent, of course) is zero. A C-level sanity check seems more
>>>> efficient and more helpful to me.
>>> 
>>> Seems to me that the S-PLUS solution (output="double") 
>> would be a lot more useful.  I'd commit that if you write it; 
>> I don't think I'd commit the warning.
>>> 
>> 
>> I was going to write some thing similar (idea = good, patch 
>> welcome ;)). My only worry is that the "output" argument is a 
>> bit misleading in that one could expect to use any 
>> combination of "input"/"output" which may be a maintenance 
>> nightmare. If I understand it correctly it's only a special 
>> case for integer input. I don't have S+ so can't say how they 
>> deal with that.
> 
> In S+'s readBin the output argument can be
> only double() or single() when what is double()
> or single() (S+ still  has a real single
> precision storage mode) and can be any
> numeric type or logical when what is integer().
> 
> The output=double() seemed like the only useful case.
> 
> It does not warn when precision is lost in the 8-byte
> integer to double conversion.  Perhaps it should.
> 
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com  
> 
>> 
>> Cheers,
>> Simon
>> 
>> 
>>> 
>>>> 
>>>>>> Pretending that it's really only four bytes because of
>>>>>> the limits of R's integer type isn't all that helpful. Perhaps a
>>>>>> warning should be put out if the cast will affect the 
>> value of the
>>>>>> result? It looks like the relevant lines in 
>> src/main/connections.c are
>>>>>> 3689-3697 in the current alpha:
>>>>>> 
>>>>>> #if SIZEOF_LONG == 8
>>>>>>                  case sizeof(long):
>>>>>>                      INTEGER(ans)[i] = (int)*((long *)buf);
>>>>>>                      break;
>>>>>> #elif SIZEOF_LONG_LONG == 8
>>>>>>                  case sizeof(_lli_t):
>>>>>>                      INTEGER(ans)[i] = (int)*((_lli_t *)buf);
>>>>>>                      break;
>>>>>> #endif
>>>>>> 
>>>>>>>> ) The value can be represented as a double,
>>>>>>>> though:
>>>>>>>> 
>>>>>>>>> 4294967296
>>>>>>>> [1] 4294967296
>>>>>>>> 
>>>>>>>> I wouldn't expect readBin() to return a double if an 
>> integer was
>>>>>>>> requested, but is there any way to get the correct 
>> value out of it?
>>>>>>> 
>>>>>>> Trivially (for your unsigned big-endian case):
>>>>>>> 
>>>>>>> y<- readBin(x, "integer", n=length(x)/4L, endian="big")
>>>>>>> y<- ifelse(y<  0, 2^32 + y, y)
>>>>>>> i<- seq(1,length(y),2)
>>>>>>> y<- y[i] * 2^32 + y[i + 1L]
>>>>>> 
>>>>>> Thanks for the code, but I'm not sure I would call that trivial,
>>>>>> especially if one needs to cater for little endian and 
>> signed cases as
>>>>>> well!
>>>>> 
>>>>> I was saying for your case and it's trivial as in read as 
>> integers, convert to double precision and add.
>>>>> 
>>>>> 
>>>>>> This is what I meant by reconstructing the number manually...
>>>>>> 
>>>>> 
>>>>> You didn't say so - you were talking about reconstructing 
>> it from a raw vector which seems a lot more painful since you 
>> can't compute with enough precision on raw vectors.
>>>> 
>>>> True - I should have been more specific. Sorry.
>>>> 
>>>> Jon
>>>> 
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>> 
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
> 
> 


From bates at stat.wisc.edu  Wed Mar 30 22:03:34 2011
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 30 Mar 2011 15:03:34 -0500
Subject: [Rd] core Matrix package segfaulted on R CMD check --use-gct
In-Reply-To: <AANLkTimuxb199-32D+043u9fNp7VsDjf5QD2qX3_Zjof@mail.gmail.com>
References: <255683.81856.qm@web29515.mail.ird.yahoo.com>
	<AANLkTimDJbJ-u3wXOyvPB0EePf98AZ-R5duKVr+Guh-v@mail.gmail.com>
	<19856.40809.236979.731769@stat.math.ethz.ch>
	<4D91B5CC.1040500@users.sourceforge.net>
	<AANLkTimuxb199-32D+043u9fNp7VsDjf5QD2qX3_Zjof@mail.gmail.com>
Message-ID: <AANLkTi=Tjjq9JtuzYp8x4Pp=gtg2eGT7C6RoaXehmX_W@mail.gmail.com>

On Tue, Mar 29, 2011 at 2:17 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
> On Tue, Mar 29, 2011 at 5:34 AM, Hin-Tak Leung
> <htl10 at users.sourceforge.net> wrote:
>> Martin Maechler wrote:
>>>>>>>>
>>>>>>>> Douglas Bates <bates at stat.wisc.edu>
>>>>>>>> ? ?on Mon, 28 Mar 2011 09:24:39 -0500 writes:
>>>
>>> ? ?> Can you provide the output from sessionInfo()
>>>
>>> ? ?> so we can know the platform? ?Also, did you configure R
>>> ? ?> with --enable-strict-barrier or set the C compilation flag
>>> ? ?> -DTESTING_WRITE_BARRIER? ?I think that run-time error
>>> ? ?> message can only be thrown under those circumstances (not
>>> ? ?> that it isn't an error, it's just not checked for in other
>>> ? ?> circumstances).
>>>
>>> interesting.
>>>
>>> In the mean time, I *did* run --- for several hours! ---
>>> your code example below,
>>> and it did *not* segfault for me (64-bit, Linux Fedora 13).
>>>
>>> Martin
>>
>> 64-bit fedora 14. For building R svn (and checking soon-to-be-released R
>> packages, rather than daily R-related work), I also have these, and indeed
>> have "--enable-strict-barrier":
>>
>> export DEFS='-DUSE_TYPE_CHECKING_STRICT -DR_MEMORY_PROFILING' \
>> ./configure --enable-memory-profiling --enable-strict-barrier
>> --enable-byte-compiled-packages --with-valgrind-instrumentation=2
>>
>>> sessionInfo()
>> R version 2.14.0 Under development (unstable) (--)
>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>
>> locale:
>> ?[1] LC_CTYPE=en_GB.UTF-8 ? ? ? LC_NUMERIC=C
>> ?[3] LC_TIME=en_GB.UTF-8 ? ? ? ?LC_COLLATE=en_GB.UTF-8
>> ?[5] LC_MONETARY=C ? ? ? ? ? ? ?LC_MESSAGES=en_GB.UTF-8
>> ?[7] LC_PAPER=en_GB.UTF-8 ? ? ? LC_NAME=C
>> ?[9] LC_ADDRESS=C ? ? ? ? ? ? ? LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
> Thanks for the information. ?I can replicate the problem on a Red Hat
> EL 5 64-bit system and will start to debug now.

I isolated the problem and tested then committed a fix. I am going to
ask Martin to upload the new release as I have gotten out of sync with
some of his recent changes and he will, I hope, reconcile the branches
and trunk.  If you need the fixed version immediately, say for
testing, the changes are in the file Matrix/src/chm_common.c  You can
visit the SVN archive for the project,
https://r-forge.r-project.org/scm/?group_id=61, click on the link to
Browse Subversion Repository and go to pkg/Matrix/src/chm_common.c

I made the mistake that I chastised others for making, performing an
operation on the result of a call to install and another value that
may have required allocation of memory.  The first time install is
called on a particular string it allocates and SEXPREC, which may
cause a garbage collection.
>>>>>>>> Douglas Bates <bates at stat.wisc.edu>
>>>>>>>> ? ?on Mon, 28 Mar 2011 09:24:39 -0500 writes:
>>>
>>> ? ?> Can you provide the output from
>>> ? ?> sessionInfo()
>>>
>>> ? ?> so we can know the platform? ?Also, did you configure R with
>>> ? ?> --enable-strict-barrier or set the C compilation flag
>>> ? ?> -DTESTING_WRITE_BARRIER? ?I think that run-time error message can
>>> only
>>> ? ?> be thrown under those circumstances (not that it isn't an error, it's
>>> ? ?> just not checked for in other circumstances).
>>>
>>> ? ?> On Sat, Mar 26, 2011 at 5:21 PM, Hin-Tak Leung
>>> <hintak_leung at yahoo.co.uk> wrote:
>>> ? ?>> Current core/Recommended Matrix package (0.999375-48) has been
>>> segfaulting against R 2.13-alpha/2.14-trunk for the last week or so (since
>>> R-2.13 was branched, when I started trying) when "run with R CMD check
>>> --use-gct":
>>> ? ?>> ? ? >> --------------
>>> ? ?>>> pkgname <- "Matrix"
>>> ? ?>>> source(file.path(R.home("share"), "R", "examples-header.R"))
>>> ? ?>>> gctorture(TRUE)
>>> ? ?>>> options(warn = 1)
>>> ? ?>>> library('Matrix')
>>> ? ?>> Loading required package: lattice
>>> ? ?>> Error : .onLoad failed in loadNamespace() for 'Matrix', details:
>>> ? ?>> ?call: fun(...)
>>> ? ?>> ?error: unprotected object (0x2768b18) encountered (was REALSXP)
>>> ? ?>> Error: package/namespace load failed for 'Matrix'
>>> ? ?>> Execution halted
>>> ? ?>> ---------------
>>> ? ?>> ? ? >> I traced to this because "R CMD check --use-gct snpStats"
>>> (both 1.1.13 and 1.1.12) segfaults with the same message, and before that,
>>> the snpMatrix 1.15.8.4 which includes some of David's newly written ld() (
>>> which depends on Matrix.)
>>> ? ?>> ? ? >> If the Matrix package segfaults, David's new ld() isn't
>>> useable.
>>> ? ?>> ? ? >>
>>
>


From hb at biostat.ucsf.edu  Thu Mar 31 04:51:04 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Wed, 30 Mar 2011 19:51:04 -0700
Subject: [Rd] Reading 64-bit integers
In-Reply-To: <ADCFBA31-C69C-4424-B55C-E130D91AE22F@r-project.org>
References: <AANLkTinndjFuoV17Th4PRUdpbrY-7RjTbyXwY6T6n+cd@mail.gmail.com>
	<10962CE3-2F14-4BCE-8E78-AE18814C3F81@r-project.org>
	<AANLkTimSWMqXM90Zg7WKYPbddk9zfQZhXXQif6eeLaGX@mail.gmail.com>
	<5544174B-A567-4126-B99C-D39542260503@r-project.org>
	<AANLkTinfH__3foy9oex9+Eq-84pr_i9M6PfKay8R4i9T@mail.gmail.com>
	<4D927DAD.7070203@gmail.com>
	<A1631B10-DB4D-4914-8FCA-C1A97178F02F@r-project.org>
	<77EB52C6DD32BA4D87471DCD70C8D70004124A5D@NA-PA-VBE03.na.tibco.com>
	<ADCFBA31-C69C-4424-B55C-E130D91AE22F@r-project.org>
Message-ID: <BANLkTimGivbUvMpoa1cw8=HU93QJFu0nQA@mail.gmail.com>

On Wed, Mar 30, 2011 at 11:22 AM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
> Bill,
>
> thanks. I like that idea of the output parameter better, especially if we ever add different scalar vector types. Admittedly, what=integer() is the most useful case. What I was worried about is things like what=double(), output=integer() which could be legal, but are more conveniently dealt with via as.integer(readBin()) instead.

What about this:

Let the default be output=what.  Then, just throw an error upon the
function for non-supported combinations of 'what' and 'output'.
Something like (assuming 'what' and 'output' already have been
converted to "type" strings):

# Validate argument 'output':
if (output != what) {
  # In most cases, we never get here.
  also <- list(integer="double")[[what]];
  if (is.null(also) || !is.element(output, also)) {
    # Throw an informative error message
    stop("Unsupported value of argument 'output' (\"", output, "\").
Supported output types when reading \"", what, "\" values: ",
paste(c(what, also), collapse=", "));
  }
}

That should prevent any unintended usage (before wasting time with
I/O).  It is also allows for future extension.

Thxs

/Henrik

> I won't have more time today, but I'll have a look tomorrow.
>
> Thanks,
> Simon
>
>
> On Mar 30, 2011, at 1:38 PM, William Dunlap wrote:
>
>>
>>> -----Original Message-----
>>> From: r-devel-bounces at r-project.org
>>> [mailto:r-devel-bounces at r-project.org] On Behalf Of Simon Urbanek
>>> Sent: Tuesday, March 29, 2011 6:49 PM
>>> To: Duncan Murdoch
>>> Cc: r-devel at r-project.org
>>> Subject: Re: [Rd] Reading 64-bit integers
>>>
>>>
>>> On Mar 29, 2011, at 8:47 PM, Duncan Murdoch wrote:
>>>
>>>> On 29/03/2011 7:01 PM, Jon Clayden wrote:
>>>>> Dear Simon,
>>>>>
>>>>> On 29 March 2011 22:40, Simon
>>> Urbanek<simon.urbanek at r-project.org> ?wrote:
>>>>>> Jon,
>>>>>>
>>>>>> On Mar 29, 2011, at 1:33 PM, Jon Clayden wrote:
>>>>>>
>>>>>>> Dear Simon,
>>>>>>>
>>>>>>> Thank you for the response.
>>>>>>>
>>>>>>> On 29 March 2011 15:06, Simon
>>> Urbanek<simon.urbanek at r-project.org> ?wrote:
>>>>>>>>
>>>>>>>> On Mar 29, 2011, at 8:46 AM, Jon Clayden wrote:
>>>>>>>>
>>>>>>>>> Dear all,
>>>>>>>>>
>>>>>>>>> I see from some previous threads that support for
>>> 64-bit integers in R
>>>>>>>>> may be an aim for future versions, but in the meantime
>>> I'm wondering
>>>>>>>>> whether it is possible to read in integers of greater
>>> than 32 bits at
>>>>>>>>> all. Judging from ?readBin, it should be possible to
>>> read 8-byte
>>>>>>>>> integers to some degree, but it is clearly limited in
>>> practice by R's
>>>>>>>>> internally 32-bit integer type:
>>>>>>>>>
>>>>>>>>>> x<- as.raw(c(0,0,0,0,1,0,0,0))
>>>>>>>>>> (readBin(x,"integer",n=1,size=8,signed=F,endian="big"))
>>>>>>>>> [1] 16777216
>>>>>>>>>> x<- as.raw(c(0,0,0,1,0,0,0,0))
>>>>>>>>>> (readBin(x,"integer",n=1,size=8,signed=F,endian="big"))
>>>>>>>>> [1] 0
>>>>>>>>>
>>>>>>>>> For values that fit into 32 bits it works fine, but
>>> for larger values
>>>>>>>>> it fails. (I'm a bit surprised by the zero - should
>>> the value not be
>>>>>>>>> NA if it is out of range?
>>>>>>>>
>>>>>>>> No, it's not out of range - int is only 4 bytes so only
>>> 4 first bytes (respecting endianness order, hence LSB) are used.
>>>>>>>
>>>>>>> The fact remains that I ask for the value of an 8-byte
>>> integer and
>>>>>>> don't get it.
>>>>>>
>>>>>> I think you're misinterpreting the documentation:
>>>>>>
>>>>>> ? ?If 'size' is specified and not the natural size of the object,
>>>>>> ? ?each element of the vector is coerced to an appropriate type
>>>>>> ? ?before being written or as it is read.
>>>>>>
>>>>>> The "integer" object type is defined as signed 32-bit in
>>> R, so if you ask for "8 bytes into object type integer", you
>>> get a coercion into that object type -- 32-bit signed integer
>>> -- as documented. I think the issue may come from the
>>> confusion of the object type "integer" with general "integer
>>> number" in mathematical sense that has no representation
>>> restrictions. (FWIW in C the "integer" type is "int" and it
>>> is 32-bit on all modern OSes regardless of platform - that's
>>> where the limitation comes from, it's not something R has made up).
>>>>>
>>>>> OK, but it still seems like there is a case for raising a
>>> warning. As
>>>>> it is there is no way to tell when reading an 8-byte integer from a
>>>>> file whether its value is really 0, or if it merely has 0 in its
>>>>> least-significant 4 bytes. If 99% of such stored numbers are below
>>>>> 2^31, one is going to need some extra logic to catch the other 1%
>>>>> where you (silently) get the wrong value. In essence, unless you're
>>>>> certain that you will never come across a number that actually uses
>>>>> the upper 4 bytes, you will always have to read it as two 4-byte
>>>>> numbers and check that the high-order one (which is endianness
>>>>> dependent, of course) is zero. A C-level sanity check seems more
>>>>> efficient and more helpful to me.
>>>>
>>>> Seems to me that the S-PLUS solution (output="double")
>>> would be a lot more useful. ?I'd commit that if you write it;
>>> I don't think I'd commit the warning.
>>>>
>>>
>>> I was going to write some thing similar (idea = good, patch
>>> welcome ;)). My only worry is that the "output" argument is a
>>> bit misleading in that one could expect to use any
>>> combination of "input"/"output" which may be a maintenance
>>> nightmare. If I understand it correctly it's only a special
>>> case for integer input. I don't have S+ so can't say how they
>>> deal with that.
>>
>> In S+'s readBin the output argument can be
>> only double() or single() when what is double()
>> or single() (S+ still ?has a real single
>> precision storage mode) and can be any
>> numeric type or logical when what is integer().
>>
>> The output=double() seemed like the only useful case.
>>
>> It does not warn when precision is lost in the 8-byte
>> integer to double conversion. ?Perhaps it should.
>>
>> Bill Dunlap
>> Spotfire, TIBCO Software
>> wdunlap tibco.com
>>
>>>
>>> Cheers,
>>> Simon
>>>
>>>
>>>>
>>>>>
>>>>>>> Pretending that it's really only four bytes because of
>>>>>>> the limits of R's integer type isn't all that helpful. Perhaps a
>>>>>>> warning should be put out if the cast will affect the
>>> value of the
>>>>>>> result? It looks like the relevant lines in
>>> src/main/connections.c are
>>>>>>> 3689-3697 in the current alpha:
>>>>>>>
>>>>>>> #if SIZEOF_LONG == 8
>>>>>>> ? ? ? ? ? ? ? ? ?case sizeof(long):
>>>>>>> ? ? ? ? ? ? ? ? ? ? ?INTEGER(ans)[i] = (int)*((long *)buf);
>>>>>>> ? ? ? ? ? ? ? ? ? ? ?break;
>>>>>>> #elif SIZEOF_LONG_LONG == 8
>>>>>>> ? ? ? ? ? ? ? ? ?case sizeof(_lli_t):
>>>>>>> ? ? ? ? ? ? ? ? ? ? ?INTEGER(ans)[i] = (int)*((_lli_t *)buf);
>>>>>>> ? ? ? ? ? ? ? ? ? ? ?break;
>>>>>>> #endif
>>>>>>>
>>>>>>>>> ) The value can be represented as a double,
>>>>>>>>> though:
>>>>>>>>>
>>>>>>>>>> 4294967296
>>>>>>>>> [1] 4294967296
>>>>>>>>>
>>>>>>>>> I wouldn't expect readBin() to return a double if an
>>> integer was
>>>>>>>>> requested, but is there any way to get the correct
>>> value out of it?
>>>>>>>>
>>>>>>>> Trivially (for your unsigned big-endian case):
>>>>>>>>
>>>>>>>> y<- readBin(x, "integer", n=length(x)/4L, endian="big")
>>>>>>>> y<- ifelse(y< ?0, 2^32 + y, y)
>>>>>>>> i<- seq(1,length(y),2)
>>>>>>>> y<- y[i] * 2^32 + y[i + 1L]
>>>>>>>
>>>>>>> Thanks for the code, but I'm not sure I would call that trivial,
>>>>>>> especially if one needs to cater for little endian and
>>> signed cases as
>>>>>>> well!
>>>>>>
>>>>>> I was saying for your case and it's trivial as in read as
>>> integers, convert to double precision and add.
>>>>>>
>>>>>>
>>>>>>> This is what I meant by reconstructing the number manually...
>>>>>>>
>>>>>>
>>>>>> You didn't say so - you were talking about reconstructing
>>> it from a raw vector which seems a lot more painful since you
>>> can't compute with enough precision on raw vectors.
>>>>>
>>>>> True - I should have been more specific. Sorry.
>>>>>
>>>>> Jon
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From hb at biostat.ucsf.edu  Thu Mar 31 05:04:32 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Wed, 30 Mar 2011 20:04:32 -0700
Subject: [Rd] R CMD build now removes empty dirs
In-Reply-To: <849792884.2828.1301468207385.JavaMail.root@zimbra4.fhcrc.org>
References: <1705062143.2814.1301464854707.JavaMail.root@zimbra4.fhcrc.org>
	<849792884.2828.1301468207385.JavaMail.root@zimbra4.fhcrc.org>
Message-ID: <BANLkTim9+O=B+hUwExw_1Af5+ojEO1w5pA@mail.gmail.com>

I am also in favor for keeping the ability of installing directory
structures that are partly empty.  I've used it before to setup
templates that can conveniently be copied recursively to a local path.
 I did noticed that R CMD INSTALL gave a warning about empty
directories before (or was it a NOTE by R CMD check?).

/Henrik

On Tue, Mar 29, 2011 at 11:56 PM, Pages, Herve <hpages at fhcrc.org> wrote:
> Hi,
>
> It's unfortunate that with recent revisions of R 2.13 (this
> appeared in revision 54640, March 2), 'R CMD build' now removes
> empty dirs in the package. People might have good reasons for
> having empty dirs in their packages. For example, in Bioconductor,
> we have some tools to automatically generate annotation packages
> and those tools are implemented in software packages that use
> templates for the annotation packages to be generated. Those
> package templates are stored under the inst/ folder of the
> software package. One of those software packages is the
> AnnotationDbi package: it contains 41 package templates under
> inst/:
>
> [hpages at latitude Rpacks]$ ls AnnotationDbi/inst/AnnDbPkg-templates/
> AFFYHUEX.DB ? ? ? ? CHIMP.DB ? ? ? MALARIA.DB ? ?WORM.DB
> ANOPHELES.DB ? ? ? ?COELICOLOR.DB ?MOUSECHIP.DB ?XENOPUSCHIP.DB
> ARABIDOPSISCHIP.DB ?ECOLICHIP.DB ? MOUSE.DB ? ? ?XENOPUS.DB
> ARABIDOPSIS.DB ? ? ?ECOLI.DB ? ? ? ORGANISM.DB ? YEASTCHIP.DB
> BASEPKG.DB ? ? ? ? ?FLYCHIP.DB ? ? PFAM.DB ? ? ? YEAST.DB
> BOVINECHIP.DB ? ? ? FLY.DB ? ? ? ? PIGCHIP.DB ? ?YEASTNCBI.DB
> BOVINE.DB ? ? ? ? ? GO.DB ? ? ? ? ?PIG.DB ? ? ? ?ZEBRAFISHCHIP.DB
> CANINECHIP.DB ? ? ? HUMANCHIP.DB ? RATCHIP.DB ? ?ZEBRAFISH.DB
> CANINE.DB ? ? ? ? ? HUMAN.DB ? ? ? RAT.DB
> CHICKENCHIP.DB ? ? ?INPARANOID.DB ?RHESUS.DB
> CHICKEN.DB ? ? ? ? ?KEGG.DB ? ? ? ?WORMCHIP.DB
>
> Those package templates are just the skeletons of the hundreds of
> annotation packages that we generate. Of course, each of them contains
> empty subfolders.
>
> Having 'R CMD build' remove those empty subfolders breaks all the
> tools that make use of those package templates.
>
> Maybe I've missed it but I didn't see any mention of this "feature"
> on this list and the fact that it was added only 6 weeks before the
> next R and Bioconductor releases is only making this worse.
>
> I hope this "feature" can be reverted. Why would people or our build
> system need to start using R CMD build --keep-empty-dirs just to get
> a source tarball right?
>
> Thanks,
> H.
>
> PS: This page
>
> ?http://stat.ethz.ch/R-manual/R-devel/doc/html/NEWS.html
>
> (referenced from http://developer.r-project.org/) has not been
> updated for months.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From hb at biostat.ucsf.edu  Thu Mar 31 05:50:32 2011
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Wed, 30 Mar 2011 20:50:32 -0700
Subject: [Rd] Reading 64-bit integers
In-Reply-To: <BANLkTimGivbUvMpoa1cw8=HU93QJFu0nQA@mail.gmail.com>
References: <AANLkTinndjFuoV17Th4PRUdpbrY-7RjTbyXwY6T6n+cd@mail.gmail.com>
	<10962CE3-2F14-4BCE-8E78-AE18814C3F81@r-project.org>
	<AANLkTimSWMqXM90Zg7WKYPbddk9zfQZhXXQif6eeLaGX@mail.gmail.com>
	<5544174B-A567-4126-B99C-D39542260503@r-project.org>
	<AANLkTinfH__3foy9oex9+Eq-84pr_i9M6PfKay8R4i9T@mail.gmail.com>
	<4D927DAD.7070203@gmail.com>
	<A1631B10-DB4D-4914-8FCA-C1A97178F02F@r-project.org>
	<77EB52C6DD32BA4D87471DCD70C8D70004124A5D@NA-PA-VBE03.na.tibco.com>
	<ADCFBA31-C69C-4424-B55C-E130D91AE22F@r-project.org>
	<BANLkTimGivbUvMpoa1cw8=HU93QJFu0nQA@mail.gmail.com>
Message-ID: <BANLkTi=KjkR67Oy996kyaBiGJ_NwGSuoww@mail.gmail.com>

On Wed, Mar 30, 2011 at 7:51 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> On Wed, Mar 30, 2011 at 11:22 AM, Simon Urbanek
> <simon.urbanek at r-project.org> wrote:
>> Bill,
>>
>> thanks. I like that idea of the output parameter better, especially if we ever add different scalar vector types. Admittedly, what=integer() is the most useful case. What I was worried about is things like what=double(), output=integer() which could be legal, but are more conveniently dealt with via as.integer(readBin()) instead.
>
> What about this:
>
> Let the default be output=what. ?Then, just throw an error upon the
> function for non-supported combinations of 'what' and 'output'.
> Something like (assuming 'what' and 'output' already have been
> converted to "type" strings):
>
> # Validate argument 'output':
> if (output != what) {
> ?# In most cases, we never get here.
> ?also <- list(integer="double")[[what]];
> ?if (is.null(also) || !is.element(output, also)) {

if (!is.element(output, also)) {

should be enough.

/H

> ? ?# Throw an informative error message
> ? ?stop("Unsupported value of argument 'output' (\"", output, "\").
> Supported output types when reading \"", what, "\" values: ",
> paste(c(what, also), collapse=", "));
> ?}
> }
>
> That should prevent any unintended usage (before wasting time with
> I/O). ?It is also allows for future extension.
>
> Thxs
>
> /Henrik
>
>> I won't have more time today, but I'll have a look tomorrow.
>>
>> Thanks,
>> Simon
>>
>>
>> On Mar 30, 2011, at 1:38 PM, William Dunlap wrote:
>>
>>>
>>>> -----Original Message-----
>>>> From: r-devel-bounces at r-project.org
>>>> [mailto:r-devel-bounces at r-project.org] On Behalf Of Simon Urbanek
>>>> Sent: Tuesday, March 29, 2011 6:49 PM
>>>> To: Duncan Murdoch
>>>> Cc: r-devel at r-project.org
>>>> Subject: Re: [Rd] Reading 64-bit integers
>>>>
>>>>
>>>> On Mar 29, 2011, at 8:47 PM, Duncan Murdoch wrote:
>>>>
>>>>> On 29/03/2011 7:01 PM, Jon Clayden wrote:
>>>>>> Dear Simon,
>>>>>>
>>>>>> On 29 March 2011 22:40, Simon
>>>> Urbanek<simon.urbanek at r-project.org> ?wrote:
>>>>>>> Jon,
>>>>>>>
>>>>>>> On Mar 29, 2011, at 1:33 PM, Jon Clayden wrote:
>>>>>>>
>>>>>>>> Dear Simon,
>>>>>>>>
>>>>>>>> Thank you for the response.
>>>>>>>>
>>>>>>>> On 29 March 2011 15:06, Simon
>>>> Urbanek<simon.urbanek at r-project.org> ?wrote:
>>>>>>>>>
>>>>>>>>> On Mar 29, 2011, at 8:46 AM, Jon Clayden wrote:
>>>>>>>>>
>>>>>>>>>> Dear all,
>>>>>>>>>>
>>>>>>>>>> I see from some previous threads that support for
>>>> 64-bit integers in R
>>>>>>>>>> may be an aim for future versions, but in the meantime
>>>> I'm wondering
>>>>>>>>>> whether it is possible to read in integers of greater
>>>> than 32 bits at
>>>>>>>>>> all. Judging from ?readBin, it should be possible to
>>>> read 8-byte
>>>>>>>>>> integers to some degree, but it is clearly limited in
>>>> practice by R's
>>>>>>>>>> internally 32-bit integer type:
>>>>>>>>>>
>>>>>>>>>>> x<- as.raw(c(0,0,0,0,1,0,0,0))
>>>>>>>>>>> (readBin(x,"integer",n=1,size=8,signed=F,endian="big"))
>>>>>>>>>> [1] 16777216
>>>>>>>>>>> x<- as.raw(c(0,0,0,1,0,0,0,0))
>>>>>>>>>>> (readBin(x,"integer",n=1,size=8,signed=F,endian="big"))
>>>>>>>>>> [1] 0
>>>>>>>>>>
>>>>>>>>>> For values that fit into 32 bits it works fine, but
>>>> for larger values
>>>>>>>>>> it fails. (I'm a bit surprised by the zero - should
>>>> the value not be
>>>>>>>>>> NA if it is out of range?
>>>>>>>>>
>>>>>>>>> No, it's not out of range - int is only 4 bytes so only
>>>> 4 first bytes (respecting endianness order, hence LSB) are used.
>>>>>>>>
>>>>>>>> The fact remains that I ask for the value of an 8-byte
>>>> integer and
>>>>>>>> don't get it.
>>>>>>>
>>>>>>> I think you're misinterpreting the documentation:
>>>>>>>
>>>>>>> ? ?If 'size' is specified and not the natural size of the object,
>>>>>>> ? ?each element of the vector is coerced to an appropriate type
>>>>>>> ? ?before being written or as it is read.
>>>>>>>
>>>>>>> The "integer" object type is defined as signed 32-bit in
>>>> R, so if you ask for "8 bytes into object type integer", you
>>>> get a coercion into that object type -- 32-bit signed integer
>>>> -- as documented. I think the issue may come from the
>>>> confusion of the object type "integer" with general "integer
>>>> number" in mathematical sense that has no representation
>>>> restrictions. (FWIW in C the "integer" type is "int" and it
>>>> is 32-bit on all modern OSes regardless of platform - that's
>>>> where the limitation comes from, it's not something R has made up).
>>>>>>
>>>>>> OK, but it still seems like there is a case for raising a
>>>> warning. As
>>>>>> it is there is no way to tell when reading an 8-byte integer from a
>>>>>> file whether its value is really 0, or if it merely has 0 in its
>>>>>> least-significant 4 bytes. If 99% of such stored numbers are below
>>>>>> 2^31, one is going to need some extra logic to catch the other 1%
>>>>>> where you (silently) get the wrong value. In essence, unless you're
>>>>>> certain that you will never come across a number that actually uses
>>>>>> the upper 4 bytes, you will always have to read it as two 4-byte
>>>>>> numbers and check that the high-order one (which is endianness
>>>>>> dependent, of course) is zero. A C-level sanity check seems more
>>>>>> efficient and more helpful to me.
>>>>>
>>>>> Seems to me that the S-PLUS solution (output="double")
>>>> would be a lot more useful. ?I'd commit that if you write it;
>>>> I don't think I'd commit the warning.
>>>>>
>>>>
>>>> I was going to write some thing similar (idea = good, patch
>>>> welcome ;)). My only worry is that the "output" argument is a
>>>> bit misleading in that one could expect to use any
>>>> combination of "input"/"output" which may be a maintenance
>>>> nightmare. If I understand it correctly it's only a special
>>>> case for integer input. I don't have S+ so can't say how they
>>>> deal with that.
>>>
>>> In S+'s readBin the output argument can be
>>> only double() or single() when what is double()
>>> or single() (S+ still ?has a real single
>>> precision storage mode) and can be any
>>> numeric type or logical when what is integer().
>>>
>>> The output=double() seemed like the only useful case.
>>>
>>> It does not warn when precision is lost in the 8-byte
>>> integer to double conversion. ?Perhaps it should.
>>>
>>> Bill Dunlap
>>> Spotfire, TIBCO Software
>>> wdunlap tibco.com
>>>
>>>>
>>>> Cheers,
>>>> Simon
>>>>
>>>>
>>>>>
>>>>>>
>>>>>>>> Pretending that it's really only four bytes because of
>>>>>>>> the limits of R's integer type isn't all that helpful. Perhaps a
>>>>>>>> warning should be put out if the cast will affect the
>>>> value of the
>>>>>>>> result? It looks like the relevant lines in
>>>> src/main/connections.c are
>>>>>>>> 3689-3697 in the current alpha:
>>>>>>>>
>>>>>>>> #if SIZEOF_LONG == 8
>>>>>>>> ? ? ? ? ? ? ? ? ?case sizeof(long):
>>>>>>>> ? ? ? ? ? ? ? ? ? ? ?INTEGER(ans)[i] = (int)*((long *)buf);
>>>>>>>> ? ? ? ? ? ? ? ? ? ? ?break;
>>>>>>>> #elif SIZEOF_LONG_LONG == 8
>>>>>>>> ? ? ? ? ? ? ? ? ?case sizeof(_lli_t):
>>>>>>>> ? ? ? ? ? ? ? ? ? ? ?INTEGER(ans)[i] = (int)*((_lli_t *)buf);
>>>>>>>> ? ? ? ? ? ? ? ? ? ? ?break;
>>>>>>>> #endif
>>>>>>>>
>>>>>>>>>> ) The value can be represented as a double,
>>>>>>>>>> though:
>>>>>>>>>>
>>>>>>>>>>> 4294967296
>>>>>>>>>> [1] 4294967296
>>>>>>>>>>
>>>>>>>>>> I wouldn't expect readBin() to return a double if an
>>>> integer was
>>>>>>>>>> requested, but is there any way to get the correct
>>>> value out of it?
>>>>>>>>>
>>>>>>>>> Trivially (for your unsigned big-endian case):
>>>>>>>>>
>>>>>>>>> y<- readBin(x, "integer", n=length(x)/4L, endian="big")
>>>>>>>>> y<- ifelse(y< ?0, 2^32 + y, y)
>>>>>>>>> i<- seq(1,length(y),2)
>>>>>>>>> y<- y[i] * 2^32 + y[i + 1L]
>>>>>>>>
>>>>>>>> Thanks for the code, but I'm not sure I would call that trivial,
>>>>>>>> especially if one needs to cater for little endian and
>>>> signed cases as
>>>>>>>> well!
>>>>>>>
>>>>>>> I was saying for your case and it's trivial as in read as
>>>> integers, convert to double precision and add.
>>>>>>>
>>>>>>>
>>>>>>>> This is what I meant by reconstructing the number manually...
>>>>>>>>
>>>>>>>
>>>>>>> You didn't say so - you were talking about reconstructing
>>>> it from a raw vector which seems a lot more painful since you
>>>> can't compute with enough precision on raw vectors.
>>>>>>
>>>>>> True - I should have been more specific. Sorry.
>>>>>>
>>>>>> Jon
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>>>
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From therneau at mayo.edu  Thu Mar 31 16:06:04 2011
From: therneau at mayo.edu (Terry Therneau)
Date: Thu, 31 Mar 2011 09:06:04 -0500
Subject: [Rd] drop.unused.levels
Message-ID: <201103311406.p2VE64R4016134@nemo.mayo.edu>

 A user sent me a query on survreg, which when boiled down is a request
to drop unused levels when setting up the X matrix.
 I don't have a strong opinion one way or the other, but am loath to
make the change: I expect that code somewhere will break, perhaps a lot,
when the length of the coefficients changes.

 On the other hand, at some point this change was made to lm().  Does
the R core have an opinion on which is better, or a pointer to
discussion that underlied the change to lm()?  It could be enough to
push me over the edge.  It would affect survreg, coxph, survfit,
survdiff, coxme, ...

Terry Therneau


From hadley at rice.edu  Thu Mar 31 17:30:13 2011
From: hadley at rice.edu (Hadley Wickham)
Date: Thu, 31 Mar 2011 10:30:13 -0500
Subject: [Rd] Bug in as.data.frame.POSIXct?
Message-ID: <AANLkTimtW4Tu-q06TYsh2NAUW_eiuVsnAY_xZUL5Gqgj@mail.gmail.com>

> a <- as.POSIXct(1:2, origin="2011-01-01")
> dim(a) <- c(1, 2)
> as.data.frame(a)
                    a
1 2011-01-01 00:00:01
2 2011-01-01 00:00:02
>
> dim(a) <- c(2, 1)
> as.data.frame(a)
                    a
1 2011-01-01 00:00:01
2 2011-01-01 00:00:02

I think this is because in as.data.frame.POSIXct we have

  nrows <- length(x)

instead of

  nrows <- NROW(x)

Hadley


-- 
Assistant Professor / Dobelman Family Junior Chair
Department of Statistics / Rice University
http://had.co.nz/


From dtenenba at fhcrc.org  Thu Mar 31 18:50:57 2011
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Thu, 31 Mar 2011 09:50:57 -0700
Subject: [Rd] typo/bug in R-Beta
Message-ID: <AANLkTinmG1s0_qzDvzfXkR=cypxpiT=v2QdFv7fvUU6E@mail.gmail.com>

In r55204
src/library/tools/R/install.R, line 338.

It says:

                             shQUote(file.path(lockdir, pkg))))

Should say:

                             shQuote(file.path(lockdir, pkg))))

Thanks
Dan


From dtenenba at fhcrc.org  Thu Mar 31 18:53:07 2011
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Thu, 31 Mar 2011 09:53:07 -0700
Subject: [Rd] typo/bug in R-Beta
In-Reply-To: <AANLkTinmG1s0_qzDvzfXkR=cypxpiT=v2QdFv7fvUU6E@mail.gmail.com>
References: <AANLkTinmG1s0_qzDvzfXkR=cypxpiT=v2QdFv7fvUU6E@mail.gmail.com>
Message-ID: <AANLkTimJD0HeQT0C=cenJOebft81y2WjdvD1Oc10UhjL@mail.gmail.com>

On Thu, Mar 31, 2011 at 9:50 AM, Dan Tenenbaum <dtenenba at fhcrc.org> wrote:
> In r55204
> src/library/tools/R/install.R, line 338.
>
> It says:
>
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? shQUote(file.path(lockdir, pkg))))
>
> Should say:
>
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? shQuote(file.path(lockdir, pkg))))
>
> Thanks
> Dan
>

Never mind, this was fixed in r55215. Thanks!
Dan


From pdalgd at gmail.com  Thu Mar 31 21:43:43 2011
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 31 Mar 2011 21:43:43 +0200
Subject: [Rd] SurviveGotoBLAS2 for Win64 (RC release)
In-Reply-To: <AANLkTimTBmFvG1H+b4PPg=qfAQ8GJFHyRfPOjjqx_=Wu@mail.gmail.com>
References: <AANLkTinYxjmGQvf-G8X1jBa3W7oF5N36d833jB6P7txz@mail.gmail.com>
	<AANLkTimTBmFvG1H+b4PPg=qfAQ8GJFHyRfPOjjqx_=Wu@mail.gmail.com>
Message-ID: <A7211836-7401-47D8-BE88-763DDA6A7538@gmail.com>


On Mar 30, 2011, at 06:28 , Ei-ji Nakama wrote:

> Hi,
> 
> I made the GotoBLAS2 for OSX version.
> two binaries are divided by kind of powerPC.
> neither binaries are different on Intel.
> because there is not PPC, I can't confirm it.
> 
> http://prs.ism.ac.jp/~nakama/SurviveGotoBLAS2/binary/OSX/


Thanks Ei-ji, 

Good to see that at least someone is doing business as usual in Japan these days.

Best,
Peter D.

> 
> 2011/2/10 Ei-ji Nakama <nakama at ki.rim.or.jp>:
>> Hi,
>> 
>> I put below Rblas.dll(GotoBLAS2 for Win64).
>> http://prs.ism.ac.jp/~nakama/SurviveGotoBLAS2/binary/windows/x64/
>> please choose the core-name of your CPU.
>> The recognition of the CPU of DYNAMIC_ARCH is low.
>> 
>> zdot[cu], zgemv came to calculate definitely.
>> 
>> --
>> EI-JI Nakama  <nakama (a) ki.rim.or.jp>
>> "\u4e2d\u9593\u6804\u6cbb"  <nakama (a) ki.rim.or.jp>
>> 
> 
> --
> EI-JI Nakama  <nakama (a) ki.rim.or.jp>
> "\u4e2d\u9593\u6804\u6cbb"  <nakama (a) ki.rim.or.jp>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dtenenba at fhcrc.org  Thu Mar 31 23:01:49 2011
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Thu, 31 Mar 2011 14:01:49 -0700
Subject: [Rd] Problem running "make bitmapdll" with R-2.13 beta r55221 on
	Windows
Message-ID: <AANLkTikhCWOR7d0PLjUF2PkqsST9wjnaB8D+py0oF4aA@mail.gmail.com>

Hello,

I am building R r55221 according to
http://cran.r-project.org/doc/manuals/R-admin.html#Building-from-source

After I have done "make all && make recommended", "make bitmapdll"
returns the following:

E:\sandbox\R-2.13.r55221\src\gnuwin32>make bitmapdll
make[1]: Entering directory
`/cygdrive/e/sandbox/R-2.13.r55221/src/gnuwin32/bitmap'
make CC='gcc -std=gnu99' AR='ar' AR_RC='ar rcs' \
  CFLAGS="-O3 -I../../../extra/zlib -DPNG_NO_MMX_CODE" \
  RANLIB=ranlib ZLIBLIB=../../../extra/zlib -C libpng \
  -f scripts/makefile.gcc prefix=foo libpng.a
gcc -std=gnu99 -c -O3 -I../../../extra/zlib -DPNG_NO_MMX_CODE -I../zlib png.c
gcc -std=gnu99 -c -O3 -I../../../extra/zlib -DPNG_NO_MMX_CODE
-I../zlib pngerror.c
gcc -std=gnu99 -c -O3 -I../../../extra/zlib -DPNG_NO_MMX_CODE -I../zlib pngget.c
gcc -std=gnu99 -c -O3 -I../../../extra/zlib -DPNG_NO_MMX_CODE -I../zlib pngmem.c
gcc -std=gnu99 -c -O3 -I../../../extra/zlib -DPNG_NO_MMX_CODE
-I../zlib pngpread.c
gcc -std=gnu99 -c -O3 -I../../../extra/zlib -DPNG_NO_MMX_CODE
-I../zlib pngread.c
gcc -std=gnu99 -c -O3 -I../../../extra/zlib -DPNG_NO_MMX_CODE -I../zlib pngrio.c
gcc -std=gnu99 -c -O3 -I../../../extra/zlib -DPNG_NO_MMX_CODE
-I../zlib pngrtran.c
gcc -std=gnu99 -c -O3 -I../../../extra/zlib -DPNG_NO_MMX_CODE
-I../zlib pngrutil.c
gcc -std=gnu99 -c -O3 -I../../../extra/zlib -DPNG_NO_MMX_CODE -I../zlib pngset.c
gcc -std=gnu99 -c -O3 -I../../../extra/zlib -DPNG_NO_MMX_CODE
-I../zlib pngtrans.c
gcc -std=gnu99 -c -O3 -I../../../extra/zlib -DPNG_NO_MMX_CODE -I../zlib pngwio.c
gcc -std=gnu99 -c -O3 -I../../../extra/zlib -DPNG_NO_MMX_CODE
-I../zlib pngwrite.c
gcc -std=gnu99 -c -O3 -I../../../extra/zlib -DPNG_NO_MMX_CODE
-I../zlib pngwtran.c
gcc -std=gnu99 -c -O3 -I../../../extra/zlib -DPNG_NO_MMX_CODE
-I../zlib pngwutil.c
ar rcs libpng.a png.o pngerror.o pngget.o pngmem.o pngpread.o
pngread.o pngrio.o pngrtran.
o pngrutil.o pngset.o pngtrans.o pngwio.o pngwrite.o pngwtran.o pngwutil.o
ranlib libpng.a
cp jconfig.h jpeg-8c/jconfig.h
cp: cannot create regular file `jpeg-8c/jconfig.h': No such file or directory
make[2]: *** [jpeg-8c/jconfig.h] Error 1
make[1]: *** [all] Error 2
make[1]: Leaving directory
`/cygdrive/e/sandbox/R-2.13.r55221/src/gnuwin32/bitmap'
make: *** [bitmapdll] Error 2

Thanks
Dan


