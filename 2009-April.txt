From weigand.stephen at gmail.com  Wed Apr  1 01:33:05 2009
From: weigand.stephen at gmail.com (Stephen Weigand)
Date: Tue, 31 Mar 2009 18:33:05 -0500
Subject: [Rd] 'sep' argument in reshape()
Message-ID: <bc47d3330903311633m6e90c73dn32b48d7e984276d4@mail.gmail.com>

I wonder if the 'sep' argument in reshape() is being ignored
unintentionally:

## From example(reshape)
 df <- data.frame(id=rep(1:4,rep(2,4)),
                  visit=I(rep(c("Before","After"),4)),
                  x=rnorm(4), y=runif(4))

reshape(df, timevar="visit", idvar="id", direction="wide", sep = "_")

  id x.Before y.Before x.After y.After
1  1    0.773    0.293  -0.021   0.658
3  2   -0.518    0.351  -0.623   0.946
5  3    0.773    0.293  -0.021   0.658
7  4   -0.518    0.351  -0.623   0.946

Is this more of the intended result when 'sep = "_"'?

  id x_Before y_Before x_After y_After
1  1    0.773    0.293  -0.021   0.658
3  2   -0.518    0.351  -0.623   0.946
5  3    0.773    0.293  -0.021   0.658
7  4   -0.518    0.351  -0.623   0.946

Thanks,

Stephen
-- 
Rochester, Minn. USA


From simon.urbanek at r-project.org  Wed Apr  1 02:57:35 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 31 Mar 2009 20:57:35 -0400
Subject: [Rd] Compile R Library with GCC garbage collection on or
	supported
In-Reply-To: <a5fee3720903311225k3446b8a3t5f8dd8fcb9da247d@mail.gmail.com>
References: <a5fee3720903311225k3446b8a3t5f8dd8fcb9da247d@mail.gmail.com>
Message-ID: <EA5303BB-E8A8-4914-92AF-BDBF811FCFA0@r-project.org>


On Mar 31, 2009, at 3:25 PM, David Zwerdling wrote:

> Hi All,
> I'm not that familiar with configure or make (more of a Java  
> developer as a
> dayjob) but I was wondering what the process would be to add the flag
> -fobjc-gcc in the compilation of the R library for use in an  
> Objective-C
> application.  Can one simply drop this into the configure file  
> somewhere?

First, I think you mean -fobjc-gc. Second, I'm not sure why you think  
it's needed, because R doesn't use any Obj-C itself so it won't have  
any effect on the R library at all. Only your application needs to use  
it if it wishes to use the gc. Finally, you can always add flags via  
the usual environment variables for example OBJCFLAGS (see B.3 in R- 
admin and ./configure --help).

Cheers,
Simon


From jafa82 at gmail.com  Wed Apr  1 04:50:08 2009
From: jafa82 at gmail.com (Eric)
Date: Tue, 31 Mar 2009 22:50:08 -0400
Subject: [Rd] R in standalone application
Message-ID: <49D2D660.8040708@hotmail.com>

I am trying to build a C application where I need to compute some 
statistics to take decisions about the direction to give to a user, 
knowing his/her habits. Because I used R back at school, I thought I can 
use some of his functions in my application,  as a shared library. I 
reviewed the "Rinternals" and "R extensions"  documents, and decided to 
give a try to the REmbedded.c file. Compilation and linking went well. 
But the execution failed with a "Fatal error: R home directory is not 
defined". Does it mean that R has to to be distributed with my 
application or, did I miss something in my readings ? If that is of any 
importance, I am working on unix but aim for full portability (i.e 
Windows too)

Thanks for any assistance.


From saptarshi.guha at gmail.com  Wed Apr  1 07:55:05 2009
From: saptarshi.guha at gmail.com (Saptarshi Guha)
Date: Wed, 1 Apr 2009 01:55:05 -0400
Subject: [Rd] Creating a VECSXP when n is unknown(using Linked list)
Message-ID: <1e7471d50903312255v477f8bf3t84886ad3941acb5@mail.gmail.com>

Hello,
I need to create a VECSXP(A) each element of which is a 2-element
VECSXP. Since I dont know
how many elements there will be i create a linked list of 2-element
VECSXP (see code at end)

Once I know the number of elements, i then go ahead allocVector A and
then SET_VECTOR_ELEMENT the
elements of A by iterating over the linked list.

Suppose the function is f(), then it works a couple of times but
crashes ( in different ways)
after that.
e.g
  for(x in 1:10){
    f(x)
      }
Then this crashes after a few iterations. If I were to perform just
one call, e.g u=f(x[1]),
i get a valid results.
Where am I going wrong? I must admit my C experience is very rough.


Thank you in advance
Saptarshi

  ==code==
struct ll_element {
    SEXP k,v;
    struct ll_element * next;
};
struct ll_element *elem,*head;
head=NULL;
unsigned long countofelems=0;
while(1){
    nextKV(jo,&val,&data,&len,&err);
    if(err && err!=2 ) {
      error("Problem reading:%d",err);
      return(R_NilValue);
    }
    if(err==2) {
      //Indicates no more values, we have all the elements we need
      //exit and make VECSXP
      break;
    }
    SEXP vxp;
    int Rerr;
    elem = (struct ll_element *)R_alloc(1,sizeof(struct ll_element));
    PROTECT(elem->k = NEW_NUMERIC(1));
    REAL(elem->k)[0]=(double)val;

    vxp = allocVector(RAWSXP,len);
    memcpy(RAW(vxp), data, sizeof(jbyte)*len);
    free(data);

    PROTECT(elem->v = R_tryEval(LCONS(install("unserialize"),CONS(vxp,
R_NilValue)), R_GlobalEnv, &Rerr));
    if(Rerr!=0){
      UNPROTECT(2);
      error("Could not unserialize");
      return(R_NilValue);
    }
    UNPROTECT(2);
    countofelems+=1;
    elem->next=head;
    head=elem;
  }
  struct ll_element *ce;
  SEXP rv;
  int k=0;
  ce=head;
  PROTECT(rv= allocVector(VECSXP, countofelems));
  while(ce){
    SEXP y ;
    PROTECT(y=allocVector(VECSXP,2));
    SET_VECTOR_ELT(y,0,ce->k);
    SET_VECTOR_ELT(y,1,ce->v);
    SET_VECTOR_ELT(rv,k,y);
    k+=1;
    ce=ce->next;
    UNPROTECT(1);
  }
  UNPROTECT(1);
  return(rv);


From maechler at stat.math.ethz.ch  Wed Apr  1 08:51:30 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 1 Apr 2009 08:51:30 +0200
Subject: [Rd] duplicated.data.frame {was "[R] which rows are
	duplicates?"}
In-Reply-To: <49D275FC.9000204@idi.ntnu.no>
References: <0F1D79E9-7146-48FB-95E9-3CD95DBD18E8@gmail.com>
	<Zen-1LoF5b-0003BD-Rf@smarthost01.mail.zen.net.uk>
	<49D0BA70.3090005@idi.ntnu.no>
	<18898.6300.26434.413865@lynne.math.ethz.ch>
	<49D222A0.7020601@idi.ntnu.no>
	<18898.15610.610205.300523@lynne.math.ethz.ch>
	<49D275FC.9000204@idi.ntnu.no>
Message-ID: <18899.3826.723018.652559@lynne.math.ethz.ch>

>>>>> "WK" == Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no>
>>>>>     on Tue, 31 Mar 2009 21:58:52 +0200 writes:

    WK> Martin Maechler wrote:
    >> 
    >> >> 
    >> >> and then be helpful to the R community and send a bug report
    >> >> *with* a patch if {as in this case} you are able to...
    >> >> 
    >> >> Well, that' no longer needed here,
    >> >> I'll fix that easily myself.
    >> >> 
    >> 
    WK> but i *have* sent a patch already!
    >> 
    >> Ok, I believe you.  But I think you did not mention that during
    >> this thread, ... and/or I must have overlooked your patch.
    >> 
    >> In any case the problem is now solved
    >> [well, a better solution of course would add the "not-yet"
    >> functionality..]; 
    >> thank you for the contribution.
    >> 

    WK> i attach the patch post for reference.  note that you need to fix all of
    WK> the functions in duplicated.R that share the buggy code.  (yes, this was
    WK> another thread;  i submitted a bug report, and then sent a follow-up
    WK> post with a patch).

Thank you; yes, in the mean time I have also seen your bug
report and patch.  
Interestingly (or not), I have myself patched identically to
what you propose, withOUT even having known about your bug report + patch.
....

{ hmmm, it seems your thinking can be very close to mine, so why
  can't you like R properly  ;-b }

Martin


From maechler at stat.math.ethz.ch  Wed Apr  1 09:32:41 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 1 Apr 2009 09:32:41 +0200
Subject: [Rd] 'sep' argument in reshape()
In-Reply-To: <bc47d3330903311633m6e90c73dn32b48d7e984276d4@mail.gmail.com>
References: <bc47d3330903311633m6e90c73dn32b48d7e984276d4@mail.gmail.com>
Message-ID: <18899.6297.627838.913631@lynne.math.ethz.ch>

>>>>> "SW" == Stephen Weigand <weigand.stephen at gmail.com>
>>>>>     on Tue, 31 Mar 2009 18:33:05 -0500 writes:

    SW> I wonder if the 'sep' argument in reshape() is being ignored
    SW> unintentionally:

No.  It is used much differently than you *assume* it's used.

As always,   ?reshape   contains the answer.


    SW> ## From example(reshape)
    SW> df <- data.frame(id=rep(1:4,rep(2,4)),
    SW> visit=I(rep(c("Before","After"),4)),
    SW> x=rnorm(4), y=runif(4))

    SW> reshape(df, timevar="visit", idvar="id", direction="wide", sep = "_")

    SW> id x.Before y.Before x.After y.After
    SW> 1  1    0.773    0.293  -0.021   0.658
    SW> 3  2   -0.518    0.351  -0.623   0.946
    SW> 5  3    0.773    0.293  -0.021   0.658
    SW> 7  4   -0.518    0.351  -0.623   0.946

    SW> Is this more of the intended result when 'sep = "_"'?

    SW> id x_Before y_Before x_After y_After
    SW> 1  1    0.773    0.293  -0.021   0.658
    SW> 3  2   -0.518    0.351  -0.623   0.946
    SW> 5  3    0.773    0.293  -0.021   0.658
    SW> 7  4   -0.518    0.351  -0.623   0.946

no it is not.

I tend to agree that I would have preferred a different argument
name than 'sep' for the current 'sep',
and then a *further* argument 'sep' with the functionality that
you'd like would be straightforward.

Martin Maechler, ETH Zurich


From maechler at stat.math.ethz.ch  Wed Apr  1 09:36:07 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 1 Apr 2009 09:36:07 +0200
Subject: [Rd] Gamma funtion(s) bug
In-Reply-To: <loom.20090331T150244-162@post.gmane.org>
References: <49D12D9F.1000203@stats.uwo.ca>
	<XFMail.090330222854.Ted.Harding@manchester.ac.uk>
	<18897.49007.275534.467989@lynne.math.ethz.ch>
	<loom.20090331T150244-162@post.gmane.org>
Message-ID: <18899.6503.896682.355534@lynne.math.ethz.ch>

>>>>> "BB" == Ben Bolker <bolker at ufl.edu>
>>>>>     on Tue, 31 Mar 2009 15:08:45 +0000 (UTC) writes:

    BB> Martin Maechler <maechler <at> stat.math.ethz.ch> writes:
    >> >> But lgamma(x) is log(abs(gamma(x))), so it looks okay to me.
    >> >> 
    >> >> Duncan Murdoch
    >> 
    TH> Oops, yes! That's what comes of talking off the top of my head
    TH> (I don't think I've ever had occasion to evaluate lgamma(x)
    TH> for negative x, so never consciously checked in ?lgamma).
    >> 
    TH> Thanks, Duncan!
    >> 
    >> Indeed.... as we all know, a picture can be worth a thousand words,
    >> and a simple R call such as
    >> plot(lgamma, -7, 0, n=1000)
    >> would have saved many words, and notably spared us from
    >> yet-another erroneous non-bug report.
    >> 
    >> Martin

    BB> In Kjetil's defense, he didn't submit an actual bug report --
    BB> and although his subject line does contain the word "bug",
    BB> I read his "bug report" as asking a question.  

    BB> People are allowed to make mistakes ...

definitely! We all are.

Using 'bug' (without any qualifying "?" or "possible" ..) 
in the subject line is still a bit unfriendly...

    BB> While I was reading ?lgamma I noticed that the "See Also"
    BB> section refers to gammaCody(), which is now defunct.  Perhaps
    BB> remove the sentence?

Yes. Thank you, Ben!
Regards, Martin Maechler

    BB> Ben Bolker


From tlumley at u.washington.edu  Wed Apr  1 10:00:13 2009
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 1 Apr 2009 01:00:13 -0700 (PDT)
Subject: [Rd] 'sep' argument in reshape()
In-Reply-To: <bc47d3330903311633m6e90c73dn32b48d7e984276d4@mail.gmail.com>
Message-ID: <Pine.LNX.4.43.0904010100130.1167@hymn11.u.washington.edu>

On Tue, 31 Mar 2009, Stephen Weigand wrote:

> I wonder if the 'sep' argument in reshape() is being ignored
> unintentionally:
>
> ## From example(reshape)
> df <- data.frame(id=rep(1:4,rep(2,4)),
>                  visit=I(rep(c("Before","After"),4)),
>                  x=rnorm(4), y=runif(4))
>
> reshape(df, timevar="visit", idvar="id", direction="wide", sep = "_")
>
>  id x.Before y.Before x.After y.After
> 1  1    0.773    0.293  -0.021   0.658
> 3  2   -0.518    0.351  -0.623   0.946
> 5  3    0.773    0.293  -0.021   0.658
> 7  4   -0.518    0.351  -0.623   0.946
>
> Is this more of the intended result when 'sep = "_"'?

No. sep= is designed for going the other way.  If you have wide-format data with variable names x.Before y.Before x.After y.After, using sep="." will let reshape() work out that the long-format variable names are x and y and the conditions to be put in the time variable are Before and After.

    -thomas


Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From maechler at stat.math.ethz.ch  Wed Apr  1 10:09:33 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 1 Apr 2009 10:09:33 +0200
Subject: [Rd] [R] variance/mean
In-Reply-To: <49C81DCE.1030901@idi.ntnu.no>
References: <20090322041729.6LTZR.3025252.root@mp11>
	<49C601BD.3080506@idi.ntnu.no>
	<001201c9abd1$4e04c5e0$3a0b2c0a@gne.windows.gene.com>
	<49C81DCE.1030901@idi.ntnu.no>
Message-ID: <18899.8509.745114.348086@lynne.math.ethz.ch>

>>>>> Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no>
>>>>>     on Tue, 24 Mar 2009 00:39:58 +0100 writes:

    > (this post suggests a patch to the sources, so i allow myself to divert
    > it to r-devel)

    > Bert Gunter wrote:
    >> x a numeric vector, matrix or data frame. 
    >> y NULL (default) or a vector, matrix or data frame with compatible
    >> dimensions to x. The default is equivalent to y = x (but more efficient). 
    >> 
    >> 
    > bert points to an interesting fragment of ?var:  it suggests that
    > computing var(x) is more efficient than computing var(x,x), for any x
    > valid as input to var.  indeed:

    > set.seed(0)
    > x = matrix(rnorm(10000), 100, 100)

    > library(rbenchmark)
    > benchmark(replications=1000, columns=c('test', 'elapsed'),
    > var(x),
    > var(x, x))
    > #        test elapsed
    > # 1    var(x)   1.091
    > # 2 var(x, x)   2.051

    > that's of course, so to speak, unreasonable:  for what var(x) does is
    > actually computing the covariance of x and x, which should be the same
    > as var(x,x). 

    > the hack is that if y is given, there's an overhead of memory allocation
    > for *both* x and y when y is given, as seen in src/main/cov.c:720+.
    > incidentally, it seems that the problem can be solved with a trivial fix
    > (see the attached patch), so that

    > set.seed(0)
    > x = matrix(rnorm(10000), 100, 100)

    > library(rbenchmark)
    > benchmark(replications=1000, columns=c('test', 'elapsed'),
    > var(x),
    > var(x, x))
    > #        test elapsed
    > # 1    var(x)   1.121
    > # 2 var(x, x)   1.107

    > with the quick checks

    > all.equal(var(x), var(x, x))
    > # TRUE
   
    > all(var(x) == var(x, x))
    > # TRUE

    > and for cor it seems to make cor(x,x) slightly faster than cor(x), while
    > originally it was twice slower:

    > # original
    > benchmark(replications=1000, columns=c('test', 'elapsed'),
    > cor(x),
    > cor(x, x))
    > #        test elapsed
    > # 1    cor(x)   1.196
    > # 2 cor(x, x)   2.253
   
    > # patched
    > benchmark(replications=1000, columns=c('test', 'elapsed'),
    > cor(x),
    > cor(x, x))
    > #        test elapsed
    > # 1    cor(x)   1.207
    > # 2 cor(x, x)   1.204

    > (there is a visible penalty due to an additional pointer test, but it's
    > 10ms on 1000 replications with 10000 data points, which i think is
    > negligible.)

    >> This is as clear as I would know how to state. 

    > i believe bert is right.

    > however, with the above fix, this can now be rewritten as:

    > "
    > x: a numeric vector, matrix or data frame. 
    > y: a vector, matrix or data frame with dimensions compatible to those of x. 
    > By default, y = x. 
    > "

    > which, to my simple mind, is even more clear than what bert would know
    > how to state, and less likely to cause the sort of confusion that
    > originated this thread.

Your patch is basically only affecting the default  
method = "pearson". For (most) other cases, 'y = NULL' would
still remain  *the* way to save computations, unless we'd start
to use an R-level equivalent [which I think does not exist] of
your C  trick   (DATAPTR(x) == DATAPTR(y)).

Also, for S- and R- backcompatibility reasons, we'd need to
continue allowing  y = NULL (as your patch would, too), so
currently I think this whole idea -- as slick as it is, I
learned something!  --  
does not make sense applying here.

    > the attached patch suggests modifications to src/main/cov.c and
    > src/library/stats/man/cor.Rd.

BTW: since you didn't (and shouldn't , because of method != "pearson" !) 
 change the R code, the docs  \usage{.} part should not have been
 changed either ! 
 and as I mentioned: using 'y = NULL' in the function call must
 continue to work, hence should also be documented as
 possibility
 ==>  the docs would not really become more clear, I think 

Martin Maechler, ETH Zurich



    > it has been prepared and checked as follows:

    > svn co https://svn.r-project.org/R/trunk trunk
    > cd trunk
    > # edited the sources
    > svn diff > cov.diff
    > svn revert -R src
    > patch -p0 < cov.diff

    > tools/rsync-recommended
    > ./configure
    > make
    > make check
    > bin/R
    > # subsequent testing within R

    > if you happen to consider this patch for a commit, please be sure to
    > examine and test it carefully first.

    > vQ
    > Content-Type: text/x-diff; name="cov.diff"
    > Content-Disposition: inline; filename="cov.diff"
    > Content-ID: <18899.7024.520234.153929 at lynne.math.ethz.ch>
    > Content-Transfer-Encoding: binary

    > [Deleted text/x-diff]

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Wed Apr  1 10:20:27 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Wed, 01 Apr 2009 10:20:27 +0200
Subject: [Rd] duplicated.data.frame {was "[R] which rows are
	duplicates?"}
In-Reply-To: <18899.3826.723018.652559@lynne.math.ethz.ch>
References: <0F1D79E9-7146-48FB-95E9-3CD95DBD18E8@gmail.com>	<Zen-1LoF5b-0003BD-Rf@smarthost01.mail.zen.net.uk>	<49D0BA70.3090005@idi.ntnu.no>	<18898.6300.26434.413865@lynne.math.ethz.ch>	<49D222A0.7020601@idi.ntnu.no>	<18898.15610.610205.300523@lynne.math.ethz.ch>	<49D275FC.9000204@idi.ntnu.no>
	<18899.3826.723018.652559@lynne.math.ethz.ch>
Message-ID: <49D323CB.1070005@idi.ntnu.no>

Martin Maechler wrote:
>
>     WK> i attach the patch post for reference.  note that you need to fix all of
>     WK> the functions in duplicated.R that share the buggy code.  (yes, this was
>     WK> another thread;  i submitted a bug report, and then sent a follow-up
>     WK> post with a patch).
>
> Thank you; yes, in the mean time I have also seen your bug
> report and patch.  
> Interestingly (or not), I have myself patched identically to
> what you propose, withOUT even having known about your bug report + patch.
>   

this means, the solution has greater chances to be correct.

> ....
>
> { hmmm, it seems your thinking can be very close to mine, so why
>   can't you like R properly  ;-b }
>   

actually, i think i *do* like r properly.

vQ


From peter.ruckdeschel at web.de  Wed Apr  1 10:21:07 2009
From: peter.ruckdeschel at web.de (Peter Ruckdeschel)
Date: Wed, 01 Apr 2009 10:21:07 +0200
Subject: [Rd] Wishlist: optional svn-revision number tag in package
 DESCRIPTION file
In-Reply-To: <18898.20780.532565.750117@ron.nulle.part>
References: <gqta20$7ua$1@ger.gmane.org>	<49D24BAF.7060405@stats.uwo.ca>
	<18898.20780.532565.750117@ron.nulle.part>
Message-ID: <49D323F3.4030505@web.de>

Thanks Gabor, Duncan, and Dirk,

for your replies.

Gabor Grothendieck wrote:
> We need to make sure we understand the implications
> for packages developed under the other major version
> control systems like git, bzr and hg.

Ok for this --- of course it would even be "greater" to have
a universal replacement scheme for general version control
systems in R for DESCRIPTION files, but actually for the moment
I would already be content with some R tools (possibly a collection
of them) for each version control system individually.

> On 31 March 2009 at 12:58, Duncan Murdoch wrote:
> | On 3/31/2009 10:41 AM, Peter Ruckdeschel wrote:
> | > Could we have one (or maybe more) standardized optional tag(s)
> | > for package DESCRIPTION files to cover svn revision info?
> | > This would be very useful for bug reporting...
> 
> Indeed. I am doing something similar with local packages at work.
> 
> | > I know that any developer is already free to append corresponding lines
> | > to DESCRIPTION files to do something of this sort --- e.g. lines like
> | > 
> | > LastChangedDate: {$LastChangedDate: 2009-03-31 $}
> | > LastChangedRevision: {$LastChangedRevision: 447 $}
> | 
> | That will give you the last change to the DESCRIPTION file, not the last 
> | change to the package, so it could be misleading.  Last time I looked, 
> | there wasn't a way in svn to auto update a file that wasn't involved in 
> | a changeset.  

Ouch. I stand corrected; and I have to say: this even is an FAQ
in the SVN documentation... So using svn properties will not work indeed.

Still, my wish for a better integration of version control
information into R persists...

So if I understand correctly, under linux / cygwin (Mac I don't know)
you would use some scripting to read out the output of svnversion;
let me add that under Windows + Tortoise SVN you would have
SubWCRev (http://tortoisesvn.tigris.org/faq.html#subwcrev) to help you.

> (You could put something into your build script to call 
> | svnversion, but I don't know anything simpler.)
> 
> Yes, I have been using configure for that (which can be really any type of
> executable script rather than something from autoconf). One can then either
> update a placeholder in DESCRIPTION.in to substitute the revision number
> and/or create a package-local function reporting svn revision, build time,
> etc.  
> 
> It may make sense to think about a more general scheme. A common problem is
> of course once again portability and the set of required tools.

If we are talking about R functions for reporting version control
information --- what about the following scheme:
-have some version control system individual functions (one for svn, one
 for git and so on)
-have some S4 control class for each of these version control systems
-have an S4 generic VCinfo() which dispatches according to an argument
VCsystem of this control class

This would give some additional flexibility to integrate infra-structure
for new version control systems ---even by other programmers--- without
interfering with the generic.

For the scripting approach --- what about some extra options for
   R CMD build
for instance --withSVN or --withTortoiseSVN ?

Thanks again for your comments --- and apologies for my wrong idea
using svn properties.

Best, Peter


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Wed Apr  1 10:39:53 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Wed, 01 Apr 2009 10:39:53 +0200
Subject: [Rd] [R] variance/mean
In-Reply-To: <18899.8509.745114.348086@lynne.math.ethz.ch>
References: <20090322041729.6LTZR.3025252.root@mp11>	<49C601BD.3080506@idi.ntnu.no>	<001201c9abd1$4e04c5e0$3a0b2c0a@gne.windows.gene.com>	<49C81DCE.1030901@idi.ntnu.no>
	<18899.8509.745114.348086@lynne.math.ethz.ch>
Message-ID: <49D32859.4050206@idi.ntnu.no>

Martin Maechler wrote:
>
> Your patch is basically only affecting the default  
> method = "pearson". For (most) other cases, 'y = NULL' would
> still remain  *the* way to save computations, unless we'd start
> to use an R-level equivalent [which I think does not exist] of
> your C  trick   (DATAPTR(x) == DATAPTR(y)).
>
>   

yes, my patch was constrained to the c code, but i don't think it would
be particularly difficult to fix the relevant r-level code as well.  i
did think about it, but didn't want to invest more time in this until
(or unless) someone would respond.  (thanks for the response.)

> Also, for S- and R- backcompatibility reasons, we'd need to
> continue allowing  y = NULL (as your patch would, too), 

only in its current for -- indeed, the (unimplemented) intention was to
detach from the old misdesign, and fix everything so that y=x by default
anywhere.

> so
> currently I think this whole idea -- as slick as it is, I
> learned something!  --  
> does not make sense applying here.
>   

i think it does, because the current state is somewhat funny, including
both the difference in performance between var(x) and var(x,x) (with x
being a matrix), and the respective comment in ?var.

>     > the attached patch suggests modifications to src/main/cov.c and
>     > src/library/stats/man/cor.Rd.
>
> BTW: since you didn't (and shouldn't , because of method != "pearson" !) 
>  change the R code, 

i would suggest it be done, though.

> the docs  \usage{.} part should not have been
>  changed either ! 
>   

indeed, the change in the docs didn't match what i *have* actually fixed
in the code.

>  and as I mentioned: using 'y = NULL' in the function call must
>   

*MUST* ?

>  continue to work, hence should also be documented as
>  possibility
>  ==>  the docs would not really become more clear, I think 
>   

no, of course, without the change in r code having the docs say y=x by
default would be a nonsense.  but again, this was a start, not a
complete modification (and i admit i failed to acknowledge this).

vQ


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Wed Apr  1 10:57:20 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Wed, 01 Apr 2009 10:57:20 +0200
Subject: [Rd] Gamma funtion(s) bug
In-Reply-To: <18899.6503.896682.355534@lynne.math.ethz.ch>
References: <49D12D9F.1000203@stats.uwo.ca>	<XFMail.090330222854.Ted.Harding@manchester.ac.uk>	<18897.49007.275534.467989@lynne.math.ethz.ch>	<loom.20090331T150244-162@post.gmane.org>
	<18899.6503.896682.355534@lynne.math.ethz.ch>
Message-ID: <49D32C70.7030005@idi.ntnu.no>

Martin Maechler wrote:
>
> Using 'bug' (without any qualifying "?" or "possible" ..) 
> in the subject line is still a bit unfriendly...
>   


is suggesting that a poster includes 'excel bug' in the subject line [1]
friendly??

vQ



[1] https://stat.ethz.ch/pipermail/r-help/2009-March/190119.html


From pingou at pingoured.fr  Wed Apr  1 10:58:52 2009
From: pingou at pingoured.fr (Pierre-Yves)
Date: Wed, 01 Apr 2009 10:58:52 +0200
Subject: [Rd] License question (RUnit)
Message-ID: <1238576332.4587.16.camel@localhost.localdomain>

Dear list,

Sorry for the noise but I have a question regarding the license used in
RUnit [1], I contacted the maintainer( burgerm -at- users -dot-
sourceforge -dot- net ) on March 20th but I have received no answer.

Could anyone help to solve this question ?

Basically, my problem is that the website and the DESCRIPTION file say
that the license is GPLv2 while the header in the code says it is GPLv2
or any later version.

Thanks in advance for your help,

Best regards,

Pierre

[1] http://cran.r-project.org/web/packages/RUnit/index.html


From ritz at life.ku.dk  Wed Apr  1 12:20:25 2009
From: ritz at life.ku.dk (Christian Ritz)
Date: Wed, 01 Apr 2009 12:20:25 +0200
Subject: [Rd] Typo in the documentation of model.extract()?
Message-ID: <49D33FE9.5060803@life.ku.dk>

Hi,

it seems that there is a minor typo in the last line of the "Details" section.

Shouldn't "model.frame" be "model.extract" in the sentence


"model.weights is slightly different from model.frame(, "weights") in not naming the
vector it returns."


?


Christian


From tlumley at u.washington.edu  Wed Apr  1 14:08:14 2009
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 1 Apr 2009 05:08:14 -0700 (PDT)
Subject: [Rd] Possible bug in summary.survfit - 'scale' argument ignored?
In-Reply-To: <D9757384-E63D-462A-8FBE-A30B3C533310@me.com>
Message-ID: <Pine.LNX.4.43.0904010508140.29619@hymn14.u.washington.edu>


I've sent a fixed version 2.35-4 to CRAN.  It turned out to be a fairly simple change.

     -thomas


On Tue, 31 Mar 2009, Marc Schwartz wrote:

> On Mar 30, 2009, at 5:55 PM, Marc Schwartz wrote:
>
>> Hi all,
>> 
>> Using:
>> 
>>  R version 2.8.1 Patched (2009-03-07 r48068)
>> 
>> on OSX (10.5.6) with survival version:
>> 
>>  Version:            2.35-3
>>  Date:               2009-02-10
>> 
>> 
>> I get the following using the first example in ?summary.survfit:
>> 
>> > summary( survfit( Surv(futime, fustat)~1, data=ovarian))
>> Call: survfit(formula = Surv(futime, fustat) ~ 1, data = ovarian)
>> 
>> time n.risk n.event survival std.err lower 95% CI upper 95% CI
>>   59     26       1    0.962  0.0377        0.890        1.000
>>  115     25       1    0.923  0.0523        0.826        1.000
>>  156     24       1    0.885  0.0627        0.770        1.000
>>  268     23       1    0.846  0.0708        0.718        0.997
>>  329     22       1    0.808  0.0773        0.670        0.974
>>  353     21       1    0.769  0.0826        0.623        0.949
>>  365     20       1    0.731  0.0870        0.579        0.923
>>  431     17       1    0.688  0.0919        0.529        0.894
>>  464     15       1    0.642  0.0965        0.478        0.862
>>  475     14       1    0.596  0.0999        0.429        0.828
>>  563     12       1    0.546  0.1032        0.377        0.791
>>  638     11       1    0.497  0.1051        0.328        0.752
>> 
>> 
>> > summary( survfit( Surv(futime, fustat)~1, data=ovarian), scale = 365.25)
>> Call: survfit(formula = Surv(futime, fustat) ~ 1, data = ovarian)
>> 
>> time n.risk n.event survival std.err lower 95% CI upper 95% CI
>>   59     26       1    0.962  0.0377        0.890        1.000
>>  115     25       1    0.923  0.0523        0.826        1.000
>>  156     24       1    0.885  0.0627        0.770        1.000
>>  268     23       1    0.846  0.0708        0.718        0.997
>>  329     22       1    0.808  0.0773        0.670        0.974
>>  353     21       1    0.769  0.0826        0.623        0.949
>>  365     20       1    0.731  0.0870        0.579        0.923
>>  431     17       1    0.688  0.0919        0.529        0.894
>>  464     15       1    0.642  0.0965        0.478        0.862
>>  475     14       1    0.596  0.0999        0.429        0.828
>>  563     12       1    0.546  0.1032        0.377        0.791
>>  638     11       1    0.497  0.1051        0.328        0.752
>> 
>> Of course the time periods in the second output should be scaled to years, 
>> that is (time / 365.25).
>> 
>> I noted this today running some Sweave code, but not sure when the actual 
>> change in behavior occurred.  I can replicate the same behavior on a Windows 
>> machine here as well, so this is not OSX specific.
>
>
> A quick follow up here. I reverted to:
>
>  R version 2.8.1 (2008-12-22)
>
> which includes survival version:
>
> Version:       2.34-1
> Date:          2008-03-31
>
>
> In that version, I get:
>
>> summary( survfit( Surv(futime, fustat)~1, data=ovarian), scale = 365.25)
> Call: survfit(formula = Surv(futime, fustat) ~ 1, data = ovarian)
>
>  time n.risk n.event survival std.err lower 95% CI upper 95% CI
> 0.162     26       1    0.962  0.0377        0.890        1.000
> 0.315     25       1    0.923  0.0523        0.826        1.000
> 0.427     24       1    0.885  0.0627        0.770        1.000
> 0.734     23       1    0.846  0.0708        0.718        0.997
> 0.901     22       1    0.808  0.0773        0.670        0.974
> 0.966     21       1    0.769  0.0826        0.623        0.949
> 0.999     20       1    0.731  0.0870        0.579        0.923
> 1.180     17       1    0.688  0.0919        0.529        0.894
> 1.270     15       1    0.642  0.0965        0.478        0.862
> 1.300     14       1    0.596  0.0999        0.429        0.828
> 1.541     12       1    0.546  0.1032        0.377        0.791
> 1.747     11       1    0.497  0.1051        0.328        0.752
>
>
> So the functional loss of the 'scale' argument took place subsequent to that 
> release. From a review of the code in both versions, it would appear that 
> substantive changes took place to the function in the intervening time frame, 
> including the addition of the 'rmean' and 'extend' arguments. One of the 
> changes appears to be the setting of:
>
>  stime <- fit$time/scale
>
> in the old version and I do not see a parallel adjustment in the time scale in 
> the new version and the subsequent use of fit$time later in the new function.
>
> Given the substantive changes to the function code, I am hesitant to propose 
> patches for fear of introducing breakage elsewhere. I also need to get some 
> work done for a client today, before I leave for vacation tomorrow for a week, 
> otherwise I would spend more time evaluating possible patches.
>
> I hope that the above is enough to give Terry and Thomas some narrowed focus.
>
> Regards,
>
> Marc
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From simon.urbanek at r-project.org  Wed Apr  1 16:03:53 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 1 Apr 2009 10:03:53 -0400
Subject: [Rd] R in standalone application
In-Reply-To: <49D2D660.8040708@hotmail.com>
References: <49D2D660.8040708@hotmail.com>
Message-ID: <CE5A6A4C-63D7-4A6E-85BF-F481C42D3D78@r-project.org>

Eric,

On Mar 31, 2009, at 10:50 PM, Eric wrote:

> I am trying to build a C application where I need to compute some  
> statistics to take decisions about the direction to give to a user,  
> knowing his/her habits. Because I used R back at school, I thought I  
> can use some of his functions in my application,  as a shared  
> library. I reviewed the "Rinternals" and "R extensions"  documents,  
> and decided to give a try to the REmbedded.c file. Compilation and  
> linking went well. But the execution failed with a "Fatal error: R  
> home directory is not defined". Does it mean that R has to to be  
> distributed with my application or, did I miss something in my  
> readings ?

Yes - you didn't read the 8.1 section of R-ext attentively enough. It  
tells you that you need to setup the environment properly and the  
easiest way to do that on unix is to run
R CMD yourApp

Clearly, R must be installed in order to use your application, since  
your application is using R ;). It is common for the embedding  
application to determine the correct settings before starting R (see  
the R.app GUI on how to setup the environment on a Mac in a GUI  
application [you can still use R CMD though], see for example Rserve  
on how to find the R settings from the registry on Windows).

Cheers,
Simon


> If that is of any importance, I am working on unix but aim for full  
> portability (i.e Windows too)
>
> Thanks for any assistance.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From macrakis at alum.mit.edu  Wed Apr  1 21:49:37 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Wed, 1 Apr 2009 15:49:37 -0400
Subject: [Rd] Assignment to string
Message-ID: <8b356f880904011249r7e68bc12jd57ce226c8daf996@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090401/4aadc3a8/attachment.pl>

From simon.urbanek at r-project.org  Wed Apr  1 22:21:53 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 1 Apr 2009 16:21:53 -0400
Subject: [Rd] Assignment to string
In-Reply-To: <8b356f880904011249r7e68bc12jd57ce226c8daf996@mail.gmail.com>
References: <8b356f880904011249r7e68bc12jd57ce226c8daf996@mail.gmail.com>
Message-ID: <EE175D00-B63F-484F-B596-A974A2305423@r-project.org>


On Apr 1, 2009, at 15:49 , Stavros Macrakis wrote:

> The documentation for assignment says:
>
>     In all the assignment operator expressions, 'x' can be a name or
>     an expression defining a part of an object to be replaced (e.g.,
>     'z[[1]]').  A syntactic name does not need to be quoted, though it
>     can be (preferably by backticks).
>
> But the implementation allows assignment to a character string (i.e.  
> not a
> name), which it coerces to a name:
>
>         "foo" <- 23; foo
>         # returns 23
>> is.name("foo")
>         [1] FALSE
>
> Is this a documentation error or an implementation error?
>

Neither - what you're missing is that you are actually quoting foo  
namely with double-quotes. Hence both the documentation and the  
implementations are correct. (Technically "name" as referred above can  
be either a symbol or a character string).

Cheers,
Simon


> The coercion is not happening at parse time:
>
>    class(quote("foo"<-3)[[2]])
>    [1] "character"
>
> In fact, bizarrely, not only does it coerce to a name, it actually
> *modifies* the parse tree:
>
>> gg <- quote("hij" <- 4)
>> gg
>    "hij" <- 4
>> eval(gg)
>> gg
>    hij <- 4
>
> *** The cases below only come up with expression trees generated
> programmatically as far as I know, so are much more marginal cases.  
> ***
>
> The <- operator even allows the left-hand-side to be of length > 1,  
> though
> it just ignores the other elements, with the same side effect as  
> before:
>
>> gg <- quote(x<-44)
>> gg[[2]] <- c("x","y")
>> gg
>    c("x", "y") <- 44
>> eval(gg)
>> x
>    [1] 44
>> y
>    Error: object "y" not found
>> gg
>    x <- 44
>
> None of this is documented in ? <-, and it is rather a surprise that
> evaluating an expression tree can modify it.  I admit we had a feature
> (performance hack) like this in MacLisp years ago, where expanded  
> syntax
> macros replaced the source code of the macro, but it was a documented,
> general, and optional part of the macro mechanism.
>
> Another little glitch:
>
>    gg <- quote(x<-44); gg[[2]] <- character(0); eval(gg)
>    Error in eval(expr, envir, enclos) :
>      'getEncChar' must be called on a CHARSXP
>
> This looks like an internal error that users shouldn't see.
>
>           -s
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From dutangc at gmail.com  Wed Apr  1 22:49:22 2009
From: dutangc at gmail.com (Christophe Dutang)
Date: Wed, 1 Apr 2009 22:49:22 +0200
Subject: [Rd] License question (RUnit)
In-Reply-To: <1238576332.4587.16.camel@localhost.localdomain>
References: <1238576332.4587.16.camel@localhost.localdomain>
Message-ID: <08C73E0D-928A-4B93-86EC-17C3F1C00EE6@gmail.com>


Hi,

Try to contact the other authors... I spent 5 min on google and found  
this http://www.uni-konstanz.de/FuF/Verwiss/koenig/

Regards

Christophe

Le 1 avr. 09 ? 10:58, Pierre-Yves a ?crit :

> Dear list,
>
> Sorry for the noise but I have a question regarding the license used  
> in
> RUnit [1], I contacted the maintainer( burgerm -at- users -dot-
> sourceforge -dot- net ) on March 20th but I have received no answer.
>
> Could anyone help to solve this question ?
>
> Basically, my problem is that the website and the DESCRIPTION file say
> that the license is GPLv2 while the header in the code says it is  
> GPLv2
> or any later version.
>
> Thanks in advance for your help,
>
> Best regards,
>
> Pierre
>
> [1] http://cran.r-project.org/web/packages/RUnit/index.html
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

--
Christophe Dutang
Ph. D. student at ISFA, Lyon, France
website: http://dutangc.free.fr


From macrakis at alum.mit.edu  Wed Apr  1 22:52:17 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Wed, 1 Apr 2009 16:52:17 -0400
Subject: [Rd] Assignment to string
In-Reply-To: <EE175D00-B63F-484F-B596-A974A2305423@r-project.org>
References: <8b356f880904011249r7e68bc12jd57ce226c8daf996@mail.gmail.com>
	<EE175D00-B63F-484F-B596-A974A2305423@r-project.org>
Message-ID: <8b356f880904011352v63a150c8peb17e43903fe775f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090401/d85f63fa/attachment.pl>

From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Wed Apr  1 23:11:26 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Wed, 01 Apr 2009 23:11:26 +0200
Subject: [Rd] Assignment to string
In-Reply-To: <8b356f880904011249r7e68bc12jd57ce226c8daf996@mail.gmail.com>
References: <8b356f880904011249r7e68bc12jd57ce226c8daf996@mail.gmail.com>
Message-ID: <49D3D87E.3050100@idi.ntnu.no>

Stavros Macrakis wrote:
> The documentation for assignment says:
>
>      In all the assignment operator expressions, 'x' can be a name or
>      an expression defining a part of an object to be replaced (e.g.,
>      'z[[1]]').  A syntactic name does not need to be quoted, though it
>      can be (preferably by backticks).
>
> But the implementation allows assignment to a character string (i.e. not a
> name), which it coerces to a name:
>
>          "foo" <- 23; foo
>          # returns 23
>          > is.name("foo")
>          [1] FALSE
>
> Is this a documentation error or an implementation error?
>   

i think this concords with the documentation in the sense that in an
assignment a string can work as a name.  note that

    `foo bar` = 1
    is.name(`foo`)
    # FALSE

the issue is different here in that in is.name("foo") "foo" evaluates to
a string (it works as a string literal), while in is.name(`foo`) `foo`
evaluates to the value of the variable named 'foo' (with the quotes
*not* belonging to the name).

with only a quick look at the sources (src/main/envir.c:1511), i guess
the first element to an assignment operator (i mean the left-assignment
operators) is converted to a name, so that in

    "foo" <- 1

"foo" evaluates to a string and not a name (hence is.name("foo") is
false), but internally it is sort of 'coerced' to a name, as in

    as.name("foo")
    # `foo`
    is.name(as.name("foo"))
    # TRUE

> The coercion is not happening at parse time:
>
>     class(quote("foo"<-3)[[2]])
>     [1] "character"
>   

i think the internal assignment op really receives a string in a case
like "foo" <- 1, it knows it has to treat it as a name without the
parser classifying the string as a name.  (pure guesswork, again.)

the documentation might avoid calling a plain string a 'quoted name',
though, it is confusing.  a quoted name is something like quote(name) or
quote(`name`):

    is(quote(name))
    # "name" "language"

    is(quote(`name`))
    # "name" "language"

but *not* something like "name":
   
    is("name")
    # "character" "vector" "data.frameRowLabels"

and *not* like quote("name"):
   
    is(quote("name"))
    # "character" "vector" "data.frameRowLabels"


> In fact, bizarrely, not only does it coerce to a name, it actually
> *modifies* the parse tree:
>
>     > gg <- quote("hij" <- 4)
>     > gg
>     "hij" <- 4
>     > eval(gg)
>     > gg
>     hij <- 4
>   

wow!  that's called 'functional programming' ;)
you're right:

    gg = quote({"a" = 1})
    is(gg[[2]][[2]])
    # "character" ...
    eval(gg)
    is(gg[[2]][[2]])
    # "name" ...
  

> *** The cases below only come up with expression trees generated
> programmatically as far as I know, so are much more marginal cases. ***
>
> The <- operator even allows the left-hand-side to be of length > 1, though
> it just ignores the other elements, with the same side effect as before:
>   

that's clear from the sources;  see src/main/envir.c:1521.  it should be
documented (maybe it is, i haven't investigated this issue).

>     > gg <- quote(x<-44)
>     > gg[[2]] <- c("x","y")
>     > gg
>     c("x", "y") <- 44
>   
> eval(gg)

but also this:

    rm(list=ls())
    do.call('=', list(letters, 1))
    # just fine
    a
    # 1
    b
    # error


weird these work.  i think it deserves a warning, at the very least, as in

    c('x', 'y') = 4
    # error: assignment to non-language object
    c(x, y) = 4
    # error: could not find function c<-

(provided that x and y are already there)

btw., that's what you can do with rvalues (using the otherwise
semantically void operator `:=`).

these could seem equivalent, but they're (obviously) not:

    'x' = 1
    c('x') = 1

    x = 1
    c(x) = 1

>     > x
>     [1] 44
>     > y
>     Error: object "y" not found
>     > gg
>     x <- 44
>
> None of this is documented in ? <-, and it is rather a surprise that
> evaluating an expression tree can modify it.  I admit we had a feature
> (performance hack) like this in MacLisp years ago, where expanded syntax
> macros replaced the source code of the macro, but it was a documented,
> general, and optional part of the macro mechanism.
>   

but

- maclisp was designed by computer scientists in a research project,
- r is being implemented by statisticians for practical purposes.

almost every part differs here (and almost no pun intended).

> Another little glitch:
>
>     gg <- quote(x<-44); gg[[2]] <- character(0); eval(gg)
>     Error in eval(expr, envir, enclos) :
>       'getEncChar' must be called on a CHARSXP
>
> This looks like an internal error that users shouldn't see.
>   

by no means the only example that the interface is no blood-brain barrier.

vQ


From fjbuch at gmail.com  Thu Apr  2 00:36:28 2009
From: fjbuch at gmail.com (Farrel Buchinsky)
Date: Wed, 1 Apr 2009 18:36:28 -0400
Subject: [Rd] RGoogleDocs so close but errors with spreadsheet reading
Message-ID: <bd93cdad0904011536n5fca90felb5896956c29721c7@mail.gmail.com>

I got RGoogleDocs to work. It works on documents but not on spreadsheets.
I get the following error.

getDocs(con, what
="http://docs.google.com/feeds/documents/private/full/-/spreadsheet")

assignment of an object of class "NULL" is not valid for slot "access"
in an object of class "GoogleSpreadsheet"; is(value, "character") is
not TRUE

How can I troubleshoot this?

Farrel Buchinsky
Google Voice Tel: (412) 567-7870

Sent from Pittsburgh, Pennsylvania, United States


From fjbuch at gmail.com  Thu Apr  2 01:17:12 2009
From: fjbuch at gmail.com (Farrel Buchinsky)
Date: Wed, 1 Apr 2009 19:17:12 -0400
Subject: [Rd] RGoogleDocs so close but errors with spreadsheet reading
In-Reply-To: <bd93cdad0904011536n5fca90felb5896956c29721c7@mail.gmail.com>
References: <bd93cdad0904011536n5fca90felb5896956c29721c7@mail.gmail.com>
Message-ID: <bd93cdad0904011617h1e534881gec4da8b669a2d5c8@mail.gmail.com>

Does it have anything to do with the following message when I load RGoogleDocs?

	The following object(s) are masked from package:methods :

	 getAccess


Farrel Buchinsky
Google Voice Tel: (412) 567-7870




On Wed, Apr 1, 2009 at 18:36, Farrel Buchinsky <fjbuch at gmail.com> wrote:
> I got RGoogleDocs to work. It works on documents but not on spreadsheets.
> I get the following error.
>
> getDocs(con, what
> ="http://docs.google.com/feeds/documents/private/full/-/spreadsheet")
>
> assignment of an object of class "NULL" is not valid for slot "access"
> in an object of class "GoogleSpreadsheet"; is(value, "character") is
> not TRUE
>
> How can I troubleshoot this?
>
> Farrel Buchinsky
> Google Voice Tel: (412) 567-7870
>
> Sent from Pittsburgh, Pennsylvania, United States
>


From duncan at wald.ucdavis.edu  Thu Apr  2 03:15:53 2009
From: duncan at wald.ucdavis.edu (Duncan Temple Lang)
Date: Wed, 01 Apr 2009 18:15:53 -0700
Subject: [Rd] RGoogleDocs so close but errors with spreadsheet reading
In-Reply-To: <bd93cdad0904011536n5fca90felb5896956c29721c7@mail.gmail.com>
References: <bd93cdad0904011536n5fca90felb5896956c29721c7@mail.gmail.com>
Message-ID: <49D411C9.9080003@wald.ucdavis.edu>


You might try my development version which I put at

    http://www.omegahat.org/Prerelease/RGoogleDocs_0.2-0.tar.gz

I am not certain if there are any substantive differences with the
one in the Omegahat repository, but it works for me with a document
and a spreadsheet in an Google Docs account.

   D.

Farrel Buchinsky wrote:
> I got RGoogleDocs to work. It works on documents but not on spreadsheets.
> I get the following error.
> 
> getDocs(con, what
> ="http://docs.google.com/feeds/documents/private/full/-/spreadsheet")
> 
> assignment of an object of class "NULL" is not valid for slot "access"
> in an object of class "GoogleSpreadsheet"; is(value, "character") is
> not TRUE
> 
> How can I troubleshoot this?
> 
> Farrel Buchinsky
> Google Voice Tel: (412) 567-7870
> 
> Sent from Pittsburgh, Pennsylvania, United States
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From macrakis at alum.mit.edu  Thu Apr  2 04:32:08 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Wed, 1 Apr 2009 22:32:08 -0400
Subject: [Rd] Assignment to string
In-Reply-To: <49D3D87E.3050100@idi.ntnu.no>
References: <8b356f880904011249r7e68bc12jd57ce226c8daf996@mail.gmail.com>
	<49D3D87E.3050100@idi.ntnu.no>
Message-ID: <8b356f880904011932h5b28ea6fg6ff3e227f249a41f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090401/d174bb26/attachment.pl>

From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Thu Apr  2 10:31:09 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Thu, 02 Apr 2009 10:31:09 +0200
Subject: [Rd] [R] Definition of = vs. <-
In-Reply-To: <49D3EED3.7040307@biostat.ku.dk>
References: <8b356f880904010738w50523b22od70849ebdc9381fa@mail.gmail.com>
	<49D3C8B2.3020701@idi.ntnu.no> <49D3EED3.7040307@biostat.ku.dk>
Message-ID: <49D477CD.2010202@idi.ntnu.no>

Peter Dalgaard wrote:
> Wacek Kusnierczyk wrote:
>> Stavros Macrakis wrote:
>>>> `->`
>>>>     
>>> Error: object "->" not found
>>>   
>>
>> that's weird!
>
> Why???
>

partly because it was april fools. 

but more seriously, it's because one could assume that in any syntactic
expression with an operator involved, the operator maps to a semantic
object.  it has been claimed on this list (as far as i recall;  don't
ask me for reference, but if pressed, i'll find it) that any expression
of the form

    <lhs> <op> <rhs>

is a syntactic variant for

    `<op>`(<lhs>, <rhs>)

(which would, following that argumentation, make r a lisp-like language)
but this apparently does not apply to '->'.  i would (naively, perhaps)
expect that `->` is a function, which, internally, may well just invert
the order of arguments and imemdiately call `<-`.  the fact that
expressions involving '->' are converted, at the parse time, into ones
using '<-' is far from obvious to me (it is now, but not a priori):

    quote(1->a)
    # a <- 1
    # why not: 1 -> a
    # why not: `->`(1, a)

and btw. the following is also weird:

    quote(a=1)
    # 1

not because '=' works as named argument specifier (so that the result
would be something like `=`(a, 1)), but because quote has no parameter
named 'a', and i would expect an error to be raised:

    # hypothetical
    quote(a=1)
    # error: unused argument(s): (a = 1)

as in, say

    vector(mode='list', i=1)
    # error: unused argument(s): (i = 1)

it appears that, in fact, quite many r functions will gladly match a
*named* argument with a *differently named* parameter.  it is weird to
the degree that it is *wrong* wrt. the 'r language definition', sec.
4.3.2 'argument matching', which says:

"The first thing that occurs in a function evaluation is the matching of
formal to the actual or
supplied arguments. This is done by a three-pass process:
 1. Exact matching on tags. For each named supplied argument the list of
formal arguments is
     searched for an item whose name matches exactly. It is an error to
have the same formal
     argument match several actuals or vice versa.
 2. Partial matching on tags. Each remaining named supplied argument is
compared to the
     remaining formal arguments using partial matching. If the name of
the supplied argument
     matches exactly with the first part of a formal argument then the
two arguments are con-
     sidered to be matched. It is an error to have multiple partial
matches. Notice that if f
     <- function(fumble, fooey) fbody, then f(f = 1, fo = 2) is illegal,
even though the 2nd
     actual argument only matches fooey. f(f = 1, fooey = 2) is legal
though since the second
     argument matches exactly and is removed from consideration for
partial matching. If the
     formal arguments contain ?...? then partial matching is only
applied to arguments that
     precede it.
 3. Positional matching. Any unmatched formal arguments are bound to
unnamed supplied
     arguments, in order. If there is a ?...? argument, it will take up
the remaining arguments,
     tagged or not.
   If any arguments remain unmatched an error is declared.
"

if you now consider the example of quote(a=1), with quote having *one*
formal argument (parameter) named 'expr' (see ?quote), we see that:

1. there is no exact match between the formal 'expr' and the actual 'a'

2. there is no partial match between the formal 'expr' and the actual 'a'

3a. there is an unmatched formal argument ('expr'), but no unnamed
actual argument.  hence, 'expr' remains unmatched. 
3b. there is no argument '...' (i think the r language definition is
lousy and should say 'formal argument' here, as you can have it as an
actual, too, as in quote('...'=1)).  hence, the actual argument named
'a' will not be 'taken up'.

there remain unmatched arguments (i guess the r language definition is
lousy and should say 'unmatched actual arguments', as you can obviously
have unmatched formals, as in eval(1)), hence an error should be
'declared' (i guess 'raised' is more appropriate). 

this does not happen in quote(a=1) (and many, many other cases), and
this makes me infer that there is a *bug* in the implementation of
argument matching, since it clearly does not conform to the definiton. 
hence, i cc: to r-devel, and will also report a bug in the usual way.

vQ


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Thu Apr  2 10:53:26 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Thu, 02 Apr 2009 10:53:26 +0200
Subject: [Rd] [R] Definition of = vs. <-
In-Reply-To: <49D477CD.2010202@idi.ntnu.no>
References: <8b356f880904010738w50523b22od70849ebdc9381fa@mail.gmail.com>	<49D3C8B2.3020701@idi.ntnu.no>
	<49D3EED3.7040307@biostat.ku.dk> <49D477CD.2010202@idi.ntnu.no>
Message-ID: <49D47D06.3090201@idi.ntnu.no>

Wacek Kusnierczyk wrote:
>
> and btw. the following is also weird:
>
>     quote(a=1)
>     # 1
>
> not because '=' works as named argument specifier (so that the result
> would be something like `=`(a, 1)), 

i meant to write: not because '=' does not work as an assignment
operator (or otherwise the result would be ...)

> but because quote has no parameter
> named 'a', and i would expect an error to be raised:
>
>     # hypothetical
>     quote(a=1)
>     # error: unused argument(s): (a = 1)
>
> as in, say
>
>     vector(mode='list', i=1)
>     # error: unused argument(s): (i = 1)
>
> it appears that, in fact, quite many r functions will gladly match a
> *named* argument with a *differently named* parameter.  it is weird to
> the degree that it is *wrong* wrt. the 'r language definition', sec.
> 4.3.2 'argument matching', which says:
>
> "The first thing that occurs in a function evaluation is the matching of
> formal to the actual or
> supplied arguments. This is done by a three-pass process:
>  1. Exact matching on tags. For each named supplied argument the list of
> formal arguments is
>      searched for an item whose name matches exactly. It is an error to
> have the same formal
>      argument match several actuals or vice versa.
>  2. Partial matching on tags. Each remaining named supplied argument is
> compared to the
>      remaining formal arguments using partial matching. If the name of
> the supplied argument
>      matches exactly with the first part of a formal argument then the
> two arguments are con-
>      sidered to be matched. It is an error to have multiple partial
> matches. Notice that if f
>      <- function(fumble, fooey) fbody, then f(f = 1, fo = 2) is illegal,
> even though the 2nd
>      actual argument only matches fooey. f(f = 1, fooey = 2) is legal
> though since the second
>      argument matches exactly and is removed from consideration for
> partial matching. If the
>      formal arguments contain ???...??? then partial matching is only
> applied to arguments that
>      precede it.
>  3. Positional matching. Any unmatched formal arguments are bound to
> unnamed supplied
>      arguments, in order. If there is a ???...??? argument, it will take up
> the remaining arguments,
>      tagged or not.
>    If any arguments remain unmatched an error is declared.
> "
>
> if you now consider the example of quote(a=1), with quote having *one*
> formal argument (parameter) named 'expr' (see ?quote), we see that:
>
> 1. there is no exact match between the formal 'expr' and the actual 'a'
>
> 2. there is no partial match between the formal 'expr' and the actual 'a'
>
> 3a. there is an unmatched formal argument ('expr'), but no unnamed
> actual argument.  hence, 'expr' remains unmatched. 
> 3b. there is no argument '...' (i think the r language definition is
> lousy and should say 'formal argument' here, as you can have it as an
> actual, too, as in quote('...'=1)).  hence, the actual argument named
> 'a' will not be 'taken up'.
>
> there remain unmatched arguments (i guess the r language definition is
> lousy and should say 'unmatched actual arguments', as you can obviously
> have unmatched formals, as in eval(1)), hence an error should be
> 'declared' (i guess 'raised' is more appropriate). 
>
> this does not happen in quote(a=1) (and many, many other cases), and
> this makes me infer that there is a *bug* in the implementation of
> argument matching, since it clearly does not conform to the definiton. 
> hence, i cc: to r-devel, and will also report a bug in the usual way.
>


From waku at idi.ntnu.no  Thu Apr  2 11:20:13 2009
From: waku at idi.ntnu.no (waku at idi.ntnu.no)
Date: Thu,  2 Apr 2009 11:20:13 +0200 (CEST)
Subject: [Rd] actual argument matching does not conform to the definition
	(PR#13634)
Message-ID: <20090402092013.1D87E2832190@mail.pubhealth.ku.dk>

Full_Name: Wacek Kusnierczyk
Version: 2.10.0 r48269
OS: Ubuntu 8.04 Linux 32 bit
Submission from: (NULL) (129.241.199.164)


In the following example (and many other cases):

   quote(a=1)
   # 1

the argument matching is apparently incorrect wrt. the documentation (The R
Language Definition, v 2.8.1, sec. 4.3.2, p. 23), which specifies the following
algorithm for argument matching:

1. Attempt to match named actual arguments to formal arguments exactly.
2. For the arguments remaining from step 1, attempt to match named actual
arguments to formal arguments partially.
3. For the arguments remaining from step 1, collectively match all unnamed
actual arguments to the formal argument '...', if available.
4. If any arguments remain, declare an error.

quote(a=1) qualifies for step 4:

1. The actual argument 'a' does not match exactly quote's only formal argument,
'expr'.
2. The actual argument 'a' does not match partially quote's only formal
argument, 'expr'.
3. quote has no formal argument '...', hence 'a' remains unmatched.
4. An error should be raised.

Instead, the actual argument 'a' is matched to the formal argument 'expr'.  This
clearly conflicts with the definition.  Either the definition or the
implementation (or both) are wrong.

The problem is not constrained to quote, and seems to be ubiquitous (though does
not apply to all functions).

There are additional minor issues with the documentation which were raised in a
separate thread.

Regards,
vQ


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Thu Apr  2 11:47:45 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Thu, 02 Apr 2009 11:47:45 +0200
Subject: [Rd] Assignment to string
In-Reply-To: <8b356f880904011932h5b28ea6fg6ff3e227f249a41f@mail.gmail.com>
References: <8b356f880904011249r7e68bc12jd57ce226c8daf996@mail.gmail.com>	
	<49D3D87E.3050100@idi.ntnu.no>
	<8b356f880904011932h5b28ea6fg6ff3e227f249a41f@mail.gmail.com>
Message-ID: <49D489C1.5000809@idi.ntnu.no>

Stavros Macrakis wrote:
> On Wed, Apr 1, 2009 at 5:11 PM, Wacek Kusnierczyk <
> Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:
>
>   
>> Stavros Macrakis wrote:
>> ...
>> i think this concords with the documentation in the sense that in an
>> assignment a string can work as a name.  note that
>>
>>    `foo bar` = 1
>>    is.name(`foo`)
>>    # FALSE
>>
>> the issue is different here in that in is.name("foo") "foo" evaluates to
>> a string (it works as a string literal), while in is.name(`foo`) `foo`
>> evaluates to the value of the variable named 'foo' (with the quotes
>> *not* belonging to the name).
>>
>>     
>
> Wacek, surely you are joking here.  The object written `foo` (a name)
> *evaluates to* its value.  

yes, which is the value of a variable named 'foo' (quotes not included
in the name), or with other words, the value of the variable foo.

> The object written "foo" (a string) evaluates to
> itself.  This has nothing to do with the case at hand, since the left-hand
> side of an assignment statement is not evaluated in the normal way.
>   

yes.  i did support your point that the documentation is confusing wrt.

    "foo" = 1

because "foo" is not a name (and in particular, not a quoted name).


>
>   
>> ...with only a quick look at the sources (src/main/envir.c:1511), i guess
>> the first element to an assignment operator (i mean the left-assignment
>> operators) is converted to a name
>>     
>
>
> Yes, clearly when the LHS of an assignment is a string it is being coerced
> to a name.  I was simply pointing out that that is not consistent with the
> documentation, which requires a name on the LHS.
>   

... but there is probably something going on in do_set (in
src/main/eval.c) before do_assign is called.

> - maclisp was designed by computer scientists in a research project,
>   
>> - r is being implemented by statisticians for practical purposes.
>>
>>     
>
> Well, I think it is overstating things to say that Maclisp was designed at
> all.  Maclisp grew out of PDP-6 Lisp, with new features being added
> regularly. Maclisp itself wasn't a research project -- 

didn't say that;  it was, as far as i know (and that's little) developed
as part, or in support of, the MIT research project MAC.


> there are vanishingly
> few papers about it in the academic literature, unlike contemporary research
> languages like Planner, EL/1, CLU, etc. In fact, there are many parallels
> with R -- it was in some sense a service project supporting AI and symbolic
> algebra research, with ad hoc features (a.k.a. hacks) 

that's a parallel to r, i guess?

> being added regularly
> to support some new idea in AI or algebra.  To circle back to the current
> discussion, Maclisp didn't even have strings as a data type until the
> mid-70's -- before that, atoms ('symbols' in more modern terminology) were
> the only way to represent strings. (And that lived on in Maxima for many
> decades...)  See http://www.softwarepreservation.org/projects/LISP/ for
> documentation on the history of many different Lisps.
>   

interesting, thanks.

> We learned many lessons with Maclisp.  Well, actually two different sets of
> lessons were learned by two different communities.  The Scheme community
> learned the importance of minimalist, clean, principled design.  

and scheme is claimed to be the inspiration for r...

> The Common
> Lisp community learned the importance of large, well-designed libraries.
> Both learned the importance of standardization and clear specification.
> There is much to learn.
>   
yes...

best,
vQ


From ligges at statistik.tu-dortmund.de  Thu Apr  2 12:07:28 2009
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 02 Apr 2009 12:07:28 +0200
Subject: [Rd] Compiler options for Makefile.win
In-Reply-To: <49CFCC79.9090409@aon.at>
References: <49CFCC79.9090409@aon.at>
Message-ID: <49D48E60.2080209@statistik.tu-dortmund.de>

I fear the number of R users under Windows that make use of a non-gcc 
compiler and is reading this list is quite close to 0. Hence you will 
probably have to find it out yourself.

Uwe Ligges






cstrato wrote:
> Dear all,
> 
> For certain reasons I have to compile the source code of my package on 
> Windows XP using Microsoft Visual Studio 9.0, thus I had to create a 
> "Makefile.win". Now I have a question regarding compiler options /MT vs 
> /MD for Makefile.win.
> 
> The following partial output shows that when building my package on 
> Windows XP using "R CMD build --binary xps" with compiler option /MT 
> everything is ok:
> 
> - - - - - - - -
>  running src/Makefile.win ...
> "C:\Programme\Microsoft Visual Studio 9.0\VC\bin/cl" /I"C:\root/include" 
> /FIw32p
> ragma.h /MT /EHsc /Ox /D "MSVC" /D "WIN32" /c TStat.cxx
> Microsoft (R) 32-bit C/C++ Optimizing Compiler Version 15.00.21022.08 
> for 80x86
> Copyright (C) Microsoft Corporation.  All rights reserved.
> 
> TStat.cxx
> 
> 
> Created c:\home\Rabbitus\CRAN\xps\chm\xps.chm, 166,304 bytes
> Compression decreased file by 442,728 bytes.
> ** building package indices ...
> ** MD5 sums
> * DONE (xps)
> * creating vignettes ... OK
> * cleaning src
> 
> 
> Created c:\home\Rabbitus\temp\Rbuild210430099\xps\chm\xps.chm, 166,308 
> bytes
> Compression decreased file by 442,724 bytes.
> ** building package indices ...
> ** MD5 sums
> packaged installation of 'xps' as xps_1.3.8.zip
> * DONE (xps)
> - - - - - - - -
> 
> As you see the package was built correctly.
> 
> 
> However, when I change the compiler option in "Makefile.win" to /MD the 
> build stops at the following position:
> 
> - - - - - - - -
> Created c:\home\Rabbitus\CRAN\xps\chm\xps.chm, 166,306 bytes
> Compression decreased file by 442,726 bytes.
> ** building package indices ...
> ** MD5 sums
> * DONE (xps)
> * creating vignettes ...Terminating on signal SIGINT(2)
> - - - - - - - -
> 
> As you see I had to terminate the build process manually after 15 min .
> 
> My question is now:
> Do you know why I can build my package w/o problems when using option 
> /MT but not when using option /MD?
> 
> As a note, I am using "R-2.9.0alpha-win32.exe" which I have downloaded 
> today.
> 
> Thank you in advance.
> 
> Best regards
> Christian
> _._._._._._._._._._._._._._._._._._
> C.h.r.i.s.t.i.a.n   S.t.r.a.t.o.w.a
> V.i.e.n.n.a           A.u.s.t.r.i.a
> e.m.a.i.l:        cstrato at aon.at
> _._._._._._._._._._._._._._._._._._
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From csardi at rmki.kfki.hu  Thu Apr  2 12:16:46 2009
From: csardi at rmki.kfki.hu (=?ISO-8859-1?B?R+Fib3IgQ3PhcmRp?=)
Date: Thu, 2 Apr 2009 12:16:46 +0200
Subject: [Rd] Compiler options for Makefile.win
In-Reply-To: <49CFCC79.9090409@aon.at>
References: <49CFCC79.9090409@aon.at>
Message-ID: <d70c15d40904020316q4b6cf5h42b4b9b626d88f9c@mail.gmail.com>

On Sun, Mar 29, 2009 at 9:31 PM, cstrato <cstrato at aon.at> wrote:
[...]
> - - - - - - - -
> Created c:\home\Rabbitus\CRAN\xps\chm\xps.chm, 166,306 bytes
> Compression decreased file by 442,726 bytes.
> ** building package indices ...
> ** MD5 sums
> * DONE (xps)
> * creating vignettes ...Terminating on signal SIGINT(2)
> - - - - - - - -
>
> As you see I had to terminate the build process manually after 15 min .
>
> My question is now:
> Do you know why I can build my package w/o problems when using option /MT
> but not when using option /MD?

It seems that the building process got into an infinite loop while
creating the vignette. Some code in the vignette/package does not work
properly. Try running the vignette "by hand" line by line to see where
the problem is.

Gabor

> As a note, I am using "R-2.9.0alpha-win32.exe" which I have downloaded
> today.
>
> Thank you in advance.
>
> Best regards
> Christian
> _._._._._._._._._._._._._._._._._._
> C.h.r.i.s.t.i.a.n ? S.t.r.a.t.o.w.a
> V.i.e.n.n.a ? ? ? ? ? A.u.s.t.r.i.a
> e.m.a.i.l: ? ? ? ?cstrato at aon.at
> _._._._._._._._._._._._._._._._._._
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Gabor Csardi <Gabor.Csardi at unil.ch>     UNIL DGM


From tlumley at u.washington.edu  Thu Apr  2 14:39:23 2009
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 2 Apr 2009 05:39:23 -0700 (PDT)
Subject: [Rd] actual argument matching does not conform to the
 definition (PR#13634)
In-Reply-To: <20090402092013.1D87E2832190@mail.pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.43.0904020539230.16128@hymn34.u.washington.edu>


The explanation is that quote() is a primitive function and that the argument matching rules do not apply to primitives.  That section of the R Language definition should say that primitives are excluded;  it is documented in ?.Primitive.

     -thomas


On Thu, 2 Apr 2009 waku at idi.ntnu.no wrote:

> Full_Name: Wacek Kusnierczyk
> Version: 2.10.0 r48269
> OS: Ubuntu 8.04 Linux 32 bit
> Submission from: (NULL) (129.241.199.164)
>
>
> In the following example (and many other cases):
>
>   quote(a=1)
>   # 1
>
> the argument matching is apparently incorrect wrt. the documentation (The R
> Language Definition, v 2.8.1, sec. 4.3.2, p. 23), which specifies the following
> algorithm for argument matching:
>
> 1. Attempt to match named actual arguments to formal arguments exactly.
> 2. For the arguments remaining from step 1, attempt to match named actual
> arguments to formal arguments partially.
> 3. For the arguments remaining from step 1, collectively match all unnamed
> actual arguments to the formal argument '...', if available.
> 4. If any arguments remain, declare an error.
>
> quote(a=1) qualifies for step 4:
>
> 1. The actual argument 'a' does not match exactly quote's only formal argument,
> 'expr'.
> 2. The actual argument 'a' does not match partially quote's only formal
> argument, 'expr'.
> 3. quote has no formal argument '...', hence 'a' remains unmatched.
> 4. An error should be raised.
>
> Instead, the actual argument 'a' is matched to the formal argument 'expr'.  This
> clearly conflicts with the definition.  Either the definition or the
> implementation (or both) are wrong.
>
> The problem is not constrained to quote, and seems to be ubiquitous (though does
> not apply to all functions).
>
> There are additional minor issues with the documentation which were raised in a
> separate thread.
>
> Regards,
> vQ
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From tlumley at u.washington.edu  Thu Apr  2 14:45:11 2009
From: tlumley at u.washington.edu (tlumley at u.washington.edu)
Date: Thu,  2 Apr 2009 14:45:11 +0200 (CEST)
Subject: [Rd] actual argument matching does not conform to the
	definition (PR#13635)
Message-ID: <20090402124511.9028128321A7@mail.pubhealth.ku.dk>


The explanation is that quote() is a primitive function and that the argument matching rules do not apply to primitives.  That section of the R Language definition should say that primitives are excluded;  it is documented in ?.Primitive.

     -thomas


On Thu, 2 Apr 2009 waku at idi.ntnu.no wrote:

> Full_Name: Wacek Kusnierczyk
> Version: 2.10.0 r48269
> OS: Ubuntu 8.04 Linux 32 bit
> Submission from: (NULL) (129.241.199.164)
>
>
> In the following example (and many other cases):
>
>   quote(a=1)
>   # 1
>
> the argument matching is apparently incorrect wrt. the documentation (The R
> Language Definition, v 2.8.1, sec. 4.3.2, p. 23), which specifies the following
> algorithm for argument matching:
>
> 1. Attempt to match named actual arguments to formal arguments exactly.
> 2. For the arguments remaining from step 1, attempt to match named actual
> arguments to formal arguments partially.
> 3. For the arguments remaining from step 1, collectively match all unnamed
> actual arguments to the formal argument '...', if available.
> 4. If any arguments remain, declare an error.
>
> quote(a=1) qualifies for step 4:
>
> 1. The actual argument 'a' does not match exactly quote's only formal argument,
> 'expr'.
> 2. The actual argument 'a' does not match partially quote's only formal
> argument, 'expr'.
> 3. quote has no formal argument '...', hence 'a' remains unmatched.
> 4. An error should be raised.
>
> Instead, the actual argument 'a' is matched to the formal argument 'expr'.  This
> clearly conflicts with the definition.  Either the definition or the
> implementation (or both) are wrong.
>
> The problem is not constrained to quote, and seems to be ubiquitous (though does
> not apply to all functions).
>
> There are additional minor issues with the documentation which were raised in a
> separate thread.
>
> Regards,
> vQ
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Thu Apr  2 15:25:14 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Thu, 02 Apr 2009 15:25:14 +0200
Subject: [Rd] actual argument matching does not conform to the
 definition (PR#13634)
In-Reply-To: <Pine.LNX.4.43.0904020539230.16128@hymn34.u.washington.edu>
References: <Pine.LNX.4.43.0904020539230.16128@hymn34.u.washington.edu>
Message-ID: <49D4BCBA.1070306@idi.ntnu.no>

Thomas Lumley wrote:
>
> The explanation is that quote() is a primitive function and that the
> argument matching rules do not apply to primitives.  That section of
> the R Language definition should say that primitives are excluded;  it
> is documented in ?.Primitive.

thanks.  indeed, the documentation --  the language *definition* --
should make this clear.  so this is a bug in the definition, which does
not match the implementation, which in turn is as intended (right?)

?.Primitive says:

"     The advantage of '.Primitive' over '.Internal' functions is the
     potential efficiency of argument passing.  However, this is done
     by ignoring argument names and using positional matching of
     arguments (unless arranged differently for specific primitives
     such as 'rep'), so this is discouraged for functions of more than
     one argument.
"

what is discouraged?

vQ


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Thu Apr  2 15:30:09 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Waclaw.Marcin.Kusnierczyk at idi.ntnu.no)
Date: Thu,  2 Apr 2009 15:30:09 +0200 (CEST)
Subject: [Rd] actual argument matching does not conform to the
	definition (PR#13636)
Message-ID: <20090402133009.D02172834170@mail.pubhealth.ku.dk>

Thomas Lumley wrote:
>
> The explanation is that quote() is a primitive function and that the
> argument matching rules do not apply to primitives.  That section of
> the R Language definition should say that primitives are excluded;  it
> is documented in ?.Primitive.

thanks.  indeed, the documentation --  the language *definition* --
should make this clear.  so this is a bug in the definition, which does
not match the implementation, which in turn is as intended (right?)

?.Primitive says:

"     The advantage of '.Primitive' over '.Internal' functions is the
     potential efficiency of argument passing.  However, this is done
     by ignoring argument names and using positional matching of
     arguments (unless arranged differently for specific primitives
     such as 'rep'), so this is discouraged for functions of more than
     one argument.
"

what is discouraged?

vQ


From armstrong.whit at gmail.com  Thu Apr  2 15:41:00 2009
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Thu, 2 Apr 2009 09:41:00 -0400
Subject: [Rd] what is the preferred method to create a package local
	variable?
In-Reply-To: <49D27438.6010806@sciviews.org>
References: <8ec76080903310845x3b0a0c2cy22d30cd0799a206e@mail.gmail.com>
	<66f3bd910903311235w5421c11ap357ced8a6706f985@mail.gmail.com>
	<49D27438.6010806@sciviews.org>
Message-ID: <8ec76080904020641m7058120ckef7dd447a83a644@mail.gmail.com>

Thanks to everyone for the suggestions.

The package local environment (per Roger Peng) works well.
.localstuff <- new.env()
.localstuff$bbg.db.conn <- dbConnect(...)

However, there is one thing that I'm confused about.

Why must the .localstuff variable be an environment?

I've tried the following, but the variable conn stays null during the
whole R session.  Despite the database connection succeeding (I can
see the constructor printing to the console):

conn <- NULL

.onAttach <- function(libname, pkgname) {
    conn <- dbConnect(dbDriver("PostgreSQL"), user="...")
}

.onUnload <- function(libpath) {
    dbDisconnect(conn)
}

output from R session:

[warmstrong at linuxsvr R.packages]$ R
> library(KLS)
Loading required package: fts
Loading required package: RCommodity
Loading required package: unifiedDBI
Loading required package: RFincad
Loading required package: RLIM
Loading required package: RBoostDateTime
PostgresConnection::PostgresConnection()
> KLS:::conn
NULL
> x <- get.bbg("EURUSD Curncy")
Error in get.bbg("EURUSD Curncy") : Database connection not initialized
> q()
PostgresConnection::~PostgresConnection()
[warmstrong at linuxsvr R.packages]$


Thanks,
Whit






On Tue, Mar 31, 2009 at 3:51 PM, Philippe Grosjean
<phgrosjean at sciviews.org> wrote:
> The best way is to have those variable hidden in the package's workspace, as
> explained by Roger Peng.
>
> However, if you like to use a mechanism managing an environment specifically
> dedicated to temporary variables very easily, look at assignTemp() and
> getTemp() from svMisc package. The advantage is an easier sharing of such
> variables between different packages (plus the bonus of easy management of
> default values, overwriting or not of current content if the variable
> already exists, ...). The temporary environment (TempEnv) is always located
> in the forelast position just before 'base'.
>
> In any cases, avoid using .GlobalEnv and the ugly <<- for that purpose.
> Best,
>
> Philippe Grosjean
>
>
> Roger Peng wrote:
>>
>> I usually use environments for this. So, in one of the R files for the
>> package, just do
>>
>> .localstuff <- new.env()
>>
>> Then, in functions you can do things like
>>
>> .localstuff$bbg.db.conn <- dbConnect(...)
>>
>> -roger
>>
>> On Tue, Mar 31, 2009 at 11:45 AM, Whit Armstrong
>> <armstrong.whit at gmail.com> wrote:
>>>
>>> for the moment, I'm using:
>>>
>>> .onAttach <- function(libname, pkgname) {
>>> ? .bbg.db.conn <<- dbConnect(dbDriver("PostgreSQL"), user="blah","blah")
>>> }
>>>
>>> .onUnload <- function(libpath) {
>>> ? dbDisconnect(.bbg.db.conn)
>>> }
>>>
>>>
>>> which results in a hidden global variable in the global environment.
>>>
>>> I would prefer to make the assignment only in the package namespace.
>>> I've looked at assignInNamespace, but I can't seem to make it work.
>>>
>>> Is there a preferred method for doing this?
>>>
>>> When I try adding an assignment directly in the source file, I get the
>>> "cannot change value of locked binding" error.
>>>
>>> What am I missing?
>>>
>>> Thanks,
>>> Whit
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>
>>
>


From rdpeng at gmail.com  Thu Apr  2 15:49:36 2009
From: rdpeng at gmail.com (Roger Peng)
Date: Thu, 2 Apr 2009 09:49:36 -0400
Subject: [Rd] what is the preferred method to create a package local
	variable?
In-Reply-To: <8ec76080904020641m7058120ckef7dd447a83a644@mail.gmail.com>
References: <8ec76080903310845x3b0a0c2cy22d30cd0799a206e@mail.gmail.com>
	<66f3bd910903311235w5421c11ap357ced8a6706f985@mail.gmail.com>
	<49D27438.6010806@sciviews.org>
	<8ec76080904020641m7058120ckef7dd447a83a644@mail.gmail.com>
Message-ID: <66f3bd910904020649x488c6dcera9dbc753e1e8f3b7@mail.gmail.com>

The use of an environment gets around the fact that package namespaces
are locked, so that values can't be changed once the package is
loaded. However, elements of environments can be changed.

-roger

On Thu, Apr 2, 2009 at 9:41 AM, Whit Armstrong <armstrong.whit at gmail.com> wrote:
> Thanks to everyone for the suggestions.
>
> The package local environment (per Roger Peng) works well.
> .localstuff <- new.env()
> .localstuff$bbg.db.conn <- dbConnect(...)
>
> However, there is one thing that I'm confused about.
>
> Why must the .localstuff variable be an environment?
>
> I've tried the following, but the variable conn stays null during the
> whole R session. ?Despite the database connection succeeding (I can
> see the constructor printing to the console):
>
> conn <- NULL
>
> .onAttach <- function(libname, pkgname) {
> ? ?conn <- dbConnect(dbDriver("PostgreSQL"), user="...")
> }
>
> .onUnload <- function(libpath) {
> ? ?dbDisconnect(conn)
> }
>
> output from R session:
>
> [warmstrong at linuxsvr R.packages]$ R
>> library(KLS)
> Loading required package: fts
> Loading required package: RCommodity
> Loading required package: unifiedDBI
> Loading required package: RFincad
> Loading required package: RLIM
> Loading required package: RBoostDateTime
> PostgresConnection::PostgresConnection()
>> KLS:::conn
> NULL
>> x <- get.bbg("EURUSD Curncy")
> Error in get.bbg("EURUSD Curncy") : Database connection not initialized
>> q()
> PostgresConnection::~PostgresConnection()
> [warmstrong at linuxsvr R.packages]$
>
>
> Thanks,
> Whit
>
>
>
>
>
>
> On Tue, Mar 31, 2009 at 3:51 PM, Philippe Grosjean
> <phgrosjean at sciviews.org> wrote:
>> The best way is to have those variable hidden in the package's workspace, as
>> explained by Roger Peng.
>>
>> However, if you like to use a mechanism managing an environment specifically
>> dedicated to temporary variables very easily, look at assignTemp() and
>> getTemp() from svMisc package. The advantage is an easier sharing of such
>> variables between different packages (plus the bonus of easy management of
>> default values, overwriting or not of current content if the variable
>> already exists, ...). The temporary environment (TempEnv) is always located
>> in the forelast position just before 'base'.
>>
>> In any cases, avoid using .GlobalEnv and the ugly <<- for that purpose.
>> Best,
>>
>> Philippe Grosjean
>>
>>
>> Roger Peng wrote:
>>>
>>> I usually use environments for this. So, in one of the R files for the
>>> package, just do
>>>
>>> .localstuff <- new.env()
>>>
>>> Then, in functions you can do things like
>>>
>>> .localstuff$bbg.db.conn <- dbConnect(...)
>>>
>>> -roger
>>>
>>> On Tue, Mar 31, 2009 at 11:45 AM, Whit Armstrong
>>> <armstrong.whit at gmail.com> wrote:
>>>>
>>>> for the moment, I'm using:
>>>>
>>>> .onAttach <- function(libname, pkgname) {
>>>> ? .bbg.db.conn <<- dbConnect(dbDriver("PostgreSQL"), user="blah","blah")
>>>> }
>>>>
>>>> .onUnload <- function(libpath) {
>>>> ? dbDisconnect(.bbg.db.conn)
>>>> }
>>>>
>>>>
>>>> which results in a hidden global variable in the global environment.
>>>>
>>>> I would prefer to make the assignment only in the package namespace.
>>>> I've looked at assignInNamespace, but I can't seem to make it work.
>>>>
>>>> Is there a preferred method for doing this?
>>>>
>>>> When I try adding an assignment directly in the source file, I get the
>>>> "cannot change value of locked binding" error.
>>>>
>>>> What am I missing?
>>>>
>>>> Thanks,
>>>> Whit
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>>
>>>
>>
>



-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/


From armstrong.whit at gmail.com  Thu Apr  2 15:55:01 2009
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Thu, 2 Apr 2009 09:55:01 -0400
Subject: [Rd] what is the preferred method to create a package local
	variable?
In-Reply-To: <66f3bd910904020649x488c6dcera9dbc753e1e8f3b7@mail.gmail.com>
References: <8ec76080903310845x3b0a0c2cy22d30cd0799a206e@mail.gmail.com>
	<66f3bd910903311235w5421c11ap357ced8a6706f985@mail.gmail.com>
	<49D27438.6010806@sciviews.org>
	<8ec76080904020641m7058120ckef7dd447a83a644@mail.gmail.com>
	<66f3bd910904020649x488c6dcera9dbc753e1e8f3b7@mail.gmail.com>
Message-ID: <8ec76080904020655q177b0c81i55001a21fb8c572@mail.gmail.com>

aha!

Now it makes sense.

Thanks, Roger.

-Whit


On Thu, Apr 2, 2009 at 9:49 AM, Roger Peng <rdpeng at gmail.com> wrote:
> The use of an environment gets around the fact that package namespaces
> are locked, so that values can't be changed once the package is
> loaded. However, elements of environments can be changed.
>
> -roger
>
> On Thu, Apr 2, 2009 at 9:41 AM, Whit Armstrong <armstrong.whit at gmail.com> wrote:
>> Thanks to everyone for the suggestions.
>>
>> The package local environment (per Roger Peng) works well.
>> .localstuff <- new.env()
>> .localstuff$bbg.db.conn <- dbConnect(...)
>>
>> However, there is one thing that I'm confused about.
>>
>> Why must the .localstuff variable be an environment?
>>
>> I've tried the following, but the variable conn stays null during the
>> whole R session. ?Despite the database connection succeeding (I can
>> see the constructor printing to the console):
>>
>> conn <- NULL
>>
>> .onAttach <- function(libname, pkgname) {
>> ? ?conn <- dbConnect(dbDriver("PostgreSQL"), user="...")
>> }
>>
>> .onUnload <- function(libpath) {
>> ? ?dbDisconnect(conn)
>> }
>>
>> output from R session:
>>
>> [warmstrong at linuxsvr R.packages]$ R
>>> library(KLS)
>> Loading required package: fts
>> Loading required package: RCommodity
>> Loading required package: unifiedDBI
>> Loading required package: RFincad
>> Loading required package: RLIM
>> Loading required package: RBoostDateTime
>> PostgresConnection::PostgresConnection()
>>> KLS:::conn
>> NULL
>>> x <- get.bbg("EURUSD Curncy")
>> Error in get.bbg("EURUSD Curncy") : Database connection not initialized
>>> q()
>> PostgresConnection::~PostgresConnection()
>> [warmstrong at linuxsvr R.packages]$
>>
>>
>> Thanks,
>> Whit
>>
>>
>>
>>
>>
>>
>> On Tue, Mar 31, 2009 at 3:51 PM, Philippe Grosjean
>> <phgrosjean at sciviews.org> wrote:
>>> The best way is to have those variable hidden in the package's workspace, as
>>> explained by Roger Peng.
>>>
>>> However, if you like to use a mechanism managing an environment specifically
>>> dedicated to temporary variables very easily, look at assignTemp() and
>>> getTemp() from svMisc package. The advantage is an easier sharing of such
>>> variables between different packages (plus the bonus of easy management of
>>> default values, overwriting or not of current content if the variable
>>> already exists, ...). The temporary environment (TempEnv) is always located
>>> in the forelast position just before 'base'.
>>>
>>> In any cases, avoid using .GlobalEnv and the ugly <<- for that purpose.
>>> Best,
>>>
>>> Philippe Grosjean
>>>
>>>
>>> Roger Peng wrote:
>>>>
>>>> I usually use environments for this. So, in one of the R files for the
>>>> package, just do
>>>>
>>>> .localstuff <- new.env()
>>>>
>>>> Then, in functions you can do things like
>>>>
>>>> .localstuff$bbg.db.conn <- dbConnect(...)
>>>>
>>>> -roger
>>>>
>>>> On Tue, Mar 31, 2009 at 11:45 AM, Whit Armstrong
>>>> <armstrong.whit at gmail.com> wrote:
>>>>>
>>>>> for the moment, I'm using:
>>>>>
>>>>> .onAttach <- function(libname, pkgname) {
>>>>> ? .bbg.db.conn <<- dbConnect(dbDriver("PostgreSQL"), user="blah","blah")
>>>>> }
>>>>>
>>>>> .onUnload <- function(libpath) {
>>>>> ? dbDisconnect(.bbg.db.conn)
>>>>> }
>>>>>
>>>>>
>>>>> which results in a hidden global variable in the global environment.
>>>>>
>>>>> I would prefer to make the assignment only in the package namespace.
>>>>> I've looked at assignInNamespace, but I can't seem to make it work.
>>>>>
>>>>> Is there a preferred method for doing this?
>>>>>
>>>>> When I try adding an assignment directly in the source file, I get the
>>>>> "cannot change value of locked binding" error.
>>>>>
>>>>> What am I missing?
>>>>>
>>>>> Thanks,
>>>>> Whit
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>>
>>>>
>>>>
>>>
>>
>
>
>
> --
> Roger D. Peng ?| ?http://www.biostat.jhsph.edu/~rpeng/
>


From murdoch at stats.uwo.ca  Thu Apr  2 16:04:12 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 02 Apr 2009 10:04:12 -0400
Subject: [Rd] what is the preferred method to create a package
	local	variable?
In-Reply-To: <8ec76080904020641m7058120ckef7dd447a83a644@mail.gmail.com>
References: <8ec76080903310845x3b0a0c2cy22d30cd0799a206e@mail.gmail.com>	<66f3bd910903311235w5421c11ap357ced8a6706f985@mail.gmail.com>	<49D27438.6010806@sciviews.org>
	<8ec76080904020641m7058120ckef7dd447a83a644@mail.gmail.com>
Message-ID: <49D4C5DC.9020607@stats.uwo.ca>

On 4/2/2009 9:41 AM, Whit Armstrong wrote:
> Thanks to everyone for the suggestions.
> 
> The package local environment (per Roger Peng) works well.
> .localstuff <- new.env()
> .localstuff$bbg.db.conn <- dbConnect(...)
> 
> However, there is one thing that I'm confused about.
> 
> Why must the .localstuff variable be an environment?

If a package doesn't have a namespace, then its functions have their 
environment set to the global environment, so they can stomp on user 
things by accident.   I'd say a better solution to this problem is that 
every package should have a namespace, then there isn't the same risk of 
messing with a user's variables.

> 
> I've tried the following, but the variable conn stays null during the
> whole R session.  Despite the database connection succeeding (I can
> see the constructor printing to the console):
> 
> conn <- NULL
> 
> .onAttach <- function(libname, pkgname) {
>     conn <- dbConnect(dbDriver("PostgreSQL"), user="...")
> }

That creates a new local variable called conn.  Use

conn <<- dbConnect ...

to modify the package one. (Assuming you have a namespace; if not, that 
will have different effects depending on whether or not the user has a 
variable named conn.  Yecch.)

Duncan Murdoch

> 
> .onUnload <- function(libpath) {
>     dbDisconnect(conn)
> }
> 
> output from R session:
> 
> [warmstrong at linuxsvr R.packages]$ R
>> library(KLS)
> Loading required package: fts
> Loading required package: RCommodity
> Loading required package: unifiedDBI
> Loading required package: RFincad
> Loading required package: RLIM
> Loading required package: RBoostDateTime
> PostgresConnection::PostgresConnection()
>> KLS:::conn
> NULL
>> x <- get.bbg("EURUSD Curncy")
> Error in get.bbg("EURUSD Curncy") : Database connection not initialized
>> q()
> PostgresConnection::~PostgresConnection()
> [warmstrong at linuxsvr R.packages]$
> 
> 
> Thanks,
> Whit
> 
> 
> 
> 
> 
> 
> On Tue, Mar 31, 2009 at 3:51 PM, Philippe Grosjean
> <phgrosjean at sciviews.org> wrote:
>> The best way is to have those variable hidden in the package's workspace, as
>> explained by Roger Peng.
>>
>> However, if you like to use a mechanism managing an environment specifically
>> dedicated to temporary variables very easily, look at assignTemp() and
>> getTemp() from svMisc package. The advantage is an easier sharing of such
>> variables between different packages (plus the bonus of easy management of
>> default values, overwriting or not of current content if the variable
>> already exists, ...). The temporary environment (TempEnv) is always located
>> in the forelast position just before 'base'.
>>
>> In any cases, avoid using .GlobalEnv and the ugly <<- for that purpose.
>> Best,
>>
>> Philippe Grosjean
>>
>>
>> Roger Peng wrote:
>>>
>>> I usually use environments for this. So, in one of the R files for the
>>> package, just do
>>>
>>> .localstuff <- new.env()
>>>
>>> Then, in functions you can do things like
>>>
>>> .localstuff$bbg.db.conn <- dbConnect(...)
>>>
>>> -roger
>>>
>>> On Tue, Mar 31, 2009 at 11:45 AM, Whit Armstrong
>>> <armstrong.whit at gmail.com> wrote:
>>>>
>>>> for the moment, I'm using:
>>>>
>>>> .onAttach <- function(libname, pkgname) {
>>>>   .bbg.db.conn <<- dbConnect(dbDriver("PostgreSQL"), user="blah","blah")
>>>> }
>>>>
>>>> .onUnload <- function(libpath) {
>>>>   dbDisconnect(.bbg.db.conn)
>>>> }
>>>>
>>>>
>>>> which results in a hidden global variable in the global environment.
>>>>
>>>> I would prefer to make the assignment only in the package namespace.
>>>> I've looked at assignInNamespace, but I can't seem to make it work.
>>>>
>>>> Is there a preferred method for doing this?
>>>>
>>>> When I try adding an assignment directly in the source file, I get the
>>>> "cannot change value of locked binding" error.
>>>>
>>>> What am I missing?
>>>>
>>>> Thanks,
>>>> Whit
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>>
>>>
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch at stats.uwo.ca  Thu Apr  2 16:08:01 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 02 Apr 2009 10:08:01 -0400
Subject: [Rd] what is the preferred method to create a package
	local	variable?
In-Reply-To: <66f3bd910904020649x488c6dcera9dbc753e1e8f3b7@mail.gmail.com>
References: <8ec76080903310845x3b0a0c2cy22d30cd0799a206e@mail.gmail.com>	<66f3bd910903311235w5421c11ap357ced8a6706f985@mail.gmail.com>	<49D27438.6010806@sciviews.org>	<8ec76080904020641m7058120ckef7dd447a83a644@mail.gmail.com>
	<66f3bd910904020649x488c6dcera9dbc753e1e8f3b7@mail.gmail.com>
Message-ID: <49D4C6C1.3090708@stats.uwo.ca>

On 4/2/2009 9:49 AM, Roger Peng wrote:
> The use of an environment gets around the fact that package namespaces
> are locked, so that values can't be changed once the package is
> loaded. However, elements of environments can be changed.

Oops, I forgot about that.  So use a NAMESPACE plus an environment.

Duncan Murdoch

> 
> -roger
> 
> On Thu, Apr 2, 2009 at 9:41 AM, Whit Armstrong <armstrong.whit at gmail.com> wrote:
>> Thanks to everyone for the suggestions.
>>
>> The package local environment (per Roger Peng) works well.
>> .localstuff <- new.env()
>> .localstuff$bbg.db.conn <- dbConnect(...)
>>
>> However, there is one thing that I'm confused about.
>>
>> Why must the .localstuff variable be an environment?
>>
>> I've tried the following, but the variable conn stays null during the
>> whole R session.  Despite the database connection succeeding (I can
>> see the constructor printing to the console):
>>
>> conn <- NULL
>>
>> .onAttach <- function(libname, pkgname) {
>>    conn <- dbConnect(dbDriver("PostgreSQL"), user="...")
>> }
>>
>> .onUnload <- function(libpath) {
>>    dbDisconnect(conn)
>> }
>>
>> output from R session:
>>
>> [warmstrong at linuxsvr R.packages]$ R
>>> library(KLS)
>> Loading required package: fts
>> Loading required package: RCommodity
>> Loading required package: unifiedDBI
>> Loading required package: RFincad
>> Loading required package: RLIM
>> Loading required package: RBoostDateTime
>> PostgresConnection::PostgresConnection()
>>> KLS:::conn
>> NULL
>>> x <- get.bbg("EURUSD Curncy")
>> Error in get.bbg("EURUSD Curncy") : Database connection not initialized
>>> q()
>> PostgresConnection::~PostgresConnection()
>> [warmstrong at linuxsvr R.packages]$
>>
>>
>> Thanks,
>> Whit
>>
>>
>>
>>
>>
>>
>> On Tue, Mar 31, 2009 at 3:51 PM, Philippe Grosjean
>> <phgrosjean at sciviews.org> wrote:
>>> The best way is to have those variable hidden in the package's workspace, as
>>> explained by Roger Peng.
>>>
>>> However, if you like to use a mechanism managing an environment specifically
>>> dedicated to temporary variables very easily, look at assignTemp() and
>>> getTemp() from svMisc package. The advantage is an easier sharing of such
>>> variables between different packages (plus the bonus of easy management of
>>> default values, overwriting or not of current content if the variable
>>> already exists, ...). The temporary environment (TempEnv) is always located
>>> in the forelast position just before 'base'.
>>>
>>> In any cases, avoid using .GlobalEnv and the ugly <<- for that purpose.
>>> Best,
>>>
>>> Philippe Grosjean
>>>
>>>
>>> Roger Peng wrote:
>>>>
>>>> I usually use environments for this. So, in one of the R files for the
>>>> package, just do
>>>>
>>>> .localstuff <- new.env()
>>>>
>>>> Then, in functions you can do things like
>>>>
>>>> .localstuff$bbg.db.conn <- dbConnect(...)
>>>>
>>>> -roger
>>>>
>>>> On Tue, Mar 31, 2009 at 11:45 AM, Whit Armstrong
>>>> <armstrong.whit at gmail.com> wrote:
>>>>>
>>>>> for the moment, I'm using:
>>>>>
>>>>> .onAttach <- function(libname, pkgname) {
>>>>>   .bbg.db.conn <<- dbConnect(dbDriver("PostgreSQL"), user="blah","blah")
>>>>> }
>>>>>
>>>>> .onUnload <- function(libpath) {
>>>>>   dbDisconnect(.bbg.db.conn)
>>>>> }
>>>>>
>>>>>
>>>>> which results in a hidden global variable in the global environment.
>>>>>
>>>>> I would prefer to make the assignment only in the package namespace.
>>>>> I've looked at assignInNamespace, but I can't seem to make it work.
>>>>>
>>>>> Is there a preferred method for doing this?
>>>>>
>>>>> When I try adding an assignment directly in the source file, I get the
>>>>> "cannot change value of locked binding" error.
>>>>>
>>>>> What am I missing?
>>>>>
>>>>> Thanks,
>>>>> Whit
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>>
>>>>
>>>>
>>>
>>
> 
> 
>


From cstrato at aon.at  Thu Apr  2 23:17:26 2009
From: cstrato at aon.at (cstrato)
Date: Thu, 02 Apr 2009 23:17:26 +0200
Subject: [Rd] Compiler options for Makefile.win
In-Reply-To: <49D48E60.2080209@statistik.tu-dortmund.de>
References: <49CFCC79.9090409@aon.at>
	<49D48E60.2080209@statistik.tu-dortmund.de>
Message-ID: <49D52B66.7060802@aon.at>

Dear Uwe,

My problem is that this is the only mailing list I know where to ask 
this question, since this problem is definitely related to R.

When I compile my source code as stand alone library using NMAKE then 
both compiler options, /MD and /MT, work fine and I can use the compiled 
library from a C++ program w/o any problems.

Only compiling the source code from within R results in the error when 
using /MD.

BTW, I forgot to mention that when "R CMD build" stops at:
* DONE (xps)
* creating vignettes ...
I get the following "Microsoft Visual C++ Runtime Library" dialogbox:
Runtime Error!
Program: c:\Programme\R\R-2.9.0alpha\bin\Rterm.exe
R6034
An application has made an attempt to load the C runtime library 
incorrectly.
Please contact the application's support team for more information.

Best regards
Christian


Uwe Ligges wrote:
> I fear the number of R users under Windows that make use of a non-gcc 
> compiler and is reading this list is quite close to 0. Hence you will 
> probably have to find it out yourself.
>
> Uwe Ligges
>
>
> cstrato wrote:
>> Dear all,
>>
>> For certain reasons I have to compile the source code of my package 
>> on Windows XP using Microsoft Visual Studio 9.0, thus I had to create 
>> a "Makefile.win". Now I have a question regarding compiler options 
>> /MT vs /MD for Makefile.win.
>>
>> The following partial output shows that when building my package on 
>> Windows XP using "R CMD build --binary xps" with compiler option /MT 
>> everything is ok:
>>
>> - - - - - - - -
>>  running src/Makefile.win ...
>> "C:\Programme\Microsoft Visual Studio 9.0\VC\bin/cl" 
>> /I"C:\root/include" /FIw32p
>> ragma.h /MT /EHsc /Ox /D "MSVC" /D "WIN32" /c TStat.cxx
>> Microsoft (R) 32-bit C/C++ Optimizing Compiler Version 15.00.21022.08 
>> for 80x86
>> Copyright (C) Microsoft Corporation.  All rights reserved.
>>
>> TStat.cxx
>>
>>
>> Created c:\home\Rabbitus\CRAN\xps\chm\xps.chm, 166,304 bytes
>> Compression decreased file by 442,728 bytes.
>> ** building package indices ...
>> ** MD5 sums
>> * DONE (xps)
>> * creating vignettes ... OK
>> * cleaning src
>>
>>
>> Created c:\home\Rabbitus\temp\Rbuild210430099\xps\chm\xps.chm, 
>> 166,308 bytes
>> Compression decreased file by 442,724 bytes.
>> ** building package indices ...
>> ** MD5 sums
>> packaged installation of 'xps' as xps_1.3.8.zip
>> * DONE (xps)
>> - - - - - - - -
>>
>> As you see the package was built correctly.
>>
>>
>> However, when I change the compiler option in "Makefile.win" to /MD 
>> the build stops at the following position:
>>
>> - - - - - - - -
>> Created c:\home\Rabbitus\CRAN\xps\chm\xps.chm, 166,306 bytes
>> Compression decreased file by 442,726 bytes.
>> ** building package indices ...
>> ** MD5 sums
>> * DONE (xps)
>> * creating vignettes ...Terminating on signal SIGINT(2)
>> - - - - - - - -
>>
>> As you see I had to terminate the build process manually after 15 min .
>>
>> My question is now:
>> Do you know why I can build my package w/o problems when using option 
>> /MT but not when using option /MD?
>>
>> As a note, I am using "R-2.9.0alpha-win32.exe" which I have 
>> downloaded today.
>>
>> Thank you in advance.
>>
>> Best regards
>> Christian
>> _._._._._._._._._._._._._._._._._._
>> C.h.r.i.s.t.i.a.n   S.t.r.a.t.o.w.a
>> V.i.e.n.n.a           A.u.s.t.r.i.a
>> e.m.a.i.l:        cstrato at aon.at
>> _._._._._._._._._._._._._._._._._._
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From cstrato at aon.at  Thu Apr  2 23:18:47 2009
From: cstrato at aon.at (cstrato)
Date: Thu, 02 Apr 2009 23:18:47 +0200
Subject: [Rd] Compiler options for Makefile.win
In-Reply-To: <d70c15d40904020316q4b6cf5h42b4b9b626d88f9c@mail.gmail.com>
References: <49CFCC79.9090409@aon.at>
	<d70c15d40904020316q4b6cf5h42b4b9b626d88f9c@mail.gmail.com>
Message-ID: <49D52BB7.4020506@aon.at>

Dear Gabor,

Thank you for your suggestion.

I forgot to mention that the build process ended with the following 
dialog box:
Runtime Error!
Program: c:\Programme\R\R-2.9.0alpha\bin\Rterm.exe
R6034
An application has made an attempt to load the C runtime library 
incorrectly.
Please contact the application's support team for more information.

Only after pressing OK there was no response of Rterm and I had to 
terminate the build process manually. I am not sure if this means that 
the build process got into an infinite loop.

Could you explain what you mean with running the vignette "by hand" line 
by line?
How can I do this?

BTW, if the problem is within one of the vignettes, as you mention, I 
assume that the problem may be at the following statements:
\begin{Sinput}
R> library(xps)
\end{Sinput}
<<echo=FALSE>>=
library(xps)
@

I believe that the error occurs when trying to load "library(xps)".

Best regards
Christian


G?bor Cs?rdi wrote:
> On Sun, Mar 29, 2009 at 9:31 PM, cstrato <cstrato at aon.at> wrote:
> [...]
>   
>> - - - - - - - -
>> Created c:\home\Rabbitus\CRAN\xps\chm\xps.chm, 166,306 bytes
>> Compression decreased file by 442,726 bytes.
>> ** building package indices ...
>> ** MD5 sums
>> * DONE (xps)
>> * creating vignettes ...Terminating on signal SIGINT(2)
>> - - - - - - - -
>>
>> As you see I had to terminate the build process manually after 15 min .
>>
>> My question is now:
>> Do you know why I can build my package w/o problems when using option /MT
>> but not when using option /MD?
>>     
>
> It seems that the building process got into an infinite loop while
> creating the vignette. Some code in the vignette/package does not work
> properly. Try running the vignette "by hand" line by line to see where
> the problem is.
>
> Gabor
>
>   
>> As a note, I am using "R-2.9.0alpha-win32.exe" which I have downloaded
>> today.
>>
>> Thank you in advance.
>>
>> Best regards
>> Christian
>> _._._._._._._._._._._._._._._._._._
>> C.h.r.i.s.t.i.a.n   S.t.r.a.t.o.w.a
>> V.i.e.n.n.a           A.u.s.t.r.i.a
>> e.m.a.i.l:        cstrato at aon.at
>> _._._._._._._._._._._._._._._._._._
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>     
>
>
>
>


From kentjin at stat.tamu.edu  Fri Apr  3 03:47:06 2009
From: kentjin at stat.tamu.edu (kentjin at stat.tamu.edu)
Date: Thu, 2 Apr 2009 20:47:06 -0500 (CDT)
Subject: [Rd] Hello! I got error in C - R
Message-ID: <39726.165.91.115.6.1238723226.squirrel@www.stat.tamu.edu>

Hello,
My name is Ick Hoon Jin and I am Ph. D. student in Texas A & M Univ..
When I run the C embedded in R in the Linux system, I confront the
following error after 6,000 iteration. By googling I found this error is
from the problem in C.

*** caught segfault ***
address (nil), cause 'memory not mapped'

My C code is following:

---------------------------------------------------------------------------
#include<stdio.h>
#include<stdlib.h>
#include<R.h>
#include<Rmath.h>
#include<malloc.h>

#define Min(X,Y) ((X) < (Y) ? (X) : (Y))

void SecondMH(int *n, int *X, int *length_X, double *theta_new, int
*n_para, double *out);
int MH_Result(double *theta_new, int n_para, int *M1, int *M2, int n);
double Count_Edges(int *X, int n);
double Cal_GWD(int *X, int n);
int Cal_Degree(int *M3, int n);
double Inner_Product( double *vector1, double *vector2, int length);
int rdtsc();

void SecondMH(int *n, int *X, int *length_X, double *theta_new, int
*n_para, double *out)
{
	int i, j, a, k;
	int *M1, *M2;
	M1 = (int *)calloc(*length_X, sizeof(int));
	M2 = (int *)calloc(*length_X, sizeof(int));

	for(i = 1; i < *n; i++)
	{
		for(j = 0; j < i; j++)
		{
			for(k = 0; k < *length_X; k++ )
			{
				M1[k] = X[k];
				M2[k] = X[k];
			}

			if(X[i * *n + j] == 1)
			{
				M1[i * *n + j] = 0;
				a = MH_Result(theta_new, *n_para, M1, M2, *n);
				if(a == 1)
				{
					X[i * *n + j] = 0;
				}
			}
			else
			{
				M1[i * *n + j] = 1;
				a = MH_Result(theta_new, *n_para, M1, M2, *n);
				if(a == 1)
				{
					X[i * *n + j] = 1;
				}
			}
		}
	}

	for(i = 1; i < *n; i++)
	{
		for(j = 0; j < i; j++)
		{
			X[j * *n + i] = 0;
		}
	}

	for(i = 0; i < *length_X; i++)
	{
		out[i] = (double)X[i];
	}

	free(M1);
	free(M2);

	return;
}

int MH_Result(double *theta_new, int n_para, int *M1, int *M2, int n)
{
	double *M1_STAT, *M2_STAT;
	double pi_Num, pi_Denom, MH_Ratio, v;

	M1_STAT = (double *)calloc( n_para, sizeof( double ) );
	M2_STAT = (double *)calloc( n_para, sizeof( double ) );

	M1_STAT[0] = Count_Edges(M1, n);
	M2_STAT[0] = Count_Edges(M2, n);

	M1_STAT[1] = Cal_GWD(M1, n);
	M2_STAT[1] = Cal_GWD(M2, n);

	pi_Num = Inner_Product(theta_new, M1_STAT, n_para);
	pi_Denom = Inner_Product(theta_new, M2_STAT, n_para);
	MH_Ratio = pi_Num - pi_Denom;

	srand(rdtsc());
	v = (double)rand() / ( (double)RAND_MAX + (double)1 );

	if( log( v ) < Min( 0, MH_Ratio ) )
		return 1;
	else
		return 0;

	free(M1_STAT);
	free(M2_STAT);
}

double Count_Edges(int *X, int n)
{
	double temp;
	int i, j;

	temp = 0;

	for(i = 1; i < n; i++)
	{
		for(j = 0; j < i; j++)
		{
			temp += X[i * n + j];
		}
	}

	return temp;
}

double Cal_GWD(int *X, int n)
{

	int *M3, *Degree, *D_Y;
	int i, j;
	double theta = 0.25;
	double GWD = 0.00;

	M3 = (int *)calloc(n, sizeof(int));
	Degree = (int *)calloc(n, sizeof(int));
	D_Y = (int *)calloc((n - 1), sizeof(int));

	for(i = 0; i < n; i++)
	{
		for(j = 0; j < n; j++)
		{
			M3[j] = X[i * n + j];
		}

		Degree[i] = Cal_Degree(M3, n);
	}

	for(i = 0; i < n - 1; i++)
	{
		D_Y[i] = 0;

		for(j = 0; j < n; j++)
		{
			if(Degree[j] = i + 1)
			{
				D_Y[i] += 1;
			}
		}
	}

	for(i = 0; i < n-1; i++)
	{
			GWD += ( 1 - pow( (1 - exp(theta*(-1))), (i + 1) ) ) * (double)D_Y[i];
	}

	GWD = GWD * exp(theta);

	free(M3);
	free(Degree);
	free(D_Y);

	return GWD;
}

int Cal_Degree(int *M3, int n)
{
	int i, result;

	result = 0;

	for(i = 0; i < n; i++)
	{
		result += M3[i];
	}

	return result;
}

double Inner_Product(double *vector1, double *vector2, int length)
{
	int i;
	double result;

	result = 0;
	for(i = 0; i < length; i++)
	{
		result += vector1[i] * vector2[i];
	}

	return result;
}

int rdtsc()
{
    __asm__ __volatile__("rdtsc");
}
-------------------------------------------------------------------------

and my R-code to call C function is following;

#-------------------------------------------------------------------------------

# Function for Second Gibbs with Metropolis-Hasting Step

#-------------------------------------------------------------------------------

dyn.load("SecondMH.so")

second.MH<-function(Adj.Matrix,theta.new,nodes){

  n<-as.integer(nodes)

  Y<-as.matrix.network(X,matrix.type="adjacency",directed=FALSE)

  Z<-as.integer(as.vector(Y))

  length.Z<-as.integer(length(Z))

  theta.star<-as.double(as.vector(theta.new))

  n.para<-as.integer(length(theta.star))

  result<-.C("SecondMH",n,Z,length.Z,theta.star,n.para,out=as.double(rep(0.0,length.Z)))

  X.new<-matrix(result$out,n,n)
  Adj.Matrix<-network(X.new, directed=FALSE)

  return(Adj.Matrix)}


--------------------------------------------------------------------------

Until this time, I have used only R and I am really a beginner for C
programming. How can I solve the segfault error? Please answer it.
Thank you very much.
Sincerely,



Jin, Ick Hoon
Ph. D. Student, Department of Statistics
Texas A&M University, College Station, TX


From mathieu.ribatet at epfl.ch  Fri Apr  3 08:35:30 2009
From: mathieu.ribatet at epfl.ch (Mathieu Ribatet)
Date: Fri, 03 Apr 2009 08:35:30 +0200
Subject: [Rd] Hello! I got error in C - R
In-Reply-To: <39726.165.91.115.6.1238723226.squirrel@www.stat.tamu.edu>
References: <39726.165.91.115.6.1238723226.squirrel@www.stat.tamu.edu>
Message-ID: <1238740530.3608.4.camel@ubuntu>

Dear Ick Hoon Jin,

Your problem is probably due to a misspecification in memory allocation
within your C code. To solve this you can:

      * check by yourself whenever there is C memory allocation - by the
        way I think it's best to use R memory allocation i.e. R_alloc
      * use valgrind (see Writing R extension for this) as you're under
        Linux and this will give you some guidance to find where the
        problem is.

Best,
Mathieu


Le vendredi 03 avril 2009 ? 03:47 +0200, kentjin at stat.tamu.edu a ?crit :
> Hello,
> My name is Ick Hoon Jin and I am Ph. D. student in Texas A & M Univ..
> When I run the C embedded in R in the Linux system, I confront the
> following error after 6,000 iteration. By googling I found this error is
> from the problem in C.
> 
> *** caught segfault ***
> address (nil), cause 'memory not mapped'
> 
> My C code is following:
> 
> ---------------------------------------------------------------------------
> #include<stdio.h>
> #include<stdlib.h>
> #include<R.h>
> #include<Rmath.h>
> #include<malloc.h>
> 
> #define Min(X,Y) ((X) < (Y) ? (X) : (Y))
> 
> void SecondMH(int *n, int *X, int *length_X, double *theta_new, int
> *n_para, double *out);
> int MH_Result(double *theta_new, int n_para, int *M1, int *M2, int n);
> double Count_Edges(int *X, int n);
> double Cal_GWD(int *X, int n);
> int Cal_Degree(int *M3, int n);
> double Inner_Product( double *vector1, double *vector2, int length);
> int rdtsc();
> 
> void SecondMH(int *n, int *X, int *length_X, double *theta_new, int
> *n_para, double *out)
> {
> 	int i, j, a, k;
> 	int *M1, *M2;
> 	M1 = (int *)calloc(*length_X, sizeof(int));
> 	M2 = (int *)calloc(*length_X, sizeof(int));
> 
> 	for(i = 1; i < *n; i++)
> 	{
> 		for(j = 0; j < i; j++)
> 		{
> 			for(k = 0; k < *length_X; k++ )
> 			{
> 				M1[k] = X[k];
> 				M2[k] = X[k];
> 			}
> 
> 			if(X[i * *n + j] == 1)
> 			{
> 				M1[i * *n + j] = 0;
> 				a = MH_Result(theta_new, *n_para, M1, M2, *n);
> 				if(a == 1)
> 				{
> 					X[i * *n + j] = 0;
> 				}
> 			}
> 			else
> 			{
> 				M1[i * *n + j] = 1;
> 				a = MH_Result(theta_new, *n_para, M1, M2, *n);
> 				if(a == 1)
> 				{
> 					X[i * *n + j] = 1;
> 				}
> 			}
> 		}
> 	}
> 
> 	for(i = 1; i < *n; i++)
> 	{
> 		for(j = 0; j < i; j++)
> 		{
> 			X[j * *n + i] = 0;
> 		}
> 	}
> 
> 	for(i = 0; i < *length_X; i++)
> 	{
> 		out[i] = (double)X[i];
> 	}
> 
> 	free(M1);
> 	free(M2);
> 
> 	return;
> }
> 
> int MH_Result(double *theta_new, int n_para, int *M1, int *M2, int n)
> {
> 	double *M1_STAT, *M2_STAT;
> 	double pi_Num, pi_Denom, MH_Ratio, v;
> 
> 	M1_STAT = (double *)calloc( n_para, sizeof( double ) );
> 	M2_STAT = (double *)calloc( n_para, sizeof( double ) );
> 
> 	M1_STAT[0] = Count_Edges(M1, n);
> 	M2_STAT[0] = Count_Edges(M2, n);
> 
> 	M1_STAT[1] = Cal_GWD(M1, n);
> 	M2_STAT[1] = Cal_GWD(M2, n);
> 
> 	pi_Num = Inner_Product(theta_new, M1_STAT, n_para);
> 	pi_Denom = Inner_Product(theta_new, M2_STAT, n_para);
> 	MH_Ratio = pi_Num - pi_Denom;
> 
> 	srand(rdtsc());
> 	v = (double)rand() / ( (double)RAND_MAX + (double)1 );
> 
> 	if( log( v ) < Min( 0, MH_Ratio ) )
> 		return 1;
> 	else
> 		return 0;
> 
> 	free(M1_STAT);
> 	free(M2_STAT);
> }
> 
> double Count_Edges(int *X, int n)
> {
> 	double temp;
> 	int i, j;
> 
> 	temp = 0;
> 
> 	for(i = 1; i < n; i++)
> 	{
> 		for(j = 0; j < i; j++)
> 		{
> 			temp += X[i * n + j];
> 		}
> 	}
> 
> 	return temp;
> }
> 
> double Cal_GWD(int *X, int n)
> {
> 
> 	int *M3, *Degree, *D_Y;
> 	int i, j;
> 	double theta = 0.25;
> 	double GWD = 0.00;
> 
> 	M3 = (int *)calloc(n, sizeof(int));
> 	Degree = (int *)calloc(n, sizeof(int));
> 	D_Y = (int *)calloc((n - 1), sizeof(int));
> 
> 	for(i = 0; i < n; i++)
> 	{
> 		for(j = 0; j < n; j++)
> 		{
> 			M3[j] = X[i * n + j];
> 		}
> 
> 		Degree[i] = Cal_Degree(M3, n);
> 	}
> 
> 	for(i = 0; i < n - 1; i++)
> 	{
> 		D_Y[i] = 0;
> 
> 		for(j = 0; j < n; j++)
> 		{
> 			if(Degree[j] = i + 1)
> 			{
> 				D_Y[i] += 1;
> 			}
> 		}
> 	}
> 
> 	for(i = 0; i < n-1; i++)
> 	{
> 			GWD += ( 1 - pow( (1 - exp(theta*(-1))), (i + 1) ) ) * (double)D_Y[i];
> 	}
> 
> 	GWD = GWD * exp(theta);
> 
> 	free(M3);
> 	free(Degree);
> 	free(D_Y);
> 
> 	return GWD;
> }
> 
> int Cal_Degree(int *M3, int n)
> {
> 	int i, result;
> 
> 	result = 0;
> 
> 	for(i = 0; i < n; i++)
> 	{
> 		result += M3[i];
> 	}
> 
> 	return result;
> }
> 
> double Inner_Product(double *vector1, double *vector2, int length)
> {
> 	int i;
> 	double result;
> 
> 	result = 0;
> 	for(i = 0; i < length; i++)
> 	{
> 		result += vector1[i] * vector2[i];
> 	}
> 
> 	return result;
> }
> 
> int rdtsc()
> {
>     __asm__ __volatile__("rdtsc");
> }
> -------------------------------------------------------------------------
> 
> and my R-code to call C function is following;
> 
> #-------------------------------------------------------------------------------
> 
> # Function for Second Gibbs with Metropolis-Hasting Step
> 
> #-------------------------------------------------------------------------------
> 
> dyn.load("SecondMH.so")
> 
> second.MH<-function(Adj.Matrix,theta.new,nodes){
> 
>   n<-as.integer(nodes)
> 
>   Y<-as.matrix.network(X,matrix.type="adjacency",directed=FALSE)
> 
>   Z<-as.integer(as.vector(Y))
> 
>   length.Z<-as.integer(length(Z))
> 
>   theta.star<-as.double(as.vector(theta.new))
> 
>   n.para<-as.integer(length(theta.star))
> 
>   result<-.C("SecondMH",n,Z,length.Z,theta.star,n.para,out=as.double(rep(0.0,length.Z)))
> 
>   X.new<-matrix(result$out,n,n)
>   Adj.Matrix<-network(X.new, directed=FALSE)
> 
>   return(Adj.Matrix)}
> 
> 
> --------------------------------------------------------------------------
> 
> Until this time, I have used only R and I am really a beginner for C
> programming. How can I solve the segfault error? Please answer it.
> Thank you very much.
> Sincerely,
> 
> 
> 
> Jin, Ick Hoon
> Ph. D. Student, Department of Statistics
> Texas A&M University, College Station, TX
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
-- 
Institute of Mathematics
Ecole Polytechnique F?d?rale de Lausanne
STAT-IMA-FSB-EPFL, Station 8
CH-1015 Lausanne   Switzerland
http://stat.epfl.ch/
Tel: + 41 (0)21 693 7907


From meyer at rice.edu  Thu Apr  2 16:10:08 2009
From: meyer at rice.edu (meyer at rice.edu)
Date: Thu,  2 Apr 2009 16:10:08 +0200 (CEST)
Subject: [Rd] Problem with LD_LIBRARY_PATH setting in ldpaths (PR#13637)
Message-ID: <20090402141008.B8FA8283430E@mail.pubhealth.ku.dk>


When using R on a linux machine (ubuntu 8.10) which DOES NOT have 
LD_LIBRARY_PATH set (I particularly have it NOT set because it causes 
problems), the script ldpaths will set LD_LIBRARY_PATH to the R Lib path 
(in my case $R_HOME/lib:).  The placement of the colon makes my system 
think that the directory "." is also on that lib path.  This causes real 
problems when trying to run R with a remote mounted file structure (over 
sshfs).  In particular, the initialization time for R is about 20 
seconds, and a simple command like help(package) takes about 10.  It is 
easily amended by not placing the colon at the end of the lib path if it 
is empty first.  Please fix this so other newbies don't have to spend a 
day and a half delving through strace output trying to figure out why 
everything is slow!


--please do not edit the information below--

Version:
 platform = i486-pc-linux-gnu
 arch = i486
 os = linux-gnu
 system = i486, linux-gnu
 status =
 major = 2
 minor = 7.1
 year = 2008
 month = 06
 day = 23
 svn rev = 45970


From maechler at stat.math.ethz.ch  Fri Apr  3 15:20:25 2009
From: maechler at stat.math.ethz.ch (maechler at stat.math.ethz.ch)
Date: Fri,  3 Apr 2009 15:20:25 +0200 (CEST)
Subject: [Rd] actual argument matching does not conform to the
	definition (PR#13634)
Message-ID: <20090403132025.194EE2834318@mail.pubhealth.ku.dk>

>>>>> "vQ" == Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no>
>>>>>     on Thu, 02 Apr 2009 15:25:14 +0200 writes:

    vQ> Thomas Lumley wrote:
    >> 
    >> The explanation is that quote() is a primitive function and that the
    >> argument matching rules do not apply to primitives.  That section of
    >> the R Language definition should say that primitives are excluded;  it
    >> is documented in ?.Primitive.

    vQ> thanks.  indeed, the documentation --  the language *definition* --
    vQ> should make this clear.  so this is a bug in the definition, which does
    vQ> not match the implementation, which in turn is as intended (right?)

    vQ> ?.Primitive says:

    vQ> "     The advantage of '.Primitive' over '.Internal' functions is the
    vQ> potential efficiency of argument passing.  However, this is done
    vQ> by ignoring argument names and using positional matching of
    vQ> arguments (unless arranged differently for specific primitives
    vQ> such as 'rep'), so this is discouraged for functions of more than
    vQ> one argument.
    vQ> "

    vQ> what is discouraged?

Well...  
Wacek, as seem to you want it, and it being Friday afternoon... 
here comes .... 
a biased view of one R hobby historian :

Even though R was created originally in New Zealand and then
heavily picked up in Europe slightly before (North) America,
the development model of R, in my eyes, has been closer to
sentiments of people from the land of the free and home of the
brave, rather than European censorship and dictatorship
{being a full-hearted European, I hope I'm allowed the slight
 exaggeration ;-)}.

Consequently, there has always been quite a bit of freedom in R
development within the R core development team...
and yes, R is not the result of comittee design-process,
but yes, it's good we have members in the core team (and the
wider R developer base) who have called us to make decisions and
try to stand by them .. ;-) :-)

The frequent vs minimal use of .Primitives has been one of the
areas where some R-core members have tried to discourage other
R-core members from "doing too much" ..

Fact is that using *more* .Primitives rather than less during
the last few years has allowed to make  S3 and S4 method
dispatch slightly more uniform and still efficient.
In the long term, ideally we'd diminuish the number of
.Primitives substantially, exactly for reasons some of which you
mention in this thread.

Martin


From jon at restlesslemon.co.uk  Fri Apr  3 16:18:51 2009
From: jon at restlesslemon.co.uk (Jon Senior)
Date: Fri, 3 Apr 2009 16:18:51 +0200
Subject: [Rd] Problem building DLL under Windows
Message-ID: <20090403161851.da78e3b8.jon@restlesslemon.co.uk>

Apologies if this has appeared before, but I've searched the archives and all the documentation and I can't find anything which helps.

I'm trying to build a DLL under windows. The process (more on that later) works fine under Linux and gives the illusion of working under Windows, but attempting to load the resulting DLL using dyn.load results in:

Error in inDL(x, as.logical(local), as.logical(now), ...) :
  unable to load shared library: 'C:/Documents... '
  LoadLibrary failure: Invalid access to memory location.

Searching Google shows that the LoadLibrary message is unique to R (Or no-one else is admitting to it).

The first problem is that the library is actually a wrapper around an existing library to make it usable under R, but the original library is built as a static object (and for reasons of controlling exciting versioning problems, I'd prefer it to stay that way).

Under Linux, I pass the library to gcc using PKG_LIBS=-static lib.a and it builds fine.

Under Windows, I put the following in Makevars.win:
PKG_LIBS -Lc:/Path/To/Library -llib.name
and it builds fine (GCC returns with no errors and I have what appears to be an appropriately sized DLL in the directory).

I've tried passing various flags into gcc, but I really don't know what I'm doing at this point with regard to building under windows (I have a pretty good grasp of how to compile libraries under Linux, and understand the concepts involved in shared libraries. I get the impression however that I'm missing something about Windows DLLs.

Compulsory version information:
OS: Windows XP SP2
R: 2.8.1
GCC: 4.2.1-sjlj (mingw32-2) (From Rtools29.exe)

For the record, I've read http://www.stats.uwo.ca/faculty/murdoch/software/compilingDLLs/readme.packages.txt which hints at some requirement for DLLs to use _cdecl. I've started exploring along this line, but there's a lot of documentation to trawl through to make sense of it all and I don't want to go off chasing a red herring if I just need to pass a special --make-it-work flag to gcc.

In the only thread I found which appeared to have any similarities, Prof. Ripley said that there was a solution (or hint): "It is there, unfortunately along with a lot of uniformed speculation." Of course, the uninformed speculation is still in the archives making it no easier to find no than in August 2007! Perhaps someone who understands this stuff (or has some experience of it) could provide a hint as to how to proceed. :-)

Thanks in advance.

-- 
Jon Senior <jon at restlesslemon.co.uk>


From marc_schwartz at me.com  Fri Apr  3 18:12:55 2009
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 03 Apr 2009 11:12:55 -0500
Subject: [Rd] Possible bug in summary.survfit - 'scale' argument ignored?
In-Reply-To: <Pine.LNX.4.43.0904010508140.29619@hymn14.u.washington.edu>
References: <Pine.LNX.4.43.0904010508140.29619@hymn14.u.washington.edu>
Message-ID: <7DFD4EFF-6A19-46A9-A981-23101B1882A5@me.com>

On Apr 1, 2009, at 7:08 AM, Thomas Lumley wrote:

>
> I've sent a fixed version 2.35-4 to CRAN.  It turned out to be a  
> fairly simple change.
>
>    -thomas

Thomas,

Apologies for the delay in my reply. I am on vacation and will only  
have sporadic e-mail access thru mid-next week.

I noted the fix that you made and it is indeed pretty simple. I do  
have one comment/question however.

It would seem that the nature of the interaction between the 'scale'  
and 'times' arguments has now changed with this update. Presumably as  
a result of the transform taking place at the beginning of the old  
version as opposed to being at the end of the new function.

For example, using the prior version of survival included with R 2.8.1  
(2.34-1):

# Get the summary output in months (eg. days / 30.44)
# Note that 'times' is in the 'scale' transformed based time interval  
(0:21 months)

 > summary( survfit( Surv(futime, fustat)~1, data=ovarian), scale =  
30.44, times = 0:21)
Call: survfit(formula = Surv(futime, fustat) ~ 1, data = ovarian)

  time n.risk n.event survival std.err lower 95% CI upper 95% CI
     0     26       0    1.000  0.0000        1.000        1.000
     1     26       0    1.000  0.0000        1.000        1.000
     2     25       1    0.962  0.0377        0.890        1.000
     3     25       0    0.962  0.0377        0.890        1.000
     4     24       1    0.923  0.0523        0.826        1.000
     5     24       0    0.923  0.0523        0.826        1.000
     6     23       1    0.885  0.0627        0.770        1.000
     7     23       0    0.885  0.0627        0.770        1.000
     8     23       0    0.885  0.0627        0.770        1.000
     9     22       1    0.846  0.0708        0.718        0.997
    10     22       0    0.846  0.0708        0.718        0.997
    11     21       1    0.808  0.0773        0.670        0.974
    12     19       2    0.731  0.0870        0.579        0.923
    13     18       0    0.731  0.0870        0.579        0.923
    14     17       0    0.731  0.0870        0.579        0.923
    15     15       1    0.688  0.0919        0.529        0.894
    16     12       2    0.596  0.0999        0.429        0.828
    17     12       0    0.596  0.0999        0.429        0.828
    18     12       0    0.596  0.0999        0.429        0.828
    19     11       1    0.546  0.1032        0.377        0.791
    20     11       0    0.546  0.1032        0.377        0.791
    21     10       1    0.497  0.1051        0.328        0.752


However, in the new version:

 > summary( survfit( Surv(futime, fustat)~1, data=ovarian), scale =  
30.44, times = 0:21)
Call: survfit(formula = Surv(futime, fustat) ~ 1, data = ovarian)

    time n.risk n.event survival std.err lower 95% CI upper 95% CI
  0.0000     26       0        1       0            1            1
  0.0329     26       0        1       0            1            1
  0.0657     26       0        1       0            1            1
  0.0986     26       0        1       0            1            1
  0.1314     26       0        1       0            1            1
  0.1643     26       0        1       0            1            1
  0.1971     26       0        1       0            1            1
  0.2300     26       0        1       0            1            1
  0.2628     26       0        1       0            1            1
  0.2957     26       0        1       0            1            1
  0.3285     26       0        1       0            1            1
  0.3614     26       0        1       0            1            1
  0.3942     26       0        1       0            1            1
  0.4271     26       0        1       0            1            1
  0.4599     26       0        1       0            1            1
  0.4928     26       0        1       0            1            1
  0.5256     26       0        1       0            1            1
  0.5585     26       0        1       0            1            1
  0.5913     26       0        1       0            1            1
  0.6242     26       0        1       0            1            1
  0.6570     26       0        1       0            1            1
  0.6899     26       0        1       0            1            1


It would appear that 'times' are 0:21 days, but as fractions of a month:

 > (0:21) / 30.44
  [1] 0.00000000 0.03285151 0.06570302 0.09855453 0.13140604 0.16425756
  [7] 0.19710907 0.22996058 0.26281209 0.29566360 0.32851511 0.36136662
[13] 0.39421813 0.42706965 0.45992116 0.49277267 0.52562418 0.55847569
[19] 0.59132720 0.62417871 0.65703022 0.68988173


To get the same output as in the prior version:

 > summary( survfit( Surv(futime, fustat)~1, data=ovarian), scale =  
30.44, times = (0:21) * 30.44)
Call: survfit(formula = Surv(futime, fustat) ~ 1, data = ovarian)

  time n.risk n.event survival std.err lower 95% CI upper 95% CI
     0     26       0    1.000  0.0000        1.000        1.000
     1     26       0    1.000  0.0000        1.000        1.000
     2     25       1    0.962  0.0377        0.890        1.000
     3     25       0    0.962  0.0377        0.890        1.000
     4     24       1    0.923  0.0523        0.826        1.000
     5     24       0    0.923  0.0523        0.826        1.000
     6     23       1    0.885  0.0627        0.770        1.000
     7     23       0    0.885  0.0627        0.770        1.000
     8     23       0    0.885  0.0627        0.770        1.000
     9     22       1    0.846  0.0708        0.718        0.997
    10     22       0    0.846  0.0708        0.718        0.997
    11     21       1    0.808  0.0773        0.670        0.974
    12     19       2    0.731  0.0870        0.579        0.923
    13     18       0    0.731  0.0870        0.579        0.923
    14     17       0    0.731  0.0870        0.579        0.923
    15     15       1    0.688  0.0919        0.529        0.894
    16     12       2    0.596  0.0999        0.429        0.828
    17     12       0    0.596  0.0999        0.429        0.828
    18     12       0    0.596  0.0999        0.429        0.828
    19     11       1    0.546  0.1032        0.377        0.791
    20     11       0    0.546  0.1032        0.377        0.791
    21     10       1    0.497  0.1051        0.328        0.752


Truth be told, the help for summary.survfit() is not explicit on this  
point, but presumably, there is much code out in the wild based upon  
the prior behavior.

I hope this is helpful.

Regards,

Marc


From simon.urbanek at r-project.org  Fri Apr  3 18:36:00 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 3 Apr 2009 12:36:00 -0400
Subject: [Rd] Problem building DLL under Windows
In-Reply-To: <20090403161851.da78e3b8.jon@restlesslemon.co.uk>
References: <20090403161851.da78e3b8.jon@restlesslemon.co.uk>
Message-ID: <4D3B62AC-A4A6-4343-9693-831A5A71CBF1@r-project.org>

Jon,

On Apr 3, 2009, at 10:18 , Jon Senior wrote:

> Apologies if this has appeared before, but I've searched the  
> archives and all the documentation and I can't find anything which  
> helps.
>
> I'm trying to build a DLL under windows. The process (more on that  
> later) works fine under Linux and gives the illusion of working  
> under Windows, but attempting to load the resulting DLL using  
> dyn.load results in:
>
> Error in inDL(x, as.logical(local), as.logical(now), ...) :
>  unable to load shared library: 'C:/Documents... '
>  LoadLibrary failure: Invalid access to memory location.
>
> Searching Google shows that the LoadLibrary message is unique to R  
> (Or no-one else is admitting to it).
>
> The first problem is that the library is actually a wrapper around  
> an existing library to make it usable under R, but the original  
> library is built as a static object (and for reasons of controlling  
> exciting versioning problems, I'd prefer it to stay that way).
>
> Under Linux, I pass the library to gcc using PKG_LIBS=-static lib.a  
> and it builds fine.
>

That is true only for very specific architectures and OS combinations  
but not on most systems (including Linux). Shared objects must be  
compiled to contain position-independent code (PIC) such that they can  
be re-located when loaded dynamically. In general you cannot use a  
static library in a package unless the library was specifically  
compiled with -fPIC.

Also please note that the above is possibly not what you want: -static  
is not an option that applies to the library - it's a global option  
for the linker which affects *all* libraries and possibly even the crt  
code and compiler-related libraries (this depends on the platform). It  
may cause additional problems since you may need to link R library  
dynamically. All this is not related to Windows - this applies in  
general on any platform (including Linux).


> Under Windows, I put the following in Makevars.win:
> PKG_LIBS -Lc:/Path/To/Library -llib.name
> and it builds fine (GCC returns with no errors and I have what  
> appears to be an appropriately sized DLL in the directory).
>
> I've tried passing various flags into gcc, but I really don't know  
> what I'm doing at this point with regard to building under windows  
> (I have a pretty good grasp of how to compile libraries under Linux,  
> and understand the concepts involved in shared libraries. I get the  
> impression however that I'm missing something about Windows DLLs.
>

See above, this may not be DLL-specific. Additionally, please make  
sure you're using the right tools (MinGW gcc) for both your static  
library and the package (you have indicated the you do, but just  
making sure :))..
I have tested a toy example with your setup and all was working just  
fine, so for further help you may have to reveal exactly what library  
you are using etc. since the devil may be in the details (if the  
general advice above doesn't help).


> Compulsory version information:
> OS: Windows XP SP2
> R: 2.8.1
> GCC: 4.2.1-sjlj (mingw32-2) (From Rtools29.exe)
>
> For the record, I've read http://www.stats.uwo.ca/faculty/murdoch/software/compilingDLLs/readme.packages.txt 
>  which hints at some requirement for DLLs to use _cdecl. I've  
> started exploring along this line, but there's a lot of  
> documentation to trawl through to make sense of it all and I don't  
> want to go off chasing a red herring if I just need to pass a  
> special --make-it-work flag to gcc.
>

AFAICS that is only mentioned with respect to VC - the current tools  
are smart enough with gcc. There are some issues when importing  
variables from R itself, but that should not be related to your code  
(unless you use this feature outside of the standard R headers).

Cheers,
Simon


> In the only thread I found which appeared to have any similarities,  
> Prof. Ripley said that there was a solution (or hint): "It is there,  
> unfortunately along with a lot of uniformed speculation." Of course,  
> the uninformed speculation is still in the archives making it no  
> easier to find no than in August 2007! Perhaps someone who  
> understands this stuff (or has some experience of it) could provide  
> a hint as to how to proceed. :-)
>
> Thanks in advance.
>
> -- 
> Jon Senior <jon at restlesslemon.co.uk>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From kelley.dan at gmail.com  Fri Apr  3 19:53:26 2009
From: kelley.dan at gmail.com (Dan Kelley)
Date: Fri, 3 Apr 2009 10:53:26 -0700 (PDT)
Subject: [Rd] Error in par(split.screens[[n]]) : parameter "i" in "mfg" is
 out of range
Message-ID: <22873439.post@talk.nabble.com>


I'm working on my 'oce' package, trying split.screen() instead of par(mfrow). 
My code is too long to post, and I hope it's ok that I ask this question
without doing so.

My code seems to work fine when I source() it, but when I do "R CMD check"
on my package, I get the error that I've put as the subject line, when it
runs examples.

If I comment out the plot() commands from my examples, and build the
package, then I can run those examples (with the plot() uncommented) from
the commandline, with no problems.  And I can run them from the console.  I
don't actually understand the error, although I can see that it is occurring
in a call to screen().

Has anyone else run across this?  Is there a trick I should employ, e.g.
making my package depend on the graphics package or setting up a virtual
device of some type for use in the building process?

PS. This is on OS X with the 2.8.1 version of R.
-- 
View this message in context: http://www.nabble.com/Error-in-par%28split.screens--n--%29-%3A-parameter-%22i%22-in-%22mfg%22-is-out-of-range-tp22873439p22873439.html
Sent from the R devel mailing list archive at Nabble.com.


From jon at restlesslemon.co.uk  Fri Apr  3 20:02:21 2009
From: jon at restlesslemon.co.uk (Jon Senior)
Date: Fri, 3 Apr 2009 20:02:21 +0200
Subject: [Rd] Problem building DLL under Windows
In-Reply-To: <4D3B62AC-A4A6-4343-9693-831A5A71CBF1@r-project.org>
References: <20090403161851.da78e3b8.jon@restlesslemon.co.uk>
	<4D3B62AC-A4A6-4343-9693-831A5A71CBF1@r-project.org>
Message-ID: <20090403200221.49a1901d.jon@restlesslemon.co.uk>

On Fri, 3 Apr 2009 12:36:00 -0400
Simon Urbanek <simon.urbanek at r-project.org> wrote:

> That is true only for very specific architectures and OS combinations  
> but not on most systems (including Linux). Shared objects must be  
> compiled to contain position-independent code (PIC) such that they can  
> be re-located when loaded dynamically. In general you cannot use a  
> static library in a package unless the library was specifically  
> compiled with -fPIC.

It was indeed compiled with -fPIC on Linux. I had forgotten that and wonder if it might be related.
 
> Also please note that the above is possibly not what you want: -static  
> is not an option that applies to the library - it's a global option  
> for the linker which affects *all* libraries and possibly even the crt  
> code and compiler-related libraries (this depends on the platform). It  
> may cause additional problems since you may need to link R library  
> dynamically. All this is not related to Windows - this applies in  
> general on any platform (including Linux).

AFAICT -static can be used to force inclusion of a library statically. It may not be the case, the bulk of my coding experience is in Java, not wrapping esoteric functions in to R-callable C code! :-) Strangely though, it seems to work fine. I'll have to do some more tinkering to see if it can forced into a single build, rather than a 2-stage one. 

> See above, this may not be DLL-specific. Additionally, please make  
> sure you're using the right tools (MinGW gcc) for both your static  
> library and the package (you have indicated the you do, but just  
> making sure :))..

Checked and doubled checked. It's a clean installation of XP running under QEMU and has nothing but R and Rtools installed.

> I have tested a toy example with your setup and all was working just  
> fine, so for further help you may have to reveal exactly what library  
> you are using etc. since the devil may be in the details (if the  
> general advice above doesn't help).

OK. Since my previous mail, I discovered the pedump tool, and found that both pedump and objdump will segfault (So it appears, Windoze doesn't give enough information to be sure!) if I attempt to retrieve the Ordinal table from the freshly compiled DLL. This suggests that something is going awry during the second stage of the build (since I can retrieve the same information from the .lib file).

The problem with adding more details is the nature of the work. At the minute, I'm obliged to keep the fine details secret. I had a feeling that this might have been the case, but I thought it was worth seeing if someone had already encountered this and solved it in a different specific case.

> AFAICS that is only mentioned with respect to VC - the current tools  
> are smart enough with gcc. There are some issues when importing  
> variables from R itself, but that should not be related to your code  
> (unless you use this feature outside of the standard R headers).

OK.

Thanks for your help. Looks like the next step is probably going to be combining both compilation steps into a single Makefile. I really hate Makefiles! :-(

-- 
Jon Senior <jon at restlesslemon.co.uk>


From fjbuch at gmail.com  Sat Apr  4 00:45:40 2009
From: fjbuch at gmail.com (Farrel Buchinsky)
Date: Fri, 3 Apr 2009 18:45:40 -0400
Subject: [Rd] RGoogleDocs so close but errors with spreadsheet reading
In-Reply-To: <49D411C9.9080003@wald.ucdavis.edu>
References: <bd93cdad0904011536n5fca90felb5896956c29721c7@mail.gmail.com>
	<49D411C9.9080003@wald.ucdavis.edu>
Message-ID: <bd93cdad0904031545k496138behf451ffa2e781fcc2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090403/baaa6829/attachment.pl>

From kelley.dan at gmail.com  Sat Apr  4 01:41:29 2009
From: kelley.dan at gmail.com (Dan Kelley)
Date: Fri, 3 Apr 2009 16:41:29 -0700 (PDT)
Subject: [Rd] Error in par(split.screens[[n]]) : parameter "i" in "mfg"
 is out of range
In-Reply-To: <22873439.post@talk.nabble.com>
References: <22873439.post@talk.nabble.com>
Message-ID: <22878253.post@talk.nabble.com>


As a followup, in case this is of use to others, I got my code working by
altering R-2.8.1/src/library/graphics/R/screen.R slightly, removing the sole
reference to "mfg", as follows.


assign("par.list",
       c("xlog","ylog",
         "adj", "bty", "cex", "col", "crt", "err", "font", "lab",
         "las", "lty", "lwd", "mar", "mex",
         ##"mfg",                                                                                
         "mgp", "pch",
         "pty", "smo", "srt", "tck", "usr", "xaxp", "xaxs", "xaxt", "xpd",
         "yaxp", "yaxs", "yaxt", "fig"), envir=.SSenv)

-- 
View this message in context: http://www.nabble.com/Error-in-par%28split.screens--n--%29-%3A-parameter-%22i%22-in-%22mfg%22-is-out-of-range-tp22873439p22878253.html
Sent from the R devel mailing list archive at Nabble.com.


From kelley.dan at gmail.com  Sat Apr  4 16:39:25 2009
From: kelley.dan at gmail.com (Dan Kelley)
Date: Sat, 4 Apr 2009 07:39:25 -0700 (PDT)
Subject: [Rd]  split.screen bug and patch
Message-ID: <22884064.post@talk.nabble.com>


I hope it's OK to post a bug report, and a possible patch, on this list.

Introduction
=======

The split.screen() docs suggest that users should not return to a screen
after it has been drawn, and that curious errors may result from doing so. 
This is clear from the test file I put below.  However, I have found that
this test file will work properly, with a tiny change to the split.screen
code.  I am posting this here in case it might help others.  (Certainly, I
make no claim that this solves a general problem with split.screen, but baby
steps are steps, nonetheless.)

The test file draws red lines in the wrong place, unless f=0.5.  But it
works OK after the split.screen code is edited as given in the last section
of this email.

Test file
=====

close.screen(all.screens=TRUE)
f <- 0.7                                # works only if f=0.5
split.screen(matrix(c(0,f,0,1, f,1,0,1), nrow=2, byrow=TRUE))
screen(1)
plot(1:10, 1:10)
screen(2)
plot(1:3, 1:3)
screen(1,FALSE)
abline(h=6,col='red')
abline(v=6,col='red')


Code change
========

Near the start of src/library/graphics/R/screen.R edit the assign() to look
as follows.  The addition solves the problem of the test file, and the
deletion solves a problem in building packages that use split.screen().

assign("par.list",
       c("xlog","ylog",
         "adj", "bty", "cex", "col", "crt", "err", "font", "lab",
         "las", "lty", "lwd", "mar", "mex",
         "fin", ## added                                                        
         ## "mfg", ## deleted                                                   
         "mgp", "pch",
         "pty", "smo", "srt", "tck", "usr",
         "xaxp", "xaxs", "xaxt", "xpd",
         "yaxp", "yaxs", "yaxt", "fig"), envir=.oceSSenv)

-- 
View this message in context: http://www.nabble.com/split.screen-bug-and-patch-tp22884064p22884064.html
Sent from the R devel mailing list archive at Nabble.com.


From ggrothendieck at gmail.com  Sat Apr  4 16:51:19 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 4 Apr 2009 10:51:19 -0400
Subject: [Rd] suggestion: default v.names in reshape
Message-ID: <971536df0904040751t75fa280ic6e2a5c4fccfafbe@mail.gmail.com>

For reshape(dir = "long", varying = list(...), ...)

it would be convenient if the names of the varying
list, if supplied, were used as the default v.names.
Currently they are ignored.

Thus one would be able to write:

# test data frame
d <- structure(list(V.1 = 1:10, V.2 = c(1L, 1L, 1L, 1L, 1L, 2L, 2L,
2L, 2L, 2L), V.3 = 101:110, V.4 = 201:210, V.5 = 301:310, V.6 = 9101:9110,
    V.7 = 9201:9210, V.8 = 9301:9310), row.names = c(NA, -10L
), class = "data.frame", .Names = c("V.1", "V.2", "V.3", "V.4",
"V.5", "V.6", "V.7", "V.8"))

# proposed
reshape(d, dir = "long", varying = list(A = 3:5, B = 6:8))

# as opposed to

# current
reshape(d, dir = "long", varying = list(3:5, 6:8), v.names = c("A", "B"))

which eliminates the need for one argument and makes it more
obvious what the correspondence is between the v.names and
the varying variables.

The old way could still work too so it would be backward
compatible.


From kushler at oakland.edu  Sat Apr  4 19:15:17 2009
From: kushler at oakland.edu (kushler at oakland.edu)
Date: Sat,  4 Apr 2009 19:15:17 +0200 (CEST)
Subject: [Rd] summary for negative binomial GLMs (PR#13640)
Message-ID: <20090404171517.73D7D282EFF6@mail.pubhealth.ku.dk>

Full_Name: Robert Kushler
Version: 2.7.2
OS: Windows XP
Submission from: (NULL) (69.246.102.98)


I believe that the negative binomial family (from MASS) should be added to the
list for which dispersion is set to 1.


From edd at debian.org  Sat Apr  4 20:11:51 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 4 Apr 2009 13:11:51 -0500
Subject: [Rd] R-alpha/R-beta builds on Alpha platform failing with compiler
	error
Message-ID: <18903.41703.731571.693110@ron.nulle.part>


Per https://buildd.debian.org/build.php?pkg=r-base, we see the Alpha platform
having trouble with deriv.c :

gcc     -I. -I../../src/include -I../../src/include  -DHAVE_CONFIG_H  -mieee-with-inexact -fpic  -std=gnu99 -O3 -pipe  -g -c deriv.c -o deriv.o
deriv.c: In function 'simplify':
deriv.c:267: error: unrecognizable insn:
(insn 2103 64 65 9 ../../src/include/Rinlinedfuns.h:86 (set (reg:DI 2 $2)
        (const:DI (plus:DI (label_ref:DI 68)
                (const_int 24 [0x18])))) -1 (insn_list:REG_LABEL_OPERAND 68 (nil)))
deriv.c:267: internal compiler error: in extract_insn, at recog.c:2001
Please submit a full bug report,
with preprocessed source if appropriate.
See <file:///usr/share/doc/gcc-4.3/README.Bugs> for instructions.
make[4]: *** [deriv.o] Error 1

This could of course be a bug in gcc.  Does anybody have insights into
anything that may have changed here? 

Dirk

-- 
Three out of two people have difficulties with fractions.


From p.dalgaard at biostat.ku.dk  Sat Apr  4 23:21:15 2009
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat, 04 Apr 2009 23:21:15 +0200
Subject: [Rd] R-alpha/R-beta builds on Alpha platform failing with
 compiler error
In-Reply-To: <18903.41703.731571.693110@ron.nulle.part>
References: <18903.41703.731571.693110@ron.nulle.part>
Message-ID: <49D7CF4B.2000809@biostat.ku.dk>

Dirk Eddelbuettel wrote:
> Per https://buildd.debian.org/build.php?pkg=r-base, we see the Alpha platform
> having trouble with deriv.c :
> 
> gcc     -I. -I../../src/include -I../../src/include  -DHAVE_CONFIG_H  -mieee-with-inexact -fpic  -std=gnu99 -O3 -pipe  -g -c deriv.c -o deriv.o
> deriv.c: In function 'simplify':
> deriv.c:267: error: unrecognizable insn:
> (insn 2103 64 65 9 ../../src/include/Rinlinedfuns.h:86 (set (reg:DI 2 $2)
>         (const:DI (plus:DI (label_ref:DI 68)
>                 (const_int 24 [0x18])))) -1 (insn_list:REG_LABEL_OPERAND 68 (nil)))
> deriv.c:267: internal compiler error: in extract_insn, at recog.c:2001
> Please submit a full bug report,
> with preprocessed source if appropriate.
> See <file:///usr/share/doc/gcc-4.3/README.Bugs> for instructions.
> make[4]: *** [deriv.o] Error 1
> 
> This could of course be a bug in gcc.  Does anybody have insights into
> anything that may have changed here? 

I think it is by definition a bug in gcc...

It is usually rather hopeless to work around this sort of issue by 
source code changes. Have you tried reducing the optimization level?

> 
> Dirk
> 


-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From edd at debian.org  Sat Apr  4 23:34:16 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 4 Apr 2009 16:34:16 -0500
Subject: [Rd] R-alpha/R-beta builds on Alpha platform failing with
 compiler error
In-Reply-To: <49D7CF4B.2000809@biostat.ku.dk>
References: <18903.41703.731571.693110@ron.nulle.part>
	<49D7CF4B.2000809@biostat.ku.dk>
Message-ID: <18903.53848.986239.317607@ron.nulle.part>


On 4 April 2009 at 23:21, Peter Dalgaard wrote:
| Dirk Eddelbuettel wrote:
| > Per https://buildd.debian.org/build.php?pkg=r-base, we see the Alpha platform
| > having trouble with deriv.c :
| > 
| > gcc     -I. -I../../src/include -I../../src/include  -DHAVE_CONFIG_H  -mieee-with-inexact -fpic  -std=gnu99 -O3 -pipe  -g -c deriv.c -o deriv.o
| > deriv.c: In function 'simplify':
| > deriv.c:267: error: unrecognizable insn:
| > (insn 2103 64 65 9 ../../src/include/Rinlinedfuns.h:86 (set (reg:DI 2 $2)
| >         (const:DI (plus:DI (label_ref:DI 68)
| >                 (const_int 24 [0x18])))) -1 (insn_list:REG_LABEL_OPERAND 68 (nil)))
| > deriv.c:267: internal compiler error: in extract_insn, at recog.c:2001
| > Please submit a full bug report,
| > with preprocessed source if appropriate.
| > See <file:///usr/share/doc/gcc-4.3/README.Bugs> for instructions.
| > make[4]: *** [deriv.o] Error 1
| > 
| > This could of course be a bug in gcc.  Does anybody have insights into
| > anything that may have changed here? 
| 
| I think it is by definition a bug in gcc...
| 
| It is usually rather hopeless to work around this sort of issue by 
| source code changes. Have you tried reducing the optimization level?

No, not yet. Let me try that for the next beta. Change made.

Dirk

-- 
Three out of two people have difficulties with fractions.


From saptarshi.guha at gmail.com  Sun Apr  5 15:26:40 2009
From: saptarshi.guha at gmail.com (Saptarshi Guha)
Date: Sun, 5 Apr 2009 09:26:40 -0400
Subject: [Rd] RJava question(class not found with rJava's vm,
	though found with 	alternate vm)
Message-ID: <1e7471d50904050626k789e6782mc6ecbcc44d45dfa6@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090405/7541728b/attachment.pl>

From simon.urbanek at r-project.org  Sun Apr  5 16:12:02 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sun, 5 Apr 2009 10:12:02 -0400
Subject: [Rd] RJava question(class not found with rJava's vm,
	though found with 	alternate vm)
In-Reply-To: <1e7471d50904050626k789e6782mc6ecbcc44d45dfa6@mail.gmail.com>
References: <1e7471d50904050626k789e6782mc6ecbcc44d45dfa6@mail.gmail.com>
Message-ID: <19E1F61B-C62C-489F-ABA4-2FAF5314B0B0@r-project.org>


On Apr 5, 2009, at 9:26 AM, Saptarshi Guha wrote:

> Not sure if this the right place, but I can't seem to subscribe to  
> the rJava
> mailing list. Sorry for the noise.
>

The correct mailing list is stats-rosuda-devel:
http://mailman.rz.uni-augsburg.de/mailman/listinfo/stats-rosuda-devel

(The rJava mailing list was a test but it turned out that everyone is  
still using stats-rosuda-devel so the idea of a separate list was  
abandoned).


> I have a jar file in the CLASSPATH variable. On running .jinit and  
> checking .jclassPath, i can see the jar file containing the class.  
> Yet when trying to instantaite the class, i get a class not found  
> error.
>

Can you, please, send me the exact code you're using? (I.e. exactly  
the value of CLASSPATH, your platform, how you started R and  
initialized rJava and what you tried to do to load the class).

A side note - preferably you should not be using the CLASSPATH  
environment variable, because that is very limited and doesn't work if  
you have multiple packages using Java. Instead use .jinit or .jpackage  
(under the hood CLASSPATH gets converted but that is for compatibility  
only).


> Now If if, create my own vm (see below), and then run .jinit (which  
> will use my vm), i can find the class in question  
> (org.apache.hadoop.io.longwritable)
>
> Is there some classloader problem in rJava?
>

No, more likely that your code is using the wrong class loader for  
loading files. The code below sets the path in the system class loader  
but that is not the loader used by R code. Since R needs to modify the  
class path on the fly (as packages are loaded) it uses its own class  
loader. It seems as if you are bypassing that loader and thus running  
into problems (without exact details we can't tell for sure).

Cheers,
Simon



> ==code==
> void create_vm(const char *clap) {
>  char* classpath = (char*) calloc(18+strlen(clap)+1, sizeof(char));
>  sprintf(classpath,"-Djava.class.path=%s",clap);
>  JavaVMInitArgs args;
>  JavaVMOption options[2];
>  args.version = JNI_VERSION_1_4;
>  args.nOptions = 2;
>  options[0].optionString = classpath;
>  options[1].optionString = "-Xrs";
>  args.options = options;
>  args.ignoreUnrecognized = JNI_TRUE;
>  JavaVM *jvms[32];
>  jsize vms=0;
>  int r=0;
>  r=JNI_GetCreatedJavaVMs(jvms, 32, &vms);
>  if (r) {
>    error("JNI_GetCreatedJavaVMs returned %d\n", r);
>  } else {
>    if (vms>0) {
>      int i=0;
>      while (i<vms) {
>    if (jvms[i]) {
>      if (!(*jvms[i])->AttachCurrentThread(jvms[i], (void**)&jenv,  
> NULL)) {
>        jvm=jvms[i];
>        break;
>      }
>    }
>    i++;
>      }
>      if (i==vms) error("Failed to attach to any existing JVM.");
>    }else {
>        JNI_CreateJavaVM(&jvm, (void **)&jenv, &args);
>      }
>    }
>  }
>
>
> Saptarshi Guha
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From saptarshi.guha at gmail.com  Sun Apr  5 20:36:10 2009
From: saptarshi.guha at gmail.com (Saptarshi Guha)
Date: Sun, 5 Apr 2009 14:36:10 -0400
Subject: [Rd] RJava question(class not found with rJava's vm,
	though found 	with alternate vm)
In-Reply-To: <19E1F61B-C62C-489F-ABA4-2FAF5314B0B0@r-project.org>
References: <1e7471d50904050626k789e6782mc6ecbcc44d45dfa6@mail.gmail.com>
	<19E1F61B-C62C-489F-ABA4-2FAF5314B0B0@r-project.org>
Message-ID: <1e7471d50904051136yb75187n84f92c9c7648e477@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090405/5553fb25/attachment.pl>

From bolker at ufl.edu  Mon Apr  6 20:21:38 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Mon, 6 Apr 2009 18:21:38 +0000 (UTC)
Subject: [Rd] summary for negative binomial GLMs (PR#13640)
References: <20090404171517.73D7D282EFF6@mail.pubhealth.ku.dk>
Message-ID: <loom.20090406T175943-439@post.gmane.org>

 <kushler <at> oakland.edu> writes:

> 
> Full_Name: Robert Kushler
> Version: 2.7.2
> OS: Windows XP
> Submission from: (NULL) (69.246.102.98)
> 
> I believe that the negative binomial family (from MASS) should be 
> added to the
> list for which dispersion is set to 1.

  Could you please clarify? In what procedures, under what
circumstances?  Sounds like you mean l. 573 of glm.R:

if(object$family$family %in% c("poisson", "binomial"))  1

  The use case here is using negative.binomial with a fixed 
theta parameter, right?  Using glm.nb takes care of this problem
(it produces an object of class "negbin": MASS:::summary.negbin
shows that the dispersion gets set to 1 here).

   I guess there's a little bit of a jurisdictional
argument here, since the negative.binomial family is
in MASS, and summary.glm is in base R ... also, there's
a bit of a challenge in figuring out the test, because
object$family$family is not a fixed string for negative
binomial-family objects (e.g. "Negative Binomial(0.4)"
in the example below) -- I'm not sure of the cleanest
way to detect this case.

   I think I agree with you, but it would help to present
your case in more detail ...

  Ben Bolker

====================
Example:

x <- rep(seq(0,23,by=1),50)
s <- rep(seq(1,2,length=50*24),1)

tmp2 <- data.frame(y=rnbinom(length(s),
                    mu=8*(sin(2*pi*x/24)+2),size = 0.4),x=factor(x),s=s)

library(MASS)
tmp.glm.nb2 <- glm.nb(y~factor(x)-1 +offset(log(s)),data = tmp2)
summary(tmp.glm.nb2)
## summary.negbin takes care of this case

tmp.glm.nb3 <- glm(y~factor(x)-1 +offset(log(s)),data = tmp2,
                   family=negative.binomial(theta=0.4))

summary(tmp.glm.nb3)


From anders at ebi.ac.uk  Mon Apr  6 22:24:21 2009
From: anders at ebi.ac.uk (Simon Anders)
Date: Mon, 06 Apr 2009 21:24:21 +0100
Subject: [Rd] Possible bug: How does libR.so find RHOME?
Message-ID: <49DA64F5.7080602@ebi.ac.uk>

Hi

While installing RPy2, I had curious problems which, if I traced them
back correctly, have their root in the way that libR.so find the R
installation directory. I wonder if this might be a subtle bug that only
causes problems when one has several versions of R on one system but
then can be very annoying and cause very strange behaviour.

It seems to me that libR.so asks the Unix shell to execute "R RHOME" or
something similar, and this causes problems, as detailed below.

We have several R installations on our server (a CentOS Linux, version
4.6, x86_64 machine), and in my shell environment, the symlink "R" that
is found in the system search path points to a static build of R-2.8.1,
while the symlink "R-2.9" points to today's R-2.9.beta, built with
'--enable-shlib'. (What follows is true, however, for R 2.8.1, built as
a library, as well.)

The setup.py script of RPy2 calls "R RHOME" to find R and then compiles
its C code to a shared object that is linked to libR.so. It uses the
'-R' linker option to store the full path to libR.so.

As "R RHOME" would have returned the path to my static R-2.8
installation, I specified the RHOME path to my R-2.9 library build
explicitly to RPy2's setup.py by means of an environment variable that
is checked by the script. This resulted in an RPy2 installation properly
linked to my R-2.9.

However, on starting RPy2 in Python, I got this strange error:

  >>> from rpy2 import robjects
  Error in grep("(_US|_CA)", lcpaper) :
    8 arguments passed to .Internal(grep) which requires 9
  [...]

RPy2 started up nevertheless, but failed to load the base packages, so
that all standard functions were missing.

Changing the "R" symlink in my search path to point to the R-2.9 version
against which RPy2 is linked solved the problem. It seems that, before,
the R-2.9 libR.so tried to load the base environment of R-2.8, because
R-2.8 was in the search path.

As a further check, I put an empty script called "R" that does nothing
into the search path. Then I get this:

   >>> from rpy2 import robjects
   cannot find system Renviron
   Fatal error: unable to open the base package

My guess is that it is libR.so (and not RPy2) that locates the R
executable in the path. If this is so, this seems to be a bug to me: An
application (let alone a shared library) should not rely on the names of
symlinks in the user's search path.

Best regards
  Simon


+---
| Dr. Simon Anders, Dipl. Phys.
| European Bioinformatics Institute, Hinxton, Cambridgeshire, UK
| office phone +44-1223-492680, mobile phone +44-7505-841692
| preferred (permanent) e-mail: sanders at fs.tum.de


From anders at ebi.ac.uk  Mon Apr  6 22:55:24 2009
From: anders at ebi.ac.uk (Simon Anders)
Date: Mon, 06 Apr 2009 21:55:24 +0100
Subject: [Rd] Possible bug: How does libR.so find RHOME?
In-Reply-To: <49DA64F5.7080602@ebi.ac.uk>
References: <49DA64F5.7080602@ebi.ac.uk>
Message-ID: <49DA6C3C.2070707@ebi.ac.uk>

Hi

please disregard the previous mail; I realized that my conclusion that
the bug is in R and not in Rpy2, was quite wrong, as I just noticed
after abit more thinking. The problem is at a pretty obvious place in
RPy2's initialization routine. I'll ask the RPy2 mailing list for help.

  Simon


From coco at badsberg.eu  Tue Apr  7 01:20:43 2009
From: coco at badsberg.eu (coco at badsberg.eu)
Date: Tue, 7 Apr 2009 01:20:43 +0200
Subject: [Rd] 'R CMD build --binary BUNDLE' and Windows
Message-ID: <1BFF99DC9507426792104D6A4DD70741@Scaleo>

'R CMD build --binary BUNDLE' and Windows.

 

When using R version 2.9.0 beta for 'R CMD build --binary CoCo' on Windows
only the first package of the 'Contains' field of the bundle DESCRIPTION
file ends up in the zip file.

(Same result for the bundle 'VR' by R version 2.9.0 beta.)

 

The check of the CoCo bundle version 0.1.7.5 by R version 2.9.0 beta is OK
(on my machine), see attached 00check.log.

 

The zip-file is OK by versions 2.6.0, 2.6.2, 2.7.2, and 2.8.0 of R.

 

Regards,

 

Jens Henrik Badsberg

 


From wdunlap at tibco.com  Tue Apr  7 17:55:35 2009
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 7 Apr 2009 08:55:35 -0700
Subject: [Rd] typo in R-ints.texi's description of P_ macro
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D700FCDEA4@NA-PA-VBE03.na.tibco.com>

I think there are some missing words in "R Internals"'s description of
the P_ macro.
It currently has "A macro as a wrapper for ngettext", which I think
ought to be
something like "The macro P_ may be used as a wrapper for ngettext".

The following patch also makes the 2 alternate definitions of P_ have
the same argument names,
StringS and StringP.  Expanding the S and P to Singular and Plural,
would be more descriptive. 

Bill Dunlap
TIBCO Software Inc - Spotfire Division
wdunlap tibco.com 


Index: doc/manual/R-ints.texi
===================================================================
--- doc/manual/R-ints.texi      (revision 48294)
+++ doc/manual/R-ints.texi      (working copy)
@@ -2149,17 +2149,18 @@
 @noindent
 from @file{src/main/errors.c}.

-A macro
+The @code{P_} macro

 @example
 #ifdef ENABLE_NLS
 #define P_(StringS, StringP, N) ngettext (StringS, StringP, N)
 #else
-#define P_(String, StringP, N) (N > 1 ? StringP: String)
+#define P_(StringS, StringP, N) (N > 1 ? StringP: StringS)
 #endif
 @end example

 @noindent
+may be used
 as a wrapper for @code{ngettext}: however in some cases the preferred
 approach has been to conditionalize (on @code{ENABLE_NLS}) code using
 @code{ngettext}.


From p.dalgaard at biostat.ku.dk  Tue Apr  7 18:58:40 2009
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 07 Apr 2009 18:58:40 +0200
Subject: [Rd] typo in R-ints.texi's description of P_ macro
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D700FCDEA4@NA-PA-VBE03.na.tibco.com>
References: <77EB52C6DD32BA4D87471DCD70C8D700FCDEA4@NA-PA-VBE03.na.tibco.com>
Message-ID: <49DB8640.8090704@biostat.ku.dk>

William Dunlap wrote:
> I think there are some missing words in "R Internals"'s description of
> the P_ macro.
> It currently has "A macro as a wrapper for ngettext", which I think
> ought to be
> something like "The macro P_ may be used as a wrapper for ngettext".
> 
> The following patch also makes the 2 alternate definitions of P_ have
> the same argument names,
> StringS and StringP.  Expanding the S and P to Singular and Plural,
> would be more descriptive. 
> 
> Bill Dunlap
> TIBCO Software Inc - Spotfire Division
> wdunlap tibco.com 
> 
> 
> Index: doc/manual/R-ints.texi
> ===================================================================
> --- doc/manual/R-ints.texi      (revision 48294)
> +++ doc/manual/R-ints.texi      (working copy)
> @@ -2149,17 +2149,18 @@
>  @noindent
>  from @file{src/main/errors.c}.
> 
> -A macro
> +The @code{P_} macro
> 
>  @example
>  #ifdef ENABLE_NLS
>  #define P_(StringS, StringP, N) ngettext (StringS, StringP, N)
>  #else
> -#define P_(String, StringP, N) (N > 1 ? StringP: String)
> +#define P_(StringS, StringP, N) (N > 1 ? StringP: StringS)
>  #endif
>  @end example
> 
>  @noindent
> +may be used
>  as a wrapper for @code{ngettext}: however in some cases the preferred
>  approach has been to conditionalize (on @code{ENABLE_NLS}) code using
>  @code{ngettext}.
> 

OK, committed.

-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From edd at debian.org  Wed Apr  8 02:53:04 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 7 Apr 2009 19:53:04 -0500
Subject: [Rd] R-alpha/R-beta builds on Alpha platform failing with
 compiler error
In-Reply-To: <18903.53848.986239.317607@ron.nulle.part>
References: <18903.41703.731571.693110@ron.nulle.part>
	<49D7CF4B.2000809@biostat.ku.dk>
	<18903.53848.986239.317607@ron.nulle.part>
Message-ID: <18907.62832.820736.589093@ron.nulle.part>


On 4 April 2009 at 16:34, Dirk Eddelbuettel wrote:
| On 4 April 2009 at 23:21, Peter Dalgaard wrote:
| | Dirk Eddelbuettel wrote:
| | > Per https://buildd.debian.org/build.php?pkg=r-base, we see the Alpha platform
| | > having trouble with deriv.c :
| | > 
| | > gcc     -I. -I../../src/include -I../../src/include  -DHAVE_CONFIG_H  -mieee-with-inexact -fpic  -std=gnu99 -O3 -pipe  -g -c deriv.c -o deriv.o
| | > deriv.c: In function 'simplify':
| | > deriv.c:267: error: unrecognizable insn:
| | > (insn 2103 64 65 9 ../../src/include/Rinlinedfuns.h:86 (set (reg:DI 2 $2)
| | >         (const:DI (plus:DI (label_ref:DI 68)
| | >                 (const_int 24 [0x18])))) -1 (insn_list:REG_LABEL_OPERAND 68 (nil)))
| | > deriv.c:267: internal compiler error: in extract_insn, at recog.c:2001
| | > Please submit a full bug report,
| | > with preprocessed source if appropriate.
| | > See <file:///usr/share/doc/gcc-4.3/README.Bugs> for instructions.
| | > make[4]: *** [deriv.o] Error 1
| | > 
| | > This could of course be a bug in gcc.  Does anybody have insights into
| | > anything that may have changed here? 
| | 
| | I think it is by definition a bug in gcc...
| | 
| | It is usually rather hopeless to work around this sort of issue by 
| | source code changes. Have you tried reducing the optimization level?
| 
| No, not yet. Let me try that for the next beta. Change made.

And tested on one the Alpha machines available to Debian -- it does build
with -O2 so that's what the next upload will use.

Dirk

-- 
Three out of two people have difficulties with fractions.


From jadler at alum.mit.edu  Wed Apr  8 06:15:12 2009
From: jadler at alum.mit.edu (jadler at alum.mit.edu)
Date: Wed,  8 Apr 2009 06:15:12 +0200 (CEST)
Subject: [Rd] history function does not work correctly (PR#13645)
Message-ID: <20090408041512.7B89128321A0@mail.pubhealth.ku.dk>

Full_Name: Joseph Adler
Version: 2.8.1
OS: Mac OS X 10.5.6
Submission from: (NULL) (71.142.93.52)


According to the help file, the history() function is supposed to show recent
command history. However, it does not do this in the current Mac OS X version.

Instead, the history function appears to simply show the contents of the file
~/.Rhistory.


From ripley at stats.ox.ac.uk  Wed Apr  8 09:06:42 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 8 Apr 2009 08:06:42 +0100 (BST)
Subject: [Rd] history function does not work correctly (PR#13645)
In-Reply-To: <20090408041512.7B89128321A0@mail.pubhealth.ku.dk>
References: <20090408041512.7B89128321A0@mail.pubhealth.ku.dk>
Message-ID: <alpine.LFD.2.00.0904080803250.7366@gannet.stats.ox.ac.uk>

On Wed, 8 Apr 2009, jadler at alum.mit.edu wrote:

> Full_Name: Joseph Adler
> Version: 2.8.1
> OS: Mac OS X 10.5.6
> Submission from: (NULL) (71.142.93.52)
>
>
> According to the help file, the history() function is supposed to show recent
> command history. However, it does not do this in the current Mac OS X version.
>
> Instead, the history function appears to simply show the contents of the file
> ~/.Rhistory.

I believe you are refering to the R.app console, not R (the 
command-line interface).  In which case this is a problem in R.app, a 
separate project for which you are asked to send reports to the 
R-sig-mac list (see the posting guide under 'Platform-specific 
questions').

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From marc_schwartz at me.com  Wed Apr  8 15:53:48 2009
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 08 Apr 2009 08:53:48 -0500
Subject: [Rd] Possible bug in summary.survfit - 'scale' argument ignored?
In-Reply-To: <7DFD4EFF-6A19-46A9-A981-23101B1882A5@me.com>
References: <Pine.LNX.4.43.0904010508140.29619@hymn14.u.washington.edu>
	<7DFD4EFF-6A19-46A9-A981-23101B1882A5@me.com>
Message-ID: <601CA9E6-E903-4A44-93DF-1D755A4CB6B9@me.com>

Thomas,

I worked on the plane home last night and have a modified version that  
restores the original behavior vis-s-vis the interaction between the  
'times' and 'scale' arguments, so that 'times' are in the 'scale'  
transformed range.

I am attaching both a patch file and the complete function code. The  
patch is against the current version in R-Forge. If you should try to  
run the full code file to test this, note that survmean() is not  
exported in the survival NAMESPACE, hence if run 'as is' there will be  
an error message about this function not being found.

I would of course advise appropriate review and testing before  
considering committing this.

Regards,

Marc



-------------- next part --------------




From p.dalgaard at biostat.ku.dk  Thu Apr  9 10:28:36 2009
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 09 Apr 2009 10:28:36 +0200
Subject: [Rd] 'R CMD build --binary BUNDLE' and Windows
In-Reply-To: <1BFF99DC9507426792104D6A4DD70741@Scaleo>
References: <1BFF99DC9507426792104D6A4DD70741@Scaleo>
Message-ID: <49DDB1B4.1030905@biostat.ku.dk>

coco at badsberg.eu wrote:
> 'R CMD build --binary BUNDLE' and Windows.
> 
>  
> 
> When using R version 2.9.0 beta for 'R CMD build --binary CoCo' on Windows
> only the first package of the 'Contains' field of the bundle DESCRIPTION
> file ends up in the zip file.
> 
> (Same result for the bundle 'VR' by R version 2.9.0 beta.)
> 
>  
> 
> The check of the CoCo bundle version 0.1.7.5 by R version 2.9.0 beta is OK
> (on my machine), see attached 00check.log.
> 
>  
> 
> The zip-file is OK by versions 2.6.0, 2.6.2, 2.7.2, and 2.8.0 of R.

Brian fixed this, please check the current version (r48312).


-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From jbrzusto at fastmail.fm  Thu Apr  9 16:20:09 2009
From: jbrzusto at fastmail.fm (jbrzusto at fastmail.fm)
Date: Thu,  9 Apr 2009 16:20:09 +0200 (CEST)
Subject: [Rd] bug/suggestion: debugger should respect option
	"deparse.max.lines" when printing the call (PR#13647)
Message-ID: <20090409142009.3975C282C76F@mail.pubhealth.ku.dk>

Full_Name: John Brzustowski
Version: 2.8.1
OS: linux
Submission from: (NULL) (67.71.250.146)


When entering a debug()'ed function, the call printout is not limited by
options()$deparse.max.lines as it is when one uses browser() or trace().

Should it be?  If so, here's a patch:

diff -cr R-2.8.1/src/library/base/man/options.Rd
R-2.8.1-patched/src/library/base/man/options.Rd
*** R-2.8.1/src/library/base/man/options.Rd     2008-11-12 04:23:36.000000000
-0500
--- R-2.8.1-patched/src/library/base/man/options.Rd     2009-04-09
10:12:31.000000000 -0400
***************
*** 77,84 ****
        initialized (see \code{\link{Startup}}).}
  
      \item{\code{deparse.max.lines}:}{controls the number of lines used
!       when deparsing in \code{\link{traceback}} and
!       \code{\link{browser}}.  Initially unset, and only used if set to
        a positive integer.}
  
      \item{\code{digits}:}{controls the number of digits to print when
--- 77,85 ----
        initialized (see \code{\link{Startup}}).}
  
      \item{\code{deparse.max.lines}:}{controls the number of lines used
!       when deparsing in \code{\link{traceback}}, \code{\link{browser}},
!       and upon entry to a function whose debugging flag is set.
!       Initially unset, and only used if set to
        a positive integer.}
  
      \item{\code{digits}:}{controls the number of digits to print when
diff -cr R-2.8.1/src/main/eval.c R-2.8.1-patched/src/main/eval.c
*** R-2.8.1/src/main/eval.c     2008-10-05 18:05:02.000000000 -0400
--- R-2.8.1-patched/src/main/eval.c     2009-04-09 09:45:03.000000000 -0400
***************
*** 526,531 ****
--- 526,532 ----
      volatile  SEXP newrho;
      SEXP f, a, tmp;
      RCNTXT cntxt;
+     int itmp;
  
      /* formals = list of formal parameters */
      /* actuals = values to be bound to formals */
***************
*** 609,615 ****
--- 610,621 ----
      SET_DEBUG(newrho, DEBUG(op));
      if (DEBUG(op)) {
        Rprintf("debugging in: ");
+ 
+       itmp = asInteger(GetOption(install("deparse.max.lines"), R_BaseEnv));
+       if(itmp != NA_INTEGER && tmp > 0) R_BrowseLines = itmp;
        PrintValueRec(call,rho);
+       R_BrowseLines = 0;
+ 
        /* Is the body a bare symbol (PR#6804) */
        if (!isSymbol(body) & !isVectorAtomic(body)){
                /* Find out if the body is function with only one statement. */


From s.raberger at innovest.at  Thu Apr  9 10:50:13 2009
From: s.raberger at innovest.at (s.raberger at innovest.at)
Date: Thu,  9 Apr 2009 10:50:13 +0200 (CEST)
Subject: [Rd] type.convert (PR#13646)
Message-ID: <20090409085013.163D42832183@mail.pubhealth.ku.dk>

Full_Name: Stefan Raberger
Version: 2.8.1
OS: Windows XP
Submission from: (NULL) (213.185.163.242)


Hi there, 

I recently noticed some strange behaviour of the command "type.convert",
depending on the startup mode used. But there also seems to be different
behaviour on different PCs (all running the same OS and the same version of R).

On PC1:
When I start R in SDI mode (RGui --no-save --no-restore --no-site-file
--no-init-file --no-environ) and try to convert, the result is

> type.convert("?")
[1] NA

If I use MDI mode (RGui --no-save --no-restore --no-site-file --no-init-file
--no-environ --no-Rconsole) instead, the result is

> type.convert("?")
[1] ?
Levels: ?

On PC2 it's exactly the other way round (SDI: ?, MDI: NA), on PC2 the result is
always NA, independent of the startup mode used, and on PC4 it's always ?.

What's the result I should expect R to return, and why is it different in so
many cases?

Any help is much appreciated!
Regards, Stefan


From tplate at acm.org  Thu Apr  9 18:18:37 2009
From: tplate at acm.org (Tony Plate)
Date: Thu, 09 Apr 2009 10:18:37 -0600
Subject: [Rd] how to add a target to the Make that R CMD check uses for
 running tests?
Message-ID: <49DE1FDD.7030105@acm.org>

I'd like to have some additional 'make' targets for tests that are run in <pkg>/tests by "R CMD check" (to do things like run tests with different pre-processing and post-processing, generate test summaries, etc.)

Is there a good way to do this?  At the moment I make 'make' jump through hoops, and it works, but I'd like to find a better way.

A method I used initially was to change the default goal by assigning .DEFAULT_GOAL in tests/Makefile.  This works nicely with GNU make version 3.81, which is standard in Ubuntu Linux.  However, the Rtools set of programs for Windows (as of R 2.6.2) includes GNU make version 3.79, which does not appear to recognize .DEFAULT_GOAL.  Additionally, version 2.6.2 (2008-02-08) of "R Installation and Administration" specifically says that GNU make version 3.81 does not work to compile R under Windows. Furthermore, Mac OS X version 10.4 (Tiger) includes GNU make version 3.80, which also does not appear to recognize the .DEFAULT_GOAL special variable.  So, that method appears to not be portable (though things might have changed since I last investigated a year ago.)

After searching around and various experiments, I came up with the following ugly hack where I include the following code in tests/Makefile:

# Use 'force targets' to effectively create another target, by calling
# make recursively with the target 'all-Rt'.  See here for 'force targets':
# http://www.gnu.org/software/automake/manual/make/Force-Targets.html
# Based on code at
# http://www.gnu.org/software/automake/manual/make/Overriding-Makefiles.html
# but with more levels of protection to avoid calling make with
# the target 'all-Rt' more than once, because this makefile is
# read many times.  Condition on DONEFORCE being not defined
# to avoid infinite recursion.
ifeq ($(strip $(DONEFORCE)),)
%: force
	@(if [ ! -f forceonce ] ; then \
	$(MAKE) -f $(R_SHARE_DIR)/make/$(RSHAREMAKEFILE) $(makevars) -f $(MAINTESTMAKE) DONEFORCE=TRUE all-Rt ; \
	fi )
	@touch forceonce

force: ;
endif

This code causes 'make' to be called just once with the target 'all-Rt', using appropriate settings for RSHAREMAKEFILE (either 'tests.mk' or 'wintests.mk') and MAINTESTMAKE (either 'Makefile' or 'Makefile.win') (There are set in other parts of the Makefile).

The above code runs as intended under Linux, Windows, and Mac OS X, at least on the installations I've tested.

However this technique is ugly.  There must be a better way.  Any suggestions? (I guess I could probably get rid of the 'forceonce' protection pretty easily, but the $(DONEFORCE) protection seems harder to get rid of, and I'd like to think there must be an easier way of adding a target anyway.)

-- Tony Plate


From p.dalgaard at biostat.ku.dk  Thu Apr  9 19:26:01 2009
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 09 Apr 2009 19:26:01 +0200
Subject: [Rd] type.convert (PR#13646)
In-Reply-To: <20090409085013.163D42832183@mail.pubhealth.ku.dk>
References: <20090409085013.163D42832183@mail.pubhealth.ku.dk>
Message-ID: <49DE2FA9.4020205@biostat.ku.dk>

s.raberger at innovest.at wrote:
> Full_Name: Stefan Raberger
> Version: 2.8.1
> OS: Windows XP
> Submission from: (NULL) (213.185.163.242)
> 
> 
> Hi there, 
> 
> I recently noticed some strange behaviour of the command "type.convert",
> depending on the startup mode used. But there also seems to be different
> behaviour on different PCs (all running the same OS and the same version of R).
> 
> On PC1:
> When I start R in SDI mode (RGui --no-save --no-restore --no-site-file
> --no-init-file --no-environ) and try to convert, the result is
> 
>> type.convert("?")
> [1] NA
> 
> If I use MDI mode (RGui --no-save --no-restore --no-site-file --no-init-file
> --no-environ --no-Rconsole) instead, the result is
> 
>> type.convert("?")
> [1] ?
> Levels: ?
> 
> On PC2 it's exactly the other way round (SDI: ?, MDI: NA), on PC2 the result is
> always NA, independent of the startup mode used, and on PC4 it's always ?.
> 
> What's the result I should expect R to return, and why is it different in so
> many cases?

Which locale does R think it is in in the four cases? 
(Sys.setlocale("LC_CTYPE"), I think).

Might well not be a bug (so please don't file it as one).

> Any help is much appreciated!
> Regards, Stefan
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From jbrzusto at fastmail.fm  Thu Apr  9 19:40:12 2009
From: jbrzusto at fastmail.fm (jbrzusto at fastmail.fm)
Date: Thu,  9 Apr 2009 19:40:12 +0200 (CEST)
Subject: [Rd] corrected patch: debugger should respect deparse.max.lines
	(PR#13648)
Message-ID: <20090409174012.C17DC2832183@mail.pubhealth.ku.dk>

Full_Name: John Brzustowski
Version: 2.8.1
OS: linux
Submission from: (NULL) (67.71.250.146)


My apologies - there was a bug in the patch I submitted on this topic earlier
today.

diff -cr R-2.8.1/src/library/base/man/options.Rd
R-2.8.1-patched/src/library/base/man/options.Rd
*** R-2.8.1/src/library/base/man/options.Rd     2008-11-12 04:23:36.000000000
-0500
--- R-2.8.1-patched/src/library/base/man/options.Rd     2009-04-09
10:12:31.000000000 -0400
***************
*** 77,84 ****
        initialized (see \code{\link{Startup}}).}
  
      \item{\code{deparse.max.lines}:}{controls the number of lines used
!       when deparsing in \code{\link{traceback}} and
!       \code{\link{browser}}.  Initially unset, and only used if set to
        a positive integer.}
  
      \item{\code{digits}:}{controls the number of digits to print when
--- 77,85 ----
        initialized (see \code{\link{Startup}}).}
  
      \item{\code{deparse.max.lines}:}{controls the number of lines used
!       when deparsing in \code{\link{traceback}}, \code{\link{browser}},
!       and upon entry to a function whose debugging flag is set.
!       Initially unset, and only used if set to
        a positive integer.}
  
      \item{\code{digits}:}{controls the number of digits to print when
diff -cr R-2.8.1/src/main/eval.c R-2.8.1-patched/src/main/eval.c
*** R-2.8.1/src/main/eval.c     2008-10-05 18:05:02.000000000 -0400
--- R-2.8.1-patched/src/main/eval.c     2009-04-09 09:45:03.000000000 -0400
***************
*** 526,531 ****
--- 526,532 ----
      volatile  SEXP newrho;
      SEXP f, a, tmp;
      RCNTXT cntxt;
+     int itmp;
  
      /* formals = list of formal parameters */
      /* actuals = values to be bound to formals */
***************
*** 609,615 ****
--- 610,621 ----
      SET_DEBUG(newrho, DEBUG(op));
      if (DEBUG(op)) {
        Rprintf("debugging in: ");
+ 
+       itmp = asInteger(GetOption(install("deparse.max.lines"), R_BaseEnv));
+       if(itmp != NA_INTEGER && itmp > 0) R_BrowseLines = itmp;
        PrintValueRec(call,rho);
+       R_BrowseLines = 0;
+ 
        /* Is the body a bare symbol (PR#6804) */
        if (!isSymbol(body) & !isVectorAtomic(body)){
                /* Find out if the body is function with only one statement. */


From tobias.verbeke at telenet.be  Thu Apr  9 20:57:05 2009
From: tobias.verbeke at telenet.be (Tobias Verbeke)
Date: Thu, 09 Apr 2009 20:57:05 +0200
Subject: [Rd] "master" vignette
Message-ID: <49DE4501.9000105@telenet.be>

Dear list,

Is there a recommended way of building a package
vignette that consists of one "master" file that
\SweaveInput{}'s several other files ?

Many thanks in advance for any pointer.

Best,
Tobias


From p.dalgaard at biostat.ku.dk  Fri Apr 10 11:02:44 2009
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 10 Apr 2009 11:02:44 +0200
Subject: [Rd] type.convert (PR#13646)
In-Reply-To: <190A9235BCE8A847B3C81191064BA5FF043A020A@nets11ca>
References: <20090409085013.163D42832183@mail.pubhealth.ku.dk>
	<49DE2FA9.4020205@biostat.ku.dk>
	<190A9235BCE8A847B3C81191064BA5FF043A020A@nets11ca>
Message-ID: <49DF0B34.7030602@biostat.ku.dk>

Raberger, Stefan wrote:
> Hi Peter,
> 
> each of the four PCs actually has the same locale setting: 
> 
>> Sys.setlocale("LC_CTYPE")
> [1] "German_Austria.1252"
> 
> (all the other settings returned by invoking Sys.getlocale() are identical as well).
> 
> Just to be sure (because it's displayed incorrectly in my browser on the bugtracking page): the character inside the type.convert function ought to be a "section"-sign (HTML Code &#167; or &sect; , in R "\247", and not a dot ".").

I saw it correctly. It's "\302\247" in UTF8 locales, which is of course 
the reason I suspected locale settings, but I can't seem to trigger the 
NA behaviour.

I'm at a loss here, but some ideas:

In the cases where it returns NA, what type is it? (I.e. 
storage.mode(type.convert(....)))

What do you get from

 > charToRaw("?")
[1] c2 a7

(a7, presumably, but better check).

-p

> -----Urspr?ngliche Nachricht-----
> Von: Peter Dalgaard [mailto:p.dalgaard at biostat.ku.dk] 
> Gesendet: Donnerstag, 09. April 2009 19:26
> An: Raberger, Stefan
> Cc: r-devel at stat.math.ethz.ch; R-bugs at r-project.org
> Betreff: Re: [Rd] type.convert (PR#13646)
> 
> s.raberger at innovest.at wrote:
>> Full_Name: Stefan Raberger
>> Version: 2.8.1
>> OS: Windows XP
>> Submission from: (NULL) (213.185.163.242)
>>
>>
>> Hi there, 
>>
>> I recently noticed some strange behaviour of the command "type.convert",
>> depending on the startup mode used. But there also seems to be different
>> behaviour on different PCs (all running the same OS and the same version of R).
>>
>> On PC1:
>> When I start R in SDI mode (RGui --no-save --no-restore --no-site-file
>> --no-init-file --no-environ) and try to convert, the result is
>>
>>> type.convert("?")
>> [1] NA
>>
>> If I use MDI mode (RGui --no-save --no-restore --no-site-file --no-init-file
>> --no-environ --no-Rconsole) instead, the result is
>>
>>> type.convert("?")
>> [1] ?
>> Levels: ?
>>
>> On PC2 it's exactly the other way round (SDI: ?, MDI: NA), on PC2 the result is
>> always NA, independent of the startup mode used, and on PC4 it's always ?.
>>
>> What's the result I should expect R to return, and why is it different in so
>> many cases?
> 
> Which locale does R think it is in in the four cases? 
> (Sys.setlocale("LC_CTYPE"), I think).
> 
> Might well not be a bug (so please don't file it as one).
> 
>> Any help is much appreciated!
>> Regards, Stefan
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From S.Ellison at lgc.co.uk  Fri Apr 10 14:35:43 2009
From: S.Ellison at lgc.co.uk (S Ellison)
Date: Fri, 10 Apr 2009 05:35:43 -0700 (PDT)
Subject: [Rd] Package (PR#13475)
In-Reply-To: <497F4B87.3050505@stats.uwo.ca>
References: <20090127151505.49050282EFF8@mail.pubhealth.ku.dk>
	<497F4B87.3050505@stats.uwo.ca>
Message-ID: <22987300.post@talk.nabble.com>


I had the same normalizePath error recently on a new laptop, with a fresh
install of R 2.8.1 and an attempt to install lme4. First attempt:
package 'Matrix' successfully unpacked and MD5 sums checked
Error in normalizePath(path) : 
  path[1]: The system cannot find the file specified

Second attempt:

package 'Matrix' successfully unpacked and MD5 sums checked
package 'mlmRev' successfully unpacked and MD5 sums checked
package 'MEMSS' successfully unpacked and MD5 sums checked
package 'lme4' successfully unpacked and MD5 sums checked
Error in normalizePath(path) : 
  path[1]: The system cannot find the file specified


The irreproducibility made me wonder... so I turned off Norton's
auto-protect, which has a habit of scanning files on the fly when requested
and that often delays file opening. The error disappeared, at least that
once and for subsequent installations of NADA and the much larger rggobi
install.

The main reason for logging this post is to suggest a posible cause and
workround. But if it does turn out to be a consistent issue, perhaps it
would be worth checking for timeout issues related to normalizePath or
related routines in a future update?

S


Duncan Murdoch-2 wrote:
> 
> On 1/27/2009 10:15 AM, partho_bhowmick at ml.com wrote:
>> Full_Name: Partho Bhowmick
>> Version: 2.8.1
>> OS: Windows XP
>> Submission from: (NULL) (199.43.48.131)
>> 
>> 
>> While trying to install package sn (I have tried multiple mirrors),
>> I get the following message
>> 
>> trying URL
>> 'http://www.revolution-computing.com/cran/bin/windows/contrib/2.8/sn_0.4-10.zip'
>> Content type 'application/zip' length 320643 bytes (313 Kb)
>> opened URL
>> downloaded 313 Kb
>> 
>> package 'sn' successfully unpacked and MD5 sums checked
>> Error in normalizePath(path) : 
>>   path[1]: The system cannot find the file specified
> 
> 
> It works for me.  I suspect it's a permission problem or something 
> similar on your system.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
View this message in context: http://www.nabble.com/Package-%28PR-13475%29-tp21690164p22987300.html
Sent from the R devel mailing list archive at Nabble.com.


From bolker at ufl.edu  Fri Apr 10 15:04:10 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 10 Apr 2009 06:04:10 -0700 (PDT)
Subject: [Rd] summary for negative binomial GLMs (PR#13640)
In-Reply-To: <loom.20090406T175943-439@post.gmane.org>
References: <20090404171517.73D7D282EFF6@mail.pubhealth.ku.dk>
	<loom.20090406T175943-439@post.gmane.org>
Message-ID: <22987694.post@talk.nabble.com>



   Bump?  Does anyone else have an opinion on this one?

  cheers
    Ben Bolker


Ben Bolker wrote:
> 
>  <kushler <at> oakland.edu> writes:
> 
>> 
>> Full_Name: Robert Kushler
>> Version: 2.7.2
>> OS: Windows XP
>> Submission from: (NULL) (69.246.102.98)
>> 
>> I believe that the negative binomial family (from MASS) should be 
>> added to the
>> list for which dispersion is set to 1.
> 
>   Could you please clarify? In what procedures, under what
> circumstances?  Sounds like you mean l. 573 of glm.R:
> 
> if(object$family$family %in% c("poisson", "binomial"))  1
> 
>   The use case here is using negative.binomial with a fixed 
> theta parameter, right?  Using glm.nb takes care of this problem
> (it produces an object of class "negbin": MASS:::summary.negbin
> shows that the dispersion gets set to 1 here).
> 
>    I guess there's a little bit of a jurisdictional
> argument here, since the negative.binomial family is
> in MASS, and summary.glm is in base R ... also, there's
> a bit of a challenge in figuring out the test, because
> object$family$family is not a fixed string for negative
> binomial-family objects (e.g. "Negative Binomial(0.4)"
> in the example below) -- I'm not sure of the cleanest
> way to detect this case.
> 
>    I think I agree with you, but it would help to present
> your case in more detail ...
> 
>   Ben Bolker
> 
> ====================
> Example:
> 
> x <- rep(seq(0,23,by=1),50)
> s <- rep(seq(1,2,length=50*24),1)
> 
> tmp2 <- data.frame(y=rnbinom(length(s),
>                     mu=8*(sin(2*pi*x/24)+2),size = 0.4),x=factor(x),s=s)
> 
> library(MASS)
> tmp.glm.nb2 <- glm.nb(y~factor(x)-1 +offset(log(s)),data = tmp2)
> summary(tmp.glm.nb2)
> ## summary.negbin takes care of this case
> 
> tmp.glm.nb3 <- glm(y~factor(x)-1 +offset(log(s)),data = tmp2,
>                    family=negative.binomial(theta=0.4))
> 
> summary(tmp.glm.nb3)
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
View this message in context: http://www.nabble.com/summary-for-negative-binomial-GLMs-%28PR-13640%29-tp22885745p22987694.html
Sent from the R devel mailing list archive at Nabble.com.


From ligges at statistik.tu-dortmund.de  Fri Apr 10 17:21:03 2009
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 10 Apr 2009 17:21:03 +0200
Subject: [Rd] Package (PR#13475)
In-Reply-To: <22987300.post@talk.nabble.com>
References: <20090127151505.49050282EFF8@mail.pubhealth.ku.dk>	<497F4B87.3050505@stats.uwo.ca>
	<22987300.post@talk.nabble.com>
Message-ID: <49DF63DF.2080006@statistik.tu-dortmund.de>



S Ellison wrote:
> I had the same normalizePath error recently on a new laptop, with a fresh
> install of R 2.8.1 and an attempt to install lme4. First attempt:
> package 'Matrix' successfully unpacked and MD5 sums checked
> Error in normalizePath(path) : 
>   path[1]: The system cannot find the file specified
> 
> Second attempt:
> 
> package 'Matrix' successfully unpacked and MD5 sums checked
> package 'mlmRev' successfully unpacked and MD5 sums checked
> package 'MEMSS' successfully unpacked and MD5 sums checked
> package 'lme4' successfully unpacked and MD5 sums checked
> Error in normalizePath(path) : 
>   path[1]: The system cannot find the file specified
> 
> 
> The irreproducibility made me wonder... so I turned off Norton's
> auto-protect, which has a habit of scanning files on the fly when requested
> and that often delays file opening. The error disappeared, at least that
> once and for subsequent installations of NADA and the much larger rggobi
> install.
 >
> The main reason for logging this post is to suggest a posible cause and
> workround. But if it does turn out to be a consistent issue, perhaps it
> would be worth checking for timeout issues related to normalizePath or
> related routines in a future update?

Well, you need to ask Symantec to fix Norton, hence this is the wrong 
address.

Best wishes,
Uwe Ligges




> S
> 
> 
> Duncan Murdoch-2 wrote:
>> On 1/27/2009 10:15 AM, partho_bhowmick at ml.com wrote:
>>> Full_Name: Partho Bhowmick
>>> Version: 2.8.1
>>> OS: Windows XP
>>> Submission from: (NULL) (199.43.48.131)
>>>
>>>
>>> While trying to install package sn (I have tried multiple mirrors),
>>> I get the following message
>>>
>>> trying URL
>>> 'http://www.revolution-computing.com/cran/bin/windows/contrib/2.8/sn_0.4-10.zip'
>>> Content type 'application/zip' length 320643 bytes (313 Kb)
>>> opened URL
>>> downloaded 313 Kb
>>>
>>> package 'sn' successfully unpacked and MD5 sums checked
>>> Error in normalizePath(path) : 
>>>   path[1]: The system cannot find the file specified
>>
>> It works for me.  I suspect it's a permission problem or something 
>> similar on your system.
>>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>


From tlumley at u.washington.edu  Fri Apr 10 18:42:24 2009
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 10 Apr 2009 09:42:24 -0700 (PDT)
Subject: [Rd] Wishlist: timeout detection (was Package (PR#13475))
In-Reply-To: <49DF63DF.2080006@statistik.tu-dortmund.de>
Message-ID: <Pine.LNX.4.43.0904100942240.17822@hymn11.u.washington.edu>


I don't know if detecting timeouts is feasible.  There are two problems. The first is being able to tell that failing to find the file was a timeout problem. The second is distinguishing timeouts due to antivirus software from timeouts due to, eg, missing network connections, where giving up quickly is better than hanging indefinitely.

      -thomas

On Fri, 10 Apr 2009, Uwe Ligges wrote:

>
>
> S Ellison wrote:
>> I had the same normalizePath error recently on a new laptop, with a fresh
>> install of R 2.8.1 and an attempt to install lme4. First attempt:
>> package 'Matrix' successfully unpacked and MD5 sums checked
>> Error in normalizePath(path) :   path[1]: The system cannot find the file 
>> specified
>> 
>> Second attempt:
>> 
>> package 'Matrix' successfully unpacked and MD5 sums checked
>> package 'mlmRev' successfully unpacked and MD5 sums checked
>> package 'MEMSS' successfully unpacked and MD5 sums checked
>> package 'lme4' successfully unpacked and MD5 sums checked
>> Error in normalizePath(path) :   path[1]: The system cannot find the file 
>> specified
>> 
>> 
>> The irreproducibility made me wonder... so I turned off Norton's
>> auto-protect, which has a habit of scanning files on the fly when requested
>> and that often delays file opening. The error disappeared, at least that
>> once and for subsequent installations of NADA and the much larger rggobi
>> install.
>>
>> The main reason for logging this post is to suggest a posible cause and
>> workround. But if it does turn out to be a consistent issue, perhaps it
>> would be worth checking for timeout issues related to normalizePath or
>> related routines in a future update?
>
> Well, you need to ask Symantec to fix Norton, hence this is the wrong address.
>
> Best wishes,
> Uwe Ligges
>
>
>
>
>> S
>> 
>> 
>> Duncan Murdoch-2 wrote:
>>> On 1/27/2009 10:15 AM, partho_bhowmick at ml.com wrote:
>>>> Full_Name: Partho Bhowmick
>>>> Version: 2.8.1
>>>> OS: Windows XP
>>>> Submission from: (NULL) (199.43.48.131)
>>>> 
>>>> 
>>>> While trying to install package sn (I have tried multiple mirrors),
>>>> I get the following message
>>>> 
>>>> trying URL
>>>> 'http://www.revolution-computing.com/cran/bin/windows/contrib/2.8/sn_0.4-10.zip'
>>>> Content type 'application/zip' length 320643 bytes (313 Kb)
>>>> opened URL
>>>> downloaded 313 Kb
>>>> 
>>>> package 'sn' successfully unpacked and MD5 sums checked
>>>> Error in normalizePath(path) :   path[1]: The system cannot find the 
>>>> file specified
>>> 
>>> It works for me.  I suspect it's a permission problem or something similar 
>>> on your system.
>>> 
>>> Duncan Murdoch
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>> 
>> 
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From wdunlap at tibco.com  Fri Apr 10 19:55:12 2009
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 10 Apr 2009 10:55:12 -0700
Subject: [Rd] type.convert (PR#13646)
In-Reply-To: <49DF0B34.7030602@biostat.ku.dk>
References: <20090409085013.163D42832183@mail.pubhealth.ku.dk><49DE2FA9.4020205@biostat.ku.dk><190A9235BCE8A847B3C81191064BA5FF043A020A@nets11ca>
	<49DF0B34.7030602@biostat.ku.dk>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D7000107579A@NA-PA-VBE03.na.tibco.com>

I can reproduce the difference that Stefan saw, depending
on whether or not I start Rgui with the flags
    --no-environ --no-Rconsole
I think it boils down to the isBlankString() function.
For the string "\247" it returns 1 when those flags are
not present and 0 when they are.  isBlankString does use
some locale-specific functions:
Rboolean isBlankString(const char *s)
{
#ifdef SUPPORT_MBCS
    if(mbcslocale) {
        wchar_t wc; int used; mbstate_t mb_st;
        mbs_init(&mb_st);
        while( (used = Mbrtowc(&wc, s, MB_CUR_MAX, &mb_st)) ) {
            if(!iswspace(wc)) return FALSE;
            s += used;
        }
    } else
#endif
        while (*s)
            if (!isspace((int)*s++)) return FALSE;
    return TRUE;
}

I was using R 2.8.1, downloaded precompiled from CRAN, on Windows
XP SP3. The outputs of sessionInfo() and Sys.getenv() are the same
in both sessions.  'Process Explorer' shows that the 2 sessions
have the same dll's opened.

> sessionInfo()
R version 2.8.1 (2008-12-22) 
i386-pc-mingw32 

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United States.1252;LC_MONETARY=English_United States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     
> 

I did the test with a dll compiled from
#include <R.h>
#include <R_ext/Utils.h>

void test_isBlankString(char **s, int *res)
{
   *res = isBlankString(*s) ;
}

and called by .C("test_isBlankString","\247",-1L)

I don't see the difference while running a version of 2.9.0(devel)
compiled locally on 11 March 2009 (from svn rev 48116).

Bill Dunlap
TIBCO Software Inc - Spotfire Division
wdunlap tibco.com  

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Peter Dalgaard
> Sent: Friday, April 10, 2009 2:03 AM
> To: Raberger, Stefan
> Cc: R-bugs at r-project.org; r-devel at stat.math.ethz.ch
> Subject: Re: [Rd] type.convert (PR#13646)
> 
> Raberger, Stefan wrote:
> > Hi Peter,
> > 
> > each of the four PCs actually has the same locale setting: 
> > 
> >> Sys.setlocale("LC_CTYPE")
> > [1] "German_Austria.1252"
> > 
> > (all the other settings returned by invoking 
> Sys.getlocale() are identical as well).
> > 
> > Just to be sure (because it's displayed incorrectly in my 
> browser on the bugtracking page): the character inside the 
> type.convert function ought to be a "section"-sign (HTML Code 
> &#167; or &sect; , in R "\247", and not a dot ".").
> 
> I saw it correctly. It's "\302\247" in UTF8 locales, which is 
> of course 
> the reason I suspected locale settings, but I can't seem to 
> trigger the 
> NA behaviour.
> 
> I'm at a loss here, but some ideas:
> 
> In the cases where it returns NA, what type is it? (I.e. 
> storage.mode(type.convert(....)))
> 
> What do you get from
> 
>  > charToRaw("?")
> [1] c2 a7
> 
> (a7, presumably, but better check).
> 
> -p
> 
> > -----Urspr?ngliche Nachricht-----
> > Von: Peter Dalgaard [mailto:p.dalgaard at biostat.ku.dk] 
> > Gesendet: Donnerstag, 09. April 2009 19:26
> > An: Raberger, Stefan
> > Cc: r-devel at stat.math.ethz.ch; R-bugs at r-project.org
> > Betreff: Re: [Rd] type.convert (PR#13646)
> > 
> > s.raberger at innovest.at wrote:
> >> Full_Name: Stefan Raberger
> >> Version: 2.8.1
> >> OS: Windows XP
> >> Submission from: (NULL) (213.185.163.242)
> >>
> >>
> >> Hi there, 
> >>
> >> I recently noticed some strange behaviour of the command 
> "type.convert",
> >> depending on the startup mode used. But there also seems 
> to be different
> >> behaviour on different PCs (all running the same OS and 
> the same version of R).
> >>
> >> On PC1:
> >> When I start R in SDI mode (RGui --no-save --no-restore 
> --no-site-file
> >> --no-init-file --no-environ) and try to convert, the result is
> >>
> >>> type.convert("?")
> >> [1] NA
> >>
> >> If I use MDI mode (RGui --no-save --no-restore 
> --no-site-file --no-init-file
> >> --no-environ --no-Rconsole) instead, the result is
> >>
> >>> type.convert("?")
> >> [1] ?
> >> Levels: ?
> >>
> >> On PC2 it's exactly the other way round (SDI: ?, MDI: NA), 
> on PC2 the result is
> >> always NA, independent of the startup mode used, and on 
> PC4 it's always ?.
> >>
> >> What's the result I should expect R to return, and why is 
> it different in so
> >> many cases?
> > 
> > Which locale does R think it is in in the four cases? 
> > (Sys.setlocale("LC_CTYPE"), I think).
> > 
> > Might well not be a bug (so please don't file it as one).
> > 
> >> Any help is much appreciated!
> >> Regards, Stefan
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> > 
> > 
> 
> 
> -- 
>     O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>    c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>   (*) \(*) -- University of Copenhagen   Denmark      Ph:  
> (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: 
> (+45) 35327907
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From p.dalgaard at biostat.ku.dk  Fri Apr 10 22:40:54 2009
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 10 Apr 2009 22:40:54 +0200
Subject: [Rd] type.convert (PR#13646)
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D7000107579A@NA-PA-VBE03.na.tibco.com>
References: <20090409085013.163D42832183@mail.pubhealth.ku.dk><49DE2FA9.4020205@biostat.ku.dk><190A9235BCE8A847B3C81191064BA5FF043A020A@nets11ca>
	<49DF0B34.7030602@biostat.ku.dk>
	<77EB52C6DD32BA4D87471DCD70C8D7000107579A@NA-PA-VBE03.na.tibco.com>
Message-ID: <49DFAED6.9010006@biostat.ku.dk>

William Dunlap wrote:
> I can reproduce the difference that Stefan saw, depending
> on whether or not I start Rgui with the flags
>     --no-environ --no-Rconsole
> I think it boils down to the isBlankString() function.
> For the string "\247" it returns 1 when those flags are
> not present and 0 when they are.  isBlankString does use
> some locale-specific functions:
> Rboolean isBlankString(const char *s)
> {
> #ifdef SUPPORT_MBCS
>     if(mbcslocale) {
>         wchar_t wc; int used; mbstate_t mb_st;
>         mbs_init(&mb_st);
>         while( (used = Mbrtowc(&wc, s, MB_CUR_MAX, &mb_st)) ) {
>             if(!iswspace(wc)) return FALSE;
>             s += used;
>         }
>     } else
> #endif
>         while (*s)
>             if (!isspace((int)*s++)) return FALSE;
>     return TRUE;
> }
> 
> I was using R 2.8.1, downloaded precompiled from CRAN, on Windows
> XP SP3. The outputs of sessionInfo() and Sys.getenv() are the same
> in both sessions.  'Process Explorer' shows that the 2 sessions
> have the same dll's opened.

Thanks for that analysis Bill!

Stefan was in "German_Austria.1252" which I don't think is multibyte, so 
only the else-clause should be relevant, pointing the finger rather 
squarely at isspace(). Googling indicates that others have been caught 
out by signed/unsigned char issues there. Should this possibly rather read

if (!isspace((unsigned int)*s++)) return FALSE;

??

> 
>> sessionInfo()
> R version 2.8.1 (2008-12-22) 
> i386-pc-mingw32 
> 
> locale:
> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United States.1252;LC_MONETARY=English_United States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base     
> 
> I did the test with a dll compiled from
> #include <R.h>
> #include <R_ext/Utils.h>
> 
> void test_isBlankString(char **s, int *res)
> {
>    *res = isBlankString(*s) ;
> }
> 
> and called by .C("test_isBlankString","\247",-1L)
> 
> I don't see the difference while running a version of 2.9.0(devel)
> compiled locally on 11 March 2009 (from svn rev 48116).
> 
> Bill Dunlap
> TIBCO Software Inc - Spotfire Division
> wdunlap tibco.com  
> 
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org 
>> [mailto:r-devel-bounces at r-project.org] On Behalf Of Peter Dalgaard
>> Sent: Friday, April 10, 2009 2:03 AM
>> To: Raberger, Stefan
>> Cc: R-bugs at r-project.org; r-devel at stat.math.ethz.ch
>> Subject: Re: [Rd] type.convert (PR#13646)
>>
>> Raberger, Stefan wrote:
>>> Hi Peter,
>>>
>>> each of the four PCs actually has the same locale setting: 
>>>
>>>> Sys.setlocale("LC_CTYPE")
>>> [1] "German_Austria.1252"
>>>
>>> (all the other settings returned by invoking 
>> Sys.getlocale() are identical as well).
>>> Just to be sure (because it's displayed incorrectly in my 
>> browser on the bugtracking page): the character inside the 
>> type.convert function ought to be a "section"-sign (HTML Code 
>> &#167; or &sect; , in R "\247", and not a dot ".").
>>
>> I saw it correctly. It's "\302\247" in UTF8 locales, which is 
>> of course 
>> the reason I suspected locale settings, but I can't seem to 
>> trigger the 
>> NA behaviour.
>>
>> I'm at a loss here, but some ideas:
>>
>> In the cases where it returns NA, what type is it? (I.e. 
>> storage.mode(type.convert(....)))
>>
>> What do you get from
>>
>>  > charToRaw("?")
>> [1] c2 a7
>>
>> (a7, presumably, but better check).
>>
>> -p
>>
>>> -----Urspr?ngliche Nachricht-----
>>> Von: Peter Dalgaard [mailto:p.dalgaard at biostat.ku.dk] 
>>> Gesendet: Donnerstag, 09. April 2009 19:26
>>> An: Raberger, Stefan
>>> Cc: r-devel at stat.math.ethz.ch; R-bugs at r-project.org
>>> Betreff: Re: [Rd] type.convert (PR#13646)
>>>
>>> s.raberger at innovest.at wrote:
>>>> Full_Name: Stefan Raberger
>>>> Version: 2.8.1
>>>> OS: Windows XP
>>>> Submission from: (NULL) (213.185.163.242)
>>>>
>>>>
>>>> Hi there, 
>>>>
>>>> I recently noticed some strange behaviour of the command 
>> "type.convert",
>>>> depending on the startup mode used. But there also seems 
>> to be different
>>>> behaviour on different PCs (all running the same OS and 
>> the same version of R).
>>>> On PC1:
>>>> When I start R in SDI mode (RGui --no-save --no-restore 
>> --no-site-file
>>>> --no-init-file --no-environ) and try to convert, the result is
>>>>
>>>>> type.convert("?")
>>>> [1] NA
>>>>
>>>> If I use MDI mode (RGui --no-save --no-restore 
>> --no-site-file --no-init-file
>>>> --no-environ --no-Rconsole) instead, the result is
>>>>
>>>>> type.convert("?")
>>>> [1] ?
>>>> Levels: ?
>>>>
>>>> On PC2 it's exactly the other way round (SDI: ?, MDI: NA), 
>> on PC2 the result is
>>>> always NA, independent of the startup mode used, and on 
>> PC4 it's always ?.
>>>> What's the result I should expect R to return, and why is 
>> it different in so
>>>> many cases?
>>> Which locale does R think it is in in the four cases? 
>>> (Sys.setlocale("LC_CTYPE"), I think).
>>>
>>> Might well not be a bug (so please don't file it as one).
>>>
>>>> Any help is much appreciated!
>>>> Regards, Stefan
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> -- 
>>     O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>>    c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>>   (*) \(*) -- University of Copenhagen   Denmark      Ph:  
>> (+45) 35327918
>> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: 
>> (+45) 35327907
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>


-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From p.dalgaard at biostat.ku.dk  Fri Apr 10 23:55:25 2009
From: p.dalgaard at biostat.ku.dk (p.dalgaard at biostat.ku.dk)
Date: Fri, 10 Apr 2009 23:55:25 +0200 (CEST)
Subject: [Rd] type.convert (PR#13646)
Message-ID: <20090410215525.8BEE22832180@mail.pubhealth.ku.dk>

William Dunlap wrote:
> You may have to use
>   (unsigned int)(unsigned char)*s++
> instead of just
>   (unsigned int)*s++
> to avoid the sign extension.

Thanks again,

I probably won't be doing the change since I don't have a Windows build 
environment around, and I'm a bit superstitious about fixing bugs that I 
cannot see...

Let me just filter this information into the bug repository for now.

	-pd

> 
> Bill Dunlap
> TIBCO Software Inc - Spotfire Division
> wdunlap tibco.com  
> 
>> -----Original Message-----
>> From: Peter Dalgaard [mailto:p.dalgaard at biostat.ku.dk] 
>> Sent: Friday, April 10, 2009 1:41 PM
>> To: William Dunlap
>> Cc: r-devel at r-project.org
>> Subject: Re: [Rd] type.convert (PR#13646)
>>
>> William Dunlap wrote:
>>> I can reproduce the difference that Stefan saw, depending
>>> on whether or not I start Rgui with the flags
>>>     --no-environ --no-Rconsole
>>> I think it boils down to the isBlankString() function.
>>> For the string "\247" it returns 1 when those flags are
>>> not present and 0 when they are.  isBlankString does use
>>> some locale-specific functions:
>>> Rboolean isBlankString(const char *s)
>>> {
>>> #ifdef SUPPORT_MBCS
>>>     if(mbcslocale) {
>>>         wchar_t wc; int used; mbstate_t mb_st;
>>>         mbs_init(&mb_st);
>>>         while( (used = Mbrtowc(&wc, s, MB_CUR_MAX, &mb_st)) ) {
>>>             if(!iswspace(wc)) return FALSE;
>>>             s += used;
>>>         }
>>>     } else
>>> #endif
>>>         while (*s)
>>>             if (!isspace((int)*s++)) return FALSE;
>>>     return TRUE;
>>> }
>>>
>>> I was using R 2.8.1, downloaded precompiled from CRAN, on Windows
>>> XP SP3. The outputs of sessionInfo() and Sys.getenv() are the same
>>> in both sessions.  'Process Explorer' shows that the 2 sessions
>>> have the same dll's opened.
>> Thanks for that analysis Bill!
>>
>> Stefan was in "German_Austria.1252" which I don't think is 
>> multibyte, so 
>> only the else-clause should be relevant, pointing the finger rather 
>> squarely at isspace(). Googling indicates that others have 
>> been caught 
>> out by signed/unsigned char issues there. Should this 
>> possibly rather read
>>
>> if (!isspace((unsigned int)*s++)) return FALSE;
>>
>> ??
>>
>>>> sessionInfo()
>>> R version 2.8.1 (2008-12-22) 
>>> i386-pc-mingw32 
>>>
>>> locale:
>>> LC_COLLATE=English_United 
>> States.1252;LC_CTYPE=English_United 
>> States.1252;LC_MONETARY=English_United 
>> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  
>> methods   base     
>>> I did the test with a dll compiled from
>>> #include <R.h>
>>> #include <R_ext/Utils.h>
>>>
>>> void test_isBlankString(char **s, int *res)
>>> {
>>>    *res = isBlankString(*s) ;
>>> }
>>>
>>> and called by .C("test_isBlankString","\247",-1L)
>>>
>>> I don't see the difference while running a version of 2.9.0(devel)
>>> compiled locally on 11 March 2009 (from svn rev 48116).
>>>
>>> Bill Dunlap
>>> TIBCO Software Inc - Spotfire Division
>>> wdunlap tibco.com  
>>>
>>>> -----Original Message-----
>>>> From: r-devel-bounces at r-project.org 
>>>> [mailto:r-devel-bounces at r-project.org] On Behalf Of Peter Dalgaard
>>>> Sent: Friday, April 10, 2009 2:03 AM
>>>> To: Raberger, Stefan
>>>> Cc: R-bugs at r-project.org; r-devel at stat.math.ethz.ch
>>>> Subject: Re: [Rd] type.convert (PR#13646)
>>>>
>>>> Raberger, Stefan wrote:
>>>>> Hi Peter,
>>>>>
>>>>> each of the four PCs actually has the same locale setting: 
>>>>>
>>>>>> Sys.setlocale("LC_CTYPE")
>>>>> [1] "German_Austria.1252"
>>>>>
>>>>> (all the other settings returned by invoking 
>>>> Sys.getlocale() are identical as well).
>>>>> Just to be sure (because it's displayed incorrectly in my 
>>>> browser on the bugtracking page): the character inside the 
>>>> type.convert function ought to be a "section"-sign (HTML Code 
>>>> &#167; or &sect; , in R "\247", and not a dot ".").
>>>>
>>>> I saw it correctly. It's "\302\247" in UTF8 locales, which is 
>>>> of course 
>>>> the reason I suspected locale settings, but I can't seem to 
>>>> trigger the 
>>>> NA behaviour.
>>>>
>>>> I'm at a loss here, but some ideas:
>>>>
>>>> In the cases where it returns NA, what type is it? (I.e. 
>>>> storage.mode(type.convert(....)))
>>>>
>>>> What do you get from
>>>>
>>>>  > charToRaw("?")
>>>> [1] c2 a7
>>>>
>>>> (a7, presumably, but better check).
>>>>
>>>> -p
>>>>
>>>>> -----Urspr?ngliche Nachricht-----
>>>>> Von: Peter Dalgaard [mailto:p.dalgaard at biostat.ku.dk] 
>>>>> Gesendet: Donnerstag, 09. April 2009 19:26
>>>>> An: Raberger, Stefan
>>>>> Cc: r-devel at stat.math.ethz.ch; R-bugs at r-project.org
>>>>> Betreff: Re: [Rd] type.convert (PR#13646)
>>>>>
>>>>> s.raberger at innovest.at wrote:
>>>>>> Full_Name: Stefan Raberger
>>>>>> Version: 2.8.1
>>>>>> OS: Windows XP
>>>>>> Submission from: (NULL) (213.185.163.242)
>>>>>>
>>>>>>
>>>>>> Hi there, 
>>>>>>
>>>>>> I recently noticed some strange behaviour of the command 
>>>> "type.convert",
>>>>>> depending on the startup mode used. But there also seems 
>>>> to be different
>>>>>> behaviour on different PCs (all running the same OS and 
>>>> the same version of R).
>>>>>> On PC1:
>>>>>> When I start R in SDI mode (RGui --no-save --no-restore 
>>>> --no-site-file
>>>>>> --no-init-file --no-environ) and try to convert, the result is
>>>>>>
>>>>>>> type.convert("?")
>>>>>> [1] NA
>>>>>>
>>>>>> If I use MDI mode (RGui --no-save --no-restore 
>>>> --no-site-file --no-init-file
>>>>>> --no-environ --no-Rconsole) instead, the result is
>>>>>>
>>>>>>> type.convert("?")
>>>>>> [1] ?
>>>>>> Levels: ?
>>>>>>
>>>>>> On PC2 it's exactly the other way round (SDI: ?, MDI: NA), 
>>>> on PC2 the result is
>>>>>> always NA, independent of the startup mode used, and on 
>>>> PC4 it's always ?.
>>>>>> What's the result I should expect R to return, and why is 
>>>> it different in so
>>>>>> many cases?
>>>>> Which locale does R think it is in in the four cases? 
>>>>> (Sys.setlocale("LC_CTYPE"), I think).
>>>>>
>>>>> Might well not be a bug (so please don't file it as one).
>>>>>
>>>>>> Any help is much appreciated!
>>>>>> Regards, Stefan
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> -- 
>>>>     O__  ---- Peter Dalgaard             ?ster 
>> Farimagsgade 5, Entr.B
>>>>    c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>>>>   (*) \(*) -- University of Copenhagen   Denmark      Ph:  
>>>> (+45) 35327918
>>>> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: 
>>>> (+45) 35327907
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>
>> -- 
>>     O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>>    c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>>   (*) \(*) -- University of Copenhagen   Denmark      Ph:  
>> (+45) 35327918
>> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: 
>> (+45) 35327907
>>


-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From wdunlap at tibco.com  Sat Apr 11 01:00:23 2009
From: wdunlap at tibco.com (wdunlap at tibco.com)
Date: Sat, 11 Apr 2009 01:00:23 +0200 (CEST)
Subject: [Rd] type.convert (PR#13646)
Message-ID: <20090410230023.A25302832180@mail.pubhealth.ku.dk>

Using the (unsigned int)(unsigned char) in isspace()
resolved the problem in my Windows build.  I put some Rprintf
statements into isBlankString and for type.convert("\247")
it printed
  *s=3D-89 (4294967207 if unsigned)
    8=3Disspace(*s)
    8=3Disspace((unsigned int)*s)
    0=3Disspace((unsigned int)(unsigned char)*s)
I think the 8 is the value of a random bit of memory.

When I converted S+ to use full 8-bit characters I ran
into the same problem.  The is<class> macros in <ctype.h>
all take unsigned int argument and if char was signed you had
to do the double cast to avoid sign extension.  Whoever
designed the interface either didn't worry about 8-bit characters
or had chars that were unsigned by default.

It doesn't look like any of the isspace calls in R do
this double casting.

Bill Dunlap
TIBCO Software Inc - Spotfire Division
wdunlap tibco.com =20

> -----Original Message-----
> From: Peter Dalgaard [mailto:p.dalgaard at biostat.ku.dk]=20
> Sent: Friday, April 10, 2009 2:50 PM
> To: William Dunlap
> Cc: R-bugs at r-project.org; Raberger, Stefan
> Subject: Re: [Rd] type.convert (PR#13646)
>=20
> William Dunlap wrote:
> > You may have to use
> >   (unsigned int)(unsigned char)*s++
> > instead of just
> >   (unsigned int)*s++
> > to avoid the sign extension.
>=20
> Thanks again,
>=20
> I probably won't be doing the change since I don't have a=20
> Windows build=20
> environment around, and I'm a bit superstitious about fixing=20
> bugs that I=20
> cannot see...
>=20
> Let me just filter this information into the bug repository for now.
>=20
> 	-pd
>=20
> >=20
> > Bill Dunlap
> > TIBCO Software Inc - Spotfire Division
> > wdunlap tibco.com =20
> >=20
> >> -----Original Message-----
> >> From: Peter Dalgaard [mailto:p.dalgaard at biostat.ku.dk]=20
> >> Sent: Friday, April 10, 2009 1:41 PM
> >> To: William Dunlap
> >> Cc: r-devel at r-project.org
> >> Subject: Re: [Rd] type.convert (PR#13646)
> >>
> >> William Dunlap wrote:
> >>> I can reproduce the difference that Stefan saw, depending
> >>> on whether or not I start Rgui with the flags
> >>>     --no-environ --no-Rconsole
> >>> I think it boils down to the isBlankString() function.
> >>> For the string "\247" it returns 1 when those flags are
> >>> not present and 0 when they are.  isBlankString does use
> >>> some locale-specific functions:
> >>> Rboolean isBlankString(const char *s)
> >>> {
> >>> #ifdef SUPPORT_MBCS
> >>>     if(mbcslocale) {
> >>>         wchar_t wc; int used; mbstate_t mb_st;
> >>>         mbs_init(&mb_st);
> >>>         while( (used =3D Mbrtowc(&wc, s, MB_CUR_MAX, &mb_st)) ) {
> >>>             if(!iswspace(wc)) return FALSE;
> >>>             s +=3D used;
> >>>         }
> >>>     } else
> >>> #endif
> >>>         while (*s)
> >>>             if (!isspace((int)*s++)) return FALSE;
> >>>     return TRUE;
> >>> }
> >>>
> >>> I was using R 2.8.1, downloaded precompiled from CRAN, on Windows
> >>> XP SP3. The outputs of sessionInfo() and Sys.getenv() are the same
> >>> in both sessions.  'Process Explorer' shows that the 2 sessions
> >>> have the same dll's opened.
> >> Thanks for that analysis Bill!
> >>
> >> Stefan was in "German_Austria.1252" which I don't think is=20
> >> multibyte, so=20
> >> only the else-clause should be relevant, pointing the=20
> finger rather=20
> >> squarely at isspace(). Googling indicates that others have=20
> >> been caught=20
> >> out by signed/unsigned char issues there. Should this=20
> >> possibly rather read
> >>
> >> if (!isspace((unsigned int)*s++)) return FALSE;
> >>
> >> ??
> >>
> >>>> sessionInfo()
> >>> R version 2.8.1 (2008-12-22)=20
> >>> i386-pc-mingw32=20
> >>>
> >>> locale:
> >>> LC_COLLATE=3DEnglish_United=20
> >> States.1252;LC_CTYPE=3DEnglish_United=20
> >> States.1252;LC_MONETARY=3DEnglish_United=20
> >> States.1252;LC_NUMERIC=3DC;LC_TIME=3DEnglish_United States.1252
> >>> attached base packages:
> >>> [1] stats     graphics  grDevices utils     datasets =20
> >> methods   base    =20
> >>> I did the test with a dll compiled from
> >>> #include <R.h>
> >>> #include <R_ext/Utils.h>
> >>>
> >>> void test_isBlankString(char **s, int *res)
> >>> {
> >>>    *res =3D isBlankString(*s) ;
> >>> }
> >>>
> >>> and called by .C("test_isBlankString","\247",-1L)
> >>>
> >>> I don't see the difference while running a version of 2.9.0(devel)
> >>> compiled locally on 11 March 2009 (from svn rev 48116).
> >>>
> >>> Bill Dunlap
> >>> TIBCO Software Inc - Spotfire Division
> >>> wdunlap tibco.com =20
> >>>
> >>>> -----Original Message-----
> >>>> From: r-devel-bounces at r-project.org=20
> >>>> [mailto:r-devel-bounces at r-project.org] On Behalf Of=20
> Peter Dalgaard
> >>>> Sent: Friday, April 10, 2009 2:03 AM
> >>>> To: Raberger, Stefan
> >>>> Cc: R-bugs at r-project.org; r-devel at stat.math.ethz.ch
> >>>> Subject: Re: [Rd] type.convert (PR#13646)
> >>>>
> >>>> Raberger, Stefan wrote:
> >>>>> Hi Peter,
> >>>>>
> >>>>> each of the four PCs actually has the same locale setting:=20
> >>>>>
> >>>>>> Sys.setlocale("LC_CTYPE")
> >>>>> [1] "German_Austria.1252"
> >>>>>
> >>>>> (all the other settings returned by invoking=20
> >>>> Sys.getlocale() are identical as well).
> >>>>> Just to be sure (because it's displayed incorrectly in my=20
> >>>> browser on the bugtracking page): the character inside the=20
> >>>> type.convert function ought to be a "section"-sign (HTML Code=20
> >>>> &#167; or &sect; , in R "\247", and not a dot ".").
> >>>>
> >>>> I saw it correctly. It's "\302\247" in UTF8 locales, which is=20
> >>>> of course=20
> >>>> the reason I suspected locale settings, but I can't seem to=20
> >>>> trigger the=20
> >>>> NA behaviour.
> >>>>
> >>>> I'm at a loss here, but some ideas:
> >>>>
> >>>> In the cases where it returns NA, what type is it? (I.e.=20
> >>>> storage.mode(type.convert(....)))
> >>>>
> >>>> What do you get from
> >>>>
> >>>>  > charToRaw("=A7")
> >>>> [1] c2 a7
> >>>>
> >>>> (a7, presumably, but better check).
> >>>>
> >>>> -p
> >>>>
> >>>>> -----Urspr=FCngliche Nachricht-----
> >>>>> Von: Peter Dalgaard [mailto:p.dalgaard at biostat.ku.dk]=20
> >>>>> Gesendet: Donnerstag, 09. April 2009 19:26
> >>>>> An: Raberger, Stefan
> >>>>> Cc: r-devel at stat.math.ethz.ch; R-bugs at r-project.org
> >>>>> Betreff: Re: [Rd] type.convert (PR#13646)
> >>>>>
> >>>>> s.raberger at innovest.at wrote:
> >>>>>> Full_Name: Stefan Raberger
> >>>>>> Version: 2.8.1
> >>>>>> OS: Windows XP
> >>>>>> Submission from: (NULL) (213.185.163.242)
> >>>>>>
> >>>>>>
> >>>>>> Hi there,=20
> >>>>>>
> >>>>>> I recently noticed some strange behaviour of the command=20
> >>>> "type.convert",
> >>>>>> depending on the startup mode used. But there also seems=20
> >>>> to be different
> >>>>>> behaviour on different PCs (all running the same OS and=20
> >>>> the same version of R).
> >>>>>> On PC1:
> >>>>>> When I start R in SDI mode (RGui --no-save --no-restore=20
> >>>> --no-site-file
> >>>>>> --no-init-file --no-environ) and try to convert, the result is
> >>>>>>
> >>>>>>> type.convert("=A7")
> >>>>>> [1] NA
> >>>>>>
> >>>>>> If I use MDI mode (RGui --no-save --no-restore=20
> >>>> --no-site-file --no-init-file
> >>>>>> --no-environ --no-Rconsole) instead, the result is
> >>>>>>
> >>>>>>> type.convert("=A7")
> >>>>>> [1] =A7
> >>>>>> Levels: =A7
> >>>>>>
> >>>>>> On PC2 it's exactly the other way round (SDI: =A7, MDI: NA),=20
> >>>> on PC2 the result is
> >>>>>> always NA, independent of the startup mode used, and on=20
> >>>> PC4 it's always =A7.
> >>>>>> What's the result I should expect R to return, and why is=20
> >>>> it different in so
> >>>>>> many cases?
> >>>>> Which locale does R think it is in in the four cases?=20
> >>>>> (Sys.setlocale("LC_CTYPE"), I think).
> >>>>>
> >>>>> Might well not be a bug (so please don't file it as one).
> >>>>>
> >>>>>> Any help is much appreciated!
> >>>>>> Regards, Stefan
> >>>>>>
> >>>>>> ______________________________________________
> >>>>>> R-devel at r-project.org mailing list
> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>> --=20
> >>>>     O__  ---- Peter Dalgaard             =D8ster=20
> >> Farimagsgade 5, Entr.B
> >>>>    c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
> >>>>   (*) \(*) -- University of Copenhagen   Denmark      Ph: =20
> >>>> (+45) 35327918
> >>>> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX:=20
> >>>> (+45) 35327907
> >>>>
> >>>> ______________________________________________
> >>>> R-devel at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>>
> >>
> >> --=20
> >>     O__  ---- Peter Dalgaard             =D8ster=20
> Farimagsgade 5, Entr.B
> >>    c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
> >>   (*) \(*) -- University of Copenhagen   Denmark      Ph: =20
> >> (+45) 35327918
> >> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX:=20
> >> (+45) 35327907
> >>
>=20
>=20
> --=20
>     O__  ---- Peter Dalgaard             =D8ster Farimagsgade 5, =
Entr.B
>    c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>   (*) \(*) -- University of Copenhagen   Denmark      Ph: =20
> (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX:=20
> (+45) 35327907
>=20


From wdunlap at tibco.com  Sat Apr 11 01:36:11 2009
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 10 Apr 2009 16:36:11 -0700
Subject: [Rd] type.convert (PR#13646)
In-Reply-To: <20090410230023.A25302832180@mail.pubhealth.ku.dk>
References: <20090410230023.A25302832180@mail.pubhealth.ku.dk>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D700010758AF@NA-PA-VBE03.na.tibco.com>

> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of wdunlap at tibco.com
> Sent: Friday, April 10, 2009 4:00 PM
> To: r-devel at stat.math.ethz.ch
> Cc: R-bugs at r-project.org
> Subject: Re: [Rd] type.convert (PR#13646)
> 
> Using the (unsigned int)(unsigned char) in isspace()
> resolved the problem in my Windows build.  

(int)(unsigned char) the proper thing, since isspace
is declared to be int isspace(int).

The (unsigned int)(unsigned char) will work because
C does the unsigned int -> int conversion automatically
when the prototype is present and that conversion doesn't
change the value of the thing.

> I put some Rprintf
> statements into isBlankString and for type.convert("\247")
> it printed
>   *s=3D-89 (4294967207 if unsigned)
>     8=3Disspace(*s)
>     8=3Disspace((unsigned int)*s)
>     0=3Disspace((unsigned int)(unsigned char)*s)
> I think the 8 is the value of a random bit of memory.
> 
> When I converted S+ to use full 8-bit characters I ran
> into the same problem.  The is<class> macros in <ctype.h>
> all take unsigned int argument and if char was signed you had
> to do the double cast to avoid sign extension.  Whoever
> designed the interface either didn't worry about 8-bit characters
> or had chars that were unsigned by default.
> 
> It doesn't look like any of the isspace calls in R do
> this double casting.
> 
> Bill Dunlap
> TIBCO Software Inc - Spotfire Division
> wdunlap tibco.com =20
> 
> > -----Original Message-----
> > From: Peter Dalgaard [mailto:p.dalgaard at biostat.ku.dk]=20
> > Sent: Friday, April 10, 2009 2:50 PM
> > To: William Dunlap
> > Cc: R-bugs at r-project.org; Raberger, Stefan
> > Subject: Re: [Rd] type.convert (PR#13646)
> >=20
> > William Dunlap wrote:
> > > You may have to use
> > >   (unsigned int)(unsigned char)*s++
> > > instead of just
> > >   (unsigned int)*s++
> > > to avoid the sign extension.
> >=20
> > Thanks again,
> >=20
> > I probably won't be doing the change since I don't have a=20
> > Windows build=20
> > environment around, and I'm a bit superstitious about fixing=20
> > bugs that I=20
> > cannot see...
> >=20
> > Let me just filter this information into the bug repository for now.
> >=20
> > 	-pd
> >=20
> > >=20
> > > Bill Dunlap
> > > TIBCO Software Inc - Spotfire Division
> > > wdunlap tibco.com =20
> > >=20
> > >> -----Original Message-----
> > >> From: Peter Dalgaard [mailto:p.dalgaard at biostat.ku.dk]=20
> > >> Sent: Friday, April 10, 2009 1:41 PM
> > >> To: William Dunlap
> > >> Cc: r-devel at r-project.org
> > >> Subject: Re: [Rd] type.convert (PR#13646)
> > >>
> > >> William Dunlap wrote:
> > >>> I can reproduce the difference that Stefan saw, depending
> > >>> on whether or not I start Rgui with the flags
> > >>>     --no-environ --no-Rconsole
> > >>> I think it boils down to the isBlankString() function.
> > >>> For the string "\247" it returns 1 when those flags are
> > >>> not present and 0 when they are.  isBlankString does use
> > >>> some locale-specific functions:
> > >>> Rboolean isBlankString(const char *s)
> > >>> {
> > >>> #ifdef SUPPORT_MBCS
> > >>>     if(mbcslocale) {
> > >>>         wchar_t wc; int used; mbstate_t mb_st;
> > >>>         mbs_init(&mb_st);
> > >>>         while( (used =3D Mbrtowc(&wc, s, MB_CUR_MAX, 
> &mb_st)) ) {
> > >>>             if(!iswspace(wc)) return FALSE;
> > >>>             s +=3D used;
> > >>>         }
> > >>>     } else
> > >>> #endif
> > >>>         while (*s)
> > >>>             if (!isspace((int)*s++)) return FALSE;
> > >>>     return TRUE;
> > >>> }
> > >>>
> > >>> I was using R 2.8.1, downloaded precompiled from CRAN, 
> on Windows
> > >>> XP SP3. The outputs of sessionInfo() and Sys.getenv() 
> are the same
> > >>> in both sessions.  'Process Explorer' shows that the 2 sessions
> > >>> have the same dll's opened.
> > >> Thanks for that analysis Bill!
> > >>
> > >> Stefan was in "German_Austria.1252" which I don't think is=20
> > >> multibyte, so=20
> > >> only the else-clause should be relevant, pointing the=20
> > finger rather=20
> > >> squarely at isspace(). Googling indicates that others have=20
> > >> been caught=20
> > >> out by signed/unsigned char issues there. Should this=20
> > >> possibly rather read
> > >>
> > >> if (!isspace((unsigned int)*s++)) return FALSE;
> > >>
> > >> ??
> > >>
> > >>>> sessionInfo()
> > >>> R version 2.8.1 (2008-12-22)=20
> > >>> i386-pc-mingw32=20
> > >>>
> > >>> locale:
> > >>> LC_COLLATE=3DEnglish_United=20
> > >> States.1252;LC_CTYPE=3DEnglish_United=20
> > >> States.1252;LC_MONETARY=3DEnglish_United=20
> > >> States.1252;LC_NUMERIC=3DC;LC_TIME=3DEnglish_United States.1252
> > >>> attached base packages:
> > >>> [1] stats     graphics  grDevices utils     datasets =20
> > >> methods   base    =20
> > >>> I did the test with a dll compiled from
> > >>> #include <R.h>
> > >>> #include <R_ext/Utils.h>
> > >>>
> > >>> void test_isBlankString(char **s, int *res)
> > >>> {
> > >>>    *res =3D isBlankString(*s) ;
> > >>> }
> > >>>
> > >>> and called by .C("test_isBlankString","\247",-1L)
> > >>>
> > >>> I don't see the difference while running a version of 
> 2.9.0(devel)
> > >>> compiled locally on 11 March 2009 (from svn rev 48116).
> > >>>
> > >>> Bill Dunlap
> > >>> TIBCO Software Inc - Spotfire Division
> > >>> wdunlap tibco.com =20
> > >>>
> > >>>> -----Original Message-----
> > >>>> From: r-devel-bounces at r-project.org=20
> > >>>> [mailto:r-devel-bounces at r-project.org] On Behalf Of=20
> > Peter Dalgaard
> > >>>> Sent: Friday, April 10, 2009 2:03 AM
> > >>>> To: Raberger, Stefan
> > >>>> Cc: R-bugs at r-project.org; r-devel at stat.math.ethz.ch
> > >>>> Subject: Re: [Rd] type.convert (PR#13646)
> > >>>>
> > >>>> Raberger, Stefan wrote:
> > >>>>> Hi Peter,
> > >>>>>
> > >>>>> each of the four PCs actually has the same locale setting:=20
> > >>>>>
> > >>>>>> Sys.setlocale("LC_CTYPE")
> > >>>>> [1] "German_Austria.1252"
> > >>>>>
> > >>>>> (all the other settings returned by invoking=20
> > >>>> Sys.getlocale() are identical as well).
> > >>>>> Just to be sure (because it's displayed incorrectly in my=20
> > >>>> browser on the bugtracking page): the character inside the=20
> > >>>> type.convert function ought to be a "section"-sign 
> (HTML Code=20
> > >>>> &#167; or &sect; , in R "\247", and not a dot ".").
> > >>>>
> > >>>> I saw it correctly. It's "\302\247" in UTF8 locales, 
> which is=20
> > >>>> of course=20
> > >>>> the reason I suspected locale settings, but I can't seem to=20
> > >>>> trigger the=20
> > >>>> NA behaviour.
> > >>>>
> > >>>> I'm at a loss here, but some ideas:
> > >>>>
> > >>>> In the cases where it returns NA, what type is it? (I.e.=20
> > >>>> storage.mode(type.convert(....)))
> > >>>>
> > >>>> What do you get from
> > >>>>
> > >>>>  > charToRaw("=A7")
> > >>>> [1] c2 a7
> > >>>>
> > >>>> (a7, presumably, but better check).
> > >>>>
> > >>>> -p
> > >>>>
> > >>>>> -----Urspr=FCngliche Nachricht-----
> > >>>>> Von: Peter Dalgaard [mailto:p.dalgaard at biostat.ku.dk]=20
> > >>>>> Gesendet: Donnerstag, 09. April 2009 19:26
> > >>>>> An: Raberger, Stefan
> > >>>>> Cc: r-devel at stat.math.ethz.ch; R-bugs at r-project.org
> > >>>>> Betreff: Re: [Rd] type.convert (PR#13646)
> > >>>>>
> > >>>>> s.raberger at innovest.at wrote:
> > >>>>>> Full_Name: Stefan Raberger
> > >>>>>> Version: 2.8.1
> > >>>>>> OS: Windows XP
> > >>>>>> Submission from: (NULL) (213.185.163.242)
> > >>>>>>
> > >>>>>>
> > >>>>>> Hi there,=20
> > >>>>>>
> > >>>>>> I recently noticed some strange behaviour of the command=20
> > >>>> "type.convert",
> > >>>>>> depending on the startup mode used. But there also seems=20
> > >>>> to be different
> > >>>>>> behaviour on different PCs (all running the same OS and=20
> > >>>> the same version of R).
> > >>>>>> On PC1:
> > >>>>>> When I start R in SDI mode (RGui --no-save --no-restore=20
> > >>>> --no-site-file
> > >>>>>> --no-init-file --no-environ) and try to convert, the 
> result is
> > >>>>>>
> > >>>>>>> type.convert("=A7")
> > >>>>>> [1] NA
> > >>>>>>
> > >>>>>> If I use MDI mode (RGui --no-save --no-restore=20
> > >>>> --no-site-file --no-init-file
> > >>>>>> --no-environ --no-Rconsole) instead, the result is
> > >>>>>>
> > >>>>>>> type.convert("=A7")
> > >>>>>> [1] =A7
> > >>>>>> Levels: =A7
> > >>>>>>
> > >>>>>> On PC2 it's exactly the other way round (SDI: =A7, 
> MDI: NA),=20
> > >>>> on PC2 the result is
> > >>>>>> always NA, independent of the startup mode used, and on=20
> > >>>> PC4 it's always =A7.
> > >>>>>> What's the result I should expect R to return, and why is=20
> > >>>> it different in so
> > >>>>>> many cases?
> > >>>>> Which locale does R think it is in in the four cases?=20
> > >>>>> (Sys.setlocale("LC_CTYPE"), I think).
> > >>>>>
> > >>>>> Might well not be a bug (so please don't file it as one).
> > >>>>>
> > >>>>>> Any help is much appreciated!
> > >>>>>> Regards, Stefan
> > >>>>>>
> > >>>>>> ______________________________________________
> > >>>>>> R-devel at r-project.org mailing list
> > >>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> > >>>> --=20
> > >>>>     O__  ---- Peter Dalgaard             =D8ster=20
> > >> Farimagsgade 5, Entr.B
> > >>>>    c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 
> 1014 Cph. K
> > >>>>   (*) \(*) -- University of Copenhagen   Denmark      Ph: =20
> > >>>> (+45) 35327918
> > >>>> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX:=20
> > >>>> (+45) 35327907
> > >>>>
> > >>>> ______________________________________________
> > >>>> R-devel at r-project.org mailing list
> > >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> > >>>>
> > >>
> > >> --=20
> > >>     O__  ---- Peter Dalgaard             =D8ster=20
> > Farimagsgade 5, Entr.B
> > >>    c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
> > >>   (*) \(*) -- University of Copenhagen   Denmark      Ph: =20
> > >> (+45) 35327918
> > >> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX:=20
> > >> (+45) 35327907
> > >>
> >=20
> >=20
> > --=20
> >     O__  ---- Peter Dalgaard             =D8ster Farimagsgade 5, =
> Entr.B
> >    c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
> >   (*) \(*) -- University of Copenhagen   Denmark      Ph: =20
> > (+45) 35327918
> > ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX:=20
> > (+45) 35327907
> >=20
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From s.raberger at innovest.at  Fri Apr 10 09:05:23 2009
From: s.raberger at innovest.at (Raberger, Stefan)
Date: Fri, 10 Apr 2009 09:05:23 +0200
Subject: [Rd] type.convert (PR#13646)
In-Reply-To: <49DE2FA9.4020205@biostat.ku.dk>
References: <20090409085013.163D42832183@mail.pubhealth.ku.dk>
	<49DE2FA9.4020205@biostat.ku.dk>
Message-ID: <190A9235BCE8A847B3C81191064BA5FF043A020A@nets11ca>

Hi Peter,

each of the four PCs actually has the same locale setting: 

> Sys.setlocale("LC_CTYPE")
[1] "German_Austria.1252"

(all the other settings returned by invoking Sys.getlocale() are identical as well).

Just to be sure (because it's displayed incorrectly in my browser on the bugtracking page): the character inside the type.convert function ought to be a "section"-sign (HTML Code &#167; or &sect; , in R "\247", and not a dot ".").

-----Urspr?ngliche Nachricht-----
Von: Peter Dalgaard [mailto:p.dalgaard at biostat.ku.dk] 
Gesendet: Donnerstag, 09. April 2009 19:26
An: Raberger, Stefan
Cc: r-devel at stat.math.ethz.ch; R-bugs at r-project.org
Betreff: Re: [Rd] type.convert (PR#13646)

s.raberger at innovest.at wrote:
> Full_Name: Stefan Raberger
> Version: 2.8.1
> OS: Windows XP
> Submission from: (NULL) (213.185.163.242)
> 
> 
> Hi there, 
> 
> I recently noticed some strange behaviour of the command "type.convert",
> depending on the startup mode used. But there also seems to be different
> behaviour on different PCs (all running the same OS and the same version of R).
> 
> On PC1:
> When I start R in SDI mode (RGui --no-save --no-restore --no-site-file
> --no-init-file --no-environ) and try to convert, the result is
> 
>> type.convert("?")
> [1] NA
> 
> If I use MDI mode (RGui --no-save --no-restore --no-site-file --no-init-file
> --no-environ --no-Rconsole) instead, the result is
> 
>> type.convert("?")
> [1] ?
> Levels: ?
> 
> On PC2 it's exactly the other way round (SDI: ?, MDI: NA), on PC2 the result is
> always NA, independent of the startup mode used, and on PC4 it's always ?.
> 
> What's the result I should expect R to return, and why is it different in so
> many cases?

Which locale does R think it is in in the four cases? 
(Sys.setlocale("LC_CTYPE"), I think).

Might well not be a bug (so please don't file it as one).

> Any help is much appreciated!
> Regards, Stefan
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From s.raberger at innovest.at  Fri Apr 10 11:22:17 2009
From: s.raberger at innovest.at (Raberger, Stefan)
Date: Fri, 10 Apr 2009 11:22:17 +0200
Subject: [Rd] type.convert (PR#13646)
In-Reply-To: <49DF0B34.7030602@biostat.ku.dk>
References: <20090409085013.163D42832183@mail.pubhealth.ku.dk>
	<49DE2FA9.4020205@biostat.ku.dk>
	<190A9235BCE8A847B3C81191064BA5FF043A020A@nets11ca>
	<49DF0B34.7030602@biostat.ku.dk>
Message-ID: <190A9235BCE8A847B3C81191064BA5FF043A0333@nets11ca>

In the NA cases, storage.mode(..) - and also typeof(..) and class(..) - 
returns "logical", whereas in the other cases I get "integer" 
(and class "factor").

charToRaw(..) returns a7, as you suspected.

-----Urspr?ngliche Nachricht-----
Von: Peter Dalgaard [mailto:p.dalgaard at biostat.ku.dk] 
Gesendet: Freitag, 10. April 2009 11:03
An: Raberger, Stefan
Cc: r-devel at stat.math.ethz.ch; R-bugs at r-project.org
Betreff: Re: AW: [Rd] type.convert (PR#13646)

Raberger, Stefan wrote:
> Hi Peter,
> 
> each of the four PCs actually has the same locale setting: 
> 
>> Sys.setlocale("LC_CTYPE")
> [1] "German_Austria.1252"
> 
> (all the other settings returned by invoking Sys.getlocale() are identical as well).
> 
> Just to be sure (because it's displayed incorrectly in my browser on the bugtracking page): the character inside the type.convert function ought to be a "section"-sign (HTML Code &#167; or &sect; , in R "\247", and not a dot ".").

I saw it correctly. It's "\302\247" in UTF8 locales, which is of course 
the reason I suspected locale settings, but I can't seem to trigger the 
NA behaviour.

I'm at a loss here, but some ideas:

In the cases where it returns NA, what type is it? (I.e. 
storage.mode(type.convert(....)))

What do you get from

 > charToRaw("?")
[1] c2 a7

(a7, presumably, but better check).

-p

> -----Urspr?ngliche Nachricht-----
> Von: Peter Dalgaard [mailto:p.dalgaard at biostat.ku.dk] 
> Gesendet: Donnerstag, 09. April 2009 19:26
> An: Raberger, Stefan
> Cc: r-devel at stat.math.ethz.ch; R-bugs at r-project.org
> Betreff: Re: [Rd] type.convert (PR#13646)
> 
> s.raberger at innovest.at wrote:
>> Full_Name: Stefan Raberger
>> Version: 2.8.1
>> OS: Windows XP
>> Submission from: (NULL) (213.185.163.242)
>>
>>
>> Hi there, 
>>
>> I recently noticed some strange behaviour of the command "type.convert",
>> depending on the startup mode used. But there also seems to be different
>> behaviour on different PCs (all running the same OS and the same version of R).
>>
>> On PC1:
>> When I start R in SDI mode (RGui --no-save --no-restore --no-site-file
>> --no-init-file --no-environ) and try to convert, the result is
>>
>>> type.convert("?")
>> [1] NA
>>
>> If I use MDI mode (RGui --no-save --no-restore --no-site-file --no-init-file
>> --no-environ --no-Rconsole) instead, the result is
>>
>>> type.convert("?")
>> [1] ?
>> Levels: ?
>>
>> On PC2 it's exactly the other way round (SDI: ?, MDI: NA), on PC2 the result is
>> always NA, independent of the startup mode used, and on PC4 it's always ?.
>>
>> What's the result I should expect R to return, and why is it different in so
>> many cases?
> 
> Which locale does R think it is in in the four cases? 
> (Sys.setlocale("LC_CTYPE"), I think).
> 
> Might well not be a bug (so please don't file it as one).
> 
>> Any help is much appreciated!
>> Regards, Stefan
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From roger at ysidro.econ.uiuc.edu  Sun Apr 12 00:50:16 2009
From: roger at ysidro.econ.uiuc.edu (roger koenker)
Date: Sat, 11 Apr 2009 17:50:16 -0500
Subject: [Rd] data argument and environments
Message-ID: <5CBE3B72-0ABC-45C5-90EA-9CAA89A36A5E@ysidro.econ.uiuc.edu>

I'm having difficulty with an environmental issue:  I have an additive  
model fitting function
with a typical call that looks like this:

require(quantreg)
n <- 100
x <- runif(n,0,10)
y <- sin(x) + rnorm(n)/5
d <- data.frame(x,y)
lam <- 2

	f <- rqss(y ~ qss(x, lambda = lam), data = d)

this is fine when invoked as is; x and y are found in d, and lam is  
found the .GlobalEnv,
or at least this is how I understand it.  Now,  I'd like to have a  
function say,

	h <- function(lam)
		AIC(rqss(y ~ qss(x, lambda = lam), data = d))

but now,  if I do:

	rm(lam)
	h(1)
Error in qss1(x, constraint = constraint, lambda = lambda, dummies =  
dummies,  :
   object "lam" not found

worse, if there is a "lam"  in the .GlobalEnv it is used instead of  
the argument specified to h().
If I remove the data=d argument in the function definition then lam is  
passed correctly.
presumably because data defaults to parent.env().   I recognize that  
this is probably an elementary confusion on my part, but my  
understanding of environments is very limited.
I did read  the entry for FAQ 7.12,  but I'm still unenlightened.

url:    www.econ.uiuc.edu/~roger                Roger Koenker
email   rkoenker at uiuc.edu                       Department of Economics
vox:    217-333-4558                            University of Illinois
fax:    217-244-6678                            Champaign, IL 61820


From murdoch at stats.uwo.ca  Sun Apr 12 01:43:06 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 11 Apr 2009 19:43:06 -0400
Subject: [Rd] data argument and environments
In-Reply-To: <5CBE3B72-0ABC-45C5-90EA-9CAA89A36A5E@ysidro.econ.uiuc.edu>
References: <5CBE3B72-0ABC-45C5-90EA-9CAA89A36A5E@ysidro.econ.uiuc.edu>
Message-ID: <49E12B0A.4020407@stats.uwo.ca>

On 11/04/2009 6:50 PM, roger koenker wrote:
> I'm having difficulty with an environmental issue:  I have an additive  
> model fitting function
> with a typical call that looks like this:
> 
> require(quantreg)
> n <- 100
> x <- runif(n,0,10)
> y <- sin(x) + rnorm(n)/5
> d <- data.frame(x,y)
> lam <- 2
> 
> 	f <- rqss(y ~ qss(x, lambda = lam), data = d)
> 
> this is fine when invoked as is; x and y are found in d, and lam is  
> found the .GlobalEnv,
> or at least this is how I understand it.  Now,  I'd like to have a  
> function say,
> 
> 	h <- function(lam)
> 		AIC(rqss(y ~ qss(x, lambda = lam), data = d))
> 
> but now,  if I do:
> 
> 	rm(lam)
> 	h(1)
> Error in qss1(x, constraint = constraint, lambda = lambda, dummies =  
> dummies,  :
>    object "lam" not found
> 
> worse, if there is a "lam"  in the .GlobalEnv it is used instead of  
> the argument specified to h().
> If I remove the data=d argument in the function definition then lam is  
> passed correctly.
> presumably because data defaults to parent.env().   I recognize that  
> this is probably an elementary confusion on my part, but my  
> understanding of environments is very limited.
> I did read  the entry for FAQ 7.12,  but I'm still unenlightened.

Formulas have environments attached to them, and modelling functions 
should look there if they don't find the object in the data argument. 
If your h is defined exactly as you wrote it, then the environment of 
the y ~ qss(...) formula will automatically be the evaluation frame of 
h, so it should be able to find lam.

You wrote rqss, right?  So perhaps you aren't evaluating the variables 
in the formula in the right place.  Do you use model.frame to do it? 
(See lm() for an example:  it takes the original call to lm, throws away 
all but a few arguments, and turns it into a call to model.frame() to 
find the necessary variables.)  model.frame() knows about environments 
and stuff, but assumes linear model-like data.

Duncan Murdoch

> 
> url:    www.econ.uiuc.edu/~roger                Roger Koenker
> email   rkoenker at uiuc.edu                       Department of Economics
> vox:    217-333-4558                            University of Illinois
> fax:    217-244-6678                            Champaign, IL 61820
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From roger at ysidro.econ.uiuc.edu  Sun Apr 12 21:08:18 2009
From: roger at ysidro.econ.uiuc.edu (roger koenker)
Date: Sun, 12 Apr 2009 14:08:18 -0500
Subject: [Rd] data argument and environments
In-Reply-To: <49E12B0A.4020407@stats.uwo.ca>
References: <5CBE3B72-0ABC-45C5-90EA-9CAA89A36A5E@ysidro.econ.uiuc.edu>
	<49E12B0A.4020407@stats.uwo.ca>
Message-ID: <B402D9D9-0F6F-4D47-99E8-4712B219C4A8@ysidro.econ.uiuc.edu>

Thanks.  Yes,  I wrote rqss,  and attempted to follow the structure of  
lm, and various analogues,
for example in survival4.  My problem seems to be that my lam variable  
is not part of
the data frame d, and I don't know how to manipulate the environment  
for the formula
so that it is found.  There is an untangle.specials() call

	tmpc <- untangle.specials(Terms, "qss")

and then each of the "specials"  terms are evaluated in:

	qss <- lapply(tmpc$vars, function(u) eval(parse(text = u), data))

which is fine if the data hasn't been specified so it defaults to  
parent.frame(), since in
this case variables and lam can all be found in the parent.frame,  but  
if
it is specified as a data frame for the variables of the model, then  
the lam value is
unavailable.  My impression is that it is somewhat unusual to pass  
data other than
variables from the data frame itself for evaluation of the formula --  
I thought there
were examples in mgcv, but I now see that  lamdas in gam() are passed  
as separate
arguments, rather than in the special components of the formula.   
Perhaps I need
to revert to this strategy, but I'd prefer not to.  Surely, there is  
some good way to modify
the above lapply so  that eval finds both stuff in data and in the  
parent.frame?  It
appears that I can simply define pf <- parent.frame()  and then add  
enclos = pf
to the above eval() call,  is this ok?

Roger

On Apr 11, 2009, at 6:43 PM, Duncan Murdoch wrote:

> On 11/04/2009 6:50 PM, roger koenker wrote:
>> I'm having difficulty with an environmental issue:  I have an  
>> additive  model fitting function
>> with a typical call that looks like this:
>> require(quantreg)
>> n <- 100
>> x <- runif(n,0,10)
>> y <- sin(x) + rnorm(n)/5
>> d <- data.frame(x,y)
>> lam <- 2
>> 	f <- rqss(y ~ qss(x, lambda = lam), data = d)
>> this is fine when invoked as is; x and y are found in d, and lam  
>> is  found the .GlobalEnv,
>> or at least this is how I understand it.  Now,  I'd like to have a   
>> function say,
>> 	h <- function(lam)
>> 		AIC(rqss(y ~ qss(x, lambda = lam), data = d))
>> but now,  if I do:
>> 	rm(lam)
>> 	h(1)
>> Error in qss1(x, constraint = constraint, lambda = lambda, dummies  
>> =  dummies,  :
>>   object "lam" not found
>> worse, if there is a "lam"  in the .GlobalEnv it is used instead  
>> of  the argument specified to h().
>> If I remove the data=d argument in the function definition then lam  
>> is  passed correctly.
>> presumably because data defaults to parent.env().   I recognize  
>> that  this is probably an elementary confusion on my part, but my   
>> understanding of environments is very limited.
>> I did read  the entry for FAQ 7.12,  but I'm still unenlightened.
>
> Formulas have environments attached to them, and modelling functions  
> should look there if they don't find the object in the data  
> argument. If your h is defined exactly as you wrote it, then the  
> environment of the y ~ qss(...) formula will automatically be the  
> evaluation frame of h, so it should be able to find lam.
>
> You wrote rqss, right?  So perhaps you aren't evaluating the  
> variables in the formula in the right place.  Do you use model.frame  
> to do it? (See lm() for an example:  it takes the original call to  
> lm, throws away all but a few arguments, and turns it into a call to  
> model.frame() to find the necessary variables.)  model.frame() knows  
> about environments and stuff, but assumes linear model-like data.
>
> Duncan Murdoch
>
>> url:    www.econ.uiuc.edu/~roger                Roger Koenker
>> email   rkoenker at uiuc.edu                       Department of  
>> Economics
>> vox:    217-333-4558                            University of  
>> Illinois
>> fax:    217-244-6678                            Champaign, IL 61820
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch at stats.uwo.ca  Sun Apr 12 21:29:48 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 12 Apr 2009 15:29:48 -0400
Subject: [Rd] data argument and environments
In-Reply-To: <B402D9D9-0F6F-4D47-99E8-4712B219C4A8@ysidro.econ.uiuc.edu>
References: <5CBE3B72-0ABC-45C5-90EA-9CAA89A36A5E@ysidro.econ.uiuc.edu>
	<49E12B0A.4020407@stats.uwo.ca>
	<B402D9D9-0F6F-4D47-99E8-4712B219C4A8@ysidro.econ.uiuc.edu>
Message-ID: <49E2412C.5040204@stats.uwo.ca>

roger koenker wrote:
> Thanks.  Yes,  I wrote rqss,  and attempted to follow the structure of  
> lm, and various analogues,
> for example in survival4.  My problem seems to be that my lam variable  
> is not part of
> the data frame d, and I don't know how to manipulate the environment  
> for the formula
> so that it is found.  There is an untangle.specials() call
>
> 	tmpc <- untangle.specials(Terms, "qss")
>
> and then each of the "specials"  terms are evaluated in:
>
> 	qss <- lapply(tmpc$vars, function(u) eval(parse(text = u), data))
>   

I think the fix here is to specify both the envir and enclos args to 
eval.  That is, do something like

eval(parse(text=u, envir=data, enclos=environment(formula)))

This says to look first in the dataframe, and then treat the environment 
of the formula as the parent environment.  By default, eval treats the 
calling frame as the parent.  In an lapply call, that's probably local 
variables in lapply(), which is not what you want.
> which is fine if the data hasn't been specified so it defaults to  
> parent.frame(), since in
> this case variables and lam can all be found in the parent.frame,  but  
> if
> it is specified as a data frame for the variables of the model, then  
> the lam value is
> unavailable.  My impression is that it is somewhat unusual to pass  
> data other than
> variables from the data frame itself for evaluation of the formula --  
> I thought there
> were examples in mgcv, but I now see that  lamdas in gam() are passed  
> as separate
> arguments, rather than in the special components of the formula.   
> Perhaps I need
> to revert to this strategy, but I'd prefer not to.  Surely, there is  
> some good way to modify
> the above lapply so  that eval finds both stuff in data and in the  
> parent.frame?  It
> appears that I can simply define pf <- parent.frame()  and then add  
> enclos = pf
> to the above eval() call,  is this ok?
>   

That might work, but some day a user might produce the formula somewhere 
else, and pass it in (e.g. if they write a wrapper function for rqss):  
using environment(formula) should guarantee you pick up the right one.

Duncan Murdoch

> Roger
>
> On Apr 11, 2009, at 6:43 PM, Duncan Murdoch wrote:
>
>   
>> On 11/04/2009 6:50 PM, roger koenker wrote:
>>     
>>> I'm having difficulty with an environmental issue:  I have an  
>>> additive  model fitting function
>>> with a typical call that looks like this:
>>> require(quantreg)
>>> n <- 100
>>> x <- runif(n,0,10)
>>> y <- sin(x) + rnorm(n)/5
>>> d <- data.frame(x,y)
>>> lam <- 2
>>> 	f <- rqss(y ~ qss(x, lambda = lam), data = d)
>>> this is fine when invoked as is; x and y are found in d, and lam  
>>> is  found the .GlobalEnv,
>>> or at least this is how I understand it.  Now,  I'd like to have a   
>>> function say,
>>> 	h <- function(lam)
>>> 		AIC(rqss(y ~ qss(x, lambda = lam), data = d))
>>> but now,  if I do:
>>> 	rm(lam)
>>> 	h(1)
>>> Error in qss1(x, constraint = constraint, lambda = lambda, dummies  
>>> =  dummies,  :
>>>   object "lam" not found
>>> worse, if there is a "lam"  in the .GlobalEnv it is used instead  
>>> of  the argument specified to h().
>>> If I remove the data=d argument in the function definition then lam  
>>> is  passed correctly.
>>> presumably because data defaults to parent.env().   I recognize  
>>> that  this is probably an elementary confusion on my part, but my   
>>> understanding of environments is very limited.
>>> I did read  the entry for FAQ 7.12,  but I'm still unenlightened.
>>>       
>> Formulas have environments attached to them, and modelling functions  
>> should look there if they don't find the object in the data  
>> argument. If your h is defined exactly as you wrote it, then the  
>> environment of the y ~ qss(...) formula will automatically be the  
>> evaluation frame of h, so it should be able to find lam.
>>
>> You wrote rqss, right?  So perhaps you aren't evaluating the  
>> variables in the formula in the right place.  Do you use model.frame  
>> to do it? (See lm() for an example:  it takes the original call to  
>> lm, throws away all but a few arguments, and turns it into a call to  
>> model.frame() to find the necessary variables.)  model.frame() knows  
>> about environments and stuff, but assumes linear model-like data.
>>
>> Duncan Murdoch
>>
>>     
>>> url:    www.econ.uiuc.edu/~roger                Roger Koenker
>>> email   rkoenker at uiuc.edu                       Department of  
>>> Economics
>>> vox:    217-333-4558                            University of  
>>> Illinois
>>> fax:    217-244-6678                            Champaign, IL 61820
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>


From p.dalgaard at biostat.ku.dk  Sun Apr 12 21:37:52 2009
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sun, 12 Apr 2009 21:37:52 +0200
Subject: [Rd] data argument and environments
In-Reply-To: <B402D9D9-0F6F-4D47-99E8-4712B219C4A8@ysidro.econ.uiuc.edu>
References: <5CBE3B72-0ABC-45C5-90EA-9CAA89A36A5E@ysidro.econ.uiuc.edu>	<49E12B0A.4020407@stats.uwo.ca>
	<B402D9D9-0F6F-4D47-99E8-4712B219C4A8@ysidro.econ.uiuc.edu>
Message-ID: <49E24310.5060404@biostat.ku.dk>

roger koenker wrote:
> Thanks.  Yes,  I wrote rqss,  and attempted to follow the structure of 
> lm, and various analogues,
> for example in survival4.  My problem seems to be that my lam variable 
> is not part of
> the data frame d, and I don't know how to manipulate the environment for 
> the formula
> so that it is found.  There is an untangle.specials() call
> 
>     tmpc <- untangle.specials(Terms, "qss")
> 
> and then each of the "specials"  terms are evaluated in:
> 
>     qss <- lapply(tmpc$vars, function(u) eval(parse(text = u), data))
> 
> which is fine if the data hasn't been specified so it defaults to 
> parent.frame(), since in
> this case variables and lam can all be found in the parent.frame,  but if
> it is specified as a data frame for the variables of the model, then the 
> lam value is
> unavailable.  My impression is that it is somewhat unusual to pass data 
> other than
> variables from the data frame itself for evaluation of the formula -- I 
> thought there
> were examples in mgcv, but I now see that  lamdas in gam() are passed as 
> separate
> arguments, rather than in the special components of the formula.  
> Perhaps I need
> to revert to this strategy, but I'd prefer not to.  Surely, there is 
> some good way to modify
> the above lapply so  that eval finds both stuff in data and in the 
> parent.frame?  It
> appears that I can simply define pf <- parent.frame()  and then add 
> enclos = pf
> to the above eval() call,  is this ok?

I think more likely you want enclos=environment(formula). This is the 
point, the formula-with-environment construction allows both

h <- function(x,y) mymodel(y~x)
h(u,v)

and

h <- function(f) mymodel(f)
h(u~v)

to find  their variables in the right place.




-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From roger at ysidro.econ.uiuc.edu  Sun Apr 12 21:42:12 2009
From: roger at ysidro.econ.uiuc.edu (roger koenker)
Date: Sun, 12 Apr 2009 14:42:12 -0500
Subject: [Rd] data argument and environments
In-Reply-To: <49E2412C.5040204@stats.uwo.ca>
References: <5CBE3B72-0ABC-45C5-90EA-9CAA89A36A5E@ysidro.econ.uiuc.edu>
	<49E12B0A.4020407@stats.uwo.ca>
	<B402D9D9-0F6F-4D47-99E8-4712B219C4A8@ysidro.econ.uiuc.edu>
	<49E2412C.5040204@stats.uwo.ca>
Message-ID: <03F431F3-858A-44BE-82F7-5F63AB8CA9DE@ysidro.econ.uiuc.edu>

Great, thanks again, Duncan.  And to Peter.  I've adopted the enclos =  
environment(formula)
solution.

Roger

On Apr 12, 2009, at 2:29 PM, Duncan Murdoch wrote:

> roger koenker wrote:
>> Thanks.  Yes,  I wrote rqss,  and attempted to follow the structure  
>> of  lm, and various analogues,
>> for example in survival4.  My problem seems to be that my lam  
>> variable  is not part of
>> the data frame d, and I don't know how to manipulate the  
>> environment  for the formula
>> so that it is found.  There is an untangle.specials() call
>>
>> 	tmpc <- untangle.specials(Terms, "qss")
>>
>> and then each of the "specials"  terms are evaluated in:
>>
>> 	qss <- lapply(tmpc$vars, function(u) eval(parse(text = u), data))
>>
>
> I think the fix here is to specify both the envir and enclos args to  
> eval.  That is, do something like
>
> eval(parse(text=u, envir=data, enclos=environment(formula)))
>
> This says to look first in the dataframe, and then treat the  
> environment of the formula as the parent environment.  By default,  
> eval treats the calling frame as the parent.  In an lapply call,  
> that's probably local variables in lapply(), which is not what you  
> want.
>> which is fine if the data hasn't been specified so it defaults to   
>> parent.frame(), since in
>> this case variables and lam can all be found in the parent.frame,   
>> but  if
>> it is specified as a data frame for the variables of the model,  
>> then  the lam value is
>> unavailable.  My impression is that it is somewhat unusual to pass   
>> data other than
>> variables from the data frame itself for evaluation of the formula  
>> --  I thought there
>> were examples in mgcv, but I now see that  lamdas in gam() are  
>> passed  as separate
>> arguments, rather than in the special components of the formula.    
>> Perhaps I need
>> to revert to this strategy, but I'd prefer not to.  Surely, there  
>> is  some good way to modify
>> the above lapply so  that eval finds both stuff in data and in the   
>> parent.frame?  It
>> appears that I can simply define pf <- parent.frame()  and then  
>> add  enclos = pf
>> to the above eval() call,  is this ok?
>>
>
> That might work, but some day a user might produce the formula  
> somewhere else, and pass it in (e.g. if they write a wrapper  
> function for rqss):  using environment(formula) should guarantee you  
> pick up the right one.
>
> Duncan Murdoch
>
>> Roger
>>
>> On Apr 11, 2009, at 6:43 PM, Duncan Murdoch wrote:
>>
>>
>>> On 11/04/2009 6:50 PM, roger koenker wrote:
>>>
>>>> I'm having difficulty with an environmental issue:  I have an   
>>>> additive  model fitting function
>>>> with a typical call that looks like this:
>>>> require(quantreg)
>>>> n <- 100
>>>> x <- runif(n,0,10)
>>>> y <- sin(x) + rnorm(n)/5
>>>> d <- data.frame(x,y)
>>>> lam <- 2
>>>> 	f <- rqss(y ~ qss(x, lambda = lam), data = d)
>>>> this is fine when invoked as is; x and y are found in d, and lam   
>>>> is  found the .GlobalEnv,
>>>> or at least this is how I understand it.  Now,  I'd like to have  
>>>> a   function say,
>>>> 	h <- function(lam)
>>>> 		AIC(rqss(y ~ qss(x, lambda = lam), data = d))
>>>> but now,  if I do:
>>>> 	rm(lam)
>>>> 	h(1)
>>>> Error in qss1(x, constraint = constraint, lambda = lambda,  
>>>> dummies  =  dummies,  :
>>>>  object "lam" not found
>>>> worse, if there is a "lam"  in the .GlobalEnv it is used instead   
>>>> of  the argument specified to h().
>>>> If I remove the data=d argument in the function definition then  
>>>> lam  is  passed correctly.
>>>> presumably because data defaults to parent.env().   I recognize   
>>>> that  this is probably an elementary confusion on my part, but  
>>>> my   understanding of environments is very limited.
>>>> I did read  the entry for FAQ 7.12,  but I'm still unenlightened.
>>>>
>>> Formulas have environments attached to them, and modelling  
>>> functions  should look there if they don't find the object in the  
>>> data  argument. If your h is defined exactly as you wrote it, then  
>>> the  environment of the y ~ qss(...) formula will automatically be  
>>> the  evaluation frame of h, so it should be able to find lam.
>>>
>>> You wrote rqss, right?  So perhaps you aren't evaluating the   
>>> variables in the formula in the right place.  Do you use  
>>> model.frame  to do it? (See lm() for an example:  it takes the  
>>> original call to  lm, throws away all but a few arguments, and  
>>> turns it into a call to  model.frame() to find the necessary  
>>> variables.)  model.frame() knows  about environments and stuff,  
>>> but assumes linear model-like data.
>>>
>>> Duncan Murdoch
>>>
>>>
>>>> url:    www.econ.uiuc.edu/~roger                Roger Koenker
>>>> email   rkoenker at uiuc.edu                       Department of   
>>>> Economics
>>>> vox:    217-333-4558                            University of   
>>>> Illinois
>>>> fax:    217-244-6678                            Champaign, IL 61820
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>


From tshort.rlists at gmail.com  Mon Apr 13 00:59:41 2009
From: tshort.rlists at gmail.com (Tom Short)
Date: Sun, 12 Apr 2009 18:59:41 -0400
Subject: [Rd] Simple class with an automatic printing issue
Message-ID: <fd27013a0904121559hc3ccb30n83272819ca8f714a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090412/d7ed9e9a/attachment.pl>

From wdunlap at tibco.com  Mon Apr 13 05:34:41 2009
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 12 Apr 2009 20:34:41 -0700
Subject: [Rd] Simple class with an automatic printing issue
In-Reply-To: <fd27013a0904121559hc3ccb30n83272819ca8f714a@mail.gmail.com>
References: <fd27013a0904121559hc3ccb30n83272819ca8f714a@mail.gmail.com>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D7000107590F@NA-PA-VBE03.na.tibco.com>

It may have to do with the results of is.object():

  > is.object(1*structure(1,class="testClass"))
  [1] FALSE
  > is.object(structure(1,class="testClass")*1)
  [1] TRUE
  > is.object(structure(1,class="testClass"))
  [1] TRUE

is.object(x) should be true if x has a class attribute,
but 1*structute(1,class="testClass") makes a thing
with a class attribute but without the 'OBJECT' bit set.

Bill Dunlap
TIBCO Software Inc - Spotfire Division
wdunlap tibco.com  

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Tom Short
> Sent: Sunday, April 12, 2009 4:00 PM
> To: r-devel at r-project.org
> Subject: [Rd] Simple class with an automatic printing issue
> 
> I don't understand the following behavior for a simple S3 class. The
> auto-printing at the command line
> doesn't behave as I expect. I'm probably missing something, 
> but it might be
> a bug.
> 
> > print.testClass <- function(x, ...) cat("Class:", class(x), 
> ":", x, "\n")
> 
> > structure(1, class = "testClass")
> Class: testClass : 1
> 
> > print(1 * structure(1, class = "testClass"))
> Class: testClass : 1
> 
> > 1 * structure(1, class = "testClass") # why doesn't 
> auto-printing call
> print.testClass here?
> [1] 1
> attr(,"class")
> [1] "testClass"
> 
> > structure(1, class = "testClass") * 1
> Class: testClass : 1
> 
> 
> platform       i386-pc-mingw32
> arch           i386
> os             mingw32
> system         i386, mingw32
> status         RC
> major          2
> minor          9.0
> year           2009
> month          04
> day            10
> svn rev        48318
> language       R
> version.string R version 2.9.0 RC (2009-04-10 r48318)
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From 4ap1 at queensu.ca  Mon Apr 13 03:40:12 2009
From: 4ap1 at queensu.ca (4ap1 at queensu.ca)
Date: Mon, 13 Apr 2009 03:40:12 +0200 (CEST)
Subject: [Rd] dnbinom with a large size parameter (PR#13650)
Message-ID: <20090413014012.85652282C765@mail.pubhealth.ku.dk>

Full_Name: Andrey Pavlov
Version: 2.7.1 (2008-06-23)
OS: Windows Vista
Submission from: (NULL) (67.193.233.43)


Dear developers,

I discovered an issue with the dnbinom function while fitting a negative
binomial model to my data. I was using the size and mu parameterization. When
the size gets large enough, the function begins to return 1, while it should
instead return the respective Poisson probability. This can be seen in the
following simple example:

> dpois(1,lambda=1)
[1] 0.3678794
> dnbinom(1,size=1e+15,mu=1)
[1] 0.3678793
> dnbinom(1,size=3e+15,mu=1)
[1] 0.3678793

- very close to Poisson. But then I increase the size further, and it goes off
somewhat:

> dnbinom(1,size=5e+15,mu=1)
[1] 0.3658024
> dnbinom(1,size=7e+15,mu=1)
[1] 0.3572676

...until suddenly it returns 1:
> dnbinom(1,size=10e+15,mu=1)
[1] 1

This turned out to be a big and hard to track down issue for me. The bug
confused the optimizer of the likelihood function, which happened to move too
far on the size dimension and began to discover "very good" parameters. I fixed
the problem by adding a logical check, which replaced the negative binomial
probability with the Poisson one in case the size was large, but this is a very
crude solution. Perhaps it is worth fixing the internal routine.

Thanks,
Andrey


From p.dalgaard at biostat.ku.dk  Mon Apr 13 10:17:06 2009
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 13 Apr 2009 10:17:06 +0200
Subject: [Rd] dnbinom with a large size parameter (PR#13650)
In-Reply-To: <20090413014012.85652282C765@mail.pubhealth.ku.dk>
References: <20090413014012.85652282C765@mail.pubhealth.ku.dk>
Message-ID: <49E2F502.3010209@biostat.ku.dk>

4ap1 at queensu.ca wrote:
> Full_Name: Andrey Pavlov
> Version: 2.7.1 (2008-06-23)
!!!


> OS: Windows Vista
> Submission from: (NULL) (67.193.233.43)
> 
> 
> Dear developers,
> 
> I discovered an issue with the dnbinom function while fitting a negative
> binomial model to my data. I was using the size and mu parameterization. When
> the size gets large enough, the function begins to return 1, while it should
> instead return the respective Poisson probability. This can be seen in the
> following simple example:
> 
>> dpois(1,lambda=1)
> [1] 0.3678794
>> dnbinom(1,size=1e+15,mu=1)
> [1] 0.3678793
>> dnbinom(1,size=3e+15,mu=1)
> [1] 0.3678793
> 
> - very close to Poisson. But then I increase the size further, and it goes off
> somewhat:
> 
>> dnbinom(1,size=5e+15,mu=1)
> [1] 0.3658024
>> dnbinom(1,size=7e+15,mu=1)
> [1] 0.3572676
> 
> ...until suddenly it returns 1:
>> dnbinom(1,size=10e+15,mu=1)
> [1] 1
> 
> This turned out to be a big and hard to track down issue for me. The bug
> confused the optimizer of the likelihood function, which happened to move too
> far on the size dimension and began to discover "very good" parameters. I fixed
> the problem by adding a logical check, which replaced the negative binomial
> probability with the Poisson one in case the size was large, but this is a very
> crude solution. Perhaps it is worth fixing the internal routine.

Doesn't happen in 2.8.1:

 > dnbinom(1,size=10e+15,mu=1)
[1] 0.3678794

This was fixed (if you define it as a "bug" rather than an "FP accuracy 
issue") in 2.7.2/2.7.2patched.

You might at least have checked the NEWS file for references to 
dnbinom() before submitting a bug report on an older version!


-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From tshort.rlists at gmail.com  Mon Apr 13 13:42:28 2009
From: tshort.rlists at gmail.com (Tom Short)
Date: Mon, 13 Apr 2009 07:42:28 -0400
Subject: [Rd] Simple class with an automatic printing issue
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D7000107590F@NA-PA-VBE03.na.tibco.com>
References: <fd27013a0904121559hc3ccb30n83272819ca8f714a@mail.gmail.com>
	<77EB52C6DD32BA4D87471DCD70C8D7000107590F@NA-PA-VBE03.na.tibco.com>
Message-ID: <fd27013a0904130442t2c6e7ad4r21b5e6c19ec0ed9f@mail.gmail.com>

Thanks, Bill. Searching R-devel based on your input shows that this is
a known issue as pointed out by Martin Maechler:

https://stat.ethz.ch/pipermail/r-devel/2008-October/051109.html

- Tom



On Sun, Apr 12, 2009 at 11:34 PM, William Dunlap <wdunlap at tibco.com> wrote:
>
> It may have to do with the results of is.object():
>
> ?> is.object(1*structure(1,class="testClass"))
> ?[1] FALSE
> ?> is.object(structure(1,class="testClass")*1)
> ?[1] TRUE
> ?> is.object(structure(1,class="testClass"))
> ?[1] TRUE
>
> is.object(x) should be true if x has a class attribute,
> but 1*structute(1,class="testClass") makes a thing
> with a class attribute but without the 'OBJECT' bit set.
>
> Bill Dunlap
> TIBCO Software Inc - Spotfire Division
> wdunlap tibco.com
>
> > -----Original Message-----
> > From: r-devel-bounces at r-project.org
> > [mailto:r-devel-bounces at r-project.org] On Behalf Of Tom Short
> > Sent: Sunday, April 12, 2009 4:00 PM
> > To: r-devel at r-project.org
> > Subject: [Rd] Simple class with an automatic printing issue
> >
> > I don't understand the following behavior for a simple S3 class. The
> > auto-printing at the command line
> > doesn't behave as I expect. I'm probably missing something,
> > but it might be
> > a bug.
> >
> > > print.testClass <- function(x, ...) cat("Class:", class(x),
> > ":", x, "\n")
> >
> > > structure(1, class = "testClass")
> > Class: testClass : 1
> >
> > > print(1 * structure(1, class = "testClass"))
> > Class: testClass : 1
> >
> > > 1 * structure(1, class = "testClass") # why doesn't
> > auto-printing call
> > print.testClass here?
> > [1] 1
> > attr(,"class")
> > [1] "testClass"
> >
> > > structure(1, class = "testClass") * 1
> > Class: testClass : 1
> >
> >
> > platform ? ? ? i386-pc-mingw32
> > arch ? ? ? ? ? i386
> > os ? ? ? ? ? ? mingw32
> > system ? ? ? ? i386, mingw32
> > status ? ? ? ? RC
> > major ? ? ? ? ?2
> > minor ? ? ? ? ?9.0
> > year ? ? ? ? ? 2009
> > month ? ? ? ? ?04
> > day ? ? ? ? ? ?10
> > svn rev ? ? ? ?48318
> > language ? ? ? R
> > version.string R version 2.9.0 RC (2009-04-10 r48318)
> >
> > ? ? ? [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >


From kfmfe04 at gmail.com  Mon Apr 13 10:46:27 2009
From: kfmfe04 at gmail.com (Ken-JP)
Date: Mon, 13 Apr 2009 01:46:27 -0700 (PDT)
Subject: [Rd]  BUG in RODBC() on Ubuntu 64amd : rows_at_time=1024
Message-ID: <23019424.post@talk.nabble.com>


R 2.8.1
Ubuntu 64amd
RODBC 1.2-5

---------------------------------

This was a hard-to-track bug for me, because sqlQuery() did not fail -
instead, it looked like it returned some good data and some NA where there
should have been numbers and 0 where there should have been NAs.

I did:

(a) sqlQuery( o, qry, as.is=TRUE, errors=TRUE, rows_at_time=1024 );
(b) sqlQuery( o, qry, as.is=TRUE, errors=TRUE );

My qry was a bit complex, with an outer join, so the first thing I did was
check from a win32 bit machine and check on 64amd with the mysql client
command-line.  Both worked fine.

Both (a) and (b) work fine from a XP Pro 32-bit R 2.8.1 installation.

On the amd64, when I tightened up my query to return less than 1024 lines,
(a) returned the correct result.  Over 1024, and (a) still returned the
right number of rows, but the results were incorrect.  Since I don't need
the rows_at_time argument, my workaround is to just use (b).

I wasn't sure where to post this, so I apologize in advance if this is the
wrong place.

- Ken



-- 
View this message in context: http://www.nabble.com/BUG-in-RODBC%28%29-on-Ubuntu-64amd-%3A-rows_at_time%3D1024-tp23019424p23019424.html
Sent from the R devel mailing list archive at Nabble.com.


From zhlong8 at yeah.net  Mon Apr 13 15:00:08 2009
From: zhlong8 at yeah.net (zhlong8 at yeah.net)
Date: Mon, 13 Apr 2009 15:00:08 +0200 (CEST)
Subject: [Rd] Rgui bug (PR#13654)
Message-ID: <20090413130008.8ED90282C765@mail.pubhealth.ku.dk>

Full_Name: Zhang Long
Version: 2.8.1
OS: winxp sp3
Submission from: (NULL) (121.33.190.173)


the script editor did not respect user preferences for the "User Input colour".
it's always black, so when I set my console "background colour" to black, I
can't
use the script editor


From murdoch at stats.uwo.ca  Mon Apr 13 17:34:19 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 13 Apr 2009 11:34:19 -0400
Subject: [Rd] Rgui bug (PR#13654)
In-Reply-To: <20090413130008.8ED90282C765@mail.pubhealth.ku.dk>
References: <20090413130008.8ED90282C765@mail.pubhealth.ku.dk>
Message-ID: <49E35B7B.8030407@stats.uwo.ca>

On 4/13/2009 9:00 AM, zhlong8 at yeah.net wrote:
> Full_Name: Zhang Long
> Version: 2.8.1
> OS: winxp sp3
> Submission from: (NULL) (121.33.190.173)
> 
> 
> the script editor did not respect user preferences for the "User Input colour".
> it's always black, so when I set my console "background colour" to black, I
> can't
> use the script editor

Please look at the beta test version:  this has been fixed already.

Duncan Murdoch


From wdunlap at tibco.com  Mon Apr 13 20:56:51 2009
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 13 Apr 2009 11:56:51 -0700
Subject: [Rd] should sub(perl=TRUE) also handle \E in replacement,
	to complement \U and \L?
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D70001075A06@NA-PA-VBE03.na.tibco.com>

Currently sub(perl=TRUE) allows you to specify \U and \L
in the replacement argument so that the rest of the subpatterns
in the line (the \\<digit> things) will be converted to upper
or lower case, respectively.  perl also also has a \E operator
to end these case conversions for the rest of the subpatterns
(so they retain whatever case they had in the original text).
For symmetry's sake I think it would be nice if R supported that
also.  E.g., to capitalize the first and last letters of every
word, leaving the case of the interior letters alone, could be
done with:

> gsub("(\\w)(\\w*)(\\w)", "\\U\\1\\E\\2\\U\\3", "useRs may fly into JFK
or laGuardia", perl=TRUE)
[1] "UseRS MaY FlY IntO JFK OR LaGuardiA"
> sub("(\\w)(\\w*)(\\w)", "\\U\\1\\E\\2\\U\\3", "useRs may fly into JFK
or laGuardia", perl=TRUE)
[1] "UseRS may fly into JFK or laGuardia"

A question regarding this came up in r-help today.

Bill Dunlap
TIBCO Software Inc - Spotfire Division
wdunlap tibco.com 

Index: src/library/base/man/grep.Rd
===================================================================
--- src/library/base/man/grep.Rd	(revision 48319)
+++ src/library/base/man/grep.Rd	(working copy)
@@ -73,7 +73,7 @@
     \code{"\\9"} to parenthesized subexpressions of \code{pattern}.
For
     \code{perl = TRUE} only, it can also contain \code{"\\U"} or
     \code{"\\L"} to convert the rest of the replacement to upper or
-    lower case.
+    lower case, or \code{"\\E"} to end such case conversion.
   }
 }
 \details{


Index: src/main/pcre.c
===================================================================
--- src/main/pcre.c	(revision 48319)
+++ src/main/pcre.c	(working copy)
@@ -90,6 +90,9 @@
 	    } else if (p[1] == 'L') {
 		p++; n -= 2;
 		upper = FALSE; lower = TRUE;
+	    } else if (p[1] == 'E') { /* end case modification */
+		p++; n -= 2;
+		upper = FALSE; lower = FALSE;
 	    } else if (p[1] == 0) {
 		/* can't escape the final '\0' */
 		n--;
@@ -168,6 +171,9 @@
 	    } else if (p[1] == 'L') {
 		p += 2;
 		upper = FALSE; lower = TRUE;
+	    } else if (p[1] == 'E') { /* end case modification */
+		p += 2;
+		upper = FALSE; lower = FALSE;
 	    } else if (p[1] == 0) {
 		p += 1;
 	    } else {
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: pcre.diff.txt
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090413/db64170b/attachment.txt>

From tchibadou at hotmail.com  Tue Apr 14 11:49:40 2009
From: tchibadou at hotmail.com (Lore M)
Date: Tue, 14 Apr 2009 09:49:40 +0000
Subject: [Rd] using Sweave, how to save a plot in a given size
Message-ID: <BAY134-W474BCD64C9B96C6D155D01A47C0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090414/f253e822/attachment.pl>

From tchibadou at hotmail.com  Tue Apr 14 12:01:02 2009
From: tchibadou at hotmail.com (Lore M)
Date: Tue, 14 Apr 2009 10:01:02 +0000
Subject: [Rd] using Sweave, how to save a plot in a given size
Message-ID: <BAY134-W437886CD0C2F67922D2795A47C0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090414/60e1c617/attachment.pl>

From jens.henrik at badsberg.eu  Tue Apr 14 13:57:37 2009
From: jens.henrik at badsberg.eu (jens.henrik at badsberg.eu)
Date: Tue, 14 Apr 2009 13:57:37 +0200 (CEST)
Subject: [Rd] 'R CMD build --binary BUNDLE' and Windows
In-Reply-To: <49DDB1B4.1030905@biostat.ku.dk>
References: <1BFF99DC9507426792104D6A4DD70741@Scaleo>
	<49DDB1B4.1030905@biostat.ku.dk>
Message-ID: <d313d5d381a2f9a2483cccd5248cf136.squirrel@webmail01.one.com>

It has only been fixed partly:

'Contains' fields with more than about 72 characters are 'corrupted' when
the DESCRIPTION file is 'reformated' in the process from 'incomming' to
'http://cran.at.r-project.org/web/packages/' - or R (2.9.0) cannot handle
'contains' fields with more than one line.

The bundle 'CoCo version 0.1.7.5' I submitted april 3th now checks OK by R
version 2.9.0 RC: http://win-builder.r-project.org/JDzIuXv33Z9B/

But a check on file 'CoCo_0.1.7.5.tar.gz' from
http://cran.at.r-project.org/web/packages/CoCo/index.html is not OK:
http://win-builder.r-project.org/9Nh7tz03uCV8/

The difference is that the DESCRIPTION file of the bundle is 'reformated'
by CRAN, dividing the 'Contains' filed onto two lines.

Regards,

Jens Henrik


'diff' of DESCRIPTION files:
< - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
$ diff -b CoCo/DESCRIPTION ../../2009.04.03/mnt/CoCo/DESCRIPTION
2,3c2
< Contains: CoCoObjects CoCoCore CoCoRaw CoCoOldData CoCoGraph CoCo
<         CoCoCg
---
> Contains: CoCoObjects CoCoCore CoCoRaw CoCoOldData CoCoGraph CoCo CoCoCg
9,15c8,13
< BundleDescription: Interface to CoCo from R - Graphical modelling by
<         CoCo. The package CoCo handles discrete data by log-linear
<         models and contingency tables. CoCoCg is for both discrete and
<         continuous data by CG-regressions. CoCoCore and CoCoRaw contain
<         respectively the one entry point interface function to CoCo end
<         the interface functions for the commands of CoCo. CoCoObjects
<         and CoCoGraph are base and extension with objects and graphs.
---
> BundleDescription: Interface to CoCo from R - Graphical modelling by CoCo.
>       The package CoCo handles discrete data by log-linear models and
contingency tables.
>       CoCoCg is for both discrete and continuous data by CG-regressions.
>       CoCoCore and CoCoRaw contain respectively the one entry point
interface function
>       to CoCo end the interface functions for the commands of CoCo.
>       CoCoObjects and CoCoGraph are base and extension with objects and
graphs.
17,18c15,16
< Copyright: Copyright (C) by Jens Henrik Badsberg, 1991-2009, non-profit
<         use and redistribution permitted (Artistic License 2.0)
---
> Copyright: Copyright (C) by Jens Henrik Badsberg, 1991-2009,
>       non-profit use and redistribution permitted (Artistic License 2.0)
22,23d19
< Repository: CRAN
< Date/Publication: 2009-04-04 20:41:49
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - >


Submitted DESCRIPTION file of the CoCo-bundle:
< - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
Bundle: CoCo
Contains: CoCoObjects CoCoCore CoCoRaw CoCoOldData CoCoGraph CoCo CoCoCg
Version: 0.1.7.5
Date: 03.04.2009
Author: Jens Henrik Badsberg <coco at badsberg.eu>
Maintainer: Jens Henrik Badsberg <coco at badsberg.eu>
Depends: R (>= 2.0.0), dynamicGraph (>= 0.2.0), MASS, methods
BundleDescription: Interface to CoCo from R - Graphical modelling by CoCo.
	The package CoCo handles discrete data by log-linear models and
contingency tables.
	CoCoCg is for both discrete and continuous data by CG-regressions.
	CoCoCore and CoCoRaw contain respectively the one entry point interface
function
	to CoCo end the interface functions for the commands of CoCo.
	CoCoObjects and CoCoGraph are base and extension with objects and graphs.
License: file LICENSE
Copyright: Copyright (C) by Jens Henrik Badsberg, 1991-2009,
	non-profit use and redistribution permitted (Artistic License 2.0)
Address: Andreas Bjorns Gade 21, 2. tv, 1428 Kobenhavn K, Denmark
URL: http://www.badsberg.eu
Packaged: Fri Apr  3 23:41:15 2009; CoCo
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - >


DESCRIPTION file of the CoCo-bundle on CRAN:
< - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
Bundle: CoCo
Contains: CoCoObjects CoCoCore CoCoRaw CoCoOldData CoCoGraph CoCo
        CoCoCg
Version: 0.1.7.5
Date: 03.04.2009
Author: Jens Henrik Badsberg <coco at badsberg.eu>
Maintainer: Jens Henrik Badsberg <coco at badsberg.eu>
Depends: R (>= 2.0.0), dynamicGraph (>= 0.2.0), MASS, methods
BundleDescription: Interface to CoCo from R - Graphical modelling by
        CoCo. The package CoCo handles discrete data by log-linear
        models and contingency tables. CoCoCg is for both discrete and
        continuous data by CG-regressions. CoCoCore and CoCoRaw contain
        respectively the one entry point interface function to CoCo end
        the interface functions for the commands of CoCo. CoCoObjects
        and CoCoGraph are base and extension with objects and graphs.
License: file LICENSE
Copyright: Copyright (C) by Jens Henrik Badsberg, 1991-2009, non-profit
        use and redistribution permitted (Artistic License 2.0)
Address: Andreas Bjorns Gade 21, 2. tv, 1428 Kobenhavn K, Denmark
URL: http://www.badsberg.eu
Packaged: Fri Apr 3 23:41:15 2009; CoCo
Repository: CRAN
Date/Publication: 2009-04-04 20:41:49
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - >


> coco at badsberg.eu wrote:
>> 'R CMD build --binary BUNDLE' and Windows.
>>
>>
>>
>> When using R version 2.9.0 beta for 'R CMD build --binary CoCo' on
>> Windows
>> only the first package of the 'Contains' field of the bundle DESCRIPTION
>> file ends up in the zip file.
>>
>> (Same result for the bundle 'VR' by R version 2.9.0 beta.)
>>
>>
>>
>> The check of the CoCo bundle version 0.1.7.5 by R version 2.9.0 beta is
>> OK
>> (on my machine), see attached 00check.log.
>>
>>
>>
>> The zip-file is OK by versions 2.6.0, 2.6.2, 2.7.2, and 2.8.0 of R.
>
> Brian fixed this, please check the current version (r48312).
>
>
> --
>     O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>    c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>   (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907
>


From romain.francois at dbmail.com  Tue Apr 14 17:32:24 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Tue, 14 Apr 2009 17:32:24 +0200
Subject: [Rd] top level condition handlers
Message-ID: <49E4AC88.2040900@dbmail.com>

Hello,

I would like to establish top level condition handlers and restarts, so 
that I don't explicit calls to withCallingHandlers and withRestarts in 
many places:

For example :

 > customError
function( message ){
  err <- simpleError( message )
  class( err ) <- c( "customError", class( err) )
   err
}
 > withCallingHandlers( { signalCondition(customError( "ouch")) } , 
customError = function(e) cat( "gotcha : ", e$message, "\n" ) )
gotcha :  ouch
NULL

I'd like to be able to do something like this:

 > topLevelCallingHandlers( customError = function(e) cat( "gotcha : ", 
e$message, "\n" ) )
 > signalCondition( customError( "ouch") )

and the "customError" condition to be caught by the handler I set up 
previously.

I tried modifying withCallingHandlers like this:

topLevelCallingHandlers <- function(...) {
    handlers <- list(...)
    classes <- names(handlers)
    if (length(classes) != length(handlers))
        stop("bad handler specification")
    .Internal(.addCondHands(classes, handlers, .GlobalEnv, .GlobalEnv, 
TRUE))
    invisible( NULL )
}
 > withCallingHandlers
function (expr, ...)
{
    handlers <- list(...)
    classes <- names(handlers)
    parentenv <- parent.frame()
    if (length(classes) != length(handlers))
        stop("bad handler specification")
    .Internal(.addCondHands(classes, handlers, parentenv, NULL,
        TRUE))
    expr
}
<environment: namespace:base>

but it does not work, probably because the handler stack is reset 
somewhere.

Would it work if I poke into the RTopLevel.handlerstack instead of the 
R_HandlerStack as .addCondHands is doing ?

R_Toplevel.handlerstack = R_HandlerStack;
R_Toplevel.restartstack = R_RestartStack;
R_GlobalContext = R_ToplevelContext = &R_Toplevel;

Romain

-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From maechler at stat.math.ethz.ch  Tue Apr 14 17:51:16 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 14 Apr 2009 17:51:16 +0200
Subject: [Rd] should sub(perl=TRUE) also handle \E in replacement,
	to complement \U and \L?
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D70001075A06@NA-PA-VBE03.na.tibco.com>
References: <77EB52C6DD32BA4D87471DCD70C8D70001075A06@NA-PA-VBE03.na.tibco.com>
Message-ID: <18916.45300.570086.267927@lynne.math.ethz.ch>

>>>>> "WD" == William Dunlap <wdunlap at tibco.com>
>>>>>     on Mon, 13 Apr 2009 11:56:51 -0700 writes:

    WD> Currently sub(perl=TRUE) allows you to specify \U and \L
    WD> in the replacement argument so that the rest of the
    WD> subpatterns in the line (the \\<digit> things) will be
    WD> converted to upper or lower case, respectively.  perl
    WD> also also has a \E operator to end these case
    WD> conversions for the rest of the subpatterns (so they
    WD> retain whatever case they had in the original text).
    WD> For symmetry's sake I think it would be nice if R
    WD> supported that also.  E.g., to capitalize the first and
    WD> last letters of every word, leaving the case of the
    WD> interior letters alone, could be done with:

    >> gsub("(\\w)(\\w*)(\\w)", "\\U\\1\\E\\2\\U\\3", "useRs may
    >> fly into JFK
    WD> or laGuardia", perl=TRUE) [1] "UseRS MaY FlY IntO JFK OR
    WD> LaGuardiA"
    >> sub("(\\w)(\\w*)(\\w)", "\\U\\1\\E\\2\\U\\3", "useRs may
    >> fly into JFK
    WD> or laGuardia", perl=TRUE) [1] "UseRS may fly into JFK or
    WD> laGuardia"

    WD> A question regarding this came up in r-help today.

    WD> Bill Dunlap TIBCO Software Inc - Spotfire Division
    WD> wdunlap tibco.com

Thanks a lot, Bill, for your patch!

I have applied and committed it (after testing) to R-devel
[rev. 48321].

Best regards,
Martin Maechler, ETH Zurich


From harry.southworth at googlemail.com  Tue Apr 14 19:24:45 2009
From: harry.southworth at googlemail.com (Harry Southworth)
Date: Tue, 14 Apr 2009 18:24:45 +0100
Subject: [Rd] Problem cross-compiling on Ubuntu
Message-ID: <9056ff740904141024r45562441t4e430a2125d49d9b@mail.gmail.com>

I'm using Ubuntu 8.10 (Intrepid Ibex) and R 2.7.1.

I've built a package from source (a modified version of gbm) and it
contains some C++ code.  I now want to cross-compile it to get a
Windows version.

I installed R using
   sudo apt-get update
   sudo apt-get install r-base
   sudo apt-get install r-base-dev

So far as I can tell, I've also followed all the instructions in the
guide to cross-compiling by Yan and Rossini.

When I try to cross-compile I get a load of errors, apparently due to
R.h (and possibly other things) not being found:

[snip - everything fine up to here]
i586-mingw32-g++ -isystem
/home/harry/RLibrary/forWindows/cross-tools/i586-mingw32/include
-I/home/harry/RLibrary/forWindows/WinR/R-2.6.0/include    -Wall -O2
-c adaboost.cpp -o adaboost.o
In file included from dataset.h:20,
                 from node_terminal.h:21,
                 from distribution.h:20,
                 from adaboost.h:20,
                 from adaboost.cpp:3:
buildinfo.h:8:19: R.h: No such file or directory
adaboost.cpp: In member function `virtual GBMRESULT
CAdaBoost::ComputeWorkingResponse(double*, double*, double*, double*,
double*, double*, bool*, long unsigned int, int)':
adaboost.cpp:33: error: `exp' was not declared in this scope
adaboost.cpp:33: warning: unused variable 'exp'
[etc. - snip]

I'd be grateful if anyone can suggest what I might be doing wrong.

Many thanks,
Harry


From khansen at stat.berkeley.edu  Tue Apr 14 20:02:23 2009
From: khansen at stat.berkeley.edu (Kasper Daniel Hansen)
Date: Tue, 14 Apr 2009 11:02:23 -0700
Subject: [Rd] Problem cross-compiling on Ubuntu
In-Reply-To: <9056ff740904141024r45562441t4e430a2125d49d9b@mail.gmail.com>
References: <9056ff740904141024r45562441t4e430a2125d49d9b@mail.gmail.com>
Message-ID: <2D3DC673-7008-4909-A11E-FC3C8989BB11@stat.berkeley.edu>

Is there any particular reason why you are doing this, instead of just  
using
   http://win-builder.r-project.org/
After that server went online, I see little (no) need for cross- 
compilation, I must say.

Kasper

On Apr 14, 2009, at 10:24 , Harry Southworth wrote:

> I'm using Ubuntu 8.10 (Intrepid Ibex) and R 2.7.1.
>
> I've built a package from source (a modified version of gbm) and it
> contains some C++ code.  I now want to cross-compile it to get a
> Windows version.
>
> I installed R using
>   sudo apt-get update
>   sudo apt-get install r-base
>   sudo apt-get install r-base-dev
>
> So far as I can tell, I've also followed all the instructions in the
> guide to cross-compiling by Yan and Rossini.
>
> When I try to cross-compile I get a load of errors, apparently due to
> R.h (and possibly other things) not being found:
>
> [snip - everything fine up to here]
> i586-mingw32-g++ -isystem
> /home/harry/RLibrary/forWindows/cross-tools/i586-mingw32/include
> -I/home/harry/RLibrary/forWindows/WinR/R-2.6.0/include    -Wall -O2
> -c adaboost.cpp -o adaboost.o
> In file included from dataset.h:20,
>                 from node_terminal.h:21,
>                 from distribution.h:20,
>                 from adaboost.h:20,
>                 from adaboost.cpp:3:
> buildinfo.h:8:19: R.h: No such file or directory
> adaboost.cpp: In member function `virtual GBMRESULT
> CAdaBoost::ComputeWorkingResponse(double*, double*, double*, double*,
> double*, double*, bool*, long unsigned int, int)':
> adaboost.cpp:33: error: `exp' was not declared in this scope
> adaboost.cpp:33: warning: unused variable 'exp'
> [etc. - snip]
>
> I'd be grateful if anyone can suggest what I might be doing wrong.
>
> Many thanks,
> Harry
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From harry.southworth at googlemail.com  Tue Apr 14 21:20:25 2009
From: harry.southworth at googlemail.com (Harry Southworth)
Date: Tue, 14 Apr 2009 20:20:25 +0100
Subject: [Rd] Problem cross-compiling on Ubuntu
In-Reply-To: <49E4D49A.3010608@openanalytics.be>
References: <9056ff740904141024r45562441t4e430a2125d49d9b@mail.gmail.com>
	<2D3DC673-7008-4909-A11E-FC3C8989BB11@stat.berkeley.edu>
	<49E4D49A.3010608@openanalytics.be>
Message-ID: <9056ff740904141220u7691fec0q355354d1c8504323@mail.gmail.com>

I'm new to building packages that have source code and I didn't know
about that site. In any event, it is an experimental private build for
testing, and it is more convenient for me to do most of the testing in
a Windows environment. I've spent a lot of time failing to build from
source on Windows, and would prefer not to name myself as maintainer
of someone else's package.

But, since it looks like that might be the easiest route, I've just
let the maintainer know what I'm up to and asked if he's fine with me
doing that.

Thanks,
Harry

On Tue, Apr 14, 2009 at 7:23 PM, Tobias Verbeke
<tobias.verbeke at openanalytics.be> wrote:
> Kasper Daniel Hansen wrote:
>
>> Is there any particular reason why you are doing this, instead of just
>> using
>> ?http://win-builder.r-project.org/
>> After that server went online, I see little (no) need for
>> cross-compilation, I must say.
>
> That service is very useful indeed, but I can imagine
> situations where one would be better off with cross-compiling
> e.g. when compiling (on a customer's request) Windows versions
> of packages that contain sensitive customer data.
>
> Best,
> Tobias
>
>> On Apr 14, 2009, at 10:24 , Harry Southworth wrote:
>>
>>> I'm using Ubuntu 8.10 (Intrepid Ibex) and R 2.7.1.
>>>
>>> I've built a package from source (a modified version of gbm) and it
>>> contains some C++ code. ?I now want to cross-compile it to get a
>>> Windows version.
>>>
>>> I installed R using
>>> ?sudo apt-get update
>>> ?sudo apt-get install r-base
>>> ?sudo apt-get install r-base-dev
>>>
>>> So far as I can tell, I've also followed all the instructions in the
>>> guide to cross-compiling by Yan and Rossini.
>>>
>>> When I try to cross-compile I get a load of errors, apparently due to
>>> R.h (and possibly other things) not being found:
>>>
>>> [snip - everything fine up to here]
>>> i586-mingw32-g++ -isystem
>>> /home/harry/RLibrary/forWindows/cross-tools/i586-mingw32/include
>>> -I/home/harry/RLibrary/forWindows/WinR/R-2.6.0/include ? ?-Wall -O2
>>> -c adaboost.cpp -o adaboost.o
>>> In file included from dataset.h:20,
>>> ? ? ? ? ? ? ? ?from node_terminal.h:21,
>>> ? ? ? ? ? ? ? ?from distribution.h:20,
>>> ? ? ? ? ? ? ? ?from adaboost.h:20,
>>> ? ? ? ? ? ? ? ?from adaboost.cpp:3:
>>> buildinfo.h:8:19: R.h: No such file or directory
>>> adaboost.cpp: In member function `virtual GBMRESULT
>>> CAdaBoost::ComputeWorkingResponse(double*, double*, double*, double*,
>>> double*, double*, bool*, long unsigned int, int)':
>>> adaboost.cpp:33: error: `exp' was not declared in this scope
>>> adaboost.cpp:33: warning: unused variable 'exp'
>>> [etc. - snip]
>>>
>>> I'd be grateful if anyone can suggest what I might be doing wrong.
>>>
>>> Many thanks,
>>> Harry
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
>


From simon.urbanek at r-project.org  Tue Apr 14 22:05:45 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 14 Apr 2009 16:05:45 -0400
Subject: [Rd] Problem cross-compiling on Ubuntu
In-Reply-To: <9056ff740904141220u7691fec0q355354d1c8504323@mail.gmail.com>
References: <9056ff740904141024r45562441t4e430a2125d49d9b@mail.gmail.com>
	<2D3DC673-7008-4909-A11E-FC3C8989BB11@stat.berkeley.edu>
	<49E4D49A.3010608@openanalytics.be>
	<9056ff740904141220u7691fec0q355354d1c8504323@mail.gmail.com>
Message-ID: <8CA9A141-A169-4A7A-B48D-598E163535D5@r-project.org>


On Apr 14, 2009, at 15:20 , Harry Southworth wrote:

> I'm new to building packages that have source code and I didn't know
> about that site. In any event, it is an experimental private build for
> testing, and it is more convenient for me to do most of the testing in
> a Windows environment. I've spent a lot of time failing to build from
> source on Windows,

Hmm.. it's should be really easy those days - just get the  
Rtools29.exe from
http://www.murdoch-sutherland.com/Rtools/
and you should be set ...

Cheers,
Simon


> and would prefer not to name myself as maintainer
> of someone else's package.
>
> But, since it looks like that might be the easiest route, I've just
> let the maintainer know what I'm up to and asked if he's fine with me
> doing that.
>
> Thanks,
> Harry
>
> On Tue, Apr 14, 2009 at 7:23 PM, Tobias Verbeke
> <tobias.verbeke at openanalytics.be> wrote:
>> Kasper Daniel Hansen wrote:
>>
>>> Is there any particular reason why you are doing this, instead of  
>>> just
>>> using
>>>  http://win-builder.r-project.org/
>>> After that server went online, I see little (no) need for
>>> cross-compilation, I must say.
>>
>> That service is very useful indeed, but I can imagine
>> situations where one would be better off with cross-compiling
>> e.g. when compiling (on a customer's request) Windows versions
>> of packages that contain sensitive customer data.
>>
>> Best,
>> Tobias
>>
>>> On Apr 14, 2009, at 10:24 , Harry Southworth wrote:
>>>
>>>> I'm using Ubuntu 8.10 (Intrepid Ibex) and R 2.7.1.
>>>>
>>>> I've built a package from source (a modified version of gbm) and it
>>>> contains some C++ code.  I now want to cross-compile it to get a
>>>> Windows version.
>>>>
>>>> I installed R using
>>>>  sudo apt-get update
>>>>  sudo apt-get install r-base
>>>>  sudo apt-get install r-base-dev
>>>>
>>>> So far as I can tell, I've also followed all the instructions in  
>>>> the
>>>> guide to cross-compiling by Yan and Rossini.
>>>>
>>>> When I try to cross-compile I get a load of errors, apparently  
>>>> due to
>>>> R.h (and possibly other things) not being found:
>>>>
>>>> [snip - everything fine up to here]
>>>> i586-mingw32-g++ -isystem
>>>> /home/harry/RLibrary/forWindows/cross-tools/i586-mingw32/include
>>>> -I/home/harry/RLibrary/forWindows/WinR/R-2.6.0/include    -Wall -O2
>>>> -c adaboost.cpp -o adaboost.o
>>>> In file included from dataset.h:20,
>>>>                from node_terminal.h:21,
>>>>                from distribution.h:20,
>>>>                from adaboost.h:20,
>>>>                from adaboost.cpp:3:
>>>> buildinfo.h:8:19: R.h: No such file or directory
>>>> adaboost.cpp: In member function `virtual GBMRESULT
>>>> CAdaBoost::ComputeWorkingResponse(double*, double*, double*,  
>>>> double*,
>>>> double*, double*, bool*, long unsigned int, int)':
>>>> adaboost.cpp:33: error: `exp' was not declared in this scope
>>>> adaboost.cpp:33: warning: unused variable 'exp'
>>>> [etc. - snip]
>>>>
>>>> I'd be grateful if anyone can suggest what I might be doing wrong.
>>>>
>>>> Many thanks,
>>>> Harry
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From edd at debian.org  Tue Apr 14 22:21:46 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 14 Apr 2009 15:21:46 -0500
Subject: [Rd] Problem cross-compiling on Ubuntu
In-Reply-To: <9056ff740904141024r45562441t4e430a2125d49d9b@mail.gmail.com>
References: <9056ff740904141024r45562441t4e430a2125d49d9b@mail.gmail.com>
Message-ID: <18916.61530.977784.961317@ron.nulle.part>


Harry,

On 14 April 2009 at 18:24, Harry Southworth wrote:
| I'm using Ubuntu 8.10 (Intrepid Ibex) and R 2.7.1.
                                            ^^^^^^^

[ You can also get R 2.8.1 for free, see the R FAQ and search Ubuntu, or go
  directly to http://cran.r-project.org/bin/linux/ubuntu ]

| I've built a package from source (a modified version of gbm) and it
| contains some C++ code.  I now want to cross-compile it to get a
| Windows version.
[...]
| [snip - everything fine up to here]
| i586-mingw32-g++ -isystem
| /home/harry/RLibrary/forWindows/cross-tools/i586-mingw32/include
| -I/home/harry/RLibrary/forWindows/WinR/R-2.6.0/include    -Wall -O2
                                         ^^^^^^^

So you are working with R 2.7,1 and R 2.6.0. May not be for the faint of
heart as some interfaces do change...

| -c adaboost.cpp -o adaboost.o
| In file included from dataset.h:20,
|                  from node_terminal.h:21,
|                  from distribution.h:20,
|                  from adaboost.h:20,
|                  from adaboost.cpp:3:
| buildinfo.h:8:19: R.h: No such file or directory
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

You may not get far til you get that sorted out -- you do need R.h from the
right place.

But as others have said, Rtools29.exe is fairly straightforward to use, esp
if you know how to use the R / gcc toolchain on Linux. And the win-builder is
also a very fine service.

Good luck, Dirk

-- 
Three out of two people have difficulties with fractions.


From harry.southworth at googlemail.com  Tue Apr 14 22:56:36 2009
From: harry.southworth at googlemail.com (Harry Southworth)
Date: Tue, 14 Apr 2009 21:56:36 +0100
Subject: [Rd] Problem cross-compiling on Ubuntu
In-Reply-To: <18916.61530.977784.961317@ron.nulle.part>
References: <9056ff740904141024r45562441t4e430a2125d49d9b@mail.gmail.com>
	<18916.61530.977784.961317@ron.nulle.part>
Message-ID: <9056ff740904141356m41946d14t3487dd8b851b1d1f@mail.gmail.com>

Thanks to everyone who responded. I should now have enough options to
make progress.

The Windows tools have been updated since the last time i tried, so
I'll have another go.

I noticed the 2.6.0/2.7.1 discrepancy, updated everything, and found
it was still there. Since the problem I'm having seems pretty basic
(missing .h files), I thought that first getting the headers and then
seeing if the discrepancy matters would be a reasonable approach.
Maybe not, though.

Anyway, once more, thanks to everyone who responded.

Harry

On Tue, Apr 14, 2009 at 9:21 PM, Dirk Eddelbuettel <edd at debian.org> wrote:
>
> Harry,
>
> On 14 April 2009 at 18:24, Harry Southworth wrote:
> | I'm using Ubuntu 8.10 (Intrepid Ibex) and R 2.7.1.
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?^^^^^^^
>
> [ You can also get R 2.8.1 for free, see the R FAQ and search Ubuntu, or go
> ?directly to http://cran.r-project.org/bin/linux/ubuntu ]
>
> | I've built a package from source (a modified version of gbm) and it
> | contains some C++ code. ?I now want to cross-compile it to get a
> | Windows version.
> [...]
> | [snip - everything fine up to here]
> | i586-mingw32-g++ -isystem
> | /home/harry/RLibrary/forWindows/cross-tools/i586-mingw32/include
> | -I/home/harry/RLibrary/forWindows/WinR/R-2.6.0/include ? ?-Wall -O2
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ^^^^^^^
>
> So you are working with R 2.7,1 and R 2.6.0. May not be for the faint of
> heart as some interfaces do change...
>
> | -c adaboost.cpp -o adaboost.o
> | In file included from dataset.h:20,
> | ? ? ? ? ? ? ? ? ?from node_terminal.h:21,
> | ? ? ? ? ? ? ? ? ?from distribution.h:20,
> | ? ? ? ? ? ? ? ? ?from adaboost.h:20,
> | ? ? ? ? ? ? ? ? ?from adaboost.cpp:3:
> | buildinfo.h:8:19: R.h: No such file or directory
> ? ? ? ? ? ? ? ? ? ?^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
>
> You may not get far til you get that sorted out -- you do need R.h from the
> right place.
>
> But as others have said, Rtools29.exe is fairly straightforward to use, esp
> if you know how to use the R / gcc toolchain on Linux. And the win-builder is
> also a very fine service.
>
> Good luck, Dirk
>
> --
> Three out of two people have difficulties with fractions.
>


From xyxyye at gmail.com  Tue Apr 14 22:57:34 2009
From: xyxyye at gmail.com (Xiangyang Ye)
Date: Tue, 14 Apr 2009 14:57:34 -0600
Subject: [Rd] R console freezes after several runs of compiled C code
Message-ID: <eb622cbf0904141357r4d6c4f16y5b65ff4761ad17ec@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090414/9992cc46/attachment.pl>

From simon.urbanek at r-project.org  Wed Apr 15 01:55:23 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 14 Apr 2009 19:55:23 -0400
Subject: [Rd] R console freezes after several runs of compiled C code
In-Reply-To: <eb622cbf0904141357r4d6c4f16y5b65ff4761ad17ec@mail.gmail.com>
References: <eb622cbf0904141357r4d6c4f16y5b65ff4761ad17ec@mail.gmail.com>
Message-ID: <9C9B2445-0192-4AD8-A6DC-CEB5F12027E5@r-project.org>


On Apr 14, 2009, at 4:57 PM, Xiangyang Ye wrote:

> Hi All,
>
> I tried my best to figure out how to deal with the freezing R  
> console but
> with no luck. I followed the instructions of calling R_ProcessEvents()
> regularly but still couldn't work it out (the callings were removed  
> from the
> below C code).
>

It's not a hang - it's a crash because of a bug in your code. Look at  
the last loop - I suspect you meant j<*n and not j<*m otherwise you'll  
be corrupting memory.

FWIW if you want to make a GUI responsive, you should be calling  
R_CheckUserInterrupt() and not R_ProcessEveents() because the latter  
is not available on all platforms.

Cheers,
Simon


> I am using R-2.8.1 on Windows XP service pack 3. The Rtools is  
> version 2.9.
> I have the following C code:
>
> void rx(int *n, int *m, int *rxmax,int *rxdate, int *refills,int  
> *rxs) {
>  int i,j,k, total;
>  int cap[*n][*m];
>  int rx[*n* *rxmax][*n];
>
>  for (i=0;i<*n;i++)
>    for (j=0;j<*m;j++)
>   cap[i][j]=0;
>
>  for (i=0;i<*n* *rxmax;i++) {
>  rx[i][0]=*(rxdate+i);
>     rx[i][1]=*(refills+i);
>     }
>
>  for (i=0;i<*n;i=i+1)
>   for (j=*rxmax *i;j<(i+1) * *rxmax-1;j++)
>        if (rx[j][0] > 0)
>          for (k = rx[j][0]; k < rx[j][0] + rx[j][1]; k++){
>          if (k<*m)
>            cap[i][k]=1; }
>
>  for (j=0;j<*m;j++)
>    for (i=0,total=0;i<*m;i++) {
>      total= total+cap[j][i];
>      rxs[j]=total;
>      }
> }
>
> And the following R code:
>
> dyn.load("c:/temp/rxc.dll")
> rx=matrix(c(1,5,11,5,21,5,0,0,
>            1,10,21,10,0,0,0,0),nrow=8, byrow=T);
> n=2
> m=31
> x=c(1:n)
> rxmax= dim(rx)[[1]]/n
> xx <- .C("rx",n=as.integer(n),m=as.integer(m),rxmax=as.integer(rxmax),
>      rxdate = as.integer(rx[,1]),
>      refills = as.integer(rx[,2]),rxs=as.integer(x))
> xx$rxs
>
>
> After I created the .dll file, I was able to load it into R and got  
> the
> result that I expected. But if I re-run the code for several times,  
> the R
> console will freeze.
>
> Thanks in advance.
>
> Xiangyang
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From xyxyye at gmail.com  Wed Apr 15 03:33:55 2009
From: xyxyye at gmail.com (Xiangyang Ye)
Date: Tue, 14 Apr 2009 19:33:55 -0600
Subject: [Rd] R console freezes after several runs of compiled C code
In-Reply-To: <9C9B2445-0192-4AD8-A6DC-CEB5F12027E5@r-project.org>
References: <eb622cbf0904141357r4d6c4f16y5b65ff4761ad17ec@mail.gmail.com>
	<9C9B2445-0192-4AD8-A6DC-CEB5F12027E5@r-project.org>
Message-ID: <eb622cbf0904141833h36eba941u857f0f9693888f26@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090414/9593d3a4/attachment.pl>

From jackiszhp at gmail.com  Wed Apr 15 04:50:48 2009
From: jackiszhp at gmail.com (Jack (Zhan, Hua Ping))
Date: Tue, 14 Apr 2009 22:50:48 -0400
Subject: [Rd] HTML help
Message-ID: <16fd0fca0904141950j559170b7kfd0d57bb9e9d09cf@mail.gmail.com>

Hi,guys,

HTML help is not right for math formula:
For example:
I got the following formula in help page of ca.jo in urca package:

<p align="center"><i><B>X</B>_t = <B>Pi</B>_1 <B>X</B>_{t-1} + ... + <B>Pi</B>_k
<B>X</B>_{t-k} + <B>&mu;</B> + <B>Phi D</B>_t + <B>varepsilon</B>_t
, quad (t = 1, ..., T),</i></p>
<p>

This presentation is just not good, however, in most browser,
with tag <math></math>, the formula in the tag works well.
such as in wikipedia. please check the same formula:
http://en.wikipedia.org/wiki/Johansen_test

Can someone please fix this?
help(ca.jo,offline=TRUE), we can get the formula right.

The problem seems to occur at the building process. Latex output is
right, but the HTML output is not good for math formula.

I guess this issue is not so difficult.

-- 
with best regards
Jack (Zhan, Hua Ping)
+1-514-8800518


From nashjc at uottawa.ca  Wed Apr 15 15:30:25 2009
From: nashjc at uottawa.ca (John C Nash)
Date: Wed, 15 Apr 2009 09:30:25 -0400
Subject: [Rd] Automatic Differentiation for R
In-Reply-To: <mailman.23.1239789606.8943.r-devel@r-project.org>
References: <mailman.23.1239789606.8943.r-devel@r-project.org>
Message-ID: <49E5E171.6030603@uottawa.ca>

In efforts to improve optimization tools for R, one of my
interests has been getting automatic differentiation capabilities
so that analytic rather than numerical derivatives can be used. They
would be helpful in several other areas besides optimization, My timings 
show
factors of the order of 1000s in time improvements by avoiding
numerical derivatives in some cases.

There has been some work in this e.g., 
http://code.google.com/p/pbs-software/
is an R interface to ADMB (Automatic Differentiation Model Builder). 
However,
as far as I can see, this is directed essentially to nonlinear least 
squares modelling,
an important but not general problem.

Tom Coleman of Waterloo responded favourably with some advice, but the most
enthusiastic answer came from Shaun Forth, which I have included below. 
I read
this as an opportunity to develop what could be a profitable 
collaboration with
the AD community. Unfortunately, I cannot take up the invitation to join 
the AD
folk in Oxford due to a pre-existing obligation. Nor am I more than a 
complete
novice with S3 and S4 classes etc. I am, nevertheless, willing to help 
organize
the effort e.g., do some of the communications, chasing grant money, getting
Google Summer of Code applications filled in etc.

Can the R community come up with a few people who can provide the AD
workers with appropriate information? If so, is there a reasonable chance to
generate sufficient funding for a student? I suspect the answer in both 
cases
is yes, but that we need some form of "booster cables" to get things going.
(In Canada, booster cables are used to get cars started in winter by 
connecting
a running vehicle's battery to that of a dead one.)

I suggest communications off-list until there is progress to report. 
Possibly
there is a better forum for this -- suggestions welcome.

John Nash

---- included msg from Shaun Forth ---

Hi John,
My computational statistics colleague Trevor Ringrose has asked me to
consider AD in R in the past. As you may or may not be aware AD is
implemented in one of two ways: overloading using OO features of the
target language, or source transformation using compiler tools (after
several man years of development) to read in the target code and spit
out the differentiated code. Last time I looked I didn't think the
object oriented features of R were up to overloading but on checking
today I can see that this might now be possible (I can see overloading
of arithmetic operators and functions for example now which I didn't see
last time).  

I'd certainly be interested in following this up particularly on the
overloading side but would need to get funding for a PhD student to do
the graft. It would be particularly interesting doing this in an open
source language because we could then perhaps tweak some of the core
language features if they didn't seamlessly support the AD (we can't do
this in Matlab and that is a pain!).

My immediate suggestion is that you, or some other more local (to UK) R
expert talks at the next European AD workshop in Oxford 
http://www.autodiff.org/?module=Workshops&submenu=EuroAD/8/main
We're a very friendly group and I'm sure there are others who might like
to tackle R or perhaps we could put together a multigroup project. If
someone could give a talk on R, its language features including the OO
aspects, and some optimisation examples with associated code, the group
there would be able to give you the best feedback on the planet on the
possibilities.

Please do treat this as a positive response and let's keep in touch on
this.

Regards

Shaun


####################################################################
Dr Shaun Forth
Applied Mathematics & Scientific Computation
Cranfield Defence and Security 
Cranfield University, Shrivenham Campus 
Swindon SN6 8LA, England
tel: +44 (0)1793 785311
fax: +44 (0)1793 784196
email: S.A.Forth at cranfield.ac.uk
http://www.amorg.co.uk
#####################################################################


From ggrothendieck at gmail.com  Wed Apr 15 15:53:18 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 15 Apr 2009 09:53:18 -0400
Subject: [Rd] Automatic Differentiation for R
In-Reply-To: <49E5E171.6030603@uottawa.ca>
References: <mailman.23.1239789606.8943.r-devel@r-project.org> 
	<49E5E171.6030603@uottawa.ca>
Message-ID: <971536df0904150653v3680b512x44d9c2987e69628b@mail.gmail.com>

Not sure if this is sufficient for your needs but R does include symbolic
differentiation, see ?D, and the Ryacas and rSymPy
packages interface R to the yacas and sympy computer algebra
systems (CAS) and those system include symbolic differentiation.

http://ryacas.googlecode.com
http://rsympy.googlecode.com

Note that Ryacas communicates with yacas via XML but recent
versions of the XML package changed in a way that breaks
Ryacas so you will likely have to use an old version of XML
and Ryacas if you want to try that one -- see home page.

The rsympy interface is early stage but its functional and is
easier to install since it includes the entire CAS right in
the R package.

On Wed, Apr 15, 2009 at 9:30 AM, John C Nash <nashjc at uottawa.ca> wrote:
> In efforts to improve optimization tools for R, one of my
> interests has been getting automatic differentiation capabilities
> so that analytic rather than numerical derivatives can be used. They
> would be helpful in several other areas besides optimization, My timings
> show
> factors of the order of 1000s in time improvements by avoiding
> numerical derivatives in some cases.
>
> There has been some work in this e.g.,
> http://code.google.com/p/pbs-software/
> is an R interface to ADMB (Automatic Differentiation Model Builder).
> However,
> as far as I can see, this is directed essentially to nonlinear least squares
> modelling,
> an important but not general problem.
>
> Tom Coleman of Waterloo responded favourably with some advice, but the most
> enthusiastic answer came from Shaun Forth, which I have included below. I
> read
> this as an opportunity to develop what could be a profitable collaboration
> with
> the AD community. Unfortunately, I cannot take up the invitation to join the
> AD
> folk in Oxford due to a pre-existing obligation. Nor am I more than a
> complete
> novice with S3 and S4 classes etc. I am, nevertheless, willing to help
> organize
> the effort e.g., do some of the communications, chasing grant money, getting
> Google Summer of Code applications filled in etc.
>
> Can the R community come up with a few people who can provide the AD
> workers with appropriate information? If so, is there a reasonable chance to
> generate sufficient funding for a student? I suspect the answer in both
> cases
> is yes, but that we need some form of "booster cables" to get things going.
> (In Canada, booster cables are used to get cars started in winter by
> connecting
> a running vehicle's battery to that of a dead one.)
>
> I suggest communications off-list until there is progress to report.
> Possibly
> there is a better forum for this -- suggestions welcome.
>
> John Nash
>
> ---- included msg from Shaun Forth ---
>
> Hi John,
> My computational statistics colleague Trevor Ringrose has asked me to
> consider AD in R in the past. As you may or may not be aware AD is
> implemented in one of two ways: overloading using OO features of the
> target language, or source transformation using compiler tools (after
> several man years of development) to read in the target code and spit
> out the differentiated code. Last time I looked I didn't think the
> object oriented features of R were up to overloading but on checking
> today I can see that this might now be possible (I can see overloading
> of arithmetic operators and functions for example now which I didn't see
> last time).
> I'd certainly be interested in following this up particularly on the
> overloading side but would need to get funding for a PhD student to do
> the graft. It would be particularly interesting doing this in an open
> source language because we could then perhaps tweak some of the core
> language features if they didn't seamlessly support the AD (we can't do
> this in Matlab and that is a pain!).
>
> My immediate suggestion is that you, or some other more local (to UK) R
> expert talks at the next European AD workshop in Oxford
> http://www.autodiff.org/?module=Workshops&submenu=EuroAD/8/main
> We're a very friendly group and I'm sure there are others who might like
> to tackle R or perhaps we could put together a multigroup project. If
> someone could give a talk on R, its language features including the OO
> aspects, and some optimisation examples with associated code, the group
> there would be able to give you the best feedback on the planet on the
> possibilities.
>
> Please do treat this as a positive response and let's keep in touch on
> this.
>
> Regards
>
> Shaun
>
>
> ####################################################################
> Dr Shaun Forth
> Applied Mathematics & Scientific Computation
> Cranfield Defence and Security Cranfield University, Shrivenham Campus
> Swindon SN6 8LA, England
> tel: +44 (0)1793 785311
> fax: +44 (0)1793 784196
> email: S.A.Forth at cranfield.ac.uk
> http://www.amorg.co.uk
> #####################################################################
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From simon.urbanek at r-project.org  Wed Apr 15 17:09:16 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 15 Apr 2009 11:09:16 -0400
Subject: [Rd] HTML help
In-Reply-To: <16fd0fca0904141950j559170b7kfd0d57bb9e9d09cf@mail.gmail.com>
References: <16fd0fca0904141950j559170b7kfd0d57bb9e9d09cf@mail.gmail.com>
Message-ID: <0DCEC0CA-FCEA-400A-A2FC-12BD6FC8D8C5@r-project.org>

JAck,

On Apr 14, 2009, at 22:50 , Jack (Zhan, Hua Ping) wrote:

> Hi,guys,
>
> HTML help is not right for math formula:
> For example:
> I got the following formula in help page of ca.jo in urca package:
>
> <p align="center"><i><B>X</B>_t = <B>Pi</B>_1 <B>X</B>_{t-1} + ... +  
> <B>Pi</B>_k
> <B>X</B>_{t-k} + <B>&mu;</B> + <B>Phi D</B>_t + <B>varepsilon</B>_t
> , quad (t = 1, ..., T),</i></p>
> <p>
>
> This presentation is just not good, however, in most browser, with  
> tag <math></math>, the formula in the tag works well.

I don't see what you mean - just putting <math> tags around the above  
doesn't change rendering at all. Moreover <math> is not a valid tag in  
the HTML standard.


> such as in wikipedia. please check the same formula: http://en.wikipedia.org/wiki/Johansen_test
>

Wikipedia uses bitmaps to represent those formulae, there are no HTML  
<math> tags involved there.


> Can someone please fix this?
> help(ca.jo,offline=TRUE), we can get the formula right.
>
> The problem seems to occur at the building process. Latex output is
> right, but the HTML output is not good for math formula.
>
> I guess this issue is not so difficult.
>

Well, then fix it and send us the patch please ...

Cheers,
Simon


From diggsb at ohsu.edu  Wed Apr 15 21:18:18 2009
From: diggsb at ohsu.edu (Brian Diggs)
Date: Wed, 15 Apr 2009 12:18:18 -0700
Subject: [Rd] Correction to documentation of print.ls_str in utils package
Message-ID: <D90C24824765F143934E4DE78009D617A14555@EX-BE05.ohsu.edu>

In the documentation for print.ls_str (on the ls.str page) in the utils package, the description for max.level is not correct.  It says "Default 0: Display all nesting levels."  The default, according to the Usage on that page and the source code, is 1. Also, a value of 0 does not display all the nesting levels; NA does that (based on the documentation of str). A value of 0 does not display any nested levels. I recommend changing that sentence to "If NA, display all nesting levels. Default 1: Display only the first nested level."

--
Brian Diggs, Ph.D.
Senior Research Associate, Department of Surgery, Oregon Health & Science University




From mnorton52 at yahoo.com  Wed Apr 15 19:52:14 2009
From: mnorton52 at yahoo.com (mnorton52)
Date: Wed, 15 Apr 2009 10:52:14 -0700 (PDT)
Subject: [Rd] HTML help
In-Reply-To: <16fd0fca0904141950j559170b7kfd0d57bb9e9d09cf@mail.gmail.com>
References: <16fd0fca0904141950j559170b7kfd0d57bb9e9d09cf@mail.gmail.com>
Message-ID: <23063793.post@talk.nabble.com>


Hi Jack,

I'm not sure about the <math> tag either, and it didn't work when I tried
it.  I think the approach this web page uses may help in writing
mathematical symbols to HTML:

http://comers.citadel.edu/math_sym2005.htm

Cheers,
Mike


Jack (Zhan, Hua Ping) wrote:
> 
> 
> HTML help is not right for math formula:
> For example:
> I got the following formula in help page of ca.jo in urca package:
> 
> <p align="center">X_t = Pi_1 X_{t-1} + ... + Pi_k
> X_{t-k} + &mu; + Phi D_t + varepsilon_t
> , quad (t = 1, ..., T),</p>
> <p>
> 
> This presentation is just not good, however, in most browser,
> with tag <math></math>, the formula in the tag works well.
> such as in wikipedia. please check the same formula:
> http://en.wikipedia.org/wiki/Johansen_test
> 
> -- 
> with best regards
> Jack (Zhan, Hua Ping)
> +1-514-8800518
> 
> 

-- 
View this message in context: http://www.nabble.com/HTML-help-tp23054298p23063793.html
Sent from the R devel mailing list archive at Nabble.com.


From romain.francois at dbmail.com  Wed Apr 15 22:14:03 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Wed, 15 Apr 2009 22:14:03 +0200
Subject: [Rd] HTML help
In-Reply-To: <23063793.post@talk.nabble.com>
References: <16fd0fca0904141950j559170b7kfd0d57bb9e9d09cf@mail.gmail.com>
	<23063793.post@talk.nabble.com>
Message-ID: <49E6400B.5020501@dbmail.com>

Hi,

if the system that builds the html help page is latex capable, then it 
would not be too difficult to use the same trick wikipedia is using 
(generating a png file for each equation). Translating latex style 
markup into mathml is another game, see this: 
http://www1.chapman.edu/~jipsen/mathml/asciimath.html for example.

Romain

mnorton52 wrote:
> Hi Jack,
>
> I'm not sure about the <math> tag either, and it didn't work when I tried
> it.  I think the approach this web page uses may help in writing
> mathematical symbols to HTML:
>
> http://comers.citadel.edu/math_sym2005.htm
>
> Cheers,
> Mike
>
>
> Jack (Zhan, Hua Ping) wrote:
>   
>> HTML help is not right for math formula:
>> For example:
>> I got the following formula in help page of ca.jo in urca package:
>>
>> <p align="center">X_t = Pi_1 X_{t-1} + ... + Pi_k
>> X_{t-k} + &mu; + Phi D_t + varepsilon_t
>> , quad (t = 1, ..., T),</p>
>> <p>
>>
>> This presentation is just not good, however, in most browser,
>> with tag <math></math>, the formula in the tag works well.
>> such as in wikipedia. please check the same formula:
>> http://en.wikipedia.org/wiki/Johansen_test
>>
>> -- 
>> with best regards
>> Jack (Zhan, Hua Ping)
>> +1-514-8800518
>>
>>     
-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From nashjc at uottawa.ca  Thu Apr 16 02:26:41 2009
From: nashjc at uottawa.ca (John C Nash)
Date: Wed, 15 Apr 2009 20:26:41 -0400
Subject: [Rd] (Not quite) Automatic Differentiation
Message-ID: <49E67B41.7070507@uottawa.ca>

Many thanks to Gabor Grothendieck for responding to my posting about 
Automatic Differentiation (invite from Shaun Forth for interaction with 
R developers) showing how one might use rSymPy and symbolic (rather than 
automatic) differentiation to get a function that computes gradients. 
See 
http://code.google.com/p/rsympy/#Automatic_Differentiation_(well,_sort_of)  
for a worked example on the Broyden test function.

This is a big step forward. There's still a way to go before we can 
produce a vectorized gradient code automatically when the size of the 
problem is variable, but the example may serve to incite some 
imaginative coders to action.

Thanks again Gabor.

JN


From koneill at bccrc.ca  Thu Apr 16 03:03:38 2009
From: koneill at bccrc.ca (Kieran O'Neill)
Date: Wed, 15 Apr 2009 18:03:38 -0700
Subject: [Rd] How can I catch errors thrown from c via the Rcpp error()
	function?
Message-ID: <49E683EA.5060001@bccrc.ca>

Hi

I am using the flowClust package from BioConductor, which is largely 
implemented in c. For some of my data, the package occasionally (and 
quite stochastically) encounters a particular condition which halts its 
operation. At this point, it calls the error() function defined by Rcpp, 
and halts.

What I would like to be able to do is to catch the error thrown, and 
retry the operation a few times before giving up.

However, when I wrap the call to flowClust in try() or tryCatch(), the 
error seems to completely bypass them:

Examples:

1. This is a trivial example just to test the try() function, and 
correctly assigns the error to the variable x:

 > x <- try(stop(simpleError('blah')))
Error : blah
 > x
[1] "Error : blah\n"
attr(,"class")
[1] "try-error"

2. This is an example using flowClust (using real data, set up to 
guarantee that the error is thrown):

 > x <- try(res30 = flowClust(tFrame, K=30, B=1000, varNames=c('CD4', 
'CD8','KI67', 'CD45RO', 'CD28', 'CD57', 'CCR5', 'CD19', 'CD27', 'CCR7', 
'CD127')))
Error in flowClust(tFrame, K = 30, B = 1000, varNames = c("CD4", "CD8",  :

The covariance matrix is near singular!
Try running the program with a different initial configuration or less 
clusters
 > x
Error: object "x" not found


The c code throwing the error is as follows (from flowClust.c):

if(status!=0)
   {
       error("\n The covariance matrix is near singular! \n Try running 
the program with a different initial configuration or less clusters 
\n");          }


I looked up the error() function in Writing R Extensions  and it states: 
"The basic error handling routines are the equivalents of stop and 
warning in R code, and use the same interface."

Yet, it seems that they are not caught by R's error handling code.

So:

1. Is this the general case (that Rcpp error()s are not handled by try() 
and related methods in R)? (I'm sure this could be tested with a trivial 
example, but I'm not yet familiar enough with wrapping c code in R to do 
so.)

2. If so, what is the correct way to handle them in R?

3. If not, do you have any suggestions as to what may have caused 
flowClust to behave in this way? (So that I can contact the package 
maintainers and report the bug.)


From edd at debian.org  Thu Apr 16 04:14:24 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 15 Apr 2009 21:14:24 -0500
Subject: [Rd] How can I catch errors thrown from c via the Rcpp
	error()	function?
In-Reply-To: <49E683EA.5060001@bccrc.ca>
References: <49E683EA.5060001@bccrc.ca>
Message-ID: <18918.38016.273317.952607@ron.nulle.part>


Kieran,

On 15 April 2009 at 18:03, Kieran O'Neill wrote:
| I am using the flowClust package from BioConductor, which is largely 
| implemented in c. For some of my data, the package occasionally (and 
| quite stochastically) encounters a particular condition which halts its 
| operation. At this point, it calls the error() function defined by Rcpp, 
| and halts.
| 
| What I would like to be able to do is to catch the error thrown, and 
| retry the operation a few times before giving up.
| 
| However, when I wrap the call to flowClust in try() or tryCatch(), the 
| error seems to completely bypass them:
| 
| Examples:
| 
| 1. This is a trivial example just to test the try() function, and 
| correctly assigns the error to the variable x:
| 
|  > x <- try(stop(simpleError('blah')))
| Error : blah
|  > x
| [1] "Error : blah\n"
| attr(,"class")
| [1] "try-error"
| 
| 2. This is an example using flowClust (using real data, set up to 
| guarantee that the error is thrown):
| 
|  > x <- try(res30 = flowClust(tFrame, K=30, B=1000, varNames=c('CD4', 
| 'CD8','KI67', 'CD45RO', 'CD28', 'CD57', 'CCR5', 'CD19', 'CD27', 'CCR7', 
| 'CD127')))
| Error in flowClust(tFrame, K = 30, B = 1000, varNames = c("CD4", "CD8",  :
| 
| The covariance matrix is near singular!
| Try running the program with a different initial configuration or less 
| clusters
|  > x
| Error: object "x" not found
| 
| 
| The c code throwing the error is as follows (from flowClust.c):
| 
| if(status!=0)
|    {
|        error("\n The covariance matrix is near singular! \n Try running 
| the program with a different initial configuration or less clusters 
| \n");          }
| 
| 
| I looked up the error() function in Writing R Extensions  and it states: 
| "The basic error handling routines are the equivalents of stop and 
| warning in R code, and use the same interface."
| 
| Yet, it seems that they are not caught by R's error handling code.
| 
| So:
| 
| 1. Is this the general case (that Rcpp error()s are not handled by try() 
| and related methods in R)? (I'm sure this could be tested with a trivial 
| example, but I'm not yet familiar enough with wrapping c code in R to do 
| so.)

Allow me to take the narrow view here as Rcpp maintainer.  What you can do
with Rcpp is to provide a C++ layer of try/catch around inner code which may
throw C++ exception.  This will usually be caught, and (as shown in the Rcpp
docs and examples) we can pass the exception message back up to R as a
regular error message.  This is very useful as it gives you control back at
the R prompt rather than just going belly-up.

Now, R's try() and tryCatch() are completely separate and not tied into the
exception mechanism Rcpp deals with, which is at a much lower level. 

Likewise, you may be out of luck with flowClust if it is C program.  You
could try to add a C++ layer that tried to catch error and allows you do
continue your loops.  I did something like that 15 years ago in my
dissertation research to ensure I survived the occassional numerical error
from Fortran during longer Monte Carlo runs,

| 2. If so, what is the correct way to handle them in R?

Tricky. See 1. :)

| 3. If not, do you have any suggestions as to what may have caused 
| flowClust to behave in this way? (So that I can contact the package 
| maintainers and report the bug.)

You could always contact them anyway and ask for advice.

Hth,  Dirk

-- 
Three out of two people have difficulties with fractions.


From charles.beaudette at usherbrooke.ca  Thu Apr 16 03:10:12 2009
From: charles.beaudette at usherbrooke.ca (charles.beaudette at usherbrooke.ca)
Date: Thu, 16 Apr 2009 03:10:12 +0200 (CEST)
Subject: [Rd] incorrect handling of NAs by na.action with lmList (package
	nlme) (PR#13658)
Message-ID: <20090416011012.C0C3B282C78A@mail.pubhealth.ku.dk>

Greetings,

I just found out a bug in the function lmList of the package nlme with R 
2.8.1 running under windows XP 32-bits. I have a data table with various 
columns corresponding to continuous variables as well as treatment 
variables taken on several years and several sites. Here is an example :

Id      year        treatment A      treatment B      variable1      
variable2      variable3
1       1             0                      0                      
6.47             3.76              NA
2       1             0                      1                      
3.23             2.15              NA
3       1             1                      0                      NA  
            8.43              NA
4       1             1                      1                      
2.15             9.34              NA
...      ...            ...                     ...                     
...                 ...                  ...
55     2             0                      0                      
5.93             5.35              6.34
56     2             0                      1                      
6.64             2.87              4.23
57     2             1                      0                      
4.23             NA               8.45
58     2             1                      1                      
3.67             8.54              7.45
...      ...            ...                     ...                     
...                 ...                  ...
105   3             0                      0                      7.45   
          8.34              7.65
106   3             0                      1                      7.98   
          9.45              9.23
107   3             1                      0                      4.56   
          8.23              8.34
108   3             1                      1                      6.34   
          9.34              5.98

As you can see, data for variable3 are missing for the first year, but 
otherwise there is little data missing. I call upon lmList :

lmgroup.data <- lmList (variable1 ~ treatmentB | year/treatmentA, data = 
data, na.action = na.omit)

When I call the object, I see :

Call:
  Model: variable1 ~ treatmentB | year/treatmentA
   Data: data

Coefficients:
                                  (Intercept)                treatment B
year2/treatmentA0        44.08387                81.11284
year2/treatmentA1        66.61333                155.62163
year3/treatmentA0        60.55125                72.83121 
year3/treatmentA1        63.62340                161.92080

Degrees of freedom: 188 total; 176 residual
Residual standard error: 24.09452

There is no data for year 1, but I didn't add variable 3 to my model, so 
the estimates should be there. When I create another data.frame and I 
omit to put in it variable 3, estimates for year 1 appear as they 
should. In my opinion, there is clearly a mishandling of the na.action 
argument here. It should omit the NAs in the vectors/columns of interest 
for the models, not the whole data.frame. I hope my explanations were 
clear and brief enough for you guys and thank you for a terrific job, R 
is a jewel of the open-source community and I enjoy working with it 
everyday !

Best Regards,

Charles Beaudette
Candidate for the master's degree in biology
University of Sherbrooke


From j.w.a.jansen at uu.nl  Thu Apr 16 10:50:11 2009
From: j.w.a.jansen at uu.nl (j.w.a.jansen at uu.nl)
Date: Thu, 16 Apr 2009 10:50:11 +0200 (CEST)
Subject: [Rd] Error in .readRDS(nsInfoFilePath) : unknown input format
	(PR#13659)
Message-ID: <20090416085011.CC477283219D@mail.pubhealth.ku.dk>

Full_Name: Jeroen Jansen
Version: 2.7.2
OS: Windows XP Pro
Submission from: (NULL) (131.211.169.89)


Allready with startup I get error message:
   R version 2.7.2 (2008-08-25)
   Copyright (C) 2008 The R Foundation for Statistical Computing
   ISBN 3-900051-07-0
   
   R is free software and comes with ABSOLUTELY NO WARRANTY.
   You are welcome to redistribute it under certain conditions.
   Type 'license()' or 'licence()' for distribution details.
   
   R is a collaborative project with many contributors.
   Type 'contributors()' for more information and
   'citation()' on how to cite R or R packages in publications.
   
   Type 'demo()' for some demos, 'help()' for on-line help, or
   'help.start()' for an HTML browser interface to help.
   Type 'q()' to quit R.
   
   Error in .readRDS(nsInfoFilePath) : unknown input format


Or with installing Packages:
   >update.packages(ask='graphics')
   Error in .readRDS(nsInfoFilePath) : unknown input format


From murdoch at stats.uwo.ca  Thu Apr 16 14:07:24 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 16 Apr 2009 08:07:24 -0400
Subject: [Rd] Error in .readRDS(nsInfoFilePath) : unknown input format
 (PR#13659)
In-Reply-To: <20090416085011.CC477283219D@mail.pubhealth.ku.dk>
References: <20090416085011.CC477283219D@mail.pubhealth.ku.dk>
Message-ID: <49E71F7C.7070800@stats.uwo.ca>

On 4/16/2009 4:50 AM, j.w.a.jansen at uu.nl wrote:
> Full_Name: Jeroen Jansen
> Version: 2.7.2
> OS: Windows XP Pro
> Submission from: (NULL) (131.211.169.89)
> 
> 
> Allready with startup I get error message:
>    R version 2.7.2 (2008-08-25)

That version is not current, but it looks to me as though you've 
corrupted a file on your system.  It would be named nsInfo.rds, and be 
in a Meta subdirectory of some package directory within RHOME/library.

The easiest thing to do is to install the latest version (which will be 
2.9.0 as of tomorrow).  That will fix whatever is wrong on your system. 
  It doesn't look like an R bug to me.

Duncan Murdoch

>    Copyright (C) 2008 The R Foundation for Statistical Computing
>    ISBN 3-900051-07-0
>    
>    R is free software and comes with ABSOLUTELY NO WARRANTY.
>    You are welcome to redistribute it under certain conditions.
>    Type 'license()' or 'licence()' for distribution details.
>    
>    R is a collaborative project with many contributors.
>    Type 'contributors()' for more information and
>    'citation()' on how to cite R or R packages in publications.
>    
>    Type 'demo()' for some demos, 'help()' for on-line help, or
>    'help.start()' for an HTML browser interface to help.
>    Type 'q()' to quit R.
>    
>    Error in .readRDS(nsInfoFilePath) : unknown input format
> 
> 
> Or with installing Packages:
>    >update.packages(ask='graphics')
>    Error in .readRDS(nsInfoFilePath) : unknown input format
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch at stats.uwo.ca  Thu Apr 16 14:10:14 2009
From: murdoch at stats.uwo.ca (murdoch at stats.uwo.ca)
Date: Thu, 16 Apr 2009 14:10:14 +0200 (CEST)
Subject: [Rd] Error in .readRDS(nsInfoFilePath) : unknown input format
	(PR#13660)
Message-ID: <20090416121014.B44982832192@mail.pubhealth.ku.dk>

On 4/16/2009 4:50 AM, j.w.a.jansen at uu.nl wrote:
> Full_Name: Jeroen Jansen
> Version: 2.7.2
> OS: Windows XP Pro
> Submission from: (NULL) (131.211.169.89)
> 
> 
> Allready with startup I get error message:
>    R version 2.7.2 (2008-08-25)

That version is not current, but it looks to me as though you've 
corrupted a file on your system.  It would be named nsInfo.rds, and be 
in a Meta subdirectory of some package directory within RHOME/library.

The easiest thing to do is to install the latest version (which will be 
2.9.0 as of tomorrow).  That will fix whatever is wrong on your system. 
  It doesn't look like an R bug to me.

Duncan Murdoch

>    Copyright (C) 2008 The R Foundation for Statistical Computing
>    ISBN 3-900051-07-0
>    
>    R is free software and comes with ABSOLUTELY NO WARRANTY.
>    You are welcome to redistribute it under certain conditions.
>    Type 'license()' or 'licence()' for distribution details.
>    
>    R is a collaborative project with many contributors.
>    Type 'contributors()' for more information and
>    'citation()' on how to cite R or R packages in publications.
>    
>    Type 'demo()' for some demos, 'help()' for on-line help, or
>    'help.start()' for an HTML browser interface to help.
>    Type 'q()' to quit R.
>    
>    Error in .readRDS(nsInfoFilePath) : unknown input format
> 
> 
> Or with installing Packages:
>    >update.packages(ask='graphics')
>    Error in .readRDS(nsInfoFilePath) : unknown input format
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ml-it-r-devel at epigenomics.com  Thu Apr 16 17:37:24 2009
From: ml-it-r-devel at epigenomics.com (ml-it-r-devel at epigenomics.com)
Date: Thu, 16 Apr 2009 17:37:24 +0200
Subject: [Rd] R (2.9.0 rc) CMD INSTALL will leave OOLOCK folder even if
 installation succeeded
Message-ID: <gs7jbl$7gq$1@perl.epigenomics.epi>


Hi,

since a couple of days ago I see failures when using
R CMD INSTALL -l lib  path-to-src/pkg.tar.gz

This occurs in automated library updating via a shell script and is caused by the
immediate preceding call to leave an 00LOCK folder
even though the package installation of that call succeeded.
This occurs at random (no obvious/systematic correlation to package name or or such) and
only for packages where an earlier version has been installed into the same library location.

e.g.

~/R/hardy$ R-2.9.0/bin/R CMD INSTALL -l R-2.9.x-libs R-2.9.x-libsSrc/CRAN/feature_1.2.3.tar.gz

...
** building package indices ...
* DONE (feature)

but
~/R/hardy$ ls -al R-2.9.x-libs/00LOCK/feature/
total 0
lrwxrwxrwx 1 XXX epiR 39 Mar 27 05:56 feature -> /mnt/local/R/hardy/R-2.9.x-libs/feature/

?INSTALL tells me of a workaround via --unsafe or --no-lock but I would prefer to use the
default incantation.
Any insights what the cause could be?

Regards, Matthias


R version 2.9.0 RC (2009-04-10 r48321)
on Ubuntu hardy

-- 
Matthias Burger                     Project Manager/ Biostatistician
Epigenomics AG    Kleine Praesidentenstr. 1    10178 Berlin, Germany
phone:+49-30-24345-0                            fax:+49-30-24345-555
http://www.epigenomics.com           matthias.burger at epigenomics.com
--
Epigenomics AG Berlin           Amtsgericht Charlottenburg HRB 75861
Vorstand:                           Geert Nygaard (CEO/Vorsitzender)
                                            Oliver Schacht PhD (CFO)
Aufsichtsrat:   Prof. Dr. Dr. hc. Rolf Krebs (Chairman/Vorsitzender)


From wdunlap at tibco.com  Thu Apr 16 17:49:22 2009
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 16 Apr 2009 08:49:22 -0700
Subject: [Rd] How can I catch errors thrown from c via the
	Rcpperror()	function?
In-Reply-To: <18918.38016.273317.952607@ron.nulle.part>
References: <49E683EA.5060001@bccrc.ca>
	<18918.38016.273317.952607@ron.nulle.part>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D70001075F7A@NA-PA-VBE03.na.tibco.com>

Note that Kieren's example labelled the first
argument to try() with an improper label res30=,
not expr= (or is that a mailer turning something
into '30='?).  If it really is an improper argument
tag then this could be showing a buglet in reporting
on wrongly named arguments:

  > invisible(rm(x,y))
  > x<-try(silent=TRUE, badTag=stop("Oops"))
  Error in try(silent = TRUE, badTag = stop("Oops")) : Oops
  > x
  Error: object "x" not found
  > y<-try(silent=TRUE, expr=stop("Oops"))
  > y
  [1] "Error in try(silent = TRUE, expr = stop(\"Oops\")) : Oops\n"
  attr(,"class")
  [1] "try-error"

In the first example I would expect an error message like
   unused argument(s) (badTag = stop("Oops"))
but it is appropriate that try() would abort if it
is called in a bad way.  Perhaps it is trying to make that
error message and that triggered the evaluation of the argument,
as in
   > grep(mypattern=stop("Oops"), "wxyz")
   Error in grep(mypattern = stop("Oops"), "wxyz") : Oops
where one might expect an error message regarding the wrongly
named argument, as in:
   > grep(mypattern="x", "wxyz")
   Error in grep(mypattern = "x", "wxyz") : 
     unused argument(s) (mypattern = "x")

Bill Dunlap
TIBCO Software Inc - Spotfire Division
wdunlap tibco.com 

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Dirk Eddelbuettel
> Sent: Wednesday, April 15, 2009 7:14 PM
> To: Kieran O'Neill
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] How can I catch errors thrown from c via 
> the Rcpperror() function?
> 
> 
> Kieran,
> 
> On 15 April 2009 at 18:03, Kieran O'Neill wrote:
> | I am using the flowClust package from BioConductor, which 
> is largely 
> | implemented in c. For some of my data, the package 
> occasionally (and 
> | quite stochastically) encounters a particular condition 
> which halts its 
> | operation. At this point, it calls the error() function 
> defined by Rcpp, 
> | and halts.
> | 
> | What I would like to be able to do is to catch the error 
> thrown, and 
> | retry the operation a few times before giving up.
> | 
> | However, when I wrap the call to flowClust in try() or 
> tryCatch(), the 
> | error seems to completely bypass them:
> | 
> | Examples:
> | 
> | 1. This is a trivial example just to test the try() function, and 
> | correctly assigns the error to the variable x:
> | 
> |  > x <- try(stop(simpleError('blah')))
> | Error : blah
> |  > x
> | [1] "Error : blah\n"
> | attr(,"class")
> | [1] "try-error"
> | 
> | 2. This is an example using flowClust (using real data, set up to 
> | guarantee that the error is thrown):
> | 
> |  > x <- try(res30 = flowClust(tFrame, K=30, B=1000, 
> varNames=c('CD4', 
> | 'CD8','KI67', 'CD45RO', 'CD28', 'CD57', 'CCR5', 'CD19', 
> 'CD27', 'CCR7', 
> | 'CD127')))
> | Error in flowClust(tFrame, K = 30, B = 1000, varNames = 
> c("CD4", "CD8",  :
> | 
> | The covariance matrix is near singular!
> | Try running the program with a different initial 
> configuration or less 
> | clusters
> |  > x
> | Error: object "x" not found
> | 
> | 
> | The c code throwing the error is as follows (from flowClust.c):
> | 
> | if(status!=0)
> |    {
> |        error("\n The covariance matrix is near singular! \n 
> Try running 
> | the program with a different initial configuration or less clusters 
> | \n");          }
> | 
> | 
> | I looked up the error() function in Writing R Extensions  
> and it states: 
> | "The basic error handling routines are the equivalents of stop and 
> | warning in R code, and use the same interface."
> | 
> | Yet, it seems that they are not caught by R's error handling code.
> | 
> | So:
> | 
> | 1. Is this the general case (that Rcpp error()s are not 
> handled by try() 
> | and related methods in R)? (I'm sure this could be tested 
> with a trivial 
> | example, but I'm not yet familiar enough with wrapping c 
> code in R to do 
> | so.)
> 
> Allow me to take the narrow view here as Rcpp maintainer.  
> What you can do
> with Rcpp is to provide a C++ layer of try/catch around inner 
> code which may
> throw C++ exception.  This will usually be caught, and (as 
> shown in the Rcpp
> docs and examples) we can pass the exception message back up to R as a
> regular error message.  This is very useful as it gives you 
> control back at
> the R prompt rather than just going belly-up.
> 
> Now, R's try() and tryCatch() are completely separate and not 
> tied into the
> exception mechanism Rcpp deals with, which is at a much lower level. 
> 
> Likewise, you may be out of luck with flowClust if it is C 
> program.  You
> could try to add a C++ layer that tried to catch error and 
> allows you do
> continue your loops.  I did something like that 15 years ago in my
> dissertation research to ensure I survived the occassional 
> numerical error
> from Fortran during longer Monte Carlo runs,
> 
> | 2. If so, what is the correct way to handle them in R?
> 
> Tricky. See 1. :)
> 
> | 3. If not, do you have any suggestions as to what may have caused 
> | flowClust to behave in this way? (So that I can contact the package 
> | maintainers and report the bug.)
> 
> You could always contact them anyway and ask for advice.
> 
> Hth,  Dirk
> 
> -- 
> Three out of two people have difficulties with fractions.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From P.Dalgaard at biostat.ku.dk  Thu Apr 16 18:25:43 2009
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 16 Apr 2009 18:25:43 +0200
Subject: [Rd] R (2.9.0 rc) CMD INSTALL will leave OOLOCK folder even if
 installation succeeded
In-Reply-To: <gs7jbl$7gq$1@perl.epigenomics.epi>
References: <gs7jbl$7gq$1@perl.epigenomics.epi>
Message-ID: <49E75C07.7000806@biostat.ku.dk>

ml-it-r-devel at epigenomics.com wrote:
> Hi,
> 
> since a couple of days ago I see failures when using
> R CMD INSTALL -l lib  path-to-src/pkg.tar.gz
> 
> This occurs in automated library updating via a shell script and is caused by the
> immediate preceding call to leave an 00LOCK folder
> even though the package installation of that call succeeded.
> This occurs at random (no obvious/systematic correlation to package name or or such) and
> only for packages where an earlier version has been installed into the same library location.
> 
> e.g.
> 
> ~/R/hardy$ R-2.9.0/bin/R CMD INSTALL -l R-2.9.x-libs R-2.9.x-libsSrc/CRAN/feature_1.2.3.tar.gz
> 
> ...
> ** building package indices ...
> * DONE (feature)
> 
> but
> ~/R/hardy$ ls -al R-2.9.x-libs/00LOCK/feature/
> total 0
> lrwxrwxrwx 1 XXX epiR 39 Mar 27 05:56 feature -> /mnt/local/R/hardy/R-2.9.x-libs/feature/
> 
> ?INSTALL tells me of a workaround via --unsafe or --no-lock but I would prefer to use the
> default incantation.
> Any insights what the cause could be?
> 
> Regards, Matthias
> 
> 
> R version 2.9.0 RC (2009-04-10 r48321)
> on Ubuntu hardy
> 

Not (easily) reproducible for me on r48325 (which only differs from
48321 in the FAQ and package count in internet.Rout.save). So, cannot
possibly fix for 2.9.0 tomorrow. Anything peculiar about your setup
(e.g., networked drive) that might keep the unlink from happening?

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From luke at stat.uiowa.edu  Thu Apr 16 18:27:17 2009
From: luke at stat.uiowa.edu (luke at stat.uiowa.edu)
Date: Thu, 16 Apr 2009 11:27:17 -0500 (CDT)
Subject: [Rd] How can I catch errors thrown from c via the	Rcpperror()
 function?
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D70001075F7A@NA-PA-VBE03.na.tibco.com>
References: <49E683EA.5060001@bccrc.ca>
	<18918.38016.273317.952607@ron.nulle.part>
	<77EB52C6DD32BA4D87471DCD70C8D70001075F7A@NA-PA-VBE03.na.tibco.com>
Message-ID: <alpine.LFD.2.00.0904161125280.18357@nokomis.stat.uiowa.edu>

Something seems amiss in the process of generating the errormessage:

> f <- function(x){}
> f(y = print("foo"))
[1] "foo"
Error in f(y = print("foo")) : unused argument(s) (y = "foo")

The argument seems to be getting evaluated and its value is being used.

luke

On Thu, 16 Apr 2009, William Dunlap wrote:

> Note that Kieren's example labelled the first
> argument to try() with an improper label res30=,
> not expr= (or is that a mailer turning something
> into '30='?).  If it really is an improper argument
> tag then this could be showing a buglet in reporting
> on wrongly named arguments:
>
>  > invisible(rm(x,y))
>  > x<-try(silent=TRUE, badTag=stop("Oops"))
>  Error in try(silent = TRUE, badTag = stop("Oops")) : Oops
>  > x
>  Error: object "x" not found
>  > y<-try(silent=TRUE, expr=stop("Oops"))
>  > y
>  [1] "Error in try(silent = TRUE, expr = stop(\"Oops\")) : Oops\n"
>  attr(,"class")
>  [1] "try-error"
>
> In the first example I would expect an error message like
>   unused argument(s) (badTag = stop("Oops"))
> but it is appropriate that try() would abort if it
> is called in a bad way.  Perhaps it is trying to make that
> error message and that triggered the evaluation of the argument,
> as in
>   > grep(mypattern=stop("Oops"), "wxyz")
>   Error in grep(mypattern = stop("Oops"), "wxyz") : Oops
> where one might expect an error message regarding the wrongly
> named argument, as in:
>   > grep(mypattern="x", "wxyz")
>   Error in grep(mypattern = "x", "wxyz") :
>     unused argument(s) (mypattern = "x")
>
> Bill Dunlap
> TIBCO Software Inc - Spotfire Division
> wdunlap tibco.com
>
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org
>> [mailto:r-devel-bounces at r-project.org] On Behalf Of Dirk Eddelbuettel
>> Sent: Wednesday, April 15, 2009 7:14 PM
>> To: Kieran O'Neill
>> Cc: r-devel at r-project.org
>> Subject: Re: [Rd] How can I catch errors thrown from c via
>> the Rcpperror() function?
>>
>>
>> Kieran,
>>
>> On 15 April 2009 at 18:03, Kieran O'Neill wrote:
>> | I am using the flowClust package from BioConductor, which
>> is largely
>> | implemented in c. For some of my data, the package
>> occasionally (and
>> | quite stochastically) encounters a particular condition
>> which halts its
>> | operation. At this point, it calls the error() function
>> defined by Rcpp,
>> | and halts.
>> |
>> | What I would like to be able to do is to catch the error
>> thrown, and
>> | retry the operation a few times before giving up.
>> |
>> | However, when I wrap the call to flowClust in try() or
>> tryCatch(), the
>> | error seems to completely bypass them:
>> |
>> | Examples:
>> |
>> | 1. This is a trivial example just to test the try() function, and
>> | correctly assigns the error to the variable x:
>> |
>> |  > x <- try(stop(simpleError('blah')))
>> | Error : blah
>> |  > x
>> | [1] "Error : blah\n"
>> | attr(,"class")
>> | [1] "try-error"
>> |
>> | 2. This is an example using flowClust (using real data, set up to
>> | guarantee that the error is thrown):
>> |
>> |  > x <- try(res30 = flowClust(tFrame, K=30, B=1000,
>> varNames=c('CD4',
>> | 'CD8','KI67', 'CD45RO', 'CD28', 'CD57', 'CCR5', 'CD19',
>> 'CD27', 'CCR7',
>> | 'CD127')))
>> | Error in flowClust(tFrame, K = 30, B = 1000, varNames =
>> c("CD4", "CD8",  :
>> |
>> | The covariance matrix is near singular!
>> | Try running the program with a different initial
>> configuration or less
>> | clusters
>> |  > x
>> | Error: object "x" not found
>> |
>> |
>> | The c code throwing the error is as follows (from flowClust.c):
>> |
>> | if(status!=0)
>> |    {
>> |        error("\n The covariance matrix is near singular! \n
>> Try running
>> | the program with a different initial configuration or less clusters
>> | \n");          }
>> |
>> |
>> | I looked up the error() function in Writing R Extensions
>> and it states:
>> | "The basic error handling routines are the equivalents of stop and
>> | warning in R code, and use the same interface."
>> |
>> | Yet, it seems that they are not caught by R's error handling code.
>> |
>> | So:
>> |
>> | 1. Is this the general case (that Rcpp error()s are not
>> handled by try()
>> | and related methods in R)? (I'm sure this could be tested
>> with a trivial
>> | example, but I'm not yet familiar enough with wrapping c
>> code in R to do
>> | so.)
>>
>> Allow me to take the narrow view here as Rcpp maintainer.
>> What you can do
>> with Rcpp is to provide a C++ layer of try/catch around inner
>> code which may
>> throw C++ exception.  This will usually be caught, and (as
>> shown in the Rcpp
>> docs and examples) we can pass the exception message back up to R as a
>> regular error message.  This is very useful as it gives you
>> control back at
>> the R prompt rather than just going belly-up.
>>
>> Now, R's try() and tryCatch() are completely separate and not
>> tied into the
>> exception mechanism Rcpp deals with, which is at a much lower level.
>>
>> Likewise, you may be out of luck with flowClust if it is C
>> program.  You
>> could try to add a C++ layer that tried to catch error and
>> allows you do
>> continue your loops.  I did something like that 15 years ago in my
>> dissertation research to ensure I survived the occassional
>> numerical error
>> from Fortran during longer Monte Carlo runs,
>>
>> | 2. If so, what is the correct way to handle them in R?
>>
>> Tricky. See 1. :)
>>
>> | 3. If not, do you have any suggestions as to what may have caused
>> | flowClust to behave in this way? (So that I can contact the package
>> | maintainers and report the bug.)
>>
>> You could always contact them anyway and ask for advice.
>>
>> Hth,  Dirk
>>
>> --
>> Three out of two people have difficulties with fractions.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From wdunlap at tibco.com  Thu Apr 16 19:04:38 2009
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 16 Apr 2009 10:04:38 -0700
Subject: [Rd] How can I catch errors thrown from c via the	Rcpperror()
	function?
In-Reply-To: <alpine.LFD.2.00.0904161125280.18357@nokomis.stat.uiowa.edu>
References: <49E683EA.5060001@bccrc.ca>
	<18918.38016.273317.952607@ron.nulle.part>
	<77EB52C6DD32BA4D87471DCD70C8D70001075F7A@NA-PA-VBE03.na.tibco.com>
	<alpine.LFD.2.00.0904161125280.18357@nokomis.stat.uiowa.edu>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D70001075FCA@NA-PA-VBE03.na.tibco.com>

> -----Original Message-----
> From: luke at stat.uiowa.edu [mailto:luke at stat.uiowa.edu] 
> Sent: Thursday, April 16, 2009 9:27 AM
> To: William Dunlap
> Cc: Dirk Eddelbuettel; Kieran O'Neill; r-devel at r-project.org
> Subject: Re: [Rd] How can I catch errors thrown from c via 
> the Rcpperror() function?
> 
> Something seems amiss in the process of generating the errormessage:
> 
> > f <- function(x){}
> > f(y = print("foo"))
> [1] "foo"
> Error in f(y = print("foo")) : unused argument(s) (y = "foo")
> 
> The argument seems to be getting evaluated and its value is 
> being used.
> 
> luke

It is in match.c, where errorcall() calls deparse1line(unused,0)
to get the name (and value) of the argument:

    357         if(last != R_NilValue) {
    358             errorcall(R_GlobalContext->call,
    359                       _("unused argument(s) %s"),
    360                       CHAR(STRING_ELT(deparse1line(unused, 0),
0)) + 4);

Before deparse1line is called unused is (in my example)
    (gdb) call Rf_PrintValue(unused)
    $badTag
    <promise: 0x9aff4d4>
and deparse1line must be evaluating the promise.  Just showing the
bad tag's name would suffice in the error message, if it is a problem
jury rigging deparse1line to avoid the evaluation in this case.

> 
> On Thu, 16 Apr 2009, William Dunlap wrote:
> 
> > Note that Kieren's example labelled the first
> > argument to try() with an improper label res30=,
> > not expr= (or is that a mailer turning something
> > into '30='?).  If it really is an improper argument
> > tag then this could be showing a buglet in reporting
> > on wrongly named arguments:
> >
> >  > invisible(rm(x,y))
> >  > x<-try(silent=TRUE, badTag=stop("Oops"))
> >  Error in try(silent = TRUE, badTag = stop("Oops")) : Oops
> >  > x
> >  Error: object "x" not found
> >  > y<-try(silent=TRUE, expr=stop("Oops"))
> >  > y
> >  [1] "Error in try(silent = TRUE, expr = stop(\"Oops\")) : Oops\n"
> >  attr(,"class")
> >  [1] "try-error"
> >
> > In the first example I would expect an error message like
> >   unused argument(s) (badTag = stop("Oops"))
> > but it is appropriate that try() would abort if it
> > is called in a bad way.  Perhaps it is trying to make that
> > error message and that triggered the evaluation of the argument,
> > as in
> >   > grep(mypattern=stop("Oops"), "wxyz")
> >   Error in grep(mypattern = stop("Oops"), "wxyz") : Oops
> > where one might expect an error message regarding the wrongly
> > named argument, as in:
> >   > grep(mypattern="x", "wxyz")
> >   Error in grep(mypattern = "x", "wxyz") :
> >     unused argument(s) (mypattern = "x")
> >
> > Bill Dunlap
> > TIBCO Software Inc - Spotfire Division
> > wdunlap tibco.com
> >
> >> -----Original Message-----
> >> From: r-devel-bounces at r-project.org
> >> [mailto:r-devel-bounces at r-project.org] On Behalf Of Dirk 
> Eddelbuettel
> >> Sent: Wednesday, April 15, 2009 7:14 PM
> >> To: Kieran O'Neill
> >> Cc: r-devel at r-project.org
> >> Subject: Re: [Rd] How can I catch errors thrown from c via
> >> the Rcpperror() function?
> >>
> >>
> >> Kieran,
> >>
> >> On 15 April 2009 at 18:03, Kieran O'Neill wrote:
> >> | I am using the flowClust package from BioConductor, which
> >> is largely
> >> | implemented in c. For some of my data, the package
> >> occasionally (and
> >> | quite stochastically) encounters a particular condition
> >> which halts its
> >> | operation. At this point, it calls the error() function
> >> defined by Rcpp,
> >> | and halts.
> >> |
> >> | What I would like to be able to do is to catch the error
> >> thrown, and
> >> | retry the operation a few times before giving up.
> >> |
> >> | However, when I wrap the call to flowClust in try() or
> >> tryCatch(), the
> >> | error seems to completely bypass them:
> >> |
> >> | Examples:
> >> |
> >> | 1. This is a trivial example just to test the try() function, and
> >> | correctly assigns the error to the variable x:
> >> |
> >> |  > x <- try(stop(simpleError('blah')))
> >> | Error : blah
> >> |  > x
> >> | [1] "Error : blah\n"
> >> | attr(,"class")
> >> | [1] "try-error"
> >> |
> >> | 2. This is an example using flowClust (using real data, set up to
> >> | guarantee that the error is thrown):
> >> |
> >> |  > x <- try(res30 = flowClust(tFrame, K=30, B=1000,
> >> varNames=c('CD4',
> >> | 'CD8','KI67', 'CD45RO', 'CD28', 'CD57', 'CCR5', 'CD19',
> >> 'CD27', 'CCR7',
> >> | 'CD127')))
> >> | Error in flowClust(tFrame, K = 30, B = 1000, varNames =
> >> c("CD4", "CD8",  :
> >> |
> >> | The covariance matrix is near singular!
> >> | Try running the program with a different initial
> >> configuration or less
> >> | clusters
> >> |  > x
> >> | Error: object "x" not found
> >> |
> >> |
> >> | The c code throwing the error is as follows (from flowClust.c):
> >> |
> >> | if(status!=0)
> >> |    {
> >> |        error("\n The covariance matrix is near singular! \n
> >> Try running
> >> | the program with a different initial configuration or 
> less clusters
> >> | \n");          }
> >> |
> >> |
> >> | I looked up the error() function in Writing R Extensions
> >> and it states:
> >> | "The basic error handling routines are the equivalents 
> of stop and
> >> | warning in R code, and use the same interface."
> >> |
> >> | Yet, it seems that they are not caught by R's error 
> handling code.
> >> |
> >> | So:
> >> |
> >> | 1. Is this the general case (that Rcpp error()s are not
> >> handled by try()
> >> | and related methods in R)? (I'm sure this could be tested
> >> with a trivial
> >> | example, but I'm not yet familiar enough with wrapping c
> >> code in R to do
> >> | so.)
> >>
> >> Allow me to take the narrow view here as Rcpp maintainer.
> >> What you can do
> >> with Rcpp is to provide a C++ layer of try/catch around inner
> >> code which may
> >> throw C++ exception.  This will usually be caught, and (as
> >> shown in the Rcpp
> >> docs and examples) we can pass the exception message back 
> up to R as a
> >> regular error message.  This is very useful as it gives you
> >> control back at
> >> the R prompt rather than just going belly-up.
> >>
> >> Now, R's try() and tryCatch() are completely separate and not
> >> tied into the
> >> exception mechanism Rcpp deals with, which is at a much 
> lower level.
> >>
> >> Likewise, you may be out of luck with flowClust if it is C
> >> program.  You
> >> could try to add a C++ layer that tried to catch error and
> >> allows you do
> >> continue your loops.  I did something like that 15 years ago in my
> >> dissertation research to ensure I survived the occassional
> >> numerical error
> >> from Fortran during longer Monte Carlo runs,
> >>
> >> | 2. If so, what is the correct way to handle them in R?
> >>
> >> Tricky. See 1. :)
> >>
> >> | 3. If not, do you have any suggestions as to what may have caused
> >> | flowClust to behave in this way? (So that I can contact 
> the package
> >> | maintainers and report the bug.)
> >>
> >> You could always contact them anyway and ask for advice.
> >>
> >> Hth,  Dirk
> >>
> >> --
> >> Three out of two people have difficulties with fractions.
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> -- 
> Luke Tierney
> Chair, Statistics and Actuarial Science
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>     Actuarial Science
> 241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
> 


From koneill at bccrc.ca  Thu Apr 16 20:50:59 2009
From: koneill at bccrc.ca (Kieran O'Neill)
Date: Thu, 16 Apr 2009 11:50:59 -0700
Subject: [Rd] How can I catch errors thrown from c via the Rcpperror()
 function?
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D70001075F7A@NA-PA-VBE03.na.tibco.com>
References: <49E683EA.5060001@bccrc.ca>
	<18918.38016.273317.952607@ron.nulle.part>
	<77EB52C6DD32BA4D87471DCD70C8D70001075F7A@NA-PA-VBE03.na.tibco.com>
Message-ID: <49E77E13.2060602@bccrc.ca>

Hi all, and thanks for the responses.

As per Bill's suggestion, I tried:

x <- try(flowClust(tFrame, K=30, B=1000, varNames=c('CD4', 'CD8','KI67', 
'CD45RO', 'CD28', 'CD57', 'CCR5', 'CD19','CD27', 'CCR7','CD127')), 
silent=TRUE)

and it caught the error.

Indeed,

 x <- try(res30 <- flowClust(tFrame, K=30, B=1000, varNames=c('CD4', 
'CD8','KI67', 'CD45RO', 'CD28', 'CD57', 'CCR5', 'CD19','CD27', 
'CCR7','CD127')), silent=TRUE)

caught the error. (What I really meant by "res30 = flowClust(...)" was 
"res30 <- flowClust(...)". I've fallen into the probably bad habit of 
using '=' in place of '<-' ) It had completely slipped my mind that '=' 
has a dual meaning, and that using it there might result in that part of 
my expression being evaluated as the passing of an argument.

Anyway, the point is that it works, and the error is caught when I use '<-'.

Thanks again for all your help (and an interesting peek into the nuts 
and bolts of R).

-Kieran

William Dunlap wrote:
> Note that Kieren's example labelled the first
> argument to try() with an improper label res30=,
> not expr= (or is that a mailer turning something
> into '30='?).  If it really is an improper argument
> tag then this could be showing a buglet in reporting
> on wrongly named arguments:
>
>   > invisible(rm(x,y))
>   > x<-try(silent=TRUE, badTag=stop("Oops"))
>   Error in try(silent = TRUE, badTag = stop("Oops")) : Oops
>   > x
>   Error: object "x" not found
>   > y<-try(silent=TRUE, expr=stop("Oops"))
>   > y
>   [1] "Error in try(silent = TRUE, expr = stop(\"Oops\")) : Oops\n"
>   attr(,"class")
>   [1] "try-error"
>
> In the first example I would expect an error message like
>    unused argument(s) (badTag = stop("Oops"))
> but it is appropriate that try() would abort if it
> is called in a bad way.  Perhaps it is trying to make that
> error message and that triggered the evaluation of the argument,
> as in
>    > grep(mypattern=stop("Oops"), "wxyz")
>    Error in grep(mypattern = stop("Oops"), "wxyz") : Oops
> where one might expect an error message regarding the wrongly
> named argument, as in:
>    > grep(mypattern="x", "wxyz")
>    Error in grep(mypattern = "x", "wxyz") : 
>      unused argument(s) (mypattern = "x")
>
> Bill Dunlap
> TIBCO Software Inc - Spotfire Division
> wdunlap tibco.com 
>
>   
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org 
>> [mailto:r-devel-bounces at r-project.org] On Behalf Of Dirk Eddelbuettel
>> Sent: Wednesday, April 15, 2009 7:14 PM
>> To: Kieran O'Neill
>> Cc: r-devel at r-project.org
>> Subject: Re: [Rd] How can I catch errors thrown from c via 
>> the Rcpperror() function?
>>
>>
>> Kieran,
>>
>> On 15 April 2009 at 18:03, Kieran O'Neill wrote:
>> | I am using the flowClust package from BioConductor, which 
>> is largely 
>> | implemented in c. For some of my data, the package 
>> occasionally (and 
>> | quite stochastically) encounters a particular condition 
>> which halts its 
>> | operation. At this point, it calls the error() function 
>> defined by Rcpp, 
>> | and halts.
>> | 
>> | What I would like to be able to do is to catch the error 
>> thrown, and 
>> | retry the operation a few times before giving up.
>> | 
>> | However, when I wrap the call to flowClust in try() or 
>> tryCatch(), the 
>> | error seems to completely bypass them:
>> | 
>> | Examples:
>> | 
>> | 1. This is a trivial example just to test the try() function, and 
>> | correctly assigns the error to the variable x:
>> | 
>> |  > x <- try(stop(simpleError('blah')))
>> | Error : blah
>> |  > x
>> | [1] "Error : blah\n"
>> | attr(,"class")
>> | [1] "try-error"
>> | 
>> | 2. This is an example using flowClust (using real data, set up to 
>> | guarantee that the error is thrown):
>> | 
>> |  > x <- try(res30 = flowClust(tFrame, K=30, B=1000, 
>> varNames=c('CD4', 
>> | 'CD8','KI67', 'CD45RO', 'CD28', 'CD57', 'CCR5', 'CD19', 
>> 'CD27', 'CCR7', 
>> | 'CD127')))
>> | Error in flowClust(tFrame, K = 30, B = 1000, varNames = 
>> c("CD4", "CD8",  :
>> | 
>> | The covariance matrix is near singular!
>> | Try running the program with a different initial 
>> configuration or less 
>> | clusters
>> |  > x
>> | Error: object "x" not found
>> | 
>> | 
>> | The c code throwing the error is as follows (from flowClust.c):
>> | 
>> | if(status!=0)
>> |    {
>> |        error("\n The covariance matrix is near singular! \n 
>> Try running 
>> | the program with a different initial configuration or less clusters 
>> | \n");          }
>> | 
>> | 
>> | I looked up the error() function in Writing R Extensions  
>> and it states: 
>> | "The basic error handling routines are the equivalents of stop and 
>> | warning in R code, and use the same interface."
>> | 
>> | Yet, it seems that they are not caught by R's error handling code.
>> | 
>> | So:
>> | 
>> | 1. Is this the general case (that Rcpp error()s are not 
>> handled by try() 
>> | and related methods in R)? (I'm sure this could be tested 
>> with a trivial 
>> | example, but I'm not yet familiar enough with wrapping c 
>> code in R to do 
>> | so.)
>>
>> Allow me to take the narrow view here as Rcpp maintainer.  
>> What you can do
>> with Rcpp is to provide a C++ layer of try/catch around inner 
>> code which may
>> throw C++ exception.  This will usually be caught, and (as 
>> shown in the Rcpp
>> docs and examples) we can pass the exception message back up to R as a
>> regular error message.  This is very useful as it gives you 
>> control back at
>> the R prompt rather than just going belly-up.
>>
>> Now, R's try() and tryCatch() are completely separate and not 
>> tied into the
>> exception mechanism Rcpp deals with, which is at a much lower level. 
>>
>> Likewise, you may be out of luck with flowClust if it is C 
>> program.  You
>> could try to add a C++ layer that tried to catch error and 
>> allows you do
>> continue your loops.  I did something like that 15 years ago in my
>> dissertation research to ensure I survived the occassional 
>> numerical error
>> from Fortran during longer Monte Carlo runs,
>>
>> | 2. If so, what is the correct way to handle them in R?
>>
>> Tricky. See 1. :)
>>
>> | 3. If not, do you have any suggestions as to what may have caused 
>> | flowClust to behave in this way? (So that I can contact the package 
>> | maintainers and report the bug.)
>>
>> You could always contact them anyway and ask for advice.
>>
>> Hth,  Dirk
>>
>> -- 
>> Three out of two people have difficulties with fractions.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>


From wdunlap at tibco.com  Thu Apr 16 21:57:10 2009
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 16 Apr 2009 12:57:10 -0700
Subject: [Rd] How can I catch errors thrown from c via
	the	Rcpperror()function?
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D70001075FCA@NA-PA-VBE03.na.tibco.com>
References: <49E683EA.5060001@bccrc.ca><18918.38016.273317.952607@ron.nulle.part><77EB52C6DD32BA4D87471DCD70C8D70001075F7A@NA-PA-VBE03.na.tibco.com><alpine.LFD.2.00.0904161125280.18357@nokomis.stat.uiowa.edu>
	<77EB52C6DD32BA4D87471DCD70C8D70001075FCA@NA-PA-VBE03.na.tibco.com>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D7000107605C@NA-PA-VBE03.na.tibco.com>

A possible fix for this is to filter the 'unsused' list before
printing the error message and replacing the promises with
their PRCODE expressions.

Index: match.c
===================================================================
--- match.c	(revision 48329)
+++ match.c	(working copy)
@@ -355,9 +355,28 @@
 	    }
 
 	if(last != R_NilValue) {
+            /* show bad arguments in call without evaluating them */
+            SEXP unusedForError = R_NilValue, last = R_NilValue ;
+            for(b=unused ; b!=R_NilValue ; b=CDR(b)) {
+                SEXP tagB = TAG(b) ;
+                SEXP carB = CAR(b) ;
+                if (TYPEOF(carB)==PROMSXP) {
+                    carB = PRCODE(carB) ;
+                }
+                if (last==R_NilValue) {
+                    PROTECT(last = CONS(carB, R_NilValue));
+                    SET_TAG(last, tagB);
+                    unusedForError = last ;
+                } else {
+                    SETCDR(last, CONS(carB, R_NilValue));
+                    last = CDR(last) ;
+                    SET_TAG(last, tagB);
+                }
+            }
 	    errorcall(R_GlobalContext->call,
 		      _("unused argument(s) %s"),
-		      CHAR(STRING_ELT(deparse1line(unused, 0), 0)) + 4);
+		      CHAR(STRING_ELT(deparse1line(unusedForError, 0),
0)) + 4);
+                      /* '+4' is to remove 'list' from
'list(badTag1,...)' */
 	}
     }
     UNPROTECT(1);

E.g.,
> f<-function(x,y)x+y
> f(print(1),y=print(2),x=print(3),stop("oops"))
Error in f(print(1), y = print(2), x = print(3), stop("oops")) :
  unused argument(s) (print(1), stop("oops"))
> f(print(1),y=print(2),x=print(3),z=stop("oops"))
Error in f(print(1), y = print(2), x = print(3), z = stop("oops")) :
  unused argument(s) (print(1), z = stop("oops"))
> f(print(1),y=print(2),z=print(3),x=stop("oops"))
Error in f(print(1), y = print(2), z = print(3), x = stop("oops")) :
  unused argument(s) (print(1), z = print(3))

These calls used to give:

> f(print(1),y=print(2),x=print(3),stop("oops"))
[1] 1
Error in f(print(1), y = print(2), x = print(3), stop("oops")) : oops
> f(print(1),y=print(2),x=print(3),z=stop("oops"))
[1] 1
Error in f(print(1), y = print(2), x = print(3), z = stop("oops")) :
oops
> f(print(1),y=print(2),z=print(3),x=stop("oops"))
[1] 1
[1] 3
Error in f(print(1), y = print(2), z = print(3), x = stop("oops")) :
  unused argument(s) (1, z = 3)

Bill Dunlap
TIBCO Software Inc - Spotfire Division
wdunlap tibco.com  

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of William Dunlap
> Sent: Thursday, April 16, 2009 10:05 AM
> To: luke at stat.uiowa.edu
> Cc: r-devel at r-project.org; Dirk Eddelbuettel
> Subject: Re: [Rd] How can I catch errors thrown from c via 
> the Rcpperror()function?
> 
> > -----Original Message-----
> > From: luke at stat.uiowa.edu [mailto:luke at stat.uiowa.edu] 
> > Sent: Thursday, April 16, 2009 9:27 AM
> > To: William Dunlap
> > Cc: Dirk Eddelbuettel; Kieran O'Neill; r-devel at r-project.org
> > Subject: Re: [Rd] How can I catch errors thrown from c via 
> > the Rcpperror() function?
> > 
> > Something seems amiss in the process of generating the errormessage:
> > 
> > > f <- function(x){}
> > > f(y = print("foo"))
> > [1] "foo"
> > Error in f(y = print("foo")) : unused argument(s) (y = "foo")
> > 
> > The argument seems to be getting evaluated and its value is 
> > being used.
> > 
> > luke
> 
> It is in match.c, where errorcall() calls deparse1line(unused,0)
> to get the name (and value) of the argument:
> 
>     357         if(last != R_NilValue) {
>     358             errorcall(R_GlobalContext->call,
>     359                       _("unused argument(s) %s"),
>     360                       CHAR(STRING_ELT(deparse1line(unused, 0),
> 0)) + 4);
> 
> Before deparse1line is called unused is (in my example)
>     (gdb) call Rf_PrintValue(unused)
>     $badTag
>     <promise: 0x9aff4d4>
> and deparse1line must be evaluating the promise.  Just showing the
> bad tag's name would suffice in the error message, if it is a problem
> jury rigging deparse1line to avoid the evaluation in this case.
> 
> > 
> > On Thu, 16 Apr 2009, William Dunlap wrote:
> > 
> > > Note that Kieren's example labelled the first
> > > argument to try() with an improper label res30=,
> > > not expr= (or is that a mailer turning something
> > > into '30='?).  If it really is an improper argument
> > > tag then this could be showing a buglet in reporting
> > > on wrongly named arguments:
> > >
> > >  > invisible(rm(x,y))
> > >  > x<-try(silent=TRUE, badTag=stop("Oops"))
> > >  Error in try(silent = TRUE, badTag = stop("Oops")) : Oops
> > >  > x
> > >  Error: object "x" not found
> > >  > y<-try(silent=TRUE, expr=stop("Oops"))
> > >  > y
> > >  [1] "Error in try(silent = TRUE, expr = stop(\"Oops\")) : Oops\n"
> > >  attr(,"class")
> > >  [1] "try-error"
> > >
> > > In the first example I would expect an error message like
> > >   unused argument(s) (badTag = stop("Oops"))
> > > but it is appropriate that try() would abort if it
> > > is called in a bad way.  Perhaps it is trying to make that
> > > error message and that triggered the evaluation of the argument,
> > > as in
> > >   > grep(mypattern=stop("Oops"), "wxyz")
> > >   Error in grep(mypattern = stop("Oops"), "wxyz") : Oops
> > > where one might expect an error message regarding the wrongly
> > > named argument, as in:
> > >   > grep(mypattern="x", "wxyz")
> > >   Error in grep(mypattern = "x", "wxyz") :
> > >     unused argument(s) (mypattern = "x")
> > >
> > > Bill Dunlap
> > > TIBCO Software Inc - Spotfire Division
> > > wdunlap tibco.com
> > >
> > >> -----Original Message-----
> > >> From: r-devel-bounces at r-project.org
> > >> [mailto:r-devel-bounces at r-project.org] On Behalf Of Dirk 
> > Eddelbuettel
> > >> Sent: Wednesday, April 15, 2009 7:14 PM
> > >> To: Kieran O'Neill
> > >> Cc: r-devel at r-project.org
> > >> Subject: Re: [Rd] How can I catch errors thrown from c via
> > >> the Rcpperror() function?
> > >>
> > >>
> > >> Kieran,
> > >>
> > >> On 15 April 2009 at 18:03, Kieran O'Neill wrote:
> > >> | I am using the flowClust package from BioConductor, which
> > >> is largely
> > >> | implemented in c. For some of my data, the package
> > >> occasionally (and
> > >> | quite stochastically) encounters a particular condition
> > >> which halts its
> > >> | operation. At this point, it calls the error() function
> > >> defined by Rcpp,
> > >> | and halts.
> > >> |
> > >> | What I would like to be able to do is to catch the error
> > >> thrown, and
> > >> | retry the operation a few times before giving up.
> > >> |
> > >> | However, when I wrap the call to flowClust in try() or
> > >> tryCatch(), the
> > >> | error seems to completely bypass them:
> > >> |
> > >> | Examples:
> > >> |
> > >> | 1. This is a trivial example just to test the try() 
> function, and
> > >> | correctly assigns the error to the variable x:
> > >> |
> > >> |  > x <- try(stop(simpleError('blah')))
> > >> | Error : blah
> > >> |  > x
> > >> | [1] "Error : blah\n"
> > >> | attr(,"class")
> > >> | [1] "try-error"
> > >> |
> > >> | 2. This is an example using flowClust (using real 
> data, set up to
> > >> | guarantee that the error is thrown):
> > >> |
> > >> |  > x <- try(res30 = flowClust(tFrame, K=30, B=1000,
> > >> varNames=c('CD4',
> > >> | 'CD8','KI67', 'CD45RO', 'CD28', 'CD57', 'CCR5', 'CD19',
> > >> 'CD27', 'CCR7',
> > >> | 'CD127')))
> > >> | Error in flowClust(tFrame, K = 30, B = 1000, varNames =
> > >> c("CD4", "CD8",  :
> > >> |
> > >> | The covariance matrix is near singular!
> > >> | Try running the program with a different initial
> > >> configuration or less
> > >> | clusters
> > >> |  > x
> > >> | Error: object "x" not found
> > >> |
> > >> |
> > >> | The c code throwing the error is as follows (from flowClust.c):
> > >> |
> > >> | if(status!=0)
> > >> |    {
> > >> |        error("\n The covariance matrix is near singular! \n
> > >> Try running
> > >> | the program with a different initial configuration or 
> > less clusters
> > >> | \n");          }
> > >> |
> > >> |
> > >> | I looked up the error() function in Writing R Extensions
> > >> and it states:
> > >> | "The basic error handling routines are the equivalents 
> > of stop and
> > >> | warning in R code, and use the same interface."
> > >> |
> > >> | Yet, it seems that they are not caught by R's error 
> > handling code.
> > >> |
> > >> | So:
> > >> |
> > >> | 1. Is this the general case (that Rcpp error()s are not
> > >> handled by try()
> > >> | and related methods in R)? (I'm sure this could be tested
> > >> with a trivial
> > >> | example, but I'm not yet familiar enough with wrapping c
> > >> code in R to do
> > >> | so.)
> > >>
> > >> Allow me to take the narrow view here as Rcpp maintainer.
> > >> What you can do
> > >> with Rcpp is to provide a C++ layer of try/catch around inner
> > >> code which may
> > >> throw C++ exception.  This will usually be caught, and (as
> > >> shown in the Rcpp
> > >> docs and examples) we can pass the exception message back 
> > up to R as a
> > >> regular error message.  This is very useful as it gives you
> > >> control back at
> > >> the R prompt rather than just going belly-up.
> > >>
> > >> Now, R's try() and tryCatch() are completely separate and not
> > >> tied into the
> > >> exception mechanism Rcpp deals with, which is at a much 
> > lower level.
> > >>
> > >> Likewise, you may be out of luck with flowClust if it is C
> > >> program.  You
> > >> could try to add a C++ layer that tried to catch error and
> > >> allows you do
> > >> continue your loops.  I did something like that 15 years 
> ago in my
> > >> dissertation research to ensure I survived the occassional
> > >> numerical error
> > >> from Fortran during longer Monte Carlo runs,
> > >>
> > >> | 2. If so, what is the correct way to handle them in R?
> > >>
> > >> Tricky. See 1. :)
> > >>
> > >> | 3. If not, do you have any suggestions as to what may 
> have caused
> > >> | flowClust to behave in this way? (So that I can contact 
> > the package
> > >> | maintainers and report the bug.)
> > >>
> > >> You could always contact them anyway and ask for advice.
> > >>
> > >> Hth,  Dirk
> > >>
> > >> --
> > >> Three out of two people have difficulties with fractions.
> > >>
> > >> ______________________________________________
> > >> R-devel at r-project.org mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-devel
> > >>
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > >
> > 
> > -- 
> > Luke Tierney
> > Chair, Statistics and Actuarial Science
> > Ralph E. Wareham Professor of Mathematical Sciences
> > University of Iowa                  Phone:             319-335-3386
> > Department of Statistics and        Fax:               319-335-3017
> >     Actuarial Science
> > 241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
> > Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
> > 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: match.c.diff.txt
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090416/3ee32a5f/attachment.txt>

From macrakis at alum.mit.edu  Fri Apr 17 01:20:19 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Thu, 16 Apr 2009 19:20:19 -0400
Subject: [Rd] Using trace
In-Reply-To: <8b356f880904122219q7c966b40h19fd83793de3dd0d@mail.gmail.com>
References: <8b356f880904122219q7c966b40h19fd83793de3dd0d@mail.gmail.com>
Message-ID: <8b356f880904161620qddbc78eq5cc9be3980ed6086@mail.gmail.com>

I posted the query below on r-help, but perhaps r-devel is more
suitable... (I guess "r-devel" should be read as "those who develop
(i.e. write) programs in R" rather than "those who develop R"?)

             -s

I would like to trace functions, displaying their arguments and return
value, but I haven't been able to figure out how to do this with the
'trace' function.

After some thrashing, I got as far as this:

? ?fact <- function(x) if(x<1) 1 else x*fact(x-1)
? ?tracefnc <- function() dput(as.list(parent.frame()), ?#
parent.frame() holds arg list
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?control=NULL)
? ?trace("fact",tracer=tracefnc,print=FALSE)

but I couldn't figure out how to access the return value of the
function in the 'exit' parameter. ?The above also doesn't work for
"..." arguments. ?(More subtly, it forces the evaluation of promises
even if they are otherwise unused -- but that is, I suppose, a weird
and obscure case.)

Surely someone has solved this already?

What I'm looking for is something very simple, along the lines of
old-fashioned Lisp trace:

> defun fact (i) (if (< i 1) 1 (* i (fact (+ i -1)))))
FACT
> (trace fact)
(FACT)
> (fact 3)
?1> (FACT 3)
? ?2> (FACT 2)
? ? ?3> (FACT 1)
? ? ? ?4> (FACT 0)
? ? ? ?<4 (FACT 1)
? ? ?<3 (FACT 1)
? ?<2 (FACT 2)
?<1 (FACT 6)
6

Can someone help? Thanks,

? ? ? ? -s


From phgrosjean at sciviews.org  Fri Apr 17 09:19:56 2009
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Fri, 17 Apr 2009 09:19:56 +0200
Subject: [Rd] suggestion for R >= 3.0: computer-readable CHANGELOG
Message-ID: <49E82D9C.9090402@sciviews.org>

Hello,

Here are a few questions that would be useful to get an answer via 
dedicated functions in utils or tools packages:
- When did function foo appeared in R or in a given package?
- When did argument myarg appeared in function foo?
- When did function bar get deprecated or when did it disappeared?
- I wrote a script using functions foo and bar with R 1.9.1. My script 
does not work any more with current version. What were all the changes 
made to foo and/or to bar since then (this could obviously help me to 
update my script for current R version)?

Currently, we have to read NEWS (or perhaps a non official changelog) 
manually to get such answers.

The basic function to retrieve data that would answer to these questions 
would be something like:

 > changes(c("foo", "bar"))

That function could, for instance, read information in a 
computer-readable file named CHANGELOG... because the problem is there! 
Changes are currently recorded in NEWS, but ONLY in a human-readable 
form! A quick suggestion for a format for CHANGELOG by example:

Date       Object   Action  Value   Message
2009-04-17 package  commit  1.1-0   Enhanced version of my package
2009-04-15 foo      add     foo(y)  New function foo in my package
2009-04-14 bar      debug           bar(NULL) returned wrong result
2009-04-01 package  commit  1.0-0   First version of package on CRAN

It should be kept simple. May be an "Author" field in the records would 
be nice too. Also a function to record a new entry in the CHANGELOG 
could look like:

 > track("XXX", action = "debug", message = "my comment", file = 
"/somewhere/CHANGELOG")

The file NEWS would not change and should be kept to present the same 
information in a human-readable format.

Also, a function that lists all functions used in a script or a package 
(Romain Fran?ois is working in this direction with svTools package), 
plus a function to plot one or several "changes" objects as returned by 
changes() on a time axis or "version axis" would be welcome additions to 
further track and plot evolution of R, or of R packages for a group of 
functions of interest. Finally, a function to easily record the 
dependences used and their versions in a script would complete the set 
of tools.

These 4-5 functions are not difficult to write (although I suspect that 
this simplistic proposal would become more complex if one consider to 
interact with subversion, to separate development and release versions, 
...). But to be really useful, they should be better designed and 
proposed by the R core team, and included in the official specifications 
for writing package. May I suggest to think about such a change for R 
version 3.0?

Things get more complicated for verifying CHANGELOG in R CMD check. At 
least, one could check actions like:
- object or function addition, deprecation or disappearance,
- argument changes in functions, slot changes in objects,
- function refactoring (change in the code from previous version)
but only if we provide also the previous version of a package to R CMD 
check.

I would be happy to contribute, but the concept must certainly be 
further discussed and enhanced (here?), and then, accepted by the R core 
team before going any further.

All the best,

Philippe Grosjean
-- 
..............................................<?}))><........
  ) ) ) ) )
( ( ( ( (    Prof. Philippe Grosjean
  ) ) ) ) )
( ( ( ( (    Numerical Ecology of Aquatic Systems
  ) ) ) ) )   Mons-Hainaut University, Belgium
( ( ( ( (
..............................................................


From murdoch at stats.uwo.ca  Fri Apr 17 12:38:05 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 17 Apr 2009 06:38:05 -0400
Subject: [Rd] suggestion for R >= 3.0: computer-readable CHANGELOG
In-Reply-To: <49E82D9C.9090402@sciviews.org>
References: <49E82D9C.9090402@sciviews.org>
Message-ID: <49E85C0D.6040809@stats.uwo.ca>

Philippe Grosjean wrote:
> Hello,
>
> Here are a few questions that would be useful to get an answer via 
> dedicated functions in utils or tools packages:
> - When did function foo appeared in R or in a given package?
> - When did argument myarg appeared in function foo?
> - When did function bar get deprecated or when did it disappeared?
> - I wrote a script using functions foo and bar with R 1.9.1. My script 
> does not work any more with current version. What were all the changes 
> made to foo and/or to bar since then (this could obviously help me to 
> update my script for current R version)?
>
> Currently, we have to read NEWS (or perhaps a non official changelog) 
> manually to get such answers.
>
> The basic function to retrieve data that would answer to these questions 
> would be something like:
>
>  > changes(c("foo", "bar"))
>
> That function could, for instance, read information in a 
> computer-readable file named CHANGELOG... because the problem is there! 
> Changes are currently recorded in NEWS, but ONLY in a human-readable 
> form! A quick suggestion for a format for CHANGELOG by example:
>   

There is the tools::readNEWS function to read the NEWS file.  It's not 
just human readable.  That's what the RSS feed uses.
> Date       Object   Action  Value   Message
> 2009-04-17 package  commit  1.1-0   Enhanced version of my package
> 2009-04-15 foo      add     foo(y)  New function foo in my package
> 2009-04-14 bar      debug           bar(NULL) returned wrong result
> 2009-04-01 package  commit  1.0-0   First version of package on CRAN
>   

It doesn't contain dates, and dates don't really make sense.  (Many 
additions are introduced over a sequence of changes.  Do you give the 
first date, the last date?  What if the change is very minor, e.g. a 
typo in the docs?)   NEWS does contain R version numbers, and those are 
well defined.

The RSS feed does list the date on which it noticed each change to the 
NEWS file, but I think that is more useful for keeping up to date with 
changes, rather than defining when something happened.
> It should be kept simple. May be an "Author" field in the records would 
> be nice too. Also a function to record a new entry in the CHANGELOG 
> could look like:
>   

Maybe you want the Subversion log.  It is machine readable; just use 
Subversion to read it.  (Something nice would be R-level access to the 
Subversion API.) You can be very specific about which files you want to 
read about, or just read the whole thing on developer.r-project.org.

Duncan Murdoch
>  > track("XXX", action = "debug", message = "my comment", file = 
> "/somewhere/CHANGELOG")
>
> The file NEWS would not change and should be kept to present the same 
> information in a human-readable format.
>
> Also, a function that lists all functions used in a script or a package 
> (Romain Fran?ois is working in this direction with svTools package), 
> plus a function to plot one or several "changes" objects as returned by 
> changes() on a time axis or "version axis" would be welcome additions to 
> further track and plot evolution of R, or of R packages for a group of 
> functions of interest. Finally, a function to easily record the 
> dependences used and their versions in a script would complete the set 
> of tools.
>
> These 4-5 functions are not difficult to write (although I suspect that 
> this simplistic proposal would become more complex if one consider to 
> interact with subversion, to separate development and release versions, 
> ...). But to be really useful, they should be better designed and 
> proposed by the R core team, and included in the official specifications 
> for writing package. May I suggest to think about such a change for R 
> version 3.0?
>
> Things get more complicated for verifying CHANGELOG in R CMD check. At 
> least, one could check actions like:
> - object or function addition, deprecation or disappearance,
> - argument changes in functions, slot changes in objects,
> - function refactoring (change in the code from previous version)
> but only if we provide also the previous version of a package to R CMD 
> check.
>
> I would be happy to contribute, but the concept must certainly be 
> further discussed and enhanced (here?), and then, accepted by the R core 
> team before going any further.
>
> All the best,
>
> Philippe Grosjean
>


From ronggui.huang at gmail.com  Fri Apr 17 13:48:47 2009
From: ronggui.huang at gmail.com (ronggui)
Date: Fri, 17 Apr 2009 19:48:47 +0800
Subject: [Rd] suggestion for R >= 3.0: computer-readable CHANGELOG
In-Reply-To: <49E85C0D.6040809@stats.uwo.ca>
References: <49E82D9C.9090402@sciviews.org> <49E85C0D.6040809@stats.uwo.ca>
Message-ID: <38b9f0350904170448nd338a84vcd2dc8f7327669a6@mail.gmail.com>

2009/4/17 Duncan Murdoch <murdoch at stats.uwo.ca>:
> Philippe Grosjean wrote:
>>
>> Hello,
>>
>> Here are a few questions that would be useful to get an answer via
>> dedicated functions in utils or tools packages:
>> - When did function foo appeared in R or in a given package?
>> - When did argument myarg appeared in function foo?
>> - When did function bar get deprecated or when did it disappeared?
>> - I wrote a script using functions foo and bar with R 1.9.1. My script
>> does not work any more with current version. What were all the changes made
>> to foo and/or to bar since then (this could obviously help me to update my
>> script for current R version)?
>>
>> Currently, we have to read NEWS (or perhaps a non official changelog)
>> manually to get such answers.
>>
>> The basic function to retrieve data that would answer to these questions
>> would be something like:
>>
>> ?> changes(c("foo", "bar"))
>>
>> That function could, for instance, read information in a computer-readable
>> file named CHANGELOG... because the problem is there! Changes are currently
>> recorded in NEWS, but ONLY in a human-readable form! A quick suggestion for
>> a format for CHANGELOG by example:
>>
>
> There is the tools::readNEWS function to read the NEWS file. ?It's not just
> human readable. ?That's what the RSS feed uses.
>>
>> Date ? ? ? Object ? Action ?Value ? Message
>> 2009-04-17 package ?commit ?1.1-0 ? Enhanced version of my package
>> 2009-04-15 foo ? ? ?add ? ? foo(y) ?New function foo in my package
>> 2009-04-14 bar ? ? ?debug ? ? ? ? ? bar(NULL) returned wrong result
>> 2009-04-01 package ?commit ?1.0-0 ? First version of package on CRAN
>>
>
> It doesn't contain dates, and dates don't really make sense. ?(Many
> additions are introduced over a sequence of changes. ?Do you give the first
> date, the last date? ?What if the change is very minor, e.g. a typo in the
> docs?) ? NEWS does contain R version numbers, and those are well defined.

Yes. Yet, as the FreeBSD, I found something like "this function first
appears in R/ foo package  version xxx" in man page helpful. It is not
bad to put such section in the R help page, I think.


> The RSS feed does list the date on which it noticed each change to the NEWS
> file, but I think that is more useful for keeping up to date with changes,
> rather than defining when something happened.
>>
>> It should be kept simple. May be an "Author" field in the records would be
>> nice too. Also a function to record a new entry in the CHANGELOG could look
>> like:
>>
>
> Maybe you want the Subversion log. ?It is machine readable; just use
> Subversion to read it. ?(Something nice would be R-level access to the
> Subversion API.) You can be very specific about which files you want to read
> about, or just read the whole thing on developer.r-project.org.
>
> Duncan Murdoch
>>
>> ?> track("XXX", action = "debug", message = "my comment", file =
>> "/somewhere/CHANGELOG")
>>
>> The file NEWS would not change and should be kept to present the same
>> information in a human-readable format.
>>
>> Also, a function that lists all functions used in a script or a package
>> (Romain Fran?ois is working in this direction with svTools package), plus a
>> function to plot one or several "changes" objects as returned by changes()
>> on a time axis or "version axis" would be welcome additions to further track
>> and plot evolution of R, or of R packages for a group of functions of
>> interest. Finally, a function to easily record the dependences used and
>> their versions in a script would complete the set of tools.
>>
>> These 4-5 functions are not difficult to write (although I suspect that
>> this simplistic proposal would become more complex if one consider to
>> interact with subversion, to separate development and release versions,
>> ...). But to be really useful, they should be better designed and proposed
>> by the R core team, and included in the official specifications for writing
>> package. May I suggest to think about such a change for R version 3.0?
>>
>> Things get more complicated for verifying CHANGELOG in R CMD check. At
>> least, one could check actions like:
>> - object or function addition, deprecation or disappearance,
>> - argument changes in functions, slot changes in objects,
>> - function refactoring (change in the code from previous version)
>> but only if we provide also the previous version of a package to R CMD
>> check.
>>
>> I would be happy to contribute, but the concept must certainly be further
>> discussed and enhanced (here?), and then, accepted by the R core team before
>> going any further.
>>
>> All the best,
>>
>> Philippe Grosjean
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
HUANG Ronggui, Wincent
PhD Candidate
Dept of Public and Social Administration
City University of Hong Kong
Home page: http://asrr.r-forge.r-project.org/rghuang.html


From murdoch at stats.uwo.ca  Fri Apr 17 13:58:53 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 17 Apr 2009 07:58:53 -0400
Subject: [Rd] suggestion for R >= 3.0: computer-readable CHANGELOG
In-Reply-To: <38b9f0350904170448nd338a84vcd2dc8f7327669a6@mail.gmail.com>
References: <49E82D9C.9090402@sciviews.org> <49E85C0D.6040809@stats.uwo.ca>
	<38b9f0350904170448nd338a84vcd2dc8f7327669a6@mail.gmail.com>
Message-ID: <49E86EFD.7020602@stats.uwo.ca>

On 4/17/2009 7:48 AM, ronggui wrote:
> 2009/4/17 Duncan Murdoch <murdoch at stats.uwo.ca>:
>> Philippe Grosjean wrote:
>>>
>>> Hello,
>>>
>>> Here are a few questions that would be useful to get an answer via
>>> dedicated functions in utils or tools packages:
>>> - When did function foo appeared in R or in a given package?
>>> - When did argument myarg appeared in function foo?
>>> - When did function bar get deprecated or when did it disappeared?
>>> - I wrote a script using functions foo and bar with R 1.9.1. My script
>>> does not work any more with current version. What were all the changes made
>>> to foo and/or to bar since then (this could obviously help me to update my
>>> script for current R version)?
>>>
>>> Currently, we have to read NEWS (or perhaps a non official changelog)
>>> manually to get such answers.
>>>
>>> The basic function to retrieve data that would answer to these questions
>>> would be something like:
>>>
>>>  > changes(c("foo", "bar"))
>>>
>>> That function could, for instance, read information in a computer-readable
>>> file named CHANGELOG... because the problem is there! Changes are currently
>>> recorded in NEWS, but ONLY in a human-readable form! A quick suggestion for
>>> a format for CHANGELOG by example:
>>>
>>
>> There is the tools::readNEWS function to read the NEWS file.  It's not just
>> human readable.  That's what the RSS feed uses.
>>>
>>> Date       Object   Action  Value   Message
>>> 2009-04-17 package  commit  1.1-0   Enhanced version of my package
>>> 2009-04-15 foo      add     foo(y)  New function foo in my package
>>> 2009-04-14 bar      debug           bar(NULL) returned wrong result
>>> 2009-04-01 package  commit  1.0-0   First version of package on CRAN
>>>
>>
>> It doesn't contain dates, and dates don't really make sense.  (Many
>> additions are introduced over a sequence of changes.  Do you give the first
>> date, the last date?  What if the change is very minor, e.g. a typo in the
>> docs?)   NEWS does contain R version numbers, and those are well defined.
> 
> Yes. Yet, as the FreeBSD, I found something like "this function first
> appears in R/ foo package  version xxx" in man page helpful. It is not
> bad to put such section in the R help page, I think.

It might be helpful, but often new arguments or changed behaviour happen 
later, so you'd really need a full change history for the function: 
that's what's in the Subversion log, or to some extent, in the NEWS file.

But since we've made an explicit decision not to provide active support 
for older versions, it seems rather pointless to devote extra resources 
to this.  Some new function is only available as of 2.8.0?  Why would 
you care?  You should be using 2.8.1 or 2.9.0 by now.  If you're using 
2.7.1 you're on your own.

Duncan Murdoch

> 
>> The RSS feed does list the date on which it noticed each change to the NEWS
>> file, but I think that is more useful for keeping up to date with changes,
>> rather than defining when something happened.
>>>
>>> It should be kept simple. May be an "Author" field in the records would be
>>> nice too. Also a function to record a new entry in the CHANGELOG could look
>>> like:
>>>
>>
>> Maybe you want the Subversion log.  It is machine readable; just use
>> Subversion to read it.  (Something nice would be R-level access to the
>> Subversion API.) You can be very specific about which files you want to read
>> about, or just read the whole thing on developer.r-project.org.
>>
>> Duncan Murdoch
>>>
>>>  > track("XXX", action = "debug", message = "my comment", file =
>>> "/somewhere/CHANGELOG")
>>>
>>> The file NEWS would not change and should be kept to present the same
>>> information in a human-readable format.
>>>
>>> Also, a function that lists all functions used in a script or a package
>>> (Romain Fran?ois is working in this direction with svTools package), plus a
>>> function to plot one or several "changes" objects as returned by changes()
>>> on a time axis or "version axis" would be welcome additions to further track
>>> and plot evolution of R, or of R packages for a group of functions of
>>> interest. Finally, a function to easily record the dependences used and
>>> their versions in a script would complete the set of tools.
>>>
>>> These 4-5 functions are not difficult to write (although I suspect that
>>> this simplistic proposal would become more complex if one consider to
>>> interact with subversion, to separate development and release versions,
>>> ...). But to be really useful, they should be better designed and proposed
>>> by the R core team, and included in the official specifications for writing
>>> package. May I suggest to think about such a change for R version 3.0?
>>>
>>> Things get more complicated for verifying CHANGELOG in R CMD check. At
>>> least, one could check actions like:
>>> - object or function addition, deprecation or disappearance,
>>> - argument changes in functions, slot changes in objects,
>>> - function refactoring (change in the code from previous version)
>>> but only if we provide also the previous version of a package to R CMD
>>> check.
>>>
>>> I would be happy to contribute, but the concept must certainly be further
>>> discussed and enhanced (here?), and then, accepted by the R core team before
>>> going any further.
>>>
>>> All the best,
>>>
>>> Philippe Grosjean
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
> 
>


From luke at stat.uiowa.edu  Fri Apr 17 14:20:13 2009
From: luke at stat.uiowa.edu (luke at stat.uiowa.edu)
Date: Fri, 17 Apr 2009 07:20:13 -0500 (CDT)
Subject: [Rd] How can I catch errors thrown from c via	the
 Rcpperror()function?
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D7000107605C@NA-PA-VBE03.na.tibco.com>
References: <49E683EA.5060001@bccrc.ca><18918.38016.273317.952607@ron.nulle.part><77EB52C6DD32BA4D87471DCD70C8D70001075F7A@NA-PA-VBE03.na.tibco.com><alpine.LFD.2.00.0904161125280.18357@nokomis.stat.uiowa.edu>
	<77EB52C6DD32BA4D87471DCD70C8D70001075FCA@NA-PA-VBE03.na.tibco.com>
	<77EB52C6DD32BA4D87471DCD70C8D7000107605C@NA-PA-VBE03.na.tibco.com>
Message-ID: <alpine.LFD.2.00.0904170719010.12926@itasca2.wildberry.org>

Thanks -- that looks like a reasonable change.  I'll have a more
careful look in the next couple of days and apply if I don't run into
any unexpected issues.

luke

On Thu, 16 Apr 2009, William Dunlap wrote:

> A possible fix for this is to filter the 'unsused' list before
> printing the error message and replacing the promises with
> their PRCODE expressions.
>
> Index: match.c
> ===================================================================
> --- match.c	(revision 48329)
> +++ match.c	(working copy)
> @@ -355,9 +355,28 @@
> 	    }
>
> 	if(last != R_NilValue) {
> +            /* show bad arguments in call without evaluating them */
> +            SEXP unusedForError = R_NilValue, last = R_NilValue ;
> +            for(b=unused ; b!=R_NilValue ; b=CDR(b)) {
> +                SEXP tagB = TAG(b) ;
> +                SEXP carB = CAR(b) ;
> +                if (TYPEOF(carB)==PROMSXP) {
> +                    carB = PRCODE(carB) ;
> +                }
> +                if (last==R_NilValue) {
> +                    PROTECT(last = CONS(carB, R_NilValue));
> +                    SET_TAG(last, tagB);
> +                    unusedForError = last ;
> +                } else {
> +                    SETCDR(last, CONS(carB, R_NilValue));
> +                    last = CDR(last) ;
> +                    SET_TAG(last, tagB);
> +                }
> +            }
> 	    errorcall(R_GlobalContext->call,
> 		      _("unused argument(s) %s"),
> -		      CHAR(STRING_ELT(deparse1line(unused, 0), 0)) + 4);
> +		      CHAR(STRING_ELT(deparse1line(unusedForError, 0),
> 0)) + 4);
> +                      /* '+4' is to remove 'list' from
> 'list(badTag1,...)' */
> 	}
>     }
>     UNPROTECT(1);
>
> E.g.,
>> f<-function(x,y)x+y
>> f(print(1),y=print(2),x=print(3),stop("oops"))
> Error in f(print(1), y = print(2), x = print(3), stop("oops")) :
>  unused argument(s) (print(1), stop("oops"))
>> f(print(1),y=print(2),x=print(3),z=stop("oops"))
> Error in f(print(1), y = print(2), x = print(3), z = stop("oops")) :
>  unused argument(s) (print(1), z = stop("oops"))
>> f(print(1),y=print(2),z=print(3),x=stop("oops"))
> Error in f(print(1), y = print(2), z = print(3), x = stop("oops")) :
>  unused argument(s) (print(1), z = print(3))
>
> These calls used to give:
>
>> f(print(1),y=print(2),x=print(3),stop("oops"))
> [1] 1
> Error in f(print(1), y = print(2), x = print(3), stop("oops")) : oops
>> f(print(1),y=print(2),x=print(3),z=stop("oops"))
> [1] 1
> Error in f(print(1), y = print(2), x = print(3), z = stop("oops")) :
> oops
>> f(print(1),y=print(2),z=print(3),x=stop("oops"))
> [1] 1
> [1] 3
> Error in f(print(1), y = print(2), z = print(3), x = stop("oops")) :
>  unused argument(s) (1, z = 3)
>
> Bill Dunlap
> TIBCO Software Inc - Spotfire Division
> wdunlap tibco.com
>
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org
>> [mailto:r-devel-bounces at r-project.org] On Behalf Of William Dunlap
>> Sent: Thursday, April 16, 2009 10:05 AM
>> To: luke at stat.uiowa.edu
>> Cc: r-devel at r-project.org; Dirk Eddelbuettel
>> Subject: Re: [Rd] How can I catch errors thrown from c via
>> the Rcpperror()function?
>>
>>> -----Original Message-----
>>> From: luke at stat.uiowa.edu [mailto:luke at stat.uiowa.edu]
>>> Sent: Thursday, April 16, 2009 9:27 AM
>>> To: William Dunlap
>>> Cc: Dirk Eddelbuettel; Kieran O'Neill; r-devel at r-project.org
>>> Subject: Re: [Rd] How can I catch errors thrown from c via
>>> the Rcpperror() function?
>>>
>>> Something seems amiss in the process of generating the errormessage:
>>>
>>>> f <- function(x){}
>>>> f(y = print("foo"))
>>> [1] "foo"
>>> Error in f(y = print("foo")) : unused argument(s) (y = "foo")
>>>
>>> The argument seems to be getting evaluated and its value is
>>> being used.
>>>
>>> luke
>>
>> It is in match.c, where errorcall() calls deparse1line(unused,0)
>> to get the name (and value) of the argument:
>>
>>     357         if(last != R_NilValue) {
>>     358             errorcall(R_GlobalContext->call,
>>     359                       _("unused argument(s) %s"),
>>     360                       CHAR(STRING_ELT(deparse1line(unused, 0),
>> 0)) + 4);
>>
>> Before deparse1line is called unused is (in my example)
>>     (gdb) call Rf_PrintValue(unused)
>>     $badTag
>>     <promise: 0x9aff4d4>
>> and deparse1line must be evaluating the promise.  Just showing the
>> bad tag's name would suffice in the error message, if it is a problem
>> jury rigging deparse1line to avoid the evaluation in this case.
>>
>>>
>>> On Thu, 16 Apr 2009, William Dunlap wrote:
>>>
>>>> Note that Kieren's example labelled the first
>>>> argument to try() with an improper label res30=,
>>>> not expr= (or is that a mailer turning something
>>>> into '30='?).  If it really is an improper argument
>>>> tag then this could be showing a buglet in reporting
>>>> on wrongly named arguments:
>>>>
>>>> > invisible(rm(x,y))
>>>> > x<-try(silent=TRUE, badTag=stop("Oops"))
>>>>  Error in try(silent = TRUE, badTag = stop("Oops")) : Oops
>>>> > x
>>>>  Error: object "x" not found
>>>> > y<-try(silent=TRUE, expr=stop("Oops"))
>>>> > y
>>>>  [1] "Error in try(silent = TRUE, expr = stop(\"Oops\")) : Oops\n"
>>>>  attr(,"class")
>>>>  [1] "try-error"
>>>>
>>>> In the first example I would expect an error message like
>>>>   unused argument(s) (badTag = stop("Oops"))
>>>> but it is appropriate that try() would abort if it
>>>> is called in a bad way.  Perhaps it is trying to make that
>>>> error message and that triggered the evaluation of the argument,
>>>> as in
>>>>  > grep(mypattern=stop("Oops"), "wxyz")
>>>>   Error in grep(mypattern = stop("Oops"), "wxyz") : Oops
>>>> where one might expect an error message regarding the wrongly
>>>> named argument, as in:
>>>>  > grep(mypattern="x", "wxyz")
>>>>   Error in grep(mypattern = "x", "wxyz") :
>>>>     unused argument(s) (mypattern = "x")
>>>>
>>>> Bill Dunlap
>>>> TIBCO Software Inc - Spotfire Division
>>>> wdunlap tibco.com
>>>>
>>>>> -----Original Message-----
>>>>> From: r-devel-bounces at r-project.org
>>>>> [mailto:r-devel-bounces at r-project.org] On Behalf Of Dirk
>>> Eddelbuettel
>>>>> Sent: Wednesday, April 15, 2009 7:14 PM
>>>>> To: Kieran O'Neill
>>>>> Cc: r-devel at r-project.org
>>>>> Subject: Re: [Rd] How can I catch errors thrown from c via
>>>>> the Rcpperror() function?
>>>>>
>>>>>
>>>>> Kieran,
>>>>>
>>>>> On 15 April 2009 at 18:03, Kieran O'Neill wrote:
>>>>> | I am using the flowClust package from BioConductor, which
>>>>> is largely
>>>>> | implemented in c. For some of my data, the package
>>>>> occasionally (and
>>>>> | quite stochastically) encounters a particular condition
>>>>> which halts its
>>>>> | operation. At this point, it calls the error() function
>>>>> defined by Rcpp,
>>>>> | and halts.
>>>>> |
>>>>> | What I would like to be able to do is to catch the error
>>>>> thrown, and
>>>>> | retry the operation a few times before giving up.
>>>>> |
>>>>> | However, when I wrap the call to flowClust in try() or
>>>>> tryCatch(), the
>>>>> | error seems to completely bypass them:
>>>>> |
>>>>> | Examples:
>>>>> |
>>>>> | 1. This is a trivial example just to test the try()
>> function, and
>>>>> | correctly assigns the error to the variable x:
>>>>> |
>>>>> |  > x <- try(stop(simpleError('blah')))
>>>>> | Error : blah
>>>>> |  > x
>>>>> | [1] "Error : blah\n"
>>>>> | attr(,"class")
>>>>> | [1] "try-error"
>>>>> |
>>>>> | 2. This is an example using flowClust (using real
>> data, set up to
>>>>> | guarantee that the error is thrown):
>>>>> |
>>>>> |  > x <- try(res30 = flowClust(tFrame, K=30, B=1000,
>>>>> varNames=c('CD4',
>>>>> | 'CD8','KI67', 'CD45RO', 'CD28', 'CD57', 'CCR5', 'CD19',
>>>>> 'CD27', 'CCR7',
>>>>> | 'CD127')))
>>>>> | Error in flowClust(tFrame, K = 30, B = 1000, varNames =
>>>>> c("CD4", "CD8",  :
>>>>> |
>>>>> | The covariance matrix is near singular!
>>>>> | Try running the program with a different initial
>>>>> configuration or less
>>>>> | clusters
>>>>> |  > x
>>>>> | Error: object "x" not found
>>>>> |
>>>>> |
>>>>> | The c code throwing the error is as follows (from flowClust.c):
>>>>> |
>>>>> | if(status!=0)
>>>>> |    {
>>>>> |        error("\n The covariance matrix is near singular! \n
>>>>> Try running
>>>>> | the program with a different initial configuration or
>>> less clusters
>>>>> | \n");          }
>>>>> |
>>>>> |
>>>>> | I looked up the error() function in Writing R Extensions
>>>>> and it states:
>>>>> | "The basic error handling routines are the equivalents
>>> of stop and
>>>>> | warning in R code, and use the same interface."
>>>>> |
>>>>> | Yet, it seems that they are not caught by R's error
>>> handling code.
>>>>> |
>>>>> | So:
>>>>> |
>>>>> | 1. Is this the general case (that Rcpp error()s are not
>>>>> handled by try()
>>>>> | and related methods in R)? (I'm sure this could be tested
>>>>> with a trivial
>>>>> | example, but I'm not yet familiar enough with wrapping c
>>>>> code in R to do
>>>>> | so.)
>>>>>
>>>>> Allow me to take the narrow view here as Rcpp maintainer.
>>>>> What you can do
>>>>> with Rcpp is to provide a C++ layer of try/catch around inner
>>>>> code which may
>>>>> throw C++ exception.  This will usually be caught, and (as
>>>>> shown in the Rcpp
>>>>> docs and examples) we can pass the exception message back
>>> up to R as a
>>>>> regular error message.  This is very useful as it gives you
>>>>> control back at
>>>>> the R prompt rather than just going belly-up.
>>>>>
>>>>> Now, R's try() and tryCatch() are completely separate and not
>>>>> tied into the
>>>>> exception mechanism Rcpp deals with, which is at a much
>>> lower level.
>>>>>
>>>>> Likewise, you may be out of luck with flowClust if it is C
>>>>> program.  You
>>>>> could try to add a C++ layer that tried to catch error and
>>>>> allows you do
>>>>> continue your loops.  I did something like that 15 years
>> ago in my
>>>>> dissertation research to ensure I survived the occassional
>>>>> numerical error
>>>>> from Fortran during longer Monte Carlo runs,
>>>>>
>>>>> | 2. If so, what is the correct way to handle them in R?
>>>>>
>>>>> Tricky. See 1. :)
>>>>>
>>>>> | 3. If not, do you have any suggestions as to what may
>> have caused
>>>>> | flowClust to behave in this way? (So that I can contact
>>> the package
>>>>> | maintainers and report the bug.)
>>>>>
>>>>> You could always contact them anyway and ask for advice.
>>>>>
>>>>> Hth,  Dirk
>>>>>
>>>>> --
>>>>> Three out of two people have difficulties with fractions.
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>> --
>>> Luke Tierney
>>> Chair, Statistics and Actuarial Science
>>> Ralph E. Wareham Professor of Mathematical Sciences
>>> University of Iowa                  Phone:             319-335-3386
>>> Department of Statistics and        Fax:               319-335-3017
>>>     Actuarial Science
>>> 241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
>>> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From ritz at life.ku.dk  Fri Apr 17 14:47:21 2009
From: ritz at life.ku.dk (Christian Ritz)
Date: Fri, 17 Apr 2009 14:47:21 +0200
Subject: [Rd] suggestion for R >= 3.0: computer-readable CHANGELOG
In-Reply-To: <49E85C0D.6040809@stats.uwo.ca>
References: <49E82D9C.9090402@sciviews.org> <49E85C0D.6040809@stats.uwo.ca>
Message-ID: <49E87A59.2010003@life.ku.dk>

Hi Duncan,

on a related note: It would be nice to have a function similar to tools::readNEWS() for
showing package-specific CHANGES/NEWS files (if available).


Something like:


"showNews" <- function(pkgname, filename = c("NEWS", "CHANGES"))
{
    filename <- match.arg(filename)

    file.show(paste(.libPaths(), pkgname, filename, sep = "/"),
    title = paste("Package information for", pkgname))
}


showNews("MASS")

showNews("multcomp", "CHANGES")
# requires 'multcomp' to be installed


Just an idea!

Christian


From murdoch at stats.uwo.ca  Fri Apr 17 15:05:09 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 17 Apr 2009 09:05:09 -0400
Subject: [Rd] suggestion for R >= 3.0: computer-readable CHANGELOG
In-Reply-To: <49E87A59.2010003@life.ku.dk>
References: <49E82D9C.9090402@sciviews.org> <49E85C0D.6040809@stats.uwo.ca>
	<49E87A59.2010003@life.ku.dk>
Message-ID: <49E87E85.4050700@stats.uwo.ca>

On 4/17/2009 8:47 AM, Christian Ritz wrote:
> Hi Duncan,
> 
> on a related note: It would be nice to have a function similar to tools::readNEWS() for
> showing package-specific CHANGES/NEWS files (if available).


That would be a waste of time.  People don't use the package 
documentation schemes that are in place; why would they use a new one?

Duncan Murdoch

> 
> 
> Something like:
> 
> 
> "showNews" <- function(pkgname, filename = c("NEWS", "CHANGES"))
> {
>     filename <- match.arg(filename)
> 
>     file.show(paste(.libPaths(), pkgname, filename, sep = "/"),
>     title = paste("Package information for", pkgname))
> }
> 
> 
> showNews("MASS")
> 
> showNews("multcomp", "CHANGES")
> # requires 'multcomp' to be installed
> 
> 
> Just an idea!
> 
> Christian


From phgrosjean at sciviews.org  Fri Apr 17 15:16:04 2009
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Fri, 17 Apr 2009 15:16:04 +0200
Subject: [Rd] suggestion for R >= 3.0: computer-readable CHANGELOG
In-Reply-To: <49E86EFD.7020602@stats.uwo.ca>
References: <49E82D9C.9090402@sciviews.org> <49E85C0D.6040809@stats.uwo.ca>
	<38b9f0350904170448nd338a84vcd2dc8f7327669a6@mail.gmail.com>
	<49E86EFD.7020602@stats.uwo.ca>
Message-ID: <49E88114.4080409@sciviews.org>

Duncan Murdoch wrote:
> On 4/17/2009 7:48 AM, ronggui wrote:
>> 2009/4/17 Duncan Murdoch <murdoch at stats.uwo.ca>:
> [...]
> It might be helpful, but often new arguments or changed behaviour happen 
> later, so you'd really need a full change history for the function: 
> that's what's in the Subversion log, or to some extent, in the NEWS file.

Only a few packages on CRAN use subversion and/or make it accessible to 
others. OK, this is improving with R-Forge. The proposed CHANGELOG 
should not duplicate subversion info. It would only be a collection of 
major milestones for each function, i.e., a new entry is written in 
CHANGELOG when changes are done and included in a new version of R or of 
a package, but individual steps followed to get there from one version 
to the other would NOT be recorded (use a subversion for that).

> But since we've made an explicit decision not to provide active support 
> for older versions, it seems rather pointless to devote extra resources 
> to this.  Some new function is only available as of 2.8.0?  Why would 
> you care?  You should be using 2.8.1 or 2.9.0 by now.  If you're using 
> 2.7.1 you're on your own.
> 
> Duncan Murdoch

It is not uncommon to use R to analyze some particular data, to save the 
script of the analysis, and to write a paper (or a book) about the 
results with some electronic supplements (including that script). From 
that moment on, the analysis is frozen. However, we may expect that 
other people would be interested to rerun the analysis at a later time, 
or even, to reuse the script on other data.

Thus, the decision for not providing active support for older versions 
should go together with the development of tools that would help people 
to upgrade such an old script when needed. I think the proposed tools 
fit this goal.

Philippe Grosjean

> [...]


From murdoch at stats.uwo.ca  Fri Apr 17 15:42:45 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 17 Apr 2009 09:42:45 -0400
Subject: [Rd] suggestion for R >= 3.0: computer-readable CHANGELOG
In-Reply-To: <49E88114.4080409@sciviews.org>
References: <49E82D9C.9090402@sciviews.org>
	<49E85C0D.6040809@stats.uwo.ca>	<38b9f0350904170448nd338a84vcd2dc8f7327669a6@mail.gmail.com>	<49E86EFD.7020602@stats.uwo.ca>
	<49E88114.4080409@sciviews.org>
Message-ID: <49E88755.9000504@stats.uwo.ca>

On 4/17/2009 9:16 AM, Philippe Grosjean wrote:
> Duncan Murdoch wrote:
>> On 4/17/2009 7:48 AM, ronggui wrote:
>>> 2009/4/17 Duncan Murdoch <murdoch at stats.uwo.ca>:
>> [...]
>> It might be helpful, but often new arguments or changed behaviour happen 
>> later, so you'd really need a full change history for the function: 
>> that's what's in the Subversion log, or to some extent, in the NEWS file.
> 
> Only a few packages on CRAN use subversion and/or make it accessible to 
> others.

Sorry, I missed the point that you were asking package writers to do 
this.  I think that's pretty much impossible.  You might be able to 
convince R Core to adopt documentation standards, but you will never be 
able to get package writers to do so.

For example:  the R Extensions manual has been recommending the use of a 
package man page since 2005, but very few packages bother.  If we invent 
a new format for a news/changelog file, it would only punish the careful 
package writers who already maintain such a file, but not in the desired 
format.  The ones who have no such file won't be impacted at all, 
because they'll just ignore it.

Duncan Murdoch


  OK, this is improving with R-Forge. The proposed CHANGELOG
> should not duplicate subversion info. It would only be a collection of 
> major milestones for each function, i.e., a new entry is written in 
> CHANGELOG when changes are done and included in a new version of R or of 
> a package, but individual steps followed to get there from one version 
> to the other would NOT be recorded (use a subversion for that).
> 
>> But since we've made an explicit decision not to provide active support 
>> for older versions, it seems rather pointless to devote extra resources 
>> to this.  Some new function is only available as of 2.8.0?  Why would 
>> you care?  You should be using 2.8.1 or 2.9.0 by now.  If you're using 
>> 2.7.1 you're on your own.
>> 
>> Duncan Murdoch
> 
> It is not uncommon to use R to analyze some particular data, to save the 
> script of the analysis, and to write a paper (or a book) about the 
> results with some electronic supplements (including that script). From 
> that moment on, the analysis is frozen. However, we may expect that 
> other people would be interested to rerun the analysis at a later time, 
> or even, to reuse the script on other data.

The paper should cite R, and the recommended citation format includes 
the R version number.  We do make old versions available, so if someone 
wants to reproduce an old analysis, there's a very good chance they can 
do so.

Now, running the old script in new R may well be difficult, as you say. 
   The documentation you are suggesting would make it less difficult. 
But I don't think the big problem is creating a new format for people to 
use; I think the big problem is getting people to use anything at all.

> Thus, the decision for not providing active support for older versions 
> should go together with the development of tools that would help people 
> to upgrade such an old script when needed. I think the proposed tools 
> fit this goal.

I agree with that, and I'm glad that you've volunteered to work on this.

Duncan Murdoch

> Philippe Grosjean
> 
>> [...]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From edd at debian.org  Fri Apr 17 16:12:04 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 17 Apr 2009 09:12:04 -0500
Subject: [Rd] suggestion for R >= 3.0: computer-readable CHANGELOG
In-Reply-To: <49E87E85.4050700@stats.uwo.ca>
References: <49E82D9C.9090402@sciviews.org> <49E85C0D.6040809@stats.uwo.ca>
	<49E87A59.2010003@life.ku.dk> <49E87E85.4050700@stats.uwo.ca>
Message-ID: <18920.36404.547796.504974@ron.nulle.part>


On 17 April 2009 at 09:05, Duncan Murdoch wrote:
| That would be a waste of time.  People don't use the package 
| documentation schemes that are in place; why would they use a new one?
 
Because of scattered documentation and lack of best practices?  Many things
are possible with R and packages, how many are really done consistently?  I
think this points to a need for better examples, better docs, and better
package checking tools.

I happended to have the same discussion via email last night with Brian
(CCed) who wanted to see NEWS / Changes in my CRANberries RSS feed for CRAN.
I suggested pretty much what Philippe suggested in the first post in this
thread --- with one addition.  I think we need a test in R CMD check that
emits a warning if there is no inst/NEWS or inst/Changes or inst/Changelog.

Your reminder of the parseable NEWS file was timely.  I would suggest to have
both NEWS (for 'big' events) and Changes (for 'smaller', incremental
changes).     I'd be happy to help code an additional parser Changes and/or
some checks for R CMD check if a consensus emerges that this is doable.  

Dirk


-- 
Three out of two people have difficulties with fractions.


From romain.francois at dbmail.com  Fri Apr 17 16:36:03 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Fri, 17 Apr 2009 16:36:03 +0200
Subject: [Rd] suggestion for R >= 3.0: computer-readable CHANGELOG
In-Reply-To: <49E82D9C.9090402@sciviews.org>
References: <49E82D9C.9090402@sciviews.org>
Message-ID: <49E893D3.2090105@dbmail.com>

Philippe Grosjean wrote:
> Hello,
>
> Here are a few questions that would be useful to get an answer via 
> dedicated functions in utils or tools packages:
> - When did function foo appeared in R or in a given package?
> - When did argument myarg appeared in function foo?
> - When did function bar get deprecated or when did it disappeared?
> - I wrote a script using functions foo and bar with R 1.9.1. My script 
> does not work any more with current version. What were all the changes 
> made to foo and/or to bar since then (this could obviously help me to 
> update my script for current R version)?
>
> Currently, we have to read NEWS (or perhaps a non official changelog) 
> manually to get such answers.

Hi,

I agree with the usefulness of having this available, but there is 
absolutely no way people are going to log such information in a 
systematic fashion. In the other hand, if you have version 1 and version 
2 of some package, then why not do some programmatic investigation of 
the code to get (some of) these answers.

This looks like CRANberries, but working at the object level instead of 
working at the file level, but then you can imagine to parse the 
package, dump each function/object/class in its own file, and cranberry 
that. Is CRANberry an R package ?

Romain

> The basic function to retrieve data that would answer to these 
> questions would be something like:
>
> > changes(c("foo", "bar"))
>
> That function could, for instance, read information in a 
> computer-readable file named CHANGELOG... because the problem is 
> there! Changes are currently recorded in NEWS, but ONLY in a 
> human-readable form! A quick suggestion for a format for CHANGELOG by 
> example:
>
> Date       Object   Action  Value   Message
> 2009-04-17 package  commit  1.1-0   Enhanced version of my package
> 2009-04-15 foo      add     foo(y)  New function foo in my package
> 2009-04-14 bar      debug           bar(NULL) returned wrong result
> 2009-04-01 package  commit  1.0-0   First version of package on CRAN
>
> It should be kept simple. May be an "Author" field in the records 
> would be nice too. Also a function to record a new entry in the 
> CHANGELOG could look like:
>
> > track("XXX", action = "debug", message = "my comment", file = 
> "/somewhere/CHANGELOG")
>
> The file NEWS would not change and should be kept to present the same 
> information in a human-readable format.
>
> Also, a function that lists all functions used in a script or a 
> package (Romain Fran?ois is working in this direction with svTools 
> package), plus a function to plot one or several "changes" objects as 
> returned by changes() on a time axis or "version axis" would be 
> welcome additions to further track and plot evolution of R, or of R 
> packages for a group of functions of interest. Finally, a function to 
> easily record the dependences used and their versions in a script 
> would complete the set of tools.
>
> These 4-5 functions are not difficult to write (although I suspect 
> that this simplistic proposal would become more complex if one 
> consider to interact with subversion, to separate development and 
> release versions, ...). But to be really useful, they should be better 
> designed and proposed by the R core team, and included in the official 
> specifications for writing package. May I suggest to think about such 
> a change for R version 3.0?
>
> Things get more complicated for verifying CHANGELOG in R CMD check. At 
> least, one could check actions like:
> - object or function addition, deprecation or disappearance,
> - argument changes in functions, slot changes in objects,
> - function refactoring (change in the code from previous version)
> but only if we provide also the previous version of a package to R CMD 
> check.
>
> I would be happy to contribute, but the concept must certainly be 
> further discussed and enhanced (here?), and then, accepted by the R 
> core team before going any further.
>
> All the best,
>
> Philippe Grosjean


-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From murdoch at stats.uwo.ca  Fri Apr 17 16:36:33 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 17 Apr 2009 10:36:33 -0400
Subject: [Rd] suggestion for R >= 3.0: computer-readable CHANGELOG
In-Reply-To: <18920.36404.547796.504974@ron.nulle.part>
References: <49E82D9C.9090402@sciviews.org>
	<49E85C0D.6040809@stats.uwo.ca>	<49E87A59.2010003@life.ku.dk>
	<49E87E85.4050700@stats.uwo.ca>
	<18920.36404.547796.504974@ron.nulle.part>
Message-ID: <49E893F1.9000007@stats.uwo.ca>

On 4/17/2009 10:12 AM, Dirk Eddelbuettel wrote:
> On 17 April 2009 at 09:05, Duncan Murdoch wrote:
> | That would be a waste of time.  People don't use the package 
> | documentation schemes that are in place; why would they use a new one?
>  
> Because of scattered documentation and lack of best practices?  Many things
> are possible with R and packages, how many are really done consistently?  I
> think this points to a need for better examples, better docs, and better
> package checking tools.
> 
> I happended to have the same discussion via email last night with Brian
> (CCed) who wanted to see NEWS / Changes in my CRANberries RSS feed for CRAN.
> I suggested pretty much what Philippe suggested in the first post in this
> thread --- with one addition.  I think we need a test in R CMD check that
> emits a warning if there is no inst/NEWS or inst/Changes or inst/Changelog.

I think it would have to do more than that to be useful.  It would need 
to warn about a lack of an entry for the current version.  Otherwise 
package.skeleton would create a blank one, and that would satisfy the 
check from then on.

To recognize an entry for the current version, it would need a standard 
format.  But then, unless whoever put together the format was willing to 
do updates to the hundreds of existing files out there, there would be a 
lot of resistance to any particular change.  I'd expect to hear messages 
like "Why not just use the format I've been using all along?  Why should 
I change to suit your design?  I don't have time to go through the 
dozens of packages that I maintain and update them." --- and that's from 
the careful developers who already have a changelog of some sort.  The 
majority of package writers who don't have one would just complain that 
you were wasting their time.


> Your reminder of the parseable NEWS file was timely.  I would suggest to have
> both NEWS (for 'big' events) and Changes (for 'smaller', incremental
> changes).   

I'd say that's too elaborate:  I want to write everything in one place. 
  We could use tags like NEWS uses to identify big versus small events, 
but even that is more elaborate than I'd expect most package writers to 
follow.

   I'd be happy to help code an additional parser Changes and/or
> some checks for R CMD check if a consensus emerges that this is doable.  

Could you take a look at CRAN and Bioconductor, and count how many 
packages already have a news/changelog file, and how hard it would be to 
convert them to a standard format?

Duncan Murdoch


From r.ted.byers at gmail.com  Fri Apr 17 17:09:17 2009
From: r.ted.byers at gmail.com (Ted Byers)
Date: Fri, 17 Apr 2009 11:09:17 -0400
Subject: [Rd] suggestion for R >= 3.0: computer-readable CHANGELOG
In-Reply-To: <18920.36404.547796.504974@ron.nulle.part>
References: <49E82D9C.9090402@sciviews.org> <49E85C0D.6040809@stats.uwo.ca>
	<49E87A59.2010003@life.ku.dk> <49E87E85.4050700@stats.uwo.ca>
	<18920.36404.547796.504974@ron.nulle.part>
Message-ID: <4f1819890904170809i761cc379v2068520452fd3619@mail.gmail.com>

On Fri, Apr 17, 2009 at 10:12 AM, Dirk Eddelbuettel <edd at debian.org> wrote:
>
> On 17 April 2009 at 09:05, Duncan Murdoch wrote:
> | That would be a waste of time. ?People don't use the package
> | documentation schemes that are in place; why would they use a new one?
>
> Because of scattered documentation and lack of best practices? ?Many things
> are possible with R and packages, how many are really done consistently? ?I
> think this points to a need for better examples, better docs, and better
> package checking tools.
>
Best practices?  Such things exist, and I am sure software engineering
students are routinely introduced to them these days, but at the same
time, I have seen projects where they were ignored and even where
management told their engineers to not waste time documenting
anything.  :-(   Of course I circumvented such direction by embedding
my 'documentation' as comments within my code so that anyone who is
assigned to maintain the code would know, from my comments and coding
practices I both used and taught to my juniors there, how it all
works.  I remember some of my old FORTRAN code where there were more
lines of comments documenting everything for other programmers than
there were lines of code; all in one file so the programmers using the
file would not have to look far to find the information they needed.
Not as good as the now usual UML documentation, but better than
nothing and essential in a project involving more than half a million
lines of code.

No matter how good you get, there is always a need for more, and
better, examples, documentation and tools.

> I happended to have the same discussion via email last night with Brian
> (CCed) who wanted to see NEWS / Changes in my CRANberries RSS feed for CRAN.
> I suggested pretty much what Philippe suggested in the first post in this
> thread --- with one addition. ?I think we need a test in R CMD check that
> emits a warning if there is no inst/NEWS or inst/Changes or inst/Changelog.
>
This reminds me of a tool I encountered years ago (called aegis) that
could be configured to not permit committing new code to production
codebase unless there were unit tests for it, ideally an integration
test or two, and that prior to commitment the entire build, including
the new code, passed all existing tests for the project.  A wonderful
tool for ensuring new code didn't break things!  But it works only is
used as intended.  After all, it would be trivial to write a dummy
test that always passes regardless of what the application code really
does.

If you really want your developers to use some minimalist list of best
practices, you really have to do two things.

First you have to be able to demonstrate that they will make life
easier for the developer.   I never met a developer who would spend
even a few minutes on a task for which they did not see a significant
benefit.  Even if you made it a condition of employment, you'd see on
half hearted, sloppy efforts at tasks for which they see no
significant benefit.  Since time is so precious, an intermediate
programmer is not likely to write usable documentation of his code for
a junior developer that has to follow in his footsteps.  Yes, as a
condition of employment, he'll write something, but it will be terse,
and next to useless for anyone who didn't write the code.

Second, you have to make it relatively easy to do.  No matter what the
payoff for the developer, he won't do it if the only way he can get it
done is to stand on his head eating peanuts and spitting the waste
shells into a garbage container 5 meters away while typing with his
toes, blindfolded.  It isn't going to happen.  And it can get worse in
that I have seen software houses that provide services to develop
custom software and they have a vested interest in making
comprehension of their code so difficult that their clients have no
option but to go back to them for maintainance and upgrades if they
want it in a timely fashion.

There are reasons why software developers don't use documentation
frameworks that are available to them, and I have seen some larger
software houses that have essentially capitulated to such human
behaviour and hired documentation specialists.  Who is best to develop
documentation for a given product: the engineer who developed or an
educator who has been assigned to teach people how to use it?

I can both appreciate the original request and understand why people
behave in a way that resulted in Duncan saying it is a waste of time
because people don't use package documentation schemes that are
available, and if I were managing a project I'd likely share his
frustration with it.  I certainly don't envy anyone trying to address
this issue.

Good luck.

Ted


From edd at debian.org  Fri Apr 17 17:20:18 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 17 Apr 2009 10:20:18 -0500
Subject: [Rd] suggestion for R >= 3.0: computer-readable CHANGELOG
In-Reply-To: <49E893D3.2090105@dbmail.com>
References: <49E82D9C.9090402@sciviews.org>
	<49E893D3.2090105@dbmail.com>
Message-ID: <18920.40498.863242.796360@ron.nulle.part>


Salut Romain,

On 17 April 2009 at 16:36, Romain Francois wrote:
| I agree with the usefulness of having this available, but there is 
| absolutely no way people are going to log such information in a 
| systematic fashion. In the other hand, if you have version 1 and version 

There is: you gently prod and later force them.  

We had this discussion fourteen or so year ago in Debian when
debian/changelog was not yet mandatory.  We should recommendend it now (and
have 'R CMD check' issue a warning if it is missing.

The factof the matter is that for R, we do have a) gatekeppers and we also
have b) enforced minimum standards (of passing R CMD checl).  We now 'just'
need to agree that we plan to raise the standard in an ever so slight way in
order to get additional information into packages.

To be clear:  I think this should still be voluntary. Some packages authors
don't want to, some won't -- but there will hopefully be enough to play along
at fist, and I hope that this will over time sway 

| 2 of some package, then why not do some programmatic investigation of 
| the code to get (some of) these answers.
| 
| This looks like CRANberries, but working at the object level instead of 
| working at the file level, but then you can imagine to parse the 
| package, dump each function/object/class in its own file, and cranberry 
| that. Is CRANberry an R package ?

CRANberries is ultra-simple and just 200 lines of R code. It basically
compares what the DESCRIPTION parser and available.packages() et al provide
with a stateful snapshot of that same info via SQLite. It then uses standard
tools like diff and diffstat to generate comparisons between tarballs. It
does NOT really peek into tarballs to read / parse / analyse source content.
And I have no plan to add that either.

Because CRANberries lives off a local mirror and needs a local db, I haven't
really worked on abstracting things out to put it onto r-forge. I will,
eventually, and have sent the code to 'interested parties' like Duncan when
he was building the R NEWS RSS feed.

Hth, Dirk

-- 
Three out of two people have difficulties with fractions.


From edd at debian.org  Fri Apr 17 17:22:41 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 17 Apr 2009 10:22:41 -0500
Subject: [Rd] suggestion for R >= 3.0: computer-readable CHANGELOG
In-Reply-To: <49E893F1.9000007@stats.uwo.ca>
References: <49E82D9C.9090402@sciviews.org> <49E85C0D.6040809@stats.uwo.ca>
	<49E87A59.2010003@life.ku.dk> <49E87E85.4050700@stats.uwo.ca>
	<18920.36404.547796.504974@ron.nulle.part>
	<49E893F1.9000007@stats.uwo.ca>
Message-ID: <18920.40641.635120.944317@ron.nulle.part>


On 17 April 2009 at 10:36, Duncan Murdoch wrote:
| I think it would have to do more than that to be useful.  It would need 
| to warn about a lack of an entry for the current version.  Otherwise 
| package.skeleton would create a blank one, and that would satisfy the 
| check from then on.
| 
| To recognize an entry for the current version, it would need a standard 
| format.  But then, unless whoever put together the format was willing to 
| do updates to the hundreds of existing files out there, there would be a 

I'd say use it on a go-forward basis.

| Could you take a look at CRAN and Bioconductor, and count how many 
| packages already have a news/changelog file, and how hard it would be to 
| convert them to a standard format?

I can do the count for CRAN using the account we use for cran2deb work.  I'll
be travelling this weekend (yay, Boston Marathon!) so please ping me next
week if I forget to aggregate this.

Dirk

-- 
Three out of two people have difficulties with fractions.


From wdunlap at tibco.com  Fri Apr 17 20:07:10 2009
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 17 Apr 2009 11:07:10 -0700
Subject: [Rd] some .Primitive's generate odd missing-argument messages
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D7000107623C@NA-PA-VBE03.na.tibco.com>

Since R 2.8.0 (and up to 2.10.0-devel, but not in 2.7.1),
if you call a function without a required argument and
the missing argument is first evaluated inside certain
.Primitive calls, then the error message about the missing
argument is different from the normal one and is harder
to understand.

E.g., sometimes you get 'element 1 is empty':
  > (function(x)x>0)()
  Error in (function(x) x > 0)() :
    element 1 is empty;
     the part of the args list of '>' being evaluated was:
     (x, 0)

and sometimes you get 'Non-numeric argument ...'
  > (function(qaz)log(qaz))()
  Error in log(qaz) : Non-numeric argument to mathematical function

and sometimes the missingness of the argument in the caller is
passed down to the callee:
  > (function(qaz,base)log(qaz,base))(qaz=10) # acts like base=exp(1)
  [1] 2.302585

Sometimes you get a direct message about the argument being missing:
  > (function(x)if(x) "yes" else "no")()
   Error in (function(x) if (x) "yes" else "no")() :
     argument "x" is missing, with no default

In 2.7.1 the missingness of the base= argument to log was passed
down, but the others gave the message "argument <x> is missing,
with no default".  The old uniform messsage made it easier to
track down problems.

Bill Dunlap
TIBCO Software Inc - Spotfire Division
wdunlap tibco.com 


From phgrosjean at sciviews.org  Fri Apr 17 20:09:08 2009
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Fri, 17 Apr 2009 20:09:08 +0200
Subject: [Rd] suggestion for R >= 3.0: computer-readable CHANGELOG
In-Reply-To: <49E893F1.9000007@stats.uwo.ca>
References: <49E82D9C.9090402@sciviews.org>	<49E85C0D.6040809@stats.uwo.ca>	<49E87A59.2010003@life.ku.dk>	<49E87E85.4050700@stats.uwo.ca>	<18920.36404.547796.504974@ron.nulle.part>
	<49E893F1.9000007@stats.uwo.ca>
Message-ID: <49E8C5C4.6030304@sciviews.org>

OK, then, I catch the practical point of view that is: nobody will use 
it and we cannot force people to use it. So, it means that we should 
think about tools to *automatically* generate a limited set of entries 
in the CHANGELOG.

Something like new functions appearing in a package, functions being 
deprecated, change in the function's interface (arguments definition), 
change in the dependence of packages could be tracked automatically if 
the previous version of the package is available. This should be the 
case for packages on CRAN and Bioconductor, after first release. So, 
those "changelog" tools should be best deployed at this level.

Further details could be provided directly inside the code, using simple 
formatting, and proposed as a purely optional feature. I think at 
something like:

foo <- function (x, mynewarg) {
     #CHANGE# arg:mynewarg:A new argument in my function
     ...
}

or

bar <- function (y) {
     #CHANGE# fun:Short details about this new function
}

Those #CHANGE# tags would be located by the function that automatically 
builds the CHANGELOG and corresponding details would be added. If I 
define a new function without documenting change, the CHANGELOG would 
still get an entry for the addition of this function, but just without 
comment.

After all, these #CHANGE# tags could be useful in the code too! So, that 
would encourage programmers to use them,... and it is not that far away 
from current practices for documenting code.

I am open to any other proposition for the syntax of those tags, of course.
Best,

Philippe Grosjean

Duncan Murdoch wrote:
> On 4/17/2009 10:12 AM, Dirk Eddelbuettel wrote:
>> On 17 April 2009 at 09:05, Duncan Murdoch wrote:
>> | That would be a waste of time.  People don't use the package | 
>> documentation schemes that are in place; why would they use a new one?
>>  
>> Because of scattered documentation and lack of best practices?  Many 
>> things
>> are possible with R and packages, how many are really done 
>> consistently?  I
>> think this points to a need for better examples, better docs, and better
>> package checking tools.
>>
>> I happended to have the same discussion via email last night with Brian
>> (CCed) who wanted to see NEWS / Changes in my CRANberries RSS feed for 
>> CRAN.
>> I suggested pretty much what Philippe suggested in the first post in this
>> thread --- with one addition.  I think we need a test in R CMD check that
>> emits a warning if there is no inst/NEWS or inst/Changes or 
>> inst/Changelog.
> 
> I think it would have to do more than that to be useful.  It would need 
> to warn about a lack of an entry for the current version.  Otherwise 
> package.skeleton would create a blank one, and that would satisfy the 
> check from then on.
> 
> To recognize an entry for the current version, it would need a standard 
> format.  But then, unless whoever put together the format was willing to 
> do updates to the hundreds of existing files out there, there would be a 
> lot of resistance to any particular change.  I'd expect to hear messages 
> like "Why not just use the format I've been using all along?  Why should 
> I change to suit your design?  I don't have time to go through the 
> dozens of packages that I maintain and update them." --- and that's from 
> the careful developers who already have a changelog of some sort.  The 
> majority of package writers who don't have one would just complain that 
> you were wasting their time.
> 
> 
>> Your reminder of the parseable NEWS file was timely.  I would suggest 
>> to have
>> both NEWS (for 'big' events) and Changes (for 'smaller', incremental
>> changes).   
> 
> I'd say that's too elaborate:  I want to write everything in one place. 
>  We could use tags like NEWS uses to identify big versus small events, 
> but even that is more elaborate than I'd expect most package writers to 
> follow.
> 
>   I'd be happy to help code an additional parser Changes and/or
>> some checks for R CMD check if a consensus emerges that this is doable.  
> 
> Could you take a look at CRAN and Bioconductor, and count how many 
> packages already have a news/changelog file, and how hard it would be to 
> convert them to a standard format?
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From diggsb at ohsu.edu  Fri Apr 17 20:45:43 2009
From: diggsb at ohsu.edu (Brian Diggs)
Date: Fri, 17 Apr 2009 11:45:43 -0700
Subject: [Rd] suggestion for R >= 3.0: computer-readable CHANGELOG
In-Reply-To: <18920.40641.635120.944317@ron.nulle.part>
References: <49E82D9C.9090402@sciviews.org><49E85C0D.6040809@stats.uwo.ca><49E87A59.2010003@life.ku.dk><49E87E85.4050700@stats.uwo.ca><18920.36404.547796.504974@ron.nulle.part><49E893F1.9000007@stats.uwo.ca>
	<18920.40641.635120.944317@ron.nulle.part>
Message-ID: <D90C24824765F143934E4DE78009D617A1487E@EX-BE05.ohsu.edu>

Dirk Eddelbuettel wrote:
> On 17 April 2009 at 10:36, Duncan Murdoch wrote:
> | Could you take a look at CRAN and Bioconductor, and count how many 
> | packages already have a news/changelog file, and how hard it would be to 
> | convert them to a standard format?
> 
> I can do the count for CRAN using the account we use for cran2deb work.  I'll
> be travelling this weekend (yay, Boston Marathon!) so please ping me next
> week if I forget to aggregate this.

I imagine that Dirk will do a better job than this, but as a point of comparison, I thought I'd look at how many of the CRAN summary pages for each package have a "News/ChangeLog" entry.  Starting from http://cran.r-project.org/web/packages/, the links to the packages were extracted and followed.  302 of the 1754 packages returned a page not found error.  Of the remaining 1452, the summary page was searched for a News/ChangeLog entry.  I don't know how the presence of this entry is determined, but I thought I'd use it as one measure.  389 packages have an entry; 1063 do not.  I didn't look at the variety of formats (or names) of these, but I thought this would be at least a starting point.  R code and output, including a complete list of which packages do and do not have a ChangeLog entry, is below.

I have not used any of the Bioconductor packages, so I don't know if a similar idea would work for them.

> Dirk

--
Brian Diggs, Ph.D.
Senior Research Associate, Department of Surgery, Oregon Health & Science University


library(plyr)

package.page <- readLines("http://cran.r-project.org/web/packages/")
package.lines <- grep("packages/(.*)/index.html",package.page, value=TRUE, perl=TRUE)
package.regexp <- regexpr("packages/(.*)/index.html",package.lines, perl=TRUE)
package.names <- substr(package.lines, package.regexp+9, package.regexp+attr(package.regexp,"match.length")-12)
package.urls <- paste("http://cran.r-project.org/web/packages/",package.names,"/index.html",sep="")
package.summaries <- llply(package.urls, function(x) {try(readLines(x), silent=TRUE)})
names(package.summaries) <- package.names

# packages that the link did not resolve to a page
package.gotsummary <- laply(package.summaries, class)=="character"
names(package.summaries[!package.gotsummary])
  [1] "aaMI"              "abind"             "accuracy"         
  [4] "acepack"           "actuar"            "ada"              
  [7] "adabag"            "adapt"             "ade4"             
 [10] "ade4TkGUI"         "adegenet"          "adehabitat"       
 [13] "adimpro"           "adk"               "adlift"           
 [16] "ads"               "afc"               "agce"             
 [19] "agreement"         "agricolae"         "agsemisc"         
 [22] "akima"             "allelic"           "alphahull"        
 [25] "alr3"              "amap"              "amei"             
 [28] "anacor"            "analogue"          "anapuce"          
 [31] "animation"         "anm"               "aod"              
 [34] "apTreeshape"       "ape"               "aplpack"          
 [37] "apsrtable"         "archetypes"        "argosfilter"      
 [40] "arm"               "arrayImpute"       "arrayMissPattern" 
 [43] "ars"               "arules"            "arulesNBMiner"    
 [46] "arulesSequences"   "ascii"             "ash"              
 [49] "aspace"            "aspect"            "assist"           
 [52] "aster"             "asuR"              "asympTest"        
 [55] "asypow"            "audio"             "automap"          
 [58] "aws"               "aylmer"            "backfitRichards"  
 [61] "backtest"          "bark"              "bayesCGH"         
 [64] "bayesGARCH"        "bayesSurv"         "bayesclust"       
 [67] "bayescount"        "bayesm"            "bayesmix"         
 [70] "bbmle"             "bcp"               "beanplot"         
 [73] "bear"              "benchden"          "bentcableAR"      
 [76] "betaper"           "betareg"           "bethel"           
 [79] "biOps"             "biOpsGUI"          "biclust"          
 [82] "bicreduc"          "bifactorial"       "biglm"            
 [85] "bigmemory"         "bim"               "binGroup"         
 [88] "binMto"            "bindata"           "binom"            
 [91] "bio.infer"         "biopara"           "bipartite"        
 [94] "birch"             "bise"              "bit"              
 [97] "bitops"            "bivpois"           "blighty"          
[100] "blockTools"        "blockmodeling"     "blockrand"        
[103] "bmd"               "bnlearn"           "boa"              
[106] "boolean"           "boost"             "boot"             
[109] "bootStepAIC"       "bootspecdens"      "bootstrap"        
[112] "bpca"              "bqtl"              "brainwaver"       
[115] "brew"              "brglm"             "bs"               
[118] "bspec"             "bvls"              "ca"               
[121] "caMassClass"       "caTools"           "cacheSweave"      
[124] "cacher"            "cairoDevice"       "calib"            
[127] "calibrate"         "candisc"           "canvas"           
[130] "car"               "caret"             "cat"              
[133] "catmap"            "catspec"           "cba"              
[136] "ccems"             "ccgarch"           "cclust"           
[139] "cellVolumeDist"    "celsius"           "cem"              
[142] "cfa"               "cggd"              "cgh"              
[145] "cghFLasso"         "changeLOS"         "cheb"             
[148] "chemCal"           "chemometrics"      "choplump"         
[151] "chplot"            "chron"             "cir"              
[154] "circular"          "clValid"           "clac"             
[157] "classGraph"        "classInt"          "classifly"        
[160] "clim.pact"         "climatol"          "clinfun"          
[163] "clinsig"           "clue"              "clues"            
[166] "clustTool"         "cluster"           "clusterGeneration"
[169] "clusterRepro"      "clusterSim"        "clusterfly"       
[172] "clustvarsel"       "clv"               "cmprsk"           
[175] "cobs"              "cobs99"            "cocorresp"        
[178] "coda"              "codetools"         "coin"             
[181] "colorRamps"        "colorspace"        "combinat"         
[184] "compHclust"        "compOverlapCorr"   "compare"          
[187] "compoisson"        "compositions"      "concor"           
[190] "concord"           "conf.design"       "connectedness"    
[193] "contfrac"          "contrast"          "convexHaz"        
[196] "copas"             "copula"            "corcounts"        
[199] "corpcor"           "corpora"           "corrgram"         
[202] "corrperm"          "covRobust"         "coxphf"           
[205] "coxphw"            "coxrobust"         "cramer"           
[208] "crank"             "crawl"             "crossdes"         
[211] "crosshybDetector"  "crq"               "cslogistic"       
[214] "cts"               "ctv"               "curvetest"        
[217] "cwhmisc"           "cyclones"          "data.table"       
[220] "dataframes2xls"    "date"              "dblcens"          
[223] "ddesolve"          "ddst"              "deSolve"          
[226] "deal"              "debug"             "degreenet"        
[229] "deldir"            "delt"              "demogR"           
[232] "denpro"            "denstrip"          "depmix"           
[235] "depmixS4"          "depth"             "desirability"     
[238] "dfcrm"             "dglm"              "diagram"          
[241] "diamonds"          "dice"              "dichromat"        
[244] "diffractometry"    "digest"            "diptest"          
[247] "dirichlet"         "dispmod"           "distr"            
[250] "distrDoc"          "distrEx"           "distrMod"         
[253] "distrSim"          "distrTEst"         "distrTeach"       
[256] "distributions"     "divagis"           "diveMove"         
[259] "dlm"               "dlmap"             "doBy"             
[262] "dplR"              "dprep"             "dr"               
[265] "drc"               "drfit"             "drm"              
[268] "dse"               "dti"               "dtt"              
[271] "dtw"               "dyad"              "dyn"              
[274] "dynCorr"           "dynamicGraph"      "dynamicTreeCut"   
[277] "dynamo"            "dynlm"             "e1071"            
[280] "eRm"               "earth"             "eba"              
[283] "ecespa"            "eco"               "ecodist"          
[286] "ecolMod"           "effects"           "eha"              
[289] "eiPack"            "eigenmodel"        "elasticnet"       
[292] "ellipse"           "elliptic"          "elrm"             
[295] "emdbook"           "emme2"             "empiricalBayes"   
[298] "emplik"            "emu"               "energy"           
[301] "ensembleBMA"       "entropy"          

package.hasChangeLog <- laply(package.summaries[package.gotsummary],
 function(x) {length(grep("News/ChangeLog", x)) > 0})
names(package.hasChangeLog) <- package.names[package.gotsummary]
 
table(package.hasChangeLog)
package.hasChangeLog
FALSE  TRUE 
 1063   389 

dput(package.hasChangeLog)
structure(c(FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
TRUE, FALSE, TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, 
FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, 
FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, 
FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
TRUE, FALSE, FALSE, TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, 
TRUE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, 
FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, 
FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, 
FALSE, TRUE, FALSE, TRUE, FALSE, FALSE, FALSE, TRUE, FALSE, TRUE, 
FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, TRUE, 
TRUE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, 
TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, 
TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, 
TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
TRUE, TRUE, FALSE, FALSE, FALSE, TRUE, FALSE, TRUE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, FALSE, TRUE, TRUE, 
FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, 
FALSE, FALSE, FALSE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, 
FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, 
FALSE, TRUE, FALSE, TRUE, FALSE, TRUE, FALSE, TRUE, FALSE, FALSE, 
FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, TRUE, TRUE, FALSE, 
FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, 
FALSE, FALSE, TRUE, TRUE, FALSE, FALSE, TRUE, TRUE, FALSE, FALSE, 
TRUE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, 
TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, 
TRUE, TRUE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, TRUE, 
FALSE, TRUE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, 
TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, FALSE, FALSE, 
FALSE, TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, 
TRUE, TRUE, TRUE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, 
FALSE, TRUE, FALSE, TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
FALSE, TRUE, TRUE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, TRUE, 
TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
TRUE, TRUE, FALSE, TRUE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, 
FALSE, FALSE, TRUE, TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, 
FALSE, TRUE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, 
TRUE, FALSE, TRUE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, 
FALSE, FALSE, FALSE, TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, 
FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, TRUE, 
FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
TRUE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, TRUE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE, TRUE, FALSE, TRUE, 
FALSE, TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, 
TRUE, TRUE, FALSE, TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, 
TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, 
FALSE, FALSE, TRUE, FALSE, FALSE, TRUE, TRUE, TRUE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, TRUE, FALSE, FALSE, 
TRUE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, 
FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, 
FALSE, FALSE, TRUE, FALSE, TRUE, FALSE, TRUE, FALSE, FALSE, FALSE, 
FALSE, TRUE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, 
FALSE, FALSE, TRUE, TRUE, FALSE, FALSE, TRUE, TRUE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, 
FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, 
TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
FALSE, TRUE, TRUE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, 
FALSE, TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, 
TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
TRUE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, 
FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
FALSE, FALSE, FALSE, TRUE, FALSE, TRUE, TRUE, TRUE, FALSE, TRUE, 
FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE, FALSE, FALSE, 
TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, 
FALSE, FALSE, TRUE, FALSE, TRUE, TRUE, FALSE, FALSE, TRUE, TRUE, 
FALSE, TRUE, FALSE, TRUE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
TRUE, FALSE, FALSE, TRUE, TRUE, FALSE, FALSE, TRUE, FALSE, FALSE, 
FALSE, FALSE, FALSE, TRUE, TRUE, TRUE, FALSE, TRUE, TRUE, TRUE, 
TRUE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
TRUE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, 
TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, TRUE, 
FALSE, TRUE, TRUE, TRUE, FALSE, TRUE, TRUE, FALSE, TRUE, FALSE, 
TRUE, TRUE, FALSE, FALSE, TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, 
FALSE, TRUE, TRUE, TRUE, FALSE, FALSE, TRUE, TRUE, FALSE, TRUE, 
FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, TRUE, 
FALSE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, TRUE, FALSE, FALSE, 
FALSE, TRUE, FALSE, FALSE, TRUE, FALSE, TRUE, FALSE, TRUE, FALSE, 
FALSE, FALSE, FALSE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, FALSE, 
FALSE, FALSE, FALSE, TRUE, FALSE, TRUE, TRUE, FALSE, TRUE, FALSE, 
FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
FALSE, TRUE, FALSE, FALSE, FALSE, TRUE, FALSE, TRUE, TRUE, FALSE, 
FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, 
FALSE, FALSE, TRUE, TRUE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, 
TRUE, TRUE, FALSE, TRUE, FALSE, TRUE, FALSE, FALSE, TRUE, TRUE, 
TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, TRUE, TRUE, 
FALSE, TRUE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, TRUE, FALSE, 
FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, 
FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
TRUE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, 
FALSE, TRUE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, 
FALSE, FALSE, TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, 
TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, 
FALSE, TRUE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, TRUE, TRUE, 
FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, TRUE, 
FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, TRUE, 
TRUE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, 
FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, 
FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
FALSE, FALSE, TRUE, FALSE, TRUE, FALSE, TRUE, FALSE, FALSE, FALSE, 
FALSE, TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, TRUE, TRUE, TRUE, 
TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, 
FALSE, TRUE, FALSE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, 
FALSE, FALSE, TRUE, FALSE, TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, 
TRUE, FALSE, FALSE, FALSE, TRUE, TRUE, FALSE, FALSE, TRUE, FALSE, 
FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, 
TRUE, TRUE, FALSE, TRUE, FALSE, TRUE, FALSE, FALSE, FALSE, TRUE, 
FALSE, FALSE, FALSE, TRUE, TRUE, FALSE, TRUE, TRUE, TRUE, FALSE, 
FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, 
FALSE, TRUE, TRUE, FALSE, TRUE, FALSE, FALSE, TRUE, FALSE, FALSE, 
FALSE, TRUE, FALSE, TRUE, TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, 
FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, 
FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, TRUE, 
FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, FALSE, FALSE, 
FALSE, FALSE, FALSE, TRUE, FALSE), .Names = c("ADaCGH", "AER", 
"AIGIS", "AIS", "ALS", "AMORE", "ARES", "AcceptanceSampling", 
"AdMit", "AdaptFit", "AlgDesign", "Amelia", "AnalyzeFMRI", "Animal", 
"AquaEnv", "ArDec", "BACCO", "BARD", "BAS", "BAYSTAR", "BB", 
"BCE", "BGSIMD", "BHH2", "BLCOP", "BMA", "BMN", "BPHO", "BSDA", 
"BSagri", "BaM", "BayHaz", "BayesDA", "BayesTree", "BayesValidate", 
"BayesX", "Bchron", "Bhat", "BiasedUrn", "BioIDMapper", "Biodem", 
"BiodiversityR", "BiplotGUI", "Bolstad", "BootCL", "BootPR", 
"BradleyTerry", "Brobdingnag", "BsMD", "CADFtest", "CADStat", 
"CCA", "CDNmoney", "CGIwithR", "CHsharp", "CORREP", "COZIGAM", 
"CPE", "CTFS", "CTT", "CVThresh", "Cairo", "CarbonEL", "CellularAutomaton", 
"ChainLadder", "CircStats", "CoCo", "ComPairWise", "CombMSC", 
"CompetingRiskFrailty", "Containers", "ConvCalendar", "ConvergenceConcepts", 
"CoxBoost", "CreditMetrics", "CvM2SL1Test", "CvM2SL2Test", "DAAG", 
"DAAGbio", "DAAGxtras", "DAKS", "DBI", "DCluster", "DDHFm", "DEA", 
"DEoptim", "DICOM", "DPpackage", "DTK", "Davies", "Defaults", 
"Depela", "DescribeDisplay", "Design", "Devore5", "Devore6", 
"Devore7", "DiagnosisMed", "DierckxSpline", "EDR", "EMC", "EMCC", 
"EMD", "EMJumpDiffusion", "ETC", "EVER", "EbayesThresh", "Ecdat", 
"EffectiveDose", "ElemStatLearn", "EngrExpt", "Epi", "epiR", 
"epibasix", "epicalc", "epitools", "eqtl", "equivalence", "ergm", 
"etm", "evd", "evdbayes", "evir", "exactLoglinTest", "exactRankTests", 
"exactmaxsel", "exams", "experiment", "expert", "extRemes", "FAiR", 
"FBN", "FD", "FGN", "FITSio", "FKBL", "FKF", "FTICRMS", "FactoClass", 
"FactoMineR", "Fahrmeir", "FieldSim", "FinTS", "FitAR", "Flury", 
"Formula", "FrF2", "FracSim", "FunCluster", "FunNet", "fArma", 
"fAsianOptions", "fAssets", "fBasics", "fBonds", "fCalendar", 
"fCopulae", "fEcofin", "fExoticOptions", "fExtremes", "fGarch", 
"fImport", "fMultivar", "fNonlinear", "fOptions", "fPortfolio", 
"fRegression", "fSeries", "fTrading", "fUnitRoots", "fUtilities", 
"fame", "far", "faraway", "fast", "fastICA", "fbati", "fda", 
"fdim", "fdrtool", "feature", "fechner", "ff", "ffmanova", "fgac", 
"fgui", "fields", "filehash", "filehashSQLite", "financial", 
"fingerprint", "fishmethods", "fit4NM", "fitdistrplus", "flashClust", 
"flexclust", "flexmix", "fmri", "foba", "forecasting", "foreign", 
"forensic", "fork", "fortunes", "forward", "fossil", "fpc", "fpca", 
"fpow", "fracdiff", "fractal", "frailtypack", "frontier", "fso", 
"ftnonpar", "fts", "futile", "fuzzyFDR", "fuzzyOP", "fuzzyRankTests", 
"fxregime", "G1DBN", "GAMBoost", "GDD", "GEOmap", "GExMap", "GFMaps", 
"GLDEX", "GOSim", "GPArotation", "GRASS", "GRRGI", "GSA", "GSM", 
"GenABEL", "GenKern", "GeneCycle", "GeneF", "GeneNT", "GeneNet", 
"Geneland", "GeoXp", "GillespieSSA", "GridR", "GroupSeq", "g.data", 
"gRain", "gRbase", "gRc", "gWidgets", "gWidgetsRGtk2", "gWidgetsWWW", 
"gWidgetsrJava", "gWidgetstcltk", "gafit", "gam", "gamair", "gamlss", 
"gamlss.cens", "gamlss.dist", "gamlss.mx", "gamlss.nl", "gamlss.tr", 
"gap", "gbev", "gbm", "gbs", "gcExplorer", "gcl", "gclus", "gcmrec", 
"gdata", "gee", "geepack", "geiger", "genalg", "gene2pathway", 
"genetics", "geoR", "geoRglm", "geomapdata", "geometry", "geonames", 
"geozoo", "getopt", "ggm", "ggplot", "ggplot2", "ghyp", "giRaph", 
"gibbs.met", "glasso", "gld", "glmc", "glmmAK", "glmmBUGS", "glmmML", 
"glmnet", "glmpath", "glpk", "gmaps", "gmm", "gmodels", "gmp", 
"gmt", "gmvalid", "gnm", "goalprog", "gof", "gogarch", "gpclib", 
"gplots", "gpls", "grImport", "grade", "granova", "graph", "graphicsQC", 
"grasp", "gregmisc", "gridBase", "grnnR", "grouped", "grplasso", 
"grpreg", "gsarima", "gsl", "gss", "gstat", "gsubfn", "gtm", 
"gtools", "gumbel", "gvlma", "HAPim", "HFWutils", "HH", "HI", 
"HSAUR", "HTMLapplets", "HadoopStreaming", "HaploSim", "HardyWeinberg", 
"HiddenMarkov", "Hmisc", "HydroMe", "HyperbolicDist", "hacks", 
"hapassoc", "haplo.ccs", "haplo.stats", "hapsim", "hash", "hbim", 
"hddplot", "hdeco", "hdf5", "hdrcde", "heatmap.plus", "helloJavaWorld", 
"heplots", "hett", "hexView", "hexbin", "hier.part", "hierfstat", 
"hints", "hlr", "hmm.discnp", "hoa", "homals", "homtest", "hopach", 
"hot", "howmany", "hsmm", "httpRequest", "hwde", "hwriter", "hybridHclust", 
"hydrogeo", "hydrosanity", "hyperdirichlet", "hypergeo", "IBrokers", 
"ICE", "ICEinfer", "ICS", "ICSNP", "IDPmisc", "ISA", "ISOcodes", 
"ISwR", "Icens", "Iso", "ibdreg", "ic.infer", "ic50", "icomp", 
"identity", "ifa", "ifs", "ifultools", "ig", "igraph", "iid.test", 
"imprProbEst", "impute", "imputeMDR", "ineq", "inetwork", "influence.ME", 
"inline", "intcox", "intervals", "introgress", "iplots", "ipptoolbox", 
"ipred", "irr", "irtProb", "irtoys", "ismev", "isotone", "its", 
"ivivc", "JADE", "JGR", "JM", "JavaGD", "JointGLM", "JointModeling", 
"JudgeIt", "jit", "jointDiag", "KMsurv", "Kendall", "KernSmooth", 
"kappalab", "kerfdr", "kernelPop", "kernlab", "kin.cohort", "kinship", 
"kknn", "klaR", "klin", "kml", "knnTree", "knncat", "knnflex", 
"knorm", "kohonen", "ks", "kst", "kza", "kzft", "kzs", "LDheatmap", 
"LDtests", "LIM", "LIStest", "LLAhclust", "LLN", "LMGene", "LambertW", 
"LearnBayes", "LearnEDA", "Lmoments", "LogConcDEAD", "LogicReg", 
"LoopAnalyst", "LowRankQP", "labdsv", "labeltodendro", "labstatR", 
"laercio", "lago", "lancet.iraqmortality", "languageR", "lars", 
"laser", "lasso2", "latentnet", "latentnetHRT", "lattice", "latticeExtra", 
"latticist", "lawstat", "lazy", "lcd", "lcda", "ldDesign", "lda.cv", 
"ldbounds", "leaps", "lga", "lgtdl", "lhs", "limSolve", "linprog", 
"ljr", "lme4", "lmeSplines", "lmec", "lmm", "lmodel2", "lmom", 
"lmomRFA", "lmomco", "lmtest", "lnMLE", "locfdr", "locfit", "locpol", 
"lodplot", "logcondens", "logilasso", "logistf", "loglognorm", 
"logregperm", "logspline", "lokern", "longRPart", "longitudinal", 
"longmemo", "lpSolve", "lpSolveAPI", "lpc", "lpridge", "lsa", 
"lspls", "lss", "ltm", "ltsa", "luca", "lvplot", "MAMSE", "MAclinical", 
"MBA", "MBESS", "MCAPS", "MCE", "MCMCglmm", "MCMCpack", "MCPAN", 
"MCPMod", "MChtest", "MDD", "MEMSS", "MFDA", "MIfuns", "MKLE", 
"MKmisc", "MLDA", "MLDS", "MLEcens", "MMG", "MNP", "MPV", "MSBVAR", 
"MSVAR", "MarkedPointProcess", "MasterBayes", "MatchIt", "Matching", 
"Matrix", "Metabonomic", "MiscPsycho", "ModelMap", "MultEq", 
"mAr", "mFilter", "maanova", "magic", "mapLD", "mapdata", "mapproj", 
"maps", "maptools", "maptree", "marelac", "marginTree", "marginalmodelplots", 
"markerSearchPower", "mathgraph", "matlab", "matrixcalc", "maxLik", 
"maxstat", "mblm", "mboost", "mc2d", "mcgibbsit", "mclust", "mclust02", 
"mcmc", "mco", "mda", "meboot", "mefa", "meifly", "memisc", "merror", 
"meta", "metaMA", "metacor", "mfp", "mgcv", "mhsmm", "mi", "micEcon", 
"mice", "mimR", "minet", "minpack.lm", "minxent", "mirf", "misc3d", 
"mitools", "mix", "mixPHM", "mixRasch", "mixdist", "mixer", "mixlow", 
"mixreg", "mixstock", "mixtools", "mlCopulaSelection", "mlbench", 
"mlegp", "mlica", "mlmRev", "mlogit", "mmcm", "mmlcr", "mnormt", 
"moc", "modeest", "modehunt", "modeltools", "moduleColor", "mokken", 
"mombf", "moments", "monoProc", "monomvn", "monreg", "moonsun", 
"mota", "mpm", "mprobit", "mra", "mratios", "mrdrc", "msBreast", 
"msDilution", "msProcess", "msProstate", "msm", "muS2RC", "muStat", 
"muUtil", "muhaz", "multcomp", "multcompView", "multic", "multicore", 
"multilevel", "multinomRob", "multipol", "multtest", "muscor", 
"mvbutils", "mvgraph", "mvna", "mvnmle", "mvnormtest", "mvoutlier", 
"mvpart", "mvtBinaryEP", "mvtnorm", "mvtnormpcs", "NADA", "NISTnls", 
"NMMAPSlite", "NMRS", "NORMT3", "NRAIA", "NestedCohort", "NetIndices", 
"nFDR", "nFactors", "ncdf", "ncf", "ncomplete", "negenes", "netmodels", 
"network", "networksis", "neural", "neuralnet", "nice", "nleqslv", 
"nlme", "nlmeODE", "nlrwr", "nls2", "nlstools", "nlt", "nltm", 
"nlts", "nnls", "noia", "nonbinROC", "nor1mix", "norm", "normalp", 
"normwn.test", "nortest", "noverlap", "np", "nparcomp", "npde", 
"nplplot", "npmc", "npmlreg", "nsRFA", "numDeriv", "nws", "OAIHarvester", 
"OPE", "ORMDR", "Oarray", "Oncotree", "OrdFacReg", "OrdMonReg", 
"obsSens", "oc", "oce", "odesolve", "odfWeave", "ofw", "onemap", 
"onion", "openNLP", "openNLPmodels", "opentick", "operators", 
"optmatch", "orientlib", "orloca", "orloca.es", "orth", "orthogonalsplinebasis", 
"orthopolynom", "ouch", "outliers", "oz", "PASWR", "PBSddesolve", 
"PBSmapping", "PBSmodelling", "PET", "PHYLOGR", "PK", "PKfit", 
"PKtools", "PMA", "POT", "PSAgraphics", "PSM", "PTAk", "PairViz", 
"Peaks", "PearsonICA", "PerformanceAnalytics", "PhViD", "PhySim", 
"PolynomF", "Pomic", "PredictiveRegression", "PresenceAbsence", 
"ProfessR", "PtProcess", "PwrGSD", "pARccs", "pack", "packClassic", 
"pairwiseCI", "paleoTS", "paltran", "pamr", "pan", "panel", "papply", 
"paran", "partitions", "partsm", "party", "pastecs", "pbatR", 
"pcaPP", "pcalg", "pcse", "pcurve", "pear", "pec", "pedigree", 
"penalized", "penalizedSVM", "peperr", "permax", "permtest", 
"perturb", "pga", "pgam", "pgirmess", "phangorn", "pheno", "phmm", 
"phpSerialize", "picante", "pinktoe", "pixmap", "plRasch", "playwith", 
"plink", "plm", "plotSEMM", "plotpc", "plotrix", "pls", "plsgenomics", 
"plspm", "plugdensity", "plyr", "pmg", "pmml", "poLCA", "poilog", 
"polspline", "polyapost", "polycor", "polydect", "polynom", "pomp", 
"popbio", "popgen", "poplab", "portfolio", "portfolioSim", "powell", 
"powerGWASinteraction", "powerpkg", "ppc", "ppls", "pps", "prabclus", 
"predbayescor", "predmixcor", "prefmod", "prettyR", "prim", "primer", 
"princurve", "prob", "prodlim", "profileModel", "profr", "proftools", 
"proj4", "proptest", "proto", "proxy", "pscl", "pseudo", "pspearman", 
"pspline", "psy", "psych", "psychometric", "psyphy", "pvclust", 
"pwr", "pwt", "QCA", "QCAGUI", "QRMlib", "QuantPsyc", "qAnalyst", 
"qcc", "qdg", "qgen", "qlspack", "qp", "qpcR", "qtl", "qtlDesign", 
"qtlbim", "qtlbook", "quadprog", "qualV", "quantchem", "quantmod", 
"quantreg", "quantregForest", "qvalue", "qvcalc", "R.cache", 
"R.huge", "R.matlab", "R.methodsS3", "R.oo", "R.rsp", "R.utils", 
"R2HTML", "R2WinBUGS", "R2jags", "RArcInfo", "RBGL", "RBloomberg", 
"RColorBrewer", "RCurl", "RDieHarder", "REQS", "RExcelInstaller", 
"RFA", "RFOC", "RFreak", "RGrace", "RGraphics", "RGtk2", "RHRV", 
"RHmm", "RII", "RItools", "RJDBC", "RJaCGH", "RKEA", "RLMM", 
"RLRsim", "RLadyBug", "RM2", "RMTstat", "RMySQL", "RNetCDF", 
"ROCR", "RODBC", "ROptEst", "ROptEstOld", "ROptRegTS", "ROracle", 
"RPMG", "RPostgreSQL", "RPyGeo", "RQDA", "RQuantLib", "RSAGA", 
"RSEIS", "RSQLite", "RSVGTipsDevice", "RScaLAPACK", "RSeqMeth", 
"RSurvey", "RSvgDevice", "RTOMO", "RTisean", "RUnit", "RWeka", 
"RWinEdt", "RXshrink", "RadioSonde", "RandVar", "RandomFields", 
"RankAggreg", "RaschSampler", "Ratings", "Rcapture", "Rcmdr", 
"RcmdrPlugin.Export", "RcmdrPlugin.FactoMineR", "RcmdrPlugin.HH", 
"RcmdrPlugin.IPSUR", "RcmdrPlugin.SurvivalT", "RcmdrPlugin.TeachingDemos", 
"RcmdrPlugin.epack", "RcmdrPlugin.orloca", "RcmdrPlugin.qcc", 
"RcmdrPlugin.survival", "Rcplex", "Rcpp", "Rcsdp", "Read.isi", 
"Reliability", "ResearchMethods", "ResistorArray", "Rfwdmv", 
"Rglpk", "RiboSort", "Rigroup", "Rlab", "Rlabkey", "Rlsf", "Rmpi", 
"RobAStBase", "RobLox", "RobRex", "Rpad", "Rsac", "Rserve", "Rsge", 
"Rsundials", "Rsymphony", "Runuran", "Rvelslant", "Rwave", "Ryacas", 
"r2lUniv", "rJava", "rPorta", "rSymPy", "race", "rake", "ramps", 
"randaes", "random", "randomForest", "randomLCA", "randomSurvivalForest", 
"randtoolbox", "rankreg", "rateratio.test", "rattle", "rbenchmark", 
"rbounds", "rbugs", "rcdd", "rcdk", "rcdklibs", "rcom", "rcompgen", 
"rconifers", "rda", "rdetools", "realized", "ref", "registry", 
"regress", "regsubseq", "regtest", "rela", "relaimpo", "relations", 
"relax", "relaxo", "reldist", "relimp", "relsurv", "remMap", 
"repolr", "reporttools", "reshape", "resper", "reweight", "rgcvpack", 
"rgdal", "rgenoud", "rggobi", "rgl", "rgr", "rgrs", "rhosp", 
"richards", "rimage", "rindex", "risksetROC", "rjacobi", "rjags", 
"rjson", "rlecuyer", "rmeta", "rmetasim", "rngwell19937", "robCompositions", 
"robfilter", "robust", "robustbase", "rootSolve", "roxygen", 
"rpanel", "rpart", "rpubchem", "rpvm", "rqmcmb2", "rrcov", "rrp", 
"rscproxy", "rsm", "rsprng", "rstream", "rtiff", "rtv", "runjags", 
"rv", "rwm", "rwt", "SASPECT", "SASmixed", "SASxport", "SDDA", 
"SDaA", "SGCS", "SGP", "SIN", "SLmisc", "SMC", "SMPracticals", 
"SMVar", "SNPMaP", "SNPMaP.cdm", "SNPassoc", "SNPmaxsel", "SQLiteDF", 
"SQLiteMap", "SRPM", "STAR", "ScottKnott", "SemiPar", "SenSrivastava", 
"SensoMineR", "SeqKnn", "SharedHT2", "SiZer", "SimComp", "SimHap", 
"SimpleTable", "Snowball", "SoDA", "SoPhy", "SparseM", "SpatialExtremes", 
"SpatialNP", "SpectralGEM", "SpherWave", "StatDA", "StatDataML", 
"StatFingerprints", "StatMatch", "Stem", "StreamMetabolism", 
"SubpathwayMiner", "SuppDists", "SweaveListingUtils", "SwissAir", 
"SyNet", "Synth", "s20x", "sabreR", "sac", "sampfling", "sampleSelection", 
"sampling", "samr", "sandwich", "sapa", "sbgcop", "sca", "scagnostics", 
"scaleboot", "scape", "scapeMCMC", "scatterplot3d", "schoolmath", 
"sciplot", "scout", "scrime", "scuba", "sda", "sdcMicro", "sdcTable", 
"sde", "sdtalt", "sdtoolkit", "seacarb", "seas", "seewave", "segclust", 
"segmented", "selectiongain", "sem", "sendplot", "sensR", "sensitivity", 
"seqinr", "seqmon", "seriation", "session", "setRNG", "sets", 
"sfsmisc", "sgeostat", "shape", "shapefiles", "shapes", "siar", 
"sigma2tools", "signal", "signalextraction", "simba", "simco", 
"simecol", "simex", "similarityRichards", "simone", "simpleboot", 
"singlecase", "sisus", "skewt", "sm", "sma", "smacof", "smatr", 
"smoothSurv", "smoothtail", "sn", "sna", "snow", "snowFT", "snowfall", 
"snp.plotter", "snpXpert", "som", "sound", "sp", "spBayes", "space", 
"spam", "sparseLDA", "spatclus", "spatgraphs", "spatialCovariance", 
"spatialkernel", "spatialsegregation", "spatstat", "spc", "spcosa", 
"spdep", "spe", "spectralGP", "spectrino", "spgrass6", "spgwr", 
"splancs", "spls", "splus2R", "spssDDI", "spsurvey", "spuRs", 
"sqldf", "ssanv", "ssize.fdr", "sspir", "sspline", "st", "staRt", 
"stab", "startupmsg", "stashR", "statmod", "statnet", "stepPlr", 
"stepwise", "stinepack", "stochasticGEM", "stochmod", "stream.net", 
"strucchange", "subplex", "subselect", "sudoku", "supclust", 
"superpc", "surv2sample", "survBayes", "survcomp", "surveillance", 
"survey", "surveyNG", "survival", "survivalROC", "survrec", "svGUI", 
"svIDE", "svMisc", "svSocket", "svcR", "svcm", "svmpath", "systemfit", 
"TIMP", "TRAMPR", "TRIANG", "TSA", "TSHRC", "TSMySQL", "TSP", 
"TSPostgreSQL", "TSSQLite", "TSdbi", "TSfame", "TShistQuote", 
"TSodbc", "TSpadi", "TTR", "TWIX", "TeachingDemos", "TeachingSampling", 
"TinnR", "TraMineR", "TwoWaySurvival", "TwslmSpikeWeight", "taskPR", 
"tawny", "tcltk2", "tdist", "tdm", "tdthap", "tensor", "tensorA", 
"termstrc", "tframe", "tframePlus", "tgp", "tiger", "tileHMM", 
"time", "timeDate", "timeSeries", "timereg", "timsac", "tis", 
"titan", "titecrm", "tkrgl", "tkrplot", "tlemix", "tlnise", "tm", 
"tmvtnorm", "topmodel", "tossm", "tpr", "trackObjs", "tradeCosts", 
"tree", "treelet", "triangle", "trimcluster", "trip", "tripEstimation", 
"tripack", "truncgof", "truncnorm", "truncreg", "trust", "tsDyn", 
"tsModel", "tseries", "tseriesChaos", "tsfa", "tslars", "tuneR", 
"tutoR", "twang", "tweedie", "twslm", "UNF", "USPS", "Umacs", 
"UsingR", "ucminf", "udunits", "ump", "unbalhaar", "uncompress", 
"uniCox", "untb", "urca", "urn", "uroot", "VDCutil", "VGAM", 
"VIM", "VLMC", "VR", "VaR", "VhayuR", "vabayelMix", "varSelRF", 
"varmixt", "vars", "vbmp", "vcd", "vegan", "verification", "verify", 
"vioplot", "vowels", "vrmlgen", "vrtest", "WINRPACK", "WWGbook", 
"WaveCGH", "WeedMap", "WhatIf", "WilcoxCV", "WriteXLS", "wasim", 
"waveclock", "waved", "wavelets", "waveslim", "wavethresh", "wccsom", 
"wgaim", "wikibooks", "wle", "wmtsa", "wnominate", "wombsoft", 
"wordnet", "write.snns", "XML", "XReg", "x12", "xgobi", "xtable", 
"xts", "YaleToolkit", "YourCast", "yaImpute", "yacca", "yaml", 
"yest", "ZIGP", "Zelig", "zipfR", "zoeppritz", "zoo", "zyp"))


From tobias.verbeke at telenet.be  Fri Apr 17 20:50:49 2009
From: tobias.verbeke at telenet.be (Tobias Verbeke)
Date: Fri, 17 Apr 2009 20:50:49 +0200
Subject: [Rd] suggestion for R >= 3.0: computer-readable CHANGELOG
In-Reply-To: <18920.40641.635120.944317@ron.nulle.part>
References: <49E82D9C.9090402@sciviews.org>
	<49E85C0D.6040809@stats.uwo.ca>	<49E87A59.2010003@life.ku.dk>
	<49E87E85.4050700@stats.uwo.ca>	<18920.36404.547796.504974@ron.nulle.part>	<49E893F1.9000007@stats.uwo.ca>
	<18920.40641.635120.944317@ron.nulle.part>
Message-ID: <49E8CF89.4030402@telenet.be>

Dirk Eddelbuettel wrote:
> On 17 April 2009 at 10:36, Duncan Murdoch wrote:
> | I think it would have to do more than that to be useful.  It would need 
> | to warn about a lack of an entry for the current version.  Otherwise 
> | package.skeleton would create a blank one, and that would satisfy the 
> | check from then on.
> | 
> | To recognize an entry for the current version, it would need a standard 
> | format.  But then, unless whoever put together the format was willing to 
> | do updates to the hundreds of existing files out there, there would be a 
> 
> I'd say use it on a go-forward basis.

I agree. For the ChangeLog, the GNU ChangeLog format could be used.
The advantage is that there are already converters available for some
commonly used source control management systems, such that users
can stick with their favorite systems and comply:

For git:
http://git.savannah.gnu.org/gitweb/?p=gnulib.git;a=blob_plain;f=build-aux/gitlog-to-changelog;hb=HEAD

For Subversion:
http://ch.tudelft.nl/~arthur/svn2cl/

For CVS:
http://www.red-bean.com/cvs2cl/

Always willing to participate (also in converting existing files).

Best,
Tobias

> | Could you take a look at CRAN and Bioconductor, and count how many 
> | packages already have a news/changelog file, and how hard it would be to 
> | convert them to a standard format?
> 
> I can do the count for CRAN using the account we use for cran2deb work.  I'll
> be travelling this weekend (yay, Boston Marathon!) so please ping me next
> week if I forget to aggregate this.
> 
> Dirk
>


From phgrosjean at sciviews.org  Fri Apr 17 22:32:28 2009
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Fri, 17 Apr 2009 22:32:28 +0200
Subject: [Rd] suggestion for R >= 3.0: computer-readable CHANGELOG
In-Reply-To: <49E8CF89.4030402@telenet.be>
References: <49E82D9C.9090402@sciviews.org>	<49E85C0D.6040809@stats.uwo.ca>	<49E87A59.2010003@life.ku.dk>	<49E87E85.4050700@stats.uwo.ca>	<18920.36404.547796.504974@ron.nulle.part>	<49E893F1.9000007@stats.uwo.ca>	<18920.40641.635120.944317@ron.nulle.part>
	<49E8CF89.4030402@telenet.be>
Message-ID: <49E8E75C.4060007@sciviews.org>

Tobias Verbeke wrote:
> Dirk Eddelbuettel wrote:
>> On 17 April 2009 at 10:36, Duncan Murdoch wrote:
>> | I think it would have to do more than that to be useful.  It would 
>> need | to warn about a lack of an entry for the current version.  
>> Otherwise | package.skeleton would create a blank one, and that would 
>> satisfy the | check from then on.
>> | | To recognize an entry for the current version, it would need a 
>> standard | format.  But then, unless whoever put together the format 
>> was willing to | do updates to the hundreds of existing files out 
>> there, there would be a
>> I'd say use it on a go-forward basis.
> 
> I agree. For the ChangeLog, the GNU ChangeLog format could be used.
> The advantage is that there are already converters available for some
> commonly used source control management systems, such that users
> can stick with their favorite systems and comply:
> 
> For git:
> http://git.savannah.gnu.org/gitweb/?p=gnulib.git;a=blob_plain;f=build-aux/gitlog-to-changelog;hb=HEAD 
> 
> 
> For Subversion:
> http://ch.tudelft.nl/~arthur/svn2cl/
> 
> For CVS:
> http://www.red-bean.com/cvs2cl/
> 
> Always willing to participate (also in converting existing files).
> 
> Best,
> Tobias

But that gives the information at the file level. Since there is no 
constraint in R package to place the function in a given file (even 
several R functions or objects can be defined in the same file), it 
gives no useful information to track changes at the level of the functions!
Best,

Philippe

>> | Could you take a look at CRAN and Bioconductor, and count how many | 
>> packages already have a news/changelog file, and how hard it would be 
>> to | convert them to a standard format?
>>
>> I can do the count for CRAN using the account we use for cran2deb 
>> work.  I'll
>> be travelling this weekend (yay, Boston Marathon!) so please ping me next
>> week if I forget to aggregate this.
>>
>> Dirk
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From tobias.verbeke at telenet.be  Fri Apr 17 23:17:43 2009
From: tobias.verbeke at telenet.be (Tobias Verbeke)
Date: Fri, 17 Apr 2009 23:17:43 +0200
Subject: [Rd] suggestion for R >= 3.0: computer-readable CHANGELOG
In-Reply-To: <49E8E75C.4060007@sciviews.org>
References: <49E82D9C.9090402@sciviews.org>	<49E85C0D.6040809@stats.uwo.ca>	<49E87A59.2010003@life.ku.dk>	<49E87E85.4050700@stats.uwo.ca>	<18920.36404.547796.504974@ron.nulle.part>	<49E893F1.9000007@stats.uwo.ca>	<18920.40641.635120.944317@ron.nulle.part>
	<49E8CF89.4030402@telenet.be> <49E8E75C.4060007@sciviews.org>
Message-ID: <49E8F1F7.6030906@telenet.be>

Philippe Grosjean wrote:
> Tobias Verbeke wrote:
>> Dirk Eddelbuettel wrote:
>>> On 17 April 2009 at 10:36, Duncan Murdoch wrote:
>>> | I think it would have to do more than that to be useful.  It would 
>>> need | to warn about a lack of an entry for the current version.  
>>> Otherwise | package.skeleton would create a blank one, and that would 
>>> satisfy the | check from then on.
>>> | | To recognize an entry for the current version, it would need a 
>>> standard | format.  But then, unless whoever put together the format 
>>> was willing to | do updates to the hundreds of existing files out 
>>> there, there would be a
>>> I'd say use it on a go-forward basis.
>>
>> I agree. For the ChangeLog, the GNU ChangeLog format could be used.
>> The advantage is that there are already converters available for some
>> commonly used source control management systems, such that users
>> can stick with their favorite systems and comply:
>>
>> For git:
>> http://git.savannah.gnu.org/gitweb/?p=gnulib.git;a=blob_plain;f=build-aux/gitlog-to-changelog;hb=HEAD 
>>
>>
>> For Subversion:
>> http://ch.tudelft.nl/~arthur/svn2cl/
>>
>> For CVS:
>> http://www.red-bean.com/cvs2cl/
>>
>> Always willing to participate (also in converting existing files).
>>
>> Best,
>> Tobias
> 
> But that gives the information at the file level. Since there is no 
> constraint in R package to place the function in a given file (even 
> several R functions or objects can be defined in the same file), it 
> gives no useful information to track changes at the level of the functions!

I understand your point, but either (1) you rely on the succinct 
descriptions of developers in commit messages (and derive code
changes to look for) or (2) (as proposed in your original post) you
generate an overview of changes in code and need to rely on your
own interpretation of what these changes are about at a higher
level.

Having a structured, computer readable ChangeLog format (that might
just come out of an SCM or not) is IMO as interesting an objective as 
(2). If an argument is added in a new version, (2) is great, but the 
mere detection of change in code will not tell you it is a bug fix, for 
example, whereas a commit message might do so.

Just my 2 eurocents.

Best,
Tobias

> 
>>> | Could you take a look at CRAN and Bioconductor, and count how many 
>>> | packages already have a news/changelog file, and how hard it would 
>>> be to | convert them to a standard format?
>>>
>>> I can do the count for CRAN using the account we use for cran2deb 
>>> work.  I'll
>>> be travelling this weekend (yay, Boston Marathon!) so please ping me 
>>> next
>>> week if I forget to aggregate this.
>>>
>>> Dirk
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
> 
>


From hpages at fhcrc.org  Sat Apr 18 09:59:38 2009
From: hpages at fhcrc.org (hpages at fhcrc.org)
Date: Sat, 18 Apr 2009 00:59:38 -0700
Subject: [Rd] bug in classesToAM()
Message-ID: <20090418005938.wqw7okho0skswcgs@webmail.fhcrc.org>

Hi,

I can't get the non-abbreviated class names of the
rows and the cols of the Adjacency Matrix:

setClass("ClassWithALongName")
setClass("SubclassOfClassWithALongName",
          contains="ClassWithALongName")

Trying all possible values for 'abbreviate' (with R-2.9.0):

> classesToAM("SubclassOfClassWithALongName", abbreviate=0)
      SubclassOfClassWithALongName ClassWithALongName
SOCW                            0                  1
CWAL                            0                  0

> classesToAM("SubclassOfClassWithALongName", abbreviate=1)
                              SOCW CWAL
SubclassOfClassWithALongName    0    1
ClassWithALongName              0    0

> classesToAM("SubclassOfClassWithALongName", abbreviate=2)
      SOCW CWAL
SOCW    0    1
CWAL    0    0

> classesToAM("SubclassOfClassWithALongName", abbreviate=3)
                              SOCW CWAL
SubclassOfClassWithALongName    0    1
ClassWithALongName              0    0

This does not reflect what the man page is saying: "values
0, 1, 2, or 3 abbreviate neither, rows, columns or both".

Cheers,
H.


From jfox at mcmaster.ca  Sat Apr 18 15:33:39 2009
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 18 Apr 2009 09:33:39 -0400
Subject: [Rd] wish list: automatic package installation
Message-ID: <002101c9c02a$50994070$f1cbc150$@ca>

Dear list members,

The release of R 2.9.0, reminds me of a long-standing nit that I have to
pick. I prefer not to transfer and update all of the packages in my old
library, because I see a new release of R as an opportunity to start with a
clean slate. I'd rather install packages as I need them. My personal
solution is to use the following function in place of library():

package <- function(package, dependencies=TRUE, ...){
     package <- as.character(substitute(package))
     if (!(package %in% .packages(all.available=TRUE)))
        install.packages(package, dependencies=dependencies)
    library(package, character.only=TRUE, ...)
    }

I'm sure that this function could be improved, and possibly I've missed a
facility that's already available. If not, it would be nice if the library()
command automatically tried to download and install missing packages
(perhaps if an option is set).

Regards,
 John

------------------------------
John Fox, Professor
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
web: socserv.mcmaster.ca/jfox


From romain.francois at dbmail.com  Sat Apr 18 15:35:41 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Sat, 18 Apr 2009 15:35:41 +0200
Subject: [Rd] speedup for as.matrix.dist
Message-ID: <49E9D72D.9030409@dbmail.com>

Hello,

I am trying to patch as.matrix.dist to achieve some speedup.

 > m <- expand.grid( x = 1:20, y = 1:20, z = 1:20 )
 > d <- dist( m )
 > system.time( out <- stats:::as.matrix.dist( d ) )
   user  system elapsed
 15.355   3.110  19.123
 > system.time( out <- as.matrix.dist( d ) )
   user  system elapsed
  3.153   0.480   3.782

The code below works if I deploy it in an additional package, but not 
when I patch the "stats" package, I get that kind of message:
  C symbol name "as_matrix_dist" not in load table

Romain


as.matrix.dist <- function(x, ...) {
    size <- as.integer(attr(x, "Size"))
    if( !is.numeric(x) ){
        storage.mode(x) <- "numeric"
    }
    df <- .External( "as_matrix_dist",
        x = x, size = size, PACKAGE = "stats" )
    labels <- attr(x, "Labels")
    dimnames(df) <- if(is.null(labels)) list(1L:size,1L:size) else 
list(labels,labels)
    df
}



/**
 * as.matrix.dist( d )
 */
SEXP as_matrix_dist(SEXP args){
   
    args = CDR( args ) ; SEXP x = CAR( args );
    args = CDR( args ) ; SEXP size = CAR( args );
   
    int i,j,k;
    int s = INTEGER(size)[0];
    SEXP d ;
    PROTECT( d = allocVector( REALSXP, s*s) );
    double element;
    for( i=0,k=0; i<s; i++){
        REAL(d)[i+s*i] = 0.0 ;
        for( j=i+1; j<s; j++,k++){
            element = REAL(x)[k] ;
            REAL( d )[ i + s*j ] = element ;
            REAL( d )[ j + s*i ] = element ;
        }
    }
    SEXP dims ;
    PROTECT( dims = allocVector(INTSXP, 2 ) );
    INTEGER(dims)[0] = s ;
    INTEGER(dims)[1] = s ;
    setAttrib( d, mkString("dim"), dims );
    UNPROTECT(2); /* d, dims */
    return( d ) ;
}



-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From romain.francois at dbmail.com  Sat Apr 18 16:12:53 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Sat, 18 Apr 2009 16:12:53 +0200
Subject: [Rd] print.closure at the R level
Message-ID: <49E9DFE5.7060501@dbmail.com>

Hello,

Could the code that auto prints a function/closure be extracted from 
print.c so that there would be a print.closure function.
I would like to be able to mask a print.closure function so that I have 
a custom auto-print. One reason for that is I plan to have syntax 
highlighting within the R console.

Romain

-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From murdoch at stats.uwo.ca  Sat Apr 18 16:23:25 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 18 Apr 2009 10:23:25 -0400
Subject: [Rd] print.closure at the R level
In-Reply-To: <49E9DFE5.7060501@dbmail.com>
References: <49E9DFE5.7060501@dbmail.com>
Message-ID: <49E9E25D.9070106@stats.uwo.ca>

On 18/04/2009 10:12 AM, Romain Francois wrote:
> Hello,
> 
> Could the code that auto prints a function/closure be extracted from 
> print.c so that there would be a print.closure function.
> I would like to be able to mask a print.closure function so that I have 
> a custom auto-print. One reason for that is I plan to have syntax 
> highlighting within the R console.

The class of a closure is "function", so you'd want the method to be 
print.function.  Currently that doesn't work for auto printing, so your 
suggestion is still interesting.  (I'm not sure why auto printing is 
special here...)

Duncan Murdoch


From zhu_qifei at yahoo.com.sg  Sat Apr 18 18:34:38 2009
From: zhu_qifei at yahoo.com.sg (Qifei Zhu)
Date: Sat, 18 Apr 2009 12:34:38 -0400
Subject: [Rd] dotplot in a loop
In-Reply-To: <mailman.0.1240072187.27009.r-devel@r-project.org>
References: <mailman.0.1240072187.27009.r-devel@r-project.org>
Message-ID: <001801c9c043$92d934e0$b88b9ea0$@com.sg>

Hi all,

I'm a newbie R developer, am trying to dotplot a few graphs using a for
loop.

The following code works fine but once I wanna plot inside a loop, nothing
happens.
> for(i in 1:1){dotplot(y~x)}
> y <- c(1,2,3)
> x <- c('a','b','c')
> dotplot(y~x)

> for (i in 1:3) {dotplot(y~x)} (y and x depends on I in actual case)
Nothing happens.

I appreciate your advice on what is going wrong? Thanks.

Best,
Tony


From maechler at stat.math.ethz.ch  Sat Apr 18 19:02:19 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 18 Apr 2009 19:02:19 +0200
Subject: [Rd] dotplot in a loop
In-Reply-To: <001801c9c043$92d934e0$b88b9ea0$@com.sg>
References: <mailman.0.1240072187.27009.r-devel@r-project.org>
	<001801c9c043$92d934e0$b88b9ea0$@com.sg>
Message-ID: <18922.1947.749283.285184@cmath-5.math.ethz.ch>

This is *definitely* a question for R-help,
not for R-devel.

Please do not misuse R-devel!

Regards,
Martin

>>>>> "QZ" == Qifei Zhu <zhu_qifei at yahoo.com.sg>
>>>>>     on Sat, 18 Apr 2009 12:34:38 -0400 writes:

    QZ> Hi all,
    QZ> I'm a newbie R developer, am trying to dotplot a few graphs using a for
    QZ> loop.

    QZ> The following code works fine but once I wanna plot inside a loop, nothing
    QZ> happens.
    >> for(i in 1:1){dotplot(y~x)}
    >> y <- c(1,2,3)
    >> x <- c('a','b','c')
    >> dotplot(y~x)

    >> for (i in 1:3) {dotplot(y~x)} (y and x depends on I in actual case)
    QZ> Nothing happens.

    QZ> I appreciate your advice on what is going wrong? Thanks.


    QZ> Best,
    QZ> Tony

    QZ> ______________________________________________
    QZ> R-devel at r-project.org mailing list
    QZ> https://stat.ethz.ch/mailman/listinfo/r-devel


From zhu_qifei at yahoo.com.sg  Sat Apr 18 19:13:02 2009
From: zhu_qifei at yahoo.com.sg (Qifei Zhu)
Date: Sat, 18 Apr 2009 13:13:02 -0400
Subject: [Rd] dotplot in a loop
In-Reply-To: <18922.1947.749283.285184@cmath-5.math.ethz.ch>
References: <mailman.0.1240072187.27009.r-devel@r-project.org>	<001801c9c043$92d934e0$b88b9ea0$@com.sg>
	<18922.1947.749283.285184@cmath-5.math.ethz.ch>
Message-ID: <001901c9c048$efd3e730$cf7bb590$@com.sg>

Ok, noted. Sorry for the confusion.



-----Original Message-----
From: Martin Maechler [mailto:maechler at stat.math.ethz.ch] 
Sent: Saturday, April 18, 2009 1:02 PM
To: Qifei Zhu
Cc: r-devel at r-project.org
Subject: Re: [Rd] dotplot in a loop

This is *definitely* a question for R-help,
not for R-devel.

Please do not misuse R-devel!

Regards,
Martin

>>>>> "QZ" == Qifei Zhu <zhu_qifei at yahoo.com.sg>
>>>>>     on Sat, 18 Apr 2009 12:34:38 -0400 writes:

    QZ> Hi all,
    QZ> I'm a newbie R developer, am trying to dotplot a few graphs using a
for
    QZ> loop.

    QZ> The following code works fine but once I wanna plot inside a loop,
nothing
    QZ> happens.
    >> for(i in 1:1){dotplot(y~x)}
    >> y <- c(1,2,3)
    >> x <- c('a','b','c')
    >> dotplot(y~x)

    >> for (i in 1:3) {dotplot(y~x)} (y and x depends on I in actual case)
    QZ> Nothing happens.

    QZ> I appreciate your advice on what is going wrong? Thanks.


    QZ> Best,
    QZ> Tony

    QZ> ______________________________________________
    QZ> R-devel at r-project.org mailing list
    QZ> https://stat.ethz.ch/mailman/listinfo/r-devel


From romain.francois at dbmail.com  Sat Apr 18 20:30:42 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Sat, 18 Apr 2009 20:30:42 +0200
Subject: [Rd] print.closure at the R level
In-Reply-To: <49E9E25D.9070106@stats.uwo.ca>
References: <49E9DFE5.7060501@dbmail.com> <49E9E25D.9070106@stats.uwo.ca>
Message-ID: <49EA1C52.1090103@dbmail.com>

Duncan Murdoch wrote:
> On 18/04/2009 10:12 AM, Romain Francois wrote:
>> Hello,
>>
>> Could the code that auto prints a function/closure be extracted from 
>> print.c so that there would be a print.closure function.
>> I would like to be able to mask a print.closure function so that I 
>> have a custom auto-print. One reason for that is I plan to have 
>> syntax highlighting within the R console.
>
> The class of a closure is "function", so you'd want the method to be 
> print.function.  Currently that doesn't work for auto printing, so 
> your suggestion is still interesting.  (I'm not sure why auto printing 
> is special here...)
>
> Duncan Murdoch
Apparently, auto printing does not use the regular dispatch mechanism. 
See below:

I'll  make a more concrete proposal. This could be an opportunity to 
nail down as.character.function as well.

Romain

(from print.c)

 *  print.default()  ->     do_printdefault (with call tree below)
 *
 *  auto-printing   ->  PrintValueEnv
 *                      -> PrintValueRec
 *                      -> call print() for objects

and PrintValueRec switches on the typeof :

switch (TYPEOF(s)) {
...
    case CLOSXP:
    case LANGSXP:
    t = getAttrib(s, R_SourceSymbol);
    if (!isString(t) || !R_print.useSource)
        t = deparse1(s, 0, R_print.useSource | DEFAULTDEPARSE);
    for (i = 0; i < LENGTH(t); i++)
        Rprintf("%s\n", CHAR(STRING_ELT(t, i))); /* translated */
#ifdef BYTECODE
    if (TYPEOF(s) == CLOSXP && isByteCode(BODY(s)))
        Rprintf("<bytecode: %p>\n", BODY(s));
#endif
    if (TYPEOF(s) == CLOSXP) {
        t = CLOENV(s);
        if (t != R_GlobalEnv)
        Rprintf("%s\n", EncodeEnvironment(t));
    }
    break;





-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From romain.francois at dbmail.com  Sat Apr 18 22:37:05 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Sat, 18 Apr 2009 22:37:05 +0200
Subject: [Rd] print.closure at the R level
In-Reply-To: <49E9E25D.9070106@stats.uwo.ca>
References: <49E9DFE5.7060501@dbmail.com> <49E9E25D.9070106@stats.uwo.ca>
Message-ID: <49EA39F1.2010709@dbmail.com>

Duncan Murdoch wrote:
> On 18/04/2009 10:12 AM, Romain Francois wrote:
>> Hello,
>>
>> Could the code that auto prints a function/closure be extracted from 
>> print.c so that there would be a print.closure function.
>> I would like to be able to mask a print.closure function so that I 
>> have a custom auto-print. One reason for that is I plan to have 
>> syntax highlighting within the R console.
>
> The class of a closure is "function", so you'd want the method to be 
> print.function.  Currently that doesn't work for auto printing, so 
> your suggestion is still interesting.  (I'm not sure why auto printing 
> is special here...)
>
> Duncan Murdoch
The attached patch implements exposing the print.function at the R level.

Romain

-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


-------------- next part --------------
A non-text attachment was scrubbed...
Name: printfunction.diff
Type: text/x-patch
Size: 4085 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090418/78735b9a/attachment.bin>

From jmc at r-project.org  Sun Apr 19 00:09:21 2009
From: jmc at r-project.org (John Chambers)
Date: Sat, 18 Apr 2009 15:09:21 -0700
Subject: [Rd] bug in classesToAM()
In-Reply-To: <20090418005938.wqw7okho0skswcgs@webmail.fhcrc.org>
References: <20090418005938.wqw7okho0skswcgs@webmail.fhcrc.org>
Message-ID: <49EA4F91.4010906@r-project.org>

Yes, thanks.  Should be fixed now in r-devel and 2.9.0 patched.

John


hpages at fhcrc.org wrote:
> Hi,
>
> I can't get the non-abbreviated class names of the
> rows and the cols of the Adjacency Matrix:
>
> setClass("ClassWithALongName")
> setClass("SubclassOfClassWithALongName",
>          contains="ClassWithALongName")
>
> Trying all possible values for 'abbreviate' (with R-2.9.0):
>
>> classesToAM("SubclassOfClassWithALongName", abbreviate=0)
>      SubclassOfClassWithALongName ClassWithALongName
> SOCW                            0                  1
> CWAL                            0                  0
>
>> classesToAM("SubclassOfClassWithALongName", abbreviate=1)
>                              SOCW CWAL
> SubclassOfClassWithALongName    0    1
> ClassWithALongName              0    0
>
>> classesToAM("SubclassOfClassWithALongName", abbreviate=2)
>      SOCW CWAL
> SOCW    0    1
> CWAL    0    0
>
>> classesToAM("SubclassOfClassWithALongName", abbreviate=3)
>                              SOCW CWAL
> SubclassOfClassWithALongName    0    1
> ClassWithALongName              0    0
>
> This does not reflect what the man page is saying: "values
> 0, 1, 2, or 3 abbreviate neither, rows, columns or both".
>
> Cheers,
> H.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From whizvast at gmail.com  Sat Apr 18 10:12:50 2009
From: whizvast at gmail.com (whizvast)
Date: Sat, 18 Apr 2009 01:12:50 -0700 (PDT)
Subject: [Rd]  export C++ array to R
Message-ID: <23110405.post@talk.nabble.com>


Hi, I am a newbie on C++

Right now I have an array of doubles in C++.

Is there a way to "export" that array into R? Of course, I can allocate 
the memory block first using "allocVector" and copying the array contents 
one by one.

But, what if that array is fairly large? Copying doesn't look that
efficient.
I was thinking of setting the data pointer(DATAPTR) point to that array,
and adjust the LENGTH of SEXP. But I don't know how to do that.

Any comment/answer would be much appreciated. Thank you.
-- 
View this message in context: http://www.nabble.com/export-C%2B%2B-array-to-R-tp23110405p23110405.html
Sent from the R devel mailing list archive at Nabble.com.


From romain.francois at dbmail.com  Sun Apr 19 12:14:54 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Sun, 19 Apr 2009 12:14:54 +0200
Subject: [Rd] print.closure at the R level
In-Reply-To: <49EA39F1.2010709@dbmail.com>
References: <49E9DFE5.7060501@dbmail.com> <49E9E25D.9070106@stats.uwo.ca>
	<49EA39F1.2010709@dbmail.com>
Message-ID: <49EAF99E.9070703@dbmail.com>

Yesterday's patch did not print the attributes. This one seems fine:

 > f <- function(){}
 > attr( f, "yada" ) <- function( ) "lobster bisk"
 > f
function(){}
attr(,"yada")
function( ) "lobster bisk"

Romain

Romain Francois wrote:
> Duncan Murdoch wrote:
>> On 18/04/2009 10:12 AM, Romain Francois wrote:
>>> Hello,
>>>
>>> Could the code that auto prints a function/closure be extracted from 
>>> print.c so that there would be a print.closure function.
>>> I would like to be able to mask a print.closure function so that I 
>>> have a custom auto-print. One reason for that is I plan to have 
>>> syntax highlighting within the R console.
>>
>> The class of a closure is "function", so you'd want the method to be 
>> print.function.  Currently that doesn't work for auto printing, so 
>> your suggestion is still interesting.  (I'm not sure why auto 
>> printing is special here...)
>>
>> Duncan Murdoch
> The attached patch implements exposing the print.function at the R level.
>
> Romain
>
> ------------------------------------------------------------------------
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


-------------- next part --------------
A non-text attachment was scrubbed...
Name: printfunction.diff
Type: text/x-patch
Size: 4121 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090419/fd934ea0/attachment.bin>

From hkawakat at gmail.com  Sun Apr 19 13:40:56 2009
From: hkawakat at gmail.com (Hiroyuki Kawakatsu)
Date: Sun, 19 Apr 2009 12:40:56 +0100
Subject: [Rd] wish list: automatic package installation
Message-ID: <307b90470904190440q436f023dy8b63ca3bde6c0769@mail.gmail.com>

Hi,

Apologies for using this thread for something that is only
tangentially related.

Is there a mechanism in R to ensure that the configure.args used to
build R is also used when installing packages? If not, I would like to
add this as wish (perhaps we can grab this info from config.log?) At
the moment, I add the line

options(configure.args="...")

in my .Rprofile and install.packages() would use them. However, if I
change these when building R, I need to remember to change my
.Rprofile as well.

h.

On Sun, Apr 19, 2009, John Fox wrote:
>
> Dear list members,
>
> The release of R 2.9.0, reminds me of a long-standing nit that I have to
> pick. I prefer not to transfer and update all of the packages in my old
> library, because I see a new release of R as an opportunity to start with a
> clean slate. I'd rather install packages as I need them. My personal
> solution is to use the following function in place of library():
>
> package <- function(package, dependencies=TRUE, ...){
>     package <- as.character(substitute(package))
>     if (!(package %in% .packages(all.available=TRUE)))
>        install.packages(package, dependencies=dependencies)
>    library(package, character.only=TRUE, ...)
>    }
>
> I'm sure that this function could be improved, and possibly I've missed a
> facility that's already available. If not, it would be nice if the library()
> command automatically tried to download and install missing packages
> (perhaps if an option is set).
>
> Regards,
>  John
>
> ------------------------------
> John Fox, Professor
> Department of Sociology
> McMaster University
> Hamilton, Ontario, Canada
> web: socserv.mcmaster.ca/jfox

-- 
+---
| Hiroyuki Kawakatsu
| Business School, Dublin City University
| Dublin 9, Ireland. Tel +353 (0)1 700 7496


From simon.urbanek at r-project.org  Sun Apr 19 17:00:57 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sun, 19 Apr 2009 11:00:57 -0400
Subject: [Rd] export C++ array to R
In-Reply-To: <23110405.post@talk.nabble.com>
References: <23110405.post@talk.nabble.com>
Message-ID: <8E0F99E8-B8CB-4550-AA4A-035355A1DF86@r-project.org>


On Apr 18, 2009, at 4:12 AM, whizvast wrote:

>
> Hi, I am a newbie on C++
>
> Right now I have an array of doubles in C++.
>
> Is there a way to "export" that array into R? Of course, I can  
> allocate
> the memory block first using "allocVector" and copying the array  
> contents
> one by one.
>
> But, what if that array is fairly large? Copying doesn't look that
> efficient.
> I was thinking of setting the data pointer(DATAPTR) point to that  
> array,
> and adjust the LENGTH of SEXP. But I don't know how to do that.
>

The short answer is no, you can't, because the memory has to be  
allocated by R. If you are allocating the memory yourself, you can  
simply use allocVector instead of malloc/new to allocate the array in  
the first place - that saves you the copying and is the more usual  
approach for such R packages.

Cheers,
Simon


From brenbarn at brenbarn.net  Sun Apr 19 23:05:11 2009
From: brenbarn at brenbarn.net (brenbarn at brenbarn.net)
Date: Sun, 19 Apr 2009 23:05:11 +0200 (CEST)
Subject: [Rd] ave returns wrong data type (PR#13664)
Message-ID: <20090419210512.07F5A282C765@mail.pubhealth.ku.dk>

Full_Name: Brendan Barnwell
Version: 2.9.0
OS: Windows XP Pro
Submission from: (NULL) (71.102.131.29)


   The ave() function returns an incorrect datatype.  Specifically, ave(x, g, f)
always returns a vector with the same mode as x, rather than using the mode of
the vector returned by f.  Observe:

> x
 [1] "A" "B" "C" "A" "B" "C" "A" "B" "C" "A" "B" "C" "A" "B" "C" "A" "B" "C" "A"
"B" "C" "A" "B" "C" "A" "B" "C" "A" "B" "C"
> g
 [1] "X" "Y" "X" "Y" "X" "Y" "X" "Y" "X" "Y" "X" "Y" "X" "Y" "X" "Y" "X" "Y" "X"
"Y" "X" "Y" "X" "Y" "X" "Y" "X" "Y" "X" "Y"
> ave(x, g, FUN=length)
 [1] "15" "15" "15" "15" "15" "15" "15" "15" "15" "15" "15" "15" "15" "15" "15"
"15" "15" "15" "15" "15" "15" "15" "15" "15"
[25] "15" "15" "15" "15" "15" "15"

   Even though the length() function returns a vector of integers, ave()
inappropriately converts this to a character vector.  The bug is due to this
line in the definition of ave(): 

split(x, g) <- lapply(split(x, g), FUN)

   By sticking the result of the lapply back into the original argument x, it
coerces that result to the type of that argument.  This contradicts the
documentation, which says that the value of ave() is "a numeric vector".  I
would suggest that this documentation itself doesn't describe the desired
behavior.  The result vector should be of the type returned by FUN (just as it
is for tapply).  Otherwise it is impossible to use ave() to compute summary
statistics whose type differs from that of the argument.


From jeet at ku.edu  Mon Apr 20 07:10:09 2009
From: jeet at ku.edu (jeet at ku.edu)
Date: Mon, 20 Apr 2009 07:10:09 +0200 (CEST)
Subject: [Rd] R build fails during make when configured with "--with-x=no"
	(PR#13665)
Message-ID: <20090420051009.535E6282C76F@mail.pubhealth.ku.dk>

Full_Name: Jeet Sukumaran
Version: 2.9.0
OS: OS X / Rocks 5.1 
Submission from: (NULL) (66.45.136.241)


If R is configured using the "--with=x=no" option, then the make fails with the
following error:

make[4]: Entering directory
`/home/jeet/Scratch/r-build/on-frontend/R-2.9.0/src/modules/vfonts'
gcc -std=gnu99 -I. -I../../../src/include -I../../../src/include
-I/usr/local/include -DHAVE_CONFIG_H   -fpic  -g -O2 -c g_alab_her.c -o
g_alab_her.o
gcc -std=gnu99 -I. -I../../../src/include -I../../../src/include
-I/usr/local/include -DHAVE_CONFIG_H   -fpic  -g -O2 -c g_cntrlify.c -o
g_cntrlify.o
gcc -std=gnu99 -I. -I../../../src/include -I../../../src/include
-I/usr/local/include -DHAVE_CONFIG_H   -fpic  -g -O2 -c g_fontdb.c -o
g_fontdb.o
gcc -std=gnu99 -I. -I../../../src/include -I../../../src/include
-I/usr/local/include -DHAVE_CONFIG_H   -fpic  -g -O2 -c g_her_glyph.c -o
g_her_glyph.o
gcc -std=gnu99 -shared -L/usr/local/lib64 -o vfonts.so g_alab_her.o g_cntrlify.o
g_fontdb.o g_her_glyph.o  -lm 
make[5]: Entering directory
`/home/jeet/Scratch/r-build/on-frontend/R-2.9.0/src/modules/vfonts'
make[5]: Leaving directory
`/home/jeet/Scratch/r-build/on-frontend/R-2.9.0/src/modules/vfonts'
make[4]: Leaving directory
`/home/jeet/Scratch/r-build/on-frontend/R-2.9.0/src/modules/vfonts'
make[3]: Leaving directory
`/home/jeet/Scratch/r-build/on-frontend/R-2.9.0/src/modules/vfonts'
make[3]: Entering directory `/home/jeet'
make[3]: *** No rule to make target `R'.  Stop.
make[3]: Leaving directory `/home/jeet'
make[2]: *** [R] Error 1
make[2]: Leaving directory
`/home/jeet/Scratch/r-build/on-frontend/R-2.9.0/src/modules'
make[1]: *** [R] Error 1
make[1]: Leaving directory `/home/jeet/Scratch/r-build/on-frontend/R-2.9.0/src'
make: *** [R] Error 1

The problem appears to be with the "src/modules/Makefile". Specfically, lines
26-29:

	@for d in "$(R_MODULES)"; do \
	  (cd $${d} && $(MAKE) $@) || exit 1; \
	done

Here, R_MODULES is blank, resulting in the "cd" command transferring to the
user's home directory, where, of course, no Makefile is found resulting in the
error above.

Work-around appears to be to simply disable loop if R_MODULES is empty.


From d.rizopoulos at erasmusmc.nl  Mon Apr 20 11:53:09 2009
From: d.rizopoulos at erasmusmc.nl (Dimitris Rizopoulos)
Date: Mon, 20 Apr 2009 11:53:09 +0200
Subject: [Rd] ave returns wrong data type (PR#13664)
In-Reply-To: <20090419210512.07F5A282C765@mail.pubhealth.ku.dk>
References: <20090419210512.07F5A282C765@mail.pubhealth.ku.dk>
Message-ID: <49EC4605.40404@erasmusmc.nl>

Note that according to ?ave, the first argument of ave(), 'x' should be 
a *numeric* vector. In your case 'x' is not numeric, it is a character 
vector. So I think that ave() works as documented, i.e., if you supply 
as first argument a numeric vector, then you do get as an output a 
numeric vector.

Best,
Dimitris


brenbarn at brenbarn.net wrote:
> Full_Name: Brendan Barnwell
> Version: 2.9.0
> OS: Windows XP Pro
> Submission from: (NULL) (71.102.131.29)
> 
> 
>    The ave() function returns an incorrect datatype.  Specifically, ave(x, g, f)
> always returns a vector with the same mode as x, rather than using the mode of
> the vector returned by f.  Observe:
> 
>> x
>  [1] "A" "B" "C" "A" "B" "C" "A" "B" "C" "A" "B" "C" "A" "B" "C" "A" "B" "C" "A"
> "B" "C" "A" "B" "C" "A" "B" "C" "A" "B" "C"
>> g
>  [1] "X" "Y" "X" "Y" "X" "Y" "X" "Y" "X" "Y" "X" "Y" "X" "Y" "X" "Y" "X" "Y" "X"
> "Y" "X" "Y" "X" "Y" "X" "Y" "X" "Y" "X" "Y"
>> ave(x, g, FUN=length)
>  [1] "15" "15" "15" "15" "15" "15" "15" "15" "15" "15" "15" "15" "15" "15" "15"
> "15" "15" "15" "15" "15" "15" "15" "15" "15"
> [25] "15" "15" "15" "15" "15" "15"
> 
>    Even though the length() function returns a vector of integers, ave()
> inappropriately converts this to a character vector.  The bug is due to this
> line in the definition of ave(): 
> 
> split(x, g) <- lapply(split(x, g), FUN)
> 
>    By sticking the result of the lapply back into the original argument x, it
> coerces that result to the type of that argument.  This contradicts the
> documentation, which says that the value of ave() is "a numeric vector".  I
> would suggest that this documentation itself doesn't describe the desired
> behavior.  The result vector should be of the type returned by FUN (just as it
> is for tapply).  Otherwise it is impossible to use ave() to compute summary
> statistics whose type differs from that of the argument.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Dimitris Rizopoulos
Assistant Professor
Department of Biostatistics
Erasmus University Medical Center

Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
Tel: +31/(0)10/7043478
Fax: +31/(0)10/7043014


From P.Dalgaard at biostat.ku.dk  Mon Apr 20 12:58:34 2009
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 20 Apr 2009 12:58:34 +0200
Subject: [Rd] R build fails during make when configured with
 "--with-x=no" (PR#13665)
In-Reply-To: <20090420051009.535E6282C76F@mail.pubhealth.ku.dk>
References: <20090420051009.535E6282C76F@mail.pubhealth.ku.dk>
Message-ID: <49EC555A.60602@biostat.ku.dk>

jeet at ku.edu wrote:

> 
> If R is configured using the "--with=x=no" option, then the make fails with the
> following error:
,,,,
> make[1]: *** [R] Error 1
> make[1]: Leaving directory `/home/jeet/Scratch/r-build/on-frontend/R-2.9.0/src'
> make: *** [R] Error 1
> 
> The problem appears to be with the "src/modules/Makefile". Specfically, lines
> 26-29:
> 
> 	@for d in "$(R_MODULES)"; do \
> 	  (cd $${d} && $(MAKE) $@) || exit 1; \
> 	done
> 
> Here, R_MODULES is blank, resulting in the "cd" command transferring to the
> user's home directory, where, of course, no Makefile is found resulting in the
> error above.

(Even more "fun" would ensue if in fact there were a Makefile there...)


> Work-around appears to be to simply disable loop if R_MODULES is empty.

Shell script and Make portability is a pain in the derriere, but
offhand, those double quotes just look wrong:

viggo:~/>for i in "" ; do echo $i; done

viggo:~/>for i in  ; do echo $i; done
viggo:~/>for i in "foo bar" ; do echo $i; done
foo bar
viggo:~/>for i in foo bar ; do echo $i; done
foo
bar

Notice that the versions with quotes invariably do the Wrong Thing....


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From P.Dalgaard at biostat.ku.dk  Mon Apr 20 13:00:08 2009
From: P.Dalgaard at biostat.ku.dk (P.Dalgaard at biostat.ku.dk)
Date: Mon, 20 Apr 2009 13:00:08 +0200 (CEST)
Subject: [Rd] R build fails during make when configured with
	"--with-x=no" (PR#13666)
Message-ID: <20090420110008.4024A282BE82@mail.pubhealth.ku.dk>

jeet at ku.edu wrote:

>=20
> If R is configured using the "--with=3Dx=3Dno" option, then the make fa=
ils with the
> following error:
,,,,
> make[1]: *** [R] Error 1
> make[1]: Leaving directory `/home/jeet/Scratch/r-build/on-frontend/R-2.=
9.0/src'
> make: *** [R] Error 1
>=20
> The problem appears to be with the "src/modules/Makefile". Specfically,=
 lines
> 26-29:
>=20
> 	@for d in "$(R_MODULES)"; do \
> 	  (cd $${d} && $(MAKE) $@) || exit 1; \
> 	done
>=20
> Here, R_MODULES is blank, resulting in the "cd" command transferring to=
 the
> user's home directory, where, of course, no Makefile is found resulting=
 in the
> error above.

(Even more "fun" would ensue if in fact there were a Makefile there...)


> Work-around appears to be to simply disable loop if R_MODULES is empty.=


Shell script and Make portability is a pain in the derriere, but
offhand, those double quotes just look wrong:

viggo:~/>for i in "" ; do echo $i; done

viggo:~/>for i in  ; do echo $i; done
viggo:~/>for i in "foo bar" ; do echo $i; done
foo bar
viggo:~/>for i in foo bar ; do echo $i; done
foo
bar

Notice that the versions with quotes invariably do the Wrong Thing....


--=20
   O__  ---- Peter Dalgaard             =C3=98ster Farimagsgade 5, Entr.B=

  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From atossava at cc.helsinki.fi  Mon Apr 20 13:54:58 2009
From: atossava at cc.helsinki.fi (Atro Tossavainen)
Date: Mon, 20 Apr 2009 14:54:58 +0300 (EEST)
Subject: [Rd] Problems building R 2.9.0... on SGI and Sun once again
Message-ID: <200904201154.n3KBswHQ013943@ruuvi.it.helsinki.fi>

I've successfully built R 2.9.0 on Linux (amd64, i386 and ppc), but am
having a bit of trouble with legacy boxen.  What should have gone into
the variable that is empty at the time it is used in "for f in $SOMETHING"
and why does it end up being empty?

Solaris 8 with Sun Studio 11 compilers:

building package 'methods'
gmake[4]: Entering directory `/scratch/atossava/R-2.9.0/src/library/methods'
all.R is unchanged
/bin/bash: -c: line 1: syntax error near unexpected token `;'
/bin/bash: -c: line 1: `for f in ; do  if test -f ./${f}; then  ../../../tools/install-sh -c -m 644 ./${f}  ../../../library/methods;  fi;  done'
gmake[4]: *** [front] Error 2
gmake[4]: Leaving directory `/scratch/atossava/R-2.9.0/src/library/methods'

IRIX 6.5 with MIPSpro 7.4.4 compilers:

building package 'methods'
gmake[4]: Entering directory `/wrk/atossava/R-2.9.0/src/library/methods'
all.R is unchanged
/bin/sh: syntax error at line 1 : `;' unexpected
gmake[4]: *** [front] Error 2
gmake[4]: Leaving directory `/wrk/atossava/R-2.9.0/src/library/methods'

-- 
Atro Tossavainen (Mr.)               / The Institute of Biotechnology at
Systems Analyst, Techno-Amish &     / the University of Helsinki, Finland,
+358-9-19158939  UNIX Dinosaur     / employs me, but my opinions are my own.
< URL : http : / / www . helsinki . fi / %7E atossava / > NO FILE ATTACHMENTS


From mxkuhn at gmail.com  Mon Apr 20 19:25:46 2009
From: mxkuhn at gmail.com (Max Kuhn)
Date: Mon, 20 Apr 2009 13:25:46 -0400
Subject: [Rd] suggestion for R >= 3.0: computer-readable CHANGELOG
In-Reply-To: <49E8C5C4.6030304@sciviews.org>
References: <49E82D9C.9090402@sciviews.org> <49E85C0D.6040809@stats.uwo.ca>
	<49E87A59.2010003@life.ku.dk> <49E87E85.4050700@stats.uwo.ca>
	<18920.36404.547796.504974@ron.nulle.part>
	<49E893F1.9000007@stats.uwo.ca> <49E8C5C4.6030304@sciviews.org>
Message-ID: <6731304c0904201025m3e8a66a8ue9dddab6ba29253b@mail.gmail.com>

On Fri, Apr 17, 2009 at 2:09 PM, Philippe Grosjean
<phgrosjean at sciviews.org> wrote:
> OK, then, I catch the practical point of view that is: nobody will use it
> and we cannot force people to use it. So, it means that we should think
> about tools to *automatically* generate a limited set of entries in the
> CHANGELOG.

Of course this tells you what was changed but not why. I'd like to
know a more top-level "what" and, more importantly, "why".

It would also pick up code formatting changes.

> Something like new functions appearing in a package, functions being
> deprecated, change in the function's interface (arguments definition),
> change in the dependence of packages could be tracked automatically if the
> previous version of the package is available. This should be the case for
> packages on CRAN and Bioconductor, after first release. So, those
> "changelog" tools should be best deployed at this level.
>
> Further details could be provided directly inside the code, using simple
> formatting, and proposed as a purely optional feature. I think at something
> like:
>
> foo <- function (x, mynewarg) {
> ? ?#CHANGE# arg:mynewarg:A new argument in my function
> ? ?...
> }
>
> or
>
> bar <- function (y) {
> ? ?#CHANGE# fun:Short details about this new function
> }
>

My code is ugly enough without the extra help, and this would take
things to a new level of ugly.

Sorry to pick on this, but it is also optional and suffers from the
same issues as you mentioned above.

-- 

Max


From romain.francois at dbmail.com  Mon Apr 20 22:42:22 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Mon, 20 Apr 2009 22:42:22 +0200
Subject: [Rd] print.closure at the R level
In-Reply-To: <49EAF99E.9070703@dbmail.com>
References: <49E9DFE5.7060501@dbmail.com>
	<49E9E25D.9070106@stats.uwo.ca>	<49EA39F1.2010709@dbmail.com>
	<49EAF99E.9070703@dbmail.com>
Message-ID: <49ECDE2E.5060105@dbmail.com>


Hello,

Sorry if I have waisted any time of people truing this patch. There was 
an issue with debugging (use of debug and browser that caused an 
infinite recursion). I think this is now fixed.

At the R level, I have now this :

 > print.function
function (x, useSource = TRUE, ...)
{
    invisible(.Internal(print.function(x, useSource, ...)))
}
<environment: namespace:base>

and the PrintValueRec dispatches like this at the C level:

    case LANGSXP:
    PrintLanguage(s, FALSE) ;
    break;
    case CLOSXP:
    {
        SEXP call;
        PROTECT( call = lang2(install("print.function"), s));
        eval(call,env);
        UNPROTECT(1);
        break;
    }

so that LANGSXP are printed using the PrintLanguage function and CLOSXP 
are printed using the R function print.function which in turns calls the 
PrintClosure function (unless it is masked in R)

Romain


Romain Francois wrote:
> Yesterday's patch did not print the attributes. This one seems fine:
>
> > f <- function(){}
> > attr( f, "yada" ) <- function( ) "lobster bisk"
> > f
> function(){}
> attr(,"yada")
> function( ) "lobster bisk"
>
> Romain
>
> Romain Francois wrote:
>> Duncan Murdoch wrote:
>>> On 18/04/2009 10:12 AM, Romain Francois wrote:
>>>> Hello,
>>>>
>>>> Could the code that auto prints a function/closure be extracted 
>>>> from print.c so that there would be a print.closure function.
>>>> I would like to be able to mask a print.closure function so that I 
>>>> have a custom auto-print. One reason for that is I plan to have 
>>>> syntax highlighting within the R console.
>>>
>>> The class of a closure is "function", so you'd want the method to be 
>>> print.function.  Currently that doesn't work for auto printing, so 
>>> your suggestion is still interesting.  (I'm not sure why auto 
>>> printing is special here...)
>>>
>>> Duncan Murdoch
>> The attached patch implements exposing the print.function at the R 
>> level.
>>
>> Romain
>>
>> ------------------------------------------------------------------------
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
> ------------------------------------------------------------------------
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


-------------- next part --------------
A non-text attachment was scrubbed...
Name: printfunction.diff
Type: text/x-patch
Size: 7012 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090420/a22f3035/attachment.bin>

From hpages at fhcrc.org  Mon Apr 20 23:07:06 2009
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Mon, 20 Apr 2009 14:07:06 -0700
Subject: [Rd] bug in classesToAM()
In-Reply-To: <49EA4F91.4010906@r-project.org>
References: <20090418005938.wqw7okho0skswcgs@webmail.fhcrc.org>
	<49EA4F91.4010906@r-project.org>
Message-ID: <49ECE3FA.1040509@fhcrc.org>

Thanks!  H.

John Chambers wrote:
> Yes, thanks.  Should be fixed now in r-devel and 2.9.0 patched.
> 
> John
> 
> 
> hpages at fhcrc.org wrote:
>> Hi,
>>
>> I can't get the non-abbreviated class names of the
>> rows and the cols of the Adjacency Matrix:
>>
>> setClass("ClassWithALongName")
>> setClass("SubclassOfClassWithALongName",
>>          contains="ClassWithALongName")
>>
>> Trying all possible values for 'abbreviate' (with R-2.9.0):
>>
>>> classesToAM("SubclassOfClassWithALongName", abbreviate=0)
>>      SubclassOfClassWithALongName ClassWithALongName
>> SOCW                            0                  1
>> CWAL                            0                  0
>>
>>> classesToAM("SubclassOfClassWithALongName", abbreviate=1)
>>                              SOCW CWAL
>> SubclassOfClassWithALongName    0    1
>> ClassWithALongName              0    0
>>
>>> classesToAM("SubclassOfClassWithALongName", abbreviate=2)
>>      SOCW CWAL
>> SOCW    0    1
>> CWAL    0    0
>>
>>> classesToAM("SubclassOfClassWithALongName", abbreviate=3)
>>                              SOCW CWAL
>> SubclassOfClassWithALongName    0    1
>> ClassWithALongName              0    0
>>
>> This does not reflect what the man page is saying: "values
>> 0, 1, 2, or 3 abbreviate neither, rows, columns or both".
>>
>> Cheers,
>> H.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From maechler at stat.math.ethz.ch  Mon Apr 20 23:23:23 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 20 Apr 2009 23:23:23 +0200
Subject: [Rd] print.closure at the R level
In-Reply-To: <49ECDE2E.5060105@dbmail.com>
References: <49E9DFE5.7060501@dbmail.com> <49E9E25D.9070106@stats.uwo.ca>
	<49EA39F1.2010709@dbmail.com> <49EAF99E.9070703@dbmail.com>
	<49ECDE2E.5060105@dbmail.com>
Message-ID: <18924.59339.873021.630427@cmath-5.math.ethz.ch>

>>>>> "RF" == Romain Francois <romain.francois at dbmail.com>
>>>>>     on Mon, 20 Apr 2009 22:42:22 +0200 writes:

    RF> Hello,

    RF> Sorry if I have waisted any time of people truing this
    RF> patch. 

yes, you did waste (sic) ....
but thank you for the code suggestions anyway.

    RF> There was an issue with debugging (use of debug
    RF> and browser that caused an infinite recursion). I think
    RF> this is now fixed.

[ actually I had found even simpler bugs in it, e.g.
  you accidentally called C-level "print.function()" on "language",
  some may have been fixed by your new patch too, but others are  
  not {e.g., print() *must* return its argument !}
]

However, I've already changed your old patch too much
(notably by using *our* C coding standards) to want to look at
your new patch in detail.

If you want we can communicate off-list about this, 
tomorrow...

Martin Maechler, ETH Zurich


    RF> At the R level, I have now this :

    >> print.function
    RF> function (x, useSource = TRUE, ...)  {
    RF> invisible(.Internal(print.function(x, useSource, ...)))
    RF> } <environment: namespace:base>

    RF> and the PrintValueRec dispatches like this at the C
    RF> level:

    RF>     case LANGSXP: PrintLanguage(s, FALSE) ; break; case
    RF> CLOSXP: { SEXP call; PROTECT( call =
    RF> lang2(install("print.function"), s)); eval(call,env);
    RF> UNPROTECT(1); break; }

    RF> so that LANGSXP are printed using the PrintLanguage
    RF> function and CLOSXP are printed using the R function
    RF> print.function which in turns calls the PrintClosure
    RF> function (unless it is masked in R)

    RF> Romain


    RF> Romain Francois wrote:
    >> Yesterday's patch did not print the attributes. This one
    >> seems fine:
    >> 
    >> > f <- function(){} > attr( f, "yada" ) <- function( )
    >> "lobster bisk" > f function(){} attr(,"yada") function( )
    >> "lobster bisk"
    >> 
    >> Romain
    >> 
    >> Romain Francois wrote:
    >>> Duncan Murdoch wrote:
    >>>> On 18/04/2009 10:12 AM, Romain Francois wrote:
    >>>>> Hello,
    >>>>> 
    >>>>> Could the code that auto prints a function/closure be
    >>>>> extracted from print.c so that there would be a
    >>>>> print.closure function.  I would like to be able to
    >>>>> mask a print.closure function so that I have a custom
    >>>>> auto-print. One reason for that is I plan to have
    >>>>> syntax highlighting within the R console.
    >>>> 
    >>>> The class of a closure is "function", so you'd want the
    >>>> method to be print.function.  Currently that doesn't
    >>>> work for auto printing, so your suggestion is still
    >>>> interesting.  (I'm not sure why auto printing is
    >>>> special here...)
    >>>> 
    >>>> Duncan Murdoch
    >>> The attached patch implements exposing the
    >>> print.function at the R level.
    >>> 
    >>> Romain
    >>> 
    >>> ------------------------------------------------------------------------
    >>> 
    >>> ______________________________________________
    >>> R-devel at r-project.org mailing list
    >>> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> 
    >> 
    >> ------------------------------------------------------------------------
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel


    RF> -- Romain Francois Independent R Consultant +33(0) 6 28
    RF> 91 30 30 http://romainfrancois.blog.free.fr


From philip at sctkjeld.dk  Tue Apr 21 00:45:02 2009
From: philip at sctkjeld.dk (Philip)
Date: Tue, 21 Apr 2009 00:45:02 +0200
Subject: [Rd] Sharing variables in seperate workspace
Message-ID: <49ECFAEE.7020003@sctkjeld.dk>

Hi all.


I'm for the first time trying to make a library in R 2.8.1 on Ubuntu
Linux. The library is very simple, R functions just need to share a
variable (that is defined in the R code) and maybe functions and export
functions for the user to .GlobalEnv. This variable should only be
directly accessible from the global workspace (without change of
environment) via a hereto dedicated function. It only consists of R
code. I'm not sure if I should rather ask R-help. If so, just tell me.

The package source is available at
http://www.delff.dk/~philip/bdplot/
the check output at
http://www.delff.dk/~philip/bdplot.Rcheck/

The package code was checked and stopped because of lack of examples.
Until that, everything is OK.

> ### ** Examples
>
> ~~ simple examples of the most important functions ~~
Error: unexpected symbol in "~~ simple examples"
Execution halted

I would like to get the code issue solved before moving the
documentation from the R scripts and have proceeded the to building and
installation. These two last steps gave no warnings or errors.

My problem is that I cannot change the mentioned variable (from now on
called .FOO) that belongs to the namespace of the package. I think it is
because .FOO variable in some locked state, maybe by default created as
read-only. It is called .FOO because I use exportPattern("^[[:alpha:]]+")
as NAMESPACE file. I don't import anything.

I have a function (bar) that, like par does with .Pars from the graphics
namespace, modifies the contents of a list. This function has in the
bottom (when the function name is called without () from the R command
line) a line

<environment: namespace:"mypackage">

This is like par() has the graphics namespace mentioned, and therefore,
as I would expect. I can via this function read the contents of the
variable just by print(.FOO). This cannot be done from .GlobalEnv which
is as intended. The surprise is that I cannot write to it. If I do

.FOO$x <<- "value"
(names and values are arguments to the function, like with par().), I
get the error:

cannot change value of locked binding for '.FOO'

The double arrow, I use because <- does not affect the contents of .FOO
after the function has run. I don't know how I can use assign in this
case. I don't know a name for my package's environment. I have tried
with my package's name in both assign() and unlockBinding(), but my
package's name is not recognized as an environment (neither beginning
with a dot.). I also tryed unlockBinding() in the NAMESPACE file.

I don't know if this is normal, but I get
<environment: R_GlobalEnv>
from print(parent.frame()) and things like
<environment: 0x8df2ad0>
from print(environment())
This is surprising to me. I would expect
<environment: bdplot>
from environment().

How can I get to write to .FOO via bar()?


Thank you very much
Philip.


From christian.ledergerber at comerge.net  Tue Apr 21 10:45:08 2009
From: christian.ledergerber at comerge.net (Christian Ledergerber)
Date: Tue, 21 Apr 2009 10:45:08 +0200
Subject: [Rd] terminating R code evalutation asynchronously
Message-ID: <7eb27ab14716044158b2231c450729c6@comerge.net>

Hi, 

I am new to this mailing list. Hence brief a introduction: I am working for
Comerge, developing an online trading platform (interacting with brokers
over the internet in realtime) which is mostly written in Pascal. We are
using R-embedded to offer the user a way to implement strategies in R and
test them. 

Currently we are facing the following problem: We need to implement an
emergency exit procedure. The idea is that we send the process a signal
(like Crtl-C) and do all the necessary cleanup after the signal has been
caught. There are a number of constraints and wishes: 

1. The signal handler should take only very little time. E.g. set a number
of flags etc. and then return and leave the rest of the work to the main
program. 
2. The signal handler is asynchronous by nature. 
3. We would like that this works even if the user is hanging in an infinite
loop in the R code. E.g. we need to kill the current R code evaluation in
the signal handler. 
4. The main program needs to keep running to finish the cleanup. 

I found that the following function which seems to do the trick:
jump_to_toplevel() however, I am unsure whether this is safe - e.g. is this
function "thread safe" or do we risk that the application crashes when the
signal handler is invoked? Is there another, safer way to terminate the
current R execution? Furthermore this function seems to crash if the R
engine is not currently inside a R_tryEval call.

Thanks! 

Christian Ledergerber


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Tue Apr 21 12:23:20 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Tue, 21 Apr 2009 12:23:20 +0200
Subject: [Rd] sprintf limits output string length with no warning/error
	message
Message-ID: <49ED9E98.40405@idi.ntnu.no>

sprintf has a limit on the length of a string produced with a '%s'
specification:

   nchar(sprintf('%10000s', ''))
   # 8191

   nchar(sprintf('%*s', 10000, ''))
   # 8191

This is sort of documented in ?sprintf:

" There is a limit of 8192 bytes on elements of 'fmt' and also on
     strings included by a '%s' conversion specification."

but it should be a good idea for sprintf to at least warn when the
output is shorter than specified.

vQ


From waku at idi.ntnu.no  Tue Apr 21 13:05:11 2009
From: waku at idi.ntnu.no (waku at idi.ntnu.no)
Date: Tue, 21 Apr 2009 13:05:11 +0200 (CEST)
Subject: [Rd] incorrect output and segfaults from sprintf with %*d (PR#13667)
Message-ID: <20090421110511.469852832193@mail.pubhealth.ku.dk>

Full_Name: Wacek Kusnierczyk
Version: 2.10.0 r48365
OS: Ubuntu 8.04 Linux 32bit
Submission from: (NULL) (129.241.110.141)


sprintf has a documented limit on strings included in the output using the
format '%s'.  It appears that there is a limit on the length of strings included
with, e.g., the format '%d' beyond which surprising things happen (output
modified for conciseness):

   gregexpr('1', sprintf('%9000d', 1))
   # [1] 9000 9801

   gregexpr('1', sprintf('%9000d', 1))
   # [1]  9000  9801 10602

   gregexpr('1', sprintf('%9000d', 1))
   # [1]  9000  9801 10602 11403

   gregexpr('1', sprintf('%9000d', 1))
   # [1]  9000  9801 10602 11403 12204

   ...

Note that not only more than one '1' is included in the output, but also that
the same functional expression (no side effects used beyond the interface) gives
different results on each execution.  Analogous behaviour can be observed with
'%nd' where n > 8200.

The actual output above is consistent across separate sessions.

With sufficiently large field width values, R segfaults:

   sprintf('%*d', 10^5, 1)
   # *** caught segfault ***
   # address 0xbfcfc000, cause 'memory not mapped'
   # Segmentation fault


   sessionInfo()
   # R version 2.10.0 Under development (unstable) (2009-04-20 r48365) 
   # i686-pc-linux-gnu


From mtmorgan at fhcrc.org  Tue Apr 21 15:41:23 2009
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Tue, 21 Apr 2009 06:41:23 -0700
Subject: [Rd] Sharing variables in seperate workspace
In-Reply-To: <49ECFAEE.7020003@sctkjeld.dk> (philip@sctkjeld.dk's message of
	"Tue, 21 Apr 2009 00:45:02 +0200")
References: <49ECFAEE.7020003@sctkjeld.dk>
Message-ID: <6ph1vrmyvi4.fsf@gopher4.fhcrc.org>

Philip <philip at sctkjeld.dk> writes:

> Hi all.

Hi Philip -- I think this thread

  https://stat.ethz.ch/pipermail/r-devel/2009-March/052867.html

addresses your issue. Basically, create an environment or closure in
which you can modify variables.

HTH,

Martin

>
>
> I'm for the first time trying to make a library in R 2.8.1 on Ubuntu
> Linux. The library is very simple, R functions just need to share a
> variable (that is defined in the R code) and maybe functions and export
> functions for the user to .GlobalEnv. This variable should only be
> directly accessible from the global workspace (without change of
> environment) via a hereto dedicated function. It only consists of R
> code. I'm not sure if I should rather ask R-help. If so, just tell me.
>
> The package source is available at
> http://www.delff.dk/~philip/bdplot/
> the check output at
> http://www.delff.dk/~philip/bdplot.Rcheck/
>
> The package code was checked and stopped because of lack of examples.
> Until that, everything is OK.
>
>> ### ** Examples
>>
>> ~~ simple examples of the most important functions ~~
> Error: unexpected symbol in "~~ simple examples"
> Execution halted
>
> I would like to get the code issue solved before moving the
> documentation from the R scripts and have proceeded the to building and
> installation. These two last steps gave no warnings or errors.
>
> My problem is that I cannot change the mentioned variable (from now on
> called .FOO) that belongs to the namespace of the package. I think it is
> because .FOO variable in some locked state, maybe by default created as
> read-only. It is called .FOO because I use exportPattern("^[[:alpha:]]+")
> as NAMESPACE file. I don't import anything.
>
> I have a function (bar) that, like par does with .Pars from the graphics
> namespace, modifies the contents of a list. This function has in the
> bottom (when the function name is called without () from the R command
> line) a line
>
> <environment: namespace:"mypackage">
>
> This is like par() has the graphics namespace mentioned, and therefore,
> as I would expect. I can via this function read the contents of the
> variable just by print(.FOO). This cannot be done from .GlobalEnv which
> is as intended. The surprise is that I cannot write to it. If I do
>
> .FOO$x <<- "value"
> (names and values are arguments to the function, like with par().), I
> get the error:
>
> cannot change value of locked binding for '.FOO'
>
> The double arrow, I use because <- does not affect the contents of .FOO
> after the function has run. I don't know how I can use assign in this
> case. I don't know a name for my package's environment. I have tried
> with my package's name in both assign() and unlockBinding(), but my
> package's name is not recognized as an environment (neither beginning
> with a dot.). I also tryed unlockBinding() in the NAMESPACE file.
>
> I don't know if this is normal, but I get
> <environment: R_GlobalEnv>
> from print(parent.frame()) and things like
> <environment: 0x8df2ad0>
> from print(environment())
> This is surprising to me. I would expect
> <environment: bdplot>
> from environment().
>
> How can I get to write to .FOO via bar()?
>
>
> Thank you very much
> Philip.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Martin Morgan
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From maechler at stat.math.ethz.ch  Tue Apr 21 16:13:42 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 21 Apr 2009 16:13:42 +0200
Subject: [Rd] print.closure at the R level
In-Reply-To: <18924.59339.873021.630427@cmath-5.math.ethz.ch>
References: <49E9DFE5.7060501@dbmail.com> <49E9E25D.9070106@stats.uwo.ca>
	<49EA39F1.2010709@dbmail.com> <49EAF99E.9070703@dbmail.com>
	<49ECDE2E.5060105@dbmail.com>
	<18924.59339.873021.630427@cmath-5.math.ethz.ch>
Message-ID: <18925.54422.329318.557524@lynne.math.ethz.ch>

>>>>> "MM" == Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Mon, 20 Apr 2009 23:23:23 +0200 writes:

>>>>> "RF" == Romain Francois <romain.francois at dbmail.com>
>>>>>     on Mon, 20 Apr 2009 22:42:22 +0200 writes:

    RF> Hello,

    RF> Sorry if I have waisted any time of people truing this
    RF> patch.

    MM> yes, you did waste (sic) ....  but thank you for the
    MM> code suggestions anyway.

    RF> There was an issue with debugging (use of debug and
    RF> browser that caused an infinite recursion). I think this
    RF> is now fixed.

    MM> [ actually I had found even simpler bugs in it, e.g.
    MM> you accidentally called C-level "print.function()" on
    MM> "language", some may have been fixed by your new patch
    MM> too, but others are not {e.g., print() *must* return its
    MM> argument !}  ]

    MM> However, I've already changed your old patch too much
    MM> (notably by using *our* C coding standards) to want to
    MM> look at your new patch in detail.

    MM> If you want we can communicate off-list about this,
    MM> tomorrow...
{and we did}

It turns out to be considerably more tricky than I had
anticipated...

Note that we also really want auto-printing and print()ing to be
equivalent,
and that is not even the case for .Primitives in current R :

  > c
  function (..., recursive = FALSE)  .Primitive("c")
  > print(c)
  function (..., recursive = FALSE)  
  > 

{for "obvious" reasons, but needing even more work ...}

Also, Romain was "right" insofar as he would have wanted to only
deal with closure, whereas of course Duncan was right that the
corresponding class is 'function' and that comprises other types
(in the 'typeof' sense).

[story to be continued ...]

Martin Maechler, ETH Zurich


    RF> At the R level, I have now this :

    >>> print.function
    RF> function (x, useSource = TRUE, ...)  {
    RF> invisible(.Internal(print.function(x, useSource, ...)))
    RF> } <environment: namespace:base>

    RF> and the PrintValueRec dispatches like this at the C
    RF> level:

    RF> case LANGSXP: PrintLanguage(s, FALSE) ; break; case
    RF> CLOSXP: { SEXP call; PROTECT( call =
    RF> lang2(install("print.function"), s)); eval(call,env);
    RF> UNPROTECT(1); break; }

    RF> so that LANGSXP are printed using the PrintLanguage
    RF> function and CLOSXP are printed using the R function
    RF> print.function which in turns calls the PrintClosure
    RF> function (unless it is masked in R)

    RF> Romain


    RF> Romain Francois wrote:
    >>> Yesterday's patch did not print the attributes. This one
    >>> seems fine:
    >>> 
    >>> > f <- function(){} > attr( f, "yada" ) <- function( )
    >>> "lobster bisk" > f function(){} attr(,"yada") function(
    >>> ) "lobster bisk"
    >>> 
    >>> Romain
    >>> 
    >>> Romain Francois wrote:
    >>>> Duncan Murdoch wrote:
    >>>>> On 18/04/2009 10:12 AM, Romain Francois wrote:
    >>>>>> Hello,
    >>>>>> 
    >>>>>> Could the code that auto prints a function/closure be
    >>>>>> extracted from print.c so that there would be a
    >>>>>> print.closure function.  I would like to be able to
    >>>>>> mask a print.closure function so that I have a custom
    >>>>>> auto-print. One reason for that is I plan to have
    >>>>>> syntax highlighting within the R console.
    >>>>> 
    >>>>> The class of a closure is "function", so you'd want
    >>>>> the method to be print.function.  Currently that
    >>>>> doesn't work for auto printing, so your suggestion is
    >>>>> still interesting.  (I'm not sure why auto printing is
    >>>>> special here...)
    >>>>> 
    >>>>> Duncan Murdoch
    >>>> The attached patch implements exposing the
    >>>> print.function at the R level.
    >>>> 
    >>>> Romain
    >>>> 
    >>>> ------------------------------------------------------------------------
    >>>> 
    >>>> ______________________________________________
    >>>> R-devel at r-project.org mailing list
    >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
    >>> 
    >>> 
    >>> ------------------------------------------------------------------------
    >>> 
    >>> ______________________________________________
    >>> R-devel at r-project.org mailing list
    >>> https://stat.ethz.ch/mailman/listinfo/r-devel


    RF> -- Romain Francois Independent R Consultant +33(0) 6 28
    RF> 91 30 30 http://romainfrancois.blog.free.fr

    MM> ______________________________________________
    MM> R-devel at r-project.org mailing list
    MM> https://stat.ethz.ch/mailman/listinfo/r-devel


From philip at sctkjeld.dk  Tue Apr 21 23:47:50 2009
From: philip at sctkjeld.dk (Philip)
Date: Tue, 21 Apr 2009 23:47:50 +0200
Subject: [Rd] Sharing variables in seperate workspace
In-Reply-To: <6ph1vrmyvi4.fsf@gopher4.fhcrc.org>
References: <49ECFAEE.7020003@sctkjeld.dk> <6ph1vrmyvi4.fsf@gopher4.fhcrc.org>
Message-ID: <49EE3F06.2080208@sctkjeld.dk>

Hi Martin

Thank you very much. That solved my problem, and the package is now working!

Best regards. Philip.


Martin Morgan wrote:
> Philip <philip at sctkjeld.dk> writes:
> 
>> Hi all.
> 
> Hi Philip -- I think this thread
> 
>   https://stat.ethz.ch/pipermail/r-devel/2009-March/052867.html
> 
> addresses your issue. Basically, create an environment or closure in
> which you can modify variables.
> 
> HTH,
> 
> Martin
> 
>>
>> I'm for the first time trying to make a library in R 2.8.1 on Ubuntu
>> Linux. The library is very simple, R functions just need to share a
>> variable (that is defined in the R code) and maybe functions and export
>> functions for the user to .GlobalEnv. This variable should only be
>> directly accessible from the global workspace (without change of
>> environment) via a hereto dedicated function. It only consists of R
>> code. I'm not sure if I should rather ask R-help. If so, just tell me.
>>
>> The package source is available at
>> http://www.delff.dk/~philip/bdplot/
>> the check output at
>> http://www.delff.dk/~philip/bdplot.Rcheck/
>>
>> The package code was checked and stopped because of lack of examples.
>> Until that, everything is OK.
>>
>>> ### ** Examples
>>>
>>> ~~ simple examples of the most important functions ~~
>> Error: unexpected symbol in "~~ simple examples"
>> Execution halted
>>
>> I would like to get the code issue solved before moving the
>> documentation from the R scripts and have proceeded the to building and
>> installation. These two last steps gave no warnings or errors.
>>
>> My problem is that I cannot change the mentioned variable (from now on
>> called .FOO) that belongs to the namespace of the package. I think it is
>> because .FOO variable in some locked state, maybe by default created as
>> read-only. It is called .FOO because I use exportPattern("^[[:alpha:]]+")
>> as NAMESPACE file. I don't import anything.
>>
>> I have a function (bar) that, like par does with .Pars from the graphics
>> namespace, modifies the contents of a list. This function has in the
>> bottom (when the function name is called without () from the R command
>> line) a line
>>
>> <environment: namespace:"mypackage">
>>
>> This is like par() has the graphics namespace mentioned, and therefore,
>> as I would expect. I can via this function read the contents of the
>> variable just by print(.FOO). This cannot be done from .GlobalEnv which
>> is as intended. The surprise is that I cannot write to it. If I do
>>
>> .FOO$x <<- "value"
>> (names and values are arguments to the function, like with par().), I
>> get the error:
>>
>> cannot change value of locked binding for '.FOO'
>>
>> The double arrow, I use because <- does not affect the contents of .FOO
>> after the function has run. I don't know how I can use assign in this
>> case. I don't know a name for my package's environment. I have tried
>> with my package's name in both assign() and unlockBinding(), but my
>> package's name is not recognized as an environment (neither beginning
>> with a dot.). I also tryed unlockBinding() in the NAMESPACE file.
>>
>> I don't know if this is normal, but I get
>> <environment: R_GlobalEnv>
>> from print(parent.frame()) and things like
>> <environment: 0x8df2ad0>
>> from print(environment())
>> This is surprising to me. I would expect
>> <environment: bdplot>
>> from environment().
>>
>> How can I get to write to .FOO via bar()?
>>
>>
>> Thank you very much
>> Philip.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From catcode at catcode.com  Tue Apr 21 23:52:21 2009
From: catcode at catcode.com (jdeisenberg)
Date: Tue, 21 Apr 2009 14:52:21 -0700 (PDT)
Subject: [Rd]  Patch for tk/GUI
Message-ID: <23165645.post@talk.nabble.com>


On 15 Feb 2009, I uploaded a patch to tkGUI.r that allows Linux users to
load/save their workspace history from the GUI. There was no response, so I
presume I did not submit the code correctly. What is the correct mechanism
for submitting a patch/new feature to R?
-- 
View this message in context: http://www.nabble.com/Patch-for-tk-GUI-tp23165645p23165645.html
Sent from the R devel mailing list archive at Nabble.com.


From p.dalgaard at biostat.ku.dk  Wed Apr 22 01:06:29 2009
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 22 Apr 2009 01:06:29 +0200
Subject: [Rd] Patch for tk/GUI
In-Reply-To: <23165645.post@talk.nabble.com>
References: <23165645.post@talk.nabble.com>
Message-ID: <49EE5175.1000206@biostat.ku.dk>

jdeisenberg wrote:
> On 15 Feb 2009, I uploaded a patch to tkGUI.r that allows Linux users to
> load/save their workspace history from the GUI. There was no response, so I
> presume I did not submit the code correctly. What is the correct mechanism
> for submitting a patch/new feature to R?

Well, it's still in my r-devel folder labeled "important". It is just 
that important things get run over by important things with deadlines.

I'll get around to it eventually.

-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From kelley.dan at gmail.com  Wed Apr 22 01:59:26 2009
From: kelley.dan at gmail.com (Dan Kelley)
Date: Tue, 21 Apr 2009 16:59:26 -0700 (PDT)
Subject: [Rd]  R CMD check dislikes .git directories
Message-ID: <23166614.post@talk.nabble.com>


This may be new to 2.9.0, but I'm not sure, since I no longer have the older
version.

I notice that  R CMD check  has no problem with .svn directories, but it
dislikes .git directories.  That seems a bit of a problem, for folks like me
who sometimes use git. Perhaps this behaviour could be changed?

Dan.
-- 
View this message in context: http://www.nabble.com/R-CMD-check-dislikes-.git-directories-tp23166614p23166614.html
Sent from the R devel mailing list archive at Nabble.com.


From murdoch at stats.uwo.ca  Wed Apr 22 02:10:10 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 21 Apr 2009 20:10:10 -0400
Subject: [Rd] R CMD check dislikes .git directories
In-Reply-To: <23166614.post@talk.nabble.com>
References: <23166614.post@talk.nabble.com>
Message-ID: <49EE6062.3000609@stats.uwo.ca>

On 21/04/2009 7:59 PM, Dan Kelley wrote:
> This may be new to 2.9.0, but I'm not sure, since I no longer have the older
> version.
> 
> I notice that  R CMD check  has no problem with .svn directories, but it
> dislikes .git directories.  That seems a bit of a problem, for folks like me
> who sometimes use git. Perhaps this behaviour could be changed?

According to the R Extensions manual, it excludes dirs named CVS, .svn, 
.arch-ids, .bzr, and git.  Is .git the right thing to exclude instead of 
git, or are both possible?

The same section points out the workaround:  use the .Rbuildignore file 
to say what isn't really part of your package.

Duncan Murdoch


From murdoch at stats.uwo.ca  Wed Apr 22 02:24:15 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 21 Apr 2009 20:24:15 -0400
Subject: [Rd] R CMD check dislikes .git directories
In-Reply-To: <49EE6062.3000609@stats.uwo.ca>
References: <23166614.post@talk.nabble.com> <49EE6062.3000609@stats.uwo.ca>
Message-ID: <49EE63AF.9080508@stats.uwo.ca>

On 21/04/2009 8:10 PM, Duncan Murdoch wrote:
> On 21/04/2009 7:59 PM, Dan Kelley wrote:
>> This may be new to 2.9.0, but I'm not sure, since I no longer have the older
>> version.
>>
>> I notice that  R CMD check  has no problem with .svn directories, but it
>> dislikes .git directories.  That seems a bit of a problem, for folks like me
>> who sometimes use git. Perhaps this behaviour could be changed?
> 
> According to the R Extensions manual, it excludes dirs named CVS, .svn, 
> .arch-ids, .bzr, and git.  Is .git the right thing to exclude instead of 
> git, or are both possible?

Actually, that looks like a typo in the manual:  the code excludes .git, 
not git.  I'll fix the typo, but it means I don't know what error you're 
talking about.  Could you post instructions for reproducing?

Duncan Murdoch

> 
> The same section points out the workaround:  use the .Rbuildignore file 
> to say what isn't really part of your package.
> 
> Duncan Murdoch
> 
>


From kelley.dan at gmail.com  Wed Apr 22 02:37:47 2009
From: kelley.dan at gmail.com (Dan Kelley)
Date: Tue, 21 Apr 2009 21:37:47 -0300
Subject: [Rd] R CMD check dislikes .git directories
In-Reply-To: <49EE63AF.9080508@stats.uwo.ca>
References: <23166614.post@talk.nabble.com> <49EE6062.3000609@stats.uwo.ca>
	<49EE63AF.9080508@stats.uwo.ca>
Message-ID: <55B28828-D415-447D-B2D7-9566E5353900@gmail.com>

I think what I'm pasting below will illustrate.  (The git repo is  
behind a firewall, so I can't invite folks to download the repo to  
test locally.  I could tar up the source and put it on a website if  
that would help.)

* checking if this is a source package ... OK
* checking for executable files ... WARNING
Found the following executable file(s):
   .git/objects/01/9002df908b9c97f98e6ad3dd079bee436a2d66
   .git/objects/08/ac4fdd57a77afe2f8071c2e697cbda02b276b7
   .git/objects/13/49be3ed32dd801eacbdf1cc96a7577dcdfa2d7
   .git/objects/14/45d1188fcd949bd77d5c1117906c7987fe15a7
   .git/objects/18/756ad87b639ad2123a0ac78d04daa613d16966



On 2009-04-21, at 9:24 PM, Duncan Murdoch wrote:

> On 21/04/2009 8:10 PM, Duncan Murdoch wrote:
>> On 21/04/2009 7:59 PM, Dan Kelley wrote:
>>> This may be new to 2.9.0, but I'm not sure, since I no longer have  
>>> the older
>>> version.
>>>
>>> I notice that  R CMD check  has no problem with .svn directories,  
>>> but it
>>> dislikes .git directories.  That seems a bit of a problem, for  
>>> folks like me
>>> who sometimes use git. Perhaps this behaviour could be changed?
>> According to the R Extensions manual, it excludes dirs named  
>> CVS, .svn, .arch-ids, .bzr, and git.  Is .git the right thing to  
>> exclude instead of git, or are both possible?
>
> Actually, that looks like a typo in the manual:  the code  
> excludes .git, not git.  I'll fix the typo, but it means I don't  
> know what error you're talking about.  Could you post instructions  
> for reproducing?
>
> Duncan Murdoch
>
>> The same section points out the workaround:  use the .Rbuildignore  
>> file to say what isn't really part of your package.
>> Duncan Murdoch
>

Dan Kelley, PhD
Associate Professor and Graduate Coordinator
Dept. Oceanography, Dalhousie University, Halifax NS B3H 4J1
kelley.dan at gmail.com (1-minute path) or Dan.Kelley at Dal.Ca (2-hour path)
Phone 902 494 1694;  Fax  902 494 3877


From murdoch at stats.uwo.ca  Wed Apr 22 03:18:32 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 21 Apr 2009 21:18:32 -0400
Subject: [Rd] R CMD check dislikes .git directories
In-Reply-To: <55B28828-D415-447D-B2D7-9566E5353900@gmail.com>
References: <23166614.post@talk.nabble.com> <49EE6062.3000609@stats.uwo.ca>
	<49EE63AF.9080508@stats.uwo.ca>
	<55B28828-D415-447D-B2D7-9566E5353900@gmail.com>
Message-ID: <49EE7068.90007@stats.uwo.ca>

On 21/04/2009 8:37 PM, Dan Kelley wrote:
> I think what I'm pasting below will illustrate.  (The git repo is  
> behind a firewall, so I can't invite folks to download the repo to  
> test locally.  I could tar up the source and put it on a website if  
> that would help.)
> 
> * checking if this is a source package ... OK
> * checking for executable files ... WARNING
> Found the following executable file(s):
>    .git/objects/01/9002df908b9c97f98e6ad3dd079bee436a2d66
>    .git/objects/08/ac4fdd57a77afe2f8071c2e697cbda02b276b7
>    .git/objects/13/49be3ed32dd801eacbdf1cc96a7577dcdfa2d7
>    .git/objects/14/45d1188fcd949bd77d5c1117906c7987fe15a7
>    .git/objects/18/756ad87b639ad2123a0ac78d04daa613d16966

Okay, that helps.  I don't think the problem is git versus svn, it's 
that you've got executable files in a directory where check shouldn't be 
looking.  I don't think .Rbuildignore would help you.

I'll pass this on as a bug...

Duncan Murdoch

> 
> 
> 
> On 2009-04-21, at 9:24 PM, Duncan Murdoch wrote:
> 
>> On 21/04/2009 8:10 PM, Duncan Murdoch wrote:
>>> On 21/04/2009 7:59 PM, Dan Kelley wrote:
>>>> This may be new to 2.9.0, but I'm not sure, since I no longer have  
>>>> the older
>>>> version.
>>>>
>>>> I notice that  R CMD check  has no problem with .svn directories,  
>>>> but it
>>>> dislikes .git directories.  That seems a bit of a problem, for  
>>>> folks like me
>>>> who sometimes use git. Perhaps this behaviour could be changed?
>>> According to the R Extensions manual, it excludes dirs named  
>>> CVS, .svn, .arch-ids, .bzr, and git.  Is .git the right thing to  
>>> exclude instead of git, or are both possible?
>> Actually, that looks like a typo in the manual:  the code  
>> excludes .git, not git.  I'll fix the typo, but it means I don't  
>> know what error you're talking about.  Could you post instructions  
>> for reproducing?
>>
>> Duncan Murdoch
>>
>>> The same section points out the workaround:  use the .Rbuildignore  
>>> file to say what isn't really part of your package.
>>> Duncan Murdoch
> 
> Dan Kelley, PhD
> Associate Professor and Graduate Coordinator
> Dept. Oceanography, Dalhousie University, Halifax NS B3H 4J1
> kelley.dan at gmail.com (1-minute path) or Dan.Kelley at Dal.Ca (2-hour path)
> Phone 902 494 1694;  Fax  902 494 3877
> 
> 
> 
>


From h.wickham at gmail.com  Wed Apr 22 03:32:27 2009
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 21 Apr 2009 20:32:27 -0500
Subject: [Rd] R CMD check dislikes .git directories
In-Reply-To: <49EE7068.90007@stats.uwo.ca>
References: <23166614.post@talk.nabble.com> <49EE6062.3000609@stats.uwo.ca>
	<49EE63AF.9080508@stats.uwo.ca>
	<55B28828-D415-447D-B2D7-9566E5353900@gmail.com>
	<49EE7068.90007@stats.uwo.ca>
Message-ID: <f8e6ff050904211832q364dba59ufc05f93da7070275@mail.gmail.com>

> Okay, that helps. ?I don't think the problem is git versus svn, it's that
> you've got executable files in a directory where check shouldn't be looking.
> ?I don't think .Rbuildignore would help you.
>
> I'll pass this on as a bug...

I've complained about this in the past, and I was told that "good
practice" was to run R CMD check on the file created by R CMD build.

Hadley

-- 
http://had.co.nz/


From murdoch at stats.uwo.ca  Wed Apr 22 03:53:15 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 21 Apr 2009 21:53:15 -0400
Subject: [Rd] R CMD check dislikes .git directories
In-Reply-To: <f8e6ff050904211832q364dba59ufc05f93da7070275@mail.gmail.com>
References: <23166614.post@talk.nabble.com> <49EE6062.3000609@stats.uwo.ca>	
	<49EE63AF.9080508@stats.uwo.ca>	
	<55B28828-D415-447D-B2D7-9566E5353900@gmail.com>	
	<49EE7068.90007@stats.uwo.ca>
	<f8e6ff050904211832q364dba59ufc05f93da7070275@mail.gmail.com>
Message-ID: <49EE788B.7090704@stats.uwo.ca>

On 21/04/2009 9:32 PM, hadley wickham wrote:
>> Okay, that helps.  I don't think the problem is git versus svn, it's that
>> you've got executable files in a directory where check shouldn't be looking.
>>  I don't think .Rbuildignore would help you.
>>
>> I'll pass this on as a bug...
> 
> I've complained about this in the past, and I was told that "good
> practice" was to run R CMD check on the file created by R CMD build.

That's true, and it would solve the problem, which may be why it hasn't 
been a high enough priority to fix.  I won't fix it:  check is written 
in Perl, and I don't know Perl well enough to want to mess with it.  But 
maybe a second complaint about it will motivate someone who does know 
Perl to put together a fix.

Duncan Murdoch


From kw.statr at gmail.com  Wed Apr 22 04:16:59 2009
From: kw.statr at gmail.com (Kevin W)
Date: Tue, 21 Apr 2009 21:16:59 -0500
Subject: [Rd] RFC: Ability to suppress 'locale' from sessionInfo
Message-ID: <5c62e0070904211916w36310bfdsd720fae189cad25b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090421/455092ee/attachment.pl>

From mdowle at mdowle.plus.com  Wed Apr 22 01:38:06 2009
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Wed, 22 Apr 2009 00:38:06 +0100
Subject: [Rd] Closed-source non-free ParallelR ?
Message-ID: <373DCC90906D430E952EF2C423B0D91B@ADAM>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090422/3778b8d7/attachment.pl>

From michael.m.spiegel at gmail.com  Tue Apr 21 20:35:14 2009
From: michael.m.spiegel at gmail.com (michael.m.spiegel at gmail.com)
Date: Tue, 21 Apr 2009 20:35:14 +0200 (CEST)
Subject: [Rd] build-aux missing in 2.9.0 packages (PR#13668)
Message-ID: <20090421183514.BF0A328321AF@mail.pubhealth.ku.dk>

Full_Name: Michael Spiegel
Version: 2.9.0
OS: linux
Submission from: (NULL) (128.143.137.189)


I think something was changed in the handling of the build-aux directory when
installing R packages.  The directory is no longer copied into the installation
directory.  I believe it was not on the list "approved" directories that are
copied into the install directory, so perhaps the better location for build-aux
is actually in inst/build-aux.  However, when I try that then inst/build-aux is
NOT copied into the installation directory.  If I try renaming inst/build-aux to
any other name (inst/config-aux), then the directory is copied over.  It appears
as if build-aux is not special enough to be copied over to the installation
directory, but too special for it to live in the /inst directory.  A consistent
strategy is preferable.


From friedrich.leisch at stat.uni-muenchen.de  Wed Apr 22 09:26:37 2009
From: friedrich.leisch at stat.uni-muenchen.de (Friedrich Leisch)
Date: Wed, 22 Apr 2009 09:26:37 +0200
Subject: [Rd] RFC: Ability to suppress 'locale' from sessionInfo
In-Reply-To: <5c62e0070904211916w36310bfdsd720fae189cad25b@mail.gmail.com>
References: <5c62e0070904211916w36310bfdsd720fae189cad25b@mail.gmail.com>
Message-ID: <18926.50861.369595.3396@lxh5.stat.uni-muenchen.de>

>>>>> On Tue, 21 Apr 2009 21:16:59 -0500,
>>>>> Kevin W (KW) wrote:

  > The printing of the locale information from sessionInfo is not very tidy.
  > Using toLatex(sessionInfo) pretty much guarantees "badness" from breaking
  > the margin boundary (though my version of TeX no longer reports such
  > errors).  A random example is here:
  > http://cran.r-project.org/web/packages/Matrix/vignettes/Design-issues.pdf

  > I find the locale information unnecessary and right now I hack this with
  > si = sessionInfo()
  > si$locale = "US"
  > toLatex(si)

  > I would like to be able to do something a bit cleaner, for example
  > sessionInfo(locale=FALSE)

  > For what it's worth, I don't think that early versions of sessionInfo
  > printed information about the locale.

It went in on 2006-05-26, so it's bben there for some time now.
  

  > Discussion welcome.

I agree that it doesn't look nice in latex documents, but it is very
handy in bug reports.

Are there any objections if we add a locale argument to the toLatex()
method and let that default to FALSE?

Best,
Fritz


From tobias.verbeke at telenet.be  Wed Apr 22 09:57:30 2009
From: tobias.verbeke at telenet.be (Tobias Verbeke)
Date: Wed, 22 Apr 2009 09:57:30 +0200
Subject: [Rd] RFC: Ability to suppress 'locale' from sessionInfo
In-Reply-To: <18926.50861.369595.3396@lxh5.stat.uni-muenchen.de>
References: <5c62e0070904211916w36310bfdsd720fae189cad25b@mail.gmail.com>
	<18926.50861.369595.3396@lxh5.stat.uni-muenchen.de>
Message-ID: <49EECDEA.9020800@telenet.be>

Friedrich Leisch wrote:
>>>>>> On Tue, 21 Apr 2009 21:16:59 -0500,
>>>>>> Kevin W (KW) wrote:
> 
>   > The printing of the locale information from sessionInfo is not very tidy.
>   > Using toLatex(sessionInfo) pretty much guarantees "badness" from breaking
>   > the margin boundary (though my version of TeX no longer reports such
>   > errors).  A random example is here:
>   > http://cran.r-project.org/web/packages/Matrix/vignettes/Design-issues.pdf
> 
>   > I find the locale information unnecessary and right now I hack this with
>   > si = sessionInfo()
>   > si$locale = "US"
>   > toLatex(si)
> 
>   > I would like to be able to do something a bit cleaner, for example
>   > sessionInfo(locale=FALSE)
> 
>   > For what it's worth, I don't think that early versions of sessionInfo
>   > printed information about the locale.
> 
> It went in on 2006-05-26, so it's bben there for some time now.
>   
> 
>   > Discussion welcome.
> 
> I agree that it doesn't look nice in latex documents, but it is very
> handy in bug reports.
> 
> Are there any objections if we add a locale argument to the toLatex()
> method and let that default to FALSE?

No objection although I would not be against letting it default to TRUE
to preserve current behaviour.

One improvement in the locale information that would make the LaTeX look 
much nicer would be to add a space after the separator, i.e.

item1; item2; item3

instead of

item1;item2;item3

That is for me more important than having the option to include locale 
info or not as without such a change I found no way to prevent the 
locale information to run into the margin (and off the page) of the 
resulting LaTeX document and that is esthetically much more displeasing
than the mere presence of the locale information.

Best,
Tobias


From maechler at stat.math.ethz.ch  Wed Apr 22 10:50:12 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 22 Apr 2009 10:50:12 +0200
Subject: [Rd] RFC: Ability to suppress 'locale' from sessionInfo
In-Reply-To: <49EECDEA.9020800@telenet.be>
References: <5c62e0070904211916w36310bfdsd720fae189cad25b@mail.gmail.com>
	<18926.50861.369595.3396@lxh5.stat.uni-muenchen.de>
	<49EECDEA.9020800@telenet.be>
Message-ID: <18926.55876.329732.6352@lynne.math.ethz.ch>

>>>>> "TobiasV" == Tobias Verbeke <tobias.verbeke at telenet.be>
>>>>>     on Wed, 22 Apr 2009 09:57:30 +0200 writes:

    TobiasV> Friedrich Leisch wrote:
    >>>>>>> On Tue, 21 Apr 2009 21:16:59 -0500,
    >>>>>>> Kevin W (KW) wrote:
    >> 
    >> > The printing of the locale information from sessionInfo is not very tidy.
    >> > Using toLatex(sessionInfo) pretty much guarantees "badness" from breaking
    >> > the margin boundary (though my version of TeX no longer reports such
    >> > errors).  A random example is here:
    >> > http://cran.r-project.org/web/packages/Matrix/vignettes/Design-issues.pdf
    >> 
    >> > I find the locale information unnecessary and right now I hack this with
    >> > si = sessionInfo()
    >> > si$locale = "US"
    >> > toLatex(si)
    >> 
    >> > I would like to be able to do something a bit cleaner, for example
    >> > sessionInfo(locale=FALSE)
    >> 
    >> > For what it's worth, I don't think that early versions of sessionInfo
    >> > printed information about the locale.
    >> 
    >> It went in on 2006-05-26, so it's bben there for some time now.
    >> 
    >> 
    >> > Discussion welcome.
    >> 
    >> I agree that it doesn't look nice in latex documents, but it is very
    >> handy in bug reports.
    >> 
    >> Are there any objections if we add a locale argument to the toLatex()
    >> method and let that default to FALSE?

    TobiasV> No objection although I would not be against
    TobiasV> letting it default to TRUE to preserve current behaviour.

I agree with setting the default to keep the current behavior.
As Fritz mentioned, there situations where the locale
(information) is of quite some importance.  As we know that
Sweave is used in quite a few circumstances with automatic
report generation, of which in *some* cases the locale may also
matter (and is desired to be visible),

I think we should not change the default behavior lightly
(apart from the extra spaces, see below).

    TobiasV> One improvement in the locale information that would make the LaTeX look 
    TobiasV> much nicer would be to add a space after the separator, i.e.

    TobiasV> item1; item2; item3

    TobiasV> instead of

    TobiasV> item1;item2;item3

    TobiasV> That is for me more important than having the
    TobiasV> option to include locale info or not 

I agree very much; and indeed, adding the space after ";" is
trivial to achieve in the next version of  toLatex()'s
"sessionInfo" method, as well.

Martin

    TobiasV> as without such a change I found no way to prevent the locale
    TobiasV> information to run into the margin (and off the
    TobiasV> page) of the resulting LaTeX document and that is
    TobiasV> esthetically much more displeasing than the mere
    TobiasV> presence of the locale information.

    TobiasV> Best,
    TobiasV> Tobias


From Dieter.Kadelka at stoch.uni-karlsruhe.de  Wed Apr 22 10:45:13 2009
From: Dieter.Kadelka at stoch.uni-karlsruhe.de (Dieter.Kadelka at stoch.uni-karlsruhe.de)
Date: Wed, 22 Apr 2009 10:45:13 +0200 (CEST)
Subject: [Rd] Installation fails (PR#13669)
Message-ID: <20090422084513.B865828321B8@mail.pubhealth.ku.dk>

Full_Name: Dieter Kadelka
Version: 2.9.0
OS: Linux
Submission from: (NULL) (129.13.115.98)


Hallo,
my system is

  Linux mspcka3 2.6.5-7.276-default #1 Mon Jul 24 10:45:31 UTC 2006 i686
GNU/Linux
  with gcc-4.3.3

Installation of R-2.9.0 fails, R-2.8.1 is o.k.

After
  configure
  make

I get
...
WARNING: ignoring environment value of R_HOME
 >>> Building/Updating help pages for package 'tcltk'
     Formats: text html latex example
  TclInterface                      text    html    latex   example
  TkCommands                        text    html    latex   example
  TkWidgetcmds                      text    html    latex   example
  TkWidgets                         text    html    latex   example
  tclServiceMode                    text    html    latex   example
  tcltk-defunct                     text    html    latex
  tcltk-package                     text    html    latex
  tkProgressBar                     text    html    latex   example
  tkStartGUI                        text    html    latex
  tk_choose.dir                     text    html    latex   example
  tk_choose.files                   text    html    latex   example
  tk_messageBox                     text    html    latex
  tk_select.list                    text    html    latex
  tkpager                           text    html    latex
make[2]: Leaving directory `/install/R/R-2.9.0/src/library'
make[1]: Leaving directory `/install/R/R-2.9.0/src/library'
make[1]: Entering directory `/install/R/R-2.9.0/src/library/Recommended'
make[2]: Entering directory `/install/R/R-2.9.0/src/library/Recommended'
begin installing recommended package VR
WARNING: ignoring environment value of R_HOME
sh: Zeile 2: `python2.4': Ist kein g?ltiger Bezeichner.
make[2]: *** [VR.ts] Fehler 1
make[2]: Leaving directory `/install/R/R-2.9.0/src/library/Recommended'
make[1]: *** [recommended-packages] Fehler 2
make[1]: Leaving directory `/install/R/R-2.9.0/src/library/Recommended'
make: *** [stamp-recommended] Fehler 2

Invoking in bin
  ./R CMD config
I get (depending on the environment) either a segfault or

WARNING: ignoring environment value of R_HOME
sh: Zeile 2: `python2.4': Ist kein g?ltiger Bezeichner.

I tried the last R-patch, no difference.

I don't whether this problem is specific to my system or a general problem.

Thanks
Dieter Kadelka


From P.Dalgaard at biostat.ku.dk  Wed Apr 22 12:00:42 2009
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 22 Apr 2009 12:00:42 +0200
Subject: [Rd] Installation fails (PR#13669)
In-Reply-To: <20090422084513.B865828321B8@mail.pubhealth.ku.dk>
References: <20090422084513.B865828321B8@mail.pubhealth.ku.dk>
Message-ID: <49EEEACA.60709@biostat.ku.dk>

Dieter.Kadelka at stoch.uni-karlsruhe.de wrote:

> Hallo,
> my system is
> 
>   Linux mspcka3 2.6.5-7.276-default #1 Mon Jul 24 10:45:31 UTC 2006 i686
> GNU/Linux
>   with gcc-4.3.3

Which distribution? (A 2.5 year old kernel suggests Debian, but...)

> Installation of R-2.9.0 fails, R-2.8.1 is o.k.
> begin installing recommended package VR
> WARNING: ignoring environment value of R_HOME
> sh: Zeile 2: `python2.4': Ist kein g?ltiger Bezeichner.

Why is R_HOME set in your environment, and how did python get into this?
You could check your set of environment variables ("env" command) for
anything python-related.

....

> 
> Invoking in bin
>   ./R CMD config
> I get (depending on the environment) either a segfault or
> 
> WARNING: ignoring environment value of R_HOME
> sh: Zeile 2: `python2.4': Ist kein g?ltiger Bezeichner.
> 
> I tried the last R-patch, no difference.
> 
> I don't whether this problem is specific to my system or a general problem.

Probably mainly local to your system, but could be something fixable in
R if we forgot to control the PATH settings or suchlike.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From S.J.Eglen at damtp.cam.ac.uk  Wed Apr 22 12:13:46 2009
From: S.J.Eglen at damtp.cam.ac.uk (Stephen Eglen)
Date: Wed, 22 Apr 2009 11:13:46 +0100
Subject: [Rd] Clarification for options(OutDec)
Message-ID: <4345.1240395226@cpc5-cmbg2-0-0-cust788.cmbg.cable.ntl.com>


The documentation for the OutDec option says that it should be a
'one-character string'; yet, if I try a unicode character, it doesn't seem
to work.  Are unicode chars not counted as one-character?

This is within the mac GUI, but I also see this on linux boxes.

> x <- '\u00B7'
> nchar(x)
[1] 1
> options(OutDec=x)
Error in options(OutDec = x) : invalid value for 'OutDec'

I don't think I've changed anything with my LANG settings, but here it
is anyway:

> Sys.getenv('LANG')
         LANG 
"en_GB.UTF-8" 

> version
               _                           
platform       i386-apple-darwin8.11.1     
arch           i386                        
os             darwin8.11.1                
system         i386, darwin8.11.1          
status                                     
major          2                           
minor          9.0                         
year           2009                        
month          04                          
day            17                          
svn rev        48333                       
language       R                           
version.string R version 2.9.0 (2009-04-17)


Stephen


From ripley at stats.ox.ac.uk  Wed Apr 22 12:33:12 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 22 Apr 2009 11:33:12 +0100 (BST)
Subject: [Rd] Clarification for options(OutDec)
In-Reply-To: <4345.1240395226@cpc5-cmbg2-0-0-cust788.cmbg.cable.ntl.com>
References: <4345.1240395226@cpc5-cmbg2-0-0-cust788.cmbg.cable.ntl.com>
Message-ID: <alpine.LFD.2.00.0904221132050.13134@gannet.stats.ox.ac.uk>

On Wed, 22 Apr 2009, Stephen Eglen wrote:

>
> The documentation for the OutDec option says that it should be a
> 'one-character string'; yet, if I try a unicode character, it doesn't seem
> to work.  Are unicode chars not counted as one-character?

Correct, it has to be a single byte (and the comment dates from 
before UTF-8 was suported).

>
> This is within the mac GUI, but I also see this on linux boxes.
>
>> x <- '\u00B7'
>> nchar(x)
> [1] 1
>> options(OutDec=x)
> Error in options(OutDec = x) : invalid value for 'OutDec'
>
> I don't think I've changed anything with my LANG settings, but here it
> is anyway:
>
>> Sys.getenv('LANG')
>         LANG
> "en_GB.UTF-8"
>
>> version
>               _
> platform       i386-apple-darwin8.11.1
> arch           i386
> os             darwin8.11.1
> system         i386, darwin8.11.1
> status
> major          2
> minor          9.0
> year           2009
> month          04
> day            17
> svn rev        48333
> language       R
> version.string R version 2.9.0 (2009-04-17)
>
>
> Stephen
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From shashikiran_ganesh at yahoo.co.in  Wed Apr 22 13:46:09 2009
From: shashikiran_ganesh at yahoo.co.in (Shashikiran Ganesh)
Date: Wed, 22 Apr 2009 17:16:09 +0530 (IST)
Subject: [Rd] reversing xlim, ylim in smoothScatter
Message-ID: <920402.63507.qm@web8401.mail.in.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090422/8c8b42d4/attachment.pl>

From marc_schwartz at me.com  Wed Apr 22 15:56:07 2009
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 22 Apr 2009 08:56:07 -0500
Subject: [Rd] [R] bug when subtracting decimals?
In-Reply-To: <18926.59431.739900.802941@lynne.math.ethz.ch>
References: <23136337.post@talk.nabble.com>
	<loom.20090420T165938-432@post.gmane.org>
	<OF9FC8FB5B.3DA92632-ONC125759F.002A75C1-C125759F.002AE5D0@precheza.cz>
	<49EDA61F.9080409@stats.uwo.ca>
	<FCBFC9DA-9242-48F0-B6E4-204A386BCC8B@me.com>
	<18926.59431.739900.802941@lynne.math.ethz.ch>
Message-ID: <F50C0415-3AF0-4935-BA56-44F00D9204F5@me.com>

On Apr 22, 2009, at 4:49 AM, Martin Maechler wrote:

>>>>>> "MS" == Marc Schwartz <marc_schwartz at me.com>
>>>>>>    on Tue, 21 Apr 2009 08:06:46 -0500 writes:
>
>
>    MS> It does look like R's behavior has changed since then. Using:
>
>    MS> R version 2.9.0 Patched (2009-04-18 r48348)
>
>    MS> on OSX:
>
>    MS> # This first example has changed.
>    MS> # Prior result was 414.99999999999994
>>> print(4.145 * 100 + 0.5, digits = 20)
>    MS> [1] 415
>
>>> formatC(4.145 * 100 + 0.5, format = "E", digits = 20)
>    MS> [1] "4.14999999999999943157E+02"
>
>>> print(0.5 - 0.4 - 0.1, digits = 20)
>    MS> [1] -2.77555756156289e-17
>
>>> formatC(0.5 - 0.4 - 0.1, format = "E", digits = 20)
>    MS> [1] "-2.77555756156289135106E-17"
>
>
>    MS> What is interesting is that:
>
>>> 4.145 * 100 + 0.5 == 415
>    MS> [1] FALSE
>
>>> (4.145 * 100 + 0.5) - 415
>    MS> [1] -5.684342e-14
>
>>> all.equal(4.145 * 100 + 0.5, 415, 0)
>    MS> [1] "Mean relative difference: 1.369721e-16"
>
>
>    MS> So it would appear that in the first R example above, the  
> print()
>    MS> function has changed in a material fashion.
>
> Yes  ((though not with *my* vote...)).
> However, be aware that such calculations *are* platform
> dependent, and IIUC, you are now using OS X wheras you've used
> another platform previously, so some of the differences you see
> may not be from changes in R, but from changes in the platform
> you use.

> Back to the topic of print():
> Actually, also  format(<numeric>)  has changed similarly to my  
> chagrin.
> In older versions of R, you could ask it to give "too many" digits,
> but now it gives "too few" even for maximal 'digits'.
> {There is a good reason - which I don't recall - for the new behavior}
>
> With as.character() it was worse (in older R versions): it gave
> sometimes too little digits, sometimes too many, whereas now it
> is at least consistently giving "too little".
> But the effect is that in  ch <- as.character(x) ,
> ch may contain duplicated entries even for unique x,
> e.g., for x <- c(1, 1 + 4e-16)
>
> BTW, one alternative to {"my"}  formatC() is  sprintf(),
> and if you are really interested: The latest changes (in 2.10.0 R- 
> devel),
> ensuring unique factor levels actually now make use of
> 	 sprintf("%.17g", .)
> instead of as.character(.) exactly in order to ensure that
> different numbers map to different strings necessarily.
>
> BTW, we are way off topic for R-help, being in R-devel realm,
> but as this thread has started here, we may keep it...
>
> Martin Maechler, ETH Zurich
>


Thanks for replying Martin.

While I appreciate your comment above, I am moving to r-devel given  
the content. I agree that we are getting into low level subject matter.

FWIW, I grabbed my dusty old Dell laptop running Fedora 10 out of the  
closet and booted it up.

I get the same behavior as above there with R 2.8.1 patched.

So this would suggest that it it not an OS issue, but indeed a change  
in R.

I did try to build R 1.7.1 (the version used in the prior examples  
almost 6 years ago) on OSX, but it would appear that things have  
changed sufficiently in the intervening time frame as to preclude a  
successful build. I suspect much of the issue may be that Apple moved  
to Intel CPU's only about 4 years ago, so perhaps the configuration of  
older versions of R on OSX for Intel would require much work which is  
not worth it here. I would of course defer to others with more in- 
depth knowledge on that point.

I did not see anything in any of the *NEWS files, but the help for  
print() does reference:

Warning
Using too large a value of digits may lead to representation errors in  
the calculation of the number of significant digits and the decimal  
representation: these are likely for digits >= 16, and these possible  
errors are taken into account in assessing the numher of significant  
digits to be printed in that case.

Whereas earlier versions of R might have printed further digits for  
digits >= 16 on some platforms, they were not necessarily reliable.



While I don't want to re-visit what from your comments appears to be a  
sensitive subject, I do want to point out that this new behavior  
arguably masks aspects of the original subject matter of the thread  
from users. It also results in inconsistent behavior when compared to  
the output of the other floating point comparisons I used, which  
suggest that the result of the operation is not an integer, which will  
serve to further confuse folks.

Is there some reasonable compromise to be had here such that  
consistent and predictable behavior is possible in this realm,  
especially given how frequently this fundamental subject comes up?

We of course don't need examples as complicated as the one above and  
can use the more common:

 > print(0.5 - 0.4, 20)

[1] 0.1



 > 0.5 - 0.4 == 0.1

[1] FALSE





 > all.equal(0.5 - 0.4, 0.1, 0)

[1] "Mean relative difference: 2.775558e-16"



So arguably, we are talking about boundary situations here.

Thanks Martin!


Marc


From maechler at stat.math.ethz.ch  Wed Apr 22 16:10:25 2009
From: maechler at stat.math.ethz.ch (maechler at stat.math.ethz.ch)
Date: Wed, 22 Apr 2009 16:10:25 +0200 (CEST)
Subject: [Rd] incorrect output and segfaults from sprintf with %*d
	(PR#13667)
Message-ID: <20090422141025.2B02528321B3@mail.pubhealth.ku.dk>

>>>>> "vQ" == Wacek Kusnierczyk <waku at idi.ntnu.no>
>>>>>     on Tue, 21 Apr 2009 13:05:11 +0200 (CEST) writes:

    vQ> Full_Name: Wacek Kusnierczyk
    vQ> Version: 2.10.0 r48365
    vQ> OS: Ubuntu 8.04 Linux 32bit
    vQ> Submission from: (NULL) (129.241.110.141)


    vQ> sprintf has a documented limit on strings included in the output using the
    vQ> format '%s'.  It appears that there is a limit on the length of strings included
    vQ> with, e.g., the format '%d' beyond which surprising things happen (output
    vQ> modified for conciseness):

    vQ> gregexpr('1', sprintf('%9000d', 1))
    vQ> # [1] 9000 9801

    vQ> gregexpr('1', sprintf('%9000d', 1))
    vQ> # [1]  9000  9801 10602

    vQ> gregexpr('1', sprintf('%9000d', 1))
    vQ> # [1]  9000  9801 10602 11403

    vQ> gregexpr('1', sprintf('%9000d', 1))
    vQ> # [1]  9000  9801 10602 11403 12204

    vQ> ...

    vQ> Note that not only more than one '1' is included in the output, but also that
    vQ> the same functional expression (no side effects used beyond the interface) gives
    vQ> different results on each execution.  Analogous behaviour can be observed with
    vQ> '%nd' where n > 8200.

    vQ> The actual output above is consistent across separate sessions.

    vQ> With sufficiently large field width values, R segfaults:

    vQ> sprintf('%*d', 10^5, 1)
    vQ> # *** caught segfault ***
    vQ> # address 0xbfcfc000, cause 'memory not mapped'
    vQ> # Segmentation fault


Thank you, Wacek.
That's all ``interesting''  ... unfortunately, 

my version of  'man 3 sprintf' contains

>> BUGS
>>        Because sprintf() and vsprintf() assume an arbitrarily
>>        long string, callers must be careful not to overflow the
>>        actual space; this is often impossible to assure. Note
>>        that the length of the strings produced is
>>        locale-dependent and difficult to predict.  Use
>>        snprintf() and vsnprintf() instead (or asprintf() and vasprintf).

(note the "impossible" part above)       
and we haven't used  snprintf() yet, probably because it
requires the  C99 C standard, and AFAIK, we have only relatively
recently started to more or less rely on C99 in the R sources.
       
More precisely, I see that some windows-only code relies on
snprintf() being available  whereas in at least on non-Windows
section, I read   /* we cannot assume snprintf here */

Now such platform dependency issues and corresponding configure
settings I do typically leave to other R-corers with a much
wider overview about platforms and their compilers and C libraries.
       

BTW,  
1) sprintf("%n %g", 1,1)   also seg.faults

2) Did you have a true use case where  the  8192  limit was an
   undesirable limit?

Martin       

    vQ> sessionInfo()
    vQ> # R version 2.10.0 Under development (unstable) (2009-04-20 r48365) 
    vQ> # i686-pc-linux-gnu


From pat at revolution-computing.com  Wed Apr 22 16:40:09 2009
From: pat at revolution-computing.com (Patrick Shields)
Date: Wed, 22 Apr 2009 10:40:09 -0400
Subject: [Rd] Closed-source non-free ParallelR ?
In-Reply-To: <373DCC90906D430E952EF2C423B0D91B@ADAM>
References: <373DCC90906D430E952EF2C423B0D91B@ADAM>
Message-ID: <ac81d400904220740i5a4adac4l41b1a170c6f27bd7@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090422/2591a61a/attachment.pl>

From david at revolution-computing.com  Wed Apr 22 17:36:56 2009
From: david at revolution-computing.com (David M Smith)
Date: Wed, 22 Apr 2009 08:36:56 -0700
Subject: [Rd] Closed-source non-free ParallelR ?
In-Reply-To: <ac81d400904220740i5a4adac4l41b1a170c6f27bd7@mail.gmail.com>
References: <373DCC90906D430E952EF2C423B0D91B@ADAM>
	<ac81d400904220740i5a4adac4l41b1a170c6f27bd7@mail.gmail.com>
Message-ID: <475a3c8f0904220836w43d07042m84f42edf6e05766c@mail.gmail.com>

Patrick made all the points that I was going to make (thanks,
Patrick), but I wanted to reinforce one point that may be the source
of the confusion: ParallelR is not a modified version of R: ParallelR
is a suite of ordinary R packages that run on top of the R engine like
any other package. The R code and Python code in these packages were
written entirely by REvolution Computing staff (including Patrick),
and do not contain any code (derived or otherwise) from the R project.

In retrospect, the name ParallelR may be somewhat confusing in this sense...

# David Smith

On Wed, Apr 22, 2009 at 7:40 AM, Patrick Shields
<pat at revolution-computing.com> wrote:
> I'm Pat Shields, one of the software engineers working on ParallelR. ?I just
> wanted to make two points: no R code or previously gpl'd code can be found
> in any of the non-gpl packages in ParallelR. ?I'm sure that the phrase
> "derived works" is a legally subtle one, but all these packages include are
> R and occasionally python scripts (as well as the standard text
> documentation). ?If these are derived works, doesn't that mean that any R
> code is also, by extension, required to be GPL'd? ?If not, is it including
> these scripts in a package that forces the use of the GPL?
>
> Also, I'm confused about your dimissal of the MCE example. ?If that code was
> a derivative work of R, how could it swap a GPL license for the BSD? ?I
> didn't think such a switch was possible. ?If it was, I'd imagine a lot more
> use of it, as a quick front project could make GPL software into BSD
> software after which all changes could go on behind closed doors.
>
> On Tue, Apr 21, 2009 at 7:38 PM, Matthew Dowle <mdowle at mdowle.plus.com>wrote:
>
>> Dear R-devel,
>>
>> REvolution appear to be offering ParallelR only when bundled with their R
>> Enterprise edition. ?As such it appears to be non-free and closed source.
>> ? ?http://www.revolution-computing.com/products/parallel-r.php
>>
>> Since R is GPL and not LGPL, is this a breach of the GPL ?
>>
>> Below is the "GPL and ParallelR" thread from their R forum.
>>
>> mdowle > ?It appears that ParallelR (packages foreach and iterators) is
>> only available bundled with the Enterprise edition. Since R is GPL, and
>> ParallelR is derived from R, should ParallelR not also be GPL? ?Regards,
>> Matthew
>>
>> revolution > Hello Matthew, ?ParallelR consists of both proprietary and GPL
>> packages. ?The randomForest and snow libraries GPL licensed, whereas the
>> other libraries we include have a commercial license(including 'foreach' and
>> 'iterators'). ?Stephen Weller
>>
>> revolution > I wanted to expand on Stephen's reply. ParallelR is a suite of
>> R packages, and it is well established that packages can be under a
>> difference license than R itself (i.e. not the GPL). For example, package
>> MCE is licensed under BSD, RColorBrewer is licensed under Apache, most of
>> Bioconductor is under the Artistic license and some are under completely
>> unique licenses (e.g. mclust). REvolution Computing developed all of the
>> code in ParallelR (except for the bundled GPL packages Stephen mentions),
>> and we decided to release it under our own license in REvolution R
>> Enterprise.
>> That said, we do already release components of parallelR, such as the
>> underlying engine, Networkspaces (also written by REvolution Computing)
>> under an open source licence. Also, we are likely to release some other
>> components including foreach and iterators, to CRAN soon.
>> David Smith
>> Director of Community, REvolution Computing
>>
>> mdowle > The examples you give (MCE, RColorBrewer, Bioconductor) are all
>> available for free including the source code. Their licenses have been
>> approved by the FSF. Free software and open source are the terms of work
>> derived from GPL licensed software. REvolution's packages 'foreach' and
>> 'iterators' are neither free or open source. ?Can you provide a precedent
>> for proprietary closed-source packages for R ? ?Is your policy approved by
>> the FSF ?
>> I don't object to REvolution. I am a fan of you making money from training
>> courses, consultancy, support and binaries. These are all permitted by the
>> GPL. However the GPL does not allow you to distribute work derived from R
>> which is either closed source or non-free.
>> R is GPL, not LGPL.
>> The above is my personal understanding. I am now posting to r-devel to
>> check, feel free to join the public debate there.
>>
>> Regards, Matthew
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>
> --
> Pat Shields
> Software Engineer
> REvolution Computing
> One Century Tower | 265 Church Street, Suite 1006
> New Haven, CT ?06510
> P: 203-777-7442 x250 | www.revolution-computing.com
>
> Check out our upcoming events schedule at
> www.revolution-computing.com/events
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
David M Smith <david at revolution-computing.com>
Director of Community, REvolution Computing www.revolution-computing.com
Tel: +1 (206) 577-4778 x3203 (San Francisco, USA)

Check out our upcoming events schedule at www.revolution-computing.com/events


From delhomme at embl.de  Wed Apr 22 16:50:09 2009
From: delhomme at embl.de (delhomme at embl.de)
Date: Wed, 22 Apr 2009 16:50:09 +0200 (CEST)
Subject: [Rd] make fails when using with-x=no on linux CentOS 5.3 (PR#13670)
Message-ID: <20090422145009.D58222834321@mail.pubhealth.ku.dk>

Full_Name: Nicolas Delhomme
Version: 2.9.0
OS: Linux CentOS release 5.3 kernel 2.6.18-128.el5 arch x86_64
Submission from: (NULL) (194.94.44.4)


Hi,

The commands I used to compile R2.9.0 on CentOS
./compile --with-x=no
make

This fails with the following message:
make[2]: Leaving directory `/home/delhomme/R-2.9.0/src/modules/vfonts'
make[1]: Leaving directory `/home/delhomme/R-2.9.0/src/modules/vfonts'
make[1]: Entering directory `/home/delhomme'
make[1]: *** No rule to make target `R'.  Stop.
make[1]: Leaving directory `/home/delhomme'
make: *** [R] Error 1

What happens is the following:

In the Makefile located in the src/modules directory, there's a check for
R_MODULES (l.17-18)
## R_MODULES is X11 (or not)
MODULES = $(R_MODULES) internet lapack vfonts

This works fine, R_MODULES being defined and equal to an empty string.

Then in the R target (l.26-30)
R: Makefile make.internet make.lapack make.vfonts
       @for d in "$(R_MODULES)"; do \
            (cd $${d} && $(MAKE) $@) || exit 1; \
       done

the R_MODULES is used again and since it is an empty string, it results in
doing
cd && make R, which means going to the home directory and executes the R target
of the Makefile there. Humm... since there's no makefile in my home dir, this
obviously breaks everything up.

The fix for that is to test wether R_MODULES is not an empty string. The
following corrects the problem:

R: Makefile make.internet make.lapack make.vfonts
        @if test "$(R_MODULES)"	!= ""; then \
                for d in "$(R_MODULES)"; do \
                  (cd $${d} && $(MAKE) $@) || exit 1; \
                done; \ 
	fi

Best,

Nicolas Delhomme


From pierre.chausse at uqam.ca  Wed Apr 22 16:43:35 2009
From: pierre.chausse at uqam.ca (=?ISO-8859-1?Q?Pierre_Chauss=E9?=)
Date: Wed, 22 Apr 2009 10:43:35 -0400
Subject: [Rd] arima
Message-ID: <49EF2D17.9060709@uqam.ca>

Hi,

I have a suggestion for the fonction arima and arima0. I think you 
should not call the constant an intercept because it creates confusion.  
It is not really an intercept but a mean. For an AR(1) the intercept mu 
should be defined as:

X(t)=mu + phi X(t-1) + e(t)

What you call intercept mu is rather defined as

(X(t)-mu) = phi (X(t-1)-mu)) + e(t)

which is not a common way to define an intercept. There is an error in 
the fGarch's predict() because of that. I think you should just be more 
explicit.

thank you

Pierre Chauss?
economics department
UQ?M


From h.wickham at gmail.com  Wed Apr 22 17:52:07 2009
From: h.wickham at gmail.com (hadley wickham)
Date: Wed, 22 Apr 2009 10:52:07 -0500
Subject: [Rd] Closed-source non-free ParallelR ?
In-Reply-To: <ac81d400904220740i5a4adac4l41b1a170c6f27bd7@mail.gmail.com>
References: <373DCC90906D430E952EF2C423B0D91B@ADAM>
	<ac81d400904220740i5a4adac4l41b1a170c6f27bd7@mail.gmail.com>
Message-ID: <f8e6ff050904220852y4fb9c112o970a44cc8a433e3@mail.gmail.com>

> Also, I'm confused about your dimissal of the MCE example. ?If that code was
> a derivative work of R, how could it swap a GPL license for the BSD? ?I
> didn't think such a switch was possible. ?If it was, I'd imagine a lot more
> use of it, as a quick front project could make GPL software into BSD
> software after which all changes could go on behind closed doors.

And there are certainly many existing R packages with
non-free/non-open licenses:

http://cran.r-project.org/web/packages/ff/LICENSE
http://cran.r-project.org/web/packages/minpack.lm/LICENSE
http://cran.r-project.org/web/packages/rngwell19937/LICENSE
http://cran.r-project.org/web/packages/SDDA/LICENSE
...

Found with http://www.google.com/search?q=site:cran.r-project.org+cran+%22file+license%22



Hadley

-- 
http://had.co.nz/


From maechler at stat.math.ethz.ch  Wed Apr 22 19:29:05 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 22 Apr 2009 19:29:05 +0200
Subject: [Rd] reversing xlim, ylim in smoothScatter
In-Reply-To: <920402.63507.qm@web8401.mail.in.yahoo.com>
References: <920402.63507.qm@web8401.mail.in.yahoo.com>
Message-ID: <18927.21473.191825.2987@lynne.math.ethz.ch>

>>>>> "SG" == Shashikiran Ganesh <shashikiran_ganesh at yahoo.co.in>
>>>>>     on Wed, 22 Apr 2009 17:16:09 +0530 (IST) writes:

    SG> Hello,
    SG> I have found that in smoothScatter it is not possible to reverse the axes plotted (R version 2.9.0) .?? It appears that this arises from the hard coding of xlim and ylim in smoothscatter.R in the lines :

    SG> x <- x[ xlim[1] <= x[,1] & x[,1] <=xlim[2], ]?? (line? number 25)

    SG> and 

    SG> x <- x[ ylim[1] <= x[,2] & x[,2] <= ylim[2], ]? (line number 31)

    SG> This results in a x being NA if ylim[1] > ylim[2] which results in an error on executing
    SG> ?map <- grDevices:::.smoothScatterCalcDensity(x, nbin, bandwidth)

    SG> To counter this problem, I replaced the above two lines by :
    SG> x <-x [min(xlim) <= x[,1] & x[,1] <= max(xlim), ]

    SG> and 
    SG> x <- x[min(ylim) <= x[,2] & x[,2] <= max(ylim), ]

    SG> and now smoothscatter reverses axes properly if xlim and/or ylim are provided with reversed ranges.?? 

    SG> I am wondering if this would break something somewhere else or if there is a better way to reverse the axes. ? ? (I am a newbie in R programming although I have been using R for some astronomical plots and computations etc...) 

No, I don't think your proposed change could create problems,
but to the contrary, I'd declare it as a simple bug fix,
so it will be part of the next versions of R,
thank you very much!

Martin Maechler, ETH Zurich

    SG> Thanks in advance for your comments!? 
    SG> Shashi
    SG> --
    SG> Shashikiran Ganesh 

    SG> http://www.prl.res.in/~shashi 

    SG> http://cosmicdiary.org/blogs/shashikiran_ganesh/
    SG> Registered linux user number: 39542 (http://counter.li.org)


From hzambran.newsgroups at gmail.com  Wed Apr 22 19:45:16 2009
From: hzambran.newsgroups at gmail.com (hzambran.newsgroups at gmail.com)
Date: Wed, 22 Apr 2009 19:45:16 +0200 (CEST)
Subject: [Rd] 'is.integer' (PR#13671)
Message-ID: <20090422174516.2EB1928321BF@mail.pubhealth.ku.dk>

Full_Name: Mauricio
Version: 2.9.0 (2009-04-17)
OS:  i486-pc-linux-gnu
Submission from: (NULL) (193.205.203.3)


This is a very simple function that seems not to be working, according to the
definition given by '?is.integer'.

I checked in the Bug Tracking page at http://bugs.R-project.org/, but I didn't
find any related message.

The possible problem is:


> is.integer(1)
[1] FALSE

and 1 is obviously an integer value.


I would really appreciate if you could clarify if this is really a bug or not.

Thanks in advance,

Mauricio

> version
               _                           
platform       i486-pc-linux-gnu           
arch           i486                        
os             linux-gnu                   
system         i486, linux-gnu             
status                                     
major          2                           
minor          9.0                         
year           2009                        
month          04                          
day            17                          
svn rev        48333                       
language       R                           
version.string R version 2.9.0 (2009-04-17)


From khansen at stat.berkeley.edu  Wed Apr 22 21:49:05 2009
From: khansen at stat.berkeley.edu (Kasper Daniel Hansen)
Date: Wed, 22 Apr 2009 12:49:05 -0700
Subject: [Rd] RFC: Ability to suppress 'locale' from sessionInfo
In-Reply-To: <18926.55876.329732.6352@lynne.math.ethz.ch>
References: <5c62e0070904211916w36310bfdsd720fae189cad25b@mail.gmail.com>
	<18926.50861.369595.3396@lxh5.stat.uni-muenchen.de>
	<49EECDEA.9020800@telenet.be>
	<18926.55876.329732.6352@lynne.math.ethz.ch>
Message-ID: <1CF05FF1-8327-4E3A-AC93-4991458FC154@stat.berkeley.edu>

This is a better way, it does two things
a) enclose the itemize environment in a flushleft environment - this  
gives us much better line breaks for the verb.
b) does a replace of ";" with ";| \verb|" so that each "component" of  
the locale gets enclosed in its own \verb command, which allows latex  
to produce line breaks (since I am using gsub, I do gsub(";", ";| \\\ 
\verb", object$locale))

Below is a proposed utils:::toLatex.sessionInfo

I think it might make sense to have a locale argument, but I would  
argue that the default ought to be TRUE.

Kasper

function (object, ...)
{
     opkgver <- sapply(object$otherPkgs, function(x) x$Version)
     nspkgver <- sapply(object$loadedOnly, function(x) x$Version)
     z <- c("\\begin{flushleft}", "\\begin{itemize}", paste("  \\item  
", object$R.version$version.string,
         ", \\verb|", object$R.version$platform, "|", sep = ""),
         paste("  \\item Locale: \\verb|", gsub(";", ";| \\\\verb|",  
object$locale), "|",
             sep = ""), strwrap(paste("\\item Base packages:",
             paste(sort(object$basePkgs), collapse = ", ")), indent = 2,
             exdent = 4))
     if (length(opkgver)) {
         opkgver <- opkgver[sort(names(opkgver))]
         z <- c(z, strwrap(paste("  \\item Other packages: ",
             paste(names(opkgver), opkgver, sep = "~", collapse = ",  
")),
             indent = 2, exdent = 4))
     }
     if (length(nspkgver)) {
         nspkgver <- nspkgver[sort(names(nspkgver))]
         z <- c(z, strwrap(paste("  \\item Loaded via a namespace (and  
not attached): ",
             paste(names(nspkgver), nspkgver, sep = "~", collapse = ",  
")),
             indent = 2, exdent = 4))
     }
     z <- c(z, "\\end{itemize}", "\\end{flushleft}")
     class(z) <- "Latex"
     z
}



On Apr 22, 2009, at 1:50 , Martin Maechler wrote:

>>>>>> "TobiasV" == Tobias Verbeke <tobias.verbeke at telenet.be>
>>>>>>    on Wed, 22 Apr 2009 09:57:30 +0200 writes:
>
>    TobiasV> Friedrich Leisch wrote:
>>>>>>>> On Tue, 21 Apr 2009 21:16:59 -0500,
>>>>>>>> Kevin W (KW) wrote:
>>>
>>>> The printing of the locale information from sessionInfo is not  
>>>> very tidy.
>>>> Using toLatex(sessionInfo) pretty much guarantees "badness" from  
>>>> breaking
>>>> the margin boundary (though my version of TeX no longer reports  
>>>> such
>>>> errors).  A random example is here:
>>>> http://cran.r-project.org/web/packages/Matrix/vignettes/Design-issues.pdf
>>>
>>>> I find the locale information unnecessary and right now I hack  
>>>> this with
>>>> si = sessionInfo()
>>>> si$locale = "US"
>>>> toLatex(si)
>>>
>>>> I would like to be able to do something a bit cleaner, for example
>>>> sessionInfo(locale=FALSE)
>>>
>>>> For what it's worth, I don't think that early versions of  
>>>> sessionInfo
>>>> printed information about the locale.
>>>
>>> It went in on 2006-05-26, so it's bben there for some time now.
>>>
>>>
>>>> Discussion welcome.
>>>
>>> I agree that it doesn't look nice in latex documents, but it is very
>>> handy in bug reports.
>>>
>>> Are there any objections if we add a locale argument to the  
>>> toLatex()
>>> method and let that default to FALSE?
>
>    TobiasV> No objection although I would not be against
>    TobiasV> letting it default to TRUE to preserve current behaviour.
>
> I agree with setting the default to keep the current behavior.
> As Fritz mentioned, there situations where the locale
> (information) is of quite some importance.  As we know that
> Sweave is used in quite a few circumstances with automatic
> report generation, of which in *some* cases the locale may also
> matter (and is desired to be visible),
>
> I think we should not change the default behavior lightly
> (apart from the extra spaces, see below).
>
>    TobiasV> One improvement in the locale information that would  
> make the LaTeX look
>    TobiasV> much nicer would be to add a space after the separator,  
> i.e.
>
>    TobiasV> item1; item2; item3
>
>    TobiasV> instead of
>
>    TobiasV> item1;item2;item3
>
>    TobiasV> That is for me more important than having the
>    TobiasV> option to include locale info or not
>
> I agree very much; and indeed, adding the space after ";" is
> trivial to achieve in the next version of  toLatex()'s
> "sessionInfo" method, as well.
>
> Martin
>
>    TobiasV> as without such a change I found no way to prevent the  
> locale
>    TobiasV> information to run into the margin (and off the
>    TobiasV> page) of the resulting LaTeX document and that is
>    TobiasV> esthetically much more displeasing than the mere
>    TobiasV> presence of the locale information.
>
>    TobiasV> Best,
>    TobiasV> Tobias
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From cowan.pd at gmail.com  Wed Apr 22 21:55:25 2009
From: cowan.pd at gmail.com (Peter Cowan)
Date: Wed, 22 Apr 2009 12:55:25 -0700
Subject: [Rd] 'is.integer' (PR#13671)
In-Reply-To: <20090422174516.2EB1928321BF@mail.pubhealth.ku.dk>
References: <20090422174516.2EB1928321BF@mail.pubhealth.ku.dk>
Message-ID: <e1fc21b0904221255h25083068h56d63f2432984167@mail.gmail.com>

On Wed, Apr 22, 2009 at 10:45 AM,  <hzambran.newsgroups at gmail.com> wrote:
> Full_Name: Mauricio
> Version: 2.9.0 (2009-04-17)
> OS: ?i486-pc-linux-gnu
> Submission from: (NULL) (193.205.203.3)
>
>
> This is a very simple function that seems not to be working, according to the
> definition given by '?is.integer'.
>
> I checked in the Bug Tracking page at http://bugs.R-project.org/, but I didn't
> find any related message.
>
> The possible problem is:
>
>
>> is.integer(1)
> [1] FALSE
>
> and 1 is obviously an integer value.
>

Actually it's not:

> typeof(1)
[1] "double"

So the command does work as the help describes.  From ?is.integer()

"is.integer returns TRUE or FALSE depending on whether its argument is
of integer type or not, unless it is a factor when it returns FALSE."

In the HTML help "type" is a link to the typeof() function.

HTH

Peter

>
> I would really appreciate if you could clarify if this is really a bug or not.
>
> Thanks in advance,
>
> Mauricio
>
>> version
> ? ? ? ? ? ? ? _
> platform ? ? ? i486-pc-linux-gnu
> arch ? ? ? ? ? i486
> os ? ? ? ? ? ? linux-gnu
> system ? ? ? ? i486, linux-gnu
> status
> major ? ? ? ? ?2
> minor ? ? ? ? ?9.0
> year ? ? ? ? ? 2009
> month ? ? ? ? ?04
> day ? ? ? ? ? ?17
> svn rev ? ? ? ?48333
> language ? ? ? R
> version.string R version 2.9.0 (2009-04-17)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From josh.m.ulrich at gmail.com  Wed Apr 22 21:55:25 2009
From: josh.m.ulrich at gmail.com (Josh Ulrich)
Date: Wed, 22 Apr 2009 14:55:25 -0500
Subject: [Rd] 'is.integer' (PR#13671)
In-Reply-To: <20090422174516.2EB1928321BF@mail.pubhealth.ku.dk>
References: <20090422174516.2EB1928321BF@mail.pubhealth.ku.dk>
Message-ID: <8cca69990904221255h2eb00e86h545032e15e4a66f5@mail.gmail.com>

> typeof(1)
[1] "double"

1 is obviously *not* an integer value.

Best,
Josh
--
http://quantemplation.blogspot.com
http://www.fosstrading.com



On Wed, Apr 22, 2009 at 12:45 PM,  <hzambran.newsgroups at gmail.com> wrote:
> Full_Name: Mauricio
> Version: 2.9.0 (2009-04-17)
> OS: ?i486-pc-linux-gnu
> Submission from: (NULL) (193.205.203.3)
>
>
> This is a very simple function that seems not to be working, according to the
> definition given by '?is.integer'.
>
> I checked in the Bug Tracking page at http://bugs.R-project.org/, but I didn't
> find any related message.
>
> The possible problem is:
>
>
>> is.integer(1)
> [1] FALSE
>
> and 1 is obviously an integer value.
>
>
> I would really appreciate if you could clarify if this is really a bug or not.
>
> Thanks in advance,
>
> Mauricio
>
>> version
> ? ? ? ? ? ? ? _
> platform ? ? ? i486-pc-linux-gnu
> arch ? ? ? ? ? i486
> os ? ? ? ? ? ? linux-gnu
> system ? ? ? ? i486, linux-gnu
> status
> major ? ? ? ? ?2
> minor ? ? ? ? ?9.0
> year ? ? ? ? ? 2009
> month ? ? ? ? ?04
> day ? ? ? ? ? ?17
> svn rev ? ? ? ?48333
> language ? ? ? R
> version.string R version 2.9.0 (2009-04-17)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From cberry at tajo.ucsd.edu  Wed Apr 22 21:57:44 2009
From: cberry at tajo.ucsd.edu (Charles C. Berry)
Date: Wed, 22 Apr 2009 12:57:44 -0700
Subject: [Rd] 'is.integer' (PR#13671)
In-Reply-To: <20090422174516.2EB1928321BF@mail.pubhealth.ku.dk>
References: <20090422174516.2EB1928321BF@mail.pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.64.0904221254160.10573@tajo.ucsd.edu>

On Wed, 22 Apr 2009, hzambran.newsgroups at gmail.com wrote:

> Full_Name: Mauricio
> Version: 2.9.0 (2009-04-17)
> OS:  i486-pc-linux-gnu
> Submission from: (NULL) (193.205.203.3)
>
>
> This is a very simple function that seems not to be working, according to the
> definition given by '?is.integer'.
>
> I checked in the Bug Tracking page at http://bugs.R-project.org/, but I didn't
> find any related message.
>
> The possible problem is:
>
>
>> is.integer(1)
> [1] FALSE
>
> and 1 is obviously an integer value.

Obvious?

You must know something I do not, as the protagonist of Zen and the Art of 
Motorcylce Maintenance would have pointed out.

And if you do then it is not really obvious.

> is.double(1)
[1] TRUE

1L _is_ an integer.

> is.integer(1L)
[1] TRUE
>

So this is not a bug. Please see the FAQ for advise on not posting 
non-bugs.

Chuck

>
>
> I would really appreciate if you could clarify if this is really a bug or not.
>
> Thanks in advance,
>
> Mauricio
>
>> version
>               _
> platform       i486-pc-linux-gnu
> arch           i486
> os             linux-gnu
> system         i486, linux-gnu
> status
> major          2
> minor          9.0
> year           2009
> month          04
> day            17
> svn rev        48333
> language       R
> version.string R version 2.9.0 (2009-04-17)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Charles C. Berry                            (858) 534-2098
                                             Dept of Family/Preventive Medicine
E mailto:cberry at tajo.ucsd.edu	            UC San Diego
http://famprevmed.ucsd.edu/faculty/cberry/  La Jolla, San Diego 92093-0901


From mathieu.ribatet at epfl.ch  Wed Apr 22 22:03:05 2009
From: mathieu.ribatet at epfl.ch (Mathieu Ribatet)
Date: Wed, 22 Apr 2009 22:03:05 +0200
Subject: [Rd] 'is.integer' (PR#13671)
In-Reply-To: <20090422174516.2EB1928321BF@mail.pubhealth.ku.dk>
References: <20090422174516.2EB1928321BF@mail.pubhealth.ku.dk>
Message-ID: <1240430585.5090.5.camel@ubuntu>

To the best of my knowledge this is not a bug. According to FAQ 3.3.3
"Numeric constants with no fractional and exponent (i.e., only integer)
part are taken as integer in S-Plus 6.x or later, but as double in R."

You can see it by invoking
>storage.mode(1)
[1] "double"

Hence, if you really want to have integers, you need to use as.integer
i.e.
> storage.mode(as.integer(1))
[1] "integer"

Cheers,
Mathieu

Le mercredi 22 avril 2009 ? 19:45 +0200, hzambran.newsgroups at gmail.com a
?crit :
> Full_Name: Mauricio
> Version: 2.9.0 (2009-04-17)
> OS:  i486-pc-linux-gnu
> Submission from: (NULL) (193.205.203.3)
> 
> 
> This is a very simple function that seems not to be working, according to the
> definition given by '?is.integer'.
> 
> I checked in the Bug Tracking page at http://bugs.R-project.org/, but I didn't
> find any related message.
> 
> The possible problem is:
> 
> 
> > is.integer(1)
> [1] FALSE
> 
> and 1 is obviously an integer value.
> 
> 
> I would really appreciate if you could clarify if this is really a bug or not.
> 
> Thanks in advance,
> 
> Mauricio
> 
> > version
>                _                           
> platform       i486-pc-linux-gnu           
> arch           i486                        
> os             linux-gnu                   
> system         i486, linux-gnu             
> status                                     
> major          2                           
> minor          9.0                         
> year           2009                        
> month          04                          
> day            17                          
> svn rev        48333                       
> language       R                           
> version.string R version 2.9.0 (2009-04-17)
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
-- 
Institute of Mathematics
Ecole Polytechnique F?d?rale de Lausanne
STAT-IMA-FSB-EPFL, Station 8
CH-1015 Lausanne   Switzerland
http://stat.epfl.ch/
Tel: + 41 (0)21 693 7907


From khansen at stat.berkeley.edu  Wed Apr 22 22:11:12 2009
From: khansen at stat.berkeley.edu (Kasper Daniel Hansen)
Date: Wed, 22 Apr 2009 13:11:12 -0700
Subject: [Rd] wishlist: change default for units  in print.object_size
Message-ID: <BA33F054-0521-497B-9ED1-D3BB0FF659A3@stat.berkeley.edu>

I would like the default for units in print.object_size to be changed  
from "b" to "auto".

Since this is just for the print method, it should not change any  
computations.

Kasper


From macrakis at alum.mit.edu  Wed Apr 22 22:30:36 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Wed, 22 Apr 2009 16:30:36 -0400
Subject: [Rd] 'is.integer' (PR#13671)
In-Reply-To: <20090422174516.2EB1928321BF@mail.pubhealth.ku.dk>
References: <20090422174516.2EB1928321BF@mail.pubhealth.ku.dk>
Message-ID: <8b356f880904221330r2c2776cid12036442511b216@mail.gmail.com>

Dear R experts,

You are being a bit harsh on this user. He simply doesn't understand
the distinction between "object of type integer" and "integer-valued
object", which is actually fairly subtle.

On Wed, Apr 22, 2009 at 1:45 PM,  <hzambran.newsgroups at gmail.com> wrote:
> This is a very simple function that seems not to be working, according to the
> definition given by '?is.integer'.
...
>> is.integer(1)
> [1] FALSE
>
> and 1 is obviously an integer value.

The is.integer function is correctly documented to check whether
objects are of *type* integer, thus:

     is.integer( 1L ) => TRUE

In R, objects of type integer are only created with literals of the
form 999L; as the output of some functions when the input is integral
(e.g. sort, unique, rev, ...); as the output of some functions which
return index values or differences of index values (which, grep, rle,
...); and the output of a few other functions in certain cases (seq).

Most numbers in R are floating-point numbers (type double), and
determining whether their value is integral is rather subtle.

For example, consider the vector 1+1000^-(1:6).  In floating-point
arithmetic, the first 5 values are distinguishable from the integer 1,
but the 6th is not, though of course the *mathematical* number
1+1000^-6 is not integral.  Now consider 1e40, which has the property
that floor(x)==x==ceiling(x), which you might think characterizes an
integer;  but it also has the property that x+1 == x.  Similarly for
1/3 * 1e40.

In other words, it is really a rather subtle question whether a
floating-point number "represents" an integer....

       -s


From tplate at acm.org  Wed Apr 22 22:37:05 2009
From: tplate at acm.org (Tony Plate)
Date: Wed, 22 Apr 2009 14:37:05 -0600
Subject: [Rd] 'is.integer' (PR#13671)
In-Reply-To: <20090422174516.2EB1928321BF@mail.pubhealth.ku.dk>
References: <20090422174516.2EB1928321BF@mail.pubhealth.ku.dk>
Message-ID: <49EF7FF1.704@acm.org>

is.integer() is one of those functions with a name that can be confusing 
-- it looks at the underlying storage type of its argument (e.g., 
integer, floating point, character, etc.) not at the value stored in the 
argument.

So, the type of behavior you see is this:

 > is.integer(1)
[1] FALSE
 > is.integer(as.integer(1))
[1] TRUE
 > is.integer(as.integer(1) * 1.0)
[1] FALSE
 > is.integer(as.integer(NA))
[1] TRUE
 >

Careful reading of ?is.integer does tell you this, but I wouldn't accuse 
that help page of making such information blatantly obvious to new users 
of R.

To test whether a value is an integer value, you can so something like this:

 > is.wholenumber <- function(x, tolerance = .Machine$double.eps^0.5) 
return(abs(x - round(x)) < tolerance)
 > is.wholenumber(1)
[1] TRUE
 > is.wholenumber(seq(1,5,by=0.5))
[1]  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE
 >

The 'tolerance' part is to allow for minor deviations that might be due 
to floating point representation issues, e.g., on my computer 1/49 * 49 
does not result in a value that is exactly equal to 1:

 > 1/49 * 49 - 1
[1] -1.110223e-16
 > is.wholenumber(1/49 * 49)
[1] TRUE
 > is.wholenumber(1/49 * 49, tol=0)
[1] FALSE
 >

-- Tony Plate

hzambran.newsgroups at gmail.com wrote:
> Full_Name: Mauricio
> Version: 2.9.0 (2009-04-17)
> OS:  i486-pc-linux-gnu
> Submission from: (NULL) (193.205.203.3)
>
>
> This is a very simple function that seems not to be working, according to the
> definition given by '?is.integer'.
>
> I checked in the Bug Tracking page at http://bugs.R-project.org/, but I didn't
> find any related message.
>
> The possible problem is:
>
>
>   
>> is.integer(1)
>>     
> [1] FALSE
>
> and 1 is obviously an integer value.
>
>
> I would really appreciate if you could clarify if this is really a bug or not.
>
> Thanks in advance,
>
> Mauricio
>
>   
>> version
>>     
>                _                           
> platform       i486-pc-linux-gnu           
> arch           i486                        
> os             linux-gnu                   
> system         i486, linux-gnu             
> status                                     
> major          2                           
> minor          9.0                         
> year           2009                        
> month          04                          
> day            17                          
> svn rev        48333                       
> language       R                           
> version.string R version 2.9.0 (2009-04-17)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From savicky at cs.cas.cz  Thu Apr 23 10:21:45 2009
From: savicky at cs.cas.cz (Petr Savicky)
Date: Thu, 23 Apr 2009 10:21:45 +0200
Subject: [Rd] 'is.integer' (PR#13671)
In-Reply-To: <8b356f880904221330r2c2776cid12036442511b216@mail.gmail.com>
References: <20090422174516.2EB1928321BF@mail.pubhealth.ku.dk>
	<8b356f880904221330r2c2776cid12036442511b216@mail.gmail.com>
Message-ID: <20090423082145.GA31740@cs.cas.cz>

On Wed, Apr 22, 2009 at 04:30:36PM -0400, Stavros Macrakis wrote:
[snip]
> Now consider 1e40, which has the property
> that floor(x)==x==ceiling(x), which you might think characterizes an
> integer;  but it also has the property that x+1 == x.  Similarly for
> 1/3 * 1e40.
[snip]

The number 1/3 * 1e40 is larger than 2^53 and every value of double type,
which is larger than 2^53, is an even integer. The number has at least 54
digits mathematically, but only the first 53 of them are stored, so the last
one is zero. Since rounding is done towards an even value, we get x+1 == x.

Double type is safe for integer values in the interval [-2^53, 2^53].
Inside this interval, basic arithmetic operations (+,-,*,/) on integers,
whose result is an integer mathematically, yield integer result also in
the machine.

Petr.


From maechler at stat.math.ethz.ch  Thu Apr 23 11:22:06 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 23 Apr 2009 11:22:06 +0200
Subject: [Rd] 'is.integer' (PR#13671)
In-Reply-To: <8b356f880904221330r2c2776cid12036442511b216@mail.gmail.com>
References: <20090422174516.2EB1928321BF@mail.pubhealth.ku.dk>
	<8b356f880904221330r2c2776cid12036442511b216@mail.gmail.com>
Message-ID: <18928.13118.892491.84418@lynne.math.ethz.ch>

>>>>> "SM" == Stavros Macrakis <macrakis at alum.mit.edu>
>>>>>     on Wed, 22 Apr 2009 16:30:36 -0400 writes:

    SM> Dear R experts,
    SM> You are being a bit harsh on this user. 

No! (see below)

    SM> He simply doesn't understand
    SM> the distinction between "object of type integer" and "integer-valued
    SM> object", which is actually fairly subtle.

yes, probably for the vast majority of today's R users.

*However*, Mauricio submitted a *formal* bug report against R
and there are many caveats against doing that "light-heartedly".
Note that he also said

 >> I would really appreciate if you could clarify if this is
 >> really a bug or not. 

and that this is exactly one of situation where one should post
a question to R-help (or maybe R-devel) but *NOT* submit a
formal bug report.

Regards,
Martin


    SM> On Wed, Apr 22, 2009 at 1:45 PM,  <hzambran.newsgroups at gmail.com> wrote:
    >> This is a very simple function that seems not to be working, according to the
    >> definition given by '?is.integer'.
    SM> ...
    >>> is.integer(1)
    >> [1] FALSE
    >> 
    >> and 1 is obviously an integer value.

    SM> The is.integer function is correctly documented to check whether
    SM> objects are of *type* integer, thus:

    SM> is.integer( 1L ) => TRUE

    SM> In R, objects of type integer are only created with literals of the
    SM> form 999L; as the output of some functions when the input is integral
    SM> (e.g. sort, unique, rev, ...); as the output of some functions which
    SM> return index values or differences of index values (which, grep, rle,
    SM> ...); and the output of a few other functions in certain cases (seq).

    SM> Most numbers in R are floating-point numbers (type double), and
    SM> determining whether their value is integral is rather subtle.

    SM> For example, consider the vector 1+1000^-(1:6).  In floating-point
    SM> arithmetic, the first 5 values are distinguishable from the integer 1,
    SM> but the 6th is not, though of course the *mathematical* number
    SM> 1+1000^-6 is not integral.  Now consider 1e40, which has the property
    SM> that floor(x)==x==ceiling(x), which you might think characterizes an
    SM> integer;  but it also has the property that x+1 == x.  Similarly for
    SM> 1/3 * 1e40.

    SM> In other words, it is really a rather subtle question whether a
    SM> floating-point number "represents" an integer....

    SM> -s

    SM> ______________________________________________
    SM> R-devel at r-project.org mailing list
    SM> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Thu Apr 23 11:37:37 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 23 Apr 2009 11:37:37 +0200
Subject: [Rd] 'is.integer' (PR#13671)
In-Reply-To: <49EF7FF1.704@acm.org>
References: <20090422174516.2EB1928321BF@mail.pubhealth.ku.dk>
	<49EF7FF1.704@acm.org>
Message-ID: <18928.14049.374028.202617@lynne.math.ethz.ch>

>>>>> "TP" == Tony Plate <tplate at acm.org>
>>>>>     on Wed, 22 Apr 2009 14:37:05 -0600 writes:

    TP> is.integer() is one of those functions with a name that can be confusing 
    TP> -- it looks at the underlying storage type of its argument (e.g., 
    TP> integer, floating point, character, etc.) not at the value stored in the 
    TP> argument.

    TP> So, the type of behavior you see is this:

    >> is.integer(1)
    TP> [1] FALSE
    >> is.integer(as.integer(1))
    TP> [1] TRUE
    >> is.integer(as.integer(1) * 1.0)
    TP> [1] FALSE
    >> is.integer(as.integer(NA))
    TP> [1] TRUE
    >> 

    TP> Careful reading of ?is.integer does tell you this, but I wouldn't accuse 
    TP> that help page of making such information blatantly obvious to new users 
    TP> of R.

    TP> To test whether a value is an integer value, you can so something like this:

    >> is.wholenumber <- function(x, tolerance = .Machine$double.eps^0.5) 
    TP> return(abs(x - round(x)) < tolerance)
    >> is.wholenumber(1)
    TP> [1] TRUE
    >> is.wholenumber(seq(1,5,by=0.5))
    TP> [1]  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE
    >> 

Thank you, Tony.

Somewhat contrary to our (R-core) beliefs that a reference
should be concise and correct, I have now added (an abridged
version of) the is.wholenumber() function to the *examples* 
on the  help(is.integer)  page and a note too.

Let's pretend we hope that this will stop such bug reports 
;-)

Martin Maechler


    TP> The 'tolerance' part is to allow for minor deviations that might be due 
    TP> to floating point representation issues, e.g., on my computer 1/49 * 49 
    TP> does not result in a value that is exactly equal to 1:

    >> 1/49 * 49 - 1
    TP> [1] -1.110223e-16
    >> is.wholenumber(1/49 * 49)
    TP> [1] TRUE
    >> is.wholenumber(1/49 * 49, tol=0)
    TP> [1] FALSE
    >> 

    TP> -- Tony Plate

    TP> hzambran.newsgroups at gmail.com wrote:
    >> Full_Name: Mauricio
    >> Version: 2.9.0 (2009-04-17)
    >> OS:  i486-pc-linux-gnu
    >> Submission from: (NULL) (193.205.203.3)
    >> 
    >> 
    >> This is a very simple function that seems not to be working, according to the
    >> definition given by '?is.integer'.
    >> 
    >> I checked in the Bug Tracking page at http://bugs.R-project.org/, but I didn't
    >> find any related message.
    >> 
    >> The possible problem is:
    >> 
    >> 
    >> 
    >>> is.integer(1)
    >>> 
    >> [1] FALSE
    >> 
    >> and 1 is obviously an integer value.
    >> 
    >> 
    >> I would really appreciate if you could clarify if this is really a bug or not.
    >> 
    >> Thanks in advance,
    >> 
    >> Mauricio
    >> 
    >> 
    >>> version
    >>> 
    >> _                           
    >> platform       i486-pc-linux-gnu           
    >> arch           i486                        
    >> os             linux-gnu                   
    >> system         i486, linux-gnu             
    >> status                                     
    >> major          2                           
    >> minor          9.0                         
    >> year           2009                        
    >> month          04                          
    >> day            17                          
    >> svn rev        48333                       
    >> language       R                           
    >> version.string R version 2.9.0 (2009-04-17)
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> 
    >> 

    TP> ______________________________________________
    TP> R-devel at r-project.org mailing list
    TP> https://stat.ethz.ch/mailman/listinfo/r-devel


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Thu Apr 23 11:49:54 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Thu, 23 Apr 2009 11:49:54 +0200
Subject: [Rd] incorrect output and segfaults from sprintf with
	%*d	(PR#13667)
In-Reply-To: <20090422141025.2B02528321B3@mail.pubhealth.ku.dk>
References: <20090422141025.2B02528321B3@mail.pubhealth.ku.dk>
Message-ID: <49F039C2.8050000@idi.ntnu.no>

maechler at stat.math.ethz.ch wrote:
>
>     vQ> sprintf has a documented limit on strings included in the output using the
>     vQ> format '%s'.  It appears that there is a limit on the length of strings included
>     vQ> with, e.g., the format '%d' beyond which surprising things happen (output
>     vQ> modified for conciseness):
>   

... and this limit is *not* documented.


>     vQ> gregexpr('1', sprintf('%9000d', 1))
>     vQ> # [1] 9000 9801
>
>     vQ> gregexpr('1', sprintf('%9000d', 1))
>     vQ> # [1]  9000  9801 10602
>
>     vQ> gregexpr('1', sprintf('%9000d', 1))
>     vQ> # [1]  9000  9801 10602 11403
>
>     vQ> gregexpr('1', sprintf('%9000d', 1))
>     vQ> # [1]  9000  9801 10602 11403 12204
>
>     vQ> ...
>
>     vQ> Note that not only more than one '1' is included in the output, but also that
>     vQ> the same functional expression (no side effects used beyond the interface) gives
>     vQ> different results on each execution.  Analogous behaviour can be observed with
>     vQ> '%nd' where n > 8200.
>
>     vQ> The actual output above is consistent across separate sessions.
>
>     vQ> With sufficiently large field width values, R segfaults:
>
>     vQ> sprintf('%*d', 10^5, 1)
>     vQ> # *** caught segfault ***
>     vQ> # address 0xbfcfc000, cause 'memory not mapped'
>     vQ> # Segmentation fault
>
>
> Thank you, Wacek.
> That's all ``interesting''  ... unfortunately, 
>
> my version of  'man 3 sprintf' contains
>
>   
>>> BUGS
>>>        Because sprintf() and vsprintf() assume an arbitrarily
>>>        long string, callers must be careful not to overflow the
>>>        actual space; this is often impossible to assure. Note
>>>        that the length of the strings produced is
>>>        locale-dependent and difficult to predict.  Use
>>>        snprintf() and vsnprintf() instead (or asprintf() and vasprintf).
>>>       
>
>   

yes, but this is c documentation, not r documentation.  it's applicable
to a degree, since ?sprintf does say that sprintf is "a wrapper for the
C function 'sprintf'".  however, in c you use a buffer and you usually
have control over it's capacity, while in r this is a hidden
implementational detail, which should not be visible to the user, or
should cause an attempt to overflow the buffer to fail more gracefully
than with a segfault.

in r, sprintf('%9000d', 1) will produce a confused output with a count
of 1's variable (!) across runs (while sprintf('%*d', 9000, 1) seems to
do fine):

    gregexpr('1', sprintf('%*d', 9000, 1))
    # [1] 9000

    gregexpr('1', sprintf('%9000d', 1))
    # [1] 9000 9801 ..., variable across executions

on one execution in a series i actually got this:

Warning message:
In gregexpr("1", sprintf("%9000d", 1)) :
  input string 1 is invalid in this locale

while the very next execution, still in the same session, gave

    # [1]  9000  9801 10602

with sprintf('%*d', 10000, 1) i got segfaults on some executions but
correct output on others, while sprintf('%10000d', 1) is confused again.



> (note the "impossible" part above)       
>   

yes, but it does also say "must be careful", and it seems that someone
has not been careful enough.

> and we haven't used  snprintf() yet, probably because it
> requires the  C99 C standard, and AFAIK, we have only relatively
> recently started to more or less rely on C99 in the R sources.
>   

while snprintf would help avoid buffer overflow, it may not be a
solution to the issue of confused output.

>        
> More precisely, I see that some windows-only code relies on
> snprintf() being available  whereas in at least on non-Windows
> section, I read   /* we cannot assume snprintf here */
>
> Now such platform dependency issues and corresponding configure
> settings I do typically leave to other R-corers with a much
> wider overview about platforms and their compilers and C libraries.
>   

it looks like src/main/sprintf.c is just buggy, and it's plausible that
the bug could be repaired in a platform-independent manner.


>        
>
> BTW,  
> 1) sprintf("%n %g", 1,1)   also seg.faults
>   

as do

    sprintf('%n%g', 1, 1)
    sprintf('%n%')

etc., while

    sprintf('%q%g', 1, 1)
    sprintf('%q%')
  
work just fine.  strange, because per ?sprintf 'n' is not recognized as
a format specifier, so the output from the first two above should be as
from the last two above, respectively.  (and likewise in the %S case,
discussed and bug-reported earlier.)


> 2) Did you have a true use case where  the  8192  limit was an
>    undesirable limit?
>   

how does it matter?  if you set a limit, be sure to consistently enforce
it and warn the user on attempts to exceed it.  or write clearly in the
docs that such attempts will cause the output to be silently truncated. 
examples such as

    sprintf('%9000d', 1)

do not contribute to the reliability of r, and neither to the user's
confidence in it.

vQ


From maechler at stat.math.ethz.ch  Thu Apr 23 12:40:22 2009
From: maechler at stat.math.ethz.ch (maechler at stat.math.ethz.ch)
Date: Thu, 23 Apr 2009 12:40:22 +0200 (CEST)
Subject: [Rd] incorrect output and segfaults from sprintf with %*d
	(PR#13667)
Message-ID: <20090423104022.8C0EA283415A@mail.pubhealth.ku.dk>

>>>>> "vQ" == Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no>
>>>>>     on Thu, 23 Apr 2009 11:49:54 +0200 writes:

    vQ> maechler at stat.math.ethz.ch wrote:
    >> 
    vQ> sprintf has a documented limit on strings included in the output using the
    vQ> format '%s'.  It appears that there is a limit on the length of strings included
    vQ> with, e.g., the format '%d' beyond which surprising things happen (output
    vQ> modified for conciseness):
    >> 

    vQ> ... and this limit is *not* documented.

well, it is basically (+ a few bytes ?)
the same  8192  limit that *is* documented.

    vQ> gregexpr('1', sprintf('%9000d', 1))
    vQ> # [1] 9000 9801
    >> 
    vQ> gregexpr('1', sprintf('%9000d', 1))
    vQ> # [1]  9000  9801 10602
    >> 
    vQ> gregexpr('1', sprintf('%9000d', 1))
    vQ> # [1]  9000  9801 10602 11403
    >> 
    vQ> gregexpr('1', sprintf('%9000d', 1))
    vQ> # [1]  9000  9801 10602 11403 12204
    >> 
    vQ> ...
    >> 
    vQ> Note that not only more than one '1' is included in the output, but also that
    vQ> the same functional expression (no side effects used beyond the interface) gives
    vQ> different results on each execution.  Analogous behaviour can be observed with
    vQ> '%nd' where n > 8200.
    >> 
    vQ> The actual output above is consistent across separate sessions.
    >> 
    vQ> With sufficiently large field width values, R segfaults:
    >> 
    vQ> sprintf('%*d', 10^5, 1)
    vQ> # *** caught segfault ***
    vQ> # address 0xbfcfc000, cause 'memory not mapped'
    vQ> # Segmentation fault
    >> 
    >> 
    >> Thank you, Wacek.
    >> That's all ``interesting''  ... unfortunately, 
    >> 
    >> my version of  'man 3 sprintf' contains
    >> 
    >> 
    >>>> BUGS
    >>>> Because sprintf() and vsprintf() assume an arbitrarily
    >>>> long string, callers must be careful not to overflow the
    >>>> actual space; this is often impossible to assure. Note
    >>>> that the length of the strings produced is
    >>>> locale-dependent and difficult to predict.  Use
    >>>> snprintf() and vsnprintf() instead (or asprintf() and vasprintf).

    vQ> yes, but this is c documentation, not r documentation.

Of course! ...  and I  *do*  apply it to R's C code [sprintf.c]
and hence am even concurring with you .. 

    vQ> it's applicable
    vQ> to a degree, since ?sprintf does say that sprintf is "a wrapper for the
    vQ> C function 'sprintf'".  however, in c you use a buffer and you usually
    vQ> have control over it's capacity, while in r this is a hidden
    vQ> implementational detail, which should not be visible to the user, or
    vQ> should cause an attempt to overflow the buffer to fail more gracefully
    vQ> than with a segfault.

    vQ> in r, sprintf('%9000d', 1) will produce a confused output with a count
    vQ> of 1's variable (!) across runs (while sprintf('%*d', 9000, 1) seems to
    vQ> do fine):

    vQ> gregexpr('1', sprintf('%*d', 9000, 1))
    vQ> # [1] 9000

    vQ> gregexpr('1', sprintf('%9000d', 1))
    vQ> # [1] 9000 9801 ..., variable across executions

    vQ> on one execution in a series i actually got this:

    vQ> Warning message:
    vQ> In gregexpr("1", sprintf("%9000d", 1)) :
    vQ> input string 1 is invalid in this locale

    vQ> while the very next execution, still in the same session, gave

    vQ> # [1]  9000  9801 10602

    vQ> with sprintf('%*d', 10000, 1) i got segfaults on some executions but
    vQ> correct output on others, while sprintf('%10000d', 1) is confused again.



    >> (note the "impossible" part above)       
    >> 

    vQ> yes, but it does also say "must be careful", and it seems that someone
    vQ> has not been careful enough.

    >> and we haven't used  snprintf() yet, probably because it
    >> requires the  C99 C standard, and AFAIK, we have only relatively
    >> recently started to more or less rely on C99 in the R sources.
    >> 

    vQ> while snprintf would help avoid buffer overflow, it may not be a
    vQ> solution to the issue of confused output.

I think it would / will.  We would be able to give warnings and
errors, by checking the  snprintf()  return codes.


    >> More precisely, I see that some windows-only code relies on
    >> snprintf() being available  whereas in at least on non-Windows
    >> section, I read   /* we cannot assume snprintf here */
    >> 
    >> Now such platform dependency issues and corresponding configure
    >> settings I do typically leave to other R-corers with a much
    >> wider overview about platforms and their compilers and C libraries.
    >> 

    vQ> it looks like src/main/sprintf.c is just buggy, and it's plausible that
    vQ> the bug could be repaired in a platform-independent manner.

definitely.
In the mean time, I've actually found that what I first said on
the usability of snprintf() in R's code base was only partly correct.
There are other parts of R code where we use  snprintf() for all
platforms, hence we rely on its presence (and correct
implementation!) and so we can and I think should use it in
place of sprintf() in quite a few places inside R's sprintf.c


    >> BTW,  
    >> 1) sprintf("%n %g", 1,1)   also seg.faults
    >> 

    vQ> as do

    vQ> sprintf('%n%g', 1, 1)
    vQ> sprintf('%n%')

    vQ> etc., while

    vQ> sprintf('%q%g', 1, 1)
    vQ> sprintf('%q%')
  
    vQ> work just fine.  strange, because per ?sprintf 'n' is not recognized as
    vQ> a format specifier, so the output from the first two above should be as
    vQ> from the last two above, respectively.  (and likewise in the %S case,
    vQ> discussed and bug-reported earlier.)

I have now fixed these bugs at least;
the more subtle  "%<too_large_n>d" ones are different, and
as I said, I'm convinced that a nice & clean fix for those will
start using snprintf().

    >> 2) Did you have a true use case where  the  8192  limit was an
    >> undesirable limit?

    vQ> how does it matter?  

well, we could increase it, if it did matter.
      {{ you *could* have been more polite here, no?
      	 it *was* after all a serious question that I asked! }}

    vQ>  if you set a limit, be sure to consistently enforce
    vQ> it and warn the user on attempts to exceed it.  or write clearly in the
    vQ> docs that such attempts will cause the output to be silently truncated. 

Sure, I'm not at all disagreeing on that, and if you read this into my
posting, you misunderstand.

Martin

    vQ> examples such as

    vQ> sprintf('%9000d', 1)

    vQ> do not contribute to the reliability of r, and neither to the user's
    vQ> confidence in it.

    vQ> vQ


From savicky at cs.cas.cz  Thu Apr 23 12:49:01 2009
From: savicky at cs.cas.cz (Petr Savicky)
Date: Thu, 23 Apr 2009 12:49:01 +0200
Subject: [Rd] 'is.integer' (PR#13671)
In-Reply-To: <18928.14049.374028.202617@lynne.math.ethz.ch>
References: <20090422174516.2EB1928321BF@mail.pubhealth.ku.dk>
	<49EF7FF1.704@acm.org>
	<18928.14049.374028.202617@lynne.math.ethz.ch>
Message-ID: <20090423104901.GB13115@cs.cas.cz>

On Thu, Apr 23, 2009 at 11:37:37AM +0200, Martin Maechler wrote:
[snip]
>     TP> To test whether a value is an integer value, you can so something like this:
> 
>     >> is.wholenumber <- function(x, tolerance = .Machine$double.eps^0.5) 
>     TP> return(abs(x - round(x)) < tolerance)
>     >> is.wholenumber(1)
>     TP> [1] TRUE
>     >> is.wholenumber(seq(1,5,by=0.5))
>     TP> [1]  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE
>     >> 
> 
> Thank you, Tony.
> 
> Somewhat contrary to our (R-core) beliefs that a reference
> should be concise and correct, I have now added (an abridged
> version of) the is.wholenumber() function to the *examples* 
> on the  help(is.integer)  page and a note too.
> 
> Let's pretend we hope that this will stop such bug reports 
> ;-)

Besides the current bug report caused by misunderstanding of the
difference between a value and a data type, there are also discussions
concerning rounding errors of decimal numbers. These are, unfortunately,
quite frequent. If i can make a suggestion in order to (at least try to)
minimize also such discussions, may be it could help, if the contents of FAQ,
which is at the top of the FAQ page, contains the word accuracy. The path
to FAQ 7.31 discussing this topic goes through titles of sections
  R Miscellanea
and
  Why doesn't R think these numbers are equal? 

May be, if the name of "R Miscellanea" is more specific and contains the
word "accuracy" or if there is a section specifically for accuracy
issues, people would find the information in FAQ 7.31 more easily.

Petr.


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Thu Apr 23 15:05:21 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Waclaw.Marcin.Kusnierczyk at idi.ntnu.no)
Date: Thu, 23 Apr 2009 15:05:21 +0200 (CEST)
Subject: [Rd] incorrect output and segfaults from sprintf with %*d
	(PR#13667)
Message-ID: <20090423130521.E93BB2834323@mail.pubhealth.ku.dk>

Martin Maechler wrote:
>>>>>> "vQ" == Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no>
>>>>>>     on Thu, 23 Apr 2009 11:49:54 +0200 writes:
>>>>>>             
>
>     vQ> maechler at stat.math.ethz.ch wrote:
>     >> 
>     vQ> sprintf has a documented limit on strings included in the output using the
>     vQ> format '%s'.  It appears that there is a limit on the length of strings included
>     vQ> with, e.g., the format '%d' beyond which surprising things happen (output
>     vQ> modified for conciseness):
>     >> 
>
>     vQ> ... and this limit is *not* documented.
>
> well, it is basically (+ a few bytes ?)
> the same  8192  limit that *is* documented.
>   

martin, ?sprintf says:

" There is a limit of 8192 bytes on elements of 'fmt' and also on
     strings included by a '%s' conversion specification."

for me, it's clear that the *elements of fmt* cannot be longer than 8192
bytes, and that each single bit included in the output in place of a %s
cannot be longer than 8192.  nowhere does it say that strings included
in the output in place of a %d, for example, cannot be longer than
8192.  the fact that %s is particularized makes me infer that there is
something specific to %s that does not apply to %d, for example,
otherwise the help would have been formulated differently.  (though
given how r help pages are written, nothing seems unlikely.)

and in fact, the limit does not seem to apply in an obvious way in cases
such as sprintf('%*d', 10000, 1), where the output is correct.  at the
very least, the documentation leaves the user ignorant as to what will
happen if the limit is exceeded.

>     >> my version of  'man 3 sprintf' contains
>     >> 
>     >> 
>     >>>> BUGS
>     >>>> Because sprintf() and vsprintf() assume an arbitrarily
>     >>>> long string, callers must be careful not to overflow the
>     >>>> actual space; this is often impossible to assure. Note
>     >>>> that the length of the strings produced is
>     >>>> locale-dependent and difficult to predict.  Use
>     >>>> snprintf() and vsnprintf() instead (or asprintf() and vasprintf).
>
>     vQ> yes, but this is c documentation, not r documentation.
>
> Of course! ...  and I  *do*  apply it to R's C code [sprintf.c]
> and hence am even concurring with you .. 
>
>
>     vQ> while snprintf would help avoid buffer overflow, it may not be a
>     vQ> solution to the issue of confused output.
>
> I think it would / will.  We would be able to give warnings and
> errors, by checking the  snprintf()  return codes.
>   

maybe, i can't judge without carefully examining the code for sprintf.c
(which i am rather unwilling to do, having had a look at a sample).

>
>     >> More precisely, I see that some windows-only code relies on
>     >> snprintf() being available  whereas in at least on non-Windows
>     >> section, I read   /* we cannot assume snprintf here */
>     >> 
>     >> Now such platform dependency issues and corresponding configure
>     >> settings I do typically leave to other R-corers with a much
>     >> wider overview about platforms and their compilers and C libraries.
>     >> 
>
>     vQ> it looks like src/main/sprintf.c is just buggy, and it's plausible that
>     vQ> the bug could be repaired in a platform-independent manner.
>
> definitely.
> In the mean time, I've actually found that what I first said on
> the usability of snprintf() in R's code base was only partly correct.
> There are other parts of R code where we use  snprintf() for all
> platforms, hence we rely on its presence (and correct
> implementation!) and so we can and I think should use it in
> place of sprintf() in quite a few places inside R's sprintf.c
>
>   

would be interesting to see how this improves sprintf.

>     >> BTW,  
>     >> 1) sprintf("%n %g", 1,1)   also seg.faults
>     >> 
>
>     vQ> as do
>
>     vQ> sprintf('%n%g', 1, 1)
>     vQ> sprintf('%n%')
>
>     vQ> etc., while
>
>     vQ> sprintf('%q%g', 1, 1)
>     vQ> sprintf('%q%')
>   
>     vQ> work just fine.  strange, because per ?sprintf 'n' is not recognized as
>     vQ> a format specifier, so the output from the first two above should be as
>     vQ> from the last two above, respectively.  (and likewise in the %S case,
>     vQ> discussed and bug-reported earlier.)
>
> I have now fixed these bugs at least;
>   

great, i'm going to torture the fix soon ;)

> the more subtle  "%<too_large_n>d" ones are different, and
> as I said, I'm convinced that a nice & clean fix for those will
> start using snprintf().
>
>     >> 2) Did you have a true use case where  the  8192  limit was an
>     >> undesirable limit?
>
>     vQ> how does it matter?  
>
> well, we could increase it, if it did matter.
>       {{ you *could* have been more polite here, no?
>   

i don't see how i could be more polite here, i had absolutely no
intention to be impolite and didn't think i were. 

i gave a serious answer by means of a serious question.  increasing an
arbitrary, poorly documented limit of obscure effect is hardly any
solution.  suggesting that a bug is not a bug because some limit is not
likely to be exceeded in practice is not a particularly good idea.


>       	 it *was* after all a serious question that I asked! }}
>
>     vQ>  if you set a limit, be sure to consistently enforce
>     vQ> it and warn the user on attempts to exceed it.  or write clearly in the
>     vQ> docs that such attempts will cause the output to be silently truncated. 
>
> Sure, I'm not at all disagreeing on that, and if you read this into my
> posting, you misunderstand.
>   

no, i didn't read that into your posting, i'm just referring to the
state of the 'art' in r.

cheers,
vQ


From h.wickham at gmail.com  Thu Apr 23 15:08:24 2009
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 23 Apr 2009 08:08:24 -0500
Subject: [Rd] 'is.integer' (PR#13671)
In-Reply-To: <18928.13118.892491.84418@lynne.math.ethz.ch>
References: <20090422174516.2EB1928321BF@mail.pubhealth.ku.dk>
	<8b356f880904221330r2c2776cid12036442511b216@mail.gmail.com>
	<18928.13118.892491.84418@lynne.math.ethz.ch>
Message-ID: <f8e6ff050904230608y31018934o235724cb3d6fccbc@mail.gmail.com>

> *However*, Mauricio submitted a *formal* bug report against R
> and there are many caveats against doing that "light-heartedly".
> Note that he also said

I know it's frustrating when people repeatedly ask this question (and
file bug reports related to it), but does it really take that long to
tell them to check out FAQ 7.31, and to close the bug report?

Hadley


-- 
http://had.co.nz/


From maechler at stat.math.ethz.ch  Thu Apr 23 15:15:22 2009
From: maechler at stat.math.ethz.ch (maechler at stat.math.ethz.ch)
Date: Thu, 23 Apr 2009 15:15:22 +0200 (CEST)
Subject: [Rd] incorrect output and segfaults from sprintf with %*d
	(PR#13667)
Message-ID: <20090423131522.5A9042834320@mail.pubhealth.ku.dk>

>>>>> "vQ" == Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no>
>>>>>     on Thu, 23 Apr 2009 15:00:29 +0200 writes:

    vQ> Martin Maechler wrote:
    >>>>>>> "vQ" == Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no>
    >>>>>>> on Thu, 23 Apr 2009 11:49:54 +0200 writes:


[......................]
[......................]

    >> >> BTW,  
    >> >> 1) sprintf("%n %g", 1,1)   also seg.faults
    >> >> 
    >> 
    vQ> as do
    >> 
    vQ> sprintf('%n%g', 1, 1)
    vQ> sprintf('%n%')
    >> 
    vQ> etc., while
    >> 
    vQ> sprintf('%q%g', 1, 1)
    vQ> sprintf('%q%')
    >> 
    vQ> work just fine.  strange, because per ?sprintf 'n' is not recognized as
    vQ> a format specifier, so the output from the first two above should be as
    vQ> from the last two above, respectively.  (and likewise in the %S case,
    vQ> discussed and bug-reported earlier.)
    >> 
    >> I have now fixed these bugs at least;
    >> 

    vQ> great, i'm going to torture the fix soon ;)

there will be another one, still today, fixing the

      sprintf("%s", tryCatch(stop(), error=identity))

bug {which actually *is* a subtle, too}

    >> the more subtle  "%<too_large_n>d" ones are different, and
    >> as I said, I'm convinced that a nice & clean fix for those will
    >> start using snprintf().
    >> 
    >> >> 2) Did you have a true use case where  the  8192  limit was an
    >> >> undesirable limit?
    >> 
    vQ> how does it matter?  
    >> 
    >> well, we could increase it, if it did matter.
    >> {{ you *could* have been more polite here, no?
    >> 

    vQ> i don't see how i could be more polite here, i had absolutely no
    vQ> intention to be impolite and didn't think i were. 

    vQ> i gave a serious answer by means of a serious question.  increasing an
    vQ> arbitrary, poorly documented limit of obscure effect is hardly any
    vQ> solution.  suggesting that a bug is not a bug because some limit is not
    vQ> likely to be exceeded in practice is not a particularly good idea.

But that's exactly what I did  NOT  suggest!!

It was a serious question, *related* to your bug report, but
*NOT* really on the bug report proper.
[It *was* under the "heading" of 'BTW' which I assumed you knew
 to interpret]
I was seriously asking, if BTW, the limit which is there was
possibly to be increased or not...


    >> it *was* after all a serious question that I asked! }}
    >> 
    vQ> if you set a limit, be sure to consistently enforce
    vQ> it and warn the user on attempts to exceed it.  or write clearly in the
    vQ> docs that such attempts will cause the output to be silently truncated. 
    >> 
    >> Sure, I'm not at all disagreeing on that, and if you read this into my
    >> posting, you misunderstand.
    >> 

    vQ> no, i didn't read that into your posting, i'm just referring to the
    vQ> state of the 'art' in r.

[not so funny...  yet another "very polite" assumption.]

    vQ> cheers,
    vQ> vQ


From romain.francois at dbmail.com  Thu Apr 23 15:49:15 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Thu, 23 Apr 2009 15:49:15 +0200
Subject: [Rd] Custom browser prompt instead of Browse[1]>
Message-ID: <49F071DB.2090406@dbmail.com>

Hello,

Would it be possible to have a custom prompt when browser()'ing.

I have made a simple implementation of this (which is attached), the 
basic idea is that instead of the hardcoded sprintf( "Browser[%d]> ", 
browselevel), a call to the getBrowsePrompt is made, and obviously the 
function is:

 > getBrowsePrompt
function (level = 1, env = .GlobalEnv) {
    sprintf("Browse[%d]> ", level)
}
<environment: namespace:base>

 > debug( rnorm )
 > rnorm( 10 )
debugging in: rnorm(10)
debug: .Internal(rnorm(n, mean, sd))
Browse[1]>
exiting from: rnorm(10)
 [1] -0.496598526 -0.006482431  1.491833990 -2.602605734 -0.275479145
 [6] -1.143580117  0.146797854 -0.529420397  0.823817647 -0.256676050

but then it can be masked so that a more informative prompt is given, 
like this for example (showing the call stack)

 > getBrowsePrompt
function( level = 1, env = .GlobalEnv){
 calls <- sys.calls()
 stack <- sapply( calls[-1], function(x) tryCatch(as.character(x[[1]]), 
error=function(e) "?") )
 sprintf( "Browse[%d] %s > ", level, paste( stack, collapse = " -> ") )
}
 > f()
debugging in: rnorm(10)
debug: .Internal(rnorm(n, mean, sd))
Browse[1] rnorm -> getBrowsePrompt >
exiting from: rnorm(10)
 [1] -0.53854862 -1.42674850 -0.48391168 -0.23446819 -0.36863380  0.53803626
 [7]  1.70176078  0.82984068  1.05101379 -0.03944557

Or this: printing the content of the environment we are browsing :

 > getBrowsePrompt <- function( level = 1, env = .GlobalEnv ){
+   print( ls.str( envir = env) )
+   base:::getBrowsePrompt( level, env )
+ }
 > f()
debugging in: rnorm(10)
debug: .Internal(rnorm(n, mean, sd))
mean :  num 0
n :  num 10
sd :  num 1
Browse[1]>
exiting from: rnorm(10)
 [1]  1.1112007  0.4921306  0.1747196 -0.2518565 -0.9342039  0.5930085
 [7] -0.5961234  0.1153541 -0.6189056  0.1670318

This probably should rely on an option instead of relying on masking 
functions. Also this opens a back door to the debugging system of R, but 
I am not sure this is entirely a bad thing. (see 
http://www.statistik.lmu.de/~eugster/soc09/#p5)

On the same note, what about having a function for the prompt, so that 
(for example) we could show the current working directory, the memory 
usage, ...


Romain

-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


-------------- next part --------------
A non-text attachment was scrubbed...
Name: browser.diff
Type: text/x-patch
Size: 2030 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090423/06a03820/attachment.bin>

From maechler at stat.math.ethz.ch  Thu Apr 23 16:05:23 2009
From: maechler at stat.math.ethz.ch (maechler at stat.math.ethz.ch)
Date: Thu, 23 Apr 2009 16:05:23 +0200 (CEST)
Subject: [Rd] matplot does not considere the parametre lend (PR#13619)
Message-ID: <20090423140523.C542A283431B@mail.pubhealth.ku.dk>

>>>>> "DM" == Duncan Murdoch <murdoch at stats.uwo.ca>
>>>>>     on Mon, 23 Mar 2009 19:35:15 -0400 writes:

    DM> On 23/03/2009 7:25 PM, cgenolin at u-paris10.fr wrote:
    >> Full_Name: Christophe Genolini
    >> Version: 2.8.1, but also 2.9
    >> OS: Windows XP
    >> Submission from: (NULL) (82.225.59.146)
    >> 
    >> 
    >> I am using matplot with the option lend="butt", but only the first line (the
    >> black) is printed correctly  :
    >> 
    >>> matplot(matrix(1:9,3),type="c",lwd=10,lty=1,lend="butt")

    DM> I'd call this another case where it is performing as documented, but 
    DM> should probably be changed (but not by me).  

I have now added the desired feature to R-devel and 
'R 2.9.0 patched'.

Martin Maechler


    DM> In the meantime, there's  the simple workaround:

    DM> save <- par(lend="butt")
    DM> matplot(matrix(1:9,3),type="c",lwd=10,lty=1)
    DM> par(save)

    DM> Duncan Murdoch

    >> 
    >> Gabor Grothendieck find the problem in matplot code:
    >> the ... is passed to plot (which plots the first series) but not to lines (which
    >> plots the rest):
    >> 
    >> if (!add) {
    >> ii <- ii[-1]
    >> plot(x[, 1], y[, 1], type = type[1], xlab = xlab, ylab = ylab,
    >> xlim = xlim, ylim = ylim, lty = lty[1], lwd = lwd[1],
    >> pch = pch[1], col = col[1], cex = cex[1], bg = bg[1],
    >> ...)
    >> }
    >> for (i in ii) {
    >> lines(x[, i], y[, i], type = type[i], lty = lty[i], lwd = lwd[i],
    >> pch = pch[i], col = col[i], cex = cex[i], bg = bg[i])
    >> }
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel

    DM> ______________________________________________
    DM> R-devel at r-project.org mailing list
    DM> https://stat.ethz.ch/mailman/listinfo/r-devel


From tplate at acm.org  Thu Apr 23 17:19:08 2009
From: tplate at acm.org (Tony Plate)
Date: Thu, 23 Apr 2009 09:19:08 -0600
Subject: [Rd] Suggestion for changing r-project.org webpage text around bug
 reporting (was Re: 'is.integer' (PR#13671))
In-Reply-To: <18928.13118.892491.84418@lynne.math.ethz.ch>
References: <20090422174516.2EB1928321BF@mail.pubhealth.ku.dk>	<8b356f880904221330r2c2776cid12036442511b216@mail.gmail.com>
	<18928.13118.892491.84418@lynne.math.ethz.ch>
Message-ID: <49F086EC.9070309@acm.org>

Martin Maechler wrote:
>>>>>> "SM" == Stavros Macrakis <macrakis at alum.mit.edu>
>>>>>>     on Wed, 22 Apr 2009 16:30:36 -0400 writes:
>>>>>>             
>
>     SM> Dear R experts,
>     SM> You are being a bit harsh on this user. 
>
> No! (see below)
>
>     SM> He simply doesn't understand
>     SM> the distinction between "object of type integer" and "integer-valued
>     SM> object", which is actually fairly subtle.
>
> yes, probably for the vast majority of today's R users.
>
> *However*, Mauricio submitted a *formal* bug report against R
> and there are many caveats against doing that "light-heartedly".
> Note that he also said
>
>  >> I would really appreciate if you could clarify if this is
>  >> really a bug or not. 
>
> and that this is exactly one of situation where one should post
> a question to R-help (or maybe R-devel) but *NOT* submit a
> formal bug report.
>
> Regards,
> Martin
>   
Yep, but still, bug reports are a valuable service provided by the user 
community, and false bug reports are treated in a rather harsh manner by 
the R community.  It looks to me like it would be quite easy to give 
users a much better idea of the treatment they will receive for abusing 
the bug reporting system by making the web page text around bug 
reporting much harsher than it currently is.

If you go to r-project.org and click on "Bug tracking", you first see 
http://bugs.r-project.org/cgi-bin/R

> You can submit new bug reports either using an online form by
> clicking on the button below or by sending email to 
> r-bugs at r-project.org <mailto:r-bugs at r-project.org>.
Then, clicking "Submit new report", you see:
>
> Before submitting a bug report, please read Chapter `R Bugs' of `The R 
> FAQ' <http://cran.r-project.org/doc/FAQ/R-FAQ.html#R-Bugs>. It 
> describes what a bug is and how to report a bug.
>
> If you are not sure whether you have observed a bug or not, it is a 
> good idea to ask on the mailing list R-Help 
> <https://www.stat.math.ethz.ch/mailman/listinfo/r-help> by sending an 
> e-mail to r-help at stat.math.ethz.ch <mailto:r-help at stat.math.ethz.ch> 
> rather than submitting a bug report.
>
All of these blocks of text are misleadingly mild and friendly.  I 
suggest the following as more appropriate (including the shouting).  And 
don't make the r-bugs at r-project.org address a clickable link, but do 
make the r-help and r-devel addresses hyperlinks:
> The bug repository is for use by R experts only.  DO NOT USE THE BUG 
> REPOSITORY FOR QUESTIONS ABOUT THE BEHAVIOR OF R, EVEN IF IT LOOKS 
> ODD.  Submit a bug report either using an online form by clicking on 
> the button below or by sending email to r-bugs at r-project.org 
> <mailto:r-bugs at r-project.org>.  For questions about the behavior of R 
> functions (including such things as 1/7 * 7 not always being exactly 
> equal to 7 in floating point arithmetic), send email to 
> r-help at r-project.org.  For questions involving  esoteric programming 
> issues in R, send email to r-devel at r-project.org.
And then after clicking "Submit new report", show this:
> The bug repository is for use by R experts only.  If you have not 
> submitted a bug report before, YOU MUST READ Chapter `R Bugs' of `The 
> R FAQ' <http://cran.r-project.org/doc/FAQ/R-FAQ.html#R-Bugs>. It 
> describes what a bug is and how to report a bug.  Also, you should at 
> least scan the contents section of `The R FAQ' 
> <http://cran.r-project.org/doc/FAQ/R-FAQ.html#R-Bugs> to make sure 
> that you are not reasking a FAQ.
> If you not absolutely sure that you have observed a bug, DO NOT SUBMIT 
> A BUG REPORT.  Instead, send a question to the mailing list R-Help 
> <https://www.stat.math.ethz.ch/mailman/listinfo/r-help> by sending an 
> e-mail to r-help at stat.math.ethz.ch <mailto:r-help at stat.math.ethz.ch> .
I suspect that making changes like this would improve things for 
everybody.  The R maintainers will have to deal with less false bug 
reports, naive users will avoid harsh criticisms, and bystanders will 
witness fewer wince-inducing lashings.

And yes, it's more words, but it's boilerplate that experienced eyes can 
easily skip over.

-- Tony Plate

[rest of correspondence regarding is.integer() clipped]


From friedrich.leisch at stat.uni-muenchen.de  Thu Apr 23 17:44:45 2009
From: friedrich.leisch at stat.uni-muenchen.de (Friedrich Leisch)
Date: Thu, 23 Apr 2009 17:44:45 +0200
Subject: [Rd] RFC: Ability to suppress 'locale' from sessionInfo
In-Reply-To: <1CF05FF1-8327-4E3A-AC93-4991458FC154@stat.berkeley.edu>
References: <5c62e0070904211916w36310bfdsd720fae189cad25b@mail.gmail.com>
	<18926.50861.369595.3396@lxh5.stat.uni-muenchen.de>
	<49EECDEA.9020800@telenet.be>
	<18926.55876.329732.6352@lynne.math.ethz.ch>
	<1CF05FF1-8327-4E3A-AC93-4991458FC154@stat.berkeley.edu>
Message-ID: <18928.36077.615345.938907@lxh5.stat.uni-muenchen.de>

>>>>> On Wed, 22 Apr 2009 12:49:05 -0700,
>>>>> Kasper Daniel Hansen (KDH) wrote:

  > This is a better way, it does two things
  > a) enclose the itemize environment in a flushleft environment - this  
  > gives us much better line breaks for the verb.
  > b) does a replace of ";" with ";| \verb|" so that each "component" of  
  > the locale gets enclosed in its own \verb command, which allows latex  
  > to produce line breaks (since I am using gsub, I do gsub(";", ";| \\\ 
  > \verb", object$locale))

  > Below is a proposed utils:::toLatex.sessionInfo

Thanks, I have integrated it into the devel branch, and also modified
the print method to split the locale information:

R> sessionInfo()
R version 2.10.0 Under development (unstable) (2009-04-23 r48380) 
x86_64-unknown-linux-gnu 

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


The default for the new locale argument is TRUE.

Best,
Fritz


From england at cs.umn.edu  Thu Apr 23 17:54:31 2009
From: england at cs.umn.edu (Darin A. England)
Date: Thu, 23 Apr 2009 10:54:31 -0500
Subject: [Rd] Problems building R 2.9.0... on SGI and Sun once again
In-Reply-To: <200904201154.n3KBswHQ013943@ruuvi.it.helsinki.fi>
References: <200904201154.n3KBswHQ013943@ruuvi.it.helsinki.fi>
Message-ID: <20090423155431.GA6821@cs.umn.edu>

I have the same problem trying build R 2.9.0 on AIX using the IBM 
Visual Age compilers and GNU make. I'm trying to figure it out, but
any hints on a fix are greatly appreciated.
Thanks,
Darin

gmake[2]: Entering directory `/home/denglan/R/builddir/src/library/methods'
building package 'methods'
mkdir ../../../library/methods
gmake[3]: Entering directory `/home/denglan/R/builddir/src/library/methods'
mkdir ../../../library/methods/R
/bin/sh: syntax error at line 1 : `;' unexpected
gmake[3]: *** [front] Error 2
gmake[3]: Leaving directory `/home/denglan/R/builddir/src/library/methods'
gmake[2]: *** [all] Error 2
gmake[2]: Leaving directory `/home/denglan/R/builddir/src/library/methods'
gmake[1]: *** [R] Error 1
gmake[1]: Leaving directory `/home/denglan/R/builddir/src/library'
gmake: *** [R] Error 1
make: The error code from the last command is 1.


On Mon, Apr 20, 2009 at 02:54:58PM +0300, Atro Tossavainen wrote:
> I've successfully built R 2.9.0 on Linux (amd64, i386 and ppc), but am
> having a bit of trouble with legacy boxen.  What should have gone into
> the variable that is empty at the time it is used in "for f in $SOMETHING"
> and why does it end up being empty?
> 
> Solaris 8 with Sun Studio 11 compilers:
> 
> building package 'methods'
> gmake[4]: Entering directory `/scratch/atossava/R-2.9.0/src/library/methods'
> all.R is unchanged
> /bin/bash: -c: line 1: syntax error near unexpected token `;'
> /bin/bash: -c: line 1: `for f in ; do  if test -f ./${f}; then  ../../../tools/install-sh -c -m 644 ./${f}  ../../../library/methods;  fi;  done'
> gmake[4]: *** [front] Error 2
> gmake[4]: Leaving directory `/scratch/atossava/R-2.9.0/src/library/methods'
> 
> IRIX 6.5 with MIPSpro 7.4.4 compilers:
> 
> building package 'methods'
> gmake[4]: Entering directory `/wrk/atossava/R-2.9.0/src/library/methods'
> all.R is unchanged
> /bin/sh: syntax error at line 1 : `;' unexpected
> gmake[4]: *** [front] Error 2
> gmake[4]: Leaving directory `/wrk/atossava/R-2.9.0/src/library/methods'
> 
> -- 
> Atro Tossavainen (Mr.)               / The Institute of Biotechnology at
> Systems Analyst, Techno-Amish &     / the University of Helsinki, Finland,
> +358-9-19158939  UNIX Dinosaur     / employs me, but my opinions are my own.
> < URL : http : / / www . helsinki . fi / %7E atossava / > NO FILE ATTACHMENTS
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hzambran.newsgroups at gmail.com  Thu Apr 23 14:35:48 2009
From: hzambran.newsgroups at gmail.com (Mauricio Zambrano)
Date: Thu, 23 Apr 2009 14:35:48 +0200
Subject: [Rd] 'is.integer' (PR#13671)
In-Reply-To: <9C0B0125E5094F7482810D54D713F6EC@G3>
References: <20090422174516.2EB1928321BF@mail.pubhealth.ku.dk>
	<9C0B0125E5094F7482810D54D713F6EC@G3>
Message-ID: <63d616b0904230535m46ad18d2rebe33df6907b11e6@mail.gmail.com>

Thanks for the clear answer Stephen and thanks to all the guys that
pointed out my misunderstanding about the distinction between object
of type integer" and "integer-valued object".

I'm sorry for submitting to the R-bugs list something that is very
clear for all the members of the list, but it was not clear for me
after reading the help, because I was testing if a particular result
had a decimal part or not, and it seemed natural to me to use the
'is.integer' function instead of a combination of other operations.

Probably, and only if the guys of r-devel deem it necessary, it could
be good to add a small example at the end of the 'is.integer' function
showing that is.integer(1) is FALSE (or the example mentioned by
Martin), which can avoid this misunderstanding to people with less
knowledge about storage modes in R.

Thank you very much, and in the future I will use R-help or maybe R-devel.

Mauricio
-- 
Linux user  #454569 -- Ubuntu user #17469


From mdowle at mdowle.plus.com  Thu Apr 23 01:36:48 2009
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Thu, 23 Apr 2009 00:36:48 +0100
Subject: [Rd] Closed-source non-free ParallelR ?
References: <373DCC90906D430E952EF2C423B0D91B@ADAM>
	<ac81d400904220740i5a4adac4l41b1a170c6f27bd7@mail.gmail.com>
	<475a3c8f0904220836w43d07042m84f42edf6e05766c@mail.gmail.com>
Message-ID: <E1C5F6F55B4445AF902DF4B970BE1688@ADAM>

> how could it [MCE] swap a GPL license for the BSD?
Because the BSD is an open source license compatible with GPL.  See 
http://www.fsf.org/licensing/licenses/index_html#GPLCompatibleLicenses

> derivative work
Points taken. It may not be derivation in the sense of modification, more in 
the sense of using R as a library :
http://www.gnu.org/licenses/gpl-faq.html#GPLInProprietarySystem
http://www.gnu.org/licenses/gpl-faq.html#IfLibraryIsGPL
http://www.gnu.org/licenses/gpl-faq.html#LinkingWithGPL
http://www.gnu.org/licenses/gpl-faq.html#IfInterpreterIsGPL  (paragraphs 3 
and 4 in particular)

R, and base functions written in R, are GPL not LGPL.  In the context of the 
FAQ above, do your packages use base functions ?
http://www.gnu.org/philosophy/why-not-lgpl.html

The first R FAQ (1.1) states that R is released under GPL version 2 or any 
later version.
At the end of the GPL (both v2 and v3) it says "This General Public License 
does not permit incorporating your program into proprietary programs. If 
your program is a subroutine library, you may consider it more useful to 
permit linking proprietary applications with the library. If this is what 
you want to do, use the GNU Lesser General Public License instead of this 
License."

> there are certainly many existing R packages with non-free/non-open 
> licenses
They could be in breach too. The fact their licenses are like that does not 
in itself mean they are compliant with the GPL. R FAQ 2.11 defers to legal 
counsel - it mentions such licenses but it states no opinion about them as 
far as my reading goes. At least the source code of those packages is 
available for download. REvolution appear to be going one step further i.e. 
bundling R with their proprietary packages and selling the work as a whole.

Could someone from the R Foundation or the FSF step in and clarify the 
situation please ?   If in your opinion it is all fine what people are 
doing, why not release R under the LGPL for clarity ?

Regards, Matthew

----- Original Message ----- 
From: "David M Smith" <david at revolution-computing.com>
To: "Matthew Dowle" <mdowle at mdowle.plus.com>
Cc: "Patrick Shields" <pat at revolution-computing.com>; 
<r-devel at r-project.org>
Sent: Wednesday, April 22, 2009 4:36 PM
Subject: Re: [Rd] Closed-source non-free ParallelR ?


Patrick made all the points that I was going to make (thanks,
Patrick), but I wanted to reinforce one point that may be the source
of the confusion: ParallelR is not a modified version of R: ParallelR
is a suite of ordinary R packages that run on top of the R engine like
any other package. The R code and Python code in these packages were
written entirely by REvolution Computing staff (including Patrick),
and do not contain any code (derived or otherwise) from the R project.

In retrospect, the name ParallelR may be somewhat confusing in this sense...

# David Smith

On Wed, Apr 22, 2009 at 7:40 AM, Patrick Shields
<pat at revolution-computing.com> wrote:
> I'm Pat Shields, one of the software engineers working on ParallelR. I 
> just
> wanted to make two points: no R code or previously gpl'd code can be found
> in any of the non-gpl packages in ParallelR. I'm sure that the phrase
> "derived works" is a legally subtle one, but all these packages include 
> are
> R and occasionally python scripts (as well as the standard text
> documentation). If these are derived works, doesn't that mean that any R
> code is also, by extension, required to be GPL'd? If not, is it including
> these scripts in a package that forces the use of the GPL?
>
> Also, I'm confused about your dimissal of the MCE example. If that code 
> was
> a derivative work of R, how could it swap a GPL license for the BSD? I
> didn't think such a switch was possible. If it was, I'd imagine a lot more
> use of it, as a quick front project could make GPL software into BSD
> software after which all changes could go on behind closed doors.
>
> On Tue, Apr 21, 2009 at 7:38 PM, Matthew Dowle 
> <mdowle at mdowle.plus.com>wrote:
>
>> Dear R-devel,
>>
>> REvolution appear to be offering ParallelR only when bundled with their R
>> Enterprise edition. As such it appears to be non-free and closed source.
>> http://www.revolution-computing.com/products/parallel-r.php
>>
>> Since R is GPL and not LGPL, is this a breach of the GPL ?
>>
>> Below is the "GPL and ParallelR" thread from their R forum.
>>
>> mdowle > It appears that ParallelR (packages foreach and iterators) is
>> only available bundled with the Enterprise edition. Since R is GPL, and
>> ParallelR is derived from R, should ParallelR not also be GPL? Regards,
>> Matthew
>>
>> revolution > Hello Matthew, ParallelR consists of both proprietary and 
>> GPL
>> packages. The randomForest and snow libraries GPL licensed, whereas the
>> other libraries we include have a commercial license(including 'foreach' 
>> and
>> 'iterators'). Stephen Weller
>>
>> revolution > I wanted to expand on Stephen's reply. ParallelR is a suite 
>> of
>> R packages, and it is well established that packages can be under a
>> difference license than R itself (i.e. not the GPL). For example, package
>> MCE is licensed under BSD, RColorBrewer is licensed under Apache, most of
>> Bioconductor is under the Artistic license and some are under completely
>> unique licenses (e.g. mclust). REvolution Computing developed all of the
>> code in ParallelR (except for the bundled GPL packages Stephen mentions),
>> and we decided to release it under our own license in REvolution R
>> Enterprise.
>> That said, we do already release components of parallelR, such as the
>> underlying engine, Networkspaces (also written by REvolution Computing)
>> under an open source licence. Also, we are likely to release some other
>> components including foreach and iterators, to CRAN soon.
>> David Smith
>> Director of Community, REvolution Computing
>>
>> mdowle > The examples you give (MCE, RColorBrewer, Bioconductor) are all
>> available for free including the source code. Their licenses have been
>> approved by the FSF. Free software and open source are the terms of work
>> derived from GPL licensed software. REvolution's packages 'foreach' and
>> 'iterators' are neither free or open source. Can you provide a precedent
>> for proprietary closed-source packages for R ? Is your policy approved by
>> the FSF ?
>> I don't object to REvolution. I am a fan of you making money from 
>> training
>> courses, consultancy, support and binaries. These are all permitted by 
>> the
>> GPL. However the GPL does not allow you to distribute work derived from R
>> which is either closed source or non-free.
>> R is GPL, not LGPL.
>> The above is my personal understanding. I am now posting to r-devel to
>> check, feel free to join the public debate there.
>>
>> Regards, Matthew
>>
>> [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>
> --
> Pat Shields
> Software Engineer
> REvolution Computing
> One Century Tower | 265 Church Street, Suite 1006
> New Haven, CT 06510
> P: 203-777-7442 x250 | www.revolution-computing.com
>
> Check out our upcoming events schedule at
> www.revolution-computing.com/events
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
David M Smith <david at revolution-computing.com>
Director of Community, REvolution Computing www.revolution-computing.com
Tel: +1 (206) 577-4778 x3203 (San Francisco, USA)

Check out our upcoming events schedule at 
www.revolution-computing.com/events


From P.Dalgaard at biostat.ku.dk  Thu Apr 23 18:20:35 2009
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 23 Apr 2009 18:20:35 +0200
Subject: [Rd] Problems building R 2.9.0... on SGI and Sun once again
In-Reply-To: <20090423155431.GA6821@cs.umn.edu>
References: <200904201154.n3KBswHQ013943@ruuvi.it.helsinki.fi>
	<20090423155431.GA6821@cs.umn.edu>
Message-ID: <49F09553.4000705@biostat.ku.dk>

Darin A. England wrote:
> I have the same problem trying build R 2.9.0 on AIX using the IBM 
> Visual Age compilers and GNU make. I'm trying to figure it out, but
> any hints on a fix are greatly appreciated.


This seems to come from constructions of the form

for i in $FOO : do .... ; done

If $FOO is empty, then the resulting "for i in ;" is a syntax error with
some versions of bash and sh. Current Linux versions of bash do not have
that behaviour. As we saw in an earlier post, quotes around $FOO is not
the answer.

One workaround could be to upgrade bash.

Another workaround could be to safeguard the for-loop with

test "$FOO" != "" && for i in $FOO : do .... ; done

in all of the Makefiles where this can be an issue.




-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From Fraser_Sim at URMC.Rochester.edu  Thu Apr 23 18:30:52 2009
From: Fraser_Sim at URMC.Rochester.edu (Sim, Fraser)
Date: Thu, 23 Apr 2009 12:30:52 -0400
Subject: [Rd] Closed-source non-free ParallelR ?
In-Reply-To: <E1C5F6F55B4445AF902DF4B970BE1688@ADAM>
References: <373DCC90906D430E952EF2C423B0D91B@ADAM><ac81d400904220740i5a4adac4l41b1a170c6f27bd7@mail.gmail.com><475a3c8f0904220836w43d07042m84f42edf6e05766c@mail.gmail.com>
	<E1C5F6F55B4445AF902DF4B970BE1688@ADAM>
Message-ID: <82377DC24E19614291D0B5A4A89DAD7401159438@e2k3ms5.urmc-sh.rochester.edu>

Hi Matt,

Do you know if a project like R(D)COM/Statconn can changing their
license to make it closed-source? (www.statconn.com &
http://rcom.univie.ac.at/ )

There was discussion on the RCom board about such changes earlier this
year as they move toward commercialization. If you're not familiar it's
a package/windows COM program that allows EXCEL and other win apps to
interact directly with R. They have also generated an installer package
which installs R at the same time as their software. It makes 'R'
effectively disappear from the windows box.

Would distribution of that software also have to stay as GPL not LGPL?
As R effectively sits within the proprietary system of Statconn.

Regards, Fraser

-----Original Message-----
From: r-devel-bounces at r-project.org
[mailto:r-devel-bounces at r-project.org] On Behalf Of Matthew Dowle
Sent: Wednesday, April 22, 2009 7:37 PM
To: David M Smith; Patrick Shields; r-devel at r-project.org
Subject: Re: [Rd] Closed-source non-free ParallelR ?

> how could it [MCE] swap a GPL license for the BSD?
Because the BSD is an open source license compatible with GPL.  See 
http://www.fsf.org/licensing/licenses/index_html#GPLCompatibleLicenses

> derivative work
Points taken. It may not be derivation in the sense of modification,
more in 
the sense of using R as a library :
http://www.gnu.org/licenses/gpl-faq.html#GPLInProprietarySystem
http://www.gnu.org/licenses/gpl-faq.html#IfLibraryIsGPL
http://www.gnu.org/licenses/gpl-faq.html#LinkingWithGPL
http://www.gnu.org/licenses/gpl-faq.html#IfInterpreterIsGPL  (paragraphs
3 
and 4 in particular)

R, and base functions written in R, are GPL not LGPL.  In the context of
the 
FAQ above, do your packages use base functions ?
http://www.gnu.org/philosophy/why-not-lgpl.html

The first R FAQ (1.1) states that R is released under GPL version 2 or
any 
later version.
At the end of the GPL (both v2 and v3) it says "This General Public
License 
does not permit incorporating your program into proprietary programs. If

your program is a subroutine library, you may consider it more useful to

permit linking proprietary applications with the library. If this is
what 
you want to do, use the GNU Lesser General Public License instead of
this 
License."

> there are certainly many existing R packages with non-free/non-open 
> licenses
They could be in breach too. The fact their licenses are like that does
not 
in itself mean they are compliant with the GPL. R FAQ 2.11 defers to
legal 
counsel - it mentions such licenses but it states no opinion about them
as 
far as my reading goes. At least the source code of those packages is 
available for download. REvolution appear to be going one step further
i.e. 
bundling R with their proprietary packages and selling the work as a
whole.

Could someone from the R Foundation or the FSF step in and clarify the 
situation please ?   If in your opinion it is all fine what people are 
doing, why not release R under the LGPL for clarity ?

Regards, Matthew

----- Original Message ----- 
From: "David M Smith" <david at revolution-computing.com>
To: "Matthew Dowle" <mdowle at mdowle.plus.com>
Cc: "Patrick Shields" <pat at revolution-computing.com>; 
<r-devel at r-project.org>
Sent: Wednesday, April 22, 2009 4:36 PM
Subject: Re: [Rd] Closed-source non-free ParallelR ?


Patrick made all the points that I was going to make (thanks,
Patrick), but I wanted to reinforce one point that may be the source
of the confusion: ParallelR is not a modified version of R: ParallelR
is a suite of ordinary R packages that run on top of the R engine like
any other package. The R code and Python code in these packages were
written entirely by REvolution Computing staff (including Patrick),
and do not contain any code (derived or otherwise) from the R project.

In retrospect, the name ParallelR may be somewhat confusing in this
sense...

# David Smith

On Wed, Apr 22, 2009 at 7:40 AM, Patrick Shields
<pat at revolution-computing.com> wrote:
> I'm Pat Shields, one of the software engineers working on ParallelR. I

> just
> wanted to make two points: no R code or previously gpl'd code can be
found
> in any of the non-gpl packages in ParallelR. I'm sure that the phrase
> "derived works" is a legally subtle one, but all these packages
include 
> are
> R and occasionally python scripts (as well as the standard text
> documentation). If these are derived works, doesn't that mean that any
R
> code is also, by extension, required to be GPL'd? If not, is it
including
> these scripts in a package that forces the use of the GPL?
>
> Also, I'm confused about your dimissal of the MCE example. If that
code 
> was
> a derivative work of R, how could it swap a GPL license for the BSD? I
> didn't think such a switch was possible. If it was, I'd imagine a lot
more
> use of it, as a quick front project could make GPL software into BSD
> software after which all changes could go on behind closed doors.
>
> On Tue, Apr 21, 2009 at 7:38 PM, Matthew Dowle 
> <mdowle at mdowle.plus.com>wrote:
>
>> Dear R-devel,
>>
>> REvolution appear to be offering ParallelR only when bundled with
their R
>> Enterprise edition. As such it appears to be non-free and closed
source.
>> http://www.revolution-computing.com/products/parallel-r.php
>>
>> Since R is GPL and not LGPL, is this a breach of the GPL ?
>>
>> Below is the "GPL and ParallelR" thread from their R forum.
>>
>> mdowle > It appears that ParallelR (packages foreach and iterators)
is
>> only available bundled with the Enterprise edition. Since R is GPL,
and
>> ParallelR is derived from R, should ParallelR not also be GPL?
Regards,
>> Matthew
>>
>> revolution > Hello Matthew, ParallelR consists of both proprietary
and 
>> GPL
>> packages. The randomForest and snow libraries GPL licensed, whereas
the
>> other libraries we include have a commercial license(including
'foreach' 
>> and
>> 'iterators'). Stephen Weller
>>
>> revolution > I wanted to expand on Stephen's reply. ParallelR is a
suite 
>> of
>> R packages, and it is well established that packages can be under a
>> difference license than R itself (i.e. not the GPL). For example,
package
>> MCE is licensed under BSD, RColorBrewer is licensed under Apache,
most of
>> Bioconductor is under the Artistic license and some are under
completely
>> unique licenses (e.g. mclust). REvolution Computing developed all of
the
>> code in ParallelR (except for the bundled GPL packages Stephen
mentions),
>> and we decided to release it under our own license in REvolution R
>> Enterprise.
>> That said, we do already release components of parallelR, such as the
>> underlying engine, Networkspaces (also written by REvolution
Computing)
>> under an open source licence. Also, we are likely to release some
other
>> components including foreach and iterators, to CRAN soon.
>> David Smith
>> Director of Community, REvolution Computing
>>
>> mdowle > The examples you give (MCE, RColorBrewer, Bioconductor) are
all
>> available for free including the source code. Their licenses have
been
>> approved by the FSF. Free software and open source are the terms of
work
>> derived from GPL licensed software. REvolution's packages 'foreach'
and
>> 'iterators' are neither free or open source. Can you provide a
precedent
>> for proprietary closed-source packages for R ? Is your policy
approved by
>> the FSF ?
>> I don't object to REvolution. I am a fan of you making money from 
>> training
>> courses, consultancy, support and binaries. These are all permitted
by 
>> the
>> GPL. However the GPL does not allow you to distribute work derived
from R
>> which is either closed source or non-free.
>> R is GPL, not LGPL.
>> The above is my personal understanding. I am now posting to r-devel
to
>> check, feel free to join the public debate there.
>>
>> Regards, Matthew
>>
>> [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>
> --
> Pat Shields
> Software Engineer
> REvolution Computing
> One Century Tower | 265 Church Street, Suite 1006
> New Haven, CT 06510
> P: 203-777-7442 x250 | www.revolution-computing.com
>
> Check out our upcoming events schedule at
> www.revolution-computing.com/events
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
David M Smith <david at revolution-computing.com>
Director of Community, REvolution Computing www.revolution-computing.com
Tel: +1 (206) 577-4778 x3203 (San Francisco, USA)

Check out our upcoming events schedule at 
www.revolution-computing.com/events

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From macrakis at alum.mit.edu  Thu Apr 23 18:47:13 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Thu, 23 Apr 2009 12:47:13 -0400
Subject: [Rd] Closed-source non-free ParallelR ?
In-Reply-To: <E1C5F6F55B4445AF902DF4B970BE1688@ADAM>
References: <373DCC90906D430E952EF2C423B0D91B@ADAM>
	<ac81d400904220740i5a4adac4l41b1a170c6f27bd7@mail.gmail.com>
	<475a3c8f0904220836w43d07042m84f42edf6e05766c@mail.gmail.com>
	<E1C5F6F55B4445AF902DF4B970BE1688@ADAM>
Message-ID: <8b356f880904230947n6a410d2lc06b9088e53041b0@mail.gmail.com>

The FSF clearly promulgated the GPL with the intent of prohibiting the
bundling of GPL code with proprietary code.  The way the GPL does this
is by putting conditions on distribution: if you "distribute" a
program "based on" a GPL program, the whole program must be licensed
under the GPL.

Clearly, the crux of the matter is the meaning of "distribute" and
"based on".  The FSF takes a maximalist view of this, so that (for
example) distributing R together with additional components (libraries
/ packages / whatever), even if they are in separate files and loaded
dynamically, would require that the additional components be licensed
under GPL (and therefore that their source be released).  The
additional libraries need not be derived works of the original; this
is not a copyright issue, but a licensing issue.

I am not a lawyer, so can't judge this professionally, but it seems to
me that the copyright owner is within his rights to impose conditions
like this on distribution -- just as he could arbitrarily decide that
he will only license his code to people whose names begin with 'T'.
The logic is not: "I require you to release your code under GPL" but:
"I will only license my GPL code to you for this application if you
release your code under GPL".

On the other hand, the GPL explicitly allows *users* of the code to do
what they want, including mixing it with proprietary code, as long as
they don't distribute the result.  And I do not believe the copyright
holder has any way of preventing a third party from distributing
*separately* code that can be run on top of R.  In fact the FSF itself
has been quite clear that they don't consider that the license for a
language implementation restricts the code that can be run on top of
it in any way.

All that being said, the entity that must enforce these conditions is
not the FSF, but the copyright owner, in this case the R Foundation
and the copyright holders of any other packages redistributed by the
bundler. So it would be useful to know what the R Foundation's
position is.  Regardless of what the license says, it is up to the R
Foundation to decide what *its* interpretation of the license is and
under what circumstances it would ask a distributor of its code to
cease and desist -- and that failing, sue.

             -s


From ldimitro at wfubmc.edu  Thu Apr 23 19:05:01 2009
From: ldimitro at wfubmc.edu (Latchezar (Lucho) Dimitrov)
Date: Thu, 23 Apr 2009 13:05:01 -0400
Subject: [Rd] 'is.integer' (PR#13671)
In-Reply-To: <f8e6ff050904230608y31018934o235724cb3d6fccbc@mail.gmail.com>
References: <20090422174516.2EB1928321BF@mail.pubhealth.ku.dk><8b356f880904221330r2c2776cid12036442511b216@mail.gmail.com><18928.13118.892491.84418@lynne.math.ethz.ch>
	<f8e6ff050904230608y31018934o235724cb3d6fccbc@mail.gmail.com>
Message-ID: <F160BE32A2E5E04497668BBDFE83FEDF24275D2B@EXCHVS1.medctr.ad.wfubmc.edu>

Hey core-developers,

With all the respect to your precious time and beliefs isn't that
phenomenon (as many others similar ones) due to deficiencies in the R
docs/FAQ's/etc? I hate to think you assume all other R users are
malicious idiots trying to spoil your time.

Thanks you very much,

Latchezar 

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of hadley wickham
> Sent: Thursday, April 23, 2009 9:08 AM
> To: Martin Maechler
> Cc: r-devel at stat.math.ethz.ch
> Subject: Re: [Rd] 'is.integer' (PR#13671)
> 
> > *However*, Mauricio submitted a *formal* bug report against R and 
> > there are many caveats against doing that "light-heartedly".
> > Note that he also said
> 
> I know it's frustrating when people repeatedly ask this 
> question (and file bug reports related to it), but does it 
> really take that long to tell them to check out FAQ 7.31, and 
> to close the bug report?
> 
> Hadley
> 
> 
> --
> http://had.co.nz/
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From wdunlap at tibco.com  Thu Apr 23 19:06:38 2009
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 23 Apr 2009 10:06:38 -0700
Subject: [Rd] reference counting problem in .Primitive's?
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D70001130F9C@NA-PA-VBE03.na.tibco.com>

I think the following rather wierd expressions show a problem in how
some of the .Primitive functions evaluate their arguments.  I haven't
yet thought of a way that a nonabusive user might run into this problem.
In each case the first argument, x, is modified in the course of
evaluating the second argument and then modified x gets used
as the first argument:

> x<-as.integer(1:5); y <- x + { x[3]<-33L ; 1L } ; y
[1]  2  3 34  5  6
> x<-2^(0:4) ; y <- log(x, { x[3]<-64 ; 2 }) ; y
[1] 0 1 6 3 4

The reason I think it looks like a sharing problem (and not an order
of evaluation problem) is that if your modification to x causes it to
use a new block of memory then the unmodified version of x gets
used as the first argument.  E.g.,

> x<-as.integer(1:5) ; y <- x + { x[3]<-33.3; 1L} ; y
[1] 2 3 4 5 6

I haven't yet thought of a way that a nonabusive user might run
into this problem.

Bill Dunlap
TIBCO Software Inc - Spotfire Division
wdunlap tibco.com 


From marc_schwartz at me.com  Thu Apr 23 19:25:32 2009
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 23 Apr 2009 12:25:32 -0500
Subject: [Rd] Closed-source non-free ParallelR ?
In-Reply-To: <8b356f880904230947n6a410d2lc06b9088e53041b0@mail.gmail.com>
References: <373DCC90906D430E952EF2C423B0D91B@ADAM>
	<ac81d400904220740i5a4adac4l41b1a170c6f27bd7@mail.gmail.com>
	<475a3c8f0904220836w43d07042m84f42edf6e05766c@mail.gmail.com>
	<E1C5F6F55B4445AF902DF4B970BE1688@ADAM>
	<8b356f880904230947n6a410d2lc06b9088e53041b0@mail.gmail.com>
Message-ID: <B49C0AC4-8331-4F2D-81A7-48119E369221@me.com>

On Apr 23, 2009, at 11:47 AM, Stavros Macrakis wrote:
>
> All that being said, the entity that must enforce these conditions is
> not the FSF, but the copyright owner, in this case the R Foundation
> and the copyright holders of any other packages redistributed by the
> bundler. So it would be useful to know what the R Foundation's
> position is.  Regardless of what the license says, it is up to the R
> Foundation to decide what *its* interpretation of the license is and
> under what circumstances it would ask a distributor of its code to
> cease and desist -- and that failing, sue.

Actually, the R Foundation has done what it is obligated to do, which  
is to describe the license under which R is made available. To ask the  
R Foundation for anything further is to ask them to render a legal  
opinion, which is not in their expertise to offer.

It is up to the prospective third party developer of an application  
that is to use R to consult with lawyers to determine what *THEIR*  
obligations are if they should elect to proceed. Since much of this  
has not yet been tested in case law, the burden is on the the third  
party developer, not on the R Foundation, since the R Foundation  
cannot reasonably conceive of every possible scenario under which R or  
subsets of code from R may be used.

The key thing to keep in mind is that the GPL really applies to the  
**distribution** of software and not the **use** of software.

Thus, if one is going to use R or code from R "internally", the  
obligations are more limited than if one builds an application that  
links to R or uses code from R and then will *distribute* that  
application to other parties, whether that distribution be free of  
charge or for a price.

There are two key scenarios here:

1. I am building an application that simply "calls" R via a script or  
batch type of interface. Think building a GUI on top of R. I  
distribute my application and may or may not distribute R with it. I  
can license my application in any fashion that I wish, closed source  
or otherwise. If I don't distribute R with my application and simply  
point users to where they can download R, then I have no obligation  
with respect to R. If I distribute R with my application, then I also  
have an obligation to make R's source code available to my users in  
some fashion. Neither situation obligates me to make the source code  
for my application available or to license my application under the GPL.

2. I build an application that includes source code from R and/or  
"links" to R libraries at a compiler level. In this case the  
"derivative works" and/or the so-called "viral" part of the GPL kicks  
in. Here, I am obligated to license my application under a compatible  
license AND make the source code to my application available as a  
consequence.

At this level, it is really pretty simple and a lot of these things  
are covered in the GPL FAQs, including the reporting of violations.

   For GPL 3:
   http://www.gnu.org/licenses/gpl-faq.html

   For GPL 2:
   http://www.gnu.org/licenses/old-licenses/gpl-2.0-faq.html

HTH,

Marc Schwartz


From friedrich.leisch at stat.uni-muenchen.de  Thu Apr 23 19:41:00 2009
From: friedrich.leisch at stat.uni-muenchen.de (Friedrich Leisch)
Date: Thu, 23 Apr 2009 19:41:00 +0200
Subject: [Rd] Closed-source non-free ParallelR ?
In-Reply-To: <E1C5F6F55B4445AF902DF4B970BE1688@ADAM>
References: <373DCC90906D430E952EF2C423B0D91B@ADAM>
	<ac81d400904220740i5a4adac4l41b1a170c6f27bd7@mail.gmail.com>
	<475a3c8f0904220836w43d07042m84f42edf6e05766c@mail.gmail.com>
	<E1C5F6F55B4445AF902DF4B970BE1688@ADAM>
Message-ID: <18928.43052.993574.159214@lxh5.stat.uni-muenchen.de>

>>>>> On Thu, 23 Apr 2009 00:36:48 +0100,
>>>>> Matthew Dowle (MD) wrote:

[...]

  > Could someone from the R Foundation or the FSF step in and clarify the 
  > situation please ?

Just a short clarification (by no means intended to stop the thread):
as you can imagine we are discussing the matter internally in R Core
and the Foundation, but there are different views and we want to
consolidate before we make a public statement.  If all of us were of
the same opinion we would already have made one.

Unfortunately New Zealand, Europe and the US are in quite different
time zones, hence discussions by email take some time.

Best regards,
Fritz Leisch

-- 
-----------------------------------------------------------------------
Prof. Dr. Friedrich Leisch 

Institut f?r Statistik                          Tel: (+49 89) 2180 3165
Ludwig-Maximilians-Universit?t                  Fax: (+49 89) 2180 5308
Ludwigstra?e 33
D-80539 M?nchen                     http://www.statistik.lmu.de/~leisch
-----------------------------------------------------------------------
   Journal Computational Statistics --- http://www.springer.com/180 
          M?nchner R Kurse --- http://www.statistik.lmu.de/R


From luke at stat.uiowa.edu  Thu Apr 23 20:05:39 2009
From: luke at stat.uiowa.edu (luke at stat.uiowa.edu)
Date: Thu, 23 Apr 2009 13:05:39 -0500 (CDT)
Subject: [Rd] reference counting problem in .Primitive's?
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D70001130F9C@NA-PA-VBE03.na.tibco.com>
References: <77EB52C6DD32BA4D87471DCD70C8D70001130F9C@NA-PA-VBE03.na.tibco.com>
Message-ID: <alpine.LFD.2.00.0904231252430.21901@nokomis.stat.uiowa.edu>

On Thu, 23 Apr 2009, William Dunlap wrote:

> I think the following rather wierd expressions show a problem in how
> some of the .Primitive functions evaluate their arguments.  I haven't
> yet thought of a way that a nonabusive user might run into this problem.
> In each case the first argument, x, is modified in the course of
> evaluating the second argument and then modified x gets used
> as the first argument:
>
>> x<-as.integer(1:5); y <- x + { x[3]<-33L ; 1L } ; y
> [1]  2  3 34  5  6
>> x<-2^(0:4) ; y <- log(x, { x[3]<-64 ; 2 }) ; y
> [1] 0 1 6 3 4
>
> The reason I think it looks like a sharing problem (and not an order
> of evaluation problem) is that if your modification to x causes it to
> use a new block of memory then the unmodified version of x gets
> used as the first argument.  E.g.,
>
>> x<-as.integer(1:5) ; y <- x + { x[3]<-33.3; 1L} ; y
> [1] 2 3 4 5 6
>
> I haven't yet thought of a way that a nonabusive user might run
> into this problem.

You are probably right.  I have not yet looked at the code but am
virtually certain it does not try to temporarily bump up the NAMED
values on argument values.  Doing so would cure this but probably at
serious cost to performance, as NAMED values of 2 cannot be brought
down again and so cause copying on next modify. (Might be worth
running some tests on that though to see what the cost would be).

I'm not sure if it is written anywhere that argunments of primitives
(BUILTINS in articular as those are always strict; SPECIALS can be
non-strict but log is strict) are evaluated in any particular order.
All these examples are consistent with _some_ evaluation order, but
not the same one.  It might be possible to show that the results
obtained in these situations will always be consistent with some
evaluation order, in which case documenting that order of evaluation
is unspecified would be good enough form me.  It may also be possible
that an order that does compound expressions first and then symbols
would also solve the issue (I don't think I would want to do this in
the interpreter though because of the performance overhead.)

luke


>
> Bill Dunlap
> TIBCO Software Inc - Spotfire Division
> wdunlap tibco.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From ggrothendieck at gmail.com  Thu Apr 23 20:44:37 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 23 Apr 2009 14:44:37 -0400
Subject: [Rd] Closed-source non-free ParallelR ?
In-Reply-To: <18928.43052.993574.159214@lxh5.stat.uni-muenchen.de>
References: <373DCC90906D430E952EF2C423B0D91B@ADAM>
	<ac81d400904220740i5a4adac4l41b1a170c6f27bd7@mail.gmail.com> 
	<475a3c8f0904220836w43d07042m84f42edf6e05766c@mail.gmail.com> 
	<E1C5F6F55B4445AF902DF4B970BE1688@ADAM>
	<18928.43052.993574.159214@lxh5.stat.uni-muenchen.de>
Message-ID: <971536df0904231144j29d939eax8ff79f7181954bcd@mail.gmail.com>

On Thu, Apr 23, 2009 at 1:41 PM, Friedrich Leisch
<friedrich.leisch at stat.uni-muenchen.de> wrote:
>>>>>> On Thu, 23 Apr 2009 00:36:48 +0100,
>>>>>> Matthew Dowle (MD) wrote:
>
> [...]
>
> ?> Could someone from the R Foundation or the FSF step in and clarify the
> ?> situation please ?
>
> Just a short clarification (by no means intended to stop the thread):
> as you can imagine we are discussing the matter internally in R Core
> and the Foundation, but there are different views and we want to
> consolidate before we make a public statement. ?If all of us were of
> the same opinion we would already have made one.
>
> Unfortunately New Zealand, Europe and the US are in quite different
> time zones, hence discussions by email take some time.


Aside from R there are the add-on packages.

A frequency table showing the licenses of the CRAN packages indicates
that the all or almost all packages have some sort of free software license
with GPL licenses being most common. (A few packages have restrictions
to noncommercial use and that may conflict with GPL, not sure.)   That is
not to say that there are no other types of packages but any such packages
are not on CRAN.

         AGPL (&gt;3.0), with attribution as per LICENSE file
                                                            1
                                  AGPL 3.0 (with attribution)
                                                            1
                                           Apache License 2.0
                                                            2
                                                 Artistic-2.0
                                                            5
                                             Artistic License
                                                            2
                                         Artistic License 2.0
                                                            1
                     avas is public domain, ace is on Statlib
                                                            1
                                                          BSD
                                                           16
                                                       CeCILL
                                                            1
                                                     CeCILL-2
                                                            2
                            Common Public License Version 1.0
                                                            2
       Distribution and use for non-commercial purposes only.
                                                            1
                                                 file LICENCE
                                                            2
                                                 file LICENSE
                                                           38
  Fortran code: ACM, free for non-commercial use, R functions
                                                            1
                             free for non-commercial purposes
                                                            1
                                      Free for nonprofit use.
                                                            1
                      Free. See the LICENCE file for details.
                                                            1
                                   GNU General Public License
                                                            3
                         GNU General Public License Version 2
                                                            4
                                                          GPL
                                                          222
                                                        GPL-2
                                                          316
                                         GPL-2 | file LICENCE
                                                            1
                                         GPL-2 | file LICENSE
                                                            7
                                                GPL-2 | GPL-3
                                                           13
  GPL-2.  Contributions from Randall C. Johnson are Copyright
                                                            1
  GPL-2; incorporates by permission code of W. Bachman (wrtab
                                                            1
                                                        GPL-3
                                                           38
                                                 GPL (&ge; 2)
                                                          872
                                  GPL (&ge; 2) | file LICENSE
                                                            1
                                               GPL (&ge; 2.0)
                                                            2
                                                 GPL (&ge; 3)
                                                           34
                                               GPL (&ge; 3.0)
                                                            1
                                                   GPL (== 2)
                                                            1
                                           GPL | file LICENSE
                                                            1
                                                   GPL | LGPL
                                                            1
                                               GPL 2 or newer
                                                            1
                               GPL AFFERO 3.0 (with citation)
                                                            1
     GPL version 2 or newer. Copyright statement for ptolemy:
                                                            1
   GPL version 2 or newer. The terms of this license are in a
                                                            2
GPL version 2 or newer. This library is Copyright (C) 2007 by
                                                            1
                                          GPL2 | file LICENSE
                                                            1
                                                         LGPL
                                                           21
                                                       LGPL-2
                                                            3
                                                     LGPL-2.1
                                                            6
                                                       LGPL-3
                                                           19
                                                LGPL (&ge; 2)
                                                            2
                                              LGPL (&ge; 2.0)
                                                            5
                                              LGPL (&ge; 2.1)
                                                            9
                                                          MIT
                                                            8
                                   Mozilla Public License 1.1
                                                            1
               Original ??, extensions GPL version 2 or newer
                                                            1
  R functions: GPL, Fortran code: ACM, free for noncommercial
                                                            1
                              S original available at statlib
                                                            1
   The caMassClass Software License, Version 1.0 (See COPYING
                                                            1
   The software may be distributed free of charge and used by
                                                            3
This package was written by Hans Peter Wolf. This software is
                                                            1
  This software may be re-distributed freely and used for any
                                                            3
             Unclear (Fortran) -- code in Statlib's ./S/adapt
                                                            1
                                                    Unlimited
                                                           18
                Unlimited distribution for noncommercial use.
                                                            1
                                      Unlimited distribution.
                                                            1
                                                          X11
                                                            7


From edd at debian.org  Thu Apr 23 21:08:55 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 23 Apr 2009 14:08:55 -0500
Subject: [Rd] License status of CRAN packages
Message-ID: <18928.48327.599527.545472@ron.nulle.part>


(Subject: renamed as thread hijacked from the ParallelR thread   --Dirk)

On 23 April 2009 at 14:44, Gabor Grothendieck wrote:
| Aside from R there are the add-on packages.
| 
| A frequency table showing the licenses of the CRAN packages indicates
| that the all or almost all packages have some sort of free software license
| with GPL licenses being most common. (A few packages have restrictions
| to noncommercial use and that may conflict with GPL, not sure.)   That is
| not to say that there are no other types of packages but any such packages
| are not on CRAN.

I fear that is not quite the case.  There are quite a few packages like that.

Charles Blundell and I have continued to work on his Google Summer of Code
2008 project of fully automatically creating Debian packages from CRAN
sources.  As this can be seen as redistributing (or at least as making
redistribution easier), we have tried to be careful about the licenses.  We
currently build about 1500 out of 1650 or so 'buildable' packages, but we
stop if we do not explicitly know the licenses (and Charles had e.g. created
several dozen variants of writing out 'GPL' in less clear ways so that we
could include those packages).  Moreover one big show stopper is 'File
license' shown below as applicable for 38 packages You need to explicitly
study all of those 'license' files; some are free and some aren't.  The
trouble is that you cannot tell and you end up labelling packages as 'maybe
not free' even if they are (an example here may be mlbench).

That does not scale.  Ultimately, I fear we need someone to sit down and
classify CRAN sources packages into appropriate buckets of 'freeness' of use,
redistribution etc.  And/or to remap all packages to a smaller, saner set of
licenses (as e.g. those in licenses.db).  Section 1.1.1 of 'R Extensions' is
quite clear about this, but I would like this to go further.  

Given that install.packages() does not check, I am afraid that we are not
going far enough in preventing users from accessing packages that they may
not be able to access and use under the terms of the license file.
Ultimately, this may mean moving some packages to a 'non-free' repository
tree as well.

I'd love to hear comments and concrete suggestions.

Dirk


|          AGPL (&gt;3.0), with attribution as per LICENSE file
|                                                             1
|                                   AGPL 3.0 (with attribution)
|                                                             1
|                                            Apache License 2.0
|                                                             2
|                                                  Artistic-2.0
|                                                             5
|                                              Artistic License
|                                                             2
|                                          Artistic License 2.0
|                                                             1
|                      avas is public domain, ace is on Statlib
|                                                             1
|                                                           BSD
|                                                            16
|                                                        CeCILL
|                                                             1
|                                                      CeCILL-2
|                                                             2
|                             Common Public License Version 1.0
|                                                             2
|        Distribution and use for non-commercial purposes only.
|                                                             1
|                                                  file LICENCE
|                                                             2
|                                                  file LICENSE
|                                                            38
|   Fortran code: ACM, free for non-commercial use, R functions
|                                                             1
|                              free for non-commercial purposes
|                                                             1
|                                       Free for nonprofit use.
|                                                             1
|                       Free. See the LICENCE file for details.
|                                                             1
|                                    GNU General Public License
|                                                             3
|                          GNU General Public License Version 2
|                                                             4
|                                                           GPL
|                                                           222
|                                                         GPL-2
|                                                           316
|                                          GPL-2 | file LICENCE
|                                                             1
|                                          GPL-2 | file LICENSE
|                                                             7
|                                                 GPL-2 | GPL-3
|                                                            13
|   GPL-2.  Contributions from Randall C. Johnson are Copyright
|                                                             1
|   GPL-2; incorporates by permission code of W. Bachman (wrtab
|                                                             1
|                                                         GPL-3
|                                                            38
|                                                  GPL (&ge; 2)
|                                                           872
|                                   GPL (&ge; 2) | file LICENSE
|                                                             1
|                                                GPL (&ge; 2.0)
|                                                             2
|                                                  GPL (&ge; 3)
|                                                            34
|                                                GPL (&ge; 3.0)
|                                                             1
|                                                    GPL (== 2)
|                                                             1
|                                            GPL | file LICENSE
|                                                             1
|                                                    GPL | LGPL
|                                                             1
|                                                GPL 2 or newer
|                                                             1
|                                GPL AFFERO 3.0 (with citation)
|                                                             1
|      GPL version 2 or newer. Copyright statement for ptolemy:
|                                                             1
|    GPL version 2 or newer. The terms of this license are in a
|                                                             2
| GPL version 2 or newer. This library is Copyright (C) 2007 by
|                                                             1
|                                           GPL2 | file LICENSE
|                                                             1
|                                                          LGPL
|                                                            21
|                                                        LGPL-2
|                                                             3
|                                                      LGPL-2.1
|                                                             6
|                                                        LGPL-3
|                                                            19
|                                                 LGPL (&ge; 2)
|                                                             2
|                                               LGPL (&ge; 2.0)
|                                                             5
|                                               LGPL (&ge; 2.1)
|                                                             9
|                                                           MIT
|                                                             8
|                                    Mozilla Public License 1.1
|                                                             1
|                Original ??, extensions GPL version 2 or newer
|                                                             1
|   R functions: GPL, Fortran code: ACM, free for noncommercial
|                                                             1
|                               S original available at statlib
|                                                             1
|    The caMassClass Software License, Version 1.0 (See COPYING
|                                                             1
|    The software may be distributed free of charge and used by
|                                                             3
| This package was written by Hans Peter Wolf. This software is
|                                                             1
|   This software may be re-distributed freely and used for any
|                                                             3
|              Unclear (Fortran) -- code in Statlib's ./S/adapt
|                                                             1
|                                                     Unlimited
|                                                            18
|                 Unlimited distribution for noncommercial use.
|                                                             1
|                                       Unlimited distribution.
|                                                             1
|                                                           X11
|                                                             7
| 
| ______________________________________________
| R-devel at r-project.org mailing list
| https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Three out of two people have difficulties with fractions.


From ggrothendieck at gmail.com  Thu Apr 23 21:32:55 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 23 Apr 2009 15:32:55 -0400
Subject: [Rd] License status of CRAN packages
In-Reply-To: <18928.48327.599527.545472@ron.nulle.part>
References: <18928.48327.599527.545472@ron.nulle.part>
Message-ID: <971536df0904231232vbb024c8p95456acaeae0ff6d@mail.gmail.com>

On Thu, Apr 23, 2009 at 3:08 PM, Dirk Eddelbuettel <edd at debian.org> wrote:
>
> (Subject: renamed as thread hijacked from the ParallelR thread ? --Dirk)
>
> On 23 April 2009 at 14:44, Gabor Grothendieck wrote:
> | Aside from R there are the add-on packages.
> |
> | A frequency table showing the licenses of the CRAN packages indicates
> | that the all or almost all packages have some sort of free software license
> | with GPL licenses being most common. (A few packages have restrictions
> | to noncommercial use and that may conflict with GPL, not sure.) ? That is
> | not to say that there are no other types of packages but any such packages
> | are not on CRAN.
>
> I fear that is not quite the case. ?There are quite a few packages like that.

Not the case?  My post included a list of all License fields from the
DESCRIPTION file of every CRAN package so the list is definitive.


From edd at debian.org  Thu Apr 23 22:02:31 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 23 Apr 2009 15:02:31 -0500
Subject: [Rd] License status of CRAN packages
In-Reply-To: <971536df0904231232vbb024c8p95456acaeae0ff6d@mail.gmail.com>
References: <18928.48327.599527.545472@ron.nulle.part>
	<971536df0904231232vbb024c8p95456acaeae0ff6d@mail.gmail.com>
Message-ID: <18928.51543.939132.165160@ron.nulle.part>


On 23 April 2009 at 15:32, Gabor Grothendieck wrote:
| On Thu, Apr 23, 2009 at 3:08 PM, Dirk Eddelbuettel <edd at debian.org> wrote:
| >
| > (Subject: renamed as thread hijacked from the ParallelR thread   --Dirk)
| >
| > On 23 April 2009 at 14:44, Gabor Grothendieck wrote:
| > | Aside from R there are the add-on packages.
| > |
| > | A frequency table showing the licenses of the CRAN packages indicates
| > | that the all or almost all packages have some sort of free software license
| > | with GPL licenses being most common. (A few packages have restrictions
| > | to noncommercial use and that may conflict with GPL, not sure.)   That is
| > | not to say that there are no other types of packages but any such packages
| > | are not on CRAN.
| >
| > I fear that is not quite the case.  There are quite a few packages like that.
| 
| Not the case?  My post included a list of all License fields from the
| DESCRIPTION file of every CRAN package so the list is definitive.

Correct me if I am wrong in the paragraph you kindly left standing above, you
seem to suggest that

	"all or almost all packages have some sort of free software license" 

and that while non-free licenses may exist, 

	"any such packages are not on CRAN".

I believe this statement to be false.

There are packages with restrictive licenese on CRAN.  They were contained in
the list of licenses you assembled, and my point is that it is overly hard to
identify them (if one were to tty to avoid using these packages).

As a non-exhautive list with possible misclassifications, cran2deb currently
has these packasges as 'maybe not free' and does not build them:

     BARD,BayesDA,CoCo,ConvCalendar,FAiR,PTAk,RScaLAPACK,Rcsdp,SDDA,SGP,
     alphahull,ash,asypow,caMassClass,gpclib,mapproj,matlab,mclust,mclust02,
     mlbench,optmatch,rankreg,realized,rngwell19937,rtiff,rwt,scagnostics,
     sgeostat,spatialkernel,tlnise,xgobi

We are missing some recently added packages, and we may yet flag several from
the list above as free. Some may be listed because of non-free Depends:

But to take a concrete example, 'realized' is not something I am supposed to
install at work.  Yet install.packages() currently has not way knowing that.

Are we approximately on the same page ?

Dirk

-- 
Three out of two people have difficulties with fractions.


From macrakis at alum.mit.edu  Thu Apr 23 22:22:37 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Thu, 23 Apr 2009 16:22:37 -0400
Subject: [Rd] Closed-source non-free ParallelR ?
In-Reply-To: <B49C0AC4-8331-4F2D-81A7-48119E369221@me.com>
References: <373DCC90906D430E952EF2C423B0D91B@ADAM>
	<ac81d400904220740i5a4adac4l41b1a170c6f27bd7@mail.gmail.com>
	<475a3c8f0904220836w43d07042m84f42edf6e05766c@mail.gmail.com>
	<E1C5F6F55B4445AF902DF4B970BE1688@ADAM>
	<8b356f880904230947n6a410d2lc06b9088e53041b0@mail.gmail.com>
	<B49C0AC4-8331-4F2D-81A7-48119E369221@me.com>
Message-ID: <8b356f880904231322j1251d50if184b94f24c619ca@mail.gmail.com>

On Thu, Apr 23, 2009 at 1:25 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
> On Apr 23, 2009, at 11:47 AM, Stavros Macrakis wrote:
>>
>> All that being said, the entity that must enforce these conditions is
>> not the FSF, but the copyright owner, in this case the R Foundation...
>> bundler. So it would be useful to know what the R Foundation's
>> position is....

> Actually, the R Foundation has done what it is obligated to do, which is to
> describe the license under which R is made available.

I did not say that the R Foundation was obligated to give advice.  I
said that it is up to the R Foundation to decide what cases it cares
about, and it would be "useful to know" what that position is.

> To ask the R Foundation for anything further is to ask them to render a legal
> opinion, which is not in their expertise to offer.

No, it is asking them what their *policy* is.  Their policy may or may
not be enforceable....

> It is up to the prospective third party developer of an application that is
> to use R to consult with lawyers to determine what *THEIR* obligations are
> if they should elect to proceed.

Yes, this is true.  But it is also true that if (for example) the R
Foundation says officially that it interprets GPL to allow
distributing proprietary packages along with R, then that is the
interpretation that matters, since the R Foundation (not the FSF) is
the copyright holder.

> At this level, it is really pretty simple and a lot of these things are
> covered in the GPL FAQs, including the reporting of violations.

The GPL FAQs are the FSF's interpretation.  The R Foundation is not
obliged to have the same interpretation, and of course the FSF cannot
enforce licenses given by the R Foundation.

                -s


From ggrothendieck at gmail.com  Thu Apr 23 22:35:12 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 23 Apr 2009 16:35:12 -0400
Subject: [Rd] License status of CRAN packages
In-Reply-To: <18928.51543.939132.165160@ron.nulle.part>
References: <18928.48327.599527.545472@ron.nulle.part>
	<971536df0904231232vbb024c8p95456acaeae0ff6d@mail.gmail.com> 
	<18928.51543.939132.165160@ron.nulle.part>
Message-ID: <971536df0904231335s25d1c134l58db3f7280c053e2@mail.gmail.com>

Of the 31 packages listed:
 [1] "BARD"          "BayesDA"       "CoCo"          "ConvCalendar"
 [5] "FAiR"          "PTAk"          "RScaLAPACK"    "Rcsdp"
 [9] "SDDA"          "SGP"           "alphahull"     "ash"
[13] "asypow"        "caMassClass"   "gpclib"        "mapproj"
[17] "matlab"        "mclust"        "mclust02"      "mlbench"
[21] "optmatch"      "rankreg"       "realized"      "rngwell19937"
[25] "rtiff"         "rwt"           "scagnostics"   "sgeostat"
[29] "spatialkernel" "tlnise"        "xgobi"

the license fields are AGPL or GPL for 3 and specified in a separate
file "file LICENSE" so about 30 of 1700 < 2% are question marks.
To me that is not inconsistent with all or nearly all being free software
licenses but at any rate this quantifies it a bit better.  (A couple are
not listed below as I got a read error when trying to access its summary
from the CRAN site.  Its possible those 2 are not actually on CRAN.)

                            BARD
                               "AGPL 3.0 (with attribution)"
                                                     BayesDA
                                              "GPL (&ge; 2)"
                                                        CoCo
                                              "file LICENSE"
                                                ConvCalendar
                                              "file LICENCE"
                                                        FAiR
                                              "file LICENSE"
                                                        PTAk
                                              "file LICENSE"
                                                       Rcsdp
                                              "file LICENSE"
                                                        SDDA
                                              "file LICENSE"
                                                         SGP
                                              "file LICENSE"
                                                   alphahull
                                              "file LICENSE"
                                                         ash
                           "S original available at statlib"
                                                      asypow
                                              "file LICENSE"
                                                 caMassClass
"The caMassClass Software License, Version 1.0 (See COPYING"
                                                      gpclib
                                              "file LICENSE"
                                                     mapproj
    "Distribution and use for non-commercial purposes only."
                                                      matlab
                                              "file LICENSE"
                                                      mclust
                                              "file LICENSE"
                                                    mclust02
                                              "file LICENSE"
                                                     mlbench
                                              "file LICENSE"
                                                    optmatch
                                              "file LICENSE"
                                                     rankreg
                                   "Free for nonprofit use."
                                                    realized
                                              "file LICENSE"
                                                rngwell19937
                                              "file LICENSE"
                                                       rtiff
                                              "file LICENSE"
                                                         rwt
                                              "file LICENSE"
                                                 scagnostics
                                              "file LICENSE"
                                                    sgeostat
            "Original ??, extensions GPL version 2 or newer"
                                               spatialkernel
                                              "file LICENSE"
                                                      tlnise
                                              "file LICENSE"


2009/4/23 Dirk Eddelbuettel <edd at debian.org>:
>
> On 23 April 2009 at 15:32, Gabor Grothendieck wrote:
> | On Thu, Apr 23, 2009 at 3:08 PM, Dirk Eddelbuettel <edd at debian.org> wrote:
> | >
> | > (Subject: renamed as thread hijacked from the ParallelR thread ? --Dirk)
> | >
> | > On 23 April 2009 at 14:44, Gabor Grothendieck wrote:
> | > | Aside from R there are the add-on packages.
> | > |
> | > | A frequency table showing the licenses of the CRAN packages indicates
> | > | that the all or almost all packages have some sort of free software license
> | > | with GPL licenses being most common. (A few packages have restrictions
> | > | to noncommercial use and that may conflict with GPL, not sure.) ? That is
> | > | not to say that there are no other types of packages but any such packages
> | > | are not on CRAN.
> | >
> | > I fear that is not quite the case. ?There are quite a few packages like that.
> |
> | Not the case? ?My post included a list of all License fields from the
> | DESCRIPTION file of every CRAN package so the list is definitive.
>
> Correct me if I am wrong in the paragraph you kindly left standing above, you
> seem to suggest that
>
> ? ? ? ?"all or almost all packages have some sort of free software license"
>
> and that while non-free licenses may exist,
>
> ? ? ? ?"any such packages are not on CRAN".
>
> I believe this statement to be false.
>
> There are packages with restrictive licenese on CRAN. ?They were contained in
> the list of licenses you assembled, and my point is that it is overly hard to
> identify them (if one were to tty to avoid using these packages).
>
> As a non-exhautive list with possible misclassifications, cran2deb currently
> has these packasges as 'maybe not free' and does not build them:
>
> ? ? BARD,BayesDA,CoCo,ConvCalendar,FAiR,PTAk,RScaLAPACK,Rcsdp,SDDA,SGP,
> ? ? alphahull,ash,asypow,caMassClass,gpclib,mapproj,matlab,mclust,mclust02,
> ? ? mlbench,optmatch,rankreg,realized,rngwell19937,rtiff,rwt,scagnostics,
> ? ? sgeostat,spatialkernel,tlnise,xgobi
>
> We are missing some recently added packages, and we may yet flag several from
> the list above as free. Some may be listed because of non-free Depends:
>
> But to take a concrete example, 'realized' is not something I am supposed to
> install at work. ?Yet install.packages() currently has not way knowing that.
>
> Are we approximately on the same page ?
>
> Dirk
>
> --
> Three out of two people have difficulties with fractions.
>


From marc_schwartz at me.com  Thu Apr 23 22:35:54 2009
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 23 Apr 2009 15:35:54 -0500
Subject: [Rd] License status of CRAN packages
In-Reply-To: <18928.51543.939132.165160@ron.nulle.part>
References: <18928.48327.599527.545472@ron.nulle.part>
	<971536df0904231232vbb024c8p95456acaeae0ff6d@mail.gmail.com>
	<18928.51543.939132.165160@ron.nulle.part>
Message-ID: <77D033CF-9E55-49C6-818D-51773FF723FD@me.com>

On Apr 23, 2009, at 3:02 PM, Dirk Eddelbuettel wrote:

>
> On 23 April 2009 at 15:32, Gabor Grothendieck wrote:
> | On Thu, Apr 23, 2009 at 3:08 PM, Dirk Eddelbuettel  
> <edd at debian.org> wrote:
> | >
> | > (Subject: renamed as thread hijacked from the ParallelR thread    
> --Dirk)
> | >
> | > On 23 April 2009 at 14:44, Gabor Grothendieck wrote:
> | > | Aside from R there are the add-on packages.
> | > |
> | > | A frequency table showing the licenses of the CRAN packages  
> indicates
> | > | that the all or almost all packages have some sort of free  
> software license
> | > | with GPL licenses being most common. (A few packages have  
> restrictions
> | > | to noncommercial use and that may conflict with GPL, not  
> sure.)   That is
> | > | not to say that there are no other types of packages but any  
> such packages
> | > | are not on CRAN.
> | >
> | > I fear that is not quite the case.  There are quite a few  
> packages like that.
> |
> | Not the case?  My post included a list of all License fields from  
> the
> | DESCRIPTION file of every CRAN package so the list is definitive.
>
> Correct me if I am wrong in the paragraph you kindly left standing  
> above, you
> seem to suggest that
>
> 	"all or almost all packages have some sort of free software license"
>
> and that while non-free licenses may exist,
>
> 	"any such packages are not on CRAN".
>
> I believe this statement to be false.
>
> There are packages with restrictive licenese on CRAN.  They were  
> contained in
> the list of licenses you assembled, and my point is that it is  
> overly hard to
> identify them (if one were to tty to avoid using these packages).
>
> As a non-exhautive list with possible misclassifications, cran2deb  
> currently
> has these packasges as 'maybe not free' and does not build them:
>
>      
> BARD,BayesDA,CoCo,ConvCalendar,FAiR,PTAk,RScaLAPACK,Rcsdp,SDDA,SGP,
>      
> alphahull 
> ,ash,asypow,caMassClass,gpclib,mapproj,matlab,mclust,mclust02,
>      
> mlbench,optmatch,rankreg,realized,rngwell19937,rtiff,rwt,scagnostics,
>     sgeostat,spatialkernel,tlnise,xgobi
>
> We are missing some recently added packages, and we may yet flag  
> several from
> the list above as free. Some may be listed because of non-free  
> Depends:
>
> But to take a concrete example, 'realized' is not something I am  
> supposed to
> install at work.  Yet install.packages() currently has not way  
> knowing that.
>
> Are we approximately on the same page ?
>
> Dirk

There is a list of acceptable entries that are defined as part of the  
specs in R-exts (see page 4). Perhaps this needs to be "tightened" a  
bit, at least in so far as packages passing R CMD check for the  
purpose of inclusion on CRAN. That would include perhaps altering the  
ability to use the 'file LICENSE' option, which at present leaves the  
door wide open for non-standard approaches. It may also have to check  
for DEPENDS and whether they too are on CRAN and passed the  
appropriate license checks.

Packages that fail this check should not be included on CRAN and the  
package author would then be obligated to find other distribution  
resources or contact the CRAN maintainers to advocate that their  
licensing schema should be acceptable.

Then the end user can at least have some comfort in knowing that  
anything they get from CRAN comes under a compatible license for  
general use without restriction. They would have to intentionally use  
other sources for packages that fail the CRAN requirements.

If other distribution venues, such as Debian/Ubuntu/Fedora elect to  
tighten those restrictions even further when making .debs or RPMs  
available, then that is a decision that they get to make and end users  
will need to be aware of those as well. Albeit I don't envision the  
aforementioned Linux distros including packages that should be a  
problem for most end users relative to usage restrictions given their  
own license review processes.

HTH,

Marc Schwartz


From ggrothendieck at gmail.com  Thu Apr 23 22:50:20 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 23 Apr 2009 16:50:20 -0400
Subject: [Rd] License status of CRAN packages
In-Reply-To: <77D033CF-9E55-49C6-818D-51773FF723FD@me.com>
References: <18928.48327.599527.545472@ron.nulle.part>
	<971536df0904231232vbb024c8p95456acaeae0ff6d@mail.gmail.com> 
	<18928.51543.939132.165160@ron.nulle.part>
	<77D033CF-9E55-49C6-818D-51773FF723FD@me.com>
Message-ID: <971536df0904231350j5da85c7dh34ce4f42b056d0e9@mail.gmail.com>

In some other software systems there are separate repositories for
free and non-free add-ons.  That way its clear what you are downloading
yet there are good outlets for both types of software.  There has been some
discussion of future features that CRAN might have that might make
this even easier to do.   My opinion is that R will suffer if it were not
to support both types of software but at the same time its reasonable
to make it clear which type you are getting before you download it.

On Thu, Apr 23, 2009 at 4:35 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
> On Apr 23, 2009, at 3:02 PM, Dirk Eddelbuettel wrote:
>
>>
>> On 23 April 2009 at 15:32, Gabor Grothendieck wrote:
>> | On Thu, Apr 23, 2009 at 3:08 PM, Dirk Eddelbuettel <edd at debian.org>
>> wrote:
>> | >
>> | > (Subject: renamed as thread hijacked from the ParallelR thread
>> --Dirk)
>> | >
>> | > On 23 April 2009 at 14:44, Gabor Grothendieck wrote:
>> | > | Aside from R there are the add-on packages.
>> | > |
>> | > | A frequency table showing the licenses of the CRAN packages
>> indicates
>> | > | that the all or almost all packages have some sort of free software
>> license
>> | > | with GPL licenses being most common. (A few packages have
>> restrictions
>> | > | to noncommercial use and that may conflict with GPL, not sure.)
>> That is
>> | > | not to say that there are no other types of packages but any such
>> packages
>> | > | are not on CRAN.
>> | >
>> | > I fear that is not quite the case. ?There are quite a few packages
>> like that.
>> |
>> | Not the case? ?My post included a list of all License fields from the
>> | DESCRIPTION file of every CRAN package so the list is definitive.
>>
>> Correct me if I am wrong in the paragraph you kindly left standing above,
>> you
>> seem to suggest that
>>
>> ? ? ? ?"all or almost all packages have some sort of free software
>> license"
>>
>> and that while non-free licenses may exist,
>>
>> ? ? ? ?"any such packages are not on CRAN".
>>
>> I believe this statement to be false.
>>
>> There are packages with restrictive licenese on CRAN. ?They were contained
>> in
>> the list of licenses you assembled, and my point is that it is overly hard
>> to
>> identify them (if one were to tty to avoid using these packages).
>>
>> As a non-exhautive list with possible misclassifications, cran2deb
>> currently
>> has these packasges as 'maybe not free' and does not build them:
>>
>> ? ?BARD,BayesDA,CoCo,ConvCalendar,FAiR,PTAk,RScaLAPACK,Rcsdp,SDDA,SGP,
>> ? ?alphahull,ash,asypow,caMassClass,gpclib,mapproj,matlab,mclust,mclust02,
>> ? ?mlbench,optmatch,rankreg,realized,rngwell19937,rtiff,rwt,scagnostics,
>> ? ?sgeostat,spatialkernel,tlnise,xgobi
>>
>> We are missing some recently added packages, and we may yet flag several
>> from
>> the list above as free. Some may be listed because of non-free Depends:
>>
>> But to take a concrete example, 'realized' is not something I am supposed
>> to
>> install at work. ?Yet install.packages() currently has not way knowing
>> that.
>>
>> Are we approximately on the same page ?
>>
>> Dirk
>
> There is a list of acceptable entries that are defined as part of the specs
> in R-exts (see page 4). Perhaps this needs to be "tightened" a bit, at least
> in so far as packages passing R CMD check for the purpose of inclusion on
> CRAN. That would include perhaps altering the ability to use the 'file
> LICENSE' option, which at present leaves the door wide open for non-standard
> approaches. It may also have to check for DEPENDS and whether they too are
> on CRAN and passed the appropriate license checks.
>
> Packages that fail this check should not be included on CRAN and the package
> author would then be obligated to find other distribution resources or
> contact the CRAN maintainers to advocate that their licensing schema should
> be acceptable.
>
> Then the end user can at least have some comfort in knowing that anything
> they get from CRAN comes under a compatible license for general use without
> restriction. They would have to intentionally use other sources for packages
> that fail the CRAN requirements.
>
> If other distribution venues, such as Debian/Ubuntu/Fedora elect to tighten
> those restrictions even further when making .debs or RPMs available, then
> that is a decision that they get to make and end users will need to be aware
> of those as well. Albeit I don't envision the aforementioned Linux distros
> including packages that should be a problem for most end users relative to
> usage restrictions given their own license review processes.
>
> HTH,
>
> Marc Schwartz
>
>


From edd at debian.org  Thu Apr 23 23:00:28 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 23 Apr 2009 16:00:28 -0500
Subject: [Rd] License status of CRAN packages
In-Reply-To: <77D033CF-9E55-49C6-818D-51773FF723FD@me.com>
References: <18928.48327.599527.545472@ron.nulle.part>
	<971536df0904231232vbb024c8p95456acaeae0ff6d@mail.gmail.com>
	<18928.51543.939132.165160@ron.nulle.part>
	<77D033CF-9E55-49C6-818D-51773FF723FD@me.com>
Message-ID: <18928.55020.929154.341291@ron.nulle.part>


On 23 April 2009 at 15:35, Marc Schwartz wrote:
| There is a list of acceptable entries that are defined as part of the  
| specs in R-exts (see page 4). Perhaps this needs to be "tightened" a  
| bit, at least in so far as packages passing R CMD check for the  
| purpose of inclusion on CRAN. That would include perhaps altering the  
| ability to use the 'file LICENSE' option, which at present leaves the  
| door wide open for non-standard approaches. It may also have to check  
| for DEPENDS and whether they too are on CRAN and passed the  
| appropriate license checks.

Exactly. 

| Packages that fail this check should not be included on CRAN and the  
| package author would then be obligated to find other distribution  
| resources or contact the CRAN maintainers to advocate that their  
| licensing schema should be acceptable.
| 
| Then the end user can at least have some comfort in knowing that  
| anything they get from CRAN comes under a compatible license for  
| general use without restriction. They would have to intentionally use  
| other sources for packages that fail the CRAN requirements.

Exactly.  I think we may have to work on tightening the standards of CRAN
re-distribution.

| If other distribution venues, such as Debian/Ubuntu/Fedora elect to  

cran2deb does not have inclusion to Debian in mind. What Charles and I are
thinking about is something aking to the Windows situation: suitable i386 and
amd64 binaries (for Debian Linux) provided from CRAN for as many packages as
possible.

Dirk

-- 
Three out of two people have difficulties with fractions.


From goodrich at fas.harvard.edu  Thu Apr 23 22:59:29 2009
From: goodrich at fas.harvard.edu (Ben Goodrich)
Date: Thu, 23 Apr 2009 20:59:29 +0000 (UTC)
Subject: [Rd] License status of CRAN packages
References: <18928.48327.599527.545472@ron.nulle.part>
	<971536df0904231232vbb024c8p95456acaeae0ff6d@mail.gmail.com>
	<18928.51543.939132.165160@ron.nulle.part>
Message-ID: <loom.20090423T204756-245@post.gmane.org>

Dirk Eddelbuettel <edd <at> debian.org> writes:
> As a non-exhautive list with possible misclassifications, cran2deb currently
> has these packasges as 'maybe not free' and does not build them:
> 
>      BARD,BayesDA,CoCo,ConvCalendar,FAiR,PTAk,RScaLAPACK,Rcsdp,SDDA,SGP,
>      alphahull,ash,asypow,caMassClass,gpclib,mapproj,matlab,mclust,mclust02,
>      mlbench,optmatch,rankreg,realized,rngwell19937,rtiff,rwt,scagnostics,
>      sgeostat,spatialkernel,tlnise,xgobi

Small point: FAiR is free. The file LICENSE thing just clarifies that most of
the code is AGPL but a couple files can't be included under the AGPL and are
plain GPL. As far as I can see, R does not give me the option of saying so in a
"standard" way, e.g. putting License: AGPL (>= 3) in the DESCRIPTION file would
only be 95% accurate and putting License: AGPL (>= 3) | GPL (>= 3) is misleading.

Ben


From edd at debian.org  Thu Apr 23 23:05:23 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 23 Apr 2009 16:05:23 -0500
Subject: [Rd] License status of CRAN packages
In-Reply-To: <971536df0904231335s25d1c134l58db3f7280c053e2@mail.gmail.com>
References: <18928.48327.599527.545472@ron.nulle.part>
	<971536df0904231232vbb024c8p95456acaeae0ff6d@mail.gmail.com>
	<18928.51543.939132.165160@ron.nulle.part>
	<971536df0904231335s25d1c134l58db3f7280c053e2@mail.gmail.com>
Message-ID: <18928.55315.939029.188945@ron.nulle.part>


On 23 April 2009 at 16:35, Gabor Grothendieck wrote:
| Of the 31 packages listed:
|  [1] "BARD"          "BayesDA"       "CoCo"          "ConvCalendar"
|  [5] "FAiR"          "PTAk"          "RScaLAPACK"    "Rcsdp"
|  [9] "SDDA"          "SGP"           "alphahull"     "ash"
| [13] "asypow"        "caMassClass"   "gpclib"        "mapproj"
| [17] "matlab"        "mclust"        "mclust02"      "mlbench"
| [21] "optmatch"      "rankreg"       "realized"      "rngwell19937"
| [25] "rtiff"         "rwt"           "scagnostics"   "sgeostat"
| [29] "spatialkernel" "tlnise"        "xgobi"
| 
| the license fields are AGPL or GPL for 3 and specified in a separate
| file "file LICENSE" so about 30 of 1700 < 2% are question marks.

My point is that you currently need to manually parse 'file LICENSE'.  

And as I said, we did not claim that our set was exhaustive, current or
perfect. We just can't automate anything better given the current framework.
And I think we all should be able to do better in scripted approaches.  I
still think you're proving my point.  

| To me that is not inconsistent with all or nearly all being free software

I doubt that "all or nearly all" would equated to "exactly all" by a
court. You only need one bad apple to spoil the lot.

Dirk

-- 
Three out of two people have difficulties with fractions.


From mxkuhn at gmail.com  Thu Apr 23 23:12:39 2009
From: mxkuhn at gmail.com (Max Kuhn)
Date: Thu, 23 Apr 2009 17:12:39 -0400
Subject: [Rd] Closed-source non-free ParallelR ?
In-Reply-To: <8b356f880904231322j1251d50if184b94f24c619ca@mail.gmail.com>
References: <373DCC90906D430E952EF2C423B0D91B@ADAM>
	<ac81d400904220740i5a4adac4l41b1a170c6f27bd7@mail.gmail.com>
	<475a3c8f0904220836w43d07042m84f42edf6e05766c@mail.gmail.com>
	<E1C5F6F55B4445AF902DF4B970BE1688@ADAM>
	<8b356f880904230947n6a410d2lc06b9088e53041b0@mail.gmail.com>
	<B49C0AC4-8331-4F2D-81A7-48119E369221@me.com>
	<8b356f880904231322j1251d50if184b94f24c619ca@mail.gmail.com>
Message-ID: <6731304c0904231412u6c191ec8h1152d38ae5f614fb@mail.gmail.com>

> REvolution appear to be offering ParallelR only when bundled with their R Enterprise edition.  As such it appears to be non-free and closed source.
>    http://www.revolution-computing.com/products/parallel-r.php

Have you also looked at:

   http://nws-r.sourceforge.net/

The core of their ParallelR product is nws and that package was last
updated a month ago.

-- 

Max


From ggrothendieck at gmail.com  Thu Apr 23 23:13:22 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 23 Apr 2009 17:13:22 -0400
Subject: [Rd] License status of CRAN packages
In-Reply-To: <loom.20090423T204756-245@post.gmane.org>
References: <18928.48327.599527.545472@ron.nulle.part>
	<971536df0904231232vbb024c8p95456acaeae0ff6d@mail.gmail.com> 
	<18928.51543.939132.165160@ron.nulle.part>
	<loom.20090423T204756-245@post.gmane.org>
Message-ID: <971536df0904231413y58e6ea53s9f23d02575c62a23@mail.gmail.com>

On Thu, Apr 23, 2009 at 4:59 PM, Ben Goodrich <goodrich at fas.harvard.edu> wrote:
> Dirk Eddelbuettel <edd <at> debian.org> writes:
>> As a non-exhautive list with possible misclassifications, cran2deb currently
>> has these packasges as 'maybe not free' and does not build them:
>>
>> ? ? ?BARD,BayesDA,CoCo,ConvCalendar,FAiR,PTAk,RScaLAPACK,Rcsdp,SDDA,SGP,
>> ? ? ?alphahull,ash,asypow,caMassClass,gpclib,mapproj,matlab,mclust,mclust02,
>> ? ? ?mlbench,optmatch,rankreg,realized,rngwell19937,rtiff,rwt,scagnostics,
>> ? ? ?sgeostat,spatialkernel,tlnise,xgobi
>
> Small point: FAiR is free. The file LICENSE thing just clarifies that most of
> the code is AGPL but a couple files can't be included under the AGPL and are
> plain GPL. As far as I can see, R does not give me the option of saying so in a
> "standard" way, e.g. putting License: AGPL (>= 3) in the DESCRIPTION file would
> only be 95% accurate and putting License: AGPL (>= 3) | GPL (>= 3) is misleading.

How about "

License: AGPL except for 2 GPL files


From fjs21 at hotmail.com  Thu Apr 23 18:28:46 2009
From: fjs21 at hotmail.com (Fraser Sim)
Date: Thu, 23 Apr 2009 12:28:46 -0400
Subject: [Rd] Closed-source non-free ParallelR ?
In-Reply-To: <E1C5F6F55B4445AF902DF4B970BE1688@ADAM>
References: <373DCC90906D430E952EF2C423B0D91B@ADAM><ac81d400904220740i5a4adac4l41b1a170c6f27bd7@mail.gmail.com><475a3c8f0904220836w43d07042m84f42edf6e05766c@mail.gmail.com>
	<E1C5F6F55B4445AF902DF4B970BE1688@ADAM>
Message-ID: <BLU142-DS67AE7CEE5D6DFCE7EED13B3750@phx.gbl>

Hi Matt,

Do you know if a project like R(D)COM/Statconn can changing their license to
make it closed-source? (www.statconn.com & http://rcom.univie.ac.at/ )

There was discussion on the RCom board about such changes earlier this year
as they move toward commercialization. If you're not familiar it's a
package/windows COM program that allows EXCEL and other win apps to interact
directly with R. They have also generated an installer package which
installs R at the same time as their software. It makes 'R' effectively
disappear from the windows box.

Would distribution of that software also have to stay as GPL not LGPL? As R
effectively sits within the proprietary system of Statconn.

Regards, Fraser

-----Original Message-----
From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
On Behalf Of Matthew Dowle
Sent: Wednesday, April 22, 2009 7:37 PM
To: David M Smith; Patrick Shields; r-devel at r-project.org
Subject: Re: [Rd] Closed-source non-free ParallelR ?

> how could it [MCE] swap a GPL license for the BSD?
Because the BSD is an open source license compatible with GPL.  See 
http://www.fsf.org/licensing/licenses/index_html#GPLCompatibleLicenses

> derivative work
Points taken. It may not be derivation in the sense of modification, more in

the sense of using R as a library :
http://www.gnu.org/licenses/gpl-faq.html#GPLInProprietarySystem
http://www.gnu.org/licenses/gpl-faq.html#IfLibraryIsGPL
http://www.gnu.org/licenses/gpl-faq.html#LinkingWithGPL
http://www.gnu.org/licenses/gpl-faq.html#IfInterpreterIsGPL  (paragraphs 3 
and 4 in particular)

R, and base functions written in R, are GPL not LGPL.  In the context of the

FAQ above, do your packages use base functions ?
http://www.gnu.org/philosophy/why-not-lgpl.html

The first R FAQ (1.1) states that R is released under GPL version 2 or any 
later version.
At the end of the GPL (both v2 and v3) it says "This General Public License 
does not permit incorporating your program into proprietary programs. If 
your program is a subroutine library, you may consider it more useful to 
permit linking proprietary applications with the library. If this is what 
you want to do, use the GNU Lesser General Public License instead of this 
License."

> there are certainly many existing R packages with non-free/non-open 
> licenses
They could be in breach too. The fact their licenses are like that does not 
in itself mean they are compliant with the GPL. R FAQ 2.11 defers to legal 
counsel - it mentions such licenses but it states no opinion about them as 
far as my reading goes. At least the source code of those packages is 
available for download. REvolution appear to be going one step further i.e. 
bundling R with their proprietary packages and selling the work as a whole.

Could someone from the R Foundation or the FSF step in and clarify the 
situation please ?   If in your opinion it is all fine what people are 
doing, why not release R under the LGPL for clarity ?

Regards, Matthew

----- Original Message ----- 
From: "David M Smith" <david at revolution-computing.com>
To: "Matthew Dowle" <mdowle at mdowle.plus.com>
Cc: "Patrick Shields" <pat at revolution-computing.com>; 
<r-devel at r-project.org>
Sent: Wednesday, April 22, 2009 4:36 PM
Subject: Re: [Rd] Closed-source non-free ParallelR ?


Patrick made all the points that I was going to make (thanks,
Patrick), but I wanted to reinforce one point that may be the source
of the confusion: ParallelR is not a modified version of R: ParallelR
is a suite of ordinary R packages that run on top of the R engine like
any other package. The R code and Python code in these packages were
written entirely by REvolution Computing staff (including Patrick),
and do not contain any code (derived or otherwise) from the R project.

In retrospect, the name ParallelR may be somewhat confusing in this sense...

# David Smith

On Wed, Apr 22, 2009 at 7:40 AM, Patrick Shields
<pat at revolution-computing.com> wrote:
> I'm Pat Shields, one of the software engineers working on ParallelR. I 
> just
> wanted to make two points: no R code or previously gpl'd code can be found
> in any of the non-gpl packages in ParallelR. I'm sure that the phrase
> "derived works" is a legally subtle one, but all these packages include 
> are
> R and occasionally python scripts (as well as the standard text
> documentation). If these are derived works, doesn't that mean that any R
> code is also, by extension, required to be GPL'd? If not, is it including
> these scripts in a package that forces the use of the GPL?
>
> Also, I'm confused about your dimissal of the MCE example. If that code 
> was
> a derivative work of R, how could it swap a GPL license for the BSD? I
> didn't think such a switch was possible. If it was, I'd imagine a lot more
> use of it, as a quick front project could make GPL software into BSD
> software after which all changes could go on behind closed doors.
>
> On Tue, Apr 21, 2009 at 7:38 PM, Matthew Dowle 
> <mdowle at mdowle.plus.com>wrote:
>
>> Dear R-devel,
>>
>> REvolution appear to be offering ParallelR only when bundled with their R
>> Enterprise edition. As such it appears to be non-free and closed source.
>> http://www.revolution-computing.com/products/parallel-r.php
>>
>> Since R is GPL and not LGPL, is this a breach of the GPL ?
>>
>> Below is the "GPL and ParallelR" thread from their R forum.
>>
>> mdowle > It appears that ParallelR (packages foreach and iterators) is
>> only available bundled with the Enterprise edition. Since R is GPL, and
>> ParallelR is derived from R, should ParallelR not also be GPL? Regards,
>> Matthew
>>
>> revolution > Hello Matthew, ParallelR consists of both proprietary and 
>> GPL
>> packages. The randomForest and snow libraries GPL licensed, whereas the
>> other libraries we include have a commercial license(including 'foreach' 
>> and
>> 'iterators'). Stephen Weller
>>
>> revolution > I wanted to expand on Stephen's reply. ParallelR is a suite 
>> of
>> R packages, and it is well established that packages can be under a
>> difference license than R itself (i.e. not the GPL). For example, package
>> MCE is licensed under BSD, RColorBrewer is licensed under Apache, most of
>> Bioconductor is under the Artistic license and some are under completely
>> unique licenses (e.g. mclust). REvolution Computing developed all of the
>> code in ParallelR (except for the bundled GPL packages Stephen mentions),
>> and we decided to release it under our own license in REvolution R
>> Enterprise.
>> That said, we do already release components of parallelR, such as the
>> underlying engine, Networkspaces (also written by REvolution Computing)
>> under an open source licence. Also, we are likely to release some other
>> components including foreach and iterators, to CRAN soon.
>> David Smith
>> Director of Community, REvolution Computing
>>
>> mdowle > The examples you give (MCE, RColorBrewer, Bioconductor) are all
>> available for free including the source code. Their licenses have been
>> approved by the FSF. Free software and open source are the terms of work
>> derived from GPL licensed software. REvolution's packages 'foreach' and
>> 'iterators' are neither free or open source. Can you provide a precedent
>> for proprietary closed-source packages for R ? Is your policy approved by
>> the FSF ?
>> I don't object to REvolution. I am a fan of you making money from 
>> training
>> courses, consultancy, support and binaries. These are all permitted by 
>> the
>> GPL. However the GPL does not allow you to distribute work derived from R
>> which is either closed source or non-free.
>> R is GPL, not LGPL.
>> The above is my personal understanding. I am now posting to r-devel to
>> check, feel free to join the public debate there.
>>
>> Regards, Matthew
>>
>> [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>
> --
> Pat Shields
> Software Engineer
> REvolution Computing
> One Century Tower | 265 Church Street, Suite 1006
> New Haven, CT 06510
> P: 203-777-7442 x250 | www.revolution-computing.com
>
> Check out our upcoming events schedule at
> www.revolution-computing.com/events
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
David M Smith <david at revolution-computing.com>
Director of Community, REvolution Computing www.revolution-computing.com
Tel: +1 (206) 577-4778 x3203 (San Francisco, USA)

Check out our upcoming events schedule at 
www.revolution-computing.com/events

______________________________________________
R-devel at r-project.org mailing list


From goodrich at fas.harvard.edu  Thu Apr 23 23:30:13 2009
From: goodrich at fas.harvard.edu (Ben Goodrich)
Date: Thu, 23 Apr 2009 17:30:13 -0400
Subject: [Rd] License status of CRAN packages
In-Reply-To: <971536df0904231413y58e6ea53s9f23d02575c62a23@mail.gmail.com>
References: <18928.48327.599527.545472@ron.nulle.part>
	<971536df0904231232vbb024c8p95456acaeae0ff6d@mail.gmail.com>
	<18928.51543.939132.165160@ron.nulle.part>
	<loom.20090423T204756-245@post.gmane.org>
	<971536df0904231413y58e6ea53s9f23d02575c62a23@mail.gmail.com>
Message-ID: <49F0DDE5.6060209@fas.harvard.edu>

Gabor Grothendieck wrote:
> On Thu, Apr 23, 2009 at 4:59 PM, Ben Goodrich <goodrich at fas.harvard.edu> wrote:
>> Dirk Eddelbuettel <edd <at> debian.org> writes:
>>> As a non-exhautive list with possible misclassifications, cran2deb currently
>>> has these packasges as 'maybe not free' and does not build them:
>>>
>>>      BARD,BayesDA,CoCo,ConvCalendar,FAiR,PTAk,RScaLAPACK,Rcsdp,SDDA,SGP,
>>>      alphahull,ash,asypow,caMassClass,gpclib,mapproj,matlab,mclust,mclust02,
>>>      mlbench,optmatch,rankreg,realized,rngwell19937,rtiff,rwt,scagnostics,
>>>      sgeostat,spatialkernel,tlnise,xgobi
>> Small point: FAiR is free. The file LICENSE thing just clarifies that most of
>> the code is AGPL but a couple files can't be included under the AGPL and are
>> plain GPL. As far as I can see, R does not give me the option of saying so in a
>> "standard" way, e.g. putting License: AGPL (>= 3) in the DESCRIPTION file would
>> only be 95% accurate and putting License: AGPL (>= 3) | GPL (>= 3) is misleading.
> 
> How about "
> 
> License: AGPL except for 2 GPL files
> 

If that would make anyone's life easier without making anyone else's
life harder, I would be happy to put that in the DESCRIPTION file. I
have been doing file LICENSE because it parses on

http://cran.r-project.org/web/packages/FAiR/index.html

and people can click to the LICENSE link to read the details if they are
interested. But maybe that is not optimal. Dirk?

Ben


From marc_schwartz at me.com  Thu Apr 23 23:34:00 2009
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 23 Apr 2009 16:34:00 -0500
Subject: [Rd] Closed-source non-free ParallelR ?
In-Reply-To: <8b356f880904231322j1251d50if184b94f24c619ca@mail.gmail.com>
References: <373DCC90906D430E952EF2C423B0D91B@ADAM>
	<ac81d400904220740i5a4adac4l41b1a170c6f27bd7@mail.gmail.com>
	<475a3c8f0904220836w43d07042m84f42edf6e05766c@mail.gmail.com>
	<E1C5F6F55B4445AF902DF4B970BE1688@ADAM>
	<8b356f880904230947n6a410d2lc06b9088e53041b0@mail.gmail.com>
	<B49C0AC4-8331-4F2D-81A7-48119E369221@me.com>
	<8b356f880904231322j1251d50if184b94f24c619ca@mail.gmail.com>
Message-ID: <F21BE202-7384-40EF-B608-A7A1E821CE4E@me.com>


On Apr 23, 2009, at 3:22 PM, Stavros Macrakis wrote:

> On Thu, Apr 23, 2009 at 1:25 PM, Marc Schwartz  
> <marc_schwartz at me.com> wrote:
>> On Apr 23, 2009, at 11:47 AM, Stavros Macrakis wrote:
>>>
>>> All that being said, the entity that must enforce these conditions  
>>> is
>>> not the FSF, but the copyright owner, in this case the R  
>>> Foundation...
>>> bundler. So it would be useful to know what the R Foundation's
>>> position is....
>
>> Actually, the R Foundation has done what it is obligated to do,  
>> which is to
>> describe the license under which R is made available.
>
> I did not say that the R Foundation was obligated to give advice.  I
> said that it is up to the R Foundation to decide what cases it cares
> about, and it would be "useful to know" what that position is.
>
>> To ask the R Foundation for anything further is to ask them to  
>> render a legal
>> opinion, which is not in their expertise to offer.
>
> No, it is asking them what their *policy* is.  Their policy may or may
> not be enforceable....
>
>> It is up to the prospective third party developer of an application  
>> that is
>> to use R to consult with lawyers to determine what *THEIR*  
>> obligations are
>> if they should elect to proceed.
>
> Yes, this is true.  But it is also true that if (for example) the R
> Foundation says officially that it interprets GPL to allow
> distributing proprietary packages along with R, then that is the
> interpretation that matters, since the R Foundation (not the FSF) is
> the copyright holder.
>
>> At this level, it is really pretty simple and a lot of these things  
>> are
>> covered in the GPL FAQs, including the reporting of violations.
>
> The GPL FAQs are the FSF's interpretation.  The R Foundation is not
> obliged to have the same interpretation, and of course the FSF cannot
> enforce licenses given by the R Foundation.

Underlying all of your comments seems to be a presumption that the R  
Foundation can disentangle themselves from the FSF vis-a-vis the GPL.

Keep in mind that it is the FSF that is the copyright holder of the GPL.

The R Foundation may be the copyright holder to R, but they are  
distributing it under a license which they did not write.

Thus, I cannot envision any reasonable circumstances under which the R  
Foundation would place themselves in a position of legal risk in  
deviating from the interpretations of the GPL by the FSF. It would be  
insane legally to do so.

The key issue is the lack of case law relative to the GPL and that  
leaves room for interpretation. One MUST therefore give significant  
weight to the interpretations of the FSF as it will likely be the FSF  
that will be involved in any legal disputes over the GPL and its  
application. You would want them on your side, not be fighting them.

A parallel here is why most large U.S. public corporations legally  
incorporate in the state of Delaware, even though they may not have  
any material physical presence in that state. It is because the  
overwhelming majority of corporate case law in the U.S. has been  
decided under the laws of Delaware and the interpretations of said  
laws. If I were to start a company (which I have done in the past) and  
feared that I should find myself facing litigation at some future  
date, I would want that huge database of case law behind me. A small  
company (such as I had) may be less concerned about this and be  
comfortable with the laws of their own state, which I was. But if I  
were to be looking to build a big company with investors, etc. and  
perhaps look to go public at a future date, you bet I would look to  
incorporate in Delaware. It would be the right fiduciary decision to  
make in the interest of all parties.

Unfortunately, we have no such archive of case law yet of the GPL.  
Thus at least from a legally enforceable perspective, all is grey and  
the FSF has to be the presumptive leader here.

HTH,

Marc Schwartz


From ifellows at ucsd.edu  Fri Apr 24 00:21:45 2009
From: ifellows at ucsd.edu (Ian Fellows)
Date: Thu, 23 Apr 2009 15:21:45 -0700
Subject: [Rd] Closed-source non-free ParallelR ?
In-Reply-To: <F21BE202-7384-40EF-B608-A7A1E821CE4E@me.com>
Message-ID: <384C84AE99C74D9898E4F04DE0E34F49@gpbdmx>

Assuming that the foundation does not want to deviate from the FSF
interpretation, there would still be value in clarifying its position
vis-?-vis how the license applies to R specifically. 

For example the FSF foundation claims that linking to a library (even in an
interpreted environment) makes your software derivative, and therefore must
be distributed Freely. They also claim that simply executing a program in an
interpreted (GPL'ed) environment is okay even though the program could not
be run without it. So one question might be, where does the language end and
the libraries begin? Are any/all of the default packages considered part of
the language? It seems hard to imagine doing anything at all without at
least 'base.' If I install R in the usual way with no other
packages/libraries can I release whatever I write under any license, or does
it have to be GPL compatible?

While I wouldn't expect R core to formulate formal legal opinions regarding
questions like these, it would be nice if there were some kind of "community
standards."

Ian

-----Original Message-----
From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
On Behalf Of Marc Schwartz
Sent: Thursday, April 23, 2009 2:34 PM
To: Stavros Macrakis
Cc: Matthew Dowle; r-devel at r-project.org
Subject: Re: [Rd] Closed-source non-free ParallelR ?


On Apr 23, 2009, at 3:22 PM, Stavros Macrakis wrote:

> On Thu, Apr 23, 2009 at 1:25 PM, Marc Schwartz  
> <marc_schwartz at me.com> wrote:
>> On Apr 23, 2009, at 11:47 AM, Stavros Macrakis wrote:
>>>
>>> All that being said, the entity that must enforce these conditions  
>>> is
>>> not the FSF, but the copyright owner, in this case the R  
>>> Foundation...
>>> bundler. So it would be useful to know what the R Foundation's
>>> position is....
>
>> Actually, the R Foundation has done what it is obligated to do,  
>> which is to
>> describe the license under which R is made available.
>
> I did not say that the R Foundation was obligated to give advice.  I
> said that it is up to the R Foundation to decide what cases it cares
> about, and it would be "useful to know" what that position is.
>
>> To ask the R Foundation for anything further is to ask them to  
>> render a legal
>> opinion, which is not in their expertise to offer.
>
> No, it is asking them what their *policy* is.  Their policy may or may
> not be enforceable....
>
>> It is up to the prospective third party developer of an application  
>> that is
>> to use R to consult with lawyers to determine what *THEIR*  
>> obligations are
>> if they should elect to proceed.
>
> Yes, this is true.  But it is also true that if (for example) the R
> Foundation says officially that it interprets GPL to allow
> distributing proprietary packages along with R, then that is the
> interpretation that matters, since the R Foundation (not the FSF) is
> the copyright holder.
>
>> At this level, it is really pretty simple and a lot of these things  
>> are
>> covered in the GPL FAQs, including the reporting of violations.
>
> The GPL FAQs are the FSF's interpretation.  The R Foundation is not
> obliged to have the same interpretation, and of course the FSF cannot
> enforce licenses given by the R Foundation.

Underlying all of your comments seems to be a presumption that the R  
Foundation can disentangle themselves from the FSF vis-a-vis the GPL.

Keep in mind that it is the FSF that is the copyright holder of the GPL.

The R Foundation may be the copyright holder to R, but they are  
distributing it under a license which they did not write.

Thus, I cannot envision any reasonable circumstances under which the R  
Foundation would place themselves in a position of legal risk in  
deviating from the interpretations of the GPL by the FSF. It would be  
insane legally to do so.

The key issue is the lack of case law relative to the GPL and that  
leaves room for interpretation. One MUST therefore give significant  
weight to the interpretations of the FSF as it will likely be the FSF  
that will be involved in any legal disputes over the GPL and its  
application. You would want them on your side, not be fighting them.

A parallel here is why most large U.S. public corporations legally  
incorporate in the state of Delaware, even though they may not have  
any material physical presence in that state. It is because the  
overwhelming majority of corporate case law in the U.S. has been  
decided under the laws of Delaware and the interpretations of said  
laws. If I were to start a company (which I have done in the past) and  
feared that I should find myself facing litigation at some future  
date, I would want that huge database of case law behind me. A small  
company (such as I had) may be less concerned about this and be  
comfortable with the laws of their own state, which I was. But if I  
were to be looking to build a big company with investors, etc. and  
perhaps look to go public at a future date, you bet I would look to  
incorporate in Delaware. It would be the right fiduciary decision to  
make in the interest of all parties.

Unfortunately, we have no such archive of case law yet of the GPL.  
Thus at least from a legally enforceable perspective, all is grey and  
the FSF has to be the presumptive leader here.

HTH,

Marc Schwartz

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From wdunlap at tibco.com  Fri Apr 24 00:23:57 2009
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 23 Apr 2009 15:23:57 -0700
Subject: [Rd] reference counting problem in .Primitive's?
In-Reply-To: <alpine.LFD.2.00.0904231252430.21901@nokomis.stat.uiowa.edu>
References: <77EB52C6DD32BA4D87471DCD70C8D70001130F9C@NA-PA-VBE03.na.tibco.com>
	<alpine.LFD.2.00.0904231252430.21901@nokomis.stat.uiowa.edu>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D70001131146@NA-PA-VBE03.na.tibco.com>

> -----Original Message-----
> From: luke at stat.uiowa.edu [mailto:luke at stat.uiowa.edu] 
> Sent: Thursday, April 23, 2009 11:06 AM
> To: William Dunlap
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] reference counting problem in .Primitive's?
> 
> On Thu, 23 Apr 2009, William Dunlap wrote:
> 
> > I think the following rather wierd expressions show a problem in how
> > some of the .Primitive functions evaluate their arguments.  
> I haven't
> > yet thought of a way that a nonabusive user might run into 
> this problem.
> > In each case the first argument, x, is modified in the course of
> > evaluating the second argument and then modified x gets used
> > as the first argument:
> >
> >> x<-as.integer(1:5); y <- x + { x[3]<-33L ; 1L } ; y
> > [1]  2  3 34  5  6
> >> x<-2^(0:4) ; y <- log(x, { x[3]<-64 ; 2 }) ; y
> > [1] 0 1 6 3 4
> >
> > The reason I think it looks like a sharing problem (and not an order
> > of evaluation problem) is that if your modification to x 
> causes it to
> > use a new block of memory then the unmodified version of x gets
> > used as the first argument.  E.g.,
> >
> >> x<-as.integer(1:5) ; y <- x + { x[3]<-33.3; 1L} ; y
> > [1] 2 3 4 5 6
> >
> > I haven't yet thought of a way that a nonabusive user might run
> > into this problem.

An hour after writing this one of our support folks sent me some
user-written code that contained something very close to this idiom;
the second argument to ":" is an altered version of the first argument:

   lengths<-5:1 ; start<-1
   for(i in seq(along=lengths)) {
        thisSeq <- start:((start <- start + lengths[i])-1)
        print(thisSeq)
   }
   [1] 1 2 3 4 5
   [1] 6 7 8 9
   [1] 10 11 12
   [1] 13 14
   [1] 15

That works.  However, if that user had also used 'start[] <- ' instead
of 'start <- ' then they would have run into this bug:

  lengths<-5:1 ; start<-1
  for(i in seq(along=lengths)) {
        thisSeq <- start:((start[] <- start + lengths[i])-1)
        print(thisSeq)
  }
  [1] 1 2 3 4 5
  [1] 10  9
  [1] 13 12
  [1] 15 14
  [1] 16 15

If they use start[] or start[1] consistently in the call to ":" then
they
don't hit the bug.

> 
> You are probably right.  I have not yet looked at the code but am
> virtually certain it does not try to temporarily bump up the NAMED
> values on argument values.  Doing so would cure this but probably at
> serious cost to performance, as NAMED values of 2 cannot be brought
> down again and so cause copying on next modify. (Might be worth
> running some tests on that though to see what the cost would be).

So, if NAMED were not limited to 0,1,or 2 this sort of thing might be
avoided with less pain?

> I'm not sure if it is written anywhere that argunments of primitives
> (BUILTINS in articular as those are always strict; SPECIALS can be
> non-strict but log is strict) are evaluated in any particular order.
> All these examples are consistent with _some_ evaluation order, but
> not the same one.  It might be possible to show that the results
> obtained in these situations will always be consistent with some
> evaluation order, in which case documenting that order of evaluation
> is unspecified would be good enough form me.  It may also be possible
> that an order that does compound expressions first and then symbols
> would also solve the issue (I don't think I would want to do this in
> the interpreter though because of the performance overhead.)
> 
> luke
> 
> 
> >
> > Bill Dunlap
> > TIBCO Software Inc - Spotfire Division
> > wdunlap tibco.com
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> -- 
> Luke Tierney
> Chair, Statistics and Actuarial Science
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>     Actuarial Science
> 241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
> 


From luke at stat.uiowa.edu  Fri Apr 24 00:44:19 2009
From: luke at stat.uiowa.edu (luke at stat.uiowa.edu)
Date: Thu, 23 Apr 2009 17:44:19 -0500 (CDT)
Subject: [Rd] reference counting problem in .Primitive's?
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D70001131146@NA-PA-VBE03.na.tibco.com>
References: <77EB52C6DD32BA4D87471DCD70C8D70001130F9C@NA-PA-VBE03.na.tibco.com>
	<alpine.LFD.2.00.0904231252430.21901@nokomis.stat.uiowa.edu>
	<77EB52C6DD32BA4D87471DCD70C8D70001131146@NA-PA-VBE03.na.tibco.com>
Message-ID: <alpine.LFD.2.00.0904231730290.3624@itasca2.wildberry.org>

On Thu, 23 Apr 2009, William Dunlap wrote:

>> -----Original Message-----
>> From: luke at stat.uiowa.edu [mailto:luke at stat.uiowa.edu]
>> Sent: Thursday, April 23, 2009 11:06 AM
>> To: William Dunlap
>> Cc: r-devel at r-project.org
>> Subject: Re: [Rd] reference counting problem in .Primitive's?
>>
>> On Thu, 23 Apr 2009, William Dunlap wrote:
>>
>>> I think the following rather wierd expressions show a problem in how
>>> some of the .Primitive functions evaluate their arguments.
>> I haven't
>>> yet thought of a way that a nonabusive user might run into
>> this problem.
>>> In each case the first argument, x, is modified in the course of
>>> evaluating the second argument and then modified x gets used
>>> as the first argument:
>>>
>>>> x<-as.integer(1:5); y <- x + { x[3]<-33L ; 1L } ; y
>>> [1]  2  3 34  5  6
>>>> x<-2^(0:4) ; y <- log(x, { x[3]<-64 ; 2 }) ; y
>>> [1] 0 1 6 3 4
>>>
>>> The reason I think it looks like a sharing problem (and not an order
>>> of evaluation problem) is that if your modification to x
>> causes it to
>>> use a new block of memory then the unmodified version of x gets
>>> used as the first argument.  E.g.,
>>>
>>>> x<-as.integer(1:5) ; y <- x + { x[3]<-33.3; 1L} ; y
>>> [1] 2 3 4 5 6
>>>
>>> I haven't yet thought of a way that a nonabusive user might run
>>> into this problem.
>
> An hour after writing this one of our support folks sent me some
> user-written code that contained something very close to this idiom;
> the second argument to ":" is an altered version of the first argument:
>
>   lengths<-5:1 ; start<-1
>   for(i in seq(along=lengths)) {
>        thisSeq <- start:((start <- start + lengths[i])-1)
>        print(thisSeq)
>   }
>   [1] 1 2 3 4 5
>   [1] 6 7 8 9
>   [1] 10 11 12
>   [1] 13 14
>   [1] 15
>
> That works.  However, if that user had also used 'start[] <- ' instead
> of 'start <- ' then they would have run into this bug:
>
>  lengths<-5:1 ; start<-1
>  for(i in seq(along=lengths)) {
>        thisSeq <- start:((start[] <- start + lengths[i])-1)
>        print(thisSeq)
>  }
>  [1] 1 2 3 4 5
>  [1] 10  9
>  [1] 13 12
>  [1] 15 14
>  [1] 16 15
>
> If they use start[] or start[1] consistently in the call to ":" then
> they
> don't hit the bug.


Unless you know of somewhere where it is guaranteed that evaluation
order for : is left to right then this code is buggy.  (At one point I
either had or serously thought about having codetools warn about
assignments in arguments other than in a very limited number of
cases.)

As I said previously unless I can convince myself that the current
behavior isn't consistent with _some_ evaluation order in each case
(even if it changes with changes in expressions used) then I don't
think it is worth doing anything about other than explicitly stating
that evaluation order is undefined.

>
>>
>> You are probably right.  I have not yet looked at the code but am
>> virtually certain it does not try to temporarily bump up the NAMED
>> values on argument values.  Doing so would cure this but probably at
>> serious cost to performance, as NAMED values of 2 cannot be brought
>> down again and so cause copying on next modify. (Might be worth
>> running some tests on that though to see what the cost would be).
>
> So, if NAMED were not limited to 0,1,or 2 this sort of thing might be
> avoided with less pain?

If we had full reference counting I think we could avoid this fairly
easily, but I'm not convinced it is worth avoiding as there are good
reasons to allow indeterminacy in order of evaluation (compiler
optimizations, parallelization, and such) and in any case going to
full reference counting is not realistic without a full rewrite of the
engine (and has its own potential performance issues).

luke

>> I'm not sure if it is written anywhere that argunments of primitives
>> (BUILTINS in articular as those are always strict; SPECIALS can be
>> non-strict but log is strict) are evaluated in any particular order.
>> All these examples are consistent with _some_ evaluation order, but
>> not the same one.  It might be possible to show that the results
>> obtained in these situations will always be consistent with some
>> evaluation order, in which case documenting that order of evaluation
>> is unspecified would be good enough form me.  It may also be possible
>> that an order that does compound expressions first and then symbols
>> would also solve the issue (I don't think I would want to do this in
>> the interpreter though because of the performance overhead.)
>>
>> luke
>>
>>
>>>
>>> Bill Dunlap
>>> TIBCO Software Inc - Spotfire Division
>>> wdunlap tibco.com
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> --
>> Luke Tierney
>> Chair, Statistics and Actuarial Science
>> Ralph E. Wareham Professor of Mathematical Sciences
>> University of Iowa                  Phone:             319-335-3386
>> Department of Statistics and        Fax:               319-335-3017
>>     Actuarial Science
>> 241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
>> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>>
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From macrakis at alum.mit.edu  Fri Apr 24 01:21:22 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Thu, 23 Apr 2009 19:21:22 -0400
Subject: [Rd] Closed-source non-free ParallelR ?
In-Reply-To: <F21BE202-7384-40EF-B608-A7A1E821CE4E@me.com>
References: <373DCC90906D430E952EF2C423B0D91B@ADAM>
	<ac81d400904220740i5a4adac4l41b1a170c6f27bd7@mail.gmail.com>
	<475a3c8f0904220836w43d07042m84f42edf6e05766c@mail.gmail.com>
	<E1C5F6F55B4445AF902DF4B970BE1688@ADAM>
	<8b356f880904230947n6a410d2lc06b9088e53041b0@mail.gmail.com>
	<B49C0AC4-8331-4F2D-81A7-48119E369221@me.com>
	<8b356f880904231322j1251d50if184b94f24c619ca@mail.gmail.com>
	<F21BE202-7384-40EF-B608-A7A1E821CE4E@me.com>
Message-ID: <8b356f880904231621h4c907e78uc1a6d56be05abaf1@mail.gmail.com>

I said:
>> ...The GPL FAQs are the FSF's interpretation. ?The R Foundation is not
>> obliged to have the same interpretation, and of course the FSF cannot
>> enforce licenses given by the R Foundation....

On Thu, Apr 23, 2009 at 5:34 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
> Underlying all of your comments seems to be a presumption that the R
> Foundation can disentangle themselves from the FSF vis-a-vis the GPL.
> Keep in mind that it is the FSF that is the copyright holder of the GPL.

Yes. The GPL itself is copyrighted.

> The R Foundation may be the copyright holder to R, but they are distributing
> it under a license which they did not write.

Yes. They chose to use a certain license.

> Thus, I cannot envision any reasonable circumstances under which the R
> Foundation would place themselves in a position of legal risk in deviating
> from the interpretations of the GPL by the FSF. It would be insane legally
> to do so.

I don't follow you here.  If the R Foundation chose not to enforce a
provision of the license in the way that the FSF thinks it ought to be
enforced, what exactly could the FSF do about it?  As far as I can
tell, the GPL does not make the FSF a party in licenses executed under
the GPL.

> The key issue is the lack of case law relative to the GPL and that leaves
> room for interpretation. One MUST therefore give significant weight to the
> interpretations of the FSF as it will likely be the FSF that will be
> involved in any legal disputes over the GPL and its application. You would
> want them on your side, not be fighting them.

You are discussing the courts' interpretation of the GPL, which is not
what I'm questioning here.

Let me give an analogy.  Suppose I buy a piece of property using a
standard form contract written by (and copyright by) my local real
estate agents' association (a common practice).  I then discover that
the seller had done something which according to the real estate
agents' association's interpretation of the contract entitled me to
$10000 damages, but that seems unreasonable to me.  The particular
clause has never been litigated.  You seem to be claiming that (a) the
real estate agents' association's interpretation of the contract has
more weight than my interpretation of it and (b) that they can somehow
oblige me to sue for the $10000 damages.  Now let's say someone else
goes to court and (with the legal support of the real estate agents'
association) prevails on that clause.  Now it is clear that the real
estate agents' association's interpretation can be enforced.  But I
still don't think it's reasonable to enforce it, and still don't
choose to sue.  You are claiming that they somehow can force me to?
Of course, it would be different if a real estate agent were also
party to the contract, and would be owed 20% of the $10000.  But that
is not the case.

> Unfortunately, we have no such archive of case law yet of the GPL. Thus at
> least from a legally enforceable perspective, all is grey and the FSF has to
> be the presumptive leader here.

Whether the FSF's interpretation is legally enforceable or not, it is
the copyright holder who choses whether to sue, not the FSF.

            -s


From Ted.Harding at manchester.ac.uk  Fri Apr 24 02:54:14 2009
From: Ted.Harding at manchester.ac.uk ( (Ted Harding))
Date: Fri, 24 Apr 2009 01:54:14 +0100 (BST)
Subject: [Rd] Closed-source non-free ParallelR ?
In-Reply-To: <384C84AE99C74D9898E4F04DE0E34F49@gpbdmx>
Message-ID: <XFMail.090424015414.Ted.Harding@manchester.ac.uk>

On 23-Apr-09 22:21:45, Ian Fellows wrote:
> Assuming that the foundation does not want to deviate from the
> FSF interpretation, there would still be value in clarifying its
> position vis-?-vis how the license applies to R specifically. 

I think (see below) that I agree with this!

> For example the FSF foundation claims that linking to a library
> (even in an interpreted environment) makes your software derivative,
> and therefore must be distributed Freely. They also claim that
> simply executing a program in an interpreted (GPL'ed) environment
> is okay even though the program could not be run without it. So one
> question might be, where does the language end and the libraries
> begin?

As far as I Understand these things (and I think I use language
differently from lawyers), it seems to me that this view about
executing a program in an interpreted environment is reasonable.

For example, suppose I bought a commercial FORTRAN interpreter.
I write a program (plain text, of course) in standard FORTRAN.
Running this on the interpreter surely would not tie me into
any licensing issues arising from the rights of the seller of
the interpreter, and I feel sure I could re-distribute my raw
(test) FORTRAN code as I pleased without any infringement arising
from the fact that I had, myself, executed it on the interpreter.
Others (and I myself) could surely compile the program on some
other compiler, etc.

However, if that commercial interpreter also had a 'compile' option,
and I compiled my progrtam using that, then equally I feel sure
that the compiled version would be subject to whatever restrictions
had been placed on distirbution fo binaries so compiled. I think
those things are clear enough.

The interesting question arises if the commercial interpreter
also included some extension of standard FORTRAN which was unique
to that interpreter. I dare say I could pass a program which
included use of the extension to others without problems, on
thr grounds that they would have to obtain te same interpreter
in order to run it.

But now suppose that my having done this inspires someone to
incorporate the same language extension into a GPL'd FORTRAN
interpreter/compiler. I think I could then be vulnerable, or
they could, on the grounds that I/they had pinched the idea
from the commercial product.

And now (relevent to Ian's next point), maybe a similar principle
might be held to apply to R code which depends on R's use of GPL?
-- since people who write R code often use features of the code
which are peculiar to R. Or maybe the GPL doesn't inhibit you
from using *ideas* and *features* of GPL software, provided you
implement them yourself and in your own way? I dunno ...

Ted.
 
> Are any/all of the default packages considered part of
> the language? It seems hard to imagine doing anything at all without at
> least 'base.' If I install R in the usual way with no other
> packages/libraries can I release whatever I write under any license, or
> does
> it have to be GPL compatible?
> 
> While I wouldn't expect R core to formulate formal legal opinions
> regarding
> questions like these, it would be nice if there were some kind of
> "community
> standards."
> 
> Ian
> 
> -----Original Message-----
> From: r-devel-bounces at r-project.org
> [mailto:r-devel-bounces at r-project.org]
> On Behalf Of Marc Schwartz
> Sent: Thursday, April 23, 2009 2:34 PM
> To: Stavros Macrakis
> Cc: Matthew Dowle; r-devel at r-project.org
> Subject: Re: [Rd] Closed-source non-free ParallelR ?
> 
> 
> On Apr 23, 2009, at 3:22 PM, Stavros Macrakis wrote:
> 
>> On Thu, Apr 23, 2009 at 1:25 PM, Marc Schwartz  
>> <marc_schwartz at me.com> wrote:
>>> On Apr 23, 2009, at 11:47 AM, Stavros Macrakis wrote:
>>>>
>>>> All that being said, the entity that must enforce these conditions  
>>>> is
>>>> not the FSF, but the copyright owner, in this case the R  
>>>> Foundation...
>>>> bundler. So it would be useful to know what the R Foundation's
>>>> position is....
>>
>>> Actually, the R Foundation has done what it is obligated to do,  
>>> which is to
>>> describe the license under which R is made available.
>>
>> I did not say that the R Foundation was obligated to give advice.  I
>> said that it is up to the R Foundation to decide what cases it cares
>> about, and it would be "useful to know" what that position is.
>>
>>> To ask the R Foundation for anything further is to ask them to  
>>> render a legal
>>> opinion, which is not in their expertise to offer.
>>
>> No, it is asking them what their *policy* is.  Their policy may or may
>> not be enforceable....
>>
>>> It is up to the prospective third party developer of an application  
>>> that is
>>> to use R to consult with lawyers to determine what *THEIR*  
>>> obligations are
>>> if they should elect to proceed.
>>
>> Yes, this is true.  But it is also true that if (for example) the R
>> Foundation says officially that it interprets GPL to allow
>> distributing proprietary packages along with R, then that is the
>> interpretation that matters, since the R Foundation (not the FSF) is
>> the copyright holder.
>>
>>> At this level, it is really pretty simple and a lot of these things  
>>> are
>>> covered in the GPL FAQs, including the reporting of violations.
>>
>> The GPL FAQs are the FSF's interpretation.  The R Foundation is not
>> obliged to have the same interpretation, and of course the FSF cannot
>> enforce licenses given by the R Foundation.
> 
> Underlying all of your comments seems to be a presumption that the R  
> Foundation can disentangle themselves from the FSF vis-a-vis the GPL.
> 
> Keep in mind that it is the FSF that is the copyright holder of the
> GPL.
> 
> The R Foundation may be the copyright holder to R, but they are  
> distributing it under a license which they did not write.
> 
> Thus, I cannot envision any reasonable circumstances under which the R 
> Foundation would place themselves in a position of legal risk in  
> deviating from the interpretations of the GPL by the FSF. It would be  
> insane legally to do so.
> 
> The key issue is the lack of case law relative to the GPL and that  
> leaves room for interpretation. One MUST therefore give significant  
> weight to the interpretations of the FSF as it will likely be the FSF  
> that will be involved in any legal disputes over the GPL and its  
> application. You would want them on your side, not be fighting them.
> 
> A parallel here is why most large U.S. public corporations legally  
> incorporate in the state of Delaware, even though they may not have  
> any material physical presence in that state. It is because the  
> overwhelming majority of corporate case law in the U.S. has been  
> decided under the laws of Delaware and the interpretations of said  
> laws. If I were to start a company (which I have done in the past) and 
> feared that I should find myself facing litigation at some future  
> date, I would want that huge database of case law behind me. A small  
> company (such as I had) may be less concerned about this and be  
> comfortable with the laws of their own state, which I was. But if I  
> were to be looking to build a big company with investors, etc. and  
> perhaps look to go public at a future date, you bet I would look to  
> incorporate in Delaware. It would be the right fiduciary decision to  
> make in the interest of all parties.
> 
> Unfortunately, we have no such archive of case law yet of the GPL.  
> Thus at least from a legally enforceable perspective, all is grey and  
> the FSF has to be the presumptive leader here.
> 
> HTH,
> 
> Marc Schwartz
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 24-Apr-09                                       Time: 01:54:11
------------------------------ XFMail ------------------------------


From ggrothendieck at gmail.com  Fri Apr 24 03:09:38 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 23 Apr 2009 21:09:38 -0400
Subject: [Rd] Closed-source non-free ParallelR ?
In-Reply-To: <XFMail.090424015414.Ted.Harding@manchester.ac.uk>
References: <384C84AE99C74D9898E4F04DE0E34F49@gpbdmx>
	<XFMail.090424015414.Ted.Harding@manchester.ac.uk>
Message-ID: <971536df0904231809t3c32a09ch4459e8311a9ece03@mail.gmail.com>

On Thu, Apr 23, 2009 at 8:54 PM, Ted Harding
<Ted.Harding at manchester.ac.uk> wrote:
> On 23-Apr-09 22:21:45, Ian Fellows wrote:
>> Assuming that the foundation does not want to deviate from the
>> FSF interpretation, there would still be value in clarifying its
>> position vis-?-vis how the license applies to R specifically.
>
> I think (see below) that I agree with this!
>
>> For example the FSF foundation claims that linking to a library
>> (even in an interpreted environment) makes your software derivative,
>> and therefore must be distributed Freely. They also claim that
>> simply executing a program in an interpreted (GPL'ed) environment
>> is okay even though the program could not be run without it. So one
>> question might be, where does the language end and the libraries
>> begin?
>
> As far as I Understand these things (and I think I use language
> differently from lawyers), it seems to me that this view about
> executing a program in an interpreted environment is reasonable.
>
> For example, suppose I bought a commercial FORTRAN interpreter.
> I write a program (plain text, of course) in standard FORTRAN.
> Running this on the interpreter surely would not tie me into
> any licensing issues arising from the rights of the seller of
> the interpreter, and I feel sure I could re-distribute my raw
> (test) FORTRAN code as I pleased without any infringement arising
> from the fact that I had, myself, executed it on the interpreter.
> Others (and I myself) could surely compile the program on some
> other compiler, etc.
>
> However, if that commercial interpreter also had a 'compile' option,
> and I compiled my progrtam using that, then equally I feel sure
> that the compiled version would be subject to whatever restrictions
> had been placed on distirbution fo binaries so compiled. I think
> those things are clear enough.

Typically commercial compilers have royalty-free runtime
libraries so you can freely distribute software processed
with the compiler.  Similarly, In the free software world,
gcc has the gcc Runtime Library Exception to allow
commercial software to use gcc.
http://www.gnu.org/licenses/gcc-exception.html


From Greg.Snow at imail.org  Fri Apr 24 04:40:45 2009
From: Greg.Snow at imail.org (Greg Snow)
Date: Thu, 23 Apr 2009 20:40:45 -0600
Subject: [Rd] License status of CRAN packages
In-Reply-To: <18928.55315.939029.188945@ron.nulle.part>
References: <18928.48327.599527.545472@ron.nulle.part>
	<971536df0904231232vbb024c8p95456acaeae0ff6d@mail.gmail.com>
	<18928.51543.939132.165160@ron.nulle.part>
	<971536df0904231335s25d1c134l58db3f7280c053e2@mail.gmail.com>
	<18928.55315.939029.188945@ron.nulle.part>
Message-ID: <B37C0A15B8FB3C468B5BC7EBC7DA14CC61CFF75804@LP-EXMBVS10.CO.IHC.COM>

I don't know about the legal definitions of all, but a few years back the British Medical Journal had a filler article that looked at some surveys of what people thought different words meant (you can get at the filler by going to http://www.bmj.com/cgi/content/full/333/7565/442 and downloading the pdf version of the article then scrolling to the end).

According to this, when people say always they could mean anywhere from 91-100% of the time and when they say never it could be 0-2% of the time.

This doesn't prove anything, but I thought it was an interesting side note to the discussion.

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
801.408.8111


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
> project.org] On Behalf Of Dirk Eddelbuettel
> Sent: Thursday, April 23, 2009 3:05 PM
> To: Gabor Grothendieck
> Cc: Friedrich Leisch; Matthew Dowle; charles blundell; r-devel at r-
> project.org
> Subject: Re: [Rd] License status of CRAN packages
> 
> 
> On 23 April 2009 at 16:35, Gabor Grothendieck wrote:
> | Of the 31 packages listed:
> |  [1] "BARD"          "BayesDA"       "CoCo"          "ConvCalendar"
> |  [5] "FAiR"          "PTAk"          "RScaLAPACK"    "Rcsdp"
> |  [9] "SDDA"          "SGP"           "alphahull"     "ash"
> | [13] "asypow"        "caMassClass"   "gpclib"        "mapproj"
> | [17] "matlab"        "mclust"        "mclust02"      "mlbench"
> | [21] "optmatch"      "rankreg"       "realized"      "rngwell19937"
> | [25] "rtiff"         "rwt"           "scagnostics"   "sgeostat"
> | [29] "spatialkernel" "tlnise"        "xgobi"
> |
> | the license fields are AGPL or GPL for 3 and specified in a separate
> | file "file LICENSE" so about 30 of 1700 < 2% are question marks.
> 
> My point is that you currently need to manually parse 'file LICENSE'.
> 
> And as I said, we did not claim that our set was exhaustive, current or
> perfect. We just can't automate anything better given the current
> framework.
> And I think we all should be able to do better in scripted approaches.
> I
> still think you're proving my point.
> 
> | To me that is not inconsistent with all or nearly all being free
> software
> 
> I doubt that "all or nearly all" would equated to "exactly all" by a
> court. You only need one bad apple to spoil the lot.
> 
> Dirk
> 
> --
> Three out of two people have difficulties with fractions.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From england at cs.umn.edu  Fri Apr 24 04:43:51 2009
From: england at cs.umn.edu (Darin A. England)
Date: Thu, 23 Apr 2009 21:43:51 -0500
Subject: [Rd] Problems building R 2.9.0... on SGI and Sun once again
In-Reply-To: <20090423155431.GA6821@cs.umn.edu>
References: <200904201154.n3KBswHQ013943@ruuvi.it.helsinki.fi>
	<20090423155431.GA6821@cs.umn.edu>
Message-ID: <20090424024351.GA24144@cs.umn.edu>

Many thanks to Peter for the explanation. I found that the fix for
me was to set the environment variable R_SHELL to '/usr/bin/bash',
otherwise (on my AIX system at least) the shell being used was
/bin/sh. 
Darin


On Thu, Apr 23, 2009 at 10:54:31AM -0500, Darin England wrote:
> I have the same problem trying build R 2.9.0 on AIX using the IBM 
> Visual Age compilers and GNU make. I'm trying to figure it out, but
> any hints on a fix are greatly appreciated.
> Thanks,
> Darin
> 
> gmake[2]: Entering directory `/home/denglan/R/builddir/src/library/methods'
> building package 'methods'
> mkdir ../../../library/methods
> gmake[3]: Entering directory `/home/denglan/R/builddir/src/library/methods'
> mkdir ../../../library/methods/R
> /bin/sh: syntax error at line 1 : `;' unexpected
> gmake[3]: *** [front] Error 2
> gmake[3]: Leaving directory `/home/denglan/R/builddir/src/library/methods'
> gmake[2]: *** [all] Error 2
> gmake[2]: Leaving directory `/home/denglan/R/builddir/src/library/methods'
> gmake[1]: *** [R] Error 1
> gmake[1]: Leaving directory `/home/denglan/R/builddir/src/library'
> gmake: *** [R] Error 1
> make: The error code from the last command is 1.


From francisco at voseconsulting.com  Fri Apr 24 05:15:12 2009
From: francisco at voseconsulting.com (francisco at voseconsulting.com)
Date: Fri, 24 Apr 2009 05:15:12 +0200 (CEST)
Subject: [Rd] memory.limit returns error (not present in 2.8.) (PR#13673)
Message-ID: <20090424031512.1092B283431D@mail.pubhealth.ku.dk>

Full_Name: Francisco J. Zagmutt
Version: 2.9.0
OS: XP pro, SP2
Submission from: (NULL) (98.245.159.214)


- Description: memory.limit(x) will yield an error even though the memory
allocation limit is changed to x (when possible). The same call does not yield
an error in R version 2.8.x

- Example code and output:

> memory.limit()
[1] 2046
> memory.limit(2092)
Error in trunc(.Internal(memory.size(size))) :
  Non-numeric argument to mathematical function
> memory.limit()
[1] 2092

- Result: The memory limit was correctly changed but still reported the error
above. 

- Version information:
               _
platform       i386-pc-mingw32
arch           i386
os             mingw32
system         i386, mingw32
status
major          2
minor          9.0
year           2009
month          04
day            17
svn rev        48333
language       R
version.string R version 2.9.0 (2009-04-17)

Thanks!

Francisco


From Bernhard_Pfaff at fra.invesco.com  Fri Apr 24 11:13:26 2009
From: Bernhard_Pfaff at fra.invesco.com (Pfaff, Bernhard Dr.)
Date: Fri, 24 Apr 2009 10:13:26 +0100
Subject: [Rd] memory.limit(): Typo in Windows NEWS and function returns a
	"disregarded" error
Message-ID: <B89F0CE41D45644A97CCC93DF548C1C319DAC132@GBHENXMB02.corp.amvescap.net>

Dear list subscriber (R-Core),

there is a minor typo in the Windows specific NEWS for R 2.9.0: 
http://cran.at.r-project.org/bin/windows/base/CHANGES.R-2.9.0
There is no function 'memory.limits() but memory.limit() (see below). 


Secondly, I am kind of irritated by the function's behaviour. It returns an Error, but as it seems the memory limit is set according to the numeric value for the size argument even it is not a numeric-value according to the error message? In R 2.8.1 this error was not returned (see below).

A clarification/explanation is most welcome.

Kind Regards,
Bernhard

> memory.limits()
Error: could not find function "memory.limits"
> memory.limit()
[1] 1535
> memory.limit(size = 2000)
Error in trunc(.Internal(memory.size(size))) : 
  Non-numeric argument to mathematical function
> memory.limit()
[1] 2000
> version
               _                           
platform       i386-pc-mingw32             
arch           i386                        
os             mingw32                     
system         i386, mingw32               
status                                     
major          2                           
minor          9.0                         
year           2009                        
month          04                          
day            17                          
svn rev        48333                       
language       R                           
version.string R version 2.9.0 (2009-04-17)
> 


In comparison for R 2.8.1:

> memory.limit()
[1] 1535.875
> memory.limit(2000)
NULL
> memory.limit()
[1] 2000
> version
               _                           
platform       i386-pc-mingw32             
arch           i386                        
os             mingw32                     
system         i386, mingw32               
status                                     
major          2                           
minor          8.1                         
year           2008                        
month          12                          
day            22                          
svn rev        47281                       
language       R                           
version.string R version 2.8.1 (2008-12-22)


Dr. Bernhard Pfaff
Director
Global Quantitative Equity

Invesco Asset Management Deutschland GmbH
Bleichstrasse 60-62
D-60313 Frankfurt am Main

Tel: +49 (0)69 29807 230
Fax: +49 (0)69 29807 178
www.institutional.invesco.com
Email: bernhard_pfaff at fra.invesco.com

Gesch?ftsf?hrer: Karl Georg Bayer, Bernhard Langer, Dr. Jens Langewand, Alexander Lehmann, Christian Puschmann
Handelsregister: Frankfurt am Main, HRB 28469
Sitz der Gesellschaft: Frankfurt am Main
 
*****************************************************************
Confidentiality Note: The information contained in this ...{{dropped:10}}


From ligges at statistik.tu-dortmund.de  Fri Apr 24 11:33:30 2009
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 24 Apr 2009 11:33:30 +0200
Subject: [Rd] memory.limit(): Typo in Windows NEWS and function returns
 a	"disregarded" error
In-Reply-To: <B89F0CE41D45644A97CCC93DF548C1C319DAC132@GBHENXMB02.corp.amvescap.net>
References: <B89F0CE41D45644A97CCC93DF548C1C319DAC132@GBHENXMB02.corp.amvescap.net>
Message-ID: <49F1876A.3030203@statistik.tu-dortmund.de>

Thanks, we know from other messages and this has been files as a bug 
report minutes ago...

Best wishes,
Uwe Ligges



Pfaff, Bernhard Dr. wrote:
> Dear list subscriber (R-Core),
> 
> there is a minor typo in the Windows specific NEWS for R 2.9.0: 
> http://cran.at.r-project.org/bin/windows/base/CHANGES.R-2.9.0
> There is no function 'memory.limits() but memory.limit() (see below). 
> 
> 
> Secondly, I am kind of irritated by the function's behaviour. It returns an Error, but as it seems the memory limit is set according to the numeric value for the size argument even it is not a numeric-value according to the error message? In R 2.8.1 this error was not returned (see below).
> 
> A clarification/explanation is most welcome.
> 
> Kind Regards,
> Bernhard
> 
>> memory.limits()
> Error: could not find function "memory.limits"
>> memory.limit()
> [1] 1535
>> memory.limit(size = 2000)
> Error in trunc(.Internal(memory.size(size))) : 
>   Non-numeric argument to mathematical function
>> memory.limit()
> [1] 2000
>> version
>                _                           
> platform       i386-pc-mingw32             
> arch           i386                        
> os             mingw32                     
> system         i386, mingw32               
> status                                     
> major          2                           
> minor          9.0                         
> year           2009                        
> month          04                          
> day            17                          
> svn rev        48333                       
> language       R                           
> version.string R version 2.9.0 (2009-04-17)
> 
> 
> In comparison for R 2.8.1:
> 
>> memory.limit()
> [1] 1535.875
>> memory.limit(2000)
> NULL
>> memory.limit()
> [1] 2000
>> version
>                _                           
> platform       i386-pc-mingw32             
> arch           i386                        
> os             mingw32                     
> system         i386, mingw32               
> status                                     
> major          2                           
> minor          8.1                         
> year           2008                        
> month          12                          
> day            22                          
> svn rev        47281                       
> language       R                           
> version.string R version 2.8.1 (2008-12-22)
> 
> 
> Dr. Bernhard Pfaff
> Director
> Global Quantitative Equity
> 
> Invesco Asset Management Deutschland GmbH
> Bleichstrasse 60-62
> D-60313 Frankfurt am Main
> 
> Tel: +49 (0)69 29807 230
> Fax: +49 (0)69 29807 178
> www.institutional.invesco.com
> Email: bernhard_pfaff at fra.invesco.com
> 
> Gesch?ftsf?hrer: Karl Georg Bayer, Bernhard Langer, Dr. Jens Langewand, Alexander Lehmann, Christian Puschmann
> Handelsregister: Frankfurt am Main, HRB 28469
> Sitz der Gesellschaft: Frankfurt am Main
>  
> *****************************************************************
> Confidentiality Note: The information contained in this ...{{dropped:10}}
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Fri Apr 24 12:45:24 2009
From: maechler at stat.math.ethz.ch (maechler at stat.math.ethz.ch)
Date: Fri, 24 Apr 2009 12:45:24 +0200 (CEST)
Subject: [Rd] incorrect output and segfaults from sprintf with %*d
	(PR#13667)
Message-ID: <20090424104524.DFA4F283432B@mail.pubhealth.ku.dk>

>>>>> "MM" == Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Thu, 23 Apr 2009 12:40:22 +0200 (CEST) writes:

>>>>> "vQ" == Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no>
>>>>>     on Thu, 23 Apr 2009 11:49:54 +0200 writes:

    vQ> maechler at stat.math.ethz.ch wrote:
    >>> 
    vQ> sprintf has a documented limit on strings included in the output using the
    vQ> format '%s'.  It appears that there is a limit on the length of strings included
    vQ> with, e.g., the format '%d' beyond which surprising things happen (output
    vQ> modified for conciseness):
    >>> 

    vQ> ... and this limit is *not* documented.

    MM> well, it is basically (+ a few bytes ?)
    MM> the same  8192  limit that *is* documented.

indeed, I was right with that..

    vQ> gregexpr('1', sprintf('%9000d', 1))
    vQ> # [1] 9000 9801
    >>> 
    vQ> gregexpr('1', sprintf('%9000d', 1))
    vQ> # [1]  9000  9801 10602
    >>> 
    vQ> gregexpr('1', sprintf('%9000d', 1))
    vQ> # [1]  9000  9801 10602 11403
    >>> 
    vQ> gregexpr('1', sprintf('%9000d', 1))
    vQ> # [1]  9000  9801 10602 11403 12204
    >>> 
    vQ> ...
    >>> 

    vQ> Note that not only more than one '1' is included in the
    vQ> output, but also that the same functional expression (no
    vQ> side effects used beyond the interface) gives different
    vQ> results on each execution.  Analogous behaviour can be
    vQ> observed with '%nd' where n > 8200.

    vQ> The actual output above is consistent across separate sessions.
    >>> 
    vQ> With sufficiently large field width values, R segfaults:
    >>> 
    vQ> sprintf('%*d', 10^5, 1)
    vQ> # *** caught segfault ***
    vQ> # address 0xbfcfc000, cause 'memory not mapped'
    vQ> # Segmentation fault
    >>> 
    >>> 
    >>> Thank you, Wacek.
    >>> That's all ``interesting''  ... unfortunately, 
    >>> 
    >>> my version of  'man 3 sprintf' contains
    >>> 
    >>> 
    >>>>> BUGS
    >>>>> Because sprintf() and vsprintf() assume an arbitrarily
    >>>>> long string, callers must be careful not to overflow the
    >>>>> actual space; this is often impossible to assure. Note
    >>>>> that the length of the strings produced is
    >>>>> locale-dependent and difficult to predict.  Use
    >>>>> snprintf() and vsnprintf() instead (or asprintf() and vasprintf).

    vQ> yes, but this is c documentation, not r documentation.

    MM> Of course! ...  and I  *do*  apply it to R's C code [sprintf.c]
    MM> and hence am even concurring with you .. 

    vQ> it's applicable
    vQ> to a degree, since ?sprintf does say that sprintf is "a wrapper for the
    vQ> C function 'sprintf'".  however, in c you use a buffer and you usually
    vQ> have control over it's capacity, while in r this is a hidden
    vQ> implementational detail, which should not be visible to the user, or
    vQ> should cause an attempt to overflow the buffer to fail more gracefully
    vQ> than with a segfault.

    vQ> in r, sprintf('%9000d', 1) will produce a confused output with a count
    vQ> of 1's variable (!) across runs (while sprintf('%*d', 9000, 1) seems to
    vQ> do fine):

    vQ> gregexpr('1', sprintf('%*d', 9000, 1))
    vQ> # [1] 9000

    vQ> gregexpr('1', sprintf('%9000d', 1))
    vQ> # [1] 9000 9801 ..., variable across executions

    vQ> on one execution in a series i actually got this:

    vQ> Warning message:
    vQ> In gregexpr("1", sprintf("%9000d", 1)) :
    vQ> input string 1 is invalid in this locale

    vQ> while the very next execution, still in the same session, gave

    vQ> # [1]  9000  9801 10602

    vQ> with sprintf('%*d', 10000, 1) i got segfaults on some executions but
    vQ> correct output on others, while sprintf('%10000d', 1) is confused again.


    >>> (note the "impossible" part above)       
    >>> 

    vQ> yes, but it does also say "must be careful", and it seems that someone
    vQ> has not been careful enough.

    >>> and we haven't used  snprintf() yet, probably because it
    >>> requires the  C99 C standard, and AFAIK, we have only relatively
    >>> recently started to more or less rely on C99 in the R sources.
    >>> 

    vQ> while snprintf would help avoid buffer overflow, it may not be a
    vQ> solution to the issue of confused output.

    MM> I think it would / will.  We would be able to give warnings and
    MM> errors, by checking the  snprintf()  return codes.

My current working code gives an error for all the above
examples, e.g.,

 > sprintf('%9999d', 1)
 Error in sprintf("%9999d", 1) : 
   required resulting string length 9999 is > maximal 8191

it passes  'make check-devel' and I am inclined to commit that
code to R-devel (e.g. tomorrow). 

Yes, the documentation will also have to be amended, but apart
from that, would people see a big problem with the "8192" limit
which now is suddenly of greater importance
{{as I said all along;  hence my question to Wacek (and the
  R-develers)  if anybody found that limit too low}}

Of course, one could realloc()ate longer strings when needed
inside R's  sprintf() code,  but I reluctant to do that (render
the code yet more complicated ...) if nobody sees a need.

Martin

    >>> More precisely, I see that some windows-only code relies on
    >>> snprintf() being available  whereas in at least on non-Windows
    >>> section, I read   /* we cannot assume snprintf here */
    >>> 
    >>> Now such platform dependency issues and corresponding configure
    >>> settings I do typically leave to other R-corers with a much
    >>> wider overview about platforms and their compilers and C libraries.
    >>> 

    vQ> it looks like src/main/sprintf.c is just buggy, and it's plausible that
    vQ> the bug could be repaired in a platform-independent manner.

    MM> definitely.
    MM> In the mean time, I've actually found that what I first said on
    MM> the usability of snprintf() in R's code base was only partly correct.
    MM> There are other parts of R code where we use  snprintf() for all
    MM> platforms, hence we rely on its presence (and correct
    MM> implementation!) and so we can and I think should use it in
    MM> place of sprintf() in quite a few places inside R's sprintf.c


    >>> BTW,  
    >>> 1) sprintf("%n %g", 1,1)   also seg.faults
    >>> 

    vQ> as do

    vQ> sprintf('%n%g', 1, 1)
    vQ> sprintf('%n%')

    vQ> etc., while

    vQ> sprintf('%q%g', 1, 1)
    vQ> sprintf('%q%')
  
    vQ> work just fine.  strange, because per ?sprintf 'n' is not recognized as
    vQ> a format specifier, so the output from the first two above should be as
    vQ> from the last two above, respectively.  (and likewise in the %S case,
    vQ> discussed and bug-reported earlier.)

    MM> I have now fixed these bugs at least;
    MM> the more subtle  "%<too_large_n>d" ones are different, and
    MM> as I said, I'm convinced that a nice & clean fix for those will
    MM> start using snprintf().

    >>> 2) Did you have a true use case where  the  8192  limit was an
    >>> undesirable limit?

    vQ> how does it matter?  

    MM> well, we could increase it, if it did matter.
    MM> {{ you *could* have been more polite here, no?
    MM> it *was* after all a serious question that I asked! }}

    vQ> if you set a limit, be sure to consistently enforce
    vQ> it and warn the user on attempts to exceed it.  or write clearly in the
    vQ> docs that such attempts will cause the output to be silently truncated. 

    MM> Sure, I'm not at all disagreeing on that, and if you read this into my
    MM> posting, you misunderstand.

    MM> Martin

    [..........................]


From marc_schwartz at me.com  Fri Apr 24 14:07:17 2009
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 24 Apr 2009 07:07:17 -0500
Subject: [Rd] Closed-source non-free ParallelR ?
In-Reply-To: <8b356f880904231621h4c907e78uc1a6d56be05abaf1@mail.gmail.com>
References: <373DCC90906D430E952EF2C423B0D91B@ADAM>
	<ac81d400904220740i5a4adac4l41b1a170c6f27bd7@mail.gmail.com>
	<475a3c8f0904220836w43d07042m84f42edf6e05766c@mail.gmail.com>
	<E1C5F6F55B4445AF902DF4B970BE1688@ADAM>
	<8b356f880904230947n6a410d2lc06b9088e53041b0@mail.gmail.com>
	<B49C0AC4-8331-4F2D-81A7-48119E369221@me.com>
	<8b356f880904231322j1251d50if184b94f24c619ca@mail.gmail.com>
	<F21BE202-7384-40EF-B608-A7A1E821CE4E@me.com>
	<8b356f880904231621h4c907e78uc1a6d56be05abaf1@mail.gmail.com>
Message-ID: <D7075B6D-E54A-4C4B-A03C-B599AE0CDFF1@me.com>

On Apr 23, 2009, at 6:21 PM, Stavros Macrakis wrote:

> I said:
>>> ...The GPL FAQs are the FSF's interpretation.  The R Foundation is  
>>> not
>>> obliged to have the same interpretation, and of course the FSF  
>>> cannot
>>> enforce licenses given by the R Foundation....
>
> On Thu, Apr 23, 2009 at 5:34 PM, Marc Schwartz  
> <marc_schwartz at me.com> wrote:
>> Underlying all of your comments seems to be a presumption that the R
>> Foundation can disentangle themselves from the FSF vis-a-vis the GPL.
>> Keep in mind that it is the FSF that is the copyright holder of the  
>> GPL.
>
> Yes. The GPL itself is copyrighted.
>
>> The R Foundation may be the copyright holder to R, but they are  
>> distributing
>> it under a license which they did not write.
>
> Yes. They chose to use a certain license.
>
>> Thus, I cannot envision any reasonable circumstances under which  
>> the R
>> Foundation would place themselves in a position of legal risk in  
>> deviating
>> from the interpretations of the GPL by the FSF. It would be insane  
>> legally
>> to do so.
>
> I don't follow you here.  If the R Foundation chose not to enforce a
> provision of the license in the way that the FSF thinks it ought to be
> enforced, what exactly could the FSF do about it?  As far as I can
> tell, the GPL does not make the FSF a party in licenses executed under
> the GPL.
>
>> The key issue is the lack of case law relative to the GPL and that  
>> leaves
>> room for interpretation. One MUST therefore give significant weight  
>> to the
>> interpretations of the FSF as it will likely be the FSF that will be
>> involved in any legal disputes over the GPL and its application.  
>> You would
>> want them on your side, not be fighting them.
>
> You are discussing the courts' interpretation of the GPL, which is not
> what I'm questioning here.
>
> Let me give an analogy.  Suppose I buy a piece of property using a
> standard form contract written by (and copyright by) my local real
> estate agents' association (a common practice).  I then discover that
> the seller had done something which according to the real estate
> agents' association's interpretation of the contract entitled me to
> $10000 damages, but that seems unreasonable to me.  The particular
> clause has never been litigated.  You seem to be claiming that (a) the
> real estate agents' association's interpretation of the contract has
> more weight than my interpretation of it and (b) that they can somehow
> oblige me to sue for the $10000 damages.  Now let's say someone else
> goes to court and (with the legal support of the real estate agents'
> association) prevails on that clause.  Now it is clear that the real
> estate agents' association's interpretation can be enforced.  But I
> still don't think it's reasonable to enforce it, and still don't
> choose to sue.  You are claiming that they somehow can force me to?
> Of course, it would be different if a real estate agent were also
> party to the contract, and would be owed 20% of the $10000.  But that
> is not the case.
>
>> Unfortunately, we have no such archive of case law yet of the GPL.  
>> Thus at
>> least from a legally enforceable perspective, all is grey and the  
>> FSF has to
>> be the presumptive leader here.
>
> Whether the FSF's interpretation is legally enforceable or not, it is
> the copyright holder who choses whether to sue, not the FSF.

We are getting into a lot of hypotheticals here which is going to be a  
problem due to the lack of clear precedence. The other problem is that  
we are considering hypotheticals in a vacuum and not in the context of  
the current political environment vis-a-vis the GPL and FOSS.

Under any circumstances, it is up to the R Foundation to pursue or not  
to pursue legal action against any party that it feels has violated  
it's copyright and the associated licensing.

If it chooses to not pursue that recourse however, it may be setting a  
precedent for future litigation, placing future actions and decisions  
at risk. A court may decide that prior inaction in a certain situation  
is evidence that is relevant to a future case. "You failed to enforce  
your legal rights previously in a 'similar' situation, thus you lose  
that right now." Not only that, but such inaction could then be used  
to define the parameters around other legal decisions involving the  
GPL and how it may be interpreted. That is always a risk that one has  
to consider and should be the basis of ensuring that all such  
considerations have a wide angle lens.

The FSF would not be in a position to compel the R Foundation to  
pursue any legal action. However, the political reality at this early  
stage of the game is that the FSF may very well have a legal interest  
in a particular situation if it feels that any legal action or lack of  
legal action by the R Foundation were to be inconsistent with the  
FSF's own strategic positions and goals. That would require a  
discussion between the R Foundation and the FSF and they would have to  
reconcile those differences. Whether the FSF might make the decision  
to provide legal and financial resources to the R Foundation to assist  
in such a venture or even pursue independent legal action would be up  
to them.

My point in raising the issues above, is principally that if the R  
Foundation were to, as you and Ian seem to be asking for, come out  
with some type of non-binding guidance document relative to R and the  
GPL, the technical and legal basis of any such guidance would need to  
be consistent with the interpretations offered by the FSF. The  
guidance could not materially deviate from the information available  
from the FSF or the R Foundation would only serve to confuse the  
situation further or worse, put itself at legal risk. In addition, in  
the presence or absence of offering specific legal guidance, it is  
still up to the third party to seek definitive legal guidance before  
proceeding.

There are specific FSF FAQs that cover particular situations and there  
are others that clearly leave the door open to future legal  
precedents. The FAQ on the "Aggregation" of both GPL and Proprietary  
software is one example providing both:

   http://www.gnu.org/licenses/gpl-faq.html#MereAggregation

How does one decide if the programs are separate and therefore can be  
bundled under differing licenses, or they are not and the viral part  
of the GPL kicks in? The FAQ covers some reasonable aspects of that  
but clearly leaves the door open for future litigation. It is a FAQ  
however that is highly relevant to the topic that started this whole  
discussion, which is the bundling of closed source proprietary  
software along with R.

Is the R Foundation in a position to offer something quite different  
or more definitive than that? I would highly doubt it.

This is why I think the greater and appropriate burden is on the third  
party that wishes to construct AND DISTRIBUTE any application that is  
in some fashion dependent upon R to function. It is up to them to seek  
appropriate legal guidance on the basis of their specific  
circumstances. It is the third party whose actions may result in a  
successful venture (financially or otherwise) or leave itself open in  
a future legal battle.

I do not speak for or on behalf of the R Foundation, but can only  
offer what I feel to be reasonable points for discussion. I have been  
involved in several startup companies over the past 20+ years  
including my own, also involving joint ventures and intellectual  
property discussions. The result of which is spending a lot of time  
with lawyers in the drafting of contracts and similar legal documents.  
I am not a lawyer, do not play one on TV and I did not sleep at a  
Holiday Inn Express last night.  However, their manner of thinking has  
rubbed off on me (for better or worse). The result of which is a  
certain level of caution in these matters and to consider in the  
broadest terms, not the narrowest, one's actions and decisions. You  
start with a broad perspective and then narrow that perspective to  
your specific circumstances as the law and legal precedent provide for  
those parameters. In the absence of such, your legal counsel engage in  
their best efforts to interpret the available data. In these  
situations, there is a clear risk/benefit process in place and any  
third party that moves forward with such activities must recognize  
that in the absence of clear decisions, they are taking a risk and as  
a consequence, may face future litigation over their decisions and  
actions.
In any business venture, it is not the marriage that is the typical  
source of the problems, but the failure to anticipate and plan for the  
divorce.

Regards,

Marc Schwartz


From romain.francois at dbmail.com  Fri Apr 24 14:14:37 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Fri, 24 Apr 2009 14:14:37 +0200
Subject: [Rd] speedup for as.matrix.dist
In-Reply-To: <49E9D72D.9030409@dbmail.com>
References: <49E9D72D.9030409@dbmail.com>
Message-ID: <49F1AD2D.8070400@dbmail.com>

Hi,

I found the init.c file I did not see before.

 > m <- expand.grid( x = 1:20, y = 1:20, z = 1:20 )
 > d <- dist( m )
 > system.time( out <- as.matrix( d ) )
   user  system elapsed
  3.006   1.252   4.429
 > old.as.matrix.dist <- function(x, ...)
+ {
+     size <- attr(x, "Size")
+     df <- matrix(0, size, size)
+     df[row(df) > col(df)] <- x
+     df <- df + t(df)
+     labels <- attr(x, "Labels")
+     dimnames(df) <-
+ if(is.null(labels)) list(1L:size,1L:size) else list(labels,labels)
+     df
+ }
 > system.time( out <- old.as.matrix.dist( d ) )
   user  system elapsed
 17.471   2.964  21.304


Romain

Romain Francois wrote:
> Hello,
>
> I am trying to patch as.matrix.dist to achieve some speedup.
>
> > m <- expand.grid( x = 1:20, y = 1:20, z = 1:20 )
> > d <- dist( m )
> > system.time( out <- stats:::as.matrix.dist( d ) )
>   user  system elapsed
> 15.355   3.110  19.123
> > system.time( out <- as.matrix.dist( d ) )
>   user  system elapsed
>  3.153   0.480   3.782


-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


-------------- next part --------------
A non-text attachment was scrubbed...
Name: dist.diff
Type: text/x-patch
Size: 3124 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090424/bbdddcc9/attachment.bin>

From murdoch at stats.uwo.ca  Fri Apr 24 14:30:18 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 24 Apr 2009 08:30:18 -0400
Subject: [Rd] memory.limit(): Typo in Windows NEWS and function returns
 a	"disregarded" error
In-Reply-To: <49F1876A.3030203@statistik.tu-dortmund.de>
References: <B89F0CE41D45644A97CCC93DF548C1C319DAC132@GBHENXMB02.corp.amvescap.net>
	<49F1876A.3030203@statistik.tu-dortmund.de>
Message-ID: <49F1B0DA.30105@stats.uwo.ca>

On 24/04/2009 5:33 AM, Uwe Ligges wrote:
> Thanks, we know from other messages and this has been files as a bug 
> report minutes ago...
> 
> Best wishes,
> Uwe Ligges
> 
> 
> 
> Pfaff, Bernhard Dr. wrote:
>> Dear list subscriber (R-Core),
>>
>> there is a minor typo in the Windows specific NEWS for R 2.9.0: 
>> http://cran.at.r-project.org/bin/windows/base/CHANGES.R-2.9.0
>> There is no function 'memory.limits() but memory.limit() (see below). 

I'll fix that.

>> Secondly, I am kind of irritated by the function's behaviour. It returns an Error, but as it seems the memory limit is set according to the numeric value for the size argument even it is not a numeric-value according to the error message? In R 2.8.1 this error was not returned (see below).

That's a bug, I'll fix it too.

Duncan Murdoch

>>
>> A clarification/explanation is most welcome.
>>
>> Kind Regards,
>> Bernhard
>>
>>> memory.limits()
>> Error: could not find function "memory.limits"
>>> memory.limit()
>> [1] 1535
>>> memory.limit(size = 2000)
>> Error in trunc(.Internal(memory.size(size))) : 
>>   Non-numeric argument to mathematical function
>>> memory.limit()
>> [1] 2000
>>> version
>>                _                           
>> platform       i386-pc-mingw32             
>> arch           i386                        
>> os             mingw32                     
>> system         i386, mingw32               
>> status                                     
>> major          2                           
>> minor          9.0                         
>> year           2009                        
>> month          04                          
>> day            17                          
>> svn rev        48333                       
>> language       R                           
>> version.string R version 2.9.0 (2009-04-17)
>>
>>
>> In comparison for R 2.8.1:
>>
>>> memory.limit()
>> [1] 1535.875
>>> memory.limit(2000)
>> NULL
>>> memory.limit()
>> [1] 2000
>>> version
>>                _                           
>> platform       i386-pc-mingw32             
>> arch           i386                        
>> os             mingw32                     
>> system         i386, mingw32               
>> status                                     
>> major          2                           
>> minor          8.1                         
>> year           2008                        
>> month          12                          
>> day            22                          
>> svn rev        47281                       
>> language       R                           
>> version.string R version 2.8.1 (2008-12-22)
>>
>>
>> Dr. Bernhard Pfaff
>> Director
>> Global Quantitative Equity
>>
>> Invesco Asset Management Deutschland GmbH
>> Bleichstrasse 60-62
>> D-60313 Frankfurt am Main
>>
>> Tel: +49 (0)69 29807 230
>> Fax: +49 (0)69 29807 178
>> www.institutional.invesco.com
>> Email: bernhard_pfaff at fra.invesco.com
>>
>> Gesch?ftsf?hrer: Karl Georg Bayer, Bernhard Langer, Dr. Jens Langewand, Alexander Lehmann, Christian Puschmann
>> Handelsregister: Frankfurt am Main, HRB 28469
>> Sitz der Gesellschaft: Frankfurt am Main
>>  
>> *****************************************************************
>> Confidentiality Note: The information contained in this ...{{dropped:10}}
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Fri Apr 24 14:40:08 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Fri, 24 Apr 2009 14:40:08 +0200
Subject: [Rd] incorrect output and segfaults from sprintf with
	%*d	(PR#13667)
In-Reply-To: <20090424104524.DFA4F283432B@mail.pubhealth.ku.dk>
References: <20090424104524.DFA4F283432B@mail.pubhealth.ku.dk>
Message-ID: <49F1B328.60503@idi.ntnu.no>

maechler at stat.math.ethz.ch wrote:
>
>     vQ> sprintf has a documented limit on strings included in the output using the
>     vQ> format '%s'.  It appears that there is a limit on the length of strings included
>     vQ> with, e.g., the format '%d' beyond which surprising things happen (output
>     vQ> modified for conciseness):
>     >>> 
>
>     vQ> ... and this limit is *not* documented.
>
>     MM> well, it is basically (+ a few bytes ?)
>     MM> the same  8192  limit that *is* documented.
>
> indeed, I was right with that..
>   

hmm, i'd guess this limit is valid for all strings included in the
output with any format?  not just %s (and, as it appears, undocumentedly
%d)?

>     vQ> while snprintf would help avoid buffer overflow, it may not be a
>     vQ> solution to the issue of confused output.
>
>     MM> I think it would / will.  We would be able to give warnings and
>     MM> errors, by checking the  snprintf()  return codes.
>
> My current working code gives an error for all the above
> examples, e.g.,
>
>  > sprintf('%9999d', 1)
>  Error in sprintf("%9999d", 1) : 
>    required resulting string length 9999 is > maximal 8191
>
> it passes  'make check-devel' and I am inclined to commit that
> code to R-devel (e.g. tomorrow). 
>
> Yes, the documentation will also have to be amended, but apart
> from that, would people see a big problem with the "8192" limit
> which now is suddenly of greater importance
> {{as I said all along;  hence my question to Wacek (and the
>   R-develers)  if anybody found that limit too low}}
>   

i didn't find the limit itself problematic.  (so far?)

btw. (i do know what that means ;)), after your recent fix:

    sprintf('%q%s', 1)
    # Error in sprintf("%q%s", 1) :
    #  use format %f, %e, %g or %a for numeric objects

    sprintf('%s', 1)
    # [1] "1"

you may want to add '%s' (and '%x', and ...) to the error message.  or
perhaps make it say sth like 'invalid format: ...'.  the problem is not
that %q is not applicable to numeric, but that it is not a valid format
at all.

there's also an issue with the additional arguments supplied after the
format:  any superfluous arguments are ignored (this is not documented,
as far as i can see), but they *are* evaluated nevertheless, e.g.:

    sprintf('%d', 0, {print(1)})
    # "1"
    # [1] "0"

it might be a good idea to document this behaviour.

best,
vQ

vQ


From Kurt.Hornik at wu-wien.ac.at  Fri Apr 24 16:17:53 2009
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Fri, 24 Apr 2009 16:17:53 +0200
Subject: [Rd] License status of CRAN packages
In-Reply-To: <49F0DDE5.6060209@fas.harvard.edu>
References: <18928.48327.599527.545472@ron.nulle.part>
	<971536df0904231232vbb024c8p95456acaeae0ff6d@mail.gmail.com>
	<18928.51543.939132.165160@ron.nulle.part>
	<loom.20090423T204756-245@post.gmane.org>
	<971536df0904231413y58e6ea53s9f23d02575c62a23@mail.gmail.com>
	<49F0DDE5.6060209@fas.harvard.edu>
Message-ID: <18929.51729.710038.745412@fangorn.hornik.net>

>>>>> Ben Goodrich writes:

> Gabor Grothendieck wrote:
>> On Thu, Apr 23, 2009 at 4:59 PM, Ben Goodrich <goodrich at fas.harvard.edu> wrote:
>>> Dirk Eddelbuettel <edd <at> debian.org> writes:
>>>> As a non-exhautive list with possible misclassifications, cran2deb currently
>>>> has these packasges as 'maybe not free' and does not build them:
>>>> 
>>>> BARD,BayesDA,CoCo,ConvCalendar,FAiR,PTAk,RScaLAPACK,Rcsdp,SDDA,SGP,
>>>> alphahull,ash,asypow,caMassClass,gpclib,mapproj,matlab,mclust,mclust02,
>>>> mlbench,optmatch,rankreg,realized,rngwell19937,rtiff,rwt,scagnostics,
>>>> sgeostat,spatialkernel,tlnise,xgobi
>>> Small point: FAiR is free. The file LICENSE thing just clarifies that most of
>>> the code is AGPL but a couple files can't be included under the AGPL and are
>>> plain GPL. As far as I can see, R does not give me the option of saying so in a
>>> "standard" way, e.g. putting License: AGPL (>= 3) in the DESCRIPTION file would
>>> only be 95% accurate and putting License: AGPL (>= 3) | GPL (>= 3) is misleading.
>> 
>> How about "
>> 
>> License: AGPL except for 2 GPL files
>> 

> If that would make anyone's life easier without making anyone else's
> life harder, I would be happy to put that in the DESCRIPTION file.

This will be a non-canonical license spec and hence I would ask you to
change back to a canonical one (file LICENSE in your case).

> I have been doing file LICENSE because it parses on

> http://cran.r-project.org/web/packages/FAiR/index.html

> and people can click to the LICENSE link to read the details if they
> are interested. But maybe that is not optimal. Dirk?

The current scheme for license specs standardizes the markup to allow
for computing on the specs.  (And in fact, the code I put into 2.9.0
allows for standardizing most non-standard specs.)  For standard
licenses we can easily provide the text as well as maintain info on
whether the license was classified as "free" (e.g. by the FSF) or "open"
etc.  

AGPL, unfortunately, allows supplements, and hence cannot fully be
standardized.  We've been thinking about extending the current scheme to
indicate a base license plus supplements, but this is still work in
progress.

-k


From kjetilbrinchmannhalvorsen at gmail.com  Fri Apr 24 16:18:24 2009
From: kjetilbrinchmannhalvorsen at gmail.com (Kjetil Halvorsen)
Date: Fri, 24 Apr 2009 10:18:24 -0400
Subject: [Rd] License status of CRAN packages
In-Reply-To: <loom.20090423T204756-245@post.gmane.org>
References: <18928.48327.599527.545472@ron.nulle.part>
	<971536df0904231232vbb024c8p95456acaeae0ff6d@mail.gmail.com>
	<18928.51543.939132.165160@ron.nulle.part>
	<loom.20090423T204756-245@post.gmane.org>
Message-ID: <556e90a80904240718m5daf6b92m717a06c5a46f8b52@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090424/cb65b9c7/attachment.pl>

From Kurt.Hornik at wu-wien.ac.at  Fri Apr 24 16:29:40 2009
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Fri, 24 Apr 2009 16:29:40 +0200
Subject: [Rd] License status of CRAN packages
In-Reply-To: <556e90a80904240718m5daf6b92m717a06c5a46f8b52@mail.gmail.com>
References: <18928.48327.599527.545472@ron.nulle.part>
	<971536df0904231232vbb024c8p95456acaeae0ff6d@mail.gmail.com>
	<18928.51543.939132.165160@ron.nulle.part>
	<loom.20090423T204756-245@post.gmane.org>
	<556e90a80904240718m5daf6b92m717a06c5a46f8b52@mail.gmail.com>
Message-ID: <18929.52436.838207.975100@fangorn.hornik.net>

>>>>> Kjetil Halvorsen writes:

> On Thu, Apr 23, 2009 at 4:59 PM, Ben Goodrich <goodrich at fas.harvard.edu>wrote:
>> Dirk Eddelbuettel <edd <at> debian.org> writes:
>> > As a non-exhautive list with possible misclassifications, cran2deb
>> currently
>> > has these packasges as 'maybe not free' and does not build them:
>> >
>> >      BARD,BayesDA,CoCo,ConvCalendar,FAiR,PTAk,RScaLAPACK,Rcsdp,SDDA,SGP,
>> 

>  BayesDA has
>    License:       GPL version 2 or any later version

> what is unclear about that?

Nothing, although the spec is not canonical as per R-exts, see
http://www.r-project.org/nosvn/R.check/r-devel-linux-ix86/BayesDA-00check.html:

* checking DESCRIPTION meta-information ... NOTE
Non-standard license specification:
GPL version 2 or any later version
Standardizable: TRUE
Standardized license specification:
GPL (>= 2)

But as I wrote, the new code in 2.9.0 standardizes when it can ...

-k



> Kjetil


>> 
>> >
>> alphahull,ash,asypow,caMassClass,gpclib,mapproj,matlab,mclust,mclust02,
>> >
>> mlbench,optmatch,rankreg,realized,rngwell19937,rtiff,rwt,scagnostics,
>> >      sgeostat,spatialkernel,tlnise,xgobi
>> 
>> Small point: FAiR is free. The file LICENSE thing just clarifies that most
>> of
>> the code is AGPL but a couple files can't be included under the AGPL and
>> are
>> plain GPL. As far as I can see, R does not give me the option of saying so
>> in a
>> "standard" way, e.g. putting License: AGPL (>= 3) in the DESCRIPTION file
>> would
>> only be 95% accurate and putting License: AGPL (>= 3) | GPL (>= 3) is
>> misleading.
>> 
>> Ben
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 

> 	[[alternative HTML version deleted]]

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From edd at debian.org  Fri Apr 24 16:48:05 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 24 Apr 2009 09:48:05 -0500
Subject: [Rd] License status of CRAN packages
In-Reply-To: <556e90a80904240718m5daf6b92m717a06c5a46f8b52@mail.gmail.com>
References: <18928.48327.599527.545472@ron.nulle.part>
	<971536df0904231232vbb024c8p95456acaeae0ff6d@mail.gmail.com>
	<18928.51543.939132.165160@ron.nulle.part>
	<loom.20090423T204756-245@post.gmane.org>
	<556e90a80904240718m5daf6b92m717a06c5a46f8b52@mail.gmail.com>
Message-ID: <18929.53541.80256.955192@ron.nulle.part>


On 24 April 2009 at 10:18, Kjetil Halvorsen wrote:
| On Thu, Apr 23, 2009 at 4:59 PM, Ben Goodrich <goodrich at fas.harvard.edu>wrote:
| 
| > Dirk Eddelbuettel <edd <at> debian.org> writes:
| > > As a non-exhautive list with possible misclassifications, cran2deb
| > currently
| > > has these packasges as 'maybe not free' and does not build them:
| > >
| > >      BARD,BayesDA,CoCo,ConvCalendar,FAiR,PTAk,RScaLAPACK,Rcsdp,SDDA,SGP,
| >
| 
|  BayesDA has
|    License:       GPL version 2 or any later version
| 
| what is unclear about that?

Pick any one of

  a)  the license may have been different when that list above was established
 
  b)  the wording, which by the way is not in the format mandated by the R
      Extentions manual, does not match any of the more than dozen free forms
      of saying GPL that we already accept automatically

  c)  the package is fine but it Depends: on another package flagged non-free
      and is hence non-free for us

  d)  lack of volunteer time to manually check and adjust among 1700 packages
      with a steady inflow of new packages

  e)  all of the above

  f)  none of the above.

Dirk

-- 
Three out of two people have difficulties with fractions.


From atp at piskorski.com  Fri Apr 24 17:11:35 2009
From: atp at piskorski.com (Andrew Piskorski)
Date: Fri, 24 Apr 2009 11:11:35 -0400
Subject: [Rd] Closed-source non-free ParallelR ?
In-Reply-To: <384C84AE99C74D9898E4F04DE0E34F49@gpbdmx>
References: <384C84AE99C74D9898E4F04DE0E34F49@gpbdmx>
Message-ID: <20090424151135.GA54749@piskorski.com>

On Thu, Apr 23, 2009 at 03:21:45PM -0700, Ian Fellows wrote:
> Assuming that the foundation does not want to deviate from the FSF
> interpretation, there would still be value in clarifying its position
> vis-?-vis how the license applies to R specifically. 
> 
> For example the FSF foundation claims that linking to a library (even in an
> interpreted environment) makes your software derivative, and therefore must

IMO, that's nuts, there is no such thing as "linking" to a library "in
an interpreted environment".  Linking is a well understood operation
in computer programming, and is always done after compilation,
typically by a special program called "the linker", which is usually
ld, the GNU linker.  If you are solely running code that you wrote in
an interpretor provided by another party, you didn't do any linking,
period.

And more to the point, this:

> ----- Original Message ----- 
> From: "David M Smith" <david at revolution-computing.com>
> Sent: Wednesday, April 22, 2009 4:36 PM
> Subject: Re: [Rd] Closed-source non-free ParallelR ?
> 
> Patrick made all the points that I was going to make (thanks,
> Patrick), but I wanted to reinforce one point that may be the source
> of the confusion: ParallelR is not a modified version of R: ParallelR
> is a suite of ordinary R packages that run on top of the R engine like
> any other package. The R code and Python code in these packages were
> written entirely by REvolution Computing staff (including Patrick),
> and do not contain any code (derived or otherwise) from the R project.

So, as described by David Smith above, the guys at REvolution
Computing ("http://www.revolution-computing.com/") have written some
code of their own code from scratch, code which is not derived from
any of the code in the R distribution.

For the sake of discussion, let's stipulate that David's statement is
in fact entirely true.  (E.g., they did not cheat and plagiarize any R
code.)

They happened to choose to write their code ** in the R programming
language **.  They could have written it in Python or C or Lisp
instead, but they chose R.  It's their code, and they can distribute
it any way they want, including selling it for money.

If you do NOT agree with me there, if you instead believe that
REvolution Computing's code is somehow automatically "derived from"
the R Project's code and therefore if distributed, must be distributed
only under the GPL, well then, logically you must believe that *ANY*
code written in the R language is automatically "derived" from R, and
can only be distributed under the GPL.

Any code.  Do you really want to take that position?  Do you REALLY
want to scare away any and ALL commercial users from writing software
in R, for fear that they'll lose control over how they choose to
distribute their own software?

No, I didn't think so.

Besides, R itself is a second (or third?) implementation and dialect
of the S language, originally created at Bell Labs.  So gee, maybe R
is "derived" from Bell Labs S, and R's own GPL license is invalid?  Of
course not, the entire idea is absurd (shades of SCO) - as I hope you
agree.

-- 
Andrew Piskorski <atp at piskorski.com>
http://www.piskorski.com/


From csardi at rmki.kfki.hu  Fri Apr 24 17:41:29 2009
From: csardi at rmki.kfki.hu (=?ISO-8859-1?B?R+Fib3IgQ3PhcmRp?=)
Date: Fri, 24 Apr 2009 17:41:29 +0200
Subject: [Rd] Closed-source non-free ParallelR ?
In-Reply-To: <20090424151135.GA54749@piskorski.com>
References: <384C84AE99C74D9898E4F04DE0E34F49@gpbdmx>
	<20090424151135.GA54749@piskorski.com>
Message-ID: <d70c15d40904240841u523e77d7s4ec7e45a870ee601@mail.gmail.com>

On Fri, Apr 24, 2009 at 5:11 PM, Andrew Piskorski <atp at piskorski.com> wrote:
> On Thu, Apr 23, 2009 at 03:21:45PM -0700, Ian Fellows wrote:
[...]
> IMO, that's nuts, there is no such thing as "linking" to a library "in
> an interpreted environment". ?Linking is a well understood operation
> in computer programming, and is always done after compilation,
> typically by a special program called "the linker", which is usually
> ld, the GNU linker. ?If you are solely running code that you wrote in
> an interpretor provided by another party, you didn't do any linking,
> period.

Khmmm, that might not be true, at least not entirely. If you develop
an R package that has C/C++/Fortran code, then the library from your
package and R link dynamically at running time. According to the FSF
interpretation, the C/C++/etc. part of your package must be under GPL
in this case.

> And more to the point, this:
>
>> ----- Original Message -----
>> From: "David M Smith" <david at revolution-computing.com>
>> Sent: Wednesday, April 22, 2009 4:36 PM
>> Subject: Re: [Rd] Closed-source non-free ParallelR ?
>>
>> Patrick made all the points that I was going to make (thanks,
>> Patrick), but I wanted to reinforce one point that may be the source
>> of the confusion: ParallelR is not a modified version of R: ParallelR
>> is a suite of ordinary R packages that run on top of the R engine like
>> any other package. The R code and Python code in these packages were
>> written entirely by REvolution Computing staff (including Patrick),
>> and do not contain any code (derived or otherwise) from the R project.
>
> So, as described by David Smith above, the guys at REvolution
> Computing ("http://www.revolution-computing.com/") have written some
> code of their own code from scratch, code which is not derived from
> any of the code in the R distribution.

Still, if they have code that is compiled and linked to R at running
time, then that code must be under the GPL. Again, this is the FSF
interpretation and certainly not R-core's, not even mine.
[...]

-- 
Gabor Csardi <Gabor.Csardi at unil.ch>     UNIL DGM


From goodrich at fas.harvard.edu  Fri Apr 24 17:44:36 2009
From: goodrich at fas.harvard.edu (Ben Goodrich)
Date: Fri, 24 Apr 2009 11:44:36 -0400
Subject: [Rd] License status of CRAN packages
In-Reply-To: <18929.51729.710038.745412@fangorn.hornik.net>
References: <18928.48327.599527.545472@ron.nulle.part>	<971536df0904231232vbb024c8p95456acaeae0ff6d@mail.gmail.com>	<18928.51543.939132.165160@ron.nulle.part>	<loom.20090423T204756-245@post.gmane.org>	<971536df0904231413y58e6ea53s9f23d02575c62a23@mail.gmail.com>	<49F0DDE5.6060209@fas.harvard.edu>
	<18929.51729.710038.745412@fangorn.hornik.net>
Message-ID: <49F1DE64.3040802@fas.harvard.edu>

Kurt Hornik wrote:
> AGPL, unfortunately, allows supplements, and hence cannot fully be
> standardized.  We've been thinking about extending the current scheme to
> indicate a base license plus supplements, but this is still work in
> progress.

This would be helpful. I would just reemphasize that a package that
includes some AGPL code and some GPL3 code is standard as far as the FSF
is concerned, e.g. from section 13 of the AGPL:

"Notwithstanding any other provision of this License, you have
permission to link or combine any covered work with a work licensed
under version 3 of the GNU General Public License into a single combined
work, and to convey the resulting work. The terms of this License will
continue to apply to the part which is the covered work, but the work
with which it is combined will remain governed by version 3 of the GNU
General Public License."

So, I think that CRAN should at least have a canonical spec that covers
*this* situation. Other situations may be more complicated to handle
elegantly.

Thanks,
Ben


From ggrothendieck at gmail.com  Fri Apr 24 18:20:05 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 24 Apr 2009 12:20:05 -0400
Subject: [Rd] License status of CRAN packages
In-Reply-To: <49F1DE64.3040802@fas.harvard.edu>
References: <18928.48327.599527.545472@ron.nulle.part>
	<971536df0904231232vbb024c8p95456acaeae0ff6d@mail.gmail.com> 
	<18928.51543.939132.165160@ron.nulle.part>
	<loom.20090423T204756-245@post.gmane.org> 
	<971536df0904231413y58e6ea53s9f23d02575c62a23@mail.gmail.com> 
	<49F0DDE5.6060209@fas.harvard.edu>
	<18929.51729.710038.745412@fangorn.hornik.net> 
	<49F1DE64.3040802@fas.harvard.edu>
Message-ID: <971536df0904240920m111b35dep5d458f81973921cd@mail.gmail.com>

On Fri, Apr 24, 2009 at 11:44 AM, Ben Goodrich <goodrich at fas.harvard.edu> wrote:
> Kurt Hornik wrote:
>> AGPL, unfortunately, allows supplements, and hence cannot fully be
>> standardized. ?We've been thinking about extending the current scheme to
>> indicate a base license plus supplements, but this is still work in
>> progress.
>
> This would be helpful. I would just reemphasize that a package that
> includes some AGPL code and some GPL3 code is standard as far as the FSF
> is concerned, e.g. from section 13 of the AGPL:
>
> "Notwithstanding any other provision of this License, you have
> permission to link or combine any covered work with a work licensed
> under version 3 of the GNU General Public License into a single combined
> work, and to convey the resulting work. The terms of this License will
> continue to apply to the part which is the covered work, but the work
> with which it is combined will remain governed by version 3 of the GNU
> General Public License."
>
> So, I think that CRAN should at least have a canonical spec that covers
> *this* situation. Other situations may be more complicated to handle
> elegantly.

Another possibility is to simply standardize the set of licenses that CRAN
supports.  GPL licenses (GPl-2, GPL-2.1, GPL-3, LGPL), MIT and
X11 already cover 98% of all packages on CRAN.   If there truly is an
advantage to the AGPL license perhaps a standard version could be offered
in the set.  Perhaps, for the 2% of packages that want a different license
a second repository could be made available.


From ifellows at ucsd.edu  Fri Apr 24 18:48:38 2009
From: ifellows at ucsd.edu (Ian Fellows)
Date: Fri, 24 Apr 2009 09:48:38 -0700
Subject: [Rd] Closed-source non-free ParallelR ?
In-Reply-To: <d70c15d40904240841u523e77d7s4ec7e45a870ee601@mail.gmail.com>
Message-ID: <80B0457F6F3843A49AC7EA5ABFC34CC0@gpbdmx>


>Still, if they have code that is compiled and linked to R at running
>time, then that code must be under the GPL. Again, this is the FSF
>?interpretation and certainly not R-core's, not even mine.
>[...]

Well, not quite. R.h RDefines.h and RInternals.h are LGPL, so as long as the
hooks go through these headers, then all is kosher is it not? Otherwise,
what is the point of having them be LGPL?

ian


From macrakis at alum.mit.edu  Fri Apr 24 18:53:04 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Fri, 24 Apr 2009 12:53:04 -0400
Subject: [Rd] Closed-source non-free ParallelR ?
In-Reply-To: <XFMail.090424015414.Ted.Harding@manchester.ac.uk>
References: <384C84AE99C74D9898E4F04DE0E34F49@gpbdmx>
	<XFMail.090424015414.Ted.Harding@manchester.ac.uk>
Message-ID: <8b356f880904240953l30d173c6jaf80df45809b2ce1@mail.gmail.com>

On Thu, Apr 23, 2009 at 8:54 PM, Ted Harding
<Ted.Harding at manchester.ac.uk> wrote:
> ...However, if that commercial interpreter also had a 'compile' option,
> and I compiled my progrtam using that, then equally I feel sure
> that the compiled version would be subject to whatever restrictions
> had been placed on distirbution fo binaries so compiled. I think
> those things are clear enough.

I do not know of any compiler licenses that place restrictions on what
you can do with code compiled under them, though I suppose they could
in principle. The restrictions typically come if you link to libraries
provided with the compiler.

> ...inspires someone to incorporate the same language extension
> into a GPL'd FORTRAN interpreter/compiler. I think I could then
> be vulnerable, or they could, on the grounds that I/they had pinched
> the idea from the commercial product.

Unless you have a confidentiality agreement of some kind, or the idea
is covered by a patent, you can pinch any ideas you like from other
products.  Copyright law does not cover ideas.

> ...Or maybe the GPL doesn't inhibit you
> from using *ideas* and *features* of GPL software, provided you
> implement them yourself and in your own way?

The GPL does not and cannot restrict reimplementations of ideas and features.

            -s


From P.Dalgaard at biostat.ku.dk  Fri Apr 24 19:08:09 2009
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 24 Apr 2009 19:08:09 +0200
Subject: [Rd] Closed-source non-free ParallelR ?
In-Reply-To: <80B0457F6F3843A49AC7EA5ABFC34CC0@gpbdmx>
References: <80B0457F6F3843A49AC7EA5ABFC34CC0@gpbdmx>
Message-ID: <49F1F1F9.3070606@biostat.ku.dk>

Ian Fellows wrote:
>> Still, if they have code that is compiled and linked to R at running
>> time, then that code must be under the GPL. Again, this is the FSF
>> ?interpretation and certainly not R-core's, not even mine.
>> [...]
> 
> Well, not quite. R.h RDefines.h and RInternals.h are LGPL, so as long as the
> hooks go through these headers, then all is kosher is it not? Otherwise,
> what is the point of having them be LGPL?

Making sure that packages are not GPL just because they include those
header files. The problem is that it is not clear that it suffices in
all cases. It is a legal grey zone, see the "plugin" sections in the GPL
FAQ, for instance.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From csardi at rmki.kfki.hu  Fri Apr 24 19:09:02 2009
From: csardi at rmki.kfki.hu (=?ISO-8859-1?B?R+Fib3IgQ3PhcmRp?=)
Date: Fri, 24 Apr 2009 19:09:02 +0200
Subject: [Rd] Closed-source non-free ParallelR ?
In-Reply-To: <80B0457F6F3843A49AC7EA5ABFC34CC0@gpbdmx>
References: <d70c15d40904240841u523e77d7s4ec7e45a870ee601@mail.gmail.com>
	<80B0457F6F3843A49AC7EA5ABFC34CC0@gpbdmx>
Message-ID: <d70c15d40904241009l70ee6891h1a6d8882971e1d64@mail.gmail.com>

On Fri, Apr 24, 2009 at 6:48 PM, Ian Fellows <ifellows at ucsd.edu> wrote:
>
>>Still, if they have code that is compiled and linked to R at running
>>time, then that code must be under the GPL. Again, this is the FSF
>>?interpretation and certainly not R-core's, not even mine.
>>[...]
>
> Well, not quite. R.h RDefines.h and RInternals.h are LGPL, so as long as the
> hooks go through these headers, then all is kosher is it not? Otherwise,
> what is the point of having them be LGPL?

What the point is I do not know, but I doubt that your argument would
satisfy FSF. The problem is not the "using the headers at compile
time", but the "linking against it at run time" step. AFAIK.

Gabor

> ian
>
>
>



-- 
Gabor Csardi <Gabor.Csardi at unil.ch>     UNIL DGM


From paboyoun at fhcrc.org  Fri Apr 24 19:38:17 2009
From: paboyoun at fhcrc.org (Patrick Aboyoun)
Date: Fri, 24 Apr 2009 10:38:17 -0700
Subject: [Rd] Managing DLLs with the same names in an R session
Message-ID: <49F1F909.3040504@fhcrc.org>

I am having a problem using two DLLs with the same name, but obviously 
located in different directories, in an R session. The troublesome 
package is the (Bioconductor) Rgraphviz package. It relies on (3rd party 
software) graphviz and imports functions from (Bioconductor) package 
graph. Unfortunately, the current stable release of graphviz for Windows

http://www.graphviz.org/pub/graphviz/stable/windows/graphviz-2.22.2.msi

contains a graph.dll in its bin directory. The situation is that 
Rgraphviz needs to link to the graph.dll from graphviz,

E:\paboyoun>..\biocbld\bbs-2.4-bioc\R\bin\R CMD build Rgraphviz
[...omitting output...]
** libs
  making DLL ...
[...omitting output...]
gcc -shared -s -o Rgraphviz.dll tmp.def LL_funcs.o Rgraphviz.o 
RgraphvizInit.o agopen.o agread.o agwr
ite.o bezier.o buildEdgeList.o buildNodeList.o doLayout.o 
graphvizVersion.o init.o -LC:/Graphviz2.22/
bin -lgvc -lgraph -lcdt -Le:/biocbld/bbs-2.4-bioc/R/bin -lR
[...omitting output...]

but at run time R dispatches to the graph.dll from the graph package to 
resolve the symbols.

R-2.9> Sys.which("graph.dll")
                        graph.dll
"C:\\GRAPHV~1.22\\bin\\graph.dll"
R-2.9> library(Rgraphviz)
Loading required package: graph
Loading required package: grid

<< Message box appears:  The procedure entry point agclose could not be 
located in the dynamic link library graph.dll >>

Running Rterm.exe through the DependencyWalker software, I see that the 
gvc.dll and cdt.dll graphviz libraries are properly loaded, but the 
graph.dll dependency of Rgraphviz.dll links to the graph.dll library 
from the graph package. I tried passing the DLLpath for graphviz to the 
library.dynam function call when loading Rgraphviz.dll in the .onLoad 
function within Rgraphviz and it had no effect. I also tried 
library.dynam.unload/dyn.unload-ing the graph.dll from the graph package 
and then loading the Rgraphviz.dll followed by the reloading of the 
graph.dll from the graph package and the graph.dll dependencies become 
broken to the point that a call out to a graph.dll results in a GPF.

Is is possible to manage DLLs with the same name from R or do I need to 
rename one of the DLL names to make them unique?

 > sessionInfo()
R version 2.9.0 (2009-04-17)
i386-pc-mingw32

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 
States.1252;LC_MONETARY=English_United
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] grid      stats     graphics  grDevices utils     datasets  methods
[8] base

other attached packages:
[1] graph_1.22.0

loaded via a namespace (and not attached):
[1] cluster_1.11.13 tools_2.9.0



Patrick


From ripley at stats.ox.ac.uk  Fri Apr 24 19:57:55 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 24 Apr 2009 18:57:55 +0100 (BST)
Subject: [Rd] Managing DLLs with the same names in an R session
In-Reply-To: <49F1F909.3040504@fhcrc.org>
References: <49F1F909.3040504@fhcrc.org>
Message-ID: <alpine.LFD.2.00.0904241852210.18819@gannet.stats.ox.ac.uk>

On Fri, 24 Apr 2009, Patrick Aboyoun wrote:

> I am having a problem using two DLLs with the same name, but obviously 
> located in different directories, in an R session. The troublesome package is 
> the (Bioconductor) Rgraphviz package. It relies on (3rd party software) 
> graphviz and imports functions from (Bioconductor) package graph. 
> Unfortunately, the current stable release of graphviz for Windows
>
> http://www.graphviz.org/pub/graphviz/stable/windows/graphviz-2.22.2.msi
>
> contains a graph.dll in its bin directory. The situation is that Rgraphviz 
> needs to link to the graph.dll from graphviz,
>
> E:\paboyoun>..\biocbld\bbs-2.4-bioc\R\bin\R CMD build Rgraphviz
> [...omitting output...]
> ** libs
> making DLL ...
> [...omitting output...]
> gcc -shared -s -o Rgraphviz.dll tmp.def LL_funcs.o Rgraphviz.o 
> RgraphvizInit.o agopen.o agread.o agwr
> ite.o bezier.o buildEdgeList.o buildNodeList.o doLayout.o graphvizVersion.o 
> init.o -LC:/Graphviz2.22/
> bin -lgvc -lgraph -lcdt -Le:/biocbld/bbs-2.4-bioc/R/bin -lR
> [...omitting output...]
>
> but at run time R dispatches to the graph.dll from the graph package to 
> resolve the symbols.
>
> R-2.9> Sys.which("graph.dll")
>                       graph.dll
> "C:\\GRAPHV~1.22\\bin\\graph.dll"
> R-2.9> library(Rgraphviz)
> Loading required package: graph
> Loading required package: grid
>
> << Message box appears:  The procedure entry point agclose could not be 
> located in the dynamic link library graph.dll >>
>
> Running Rterm.exe through the DependencyWalker software, I see that the 
> gvc.dll and cdt.dll graphviz libraries are properly loaded, but the graph.dll 
> dependency of Rgraphviz.dll links to the graph.dll library from the graph 
> package. I tried passing the DLLpath for graphviz to the library.dynam 
> function call when loading Rgraphviz.dll in the .onLoad function within 
> Rgraphviz and it had no effect. I also tried 
> library.dynam.unload/dyn.unload-ing the graph.dll from the graph package and 
> then loading the Rgraphviz.dll followed by the reloading of the graph.dll 
> from the graph package and the graph.dll dependencies become broken to the 
> point that a call out to a graph.dll results in a GPF.
>
> Is is possible to manage DLLs with the same name from R or do I need to 
> rename one of the DLL names to make them unique?

On Windows, the latter is the only completely reliable solution that 
we know of.  We've been here with iconv.dll, and had to rename the R 
copy to Riconv.dll as a result.  (Unfortunately, it depends on the 
version of Windows and even the service pack installed. AFAICS some 
versions of Windows only allow one DLL of a given name to be loaded 
by a single process, here the R process.)

There are (older?) Unix-alike OSes with similar issues.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From paboyoun at fhcrc.org  Fri Apr 24 20:07:43 2009
From: paboyoun at fhcrc.org (Patrick Aboyoun)
Date: Fri, 24 Apr 2009 11:07:43 -0700
Subject: [Rd] Managing DLLs with the same names in an R session
In-Reply-To: <alpine.LFD.2.00.0904241852210.18819@gannet.stats.ox.ac.uk>
References: <49F1F909.3040504@fhcrc.org>
	<alpine.LFD.2.00.0904241852210.18819@gannet.stats.ox.ac.uk>
Message-ID: <49F1FFEF.4010601@fhcrc.org>

Thanks Brian. I'll stop trying to hack the code to work and opt for the 
dll rename option.

Patrick


Prof Brian Ripley wrote:
> On Fri, 24 Apr 2009, Patrick Aboyoun wrote:
>
>> I am having a problem using two DLLs with the same name, but 
>> obviously located in different directories, in an R session. The 
>> troublesome package is the (Bioconductor) Rgraphviz package. It 
>> relies on (3rd party software) graphviz and imports functions from 
>> (Bioconductor) package graph. Unfortunately, the current stable 
>> release of graphviz for Windows
>>
>> http://www.graphviz.org/pub/graphviz/stable/windows/graphviz-2.22.2.msi
>>
>> contains a graph.dll in its bin directory. The situation is that 
>> Rgraphviz needs to link to the graph.dll from graphviz,
>>
>> E:\paboyoun>..\biocbld\bbs-2.4-bioc\R\bin\R CMD build Rgraphviz
>> [...omitting output...]
>> ** libs
>> making DLL ...
>> [...omitting output...]
>> gcc -shared -s -o Rgraphviz.dll tmp.def LL_funcs.o Rgraphviz.o 
>> RgraphvizInit.o agopen.o agread.o agwr
>> ite.o bezier.o buildEdgeList.o buildNodeList.o doLayout.o 
>> graphvizVersion.o init.o -LC:/Graphviz2.22/
>> bin -lgvc -lgraph -lcdt -Le:/biocbld/bbs-2.4-bioc/R/bin -lR
>> [...omitting output...]
>>
>> but at run time R dispatches to the graph.dll from the graph package 
>> to resolve the symbols.
>>
>> R-2.9> Sys.which("graph.dll")
>>                       graph.dll
>> "C:\\GRAPHV~1.22\\bin\\graph.dll"
>> R-2.9> library(Rgraphviz)
>> Loading required package: graph
>> Loading required package: grid
>>
>> << Message box appears:  The procedure entry point agclose could not 
>> be located in the dynamic link library graph.dll >>
>>
>> Running Rterm.exe through the DependencyWalker software, I see that 
>> the gvc.dll and cdt.dll graphviz libraries are properly loaded, but 
>> the graph.dll dependency of Rgraphviz.dll links to the graph.dll 
>> library from the graph package. I tried passing the DLLpath for 
>> graphviz to the library.dynam function call when loading 
>> Rgraphviz.dll in the .onLoad function within Rgraphviz and it had no 
>> effect. I also tried library.dynam.unload/dyn.unload-ing the 
>> graph.dll from the graph package and then loading the Rgraphviz.dll 
>> followed by the reloading of the graph.dll from the graph package and 
>> the graph.dll dependencies become broken to the point that a call out 
>> to a graph.dll results in a GPF.
>>
>> Is is possible to manage DLLs with the same name from R or do I need 
>> to rename one of the DLL names to make them unique?
>
> On Windows, the latter is the only completely reliable solution that 
> we know of.  We've been here with iconv.dll, and had to rename the R 
> copy to Riconv.dll as a result.  (Unfortunately, it depends on the 
> version of Windows and even the service pack installed. AFAICS some 
> versions of Windows only allow one DLL of a given name to be loaded by 
> a single process, here the R process.)
>
> There are (older?) Unix-alike OSes with similar issues.
>


From danese at revolution-computing.com  Fri Apr 24 20:54:44 2009
From: danese at revolution-computing.com (Danese Cooper)
Date: Fri, 24 Apr 2009 11:54:44 -0700
Subject: [Rd] About ParallelR and licensing of packages
Message-ID: <ca738afd0904241154g64efe7a5jca29a9fd598a13c3@mail.gmail.com>

Howdy all...
Reading with interest the thread(s) about REvolution, package
licensing and the requirements of the GPL.

First of all, let me introduce myself?. ?I joined REvolution Computing
in February, after working for nearly 4 years for Intel as an open
source strategist and before that for 6 years at Sun, where I
established the first corporate open source programs office. ?I'm a
Member of the Apache Software Foundation and serve on a Special
Advisory Board for Mozilla.org. ?I'm also a long-time supporter of the
Free Software Foundation and have served on the board of the Open
Source Initiative since 2001. ?I joined REvolution partly to help them
sort out their open source strategy.

So presumably I know a little bit about licensing.

Part of why I joined REvolution was because it was so clear that they
*really* care about being members in good standing of the R community,
and had already given back several packages and 100% of their mods to
Core R. ?In general REvolution thinks of its self as a "commercial
open source" company, which means that they hope to do well while
doing good...by adding needed functionality and reach to R,
professionalizing support and training for R and in general getting a
bigger slice by making the whole R pizza bigger.

My first interview question to REvolution's CEO was the same one all
of you have been asking. ?"Have you checked with legal counsel about
your package licensing strategy?" and the answer was "Of course we
have."..."Who are your lawyers?" was my next question and the answer
was "Well, we asked the Software Freedom Law Center?." ?What the SFLC
essentially said was that packages designed to run through the R
interpreter don't necessarily have to be licensed under the GPL.
Obviously, changes to Core R do need to be under GPL. and REvolution
has always done that.

The R community has a long-standing practice of allowing packages to
be distributed in CRAN under licenses other than the GPL.  What really
influences package licensing is market forces.  If REvolution or XL
Solutions or any other company in the R space creates an innovative
commercial package that everybody loves, its only a matter of time
until that package will be imitated with an open source package, so
there is a brief commercial life for any R package.  That said,
REvolution is working that commercial innovation space, while seeding
key packages into open source all the time.  So there is a version of
NWS (the guts of ParallelR) available now under GPL.  Internal
discussions about when to open other packages relating to ParallelR
are currently underway.

I'm satisfied that REvolution is very aware of and has been thinking
about licensing questions since their beginning and that we will
continue to work as a member of the larger R community to expand the
reach and utility of R.

--
Danese Cooper
Open Source Diva
REvolution Computing
One Century Tower | 265 Church Street, Suite 1006
New Haven, CT ?06510
P: 408-348-8000 | www.revolution-computing.com

Check out our upcoming events schedule at www.revolution-computing.com/events


From dutangc at gmail.com  Fri Apr 24 22:32:48 2009
From: dutangc at gmail.com (Christophe Dutang)
Date: Fri, 24 Apr 2009 22:32:48 +0200
Subject: [Rd] License status of CRAN packages
In-Reply-To: <971536df0904240920m111b35dep5d458f81973921cd@mail.gmail.com>
References: <18928.48327.599527.545472@ron.nulle.part>
	<971536df0904231232vbb024c8p95456acaeae0ff6d@mail.gmail.com>
	<18928.51543.939132.165160@ron.nulle.part>
	<loom.20090423T204756-245@post.gmane.org>
	<971536df0904231413y58e6ea53s9f23d02575c62a23@mail.gmail.com>
	<49F0DDE5.6060209@fas.harvard.edu>
	<18929.51729.710038.745412@fangorn.hornik.net>
	<49F1DE64.3040802@fas.harvard.edu>
	<971536df0904240920m111b35dep5d458f81973921cd@mail.gmail.com>
Message-ID: <835D77AE-55E8-4036-94E3-3B5AFCD8EC50@gmail.com>

Hi all,

I think for the common licences, we should also add BSD licence... for  
example my pkg randtoolbox (which is currently with incompatible  
licences) will probably be in a near future with the BSD licence.

Anyway I like the idea of two different repositories for GPL like  
licensed pkg and other packages.

Christophe

Le 24 avr. 09 ? 18:20, Gabor Grothendieck a ?crit :

> On Fri, Apr 24, 2009 at 11:44 AM, Ben Goodrich <goodrich at fas.harvard.edu 
> > wrote:
>> Kurt Hornik wrote:
>>> AGPL, unfortunately, allows supplements, and hence cannot fully be
>>> standardized.  We've been thinking about extending the current  
>>> scheme to
>>> indicate a base license plus supplements, but this is still work in
>>> progress.
>>
>> This would be helpful. I would just reemphasize that a package that
>> includes some AGPL code and some GPL3 code is standard as far as  
>> the FSF
>> is concerned, e.g. from section 13 of the AGPL:
>>
>> "Notwithstanding any other provision of this License, you have
>> permission to link or combine any covered work with a work licensed
>> under version 3 of the GNU General Public License into a single  
>> combined
>> work, and to convey the resulting work. The terms of this License  
>> will
>> continue to apply to the part which is the covered work, but the work
>> with which it is combined will remain governed by version 3 of the  
>> GNU
>> General Public License."
>>
>> So, I think that CRAN should at least have a canonical spec that  
>> covers
>> *this* situation. Other situations may be more complicated to handle
>> elegantly.
>
> Another possibility is to simply standardize the set of licenses  
> that CRAN
> supports.  GPL licenses (GPl-2, GPL-2.1, GPL-3, LGPL), MIT and
> X11 already cover 98% of all packages on CRAN.   If there truly is an
> advantage to the AGPL license perhaps a standard version could be  
> offered
> in the set.  Perhaps, for the 2% of packages that want a different  
> license
> a second repository could be made available.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

--
Christophe Dutang
Ph. D. student at ISFA, Lyon, France
website: http://dutangc.free.fr


From goodrich at fas.harvard.edu  Fri Apr 24 23:26:46 2009
From: goodrich at fas.harvard.edu (Ben Goodrich)
Date: Fri, 24 Apr 2009 17:26:46 -0400
Subject: [Rd] License status of CRAN packages
In-Reply-To: <835D77AE-55E8-4036-94E3-3B5AFCD8EC50@gmail.com>
References: <18928.48327.599527.545472@ron.nulle.part>
	<971536df0904231232vbb024c8p95456acaeae0ff6d@mail.gmail.com>
	<18928.51543.939132.165160@ron.nulle.part>
	<loom.20090423T204756-245@post.gmane.org>
	<971536df0904231413y58e6ea53s9f23d02575c62a23@mail.gmail.com>
	<49F0DDE5.6060209@fas.harvard.edu>
	<18929.51729.710038.745412@fangorn.hornik.net>
	<49F1DE64.3040802@fas.harvard.edu>
	<971536df0904240920m111b35dep5d458f81973921cd@mail.gmail.com>
	<835D77AE-55E8-4036-94E3-3B5AFCD8EC50@gmail.com>
Message-ID: <49F22E96.1040605@fas.harvard.edu>

I don't have a strong opinion about partitioning the repository, but I
don't think partitioning based on whether the license is commonly used
for R packages is terribly helpful. AGPL and AGPL + GPL3 are not common
licensing schemes for R packages currently, but from the perspective of
a useR, there is no relevant distinction between these two rare cases
and the more common case of GPL3. So why should packages be put in
separate repositories based on this non-distinction? A partition based
on whether the package is free according to the FSF definition seems
more plausible to me.

Ben

Christophe Dutang wrote:
> Hi all,
> 
> I think for the common licences, we should also add BSD licence... for
> example my pkg randtoolbox (which is currently with incompatible
> licences) will probably be in a near future with the BSD licence.
> 
> Anyway I like the idea of two different repositories for GPL like
> licensed pkg and other packages.
> 
> Christophe
> 
> Le 24 avr. 09 ? 18:20, Gabor Grothendieck a ?crit :
> 
>> On Fri, Apr 24, 2009 at 11:44 AM, Ben Goodrich
>> <goodrich at fas.harvard.edu> wrote:
>>> Kurt Hornik wrote:
>>>> AGPL, unfortunately, allows supplements, and hence cannot fully be
>>>> standardized.  We've been thinking about extending the current
>>>> scheme to
>>>> indicate a base license plus supplements, but this is still work in
>>>> progress.
>>>
>>> This would be helpful. I would just reemphasize that a package that
>>> includes some AGPL code and some GPL3 code is standard as far as the FSF
>>> is concerned, e.g. from section 13 of the AGPL:
>>>
>>> "Notwithstanding any other provision of this License, you have
>>> permission to link or combine any covered work with a work licensed
>>> under version 3 of the GNU General Public License into a single combined
>>> work, and to convey the resulting work. The terms of this License will
>>> continue to apply to the part which is the covered work, but the work
>>> with which it is combined will remain governed by version 3 of the GNU
>>> General Public License."
>>>
>>> So, I think that CRAN should at least have a canonical spec that covers
>>> *this* situation. Other situations may be more complicated to handle
>>> elegantly.
>>
>> Another possibility is to simply standardize the set of licenses that
>> CRAN
>> supports.  GPL licenses (GPl-2, GPL-2.1, GPL-3, LGPL), MIT and
>> X11 already cover 98% of all packages on CRAN.   If there truly is an
>> advantage to the AGPL license perhaps a standard version could be offered
>> in the set.  Perhaps, for the 2% of packages that want a different
>> license
>> a second repository could be made available.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> -- 
> Christophe Dutang
> Ph. D. student at ISFA, Lyon, France
> website: http://dutangc.free.fr
> 
> 
> 
>


From alex at revolution-computing.com  Sat Apr 25 09:16:56 2009
From: alex at revolution-computing.com (Alex Chen)
Date: Sat, 25 Apr 2009 00:16:56 -0700
Subject: [Rd] Managing DLLs with the same names in an R session
In-Reply-To: <49F1FFEF.4010601@fhcrc.org>
References: <49F1F909.3040504@fhcrc.org>
	<alpine.LFD.2.00.0904241852210.18819@gannet.stats.ox.ac.uk>
	<49F1FFEF.4010601@fhcrc.org>
Message-ID: <db7324250904250016t64c09a29xf342df0ad95f89c2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090425/9301923b/attachment.pl>

From maechler at stat.math.ethz.ch  Sat Apr 25 15:00:13 2009
From: maechler at stat.math.ethz.ch (maechler at stat.math.ethz.ch)
Date: Sat, 25 Apr 2009 15:00:13 +0200 (CEST)
Subject: [Rd] incorrect output and segfaults from sprintf with %*d
	(PR#13675)
Message-ID: <20090425130013.93775282C78A@mail.pubhealth.ku.dk>

On Fri, Apr 24, 2009 at 14:40, Wacek Kusnierczyk
<Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:
> maechler at stat.math.ethz.ch wrote:
>>
>> =A0 =A0 vQ> sprintf has a documented limit on strings included in the ou=
tput using the
>> =A0 =A0 vQ> format '%s'. =A0It appears that there is a limit on the leng=
th of strings included
>> =A0 =A0 vQ> with, e.g., the format '%d' beyond which surprising things h=
appen (output
>> =A0 =A0 vQ> modified for conciseness):
>> =A0 =A0 >>>
>>
>> =A0 =A0 vQ> ... and this limit is *not* documented.
>>
>> =A0 =A0 MM> well, it is basically (+ a few bytes ?)
>> =A0 =A0 MM> the same =A08192 =A0limit that *is* documented.
>>
>> indeed, I was right with that..
>>
>
> hmm, i'd guess this limit is valid for all strings included in the
> output with any format? =A0not just %s (and, as it appears, undocumentedl=
y
> %d)?

yes.

>> =A0 =A0 vQ> while snprintf would help avoid buffer overflow, it may not =
be a
>> =A0 =A0 vQ> solution to the issue of confused output.
>>
>> =A0 =A0 MM> I think it would / will. =A0We would be able to give warning=
s and
>> =A0 =A0 MM> errors, by checking the =A0snprintf() =A0return codes.
>>
>> My current working code gives an error for all the above
>> examples, e.g.,
>>
>> =A0> sprintf('%9999d', 1)
>> =A0Error in sprintf("%9999d", 1) :
>> =A0 =A0required resulting string length 9999 is > maximal 8191
>>
>> it passes =A0'make check-devel' and I am inclined to commit that
>> code to R-devel (e.g. tomorrow).
>>
>> Yes, the documentation will also have to be amended, but apart
>> from that, would people see a big problem with the "8192" limit
>> which now is suddenly of greater importance
>> {{as I said all along; =A0hence my question to Wacek (and the
>> =A0 R-develers) =A0if anybody found that limit too low}}
>>
>
> i didn't find the limit itself problematic. =A0(so far?)

ok.

> btw. (i do know what that means ;)), after your recent fix:
>
> =A0 =A0sprintf('%q%s', 1)
> =A0 =A0# Error in sprintf("%q%s", 1) :
> =A0 =A0# =A0use format %f, %e, %g or %a for numeric objects
>
> =A0 =A0sprintf('%s', 1)
> =A0 =A0# [1] "1"
>
> you may want to add '%s' (and '%x', and ...) to the error message. =A0or
> perhaps make it say sth like 'invalid format: ...'. =A0the problem is not
> that %q is not applicable to numeric, but that it is not a valid format
> at all.

yes.  As a matter of fact,  "%q%s" is dealt with as *one* format
chunk, since "%q" is
not a valid format.
The code I have just committed now gives a longer erro message, that
should be more helpful.
Thank you for the suggestion!

> there's also an issue with the additional arguments supplied after the
> format: =A0any superfluous arguments are ignored (this is not documented,
> as far as i can see),

I think we should signal an error if there are too many arguments.
Could anyone think of a case where the current behavior is desirable ?

> but they *are* evaluated nevertheless, e.g.:
>
> =A0 =A0sprintf('%d', 0, {print(1)})
> =A0 =A0# "1"
> =A0 =A0# [1] "0"
>
> it might be a good idea to document this behaviour.

actually I think it should be changed to be more strict (see above).

Thank you for the constructive feedback!
Martin


From tlumley at u.washington.edu  Sat Apr 25 19:00:14 2009
From: tlumley at u.washington.edu (tlumley at u.washington.edu)
Date: Sat, 25 Apr 2009 19:00:14 +0200 (CEST)
Subject: [Rd] printCoefmat() with all-zero first column (PR#13677)
Message-ID: <20090425170015.26EF0282BE88@mail.pubhealth.ku.dk>


> m<-matrix(c(0,1),ncol=2)
> printCoefmat(m)
      [,1] [,2]
[1,]  NaN    1
Warning messages:
1: In min(x) : no non-missing arguments to min; returning Inf
2: In max(x) : no non-missing arguments to max; returning -Inf
3: In log(c(Inf, -Inf), 10) : NaNs produced

> sessionInfo()
R version 2.9.0 beta (2009-04-08 r48309)
i386-apple-darwin9.6.0

locale:
en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Sat Apr 25 19:40:27 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Waclaw.Marcin.Kusnierczyk at idi.ntnu.no)
Date: Sat, 25 Apr 2009 19:40:27 +0200 (CEST)
Subject: [Rd] incorrect output and segfaults from sprintf with %*d
	(PR#13667)
Message-ID: <20090425174027.50884282BE88@mail.pubhealth.ku.dk>

Martin Maechler wrote:
>
>>>     MM> well, it is basically (+ a few bytes ?)
>>>     MM> the same  8192  limit that *is* documented.
>>>
>>> indeed, I was right with that..
>>>
>>>       
>> hmm, i'd guess this limit is valid for all strings included in the
>> output with any format?  not just %s (and, as it appears, undocumentedly
>> %d)?
>>     
>
> yes.
>   

so it's perhaps easiest to change

" There is a limit of 8192 bytes on elements of 'fmt' and also on
     strings included by a '%s' conversion specification."

to sth like

" There is a limit of 8192 bytes on elements of 'fmt' and also on
     strings included in the output by any conversion specification."

it's in fact so easy that even i should be able to do it.

[1 minute later...]  i see you've fixed this one, too.


>> btw. (i do know what that means ;)), after your recent fix:
>>
>>    sprintf('%q%s', 1)
>>    # Error in sprintf("%q%s", 1) :
>>    #  use format %f, %e, %g or %a for numeric objects
>>
>>    sprintf('%s', 1)
>>    # [1] "1"
>>
>> you may want to add '%s' (and '%x', and ...) to the error message.  or
>> perhaps make it say sth like 'invalid format: ...'.  the problem is not
>> that %q is not applicable to numeric, but that it is not a valid format
>> at all.
>>     
>
> yes.  As a matter of fact,  "%q%s" is dealt with as *one* format
> chunk, since "%q" is
> not a valid format.
> The code I have just committed now gives a longer erro message, that
> should be more helpful.
>   

yes, but

    sptinf('%q%s', 1)


still suggests that one uses %{f,e,g,a} for numerics, while %s is pretty
much valid, too.  you see, in c sprintf(buffer, "%s", 1) is destined to
cause a segfault, but in r it works -- so the error message is slightly
misleading, as it suggests %s is *not* valid for numerics.

> Thank you for the suggestion!
>   

yo welcum

>   
>> there's also an issue with the additional arguments supplied after the
>> format:  any superfluous arguments are ignored (this is not documented,
>> as far as i can see),
>>     
>
> I think we should signal an error if there are too many arguments.
>   

agree.  but it might be more complex than it appears:

    sprintf('%3$s', 1, 2, 3)

should *not* complain about too many args, despite just one conversion
spec in the format.  interestingly,

    sprintf('%3$s', , , 3)
    # error: argument is missing, with no default


> Could anyone think of a case where the current behavior is desirable ?
>   

well, one scenario might be that one wants to print a collection of
items with an arbitrary format, supplied by the users, e.g.

    foo = function(fmt) {
       a = ...
       b = ...
       ...
       s = sprintf(fmt, a, b, ...)
       ... }

without having to examine the format to establish which values are
needed.  in the current state, sprintf would use those it would need to
use with a particular format, with no undesirable complaints.


>   
>> but they *are* evaluated nevertheless, e.g.:
>>
>>    sprintf('%d', 0, {print(1)})
>>    # "1"
>>    # [1] "0"
>>
>> it might be a good idea to document this behaviour.
>>     
>
> actually I think it should be changed to be more strict (see above).
>   

strict in which sense?  enforce a constraint on the number of arguments
to that needed by a specific format?  or do you mean evaluation of only
those arguments that are needed in a format?  or both?

what about:

    sprintf('%2$s', {print(1)}, 2)
    # too many arguments?
    # should 1 be printed?

    sprintf('%2$s', , 2)
    # too few arguments?
    # missing value?  (yes, sprintf is .Internal, but...)


> Thank you for the constructive feedback!
>   

not much to thank for...  certainly, it's the first time my feedback is
called 'constructive'.  i'm making progress, am i not?

btw., thank you for the fixes.  i appreciate your efforts a lot.

best,
vQ


From chuck at sharpsteen.net  Fri Apr 24 19:31:17 2009
From: chuck at sharpsteen.net (pax131)
Date: Fri, 24 Apr 2009 10:31:17 -0700 (PDT)
Subject: [Rd] Closed-source non-free ParallelR ?
In-Reply-To: <8b356f880904240953l30d173c6jaf80df45809b2ce1@mail.gmail.com>
References: <373DCC90906D430E952EF2C423B0D91B@ADAM>
	<ac81d400904220740i5a4adac4l41b1a170c6f27bd7@mail.gmail.com>
	<475a3c8f0904220836w43d07042m84f42edf6e05766c@mail.gmail.com>
	<E1C5F6F55B4445AF902DF4B970BE1688@ADAM>
	<8b356f880904230947n6a410d2lc06b9088e53041b0@mail.gmail.com>
	<B49C0AC4-8331-4F2D-81A7-48119E369221@me.com>
	<8b356f880904231322j1251d50if184b94f24c619ca@mail.gmail.com>
	<F21BE202-7384-40EF-B608-A7A1E821CE4E@me.com>
	<384C84AE99C74D9898E4F04DE0E34F49@gpbdmx>
	<XFMail.090424015414.Ted.Harding@manchester.ac.uk>
	<8b356f880904240953l30d173c6jaf80df45809b2ce1@mail.gmail.com>
Message-ID: <23221398.post@talk.nabble.com>



Stavros Macrakis-2 wrote:
> 
> 
> I do not know of any compiler licenses that place restrictions on what
> you can do with code compiled under them, though I suppose they could
> in principle. The restrictions typically come if you link to libraries
> provided with the compiler.
> 
> 

These restrictions definitely exist. For example, you can not legally run
programs created with an educational version of a compiler in support of
commercial or governmental purposes. Intel provides free compilers for
non-commercial software development, with licenses that I think preclude the
use of any created programs for governmental purposes.
-- 
View this message in context: http://www.nabble.com/Closed-source-non-free-ParallelR---tp23170843p23221398.html
Sent from the R devel mailing list archive at Nabble.com.


From pnovak at azcc.arizona.edu  Fri Apr 24 13:50:36 2009
From: pnovak at azcc.arizona.edu (Petr Novak)
Date: Fri, 24 Apr 2009 04:50:36 -0700
Subject: [Rd] Error in X11() : X11 module cannot be loaded
Message-ID: <0BBB2D68F1083F4EAC35E5EBE1511CB61285887463@azccex01.azcc.local>

Hi,
we are using R installed on several linux computer - mostly debian lenny
and also ubuntu, all 64 bit. Approx.two week ago, I started getting the
following error when I tried to plot().

Error in X11() : X11 module cannot be loaded
In addition: Warning message:
In X11() : unable to load shared library
'/usr/lib64/R/modules//R_X11.so':
  /usr/lib/libcairo.so.2: symbol png_set_expand_gray_1_2_4_to_8, version
PNG12_0 not defined in file libpng12.so.0 with link time reference

This error occurs now on all five computer we are using (due to
aupdate???)

we are using  R version 2.7.1 (2008-06-23) installed using aptitude from
repositories.

Does anybody have idea what is going on?

Petr


DISCLAIMER: This email and any files transmitted with it...{{dropped:7}}


From simon.urbanek at r-project.org  Sun Apr 26 00:11:21 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 25 Apr 2009 18:11:21 -0400
Subject: [Rd] R build fails during make when configured with
	"--with-x=no" (PR#13665)
In-Reply-To: <49EC555A.60602@biostat.ku.dk>
References: <20090420051009.535E6282C76F@mail.pubhealth.ku.dk>
	<49EC555A.60602@biostat.ku.dk>
Message-ID: <235F553F-2113-48DC-B933-265F255BB84A@r-project.org>

It should be fixed now.

Cheers,
Simon

On Apr 20, 2009, at 6:58 AM, Peter Dalgaard wrote:

> jeet at ku.edu wrote:
>
>>
>> If R is configured using the "--with=x=no" option, then the make  
>> fails with the
>> following error:
> ,,,,
>> make[1]: *** [R] Error 1
>> make[1]: Leaving directory `/home/jeet/Scratch/r-build/on-frontend/ 
>> R-2.9.0/src'
>> make: *** [R] Error 1
>>
>> The problem appears to be with the "src/modules/Makefile".  
>> Specfically, lines
>> 26-29:
>>
>> 	@for d in "$(R_MODULES)"; do \
>> 	  (cd $${d} && $(MAKE) $@) || exit 1; \
>> 	done
>>
>> Here, R_MODULES is blank, resulting in the "cd" command  
>> transferring to the
>> user's home directory, where, of course, no Makefile is found  
>> resulting in the
>> error above.
>
> (Even more "fun" would ensue if in fact there were a Makefile  
> there...)
>
>
>> Work-around appears to be to simply disable loop if R_MODULES is  
>> empty.
>
> Shell script and Make portability is a pain in the derriere, but
> offhand, those double quotes just look wrong:
>
> viggo:~/>for i in "" ; do echo $i; done
>
> viggo:~/>for i in  ; do echo $i; done
> viggo:~/>for i in "foo bar" ; do echo $i; done
> foo bar
> viggo:~/>for i in foo bar ; do echo $i; done
> foo
> bar
>
> Notice that the versions with quotes invariably do the Wrong Thing....
>
>
> -- 
>   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
> (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45)  
> 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45)  
> 35327907
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Ted.Harding at manchester.ac.uk  Sun Apr 26 13:24:23 2009
From: Ted.Harding at manchester.ac.uk ( (Ted Harding))
Date: Sun, 26 Apr 2009 12:24:23 +0100 (BST)
Subject: [Rd] Closed-source non-free ParallelR ?
In-Reply-To: <8b356f880904240953l30d173c6jaf80df45809b2ce1@mail.gmail.com>
Message-ID: <XFMail.090426122423.Ted.Harding@manchester.ac.uk>

On 24-Apr-09 16:53:04, Stavros Macrakis wrote:
> On Thu, Apr 23, 2009 at 8:54 PM, Ted Harding
> <Ted.Harding at manchester.ac.uk> wrote:
> [...]
>> ...inspires someone to incorporate the same language extension
>> into a GPL'd FORTRAN interpreter/compiler. I think I could then
>> be vulnerable, or they could, on the grounds that I/they had pinched
>> the idea from the commercial product.
> 
> Unless you have a confidentiality agreement of some kind, or the idea
> is covered by a patent, you can pinch any ideas you like from other
> products.  Copyright law does not cover ideas.

Well, I'm not so sure about that ... back in 2002/2003, National
Instrument sued the MathWorks (MatLab proprietors) on the grounds
that the MathWorks Simulink graphical development tool infringed
on National Instruments' patented rights in such an idea. NI's
implementation is embodied in their LabVIEW tool.

In both cases, the tool consists of 'data flow diagrams' drawn on
screen under the user's mouse control, using icons, with the ability
to associate data structures and code with the nodes and the links.

On my reading of it, it was the *idea* of using such a graphical
interface itself which National Instruments claimed to have patented,
namely

  The technology of the patents in suit concerns the creation
  of model systems (generally known as "data flow diagrams")
  through building diagrams on a computer screen by pointing
  and clicking with a mouse, rather than writing traditional
  lines of code. ...

The patent claims (long, and hoghly detailed) can be read at

  http://www.freepatentsonline.com/4901221.html
  http://www.freepatentsonline.com/4914568.html
  http://www.freepatentsonline.com/5301336.html

The Mathworks lost, and it went to appeal. Mathworks also lost the
appeal. The Appeal Court's opinion can be read at

  http://cafc.bna.com/03-1540.pdf

And the best of luck ... As I said before, I am not a lawyer and
tend to get bewildered by their use of language; but others may end
up more sure about this topic!

Ted.

>> ...Or maybe the GPL doesn't inhibit you
>> from using *ideas* and *features* of GPL software, provided you
>> implement them yourself and in your own way?
> 
> The GPL does not and cannot restrict reimplementations of ideas and
> features.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 26-Apr-09                                       Time: 12:24:16
------------------------------ XFMail ------------------------------


From simon.urbanek at r-project.org  Sun Apr 26 16:16:16 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sun, 26 Apr 2009 10:16:16 -0400
Subject: [Rd] Closed-source non-free ParallelR ?
In-Reply-To: <XFMail.090426122423.Ted.Harding@manchester.ac.uk>
References: <XFMail.090426122423.Ted.Harding@manchester.ac.uk>
Message-ID: <EA309168-2AB4-48A9-A9D6-30471FC49966@r-project.org>


On Apr 26, 2009, at 7:24 AM, (Ted Harding) wrote:

> On 24-Apr-09 16:53:04, Stavros Macrakis wrote:
>> On Thu, Apr 23, 2009 at 8:54 PM, Ted Harding
>> <Ted.Harding at manchester.ac.uk> wrote:
>> [...]
>>> ...inspires someone to incorporate the same language extension
>>> into a GPL'd FORTRAN interpreter/compiler. I think I could then
>>> be vulnerable, or they could, on the grounds that I/they had pinched
>>> the idea from the commercial product.
>>
>> Unless you have a confidentiality agreement of some kind, or the idea
>> is covered by a patent, you can pinch any ideas you like from other
>> products.  Copyright law does not cover ideas.
>
> Well, I'm not so sure about that ...

Ted, the key word here is "copyright" law. That is entirely different  
from patents and IP (that was Stavros' point I think).

Cheers,
Simon


> back in 2002/2003, National
> Instrument sued the MathWorks (MatLab proprietors) on the grounds
> that the MathWorks Simulink graphical development tool infringed
> on National Instruments' patented rights in such an idea. NI's
> implementation is embodied in their LabVIEW tool.
>
> In both cases, the tool consists of 'data flow diagrams' drawn on
> screen under the user's mouse control, using icons, with the ability
> to associate data structures and code with the nodes and the links.
>
> On my reading of it, it was the *idea* of using such a graphical
> interface itself which National Instruments claimed to have patented,
> namely
>
>  The technology of the patents in suit concerns the creation
>  of model systems (generally known as "data flow diagrams")
>  through building diagrams on a computer screen by pointing
>  and clicking with a mouse, rather than writing traditional
>  lines of code. ...
>
> The patent claims (long, and hoghly detailed) can be read at
>
>  http://www.freepatentsonline.com/4901221.html
>  http://www.freepatentsonline.com/4914568.html
>  http://www.freepatentsonline.com/5301336.html
>
> The Mathworks lost, and it went to appeal. Mathworks also lost the
> appeal. The Appeal Court's opinion can be read at
>
>  http://cafc.bna.com/03-1540.pdf
>
> And the best of luck ... As I said before, I am not a lawyer and
> tend to get bewildered by their use of language; but others may end
> up more sure about this topic!
>
> Ted.
>
>>> ...Or maybe the GPL doesn't inhibit you
>>> from using *ideas* and *features* of GPL software, provided you
>>> implement them yourself and in your own way?
>>
>> The GPL does not and cannot restrict reimplementations of ideas and
>> features.
>
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
> Fax-to-email: +44 (0)870 094 0861
> Date: 26-Apr-09                                       Time: 12:24:16
> ------------------------------ XFMail ------------------------------
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From macrakis at alum.mit.edu  Sun Apr 26 18:33:43 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Sun, 26 Apr 2009 12:33:43 -0400
Subject: [Rd] Closed-source non-free ParallelR ?
In-Reply-To: <XFMail.090426122423.Ted.Harding@manchester.ac.uk>
References: <8b356f880904240953l30d173c6jaf80df45809b2ce1@mail.gmail.com>
	<XFMail.090426122423.Ted.Harding@manchester.ac.uk>
Message-ID: <8b356f880904260933p4cb169b9k495608c8b772f977@mail.gmail.com>

On Sun, Apr 26, 2009 at 7:24 AM, Ted Harding
<Ted.Harding at manchester.ac.uk> wrote:
> On 24-Apr-09 16:53:04, Stavros Macrakis wrote:
>> On Thu, Apr 23, 2009 at 8:54 PM, Ted Harding
>> <Ted.Harding at manchester.ac.uk> wrote:
>> [...]
>>> ...inspires someone to incorporate the same language extension
>>> into a GPL'd FORTRAN interpreter/compiler. I think I could then
>>> be vulnerable, or they could, on the grounds that I/they had pinched
>>> the idea from the commercial product.
>>
>> Unless you have a confidentiality agreement of some kind, or the idea
>> is covered by a patent, you can pinch any ideas you like from other
>> products. ?Copyright law does not cover ideas.
>
> Well, I'm not so sure about that ... back in 2002/2003, National
> Instrument sued the MathWorks (MatLab proprietors) on the grounds
> that the MathWorks Simulink graphical development tool infringed
> on National Instruments' patented rights in such an idea....

That was a patent case.  We were discussing copyright licenses. Please
read up on the difference before speculating.

            -s


From edd at debian.org  Sun Apr 26 19:03:35 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 26 Apr 2009 12:03:35 -0500
Subject: [Rd] Error in X11() : X11 module cannot be loaded
In-Reply-To: <0BBB2D68F1083F4EAC35E5EBE1511CB61285887463@azccex01.azcc.local>
References: <0BBB2D68F1083F4EAC35E5EBE1511CB61285887463@azccex01.azcc.local>
Message-ID: <18932.37863.536570.107125@ron.nulle.part>


On 24 April 2009 at 04:50, Petr Novak wrote:
| Hi,
| we are using R installed on several linux computer - mostly debian lenny
| and also ubuntu, all 64 bit. Approx.two week ago, I started getting the
| following error when I tried to plot().
| 
| Error in X11() : X11 module cannot be loaded
| In addition: Warning message:
| In X11() : unable to load shared library
| '/usr/lib64/R/modules//R_X11.so':
|   /usr/lib/libcairo.so.2: symbol png_set_expand_gray_1_2_4_to_8, version
| PNG12_0 not defined in file libpng12.so.0 with link time reference
| 
| This error occurs now on all five computer we are using (due to
| aupdate???)
| 
| we are using  R version 2.7.1 (2008-06-23) installed using aptitude from
| repositories.
| 
| Does anybody have idea what is going on?

Nope, not from what you wrote.

My amd64 builds of R on Ubuntu---using Vincent and Michael's builds of my
Debian packages---continue to work fine, including use of x11.  I tend to
keep them current to Ubuntu repos too (but I am still using Ubuntu 8.10 not
9.04). 

Dirk

-- 
Three out of two people have difficulties with fractions.


From deepayan.sarkar at gmail.com  Sun Apr 26 20:40:56 2009
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Sun, 26 Apr 2009 11:40:56 -0700
Subject: [Rd] Closed-source non-free ParallelR ?
In-Reply-To: <8b356f880904260933p4cb169b9k495608c8b772f977@mail.gmail.com>
References: <8b356f880904240953l30d173c6jaf80df45809b2ce1@mail.gmail.com>
	<XFMail.090426122423.Ted.Harding@manchester.ac.uk>
	<8b356f880904260933p4cb169b9k495608c8b772f977@mail.gmail.com>
Message-ID: <eb555e660904261140x3268b095o8b897b9a7ad6f481@mail.gmail.com>

On 4/26/09, Stavros Macrakis <macrakis at alum.mit.edu> wrote:
> On Sun, Apr 26, 2009 at 7:24 AM, Ted Harding
>
> <Ted.Harding at manchester.ac.uk> wrote:
>  > On 24-Apr-09 16:53:04, Stavros Macrakis wrote:
>  >> On Thu, Apr 23, 2009 at 8:54 PM, Ted Harding
>  >> <Ted.Harding at manchester.ac.uk> wrote:
>  >> [...]
>  >>> ...inspires someone to incorporate the same language extension
>  >>> into a GPL'd FORTRAN interpreter/compiler. I think I could then
>  >>> be vulnerable, or they could, on the grounds that I/they had pinched
>  >>> the idea from the commercial product.
>  >>
>  >> Unless you have a confidentiality agreement of some kind, or the idea
>  >> is covered by a patent, you can pinch any ideas you like from other
>  >> products.  Copyright law does not cover ideas.
>  >
>  > Well, I'm not so sure about that ... back in 2002/2003, National
>  > Instrument sued the MathWorks (MatLab proprietors) on the grounds
>  > that the MathWorks Simulink graphical development tool infringed
>
> > on National Instruments' patented rights in such an idea....
>
>  That was a patent case.  We were discussing copyright licenses. Please
>  read up on the difference before speculating.

And you can read Stallman's take on it here:

http://www.gnu.org/philosophy/not-ipr.xhtml

-Deepayan


From jmc at r-project.org  Sun Apr 26 21:58:27 2009
From: jmc at r-project.org (John Chambers)
Date: Sun, 26 Apr 2009 12:58:27 -0700
Subject: [Rd] Some extensions to class inheritance and method selection
Message-ID: <49F4BCE3.5040704@r-project.org>

Changes were committed today to the r-devel version of R to make S4 and 
S3 classes (and abnormal object types such as "environment") work 
together more consistently.

Basically, S4 classes can now contain any S3 class or object type, and 
should now inherit S3 methods for these.  Also, the main practical 
problem with defining S3 methods for other S4 classes (namely, that S4 
inheritance was not recognized) has been fixed, to the extent possible.

See ?Methods (especially the section on S3 methods).  For details (there 
are quite a few) see the paper referenced there,
  http://stat.stanford.edu/~jmc4/classInheritance.pdf

Since these changes arguably fix design flaws, I would like to see them 
in 2.9.1, so please test them out.  For the moment, they are only in the 
r-devel version.

There can be changes to current behavior.  For example, I found one 
regression test for S4 methods that only worked because an apparent S3 
method, sort.list, was NOT inherited by an S4 class that contained "list".

John


From mdowle at mdowle.plus.com  Mon Apr 27 04:21:17 2009
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Mon, 27 Apr 2009 03:21:17 +0100
Subject: [Rd] About ParallelR and licensing of packages
Message-ID: <63F1FB9F17FC464F99E370DAAEC9C6BB@ADAM>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090427/449d3e4c/attachment.pl>

From ifellows at ucsd.edu  Mon Apr 27 07:24:31 2009
From: ifellows at ucsd.edu (Fellows, Ian)
Date: Sun, 26 Apr 2009 22:24:31 -0700
Subject: [Rd] About ParallelR and licensing of packages
In-Reply-To: <63F1FB9F17FC464F99E370DAAEC9C6BB@ADAM>
References: <63F1FB9F17FC464F99E370DAAEC9C6BB@ADAM>
Message-ID: <B446C80490282E4DA89675F5F736D7513C450CDED6@MBX3.AD.UCSD.EDU>

Matthew,

   I can only assume that because you posted this to R Devel that you wish for general commentary. So far as I am able to tell, Revolutions has acted in the best of faith regarding respecting the GPL license and the R community. It is unfortunate that premature claims like yours may scare off future commercial vendors who wish to respect the IP of contributors.

Without knowing much about it's implementation, it seems to me that your claim that ParallelR is somehow a derivative of data.table seems implausible to the extreme. How exactly do you think that their parallel code 'requires' your package to work? And if you don't know, don't you think that it might have been a little premature to make a big public fuss about it?

>This potential dispute is between myself only and REvolution. You must engage with me directly by answering the questions above with respect to data.table. It is a matter for you whether you answer publicly, via your lawyers or
>privately to me.  It is my understanding that any other GPL'd R library owners is also entitled to establish, either now or in the future, whether they are also potentially in dispute with you on the same basis as above. There are up
>to 1,700 distinct R libraries, each of which could potentially generate 1,700 claims of breach of contract on you. One of those is the R Foundation, who as license holder for the library "base" have stated they will make a public
>statement in due course. That is a matter for the R Foundation, and them alone.  In my potential dispute with you, under English law I have 6 years between the date of any as yet unknown breach of contract and the date by
>which I must serve notice on you and submit particulars of claim to the court.  My lawyers cannot start to draft particulars of claim until we have established we are actually in dispute.

Dr. Ripley noted earlier in this thread that base is considered part of the language. As for your mythical storm of 1700 breaches of contract,... that would only be the case if either, 1700 packages were directly called, and required by the parts of REvolutions that are proprietary, or 1700 package maintainers misunderstood the GPL.

>4. Whether or not I felt legally obligated to release data.table under the GPL, because it was or was not derived from the R library "base", or any other point of FSF guidance, is irrelevant to my potential dispute with you regarding
> data.table. The fact is I released data.table under the GPL.

again, base would seem to be part of the language.

>5. Denise has stated to be a long-time supporter of the FSF and has served on the board of the Open Source Initiative since 2001. In what manner does support of FSF extend?  Holding such affiliations may create a conflict o
>f interest with regard to my potential claim against you. It is feasible, if we are in dispute of course, that my lawyers could at a future date ask Denise to relinquish either the FSF affiliation or employment by you.  I had already
> communicated with the FSF for example before the email from Denise, so you may be privy to such communication, potentially causing a conflict or interest.

It seems a bit arrogant to claim that you might be able legally force a private individual who has committed no crime to change what people or organizations that they associate with. You could of course "ask" that she relinquish associations, but that is not up to you or your lawyers. That is between the FSF and her.

Ian



________________________________________
From: r-devel-bounces at r-project.org [r-devel-bounces at r-project.org] On Behalf Of Matthew Dowle [mdowle at mdowle.plus.com]
Sent: Sunday, April 26, 2009 7:21 PM
To: Danese Cooper
Cc: r-devel at r-project.org
Subject: Re: [Rd] About ParallelR and licensing of packages

Dear Danese,

Without prejudice save as to costs

I am the author of the R library "data.table". I released data.table under the provisions of the General Public License (GPL). This email is to notify REvolution that we may be in dispute.  If we are in dispute then I am entitled to issue litigation proceedings against REvolution for breach of contract.

To establish if we are in fact in dispute, please answer the following :

1. Does REvolution R Enterprise include the library data.table ?
2. Has REvolution R Enterprise been distributed yet, for example has REvolution sold a copy ?
3. If it was distributed, was it distributed under a GPL-compatible license ?

FSF guidance :  http://www.fsf.org/licensing/licenses/gpl-faq.html#GPLInProprietarySystem

Notwithstanding a potential dispute on the basis above, please also answer the following :

4. Has REvolution distributed any program code, written in R or any other language or environment or otherwise, which uses the library data.table, for example by calling functions that are provided by data.table at run time ?
5. If so, was such program code distributed under a GPL compatible license ?
FSF guidance :
http://www.fsf.org/licensing/licenses/gpl-faq.html#IfInterpreterIsGPL  (3rd paragraph)
http://www.fsf.org/licensing/licenses/gpl-faq.html#IfLibraryIsGPL
http://www.fsf.org/licensing/licenses/gpl-faq.html#NFUseGPLPlugins

I am making every effort to agree with you that we are not in dispute.  I have several suggestions which may avoid dispute, for example you could remove data.table from REvolution R Enterprise. You could confirm that the aggregate work REvolution R Enterprise is released under a GPL-compatible license. There may well be other solutions you could suggest. You could decide to postpone distribution of REvolution R Enterprise until all potential disputes are resolved.  If I have not heard from you or your representatives within 21 days of today 26 April 2009 then I will instruct my legal representatives to establish whether there is a dispute. Alternatively you can confirm we are in dispute and I will start to accrue legal costs immediately thereon. Any such costs will themselves form part of the claim. I intend to be as open and forthcoming with you about costs as my lawyers permit me.

This potential dispute is between myself only and REvolution. You must engage with me directly by answering the questions above with respect to data.table. It is a matter for you whether you answer publicly, via your lawyers or privately to me.  It is my understanding that any other GPL'd R library owners is also entitled to establish, either now or in the future, whether they are also potentially in dispute with you on the same basis as above. There are up to 1,700 distinct R libraries, each of which could potentially generate 1,700 claims of breach of contract on you. One of those is the R Foundation, who as license holder for the library "base" have stated they will make a public statement in due course. That is a matter for the R Foundation, and them alone.  In my potential dispute with you, under English law I have 6 years between the date of any as yet unknown breach of contract and the date by which I must serve notice on you and submit particulars of claim to the cou!
 rt.  My lawyers cannot start to draft particulars of claim until we have established we are actually in dispute.

I remind you of the contract by which you are bound by me of your distributing of my library, or your distributing of programs (yours or otherwise) which use my library :

Licensing FAQ page:    http://www.fsf.org/licenses/gpl-faq.html
Text of the GNU GPL:   http://www.fsf.org/copyleft/gpl.html
Text of the GNU LGPL:  http://www.fsf.org/copyleft/lgpl.html
FSF license list page: http://www.fsf.org/licenses/license-list.html

I look forward to your response.

I have 5 further points to add, each of which may be relevant with respect to my potential dispute with you.

1.  NetworkSpaces (library 'nws')
This is very welcome. I look forward to using it and I look forward to seeing many other GPL'd libraries being distributed that use it. REvolution released nws under the GPL, the same license as data.table is released under. This is a material fact that may be relevant in our potential dispute. It will be difficult for REvolution to argue in court in defence of my claim, that either you do not agree with the FSF's GPL license, you do not agree with the FSF guidance, or you were not aware of the differences between GPL and LGPL, for example, since your firm has already relied on the GPL license to protect your library, and the CRAN repository as a method to impose the license. You would find it hard to argue that no contract has been signed with a wet signature for example, since you did not impose that requirement on R users for your own library 'nws'.  Your difficulty would be further compounded if you were yourself the claimant against another entity which had distributed !
 non-GPL work which used the library nws.

2.  SFLC
The guidance from the FSF on this matter is above. It goes further than your summary of SFLC's counsel.  As we are both holders of FSF licenses, I suggest we should both follow the FSF guidance as a standard. This would of course be a matter for our lawyers to establish in due course,  if it turns out we are in dispute.

3.  Precedent for CRAN package license status
The onus is on you to prove precedent, since your apparent claim of precedent would be your defence in the potential case against you from the R Foundation or indeed in my case against you. There are several steps required to prove precedent in my person opinion :
i.  You must prove that distribution actually took place. The existence of a package on CRAN does not prove it has been distributed. In the same way that the REvolution R Enterprise web page exists on your website does not prove you have distributed that product.  It is possible that there are packages on CRAN that no entity has ever downloaded. Such non-distributed packages could not breach R's GPL, regardless of their license status.
ii.  Then you must prove that the R Foundation knew about such distribution.  The distribution may have taken place off-CRAN, or a host of other reasons.
iii.  Then you must prove that such distribution event did actually breach R's GPL license,  and that the R Foundation knew they would have been able to prove that.  However, the following guidance from the FSF would appear to suggest that any added restrictions can be removed by the user (the person using such package) anyway : http://www.fsf.org/licensing/licenses/gpl-faq.html#NoMilitary.  So there would be no breach of GPL in this instance even though the package author attempted to add restrictions.
iv.  Then you must prove that the R Foundation did not, and can not in the future, bring legal action against the particular distribution occurrence. Under English law a claimant has 6 years from the date of breach of contract in which to file particulars of claim with the court.  The R Foundation may well have already been taking action.  Nobody knows other than the R Foundation.  It could take a long time before the R Foundation is able to clarify their position. I see no rush.

Once you had proved each and every point i-iv above, the particular details of such proved precedent would apply, and those only.  So for example, you might be able to end up being allowed to submit an R library to CRAN with a potentially GPL-incompatible license, just like the others you claim set precedent, but that would be all.  As far as I am aware, for a package to be accepted on CRAN it must include all its source code, regardless of its license file.  That may or may not be acceptable to any potential commercial strategy you are proposing.

To labour this point, you appear to claim that precedent has been set that allows you to bundle R along with GPL'd add-on packages along with your own non-GPL'd packages, and distribute such bundle under a non-GPL license, distributed off-CRAN.  You also or alternatively perhaps claim that precedent has been set that allows you to distribute your own proprietary R library 'foreach' and 'iterators' using a non-CRAN distribution mechanism.  Such precedent claims are frankly laughable in my personal opinion.

One reason your potential defence of legal precedent with respect to the R Foundation's potential claim on you, involves me, is that in a future potential dispute with you about a future potential package I might release under GPL, you might claim in your defence that I have created president by not issuing proceedings against you now. Therefore your potential claim of defence with the R Foundation mean that I would be advised to start proceedings against you now, to avert a similar potential claim of defence in the future. This is notwithstanding the fact that such claims of legal precedent in defence of your particular potential breach are laughable anyway.  Then you must consider all other authors of R packages whose packages you intend to bundle, and you have the same difficulty with them.  In short, your claims of precedent in defence of R Foundation potential dispute with you, may potentially create a case for legal costs incurred now by the set of distinct owners of t!
 he apx 1,700 package authors who will require to consult legal advisers as to their positions, as to the best way to avoid compromising their entitlements due to inaction now.  I advise you to act swiftly therefore.

4. Whether or not I felt legally obligated to release data.table under the GPL, because it was or was not derived from the R library "base", or any other point of FSF guidance, is irrelevant to my potential dispute with you regarding data.table. The fact is I released data.table under the GPL.

5. Denise has stated to be a long-time supporter of the FSF and has served on the board of the Open Source Initiative since 2001. In what manner does support of FSF extend?  Holding such affiliations may create a conflict of interest with regard to my potential claim against you. It is feasible, if we are in dispute of course, that my lawyers could at a future date ask Denise to relinquish either the FSF affiliation or employment by you.  I had already communicated with the FSF for example before the email from Denise, so you may be privy to such communication, potentially causing a conflict or interest.

6. On the 22nd April 2009 at 00:30 hours I posted item 4 to the "GPL and ParallelR" thread on the R Evolution Forum. This item has not yet appeared on your Forum. Why is this?  I refer to the post in which I said I was moving the thread to r-devel.

7. The apparent lack of court judgements with regard to the GPL license is not in my opinion a weakness of any potential legal action against you.  On the contrary. The measure of the success of the GPL license, and the FSF's guidance, should in my opinion be the number of disputes that have been avoided due to the GPL license provisions being abided to thus far.  Perhaps reasonable lower and upper bounds could be put on this number, using R of course.

8. Whether or not the GPL is an advantageous strategy for either the R community or REvolution is a matter of debate for everyone involved.  Such debate is however irrelevant to my potential dispute with you.  We must first establish that all parties will abide by the FSF's guidance on GPL.   Once that is established we can move on to discuss re-licensing, or dual-licensing to LGPL. I would again refer you to the FSF's guidance on that also: http://www.fsf.org/licensing/licenses/why-not-lgpl.html.  Whether or not I have the option to license data.table under LGPL may or may not depend on the license of the base package to which data.table in turn links to.   It may be relevant in my potential dispute with you whether or not your packages 'foreach' and 'iterators' link to base,  if you potentially make new claims of precedent in that regard in the future for example.

The opinions and statements in this email are my own, and my own only.   For completeness, I will repeat in public that I support REvolution and have every respect for all your members of staff.  I consider myself a potential source of revenue for you. You must however abide by the provisions of the GPL license.

Yours sincerely,
Matthew


P.S. If you are an interested 3rd party reading the letter above and are now worried about using R due to fear of a potential litigation against you, then the following 2 links should allay your fears.  I am unable to think of anything that could be more clear than this.
http://www.fsf.org/licensing/licenses/gpl-faq.html#InternalDistribution
http://www.fsf.org/licensing/licenses/gpl-faq.html#GPLRequireSourcePostedPublic

P.P.S. There are several nodes in the previous threads that I could respond to individually. It would take too long to do so. I believe I have read everything on the threads (thanks to all) and tried to respond accordingly to any outstanding point above.  For example point 3.iii may help with several points raised.



        [[alternative HTML version deleted]]

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From david at revolution-computing.com  Mon Apr 27 07:45:39 2009
From: david at revolution-computing.com (David M Smith)
Date: Mon, 27 Apr 2009 00:45:39 -0500
Subject: [Rd] About ParallelR and licensing of packages
In-Reply-To: <63F1FB9F17FC464F99E370DAAEC9C6BB@ADAM>
References: <63F1FB9F17FC464F99E370DAAEC9C6BB@ADAM>
Message-ID: <475a3c8f0904262245g6844fe47h6d8f276777511fe8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090427/8008b438/attachment.pl>

From cyrix333 at gmx.net  Mon Apr 27 09:15:14 2009
From: cyrix333 at gmx.net (cyrix333 at gmx.net)
Date: Mon, 27 Apr 2009 09:15:14 +0200 (CEST)
Subject: [Rd] memory.limit returns error (PR#13678)
Message-ID: <20090427071514.75E39282EFF6@mail.pubhealth.ku.dk>

Full_Name: Hans
Version: 2.9.0
OS: Windows
Submission from: (NULL) (91.38.207.23)


Hi,
using memory.limit(4095) in Windows returns an error 
trunc(.Internal(memory.size(size))).

In other R-Versions the funktion worked fine.

Greetings


From statba at nus.edu.sg  Mon Apr 27 10:22:08 2009
From: statba at nus.edu.sg (Berwin A Turlach)
Date: Mon, 27 Apr 2009 16:22:08 +0800
Subject: [Rd] Patch proposal for logspace_sub
Message-ID: <20090427162208.5fd4de83@berwin-nus1>

G'day all,

I am working on problems where I have to calculate the logarithm of a
sum or difference from the logarithms of the individual terms; so the
functions logspace_add and logspace_sub which are part of R's API come
in handy.

However, I noticed that logspace_sub can have problems if both
arguments are (very) small or the difference between the arguments are
vary small.  The logic behind logspace_sup, when called with arguments
lx and ly, is:

log( exp(lx) - exp(ly) ) = log( exp(lx) * ( 1 - exp(ly - lx) ) )
                         = lx + log( 1 - exp(ly - lx) )
                         = lx + log1p( - exp(ly - lx) )
and it is the last expression that is evaluated by logspace_sub.

However the use of log1p for additional precision is appropriate if
exp(ly-lx) is small, i.e. when lx >> ly.  If |ly-lx| << 1, then 
exp(ly-lx) is close to one; if this term becomes numerically one, then
log1p will return -Inf and "large handfuls of accuracy" are thrown
away.  In such circumstances, it would be better to use the following
evaluation scheme:
log( exp(lx) - exp(ly) ) = lx + log( - ( exp(ly - lx) - 1 ) )
                         = lx + log( - expm1(ly-lx) )

The following code, using the equivalent commands and evaluation schemes
at the R level, illustrates my points:

R> lx <- 2e-17
R> ly <- 1e-17
R> lx + log1p(-exp(ly-lx)) ; lx + log(-expm1(ly-lx))
[1] -Inf
[1] -39.1439465808988
R> lx <- 2e-17
R> ly <- 1e-20
R> lx + log1p(-exp(ly-lx)) ; lx + log(-expm1(ly-lx))
[1] -Inf
[1] -38.4512995253805
R> lx <- 1e-16
R> ly <- 1e-20
R> lx + log1p(-exp(ly-lx)) ; lx + log(-expm1(ly-lx))
[1] -36.7368005696771
[1] -36.8414614929051

In all these cases the output from the second evaluation scheme compares
favourably with the output of yacas or bc. 

The current version of R-devel, with this patch applied, passes "make
check FORCE=FORCE" on my machine.  The cut-off point for switching
between the two evaluation schemes was chosen arbitrarily.  

I hope this patch will proof to be useful and will be applied. :)

Cheers,

	Berwin

PS;  If use of the equivalent commands and evaluation schemes at the R
level are not convincing enough, then the following code can be used to
verify that logspace_sub has the same behaviour.  But one would need two
versions of R for to do so, one without the patch and one with it.

R> install.packages("inline") ## if necessary
R> library(inline)
R> sig <- signature(lx="double", ly="double", res="double")
R> code <- "*res = logspace_sub(*lx, *ly);"
R> incl <- "#include <Rmath.h>"
R> fn <- cfunction(sig,code,convention=".C",language="C",includes=incl)
R> lx <- 1e-16
R> ly <- 1e-20
R> fn(lx, ly, res=0)$res
[1] -36.7368005696771

=========================== Full address =============================
Berwin A Turlach                            Tel.: +65 6516 4416 (secr)
Dept of Statistics and Applied Probability        +65 6516 6650 (self)
Faculty of Science                          FAX : +65 6872 3919       
National University of Singapore     
6 Science Drive 2, Blk S16, Level 7          e-mail: statba at nus.edu.sg
Singapore 117546                    http://www.stat.nus.edu.sg/~statba
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: R-patch
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090427/bba56f7d/attachment.pl>

From ligges at statistik.tu-dortmund.de  Mon Apr 27 10:25:23 2009
From: ligges at statistik.tu-dortmund.de (ligges at statistik.tu-dortmund.de)
Date: Mon, 27 Apr 2009 10:25:23 +0200 (CEST)
Subject: [Rd] memory.limit returns error (PR#13678)
Message-ID: <20090427082523.C9E29283218C@mail.pubhealth.ku.dk>



cyrix333 at gmx.net wrote:
> Full_Name: Hans
> Version: 2.9.0
> OS: Windows
> Submission from: (NULL) (91.38.207.23)
> 
> 
> Hi,
> using memory.limit(4095) in Windows returns an error 
> trunc(.Internal(memory.size(size))).
> 
> In other R-Versions the funktion worked fine.


Please read the FAQs about bugs. This one is already fixed. From the svn 
logs:

r48390 | murdoch | 2009-04-24 09:20:41 -0400 (Fri, 24 Apr 2009) | 1 line
Changed paths:
    M /trunk/src/gnuwin32/CHANGES
    M /trunk/src/gnuwin32/extra.c
    M /trunk/src/library/utils/man/windows/memory.size.Rd

Fix spurious error in memory.limit (PR#13673), plus some cleanup of the docs

Best,
Uwe Ligges



> Greetings
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From henrik.parn at bio.ntnu.no  Mon Apr 27 11:12:07 2009
From: henrik.parn at bio.ntnu.no (Henrik Parn)
Date: Mon, 27 Apr 2009 11:12:07 +0200
Subject: [Rd] small typo in "CHANGES IN R VERSION 2.9.0"
Message-ID: <49F576E7.6020406@bio.ntnu.no>

Hi!

In the second sub-heading in this document... 
http://cran.r-project.org/bin/windows/base/CHANGES.R-2.9.0

...INSTALLATION is misspelled (INSTALLATIOM)..


Really no big deal, but anyway.


Cheers,

Henrik


-- 
Henrik P?rn
Centre for Conservation Biology
Department of Biology
Norwegian University of Science and Technology
NO-7491 Trondheim
Norway

Office: +47 73596285
Fax: +47 73596100
Mobile: +47 90989255

E-mail: henrik.parn at bio.ntnu.no


From murdoch at stats.uwo.ca  Mon Apr 27 13:04:53 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 27 Apr 2009 07:04:53 -0400
Subject: [Rd] small typo in "CHANGES IN R VERSION 2.9.0"
In-Reply-To: <49F576E7.6020406@bio.ntnu.no>
References: <49F576E7.6020406@bio.ntnu.no>
Message-ID: <49F59155.2000308@stats.uwo.ca>

On 27/04/2009 5:12 AM, Henrik Parn wrote:
> Hi!
> 
> In the second sub-heading in this document... 
> http://cran.r-project.org/bin/windows/base/CHANGES.R-2.9.0
> 
> ...INSTALLATION is misspelled (INSTALLATIOM)..
> 
> 
> Really no big deal, but anyway.

Thanks, I'll fix it.

Duncan Murdoch


From maechler at stat.math.ethz.ch  Mon Apr 27 16:50:23 2009
From: maechler at stat.math.ethz.ch (maechler at stat.math.ethz.ch)
Date: Mon, 27 Apr 2009 16:50:23 +0200 (CEST)
Subject: [Rd] incorrect output and segfaults from sprintf with %*d
	(PR#13667)
Message-ID: <20090427145023.6D0082832193@mail.pubhealth.ku.dk>

>>>>> "vQ" == Waclaw Marcin Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no>
>>>>>     on Sat, 25 Apr 2009 19:40:27 +0200 (CEST) writes:

    vQ> Martin Maechler wrote:
    >> 
    MM> well, it is basically (+ a few bytes ?)  the same 8192
    MM> limit that *is* documented.
    >>>> 
    >>>> indeed, I was right with that..
    >>>> 
    >>>> 
    >>> hmm, i'd guess this limit is valid for all strings
    >>> included in the output with any format?  not just %s
    >>> (and, as it appears, undocumentedly %d)?
    >>> 
    >> 


    >>> btw. (i do know what that means ;)), after your recent
    >>> fix:
    >>> 
    >>> sprintf('%q%s', 1) # Error in sprintf("%q%s", 1) : # use
    >>> format %f, %e, %g or %a for numeric objects
    >>> 
    >>> sprintf('%s', 1) # [1] "1"
    >>> 
    >>> you may want to add '%s' (and '%x', and ...) to the
    >>> error message.  or perhaps make it say sth like 'invalid
    >>> format: ...'.  the problem is not that %q is not
    >>> applicable to numeric, but that it is not a valid format
    >>> at all.
    >>> 
    >> 
> yes.  As a matter of fact, "%q%s" is dealt with as *one*
    >> format chunk, since "%q" is not a valid format.  The code
    >> I have just committed now gives a longer erro message,
    >> that should be more helpful.
    >> 

    vQ> yes, but

    vQ>     sptinf('%q%s', 1)


    vQ> still suggests that one uses %{f,e,g,a} for numerics,
    vQ> while %s is pretty much valid, too.  you see, in c
    vQ> sprintf(buffer, "%s", 1) is destined to cause a
    vQ> segfault, but in r it works -- so the error message is
    vQ> slightly misleading, as it suggests %s is *not* valid
    vQ> for numerics.

yes, but only the error message somewhat suggests that;
at the moment, I'd like to keep it, since really the user
*should* think of using the number formats, rather than %s
{which just calls  as.character(.)}  for numeric arguments


    >> Thank you for the suggestion!
    >> 

  vQ> yo welcum

    >> 
    >>> there's also an issue with the additional arguments
    >>> supplied after the format: any superfluous arguments are
    >>> ignored (this is not documented, as far as i can see),
    >>> 
    >> 

  MM> I think we should signal an error if there are too many arguments.

  vQ> agree.  but it might be more complex than it appears:

    vQ>     sprintf('%3$s', 1, 2, 3)

    vQ> should *not* complain about too many args, despite just
    vQ> one conversion spec in the format.  

very good point; thanks!

    vQ> Interestingly,

    vQ>     sprintf('%3$s', , , 3) # error: argument is missing,
    vQ> with no default

yes, empty (aka "missing") arguments are not allowed in  sprintf().

    >> Could anyone think of a case where the current behavior
    >> is desirable ?
    >> 

    vQ> well, one scenario might be that one wants to print a collection of
    vQ> items with an arbitrary format, supplied by the users,
    vQ> e.g.

    vQ>     foo = function(fmt) { a = ...  b = ...  ...  s =
    vQ> sprintf(fmt, a, b, ...)  ... }

    vQ> without having to examine the format to establish which
    vQ> values are needed.  in the current state, sprintf would
    vQ> use those it would need to use with a particular format,
    vQ> with no undesirable complaints.

ok. you have given good examples which make me revert my
proposal, i.e. continue to not erroring about "too many" arguments. 

    >>> but they *are* evaluated nevertheless, e.g.:
    >>> 
    >>> sprintf('%d', 0, {print(1)}) # "1" # [1] "0"
    >>> 
    >>> it might be a good idea to document this behaviour.

   MM> actually I think it should be changed to be more strict
   MM> (see above).

as a matter of fact, and the result of many more examples,
I've changed my oppinion and now agree with your original
proposal:

I've just commmited another sprintf() patch which (among more
more important changes) *documents* that all arguments of
sprintf() are evaluated; this actually already entails that
empty / missing arguments are not allowed.

    vq> strict in which sense?  enforce a constraint on the
    vQ> number of arguments to that needed by a specific format?
    vQ> or do you mean evaluation of only those arguments that
    vQ> are needed in a format?  or both?

    vQ> what about:

    vQ>     sprintf('%2$s', {print(1)}, 2) # too many arguments?
    vQ> # should 1 be printed?

    vQ>     sprintf('%2$s', , 2) # too few arguments?  # missing
    vQ> value?  (yes, sprintf is .Internal, but...)


    >> Thank you for the constructive feedback!
    >> 

    vQ> not much to thank for...  certainly, it's the first time my feedback is
    vQ> called 'constructive'.  i'm making progress, am i not?

indeed!  :-)

Martin Maechler, ETH Zurich

    vQ> btw., thank you for the fixes.  i appreciate your
    vQ> efforts a lot.

    vQ> best, vQ


From ggrothendieck at gmail.com  Mon Apr 27 17:05:33 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 27 Apr 2009 11:05:33 -0400
Subject: [Rd] incorrect output and segfaults from sprintf with %*d
	(PR#13667)
In-Reply-To: <20090424104524.DFA4F283432B@mail.pubhealth.ku.dk>
References: <20090424104524.DFA4F283432B@mail.pubhealth.ku.dk>
Message-ID: <971536df0904270805s22bb72a9xce5f17ec8f13f20e@mail.gmail.com>

On Fri, Apr 24, 2009 at 6:45 AM,  <maechler at stat.math.ethz.ch> wrote:
>
> Yes, the documentation will also have to be amended, but apart
> from that, would people see a big problem with the "8192" limit
> which now is suddenly of greater importance
> {{as I said all along; ?hence my question to Wacek (and the
> ?R-develers) ?if anybody found that limit too low}}

I haven't been following all this but in working with strings for
the gsubfn package my own usage of the package was primarily
for small strings but then I discovered that others wanted to use
it for much larger strings of 25,000 characters, say, and it was
necessary to raise the limits (and there are also performance
implications which could be addressed too). I don't know what
the situation is particularly here but cases where
very large strings can be used include linguistic analysis and
computer generated R code.


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Mon Apr 27 21:15:27 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Waclaw.Marcin.Kusnierczyk at idi.ntnu.no)
Date: Mon, 27 Apr 2009 21:15:27 +0200 (CEST)
Subject: [Rd] incorrect output and segfaults from sprintf with %*d
	(PR#13667)
Message-ID: <20090427191527.77109282BE84@mail.pubhealth.ku.dk>

Martin Maechler wrote:
>
>     vQ>     sptinf('%q%s', 1)
>
>
>     vQ> still suggests that one uses %{f,e,g,a} for numerics,
>     vQ> while %s is pretty much valid, too.  you see, in c
>     vQ> sprintf(buffer, "%s", 1) is destined to cause a
>     vQ> segfault, but in r it works -- so the error message is
>     vQ> slightly misleading, as it suggests %s is *not* valid
>     vQ> for numerics.
>
> yes, but only the error message somewhat suggests that;
> at the moment, I'd like to keep it, since really the user
> *should* think of using the number formats, rather than %s
> {which just calls  as.character(.)}  for numeric arguments
>   

then maybe sprintf('%s', 1) should complain about a format-argument
mismatch?  in c, 1 would be taken to be an address at which a string
starts, but in r you do not have pointers, so this interpretation is
impossible.  if the user *should* use number formats for numerics, %s
should not work.  smells lack of design.


>   MM> I think we should signal an error if there are too many arguments.
>
>   vQ> agree.  but it might be more complex than it appears:
>
>     vQ>     sprintf('%3$s', 1, 2, 3)
>
>     vQ> should *not* complain about too many args, despite just
>     vQ> one conversion spec in the format.  
>
> very good point; thanks!
>
>     vQ> Interestingly,
>
>     vQ>     sprintf('%3$s', , , 3) # error: argument is missing,
>     vQ> with no default
>
> yes, empty (aka "missing") arguments are not allowed in  sprintf().
>   

be nice and document such items, pliz....  even if all internal
functions have this behavour (do they?), ?sprintf does not say that
sprintf is internal, or that the r wrapper calls an internal so that all
arguments are necessarily evaluated.

>     >> Could anyone think of a case where the current behavior
>     >> is desirable ?
>     >> 
>
>     vQ> well, one scenario might be that one wants to print a collection of
>     vQ> items with an arbitrary format, supplied by the users,
>     vQ> e.g.
>
>     vQ>     foo = function(fmt) { a = ...  b = ...  ...  s =
>     vQ> sprintf(fmt, a, b, ...)  ... }
>
>     vQ> without having to examine the format to establish which
>     vQ> values are needed.  in the current state, sprintf would
>     vQ> use those it would need to use with a particular format,
>     vQ> with no undesirable complaints.
>
> ok. you have given good examples which make me revert my
> proposal, i.e. continue to not erroring about "too many" arguments. 
>   

i did not say i supported that view, however.  it was just an example
where *a* developer might wish sprintf did not complain about wrong
number of arguments.  examples to the opposite effect can easily be
given, but that's not what you asked about.


>     >>> but they *are* evaluated nevertheless, e.g.:
>     >>> 
>     >>> sprintf('%d', 0, {print(1)}) # "1" # [1] "0"
>     >>> 
>     >>> it might be a good idea to document this behaviour.
>
>    MM> actually I think it should be changed to be more strict
>    MM> (see above).
>
> as a matter of fact, and the result of many more examples,
> I've changed my oppinion and now agree with your original
> proposal:
>
> I've just commmited another sprintf() patch which (among more
> more important changes) *documents* that all arguments of
> sprintf() are evaluated; this actually already entails that
> empty / missing arguments are not allowed.
>   

excellent, thanks.

vQ


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Mon Apr 27 21:25:06 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Mon, 27 Apr 2009 21:25:06 +0200
Subject: [Rd] incorrect output and segfaults from sprintf with
	%*d	(PR#13667)
In-Reply-To: <971536df0904270805s22bb72a9xce5f17ec8f13f20e@mail.gmail.com>
References: <20090424104524.DFA4F283432B@mail.pubhealth.ku.dk>
	<971536df0904270805s22bb72a9xce5f17ec8f13f20e@mail.gmail.com>
Message-ID: <49F60692.1080400@idi.ntnu.no>

Gabor Grothendieck wrote:
> On Fri, Apr 24, 2009 at 6:45 AM,  <maechler at stat.math.ethz.ch> wrote:
>   
>> Yes, the documentation will also have to be amended, but apart
>> from that, would people see a big problem with the "8192" limit
>> which now is suddenly of greater importance
>> {{as I said all along;  hence my question to Wacek (and the
>>  R-develers)  if anybody found that limit too low}}
>>     
>
> I haven't been following all this but in working with strings for
> the gsubfn package my own usage of the package was primarily
> for small strings but then I discovered that others wanted to use
> it for much larger strings of 25,000 characters, say, and it was
> necessary to raise the limits (and there are also performance
> implications which could be addressed too). I don't know what
> the situation is particularly here but cases where
> very large strings can be used include linguistic analysis and
> computer generated R code.
>   

in principle, instead of the quite arbitrary and not justified constant
size limit 8192 [1], one could use dynamic arrays.  this would allow
strings of arbitrary length without adding much performance penalty for
strings shorter than 8193 bytes.

[1] src/include/Defn.h:60


From rksh1 at cam.ac.uk  Tue Apr 28 09:06:12 2009
From: rksh1 at cam.ac.uk (Robin Hankin)
Date: Tue, 28 Apr 2009 08:06:12 +0100
Subject: [Rd] vignettes in a bundle
Message-ID: <49F6AAE4.4020305@cam.ac.uk>

Hi

I have a bundle comprising three packages.

Each package has a vignette.  Currently each
vignette has a separate .bib file.

How do I arrange the bundle so that each
vignette accesses a single, common, .bib file?


thanks

Robin

-- 
Robin K. S. Hankin
Uncertainty Analyst
University of Cambridge
19 Silver Street
Cambridge CB3 9EP
01223-764877


From romain.francois at dbmail.com  Tue Apr 28 09:19:34 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Tue, 28 Apr 2009 09:19:34 +0200
Subject: [Rd] vignettes in a bundle
In-Reply-To: <49F6AAE4.4020305@cam.ac.uk>
References: <49F6AAE4.4020305@cam.ac.uk>
Message-ID: <49F6AE06.2090608@dbmail.com>

Hi Robin,

Something like:

<<echo=FALSE>>=
bib <- system.file( "bib", "mybib.bib", package = "yada" )
cat( "\\bibliography{",bib,"}\n")
@

It would also be nice to be able to use bibliography in Rd files ...

Romain

Robin Hankin wrote:
> Hi
>
> I have a bundle comprising three packages.
>
> Each package has a vignette.  Currently each
> vignette has a separate .bib file.
>
> How do I arrange the bundle so that each
> vignette accesses a single, common, .bib file?
>
>
> thanks
>
> Robin
>


-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From maechler at stat.math.ethz.ch  Tue Apr 28 09:50:21 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 28 Apr 2009 09:50:21 +0200
Subject: [Rd] incorrect output and segfaults from sprintf with %*d
	(PR#13667)
In-Reply-To: <49F60692.1080400@idi.ntnu.no>
References: <20090424104524.DFA4F283432B@mail.pubhealth.ku.dk>
	<971536df0904270805s22bb72a9xce5f17ec8f13f20e@mail.gmail.com>
	<49F60692.1080400@idi.ntnu.no>
Message-ID: <18934.46397.747957.757000@lynne.math.ethz.ch>

>>>>> "vQ" == Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no>
>>>>>     on Mon, 27 Apr 2009 21:25:06 +0200 writes:

    vQ> Gabor Grothendieck wrote:
    >> On Fri, Apr 24, 2009 at 6:45 AM,
    >> <maechler at stat.math.ethz.ch> wrote:
    >> 
    >>> Yes, the documentation will also have to be amended, but
    >>> apart from that, would people see a big problem with the
    >>> "8192" limit which now is suddenly of greater importance
    >>> {{as I said all along; hence my question to Wacek (and
    >>> the R-develers) if anybody found that limit too low}}
    >>> 
    >> 
> I haven't been following all this but in working with strings
    >> for the gsubfn package my own usage of the package was
    >> primarily for small strings but then I discovered that
    >> others wanted to use it for much larger strings of 25,000
    >> characters, say, and it was necessary to raise the limits
    >> (and there are also performance implications which could
    >> be addressed too). I don't know what the situation is
    >> particularly here but cases where very large strings can
    >> be used include linguistic analysis and computer
    >> generated R code.
    >> 

    vQ> in principle, instead of the quite arbitrary and not
    vQ> justified constant vQ> size limit 8192 [1], one could
    vQ> use dynamic arrays.  this would allow strings of
    vQ> arbitrary length without adding much performance penalty
    vQ> for strings shorter than 8193 bytes.

    vQ> [1] src/include/Defn.h:60

Yes, in principle that would be clearly better.
well-tested ('make check-all') patches are welcome!

Martin


From rksh1 at cam.ac.uk  Tue Apr 28 10:32:08 2009
From: rksh1 at cam.ac.uk (Robin Hankin)
Date: Tue, 28 Apr 2009 09:32:08 +0100
Subject: [Rd] vignettes in a bundle
In-Reply-To: <49F6AE06.2090608@dbmail.com>
References: <49F6AAE4.4020305@cam.ac.uk> <49F6AE06.2090608@dbmail.com>
Message-ID: <49F6BF08.7060800@cam.ac.uk>

Hello Romain

this is brilliant; it never occurred to me to use cat() in this way.

It works but I don't know why.

With:

<<echo=FALSE>>=
bib <- system.file( "doc", "bayesian.bib", package = "emulator" )
cat( "\\bibliography{",bib,"}\n",sep='')
@

in the Rnw file, the TeX file looks like this:

\begin{Schunk}
\begin{Soutput}
\bibliography{/usr/local/lib/R/library/emulator/doc/bayesian.bib}
\end{Soutput}
\end{Schunk}


So, my question is: why does TeX parse the  middle line? why isn't this
line interpreted as regular Soutput?

best wishes and thanks again

Robin



Romain Francois wrote:
> Hi Robin,
>
> Something like:
>
> <<echo=FALSE>>=
> bib <- system.file( "bib", "mybib.bib", package = "yada" )
> cat( "\\bibliography{",bib,"}\n")
> @
>
> It would also be nice to be able to use bibliography in Rd files ...
>
> Romain
>
> Robin Hankin wrote:
>> Hi
>>
>> I have a bundle comprising three packages.
>>
>> Each package has a vignette.  Currently each
>> vignette has a separate .bib file.
>>
>> How do I arrange the bundle so that each
>> vignette accesses a single, common, .bib file?
>>
>>
>> thanks
>>
>> Robin
>>
>
>


-- 
Robin K. S. Hankin
Uncertainty Analyst
University of Cambridge
19 Silver Street
Cambridge CB3 9EP
01223-764877


From romain.francois at dbmail.com  Tue Apr 28 12:45:23 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Tue, 28 Apr 2009 12:45:23 +0200
Subject: [Rd] vignettes in a bundle
In-Reply-To: <49F6BF08.7060800@cam.ac.uk>
References: <49F6AAE4.4020305@cam.ac.uk> <49F6AE06.2090608@dbmail.com>
	<49F6BF08.7060800@cam.ac.uk>
Message-ID: <49F6DE43.6090704@dbmail.com>

Would this work better:

<<echo=FALSE,results=tex>>=
bib <- system.file( "doc", "bayesian.bib", package = "emulator" )
cat( "\\bibliography{",bib,"}\n",sep='')
@

Romain

Robin Hankin wrote:
> Hello Romain
>
> this is brilliant; it never occurred to me to use cat() in this way.
>
> It works but I don't know why.
>
> With:
>
> <<echo=FALSE>>=
> bib <- system.file( "doc", "bayesian.bib", package = "emulator" )
> cat( "\\bibliography{",bib,"}\n",sep='')
> @
>
> in the Rnw file, the TeX file looks like this:
>
> \begin{Schunk}
> \begin{Soutput}
> \bibliography{/usr/local/lib/R/library/emulator/doc/bayesian.bib}
> \end{Soutput}
> \end{Schunk}
>
>
> So, my question is: why does TeX parse the  middle line? why isn't this
> line interpreted as regular Soutput?
>
> best wishes and thanks again
>
> Robin
>
>
>
> Romain Francois wrote:
>> Hi Robin,
>>
>> Something like:
>>
>> <<echo=FALSE>>=
>> bib <- system.file( "bib", "mybib.bib", package = "yada" )
>> cat( "\\bibliography{",bib,"}\n")
>> @
>>
>> It would also be nice to be able to use bibliography in Rd files ...
>>
>> Romain
>>
>> Robin Hankin wrote:
>>> Hi
>>>
>>> I have a bundle comprising three packages.
>>>
>>> Each package has a vignette.  Currently each
>>> vignette has a separate .bib file.
>>>
>>> How do I arrange the bundle so that each
>>> vignette accesses a single, common, .bib file?
>>>
>>>
>>> thanks
>>>
>>> Robin
>>>
>>
>>
>
>


-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From rksh1 at cam.ac.uk  Tue Apr 28 13:30:31 2009
From: rksh1 at cam.ac.uk (Robin Hankin)
Date: Tue, 28 Apr 2009 12:30:31 +0100
Subject: [Rd] vignettes in a bundle
In-Reply-To: <49F6DE43.6090704@dbmail.com>
References: <49F6AAE4.4020305@cam.ac.uk> <49F6AE06.2090608@dbmail.com>
	<49F6BF08.7060800@cam.ac.uk> <49F6DE43.6090704@dbmail.com>
Message-ID: <49F6E8D7.4030904@cam.ac.uk>

Romain Francois wrote:
> Would this work better:
>
> <<echo=FALSE,results=tex>>=
> bib <- system.file( "doc", "bayesian.bib", package = "emulator" )
> cat( "\\bibliography{",bib,"}\n",sep='')
> @
>
> Romain

Yes, this gives cleaner TeX output (I keep on forgetting about Sweave's
'result' code chunk option).

But I still don't understand why your first suggestion worked.
How does TeX 'know' that this is not to be included verbatim?

best wishes and thanks again

Robin

>
> Robin Hankin wrote:
>> Hello Romain
>>
>> this is brilliant; it never occurred to me to use cat() in this way.
>>
>> It works but I don't know why.
>>
>> With:
>>
>> <<echo=FALSE>>=
>> bib <- system.file( "doc", "bayesian.bib", package = "emulator" )
>> cat( "\\bibliography{",bib,"}\n",sep='')
>> @
>>
>> in the Rnw file, the TeX file looks like this:
>>
>> \begin{Schunk}
>> \begin{Soutput}
>> \bibliography{/usr/local/lib/R/library/emulator/doc/bayesian.bib}
>> \end{Soutput}
>> \end{Schunk}
>>
>>
>> So, my question is: why does TeX parse the  middle line? why isn't this
>> line interpreted as regular Soutput?
>>
>> best wishes and thanks again
>>
>> Robin
>>
>>
>>
>> Romain Francois wrote:
>>> Hi Robin,
>>>
>>> Something like:
>>>
>>> <<echo=FALSE>>=
>>> bib <- system.file( "bib", "mybib.bib", package = "yada" )
>>> cat( "\\bibliography{",bib,"}\n")
>>> @
>>>
>>> It would also be nice to be able to use bibliography in Rd files ...
>>>
>>> Romain
>>>
>>> Robin Hankin wrote:
>>>> Hi
>>>>
>>>> I have a bundle comprising three packages.
>>>>
>>>> Each package has a vignette.  Currently each
>>>> vignette has a separate .bib file.
>>>>
>>>> How do I arrange the bundle so that each
>>>> vignette accesses a single, common, .bib file?
>>>>
>>>>
>>>> thanks
>>>>
>>>> Robin
>>>>
>>>
>>>
>>
>>
>
>


-- 
Robin K. S. Hankin
Uncertainty Analyst
University of Cambridge
19 Silver Street
Cambridge CB3 9EP
01223-764877


From maechler at stat.math.ethz.ch  Wed Apr 29 11:20:22 2009
From: maechler at stat.math.ethz.ch (maechler at stat.math.ethz.ch)
Date: Wed, 29 Apr 2009 11:20:22 +0200 (CEST)
Subject: [Rd] printCoefmat() with all-zero first column (PR#13677)
Message-ID: <20090429092022.820CB282EFF0@mail.pubhealth.ku.dk>


>>>>> "TL" == Thomas Lumley <tlumley at u.washington.edu>
>>>>>     on Sat, 25 Apr 2009 19:00:14 +0200 (CEST) writes:

    >> m<-matrix(c(0,1),ncol=2)
    >> printCoefmat(m)
    TL> [,1] [,2]
    TL> [1,]  NaN    1
    TL> Warning messages:
    TL> 1: In min(x) : no non-missing arguments to min; returning Inf
    TL> 2: In max(x) : no non-missing arguments to max; returning -Inf
    TL> 3: In log(c(Inf, -Inf), 10) : NaNs produced

Thank you, Thomas.
This is now fixed in R 2.9.0 patched (rev.48431) and R-devel.

Martin

    >> sessionInfo()
    TL> R version 2.9.0 beta (2009-04-08 r48309)
    TL> i386-apple-darwin9.6.0

    TL> locale:
    TL> en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8

    TL> attached base packages:
    TL> [1] stats     graphics  grDevices utils     datasets  methods   base


    TL> Thomas Lumley			Assoc. Professor, Biostatistics
    TL> tlumley at u.washington.edu	University of Washington, Seattle


From atossava at cc.helsinki.fi  Wed Apr 29 11:55:44 2009
From: atossava at cc.helsinki.fi (Atro Tossavainen)
Date: Wed, 29 Apr 2009 12:55:44 +0300 (EEST)
Subject: [Rd] Problems building R 2.9.0... on SGI and Sun once again
Message-ID: <200904290955.n3T9ti6H016943@ruuvi.it.helsinki.fi>

(This is really in response to Peter Dalgaard, not to myself)

> This seems to come from constructions of the form
> 
> for i in $FOO : do .... ; done
> 
> If $FOO is empty, then the resulting "for i in ;" is a syntax error
> with some versions of bash and sh.

Given that one should generally be writing scripts for the Bourne
shell, it is IMHO the case that "for i in ;" is a syntax error, period.

> Current Linux versions of bash do not have that behaviour.

...violating Bourne shell compatibility in yet another way...

> One workaround could be to upgrade bash.

If R is to be an application that is not specific to (recent distributions
of) Linux, one should expect and code for systems that may not have bash
at all but only the Bourne shell.

> Another workaround could be to safeguard the for-loop with
> 
> test "$FOO" != "" && for i in $FOO : do .... ; done
> 
> in all of the Makefiles where this can be an issue.

That is one of the possible ways in which R developers could, I
suppose, address the issue.

-- 
Atro Tossavainen (Mr.)               / The Institute of Biotechnology at
Systems Analyst, Techno-Amish &     / the University of Helsinki, Finland,
+358-9-19158939  UNIX Dinosaur     / employs me, but my opinions are my own.
< URL : http : / / www . helsinki . fi / %7E atossava / > NO FILE ATTACHMENTS


From Roger.Bivand at nhh.no  Wed Apr 29 13:54:04 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 29 Apr 2009 04:54:04 -0700 (PDT)
Subject: [Rd] Some extensions to class inheritance and method selection
In-Reply-To: <49F4BCE3.5040704@r-project.org>
References: <49F4BCE3.5040704@r-project.org>
Message-ID: <23295792.post@talk.nabble.com>


In released 2.9.0, we have been seeing warnings when installing sp, for
example:

Warning in .checkS3forClass(ClassDef at className, where, names(exts)) :
  Some of the superclasses in the definition of class "SpatialPoints" have
apparent S3 methods.

DANGER: the new class will not inherit these methods.
Complain to the author of the superclass definitions.

The apparent methods are  "plot.Spatial", "summary.Spatial"

Running R CMD check sp (or installing from CRAN) on 2.10.0 (2009-04-29
r48433) does not generate any such warnings. For us, it would be helpful if
the extensions could be patched into 2.9.1 (although no user has complained,
curiously enough).

Roger



John Chambers-2 wrote:
> 
> Changes were committed today to the r-devel version of R to make S4 and 
> S3 classes (and abnormal object types such as "environment") work 
> together more consistently.
> 
> Basically, S4 classes can now contain any S3 class or object type, and 
> should now inherit S3 methods for these.  Also, the main practical 
> problem with defining S3 methods for other S4 classes (namely, that S4 
> inheritance was not recognized) has been fixed, to the extent possible.
> 
> See ?Methods (especially the section on S3 methods).  For details (there 
> are quite a few) see the paper referenced there,
>   http://stat.stanford.edu/~jmc4/classInheritance.pdf
> 
> Since these changes arguably fix design flaws, I would like to see them 
> in 2.9.1, so please test them out.  For the moment, they are only in the 
> r-devel version.
> 
> There can be changes to current behavior.  For example, I found one 
> regression test for S4 methods that only worked because an apparent S3 
> method, sort.list, was NOT inherited by an S4 class that contained "list".
> 
> John
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
View this message in context: http://www.nabble.com/Some-extensions-to-class-inheritance-and-method-selection-tp23245983p23295792.html
Sent from the R devel mailing list archive at Nabble.com.


From simon.urbanek at r-project.org  Wed Apr 29 15:36:52 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 29 Apr 2009 09:36:52 -0400
Subject: [Rd] Problems building R 2.9.0... on SGI and Sun once again
In-Reply-To: <200904290955.n3T9ti6H016943@ruuvi.it.helsinki.fi>
References: <200904290955.n3T9ti6H016943@ruuvi.it.helsinki.fi>
Message-ID: <F4F64C57-A1FF-4EE0-9DAE-8C233B49BC7B@r-project.org>


On Apr 29, 2009, at 5:55 , Atro Tossavainen wrote:

> (This is really in response to Peter Dalgaard, not to myself)
>
>> This seems to come from constructions of the form
>>
>> for i in $FOO : do .... ; done
>>
>> If $FOO is empty, then the resulting "for i in ;" is a syntax error
>> with some versions of bash and sh.
>
> Given that one should generally be writing scripts for the Bourne
> shell, it is IMHO the case that "for i in ;" is a syntax error,  
> period.
>
>> Current Linux versions of bash do not have that behaviour.
>
> ...violating Bourne shell compatibility in yet another way...
>
>> One workaround could be to upgrade bash.
>
> If R is to be an application that is not specific to (recent  
> distributions
> of) Linux, one should expect and code for systems that may not have  
> bash
> at all but only the Bourne shell.
>
>> Another workaround could be to safeguard the for-loop with
>>
>> test "$FOO" != "" && for i in $FOO : do .... ; done
>>
>> in all of the Makefiles where this can be an issue.
>
> That is one of the possible ways in which R developers could, I
> suppose, address the issue.
>

You could check, I suppose, that it has been addressed in a similar  
way ;).

Cheers,
Simon


From mxkuhn at gmail.com  Wed Apr 29 16:24:53 2009
From: mxkuhn at gmail.com (Max Kuhn)
Date: Wed, 29 Apr 2009 10:24:53 -0400
Subject: [Rd] link to latest package announcements
Message-ID: <6731304c0904290724w5e15687fm889d7f6e74018176@mail.gmail.com>

I wasn't sure where to send this...

On the "What's New" section of the homepage, the "Latest" package link
points towards

   https://stat.ethz.ch/pipermail/r-packages/2008/date.html#end

It should probably point towards 2009.

Thanks,

Max


From macrakis at alum.mit.edu  Wed Apr 29 16:29:38 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Wed, 29 Apr 2009 10:29:38 -0400
Subject: [Rd] Some extensions to class inheritance and method selection
In-Reply-To: <49F4BCE3.5040704@r-project.org>
References: <49F4BCE3.5040704@r-project.org>
Message-ID: <8b356f880904290729w5ee331bfi858ae32b540d7f81@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090429/a9186512/attachment.pl>

From friedrich.leisch at stat.uni-muenchen.de  Wed Apr 29 17:03:12 2009
From: friedrich.leisch at stat.uni-muenchen.de (Friedrich Leisch)
Date: Wed, 29 Apr 2009 17:03:12 +0200
Subject: [Rd] link to latest package announcements
In-Reply-To: <6731304c0904290724w5e15687fm889d7f6e74018176@mail.gmail.com>
References: <6731304c0904290724w5e15687fm889d7f6e74018176@mail.gmail.com>
Message-ID: <18936.27696.685143.881517@lxh5.stat.uni-muenchen.de>

>>>>> On Wed, 29 Apr 2009 10:24:53 -0400,
>>>>> Max Kuhn (MK) wrote:

  > I wasn't sure where to send this...
  > On the "What's New" section of the homepage, the "Latest" package link
  > points towards

  >    https://stat.ethz.ch/pipermail/r-packages/2008/date.html#end

  > It should probably point towards 2009.

Thanks for spotting this, submitted bugfix to SVN (will automatically
go live in an hour or so).

Best,
Fritz


From jmc at r-project.org  Wed Apr 29 18:58:08 2009
From: jmc at r-project.org (John Chambers)
Date: Wed, 29 Apr 2009 09:58:08 -0700
Subject: [Rd] Some extensions to class inheritance and method selection
In-Reply-To: <23295792.post@talk.nabble.com>
References: <49F4BCE3.5040704@r-project.org> <23295792.post@talk.nabble.com>
Message-ID: <49F88720.3030104@r-project.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090429/4d5593cc/attachment.pl>

From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Wed Apr 29 19:57:49 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Wed, 29 Apr 2009 19:57:49 +0200
Subject: [Rd] Some extensions to class inheritance and method selection
In-Reply-To: <8b356f880904290729w5ee331bfi858ae32b540d7f81@mail.gmail.com>
References: <49F4BCE3.5040704@r-project.org>
	<8b356f880904290729w5ee331bfi858ae32b540d7f81@mail.gmail.com>
Message-ID: <49F8951D.90407@idi.ntnu.no>

Stavros Macrakis wrote:
> These look like important improvements.  As a relative newcomer to the R
> community, I'm not sure I understand what the procedures are for such
> changes.
>
> In particular, does the fact that the changes were committed to R-devel mean
> that the changes have already been reviewed and approved by R Core?  Are R
> Core's discussions / deliberations archived somewhere? What is the role of
> the larger R community in reviewing and approving changes like this?
>
> How is documentation handled? Who is responsible for developing and
> maintaining a definitive reference manual (not just man pages) which
> includes all the cumulative changes and describes them comprehensively and
> in black-box way (not referring to history and implementation details)?
>   

as another newcommer, i admit the procedures mentioned above are quite
opaque to me, too.  from my perspective, it seems like quite many, if
not most, improvements (changes, at least) to r code are committed in an
ad hoc fashion, by a single developer, without any publicly visible
discussion.  this is likely to lead, and in certain circumstances does
lead, to bizarre, eclectic patches visible in the sources. 

it would be indeed interesting and desirable to make the process more
open, at least for review, by users.  or is r not *that* open?

vQ


From bef at northwestern.edu  Thu Apr 30 03:55:12 2009
From: bef at northwestern.edu (bef at northwestern.edu)
Date: Thu, 30 Apr 2009 03:55:12 +0200 (CEST)
Subject: [Rd] Linux Huge R/lib64/R/doc/html/search/index.txt (PR#13683)
Message-ID: <20090430015512.407F728321AF@mail.pubhealth.ku.dk>

Full_Name: Bruce Foster
Version: 2.9.0
OS: Red Hat Linux 5.3
Submission from: (NULL) (129.105.110.38)


The R/lib64/R/doc/html/search/index.txt file for R2.9.0 is much too large and
contains multiple copies of its entries. In comparison with R 2.8.0:

[root at seldon search]# pwd
/sscc/opt/R-2.8.0/lib64/R/doc/html/search

[root at seldon search]# ll index.txt 
-rw-r--r-- 1 root root 4496494 Nov 11 16:39 index.txt

[root at seldon search]# grep "^Entry: abind" index.txt | wc -l
1

[root at mule2 search]# pwd
/sscc/opt/R-2.9.0/lib64/R/doc/html/search

[root at mule2 search]# ll index.txt
-rw-r--r-- 1 root root 1858821960 Apr 28 21:31 index.txt

[root at mule2 search]# grep "^Entry: abind" index.txt | wc -l
732

There are 732 copies of the abind entry in 2.9.0! 

The two installations are comparable, in that they are standard builds of R with
the addition of 18 overlapping task views, which were individually installed
with the command update.views("viewname").

1. The index is too large to work with the web search engine. All searches
fail.
2. Can I rebuild this index file somehow to eliminate multiple entries?

Thanks!
Bruce


From nhepburn at ualberta.ca  Tue Apr 28 19:25:15 2009
From: nhepburn at ualberta.ca (nhepburn at ualberta.ca)
Date: Tue, 28 Apr 2009 19:25:15 +0200 (CEST)
Subject: [Rd] crash after using graphics in Rcmdr (PR#13679)
Message-ID: <20090428172515.2E4E928321A2@mail.pubhealth.ku.dk>

Full_Name: Neil Hepburn
Version: 2.81 and 2.90
OS: OS-X 10.5.6
Submission from: (NULL) (142.244.28.93)


When I create graphs using Rcmdr and then close the quartz display, R blows up
and tells me of a segmentation fault. It then gives me
 *** caught segfault ***
address 0xc0000023, cause 'memory not mapped'

Possible actions:
1: abort (with core dump, if enabled)
2: normal R exit
3: exit R without saving workspace
4: exit R saving workspace
> 
Selection: 

This only happens if I create the graphics from within Rcmdr. If I create the
graphics manually, there is no problem. This occurs on my laptop with R 2.8.1 (I
uninstalled 2.9 and reinstall 2.8.1 to see if the problem existed there) and
also on my iMac with R2.9.


From jfox at mcmaster.ca  Thu Apr 30 15:29:33 2009
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 30 Apr 2009 09:29:33 -0400
Subject: [Rd] crash after using graphics in Rcmdr (PR#13679)
In-Reply-To: <20090428172515.2E4E928321A2@mail.pubhealth.ku.dk>
References: <20090428172515.2E4E928321A2@mail.pubhealth.ku.dk>
Message-ID: <003501c9c997$b32cc470$19864d50$@ca>

Dear Neil,

I had R 2.8.0 installed on my Mac Book, also with OS X 10.5.6, and was
unable to duplicate this problem. I then installed R 2.9.0 and observed the
same problem that you did. In both cases, I used the latest version of the
Rcmdr package, 1.4-10. 

I also observed the following: (1) The problem occurred only if I closed the
Quartz graphics device after the first graph was plotted; if I plotted
another graph and then closed the device, the problem did not occur. (2) The
problem did not occur if I ran R from a terminal with an X11 graphics device
rather than using R.app.

I'm afraid that there's not much more that I can do at this point, since my
familiarity with Macs is minimal. I'm copying this message to Rob Goedman,
who has proven helpful in the past. Of course, if there's something in the
Rcmdr that's causing the problem and I can fix it, I will.

Regards,
 John


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
On
> Behalf Of nhepburn at ualberta.ca
> Sent: April-28-09 1:25 PM
> To: r-devel at stat.math.ethz.ch
> Cc: R-bugs at r-project.org
> Subject: [Rd] crash after using graphics in Rcmdr (PR#13679)
> 
> Full_Name: Neil Hepburn
> Version: 2.81 and 2.90
> OS: OS-X 10.5.6
> Submission from: (NULL) (142.244.28.93)
> 
> 
> When I create graphs using Rcmdr and then close the quartz display, R
blows
> up
> and tells me of a segmentation fault. It then gives me
>  *** caught segfault ***
> address 0xc0000023, cause 'memory not mapped'
> 
> Possible actions:
> 1: abort (with core dump, if enabled)
> 2: normal R exit
> 3: exit R without saving workspace
> 4: exit R saving workspace
> >
> Selection:
> 
> This only happens if I create the graphics from within Rcmdr. If I create
the
> graphics manually, there is no problem. This occurs on my laptop with R
2.8.1
> (I
> uninstalled 2.9 and reinstall 2.8.1 to see if the problem existed there)
and
> also on my iMac with R2.9.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From cooch17 at verizon.net  Thu Apr 30 17:26:43 2009
From: cooch17 at verizon.net (egc)
Date: Thu, 30 Apr 2009 11:26:43 -0400
Subject: [Rd] problems installing rjags | tcltk
Message-ID: <49F9C333.6070708@verizon.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090430/aea531cb/attachment.pl>

From cooch17 at verizon.net  Thu Apr 30 18:00:05 2009
From: cooch17 at verizon.net (egc)
Date: Thu, 30 Apr 2009 12:00:05 -0400
Subject: [Rd] [Fwd:  problems installing rjags | tcltk]
Message-ID: <49F9CB05.2030500@verizon.net>

Quick followup. Confirmed that TCl/Tk are both installed on the machine 
(they are, in both 32- and 64-bit flavours), as are all tcl and 
tk-related libs, devel packages, and about everything else I could find.

It occurred to me that perhaps the R I compiled isn't 'tcltk' aware. I 
checked the config.log, and there is some hint that this might be the 
case. Just before ## File substitutions ## I see

use_tcltk='no'

Further upstream in the config.log, I see

configure:42914: checking for tcl.h
conftest.c:204:17: error: tcl.h: No such file or directory   

and

ac_cv_env_TCLTK_CPPFLAGS_set=
ac_cv_env_TCLTK_CPPFLAGS_value=
ac_cv_env_TCLTK_LIBS_set=
ac_cv_env_TCLTK_LIBS_value= 

and

r_cv_header_tcl_h=no 

and

TCLTK_CPPFLAGS=''
TCLTK_LIBS=''
TCL_CONFIG='' 

So, it seems as if my self-rolled R isn't  TCLTK 'aware'. Is simply adding

--with-tcltk

to my configure call (i.e.,

./configure --with-lapack="-L/usr/lib64" 
--with-blas="-L/opt/acml4.2.0/gfortran64/lib -lacml" --with-tcltk

the solution? I figure worth asking before I literally 'start over'. I 
see from the manual for linux installs there may be some issues with 
playing nice if both 32- and 64-bit versions of Tcl/Tk are installed.



-------- Original Message --------
Subject: 	[Rd] problems installing rjags | tcltk
Date: 	Thu, 30 Apr 2009 11:26:43 -0400
From: 	egc <cooch17 at verizon.net>
To: 	r-devel at r-project.org



Greetings.

Running Fedora Cora 8 on multi-Opteron system - full 32- and 64-bit libs 
installed (R compiled 64-bit on this machine). R 2.9.0 - libs sitting in 
/usr/local/lib64/R/library. Trying to install JAGS, with rjags. Partial 
success.

For JAGS install:

|./configure --with-jags-modules=/usr/local/lib/JAGS/modules 
--libdir=/usr/local/lib64
make
make check
make install

Seems to work / no config or make errors, and jags fires up fine when I 
invoke it.

Problems start with rjags. Download latest tarball, and try

|| R --with-jags-modules=/usr/local/lib/JAGS/modules/ CMD INSTALL 
rjags_1.0.3-8.tar.gz


||Here is the relevant part of the error messages I get:

** Preparing for lazy loading
Loading required package: lattice
Error: package 'tcltk' does not have a name space
ERROR: lazy loading failing for package 'rjags'
|*  Removing '/usr/local/lib64/R/library/rjags'

No idea what to do now. Only tcltk-like package I see is tcltk2. Tried 
installing it, get the following error:

Error in library(pkg, character.only=TRUE, logical.return=TRUE, 
lib.loc-lib.loc) :
'tcltk' is not a valid installed package.
ERROR: lazy loading failed for package 'tcltk2'

So, I'm stumped.

	[[alternative HTML version deleted]]

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From cooch17 at verizon.net  Thu Apr 30 19:38:14 2009
From: cooch17 at verizon.net (egc)
Date: Thu, 30 Apr 2009 13:38:14 -0400
Subject: [Rd] [Fwd:  problems installing rjags | tcltk]
In-Reply-To: <49F9CB05.2030500@verizon.net>
References: <49F9CB05.2030500@verizon.net>
Message-ID: <49F9E206.6090102@verizon.net>

That was it - rebuilt R with --with-tcltk, then tried rebuilding rjags. 
Seems to have done the trick.

egc wrote:
> Quick followup. Confirmed that TCl/Tk are both installed on the 
> machine (they are, in both 32- and 64-bit flavours), as are all tcl 
> and tk-related libs, devel packages, and about everything else I could 
> find.
>
> It occurred to me that perhaps the R I compiled isn't 'tcltk' aware. I 
> checked the config.log, and there is some hint that this might be the 
> case. Just before ## File substitutions ## I see
>
> use_tcltk='no'
>
> Further upstream in the config.log, I see
>
> configure:42914: checking for tcl.h
> conftest.c:204:17: error: tcl.h: No such file or directory  
> and
>
> ac_cv_env_TCLTK_CPPFLAGS_set=
> ac_cv_env_TCLTK_CPPFLAGS_value=
> ac_cv_env_TCLTK_LIBS_set=
> ac_cv_env_TCLTK_LIBS_value=
> and
>
> r_cv_header_tcl_h=no
> and
>
> TCLTK_CPPFLAGS=''
> TCLTK_LIBS=''
> TCL_CONFIG=''
> So, it seems as if my self-rolled R isn't  TCLTK 'aware'. Is simply 
> adding
>
> --with-tcltk
>
> to my configure call (i.e.,
>
> ./configure --with-lapack="-L/usr/lib64" 
> --with-blas="-L/opt/acml4.2.0/gfortran64/lib -lacml" --with-tcltk
>
> the solution? I figure worth asking before I literally 'start over'. I 
> see from the manual for linux installs there may be some issues with 
> playing nice if both 32- and 64-bit versions of Tcl/Tk are installed.
>
>
>
> -------- Original Message --------
> Subject:     [Rd] problems installing rjags | tcltk
> Date:     Thu, 30 Apr 2009 11:26:43 -0400
> From:     egc <cooch17 at verizon.net>
> To:     r-devel at r-project.org
>
>
>
> Greetings.
>
> Running Fedora Cora 8 on multi-Opteron system - full 32- and 64-bit 
> libs installed (R compiled 64-bit on this machine). R 2.9.0 - libs 
> sitting in /usr/local/lib64/R/library. Trying to install JAGS, with 
> rjags. Partial success.
>
> For JAGS install:
>
> |./configure --with-jags-modules=/usr/local/lib/JAGS/modules 
> --libdir=/usr/local/lib64
> make
> make check
> make install
>
> Seems to work / no config or make errors, and jags fires up fine when 
> I invoke it.
>
> Problems start with rjags. Download latest tarball, and try
>
> || R --with-jags-modules=/usr/local/lib/JAGS/modules/ CMD INSTALL 
> rjags_1.0.3-8.tar.gz
>
>
> ||Here is the relevant part of the error messages I get:
>
> ** Preparing for lazy loading
> Loading required package: lattice
> Error: package 'tcltk' does not have a name space
> ERROR: lazy loading failing for package 'rjags'
> |*  Removing '/usr/local/lib64/R/library/rjags'
>
> No idea what to do now. Only tcltk-like package I see is tcltk2. Tried 
> installing it, get the following error:
>
> Error in library(pkg, character.only=TRUE, logical.return=TRUE, 
> lib.loc-lib.loc) :
> 'tcltk' is not a valid installed package.
> ERROR: lazy loading failed for package 'tcltk2'
>
> So, I'm stumped.
>
>     [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From wdunlap at tibco.com  Thu Apr 30 19:51:43 2009
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 30 Apr 2009 10:51:43 -0700
Subject: [Rd] NA_real_ <op> NaN -> NA or NaN, should we care?
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D700011DF636@NA-PA-VBE03.na.tibco.com>

On Linux when I compile R 2.10.0(devel) (src/main/arithmetic.c in
particular)
with gcc 3.4.5 using the flags -g -O2 I get noncommutative behavior when
adding NA and NaN:
   > NA_real_ + NaN
   [1] NaN
   > NaN + NA_real_
   [1] NA
If I compile src/main/arithmetic.c without optimization (just -g)
then both of those return NA.

On Windows, using a precompiled R 2.8.1 from CRAN I get
NA for both answers.

On Linux, after compiling src/main/arithmetic.c with -g -O2 the bit
patterns for NA_real_ and as.numeric(NA) are different:
   > my_numeric_NA <- as.numeric(NA)
   > writeBin(my_numeric_NA, ptmp<-pipe("od -x", open="wb"));close(ptmp)
   0000000 07a2 0000 0000 7ff8
   0000010
   > writeBin(NA_real_, ptmp<-pipe("od -x", open="wb"));close(ptmp)
   0000000 07a2 0000 0000 7ff0
   0000010 
On Linux, after compiling with -g the bit patterns for NA_real_
and as.numeric(NA) are identical.
   > my_numeric_NA <- as.numeric(NA)
   > writeBin(my_numeric_NA, ptmp<-pipe("od -x", open="wb"));close(ptmp)
   0000000 07a2 0000 0000 7ff8
   0000010
   > writeBin(NA_real_, ptmp<-pipe("od -x", open="wb"));close(ptmp)
   0000000 07a2 0000 0000 7ff8
   0000010

On Windows, using precompiled R 2.8.1 and cygwin/bin/od, both of those
gave the 7ff8 version.

Is this confounding of NA and NaN of concern or does R not promise to
keep NA and NaN distinct? 

I haven't followed all the macros, but it looks like arithmetic.c just
does
    result[i]=x[i]+y[i]
and lets the compiler/floating point unit decide what to do when x[i]
and y[i]
are different NaN values (NA is a NaN value).  I haven't looked at the C
code
for the initialization of NA_real_.  Adding explicit tests for NA-ness
in the
binary operators (as S+ does) adds a fairly significant cost.

Bill Dunlap
TIBCO Software Inc - Spotfire Division
wdunlap tibco.com 


From sich at gmx.de  Thu Apr 30 18:43:18 2009
From: sich at gmx.de (Lars)
Date: Thu, 30 Apr 2009 18:43:18 +0200
Subject: [Rd] unexpected behavior of rpart 3.1-43, loss matrix
Message-ID: <49F9D526.5070302@gmx.de>

Hi,

I just noticed that rpart behaves unexpectecly, when performing
classification learning and specifying a loss matrix.
if the response variable y is a factor and if not all levels of the
factor  occur in the observations, rpart exits with an error:


> df=data.frame(attr=1:5,class=factor(c(2,3,1,5,3),levels=1:6))
> rpart(class~attr,df,parms=list(loss=matrix(0,6,6)))
Error in (get(paste("rpart", method, sep = ".")))(Y, offset, parms, wt)
:   Wrong length for loss matrix


note that while the levels of the factor range from 1:6, for the
concrete obseration data, only levels 1, 2, 3, 5 do occur.

the error is caused by the code of rpart.class:

 fy <- as.factor(y)
 y <- as.integer(fy)
 numclass <- max(y[!is.na(y)])
...

temp2 <- parms$loss
if (length(temp2) != numclass^2)
  stop("Wrong length for loss matrix")


for the example, numclass is set to 5 instead of 6.


while for that small example, it may be discussable whether or not
numclass should be 6, consider a set of data for that the response
variable has a certain range. Then, it may be the case that for some
data, not all levels of the response variable do occur. at the same
time, it is desirable to use the same loss matrix when training a
deicision tree from the data.


having said that, i am very happy with the rpart package and with its
high configurability.

best regards
lars


