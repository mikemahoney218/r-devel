From radford at cs.toronto.edu  Sun Mar  1 18:17:33 2015
From: radford at cs.toronto.edu (Radford Neal)
Date: Sun, 1 Mar 2015 12:17:33 -0500
Subject: [Rd] iterated lapply
In-Reply-To: <mailman.17.1425034805.31301.r-devel@r-project.org>
References: <mailman.17.1425034805.31301.r-devel@r-project.org>
Message-ID: <20150301171733.GA28691@cs.toronto.edu>

I think the discussion of this issue has gotten more complicated than
necessary.

First, there really is a bug.  You can see this also by the fact that
delayed warning messages are wrong.  For instance, in R-3.1.2:

  > lapply(c(-1,2,-1),sqrt)
  [[1]]
  [1] NaN
  
  [[2]]
  [1] 1.414214
  
  [[3]]
  [1] NaN
  
  Warning messages:
  1: In FUN(c(-1, 2, -1)[[3L]], ...) : NaNs produced
  2: In FUN(c(-1, 2, -1)[[3L]], ...) : NaNs produced
  
The first warning message should have "1L" rather than "3L".  It
doesn't because lapply made a destructive change to the R expression
that was evaluated for the first element.  Throughout the R
interpreter, there is a general assumption that expressions that are
or were evaluated are immutable, which lapply is not abiding by.  The
only question is whether the bugs from this are sufficiently obscure
that it's worth keeping them for the gain in speed, but the speed cost
of fixing it is fairly small (though it's not negligible when the
function applied is something simple like sqrt).

The fix in the C code for lapply, vapply, and eapply is easy: Rather
than create an R expression such as FUN(X[[1L]]) for the first
function call, and then modify it in place to FUN(X[[2L]]), and so
forth, just create a new expression for each iteration.  This requires
allocating a few new CONS cells each iteration, which does have a
cost, but not a huge one.  It's certainly easier and faster than
creating a new environment (and also less likely to cause
incompatibilities).

The R code for apply can be changed to use the same approach, 
rather than using expressions such as FUN(X[i,]), where i is an
index variable, it can create expressions like FUN(X[1L,]), then
FUN(X[2L,]), etc.  The method for this is simple, like so:

  > a <- quote(FUN(X[i,]))     # "i" could be anything
  > b <- a; b[[c(2,3)]] <- 1L  # change "i" to 1L (creates new expr)

This has the added advantage of making error messages refer to the
actual index, not to "i", which has no meaning if you haven't looked
at the source code for apply (and which doesn't tell you which element
led to the error even if you know what "i" does).

I've implemented this in the development version of pqR, on the
development branch 31-apply-fix, at

  https://github.com/radfordneal/pqR/tree/31-apply-fix

The changes are in src/main/apply.R, src/main/envir.R, and
src/library/base/R/apply.R, plus a new test in tests/apply.R.  You can
compare to branch 31 to see what's changed.  (Note rapply seems to not
have had a problem, and that other apply functions just use these, so
should be fixed as well.)  There are also other optimizations in pqR
for these functions but the code is still quite similar to R-3.1.2.

   Radford Neal


From luke-tierney at uiowa.edu  Sun Mar  1 20:37:50 2015
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Sun, 1 Mar 2015 13:37:50 -0600
Subject: [Rd] iterated lapply
In-Reply-To: <20150301171733.GA28691@cs.toronto.edu>
References: <mailman.17.1425034805.31301.r-devel@r-project.org>
	<20150301171733.GA28691@cs.toronto.edu>
Message-ID: <alpine.DEB.2.02.1503011329120.2327@luke-Latitude>

On Sun, 1 Mar 2015, Radford Neal wrote:

> I think the discussion of this issue has gotten more complicated than
> necessary.

The discussion has gotten no more complicated than it needs to
be. There are other instances, such as Reduce where there is a bug
report pending that amounts to the same issue.  Performing surgery on
expressions and calling eval is not good practice at the R level and
probably not a good idea at the C level either.  It is worth thinking
this through carefully before a adopting a solution, which is what we
will be doing.

Best,

luke

>
> First, there really is a bug.  You can see this also by the fact that
> delayed warning messages are wrong.  For instance, in R-3.1.2:
>
>  > lapply(c(-1,2,-1),sqrt)
>  [[1]]
>  [1] NaN
>
>  [[2]]
>  [1] 1.414214
>
>  [[3]]
>  [1] NaN
>
>  Warning messages:
>  1: In FUN(c(-1, 2, -1)[[3L]], ...) : NaNs produced
>  2: In FUN(c(-1, 2, -1)[[3L]], ...) : NaNs produced
>
> The first warning message should have "1L" rather than "3L".  It
> doesn't because lapply made a destructive change to the R expression
> that was evaluated for the first element.  Throughout the R
> interpreter, there is a general assumption that expressions that are
> or were evaluated are immutable, which lapply is not abiding by.  The
> only question is whether the bugs from this are sufficiently obscure
> that it's worth keeping them for the gain in speed, but the speed cost
> of fixing it is fairly small (though it's not negligible when the
> function applied is something simple like sqrt).
>
> The fix in the C code for lapply, vapply, and eapply is easy: Rather
> than create an R expression such as FUN(X[[1L]]) for the first
> function call, and then modify it in place to FUN(X[[2L]]), and so
> forth, just create a new expression for each iteration.  This requires
> allocating a few new CONS cells each iteration, which does have a
> cost, but not a huge one.  It's certainly easier and faster than
> creating a new environment (and also less likely to cause
> incompatibilities).
>
> The R code for apply can be changed to use the same approach,
> rather than using expressions such as FUN(X[i,]), where i is an
> index variable, it can create expressions like FUN(X[1L,]), then
> FUN(X[2L,]), etc.  The method for this is simple, like so:
>
>  > a <- quote(FUN(X[i,]))     # "i" could be anything
>  > b <- a; b[[c(2,3)]] <- 1L  # change "i" to 1L (creates new expr)
>
> This has the added advantage of making error messages refer to the
> actual index, not to "i", which has no meaning if you haven't looked
> at the source code for apply (and which doesn't tell you which element
> led to the error even if you know what "i" does).
>
> I've implemented this in the development version of pqR, on the
> development branch 31-apply-fix, at
>
>  https://github.com/radfordneal/pqR/tree/31-apply-fix
>
> The changes are in src/main/apply.R, src/main/envir.R, and
> src/library/base/R/apply.R, plus a new test in tests/apply.R.  You can
> compare to branch 31 to see what's changed.  (Note rapply seems to not
> have had a problem, and that other apply functions just use these, so
> should be fixed as well.)  There are also other optimizations in pqR
> for these functions but the code is still quite similar to R-3.1.2.
>
>   Radford Neal
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From radford at cs.toronto.edu  Sun Mar  1 23:43:45 2015
From: radford at cs.toronto.edu (Radford Neal)
Date: Sun, 1 Mar 2015 17:43:45 -0500
Subject: [Rd] iterated lapply
In-Reply-To: <alpine.DEB.2.02.1503011329120.2327@luke-Latitude>
References: <mailman.17.1425034805.31301.r-devel@r-project.org>
	<20150301171733.GA28691@cs.toronto.edu>
	<alpine.DEB.2.02.1503011329120.2327@luke-Latitude>
Message-ID: <20150301224345.GA2941@cs.toronto.edu>

> There are other instances, such as Reduce where there is a bug
> report pending that amounts to the same issue.  Performing surgery on
> expressions and calling eval is not good practice at the R level and
> probably not a good idea at the C level either.  It is worth thinking
> this through carefully before a adopting a solution, which is what we
> will be doing.

Surgery on expressions is what lapply does at the moment.  My change
makes it no longer do that.  

There is a general problem that lazy evaluation can have the effect
of making the internal details of how an R function like "apply" is
implemented leak into its semantics.  That's what's going on with
the Reduce bug (16093) too.  

I think one can avoid this by defining the following function for
calling a function with evaluation of arguments forced (ie, lazy
evaluation disabled):

  call_forced <- function (f, ...) { list (...); f (...) }

(Of course, for speed one could make this a primitive function, which
wouldn't actually build a list.)

Then the critical code in Reduce could be changed from

  for (i in rev(ind)) init <- f(x[[i]], init)

to

  for (i in rev(ind)) init <- call_forced (f, x[[i]], init)

If one had a primitive (ie, fast) call_forced, a similar technique
might be better than the one I presented for fixing "apply" (cleaner,
and perhaps slightly faster).  I don't see how it helps for functions
like lapply that are written in C, however (where help isn't needed,
since there's nothing wrong with the mod in my previous message).

   Radford Neal


From luke-tierney at uiowa.edu  Mon Mar  2 00:07:23 2015
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Sun, 1 Mar 2015 17:07:23 -0600
Subject: [Rd] iterated lapply
In-Reply-To: <20150301224345.GA2941@cs.toronto.edu>
References: <mailman.17.1425034805.31301.r-devel@r-project.org>
	<20150301171733.GA28691@cs.toronto.edu>
	<alpine.DEB.2.02.1503011329120.2327@luke-Latitude>
	<20150301224345.GA2941@cs.toronto.edu>
Message-ID: <alpine.DEB.2.02.1503011653250.2327@luke-Latitude>

On Sun, 1 Mar 2015, Radford Neal wrote:

>> There are other instances, such as Reduce where there is a bug
>> report pending that amounts to the same issue.  Performing surgery on
>> expressions and calling eval is not good practice at the R level and
>> probably not a good idea at the C level either.  It is worth thinking
>> this through carefully before a adopting a solution, which is what we
>> will be doing.
>
> Surgery on expressions is what lapply does at the moment.  My change
> makes it no longer do that.
>
> There is a general problem that lazy evaluation can have the effect
> of making the internal details of how an R function like "apply" is
> implemented leak into its semantics.  That's what's going on with
> the Reduce bug (16093) too.
>
> I think one can avoid this by defining the following function for
> calling a function with evaluation of arguments forced (ie, lazy
> evaluation disabled):
>
>  call_forced <- function (f, ...) { list (...); f (...) }
>
> (Of course, for speed one could make this a primitive function, which
> wouldn't actually build a list.)
>
> Then the critical code in Reduce could be changed from
>
>  for (i in rev(ind)) init <- f(x[[i]], init)
>
> to
>
>  for (i in rev(ind)) init <- call_forced (f, x[[i]], init)

This is the option I was suggesting as a possibility in my reply to
Bill Dunlap -- I called it funcall. This may be the right way to
go. There are some subtleties to sort out, such as how missing
arguments should be handled (allowed or error), and whether the force
should stop at ... arguments as in turning

     FUN(X[[i]], ...)

into

      funcall(FUN, X[[i]], ...)

There is also a change in when the evaluation of X[[i]] happens, which
may or may not matter.  Some testing against CRAN/BIOC packages should
reveal how much of an issue these are.

> If one had a primitive (ie, fast) call_forced, a similar technique
> might be better than the one I presented for fixing "apply" (cleaner,
> and perhaps slightly faster).  I don't see how it helps for functions
> like lapply that are written in C, however (where help isn't needed,
> since there's nothing wrong with the mod in my previous message).

If we adapt the funcall approach then it would be best if the C
implementation stayed as close as possible to an R reference
implementation. I do not think your proposed approach would do that.

mapply has its own issues with the MoreArgs argument that would be
nice to sort out at the same time if possible, as there are also a few
more instances of this in several places.

I will try to look into this more in the next week or so.

Best,

luke

>
>   Radford Neal
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From luke-tierney at uiowa.edu  Mon Mar  2 00:48:06 2015
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Sun, 1 Mar 2015 17:48:06 -0600
Subject: [Rd] iterated lapply
In-Reply-To: <CAF8bMcbu93drmsDEc6DpSiKpb1sx-ufMZhC81Z5pp+c4ZzpxFw@mail.gmail.com>
References: <mailman.21.1424775604.19275.r-devel@r-project.org>
	<20150224113908.GA7612@cs.toronto.edu>
	<alpine.DEB.2.02.1502240950150.2336@luke-Latitude>
	<CAF8bMcbu93drmsDEc6DpSiKpb1sx-ufMZhC81Z5pp+c4ZzpxFw@mail.gmail.com>
Message-ID: <alpine.DEB.2.02.1503011742280.2327@luke-Latitude>

On Thu, 26 Feb 2015, William Dunlap wrote:

> ...
> It also seems to cause problems with some built-in functions:
> newlapply <- function (X, FUN, ...)?
> {
> ? ? FUN <- match.fun(FUN)
> ? ? if (!is.list(X))?
> ? ? ? ? X <- as.list(X)
> ? ? rval <- vector("list", length(X))
> ? ? for (i in seq(along = X)) {
> ? ? ? ? rval[i] <- list(local({
> ? ? ? ? ? ? i <- i
> ? ? ? ? ? ? FUN(X[[i]], ...)
> ? ? ? ? }))
> ? ? }
> ? ? names(rval) <- names(X)
> ? ? return(rval)
> }
> newlapply(1:2,log)
> #Error in FUN(X[[i]], ...) : non-numeric argument to mathematical function

This seems to be a bug in log() -- this takes local() out of the issue:

> f <- function(x, ...) {
+     g <- function()
+         log(x, ...)
+     g()
+ }
> f(1)
Error in log(x, ...) : non-numeric argument to mathematical function

It's not following the ... properly for some reason.

Best,

luke

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From luke-tierney at uiowa.edu  Mon Mar  2 00:52:28 2015
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Sun, 1 Mar 2015 17:52:28 -0600
Subject: [Rd] iterated lapply
In-Reply-To: <alpine.DEB.2.02.1503011742280.2327@luke-Latitude>
References: <mailman.21.1424775604.19275.r-devel@r-project.org>
	<20150224113908.GA7612@cs.toronto.edu>
	<alpine.DEB.2.02.1502240950150.2336@luke-Latitude>
	<CAF8bMcbu93drmsDEc6DpSiKpb1sx-ufMZhC81Z5pp+c4ZzpxFw@mail.gmail.com>
	<alpine.DEB.2.02.1503011742280.2327@luke-Latitude>
Message-ID: <alpine.DEB.2.02.1503011751160.2327@luke-Latitude>

On Sun, 1 Mar 2015, luke-tierney at uiowa.edu wrote:

> On Thu, 26 Feb 2015, William Dunlap wrote:
>
>> ...
>> It also seems to cause problems with some built-in functions:
>> newlapply <- function (X, FUN, ...)?
>> {
>> ? ? FUN <- match.fun(FUN)
>> ? ? if (!is.list(X))?
>> ? ? ? ? X <- as.list(X)
>> ? ? rval <- vector("list", length(X))
>> ? ? for (i in seq(along = X)) {
>> ? ? ? ? rval[i] <- list(local({
>> ? ? ? ? ? ? i <- i
>> ? ? ? ? ? ? FUN(X[[i]], ...)
>> ? ? ? ? }))
>> ? ? }
>> ? ? names(rval) <- names(X)
>> ? ? return(rval)
>> }
>> newlapply(1:2,log)
>> #Error in FUN(X[[i]], ...) : non-numeric argument to mathematical function
>
> This seems to be a bug in log() -- this takes local() out of the issue:
>
>> f <- function(x, ...) {
> +     g <- function()
> +         log(x, ...)
> +     g()
> + }
>> f(1)
> Error in log(x, ...) : non-numeric argument to mathematical function
>
> It's not following the ... properly for some reason.

But no longer a problem in R-devel -- maybe there is a change worth
back-porting to R-patched.

Best,

luke

> luke
>
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From luckbuttered at gmail.com  Mon Mar  2 04:09:53 2015
From: luckbuttered at gmail.com (Luck Buttered)
Date: Sun, 1 Mar 2015 21:09:53 -0600
Subject: [Rd] Fixing ambiguous corrections and reattempting to submit
	package to R
Message-ID: <CAGRPoRSLhGQpzn3i+cFMs+6BQnMtEcnY2LkECK_+eq3dJw3DUg@mail.gmail.com>

Hello:

I recently submitted a package to R using devtools:release().

I received no errors, warnings, or notes in R CMD check.

However, I received two notes in devtools::release():

1) checking CRAN incoming feasibility ... NOTE
2) checking package dependencies ... NOTE
   No repository set, so cyclic dependency check skipped

After I submitted the package, I was told to fix two things, of which I am
unsure:

1) The Title field should be in title case, current version then in title case
2) checking CRAN incoming feasibility ... NOTE

For the first issue, I changed my title field in the DESCRIPTION file to be
title case, as it had been all lower-case. However, I do not know if that
is a sufficient change, given their response wording "The Title field
should be in title case, current version then in title case". If all I need
to do is change my title field to title case, I would imagine their
response would simply be "The Title field should be in title case".

When I did research on the second issue (from websites like these):
1)
http://stackoverflow.com/questions/23829978/checking-cran-incoming-feasibility-note-maintainer
2) http://grokbase.com/t/r/r-help/129ncmtvga/r-new-submission-to-cran-note

The first website tells me to ignore the note, with a reference to CRAN
member Uwe Ligges, while the second website tells me to send an e-mail to
cran at r-project.org, and state that I agree to the CRAN repository
policies.

So, would it be correct (of good etiquette) for me to simply change my
title field in the DESCRIPTION field to title case, rerun
devtools::release(), and then send an e-mail to cran at r-project.org, and
state that I agree to the CRAN repository policies (which I did not do the
first time I submitted)?

Thank you for any advice.


Below is the format of my DESCRIPTION file:


Package: packageName

Version: 0.1.0

Title: Title in Title Case that does not end in Period

Description: Statement about methods available.

Author: Author One, Author Two

Maintainer: Author One <authorOne at school.edu>

License: GPL

Depends:

    R (>= 3.0.2)

Imports:

    ggplot2 (>= 1.0.0),

VignetteBuilder: knitr

Suggests:

    knitr,

    roxygen2 (>= 3.0.0)

Roxygen: list(wrap = TRUE)

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon Mar  2 11:03:05 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 02 Mar 2015 05:03:05 -0500
Subject: [Rd] Fixing ambiguous corrections and reattempting to submit
 package to R
In-Reply-To: <CAGRPoRSLhGQpzn3i+cFMs+6BQnMtEcnY2LkECK_+eq3dJw3DUg@mail.gmail.com>
References: <CAGRPoRSLhGQpzn3i+cFMs+6BQnMtEcnY2LkECK_+eq3dJw3DUg@mail.gmail.com>
Message-ID: <54F43559.70702@gmail.com>

On 01/03/2015 10:09 PM, Luck Buttered wrote:
> Hello:
> 
> I recently submitted a package to R using devtools:release().
> 
> I received no errors, warnings, or notes in R CMD check.
> 
> However, I received two notes in devtools::release():
> 
> 1) checking CRAN incoming feasibility ... NOTE
> 2) checking package dependencies ... NOTE
>    No repository set, so cyclic dependency check skipped
> 
> After I submitted the package, I was told to fix two things, of which I am
> unsure:
> 
> 1) The Title field should be in title case, current version then in title case
> 2) checking CRAN incoming feasibility ... NOTE
> 
> For the first issue, I changed my title field in the DESCRIPTION file to be
> title case, as it had been all lower-case. However, I do not know if that
> is a sufficient change, given their response wording "The Title field
> should be in title case, current version then in title case". If all I need
> to do is change my title field to title case, I would imagine their
> response would simply be "The Title field should be in title case".

Perhaps they made an error editing.  It happens.

> 
> When I did research on the second issue (from websites like these):
> 1)
> http://stackoverflow.com/questions/23829978/checking-cran-incoming-feasibility-note-maintainer
> 2) http://grokbase.com/t/r/r-help/129ncmtvga/r-new-submission-to-cran-note
> 
> The first website tells me to ignore the note, with a reference to CRAN
> member Uwe Ligges, while the second website tells me to send an e-mail to
> cran at r-project.org, and state that I agree to the CRAN repository
> policies.
> 
> So, would it be correct (of good etiquette) for me to simply change my
> title field in the DESCRIPTION field to title case, rerun
> devtools::release(), and then send an e-mail to cran at r-project.org, and
> state that I agree to the CRAN repository policies (which I did not do the
> first time I submitted)?

The people at CRAN prefer that you use their web page for submissions.
(The URL is listed in their policy document.)  It is less work for them,
and believe me, they do a lot of work.
> 
> Thank you for any advice.
> 
> 
> Below is the format of my DESCRIPTION file:
> 
> 
> Package: packageName
> 
> Version: 0.1.0
> 
> Title: Title in Title Case that does not end in Period
> 
> Description: Statement about methods available.
> 
> Author: Author One, Author Two
> 
> Maintainer: Author One <authorOne at school.edu>

Those don't look like real names.  Since you are claiming copyright on
the work you're submitting, you should include real names, and a real
email address in the Maintainer field to respond to queries about it.
See the CRAN policy document on the CRAN website.

Duncan Murdoch


From sarahmanderni at gmail.com  Mon Mar  2 09:50:00 2015
From: sarahmanderni at gmail.com (sarah manderni)
Date: Mon, 2 Mar 2015 10:50:00 +0200
Subject: [Rd] R-devel does not update the C++ returned variables
Message-ID: <CAHyAz7TOELUyX2XW=8Abvuz2tU0_ZXVuyx-B84RBk7TQyM-mAA@mail.gmail.com>

Hi,

Within my R code, I am using a C++ function as below:

     overlaps <- matrix(0, nrow=B, ncol=length(N))
        overlaps.P <- matrix(0, nrow=B, ncol=length(N))

       .C("speedUp", D, S, pD, pS, nrow(D), as.integer(N), length(N),
           ssq[i], i, as.integer(B), overlaps, overlaps.P, DUP=FALSE)


the function "speedUp", is supposed to update matrices overlaps and
 overlaps.P and it works with official R versions.
However, using the same code in R-devel, it does not update matrices and
they remain all zero without returning any errors.
But, if I store the return values from C function in a variable lets say
"test" as follows:

test <-        .C("speedUp", D, S, pD, pS, nrow(D), as.integer(N),
length(N),
           ssq[i], i, as.integer(B), overlaps, overlaps.P, DUP=FALSE)

then the corresponding element of test to matrix "overlaps"
(test[["overlaps"]]) again has the updated values (correct non-zero values)
though the overlaps matrix itself is still empty.

I mean in official R, the "overlaps" matrix is updated after calling the
function but not in R-devel. Also it works in both environment and return
correct values to variable "test" in R-devel as well.
Did you face any similar problem so that R-devel does not update the
variable returned by C++?

Thanks for the help.

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon Mar  2 13:01:09 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 02 Mar 2015 07:01:09 -0500
Subject: [Rd] R-devel does not update the C++ returned variables
In-Reply-To: <CAHyAz7TOELUyX2XW=8Abvuz2tU0_ZXVuyx-B84RBk7TQyM-mAA@mail.gmail.com>
References: <CAHyAz7TOELUyX2XW=8Abvuz2tU0_ZXVuyx-B84RBk7TQyM-mAA@mail.gmail.com>
Message-ID: <54F45105.40608@gmail.com>

On 02/03/2015 3:50 AM, sarah manderni wrote:
> Hi,
> 
> Within my R code, I am using a C++ function as below:
> 
>      overlaps <- matrix(0, nrow=B, ncol=length(N))
>         overlaps.P <- matrix(0, nrow=B, ncol=length(N))
> 
>        .C("speedUp", D, S, pD, pS, nrow(D), as.integer(N), length(N),
>            ssq[i], i, as.integer(B), overlaps, overlaps.P, DUP=FALSE)
> 
> 
> the function "speedUp", is supposed to update matrices overlaps and
>  overlaps.P and it works with official R versions.
> However, using the same code in R-devel, it does not update matrices and
> they remain all zero without returning any errors.

See the NEWS:  DUP=FALSE is now ignored.  It led to too many bugs.  Use
the .Call interface if duplication causes problems.

Duncan Murdoch

> But, if I store the return values from C function in a variable lets say
> "test" as follows:
> 
> test <-        .C("speedUp", D, S, pD, pS, nrow(D), as.integer(N),
> length(N),
>            ssq[i], i, as.integer(B), overlaps, overlaps.P, DUP=FALSE)
> 
> then the corresponding element of test to matrix "overlaps"
> (test[["overlaps"]]) again has the updated values (correct non-zero values)
> though the overlaps matrix itself is still empty.
> 
> I mean in official R, the "overlaps" matrix is updated after calling the
> function but not in R-devel. Also it works in both environment and return
> correct values to variable "test" in R-devel as well.
> Did you face any similar problem so that R-devel does not update the
> variable returned by C++?
> 
> Thanks for the help.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From murdoch.duncan at gmail.com  Mon Mar  2 15:09:25 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 02 Mar 2015 09:09:25 -0500
Subject: [Rd] R-devel does not update the C++ returned variables
In-Reply-To: <CAHyAz7QvAyL-KgKp0B6pk=RDHAQs2LHeGS48HvATqZnbuoAfww@mail.gmail.com>
References: <CAHyAz7TOELUyX2XW=8Abvuz2tU0_ZXVuyx-B84RBk7TQyM-mAA@mail.gmail.com>	<54F45105.40608@gmail.com>
	<CAHyAz7QvAyL-KgKp0B6pk=RDHAQs2LHeGS48HvATqZnbuoAfww@mail.gmail.com>
Message-ID: <54F46F15.3030901@gmail.com>

On 02/03/2015 8:46 AM, sarah manderni wrote:
> Thanks! I went through the online posts which supports the power of 
> .Call over .C. But my probably naive question is why does this work 
> for my code with R but not R-devel?

Because of the change mentioned in the NEWS file.

> And another question is related to using .Call. Based on the manual 
> page, I do not need to change the function parameters when using 
> .Call. So I can run like this:
> .Call("sppedUp", D, S, pD, pS, nrow(D), as.integer(N), length(N),
>            ssq[i], i, as.integer(B), overlaps, overlaps.P)
>
> But I am receiving the memory(?) related error:
> terminate called after throwing an instance of 'std::bad_alloc'   
> what():  std::bad_alloc
> Now that I am running the code using .Call.

Code using .Call is quite different from code using .C.  My guess would 
be that you didn't get all the details right.

I generally recommend that people use Rcpp, which hides a lot of the 
details.  It will generate your .Call calls for you, and generate the 
C++ code that receives them; you just need to think about the real 
problem, not the interface.  It has its own learning curve, but I think 
it is easier than using the low-level code that you need to work with .Call.

Duncan Murdoch
>
> Thanks.
>
> On Mon, Mar 2, 2015 at 2:01 PM, Duncan Murdoch 
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>
>     On 02/03/2015 3:50 AM, sarah manderni wrote:
>     > Hi,
>     >
>     > Within my R code, I am using a C++ function as below:
>     >
>     >      overlaps <- matrix(0, nrow=B, ncol=length(N))
>     >         overlaps.P <- matrix(0, nrow=B, ncol=length(N))
>     >
>     >        .C("speedUp", D, S, pD, pS, nrow(D), as.integer(N),
>     length(N),
>     >            ssq[i], i, as.integer(B), overlaps, overlaps.P,
>     DUP=FALSE)
>     >
>     >
>     > the function "speedUp", is supposed to update matrices overlaps and
>     >  overlaps.P and it works with official R versions.
>     > However, using the same code in R-devel, it does not update
>     matrices and
>     > they remain all zero without returning any errors.
>
>     See the NEWS:  DUP=FALSE is now ignored.  It led to too many
>     bugs.  Use
>     the .Call interface if duplication causes problems.
>
>     Duncan Murdoch
>
>     > But, if I store the return values from C function in a variable
>     lets say
>     > "test" as follows:
>     >
>     > test <-        .C("speedUp", D, S, pD, pS, nrow(D), as.integer(N),
>     > length(N),
>     >            ssq[i], i, as.integer(B), overlaps, overlaps.P,
>     DUP=FALSE)
>     >
>     > then the corresponding element of test to matrix "overlaps"
>     > (test[["overlaps"]]) again has the updated values (correct
>     non-zero values)
>     > though the overlaps matrix itself is still empty.
>     >
>     > I mean in official R, the "overlaps" matrix is updated after
>     calling the
>     > function but not in R-devel. Also it works in both environment
>     and return
>     > correct values to variable "test" in R-devel as well.
>     > Did you face any similar problem so that R-devel does not update the
>     > variable returned by C++?
>     >
>     > Thanks for the help.
>     >
>     >       [[alternative HTML version deleted]]
>     >
>     > ______________________________________________
>     > R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-devel
>     >
>
>


From edd at debian.org  Mon Mar  2 15:43:25 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 2 Mar 2015 08:43:25 -0600
Subject: [Rd] R-devel does not update the C++ returned variables
In-Reply-To: <54F46F15.3030901@gmail.com>
References: <CAHyAz7TOELUyX2XW=8Abvuz2tU0_ZXVuyx-B84RBk7TQyM-mAA@mail.gmail.com>
	<54F45105.40608@gmail.com>
	<CAHyAz7QvAyL-KgKp0B6pk=RDHAQs2LHeGS48HvATqZnbuoAfww@mail.gmail.com>
	<54F46F15.3030901@gmail.com>
Message-ID: <21748.30477.886575.819346@max.nulle.part>


On 2 March 2015 at 09:09, Duncan Murdoch wrote:
| I generally recommend that people use Rcpp, which hides a lot of the 
| details.  It will generate your .Call calls for you, and generate the 
| C++ code that receives them; you just need to think about the real 
| problem, not the interface.  It has its own learning curve, but I think 
| it is easier than using the low-level code that you need to work with .Call.

Thanks for that vote, and I second that.

And these days the learning is a lot flatter than it was a decade ago:

R> Rcpp::cppFunction("NumericVector doubleThis(NumericVector x) { return(2*x); }")
R> doubleThis(c(1,2,3,21,-4))
[1]  2  4  6 42 -8
R>

That defined, compiled, loaded and run/illustrated a simple function. 

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From therneau at mayo.edu  Mon Mar  2 15:45:39 2015
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Mon, 02 Mar 2015 08:45:39 -0600
Subject: [Rd] clarification on import/depends for a method
Message-ID: <1e7ee5$5ak42@ironport10.mayo.edu>

User of the coxme library (mixed effects Cox models) are instructed to use ranef(), 
fixed(), VarCorr(), etc to retrieve bits out of a fitted model; it purposely uses the same 
methods as nlme and/or lmer.

The current behavior is to "depend" on nlme.  If I defined the methods myself in coxme, 
then someone who had both nlme and coxme loaded will suffer from "last loaded wins", and 
the methods for one or the other are not found.  I'm willing to update this but want to 
get it right.  The import(nlme) +  nlme::ranef(fit) solution is not appealing.  I don't 
mind putting :: in my source code, but users of the package should not be forced into this.

Is the correct current solution (using ranef as an example)
    importFrom(nlme, ranef)
    export(ranef)

then use promptImport() to create a manual page?


If users always had only one of coxme, lmer, or nlme loaded in any given session then 
there are multiple solutions, but occassionally one wants both linear and Cox mixed effects.

Terry T.


From sarahmanderni at gmail.com  Mon Mar  2 14:46:43 2015
From: sarahmanderni at gmail.com (sarah manderni)
Date: Mon, 2 Mar 2015 15:46:43 +0200
Subject: [Rd] R-devel does not update the C++ returned variables
In-Reply-To: <54F45105.40608@gmail.com>
References: <CAHyAz7TOELUyX2XW=8Abvuz2tU0_ZXVuyx-B84RBk7TQyM-mAA@mail.gmail.com>
	<54F45105.40608@gmail.com>
Message-ID: <CAHyAz7QvAyL-KgKp0B6pk=RDHAQs2LHeGS48HvATqZnbuoAfww@mail.gmail.com>

Thanks! I went through the online posts which supports the power of .Call
over .C. But my probably naive question is why does this work for my code
with R but not R-devel?
And another question is related to using .Call. Based on the manual page, I
do not need to change the function parameters when using .Call. So I can
run like this:
.Call("sppedUp", D, S, pD, pS, nrow(D), as.integer(N), length(N),
           ssq[i], i, as.integer(B), overlaps, overlaps.P)

But I am receiving the memory(?) related error:
terminate called after throwing an instance of 'std::bad_alloc'   what():
 std::bad_alloc
Now that I am running the code using .Call.

Thanks.

On Mon, Mar 2, 2015 at 2:01 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 02/03/2015 3:50 AM, sarah manderni wrote:
> > Hi,
> >
> > Within my R code, I am using a C++ function as below:
> >
> >      overlaps <- matrix(0, nrow=B, ncol=length(N))
> >         overlaps.P <- matrix(0, nrow=B, ncol=length(N))
> >
> >        .C("speedUp", D, S, pD, pS, nrow(D), as.integer(N), length(N),
> >            ssq[i], i, as.integer(B), overlaps, overlaps.P, DUP=FALSE)
> >
> >
> > the function "speedUp", is supposed to update matrices overlaps and
> >  overlaps.P and it works with official R versions.
> > However, using the same code in R-devel, it does not update matrices and
> > they remain all zero without returning any errors.
>
> See the NEWS:  DUP=FALSE is now ignored.  It led to too many bugs.  Use
> the .Call interface if duplication causes problems.
>
> Duncan Murdoch
>
> > But, if I store the return values from C function in a variable lets say
> > "test" as follows:
> >
> > test <-        .C("speedUp", D, S, pD, pS, nrow(D), as.integer(N),
> > length(N),
> >            ssq[i], i, as.integer(B), overlaps, overlaps.P, DUP=FALSE)
> >
> > then the corresponding element of test to matrix "overlaps"
> > (test[["overlaps"]]) again has the updated values (correct non-zero
> values)
> > though the overlaps matrix itself is still empty.
> >
> > I mean in official R, the "overlaps" matrix is updated after calling the
> > function but not in R-devel. Also it works in both environment and return
> > correct values to variable "test" in R-devel as well.
> > Did you face any similar problem so that R-devel does not update the
> > variable returned by C++?
> >
> > Thanks for the help.
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>

	[[alternative HTML version deleted]]


From maechler at lynne.stat.math.ethz.ch  Mon Mar  2 16:37:35 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Mon, 2 Mar 2015 16:37:35 +0100
Subject: [Rd] R-devel does not update the C++ returned variables
In-Reply-To: <21748.30477.886575.819346@max.nulle.part>
References: <CAHyAz7TOELUyX2XW=8Abvuz2tU0_ZXVuyx-B84RBk7TQyM-mAA@mail.gmail.com>
	<54F45105.40608@gmail.com>
	<CAHyAz7QvAyL-KgKp0B6pk=RDHAQs2LHeGS48HvATqZnbuoAfww@mail.gmail.com>
	<54F46F15.3030901@gmail.com>
	<21748.30477.886575.819346@max.nulle.part>
Message-ID: <21748.33727.92491.976456@stat.math.ethz.ch>


> On 2 March 2015 at 09:09, Duncan Murdoch wrote:
> | I generally recommend that people use Rcpp, which hides a lot of the 
> | details.  It will generate your .Call calls for you, and generate the 
> | C++ code that receives them; you just need to think about the real 
> | problem, not the interface.  It has its own learning curve, but I think 
> | it is easier than using the low-level code that you need to work with .Call.

> Thanks for that vote, and I second that.

> And these days the learning is a lot flatter than it was a decade ago:

> R> Rcpp::cppFunction("NumericVector doubleThis(NumericVector x) { return(2*x); }")
> R> doubleThis(c(1,2,3,21,-4))
> [1]  2  4  6 42 -8
> R>

> That defined, compiled, loaded and run/illustrated a simple function. 

> Dirk

Indeed impressive,  ... and it also works with integer vectors
something also not 100% trivial when working with compiled code.

When testing that, I've went a step further:

##---- now "test":
require(microbenchmark)
i <- 1:10
(mb <- microbenchmark(doubleThis(i), i*2, 2*i, i*2L, 2L*i, i+i, times=2^12))
## Lynne (i7; FC 20), R Under development ... (2015-03-02 r67924):
## Unit: nanoseconds
##           expr min  lq      mean median   uq   max neval cld
##  doubleThis(i) 762 985 1319.5974   1124 1338 17831  4096   b
##          i * 2 124 151  258.4419    164  221 22224  4096  a 
##          2 * i 127 154  266.4707    169  216 20213  4096  a 
##         i * 2L 143 164  250.6057    181  234 16863  4096  a 
##         2L * i 144 177  269.5015    193  237 16119  4096  a 
##          i + i 152 183  272.6179    199  243 10434  4096  a 

plot(mb, log="y", notch=TRUE)
## hmm, looks like even the simple arithm. differ slightly ...
##
## ==> zoom in:
plot(mb, log="y", notch=TRUE, ylim = c(150,300))

dev.copy(png, file="mbenchm-doubling.png")
dev.off() # [ <- why do I need this here for png ??? ]
##--> see the appended *png graphic

Those who've learnt EDA or otherwise about boxplot notches, will
know that they provide somewhat informal but robust pairwise tests on
approximate 5% level.
>From these, one *could* - possibly wrongly - conclude that
'i * 2' is significantly faster than both 'i * 2L' and also
'i + i' ---- which I find astonishing, given that  i is integer here...

Probably no reason for deep thoughts here, but if someone is
enticed, this maybe slightly interesting to read.

Martin Maechler, ETH Zurich

-------------- next part --------------
A non-text attachment was scrubbed...
Name: mbenchm-doubling.png
Type: image/png
Size: 7244 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20150302/0f61efab/attachment.png>

From h.wickham at gmail.com  Mon Mar  2 19:58:42 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 2 Mar 2015 12:58:42 -0600
Subject: [Rd] clarification on import/depends for a method
In-Reply-To: <1e7ee5$5ak42@ironport10.mayo.edu>
References: <1e7ee5$5ak42@ironport10.mayo.edu>
Message-ID: <CABdHhvFV2-hnS6UG7HY3xauzZLAC=NtMJd3us-N1Tg0XsZhA+A@mail.gmail.com>

That makes sense to me.
Hadley

On Mon, Mar 2, 2015 at 8:45 AM, Therneau, Terry M., Ph.D.
<therneau at mayo.edu> wrote:
> User of the coxme library (mixed effects Cox models) are instructed to use
> ranef(), fixed(), VarCorr(), etc to retrieve bits out of a fitted model; it
> purposely uses the same methods as nlme and/or lmer.
>
> The current behavior is to "depend" on nlme.  If I defined the methods
> myself in coxme, then someone who had both nlme and coxme loaded will suffer
> from "last loaded wins", and the methods for one or the other are not found.
> I'm willing to update this but want to get it right.  The import(nlme) +
> nlme::ranef(fit) solution is not appealing.  I don't mind putting :: in my
> source code, but users of the package should not be forced into this.
>
> Is the correct current solution (using ranef as an example)
>    importFrom(nlme, ranef)
>    export(ranef)
>
> then use promptImport() to create a manual page?
>
>
> If users always had only one of coxme, lmer, or nlme loaded in any given
> session then there are multiple solutions, but occassionally one wants both
> linear and Cox mixed effects.
>
> Terry T.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
http://had.co.nz/


From winstonchang1 at gmail.com  Mon Mar  2 20:14:18 2015
From: winstonchang1 at gmail.com (Winston Chang)
Date: Mon, 2 Mar 2015 13:14:18 -0600
Subject: [Rd] Errors on Windows with grep(fixed=TRUE) on UTF-8 strings
Message-ID: <CAFOpNVE1YUrhntksnfp80kcaQXncHGka=NUJqj2O4rSxYnaopQ@mail.gmail.com>

On Windows, grep(fixed=TRUE) throws errors with some UTF-8 strings.
Here's an example (must be run on Windows to reproduce the error):

Sys.setlocale("LC_CTYPE", "chinese")
y <- rawToChar(as.raw(c(0xe6, 0xb8, 0x97)))
Encoding(y) <- "UTF-8"
y
# [1] "?"
grep("\n", y, fixed = TRUE)
# Error in grep("\n", y, fixed = TRUE) : invalid multibyte string at '<97>'


In my particular case, I'm using parse() on a string that contains
characters like this, and it triggers the same error, because parse()
calls srcfilecopy(), which calls grepl():

parse(text=y)
# Error in grepl("\n", lines, fixed = TRUE) :
#   invalid multibyte string at '<97>'


Am I right in assuming that this isn't the expected behavior?

-Winston


From edd at debian.org  Mon Mar  2 20:39:48 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 2 Mar 2015 13:39:48 -0600
Subject: [Rd] R-devel does not update the C++ returned variables
In-Reply-To: <21748.33727.92491.976456@stat.math.ethz.ch>
References: <CAHyAz7TOELUyX2XW=8Abvuz2tU0_ZXVuyx-B84RBk7TQyM-mAA@mail.gmail.com>
	<54F45105.40608@gmail.com>
	<CAHyAz7QvAyL-KgKp0B6pk=RDHAQs2LHeGS48HvATqZnbuoAfww@mail.gmail.com>
	<54F46F15.3030901@gmail.com>
	<21748.30477.886575.819346@max.nulle.part>
	<21748.33727.92491.976456@stat.math.ethz.ch>
Message-ID: <21748.48260.625372.931074@max.nulle.part>


On 2 March 2015 at 16:37, Martin Maechler wrote:
| 
| > On 2 March 2015 at 09:09, Duncan Murdoch wrote:
| > | I generally recommend that people use Rcpp, which hides a lot of the 
| > | details.  It will generate your .Call calls for you, and generate the 
| > | C++ code that receives them; you just need to think about the real 
| > | problem, not the interface.  It has its own learning curve, but I think 
| > | it is easier than using the low-level code that you need to work with .Call.
| 
| > Thanks for that vote, and I second that.
| 
| > And these days the learning is a lot flatter than it was a decade ago:
| 
| > R> Rcpp::cppFunction("NumericVector doubleThis(NumericVector x) { return(2*x); }")
| > R> doubleThis(c(1,2,3,21,-4))
| > [1]  2  4  6 42 -8
| > R>
| 
| > That defined, compiled, loaded and run/illustrated a simple function. 
| 
| > Dirk
| 
| Indeed impressive,  ... and it also works with integer vectors
| something also not 100% trivial when working with compiled code.
| 
| When testing that, I've went a step further:

As you may know, int can be 'casted up' to double which is what happens
here.  So in what follows you _always_ create a copy from an int vector to a
numeric vector. 

For pure int, use eg 

    Rcpp::cppFunction("IntegerVector doubleThis(IntegeerVector x) { return(2*x); }")

and rename the function names as needed to have two defined concurrently.

Dirk

| 
| ##---- now "test":
| require(microbenchmark)
| i <- 1:10
| (mb <- microbenchmark(doubleThis(i), i*2, 2*i, i*2L, 2L*i, i+i, times=2^12))
| ## Lynne (i7; FC 20), R Under development ... (2015-03-02 r67924):
| ## Unit: nanoseconds
| ##           expr min  lq      mean median   uq   max neval cld
| ##  doubleThis(i) 762 985 1319.5974   1124 1338 17831  4096   b
| ##          i * 2 124 151  258.4419    164  221 22224  4096  a 
| ##          2 * i 127 154  266.4707    169  216 20213  4096  a 
| ##         i * 2L 143 164  250.6057    181  234 16863  4096  a 
| ##         2L * i 144 177  269.5015    193  237 16119  4096  a 
| ##          i + i 152 183  272.6179    199  243 10434  4096  a 
| 
| plot(mb, log="y", notch=TRUE)
| ## hmm, looks like even the simple arithm. differ slightly ...
| ##
| ## ==> zoom in:
| plot(mb, log="y", notch=TRUE, ylim = c(150,300))
| 
| dev.copy(png, file="mbenchm-doubling.png")
| dev.off() # [ <- why do I need this here for png ??? ]
| ##--> see the appended *png graphic
| 
| Those who've learnt EDA or otherwise about boxplot notches, will
| know that they provide somewhat informal but robust pairwise tests on
| approximate 5% level.
| >From these, one *could* - possibly wrongly - conclude that
| 'i * 2' is significantly faster than both 'i * 2L' and also
| 'i + i' ---- which I find astonishing, given that  i is integer here...
| 
| Probably no reason for deep thoughts here, but if someone is
| enticed, this maybe slightly interesting to read.
| 
| Martin Maechler, ETH Zurich
| 
| [DELETED ATTACHMENT mbenchm-doubling.png, PNG image]

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From toth.denes at ttk.mta.hu  Mon Mar  2 21:18:15 2015
From: toth.denes at ttk.mta.hu (=?ISO-8859-1?Q?D=E9nes_T=F3th?=)
Date: Mon, 02 Mar 2015 21:18:15 +0100
Subject: [Rd] R-devel does not update the C++ returned variables
In-Reply-To: <21748.33727.92491.976456@stat.math.ethz.ch>
References: <CAHyAz7TOELUyX2XW=8Abvuz2tU0_ZXVuyx-B84RBk7TQyM-mAA@mail.gmail.com>	<54F45105.40608@gmail.com>	<CAHyAz7QvAyL-KgKp0B6pk=RDHAQs2LHeGS48HvATqZnbuoAfww@mail.gmail.com>	<54F46F15.3030901@gmail.com>	<21748.30477.886575.819346@max.nulle.part>
	<21748.33727.92491.976456@stat.math.ethz.ch>
Message-ID: <54F4C587.5040501@ttk.mta.hu>



On 03/02/2015 04:37 PM, Martin Maechler wrote:
>
>> On 2 March 2015 at 09:09, Duncan Murdoch wrote:
>> | I generally recommend that people use Rcpp, which hides a lot of the
>> | details.  It will generate your .Call calls for you, and generate the
>> | C++ code that receives them; you just need to think about the real
>> | problem, not the interface.  It has its own learning curve, but I think
>> | it is easier than using the low-level code that you need to work with .Call.
>
>> Thanks for that vote, and I second that.
>
>> And these days the learning is a lot flatter than it was a decade ago:
>
>> R> Rcpp::cppFunction("NumericVector doubleThis(NumericVector x) { return(2*x); }")
>> R> doubleThis(c(1,2,3,21,-4))
>> [1]  2  4  6 42 -8
>> R>
>
>> That defined, compiled, loaded and run/illustrated a simple function.
>
>> Dirk
>
> Indeed impressive,  ... and it also works with integer vectors
> something also not 100% trivial when working with compiled code.
>
> When testing that, I've went a step further:
>
> ##---- now "test":
> require(microbenchmark)
> i <- 1:10

Note that the relative speed of the algorithms also depends on the size 
of the input vector. i + i becomes the winner for longer vectors (e.g. i 
<- 1:1e6), but a proper Rcpp version is still approximately twice as fast.

Rcpp::cppFunction("NumericVector doubleThisNum(NumericVector x) { 
return(2*x); }")
Rcpp::cppFunction("IntegerVector doubleThisInt(IntegerVector x) { 
return(2*x); }")
i <- 1:1e6
mb <- microbenchmark::microbenchmark(doubleThisNum(i), doubleThisInt(i), 
i*2, 2*i, i*2L, 2L*i, i+i, times=100)
plot(mb, log="y", notch=TRUE)


> (mb <- microbenchmark(doubleThis(i), i*2, 2*i, i*2L, 2L*i, i+i, times=2^12))
> ## Lynne (i7; FC 20), R Under development ... (2015-03-02 r67924):
> ## Unit: nanoseconds
> ##           expr min  lq      mean median   uq   max neval cld
> ##  doubleThis(i) 762 985 1319.5974   1124 1338 17831  4096   b
> ##          i * 2 124 151  258.4419    164  221 22224  4096  a
> ##          2 * i 127 154  266.4707    169  216 20213  4096  a
> ##         i * 2L 143 164  250.6057    181  234 16863  4096  a
> ##         2L * i 144 177  269.5015    193  237 16119  4096  a
> ##          i + i 152 183  272.6179    199  243 10434  4096  a
>
> plot(mb, log="y", notch=TRUE)
> ## hmm, looks like even the simple arithm. differ slightly ...
> ##
> ## ==> zoom in:
> plot(mb, log="y", notch=TRUE, ylim = c(150,300))
>
> dev.copy(png, file="mbenchm-doubling.png")
> dev.off() # [ <- why do I need this here for png ??? ]
> ##--> see the appended *png graphic
>
> Those who've learnt EDA or otherwise about boxplot notches, will
> know that they provide somewhat informal but robust pairwise tests on
> approximate 5% level.
>  From these, one *could* - possibly wrongly - conclude that
> 'i * 2' is significantly faster than both 'i * 2L' and also
> 'i + i' ---- which I find astonishing, given that  i is integer here...
>
> Probably no reason for deep thoughts here, but if someone is
> enticed, this maybe slightly interesting to read.
>
> Martin Maechler, ETH Zurich
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From mtmorgan at fredhutch.org  Mon Mar  2 21:24:12 2015
From: mtmorgan at fredhutch.org (Martin Morgan)
Date: Mon, 02 Mar 2015 12:24:12 -0800
Subject: [Rd] R-devel does not update the C++ returned variables
In-Reply-To: <21748.48260.625372.931074@max.nulle.part>
References: <CAHyAz7TOELUyX2XW=8Abvuz2tU0_ZXVuyx-B84RBk7TQyM-mAA@mail.gmail.com>	<54F45105.40608@gmail.com>	<CAHyAz7QvAyL-KgKp0B6pk=RDHAQs2LHeGS48HvATqZnbuoAfww@mail.gmail.com>	<54F46F15.3030901@gmail.com>	<21748.30477.886575.819346@max.nulle.part>	<21748.33727.92491.976456@stat.math.ethz.ch>
	<21748.48260.625372.931074@max.nulle.part>
Message-ID: <54F4C6EC.1060205@fredhutch.org>

On 03/02/2015 11:39 AM, Dirk Eddelbuettel wrote:
>
> On 2 March 2015 at 16:37, Martin Maechler wrote:
> |
> | > On 2 March 2015 at 09:09, Duncan Murdoch wrote:
> | > | I generally recommend that people use Rcpp, which hides a lot of the
> | > | details.  It will generate your .Call calls for you, and generate the
> | > | C++ code that receives them; you just need to think about the real
> | > | problem, not the interface.  It has its own learning curve, but I think
> | > | it is easier than using the low-level code that you need to work with .Call.
> |
> | > Thanks for that vote, and I second that.
> |
> | > And these days the learning is a lot flatter than it was a decade ago:
> |
> | > R> Rcpp::cppFunction("NumericVector doubleThis(NumericVector x) { return(2*x); }")
> | > R> doubleThis(c(1,2,3,21,-4))
> | > [1]  2  4  6 42 -8
> | > R>
> |
> | > That defined, compiled, loaded and run/illustrated a simple function.
> |
> | > Dirk
> |
> | Indeed impressive,  ... and it also works with integer vectors
> | something also not 100% trivial when working with compiled code.
> |
> | When testing that, I've went a step further:
>
> As you may know, int can be 'casted up' to double which is what happens
> here.  So in what follows you _always_ create a copy from an int vector to a
> numeric vector.
>
> For pure int, use eg
>
>      Rcpp::cppFunction("IntegerVector doubleThis(IntegeerVector x) { return(2*x); }")
>
> and rename the function names as needed to have two defined concurrently.

avoiding duplication, harmless in the doubleThis() case, comes at some 
considerable hazard in general

 > Rcpp::cppFunction("IntegerVector incrThisAndThat(IntegerVector x) { x[0] += 
1; return x; }")
 > x = y = 1:5
 > incrThisAndThat(x)
[1] 2 2 3 4 5
 > x
[1] 2 2 3 4 5
 > y
[1] 2 2 3 4 5

(how often this happens in the now relatively large number of user-contributed 
packages using Rcpp?). It seems like 'one-liners' should really encourage 
something safer (sometimes at the expense of 'speed'),

   Rcpp::cppFunction("IntegerVector doubleThis(const IntegerVector x) { return x 
* 2; }")

   Rcpp::cppFunction("std::vector<int> incrThis(std::vector<int> x) { x[0] += 1; 
return x; }")

or that Rcpp should become more careful (i.e., should not allow!) modifying 
arguments with NAMED != 0.

Martin (Morgan)

>
> Dirk
>
> |
> | ##---- now "test":
> | require(microbenchmark)
> | i <- 1:10
> | (mb <- microbenchmark(doubleThis(i), i*2, 2*i, i*2L, 2L*i, i+i, times=2^12))
> | ## Lynne (i7; FC 20), R Under development ... (2015-03-02 r67924):
> | ## Unit: nanoseconds
> | ##           expr min  lq      mean median   uq   max neval cld
> | ##  doubleThis(i) 762 985 1319.5974   1124 1338 17831  4096   b
> | ##          i * 2 124 151  258.4419    164  221 22224  4096  a
> | ##          2 * i 127 154  266.4707    169  216 20213  4096  a
> | ##         i * 2L 143 164  250.6057    181  234 16863  4096  a
> | ##         2L * i 144 177  269.5015    193  237 16119  4096  a
> | ##          i + i 152 183  272.6179    199  243 10434  4096  a
> |
> | plot(mb, log="y", notch=TRUE)
> | ## hmm, looks like even the simple arithm. differ slightly ...
> | ##
> | ## ==> zoom in:
> | plot(mb, log="y", notch=TRUE, ylim = c(150,300))
> |
> | dev.copy(png, file="mbenchm-doubling.png")
> | dev.off() # [ <- why do I need this here for png ??? ]
> | ##--> see the appended *png graphic
> |
> | Those who've learnt EDA or otherwise about boxplot notches, will
> | know that they provide somewhat informal but robust pairwise tests on
> | approximate 5% level.
> | >From these, one *could* - possibly wrongly - conclude that
> | 'i * 2' is significantly faster than both 'i * 2L' and also
> | 'i + i' ---- which I find astonishing, given that  i is integer here...
> |
> | Probably no reason for deep thoughts here, but if someone is
> | enticed, this maybe slightly interesting to read.
> |
> | Martin Maechler, ETH Zurich
> |
> | [DELETED ATTACHMENT mbenchm-doubling.png, PNG image]
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From hpages at fredhutch.org  Mon Mar  2 22:00:47 2015
From: hpages at fredhutch.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Mon, 02 Mar 2015 13:00:47 -0800
Subject: [Rd] R-devel does not update the C++ returned variables
In-Reply-To: <54F4C587.5040501@ttk.mta.hu>
References: <CAHyAz7TOELUyX2XW=8Abvuz2tU0_ZXVuyx-B84RBk7TQyM-mAA@mail.gmail.com>	<54F45105.40608@gmail.com>	<CAHyAz7QvAyL-KgKp0B6pk=RDHAQs2LHeGS48HvATqZnbuoAfww@mail.gmail.com>	<54F46F15.3030901@gmail.com>	<21748.30477.886575.819346@max.nulle.part>	<21748.33727.92491.976456@stat.math.ethz.ch>
	<54F4C587.5040501@ttk.mta.hu>
Message-ID: <54F4CF7F.4080808@fredhutch.org>

Hi,

On 03/02/2015 12:18 PM, D?nes T?th wrote:
>
>
> On 03/02/2015 04:37 PM, Martin Maechler wrote:
>>
>>> On 2 March 2015 at 09:09, Duncan Murdoch wrote:
>>> | I generally recommend that people use Rcpp, which hides a lot of the
>>> | details.  It will generate your .Call calls for you, and generate the
>>> | C++ code that receives them; you just need to think about the real
>>> | problem, not the interface.  It has its own learning curve, but I
>>> think
>>> | it is easier than using the low-level code that you need to work
>>> with .Call.
>>
>>> Thanks for that vote, and I second that.
>>
>>> And these days the learning is a lot flatter than it was a decade ago:
>>
>>> R> Rcpp::cppFunction("NumericVector doubleThis(NumericVector x) {
>>> return(2*x); }")
>>> R> doubleThis(c(1,2,3,21,-4))
>>> [1]  2  4  6 42 -8
>>> R>
>>
>>> That defined, compiled, loaded and run/illustrated a simple function.
>>
>>> Dirk
>>
>> Indeed impressive,  ... and it also works with integer vectors
>> something also not 100% trivial when working with compiled code.
>>
>> When testing that, I've went a step further:
>>
>> ##---- now "test":
>> require(microbenchmark)
>> i <- 1:10
>
> Note that the relative speed of the algorithms also depends on the size
> of the input vector. i + i becomes the winner for longer vectors (e.g. i
> <- 1:1e6), but a proper Rcpp version is still approximately twice as fast.

The difference in speed is probably due to the fact that R does safe
arithmetic. C or C++ do not:

   > doubleThisInt(i)
   [1]  2147483642  2147483644  2147483646          NA -2147483646 
-2147483644

   > 2L * i
   [1] 2147483642 2147483644 2147483646         NA         NA         NA
   Warning message:
   In 2L * i : NAs produced by integer overflow

H.

>
> Rcpp::cppFunction("NumericVector doubleThisNum(NumericVector x) {
> return(2*x); }")
> Rcpp::cppFunction("IntegerVector doubleThisInt(IntegerVector x) {
> return(2*x); }")
> i <- 1:1e6
> mb <- microbenchmark::microbenchmark(doubleThisNum(i), doubleThisInt(i),
> i*2, 2*i, i*2L, 2L*i, i+i, times=100)
> plot(mb, log="y", notch=TRUE)
>
>
>> (mb <- microbenchmark(doubleThis(i), i*2, 2*i, i*2L, 2L*i, i+i,
>> times=2^12))
>> ## Lynne (i7; FC 20), R Under development ... (2015-03-02 r67924):
>> ## Unit: nanoseconds
>> ##           expr min  lq      mean median   uq   max neval cld
>> ##  doubleThis(i) 762 985 1319.5974   1124 1338 17831  4096   b
>> ##          i * 2 124 151  258.4419    164  221 22224  4096  a
>> ##          2 * i 127 154  266.4707    169  216 20213  4096  a
>> ##         i * 2L 143 164  250.6057    181  234 16863  4096  a
>> ##         2L * i 144 177  269.5015    193  237 16119  4096  a
>> ##          i + i 152 183  272.6179    199  243 10434  4096  a
>>
>> plot(mb, log="y", notch=TRUE)
>> ## hmm, looks like even the simple arithm. differ slightly ...
>> ##
>> ## ==> zoom in:
>> plot(mb, log="y", notch=TRUE, ylim = c(150,300))
>>
>> dev.copy(png, file="mbenchm-doubling.png")
>> dev.off() # [ <- why do I need this here for png ??? ]
>> ##--> see the appended *png graphic
>>
>> Those who've learnt EDA or otherwise about boxplot notches, will
>> know that they provide somewhat informal but robust pairwise tests on
>> approximate 5% level.
>>  From these, one *could* - possibly wrongly - conclude that
>> 'i * 2' is significantly faster than both 'i * 2L' and also
>> 'i + i' ---- which I find astonishing, given that  i is integer here...
>>
>> Probably no reason for deep thoughts here, but if someone is
>> enticed, this maybe slightly interesting to read.
>>
>> Martin Maechler, ETH Zurich
>>
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From hpages at fredhutch.org  Mon Mar  2 22:02:53 2015
From: hpages at fredhutch.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Mon, 02 Mar 2015 13:02:53 -0800
Subject: [Rd] R-devel does not update the C++ returned variables
In-Reply-To: <54F4CF7F.4080808@fredhutch.org>
References: <CAHyAz7TOELUyX2XW=8Abvuz2tU0_ZXVuyx-B84RBk7TQyM-mAA@mail.gmail.com>	<54F45105.40608@gmail.com>	<CAHyAz7QvAyL-KgKp0B6pk=RDHAQs2LHeGS48HvATqZnbuoAfww@mail.gmail.com>	<54F46F15.3030901@gmail.com>	<21748.30477.886575.819346@max.nulle.part>	<21748.33727.92491.976456@stat.math.ethz.ch>
	<54F4C587.5040501@ttk.mta.hu> <54F4CF7F.4080808@fredhutch.org>
Message-ID: <54F4CFFD.9020800@fredhutch.org>

On 03/02/2015 01:00 PM, Herv? Pag?s wrote:
> Hi,
>
> On 03/02/2015 12:18 PM, D?nes T?th wrote:
>>
>>
>> On 03/02/2015 04:37 PM, Martin Maechler wrote:
>>>
>>>> On 2 March 2015 at 09:09, Duncan Murdoch wrote:
>>>> | I generally recommend that people use Rcpp, which hides a lot of the
>>>> | details.  It will generate your .Call calls for you, and generate the
>>>> | C++ code that receives them; you just need to think about the real
>>>> | problem, not the interface.  It has its own learning curve, but I
>>>> think
>>>> | it is easier than using the low-level code that you need to work
>>>> with .Call.
>>>
>>>> Thanks for that vote, and I second that.
>>>
>>>> And these days the learning is a lot flatter than it was a decade ago:
>>>
>>>> R> Rcpp::cppFunction("NumericVector doubleThis(NumericVector x) {
>>>> return(2*x); }")
>>>> R> doubleThis(c(1,2,3,21,-4))
>>>> [1]  2  4  6 42 -8
>>>> R>
>>>
>>>> That defined, compiled, loaded and run/illustrated a simple function.
>>>
>>>> Dirk
>>>
>>> Indeed impressive,  ... and it also works with integer vectors
>>> something also not 100% trivial when working with compiled code.
>>>
>>> When testing that, I've went a step further:
>>>
>>> ##---- now "test":
>>> require(microbenchmark)
>>> i <- 1:10
>>
>> Note that the relative speed of the algorithms also depends on the size
>> of the input vector. i + i becomes the winner for longer vectors (e.g. i
>> <- 1:1e6), but a proper Rcpp version is still approximately twice as
>> fast.
>
> The difference in speed is probably due to the fact that R does safe
> arithmetic. C or C++ do not:
>
>    > doubleThisInt(i)
>    [1]  2147483642  2147483644  2147483646          NA -2147483646
> -2147483644
>
>    > 2L * i
>    [1] 2147483642 2147483644 2147483646         NA         NA         NA
>    Warning message:
>    In 2L * i : NAs produced by integer overflow

That was with

   i <- as.integer(2^30-4) + 1:6

Cheers,
H.

>
> H.
>
>>
>> Rcpp::cppFunction("NumericVector doubleThisNum(NumericVector x) {
>> return(2*x); }")
>> Rcpp::cppFunction("IntegerVector doubleThisInt(IntegerVector x) {
>> return(2*x); }")
>> i <- 1:1e6
>> mb <- microbenchmark::microbenchmark(doubleThisNum(i), doubleThisInt(i),
>> i*2, 2*i, i*2L, 2L*i, i+i, times=100)
>> plot(mb, log="y", notch=TRUE)
>>
>>
>>> (mb <- microbenchmark(doubleThis(i), i*2, 2*i, i*2L, 2L*i, i+i,
>>> times=2^12))
>>> ## Lynne (i7; FC 20), R Under development ... (2015-03-02 r67924):
>>> ## Unit: nanoseconds
>>> ##           expr min  lq      mean median   uq   max neval cld
>>> ##  doubleThis(i) 762 985 1319.5974   1124 1338 17831  4096   b
>>> ##          i * 2 124 151  258.4419    164  221 22224  4096  a
>>> ##          2 * i 127 154  266.4707    169  216 20213  4096  a
>>> ##         i * 2L 143 164  250.6057    181  234 16863  4096  a
>>> ##         2L * i 144 177  269.5015    193  237 16119  4096  a
>>> ##          i + i 152 183  272.6179    199  243 10434  4096  a
>>>
>>> plot(mb, log="y", notch=TRUE)
>>> ## hmm, looks like even the simple arithm. differ slightly ...
>>> ##
>>> ## ==> zoom in:
>>> plot(mb, log="y", notch=TRUE, ylim = c(150,300))
>>>
>>> dev.copy(png, file="mbenchm-doubling.png")
>>> dev.off() # [ <- why do I need this here for png ??? ]
>>> ##--> see the appended *png graphic
>>>
>>> Those who've learnt EDA or otherwise about boxplot notches, will
>>> know that they provide somewhat informal but robust pairwise tests on
>>> approximate 5% level.
>>>  From these, one *could* - possibly wrongly - conclude that
>>> 'i * 2' is significantly faster than both 'i * 2L' and also
>>> 'i + i' ---- which I find astonishing, given that  i is integer here...
>>>
>>> Probably no reason for deep thoughts here, but if someone is
>>> enticed, this maybe slightly interesting to read.
>>>
>>> Martin Maechler, ETH Zurich
>>>
>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From therneau at mayo.edu  Mon Mar  2 23:48:54 2015
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Mon, 02 Mar 2015 16:48:54 -0600
Subject: [Rd] Import data set from another package?
Message-ID: <1e7ee5$5h3fc@ironport10.mayo.edu>

I've moved nlme from Depends to Imports in my coxme package. However, a few of the 
examples for lmekin use one of the data sets from nlme.  This is on purpose, to show how 
the results are the same and how they differ.

  If I use  data(nlme::ergoStool)  the data is not found, data(nlme:::ergoStool) does no 
better.
  If I add importFrom(nlme, "ergoStool") the error message is that ergoStool is not exported.

There likely is a simple way, but I currently don't see it.

Terry T.


From brian at braverock.com  Mon Mar  2 23:56:51 2015
From: brian at braverock.com (Brian G. Peterson)
Date: Mon, 02 Mar 2015 16:56:51 -0600
Subject: [Rd] Import data set from another package?
In-Reply-To: <1e7ee5$5h3fc@ironport10.mayo.edu>
References: <1e7ee5$5h3fc@ironport10.mayo.edu>
Message-ID: <54F4EAB3.50505@braverock.com>

On 03/02/2015 04:48 PM, Therneau, Terry M., Ph.D. wrote:
> I've moved nlme from Depends to Imports in my coxme package. However, a
> few of the examples for lmekin use one of the data sets from nlme.  This
> is on purpose, to show how the results are the same and how they differ.
>
>   If I use  data(nlme::ergoStool)  the data is not found,
> data(nlme:::ergoStool) does no better.
>   If I add importFrom(nlme, "ergoStool") the error message is that
> ergoStool is not exported.
>
> There likely is a simple way, but I currently don't see it.

In your examples, can't you use:

data("ergoStool", package="nlme")

?

That is how a user would call it if they wished to use the dataset.

Regards,

Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From h.wickham at gmail.com  Tue Mar  3 00:14:15 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 2 Mar 2015 17:14:15 -0600
Subject: [Rd] Import data set from another package?
In-Reply-To: <1e7ee5$5h3fc@ironport10.mayo.edu>
References: <1e7ee5$5h3fc@ironport10.mayo.edu>
Message-ID: <CABdHhvGWasPvVg2MTWJkzw+oOFX39NpnAQOt7EDn2xG-HiJJkQ@mail.gmail.com>

How about just nlme::ergoStool ?

Hadley

On Mon, Mar 2, 2015 at 4:48 PM, Therneau, Terry M., Ph.D.
<therneau at mayo.edu> wrote:
> I've moved nlme from Depends to Imports in my coxme package. However, a few
> of the examples for lmekin use one of the data sets from nlme.  This is on
> purpose, to show how the results are the same and how they differ.
>
>  If I use  data(nlme::ergoStool)  the data is not found,
> data(nlme:::ergoStool) does no better.
>  If I add importFrom(nlme, "ergoStool") the error message is that ergoStool
> is not exported.
>
> There likely is a simple way, but I currently don't see it.
>
> Terry T.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
http://had.co.nz/


From jeroenooms at gmail.com  Tue Mar  3 01:32:02 2015
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Mon, 2 Mar 2015 16:32:02 -0800
Subject: [Rd] Import data set from another package?
In-Reply-To: <1e7ee5$5h3fc@ironport10.mayo.edu>
References: <1e7ee5$5h3fc@ironport10.mayo.edu>
Message-ID: <CABFfbXto_-HUoB=pR_=B7+UMsoep+15c8u0Lxjs5E5YUkpS6=Q@mail.gmail.com>

You could add something like this to your package:

.onLoad <- function(libname, pkgname){
  data(ergoStool, package="nlme", envir = environment(.onLoad));
}

This should basically do the same as importFrom(nlme, "ergoStool") but
then for a lazy load dataset.


On Mon, Mar 2, 2015 at 2:48 PM, Therneau, Terry M., Ph.D.
<therneau at mayo.edu> wrote:
> I've moved nlme from Depends to Imports in my coxme package. However, a few
> of the examples for lmekin use one of the data sets from nlme.  This is on
> purpose, to show how the results are the same and how they differ.
>
>  If I use  data(nlme::ergoStool)  the data is not found,
> data(nlme:::ergoStool) does no better.
>  If I add importFrom(nlme, "ergoStool") the error message is that ergoStool
> is not exported.
>
> There likely is a simple way, but I currently don't see it.
>
> Terry T.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at lynne.stat.math.ethz.ch  Tue Mar  3 09:59:28 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Tue, 3 Mar 2015 09:59:28 +0100
Subject: [Rd] R-devel does not update the C++ returned variables
In-Reply-To: <54F4CF7F.4080808@fredhutch.org>
References: <CAHyAz7TOELUyX2XW=8Abvuz2tU0_ZXVuyx-B84RBk7TQyM-mAA@mail.gmail.com>
	<54F45105.40608@gmail.com>
	<CAHyAz7QvAyL-KgKp0B6pk=RDHAQs2LHeGS48HvATqZnbuoAfww@mail.gmail.com>
	<54F46F15.3030901@gmail.com>
	<21748.30477.886575.819346@max.nulle.part>
	<21748.33727.92491.976456@stat.math.ethz.ch>
	<54F4C587.5040501@ttk.mta.hu> <54F4CF7F.4080808@fredhutch.org>
Message-ID: <21749.30704.941749.320247@stat.math.ethz.ch>

>>>>> Herv? Pag?s <hpages at fredhutch.org>
>>>>>     on Mon, 2 Mar 2015 13:00:47 -0800 writes:

    > Hi,
    > On 03/02/2015 12:18 PM, D?nes T?th wrote:
    >> 
    >> 
    >> On 03/02/2015 04:37 PM, Martin Maechler wrote:
    >>> 
    >>>> On 2 March 2015 at 09:09, Duncan Murdoch wrote:
    >>>> | I generally recommend that people use Rcpp, which hides a lot of the
    >>>> | details.  It will generate your .Call calls for you, and generate the
    >>>> | C++ code that receives them; you just need to think about the real
    >>>> | problem, not the interface.  It has its own learning curve, but I
    >>>> think
    >>>> | it is easier than using the low-level code that you need to work
    >>>> with .Call.
    >>> 
    >>>> Thanks for that vote, and I second that.
    >>> 
    >>>> And these days the learning is a lot flatter than it was a decade ago:
    >>> 
    R> Rcpp::cppFunction("NumericVector doubleThis(NumericVector x) {
    >>>> return(2*x); }")
    R> doubleThis(c(1,2,3,21,-4))
    >>>> [1]  2  4  6 42 -8
    R> 
    >>> 
    >>>> That defined, compiled, loaded and run/illustrated a simple function.
    >>> 
    >>>> Dirk
    >>> 
    >>> Indeed impressive,  ... and it also works with integer vectors
    >>> something also not 100% trivial when working with compiled code.
    >>> 
    >>> When testing that, I've went a step further:
    >>> 
    >>> ##---- now "test":
    >>> require(microbenchmark)
    >>> i <- 1:10
    >> 
    >> Note that the relative speed of the algorithms also depends on the size
    >> of the input vector. i + i becomes the winner for longer vectors (e.g. i
    >> <- 1:1e6), but a proper Rcpp version is still approximately twice as fast.

    > The difference in speed is probably due to the fact that R does safe
    > arithmetic. C or C++ do not:

    >> doubleThisInt(i)
    > [1]  2147483642  2147483644  2147483646          NA -2147483646 
    > -2147483644

    >> 2L * i
    > [1] 2147483642 2147483644 2147483646         NA         NA         NA
    > Warning message:
    > In 2L * i : NAs produced by integer overflow

    > H.

Exactly, excellent, Herv?!    

Luke also told me so in a private message.
and 'i+i' is looking up 'i' twice  which is relatively costly
for very small i  as in my example.

This ("no safe integer arithmetic in C, but in R") is another
good example {as Martin Morgan's}  why using 
Rccp -- or .Call() directly -- may be a too sharp edged sword and
maybe should be advocated for good programmers only.

Martin


    >> 
    >> Rcpp::cppFunction("NumericVector doubleThisNum(NumericVector x) {
    >> return(2*x); }")
    >> Rcpp::cppFunction("IntegerVector doubleThisInt(IntegerVector x) {
    >> return(2*x); }")
    >> i <- 1:1e6
    >> mb <- microbenchmark::microbenchmark(doubleThisNum(i), doubleThisInt(i),
    >> i*2, 2*i, i*2L, 2L*i, i+i, times=100)
    >> plot(mb, log="y", notch=TRUE)
    >> 
    >> 
    >>> (mb <- microbenchmark(doubleThis(i), i*2, 2*i, i*2L, 2L*i, i+i,
    >>> times=2^12))
    >>> ## Lynne (i7; FC 20), R Under development ... (2015-03-02 r67924):
    >>> ## Unit: nanoseconds
    >>> ##           expr min  lq      mean median   uq   max neval cld
    >>> ##  doubleThis(i) 762 985 1319.5974   1124 1338 17831  4096   b
    >>> ##          i * 2 124 151  258.4419    164  221 22224  4096  a
    >>> ##          2 * i 127 154  266.4707    169  216 20213  4096  a
    >>> ##         i * 2L 143 164  250.6057    181  234 16863  4096  a
    >>> ##         2L * i 144 177  269.5015    193  237 16119  4096  a
    >>> ##          i + i 152 183  272.6179    199  243 10434  4096  a
    >>> 
    >>> plot(mb, log="y", notch=TRUE)
    >>> ## hmm, looks like even the simple arithm. differ slightly ...
    >>> ##
    >>> ## ==> zoom in:
    >>> plot(mb, log="y", notch=TRUE, ylim = c(150,300))
    >>> 
    >>> dev.copy(png, file="mbenchm-doubling.png")
    >>> dev.off() # [ <- why do I need this here for png ??? ]
    >>> ##--> see the appended *png graphic
    >>> 
    >>> Those who've learnt EDA or otherwise about boxplot notches, will
    >>> know that they provide somewhat informal but robust pairwise tests on
    >>> approximate 5% level.
    >>> From these, one *could* - possibly wrongly - conclude that
    >>> 'i * 2' is significantly faster than both 'i * 2L' and also
    >>> 'i + i' ---- which I find astonishing, given that  i is integer here...
    >>> 
    >>> Probably no reason for deep thoughts here, but if someone is
    >>> enticed, this maybe slightly interesting to read.
    >>> 
    >>> Martin Maechler, ETH Zurich
    >>> 
    >>> 
    >>> 
    >>> ______________________________________________
    >>> R-devel at r-project.org mailing list
    >>> https://stat.ethz.ch/mailman/listinfo/r-devel
    >>> 
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel

    > -- 
    > Herv? Pag?s

    > Program in Computational Biology
    > Division of Public Health Sciences
    > Fred Hutchinson Cancer Research Center
    > 1100 Fairview Ave. N, M1-B514
    > P.O. Box 19024
    > Seattle, WA 98109-1024

    > E-mail: hpages at fredhutch.org
    > Phone:  (206) 667-5791
    > Fax:    (206) 667-1319


From ripley at stats.ox.ac.uk  Tue Mar  3 10:12:02 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 03 Mar 2015 09:12:02 +0000
Subject: [Rd] Import data set from another package?
In-Reply-To: <1e7ee5$5h3fc@ironport10.mayo.edu>
References: <1e7ee5$5h3fc@ironport10.mayo.edu>
Message-ID: <54F57AE2.2050906@stats.ox.ac.uk>

On 02/03/2015 22:48, Therneau, Terry M., Ph.D. wrote:
> I've moved nlme from Depends to Imports in my coxme package. However, a
> few of the examples for lmekin use one of the data sets from nlme.  This
> is on purpose, to show how the results are the same and how they differ.
>
>   If I use  data(nlme::ergoStool)  the data is not found,
> data(nlme:::ergoStool) does no better.
>   If I add importFrom(nlme, "ergoStool") the error message is that
> ergoStool is not exported.
>
> There likely is a simple way, but I currently don't see it.

There were some off-the-mark suggestions in this thread.  If you just 
want a dataset from a package, use

data("ergoStool", package = "nlme")

In particular, it is somewhat wasteful to load a large namespace like 
nlme when it is not needed.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From maechler at lynne.stat.math.ethz.ch  Tue Mar  3 11:28:44 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Tue, 3 Mar 2015 11:28:44 +0100
Subject: [Rd] [R] Why does R replace all row values with NAs
In-Reply-To: <CAF8bMcYrPtnLpvOfa17ZthjhSkp3L8KbFcy5uMv+sf-m+5X3UA@mail.gmail.com>
References: <CAN2xGJbe06Kqae9BCxvCMykeDjt5oJfdPAGuXWV_vd-uCLQJNw@mail.gmail.com>
	<54F07B99.90005@gmail.com>
	<CAN2xGJYmhkJmndSBVBL3WD+hEBFVKLhUGDDX_oi2WOQt+uDTiQ@mail.gmail.com>
	<54F086EA.7020800@gmail.com>
	<CAN2xGJauN=swX6P0WHzH+bsEcobCn24_z0pJWr64D5p-UBwVHg@mail.gmail.com>
	<CAF8bMcYrPtnLpvOfa17ZthjhSkp3L8KbFcy5uMv+sf-m+5X3UA@mail.gmail.com>
Message-ID: <21749.36060.745365.225385@stat.math.ethz.ch>

Diverted from R-help :
.... as it gets into musing about new R language "primitives"

>>>>> William Dunlap <wdunlap at tibco.com>
>>>>>     on Fri, 27 Feb 2015 08:04:36 -0800 writes:

    > You could define functions like

    > is.true <- function(x) !is.na(x) & x
    > is.false <- function(x) !is.na(x) & !x

    > and use them in your selections.  E.g.,
    >> x <- data.frame(a=1:10,b=2:11,c=c(1,NA,3,NA,5,NA,7,NA,NA,10))
    >> x[is.true(x$c >= 6), ]
    > a  b  c
    > 7   7  8  7
    > 10 10 11 10

    > Bill Dunlap
    > TIBCO Software
    > wdunlap tibco.com

Yes; the Matrix package has had these

is0  <- function(x) !is.na(x) & x == 0
isN0 <- function(x)  is.na(x) | x != 0
is1  <- function(x) !is.na(x) & x   # also == "isTRUE componentwise"

namespace hidden for a while  [note the comment of the last one!]
and using them for readibility in its own code.

Maybe we should (again) consider providing some versions of
these with R ?

The Matrix package also has had fast 

allFalse <- all0 <- function(x) .Call(R_all0, x)
anyFalse <- any0 <- function(x) .Call(R_any0, x)
## 
## anyFalse <- function(x) isTRUE(any(!x))		 ## ~= any0
## any0 <- function(x) isTRUE(any(x == 0))	      ## ~= anyFalse

namespace hidden as well, already, which probably could also be
brought to base R.

One big reason to *not* go there (to internal C code) at all with R is that
S3 and S4 dispatch for '==' ('!=', etc, the 'Compare' group generics) 
and 'is.na() have been known and package writers have
programmed methods for these.
To ensure that S3 and S4 dispatch works "correctly" also inside
such new internals is much less easily achieved, and so
such a C-based internal function  is0() would no longer be
equivalent with    !is.na(x) & x == 0
as soon as 'x' is an "object" with a '==', 'Compare' and/or an is.na() method.

OTOH, simple R versions such as your  'is.true',  called 'is1'
inside Matrix maybe optimizable a bit by the byte compiler (and
jit and other such tricks) and still keep the full
semantic including correct method dispatch.

Martin Maechler, ETH Zurich


    > On Fri, Feb 27, 2015 at 7:27 AM, Dimitri Liakhovitski <
    > dimitri.liakhovitski at gmail.com> wrote:

    >> Thank you very much, Duncan.
    >> All this being said:
    >> 
    >> What would you say is the most elegant and most safe way to solve such
    >> a seemingly simple task?
    >> 
    >> Thank you!
    >> 
    >> On Fri, Feb 27, 2015 at 10:02 AM, Duncan Murdoch
    >> <murdoch.duncan at gmail.com> wrote:
    >> > On 27/02/2015 9:49 AM, Dimitri Liakhovitski wrote:
    >> >> So, Duncan, do I understand you correctly:
    >> >>
    >> >> When I use x$x<6, R doesn't know if it's TRUE or FALSE, so it returns
    >> >> a logical value of NA.
    >> >
    >> > Yes, when x$x is NA.  (Though I think you meant x$c.)
    >> >
    >> >> When this logical value is applied to a row, the R says: hell, I don't
    >> >> know if I should keep it or not, so, just in case, I am going to keep
    >> >> it, but I'll replace all the values in this row with NAs?
    >> >
    >> > Yes.  Indexing with a logical NA is probably a mistake, and this is one
    >> > way to signal it without actually triggering a warning or error.
    >> >
    >> > BTW, I should have mentioned that the example where you indexed using
    >> > -which(x$c>=6) is a bad idea:  if none of the entries were 6 or more,
    >> > this would be indexing with an empty vector, and you'd get nothing, not
    >> > everything.
    >> >
    >> > Duncan Murdoch
    >> >
    >> >
    >> >>
    >> >> On Fri, Feb 27, 2015 at 9:13 AM, Duncan Murdoch
    >> >> <murdoch.duncan at gmail.com> wrote:
    >> >>> On 27/02/2015 9:04 AM, Dimitri Liakhovitski wrote:
    >> >>>> I know how to get the output I need, but I would benefit from an
    >> >>>> explanation why R behaves the way it does.
    >> >>>>
    >> >>>> # I have a data frame x:
    >> >>>> x = data.frame(a=1:10,b=2:11,c=c(1,NA,3,NA,5,NA,7,NA,NA,10))
    >> >>>> x
    >> >>>> # I want to toss rows in x that contain values >=6. But I don't want
    >> >>>> to toss my NAs there.
    >> >>>>
    >> >>>> subset(x,c<6) # Works correctly, but removes NAs in c, understand why
    >> >>>> x[which(x$c<6),] # Works correctly, but removes NAs in c, understand
    >> why
    >> >>>> x[-which(x$c>=6),] # output I need
    >> >>>>
    >> >>>> # Here is my question: why does the following line replace the values
    >> >>>> of all rows that contain an NA # in x$c with NAs?
    >> >>>>
    >> >>>> x[x$c<6,]  # Leaves rows with c=NA, but makes the whole row an NA.
    >> Why???
    >> >>>> x[(x$c<6) | is.na(x$c),] # output I need - I have to be
    >> super-explicit
    >> >>>>
    >> >>>> Thank you very much!
    >> >>>
    >> >>> Most of your examples (except the ones using which()) are doing logical
    >> >>> indexing.  In logical indexing, TRUE keeps a line, FALSE drops the
    >> line,
    >> >>> and NA returns NA.  Since "x$c < 6" is NA if x$c is NA, you get the
    >> >>> third kind of indexing.
    >> >>>
    >> >>> Your last example works because in the cases where x$c is NA, it
    >> >>> evaluates NA | TRUE, and that evaluates to TRUE.  In the cases where
    >> x$c
    >> >>> is not NA, you get x$c < 6 | FALSE, and that's the same as x$c < 6,
    >> >>> which will be either TRUE or FALSE.
    >> >>>
    >> >>> Duncan Murdoch
    >> >>>
    >> >>
    >> >>
    >> >>
    >> >
    >> 
    >> 
    >> 
    >> --
    >> Dimitri Liakhovitski
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide
    >> http://www.R-project.org/posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.
    >> 

    > [[alternative HTML version deleted]]

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From hank9cao at gmail.com  Mon Mar  2 16:53:44 2015
From: hank9cao at gmail.com (han cao)
Date: Mon, 2 Mar 2015 16:53:44 +0100
Subject: [Rd] Asking for tasks of summer code 2015
Message-ID: <CADp3KeaADyobvqRSrqB28u1hwsbOBhQ8RjpR5mYa3Cw+q5BNgA@mail.gmail.com>

Hey everyone:
I am a Master student from Saarland Unirversity, Germany with the major of
Bioinformatics. And I am interested in statistical learning which is also
my major work in the future with the implementation by R. So I 'd like join
the google summer code this year by doing tasks in your community. However
I can not find whether there are tasks available provided for this year,
anyone can tell me?


Hank Cao

	[[alternative HTML version deleted]]


From evansochiaga at aims.ac.za  Tue Mar  3 11:47:58 2015
From: evansochiaga at aims.ac.za (Evans Otieno Ochiaga)
Date: Tue, 3 Mar 2015 12:47:58 +0200
Subject: [Rd] Asssistance
Message-ID: <CAObCh3WeWm5E0O6cZ8zsGJEZsrVbVT2OsxMHXTi_T+=Tfe=hgg@mail.gmail.com>

Hi to All,

I am building a package in R and whenever I run command "R CMD build OAR"
in the terminal, I get the following error:

* checking for file ?OAR/DESCRIPTION? ... OK
* preparing ?OAR?:
* checking DESCRIPTION meta-information ... ERROR
Malformed Depends or Suggests or Imports or Enhances field.
Offending entries:
  R (>=3.0.2)
Entries must be names of packages optionally followed by '<=' or '>=',
white space, and a valid version number in parentheses.

See the information on DESCRIPTION files in section 'Creating R
packages' of the 'Writing R Extensions' manual.

This is my first time to build a package using R and it's very hard for me
to figure out where the problem is. I kindly call for your assistance in
fixing the problem. Below is my function;

bcidata <- read.csv("~/Desktop/Files_for_Package/data.csv"); bcidata

Modelsfunc<- function(bcidata){

  occupancymean.data.frame <- NULL

  for (k in seq(2.5,250,by=2.5)){

    i <- 1000/k

    j <- 500/k

    bcidata$Xgrid <- cut(bcidata$PX, breaks = i, include.lowest = T)

    bcidata$Ygrid <- cut(bcidata$PY, breaks = j, include.lowest = T)

    bcidata$IDgrid <- with(bcidata, interaction(Xgrid,Ygrid))

    bcidata$IDNgrid <- factor(bcidata$IDgrid)

    levels(bcidata$IDgrid) <- seq_along(levels(bcidata$IDgrid))

    bcidata$count <- ave(bcidata$PX, bcidata$IDgrid, FUN = length)

    aggregate <- aggregate(bcidata$PX,bcidata[,c("Xgrid","Ygrid","IDNgrid")],
FUN = length)

    Totalgrids <- length(levels(bcidata$IDgrid))

    Occupiedgrids <- length(aggregate$IDNgrid)

    sum <- sum(aggregate$x)

    TotalArea <- 500000

    Area <- (1000/i*500/j)

    Occupancy <- (Occupiedgrids/Totalgrids)

    Mean <- length(bcidata$Latin)/(Occupiedgrids)

    Variance <- var(aggregate$x)

    occupancymean.data.frame <- rbind(occupancymean.data.frame,
data.frame(Area, Totalgrids, Occupiedgrids, Occupancy, Mean, Variance))

  }

  occupancymean.data.frame

  Occupancy <- occupancymean.data.frame$Occupancy

  Mean <- occupancymean.data.frame$Mean

  poission <- nls(Occupancy ~ 1-exp(-rho*Mean), start = list(rho = 2.1),
data = occupancymean.data.frame)

  nachman <- nls(Occupancy ~ 1-exp(-alpha*Mean^beta), start = list(alpha =
0.2, beta = 0.1), data = occupancymean.data.frame)

  logistic <- nls(Occupancy ~ (alpha*Mean^beta)/(1+alpha*Mean^beta), start
= list(alpha = 0.2, beta = 0.1),data = occupancymean.data.frame)

  nbd <- nls(Occupancy ~ 1-(1+(Mean)/k)^-k, start = list(k = 1), data =
occupancymean.data.frame)

  power <- nls(Occupancy ~ alpha*Mean^beta, start = list(alpha = 0.2, beta=
0.1), data = occupancymean.data.frame)

  inbd <- nls(Occupancy ~
1-(alpha*(Mean^(beta-1)))^(Mean/(1-alpha*Mean^(beta-1))), start =
list(alpha = 0.2, beta = 0.3),

              data = occupancymean.data.frame)

  fnbd <- nls(Occupancy ~ 1- (gamma(N +
k/(Mean*A/N)-k)*gamma(k/(Mean*A/N)))/(gamma(k/(Mean*A/N)-k)*gamma(N+k/(Mean*A/N))),


              start = list(k = 0.2, A = 0.1, N = 0.2), data =  occupancymean
.data.frame)

  bayesianII <- nls(Occupancy ~ 1-(theta*beta^(2*(TotalArea
*Mean/sum)^0.5)*delta^(TotalArea*Mean/sum)), start = list(theta=0.9956,
beta=1, delta=1), data = occupancymean.data.frame)


  return(list(summary(poission), summary(nachman), summary(logistic),
summary(nbd),

              summary(power), summary(inbd), summary(fnbd), summary(
bayesianII)))

}

Modelsfunc(bcidata)

Your assistance will be highly appreciated. Thanks in advance.

Regards,


*Evans Ochiaga*

*African Institute for Mathematical Sciences*

*6 Melrose Road*

*Muizenberg, South Africa*

*Msc in Mathematical Sciences+27 84 61 69 183 *

*"When I cannot understand my Father?s leading, And it seems to be but hard
and cruel fate, Still I hear that gentle whisper ever pleading, God is
working, God is faithful?Only wait."*

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Mar  3 12:46:07 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 03 Mar 2015 06:46:07 -0500
Subject: [Rd] Asssistance
In-Reply-To: <CAObCh3WeWm5E0O6cZ8zsGJEZsrVbVT2OsxMHXTi_T+=Tfe=hgg@mail.gmail.com>
References: <CAObCh3WeWm5E0O6cZ8zsGJEZsrVbVT2OsxMHXTi_T+=Tfe=hgg@mail.gmail.com>
Message-ID: <54F59EFF.20409@gmail.com>

On 03/03/2015 5:47 AM, Evans Otieno Ochiaga wrote:
> Hi to All,
> 
> I am building a package in R and whenever I run command "R CMD build OAR"
> in the terminal, I get the following error:
> 
> * checking for file ?OAR/DESCRIPTION? ... OK
> * preparing ?OAR?:
> * checking DESCRIPTION meta-information ... ERROR
> Malformed Depends or Suggests or Imports or Enhances field.
> Offending entries:
>   R (>=3.0.2)
> Entries must be names of packages optionally followed by '<=' or '>=',
> white space, and a valid version number in parentheses.

That looks okay; I'm guessing it is out of place.  Can you show use your
DESCRIPTION file?

Duncan Murdoch

> 
> See the information on DESCRIPTION files in section 'Creating R
> packages' of the 'Writing R Extensions' manual.
> 
> This is my first time to build a package using R and it's very hard for me
> to figure out where the problem is. I kindly call for your assistance in
> fixing the problem. Below is my function;
> 
> bcidata <- read.csv("~/Desktop/Files_for_Package/data.csv"); bcidata
> 
> Modelsfunc<- function(bcidata){
> 
>   occupancymean.data.frame <- NULL
> 
>   for (k in seq(2.5,250,by=2.5)){
> 
>     i <- 1000/k
> 
>     j <- 500/k
> 
>     bcidata$Xgrid <- cut(bcidata$PX, breaks = i, include.lowest = T)
> 
>     bcidata$Ygrid <- cut(bcidata$PY, breaks = j, include.lowest = T)
> 
>     bcidata$IDgrid <- with(bcidata, interaction(Xgrid,Ygrid))
> 
>     bcidata$IDNgrid <- factor(bcidata$IDgrid)
> 
>     levels(bcidata$IDgrid) <- seq_along(levels(bcidata$IDgrid))
> 
>     bcidata$count <- ave(bcidata$PX, bcidata$IDgrid, FUN = length)
> 
>     aggregate <- aggregate(bcidata$PX,bcidata[,c("Xgrid","Ygrid","IDNgrid")],
> FUN = length)
> 
>     Totalgrids <- length(levels(bcidata$IDgrid))
> 
>     Occupiedgrids <- length(aggregate$IDNgrid)
> 
>     sum <- sum(aggregate$x)
> 
>     TotalArea <- 500000
> 
>     Area <- (1000/i*500/j)
> 
>     Occupancy <- (Occupiedgrids/Totalgrids)
> 
>     Mean <- length(bcidata$Latin)/(Occupiedgrids)
> 
>     Variance <- var(aggregate$x)
> 
>     occupancymean.data.frame <- rbind(occupancymean.data.frame,
> data.frame(Area, Totalgrids, Occupiedgrids, Occupancy, Mean, Variance))
> 
>   }
> 
>   occupancymean.data.frame
> 
>   Occupancy <- occupancymean.data.frame$Occupancy
> 
>   Mean <- occupancymean.data.frame$Mean
> 
>   poission <- nls(Occupancy ~ 1-exp(-rho*Mean), start = list(rho = 2.1),
> data = occupancymean.data.frame)
> 
>   nachman <- nls(Occupancy ~ 1-exp(-alpha*Mean^beta), start = list(alpha =
> 0.2, beta = 0.1), data = occupancymean.data.frame)
> 
>   logistic <- nls(Occupancy ~ (alpha*Mean^beta)/(1+alpha*Mean^beta), start
> = list(alpha = 0.2, beta = 0.1),data = occupancymean.data.frame)
> 
>   nbd <- nls(Occupancy ~ 1-(1+(Mean)/k)^-k, start = list(k = 1), data =
> occupancymean.data.frame)
> 
>   power <- nls(Occupancy ~ alpha*Mean^beta, start = list(alpha = 0.2, beta=
> 0.1), data = occupancymean.data.frame)
> 
>   inbd <- nls(Occupancy ~
> 1-(alpha*(Mean^(beta-1)))^(Mean/(1-alpha*Mean^(beta-1))), start =
> list(alpha = 0.2, beta = 0.3),
> 
>               data = occupancymean.data.frame)
> 
>   fnbd <- nls(Occupancy ~ 1- (gamma(N +
> k/(Mean*A/N)-k)*gamma(k/(Mean*A/N)))/(gamma(k/(Mean*A/N)-k)*gamma(N+k/(Mean*A/N))),
> 
> 
>               start = list(k = 0.2, A = 0.1, N = 0.2), data =  occupancymean
> .data.frame)
> 
>   bayesianII <- nls(Occupancy ~ 1-(theta*beta^(2*(TotalArea
> *Mean/sum)^0.5)*delta^(TotalArea*Mean/sum)), start = list(theta=0.9956,
> beta=1, delta=1), data = occupancymean.data.frame)
> 
> 
>   return(list(summary(poission), summary(nachman), summary(logistic),
> summary(nbd),
> 
>               summary(power), summary(inbd), summary(fnbd), summary(
> bayesianII)))
> 
> }
> 
> Modelsfunc(bcidata)
> 
> Your assistance will be highly appreciated. Thanks in advance.
> 
> Regards,
> 
> 
> *Evans Ochiaga*
> 
> *African Institute for Mathematical Sciences*
> 
> *6 Melrose Road*
> 
> *Muizenberg, South Africa*
> 
> *Msc in Mathematical Sciences+27 84 61 69 183 *
> 
> *"When I cannot understand my Father?s leading, And it seems to be but hard
> and cruel fate, Still I hear that gentle whisper ever pleading, God is
> working, God is faithful?Only wait."*
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From gregor.kastner at wu.ac.at  Tue Mar  3 12:59:56 2015
From: gregor.kastner at wu.ac.at (Gregor Kastner)
Date: Tue, 3 Mar 2015 12:59:56 +0100
Subject: [Rd] Asssistance
In-Reply-To: <CAObCh3WeWm5E0O6cZ8zsGJEZsrVbVT2OsxMHXTi_T+=Tfe=hgg@mail.gmail.com>
References: <CAObCh3WeWm5E0O6cZ8zsGJEZsrVbVT2OsxMHXTi_T+=Tfe=hgg@mail.gmail.com>
Message-ID: <20150303125956.69019035@mine>

Hi Evans,

> * checking for file ?OAR/DESCRIPTION? ... OK
> * preparing ?OAR?:
> * checking DESCRIPTION meta-information ... ERROR
> Malformed Depends or Suggests or Imports or Enhances field.
> Offending entries:
>   R (>=3.0.2)
> Entries must be names of packages optionally followed by '<=' or '>=',
> white space, and a valid version number in parentheses.

The _white space_ (see explanation above) seems to be missing.

Try "R (>= 3.0.2)"

Best,
/g


From therneau at mayo.edu  Tue Mar  3 14:05:02 2015
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Tue, 03 Mar 2015 07:05:02 -0600
Subject: [Rd] Import data set from another package?
In-Reply-To: <54F57AE2.2050906@stats.ox.ac.uk>
References: <1e7ee5$5h3fc@ironport10.mayo.edu>
	<54F57AE2.2050906@stats.ox.ac.uk>
Message-ID: <1e7ee5$5ik5k@ironport10.mayo.edu>

As I expected: there was something simple and obvious, which I somehow could not see.
Thanks for the pointer.

Terry T.


On 03/03/2015 03:12 AM, Prof Brian Ripley wrote:
> On 02/03/2015 22:48, Therneau, Terry M., Ph.D. wrote:
>> I've moved nlme from Depends to Imports in my coxme package. However, a
>> few of the examples for lmekin use one of the data sets from nlme.  This
>> is on purpose, to show how the results are the same and how they differ.
>>
>>   If I use  data(nlme::ergoStool)  the data is not found,
>> data(nlme:::ergoStool) does no better.
>>   If I add importFrom(nlme, "ergoStool") the error message is that
>> ergoStool is not exported.
>>
>> There likely is a simple way, but I currently don't see it.
>
> There were some off-the-mark suggestions in this thread.  If you just want a dataset from
> a package, use
>
> data("ergoStool", package = "nlme")
>
> In particular, it is somewhat wasteful to load a large namespace like nlme when it is not
> needed.
>
>


From claudia.beleites at ipht-jena.de  Tue Mar  3 15:34:14 2015
From: claudia.beleites at ipht-jena.de (beleites,claudia)
Date: Tue, 3 Mar 2015 14:34:14 +0000
Subject: [Rd] Asking for tasks of summer code 2015
In-Reply-To: <CADp3KeaADyobvqRSrqB28u1hwsbOBhQ8RjpR5mYa3Cw+q5BNgA@mail.gmail.com>
References: <CADp3KeaADyobvqRSrqB28u1hwsbOBhQ8RjpR5mYa3Cw+q5BNgA@mail.gmail.com>
Message-ID: <1425393254.3258.1.camel@cbdesktop>

On Mo, 2015-03-02 at 16:53 +0100, han cao wrote:
> Hey everyone:
> I am a Master student from Saarland Unirversity, Germany with the major of
> Bioinformatics. And I am interested in statistical learning which is also
> my major work in the future with the implementation by R. So I 'd like join
> the google summer code this year by doing tasks in your community. However
> I can not find whether there are tasks available provided for this year,
> anyone can tell me?

The R GSoC pages moved to GitHub:
https://github.com/rstats-gsoc/gsoc2015/wiki


Best,

Claudia

> 
> 
> Hank Cao
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jeroenooms at gmail.com  Tue Mar  3 19:43:20 2015
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Tue, 3 Mar 2015 10:43:20 -0800
Subject: [Rd] Feature request: copy attributes in gzcon
Message-ID: <CABFfbXt2ixrcz=k7STaXSBzUKqq+aprTGeKyrgw8a1f7-r0Yww@mail.gmail.com>

The `gzcon` function both modifies and copies a connection object:

  # compressed text
  con1 <- url("http://www.stats.ox.ac.uk/pub/datasets/csb/ch12.dat.gz")
  con2 <- gzcon(con1)

  # almost indistinguishable
  con1==con2
  identical(summary(con2), summary(con1))

  # both support gzip
  readLines(con1, n = 3)
  readLines(con2, n = 3)

  # opening one opens both
  isOpen(con2)
  open(con1)
  isOpen(con2)

In the example, `con1` and `con2` are two different objects
interfacing the same connection. It might seem as if gzcon has simply
returned the modified connection object, but the documentation
explains that it in fact creates a copy referencing the same
connection but with a "modified internal structure".

It is unclear to me how `con1` is different from `con2`, but given
that they represent one and the same connection, would it be possible
to make gzcon copy over attributes from the input connection to the
output object?

This would allow custom connection implementations such as the curl
package to use attributes for storing additional metadata about
connection. Currently those attributes get dropped after calling gzcon
on the connection:

  library(curl)
  con <- curl("http://www.stats.ox.ac.uk/pub/datasets/csb/ch12.dat.gz")
  attr(con, "foo") <- "bar"

  con <- gzcon(con)
  attr(con, "foo")

It would be very helpful if gzcon would instead copy attributes onto
the output object, such that any potential meta-data about the
connection as stored in attributes gets retained.


From hpages at fredhutch.org  Tue Mar  3 22:26:55 2015
From: hpages at fredhutch.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 03 Mar 2015 13:26:55 -0800
Subject: [Rd] [R] Why does R replace all row values with NAs
In-Reply-To: <21749.36060.745365.225385@stat.math.ethz.ch>
References: <CAN2xGJbe06Kqae9BCxvCMykeDjt5oJfdPAGuXWV_vd-uCLQJNw@mail.gmail.com>	<54F07B99.90005@gmail.com>	<CAN2xGJYmhkJmndSBVBL3WD+hEBFVKLhUGDDX_oi2WOQt+uDTiQ@mail.gmail.com>	<54F086EA.7020800@gmail.com>	<CAN2xGJauN=swX6P0WHzH+bsEcobCn24_z0pJWr64D5p-UBwVHg@mail.gmail.com>	<CAF8bMcYrPtnLpvOfa17ZthjhSkp3L8KbFcy5uMv+sf-m+5X3UA@mail.gmail.com>
	<21749.36060.745365.225385@stat.math.ethz.ch>
Message-ID: <54F6271F.9030801@fredhutch.org>



On 03/03/2015 02:28 AM, Martin Maechler wrote:
> Diverted from R-help :
> .... as it gets into musing about new R language "primitives"
>
>>>>>> William Dunlap <wdunlap at tibco.com>
>>>>>>      on Fri, 27 Feb 2015 08:04:36 -0800 writes:
>
>      > You could define functions like
>
>      > is.true <- function(x) !is.na(x) & x
>      > is.false <- function(x) !is.na(x) & !x
>
>      > and use them in your selections.  E.g.,
>      >> x <- data.frame(a=1:10,b=2:11,c=c(1,NA,3,NA,5,NA,7,NA,NA,10))
>      >> x[is.true(x$c >= 6), ]
>      > a  b  c
>      > 7   7  8  7
>      > 10 10 11 10
>
>      > Bill Dunlap
>      > TIBCO Software
>      > wdunlap tibco.com
>
> Yes; the Matrix package has had these
>
> is0  <- function(x) !is.na(x) & x == 0
> isN0 <- function(x)  is.na(x) | x != 0
> is1  <- function(x) !is.na(x) & x   # also == "isTRUE componentwise"

Note that using %in% to block propagation of NAs is about 2x faster:

 > x <- sample(c(NA_integer_, 1:10000), 500000, replace=TRUE)
 > microbenchmark(as.logical(x) %in% TRUE, !is.na(x) & x)
Unit: milliseconds
                     expr       min        lq      mean   median        uq
  as.logical(x) %in% TRUE  6.034744  6.264382  6.999083  6.29488  6.346028
            !is.na(x) & x 11.202808 11.402437 11.469101 11.44848 11.517576
       max neval
  40.36472   100
  11.90916   100



>
> namespace hidden for a while  [note the comment of the last one!]
> and using them for readibility in its own code.
>
> Maybe we should (again) consider providing some versions of
> these with R ?
>
> The Matrix package also has had fast
>
> allFalse <- all0 <- function(x) .Call(R_all0, x)
> anyFalse <- any0 <- function(x) .Call(R_any0, x)
> ##
> ## anyFalse <- function(x) isTRUE(any(!x))		 ## ~= any0
> ## any0 <- function(x) isTRUE(any(x == 0))	      ## ~= anyFalse
>
> namespace hidden as well, already, which probably could also be
> brought to base R.
>
> One big reason to *not* go there (to internal C code) at all with R is that
> S3 and S4 dispatch for '==' ('!=', etc, the 'Compare' group generics)
> and 'is.na() have been known and package writers have
> programmed methods for these.
> To ensure that S3 and S4 dispatch works "correctly" also inside
> such new internals is much less easily achieved, and so
> such a C-based internal function  is0() would no longer be
> equivalent with    !is.na(x) & x == 0
> as soon as 'x' is an "object" with a '==', 'Compare' and/or an is.na() method.

Excellent point. Thank you! It really makes a big difference for 
developers who maintain a complex hierarchy of S4 classes and methods,
when functions like is.true, anyFalse, etc..., which can be expressed in
terms of more basic operations like ==, !=, !, is.na, etc..., just work
out-of-the-box on objects for which these basic operations are defined.

There is conceptually a small set of "building blocks", at least for
objects with a vector-like or list-like semantic, that can be used
to formally describe the semantic of many functions in base R. This
is what the man page for anyNA does by saying:

   anyNA implements any(is.na(x))

even though the actual implementation differs, but that's ok, as long
as anyNA is equivalent to doing any(is.na(x)) on any object for which
building block is.na() is implemented.

Unfortunately there is no clearly identified set of building blocks
in base R. For example, if I want the comparison operations to work
on my object, I need to implement ==, >, <, !=, <=, and >= (the
'Compare' group generics) even though it should be enough to implement
== and >=, because all the others can be described in terms of these
2 building blocks. unique/duplicated is another example (unique(x) is
conceptually x[!duplicated(x)]). And so on...

Cheers,
H.

>
> OTOH, simple R versions such as your  'is.true',  called 'is1'
> inside Matrix maybe optimizable a bit by the byte compiler (and
> jit and other such tricks) and still keep the full
> semantic including correct method dispatch.
>
> Martin Maechler, ETH Zurich
>
>
>      > On Fri, Feb 27, 2015 at 7:27 AM, Dimitri Liakhovitski <
>      > dimitri.liakhovitski at gmail.com> wrote:
>
>      >> Thank you very much, Duncan.
>      >> All this being said:
>      >>
>      >> What would you say is the most elegant and most safe way to solve such
>      >> a seemingly simple task?
>      >>
>      >> Thank you!
>      >>
>      >> On Fri, Feb 27, 2015 at 10:02 AM, Duncan Murdoch
>      >> <murdoch.duncan at gmail.com> wrote:
>      >> > On 27/02/2015 9:49 AM, Dimitri Liakhovitski wrote:
>      >> >> So, Duncan, do I understand you correctly:
>      >> >>
>      >> >> When I use x$x<6, R doesn't know if it's TRUE or FALSE, so it returns
>      >> >> a logical value of NA.
>      >> >
>      >> > Yes, when x$x is NA.  (Though I think you meant x$c.)
>      >> >
>      >> >> When this logical value is applied to a row, the R says: hell, I don't
>      >> >> know if I should keep it or not, so, just in case, I am going to keep
>      >> >> it, but I'll replace all the values in this row with NAs?
>      >> >
>      >> > Yes.  Indexing with a logical NA is probably a mistake, and this is one
>      >> > way to signal it without actually triggering a warning or error.
>      >> >
>      >> > BTW, I should have mentioned that the example where you indexed using
>      >> > -which(x$c>=6) is a bad idea:  if none of the entries were 6 or more,
>      >> > this would be indexing with an empty vector, and you'd get nothing, not
>      >> > everything.
>      >> >
>      >> > Duncan Murdoch
>      >> >
>      >> >
>      >> >>
>      >> >> On Fri, Feb 27, 2015 at 9:13 AM, Duncan Murdoch
>      >> >> <murdoch.duncan at gmail.com> wrote:
>      >> >>> On 27/02/2015 9:04 AM, Dimitri Liakhovitski wrote:
>      >> >>>> I know how to get the output I need, but I would benefit from an
>      >> >>>> explanation why R behaves the way it does.
>      >> >>>>
>      >> >>>> # I have a data frame x:
>      >> >>>> x = data.frame(a=1:10,b=2:11,c=c(1,NA,3,NA,5,NA,7,NA,NA,10))
>      >> >>>> x
>      >> >>>> # I want to toss rows in x that contain values >=6. But I don't want
>      >> >>>> to toss my NAs there.
>      >> >>>>
>      >> >>>> subset(x,c<6) # Works correctly, but removes NAs in c, understand why
>      >> >>>> x[which(x$c<6),] # Works correctly, but removes NAs in c, understand
>      >> why
>      >> >>>> x[-which(x$c>=6),] # output I need
>      >> >>>>
>      >> >>>> # Here is my question: why does the following line replace the values
>      >> >>>> of all rows that contain an NA # in x$c with NAs?
>      >> >>>>
>      >> >>>> x[x$c<6,]  # Leaves rows with c=NA, but makes the whole row an NA.
>      >> Why???
>      >> >>>> x[(x$c<6) | is.na(x$c),] # output I need - I have to be
>      >> super-explicit
>      >> >>>>
>      >> >>>> Thank you very much!
>      >> >>>
>      >> >>> Most of your examples (except the ones using which()) are doing logical
>      >> >>> indexing.  In logical indexing, TRUE keeps a line, FALSE drops the
>      >> line,
>      >> >>> and NA returns NA.  Since "x$c < 6" is NA if x$c is NA, you get the
>      >> >>> third kind of indexing.
>      >> >>>
>      >> >>> Your last example works because in the cases where x$c is NA, it
>      >> >>> evaluates NA | TRUE, and that evaluates to TRUE.  In the cases where
>      >> x$c
>      >> >>> is not NA, you get x$c < 6 | FALSE, and that's the same as x$c < 6,
>      >> >>> which will be either TRUE or FALSE.
>      >> >>>
>      >> >>> Duncan Murdoch
>      >> >>>
>      >> >>
>      >> >>
>      >> >>
>      >> >
>      >>
>      >>
>      >>
>      >> --
>      >> Dimitri Liakhovitski
>      >>
>      >> ______________________________________________
>      >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>      >> https://stat.ethz.ch/mailman/listinfo/r-help
>      >> PLEASE do read the posting guide
>      >> http://www.R-project.org/posting-guide.html
>      >> and provide commented, minimal, self-contained, reproducible code.
>      >>
>
>      > [[alternative HTML version deleted]]
>
>      > ______________________________________________
>      > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>      > https://stat.ethz.ch/mailman/listinfo/r-help
>      > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>      > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From sdmorris at u.washington.edu  Tue Mar  3 23:09:59 2015
From: sdmorris at u.washington.edu (Stephanie M. Gogarten)
Date: Tue, 03 Mar 2015 14:09:59 -0800
Subject: [Rd] [R] Why does R replace all row values with NAs
In-Reply-To: <54F6271F.9030801@fredhutch.org>
References: <CAN2xGJbe06Kqae9BCxvCMykeDjt5oJfdPAGuXWV_vd-uCLQJNw@mail.gmail.com>	<54F07B99.90005@gmail.com>	<CAN2xGJYmhkJmndSBVBL3WD+hEBFVKLhUGDDX_oi2WOQt+uDTiQ@mail.gmail.com>	<54F086EA.7020800@gmail.com>	<CAN2xGJauN=swX6P0WHzH+bsEcobCn24_z0pJWr64D5p-UBwVHg@mail.gmail.com>	<CAF8bMcYrPtnLpvOfa17ZthjhSkp3L8KbFcy5uMv+sf-m+5X3UA@mail.gmail.com>	<21749.36060.745365.225385@stat.math.ethz.ch>
	<54F6271F.9030801@fredhutch.org>
Message-ID: <54F63137.5060903@u.washington.edu>



On 3/3/15 1:26 PM, Herv? Pag?s wrote:
>
>
> On 03/03/2015 02:28 AM, Martin Maechler wrote:
>> Diverted from R-help :
>> .... as it gets into musing about new R language "primitives"
>>
>>>>>>> William Dunlap <wdunlap at tibco.com>
>>>>>>>      on Fri, 27 Feb 2015 08:04:36 -0800 writes:
>>
>>      > You could define functions like
>>
>>      > is.true <- function(x) !is.na(x) & x
>>      > is.false <- function(x) !is.na(x) & !x
>>
>>      > and use them in your selections.  E.g.,
>>      >> x <- data.frame(a=1:10,b=2:11,c=c(1,NA,3,NA,5,NA,7,NA,NA,10))
>>      >> x[is.true(x$c >= 6), ]
>>      > a  b  c
>>      > 7   7  8  7
>>      > 10 10 11 10
>>
>>      > Bill Dunlap
>>      > TIBCO Software
>>      > wdunlap tibco.com
>>
>> Yes; the Matrix package has had these
>>
>> is0  <- function(x) !is.na(x) & x == 0
>> isN0 <- function(x)  is.na(x) | x != 0
>> is1  <- function(x) !is.na(x) & x   # also == "isTRUE componentwise"
>
> Note that using %in% to block propagation of NAs is about 2x faster:
>
>  > x <- sample(c(NA_integer_, 1:10000), 500000, replace=TRUE)
>  > microbenchmark(as.logical(x) %in% TRUE, !is.na(x) & x)
> Unit: milliseconds
>                      expr       min        lq      mean   median        uq
>   as.logical(x) %in% TRUE  6.034744  6.264382  6.999083  6.29488  6.346028
>             !is.na(x) & x 11.202808 11.402437 11.469101 11.44848 11.517576
>        max neval
>   40.36472   100
>   11.90916   100

Unfortunately %in% does not preserve matrix dimensions:

 > x <- matrix(sample(c(NA_integer_, 1:100), 500, replace=TRUE), nrow=50)
 > dim(x)
[1] 50 10
 > dim(!is.na(x) & x)
[1] 50 10
 > dim(as.logical(x) %in% TRUE)
NULL

Stephanie

>
>
>
>>
>> namespace hidden for a while  [note the comment of the last one!]
>> and using them for readibility in its own code.
>>
>> Maybe we should (again) consider providing some versions of
>> these with R ?
>>
>> The Matrix package also has had fast
>>
>> allFalse <- all0 <- function(x) .Call(R_all0, x)
>> anyFalse <- any0 <- function(x) .Call(R_any0, x)
>> ##
>> ## anyFalse <- function(x) isTRUE(any(!x))         ## ~= any0
>> ## any0 <- function(x) isTRUE(any(x == 0))          ## ~= anyFalse
>>
>> namespace hidden as well, already, which probably could also be
>> brought to base R.
>>
>> One big reason to *not* go there (to internal C code) at all with R is
>> that
>> S3 and S4 dispatch for '==' ('!=', etc, the 'Compare' group generics)
>> and 'is.na() have been known and package writers have
>> programmed methods for these.
>> To ensure that S3 and S4 dispatch works "correctly" also inside
>> such new internals is much less easily achieved, and so
>> such a C-based internal function  is0() would no longer be
>> equivalent with    !is.na(x) & x == 0
>> as soon as 'x' is an "object" with a '==', 'Compare' and/or an is.na()
>> method.
>
> Excellent point. Thank you! It really makes a big difference for
> developers who maintain a complex hierarchy of S4 classes and methods,
> when functions like is.true, anyFalse, etc..., which can be expressed in
> terms of more basic operations like ==, !=, !, is.na, etc..., just work
> out-of-the-box on objects for which these basic operations are defined.
>
> There is conceptually a small set of "building blocks", at least for
> objects with a vector-like or list-like semantic, that can be used
> to formally describe the semantic of many functions in base R. This
> is what the man page for anyNA does by saying:
>
>    anyNA implements any(is.na(x))
>
> even though the actual implementation differs, but that's ok, as long
> as anyNA is equivalent to doing any(is.na(x)) on any object for which
> building block is.na() is implemented.
>
> Unfortunately there is no clearly identified set of building blocks
> in base R. For example, if I want the comparison operations to work
> on my object, I need to implement ==, >, <, !=, <=, and >= (the
> 'Compare' group generics) even though it should be enough to implement
> == and >=, because all the others can be described in terms of these
> 2 building blocks. unique/duplicated is another example (unique(x) is
> conceptually x[!duplicated(x)]). And so on...
>
> Cheers,
> H.
>
>>
>> OTOH, simple R versions such as your  'is.true',  called 'is1'
>> inside Matrix maybe optimizable a bit by the byte compiler (and
>> jit and other such tricks) and still keep the full
>> semantic including correct method dispatch.
>>
>> Martin Maechler, ETH Zurich
>>
>>
>>      > On Fri, Feb 27, 2015 at 7:27 AM, Dimitri Liakhovitski <
>>      > dimitri.liakhovitski at gmail.com> wrote:
>>
>>      >> Thank you very much, Duncan.
>>      >> All this being said:
>>      >>
>>      >> What would you say is the most elegant and most safe way to
>> solve such
>>      >> a seemingly simple task?
>>      >>
>>      >> Thank you!
>>      >>
>>      >> On Fri, Feb 27, 2015 at 10:02 AM, Duncan Murdoch
>>      >> <murdoch.duncan at gmail.com> wrote:
>>      >> > On 27/02/2015 9:49 AM, Dimitri Liakhovitski wrote:
>>      >> >> So, Duncan, do I understand you correctly:
>>      >> >>
>>      >> >> When I use x$x<6, R doesn't know if it's TRUE or FALSE, so
>> it returns
>>      >> >> a logical value of NA.
>>      >> >
>>      >> > Yes, when x$x is NA.  (Though I think you meant x$c.)
>>      >> >
>>      >> >> When this logical value is applied to a row, the R says:
>> hell, I don't
>>      >> >> know if I should keep it or not, so, just in case, I am
>> going to keep
>>      >> >> it, but I'll replace all the values in this row with NAs?
>>      >> >
>>      >> > Yes.  Indexing with a logical NA is probably a mistake, and
>> this is one
>>      >> > way to signal it without actually triggering a warning or
>> error.
>>      >> >
>>      >> > BTW, I should have mentioned that the example where you
>> indexed using
>>      >> > -which(x$c>=6) is a bad idea:  if none of the entries were 6
>> or more,
>>      >> > this would be indexing with an empty vector, and you'd get
>> nothing, not
>>      >> > everything.
>>      >> >
>>      >> > Duncan Murdoch
>>      >> >
>>      >> >
>>      >> >>
>>      >> >> On Fri, Feb 27, 2015 at 9:13 AM, Duncan Murdoch
>>      >> >> <murdoch.duncan at gmail.com> wrote:
>>      >> >>> On 27/02/2015 9:04 AM, Dimitri Liakhovitski wrote:
>>      >> >>>> I know how to get the output I need, but I would benefit
>> from an
>>      >> >>>> explanation why R behaves the way it does.
>>      >> >>>>
>>      >> >>>> # I have a data frame x:
>>      >> >>>> x = data.frame(a=1:10,b=2:11,c=c(1,NA,3,NA,5,NA,7,NA,NA,10))
>>      >> >>>> x
>>      >> >>>> # I want to toss rows in x that contain values >=6. But I
>> don't want
>>      >> >>>> to toss my NAs there.
>>      >> >>>>
>>      >> >>>> subset(x,c<6) # Works correctly, but removes NAs in c,
>> understand why
>>      >> >>>> x[which(x$c<6),] # Works correctly, but removes NAs in c,
>> understand
>>      >> why
>>      >> >>>> x[-which(x$c>=6),] # output I need
>>      >> >>>>
>>      >> >>>> # Here is my question: why does the following line
>> replace the values
>>      >> >>>> of all rows that contain an NA # in x$c with NAs?
>>      >> >>>>
>>      >> >>>> x[x$c<6,]  # Leaves rows with c=NA, but makes the whole
>> row an NA.
>>      >> Why???
>>      >> >>>> x[(x$c<6) | is.na(x$c),] # output I need - I have to be
>>      >> super-explicit
>>      >> >>>>
>>      >> >>>> Thank you very much!
>>      >> >>>
>>      >> >>> Most of your examples (except the ones using which()) are
>> doing logical
>>      >> >>> indexing.  In logical indexing, TRUE keeps a line, FALSE
>> drops the
>>      >> line,
>>      >> >>> and NA returns NA.  Since "x$c < 6" is NA if x$c is NA,
>> you get the
>>      >> >>> third kind of indexing.
>>      >> >>>
>>      >> >>> Your last example works because in the cases where x$c is
>> NA, it
>>      >> >>> evaluates NA | TRUE, and that evaluates to TRUE.  In the
>> cases where
>>      >> x$c
>>      >> >>> is not NA, you get x$c < 6 | FALSE, and that's the same as
>> x$c < 6,
>>      >> >>> which will be either TRUE or FALSE.
>>      >> >>>
>>      >> >>> Duncan Murdoch
>>      >> >>>
>>      >> >>
>>      >> >>
>>      >> >>
>>      >> >
>>      >>
>>      >>
>>      >>
>>      >> --
>>      >> Dimitri Liakhovitski
>>      >>
>>      >> ______________________________________________
>>      >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>      >> https://stat.ethz.ch/mailman/listinfo/r-help
>>      >> PLEASE do read the posting guide
>>      >> http://www.R-project.org/posting-guide.html
>>      >> and provide commented, minimal, self-contained, reproducible
>> code.
>>      >>
>>
>>      > [[alternative HTML version deleted]]
>>
>>      > ______________________________________________
>>      > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>      > https://stat.ethz.ch/mailman/listinfo/r-help
>>      > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>      > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From gmbecker at ucdavis.edu  Tue Mar  3 23:17:00 2015
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Tue, 3 Mar 2015 14:17:00 -0800
Subject: [Rd] [R] Why does R replace all row values with NAs
In-Reply-To: <54F63137.5060903@u.washington.edu>
References: <CAN2xGJbe06Kqae9BCxvCMykeDjt5oJfdPAGuXWV_vd-uCLQJNw@mail.gmail.com>
	<54F07B99.90005@gmail.com>
	<CAN2xGJYmhkJmndSBVBL3WD+hEBFVKLhUGDDX_oi2WOQt+uDTiQ@mail.gmail.com>
	<54F086EA.7020800@gmail.com>
	<CAN2xGJauN=swX6P0WHzH+bsEcobCn24_z0pJWr64D5p-UBwVHg@mail.gmail.com>
	<CAF8bMcYrPtnLpvOfa17ZthjhSkp3L8KbFcy5uMv+sf-m+5X3UA@mail.gmail.com>
	<21749.36060.745365.225385@stat.math.ethz.ch>
	<54F6271F.9030801@fredhutch.org>
	<54F63137.5060903@u.washington.edu>
Message-ID: <CADwqtCOYxeK-QwkXPhhaeWyT-GAvrem6EW=ezzH6qFKMG+4i9Q@mail.gmail.com>

Stephanie,

Actually, it's as.logical that isn't preserving matrix dimensions, because
it coerces to a logical vector:

> x <- matrix(sample(c(NA_integer_, 1:100), 500, replace=TRUE), nrow=50)
> dim(as.logical(x))
NULL

~G

On Tue, Mar 3, 2015 at 2:09 PM, Stephanie M. Gogarten <
sdmorris at u.washington.edu> wrote:

>
>
> On 3/3/15 1:26 PM, Herv? Pag?s wrote:
>
>>
>>
>> On 03/03/2015 02:28 AM, Martin Maechler wrote:
>>
>>> Diverted from R-help :
>>> .... as it gets into musing about new R language "primitives"
>>>
>>>  William Dunlap <wdunlap at tibco.com>
>>>>>>>>      on Fri, 27 Feb 2015 08:04:36 -0800 writes:
>>>>>>>>
>>>>>>>
>>>      > You could define functions like
>>>
>>>      > is.true <- function(x) !is.na(x) & x
>>>      > is.false <- function(x) !is.na(x) & !x
>>>
>>>      > and use them in your selections.  E.g.,
>>>      >> x <- data.frame(a=1:10,b=2:11,c=c(1,NA,3,NA,5,NA,7,NA,NA,10))
>>>      >> x[is.true(x$c >= 6), ]
>>>      > a  b  c
>>>      > 7   7  8  7
>>>      > 10 10 11 10
>>>
>>>      > Bill Dunlap
>>>      > TIBCO Software
>>>      > wdunlap tibco.com
>>>
>>> Yes; the Matrix package has had these
>>>
>>> is0  <- function(x) !is.na(x) & x == 0
>>> isN0 <- function(x)  is.na(x) | x != 0
>>> is1  <- function(x) !is.na(x) & x   # also == "isTRUE componentwise"
>>>
>>
>> Note that using %in% to block propagation of NAs is about 2x faster:
>>
>>  > x <- sample(c(NA_integer_, 1:10000), 500000, replace=TRUE)
>>  > microbenchmark(as.logical(x) %in% TRUE, !is.na(x) & x)
>> Unit: milliseconds
>>                      expr       min        lq      mean   median        uq
>>   as.logical(x) %in% TRUE  6.034744  6.264382  6.999083  6.29488  6.346028
>>             !is.na(x) & x 11.202808 11.402437 11.469101 11.44848
>> 11.517576
>>        max neval
>>   40.36472 100
>>   11.90916   100
>>
>
> Unfortunately %in% does not preserve matrix dimensions:
>
> > x <- matrix(sample(c(NA_integer_, 1:100), 500, replace=TRUE), nrow=50)
> > dim(x)
> [1] 50 10
> > dim(!is.na(x) & x)
> [1] 50 10
> > dim(as.logical(x) %in% TRUE)
> NULL
>
> Stephanie
>
>
>
>>
>>
>>
>>> namespace hidden for a while  [note the comment of the last one!]
>>> and using them for readibility in its own code.
>>>
>>> Maybe we should (again) consider providing some versions of
>>> these with R ?
>>>
>>> The Matrix package also has had fast
>>>
>>> allFalse <- all0 <- function(x) .Call(R_all0, x)
>>> anyFalse <- any0 <- function(x) .Call(R_any0, x)
>>> ##
>>> ## anyFalse <- function(x) isTRUE(any(!x))         ## ~= any0
>>> ## any0 <- function(x) isTRUE(any(x == 0))          ## ~= anyFalse
>>>
>>> namespace hidden as well, already, which probably could also be
>>> brought to base R.
>>>
>>> One big reason to *not* go there (to internal C code) at all with R is
>>> that
>>> S3 and S4 dispatch for '==' ('!=', etc, the 'Compare' group generics)
>>> and 'is.na() have been known and package writers have
>>> programmed methods for these.
>>> To ensure that S3 and S4 dispatch works "correctly" also inside
>>> such new internals is much less easily achieved, and so
>>> such a C-based internal function  is0() would no longer be
>>> equivalent with    !is.na(x) & x == 0
>>> as soon as 'x' is an "object" with a '==', 'Compare' and/or an is.na()
>>> method.
>>>
>>
>> Excellent point. Thank you! It really makes a big difference for
>> developers who maintain a complex hierarchy of S4 classes and methods,
>> when functions like is.true, anyFalse, etc..., which can be expressed in
>> terms of more basic operations like ==, !=, !, is.na, etc..., just work
>> out-of-the-box on objects for which these basic operations are defined.
>>
>> There is conceptually a small set of "building blocks", at least for
>> objects with a vector-like or list-like semantic, that can be used
>> to formally describe the semantic of many functions in base R. This
>> is what the man page for anyNA does by saying:
>>
>>    anyNA implements any(is.na(x))
>>
>> even though the actual implementation differs, but that's ok, as long
>> as anyNA is equivalent to doing any(is.na(x)) on any object for which
>> building block is.na() is implemented.
>>
>> Unfortunately there is no clearly identified set of building blocks
>> in base R. For example, if I want the comparison operations to work
>> on my object, I need to implement ==, >, <, !=, <=, and >= (the
>> 'Compare' group generics) even though it should be enough to implement
>> == and >=, because all the others can be described in terms of these
>> 2 building blocks. unique/duplicated is another example (unique(x) is
>> conceptually x[!duplicated(x)]). And so on...
>>
>> Cheers,
>> H.
>>
>>
>>> OTOH, simple R versions such as your  'is.true',  called 'is1'
>>> inside Matrix maybe optimizable a bit by the byte compiler (and
>>> jit and other such tricks) and still keep the full
>>> semantic including correct method dispatch.
>>>
>>> Martin Maechler, ETH Zurich
>>>
>>>
>>>      > On Fri, Feb 27, 2015 at 7:27 AM, Dimitri Liakhovitski <
>>>      > dimitri.liakhovitski at gmail.com> wrote:
>>>
>>>      >> Thank you very much, Duncan.
>>>      >> All this being said:
>>>      >>
>>>      >> What would you say is the most elegant and most safe way to
>>> solve such
>>>      >> a seemingly simple task?
>>>      >>
>>>      >> Thank you!
>>>      >>
>>>      >> On Fri, Feb 27, 2015 at 10:02 AM, Duncan Murdoch
>>>      >> <murdoch.duncan at gmail.com> wrote:
>>>      >> > On 27/02/2015 9:49 AM, Dimitri Liakhovitski wrote:
>>>      >> >> So, Duncan, do I understand you correctly:
>>>      >> >>
>>>      >> >> When I use x$x<6, R doesn't know if it's TRUE or FALSE, so
>>> it returns
>>>      >> >> a logical value of NA.
>>>      >> >
>>>      >> > Yes, when x$x is NA.  (Though I think you meant x$c.)
>>>      >> >
>>>      >> >> When this logical value is applied to a row, the R says:
>>> hell, I don't
>>>      >> >> know if I should keep it or not, so, just in case, I am
>>> going to keep
>>>      >> >> it, but I'll replace all the values in this row with NAs?
>>>      >> >
>>>      >> > Yes.  Indexing with a logical NA is probably a mistake, and
>>> this is one
>>>      >> > way to signal it without actually triggering a warning or
>>> error.
>>>      >> >
>>>      >> > BTW, I should have mentioned that the example where you
>>> indexed using
>>>      >> > -which(x$c>=6) is a bad idea:  if none of the entries were 6
>>> or more,
>>>      >> > this would be indexing with an empty vector, and you'd get
>>> nothing, not
>>>      >> > everything.
>>>      >> >
>>>      >> > Duncan Murdoch
>>>      >> >
>>>      >> >
>>>      >> >>
>>>      >> >> On Fri, Feb 27, 2015 at 9:13 AM, Duncan Murdoch
>>>      >> >> <murdoch.duncan at gmail.com> wrote:
>>>      >> >>> On 27/02/2015 9:04 AM, Dimitri Liakhovitski wrote:
>>>      >> >>>> I know how to get the output I need, but I would benefit
>>> from an
>>>      >> >>>> explanation why R behaves the way it does.
>>>      >> >>>>
>>>      >> >>>> # I have a data frame x:
>>>      >> >>>> x = data.frame(a=1:10,b=2:11,c=c(
>>> 1,NA,3,NA,5,NA,7,NA,NA,10))
>>>      >> >>>> x
>>>      >> >>>> # I want to toss rows in x that contain values >=6. But I
>>> don't want
>>>      >> >>>> to toss my NAs there.
>>>      >> >>>>
>>>      >> >>>> subset(x,c<6) # Works correctly, but removes NAs in c,
>>> understand why
>>>      >> >>>> x[which(x$c<6),] # Works correctly, but removes NAs in c,
>>> understand
>>>      >> why
>>>      >> >>>> x[-which(x$c>=6),] # output I need
>>>      >> >>>>
>>>      >> >>>> # Here is my question: why does the following line
>>> replace the values
>>>      >> >>>> of all rows that contain an NA # in x$c with NAs?
>>>      >> >>>>
>>>      >> >>>> x[x$c<6,]  # Leaves rows with c=NA, but makes the whole
>>> row an NA.
>>>      >> Why???
>>>      >> >>>> x[(x$c<6) | is.na(x$c),] # output I need - I have to be
>>>      >> super-explicit
>>>      >> >>>>
>>>      >> >>>> Thank you very much!
>>>      >> >>>
>>>      >> >>> Most of your examples (except the ones using which()) are
>>> doing logical
>>>      >> >>> indexing.  In logical indexing, TRUE keeps a line, FALSE
>>> drops the
>>>      >> line,
>>>      >> >>> and NA returns NA.  Since "x$c < 6" is NA if x$c is NA,
>>> you get the
>>>      >> >>> third kind of indexing.
>>>      >> >>>
>>>      >> >>> Your last example works because in the cases where x$c is
>>> NA, it
>>>      >> >>> evaluates NA | TRUE, and that evaluates to TRUE.  In the
>>> cases where
>>>      >> x$c
>>>      >> >>> is not NA, you get x$c < 6 | FALSE, and that's the same as
>>> x$c < 6,
>>>      >> >>> which will be either TRUE or FALSE.
>>>      >> >>>
>>>      >> >>> Duncan Murdoch
>>>      >> >>>
>>>      >> >>
>>>      >> >>
>>>      >> >>
>>>      >> >
>>>      >>
>>>      >>
>>>      >>
>>>      >> --
>>>      >> Dimitri Liakhovitski
>>>      >>
>>>      >> ______________________________________________
>>>      >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>> see
>>>      >> https://stat.ethz.ch/mailman/listinfo/r-help
>>>      >> PLEASE do read the posting guide
>>>      >> http://www.R-project.org/posting-guide.html
>>>      >> and provide commented, minimal, self-contained, reproducible
>>> code.
>>>      >>
>>>
>>>      > [[alternative HTML version deleted]]
>>>
>>>      > ______________________________________________
>>>      > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>      > https://stat.ethz.ch/mailman/listinfo/r-help
>>>      > PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>      > and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Gabriel Becker, PhD
Computational Biologist
Bioinformatics and Computational Biology
Genentech, Inc.

	[[alternative HTML version deleted]]


From hpages at fredhutch.org  Tue Mar  3 23:26:25 2015
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Tue, 03 Mar 2015 14:26:25 -0800
Subject: [Rd] [R] Why does R replace all row values with NAs
In-Reply-To: <CADwqtCOYxeK-QwkXPhhaeWyT-GAvrem6EW=ezzH6qFKMG+4i9Q@mail.gmail.com>
References: <CAN2xGJbe06Kqae9BCxvCMykeDjt5oJfdPAGuXWV_vd-uCLQJNw@mail.gmail.com>	<54F07B99.90005@gmail.com>	<CAN2xGJYmhkJmndSBVBL3WD+hEBFVKLhUGDDX_oi2WOQt+uDTiQ@mail.gmail.com>	<54F086EA.7020800@gmail.com>	<CAN2xGJauN=swX6P0WHzH+bsEcobCn24_z0pJWr64D5p-UBwVHg@mail.gmail.com>	<CAF8bMcYrPtnLpvOfa17ZthjhSkp3L8KbFcy5uMv+sf-m+5X3UA@mail.gmail.com>	<21749.36060.745365.225385@stat.math.ethz.ch>	<54F6271F.9030801@fredhutch.org>	<54F63137.5060903@u.washington.edu>
	<CADwqtCOYxeK-QwkXPhhaeWyT-GAvrem6EW=ezzH6qFKMG+4i9Q@mail.gmail.com>
Message-ID: <54F63511.9010007@fredhutch.org>



On 03/03/2015 02:17 PM, Gabriel Becker wrote:
> Stephanie,
>
> Actually, it's as.logical that isn't preserving matrix dimensions,
> because it coerces to a logical vector:
>
>  > x <- matrix(sample(c(NA_integer_, 1:100), 500, replace=TRUE), nrow=50)
>  > dim(as.logical(x))

It's true, as.logical() doesn't help here but Stephanie is right, %in%
does not preserve the dimensions either:

 > dim(x %in% 1:5)
NULL

That's because match() itself doesn't preserve the dimensions:

 > dim(match(x, 1:5))
NULL

So maybe my fast is.true() should be:

is.true <- function(x)
{
   ans <- as.logical(x) %in% TRUE
   if (is.null(dim(x))) {
     names(ans) <- names(x)
   } else {
     dim(ans) <- dim(x)
     dimnames(ans) <- dimnames(x)
   }
   ans
}

or something like that...

H.

> NULL
>
> ~G
>
> On Tue, Mar 3, 2015 at 2:09 PM, Stephanie M. Gogarten
> <sdmorris at u.washington.edu <mailto:sdmorris at u.washington.edu>> wrote:
>
>
>
>     On 3/3/15 1:26 PM, Herv? Pag?s wrote:
>
>
>
>         On 03/03/2015 02:28 AM, Martin Maechler wrote:
>
>             Diverted from R-help :
>             .... as it gets into musing about new R language "primitives"
>
>                                 William Dunlap <wdunlap at tibco.com
>                                 <mailto:wdunlap at tibco.com>>
>                                       on Fri, 27 Feb 2015 08:04:36 -0800
>                                 writes:
>
>
>                   > You could define functions like
>
>                   > is.true <- function(x) !is.na <http://is.na>(x) & x
>                   > is.false <- function(x) !is.na <http://is.na>(x) & !x
>
>                   > and use them in your selections.  E.g.,
>                   >> x <-
>             data.frame(a=1:10,b=2:11,c=c(__1,NA,3,NA,5,NA,7,NA,NA,10))
>                   >> x[is.true(x$c >= 6), ]
>                   > a  b  c
>                   > 7   7  8  7
>                   > 10 10 11 10
>
>                   > Bill Dunlap
>                   > TIBCO Software
>                   > wdunlap tibco.com <http://tibco.com>
>
>             Yes; the Matrix package has had these
>
>             is0  <- function(x) !is.na <http://is.na>(x) & x == 0
>             isN0 <- function(x) is.na <http://is.na>(x) | x != 0
>             is1  <- function(x) !is.na <http://is.na>(x) & x   # also ==
>             "isTRUE componentwise"
>
>
>         Note that using %in% to block propagation of NAs is about 2x faster:
>
>           > x <- sample(c(NA_integer_, 1:10000), 500000, replace=TRUE)
>           > microbenchmark(as.logical(x) %in% TRUE, !is.na
>         <http://is.na>(x) & x)
>         Unit: milliseconds
>                               expr       min        lq      mean
>           median        uq
>            as.logical(x) %in% TRUE  6.034744  6.264382  6.999083
>         6.29488  6.346028
>                      !is.na <http://is.na>(x) & x 11.202808 11.402437
>         11.469101 11.44848 11.517576
>                 max neval
>         40.36472 100 <tel:40.36472%20%20%20100>
>            11.90916   100
>
>
>     Unfortunately %in% does not preserve matrix dimensions:
>
>      > x <- matrix(sample(c(NA_integer_, 1:100), 500, replace=TRUE),
>     nrow=50)
>      > dim(x)
>     [1] 50 10
>      > dim(!is.na <http://is.na>(x) & x)
>     [1] 50 10
>      > dim(as.logical(x) %in% TRUE)
>     NULL
>
>     Stephanie
>
>
>
>
>
>
>             namespace hidden for a while  [note the comment of the last
>             one!]
>             and using them for readibility in its own code.
>
>             Maybe we should (again) consider providing some versions of
>             these with R ?
>
>             The Matrix package also has had fast
>
>             allFalse <- all0 <- function(x) .Call(R_all0, x)
>             anyFalse <- any0 <- function(x) .Call(R_any0, x)
>             ##
>             ## anyFalse <- function(x) isTRUE(any(!x))         ## ~= any0
>             ## any0 <- function(x) isTRUE(any(x == 0))          ## ~=
>             anyFalse
>
>             namespace hidden as well, already, which probably could also be
>             brought to base R.
>
>             One big reason to *not* go there (to internal C code) at all
>             with R is
>             that
>             S3 and S4 dispatch for '==' ('!=', etc, the 'Compare' group
>             generics)
>             and 'is.na <http://is.na>() have been known and package
>             writers have
>             programmed methods for these.
>             To ensure that S3 and S4 dispatch works "correctly" also inside
>             such new internals is much less easily achieved, and so
>             such a C-based internal function  is0() would no longer be
>             equivalent with    !is.na <http://is.na>(x) & x == 0
>             as soon as 'x' is an "object" with a '==', 'Compare' and/or
>             an is.na <http://is.na>()
>             method.
>
>
>         Excellent point. Thank you! It really makes a big difference for
>         developers who maintain a complex hierarchy of S4 classes and
>         methods,
>         when functions like is.true, anyFalse, etc..., which can be
>         expressed in
>         terms of more basic operations like ==, !=, !, is.na
>         <http://is.na>, etc..., just work
>         out-of-the-box on objects for which these basic operations are
>         defined.
>
>         There is conceptually a small set of "building blocks", at least for
>         objects with a vector-like or list-like semantic, that can be used
>         to formally describe the semantic of many functions in base R. This
>         is what the man page for anyNA does by saying:
>
>             anyNA implements any(is.na <http://is.na>(x))
>
>         even though the actual implementation differs, but that's ok, as
>         long
>         as anyNA is equivalent to doing any(is.na <http://is.na>(x)) on
>         any object for which
>         building block is.na <http://is.na>() is implemented.
>
>         Unfortunately there is no clearly identified set of building blocks
>         in base R. For example, if I want the comparison operations to work
>         on my object, I need to implement ==, >, <, !=, <=, and >= (the
>         'Compare' group generics) even though it should be enough to
>         implement
>         == and >=, because all the others can be described in terms of these
>         2 building blocks. unique/duplicated is another example
>         (unique(x) is
>         conceptually x[!duplicated(x)]). And so on...
>
>         Cheers,
>         H.
>
>
>             OTOH, simple R versions such as your  'is.true',  called 'is1'
>             inside Matrix maybe optimizable a bit by the byte compiler (and
>             jit and other such tricks) and still keep the full
>             semantic including correct method dispatch.
>
>             Martin Maechler, ETH Zurich
>
>
>                   > On Fri, Feb 27, 2015 at 7:27 AM, Dimitri Liakhovitski <
>                   > dimitri.liakhovitski at gmail.com
>             <mailto:dimitri.liakhovitski at gmail.com>__> wrote:
>
>                   >> Thank you very much, Duncan.
>                   >> All this being said:
>                   >>
>                   >> What would you say is the most elegant and most
>             safe way to
>             solve such
>                   >> a seemingly simple task?
>                   >>
>                   >> Thank you!
>                   >>
>                   >> On Fri, Feb 27, 2015 at 10:02 AM, Duncan Murdoch
>                   >> <murdoch.duncan at gmail.com
>             <mailto:murdoch.duncan at gmail.com>> wrote:
>                   >> > On 27/02/2015 9:49 AM, Dimitri Liakhovitski wrote:
>                   >> >> So, Duncan, do I understand you correctly:
>                   >> >>
>                   >> >> When I use x$x<6, R doesn't know if it's TRUE or
>             FALSE, so
>             it returns
>                   >> >> a logical value of NA.
>                   >> >
>                   >> > Yes, when x$x is NA.  (Though I think you meant x$c.)
>                   >> >
>                   >> >> When this logical value is applied to a row, the
>             R says:
>             hell, I don't
>                   >> >> know if I should keep it or not, so, just in
>             case, I am
>             going to keep
>                   >> >> it, but I'll replace all the values in this row
>             with NAs?
>                   >> >
>                   >> > Yes.  Indexing with a logical NA is probably a
>             mistake, and
>             this is one
>                   >> > way to signal it without actually triggering a
>             warning or
>             error.
>                   >> >
>                   >> > BTW, I should have mentioned that the example
>             where you
>             indexed using
>                   >> > -which(x$c>=6) is a bad idea:  if none of the
>             entries were 6
>             or more,
>                   >> > this would be indexing with an empty vector, and
>             you'd get
>             nothing, not
>                   >> > everything.
>                   >> >
>                   >> > Duncan Murdoch
>                   >> >
>                   >> >
>                   >> >>
>                   >> >> On Fri, Feb 27, 2015 at 9:13 AM, Duncan Murdoch
>                   >> >> <murdoch.duncan at gmail.com
>             <mailto:murdoch.duncan at gmail.com>> wrote:
>                   >> >>> On 27/02/2015 9:04 AM, Dimitri Liakhovitski wrote:
>                   >> >>>> I know how to get the output I need, but I
>             would benefit
>             from an
>                   >> >>>> explanation why R behaves the way it does.
>                   >> >>>>
>                   >> >>>> # I have a data frame x:
>                   >> >>>> x =
>             data.frame(a=1:10,b=2:11,c=c(__1,NA,3,NA,5,NA,7,NA,NA,10))
>                   >> >>>> x
>                   >> >>>> # I want to toss rows in x that contain values
>              >=6. But I
>             don't want
>                   >> >>>> to toss my NAs there.
>                   >> >>>>
>                   >> >>>> subset(x,c<6) # Works correctly, but removes
>             NAs in c,
>             understand why
>                   >> >>>> x[which(x$c<6),] # Works correctly, but
>             removes NAs in c,
>             understand
>                   >> why
>                   >> >>>> x[-which(x$c>=6),] # output I need
>                   >> >>>>
>                   >> >>>> # Here is my question: why does the following line
>             replace the values
>                   >> >>>> of all rows that contain an NA # in x$c with NAs?
>                   >> >>>>
>                   >> >>>> x[x$c<6,]  # Leaves rows with c=NA, but makes
>             the whole
>             row an NA.
>                   >> Why???
>                   >> >>>> x[(x$c<6) | is.na <http://is.na>(x$c),] #
>             output I need - I have to be
>                   >> super-explicit
>                   >> >>>>
>                   >> >>>> Thank you very much!
>                   >> >>>
>                   >> >>> Most of your examples (except the ones using
>             which()) are
>             doing logical
>                   >> >>> indexing.  In logical indexing, TRUE keeps a
>             line, FALSE
>             drops the
>                   >> line,
>                   >> >>> and NA returns NA.  Since "x$c < 6" is NA if
>             x$c is NA,
>             you get the
>                   >> >>> third kind of indexing.
>                   >> >>>
>                   >> >>> Your last example works because in the cases
>             where x$c is
>             NA, it
>                   >> >>> evaluates NA | TRUE, and that evaluates to
>             TRUE.  In the
>             cases where
>                   >> x$c
>                   >> >>> is not NA, you get x$c < 6 | FALSE, and that's
>             the same as
>             x$c < 6,
>                   >> >>> which will be either TRUE or FALSE.
>                   >> >>>
>                   >> >>> Duncan Murdoch
>                   >> >>>
>                   >> >>
>                   >> >>
>                   >> >>
>                   >> >
>                   >>
>                   >>
>                   >>
>                   >> --
>                   >> Dimitri Liakhovitski
>                   >>
>                   >> ________________________________________________
>                   >> R-help at r-project.org <mailto:R-help at r-project.org>
>             mailing list -- To UNSUBSCRIBE and more, see
>                   >> https://stat.ethz.ch/mailman/__listinfo/r-help
>             <https://stat.ethz.ch/mailman/listinfo/r-help>
>                   >> PLEASE do read the posting guide
>                   >> http://www.R-project.org/__posting-guide.html
>             <http://www.R-project.org/posting-guide.html>
>                   >> and provide commented, minimal, self-contained,
>             reproducible
>             code.
>                   >>
>
>                   > [[alternative HTML version deleted]]
>
>                   > ________________________________________________
>                   > R-help at r-project.org <mailto:R-help at r-project.org>
>             mailing list -- To UNSUBSCRIBE and more, see
>                   > https://stat.ethz.ch/mailman/__listinfo/r-help
>             <https://stat.ethz.ch/mailman/listinfo/r-help>
>                   > PLEASE do read the posting guide
>             http://www.R-project.org/__posting-guide.html
>             <http://www.R-project.org/posting-guide.html>
>                   > and provide commented, minimal, self-contained,
>             reproducible code.
>
>             ________________________________________________
>             R-devel at r-project.org <mailto:R-devel at r-project.org> mailing
>             list
>             https://stat.ethz.ch/mailman/__listinfo/r-devel
>             <https://stat.ethz.ch/mailman/listinfo/r-devel>
>
>
>
>     ________________________________________________
>     R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/__listinfo/r-devel
>     <https://stat.ethz.ch/mailman/listinfo/r-devel>
>
>
>
>
> --
> Gabriel Becker, PhD
> Computational Biologist
> Bioinformatics and Computational Biology
> Genentech, Inc.

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From winstonchang1 at gmail.com  Wed Mar  4 03:12:54 2015
From: winstonchang1 at gmail.com (Winston Chang)
Date: Tue, 03 Mar 2015 20:12:54 -0600
Subject: [Rd] Errors on Windows with grep(fixed=TRUE) on UTF-8 strings
In-Reply-To: <CAFOpNVE1YUrhntksnfp80kcaQXncHGka=NUJqj2O4rSxYnaopQ@mail.gmail.com>
References: <CAFOpNVE1YUrhntksnfp80kcaQXncHGka=NUJqj2O4rSxYnaopQ@mail.gmail.com>
Message-ID: <1425435174.17350.26.camel@bigboy>

After a bit more investigation, I think I've found the cause of the bug,
and I have a patch.

This bug happens with grep(), when:
* Running on Windows.
* The search uses fixed=TRUE.
* The search pattern is a single byte.
* The current locale has a multibyte encoding.

=======================
Here's an example that demonstrates the bug:

# First, create a 3-byte UTF-8 character
y <- rawToChar(as.raw(c(0xe6, 0xb8, 0x97)))
Encoding(y) <- "UTF-8"
y
# [1] "?"

# In my default locale, grep with a single-char pattern and fixed=TRUE
# returns integer(0), as expected.
Sys.getlocale("LC_CTYPE")
# [1] "English_United States.1252"
grep("a", y, fixed = TRUE)
# integer(0)

# When the using a multibyte locale, grep with a single-char
# pattern and fixed=TRUE results in an error.
Sys.setlocale("LC_CTYPE", "chinese")
grep("a", y, fixed = TRUE)
# Error in grep("a", y, fixed = TRUE) : invalid multibyte string at '<97>'


=======================

I believe the problem is in the main/grep.c file, in the fgrep_one
function. It tests for a multi-byte character string locale
`mbcslocale`, and then for the `use_UTF8`, like so:

    if (!useBytes && mbcslocale) {
        ...
    } else if (!useBytes && use_UTF8) {
        ...
    } else ...

This can be seen at
https://github.com/wch/r-source/blob/e92b4c1cba05762480cd3898335144e5dd111cb7/src/main/grep.c#L668-L692

A similar pattern occurs in the fgrep_one_bytes function, at
https://github.com/wch/r-source/blob/e92b4c1cba05762480cd3898335144e5dd111cb7/src/main/grep.c#L718-L736


I believe that the test order should be reversed; it should test first
for `use_UTF8`, and then for `mbcslocale`. This pattern occurs in a few
places in grep.c. It looks like this:

    if (!useBytes && use_UTF8) {
        ...
    } else if (!useBytes && mbcslocale) {
        ...
    } else ...


=======================
This patch does what I described; it simply tests for `use_UTF8` first,
and then `mbcslocale`, in both fgrep_one and fgrep_one_bytes. I made
this patch against the 3.1.2 sources, and tested the example code above.
In both cases, grep() returned integer(0), as expected.

(The reason I made this change against 3.1.2 is because I had problems
getting the current trunk to compile on both Linux or Windows.)


diff --git src/main/grep.c src/main/grep.c
index 6e6ec3e..348c63d 100644
--- src/main/grep.c
+++ src/main/grep.c
@@ -664,27 +664,27 @@ static int fgrep_one(const char *pat, const char *target,
 	    }
 	return -1;
     }
-    if (!useBytes && mbcslocale) { /* skip along by chars */
-	mbstate_t mb_st;
+    if (!useBytes && use_UTF8) {
 	int ib, used;
-	mbs_init(&mb_st);
 	for (ib = 0, i = 0; ib <= len-plen; i++) {
 	    if (strncmp(pat, target+ib, plen) == 0) {
 		if (next != NULL) *next = ib + plen;
 		return i;
 	    }
-	    used = (int) Mbrtowc(NULL,  target+ib, MB_CUR_MAX, &mb_st);
+	    used = utf8clen(target[ib]);
 	    if (used <= 0) break;
 	    ib += used;
 	}
-    } else if (!useBytes && use_UTF8) {
+    } else if (!useBytes && mbcslocale) { /* skip along by chars */
+	mbstate_t mb_st;
 	int ib, used;
+	mbs_init(&mb_st);
 	for (ib = 0, i = 0; ib <= len-plen; i++) {
 	    if (strncmp(pat, target+ib, plen) == 0) {
 		if (next != NULL) *next = ib + plen;
 		return i;
 	    }
-	    used = utf8clen(target[ib]);
+	    used = (int) Mbrtowc(NULL,  target+ib, MB_CUR_MAX, &mb_st);
 	    if (used <= 0) break;
 	    ib += used;
 	}
@@ -714,21 +714,21 @@ static int fgrep_one_bytes(const char *pat, const char *target, int len,
 	    if (*p == pat[0]) return i;
 	return -1;
     }
-    if (!useBytes && mbcslocale) { /* skip along by chars */
-	mbstate_t mb_st;
+    if (!useBytes && use_UTF8) { /* not really needed */
 	int ib, used;
-	mbs_init(&mb_st);
 	for (ib = 0, i = 0; ib <= len-plen; i++) {
 	    if (strncmp(pat, target+ib, plen) == 0) return ib;
-	    used = (int) Mbrtowc(NULL, target+ib, MB_CUR_MAX, &mb_st);
+	    used = utf8clen(target[ib]);
 	    if (used <= 0) break;
 	    ib += used;
 	}
-    } else if (!useBytes && use_UTF8) { /* not really needed */
+    } else if (!useBytes && mbcslocale) { /* skip along by chars */
+	mbstate_t mb_st;
 	int ib, used;
+	mbs_init(&mb_st);
 	for (ib = 0, i = 0; ib <= len-plen; i++) {
 	    if (strncmp(pat, target+ib, plen) == 0) return ib;
-	    used = utf8clen(target[ib]);
+	    used = (int) Mbrtowc(NULL, target+ib, MB_CUR_MAX, &mb_st);
 	    if (used <= 0) break;
 	    ib += used;
 	}


-Winston


From evansochiaga at aims.ac.za  Wed Mar  4 14:01:23 2015
From: evansochiaga at aims.ac.za (Evans Otieno Ochiaga)
Date: Wed, 4 Mar 2015 15:01:23 +0200
Subject: [Rd] nonlinear least square
Message-ID: <CAObCh3WhDRz1inw_63SOu9hxCO0-xOnsF7XR8sq4MqfMgy4yTg@mail.gmail.com>

Hi to all,

Is there a way we can fit a non linear model to a data using non linear
least square method without necessarily initialising the parameters of the
model. I find it hard to get the initial value of the parameter. Below is a
sample of the code I have.





*nachman<-nls(OARmedium$OCCUPANCY~1exp(-alpha*OARmedium$MEAN^beta),start=list(alpha=0.2,beta=0.1),data=OARmedium)summary(nachman)*
Thanks,


*Evans Ochiaga*

*African Institute for Mathematical Sciences*

*6 Melrose Road*

*Muizenberg, South Africa*

*Msc in Mathematical Sciences+27 84 61 69 183 *

*"When I cannot understand my Father?s leading, And it seems to be but hard
and cruel fate, Still I hear that gentle whisper ever pleading, God is
working, God is faithful?Only wait."*

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Wed Mar  4 16:31:21 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 4 Mar 2015 07:31:21 -0800
Subject: [Rd] nonlinear least square
In-Reply-To: <CAObCh3WhDRz1inw_63SOu9hxCO0-xOnsF7XR8sq4MqfMgy4yTg@mail.gmail.com>
References: <CAObCh3WhDRz1inw_63SOu9hxCO0-xOnsF7XR8sq4MqfMgy4yTg@mail.gmail.com>
Message-ID: <CAF8bMcachwf+6r3WM2djv8oPdG7gcnW7c9=71P-LZVx0PWeozQ@mail.gmail.com>

Look at the 'self-starting' functions for nls(), such as SSasymp().

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Mar 4, 2015 at 5:01 AM, Evans Otieno Ochiaga <
evansochiaga at aims.ac.za> wrote:

> Hi to all,
>
> Is there a way we can fit a non linear model to a data using non linear
> least square method without necessarily initialising the parameters of the
> model. I find it hard to get the initial value of the parameter. Below is a
> sample of the code I have.
>
>
>
>
>
>
> *nachman<-nls(OARmedium$OCCUPANCY~1exp(-alpha*OARmedium$MEAN^beta),start=list(alpha=0.2,beta=0.1),data=OARmedium)summary(nachman)*
> Thanks,
>
>
> *Evans Ochiaga*
>
> *African Institute for Mathematical Sciences*
>
> *6 Melrose Road*
>
> *Muizenberg, South Africa*
>
> *Msc in Mathematical Sciences+27 84 61 69 183 *
>
> *"When I cannot understand my Father?s leading, And it seems to be but hard
> and cruel fate, Still I hear that gentle whisper ever pleading, God is
> working, God is faithful?Only wait."*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From tadeas at palusga.cz  Thu Mar  5 15:55:15 2015
From: tadeas at palusga.cz (=?UTF-8?B?VGFkZcOhxaEgUGFsdXNnYQ==?=)
Date: Thu, 05 Mar 2015 15:55:15 +0100
Subject: [Rd] Performance issue in stats:::weighted.mean.default method
Message-ID: <54F86E53.4050809@palusga.cz>

Hi,
   I'm using this mailing list for the first time and I hope this is the 
right one. I don't think that the following is a bug but it can be a 
performance issue.

    By my opinion, there is no need to filter by [w != 0] in last sum of 
weighted.mean.default method defined in 
src/library/stats/R/weighted.mean.R. There is no need to do it because 
you can always sum zero numbers and filtering is too expensive (see 
following benchmark snippet)



library(microbenchmark)
x <- sample(500,5000,replace=TRUE)
w <- sample(1000,5000,replace=TRUE)/1000 * 
ifelse((sample(10,5000,replace=TRUE) -1) > 0, 1, 0)
fun.new <- function(x,w) {sum(x*w)/sum(w)}
fun.orig  <- function(x,w) {sum(x*w[w!=0])/sum(w)}
print(microbenchmark(
   ORIGFN = fun.orig(x,w),
   NEWFN  = fun.new(x,w),
   times = 1000))

#results:
#Unit: microseconds
#   expr     min       lq      mean  median      uq      max neval
# ORIGFN 190.889 194.6590 210.08952 198.847 202.928 1779.789  1000
#  NEWFN  20.857  21.7175  24.61149  22.080  22.594 1744.014  1000




So my suggestion is to remove the w != check




Index: weighted.mean.R
===================================================================
--- weighted.mean.R     (revision 67941)
+++ weighted.mean.R     (working copy)
@@ -29,7 +29,7 @@
          stop("'x' and 'w' must have the same length")
      w <- as.double(w) # avoid overflow in sum for integer weights.
      if (na.rm) { i <- !is.na(x); w <- w[i]; x <- x[i] }
-    sum((x*w)[w != 0])/sum(w) # --> NaN in empty case
+    sum(x*w)/sum(w) # --> NaN in empty case
  }

  ## see note for ?mean.Date


I hope i'm not missing something - I really don't see the reason to have 
this filtration here.

BR

Tadeas 'donarus' Palusga


From ripley at stats.ox.ac.uk  Thu Mar  5 18:49:59 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 05 Mar 2015 17:49:59 +0000
Subject: [Rd] Performance issue in stats:::weighted.mean.default method
In-Reply-To: <54F86E53.4050809@palusga.cz>
References: <54F86E53.4050809@palusga.cz>
Message-ID: <54F89747.70609@stats.ox.ac.uk>

On 05/03/2015 14:55, Tade?? Palusga wrote:
> Hi,
>    I'm using this mailing list for the first time and I hope this is the
> right one. I don't think that the following is a bug but it can be a
> performance issue.
>
>     By my opinion, there is no need to filter by [w != 0] in last sum of
> weighted.mean.default method defined in
> src/library/stats/R/weighted.mean.R. There is no need to do it because
> you can always sum zero numbers and filtering is too expensive (see
> following benchmark snippet)

But 0*x is not necessarily 0, so there is a need to do it ... see

 > w <- c(0, 1)
 > x <- c(Inf, 1)
 > weighted.mean(x, w)
[1] 1
 > fun.new(x, w)
[1] NaN

>
>
>
> library(microbenchmark)
> x <- sample(500,5000,replace=TRUE)
> w <- sample(1000,5000,replace=TRUE)/1000 *
> ifelse((sample(10,5000,replace=TRUE) -1) > 0, 1, 0)
> fun.new <- function(x,w) {sum(x*w)/sum(w)}
> fun.orig  <- function(x,w) {sum(x*w[w!=0])/sum(w)}
> print(microbenchmark(
>    ORIGFN = fun.orig(x,w),
>    NEWFN  = fun.new(x,w),
>    times = 1000))
>
> #results:
> #Unit: microseconds
> #   expr     min       lq      mean  median      uq      max neval
> # ORIGFN 190.889 194.6590 210.08952 198.847 202.928 1779.789  1000
> #  NEWFN  20.857  21.7175  24.61149  22.080  22.594 1744.014  1000
>
>
>
>
> So my suggestion is to remove the w != check
>
>
>
>
> Index: weighted.mean.R
> ===================================================================
> --- weighted.mean.R     (revision 67941)
> +++ weighted.mean.R     (working copy)
> @@ -29,7 +29,7 @@
>           stop("'x' and 'w' must have the same length")
>       w <- as.double(w) # avoid overflow in sum for integer weights.
>       if (na.rm) { i <- !is.na(x); w <- w[i]; x <- x[i] }
> -    sum((x*w)[w != 0])/sum(w) # --> NaN in empty case
> +    sum(x*w)/sum(w) # --> NaN in empty case
>   }
>
>   ## see note for ?mean.Date
>
>
> I hope i'm not missing something - I really don't see the reason to have
> this filtration here.
>
> BR
>
> Tadeas 'donarus' Palusga
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From hb at biostat.ucsf.edu  Thu Mar  5 20:39:45 2015
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Thu, 5 Mar 2015 11:39:45 -0800
Subject: [Rd] Performance issue in stats:::weighted.mean.default method
In-Reply-To: <54F89747.70609@stats.ox.ac.uk>
References: <54F86E53.4050809@palusga.cz> <54F89747.70609@stats.ox.ac.uk>
Message-ID: <CAFDcVCTk2y0NLQy53mwcR3a-OMXy7utEWbRtje3x3me=EG91hA@mail.gmail.com>

See weightedMean() in the matrixStats package.  It's optimized for
data type, speed and memory and implemented in native code so it can
avoid some of these intermediate copies.  It's a few times faster than
weighted.mean[.default]();

library(matrixStats)
library(microbenchmark)
n <- 5000
x <- sample(500,n,replace=TRUE)
w <- sample(1000,n,replace=TRUE)/1000 *
ifelse((sample(10,n,replace=TRUE) -1) > 0, 1, 0)
fun.new <- function(x,w) {sum(x*w)/sum(w)}
fun.orig  <- function(x,w) {sum(x*w[w!=0])/sum(w)}
stats <- microbenchmark(
  weightedMean(x,w),
  weighted.mean(x,w),
  ORIGFN = fun.orig(x,w),
  NEWFN  = fun.new(x,w),
  times = 1000
)

> print(stats, digits=3)
Unit: microseconds
                expr   min    lq  mean median    uq    max neval
  weightedMean(x, w)  28.7  31.7  33.4   32.9  33.8   81.7  1000
 weighted.mean(x, w) 129.6 141.6 149.6  143.7 147.1 2332.9  1000
              ORIGFN 205.7 222.0 235.0  225.4 231.4 2655.8  1000
               NEWFN  38.9  42.3  44.3   42.8  43.6  385.8  1000

Relative performance will vary with n = length(x).

The weightedMean() function handles zero-weight Inf values:

> w <- c(0, 1)
> x <- c(Inf, 1)
> weighted.mean(x, w)
[1] 1
> fun.new(x, w)
[1] NaN
> weightedMean(x,w)
[1] 1

You'll find more benchmark results on weightedMean() vs
weighted.mean() on
https://github.com/HenrikBengtsson/matrixStats/wiki/weightedMean

/Henrik

On Thu, Mar 5, 2015 at 9:49 AM, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> On 05/03/2015 14:55, Tade?? Palusga wrote:
>>
>> Hi,
>>    I'm using this mailing list for the first time and I hope this is the
>> right one. I don't think that the following is a bug but it can be a
>> performance issue.
>>
>>     By my opinion, there is no need to filter by [w != 0] in last sum of
>> weighted.mean.default method defined in
>> src/library/stats/R/weighted.mean.R. There is no need to do it because
>> you can always sum zero numbers and filtering is too expensive (see
>> following benchmark snippet)
>
>
> But 0*x is not necessarily 0, so there is a need to do it ... see
>
>> w <- c(0, 1)
>> x <- c(Inf, 1)
>> weighted.mean(x, w)
> [1] 1
>> fun.new(x, w)
> [1] NaN
>
>
>>
>>
>>
>> library(microbenchmark)
>> x <- sample(500,5000,replace=TRUE)
>> w <- sample(1000,5000,replace=TRUE)/1000 *
>> ifelse((sample(10,5000,replace=TRUE) -1) > 0, 1, 0)
>> fun.new <- function(x,w) {sum(x*w)/sum(w)}
>> fun.orig  <- function(x,w) {sum(x*w[w!=0])/sum(w)}
>> print(microbenchmark(
>>    ORIGFN = fun.orig(x,w),
>>    NEWFN  = fun.new(x,w),
>>    times = 1000))
>>
>> #results:
>> #Unit: microseconds
>> #   expr     min       lq      mean  median      uq      max neval
>> # ORIGFN 190.889 194.6590 210.08952 198.847 202.928 1779.789  1000
>> #  NEWFN  20.857  21.7175  24.61149  22.080  22.594 1744.014  1000
>>
>>
>>
>>
>> So my suggestion is to remove the w != check
>>
>>
>>
>>
>> Index: weighted.mean.R
>> ===================================================================
>> --- weighted.mean.R     (revision 67941)
>> +++ weighted.mean.R     (working copy)
>> @@ -29,7 +29,7 @@
>>           stop("'x' and 'w' must have the same length")
>>       w <- as.double(w) # avoid overflow in sum for integer weights.
>>       if (na.rm) { i <- !is.na(x); w <- w[i]; x <- x[i] }
>> -    sum((x*w)[w != 0])/sum(w) # --> NaN in empty case
>> +    sum(x*w)/sum(w) # --> NaN in empty case
>>   }
>>
>>   ## see note for ?mean.Date
>>
>>
>> I hope i'm not missing something - I really don't see the reason to have
>> this filtration here.
>>
>> BR
>>
>> Tadeas 'donarus' Palusga
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Emeritus Professor of Applied Statistics, University of Oxford
> 1 South Parks Road, Oxford OX1 3TG, UK
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From tadeas at palusga.cz  Thu Mar  5 20:54:49 2015
From: tadeas at palusga.cz (=?UTF-8?B?VGFkZcOhxaEgUGFsdXNnYQ==?=)
Date: Thu, 05 Mar 2015 20:54:49 +0100
Subject: [Rd] Performance issue in stats:::weighted.mean.default method
In-Reply-To: <54F89747.70609@stats.ox.ac.uk>
References: <54F86E53.4050809@palusga.cz> <54F89747.70609@stats.ox.ac.uk>
Message-ID: <54F8B489.70506@palusga.cz>

Oops, such an amateur mistake. Thanks a lot for your quick response.

Regards

TP

On 03/05/2015 06:49 PM, Prof Brian Ripley wrote:
> On 05/03/2015 14:55, Tade?? Palusga wrote:
>> Hi,
>>    I'm using this mailing list for the first time and I hope this is the
>> right one. I don't think that the following is a bug but it can be a
>> performance issue.
>>
>>     By my opinion, there is no need to filter by [w != 0] in last sum of
>> weighted.mean.default method defined in
>> src/library/stats/R/weighted.mean.R. There is no need to do it because
>> you can always sum zero numbers and filtering is too expensive (see
>> following benchmark snippet)
>
> But 0*x is not necessarily 0, so there is a need to do it ... see
>
> > w <- c(0, 1)
> > x <- c(Inf, 1)
> > weighted.mean(x, w)
> [1] 1
> > fun.new(x, w)
> [1] NaN
>
>>
>>
>>
>> library(microbenchmark)
>> x <- sample(500,5000,replace=TRUE)
>> w <- sample(1000,5000,replace=TRUE)/1000 *
>> ifelse((sample(10,5000,replace=TRUE) -1) > 0, 1, 0)
>> fun.new <- function(x,w) {sum(x*w)/sum(w)}
>> fun.orig  <- function(x,w) {sum(x*w[w!=0])/sum(w)}
>> print(microbenchmark(
>>    ORIGFN = fun.orig(x,w),
>>    NEWFN  = fun.new(x,w),
>>    times = 1000))
>>
>> #results:
>> #Unit: microseconds
>> #   expr     min       lq      mean  median      uq      max neval
>> # ORIGFN 190.889 194.6590 210.08952 198.847 202.928 1779.789 1000
>> #  NEWFN  20.857  21.7175  24.61149  22.080  22.594 1744.014 1000
>>
>>
>>
>>
>> So my suggestion is to remove the w != check
>>
>>
>>
>>
>> Index: weighted.mean.R
>> ===================================================================
>> --- weighted.mean.R     (revision 67941)
>> +++ weighted.mean.R     (working copy)
>> @@ -29,7 +29,7 @@
>>           stop("'x' and 'w' must have the same length")
>>       w <- as.double(w) # avoid overflow in sum for integer weights.
>>       if (na.rm) { i <- !is.na(x); w <- w[i]; x <- x[i] }
>> -    sum((x*w)[w != 0])/sum(w) # --> NaN in empty case
>> +    sum(x*w)/sum(w) # --> NaN in empty case
>>   }
>>
>>   ## see note for ?mean.Date
>>
>>
>> I hope i'm not missing something - I really don't see the reason to have
>> this filtration here.
>>
>> BR
>>
>> Tadeas 'donarus' Palusga
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From m.etienne.lord at gmail.com  Fri Mar  6 00:03:09 2015
From: m.etienne.lord at gmail.com (Etienne Lord)
Date: Thu, 5 Mar 2015 18:03:09 -0500
Subject: [Rd] Submit a package which use doParallel
Message-ID: <CAFin55WOa+OXsG7JEqPp1-Le1Cir+0mHrrECEbQKFkGGoTTKTQ@mail.gmail.com>

Hi,

I'm trying to submit my first package which depends on doParallel:

Depends: R (>= 3.0), igraph, doParallel

Running hadley devtools: devtools::check() and devtools::release() result
in no problem (no ERROR nor NOTE on Linux, Mac and Windows).

However, when in use the devtools::build_win() command, it results in the
following note:

* checking R code for possible problems ... NOTE

complete_network: no visible global function definition for '%dopar%'
complete_network: no visible global function definition for '%:%'
complete_network: no visible global function definition for 'foreach'
sample_network: no visible global function definition for '%dopar%'
sample_network: no visible global function definition for 'foreach'

Googling for " no visible global function definition for '%dopar%' " result
in a few CRAN packages with
similar note e.g.
http://www.r-project.org/nosvn/R.check/r-devel-linux-x86_64-fedora-clang/penDvine-00check.html

1) Is there a special way to include the doParallel package so that this
error do not occur?

2) Installing the doParallel package "before" running any test on windows
seems to remove this note. Is there any way to specify it in the
DESCRIPTION?

Best regards,

Have a nice day.

-- 
Etienne Lord, Ph.D.
Post-Doc Bioinformatics.
Universit? du Qu?bec ? Montr?al
Universit? de Montr?al

	[[alternative HTML version deleted]]


From brian at braverock.com  Fri Mar  6 00:16:47 2015
From: brian at braverock.com (Brian G. Peterson)
Date: Thu, 05 Mar 2015 17:16:47 -0600
Subject: [Rd] Submit a package which use doParallel
In-Reply-To: <CAFin55WOa+OXsG7JEqPp1-Le1Cir+0mHrrECEbQKFkGGoTTKTQ@mail.gmail.com>
References: <CAFin55WOa+OXsG7JEqPp1-Le1Cir+0mHrrECEbQKFkGGoTTKTQ@mail.gmail.com>
Message-ID: <1425597407.32760.3.camel@brian-rcg.priv.dvtrading.co>

On Thu, 2015-03-05 at 18:03 -0500, Etienne Lord wrote:
> Hi,
> 
> I'm trying to submit my first package which depends on doParallel:
> 
> Depends: R (>= 3.0), igraph, doParallel

add foreach to your Depends.  That should resolve the error you're
seeing.


> Running hadley devtools: devtools::check() and devtools::release() result
> in no problem (no ERROR nor NOTE on Linux, Mac and Windows).
> 
> However, when in use the devtools::build_win() command, it results in the
> following note:
> 
> * checking R code for possible problems ... NOTE
> 
> complete_network: no visible global function definition for '%dopar%'
> complete_network: no visible global function definition for '%:%'
> complete_network: no visible global function definition for 'foreach'

<...>

> 2) Installing the doParallel package "before" running any test on windows
> seems to remove this note. Is there any way to specify it in the
> DESCRIPTION?

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From murdoch.duncan at gmail.com  Fri Mar  6 00:21:38 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 05 Mar 2015 18:21:38 -0500
Subject: [Rd] Submit a package which use doParallel
In-Reply-To: <CAFin55WOa+OXsG7JEqPp1-Le1Cir+0mHrrECEbQKFkGGoTTKTQ@mail.gmail.com>
References: <CAFin55WOa+OXsG7JEqPp1-Le1Cir+0mHrrECEbQKFkGGoTTKTQ@mail.gmail.com>
Message-ID: <54F8E502.9040704@gmail.com>

On 05/03/2015 6:03 PM, Etienne Lord wrote:
> Hi,
> 
> I'm trying to submit my first package which depends on doParallel:
> 
> Depends: R (>= 3.0), igraph, doParallel

It's much better to import what you need.  If someone calls one of your
functions using :: notation, it will fail, because it won't know where
to find the doParallel objects.

> 
> Running hadley devtools: devtools::check() and devtools::release() result
> in no problem (no ERROR nor NOTE on Linux, Mac and Windows).
> 
> However, when in use the devtools::build_win() command, it results in the
> following note:
> 
> * checking R code for possible problems ... NOTE
> 
> complete_network: no visible global function definition for '%dopar%'
> complete_network: no visible global function definition for '%:%'
> complete_network: no visible global function definition for 'foreach'
> sample_network: no visible global function definition for '%dopar%'
> sample_network: no visible global function definition for 'foreach'
> 
> Googling for " no visible global function definition for '%dopar%' " result
> in a few CRAN packages with
> similar note e.g.
> http://www.r-project.org/nosvn/R.check/r-devel-linux-x86_64-fedora-clang/penDvine-00check.html
> 
> 1) Is there a special way to include the doParallel package so that this
> error do not occur?

List it in the DESCRIPTION as "Imports:  doParallel" and in your
NAMESPACE file import the functions you need.

> 
> 2) Installing the doParallel package "before" running any test on windows
> seems to remove this note. Is there any way to specify it in the
> DESCRIPTION?

That's a problem with testing within a session.  It's best to run checks
on a vanilla system, using R CMD check.

Duncan Murdoch


From murdoch.duncan at gmail.com  Fri Mar  6 00:22:10 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 05 Mar 2015 18:22:10 -0500
Subject: [Rd] Submit a package which use doParallel
In-Reply-To: <1425597407.32760.3.camel@brian-rcg.priv.dvtrading.co>
References: <CAFin55WOa+OXsG7JEqPp1-Le1Cir+0mHrrECEbQKFkGGoTTKTQ@mail.gmail.com>
	<1425597407.32760.3.camel@brian-rcg.priv.dvtrading.co>
Message-ID: <54F8E522.8030104@gmail.com>

On 05/03/2015 6:16 PM, Brian G. Peterson wrote:
> On Thu, 2015-03-05 at 18:03 -0500, Etienne Lord wrote:
>> Hi,
>>
>> I'm trying to submit my first package which depends on doParallel:
>>
>> Depends: R (>= 3.0), igraph, doParallel
> 
> add foreach to your Depends.  That should resolve the error you're
> seeing.

Please don't do that.  Use Imports.

Duncan Murdoch

> 
> 
>> Running hadley devtools: devtools::check() and devtools::release() result
>> in no problem (no ERROR nor NOTE on Linux, Mac and Windows).
>>
>> However, when in use the devtools::build_win() command, it results in the
>> following note:
>>
>> * checking R code for possible problems ... NOTE
>>
>> complete_network: no visible global function definition for '%dopar%'
>> complete_network: no visible global function definition for '%:%'
>> complete_network: no visible global function definition for 'foreach'
> 
> <...>
> 
>> 2) Installing the doParallel package "before" running any test on windows
>> seems to remove this note. Is there any way to specify it in the
>> DESCRIPTION?
>


From m.etienne.lord at gmail.com  Fri Mar  6 02:01:21 2015
From: m.etienne.lord at gmail.com (Etienne Lord)
Date: Thu, 5 Mar 2015 20:01:21 -0500
Subject: [Rd] Submit a package which use doParallel
In-Reply-To: <54F8E522.8030104@gmail.com>
References: <CAFin55WOa+OXsG7JEqPp1-Le1Cir+0mHrrECEbQKFkGGoTTKTQ@mail.gmail.com>
	<1425597407.32760.3.camel@brian-rcg.priv.dvtrading.co>
	<54F8E522.8030104@gmail.com>
Message-ID: <CAFin55UctZk8mpTNe4Wa6B8kp5V01=RkQ5D8UU6GHkj8kDs5HQ@mail.gmail.com>

Thanks for the quick reply.

Adding all the dependencies of doParallel (foreach, parallel, iterators) in
the DESCRIPTION and in import statements in NAMESPACE resolved the
build_win problems. Don't know why this is required for Windows build.

Thanks again.

2015-03-05 18:22 GMT-05:00 Duncan Murdoch <murdoch.duncan at gmail.com>:

> On 05/03/2015 6:16 PM, Brian G. Peterson wrote:
> > On Thu, 2015-03-05 at 18:03 -0500, Etienne Lord wrote:
> >> Hi,
> >>
> >> I'm trying to submit my first package which depends on doParallel:
> >>
> >> Depends: R (>= 3.0), igraph, doParallel
> >
> > add foreach to your Depends.  That should resolve the error you're
> > seeing.
>
> Please don't do that.  Use Imports.
>
> Duncan Murdoch
>
> >
> >
> >> Running hadley devtools: devtools::check() and devtools::release()
> result
> >> in no problem (no ERROR nor NOTE on Linux, Mac and Windows).
> >>
> >> However, when in use the devtools::build_win() command, it results in
> the
> >> following note:
> >>
> >> * checking R code for possible problems ... NOTE
> >>
> >> complete_network: no visible global function definition for '%dopar%'
> >> complete_network: no visible global function definition for '%:%'
> >> complete_network: no visible global function definition for 'foreach'
> >
> > <...>
> >
> >> 2) Installing the doParallel package "before" running any test on
> windows
> >> seems to remove this note. Is there any way to specify it in the
> >> DESCRIPTION?
> >
>
>


-- 
Etienne Lord
?tudiant au Doctorat en Informatique
Universit? du Qu?bec ? Montr?al
tel : 514 987-3000 ext. 4803

	[[alternative HTML version deleted]]


From henrik.bengtsson at ucsf.edu  Fri Mar  6 02:24:09 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Thu, 5 Mar 2015 17:24:09 -0800
Subject: [Rd] Submit a package which use doParallel
In-Reply-To: <CAFin55UctZk8mpTNe4Wa6B8kp5V01=RkQ5D8UU6GHkj8kDs5HQ@mail.gmail.com>
References: <CAFin55WOa+OXsG7JEqPp1-Le1Cir+0mHrrECEbQKFkGGoTTKTQ@mail.gmail.com>
	<1425597407.32760.3.camel@brian-rcg.priv.dvtrading.co>
	<54F8E522.8030104@gmail.com>
	<CAFin55UctZk8mpTNe4Wa6B8kp5V01=RkQ5D8UU6GHkj8kDs5HQ@mail.gmail.com>
Message-ID: <CAFDcVCS9Ro6SeZzo2Oq-rbq-OCs5tRSf7Q5KxSKamB2UbCVgpw@mail.gmail.com>

On Mar 5, 2015 5:01 PM, "Etienne Lord" <m.etienne.lord at gmail.com> wrote:
>
> Thanks for the quick reply.
>
> Adding all the dependencies of doParallel (foreach, parallel, iterators)
in
> the DESCRIPTION and in import statements in NAMESPACE resolved the
> build_win problems. Don't know why this is required for Windows build.

Most likely not a Windows specific issue,. Instead it could be because the
latter uses http://win-builder.r-project.org/ and that uses newer versions
of R than what you use locally. I'd guess you get the same NOTEs if you
test with R devel (now 3.2.0rc) locally and maybe even R 3.1.2 patched.

Henrik

>
> Thanks again.
>
> 2015-03-05 18:22 GMT-05:00 Duncan Murdoch <murdoch.duncan at gmail.com>:
>
> > On 05/03/2015 6:16 PM, Brian G. Peterson wrote:
> > > On Thu, 2015-03-05 at 18:03 -0500, Etienne Lord wrote:
> > >> Hi,
> > >>
> > >> I'm trying to submit my first package which depends on doParallel:
> > >>
> > >> Depends: R (>= 3.0), igraph, doParallel
> > >
> > > add foreach to your Depends.  That should resolve the error you're
> > > seeing.
> >
> > Please don't do that.  Use Imports.
> >
> > Duncan Murdoch
> >
> > >
> > >
> > >> Running hadley devtools: devtools::check() and devtools::release()
> > result
> > >> in no problem (no ERROR nor NOTE on Linux, Mac and Windows).
> > >>
> > >> However, when in use the devtools::build_win() command, it results in
> > the
> > >> following note:
> > >>
> > >> * checking R code for possible problems ... NOTE
> > >>
> > >> complete_network: no visible global function definition for '%dopar%'
> > >> complete_network: no visible global function definition for '%:%'
> > >> complete_network: no visible global function definition for 'foreach'
> > >
> > > <...>
> > >
> > >> 2) Installing the doParallel package "before" running any test on
> > windows
> > >> seems to remove this note. Is there any way to specify it in the
> > >> DESCRIPTION?
> > >
> >
> >
>
>
> --
> Etienne Lord
> ?tudiant au Doctorat en Informatique
> Universit? du Qu?bec ? Montr?al
> tel : 514 987-3000 ext. 4803
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

	[[alternative HTML version deleted]]


From jeffrey.horner at gmail.com  Fri Mar  6 16:19:18 2015
From: jeffrey.horner at gmail.com (Jeffrey Horner)
Date: Fri, 6 Mar 2015 09:19:18 -0600
Subject: [Rd] R with Array Hashes
Message-ID: <CAD+yNFgdq1jf-epjempOe78-xC-t-T0dpz_tg9fAEF5niTOWAg@mail.gmail.com>

Hi,

I wanted to share with the mailing list members here details about the
project I've been working on:

https://github.com/jeffreyhorner/R-Array-Hash

This is a re-implementation of R's hashed environments, the global
variable cache, the global string cache and symbol table with
cache-conscious array hash tables. The results are quite encouraging.
However, the implementation is a big departure from R's API:

"An array hash is a cache-conscious data structure that takes
advantage of hardware prefetchers for improved performance on large
hash tables, those large enough to fit in main memory and larger than
fast fixed size cpu caches.

However, their implementation is a radical departure from standard
chained hash tables. Rather than using chains of hash buckets for
collision resolution, array hashes use segements of contiguous memory
called dynamic arrays to store keys and values. Adding and deleting
items from the hash involve copying the entire segment to new areas in
memory. While this may seem wasteful and slow, it's surprisingly
efficient in both time and space.

In R, hashed environments are implemented using lists with each list
element (a CONS cell) acting as the hash bucket. The CONS cell is the
binding agent for a symbol and value. Hashed environments are searched
using the pointer address of the symbol rather than the symbol's
printed name.

R-Array-Hash takes advantage of this by implementing an integer array
hash to store addresses of symbols and their associated values. Care
is also taken to account for whether or not a binding is locked,
active, etc.

Similarly, R-Array-Hash re-implements R's string cache using a string
array hash. This introduces the most radical change to R's API: CHAR()
no longer returns an address that points to the area at the end of the
SEXP (containing the string value). Rather it returns an address
located in one of the contiguous dynamic arrays of the string hash
table. Therefore, care must be taken in C code to use the address
immediately since additions and deletions to the string hash could
render the result of CHAR() useless. There are many areas of the code
that sidestep this by calling translateChar(), which has been changed
to always copy the string pointed by CHAR()."

Comments, constructive or otherwise are welcome.

Best,

Jeff


From edd at debian.org  Fri Mar  6 16:36:53 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 6 Mar 2015 09:36:53 -0600
Subject: [Rd] R with Array Hashes
In-Reply-To: <CAD+yNFgdq1jf-epjempOe78-xC-t-T0dpz_tg9fAEF5niTOWAg@mail.gmail.com>
References: <CAD+yNFgdq1jf-epjempOe78-xC-t-T0dpz_tg9fAEF5niTOWAg@mail.gmail.com>
Message-ID: <21753.51605.181454.609423@max.nulle.part>


Jeff,

Nice writeup and promising idea.  From the "gimme numbers" department:

 - do you pass the R regression tests?

 - what sort of speedups do you see on which type of benchmarks?

When you asked about benchmark code on Twitter, I shared the somewhat
well-known (but no R ...) http://benchmarksgame.alioth.debian.org/
Did you write new benchmarks?  Did you try the ones once assembled by Simon?  

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From jeffrey.horner at gmail.com  Fri Mar  6 17:03:09 2015
From: jeffrey.horner at gmail.com (Jeffrey Horner)
Date: Fri, 6 Mar 2015 10:03:09 -0600
Subject: [Rd] R with Array Hashes
In-Reply-To: <21753.51605.181454.609423@max.nulle.part>
References: <CAD+yNFgdq1jf-epjempOe78-xC-t-T0dpz_tg9fAEF5niTOWAg@mail.gmail.com>
	<21753.51605.181454.609423@max.nulle.part>
Message-ID: <CAD+yNFgEPfhP-2KsiyHiRKKJMONoO9dSieA6NnaoTbp9ZzoXsg@mail.gmail.com>

On Fri, Mar 6, 2015 at 9:36 AM, Dirk Eddelbuettel <edd at debian.org> wrote:
>
> Jeff,
>
> Nice writeup and promising idea.  From the "gimme numbers" department:
>
>  - do you pass the R regression tests?

I made sure that the implementation passed 99% of the tests, however
there were two that gave differing results which I think are related
to traversing hashed environments.

>
>  - what sort of speedups do you see on which type of benchmarks?

I wrote up some notes on the benchmark I conducted here:

https://github.com/jeffreyhorner/R-Array-Hash/tree/master/benchmarks

> When you asked about benchmark code on Twitter, I shared the somewhat
> well-known (but no R ...) http://benchmarksgame.alioth.debian.org/
> Did you write new benchmarks?  Did you try the ones once assembled by Simon?

I decided to design the benchmark very close to the one I found in:

Askitis, Nikolas, and Justin Zobel. "Redesigning the string hash
table, burst trie, and bst to exploit cache." Journal of Experimental
Algorithmics (JEA) 15 (2010): 1-7.

Its a synthetic benchmark that just measures aspects of constructing
and searching an R environment.

>
> Dirk
>
> --
> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From ravi.varadhan at jhu.edu  Fri Mar  6 17:18:52 2015
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Fri, 6 Mar 2015 16:18:52 +0000
Subject: [Rd] Hyper-dual numbers in R
Message-ID: <43b95f774cfb42f499f051012d88796f@DOM-EB1-2013.win.ad.jhu.edu>

Hi,
Has anyone in R core thought about providing "hyper-dual numbers" in R?  Hyper-dual (HD) numbers, invented by Jeffrey Fike at Stanford, are useful for computing exact second-order derivatives (e.g., Hessian).  HD numbers are extensions of complex numbers. They are like "quaternions" and have 4 parts to them (one real and 3 non-real).  They seem to be available in Julia.  Obviously, the HD numbers involve a lot more book keeping.

http://adl.stanford.edu/hyperdual/

Thanks,
Ravi


	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Mar  6 21:31:33 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 06 Mar 2015 15:31:33 -0500
Subject: [Rd] Hyper-dual numbers in R
In-Reply-To: <43b95f774cfb42f499f051012d88796f@DOM-EB1-2013.win.ad.jhu.edu>
References: <43b95f774cfb42f499f051012d88796f@DOM-EB1-2013.win.ad.jhu.edu>
Message-ID: <54FA0EA5.6080005@gmail.com>

On 06/03/2015 11:18 AM, Ravi Varadhan wrote:
> Hi,
> Has anyone in R core thought about providing "hyper-dual numbers" in R?  Hyper-dual (HD) numbers, invented by Jeffrey Fike at Stanford, are useful for computing exact second-order derivatives (e.g., Hessian).  HD numbers are extensions of complex numbers. They are like "quaternions" and have 4 parts to them (one real and 3 non-real).  They seem to be available in Julia.  Obviously, the HD numbers involve a lot more book keeping.

Why would you limit this to R core?  Seems like something a package
could provide.  After all, we have other packages extending the number
system, e.g. Rmpfr.

Duncan Murdoch

> http://adl.stanford.edu/hyperdual/
> 
> Thanks,
> Ravi


From ravi.varadhan at jhu.edu  Sat Mar  7 14:42:40 2015
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Sat, 7 Mar 2015 13:42:40 +0000
Subject: [Rd] Hyper-dual numbers in R
In-Reply-To: <54FA0EA5.6080005@gmail.com>
References: <43b95f774cfb42f499f051012d88796f@DOM-EB1-2013.win.ad.jhu.edu>,
	<54FA0EA5.6080005@gmail.com>
Message-ID: <1425735750597.76689@jhu.edu>

Is anyone interested in writing a package for this?  I know that there is C++ code available (written by Fike himself).  I can help to the extent of my knowledge, which is very minimal in terms of C++, but I am willing to do testing and other kinds of tasks.  Please contact me offline, if there is any interest.

Thanks & Best,
Ravi
________________________________________
From: Duncan Murdoch <murdoch.duncan at gmail.com>
Sent: Friday, March 6, 2015 3:31 PM
To: Ravi Varadhan; r-devel at r-project.org
Subject: Re: [Rd] Hyper-dual numbers in R

On 06/03/2015 11:18 AM, Ravi Varadhan wrote:
> Hi,
> Has anyone in R core thought about providing "hyper-dual numbers" in R?  Hyper-dual (HD) numbers, invented by Jeffrey Fike at Stanford, are useful for computing exact second-order derivatives (e.g., Hessian).  HD numbers are extensions of complex numbers. They are like "quaternions" and have 4 parts to them (one real and 3 non-real).  They seem to be available in Julia.  Obviously, the HD numbers involve a lot more book keeping.

Why would you limit this to R core?  Seems like something a package
could provide.  After all, we have other packages extending the number
system, e.g. Rmpfr.

Duncan Murdoch

> http://adl.stanford.edu/hyperdual/
>
> Thanks,
> Ravi



From marius.hofert at uwaterloo.ca  Sun Mar  8 16:19:45 2015
From: marius.hofert at uwaterloo.ca (Marius Hofert)
Date: Sun, 8 Mar 2015 11:19:45 -0400
Subject: [Rd] Seed in 'parallel' vignette
In-Reply-To: <CAM3-Kjah4y2Mr7snden5XJsx6nUFEpMO30Q_sAyBh9fD0bp-Vg@mail.gmail.com>
References: <CAM3-Kjah4y2Mr7snden5XJsx6nUFEpMO30Q_sAyBh9fD0bp-Vg@mail.gmail.com>
Message-ID: <CAM3-KjZeYc6JMXDv8QdcF2efAPwaYMf=GLPNzV1jp_R93gGq6A@mail.gmail.com>

On Tue, Feb 3, 2015 at 10:39 AM, Marius Hofert
<marius.hofert at uwaterloo.ca> wrote:
> Hi,
>
> This is most likely only a minor technicality, but I saw the
> following: On page 6 of the 'parallel' vignette
> (http://stat.ethz.ch/R-manual/R-devel/library/parallel/doc/parallel.pdf),
> the random-number generator "L'Ecuyer-CMRG" is said to have seed
> "(x_n, x_{n-1}, x_{n-2}, y_n, y_{n-1}, y_{n-2})". However, in L'Ecuyer
> et al. (2002), the seed is given with 'increasing' indices, so should
> rather be "(x_{n-2}, x_{n-1}, x_n, y_{n-2}, y_{n-1}, y_n)" (or, even
> more intuitively, "(x_{n-3}, x_{n-2}, x_{n-1}, y_{n-3}, y_{n-2},
> y_{n-1})"). The question is how it's done in R (?):

... in the meanwhile, I found out that this is indeed a typo in the
vignette. I suggest to change it to "(x_{n-3}, x_{n-2}, x_{n-1},
y_{n-3}, y_{n-2}, y_{n-1})" on page 6 in the version of October 31, 2014.

> If as given in the
> vignette, one should maybe point this out as other (languages)
> following L'Ecuyer et al. (2002) might obtain different random numbers
> then. And if it's implemented as in L'Ecuyer, then one probably wants
> to adjust the vignette to reflect this.
>
> Other minor suggestions to improve the vignette (if that's what's also
> done in R; I couldn't easily figure that out from ./src/main/RNG.c):
> 1) when defining u_n, I would write u_n = z_n / (2^32-208) [as it is
> immediately clear then that one divides by the modulus of the first
> linear congruential generator + 1]
> 2) The case z_n=0 is not provided (for a reason?). If z_n=0, L'Ecuyer
> suggests to set u_n to "(2^32-209)/(2^32-208)".
>
> Cheers,
> Marius
>
>
>
>
> --
> Marius Hofert, Dr. rer. nat.
> Assistant Professor
> Department of Statistics and Actuarial Science
> Faculty of Mathematics
> University of Waterloo
> 200 University Avenue West, Waterloo, ON, N2L 3G1
> +1-519-888-4567, ext. 31394 (office M3 4207)
> http://math.uwaterloo.ca/~mhofert



-- 
Marius Hofert, Dr. rer. nat.
Assistant Professor
Department of Statistics and Actuarial Science
Faculty of Mathematics
University of Waterloo
200 University Avenue West, Waterloo, ON, N2L 3G1
+1-519-888-4567, ext. 31394 (office M3 4207)
http://math.uwaterloo.ca/~mhofert


From tangoh at gmail.com  Mon Mar  9 03:02:30 2015
From: tangoh at gmail.com (Hsiu-Khuern Tang)
Date: Sun, 8 Mar 2015 19:02:30 -0700
Subject: [Rd] Notes on building a gcc toolchain for Rtools (but not multilib)
Message-ID: <CAPuMoLZAWUvcQ-ubBwuqzLONom3ZLGJzzUPbmzm2E_2HzCHWYg@mail.gmail.com>

Hi,

[This is a follow-up to the "New version of Rtools for Windows" thread
in January, but I just subscribed and don't know how to reply to an
old thread -- my apologies.]

I was able to use the nuwen distro to build a gcc 4.9.2 toolchain and
use it to build the latest R-patched with it.

Below are some notes about what I did; I hope they will be useful for
keeping Rtools up-to-date.


Note:

- This is 64-bit only; I tried but was unable to create a multilib toolchain

- I did not run any tests on the resulting R binary, other than
starting R and running some basic commands

- I don't necessarily know what I'm doing!


Outline of steps:

- The (nicely done!) nuwen website by Stephan Lavavej has made
available a MinGW distro and the scripts used to create it.

  + However, the gcc toolchain there is built with --disable-lib32 (so
no multilib) and with --disable-gomp (the default)

  + Moreover, the pthreads library is not included in the distro

  + I believe building R requires GOMP and pthreads, hence I tried to
modify the scripts to add these

- Installing your own toolchain

  + Read the instructions in the section "How To Build Your Own Distro"

  + You don't have to rebuild everything in components-12.2.7z: you
only need the original binutils-2.25.7z and your own build of
mingw-w64+gcc.7z to replace Rtools's gcc

  + You will need to run a modified version of Stephan's
mingw-w64+gcc.sh script.  Besides the gcc source code, you will also
need to download the pthreads-w32 source code from
https://www.sourceware.org/pthreads-win32/

  + Here are the changes I made to the mingw-w64+gcc.sh script:

--------------------------------------------------

diff --git a/mingw-w64+gcc.sh b/mingw-w64+gcc.sh
index 2402ffc..fd44e76 100644
--- a/mingw-w64+gcc.sh
+++ b/mingw-w64+gcc.sh
@@ -8,6 +8,7 @@ source 0_append_distro_path.sh
 7z x '-oC:\Temp\gcc' gmp-6.0.0a.tar > NUL || fail_with gmp-6.0.0a.tar
- EPIC FAIL
 7z x '-oC:\Temp\gcc' mpfr-3.1.2.tar > NUL || fail_with mpfr-3.1.2.tar
- EPIC FAIL
 7z x '-oC:\Temp\gcc' mpc-1.0.2.tar > NUL || fail_with mpc-1.0.2.tar - EPIC FAIL
+7z x '-oC:\Temp\gcc' pthreads-w32-2-9-1-release.tar > NUL ||
fail_with pthreads-w32-2-9-1-release.tar - EPIC FAIL

 patch -Z -d /c/temp/gcc/mpfr-3.1.2 -p1 < mpfr.patch

@@ -25,6 +26,14 @@ make all install "CFLAGS=-s -O3" || fail_with
mingw-w64 make - EPIC FAIL
 cd /c/temp/gcc
 rm -rf build src

+# Build pthreads-w32.
+cd pthreads-w32-2-9-1-release
+make clean GC
+
+cp libpthreadGC2.a ../dest/x86_64-w64-mingw32/lib/libpthread.a
+cp pthread.h sched.h semaphore.h ../dest/x86_64-w64-mingw32/include
+cp pthreadGC2.dll $X_DISTRO_ROOT/bin/
+
 # Prepare to build gcc - set up the in-tree builds of gmp, mpfr, and mpc.
 mv gcc-4.9.2 src
 mv gmp-6.0.0 src/gmp
@@ -40,7 +49,7 @@ cp -r dest/x86_64-w64-mingw32/include
src/gcc/winsup/mingw/include
 # Configure.
 mkdir build
 cd build
-../src/configure --enable-languages=c,c++ --build=x86_64-w64-mingw32
--host=x86_64-w64-mingw32 --target=x86_64-w64-mingw32
--disable-multilib --prefix=/c/temp/gcc/dest
--with-sysroot=/c/temp/gcc/dest --disable-libstdcxx-pch --disable-lto
--disable-nls --disable-shared --disable-win32-registry
--enable-checking=release --with-tune=haswell || fail_with gcc
configure - EPIC FAIL
+../src/configure --enable-languages=c,c++,fortran
--build=x86_64-w64-mingw32 --host=x86_64-w64-mingw32
--target=x86_64-w64-mingw32 --disable-multilib
--prefix=/c/temp/gcc/dest --with-sysroot=/c/temp/gcc/dest
--disable-libstdcxx-pch --disable-lto --disable-nls --disable-shared
--disable-win32-registry --enable-libgomp --enable-checking=release
--with-tune=haswell || fail_with gcc configure - EPIC FAIL

 # --enable-languages=c,c++        : I want C and C++ only.
 # --build=x86_64-w64-mingw32      : I want a native compiler.

--------------------------------------------------

  + After running this script, you'll get your own mingw-w64+gcc.7z.

    - You'll need some patience -- the full 3-stage bootstrap of gcc
took 10 hours for me

    - You can replace the "make bootstrap" in the script by "make
bootstrap2" to omit the last stage.

  + Install your toolchain:

    - If you haven't done so, install Rtools.  We will still use the
command line utilities in C:\Rtools\bin

    - Make a new directory, e.g., C:\Rtools\nuwen and unpack
binutils-2.25.7z and mingw-w64+gcc.7z there

    - Put the above directory in your PATH, in front of any other
toolchain locations such as C:\Rtools\gcc-4.6.3\bin (it may be better
to remove the latter from your PATH)

- Now for the installation of R:

  + Get the latest R-patched sources (rather than 3.1.2, because
Duncan (thanks!) have added some useful changes)

  + Make sure you have the prerequisites for building R (see the R
Installation and Administration Manual)

    - In particular, the source files for the recommended packages,
the support files for Tcl, and the "extsoft" headers and libraries

  + In src/gnuwin32, copy MkRules.dist to MkRules.local and apply the
following patch:

--------------------------------------------------

--- MkRules.local 2015-03-02 13:57:38.601903500 -0800
+++ MkRules.local 2015-03-06 10:43:44.708581800 -0800
@@ -52,6 +52,7 @@
 # BINPREF =
 # prefix for 64-bit: path or x86_64-w64-mingw32-
 # BINPREF64 = x86_64-w64-mingw32-
+BINPREF64 =

 # Others use a -m64 or -m32 option to select architectures
 # M_ARCH =
@@ -64,6 +65,7 @@

 # 32- or 64-bit Windows?
 # WIN = 32
+WIN = 64

 # The gcc 4.9.2 64 bit toolchain is set up for the 'medium code'
model and needs
 # to remove the .refptr entries from the exports list; this is the default
@@ -135,12 +137,12 @@
 # Full paths of extra DLLs that need to be shipped
 # e.g
 # DLLs32 = c:/R/bin/pthreadGC2-w32.dll
-# DLLs64 = c:/R/bin64/pthreadGC2-w64.dll
+DLLs64 = c:/MinGW/bin/pthreadGC2.dll
 # DLLs32 =
 # DLLs64 =

 # Define this to 1 if using the gcc 4.9.2 toolchain with dynamic linking
-# COPY_RUNTIME_DLLS =
+COPY_RUNTIME_DLLS = 1

 ## ====== configuration macros for building MSI installer ===========

--------------------------------------------------

  + (I don't know whether the DLLs64 and COPY_RUNTIME_DLLS changes
above are necessary or not.  C:/MinGW/bin is where I put the pthreads
DLL that was built earlier)

  + Run "make all recommended".  If this works, you should have a
working R, built using your new toolchain!



Additional notes:

- I tried using my new R to install Rcpp from source, but this failed
because the R build scripts was not able to determine the right set of
symbols to be exported in the Rcpp DLL.  To solve this, edit the file
etc/x64/Makeconf under your R source tree, replacing

NM_FILTER = | sed -e '/.refptr./d'

by

NM_FILTER = | sed -e '/.refptr./d; /\.weak\./d'


Hope this helps,

- Hsiu-Khuern


From avraham.adler at gmail.com  Mon Mar  9 04:33:08 2015
From: avraham.adler at gmail.com (Avraham Adler)
Date: Sun, 8 Mar 2015 23:33:08 -0400
Subject: [Rd] Notes on building a gcc toolchain for Rtools (but not
	multilib)
In-Reply-To: <CAPuMoLZAWUvcQ-ubBwuqzLONom3ZLGJzzUPbmzm2E_2HzCHWYg@mail.gmail.com>
References: <CAPuMoLZAWUvcQ-ubBwuqzLONom3ZLGJzzUPbmzm2E_2HzCHWYg@mail.gmail.com>
Message-ID: <CAL6gwnKDrzw-qR43A4bd+0hKk8jzd=pPVBfMP6jmeQgH4v8EAg@mail.gmail.com>

On Sun, Mar 8, 2015 at 10:02 PM, Hsiu-Khuern Tang <tangoh at gmail.com> wrote:
> Hi,
>
> [This is a follow-up to the "New version of Rtools for Windows" thread
> in January, but I just subscribed and don't know how to reply to an
> old thread -- my apologies.]
>
> I was able to use the nuwen distro to build a gcc 4.9.2 toolchain and
> use it to build the latest R-patched with it.
>
> Below are some notes about what I did; I hope they will be useful for
> keeping Rtools up-to-date.
>
>
> Note:
>
> - This is 64-bit only; I tried but was unable to create a multilib toolchain
>
> - I did not run any tests on the resulting R binary, other than
> starting R and running some basic commands
>
> - I don't necessarily know what I'm doing!
>

Thank you for the  update, Hsiu-Khuern. Can you check how many digits
scientific notation shows? I was able to build a 64bit version of R
using the mingw64 4.8.4 distro, but ran into trouble with compat.c,
and the only work-around I found ended breaking R's defualt two digit
notation and used Windows's three-digit notation; it seems as if you
did not have this problem. Also, do you plan on running 'make check'
eventually on your build?

Avi


From tangoh at gmail.com  Mon Mar  9 05:11:31 2015
From: tangoh at gmail.com (Hsiu-Khuern Tang)
Date: Sun, 8 Mar 2015 21:11:31 -0700
Subject: [Rd] Notes on building a gcc toolchain for Rtools (but not
	multilib)
In-Reply-To: <CAL6gwnKDrzw-qR43A4bd+0hKk8jzd=pPVBfMP6jmeQgH4v8EAg@mail.gmail.com>
References: <CAPuMoLZAWUvcQ-ubBwuqzLONom3ZLGJzzUPbmzm2E_2HzCHWYg@mail.gmail.com>
	<CAL6gwnKDrzw-qR43A4bd+0hKk8jzd=pPVBfMP6jmeQgH4v8EAg@mail.gmail.com>
Message-ID: <CAPuMoLaHvijBO4autv7h2QJ6Mewptn_kXXocxO5D+BZUkLPvJA@mail.gmail.com>

On Sun, Mar 8, 2015 at 8:33 PM, Avraham Adler <avraham.adler at gmail.com> wrote:

>
> Thank you for the  update, Hsiu-Khuern. Can you check how many digits
> scientific notation shows? I was able to build a 64bit version of R
> using the mingw64 4.8.4 distro, but ran into trouble with compat.c,
> and the only work-around I found ended breaking R's defualt two digit
> notation and used Windows's three-digit notation; it seems as if you
> did not have this problem.

I get notation like "1e-09".  I think (but am not sure) that there
were some changes in mingw's stdio.h that got rid of the errors about
redefined *sprintf functions.

> Also, do you plan on running 'make check'
> eventually on your build?

I don't have any plans to do that, mainly for fear that I would find
some problems and be sucked down the rabbit hole of trying to solve
them!  Hoping someone else more knowledgeable will take the plunge :)

>
> Avi
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From avraham.adler at gmail.com  Mon Mar  9 05:37:57 2015
From: avraham.adler at gmail.com (Avraham Adler)
Date: Mon, 9 Mar 2015 00:37:57 -0400
Subject: [Rd] ICU_531 and sjlj vs.seh
Message-ID: <CAL6gwnJyKX_TRd__dNoFVtQ=Vg-MyCN6xHR9LLHBfKX+N=LhQQ@mail.gmail.com>

It seems that version of ICU_531 in
<http://www.stats.ox.ac.uk/pub/Rtools/goodies/> as of June 25, 2014,
was compiled using sjlj exception handling (current gcc-4.6.3,
perhaps?).  I say that as I am trying a 4.9.2 distribution which uses
seh handling, and I get errors like:


gcc -std=gnu99 -m64 -shared -s -mwindows -o R.dll R.def console.o
dynload.o editor.o embeddedR.o extra.o malloc.o opt.o pager.o
preferences.o psignal.o rhome.o rt_complete.o rui.o run.o shext.o
sys-win32.o system.o dos_wglob.o dllversion.o ../main/libmain.a
../appl/libappl.a ../nmath/libnmath.a getline/gl.a
../extra/xdr/libxdr.a ../extra/intl/libintl.a ../extra/trio/libtrio.a
../extra/tzone/libtz.a ../extra/tre/libtre.a -fopenmp -L. -lgfortran
-lquadmath -lRblas -L../../bin/x64 -lRgraphapp -lRiconv -lcomctl32
-lversion -L"F:/R/RLocalSoft"/lib/x64 -lpcre -lz -lbz2 -llzma
-L"F:/R/ICU_531"/lib/x64 -lsicuin -lsicuuc -lsicudt -lstdc++

F:/R/ICU_531/lib/x64/libsicuin.a(ucol.ao):ucol.cpp:(.text+0xb):
undefined reference to `__gxx_personality_sj0'
F:/R/ICU_531/lib/x64/libsicuin.a(ucol.ao):ucol.cpp:(.text+0x72):
undefined reference to `_Unwind_SjLj_Register'
F:/R/ICU_531/lib/x64/libsicuin.a(ucol.ao):ucol.cpp:(.text+0x142):
undefined reference to `_Unwind_SjLj_Unregister'
F:/R/ICU_531/lib/x64/libsicuin.a(ucol.ao):ucol.cpp:(.text+0x1b6):
undefined reference to `_Unwind_SjLj_Resume'
F:/R/ICU_531/lib/x64/libsicuin.a(ucol.ao):ucol.cpp:(.text+0x9bb):
undefined reference to `__gxx_personality_sj0'
F:/R/ICU_531/lib/x64/libsicuin.a(ucol.ao):ucol.cpp:(.text+0xa16):
undefined reference to `_Unwind_SjLj_Register'
F:/R/ICU_531/lib/x64/libsicuin.a(ucol.ao):ucol.cpp:(.text+0xaa6):
undefined reference to `_Unwind_SjLj_Unregister'
F:/R/ICU_531/lib/x64/libsicuin.a(ucol.ao):ucol.cpp:(.text+0xb6f):
undefined reference to `_Unwind_SjLj_Resume'
F:/mingw64/bin/../lib/gcc/x86_64-w64-mingw32/4.9.2/../../../../x86_64-w64-mingw32/bin/ld.exe:
F:/R/ICU_531/lib/x64/libsicuin.a(ucol.ao): bad reloc address 0x0 in
section `.pdata'
collect2.exe: error: ld returned 1 exit status
make[3]: *** [R.dll] Error 1
make[2]: *** [../../bin/x64/R.dll] Error 2
make[1]: *** [rbuild] Error 2
make: *** [all] Error 2


which seem to reflect the difference in error handling. Is there any
intention to recompile the ICU pack in the goodies directory of Rtools
with seh? If not, are there relatively straightforward directions as
to how to compile ICU from source for R which a neophyte can follow?
Ostensibly, seh provides better performance[1], [2], and if a 4.9.2
toolchain is being developed, it may be worth considering using seh.

Thank you,

Avi

[1] <http://sourceforge.net/p/mingw-w64/mailman/message/30532139/>
[2] <http://wiki.qt.io/MinGW-64-bit#Exception_handling:_SJLJ.2C_DWARF.2C_and_SEH>


From avraham.adler at gmail.com  Mon Mar  9 06:33:39 2015
From: avraham.adler at gmail.com (Avraham Adler)
Date: Mon, 9 Mar 2015 01:33:39 -0400
Subject: [Rd] Notes on building a gcc toolchain for Rtools (but not
	multilib)
In-Reply-To: <CAPuMoLaHvijBO4autv7h2QJ6Mewptn_kXXocxO5D+BZUkLPvJA@mail.gmail.com>
References: <CAPuMoLZAWUvcQ-ubBwuqzLONom3ZLGJzzUPbmzm2E_2HzCHWYg@mail.gmail.com>
	<CAL6gwnKDrzw-qR43A4bd+0hKk8jzd=pPVBfMP6jmeQgH4v8EAg@mail.gmail.com>
	<CAPuMoLaHvijBO4autv7h2QJ6Mewptn_kXXocxO5D+BZUkLPvJA@mail.gmail.com>
Message-ID: <CAL6gwnK-bVqwfqBmEhXidaTG8hBF+u9Ox_fyY9enek0GpUK=Nw@mail.gmail.com>

Spurred by Hsiu-Khuern's post, I was able to compile
R-devel_2015-03-08 using the already compiled distribution at
<http://sourceforge.net/projects/mingw-w64/files/Toolchains%20targetting%20Win64/Personal%20Builds/mingw-builds/4.9.2/threads-win32/seh/x86_64-4.9.2-release-win32-seh-rt_v3-rev1.7z/download>This
GCC 4.9.2 using seh error handling and windows threads, so as per this
note <https://stat.ethz.ch/pipermail/r-devel/2015-March/070782.html>,
I left out ICU. I also did not use curl for this build, I applied
Hsiu-Khuern's suggestion to the NM filtering, and I left leaving
Rtools\bin to handle utilities like tar.

I built all, cairodevices, recommended, vignettes, manuals, and
rinstaller, and then ran make check-all. The only .out.fail file that
appeared was the one for "internet.R" where I got a "connect: No
error". That was fixed inside R by using setInternet2(). This has not
happened for me before; has the internet handling in r-devel been
changed? Is there a way to have that properly set in the Makefile?
Skimming through the logs of the make check-all, some vignettes failed
to generate as the packages they depend on could not be loaded. If
there was a way to have the proper internet connectivity set when
being compiled, it appears this would have passed make check-all
completely.

This build was also compiled against OpenBLAS 2.13 and a bunch of
optimizations (specifically -O3 -march=native -mfpmath=sse -msse2avx
-mavx256-split-unaligned-load -mavx256-split-unaligned-store
-mvzeroupper -std=gnu++11 -pipe) and it still passed.

While I uncommented OPENMP and PTHREAD in Mkrules, I have not
explicitly checked them (unless that is handled in check-all). Also, I
only built 64 bit, I did not try to simultaneously build a 32-bit
version. However, being that this distribution is already compiled and
exists, it may be easier to use than having to custom build off of the
neuwen distro, and perhaps someone with more skill can try the 32 bit
version and even getting curl to work (which may sidestep the internet
problem I had above).

Thank you,

Avi


From murdoch.duncan at gmail.com  Mon Mar  9 11:50:54 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 09 Mar 2015 06:50:54 -0400
Subject: [Rd] Notes on building a gcc toolchain for Rtools (but not
	multilib)
In-Reply-To: <CAPuMoLZAWUvcQ-ubBwuqzLONom3ZLGJzzUPbmzm2E_2HzCHWYg@mail.gmail.com>
References: <CAPuMoLZAWUvcQ-ubBwuqzLONom3ZLGJzzUPbmzm2E_2HzCHWYg@mail.gmail.com>
Message-ID: <54FD7B0E.8040500@gmail.com>

On 08/03/2015 10:02 PM, Hsiu-Khuern Tang wrote:
> Hi,
> 
> [This is a follow-up to the "New version of Rtools for Windows" thread
> in January, but I just subscribed and don't know how to reply to an
> old thread -- my apologies.]

I am planning to put a new Rtools online today that uses a different
build of gcc 4.9.2.  I will be concentrating on getting it to work with
all the external libraries before the 3.2.0 release next month.  I'm not
planning to try to get it to work with R-patched, and I expect it won't:
 I needed to make a number of patches to R-devel for compatibility.

It is also not multilib.  It uses static linking of libraries, and SJLJ
exception handling in both 32 and 64 bit builds -- this is necessary for
compatibility with existing compiles of external libraries, but may not
be ideal in 64 bits.  However, I believe using SEH will mean static
linking is impossible, and that leads to problems distributing run-time
DLLs, and I'd rather not worry about those.

Testing of the new Rtools will be appreciated.  I expect the R-devel
builds will start using it tomorrow or the next day.

Duncan Murdoch

> 
> I was able to use the nuwen distro to build a gcc 4.9.2 toolchain and
> use it to build the latest R-patched with it.
> 
> Below are some notes about what I did; I hope they will be useful for
> keeping Rtools up-to-date.
> 
> 
> Note:
> 
> - This is 64-bit only; I tried but was unable to create a multilib toolchain
> 
> - I did not run any tests on the resulting R binary, other than
> starting R and running some basic commands
> 
> - I don't necessarily know what I'm doing!
> 
> 
> Outline of steps:
> 
> - The (nicely done!) nuwen website by Stephan Lavavej has made
> available a MinGW distro and the scripts used to create it.
> 
>   + However, the gcc toolchain there is built with --disable-lib32 (so
> no multilib) and with --disable-gomp (the default)
> 
>   + Moreover, the pthreads library is not included in the distro
> 
>   + I believe building R requires GOMP and pthreads, hence I tried to
> modify the scripts to add these
> 
> - Installing your own toolchain
> 
>   + Read the instructions in the section "How To Build Your Own Distro"
> 
>   + You don't have to rebuild everything in components-12.2.7z: you
> only need the original binutils-2.25.7z and your own build of
> mingw-w64+gcc.7z to replace Rtools's gcc
> 
>   + You will need to run a modified version of Stephan's
> mingw-w64+gcc.sh script.  Besides the gcc source code, you will also
> need to download the pthreads-w32 source code from
> https://www.sourceware.org/pthreads-win32/
> 
>   + Here are the changes I made to the mingw-w64+gcc.sh script:
> 
> --------------------------------------------------
> 
> diff --git a/mingw-w64+gcc.sh b/mingw-w64+gcc.sh
> index 2402ffc..fd44e76 100644
> --- a/mingw-w64+gcc.sh
> +++ b/mingw-w64+gcc.sh
> @@ -8,6 +8,7 @@ source 0_append_distro_path.sh
>  7z x '-oC:\Temp\gcc' gmp-6.0.0a.tar > NUL || fail_with gmp-6.0.0a.tar
> - EPIC FAIL
>  7z x '-oC:\Temp\gcc' mpfr-3.1.2.tar > NUL || fail_with mpfr-3.1.2.tar
> - EPIC FAIL
>  7z x '-oC:\Temp\gcc' mpc-1.0.2.tar > NUL || fail_with mpc-1.0.2.tar - EPIC FAIL
> +7z x '-oC:\Temp\gcc' pthreads-w32-2-9-1-release.tar > NUL ||
> fail_with pthreads-w32-2-9-1-release.tar - EPIC FAIL
> 
>  patch -Z -d /c/temp/gcc/mpfr-3.1.2 -p1 < mpfr.patch
> 
> @@ -25,6 +26,14 @@ make all install "CFLAGS=-s -O3" || fail_with
> mingw-w64 make - EPIC FAIL
>  cd /c/temp/gcc
>  rm -rf build src
> 
> +# Build pthreads-w32.
> +cd pthreads-w32-2-9-1-release
> +make clean GC
> +
> +cp libpthreadGC2.a ../dest/x86_64-w64-mingw32/lib/libpthread.a
> +cp pthread.h sched.h semaphore.h ../dest/x86_64-w64-mingw32/include
> +cp pthreadGC2.dll $X_DISTRO_ROOT/bin/
> +
>  # Prepare to build gcc - set up the in-tree builds of gmp, mpfr, and mpc.
>  mv gcc-4.9.2 src
>  mv gmp-6.0.0 src/gmp
> @@ -40,7 +49,7 @@ cp -r dest/x86_64-w64-mingw32/include
> src/gcc/winsup/mingw/include
>  # Configure.
>  mkdir build
>  cd build
> -../src/configure --enable-languages=c,c++ --build=x86_64-w64-mingw32
> --host=x86_64-w64-mingw32 --target=x86_64-w64-mingw32
> --disable-multilib --prefix=/c/temp/gcc/dest
> --with-sysroot=/c/temp/gcc/dest --disable-libstdcxx-pch --disable-lto
> --disable-nls --disable-shared --disable-win32-registry
> --enable-checking=release --with-tune=haswell || fail_with gcc
> configure - EPIC FAIL
> +../src/configure --enable-languages=c,c++,fortran
> --build=x86_64-w64-mingw32 --host=x86_64-w64-mingw32
> --target=x86_64-w64-mingw32 --disable-multilib
> --prefix=/c/temp/gcc/dest --with-sysroot=/c/temp/gcc/dest
> --disable-libstdcxx-pch --disable-lto --disable-nls --disable-shared
> --disable-win32-registry --enable-libgomp --enable-checking=release
> --with-tune=haswell || fail_with gcc configure - EPIC FAIL
> 
>  # --enable-languages=c,c++        : I want C and C++ only.
>  # --build=x86_64-w64-mingw32      : I want a native compiler.
> 
> --------------------------------------------------
> 
>   + After running this script, you'll get your own mingw-w64+gcc.7z.
> 
>     - You'll need some patience -- the full 3-stage bootstrap of gcc
> took 10 hours for me
> 
>     - You can replace the "make bootstrap" in the script by "make
> bootstrap2" to omit the last stage.
> 
>   + Install your toolchain:
> 
>     - If you haven't done so, install Rtools.  We will still use the
> command line utilities in C:\Rtools\bin
> 
>     - Make a new directory, e.g., C:\Rtools\nuwen and unpack
> binutils-2.25.7z and mingw-w64+gcc.7z there
> 
>     - Put the above directory in your PATH, in front of any other
> toolchain locations such as C:\Rtools\gcc-4.6.3\bin (it may be better
> to remove the latter from your PATH)
> 
> - Now for the installation of R:
> 
>   + Get the latest R-patched sources (rather than 3.1.2, because
> Duncan (thanks!) have added some useful changes)
> 
>   + Make sure you have the prerequisites for building R (see the R
> Installation and Administration Manual)
> 
>     - In particular, the source files for the recommended packages,
> the support files for Tcl, and the "extsoft" headers and libraries
> 
>   + In src/gnuwin32, copy MkRules.dist to MkRules.local and apply the
> following patch:
> 
> --------------------------------------------------
> 
> --- MkRules.local 2015-03-02 13:57:38.601903500 -0800
> +++ MkRules.local 2015-03-06 10:43:44.708581800 -0800
> @@ -52,6 +52,7 @@
>  # BINPREF =
>  # prefix for 64-bit: path or x86_64-w64-mingw32-
>  # BINPREF64 = x86_64-w64-mingw32-
> +BINPREF64 =
> 
>  # Others use a -m64 or -m32 option to select architectures
>  # M_ARCH =
> @@ -64,6 +65,7 @@
> 
>  # 32- or 64-bit Windows?
>  # WIN = 32
> +WIN = 64
> 
>  # The gcc 4.9.2 64 bit toolchain is set up for the 'medium code'
> model and needs
>  # to remove the .refptr entries from the exports list; this is the default
> @@ -135,12 +137,12 @@
>  # Full paths of extra DLLs that need to be shipped
>  # e.g
>  # DLLs32 = c:/R/bin/pthreadGC2-w32.dll
> -# DLLs64 = c:/R/bin64/pthreadGC2-w64.dll
> +DLLs64 = c:/MinGW/bin/pthreadGC2.dll
>  # DLLs32 =
>  # DLLs64 =
> 
>  # Define this to 1 if using the gcc 4.9.2 toolchain with dynamic linking
> -# COPY_RUNTIME_DLLS =
> +COPY_RUNTIME_DLLS = 1
> 
>  ## ====== configuration macros for building MSI installer ===========
> 
> --------------------------------------------------
> 
>   + (I don't know whether the DLLs64 and COPY_RUNTIME_DLLS changes
> above are necessary or not.  C:/MinGW/bin is where I put the pthreads
> DLL that was built earlier)
> 
>   + Run "make all recommended".  If this works, you should have a
> working R, built using your new toolchain!
> 
> 
> 
> Additional notes:
> 
> - I tried using my new R to install Rcpp from source, but this failed
> because the R build scripts was not able to determine the right set of
> symbols to be exported in the Rcpp DLL.  To solve this, edit the file
> etc/x64/Makeconf under your R source tree, replacing
> 
> NM_FILTER = | sed -e '/.refptr./d'
> 
> by
> 
> NM_FILTER = | sed -e '/.refptr./d; /\.weak\./d'
> 
> 
> Hope this helps,
> 
> - Hsiu-Khuern
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From tangoh at gmail.com  Mon Mar  9 16:07:27 2015
From: tangoh at gmail.com (Hsiu-Khuern Tang)
Date: Mon, 9 Mar 2015 08:07:27 -0700
Subject: [Rd] Notes on building a gcc toolchain for Rtools (but not
	multilib)
In-Reply-To: <54FD7B0E.8040500@gmail.com>
References: <CAPuMoLZAWUvcQ-ubBwuqzLONom3ZLGJzzUPbmzm2E_2HzCHWYg@mail.gmail.com>
	<54FD7B0E.8040500@gmail.com>
Message-ID: <CAPuMoLba=3k_tX3Vg8hn8=30LzhTRTpVexkk0WZTn7vCOCp6Mw@mail.gmail.com>

On Mon, Mar 9, 2015 at 3:50 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 08/03/2015 10:02 PM, Hsiu-Khuern Tang wrote:
>> Hi,
>>
>> [This is a follow-up to the "New version of Rtools for Windows" thread
>> in January, but I just subscribed and don't know how to reply to an
>> old thread -- my apologies.]
>
> I am planning to put a new Rtools online today that uses a different
> build of gcc 4.9.2.  I will be concentrating on getting it to work with
> all the external libraries before the 3.2.0 release next month.  I'm not
> planning to try to get it to work with R-patched, and I expect it won't:
>  I needed to make a number of patches to R-devel for compatibility.

I also worked off R-devel (I said wrongly that it was R-patched in my
original post) and benefited from your compatibility changes.

I look forward to the new Rtools and will test it by compiling some packages.

- Hsiu-Khuern


From avraham.adler at gmail.com  Mon Mar  9 16:10:30 2015
From: avraham.adler at gmail.com (Avraham Adler)
Date: Mon, 9 Mar 2015 11:10:30 -0400
Subject: [Rd] Notes on building a gcc toolchain for Rtools (but not
	multilib)
In-Reply-To: <54FD7B0E.8040500@gmail.com>
References: <CAPuMoLZAWUvcQ-ubBwuqzLONom3ZLGJzzUPbmzm2E_2HzCHWYg@mail.gmail.com>
	<54FD7B0E.8040500@gmail.com>
Message-ID: <CAL6gwnLmb7kQfVq0x0dV2LNedAJY8_pR3v9ABCTPQ76x-dtK9A@mail.gmail.com>

On Mon, Mar 9, 2015 at 6:50 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> It is also not multilib.  It uses static linking of libraries, and SJLJ
> exception handling in both 32 and 64 bit builds -- this is necessary for
> compatibility with existing compiles of external libraries, but may not
> be ideal in 64 bits.  However, I believe using SEH will mean static
> linking is impossible, and that leads to problems distributing run-time
> DLLs, and I'd rather not worry about those.

That is great news, Dr. Murdoch.

I know that ICU, curl, and the files in goodies (lzma, jpeg ,etc.) are
now external libraries necessary for compiling R. Is that all, or are
there (many) others of which I am unaware? I understand that given the
release date of 3.2.0, the focus needs to be on having a functional
toolset and all that entails, and if that means sjlj is used for now,
that is perfectly reasonable.

However, if the number of such external libraries is manageable, would
it make sense to recompile /them/ using an seh toolchain to take
advantage of the increased performance?

Thank you,

Avi


From avraham.adler at gmail.com  Mon Mar  9 16:11:05 2015
From: avraham.adler at gmail.com (Avraham Adler)
Date: Mon, 9 Mar 2015 11:11:05 -0400
Subject: [Rd] Notes on building a gcc toolchain for Rtools (but not
	multilib)
In-Reply-To: <CAPuMoLba=3k_tX3Vg8hn8=30LzhTRTpVexkk0WZTn7vCOCp6Mw@mail.gmail.com>
References: <CAPuMoLZAWUvcQ-ubBwuqzLONom3ZLGJzzUPbmzm2E_2HzCHWYg@mail.gmail.com>
	<54FD7B0E.8040500@gmail.com>
	<CAPuMoLba=3k_tX3Vg8hn8=30LzhTRTpVexkk0WZTn7vCOCp6Mw@mail.gmail.com>
Message-ID: <CAL6gwnJHJrqEnrSMA44yH+mrJFXiOXXja0uu8paGx-WE3SnX9g@mail.gmail.com>

On Mon, Mar 9, 2015 at 11:07 AM, Hsiu-Khuern Tang <tangoh at gmail.com> wrote:
> I also worked off R-devel (I said wrongly that it was R-patched in my
> original post) and benefited from your compatibility changes.

Hsiu-Khuern, using your suggest filter in NM, I was able to build Rcpp
in the R_devel compiled with Gcc 4.9.2/win32/seh last night, and I saw
around a 10%-15% speedup in Rcpp performance (and R performance in
general) from the 3.1.2 version I compiled with Rtool 4.6.3. That may
be related to inherent optimizations in 4.9.2 vs 4.6.3, it may be
related to seh vs sjlj, or it may be related to passing gnu++11
instead of gnu++0x, I don't know. I do know it was the same code on
the same machine, for what it is worth.

Thank you,

Avi


From kmezhoud at gmail.com  Mon Mar  9 17:49:29 2015
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Mon, 9 Mar 2015 16:49:29 +0000
Subject: [Rd] Fwd: Rstudio R-devel libR.so
In-Reply-To: <CALJKBv__2iVp1-4C+q513npuYQKqwiDQ+zD15eBMxhKOYyt7FQ@mail.gmail.com>
References: <CALJKBv__2iVp1-4C+q513npuYQKqwiDQ+zD15eBMxhKOYyt7FQ@mail.gmail.com>
Message-ID: <CALJKBv-L66+z+oReyFAHROE_P+gsEye2=vEynGWoJnjn_yDWqw@mail.gmail.com>

Dear All,
I am actually on R-devel using shell consol. When I run RStudio, it can't
find libR.so in the new /lib folder where is libRblas.so  libRlapack.so.
At first step I configure R-devel to share library with ./configure
--enable-R-shlib.

when I copied libR.so from  /usr/lib/R/lib/libR.so (stable version R 3.1)
to /usr/local/R-devel/lib/libR.so (R-devel version), That doesn't work.

please find the detail  at below.
Karim mezhoud




$which R
/usr/bin/R
$R
> R.Version()[13]
$version.string
[1] "R version 3.1.2 (2014-10-31)

> Sys.getenv("R_HOME")
[1] "/usr/lib/R"

> .Library
[1] "/usr/lib/R/library"
> .libPaths()
[1] "/home/mezhoud/R/x86_64-pc-linux-gnu-library/3.1"
[2] "/usr/local/lib/R/site-library"
[3] "/usr/lib/R/site-library"
[4] "/usr/lib/R/library"
"


$sudo apt-get build-dep r-base
$sudo apt-get install subversion ccache
$mkdir ~/svn/
$cd ~/svn/
$svn co https://svn.r-project.org/R/trunk r-devel/R

$cd /svn/r-devel/R
$./configure --enable-R-shlib
$make
$make check
$sudo make install rhome=/usr/local/R-devel

$which R
/usr/local/bin/R

$cd /usr/local/bin
$R

>R.Version()[13]
$version.string
[1] "R Under development (unstable) (2015-03-07 r67951)"

> .libPaths()
[1] "/usr/local/R-devel/library"
> .Library
[1] "/usr/local/R-devel/library"

> Sys.getenv("R_HOME")
[1] "/usr/local/R-devel"

$rstudio
R shared library (/usr/local/R-devel/lib/libR.so) not found.
If this is a custom build of R, was it built with the --enable-R-shlib
option?

$export RSTUDIO_WHICH_R=/usr/local/bin/R
$rstudio
R shared library (/usr/local/R-devel/lib/libR.so) not found.
If this is a custom build of R, was it built with the --enable-R-shlib
option?

$export RSTUDIO_WHICH_R=/usr/local/R-devel/bin/R
$rstudio
R shared library (/usr/local/R-devel/lib/libR.so) not found.
If this is a custom build of R, was it built with the --enable-R-shlib
option?

$sudo locate libR.so
/usr/lib/libR.so
/usr/lib/R/lib/libR.so


When I get a symbolic link with:

 sudo ln -s  /usr/lib/R/lib/libR.so /usr/local/R-devel//lib/libR.so


The R session had a fatal error.


ERROR r error 4 (R code execution error) [errormsg=Error in
.Internal(getOption(x)) :

there is no .Internal function 'getOption'

]; OCCURRED AT: core::Error r::exec::evaluateString(const std::string&,
SEXPREC**, r::sexp::Protect*) /home/ubuntu/rstudio/src/cpp/r/RExec.cpp:

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon Mar  9 18:40:02 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 09 Mar 2015 13:40:02 -0400
Subject: [Rd] Notes on building a gcc toolchain for Rtools (but not
	multilib)
In-Reply-To: <CAPuMoLba=3k_tX3Vg8hn8=30LzhTRTpVexkk0WZTn7vCOCp6Mw@mail.gmail.com>
References: <CAPuMoLZAWUvcQ-ubBwuqzLONom3ZLGJzzUPbmzm2E_2HzCHWYg@mail.gmail.com>	<54FD7B0E.8040500@gmail.com>
	<CAPuMoLba=3k_tX3Vg8hn8=30LzhTRTpVexkk0WZTn7vCOCp6Mw@mail.gmail.com>
Message-ID: <54FDDAF2.9040005@gmail.com>

On 09/03/2015 11:07 AM, Hsiu-Khuern Tang wrote:
> On Mon, Mar 9, 2015 at 3:50 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> > On 08/03/2015 10:02 PM, Hsiu-Khuern Tang wrote:
> >> Hi,
> >>
> >> [This is a follow-up to the "New version of Rtools for Windows" thread
> >> in January, but I just subscribed and don't know how to reply to an
> >> old thread -- my apologies.]
> >
> > I am planning to put a new Rtools online today that uses a different
> > build of gcc 4.9.2.  I will be concentrating on getting it to work with
> > all the external libraries before the 3.2.0 release next month.  I'm not
> > planning to try to get it to work with R-patched, and I expect it won't:
> >  I needed to make a number of patches to R-devel for compatibility.
>
> I also worked off R-devel (I said wrongly that it was R-patched in my
> original post) and benefited from your compatibility changes.
>
> I look forward to the new Rtools and will test it by compiling some packages.

It's now on the main site at CRAN, and should propagate to the mirrors 
reasonably quickly.  I'm hoping that tomorrow's R-devel build will use 
it, but there may be some last minute problems.

Duncan Murdoch


From murdoch.duncan at gmail.com  Mon Mar  9 21:30:20 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 09 Mar 2015 16:30:20 -0400
Subject: [Rd] Notes on building a gcc toolchain for Rtools (but not
	multilib)
In-Reply-To: <54FDDAF2.9040005@gmail.com>
References: <CAPuMoLZAWUvcQ-ubBwuqzLONom3ZLGJzzUPbmzm2E_2HzCHWYg@mail.gmail.com>	<54FD7B0E.8040500@gmail.com>
	<CAPuMoLba=3k_tX3Vg8hn8=30LzhTRTpVexkk0WZTn7vCOCp6Mw@mail.gmail.com>
	<54FDDAF2.9040005@gmail.com>
Message-ID: <54FE02DC.1010908@gmail.com>

On 09/03/2015 1:40 PM, Duncan Murdoch wrote:
> On 09/03/2015 11:07 AM, Hsiu-Khuern Tang wrote:
> > On Mon, Mar 9, 2015 at 3:50 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> > > On 08/03/2015 10:02 PM, Hsiu-Khuern Tang wrote:
> > >> Hi,
> > >>
> > >> [This is a follow-up to the "New version of Rtools for Windows" thread
> > >> in January, but I just subscribed and don't know how to reply to an
> > >> old thread -- my apologies.]
> > >
> > > I am planning to put a new Rtools online today that uses a different
> > > build of gcc 4.9.2.  I will be concentrating on getting it to work with
> > > all the external libraries before the 3.2.0 release next month.  I'm not
> > > planning to try to get it to work with R-patched, and I expect it won't:
> > >  I needed to make a number of patches to R-devel for compatibility.
> >
> > I also worked off R-devel (I said wrongly that it was R-patched in my
> > original post) and benefited from your compatibility changes.
> >
> > I look forward to the new Rtools and will test it by compiling some packages.
>
> It's now on the main site at CRAN, and should propagate to the mirrors
> reasonably quickly.  I'm hoping that tomorrow's R-devel build will use
> it, but there may be some last minute problems.

I think R-devel will have some trouble finding the compilers if they 
aren't in the default install locations in c:\Rtools.  This should be 
fixed in a few days, probably by requiring an environment variable to 
specify where Rtools is installed.

In the meantime, if you get "gcc not found" errors, you can manually 
edit the etc/*/Makeconf file in the R-devel binary install, and set 
BINPREF to  <Rtools>/gcc492_32/bin/ for *=i386, and set BINPREF64 to 
<Rtools>/gcc492_64/bin/ for *=x64.

Duncan Murdoch


From kmezhoud at gmail.com  Mon Mar  9 22:44:25 2015
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Mon, 9 Mar 2015 21:44:25 +0000
Subject: [Rd] Fwd: Rstudio R-devel libR.so
In-Reply-To: <CAJXgQP0h0kk9HvcN9jf3dNL2iFahM-pUHWwGkys2=1Px2cXMzg@mail.gmail.com>
References: <CALJKBv__2iVp1-4C+q513npuYQKqwiDQ+zD15eBMxhKOYyt7FQ@mail.gmail.com>
	<CALJKBv-L66+z+oReyFAHROE_P+gsEye2=vEynGWoJnjn_yDWqw@mail.gmail.com>
	<CAJXgQP0h0kk9HvcN9jf3dNL2iFahM-pUHWwGkys2=1Px2cXMzg@mail.gmail.com>
Message-ID: <CALJKBv-JjTj_Na4gaJE+aa6SBJxQj8PNDJ-sdPKWskRm92ukMg@mail.gmail.com>

Hi,
I forgot

tools/rsync-recommended

before

./configure



Thanks


On Mon, Mar 9, 2015 at 6:51 PM, Kevin Ushey <kevinushey at gmail.com> wrote:

> I believe you need to set the environment variable R_HOME_DIR to the
> path pointing to your R-devel installation before launching RStudio.
>
> On Mon, Mar 9, 2015 at 9:49 AM, Karim Mezhoud <kmezhoud at gmail.com> wrote:
> > Dear All,
> > I am actually on R-devel using shell consol. When I run RStudio, it can't
> > find libR.so in the new /lib folder where is libRblas.so  libRlapack.so.
> > At first step I configure R-devel to share library with ./configure
> > --enable-R-shlib.
> >
> > when I copied libR.so from  /usr/lib/R/lib/libR.so (stable version R 3.1)
> > to /usr/local/R-devel/lib/libR.so (R-devel version), That doesn't work.
> >
> > please find the detail  at below.
> > Karim mezhoud
> >
> >
> >
> >
> > $which R
> > /usr/bin/R
> > $R
> >> R.Version()[13]
> > $version.string
> > [1] "R version 3.1.2 (2014-10-31)
> >
> >> Sys.getenv("R_HOME")
> > [1] "/usr/lib/R"
> >
> >> .Library
> > [1] "/usr/lib/R/library"
> >> .libPaths()
> > [1] "/home/mezhoud/R/x86_64-pc-linux-gnu-library/3.1"
> > [2] "/usr/local/lib/R/site-library"
> > [3] "/usr/lib/R/site-library"
> > [4] "/usr/lib/R/library"
> > "
> >
> >
> > $sudo apt-get build-dep r-base
> > $sudo apt-get install subversion ccache
> > $mkdir ~/svn/
> > $cd ~/svn/
> > $svn co https://svn.r-project.org/R/trunk r-devel/R
> >
> > $cd /svn/r-devel/R
> > $./configure --enable-R-shlib
> > $make
> > $make check
> > $sudo make install rhome=/usr/local/R-devel
> >
> > $which R
> > /usr/local/bin/R
> >
> > $cd /usr/local/bin
> > $R
> >
> >>R.Version()[13]
> > $version.string
> > [1] "R Under development (unstable) (2015-03-07 r67951)"
> >
> >> .libPaths()
> > [1] "/usr/local/R-devel/library"
> >> .Library
> > [1] "/usr/local/R-devel/library"
> >
> >> Sys.getenv("R_HOME")
> > [1] "/usr/local/R-devel"
> >
> > $rstudio
> > R shared library (/usr/local/R-devel/lib/libR.so) not found.
> > If this is a custom build of R, was it built with the --enable-R-shlib
> > option?
> >
> > $export RSTUDIO_WHICH_R=/usr/local/bin/R
> > $rstudio
> > R shared library (/usr/local/R-devel/lib/libR.so) not found.
> > If this is a custom build of R, was it built with the --enable-R-shlib
> > option?
> >
> > $export RSTUDIO_WHICH_R=/usr/local/R-devel/bin/R
> > $rstudio
> > R shared library (/usr/local/R-devel/lib/libR.so) not found.
> > If this is a custom build of R, was it built with the --enable-R-shlib
> > option?
> >
> > $sudo locate libR.so
> > /usr/lib/libR.so
> > /usr/lib/R/lib/libR.so
> >
> >
> > When I get a symbolic link with:
> >
> >  sudo ln -s  /usr/lib/R/lib/libR.so /usr/local/R-devel//lib/libR.so
> >
> >
> > The R session had a fatal error.
> >
> >
> > ERROR r error 4 (R code execution error) [errormsg=Error in
> > .Internal(getOption(x)) :
> >
> > there is no .Internal function 'getOption'
> >
> > ]; OCCURRED AT: core::Error r::exec::evaluateString(const std::string&,
> > SEXPREC**, r::sexp::Protect*) /home/ubuntu/rstudio/src/cpp/r/RExec.cpp:
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From tangoh at gmail.com  Tue Mar 10 04:02:44 2015
From: tangoh at gmail.com (Hsiu-Khuern Tang)
Date: Mon, 9 Mar 2015 20:02:44 -0700
Subject: [Rd] Notes on building a gcc toolchain for Rtools (but not
	multilib)
In-Reply-To: <54FDDAF2.9040005@gmail.com>
References: <CAPuMoLZAWUvcQ-ubBwuqzLONom3ZLGJzzUPbmzm2E_2HzCHWYg@mail.gmail.com>
	<54FD7B0E.8040500@gmail.com>
	<CAPuMoLba=3k_tX3Vg8hn8=30LzhTRTpVexkk0WZTn7vCOCp6Mw@mail.gmail.com>
	<54FDDAF2.9040005@gmail.com>
Message-ID: <CAPuMoLY7oBsRbk_L82u4QEHxL+KRY07yNMotdVesF8+KQ9TdnA@mail.gmail.com>

Hi Duncan,

On Mon, Mar 9, 2015 at 10:40 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 09/03/2015 11:07 AM, Hsiu-Khuern Tang wrote:
>>
>> On Mon, Mar 9, 2015 at 3:50 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
>> wrote:
>> > On 08/03/2015 10:02 PM, Hsiu-Khuern Tang wrote:
>> >> Hi,
>> >>
>> >> [This is a follow-up to the "New version of Rtools for Windows" thread
>> >> in January, but I just subscribed and don't know how to reply to an
>> >> old thread -- my apologies.]
>> >
>> > I am planning to put a new Rtools online today that uses a different
>> > build of gcc 4.9.2.  I will be concentrating on getting it to work with
>> > all the external libraries before the 3.2.0 release next month.  I'm not
>> > planning to try to get it to work with R-patched, and I expect it won't:
>> >  I needed to make a number of patches to R-devel for compatibility.
>>
>> I also worked off R-devel (I said wrongly that it was R-patched in my
>> original post) and benefited from your compatibility changes.
>>
>> I look forward to the new Rtools and will test it by compiling some
>> packages.
>
>
> It's now on the main site at CRAN, and should propagate to the mirrors
> reasonably quickly.  I'm hoping that tomorrow's R-devel build will use it,
> but there may be some last minute problems.

Is the new Rtools at
http://cran.r-project.org/bin/windows/Rtools/Rtools33.exe?  I'm still
getting "Error 404 object not found".

Thanks,
- Hsiu-Khuern


From avraham.adler at gmail.com  Tue Mar 10 08:03:20 2015
From: avraham.adler at gmail.com (Avraham Adler)
Date: Tue, 10 Mar 2015 03:03:20 -0400
Subject: [Rd] Notes on building a gcc toolchain for Rtools (but not
	multilib)
In-Reply-To: <CAPuMoLY7oBsRbk_L82u4QEHxL+KRY07yNMotdVesF8+KQ9TdnA@mail.gmail.com>
References: <CAPuMoLZAWUvcQ-ubBwuqzLONom3ZLGJzzUPbmzm2E_2HzCHWYg@mail.gmail.com>
	<54FD7B0E.8040500@gmail.com>
	<CAPuMoLba=3k_tX3Vg8hn8=30LzhTRTpVexkk0WZTn7vCOCp6Mw@mail.gmail.com>
	<54FDDAF2.9040005@gmail.com>
	<CAPuMoLY7oBsRbk_L82u4QEHxL+KRY07yNMotdVesF8+KQ9TdnA@mail.gmail.com>
Message-ID: <CAL6gwnJ7-JZTD+JuswunMqRHjGNyHL3X5abECrQM4T68o7JSsA@mail.gmail.com>

> On Mon, Mar 9, 2015 at 10:40 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
> It's now on the main site at CRAN, and should propagate to the mirrors
> reasonably quickly.  I'm hoping that tomorrow's R-devel build will use it,
> but there may be some last minute problems.

Using Rtools 3.3, once it propagated through the cran servers, I have
successfully built a 64-bit version of R on Windows 7, up through make
rinstaller. This one includes using ICU_531, and also includes linking
to 64-bit OpenBLAS 2.13 (4 threads).

As with yesterday's build using 4.9.2.-seh (although that one left ICU
out) the only issue that seems to have failed in make check-all is the
internet connectivity, which is disabled by default. Loading R and
passing setinternet2() fixes that, and I plan on using the options
built into the installer I create to have that set at install (like
SDI). Is it at all possible to have that setting exposed in
Mkrules.dist so as to be set at compile?

I also built microbenchmark, which requires packages ?colorspace?,
?Rcpp?, ?stringr?, ?RColorBrewer?, ?dichromat?, ?munsell?, ?labeling?,
?plyr?, ?digest?, ?gtable?, ?reshape2?, ?scales?, ?proto?, and
?ggplot2?, and they all worked fine. For what it is worth, I forgot to
uncomment (unhash) Hsiu-Khuern's addition to the NM filter, yet Rcpp
built fine and compiled C++ code fine as well, although about 3%-5%
slower than what I recall from last night's seh version.

So, outside of this hiccup with somehow now needing internet2 (which
may have to do with microsoft Windows patches for all I know) which
cannot be set at default, it seems as if the toolchain is behaving
well! I have not tried building with curl, though; that looks a bit
more hairy, although it may address the internet2 issue, who knows.

For interest sakes, below is a comparison of speed across various
versions/compilers which may prove of interest. The takeaway for me is
that for matrix code a fast BLAS is significantly more important than
which version of GCC and exception handling is used. For non-BLAS
specific code, at least on my machine, the SJLJ performed about 1%?2%
*faster*. Go figure! Maybe someone will run Simon Urbanek's benchmark
against them.

Regardless, I'm much less apprehensive about 3.2's release in April.
Thank you, Duncan and all!


Avi



== Speed results compiled over a few months (except for the last two) ==

For the record, all code run on an Intel i7-2600K overclocked to
4.6Ghz, 16GB RAM, Windows 7 64bit Matrices A and B are 1000x1000 dense
matrices, of which A is positive semi-definite and B is not. I use
this to test BLAS builds. I hope that the fixed width works in plain
text model.

=== Non-BLAS dependent ===

#Test code
library(microbenchmark)
A <- as.matrix(read.csv(file="F:/R/A.csv", colClasses='numeric'))
B <- as.matrix(read.csv(file="F:/R/B.csv", colClasses='numeric'))
colnames(A) <- colnames(B) <- NULL
Z <- microbenchmark(A + 2, A - 2, A * 2, A / 2, A + B, A - B, A * B, A
/ B, A ^ 2, sqrt(A), control=list(order = 'block'), times = 1000L)


 R-devel_2015-03-08 compiled using
x86_64-4.9.2-release-win32-seh-rt_v3-rev1 (EOPTS = -O3 -march=native
-mfpmath=sse -msse2avx -mavx256-split-unaligned-load
-mavx256-split-unaligned-store -mvzeroupper -std=gnu++11 -pipe)
 OpenBLAS 2.13 - Multi-threaded (max 4 threads) - compiled under GCC
4.9.1 (MinGW-64)

 Unit: microseconds
    expr       min        lq      mean    median        uq      max neval
   A + 2   923.001  1844.215  2205.385  1858.957  1990.900 21714.18  1000
   A - 2  1742.652  1830.215  2196.901  1844.810  2507.798 21778.22  1000
   A * 2  1743.247  1843.023  2208.374  1860.298  2547.112 21776.43  1000
     A/2  2025.598  2111.375  2438.503  2122.097  2701.243 22034.06  1000
   A + B  2016.662  2124.182  2554.006  2143.690  2948.896 21964.07  1000
   A - B  2004.153  2103.930  2527.219  2128.203  2982.552 22295.27  1000
   A * B  2023.215  2119.715  2540.680  2141.010  3154.553 22074.27  1000
     A/B  3256.265  3354.700  3633.556  3368.252  3953.950 23189.67  1000
     A^2  1745.332  1835.279  2204.023  1850.469  2554.856 21869.66  1000
 sqrt(A) 49945.064 50066.434 50506.344 50187.356 50883.403 70006.25  1000


R-devel_2015-03-09 compiled using Rtools 3.3 (GCC 4.9.2, SJLJ, EOPTS =
-O3 -march=native -mfpmath=sse -msse2avx -mavx256-split-unaligned-load
-mavx256-split-unaligned-store -mvzeroupper -std=gnu++11 -pipe)
OpenBLAS 2.13 - Multi-threaded (max 4 threads) - compiled under GCC
4.9.1 (MinGW-64)

Unit: microseconds
    expr       min        lq      mean    median        uq      max neval
   A + 2   925.980  1777.350  2167.326  1791.795  2384.641 21660.28  1000
   A - 2  1673.256  1777.648  2188.756  1806.687  2670.715 21724.01  1000
   A * 2  1680.999  1786.434  2221.432  1835.130  2766.916 22254.16  1000
     A/2  1992.836  2085.165  2450.455  2108.694  2865.203 22803.08  1000
   A + B  1977.646  2089.632  2559.912  2121.204  3031.397 22884.99  1000
   A - B  1979.135  2081.591  2516.943  2101.398  3003.548 22377.77  1000
   A * B  1971.689  2073.699  2510.912  2092.462  2921.345 22308.37  1000
     A/B  3247.031  3345.169  3633.351  3361.402  3941.590 23231.97  1000
     A^2  1668.788  1771.244  2169.422  1788.220  2745.026 21786.86  1000
 sqrt(A) 48662.871 48805.537 49357.270 49003.003 49715.283 69269.10  1000


=== BLAS dependent code (statistics gathered over a few months ===

#Test code
library(microbenchmark)
library(Matrix)
A <- as.matrix(read.csv(file="F:/R/A.csv", colClasses='numeric'))
B <- as.matrix(read.csv(file="F:/R/B.csv", colClasses='numeric'))
colnames(A) <- colnames(B) <- NULL

Z <- microbenchmark(
    sort(A),
    t(A) %*% B,
    crossprod(A, B),
    solve(A),
    solve(A, diag(A)),
    chol(A),
    chol(B, pivot = TRUE),
    qr(A, LAPACK=TRUE),
    svd(A),
    eigen(A, symmetric = TRUE),
    eigen(A, symmetric = FALSE),
    eigen(B, symmetric = FALSE),
    lu(A),
    fft(A),
    times=100L, unit='ms', control = list(order = 'block'))


REFERENCE 3.1.1 compiled using Rtools 3.1 (GCC 4.6.3, default EOPTS flags)
reference BLAS

Unit: milliseconds
                        expr         min          lq        mean
median          uq         max neval
                     sort(A)   89.364120   90.760662   95.096270
91.561537   92.573725  154.081306   100
                  t(A) %*% B  463.145756  470.406496  487.680120
474.872066  490.043866  642.640917   100
             crossprod(A, B)  727.114903  729.128111  730.031458
729.785877  731.120320  733.078130   100
                    solve(A)  600.629979  604.814394  630.598703
608.606561  658.326032  662.879314   100
           solve(A, diag(A))  145.738089  146.774104  147.629655
147.959780  148.371535  148.883512   100
                     chol(A)  115.873110  116.019644  117.347118
116.212938  118.026150  172.853468   100
       chol(B, pivot = TRUE)    2.415134    2.548564    3.227905
2.559286    4.568473    4.689393   100
        qr(A, LAPACK = TRUE)  414.455301  416.033671  418.583569
416.972741  417.814271  473.541941   100
                      svd(A) 1952.765952 1957.070246 1974.547371
1959.374735 2010.263499 2017.405106   100
  eigen(A, symmetric = TRUE)  917.120317  920.482414  923.423802
921.784990  924.577926  980.692929   100
 eigen(A, symmetric = FALSE) 2981.049436 2985.640691 3007.526012
2991.149276 3014.926832 3130.924137   100
 eigen(B, symmetric = FALSE) 3964.874086 3974.978839 3999.080880
3991.973829 4019.799690 4078.083071   100
                       lu(A)  137.437464  138.229850  141.696849
138.906528  142.217546  198.202991   100
                      fft(A)  109.981065  110.321042  111.753592
110.640916  111.268152  116.670410   100


3.1.2 compiled using Rtools 3.2 (GCC 4.6.3, EOPTS = -march=native -O3
-std=gnu++0x -msse2avx -mavx256-split-unaligned-load
-mavx256-split-unaligned-store -mvzeroupper --param
l1-cache-line-size=64 --param l1-cache-size=64 --param
l2-cache-size=256)
OpenBLAS 2.13 - Multi-threaded (max 4 threads) - compiled under GCC
4.9.1 (MinGW-64)

Unit: milliseconds
                        expr         min          lq        mean
median          uq         max neval
                     sort(A)   88.771066   89.748265   94.542642
90.596947   91.482709  149.171214   100
                  t(A) %*% B   27.507195   33.359067   40.378088
37.689446   41.512909   96.868916   100
             crossprod(A, B)   17.783759   22.327538   26.787467
27.059399   31.918288   36.209055   100
                    solve(A)   45.964657   54.856090   80.761447
60.499775  109.150759  118.817308   100
           solve(A, diag(A))   24.704266   26.370058   26.805694
26.936840   27.400868   29.522052   100
                     chol(A)    6.762058    7.088337    8.725137
8.145653    8.973040   65.570275   100
       chol(B, pivot = TRUE)    2.558110    2.702412    3.481314
2.831076    4.789643    5.346446   100
        qr(A, LAPACK = TRUE)   78.757538   81.620631   85.132413
82.940043   85.099350  141.434937   100
                      svd(A)  361.539846  366.637747  386.533779
370.769323  421.736275  445.087770   100
  eigen(A, symmetric = TRUE)  174.249560  180.402841  186.649060
182.628715  188.931063  241.414148   100
 eigen(A, symmetric = FALSE)  734.881721  744.303748  772.203936
751.104077  795.883051  915.351575   100
 eigen(B, symmetric = FALSE) 2522.750166 2551.112148 2596.798329
2581.940655 2633.440287 2861.722717   100
                       lu(A)   20.277535   21.227185   25.068971
23.319926   25.130468   84.837552   100
                      fft(A)  109.757747  110.347313  112.123488
110.725415  114.057152  120.250492   100


R-devel_2015-03-09 compiled using Rtools 3.3 (GCC 4.9.2, SJLJ, EOPTS =
-O3 -march=native -mfpmath=sse -msse2avx -mavx256-split-unaligned-load
-mavx256-split-unaligned-store -mvzeroupper -std=gnu++11 -pipe)
OpenBLAS 2.13 - Multi-threaded (max 4 threads) - compiled under GCC
4.9.1 (MinGW-64)

Unit: milliseconds
                        expr         min          lq        mean
median          uq        max neval
                     sort(A)   88.025153   88.255828   92.701967
89.571826   90.320888  146.40380   100
                  t(A) %*% B   26.471552   30.866301   35.293662
34.069253   38.490212   85.57007   100
             crossprod(A, B)   17.606699   17.898879   23.999433
22.228699   28.620007   37.06744   100
                    solve(A)   43.410199   48.448279   54.914690
51.338798   55.865639  116.81746   100
           solve(A, diag(A))   24.655633   25.414227   27.692980
27.301179   28.757458   38.95692   100
                     chol(A)    6.620942    6.891379    8.010618
7.474695    8.233586   12.62357   100
       chol(B, pivot = TRUE)    2.456867    2.541751    3.737836
2.575556    2.722390   61.46246   100
        qr(A, LAPACK = TRUE)   78.153905   80.980389   83.663278
82.458112   84.998671  101.89696   100
                      svd(A)  353.204099  365.191932  390.446252
377.001957  417.792818  475.73975   100
  eigen(A, symmetric = TRUE)  173.627391  177.985954  186.068097
182.131711  187.866286  251.19902   100
 eigen(A, symmetric = FALSE)  771.643075  788.242038  813.902106
801.689427  839.380539  921.24119   100
 eigen(B, symmetric = FALSE) 2591.501370 2644.449833 2691.339277
2678.241053 2722.924657 2935.76884   100
                       lu(A)   19.969747   20.959164   24.298874
22.426017   24.017664   81.95253   100
                      fft(A)  106.862816  107.191480  108.985064
107.466682  110.465762  115.73511   100


 R-devel_2015-03-08 compiled using
x86_64-4.9.2-release-win32-seh-rt_v3-rev1 (EOPTS = -O3 -march=native
-mfpmath=sse -msse2avx -mavx256-split-unaligned-load
-mavx256-split-unaligned-store -mvzeroupper -std=gnu++11 -pipe)
 OpenBLAS 2.13 - Multi-threaded (max 4 threads) - compiled under GCC
4.9.1 (MinGW-64)

 Unit: milliseconds
                        expr         min          lq        mean
median          uq        max neval
                     sort(A)   88.372432   88.811892   93.321491
90.093638   90.754540  150.02760   100
                  t(A) %*% B   26.583837   30.443074   34.765044
33.903505   37.455374   82.54761   100
             crossprod(A, B)   17.715707   22.088566   26.875521
27.185023   31.154311   36.72850   100
                    solve(A)   44.112203   49.217298   55.707862
52.651668   57.331152  116.44069   100
           solve(A, diag(A))   24.891819   25.468731   27.590369
27.302520   29.217172   37.90168   100
                     chol(A)    6.658469    6.872168    7.893779
7.058167    8.968203   13.32230   100
       chol(B, pivot = TRUE)    2.451208    2.529540    3.742339
2.578981    2.646143   62.62224   100
        qr(A, LAPACK = TRUE)   78.839230   80.413602   82.989497
81.778148   84.447373   98.13199   100
                      svd(A)  352.931278  362.746235  387.952468
374.631166  415.481743  500.52405   100
  eigen(A, symmetric = TRUE)  172.696946  178.109557  187.816872
181.375053  190.414291  256.44276   100
 eigen(A, symmetric = FALSE)  778.904964  793.941318  820.598107
812.244809  841.944627  919.02527   100
 eigen(B, symmetric = FALSE) 2494.645617 2514.200623 2562.484197
2561.112354 2586.092481 2806.00525   100
                       lu(A)   19.762154   20.663114   24.555941
22.403382   24.369411   80.98218   100
                      fft(A)  106.374956  107.120148  108.625520
107.433176  108.786850  116.43563   100


From avraham.adler at gmail.com  Tue Mar 10 08:09:10 2015
From: avraham.adler at gmail.com (Avraham Adler)
Date: Tue, 10 Mar 2015 03:09:10 -0400
Subject: [Rd] ICU_531 and sjlj vs.seh
In-Reply-To: <CAL6gwnJyKX_TRd__dNoFVtQ=Vg-MyCN6xHR9LLHBfKX+N=LhQQ@mail.gmail.com>
References: <CAL6gwnJyKX_TRd__dNoFVtQ=Vg-MyCN6xHR9LLHBfKX+N=LhQQ@mail.gmail.com>
Message-ID: <CAL6gwnJ4jiscBR-Y5bCCfPd0yhPzrjwaq+B0t_dQjsjwY2_0PQ@mail.gmail.com>

Just to close the loop (and prevent this xkcd cartoon from becoming
even more true <https://xkcd.com/979/>), the answer to this question
was addressed in this post
<https://stat.ethz.ch/pipermail/r-devel/2015-March/070784.html> and
subsequent.

Avi


From murdoch.duncan at gmail.com  Tue Mar 10 12:07:43 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 10 Mar 2015 07:07:43 -0400
Subject: [Rd] Notes on building a gcc toolchain for Rtools (but not
	multilib)
In-Reply-To: <CAPuMoLY7oBsRbk_L82u4QEHxL+KRY07yNMotdVesF8+KQ9TdnA@mail.gmail.com>
References: <CAPuMoLZAWUvcQ-ubBwuqzLONom3ZLGJzzUPbmzm2E_2HzCHWYg@mail.gmail.com>	<54FD7B0E.8040500@gmail.com>	<CAPuMoLba=3k_tX3Vg8hn8=30LzhTRTpVexkk0WZTn7vCOCp6Mw@mail.gmail.com>	<54FDDAF2.9040005@gmail.com>
	<CAPuMoLY7oBsRbk_L82u4QEHxL+KRY07yNMotdVesF8+KQ9TdnA@mail.gmail.com>
Message-ID: <54FED07F.7060308@gmail.com>

On 09/03/2015 11:02 PM, Hsiu-Khuern Tang wrote:
> Hi Duncan,
> 
> On Mon, Mar 9, 2015 at 10:40 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> On 09/03/2015 11:07 AM, Hsiu-Khuern Tang wrote:
>>>
>>> On Mon, Mar 9, 2015 at 3:50 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
>>> wrote:
>>>> On 08/03/2015 10:02 PM, Hsiu-Khuern Tang wrote:
>>>>> Hi,
>>>>>
>>>>> [This is a follow-up to the "New version of Rtools for Windows" thread
>>>>> in January, but I just subscribed and don't know how to reply to an
>>>>> old thread -- my apologies.]
>>>>
>>>> I am planning to put a new Rtools online today that uses a different
>>>> build of gcc 4.9.2.  I will be concentrating on getting it to work with
>>>> all the external libraries before the 3.2.0 release next month.  I'm not
>>>> planning to try to get it to work with R-patched, and I expect it won't:
>>>>  I needed to make a number of patches to R-devel for compatibility.
>>>
>>> I also worked off R-devel (I said wrongly that it was R-patched in my
>>> original post) and benefited from your compatibility changes.
>>>
>>> I look forward to the new Rtools and will test it by compiling some
>>> packages.
>>
>>
>> It's now on the main site at CRAN, and should propagate to the mirrors
>> reasonably quickly.  I'm hoping that tomorrow's R-devel build will use it,
>> but there may be some last minute problems.
> 
> Is the new Rtools at
> http://cran.r-project.org/bin/windows/Rtools/Rtools33.exe?  I'm still
> getting "Error 404 object not found".

There were some permission problems on the file for a while yesterday;
perhaps the index page got propagated but the actual file didn't.

Duncan Murdoch


From kmezhoud at gmail.com  Tue Mar 10 16:31:52 2015
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Tue, 10 Mar 2015 15:31:52 +0000
Subject: [Rd] R_HOME default setting
Message-ID: <CALJKBv8OS75t1-6T50p1hkY_PXTbU2Xh9UEeVXB6_ULrx1ZGKg@mail.gmail.com>

Dear All,
I would like to reset default R_HOME PATH for R.3.1.3.
I installed R-devel in /usr/local/R-devel but I can't install many packages
as tcltk.
I uninstalled R-devel and I would reuse R.3.1.3 but the PATH is remaining
to  /usr/local/R-devel.

I touch ~.Renviron file with

R_HOME=/usr/lib/R/bin/
RSTUDIO_R_HOME=/usr/lib/R/bin/

R_LIBS=~/R/x86_64-pc-linux-gnu-library/3.1

R_LIBS_USER=${R_LIBS_USER-'~/R/x86_64-pc-linux-gnu-library/3.1'}

Without success.
Any idea?
which file has the R_HOME setting?
Thanks
Karim

	[[alternative HTML version deleted]]


From dtenenba at fredhutch.org  Tue Mar 10 17:54:43 2015
From: dtenenba at fredhutch.org (Dan Tenenbaum)
Date: Tue, 10 Mar 2015 09:54:43 -0700 (PDT)
Subject: [Rd] Notes on building a gcc toolchain for Rtools (but
	not	multilib)
In-Reply-To: <54FDDAF2.9040005@gmail.com>
Message-ID: <1341091521.484978.1426006483818.JavaMail.root@fredhutch.org>



----- Original Message -----
> From: "Duncan Murdoch" <murdoch.duncan at gmail.com>
> To: "Hsiu-Khuern Tang" <tangoh at gmail.com>, r-devel at r-project.org
> Sent: Monday, March 9, 2015 10:40:02 AM
> Subject: Re: [Rd] Notes on building a gcc toolchain for Rtools (but not	multilib)
> 
> On 09/03/2015 11:07 AM, Hsiu-Khuern Tang wrote:
> > On Mon, Mar 9, 2015 at 3:50 AM, Duncan Murdoch
> > <murdoch.duncan at gmail.com> wrote:
> > > On 08/03/2015 10:02 PM, Hsiu-Khuern Tang wrote:
> > >> Hi,
> > >>
> > >> [This is a follow-up to the "New version of Rtools for Windows"
> > >> thread
> > >> in January, but I just subscribed and don't know how to reply to
> > >> an
> > >> old thread -- my apologies.]
> > >
> > > I am planning to put a new Rtools online today that uses a
> > > different
> > > build of gcc 4.9.2.  I will be concentrating on getting it to
> > > work with
> > > all the external libraries before the 3.2.0 release next month.
> > >  I'm not
> > > planning to try to get it to work with R-patched, and I expect it
> > > won't:
> > >  I needed to make a number of patches to R-devel for
> > >  compatibility.
> >
> > I also worked off R-devel (I said wrongly that it was R-patched in
> > my
> > original post) and benefited from your compatibility changes.
> >
> > I look forward to the new Rtools and will test it by compiling some
> > packages.
> 
> It's now on the main site at CRAN, and should propagate to the
> mirrors
> reasonably quickly.  I'm hoping that tomorrow's R-devel build will
> use
> it, but there may be some last minute problems.
> 

Thanks to you and everyone who worked on this. Is there a way to tell which toolchain built a given R-devel binary?
If not, can you let us know when there is one on CRAN that was built with the new Rtools?

Thanks,
Dan


> Duncan Murdoch
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From maechler at lynne.stat.math.ethz.ch  Tue Mar 10 18:31:52 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Tue, 10 Mar 2015 18:31:52 +0100
Subject: [Rd] Seed in 'parallel' vignette
In-Reply-To: <CAM3-KjZeYc6JMXDv8QdcF2efAPwaYMf=GLPNzV1jp_R93gGq6A@mail.gmail.com>
References: <CAM3-Kjah4y2Mr7snden5XJsx6nUFEpMO30Q_sAyBh9fD0bp-Vg@mail.gmail.com>
	<CAM3-KjZeYc6JMXDv8QdcF2efAPwaYMf=GLPNzV1jp_R93gGq6A@mail.gmail.com>
Message-ID: <21759.10888.736694.631261@stat.math.ethz.ch>

>>>>> Marius Hofert <marius.hofert at uwaterloo.ca>
>>>>>     on Sun, 8 Mar 2015 11:19:45 -0400 writes:

    > On Tue, Feb 3, 2015 at 10:39 AM, Marius Hofert
    > <marius.hofert at uwaterloo.ca> wrote:
    >> Hi,
    >> 
    >> This is most likely only a minor technicality, but I saw the
    >> following: On page 6 of the 'parallel' vignette
    >> (http://stat.ethz.ch/R-manual/R-devel/library/parallel/doc/parallel.pdf),
    >> the random-number generator "L'Ecuyer-CMRG" is said to have seed
    >> "(x_n, x_{n-1}, x_{n-2}, y_n, y_{n-1}, y_{n-2})". However, in L'Ecuyer
    >> et al. (2002), the seed is given with 'increasing' indices, so should
    >> rather be "(x_{n-2}, x_{n-1}, x_n, y_{n-2}, y_{n-1}, y_n)" (or, even
    >> more intuitively, "(x_{n-3}, x_{n-2}, x_{n-1}, y_{n-3}, y_{n-2},
    >> y_{n-1})"). The question is how it's done in R (?):

    > ... in the meanwhile, I found out that this is indeed a typo in the
    > vignette. I suggest to change it to "(x_{n-3}, x_{n-2}, x_{n-1},
    > y_{n-3}, y_{n-2}, y_{n-1})" on page 6 in the version of October 31, 2014.

Thank you, Marius.
I've committed this change now.

With regards: Martin

    >> If as given in the
    >> vignette, one should maybe point this out as other (languages)
    >> following L'Ecuyer et al. (2002) might obtain different random numbers
    >> then. And if it's implemented as in L'Ecuyer, then one probably wants
    >> to adjust the vignette to reflect this.
    >> 
    >> Other minor suggestions to improve the vignette (if that's what's also
    >> done in R; I couldn't easily figure that out from ./src/main/RNG.c):
    >> 1) when defining u_n, I would write u_n = z_n / (2^32-208) [as it is
    >> immediately clear then that one divides by the modulus of the first
    >> linear congruential generator + 1]
    >> 2) The case z_n=0 is not provided (for a reason?). If z_n=0, L'Ecuyer
    >> suggests to set u_n to "(2^32-209)/(2^32-208)".
    >> 
    >> Cheers,
    >> Marius
    >> 
    >> 
    >> 
    >> 
    >> --
    >> Marius Hofert, Dr. rer. nat.
    >> Assistant Professor
    >> Department of Statistics and Actuarial Science
    >> Faculty of Mathematics
    >> University of Waterloo
    >> 200 University Avenue West, Waterloo, ON, N2L 3G1
    >> +1-519-888-4567, ext. 31394 (office M3 4207)
    >> http://math.uwaterloo.ca/~mhofert



    > -- 
    > Marius Hofert, Dr. rer. nat.
    > Assistant Professor
    > Department of Statistics and Actuarial Science
    > Faculty of Mathematics
    > University of Waterloo
    > 200 University Avenue West, Waterloo, ON, N2L 3G1
    > +1-519-888-4567, ext. 31394 (office M3 4207)
    > http://math.uwaterloo.ca/~mhofert

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From tangoh at gmail.com  Tue Mar 10 19:26:17 2015
From: tangoh at gmail.com (Hsiu-Khuern Tang)
Date: Tue, 10 Mar 2015 11:26:17 -0700
Subject: [Rd] Notes on building a gcc toolchain for Rtools (but not
	multilib)
In-Reply-To: <54FED07F.7060308@gmail.com>
References: <CAPuMoLZAWUvcQ-ubBwuqzLONom3ZLGJzzUPbmzm2E_2HzCHWYg@mail.gmail.com>
	<54FD7B0E.8040500@gmail.com>
	<CAPuMoLba=3k_tX3Vg8hn8=30LzhTRTpVexkk0WZTn7vCOCp6Mw@mail.gmail.com>
	<54FDDAF2.9040005@gmail.com>
	<CAPuMoLY7oBsRbk_L82u4QEHxL+KRY07yNMotdVesF8+KQ9TdnA@mail.gmail.com>
	<54FED07F.7060308@gmail.com>
Message-ID: <CAPuMoLaBOohEWR5pn9cU8dB=mrvHsmEPx5pz0Sr0CJgJhbM5wQ@mail.gmail.com>

On Tue, Mar 10, 2015 at 4:07 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 09/03/2015 11:02 PM, Hsiu-Khuern Tang wrote:
>> Hi Duncan,
>>
>> On Mon, Mar 9, 2015 at 10:40 AM, Duncan Murdoch
>> <murdoch.duncan at gmail.com> wrote:
>>> On 09/03/2015 11:07 AM, Hsiu-Khuern Tang wrote:
>>>>
>>>> On Mon, Mar 9, 2015 at 3:50 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
>>>> wrote:
>>>>> On 08/03/2015 10:02 PM, Hsiu-Khuern Tang wrote:
>>>>>> Hi,
>>>>>>
>>>>>> [This is a follow-up to the "New version of Rtools for Windows" thread
>>>>>> in January, but I just subscribed and don't know how to reply to an
>>>>>> old thread -- my apologies.]
>>>>>
>>>>> I am planning to put a new Rtools online today that uses a different
>>>>> build of gcc 4.9.2.  I will be concentrating on getting it to work with
>>>>> all the external libraries before the 3.2.0 release next month.  I'm not
>>>>> planning to try to get it to work with R-patched, and I expect it won't:
>>>>>  I needed to make a number of patches to R-devel for compatibility.
>>>>
>>>> I also worked off R-devel (I said wrongly that it was R-patched in my
>>>> original post) and benefited from your compatibility changes.
>>>>
>>>> I look forward to the new Rtools and will test it by compiling some
>>>> packages.
>>>
>>>
>>> It's now on the main site at CRAN, and should propagate to the mirrors
>>> reasonably quickly.  I'm hoping that tomorrow's R-devel build will use it,
>>> but there may be some last minute problems.
>>
>> Is the new Rtools at
>> http://cran.r-project.org/bin/windows/Rtools/Rtools33.exe?  I'm still
>> getting "Error 404 object not found".
>
> There were some permission problems on the file for a while yesterday;
> perhaps the index page got propagated but the actual file didn't.
>
> Duncan Murdoch
>

Got it now, thanks!  Are you planning to publish the build scripts for
the new Rtools as well?

I did the following limited test on the new Rtools:

R CMD INSTALL --no-multiarch Rcpp_0.11.5.tar.gz

I did this under various settings:

- the default settings
- with -std=c++11 added to CXXFLAGS in my .R\Makevars file.

This was done under the newly released R-3.1.3, using the 64-bit R binary.

Here are my findings:

- With the default settings, the command succeeded

- With -std=c++11, there were two problems:
  + api.cpp failed to compile because it could not find execinfo.h
    * I worked around this by using CXXFLAGS=-DWIN32 -std=c++11
    * CXXFLAGS=-std=gnu++11 also works around this
    * Maybe Rcpp needs to guard against this?
  + the package could not be loaded because some of the object files
contain symbols named .refptr.* and .weak.*, which should be excluded
from the exports list
    * To work around this, put this line in .R\Makevars: NM_FILTER = |
sed -e '/\.refptr\./d; /\.weak\./d'


- Hsiu-Khuern


From murdoch.duncan at gmail.com  Tue Mar 10 19:37:12 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 10 Mar 2015 14:37:12 -0400
Subject: [Rd] Notes on building a gcc toolchain for Rtools (but not
	multilib)
In-Reply-To: <1341091521.484978.1426006483818.JavaMail.root@fredhutch.org>
References: <1341091521.484978.1426006483818.JavaMail.root@fredhutch.org>
Message-ID: <54FF39D8.20102@gmail.com>

On 10/03/2015 12:54 PM, Dan Tenenbaum wrote:
>
> ----- Original Message -----
> > From: "Duncan Murdoch" <murdoch.duncan at gmail.com>
> > To: "Hsiu-Khuern Tang" <tangoh at gmail.com>, r-devel at r-project.org
> > Sent: Monday, March 9, 2015 10:40:02 AM
> > Subject: Re: [Rd] Notes on building a gcc toolchain for Rtools (but not	multilib)
> >
> > On 09/03/2015 11:07 AM, Hsiu-Khuern Tang wrote:
> > > On Mon, Mar 9, 2015 at 3:50 AM, Duncan Murdoch
> > > <murdoch.duncan at gmail.com> wrote:
> > > > On 08/03/2015 10:02 PM, Hsiu-Khuern Tang wrote:
> > > >> Hi,
> > > >>
> > > >> [This is a follow-up to the "New version of Rtools for Windows"
> > > >> thread
> > > >> in January, but I just subscribed and don't know how to reply to
> > > >> an
> > > >> old thread -- my apologies.]
> > > >
> > > > I am planning to put a new Rtools online today that uses a
> > > > different
> > > > build of gcc 4.9.2.  I will be concentrating on getting it to
> > > > work with
> > > > all the external libraries before the 3.2.0 release next month.
> > > >  I'm not
> > > > planning to try to get it to work with R-patched, and I expect it
> > > > won't:
> > > >  I needed to make a number of patches to R-devel for
> > > >  compatibility.
> > >
> > > I also worked off R-devel (I said wrongly that it was R-patched in
> > > my
> > > original post) and benefited from your compatibility changes.
> > >
> > > I look forward to the new Rtools and will test it by compiling some
> > > packages.
> >
> > It's now on the main site at CRAN, and should propagate to the
> > mirrors
> > reasonably quickly.  I'm hoping that tomorrow's R-devel build will
> > use
> > it, but there may be some last minute problems.
> >
>
> Thanks to you and everyone who worked on this. Is there a way to tell which toolchain built a given R-devel binary?
> If not, can you let us know when there is one on CRAN that was built with the new Rtools?

If you look in etc/*/Makeconf, you'll see something like this:

BINPREF ?= $(RTOOLS)gcc492_64/bin/

hopefully from tomorrow onwards.  If today's build was with the new 
toolchain, you should see a hardcoded path to where I have Rtools 
installed on the build machine, which isn't so helpful.  The previous 
toolchain left BINPREF blank.

If you want to use your own toolchain, just edit those files.  If you 
want to install the standard Rtools somewhere else, set an environment 
variable like

RTOOLS = C:/Rtools/

(where the terminal / is required.)


From murdoch.duncan at gmail.com  Tue Mar 10 19:44:29 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 10 Mar 2015 14:44:29 -0400
Subject: [Rd] Notes on building a gcc toolchain for Rtools (but not
	multilib)
In-Reply-To: <CAPuMoLaBOohEWR5pn9cU8dB=mrvHsmEPx5pz0Sr0CJgJhbM5wQ@mail.gmail.com>
References: <CAPuMoLZAWUvcQ-ubBwuqzLONom3ZLGJzzUPbmzm2E_2HzCHWYg@mail.gmail.com>	<54FD7B0E.8040500@gmail.com>	<CAPuMoLba=3k_tX3Vg8hn8=30LzhTRTpVexkk0WZTn7vCOCp6Mw@mail.gmail.com>	<54FDDAF2.9040005@gmail.com>	<CAPuMoLY7oBsRbk_L82u4QEHxL+KRY07yNMotdVesF8+KQ9TdnA@mail.gmail.com>	<54FED07F.7060308@gmail.com>
	<CAPuMoLaBOohEWR5pn9cU8dB=mrvHsmEPx5pz0Sr0CJgJhbM5wQ@mail.gmail.com>
Message-ID: <54FF3B8D.40400@gmail.com>

On 10/03/2015 2:26 PM, Hsiu-Khuern Tang wrote:
> On Tue, Mar 10, 2015 at 4:07 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
> > On 09/03/2015 11:02 PM, Hsiu-Khuern Tang wrote:
> >> Hi Duncan,
> >>
> >> On Mon, Mar 9, 2015 at 10:40 AM, Duncan Murdoch
> >> <murdoch.duncan at gmail.com> wrote:
> >>> On 09/03/2015 11:07 AM, Hsiu-Khuern Tang wrote:
> >>>>
> >>>> On Mon, Mar 9, 2015 at 3:50 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
> >>>> wrote:
> >>>>> On 08/03/2015 10:02 PM, Hsiu-Khuern Tang wrote:
> >>>>>> Hi,
> >>>>>>
> >>>>>> [This is a follow-up to the "New version of Rtools for Windows" thread
> >>>>>> in January, but I just subscribed and don't know how to reply to an
> >>>>>> old thread -- my apologies.]
> >>>>>
> >>>>> I am planning to put a new Rtools online today that uses a different
> >>>>> build of gcc 4.9.2.  I will be concentrating on getting it to work with
> >>>>> all the external libraries before the 3.2.0 release next month.  I'm not
> >>>>> planning to try to get it to work with R-patched, and I expect it won't:
> >>>>>  I needed to make a number of patches to R-devel for compatibility.
> >>>>
> >>>> I also worked off R-devel (I said wrongly that it was R-patched in my
> >>>> original post) and benefited from your compatibility changes.
> >>>>
> >>>> I look forward to the new Rtools and will test it by compiling some
> >>>> packages.
> >>>
> >>>
> >>> It's now on the main site at CRAN, and should propagate to the mirrors
> >>> reasonably quickly.  I'm hoping that tomorrow's R-devel build will use it,
> >>> but there may be some last minute problems.
> >>
> >> Is the new Rtools at
> >> http://cran.r-project.org/bin/windows/Rtools/Rtools33.exe?  I'm still
> >> getting "Error 404 object not found".
> >
> > There were some permission problems on the file for a while yesterday;
> > perhaps the index page got propagated but the actual file didn't.
> >
> > Duncan Murdoch
> >
>
> Got it now, thanks!  Are you planning to publish the build scripts for
> the new Rtools as well?

Yes, they are on pre-CRAN now (that's where I put things, CRAN picks 
them up from there, the mirrors pick them up from CRAN).  Not sure when 
they'll propagate, but the URL is

bin/windows/Rtools/scripts

I'm going to be uploading a new Rtools33.exe in a few minutes.  It puts 
back gdb, which had been included in the 4.6.3 build but not this one; 
it is now in Rtools/bin as gdb.exe for 32 bits and gdb64.exe for 64 
bits.  It also cleans up the PATH editing; the new scheme doesn't need 
gcc to be on the PATH.  And the index page points to the scripts.

Duncan Murdoch
>
> I did the following limited test on the new Rtools:
>
> R CMD INSTALL --no-multiarch Rcpp_0.11.5.tar.gz
>
> I did this under various settings:
>
> - the default settings
> - with -std=c++11 added to CXXFLAGS in my .R\Makevars file.
>
> This was done under the newly released R-3.1.3, using the 64-bit R binary.
>
> Here are my findings:
>
> - With the default settings, the command succeeded
>
> - With -std=c++11, there were two problems:
>    + api.cpp failed to compile because it could not find execinfo.h
>      * I worked around this by using CXXFLAGS=-DWIN32 -std=c++11
>      * CXXFLAGS=-std=gnu++11 also works around this
>      * Maybe Rcpp needs to guard against this?
>    + the package could not be loaded because some of the object files
> contain symbols named .refptr.* and .weak.*, which should be excluded
> from the exports list
>      * To work around this, put this line in .R\Makevars: NM_FILTER = |
> sed -e '/\.refptr\./d; /\.weak\./d'
>
>
> - Hsiu-Khuern
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From dtenenba at fredhutch.org  Tue Mar 10 19:56:29 2015
From: dtenenba at fredhutch.org (Dan Tenenbaum)
Date: Tue, 10 Mar 2015 11:56:29 -0700 (PDT)
Subject: [Rd] Notes on building a gcc toolchain for Rtools (but not
 multilib)
In-Reply-To: <54FF39D8.20102@gmail.com>
Message-ID: <1110879639.489054.1426013789755.JavaMail.root@fredhutch.org>



----- Original Message -----
> From: "Duncan Murdoch" <murdoch.duncan at gmail.com>
> To: "Dan Tenenbaum" <dtenenba at fredhutch.org>
> Cc: "Hsiu-Khuern Tang" <tangoh at gmail.com>, r-devel at r-project.org
> Sent: Tuesday, March 10, 2015 11:37:12 AM
> Subject: Re: [Rd] Notes on building a gcc toolchain for Rtools (but not multilib)
> 
> On 10/03/2015 12:54 PM, Dan Tenenbaum wrote:
> >
> > ----- Original Message -----
> > > From: "Duncan Murdoch" <murdoch.duncan at gmail.com>
> > > To: "Hsiu-Khuern Tang" <tangoh at gmail.com>, r-devel at r-project.org
> > > Sent: Monday, March 9, 2015 10:40:02 AM
> > > Subject: Re: [Rd] Notes on building a gcc toolchain for Rtools
> > > (but not	multilib)
> > >
> > > On 09/03/2015 11:07 AM, Hsiu-Khuern Tang wrote:
> > > > On Mon, Mar 9, 2015 at 3:50 AM, Duncan Murdoch
> > > > <murdoch.duncan at gmail.com> wrote:
> > > > > On 08/03/2015 10:02 PM, Hsiu-Khuern Tang wrote:
> > > > >> Hi,
> > > > >>
> > > > >> [This is a follow-up to the "New version of Rtools for
> > > > >> Windows"
> > > > >> thread
> > > > >> in January, but I just subscribed and don't know how to
> > > > >> reply to
> > > > >> an
> > > > >> old thread -- my apologies.]
> > > > >
> > > > > I am planning to put a new Rtools online today that uses a
> > > > > different
> > > > > build of gcc 4.9.2.  I will be concentrating on getting it to
> > > > > work with
> > > > > all the external libraries before the 3.2.0 release next
> > > > > month.
> > > > >  I'm not
> > > > > planning to try to get it to work with R-patched, and I
> > > > > expect it
> > > > > won't:
> > > > >  I needed to make a number of patches to R-devel for
> > > > >  compatibility.
> > > >
> > > > I also worked off R-devel (I said wrongly that it was R-patched
> > > > in
> > > > my
> > > > original post) and benefited from your compatibility changes.
> > > >
> > > > I look forward to the new Rtools and will test it by compiling
> > > > some
> > > > packages.
> > >
> > > It's now on the main site at CRAN, and should propagate to the
> > > mirrors
> > > reasonably quickly.  I'm hoping that tomorrow's R-devel build
> > > will
> > > use
> > > it, but there may be some last minute problems.
> > >
> >
> > Thanks to you and everyone who worked on this. Is there a way to
> > tell which toolchain built a given R-devel binary?
> > If not, can you let us know when there is one on CRAN that was
> > built with the new Rtools?
> 
> If you look in etc/*/Makeconf, you'll see something like this:
> 
> BINPREF ?= $(RTOOLS)gcc492_64/bin/
> 
> hopefully from tomorrow onwards.  If today's build was with the new
> toolchain, you should see a hardcoded path to where I have Rtools
> installed on the build machine, which isn't so helpful.  The previous
> toolchain left BINPREF blank.
> 
> If you want to use your own toolchain, just edit those files.  If you
> want to install the standard Rtools somewhere else, set an
> environment
> variable like
> 
> RTOOLS = C:/Rtools/
> 
> (where the terminal / is required.)
> 

Thanks, that's very helpful. I also notice with the latest R-devel binary (67969, which is built with the new Rtools according to what you say above) that I need to do setInternet2(TRUE) before I can download from any URLs; I see some mention of that earlier in this thread, is this intended? If so is there a way to make this the default?

Thanks,
Dan


> 
>


From murdoch.duncan at gmail.com  Tue Mar 10 20:17:00 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 10 Mar 2015 15:17:00 -0400
Subject: [Rd] Notes on building a gcc toolchain for Rtools (but not
	multilib)
In-Reply-To: <1110879639.489054.1426013789755.JavaMail.root@fredhutch.org>
References: <1110879639.489054.1426013789755.JavaMail.root@fredhutch.org>
Message-ID: <54FF432C.8030200@gmail.com>

On 10/03/2015 2:56 PM, Dan Tenenbaum wrote:
> 
> 
> ----- Original Message -----
>> From: "Duncan Murdoch" <murdoch.duncan at gmail.com>
>> To: "Dan Tenenbaum" <dtenenba at fredhutch.org>
>> Cc: "Hsiu-Khuern Tang" <tangoh at gmail.com>, r-devel at r-project.org
>> Sent: Tuesday, March 10, 2015 11:37:12 AM
>> Subject: Re: [Rd] Notes on building a gcc toolchain for Rtools (but not multilib)
>>
>> On 10/03/2015 12:54 PM, Dan Tenenbaum wrote:
>>>
>>> ----- Original Message -----
>>>> From: "Duncan Murdoch" <murdoch.duncan at gmail.com>
>>>> To: "Hsiu-Khuern Tang" <tangoh at gmail.com>, r-devel at r-project.org
>>>> Sent: Monday, March 9, 2015 10:40:02 AM
>>>> Subject: Re: [Rd] Notes on building a gcc toolchain for Rtools
>>>> (but not	multilib)
>>>>
>>>> On 09/03/2015 11:07 AM, Hsiu-Khuern Tang wrote:
>>>>> On Mon, Mar 9, 2015 at 3:50 AM, Duncan Murdoch
>>>>> <murdoch.duncan at gmail.com> wrote:
>>>>>> On 08/03/2015 10:02 PM, Hsiu-Khuern Tang wrote:
>>>>>>> Hi,
>>>>>>>
>>>>>>> [This is a follow-up to the "New version of Rtools for
>>>>>>> Windows"
>>>>>>> thread
>>>>>>> in January, but I just subscribed and don't know how to
>>>>>>> reply to
>>>>>>> an
>>>>>>> old thread -- my apologies.]
>>>>>>
>>>>>> I am planning to put a new Rtools online today that uses a
>>>>>> different
>>>>>> build of gcc 4.9.2.  I will be concentrating on getting it to
>>>>>> work with
>>>>>> all the external libraries before the 3.2.0 release next
>>>>>> month.
>>>>>>  I'm not
>>>>>> planning to try to get it to work with R-patched, and I
>>>>>> expect it
>>>>>> won't:
>>>>>>  I needed to make a number of patches to R-devel for
>>>>>>  compatibility.
>>>>>
>>>>> I also worked off R-devel (I said wrongly that it was R-patched
>>>>> in
>>>>> my
>>>>> original post) and benefited from your compatibility changes.
>>>>>
>>>>> I look forward to the new Rtools and will test it by compiling
>>>>> some
>>>>> packages.
>>>>
>>>> It's now on the main site at CRAN, and should propagate to the
>>>> mirrors
>>>> reasonably quickly.  I'm hoping that tomorrow's R-devel build
>>>> will
>>>> use
>>>> it, but there may be some last minute problems.
>>>>
>>>
>>> Thanks to you and everyone who worked on this. Is there a way to
>>> tell which toolchain built a given R-devel binary?
>>> If not, can you let us know when there is one on CRAN that was
>>> built with the new Rtools?
>>
>> If you look in etc/*/Makeconf, you'll see something like this:
>>
>> BINPREF ?= $(RTOOLS)gcc492_64/bin/
>>
>> hopefully from tomorrow onwards.  If today's build was with the new
>> toolchain, you should see a hardcoded path to where I have Rtools
>> installed on the build machine, which isn't so helpful.  The previous
>> toolchain left BINPREF blank.
>>
>> If you want to use your own toolchain, just edit those files.  If you
>> want to install the standard Rtools somewhere else, set an
>> environment
>> variable like
>>
>> RTOOLS = C:/Rtools/
>>
>> (where the terminal / is required.)
>>
> 
> Thanks, that's very helpful. I also notice with the latest R-devel binary (67969, which is built with the new Rtools according to what you say above) that I need to do setInternet2(TRUE) before I can download from any URLs; I see some mention of that earlier in this thread, is this intended? If so is there a way to make this the default?

That's a bug.  I haven't tracked down what's going wrong with our
regular code.  If I can't find that and fix it soon, I'll make Internet2
the default.  For now, you can do it yourself using the instructions on
?setInternet2.

Duncan Murdoch


From jeroen.ooms at stat.ucla.edu  Tue Mar 10 21:32:22 2015
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Tue, 10 Mar 2015 13:32:22 -0700
Subject: [Rd] [R] How to access https page
In-Reply-To: <7EAE98EE-9247-4542-A956-ABD04BE29D30@savvyrookies.com>
References: <CAAu=cySbps8CcJCZ4P56CfXAZ-rgMWKmnG1RQVSVotM5Laa6aQ@mail.gmail.com>
	<CABFfbXvrOJKLc-ZQuWNCd_S=R5-fbHy7i4n_aDTS5__UUU+bGg@mail.gmail.com>
	<7EAE98EE-9247-4542-A956-ABD04BE29D30@savvyrookies.com>
Message-ID: <CABFfbXvWVVwe5gLjzynfZMeo-y0g8no4wXBvPErWfQURzMUJ+Q@mail.gmail.com>

On Tue, Mar 10, 2015 at 12:56 PM, Hui <hui.du at savvyrookies.com> wrote:

> Thanks. However I got http error 999.
>

There is an additional complication here that linkedin doesn't want you to
scrape the website and denies requests form non-browser clients. To get
around this you need to set the "User-Agent" header to something that looks
like a browser. Try this:

devtools::install_github("jeroenooms/curl")
h <- new_handle()
handle_setheaders(h, "User-Agent" = "Mozilla/5.0 (Windows NT 6.3; rv:36.0)
Gecko/20100101 Firefox/36.0")
txt <- readLines(curl("https://www.linkedin.com/in/huidu", handle = h))






>
> Hui
>
> Sent from my iPhone
>
> On Mar 10, 2015, at 12:07 PM, Jeroen Ooms <jeroen.ooms at stat.ucla.edu>
> wrote:
>
>
>
> On Mon, Mar 9, 2015 at 3:39 PM, Hui Du <hui.du at savvyrookies.com> wrote:
>
>> > readLines(url)
>> Error in file(con, "r") : cannot open the connection
>> In addition: Warning message:
>> In file(con, "r") : unsupported URL scheme
>>
>
> Try:
>
> library(curl)
> readLines(curl(url))
>
>
>

	[[alternative HTML version deleted]]


From ucfagls at gmail.com  Tue Mar 10 22:07:46 2015
From: ucfagls at gmail.com (Gavin Simpson)
Date: Tue, 10 Mar 2015 15:07:46 -0600
Subject: [Rd] R_HOME default setting
In-Reply-To: <CALJKBv8OS75t1-6T50p1hkY_PXTbU2Xh9UEeVXB6_ULrx1ZGKg@mail.gmail.com>
References: <CALJKBv8OS75t1-6T50p1hkY_PXTbU2Xh9UEeVXB6_ULrx1ZGKg@mail.gmail.com>
Message-ID: <CAAHES9zrOx35gJ1=ox83Gy=3g90dKAbGPQxtF9O-aGAfv5oKYA@mail.gmail.com>

Wrong list, as you've been told several times yet you seemingly decided to
ignore the advice!

Your question would be on topic for R-Help. But please do your homework and
check that the issue is not documented somewhere first. You've spammed this
list enough already without you doing the same to R-Help.

G

On 10 March 2015 at 09:31, Karim Mezhoud <kmezhoud at gmail.com> wrote:

> Dear All,
> I would like to reset default R_HOME PATH for R.3.1.3.
> I installed R-devel in /usr/local/R-devel but I can't install many packages
> as tcltk.
> I uninstalled R-devel and I would reuse R.3.1.3 but the PATH is remaining
> to  /usr/local/R-devel.
>
> I touch ~.Renviron file with
>
> R_HOME=/usr/lib/R/bin/
> RSTUDIO_R_HOME=/usr/lib/R/bin/
>
> R_LIBS=~/R/x86_64-pc-linux-gnu-library/3.1
>
> R_LIBS_USER=${R_LIBS_USER-'~/R/x86_64-pc-linux-gnu-library/3.1'}
>
> Without success.
> Any idea?
> which file has the R_HOME setting?
> Thanks
> Karim
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Gavin Simpson, PhD

	[[alternative HTML version deleted]]


From avraham.adler at gmail.com  Wed Mar 11 04:54:03 2015
From: avraham.adler at gmail.com (Avraham Adler)
Date: Tue, 10 Mar 2015 23:54:03 -0400
Subject: [Rd] Notes on building a gcc toolchain for Rtools (but not
	multilib)
In-Reply-To: <54FF432C.8030200@gmail.com>
References: <1110879639.489054.1426013789755.JavaMail.root@fredhutch.org>
	<54FF432C.8030200@gmail.com>
Message-ID: <CAL6gwn+7k9=BnzCZ+v9s3rXVMZ_okns7WUVKfFLp7bj7pDzWfA@mail.gmail.com>

On Tue, Mar 10, 2015 at 3:17 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
>
> That's a bug.  I haven't tracked down what's going wrong with our
> regular code.  If I can't find that and fix it soon, I'll make Internet2
> the default.  For now, you can do it yourself using the instructions on
> ?setInternet2.
>
> Duncan Murdoch

I successfully rebuilt R-devel_2015-03-09 with the most recent version
of Rtools tonight, building both ICU_531 and this time libcurl (7.39)
as well (and OpenBLAS, of course). The internet bug is still there,
but the rest of make-check all passed with flying colors, as did
building 'microbenchmark' from source (with all the other needed
packages, including Rcpp and Hsiu-Kheurn's change to NM was *not*
used). My non-BLAS test tonight ran faster than last night; maybe 1000
iterations aren't enough or I had something else eating up clock
cycles last night. Either way, outside the internet bug, it's looking
good for Windows 64bit (Win7 at least).

Thanks,

Avi


From tangoh at gmail.com  Wed Mar 11 06:40:16 2015
From: tangoh at gmail.com (Hsiu-Khuern Tang)
Date: Tue, 10 Mar 2015 22:40:16 -0700
Subject: [Rd] Notes on building a gcc toolchain for Rtools (but not
	multilib)
In-Reply-To: <CAL6gwn+7k9=BnzCZ+v9s3rXVMZ_okns7WUVKfFLp7bj7pDzWfA@mail.gmail.com>
References: <1110879639.489054.1426013789755.JavaMail.root@fredhutch.org>
	<54FF432C.8030200@gmail.com>
	<CAL6gwn+7k9=BnzCZ+v9s3rXVMZ_okns7WUVKfFLp7bj7pDzWfA@mail.gmail.com>
Message-ID: <CAPuMoLb-1zoWV59atQH5eKi4oPG1sY+WXr4e+cDw5V9soiM3NQ@mail.gmail.com>

On Tue, Mar 10, 2015 at 8:54 PM, Avraham Adler <avraham.adler at gmail.com> wrote:
> On Tue, Mar 10, 2015 at 3:17 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>>
>> That's a bug.  I haven't tracked down what's going wrong with our
>> regular code.  If I can't find that and fix it soon, I'll make Internet2
>> the default.  For now, you can do it yourself using the instructions on
>> ?setInternet2.
>>
>> Duncan Murdoch
>
> I successfully rebuilt R-devel_2015-03-09 with the most recent version
> of Rtools tonight, building both ICU_531 and this time libcurl (7.39)
> as well (and OpenBLAS, of course). The internet bug is still there,
> but the rest of make-check all passed with flying colors, as did
> building 'microbenchmark' from source (with all the other needed
> packages, including Rcpp and Hsiu-Kheurn's change to NM was *not*
> used).
> ...

The NM_FILTER change seems to be needed only when compiling C++ code
with -std=c++11 or -std=gnu++11.

Even though the current CRAN policy doesn't allow the C++11 standard,
it would still be useful to document this, perhaps in the Writing R
Extensions manual.

- Hsiu-Khuern


From avraham.adler at gmail.com  Wed Mar 11 06:47:47 2015
From: avraham.adler at gmail.com (Avraham Adler)
Date: Wed, 11 Mar 2015 01:47:47 -0400
Subject: [Rd] Notes on building a gcc toolchain for Rtools (but not
	multilib)
In-Reply-To: <CAPuMoLb-1zoWV59atQH5eKi4oPG1sY+WXr4e+cDw5V9soiM3NQ@mail.gmail.com>
References: <1110879639.489054.1426013789755.JavaMail.root@fredhutch.org>
	<54FF432C.8030200@gmail.com>
	<CAL6gwn+7k9=BnzCZ+v9s3rXVMZ_okns7WUVKfFLp7bj7pDzWfA@mail.gmail.com>
	<CAPuMoLb-1zoWV59atQH5eKi4oPG1sY+WXr4e+cDw5V9soiM3NQ@mail.gmail.com>
Message-ID: <CAL6gwn+cBmUnouoEG=-X-bm-QNYUiBv54TZRSYiTJZKt9KXFCg@mail.gmail.com>

On Wed, Mar 11, 2015 at 1:40 AM, Hsiu-Khuern Tang <tangoh at gmail.com> wrote:
> On Tue, Mar 10, 2015 at 8:54 PM, Avraham Adler <avraham.adler at gmail.com> wrote:
>>
>> I successfully rebuilt R-devel_2015-03-09 with the most recent version
>> of Rtools tonight, building both ICU_531 and this time libcurl (7.39)
>> as well (and OpenBLAS, of course). The internet bug is still there,
>> but the rest of make-check all passed with flying colors, as did
>> building 'microbenchmark' from source (with all the other needed
>> packages, including Rcpp and Hsiu-Kheurn's change to NM was *not*
>> used).
>> ...
>
> The NM_FILTER change seems to be needed only when compiling C++ code
> with -std=c++11 or -std=gnu++11.
>
> Even though the current CRAN policy doesn't allow the C++11 standard,
> it would still be useful to document this, perhaps in the Writing R
> Extensions manual.
>
> - Hsiu-Khuern

Hello, Hsiu-Khuern.

All the times I have built, I've passed -std-gnu++11. Specifically, I
pass: -march=native -O3 -mfpmath=sse -std=gnu++11 -msse2avx
-mavx256-split-unaligned-load -mavx256-split-unaligned-store
-mvzeroupper --param l1-cache-line-size=64 --param l1-cache-size=64
--param l2-cache-size=256. I live with the repeated warnings that it
isn't needed for gcc, but I know it takes as I see the same string
(gnu++11) passed when I build Rcpp from inside an R session.

Avi


From thierry.onkelinx at inbo.be  Wed Mar 11 13:55:28 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 11 Mar 2015 13:55:28 +0100
Subject: [Rd] normalizePath output depends on existence of directory
Message-ID: <CAJuCY5x=ivKXOpysF_t+1jmzuR=N_OHS7R5t1GYvs2fVDu3w6w@mail.gmail.com>

Dear all,


I'm not sure whether this is intended behaviour or a bug. The path returns
from normalizePath is different when the directory doesn't exist. I have
included a reproducible example.

path <- tempfile()
missing.dir <- normalizePath(path, winslash = "/", mustWork = FALSE)
dir.create(path)
existing.dir <- normalizePath(path, winslash = "/", mustWork = FALSE)

> all.equal(missing.dir, existing.dir)
[1] "1 string mismatch"
> missing.dir
[1] "C:/Users/THIERR~2/AppData/Local/Temp/RtmpagA8Gx/filed5c2cd03543"
> existing.dir
[1]
"C:/Users/thierry_onkelinx/AppData/Local/Temp/RtmpagA8Gx/filed5c2cd03543"

sessionInfo()

R version 3.1.2 (2014-10-31)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=Dutch_Belgium.1252  LC_CTYPE=Dutch_Belgium.1252
 LC_MONETARY=Dutch_Belgium.1252
[4] LC_NUMERIC=C                   LC_TIME=Dutch_Belgium.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] fortunes_1.5-2 tools_3.1.2

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Mar 11 14:07:12 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 11 Mar 2015 09:07:12 -0400
Subject: [Rd] normalizePath output depends on existence of directory
In-Reply-To: <CAJuCY5x=ivKXOpysF_t+1jmzuR=N_OHS7R5t1GYvs2fVDu3w6w@mail.gmail.com>
References: <CAJuCY5x=ivKXOpysF_t+1jmzuR=N_OHS7R5t1GYvs2fVDu3w6w@mail.gmail.com>
Message-ID: <55003E00.9090107@gmail.com>

On 11/03/2015 8:55 AM, Thierry Onkelinx wrote:
> Dear all,
>
>
> I'm not sure whether this is intended behaviour or a bug. The path returns
> from normalizePath is different when the directory doesn't exist. I have
> included a reproducible example.

See the help page.

Duncan Murdoch
>
> path <- tempfile()
> missing.dir <- normalizePath(path, winslash = "/", mustWork = FALSE)
> dir.create(path)
> existing.dir <- normalizePath(path, winslash = "/", mustWork = FALSE)
>
> > all.equal(missing.dir, existing.dir)
> [1] "1 string mismatch"
> > missing.dir
> [1] "C:/Users/THIERR~2/AppData/Local/Temp/RtmpagA8Gx/filed5c2cd03543"
> > existing.dir
> [1]
> "C:/Users/thierry_onkelinx/AppData/Local/Temp/RtmpagA8Gx/filed5c2cd03543"
>
> sessionInfo()
>
> R version 3.1.2 (2014-10-31)
> Platform: i386-w64-mingw32/i386 (32-bit)
>
> locale:
> [1] LC_COLLATE=Dutch_Belgium.1252  LC_CTYPE=Dutch_Belgium.1252
>   LC_MONETARY=Dutch_Belgium.1252
> [4] LC_NUMERIC=C                   LC_TIME=Dutch_Belgium.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] fortunes_1.5-2 tools_3.1.2
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From tangoh at gmail.com  Wed Mar 11 18:23:10 2015
From: tangoh at gmail.com (Hsiu-Khuern Tang)
Date: Wed, 11 Mar 2015 10:23:10 -0700
Subject: [Rd] Notes on building a gcc toolchain for Rtools (but not
	multilib)
In-Reply-To: <CAL6gwn+cBmUnouoEG=-X-bm-QNYUiBv54TZRSYiTJZKt9KXFCg@mail.gmail.com>
References: <1110879639.489054.1426013789755.JavaMail.root@fredhutch.org>
	<54FF432C.8030200@gmail.com>
	<CAL6gwn+7k9=BnzCZ+v9s3rXVMZ_okns7WUVKfFLp7bj7pDzWfA@mail.gmail.com>
	<CAPuMoLb-1zoWV59atQH5eKi4oPG1sY+WXr4e+cDw5V9soiM3NQ@mail.gmail.com>
	<CAL6gwn+cBmUnouoEG=-X-bm-QNYUiBv54TZRSYiTJZKt9KXFCg@mail.gmail.com>
Message-ID: <CAPuMoLZB8j_xvOEy9VTrFvbp7TNmaFy7UXkNg694f3o8sDg+Tw@mail.gmail.com>

On Tue, Mar 10, 2015 at 10:47 PM, Avraham Adler <avraham.adler at gmail.com> wrote:
> On Wed, Mar 11, 2015 at 1:40 AM, Hsiu-Khuern Tang <tangoh at gmail.com> wrote:
>> On Tue, Mar 10, 2015 at 8:54 PM, Avraham Adler <avraham.adler at gmail.com> wrote:
>>>
>>> I successfully rebuilt R-devel_2015-03-09 with the most recent version
>>> of Rtools tonight, building both ICU_531 and this time libcurl (7.39)
>>> as well (and OpenBLAS, of course). The internet bug is still there,
>>> but the rest of make-check all passed with flying colors, as did
>>> building 'microbenchmark' from source (with all the other needed
>>> packages, including Rcpp and Hsiu-Kheurn's change to NM was *not*
>>> used).
>>> ...
>>
>> The NM_FILTER change seems to be needed only when compiling C++ code
>> with -std=c++11 or -std=gnu++11.
>>
>> Even though the current CRAN policy doesn't allow the C++11 standard,
>> it would still be useful to document this, perhaps in the Writing R
>> Extensions manual.
>>
>> - Hsiu-Khuern
>
> Hello, Hsiu-Khuern.
>
> All the times I have built, I've passed -std-gnu++11. Specifically, I
> pass: -march=native -O3 -mfpmath=sse -std=gnu++11 -msse2avx
> -mavx256-split-unaligned-load -mavx256-split-unaligned-store
> -mvzeroupper --param l1-cache-line-size=64 --param l1-cache-size=64
> --param l2-cache-size=256.
> ...

Interesting.  I tested the use of -O0, ..., -O3 together with
-std=gnu++11.  With -O0 (which I suppose is the default if not
specified), I get the following error when R CMD INSTALL is trying to
create Rcpp.dll:

collect2.exe: error: ld returned 5 exit status

With -O1, -O2, or -O3, there is no error.

- Hsiu-Khuern


From avraham.adler at gmail.com  Wed Mar 11 18:32:13 2015
From: avraham.adler at gmail.com (Avraham Adler)
Date: Wed, 11 Mar 2015 13:32:13 -0400
Subject: [Rd] Notes on building a gcc toolchain for Rtools (but not
	multilib)
In-Reply-To: <CAPuMoLZB8j_xvOEy9VTrFvbp7TNmaFy7UXkNg694f3o8sDg+Tw@mail.gmail.com>
References: <1110879639.489054.1426013789755.JavaMail.root@fredhutch.org>
	<54FF432C.8030200@gmail.com>
	<CAL6gwn+7k9=BnzCZ+v9s3rXVMZ_okns7WUVKfFLp7bj7pDzWfA@mail.gmail.com>
	<CAPuMoLb-1zoWV59atQH5eKi4oPG1sY+WXr4e+cDw5V9soiM3NQ@mail.gmail.com>
	<CAL6gwn+cBmUnouoEG=-X-bm-QNYUiBv54TZRSYiTJZKt9KXFCg@mail.gmail.com>
	<CAPuMoLZB8j_xvOEy9VTrFvbp7TNmaFy7UXkNg694f3o8sDg+Tw@mail.gmail.com>
Message-ID: <CAL6gwn+4zKHGFZV-QPDv5oSt_pY4UKjmU=R+Kxoqq7NuLGBL_g@mail.gmail.com>

On Wed, Mar 11, 2015 at 1:23 PM, Hsiu-Khuern Tang <tangoh at gmail.com> wrote:
> On Tue, Mar 10, 2015 at 10:47 PM, Avraham Adler <avraham.adler at gmail.com> wrote:
>> On Wed, Mar 11, 2015 at 1:40 AM, Hsiu-Khuern Tang <tangoh at gmail.com> wrote:
>>> On Tue, Mar 10, 2015 at 8:54 PM, Avraham Adler <avraham.adler at gmail.com> wrote:
>>>>
>>>> I successfully rebuilt R-devel_2015-03-09 with the most recent version
>>>> of Rtools tonight, building both ICU_531 and this time libcurl (7.39)
>>>> as well (and OpenBLAS, of course). The internet bug is still there,
>>>> but the rest of make-check all passed with flying colors, as did
>>>> building 'microbenchmark' from source (with all the other needed
>>>> packages, including Rcpp and Hsiu-Kheurn's change to NM was *not*
>>>> used).
>>>> ...
>>>
>>> The NM_FILTER change seems to be needed only when compiling C++ code
>>> with -std=c++11 or -std=gnu++11.
>>>
>>> Even though the current CRAN policy doesn't allow the C++11 standard,
>>> it would still be useful to document this, perhaps in the Writing R
>>> Extensions manual.
>>>
>>> - Hsiu-Khuern
>>
>> Hello, Hsiu-Khuern.
>>
>> All the times I have built, I've passed -std-gnu++11. Specifically, I
>> pass: -march=native -O3 -mfpmath=sse -std=gnu++11 -msse2avx
>> -mavx256-split-unaligned-load -mavx256-split-unaligned-store
>> -mvzeroupper --param l1-cache-line-size=64 --param l1-cache-size=64
>> --param l2-cache-size=256.
>> ...
>
> Interesting.  I tested the use of -O0, ..., -O3 together with
> -std=gnu++11.  With -O0 (which I suppose is the default if not
> specified), I get the following error when R CMD INSTALL is trying to
> create Rcpp.dll:
>
> collect2.exe: error: ld returned 5 exit status
>
> With -O1, -O2, or -O3, there is no error.
>
> - Hsiu-Khuern
>

The default is O2, I believe, as the default EOPTS in
src/gnuwin32/Mkrules.dist are -O2 -mtune=core2.

Avi


From murdoch.duncan at gmail.com  Wed Mar 11 20:06:48 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 11 Mar 2015 15:06:48 -0400
Subject: [Rd] Notes on building a gcc toolchain for Rtools (but not
	multilib)
In-Reply-To: <54FF432C.8030200@gmail.com>
References: <1110879639.489054.1426013789755.JavaMail.root@fredhutch.org>
	<54FF432C.8030200@gmail.com>
Message-ID: <55009248.1060002@gmail.com>

On 10/03/2015 3:17 PM, Duncan Murdoch wrote:
> On 10/03/2015 2:56 PM, Dan Tenenbaum wrote:
> >
> >
> > ----- Original Message -----
> >> From: "Duncan Murdoch" <murdoch.duncan at gmail.com>
> >> To: "Dan Tenenbaum" <dtenenba at fredhutch.org>
> >> Cc: "Hsiu-Khuern Tang" <tangoh at gmail.com>, r-devel at r-project.org
> >> Sent: Tuesday, March 10, 2015 11:37:12 AM
> >> Subject: Re: [Rd] Notes on building a gcc toolchain for Rtools (but not multilib)
> >>
> >> On 10/03/2015 12:54 PM, Dan Tenenbaum wrote:
> >>>
> >>> ----- Original Message -----
> >>>> From: "Duncan Murdoch" <murdoch.duncan at gmail.com>
> >>>> To: "Hsiu-Khuern Tang" <tangoh at gmail.com>, r-devel at r-project.org
> >>>> Sent: Monday, March 9, 2015 10:40:02 AM
> >>>> Subject: Re: [Rd] Notes on building a gcc toolchain for Rtools
> >>>> (but not	multilib)
> >>>>
> >>>> On 09/03/2015 11:07 AM, Hsiu-Khuern Tang wrote:
> >>>>> On Mon, Mar 9, 2015 at 3:50 AM, Duncan Murdoch
> >>>>> <murdoch.duncan at gmail.com> wrote:
> >>>>>> On 08/03/2015 10:02 PM, Hsiu-Khuern Tang wrote:
> >>>>>>> Hi,
> >>>>>>>
> >>>>>>> [This is a follow-up to the "New version of Rtools for
> >>>>>>> Windows"
> >>>>>>> thread
> >>>>>>> in January, but I just subscribed and don't know how to
> >>>>>>> reply to
> >>>>>>> an
> >>>>>>> old thread -- my apologies.]
> >>>>>>
> >>>>>> I am planning to put a new Rtools online today that uses a
> >>>>>> different
> >>>>>> build of gcc 4.9.2.  I will be concentrating on getting it to
> >>>>>> work with
> >>>>>> all the external libraries before the 3.2.0 release next
> >>>>>> month.
> >>>>>>  I'm not
> >>>>>> planning to try to get it to work with R-patched, and I
> >>>>>> expect it
> >>>>>> won't:
> >>>>>>  I needed to make a number of patches to R-devel for
> >>>>>>  compatibility.
> >>>>>
> >>>>> I also worked off R-devel (I said wrongly that it was R-patched
> >>>>> in
> >>>>> my
> >>>>> original post) and benefited from your compatibility changes.
> >>>>>
> >>>>> I look forward to the new Rtools and will test it by compiling
> >>>>> some
> >>>>> packages.
> >>>>
> >>>> It's now on the main site at CRAN, and should propagate to the
> >>>> mirrors
> >>>> reasonably quickly.  I'm hoping that tomorrow's R-devel build
> >>>> will
> >>>> use
> >>>> it, but there may be some last minute problems.
> >>>>
> >>>
> >>> Thanks to you and everyone who worked on this. Is there a way to
> >>> tell which toolchain built a given R-devel binary?
> >>> If not, can you let us know when there is one on CRAN that was
> >>> built with the new Rtools?
> >>
> >> If you look in etc/*/Makeconf, you'll see something like this:
> >>
> >> BINPREF ?= $(RTOOLS)gcc492_64/bin/
> >>
> >> hopefully from tomorrow onwards.  If today's build was with the new
> >> toolchain, you should see a hardcoded path to where I have Rtools
> >> installed on the build machine, which isn't so helpful.  The previous
> >> toolchain left BINPREF blank.
> >>
> >> If you want to use your own toolchain, just edit those files.  If you
> >> want to install the standard Rtools somewhere else, set an
> >> environment
> >> variable like
> >>
> >> RTOOLS = C:/Rtools/
> >>
> >> (where the terminal / is required.)
> >>
> >
> > Thanks, that's very helpful. I also notice with the latest R-devel binary (67969, which is built with the new Rtools according to what you say above) that I need to do setInternet2(TRUE) before I can download from any URLs; I see some mention of that earlier in this thread, is this intended? If so is there a way to make this the default?
>
> That's a bug.  I haven't tracked down what's going wrong with our
> regular code.  If I can't find that and fix it soon, I'll make Internet2
> the default.  For now, you can do it yourself using the instructions on
> ?setInternet2.

I've found the problem now, and it will be easy to fix.  In case anyone 
else finds this thread, here's the problem:

The regular Windows internet code (not internet2) used the Winsock 
interface.  It returns different error codes than the Unix sockets 
interface.   Some error codes are ignorable (EWOULDBLOCK and 
EINPROGRESS); these are WSAEWOULDBLOCK and WSAEINPROGRESS in Winsock.  
We had code like

#ifndef EWOULDBLOCK
# define EWOULDBLOCK             WSAEWOULDBLOCK
#endif

so our code could work with the Unix macro names.  However, the new 
toolchain defines both EWOULDBLOCK
and WSAEWOULDBLOCK, so the remapping never happened, and we didn't 
ignore those errors.

Tomorrow's R-devel should have the fix in place, unless something else 
goes wrong, or I'm too slow.

Duncan Murdoch


From tangoh at gmail.com  Wed Mar 11 20:07:19 2015
From: tangoh at gmail.com (Hsiu-Khuern Tang)
Date: Wed, 11 Mar 2015 12:07:19 -0700
Subject: [Rd] Notes on building a gcc toolchain for Rtools (but not
	multilib)
In-Reply-To: <CAL6gwn+4zKHGFZV-QPDv5oSt_pY4UKjmU=R+Kxoqq7NuLGBL_g@mail.gmail.com>
References: <1110879639.489054.1426013789755.JavaMail.root@fredhutch.org>
	<54FF432C.8030200@gmail.com>
	<CAL6gwn+7k9=BnzCZ+v9s3rXVMZ_okns7WUVKfFLp7bj7pDzWfA@mail.gmail.com>
	<CAPuMoLb-1zoWV59atQH5eKi4oPG1sY+WXr4e+cDw5V9soiM3NQ@mail.gmail.com>
	<CAL6gwn+cBmUnouoEG=-X-bm-QNYUiBv54TZRSYiTJZKt9KXFCg@mail.gmail.com>
	<CAPuMoLZB8j_xvOEy9VTrFvbp7TNmaFy7UXkNg694f3o8sDg+Tw@mail.gmail.com>
	<CAL6gwn+4zKHGFZV-QPDv5oSt_pY4UKjmU=R+Kxoqq7NuLGBL_g@mail.gmail.com>
Message-ID: <CAPuMoLZJMQ+mgQv7vd_UAbwF=wkM=cBxSjvPgYp3fX5KG=hYHw@mail.gmail.com>

On Wed, Mar 11, 2015 at 10:32 AM, Avraham Adler <avraham.adler at gmail.com> wrote:
> On Wed, Mar 11, 2015 at 1:23 PM, Hsiu-Khuern Tang <tangoh at gmail.com> wrote:
>> On Tue, Mar 10, 2015 at 10:47 PM, Avraham Adler <avraham.adler at gmail.com> wrote:
>>> On Wed, Mar 11, 2015 at 1:40 AM, Hsiu-Khuern Tang <tangoh at gmail.com> wrote:
>>>> On Tue, Mar 10, 2015 at 8:54 PM, Avraham Adler <avraham.adler at gmail.com> wrote:
>>>>>
>>>>> I successfully rebuilt R-devel_2015-03-09 with the most recent version
>>>>> of Rtools tonight, building both ICU_531 and this time libcurl (7.39)
>>>>> as well (and OpenBLAS, of course). The internet bug is still there,
>>>>> but the rest of make-check all passed with flying colors, as did
>>>>> building 'microbenchmark' from source (with all the other needed
>>>>> packages, including Rcpp and Hsiu-Kheurn's change to NM was *not*
>>>>> used).
>>>>> ...
>>>>
>>>> The NM_FILTER change seems to be needed only when compiling C++ code
>>>> with -std=c++11 or -std=gnu++11.
>>>>
>>>> Even though the current CRAN policy doesn't allow the C++11 standard,
>>>> it would still be useful to document this, perhaps in the Writing R
>>>> Extensions manual.
>>>>
>>>> - Hsiu-Khuern
>>>
>>> Hello, Hsiu-Khuern.
>>>
>>> All the times I have built, I've passed -std-gnu++11. Specifically, I
>>> pass: -march=native -O3 -mfpmath=sse -std=gnu++11 -msse2avx
>>> -mavx256-split-unaligned-load -mavx256-split-unaligned-store
>>> -mvzeroupper --param l1-cache-line-size=64 --param l1-cache-size=64
>>> --param l2-cache-size=256.
>>> ...
>>
>> Interesting.  I tested the use of -O0, ..., -O3 together with
>> -std=gnu++11.  With -O0 (which I suppose is the default if not
>> specified), I get the following error when R CMD INSTALL is trying to
>> create Rcpp.dll:
>>
>> collect2.exe: error: ld returned 5 exit status
>>
>> With -O1, -O2, or -O3, there is no error.
>>
>> - Hsiu-Khuern
>>
>
> The default is O2, I believe, as the default EOPTS in
> src/gnuwin32/Mkrules.dist are -O2 -mtune=core2.

I was setting CXXFLAGS=-std=gnu++11 in my .R/Makevars, which overrides
the CXXFLAGS setting in $R_HOME/etc/x64/Makeconf, hence the final g++
option didn't include the -O2 -mtune=core2.

Sorry for not being clear.

- Hsiu-Khuern


From dtenenba at fredhutch.org  Wed Mar 11 20:09:57 2015
From: dtenenba at fredhutch.org (Dan Tenenbaum)
Date: Wed, 11 Mar 2015 12:09:57 -0700 (PDT)
Subject: [Rd] Notes on building a gcc toolchain for Rtools (but not
 multilib)
In-Reply-To: <55009248.1060002@gmail.com>
Message-ID: <2019630797.513208.1426100997515.JavaMail.root@fredhutch.org>



----- Original Message -----
> From: "Duncan Murdoch" <murdoch.duncan at gmail.com>
> To: "Dan Tenenbaum" <dtenenba at fredhutch.org>
> Cc: r-devel at r-project.org
> Sent: Wednesday, March 11, 2015 12:06:48 PM
> Subject: Re: [Rd] Notes on building a gcc toolchain for Rtools (but not multilib)
> 
> On 10/03/2015 3:17 PM, Duncan Murdoch wrote:
> > On 10/03/2015 2:56 PM, Dan Tenenbaum wrote:
> > >
> > >
> > > ----- Original Message -----
> > >> From: "Duncan Murdoch" <murdoch.duncan at gmail.com>
> > >> To: "Dan Tenenbaum" <dtenenba at fredhutch.org>
> > >> Cc: "Hsiu-Khuern Tang" <tangoh at gmail.com>, r-devel at r-project.org
> > >> Sent: Tuesday, March 10, 2015 11:37:12 AM
> > >> Subject: Re: [Rd] Notes on building a gcc toolchain for Rtools
> > >> (but not multilib)
> > >>
> > >> On 10/03/2015 12:54 PM, Dan Tenenbaum wrote:
> > >>>
> > >>> ----- Original Message -----
> > >>>> From: "Duncan Murdoch" <murdoch.duncan at gmail.com>
> > >>>> To: "Hsiu-Khuern Tang" <tangoh at gmail.com>,
> > >>>> r-devel at r-project.org
> > >>>> Sent: Monday, March 9, 2015 10:40:02 AM
> > >>>> Subject: Re: [Rd] Notes on building a gcc toolchain for Rtools
> > >>>> (but not	multilib)
> > >>>>
> > >>>> On 09/03/2015 11:07 AM, Hsiu-Khuern Tang wrote:
> > >>>>> On Mon, Mar 9, 2015 at 3:50 AM, Duncan Murdoch
> > >>>>> <murdoch.duncan at gmail.com> wrote:
> > >>>>>> On 08/03/2015 10:02 PM, Hsiu-Khuern Tang wrote:
> > >>>>>>> Hi,
> > >>>>>>>
> > >>>>>>> [This is a follow-up to the "New version of Rtools for
> > >>>>>>> Windows"
> > >>>>>>> thread
> > >>>>>>> in January, but I just subscribed and don't know how to
> > >>>>>>> reply to
> > >>>>>>> an
> > >>>>>>> old thread -- my apologies.]
> > >>>>>>
> > >>>>>> I am planning to put a new Rtools online today that uses a
> > >>>>>> different
> > >>>>>> build of gcc 4.9.2.  I will be concentrating on getting it
> > >>>>>> to
> > >>>>>> work with
> > >>>>>> all the external libraries before the 3.2.0 release next
> > >>>>>> month.
> > >>>>>>  I'm not
> > >>>>>> planning to try to get it to work with R-patched, and I
> > >>>>>> expect it
> > >>>>>> won't:
> > >>>>>>  I needed to make a number of patches to R-devel for
> > >>>>>>  compatibility.
> > >>>>>
> > >>>>> I also worked off R-devel (I said wrongly that it was
> > >>>>> R-patched
> > >>>>> in
> > >>>>> my
> > >>>>> original post) and benefited from your compatibility changes.
> > >>>>>
> > >>>>> I look forward to the new Rtools and will test it by
> > >>>>> compiling
> > >>>>> some
> > >>>>> packages.
> > >>>>
> > >>>> It's now on the main site at CRAN, and should propagate to the
> > >>>> mirrors
> > >>>> reasonably quickly.  I'm hoping that tomorrow's R-devel build
> > >>>> will
> > >>>> use
> > >>>> it, but there may be some last minute problems.
> > >>>>
> > >>>
> > >>> Thanks to you and everyone who worked on this. Is there a way
> > >>> to
> > >>> tell which toolchain built a given R-devel binary?
> > >>> If not, can you let us know when there is one on CRAN that was
> > >>> built with the new Rtools?
> > >>
> > >> If you look in etc/*/Makeconf, you'll see something like this:
> > >>
> > >> BINPREF ?= $(RTOOLS)gcc492_64/bin/
> > >>
> > >> hopefully from tomorrow onwards.  If today's build was with the
> > >> new
> > >> toolchain, you should see a hardcoded path to where I have
> > >> Rtools
> > >> installed on the build machine, which isn't so helpful.  The
> > >> previous
> > >> toolchain left BINPREF blank.
> > >>
> > >> If you want to use your own toolchain, just edit those files.
> > >>  If you
> > >> want to install the standard Rtools somewhere else, set an
> > >> environment
> > >> variable like
> > >>
> > >> RTOOLS = C:/Rtools/
> > >>
> > >> (where the terminal / is required.)
> > >>
> > >
> > > Thanks, that's very helpful. I also notice with the latest
> > > R-devel binary (67969, which is built with the new Rtools
> > > according to what you say above) that I need to do
> > > setInternet2(TRUE) before I can download from any URLs; I see
> > > some mention of that earlier in this thread, is this intended?
> > > If so is there a way to make this the default?
> >
> > That's a bug.  I haven't tracked down what's going wrong with our
> > regular code.  If I can't find that and fix it soon, I'll make
> > Internet2
> > the default.  For now, you can do it yourself using the
> > instructions on
> > ?setInternet2.
> 
> I've found the problem now, and it will be easy to fix.  In case
> anyone
> else finds this thread, here's the problem:
> 
> The regular Windows internet code (not internet2) used the Winsock
> interface.  It returns different error codes than the Unix sockets
> interface.   Some error codes are ignorable (EWOULDBLOCK and
> EINPROGRESS); these are WSAEWOULDBLOCK and WSAEINPROGRESS in Winsock.
> We had code like
> 
> #ifndef EWOULDBLOCK
> # define EWOULDBLOCK             WSAEWOULDBLOCK
> #endif
> 
> so our code could work with the Unix macro names.  However, the new
> toolchain defines both EWOULDBLOCK
> and WSAEWOULDBLOCK, so the remapping never happened, and we didn't
> ignore those errors.
> 
> Tomorrow's R-devel should have the fix in place, unless something
> else
> goes wrong, or I'm too slow.
> 

Thanks! Will there be a corresponding update to Rtools as well, or is that not necessary?

Dan


From murdoch.duncan at gmail.com  Wed Mar 11 20:38:20 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 11 Mar 2015 15:38:20 -0400
Subject: [Rd] Notes on building a gcc toolchain for Rtools (but not
	multilib)
In-Reply-To: <2019630797.513208.1426100997515.JavaMail.root@fredhutch.org>
References: <2019630797.513208.1426100997515.JavaMail.root@fredhutch.org>
Message-ID: <550099AC.8010309@gmail.com>

On 11/03/2015 3:09 PM, Dan Tenenbaum wrote:
>
> ----- Original Message -----
> > From: "Duncan Murdoch" <murdoch.duncan at gmail.com>
> > To: "Dan Tenenbaum" <dtenenba at fredhutch.org>
> > Cc: r-devel at r-project.org
> > Sent: Wednesday, March 11, 2015 12:06:48 PM
> > Subject: Re: [Rd] Notes on building a gcc toolchain for Rtools (but not multilib)
> >
> > On 10/03/2015 3:17 PM, Duncan Murdoch wrote:
> > > On 10/03/2015 2:56 PM, Dan Tenenbaum wrote:
> > > >
> > > >
> > > > ----- Original Message -----
> > > >> From: "Duncan Murdoch" <murdoch.duncan at gmail.com>
> > > >> To: "Dan Tenenbaum" <dtenenba at fredhutch.org>
> > > >> Cc: "Hsiu-Khuern Tang" <tangoh at gmail.com>, r-devel at r-project.org
> > > >> Sent: Tuesday, March 10, 2015 11:37:12 AM
> > > >> Subject: Re: [Rd] Notes on building a gcc toolchain for Rtools
> > > >> (but not multilib)
> > > >>
> > > >> On 10/03/2015 12:54 PM, Dan Tenenbaum wrote:
> > > >>>
> > > >>> ----- Original Message -----
> > > >>>> From: "Duncan Murdoch" <murdoch.duncan at gmail.com>
> > > >>>> To: "Hsiu-Khuern Tang" <tangoh at gmail.com>,
> > > >>>> r-devel at r-project.org
> > > >>>> Sent: Monday, March 9, 2015 10:40:02 AM
> > > >>>> Subject: Re: [Rd] Notes on building a gcc toolchain for Rtools
> > > >>>> (but not	multilib)
> > > >>>>
> > > >>>> On 09/03/2015 11:07 AM, Hsiu-Khuern Tang wrote:
> > > >>>>> On Mon, Mar 9, 2015 at 3:50 AM, Duncan Murdoch
> > > >>>>> <murdoch.duncan at gmail.com> wrote:
> > > >>>>>> On 08/03/2015 10:02 PM, Hsiu-Khuern Tang wrote:
> > > >>>>>>> Hi,
> > > >>>>>>>
> > > >>>>>>> [This is a follow-up to the "New version of Rtools for
> > > >>>>>>> Windows"
> > > >>>>>>> thread
> > > >>>>>>> in January, but I just subscribed and don't know how to
> > > >>>>>>> reply to
> > > >>>>>>> an
> > > >>>>>>> old thread -- my apologies.]
> > > >>>>>>
> > > >>>>>> I am planning to put a new Rtools online today that uses a
> > > >>>>>> different
> > > >>>>>> build of gcc 4.9.2.  I will be concentrating on getting it
> > > >>>>>> to
> > > >>>>>> work with
> > > >>>>>> all the external libraries before the 3.2.0 release next
> > > >>>>>> month.
> > > >>>>>>  I'm not
> > > >>>>>> planning to try to get it to work with R-patched, and I
> > > >>>>>> expect it
> > > >>>>>> won't:
> > > >>>>>>  I needed to make a number of patches to R-devel for
> > > >>>>>>  compatibility.
> > > >>>>>
> > > >>>>> I also worked off R-devel (I said wrongly that it was
> > > >>>>> R-patched
> > > >>>>> in
> > > >>>>> my
> > > >>>>> original post) and benefited from your compatibility changes.
> > > >>>>>
> > > >>>>> I look forward to the new Rtools and will test it by
> > > >>>>> compiling
> > > >>>>> some
> > > >>>>> packages.
> > > >>>>
> > > >>>> It's now on the main site at CRAN, and should propagate to the
> > > >>>> mirrors
> > > >>>> reasonably quickly.  I'm hoping that tomorrow's R-devel build
> > > >>>> will
> > > >>>> use
> > > >>>> it, but there may be some last minute problems.
> > > >>>>
> > > >>>
> > > >>> Thanks to you and everyone who worked on this. Is there a way
> > > >>> to
> > > >>> tell which toolchain built a given R-devel binary?
> > > >>> If not, can you let us know when there is one on CRAN that was
> > > >>> built with the new Rtools?
> > > >>
> > > >> If you look in etc/*/Makeconf, you'll see something like this:
> > > >>
> > > >> BINPREF ?= $(RTOOLS)gcc492_64/bin/
> > > >>
> > > >> hopefully from tomorrow onwards.  If today's build was with the
> > > >> new
> > > >> toolchain, you should see a hardcoded path to where I have
> > > >> Rtools
> > > >> installed on the build machine, which isn't so helpful.  The
> > > >> previous
> > > >> toolchain left BINPREF blank.
> > > >>
> > > >> If you want to use your own toolchain, just edit those files.
> > > >>  If you
> > > >> want to install the standard Rtools somewhere else, set an
> > > >> environment
> > > >> variable like
> > > >>
> > > >> RTOOLS = C:/Rtools/
> > > >>
> > > >> (where the terminal / is required.)
> > > >>
> > > >
> > > > Thanks, that's very helpful. I also notice with the latest
> > > > R-devel binary (67969, which is built with the new Rtools
> > > > according to what you say above) that I need to do
> > > > setInternet2(TRUE) before I can download from any URLs; I see
> > > > some mention of that earlier in this thread, is this intended?
> > > > If so is there a way to make this the default?
> > >
> > > That's a bug.  I haven't tracked down what's going wrong with our
> > > regular code.  If I can't find that and fix it soon, I'll make
> > > Internet2
> > > the default.  For now, you can do it yourself using the
> > > instructions on
> > > ?setInternet2.
> >
> > I've found the problem now, and it will be easy to fix.  In case
> > anyone
> > else finds this thread, here's the problem:
> >
> > The regular Windows internet code (not internet2) used the Winsock
> > interface.  It returns different error codes than the Unix sockets
> > interface.   Some error codes are ignorable (EWOULDBLOCK and
> > EINPROGRESS); these are WSAEWOULDBLOCK and WSAEINPROGRESS in Winsock.
> > We had code like
> >
> > #ifndef EWOULDBLOCK
> > # define EWOULDBLOCK             WSAEWOULDBLOCK
> > #endif
> >
> > so our code could work with the Unix macro names.  However, the new
> > toolchain defines both EWOULDBLOCK
> > and WSAEWOULDBLOCK, so the remapping never happened, and we didn't
> > ignore those errors.
> >
> > Tomorrow's R-devel should have the fix in place, unless something
> > else
> > goes wrong, or I'm too slow.
> >
>
> Thanks! Will there be a corresponding update to Rtools as well, or is that not necessary?

Not necessary.

Duncan Murdoch


From nashjc at uottawa.ca  Thu Mar 12 14:51:02 2015
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Thu, 12 Mar 2015 09:51:02 -0400
Subject: [Rd] Requirement for pandoc 1.12.3 in R 3.1.3
Message-ID: <550199C6.1060301@uottawa.ca>

Are other developers finding R 3.1.3 problematic because vignette
building requires pandoc 1.12.3, while Linux Mint 17 / Ubuntu 14.04 have
1.12.2.1? R 3.1.2 seems to work fine.

I'd very much like to avoid having to build as large a Linux package as
pandoc, which has given me issues outside of R (it leaves out words,
sentences or paragraphs when converting Latex to epub in a novel I'm
working on, and does so without warning). Possibly concerns like this
are why R has moved to a later pandoc.

Suggestions welcome.

John Nash


From ripley at stats.ox.ac.uk  Thu Mar 12 15:21:39 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 12 Mar 2015 14:21:39 +0000
Subject: [Rd] Requirement for pandoc 1.12.3 in R 3.1.3
In-Reply-To: <550199C6.1060301@uottawa.ca>
References: <550199C6.1060301@uottawa.ca>
Message-ID: <5501A0F3.3060302@stats.ox.ac.uk>

On 12/03/2015 13:51, Prof J C Nash (U30A) wrote:
> Are other developers finding R 3.1.3 problematic because vignette
> building requires pandoc 1.12.3, while Linux Mint 17 / Ubuntu 14.04 have
> 1.12.2.1? R 3.1.2 seems to work fine.

R has no built-in support for non-Sweave vignettes, and there is no 
mention of pandoc in the R 3.1.3 sources except for the manual:

'Complete checking of a package which contains a file @file{README.md}
needs @command{pandoc} installed: see
@uref{http://johnmacfarlane.net/@/pandoc/@/installing.html}.'

which is true (but is not done with R 3.1.3).

I suspect you are confusing an R update with an update of whatever 
packages you use to process your vignettes: package rmarkdown has a 
pandoc version requirement of

SystemRequirements: pandoc (>= 1.12.3) -

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From profjcnash at gmail.com  Thu Mar 12 16:15:42 2015
From: profjcnash at gmail.com (John Nash)
Date: Thu, 12 Mar 2015 11:15:42 -0400
Subject: [Rd] Requirement for pandoc 1.12.3 in R 3.1.3
In-Reply-To: <5501A0F3.3060302@stats.ox.ac.uk>
References: <550199C6.1060301@uottawa.ca> <5501A0F3.3060302@stats.ox.ac.uk>
Message-ID: <5501AD9E.4090007@messier.ca>

Thanks Brian.

Indeed, the vignette is in markdown form. When I updated my system to
R 3.1.3 I ran update.packages() and this seems to have upset things
(including R-studio processing of markdown files).

I tried removing rmarkdown and reverting to an older version so that my
sessionInfo() is

Loading required package: rmarkdown
> sessionInfo()
R version 3.1.3 (2015-03-09)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.2 LTS

locale:
 [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
 [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
 [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] rmarkdown_0.3.3

loaded via a namespace (and not attached):
[1] digest_0.6.8    htmltools_0.2.6

I also made sure to remove all instances of rmarkdown before installing
the older version.

However,

R CMD build nls14

still gives lots of errors (these are related to content in the vignette
source and are, I believe, consequent on the warning about
engine$weave). The warning still refers to the later version of pandoc
which Ubuntu 14.04 repos don't yet have.

My current guess is some mismatch in the software infrastructure.  I
have another machine with R 3.1.2 and rmarkdown_0.3.3 that manages to
build the package without complaint, but it would be good to get this
sorted out. Pointers on where to look for a fix are welcome.

 R CMD build nls14
* checking for file ?nls14/DESCRIPTION? ... OK
* preparing ?nls14?:
* checking DESCRIPTION meta-information ... OK
* installing the package to build vignettes
* creating vignettes ... ERROR
Warning in engine$weave(file, quiet = quiet, encoding = enc) :
  Pandoc (>= 1.12.3) and/or pandoc-citeproc is not available. Please
install both.
Error in fnDeriv(r1, "x") : Only single expressions allowed
Error in as.vector(x, "expression") :
  cannot coerce type 'closure' to vector of type 'expression'
Error in as.vector(x, "expression") :
  cannot coerce type 'closure' to vector of type 'expression'
Error in array(0, c(length(.value), 2L), list(NULL, c("x001", "x002",  :
  length of 'dimnames' [2] not equal to array extent
Error in D(~log(x), "x") : Function '`~`' is not in the derivatives table
Error in D(interme, "x") : Function '`~`' is not in the derivatives table
Error in deriv.default(interme, "x") :
  Function '`~`' is not in the derivatives table
Error in D(expression(log(x, base = 3)), "x") :
  only single-argument calls are supported
Error in deriv.formula(~log(x, base = 3), "x") :
  only single-argument calls are supported
Error in deriv.default(expression(log(x, base = 3)), "x") :
  only single-argument calls are supported
Error in deriv3.default(expression(log(x, base = 3)), "x") :
  only single-argument calls are supported
Error in D(expression(abs(x)), "x") :
  Function 'abs' is not in the derivatives table
Error in deriv.formula(~abs(x), "x") :
  Function 'abs' is not in the derivatives table
Error in D(expression(sign(x)), "x") :
  Function 'sign' is not in the derivatives table
Error in deriv.formula(~sign(x), "x") :
  Function 'sign' is not in the derivatives table
sh: 1: yacas: not found
Quitting from lines 629-641 (nls14tutorial.Rmd)
Error: processing vignette 'nls14tutorial.Rmd' failed with diagnostics:
cannot open the connection
Execution halted

For reference:

john at john-J6-2015 ~/current/nls14work $ cat /etc/os-release
NAME="Ubuntu"
VERSION="14.04.2 LTS, Trusty Tahr"
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME="Ubuntu 14.04.2 LTS"
VERSION_ID="14.04"
HOME_URL="http://www.ubuntu.com/"
SUPPORT_URL="http://help.ubuntu.com/"
BUG_REPORT_URL="http://bugs.launchpad.net/ubuntu/"

john at john-J6-2015 ~/current/nls14work $ cat /etc/linuxmint/info
RELEASE=17.1
CODENAME=rebecca
EDITION="MATE 64-bit"
DESCRIPTION="Linux Mint 17.1 Rebecca"
DESKTOP=MATE
TOOLKIT=GTK
NEW_FEATURES_URL=http://www.linuxmint.com/rel_rebecca_mate_whatsnew.php
RELEASE_NOTES_URL=http://www.linuxmint.com/rel_rebecca_mate.php
USER_GUIDE_URL=help:linuxmint
GRUB_TITLE=Linux Mint 17.1 MATE 64-bit



john at john-J6-2015 ~/current/nls14work $ dpkg -l | grep -i pandoc
ii  libghc-pandoc-citeproc-data                 0.2-3build1
                            all          Pandoc support for Citation
Style Language - data files

ii  pandoc                                      1.12.2.1-1build2
                            amd64        general markup converter

ii  pandoc-citeproc                             0.2-3build1
                            amd64        Pandoc support for Citation
Style Language - tools

ii  pandoc-data                                 1.12.2.1-1build2
                            all          general markup converter - data
files

JN


On 15-03-12 10:21 AM, Prof Brian Ripley wrote:
> On 12/03/2015 13:51, Prof J C Nash (U30A) wrote:
>> Are other developers finding R 3.1.3 problematic because vignette
>> building requires pandoc 1.12.3, while Linux Mint 17 / Ubuntu 14.04 have
>> 1.12.2.1? R 3.1.2 seems to work fine.
> 
> R has no built-in support for non-Sweave vignettes, and there is no
> mention of pandoc in the R 3.1.3 sources except for the manual:
> 
> 'Complete checking of a package which contains a file @file{README.md}
> needs @command{pandoc} installed: see
> @uref{http://johnmacfarlane.net/@/pandoc/@/installing.html}.'
> 
> which is true (but is not done with R 3.1.3).
> 
> I suspect you are confusing an R update with an update of whatever
> packages you use to process your vignettes: package rmarkdown has a
> pandoc version requirement of
> 
> SystemRequirements: pandoc (>= 1.12.3) -
>


From dtenenba at fredhutch.org  Thu Mar 12 16:21:15 2015
From: dtenenba at fredhutch.org (Dan Tenenbaum)
Date: Thu, 12 Mar 2015 08:21:15 -0700 (PDT)
Subject: [Rd] Requirement for pandoc 1.12.3 in R 3.1.3
In-Reply-To: <5501AD9E.4090007@messier.ca>
Message-ID: <393541412.529282.1426173675674.JavaMail.root@fredhutch.org>



----- Original Message -----
> From: "John Nash" <profjcnash at gmail.com>
> To: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>, r-devel at r-project.org
> Sent: Thursday, March 12, 2015 8:15:42 AM
> Subject: Re: [Rd] Requirement for pandoc 1.12.3 in R 3.1.3
> 
> Thanks Brian.
> 
> Indeed, the vignette is in markdown form. When I updated my system to
> R 3.1.3 I ran update.packages() and this seems to have upset things
> (including R-studio processing of markdown files).
> 
> I tried removing rmarkdown and reverting to an older version so that
> my
> sessionInfo() is
> 
> Loading required package: rmarkdown
> > sessionInfo()
> R version 3.1.3 (2015-03-09)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 14.04.2 LTS
> 
> locale:
>  [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
>  [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
>  [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] rmarkdown_0.3.3
> 
> loaded via a namespace (and not attached):
> [1] digest_0.6.8    htmltools_0.2.6
> 
> I also made sure to remove all instances of rmarkdown before
> installing
> the older version.
> 
> However,
> 
> R CMD build nls14
> 
> still gives lots of errors (these are related to content in the
> vignette
> source and are, I believe, consequent on the warning about
> engine$weave). The warning still refers to the later version of
> pandoc
> which Ubuntu 14.04 repos don't yet have.
> 

You can always download the latest version of pandoc; it's available as a .deb file at https://github.com/jgm/pandoc/releases .

Dan


> My current guess is some mismatch in the software infrastructure.  I
> have another machine with R 3.1.2 and rmarkdown_0.3.3 that manages to
> build the package without complaint, but it would be good to get this
> sorted out. Pointers on where to look for a fix are welcome.
> 
>  R CMD build nls14
> * checking for file ?nls14/DESCRIPTION? ... OK
> * preparing ?nls14?:
> * checking DESCRIPTION meta-information ... OK
> * installing the package to build vignettes
> * creating vignettes ... ERROR
> Warning in engine$weave(file, quiet = quiet, encoding = enc) :
>   Pandoc (>= 1.12.3) and/or pandoc-citeproc is not available. Please
> install both.
> Error in fnDeriv(r1, "x") : Only single expressions allowed
> Error in as.vector(x, "expression") :
>   cannot coerce type 'closure' to vector of type 'expression'
> Error in as.vector(x, "expression") :
>   cannot coerce type 'closure' to vector of type 'expression'
> Error in array(0, c(length(.value), 2L), list(NULL, c("x001", "x002",
>  :
>   length of 'dimnames' [2] not equal to array extent
> Error in D(~log(x), "x") : Function '`~`' is not in the derivatives
> table
> Error in D(interme, "x") : Function '`~`' is not in the derivatives
> table
> Error in deriv.default(interme, "x") :
>   Function '`~`' is not in the derivatives table
> Error in D(expression(log(x, base = 3)), "x") :
>   only single-argument calls are supported
> Error in deriv.formula(~log(x, base = 3), "x") :
>   only single-argument calls are supported
> Error in deriv.default(expression(log(x, base = 3)), "x") :
>   only single-argument calls are supported
> Error in deriv3.default(expression(log(x, base = 3)), "x") :
>   only single-argument calls are supported
> Error in D(expression(abs(x)), "x") :
>   Function 'abs' is not in the derivatives table
> Error in deriv.formula(~abs(x), "x") :
>   Function 'abs' is not in the derivatives table
> Error in D(expression(sign(x)), "x") :
>   Function 'sign' is not in the derivatives table
> Error in deriv.formula(~sign(x), "x") :
>   Function 'sign' is not in the derivatives table
> sh: 1: yacas: not found
> Quitting from lines 629-641 (nls14tutorial.Rmd)
> Error: processing vignette 'nls14tutorial.Rmd' failed with
> diagnostics:
> cannot open the connection
> Execution halted
> 
> For reference:
> 
> john at john-J6-2015 ~/current/nls14work $ cat /etc/os-release
> NAME="Ubuntu"
> VERSION="14.04.2 LTS, Trusty Tahr"
> ID=ubuntu
> ID_LIKE=debian
> PRETTY_NAME="Ubuntu 14.04.2 LTS"
> VERSION_ID="14.04"
> HOME_URL="http://www.ubuntu.com/"
> SUPPORT_URL="http://help.ubuntu.com/"
> BUG_REPORT_URL="http://bugs.launchpad.net/ubuntu/"
> 
> john at john-J6-2015 ~/current/nls14work $ cat /etc/linuxmint/info
> RELEASE=17.1
> CODENAME=rebecca
> EDITION="MATE 64-bit"
> DESCRIPTION="Linux Mint 17.1 Rebecca"
> DESKTOP=MATE
> TOOLKIT=GTK
> NEW_FEATURES_URL=http://www.linuxmint.com/rel_rebecca_mate_whatsnew.php
> RELEASE_NOTES_URL=http://www.linuxmint.com/rel_rebecca_mate.php
> USER_GUIDE_URL=help:linuxmint
> GRUB_TITLE=Linux Mint 17.1 MATE 64-bit
> 
> 
> 
> john at john-J6-2015 ~/current/nls14work $ dpkg -l | grep -i pandoc
> ii  libghc-pandoc-citeproc-data                 0.2-3build1
>                             all          Pandoc support for Citation
> Style Language - data files
> 
> ii  pandoc                                      1.12.2.1-1build2
>                             amd64        general markup converter
> 
> ii  pandoc-citeproc                             0.2-3build1
>                             amd64        Pandoc support for Citation
> Style Language - tools
> 
> ii  pandoc-data                                 1.12.2.1-1build2
>                             all          general markup converter -
>                             data
> files
> 
> JN
> 
> 
> On 15-03-12 10:21 AM, Prof Brian Ripley wrote:
> > On 12/03/2015 13:51, Prof J C Nash (U30A) wrote:
> >> Are other developers finding R 3.1.3 problematic because vignette
> >> building requires pandoc 1.12.3, while Linux Mint 17 / Ubuntu
> >> 14.04 have
> >> 1.12.2.1? R 3.1.2 seems to work fine.
> > 
> > R has no built-in support for non-Sweave vignettes, and there is no
> > mention of pandoc in the R 3.1.3 sources except for the manual:
> > 
> > 'Complete checking of a package which contains a file
> > @file{README.md}
> > needs @command{pandoc} installed: see
> > @uref{http://johnmacfarlane.net/@/pandoc/@/installing.html}.'
> > 
> > which is true (but is not done with R 3.1.3).
> > 
> > I suspect you are confusing an R update with an update of whatever
> > packages you use to process your vignettes: package rmarkdown has a
> > pandoc version requirement of
> > 
> > SystemRequirements: pandoc (>= 1.12.3) -
> >
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From arilamstein at gmail.com  Thu Mar 12 16:41:52 2015
From: arilamstein at gmail.com (arilamstein at gmail.com)
Date: Thu, 12 Mar 2015 08:41:52 -0700
Subject: [Rd] Best way to handle dependency on non-CRAN package / large data
	package?
Message-ID: <CAEO2kuJzie8_eFi0RYA=V5rUk4DYQa6OeuR21XypUdanJXVSyw@mail.gmail.com>

I have just written a package called choroplethrZip
<https://github.com/arilamstein/choroplethrZip> which contains a shapefile
and metadata on US Zip codes. It is currently hosted on github, has a
tagged version number (v1.0.0) and passes R CMD check as verified by
Travis. My plan is to use this in the next version of my package choroplethr
<https://github.com/arilamstein/choroplethr>.

This is exactly what I have done in the past with other map/data packages
(notably choroplethrMaps <https://github.com/arilamstein/choroplethrMaps>
 and choroplethrAdmin1 <https://github.com/arilamstein/choroplethrAdmin1>),
and is the architecture that CRAN requested: large data in a separate
package, listing it in the 'Suggests', and putting code like this where
appropriate:

if (!requireNamespace("choroplethrAdmin1", quietly = TRUE)) {
  stop("Package choroplethrAdmin1 is needed for this function to work.
Please install it.", call. = FALSE)
}

The problem I now face is that choroplethrZip is too large to be hosted on
CRAN (~75MB), and I am unclear on the best way to manage this dependency.
Presumably I could just change the above message to say

Please install choropltherZip by typing:
    library(devtools)
    install_github('arilamstein/choroplethr at v1.0.0')

But I don't know if this is the best way to do this, or if there is
anything else to consider. I have never had to manage package dependencies
outside of CRAN, and have always thought of CRAN as being a "closed
ecosystem", where there were not any dependencies outside of CRAN.

Can anyone provide guidance on this?

Thanks.

Ari

	[[alternative HTML version deleted]]


From edd at debian.org  Thu Mar 12 17:22:00 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 12 Mar 2015 11:22:00 -0500
Subject: [Rd] Best way to handle dependency on non-CRAN package / large
	data	package?
In-Reply-To: <CAEO2kuJzie8_eFi0RYA=V5rUk4DYQa6OeuR21XypUdanJXVSyw@mail.gmail.com>
References: <CAEO2kuJzie8_eFi0RYA=V5rUk4DYQa6OeuR21XypUdanJXVSyw@mail.gmail.com>
Message-ID: <21761.48424.267182.677329@max.nulle.part>


On 12 March 2015 at 08:41, arilamstein at gmail.com wrote:
| But I don't know if this is the best way to do this, or if there is
| anything else to consider. I have never had to manage package dependencies
| outside of CRAN, and have always thought of CRAN as being a "closed
| ecosystem", where there were not any dependencies outside of CRAN.
| 
| Can anyone provide guidance on this?

drat can help with this problem. Have a look at 

     http://dirk.eddelbuettel.com/code/drat.html

as well as my blog and the GitHub repo of drat.

In a nutshell, it creates repositories you can access via update.packages()
and install.packages() as if they were CRAN or BioC.  It also uses GitHub to
automagically provide a repository server via the webserverd "embedded" in
each GitHub repo (and turned on as soon as you use the gh-pages branch).

Some package authors have turned to using drat to distribute packages (often
in addition to CRAN, you can also do it instead of CRAN given a constraint as
here).  One such package author and I are working on another short blog post
detailing just this.  If you want, I can send you an 'informal preview' as
yet another source of documentation.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From arilamstein at gmail.com  Thu Mar 12 17:40:47 2015
From: arilamstein at gmail.com (arilamstein at gmail.com)
Date: Thu, 12 Mar 2015 09:40:47 -0700
Subject: [Rd] Best way to handle dependency on non-CRAN package / large
 data package?
In-Reply-To: <21761.48424.267182.677329@max.nulle.part>
References: <CAEO2kuJzie8_eFi0RYA=V5rUk4DYQa6OeuR21XypUdanJXVSyw@mail.gmail.com>
	<21761.48424.267182.677329@max.nulle.part>
Message-ID: <CAEO2kuLw=dvWQz2hWWRPnZiayV=xaZu-eH4beG4AhfmT_-axcQ@mail.gmail.com>

Thanks Dirk. I'm looking at it now.

At first glance your documentation brings up a good limitation of simply
telling users to type "devtools::install_github()". Namely, what happens
when the census bureau updates their shapefiles, and I subsequently decide
to update the package? Or if I discover an error in the package and decide
to update it? The choroplethr package could have a dependency, and it's not
clear how to make that dependency explicit to the user.



On Thu, Mar 12, 2015 at 9:22 AM, Dirk Eddelbuettel <edd at debian.org> wrote:

>
> On 12 March 2015 at 08:41, arilamstein at gmail.com wrote:
> | But I don't know if this is the best way to do this, or if there is
> | anything else to consider. I have never had to manage package
> dependencies
> | outside of CRAN, and have always thought of CRAN as being a "closed
> | ecosystem", where there were not any dependencies outside of CRAN.
> |
> | Can anyone provide guidance on this?
>
> drat can help with this problem. Have a look at
>
>      http://dirk.eddelbuettel.com/code/drat.html
>
> as well as my blog and the GitHub repo of drat.
>
> In a nutshell, it creates repositories you can access via update.packages()
> and install.packages() as if they were CRAN or BioC.  It also uses GitHub
> to
> automagically provide a repository server via the webserverd "embedded" in
> each GitHub repo (and turned on as soon as you use the gh-pages branch).
>
> Some package authors have turned to using drat to distribute packages
> (often
> in addition to CRAN, you can also do it instead of CRAN given a constraint
> as
> here).  One such package author and I are working on another short blog
> post
> detailing just this.  If you want, I can send you an 'informal preview' as
> yet another source of documentation.
>
> Dirk
>
> --
> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>

	[[alternative HTML version deleted]]


From edd at debian.org  Thu Mar 12 17:58:28 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 12 Mar 2015 11:58:28 -0500
Subject: [Rd] Best way to handle dependency on non-CRAN package / large
 data package?
In-Reply-To: <CAEO2kuLw=dvWQz2hWWRPnZiayV=xaZu-eH4beG4AhfmT_-axcQ@mail.gmail.com>
References: <CAEO2kuJzie8_eFi0RYA=V5rUk4DYQa6OeuR21XypUdanJXVSyw@mail.gmail.com>
	<21761.48424.267182.677329@max.nulle.part>
	<CAEO2kuLw=dvWQz2hWWRPnZiayV=xaZu-eH4beG4AhfmT_-axcQ@mail.gmail.com>
Message-ID: <21761.50612.724681.741878@max.nulle.part>


On 12 March 2015 at 09:40, arilamstein at gmail.com wrote:
| Thanks Dirk. I'm looking at it now.?
| 
| At first glance your documentation brings up a good limitation of simply
| telling users to type "devtools::install_github()". Namely, what happens when
| the census bureau updates their shapefiles, and I subsequently decide to update
| the package? Or if I discover an error in the package and decide to update it?
| The choroplethr package could have a dependency, and it's not clear how to make
| that dependency explicit to the user.?

100% agree. 

In writing drat, and talking to R users about it, I surprisingly often find
many (advanced) R users who seem to not use update.packages() at all.

R itself has your problem solved by providing repositries. And drat makes
creating and filling repositories (the author side) vey easy -- and that we
also aid the user side as installation as well as regular updates fall back
onto standard R functions: install.packages(), update.packages().  And this
does not require any additinal or manual steps on the part of the users (once
drat:::add(...)  has been added to their startup files).

So for this example, you could add a versioned Depends: in the
shapefile-using package and update the drat repository with an updated
shapefile package.  Users of drat and update.packages() would get updates
automagically. 

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From nashjc at uottawa.ca  Thu Mar 12 18:09:42 2015
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Thu, 12 Mar 2015 13:09:42 -0400
Subject: [Rd] Requirement for pandoc 1.12.3 in R 3.1.3
In-Reply-To: <393541412.529282.1426173675674.JavaMail.root@fredhutch.org>
References: <393541412.529282.1426173675674.JavaMail.root@fredhutch.org>
Message-ID: <5501C856.4020707@uottawa.ca>

Dan's suggestion to get latest pandoc got me part of the way to a
workaround. The other part was removing references in the vignette to
alpha versions of some software.

For info: pandoc 1.13.2 seems to have some bugs for conversion of LaTeX
to html or epub still (or at least the error messages point to the wrong
place). However, these are in work I'm doing outside of R, and I'll
pursue them with the pandoc developer(s).

JN


On 15-03-12 11:21 AM, Dan Tenenbaum wrote:
> 
> 
> ----- Original Message -----
>> From: "John Nash" <profjcnash at gmail.com>
>> To: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>, r-devel at r-project.org
>> Sent: Thursday, March 12, 2015 8:15:42 AM
>> Subject: Re: [Rd] Requirement for pandoc 1.12.3 in R 3.1.3
>>
>> Thanks Brian.
>>
>> Indeed, the vignette is in markdown form. When I updated my system to
>> R 3.1.3 I ran update.packages() and this seems to have upset things
>> (including R-studio processing of markdown files).
>>
>> I tried removing rmarkdown and reverting to an older version so that
>> my
>> sessionInfo() is
>>
>> Loading required package: rmarkdown
>>> sessionInfo()
>> R version 3.1.3 (2015-03-09)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Ubuntu 14.04.2 LTS
>>
>> locale:
>>  [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
>>  [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
>>  [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
>>  [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C
>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] rmarkdown_0.3.3
>>
>> loaded via a namespace (and not attached):
>> [1] digest_0.6.8    htmltools_0.2.6
>>
>> I also made sure to remove all instances of rmarkdown before
>> installing
>> the older version.
>>
>> However,
>>
>> R CMD build nls14
>>
>> still gives lots of errors (these are related to content in the
>> vignette
>> source and are, I believe, consequent on the warning about
>> engine$weave). The warning still refers to the later version of
>> pandoc
>> which Ubuntu 14.04 repos don't yet have.
>>
> 
> You can always download the latest version of pandoc; it's available as a .deb file at https://github.com/jgm/pandoc/releases .
> 
> Dan
> 
> 
>> My current guess is some mismatch in the software infrastructure.  I
>> have another machine with R 3.1.2 and rmarkdown_0.3.3 that manages to
>> build the package without complaint, but it would be good to get this
>> sorted out. Pointers on where to look for a fix are welcome.
>>
>>  R CMD build nls14
>> * checking for file ?nls14/DESCRIPTION? ... OK
>> * preparing ?nls14?:
>> * checking DESCRIPTION meta-information ... OK
>> * installing the package to build vignettes
>> * creating vignettes ... ERROR
>> Warning in engine$weave(file, quiet = quiet, encoding = enc) :
>>   Pandoc (>= 1.12.3) and/or pandoc-citeproc is not available. Please
>> install both.
>> Error in fnDeriv(r1, "x") : Only single expressions allowed
>> Error in as.vector(x, "expression") :
>>   cannot coerce type 'closure' to vector of type 'expression'
>> Error in as.vector(x, "expression") :
>>   cannot coerce type 'closure' to vector of type 'expression'
>> Error in array(0, c(length(.value), 2L), list(NULL, c("x001", "x002",
>>  :
>>   length of 'dimnames' [2] not equal to array extent
>> Error in D(~log(x), "x") : Function '`~`' is not in the derivatives
>> table
>> Error in D(interme, "x") : Function '`~`' is not in the derivatives
>> table
>> Error in deriv.default(interme, "x") :
>>   Function '`~`' is not in the derivatives table
>> Error in D(expression(log(x, base = 3)), "x") :
>>   only single-argument calls are supported
>> Error in deriv.formula(~log(x, base = 3), "x") :
>>   only single-argument calls are supported
>> Error in deriv.default(expression(log(x, base = 3)), "x") :
>>   only single-argument calls are supported
>> Error in deriv3.default(expression(log(x, base = 3)), "x") :
>>   only single-argument calls are supported
>> Error in D(expression(abs(x)), "x") :
>>   Function 'abs' is not in the derivatives table
>> Error in deriv.formula(~abs(x), "x") :
>>   Function 'abs' is not in the derivatives table
>> Error in D(expression(sign(x)), "x") :
>>   Function 'sign' is not in the derivatives table
>> Error in deriv.formula(~sign(x), "x") :
>>   Function 'sign' is not in the derivatives table
>> sh: 1: yacas: not found
>> Quitting from lines 629-641 (nls14tutorial.Rmd)
>> Error: processing vignette 'nls14tutorial.Rmd' failed with
>> diagnostics:
>> cannot open the connection
>> Execution halted
>>
>> For reference:
>>
>> john at john-J6-2015 ~/current/nls14work $ cat /etc/os-release
>> NAME="Ubuntu"
>> VERSION="14.04.2 LTS, Trusty Tahr"
>> ID=ubuntu
>> ID_LIKE=debian
>> PRETTY_NAME="Ubuntu 14.04.2 LTS"
>> VERSION_ID="14.04"
>> HOME_URL="http://www.ubuntu.com/"
>> SUPPORT_URL="http://help.ubuntu.com/"
>> BUG_REPORT_URL="http://bugs.launchpad.net/ubuntu/"
>>
>> john at john-J6-2015 ~/current/nls14work $ cat /etc/linuxmint/info
>> RELEASE=17.1
>> CODENAME=rebecca
>> EDITION="MATE 64-bit"
>> DESCRIPTION="Linux Mint 17.1 Rebecca"
>> DESKTOP=MATE
>> TOOLKIT=GTK
>> NEW_FEATURES_URL=http://www.linuxmint.com/rel_rebecca_mate_whatsnew.php
>> RELEASE_NOTES_URL=http://www.linuxmint.com/rel_rebecca_mate.php
>> USER_GUIDE_URL=help:linuxmint
>> GRUB_TITLE=Linux Mint 17.1 MATE 64-bit
>>
>>
>>
>> john at john-J6-2015 ~/current/nls14work $ dpkg -l | grep -i pandoc
>> ii  libghc-pandoc-citeproc-data                 0.2-3build1
>>                             all          Pandoc support for Citation
>> Style Language - data files
>>
>> ii  pandoc                                      1.12.2.1-1build2
>>                             amd64        general markup converter
>>
>> ii  pandoc-citeproc                             0.2-3build1
>>                             amd64        Pandoc support for Citation
>> Style Language - tools
>>
>> ii  pandoc-data                                 1.12.2.1-1build2
>>                             all          general markup converter -
>>                             data
>> files
>>
>> JN
>>
>>
>> On 15-03-12 10:21 AM, Prof Brian Ripley wrote:
>>> On 12/03/2015 13:51, Prof J C Nash (U30A) wrote:
>>>> Are other developers finding R 3.1.3 problematic because vignette
>>>> building requires pandoc 1.12.3, while Linux Mint 17 / Ubuntu
>>>> 14.04 have
>>>> 1.12.2.1? R 3.1.2 seems to work fine.
>>>
>>> R has no built-in support for non-Sweave vignettes, and there is no
>>> mention of pandoc in the R 3.1.3 sources except for the manual:
>>>
>>> 'Complete checking of a package which contains a file
>>> @file{README.md}
>>> needs @command{pandoc} installed: see
>>> @uref{http://johnmacfarlane.net/@/pandoc/@/installing.html}.'
>>>
>>> which is true (but is not done with R 3.1.3).
>>>
>>> I suspect you are confusing an R update with an update of whatever
>>> packages you use to process your vignettes: package rmarkdown has a
>>> pandoc version requirement of
>>>
>>> SystemRequirements: pandoc (>= 1.12.3) -
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>


From murdoch.duncan at gmail.com  Thu Mar 12 18:17:23 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 12 Mar 2015 13:17:23 -0400
Subject: [Rd] Notes on building a gcc toolchain for Rtools (but not
	multilib)
In-Reply-To: <550099AC.8010309@gmail.com>
References: <2019630797.513208.1426100997515.JavaMail.root@fredhutch.org>
	<550099AC.8010309@gmail.com>
Message-ID: <5501CA23.2050000@gmail.com>

I've just uploaded a minor update (3.3.0.1957) to Rtools33, adding the 
cygpath.exe utility.  That utility converts between Windows style paths 
like D:/Rtools and Cygwin style paths like /cygdrive/d/Rtools.   It may 
be useful in configuration files if your external library expects to 
find gcc on the path, since Rtools no longer puts it there.  Assuming 
you want to use the Rtools toolchain, you can construct the path to the 
gcc directory in your Makevars.win file as

$(cygpath $(RTOOLS))gcc492_$(WIN)/bin

(where RTOOLS and WIN are macros from RHOME/etc/*/Makeconf that should 
already have been read.)

Thanks to JJ Allaire for the prompting on this.

Duncan Murdoch


From geoff.lee99 at gmail.com  Thu Mar 12 21:47:21 2015
From: geoff.lee99 at gmail.com (Geoff Lee)
Date: Fri, 13 Mar 2015 07:47:21 +1100
Subject: [Rd] Understanding why "no metadata object found ... not exported?"
	warnings from the methods package exist, and what they mean
Message-ID: <00b601d05d05$c0a73e70$41f5bb50$@gmail.com>

Hi

 

I am seeking to understand why the methods package (to be specific
`methods:::.findOrCopyClass` when called by `setIs` when called by
`setClass`) emits a warning message such as

 

` class "SpatialLinesNULL" is defined (with package slot 'rgeos') but no
metadata object found to revise subclass information---not exported?  Making
a copy in package 'minweSpatialNULL `

 

when I try to `R cmd build .` and then R cmd check *.gz` (or alternatively
`devtools::load_all()`) the package I am building.

 

What I don't really follow is why I am being warned when evidently the
methods package *can* actually find the metadata object in order to make a
copy of it (or does it just copy a name which binds to the original metadata
object - I'm not clear on that).  What is the danger I am being warned
about, and what, ideally should I do about it?  

 

In practice I know I can make the message go away by using
`importClassesFrom(rgeos,SpatialLinesNULL)` in my NAMESPACE file now that
Edzer Pebesma has arranged for a version of rgeos which exports
SpatialLinesNULL.  

 

But why do I need to explicitly import the superclass of the class I am
actually using?  If I were using a *function* from rgeos, which in turn
utilised a second non-exported function from rgeos, the package namespace
environments mechanism would take care of how to find and access that second
function, silently.  It wouldn't warn me about it and make me import it - in
fact avoiding that is as I understand it a major purpose of the packaging
namespace process.

 

There is obviously something I am missing, but having thought and read for
several days I am at a loss as to what.

 

Thanks heaps in advance for any illumination that you can offer me!

 

What I have done already.

 

I have a toy example in folder SpatialLinesNULL of branch SpatialLinesNULL
in a github repo at http://github.com/Geoff99/Examples/tree/SpatialLinesNULL

 

I have asked a (far too) long question on Stack Overflow (see
http://stackoverflow.com/questions/28871632/how-to-resolve-warning-messages-
metadata-object-not-found-spatiallinesnull-cla/29010169#29010169), the
specific aspect of which was very kindly and quickly answered by Edzer
Pebesma.

 

I have read the methods documentation ( which was very valuable indeed) and
have posted my understanding of what I learnt from that (and from stepping
through my toy example in the debugger) as a (once again quite long) answer
on Stack Overflow here

 

http://stackoverflow.com/questions/28871632/how-to-resolve-warning-messages-
metadata-object-not-found-spatiallinesnull-cla/29010169#29010169

 

PS If I should be asking this somewhere else, please just say.

 

PPS The primary purpose of the package I am building (not the toy example)
is to help me learn about programming and packaging in R, hence my desire to
chase down and understand this warning fully.


	[[alternative HTML version deleted]]


From arilamstein at gmail.com  Thu Mar 12 22:29:04 2015
From: arilamstein at gmail.com (arilamstein at gmail.com)
Date: Thu, 12 Mar 2015 14:29:04 -0700
Subject: [Rd] Best way to handle dependency on non-CRAN package / large
 data package?
In-Reply-To: <21761.50612.724681.741878@max.nulle.part>
References: <CAEO2kuJzie8_eFi0RYA=V5rUk4DYQa6OeuR21XypUdanJXVSyw@mail.gmail.com>
	<21761.48424.267182.677329@max.nulle.part>
	<CAEO2kuLw=dvWQz2hWWRPnZiayV=xaZu-eH4beG4AhfmT_-axcQ@mail.gmail.com>
	<21761.50612.724681.741878@max.nulle.part>
Message-ID: <CAEO2kuKjxWoJE+Rn7JBu1tp7BiAeDiLTAro2SrtonMPfsdCDww@mail.gmail.com>

Hi Dirk,

I'm interested in pursing this but I haven't been able to figure how to to
make it work.  Here's what I have so far:

install.packages("drat")
library(drat)
addRepo("arilamstein")

I (obviously) have a copy of the choroplethrZip github repo locally. I
typed:

git checkout gh-pages
git push

I gather that this is what I needed to to do make the repo web-accessible.
Although I found this step a bit confusing because it looks like github has
a pages feature for both accounts and projects.

And now the instructions say to type something like:

> insertPackage("~/Desktop/choroplethrZip_1.0.0.tar.gz")
Error in insertPackage("~/Desktop/choroplethrZip_1.0.0.tar.gz") :
  Directory ~/git/drat not found
FALSE

The file I provided is what was created by calling devtools::build() on my
R package that I want to distribute.

Can you explain this error message to me and tell me what I'm doing wrong?
I've read several of the documents on drat but am unclear on whether I need
modify my existing repository in any way in order to make it work with drat.

Thanks.

Ari

On Thu, Mar 12, 2015 at 9:58 AM, Dirk Eddelbuettel <edd at debian.org> wrote:

>
> On 12 March 2015 at 09:40, arilamstein at gmail.com wrote:
> | Thanks Dirk. I'm looking at it now.
> |
> | At first glance your documentation brings up a good limitation of simply
> | telling users to type "devtools::install_github()". Namely, what happens
> when
> | the census bureau updates their shapefiles, and I subsequently decide to
> update
> | the package? Or if I discover an error in the package and decide to
> update it?
> | The choroplethr package could have a dependency, and it's not clear how
> to make
> | that dependency explicit to the user.
>
> 100% agree.
>
> In writing drat, and talking to R users about it, I surprisingly often find
> many (advanced) R users who seem to not use update.packages() at all.
>
> R itself has your problem solved by providing repositries. And drat makes
> creating and filling repositories (the author side) vey easy -- and that we
> also aid the user side as installation as well as regular updates fall back
> onto standard R functions: install.packages(), update.packages().  And this
> does not require any additinal or manual steps on the part of the users
> (once
> drat:::add(...)  has been added to their startup files).
>
> So for this example, you could add a versioned Depends: in the
> shapefile-using package and update the drat repository with an updated
> shapefile package.  Users of drat and update.packages() would get updates
> automagically.
>
> Dirk
>
> --
> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>

	[[alternative HTML version deleted]]


From dtenenba at fredhutch.org  Thu Mar 12 22:40:38 2015
From: dtenenba at fredhutch.org (Dan Tenenbaum)
Date: Thu, 12 Mar 2015 14:40:38 -0700 (PDT)
Subject: [Rd] Notes on building a gcc toolchain for Rtools (but
	not	multilib)
In-Reply-To: <5501CA23.2050000@gmail.com>
Message-ID: <935890228.539806.1426196438165.JavaMail.root@fredhutch.org>



----- Original Message -----
> From: "Duncan Murdoch" <murdoch.duncan at gmail.com>
> Cc: r-devel at r-project.org
> Sent: Thursday, March 12, 2015 10:17:23 AM
> Subject: Re: [Rd] Notes on building a gcc toolchain for Rtools (but not	multilib)
> 
> I've just uploaded a minor update (3.3.0.1957) to Rtools33, adding
> the
> cygpath.exe utility.  That utility converts between Windows style
> paths
> like D:/Rtools and Cygwin style paths like /cygdrive/d/Rtools.   It
> may
> be useful in configuration files if your external library expects to
> find gcc on the path, since Rtools no longer puts it there.  Assuming
> you want to use the Rtools toolchain, you can construct the path to
> the
> gcc directory in your Makevars.win file as
> 
> $(cygpath $(RTOOLS))gcc492_$(WIN)/bin
> 
> (where RTOOLS and WIN are macros from RHOME/etc/*/Makeconf that
> should
> already have been read.)
> 

I had some problems with this. In the Bioconductor package zlibbioc, for example (which wraps zlib) there is a lower-level "Makefile.gcc" inside src/zlib-1.2.5/win32 which contains:

PREFIX =
ifeq "$(WIN)" "64"
CC = $(PREFIX)gcc -m64
else
CC = $(PREFIX)gcc -m32
endif


First of all, even though I have cygpath installed, using it as you suggest does not work, and does not seem to be necessary. Secondly, although $(WIN) is visible to the ifeq statement, it can't be expanded, that is to say, changing PREFIX to 

PREFIX = "$(RTOOLS)gcc492_$(WIN)/bin/"

doesn't work, and the error shows that gcc is being looked for in a path that ends with gcc492_/bin/ , in other words, the $(WIN) does not expand. However, changing to this:

ifeq "$(WIN)" "64"
PREFIX = "$(RTOOLS)gcc492_64/bin/"
CC = $(PREFIX)gcc -m64
else
PREFIX = "$(RTOOLS)gcc492_32/bin/"
CC = $(PREFIX)gcc -m32
endif

Works just fine. It's odd that the value of $(WIN) can be "seen" in order to correctly execute
the "ifeq", but it can't be expanded.

There are a number of fairly important packages in Bioconductor (and in CRAN too I imagine) that wrap C/C++ libraries and they all probably need some tweaking like this. I'm a little concerned that it's not such good practice to change third party code in this way, it makes maintenance just a little harder. It would be nice if maintainers could just add the latest version of the library to their packages without changing anything. But if making these changes is the only option, then so be it.

Dan



> Thanks to JJ Allaire for the prompting on this.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From mick.jordan at oracle.com  Thu Mar 12 22:55:05 2015
From: mick.jordan at oracle.com (Mick Jordan)
Date: Thu, 12 Mar 2015 14:55:05 -0700
Subject: [Rd] How do you debug the R implementation?
Message-ID: <55020B39.2030005@oracle.com>

This is a question for the folks who are developing the C part of the R 
implementation, and not about R debugging.

I'm curious what tools developers use to debug the C implementation on 
Mac OS and Linux (my two platforms). And, if you happen to use gdb, 
whether anyone has any macros to simplify seeing inside the R internal 
data structures.

Thanks
Mick Jordan


From edd at debian.org  Thu Mar 12 22:57:27 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 12 Mar 2015 16:57:27 -0500
Subject: [Rd] Best way to handle dependency on non-CRAN package / large
 data package?
In-Reply-To: <CAEO2kuKjxWoJE+Rn7JBu1tp7BiAeDiLTAro2SrtonMPfsdCDww@mail.gmail.com>
References: <CAEO2kuJzie8_eFi0RYA=V5rUk4DYQa6OeuR21XypUdanJXVSyw@mail.gmail.com>
	<21761.48424.267182.677329@max.nulle.part>
	<CAEO2kuLw=dvWQz2hWWRPnZiayV=xaZu-eH4beG4AhfmT_-axcQ@mail.gmail.com>
	<21761.50612.724681.741878@max.nulle.part>
	<CAEO2kuKjxWoJE+Rn7JBu1tp7BiAeDiLTAro2SrtonMPfsdCDww@mail.gmail.com>
Message-ID: <21762.3015.541053.277194@max.nulle.part>


Ari,

On 12 March 2015 at 14:29, arilamstein at gmail.com wrote:
| I'm interested in pursing this but I haven't been able to figure how to to make
| it work.? Here's what I have so far:
| 
| install.packages("drat")
| library(drat)
| addRepo("arilamstein")
| 
| I (obviously) have a copy of the choroplethrZip github repo locally. I typed:
| 
| git checkout gh-pages
| git push

Drat makes one simple assumption (in the one / default argument case): that
the repo is called  'drat'  within gh repo of the given user. Ie using
addRepo("arilamstein")  requires that   ttps://github.com/arilamstin/drat/ 
exists and has a gh-pages branch. Drat would not know about  choroplethrZip

Which is why the docs say 'easiest to just fork the drat repo'. That give you
arilmastein/drat and gh-pages in one swoop.

In the expanded form you can give any (http or file) URL, that is was use at
work for files shared via the local network. 

Please try this, and if you need more follow-up we may want to move off-list
now.  You have a pretty good use case so I want to help you with this.

Dirk 

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From csardi.gabor at gmail.com  Fri Mar 13 02:04:42 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Thu, 12 Mar 2015 21:04:42 -0400
Subject: [Rd] How do you debug the R implementation?
In-Reply-To: <55020B39.2030005@oracle.com>
References: <55020B39.2030005@oracle.com>
Message-ID: <CABtg=Km1yjbu_=D=88VCoSs+dmnwAwV_AW7d6+k23E6BxsZAwg@mail.gmail.com>

On OSX I suggest using lldb instead of gdb, it works better with the
toolchain. If you want C level profiling, try Instruments, it is part of
xcode.

See also
http://cran.r-project.org/doc/manuals/r-devel/R-exts.html#Debugging-compiled-code

Gabor


On Thu, Mar 12, 2015 at 5:55 PM, Mick Jordan <mick.jordan at oracle.com> wrote:

> This is a question for the folks who are developing the C part of the R
> implementation, and not about R debugging.
>
> I'm curious what tools developers use to debug the C implementation on Mac
> OS and Linux (my two platforms). And, if you happen to use gdb, whether
> anyone has any macros to simplify seeing inside the R internal data
> structures.
>
> Thanks
> Mick Jordan
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From avraham.adler at gmail.com  Fri Mar 13 04:15:23 2015
From: avraham.adler at gmail.com (Avraham Adler)
Date: Thu, 12 Mar 2015 23:15:23 -0400
Subject: [Rd] Rtools version 3.3.0.1957 looking for C even though RTOOLS
 variable is pointing elsewhere
Message-ID: <CAL6gwnJimpo=K=DozCmPVbXdn5pQdhUQWVLfjm8LHTwRcOVSrw@mail.gmail.com>

Good evening.

Testing the most recent version of Rtools, the build stops about when
text.c is being compiled in the tools package (just after R.Lapack). The
compilation is looking for gcc in C:, even though RTOOLS is set for another
drive, and the compilation has successfully run until this point. This did
not happen last night with version 1955.

I've uninstalled and reinstalled Rtools three times, I have
F:/R/Rtools/gcc492_64/bin as the first entry in my path, and I do not have
a Makevars file in my user directory that could possibly override it, so I
am at a loss as to why this happening. The specific error is brought below.

Thank you,

Avi


F:/R/Rtools/gcc492_64/bin/windres    -i dllversion.rc -o dllversion.o
F:/R/Rtools/gcc492_64/bin/gcc -std=gnu99  -shared -s  -o lapack.dll
lapack.def Lapack.o dllversion.o
 -L../../../bin/x64 -lRlapack -lRblas -lR
cp lapack.dll ../../../modules/x64/lapack.dll
building package 'base'
building package 'tools'
making text.d from text.c
C:/Rtools/gcc492_64/bin/gcc: not found
make[4]: *** [text.d] Error 127
make[3]: *** [mksrc-win2] Error 1
make[2]: *** [all] Error 2
make[1]: *** [R] Error 1
make: *** [all] Error 2

	[[alternative HTML version deleted]]


From avraham.adler at gmail.com  Fri Mar 13 04:46:30 2015
From: avraham.adler at gmail.com (Avraham Adler)
Date: Thu, 12 Mar 2015 23:46:30 -0400
Subject: [Rd] Rtools version 3.3.0.1957 looking for C even though RTOOLS
 variable is pointing elsewhere
In-Reply-To: <CAL6gwnJimpo=K=DozCmPVbXdn5pQdhUQWVLfjm8LHTwRcOVSrw@mail.gmail.com>
References: <CAL6gwnJimpo=K=DozCmPVbXdn5pQdhUQWVLfjm8LHTwRcOVSrw@mail.gmail.com>
Message-ID: <CAL6gwnL67jfGQxPthBSeE-aORG_23f3yA=cL5idE-bpp_o7_CA@mail.gmail.com>

The subject line is in error, as the issue must be in "R-devel.tar.gz"
as running the same Rtools on last night's download of
R-devel_2015-03-09.tar.gz successfully navigates that error.

The error exists in R-devel_2015-03-12.tar.gz and
R-devel_2015-03-12.tar.gz and R-devel_2015-03-10.tar.gz, but not
R-devel_2015-03-09.tar.gz, so it must have been something between 09
and 10.

Avi

On Thu, Mar 12, 2015 at 11:15 PM, Avraham Adler <avraham.adler at gmail.com> wrote:
> Good evening.
>
> Testing the most recent version of Rtools, the build stops about when text.c
> is being compiled in the tools package (just after R.Lapack). The
> compilation is looking for gcc in C:, even though RTOOLS is set for another
> drive, and the compilation has successfully run until this point. This did
> not happen last night with version 1955.
>
> I've uninstalled and reinstalled Rtools three times, I have
> F:/R/Rtools/gcc492_64/bin as the first entry in my path, and I do not have a
> Makevars file in my user directory that could possibly override it, so I am
> at a loss as to why this happening. The specific error is brought below.
>
> Thank you,
>
> Avi
>
>
> F:/R/Rtools/gcc492_64/bin/windres    -i dllversion.rc -o dllversion.o
> F:/R/Rtools/gcc492_64/bin/gcc -std=gnu99  -shared -s  -o lapack.dll
> lapack.def Lapack.o dllversion.o
>  -L../../../bin/x64 -lRlapack -lRblas -lR
> cp lapack.dll ../../../modules/x64/lapack.dll
> building package 'base'
> building package 'tools'
> making text.d from text.c
> C:/Rtools/gcc492_64/bin/gcc: not found
> make[4]: *** [text.d] Error 127
> make[3]: *** [mksrc-win2] Error 1
> make[2]: *** [all] Error 2
> make[1]: *** [R] Error 1
> make: *** [all] Error 2


From avraham.adler at gmail.com  Fri Mar 13 05:03:43 2015
From: avraham.adler at gmail.com (Avraham Adler)
Date: Fri, 13 Mar 2015 00:03:43 -0400
Subject: [Rd] Rtools version 3.3.0.1957 looking for C even though RTOOLS
 variable is pointing elsewhere
In-Reply-To: <CAL6gwnL67jfGQxPthBSeE-aORG_23f3yA=cL5idE-bpp_o7_CA@mail.gmail.com>
References: <CAL6gwnJimpo=K=DozCmPVbXdn5pQdhUQWVLfjm8LHTwRcOVSrw@mail.gmail.com>
	<CAL6gwnL67jfGQxPthBSeE-aORG_23f3yA=cL5idE-bpp_o7_CA@mail.gmail.com>
Message-ID: <CAL6gwnJ+fK4K9NUOGxYEQY_paBohZHpDFFr6SS=_7b0u356bhw@mail.gmail.com>

The following changes may be responsible:

src\gnuwin32\fixed\Makefile lines 31 and 47 where version 9 has '-e
"s|BINPREF =|BINPREF = $(BINPREF)|" \' and version 10 has '-e
's|BINPREF =|BINPREF ?= $$(RTOOLS)gcc492_64/bin/|' \'.

Or, it may have been the addition of "RTOOLS ?= C:/Rtools/" on line 17
of src\gnuwin32\fixed\etc\Makeconf in version 10.

There are 31 other files with differences, but they do not seem to have bearing.

Thank you,

Avi


From avraham.adler at gmail.com  Fri Mar 13 05:14:59 2015
From: avraham.adler at gmail.com (Avraham Adler)
Date: Fri, 13 Mar 2015 00:14:59 -0400
Subject: [Rd] Rtools version 3.3.0.1957 looking for C even though RTOOLS
 variable is pointing elsewhere
In-Reply-To: <CAL6gwnJ+fK4K9NUOGxYEQY_paBohZHpDFFr6SS=_7b0u356bhw@mail.gmail.com>
References: <CAL6gwnJimpo=K=DozCmPVbXdn5pQdhUQWVLfjm8LHTwRcOVSrw@mail.gmail.com>
	<CAL6gwnL67jfGQxPthBSeE-aORG_23f3yA=cL5idE-bpp_o7_CA@mail.gmail.com>
	<CAL6gwnJ+fK4K9NUOGxYEQY_paBohZHpDFFr6SS=_7b0u356bhw@mail.gmail.com>
Message-ID: <CAL6gwnKKgPf+cvNLp103RVRHzi-5kJ4c1UmV8WoeNHv+frLvHA@mail.gmail.com>

Removing the extra '$' from $$(RTOOLS) solves the issue.

Thank you,

Avi


From jmc at r-project.org  Fri Mar 13 17:32:24 2015
From: jmc at r-project.org (John Chambers)
Date: Fri, 13 Mar 2015 09:32:24 -0700
Subject: [Rd] Understanding why "no metadata object found ... not
	exported?" warnings from the methods package exist,
	and what they mean
In-Reply-To: <00b601d05d05$c0a73e70$41f5bb50$@gmail.com>
References: <00b601d05d05$c0a73e70$41f5bb50$@gmail.com>
Message-ID: <92B48CD5-B19F-4DBE-ACFF-A61DC207F04D@r-project.org>

This warning message is on my to-look-at list; I agree that sometimes it's obviously possible for the system to get the information if it tries hard enough.

The message means what it says:  Class information in a session includes the currently loaded subclasses of a particular class.  Not critical but sometimes useful.

In this case, (as I understand it without having looked recently), the issue is that the "rgeos" namespace has not been loaded, although a subclass of a class in that package has.  

So, should that namespace be loaded, to access (presumably) the class object?  Or the copy made silently somewhere?  It's probably true that the warning is not being seen by the owner of the package that could fix the problem.

John



On Mar 12, 2015, at 1:47 PM, Geoff Lee <geoff.lee99 at gmail.com> wrote:

> Hi
> 
> 
> 
> I am seeking to understand why the methods package (to be specific
> `methods:::.findOrCopyClass` when called by `setIs` when called by
> `setClass`) emits a warning message such as
> 
> 
> 
> ` class "SpatialLinesNULL" is defined (with package slot 'rgeos') but no
> metadata object found to revise subclass information---not exported?  Making
> a copy in package 'minweSpatialNULL `
> 
> 
> 
> when I try to `R cmd build .` and then R cmd check *.gz` (or alternatively
> `devtools::load_all()`) the package I am building.
> 
> 
> 
> What I don't really follow is why I am being warned when evidently the
> methods package *can* actually find the metadata object in order to make a
> copy of it (or does it just copy a name which binds to the original metadata
> object - I'm not clear on that).  What is the danger I am being warned
> about, and what, ideally should I do about it?  
> 
> 
> 
> In practice I know I can make the message go away by using
> `importClassesFrom(rgeos,SpatialLinesNULL)` in my NAMESPACE file now that
> Edzer Pebesma has arranged for a version of rgeos which exports
> SpatialLinesNULL.  
> 
> 
> 
> But why do I need to explicitly import the superclass of the class I am
> actually using?  If I were using a *function* from rgeos, which in turn
> utilised a second non-exported function from rgeos, the package namespace
> environments mechanism would take care of how to find and access that second
> function, silently.  It wouldn't warn me about it and make me import it - in
> fact avoiding that is as I understand it a major purpose of the packaging
> namespace process.
> 
> 
> 
> There is obviously something I am missing, but having thought and read for
> several days I am at a loss as to what.
> 
> 
> 
> Thanks heaps in advance for any illumination that you can offer me!
> 
> 
> 
> What I have done already.
> 
> 
> 
> I have a toy example in folder SpatialLinesNULL of branch SpatialLinesNULL
> in a github repo at http://github.com/Geoff99/Examples/tree/SpatialLinesNULL
> 
> 
> 
> I have asked a (far too) long question on Stack Overflow (see
> http://stackoverflow.com/questions/28871632/how-to-resolve-warning-messages-
> metadata-object-not-found-spatiallinesnull-cla/29010169#29010169), the
> specific aspect of which was very kindly and quickly answered by Edzer
> Pebesma.
> 
> 
> 
> I have read the methods documentation ( which was very valuable indeed) and
> have posted my understanding of what I learnt from that (and from stepping
> through my toy example in the debugger) as a (once again quite long) answer
> on Stack Overflow here
> 
> 
> 
> http://stackoverflow.com/questions/28871632/how-to-resolve-warning-messages-
> metadata-object-not-found-spatiallinesnull-cla/29010169#29010169
> 
> 
> 
> PS If I should be asking this somewhere else, please just say.
> 
> 
> 
> PPS The primary purpose of the package I am building (not the toy example)
> is to help me learn about programming and packaging in R, hence my desire to
> chase down and understand this warning fully.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jmc at r-project.org  Fri Mar 13 22:11:12 2015
From: jmc at r-project.org (John Chambers)
Date: Fri, 13 Mar 2015 14:11:12 -0700
Subject: [Rd] Understanding why "no metadata object found ... not
	exported?" warnings from the methods package exist,
	and what they mean
In-Reply-To: <92B48CD5-B19F-4DBE-ACFF-A61DC207F04D@r-project.org>
References: <00b601d05d05$c0a73e70$41f5bb50$@gmail.com>
	<92B48CD5-B19F-4DBE-ACFF-A61DC207F04D@r-project.org>
Message-ID: <917F33A9-64D7-47AF-B48A-C6C83BD5638A@r-project.org>

On looking more closely, the purpose of finding the class definition is to update the entry for the new relationship, as the warning message suggests.  That requires that the namespace holding the definition be writable.

In the case of subclass information, the original namespace is very likely to be locked, if it's not the package currently being loaded.  Copying the definition in order to update subclass information seems the only reasonable choice, and no warning message is needed.

A revised version will omit this message.

On Mar 13, 2015, at 9:32 AM, John Chambers <jmc at r-project.org> wrote:

> This warning message is on my to-look-at list; I agree that sometimes it's obviously possible for the system to get the information if it tries hard enough.
> 
> The message means what it says:  Class information in a session includes the currently loaded subclasses of a particular class.  Not critical but sometimes useful.
> 
> In this case, (as I understand it without having looked recently), the issue is that the "rgeos" namespace has not been loaded, although a subclass of a class in that package has.  
> 
> So, should that namespace be loaded, to access (presumably) the class object?  Or the copy made silently somewhere?  It's probably true that the warning is not being seen by the owner of the package that could fix the problem.
> 
> John
> 
> 
> 
> On Mar 12, 2015, at 1:47 PM, Geoff Lee <geoff.lee99 at gmail.com> wrote:
> 
>> Hi
>> 
>> 
>> 
>> I am seeking to understand why the methods package (to be specific
>> `methods:::.findOrCopyClass` when called by `setIs` when called by
>> `setClass`) emits a warning message such as
>> 
>> 
>> 
>> ` class "SpatialLinesNULL" is defined (with package slot 'rgeos') but no
>> metadata object found to revise subclass information---not exported?  Making
>> a copy in package 'minweSpatialNULL `
>> 
>> 
>> 
>> when I try to `R cmd build .` and then R cmd check *.gz` (or alternatively
>> `devtools::load_all()`) the package I am building.
>> 
>> 
>> 
>> What I don't really follow is why I am being warned when evidently the
>> methods package *can* actually find the metadata object in order to make a
>> copy of it (or does it just copy a name which binds to the original metadata
>> object - I'm not clear on that).  What is the danger I am being warned
>> about, and what, ideally should I do about it?  
>> 
>> 
>> 
>> In practice I know I can make the message go away by using
>> `importClassesFrom(rgeos,SpatialLinesNULL)` in my NAMESPACE file now that
>> Edzer Pebesma has arranged for a version of rgeos which exports
>> SpatialLinesNULL.  
>> 
>> 
>> 
>> But why do I need to explicitly import the superclass of the class I am
>> actually using?  If I were using a *function* from rgeos, which in turn
>> utilised a second non-exported function from rgeos, the package namespace
>> environments mechanism would take care of how to find and access that second
>> function, silently.  It wouldn't warn me about it and make me import it - in
>> fact avoiding that is as I understand it a major purpose of the packaging
>> namespace process.
>> 
>> 
>> 
>> There is obviously something I am missing, but having thought and read for
>> several days I am at a loss as to what.
>> 
>> 
>> 
>> Thanks heaps in advance for any illumination that you can offer me!
>> 
>> 
>> 
>> What I have done already.
>> 
>> 
>> 
>> I have a toy example in folder SpatialLinesNULL of branch SpatialLinesNULL
>> in a github repo at http://github.com/Geoff99/Examples/tree/SpatialLinesNULL
>> 
>> 
>> 
>> I have asked a (far too) long question on Stack Overflow (see
>> http://stackoverflow.com/questions/28871632/how-to-resolve-warning-messages-
>> metadata-object-not-found-spatiallinesnull-cla/29010169#29010169), the
>> specific aspect of which was very kindly and quickly answered by Edzer
>> Pebesma.
>> 
>> 
>> 
>> I have read the methods documentation ( which was very valuable indeed) and
>> have posted my understanding of what I learnt from that (and from stepping
>> through my toy example in the debugger) as a (once again quite long) answer
>> on Stack Overflow here
>> 
>> 
>> 
>> http://stackoverflow.com/questions/28871632/how-to-resolve-warning-messages-
>> metadata-object-not-found-spatiallinesnull-cla/29010169#29010169
>> 
>> 
>> 
>> PS If I should be asking this somewhere else, please just say.
>> 
>> 
>> 
>> PPS The primary purpose of the package I am building (not the toy example)
>> is to help me learn about programming and packaging in R, hence my desire to
>> chase down and understand this warning fully.
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From geoff.lee99 at gmail.com  Fri Mar 13 23:30:21 2015
From: geoff.lee99 at gmail.com (Geoff Lee)
Date: Sat, 14 Mar 2015 09:30:21 +1100
Subject: [Rd] Understanding why "no metadata object found ... not
	exported?" warnings from the methods package exist,
	and what they mean
In-Reply-To: <917F33A9-64D7-47AF-B48A-C6C83BD5638A@r-project.org>
References: <00b601d05d05$c0a73e70$41f5bb50$@gmail.com>
	<92B48CD5-B19F-4DBE-ACFF-A61DC207F04D@r-project.org>
	<917F33A9-64D7-47AF-B48A-C6C83BD5638A@r-project.org>
Message-ID: <00bb01d05ddd$4e1810e0$ea4832a0$@gmail.com>

Very many thanks indeed John for taking the time to look into this so
closely and respond to me twice.

I am hovering on the edge of understanding what was / is confusing me, and
will read both your replies very closely.

I think my conceptual problem relates to the difference between what happens
to the *name* of an object (eg a function or a class (to be precise, a
function object or a class metadata object)) and what happens to the
*object* itself. Or in other terms, whether a namespace (possibly locked)
needs to be updated, or the (state of the) object itself is what needs to be
updated.  I'll try and explain below.

If `mypkg` want to use a function called `other_fun` from package `otherpkg`
all I have to do is import the *name* of `other_fun` into the `mypkg`
namespace.

After that all the magic of making sure that the other_fun *object* works
and can find everything it needs is taken care of for me.  The other_fun
object knows the enclosing environment where it was created and finds any
information it needs about additional functions etc, that may or may not
have been exported by package otherpkg behind the scenes.

My reasoning was that the same should apply to the *names* of classes as
well.

If `mypkg` wanted to use a class called `OtherClass` from package `otherpkg`
all it would need to do was import the *name* of `OtherClass` into the
`mypkg` namespace.

After that the `OtherClass` (metadata) object would know where it came from
and look after itself.  In particular, if the operation of the OtherClass
(metadata) object involved any superclasses (or later on, subclasses), the
manipulations required would occur at the object level, not at the *name*
level.  I can see why it is necessary to update the metadata object itself,
because functions like `setIs` and `setClassUnion` allow the upstream
parentage of a class to be altered post hoc in ways which depend upon what
else is loaded, and a class must be able to find that type of information if
inheritance is going to work.

But at the moment it seems that it is necessary to import the *name* of the
superclass(es) into the `mypkg` namespace as well, and that is what I can't
fully follow.

I do confess that I get quite lost when I try and follow my logic chain
through to the implementation level for class metadata objects.

I have got as far as understanding that the *name* of a metadata object is
mangled and hidden (I think the real *name* of `OtherClass` is usually
`.__C__OtherClass` ).  And that the metadata objects themselves need to be
able to maintain and manage any superclass and subclass relationships as
they evolve.  But when I get to trying to figure out how on earth the
various metadata objects would avoid the garbage collector, and cope with
unevaluated expressions, promises, pass by copying etc I am (well) over the
boundaries of my understanding.

Thinking as I type, if the current warning message is telling me that I am
getting a copy of the superclass metadata object, rather than a copied name
which points to the original metadata object itself, I can begin to see why
that would be a worry.

Mmmm, more for me to think about.

Once again, many many thanks for helping me work my way towards
understanding this

Geoff

-----Original Message-----
From: John Chambers [mailto:jmc at r-project.org] 
Sent: Saturday, 14 March 2015 8:11 AM
To: Geoff Lee
Cc: r-devel at r-project.org
Subject: Re: [Rd] Understanding why "no metadata object found ... not
exported?" warnings from the methods package exist, and what they mean

On looking more closely, the purpose of finding the class definition is to
update the entry for the new relationship, as the warning message suggests.
That requires that the namespace holding the definition be writable.

In the case of subclass information, the original namespace is very likely
to be locked, if it's not the package currently being loaded.  Copying the
definition in order to update subclass information seems the only reasonable
choice, and no warning message is needed.

A revised version will omit this message.

On Mar 13, 2015, at 9:32 AM, John Chambers <jmc at r-project.org> wrote:

> This warning message is on my to-look-at list; I agree that sometimes it's
obviously possible for the system to get the information if it tries hard
enough.
> 
> The message means what it says:  Class information in a session includes
the currently loaded subclasses of a particular class.  Not critical but
sometimes useful.
> 
> In this case, (as I understand it without having looked recently), the
issue is that the "rgeos" namespace has not been loaded, although a subclass
of a class in that package has.  
> 
> So, should that namespace be loaded, to access (presumably) the class
object?  Or the copy made silently somewhere?  It's probably true that the
warning is not being seen by the owner of the package that could fix the
problem.
> 
> John
> 
> 
> 
> On Mar 12, 2015, at 1:47 PM, Geoff Lee <geoff.lee99 at gmail.com> wrote:
> 
>> Hi
>> 
>> 
>> 
>> I am seeking to understand why the methods package (to be specific 
>> `methods:::.findOrCopyClass` when called by `setIs` when called by
>> `setClass`) emits a warning message such as
>> 
>> 
>> 
>> ` class "SpatialLinesNULL" is defined (with package slot 'rgeos') but 
>> no metadata object found to revise subclass information---not 
>> exported?  Making a copy in package 'minweSpatialNULL `
>> 
>> 
>> 
>> when I try to `R cmd build .` and then R cmd check *.gz` (or 
>> alternatively
>> `devtools::load_all()`) the package I am building.
>> 
>> 
>> 
>> What I don't really follow is why I am being warned when evidently 
>> the methods package *can* actually find the metadata object in order 
>> to make a copy of it (or does it just copy a name which binds to the 
>> original metadata object - I'm not clear on that).  What is the 
>> danger I am being warned about, and what, ideally should I do about it?
>> 
>> 
>> 
>> In practice I know I can make the message go away by using 
>> `importClassesFrom(rgeos,SpatialLinesNULL)` in my NAMESPACE file now 
>> that Edzer Pebesma has arranged for a version of rgeos which exports 
>> SpatialLinesNULL.
>> 
>> 
>> 
>> But why do I need to explicitly import the superclass of the class I 
>> am actually using?  If I were using a *function* from rgeos, which in 
>> turn utilised a second non-exported function from rgeos, the package 
>> namespace environments mechanism would take care of how to find and 
>> access that second function, silently.  It wouldn't warn me about it 
>> and make me import it - in fact avoiding that is as I understand it a 
>> major purpose of the packaging namespace process.
>> 
>> 
>> 
>> There is obviously something I am missing, but having thought and 
>> read for several days I am at a loss as to what.
>> 
>> 
>> 
>> Thanks heaps in advance for any illumination that you can offer me!
>> 
>> 
>> 
>> What I have done already.
>> 
>> 
>> 
>> I have a toy example in folder SpatialLinesNULL of branch 
>> SpatialLinesNULL in a github repo at 
>> http://github.com/Geoff99/Examples/tree/SpatialLinesNULL
>> 
>> 
>> 
>> I have asked a (far too) long question on Stack Overflow (see
>> http://stackoverflow.com/questions/28871632/how-to-resolve-warning-me
>> ssages- 
>> metadata-object-not-found-spatiallinesnull-cla/29010169#29010169), 
>> the specific aspect of which was very kindly and quickly answered by 
>> Edzer Pebesma.
>> 
>> 
>> 
>> I have read the methods documentation ( which was very valuable 
>> indeed) and have posted my understanding of what I learnt from that 
>> (and from stepping through my toy example in the debugger) as a (once 
>> again quite long) answer on Stack Overflow here
>> 
>> 
>> 
>> http://stackoverflow.com/questions/28871632/how-to-resolve-warning-me
>> ssages-
>> metadata-object-not-found-spatiallinesnull-cla/29010169#29010169
>> 
>> 
>> 
>> PS If I should be asking this somewhere else, please just say.
>> 
>> 
>> 
>> PPS The primary purpose of the package I am building (not the toy 
>> example) is to help me learn about programming and packaging in R, 
>> hence my desire to chase down and understand this warning fully.
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From geoff.lee99 at gmail.com  Sat Mar 14 00:38:08 2015
From: geoff.lee99 at gmail.com (Geoff Lee)
Date: Sat, 14 Mar 2015 10:38:08 +1100
Subject: [Rd] Ah I've got it now .Thanks! RE: Understanding why "no metadata
	object found ... not exported?" warnings from the methods
	package exist, and what they mean
Message-ID: <00c601d05de6$c8532da0$58f988e0$@gmail.com>

Ah, I've got it now.

>From `?base:bindenv` comes

> " The namespace environments of packages with namespaces are locked when
loaded."

A locked environment 

> " prevents adding or removing variable bindings from the environment.
Changing the value of a variable is still possible unless the binding has
been locked"

A bit of experimentation shows that as well as package namespace
*environments* being locked, the *bindings* in the namespaces are locked.
Locked bindings means that :

> " The value of a locked binding cannot be changed".

Since the superclass metadata object comes from another package, its binding
(name) in that other package's namespace is locked and hence its value
cannot be changed.  So `mypkg` needs to work on a copy of the metadata
object if it needs to update the value of the metadata object (which in fact
it does need to do).

An alternative to copying might be to temporarily unlock the binding in the
namespace of the otherpackage, update the object, and relock the binding -
but since I have only just learnt about locking environments and bindings, I
have no idea what the consequences of that might be.  I'll leave well enough
alone.

Many thanks for helping me learn about this.

Geoff

PS Apologies if I have sent too much to the list about this topic - if so
let me know (gently please), so I can be better behaved in the future.

-----Original Message-----
From: Geoff Lee [mailto:geoff.lee99 at gmail.com] 
Sent: Saturday, 14 March 2015 9:30 AM
To: 'John Chambers'
Cc: 'r-devel at r-project.org'
Subject: RE: [Rd] Understanding why "no metadata object found ... not
exported?" warnings from the methods package exist, and what they mean

Very many thanks indeed John for taking the time to look into this so
closely and respond to me twice.

I am hovering on the edge of understanding what was / is confusing me, and
will read both your replies very closely.

I think my conceptual problem relates to the difference between what happens
to the *name* of an object (eg a function or a class (to be precise, a
function object or a class metadata object)) and what happens to the
*object* itself. Or in other terms, whether a namespace (possibly locked)
needs to be updated, or the (state of the) object itself is what needs to be
updated.  I'll try and explain below.

If `mypkg` want to use a function called `other_fun` from package `otherpkg`
all I have to do is import the *name* of `other_fun` into the `mypkg`
namespace.

After that all the magic of making sure that the other_fun *object* works
and can find everything it needs is taken care of for me.  The other_fun
object knows the enclosing environment where it was created and finds any
information it needs about additional functions etc, that may or may not
have been exported by package otherpkg behind the scenes.

My reasoning was that the same should apply to the *names* of classes as
well.

If `mypkg` wanted to use a class called `OtherClass` from package `otherpkg`
all it would need to do was import the *name* of `OtherClass` into the
`mypkg` namespace.

After that the `OtherClass` (metadata) object would know where it came from
and look after itself.  In particular, if the operation of the OtherClass
(metadata) object involved any superclasses (or later on, subclasses), the
manipulations required would occur at the object level, not at the *name*
level.  I can see why it is necessary to update the metadata object itself,
because functions like `setIs` and `setClassUnion` allow the upstream
parentage of a class to be altered post hoc in ways which depend upon what
else is loaded, and a class must be able to find that type of information if
inheritance is going to work.

But at the moment it seems that it is necessary to import the *name* of the
superclass(es) into the `mypkg` namespace as well, and that is what I can't
fully follow.

I do confess that I get quite lost when I try and follow my logic chain
through to the implementation level for class metadata objects.

I have got as far as understanding that the *name* of a metadata object is
mangled and hidden (I think the real *name* of `OtherClass` is usually
`.__C__OtherClass` ).  And that the metadata objects themselves need to be
able to maintain and manage any superclass and subclass relationships as
they evolve.  But when I get to trying to figure out how on earth the
various metadata objects would avoid the garbage collector, and cope with
unevaluated expressions, promises, pass by copying etc I am (well) over the
boundaries of my understanding.

Thinking as I type, if the current warning message is telling me that I am
getting a copy of the superclass metadata object, rather than a copied name
which points to the original metadata object itself, I can begin to see why
that would be a worry.

Mmmm, more for me to think about.

Once again, many many thanks for helping me work my way towards
understanding this

Geoff

-----Original Message-----
From: John Chambers [mailto:jmc at r-project.org]
Sent: Saturday, 14 March 2015 8:11 AM
To: Geoff Lee
Cc: r-devel at r-project.org
Subject: Re: [Rd] Understanding why "no metadata object found ... not
exported?" warnings from the methods package exist, and what they mean

On looking more closely, the purpose of finding the class definition is to
update the entry for the new relationship, as the warning message suggests.
That requires that the namespace holding the definition be writable.

In the case of subclass information, the original namespace is very likely
to be locked, if it's not the package currently being loaded.  Copying the
definition in order to update subclass information seems the only reasonable
choice, and no warning message is needed.

A revised version will omit this message.

On Mar 13, 2015, at 9:32 AM, John Chambers <jmc at r-project.org> wrote:

> This warning message is on my to-look-at list; I agree that sometimes it's
obviously possible for the system to get the information if it tries hard
enough.
> 
> The message means what it says:  Class information in a session includes
the currently loaded subclasses of a particular class.  Not critical but
sometimes useful.
> 
> In this case, (as I understand it without having looked recently), the
issue is that the "rgeos" namespace has not been loaded, although a subclass
of a class in that package has.  
> 
> So, should that namespace be loaded, to access (presumably) the class
object?  Or the copy made silently somewhere?  It's probably true that the
warning is not being seen by the owner of the package that could fix the
problem.
> 
> John
> 
> 
> 
> On Mar 12, 2015, at 1:47 PM, Geoff Lee <geoff.lee99 at gmail.com> wrote:
> 
>> Hi
>> 
>> 
>> 
>> I am seeking to understand why the methods package (to be specific 
>> `methods:::.findOrCopyClass` when called by `setIs` when called by
>> `setClass`) emits a warning message such as
>> 
>> 
>> 
>> ` class "SpatialLinesNULL" is defined (with package slot 'rgeos') but 
>> no metadata object found to revise subclass information---not 
>> exported?  Making a copy in package 'minweSpatialNULL `
>> 
>> 
>> 
>> when I try to `R cmd build .` and then R cmd check *.gz` (or 
>> alternatively
>> `devtools::load_all()`) the package I am building.
>> 
>> 
>> 
>> What I don't really follow is why I am being warned when evidently 
>> the methods package *can* actually find the metadata object in order 
>> to make a copy of it (or does it just copy a name which binds to the 
>> original metadata object - I'm not clear on that).  What is the 
>> danger I am being warned about, and what, ideally should I do about it?
>> 
>> 
>> 
>> In practice I know I can make the message go away by using 
>> `importClassesFrom(rgeos,SpatialLinesNULL)` in my NAMESPACE file now 
>> that Edzer Pebesma has arranged for a version of rgeos which exports 
>> SpatialLinesNULL.
>> 
>> 
>> 
>> But why do I need to explicitly import the superclass of the class I 
>> am actually using?  If I were using a *function* from rgeos, which in 
>> turn utilised a second non-exported function from rgeos, the package 
>> namespace environments mechanism would take care of how to find and 
>> access that second function, silently.  It wouldn't warn me about it 
>> and make me import it - in fact avoiding that is as I understand it a 
>> major purpose of the packaging namespace process.
>> 
>> 
>> 
>> There is obviously something I am missing, but having thought and 
>> read for several days I am at a loss as to what.
>> 
>> 
>> 
>> Thanks heaps in advance for any illumination that you can offer me!
>> 
>> 
>> 
>> What I have done already.
>> 
>> 
>> 
>> I have a toy example in folder SpatialLinesNULL of branch 
>> SpatialLinesNULL in a github repo at 
>> http://github.com/Geoff99/Examples/tree/SpatialLinesNULL
>> 
>> 
>> 
>> I have asked a (far too) long question on Stack Overflow (see 
>> http://stackoverflow.com/questions/28871632/how-to-resolve-warning-me
>> ssages-
>> metadata-object-not-found-spatiallinesnull-cla/29010169#29010169),
>> the specific aspect of which was very kindly and quickly answered by 
>> Edzer Pebesma.
>> 
>> 
>> 
>> I have read the methods documentation ( which was very valuable
>> indeed) and have posted my understanding of what I learnt from that 
>> (and from stepping through my toy example in the debugger) as a (once 
>> again quite long) answer on Stack Overflow here
>> 
>> 
>> 
>> http://stackoverflow.com/questions/28871632/how-to-resolve-warning-me
>> ssages-
>> metadata-object-not-found-spatiallinesnull-cla/29010169#29010169
>> 
>> 
>> 
>> PS If I should be asking this somewhere else, please just say.
>> 
>> 
>> 
>> PPS The primary purpose of the package I am building (not the toy
>> example) is to help me learn about programming and packaging in R, 
>> hence my desire to chase down and understand this warning fully.
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From mick.jordan at oracle.com  Sun Mar 15 00:16:39 2015
From: mick.jordan at oracle.com (Mick Jordan)
Date: Sat, 14 Mar 2015 16:16:39 -0700
Subject: [Rd] gzfile text value
Message-ID: <5504C157.8030901@oracle.com>

I'm puzzled why gzfile (which the spec says the default mode is "rb") 
shows mode="rb" but text="text" from summary when it is in lazy state:

  cc <- gzfile("ll.rds")
cc <- gzfile("ll.rds")
 > summary(cc)
summary(cc)
$description
[1] "ll.rds"

$class
[1] "gzfile"

$mode
[1] "rb"

$text
[1] "text"

$opened
[1] "closed"


From jouni.helske at jyu.fi  Mon Mar 16 09:21:19 2015
From: jouni.helske at jyu.fi (Helske, Jouni)
Date: Mon, 16 Mar 2015 08:21:19 +0000
Subject: [Rd] Initial covariance matrix in StructTS
Message-ID: <7FC11B33B8C53E4EB9510C0BAA73EAE34101AE2E@mbs2.ad.jyu.fi>

Dear all,

The definition of the initial covariance matrix P in StructTS function seems to be defined in a somewhat non-standard way without any references. Usually that matrix is defined as a diagonal matrix in case of structural time series models, but StructTS defines this as a singular matrix filled with  1e+06 * var(x, na.rm = TRUE)/100 where x is the time series being modelled.

I wonder if this is a bug or an undocumented feature?

There was more detailed question by Javier L?pez-de-Lacalle in R-help last November without replies:  https://stat.ethz.ch/pipermail/r-help//2014-November/423128.html<https://stat.ethz.ch/pipermail/r-help/2014-November/423128.html>

There is also illustrative figure in his blog post about the effects of this initial covariance matrix (scroll to the bottom of the page):
http://www.jalobe.com:8080/blog/variations-on-a-maximum-likelihood-procedure/

Best regards,

Jouni Helske

	[[alternative HTML version deleted]]


From hhamid at gmail.com  Tue Mar 17 06:08:11 2015
From: hhamid at gmail.com (Hamid Bazzaz)
Date: Mon, 16 Mar 2015 22:08:11 -0700
Subject: [Rd] Proposing a change in the base::sink interface for type
	argument
Message-ID: <CAJyqX+D7V0HQDz4mctXOQ8GJr6otE+7x9jgb4raSEOpPskyGxg@mail.gmail.com>

Hi folks,

Here is the current interface:

sink(file=NULL, append=FALSE, type = c("output", "message"), split=FALSE)

However, reading the implementation there is implicit assumption that type
is a single character value:
https://github.com/wch/r-source/blob/trunk/src/library/base/R/sink.R#L23

I'm finding this very confusing as the interface is giving a default value
of a character _vector_ causing the illusion that by default both
output/message will be redirected.

I'm proposing either a change in the interface so it is a single character
(either output or message) or a loop in the implementation on all values in
type so it will actually be considered a vector. Here is an example change
for the former:

https://github.com/hhamid/r-source/commit/d3cad22e1b9beca0a55004d74fc95059c279d770#diff-498a99501a04c6d9a66ee95ad6614734L19

Just wondering what people think and if this makes sense.

Thanks a lot,
Hamid

	[[alternative HTML version deleted]]


From lukaslehnert at googlemail.com  Tue Mar 17 11:26:59 2015
From: lukaslehnert at googlemail.com (Lukas Lehnert)
Date: Tue, 17 Mar 2015 11:26:59 +0100
Subject: [Rd] Using Fortran 90 code in packages for CRAN
Message-ID: <2050843.IaTBr2YW5h@pc19329>

I recently submitted a package to CRAN which encompasses Fortran 90 code. 
Neither on my linux system nor on the win-builder system the compilation 
reported any error or warning. The function worked fine. However, after 
submission of the package to CRAN, I received an email that I should not 
include Fortran 90 code. 

The problem is that the part written in Fortran is a large function using 
modules. Thus, rewriting the function in FORTRAN 77 is  impossible. So, I 
searched on CRAN and found some packages which contain Fortran 90 code. Is it 
generally possible to submit R packages to CRAN containing Fortran 90 source 
code? If so, what specific things should I consider?

Thank you for your help 

Lukas Lehnert


From jorge.martinez-de-salinas at hp.com  Tue Mar 17 18:37:53 2015
From: jorge.martinez-de-salinas at hp.com (Martinez de Salinas, Jorge)
Date: Tue, 17 Mar 2015 17:37:53 +0000
Subject: [Rd] Reduce memory peak when serializing to raw vectors
Message-ID: <1C69E21C7A9EC44AB81CB0C2D6496800205B5C59@G1W3780.americas.hpqcorp.net>

Hi,

I've been doing some tests using serialize() to a raw vector:

	df <- data.frame(runif(50e6,1,10))
	ser <- serialize(df,NULL)

In this example the data frame and the serialized raw vector occupy ~400MB each, for a total of ~800M. However the memory peak during serialize() is ~1.2GB:

	$ cat /proc/15155/status |grep Vm
	...
	VmHWM:	 1207792 kB
	VmRSS:	  817272 kB

We work with very large data frames and in many cases this is killing R with an "out of memory" error.

This is the relevant code in R 3.1.3 in src/main/serialize.c:2494

	InitMemOutPStream(&out, &mbs, type, version, hook, fun);
	R_Serialize(object, &out);
	val =  CloseMemOutPStream(&out);

The serialized object is being stored in a buffer pointed by out.data. Then in CloseMemOutPStream() R copies the whole buffer to a newly allocated SEXP object (the raw vector that stores the final result):

	PROTECT(val = allocVector(RAWSXP, mb->count));
	memcpy(RAW(val), mb->buf, mb->count);
	free_mem_buffer(mb);
	UNPROTECT(1);

Before calling free_mem_buffer() the process is using ~1.2GB (the original data frame + the serialization buffer + final serialized raw vector). 

One possible solution would be to allocate a buffer for the final raw vector and store the serialization result directly into that buffer. This would bring the memory peak down from ~1.2GB to ~800MB.

Thanks,
-Jorge


From simon.urbanek at r-project.org  Tue Mar 17 22:03:05 2015
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 17 Mar 2015 17:03:05 -0400
Subject: [Rd] Reduce memory peak when serializing to raw vectors
In-Reply-To: <1C69E21C7A9EC44AB81CB0C2D6496800205B5C59@G1W3780.americas.hpqcorp.net>
References: <1C69E21C7A9EC44AB81CB0C2D6496800205B5C59@G1W3780.americas.hpqcorp.net>
Message-ID: <084FC29C-3855-49BC-8A0E-BF81CD37C9C7@r-project.org>

Jorge,

what you propose is not possible because the size of the output is unknown, that's why a dynamically growing PStream buffer is used - it cannot be pre-allocated.

Cheers,
Simon


> On Mar 17, 2015, at 1:37 PM, Martinez de Salinas, Jorge <jorge.martinez-de-salinas at hp.com> wrote:
> 
> Hi,
> 
> I've been doing some tests using serialize() to a raw vector:
> 
> 	df <- data.frame(runif(50e6,1,10))
> 	ser <- serialize(df,NULL)
> 
> In this example the data frame and the serialized raw vector occupy ~400MB each, for a total of ~800M. However the memory peak during serialize() is ~1.2GB:
> 
> 	$ cat /proc/15155/status |grep Vm
> 	...
> 	VmHWM:	 1207792 kB
> 	VmRSS:	  817272 kB
> 
> We work with very large data frames and in many cases this is killing R with an "out of memory" error.
> 
> This is the relevant code in R 3.1.3 in src/main/serialize.c:2494
> 
> 	InitMemOutPStream(&out, &mbs, type, version, hook, fun);
> 	R_Serialize(object, &out);
> 	val =  CloseMemOutPStream(&out);
> 
> The serialized object is being stored in a buffer pointed by out.data. Then in CloseMemOutPStream() R copies the whole buffer to a newly allocated SEXP object (the raw vector that stores the final result):
> 
> 	PROTECT(val = allocVector(RAWSXP, mb->count));
> 	memcpy(RAW(val), mb->buf, mb->count);
> 	free_mem_buffer(mb);
> 	UNPROTECT(1);
> 
> Before calling free_mem_buffer() the process is using ~1.2GB (the original data frame + the serialization buffer + final serialized raw vector). 
> 
> One possible solution would be to allocate a buffer for the final raw vector and store the serialization result directly into that buffer. This would bring the memory peak down from ~1.2GB to ~800MB.
> 
> Thanks,
> -Jorge
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From lawrence.michael at gene.com  Tue Mar 17 22:48:00 2015
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Tue, 17 Mar 2015 14:48:00 -0700
Subject: [Rd] Reduce memory peak when serializing to raw vectors
In-Reply-To: <084FC29C-3855-49BC-8A0E-BF81CD37C9C7@r-project.org>
References: <1C69E21C7A9EC44AB81CB0C2D6496800205B5C59@G1W3780.americas.hpqcorp.net>
	<084FC29C-3855-49BC-8A0E-BF81CD37C9C7@r-project.org>
Message-ID: <CAOQ5NyfCiStuddkzXY_hch+2muEBGDWQ9q8oWPWsA7ReQvzXqg@mail.gmail.com>

Presumably one could stream over the data twice, the first to get the size,
without storing the data. Slower but more memory efficient, unless I'm
missing something.

Michael

On Tue, Mar 17, 2015 at 2:03 PM, Simon Urbanek <simon.urbanek at r-project.org>
wrote:

> Jorge,
>
> what you propose is not possible because the size of the output is
> unknown, that's why a dynamically growing PStream buffer is used - it
> cannot be pre-allocated.
>
> Cheers,
> Simon
>
>
> > On Mar 17, 2015, at 1:37 PM, Martinez de Salinas, Jorge <
> jorge.martinez-de-salinas at hp.com> wrote:
> >
> > Hi,
> >
> > I've been doing some tests using serialize() to a raw vector:
> >
> >       df <- data.frame(runif(50e6,1,10))
> >       ser <- serialize(df,NULL)
> >
> > In this example the data frame and the serialized raw vector occupy
> ~400MB each, for a total of ~800M. However the memory peak during
> serialize() is ~1.2GB:
> >
> >       $ cat /proc/15155/status |grep Vm
> >       ...
> >       VmHWM:   1207792 kB
> >       VmRSS:    817272 kB
> >
> > We work with very large data frames and in many cases this is killing R
> with an "out of memory" error.
> >
> > This is the relevant code in R 3.1.3 in src/main/serialize.c:2494
> >
> >       InitMemOutPStream(&out, &mbs, type, version, hook, fun);
> >       R_Serialize(object, &out);
> >       val =  CloseMemOutPStream(&out);
> >
> > The serialized object is being stored in a buffer pointed by out.data.
> Then in CloseMemOutPStream() R copies the whole buffer to a newly allocated
> SEXP object (the raw vector that stores the final result):
> >
> >       PROTECT(val = allocVector(RAWSXP, mb->count));
> >       memcpy(RAW(val), mb->buf, mb->count);
> >       free_mem_buffer(mb);
> >       UNPROTECT(1);
> >
> > Before calling free_mem_buffer() the process is using ~1.2GB (the
> original data frame + the serialization buffer + final serialized raw
> vector).
> >
> > One possible solution would be to allocate a buffer for the final raw
> vector and store the serialization result directly into that buffer. This
> would bring the memory peak down from ~1.2GB to ~800MB.
> >
> > Thanks,
> > -Jorge
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From jorge.martinez-de-salinas at hp.com  Tue Mar 17 23:09:21 2015
From: jorge.martinez-de-salinas at hp.com (Martinez de Salinas, Jorge)
Date: Tue, 17 Mar 2015 22:09:21 +0000
Subject: [Rd] Reduce memory peak when serializing to raw vectors
Message-ID: <1C69E21C7A9EC44AB81CB0C2D6496800205B5EEB@G1W3780.americas.hpqcorp.net>

Hi,

I've been doing some tests using serialize() to a raw vector:

	df <- data.frame(runif(50e6,1,10))
	ser <- serialize(df,NULL)

In this example the data frame and the serialized raw vector occupy ~400MB each, for a total of ~800M. However the memory peak during serialize() is ~1.2GB:

	$ cat /proc/15155/status |grep Vm
	...
	VmHWM:	 1207792 kB
	VmRSS:	  817272 kB

We work with very large data frames and in many cases this is killing R with an "out of memory" error.

This is the relevant code in R 3.1.3 in src/main/serialize.c:2494

	InitMemOutPStream(&out, &mbs, type, version, hook, fun);
	R_Serialize(object, &out);
	val =  CloseMemOutPStream(&out);

The serialized object is being stored in a buffer pointed by out.data. Then in CloseMemOutPStream() R copies the whole buffer to a newly allocated SEXP object (the raw vector that stores the final result):

	PROTECT(val = allocVector(RAWSXP, mb->count));
	memcpy(RAW(val), mb->buf, mb->count);
	free_mem_buffer(mb);
	UNPROTECT(1);

Before calling free_mem_buffer() the process is using ~1.2GB (the original data frame + the serialization buffer + final serialized raw vector). 

One possible solution would be to allocate a buffer for the final raw vector and store the serialization result directly into that buffer. This would bring the memory peak down from ~1.2GB to ~800MB.

Thanks,
-Jorge


From simon.urbanek at r-project.org  Tue Mar 17 23:13:29 2015
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 17 Mar 2015 18:13:29 -0400
Subject: [Rd] Reduce memory peak when serializing to raw vectors
In-Reply-To: <CAOQ5NyfCiStuddkzXY_hch+2muEBGDWQ9q8oWPWsA7ReQvzXqg@mail.gmail.com>
References: <1C69E21C7A9EC44AB81CB0C2D6496800205B5C59@G1W3780.americas.hpqcorp.net>
	<084FC29C-3855-49BC-8A0E-BF81CD37C9C7@r-project.org>
	<CAOQ5NyfCiStuddkzXY_hch+2muEBGDWQ9q8oWPWsA7ReQvzXqg@mail.gmail.com>
Message-ID: <1EEC460E-A048-404F-AA73-7AD7D272D17B@r-project.org>

In principle, yes (that's what Rserve serialization does), but AFAIR we don't have the infrastructure in place for that. But then you may as well serialize to a connection instead. To be honest I don't see why you would serialize anything big to a vector - you can't really do anything useful with that ... (what you couldn't do with the streaming version).

Sent from my iPhone

> On Mar 17, 2015, at 17:48, Michael Lawrence <lawrence.michael at gene.com> wrote:
> 
> Presumably one could stream over the data twice, the first to get the size, without storing the data. Slower but more memory efficient, unless I'm missing something.
> 
> Michael
> 
>> On Tue, Mar 17, 2015 at 2:03 PM, Simon Urbanek <simon.urbanek at r-project.org> wrote:
>> Jorge,
>> 
>> what you propose is not possible because the size of the output is unknown, that's why a dynamically growing PStream buffer is used - it cannot be pre-allocated.
>> 
>> Cheers,
>> Simon
>> 
>> 
>> > On Mar 17, 2015, at 1:37 PM, Martinez de Salinas, Jorge <jorge.martinez-de-salinas at hp.com> wrote:
>> >
>> > Hi,
>> >
>> > I've been doing some tests using serialize() to a raw vector:
>> >
>> >       df <- data.frame(runif(50e6,1,10))
>> >       ser <- serialize(df,NULL)
>> >
>> > In this example the data frame and the serialized raw vector occupy ~400MB each, for a total of ~800M. However the memory peak during serialize() is ~1.2GB:
>> >
>> >       $ cat /proc/15155/status |grep Vm
>> >       ...
>> >       VmHWM:   1207792 kB
>> >       VmRSS:    817272 kB
>> >
>> > We work with very large data frames and in many cases this is killing R with an "out of memory" error.
>> >
>> > This is the relevant code in R 3.1.3 in src/main/serialize.c:2494
>> >
>> >       InitMemOutPStream(&out, &mbs, type, version, hook, fun);
>> >       R_Serialize(object, &out);
>> >       val =  CloseMemOutPStream(&out);
>> >
>> > The serialized object is being stored in a buffer pointed by out.data. Then in CloseMemOutPStream() R copies the whole buffer to a newly allocated SEXP object (the raw vector that stores the final result):
>> >
>> >       PROTECT(val = allocVector(RAWSXP, mb->count));
>> >       memcpy(RAW(val), mb->buf, mb->count);
>> >       free_mem_buffer(mb);
>> >       UNPROTECT(1);
>> >
>> > Before calling free_mem_buffer() the process is using ~1.2GB (the original data frame + the serialization buffer + final serialized raw vector).
>> >
>> > One possible solution would be to allocate a buffer for the final raw vector and store the serialization result directly into that buffer. This would bring the memory peak down from ~1.2GB to ~800MB.
>> >
>> > Thanks,
>> > -Jorge
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>> >
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

	[[alternative HTML version deleted]]


From jorge.martinez-de-salinas at hp.com  Wed Mar 18 06:53:44 2015
From: jorge.martinez-de-salinas at hp.com (Martinez de Salinas, Jorge)
Date: Wed, 18 Mar 2015 05:53:44 +0000
Subject: [Rd] Reduce memory peak when serializing to raw vectors
In-Reply-To: <1EEC460E-A048-404F-AA73-7AD7D272D17B@r-project.org>
References: <1C69E21C7A9EC44AB81CB0C2D6496800205B5C59@G1W3780.americas.hpqcorp.net>
	<084FC29C-3855-49BC-8A0E-BF81CD37C9C7@r-project.org>
	<CAOQ5NyfCiStuddkzXY_hch+2muEBGDWQ9q8oWPWsA7ReQvzXqg@mail.gmail.com>
	<1EEC460E-A048-404F-AA73-7AD7D272D17B@r-project.org>
Message-ID: <1C69E21C7A9EC44AB81CB0C2D6496800205B6092@G1W3780.americas.hpqcorp.net>

Thanks Simon, Michael. 
Looking at the design more carefully I think we can get away with serializing directly to sockets or to a file in /dev/shm if we want to keep things in memory.

-Jorge

From: Simon Urbanek [mailto:simon.urbanek at r-project.org] 
Sent: Tuesday, March 17, 2015 3:13 PM
To: Michael Lawrence
Cc: Martinez de Salinas, Jorge; r-devel at r-project.org
Subject: Re: [Rd] Reduce memory peak when serializing to raw vectors

In principle, yes (that's what Rserve serialization does), but AFAIR we don't have the infrastructure in place for that. But then you may as well serialize to a connection instead. To be honest I don't see why you would serialize anything big to a vector - you can't really do anything useful with that ... (what you couldn't do with the streaming version).

Sent from my iPhone

On Mar 17, 2015, at 17:48, Michael Lawrence <lawrence.michael at gene.com> wrote:
Presumably one could stream over the data twice, the first to get the size, without storing the data. Slower but more memory efficient, unless I'm missing something.
Michael

On Tue, Mar 17, 2015 at 2:03 PM, Simon Urbanek <simon.urbanek at r-project.org> wrote:
Jorge,

what you propose is not possible because the size of the output is unknown, that's why a dynamically growing PStream buffer is used - it cannot be pre-allocated.

Cheers,
Simon


> On Mar 17, 2015, at 1:37 PM, Martinez de Salinas, Jorge <jorge.martinez-de-salinas at hp.com> wrote:
>
> Hi,
>
> I've been doing some tests using serialize() to a raw vector:
>
>? ? ? ?df <- data.frame(runif(50e6,1,10))
>? ? ? ?ser <- serialize(df,NULL)
>
> In this example the data frame and the serialized raw vector occupy ~400MB each, for a total of ~800M. However the memory peak during serialize() is ~1.2GB:
>
>? ? ? ?$ cat /proc/15155/status |grep Vm
>? ? ? ?...
>? ? ? ?VmHWM:? ?1207792 kB
>? ? ? ?VmRSS:? ? 817272 kB
>
> We work with very large data frames and in many cases this is killing R with an "out of memory" error.
>
> This is the relevant code in R 3.1.3 in src/main/serialize.c:2494
>
>? ? ? ?InitMemOutPStream(&out, &mbs, type, version, hook, fun);
>? ? ? ?R_Serialize(object, &out);
>? ? ? ?val =? CloseMemOutPStream(&out);
>
> The serialized object is being stored in a buffer pointed by out.data. Then in CloseMemOutPStream() R copies the whole buffer to a newly allocated SEXP object (the raw vector that stores the final result):
>
>? ? ? ?PROTECT(val = allocVector(RAWSXP, mb->count));
>? ? ? ?memcpy(RAW(val), mb->buf, mb->count);
>? ? ? ?free_mem_buffer(mb);
>? ? ? ?UNPROTECT(1);
>
> Before calling free_mem_buffer() the process is using ~1.2GB (the original data frame + the serialization buffer + final serialized raw vector).
>
> One possible solution would be to allocate a buffer for the final raw vector and store the serialization result directly into that buffer. This would bring the memory peak down from ~1.2GB to ~800MB.
>
> Thanks,
> -Jorge
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From plummerm at iarc.fr  Wed Mar 18 11:17:32 2015
From: plummerm at iarc.fr (Martyn Plummer)
Date: Wed, 18 Mar 2015 10:17:32 +0000
Subject: [Rd] Using Fortran 90 code in packages for CRAN
In-Reply-To: <2050843.IaTBr2YW5h@pc19329>
References: <2050843.IaTBr2YW5h@pc19329>
Message-ID: <1426673852.18065.11.camel@iarc.fr>

Everything you need to know is in the Writing R Extensions manual, and
section 1.2.3 in particular. There are restrictions on Fortran 90/95 use
due to portability issues.

Make sure you are following all of the advice in the manual, e.g.:
- Files containing Fortran 90 code should have extension .f90
- Mixed Fortran 9x and C++ code is not supported and there is no
  guarantee that Fortran 9x can be mixed with other languages.
- Free source form Fortran 9x is not portable.
- When using modules, you may need to give compile-order hints to 
  parallel make.
- Do not include module files in the source - they are
  compiler-dependent.

Martyn

On Tue, 2015-03-17 at 11:26 +0100, Lukas Lehnert wrote:
> I recently submitted a package to CRAN which encompasses Fortran 90 code. 
> Neither on my linux system nor on the win-builder system the compilation 
> reported any error or warning. The function worked fine. However, after 
> submission of the package to CRAN, I received an email that I should not 
> include Fortran 90 code. 
> 
> The problem is that the part written in Fortran is a large function using 
> modules. Thus, rewriting the function in FORTRAN 77 is  impossible. So, I 
> searched on CRAN and found some packages which contain Fortran 90 code. Is it 
> generally possible to submit R packages to CRAN containing Fortran 90 source 
> code? If so, what specific things should I consider?
> 
> Thank you for your help 
> 
> Lukas Lehnert
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-----------------------------------------------------------------------
This message and its attachments are strictly confidenti...{{dropped:8}}


From evansochiaga at aims.ac.za  Wed Mar 18 13:14:12 2015
From: evansochiaga at aims.ac.za (Evans Otieno Ochiaga)
Date: Wed, 18 Mar 2015 14:14:12 +0200
Subject: [Rd] Help
Message-ID: <CAObCh3XfvtCz+qWtSS+pSPrhWtUKtdZoYANN=_4AJndziiiDOQ@mail.gmail.com>

Hi to All,

I am fitting some models to a data using non linear least square, and
whenever i run the command, parameters value have good convergence but I
get the  error in red as shown below. Kindly how can I fix this problem.


Convergence of parameter values

0.2390121 :  0.1952981 0.9999975 1.0000000
0.03716107 :  0.1553976 0.9999910 1.0000000
0.009478433 :  0.2011017 0.9999798 1.0000000
0.004108196 :  0.2640111 0.9999693 1.0000000
0.003705189 :  0.2938360 0.9999652 1.0000000
0.003702546 :  0.2965745 0.9999650 1.0000000
0.003702546 :  0.2965898 0.9999650 1.0000000
0.003702546 :  0.2965898 0.9999650 1.0000000
0.003702546 :  0.2965898 0.9999650 1.0000000

Error in nls(Occupancy ~ 1 - (theta * beta^(2 * Resolution^(1/2)) *
delta^Resolution),  :
  step factor 0.000488281 reduced below 'minFactor' of 0.000976562

Regards,




*Evans Ochiaga*

*African Institute for Mathematical Sciences*

*6 Melrose Road*

*Muizenberg, South Africa*

*Msc in Mathematical Sciences+27 84 61 69 183 *

*"When I cannot understand my Father?s leading, And it seems to be but hard
and cruel fate, Still I hear that gentle whisper ever pleading, God is
working, God is faithful?Only wait."*

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Mar 18 14:27:19 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 18 Mar 2015 09:27:19 -0400
Subject: [Rd] Windows gcc toolchain for R 3.2.0
Message-ID: <55097D37.3040105@gmail.com>

To anyone following the Windows toolchain saga:

The gcc 4.9.2 toolchain that is currently in Rtools33 has too many 
incompatibilities with existing code, so we won't be using it in the R 
3.2.0 build.  I will soon be uploading to CRAN a new version of Rtools33 
that is very similar to Rtools32, containing gcc 4.6.3.

We are continuing to work on the new toolchain, and hope to have it 
ready before R 3.2.1 is released.

The known problems are as follows:

   - C++ code should not call Rf_error(), as it uses longjmp, and the 
behaviour of longjmp is undefined in C++ when destructors need to be 
called.  However, a number of packages do call Rf_error, and in gcc 
4.6.3, they get away with it.  In our candidate 4.9.2 build, they 
crashed.  If we can't work around this, I'll suggest that we test for 
the presence of Rf_error in C++ code, and start issuing warnings or 
errors when it is seen.  But before we do that, we need a solid replacement.

  - There are some other crashes that appear to be unrelated, also with 
C++ code.

  - There are some subtle differences in arithmetic that result in tests 
failing.  These may be due to bugs in MinGW-w64 code,
or may be unavoidable.

Duncan Murdoch


From murdoch.duncan at gmail.com  Wed Mar 18 14:27:26 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 18 Mar 2015 09:27:26 -0400
Subject: [Rd] Windows gcc toolchain for R 3.2.0
Message-ID: <55097D3E.7020606@gmail.com>

To anyone following the Windows toolchain saga:

The gcc 4.9.2 toolchain that is currently in Rtools33 has too many 
incompatibilities with existing code, so we won't be using it in the R 
3.2.0 build.  I will soon be uploading to CRAN a new version of Rtools33 
that is very similar to Rtools32, containing gcc 4.6.3.

We are continuing to work on the new toolchain, and hope to have it 
ready before R 3.2.1 is released.

The known problems are as follows:

   - C++ code should not call Rf_error(), as it uses longjmp, and the 
behaviour of longjmp is undefined in C++ when destructors need to be 
called.  However, a number of packages do call Rf_error, and in gcc 
4.6.3, they get away with it.  In our candidate 4.9.2 build, they 
crashed.  If we can't work around this, I'll suggest that we test for 
the presence of Rf_error in C++ code, and start issuing warnings or 
errors when it is seen.  But before we do that, we need a solid replacement.

  - There are some other crashes that appear to be unrelated, also with 
C++ code.

  - There are some subtle differences in arithmetic that result in tests 
failing.  These may be due to bugs in MinGW-w64 code,
or may be unavoidable.

Duncan Murdoch


From edd at debian.org  Wed Mar 18 15:04:49 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 18 Mar 2015 09:04:49 -0500
Subject: [Rd] [Rcpp-devel] Windows gcc toolchain for R 3.2.0
In-Reply-To: <55097D3E.7020606@gmail.com>
References: <55097D3E.7020606@gmail.com>
Message-ID: <21769.34305.173670.719458@max.nulle.part>


Duncan (and everybody else working on it behind the curtains),

Thanks for the update. All the work is truly appreciated, and it is really
too bad that we turned to C++ testing so late in the process.  But ensuring
release quality is paramount, so withholding g++ 4.9.* on Windows til these
issues are sorted out is the correct approach. 

On 18 March 2015 at 09:27, Duncan Murdoch wrote:
| called.  However, a number of packages do call Rf_error, and in gcc 
| 4.6.3, they get away with it.  In our candidate 4.9.2 build, they 

For the record, "we also got away with it" using every other know compiler
and configuration. We would have addressed this earlier if it had been known.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From dtenenba at fredhutch.org  Wed Mar 18 15:55:06 2015
From: dtenenba at fredhutch.org (Dan Tenenbaum)
Date: Wed, 18 Mar 2015 07:55:06 -0700 (PDT)
Subject: [Rd] [Rcpp-devel] Windows gcc toolchain for R 3.2.0
In-Reply-To: <55097D3E.7020606@gmail.com>
Message-ID: <1298686136.647031.1426690506425.JavaMail.root@fredhutch.org>

Duncan,

----- Original Message -----
> From: "Duncan Murdoch" <murdoch.duncan at gmail.com>
> To: "R-devel at r-project.org" <r-devel at r-project.org>, rcpp-devel at r-forge.wu-wien.ac.at
> Sent: Wednesday, March 18, 2015 6:27:26 AM
> Subject: [Rcpp-devel] Windows gcc toolchain for R 3.2.0
> 
> To anyone following the Windows toolchain saga:
> 
> The gcc 4.9.2 toolchain that is currently in Rtools33 has too many
> incompatibilities with existing code, so we won't be using it in the
> R
> 3.2.0 build.  I will soon be uploading to CRAN a new version of
> Rtools33
> that is very similar to Rtools32, containing gcc 4.6.3.
> 
> We are continuing to work on the new toolchain, and hope to have it
> ready before R 3.2.1 is released.

Thanks very much for your work on this.

> 
> The known problems are as follows:
> 
>    - C++ code should not call Rf_error(), as it uses longjmp, and the
> behaviour of longjmp is undefined in C++ when destructors need to be
> called.  However, a number of packages do call Rf_error, and in gcc
> 4.6.3, they get away with it.  In our candidate 4.9.2 build, they
> crashed.  If we can't work around this, I'll suggest that we test for
> the presence of Rf_error in C++ code, and start issuing warnings or
> errors when it is seen.  But before we do that, we need a solid
> replacement.
> 
>   - There are some other crashes that appear to be unrelated, also
>   with
> C++ code.
> 
>   - There are some subtle differences in arithmetic that result in
>   tests
> failing.  These may be due to bugs in MinGW-w64 code,
> or may be unavoidable.

Is it not considered a "known problem" that C++ libraries linked against by R packages need to be rebuilt with g++ 4.9.2 in order for the R packages to install/load?

Thanks again,
Dan


> 
> Duncan Murdoch
> _______________________________________________
> Rcpp-devel mailing list
> Rcpp-devel at lists.r-forge.r-project.org
> https://lists.r-forge.r-project.org/cgi-bin/mailman/listinfo/rcpp-devel
>


From plummerm at iarc.fr  Wed Mar 18 16:33:30 2015
From: plummerm at iarc.fr (Martyn Plummer)
Date: Wed, 18 Mar 2015 15:33:30 +0000
Subject: [Rd] [Rcpp-devel] Windows gcc toolchain for R 3.2.0
In-Reply-To: <1298686136.647031.1426690506425.JavaMail.root@fredhutch.org>
References: <1298686136.647031.1426690506425.JavaMail.root@fredhutch.org>
Message-ID: <1426692809.18065.14.camel@iarc.fr>

On Wed, 2015-03-18 at 07:55 -0700, Dan Tenenbaum wrote:
> Is it not considered a "known problem" that C++ libraries linked
> against by R packages need to be rebuilt with g++ 4.9.2 in order for
> the R packages to install/load?

This could well be due to incompatible thread models (win32 vs posix).
See the thread "V8 crashes..." on the Rcpp-devel mailing list. We have
not yet had a chance to test the gcc 4.9.2 toolchain built with win32
threads.

Martyn

> Thanks again,
> Dan

-----------------------------------------------------------------------
This message and its attachments are strictly confidenti...{{dropped:8}}


From wdunlap at tibco.com  Wed Mar 18 17:21:56 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 18 Mar 2015 09:21:56 -0700
Subject: [Rd] Help
In-Reply-To: <CAObCh3XfvtCz+qWtSS+pSPrhWtUKtdZoYANN=_4AJndziiiDOQ@mail.gmail.com>
References: <CAObCh3XfvtCz+qWtSS+pSPrhWtUKtdZoYANN=_4AJndziiiDOQ@mail.gmail.com>
Message-ID: <CAF8bMcZJRxb+W5sPVZSu7HD1Z5URcWkB+9D1Wo_d90J3cJJ3_A@mail.gmail.com>

You can use nls's 'control' argument to work around this problem.
Read help(nls.control) for details.
   nls(control = nls.control(minFactor=2^-20), ...)
will allow a smaller step factor than the default 2^-10 and loosening
the convergence tolerance with
   nls(control = nls.control(tol=1e-4))
may lessen the need for the step-halving (at the cost of a less
accurate answer than you desire).  'Step-halving' is done when
the Newton-Raphson step would increase the sum of squared
residuals -- the the step size is halved until the ssr goes down
or until 'minFactor' is reached.

   nls(control = nls.control(printEval=TRUE), ...)
will show any step-halving that is going on and
   nls(control = nls.control(warnOnly=TRUE), ...)
will make the non-convergence messages warnings instead of fatal
errors so you can get some sort of answer from nls (it is up to you
to evaluate their appropriateness).

You can give nls.control several of these arguments at once (and a 'maxiter'
argument to control the number of major iterations.



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Mar 18, 2015 at 5:14 AM, Evans Otieno Ochiaga <
evansochiaga at aims.ac.za> wrote:

> Hi to All,
>
> I am fitting some models to a data using non linear least square, and
> whenever i run the command, parameters value have good convergence but I
> get the  error in red as shown below. Kindly how can I fix this problem.
>
>
> Convergence of parameter values
>
> 0.2390121 :  0.1952981 0.9999975 1.0000000
> 0.03716107 :  0.1553976 0.9999910 1.0000000
> 0.009478433 :  0.2011017 0.9999798 1.0000000
> 0.004108196 :  0.2640111 0.9999693 1.0000000
> 0.003705189 :  0.2938360 0.9999652 1.0000000
> 0.003702546 :  0.2965745 0.9999650 1.0000000
> 0.003702546 :  0.2965898 0.9999650 1.0000000
> 0.003702546 :  0.2965898 0.9999650 1.0000000
> 0.003702546 :  0.2965898 0.9999650 1.0000000
>
> Error in nls(Occupancy ~ 1 - (theta * beta^(2 * Resolution^(1/2)) *
> delta^Resolution),  :
>   step factor 0.000488281 reduced below 'minFactor' of 0.000976562
>
> Regards,
>
>
>
>
> *Evans Ochiaga*
>
> *African Institute for Mathematical Sciences*
>
> *6 Melrose Road*
>
> *Muizenberg, South Africa*
>
> *Msc in Mathematical Sciences+27 84 61 69 183 *
>
> *"When I cannot understand my Father?s leading, And it seems to be but hard
> and cruel fate, Still I hear that gentle whisper ever pleading, God is
> working, God is faithful?Only wait."*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Mar 18 17:29:40 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 18 Mar 2015 12:29:40 -0400
Subject: [Rd] [Rcpp-devel] Windows gcc toolchain for R 3.2.0
In-Reply-To: <1426692809.18065.14.camel@iarc.fr>
References: <1298686136.647031.1426690506425.JavaMail.root@fredhutch.org>
	<1426692809.18065.14.camel@iarc.fr>
Message-ID: <5509A7F4.7090408@gmail.com>

On 18/03/2015 11:33 AM, Martyn Plummer wrote:
> On Wed, 2015-03-18 at 07:55 -0700, Dan Tenenbaum wrote:
> > Is it not considered a "known problem" that C++ libraries linked
> > against by R packages need to be rebuilt with g++ 4.9.2 in order for
> > the R packages to install/load?
>
> This could well be due to incompatible thread models (win32 vs posix).
> See the thread "V8 crashes..." on the Rcpp-devel mailing list. We have
> not yet had a chance to test the gcc 4.9.2 toolchain built with win32
> threads.

I believe the RStudio folks have tried it, and it was not sufficient to 
fix everything; time just ran out for finding what else was wrong.

Duncan Murdoch


From macqueen1 at llnl.gov  Wed Mar 18 22:42:27 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 18 Mar 2015 21:42:27 +0000
Subject: [Rd] Proposing a change in the base::sink interface for type
 argument
In-Reply-To: <CAJyqX+D7V0HQDz4mctXOQ8GJr6otE+7x9jgb4raSEOpPskyGxg@mail.gmail.com>
References: <CAJyqX+D7V0HQDz4mctXOQ8GJr6otE+7x9jgb4raSEOpPskyGxg@mail.gmail.com>
Message-ID: <D12F3B10.122AF9%macqueen1@llnl.gov>

It's only an illusion until one actually tries providing a vector.

  > sink('foo', type=c('s','m'))
  Error in match.arg(type) : 'arg' must be of length 1

The additional benefit of match.arg() which you may have not appreciated
is that it allows the user to abbreviate. That is,
  > sink('foo', type='o')
is valid usage. The essential concept of match.arg() is that it tries to
match whatever the user supplied with one, and only one, of the values
provided in the argument's default value, and that is the value used in
the rest of the function.

For example:
> foo <- function(arg=c('aa','bb','cc')) cat(match.arg(arg),'\n')
> foo('a')
aa 
> foo('b')
bb 
> foo('x')
Error in match.arg(arg) : 'arg' should be one of "aa", "bb", "cc"
> 
> foo('aa')
aa 




Being "non-intuitive" or puzzling to people coming from other languages is
not a sufficient reason for a change. Obviously, different languages have
different features, otherwise, why bother to have different languages?
 
And yes, match.arg() is widely used in R. I find it quite useful in my own
programming.


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 3/16/15, 10:08 PM, "Hamid Bazzaz" <hhamid at gmail.com> wrote:

>Hi folks,
>
>Here is the current interface:
>
>sink(file=NULL, append=FALSE, type = c("output", "message"), split=FALSE)
>
>However, reading the implementation there is implicit assumption that type
>is a single character value:
>https://github.com/wch/r-source/blob/trunk/src/library/base/R/sink.R#L23
>
>I'm finding this very confusing as the interface is giving a default value
>of a character _vector_ causing the illusion that by default both
>output/message will be redirected.
>
>I'm proposing either a change in the interface so it is a single character
>(either output or message) or a loop in the implementation on all values
>in
>type so it will actually be considered a vector. Here is an example change
>for the former:
>
>https://github.com/hhamid/r-source/commit/d3cad22e1b9beca0a55004d74fc95059
>c279d770#diff-498a99501a04c6d9a66ee95ad6614734L19
>
>Just wondering what people think and if this makes sense.
>
>Thanks a lot,
>Hamid
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-devel at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel


From kasperdanielhansen at gmail.com  Thu Mar 19 00:48:07 2015
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Wed, 18 Mar 2015 19:48:07 -0400
Subject: [Rd] Proposing a change in the base::sink interface for type
	argument
In-Reply-To: <D12F3B10.122AF9%macqueen1@llnl.gov>
References: <CAJyqX+D7V0HQDz4mctXOQ8GJr6otE+7x9jgb4raSEOpPskyGxg@mail.gmail.com>
	<D12F3B10.122AF9%macqueen1@llnl.gov>
Message-ID: <CAC2h7utZQVYRBdTBpOYiYAUCgE6iSf4Up5pRikDCp=00dCE+vw@mail.gmail.com>

In other words: this is a standard programming paradigm in R/S which
(unfortunately) is not widely known, based on my network.  It is really
nice for developers.

Best,
Kasper

On Wed, Mar 18, 2015 at 5:42 PM, MacQueen, Don <macqueen1 at llnl.gov> wrote:

> It's only an illusion until one actually tries providing a vector.
>
>   > sink('foo', type=c('s','m'))
>   Error in match.arg(type) : 'arg' must be of length 1
>
> The additional benefit of match.arg() which you may have not appreciated
> is that it allows the user to abbreviate. That is,
>   > sink('foo', type='o')
> is valid usage. The essential concept of match.arg() is that it tries to
> match whatever the user supplied with one, and only one, of the values
> provided in the argument's default value, and that is the value used in
> the rest of the function.
>
> For example:
> > foo <- function(arg=c('aa','bb','cc')) cat(match.arg(arg),'\n')
> > foo('a')
> aa
> > foo('b')
> bb
> > foo('x')
> Error in match.arg(arg) : 'arg' should be one of "aa", "bb", "cc"
> >
> > foo('aa')
> aa
>
>
>
>
> Being "non-intuitive" or puzzling to people coming from other languages is
> not a sufficient reason for a change. Obviously, different languages have
> different features, otherwise, why bother to have different languages?
>
> And yes, match.arg() is widely used in R. I find it quite useful in my own
> programming.
>
>
> --
> Don MacQueen
>
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
>
>
>
>
>
> On 3/16/15, 10:08 PM, "Hamid Bazzaz" <hhamid at gmail.com> wrote:
>
> >Hi folks,
> >
> >Here is the current interface:
> >
> >sink(file=NULL, append=FALSE, type = c("output", "message"), split=FALSE)
> >
> >However, reading the implementation there is implicit assumption that type
> >is a single character value:
> >https://github.com/wch/r-source/blob/trunk/src/library/base/R/sink.R#L23
> >
> >I'm finding this very confusing as the interface is giving a default value
> >of a character _vector_ causing the illusion that by default both
> >output/message will be redirected.
> >
> >I'm proposing either a change in the interface so it is a single character
> >(either output or message) or a loop in the implementation on all values
> >in
> >type so it will actually be considered a vector. Here is an example change
> >for the former:
> >
> >
> https://github.com/hhamid/r-source/commit/d3cad22e1b9beca0a55004d74fc95059
> >c279d770#diff-498a99501a04c6d9a66ee95ad6614734L19
> >
> >Just wondering what people think and if this makes sense.
> >
> >Thanks a lot,
> >Hamid
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-devel at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From hhamid at gmail.com  Thu Mar 19 04:15:25 2015
From: hhamid at gmail.com (Hamid Bazzaz)
Date: Wed, 18 Mar 2015 20:15:25 -0700
Subject: [Rd] Proposing a change in the base::sink interface for type
	argument
In-Reply-To: <CAC2h7utZQVYRBdTBpOYiYAUCgE6iSf4Up5pRikDCp=00dCE+vw@mail.gmail.com>
References: <CAJyqX+D7V0HQDz4mctXOQ8GJr6otE+7x9jgb4raSEOpPskyGxg@mail.gmail.com>
	<D12F3B10.122AF9%macqueen1@llnl.gov>
	<CAC2h7utZQVYRBdTBpOYiYAUCgE6iSf4Up5pRikDCp=00dCE+vw@mail.gmail.com>
Message-ID: <CAJyqX+BcdUjftfkjBaTEDWkw7o0tke29Axrvei6ZyARW2Zmfig@mail.gmail.com>

Thanks Don/Kasper for the detailed explanation. Understood the idea behind
match.arg. Meanwhile, it might look handy, the part I am finding tricky is
that it makes the signature of the function misleading. That is, client
would have no idea that a particular arg is accessed through match.arg. So,
unless (A) this is well-documented or (B) one go read the implementation,
he wouldn't know the actual type of the arg is atomic not a vector. To be
fair, in the case of sink, documentation is clear that type is a character.
So, I am dropping my request. But, I probably won't use match.arg myself
given the illusion it causes in the interface of a function.

Thanks,
Hamid

On Wed, Mar 18, 2015 at 4:48 PM, Kasper Daniel Hansen <
kasperdanielhansen at gmail.com> wrote:

> In other words: this is a standard programming paradigm in R/S which
> (unfortunately) is not widely known, based on my network.  It is really
> nice for developers.
>
> Best,
> Kasper
>
> On Wed, Mar 18, 2015 at 5:42 PM, MacQueen, Don <macqueen1 at llnl.gov> wrote:
>
>> It's only an illusion until one actually tries providing a vector.
>>
>>   > sink('foo', type=c('s','m'))
>>   Error in match.arg(type) : 'arg' must be of length 1
>>
>> The additional benefit of match.arg() which you may have not appreciated
>> is that it allows the user to abbreviate. That is,
>>   > sink('foo', type='o')
>> is valid usage. The essential concept of match.arg() is that it tries to
>> match whatever the user supplied with one, and only one, of the values
>> provided in the argument's default value, and that is the value used in
>> the rest of the function.
>>
>> For example:
>> > foo <- function(arg=c('aa','bb','cc')) cat(match.arg(arg),'\n')
>> > foo('a')
>> aa
>> > foo('b')
>> bb
>> > foo('x')
>> Error in match.arg(arg) : 'arg' should be one of "aa", "bb", "cc"
>> >
>> > foo('aa')
>> aa
>>
>>
>>
>>
>> Being "non-intuitive" or puzzling to people coming from other languages is
>> not a sufficient reason for a change. Obviously, different languages have
>> different features, otherwise, why bother to have different languages?
>>
>> And yes, match.arg() is widely used in R. I find it quite useful in my own
>> programming.
>>
>>
>> --
>> Don MacQueen
>>
>> Lawrence Livermore National Laboratory
>> 7000 East Ave., L-627
>> Livermore, CA 94550
>> 925-423-1062
>>
>>
>>
>>
>>
>> On 3/16/15, 10:08 PM, "Hamid Bazzaz" <hhamid at gmail.com> wrote:
>>
>> >Hi folks,
>> >
>> >Here is the current interface:
>> >
>> >sink(file=NULL, append=FALSE, type = c("output", "message"), split=FALSE)
>> >
>> >However, reading the implementation there is implicit assumption that
>> type
>> >is a single character value:
>> >https://github.com/wch/r-source/blob/trunk/src/library/base/R/sink.R#L23
>> >
>> >I'm finding this very confusing as the interface is giving a default
>> value
>> >of a character _vector_ causing the illusion that by default both
>> >output/message will be redirected.
>> >
>> >I'm proposing either a change in the interface so it is a single
>> character
>> >(either output or message) or a loop in the implementation on all values
>> >in
>> >type so it will actually be considered a vector. Here is an example
>> change
>> >for the former:
>> >
>> >
>> https://github.com/hhamid/r-source/commit/d3cad22e1b9beca0a55004d74fc95059
>> >c279d770#diff-498a99501a04c6d9a66ee95ad6614734L19
>> >
>> >Just wondering what people think and if this makes sense.
>> >
>> >Thanks a lot,
>> >Hamid
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-devel at r-project.org mailing list
>> >https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu Mar 19 13:53:47 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 19 Mar 2015 08:53:47 -0400
Subject: [Rd] Windows gcc toolchain for R 3.2.0
In-Reply-To: <55097D3E.7020606@gmail.com>
References: <55097D3E.7020606@gmail.com>
Message-ID: <550AC6DB.60101@gmail.com>

I have updated and moved the notes on the new toolchain.  Their URL is

https://rawgit.com/kevinushey/RToolsToolchainUpdate/master/mingwnotes.html

Thanks to Kevin for setting this up.  Anyone who can solve the problems
on that page, or who finds a new problem, please get in contact with us
by email or on Github.

Duncan Murdoch

On 18/03/2015 9:27 AM, Duncan Murdoch wrote:
> To anyone following the Windows toolchain saga:
> 
> The gcc 4.9.2 toolchain that is currently in Rtools33 has too many 
> incompatibilities with existing code, so we won't be using it in the R 
> 3.2.0 build.  I will soon be uploading to CRAN a new version of Rtools33 
> that is very similar to Rtools32, containing gcc 4.6.3.
> 
> We are continuing to work on the new toolchain, and hope to have it 
> ready before R 3.2.1 is released.
> 
> The known problems are as follows:
> 
>    - C++ code should not call Rf_error(), as it uses longjmp, and the 
> behaviour of longjmp is undefined in C++ when destructors need to be 
> called.  However, a number of packages do call Rf_error, and in gcc 
> 4.6.3, they get away with it.  In our candidate 4.9.2 build, they 
> crashed.  If we can't work around this, I'll suggest that we test for 
> the presence of Rf_error in C++ code, and start issuing warnings or 
> errors when it is seen.  But before we do that, we need a solid replacement.
> 
>   - There are some other crashes that appear to be unrelated, also with 
> C++ code.
> 
>   - There are some subtle differences in arithmetic that result in tests 
> failing.  These may be due to bugs in MinGW-w64 code,
> or may be unavoidable.
> 
> Duncan Murdoch
>


From nashjc at uottawa.ca  Thu Mar 19 14:36:50 2015
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Thu, 19 Mar 2015 09:36:50 -0400
Subject: [Rd] nls
In-Reply-To: <mailman.21.1426762805.8229.r-devel@r-project.org>
References: <mailman.21.1426762805.8229.r-devel@r-project.org>
Message-ID: <550AD0F2.4010608@uottawa.ca>

nls() is using
1) only a Gauss-Newton code which is prone to some glitches
2) approximate derivatives

Package nlmrt uses symbolic derivatives for expressions (you have to
provide Jacobian code for R functions) and an aggressive Marquardt
method to try to reduce the sum of squares. It does return more
information about the problem (singular values of the final Jacobian
and gradient at the proposed solution) but does NOT return the nls
structured object. And it will usually take more time and computing
effort because it tries hard to reduce the SS.

A reproducible example would get you a more informed response.

John Nash


On 15-03-19 07:00 AM, r-devel-request at r-project.org wrote:
> Date: Wed, 18 Mar 2015 14:14:12 +0200
> From: Evans Otieno Ochiaga <evansochiaga at aims.ac.za>
> To: r-devel at r-project.org
> Subject: [Rd] Help
> Message-ID:
> 	<CAObCh3XfvtCz+qWtSS+pSPrhWtUKtdZoYANN=_4AJndziiiDOQ at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
> 
> Hi to All,
> 
> I am fitting some models to a data using non linear least square, and
> whenever i run the command, parameters value have good convergence but I
> get the  error in red as shown below. Kindly how can I fix this problem.
> 
> 
> Convergence of parameter values
> 
> 0.2390121 :  0.1952981 0.9999975 1.0000000
> 0.03716107 :  0.1553976 0.9999910 1.0000000
> 0.009478433 :  0.2011017 0.9999798 1.0000000
> 0.004108196 :  0.2640111 0.9999693 1.0000000
> 0.003705189 :  0.2938360 0.9999652 1.0000000
> 0.003702546 :  0.2965745 0.9999650 1.0000000
> 0.003702546 :  0.2965898 0.9999650 1.0000000
> 0.003702546 :  0.2965898 0.9999650 1.0000000
> 0.003702546 :  0.2965898 0.9999650 1.0000000
> 
> Error in nls(Occupancy ~ 1 - (theta * beta^(2 * Resolution^(1/2)) *
> delta^Resolution),  :
>   step factor 0.000488281 reduced below 'minFactor' of 0.000976562
> 
> Regards,
> 
> 
> 
> 
> *Evans Ochiaga*


From csardi.gabor at gmail.com  Thu Mar 19 16:46:41 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Thu, 19 Mar 2015 11:46:41 -0400
Subject: [Rd] CRAN binary, but no source
Message-ID: <CABtg=K=hjuVSqciab-4WRBVhpjJQRg-H6+R9MGw74QpjY3n_4A@mail.gmail.com>

Hi All,

this is a CRAN question, so I am sorry if this is not the appropriate forum.

I noticed that there is at least one CRAN package that has a binary (OSX
Mavericks) for a version, that does not have any source package on CRAN. Or
at least I am unable to locate it. The package is Rglpk:
http://cran.r-project.org/web/packages/Rglpk/index.html

It offers a binary for 0.5-2, but there is no 0.5-2 source package
anywhere. Is this simply a mistake, or it is OK to have binary-only
packages on CRAN?

Thanks much, Best,
Gabor

	[[alternative HTML version deleted]]


From john.archie.mckown at gmail.com  Thu Mar 19 16:54:12 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Thu, 19 Mar 2015 10:54:12 -0500
Subject: [Rd] CRAN binary, but no source
In-Reply-To: <CABtg=K=hjuVSqciab-4WRBVhpjJQRg-H6+R9MGw74QpjY3n_4A@mail.gmail.com>
References: <CABtg=K=hjuVSqciab-4WRBVhpjJQRg-H6+R9MGw74QpjY3n_4A@mail.gmail.com>
Message-ID: <CAAJSdjiWvxRmu5pgEgN+sGi1waAKLwFsHD2ipC1h5K20mN51HQ@mail.gmail.com>

On Thu, Mar 19, 2015 at 10:46 AM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
> Hi All,
>
> this is a CRAN question, so I am sorry if this is not the appropriate forum.
>
> I noticed that there is at least one CRAN package that has a binary (OSX
> Mavericks) for a version, that does not have any source package on CRAN. Or
> at least I am unable to locate it. The package is Rglpk:
> http://cran.r-project.org/web/packages/Rglpk/index.html

I went there and say a source package:

<quote>

Downloads:

Reference manual:Rglpk.pdf
Package source:Rglpk_0.6-0.tar.gz  <<<!!!!!!!!!!!!!!! SOURCE !!!!!!!!!!!>>>
Windows binaries:r-devel: Rglpk_0.6-0.zip, r-release: Rglpk_0.6-0.zip,
r-oldrel: Rglpk_0.6-0.zip
OS X Snow Leopard binaries:r-release: Rglpk_0.6-0.tgz, r-oldrel: Rglpk_0.6-0.tgz
OS X Mavericks binaries:r-release: Rglpk_0.5-2.tgz
Old sources:Rglpk archive
</quote>

Or: http://cran.r-project.org/src/contrib/Rglpk_0.6-0.tar.gz

>
> It offers a binary for 0.5-2, but there is no 0.5-2 source package
> anywhere. Is this simply a mistake, or it is OK to have binary-only
> packages on CRAN?
>
> Thanks much, Best,
> Gabor
>
>         [[alternative HTML version deleted]]

Please, no HTML, per forum rules.


-- 
If you sent twitter messages while exploring, are you on a textpedition?

He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown


From john.archie.mckown at gmail.com  Thu Mar 19 16:59:18 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Thu, 19 Mar 2015 10:59:18 -0500
Subject: [Rd] CRAN binary, but no source
In-Reply-To: <CAAJSdjiWvxRmu5pgEgN+sGi1waAKLwFsHD2ipC1h5K20mN51HQ@mail.gmail.com>
References: <CABtg=K=hjuVSqciab-4WRBVhpjJQRg-H6+R9MGw74QpjY3n_4A@mail.gmail.com>
	<CAAJSdjiWvxRmu5pgEgN+sGi1waAKLwFsHD2ipC1h5K20mN51HQ@mail.gmail.com>
Message-ID: <CAAJSdjiejsKfXQjK8KpBJFEA2SdnAJy6E7pNambBKPFt6OWHFg@mail.gmail.com>

On Thu, Mar 19, 2015 at 10:54 AM, John McKown
<john.archie.mckown at gmail.com> wrote:
> On Thu, Mar 19, 2015 at 10:46 AM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
>> Hi All,
>>
>> this is a CRAN question, so I am sorry if this is not the appropriate forum.
>>
>> I noticed that there is at least one CRAN package that has a binary (OSX
>> Mavericks) for a version, that does not have any source package on CRAN. Or
>> at least I am unable to locate it. The package is Rglpk:
>> http://cran.r-project.org/web/packages/Rglpk/index.html
>
> I went there and say a source package:
>
> <quote>
>
> Downloads:
>
> Reference manual:Rglpk.pdf
> Package source:Rglpk_0.6-0.tar.gz  <<<!!!!!!!!!!!!!!! SOURCE !!!!!!!!!!!>>>
> Windows binaries:r-devel: Rglpk_0.6-0.zip, r-release: Rglpk_0.6-0.zip,
> r-oldrel: Rglpk_0.6-0.zip
> OS X Snow Leopard binaries:r-release: Rglpk_0.6-0.tgz, r-oldrel: Rglpk_0.6-0.tgz
> OS X Mavericks binaries:r-release: Rglpk_0.5-2.tgz
> Old sources:Rglpk archive
> </quote>
>
> Or: http://cran.r-project.org/src/contrib/Rglpk_0.6-0.tar.gz
>
>>
>> It offers a binary for 0.5-2, but there is no 0.5-2 source package
>> anywhere. Is this simply a mistake, or it is OK to have binary-only
>> packages on CRAN?

OOPS, I saw the 0.6 package source, not 0.5. My mistake. Why not
recompile? Do you require 0.5 for some reason? I would guess that CRAN
requires only the _current_ source, not _every_ source. And
http://cran.r-project.org/src/contrib/Archive/Rglpk/ only has the
source archived for 0.4-1

>>
>> Thanks much, Best,
>> Gabor



-- 
If you sent twitter messages while exploring, are you on a textpedition?

He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown


From csardi.gabor at gmail.com  Thu Mar 19 17:00:48 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Thu, 19 Mar 2015 12:00:48 -0400
Subject: [Rd] CRAN binary, but no source
In-Reply-To: <CAAJSdjiWvxRmu5pgEgN+sGi1waAKLwFsHD2ipC1h5K20mN51HQ@mail.gmail.com>
References: <CABtg=K=hjuVSqciab-4WRBVhpjJQRg-H6+R9MGw74QpjY3n_4A@mail.gmail.com>
	<CAAJSdjiWvxRmu5pgEgN+sGi1waAKLwFsHD2ipC1h5K20mN51HQ@mail.gmail.com>
Message-ID: <CABtg=KkAU4h4Ra8P-HqoA9xcH_P6T1sQVkPMJ3L3EATjxYzyMA@mail.gmail.com>

On Thu, Mar 19, 2015 at 11:54 AM, John McKown <john.archie.mckown at gmail.com>
wrote:

> On Thu, Mar 19, 2015 at 10:46 AM, G?bor Cs?rdi <csardi.gabor at gmail.com>
> wrote:
>
[...]

> > http://cran.r-project.org/web/packages/Rglpk/index.html
>
> I went there and say a source package:
>
> <quote>
>
> Downloads:
>
> Reference manual:Rglpk.pdf
> Package source:Rglpk_0.6-0.tar.gz  <<<!!!!!!!!!!!!!!! SOURCE !!!!!!!!!!!>>>
> Windows binaries:r-devel: Rglpk_0.6-0.zip, r-release: Rglpk_0.6-0.zip,
> r-oldrel: Rglpk_0.6-0.zip
> OS X Snow Leopard binaries:r-release: Rglpk_0.6-0.tgz, r-oldrel:
> Rglpk_0.6-0.tgz
> OS X Mavericks binaries:r-release: Rglpk_0.5-2.tgz
> Old sources:Rglpk archive
> </quote>
>
> Or: http://cran.r-project.org/src/contrib/Rglpk_0.6-0.tar.gz


Yes, sorry, what I meant is that there is no source package for version
version 0.5-2 here:
http://cran.r-project.org/src/contrib/Archive/Rglpk/

I guess it was accidentally deleted, because the CRAN at github mirror has it:
https://github.com/cran/Rglpk/commits/master

Gabor

	[[alternative HTML version deleted]]


From csardi.gabor at gmail.com  Thu Mar 19 17:03:37 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Thu, 19 Mar 2015 12:03:37 -0400
Subject: [Rd] CRAN binary, but no source
In-Reply-To: <CAAJSdjiejsKfXQjK8KpBJFEA2SdnAJy6E7pNambBKPFt6OWHFg@mail.gmail.com>
References: <CABtg=K=hjuVSqciab-4WRBVhpjJQRg-H6+R9MGw74QpjY3n_4A@mail.gmail.com>
	<CAAJSdjiWvxRmu5pgEgN+sGi1waAKLwFsHD2ipC1h5K20mN51HQ@mail.gmail.com>
	<CAAJSdjiejsKfXQjK8KpBJFEA2SdnAJy6E7pNambBKPFt6OWHFg@mail.gmail.com>
Message-ID: <CABtg=K=BLtnBMVgOk1Px+WWjxn3qfA+o2_gLR0u7CP7BghjPEw@mail.gmail.com>

On Thu, Mar 19, 2015 at 11:59 AM, John McKown <john.archie.mckown at gmail.com>
wrote:
[...]
>
> OOPS, I saw the 0.6 package source, not 0.5. My mistake. Why not
> recompile? Do you require 0.5 for some reason? I would guess that CRAN
> requires only the _current_ source, not _every_ source.


Well, it seems to me that for the OSX Mavericks platform 0.5-2 is the
current version.

Gabor

	[[alternative HTML version deleted]]


From dtenenba at fredhutch.org  Thu Mar 19 19:04:01 2015
From: dtenenba at fredhutch.org (Dan Tenenbaum)
Date: Thu, 19 Mar 2015 11:04:01 -0700 (PDT)
Subject: [Rd] CRAN binary, but no source
In-Reply-To: <CABtg=K=BLtnBMVgOk1Px+WWjxn3qfA+o2_gLR0u7CP7BghjPEw@mail.gmail.com>
Message-ID: <679653147.678825.1426788241564.JavaMail.root@fredhutch.org>



----- Original Message -----
> From: "G?bor Cs?rdi" <csardi.gabor at gmail.com>
> To: "John McKown" <john.archie.mckown at gmail.com>
> Cc: r-devel at r-project.org
> Sent: Thursday, March 19, 2015 9:03:37 AM
> Subject: Re: [Rd] CRAN binary, but no source
> 
> On Thu, Mar 19, 2015 at 11:59 AM, John McKown
> <john.archie.mckown at gmail.com>
> wrote:
> [...]
> >
> > OOPS, I saw the 0.6 package source, not 0.5. My mistake. Why not
> > recompile? Do you require 0.5 for some reason? I would guess that
> > CRAN
> > requires only the _current_ source, not _every_ source.
> 
> 
> Well, it seems to me that for the OSX Mavericks platform 0.5-2 is the
> current version.


Because the latest version failed to build on Mavericks:

http://www.r-project.org/nosvn/R.check/r-release-osx-x86_64-mavericks/Rglpk-00install.html

Possibly because a system requirement is not installed.

Dan


> 
> Gabor
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From csardi.gabor at gmail.com  Thu Mar 19 19:15:47 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Thu, 19 Mar 2015 14:15:47 -0400
Subject: [Rd] CRAN binary, but no source
In-Reply-To: <679653147.678825.1426788241564.JavaMail.root@fredhutch.org>
References: <CABtg=K=BLtnBMVgOk1Px+WWjxn3qfA+o2_gLR0u7CP7BghjPEw@mail.gmail.com>
	<679653147.678825.1426788241564.JavaMail.root@fredhutch.org>
Message-ID: <CABtg=K=724CjWJoEY+JuKohiR7B+n736r6b5oqQD1ddjdxMb-A@mail.gmail.com>

On Thu, Mar 19, 2015 at 2:04 PM, Dan Tenenbaum <dtenenba at fredhutch.org>
wrote:
[...]

>
> Because the latest version failed to build on Mavericks:
>
>
> http://www.r-project.org/nosvn/R.check/r-release-osx-x86_64-mavericks/Rglpk-00install.html
>
> Possibly because a system requirement is not installed.
>

Thanks, indeed.

My question is not "why do we have 0.5-2 for OSX Mavericks?", but rather
"where is the source code of Rglpk-0.5-2?

Sorry for not making it clear.

Gabor


>
> Dan
>
>
> >
> > Gabor
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>

	[[alternative HTML version deleted]]


From dtenenba at fredhutch.org  Thu Mar 19 19:19:27 2015
From: dtenenba at fredhutch.org (Dan Tenenbaum)
Date: Thu, 19 Mar 2015 11:19:27 -0700 (PDT)
Subject: [Rd] CRAN binary, but no source
In-Reply-To: <CABtg=K=724CjWJoEY+JuKohiR7B+n736r6b5oqQD1ddjdxMb-A@mail.gmail.com>
Message-ID: <768427295.679273.1426789167842.JavaMail.root@fredhutch.org>



----- Original Message -----
> From: "G?bor Cs?rdi" <csardi.gabor at gmail.com>
> To: "Dan Tenenbaum" <dtenenba at fredhutch.org>
> Cc: r-devel at r-project.org, "John McKown" <john.archie.mckown at gmail.com>
> Sent: Thursday, March 19, 2015 11:15:47 AM
> Subject: Re: [Rd] CRAN binary, but no source
> 
> 
> 
> 
> On Thu, Mar 19, 2015 at 2:04 PM, Dan Tenenbaum <
> dtenenba at fredhutch.org > wrote:
> [...]
> 
> 
> 
> 
> 
> Because the latest version failed to build on Mavericks:
> 
> http://www.r-project.org/nosvn/R.check/r-release-osx-x86_64-mavericks/Rglpk-00install.html
> 
> Possibly because a system requirement is not installed.
> 
> 
> 
> Thanks, indeed.
> 
> 
> My question is not "why do we have 0.5-2 for OSX Mavericks?", but
> rather "where is the source code of Rglpk-0.5-2?
> 

In github? ;-)

Dan


> 
> Sorry for not making it clear.
> 
> 
> Gabor
> 
> 
> 
> Dan
> 
> 
> > 
> > Gabor
> > 
> > [[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> > 
> 
> 


From csardi.gabor at gmail.com  Thu Mar 19 19:45:10 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Thu, 19 Mar 2015 14:45:10 -0400
Subject: [Rd] CRAN binary, but no source
In-Reply-To: <768427295.679273.1426789167842.JavaMail.root@fredhutch.org>
References: <CABtg=K=724CjWJoEY+JuKohiR7B+n736r6b5oqQD1ddjdxMb-A@mail.gmail.com>
	<768427295.679273.1426789167842.JavaMail.root@fredhutch.org>
Message-ID: <CABtg=KkfZBHu_Xy+DYNDK6f1g+S9JU659rOVPpv_RL3W3hb2aA@mail.gmail.com>

On Thu, Mar 19, 2015 at 2:19 PM, Dan Tenenbaum <dtenenba at fredhutch.org>
wrote:
[...]

>
> In github? ;-)
>

Well, that's the thing. If github/cran is a read-only mirror, then should I
delete these versions from there, too? :) On CRAN not just the files are
missing, but these versions are also missing from the RDS database. So they
won't be coming back I assume?

Gabor

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Thu Mar 19 19:55:59 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 19 Mar 2015 19:55:59 +0100
Subject: [Rd] CRAN binary, but no source
In-Reply-To: <CABtg=KkfZBHu_Xy+DYNDK6f1g+S9JU659rOVPpv_RL3W3hb2aA@mail.gmail.com>
References: <CABtg=K=724CjWJoEY+JuKohiR7B+n736r6b5oqQD1ddjdxMb-A@mail.gmail.com>
	<768427295.679273.1426789167842.JavaMail.root@fredhutch.org>
	<CABtg=KkfZBHu_Xy+DYNDK6f1g+S9JU659rOVPpv_RL3W3hb2aA@mail.gmail.com>
Message-ID: <28AFB5E4-0432-4C61-97EB-6E9F3C1A6C58@gmail.com>


> On 19 Mar 2015, at 19:45 , G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
> 
> On Thu, Mar 19, 2015 at 2:19 PM, Dan Tenenbaum <dtenenba at fredhutch.org>
> wrote:
> [...]
> 
>> 
>> In github? ;-)
>> 
> 
> Well, that's the thing. If github/cran is a read-only mirror, then should I
> delete these versions from there, too? :) On CRAN not just the files are
> missing, but these versions are also missing from the RDS database. So they
> won't be coming back I assume?
> 

Perhaps you should stop guessing and start asking the CRAN maintainers? Hint: cran at r-project.org

-pd

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From murdoch.duncan at gmail.com  Thu Mar 19 20:26:06 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 19 Mar 2015 15:26:06 -0400
Subject: [Rd] CRAN binary, but no source
In-Reply-To: <28AFB5E4-0432-4C61-97EB-6E9F3C1A6C58@gmail.com>
References: <CABtg=K=724CjWJoEY+JuKohiR7B+n736r6b5oqQD1ddjdxMb-A@mail.gmail.com>	<768427295.679273.1426789167842.JavaMail.root@fredhutch.org>	<CABtg=KkfZBHu_Xy+DYNDK6f1g+S9JU659rOVPpv_RL3W3hb2aA@mail.gmail.com>
	<28AFB5E4-0432-4C61-97EB-6E9F3C1A6C58@gmail.com>
Message-ID: <550B22CE.8060404@gmail.com>

On 19/03/2015 2:55 PM, peter dalgaard wrote:
> > On 19 Mar 2015, at 19:45 , G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
> >
> > On Thu, Mar 19, 2015 at 2:19 PM, Dan Tenenbaum <dtenenba at fredhutch.org>
> > wrote:
> > [...]
> >
> >>
> >> In github? ;-)
> >>
> >
> > Well, that's the thing. If github/cran is a read-only mirror, then should I
> > delete these versions from there, too? :) On CRAN not just the files are
> > missing, but these versions are also missing from the RDS database. So they
> > won't be coming back I assume?
> >
>
> Perhaps you should stop guessing and start asking the CRAN maintainers? Hint: cran at r-project.org
>

I did: the problem was that the source had a license violation, so CRAN 
can't keep it online.  (It had some GPL-3 code, but was released under 
GPL-2.)

Duncan Murdoch


From maechler at stat.math.ethz.ch  Thu Mar 19 23:02:15 2015
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 19 Mar 2015 23:02:15 +0100
Subject: [Rd] RFC: Matrix package: Matrix products (%*%, crossprod,
 tcrossprod) involving "nsparseMatrix" aka sparse pattern matrices
Message-ID: <CAPRP4-ciBhLvJAEbiwdp+kZF3Sg4nr3NBohmV43P1gQF0pCA3Q@mail.gmail.com>

This is a Request For Comment, also BCCed to 390 package maintainers
of reverse dependencies of the Matrix package.

Most users and package authors working with our 'Matrix' package will
be using it for numerical computations, and so will be using
"dMatrix" (d : double precision) matrix objects  M,   and indirectly, e.g., for
M >= c  will also use "lMatrix" (l: logical i.e.  TRUE/FALSE/NA).
All the following is  **not** affecting those numerical / logical
computations.

A few others will know that we also have "pattern" matrices (purely
binary: TRUE/FALSE, no NA) notably sparse ones, those "ngCMatrix" etc,
all starting with "n" (from ``patter[n]``) which do play a prominent
role in the internal sparse matrix algorithms, notably of the
(underlying C code) CHOLMOD library in the so-called "symbolic"
cholesky decomposition and other such operations. Another reason you
may use them because they are equivalent to incidence matrices of
unweighted (directed or undirected) graphs.

Now, as the subject says, I'm bringing up the topic of what should
happen when these matrices appear in matrix multiplications.
Somewhat by design, but also partly by coincidence,  the *sparse*
pattern matrices multiplication in the Matrix package mostly builds on
the CHOLMOD library `cholmod_ssmult()` function which implements
"Boolean arithmetic" for them, instead of regular arithmetic:
 "+" is logical "or"
 "*" is  logical "and".
Once we map  TRUE <-> 1  and  FALSE <-> 0, the only difference between
boolean and regular arithmetic is that "1+1 = 1" in the (mapped)
boolean arithmetic, because  "TRUE | TRUE" is TRUE in original logic.

The drawback of using the boolean arithmetic here is the "clash" with
the usual numeric arithmetic, and arithmetic in R where logical is
coerced to integer (and that to "double") when certain numerical
functions/operations are used.

A more severe problem --- which I had not been aware of until
relatively recently -- is the fact that  the CHOLMD function
cholmod_ssdmult(A, B)
treats *both* A and B as "pattern" as soon as one of them is a
(sparse) pattern matrix.
And this is - I say - in clear contrast to what R users would expect:
If you multiply a numeric with a "kind of logical" matrix (a pattern
one), you will expect that the
TRUE/FALSE matrix will be treated as a 1/0 matrix because it is
combined with a numeric matrix.
So we could say that in this case, the Matrix package behavior is
clearly bugous .... but still it has been the behavior for the last 10
years or so.

RFC 1: "Change 1":
I currently propose to change this behavior for the upcoming release
of Matrix (version 1.2-0),  though I have no idea if dependent
packages would partly fail their checks or otherwise have changed
behavior subsequently.
The change seems sensible, since I think if your package relied on
this behavior, it was inadvertent and accidental.
Still you may differ in your opinion about this change nr.1

RFC 2: "Change 2":
This change would be more radical, and something I would not plan for
the upcoming release of Matrix, but possibly for an update say one or
two months later or so:  It concerns the matrix products when *both*
matrices are pattern.  A situation where the boolean arithmetic may
really make sense and where indeed packages may have depended on the
current behavior  ("T + T  |--> T"). ... although that is currently
only used for *sparse* pattern matrices, not for dense ones.

Further, it may still seem surprising that matrix multiplication does
not behave numerically for a pair of such matrices, and by the
principle of "least surprise" we should provide the boolean arithmetic
matrix products in another way than  by the   standard  %*%,
crossprod()  and  tcrossprod() functions.
So one possibility could be to change the standard functions to behave
numerically,
and e.g., use   %&%  (replace the numeric "*" by a logical "&")  and
crossprod(A,B, boolean=TRUE),  tcrossprod(A,B, boolean=TRUE)
for the three  boolean arithmetic  version of matrix multiplications.

What do you think about this?   I'm particularly interested to hear
from authors and users of  packages such as 'arules'  which IIRC
explicitly work with sparse pattern matrices.

Thank you for your thoughts and creative ideas,
Martin Maechler, ETH Zurich


From hastie at stanford.edu  Fri Mar 20 00:03:38 2015
From: hastie at stanford.edu (Trevor Hastie)
Date: Thu, 19 Mar 2015 16:03:38 -0700
Subject: [Rd] RFC: Matrix package: Matrix products (%*%, crossprod,
	tcrossprod) involving "nsparseMatrix" aka sparse pattern matrices
In-Reply-To: <CAPRP4-ciBhLvJAEbiwdp+kZF3Sg4nr3NBohmV43P1gQF0pCA3Q@mail.gmail.com>
References: <CAPRP4-ciBhLvJAEbiwdp+kZF3Sg4nr3NBohmV43P1gQF0pCA3Q@mail.gmail.com>
Message-ID: <0E42D6C1-B1F3-4CC6-84EC-279FDD041AE1@stanford.edu>

Hi Martin

I got stung by this last week.
glmnet produces a coefficient matrix of class ?dgCMatrix?
If a predictor matrix was created using sparseMatrix as follows,
one gets unexpected results, as this simple example shows.
My fix was easy (I always convert the predictor matrix to class ?dgCMatrix? now)

Trevor

> y=Matrix(diag(4))
> y
4 x 4 diagonal matrix of class "ddiMatrix"
     [,1] [,2] [,3] [,4]
[1,]    1    .    .    .
[2,]    .    1    .    .
[3,]    .    .    1    .
[4,]    .    .    .    1
> z=sparseMatrix(1:4,1:4)
> z
4 x 4 sparse Matrix of class "ngCMatrix"
            
[1,] | . . .
[2,] . | . .
[3,] . . | .
[4,] . . . |
> beta=as(Matrix(1:4),"dgCMatrix")
> y%*%beta
4 x 1 sparse Matrix of class "dgCMatrix"
      
[1,] 1
[2,] 2
[3,] 3
[4,] 4
> z%*%beta
4 x 1 sparse Matrix of class "ngCMatrix"
      
[1,] |
[2,] |
[3,] |
[4,] |
> 

> On Mar 19, 2015, at 3:02 PM, Martin Maechler <maechler at stat.math.ethz.ch> wrote:
> 
> This is a Request For Comment, also BCCed to 390 package maintainers
> of reverse dependencies of the Matrix package.
> 
> Most users and package authors working with our 'Matrix' package will
> be using it for numerical computations, and so will be using
> "dMatrix" (d : double precision) matrix objects  M,   and indirectly, e.g., for
> M >= c  will also use "lMatrix" (l: logical i.e.  TRUE/FALSE/NA).
> All the following is  **not** affecting those numerical / logical
> computations.
> 
> A few others will know that we also have "pattern" matrices (purely
> binary: TRUE/FALSE, no NA) notably sparse ones, those "ngCMatrix" etc,
> all starting with "n" (from ``patter[n]``) which do play a prominent
> role in the internal sparse matrix algorithms, notably of the
> (underlying C code) CHOLMOD library in the so-called "symbolic"
> cholesky decomposition and other such operations. Another reason you
> may use them because they are equivalent to incidence matrices of
> unweighted (directed or undirected) graphs.
> 
> Now, as the subject says, I'm bringing up the topic of what should
> happen when these matrices appear in matrix multiplications.
> Somewhat by design, but also partly by coincidence,  the *sparse*
> pattern matrices multiplication in the Matrix package mostly builds on
> the CHOLMOD library `cholmod_ssmult()` function which implements
> "Boolean arithmetic" for them, instead of regular arithmetic:
> "+" is logical "or"
> "*" is  logical "and".
> Once we map  TRUE <-> 1  and  FALSE <-> 0, the only difference between
> boolean and regular arithmetic is that "1+1 = 1" in the (mapped)
> boolean arithmetic, because  "TRUE | TRUE" is TRUE in original logic.
> 
> The drawback of using the boolean arithmetic here is the "clash" with
> the usual numeric arithmetic, and arithmetic in R where logical is
> coerced to integer (and that to "double") when certain numerical
> functions/operations are used.
> 
> A more severe problem --- which I had not been aware of until
> relatively recently -- is the fact that  the CHOLMD function
> cholmod_ssdmult(A, B)
> treats *both* A and B as "pattern" as soon as one of them is a
> (sparse) pattern matrix.
> And this is - I say - in clear contrast to what R users would expect:
> If you multiply a numeric with a "kind of logical" matrix (a pattern
> one), you will expect that the
> TRUE/FALSE matrix will be treated as a 1/0 matrix because it is
> combined with a numeric matrix.
> So we could say that in this case, the Matrix package behavior is
> clearly bugous .... but still it has been the behavior for the last 10
> years or so.
> 
> RFC 1: "Change 1":
> I currently propose to change this behavior for the upcoming release
> of Matrix (version 1.2-0),  though I have no idea if dependent
> packages would partly fail their checks or otherwise have changed
> behavior subsequently.
> The change seems sensible, since I think if your package relied on
> this behavior, it was inadvertent and accidental.
> Still you may differ in your opinion about this change nr.1
> 
> RFC 2: "Change 2":
> This change would be more radical, and something I would not plan for
> the upcoming release of Matrix, but possibly for an update say one or
> two months later or so:  It concerns the matrix products when *both*
> matrices are pattern.  A situation where the boolean arithmetic may
> really make sense and where indeed packages may have depended on the
> current behavior  ("T + T  |--> T"). ... although that is currently
> only used for *sparse* pattern matrices, not for dense ones.
> 
> Further, it may still seem surprising that matrix multiplication does
> not behave numerically for a pair of such matrices, and by the
> principle of "least surprise" we should provide the boolean arithmetic
> matrix products in another way than  by the   standard  %*%,
> crossprod()  and  tcrossprod() functions.
> So one possibility could be to change the standard functions to behave
> numerically,
> and e.g., use   %&%  (replace the numeric "*" by a logical "&")  and
> crossprod(A,B, boolean=TRUE),  tcrossprod(A,B, boolean=TRUE)
> for the three  boolean arithmetic  version of matrix multiplications.
> 
> What do you think about this?   I'm particularly interested to hear
> from authors and users of  packages such as 'arules'  which IIRC
> explicitly work with sparse pattern matrices.
> 
> Thank you for your thoughts and creative ideas,
> Martin Maechler, ETH Zurich

 ----------------------------------------------------------------------------------------
  Trevor Hastie                                   hastie at stanford.edu <mailto:hastie at stanford.edu>  
  Professor, Department of Statistics, Stanford University
  Phone: (650) 725-2231                 Fax: (650) 725-8977  
  URL: http://www.stanford.edu/~hastie <http://www-stat.stanford.edu/~hastie>  
   address: room 104, Department of Statistics, Sequoia Hall
           390 Serra Mall, Stanford University, CA 94305-4065  
 --------------------------------------------------------------------------------------




	[[alternative HTML version deleted]]


From mhahsler at lyle.smu.edu  Fri Mar 20 02:15:37 2015
From: mhahsler at lyle.smu.edu (Michael Hahsler)
Date: Thu, 19 Mar 2015 20:15:37 -0500
Subject: [Rd] RFC: Matrix package: Matrix products (%*%, crossprod,
 tcrossprod) involving "nsparseMatrix" aka sparse pattern matrices
In-Reply-To: <CAPRP4-ciBhLvJAEbiwdp+kZF3Sg4nr3NBohmV43P1gQF0pCA3Q@mail.gmail.com>
References: <CAPRP4-ciBhLvJAEbiwdp+kZF3Sg4nr3NBohmV43P1gQF0pCA3Q@mail.gmail.com>
Message-ID: <550B74B9.7080303@lyle.smu.edu>

Hi Martin,

package arules heavily relies on ngCMatrix and uses multiplication and 
addition for logical operations. I think it makes sense that in a mixed 
operation with one dgCMatrix and one ngCMatrix the ngCMatrix should be 
"promoted" to a dgCMatrix.

The current behavior of %*% and friends is in deed confusing:

 > m <- matrix(sample(c(0,1), 5*5, replace=TRUE), nrow=5)
 > x <- as(m, "dgCMatrix")
 > y <- as(m, "ngCMatrix")
 > x %*% y
5 x 5 sparse Matrix of class "ngCMatrix"

[1,] | | | . |
[2,] | | | . |
[3,] . . | | .
[4,] . . . | .
[5,] | | | | |

 > x %*% x
5 x 5 sparse Matrix of class "dgCMatrix"

[1,] 1 2 1 . 2
[2,] 1 3 1 . 3
[3,] . . 1 2 .
[4,] . . . 1 .
[5,] 1 2 2 1 2

We even explicitly coerce in our code ngCMatrix to dgCMatrix to avoid 
this behavior. I think all these operations probably should result 
consistently in a dgCMatrix.

I would love to see | and & for position-wise AND and OR for ngCMatrix.

Thanks,
-Michael

On 03/19/2015 05:02 PM, Martin Maechler wrote:
> This is a Request For Comment, also BCCed to 390 package maintainers
> of reverse dependencies of the Matrix package.
>
> Most users and package authors working with our 'Matrix' package will
> be using it for numerical computations, and so will be using
> "dMatrix" (d : double precision) matrix objects  M,   and indirectly, e.g., for
> M >= c  will also use "lMatrix" (l: logical i.e.  TRUE/FALSE/NA).
> All the following is  **not** affecting those numerical / logical
> computations.
>
> A few others will know that we also have "pattern" matrices (purely
> binary: TRUE/FALSE, no NA) notably sparse ones, those "ngCMatrix" etc,
> all starting with "n" (from ``patter[n]``) which do play a prominent
> role in the internal sparse matrix algorithms, notably of the
> (underlying C code) CHOLMOD library in the so-called "symbolic"
> cholesky decomposition and other such operations. Another reason you
> may use them because they are equivalent to incidence matrices of
> unweighted (directed or undirected) graphs.
>
> Now, as the subject says, I'm bringing up the topic of what should
> happen when these matrices appear in matrix multiplications.
> Somewhat by design, but also partly by coincidence,  the *sparse*
> pattern matrices multiplication in the Matrix package mostly builds on
> the CHOLMOD library `cholmod_ssmult()` function which implements
> "Boolean arithmetic" for them, instead of regular arithmetic:
>   "+" is logical "or"
>   "*" is  logical "and".
> Once we map  TRUE <-> 1  and  FALSE <-> 0, the only difference between
> boolean and regular arithmetic is that "1+1 = 1" in the (mapped)
> boolean arithmetic, because  "TRUE | TRUE" is TRUE in original logic.
>
> The drawback of using the boolean arithmetic here is the "clash" with
> the usual numeric arithmetic, and arithmetic in R where logical is
> coerced to integer (and that to "double") when certain numerical
> functions/operations are used.
>
> A more severe problem --- which I had not been aware of until
> relatively recently -- is the fact that  the CHOLMD function
> cholmod_ssdmult(A, B)
> treats *both* A and B as "pattern" as soon as one of them is a
> (sparse) pattern matrix.
> And this is - I say - in clear contrast to what R users would expect:
> If you multiply a numeric with a "kind of logical" matrix (a pattern
> one), you will expect that the
> TRUE/FALSE matrix will be treated as a 1/0 matrix because it is
> combined with a numeric matrix.
> So we could say that in this case, the Matrix package behavior is
> clearly bugous .... but still it has been the behavior for the last 10
> years or so.
>
> RFC 1: "Change 1":
> I currently propose to change this behavior for the upcoming release
> of Matrix (version 1.2-0),  though I have no idea if dependent
> packages would partly fail their checks or otherwise have changed
> behavior subsequently.
> The change seems sensible, since I think if your package relied on
> this behavior, it was inadvertent and accidental.
> Still you may differ in your opinion about this change nr.1
>
> RFC 2: "Change 2":
> This change would be more radical, and something I would not plan for
> the upcoming release of Matrix, but possibly for an update say one or
> two months later or so:  It concerns the matrix products when *both*
> matrices are pattern.  A situation where the boolean arithmetic may
> really make sense and where indeed packages may have depended on the
> current behavior  ("T + T  |--> T"). ... although that is currently
> only used for *sparse* pattern matrices, not for dense ones.
>
> Further, it may still seem surprising that matrix multiplication does
> not behave numerically for a pair of such matrices, and by the
> principle of "least surprise" we should provide the boolean arithmetic
> matrix products in another way than  by the   standard  %*%,
> crossprod()  and  tcrossprod() functions.
> So one possibility could be to change the standard functions to behave
> numerically,
> and e.g., use   %&%  (replace the numeric "*" by a logical "&")  and
> crossprod(A,B, boolean=TRUE),  tcrossprod(A,B, boolean=TRUE)
> for the three  boolean arithmetic  version of matrix multiplications.
>
> What do you think about this?   I'm particularly interested to hear
> from authors and users of  packages such as 'arules'  which IIRC
> explicitly work with sparse pattern matrices.
>
> Thank you for your thoughts and creative ideas,
> Martin Maechler, ETH Zurich
>

-- 
   Michael Hahsler, Assistant Professor
   Department of Engineering Management, Information, and Systems
   Department of Computer Science and Engineering (by courtesy)
   Bobby B. Lyle School of Engineering
   Southern Methodist University, Dallas, Texas

   office: Caruth Hall, suite 337, room 311
   email:  mhahsler at lyle.smu.edu
   web:    http://lyle.smu.edu/~mhahsler


From ht at heatherturner.net  Fri Mar 20 09:42:21 2015
From: ht at heatherturner.net (Heather Turner)
Date: Fri, 20 Mar 2015 08:42:21 +0000
Subject: [Rd] RFC: Matrix package: Matrix products (%*%, crossprod,
 tcrossprod) involving "nsparseMatrix" aka sparse pattern matrices
In-Reply-To: <CAPRP4-ciBhLvJAEbiwdp+kZF3Sg4nr3NBohmV43P1gQF0pCA3Q@mail.gmail.com>
References: <CAPRP4-ciBhLvJAEbiwdp+kZF3Sg4nr3NBohmV43P1gQF0pCA3Q@mail.gmail.com>
Message-ID: <1426840941.2443851.242906674.0345C347@webmail.messagingengine.com>

We don't use the pattern matrices, nevertheless the proposed changes
sound good to me. I particularly like the suggestion to treat the
matrices as numeric by default, but provide simple ways to use boolean
arithmetic instead - this means that developers have access to both
forms of arithmetic and it will be more obvious from the code which
arithmetic is being used.

Best wishes,

Heather

On Thu, Mar 19, 2015, at 10:02 PM, Martin Maechler wrote:
> This is a Request For Comment, also BCCed to 390 package maintainers
> of reverse dependencies of the Matrix package.
> 
> Most users and package authors working with our 'Matrix' package will
> be using it for numerical computations, and so will be using
> "dMatrix" (d : double precision) matrix objects  M,   and indirectly,
> e.g., for
> M >= c  will also use "lMatrix" (l: logical i.e.  TRUE/FALSE/NA).
> All the following is  **not** affecting those numerical / logical
> computations.
> 
> A few others will know that we also have "pattern" matrices (purely
> binary: TRUE/FALSE, no NA) notably sparse ones, those "ngCMatrix" etc,
> all starting with "n" (from ``patter[n]``) which do play a prominent
> role in the internal sparse matrix algorithms, notably of the
> (underlying C code) CHOLMOD library in the so-called "symbolic"
> cholesky decomposition and other such operations. Another reason you
> may use them because they are equivalent to incidence matrices of
> unweighted (directed or undirected) graphs.
> 
> Now, as the subject says, I'm bringing up the topic of what should
> happen when these matrices appear in matrix multiplications.
> Somewhat by design, but also partly by coincidence,  the *sparse*
> pattern matrices multiplication in the Matrix package mostly builds on
> the CHOLMOD library `cholmod_ssmult()` function which implements
> "Boolean arithmetic" for them, instead of regular arithmetic:
>  "+" is logical "or"
>  "*" is  logical "and".
> Once we map  TRUE <-> 1  and  FALSE <-> 0, the only difference between
> boolean and regular arithmetic is that "1+1 = 1" in the (mapped)
> boolean arithmetic, because  "TRUE | TRUE" is TRUE in original logic.
> 
> The drawback of using the boolean arithmetic here is the "clash" with
> the usual numeric arithmetic, and arithmetic in R where logical is
> coerced to integer (and that to "double") when certain numerical
> functions/operations are used.
> 
> A more severe problem --- which I had not been aware of until
> relatively recently -- is the fact that  the CHOLMD function
> cholmod_ssdmult(A, B)
> treats *both* A and B as "pattern" as soon as one of them is a
> (sparse) pattern matrix.
> And this is - I say - in clear contrast to what R users would expect:
> If you multiply a numeric with a "kind of logical" matrix (a pattern
> one), you will expect that the
> TRUE/FALSE matrix will be treated as a 1/0 matrix because it is
> combined with a numeric matrix.
> So we could say that in this case, the Matrix package behavior is
> clearly bugous .... but still it has been the behavior for the last 10
> years or so.
> 
> RFC 1: "Change 1":
> I currently propose to change this behavior for the upcoming release
> of Matrix (version 1.2-0),  though I have no idea if dependent
> packages would partly fail their checks or otherwise have changed
> behavior subsequently.
> The change seems sensible, since I think if your package relied on
> this behavior, it was inadvertent and accidental.
> Still you may differ in your opinion about this change nr.1
> 
> RFC 2: "Change 2":
> This change would be more radical, and something I would not plan for
> the upcoming release of Matrix, but possibly for an update say one or
> two months later or so:  It concerns the matrix products when *both*
> matrices are pattern.  A situation where the boolean arithmetic may
> really make sense and where indeed packages may have depended on the
> current behavior  ("T + T  |--> T"). ... although that is currently
> only used for *sparse* pattern matrices, not for dense ones.
> 
> Further, it may still seem surprising that matrix multiplication does
> not behave numerically for a pair of such matrices, and by the
> principle of "least surprise" we should provide the boolean arithmetic
> matrix products in another way than  by the   standard  %*%,
> crossprod()  and  tcrossprod() functions.
> So one possibility could be to change the standard functions to behave
> numerically,
> and e.g., use   %&%  (replace the numeric "*" by a logical "&")  and
> crossprod(A,B, boolean=TRUE),  tcrossprod(A,B, boolean=TRUE)
> for the three  boolean arithmetic  version of matrix multiplications.
> 
> What do you think about this?   I'm particularly interested to hear
> from authors and users of  packages such as 'arules'  which IIRC
> explicitly work with sparse pattern matrices.
> 
> Thank you for your thoughts and creative ideas,
> Martin Maechler, ETH Zurich


From maechler at lynne.stat.math.ethz.ch  Fri Mar 20 10:33:58 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Fri, 20 Mar 2015 10:33:58 +0100
Subject: [Rd] RFC: Matrix package: Matrix products (%*%, crossprod,
	tcrossprod) involving "nsparseMatrix" aka sparse pattern matrices
In-Reply-To: <0E42D6C1-B1F3-4CC6-84EC-279FDD041AE1@stanford.edu>
References: <CAPRP4-ciBhLvJAEbiwdp+kZF3Sg4nr3NBohmV43P1gQF0pCA3Q@mail.gmail.com>
	<0E42D6C1-B1F3-4CC6-84EC-279FDD041AE1@stanford.edu>
Message-ID: <21771.59782.204607.923094@stat.math.ethz.ch>

>>>>> Trevor Hastie <hastie at stanford.edu>
>>>>>     on Thu, 19 Mar 2015 16:03:38 -0700 writes:

    > Hi Martin
    > I got stung by this last week.
    > glmnet produces a coefficient matrix of class ?dgCMatrix?
    > If a predictor matrix was created using sparseMatrix as follows,
    > one gets unexpected results, as this simple example shows.
    > My fix was easy (I always convert the predictor matrix to class ?dgCMatrix? now)

    > Trevor

    >> y=Matrix(diag(4))


Considerably faster  (for larger n):   

	  Diagonal(4)

if you want a sparse matrix directly, there are

    .sparseDiagonal() 
and .symDiagonal()  
function


    >> y
    > 4 x 4 diagonal matrix of class "ddiMatrix"
    > [,1] [,2] [,3] [,4]
    > [1,]    1    .    .    .
    > [2,]    .    1    .    .
    > [3,]    .    .    1    .
    > [4,]    .    .    .    1

there's no problem with 'y' which is a "diagonalMatrix" and only
needs  O(n) storage  rather than  diag(n),
right ?

    >> z=sparseMatrix(1:4,1:4)
    >> z
    > 4 x 4 sparse Matrix of class "ngCMatrix"
            
    > [1,] | . . .
    > [2,] . | . .
    > [3,] . . | .
    > [4,] . . . |
    >> beta=as(Matrix(1:4),"dgCMatrix")
    >> y%*%beta
    > 4 x 1 sparse Matrix of class "dgCMatrix"
      
    > [1,] 1
    > [2,] 2
    > [3,] 3
    > [4,] 4
    >> z%*%beta
    > 4 x 1 sparse Matrix of class "ngCMatrix"
      
    > [1,] |
    > [2,] |
    > [3,] |
    > [4,] |
    >> 
Yes, the last one is what I consieder bogous.

Thank you, Trevor, for the feedback!
Martin


    >> On Mar 19, 2015, at 3:02 PM, Martin Maechler <maechler at stat.math.ethz.ch> wrote:
    >> 
    >> This is a Request For Comment, also BCCed to 390 package maintainers
    >> of reverse dependencies of the Matrix package.
    >> 
    >> Most users and package authors working with our 'Matrix' package will
    >> be using it for numerical computations, and so will be using
    >> "dMatrix" (d : double precision) matrix objects  M,   and indirectly, e.g., for
    >> M >= c  will also use "lMatrix" (l: logical i.e.  TRUE/FALSE/NA).
    >> All the following is  **not** affecting those numerical / logical
    >> computations.
    >> 
    >> A few others will know that we also have "pattern" matrices (purely
    >> binary: TRUE/FALSE, no NA) notably sparse ones, those "ngCMatrix" etc,
    >> all starting with "n" (from ``patter[n]``) which do play a prominent
    >> role in the internal sparse matrix algorithms, notably of the
    >> (underlying C code) CHOLMOD library in the so-called "symbolic"
    >> cholesky decomposition and other such operations. Another reason you
    >> may use them because they are equivalent to incidence matrices of
    >> unweighted (directed or undirected) graphs.
    >> 
    >> Now, as the subject says, I'm bringing up the topic of what should
    >> happen when these matrices appear in matrix multiplications.
    >> Somewhat by design, but also partly by coincidence,  the *sparse*
    >> pattern matrices multiplication in the Matrix package mostly builds on
    >> the CHOLMOD library `cholmod_ssmult()` function which implements
    >> "Boolean arithmetic" for them, instead of regular arithmetic:
    >> "+" is logical "or"
    >> "*" is  logical "and".
    >> Once we map  TRUE <-> 1  and  FALSE <-> 0, the only difference between
    >> boolean and regular arithmetic is that "1+1 = 1" in the (mapped)
    >> boolean arithmetic, because  "TRUE | TRUE" is TRUE in original logic.
    >> 
    >> The drawback of using the boolean arithmetic here is the "clash" with
    >> the usual numeric arithmetic, and arithmetic in R where logical is
    >> coerced to integer (and that to "double") when certain numerical
    >> functions/operations are used.
    >> 
    >> A more severe problem --- which I had not been aware of until
    >> relatively recently -- is the fact that  the CHOLMD function
    >> cholmod_ssdmult(A, B)
    >> treats *both* A and B as "pattern" as soon as one of them is a
    >> (sparse) pattern matrix.
    >> And this is - I say - in clear contrast to what R users would expect:
    >> If you multiply a numeric with a "kind of logical" matrix (a pattern
    >> one), you will expect that the
    >> TRUE/FALSE matrix will be treated as a 1/0 matrix because it is
    >> combined with a numeric matrix.
    >> So we could say that in this case, the Matrix package behavior is
    >> clearly bugous .... but still it has been the behavior for the last 10
    >> years or so.
    >> 
    >> RFC 1: "Change 1":
    >> I currently propose to change this behavior for the upcoming release
    >> of Matrix (version 1.2-0),  though I have no idea if dependent
    >> packages would partly fail their checks or otherwise have changed
    >> behavior subsequently.
    >> The change seems sensible, since I think if your package relied on
    >> this behavior, it was inadvertent and accidental.
    >> Still you may differ in your opinion about this change nr.1
    >> 
    >> RFC 2: "Change 2":
    >> This change would be more radical, and something I would not plan for
    >> the upcoming release of Matrix, but possibly for an update say one or
    >> two months later or so:  It concerns the matrix products when *both*
    >> matrices are pattern.  A situation where the boolean arithmetic may
    >> really make sense and where indeed packages may have depended on the
    >> current behavior  ("T + T  |--> T"). ... although that is currently
    >> only used for *sparse* pattern matrices, not for dense ones.
    >> 
    >> Further, it may still seem surprising that matrix multiplication does
    >> not behave numerically for a pair of such matrices, and by the
    >> principle of "least surprise" we should provide the boolean arithmetic
    >> matrix products in another way than  by the   standard  %*%,
    >> crossprod()  and  tcrossprod() functions.
    >> So one possibility could be to change the standard functions to behave
    >> numerically,
    >> and e.g., use   %&%  (replace the numeric "*" by a logical "&")  and
    >> crossprod(A,B, boolean=TRUE),  tcrossprod(A,B, boolean=TRUE)
    >> for the three  boolean arithmetic  version of matrix multiplications.
    >> 
    >> What do you think about this?   I'm particularly interested to hear
    >> from authors and users of  packages such as 'arules'  which IIRC
    >> explicitly work with sparse pattern matrices.
    >> 
    >> Thank you for your thoughts and creative ideas,
    >> Martin Maechler, ETH Zurich

    > ----------------------------------------------------------------------------------------
    > Trevor Hastie                                   hastie at stanford.edu <mailto:hastie at stanford.edu>  
    > Professor, Department of Statistics, Stanford University
    > Phone: (650) 725-2231                 Fax: (650) 725-8977  
    > URL: http://www.stanford.edu/~hastie <http://www-stat.stanford.edu/~hastie>  
    > address: room 104, Department of Statistics, Sequoia Hall
    > 390 Serra Mall, Stanford University, CA 94305-4065  
    > --------------------------------------------------------------------------------------


From maechler at lynne.stat.math.ethz.ch  Fri Mar 20 11:07:32 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Fri, 20 Mar 2015 11:07:32 +0100
Subject: [Rd] RFC: Matrix package: Matrix products (%*%, crossprod,
 tcrossprod) involving "nsparseMatrix" aka sparse pattern matrices
In-Reply-To: <550B74B9.7080303@lyle.smu.edu>
References: <CAPRP4-ciBhLvJAEbiwdp+kZF3Sg4nr3NBohmV43P1gQF0pCA3Q@mail.gmail.com>
	<550B74B9.7080303@lyle.smu.edu>
Message-ID: <21771.61796.717026.182659@stat.math.ethz.ch>

>>>>> "MH" == Michael Hahsler <mhahsler at lyle.smu.edu>
>>>>>     on Thu, 19 Mar 2015 20:15:37 -0500 writes:

    MH> Hi Martin,
    MH> package arules heavily relies on ngCMatrix and uses multiplication and 
    MH> addition for logical operations. I think it makes sense that in a mixed 
    MH> operation with one dgCMatrix and one ngCMatrix the ngCMatrix should be 
    MH> "promoted" to a dgCMatrix.

    MH> The current behavior of %*% and friends is in deed confusing:

    >> m <- matrix(sample(c(0,1), 5*5, replace=TRUE), nrow=5)
    >> x <- as(m, "dgCMatrix")
    >> y <- as(m, "ngCMatrix")
    >> x %*% y
    MH> 5 x 5 sparse Matrix of class "ngCMatrix"

    MH> [1,] | | | . |
    MH> [2,] | | | . |
    MH> [3,] . . | | .
    MH> [4,] . . . | .
    MH> [5,] | | | | |

    >> x %*% x
    MH> 5 x 5 sparse Matrix of class "dgCMatrix"

    MH> [1,] 1 2 1 . 2
    MH> [2,] 1 3 1 . 3
    MH> [3,] . . 1 2 .
    MH> [4,] . . . 1 .
    MH> [5,] 1 2 2 1 2

Indeed, that is not what one should expect.

    MH> We even explicitly coerce in our code ngCMatrix to dgCMatrix to avoid 
    MH> this behavior. I think all these operations probably should result 
    MH> consistently in a dgCMatrix.

Eventually.   As I said, it *is* useful to work with boolean
arithmetic in some cases here, so I do want to provide that
.. hopefully entirely consistently as well in the future, but
longer term not via '%*%'

    MH> I would love to see | and & for position-wise AND and OR for ngCMatrix.

Well, why don't you look? ;-)

These have worked for a long time already! (I checked a version
from 2008)

Thanks a lot, Michael, for your valuable feedback.
Martin

    MH> Thanks,
    MH> -Michael

    MH> On 03/19/2015 05:02 PM, Martin Maechler wrote:
    >> This is a Request For Comment, also BCCed to 390 package maintainers
    >> of reverse dependencies of the Matrix package.
    >> 
    >> Most users and package authors working with our 'Matrix' package will
    >> be using it for numerical computations, and so will be using
    >> "dMatrix" (d : double precision) matrix objects  M,   and indirectly, e.g., for
    >> M >= c  will also use "lMatrix" (l: logical i.e.  TRUE/FALSE/NA).
    >> All the following is  **not** affecting those numerical / logical
    >> computations.
    >> 
    >> A few others will know that we also have "pattern" matrices (purely
    >> binary: TRUE/FALSE, no NA) notably sparse ones, those "ngCMatrix" etc,
    >> all starting with "n" (from ``patter[n]``) which do play a prominent
    >> role in the internal sparse matrix algorithms, notably of the
    >> (underlying C code) CHOLMOD library in the so-called "symbolic"
    >> cholesky decomposition and other such operations. Another reason you
    >> may use them because they are equivalent to incidence matrices of
    >> unweighted (directed or undirected) graphs.
    >> 
    >> Now, as the subject says, I'm bringing up the topic of what should
    >> happen when these matrices appear in matrix multiplications.
    >> Somewhat by design, but also partly by coincidence,  the *sparse*
    >> pattern matrices multiplication in the Matrix package mostly builds on
    >> the CHOLMOD library `cholmod_ssmult()` function which implements
    >> "Boolean arithmetic" for them, instead of regular arithmetic:
    >> "+" is logical "or"
    >> "*" is  logical "and".
    >> Once we map  TRUE <-> 1  and  FALSE <-> 0, the only difference between
    >> boolean and regular arithmetic is that "1+1 = 1" in the (mapped)
    >> boolean arithmetic, because  "TRUE | TRUE" is TRUE in original logic.
    >> 
    >> The drawback of using the boolean arithmetic here is the "clash" with
    >> the usual numeric arithmetic, and arithmetic in R where logical is
    >> coerced to integer (and that to "double") when certain numerical
    >> functions/operations are used.
    >> 
    >> A more severe problem --- which I had not been aware of until
    >> relatively recently -- is the fact that  the CHOLMD function
    >> cholmod_ssdmult(A, B)
    >> treats *both* A and B as "pattern" as soon as one of them is a
    >> (sparse) pattern matrix.
    >> And this is - I say - in clear contrast to what R users would expect:
    >> If you multiply a numeric with a "kind of logical" matrix (a pattern
    >> one), you will expect that the
    >> TRUE/FALSE matrix will be treated as a 1/0 matrix because it is
    >> combined with a numeric matrix.
    >> So we could say that in this case, the Matrix package behavior is
    >> clearly bugous .... but still it has been the behavior for the last 10
    >> years or so.
    >> 
    >> RFC 1: "Change 1":
    >> I currently propose to change this behavior for the upcoming release
    >> of Matrix (version 1.2-0),  though I have no idea if dependent
    >> packages would partly fail their checks or otherwise have changed
    >> behavior subsequently.
    >> The change seems sensible, since I think if your package relied on
    >> this behavior, it was inadvertent and accidental.
    >> Still you may differ in your opinion about this change nr.1
    >> 
    >> RFC 2: "Change 2":
    >> This change would be more radical, and something I would not plan for
    >> the upcoming release of Matrix, but possibly for an update say one or
    >> two months later or so:  It concerns the matrix products when *both*
    >> matrices are pattern.  A situation where the boolean arithmetic may
    >> really make sense and where indeed packages may have depended on the
    >> current behavior  ("T + T  |--> T"). ... although that is currently
    >> only used for *sparse* pattern matrices, not for dense ones.
    >> 
    >> Further, it may still seem surprising that matrix multiplication does
    >> not behave numerically for a pair of such matrices, and by the
    >> principle of "least surprise" we should provide the boolean arithmetic
    >> matrix products in another way than  by the   standard  %*%,
    >> crossprod()  and  tcrossprod() functions.
    >> So one possibility could be to change the standard functions to behave
    >> numerically,
    >> and e.g., use   %&%  (replace the numeric "*" by a logical "&")  and
    >> crossprod(A,B, boolean=TRUE),  tcrossprod(A,B, boolean=TRUE)
    >> for the three  boolean arithmetic  version of matrix multiplications.
    >> 
    >> What do you think about this?   I'm particularly interested to hear
    >> from authors and users of  packages such as 'arules'  which IIRC
    >> explicitly work with sparse pattern matrices.
    >> 
    >> Thank you for your thoughts and creative ideas,
    >> Martin Maechler, ETH Zurich
    >> 

    MH> -- 
    MH> Michael Hahsler, Assistant Professor
    MH> Department of Engineering Management, Information, and Systems
    MH> Department of Computer Science and Engineering (by courtesy)
    MH> Bobby B. Lyle School of Engineering
    MH> Southern Methodist University, Dallas, Texas

    MH> office: Caruth Hall, suite 337, room 311
    MH> email:  mhahsler at lyle.smu.edu
    MH> web:    http://lyle.smu.edu/~mhahsler


From ripley at stats.ox.ac.uk  Fri Mar 20 16:03:01 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 20 Mar 2015 15:03:01 +0000
Subject: [Rd] CRAN binary, but no source
In-Reply-To: <550B22CE.8060404@gmail.com>
References: <CABtg=K=724CjWJoEY+JuKohiR7B+n736r6b5oqQD1ddjdxMb-A@mail.gmail.com>	<768427295.679273.1426789167842.JavaMail.root@fredhutch.org>	<CABtg=KkfZBHu_Xy+DYNDK6f1g+S9JU659rOVPpv_RL3W3hb2aA@mail.gmail.com>	<28AFB5E4-0432-4C61-97EB-6E9F3C1A6C58@gmail.com>
	<550B22CE.8060404@gmail.com>
Message-ID: <550C36A5.5020503@stats.ox.ac.uk>

On 19/03/2015 19:26, Duncan Murdoch wrote:
> On 19/03/2015 2:55 PM, peter dalgaard wrote:
>> > On 19 Mar 2015, at 19:45 , G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
>> >
>> > On Thu, Mar 19, 2015 at 2:19 PM, Dan Tenenbaum <dtenenba at fredhutch.org>
>> > wrote:
>> > [...]
>> >
>> >>
>> >> In github? ;-)
>> >>
>> >
>> > Well, that's the thing. If github/cran is a read-only mirror, then
>> should I
>> > delete these versions from there, too? :) On CRAN not just the files
>> are
>> > missing, but these versions are also missing from the RDS database.
>> So they
>> > won't be coming back I assume?
>> >
>>
>> Perhaps you should stop guessing and start asking the CRAN
>> maintainers? Hint: cran at r-project.org
>>
>
> I did: the problem was that the source had a license violation, so CRAN
> can't keep it online.  (It had some GPL-3 code, but was released under
> GPL-2.)

Two places to look for such information on CRAN:

- Where a fair amount of information needs to be given (like exactly 
which versions have been removed), there may be a README in the Archive 
directory.  E.g. 
http://cran.r-project.org/src/contrib/Archive/sdcTable/README , and I 
have added one for Rglpk.

- There is a DCF file http://cran.r-project.org/src/contrib/PACKAGES.in 
which acts as the database which R CMD check --as-cran consults.  That 
contains concise records of archival and removal.  Its coverage is 
pretty good for the last three years.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From csardi.gabor at gmail.com  Fri Mar 20 16:14:14 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Fri, 20 Mar 2015 11:14:14 -0400
Subject: [Rd] CRAN binary, but no source
In-Reply-To: <550C36A5.5020503@stats.ox.ac.uk>
References: <CABtg=K=724CjWJoEY+JuKohiR7B+n736r6b5oqQD1ddjdxMb-A@mail.gmail.com>
	<768427295.679273.1426789167842.JavaMail.root@fredhutch.org>
	<CABtg=KkfZBHu_Xy+DYNDK6f1g+S9JU659rOVPpv_RL3W3hb2aA@mail.gmail.com>
	<28AFB5E4-0432-4C61-97EB-6E9F3C1A6C58@gmail.com>
	<550B22CE.8060404@gmail.com> <550C36A5.5020503@stats.ox.ac.uk>
Message-ID: <CABtg=Km-P-Leh6a=P--HvmOb34qDHwnqJ+mSQcY7K4AkQXzLJw@mail.gmail.com>

On Fri, Mar 20, 2015 at 11:03 AM, Prof Brian Ripley <ripley at stats.ox.ac.uk>
wrote:
[...]
>
> Two places to look for such information on CRAN:
>
> - Where a fair amount of information needs to be given (like exactly which
> versions have been removed), there may be a README in the Archive
> directory.  E.g. http://cran.r-project.org/src/contrib/Archive/sdcTable/
> README , and I have added one for Rglpk.
>
> - There is a DCF file http://cran.r-project.org/src/contrib/PACKAGES.in
> which acts as the database which R CMD check --as-cran consults.  That
> contains concise records of archival and removal.  Its coverage is pretty
> good for the last three years.


Ah, yes, I forgot about PACKAGES.in. (Which I actually parse in another
project.) I guess I was mostly puzzled by the non-removal of the binary
package. (Which is just temporary, and it will be removed as soon as 0.6-0
is available for that platform.)

Thanks to everyone who replied, including CRAN maintainers in private.
Gabor

	[[alternative HTML version deleted]]


From skyebend at skyeome.net  Fri Mar 20 16:40:42 2015
From: skyebend at skyeome.net (Skye Bender-deMoll)
Date: Fri, 20 Mar 2015 08:40:42 -0700
Subject: [Rd] quieting the "apparent S3 methods" warning
Message-ID: <550C3F7A.8030406@skyeome.net>

Dear R-devel,
  Recent versions of R CMD check have been flagging apparent S3 methods 
that are not registered in the NAMESPACE as such.  In most situations 
this is very helpful.  However, I have few cases in existing packages 
where we have unfortunately named functions using a "." in them that 
makes them appear as S3 methods when they are not.

As there is no existing class corresponding to the last suffix of the 
function, I could quiet the warning by registering the "fake" S3 
function, but this seems contrary to the intent and not very future-proof.

Is there a way to register methods as "non-S3 methods" so as to block 
any potential S3 dispatch? Or is there any other way to quiet the 
warning?  In the long term, I imagine we can deprecate the function and 
replace it with a better name?

best,
  -skye


From peter.ruckdeschel at itwm.fraunhofer.de  Fri Mar 20 20:04:01 2015
From: peter.ruckdeschel at itwm.fraunhofer.de (Dr. Peter Ruckdeschel)
Date: Fri, 20 Mar 2015 20:04:01 +0100
Subject: [Rd] RFC: Matrix package: Matrix products (%*%, crossprod,
 tcrossprod) involving "nsparseMatrix" aka sparse pattern matrices
In-Reply-To: <CAPRP4-ciBhLvJAEbiwdp+kZF3Sg4nr3NBohmV43P1gQF0pCA3Q@mail.gmail.com>
References: <CAPRP4-ciBhLvJAEbiwdp+kZF3Sg4nr3NBohmV43P1gQF0pCA3Q@mail.gmail.com>
Message-ID: <550C6F21.1090102@itwm.fraunhofer.de>

Hi Martin,

many thanks to you and Doug for providing the Matrix package
in the first place, and, second, for taking us into this decision.

I have only some minor comments to make:

+ wherever there is a usual function call involved, using an
   argument "boolean" as you proposed seems perfect to me

+ default behaviour and default values in function arguments
   should, even if bugous, stick to the old behaviour for backward
   compatibility right now, but you might still want to change this
   after a long enough announcement period

+ when it comes to arithmetic symbols, something like %&%
   certainly is nice to have, but the inadvertent user (like me,
   probably) would not know of this, unless this is documented
   at a prominent place

+ although this is against the functional paradigm of R, I would
   --exceptionally-- opt for a global option to change the behaviour
   (a) in function argument defaults and (b), more importantly, in
    binary arithmetic operators like %*%, *, +
    --- this way everybody can have the Matrix flavour he likes
 

just my 2c,
best regards,
Peter


Am 19.03.2015 um 23:02 schrieb Martin Maechler:
> This is a Request For Comment, also BCCed to 390 package maintainers
> of reverse dependencies of the Matrix package.
>
> Most users and package authors working with our 'Matrix' package will
> be using it for numerical computations, and so will be using
> "dMatrix" (d : double precision) matrix objects  M,   and indirectly, e.g., for
> M >= c  will also use "lMatrix" (l: logical i.e.  TRUE/FALSE/NA).
> All the following is  **not** affecting those numerical / logical
> computations.
>
> A few others will know that we also have "pattern" matrices (purely
> binary: TRUE/FALSE, no NA) notably sparse ones, those "ngCMatrix" etc,
> all starting with "n" (from ``patter[n]``) which do play a prominent
> role in the internal sparse matrix algorithms, notably of the
> (underlying C code) CHOLMOD library in the so-called "symbolic"
> cholesky decomposition and other such operations. Another reason you
> may use them because they are equivalent to incidence matrices of
> unweighted (directed or undirected) graphs.
>
> Now, as the subject says, I'm bringing up the topic of what should
> happen when these matrices appear in matrix multiplications.
> Somewhat by design, but also partly by coincidence,  the *sparse*
> pattern matrices multiplication in the Matrix package mostly builds on
> the CHOLMOD library `cholmod_ssmult()` function which implements
> "Boolean arithmetic" for them, instead of regular arithmetic:
>  "+" is logical "or"
>  "*" is  logical "and".
> Once we map  TRUE <-> 1  and  FALSE <-> 0, the only difference between
> boolean and regular arithmetic is that "1+1 = 1" in the (mapped)
> boolean arithmetic, because  "TRUE | TRUE" is TRUE in original logic.
>
> The drawback of using the boolean arithmetic here is the "clash" with
> the usual numeric arithmetic, and arithmetic in R where logical is
> coerced to integer (and that to "double") when certain numerical
> functions/operations are used.
>
> A more severe problem --- which I had not been aware of until
> relatively recently -- is the fact that  the CHOLMD function
> cholmod_ssdmult(A, B)
> treats *both* A and B as "pattern" as soon as one of them is a
> (sparse) pattern matrix.
> And this is - I say - in clear contrast to what R users would expect:
> If you multiply a numeric with a "kind of logical" matrix (a pattern
> one), you will expect that the
> TRUE/FALSE matrix will be treated as a 1/0 matrix because it is
> combined with a numeric matrix.
> So we could say that in this case, the Matrix package behavior is
> clearly bugous .... but still it has been the behavior for the last 10
> years or so.
>
> RFC 1: "Change 1":
> I currently propose to change this behavior for the upcoming release
> of Matrix (version 1.2-0),  though I have no idea if dependent
> packages would partly fail their checks or otherwise have changed
> behavior subsequently.
> The change seems sensible, since I think if your package relied on
> this behavior, it was inadvertent and accidental.
> Still you may differ in your opinion about this change nr.1
>
> RFC 2: "Change 2":
> This change would be more radical, and something I would not plan for
> the upcoming release of Matrix, but possibly for an update say one or
> two months later or so:  It concerns the matrix products when *both*
> matrices are pattern.  A situation where the boolean arithmetic may
> really make sense and where indeed packages may have depended on the
> current behavior  ("T + T  |--> T"). ... although that is currently
> only used for *sparse* pattern matrices, not for dense ones.
>
> Further, it may still seem surprising that matrix multiplication does
> not behave numerically for a pair of such matrices, and by the
> principle of "least surprise" we should provide the boolean arithmetic
> matrix products in another way than  by the   standard  %*%,
> crossprod()  and  tcrossprod() functions.
> So one possibility could be to change the standard functions to behave
> numerically,
> and e.g., use   %&%  (replace the numeric "*" by a logical "&")  and
> crossprod(A,B, boolean=TRUE),  tcrossprod(A,B, boolean=TRUE)
> for the three  boolean arithmetic  version of matrix multiplications.
>
> What do you think about this?   I'm particularly interested to hear
> from authors and users of  packages such as 'arules'  which IIRC
> explicitly work with sparse pattern matrices.
>
> Thank you for your thoughts and creative ideas,
> Martin Maechler, ETH Zurich


-- 
Dr. habil. Peter Ruckdeschel, Abteilung Finanzmathematik, F3.17
Fraunhofer ITWM, Fraunhofer Platz 1, 67663 Kaiserslautern
Telefon:  +49 631/31600-4699   Fax:  +49 631/31600-5699
E-Mail :  peter.ruckdeschel at itwm.fraunhofer.de
http://www.itwm.fraunhofer.de/abteilungen/finanzmathematik/mitarbeiterinnen/mitarbeiter/dr-peter-ruckdeschel.html


From jeffrey.horner at gmail.com  Fri Mar 20 22:35:18 2015
From: jeffrey.horner at gmail.com (Jeffrey Horner)
Date: Fri, 20 Mar 2015 16:35:18 -0500
Subject: [Rd] R with Array Hashes
In-Reply-To: <CAD+yNFgEPfhP-2KsiyHiRKKJMONoO9dSieA6NnaoTbp9ZzoXsg@mail.gmail.com>
References: <CAD+yNFgdq1jf-epjempOe78-xC-t-T0dpz_tg9fAEF5niTOWAg@mail.gmail.com>
	<21753.51605.181454.609423@max.nulle.part>
	<CAD+yNFgEPfhP-2KsiyHiRKKJMONoO9dSieA6NnaoTbp9ZzoXsg@mail.gmail.com>
Message-ID: <CAD+yNFiTve6cnWtNXq+2d_GrrJ3candAcrZK+EZjTYq8dceDbg@mail.gmail.com>

On Fri, Mar 6, 2015 at 10:03 AM, Jeffrey Horner
<jeffrey.horner at gmail.com> wrote:
> On Fri, Mar 6, 2015 at 9:36 AM, Dirk Eddelbuettel <edd at debian.org> wrote:
[...]
>> When you asked about benchmark code on Twitter, I shared the somewhat
>> well-known (but no R ...) http://benchmarksgame.alioth.debian.org/
>> Did you write new benchmarks?  Did you try the ones once assembled by Simon?

I added some runs of that benchmark which you can view here:

https://github.com/jeffreyhorner/R-Array-Hash/tree/master/benchmarks/runs

Scope out the ones that start with R-benchmark-25.*

R-Array-Hash and R-devel are very similar using ATLAS.

[...]
>> Dirk
>>
>> --
>> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From bbolker at gmail.com  Sun Mar 22 17:45:53 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 22 Mar 2015 12:45:53 -0400
Subject: [Rd] robust updating methods
Message-ID: <550EF1C1.7080805@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

WARNING: this is long.  Sorry I couldn't find a way to compress it.

Is there a reasonable way to design an update method so that it's
robust to a variety of reasonable use cases of generating calls or
data inside or outside a function?  Is it even possible?  Should I
just tell users "don't do that"?

* `update.default()` uses `eval(call, parent.frame())`; this fails
  when the call depends on objects that were defined in a different
  environment (e.g., when the data are generated and the model
  initially fitted within a function scope)

* an alternative is to store the original environment in which the
  fitting is done in the environment of the formula and use
  `eval(call, env=environment(formula(object)))`; this fails if the
  user tries to update the model originally fitted outside a function
  with data modified within a function ...

* I think I've got a hack that works below, which first tries in the
  environment of the formula and falls back to the parent frame if
  that fails, but I wonder if I'm missing something much simpler ..

  Thoughts?  My understanding of environments and frames is still,
after all these years, not what it should be ...

I've thought of some other workarounds, none entirely satisfactory:

* force evaluation of all elements in the original call
    * printing components of the call can get ugly (can save the
original call before evaluating)
    * large objects in the call get duplicated
* don't use `eval(call)` for updates; instead try to store everything
internally
    * this works OK but has the same drawback of potentially storing
large extra copies
    * we could try to use the model frame (which is stored already),
but there are issues with this (the basis of a whole separate rant)
because the model frame stores something in between predictor
variables and input variables. For example

   d <- data.frame(y=1:10,x=runif(10))
   names(model.frame(lm(y~log(x),data=d)))
   ## "y" "log(x)"

So if we wanted to do something like update to "y ~ sqrt(x)",
it wouldn't work ...

==================
update.envformula <- function(object,...) {
    extras <- match.call(expand.dots = FALSE)$...
    call <- getCall(object)
    for (i in names(extras)) {
        existing <- !is.na(match(names(extras), names(call)))
        for (a in names(extras)[existing]) call[[a]] <- extras[[a]]
        if (any(!existing)) {
            call <- c(as.list(call), extras[!existing])
            call <- as.call(call)
        }
    }
    eval(call, env=environment(formula(object)))
    ## enclos=parent.frame() doesn't help
}

update.both <- function(object,...) {
    extras <- match.call(expand.dots = FALSE)$...
    call <- getCall(object)
    for (i in names(extras)) {
        existing <- !is.na(match(names(extras), names(call)))
        for (a in names(extras)[existing]) call[[a]] <- extras[[a]]
        if (any(!existing)) {
            call <- c(as.list(call), extras[!existing])
            call <- as.call(call)
        }
    }
    pf <- parent.frame()  ## save parent frame in case we need it
    tryCatch(eval(call, env=environment(formula(object))),
             error=function(e) {
                 eval(call, pf)
             })
}

### TEST CASES

set.seed(101)
d <- data.frame(x=1:10,y=rnorm(10))
m1 <- lm(y~x,data=d)

##' define data within function, return fitted model
f1 <- function() {
    d2 <- d
    lm(y~x,data=d2)
    return(lm(y~x,data=d2))
}
##' define (and modify) data within function, try to update
##' model fitted elsewhere
f2 <- function(m) {
    d2 <- d; d2[1] <- d2[1]+0 ## force copy
    update.default(m,data=d2)
}
##' define (and modify) data within function, try to update
##' model fitted elsewhere (use envformula)
f3 <- function(m) {
    d2 <- d; d2[1] <- d2[1]+0 ## force copy
    update.envformula(m,data=d2)
}

##' hack: first try the formula, then the parent frame
##' if that doesn't work for any reason
f4 <- function(m) {
    d2 <- d; d2[1] <- d2[1]+0 ## force copy
    update.both(m,data=d2)
}

## Case 1: fit within function
m2 <- f1()
try(update.default(m2))       ## default: object 'd2' not found
m3A <- update.envformula(m2)  ## envformula: works
m3B <- update.both(m2)        ## works

## Case 2: update within function
m4A <- f2(m1)  ## default: works
try(f3(m1))    ## envformula: object 'd2' not found
m4B <- f4(m1)  ## works

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVDvHBAAoJEOCV5YRblxUHtnwH/2452Fqmsm//LxNeXxhNrs/G
3ss8rPV2EVJQFjAyO34zzuYZVp1mWlgt7C1L7nXcH4lcf66gYfj75X/yVvMxxwmS
uXEP9HKr4TR5D6Ukf16qqtK41PhTkjS+RDaEpj6BVq9YxlYb53kSjKF+anrf08SL
K6i2L+c4nJIwk56CCp0Re/EIDCNeW5lXYX9jdPAalMoxSHTG8wmytvq0x89+KsRC
aUTpdylPka70vwBQle9W4OEyhBpADIHfEg8csYXZ/MeOKM0bqCRu2IU3OyuCsxyX
Pbo3w1Z7x0e+2WoX4PcltweYK4PJC9O10v+RKYaI5YRy1dFWMQWcPoAKRKf7jwY=
=S7zP
-----END PGP SIGNATURE-----


From richierocks at gmail.com  Mon Mar 23 14:17:37 2015
From: richierocks at gmail.com (Richard Cotton)
Date: Mon, 23 Mar 2015 16:17:37 +0300
Subject: [Rd] Possible values for R version status
Message-ID: <CAPp_+=fr2DhNsrQqSkEw=-LDkkAdJTmE9J4RNiFrbeENZp7jqw@mail.gmail.com>

Is there a complete list somewhere of the possible values for R's
status, as returned by version$status?

I know about these values:
Stable: ""
Devel: "Under development (unstable)"
Patched: "Patched"
Release candidate: "RC"
Alpha: "Alpha"

Are there any others that I've missed?


From murdoch.duncan at gmail.com  Mon Mar 23 14:36:58 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 23 Mar 2015 09:36:58 -0400
Subject: [Rd] Possible values for R version status
In-Reply-To: <CAPp_+=fr2DhNsrQqSkEw=-LDkkAdJTmE9J4RNiFrbeENZp7jqw@mail.gmail.com>
References: <CAPp_+=fr2DhNsrQqSkEw=-LDkkAdJTmE9J4RNiFrbeENZp7jqw@mail.gmail.com>
Message-ID: <551016FA.2090906@gmail.com>

On 23/03/2015 9:17 AM, Richard Cotton wrote:
> Is there a complete list somewhere of the possible values for R's
> status, as returned by version$status?
>
> I know about these values:
> Stable: ""
> Devel: "Under development (unstable)"
> Patched: "Patched"
> Release candidate: "RC"
> Alpha: "Alpha"

I don't think we use "Alpha", I think it's lowercase.  There is also 
"beta".  You can see the list at 
http://developer.r-project.org/release-checklist.html, in the lines that 
describe the version being set.

Duncan Murdoch


From mark.vanderloo at gmail.com  Mon Mar 23 14:44:51 2015
From: mark.vanderloo at gmail.com (Mark van der Loo)
Date: Mon, 23 Mar 2015 14:44:51 +0100
Subject: [Rd] Possible values for R version status
In-Reply-To: <CAPp_+=fr2DhNsrQqSkEw=-LDkkAdJTmE9J4RNiFrbeENZp7jqw@mail.gmail.com>
References: <CAPp_+=fr2DhNsrQqSkEw=-LDkkAdJTmE9J4RNiFrbeENZp7jqw@mail.gmail.com>
Message-ID: <CAOKDuOi5JpGhXaZWJL9eXhWQVHuLt0C5nO2myLT4V_WobiPihA@mail.gmail.com>

In the R installation and administration manual[*] I see at least mentioned

  The alpha, beta and RC versions of an upcoming x.y.0 release are
available [...]

so 'beta' seems to be an option unless it is only  used informally there.

Mark

[*] http://cran.r-project.org/doc/manuals/r-release/R-admin.html#Using-Subversion-and-rsync


On Mon, Mar 23, 2015 at 2:17 PM, Richard Cotton <richierocks at gmail.com> wrote:
> Is there a complete list somewhere of the possible values for R's
> status, as returned by version$status?
>
> I know about these values:
> Stable: ""
> Devel: "Under development (unstable)"
> Patched: "Patched"
> Release candidate: "RC"
> Alpha: "Alpha"
>
> Are there any others that I've missed?
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From richierocks at gmail.com  Mon Mar 23 14:55:40 2015
From: richierocks at gmail.com (Richard Cotton)
Date: Mon, 23 Mar 2015 16:55:40 +0300
Subject: [Rd] Possible values for R version status
In-Reply-To: <551016FA.2090906@gmail.com>
References: <CAPp_+=fr2DhNsrQqSkEw=-LDkkAdJTmE9J4RNiFrbeENZp7jqw@mail.gmail.com>
	<551016FA.2090906@gmail.com>
Message-ID: <CAPp_+=d8RcGjL1fOQ8yPW_x3-2ydVqPyAPpeHZR6r1bGi-JGAg@mail.gmail.com>

Thanks for this.  You are right that it's a lowercase "a"; the
documentation on the R.Version help page is incorrect.  That describes
status as 'the status of the version (e.g., "Alpha")'.

On 23 March 2015 at 16:36, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 23/03/2015 9:17 AM, Richard Cotton wrote:
>>
>> Is there a complete list somewhere of the possible values for R's
>> status, as returned by version$status?
>>
>> I know about these values:
>> Stable: ""
>> Devel: "Under development (unstable)"
>> Patched: "Patched"
>> Release candidate: "RC"
>> Alpha: "Alpha"
>
>
> I don't think we use "Alpha", I think it's lowercase.  There is also "beta".
> You can see the list at
> http://developer.r-project.org/release-checklist.html, in the lines that
> describe the version being set.
>
> Duncan Murdoch



-- 
Regards,
Richie

Learning R
4dpiecharts.com


From pdalgd at gmail.com  Mon Mar 23 15:39:57 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 23 Mar 2015 15:39:57 +0100
Subject: [Rd] Possible values for R version status
In-Reply-To: <551016FA.2090906@gmail.com>
References: <CAPp_+=fr2DhNsrQqSkEw=-LDkkAdJTmE9J4RNiFrbeENZp7jqw@mail.gmail.com>
	<551016FA.2090906@gmail.com>
Message-ID: <4DAE303C-21C9-4A76-9335-7B0D149B0A07@gmail.com>


On 23 Mar 2015, at 14:36 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 23/03/2015 9:17 AM, Richard Cotton wrote:
>> Is there a complete list somewhere of the possible values for R's
>> status, as returned by version$status?
>> 
>> I know about these values:
>> Stable: ""
>> Devel: "Under development (unstable)"
>> Patched: "Patched"
>> Release candidate: "RC"
>> Alpha: "Alpha"
> 
> I don't think we use "Alpha", I think it's lowercase.  There is also "beta".  You can see the list at http://developer.r-project.org/release-checklist.html, in the lines that describe the version being set.

Yep. The transition cycle on the SVN release branch goes

alpha -> beta -> RC -> "" -> Patched

and the SVN trunk is permanently 

"Under development (unstable)"

Notice that the empty string is used for _official releases_. I wouldn't know in what sense "Stable" would apply to those, but they are typically the ones that 3rd party developers like Linux distributions would pick up and ship.   


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From thierry.onkelinx at inbo.be  Mon Mar 23 17:55:52 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 23 Mar 2015 17:55:52 +0100
Subject: [Rd] robust updating methods
In-Reply-To: <550EF1C1.7080805@gmail.com>
References: <550EF1C1.7080805@gmail.com>
Message-ID: <CAJuCY5z9Q9T9Q3V-khXfSfwOOU_RrhWZDjw8JE7L2tUv1n6RVg@mail.gmail.com>

Dear Ben,

Last week I was struggling with incorporating lme4 into a package. I traced
the problem and made a reproducible example (
https://github.com/ThierryO/testlme4).  It looks very simular to the
problem you describe.

The 'tests' directory contains the reproducible examples. confint() of a
model as returned by a function fails. It even fails when I try to
calculate the confint() inside the same function as the glmer() call (see
the fit_model_ci function).

Best regards,

Thierry


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-03-22 17:45 GMT+01:00 Ben Bolker <bbolker at gmail.com>:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
> WARNING: this is long.  Sorry I couldn't find a way to compress it.
>
> Is there a reasonable way to design an update method so that it's
> robust to a variety of reasonable use cases of generating calls or
> data inside or outside a function?  Is it even possible?  Should I
> just tell users "don't do that"?
>
> * `update.default()` uses `eval(call, parent.frame())`; this fails
>   when the call depends on objects that were defined in a different
>   environment (e.g., when the data are generated and the model
>   initially fitted within a function scope)
>
> * an alternative is to store the original environment in which the
>   fitting is done in the environment of the formula and use
>   `eval(call, env=environment(formula(object)))`; this fails if the
>   user tries to update the model originally fitted outside a function
>   with data modified within a function ...
>
> * I think I've got a hack that works below, which first tries in the
>   environment of the formula and falls back to the parent frame if
>   that fails, but I wonder if I'm missing something much simpler ..
>
>   Thoughts?  My understanding of environments and frames is still,
> after all these years, not what it should be ...
>
> I've thought of some other workarounds, none entirely satisfactory:
>
> * force evaluation of all elements in the original call
>     * printing components of the call can get ugly (can save the
> original call before evaluating)
>     * large objects in the call get duplicated
> * don't use `eval(call)` for updates; instead try to store everything
> internally
>     * this works OK but has the same drawback of potentially storing
> large extra copies
>     * we could try to use the model frame (which is stored already),
> but there are issues with this (the basis of a whole separate rant)
> because the model frame stores something in between predictor
> variables and input variables. For example
>
>    d <- data.frame(y=1:10,x=runif(10))
>    names(model.frame(lm(y~log(x),data=d)))
>    ## "y" "log(x)"
>
> So if we wanted to do something like update to "y ~ sqrt(x)",
> it wouldn't work ...
>
> ==================
> update.envformula <- function(object,...) {
>     extras <- match.call(expand.dots = FALSE)$...
>     call <- getCall(object)
>     for (i in names(extras)) {
>         existing <- !is.na(match(names(extras), names(call)))
>         for (a in names(extras)[existing]) call[[a]] <- extras[[a]]
>         if (any(!existing)) {
>             call <- c(as.list(call), extras[!existing])
>             call <- as.call(call)
>         }
>     }
>     eval(call, env=environment(formula(object)))
>     ## enclos=parent.frame() doesn't help
> }
>
> update.both <- function(object,...) {
>     extras <- match.call(expand.dots = FALSE)$...
>     call <- getCall(object)
>     for (i in names(extras)) {
>         existing <- !is.na(match(names(extras), names(call)))
>         for (a in names(extras)[existing]) call[[a]] <- extras[[a]]
>         if (any(!existing)) {
>             call <- c(as.list(call), extras[!existing])
>             call <- as.call(call)
>         }
>     }
>     pf <- parent.frame()  ## save parent frame in case we need it
>     tryCatch(eval(call, env=environment(formula(object))),
>              error=function(e) {
>                  eval(call, pf)
>              })
> }
>
> ### TEST CASES
>
> set.seed(101)
> d <- data.frame(x=1:10,y=rnorm(10))
> m1 <- lm(y~x,data=d)
>
> ##' define data within function, return fitted model
> f1 <- function() {
>     d2 <- d
>     lm(y~x,data=d2)
>     return(lm(y~x,data=d2))
> }
> ##' define (and modify) data within function, try to update
> ##' model fitted elsewhere
> f2 <- function(m) {
>     d2 <- d; d2[1] <- d2[1]+0 ## force copy
>     update.default(m,data=d2)
> }
> ##' define (and modify) data within function, try to update
> ##' model fitted elsewhere (use envformula)
> f3 <- function(m) {
>     d2 <- d; d2[1] <- d2[1]+0 ## force copy
>     update.envformula(m,data=d2)
> }
>
> ##' hack: first try the formula, then the parent frame
> ##' if that doesn't work for any reason
> f4 <- function(m) {
>     d2 <- d; d2[1] <- d2[1]+0 ## force copy
>     update.both(m,data=d2)
> }
>
> ## Case 1: fit within function
> m2 <- f1()
> try(update.default(m2))       ## default: object 'd2' not found
> m3A <- update.envformula(m2)  ## envformula: works
> m3B <- update.both(m2)        ## works
>
> ## Case 2: update within function
> m4A <- f2(m1)  ## default: works
> try(f3(m1))    ## envformula: object 'd2' not found
> m4B <- f4(m1)  ## works
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.11 (GNU/Linux)
>
> iQEcBAEBAgAGBQJVDvHBAAoJEOCV5YRblxUHtnwH/2452Fqmsm//LxNeXxhNrs/G
> 3ss8rPV2EVJQFjAyO34zzuYZVp1mWlgt7C1L7nXcH4lcf66gYfj75X/yVvMxxwmS
> uXEP9HKr4TR5D6Ukf16qqtK41PhTkjS+RDaEpj6BVq9YxlYb53kSjKF+anrf08SL
> K6i2L+c4nJIwk56CCp0Re/EIDCNeW5lXYX9jdPAalMoxSHTG8wmytvq0x89+KsRC
> aUTpdylPka70vwBQle9W4OEyhBpADIHfEg8csYXZ/MeOKM0bqCRu2IU3OyuCsxyX
> Pbo3w1Z7x0e+2WoX4PcltweYK4PJC9O10v+RKYaI5YRy1dFWMQWcPoAKRKf7jwY=
> =S7zP
> -----END PGP SIGNATURE-----
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From marius.hofert at uwaterloo.ca  Wed Mar 25 00:15:11 2015
From: marius.hofert at uwaterloo.ca (Marius Hofert)
Date: Tue, 24 Mar 2015 19:15:11 -0400
Subject: [Rd] Faster version of rgeom()
Message-ID: <CAM3-KjaYnSyNLfdLV6OwfTu-bxEeN_Td3_6od5YacQZuPAzp8w@mail.gmail.com>

Hi,

I recently took a closer look at the implementations of sampling
algorithms for all basic distributions in R. Two seemed inefficient
(slow) to me:
1) rgeom()
2) rexp()
Obviously, Geo(p) and Exp(lambda) have very simple stochastic
representations (floor(Y) for Y ~ Exp(-log(1-p)) and (-log U)/lambda
for U ~ U[0,1]). I thought I could easily beat the (more complicated)
algorithms that R uses for these two distributions. Even Ahrens and
Dieter (1972) (the paper describing the algorithm rexp() uses; see
below) report that the inversion method for sampling Exp(lambda) is
not beatable).

With a student, I put together a small package (attached) comparing
some run times in
the form of a demo (original version R uses vs the above stochastic
representations in both pure R implementations and pure C
implementations). Here are the results (simple screenshots from the
demo attached):
1) rexp: quite different on Ubuntu Linux / OS X. On OS X it seems easy
to beat rexp(), but on Ubuntu not. Still quite a surprise to me... Is
it that log() is implemented differently on different platforms which
was maybe (?) the original reason for using Ahrens and Dieter (1972)
for sampling from Exp(lambda)?
2) rgeom: both platforms more or less show the same results: rgeom()
can be outperformed (by a factor of two or so).

I know that's quite 'philosophical', but I'm wondering whether a
simpler and faster algorithm such as the one-liner for sampling from
Geo(p) is something one could consider to make available in R and keep
rgeom()'s current default for reproducibility (similar to the change
not too long ago where rnorm() was changed to inversion [if I remember
correctly])?

Any comments are welcome. I'm trying to understand and learn with this
(so not complaining that rgeom() is too slow :-) )

Many cheers,
Marius

PS: Ahrens and Dieter (1972): "Computer methods for sampling from the
exponential and normal distributions"




-- 
Marius Hofert, Dr. rer. nat.
Assistant Professor
Department of Statistics and Actuarial Science
Faculty of Mathematics
University of Waterloo
200 University Avenue West, Waterloo, ON, N2L 3G1
+1-519-888-4567, ext. 31394 (office M3 4207)
http://math.uwaterloo.ca/~mhofert
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 1_rgeom_comparison_os_x.png
Type: image/png
Size: 397097 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20150324/54a9624f/attachment-0008.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 1_rgeom_comparison_ubuntu.png
Type: image/png
Size: 63615 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20150324/54a9624f/attachment-0009.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 2_rexp_comparison_os_x.png
Type: image/png
Size: 374402 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20150324/54a9624f/attachment-0010.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 2_rexp_comparison_ubuntu.png
Type: image/png
Size: 57036 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20150324/54a9624f/attachment-0011.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 3_rgeom_effect_of_prob_os_x.png
Type: image/png
Size: 208246 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20150324/54a9624f/attachment-0012.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 3_rgeom_effect_of_prob_ubuntu.png
Type: image/png
Size: 52621 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20150324/54a9624f/attachment-0013.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 4_rexp_effect_of_lambda_os_x.png
Type: image/png
Size: 191788 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20150324/54a9624f/attachment-0014.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 4_rexp_effect_of_lambda_ubuntu.png
Type: image/png
Size: 55383 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20150324/54a9624f/attachment-0015.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: rgeomexp_0.0-1.tar.gz
Type: application/x-gzip
Size: 4388 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20150324/54a9624f/attachment-0001.gz>

From bbolker at gmail.com  Wed Mar 25 00:55:43 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 24 Mar 2015 19:55:43 -0400
Subject: [Rd] robust updating methods
In-Reply-To: <CAJuCY5z9Q9T9Q3V-khXfSfwOOU_RrhWZDjw8JE7L2tUv1n6RVg@mail.gmail.com>
References: <550EF1C1.7080805@gmail.com>
	<CAJuCY5z9Q9T9Q3V-khXfSfwOOU_RrhWZDjw8JE7L2tUv1n6RVg@mail.gmail.com>
Message-ID: <5511F97F.8000108@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

On 15-03-23 12:55 PM, Thierry Onkelinx wrote:
> Dear Ben,
> 
> Last week I was struggling with incorporating lme4 into a package.
> I traced the problem and made a reproducible example ( 
> https://github.com/ThierryO/testlme4).  It looks very simular to
> the problem you describe.
> 
> The 'tests' directory contains the reproducible examples. confint()
> of a model as returned by a function fails. It even fails when I
> try to calculate the confint() inside the same function as the
> glmer() call (see the fit_model_ci function).
> 
> Best regards,
> 
> Thierry


Ugh.  I can get this to work if I also try searching up the call
stack, as follows (within update.merMod).  This feels like "code
smell" to me though -- i.e., if I have to hack this hard I must be
doing something wrong/misunderstanding how the problem *should* be done.


    if (evaluate) {
        ff <- environment(formula(object))
        pf <- parent.frame()  ## save parent frame in case we need it
        sf <- sys.frames()[[1]]
        tryCatch(eval(call, env=ff),
                 error=function(e) {
                     tryCatch(eval(call, env=sf),
                              error=function(e) {
                                  eval(call, pf)
                              })
                 })
    } else call

  Here is an adapted even-more-minimal version of your code, which
seems to work with the version of update.merMod I just pushed to
github, but fails for glm():


## https://github.com/ThierryO/testlme4/blob/master/R/fit_model_ci.R
fit_model_ci <- function(formula, dataset, mfun=glmer){
    model <- mfun(
        formula = formula,
        data = dataset,
        family = "poisson"
    )
    ci <- confint(model)
    return(list(model = model, confint = ci))
}

library("lme4")
set.seed(101)
dd <- data.frame(f=factor(rep(1:10,each=100)),
                 y=rpois(2,1000))
fit_model_ci(y~(1|f),dataset=dd)
fit_model_ci(y~(1|f),dataset=dd,mfun=glm)



> 
> 
> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
> Research Institute for Nature and Forest team Biometrie &
> Kwaliteitszorg / team Biometrics & Quality Assurance Kliniekstraat
> 25 1070 Anderlecht Belgium
> 
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may
> be able to say what the experiment died of. ~ Sir Ronald Aylmer
> Fisher The plural of anecdote is not data. ~ Roger Brinner The
> combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given
> body of data. ~ John Tukey
> 
> 2015-03-22 17:45 GMT+01:00 Ben Bolker <bbolker at gmail.com>:
> 
> WARNING: this is long.  Sorry I couldn't find a way to compress
> it.
> 
> Is there a reasonable way to design an update method so that it's 
> robust to a variety of reasonable use cases of generating calls or 
> data inside or outside a function?  Is it even possible?  Should I 
> just tell users "don't do that"?
> 
> * `update.default()` uses `eval(call, parent.frame())`; this fails 
> when the call depends on objects that were defined in a different 
> environment (e.g., when the data are generated and the model 
> initially fitted within a function scope)
> 
> * an alternative is to store the original environment in which the 
> fitting is done in the environment of the formula and use 
> `eval(call, env=environment(formula(object)))`; this fails if the 
> user tries to update the model originally fitted outside a
> function with data modified within a function ...
> 
> * I think I've got a hack that works below, which first tries in
> the environment of the formula and falls back to the parent frame
> if that fails, but I wonder if I'm missing something much simpler
> ..
> 
> Thoughts?  My understanding of environments and frames is still, 
> after all these years, not what it should be ...
> 
> I've thought of some other workarounds, none entirely
> satisfactory:
> 
> * force evaluation of all elements in the original call * printing
> components of the call can get ugly (can save the original call
> before evaluating) * large objects in the call get duplicated *
> don't use `eval(call)` for updates; instead try to store
> everything internally * this works OK but has the same drawback of
> potentially storing large extra copies * we could try to use the
> model frame (which is stored already), but there are issues with
> this (the basis of a whole separate rant) because the model frame
> stores something in between predictor variables and input
> variables. For example
> 
> d <- data.frame(y=1:10,x=runif(10)) 
> names(model.frame(lm(y~log(x),data=d))) ## "y" "log(x)"
> 
> So if we wanted to do something like update to "y ~ sqrt(x)", it
> wouldn't work ...
> 
> ================== update.envformula <- function(object,...) { 
> extras <- match.call(expand.dots = FALSE)$... call <-
> getCall(object) for (i in names(extras)) { existing <-
> !is.na(match(names(extras), names(call))) for (a in
> names(extras)[existing]) call[[a]] <- extras[[a]] if
> (any(!existing)) { call <- c(as.list(call), extras[!existing]) call
> <- as.call(call) } } eval(call, env=environment(formula(object))) 
> ## enclos=parent.frame() doesn't help }
> 
> update.both <- function(object,...) { extras <-
> match.call(expand.dots = FALSE)$... call <- getCall(object) for (i
> in names(extras)) { existing <- !is.na(match(names(extras),
> names(call))) for (a in names(extras)[existing]) call[[a]] <-
> extras[[a]] if (any(!existing)) { call <- c(as.list(call),
> extras[!existing]) call <- as.call(call) } } pf <- parent.frame()
> ## save parent frame in case we need it tryCatch(eval(call,
> env=environment(formula(object))), error=function(e) { eval(call,
> pf) }) }
> 
> ### TEST CASES
> 
> set.seed(101) d <- data.frame(x=1:10,y=rnorm(10)) m1 <-
> lm(y~x,data=d)
> 
> ##' define data within function, return fitted model f1 <-
> function() { d2 <- d lm(y~x,data=d2) return(lm(y~x,data=d2)) } ##'
> define (and modify) data within function, try to update ##' model
> fitted elsewhere f2 <- function(m) { d2 <- d; d2[1] <- d2[1]+0 ##
> force copy update.default(m,data=d2) } ##' define (and modify) data
> within function, try to update ##' model fitted elsewhere (use
> envformula) f3 <- function(m) { d2 <- d; d2[1] <- d2[1]+0 ## force
> copy update.envformula(m,data=d2) }
> 
> ##' hack: first try the formula, then the parent frame ##' if that
> doesn't work for any reason f4 <- function(m) { d2 <- d; d2[1] <-
> d2[1]+0 ## force copy update.both(m,data=d2) }
> 
> ## Case 1: fit within function m2 <- f1() try(update.default(m2))
> ## default: object 'd2' not found m3A <- update.envformula(m2)  ##
> envformula: works m3B <- update.both(m2)        ## works
> 
> ## Case 2: update within function m4A <- f2(m1)  ## default: works 
> try(f3(m1))    ## envformula: object 'd2' not found m4B <- f4(m1)
> ## works
> 
>> 
>> ______________________________________________ 
>> R-devel at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVEfl/AAoJEOCV5YRblxUHWdgH/AqLAhDqKV8aRg6jnX9rO96D
nwzqv0ClMIxVr2dzD4eSQTL2caWZnXVkws+lg9N7bc4BaWplcYxLNRBw5M8zHOPJ
E7JlhG3EecvmeAEt9OY0/q6I0D6vdoEjcH7wzzuyLLIqllu9OskxURi/azMs0XRo
tiN+oG5aOKsMYsEGjtiWySRDzhJh2TM40A1HHjAViqpxZcqilAZ6RiNEFe1t1JY0
IvDI8yesSuHnKtgAiqk9ivGw4BCCGoBSIHB3GrJIi11j06iYKw0ugVHIlKYO8cqf
AYTvEX2sSxsJgKWYTiG/1dr/kiFTntTDji03zRLVUdPKIZATJMczv+KB+0bpoVY=
=Z34K
-----END PGP SIGNATURE-----


From nicola.lunardon at hotmail.it  Wed Mar 25 10:44:54 2015
From: nicola.lunardon at hotmail.it (bstr)
Date: Wed, 25 Mar 2015 02:44:54 -0700 (PDT)
Subject: [Rd] F77_CALL/NAME problem
Message-ID: <1427276694207-4705076.post@n4.nabble.com>

Dear R-devel,

I am trying to use Fortran DGESV subroutine into C. Here it is the relevant
part of the C file I am currently writing

#include<stdio.h>
#include<R.h>
#include<Rmath.h>
#include<math.h>

void F77_NAME(DGESV)( int*, int*, double*, int*, int*, double*, int*, int*);

void solve( int *p, double *A, double *Ainv)
{
        ...
	F77_CALL(DGESV)(p, p, Ain, p, ipiv, Bin, p, &info);
}

In order to create the ".so" file to load in R I downloaded the dgesv.f file
as well as the dependencies (dgetf2.f dgetrf.f dgetrs.f dlaswp.f). As I was
used to I ran in a terminal

R CMD COMPILE *.f
R CMD SHLIB MY_C_FILE.c *.o

to get the MY_C_FILE.so file. However, when I try to load it in a R session
I get the following error message "undefined symbol: DGESV_". Similar errors
are occurring with some other (old) C files that I was used to use a couple
of years ago. In this connection I have to say that those file were working
under an older linux version (I guess ubuntu 12.04 LTS rather than the
current one which is 14.04 LTS).

Best Regards,

N. Lunardon



--
View this message in context: http://r.789695.n4.nabble.com/F77-CALL-NAME-problem-tp4705076.html
Sent from the R devel mailing list archive at Nabble.com.


From nicola.lunardon at hotmail.it  Wed Mar 25 17:36:00 2015
From: nicola.lunardon at hotmail.it (bstr)
Date: Wed, 25 Mar 2015 09:36:00 -0700 (PDT)
Subject: [Rd] F77_CALL/NAME problem
In-Reply-To: <1427276694207-4705076.post@n4.nabble.com>
References: <1427276694207-4705076.post@n4.nabble.com>
Message-ID: <1427301360411-4705096.post@n4.nabble.com>

I was not able to find why my old way to do things did not work. However, I
"discovered" that dgesv is also in the header Lapack.h. So I just dropped
form the C code the declarations F77_NAME/CALL and used directly function
dgesv_ as declared in Lapack.h. Of course I had to compile with the -llapack
flag.



--
View this message in context: http://r.789695.n4.nabble.com/F77-CALL-NAME-problem-tp4705076p4705096.html
Sent from the R devel mailing list archive at Nabble.com.


From john.archie.mckown at gmail.com  Wed Mar 25 18:51:08 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Wed, 25 Mar 2015 12:51:08 -0500
Subject: [Rd] F77_CALL/NAME problem
In-Reply-To: <1427276694207-4705076.post@n4.nabble.com>
References: <1427276694207-4705076.post@n4.nabble.com>
Message-ID: <CAAJSdjhCSrcroCos9xsJ0cheQQHeZATqv_HRZ9a2VJ+on0SBJQ@mail.gmail.com>

On Wed, Mar 25, 2015 at 4:44 AM, bstr <nicola.lunardon at hotmail.it> wrote:
> Dear R-devel,
>
> I am trying to use Fortran DGESV subroutine into C. Here it is the relevant
> part of the C file I am currently writing
>
> #include<stdio.h>
> #include<R.h>
> #include<Rmath.h>
> #include<math.h>
>
> void F77_NAME(DGESV)( int*, int*, double*, int*, int*, double*, int*, int*);
>
> void solve( int *p, double *A, double *Ainv)
> {
>         ...
>         F77_CALL(DGESV)(p, p, Ain, p, ipiv, Bin, p, &info);
> }

Try lower case.

void F77_NAME(dgesv)( int*, int*, double*, int*, int*, double*, int*, int*);

 void solve( int *p, double *A, double *Ainv)
 {
         ...
         F77_CALL(dgesv)(p, p, Ain, p, ipiv, Bin, p, &info);
 }

The lapack.so file has a name "dgesv_" in it, not DGESV_.

>
> In order to create the ".so" file to load in R I downloaded the dgesv.f file
> as well as the dependencies (dgetf2.f dgetrf.f dgetrs.f dlaswp.f). As I was
> used to I ran in a terminal
>
> R CMD COMPILE *.f
> R CMD SHLIB MY_C_FILE.c *.o
>
> to get the MY_C_FILE.so file. However, when I try to load it in a R session
> I get the following error message "undefined symbol: DGESV_". Similar errors
> are occurring with some other (old) C files that I was used to use a couple
> of years ago. In this connection I have to say that those file were working
> under an older linux version (I guess ubuntu 12.04 LTS rather than the
> current one which is 14.04 LTS).
>
> Best Regards,
>
> N. Lunardon

-- 
If you sent twitter messages while exploring, are you on a textpedition?

He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown


From wdunlap at tibco.com  Wed Mar 25 19:00:18 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 25 Mar 2015 11:00:18 -0700
Subject: [Rd] F77_CALL/NAME problem
In-Reply-To: <1427301360411-4705096.post@n4.nabble.com>
References: <1427276694207-4705076.post@n4.nabble.com>
	<1427301360411-4705096.post@n4.nabble.com>
Message-ID: <CAF8bMcZ4_QgYqMnLnOxi8V4AxHexNud5pT84ju6NYxPL6KrAng@mail.gmail.com>

You said you changed F77_NAME(DGESV) to dgesv_ to make it
work and inferred that F77_NAME was the the problem.

I suspect that things got better because you changed the capitalization
and that F77_NAME(dgesv) would have worked as well.

Adding
   #include <R_ext/Lapack.h>
to your code would declare these things as well (and declare them
properly, with the 'const' declarations in the appropriate places).



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Mar 25, 2015 at 9:36 AM, bstr <nicola.lunardon at hotmail.it> wrote:

> I was not able to find why my old way to do things did not work. However, I
> "discovered" that dgesv is also in the header Lapack.h. So I just dropped
> form the C code the declarations F77_NAME/CALL and used directly function
> dgesv_ as declared in Lapack.h. Of course I had to compile with the
> -llapack
> flag.
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/F77-CALL-NAME-problem-tp4705076p4705096.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From rkoenker at illinois.edu  Wed Mar 25 19:59:02 2015
From: rkoenker at illinois.edu (Roger Koenker)
Date: Wed, 25 Mar 2015 13:59:02 -0500
Subject: [Rd] vignette checking woes
Message-ID: <9D62BF42-5AB3-4600-A6F1-66C56426304D@illinois.edu>

I'm having trouble with R CMD check of my quantreg package.  All is well
until I get to:  

checking running R code from vignettes ...
   ?rq.Rnw? ... failed
 ERROR
Errors in running code in vignettes:
when running code in ?rq.Rnw?

when I see a snippet from the vignette code and then:

Loading required namespace: MatrixModels

  When sourcing ?rq.R?:
Error: could not find function "sparse.model.matrix"
Execution halted

This is baffling to me since sparse.model.matrix is in the
namespace of Matrix and it should be loaded at this stage
since it is required by MatrixModels which has just been
pronounced "loaded".

I've verified that I can Sweave("rq.Rnw")
and texi2pdf("rq.tex", clean=TRUE) without any problem.

Any hints greatly appreciated, as always.

Roger


url:    www.econ.uiuc.edu/~roger            Roger Koenker
email    rkoenker at uiuc.edu            Department of Economics
vox:     217-333-4558                University of Illinois
fax:       217-244-6678                Urbana, IL 61801


From murdoch.duncan at gmail.com  Wed Mar 25 20:45:34 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 25 Mar 2015 15:45:34 -0400
Subject: [Rd] vignette checking woes
In-Reply-To: <9D62BF42-5AB3-4600-A6F1-66C56426304D@illinois.edu>
References: <9D62BF42-5AB3-4600-A6F1-66C56426304D@illinois.edu>
Message-ID: <5513105E.8010806@gmail.com>

On 25/03/2015 2:59 PM, Roger Koenker wrote:
> I'm having trouble with R CMD check of my quantreg package.  All is well
> until I get to:
>
> checking running R code from vignettes ...
>     ?rq.Rnw? ... failed
>   ERROR
> Errors in running code in vignettes:
> when running code in ?rq.Rnw?
>
> when I see a snippet from the vignette code and then:
>
> Loading required namespace: MatrixModels
>
>    When sourcing ?rq.R?:
> Error: could not find function "sparse.model.matrix"
> Execution halted
>
> This is baffling to me since sparse.model.matrix is in the
> namespace of Matrix and it should be loaded at this stage
> since it is required by MatrixModels which has just been
> pronounced "loaded".
>
> I've verified that I can Sweave("rq.Rnw")
> and texi2pdf("rq.tex", clean=TRUE) without any problem.
>
> Any hints greatly appreciated, as always.
>

This could happen if you load the namespace of MatrixModels (e.g. by 
using :: notation), but don't put it on your search path (e.g. by using 
library(MatrixModels)).

When you run Sweave from within R, it sees the search path that was 
active when you called Sweave; when checking a vignette, it starts with 
a clean slate.

Duncan Murdoch


From vobencha at fredhutch.org  Wed Mar 25 20:46:54 2015
From: vobencha at fredhutch.org (Valerie Obenchain)
Date: Wed, 25 Mar 2015 12:46:54 -0700
Subject: [Rd] nested parallel workers
Message-ID: <551310AE.30008@fredhutch.org>

Hi Simon,

I'm having trouble with nested parallel workers, specifically, forking
inside socket connections.

When mclapply is called inside a SOCK, PSOCK or FORK worker I get an
error in unserialize().

cl <- makeCluster(1, "SOCK")

fun = function(i) {
   library(parallel)
   mclapply(1:2, sqrt)
}

Failure occurs after multiple calls to clusterApply:

 > clusterApply(cl, 1, fun)
[[1]]
[[1]][[1]]
[1] 1

[[1]][[2]]
[1] 1.414214

 > clusterApply(cl, 1, fun)
[[1]]
[[1]][[1]]
[1] 1

[[1]][[2]]
[1] 1.414214

 > clusterApply(cl, 1, fun)
Error in unserialize(node$con) : error reading from connection


This example is from Martin and may be a different problem.

~/tmp >cat test1.R
## like mclapply
## should run 'forever' but terminates semi-randomly
library(parallel)
children <- parallel:::children

while (TRUE) {
     n <- 8            ## n == dectectCores()
     jobs <- lapply(seq_len(n), function(i) mcparallel(Sys.sleep(20)))
     mccollect(children(jobs), FALSE)
     parallel:::mckill(children(jobs), tools::SIGTERM)
     leni <- length(mccollect(children(jobs)))
     message("leni: ", leni)
}

~/tmp >R-dev --vanilla --slave -f test1.R
leni: 6
leni: 7
leni: 7
leni: 7
leni: 7
leni: 7
leni: 7
leni: 7
leni: 8
leni: 7
leni: 7
leni: 7
~/tmp >


Thanks.
Valerie


 > sessionInfo()
R Under development (unstable) (2015-03-18 r68009)
Platform: x86_64-unknown-linux-gnu (64-bit)
Running under: Fedora 21 (Twenty One)

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] parallel  stats     graphics  grDevices utils     datasets  methods
[8] base

loaded via a namespace (and not attached):
[1] snow_0.3-13


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, Seattle, WA 98109

Email: vobencha at fredhutch.org
Phone: (206) 667-3158


From thierry.onkelinx at inbo.be  Wed Mar 25 20:54:35 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 25 Mar 2015 20:54:35 +0100
Subject: [Rd] vignette checking woes
In-Reply-To: <9D62BF42-5AB3-4600-A6F1-66C56426304D@illinois.edu>
References: <9D62BF42-5AB3-4600-A6F1-66C56426304D@illinois.edu>
Message-ID: <CAJuCY5yD=j6XH3TZoMMEvm2L_uATWxo1p133PqWCUgeC2+Lr7A@mail.gmail.com>

Dear Roger,

How is Matrix loaded?

If you use sparse.model.matrix() inside a function from your package you
need to declare it as Matrix::sparse.model.matrix()

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-03-25 19:59 GMT+01:00 Roger Koenker <rkoenker at illinois.edu>:

> I'm having trouble with R CMD check of my quantreg package.  All is well
> until I get to:
>
> checking running R code from vignettes ...
>    ?rq.Rnw? ... failed
>  ERROR
> Errors in running code in vignettes:
> when running code in ?rq.Rnw?
>
> when I see a snippet from the vignette code and then:
>
> Loading required namespace: MatrixModels
>
>   When sourcing ?rq.R?:
> Error: could not find function "sparse.model.matrix"
> Execution halted
>
> This is baffling to me since sparse.model.matrix is in the
> namespace of Matrix and it should be loaded at this stage
> since it is required by MatrixModels which has just been
> pronounced "loaded".
>
> I've verified that I can Sweave("rq.Rnw")
> and texi2pdf("rq.tex", clean=TRUE) without any problem.
>
> Any hints greatly appreciated, as always.
>
> Roger
>
>
> url:    www.econ.uiuc.edu/~roger            Roger Koenker
> email    rkoenker at uiuc.edu            Department of Economics
> vox:     217-333-4558                University of Illinois
> fax:       217-244-6678                Urbana, IL 61801
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From rkoenker at illinois.edu  Wed Mar 25 21:12:06 2015
From: rkoenker at illinois.edu (Roger Koenker)
Date: Wed, 25 Mar 2015 15:12:06 -0500
Subject: [Rd] vignette checking woes
In-Reply-To: <ba2481dbbbd94d8aa33f09b482e7ac2a@CHIHT3.ad.uillinois.edu>
References: <9D62BF42-5AB3-4600-A6F1-66C56426304D@illinois.edu>
	<ba2481dbbbd94d8aa33f09b482e7ac2a@CHIHT3.ad.uillinois.edu>
Message-ID: <85544E7F-4A52-46B1-AEEE-1AC5130D3F6F@illinois.edu>

Thierry,

I have this:

if (require(MatrixModels) && require(Matrix)) {
      X <- model.Matrix(Terms, m, contrasts, sparse = TRUE)

in my function rqss()  I've tried variants of requireNamespace too without success.
If I understand properly model.Matrix is from MatrixModels but it calls 
sparse.model.matrix which is part of Matrix, and it is the latter function that I'm
not finding.  Maybe I should go back to the requireNamespace strategy again?

Roger

url:    www.econ.uiuc.edu/~roger            Roger Koenker
email    rkoenker at uiuc.edu            Department of Economics
vox:     217-333-4558                University of Illinois
fax:       217-244-6678                Urbana, IL 61801

> On Mar 25, 2015, at 2:54 PM, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
> 
> Dear Roger,
> 
> How is Matrix loaded?
> 
> If you use sparse.model.matrix() inside a function from your package you need to declare it as Matrix::sparse.model.matrix()
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest 
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance 
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner 
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
> 
> 2015-03-25 19:59 GMT+01:00 Roger Koenker <rkoenker at illinois.edu>:
> I'm having trouble with R CMD check of my quantreg package.  All is well
> until I get to:
> 
> checking running R code from vignettes ...
>  ?rq.Rnw? ... failed
> ERROR
> Errors in running code in vignettes:
> when running code in ?rq.Rnw?
> 
> when I see a snippet from the vignette code and then:
> 
> Loading required namespace: MatrixModels
> 
> When sourcing ?rq.R?:
> Error: could not find function "sparse.model.matrix"
> Execution halted
> 
> This is baffling to me since sparse.model.matrix is in the
> namespace of Matrix and it should be loaded at this stage
> since it is required by MatrixModels which has just been
> pronounced "loaded".
> 
> I've verified that I can Sweave("rq.Rnw")
> and texi2pdf("rq.tex", clean=TRUE) without any problem.
> 
> Any hints greatly appreciated, as always.
> 
> Roger
> 
> 
> url:    www.econ.uiuc.edu/~roger            Roger Koenker
> email    rkoenker at uiuc.edu            Department of Economics
> vox:     217-333-4558                University of Illinois
> fax:       217-244-6678                Urbana, IL 61801
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From thierry.onkelinx at inbo.be  Wed Mar 25 21:17:25 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 25 Mar 2015 21:17:25 +0100
Subject: [Rd] vignette checking woes
In-Reply-To: <85544E7F-4A52-46B1-AEEE-1AC5130D3F6F@illinois.edu>
References: <9D62BF42-5AB3-4600-A6F1-66C56426304D@illinois.edu>
	<ba2481dbbbd94d8aa33f09b482e7ac2a@CHIHT3.ad.uillinois.edu>
	<85544E7F-4A52-46B1-AEEE-1AC5130D3F6F@illinois.edu>
Message-ID: <CAJuCY5wGAvVZuL9OVwNz1LP2cyVkiOXQNoARC17JC_h_2Ey1bg@mail.gmail.com>

I think that you need to check how MatrixModels imports
sparse.model.matrix(). If MatrixModels depends on Matrix, then you are
probably forced to depend on MatrixModels.

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-03-25 21:12 GMT+01:00 Roger Koenker <rkoenker at illinois.edu>:

> Thierry,
>
> I have this:
>
> if (require(MatrixModels) && require(Matrix)) {
>       X <- model.Matrix(Terms, m, contrasts, sparse = TRUE)
>
> in my function rqss()  I've tried variants of requireNamespace too without
> success.
> If I understand properly model.Matrix is from MatrixModels but it calls
> sparse.model.matrix which is part of Matrix, and it is the latter function
> that I'm
> not finding.  Maybe I should go back to the requireNamespace strategy
> again?
>
> Roger
>
> url:    www.econ.uiuc.edu/~roger            Roger Koenker
> email    rkoenker at uiuc.edu            Department of Economics
> vox:     217-333-4558                University of Illinois
> fax:       217-244-6678                Urbana, IL 61801
>
> > On Mar 25, 2015, at 2:54 PM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
> >
> > Dear Roger,
> >
> > How is Matrix loaded?
> >
> > If you use sparse.model.matrix() inside a function from your package you
> need to declare it as Matrix::sparse.model.matrix()
> >
> > Best regards,
> >
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> > Kliniekstraat 25
> > 1070 Anderlecht
> > Belgium
> >
> > To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> >
> > 2015-03-25 19:59 GMT+01:00 Roger Koenker <rkoenker at illinois.edu>:
> > I'm having trouble with R CMD check of my quantreg package.  All is well
> > until I get to:
> >
> > checking running R code from vignettes ...
> >  ?rq.Rnw? ... failed
> > ERROR
> > Errors in running code in vignettes:
> > when running code in ?rq.Rnw?
> >
> > when I see a snippet from the vignette code and then:
> >
> > Loading required namespace: MatrixModels
> >
> > When sourcing ?rq.R?:
> > Error: could not find function "sparse.model.matrix"
> > Execution halted
> >
> > This is baffling to me since sparse.model.matrix is in the
> > namespace of Matrix and it should be loaded at this stage
> > since it is required by MatrixModels which has just been
> > pronounced "loaded".
> >
> > I've verified that I can Sweave("rq.Rnw")
> > and texi2pdf("rq.tex", clean=TRUE) without any problem.
> >
> > Any hints greatly appreciated, as always.
> >
> > Roger
> >
> >
> > url:    www.econ.uiuc.edu/~roger            Roger Koenker
> > email    rkoenker at uiuc.edu            Department of Economics
> > vox:     217-333-4558                University of Illinois
> > fax:       217-244-6678                Urbana, IL 61801
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>

	[[alternative HTML version deleted]]


From simon.urbanek at r-project.org  Thu Mar 26 03:48:48 2015
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 25 Mar 2015 22:48:48 -0400
Subject: [Rd] nested parallel workers
In-Reply-To: <551310AE.30008@fredhutch.org>
References: <551310AE.30008@fredhutch.org>
Message-ID: <DE23891F-86FE-4F68-8838-45670FF7C8A0@r-project.org>

On Mar 25, 2015, at 3:46 PM, Valerie Obenchain <vobencha at fredhutch.org> wrote:

> Hi Simon,
> 
> I'm having trouble with nested parallel workers, specifically, forking inside socket connections.
> 

You simply can't by definition - when you fork *all* the workers share the same connection inherited from the parent, so you cannot use any I/O operations that you didn't start in the worker since reading in one worker affects all the workers.

Cheers,
Simon


> When mclapply is called inside a SOCK, PSOCK or FORK worker I get an
> error in unserialize().
> 
> cl <- makeCluster(1, "SOCK")
> 
> fun = function(i) {
>  library(parallel)
>  mclapply(1:2, sqrt)
> }
> 
> Failure occurs after multiple calls to clusterApply:
> 
> > clusterApply(cl, 1, fun)
> [[1]]
> [[1]][[1]]
> [1] 1
> 
> [[1]][[2]]
> [1] 1.414214
> 
> > clusterApply(cl, 1, fun)
> [[1]]
> [[1]][[1]]
> [1] 1
> 
> [[1]][[2]]
> [1] 1.414214
> 
> > clusterApply(cl, 1, fun)
> Error in unserialize(node$con) : error reading from connection
> 
> 
> This example is from Martin and may be a different problem.
> 
> ~/tmp >cat test1.R
> ## like mclapply
> ## should run 'forever' but terminates semi-randomly
> library(parallel)
> children <- parallel:::children
> 
> while (TRUE) {
>    n <- 8            ## n == dectectCores()
>    jobs <- lapply(seq_len(n), function(i) mcparallel(Sys.sleep(20)))
>    mccollect(children(jobs), FALSE)
>    parallel:::mckill(children(jobs), tools::SIGTERM)
>    leni <- length(mccollect(children(jobs)))
>    message("leni: ", leni)
> }
> 
> ~/tmp >R-dev --vanilla --slave -f test1.R
> leni: 6
> leni: 7
> leni: 7
> leni: 7
> leni: 7
> leni: 7
> leni: 7
> leni: 7
> leni: 8
> leni: 7
> leni: 7
> leni: 7
> ~/tmp >
> 
> 
> Thanks.
> Valerie
> 
> 
> > sessionInfo()
> R Under development (unstable) (2015-03-18 r68009)
> Platform: x86_64-unknown-linux-gnu (64-bit)
> Running under: Fedora 21 (Twenty One)
> 
> locale:
> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
> [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] parallel  stats     graphics  grDevices utils     datasets  methods
> [8] base
> 
> loaded via a namespace (and not attached):
> [1] snow_0.3-13
> 
> 
> -- 
> Computational Biology / Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, Seattle, WA 98109
> 
> Email: vobencha at fredhutch.org
> Phone: (206) 667-3158
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From nicola.lunardon at hotmail.it  Thu Mar 26 09:20:16 2015
From: nicola.lunardon at hotmail.it (bstr)
Date: Thu, 26 Mar 2015 01:20:16 -0700 (PDT)
Subject: [Rd] F77_CALL/NAME problem
In-Reply-To: <1427276694207-4705076.post@n4.nabble.com>
References: <1427276694207-4705076.post@n4.nabble.com>
Message-ID: <1427358016722-4705128.post@n4.nabble.com>

Thank you John and William for the replies!

@John: I downloaded the Fortran files from 
http://www.netlib.org/lapack/double/ <http://www.netlib.org/lapack/double/>  
(the link "dgesv.f plus dependencies"). In file dgesv.f the subroutine is
declared as 

SUBROUTINE DGESV( N, NRHS, A, LDA, IPIV, B, LDB, INFO ) 

with capital letters.

@William: after looking for a while for a solution I discovered that R had
"embedded" all the things I needed, so I just got rid of F77_NAME/CALL in my
C code and simply called dgesv_ as declared in Lapack.h (adding as you
suggested #include <R_ext/Lapack.h> in the preamble). So I did not changed
the previous declarations of DGESV in my C file to lower case.

On the one hand, it seemed (and seems) to me quite odd that my old code did
not work and I would like to know why, even if it not a priority anymore. On
the other hand, I am happy to have found a new, and, I suppose, more
"R-package" oriented way, to use Fortran's linear algebra routines in my C
code. 

N. Lunardon



--
View this message in context: http://r.789695.n4.nabble.com/F77-CALL-NAME-problem-tp4705076p4705128.html
Sent from the R devel mailing list archive at Nabble.com.


From plummerm at iarc.fr  Thu Mar 26 14:50:47 2015
From: plummerm at iarc.fr (Martyn Plummer)
Date: Thu, 26 Mar 2015 13:50:47 +0000
Subject: [Rd] vignette checking woes
In-Reply-To: <85544E7F-4A52-46B1-AEEE-1AC5130D3F6F@illinois.edu>
References: <9D62BF42-5AB3-4600-A6F1-66C56426304D@illinois.edu>
	<ba2481dbbbd94d8aa33f09b482e7ac2a@CHIHT3.ad.uillinois.edu>
	<85544E7F-4A52-46B1-AEEE-1AC5130D3F6F@illinois.edu>
Message-ID: <1427377847.18388.63.camel@iarc.fr>

On Wed, 2015-03-25 at 15:12 -0500, Roger Koenker wrote:
> Thierry,
> 
> I have this:
> 
> if (require(MatrixModels) && require(Matrix)) {
>       X <- model.Matrix(Terms, m, contrasts, sparse = TRUE)

You have this in the current release, which does not show this problem
in the CRAN tests. This, and the fact that you can build the vignette
manually, suggests that there is a problem with your checking
environment.

Did you set up a special checking environment in ~/.R/check.Renviron ?
Does it set R_LIBS?

Martyn

> in my function rqss()  I've tried variants of requireNamespace too without success.
> If I understand properly model.Matrix is from MatrixModels but it calls 
> sparse.model.matrix which is part of Matrix, and it is the latter function that I'm
> not finding.  Maybe I should go back to the requireNamespace strategy again?
> 
> Roger
> 
> url:    www.econ.uiuc.edu/~roger            Roger Koenker
> email    rkoenker at uiuc.edu            Department of Economics
> vox:     217-333-4558                University of Illinois
> fax:       217-244-6678                Urbana, IL 61801
> 
> > On Mar 25, 2015, at 2:54 PM, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
> > 
> > Dear Roger,
> > 
> > How is Matrix loaded?
> > 
> > If you use sparse.model.matrix() inside a function from your package you need to declare it as Matrix::sparse.model.matrix()
> > 
> > Best regards,
> > 
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest 
> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance 
> > Kliniekstraat 25
> > 1070 Anderlecht
> > Belgium
> > 
> > To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner 
> > The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
> > 
> > 2015-03-25 19:59 GMT+01:00 Roger Koenker <rkoenker at illinois.edu>:
> > I'm having trouble with R CMD check of my quantreg package.  All is well
> > until I get to:
> > 
> > checking running R code from vignettes ...
> >  ?rq.Rnw? ... failed
> > ERROR
> > Errors in running code in vignettes:
> > when running code in ?rq.Rnw?
> > 
> > when I see a snippet from the vignette code and then:
> > 
> > Loading required namespace: MatrixModels
> > 
> > When sourcing ?rq.R?:
> > Error: could not find function "sparse.model.matrix"
> > Execution halted
> > 
> > This is baffling to me since sparse.model.matrix is in the
> > namespace of Matrix and it should be loaded at this stage
> > since it is required by MatrixModels which has just been
> > pronounced "loaded".
> > 
> > I've verified that I can Sweave("rq.Rnw")
> > and texi2pdf("rq.tex", clean=TRUE) without any problem.
> > 
> > Any hints greatly appreciated, as always.
> > 
> > Roger
> > 
> > 
> > url:    www.econ.uiuc.edu/~roger            Roger Koenker
> > email    rkoenker at uiuc.edu            Department of Economics
> > vox:     217-333-4558                University of Illinois
> > fax:       217-244-6678                Urbana, IL 61801
> > 
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> > 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From csardi.gabor at gmail.com  Thu Mar 26 15:47:36 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Thu, 26 Mar 2015 07:47:36 -0700
Subject: [Rd] About removing zlib from R-devel
Message-ID: <CABtg=KkKOmhGait1QAR_5LiYrY0hgggpXDhWqGFfTsJ+jaOiPA@mail.gmail.com>

Dear All,

zlib has been removed from R-devel src/extra recently, and building R
requires zlib >= 1.2.5. Ubuntu 12.04 LTS (also used on Travis CI) only has
1.2.3.

This means that the next version of R will probably not available on Ubuntu
12.04. (Unless I am missing something of course.) Which is probably fine,
it is almost three years old now.

I guess R-core is aware of this. Just wanted to be sure.

Best Regads,
Gabor

	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Thu Mar 26 16:49:19 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 26 Mar 2015 15:49:19 +0000
Subject: [Rd] About removing zlib from R-devel
In-Reply-To: <CABtg=KkKOmhGait1QAR_5LiYrY0hgggpXDhWqGFfTsJ+jaOiPA@mail.gmail.com>
References: <CABtg=KkKOmhGait1QAR_5LiYrY0hgggpXDhWqGFfTsJ+jaOiPA@mail.gmail.com>
Message-ID: <55142A7F.1030205@stats.ox.ac.uk>

On 26/03/2015 14:47, G?bor Cs?rdi wrote:
> Dear All,
>
> zlib has been removed from R-devel src/extra recently, and building R
> requires zlib >= 1.2.5. Ubuntu 12.04 LTS (also used on Travis CI) only has
> 1.2.3.

Hmm, 1.2.3 is from July 2005, 1.2.5 from July 2010.

> This means that the next version of R will probably not available on Ubuntu

The 'next version of R' will be 3.2.0, and the pre-3.2.0 sources include 
zlib.

> 12.04. (Unless I am missing something of course.) Which is probably fine,
> it is almost three years old now.
>
> I guess R-core is aware of this. Just wanted to be sure.

Yes, although nothing stops you installing zlib >= 1.2.5 from sources.

The minimal required versions of bzip2, pcre, zlib are all from 2010, 
and of liblzma from 2011.

Whereas R-devel will not be released (as 3.3.x) until 2016.

>
> Best Regads,
> Gabor
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From csardi.gabor at gmail.com  Thu Mar 26 17:09:17 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Thu, 26 Mar 2015 09:09:17 -0700
Subject: [Rd] About removing zlib from R-devel
In-Reply-To: <55142A7F.1030205@stats.ox.ac.uk>
References: <CABtg=KkKOmhGait1QAR_5LiYrY0hgggpXDhWqGFfTsJ+jaOiPA@mail.gmail.com>
	<55142A7F.1030205@stats.ox.ac.uk>
Message-ID: <CABtg=Km1saoNDvH0FfEGXi=_m7fu-5HqEKdtJZKB4R0dUB8wew@mail.gmail.com>

On Thu, Mar 26, 2015 at 8:49 AM, Prof Brian Ripley <ripley at stats.ox.ac.uk>
wrote:
[...]
>
> This means that the next version of R will probably not available on Ubuntu
>>
>
> The 'next version of R' will be 3.2.0, and the pre-3.2.0 sources include
> zlib.


My bad, sorry about that. I thought R-devel (trunk) will be released next,
obviously not.


> Whereas R-devel will not be released (as 3.3.x) until 2016.
>

Great, I just hope that Travis will upgrade before that. Although the end
of life of 12.04 is April 2017.

Thanks,
Gabor

	[[alternative HTML version deleted]]


From rkoenker at illinois.edu  Thu Mar 26 17:42:14 2015
From: rkoenker at illinois.edu (Roger Koenker)
Date: Thu, 26 Mar 2015 11:42:14 -0500
Subject: [Rd] vignette checking woes
In-Reply-To: <66fc43a773d049129cce5a0ecc31e54c@CITESHT3.ad.uillinois.edu>
References: <9D62BF42-5AB3-4600-A6F1-66C56426304D@illinois.edu>
	<ba2481dbbbd94d8aa33f09b482e7ac2a@CHIHT3.ad.uillinois.edu>
	<85544E7F-4A52-46B1-AEEE-1AC5130D3F6F@illinois.edu>
	<66fc43a773d049129cce5a0ecc31e54c@CITESHT3.ad.uillinois.edu>
Message-ID: <9CC8E172-2E73-457D-9DBD-61AFED7833DB@illinois.edu>


> On Mar 26, 2015, at 8:50 AM, Martyn Plummer <plummerM at iarc.fr> wrote:
> 
> On Wed, 2015-03-25 at 15:12 -0500, Roger Koenker wrote:
>> Thierry,
>> 
>> I have this:
>> 
>> if (require(MatrixModels) && require(Matrix)) {
>>   X <- model.Matrix(Terms, m, contrasts, sparse = TRUE)
> 
> You have this in the current release, which does not show this problem
> in the CRAN tests. This, and the fact that you can build the vignette
> manually, suggests that there is a problem with your checking
> environment.
> 
> Did you set up a special checking environment in ~/.R/check.Renviron ?
> Does it set R_LIBS?

No, not that I can find.  But I agree that there seems to be something fishy.  Another
bit of evidence for this is fact that R CMD build gives me:

* creating vignettes ... ERROR
Rscript execution error: No such file or directory

so I've been building with the --no-build-vignettes flag...

Many thanks, for your suggestions,
Roger

> 
> Martyn
> 
>> in my function rqss()  I've tried variants of requireNamespace too without success.
>> If I understand properly model.Matrix is from MatrixModels but it calls 
>> sparse.model.matrix which is part of Matrix, and it is the latter function that I'm
>> not finding.  Maybe I should go back to the requireNamespace strategy again?
>> 
>> Roger
>> 
>> url:    www.econ.uiuc.edu/~roger            Roger Koenker
>> email    rkoenker at uiuc.edu            Department of Economics
>> vox:     217-333-4558                University of Illinois
>> fax:       217-244-6678                Urbana, IL 61801
>> 
>>> On Mar 25, 2015, at 2:54 PM, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
>>> 
>>> Dear Roger,
>>> 
>>> How is Matrix loaded?
>>> 
>>> If you use sparse.model.matrix() inside a function from your package you need to declare it as Matrix::sparse.model.matrix()
>>> 
>>> Best regards,
>>> 
>>> ir. Thierry Onkelinx
>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest 
>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance 
>>> Kliniekstraat 25
>>> 1070 Anderlecht
>>> Belgium
>>> 
>>> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner 
>>> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
>>> 
>>> 2015-03-25 19:59 GMT+01:00 Roger Koenker <rkoenker at illinois.edu>:
>>> I'm having trouble with R CMD check of my quantreg package.  All is well
>>> until I get to:
>>> 
>>> checking running R code from vignettes ...
>>> ?rq.Rnw? ... failed
>>> ERROR
>>> Errors in running code in vignettes:
>>> when running code in ?rq.Rnw?
>>> 
>>> when I see a snippet from the vignette code and then:
>>> 
>>> Loading required namespace: MatrixModels
>>> 
>>> When sourcing ?rq.R?:
>>> Error: could not find function "sparse.model.matrix"
>>> Execution halted
>>> 
>>> This is baffling to me since sparse.model.matrix is in the
>>> namespace of Matrix and it should be loaded at this stage
>>> since it is required by MatrixModels which has just been
>>> pronounced "loaded".
>>> 
>>> I've verified that I can Sweave("rq.Rnw")
>>> and texi2pdf("rq.tex", clean=TRUE) without any problem.
>>> 
>>> Any hints greatly appreciated, as always.
>>> 
>>> Roger
>>> 
>>> 
>>> url:    www.econ.uiuc.edu/~roger            Roger Koenker
>>> email    rkoenker at uiuc.edu            Department of Economics
>>> vox:     217-333-4558                University of Illinois
>>> fax:       217-244-6678                Urbana, IL 61801
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From simon.urbanek at r-project.org  Thu Mar 26 19:18:30 2015
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 26 Mar 2015 14:18:30 -0400
Subject: [Rd] About removing zlib from R-devel
In-Reply-To: <CABtg=Km1saoNDvH0FfEGXi=_m7fu-5HqEKdtJZKB4R0dUB8wew@mail.gmail.com>
References: <CABtg=KkKOmhGait1QAR_5LiYrY0hgggpXDhWqGFfTsJ+jaOiPA@mail.gmail.com>
	<55142A7F.1030205@stats.ox.ac.uk>
	<CABtg=Km1saoNDvH0FfEGXi=_m7fu-5HqEKdtJZKB4R0dUB8wew@mail.gmail.com>
Message-ID: <10294D18-4AEC-4DEB-9008-D13729C9F564@r-project.org>


> On Mar 26, 2015, at 12:09 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
> 
> On Thu, Mar 26, 2015 at 8:49 AM, Prof Brian Ripley <ripley at stats.ox.ac.uk>
> wrote:
> [...]
>> 
>> This means that the next version of R will probably not available on Ubuntu
>>> 
>> 
>> The 'next version of R' will be 3.2.0, and the pre-3.2.0 sources include
>> zlib.
> 
> 
> My bad, sorry about that. I thought R-devel (trunk) will be released next,
> obviously not.
> 
> 
>> Whereas R-devel will not be released (as 3.3.x) until 2016.
>> 
> 
> Great, I just hope that Travis will upgrade before that. Although the end
> of life of 12.04 is April 2017.
> 

Yes, but with LTS you're locked in to the versions at the time so for 12.04 LTS that is R 2.14.1 so I'm not sure what R 3.x has anything to do with that. If you want to use any R more recent that R 2.14.1 on 12.04 then you have to supply your own binaries either way so this is a non-issue.

Cheers,
Simon




> Thanks,
> Gabor
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From edd at debian.org  Thu Mar 26 19:49:20 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 26 Mar 2015 13:49:20 -0500
Subject: [Rd] About removing zlib from R-devel
In-Reply-To: <CABtg=KkKOmhGait1QAR_5LiYrY0hgggpXDhWqGFfTsJ+jaOiPA@mail.gmail.com>
References: <CABtg=KkKOmhGait1QAR_5LiYrY0hgggpXDhWqGFfTsJ+jaOiPA@mail.gmail.com>
Message-ID: <21780.21680.951993.617987@max.nulle.part>


On 26 March 2015 at 07:47, G?bor Cs?rdi wrote:
| Dear All,
| 
| zlib has been removed from R-devel src/extra recently, and building R
| requires zlib >= 1.2.5. Ubuntu 12.04 LTS (also used on Travis CI) only has
| 1.2.3.
| 
| This means that the next version of R will probably not available on Ubuntu
| 12.04. (Unless I am missing something of course.) Which is probably fine,
| it is almost three years old now.

I think Michael Rutter (who (re-)builds for 12.04 and other Ubuntu releases
when I update the Debian package) can create a local backport of zlib.

I somewhat recently started to (entirely locally) build some "backports" via 
https://launchpad.net/~edd/+archive/ubuntu/misc solely so that Travis can use
them as binary.  It's good option to have.

Dirk
 
| I guess R-core is aware of this. Just wanted to be sure.
| 
| Best Regads,
| Gabor
| 
| 	[[alternative HTML version deleted]]
| 
| ______________________________________________
| R-devel at r-project.org mailing list
| https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From kasperdanielhansen at gmail.com  Fri Mar 27 16:19:40 2015
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Fri, 27 Mar 2015 11:19:40 -0400
Subject: [Rd] About removing zlib from R-devel
In-Reply-To: <21780.21680.951993.617987@max.nulle.part>
References: <CABtg=KkKOmhGait1QAR_5LiYrY0hgggpXDhWqGFfTsJ+jaOiPA@mail.gmail.com>
	<21780.21680.951993.617987@max.nulle.part>
Message-ID: <CAC2h7utZmvRWccfJM60o40Qydbe+7d9vcQP5w3VbhCKQPEd1ig@mail.gmail.com>

Related to this question:

I have installed bzip2 1.0.6 by hand, but configure still fails.  When I
look at config.log I get the following

configure:34150: /usr/bin/gcc -std=gnu99 -o conftest -g -O2 -march=amdfam10
 -g -O2 -march=amdfam10  -L/usr/local/lib64 confte
st.c -lbz2 -lz -lrt -ldl -lm  >&5
conftest.c: In function 'main':
conftest.c:250: warning: initialization discards qualifiers from pointer
target type
conftest.c:251: warning: implicit declaration of function 'exit'
conftest.c:251: warning: incompatible implicit declaration of built-in
function 'exit'
conftest.c:251: warning: implicit declaration of function 'strcmp'

for the program

| #ifdef HAVE_BZLIB_H
| #include <bzlib.h>
| #endif
| int main() {
|     char *ver = BZ2_bzlibVersion();
|     exit(strcmp(ver, "1.0.6") < 0);
| }
|
configure:34167: result: no
configure:34173: checking whether bzip2 support suffices
configure:34180: error: bzip2 library and headers are required

To me, it seems as if the test might be broken.  I'll do some more
investigation, but thought I would report this. It works for libz which I
also had to install by hand.

Best,
Kasper


On Thu, Mar 26, 2015 at 2:49 PM, Dirk Eddelbuettel <edd at debian.org> wrote:

>
> On 26 March 2015 at 07:47, G?bor Cs?rdi wrote:
> | Dear All,
> |
> | zlib has been removed from R-devel src/extra recently, and building R
> | requires zlib >= 1.2.5. Ubuntu 12.04 LTS (also used on Travis CI) only
> has
> | 1.2.3.
> |
> | This means that the next version of R will probably not available on
> Ubuntu
> | 12.04. (Unless I am missing something of course.) Which is probably fine,
> | it is almost three years old now.
>
> I think Michael Rutter (who (re-)builds for 12.04 and other Ubuntu releases
> when I update the Debian package) can create a local backport of zlib.
>
> I somewhat recently started to (entirely locally) build some "backports"
> via
> https://launchpad.net/~edd/+archive/ubuntu/misc solely so that Travis can
> use
> them as binary.  It's good option to have.
>
> Dirk
>
> | I guess R-core is aware of this. Just wanted to be sure.
> |
> | Best Regads,
> | Gabor
> |
> |       [[alternative HTML version deleted]]
> |
> | ______________________________________________
> | R-devel at r-project.org mailing list
> | https://stat.ethz.ch/mailman/listinfo/r-devel
>
> --
> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Mar 27 22:36:02 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 27 Mar 2015 17:36:02 -0400
Subject: [Rd] robust updating methods
In-Reply-To: <5511F97F.8000108@gmail.com>
References: <550EF1C1.7080805@gmail.com>
	<CAJuCY5z9Q9T9Q3V-khXfSfwOOU_RrhWZDjw8JE7L2tUv1n6RVg@mail.gmail.com>
	<5511F97F.8000108@gmail.com>
Message-ID: <5515CD42.3010007@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

  [Sorry to those who don't like it for top-posting]

  Thierry, I'm curious whether this addresses your problem (although
we don't have a hard timetable for the next release [it has to avoid
conflicts with the 3.2.0 release in 2.5 weeks at the very least], so
this might be problematic if your package needs to depend on it).

  I'm still curious whether there are any ideas/opinions from other
readers.  Has anyone else struggled with this?  Is there a canonical
solution?

 Ben Bolker


On 15-03-24 07:55 PM, Ben Bolker wrote:
> On 15-03-23 12:55 PM, Thierry Onkelinx wrote:
>> Dear Ben,
> 
>> Last week I was struggling with incorporating lme4 into a
>> package. I traced the problem and made a reproducible example ( 
>> https://github.com/ThierryO/testlme4).  It looks very simular to 
>> the problem you describe.
> 
>> The 'tests' directory contains the reproducible examples.
>> confint() of a model as returned by a function fails. It even
>> fails when I try to calculate the confint() inside the same
>> function as the glmer() call (see the fit_model_ci function).
> 
>> Best regards,
> 
>> Thierry
> 
> 
> Ugh.  I can get this to work if I also try searching up the call 
> stack, as follows (within update.merMod).  This feels like "code 
> smell" to me though -- i.e., if I have to hack this hard I must be 
> doing something wrong/misunderstanding how the problem *should* be
> done.
> 
> 
> if (evaluate) { ff <- environment(formula(object)) pf <-
> parent.frame()  ## save parent frame in case we need it sf <-
> sys.frames()[[1]] tryCatch(eval(call, env=ff), error=function(e) { 
> tryCatch(eval(call, env=sf), error=function(e) { eval(call, pf) }) 
> }) } else call
> 
> Here is an adapted even-more-minimal version of your code, which 
> seems to work with the version of update.merMod I just pushed to 
> github, but fails for glm():
> 
> 
> ##
> https://github.com/ThierryO/testlme4/blob/master/R/fit_model_ci.R 
> fit_model_ci <- function(formula, dataset, mfun=glmer){ model <-
> mfun( formula = formula, data = dataset, family = "poisson" ) ci <-
> confint(model) return(list(model = model, confint = ci)) }
> 
> library("lme4") set.seed(101) dd <-
> data.frame(f=factor(rep(1:10,each=100)), y=rpois(2,1000)) 
> fit_model_ci(y~(1|f),dataset=dd) 
> fit_model_ci(y~(1|f),dataset=dd,mfun=glm)
> 
> 
> 
> 
> 
>> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek / 
>> Research Institute for Nature and Forest team Biometrie & 
>> Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25 1070 Anderlecht Belgium
> 
>> To call in the statistician after the experiment is done may be
>> no more than asking him to perform a post-mortem examination: he
>> may be able to say what the experiment died of. ~ Sir Ronald
>> Aylmer Fisher The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer
>> does not ensure that a reasonable answer can be extracted from a
>> given body of data. ~ John Tukey
> 
>> 2015-03-22 17:45 GMT+01:00 Ben Bolker <bbolker at gmail.com>:
> 
>> WARNING: this is long.  Sorry I couldn't find a way to compress 
>> it.
> 
>> Is there a reasonable way to design an update method so that it's
>>  robust to a variety of reasonable use cases of generating calls
>> or data inside or outside a function?  Is it even possible?
>> Should I just tell users "don't do that"?
> 
>> * `update.default()` uses `eval(call, parent.frame())`; this
>> fails when the call depends on objects that were defined in a
>> different environment (e.g., when the data are generated and the
>> model initially fitted within a function scope)
> 
>> * an alternative is to store the original environment in which
>> the fitting is done in the environment of the formula and use 
>> `eval(call, env=environment(formula(object)))`; this fails if the
>>  user tries to update the model originally fitted outside a 
>> function with data modified within a function ...
> 
>> * I think I've got a hack that works below, which first tries in 
>> the environment of the formula and falls back to the parent
>> frame if that fails, but I wonder if I'm missing something much
>> simpler ..
> 
>> Thoughts?  My understanding of environments and frames is still,
>>  after all these years, not what it should be ...
> 
>> I've thought of some other workarounds, none entirely 
>> satisfactory:
> 
>> * force evaluation of all elements in the original call *
>> printing components of the call can get ugly (can save the
>> original call before evaluating) * large objects in the call get
>> duplicated * don't use `eval(call)` for updates; instead try to
>> store everything internally * this works OK but has the same
>> drawback of potentially storing large extra copies * we could try
>> to use the model frame (which is stored already), but there are
>> issues with this (the basis of a whole separate rant) because the
>> model frame stores something in between predictor variables and
>> input variables. For example
> 
>> d <- data.frame(y=1:10,x=runif(10)) 
>> names(model.frame(lm(y~log(x),data=d))) ## "y" "log(x)"
> 
>> So if we wanted to do something like update to "y ~ sqrt(x)", it 
>> wouldn't work ...
> 
>> ================== update.envformula <- function(object,...) { 
>> extras <- match.call(expand.dots = FALSE)$... call <- 
>> getCall(object) for (i in names(extras)) { existing <- 
>> !is.na(match(names(extras), names(call))) for (a in 
>> names(extras)[existing]) call[[a]] <- extras[[a]] if 
>> (any(!existing)) { call <- c(as.list(call), extras[!existing])
>> call <- as.call(call) } } eval(call,
>> env=environment(formula(object))) ## enclos=parent.frame()
>> doesn't help }
> 
>> update.both <- function(object,...) { extras <- 
>> match.call(expand.dots = FALSE)$... call <- getCall(object) for
>> (i in names(extras)) { existing <- !is.na(match(names(extras), 
>> names(call))) for (a in names(extras)[existing]) call[[a]] <- 
>> extras[[a]] if (any(!existing)) { call <- c(as.list(call), 
>> extras[!existing]) call <- as.call(call) } } pf <-
>> parent.frame() ## save parent frame in case we need it
>> tryCatch(eval(call, env=environment(formula(object))),
>> error=function(e) { eval(call, pf) }) }
> 
>> ### TEST CASES
> 
>> set.seed(101) d <- data.frame(x=1:10,y=rnorm(10)) m1 <- 
>> lm(y~x,data=d)
> 
>> ##' define data within function, return fitted model f1 <- 
>> function() { d2 <- d lm(y~x,data=d2) return(lm(y~x,data=d2)) }
>> ##' define (and modify) data within function, try to update ##'
>> model fitted elsewhere f2 <- function(m) { d2 <- d; d2[1] <-
>> d2[1]+0 ## force copy update.default(m,data=d2) } ##' define (and
>> modify) data within function, try to update ##' model fitted
>> elsewhere (use envformula) f3 <- function(m) { d2 <- d; d2[1] <-
>> d2[1]+0 ## force copy update.envformula(m,data=d2) }
> 
>> ##' hack: first try the formula, then the parent frame ##' if
>> that doesn't work for any reason f4 <- function(m) { d2 <- d;
>> d2[1] <- d2[1]+0 ## force copy update.both(m,data=d2) }
> 
>> ## Case 1: fit within function m2 <- f1()
>> try(update.default(m2)) ## default: object 'd2' not found m3A <-
>> update.envformula(m2)  ## envformula: works m3B <-
>> update.both(m2)        ## works
> 
>> ## Case 2: update within function m4A <- f2(m1)  ## default:
>> works try(f3(m1))    ## envformula: object 'd2' not found m4B <-
>> f4(m1) ## works
> 
>>> 
>>> ______________________________________________ 
>>> R-devel at r-project.org mailing list 
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
> 
> 
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVFc1CAAoJEOCV5YRblxUHF+MH/3Y9uFZFolhx5b5jWSyXwQgp
i9oawx4K6il0qiAiDiO5D7NSSdc0u9jlgj8NjH0G2O9u3ctpvcYNVwa7cP9288Xz
xRyInnnh2FIpT6W0XyzJDivw5EX3IkyYuv6eDNqVyGcYXkvzJMA+vwMMWdGWEZbL
jKtDc0trG+9yJnwIi6DW6IQWPovrDaNxEinS+V7+DmYACQvJ4P2kg2u/ZsxAx89q
mcA1pS5usJjkOiQwBVUvV7l2UKNhHPFNwbBK1QdHgpP7PTdB52EQr+IyERhpf56s
8tYyNbSSPWoG9vt6/1pKyUK4iNRBtGgxtuozAv5OUjF8VGWGwUXBLo5G2yrBbs4=
=o1PJ
-----END PGP SIGNATURE-----


From thierry.onkelinx at inbo.be  Sat Mar 28 12:01:18 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Sat, 28 Mar 2015 12:01:18 +0100
Subject: [Rd] robust updating methods
In-Reply-To: <5515CD42.3010007@gmail.com>
References: <550EF1C1.7080805@gmail.com>
	<CAJuCY5z9Q9T9Q3V-khXfSfwOOU_RrhWZDjw8JE7L2tUv1n6RVg@mail.gmail.com>
	<5511F97F.8000108@gmail.com> <5515CD42.3010007@gmail.com>
Message-ID: <CAJuCY5wpjkKdL2UZUyBSQTzH9caqqN=qAkHo1eB_002CNywRsA@mail.gmail.com>

Dear Ben,

Fitting the model and calculating the confidence intervals within the same
function works (
https://github.com/ThierryO/testlme4/blob/master/tests/testthat/test_fit_model_ci.R
passes).
Fitting the model inside a function and calculating the confidence
intervals on the output still fails (
https://github.com/ThierryO/testlme4/blob/master/tests/testthat/test_fit_model.R
fails).

Directly calculating the confidence intervals in the same function is an
acceptable solution for my work. Thank you for this solution.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-03-27 22:36 GMT+01:00 Ben Bolker <bbolker at gmail.com>:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
>   [Sorry to those who don't like it for top-posting]
>
>   Thierry, I'm curious whether this addresses your problem (although
> we don't have a hard timetable for the next release [it has to avoid
> conflicts with the 3.2.0 release in 2.5 weeks at the very least], so
> this might be problematic if your package needs to depend on it).
>
>   I'm still curious whether there are any ideas/opinions from other
> readers.  Has anyone else struggled with this?  Is there a canonical
> solution?
>
>  Ben Bolker
>
>
> On 15-03-24 07:55 PM, Ben Bolker wrote:
> > On 15-03-23 12:55 PM, Thierry Onkelinx wrote:
> >> Dear Ben,
> >
> >> Last week I was struggling with incorporating lme4 into a
> >> package. I traced the problem and made a reproducible example (
> >> https://github.com/ThierryO/testlme4).  It looks very simular to
> >> the problem you describe.
> >
> >> The 'tests' directory contains the reproducible examples.
> >> confint() of a model as returned by a function fails. It even
> >> fails when I try to calculate the confint() inside the same
> >> function as the glmer() call (see the fit_model_ci function).
> >
> >> Best regards,
> >
> >> Thierry
> >
> >
> > Ugh.  I can get this to work if I also try searching up the call
> > stack, as follows (within update.merMod).  This feels like "code
> > smell" to me though -- i.e., if I have to hack this hard I must be
> > doing something wrong/misunderstanding how the problem *should* be
> > done.
> >
> >
> > if (evaluate) { ff <- environment(formula(object)) pf <-
> > parent.frame()  ## save parent frame in case we need it sf <-
> > sys.frames()[[1]] tryCatch(eval(call, env=ff), error=function(e) {
> > tryCatch(eval(call, env=sf), error=function(e) { eval(call, pf) })
> > }) } else call
> >
> > Here is an adapted even-more-minimal version of your code, which
> > seems to work with the version of update.merMod I just pushed to
> > github, but fails for glm():
> >
> >
> > ##
> > https://github.com/ThierryO/testlme4/blob/master/R/fit_model_ci.R
> > fit_model_ci <- function(formula, dataset, mfun=glmer){ model <-
> > mfun( formula = formula, data = dataset, family = "poisson" ) ci <-
> > confint(model) return(list(model = model, confint = ci)) }
> >
> > library("lme4") set.seed(101) dd <-
> > data.frame(f=factor(rep(1:10,each=100)), y=rpois(2,1000))
> > fit_model_ci(y~(1|f),dataset=dd)
> > fit_model_ci(y~(1|f),dataset=dd,mfun=glm)
> >
> >
> >
> >
> >
> >> ir. Thierry Onkelinx Instituut voor natuur- en bosonderzoek /
> >> Research Institute for Nature and Forest team Biometrie &
> >> Kwaliteitszorg / team Biometrics & Quality Assurance
> >> Kliniekstraat 25 1070 Anderlecht Belgium
> >
> >> To call in the statistician after the experiment is done may be
> >> no more than asking him to perform a post-mortem examination: he
> >> may be able to say what the experiment died of. ~ Sir Ronald
> >> Aylmer Fisher The plural of anecdote is not data. ~ Roger Brinner
> >> The combination of some data and an aching desire for an answer
> >> does not ensure that a reasonable answer can be extracted from a
> >> given body of data. ~ John Tukey
> >
> >> 2015-03-22 17:45 GMT+01:00 Ben Bolker <bbolker at gmail.com>:
> >
> >> WARNING: this is long.  Sorry I couldn't find a way to compress
> >> it.
> >
> >> Is there a reasonable way to design an update method so that it's
> >>  robust to a variety of reasonable use cases of generating calls
> >> or data inside or outside a function?  Is it even possible?
> >> Should I just tell users "don't do that"?
> >
> >> * `update.default()` uses `eval(call, parent.frame())`; this
> >> fails when the call depends on objects that were defined in a
> >> different environment (e.g., when the data are generated and the
> >> model initially fitted within a function scope)
> >
> >> * an alternative is to store the original environment in which
> >> the fitting is done in the environment of the formula and use
> >> `eval(call, env=environment(formula(object)))`; this fails if the
> >>  user tries to update the model originally fitted outside a
> >> function with data modified within a function ...
> >
> >> * I think I've got a hack that works below, which first tries in
> >> the environment of the formula and falls back to the parent
> >> frame if that fails, but I wonder if I'm missing something much
> >> simpler ..
> >
> >> Thoughts?  My understanding of environments and frames is still,
> >>  after all these years, not what it should be ...
> >
> >> I've thought of some other workarounds, none entirely
> >> satisfactory:
> >
> >> * force evaluation of all elements in the original call *
> >> printing components of the call can get ugly (can save the
> >> original call before evaluating) * large objects in the call get
> >> duplicated * don't use `eval(call)` for updates; instead try to
> >> store everything internally * this works OK but has the same
> >> drawback of potentially storing large extra copies * we could try
> >> to use the model frame (which is stored already), but there are
> >> issues with this (the basis of a whole separate rant) because the
> >> model frame stores something in between predictor variables and
> >> input variables. For example
> >
> >> d <- data.frame(y=1:10,x=runif(10))
> >> names(model.frame(lm(y~log(x),data=d))) ## "y" "log(x)"
> >
> >> So if we wanted to do something like update to "y ~ sqrt(x)", it
> >> wouldn't work ...
> >
> >> ================== update.envformula <- function(object,...) {
> >> extras <- match.call(expand.dots = FALSE)$... call <-
> >> getCall(object) for (i in names(extras)) { existing <-
> >> !is.na(match(names(extras), names(call))) for (a in
> >> names(extras)[existing]) call[[a]] <- extras[[a]] if
> >> (any(!existing)) { call <- c(as.list(call), extras[!existing])
> >> call <- as.call(call) } } eval(call,
> >> env=environment(formula(object))) ## enclos=parent.frame()
> >> doesn't help }
> >
> >> update.both <- function(object,...) { extras <-
> >> match.call(expand.dots = FALSE)$... call <- getCall(object) for
> >> (i in names(extras)) { existing <- !is.na(match(names(extras),
> >> names(call))) for (a in names(extras)[existing]) call[[a]] <-
> >> extras[[a]] if (any(!existing)) { call <- c(as.list(call),
> >> extras[!existing]) call <- as.call(call) } } pf <-
> >> parent.frame() ## save parent frame in case we need it
> >> tryCatch(eval(call, env=environment(formula(object))),
> >> error=function(e) { eval(call, pf) }) }
> >
> >> ### TEST CASES
> >
> >> set.seed(101) d <- data.frame(x=1:10,y=rnorm(10)) m1 <-
> >> lm(y~x,data=d)
> >
> >> ##' define data within function, return fitted model f1 <-
> >> function() { d2 <- d lm(y~x,data=d2) return(lm(y~x,data=d2)) }
> >> ##' define (and modify) data within function, try to update ##'
> >> model fitted elsewhere f2 <- function(m) { d2 <- d; d2[1] <-
> >> d2[1]+0 ## force copy update.default(m,data=d2) } ##' define (and
> >> modify) data within function, try to update ##' model fitted
> >> elsewhere (use envformula) f3 <- function(m) { d2 <- d; d2[1] <-
> >> d2[1]+0 ## force copy update.envformula(m,data=d2) }
> >
> >> ##' hack: first try the formula, then the parent frame ##' if
> >> that doesn't work for any reason f4 <- function(m) { d2 <- d;
> >> d2[1] <- d2[1]+0 ## force copy update.both(m,data=d2) }
> >
> >> ## Case 1: fit within function m2 <- f1()
> >> try(update.default(m2)) ## default: object 'd2' not found m3A <-
> >> update.envformula(m2)  ## envformula: works m3B <-
> >> update.both(m2)        ## works
> >
> >> ## Case 2: update within function m4A <- f2(m1)  ## default:
> >> works try(f3(m1))    ## envformula: object 'd2' not found m4B <-
> >> f4(m1) ## works
> >
> >>>
> >>> ______________________________________________
> >>> R-devel at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>
> >
> >
> >
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.11 (GNU/Linux)
>
> iQEcBAEBAgAGBQJVFc1CAAoJEOCV5YRblxUHF+MH/3Y9uFZFolhx5b5jWSyXwQgp
> i9oawx4K6il0qiAiDiO5D7NSSdc0u9jlgj8NjH0G2O9u3ctpvcYNVwa7cP9288Xz
> xRyInnnh2FIpT6W0XyzJDivw5EX3IkyYuv6eDNqVyGcYXkvzJMA+vwMMWdGWEZbL
> jKtDc0trG+9yJnwIi6DW6IQWPovrDaNxEinS+V7+DmYACQvJ4P2kg2u/ZsxAx89q
> mcA1pS5usJjkOiQwBVUvV7l2UKNhHPFNwbBK1QdHgpP7PTdB52EQr+IyERhpf56s
> 8tYyNbSSPWoG9vt6/1pKyUK4iNRBtGgxtuozAv5OUjF8VGWGwUXBLo5G2yrBbs4=
> =o1PJ
> -----END PGP SIGNATURE-----
>

	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Mon Mar 30 22:10:16 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 30 Mar 2015 15:10:16 -0500
Subject: [Rd] Segfault with match()
Message-ID: <CABdHhvGoW+p0Rw3Oeg7bWdi-XsXAv-XAbS-Q9rv90StXAtnXKw@mail.gmail.com>

This is admittedly a contrived example, but...

data(housing, package ="MASS")
x <- housing$Type + housing$Sat
match(x, unique(x))

Hadley

-- 
http://had.co.nz/


From vobencha at fredhutch.org  Mon Mar 30 22:40:07 2015
From: vobencha at fredhutch.org (Valerie Obenchain)
Date: Mon, 30 Mar 2015 13:40:07 -0700
Subject: [Rd] nested parallel workers
In-Reply-To: <DE23891F-86FE-4F68-8838-45670FF7C8A0@r-project.org>
References: <551310AE.30008@fredhutch.org>
	<DE23891F-86FE-4F68-8838-45670FF7C8A0@r-project.org>
Message-ID: <5519B4A7.8030002@fredhutch.org>

On 03/25/2015 07:48 PM, Simon Urbanek wrote:
> On Mar 25, 2015, at 3:46 PM, Valerie Obenchain <vobencha at fredhutch.org> wrote:
>
>> Hi Simon,
>>
>> I'm having trouble with nested parallel workers, specifically, forking inside socket connections.
>>
>
> You simply can't by definition - when you fork *all* the workers share the same connection inherited from the parent, so you cannot use any I/O operations that you didn't start in the worker since reading in one worker affects all the workers.
>

Sorry if I'm missing the obvious here -
I thought since the fork workers were shut down by the time the SOCK 
worker returned to its master conflicting I/O wouldn't be a problem.

There are quite a few examples floating around where SOCK workers are 
spawned on a cluster and multicore workers are called within them. If I 
understand correctly this should not be done (or at least not 
encouraged). Instead, nested parallel should only be done with 
distributed memory workers, SOCK, MPI etc.

Thanks.
Valerie


> Cheers,
> Simon
>
>
>> When mclapply is called inside a SOCK, PSOCK or FORK worker I get an
>> error in unserialize().
>>
>> cl <- makeCluster(1, "SOCK")
>>
>> fun = function(i) {
>>   library(parallel)
>>   mclapply(1:2, sqrt)
>> }
>>
>> Failure occurs after multiple calls to clusterApply:
>>
>>> clusterApply(cl, 1, fun)
>> [[1]]
>> [[1]][[1]]
>> [1] 1
>>
>> [[1]][[2]]
>> [1] 1.414214
>>
>>> clusterApply(cl, 1, fun)
>> [[1]]
>> [[1]][[1]]
>> [1] 1
>>
>> [[1]][[2]]
>> [1] 1.414214
>>
>>> clusterApply(cl, 1, fun)
>> Error in unserialize(node$con) : error reading from connection
>>
>>
>> This example is from Martin and may be a different problem.
>>
>> ~/tmp >cat test1.R
>> ## like mclapply
>> ## should run 'forever' but terminates semi-randomly
>> library(parallel)
>> children <- parallel:::children
>>
>> while (TRUE) {
>>     n <- 8            ## n == dectectCores()
>>     jobs <- lapply(seq_len(n), function(i) mcparallel(Sys.sleep(20)))
>>     mccollect(children(jobs), FALSE)
>>     parallel:::mckill(children(jobs), tools::SIGTERM)
>>     leni <- length(mccollect(children(jobs)))
>>     message("leni: ", leni)
>> }
>>
>> ~/tmp >R-dev --vanilla --slave -f test1.R
>> leni: 6
>> leni: 7
>> leni: 7
>> leni: 7
>> leni: 7
>> leni: 7
>> leni: 7
>> leni: 7
>> leni: 8
>> leni: 7
>> leni: 7
>> leni: 7
>> ~/tmp >
>>
>>
>> Thanks.
>> Valerie
>>
>>
>>> sessionInfo()
>> R Under development (unstable) (2015-03-18 r68009)
>> Platform: x86_64-unknown-linux-gnu (64-bit)
>> Running under: Fedora 21 (Twenty One)
>>
>> locale:
>> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>> [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] parallel  stats     graphics  grDevices utils     datasets  methods
>> [8] base
>>
>> loaded via a namespace (and not attached):
>> [1] snow_0.3-13
>>
>>
>> --
>> Computational Biology / Fred Hutchinson Cancer Research Center
>> 1100 Fairview Ave. N, Seattle, WA 98109
>>
>> Email: vobencha at fredhutch.org
>> Phone: (206) 667-3158
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From wdunlap at tibco.com  Mon Mar 30 22:50:35 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 30 Mar 2015 13:50:35 -0700
Subject: [Rd] Segfault with match()
In-Reply-To: <CABdHhvGoW+p0Rw3Oeg7bWdi-XsXAv-XAbS-Q9rv90StXAtnXKw@mail.gmail.com>
References: <CABdHhvGoW+p0Rw3Oeg7bWdi-XsXAv-XAbS-Q9rv90StXAtnXKw@mail.gmail.com>
Message-ID: <CAF8bMcaO+_La_wU1s7uFpMo2atfxDrcLogWvsHz7HaO8JfESGw@mail.gmail.com>

Did you leave out the warning from "+", which should be an error,
as it produces an illegal ordered factor in this case and factor+factor
is nonsensical?  Or is the warning missing in the current development
version of R?

> x <- factor("A", ordered=FALSE) + factor(c("B","C"), ordered=TRUE)
Warning message:
Incompatible methods ("Ops.factor", "Ops.ordered") for "+"
> str(x) # 2 levels, so integer codes of 3 is illegal
ordered[1:2] w/ 2 levels B<C:  2 3


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Mar 30, 2015 at 1:10 PM, Hadley Wickham <h.wickham at gmail.com> wrote:

> This is admittedly a contrived example, but...
>
> data(housing, package ="MASS")
> x <- housing$Type + housing$Sat
> match(x, unique(x))
>
> Hadley
>
> --
> http://had.co.nz/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Mon Mar 30 23:07:35 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 30 Mar 2015 14:07:35 -0700
Subject: [Rd] Segfault with match()
In-Reply-To: <CAF8bMcaO+_La_wU1s7uFpMo2atfxDrcLogWvsHz7HaO8JfESGw@mail.gmail.com>
References: <CABdHhvGoW+p0Rw3Oeg7bWdi-XsXAv-XAbS-Q9rv90StXAtnXKw@mail.gmail.com>
	<CAF8bMcaO+_La_wU1s7uFpMo2atfxDrcLogWvsHz7HaO8JfESGw@mail.gmail.com>
Message-ID: <CAF8bMcbAORmPtwypgLG+ya9z+64KkdW=WNMS=Y+-P0g2z=xCOQ@mail.gmail.com>

For consistency with factor+factor and factor+numeric, factor+ordered
should produce a logical vector filled with NAs, not throw an error.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Mar 30, 2015 at 1:50 PM, William Dunlap <wdunlap at tibco.com> wrote:

> Did you leave out the warning from "+", which should be an error,
> as it produces an illegal ordered factor in this case and factor+factor
> is nonsensical?  Or is the warning missing in the current development
> version of R?
>
> > x <- factor("A", ordered=FALSE) + factor(c("B","C"), ordered=TRUE)
> Warning message:
> Incompatible methods ("Ops.factor", "Ops.ordered") for "+"
> > str(x) # 2 levels, so integer codes of 3 is illegal
> ordered[1:2] w/ 2 levels B<C:  2 3
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Mon, Mar 30, 2015 at 1:10 PM, Hadley Wickham <h.wickham at gmail.com>
> wrote:
>
>> This is admittedly a contrived example, but...
>>
>> data(housing, package ="MASS")
>> x <- housing$Type + housing$Sat
>> match(x, unique(x))
>>
>> Hadley
>>
>> --
>> http://had.co.nz/
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>

	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Mon Mar 30 23:08:06 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 30 Mar 2015 16:08:06 -0500
Subject: [Rd] Segfault with match()
In-Reply-To: <CAF8bMcaO+_La_wU1s7uFpMo2atfxDrcLogWvsHz7HaO8JfESGw@mail.gmail.com>
References: <CABdHhvGoW+p0Rw3Oeg7bWdi-XsXAv-XAbS-Q9rv90StXAtnXKw@mail.gmail.com>
	<CAF8bMcaO+_La_wU1s7uFpMo2atfxDrcLogWvsHz7HaO8JfESGw@mail.gmail.com>
Message-ID: <CABdHhvEXZ-4ZO8DUsb=bNaJ4vSgWP8qYWwo3Ow46x3wpsN-dWg@mail.gmail.com>

I left out the warning - it's still there. The output object is
malformed but either +.factor should prevent this or match() should
check.

Hadley

On Mon, Mar 30, 2015 at 3:50 PM, William Dunlap <wdunlap at tibco.com> wrote:
> Did you leave out the warning from "+", which should be an error,
> as it produces an illegal ordered factor in this case and factor+factor
> is nonsensical?  Or is the warning missing in the current development
> version of R?
>
>> x <- factor("A", ordered=FALSE) + factor(c("B","C"), ordered=TRUE)
> Warning message:
> Incompatible methods ("Ops.factor", "Ops.ordered") for "+"
>> str(x) # 2 levels, so integer codes of 3 is illegal
> ordered[1:2] w/ 2 levels B<C:  2 3
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Mon, Mar 30, 2015 at 1:10 PM, Hadley Wickham <h.wickham at gmail.com> wrote:
>>
>> This is admittedly a contrived example, but...
>>
>> data(housing, package ="MASS")
>> x <- housing$Type + housing$Sat
>> match(x, unique(x))
>>
>> Hadley
>>
>> --
>> http://had.co.nz/
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>



-- 
http://had.co.nz/


From simon.urbanek at r-project.org  Mon Mar 30 23:51:17 2015
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 30 Mar 2015 17:51:17 -0400
Subject: [Rd] nested parallel workers
In-Reply-To: <5519B4A7.8030002@fredhutch.org>
References: <551310AE.30008@fredhutch.org>
	<DE23891F-86FE-4F68-8838-45670FF7C8A0@r-project.org>
	<5519B4A7.8030002@fredhutch.org>
Message-ID: <BB1E8ECF-DFEC-481B-BA46-3EB8AF928432@r-project.org>


On Mar 30, 2015, at 4:40 PM, Valerie Obenchain <vobencha at fredhutch.org> wrote:

> On 03/25/2015 07:48 PM, Simon Urbanek wrote:
>> On Mar 25, 2015, at 3:46 PM, Valerie Obenchain <vobencha at fredhutch.org> wrote:
>> 
>>> Hi Simon,
>>> 
>>> I'm having trouble with nested parallel workers, specifically, forking inside socket connections.
>>> 
>> 
>> You simply can't by definition - when you fork *all* the workers share the same connection inherited from the parent, so you cannot use any I/O operations that you didn't start in the worker since reading in one worker affects all the workers.
>> 
> 
> Sorry if I'm missing the obvious here -
> I thought since the fork workers were shut down by the time the SOCK worker returned to its master conflicting I/O wouldn't be a problem.
> 

If the workers are done and don't use I/O then all is well. However, it's not easy to guarantee that they don't use I/O since they all already come with active sockets, so e.g. on exit they may flush the socket buffers which would confuse the recipient. Interestingly your example works fine on OS X but fails on Linux. I'll try to dig deeper in a quiet minute --- in principle it should be sufficient to close all FDs right away, which you can do when using mcparallel() but not using mclapply().

Cheers,
Simon



> There are quite a few examples floating around where SOCK workers are spawned on a cluster and multicore workers are called within them. If I understand correctly this should not be done (or at least not encouraged). Instead, nested parallel should only be done with distributed memory workers, SOCK, MPI etc.
> 
> Thanks.
> Valerie
> 
> 
>> Cheers,
>> Simon
>> 
>> 
>>> When mclapply is called inside a SOCK, PSOCK or FORK worker I get an
>>> error in unserialize().
>>> 
>>> cl <- makeCluster(1, "SOCK")
>>> 
>>> fun = function(i) {
>>>  library(parallel)
>>>  mclapply(1:2, sqrt)
>>> }
>>> 
>>> Failure occurs after multiple calls to clusterApply:
>>> 
>>>> clusterApply(cl, 1, fun)
>>> [[1]]
>>> [[1]][[1]]
>>> [1] 1
>>> 
>>> [[1]][[2]]
>>> [1] 1.414214
>>> 
>>>> clusterApply(cl, 1, fun)
>>> [[1]]
>>> [[1]][[1]]
>>> [1] 1
>>> 
>>> [[1]][[2]]
>>> [1] 1.414214
>>> 
>>>> clusterApply(cl, 1, fun)
>>> Error in unserialize(node$con) : error reading from connection
>>> 
>>> 
>>> This example is from Martin and may be a different problem.
>>> 
>>> ~/tmp >cat test1.R
>>> ## like mclapply
>>> ## should run 'forever' but terminates semi-randomly
>>> library(parallel)
>>> children <- parallel:::children
>>> 
>>> while (TRUE) {
>>>    n <- 8            ## n == dectectCores()
>>>    jobs <- lapply(seq_len(n), function(i) mcparallel(Sys.sleep(20)))
>>>    mccollect(children(jobs), FALSE)
>>>    parallel:::mckill(children(jobs), tools::SIGTERM)
>>>    leni <- length(mccollect(children(jobs)))
>>>    message("leni: ", leni)
>>> }
>>> 
>>> ~/tmp >R-dev --vanilla --slave -f test1.R
>>> leni: 6
>>> leni: 7
>>> leni: 7
>>> leni: 7
>>> leni: 7
>>> leni: 7
>>> leni: 7
>>> leni: 7
>>> leni: 8
>>> leni: 7
>>> leni: 7
>>> leni: 7
>>> ~/tmp >
>>> 
>>> 
>>> Thanks.
>>> Valerie
>>> 
>>> 
>>>> sessionInfo()
>>> R Under development (unstable) (2015-03-18 r68009)
>>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>> Running under: Fedora 21 (Twenty One)
>>> 
>>> locale:
>>> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>> [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>> 
>>> attached base packages:
>>> [1] parallel  stats     graphics  grDevices utils     datasets  methods
>>> [8] base
>>> 
>>> loaded via a namespace (and not attached):
>>> [1] snow_0.3-13
>>> 
>>> 
>>> --
>>> Computational Biology / Fred Hutchinson Cancer Research Center
>>> 1100 Fairview Ave. N, Seattle, WA 98109
>>> 
>>> Email: vobencha at fredhutch.org
>>> Phone: (206) 667-3158
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>> 
> 


From vobencha at fredhutch.org  Tue Mar 31 00:39:37 2015
From: vobencha at fredhutch.org (Valerie Obenchain)
Date: Mon, 30 Mar 2015 15:39:37 -0700
Subject: [Rd] nested parallel workers
In-Reply-To: <BB1E8ECF-DFEC-481B-BA46-3EB8AF928432@r-project.org>
References: <551310AE.30008@fredhutch.org>
	<DE23891F-86FE-4F68-8838-45670FF7C8A0@r-project.org>
	<5519B4A7.8030002@fredhutch.org>
	<BB1E8ECF-DFEC-481B-BA46-3EB8AF928432@r-project.org>
Message-ID: <5519D0A9.4030103@fredhutch.org>

On 03/30/2015 02:51 PM, Simon Urbanek wrote:
>
> On Mar 30, 2015, at 4:40 PM, Valerie Obenchain <vobencha at fredhutch.org> wrote:
>
>> On 03/25/2015 07:48 PM, Simon Urbanek wrote:
>>> On Mar 25, 2015, at 3:46 PM, Valerie Obenchain <vobencha at fredhutch.org> wrote:
>>>
>>>> Hi Simon,
>>>>
>>>> I'm having trouble with nested parallel workers, specifically, forking inside socket connections.
>>>>
>>>
>>> You simply can't by definition - when you fork *all* the workers share the same connection inherited from the parent, so you cannot use any I/O operations that you didn't start in the worker since reading in one worker affects all the workers.
>>>
>>
>> Sorry if I'm missing the obvious here -
>> I thought since the fork workers were shut down by the time the SOCK worker returned to its master conflicting I/O wouldn't be a problem.
>>
>
> If the workers are done and don't use I/O then all is well. However, it's not easy to guarantee that they don't use I/O since they all already come with active sockets, so e.g. on exit they may flush the socket buffers which would confuse the recipient. Interestingly your example works fine on OS X but fails on Linux. I'll try to dig deeper in a quiet minute --- in principle it should be sufficient to close all FDs right away, which you can do when using mcparallel() but not using mclapply().
>

I see. Thanks for the explanation.

Valerie


> Cheers,
> Simon
>
>
>
>> There are quite a few examples floating around where SOCK workers are spawned on a cluster and multicore workers are called within them. If I understand correctly this should not be done (or at least not encouraged). Instead, nested parallel should only be done with distributed memory workers, SOCK, MPI etc.
>>
>> Thanks.
>> Valerie
>>
>>
>>> Cheers,
>>> Simon
>>>
>>>
>>>> When mclapply is called inside a SOCK, PSOCK or FORK worker I get an
>>>> error in unserialize().
>>>>
>>>> cl <- makeCluster(1, "SOCK")
>>>>
>>>> fun = function(i) {
>>>>   library(parallel)
>>>>   mclapply(1:2, sqrt)
>>>> }
>>>>
>>>> Failure occurs after multiple calls to clusterApply:
>>>>
>>>>> clusterApply(cl, 1, fun)
>>>> [[1]]
>>>> [[1]][[1]]
>>>> [1] 1
>>>>
>>>> [[1]][[2]]
>>>> [1] 1.414214
>>>>
>>>>> clusterApply(cl, 1, fun)
>>>> [[1]]
>>>> [[1]][[1]]
>>>> [1] 1
>>>>
>>>> [[1]][[2]]
>>>> [1] 1.414214
>>>>
>>>>> clusterApply(cl, 1, fun)
>>>> Error in unserialize(node$con) : error reading from connection
>>>>
>>>>
>>>> This example is from Martin and may be a different problem.
>>>>
>>>> ~/tmp >cat test1.R
>>>> ## like mclapply
>>>> ## should run 'forever' but terminates semi-randomly
>>>> library(parallel)
>>>> children <- parallel:::children
>>>>
>>>> while (TRUE) {
>>>>     n <- 8            ## n == dectectCores()
>>>>     jobs <- lapply(seq_len(n), function(i) mcparallel(Sys.sleep(20)))
>>>>     mccollect(children(jobs), FALSE)
>>>>     parallel:::mckill(children(jobs), tools::SIGTERM)
>>>>     leni <- length(mccollect(children(jobs)))
>>>>     message("leni: ", leni)
>>>> }
>>>>
>>>> ~/tmp >R-dev --vanilla --slave -f test1.R
>>>> leni: 6
>>>> leni: 7
>>>> leni: 7
>>>> leni: 7
>>>> leni: 7
>>>> leni: 7
>>>> leni: 7
>>>> leni: 7
>>>> leni: 8
>>>> leni: 7
>>>> leni: 7
>>>> leni: 7
>>>> ~/tmp >
>>>>
>>>>
>>>> Thanks.
>>>> Valerie
>>>>
>>>>
>>>>> sessionInfo()
>>>> R Under development (unstable) (2015-03-18 r68009)
>>>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>>> Running under: Fedora 21 (Twenty One)
>>>>
>>>> locale:
>>>> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>>> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>>> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>>> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>>> [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>>
>>>> attached base packages:
>>>> [1] parallel  stats     graphics  grDevices utils     datasets  methods
>>>> [8] base
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] snow_0.3-13
>>>>
>>>>
>>>> --
>>>> Computational Biology / Fred Hutchinson Cancer Research Center
>>>> 1100 Fairview Ave. N, Seattle, WA 98109
>>>>
>>>> Email: vobencha at fredhutch.org
>>>> Phone: (206) 667-3158
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>
>


From luke-tierney at uiowa.edu  Tue Mar 31 00:41:39 2015
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Mon, 30 Mar 2015 17:41:39 -0500
Subject: [Rd] Segfault with match()
In-Reply-To: <CABdHhvEXZ-4ZO8DUsb=bNaJ4vSgWP8qYWwo3Ow46x3wpsN-dWg@mail.gmail.com>
References: <CABdHhvGoW+p0Rw3Oeg7bWdi-XsXAv-XAbS-Q9rv90StXAtnXKw@mail.gmail.com>
	<CAF8bMcaO+_La_wU1s7uFpMo2atfxDrcLogWvsHz7HaO8JfESGw@mail.gmail.com>
	<CABdHhvEXZ-4ZO8DUsb=bNaJ4vSgWP8qYWwo3Ow46x3wpsN-dWg@mail.gmail.com>
Message-ID: <alpine.DEB.2.10.1503301738110.2707@luke-Latitude>

The segfault was occurring in Rf_asCharacterFactor, which was using
the levels attribute without sanity checks. Sanity checks are now
added (r68119 in trunk and r68120. in R-3-2-branch), which now gives

> data(housing, package ="MASS")
> x <- housing$Type + housing$Sat
Warning message:
Incompatible methods ("Ops.factor", "Ops.ordered") for "+" 
> match(x, unique(x))
Error in match(x, unique(x)) : malformed factor

I'll leave it to others to figure out how not to get the malformed
factor in the first place (but as a user could intentionally create
one we need the sanity checks anyway).

Best,

luke

On Mon, 30 Mar 2015, Hadley Wickham wrote:

> I left out the warning - it's still there. The output object is
> malformed but either +.factor should prevent this or match() should
> check.
>
> Hadley
>
> On Mon, Mar 30, 2015 at 3:50 PM, William Dunlap <wdunlap at tibco.com> wrote:
>> Did you leave out the warning from "+", which should be an error,
>> as it produces an illegal ordered factor in this case and factor+factor
>> is nonsensical?  Or is the warning missing in the current development
>> version of R?
>>
>>> x <- factor("A", ordered=FALSE) + factor(c("B","C"), ordered=TRUE)
>> Warning message:
>> Incompatible methods ("Ops.factor", "Ops.ordered") for "+"
>>> str(x) # 2 levels, so integer codes of 3 is illegal
>> ordered[1:2] w/ 2 levels B<C:  2 3
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>> On Mon, Mar 30, 2015 at 1:10 PM, Hadley Wickham <h.wickham at gmail.com> wrote:
>>>
>>> This is admittedly a contrived example, but...
>>>
>>> data(housing, package ="MASS")
>>> x <- housing$Type + housing$Sat
>>> match(x, unique(x))
>>>
>>> Hadley
>>>
>>> --
>>> http://had.co.nz/
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
>
>
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From kasperdanielhansen at gmail.com  Tue Mar 31 02:51:35 2015
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Mon, 30 Mar 2015 20:51:35 -0400
Subject: [Rd] About removing zlib from R-devel
In-Reply-To: <CAC2h7utZmvRWccfJM60o40Qydbe+7d9vcQP5w3VbhCKQPEd1ig@mail.gmail.com>
References: <CABtg=KkKOmhGait1QAR_5LiYrY0hgggpXDhWqGFfTsJ+jaOiPA@mail.gmail.com>
	<21780.21680.951993.617987@max.nulle.part>
	<CAC2h7utZmvRWccfJM60o40Qydbe+7d9vcQP5w3VbhCKQPEd1ig@mail.gmail.com>
Message-ID: <CAC2h7uuOD0L6Kv3rmiSiqb5jstC6rGb3zuYk440rcb0gF5T3Bw@mail.gmail.com>

For people reading this: I was installing bzip2 by hand.  Two things to
bear in mind (1) it only installs a shared library if you use a special
Makefile (this is clearly stated in the installation docs) and (2) I had to
symlink libbz2.so.1 to libbz2.so.1.0.6 (the included libbz2.so.1.0 was not
being picked up).

Best,
Kasper

On Fri, Mar 27, 2015 at 11:19 AM, Kasper Daniel Hansen <
kasperdanielhansen at gmail.com> wrote:

> Related to this question:
>
> I have installed bzip2 1.0.6 by hand, but configure still fails.  When I
> look at config.log I get the following
>
> configure:34150: /usr/bin/gcc -std=gnu99 -o conftest -g -O2
> -march=amdfam10  -g -O2 -march=amdfam10  -L/usr/local/lib64 confte
> st.c -lbz2 -lz -lrt -ldl -lm  >&5
> conftest.c: In function 'main':
> conftest.c:250: warning: initialization discards qualifiers from pointer
> target type
> conftest.c:251: warning: implicit declaration of function 'exit'
> conftest.c:251: warning: incompatible implicit declaration of built-in
> function 'exit'
> conftest.c:251: warning: implicit declaration of function 'strcmp'
>
> for the program
>
> | #ifdef HAVE_BZLIB_H
> | #include <bzlib.h>
> | #endif
> | int main() {
> |     char *ver = BZ2_bzlibVersion();
> |     exit(strcmp(ver, "1.0.6") < 0);
> | }
> |
> configure:34167: result: no
> configure:34173: checking whether bzip2 support suffices
> configure:34180: error: bzip2 library and headers are required
>
> To me, it seems as if the test might be broken.  I'll do some more
> investigation, but thought I would report this. It works for libz which I
> also had to install by hand.
>
> Best,
> Kasper
>
>
> On Thu, Mar 26, 2015 at 2:49 PM, Dirk Eddelbuettel <edd at debian.org> wrote:
>
>>
>> On 26 March 2015 at 07:47, G?bor Cs?rdi wrote:
>> | Dear All,
>> |
>> | zlib has been removed from R-devel src/extra recently, and building R
>> | requires zlib >= 1.2.5. Ubuntu 12.04 LTS (also used on Travis CI) only
>> has
>> | 1.2.3.
>> |
>> | This means that the next version of R will probably not available on
>> Ubuntu
>> | 12.04. (Unless I am missing something of course.) Which is probably
>> fine,
>> | it is almost three years old now.
>>
>> I think Michael Rutter (who (re-)builds for 12.04 and other Ubuntu
>> releases
>> when I update the Debian package) can create a local backport of zlib.
>>
>> I somewhat recently started to (entirely locally) build some "backports"
>> via
>> https://launchpad.net/~edd/+archive/ubuntu/misc solely so that Travis
>> can use
>> them as binary.  It's good option to have.
>>
>> Dirk
>>
>> | I guess R-core is aware of this. Just wanted to be sure.
>> |
>> | Best Regads,
>> | Gabor
>> |
>> |       [[alternative HTML version deleted]]
>> |
>> | ______________________________________________
>> | R-devel at r-project.org mailing list
>> | https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> --
>> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>

	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Tue Mar 31 08:48:46 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 31 Mar 2015 07:48:46 +0100
Subject: [Rd] About removing zlib from R-devel
In-Reply-To: <CAC2h7uuOD0L6Kv3rmiSiqb5jstC6rGb3zuYk440rcb0gF5T3Bw@mail.gmail.com>
References: <CABtg=KkKOmhGait1QAR_5LiYrY0hgggpXDhWqGFfTsJ+jaOiPA@mail.gmail.com>	<21780.21680.951993.617987@max.nulle.part>	<CAC2h7utZmvRWccfJM60o40Qydbe+7d9vcQP5w3VbhCKQPEd1ig@mail.gmail.com>
	<CAC2h7uuOD0L6Kv3rmiSiqb5jstC6rGb3zuYk440rcb0gF5T3Bw@mail.gmail.com>
Message-ID: <551A434E.3050605@stats.ox.ac.uk>

On 31/03/2015 01:51, Kasper Daniel Hansen wrote:
> For people reading this: I was installing bzip2 by hand.  Two things to
> bear in mind (1) it only installs a shared library if you use a special

But R does not require a shared library for bzip2 ....

> Makefile (this is clearly stated in the installation docs) and (2) I had to
> symlink libbz2.so.1 to libbz2.so.1.0.6 (the included libbz2.so.1.0 was not
> being picked up).

The most complete way on an ELF system would be to link

libbz2.so.1.0.6 to libbz2.so.1.0
libbz2.so.1.0 to libbz2.so.1
libbz2.so.1 to libbz2.so

as done on Solaris, but I see Fedora has

libbz2.so.1.0.6 to libbz2.so.1
libbz2.so.1 to libbz2.so

and OS X has

libbz2.1.0.5.dylib to libbz2.1.0.dylib
libbz2.dylib to libbz2.1.0.dylib

!  (It does have 1.0.6, so the first seems a back-compatibility link.)


>
> Best,
> Kasper
>
> On Fri, Mar 27, 2015 at 11:19 AM, Kasper Daniel Hansen <
> kasperdanielhansen at gmail.com> wrote:
>
>> Related to this question:
>>
>> I have installed bzip2 1.0.6 by hand, but configure still fails.  When I
>> look at config.log I get the following
>>
>> configure:34150: /usr/bin/gcc -std=gnu99 -o conftest -g -O2
>> -march=amdfam10  -g -O2 -march=amdfam10  -L/usr/local/lib64 confte
>> st.c -lbz2 -lz -lrt -ldl -lm  >&5
>> conftest.c: In function 'main':
>> conftest.c:250: warning: initialization discards qualifiers from pointer
>> target type
>> conftest.c:251: warning: implicit declaration of function 'exit'
>> conftest.c:251: warning: incompatible implicit declaration of built-in
>> function 'exit'
>> conftest.c:251: warning: implicit declaration of function 'strcmp'
>>
>> for the program
>>
>> | #ifdef HAVE_BZLIB_H
>> | #include <bzlib.h>
>> | #endif
>> | int main() {
>> |     char *ver = BZ2_bzlibVersion();
>> |     exit(strcmp(ver, "1.0.6") < 0);
>> | }
>> |
>> configure:34167: result: no
>> configure:34173: checking whether bzip2 support suffices
>> configure:34180: error: bzip2 library and headers are required
>>
>> To me, it seems as if the test might be broken.  I'll do some more
>> investigation, but thought I would report this. It works for libz which I
>> also had to install by hand.
>>
>> Best,
>> Kasper
>>
>>
>> On Thu, Mar 26, 2015 at 2:49 PM, Dirk Eddelbuettel <edd at debian.org> wrote:
>>
>>>
>>> On 26 March 2015 at 07:47, G?bor Cs?rdi wrote:
>>> | Dear All,
>>> |
>>> | zlib has been removed from R-devel src/extra recently, and building R
>>> | requires zlib >= 1.2.5. Ubuntu 12.04 LTS (also used on Travis CI) only
>>> has
>>> | 1.2.3.
>>> |
>>> | This means that the next version of R will probably not available on
>>> Ubuntu
>>> | 12.04. (Unless I am missing something of course.) Which is probably
>>> fine,
>>> | it is almost three years old now.
>>>
>>> I think Michael Rutter (who (re-)builds for 12.04 and other Ubuntu
>>> releases
>>> when I update the Debian package) can create a local backport of zlib.
>>>
>>> I somewhat recently started to (entirely locally) build some "backports"
>>> via
>>> https://launchpad.net/~edd/+archive/ubuntu/misc solely so that Travis
>>> can use
>>> them as binary.  It's good option to have.
>>>
>>> Dirk
>>>
>>> | I guess R-core is aware of this. Just wanted to be sure.
>>> |
>>> | Best Regads,
>>> | Gabor
>>> |
>>> |       [[alternative HTML version deleted]]
>>> |
>>> | ______________________________________________
>>> | R-devel at r-project.org mailing list
>>> | https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>> --
>>> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From mick.jordan at oracle.com  Tue Mar 31 19:19:13 2015
From: mick.jordan at oracle.com (Mick Jordan)
Date: Tue, 31 Mar 2015 10:19:13 -0700
Subject: [Rd] VPATH build of R on MacOSX
Message-ID: <551AD711.7010608@oracle.com>

I am trying to do VPATH builds of R3.1.3, i.e. binaries built outside 
the source directory. It works just fine on Linux but on Mac OSX 
(Mavericks) I get the following trace from make, after a successful 
configure step. Any insights gratefully received. make is GNU make 3.81 
on both systems.

bash-3.2$ make
make
make[1]: Nothing to be done for `R'.
make[1]: Nothing to be done for `R'.
make[2]: Nothing to be done for `R'.
mkdir ../share/R
mkdir ../share/dictionaries
mkdir ../share/encodings
mkdir ../share/java
mkdir ../share/licenses
mkdir ../share/make
mkdir ../share/sh
mkdir ../share/texmf
mkdir ../share/texmf/bibtex
mkdir ../share/texmf/bibtex/bib
mkdir ../share/texmf/bibtex/bst
mkdir ../share/texmf/tex
mkdir ../share/texmf/tex/latex
creating src/scripts/R.fe
mkdir ../../bin
install: ../../include/Rconfig.h: No such file or directory
make[2]: *** [Rconfig.tsa] Error 71
make[1]: *** [R] Error 1
make: *** [R] Error 1


From mick.jordan at oracle.com  Tue Mar 31 19:35:52 2015
From: mick.jordan at oracle.com (Mick Jordan)
Date: Tue, 31 Mar 2015 10:35:52 -0700
Subject: [Rd] VPATH build of R on MacOSX
In-Reply-To: <551AD711.7010608@oracle.com>
References: <551AD711.7010608@oracle.com>
Message-ID: <551ADAF8.6060202@oracle.com>

On 3/31/15 10:19 AM, Mick Jordan wrote:
> I am trying to do VPATH builds of R3.1.3, i.e. binaries built outside 
> the source directory. It works just fine on Linux but on Mac OSX 
> (Mavericks) I get the following trace from make, after a successful 
> configure step. Any insights gratefully received. make is GNU make 
> 3.81 on both systems.
Answering my own question - it appears that if a build has already been 
done in the source directory, this problem occurs. With a pristine 
source directory a VPATH build works as expected.

Micki


From ripley at stats.ox.ac.uk  Tue Mar 31 20:40:28 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 31 Mar 2015 19:40:28 +0100
Subject: [Rd] VPATH build of R on MacOSX
In-Reply-To: <551ADAF8.6060202@oracle.com>
References: <551AD711.7010608@oracle.com> <551ADAF8.6060202@oracle.com>
Message-ID: <551AEA1C.604@stats.ox.ac.uk>

On 31/03/2015 18:35, Mick Jordan wrote:
> On 3/31/15 10:19 AM, Mick Jordan wrote:
>> I am trying to do VPATH builds of R3.1.3, i.e. binaries built outside
>> the source directory. It works just fine on Linux but on Mac OSX
>> (Mavericks) I get the following trace from make, after a successful
>> configure step. Any insights gratefully received. make is GNU make
>> 3.81 on both systems.
> Answering my own question - it appears that if a build has already been
> done in the source directory, this problem occurs. With a pristine
> source directory a VPATH build works as expected.

The problem is the incorrect expectations.  See
https://www.gnu.org/software/make/manual/html_node/General-Search.html .

And BTW, the OS is called 'OS X' and has been for a long time.
>
> Micki
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


