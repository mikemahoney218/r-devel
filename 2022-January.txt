From c@g|||e@p|e @end|ng |rom gm@||@com  Sat Jan  1 20:24:01 2022
From: c@g|||e@p|e @end|ng |rom gm@||@com (Colin Gillespie)
Date: Sat, 1 Jan 2022 19:24:01 +0000
Subject: [Rd] Documentation for floor, ceiling & trunc
Message-ID: <CADbDLZkcaK+2E_KA6+NwBhXDYhKjF-KbR9YXtzt6DjDDjH7Hyg@mail.gmail.com>

Hi,

The documentation for floor, ceiling and trunc is slightly ambiguous.

"floor takes ... and returns a numeric vector containing the largest
integers ..."

My initial thought was that floor() would return a vector of integers.
Instead, it returns a vector of doubles, i.e c(1L, 2L) vs c(1, 2)

 * Could the docs be changed
 * Would it be worth returning integers instead?

Thanks

Colin


From murdoch@dunc@n @end|ng |rom gm@||@com  Sat Jan  1 21:03:49 2022
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sat, 1 Jan 2022 15:03:49 -0500
Subject: [Rd] Documentation for floor, ceiling & trunc
In-Reply-To: <CADbDLZkcaK+2E_KA6+NwBhXDYhKjF-KbR9YXtzt6DjDDjH7Hyg@mail.gmail.com>
References: <CADbDLZkcaK+2E_KA6+NwBhXDYhKjF-KbR9YXtzt6DjDDjH7Hyg@mail.gmail.com>
Message-ID: <5d3c433a-9711-e1a2-64cc-dadc2a4cc347@gmail.com>

On 01/01/2022 2:24 p.m., Colin Gillespie wrote:
> Hi,
> 
> The documentation for floor, ceiling and trunc is slightly ambiguous.
> 
> "floor takes ... and returns a numeric vector containing the largest
> integers ..."
> 
> My initial thought was that floor() would return a vector of integers.

That would be described as "an integer vector".  I think the docs are 
pretty consistent about this:  if an output is described as "a numeric 
vector", that's the type you get.  ("numeric" and "double" refer to the 
same type in R.  This naming inconsistency is discussed in the ?double 
help page.)

> Instead, it returns a vector of doubles, i.e c(1L, 2L) vs c(1, 2)
> 
>   * Could the docs be changed
>   * Would it be worth returning integers instead?

The range of inputs is much larger than the range of 32 bit integers, so 
this would just make things more complicated, and would mean that code 
that cares about the difference between numeric and integer would need 
extra tests.

For example 3e9 + 0.1 is not an integer, and if you take the floor you 
get 3e9. That number can't be represented in the integer type, but can 
be exactly represented as a mathematical integer in the numeric/double type.

Duncan Murdoch


From @v|gro@@ @end|ng |rom ver|zon@net  Sat Jan  1 21:31:18 2022
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Sat, 1 Jan 2022 15:31:18 -0500
Subject: [Rd] Documentation for floor, ceiling & trunc
In-Reply-To: <5d3c433a-9711-e1a2-64cc-dadc2a4cc347@gmail.com>
References: <CADbDLZkcaK+2E_KA6+NwBhXDYhKjF-KbR9YXtzt6DjDDjH7Hyg@mail.gmail.com>
 <5d3c433a-9711-e1a2-64cc-dadc2a4cc347@gmail.com>
Message-ID: <015201d7ff4e$88696720$993c3560$@verizon.net>

Excellent reason, Duncan. R does not have an unlimited integer type as in
Python so truncating or rounding activities can well produce a result that
would be out of bounds.

If someone really wants an array of integers, other than efficiency reasons,
they could process the output from something like floor carefully to see if
all number returned were less than .Machine$integer.max (and similarly for
negatives in the other direction) and then have the option to make a vector
of as.integer(whatever) for later uses. If any numbers where out of the
range, they could presumably do other things like make then NA or Inf or
switch to some larger integer format they can find or create. Of course, any
such alterations may well not work well if fed to anything not expecting
them.

Now consider the purpose of the R functions round(), floor(), ceiling() and
trunc() and perhaps even signif() taken as a group. Clearly some of them can
be used only in a floating point context as rounding something to three
significant digits beyond the decimal point will not usually result in an
integer. Sure, some of them are normally used in real life to mean round it
to the nearest integer and in those cases it could be reasonable to have a
function with a restricted domain that maps into the restricted integer
range.  You can make your own such function easily enough.

-----Original Message-----
From: R-devel <r-devel-bounces at r-project.org> On Behalf Of Duncan Murdoch
Sent: Saturday, January 1, 2022 3:04 PM
To: Colin Gillespie <csgillespie at gmail.com>; r-devel at r-project.org
Subject: Re: [Rd] Documentation for floor, ceiling & trunc

On 01/01/2022 2:24 p.m., Colin Gillespie wrote:
> Hi,
> 
> The documentation for floor, ceiling and trunc is slightly ambiguous.
> 
> "floor takes ... and returns a numeric vector containing the largest 
> integers ..."
> 
> My initial thought was that floor() would return a vector of integers.

That would be described as "an integer vector".  I think the docs are pretty
consistent about this:  if an output is described as "a numeric vector",
that's the type you get.  ("numeric" and "double" refer to the same type in
R.  This naming inconsistency is discussed in the ?double help page.)

> Instead, it returns a vector of doubles, i.e c(1L, 2L) vs c(1, 2)
> 
>   * Could the docs be changed
>   * Would it be worth returning integers instead?

The range of inputs is much larger than the range of 32 bit integers, so
this would just make things more complicated, and would mean that code that
cares about the difference between numeric and integer would need extra
tests.

For example 3e9 + 0.1 is not an integer, and if you take the floor you get
3e9. That number can't be represented in the integer type, but can be
exactly represented as a mathematical integer in the numeric/double type.

Duncan Murdoch

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Mon Jan  3 16:54:26 2022
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Mon, 3 Jan 2022 16:54:26 +0100
Subject: [Rd] 
 Why does lm() with the subset argument give a different answer
 than subsetting in advance?
In-Reply-To: <82962536-60a4-8a71-eaa0-ce79f5025d2e@gmail.com>
References: <B29E2C41-2EB5-465D-8EA2-6E9E3B9906A3@miami.edu>
 <82962536-60a4-8a71-eaa0-ce79f5025d2e@gmail.com>
Message-ID: <25043.7218.319752.651473@stat.math.ethz.ch>

>>>>> Ben Bolker 
>>>>>     on Mon, 27 Dec 2021 09:43:42 -0500 writes:

    >    I agree that it seems non-intuitive (I can't think of a
    > design reason for it to look this way), but I'd like to
    > stress that it's *not* an information leak; the
    > predictions of the model are independent of the
    > parameterization, which is all this issue affects. In a
    > worst case there might be some unfortunate effects on
    > numerical stability if the data-dependent bases are
    > computed on a very different set of data than the model
    > fitting actually uses.

    >    I've attached a suggested documentation patch (I hope
    > it makes it through to the list, if not I can add it to
    > the body of a message.)

It did make it through;  thank you, Ben!
( After adding two forgotten '}' ) I've committed the help file
additions to the R sources (R-devel) in svn r81434 .

Thanks again and

       "Happy New Year"

to all readers,

Martin




    > On 12/26/21 8:35 PM, Balise, Raymond R wrote:
    >> Hello R folks, Today I noticed that using the subset
    >> argument in lm() with a polynomial gives a different
    >> result than using the polynomial when the data has
    >> already been subsetted. This was not at all intuitive for
    >> me.  You can see an example here:
    >> https://stackoverflow.com/questions/70490599/why-does-lm-with-the-subset-argument-give-a-different-answer-than-subsetting-i
    >> 
    >> If this is a design feature that you don?t think should
    >> be fixed, can you please include it in the documentation
    >> and explain why it makes sense to figure out the
    >> orthogonal polynomials on the entire dataset?  This feels
    >> like a serous leak of information when evaluating train
    >> and test datasets in a statistical learning framework.
    >> 
    >> Ray
    >> 
    >> Raymond R. Balise, PhD Assistant Professor Department of
    >> Public Health Sciences, Biostatistics
    >> 
    >> University of Miami, Miller School of Medicine 1120
    >> N.W. 14th Street Don Soffer Clinical Research Center -
    >> Room 1061 Miami, Florida 33136
    >> 
    >> 
    >> 
    >> [[alternative HTML version deleted]]
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> 

    > -- 
    > Dr. Benjamin Bolker Professor, Mathematics & Statistics
    > and Biology, McMaster University Director, School of
    > Computational Science and Engineering Graduate chair,
    > Mathematics & Statistics x[DELETED ATTACHMENT external:
    > BenB_lm-subset.patch, plain text]
    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From bbo|ker @end|ng |rom gm@||@com  Mon Jan  3 17:04:48 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 3 Jan 2022 11:04:48 -0500
Subject: [Rd] trivial typo in NEWS file
Message-ID: <77a401c8-722b-95d7-7d54-c442c478f5ef@gmail.com>


   Index: doc/NEWS.Rd
===================================================================
--- doc/NEWS.Rd	(revision 81435)
+++ doc/NEWS.Rd	(working copy)
@@ -425,7 +425,7 @@
        data frames with default row names (Thanks to Charlie Gao's
        \PR{18179}).

-      \item \code{txtProgresBar()} now enforces a non-zero width for
+      \item \code{txtProgressBar()} now enforces a non-zero width for
        \code{char}, without which no progress can be visible.

        \item \code{dimnames(table(d))} is more consistent in the case where


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Mon Jan  3 17:23:45 2022
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Mon, 3 Jan 2022 17:23:45 +0100
Subject: [Rd] trivial typo in NEWS file
In-Reply-To: <77a401c8-722b-95d7-7d54-c442c478f5ef@gmail.com>
References: <77a401c8-722b-95d7-7d54-c442c478f5ef@gmail.com>
Message-ID: <25043.8977.289648.963947@stat.math.ethz.ch>

>>>>> Ben Bolker 
>>>>>     on Mon, 3 Jan 2022 11:04:48 -0500 writes:

    > Index: doc/NEWS.Rd
    > ===================================================================
    > --- doc/NEWS.Rd	(revision 81435)
    > +++ doc/NEWS.Rd	(working copy)
    > @@ -425,7 +425,7 @@
    > data frames with default row names (Thanks to Charlie Gao's
    > \PR{18179}).

    > -      \item \code{txtProgresBar()} now enforces a non-zero width for
    > +      \item \code{txtProgressBar()} now enforces a non-zero width for
    > \code{char}, without which no progress can be visible.

    > \item \code{dimnames(table(d))} is more consistent in the case where


Thank you, Ben!

I will take care of this with my next commit (dealing with R's
bugzilla PR#18272).

Martin


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Mon Jan  3 18:15:20 2022
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Mon, 3 Jan 2022 18:15:20 +0100
Subject: [Rd] "getOption(max.print) omitted %d entries" may be negative
In-Reply-To: <CAJmOi+MFUrn+hx9PVj1ALWwMFPq518dTYGPDToqF92TB4w9xgw@mail.gmail.com>
References: <CAJmOi+MFUrn+hx9PVj1ALWwMFPq518dTYGPDToqF92TB4w9xgw@mail.gmail.com>
Message-ID: <25043.12072.659723.752755@stat.math.ethz.ch>

>>>>> Hugh Parsonage 
>>>>>     on Wed, 29 Dec 2021 00:36:51 +1100 writes:

    > In src/main/printvector.c in the definition of printVector and
    > printNamedVector  (and elsewhere):

    > Rprintf(" [ reached getOption(\"max.print\") -- omitted %d entries ]\n",
    >         n - n_pr);

    > Though n - n_pr is of type R_xlen_t so may not be representable as
    > int. In practice negative values may be observed for long vectors.

    > Rprintf(" [ reached getOption(\"max.print\") -- omitted %lld entries ]\n",
    >         n - n_pr);


Thank you Hugh, for finding and reporting this,
including a proposed remedy. 

At some point in time, I think the   %lld   format specifier was
not portable enough to all versions of C compiler / libraries
that were considered valid for compiling R.

See e.g.,

   https://stackoverflow.com/questions/462345/format-specifier-for-long-long

which says that "it" does not work on Windows.

Maybe this has changed now that we require C99 and also that
since R version 4.0.0 (or 4.0.1) we also use a somewhat more
recent version of gcc also on Windows?

... ah, searching the R sources reveals uses of %lld
*plus*

#ifdef Win32
#include <trioremap.h> /* for %lld */
#endif

so it seems we can and should probably change this ...

[Please, C  compiler / library standard experts, chime in !]

Martin Maechler
ETH Zurich  and  R core team


From tom@@@k@||ber@ @end|ng |rom gm@||@com  Mon Jan  3 20:59:30 2022
From: tom@@@k@||ber@ @end|ng |rom gm@||@com (Tomas Kalibera)
Date: Mon, 3 Jan 2022 20:59:30 +0100
Subject: [Rd] "getOption(max.print) omitted %d entries" may be negative
In-Reply-To: <25043.12072.659723.752755@stat.math.ethz.ch>
References: <CAJmOi+MFUrn+hx9PVj1ALWwMFPq518dTYGPDToqF92TB4w9xgw@mail.gmail.com>
 <25043.12072.659723.752755@stat.math.ethz.ch>
Message-ID: <fe5e0663-1827-8045-7aee-6b87e9c140ac@gmail.com>


On 1/3/22 6:15 PM, Martin Maechler wrote:
>>>>>> Hugh Parsonage
>>>>>>      on Wed, 29 Dec 2021 00:36:51 +1100 writes:
>      > In src/main/printvector.c in the definition of printVector and
>      > printNamedVector  (and elsewhere):
>
>      > Rprintf(" [ reached getOption(\"max.print\") -- omitted %d entries ]\n",
>      >         n - n_pr);
>
>      > Though n - n_pr is of type R_xlen_t so may not be representable as
>      > int. In practice negative values may be observed for long vectors.
>
>      > Rprintf(" [ reached getOption(\"max.print\") -- omitted %lld entries ]\n",
>      >         n - n_pr);
>
>
> Thank you Hugh, for finding and reporting this,
> including a proposed remedy.
>
> At some point in time, I think the   %lld   format specifier was
> not portable enough to all versions of C compiler / libraries
> that were considered valid for compiling R.
>
> See e.g.,
>
>     https://stackoverflow.com/questions/462345/format-specifier-for-long-long
>
> which says that "it" does not work on Windows.
>
> Maybe this has changed now that we require C99 and also that
> since R version 4.0.0 (or 4.0.1) we also use a somewhat more
> recent version of gcc also on Windows?
>
> ... ah, searching the R sources reveals uses of %lld
> *plus*
>
> #ifdef Win32
> #include <trioremap.h> /* for %lld */
> #endif
>
> so it seems we can and should probably change this ...

UCRT on Windows supports the C99 format, so %lld works, but there is a 
bug in GCC which causes a compilation warning to appear for %lld.

There is an open GCC bug report with a patch. It has not been adopted, 
yet, but I got reviews from two people and patched the build of GCC in 
Rtools42. So, %lld etc now works without a warning for us on Windows and 
certainly can be used in package code.
https://gcc.gnu.org/bugzilla/show_bug.cgi?id=95130

For base R, as we have been using the trio remap to get rid of the 
warning with %lld, it would make sense to keep doing this for 
consistency. Eventually we might be able to remove the dependency on 
trio, after checking that the other problems due to which we use it have 
been resolved in UCRT.

Tomas

>
> [Please, C  compiler / library standard experts, chime in !]
>
> Martin Maechler
> ETH Zurich  and  R core team
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From @v|gro@@ @end|ng |rom ver|zon@net  Mon Jan  3 21:42:16 2022
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Mon, 3 Jan 2022 15:42:16 -0500
Subject: [Rd] A patchwork indeed
References: <018301d800e2$65064bf0$2f12e3d0$.ref@verizon.net>
Message-ID: <018301d800e2$65064bf0$2f12e3d0$@verizon.net>

Let me be clear up front that I do not want to start any major discussions,
merely to share some observations.

 

We discussed at length what it would mean if R was extended to allow a plus
sign to concatenate text when the operands were both of the right types that
made sense for the purpose so that, as in a language like Python:

 

                "Hello " + "World!"

 

would result in the obvious concatenation and not as an error. It might be a
way to call perhaps a limited functionality of paste0() as an example. 

 

So, I was studying an R package called patchwork and looking at it from a
perspective in that it slightly extends the way ggplot uses the plus sign
when applied to objects of certain classes. Patchwork does allow something
like some form of (many types) of graphic objects to be displayed left to
right (or in a grid) by just typing 

p1 + p2 + p3

 

BUT it goes a bit nuts and overlays lots of operators so that:

 

                (p1 | p2) / p3

 

results in the first two taking up half each of a top row and the third in
the next row and wide. You can of course make all kinds of adjustments but
the point is that those symbols are in a sense overlaid from their default
meanings. there is also a meaning (a tad obscure) for a unary negative sign
as in

- p1 

 

And, without explanation here, the symbols * and & also are used in new
ways. 

 

I note the obvious that the normal precedence rules in R for these
symbols/operators are NOT changed so you often need to use extra levels of
parentheses to guarantee the order of evaluation.

 

Clearly anyone reading your code that has not thoroughly read the manual for
the package will be even more mystified than people are about ggplot and the
plus sign, or the pipe symbols used in the tidyverse and even the new one
now in base R. 

 

But my point is that it looks like doing it is quite possible and small
isolated worlds can benefit from the notational simplicity. Having said
that, this package also allows you to bypass all of this and use more
standard functions that generally get you the same results. Since
manipulating graphs and subgraphs generally does not require combining the
above symbols alongside their other normal usage, this may look harmless and
if you come from languages that routinely allow operators to be overloaded
or polymorphic, looks fine.

 

I am providing this info, not to make a case for doing anything but to ask
if it makes sense to document acceptable methods for others, perhaps using
their own created objects, to do such effects.

 

In case anyone is curious, start here for a sort of tutorial:

 

https://patchwork.data-imaginist.com/

 

Again, not advocating, just providing an example, no doubt among many
others, where R is used in an extended way that can be useful. But of course
moving R to be fully object-oriented in the same way as some other specific
language is not a valid goal.

 


	[[alternative HTML version deleted]]


From mtmorg@n@b|oc @end|ng |rom gm@||@com  Tue Jan  4 20:35:30 2022
From: mtmorg@n@b|oc @end|ng |rom gm@||@com (Martin Morgan)
Date: Tue, 4 Jan 2022 19:35:30 +0000
Subject: [Rd] gsub() hex character range problems in R-devel?
Message-ID: <BN8PR04MB6241FCAA6D228F3CB00991B5F94A9@BN8PR04MB6241.namprd04.prod.outlook.com>

I'm not very good at character encoding / etc so this might be user error. The following code is meant to replace extended ASCII characters, in particular a non-breaking space, with "", and it works in R-4-1-branch

> R.version.string
[1] "R version 4.1.2 Patched (2022-01-04 r81445)"
> gsub("[\x7f-\xff]", "", "fo\xa0o")
[1] "foo"

but fails in R-devel

> R.version.string
[1] "R Under development (unstable) (2022-01-04 r81445)"
> gsub("[\x7f-\xff]", "", "fo\xa0o")
Error in gsub("[\177-\xff]", "", "fo\xa0o") : invalid regular expression '[-?]', reason 'Invalid character range'
In addition: Warning message:
In gsub("[\177-\xff]", "", "fo\xa0o") :
  TRE pattern compilation error 'Invalid character range'

There are other oddities, too, like

> gsub("[[:alnum:]]", "", "fo\xa0o")  # R-4-1-branch
[1] "\xfc\xbe\x8c\x86\x84\xbc"

> gsub("[[:alnum:]]", "", "fo\xa0o")  # R-devel
[1] "<>"

The R-devel sessionInfo is

> sessionInfo()
R Under development (unstable) (2022-01-04 r81445)
Platform: x86_64-apple-darwin19.6.0 (64-bit)
Running under: macOS Catalina 10.15.7

Matrix products: default
BLAS:   /Users/ma38727/bin/R-devel/lib/libRblas.dylib
LAPACK: /Users/ma38727/bin/R-devel/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_4.2.0

(I have built my own R on macOS; similar behavior is observed on a Linux machine)

Any hints welcome,

Martin Morgan

From brod|e@g@@|@m @end|ng |rom y@hoo@com  Wed Jan  5 02:54:21 2022
From: brod|e@g@@|@m @end|ng |rom y@hoo@com (Brodie Gaslam)
Date: Wed, 5 Jan 2022 01:54:21 +0000 (UTC)
Subject: [Rd] gsub() hex character range problems in R-devel?
In-Reply-To: <BN8PR04MB6241FCAA6D228F3CB00991B5F94A9@BN8PR04MB6241.namprd04.prod.outlook.com>
References: <BN8PR04MB6241FCAA6D228F3CB00991B5F94A9@BN8PR04MB6241.namprd04.prod.outlook.com>
Message-ID: <1523321191.1706512.1641347661397@mail.yahoo.com>

> On Tuesday, January 4, 2022, 02:35:50 PM EST, Martin Morgan <mtmorgan.bioc at gmail.com> wrote:
>
> I'm not very good at character encoding / etc so this might be user
> error. The following code is meant to replace extended ASCII characters,
> in particular a non-breaking space, with "", and it works in
> R-4-1-branch

Martin,

I'm (obviously) not R-Core, so you should take whatever I say with a grain
of salt.? Nonetheless I have run into a similar issue as you, and my
assessment is that the behavior in R-4-1-2 is due to a bug that was fixed
with -r81103 for R-devel only.? It only appears more correct due to
happenstance and "surprising" (at least to me) behavior from the
"corrected" code.

But before I get into the details, I'd be remiss not to add some warnings
about using arbitrary bytes in strings as you do here.? The strings in
your examples are not marked:

??? Encoding("fo\xa0o")
??? [1] "unknown"

This means internals may interpret them as being in native encoding (UTF-8
in your case, in which your string is invalid).? If you want to use byte
operations you should mark your strings as "bytes" / use the "useBytes"
parameter to the functions in question (and assume all the consequences of
generating invalid encodings), or even better translate the string from its
actual encoding to your encoding.? For your case assuming you have
ISO-8859-1 encoding (I'm just guessing) I would do:

??? x <- "fo\xa0o"
??? y <- iconv(x, "ISO-8859-1", "UTF-8")
??? gsub("\ua0", "", y)
??? [1] "foo"

You could also just have marked your string as "latin1" as for 0xA0 it is
the same as ISO-8859-1 and gotten the same result without `iconv`, but the
`iconv` solution is more general.

I'll address the two examples in reverse order as the first one
is more obvious.

> > gsub("[[:alnum:]]", "", "fo\xa0o")? # R-4-1-branch
> [1] "\xfc\xbe\x8c\x86\x84\xbc"
>
> > gsub("[[:alnum:]]", "", "fo\xa0o")? # R-devel
> [1] "<>"

The result in the 4-1 contains bytes not present in the input.? Clearly
this cannot be correct.? R-devel is "correct" if you account for the
surprising (to me) behavior that invalid bytes in UTF-8 interpreted
strings may be escaped in pre-processing.? This is roughly what's
happening:

??? "fo\xa0o" -> "fo<a0>o" -> gsub("[[:alnum:]]", "", "fo<a0>o") -> "<>"

Where "<a0>" is the escaped version of the "\xa0".? It's clearer if you do
(R-devel):

??? gsub("f", "", "fo\xa0o")
??? [1] "o<a0>o"

I do think this "correct" behavior would be better as an error or at a
minimum a warning, and hopefully this is something that will change in the
future.

> > R.version.string
> [1] "R version 4.1.2 Patched (2022-01-04 r81445)"
> > gsub("[\x7f-\xff]", "", "fo\xa0o")
> [1] "foo"
>
> but fails in R-devel
> > R.version.string
> [1] "R Under development (unstable) (2022-01-04 r81445)"
> > gsub("[\x7f-\xff]", "", "fo\xa0o")
> Error in gsub("[\177-\xff]", "", "fo\xa0o") : invalid regular expression '[-?]', reason 'Invalid character range'
> In addition: Warning message:
> In gsub("[\177-\xff]", "", "fo\xa0o") :
>?? TRE pattern compilation error 'Invalid character range'

This one is pretty interesting.? The same bug persists, but because it
affects both the pattern and the string to manipulate the bugs cancel out.
If you look at what's happening internally in R-4-1, the range "\x7f-\xff"
is translated to "\u7f-\U{3e66663c}", but "fo\xa0o" is also translated to
"fo\U{3e30613c}o", so it happens to work.

Why "\U{3e66663c}"?? Well, it's really 3e 66 66 3c, which the code
intended to have interpreted as < f f >.? In ASCII encoding, we have 3e =
<, 66 = f, 3c = >.? So the intent was to write out "<ff>", the 4 character
escape for the single byte "\xff".? Instead, the 4 bytes are written into
a single wchar_t (on systems with 32bit wchar_t) and interpreted as that
code point.

In little-endian machines like ours, the double cancellation does not
always work as seen in R-4-1-2:

??? gsub("[\x7f-\xab]", "",? "\xab")
??? ## [1] ""
??? gsub("[\x7f-\xba]", "",? "\xab")? # changed end to be \xba
??? ## [1] "\xab"

One would expect the second range to still capture the character, but
because wchar_t is interpreted little endian the order of the "a" and "b"
written into the wchar_t is opposite of what is desired.? So it would not
be possible to leave the bug in (even if it didn't cause other issues) on
the grounds it cancels itself out.

With the patch applied in R-devel, the range "[\x7f-\xff]" becomes
"[\x7f-<ff>]", which is invalid because "<" has a lower code point that
"\x7f".? Here the fix exposes the "surprisingness" of the current
behavior.

Although again, you can currently side-step all this simply by
converting everything into valid encodings and avoiding bytes
manipulation, or doing everything very carefully explicitly with "bytes"
marked strings and "useBytes=TRUE".

Best,

B.

> The R-devel sessionInfo is
>
> > sessionInfo()
> R Under development (unstable) (2022-01-04 r81445)
> Platform: x86_64-apple-darwin19.6.0 (64-bit)
> Running under: macOS Catalina 10.15.7
>
> Matrix products: default
> BLAS:? /Users/ma38727/bin/R-devel/lib/libRblas.dylib
> LAPACK: /Users/ma38727/bin/R-devel/lib/libRlapack.dylib
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats??? graphics? grDevices utils??? datasets? methods? base
>
> loaded via a namespace (and not attached):
> [1] compiler_4.2.0
>
> (I have built my own R on macOS; similar behavior is observed on a Linux machine)
>
> Any hints welcome,
>
> Martin Morgan
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From tom@@@k@||ber@ @end|ng |rom gm@||@com  Wed Jan  5 10:17:01 2022
From: tom@@@k@||ber@ @end|ng |rom gm@||@com (Tomas Kalibera)
Date: Wed, 5 Jan 2022 10:17:01 +0100
Subject: [Rd] gsub() hex character range problems in R-devel?
In-Reply-To: <BN8PR04MB6241FCAA6D228F3CB00991B5F94A9@BN8PR04MB6241.namprd04.prod.outlook.com>
References: <BN8PR04MB6241FCAA6D228F3CB00991B5F94A9@BN8PR04MB6241.namprd04.prod.outlook.com>
Message-ID: <04c065e3-8f53-0233-55c5-a8ce510bd47f@gmail.com>

Hi Martin,

I'd add few comments to the excellent analysis of Brodie.

- \xhh is allowed and defined in Perl regular expressions, see ?regex 
(would need perl=TRUE), but to enter that in an R string, you need to 
escape the backslash.

- \xhh is not defined by POSIX for extended regular expressions, neither 
it is documented in ?regex for those; TRE supports it, but still 
portable programs should not rely on that

- literal \xhh in an R string is turned to the byte by R, but I would 
say this should not be used at all by users, because the result is 
encoding specific

- use of \u and \U in an R string is fine, it has well defined semantics 
and the corresponding string will then be flagged UTF-8 in R (so e.g. 
\ua0 is fine to represent the Unicode no-break space)

- see caveats of using character ranges with POSIX extended regular 
expressions in ?regex re encodings, using Perl regular expressions in 
UTF-8 mode is more reliable for those

So, a variant of your example might be:

 > gsub("[\\x7f-\\xff]", "", "fo\ua0o", perl=TRUE)
[1] "foo"

(note that the \ua0 ensures that the text is UTF-8, and hence the UTF-8 
mode for regular expressions is used, ?regex has more)

However, I think it is better to formulate regular expressions to cover 
all of Unicode, so do something like e.g. "only keep ASCII digits, ASCII 
space, ASCII underscore, but remove all other characters".

Best
Tomas

On 1/4/22 8:35 PM, Martin Morgan wrote:

> I'm not very good at character encoding / etc so this might be user error. The following code is meant to replace extended ASCII characters, in particular a non-breaking space, with "", and it works in R-4-1-branch
>
>> R.version.string
> [1] "R version 4.1.2 Patched (2022-01-04 r81445)"
>> gsub("[\x7f-\xff]", "", "fo\xa0o")
> [1] "foo"
>
> but fails in R-devel
>
>> R.version.string
> [1] "R Under development (unstable) (2022-01-04 r81445)"
>> gsub("[\x7f-\xff]", "", "fo\xa0o")
> Error in gsub("[\177-\xff]", "", "fo\xa0o") : invalid regular expression '[-?]', reason 'Invalid character range'
> In addition: Warning message:
> In gsub("[\177-\xff]", "", "fo\xa0o") :
>    TRE pattern compilation error 'Invalid character range'
>
> There are other oddities, too, like
>
>> gsub("[[:alnum:]]", "", "fo\xa0o")  # R-4-1-branch
> [1] "\xfc\xbe\x8c\x86\x84\xbc"
>
>> gsub("[[:alnum:]]", "", "fo\xa0o")  # R-devel
> [1] "<>"
>
> The R-devel sessionInfo is
>
>> sessionInfo()
> R Under development (unstable) (2022-01-04 r81445)
> Platform: x86_64-apple-darwin19.6.0 (64-bit)
> Running under: macOS Catalina 10.15.7
>
> Matrix products: default
> BLAS:   /Users/ma38727/bin/R-devel/lib/libRblas.dylib
> LAPACK: /Users/ma38727/bin/R-devel/lib/libRlapack.dylib
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_4.2.0
>
> (I have built my own R on macOS; similar behavior is observed on a Linux machine)
>
> Any hints welcome,
>
> Martin Morgan
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From mtmorg@n@b|oc @end|ng |rom gm@||@com  Thu Jan  6 17:47:31 2022
From: mtmorg@n@b|oc @end|ng |rom gm@||@com (Martin Morgan)
Date: Thu, 6 Jan 2022 16:47:31 +0000
Subject: [Rd] gsub() hex character range problems in R-devel?
In-Reply-To: <04c065e3-8f53-0233-55c5-a8ce510bd47f@gmail.com>
References: <BN8PR04MB6241FCAA6D228F3CB00991B5F94A9@BN8PR04MB6241.namprd04.prod.outlook.com>
 <04c065e3-8f53-0233-55c5-a8ce510bd47f@gmail.com>
Message-ID: <BN8PR04MB6241C3B0400F5E25DA88C629F94C9@BN8PR04MB6241.namprd04.prod.outlook.com>

Thanks Tomas and 'Brodie' for your expert explanation; it provides great help in understanding and solving my immediate problem.

Thomas' observation to 'do something like e.g. "only keep ASCII digits, ASCII space, ASCII underscore, but remove all other characters"' points to a basic weakness in the code I'm looking at. E.g., removing non-breaking space is probably not appropriate ('foo\ua0bar' is probably cleaned to 'foo bar' and not 'foobar'). And more generally other non-ASCII characters ('fancy' quotes, em-dashes, ...) would require special treatment. It seems like the right thing to do is to handle the raw data in its original encoding, rather than to try to clean it to ASCII.

Martin

?On 1/5/22, 4:17 AM, "Tomas Kalibera" <tomas.kalibera at gmail.com> wrote:

    Hi Martin,

    I'd add few comments to the excellent analysis of Brodie.

    - \xhh is allowed and defined in Perl regular expressions, see ?regex 
    (would need perl=TRUE), but to enter that in an R string, you need to 
    escape the backslash.

    - \xhh is not defined by POSIX for extended regular expressions, neither 
    it is documented in ?regex for those; TRE supports it, but still 
    portable programs should not rely on that

    - literal \xhh in an R string is turned to the byte by R, but I would 
    say this should not be used at all by users, because the result is 
    encoding specific

    - use of \u and \U in an R string is fine, it has well defined semantics 
    and the corresponding string will then be flagged UTF-8 in R (so e.g. 
    \ua0 is fine to represent the Unicode no-break space)

    - see caveats of using character ranges with POSIX extended regular 
    expressions in ?regex re encodings, using Perl regular expressions in 
    UTF-8 mode is more reliable for those

    So, a variant of your example might be:

     > gsub("[\\x7f-\\xff]", "", "fo\ua0o", perl=TRUE)
    [1] "foo"

    (note that the \ua0 ensures that the text is UTF-8, and hence the UTF-8 
    mode for regular expressions is used, ?regex has more)

    However, I think it is better to formulate regular expressions to cover 
    all of Unicode, so do something like e.g. "only keep ASCII digits, ASCII 
    space, ASCII underscore, but remove all other characters".

    Best
    Tomas

    On 1/4/22 8:35 PM, Martin Morgan wrote:

    > I'm not very good at character encoding / etc so this might be user error. The following code is meant to replace extended ASCII characters, in particular a non-breaking space, with "", and it works in R-4-1-branch
    >
    >> R.version.string
    > [1] "R version 4.1.2 Patched (2022-01-04 r81445)"
    >> gsub("[\x7f-\xff]", "", "fo\xa0o")
    > [1] "foo"
    >
    > but fails in R-devel
    >
    >> R.version.string
    > [1] "R Under development (unstable) (2022-01-04 r81445)"
    >> gsub("[\x7f-\xff]", "", "fo\xa0o")
    > Error in gsub("[\177-\xff]", "", "fo\xa0o") : invalid regular expression '[-?]', reason 'Invalid character range'
    > In addition: Warning message:
    > In gsub("[\177-\xff]", "", "fo\xa0o") :
    >    TRE pattern compilation error 'Invalid character range'
    >
    > There are other oddities, too, like
    >
    >> gsub("[[:alnum:]]", "", "fo\xa0o")  # R-4-1-branch
    > [1] "\xfc\xbe\x8c\x86\x84\xbc"
    >
    >> gsub("[[:alnum:]]", "", "fo\xa0o")  # R-devel
    > [1] "<>"
    >
    > The R-devel sessionInfo is
    >
    >> sessionInfo()
    > R Under development (unstable) (2022-01-04 r81445)
    > Platform: x86_64-apple-darwin19.6.0 (64-bit)
    > Running under: macOS Catalina 10.15.7
    >
    > Matrix products: default
    > BLAS:   /Users/ma38727/bin/R-devel/lib/libRblas.dylib
    > LAPACK: /Users/ma38727/bin/R-devel/lib/libRlapack.dylib
    >
    > locale:
    > [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
    >
    > attached base packages:
    > [1] stats     graphics  grDevices utils     datasets  methods   base
    >
    > loaded via a namespace (and not attached):
    > [1] compiler_4.2.0
    >
    > (I have built my own R on macOS; similar behavior is observed on a Linux machine)
    >
    > Any hints welcome,
    >
    > Martin Morgan
    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel

From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Sat Jan  8 16:36:26 2022
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Sat, 8 Jan 2022 16:36:26 +0100
Subject: [Rd] "getOption(max.print) omitted %d entries" may be negative
In-Reply-To: <fe5e0663-1827-8045-7aee-6b87e9c140ac@gmail.com>
References: <CAJmOi+MFUrn+hx9PVj1ALWwMFPq518dTYGPDToqF92TB4w9xgw@mail.gmail.com>
 <25043.12072.659723.752755@stat.math.ethz.ch>
 <fe5e0663-1827-8045-7aee-6b87e9c140ac@gmail.com>
Message-ID: <25049.44922.461214.439279@stat.math.ethz.ch>

>>>>> Tomas Kalibera 
>>>>>     on Mon, 3 Jan 2022 20:59:30 +0100 writes:

    > On 1/3/22 6:15 PM, Martin Maechler wrote:
    >>>>>>> Hugh Parsonage on Wed, 29 Dec 2021 00:36:51 +1100
    >>>>>>> writes:
    >> > In src/main/printvector.c in the definition of
    >> printVector and > printNamedVector (and elsewhere):
    >> 
    >> > Rprintf(" [ reached getOption(\"max.print\") -- omitted
    >> %d entries ]\n", > n - n_pr);
    >> 
    >> > Though n - n_pr is of type R_xlen_t so may not be
    >> representable as > int. In practice negative values may
    >> be observed for long vectors.
    >> 
    >> > Rprintf(" [ reached getOption(\"max.print\") -- omitted
    >> %lld entries ]\n", > n - n_pr);
    >> 
    >> 
    >> Thank you Hugh, for finding and reporting this, including
    >> a proposed remedy.
    >> 
    >> At some point in time, I think the %lld format specifier
    >> was not portable enough to all versions of C compiler /
    >> libraries that were considered valid for compiling R.
    >> 
    >> See e.g.,
    >> 
    >> https://stackoverflow.com/questions/462345/format-specifier-for-long-long
    >> 
    >> which says that "it" does not work on Windows.
    >> 
    >> Maybe this has changed now that we require C99 and also
    >> that since R version 4.0.0 (or 4.0.1) we also use a
    >> somewhat more recent version of gcc also on Windows?
    >> 
    >> ... ah, searching the R sources reveals uses of %lld
    >> *plus*
    >> 
    >> #ifdef Win32 #include <trioremap.h> /* for %lld */ #endif
    >> 
    >> so it seems we can and should probably change this ...

    > UCRT on Windows supports the C99 format, so %lld works,
    > but there is a bug in GCC which causes a compilation
    > warning to appear for %lld.

    > There is an open GCC bug report with a patch. It has not
    > been adopted, yet, but I got reviews from two people and
    > patched the build of GCC in Rtools42. So, %lld etc now
    > works without a warning for us on Windows and certainly
    > can be used in package code.
    > https://gcc.gnu.org/bugzilla/show_bug.cgi?id=95130

    > For base R, as we have been using the trio remap to get
    > rid of the warning with %lld, it would make sense to keep
    > doing this for consistency. Eventually we might be able to
    > remove the dependency on trio, after checking that the
    > other problems due to which we use it have been resolved
    > in UCRT.

    > Tomas

I have committed changes now (svn r81459), using %lld as mentioned above,
also including  trioremap.h  for Windows,
not just for printing long unnamed atomic vectors, but also in
the code for printing named vectors and "generic vectors" aka
lists.... which previously did not allow long vectors at all,
using `length() and `int` before.

I've set it as to be ported to  "R 4.1.2 patched" eventually.
Martin




    >> 
    >> [Please, C compiler / library standard experts, chime in
    >> !]
    >> 
    >> Martin Maechler ETH Zurich and R core team


From bbo|ker @end|ng |rom gm@||@com  Sun Jan  9 22:39:43 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sun, 9 Jan 2022 16:39:43 -0500
Subject: [Rd] =?utf-8?q?documentation_patch_for_as=2Eformula_=E2=86=92_re?=
 =?utf-8?q?formulate?=
Message-ID: <7150b64c-c139-1421-9ba2-1a297dc32ac9@gmail.com>

   There was some discussion on twitter about the fact that the manual 
page for as.formula() doesn't mention reformulate(), and indeed the last 
example is

## Create a formula for a model with a large number of variables:
      xnam <- paste0("x", 1:25)
      (fmla <- as.formula(paste("y ~ ", paste(xnam, collapse= "+"))))


which could arguably be better done as

   reformulate(xname, response = "y")

   I've attached a documentation patch that adds the alternative version 
and a \seealso{} link.

   Happy to submit to r-bugzilla if requested.

   cheers
    Ben Bolker

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: reformulate_patch.txt
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20220109/f3266495/attachment.txt>

From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Mon Jan 10 10:04:11 2022
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Mon, 10 Jan 2022 10:04:11 +0100
Subject: [Rd] 
 =?utf-8?q?documentation_patch_for_as=2Eformula_=E2=86=92_re?=
 =?utf-8?q?formulate?=
In-Reply-To: <7150b64c-c139-1421-9ba2-1a297dc32ac9@gmail.com>
References: <7150b64c-c139-1421-9ba2-1a297dc32ac9@gmail.com>
Message-ID: <25051.63115.679473.229695@stat.math.ethz.ch>

>>>>> Ben Bolker   on Sun, 9 Jan 2022 16:39:43 -0500 writes:

>    There was some discussion on twitter about the fact
> that the manual page for as.formula() doesn't mention
> reformulate(), and indeed the last example is

> ## Create a formula for a model with a large number of
> variables: xnam <- paste0("x", 1:25) (fmla <-
> as.formula(paste("y ~ ", paste(xnam, collapse= "+"))))


> which could arguably be better done as

>    reformulate(xname, response = "y")

>    I've attached a documentation patch that adds the
> alternative version and a \seealso{} link.

>    Happy to submit to r-bugzilla if requested.

>    cheers Ben Bolker

x[DELETED ATTACHMENT external:  reformulate_patch.txt, plain text]

Thanks a lot, Ben!

I've committed (+-) it to R-devel as svn rev 81464
Martin


From bbo|ker @end|ng |rom gm@||@com  Sat Jan 15 02:39:59 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 14 Jan 2022 20:39:59 -0500
Subject: [Rd] partial matching of row names in [-indexing
Message-ID: <66cd913b-233a-c9ea-1d48-e9192e408c1d@gmail.com>


   People are often surprised that row-indexing a data frame by [ + 
character does partial matching (and annoyed that there is no way to 
turn it off:

https://stackoverflow.com/questions/18033501/warning-when-partial-matching-rownames

https://stackoverflow.com/questions/34233235/r-returning-partial-matching-of-row-names

https://stackoverflow.com/questions/70716905/why-does-r-have-inconsistent-behaviors-when-a-non-existent-rowname-is-retrieved


?"[" says:

Character indices can in some circumstances be partially matched
      (see ?pmatch?) to the names or dimnames of the object being
      subsetted (but never for subassignment).  UNLIKE S (Becker et al_
      p. 358), R NEVER USES PARTIAL MATCHING WHEN EXTRACTING BY ?[?, and
      partial matching is not by default used by ?[[? (see argument
      ?exact?).

(EMPHASIS ADDED).

Looking through the rest of that page, I don't see any other text that 
modifies or supersedes that statement.

   Is this a documentation bug?

The example given in one of the links above:

b <- as.data.frame(matrix(4:5, ncol = 1, nrow = 2, dimnames = 
list(c("A10", "B"), "V1")))

b["A1",]  ## 4 (partial matching)
b[rownames(b) == "A1",]  ## logical(0)
b["A1", , exact=TRUE]    ## unused argument error
b$V1[["A1"]] ## subscript out of bounds error
b$V1["A1"]   ## NA


From @tevem@rt|n041 @end|ng |rom gm@||@com  Sat Jan 15 03:19:16 2022
From: @tevem@rt|n041 @end|ng |rom gm@||@com (Steve Martin)
Date: Fri, 14 Jan 2022 21:19:16 -0500
Subject: [Rd] partial matching of row names in [-indexing
In-Reply-To: <66cd913b-233a-c9ea-1d48-e9192e408c1d@gmail.com>
References: <66cd913b-233a-c9ea-1d48-e9192e408c1d@gmail.com>
Message-ID: <CAP=dwz-tFm6eK1gd2xhU6ayjTK6jD0HNwG_52PrUwc2BjfvzAQ@mail.gmail.com>

I don't think this is a bug in the documentation. The help page for
`?[.data.frame` has the following in the last paragraph of the
details:

Both [ and [[ extraction methods partially match row names. By default
neither partially match column names, but [[ will if exact = FALSE
(and with a warning if exact = NA). If you want to exact matching on
row names use match, as in the examples.

The example it refers to is

sw <- swiss[1:5, 1:4]  # select a manageable subset
sw["C", ] # partially matches
sw[match("C", row.names(sw)), ] # no exact match

Whether this is good behaviour or not is a different question, but the
documentation seems clear enough (to me, at least).

Best,
Steve

On Fri, 14 Jan 2022 at 20:40, Ben Bolker <bbolker at gmail.com> wrote:
>
>
>    People are often surprised that row-indexing a data frame by [ +
> character does partial matching (and annoyed that there is no way to
> turn it off:
>
> https://stackoverflow.com/questions/18033501/warning-when-partial-matching-rownames
>
> https://stackoverflow.com/questions/34233235/r-returning-partial-matching-of-row-names
>
> https://stackoverflow.com/questions/70716905/why-does-r-have-inconsistent-behaviors-when-a-non-existent-rowname-is-retrieved
>
>
> ?"[" says:
>
> Character indices can in some circumstances be partially matched
>       (see ?pmatch?) to the names or dimnames of the object being
>       subsetted (but never for subassignment).  UNLIKE S (Becker et al_
>       p. 358), R NEVER USES PARTIAL MATCHING WHEN EXTRACTING BY ?[?, and
>       partial matching is not by default used by ?[[? (see argument
>       ?exact?).
>
> (EMPHASIS ADDED).
>
> Looking through the rest of that page, I don't see any other text that
> modifies or supersedes that statement.
>
>    Is this a documentation bug?
>
> The example given in one of the links above:
>
> b <- as.data.frame(matrix(4:5, ncol = 1, nrow = 2, dimnames =
> list(c("A10", "B"), "V1")))
>
> b["A1",]  ## 4 (partial matching)
> b[rownames(b) == "A1",]  ## logical(0)
> b["A1", , exact=TRUE]    ## unused argument error
> b$V1[["A1"]] ## subscript out of bounds error
> b$V1["A1"]   ## NA
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From bbo|ker @end|ng |rom gm@||@com  Sat Jan 15 03:54:56 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 14 Jan 2022 21:54:56 -0500
Subject: [Rd] partial matching of row names in [-indexing
In-Reply-To: <CAP=dwz-tFm6eK1gd2xhU6ayjTK6jD0HNwG_52PrUwc2BjfvzAQ@mail.gmail.com>
References: <66cd913b-233a-c9ea-1d48-e9192e408c1d@gmail.com>
 <CAP=dwz-tFm6eK1gd2xhU6ayjTK6jD0HNwG_52PrUwc2BjfvzAQ@mail.gmail.com>
Message-ID: <a0af0044-b91f-e983-dda6-63288ff23707@gmail.com>

   Makes sense if you realize that ?"[" only applies to *vector*, 
*list*, and *matrix* indexing and that data frames follow their own 
rules that are documented elsewhere ...

   So yes, not a bug but I claim it's an infelicity. I might submit a 
doc patch.

  FWIW

b["A1",]
as.matrix(b)["A1",]

  illustrates the difference.

  thanks
    Ben


On 1/14/22 9:19 PM, Steve Martin wrote:
> I don't think this is a bug in the documentation. The help page for
> `?[.data.frame` has the following in the last paragraph of the
> details:
> 
> Both [ and [[ extraction methods partially match row names. By default
> neither partially match column names, but [[ will if exact = FALSE
> (and with a warning if exact = NA). If you want to exact matching on
> row names use match, as in the examples.
> 
> The example it refers to is
> 
> sw <- swiss[1:5, 1:4]  # select a manageable subset
> sw["C", ] # partially matches
> sw[match("C", row.names(sw)), ] # no exact match
> 
> Whether this is good behaviour or not is a different question, but the
> documentation seems clear enough (to me, at least).
> 
> Best,
> Steve
> 
> On Fri, 14 Jan 2022 at 20:40, Ben Bolker <bbolker at gmail.com> wrote:
>>
>>
>>     People are often surprised that row-indexing a data frame by [ +
>> character does partial matching (and annoyed that there is no way to
>> turn it off:
>>
>> https://stackoverflow.com/questions/18033501/warning-when-partial-matching-rownames
>>
>> https://stackoverflow.com/questions/34233235/r-returning-partial-matching-of-row-names
>>
>> https://stackoverflow.com/questions/70716905/why-does-r-have-inconsistent-behaviors-when-a-non-existent-rowname-is-retrieved
>>
>>
>> ?"[" says:
>>
>> Character indices can in some circumstances be partially matched
>>        (see ?pmatch?) to the names or dimnames of the object being
>>        subsetted (but never for subassignment).  UNLIKE S (Becker et al_
>>        p. 358), R NEVER USES PARTIAL MATCHING WHEN EXTRACTING BY ?[?, and
>>        partial matching is not by default used by ?[[? (see argument
>>        ?exact?).
>>
>> (EMPHASIS ADDED).
>>
>> Looking through the rest of that page, I don't see any other text that
>> modifies or supersedes that statement.
>>
>>     Is this a documentation bug?
>>
>> The example given in one of the links above:
>>
>> b <- as.data.frame(matrix(4:5, ncol = 1, nrow = 2, dimnames =
>> list(c("A10", "B"), "V1")))
>>
>> b["A1",]  ## 4 (partial matching)
>> b[rownames(b) == "A1",]  ## logical(0)
>> b["A1", , exact=TRUE]    ## unused argument error
>> b$V1[["A1"]] ## subscript out of bounds error
>> b$V1["A1"]   ## NA
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics


From therne@u @end|ng |rom m@yo@edu  Mon Jan 17 19:06:57 2022
From: therne@u @end|ng |rom m@yo@edu (Therneau, Terry M., Ph.D.)
Date: Mon, 17 Jan 2022 12:06:57 -0600
Subject: [Rd] compile failure for R-devel
Message-ID: <f03410$ha1nt1@ironport10.mayo.edu>

I reran my usual steps to update R this AM, preparatory to doing checks on the rpart 
package.? (I had made changes from Free to R_Free, requested by Brian R.)?? However, the 
process fails:

 ?svn up
tools/rsync-recommended
./configure
make

The make finishes with the following:

gcc -I"../../../../include" -DNDEBUG -I../../../include -I../../../../src/include 
-DHAVE_CONFIG_H -I../../../../src/main -I/usr/local/include? -fvisibility=hidden -fpic? -g 
-O2? -c http.c -o http.o
gcc -shared -L/usr/local/lib -o tools.so text.o init.o Rmd5.o md5.o signals.o install.o 
getfmts.o http.o gramLatex.o gramRd.o pdscan.o
make[6]: Leaving directory '/usr/local/src/R-devel/src/library/tools/src'
make[5]: Leaving directory '/usr/local/src/R-devel/src/library/tools/src'
make[4]: Leaving directory '/usr/local/src/R-devel/src/library/tools'
make[4]: Entering directory '/usr/local/src/R-devel/src/library/tools'
installing 'sysdata.rda'
Error: 'hashtab' is not an exported object from 'namespace:utils'
Execution halted
make[4]: *** [../../../share/make/basepkg.mk:151: sysdata] Error 1
make[4]: Leaving directory '/usr/local/src/R-devel/src/library/tools'
make[3]: *** [Makefile:36: all] Error 2
make[3]: Leaving directory '/usr/local/src/R-devel/src/library/tools'
make[2]: *** [Makefile:37: R] Error 1
make[2]: Leaving directory '/usr/local/src/R-devel/src/library'
make[1]: *** [Makefile:28: R] Error 1
make[1]: Leaving directory '/usr/local/src/R-devel/src'
make: *** [Makefile:61: R] Error 1--

-------
 > sessionInfo()
R Under development (unstable) (2022-01-17 r81511)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 20.04.3 LTS

Matrix products: default
BLAS:?? /usr/local/src/R-devel/lib/libRblas.so
LAPACK: /usr/local/src/R-devel/lib/libRlapack.so

locale:
 ?[1] LC_CTYPE=en_US.UTF-8?????? LC_NUMERIC=C
 ?[3] LC_TIME=en_US.UTF-8??????? LC_COLLATE=C
 ?[5] LC_MONETARY=en_US.UTF-8??? LC_MESSAGES=en_US.UTF-8
 ?[7] LC_PAPER=en_US.UTF-8?????? LC_NAME=C
 ?[9] LC_ADDRESS=C?????????????? LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats???? graphics? grDevices utils???? datasets? methods base

loaded via a namespace (and not attached):
[1] compiler_4.2.0
 >

Any hints?

Terry

Terry M Therneau, PhD
Department of Quantitative Health Sciences
Mayo Clinic
therneau at mayo.edu

"TERR-ree THUR-noh"


	[[alternative HTML version deleted]]


From tom@@@k@||ber@ @end|ng |rom gm@||@com  Mon Jan 17 19:08:34 2022
From: tom@@@k@||ber@ @end|ng |rom gm@||@com (Tomas Kalibera)
Date: Mon, 17 Jan 2022 19:08:34 +0100
Subject: [Rd] compile failure for R-devel
In-Reply-To: <f03410$ha1nt1@ironport10.mayo.edu>
References: <f03410$ha1nt1@ironport10.mayo.edu>
Message-ID: <9359157d-829c-9e87-d5e8-398cdf936dd7@gmail.com>


On 1/17/22 7:06 PM, Therneau, Terry M., Ph.D. via R-devel wrote:
> I reran my usual steps to update R this AM, preparatory to doing checks on the rpart
> package.? (I had made changes from Free to R_Free, requested by Brian R.)?? However, the
> process fails:

Make distclean (or otherwise a fresh build) should resolve this.

Best
Tomas

>
>   ?svn up
> tools/rsync-recommended
> ./configure
> make
>
> The make finishes with the following:
>
> gcc -I"../../../../include" -DNDEBUG -I../../../include -I../../../../src/include
> -DHAVE_CONFIG_H -I../../../../src/main -I/usr/local/include? -fvisibility=hidden -fpic? -g
> -O2? -c http.c -o http.o
> gcc -shared -L/usr/local/lib -o tools.so text.o init.o Rmd5.o md5.o signals.o install.o
> getfmts.o http.o gramLatex.o gramRd.o pdscan.o
> make[6]: Leaving directory '/usr/local/src/R-devel/src/library/tools/src'
> make[5]: Leaving directory '/usr/local/src/R-devel/src/library/tools/src'
> make[4]: Leaving directory '/usr/local/src/R-devel/src/library/tools'
> make[4]: Entering directory '/usr/local/src/R-devel/src/library/tools'
> installing 'sysdata.rda'
> Error: 'hashtab' is not an exported object from 'namespace:utils'
> Execution halted
> make[4]: *** [../../../share/make/basepkg.mk:151: sysdata] Error 1
> make[4]: Leaving directory '/usr/local/src/R-devel/src/library/tools'
> make[3]: *** [Makefile:36: all] Error 2
> make[3]: Leaving directory '/usr/local/src/R-devel/src/library/tools'
> make[2]: *** [Makefile:37: R] Error 1
> make[2]: Leaving directory '/usr/local/src/R-devel/src/library'
> make[1]: *** [Makefile:28: R] Error 1
> make[1]: Leaving directory '/usr/local/src/R-devel/src'
> make: *** [Makefile:61: R] Error 1--
>
> -------
>   > sessionInfo()
> R Under development (unstable) (2022-01-17 r81511)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 20.04.3 LTS
>
> Matrix products: default
> BLAS:?? /usr/local/src/R-devel/lib/libRblas.so
> LAPACK: /usr/local/src/R-devel/lib/libRlapack.so
>
> locale:
>   ?[1] LC_CTYPE=en_US.UTF-8?????? LC_NUMERIC=C
>   ?[3] LC_TIME=en_US.UTF-8??????? LC_COLLATE=C
>   ?[5] LC_MONETARY=en_US.UTF-8??? LC_MESSAGES=en_US.UTF-8
>   ?[7] LC_PAPER=en_US.UTF-8?????? LC_NAME=C
>   ?[9] LC_ADDRESS=C?????????????? LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats???? graphics? grDevices utils???? datasets? methods base
>
> loaded via a namespace (and not attached):
> [1] compiler_4.2.0
>   >
>
> Any hints?
>
> Terry
>
> Terry M Therneau, PhD
> Department of Quantitative Health Sciences
> Mayo Clinic
> therneau at mayo.edu
>
> "TERR-ree THUR-noh"
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From therne@u @end|ng |rom m@yo@edu  Mon Jan 17 19:46:06 2022
From: therne@u @end|ng |rom m@yo@edu (Therneau, Terry M., Ph.D.)
Date: Mon, 17 Jan 2022 12:46:06 -0600
Subject: [Rd] [EXTERNAL] Re:  compile failure for R-devel
In-Reply-To: <9359157d-829c-9e87-d5e8-398cdf936dd7@gmail.com>
References: <f03410$ha1nt1@ironport10.mayo.edu>
 <9359157d-829c-9e87-d5e8-398cdf936dd7@gmail.com>
Message-ID: <f03410$ha221q@ironport10.mayo.edu>

Thank you Tomas, this fixed the issue.

On 1/17/22 12:08 PM, Tomas Kalibera wrote:
>
> On 1/17/22 7:06 PM, Therneau, Terry M., Ph.D. via R-devel wrote:
>> I reran my usual steps to update R this AM, preparatory to doing checks on the rpart
>> package.? (I had made changes from Free to R_Free, requested by Brian R.)?? However, the
>> process fails:
>
> Make distclean (or otherwise a fresh build) should resolve this.
>
> Best
> Tomas
>


From henr|k@bengt@@on @end|ng |rom gm@||@com  Thu Jan 20 20:58:50 2022
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Thu, 20 Jan 2022 11:58:50 -0800
Subject: [Rd] partial matching of row names in [-indexing
In-Reply-To: <a0af0044-b91f-e983-dda6-63288ff23707@gmail.com>
References: <66cd913b-233a-c9ea-1d48-e9192e408c1d@gmail.com>
 <CAP=dwz-tFm6eK1gd2xhU6ayjTK6jD0HNwG_52PrUwc2BjfvzAQ@mail.gmail.com>
 <a0af0044-b91f-e983-dda6-63288ff23707@gmail.com>
Message-ID: <CAFDcVCSHDiQr6Ms9y6BA-HqTo3wXGh61zEJSXmiAJNLZaeLODw@mail.gmail.com>

Although implicit, but what I don't think anyone has mentioned is that
the partial matching of row names only applies if the row name is
uniquely matched, as in:

> X <- data.frame(a=1:3, b=letters[1:3], row.names=c("A1", "B", "C"))
> X["A", ]
   a b
A1 1 a

If it matches two or more rows, you get:

> X <- data.frame(a=1:3, b=letters[1:3], row.names=c("A1", "A2", "C"))
> X["A", ]
    a    b
NA NA <NA>

just as you would get if there is no match:

> X["A3", ]
    a    b
NA NA <NA>

So, the current behavior is dependent on what the other similar row
names too, that is, what might work at one point, might break when new
data are added to the data frame.

This is a behavior that I think stems from someone thought it's handy
while working interactively with data.frame:s interactively.  I think
it's an error-prone property when it comes to production code (script,
packages, and dynamic documents).  To me, this behavior should be
phased out from R to avoid silent errors and false scientific results.
It's not clear to me how to best deprecate the partial matching,
because of the default behavior of returning NA:s when there is no
match.  This means it can't be just a warning or an error.

My $.03

/Henrik

On Fri, Jan 14, 2022 at 6:55 PM Ben Bolker <bbolker at gmail.com> wrote:
>
>    Makes sense if you realize that ?"[" only applies to *vector*,
> *list*, and *matrix* indexing and that data frames follow their own
> rules that are documented elsewhere ...
>
>    So yes, not a bug but I claim it's an infelicity. I might submit a
> doc patch.
>
>   FWIW
>
> b["A1",]
> as.matrix(b)["A1",]
>
>   illustrates the difference.
>
>   thanks
>     Ben
>
>
> On 1/14/22 9:19 PM, Steve Martin wrote:
> > I don't think this is a bug in the documentation. The help page for
> > `?[.data.frame` has the following in the last paragraph of the
> > details:
> >
> > Both [ and [[ extraction methods partially match row names. By default
> > neither partially match column names, but [[ will if exact = FALSE
> > (and with a warning if exact = NA). If you want to exact matching on
> > row names use match, as in the examples.
> >
> > The example it refers to is
> >
> > sw <- swiss[1:5, 1:4]  # select a manageable subset
> > sw["C", ] # partially matches
> > sw[match("C", row.names(sw)), ] # no exact match
> >
> > Whether this is good behaviour or not is a different question, but the
> > documentation seems clear enough (to me, at least).
> >
> > Best,
> > Steve
> >
> > On Fri, 14 Jan 2022 at 20:40, Ben Bolker <bbolker at gmail.com> wrote:
> >>
> >>
> >>     People are often surprised that row-indexing a data frame by [ +
> >> character does partial matching (and annoyed that there is no way to
> >> turn it off:
> >>
> >> https://stackoverflow.com/questions/18033501/warning-when-partial-matching-rownames
> >>
> >> https://stackoverflow.com/questions/34233235/r-returning-partial-matching-of-row-names
> >>
> >> https://stackoverflow.com/questions/70716905/why-does-r-have-inconsistent-behaviors-when-a-non-existent-rowname-is-retrieved
> >>
> >>
> >> ?"[" says:
> >>
> >> Character indices can in some circumstances be partially matched
> >>        (see ?pmatch?) to the names or dimnames of the object being
> >>        subsetted (but never for subassignment).  UNLIKE S (Becker et al_
> >>        p. 358), R NEVER USES PARTIAL MATCHING WHEN EXTRACTING BY ?[?, and
> >>        partial matching is not by default used by ?[[? (see argument
> >>        ?exact?).
> >>
> >> (EMPHASIS ADDED).
> >>
> >> Looking through the rest of that page, I don't see any other text that
> >> modifies or supersedes that statement.
> >>
> >>     Is this a documentation bug?
> >>
> >> The example given in one of the links above:
> >>
> >> b <- as.data.frame(matrix(4:5, ncol = 1, nrow = 2, dimnames =
> >> list(c("A10", "B"), "V1")))
> >>
> >> b["A1",]  ## 4 (partial matching)
> >> b[rownames(b) == "A1",]  ## logical(0)
> >> b["A1", , exact=TRUE]    ## unused argument error
> >> b$V1[["A1"]] ## subscript out of bounds error
> >> b$V1["A1"]   ## NA
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> (Acting) Graduate chair, Mathematics & Statistics
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From bbo|ker @end|ng |rom gm@||@com  Thu Jan 20 21:02:37 2022
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 20 Jan 2022 15:02:37 -0500
Subject: [Rd] partial matching of row names in [-indexing
In-Reply-To: <CAFDcVCSHDiQr6Ms9y6BA-HqTo3wXGh61zEJSXmiAJNLZaeLODw@mail.gmail.com>
References: <66cd913b-233a-c9ea-1d48-e9192e408c1d@gmail.com>
 <CAP=dwz-tFm6eK1gd2xhU6ayjTK6jD0HNwG_52PrUwc2BjfvzAQ@mail.gmail.com>
 <a0af0044-b91f-e983-dda6-63288ff23707@gmail.com>
 <CAFDcVCSHDiQr6Ms9y6BA-HqTo3wXGh61zEJSXmiAJNLZaeLODw@mail.gmail.com>
Message-ID: <c1737bf2-bad5-9058-7659-fbcc5a5f33f1@gmail.com>

   FWIW there is also a discussion of this on bugzilla:

https://bugs.r-project.org/show_bug.cgi?id=18278

On 1/20/22 2:58 PM, Henrik Bengtsson wrote:
> Although implicit, but what I don't think anyone has mentioned is that
> the partial matching of row names only applies if the row name is
> uniquely matched, as in:
> 
>> X <- data.frame(a=1:3, b=letters[1:3], row.names=c("A1", "B", "C"))
>> X["A", ]
>     a b
> A1 1 a
> 
> If it matches two or more rows, you get:
> 
>> X <- data.frame(a=1:3, b=letters[1:3], row.names=c("A1", "A2", "C"))
>> X["A", ]
>      a    b
> NA NA <NA>
> 
> just as you would get if there is no match:
> 
>> X["A3", ]
>      a    b
> NA NA <NA>
> 
> So, the current behavior is dependent on what the other similar row
> names too, that is, what might work at one point, might break when new
> data are added to the data frame.
> 
> This is a behavior that I think stems from someone thought it's handy
> while working interactively with data.frame:s interactively.  I think
> it's an error-prone property when it comes to production code (script,
> packages, and dynamic documents).  To me, this behavior should be
> phased out from R to avoid silent errors and false scientific results.
> It's not clear to me how to best deprecate the partial matching,
> because of the default behavior of returning NA:s when there is no
> match.  This means it can't be just a warning or an error.
> 
> My $.03
> 
> /Henrik
> 
> On Fri, Jan 14, 2022 at 6:55 PM Ben Bolker <bbolker at gmail.com> wrote:
>>
>>     Makes sense if you realize that ?"[" only applies to *vector*,
>> *list*, and *matrix* indexing and that data frames follow their own
>> rules that are documented elsewhere ...
>>
>>     So yes, not a bug but I claim it's an infelicity. I might submit a
>> doc patch.
>>
>>    FWIW
>>
>> b["A1",]
>> as.matrix(b)["A1",]
>>
>>    illustrates the difference.
>>
>>    thanks
>>      Ben
>>
>>
>> On 1/14/22 9:19 PM, Steve Martin wrote:
>>> I don't think this is a bug in the documentation. The help page for
>>> `?[.data.frame` has the following in the last paragraph of the
>>> details:
>>>
>>> Both [ and [[ extraction methods partially match row names. By default
>>> neither partially match column names, but [[ will if exact = FALSE
>>> (and with a warning if exact = NA). If you want to exact matching on
>>> row names use match, as in the examples.
>>>
>>> The example it refers to is
>>>
>>> sw <- swiss[1:5, 1:4]  # select a manageable subset
>>> sw["C", ] # partially matches
>>> sw[match("C", row.names(sw)), ] # no exact match
>>>
>>> Whether this is good behaviour or not is a different question, but the
>>> documentation seems clear enough (to me, at least).
>>>
>>> Best,
>>> Steve
>>>
>>> On Fri, 14 Jan 2022 at 20:40, Ben Bolker <bbolker at gmail.com> wrote:
>>>>
>>>>
>>>>      People are often surprised that row-indexing a data frame by [ +
>>>> character does partial matching (and annoyed that there is no way to
>>>> turn it off:
>>>>
>>>> https://stackoverflow.com/questions/18033501/warning-when-partial-matching-rownames
>>>>
>>>> https://stackoverflow.com/questions/34233235/r-returning-partial-matching-of-row-names
>>>>
>>>> https://stackoverflow.com/questions/70716905/why-does-r-have-inconsistent-behaviors-when-a-non-existent-rowname-is-retrieved
>>>>
>>>>
>>>> ?"[" says:
>>>>
>>>> Character indices can in some circumstances be partially matched
>>>>         (see ?pmatch?) to the names or dimnames of the object being
>>>>         subsetted (but never for subassignment).  UNLIKE S (Becker et al_
>>>>         p. 358), R NEVER USES PARTIAL MATCHING WHEN EXTRACTING BY ?[?, and
>>>>         partial matching is not by default used by ?[[? (see argument
>>>>         ?exact?).
>>>>
>>>> (EMPHASIS ADDED).
>>>>
>>>> Looking through the rest of that page, I don't see any other text that
>>>> modifies or supersedes that statement.
>>>>
>>>>      Is this a documentation bug?
>>>>
>>>> The example given in one of the links above:
>>>>
>>>> b <- as.data.frame(matrix(4:5, ncol = 1, nrow = 2, dimnames =
>>>> list(c("A10", "B"), "V1")))
>>>>
>>>> b["A1",]  ## 4 (partial matching)
>>>> b[rownames(b) == "A1",]  ## logical(0)
>>>> b["A1", , exact=TRUE]    ## unused argument error
>>>> b$V1[["A1"]] ## subscript out of bounds error
>>>> b$V1["A1"]   ## NA
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> --
>> Dr. Benjamin Bolker
>> Professor, Mathematics & Statistics and Biology, McMaster University
>> Director, School of Computational Science and Engineering
>> (Acting) Graduate chair, Mathematics & Statistics
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics


From gm@t|m@ @end|ng |rom gm@||@com  Thu Jan 20 22:33:40 2022
From: gm@t|m@ @end|ng |rom gm@||@com (Roman Savchenko)
Date: Thu, 20 Jan 2022 23:33:40 +0200
Subject: [Rd] Out buffers flushing
Message-ID: <CAGpdKUJJsCY_+1=SePCOaJY5VhTZbHJ-jaZGqn+iLkx=uyEMAw@mail.gmail.com>

Hey Dear R devs,

I'm using R CMD BATCH output stream as control stream (via IPC) in my
project. I noticed that sometimes I'm not receiving out line intime (that
leads to unwanted behaviour). I suspect it is due to some buffering
mechanism. I tried to use flush.console() but it does not help.

Thanks for any advices,
Roman.

	[[alternative HTML version deleted]]


From m|n@h@|| @end|ng |rom um|ch@edu  Fri Jan 21 16:51:52 2022
From: m|n@h@|| @end|ng |rom um|ch@edu (Greg Minshall)
Date: Fri, 21 Jan 2022 07:51:52 -0800
Subject: [Rd] Out buffers flushing
In-Reply-To: <CAGpdKUJJsCY_+1=SePCOaJY5VhTZbHJ-jaZGqn+iLkx=uyEMAw@mail.gmail.com>
References: <CAGpdKUJJsCY_+1=SePCOaJY5VhTZbHJ-jaZGqn+iLkx=uyEMAw@mail.gmail.com>
Message-ID: <4150804.1642780312@apollo2.minshall.org>

Roman,

> I'm using R CMD BATCH output stream as control stream (via IPC) in my
> project. I noticed that sometimes I'm not receiving out line intime
> (that leads to unwanted behaviour). I suspect it is due to some
> buffering mechanism. I tried to use flush.console() but it does not
> help.

so, i'm not quite sure i understand the setup here.  you are running
some script via `R CMD BATCH`.  that i got.  but i don't know what you
mean with "(via IPC)".

if when running `R CMD BATCH` on a terminal, your output is showing up
in a timely way, but when running it some other way, the output is
delayed, you might try running (on Unix, say) it through a pipe like
> R CMD BATCH <YOUR_ARGUMENTS_HERE> | cat
and seeing if you still get the output in a timely way.  if not, then
there might be some buffering inside the R code that disables buffering
when going to a terminal, but does buffer when the output is going
somewhere other than your terminal (this is not uncommon in, e.g.,
Unix's "standard I/O library").

but, if that pipeline gives output in a timely manner, then maybe your
"IPC" mechanism is causing the problem.

i don't know if that will be of any help.

cheers, Greg


From w||||@mwdun|@p @end|ng |rom gm@||@com  Fri Jan 21 17:25:06 2022
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Fri, 21 Jan 2022 08:25:06 -0800
Subject: [Rd] Out buffers flushing
In-Reply-To: <4150804.1642780312@apollo2.minshall.org>
References: <CAGpdKUJJsCY_+1=SePCOaJY5VhTZbHJ-jaZGqn+iLkx=uyEMAw@mail.gmail.com>
 <4150804.1642780312@apollo2.minshall.org>
Message-ID: <CAHqSRuSSeSdO5RTLfVMMU0QuyWq7dh0DY0e-p71KUSpAHXpkrg@mail.gmail.com>

On Linux you could try
    stdbuf --output=L R 2>&1 | cat
to force line buffering when the output goes to a pipe (replace 'cat' by
the command of your choice).  'R' may have to be replaced by the actual
executable, e.g.,
    R CMD stdbuf --output=L `R RHOME`/bin/exec/R 2>&1 | cat

-Bill

On Fri, Jan 21, 2022 at 7:52 AM Greg Minshall <minshall at umich.edu> wrote:

> Roman,
>
> > I'm using R CMD BATCH output stream as control stream (via IPC) in my
> > project. I noticed that sometimes I'm not receiving out line intime
> > (that leads to unwanted behaviour). I suspect it is due to some
> > buffering mechanism. I tried to use flush.console() but it does not
> > help.
>
> so, i'm not quite sure i understand the setup here.  you are running
> some script via `R CMD BATCH`.  that i got.  but i don't know what you
> mean with "(via IPC)".
>
> if when running `R CMD BATCH` on a terminal, your output is showing up
> in a timely way, but when running it some other way, the output is
> delayed, you might try running (on Unix, say) it through a pipe like
> > R CMD BATCH <YOUR_ARGUMENTS_HERE> | cat
> and seeing if you still get the output in a timely way.  if not, then
> there might be some buffering inside the R code that disables buffering
> when going to a terminal, but does buffer when the output is going
> somewhere other than your terminal (this is not uncommon in, e.g.,
> Unix's "standard I/O library").
>
> but, if that pipeline gives output in a timely manner, then maybe your
> "IPC" mechanism is causing the problem.
>
> i don't know if that will be of any help.
>
> cheers, Greg
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From c@@rd|@g@bor @end|ng |rom gm@||@com  Fri Jan 21 17:26:23 2022
From: c@@rd|@g@bor @end|ng |rom gm@||@com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Fri, 21 Jan 2022 17:26:23 +0100
Subject: [Rd] isNamespaceLoaded() while the namespace is loading
Message-ID: <CABtg=Kn8zaF+ebw8qd-PeG2DnzT6xa-r3tMct9raDLUPFz=X0A@mail.gmail.com>

We ran into a bug in our package that seems to boil down to
isNamespaceLoaded() returning TRUE for namespaces that R is currently
loading.

We had something like this in an .onLoad function:

if (isNamespaceLoaded("upstream")) {
  upstream::upstream_function()
}

Which seems OK, unless upstream (recursively) imports the package
having this code. Should that happen, the loading of upstream triggers
the loading of this package as well and isNamespaceLoaded() seems to
return TRUE, even though the namespace of upstream is not fully loaded
yet, and we get an error that looks like this:

Error : .onLoad failed in loadNamespace() for 'foo', details:
     call: NULL
     error: 'upstream_function' is not an exported object from
'namespace:upstream'

I wonder if isNamespaceLoaded() returning TRUE is correct in this
case, or returning FALSE would be better. Or maybe it would make sense
to have a way to query the packages that are being loaded currently?

AFAICT this works, but it does use some implementation details from
loadNamespace(), so it does not seem like a proper solution:

dynGet("__NameSpacesLoading__", NULL)

Another workaround is something like this:

  is_loaded <- function(pkg) {
    if (!isNamespaceLoaded(pkg)) return(FALSE)
    tryCatch({
      loadNamespace(pkg)
      TRUE
    }, error = function(err) FALSE)
  }

which forces an error for currently loading namespaces by triggering a
(fake) recursive dependency.

Thanks,
Gabor


From pro|jcn@@h @end|ng |rom gm@||@com  Sat Jan 22 02:51:08 2022
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Fri, 21 Jan 2022 20:51:08 -0500
Subject: [Rd] reason for odd timings
Message-ID: <87f61918-0bd9-638c-83ef-1057d2f7dfd5@gmail.com>

Occasionally I run some rather trivial timings to get an idea of what might
be the best way to compute some quantities.

The program below gave timings for sums of squares of 100 elements much greater
than those for 1000, which seems surprising. Does anyone know the cause of this?

This isn't holding up my work. Just causing some head scratching.

JN

> source("sstimer.R")
 n  	  t(forloop) : ratio 	  t(sum) : ratio 	 t(crossprod) 	 all.equal
100 	 38719.15  :  1.766851 	 13421.12  :  0.6124391 	 21914.21 	 TRUE
1000 	 44722.71  :  20.98348 	 3093.94  :  1.451648 	 2131.33 	 TRUE
10000 	 420149.9  :  42.10269 	 27341.6  :  2.739867 	 9979.17 	 TRUE
1e+05 	 4070469  :  39.89473 	 343293.5  :  3.364625 	 102030.2 	 TRUE
1e+06 	 42293696  :  33.27684 	 3605866  :  2.837109 	 1270965 	 TRUE
1e+07 	 408123066  :  29.20882 	 35415106  :  2.534612 	 13972596 	 TRUE
>

# crossprod timer
library(microbenchmark)
suml<-function(vv) {
    ss<-0.0
    for (i in 1:length(vv)) {ss<-ss+vv[i]^2}
    ss
}
sums<-function(vv) {
  ss<-sum(vv^2)
  ss
}
sumc<-function(vv) {
  ss<-as.numeric(crossprod(vv))
  ss
}
ll <- c(100, 1000, 10000, 100000, 1000000, 10000000)
cat(" n  \t  t(forloop) : ratio \t  t(sum) : ratio \t t(crossprod) \t all.equal \n")
for (nn in ll ){
   set.seed(1234)
   vv <- runif(nn)
   tsuml<-microbenchmark(sl<-suml(vv), unit="us")
   tsums<-microbenchmark(ss<-sums(vv), unit="us")
   tsumc<-microbenchmark(sc<-sumc(vv), unit="us")
   ml<-mean(tsuml$time)
   ms<-mean(tsums$time)
   mc<-mean(tsumc$time)
   cat(nn,"\t",ml," : ",ml/mc,"\t",ms," : ",ms/mc,"\t",mc,"\t",all.equal(sl, ss, sc),"\n")
}


From peter@|@ng|e|der @end|ng |rom gm@||@com  Sat Jan 22 05:27:02 2022
From: peter@|@ng|e|der @end|ng |rom gm@||@com (Peter Langfelder)
Date: Fri, 21 Jan 2022 20:27:02 -0800
Subject: [Rd] reason for odd timings
In-Reply-To: <87f61918-0bd9-638c-83ef-1057d2f7dfd5@gmail.com>
References: <87f61918-0bd9-638c-83ef-1057d2f7dfd5@gmail.com>
Message-ID: <CA+hbrhVGE1a4BY7ubEhPXRJPs5aKt9id5O_C2hUWGVLxQ3BVEQ@mail.gmail.com>

I think R spends a little bit of time compiling the functions into byte
code the first time you call the function. The hint is that the oddity
seems to go away when running the code repeatedly. The first timing for the
first three values of ll returns this:

100 65347.45  :  2.491943 24329.94  :  0.9277918 26223.49 TRUE
1000 71387.79  :  11.49891 4619.35  :  0.74407 6208.22 TRUE
10000 711115.8  :  16.82563 61732.79  :  1.460653 42263.83 TRUE

the subsequent runs return this:

100 8349.68  :  3.125699 1821.28  :  0.6817954 2671.3 TRUE
1000 72191.88  :  11.8359 4712.81  :  0.7726678 6099.4 TRUE
10000 706826.9  :  15.95787 61574.9  :  1.390162 44293.32 TRUE

100 8390.46  :  3.159023 1815.71  :  0.683618 2656.03 TRUE
1000 93731.96  :  15.3112 4630.55  :  0.7564046 6121.79 TRUE
10000 809345.8  :  18.75048 61903.45  :  1.434145 43164 TRUE

Peter

On Fri, Jan 21, 2022 at 5:51 PM J C Nash <profjcnash at gmail.com> wrote:

> Occasionally I run some rather trivial timings to get an idea of what might
> be the best way to compute some quantities.
>
> The program below gave timings for sums of squares of 100 elements much
> greater
> than those for 1000, which seems surprising. Does anyone know the cause of
> this?
>
> This isn't holding up my work. Just causing some head scratching.
>
> JN
>
> > source("sstimer.R")
>  n        t(forloop) : ratio      t(sum) : ratio         t(crossprod)
> all.equal
> 100      38719.15  :  1.766851   13421.12  :  0.6124391          21914.21
>       TRUE
> 1000     44722.71  :  20.98348   3093.94  :  1.451648    2131.33
>  TRUE
> 10000    420149.9  :  42.10269   27341.6  :  2.739867    9979.17
>  TRUE
> 1e+05    4070469  :  39.89473    343293.5  :  3.364625   102030.2
> TRUE
> 1e+06    42293696  :  33.27684   3605866  :  2.837109    1270965
>  TRUE
> 1e+07    408123066  :  29.20882          35415106  :  2.534612   13972596
>       TRUE
> >
>
> # crossprod timer
> library(microbenchmark)
> suml<-function(vv) {
>     ss<-0.0
>     for (i in 1:length(vv)) {ss<-ss+vv[i]^2}
>     ss
> }
> sums<-function(vv) {
>   ss<-sum(vv^2)
>   ss
> }
> sumc<-function(vv) {
>   ss<-as.numeric(crossprod(vv))
>   ss
> }
> ll <- c(100, 1000, 10000, 100000, 1000000, 10000000)
> cat(" n  \t  t(forloop) : ratio \t  t(sum) : ratio \t t(crossprod) \t
> all.equal \n")
> for (nn in ll ){
>    set.seed(1234)
>    vv <- runif(nn)
>    tsuml<-microbenchmark(sl<-suml(vv), unit="us")
>    tsums<-microbenchmark(ss<-sums(vv), unit="us")
>    tsumc<-microbenchmark(sc<-sumc(vv), unit="us")
>    ml<-mean(tsuml$time)
>    ms<-mean(tsums$time)
>    mc<-mean(tsumc$time)
>    cat(nn,"\t",ml," : ",ml/mc,"\t",ms," :
> ",ms/mc,"\t",mc,"\t",all.equal(sl, ss, sc),"\n")
> }
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From @tevem@rt|n041 @end|ng |rom gm@||@com  Sat Jan 22 05:38:33 2022
From: @tevem@rt|n041 @end|ng |rom gm@||@com (Steve Martin)
Date: Fri, 21 Jan 2022 23:38:33 -0500
Subject: [Rd] reason for odd timings
In-Reply-To: <87f61918-0bd9-638c-83ef-1057d2f7dfd5@gmail.com>
References: <87f61918-0bd9-638c-83ef-1057d2f7dfd5@gmail.com>
Message-ID: <CAP=dwz_WWXb6_bejxvPUwYUFzvO=qbQBV7aCAQ6+Sa0mkhYaNQ@mail.gmail.com>

Just to add a bit more, stripping out most of your test shows that
there is one iteration (the 2nd one) that takes a lot longer than the
others because the sums() function gets bytecode compiled.

library(microbenchmark)

sums <- function(vv) {
  ss <- sum(vv^2)
  ss
}

sums2 <- compiler::cmpfun(sums)

x <- runif(100)

head(as.data.frame(microbenchmark(sums(x), sums2(x))))
          expr    time
1  sums(x)   29455
2  sums(x) 3683091
3 sums2(x)    7108
4  sums(x)    4305
5  sums(x)    2733
6  sums(x)    2797

The paragraph on JIT in the details of ?compiler::compile explains
that this is the default behavior.

Steve

On Fri, 21 Jan 2022 at 20:51, J C Nash <profjcnash at gmail.com> wrote:
>
> Occasionally I run some rather trivial timings to get an idea of what might
> be the best way to compute some quantities.
>
> The program below gave timings for sums of squares of 100 elements much greater
> than those for 1000, which seems surprising. Does anyone know the cause of this?
>
> This isn't holding up my work. Just causing some head scratching.
>
> JN
>
> > source("sstimer.R")
>  n        t(forloop) : ratio      t(sum) : ratio         t(crossprod)    all.equal
> 100      38719.15  :  1.766851   13421.12  :  0.6124391          21914.21        TRUE
> 1000     44722.71  :  20.98348   3093.94  :  1.451648    2131.33         TRUE
> 10000    420149.9  :  42.10269   27341.6  :  2.739867    9979.17         TRUE
> 1e+05    4070469  :  39.89473    343293.5  :  3.364625   102030.2        TRUE
> 1e+06    42293696  :  33.27684   3605866  :  2.837109    1270965         TRUE
> 1e+07    408123066  :  29.20882          35415106  :  2.534612   13972596        TRUE
> >
>
> # crossprod timer
> library(microbenchmark)
> suml<-function(vv) {
>     ss<-0.0
>     for (i in 1:length(vv)) {ss<-ss+vv[i]^2}
>     ss
> }
> sums<-function(vv) {
>   ss<-sum(vv^2)
>   ss
> }
> sumc<-function(vv) {
>   ss<-as.numeric(crossprod(vv))
>   ss
> }
> ll <- c(100, 1000, 10000, 100000, 1000000, 10000000)
> cat(" n  \t  t(forloop) : ratio \t  t(sum) : ratio \t t(crossprod) \t all.equal \n")
> for (nn in ll ){
>    set.seed(1234)
>    vv <- runif(nn)
>    tsuml<-microbenchmark(sl<-suml(vv), unit="us")
>    tsums<-microbenchmark(ss<-sums(vv), unit="us")
>    tsumc<-microbenchmark(sc<-sumc(vv), unit="us")
>    ml<-mean(tsuml$time)
>    ms<-mean(tsums$time)
>    mc<-mean(tsumc$time)
>    cat(nn,"\t",ml," : ",ml/mc,"\t",ms," : ",ms/mc,"\t",mc,"\t",all.equal(sl, ss, sc),"\n")
> }
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From pro|jcn@@h @end|ng |rom gm@||@com  Sat Jan 22 18:18:38 2022
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Sat, 22 Jan 2022 12:18:38 -0500
Subject: [Rd] reason for odd timings
In-Reply-To: <CAP=dwz_WWXb6_bejxvPUwYUFzvO=qbQBV7aCAQ6+Sa0mkhYaNQ@mail.gmail.com>
References: <87f61918-0bd9-638c-83ef-1057d2f7dfd5@gmail.com>
 <CAP=dwz_WWXb6_bejxvPUwYUFzvO=qbQBV7aCAQ6+Sa0mkhYaNQ@mail.gmail.com>
Message-ID: <13444c9f-4d81-2431-b409-3901a6c94f61@gmail.com>

Many thanks for quick and reasonable explanation.

Now the issue is to figure out when it is worthwhile to recommend/use sums2.

Best, JN


On 2022-01-21 23:38, Steve Martin wrote:
> Just to add a bit more, stripping out most of your test shows that
> there is one iteration (the 2nd one) that takes a lot longer than the
> others because the sums() function gets bytecode compiled.
> 
> library(microbenchmark)
> 
> sums <- function(vv) {
>    ss <- sum(vv^2)
>    ss
> }
> 
> sums2 <- compiler::cmpfun(sums)
> 
> x <- runif(100)
> 
> head(as.data.frame(microbenchmark(sums(x), sums2(x))))
>            expr    time
> 1  sums(x)   29455
> 2  sums(x) 3683091
> 3 sums2(x)    7108
> 4  sums(x)    4305
> 5  sums(x)    2733
> 6  sums(x)    2797
> 
> The paragraph on JIT in the details of ?compiler::compile explains
> that this is the default behavior.
> 
> Steve
> 
> On Fri, 21 Jan 2022 at 20:51, J C Nash <profjcnash at gmail.com> wrote:
>>
>> Occasionally I run some rather trivial timings to get an idea of what might
>> be the best way to compute some quantities.
>>
>> The program below gave timings for sums of squares of 100 elements much greater
>> than those for 1000, which seems surprising. Does anyone know the cause of this?
>>
>> This isn't holding up my work. Just causing some head scratching.
>>
>> JN
>>
>>> source("sstimer.R")
>>   n        t(forloop) : ratio      t(sum) : ratio         t(crossprod)    all.equal
>> 100      38719.15  :  1.766851   13421.12  :  0.6124391          21914.21        TRUE
>> 1000     44722.71  :  20.98348   3093.94  :  1.451648    2131.33         TRUE
>> 10000    420149.9  :  42.10269   27341.6  :  2.739867    9979.17         TRUE
>> 1e+05    4070469  :  39.89473    343293.5  :  3.364625   102030.2        TRUE
>> 1e+06    42293696  :  33.27684   3605866  :  2.837109    1270965         TRUE
>> 1e+07    408123066  :  29.20882          35415106  :  2.534612   13972596        TRUE
>>>
>>
>> # crossprod timer
>> library(microbenchmark)
>> suml<-function(vv) {
>>      ss<-0.0
>>      for (i in 1:length(vv)) {ss<-ss+vv[i]^2}
>>      ss
>> }
>> sums<-function(vv) {
>>    ss<-sum(vv^2)
>>    ss
>> }
>> sumc<-function(vv) {
>>    ss<-as.numeric(crossprod(vv))
>>    ss
>> }
>> ll <- c(100, 1000, 10000, 100000, 1000000, 10000000)
>> cat(" n  \t  t(forloop) : ratio \t  t(sum) : ratio \t t(crossprod) \t all.equal \n")
>> for (nn in ll ){
>>     set.seed(1234)
>>     vv <- runif(nn)
>>     tsuml<-microbenchmark(sl<-suml(vv), unit="us")
>>     tsums<-microbenchmark(ss<-sums(vv), unit="us")
>>     tsumc<-microbenchmark(sc<-sumc(vv), unit="us")
>>     ml<-mean(tsuml$time)
>>     ms<-mean(tsums$time)
>>     mc<-mean(tsumc$time)
>>     cat(nn,"\t",ml," : ",ml/mc,"\t",ms," : ",ms/mc,"\t",mc,"\t",all.equal(sl, ss, sc),"\n")
>> }
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From @|mon@urb@nek @end|ng |rom R-project@org  Sat Jan 22 22:44:54 2022
From: @|mon@urb@nek @end|ng |rom R-project@org (Simon Urbanek)
Date: Sun, 23 Jan 2022 10:44:54 +1300
Subject: [Rd] reason for odd timings
In-Reply-To: <13444c9f-4d81-2431-b409-3901a6c94f61@gmail.com>
References: <87f61918-0bd9-638c-83ef-1057d2f7dfd5@gmail.com>
 <CAP=dwz_WWXb6_bejxvPUwYUFzvO=qbQBV7aCAQ6+Sa0mkhYaNQ@mail.gmail.com>
 <13444c9f-4d81-2431-b409-3901a6c94f61@gmail.com>
Message-ID: <B8A7884D-6970-461B-9A1D-941EC0162520@R-project.org>

FWIW crossprod timings are likely not generalizable, because unlike sum() they depend on the BLAS implementation used so it's not uncommon to see significant differences. For simple things like this the parallel BLAS can actually be slower than the built-in one (since the computation is limited by memory throughput).

Also if you actually want to measure the difference, don't use functions as they have significant overhead (for short evals), just use the expressions, e.g.:

> library(microbenchmark)
> ll <- c(100, 1000, 10000, 100000, 1000000, 10000000)
> l <- lapply(ll, function(nn) {
+    set.seed(1234)
+    vv <- runif(nn)
+    rbind(microbenchmark(sum(vv^2)),
+          microbenchmark(c(crossprod(vv))))
+ })
> do.call("rbind", lapply(l, summary, unit="us"))
               expr       min        lq        mean     median         uq       max neval
1         sum(vv^2)     0.703     0.731     1.09781     0.7665     0.9050    10.356   100
2  c(crossprod(vv))     2.317     2.334     3.39735     2.4025     2.5390    92.110   100
3         sum(vv^2)     3.200     3.261     3.51941     3.3580     3.5425    13.109   100
4  c(crossprod(vv))     3.919     3.973     4.29774     4.0145     4.1200    25.054   100
5         sum(vv^2)    57.461    60.910    69.12497    67.4455    75.9360   102.943   100
6  c(crossprod(vv))    18.321    18.468    19.32948    18.5735    18.6795    82.353   100
7         sum(vv^2)   286.488   566.928   607.11935   596.7610   631.5625  4955.724   100
8  c(crossprod(vv))   161.757   163.338   167.62892   165.1660   165.8425   327.439   100
9         sum(vv^2)  3221.395  3694.859  4604.01607  3867.5830  4050.5715  8565.486   100
10 c(crossprod(vv))  1898.899  1922.386  1955.75945  1941.1760  1959.3340  2392.512   100
11        sum(vv^2) 43634.025 44486.356 45493.26093 44850.8460 45170.9870 97560.633   100
12 c(crossprod(vv)) 19379.950 19631.935 19817.88547 19770.3475 19922.6035 21512.017   100

That said, I suspect that we used more time talking about this than will be ever saved by picking one method over the other ;).

Cheers,
Simon



> On Jan 23, 2022, at 6:18 AM, J C Nash <profjcnash at gmail.com> wrote:
> 
> Many thanks for quick and reasonable explanation.
> 
> Now the issue is to figure out when it is worthwhile to recommend/use sums2.
> 
> Best, JN
> 
> 
> On 2022-01-21 23:38, Steve Martin wrote:
>> Just to add a bit more, stripping out most of your test shows that
>> there is one iteration (the 2nd one) that takes a lot longer than the
>> others because the sums() function gets bytecode compiled.
>> library(microbenchmark)
>> sums <- function(vv) {
>>   ss <- sum(vv^2)
>>   ss
>> }
>> sums2 <- compiler::cmpfun(sums)
>> x <- runif(100)
>> head(as.data.frame(microbenchmark(sums(x), sums2(x))))
>>           expr    time
>> 1  sums(x)   29455
>> 2  sums(x) 3683091
>> 3 sums2(x)    7108
>> 4  sums(x)    4305
>> 5  sums(x)    2733
>> 6  sums(x)    2797
>> The paragraph on JIT in the details of ?compiler::compile explains
>> that this is the default behavior.
>> Steve
>> On Fri, 21 Jan 2022 at 20:51, J C Nash <profjcnash at gmail.com> wrote:
>>> 
>>> Occasionally I run some rather trivial timings to get an idea of what might
>>> be the best way to compute some quantities.
>>> 
>>> The program below gave timings for sums of squares of 100 elements much greater
>>> than those for 1000, which seems surprising. Does anyone know the cause of this?
>>> 
>>> This isn't holding up my work. Just causing some head scratching.
>>> 
>>> JN
>>> 
>>>> source("sstimer.R")
>>>  n        t(forloop) : ratio      t(sum) : ratio         t(crossprod)    all.equal
>>> 100      38719.15  :  1.766851   13421.12  :  0.6124391          21914.21        TRUE
>>> 1000     44722.71  :  20.98348   3093.94  :  1.451648    2131.33         TRUE
>>> 10000    420149.9  :  42.10269   27341.6  :  2.739867    9979.17         TRUE
>>> 1e+05    4070469  :  39.89473    343293.5  :  3.364625   102030.2        TRUE
>>> 1e+06    42293696  :  33.27684   3605866  :  2.837109    1270965         TRUE
>>> 1e+07    408123066  :  29.20882          35415106  :  2.534612   13972596        TRUE
>>>> 
>>> 
>>> # crossprod timer
>>> library(microbenchmark)
>>> suml<-function(vv) {
>>>     ss<-0.0
>>>     for (i in 1:length(vv)) {ss<-ss+vv[i]^2}
>>>     ss
>>> }
>>> sums<-function(vv) {
>>>   ss<-sum(vv^2)
>>>   ss
>>> }
>>> sumc<-function(vv) {
>>>   ss<-as.numeric(crossprod(vv))
>>>   ss
>>> }
>>> ll <- c(100, 1000, 10000, 100000, 1000000, 10000000)
>>> cat(" n  \t  t(forloop) : ratio \t  t(sum) : ratio \t t(crossprod) \t all.equal \n")
>>> for (nn in ll ){
>>>    set.seed(1234)
>>>    vv <- runif(nn)
>>>    tsuml<-microbenchmark(sl<-suml(vv), unit="us")
>>>    tsums<-microbenchmark(ss<-sums(vv), unit="us")
>>>    tsumc<-microbenchmark(sc<-sumc(vv), unit="us")
>>>    ml<-mean(tsuml$time)
>>>    ms<-mean(tsums$time)
>>>    mc<-mean(tsumc$time)
>>>    cat(nn,"\t",ml," : ",ml/mc,"\t",ms," : ",ms/mc,"\t",mc,"\t",all.equal(sl, ss, sc),"\n")
>>> }
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From ggrothend|eck @end|ng |rom gm@||@com  Wed Jan 26 15:48:21 2022
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Wed, 26 Jan 2022 09:48:21 -0500
Subject: [Rd] aggregate.formula and pipes
Message-ID: <CAP01uRnONpc=WnQATrcdU0xLv_Ce=RJ-TTyCfKBN+pnV0NMYbw@mail.gmail.com>

Because aggregate.formula has a formula argument but the generic
has an x argument neither of these work:

  mtcars |> aggregate(x = mpg ~ cyl, FUN = mean)
  mtcars |> aggregate(formula = mpg ~ cyl, FUN = mean)

This does work:

  mtcars |> stats:::aggregate.formula(formula = mpg ~ cyl, FUN = mean)

Suggest that aggregate.formula be exported.

--
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Jan 30 12:50:19 2022
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 30 Jan 2022 06:50:19 -0500
Subject: [Rd] Bug in rbind.data.frame?
Message-ID: <6244c3b8-0750-c675-9353-92fc78cfd02f@gmail.com>

I was surprised to see this result:

# This works:  Create a dataframe and add a row:
df <- data.frame(a = 1, b = 2)
rbind(df, c(3, 4))
#>   a b
#> 1 1 2
#> 2 3 4

# It doesn't work if the original dataframe is empty
df <- data.frame(a = numeric(), b = numeric())
rbind(df, c(1, 2))
#>   X1 X2
#> 1  1  2
# The column names changed!

# It doesn't matter if the new row is named:
rbind(df, c(a = 1, b = 2))
#>   X1 X2
#> 1  1  2

I tried this in a very old R version, and saw the same result, so it's 
not a new bug:  but is it maybe intentional, and if so, what is the 
reason for it?

Duncan Murdoch


From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Jan 30 13:00:39 2022
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 30 Jan 2022 07:00:39 -0500
Subject: [Rd] Bug in rbind.data.frame?
In-Reply-To: <6244c3b8-0750-c675-9353-92fc78cfd02f@gmail.com>
References: <6244c3b8-0750-c675-9353-92fc78cfd02f@gmail.com>
Message-ID: <90da4fd6-2e80-1b7b-4e36-5895138fa42b@gmail.com>

Okay, I spotted it.  This is intentional.  From ?rbind.data.frame:

"The rbind data frame method first drops all zero-column and zero-row 
arguments."

So I wouldn't expect to keep the names in the argument that was dropped.

However, there's still an issue in the case where the row is named.  To 
me it implies that when df is empty, rbind(df, c(a=1, b=2)) should be 
the same as rbind(c(a=1, b=2)), which gives a properly named result.  Of 
course, rbind(c(a=1, b=2)) won't call rbind.data.frame() at all, so that 
explains the difference, but not the intention.

Duncan Murdoch

On 30/01/2022 6:50 a.m., Duncan Murdoch wrote:
> I was surprised to see this result:
> 
> # This works:  Create a dataframe and add a row:
> df <- data.frame(a = 1, b = 2)
> rbind(df, c(3, 4))
> #>   a b
> #> 1 1 2
> #> 2 3 4
> 
> # It doesn't work if the original dataframe is empty
> df <- data.frame(a = numeric(), b = numeric())
> rbind(df, c(1, 2))
> #>   X1 X2
> #> 1  1  2
> # The column names changed!
> 
> # It doesn't matter if the new row is named:
> rbind(df, c(a = 1, b = 2))
> #>   X1 X2
> #> 1  1  2
> 
> I tried this in a very old R version, and saw the same result, so it's
> not a new bug:  but is it maybe intentional, and if so, what is the
> reason for it?
> 
> Duncan Murdoch


From p@tr|ck@g|r@udoux @end|ng |rom un|v-|comte@|r  Sun Jan 30 18:52:51 2022
From: p@tr|ck@g|r@udoux @end|ng |rom un|v-|comte@|r (Patrick Giraudoux)
Date: Sun, 30 Jan 2022 18:52:51 +0100
Subject: [Rd] =?utf-8?q?trouble_with_package_loading=3A_Function_found_wh?=
 =?utf-8?q?en_exporting_methods_from_the_namespace_=E2=80=98raster?=
 =?utf-8?b?4oCZIHdoaWNoIGlzIG5vdCBTNCBnZW5lcmljOiDigJhhbGwuZXF1YWzigJk=?=
Message-ID: <ba62c6ce-71f5-c43a-2746-d02f1d4c2256@univ-fcomte.fr>

Dear listers,

After having exchanged on the R-package-devel at r-project.org list, I feel 
that the question should now be adressed on the R developper list.

You'll find below the trouble I met, and one of the answers that Zhian 
Kamvar has been kind enough to provide.

Il looks like the origin might be found in the way R deploys methods and 
namespace is managed, which is by far out my skills...

Suspect some bug somewhere (?)

Best,

Patrick

------------------------------------------------------------------------

THE PROBLEM

One user (in cc) has signaled a problem installing the package pgirmess 
(version 1.7.1 on CRAN), with this message on loading:

> library(pgirmess)

Error: package or namespace load failed for ?pgirmess?:

Function found when exporting methods from the namespace ?raster? which 
is not S4 generic: ?all.equal?

In addition: Warning message:

no function found corresponding to methods exports from ?raster? for: 
?direction?, ?gridDistance?

I cannot identify where the trouble comes from since:

- pgirmess goes through OK in all the checks on CRAN

- I can install/remove it with correct loading on my own platform 
(Windows 10)

- pgirmess 1.7.1 does not import 'raster' and the functions mentioned above

The user has installed the last R version on Windows.? However, she gets 
a correct loading only if she loads 'Matrix' before (or 'lme4' - but to 
my knowlege, lme4 actually loads Matrix).

She meets also the same issue with pgirmess 2.0 (not on CRAN yet, see 
https://github.com/pgiraudoux/pgirmess however this version (still on 
test) has deprecated/dropped all functions related to dealing with rasters.

This occurs in R directly (not necessarily within RStudio).

On the web, Iook likes this issue has is already been spotted for some 
other packages (e.g. mapview, tmap, etc.). Checking help-lists I saw 
that installing rtools might solve the problem (e.g. 
https://community.rstudio.com/t/error-package-or-namespace-load-failed-for-mapview/126914) 
however, it seems to me a strange workaround since rtools should not be 
made necessary for lay R user (not developers).

Best,

------------------------------------------------------------------------

ZHIAN's ANSWER

Le 28/01/2022 ? 17:35, Zhian Kamvar wrote :
I've run into deep dependencies registering methods that mess things up 
before: https://github.com/thibautjombart/adegenet/issues/308.
AFAICT, it has something to do with the way R deploys methods where they 
can be available if the namespace is available. In this case, it's via 
spdep -> spData -> raster. That being said, I am NOT an expert on this 
and would?like to know more if anyone has better insight.


	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Jan 30 19:09:52 2022
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 30 Jan 2022 13:09:52 -0500
Subject: [Rd] 
 =?utf-8?q?trouble_with_package_loading=3A_Function_found_wh?=
 =?utf-8?q?en_exporting_methods_from_the_namespace_=E2=80=98raster?=
 =?utf-8?b?4oCZIHdoaWNoIGlzIG5vdCBTNCBnZW5lcmljOiDigJhhbGwuZXF1YWzigJk=?=
In-Reply-To: <ba62c6ce-71f5-c43a-2746-d02f1d4c2256@univ-fcomte.fr>
References: <ba62c6ce-71f5-c43a-2746-d02f1d4c2256@univ-fcomte.fr>
Message-ID: <30f6ea02-5405-8981-cc3c-65773d7ac866@gmail.com>

Can you reproduce the problem?  If so, please post the recipe for doing 
so here, e.g. "install x from Github, y from CRAN, ..."  If not, it's 
unlikely anyone will be able to help.

If you don't know how to do it, I'd contact the original reporter, and 
at least ask the original reporter for sessionInfo() just before and 
after the error occurs.

Duncan Murdoch



On 30/01/2022 12:52 p.m., Patrick Giraudoux wrote:
> Dear listers,
> 
> After having exchanged on the R-package-devel at r-project.org list, I feel
> that the question should now be adressed on the R developper list.
> 
> You'll find below the trouble I met, and one of the answers that Zhian
> Kamvar has been kind enough to provide.
> 
> Il looks like the origin might be found in the way R deploys methods and
> namespace is managed, which is by far out my skills...
> 
> Suspect some bug somewhere (?)
> 
> Best,
> 
> Patrick
> 
> ------------------------------------------------------------------------
> 
> THE PROBLEM
> 
> One user (in cc) has signaled a problem installing the package pgirmess
> (version 1.7.1 on CRAN), with this message on loading:
> 
>> library(pgirmess)
> 
> Error: package or namespace load failed for ?pgirmess?:
> 
> Function found when exporting methods from the namespace ?raster? which
> is not S4 generic: ?all.equal?
> 
> In addition: Warning message:
> 
> no function found corresponding to methods exports from ?raster? for:
> ?direction?, ?gridDistance?
> 
> I cannot identify where the trouble comes from since:
> 
> - pgirmess goes through OK in all the checks on CRAN
> 
> - I can install/remove it with correct loading on my own platform
> (Windows 10)
> 
> - pgirmess 1.7.1 does not import 'raster' and the functions mentioned above
> 
> The user has installed the last R version on Windows.? However, she gets
> a correct loading only if she loads 'Matrix' before (or 'lme4' - but to
> my knowlege, lme4 actually loads Matrix).
> 
> She meets also the same issue with pgirmess 2.0 (not on CRAN yet, see
> https://github.com/pgiraudoux/pgirmess however this version (still on
> test) has deprecated/dropped all functions related to dealing with rasters.
> 
> This occurs in R directly (not necessarily within RStudio).
> 
> On the web, Iook likes this issue has is already been spotted for some
> other packages (e.g. mapview, tmap, etc.). Checking help-lists I saw
> that installing rtools might solve the problem (e.g.
> https://community.rstudio.com/t/error-package-or-namespace-load-failed-for-mapview/126914)
> however, it seems to me a strange workaround since rtools should not be
> made necessary for lay R user (not developers).
> 
> Best,
> 
> ------------------------------------------------------------------------
> 
> ZHIAN's ANSWER
> 
> Le 28/01/2022 ? 17:35, Zhian Kamvar wrote :
> I've run into deep dependencies registering methods that mess things up
> before: https://github.com/thibautjombart/adegenet/issues/308.
> AFAICT, it has something to do with the way R deploys methods where they
> can be available if the namespace is available. In this case, it's via
> spdep -> spData -> raster. That being said, I am NOT an expert on this
> and would?like to know more if anyone has better insight.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From p@tr|ck@g|r@udoux @end|ng |rom un|v-|comte@|r  Sun Jan 30 19:21:08 2022
From: p@tr|ck@g|r@udoux @end|ng |rom un|v-|comte@|r (Patrick Giraudoux)
Date: Sun, 30 Jan 2022 19:21:08 +0100
Subject: [Rd] 
 =?utf-8?q?trouble_with_package_loading=3A_Function_found_wh?=
 =?utf-8?q?en_exporting_methods_from_the_namespace_=E2=80=98raster?=
 =?utf-8?b?4oCZIHdoaWNoIGlzIG5vdCBTNCBnZW5lcmljOiDigJhhbGwuZXF1YWzigJk=?=
In-Reply-To: <30f6ea02-5405-8981-cc3c-65773d7ac866@gmail.com>
References: <ba62c6ce-71f5-c43a-2746-d02f1d4c2256@univ-fcomte.fr>
 <30f6ea02-5405-8981-cc3c-65773d7ac866@gmail.com>
Message-ID: <307d5902-69d9-d929-52fe-ce36ee780a12@univ-fcomte.fr>

Le 30/01/2022 ? 19:09, Duncan Murdoch a ?crit?:
> Can you reproduce the problem?? If so, please post the recipe for 
> doing so here, e.g. "install x from Github, y from CRAN, ..."? If not, 
> it's unlikely anyone will be able to help.
>
> If you don't know how to do it, I'd contact the original reporter, and 
> at least ask the original reporter for sessionInfo() just before and 
> after the error occurs.
>
> Duncan Murdoch


OK. Will do my best however the problem has been reported to me by a 
'lay' user (I do not met it however I tried installing/desinstalling to 
get a reproducible error etc). I will ask her to follow your 
instructions (she is in cc) and help her if I can. She repeatly met her 
on three different computer in her office and home, all Windows. However 
Googling a bit one can see that this problem is not met for the first 
time with other packages

- https://github.com/r-tmap/tmap/issues/621

- 
https://community.rstudio.com/t/error-package-or-namespace-load-failed-for-mapview/126914

I also put Zhian Kamvar in cc, in the case he can report on his own case

Thanks for your concern (and congrats/thanks for all the work done by 
the R core team including yourself).

Patrick


	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Jan 30 19:57:27 2022
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 30 Jan 2022 13:57:27 -0500
Subject: [Rd] 
 =?utf-8?q?trouble_with_package_loading=3A_Function_found_wh?=
 =?utf-8?q?en_exporting_methods_from_the_namespace_=E2=80=98raster?=
 =?utf-8?b?4oCZIHdoaWNoIGlzIG5vdCBTNCBnZW5lcmljOiDigJhhbGwuZXF1YWzigJk=?=
In-Reply-To: <307d5902-69d9-d929-52fe-ce36ee780a12@univ-fcomte.fr>
References: <ba62c6ce-71f5-c43a-2746-d02f1d4c2256@univ-fcomte.fr>
 <30f6ea02-5405-8981-cc3c-65773d7ac866@gmail.com>
 <307d5902-69d9-d929-52fe-ce36ee780a12@univ-fcomte.fr>
Message-ID: <e8d1998b-507a-b1f5-2849-393b33bc1159@gmail.com>

On 30/01/2022 1:21 p.m., Patrick Giraudoux wrote:
> Le 30/01/2022 ? 19:09, Duncan Murdoch a ?crit?:
>> Can you reproduce the problem?? If so, please post the recipe for 
>> doing so here, e.g. "install x from Github, y from CRAN, ..."? If not, 
>> it's unlikely anyone will be able to help.
>>
>> If you don't know how to do it, I'd contact the original reporter, and 
>> at least ask the original reporter for sessionInfo() just before and 
>> after the error occurs.
>>
>> Duncan Murdoch
> 
> 
> OK. Will do my best however the problem has been reported to me by a 
> 'lay' user (I do not met it however I tried installing/desinstalling to 
> get a reproducible error etc). I will ask her to follow your 
> instructions (she is in cc) and help her if I can. She repeatly met her 
> on three different computer in her office and home, all Windows. However 
> Googling a bit one can see that this problem is not met for the first 
> time with other packages
> 
> - https://github.com/r-tmap/tmap/issues/621
> 
> - 
> https://community.rstudio.com/t/error-package-or-namespace-load-failed-for-mapview/126914
> 
> I also put Zhian Kamvar in cc, in the case he can report on his own case
> 
> Thanks for your concern (and congrats/thanks for all the work done by 
> the R core team including yourself).

Neither of those links posted useful information.  They show that it 
isn't something specific to Julie's system, but don't really give a hint 
about where to look to fix it.  My guess would be some version 
dependence between two packages that isn't being declared.  That is, 
package A declares that it depends on package B, but in fact it needs a 
particular version of B, so people who happen to have the wrong version 
installed get the error.

A complication that is Windows-specific is that it is so easy on that 
system to have two versions of packages installed:  one in the system 
library, one in the user library.  (It's possible on all systems, it 
just seems to happen more on Windows.)

Duncan Murdoch


From Kurt@Horn|k @end|ng |rom wu@@c@@t  Mon Jan 31 09:29:22 2022
From: Kurt@Horn|k @end|ng |rom wu@@c@@t (Kurt Hornik)
Date: Mon, 31 Jan 2022 09:29:22 +0100
Subject: [Rd] Bug in rbind.data.frame?
In-Reply-To: <90da4fd6-2e80-1b7b-4e36-5895138fa42b@gmail.com>
References: <6244c3b8-0750-c675-9353-92fc78cfd02f@gmail.com>
 <90da4fd6-2e80-1b7b-4e36-5895138fa42b@gmail.com>
Message-ID: <25079.40418.973003.506232@hornik.net>

>>>>> Duncan Murdoch writes:

> Okay, I spotted it.  This is intentional.  From ?rbind.data.frame:
> "The rbind data frame method first drops all zero-column and zero-row 
> arguments."

Hmm.  "As document", but still surprising too me as well ...

We also say

     For ?rbind? column names are taken from the first argument with
     appropriate names: colnames for a matrix, or names for a vector of
     length the number of columns of the result.

Of course, one could argue that "The rbind data frame method first drops
all zero-column and zero-row arguments." implies that "first argument
..." should be taken after dropping, but then

R> m <- matrix(0, 0, 2, dimnames = list(NULL, c("a", "b")))
R> rbind(m, c(3, 4))
     a b
[1,] 3 4

which is not consistent with the data frame case.

Btw, whereas

R> rbind(c(1, 2),
      c(3, 4, 5))
Warning in rbind(c(1, 2), c(3, 4, 5)) :
  number of columns of result is not a multiple of vector length (arg 1)
     [,1] [,2] [,3]
[1,]    1    2    1
[2,]    3    4    5

"as documented", 

R> df <- data.frame(a = 1, b = 2)
rbind(df, c(3, 4, 5))
  a b
1 1 2
2 3 4

with is a bit worrying (and not as documented)?

Best
-k

> So I wouldn't expect to keep the names in the argument that was dropped.

> However, there's still an issue in the case where the row is named.  To 
> me it implies that when df is empty, rbind(df, c(a=1, b=2)) should be 
> the same as rbind(c(a=1, b=2)), which gives a properly named result.  Of 
> course, rbind(c(a=1, b=2)) won't call rbind.data.frame() at all, so that 
> explains the difference, but not the intention.

> Duncan Murdoch

> On 30/01/2022 6:50 a.m., Duncan Murdoch wrote:
>> I was surprised to see this result:
>> 
>> # This works:  Create a dataframe and add a row:
>> df <- data.frame(a = 1, b = 2)
>> rbind(df, c(3, 4))
>> #>   a b
>> #> 1 1 2
>> #> 2 3 4
>> 
>> # It doesn't work if the original dataframe is empty
>> df <- data.frame(a = numeric(), b = numeric())
>> rbind(df, c(1, 2))
>> #>   X1 X2
>> #> 1  1  2
>> # The column names changed!
>> 
>> # It doesn't matter if the new row is named:
>> rbind(df, c(a = 1, b = 2))
>> #>   X1 X2
>> #> 1  1  2
>> 
>> I tried this in a very old R version, and saw the same result, so it's
>> not a new bug:  but is it maybe intentional, and if so, what is the
>> reason for it?
>> 
>> Duncan Murdoch

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From @ndre@@@b|@ette @end|ng |rom un|-due@de  Mon Jan 31 10:56:27 2022
From: @ndre@@@b|@ette @end|ng |rom un|-due@de (=?utf-8?B?QmzDpHR0ZSwgQW5kcmVhcw==?=)
Date: Mon, 31 Jan 2022 09:56:27 +0000
Subject: [Rd] localeToCharset()
Message-ID: <68F1ECBC-E65A-443B-928B-94889F183D03@uni-due.de>

Dear all,

packages for processing text may need information on the charset of the R session. In my packages RcppCWB and polmineR, I extract this information from the locale using `localeToCharset()`. But when running cross-platform checks (Github Actions and Docker), I recurringly encounter unexpected behavior of `localeToCharset()`.

As a a reproducible example, I suggest to use a local Fedora (latest) container, starting as follows:

docker pull fedora:latest
docker run -it fedora:latest /bin/bash

After installing R (`yum install -y R`) and starting R, `localeToCharset()` returns `NA`. However, the part of sessionInfo() on the locale is as follows:
 [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8
 [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8
 [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C
[10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C

If I run R CMD check on any arbitrary package in this environment at this stage, I see:
* using session charset: UTF-8

The documentation says however: ?In the C locale the answer will be "ASCII".?  Why not UTF-8 in this case?

The `localeToCharset()` function is also confusing for me, when I explicitly re-define the locale. In my fresh Fedora docker container, I need to install English-language locales first:
dnf install langpacks-en

After starting R with a re-defined locale (`env LC_CTYPE=en_US.UTF-8 R`,  the output of `localeToCharset()` is:
[1] "UTF-8"     "ISO8859-1"

The ?Value? section of the documentation says: ?A character vector naming an encoding and possibly a fallback single-encoding, NA if unknown.?  But I do not understand why ISO8859-1 might be a fallback option here?

I do not know whether this is just a matter of documentation? My intuition is that `localeToCharset()` should work differently. At the moment, I need to rely on a few workarounds to cope with the behavior I do not understand.  (Or is there a better function to detect the encoding of the R session?)

Part of my analysis of the code of `localeToCharset()` is that it targets special scenarios on Windows and macOS, but not on Linux.

Kind regards
Andreas

--
Prof. Dr. Andreas Blaette
Professor of Public Policy and Regional Politics
University of Duisburg-Essen



	[[alternative HTML version deleted]]


From jr@| @end|ng |rom po@teo@no  Mon Jan 31 11:35:06 2022
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Mon, 31 Jan 2022 10:35:06 +0000
Subject: [Rd] localeToCharset()
In-Reply-To: <68F1ECBC-E65A-443B-928B-94889F183D03@uni-due.de>
References: <68F1ECBC-E65A-443B-928B-94889F183D03@uni-due.de>
Message-ID: <Yfe7WizKVWtGC9yc@posteo.no>

Dear Andreas,

I think your R session is able to use 
correct unicode from your Fedora docker 
container, because I get the same output 
from `localeToCharset()` on my similarly 
configured ArchLinux system.

I found some notes on setting locale in 
Fedora [1]

On ArchLinux, I set my locale globally 
in /etc/locale.conf, since a long time 
ago

	LANG=en_GB.UTF-8
	LC_CTYPE="en_GB.UTF-8"
	LC_NUMERIC="en_GB.UTF-8"
	LC_TIME="en_DK.UTF-8"
	LC_COLLATE="en_GB.UTF-8"
	LC_MONETARY="nb_NO.UTF-8"
	LC_PAPER="nb_NO.UTF-8"
	LC_NAME="nb_NO.UTF-8"
	LC_ADDRESS="nb_NO.UTF-8"
	LC_TELEPHONE="nb_NO.UTF-8"
	LC_MEASUREMENT="nb_NO.UTF-8"
	LC_INDENTIFICATION="nb_NO.UTF-8"

On FreeBSD, it is customary to set the 
locale locally in your ~/.login_conf

	me:\
		:charset=UTF-8:\
		:lang=en_GB.UTF-8:\
		:setenv=LC_COLLATE=C:

OpenBSD has UTF-8 enabled for everything 
all of the time (I'm thinking), coming 
from a state not long ago where it was 
largely unavailable ...

Best,
Rasmus

[1] https://docs.fedoraproject.org/en-US/Fedora/26/html/System_Administrators_Guide/ch-System_Locale_and_Keyboard_Configuration.html


From kry|ov@r00t @end|ng |rom gm@||@com  Mon Jan 31 12:32:01 2022
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Mon, 31 Jan 2022 14:32:01 +0300
Subject: [Rd] localeToCharset()
In-Reply-To: <68F1ECBC-E65A-443B-928B-94889F183D03@uni-due.de>
References: <68F1ECBC-E65A-443B-928B-94889F183D03@uni-due.de>
Message-ID: <20220131143201.10e183dc@Tarkus>

On Mon, 31 Jan 2022 09:56:27 +0000
"Bl?tte, Andreas" <andreas.blaette at uni-due.de> wrote:

> After starting R with a re-defined locale (`env LC_CTYPE=en_US.UTF-8
> R`,  the output of `localeToCharset()` is:
> [1] "UTF-8"     "ISO8859-1"

> why ISO8859-1 might be a fallback option here?

ISO8859-1 seems to be offered because it covers the alphabet of
American English. Obviously, this doesn't guarantee that the guess is
correct. For example, I could symlink the ru_RU.KOI8-R locale on my
system to name it "ru_RU", and localeToCharset() would return
"ISO8859-5", not knowing the correct answer. ??????, anyone?

> Part of my analysis of the code of `localeToCharset()` is that it
> targets special scenarios on Windows and macOS, but not on Linux.

Well, it almost does the right thing. GNU/Linux locales are typically
named like <language>_<country>.<encoding>, and localeToCharset()
respects the <encoding> part, but only if the language and the country
are specified. A quick fix for that would be to add one final case:

Index: src/library/utils/R/iconv.R
===================================================================
--- src/library/utils/R/iconv.R (revision 81596)
+++ src/library/utils/R/iconv.R (working copy)
@@ -135,6 +135,7 @@
             if(enc == "utf8") return(c("UTF-8", guess(ll)))
             else return(guess(ll))
         }
+        if (enc == "utf8") return("UTF-8") # fallback for ???.UTF-8
         return(NA_character_)
     }
 }

(Non-UTF-8 encodings on POSIX are handled above, in the if(nzchar(enc)
&& enc != "utf8") branch.)

Maybe a better fix would be to restructure the code a bit, to always
take the encoding hint and then also try to guess if the locale looks
like it provides a language code.

-- 
Best regards,
Ivan


From @ndre@@@b|@ette @end|ng |rom un|-due@de  Mon Jan 31 12:38:45 2022
From: @ndre@@@b|@ette @end|ng |rom un|-due@de (=?utf-8?B?QmzDpHR0ZSwgQW5kcmVhcw==?=)
Date: Mon, 31 Jan 2022 11:38:45 +0000
Subject: [Rd] localeToCharset()
In-Reply-To: <20220131143201.10e183dc@Tarkus>
References: <68F1ECBC-E65A-443B-928B-94889F183D03@uni-due.de>
 <20220131143201.10e183dc@Tarkus>
Message-ID: <E5C802F0-1943-4CF4-AE64-9545207B285C@uni-due.de>

Dear Ivan,

this is a very helpful explanation!  I think it is important to make output of localeToCharset() more predictable. My problem is essentially not to set the locale such that things will work after all. I think the problem is that you see unexpected results.  I guess I owe a suggestion how to improve the code, but your suggestion looks like a very good starting point. 

Andreas 

?Am 31.01.22, 12:32 schrieb "Ivan Krylov" <krylov.r00t at gmail.com>:

    On Mon, 31 Jan 2022 09:56:27 +0000
    "Bl?tte, Andreas" <andreas.blaette at uni-due.de> wrote:

    > After starting R with a re-defined locale (`env LC_CTYPE=en_US.UTF-8
    > R`,  the output of `localeToCharset()` is:
    > [1] "UTF-8"     "ISO8859-1"

    > why ISO8859-1 might be a fallback option here?

    ISO8859-1 seems to be offered because it covers the alphabet of
    American English. Obviously, this doesn't guarantee that the guess is
    correct. For example, I could symlink the ru_RU.KOI8-R locale on my
    system to name it "ru_RU", and localeToCharset() would return
    "ISO8859-5", not knowing the correct answer. ??????, anyone?

    > Part of my analysis of the code of `localeToCharset()` is that it
    > targets special scenarios on Windows and macOS, but not on Linux.

    Well, it almost does the right thing. GNU/Linux locales are typically
    named like <language>_<country>.<encoding>, and localeToCharset()
    respects the <encoding> part, but only if the language and the country
    are specified. A quick fix for that would be to add one final case:

    Index: src/library/utils/R/iconv.R
    ===================================================================
    --- src/library/utils/R/iconv.R (revision 81596)
    +++ src/library/utils/R/iconv.R (working copy)
    @@ -135,6 +135,7 @@
                 if(enc == "utf8") return(c("UTF-8", guess(ll)))
                 else return(guess(ll))
             }
    +        if (enc == "utf8") return("UTF-8") # fallback for ???.UTF-8
             return(NA_character_)
         }
     }

    (Non-UTF-8 encodings on POSIX are handled above, in the if(nzchar(enc)
    && enc != "utf8") branch.)

    Maybe a better fix would be to restructure the code a bit, to always
    take the encoding hint and then also try to guess if the locale looks
    like it provides a language code.

    -- 
    Best regards,
    Ivan


From @|mon@urb@nek @end|ng |rom R-project@org  Mon Jan 31 13:16:03 2022
From: @|mon@urb@nek @end|ng |rom R-project@org (Simon Urbanek)
Date: Tue, 1 Feb 2022 01:16:03 +1300
Subject: [Rd] localeToCharset()
In-Reply-To: <E5C802F0-1943-4CF4-AE64-9545207B285C@uni-due.de>
References: <68F1ECBC-E65A-443B-928B-94889F183D03@uni-due.de>
 <20220131143201.10e183dc@Tarkus>
 <E5C802F0-1943-4CF4-AE64-9545207B285C@uni-due.de>
Message-ID: <44E23467-FA5E-4722-A988-A9EAD32C1D12@R-project.org>

Andreas,

The output is very predictable, so this is not about predictability. Note that C.UTF-8 is technically an invalid locale by the semantics rules (see below). Also note that the C locale is "C" - it is not allowed to have any string behind the C (or else is not the C locale) so what you have is NOT a C locale (see POSIX 7.2).

The issue here is that the POSIX standard provides no semantic rules, locale names can be arbitrary, the only defined one is C (and its synonym POSIX). All others are random locales that can do whatever they want. Then later some systems have introduced semantic guidelines such as the <language>_<territory>.<codeset> convention - that that is what localeToCharsets() expected so it can try to guess the charset for that language. Since C.UTF-8 is such an aberration (not in the standard form) localeToCharset() doesn't know about it and returns NA since it can't guess the language.

Long story short, C.UTF-8 breaks all common rules and has been introduced fairly recently to some Linux systems so R doesn't not know about it yet. Ivan's patch fixes that. That aside, locale names have no official provision to provide the charset, so all you get is a guess assuming the system follows the common rules.

Cheers,
Simon



> On Feb 1, 2022, at 00:38, Bl?tte, Andreas <andreas.blaette at uni-due.de> wrote:
> 
> Dear Ivan,
> 
> this is a very helpful explanation!  I think it is important to make output of localeToCharset() more predictable. My problem is essentially not to set the locale such that things will work after all. I think the problem is that you see unexpected results.  I guess I owe a suggestion how to improve the code, but your suggestion looks like a very good starting point. 
> 
> Andreas 
> 
> ?Am 31.01.22, 12:32 schrieb "Ivan Krylov" <krylov.r00t at gmail.com>:
> 
>    On Mon, 31 Jan 2022 09:56:27 +0000
>    "Bl?tte, Andreas" <andreas.blaette at uni-due.de> wrote:
> 
>> After starting R with a re-defined locale (`env LC_CTYPE=en_US.UTF-8
>> R`,  the output of `localeToCharset()` is:
>> [1] "UTF-8"     "ISO8859-1"
> 
>> why ISO8859-1 might be a fallback option here?
> 
>    ISO8859-1 seems to be offered because it covers the alphabet of
>    American English. Obviously, this doesn't guarantee that the guess is
>    correct. For example, I could symlink the ru_RU.KOI8-R locale on my
>    system to name it "ru_RU", and localeToCharset() would return
>    "ISO8859-5", not knowing the correct answer. ??????, anyone?
> 
>> Part of my analysis of the code of `localeToCharset()` is that it
>> targets special scenarios on Windows and macOS, but not on Linux.
> 
>    Well, it almost does the right thing. GNU/Linux locales are typically
>    named like <language>_<country>.<encoding>, and localeToCharset()
>    respects the <encoding> part, but only if the language and the country
>    are specified. A quick fix for that would be to add one final case:
> 
>    Index: src/library/utils/R/iconv.R
>    ===================================================================
>    --- src/library/utils/R/iconv.R (revision 81596)
>    +++ src/library/utils/R/iconv.R (working copy)
>    @@ -135,6 +135,7 @@
>                 if(enc == "utf8") return(c("UTF-8", guess(ll)))
>                 else return(guess(ll))
>             }
>    +        if (enc == "utf8") return("UTF-8") # fallback for ???.UTF-8
>             return(NA_character_)
>         }
>     }
> 
>    (Non-UTF-8 encodings on POSIX are handled above, in the if(nzchar(enc)
>    && enc != "utf8") branch.)
> 
>    Maybe a better fix would be to restructure the code a bit, to always
>    take the encoding hint and then also try to guess if the locale looks
>    like it provides a language code.
> 
>    -- 
>    Best regards,
>    Ivan
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From tom@@@k@||ber@ @end|ng |rom gm@||@com  Mon Jan 31 13:32:23 2022
From: tom@@@k@||ber@ @end|ng |rom gm@||@com (Tomas Kalibera)
Date: Mon, 31 Jan 2022 13:32:23 +0100
Subject: [Rd] localeToCharset()
In-Reply-To: <E5C802F0-1943-4CF4-AE64-9545207B285C@uni-due.de>
References: <68F1ECBC-E65A-443B-928B-94889F183D03@uni-due.de>
 <20220131143201.10e183dc@Tarkus>
 <E5C802F0-1943-4CF4-AE64-9545207B285C@uni-due.de>
Message-ID: <7d32a02d-e03f-11e6-0f92-9826bd4e96b6@gmail.com>

Hi Andreas,

is there still any higher-level problem left you need to solve? Ideally 
one wouldn't need to query what is the native encoding, but directly use 
iconv() or indirectly other R functions to convert the data from/to the 
native encoding. iconv() will find out internally what is the native 
encoding (via data that is available also by l10n_info(), but with care 
for differences between OSes).

Best
Tomas

On 1/31/22 12:38, Bl?tte, Andreas wrote:
> Dear Ivan,
>
> this is a very helpful explanation!  I think it is important to make output of localeToCharset() more predictable. My problem is essentially not to set the locale such that things will work after all. I think the problem is that you see unexpected results.  I guess I owe a suggestion how to improve the code, but your suggestion looks like a very good starting point.
>
> Andreas
>
> ?Am 31.01.22, 12:32 schrieb "Ivan Krylov" <krylov.r00t at gmail.com>:
>
>      On Mon, 31 Jan 2022 09:56:27 +0000
>      "Bl?tte, Andreas" <andreas.blaette at uni-due.de> wrote:
>
>      > After starting R with a re-defined locale (`env LC_CTYPE=en_US.UTF-8
>      > R`,  the output of `localeToCharset()` is:
>      > [1] "UTF-8"     "ISO8859-1"
>
>      > why ISO8859-1 might be a fallback option here?
>
>      ISO8859-1 seems to be offered because it covers the alphabet of
>      American English. Obviously, this doesn't guarantee that the guess is
>      correct. For example, I could symlink the ru_RU.KOI8-R locale on my
>      system to name it "ru_RU", and localeToCharset() would return
>      "ISO8859-5", not knowing the correct answer. ??????, anyone?
>
>      > Part of my analysis of the code of `localeToCharset()` is that it
>      > targets special scenarios on Windows and macOS, but not on Linux.
>
>      Well, it almost does the right thing. GNU/Linux locales are typically
>      named like <language>_<country>.<encoding>, and localeToCharset()
>      respects the <encoding> part, but only if the language and the country
>      are specified. A quick fix for that would be to add one final case:
>
>      Index: src/library/utils/R/iconv.R
>      ===================================================================
>      --- src/library/utils/R/iconv.R (revision 81596)
>      +++ src/library/utils/R/iconv.R (working copy)
>      @@ -135,6 +135,7 @@
>                   if(enc == "utf8") return(c("UTF-8", guess(ll)))
>                   else return(guess(ll))
>               }
>      +        if (enc == "utf8") return("UTF-8") # fallback for ???.UTF-8
>               return(NA_character_)
>           }
>       }
>
>      (Non-UTF-8 encodings on POSIX are handled above, in the if(nzchar(enc)
>      && enc != "utf8") branch.)
>
>      Maybe a better fix would be to restructure the code a bit, to always
>      take the encoding hint and then also try to guess if the locale looks
>      like it provides a language code.
>
>      --
>      Best regards,
>      Ivan
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From p@tr|ck@g|r@udoux @end|ng |rom un|v-|comte@|r  Mon Jan 31 13:53:12 2022
From: p@tr|ck@g|r@udoux @end|ng |rom un|v-|comte@|r (Patrick Giraudoux)
Date: Mon, 31 Jan 2022 13:53:12 +0100
Subject: [Rd] 
 =?utf-8?q?trouble_with_package_loading=3A_Function_found_wh?=
 =?utf-8?q?en_exporting_methods_from_the_namespace_=E2=80=98raster?=
 =?utf-8?b?4oCZIHdoaWNoIGlzIG5vdCBTNCBnZW5lcmljOiDigJhhbGwuZXF1YWzigJk=?=
In-Reply-To: <SV0P279MB04758AD91D4739D2BAA5F067EE259@SV0P279MB0475.NORP279.PROD.OUTLOOK.COM>
References: <SV0P279MB04758AD91D4739D2BAA5F067EE259@SV0P279MB0475.NORP279.PROD.OUTLOOK.COM>
Message-ID: <67417606-90c4-4107-ed5b-a1062fd2a158@univ-fcomte.fr>

This contribution below from Roger Bivand seems to answer the issue 
raised on this thread.

Actually it matches quite well Zhian and Duncan's suspicions, doesn'it ?

Best,

Patrick


-------- Message transf?r? --------
Sujet?: 	Follow-up on R-devel
Date?: 	Mon, 31 Jan 2022 12:23:57 +0000
De?: 	Roger Bivand <Roger.Bivand at nhh.no>
Pour?: 	Patrick Giraudoux <patrick.giraudoux at univ-fcomte.fr>



Dear Patrick,

Could you follow up on R-package-devel and R-devel that (from 
https://github.com/rspatial/terra/issues/514):
CRAN has not yet updated terra to 1.5-12 for R 4.1.2 (since two weeks it 
is still the previous version).

I will send a new version to CRAN this weekend, hopefully it will get 
build for windows. What happens is that raster is dependent on that 
version of terra (or later), so you should first do

install.packages('terra')

(once Windows terra_1.5-17.zip is published and on your mirror) and then

install.packages('raster')

Best wishes,

Roger
	[[alternative HTML version deleted]]


From @ndre@@@b|@ette @end|ng |rom un|-due@de  Mon Jan 31 14:08:11 2022
From: @ndre@@@b|@ette @end|ng |rom un|-due@de (=?utf-8?B?QmzDpHR0ZSwgQW5kcmVhcw==?=)
Date: Mon, 31 Jan 2022 13:08:11 +0000
Subject: [Rd] localeToCharset()
In-Reply-To: <7d32a02d-e03f-11e6-0f92-9826bd4e96b6@gmail.com>
References: <68F1ECBC-E65A-443B-928B-94889F183D03@uni-due.de>
 <20220131143201.10e183dc@Tarkus>
 <E5C802F0-1943-4CF4-AE64-9545207B285C@uni-due.de>
 <7d32a02d-e03f-11e6-0f92-9826bd4e96b6@gmail.com>
Message-ID: <143B435C-3E84-4B29-A06E-FDBFC487962C@uni-due.de>

Dear Tomas,

thanks a lot. I do understand the explanation of Simon - I was not aware of the standardization issue. My conclusion is that I should rely on another approach to detect the session charset, and your suggestions are my first option.

My final thought: For users who do not know the POSIX standards and recent aberrations , a warning might be helpful, something such as:
If (startsWith(locale, "C.")) warning (sprintf("%s is a non-standard locale", locale))

As far as I am concerned, I take away a lot from this discussion! Thank you!

Kind regards
Andreas 
 

?Am 31.01.22, 13:32 schrieb "Tomas Kalibera" <tomas.kalibera at gmail.com>:

    Hi Andreas,

    is there still any higher-level problem left you need to solve? Ideally 
    one wouldn't need to query what is the native encoding, but directly use 
    iconv() or indirectly other R functions to convert the data from/to the 
    native encoding. iconv() will find out internally what is the native 
    encoding (via data that is available also by l10n_info(), but with care 
    for differences between OSes).

    Best
    Tomas

    On 1/31/22 12:38, Bl?tte, Andreas wrote:
    > Dear Ivan,
    >
    > this is a very helpful explanation!  I think it is important to make output of localeToCharset() more predictable. My problem is essentially not to set the locale such that things will work after all. I think the problem is that you see unexpected results.  I guess I owe a suggestion how to improve the code, but your suggestion looks like a very good starting point.
    >
    > Andreas
    >
    > Am 31.01.22, 12:32 schrieb "Ivan Krylov" <krylov.r00t at gmail.com>:
    >
    >      On Mon, 31 Jan 2022 09:56:27 +0000
    >      "Bl?tte, Andreas" <andreas.blaette at uni-due.de> wrote:
    >
    >      > After starting R with a re-defined locale (`env LC_CTYPE=en_US.UTF-8
    >      > R`,  the output of `localeToCharset()` is:
    >      > [1] "UTF-8"     "ISO8859-1"
    >
    >      > why ISO8859-1 might be a fallback option here?
    >
    >      ISO8859-1 seems to be offered because it covers the alphabet of
    >      American English. Obviously, this doesn't guarantee that the guess is
    >      correct. For example, I could symlink the ru_RU.KOI8-R locale on my
    >      system to name it "ru_RU", and localeToCharset() would return
    >      "ISO8859-5", not knowing the correct answer. ??????, anyone?
    >
    >      > Part of my analysis of the code of `localeToCharset()` is that it
    >      > targets special scenarios on Windows and macOS, but not on Linux.
    >
    >      Well, it almost does the right thing. GNU/Linux locales are typically
    >      named like <language>_<country>.<encoding>, and localeToCharset()
    >      respects the <encoding> part, but only if the language and the country
    >      are specified. A quick fix for that would be to add one final case:
    >
    >      Index: src/library/utils/R/iconv.R
    >      ===================================================================
    >      --- src/library/utils/R/iconv.R (revision 81596)
    >      +++ src/library/utils/R/iconv.R (working copy)
    >      @@ -135,6 +135,7 @@
    >                   if(enc == "utf8") return(c("UTF-8", guess(ll)))
    >                   else return(guess(ll))
    >               }
    >      +        if (enc == "utf8") return("UTF-8") # fallback for ???.UTF-8
    >               return(NA_character_)
    >           }
    >       }
    >
    >      (Non-UTF-8 encodings on POSIX are handled above, in the if(nzchar(enc)
    >      && enc != "utf8") branch.)
    >
    >      Maybe a better fix would be to restructure the code a bit, to always
    >      take the encoding hint and then also try to guess if the locale looks
    >      like it provides a language code.
    >
    >      --
    >      Best regards,
    >      Ivan
    >
    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From g@bembecker @end|ng |rom gm@||@com  Mon Jan 31 21:11:10 2022
From: g@bembecker @end|ng |rom gm@||@com (Gabriel Becker)
Date: Mon, 31 Jan 2022 12:11:10 -0800
Subject: [Rd] inconsistency between as.list(df) and as.list(mat) with
 mode(mat) == "list"
Message-ID: <CAD4oTHFotrgFG6m4oL7EsxdFjf=_4b485kgLzVNifwLZgGiOOA@mail.gmail.com>

Hi All,

I ran into the following the other day:

> mat <- matrix(1:6, nrow = 2)

> as.list(mat)

[[1]]

[1] 1


*<snip>*


[[6]]

[1] 6


> mat2 <- mat

> mode(mat2) <- "list"

> as.list(mat2)

     [,1] [,2] [,3]

[1,] 1    3    5

[2,] 2    4    6

>


I realize this is not guaranteed by the documentation, and the behavior is
technically (if I would argue fairly subtly) as documented. Generally,
however, as.list returns something without dimensions (other than length),
regardless of the dimensions of the input.

Furthermore, this behavior agrees with neither the data.frame (which are
lists) method nor the non-list-mode matrix behavior which comes from the
default behavior. Both result in a non-dimensioned object (the data.frame
method explicitly and intentionally so).

Matrices of mode "list" are fairly rare, in practice, I would think, but I
wonder if the as.list behavior for them should agree with that of similar
dimensioned objects (data.frames and non-list-mode matrices). As a user, I
certainly expected it to, and had to read the docs with a careful eye
before I realized what was happening and why.

For the record, as.vector  does not drop dimension (or anything else) from
data.frames nor list-matrices, so there the behaviors agree, although we do
get:

> is.vector(mat)

[1] FALSE

> is.vector(mat2)

[1] FALSE

> is.vector(mtcars)

[1] FALSE


Which does make the fact that for the latter two as.vector returns the
objects unmodified somewhat puzzling.

I wonder if as.list and as.vector could get a strict argument - it could
default to FALSE for a deprecation period, or forever if preferred by
R-core -  where attributes are always stripped for 'strict' conversions.

Also, as a final aside, the documentation at ?as.list says:

 Attributes may be

     dropped unless the argument already is a list or expression.

     (This is inconsistent with functions such as ?as.character? which

     always drop attributes, *and is for efficiency since lists can be*

*     expensive to copy.*)


(emphasis mine). Is this still the case with shallow duplication? I was
under the impression that it was not.


Best,

~G

	[[alternative HTML version deleted]]


