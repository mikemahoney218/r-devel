From cgenolin at u-paris10.fr  Wed May  1 12:01:15 2013
From: cgenolin at u-paris10.fr (cgenolin)
Date: Wed, 1 May 2013 03:01:15 -0700 (PDT)
Subject: [Rd] Comments in the DESCRIPTION file
In-Reply-To: <509A2942.3050004@u-paris10.fr>
References: <509A2942.3050004@u-paris10.fr>
Message-ID: <1367402475396-4665892.post@n4.nabble.com>

Hi all,

Since R 3.0.0, the '#' does no longuer works for comments.
But as noticed above, comments can be introduce by 'anyWord:' or
'myComment;' or 'toto:'.

Since '#' can be used to name a field, we can also used '#:' or '###:' (or
even '%:' for LaTeX's fans).

So '#:' is a new possible way for adding comments in DESCRIPTION file.

Christophe



--
View this message in context: http://r.789695.n4.nabble.com/Comments-in-the-DESCRIPTION-file-tp4648678p4665892.html
Sent from the R devel mailing list archive at Nabble.com.


From simon.urbanek at r-project.org  Wed May  1 13:44:35 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 1 May 2013 07:44:35 -0400
Subject: [Rd] Comments in the DESCRIPTION file
In-Reply-To: <1367402475396-4665892.post@n4.nabble.com>
References: <509A2942.3050004@u-paris10.fr>
	<1367402475396-4665892.post@n4.nabble.com>
Message-ID: <C4C6B669-E9A6-4D2F-AC55-4968F3CBE764@r-project.org>


On May 1, 2013, at 6:01 AM, cgenolin wrote:

> Hi all,
> 
> Since R 3.0.0, the '#' does no longuer works for comments.
> But as noticed above, comments can be introduce by 'anyWord:' or
> 'myComment;' or 'toto:'.
> 
> Since '#' can be used to name a field, we can also used '#:' or '###:' (or
> even '%:' for LaTeX's fans).
> 
> So '#:' is a new possible way for adding comments in DESCRIPTION file.
> 

No, it's not, they are not permitted -- please read the DCF specs:

"Field names must not begin with the comment character, #."

Cheers,
Simon


> Christophe
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Comments-in-the-DESCRIPTION-file-tp4648678p4665892.html
> Sent from the R devel mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From h.wickham at gmail.com  Wed May  1 16:06:53 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Wed, 1 May 2013 10:06:53 -0400
Subject: [Rd] Windows, format.POSIXct and character encodings
Message-ID: <CABdHhvGT1hXm694y+yRSgD2JC_+KS3eUFGCycVVcjsneUGpAGA@mail.gmail.com>

Hi all,

In what encoding does format.POSIXct return its output? It doesn't
seem to be utf-8:

Sys.setlocale("LC_ALL", "Japanese_Japan.932")

times <- c("1970-01-01 01:00:00 UTC", "1970-02-02 22:00:00 UTC")
ampm <- format(as.POSIXct(times), format = "%p")
x <- gsub(">", "*", paste(ampm, collapse = "+>"))

y <- "??+*??"
identical(x, y)
# [1] TRUE

# But, confusingly, ...

charToRaw(x)
# [1] e5 8d 88 e5 89 8d 2b 2a e5 8d 88 e5 be 8c

charToRaw(y)
# [1] 8c df 91 4f 2b 2a 8c df 8c e3

# So there's at least a small bug with identical

# And this causes a problem when you attempt to do
# stuff with the string

gsub("+", "*", x, fixed = T)
# Error in gsub("+", "*", x, fixed = T) :
#  invalid multibyte string at '<8c>'
gsub("+", "*", y, fixed = T)
# [1] "??**??"


My session info is

R version 3.0.0 (2013-04-03)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=Japanese_Japan.932  LC_CTYPE=Japanese_Japan.932
[3] LC_MONETARY=Japanese_Japan.932 LC_NUMERIC=C
[5] LC_TIME=Japanese_Japan.932

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.0.0

Any ideas? Thanks!

Hadley

--
Chief Scientist, RStudio
http://had.co.nz/


From jmc at r-project.org  Wed May  1 17:43:50 2013
From: jmc at r-project.org (John Chambers)
Date: Wed, 01 May 2013 08:43:50 -0700
Subject: [Rd] trace with reference class
In-Reply-To: <CAC-jPZpk4NZrrTOReeHXOTZOFxD7sC=8iDAunWeoRTzqYwv8cg@mail.gmail.com>
References: <CAC-jPZpk4NZrrTOReeHXOTZOFxD7sC=8iDAunWeoRTzqYwv8cg@mail.gmail.com>
Message-ID: <51813836.9080604@r-project.org>

No intended change.  The trace method was not updated when reference 
class generators became functions.  Should be fixed now in r-devel and 
3.0.0 patched (rev 62699).

Thanks for the catch.

John

On 4/29/13 11:30 PM, Kohske Takahashi wrote:
> Hi
>
> The final line of the example in ?setRefClass induces an error:
>
>> ## debugging all objects from class mEdit in method $undo()
>> mEdit$trace(undo, browser)
> Error in envRefInferField(x, what, getClass(class(x)), selfEnv) :
>    'undo' is not a valid field or method name for reference class
> "refGeneratorSlot"
>
> $trace tries to embed the trace in the generator object (instead of
> the generated object).
> Has this functionality been removed?
>
> best,
>
> kohske
>
> --
> Kohske Takahashi <takahashi.kohske at gmail.com>
>
> Assistant Professor,
> Research Center for Advanced Science and Technology,
> The University of  Tokyo, Japan.
> http://www.fennel.rcast.u-tokyo.ac.jp/profilee_ktakahashi.html
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From pauljohn32 at gmail.com  Wed May  1 18:45:54 2013
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Wed, 1 May 2013 11:45:54 -0500
Subject: [Rd] Patch proposal for R style consistency (concerning
	deparse.c)
In-Reply-To: <5178D695.30009@fhcrc.org>
References: <CAErODj85saboM+8SaYKKVVDL6cPeX=LVR=PKwY+FZb2ky_cpBg@mail.gmail.com>
	<5478C197-76AB-481D-A1AA-64DB63D8D122@gmail.com>
	<CAErODj_N+FCjP1zt2H4VHv28o8RDU8sQ-W4qGONkx1gLvC33pg@mail.gmail.com>
	<CANROs4emmr=rGLKWpCQ6z_016mAk7O42=ttA1BLnc9zQ_DTzqQ@mail.gmail.com>
	<51787400.7010305@fhcrc.org> <51787C98.2030106@gmail.com>
	<5178D695.30009@fhcrc.org>
Message-ID: <CAErODj9nL5SOPCJ1R=NjueZAiG=WJo1V1KwPxbNGJpR1z1bJbg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130501/ee3f6a49/attachment.pl>

From tim.triche at gmail.com  Wed May  1 19:34:28 2013
From: tim.triche at gmail.com (Tim Triche, Jr.)
Date: Wed, 1 May 2013 10:34:28 -0700
Subject: [Rd] Patch proposal for R style consistency (concerning
	deparse.c)
In-Reply-To: <CAErODj9nL5SOPCJ1R=NjueZAiG=WJo1V1KwPxbNGJpR1z1bJbg@mail.gmail.com>
References: <CAErODj85saboM+8SaYKKVVDL6cPeX=LVR=PKwY+FZb2ky_cpBg@mail.gmail.com>
	<5478C197-76AB-481D-A1AA-64DB63D8D122@gmail.com>
	<CAErODj_N+FCjP1zt2H4VHv28o8RDU8sQ-W4qGONkx1gLvC33pg@mail.gmail.com>
	<CANROs4emmr=rGLKWpCQ6z_016mAk7O42=ttA1BLnc9zQ_DTzqQ@mail.gmail.com>
	<51787400.7010305@fhcrc.org> <51787C98.2030106@gmail.com>
	<5178D695.30009@fhcrc.org>
	<CAErODj9nL5SOPCJ1R=NjueZAiG=WJo1V1KwPxbNGJpR1z1bJbg@mail.gmail.com>
Message-ID: <CAC+N9BWCDacT_cCD3fGAb2EgB+oaQ0qGNq0fkOWsigzZtTJfaA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130501/db10b80d/attachment.pl>

From wdunlap at tibco.com  Wed May  1 20:08:21 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 1 May 2013 18:08:21 +0000
Subject: [Rd] objects with tsp attribute but no class
Message-ID: <E66794E69CFDE04D9A70842786030B931C2E31F6@PA-MBX01.na.tibco.com>

What is the intended difference between objects of class "ts",
which must have an attribute called "tsp", and objects with that
attribute but not that class?

Calling time series oriented functions like time() or window()
on vectors of numbers produce the classless objects with the
tsp attribute.  Should methods for atomic vectors check for
the tsp attribute and do special things for it?

I was wondering if it was just to be compatible with S or S+,
where in ancient (pre-class) times, the ".Tsp" attribute indicated
that you were dealing with a time series, just as the presence
of of a ".Dim" attribute meant the object was a matrix.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


From murdoch.duncan at gmail.com  Wed May  1 21:19:24 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 01 May 2013 15:19:24 -0400
Subject: [Rd] Patch proposal for R style consistency (concerning
	deparse.c)
In-Reply-To: <CAC+N9BWCDacT_cCD3fGAb2EgB+oaQ0qGNq0fkOWsigzZtTJfaA@mail.gmail.com>
References: <CAErODj85saboM+8SaYKKVVDL6cPeX=LVR=PKwY+FZb2ky_cpBg@mail.gmail.com>
	<5478C197-76AB-481D-A1AA-64DB63D8D122@gmail.com>
	<CAErODj_N+FCjP1zt2H4VHv28o8RDU8sQ-W4qGONkx1gLvC33pg@mail.gmail.com>
	<CANROs4emmr=rGLKWpCQ6z_016mAk7O42=ttA1BLnc9zQ_DTzqQ@mail.gmail.com>
	<51787400.7010305@fhcrc.org> <51787C98.2030106@gmail.com>
	<5178D695.30009@fhcrc.org>
	<CAErODj9nL5SOPCJ1R=NjueZAiG=WJo1V1KwPxbNGJpR1z1bJbg@mail.gmail.com>
	<CAC+N9BWCDacT_cCD3fGAb2EgB+oaQ0qGNq0fkOWsigzZtTJfaA@mail.gmail.com>
Message-ID: <51816ABC.1070407@gmail.com>

On 01/05/2013 1:34 PM, Tim Triche, Jr. wrote:
> +1 to having runnable code emitted

It does emit runnable code, which is why Herve's complaint was 
nonsense.  It doesn't emit code of which every substring is runnable.

Duncan Murdoch

>
> patch seems to work nicely, hopefully R-core will agree to apply it to HEAD
>
>
>
> On Wed, May 1, 2013 at 9:45 AM, Paul Johnson <pauljohn32 at gmail.com> wrote:
>
> > Whoa.
> >
> > Don't let my valuable suggestion get lost.
> >
> >  I want "} else {".  Yihue wants "} else {".  And I have not heard anybody
> > say they prefer the other way, unless you interpret Duncan's comment
> > "that's nonsense" as a blanket defense of the status quo. But I don't think
> > he meant that.  This is a matter of style consistency and avoidance of new
> > R-user confusion and error.
> >
> > After reading the help for "if", I don't see how anybody can argue against
> > this.  Good R code has this style:
> >
> > } else {
> >
> > and not
> >
> > }
> >  else
> >
> > because the latter fails if it is run line-by-line.  While trying to teach
> > people how to write R programs, it would be nice if the output of
> > print.function was consistent with the good way, the way that is actually
> > practiced in the R source code itself. This is a major source of new
> > programmer confusion. Its very tough to explain and teach.
> >
> > pj
> > --
> > Paul E. Johnson
> > Professor, Political Science      Assoc. Director
> > 1541 Lilac Lane, Room 504      Center for Research Methods
> > University of Kansas                 University of Kansas
> > http://pj.freefaculty.org               http://quant.ku.edu
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>
>


From jorismeys at gmail.com  Wed May  1 21:34:14 2013
From: jorismeys at gmail.com (Joris Meys)
Date: Wed, 1 May 2013 21:34:14 +0200
Subject: [Rd] Patch proposal for R style consistency (concerning
	deparse.c)
In-Reply-To: <51816ABC.1070407@gmail.com>
References: <CAErODj85saboM+8SaYKKVVDL6cPeX=LVR=PKwY+FZb2ky_cpBg@mail.gmail.com>
	<5478C197-76AB-481D-A1AA-64DB63D8D122@gmail.com>
	<CAErODj_N+FCjP1zt2H4VHv28o8RDU8sQ-W4qGONkx1gLvC33pg@mail.gmail.com>
	<CANROs4emmr=rGLKWpCQ6z_016mAk7O42=ttA1BLnc9zQ_DTzqQ@mail.gmail.com>
	<51787400.7010305@fhcrc.org> <51787C98.2030106@gmail.com>
	<5178D695.30009@fhcrc.org>
	<CAErODj9nL5SOPCJ1R=NjueZAiG=WJo1V1KwPxbNGJpR1z1bJbg@mail.gmail.com>
	<CAC+N9BWCDacT_cCD3fGAb2EgB+oaQ0qGNq0fkOWsigzZtTJfaA@mail.gmail.com>
	<51816ABC.1070407@gmail.com>
Message-ID: <CAO1zAVb=TJdRoJhUoYy=N4g+iw_qgHt59n5CH+AXqR-EU4ixNw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130501/a1c4f025/attachment.pl>

From tim.triche at gmail.com  Wed May  1 22:08:16 2013
From: tim.triche at gmail.com (Tim Triche, Jr.)
Date: Wed, 1 May 2013 13:08:16 -0700
Subject: [Rd] Patch proposal for R style consistency (concerning
	deparse.c)
In-Reply-To: <51816ABC.1070407@gmail.com>
References: <CAErODj85saboM+8SaYKKVVDL6cPeX=LVR=PKwY+FZb2ky_cpBg@mail.gmail.com>
	<5478C197-76AB-481D-A1AA-64DB63D8D122@gmail.com>
	<CAErODj_N+FCjP1zt2H4VHv28o8RDU8sQ-W4qGONkx1gLvC33pg@mail.gmail.com>
	<CANROs4emmr=rGLKWpCQ6z_016mAk7O42=ttA1BLnc9zQ_DTzqQ@mail.gmail.com>
	<51787400.7010305@fhcrc.org> <51787C98.2030106@gmail.com>
	<5178D695.30009@fhcrc.org>
	<CAErODj9nL5SOPCJ1R=NjueZAiG=WJo1V1KwPxbNGJpR1z1bJbg@mail.gmail.com>
	<CAC+N9BWCDacT_cCD3fGAb2EgB+oaQ0qGNq0fkOWsigzZtTJfaA@mail.gmail.com>
	<51816ABC.1070407@gmail.com>
Message-ID: <CAC+N9BW9GOq-XvzUJ3yWqz8hp=zgRskTt36PjPbHpCfnX-FbYA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130501/9f6cd7c4/attachment.pl>

From simon.urbanek at r-project.org  Wed May  1 23:33:09 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 1 May 2013 17:33:09 -0400
Subject: [Rd] Windows, format.POSIXct and character encodings
In-Reply-To: <CABdHhvGT1hXm694y+yRSgD2JC_+KS3eUFGCycVVcjsneUGpAGA@mail.gmail.com>
References: <CABdHhvGT1hXm694y+yRSgD2JC_+KS3eUFGCycVVcjsneUGpAGA@mail.gmail.com>
Message-ID: <77A76E74-6304-4236-8609-A5E08BC5B1A7@r-project.org>


On May 1, 2013, at 10:06 AM, Hadley Wickham wrote:

> Hi all,
> 
> In what encoding does format.POSIXct return its output? It doesn't
> seem to be utf-8:
> 
> Sys.setlocale("LC_ALL", "Japanese_Japan.932")
> 
> times <- c("1970-01-01 01:00:00 UTC", "1970-02-02 22:00:00 UTC")
> ampm <- format(as.POSIXct(times), format = "%p")
> x <- gsub(">", "*", paste(ampm, collapse = "+>"))
> 
> y <- "??+*??"
> identical(x, y)
> # [1] TRUE
> 
> # But, confusingly, ...
> 
> charToRaw(x)
> # [1] e5 8d 88 e5 89 8d 2b 2a e5 8d 88 e5 be 8c
> 
> charToRaw(y)
> # [1] 8c df 91 4f 2b 2a 8c df 8c e3
> 

That's not confusing at all:

> Encoding(x)
[1] "UTF-8"
> Encoding(y)
[1] "unknown"

The first string is in UTF-8 the second is in the local locale (here 932).


> # So there's at least a small bug with identical
> 

Nope: ?identical
"Character strings are regarded as identical if they are in different marked encodings but would agree when translated to UTF-8."


> # And this causes a problem when you attempt to do
> # stuff with the string
> 
> gsub("+", "*", x, fixed = T)
> # Error in gsub("+", "*", x, fixed = T) :
> #  invalid multibyte string at '<8c>'
> gsub("+", "*", y, fixed = T)
> # [1] "??**??"
> 

This is where the problem lies - and it has nothing to do with format:

> z=enc2utf8("??+*??")
> gsub("+", "*", z, fixed = T)
Error in gsub("+", "*", z, fixed = T) : 
  invalid multibyte string at '<8c>'

The cause is that  fgrep_one() gives higher precedence to mbcslocale than use_UTF8 so the grep is actually done in the MBCS locale and not UTF-8. Consequently, you'll see this only in multi-byte locales other than UTF-8, so on let's say OS X you can reproduce it with

> x="??+*??"
> gsub("+", "*", x, fixed = T)
Error in gsub("+", "*", x, fixed = T) : 
  invalid multibyte string at '<8c>'

Inverting the precedence would fix this issue, but I'm not sure if it would have unwanted side-effects on MBCS locales ...

Cheers,
Simon


> 
> My session info is
> 
> R version 3.0.0 (2013-04-03)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> 
> locale:
> [1] LC_COLLATE=Japanese_Japan.932  LC_CTYPE=Japanese_Japan.932
> [3] LC_MONETARY=Japanese_Japan.932 LC_NUMERIC=C
> [5] LC_TIME=Japanese_Japan.932
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> loaded via a namespace (and not attached):
> [1] tools_3.0.0
> 
> Any ideas? Thanks!
> 
> Hadley
> 
> --
> Chief Scientist, RStudio
> http://had.co.nz/
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From simon.urbanek at r-project.org  Thu May  2 00:10:11 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 1 May 2013 18:10:11 -0400
Subject: [Rd] Windows, format.POSIXct and character encodings
In-Reply-To: <77A76E74-6304-4236-8609-A5E08BC5B1A7@r-project.org>
References: <CABdHhvGT1hXm694y+yRSgD2JC_+KS3eUFGCycVVcjsneUGpAGA@mail.gmail.com>
	<77A76E74-6304-4236-8609-A5E08BC5B1A7@r-project.org>
Message-ID: <0F42A35A-0DEB-4FC6-8873-5129FCB6A30E@r-project.org>


On May 1, 2013, at 5:33 PM, Simon Urbanek wrote:

> 
> On May 1, 2013, at 10:06 AM, Hadley Wickham wrote:
> 
>> Hi all,
>> 
>> In what encoding does format.POSIXct return its output? It doesn't
>> seem to be utf-8:
>> 
>> Sys.setlocale("LC_ALL", "Japanese_Japan.932")
>> 
>> times <- c("1970-01-01 01:00:00 UTC", "1970-02-02 22:00:00 UTC")
>> ampm <- format(as.POSIXct(times), format = "%p")
>> x <- gsub(">", "*", paste(ampm, collapse = "+>"))
>> 
>> y <- "??+*??"
>> identical(x, y)
>> # [1] TRUE
>> 
>> # But, confusingly, ...
>> 
>> charToRaw(x)
>> # [1] e5 8d 88 e5 89 8d 2b 2a e5 8d 88 e5 be 8c
>> 
>> charToRaw(y)
>> # [1] 8c df 91 4f 2b 2a 8c df 8c e3
>> 
> 
> That's not confusing at all:
> 
>> Encoding(x)
> [1] "UTF-8"
>> Encoding(y)
> [1] "unknown"
> 
> The first string is in UTF-8 the second is in the local locale (here 932).
> 
> 
>> # So there's at least a small bug with identical
>> 
> 
> Nope: ?identical
> "Character strings are regarded as identical if they are in different marked encodings but would agree when translated to UTF-8."
> 
> 
>> # And this causes a problem when you attempt to do
>> # stuff with the string
>> 
>> gsub("+", "*", x, fixed = T)
>> # Error in gsub("+", "*", x, fixed = T) :
>> #  invalid multibyte string at '<8c>'
>> gsub("+", "*", y, fixed = T)
>> # [1] "??**??"
>> 
> 
> This is where the problem lies - and it has nothing to do with format:
> 
>> z=enc2utf8("??+*??")
>> gsub("+", "*", z, fixed = T)
> Error in gsub("+", "*", z, fixed = T) : 
>  invalid multibyte string at '<8c>'
> 
> The cause is that  fgrep_one() gives higher precedence to mbcslocale than use_UTF8 so the grep is actually done in the MBCS locale and not UTF-8. Consequently, you'll see this only in multi-byte locales other than UTF-8, so on let's say OS X you can reproduce it with
> 
>> x="??+*??"
>> gsub("+", "*", x, fixed = T)
> Error in gsub("+", "*", x, fixed = T) : 
>  invalid multibyte string at '<8c>'
> 

This should have been

> Sys.getlocale()
[1] "en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8"
> x="??+*??"
> Encoding(x)
[1] "UTF-8"
> Sys.setlocale("LC_ALL", "ja_JP.SJIS")
[1] "ja_JP.SJIS/ja_JP.SJIS/ja_JP.SJIS/C/ja_JP.SJIS/en_US.UTF-8"
> gsub("+", "*", x, fixed = T)
Error in gsub("+", "*", x, fixed = T) : 
  invalid multibyte string at '<8c>'

Cheers,
S


> Inverting the precedence would fix this issue, but I'm not sure if it would have unwanted side-effects on MBCS locales ...
> 
> Cheers,
> Simon
> 
> 
>> 
>> My session info is
>> 
>> R version 3.0.0 (2013-04-03)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> 
>> locale:
>> [1] LC_COLLATE=Japanese_Japan.932  LC_CTYPE=Japanese_Japan.932
>> [3] LC_MONETARY=Japanese_Japan.932 LC_NUMERIC=C
>> [5] LC_TIME=Japanese_Japan.932
>> 
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>> 
>> loaded via a namespace (and not attached):
>> [1] tools_3.0.0
>> 
>> Any ideas? Thanks!
>> 
>> Hadley
>> 
>> --
>> Chief Scientist, RStudio
>> http://had.co.nz/
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hpages at fhcrc.org  Thu May  2 01:49:49 2013
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Wed, 01 May 2013 16:49:49 -0700
Subject: [Rd] Patch proposal for R style consistency (concerning
	deparse.c)
In-Reply-To: <51816ABC.1070407@gmail.com>
References: <CAErODj85saboM+8SaYKKVVDL6cPeX=LVR=PKwY+FZb2ky_cpBg@mail.gmail.com>
	<5478C197-76AB-481D-A1AA-64DB63D8D122@gmail.com>
	<CAErODj_N+FCjP1zt2H4VHv28o8RDU8sQ-W4qGONkx1gLvC33pg@mail.gmail.com>
	<CANROs4emmr=rGLKWpCQ6z_016mAk7O42=ttA1BLnc9zQ_DTzqQ@mail.gmail.com>
	<51787400.7010305@fhcrc.org> <51787C98.2030106@gmail.com>
	<5178D695.30009@fhcrc.org>
	<CAErODj9nL5SOPCJ1R=NjueZAiG=WJo1V1KwPxbNGJpR1z1bJbg@mail.gmail.com>
	<CAC+N9BWCDacT_cCD3fGAb2EgB+oaQ0qGNq0fkOWsigzZtTJfaA@mail.gmail.com>
	<51816ABC.1070407@gmail.com>
Message-ID: <5181AA1D.1070409@fhcrc.org>

On 05/01/2013 12:19 PM, Duncan Murdoch wrote:
> On 01/05/2013 1:34 PM, Tim Triche, Jr. wrote:
>> +1 to having runnable code emitted
>
> It does emit runnable code, which is why Herve's complaint was
> nonsense.  It doesn't emit code of which every substring is runnable.

Perdon me, but I was not of course suggesting that every substring be
runnable. That would be non-sense. So please, don't make me say what
I didn't say. Thank you!

H.

>
> Duncan Murdoch
>
>>
>> patch seems to work nicely, hopefully R-core will agree to apply it to
>> HEAD
>>
>>
>>
>> On Wed, May 1, 2013 at 9:45 AM, Paul Johnson <pauljohn32 at gmail.com>
>> wrote:
>>
>> > Whoa.
>> >
>> > Don't let my valuable suggestion get lost.
>> >
>> >  I want "} else {".  Yihue wants "} else {".  And I have not heard
>> anybody
>> > say they prefer the other way, unless you interpret Duncan's comment
>> > "that's nonsense" as a blanket defense of the status quo. But I
>> don't think
>> > he meant that.  This is a matter of style consistency and avoidance
>> of new
>> > R-user confusion and error.
>> >
>> > After reading the help for "if", I don't see how anybody can argue
>> against
>> > this.  Good R code has this style:
>> >
>> > } else {
>> >
>> > and not
>> >
>> > }
>> >  else
>> >
>> > because the latter fails if it is run line-by-line.  While trying to
>> teach
>> > people how to write R programs, it would be nice if the output of
>> > print.function was consistent with the good way, the way that is
>> actually
>> > practiced in the R source code itself. This is a major source of new
>> > programmer confusion. Its very tough to explain and teach.
>> >
>> > pj
>> > --
>> > Paul E. Johnson
>> > Professor, Political Science      Assoc. Director
>> > 1541 Lilac Lane, Room 504      Center for Research Methods
>> > University of Kansas                 University of Kansas
>> > http://pj.freefaculty.org               http://quant.ku.edu
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>> >
>>
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From murdoch.duncan at gmail.com  Thu May  2 04:20:25 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 01 May 2013 22:20:25 -0400
Subject: [Rd] Patch proposal for R style consistency (concerning
	deparse.c)
In-Reply-To: <CAC+N9BW9GOq-XvzUJ3yWqz8hp=zgRskTt36PjPbHpCfnX-FbYA@mail.gmail.com>
References: <CAErODj85saboM+8SaYKKVVDL6cPeX=LVR=PKwY+FZb2ky_cpBg@mail.gmail.com>
	<5478C197-76AB-481D-A1AA-64DB63D8D122@gmail.com>
	<CAErODj_N+FCjP1zt2H4VHv28o8RDU8sQ-W4qGONkx1gLvC33pg@mail.gmail.com>
	<CANROs4emmr=rGLKWpCQ6z_016mAk7O42=ttA1BLnc9zQ_DTzqQ@mail.gmail.com>
	<51787400.7010305@fhcrc.org> <51787C98.2030106@gmail.com>
	<5178D695.30009@fhcrc.org>
	<CAErODj9nL5SOPCJ1R=NjueZAiG=WJo1V1KwPxbNGJpR1z1bJbg@mail.gmail.com>
	<CAC+N9BWCDacT_cCD3fGAb2EgB+oaQ0qGNq0fkOWsigzZtTJfaA@mail.gmail.com>
	<51816ABC.1070407@gmail.com>
	<CAC+N9BW9GOq-XvzUJ3yWqz8hp=zgRskTt36PjPbHpCfnX-FbYA@mail.gmail.com>
Message-ID: <5181CD69.1010603@gmail.com>

On 13-05-01 4:08 PM, Tim Triche, Jr. wrote:
> What harm comes of having the code be cut-and-paste-able?
>
> I do not mean to be contrary but a downside to applying the patch seems to
> be lacking.
> Perhaps I am missing something obvious and if so I beg your pardon for
> wasting your time.

I think you are missing some downsides which may not be obvious:

  - it would mean that lots of published results would no longer match 
what R produces.
  - it would mean that lots of tests for changes in output would 
suddenly fail.
  - it would support the mistaken belief that some people have that the 
current output is not valid code (even though there are nearly 200,000 
instances of similar usage on CRAN).

Perhaps 20 years ago it should have been written the way you suggest, 
but it would cause far more harm than benefit to change it now.

Duncan Murdoch

>
> Thanks,
>
> --t
>
>
>
> On Wed, May 1, 2013 at 12:19 PM, Duncan Murdoch <murdoch.duncan at gmail.com>wrote:
>
>> On 01/05/2013 1:34 PM, Tim Triche, Jr. wrote:
>>
>>> +1 to having runnable code emitted
>>>
>>
>> It does emit runnable code, which is why Herve's complaint was nonsense.
>>   It doesn't emit code of which every substring is runnable.
>>
>> Duncan Murdoch
>>
>>
>>
>>> patch seems to work nicely, hopefully R-core will agree to apply it to
>>> HEAD
>>>
>>>
>>>
>>> On Wed, May 1, 2013 at 9:45 AM, Paul Johnson <pauljohn32 at gmail.com>
>>> wrote:
>>>
>>>> Whoa.
>>>>
>>>> Don't let my valuable suggestion get lost.
>>>>
>>>>   I want "} else {".  Yihue wants "} else {".  And I have not heard
>>> anybody
>>>> say they prefer the other way, unless you interpret Duncan's comment
>>>> "that's nonsense" as a blanket defense of the status quo. But I don't
>>> think
>>>> he meant that.  This is a matter of style consistency and avoidance of
>>> new
>>>> R-user confusion and error.
>>>>
>>>> After reading the help for "if", I don't see how anybody can argue
>>> against
>>>> this.  Good R code has this style:
>>>>
>>>> } else {
>>>>
>>>> and not
>>>>
>>>> }
>>>>   else
>>>>
>>>> because the latter fails if it is run line-by-line.  While trying to
>>> teach
>>>> people how to write R programs, it would be nice if the output of
>>>> print.function was consistent with the good way, the way that is
>>> actually
>>>> practiced in the R source code itself. This is a major source of new
>>>> programmer confusion. Its very tough to explain and teach.
>>>>
>>>> pj
>>>> --
>>>> Paul E. Johnson
>>>> Professor, Political Science      Assoc. Director
>>>> 1541 Lilac Lane, Room 504      Center for Research Methods
>>>> University of Kansas                 University of Kansas
>>>> http://pj.freefaculty.org               http://quant.ku.edu
>>>>
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> ______________________________**________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/**listinfo/r-devel<https://stat.ethz.ch/mailman/listinfo/r-devel>
>>>>
>>>
>>>
>>>
>>>
>>
>
>


From hpages at fhcrc.org  Thu May  2 08:51:29 2013
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Wed, 01 May 2013 23:51:29 -0700
Subject: [Rd] Patch proposal for R style consistency (concerning
	deparse.c)
In-Reply-To: <5181CD69.1010603@gmail.com>
References: <CAErODj85saboM+8SaYKKVVDL6cPeX=LVR=PKwY+FZb2ky_cpBg@mail.gmail.com>
	<5478C197-76AB-481D-A1AA-64DB63D8D122@gmail.com>
	<CAErODj_N+FCjP1zt2H4VHv28o8RDU8sQ-W4qGONkx1gLvC33pg@mail.gmail.com>
	<CANROs4emmr=rGLKWpCQ6z_016mAk7O42=ttA1BLnc9zQ_DTzqQ@mail.gmail.com>
	<51787400.7010305@fhcrc.org> <51787C98.2030106@gmail.com>
	<5178D695.30009@fhcrc.org>
	<CAErODj9nL5SOPCJ1R=NjueZAiG=WJo1V1KwPxbNGJpR1z1bJbg@mail.gmail.com>
	<CAC+N9BWCDacT_cCD3fGAb2EgB+oaQ0qGNq0fkOWsigzZtTJfaA@mail.gmail.com>
	<51816ABC.1070407@gmail.com>
	<CAC+N9BW9GOq-XvzUJ3yWqz8hp=zgRskTt36PjPbHpCfnX-FbYA@mail.gmail.com>
	<5181CD69.1010603@gmail.com>
Message-ID: <51820CF1.40104@fhcrc.org>

On 05/01/2013 07:20 PM, Duncan Murdoch wrote:
> On 13-05-01 4:08 PM, Tim Triche, Jr. wrote:
>> What harm comes of having the code be cut-and-paste-able?
>>
>> I do not mean to be contrary but a downside to applying the patch
>> seems to
>> be lacking.
>> Perhaps I am missing something obvious and if so I beg your pardon for
>> wasting your time.
>
> I think you are missing some downsides which may not be obvious:
>
>   - it would mean that lots of published results would no longer match
> what R produces.

What kind of published results? Results that do statistics on the nb
of lines of code in a function based on the output of print.function()?

Would it make sense to try to reproduce results that were published 5
or 10 years ago with R >= 3.0.0? Too many things have changed in R
and on CRAN anyway so it's hopeless. The only reasonable/realistic way
to reproduce is to use the version of R and packages that were used
at the time of the publication.

>   - it would mean that lots of tests for changes in output would
> suddenly fail.

Lots of tests really? Where are they?

>   - it would support the mistaken belief that some people have that the
> current output is not valid code (even though there are nearly 200,000
> instances of similar usage on CRAN).

Is that number supposed to impress someone?

Running

   grep -E '^[[:space:]]*else' */R/*

produces 112,518 lines of output on the 4479 source packages currently 
available on CRAN. So 112,518 "if else" statements use the formatting
that breaks copy/paste.

Also, interestingly, running

   grep else */R/*

on those packages produces 276028 lines of output. So only 34% of the
"if else" statements use the formatting that breaks copy/paste. Far
from being the dominant idiom, which is probably a good sign for CRAN.

Unfortunately, with the current output of print.function(), 100% of
the "if else" statements on CRAN break copy/paste. Unfair for the
majority of CRAN contributors to see their nicely formatted code
exposed that way to the end-user. Unfair for the end-user, especially
the R novice, to get code s/he cannot copy/paste.

>
> Perhaps 20 years ago it should have been written the way you suggest,
> but it would cause far more harm than benefit to change it now.

You clearly underestimate the harm the current formatting causes
every day to many R users, developers, teachers, students...

H.

>
> Duncan Murdoch
>
>>
>> Thanks,
>>
>> --t
>>
>>
>>
>> On Wed, May 1, 2013 at 12:19 PM, Duncan Murdoch
>> <murdoch.duncan at gmail.com>wrote:
>>
>>> On 01/05/2013 1:34 PM, Tim Triche, Jr. wrote:
>>>
>>>> +1 to having runnable code emitted
>>>>
>>>
>>> It does emit runnable code, which is why Herve's complaint was nonsense.
>>>   It doesn't emit code of which every substring is runnable.
>>>
>>> Duncan Murdoch
>>>
>>>
>>>
>>>> patch seems to work nicely, hopefully R-core will agree to apply it to
>>>> HEAD
>>>>
>>>>
>>>>
>>>> On Wed, May 1, 2013 at 9:45 AM, Paul Johnson <pauljohn32 at gmail.com>
>>>> wrote:
>>>>
>>>>> Whoa.
>>>>>
>>>>> Don't let my valuable suggestion get lost.
>>>>>
>>>>>   I want "} else {".  Yihue wants "} else {".  And I have not heard
>>>> anybody
>>>>> say they prefer the other way, unless you interpret Duncan's comment
>>>>> "that's nonsense" as a blanket defense of the status quo. But I don't
>>>> think
>>>>> he meant that.  This is a matter of style consistency and avoidance of
>>>> new
>>>>> R-user confusion and error.
>>>>>
>>>>> After reading the help for "if", I don't see how anybody can argue
>>>> against
>>>>> this.  Good R code has this style:
>>>>>
>>>>> } else {
>>>>>
>>>>> and not
>>>>>
>>>>> }
>>>>>   else
>>>>>
>>>>> because the latter fails if it is run line-by-line.  While trying to
>>>> teach
>>>>> people how to write R programs, it would be nice if the output of
>>>>> print.function was consistent with the good way, the way that is
>>>> actually
>>>>> practiced in the R source code itself. This is a major source of new
>>>>> programmer confusion. Its very tough to explain and teach.
>>>>>
>>>>> pj
>>>>> --
>>>>> Paul E. Johnson
>>>>> Professor, Political Science      Assoc. Director
>>>>> 1541 Lilac Lane, Room 504      Center for Research Methods
>>>>> University of Kansas                 University of Kansas
>>>>> http://pj.freefaculty.org               http://quant.ku.edu
>>>>>
>>>>>          [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________**________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/**listinfo/r-devel<https://stat.ethz.ch/mailman/listinfo/r-devel>
>>>>>
>>>>>
>>>>
>>>>
>>>>
>>>>
>>>
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From cgenolin at u-paris10.fr  Thu May  2 08:58:39 2013
From: cgenolin at u-paris10.fr (cgenolin)
Date: Wed, 1 May 2013 23:58:39 -0700 (PDT)
Subject: [Rd] Comments in the DESCRIPTION file
In-Reply-To: <C4C6B669-E9A6-4D2F-AC55-4968F3CBE764@r-project.org>
References: <509A2942.3050004@u-paris10.fr>
	<1367402475396-4665892.post@n4.nabble.com>
	<C4C6B669-E9A6-4D2F-AC55-4968F3CBE764@r-project.org>
Message-ID: <1367477919284-4666017.post@n4.nabble.com>

Hi,

I am not that familiar with the DCF... But R seems to accept # quite easely.
More precisely:

Before posting my message, I try it on a small package: R CMD check or R CMD
INSTALL did not make any warning or error (whereas they do if I use '#'
alone). 

After reading your response, I dig a bit more. The source of my DESCRIPTION
file was:

--- 8< ------------------
#############################:
###: This is some kind of 'section 1'
###:
Package: packBasic1
Title: Very simple package
Version: 0.9.2
License: GPL (>=2.0)
Description: A package
#:
#:
#############################:
###: This is 'section 2'
###:
Author: Christophe Genolini
Maintainer: Christophe Genolini <genolini at u-paris10.fr>
--- 8< ------------------

The DESCRIPTION file after installation was: 

--- 8< ------------------
#############################:
###:
Package: packBasic1
Title: Very simple package
Version: 0.9.2
License: GPL (>=2.0)
Description: A package
#:
Author: Christophe Genolini
Maintainer: Christophe Genolini <genolini at u-paris10.fr>
Built: R 3.0.0; ; 2013-05-02 06:50:57 UTC; windows
--- 8< ------------------

So I guess there was a problem.
But if I number the comments line, then it works:

--- 8< ---------------------
#############################1:
###2: This is some kind of 'section 1'
###3:
Package: packBasic1
Title: Very simple package
Version: 0.9.2
License: GPL (>=2.0)
Description: A package
#4:
#5:
#############################6:
###7: This is 'section 2'
###8:
Author: Christophe Genolini
Maintainer: Christophe Genolini <genolini at u-paris10.fr>
Built: R 3.0.0; ; 2013-05-02 06:49:27 UTC; windows
--- 8< ---------------------

Christophe



--
View this message in context: http://r.789695.n4.nabble.com/Comments-in-the-DESCRIPTION-file-tp4648678p4666017.html
Sent from the R devel mailing list archive at Nabble.com.


From C.P.Jewell at massey.ac.nz  Thu May  2 01:50:41 2013
From: C.P.Jewell at massey.ac.nz (Jewell, Chris)
Date: Wed, 1 May 2013 23:50:41 +0000
Subject: [Rd] Catch SIGINT from user in backend C++ code
Message-ID: <B09F1CDB-1596-4950-9037-9BF009C84822@massey.ac.nz>

Hi,

I was wondering if anybody knew how to trap SIGINTs (ie Ctrl-C) in backend C++ code for R extensions?  I'm writing a package that uses the GPU for some hefty matrix operations in a tightly coupled parallel algorithm implemented in CUDA.

The problem is that once running, the C++ module cannot apparently be interrupted by a SIGINT, leaving the user sat waiting even if they realise they've launched the algorithm with incorrect settings.  Occasionally, the SIGINT gets through and the C++ module stops.  However, this leaves the CUDA context hanging, meaning that if the algorithm is launched again R dies.  If I could trap the SIGINT, then I could make sure a) that the algorithm stops immediately, and b) that the CUDA context is destructed nicely.

Is there a "R-standard" method of doing this?

Thanks,

Chris


--
Dr Chris Jewell
Lecturer in Biostatistics
Institute of Fundamental Sciences
Massey University
Private Bag 11222
Palmerston North 4442
New Zealand
Tel: +64 (0) 6 350 5701 Extn: 3586


From rphilip.chalmers at gmail.com  Thu May  2 01:35:16 2013
From: rphilip.chalmers at gmail.com (philchalmers)
Date: Wed, 1 May 2013 16:35:16 -0700 (PDT)
Subject: [Rd] diag() when input is a numeric scalar
Message-ID: <1367451316781-4665986.post@n4.nabble.com>

Hi All,

I'm wondering why when passing a single numeric value that contains any
decimals to diag() that the value is silently coerced to a integer for
constructing an identify matrix. To me, an input like diag(5.435) seems
fairly ambiguous and is more than likely a programming mistake, since it's
not obvious that a 5x5 identity matrix should be created. I've seen some
code where other writers have been burned on this as well, especially when
trying extract diagonal elements but forget about the scalar case. A warning
or message would help track this problem down really quickly to force the
author to use diag(floor(5.435)) explicitly, if indeed that is there
intention. Thoughts?

Phil



--
View this message in context: http://r.789695.n4.nabble.com/diag-when-input-is-a-numeric-scalar-tp4665986.html
Sent from the R devel mailing list archive at Nabble.com.


From timb at metrumrg.com  Wed May  1 20:12:33 2013
From: timb at metrumrg.com (Tim Bergsma)
Date: Wed, 1 May 2013 14:12:33 -0400
Subject: [Rd] foreign: write.xport
Message-ID: <CAK0Ebm6Wq6iW_csoDekCYxvTjKUZZL3aNqCwoS0=GgH780Xxnw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130501/992dcd97/attachment.pl>

From michael.weylandt at gmail.com  Thu May  2 12:04:38 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt)
Date: Thu, 2 May 2013 11:04:38 +0100
Subject: [Rd] Catch SIGINT from user in backend C++ code
In-Reply-To: <B09F1CDB-1596-4950-9037-9BF009C84822@massey.ac.nz>
References: <B09F1CDB-1596-4950-9037-9BF009C84822@massey.ac.nz>
Message-ID: <CAAmySGOmfxfJhYuWgkdFXidgiMgPcjFWo7jytcYzZnHg7UJFYw@mail.gmail.com>

On Thu, May 2, 2013 at 12:50 AM, Jewell, Chris <C.P.Jewell at massey.ac.nz> wrote:
> Hi,
>
> I was wondering if anybody knew how to trap SIGINTs (ie Ctrl-C) in backend C++ code for R extensions?  I'm writing a package that uses the GPU for some hefty matrix operations in a tightly coupled parallel algorithm implemented in CUDA.
>
> The problem is that once running, the C++ module cannot apparently be interrupted by a SIGINT, leaving the user sat waiting even if they realise they've launched the algorithm with incorrect settings.  Occasionally, the SIGINT gets through and the C++ module stops.  However, this leaves the CUDA context hanging, meaning that if the algorithm is launched again R dies.  If I could trap the SIGINT, then I could make sure a) that the algorithm stops immediately, and b) that the CUDA context is destructed nicely.
>
> Is there a "R-standard" method of doing this?
>

I think R_CheckUserInterrupt() might be the right way to go but I
haven't used it much, so not sure if it gives you recovery ability.

Cheers,
Michael


> Thanks,
>
> Chris
>
>
> --
> Dr Chris Jewell
> Lecturer in Biostatistics
> Institute of Fundamental Sciences
> Massey University
> Private Bag 11222
> Palmerston North 4442
> New Zealand
> Tel: +64 (0) 6 350 5701 Extn: 3586
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From michael.weylandt at gmail.com  Thu May  2 12:36:25 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt)
Date: Thu, 2 May 2013 11:36:25 +0100
Subject: [Rd] diag() when input is a numeric scalar
In-Reply-To: <1367451316781-4665986.post@n4.nabble.com>
References: <1367451316781-4665986.post@n4.nabble.com>
Message-ID: <CAAmySGPLSZhkDCx7EnfVNY08Sf4goZPTiULDGWQex2f-qd_UXg@mail.gmail.com>

On Thu, May 2, 2013 at 12:35 AM, philchalmers
<rphilip.chalmers at gmail.com> wrote:
> Hi All,
>
> I'm wondering why when passing a single numeric value that contains any
> decimals to diag() that the value is silently coerced to a integer for
> constructing an identify matrix. To me, an input like diag(5.435) seems
> fairly ambiguous and is more than likely a programming mistake, since it's
> not obvious that a 5x5 identity matrix should be created. I've seen some
> code where other writers have been burned on this as well, especially when
> trying extract diagonal elements but forget about the scalar case. A warning
> or message would help track this problem down really quickly to force the
> author to use diag(floor(5.435)) explicitly, if indeed that is there
> intention. Thoughts?
>

I agree it's probably rather dangerous, but it does seem consistent
with much of R:

matrix(0, ncol = 3.5)

replicate(2.525, rnorm(3))

etc.

So would you propose a global change (the oft talked about "strict
mode") of R or just here? Either way, does this play nicely with R's
goals of having integers and floats behave more or less
interchangeably?

That said, I'm slightly confused by a bit of your message: are you
conflating the rounding to integer issue with the different behavior
for scalars issue (same as with sample())?

Michael


From therneau at mayo.edu  Thu May  2 14:26:24 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Thu, 02 May 2013 07:26:24 -0500
Subject: [Rd] Patch proposal for R style consistency (concerning
	deparse.c)
In-Reply-To: <mailman.23.1367488807.10840.r-devel@r-project.org>
References: <mailman.23.1367488807.10840.r-devel@r-project.org>
Message-ID: <51825B70.8090604@mayo.edu>

I'll be the "anybody" to argue that
      }  else {
is an ugly kludge which you will never find in my source code.  Yes, it's necessary at the 
command line because the parser needs help in guessing when an expression is finished, but 
is only needed in that case.  Since I can hardly imagine using else at the command line 
(that many correct characters in a row exceeds my typing skill) it's not an issue for me.  
I most certainly would not inflict this construction on my pupils when teaching a class, 
nor that any break of a long line has to be after "+" but not before, nor other crutches 
for the parser's sake.  Let them know about the special case of course, but don't 
sacrifice good coding style the deficiency.

That said, I am completely ambivalent to the result of deparse.  Just throwing up an 
objection to the "purity" argument: things were beginning to sound a bit too bombastic :-).

Terry T.

On 05/02/2013 05:00 AM, r-devel-request at r-project.org wrote:
>   I want "} else {".  Yihue wants "} else {".  And I have not heard anybody
> say they prefer the other way, unless you interpret Duncan's comment
> "that's nonsense" as a blanket defense of the status quo. But I don't think
> he meant that.  This is a matter of style consistency and avoidance of new
> R-user confusion and error.


From takahashi.kohske at gmail.com  Thu May  2 14:31:38 2013
From: takahashi.kohske at gmail.com (Kohske Takahashi)
Date: Thu, 2 May 2013 21:31:38 +0900
Subject: [Rd] trace with reference class
In-Reply-To: <51813836.9080604@r-project.org>
References: <CAC-jPZpk4NZrrTOReeHXOTZOFxD7sC=8iDAunWeoRTzqYwv8cg@mail.gmail.com>
	<51813836.9080604@r-project.org>
Message-ID: <CAC-jPZq12o5TaL1bfDdPkDhzgWXAGGKvW1yvdiQxhjESZ2Eixw@mail.gmail.com>

I got it, thanks!

kohske

2013/5/2 John Chambers <jmc at r-project.org>:
> No intended change.  The trace method was not updated when reference class
> generators became functions.  Should be fixed now in r-devel and 3.0.0
> patched (rev 62699).
>
> Thanks for the catch.
>
> John
>
>
> On 4/29/13 11:30 PM, Kohske Takahashi wrote:
>>
>> Hi
>>
>> The final line of the example in ?setRefClass induces an error:
>>
>>> ## debugging all objects from class mEdit in method $undo()
>>> mEdit$trace(undo, browser)
>>
>> Error in envRefInferField(x, what, getClass(class(x)), selfEnv) :
>>    'undo' is not a valid field or method name for reference class
>> "refGeneratorSlot"
>>
>> $trace tries to embed the trace in the generator object (instead of
>> the generated object).
>> Has this functionality been removed?
>>
>> best,
>>
>> kohske
>>
>> --
>> Kohske Takahashi <takahashi.kohske at gmail.com>
>>
>> Assistant Professor,
>> Research Center for Advanced Science and Technology,
>> The University of  Tokyo, Japan.
>> http://www.fennel.rcast.u-tokyo.ac.jp/profilee_ktakahashi.html
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>



-- 
Kohske Takahashi <takahashi.kohske at gmail.com>

Assistant Professor,
Research Center for Advanced Science and Technology,
The University of  Tokyo, Japan.
http://www.fennel.rcast.u-tokyo.ac.jp/profilee_ktakahashi.html


From marc_schwartz at me.com  Thu May  2 14:37:10 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 02 May 2013 07:37:10 -0500
Subject: [Rd] foreign: write.xport
In-Reply-To: <CAK0Ebm6Wq6iW_csoDekCYxvTjKUZZL3aNqCwoS0=GgH780Xxnw@mail.gmail.com>
References: <CAK0Ebm6Wq6iW_csoDekCYxvTjKUZZL3aNqCwoS0=GgH780Xxnw@mail.gmail.com>
Message-ID: <077E14AA-8292-43D1-BEC5-D269E45BA990@me.com>

On May 1, 2013, at 1:12 PM, Tim Bergsma <timb at metrumrg.com> wrote:

> I see in the archives significant discussion about SAS, CDISC formats etc.
> for FDA, but no direct suggestion of adding a write.xport method to the
> foreign package.  Are there significant barriers to doing so?



Hi,

The primary barrier would be that a member of the R Core team would likely need to have the interest and time to do this and then maintain the code in the future, if it were to become a part of the foreign package, since it is part of the Recommended packages that ship with R. 

The better alternative would be to see if you can use the SASxport package on CRAN:

  http://cran.r-project.org/web/packages/SASxport/

which looks like it was just recently updated, after Greg, the maintainer, had gone missing for a few years. So perhaps Greg has resurfaced to resolve some of the issues that resulted in the package failing CRAN checks recently.

Regards,

Marc Schwartz


From h.wickham at gmail.com  Thu May  2 15:46:26 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 2 May 2013 09:46:26 -0400
Subject: [Rd] Windows, format.POSIXct and character encodings
In-Reply-To: <77A76E74-6304-4236-8609-A5E08BC5B1A7@r-project.org>
References: <CABdHhvGT1hXm694y+yRSgD2JC_+KS3eUFGCycVVcjsneUGpAGA@mail.gmail.com>
	<77A76E74-6304-4236-8609-A5E08BC5B1A7@r-project.org>
Message-ID: <CABdHhvHY_QWE3x-QBUvRXDqDLEyLM3fSR4YBoET2aSWFVxj4Bg@mail.gmail.com>

>> identical(x, y)
>> # [1] TRUE
>>
>> # But, confusingly, ...
>>
>> charToRaw(x)
>> # [1] e5 8d 88 e5 89 8d 2b 2a e5 8d 88 e5 be 8c
>>
>> charToRaw(y)
>> # [1] 8c df 91 4f 2b 2a 8c df 8c e3
>>
>
> That's not confusing at all:
>
>> Encoding(x)
> [1] "UTF-8"
>> Encoding(y)
> [1] "unknown"
>
> The first string is in UTF-8 the second is in the local locale (here 932).

It's confusing because two "identical" objects have different
behaviour. Thanks for pointing out that it's documented, but it
doesn't make it any less confusing.

>> # And this causes a problem when you attempt to do
>> # stuff with the string
>>
>> gsub("+", "*", x, fixed = T)
>> # Error in gsub("+", "*", x, fixed = T) :
>> #  invalid multibyte string at '<8c>'
>> gsub("+", "*", y, fixed = T)
>> # [1] "??**??"
>>
>
> This is where the problem lies - and it has nothing to do with format:
>
>> z=enc2utf8("??+*??")
>> gsub("+", "*", z, fixed = T)
> Error in gsub("+", "*", z, fixed = T) :
>   invalid multibyte string at '<8c>'

So is there a way I can convert x into a utf-8 string in general? i.e.
how can I this regular expression not fail given that the text is
encoded in locale 932?


Hadley

--
Chief Scientist, RStudio
http://had.co.nz/


From rh at knut-krueger.de  Thu May  2 15:58:40 2013
From: rh at knut-krueger.de (Knut Krueger)
Date: Thu, 02 May 2013 15:58:40 +0200
Subject: [Rd] install.packages from own rpository - depencies
Message-ID: <51827110.4010009@knut-krueger.de>

I am trying to setup a respository for students with a own package.
Its working fine when the depended packages are already installed with:
install.packages("mypackage", 
type="source",repos="http://myrepository.example.com")

but if the the dependencies are not already installed I get the 
following error:
ERROR: dependencies 'igraph', 'chron', 'gdata' are not available for 
package 'mypackage'
* removing 'C:/.../mypackage'


From simon.urbanek at r-project.org  Thu May  2 16:03:07 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 2 May 2013 10:03:07 -0400
Subject: [Rd] Comments in the DESCRIPTION file
In-Reply-To: <1367477919284-4666017.post@n4.nabble.com>
References: <509A2942.3050004@u-paris10.fr>
	<1367402475396-4665892.post@n4.nabble.com>
	<C4C6B669-E9A6-4D2F-AC55-4968F3CBE764@r-project.org>
	<1367477919284-4666017.post@n4.nabble.com>
Message-ID: <40677854-5CFC-4FA1-B1F6-E27C3CEBF772@r-project.org>


On May 2, 2013, at 2:58 AM, cgenolin wrote:

> Hi,
> 
> I am not that familiar with the DCF... But R seems to accept # quite easely.

The fact that R currently accepts invalid DCF files is not a guarantee that it won't be following the standard more closely in the future. What you are doing is illegal in the DCF standard so don't do it. If you do so, don't be surprised that it will fail tomorrow, you have been warned.

Cheers,
S





> More precisely:
> 
> Before posting my message, I try it on a small package: R CMD check or R CMD
> INSTALL did not make any warning or error (whereas they do if I use '#'
> alone). 
> 
> After reading your response, I dig a bit more. The source of my DESCRIPTION
> file was:
> 
> --- 8< ------------------
> #############################:
> ###: This is some kind of 'section 1'
> ###:
> Package: packBasic1
> Title: Very simple package
> Version: 0.9.2
> License: GPL (>=2.0)
> Description: A package
> #:
> #:
> #############################:
> ###: This is 'section 2'
> ###:
> Author: Christophe Genolini
> Maintainer: Christophe Genolini <genolini at u-paris10.fr>
> --- 8< ------------------
> 
> The DESCRIPTION file after installation was: 
> 
> --- 8< ------------------
> #############################:
> ###:
> Package: packBasic1
> Title: Very simple package
> Version: 0.9.2
> License: GPL (>=2.0)
> Description: A package
> #:
> Author: Christophe Genolini
> Maintainer: Christophe Genolini <genolini at u-paris10.fr>
> Built: R 3.0.0; ; 2013-05-02 06:50:57 UTC; windows
> --- 8< ------------------
> 
> So I guess there was a problem.
> But if I number the comments line, then it works:
> 
> --- 8< ---------------------
> #############################1:
> ###2: This is some kind of 'section 1'
> ###3:
> Package: packBasic1
> Title: Very simple package
> Version: 0.9.2
> License: GPL (>=2.0)
> Description: A package
> #4:
> #5:
> #############################6:
> ###7: This is 'section 2'
> ###8:
> Author: Christophe Genolini
> Maintainer: Christophe Genolini <genolini at u-paris10.fr>
> Built: R 3.0.0; ; 2013-05-02 06:49:27 UTC; windows
> --- 8< ---------------------
> 
> Christophe
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Comments-in-the-DESCRIPTION-file-tp4648678p4666017.html
> Sent from the R devel mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From simon.urbanek at r-project.org  Thu May  2 16:05:43 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 2 May 2013 10:05:43 -0400
Subject: [Rd] install.packages from own rpository - depencies
In-Reply-To: <51827110.4010009@knut-krueger.de>
References: <51827110.4010009@knut-krueger.de>
Message-ID: <C3240E98-3917-48AB-B657-C0C291B5DC5F@r-project.org>

On May 2, 2013, at 9:58 AM, Knut Krueger wrote:

> I am trying to setup a respository for students with a own package.
> Its working fine when the depended packages are already installed with:
> install.packages("mypackage", type="source",repos="http://myrepository.example.com")
> 
> but if the the dependencies are not already installed I get the following error:
> ERROR: dependencies 'igraph', 'chron', 'gdata' are not available for package 'mypackage'
> * removing 'C:/.../mypackage'
> 

You should add the repositories for the dependencies as well, e.g.:

install.packages("mypackage", type="source",repos=c("http://myrepository.example.com", "http://cran.r-project.org/"))

or make your repository more complete (e.g. if you want to pin certain versions to guarantee interoperability).

Cheers,
Simon


From cgenolin at u-paris10.fr  Thu May  2 16:17:52 2013
From: cgenolin at u-paris10.fr (cgenolin)
Date: Thu, 2 May 2013 07:17:52 -0700 (PDT)
Subject: [Rd] Comments in the DESCRIPTION file
In-Reply-To: <40677854-5CFC-4FA1-B1F6-E27C3CEBF772@r-project.org>
References: <509A2942.3050004@u-paris10.fr>
	<1367402475396-4665892.post@n4.nabble.com>
	<C4C6B669-E9A6-4D2F-AC55-4968F3CBE764@r-project.org>
	<1367477919284-4666017.post@n4.nabble.com>
	<40677854-5CFC-4FA1-B1F6-E27C3CEBF772@r-project.org>
Message-ID: <1367504272704-4666058.post@n4.nabble.com>

So it IS curently accepted, but may NOT be in the futur. Thanks for your
answer.

So I guess that using 
--- 8< -------------
%%%%%%%%%1: 
%%%2: Section 1
%%%3
...
--- 8< -------------

is correct, isn't it?

Christophe



--
View this message in context: http://r.789695.n4.nabble.com/Comments-in-the-DESCRIPTION-file-tp4648678p4666058.html
Sent from the R devel mailing list archive at Nabble.com.


From simon.urbanek at r-project.org  Thu May  2 16:30:27 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 2 May 2013 10:30:27 -0400
Subject: [Rd] Comments in the DESCRIPTION file
In-Reply-To: <1367504272704-4666058.post@n4.nabble.com>
References: <509A2942.3050004@u-paris10.fr>
	<1367402475396-4665892.post@n4.nabble.com>
	<C4C6B669-E9A6-4D2F-AC55-4968F3CBE764@r-project.org>
	<1367477919284-4666017.post@n4.nabble.com>
	<40677854-5CFC-4FA1-B1F6-E27C3CEBF772@r-project.org>
	<1367504272704-4666058.post@n4.nabble.com>
Message-ID: <12076D09-7A94-4632-B692-AAB2F6061DE2@r-project.org>

On May 2, 2013, at 10:17 AM, cgenolin wrote:

> So it IS curently accepted, but may NOT be in the futur. Thanks for your
> answer.
> 
> So I guess that using 
> --- 8< -------------
> %%%%%%%%%1: 
> %%%2: Section 1
> %%%3
> ...
> --- 8< -------------
> 
> is correct, isn't it?
> 

Yes, that is legal (assuming a colon after the 3).

FWIW this is legal as well:

A######:
B###: section 1

The two relevant requirements are:

"A paragraph must not contain more than one instance of a particular field name." and "Field names must not begin with the comment character, #."

see 5.1 Syntax of control files:
http://www.debian.org/doc/debian-policy/ch-controlfields.html

Cheers,
Simon


> Christophe
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Comments-in-the-DESCRIPTION-file-tp4648678p4666058.html
> Sent from the R devel mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From cgenolin at u-paris10.fr  Thu May  2 16:32:49 2013
From: cgenolin at u-paris10.fr (cgenolin)
Date: Thu, 2 May 2013 07:32:49 -0700 (PDT)
Subject: [Rd] Data in packages: save or write.table?
Message-ID: <1367505169081-4666061.post@n4.nabble.com>

Hi all,
I am trying to understand Writing R Extension...
Section 1.1.5, data: I include two datasets in a package, one using 'save',
the other using 'write.table':

--- 8< ----
myData1 <- data.frame(x=1:10)
write.table(myData1,file="myData1.txt")
myData2 <- data.frame(x=2:10)
save(myData2,file="myData2.Rdata")
--- 8< ----

Then R CMD check aks me to document myData1, but does not ask me to document
myData2.
In the R session, after 'library(myPack)', the data 'myData2' is
automatically present in the session while myData1 require the use of
data(myData1). Is that correct, or is there a bug in my code?

Christophe



--
View this message in context: http://r.789695.n4.nabble.com/Data-in-packages-save-or-write-table-tp4666061.html
Sent from the R devel mailing list archive at Nabble.com.


From murdoch.duncan at gmail.com  Thu May  2 16:49:28 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 02 May 2013 10:49:28 -0400
Subject: [Rd] Patch proposal for R style consistency (concerning
	deparse.c)
In-Reply-To: <CAO1zAVb=TJdRoJhUoYy=N4g+iw_qgHt59n5CH+AXqR-EU4ixNw@mail.gmail.com>
References: <CAErODj85saboM+8SaYKKVVDL6cPeX=LVR=PKwY+FZb2ky_cpBg@mail.gmail.com>
	<5478C197-76AB-481D-A1AA-64DB63D8D122@gmail.com>
	<CAErODj_N+FCjP1zt2H4VHv28o8RDU8sQ-W4qGONkx1gLvC33pg@mail.gmail.com>
	<CANROs4emmr=rGLKWpCQ6z_016mAk7O42=ttA1BLnc9zQ_DTzqQ@mail.gmail.com>
	<51787400.7010305@fhcrc.org> <51787C98.2030106@gmail.com>
	<5178D695.30009@fhcrc.org>
	<CAErODj9nL5SOPCJ1R=NjueZAiG=WJo1V1KwPxbNGJpR1z1bJbg@mail.gmail.com>
	<CAC+N9BWCDacT_cCD3fGAb2EgB+oaQ0qGNq0fkOWsigzZtTJfaA@mail.gmail.com>
	<51816ABC.1070407@gmail.com>
	<CAO1zAVb=TJdRoJhUoYy=N4g+iw_qgHt59n5CH+AXqR-EU4ixNw@mail.gmail.com>
Message-ID: <51827CF8.5020309@gmail.com>

On 01/05/2013 3:34 PM, Joris Meys wrote:
> +1 for "} else {" . It might seem a detail, but I agree wholeheartedly 
> that this would make teaching R easier.

Just one last comment to finish off my participation in this thread.  I 
think that in general, "+1" votes mean almost nothing. To have a change 
accepted, you need to convince a member of R Core that it's a good idea, 
without convincing another one that it's a bad idea.

Personally I listen to arguments for changes, but repetitions of the 
same argument are just irritating.  I was not convinced by the 
copy-and-paste argument.  I think that if this is causing you problems 
in teaching, you're doing it wrong.  I'm not going to be convinced by 
repetitions of that same argument.

Duncan Murdoch

>
> Btw, thank you Paul for the link to your coding style document. It was 
> a nice read.
>
> Cheers
> Joris
>
>
> On Wed, May 1, 2013 at 9:19 PM, Duncan Murdoch 
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>
>     On 01/05/2013 1:34 PM, Tim Triche, Jr. wrote:
>
>         +1 to having runnable code emitted
>
>
>     It does emit runnable code, which is why Herve's complaint was
>     nonsense.  It doesn't emit code of which every substring is runnable.
>
>     Duncan Murdoch
>
>
>         patch seems to work nicely, hopefully R-core will agree to
>         apply it to HEAD
>
>
>
>         On Wed, May 1, 2013 at 9:45 AM, Paul Johnson
>         <pauljohn32 at gmail.com <mailto:pauljohn32 at gmail.com>> wrote:
>
>         > Whoa.
>         >
>         > Don't let my valuable suggestion get lost.
>         >
>         >  I want "} else {".  Yihue wants "} else {".  And I have not
>         heard anybody
>         > say they prefer the other way, unless you interpret Duncan's
>         comment
>         > "that's nonsense" as a blanket defense of the status quo.
>         But I don't think
>         > he meant that.  This is a matter of style consistency and
>         avoidance of new
>         > R-user confusion and error.
>         >
>         > After reading the help for "if", I don't see how anybody can
>         argue against
>         > this.  Good R code has this style:
>         >
>         > } else {
>         >
>         > and not
>         >
>         > }
>         >  else
>         >
>         > because the latter fails if it is run line-by-line.  While
>         trying to teach
>         > people how to write R programs, it would be nice if the
>         output of
>         > print.function was consistent with the good way, the way
>         that is actually
>         > practiced in the R source code itself. This is a major
>         source of new
>         > programmer confusion. Its very tough to explain and teach.
>         >
>         > pj
>         > --
>         > Paul E. Johnson
>         > Professor, Political Science      Assoc. Director
>         > 1541 Lilac Lane, Room 504      Center for Research Methods
>         > University of Kansas                 University of Kansas
>         > http://pj.freefaculty.org http://quant.ku.edu
>         >
>         >         [[alternative HTML version deleted]]
>         >
>         > ______________________________________________
>         > R-devel at r-project.org <mailto:R-devel at r-project.org> mailing
>         list
>         > https://stat.ethz.ch/mailman/listinfo/r-devel
>         >
>
>
>
>
>     ______________________________________________
>     R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
>
> -- 
> Joris Meys
> Statistical consultant
>
> Ghent University
> Faculty of Bioscience Engineering
> Department of Mathematical Modelling, Statistics and Bio-Informatics
>
> tel : +32 9 264 59 87
> Joris.Meys at Ugent.be
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php


From jorismeys at gmail.com  Thu May  2 17:21:54 2013
From: jorismeys at gmail.com (Joris Meys)
Date: Thu, 2 May 2013 17:21:54 +0200
Subject: [Rd] Patch proposal for R style consistency (concerning
	deparse.c)
In-Reply-To: <51827CF8.5020309@gmail.com>
References: <CAErODj85saboM+8SaYKKVVDL6cPeX=LVR=PKwY+FZb2ky_cpBg@mail.gmail.com>
	<5478C197-76AB-481D-A1AA-64DB63D8D122@gmail.com>
	<CAErODj_N+FCjP1zt2H4VHv28o8RDU8sQ-W4qGONkx1gLvC33pg@mail.gmail.com>
	<CANROs4emmr=rGLKWpCQ6z_016mAk7O42=ttA1BLnc9zQ_DTzqQ@mail.gmail.com>
	<51787400.7010305@fhcrc.org> <51787C98.2030106@gmail.com>
	<5178D695.30009@fhcrc.org>
	<CAErODj9nL5SOPCJ1R=NjueZAiG=WJo1V1KwPxbNGJpR1z1bJbg@mail.gmail.com>
	<CAC+N9BWCDacT_cCD3fGAb2EgB+oaQ0qGNq0fkOWsigzZtTJfaA@mail.gmail.com>
	<51816ABC.1070407@gmail.com>
	<CAO1zAVb=TJdRoJhUoYy=N4g+iw_qgHt59n5CH+AXqR-EU4ixNw@mail.gmail.com>
	<51827CF8.5020309@gmail.com>
Message-ID: <CAO1zAVZQg8wOnWBpV6FkyPrLmdSZS80z+fbisHEnzdK19RWCRg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130502/22465cd0/attachment.pl>

From rowe at muxspace.com  Thu May  2 17:59:35 2013
From: rowe at muxspace.com (Brian Lee Yung Rowe)
Date: Thu, 2 May 2013 11:59:35 -0400
Subject: [Rd] Patch proposal for R style consistency (concerning
	deparse.c)
In-Reply-To: <51825B70.8090604@mayo.edu>
References: <mailman.23.1367488807.10840.r-devel@r-project.org>
	<51825B70.8090604@mayo.edu>
Message-ID: <74FE3C2F-9CF7-4CAA-9AE1-63FD7EBD3B7C@muxspace.com>

Writing R in a declarative style a la functional programming makes this whole thread go away since you don't need if/else blocks. 

?????
Brian Lee Yung Rowe


On May 2, 2013, at 8:27 AM, Terry Therneau <therneau at mayo.edu> wrote:

> I'll be the "anybody" to argue that
>     }  else {
> is an ugly kludge which you will never find in my source code.  Yes, it's necessary at the command line because the parser needs help in guessing when an expression is finished, but is only needed in that case.  Since I can hardly imagine using else at the command line (that many correct characters in a row exceeds my typing skill) it's not an issue for me.  I most certainly would not inflict this construction on my pupils when teaching a class, nor that any break of a long line has to be after "+" but not before, nor other crutches for the parser's sake.  Let them know about the special case of course, but don't sacrifice good coding style the deficiency.
> 
> That said, I am completely ambivalent to the result of deparse.  Just throwing up an objection to the "purity" argument: things were beginning to sound a bit too bombastic :-).
> 
> Terry T.
> 
> On 05/02/2013 05:00 AM, r-devel-request at r-project.org wrote:
>>  I want "} else {".  Yihue wants "} else {".  And I have not heard anybody
>> say they prefer the other way, unless you interpret Duncan's comment
>> "that's nonsense" as a blanket defense of the status quo. But I don't think
>> he meant that.  This is a matter of style consistency and avoidance of new
>> R-user confusion and error.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From therneau at mayo.edu  Thu May  2 21:05:59 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Thu, 02 May 2013 14:05:59 -0500
Subject: [Rd] loading of an unwanted namespace
Message-ID: <5182B917.9050709@mayo.edu>

I have a debugging environment for the survival package, perhaps unique to me, but I find 
it works very well.
To wit, a separate directory with copies of the source code but none of the package 
accuements of DESCRIPTION, NAMESPACE, etc. This separate space does NOT contain a copy of 
src/init.c
Within this I use R --vanilla, attach my .RData file, survival.so file, and away we go.

That is, until my first useage of it today under R 3.0. My runs get into trouble with 
messages about
"conflicts with the survival namespace". My problem is that I can't figure out where or 
how the name space is being searched out and attached. Any hints on where to look would be 
appreciated. This "magical" load is
kind of spooky.

Here is a session that displays it. The "setup.s" file does the dyn.load and attaches some 
data sets.

tmt-local3499% R --vanilla

R version 3.0.0 (2013-04-03) -- "Masked Marvel"
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: i686-pc-linux-gnu (32-bit)> source('setup.s')
 > sessionInfo()
R version 3.0.0 (2013-04-03)
Platform: i686-pc-linux-gnu (32-bit)

locale:
[1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C
[3] LC_TIME=en_US.UTF-8 LC_COLLATE=C
[5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8
[7] LC_PAPER=C LC_NAME=C
[9] LC_ADDRESS=C LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] splines stats graphics grDevices utils datasets methods
[8] base
 > search()
[1] ".GlobalEnv" "file:../.RData" "file:../data/.RData"
[4] "package:splines" "package:stats" "package:graphics"
[7] "package:grDevices" "package:utils" "package:datasets" > coxph(Surv(time, status) ~ 
age, data=lung)
Call:
coxph(formula = Surv(time, status) ~ age, data = lung)


coef exp(coef) se(coef) z p
age 0.0187 1.02 0.0092 2.03 0.042

Likelihood ratio test=4.24 on 1 df, p=0.0395 n= 228, number of events= 165
 >
 > # That worked fine, but the next fails
 > coxph(Surv(time, status) ~ pspline(age), data=lung)
Error in FUN(X[[2L]], ...) :
(converted from warning) failed to assign RegisteredNativeSymbol for Cagfit5a to Cagfit5a 
since Cagfit5a is already defined in the ?survival? namespace
 >
 > sessionInfo()
R version 3.0.0 (2013-04-03)
Platform: i686-pc-linux-gnu (32-bit)

locale:
[1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C
[3] LC_TIME=en_US.UTF-8 LC_COLLATE=C
[5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8
[7] LC_PAPER=C LC_NAME=C
[9] LC_ADDRESS=C LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] splines stats graphics grDevices utils datasets methods
[8] base
 >

[10] "package:methods" "Autoloads" "package:base"
 >
 > options(warn=2)


R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.


From hpages at fhcrc.org  Thu May  2 21:09:21 2013
From: hpages at fhcrc.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Thu, 02 May 2013 12:09:21 -0700
Subject: [Rd] Patch proposal for R style consistency (concerning
	deparse.c)
In-Reply-To: <51825B70.8090604@mayo.edu>
References: <mailman.23.1367488807.10840.r-devel@r-project.org>
	<51825B70.8090604@mayo.edu>
Message-ID: <5182B9E1.1040800@fhcrc.org>

On 05/02/2013 05:26 AM, Terry Therneau wrote:
> I'll be the "anybody" to argue that
>       }  else {
> is an ugly kludge which you will never find in my source code.  Yes,
> it's necessary at the command line because the parser needs help in
> guessing when an expression is finished, but is only needed in that
> case.

No, it's also needed wherever the if statement is at the top-level
(i.e. not nested within { ... }), in a package:

   hpages at thinkpad:~$ R CMD INSTALL SomePackage
   * installing to library 
?/home/hpages/R/R-3.0.0--disable-byte-compiled-packages/library?
   * installing *source* package ?SomePackage? ...
   ** R
   Error in parse(outFile) :
 
/home/hpages/svn/bioconductor/Rpacks/SomePackage/R/assignReads.R:8:1: 
unexpected 'else'
   7: }
   8: else
     ^
   ERROR: unable to collate and parse R files for package ?SomePackage?
   * removing 
?/home/hpages/R/R-3.0.0--disable-byte-compiled-packages/library/SomePackage?

or in a stand-alone script:

   > source("somescript.R")
   Error in source("somescript.R") : somescript.R:4:1: unexpected 'else'
   3: }
   4: else
   ^

It's invalid code. Period.

H.


> Since I can hardly imagine using else at the command line (that
> many correct characters in a row exceeds my typing skill) it's not an
> issue for me. I most certainly would not inflict this construction on my
> pupils when teaching a class, nor that any break of a long line has to
> be after "+" but not before, nor other crutches for the parser's sake.
> Let them know about the special case of course, but don't sacrifice good
> coding style the deficiency.
>
> That said, I am completely ambivalent to the result of deparse.  Just
> throwing up an objection to the "purity" argument: things were beginning
> to sound a bit too bombastic :-).
>
> Terry T.
>
> On 05/02/2013 05:00 AM, r-devel-request at r-project.org wrote:
>>   I want "} else {".  Yihue wants "} else {".  And I have not heard
>> anybody
>> say they prefer the other way, unless you interpret Duncan's comment
>> "that's nonsense" as a blanket defense of the status quo. But I don't
>> think
>> he meant that.  This is a matter of style consistency and avoidance of
>> new
>> R-user confusion and error.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From murdoch.duncan at gmail.com  Thu May  2 22:35:45 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 02 May 2013 16:35:45 -0400
Subject: [Rd] loading of an unwanted namespace
In-Reply-To: <5182B917.9050709@mayo.edu>
References: <5182B917.9050709@mayo.edu>
Message-ID: <5182CE21.4080901@gmail.com>

On 13-05-02 3:05 PM, Terry Therneau wrote:
> I have a debugging environment for the survival package, perhaps unique to me, but I find
> it works very well.
> To wit, a separate directory with copies of the source code but none of the package
> accuements of DESCRIPTION, NAMESPACE, etc. This separate space does NOT contain a copy of
> src/init.c
> Within this I use R --vanilla, attach my .RData file, survival.so file, and away we go.
>
> That is, until my first useage of it today under R 3.0. My runs get into trouble with
> messages about
> "conflicts with the survival namespace". My problem is that I can't figure out where or
> how the name space is being searched out and attached. Any hints on where to look would be
> appreciated. This "magical" load is
> kind of spooky.
>
> Here is a session that displays it. The "setup.s" file does the dyn.load and attaches some
> data sets.

I don't know a direct way to find this, but you could add some debugging 
code to the .Onload function in survival, e.g. to print what the stack 
is like when it's loading.  That should be informative.

Duncan Murdoch


>
> tmt-local3499% R --vanilla
>
> R version 3.0.0 (2013-04-03) -- "Masked Marvel"
> Copyright (C) 2013 The R Foundation for Statistical Computing
> Platform: i686-pc-linux-gnu (32-bit)> source('setup.s')
>   > sessionInfo()
> R version 3.0.0 (2013-04-03)
> Platform: i686-pc-linux-gnu (32-bit)
>
> locale:
> [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C
> [3] LC_TIME=en_US.UTF-8 LC_COLLATE=C
> [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8
> [7] LC_PAPER=C LC_NAME=C
> [9] LC_ADDRESS=C LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] splines stats graphics grDevices utils datasets methods
> [8] base
>   > search()
> [1] ".GlobalEnv" "file:../.RData" "file:../data/.RData"
> [4] "package:splines" "package:stats" "package:graphics"
> [7] "package:grDevices" "package:utils" "package:datasets" > coxph(Surv(time, status) ~
> age, data=lung)
> Call:
> coxph(formula = Surv(time, status) ~ age, data = lung)
>
>
> coef exp(coef) se(coef) z p
> age 0.0187 1.02 0.0092 2.03 0.042
>
> Likelihood ratio test=4.24 on 1 df, p=0.0395 n= 228, number of events= 165
>   >
>   > # That worked fine, but the next fails
>   > coxph(Surv(time, status) ~ pspline(age), data=lung)
> Error in FUN(X[[2L]], ...) :
> (converted from warning) failed to assign RegisteredNativeSymbol for Cagfit5a to Cagfit5a
> since Cagfit5a is already defined in the ?survival? namespace
>   >
>   > sessionInfo()
> R version 3.0.0 (2013-04-03)
> Platform: i686-pc-linux-gnu (32-bit)
>
> locale:
> [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C
> [3] LC_TIME=en_US.UTF-8 LC_COLLATE=C
> [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8
> [7] LC_PAPER=C LC_NAME=C
> [9] LC_ADDRESS=C LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] splines stats graphics grDevices utils datasets methods
> [8] base
>   >
>
> [10] "package:methods" "Autoloads" "package:base"
>   >
>   > options(warn=2)
>
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>
> Natural language support but running in an English locale
>
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From mtmorgan at fhcrc.org  Thu May  2 22:43:55 2013
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Thu, 02 May 2013 13:43:55 -0700
Subject: [Rd] loading of an unwanted namespace
In-Reply-To: <5182CE21.4080901@gmail.com>
References: <5182B917.9050709@mayo.edu> <5182CE21.4080901@gmail.com>
Message-ID: <5182D00B.5020503@fhcrc.org>

On 05/02/2013 01:35 PM, Duncan Murdoch wrote:
> On 13-05-02 3:05 PM, Terry Therneau wrote:
>> I have a debugging environment for the survival package, perhaps unique to me,
>> but I find
>> it works very well.
>> To wit, a separate directory with copies of the source code but none of the
>> package
>> accuements of DESCRIPTION, NAMESPACE, etc. This separate space does NOT
>> contain a copy of
>> src/init.c
>> Within this I use R --vanilla, attach my .RData file, survival.so file, and
>> away we go.
>>
>> That is, until my first useage of it today under R 3.0. My runs get into
>> trouble with
>> messages about
>> "conflicts with the survival namespace". My problem is that I can't figure out
>> where or
>> how the name space is being searched out and attached. Any hints on where to
>> look would be
>> appreciated. This "magical" load is
>> kind of spooky.
>>
>> Here is a session that displays it. The "setup.s" file does the dyn.load and
>> attaches some
>> data sets.
>
> I don't know a direct way to find this, but you could add some debugging code to
> the .Onload function in survival, e.g. to print what the stack is like when it's
> loading.  That should be informative.

   trace(loadNamespace, quote(if (package == "survival") recover()))

will break into ?recover when survival is being loaded.

Martin


>
> Duncan Murdoch
>
>
>>
>> tmt-local3499% R --vanilla
>>
>> R version 3.0.0 (2013-04-03) -- "Masked Marvel"
>> Copyright (C) 2013 The R Foundation for Statistical Computing
>> Platform: i686-pc-linux-gnu (32-bit)> source('setup.s')
>>   > sessionInfo()
>> R version 3.0.0 (2013-04-03)
>> Platform: i686-pc-linux-gnu (32-bit)
>>
>> locale:
>> [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C
>> [3] LC_TIME=en_US.UTF-8 LC_COLLATE=C
>> [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8
>> [7] LC_PAPER=C LC_NAME=C
>> [9] LC_ADDRESS=C LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] splines stats graphics grDevices utils datasets methods
>> [8] base
>>   > search()
>> [1] ".GlobalEnv" "file:../.RData" "file:../data/.RData"
>> [4] "package:splines" "package:stats" "package:graphics"
>> [7] "package:grDevices" "package:utils" "package:datasets" > coxph(Surv(time,
>> status) ~
>> age, data=lung)
>> Call:
>> coxph(formula = Surv(time, status) ~ age, data = lung)
>>
>>
>> coef exp(coef) se(coef) z p
>> age 0.0187 1.02 0.0092 2.03 0.042
>>
>> Likelihood ratio test=4.24 on 1 df, p=0.0395 n= 228, number of events= 165
>>   >
>>   > # That worked fine, but the next fails
>>   > coxph(Surv(time, status) ~ pspline(age), data=lung)
>> Error in FUN(X[[2L]], ...) :
>> (converted from warning) failed to assign RegisteredNativeSymbol for Cagfit5a
>> to Cagfit5a
>> since Cagfit5a is already defined in the ?survival? namespace
>>   >
>>   > sessionInfo()
>> R version 3.0.0 (2013-04-03)
>> Platform: i686-pc-linux-gnu (32-bit)
>>
>> locale:
>> [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C
>> [3] LC_TIME=en_US.UTF-8 LC_COLLATE=C
>> [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8
>> [7] LC_PAPER=C LC_NAME=C
>> [9] LC_ADDRESS=C LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] splines stats graphics grDevices utils datasets methods
>> [8] base
>>   >
>>
>> [10] "package:methods" "Autoloads" "package:base"
>>   >
>>   > options(warn=2)
>>
>>
>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>> You are welcome to redistribute it under certain conditions.
>> Type 'license()' or 'licence()' for distribution details.
>>
>> Natural language support but running in an English locale
>>
>> R is a collaborative project with many contributors.
>> Type 'contributors()' for more information and
>> 'citation()' on how to cite R or R packages in publications.
>>
>> Type 'demo()' for some demos, 'help()' for on-line help, or
>> 'help.start()' for an HTML browser interface to help.
>> Type 'q()' to quit R.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From amejia at factset.com  Thu May  2 14:57:07 2013
From: amejia at factset.com (Adrian Mejia)
Date: Thu, 2 May 2013 12:57:07 +0000
Subject: [Rd] dyn.load inside a package in R >= 3.0
In-Reply-To: <517D31C9.5080101@statistik.tu-dortmund.de>
References: <23F5015AB166A946A49A38282DB0C3E2C2B9A4@EXCHMBOXB01.pc.factset.com>
	<517D31C9.5080101@statistik.tu-dortmund.de>
Message-ID: <23F5015AB166A946A49A38282DB0C3E2C2C53D@EXCHMBOXB01.pc.factset.com>

I see that for the x64 architecture a function is used called dyn.open. Is that what puts it in the appropriate namespace? The x86 version uses dyn.load and it doesn't seem to specify a package or namespace.
I can't find any documentation for dyn.open - is it defined somewhere I can't find it?
What would be a less ugly hack for accomplishing this?
Thanks
Adrian

-----Original Message-----
From: Uwe Ligges [mailto:ligges at statistik.tu-dortmund.de] 
Sent: Sunday, April 28, 2013 10:27 AM
To: Adrian Mejia
Cc: r-devel at r-project.org
Subject: Re: [Rd] dyn.load inside a package in R >= 3.0



On 24.04.2013 19:55, Adrian Mejia wrote:
> Hello,
> I am trying to port a package that was built for R 2.15 over to R 3.0. This package has an Initialize method that uses dyn.load to load a dll that was built separately, and then uses .C() to make calls on the functions in that dll. This worked fine in 2.15, however, I see that now for 3.0 .C() will only search in the namespace of your current package. This seems to make it impossible to use dyn.load for loading a dll, as I can't find a way to get the loaded dll to belong to the namespace of the package that is using it. It tells me that the function I'm trying to call is not resolved from the current namespace, or if pass the .C function a value for the PACKAGE optional argument it tells me that the symbol is not available for .C() for the package.
> Is there a way to still use dyn.load to use a dll inside my package? Do I need to change the structure of my project to still be able to use my dll?

If you need an example for such an ugly hack, see how we did it in the BRugs package.

Best,
Uwe Ligges





> Thanks
> Adrian
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From jony.hudson at imperial.ac.uk  Thu May  2 18:12:11 2013
From: jony.hudson at imperial.ac.uk (Jony Hudson)
Date: Thu, 2 May 2013 17:12:11 +0100
Subject: [Rd] Minimal build of R ...
Message-ID: <1D5CC664-B90A-444E-9389-9ED0ABC38999@imperial.ac.uk>

Hi,

 I'm trying to cross-compile R to javascript so that it can run in a web-browser. Take as long as you need to stop laughing. So, as I was saying - I want to try and get a build of R running in the browser. [If you're not familiar with it already, you might enjoy looking at emscripten.org. It's a remarkably capable tool for translating LLVM bitcode to javascript. Check out some of the demos!]

I'm trying to start out with the most minimal build of R possible. I can turn off various options in the configure script, but I'm wondering about the bundled R packages (base, stats etc). I'm guessing that the native code portions of these packages are dynamically loaded at runtime, which will probably need patching. To start off, I'd like to not build these packages if possible.

So, is there a way to configure which packages in the library get built or is it just a case of editing the makefile? And is there a minimal set of them that would still allow R to run (not be useful - that can come later - just run)?

Thanks in advance for any help anyone can provide :-)


Jony

--
Centre for Cold Matter, The Blackett Laboratory,
Imperial College London, London SW7 2BW
T: +44 (0)207 5947741
http://www.imperial.ac.uk/people/jony.hudson
http://www.imperial.ac.uk/ccm/research/edm
http://www.monkeycruncher.org
http://j-star.org/
--


From jrminter at gmail.com  Thu May  2 21:01:56 2013
From: jrminter at gmail.com (John Minter)
Date: Thu, 2 May 2013 15:01:56 -0400
Subject: [Rd] Please check link for R-patched.tar.gz
Message-ID: <CABq4i1OBHXkDRqmrPdFShNEsLoqwSb5JesQoahdeTC7TG4d-Ww@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130502/0b3f8a4c/attachment.pl>

From rphilip.chalmers at gmail.com  Thu May  2 17:50:06 2013
From: rphilip.chalmers at gmail.com (philchalmers)
Date: Thu, 2 May 2013 08:50:06 -0700 (PDT)
Subject: [Rd] diag() when input is a numeric scalar
In-Reply-To: <CAAmySGPLSZhkDCx7EnfVNY08Sf4goZPTiULDGWQex2f-qd_UXg@mail.gmail.com>
References: <1367451316781-4665986.post@n4.nabble.com>
	<CAAmySGPLSZhkDCx7EnfVNY08Sf4goZPTiULDGWQex2f-qd_UXg@mail.gmail.com>
Message-ID: <1367509806804-4666072.post@n4.nabble.com>

Thanks for the reply Michael,

Although I probably would lean a bit more to the 'strict mode', I wouldn't
suggest changing the default behavior since it could break existing code and
goes against R's current philosophy. However, adding an additional argument
to some functions where the floating digits are ambiguous would be helpful,
or allowing for an optional warning message would also work to avoid these
problems.

Perhaps better yet would be to include a global argument to option() to
check for this type of default float to int coercion in base functions,
simply to see if the users code does follow a kind of 'strict mode', and to
print warnings whenever this occurs in areas where integers are needed and
floats are being coerced. This way the base functionality would remain the
same, but those who wanted to be warned about where the potential
as.integer() ambiguity is occurring could know (personally, I would leave it
on all the time, but that's a matter of preference). I wouldn't be so bold
as to change what R currently does, but I would like the option to make it
more strict if requested. Cheers.

Phil
  



--
View this message in context: http://r.789695.n4.nabble.com/diag-when-input-is-a-numeric-scalar-tp4665986p4666072.html
Sent from the R devel mailing list archive at Nabble.com.


From gmbecker at ucdavis.edu  Fri May  3 00:18:35 2013
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Thu, 2 May 2013 15:18:35 -0700
Subject: [Rd] Minimal build of R ...
In-Reply-To: <1D5CC664-B90A-444E-9389-9ED0ABC38999@imperial.ac.uk>
References: <1D5CC664-B90A-444E-9389-9ED0ABC38999@imperial.ac.uk>
Message-ID: <CADwqtCNY7EwsjNugJpOiOBSthGXRRnEiDDNPksHo0VAMLg3-+w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130502/06cb0328/attachment.pl>

From michael.weylandt at gmail.com  Fri May  3 00:35:23 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt)
Date: Thu, 2 May 2013 23:35:23 +0100
Subject: [Rd] Minimal build of R ...
In-Reply-To: <1D5CC664-B90A-444E-9389-9ED0ABC38999@imperial.ac.uk>
References: <1D5CC664-B90A-444E-9389-9ED0ABC38999@imperial.ac.uk>
Message-ID: <CAAmySGN_+LPbCFGF0a4vOUcz4=ySfdRyiThkBCZt9WD_RpGjkA@mail.gmail.com>

On Thu, May 2, 2013 at 5:12 PM, Jony Hudson <jony.hudson at imperial.ac.uk> wrote:
> Hi,
>
>  I'm trying to cross-compile R to javascript so that it can run in a web-browser. Take as long as you need to stop laughing. So, as I was saying - I want to try and get a build of R running in the browser. [If you're not familiar with it already, you might enjoy looking at emscripten.org. It's a remarkably capable tool for translating LLVM bitcode to javascript. Check out some of the demos!]
>
> I'm trying to start out with the most minimal build of R possible. I can turn off various options in the configure script, but I'm wondering about the bundled R packages (base, stats etc). I'm guessing that the native code portions of these packages are dynamically loaded at runtime, which will probably need patching. To start off, I'd like to not build these packages if possible.
>
> So, is there a way to configure which packages in the library get built or is it just a case of editing the makefile? And is there a minimal set of them that would still allow R to run (not be useful - that can come later - just run)?

You can run just "base:"

for(i in 1:(length(search()) - 2)){detach(2)}

search()

Not sure if you need "compiler" around for the build process, but we
survived without it once, so I'd assume you can get by without it if
you're willing to tweak.

Godspeed,

MW


From simon.urbanek at r-project.org  Fri May  3 02:31:42 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 2 May 2013 20:31:42 -0400
Subject: [Rd] Minimal build of R ...
In-Reply-To: <CADwqtCNY7EwsjNugJpOiOBSthGXRRnEiDDNPksHo0VAMLg3-+w@mail.gmail.com>
References: <1D5CC664-B90A-444E-9389-9ED0ABC38999@imperial.ac.uk>
	<CADwqtCNY7EwsjNugJpOiOBSthGXRRnEiDDNPksHo0VAMLg3-+w@mail.gmail.com>
Message-ID: <D4B50715-13B1-461B-BC79-BA76738AE052@r-project.org>

On May 2, 2013, at 6:18 PM, Gabriel Becker wrote:

> Jony,
> 
> I'm currently writing up the paper for something with a similar result but
> very different implementation. The RBrowserPlugin package/browser plugin
> (joint with my advisor Duncan Temple Lang) embeds R within the web browser
> as an NPAPI plugin.
> 
> This approach allows full bi-directional communication between R and the
> javascript engine (including direct function calling and references to
> native objects in both directions) using a user's existing local R
> installation (including packages).
> 

Minor detail: it requires you to have R *and* a special plugin which makes it pretty much non-deployable. It's completely unrelated to what Jony is proposing - which doesn't require any dependencies and is actually pretty cool and would be useful if feasible. FWIW: There are many ways to run R from a browser that already exist - without the need for plugins or other client-side hacks - that's the beauty of modern browsers :).


To get this back on the actual topic: I have been toying with cross-compiling R when I was porting it on the iPhone and it's possible, however, you can't use the build process as-is. It does build core R properly, but the problem is that you need to bootstrap R to build any packages. I worked around the problem at the time by building packages on another platform and re-using those files (things like lazy-loaded DBs, compiled RD files etc.).

I can imagine that you'll need some equivalent to dynamic linking, but conceptually it's nothing else but calling functions, so I think you should be able to compile each package separately and just replace the dynload code by code that loads another JavaScript. The nice thing is that packages will simply be just another JS libraries. That's all in theory, I didn't actually try that part. I suspect you'll have a lot of work, e.g. you'll need to map all the I/O operations that load compiled/stored R code, documentation, data from somewhere etc. Good luck!
If all fails, you can always compile R for JS/Linux ;).

Cheers,
Simon



> Devel source at https://github.com/gmbecker/RFirefox, release, (hopefully)
> officially cross-platform version to coincide with the paper going off for
> review.
> 
> I had toyed with the idea of the emscripten approach, but I think putting R
> in the browser once is enough for me at the moment so I will happily keep
> an eye on your project instead of attacking that myself :).
> 
> As for your actual question I can't really say, other than that I suspect
> you will not be able to dispense with base and methods, but that I would
> conjecture that stats is "optional".
> 
> ~G
> 
> 
> On Thu, May 2, 2013 at 9:12 AM, Jony Hudson <jony.hudson at imperial.ac.uk>wrote:
> 
>> Hi,
>> 
>> I'm trying to cross-compile R to javascript so that it can run in a
>> web-browser. Take as long as you need to stop laughing. So, as I was saying
>> - I want to try and get a build of R running in the browser. [If you're not
>> familiar with it already, you might enjoy looking at emscripten.org. It's
>> a remarkably capable tool for translating LLVM bitcode to javascript. Check
>> out some of the demos!]
>> 
>> I'm trying to start out with the most minimal build of R possible. I can
>> turn off various options in the configure script, but I'm wondering about
>> the bundled R packages (base, stats etc). I'm guessing that the native code
>> portions of these packages are dynamically loaded at runtime, which will
>> probably need patching. To start off, I'd like to not build these packages
>> if possible.
>> 
>> So, is there a way to configure which packages in the library get built or
>> is it just a case of editing the makefile? And is there a minimal set of
>> them that would still allow R to run (not be useful - that can come later -
>> just run)?
>> 
>> Thanks in advance for any help anyone can provide :-)
>> 
>> 
>> Jony
>> 
>> --
>> Centre for Cold Matter, The Blackett Laboratory,
>> Imperial College London, London SW7 2BW
>> T: +44 (0)207 5947741
>> http://www.imperial.ac.uk/people/jony.hudson
>> http://www.imperial.ac.uk/ccm/research/edm
>> http://www.monkeycruncher.org
>> http://j-star.org/
>> --
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
> 
> 
> 
> -- 
> Gabriel Becker
> Graduate Student
> Statistics Department
> University of California, Davis
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From rh at knut-krueger.de  Fri May  3 09:46:06 2013
From: rh at knut-krueger.de (Knut Krueger)
Date: Fri, 03 May 2013 09:46:06 +0200
Subject: [Rd] Latex errors  (build on windows)
Message-ID: <51836B3E.2040307@knut-krueger.de>

Where can I found hepl about latex errors:

the R CMD check tells me less, but:
* checking PDF version of manual ... WARNING
LaTeX errors when creating PDF version.
This typically indicates Rd problems.
* checking PDF version of manual without hyperrefs or index ... ERROR
Re-running with no redirection of stdout/stderr.
Hmm ... looks like a package
Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,  :
   pdflatex is not available
Error in running tools::texi2pdf()

The http://win-builder.r-project.org tells me more details but I am 
comlpetely lost

especially.:

LaTeX errors found:



  ! Paragraph ended before \hyper at n@rmalise was complete.
<to be read again>
                    \par
l.575 \end

  {ExampleCode}
! You can't use `macro parameter character #' in horizontal mode.
<argument> ...1,1,1,-1),stringsAsFactors=FALSE) ##
                                                   ## comment text in the examples ...
l.575 \end


{ExampleCode}
! Missing $ inserted.
<inserted text>
                 $
l.575 \end

Knut


From michael.weylandt at gmail.com  Fri May  3 09:58:02 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt)
Date: Fri, 3 May 2013 08:58:02 +0100
Subject: [Rd] Latex errors (build on windows)
In-Reply-To: <51836B3E.2040307@knut-krueger.de>
References: <51836B3E.2040307@knut-krueger.de>
Message-ID: <CAAmySGNfNwL0om7NQZpbMLDxmRtvVFTgWCE+YcqhhGxD1QX+fQ@mail.gmail.com>

Can you post the offending package?

On Fri, May 3, 2013 at 8:46 AM, Knut Krueger <rh at knut-krueger.de> wrote:
> Where can I found hepl about latex errors:
>
> the R CMD check tells me less, but:
> * checking PDF version of manual ... WARNING
> LaTeX errors when creating PDF version.
> This typically indicates Rd problems.
> * checking PDF version of manual without hyperrefs or index ... ERROR
> Re-running with no redirection of stdout/stderr.
> Hmm ... looks like a package
> Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,  :
>   pdflatex is not available
> Error in running tools::texi2pdf()
>
> The http://win-builder.r-project.org tells me more details but I am
> comlpetely lost
>
> especially.:
>
> LaTeX errors found:
>
>
>
>  ! Paragraph ended before \hyper at n@rmalise was complete.
> <to be read again>
>                    \par
> l.575 \end
>
>  {ExampleCode}
> ! You can't use `macro parameter character #' in horizontal mode.
> <argument> ...1,1,1,-1),stringsAsFactors=FALSE) ##
>                                                   ## comment text in the
> examples ...
> l.575 \end
>
>
> {ExampleCode}
> ! Missing $ inserted.
> <inserted text>
>                 $
> l.575 \end
>
> Knut
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From rh at knut-krueger.de  Fri May  3 11:15:00 2013
From: rh at knut-krueger.de (Knut Krueger)
Date: Fri, 03 May 2013 11:15:00 +0200
Subject: [Rd] Latex errors (build on windows)
In-Reply-To: <CAAmySGNfNwL0om7NQZpbMLDxmRtvVFTgWCE+YcqhhGxD1QX+fQ@mail.gmail.com>
References: <51836B3E.2040307@knut-krueger.de>
	<CAAmySGNfNwL0om7NQZpbMLDxmRtvVFTgWCE+YcqhhGxD1QX+fQ@mail.gmail.com>
Message-ID: <51838014.8070007@knut-krueger.de>

Am 03.05.2013 09:58, schrieb R. Michael Weylandt:
> Can you post the offending package?
http://rrepository.konstanze-krueger.de/src/contrib/Dominance_0.9.5.tar.gz

Knut


From murdoch.duncan at gmail.com  Fri May  3 13:03:36 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 03 May 2013 07:03:36 -0400
Subject: [Rd] Latex errors  (build on windows)
In-Reply-To: <51836B3E.2040307@knut-krueger.de>
References: <51836B3E.2040307@knut-krueger.de>
Message-ID: <51839988.30101@gmail.com>

On 13-05-03 3:46 AM, Knut Krueger wrote:
> Where can I found hepl about latex errors:
>
> the R CMD check tells me less, but:
> * checking PDF version of manual ... WARNING
> LaTeX errors when creating PDF version.
> This typically indicates Rd problems.
> * checking PDF version of manual without hyperrefs or index ... ERROR
> Re-running with no redirection of stdout/stderr.
> Hmm ... looks like a package
> Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,  :
>     pdflatex is not available

You should install MikTeX, from www.miktex.org.  I think it will put 
itself on your path, but if it does not, you need to make sure the 
miktex/bin directory is on your path.

> Error in running tools::texi2pdf()
>
> The http://win-builder.r-project.org tells me more details but I am
> comlpetely lost
>
> especially.:
>
> LaTeX errors found:
>
>
>
>    ! Paragraph ended before \hyper at n@rmalise was complete.
> <to be read again>
>                      \par
> l.575 \end
>
>    {ExampleCode}
> ! You can't use `macro parameter character #' in horizontal mode.
> <argument> ...1,1,1,-1),stringsAsFactors=FALSE) ##
>                                                     ## comment text in the examples ...
> l.575 \end
>
>
> {ExampleCode}
> ! Missing $ inserted.
> <inserted text>
>                   $
> l.575 \end

Once you have pdflatex available, you can run

R CMD Rd2pdf --no-clean <your pkg directory>

and it will likely give the same error, but will leave behind the files 
that caused the errors.  Take a look at line 575 (or whatever) of the 
.tex file, and you should be able to spot where it came from in your 
code.  Fix that if the problem is obvious, or show us.

Duncan Murdoch

>
> Knut
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From rh at knut-krueger.de  Fri May  3 15:12:37 2013
From: rh at knut-krueger.de (Knut Krueger)
Date: Fri, 03 May 2013 15:12:37 +0200
Subject: [Rd] Latex errors  (build on windows)
In-Reply-To: <51839988.30101@gmail.com>
References: <51836B3E.2040307@knut-krueger.de> <51839988.30101@gmail.com>
Message-ID: <5183B7C5.3090609@knut-krueger.de>

Am 03.05.2013 13:03, schrieb Duncan Murdoch:
>
> You should install MikTeX, from www.miktex.org.  I think it will put 
> itself on your path, but if it does not, you need to make sure the 
> miktex/bin directory is on your path.
>
Thank you, it worked
first with a strange error message:  File ended while scanning use of 
\Rhref.


there was a % in the DOI path of an URL


Knut


From therneau at mayo.edu  Fri May  3 15:21:45 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Fri, 03 May 2013 08:21:45 -0500
Subject: [Rd] loading of unwanted namespace
Message-ID: <5183B9E9.4050207@mayo.edu>

Martin,
  Your suggestion below did the trick.  The issue was obvious once this pointed me to the correct bit of code.
  Thanks much.

Terry T.


---- begin included text ---
    trace(loadNamespace, quote(if (package == "survival") recover()))

will break into ?recover when survival is being loaded.

Martin


From rh at knut-krueger.de  Fri May  3 15:22:35 2013
From: rh at knut-krueger.de (Knut Krueger)
Date: Fri, 03 May 2013 15:22:35 +0200
Subject: [Rd] Latex errors (build on windows)
In-Reply-To: <CAAmySGNfNwL0om7NQZpbMLDxmRtvVFTgWCE+YcqhhGxD1QX+fQ@mail.gmail.com>
References: <51836B3E.2040307@knut-krueger.de>
	<CAAmySGNfNwL0om7NQZpbMLDxmRtvVFTgWCE+YcqhhGxD1QX+fQ@mail.gmail.com>
Message-ID: <5183BA1B.4040207@knut-krueger.de>

Am 03.05.2013 09:58, schrieb R. Michael Weylandt:
> Can you post the offending package?

I solved the problem all is fine now, thanks


From murdoch.duncan at gmail.com  Fri May  3 15:29:18 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 03 May 2013 09:29:18 -0400
Subject: [Rd] Latex errors  (build on windows)
In-Reply-To: <5183B7C5.3090609@knut-krueger.de>
References: <51836B3E.2040307@knut-krueger.de> <51839988.30101@gmail.com>
	<5183B7C5.3090609@knut-krueger.de>
Message-ID: <5183BBAE.6050704@gmail.com>

On 03/05/2013 9:12 AM, Knut Krueger wrote:
> Am 03.05.2013 13:03, schrieb Duncan Murdoch:
> >
> > You should install MikTeX, from www.miktex.org.  I think it will put
> > itself on your path, but if it does not, you need to make sure the
> > miktex/bin directory is on your path.
> >
> Thank you, it worked
> first with a strange error message:  File ended while scanning use of
> \Rhref.
>
>
> there was a % in the DOI path of an URL

Percent signs are comment markers in .Rd files, so if you want to keep 
one, you need to escape it by preceding it with a backslash.

Duncan Murdoch


From rh at knut-krueger.de  Fri May  3 15:35:49 2013
From: rh at knut-krueger.de (Knut Krueger)
Date: Fri, 03 May 2013 15:35:49 +0200
Subject: [Rd] Latex errors  (build on windows)
In-Reply-To: <5183BBAE.6050704@gmail.com>
References: <51836B3E.2040307@knut-krueger.de> <51839988.30101@gmail.com>
	<5183B7C5.3090609@knut-krueger.de> <5183BBAE.6050704@gmail.com>
Message-ID: <5183BD35.2020601@knut-krueger.de>


> Percent signs are comment markers in .Rd files, so if you want to keep 
> one, you need to escape it by preceding it with a backslash.
>
I know but it was a copy and paste error ... I fixed it just in this way.
> Duncan Murdoch
>

by the way, what's the next step to get the files on an mirror .. if 
anybody is interested in that stuff?

Knut


From murdoch.duncan at gmail.com  Fri May  3 16:05:12 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 03 May 2013 10:05:12 -0400
Subject: [Rd] Latex errors  (build on windows)
In-Reply-To: <5183BD35.2020601@knut-krueger.de>
References: <51836B3E.2040307@knut-krueger.de> <51839988.30101@gmail.com>
	<5183B7C5.3090609@knut-krueger.de> <5183BBAE.6050704@gmail.com>
	<5183BD35.2020601@knut-krueger.de>
Message-ID: <5183C418.5070409@gmail.com>

On 03/05/2013 9:35 AM, Knut Krueger wrote:
> > Percent signs are comment markers in .Rd files, so if you want to keep
> > one, you need to escape it by preceding it with a backslash.
> >
> I know but it was a copy and paste error ... I fixed it just in this way.
> > Duncan Murdoch
> >
>
> by the way, what's the next step to get the files on an mirror .. if
> anybody is interested in that stuff?

There are several different systems that distribute packages.  The main 
one is CRAN.  Their policies and upload instructions are here:

http://cran.r-project.org/web/packages/policies.html

You might instead want to submit to Bioconductor, R-forge, Rforge, etc.

Duncan Murdoch


From rh at knut-krueger.de  Fri May  3 16:13:43 2013
From: rh at knut-krueger.de (Knut Krueger)
Date: Fri, 03 May 2013 16:13:43 +0200
Subject: [Rd] submiting a package [was]Latex errors  (build on windows)
In-Reply-To: <5183C418.5070409@gmail.com>
References: <51836B3E.2040307@knut-krueger.de> <51839988.30101@gmail.com>
	<5183B7C5.3090609@knut-krueger.de> <5183BBAE.6050704@gmail.com>
	<5183BD35.2020601@knut-krueger.de> <5183C418.5070409@gmail.com>
Message-ID: <5183C617.1090705@knut-krueger.de>

Am 03.05.2013 16:05, schrieb Duncan Murdoch:
> On 03/05/2013 9:35 AM, Knut Krueger wrote:
>> > Percent signs are comment markers in .Rd files, so if you want to keep
>> > one, you need to escape it by preceding it with a backslash.
>> >
>> I know but it was a copy and paste error ... I fixed it just in this 
>> way.
>> > Duncan Murdoch
>> >
>>
>> by the way, what's the next step to get the files on an mirror .. if
>> anybody is interested in that stuff?
>
> There are several different systems that distribute packages.  The 
> main one is CRAN.  Their policies and upload instructions are here:
>
> http://cran.r-project.org/web/packages/policies.html
>
> You might instead want to submit to Bioconductor, R-forge, Rforge, etc.
I don't know where is the best for that

the package is building an ADI (Average Dominance index) building a 
special sociogramm
with igraph, and building a Musicnotation graph 
http://dx.doi.org/10.1186%2F1742-9994-3-18

all three things are for calculating dominance hierarchies in animals.

Knut


From mauricio.zambrano at jrc.ec.europa.eu  Fri May  3 16:34:20 2013
From: mauricio.zambrano at jrc.ec.europa.eu (Mauricio Zambrano-Bigiarini)
Date: Fri, 03 May 2013 16:34:20 +0200
Subject: [Rd] Licence change
Message-ID: <5183CAEC.8080208@jrc.ec.europa.eu>

Dear list,

For the maintainer of a given package, is it possible to change the 
licence of a it from GPL >= 2 to GPL >= 3 ?

Thanks in advance,

Mauricio Zambrano-Bigiarini, Ph.D

-- 
=================================================
Water Resources Unit
Institute for Environment and Sustainability (IES)
Joint Research Centre (JRC), European Commission
TP 261, Via Enrico Fermi 2749, 21027 Ispra (VA), IT
webinfo    : http://floods.jrc.ec.europa.eu/
=================================================
DISCLAIMER:\ "The views expressed are purely those of th...{{dropped:9}}


From e.troup at epcc.ed.ac.uk  Fri May  3 14:55:41 2013
From: e.troup at epcc.ed.ac.uk (Eilidh Troup)
Date: Fri, 3 May 2013 13:55:41 +0100
Subject: [Rd] Package update for old version of R
Message-ID: <BAF57135-9591-4044-A471-15B9AB948452@epcc.ed.ac.uk>

Hi,

Is is possible to create a release of a package against an older version of R? I would like to release a new version of the package I maintain, but have some errors when I test it against R 3.0.0. Would CRAN accept a new release that works with R 2.15.3 but not R 3.0.0?

Thanks,
Eilidh Troup
-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From pdalgd at gmail.com  Fri May  3 16:47:02 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 3 May 2013 16:47:02 +0200
Subject: [Rd] Package update for old version of R
In-Reply-To: <BAF57135-9591-4044-A471-15B9AB948452@epcc.ed.ac.uk>
References: <BAF57135-9591-4044-A471-15B9AB948452@epcc.ed.ac.uk>
Message-ID: <413765D2-8D38-421F-BC10-1FFB4AA2F140@gmail.com>


On May 3, 2013, at 14:55 , Eilidh Troup wrote:

> Hi,
> 
> Is is possible to create a release of a package against an older version of R? I would like to release a new version of the package I maintain, but have some errors when I test it against R 3.0.0. Would CRAN accept a new release that works with R 2.15.3 but not R 3.0.0?

I strongly doubt it. By the CRAN logic, it would move immediately to the Archived folder, which is a fairly obscure place to have your users go look...

They're usually helpful in getting you to fix the errors, though.

-p

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From murdoch.duncan at gmail.com  Fri May  3 16:51:50 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 03 May 2013 10:51:50 -0400
Subject: [Rd] Licence change
In-Reply-To: <5183CAEC.8080208@jrc.ec.europa.eu>
References: <5183CAEC.8080208@jrc.ec.europa.eu>
Message-ID: <5183CF06.7010502@gmail.com>

On 03/05/2013 10:34 AM, Mauricio Zambrano-Bigiarini wrote:
> Dear list,
>
> For the maintainer of a given package, is it possible to change the
> licence of a it from GPL >= 2 to GPL >= 3 ?

Are you the author and copyright holder of everything in the package?  
If so, then I think the answer is yes.

If not, then what license did the author give you for the parts you 
didn't write?  You'll need to consult that, to find out if you can still 
distribute the code with a more restrictive license.  For example, if 
you're using some code that was licensed under GPL 2 (not GPL >= 2), 
then you need permission from the author of it to distribute it under a 
different license.

If you are distributing the package on CRAN, you'll have to ask them 
whether they'll still choose to distribute your package after the change.

Duncan Murdoch


From simon.urbanek at r-project.org  Fri May  3 16:56:20 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 3 May 2013 10:56:20 -0400
Subject: [Rd] Licence change
In-Reply-To: <5183CAEC.8080208@jrc.ec.europa.eu>
References: <5183CAEC.8080208@jrc.ec.europa.eu>
Message-ID: <303921F7-3702-46AA-922A-8F773F9002D8@r-project.org>


On May 3, 2013, at 10:34 AM, Mauricio Zambrano-Bigiarini wrote:

> Dear list,
> 
> For the maintainer of a given package, is it possible to change the licence of a it from GPL >= 2 to GPL >= 3 ?
> 

In general the maintainer has no such rights. However, if the maintainer is also the author and holds all copyright, he can release the package under any license he feels fit. What has been already released cannot be affected, obviously, but you can release a new version under a different license if you have the legal right to do so.

(This is not related to the possibility, but one practical problem with requiring GPL >=3 is that it is not GPL-2 compatible so it's a decision that better be made very consciously with all the consequences in mind).

Cheers,
Simon


> Thanks in advance,
> 
> Mauricio Zambrano-Bigiarini, Ph.D
> 
> -- 
> =================================================
> Water Resources Unit
> Institute for Environment and Sustainability (IES)
> Joint Research Centre (JRC), European Commission
> TP 261, Via Enrico Fermi 2749, 21027 Ispra (VA), IT
> webinfo    : http://floods.jrc.ec.europa.eu/
> =================================================
> DISCLAIMER:\ "The views expressed are purely those of th...{{dropped:9}}
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From jony.hudson at imperial.ac.uk  Fri May  3 17:21:00 2013
From: jony.hudson at imperial.ac.uk (Jony Hudson)
Date: Fri, 3 May 2013 16:21:00 +0100
Subject: [Rd] Minimal build of R ...
In-Reply-To: <D4B50715-13B1-461B-BC79-BA76738AE052@r-project.org>
References: <1D5CC664-B90A-444E-9389-9ED0ABC38999@imperial.ac.uk>
	<CADwqtCNY7EwsjNugJpOiOBSthGXRRnEiDDNPksHo0VAMLg3-+w@mail.gmail.com>
	<D4B50715-13B1-461B-BC79-BA76738AE052@r-project.org>
Message-ID: <06F05F34-7B2C-40AE-924F-8FA90516E21D@imperial.ac.uk>

Hi All,

 thanks for the replies. Very helpful to know that it will run with just base. Looks like the best bet, at least to get started, is to not use the usual build-process, but to come up with a simple build-script for just the core. Ultimately, the build script has to be different anyway, as compiling the Fortran code to JS requires a few more steps than the native compile.

For a bit of context, the reason I'm toying with this is I've been experimenting recently with analysis-in-the-browser. The kernel of the idea is that if you could do real analysis, without installing anything, and share it on the web then it would be a Good Thing, and could make it easier to engage people with data. I've got a proof-of-concept version running here http://www.monkeycruncher.org that let's you write javascript analysis code in notebook-style documents. It's neat, but it's a bit hamstrung by the lack of javascript libraries to actually do any useful analysis! If you could have R running in there though, that would be a much better proposition ...

I'll let you know if I make any progress!


Jony


--
Centre for Cold Matter, The Blackett Laboratory,
Imperial College London, London SW7 2BW
T: +44 (0)207 5947741
http://www.imperial.ac.uk/people/jony.hudson
http://www.imperial.ac.uk/ccm/research/edm
http://www.monkeycruncher.org
http://j-star.org/
--

On 3 May 2013, at 01:31, Simon Urbanek <simon.urbanek at r-project.org> wrote:

> On May 2, 2013, at 6:18 PM, Gabriel Becker wrote:
> 
>> Jony,
>> 
>> I'm currently writing up the paper for something with a similar result but
>> very different implementation. The RBrowserPlugin package/browser plugin
>> (joint with my advisor Duncan Temple Lang) embeds R within the web browser
>> as an NPAPI plugin.
>> 
>> This approach allows full bi-directional communication between R and the
>> javascript engine (including direct function calling and references to
>> native objects in both directions) using a user's existing local R
>> installation (including packages).
>> 
> 
> Minor detail: it requires you to have R *and* a special plugin which makes it pretty much non-deployable. It's completely unrelated to what Jony is proposing - which doesn't require any dependencies and is actually pretty cool and would be useful if feasible. FWIW: There are many ways to run R from a browser that already exist - without the need for plugins or other client-side hacks - that's the beauty of modern browsers :).
> 
> 
> To get this back on the actual topic: I have been toying with cross-compiling R when I was porting it on the iPhone and it's possible, however, you can't use the build process as-is. It does build core R properly, but the problem is that you need to bootstrap R to build any packages. I worked around the problem at the time by building packages on another platform and re-using those files (things like lazy-loaded DBs, compiled RD files etc.).
> 
> I can imagine that you'll need some equivalent to dynamic linking, but conceptually it's nothing else but calling functions, so I think you should be able to compile each package separately and just replace the dynload code by code that loads another JavaScript. The nice thing is that packages will simply be just another JS libraries. That's all in theory, I didn't actually try that part. I suspect you'll have a lot of work, e.g. you'll need to map all the I/O operations that load compiled/stored R code, documentation, data from somewhere etc. Good luck!
> If all fails, you can always compile R for JS/Linux ;).
> 
> Cheers,
> Simon
> 
> 
> 
>> Devel source at https://github.com/gmbecker/RFirefox, release, (hopefully)
>> officially cross-platform version to coincide with the paper going off for
>> review.
>> 
>> I had toyed with the idea of the emscripten approach, but I think putting R
>> in the browser once is enough for me at the moment so I will happily keep
>> an eye on your project instead of attacking that myself :).
>> 
>> As for your actual question I can't really say, other than that I suspect
>> you will not be able to dispense with base and methods, but that I would
>> conjecture that stats is "optional".
>> 
>> ~G
>> 
>> 
>> On Thu, May 2, 2013 at 9:12 AM, Jony Hudson <jony.hudson at imperial.ac.uk>wrote:
>> 
>>> Hi,
>>> 
>>> I'm trying to cross-compile R to javascript so that it can run in a
>>> web-browser. Take as long as you need to stop laughing. So, as I was saying
>>> - I want to try and get a build of R running in the browser. [If you're not
>>> familiar with it already, you might enjoy looking at emscripten.org. It's
>>> a remarkably capable tool for translating LLVM bitcode to javascript. Check
>>> out some of the demos!]
>>> 
>>> I'm trying to start out with the most minimal build of R possible. I can
>>> turn off various options in the configure script, but I'm wondering about
>>> the bundled R packages (base, stats etc). I'm guessing that the native code
>>> portions of these packages are dynamically loaded at runtime, which will
>>> probably need patching. To start off, I'd like to not build these packages
>>> if possible.
>>> 
>>> So, is there a way to configure which packages in the library get built or
>>> is it just a case of editing the makefile? And is there a minimal set of
>>> them that would still allow R to run (not be useful - that can come later -
>>> just run)?
>>> 
>>> Thanks in advance for any help anyone can provide :-)
>>> 
>>> 
>>> Jony
>>> 
>>> --
>>> Centre for Cold Matter, The Blackett Laboratory,
>>> Imperial College London, London SW7 2BW
>>> T: +44 (0)207 5947741
>>> http://www.imperial.ac.uk/people/jony.hudson
>>> http://www.imperial.ac.uk/ccm/research/edm
>>> http://www.monkeycruncher.org
>>> http://j-star.org/
>>> --
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>> 
>> 
>> 
>> -- 
>> Gabriel Becker
>> Graduate Student
>> Statistics Department
>> University of California, Davis
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> 
> 


From mauricio.zambrano at jrc.ec.europa.eu  Fri May  3 17:31:41 2013
From: mauricio.zambrano at jrc.ec.europa.eu (Mauricio Zambrano-Bigiarini)
Date: Fri, 03 May 2013 17:31:41 +0200
Subject: [Rd] Licence change
In-Reply-To: <303921F7-3702-46AA-922A-8F773F9002D8@r-project.org>
References: <5183CAEC.8080208@jrc.ec.europa.eu>
	<303921F7-3702-46AA-922A-8F773F9002D8@r-project.org>
Message-ID: <5183D85D.2000103@jrc.ec.europa.eu>


On 03/05/13 16:56, Simon Urbanek wrote:
>
> On May 3, 2013, at 10:34 AM, Mauricio Zambrano-Bigiarini wrote:
>
>> Dear list,
>>
>> For the maintainer of a given package, is it possible to change the licence of a it from GPL >= 2 to GPL >= 3 ?
>>
>
> In general the maintainer has no such rights. However, if the maintainer is also the author and holds all copyright, he can release the package under any license he feels fit. What has been already released cannot be affected, obviously, but you can release a new version under a different license if you have the legal right to do so.

Thank you very much Duncan and Simon for your replies.

The package I'm asking about has 1 author [aut] (me) and 1 contributor 
[ctb] in the 'Author' field of the DESCRIPTION file. Both of them hold 
the copyright of the package.

In case we want to change the licence. Do the 2 authors write something 
particular in the next submission to CRAN ?
Do we need to provide some written document to CRAN ?


What Duncan means with
"If you are distributing the package on CRAN, you'll have to ask them 
whether they'll still choose to distribute your package after the change"

May CRAN to decide not to distribute the package because of the change 
in the licence ?


>
> (This is not related to the possibility, but one practical problem with requiring GPL >=3 is that it is not GPL-2 compatible so it's a decision that better be made very consciously with all the consequences in mind).

If the package we are talking about is pure R code, with only some 
dependencies to other R packages, what are the implications of:

" one practical problem with requiring GPL >=3 is that it is not GPL-2 
compatible"


Thanks again,

Mauricio

-- 
=================================================
Linux user #454569 -- Ubuntu user #17469
=================================================
"Study, Practice and Teach" (Jim Rohn)


From gmbecker at ucdavis.edu  Fri May  3 17:46:07 2013
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Fri, 3 May 2013 08:46:07 -0700
Subject: [Rd] Minimal build of R ...
In-Reply-To: <06F05F34-7B2C-40AE-924F-8FA90516E21D@imperial.ac.uk>
References: <1D5CC664-B90A-444E-9389-9ED0ABC38999@imperial.ac.uk>
	<CADwqtCNY7EwsjNugJpOiOBSthGXRRnEiDDNPksHo0VAMLg3-+w@mail.gmail.com>
	<D4B50715-13B1-461B-BC79-BA76738AE052@r-project.org>
	<06F05F34-7B2C-40AE-924F-8FA90516E21D@imperial.ac.uk>
Message-ID: <CADwqtCMsrbNHY=3Y-+8HvwM-_km-60dacZ9pqQC12CzU99=eWQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130503/1dc3b0cc/attachment.pl>

From jony.hudson at imperial.ac.uk  Fri May  3 18:13:03 2013
From: jony.hudson at imperial.ac.uk (Jony Hudson)
Date: Fri, 3 May 2013 17:13:03 +0100
Subject: [Rd] Minimal build of R ...
In-Reply-To: <CADwqtCMsrbNHY=3Y-+8HvwM-_km-60dacZ9pqQC12CzU99=eWQ@mail.gmail.com>
References: <1D5CC664-B90A-444E-9389-9ED0ABC38999@imperial.ac.uk>
	<CADwqtCNY7EwsjNugJpOiOBSthGXRRnEiDDNPksHo0VAMLg3-+w@mail.gmail.com>
	<D4B50715-13B1-461B-BC79-BA76738AE052@r-project.org>
	<06F05F34-7B2C-40AE-924F-8FA90516E21D@imperial.ac.uk>
	<CADwqtCMsrbNHY=3Y-+8HvwM-_km-60dacZ9pqQC12CzU99=eWQ@mail.gmail.com>
Message-ID: <19E9BBBD-1D5B-43DE-8A33-350F0A3D6036@imperial.ac.uk>

Hi Gabriel,

 yes, packages obviously contain all the good stuff, but need to start somewhere!

The ipython notebook project is very impressive, and I've been keeping a close eye on it, although I started out on monkeycruncher long before I was aware of it (I make slow progress). I guess I think of my thing as an experiment in just how much can be done purely in the web client. There are some advantages to pure client-side (rich interactivity, no need for a server, ubiquity) which make it interesting, but it might be a bit "too soon" to be useful!


Jony


--
Centre for Cold Matter, The Blackett Laboratory,
Imperial College London, London SW7 2BW
T: +44 (0)207 5947741
http://www.imperial.ac.uk/people/jony.hudson
http://www.imperial.ac.uk/ccm/research/edm
http://www.monkeycruncher.org
http://j-star.org/
--

On 3 May 2013, at 16:46, Gabriel Becker <gmbecker at ucdavis.edu> wrote:

> Jony,
> 
> I would caution that while R will run with just base, you won't be able to do much of anything with it. All the statistical analysis and graphing functions reside in additional packages. So practically speaking you'll need the workarounds Simon mentioned involving an alternative to dyn.load so you can attach additional packages. Your project looks pretty cool though!
> 
> Also, as an aside have you seen the ipython notebook ( http://ipython.org/ipython-doc/dev/interactive/htmlnotebook.html )? It doesn't meet your requirement of not installing anything, and currently has a slightly different focus, but the appearance of the documents is very similar to what you are doing here (other than being server based), and it already understands multiple languages, including python, R, matlab, octave, etc and is being actively developed and supported.
> 
> ~G
> 
> 
> On Fri, May 3, 2013 at 8:21 AM, Jony Hudson <jony.hudson at imperial.ac.uk> wrote:
> Hi All,
> 
>  thanks for the replies. Very helpful to know that it will run with just base. Looks like the best bet, at least to get started, is to not use the usual build-process, but to come up with a simple build-script for just the core. Ultimately, the build script has to be different anyway, as compiling the Fortran code to JS requires a few more steps than the native compile.
> 
> For a bit of context, the reason I'm toying with this is I've been experimenting recently with analysis-in-the-browser. The kernel of the idea is that if you could do real analysis, without installing anything, and share it on the web then it would be a Good Thing, and could make it easier to engage people with data. I've got a proof-of-concept version running here http://www.monkeycruncher.org that let's you write javascript analysis code in notebook-style documents. It's neat, but it's a bit hamstrung by the lack of javascript libraries to actually do any useful analysis! If you could have R running in there though, that would be a much better proposition ...
> 
> I'll let you know if I make any progress!
> 
> 
> Jony
> 
> 
> --
> Centre for Cold Matter, The Blackett Laboratory,
> Imperial College London, London SW7 2BW
> T: +44 (0)207 5947741
> http://www.imperial.ac.uk/people/jony.hudson
> http://www.imperial.ac.uk/ccm/research/edm
> http://www.monkeycruncher.org
> http://j-star.org/
> --
> 
> On 3 May 2013, at 01:31, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> 
> > On May 2, 2013, at 6:18 PM, Gabriel Becker wrote:
> >
> >> Jony,
> >>
> >> I'm currently writing up the paper for something with a similar result but
> >> very different implementation. The RBrowserPlugin package/browser plugin
> >> (joint with my advisor Duncan Temple Lang) embeds R within the web browser
> >> as an NPAPI plugin.
> >>
> >> This approach allows full bi-directional communication between R and the
> >> javascript engine (including direct function calling and references to
> >> native objects in both directions) using a user's existing local R
> >> installation (including packages).
> >>
> >
> > Minor detail: it requires you to have R *and* a special plugin which makes it pretty much non-deployable. It's completely unrelated to what Jony is proposing - which doesn't require any dependencies and is actually pretty cool and would be useful if feasible. FWIW: There are many ways to run R from a browser that already exist - without the need for plugins or other client-side hacks - that's the beauty of modern browsers :).
> >
> >
> > To get this back on the actual topic: I have been toying with cross-compiling R when I was porting it on the iPhone and it's possible, however, you can't use the build process as-is. It does build core R properly, but the problem is that you need to bootstrap R to build any packages. I worked around the problem at the time by building packages on another platform and re-using those files (things like lazy-loaded DBs, compiled RD files etc.).
> >
> > I can imagine that you'll need some equivalent to dynamic linking, but conceptually it's nothing else but calling functions, so I think you should be able to compile each package separately and just replace the dynload code by code that loads another JavaScript. The nice thing is that packages will simply be just another JS libraries. That's all in theory, I didn't actually try that part. I suspect you'll have a lot of work, e.g. you'll need to map all the I/O operations that load compiled/stored R code, documentation, data from somewhere etc. Good luck!
> > If all fails, you can always compile R for JS/Linux ;).
> >
> > Cheers,
> > Simon
> >
> >
> >
> >> Devel source at https://github.com/gmbecker/RFirefox, release, (hopefully)
> >> officially cross-platform version to coincide with the paper going off for
> >> review.
> >>
> >> I had toyed with the idea of the emscripten approach, but I think putting R
> >> in the browser once is enough for me at the moment so I will happily keep
> >> an eye on your project instead of attacking that myself :).
> >>
> >> As for your actual question I can't really say, other than that I suspect
> >> you will not be able to dispense with base and methods, but that I would
> >> conjecture that stats is "optional".
> >>
> >> ~G
> >>
> >>
> >> On Thu, May 2, 2013 at 9:12 AM, Jony Hudson <jony.hudson at imperial.ac.uk>wrote:
> >>
> >>> Hi,
> >>>
> >>> I'm trying to cross-compile R to javascript so that it can run in a
> >>> web-browser. Take as long as you need to stop laughing. So, as I was saying
> >>> - I want to try and get a build of R running in the browser. [If you're not
> >>> familiar with it already, you might enjoy looking at emscripten.org. It's
> >>> a remarkably capable tool for translating LLVM bitcode to javascript. Check
> >>> out some of the demos!]
> >>>
> >>> I'm trying to start out with the most minimal build of R possible. I can
> >>> turn off various options in the configure script, but I'm wondering about
> >>> the bundled R packages (base, stats etc). I'm guessing that the native code
> >>> portions of these packages are dynamically loaded at runtime, which will
> >>> probably need patching. To start off, I'd like to not build these packages
> >>> if possible.
> >>>
> >>> So, is there a way to configure which packages in the library get built or
> >>> is it just a case of editing the makefile? And is there a minimal set of
> >>> them that would still allow R to run (not be useful - that can come later -
> >>> just run)?
> >>>
> >>> Thanks in advance for any help anyone can provide :-)
> >>>
> >>>
> >>> Jony
> >>>
> >>> --
> >>> Centre for Cold Matter, The Blackett Laboratory,
> >>> Imperial College London, London SW7 2BW
> >>> T: +44 (0)207 5947741
> >>> http://www.imperial.ac.uk/people/jony.hudson
> >>> http://www.imperial.ac.uk/ccm/research/edm
> >>> http://www.monkeycruncher.org
> >>> http://j-star.org/
> >>> --
> >>>
> >>> ______________________________________________
> >>> R-devel at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>
> >>
> >>
> >>
> >> --
> >> Gabriel Becker
> >> Graduate Student
> >> Statistics Department
> >> University of California, Davis
> >>
> >>      [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >>
> >
> 
> 
> 
> 
> -- 
> Gabriel Becker
> Graduate Student
> Statistics Department
> University of California, Davis


From murdoch.duncan at gmail.com  Fri May  3 18:42:03 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 03 May 2013 12:42:03 -0400
Subject: [Rd] Licence change
In-Reply-To: <5183D85D.2000103@jrc.ec.europa.eu>
References: <5183CAEC.8080208@jrc.ec.europa.eu>
	<303921F7-3702-46AA-922A-8F773F9002D8@r-project.org>
	<5183D85D.2000103@jrc.ec.europa.eu>
Message-ID: <5183E8DB.7040206@gmail.com>

On 03/05/2013 11:31 AM, Mauricio Zambrano-Bigiarini wrote:
> On 03/05/13 16:56, Simon Urbanek wrote:
> >
> > On May 3, 2013, at 10:34 AM, Mauricio Zambrano-Bigiarini wrote:
> >
> >> Dear list,
> >>
> >> For the maintainer of a given package, is it possible to change the licence of a it from GPL >= 2 to GPL >= 3 ?
> >>
> >
> > In general the maintainer has no such rights. However, if the maintainer is also the author and holds all copyright, he can release the package under any license he feels fit. What has been already released cannot be affected, obviously, but you can release a new version under a different license if you have the legal right to do so.
>
> Thank you very much Duncan and Simon for your replies.
>
> The package I'm asking about has 1 author [aut] (me) and 1 contributor
> [ctb] in the 'Author' field of the DESCRIPTION file. Both of them hold
> the copyright of the package.
>
> In case we want to change the licence. Do the 2 authors write something
> particular in the next submission to CRAN ?
> Do we need to provide some written document to CRAN ?
>
>
> What Duncan means with
> "If you are distributing the package on CRAN, you'll have to ask them
> whether they'll still choose to distribute your package after the change"
>
> May CRAN to decide not to distribute the package because of the change
> in the licence ?

You'll have to ask them that.
>
>
> >
> > (This is not related to the possibility, but one practical problem with requiring GPL >=3 is that it is not GPL-2 compatible so it's a decision that better be made very consciously with all the consequences in mind).
>
> If the package we are talking about is pure R code, with only some
> dependencies to other R packages, what are the implications of:
>
> " one practical problem with requiring GPL >=3 is that it is not GPL-2
> compatible"

It may mean that one of your users won't be able to use the package, for 
example if something else that they need requires GPL-2 licensing.

Duncan Murdoch


From gmbecker at ucdavis.edu  Fri May  3 18:52:52 2013
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Fri, 3 May 2013 09:52:52 -0700
Subject: [Rd] Minimal build of R ...
In-Reply-To: <19E9BBBD-1D5B-43DE-8A33-350F0A3D6036@imperial.ac.uk>
References: <1D5CC664-B90A-444E-9389-9ED0ABC38999@imperial.ac.uk>
	<CADwqtCNY7EwsjNugJpOiOBSthGXRRnEiDDNPksHo0VAMLg3-+w@mail.gmail.com>
	<D4B50715-13B1-461B-BC79-BA76738AE052@r-project.org>
	<06F05F34-7B2C-40AE-924F-8FA90516E21D@imperial.ac.uk>
	<CADwqtCMsrbNHY=3Y-+8HvwM-_km-60dacZ9pqQC12CzU99=eWQ@mail.gmail.com>
	<19E9BBBD-1D5B-43DE-8A33-350F0A3D6036@imperial.ac.uk>
Message-ID: <CADwqtCMqDOvpXHujdYjAU4ixj38+X9Aq3+kej0_ACLtvsYA1FA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130503/d4a47044/attachment.pl>

From simon.urbanek at r-project.org  Fri May  3 19:11:26 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 3 May 2013 13:11:26 -0400
Subject: [Rd] Minimal build of R ...
In-Reply-To: <06F05F34-7B2C-40AE-924F-8FA90516E21D@imperial.ac.uk>
References: <1D5CC664-B90A-444E-9389-9ED0ABC38999@imperial.ac.uk>
	<CADwqtCNY7EwsjNugJpOiOBSthGXRRnEiDDNPksHo0VAMLg3-+w@mail.gmail.com>
	<D4B50715-13B1-461B-BC79-BA76738AE052@r-project.org>
	<06F05F34-7B2C-40AE-924F-8FA90516E21D@imperial.ac.uk>
Message-ID: <6A17E389-E9A0-48B8-AFBF-28F27BFF85BE@r-project.org>


On May 3, 2013, at 11:21 AM, Jony Hudson wrote:

> Hi All,
> 
> thanks for the replies. Very helpful to know that it will run with just base. Looks like the best bet, at least to get started, is to not use the usual build-process, but to come up with a simple build-script for just the core. Ultimately, the build script has to be different anyway, as compiling the Fortran code to JS requires a few more steps than the native compile.
> 
> For a bit of context, the reason I'm toying with this is I've been experimenting recently with analysis-in-the-browser. The kernel of the idea is that if you could do real analysis, without installing anything, and share it on the web then it would be a Good Thing, and could make it easier to engage people with data. I've got a proof-of-concept version running here http://www.monkeycruncher.org that let's you write javascript analysis code in notebook-style documents. It's neat, but it's a bit hamstrung by the lack of javascript libraries to actually do any useful analysis! If you could have R running in there though, that would be a much better proposition ...
> 

It seems that you want something not unlike RCloud
http://stats.research.att.com/RCloud/
It uses WebSockets to talk to R either locally or on a server. The nice thing about using WS is that you can leverage large clusters - are not tied to the local machine. Also it allows you to get the benefits of both worlds: R for computation + static graphics while allowing you do to cool interactive graphics in JavaScript. RCloud is something like iPython notebook but based on R with extra interactive graphics. But this is getting OT ;).

Cheers,
Simon



> I'll let you know if I make any progress!
> 
> 
> Jony
> 
> 
> --
> Centre for Cold Matter, The Blackett Laboratory,
> Imperial College London, London SW7 2BW
> T: +44 (0)207 5947741
> http://www.imperial.ac.uk/people/jony.hudson
> http://www.imperial.ac.uk/ccm/research/edm
> http://www.monkeycruncher.org
> http://j-star.org/
> --
> 
> On 3 May 2013, at 01:31, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> 
>> On May 2, 2013, at 6:18 PM, Gabriel Becker wrote:
>> 
>>> Jony,
>>> 
>>> I'm currently writing up the paper for something with a similar result but
>>> very different implementation. The RBrowserPlugin package/browser plugin
>>> (joint with my advisor Duncan Temple Lang) embeds R within the web browser
>>> as an NPAPI plugin.
>>> 
>>> This approach allows full bi-directional communication between R and the
>>> javascript engine (including direct function calling and references to
>>> native objects in both directions) using a user's existing local R
>>> installation (including packages).
>>> 
>> 
>> Minor detail: it requires you to have R *and* a special plugin which makes it pretty much non-deployable. It's completely unrelated to what Jony is proposing - which doesn't require any dependencies and is actually pretty cool and would be useful if feasible. FWIW: There are many ways to run R from a browser that already exist - without the need for plugins or other client-side hacks - that's the beauty of modern browsers :).
>> 
>> 
>> To get this back on the actual topic: I have been toying with cross-compiling R when I was porting it on the iPhone and it's possible, however, you can't use the build process as-is. It does build core R properly, but the problem is that you need to bootstrap R to build any packages. I worked around the problem at the time by building packages on another platform and re-using those files (things like lazy-loaded DBs, compiled RD files etc.).
>> 
>> I can imagine that you'll need some equivalent to dynamic linking, but conceptually it's nothing else but calling functions, so I think you should be able to compile each package separately and just replace the dynload code by code that loads another JavaScript. The nice thing is that packages will simply be just another JS libraries. That's all in theory, I didn't actually try that part. I suspect you'll have a lot of work, e.g. you'll need to map all the I/O operations that load compiled/stored R code, documentation, data from somewhere etc. Good luck!
>> If all fails, you can always compile R for JS/Linux ;).
>> 
>> Cheers,
>> Simon
>> 
>> 
>> 
>>> Devel source at https://github.com/gmbecker/RFirefox, release, (hopefully)
>>> officially cross-platform version to coincide with the paper going off for
>>> review.
>>> 
>>> I had toyed with the idea of the emscripten approach, but I think putting R
>>> in the browser once is enough for me at the moment so I will happily keep
>>> an eye on your project instead of attacking that myself :).
>>> 
>>> As for your actual question I can't really say, other than that I suspect
>>> you will not be able to dispense with base and methods, but that I would
>>> conjecture that stats is "optional".
>>> 
>>> ~G
>>> 
>>> 
>>> On Thu, May 2, 2013 at 9:12 AM, Jony Hudson <jony.hudson at imperial.ac.uk>wrote:
>>> 
>>>> Hi,
>>>> 
>>>> I'm trying to cross-compile R to javascript so that it can run in a
>>>> web-browser. Take as long as you need to stop laughing. So, as I was saying
>>>> - I want to try and get a build of R running in the browser. [If you're not
>>>> familiar with it already, you might enjoy looking at emscripten.org. It's
>>>> a remarkably capable tool for translating LLVM bitcode to javascript. Check
>>>> out some of the demos!]
>>>> 
>>>> I'm trying to start out with the most minimal build of R possible. I can
>>>> turn off various options in the configure script, but I'm wondering about
>>>> the bundled R packages (base, stats etc). I'm guessing that the native code
>>>> portions of these packages are dynamically loaded at runtime, which will
>>>> probably need patching. To start off, I'd like to not build these packages
>>>> if possible.
>>>> 
>>>> So, is there a way to configure which packages in the library get built or
>>>> is it just a case of editing the makefile? And is there a minimal set of
>>>> them that would still allow R to run (not be useful - that can come later -
>>>> just run)?
>>>> 
>>>> Thanks in advance for any help anyone can provide :-)
>>>> 
>>>> 
>>>> Jony
>>>> 
>>>> --
>>>> Centre for Cold Matter, The Blackett Laboratory,
>>>> Imperial College London, London SW7 2BW
>>>> T: +44 (0)207 5947741
>>>> http://www.imperial.ac.uk/people/jony.hudson
>>>> http://www.imperial.ac.uk/ccm/research/edm
>>>> http://www.monkeycruncher.org
>>>> http://j-star.org/
>>>> --
>>>> 
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> 
>>> 
>>> 
>>> 
>>> -- 
>>> Gabriel Becker
>>> Graduate Student
>>> Statistics Department
>>> University of California, Davis
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>> 
>> 
> 
> 


From simon.urbanek at r-project.org  Fri May  3 19:52:57 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 3 May 2013 13:52:57 -0400
Subject: [Rd] Minimal build of R ...
In-Reply-To: <CADwqtCMqDOvpXHujdYjAU4ixj38+X9Aq3+kej0_ACLtvsYA1FA@mail.gmail.com>
References: <1D5CC664-B90A-444E-9389-9ED0ABC38999@imperial.ac.uk>
	<CADwqtCNY7EwsjNugJpOiOBSthGXRRnEiDDNPksHo0VAMLg3-+w@mail.gmail.com>
	<D4B50715-13B1-461B-BC79-BA76738AE052@r-project.org>
	<06F05F34-7B2C-40AE-924F-8FA90516E21D@imperial.ac.uk>
	<CADwqtCMsrbNHY=3Y-+8HvwM-_km-60dacZ9pqQC12CzU99=eWQ@mail.gmail.com>
	<19E9BBBD-1D5B-43DE-8A33-350F0A3D6036@imperial.ac.uk>
	<CADwqtCMqDOvpXHujdYjAU4ixj38+X9Aq3+kej0_ACLtvsYA1FA@mail.gmail.com>
Message-ID: <08C4ED64-00FA-4942-B270-0C1098EA4BF8@r-project.org>


On May 3, 2013, at 12:52 PM, Gabriel Becker wrote:

> On Fri, May 3, 2013 at 9:13 AM, Jony Hudson <jony.hudson at imperial.ac.uk> wrote:
> ... I guess I think of my thing as an experiment in just how much can be done purely in the web client. There are some advantages to pure client-side (rich interactivity, no need for a server, ubiquity) which make it interesting,
> 
> I completely agree. Added to that list, depending on implementation of course, are direct control of the DOM via R code (allowing statisticians to script entire pages using a language they are more comfortable with), the use of R functions directly as event handlers, including for super high-frequency events such as mousemove (which is infeasible in server based approaches due to the required round-trip), and interactive versions of actual R plots (drawn with standard R plotting code), drawn directly to the page via graphics devices which draw primitives via Javascript, among other things
> 

This has been attempted quite a few times - literally by the canvas package (in generates JavaScript) and in more general terms by using SVG (this was way back when it was en vogue). The problem is that by design R plots lack the link between data and the objects drawn so you can only add a small amount of interactivity to very specific plots by hand-crafing the links or by trying to apply some heuristics, but it doesn't work in general. That's why all the web-baed interactive graphics typically do it the other way around - define JS-based primitives with interactions and build plots from this. You actually get nice interactive graphics, but you can't re-use R-based graphics (other than re-drawing it interactively, but that's another story).

Cheers,
Simon


> As you can probably tell, I have thought a bit about this :)
> 
> I feel that client-side approaches have a lot of value and can stand alongside server-based approaches. Each approach type has different advantages and disadvantages, neither dominating the other across all scenarios.
> 
> I will be watching your project with interest.
> 
> ~G
> 
> 
> 
> Jony
> 
> 
> --
> Centre for Cold Matter, The Blackett Laboratory,
> Imperial College London, London SW7 2BW
> T: +44 (0)207 5947741
> http://www.imperial.ac.uk/people/jony.hudson
> http://www.imperial.ac.uk/ccm/research/edm
> http://www.monkeycruncher.org
> http://j-star.org/
> --
> 
> On 3 May 2013, at 16:46, Gabriel Becker <gmbecker at ucdavis.edu> wrote:
> 
> > Jony,
> >
> > I would caution that while R will run with just base, you won't be able to do much of anything with it. All the statistical analysis and graphing functions reside in additional packages. So practically speaking you'll need the workarounds Simon mentioned involving an alternative to dyn.load so you can attach additional packages. Your project looks pretty cool though!
> >
> > Also, as an aside have you seen the ipython notebook ( http://ipython.org/ipython-doc/dev/interactive/htmlnotebook.html )? It doesn't meet your requirement of not installing anything, and currently has a slightly different focus, but the appearance of the documents is very similar to what you are doing here (other than being server based), and it already understands multiple languages, including python, R, matlab, octave, etc and is being actively developed and supported.
> >
> > ~G
> >
> >
> > On Fri, May 3, 2013 at 8:21 AM, Jony Hudson <jony.hudson at imperial.ac.uk> wrote:
> > Hi All,
> >
> >  thanks for the replies. Very helpful to know that it will run with just base. Looks like the best bet, at least to get started, is to not use the usual build-process, but to come up with a simple build-script for just the core. Ultimately, the build script has to be different anyway, as compiling the Fortran code to JS requires a few more steps than the native compile.
> >
> > For a bit of context, the reason I'm toying with this is I've been experimenting recently with analysis-in-the-browser. The kernel of the idea is that if you could do real analysis, without installing anything, and share it on the web then it would be a Good Thing, and could make it easier to engage people with data. I've got a proof-of-concept version running here http://www.monkeycruncher.org that let's you write javascript analysis code in notebook-style documents. It's neat, but it's a bit hamstrung by the lack of javascript libraries to actually do any useful analysis! If you could have R running in there though, that would be a much better proposition ...
> >
> > I'll let you know if I make any progress!
> >
> >
> > Jony
> >
> >
> > --
> > Centre for Cold Matter, The Blackett Laboratory,
> > Imperial College London, London SW7 2BW
> > T: +44 (0)207 5947741
> > http://www.imperial.ac.uk/people/jony.hudson
> > http://www.imperial.ac.uk/ccm/research/edm
> > http://www.monkeycruncher.org
> > http://j-star.org/
> > --
> >
> > On 3 May 2013, at 01:31, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> >
> > > On May 2, 2013, at 6:18 PM, Gabriel Becker wrote:
> > >
> > >> Jony,
> > >>
> > >> I'm currently writing up the paper for something with a similar result but
> > >> very different implementation. The RBrowserPlugin package/browser plugin
> > >> (joint with my advisor Duncan Temple Lang) embeds R within the web browser
> > >> as an NPAPI plugin.
> > >>
> > >> This approach allows full bi-directional communication between R and the
> > >> javascript engine (including direct function calling and references to
> > >> native objects in both directions) using a user's existing local R
> > >> installation (including packages).
> > >>
> > >
> > > Minor detail: it requires you to have R *and* a special plugin which makes it pretty much non-deployable. It's completely unrelated to what Jony is proposing - which doesn't require any dependencies and is actually pretty cool and would be useful if feasible. FWIW: There are many ways to run R from a browser that already exist - without the need for plugins or other client-side hacks - that's the beauty of modern browsers :).
> > >
> > >
> > > To get this back on the actual topic: I have been toying with cross-compiling R when I was porting it on the iPhone and it's possible, however, you can't use the build process as-is. It does build core R properly, but the problem is that you need to bootstrap R to build any packages. I worked around the problem at the time by building packages on another platform and re-using those files (things like lazy-loaded DBs, compiled RD files etc.).
> > >
> > > I can imagine that you'll need some equivalent to dynamic linking, but conceptually it's nothing else but calling functions, so I think you should be able to compile each package separately and just replace the dynload code by code that loads another JavaScript. The nice thing is that packages will simply be just another JS libraries. That's all in theory, I didn't actually try that part. I suspect you'll have a lot of work, e.g. you'll need to map all the I/O operations that load compiled/stored R code, documentation, data from somewhere etc. Good luck!
> > > If all fails, you can always compile R for JS/Linux ;).
> > >
> > > Cheers,
> > > Simon
> > >
> > >
> > >
> > >> Devel source at https://github.com/gmbecker/RFirefox, release, (hopefully)
> > >> officially cross-platform version to coincide with the paper going off for
> > >> review.
> > >>
> > >> I had toyed with the idea of the emscripten approach, but I think putting R
> > >> in the browser once is enough for me at the moment so I will happily keep
> > >> an eye on your project instead of attacking that myself :).
> > >>
> > >> As for your actual question I can't really say, other than that I suspect
> > >> you will not be able to dispense with base and methods, but that I would
> > >> conjecture that stats is "optional".
> > >>
> > >> ~G
> > >>
> > >>
> > >> On Thu, May 2, 2013 at 9:12 AM, Jony Hudson <jony.hudson at imperial.ac.uk>wrote:
> > >>
> > >>> Hi,
> > >>>
> > >>> I'm trying to cross-compile R to javascript so that it can run in a
> > >>> web-browser. Take as long as you need to stop laughing. So, as I was saying
> > >>> - I want to try and get a build of R running in the browser. [If you're not
> > >>> familiar with it already, you might enjoy looking at emscripten.org. It's
> > >>> a remarkably capable tool for translating LLVM bitcode to javascript. Check
> > >>> out some of the demos!]
> > >>>
> > >>> I'm trying to start out with the most minimal build of R possible. I can
> > >>> turn off various options in the configure script, but I'm wondering about
> > >>> the bundled R packages (base, stats etc). I'm guessing that the native code
> > >>> portions of these packages are dynamically loaded at runtime, which will
> > >>> probably need patching. To start off, I'd like to not build these packages
> > >>> if possible.
> > >>>
> > >>> So, is there a way to configure which packages in the library get built or
> > >>> is it just a case of editing the makefile? And is there a minimal set of
> > >>> them that would still allow R to run (not be useful - that can come later -
> > >>> just run)?
> > >>>
> > >>> Thanks in advance for any help anyone can provide :-)
> > >>>
> > >>>
> > >>> Jony
> > >>>
> > >>> --
> > >>> Centre for Cold Matter, The Blackett Laboratory,
> > >>> Imperial College London, London SW7 2BW
> > >>> T: +44 (0)207 5947741
> > >>> http://www.imperial.ac.uk/people/jony.hudson
> > >>> http://www.imperial.ac.uk/ccm/research/edm
> > >>> http://www.monkeycruncher.org
> > >>> http://j-star.org/
> > >>> --
> > >>>
> > >>> ______________________________________________
> > >>> R-devel at r-project.org mailing list
> > >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> > >>>
> > >>
> > >>
> > >>
> > >> --
> > >> Gabriel Becker
> > >> Graduate Student
> > >> Statistics Department
> > >> University of California, Davis
> > >>
> > >>      [[alternative HTML version deleted]]
> > >>
> > >> ______________________________________________
> > >> R-devel at r-project.org mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-devel
> > >>
> > >>
> > >
> >
> >
> >
> >
> > --
> > Gabriel Becker
> > Graduate Student
> > Statistics Department
> > University of California, Davis
> 
> 
> 
> 
> -- 
> Gabriel Becker
> Graduate Student
> Statistics Department
> University of California, Davis


From ligges at statistik.tu-dortmund.de  Fri May  3 20:04:46 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 03 May 2013 20:04:46 +0200
Subject: [Rd] Package update for old version of R
In-Reply-To: <413765D2-8D38-421F-BC10-1FFB4AA2F140@gmail.com>
References: <BAF57135-9591-4044-A471-15B9AB948452@epcc.ed.ac.uk>
	<413765D2-8D38-421F-BC10-1FFB4AA2F140@gmail.com>
Message-ID: <5183FC3E.9060204@statistik.tu-dortmund.de>



On 03.05.2013 16:47, peter dalgaard wrote:
>
> On May 3, 2013, at 14:55 , Eilidh Troup wrote:
>
>> Hi,
>>
>> Is is possible to create a release of a package against an older version of R? I would like to release a new version of the package I maintain, but have some errors when I test it against R 3.0.0. Would CRAN accept a new release that works with R 2.15.3 but not R 3.0.0?
>
> I strongly doubt it. By the CRAN logic, it would move immediately to the Archived folder, which is a fairly obscure place to have your users go look...

Right.
You could try a version that works both under R-oldrelease and 
R-release/R-devel which would be accepted, of course.

Best,
Uwe Ligges

>
> They're usually helpful in getting you to fix the errors, though.
>
> -p
>


From ligges at statistik.tu-dortmund.de  Fri May  3 20:06:39 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 03 May 2013 20:06:39 +0200
Subject: [Rd] Please check link for R-patched.tar.gz
In-Reply-To: <CABq4i1OBHXkDRqmrPdFShNEsLoqwSb5JesQoahdeTC7TG4d-Ww@mail.gmail.com>
References: <CABq4i1OBHXkDRqmrPdFShNEsLoqwSb5JesQoahdeTC7TG4d-Ww@mail.gmail.com>
Message-ID: <5183FCAF.3090502@statistik.tu-dortmund.de>



On 02.05.2013 21:01, John Minter wrote:
> I have been trying to build R-patched from source using the link
>
> ftp://ftp.stat.math.ethz.ch/Software/R/R-patched.tar.gz
>
> Which the file list says is linked to R-patched_2013-05-01.tar.gz but what
> I download by both wget and curl (with -R -O --ssl ) is dated 2013-04-23
> and builds to an old patch level.... It could be some hidden cache on my
> side (I've tried finding and removing) but I think the symbolic link may be
> wrong on the server.  Please let me know if you think I am missing
> something.

You can also try the versions on CRAN:
http://cran.r-project.org/src/base-prerelease/

Uwe Ligges

>
> Best regards,
> John Minter
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From mauricio.zambrano at jrc.ec.europa.eu  Fri May  3 20:09:31 2013
From: mauricio.zambrano at jrc.ec.europa.eu (mauricio zambrano)
Date: Fri, 03 May 2013 20:09:31 +0200
Subject: [Rd] Licence change
In-Reply-To: <5183E8DB.7040206@gmail.com>
References: <5183CAEC.8080208@jrc.ec.europa.eu>
	<303921F7-3702-46AA-922A-8F773F9002D8@r-project.org>
	<5183D85D.2000103@jrc.ec.europa.eu> <5183E8DB.7040206@gmail.com>
Message-ID: <73c0f2206af5.5184197b@jrc.ec.europa.eu>

Thank you very much for all the feedback.

I will think about carefully.

All the best,

Mauricio

-- 
=====================================
Linux user #454569 -- Ubuntu user #17469
=====================================
"If you torture any data set long enough, 
it will confess anything!" (Murray Lark)

On 05/03/13, Duncan Murdoch  <murdoch.duncan at gmail.com> wrote:

> On 03/05/2013 11:31 AM, Mauricio Zambrano-Bigiarini wrote:
> >On 03/05/13 16:56, Simon Urbanek wrote:
> >>
> >> On May 3, 2013, at 10:34 AM, Mauricio Zambrano-Bigiarini wrote:
> >>
> >>> Dear list,
> >>>
> >>> For the maintainer of a given package, is it possible to change the licence of a it from GPL >= 2 to GPL >= 3 ?
> >>>
> >>
> >> In general the maintainer has no such rights. However, if the maintainer is also the author and holds all copyright, he can release the package under any license he feels fit. What has been already released cannot be affected, obviously, but you can release a new version under a different license if you have the legal right to do so.
> >
> >Thank you very much Duncan and Simon for your replies.
> >
> >The package I'm asking about has 1 author [aut] (me) and 1 contributor
> >[ctb] in the 'Author' field of the DESCRIPTION file. Both of them hold
> >the copyright of the package.
> >
> >In case we want to change the licence. Do the 2 authors write something
> >particular in the next submission to CRAN ?
> >Do we need to provide some written document to CRAN ?
> >
> >
> >What Duncan means with
> >"If you are distributing the package on CRAN, you'll have to ask them
> >whether they'll still choose to distribute your package after the change"
> >
> >May CRAN to decide not to distribute the package because of the change
> >in the licence ?
> 
> You'll have to ask them that.
> >
> >
> >>
> >> (This is not related to the possibility, but one practical problem with requiring GPL >=3 is that it is not GPL-2 compatible so it's a decision that better be made very consciously with all the consequences in mind).
> >
> >If the package we are talking about is pure R code, with only some
> >dependencies to other R packages, what are the implications of:
> >
> >" one practical problem with requiring GPL >=3 is that it is not GPL-2
> >compatible"
> 
> It may mean that one of your users won't be able to use the package, for example if something else that they need requires GPL-2 licensing.
> 
> Duncan Murdoch


From pdalgd at gmail.com  Fri May  3 20:29:26 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 3 May 2013 20:29:26 +0200
Subject: [Rd] Licence change
In-Reply-To: <5183E8DB.7040206@gmail.com>
References: <5183CAEC.8080208@jrc.ec.europa.eu>
	<303921F7-3702-46AA-922A-8F773F9002D8@r-project.org>
	<5183D85D.2000103@jrc.ec.europa.eu> <5183E8DB.7040206@gmail.com>
Message-ID: <DC5D928A-BF65-41EF-A043-52E040B65041@gmail.com>


On May 3, 2013, at 18:42 , Duncan Murdoch wrote:

>> 
>> " one practical problem with requiring GPL >=3 is that it is not GPL-2
>> compatible"
> 
> It may mean that one of your users won't be able to use the package, for example if something else that they need requires GPL-2 licensing.

Actually, with the GPL licenses, usage is not a problem, but distribution can be. 

These legalities are a bit inane, and I try to forget about them as far as possible, but I think trouble kicks in if someone wants to distribute a work that derives from both GPL-2 and GPL-3 codes.  What "derived" means is yet another inane discussion... 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From murdoch.duncan at gmail.com  Fri May  3 20:59:30 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 03 May 2013 14:59:30 -0400
Subject: [Rd] Licence change
In-Reply-To: <DC5D928A-BF65-41EF-A043-52E040B65041@gmail.com>
References: <5183CAEC.8080208@jrc.ec.europa.eu>
	<303921F7-3702-46AA-922A-8F773F9002D8@r-project.org>
	<5183D85D.2000103@jrc.ec.europa.eu> <5183E8DB.7040206@gmail.com>
	<DC5D928A-BF65-41EF-A043-52E040B65041@gmail.com>
Message-ID: <51840912.1000307@gmail.com>

On 03/05/2013 2:29 PM, peter dalgaard wrote:
> On May 3, 2013, at 18:42 , Duncan Murdoch wrote:
>
> >>
> >> " one practical problem with requiring GPL >=3 is that it is not GPL-2
> >> compatible"
> >
> > It may mean that one of your users won't be able to use the package, for example if something else that they need requires GPL-2 licensing.
>
> Actually, with the GPL licenses, usage is not a problem, but distribution can be.

Yes, absolutely.

Duncan Murdoch
> These legalities are a bit inane, and I try to forget about them as far as possible, but I think trouble kicks in if someone wants to distribute a work that derives from both GPL-2 and GPL-3 codes.  What "derived" means is yet another inane discussion...
>


From gmbecker at ucdavis.edu  Fri May  3 22:20:06 2013
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Fri, 3 May 2013 13:20:06 -0700
Subject: [Rd] Minimal build of R ...
In-Reply-To: <08C4ED64-00FA-4942-B270-0C1098EA4BF8@r-project.org>
References: <1D5CC664-B90A-444E-9389-9ED0ABC38999@imperial.ac.uk>
	<CADwqtCNY7EwsjNugJpOiOBSthGXRRnEiDDNPksHo0VAMLg3-+w@mail.gmail.com>
	<D4B50715-13B1-461B-BC79-BA76738AE052@r-project.org>
	<06F05F34-7B2C-40AE-924F-8FA90516E21D@imperial.ac.uk>
	<CADwqtCMsrbNHY=3Y-+8HvwM-_km-60dacZ9pqQC12CzU99=eWQ@mail.gmail.com>
	<19E9BBBD-1D5B-43DE-8A33-350F0A3D6036@imperial.ac.uk>
	<CADwqtCMqDOvpXHujdYjAU4ixj38+X9Aq3+kej0_ACLtvsYA1FA@mail.gmail.com>
	<08C4ED64-00FA-4942-B270-0C1098EA4BF8@r-project.org>
Message-ID: <CADwqtCMX3wqN8h9tJf2HkH3wzCEtmxyRUD97OCUb2hvr1=PUNg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130503/445b3c5f/attachment.pl>

From spinuvit at gmail.com  Sun May  5 16:11:22 2013
From: spinuvit at gmail.com (Vitalie Spinu)
Date: Sun, 05 May 2013 16:11:22 +0200
Subject: [Rd] Avoid entering {} evaluation in debugger
Message-ID: <87fvy1ms8l.fsf@gmail.com>



Hi, 
   
   f1 <- function(){
       browser()
       print("aaa")
   }
   
   f2 <- function(){
       a <- 12
       eval(envir = parent.frame(),
            bquote({
           b <- .(a)
       }))
   }
   

Now do, 

 f1()

and enter n RET  and then {1+2}:

Browse[2]> {1 + 2}
debug at #1: 1 + 2
Browse[3]>  


{} is now being debugged. This was never bothering me till I got into
unexpected behavior with functions that evaluate in the current
environment. 

For example calling f2() starts debugging b <- 12:

Browse[2]> f2()
debug: b <- 12
Browse[4]> 

Is there some sort of dont-debug-me flag that I can set in f2 to avoid
this behavior?

Thanks, 
    Vitalie


R Under development (unstable) (2013-04-19 r62622)
Platform: i686-pc-linux-gnu (32-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=C                 LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


From pauljohn32 at gmail.com  Sun May  5 19:37:15 2013
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Sun, 5 May 2013 12:37:15 -0500
Subject: [Rd] Patch proposal for R style consistency (concerning
	deparse.c)
In-Reply-To: <51825B70.8090604@mayo.edu>
References: <mailman.23.1367488807.10840.r-devel@r-project.org>
	<51825B70.8090604@mayo.edu>
Message-ID: <CAErODj-Ue-B7z12e8nZOdZMDpS_fA1wma1st=8uy7N2_LYXp1A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130505/13ccdcca/attachment.pl>

From karl.forner at gmail.com  Mon May  6 13:07:42 2013
From: karl.forner at gmail.com (Karl Forner)
Date: Mon, 6 May 2013 13:07:42 +0200
Subject: [Rd] Catch SIGINT from user in backend C++ code
In-Reply-To: <B09F1CDB-1596-4950-9037-9BF009C84822@massey.ac.nz>
References: <B09F1CDB-1596-4950-9037-9BF009C84822@massey.ac.nz>
Message-ID: <CAMd4_Aefa-xSZEv8bto-j_T16Gy_9N9=7khXAyKpubrwsGc8mw@mail.gmail.com>

Hello,

I once wrote  a package called RcppProgress, that you can find here:
https://r-forge.r-project.org/R/?group_id=1230
I did not try it for a long time, but it was developed to solve this
exact problem.
You can have a look the its companion package: RcppProgressExample.
Here's a link to the original announcement:
http://tolstoy.newcastle.edu.au/R/e17/devel/12/02/0443.html

Hope it helps.
Karl Forner
Quartz Bio

On Thu, May 2, 2013 at 1:50 AM, Jewell, Chris <C.P.Jewell at massey.ac.nz> wrote:
> Hi,
>
> I was wondering if anybody knew how to trap SIGINTs (ie Ctrl-C) in backend C++ code for R extensions?  I'm writing a package that uses the GPU for some hefty matrix operations in a tightly coupled parallel algorithm implemented in CUDA.
>
> The problem is that once running, the C++ module cannot apparently be interrupted by a SIGINT, leaving the user sat waiting even if they realise they've launched the algorithm with incorrect settings.  Occasionally, the SIGINT gets through and the C++ module stops.  However, this leaves the CUDA context hanging, meaning that if the algorithm is launched again R dies.  If I could trap the SIGINT, then I could make sure a) that the algorithm stops immediately, and b) that the CUDA context is destructed nicely.
>
> Is there a "R-standard" method of doing this?
>
> Thanks,
>
> Chris
>
>
> --
> Dr Chris Jewell
> Lecturer in Biostatistics
> Institute of Fundamental Sciences
> Massey University
> Private Bag 11222
> Palmerston North 4442
> New Zealand
> Tel: +64 (0) 6 350 5701 Extn: 3586
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From joshmobrien at gmail.com  Tue May  7 00:29:39 2013
From: joshmobrien at gmail.com (Josh O'Brien)
Date: Mon, 6 May 2013 15:29:39 -0700 (PDT)
Subject: [Rd] Avoid entering {} evaluation in debugger
In-Reply-To: <87fvy1ms8l.fsf@gmail.com>
References: <87fvy1ms8l.fsf@gmail.com>
Message-ID: <1367879379354-4666437.post@n4.nabble.com>

Vitalie Spinu wrote
> Hi, 
>    
>    f1 <- function(){
>        browser()
>        print("aaa")
>    }
>    
>    f2 <- function(){
>        a <- 12
>        eval(envir = parent.frame(),
>             bquote({
>            b <- .(a)
>        }))
>    }
>    
> 
> Now do, 
> 
>  f1()
> 
> and enter n RET  and then {1+2}:
> 
> Browse[2]> {1 + 2}
> debug at #1: 1 + 2
> Browse[3]>  
> 
> 
> {} is now being debugged. This was never bothering me till I got into
> unexpected behavior with functions that evaluate in the current
> environment. 
> 
> For example calling f2() starts debugging b <- 12:
> 
> Browse[2]> f2()
> debug: b <- 12
> Browse[4]> 
> 
> Is there some sort of dont-debug-me flag that I can set in f2 to avoid
> this behavior?
> 
> Thanks, 
>     Vitalie
>    f1 <- function(){
>        browser()
>        print("aaa")
>    }
>    
>    f2 <- function(){
>        a <- 12
>        eval(envir = parent.frame(),
>             bquote({
>            b <- .(a)
>        }))
>    }
>    
> 
> R Under development (unstable) (2013-04-19 r62622)
> Platform: i686-pc-linux-gnu (32-bit)
> 
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
>  [7] LC_PAPER=C                 LC_NAME=C                 
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C            
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> ______________________________________________

> R-devel@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

I believe that your sessionInfo() results leave out the most important
detail, which is that you're running R from Emacs/ESS. Is that right?

I get this same, occasionally annoying, behavior when using ESS 13.03 and
Emacs 23.3.1, but not from Rgui, Rterm, etc.

Haven't brought it up there, but this would obviously be a good topic for
ESS-help.

Cheers,

Josh



--
View this message in context: http://r.789695.n4.nabble.com/Avoid-entering-evaluation-in-debugger-tp4666350p4666437.html
Sent from the R devel mailing list archive at Nabble.com.


From spinuvit at gmail.com  Tue May  7 01:27:07 2013
From: spinuvit at gmail.com (Vitalie Spinu)
Date: Tue, 07 May 2013 01:27:07 +0200
Subject: [Rd] Avoid entering {} evaluation in debugger
In-Reply-To: <1367879379354-4666437.post@n4.nabble.com> (Josh O'Brien's
	message of "Mon, 6 May 2013 15:29:39 -0700 (PDT)")
References: <87fvy1ms8l.fsf@gmail.com>
	<1367879379354-4666437.post@n4.nabble.com>
Message-ID: <87ip2vy9is.fsf@gmail.com>

 >> "Josh O'Brien" <joshmobrien at gmail.com>
 >> on Mon, 6 May 2013 15:29:39 -0700 (PDT) wrote:

[...]


 > I believe that your sessionInfo() results leave out the most important
 > detail, which is that you're running R from Emacs/ESS. Is that right?

Nope, I have reported it from R terminal.

 > I get this same, occasionally annoying, behavior when using ESS 13.03 and
 > Emacs 23.3.1, but not from Rgui, Rterm, etc.

In ESS it indeed happens more often because visual debugger sends "n"
commands to R.

    Vitalie


From hpages at fhcrc.org  Wed May  8 00:08:02 2013
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 07 May 2013 15:08:02 -0700
Subject: [Rd] error when calling seek() twice on a gzfile connection
Message-ID: <51897B42.3070307@fhcrc.org>

Hi,

I get an "internal error" when calling seek() twice on a gzfile
connection.

Create a gzip file:

   bigraw <- sample(charToRaw("abcdef"), 30000000, replace=TRUE)
   save(bigraw, file="bigraw.rda")

Open it:

   con <- gzfile("bigraw.rda", "rb")

Then:

   > seek(con, where=1)
   [1] 0

   > seek(con, where=24980000)
   [1] 1
   Warning message:
   In seek.connection(con, where = 24980000) :
     seek on a gzfile connection returned an internal error

   > seek(con)
   [1] 286

I don't get this error if I omit the 1st call to seek(), or if
I use a smaller 'where' value in the 2nd call to seek().

According to the man page, gzfile connections support seek()
but with a number of limitations. It doesn't seem that what I'm
trying to do falls into any of the limitations mentioned in
the man page though.

As a side note, this is maybe the kind of internal error that seems
serious enough to deserve being turned into a real error, not just
a warning.

Thanks,
H.

 > sessionInfo()
R version 3.0.0 (2013-04-03)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=C                 LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.0.0

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From peter.meilstrup at gmail.com  Wed May  8 05:35:38 2013
From: peter.meilstrup at gmail.com (Peter Meilstrup)
Date: Tue, 7 May 2013 20:35:38 -0700
Subject: [Rd] Dependencies of Imports not attached?
Message-ID: <CAJoaRhbvZuNOezQr9-RjFzJ1O1s0+xy442wFvDsZVK=C9jXGrA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130507/d3fd0547/attachment.pl>

From renaud at mancala.cbio.uct.ac.za  Wed May  8 08:05:48 2013
From: renaud at mancala.cbio.uct.ac.za (Renaud Gaujoux)
Date: Wed, 8 May 2013 09:05:48 +0300
Subject: [Rd] Namespace/inheritance problem in S4 methods for a union class
Message-ID: <CAHavPHH2SWuCHPOz6O33KxUOjWbfGrBwfZ0-6dPn06uBydq3iA@mail.gmail.com>

Hi,

I started this post on bioc-devel but this seems to be more general:

https://stat.ethz.ch/pipermail/bioc-devel/2013-May/004311.html

See reproducible example from Martin below.

Thank you.

Renaud

---------- Forwarded message ----------
From: Martin Morgan <mtmorgan at fhcrc.org>
Date: 7 May 2013 19:55
Subject: Re: [Bioc-devel] ExpressionSet and LumiBatch: inheritance problem
in S4 methods for union class
To: Renaud Gaujoux <renaud at mancala.cbio.uct.ac.za>
Cc: bioc-devel at r-project.org, dupan.mail at gmail.com

I can replicate this with a simpler example, where PkgA has

  setClass("A", representation(x="numeric"))

with NAMESPACE

  import(methods)
  exportClasses("A")

PkgB has

  setClass("B", contains="A")

NAMESPACE

  import(methods)
  importClassesFrom("PkgA", "A")
  exportClasses("B")

and then

  library(PkgA); library(PkgB)
  setClassUnion("C", c("matrix", "A"))
  setGeneric("do", function(x) standardGeneric("do"))
  setMethod("do", "C", function(x) "done")

leading to

  > do(new("A"))
  [1] "done"
  > do(new("B"))

  Error in (function (classes, fdef, mtable)  :
    unable to find an inherited method for function ?do? for signature ?"B"?

suggesting name space issues rather than something about ExpressionSet. The
sample packages and test script are attached; it would be appropriate to
pursue this on the R-devel mailing list.

Martin

-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793
-------------- next part --------------
A non-text attachment was scrubbed...
Name: setClassUnion.tar.gz
Type: application/x-gzip
Size: 777 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130508/cf4cbfb4/attachment.gz>

From hpages at fhcrc.org  Wed May  8 10:51:14 2013
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Wed, 08 May 2013 01:51:14 -0700
Subject: [Rd] getting corrupted data when using readBin() after seek() on a
 gzfile connection
Message-ID: <518A1202.4000508@fhcrc.org>

Hi,

I'm running into more issues when reading data from a gzfile connection.
If I read the data sequentially with successive calls to readBin(), the
data I get looks ok. But if I call seek() between the successive calls
to readBin(), I get corrupted data.

Here is a (hopefully) reproducible example. See my sessionInfo() at the
end (I'm not on Windows, where, according to the man page, seek() is
broken).

   ## Generate data with a repeated easy-to-recognize byte pattern
   ## of length 26:
   mydata <- rep(charToRaw(paste(letters, collapse="")), 400)

   ## Write the data to test.gz file:
   con <- gzfile("test.gz", open="wb")
   writeBin(mydata, con)
   close(con)

   ## Read the data from test.gz file. We'll read blocks of 26 bytes
   ## located at various offsets that are multiple of 26, so we expect
   ## to see our original pattern ("abc...xyz").
   con <- gzfile("test.gz", open="rb")

   ## Offset 0: ok
   > rawToChar(readBin(con, "raw", n=26))
   [1] "abcdefghijklmnopqrstuvwxyz"

   ## Offset 78: still ok
   > seek(con, where=78)
   [1] 26
   > seek(con)
   [1] 78
   > rawToChar(readBin(con, "raw", n=26))
   [1] "abcdefghijklmnopqrstuvwxyz"

   ## Offset 520: data is messed up
   > seek(con, where=520)
   [1] 104
   > seek(con)
   [1] 520
   > rawToChar(readBin(con, "raw", n=26))
   [1] "zabcdefghijklmnopqrstuvvuv"


   ## Offset 2600: very messed up
   > seek(con, where=2600)
   [1] 546
   > seek(con)
   [1] 2600
   > rawToChar(readBin(con, "raw", n=26))
   [1] "xxxxxmpxxxxxxesxxxxxxxxxxp"

   ## Offset 10400: see previous email (subject: "error when calling
   ## seek() twice on a gzfile connection")
   > seek(con, where=10400)
   [1] 2626
   Warning message:
   In seek.connection(con, where = 10400) :
     seek on a gzfile connection returned an internal error

   close(con)

Reading the data sequentially with no calls to seek() returns the
expected pattern 400 times:

   con <- gzfile("test.gz", open="rb")
   blocks <- sapply(1:400, function(i) rawToChar(readBin(con, "raw", n=26)))

   ## Check the result:

   > readBin(con, "raw", n=26)  # no more data
   raw(0)

   > seek(con)
   [1] 10400

   > table(blocks)
   blocks
   abcdefghijklmnopqrstuvwxyz
                          400

Thanks,
H.

 > sessionInfo()
R version 3.0.0 (2013-04-03)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=C                 LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From jmc at r-project.org  Wed May  8 18:02:11 2013
From: jmc at r-project.org (John Chambers)
Date: Wed, 08 May 2013 09:02:11 -0700
Subject: [Rd] Namespace/inheritance problem in S4 methods for a union
 class
In-Reply-To: <CAHavPHH2SWuCHPOz6O33KxUOjWbfGrBwfZ0-6dPn06uBydq3iA@mail.gmail.com>
References: <CAHavPHH2SWuCHPOz6O33KxUOjWbfGrBwfZ0-6dPn06uBydq3iA@mail.gmail.com>
Message-ID: <518A7703.3050004@r-project.org>

No need for generic functions and methods.  Just looking at the 
hierarchy of the classes shows the problem.

With Martin's simplified version:

 > library(PkgA)
 > extends("A")
[1] "A"
 > library(PkgB)
 > extends("B")
[1] "B" "A"
 > setClassUnion("C", c("matrix", "A"))
 > extends("A")
[1] "A" "C"
 > extends("B")
[1] "B" "A"


So defining the union does not make all the subclasses of "A" members of 
the union.

The next comments are guesses but plausible.  Loading the namespace of 
PkgB may not update the known subclasses of classes from PkgA.

This is one of R's touchier points in general:  The state of things with 
respect to classes and methods changes dynamically as packages are 
loaded.  Until PkgB is loaded, "A" has no known subclasses.

If the guess is correct, then when the  class union is formed, nothing 
tells us that "A" has a subclass "B" that should be added to the union.

Fixing this properly may involve the load-time actions and not be quite 
trivial.

John


On 5/7/13 11:05 PM, Renaud Gaujoux wrote:
> Hi,
>
> I started this post on bioc-devel but this seems to be more general:
>
> https://stat.ethz.ch/pipermail/bioc-devel/2013-May/004311.html
>
> See reproducible example from Martin below.
>
> Thank you.
>
> Renaud
>
> ---------- Forwarded message ----------
> From: Martin Morgan <mtmorgan at fhcrc.org>
> Date: 7 May 2013 19:55
> Subject: Re: [Bioc-devel] ExpressionSet and LumiBatch: inheritance problem
> in S4 methods for union class
> To: Renaud Gaujoux <renaud at mancala.cbio.uct.ac.za>
> Cc: bioc-devel at r-project.org, dupan.mail at gmail.com
>
> I can replicate this with a simpler example, where PkgA has
>
>    setClass("A", representation(x="numeric"))
>
> with NAMESPACE
>
>    import(methods)
>    exportClasses("A")
>
> PkgB has
>
>    setClass("B", contains="A")
>
> NAMESPACE
>
>    import(methods)
>    importClassesFrom("PkgA", "A")
>    exportClasses("B")
>
> and then
>
>    library(PkgA); library(PkgB)
>    setClassUnion("C", c("matrix", "A"))
>    setGeneric("do", function(x) standardGeneric("do"))
>    setMethod("do", "C", function(x) "done")
>
> leading to
>
>    > do(new("A"))
>    [1] "done"
>    > do(new("B"))
>
>    Error in (function (classes, fdef, mtable)  :
>      unable to find an inherited method for function ?do? for signature ?"B"?
>
> suggesting name space issues rather than something about ExpressionSet. The
> sample packages and test script are attached; it would be appropriate to
> pursue this on the R-devel mailing list.
>
> Martin
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From simon.urbanek at r-project.org  Wed May  8 19:25:39 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 8 May 2013 13:25:39 -0400
Subject: [Rd] Dependencies of Imports not attached?
In-Reply-To: <CAJoaRhbvZuNOezQr9-RjFzJ1O1s0+xy442wFvDsZVK=C9jXGrA@mail.gmail.com>
References: <CAJoaRhbvZuNOezQr9-RjFzJ1O1s0+xy442wFvDsZVK=C9jXGrA@mail.gmail.com>
Message-ID: <71CEDD11-1D4C-40BE-A106-E2D2933EAC75@r-project.org>


On May 7, 2013, at 11:35 PM, Peter Meilstrup wrote:

> Encountered an error in scripting, which can be reproduced using Rscript as
> follows:
> 
> $ Rscript -e "library(httr); handle('http://cran.r-project.org')"
> 
> Error in getCurlHandle(cookiefile = cookie_path, .defaults = list()) :
>  could not find function "getClass"
> Calls: handle -> getCurlHandle
> 
> or by starting R without the methods package attached:
> 
> $ R_DEFAULT_PACKAGES=base R
> [snip]
>> library(httr)
>> handle('http://cran.fhcrc.org/')
> Error in getCurlHandle(cookiefile = cookie_path, .defaults = list()) :
>  could not find function "getClass"
> 
> As far as I can tell the error occurs when getCurlHandle .Calls a C
> function which then calls SET_CLASS, which (I guess) requires
> methods::setClass to be in the search path.
> 
> Now 'httr' Imports 'RCurl' which Depends on 'methods'. So I think
> `library(httr)` should end up attaching 'methods' to the search path, but
> it seems 'methods' is just imported to RCurl's namespace.
> 
> I think this is a problem since the Depends line is indicating that
> 'methods' must be attached for RCurl to work, whether or not RCurl itself
> is being attached.
> 

For the record, I see the same problem with other packages that use S4 - very often it trips packages that don't use S4 but import a package that does. The analysis is correct - if a package B just imports a function from another package A which in turn relies on something in Depends, it breaks, because A is not on the search path and thus A doesn't have access to the dependencies it needs. I don't know that was the intended design. I see two way to fix this
1) make sure Depends: are always put on the search path even if the package is not attached
2) automatically generate imports for all packages in Depends:

The main problem is that B is helpless - only a change in A can make it work. Fix for A is to explicitly add import(methods) even though it's already in Depends:. Note that R CMD check doesn't detect this.

Cheers,
Simon


From mtmorgan at fhcrc.org  Wed May  8 19:52:06 2013
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Wed, 08 May 2013 10:52:06 -0700
Subject: [Rd] Dependencies of Imports not attached?
In-Reply-To: <71CEDD11-1D4C-40BE-A106-E2D2933EAC75@r-project.org>
References: <CAJoaRhbvZuNOezQr9-RjFzJ1O1s0+xy442wFvDsZVK=C9jXGrA@mail.gmail.com>
	<71CEDD11-1D4C-40BE-A106-E2D2933EAC75@r-project.org>
Message-ID: <518A90C6.1090501@fhcrc.org>

On 05/08/2013 10:25 AM, Simon Urbanek wrote:
>
> On May 7, 2013, at 11:35 PM, Peter Meilstrup wrote:
>
>> Encountered an error in scripting, which can be reproduced using Rscript as
>> follows:
>>
>> $ Rscript -e "library(httr); handle('http://cran.r-project.org')"
>>
>> Error in getCurlHandle(cookiefile = cookie_path, .defaults = list()) :
>>   could not find function "getClass"
>> Calls: handle -> getCurlHandle
>>
>> or by starting R without the methods package attached:
>>
>> $ R_DEFAULT_PACKAGES=base R
>> [snip]
>>> library(httr)
>>> handle('http://cran.fhcrc.org/')
>> Error in getCurlHandle(cookiefile = cookie_path, .defaults = list()) :
>>   could not find function "getClass"
>>
>> As far as I can tell the error occurs when getCurlHandle .Calls a C
>> function which then calls SET_CLASS, which (I guess) requires
>> methods::setClass to be in the search path.
>>
>> Now 'httr' Imports 'RCurl' which Depends on 'methods'. So I think
>> `library(httr)` should end up attaching 'methods' to the search path, but
>> it seems 'methods' is just imported to RCurl's namespace.
>>
>> I think this is a problem since the Depends line is indicating that
>> 'methods' must be attached for RCurl to work, whether or not RCurl itself
>> is being attached.
>>
>
> For the record, I see the same problem with other packages that use S4 - very often it trips packages that don't use S4 but import a package that does. The analysis is correct - if a package B just imports a function from another package A which in turn relies on something in Depends, it breaks, because A is not on the search path and thus A doesn't have access to the dependencies it needs. I don't know that was the intended design. I see two way to fix this
> 1) make sure Depends: are always put on the search path even if the package is not attached
> 2) automatically generate imports for all packages in Depends:
>
> The main problem is that B is helpless - only a change in A can make it work. Fix for A is to explicitly add import(methods) even though it's already in Depends:. Note that R CMD check doesn't detect this.

As described, this is a 'package maintainer' problem -- fix package A. Also, 
this isn't unique to methods, other packages routinely Depend: on something that 
should instead be Import:'ed.

But I think Peter's case is different, because the C implementations of

     SEXP R_do_MAKE_CLASS(const char *what);
     SEXP R_getClassDef  (const char *what);

need to be called from inside the package environment, but there is no way to 
pass the package environment through the interface above.

Maybe the partial patch (attached) points to a solution? It changes the 
interface (though would only break a couple of Bioconductor packages in a minor 
way) (I think there's a missing PROTECT in there too.)


>
> Cheers,
> Simon
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793
-------------- next part --------------
A non-text attachment was scrubbed...
Name: object-env.diff
Type: text/x-patch
Size: 3587 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130508/9801ed30/attachment.bin>

From hb at biostat.ucsf.edu  Wed May  8 19:54:00 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Wed, 8 May 2013 10:54:00 -0700
Subject: [Rd] getting corrupted data when using readBin() after seek()
 on a gzfile connection
In-Reply-To: <518A1202.4000508@fhcrc.org>
References: <518A1202.4000508@fhcrc.org>
Message-ID: <CAFDcVCQy2ZeHwezdaKXYD6Tvc4uceUbKa3MmDENAEVguBGCM2A@mail.gmail.com>

I can reproduce this (exactly the same output) on Windows:

> sessionInfo()
R version 3.0.0 Patched (2013-04-29 r62694)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.0.0

/Henrik

On Wed, May 8, 2013 at 1:51 AM, Herv? Pag?s <hpages at fhcrc.org> wrote:
> Hi,
>
> I'm running into more issues when reading data from a gzfile connection.
> If I read the data sequentially with successive calls to readBin(), the
> data I get looks ok. But if I call seek() between the successive calls
> to readBin(), I get corrupted data.
>
> Here is a (hopefully) reproducible example. See my sessionInfo() at the
> end (I'm not on Windows, where, according to the man page, seek() is
> broken).
>
>   ## Generate data with a repeated easy-to-recognize byte pattern
>   ## of length 26:
>   mydata <- rep(charToRaw(paste(letters, collapse="")), 400)
>
>   ## Write the data to test.gz file:
>   con <- gzfile("test.gz", open="wb")
>   writeBin(mydata, con)
>   close(con)
>
>   ## Read the data from test.gz file. We'll read blocks of 26 bytes
>   ## located at various offsets that are multiple of 26, so we expect
>   ## to see our original pattern ("abc...xyz").
>   con <- gzfile("test.gz", open="rb")
>
>   ## Offset 0: ok
>   > rawToChar(readBin(con, "raw", n=26))
>   [1] "abcdefghijklmnopqrstuvwxyz"
>
>   ## Offset 78: still ok
>   > seek(con, where=78)
>   [1] 26
>   > seek(con)
>   [1] 78
>   > rawToChar(readBin(con, "raw", n=26))
>   [1] "abcdefghijklmnopqrstuvwxyz"
>
>   ## Offset 520: data is messed up
>   > seek(con, where=520)
>   [1] 104
>   > seek(con)
>   [1] 520
>   > rawToChar(readBin(con, "raw", n=26))
>   [1] "zabcdefghijklmnopqrstuvvuv"
>
>
>   ## Offset 2600: very messed up
>   > seek(con, where=2600)
>   [1] 546
>   > seek(con)
>   [1] 2600
>   > rawToChar(readBin(con, "raw", n=26))
>   [1] "xxxxxmpxxxxxxesxxxxxxxxxxp"
>
>   ## Offset 10400: see previous email (subject: "error when calling
>   ## seek() twice on a gzfile connection")
>   > seek(con, where=10400)
>   [1] 2626
>   Warning message:
>   In seek.connection(con, where = 10400) :
>     seek on a gzfile connection returned an internal error
>
>   close(con)
>
> Reading the data sequentially with no calls to seek() returns the
> expected pattern 400 times:
>
>   con <- gzfile("test.gz", open="rb")
>   blocks <- sapply(1:400, function(i) rawToChar(readBin(con, "raw", n=26)))
>
>   ## Check the result:
>
>   > readBin(con, "raw", n=26)  # no more data
>   raw(0)
>
>   > seek(con)
>   [1] 10400
>
>   > table(blocks)
>   blocks
>   abcdefghijklmnopqrstuvwxyz
>                          400
>
> Thanks,
> H.
>
>> sessionInfo()
> R version 3.0.0 (2013-04-03)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=C                 LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> --
> Herv? Pag?s
>
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
>
> E-mail: hpages at fhcrc.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From simon.urbanek at r-project.org  Wed May  8 21:27:33 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 8 May 2013 15:27:33 -0400
Subject: [Rd] Dependencies of Imports not attached?
In-Reply-To: <518A90C6.1090501@fhcrc.org>
References: <CAJoaRhbvZuNOezQr9-RjFzJ1O1s0+xy442wFvDsZVK=C9jXGrA@mail.gmail.com>
	<71CEDD11-1D4C-40BE-A106-E2D2933EAC75@r-project.org>
	<518A90C6.1090501@fhcrc.org>
Message-ID: <FCE1EC36-284F-4CB3-AD30-FE1E04D11217@r-project.org>

On May 8, 2013, at 1:52 PM, Martin Morgan wrote:

> On 05/08/2013 10:25 AM, Simon Urbanek wrote:
>> 
>> On May 7, 2013, at 11:35 PM, Peter Meilstrup wrote:
>> 
>>> Encountered an error in scripting, which can be reproduced using Rscript as
>>> follows:
>>> 
>>> $ Rscript -e "library(httr); handle('http://cran.r-project.org')"
>>> 
>>> Error in getCurlHandle(cookiefile = cookie_path, .defaults = list()) :
>>>  could not find function "getClass"
>>> Calls: handle -> getCurlHandle
>>> 
>>> or by starting R without the methods package attached:
>>> 
>>> $ R_DEFAULT_PACKAGES=base R
>>> [snip]
>>>> library(httr)
>>>> handle('http://cran.fhcrc.org/')
>>> Error in getCurlHandle(cookiefile = cookie_path, .defaults = list()) :
>>>  could not find function "getClass"
>>> 
>>> As far as I can tell the error occurs when getCurlHandle .Calls a C
>>> function which then calls SET_CLASS, which (I guess) requires
>>> methods::setClass to be in the search path.
>>> 
>>> Now 'httr' Imports 'RCurl' which Depends on 'methods'. So I think
>>> `library(httr)` should end up attaching 'methods' to the search path, but
>>> it seems 'methods' is just imported to RCurl's namespace.
>>> 
>>> I think this is a problem since the Depends line is indicating that
>>> 'methods' must be attached for RCurl to work, whether or not RCurl itself
>>> is being attached.
>>> 
>> 
>> For the record, I see the same problem with other packages that use S4 - very often it trips packages that don't use S4 but import a package that does. The analysis is correct - if a package B just imports a function from another package A which in turn relies on something in Depends, it breaks, because A is not on the search path and thus A doesn't have access to the dependencies it needs. I don't know that was the intended design. I see two way to fix this
>> 1) make sure Depends: are always put on the search path even if the package is not attached
>> 2) automatically generate imports for all packages in Depends:
>> 
>> The main problem is that B is helpless - only a change in A can make it work. Fix for A is to explicitly add import(methods) even though it's already in Depends:. Note that R CMD check doesn't detect this.
> 
> As described, this is a 'package maintainer' problem -- fix package A. Also, this isn't unique to methods, other packages routinely Depend: on something that should instead be Import:'ed.
> 

By that argument Depends: is unusable. If you specify Depends: you are expressing that your package will work if those packages are on the search path. The fact that R will happily import functions from the package despite that requirement not being fulfilled seems like a bug to me.


> But I think Peter's case is different, because the C implementations of
> 
>    SEXP R_do_MAKE_CLASS(const char *what);
>    SEXP R_getClassDef  (const char *what);
> 
> need to be called from inside the package environment, but there is no way to pass the package environment through the interface above.
> 

Yes, it's the same issue, but a case where adding imports doesn't help because they are not consulted. So in the current setup only 1) is a solution. With your patch, 2) would work as well.


> Maybe the partial patch (attached) points to a solution? It changes the interface (though would only break a couple of Bioconductor packages in a minor way) (I think there's a missing PROTECT in there too.)
> 

At least currently the PROTECT is not needed because setAttrib() protects its arguments (although there are some dangerous comments in installAttrib ;)).

Cheers,
Simon



> 
>> 
>> Cheers,
>> Simon
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
> 
> 
> -- 
> Computational Biology / Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N.
> PO Box 19024 Seattle, WA 98109
> 
> Location: Arnold Building M1 B861
> Phone: (206) 667-2793
> <object-env.diff>


From hpages at fhcrc.org  Wed May  8 22:53:57 2013
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Wed, 8 May 2013 13:53:57 -0700
Subject: [Rd] subsetting by name is very slow when subscript contains a lot
 of "invalid" names
Message-ID: <518ABB65.1030204@fhcrc.org>

Hi,

Note sure why but subsetting by name is *very* slow when the character
vector used as subscript contains a lot of "invalid" names:

   x <- c(A=10L, B=20L, C=30L)
   subscript <- c(LETTERS[1:3], sprintf("ID%05d", 1:150000))

   > system.time(y1 <- x[subscript])
      user  system elapsed
   111.991   0.000 112.230

Since subsetting by name is basically equivalent to

   i <- match(subscript, names(x))
   x[i]

it's quite surprising that the former is more than 10 thousand times
slower than the latter:

   > system.time({i <- match(subscript, names(x)); y2 <- x[i]})
      user  system elapsed
     0.008   0.000   0.007

   > identical(y2, y1)
   [1] TRUE

Thanks,
H.

PS: This issue was already reported here
   https://stat.ethz.ch/pipermail/r-devel/2010-July/057945.html
in 2010, and with a proposed fix by Martin Morgan.

 > sessionInfo()
R version 3.0.0 (2013-04-03)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=C                 LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] parallel  stats     graphics  grDevices utils     datasets  methods
[8] base

other attached packages:
[1] GenomicRanges_1.13.8 IRanges_1.19.3       BiocGenerics_0.7.2

loaded via a namespace (and not attached):
[1] stats4_3.0.0 tools_3.0.0

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From renaud at mancala.cbio.uct.ac.za  Thu May  9 07:46:06 2013
From: renaud at mancala.cbio.uct.ac.za (Renaud Gaujoux)
Date: Thu, 9 May 2013 08:46:06 +0300
Subject: [Rd] Namespace/inheritance problem in S4 methods for a union
	class
In-Reply-To: <518A7703.3050004@r-project.org>
References: <CAHavPHH2SWuCHPOz6O33KxUOjWbfGrBwfZ0-6dPn06uBydq3iA@mail.gmail.com>
	<518A7703.3050004@r-project.org>
Message-ID: <CAHavPHF4oE4oBVHWyP1WsXJF034A3rTy7f3XQw9rj0uvaMcw7w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130509/044fc596/attachment.pl>

From jmc at r-project.org  Thu May  9 18:08:02 2013
From: jmc at r-project.org (John Chambers)
Date: Thu, 9 May 2013 09:08:02 -0700
Subject: [Rd] Namespace/inheritance problem in S4 methods for a union
	class
In-Reply-To: <CAHavPHF4oE4oBVHWyP1WsXJF034A3rTy7f3XQw9rj0uvaMcw7w@mail.gmail.com>
References: <CAHavPHH2SWuCHPOz6O33KxUOjWbfGrBwfZ0-6dPn06uBydq3iA@mail.gmail.com>
	<518A7703.3050004@r-project.org>
	<CAHavPHF4oE4oBVHWyP1WsXJF034A3rTy7f3XQw9rj0uvaMcw7w@mail.gmail.com>
Message-ID: <28B6612D-DCB2-4254-8B73-00DDC50A47F0@r-project.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130509/56f686b6/attachment.pl>

From matwey.kornilov at gmail.com  Wed May  8 20:24:01 2013
From: matwey.kornilov at gmail.com (Matwey V. Kornilov)
Date: Wed, 8 May 2013 22:24:01 +0400
Subject: [Rd] call R function from C code
Message-ID: <kme57t$sca$1@ger.gmane.org>

Hi,

I am writing C code for R, but in middle of the routine I want to call 
solve(A,b) function. What is the right way to solve linear set inside C 
code? Is it ok to just invoke La_solve()?


From michael.bell at acm.org  Thu May  9 16:12:57 2013
From: michael.bell at acm.org (Michael Bell)
Date: Thu, 9 May 2013 10:12:57 -0400
Subject: [Rd] cairo is not the default when available
Message-ID: <CAC98X7uL3SLf3BpM2hq5tCvXU-bUWHS5D9bYgGzZY8wsrpaiLA@mail.gmail.com>

This question was asked previously here, but not resolved:
http://tolstoy.newcastle.edu.au/R/e15/devel/11/08/0307.html

The upshot is that cairo is not being used as the default when it is
available, even though the documentation says:
Default "cairo" where available and reliable, otherwise "Xlib".

Here is my system information:
% uname -a
Linux anvil 2.6.18-194.11.4.el5 #1 SMP Fri Sep 17 04:57:05 EDT 2010
x86_64 x86_64 x86_64 GNU/Linux

> R.version
               _
platform       x86_64-unknown-linux-gnu
arch           x86_64
os             linux-gnu
system         x86_64, linux-gnu
status
major          3
minor          0.0
year           2013
month          04
day            03
svn rev        62481
language       R
version.string R version 3.0.0 (2013-04-03)
nickname       Masked Marvel

> capabilities("X11");capabilities("cairo");options("bitmapType")
 X11
TRUE
cairo
 TRUE
$bitmapType
[1] "Xlib"

It is clear whether cairo or X11 is being used because cairo does
antialiasing, and X11 does not:
plot(read.table("in.txt"));

Whether cairo is the default is decided in
src/library/grDevices/R/zzz.R in the onLoad function:
 list(bitmapType = if(capabilities("aqua")) "quartz"
 else if(.Call(C_cairoProps, 2L)) "cairo" else "Xlib")
and
if (.Platform$OS.type != "windows" && !.Call(C_cairoProps, 2L))
        X11.options(type = "Xlib")


cairoProps is in src/library/grDevices/src/init.c:
static SEXP cairoProps(SEXP in)
{
    int which = asInteger(in);
    if(which == 1)
    return ScalarLogical(
#ifdef HAVE_WORKING_CAIRO
        1
#else
        0
#endif
        );
    else if(which == 2)
    return ScalarLogical(
#ifdef HAVE_PANGOCAIRO
        1
#else
        0
#endif
        );
    return R_NilValue;
}

I believe this is where the problem comes in. I don't have pangocairo
and cairoProps is being called with 2L instead of 1L. Indeed, if I
change it to 1L and recompile, cairo becomes the default, and
everything runs as expected.

I would like cairo to be checked for rather than pangocairo, but
perhaps there is a good reason how it is being done now. Can this be
changed?

thanks,
michael


--
michael.bell at acm.org


From simon.urbanek at r-project.org  Thu May  9 21:54:40 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 9 May 2013 15:54:40 -0400
Subject: [Rd] call R function from C code
In-Reply-To: <kme57t$sca$1@ger.gmane.org>
References: <kme57t$sca$1@ger.gmane.org>
Message-ID: <2DC85D00-8F28-4EFA-BBE7-D5488B1DC894@r-project.org>


On May 8, 2013, at 2:24 PM, Matwey V. Kornilov wrote:

> Hi,
> 
> I am writing C code for R, but in middle of the routine I want to call solve(A,b) function. What is the right way to solve linear set inside C code? Is it ok to just invoke La_solve()?
> 

There is no such thing as La_solve(). You can use dgesv from LAPACK, though.
However, the subject poses a different question -- you can call R function from C code by using eval().

Cheers,
Simon


From gmbecker at ucdavis.edu  Thu May  9 22:13:36 2013
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Thu, 9 May 2013 13:13:36 -0700
Subject: [Rd] call R function from C code
In-Reply-To: <2DC85D00-8F28-4EFA-BBE7-D5488B1DC894@r-project.org>
References: <kme57t$sca$1@ger.gmane.org>
	<2DC85D00-8F28-4EFA-BBE7-D5488B1DC894@r-project.org>
Message-ID: <CADwqtCNZrAsF+j5NCqiAnqz7Go4eGSE5ctw0Hb0nYOjP6vswdA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130509/2486cefb/attachment.pl>

From matwey.kornilov at gmail.com  Fri May 10 11:34:31 2013
From: matwey.kornilov at gmail.com (Matwey V. Kornilov)
Date: Fri, 10 May 2013 13:34:31 +0400
Subject: [Rd] call R function from C code
In-Reply-To: <CADwqtCNZrAsF+j5NCqiAnqz7Go4eGSE5ctw0Hb0nYOjP6vswdA@mail.gmail.com>
References: <kme57t$sca$1@ger.gmane.org>
	<2DC85D00-8F28-4EFA-BBE7-D5488B1DC894@r-project.org>
	<CADwqtCNZrAsF+j5NCqiAnqz7Go4eGSE5ctw0Hb0nYOjP6vswdA@mail.gmail.com>
Message-ID: <kmiev2$qj2$1@ger.gmane.org>


Thanks, It is what I was looking for. But now, I poorly understand 
environment conception. My initial C function in invoked from R (in some 
environment I suppose), how do I know this env, to provide it to eval()? 
Or, may I just make a clean env?


10.05.2013 00:13, Gabriel Becker ?????:
> Matwey,
>
> There are a number of ways to do this, but it depends on what exactly you
> want. Do you want to execute a call to an actual R function from within C,
> or do you want to directly call one of R's internal C functions (which may
> work but is not future-safe unless it is part of the official API).
>
> If its the first, see Martin Morgan's post here:
> http://stackoverflow.com/questions/7457635/calling-r-function-from-c for
> more detail about the approach I believe Simon is referring to. As for the
> second, they are normal C functions, but I believe the consensus is that if
> they aren't part of the API you are on your own figuring out how they work
> (the source code is available for this of course).
>
> Hope that helps,
> ~G


From edd at debian.org  Fri May 10 13:27:26 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 10 May 2013 06:27:26 -0500
Subject: [Rd] call R function from C code
In-Reply-To: <kmiev2$qj2$1@ger.gmane.org>
References: <kme57t$sca$1@ger.gmane.org>
	<2DC85D00-8F28-4EFA-BBE7-D5488B1DC894@r-project.org>
	<CADwqtCNZrAsF+j5NCqiAnqz7Go4eGSE5ctw0Hb0nYOjP6vswdA@mail.gmail.com>
	<kmiev2$qj2$1@ger.gmane.org>
Message-ID: <20876.55710.307173.454481@max.nulle.part>


On 10 May 2013 at 13:34, Matwey V. Kornilov wrote:
| Thanks, It is what I was looking for. But now, I poorly understand 
| environment conception. My initial C function in invoked from R (in some 
| environment I suppose), how do I know this env, to provide it to eval()? 
| Or, may I just make a clean env?

Given that you seem a little fuzzy about all this, may I suggest a pivot over
to Rcpp? While it uses C++ features, you are not really forced to use C++.
Here is one really quick example:

  R> library(Rcpp)
  R> cppFunction('NumericVector callRonVec(NumericVector x, Function f) { NumericVector res = f(x); return(res); }')
  R> callRonVec( (1:100)^2, fivenum)
  [1]     1.0   650.5  2550.5  5700.5 10000.0
  R> fivenum( (1:100)^2 )   # obviously the same
  [1]     1.0   650.5  2550.5  5700.5 10000.0
  R> 

All we are doing here is instantiating some variable.  You can access their
content and modify it C style if you so desire, or you can use the C++
features you like and ignore any others.  As you mentioned environment, you
can also pass down any R environment.

You can also combine this with other packages such as RcppArmadillo which
give you easy-to-use idioms often modeled after Matlab. One such example is
the solve() function at the C++ level.  Another quick example:

  R> X <- as.matrix(cbind(1:100, sqrt(1:100))); y <- rowSums(X) + rnorm(100)
  R> lm.fit(X,y)$coefficients       # fit in R as a baseline
        x1       x2 
  1.003357 0.981233 
  R> cppFunction('arma::vec mySolve(arma::mat x, arma::vec y) { return(solve(x,y)); }', depends="RcppArmadillo")
  R> mySolve(X, y)                  # no surprise, we get the same answer
           [,1]
  [1,] 1.003357
  [2,] 0.981233
  R> 

This use the Armadillo matrix and vector types, and calls solve() for you --
which will dispatch to the same BLAS functions R uses, but gets there at no
extra effort for you (besides having to read up on (Rcpp)Armadillo).  As a
side benefit, these things tend to be faster in C++.

Hope this helps.  The introductory vignettes to Rcpp and RcppArmadillo are
also available as papers in JSS (in 2011) and CSDA (2013, in press), and
there is a fair bit of other documentation out there.

Dirk
 
| 10.05.2013 00:13, Gabriel Becker ?????:
| > Matwey,
| >
| > There are a number of ways to do this, but it depends on what exactly you
| > want. Do you want to execute a call to an actual R function from within C,
| > or do you want to directly call one of R's internal C functions (which may
| > work but is not future-safe unless it is part of the official API).
| >
| > If its the first, see Martin Morgan's post here:
| > http://stackoverflow.com/questions/7457635/calling-r-function-from-c for
| > more detail about the approach I believe Simon is referring to. As for the
| > second, they are normal C functions, but I believe the consensus is that if
| > they aren't part of the API you are on your own figuring out how they work
| > (the source code is available for this of course).
| >
| > Hope that helps,
| > ~G
| 
| ______________________________________________
| R-devel at r-project.org mailing list
| https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From simon.urbanek at r-project.org  Fri May 10 14:37:41 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 10 May 2013 08:37:41 -0400
Subject: [Rd] call R function from C code
In-Reply-To: <kmiev2$qj2$1@ger.gmane.org>
References: <kme57t$sca$1@ger.gmane.org>
	<2DC85D00-8F28-4EFA-BBE7-D5488B1DC894@r-project.org>
	<CADwqtCNZrAsF+j5NCqiAnqz7Go4eGSE5ctw0Hb0nYOjP6vswdA@mail.gmail.com>
	<kmiev2$qj2$1@ger.gmane.org>
Message-ID: <AD1B2862-34DB-42E4-BCDF-52FCEE80ACC5@r-project.org>

On May 10, 2013, at 5:34 AM, Matwey V. Kornilov wrote:

> 
> Thanks, It is what I was looking for. But now, I poorly understand environment conception. My initial C function in invoked from R (in some environment I suppose), how do I know this env, to provide it to eval()? Or, may I just make a clean env?
> 

It depends on where you want to evaluate it. R_GlobalEnv is the most common - mostly it acts as if you evaluated it on the console. If you want a particular namespace (e.g. myPackage), you can use R_FindNamespace(mkString("myPackage")) to find it.

Cheers,
Simon


> 
> 10.05.2013 00:13, Gabriel Becker ?????:
>> Matwey,
>> 
>> There are a number of ways to do this, but it depends on what exactly you
>> want. Do you want to execute a call to an actual R function from within C,
>> or do you want to directly call one of R's internal C functions (which may
>> work but is not future-safe unless it is part of the official API).
>> 
>> If its the first, see Martin Morgan's post here:
>> http://stackoverflow.com/questions/7457635/calling-r-function-from-c for
>> more detail about the approach I believe Simon is referring to. As for the
>> second, they are normal C functions, but I believe the consensus is that if
>> they aren't part of the API you are on your own figuring out how they work
>> (the source code is available for this of course).
>> 
>> Hope that helps,
>> ~G
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From matwey.kornilov at gmail.com  Fri May 10 14:55:00 2013
From: matwey.kornilov at gmail.com (Matwey V. Kornilov)
Date: Fri, 10 May 2013 16:55:00 +0400
Subject: [Rd] call R function from C code
In-Reply-To: <AD1B2862-34DB-42E4-BCDF-52FCEE80ACC5@r-project.org>
References: <kme57t$sca$1@ger.gmane.org>
	<2DC85D00-8F28-4EFA-BBE7-D5488B1DC894@r-project.org>
	<CADwqtCNZrAsF+j5NCqiAnqz7Go4eGSE5ctw0Hb0nYOjP6vswdA@mail.gmail.com>
	<kmiev2$qj2$1@ger.gmane.org>
	<AD1B2862-34DB-42E4-BCDF-52FCEE80ACC5@r-project.org>
Message-ID: <kmiqmv$mv9$1@ger.gmane.org>


Thank you all,

the following seems to work just great for me:

PROTECT(sx = eval(lang3(install("solve"),sA,sb),R_BaseEnv))


From radford at cs.toronto.edu  Sat May 11 17:27:21 2013
From: radford at cs.toronto.edu (Radford Neal)
Date: Sat, 11 May 2013 11:27:21 -0400
Subject: [Rd] call R function from C code
Message-ID: <20130511152721.GA23097@cs.toronto.edu>

> From: "Matwey V. Kornilov" <matwey.kornilov at gmail.com>
>
> the following seems to work just great for me:
>
> PROTECT(sx = eval(lang3(install("solve"),sA,sb),R_BaseEnv))

You need to PROTECT the result of lang3 before calling eval.
And on the other hand, you don't necessarily have to protect
the result of eval (only if you will be doing further allocations
while still using sx).

   Radford Neal


From dwinsemius at comcast.net  Mon May 13 19:21:33 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 13 May 2013 10:21:33 -0700
Subject: [Rd] Documentation request Re: [R] recode categorial vars into
	binary data
In-Reply-To: <51893FF2.4090602@lanl.gov>
References: <A94D31B3-1F03-4D34-AEB4-57AC14091B1C@comcast.net>
	<51893FF2.4090602@lanl.gov>
Message-ID: <FC69986C-21A6-4A36-8072-9FCE81AC7BD4@comcast.net>


On May 7, 2013, at 10:54 AM, Chris Stubben wrote:

> 
>> First off, stop using cbind() when it is not needed. You will not see the reason when the columns are all numeric but you will start experiencing pain and puzzlement when the arguments are of mixed classes. The data.frame function will do what you want. (Where do people pick up this practice anyway?)
> 
> Maybe from help( data.frame)?
> 
> It's in most of the  examples and is not needed ...
> 
> L3 <- LETTERS[1:3]
>    (d <- data.frame(cbind(x=1, y=1:10), fac=sample(L3, 10, replace=TRUE)))
>        ## The same with automatic column names:
>    data.frame(cbind(  1,   1:10),     sample(L3, 10, replace=TRUE))
>    
> Chris

There are many instances of new users posting questions to R-help where they use the form:

dfrm <- data.frame(cbind(1:10, letter[1:10]) )

? and predictably get a character mode for all their columns. I was pointed to the help page for `data.frame` as one possible source of this confusion. I would like to request that the examples be changed to: 

L3 <- LETTERS[1:3]
(d <- data.frame(x = 1, y = 1:10, fac = sample(L3, 10, replace = TRUE)))

## The same with automatic column names:
data.frame( 1,   1:10,     sample(L3, 10, replace = TRUE))

--

David Winsemius
Alameda, CA, USA


From cuiyan at tjutcm.edu.cn  Tue May 14 03:16:24 2013
From: cuiyan at tjutcm.edu.cn (cuiyan)
Date: Mon, 13 May 2013 18:16:24 -0700 (PDT)
Subject: [Rd] Segmentation fault on Python+Rpy2+R
Message-ID: <1368494184638-4666997.post@n4.nabble.com>

Hi, everyone
I met a trouble, not only about R, but Python+RPy2+R
When I run "from rpy2 import robjects" or other packages/codes,
I receive "Segmentation Fault" inevitably like this:

linux-yhwx:/ # python
Python 2.7.2 (default, Aug 19 2011, 20:41:43) [GCC] on linux2
Type "help", "copyright", "credits" or "license" for more information.
>>> import rpy2
>>> rpy2.__version__
'2.2.2'
>>> import rpy2.tests
Segmentation fault
linux-yhwx:/ # 

My OS on cluster is Suse family (not ubuntu or other linuxes),
R is 2.15.2-devel
Python 2.7.2 and RPy 2.2.2 as described above.

Where can I find how this happens or deal with this segment fault?



--
View this message in context: http://r.789695.n4.nabble.com/Segmentation-fault-on-Python-Rpy2-R-tp4666997.html
Sent from the R devel mailing list archive at Nabble.com.


From praguewatermelon at gmail.com  Tue May 14 06:42:13 2013
From: praguewatermelon at gmail.com (Xiao He)
Date: Mon, 13 May 2013 21:42:13 -0700
Subject: [Rd] =?windows-1252?q?invalid_operands_of_types_=91SEXPREC*=92_an?=
	=?windows-1252?q?d_=91R=5Flen=5Ft=92_to_binary_=91operator/=92_wit?=
	=?windows-1252?q?h_Rcpp=2E?=
Message-ID: <CAGBzz=Jg5KSKE=0g_i8EyhfjR_k_6ivPpyAmFHhKyVHuQbOLVQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130513/e3c91261/attachment.pl>

From romain at r-enthusiasts.com  Tue May 14 15:37:56 2013
From: romain at r-enthusiasts.com (Romain Francois)
Date: Tue, 14 May 2013 15:37:56 +0200
Subject: [Rd] =?utf-8?q?invalid_operands_of_types_=E2=80=98SEXPREC*?=
 =?utf-8?b?4oCZIGFuZCDigJhSX2xlbl904oCZIHRvIGJpbmFyeSDigJhvcGVyYXRvci8=?=
 =?utf-8?b?4oCZIHdpdGggUmNwcC4=?=
In-Reply-To: <CAGBzz=Jg5KSKE=0g_i8EyhfjR_k_6ivPpyAmFHhKyVHuQbOLVQ@mail.gmail.com>
References: <CAGBzz=Jg5KSKE=0g_i8EyhfjR_k_6ivPpyAmFHhKyVHuQbOLVQ@mail.gmail.com>
Message-ID: <EFD4F968-7262-4D5F-8D32-EDA60D6F16C2@r-enthusiasts.com>

Please use the appropriate mailing list (Rcpp-devel) for Rcpp questions. 

Romain

Le 14 mai 2013 ? 06:42, Xiao He <praguewatermelon at gmail.com> a ?crit :

> Dear R-Developers,
> 
> I just started learning how to use Rcpp. Earlier while using it, I
> encountered an error as shown below:
> 
> file74d8254b96d4.cpp: In function ?Rcpp::NumericVector
> foo(Rcpp::NumericVector, Rcpp::NumericVector, Rcpp::NumericVector,
> Rcpp::Function, Rcpp::Function)?:
> file74d8254b96d4.cpp:10: error: invalid operands of types ?SEXPREC*? and
> ?R_len_t? to binary ?operator/?
> make: *** [file74d8254b96d4.o] Error 1
> 
> Below is a mock function that can reproduce this error. I wonder if anyone
> can tell me what is the problem here. Thank you in advance!!
> 
> foo<-cppFunction('
>   NumericVector foo(NumericVector q, NumericVector shape1, NumericVector
> shape2, Function pbeta, Function sequence){
>         NumericVector output(q.size());
>         output=pbeta(sequence(q.size())/q.size(), shape1, shape2);
>        return output;
> }
> ')
> 
> 
> Best,
> Xiao
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From edd at debian.org  Tue May 14 15:39:26 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 14 May 2013 08:39:26 -0500
Subject: [Rd] =?utf-8?q?invalid_operands_of_types_=E2=80=98SEXPREC*?=
	=?utf-8?b?4oCZIGFuIGQg4oCYUl9sZW5fdOKAmSB0byBiaW5hcnkg4oCYb3BlcmF0?=
	=?utf-8?b?b3Iv4oCZIHdpdAloIFJjcHAu?=
In-Reply-To: <CAGBzz=Jg5KSKE=0g_i8EyhfjR_k_6ivPpyAmFHhKyVHuQbOLVQ@mail.gmail.com>
References: <CAGBzz=Jg5KSKE=0g_i8EyhfjR_k_6ivPpyAmFHhKyVHuQbOLVQ@mail.gmail.com>
Message-ID: <20882.16014.789871.565579@max.nulle.part>


On 13 May 2013 at 21:42, Xiao He wrote:
| Dear R-Developers,
| 
| I just started learning how to use Rcpp. Earlier while using it, I
| encountered an error as shown below:
| 
| file74d8254b96d4.cpp: In function ?Rcpp::NumericVector
| foo(Rcpp::NumericVector, Rcpp::NumericVector, Rcpp::NumericVector,
| Rcpp::Function, Rcpp::Function)?:
| file74d8254b96d4.cpp:10: error: invalid operands of types ?SEXPREC*? and
| ?R_len_t? to binary ?operator/?
| make: *** [file74d8254b96d4.o] Error 1
| 
| Below is a mock function that can reproduce this error. I wonder if anyone
| can tell me what is the problem here. Thank you in advance!!
| 
| foo<-cppFunction('
|    NumericVector foo(NumericVector q, NumericVector shape1, NumericVector
| shape2, Function pbeta, Function sequence){
|          NumericVector output(q.size());
|          output=pbeta(sequence(q.size())/q.size(), shape1, shape2);
|         return output;
|  }
|  ')

Really briefly:

 1)  Wrong mailing list. Rcpp question are to be sent to rcpp-devel

 2)  Possible error in your function setup.  Why do you supply pbeta?  What is sequence?

 3)  Error in how you call pbeta.  The first argument is a vector, the other
     two are scalars.

 4)  Compiler error is pretty clear for once: it does not understand the
     division, and you only have one so look there.


Here is a minimal working example:

library(Rcpp)
foo<-cppFunction('NumericVector foo(NumericVector q, double shape1, double shape2){
  return pbeta(q, shape1, shape2);                                                                                                                                                                                }')  

for which I get

R> source('/tmp/foo.R')
R> foo(seq(0.1, 0.5, by=0.1), 2, 3)
[1] 0.0523 0.1808 0.3483 0.5248 0.6875

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From edd at debian.org  Tue May 14 15:47:33 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 14 May 2013 08:47:33 -0500
Subject: [Rd] call R function from C code
In-Reply-To: <kmiqmv$mv9$1@ger.gmane.org>
References: <kme57t$sca$1@ger.gmane.org>
	<2DC85D00-8F28-4EFA-BBE7-D5488B1DC894@r-project.org>
	<CADwqtCNZrAsF+j5NCqiAnqz7Go4eGSE5ctw0Hb0nYOjP6vswdA@mail.gmail.com>
	<kmiev2$qj2$1@ger.gmane.org>
	<AD1B2862-34DB-42E4-BCDF-52FCEE80ACC5@r-project.org>
	<kmiqmv$mv9$1@ger.gmane.org>
Message-ID: <20882.16501.602851.955871@max.nulle.part>


If you are fine with another package doing the legwork for you, calling an R
function from C++ is very easy:

R> library(Rcpp)
R> cppFunction('NumericVector fun(NumericMatrix X, NumericVector y, Function s) { return s(X, y); }')
R> set.seed(42); solve(matrix(rnorm(9),3,3), rep(1,3))
[1] -0.778649  1.553893  0.717221
R> set.seed(42); fun(matrix(rnorm(9),3,3), rep(1,3), solve)
[1] -0.778649  1.553893  0.717221
R> 

So the C++ function 'fun' we created using Rcpp, and which just calls the
supplied function on the first two arguments, returns us the same answer from
C++ as we get when we call solve(X, y) in R.

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From praguewatermelon at gmail.com  Tue May 14 15:47:43 2013
From: praguewatermelon at gmail.com (Xiao He)
Date: Tue, 14 May 2013 06:47:43 -0700
Subject: [Rd]
	=?windows-1252?q?invalid_operands_of_types_=91SEXPREC*=92_an?=
	=?windows-1252?q?_d_=91R=5Flen=5Ft=92_to_binary_=91operator/=92_wi?=
	=?windows-1252?q?t_h_Rcpp=2E?=
In-Reply-To: <20882.16014.789871.565579@max.nulle.part>
References: <CAGBzz=Jg5KSKE=0g_i8EyhfjR_k_6ivPpyAmFHhKyVHuQbOLVQ@mail.gmail.com>
	<20882.16014.789871.565579@max.nulle.part>
Message-ID: <CAGBzz=L=-BMjx0fZP76G4GEZUpXAs40_HMK+Q6EPZMSW=KsO-A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130514/b68a2e92/attachment.pl>

From edd at debian.org  Tue May 14 16:17:35 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 14 May 2013 09:17:35 -0500
Subject: [Rd] =?utf-8?q?invalid_operands_of_types_=E2=80=98SEXPREC*?=
	=?utf-8?b?4oCZIGFuIGQg4oCYUl9sZW5fdOKAmSB0byBiaW5hcnkg4oCYb3BlcmF0?=
	=?utf-8?b?b3Iv4oCZIHdpdCBoIFJjcHAu?=
In-Reply-To: <CAGBzz=L=-BMjx0fZP76G4GEZUpXAs40_HMK+Q6EPZMSW=KsO-A@mail.gmail.com>
References: <CAGBzz=Jg5KSKE=0g_i8EyhfjR_k_6ivPpyAmFHhKyVHuQbOLVQ@mail.gmail.com>
	<20882.16014.789871.565579@max.nulle.part>
	<CAGBzz=L=-BMjx0fZP76G4GEZUpXAs40_HMK+Q6EPZMSW=KsO-A@mail.gmail.com>
Message-ID: <20882.18303.905778.385712@max.nulle.part>


On 14 May 2013 at 06:47, Xiao He wrote:
| Thank you!
| 
| I will send my reply to Rcpp-devel from now on Re: my question -. Since I
| thought cppFunction() allows vectorized operations, I thought any R functions I
| call from R would also allow it. pbeta() within R can be specified as ?pbeta
| (runif(10), 1, 2) where the first argument is a vector. 


And of course so does the pbeta() we offer in Rcpp, and so does the example I
posted below.

| the function sequence()
| basically takes an integer, and produce a vector of consecutive integers
| starting from 1 to the provided value.?

Ie the same as typing  1:N  ?

Dirk
 
| 
| Best,
| Xiao
| 
| On Tue, May 14, 2013 at 6:39 AM, Dirk Eddelbuettel <edd at debian.org> wrote:
| 
| 
|     On 13 May 2013 at 21:42, Xiao He wrote:
|     | Dear R-Developers,
|     |
|     | I just started learning how to use Rcpp. Earlier while using it, I
|     | encountered an error as shown below:
|     |
|     | file74d8254b96d4.cpp: In function ?Rcpp::NumericVector
|     | foo(Rcpp::NumericVector, Rcpp::NumericVector, Rcpp::NumericVector,
|     | Rcpp::Function, Rcpp::Function)?:
|     | file74d8254b96d4.cpp:10: error: invalid operands of types ?SEXPREC*?
|     and
|     | ?R_len_t? to binary ?operator/?
|     | make: *** [file74d8254b96d4.o] Error 1
|     |
|     | Below is a mock function that can reproduce this error. I wonder if
|     anyone
|     | can tell me what is the problem here. Thank you in advance!!
|     |
|     | foo<-cppFunction('
|     | ? ?NumericVector foo(NumericVector q, NumericVector shape1,
|     NumericVector
|     | shape2, Function pbeta, Function sequence){
|     | ? ? ? ? ?NumericVector output(q.size());
|     | ? ? ? ? ?output=pbeta(sequence(q.size())/q.size(), shape1, shape2);
|     | ? ? ? ? return output;
|     | ?}
|     | ?')
| 
|     Really briefly:
| 
|     ?1) ?Wrong mailing list. Rcpp question are to be sent to rcpp-devel
| 
|     ?2) ?Possible error in your function setup. ?Why do you supply pbeta?
|     ?What is sequence?
| 
|     ?3) ?Error in how you call pbeta. ?The first argument is a vector, the
|     other
|     ? ? ?two are scalars.
| 
|     ?4) ?Compiler error is pretty clear for once: it does not understand the
|     ? ? ?division, and you only have one so look there.
| 
| 
|     Here is a minimal working example:
| 
|     library(Rcpp)
|     foo<-cppFunction('NumericVector foo(NumericVector q, double shape1, double
|     shape2){
|     ? return pbeta(q, shape1, shape2); ? ? ? ? ? ? ? ? ? ? ? ? ?
|     ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
|     ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
|     ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?}
|     ')
| 
|     for which I get
| 
|     R> source('/tmp/foo.R')
|     R> foo(seq(0.1, 0.5, by=0.1), 2, 3)
|     [1] 0.0523 0.1808 0.3483 0.5248 0.6875
|    
|     Dirk
| 
|     --
|     Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com
| 
| 

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From maechler at stat.math.ethz.ch  Tue May 14 17:44:43 2013
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 14 May 2013 17:44:43 +0200
Subject: [Rd] Documentation request Re: [R] recode categorial vars into
	binary data
In-Reply-To: <FC69986C-21A6-4A36-8072-9FCE81AC7BD4@comcast.net>
References: <A94D31B3-1F03-4D34-AEB4-57AC14091B1C@comcast.net>
	<51893FF2.4090602@lanl.gov>
	<FC69986C-21A6-4A36-8072-9FCE81AC7BD4@comcast.net>
Message-ID: <20882.23531.134362.54519@stat.math.ethz.ch>

>>>>> David Winsemius <dwinsemius at comcast.net>
>>>>>     on Mon, 13 May 2013 10:21:33 -0700 writes:

    > On May 7, 2013, at 10:54 AM, Chris Stubben wrote:

    >> 
    >>> First off, stop using cbind() when it is not needed. You will not see the reason when the columns are all numeric but you will start experiencing pain and puzzlement when the arguments are of mixed classes. The data.frame function will do what you want. (Where do people pick up this practice anyway?)

I had asked the same (in the past)...
and you guess a probable answer below.


    >> Maybe from help( data.frame)?
    >> 
    >> It's in most of the  examples and is not needed ...
    >> 
    >> L3 <- LETTERS[1:3]
    >> (d <- data.frame(cbind(x=1, y=1:10), fac=sample(L3, 10, replace=TRUE)))
    >> ## The same with automatic column names:
    >> data.frame(cbind(  1,   1:10),     sample(L3, 10, replace=TRUE))
    >> 
    >> Chris

    > There are many instances of new users posting questions to R-help where they use the form:

    > dfrm <- data.frame(cbind(1:10, letter[1:10]) )

    > ? and predictably get a character mode for all their columns. I was pointed to the help page for `data.frame` as one possible source of this confusion. I would like to request that the examples be changed to: 

    > L3 <- LETTERS[1:3]
    > (d <- data.frame(x = 1, y = 1:10, fac = sample(L3, 10, replace = TRUE)))

    > ## The same with automatic column names:
    > data.frame( 1,   1:10,     sample(L3, 10, replace = TRUE))

Very good suggestion.... notably if your guess was right !

Unfortunately, this cannot make it into 3.0.1  (the examples are
*run* etc... to much for "deep code freeze" we are in now).
But I plan to backport the change to  "3.0.1 patched" once that
is released...

all in the big hope that people will *STOP* using
    data.frame( cbind( ... ) ) 
in a habitual way.

Martin

    > --
    > David Winsemius
    > Alameda, CA, USA

PS: Are there other suggestions to help people *stop* using

    ifelse(A, B, C)  

    	      in those many places where they should use

    if(A) B else C
?


From wdunlap at tibco.com  Tue May 14 21:23:56 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 14 May 2013 19:23:56 +0000
Subject: [Rd] problem in add1's F statistic when data contains NAs?
Message-ID: <E66794E69CFDE04D9A70842786030B931C2EB031@PA-MBX01.na.tibco.com>

Shouldn't the F statistic (and p value) for the x2 term in the following calls
to anova() and add1() be the same?  I think anova() gets it right and add1()
does not.

> d <- data.frame(y=1:10, x1=log(1:10), x2=replace(1/(1:10), 2:3, NA))
> anova(lm(y ~ x1 + x2, data=d))
Analysis of Variance Table

Response: y
          Df    Sum Sq   Mean Sq    F value     Pr(>F)    
x1         1 52.905613 52.905613 1108.61455 4.5937e-07 ***
x2         1  6.355775  6.355775  133.18256 8.5678e-05 ***
Residuals  5  0.238611  0.047722                          
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
> add1(lm(y ~ x1, data=d), y ~ x1 + x2, test="F")
Single term additions

Model:
y ~ x1
       Df Sum of Sq       RSS         AIC   F value     Pr(>F)    
<none>              6.5943869   2.4542182                         
x2      1 6.3557755 0.2386114 -22.0988844 186.45559 2.6604e-06 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
Warning message:
In add1.lm(lm(y ~ x1, data = d), y ~ x1 + x2, test = "F") :
  using the 8/10 rows from a combined fit

It looks like add1 is using 7 instead of 5 for the denominator degrees of freedom,
7 being the value in the original fit, before the 2 rows containing NA's in x2
were omitted.

> (6.355775/1) / (0.238611/5)
[1] 133.1827745
> (6.355775/1) / (0.238611/7)
[1] 186.4558843

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


From hpages at fhcrc.org  Wed May 15 00:14:48 2013
From: hpages at fhcrc.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Tue, 14 May 2013 15:14:48 -0700
Subject: [Rd] Documentation request Re: [R] recode categorial vars into
 binary data
In-Reply-To: <20882.23531.134362.54519@stat.math.ethz.ch>
References: <A94D31B3-1F03-4D34-AEB4-57AC14091B1C@comcast.net>
	<51893FF2.4090602@lanl.gov>
	<FC69986C-21A6-4A36-8072-9FCE81AC7BD4@comcast.net>
	<20882.23531.134362.54519@stat.math.ethz.ch>
Message-ID: <5192B758.20205@fhcrc.org>

Hi Martin,

On 05/14/2013 08:44 AM, Martin Maechler wrote:
[...]
>
> PS: Are there other suggestions to help people *stop* using
>
>      ifelse(A, B, C)
>
>      	      in those many places where they should use
>
>      if(A) B else C
> ?

Or to help people stop using

   if (... & ...)
   if (... | ...)

in those many places where they should use

   if (... && ...)
   if (... || ...)

Cheers,
H.


>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From santoshdvn at gmail.com  Wed May 15 08:05:09 2013
From: santoshdvn at gmail.com (santoshdvn)
Date: Tue, 14 May 2013 23:05:09 -0700 (PDT)
Subject: [Rd] Missing Dependency: tex(latex) is needed by package R-devel -
 Help Required
Message-ID: <1368597909439-4667090.post@n4.nabble.com>

Hi ALl,


I am trying to install R on RHEL 5.4 

while install R i am getting the dependency errors ..

can you please help on this . 

[root at Rgraph ~]# yum install R
Loaded plugins: rhnplugin, security
This system is not registered with RHN.
RHN support will be disabled.
Setting up Install Process
Parsing package install arguments
Resolving Dependencies
--> Running transaction check
---> Package R.x86_64 0:2.15.2-1.el5 set to be updated
--> Processing Dependency: libRmath-devel = 2.15.2-1.el5 for package: R
--> Processing Dependency: R-devel = 2.15.2-1.el5 for package: R
--> Running transaction check
---> Package libRmath-devel.x86_64 0:2.15.2-1.el5 set to be updated
--> Processing Dependency: libRmath = 2.15.2-1.el5 for package:
libRmath-devel
---> Package R-devel.x86_64 0:2.15.2-1.el5 set to be updated
--> Processing Dependency: R-core = 2.15.2-1.el5 for package: R-devel
--> Processing Dependency: tk-devel for package: R-devel
--> Processing Dependency: texinfo-tex for package: R-devel
--> Processing Dependency: tex(latex) for package: R-devel
--> Processing Dependency: tcl-devel for package: R-devel
--> Processing Dependency: pcre-devel for package: R-devel
--> Running transaction check
---> Package R-devel.x86_64 0:2.15.2-1.el5 set to be updated
--> Processing Dependency: tex(latex) for package: R-devel
---> Package pcre-devel.x86_64 0:6.6-2.el5_1.7 set to be updated
---> Package tcl-devel.x86_64 0:8.4.13-3.fc6 set to be updated
---> Package tk-devel.x86_64 0:8.4.13-5.el5_1.1 set to be updated
---> Package R-core.x86_64 0:2.15.2-1.el5 set to be updated
--> Processing Dependency: xdg-utils for package: R-core
--> Processing Dependency: tex(latex) for package: R-core
---> Package libRmath.x86_64 0:2.15.2-1.el5 set to be updated
---> Package texinfo-tex.x86_64 0:4.8-14.el5 set to be updated
--> Processing Dependency: tetex for package: texinfo-tex
--> Running transaction check
---> Package R-devel.x86_64 0:2.15.2-1.el5 set to be updated
--> Processing Dependency: tex(latex) for package: R-devel
---> Package xdg-utils.noarch 0:1.0.2-4.el5 set to be updated
---> Package R-core.x86_64 0:2.15.2-1.el5 set to be updated
--> Processing Dependency: tex(latex) for package: R-core
---> Package tetex.x86_64 0:3.0-33.2.el5_1.2 set to be updated
--> Processing Dependency: tetex-fonts = 3.0 for package: tetex
--> Processing Dependency: dialog for package: tetex
--> Running transaction check
---> Package R-devel.x86_64 0:2.15.2-1.el5 set to be updated
--> Processing Dependency: tex(latex) for package: R-devel
---> Package tetex-fonts.x86_64 0:3.0-33.2.el5_1.2 set to be updated
---> Package dialog.x86_64 0:1.0.20051107-1.2.2 set to be updated
---> Package R-core.x86_64 0:2.15.2-1.el5 set to be updated
--> Processing Dependency: tex(latex) for package: R-core
--> Finished Dependency Resolution
R-core-2.15.2-1.el5.x86_64 from epel has depsolving problems
  --> Missing Dependency: tex(latex) is needed by package
R-core-2.15.2-1.el5.x86_64 (epel)
R-devel-2.15.2-1.el5.x86_64 from epel has depsolving problems
  --> Missing Dependency: tex(latex) is needed by package
R-devel-2.15.2-1.el5.x86_64 (epel)
Error: Missing Dependency: tex(latex) is needed by package
R-devel-2.15.2-1.el5.x86_64 (epel)
Error: Missing Dependency: tex(latex) is needed by package
R-core-2.15.2-1.el5.x86_64 (epel)
[root at Rgraph ~]#


Regards,
santosh



--
View this message in context: http://r.789695.n4.nabble.com/Missing-Dependency-tex-latex-is-needed-by-package-R-devel-Help-Required-tp4667090.html
Sent from the R devel mailing list archive at Nabble.com.


From marc_schwartz at me.com  Wed May 15 14:20:56 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 15 May 2013 07:20:56 -0500
Subject: [Rd] Missing Dependency: tex(latex) is needed by package
 R-devel - Help Required
In-Reply-To: <1368597909439-4667090.post@n4.nabble.com>
References: <1368597909439-4667090.post@n4.nabble.com>
Message-ID: <C9E04DC8-2D31-4695-9D10-81BC3584BF93@me.com>

On May 15, 2013, at 1:05 AM, santoshdvn <santoshdvn at gmail.com> wrote:

> Hi ALl,
> 
> 
> I am trying to install R on RHEL 5.4 
> 
> while install R i am getting the dependency errors ..
> 
> can you please help on this . 
> 
> [root at Rgraph ~]# yum install R
> Loaded plugins: rhnplugin, security
> This system is not registered with RHN.
> RHN support will be disabled.
> Setting up Install Process
> Parsing package install arguments
> Resolving Dependencies
> --> Running transaction check
> ---> Package R.x86_64 0:2.15.2-1.el5 set to be updated
> --> Processing Dependency: libRmath-devel = 2.15.2-1.el5 for package: R
> --> Processing Dependency: R-devel = 2.15.2-1.el5 for package: R
> --> Running transaction check
> ---> Package libRmath-devel.x86_64 0:2.15.2-1.el5 set to be updated
> --> Processing Dependency: libRmath = 2.15.2-1.el5 for package:
> libRmath-devel
> ---> Package R-devel.x86_64 0:2.15.2-1.el5 set to be updated
> --> Processing Dependency: R-core = 2.15.2-1.el5 for package: R-devel
> --> Processing Dependency: tk-devel for package: R-devel
> --> Processing Dependency: texinfo-tex for package: R-devel
> --> Processing Dependency: tex(latex) for package: R-devel
> --> Processing Dependency: tcl-devel for package: R-devel
> --> Processing Dependency: pcre-devel for package: R-devel
> --> Running transaction check
> ---> Package R-devel.x86_64 0:2.15.2-1.el5 set to be updated
> --> Processing Dependency: tex(latex) for package: R-devel
> ---> Package pcre-devel.x86_64 0:6.6-2.el5_1.7 set to be updated
> ---> Package tcl-devel.x86_64 0:8.4.13-3.fc6 set to be updated
> ---> Package tk-devel.x86_64 0:8.4.13-5.el5_1.1 set to be updated
> ---> Package R-core.x86_64 0:2.15.2-1.el5 set to be updated
> --> Processing Dependency: xdg-utils for package: R-core
> --> Processing Dependency: tex(latex) for package: R-core
> ---> Package libRmath.x86_64 0:2.15.2-1.el5 set to be updated
> ---> Package texinfo-tex.x86_64 0:4.8-14.el5 set to be updated
> --> Processing Dependency: tetex for package: texinfo-tex
> --> Running transaction check
> ---> Package R-devel.x86_64 0:2.15.2-1.el5 set to be updated
> --> Processing Dependency: tex(latex) for package: R-devel
> ---> Package xdg-utils.noarch 0:1.0.2-4.el5 set to be updated
> ---> Package R-core.x86_64 0:2.15.2-1.el5 set to be updated
> --> Processing Dependency: tex(latex) for package: R-core
> ---> Package tetex.x86_64 0:3.0-33.2.el5_1.2 set to be updated
> --> Processing Dependency: tetex-fonts = 3.0 for package: tetex
> --> Processing Dependency: dialog for package: tetex
> --> Running transaction check
> ---> Package R-devel.x86_64 0:2.15.2-1.el5 set to be updated
> --> Processing Dependency: tex(latex) for package: R-devel
> ---> Package tetex-fonts.x86_64 0:3.0-33.2.el5_1.2 set to be updated
> ---> Package dialog.x86_64 0:1.0.20051107-1.2.2 set to be updated
> ---> Package R-core.x86_64 0:2.15.2-1.el5 set to be updated
> --> Processing Dependency: tex(latex) for package: R-core
> --> Finished Dependency Resolution
> R-core-2.15.2-1.el5.x86_64 from epel has depsolving problems
>  --> Missing Dependency: tex(latex) is needed by package
> R-core-2.15.2-1.el5.x86_64 (epel)
> R-devel-2.15.2-1.el5.x86_64 from epel has depsolving problems
>  --> Missing Dependency: tex(latex) is needed by package
> R-devel-2.15.2-1.el5.x86_64 (epel)
> Error: Missing Dependency: tex(latex) is needed by package
> R-devel-2.15.2-1.el5.x86_64 (epel)
> Error: Missing Dependency: tex(latex) is needed by package
> R-core-2.15.2-1.el5.x86_64 (epel)
> [root at Rgraph ~]#
> 
> 
> Regards,
> santosh



First, this question should have been posted to R-SIG-Fedora:

  https://stat.ethz.ch/mailman/listinfo/r-sig-fedora

which covers RH based (RHEL/CentOS/Fedora) Linux distributions.

That being said, RHEL requires a paid subscription to utilize the Red Hat Network (RHN). It would appear that either you are not logged into RHN and/or you have not paid for support. You need to resolve that problem.

If you do not want to pay for support and stay with an RHEL compatible distribution, consider CentOS:

  http://www.centos.org/

Regards,

Marc Schwartz


From Robert.McGehee at geodecapital.com  Wed May 15 17:54:26 2013
From: Robert.McGehee at geodecapital.com (McGehee, Robert)
Date: Wed, 15 May 2013 11:54:26 -0400
Subject: [Rd] Substitute unaware when promise objects are evaluated
Message-ID: <17B09E7789D3104E8F5EEB0582A8D66FF25D00B8E5@MSGRTPCCRF2WIN.DMN1.FMR.COM>

R-devel,
I used the 'substitute' function to create labels for objects inside an environment, without actually evaluating the objects, as the objects might be promises.

However, I was surprised to see that 'substitute' returns the expression slot of the original promise even after the promise has been forcibly evaluated. (Doesn't the promise go away after evaluation?) This behavior probably falls under the "...no guarantee that the resulting expression makes any sense" clause of the ?substitute documentation, but in case there's something actually wrong here, I thought I'd send an example.

Here's an example showing how the evaluated expression returned by substitute does not match the actual variable value:

> env <- new.env()
> z <- 0
> delayedAssign("var", z+2, assign.env=env)
> substitute(var, env=env)
z + 2
> force(env$var)
[1] 2
> z <- 10
> substitute(var, env=env)
z + 2
> eval(substitute(var, env=env))
[1] 12
> force(env$var)
[1] 2

Is there any obvious way to code around this behavior, e.g. can I explicitly check if an object in an environment is an unevaluated promise?

Thanks, 
Robert

> R.version
               _
platform       x86_64-pc-linux-gnu
arch           x86_64
os             linux-gnu
system         x86_64, linux-gnu
status
major          3
minor          0.0
year           2013
month          04
day            03
svn rev        62481
language       R
version.string R version 3.0.0 (2013-04-03)
nickname       Masked Marvel

Robert McGehee, CFA
Geode Capital Management, LLC
One Post Office Square, 28th Floor | Boston, MA | 02109
Direct: (617)392-8396


From murdoch.duncan at gmail.com  Thu May 16 00:03:57 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 15 May 2013 18:03:57 -0400
Subject: [Rd] Substitute unaware when promise objects are evaluated
In-Reply-To: <17B09E7789D3104E8F5EEB0582A8D66FF25D00B8E5@MSGRTPCCRF2WIN.DMN1.FMR.COM>
References: <17B09E7789D3104E8F5EEB0582A8D66FF25D00B8E5@MSGRTPCCRF2WIN.DMN1.FMR.COM>
Message-ID: <5194064D.2040801@gmail.com>

On 13-05-15 11:54 AM, McGehee, Robert wrote:
> R-devel,
> I used the 'substitute' function to create labels for objects inside an environment, without actually evaluating the objects, as the objects might be promises.
>
> However, I was surprised to see that 'substitute' returns the expression slot of the original promise even after the promise has been forcibly evaluated. (Doesn't the promise go away after evaluation?) This behavior probably falls under the "...no guarantee that the resulting expression makes any sense" clause of the ?substitute documentation, but in case there's something actually wrong here, I thought I'd send an example.

I think you misunderstand promises.

A promise has two (or three, depending how you count) parts:  an 
expression with an associated environment, and a value.  The value isn't 
filled in until the expression is evaluated, but the expression doesn't 
go away then.  You can still see it until you change the variable that 
holds the promise.


> Here's an example showing how the evaluated expression returned by substitute does not match the actual variable value:
>
>> env <- new.env()
>> z <- 0
>> delayedAssign("var", z+2, assign.env=env)
>> substitute(var, env=env)
> z + 2

The documentation for substitute may not be clear on this, but for a 
promise, the env argument will be ignored.  It was the eval.env argument 
to delayedAssign that set the promise's environment.

>> force(env$var)
> [1] 2
>> z <- 10
>> substitute(var, env=env)
> z + 2
>> eval(substitute(var, env=env))
> [1] 12
>> force(env$var)
> [1] 2
>
> Is there any obvious way to code around this behavior, e.g. can I explicitly check if an object in an environment is an unevaluated promise?

Not at R level. In C code you could, but you probably shouldn't.  Think 
of promises as values where you can look up the expression that gave the 
value, and sometimes delay the calculation until you need it.

Duncan Murdoch


From ingo.korb at tu-dortmund.de  Thu May 16 11:26:44 2013
From: ingo.korb at tu-dortmund.de (Ingo Korb)
Date: Thu, 16 May 2013 11:26:44 +0200
Subject: [Rd] Incorrect target file name for gramLatex.c
Message-ID: <b9ab1e8599640541e31eaf44218fa397.squirrel@webmail.tu-dortmund.de>

Hi!

The attached patch changes the rule that describes the actions for
gramLatex.c in src/library/tools/src/Makefile.in so it actually
generates that file instead of "gramLatex." (no extension). The
file name without extension is not referenced anywhere else and
in R-2.12 the same rule still used the full name, so it appears
that the "c" was lost in editing somewhere along the way.

The patch was generated for R-3.0.1, but also applies cleanly to
R-devel_2013-05-14.

-ik
-------------- next part --------------
A non-text attachment was scrubbed...
Name: fix-gramLatex-name.patch
Type: text/x-diff
Size: 613 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130516/318aa2c3/attachment.bin>

From murdoch.duncan at gmail.com  Thu May 16 13:39:50 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 16 May 2013 07:39:50 -0400
Subject: [Rd] Incorrect target file name for gramLatex.c
In-Reply-To: <b9ab1e8599640541e31eaf44218fa397.squirrel@webmail.tu-dortmund.de>
References: <b9ab1e8599640541e31eaf44218fa397.squirrel@webmail.tu-dortmund.de>
Message-ID: <5194C586.1090303@gmail.com>

On 13-05-16 5:26 AM, Ingo Korb wrote:
> Hi!
>
> The attached patch changes the rule that describes the actions for
> gramLatex.c in src/library/tools/src/Makefile.in so it actually
> generates that file instead of "gramLatex." (no extension). The
> file name without extension is not referenced anywhere else and
> in R-2.12 the same rule still used the full name, so it appears
> that the "c" was lost in editing somewhere along the way.
>
> The patch was generated for R-3.0.1, but also applies cleanly to
> R-devel_2013-05-14.

Thanks, I'll put your fix in.

Duncan Murdoch


From pdalgd at gmail.com  Thu May 16 13:40:58 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 16 May 2013 13:40:58 +0200
Subject: [Rd] Incorrect target file name for gramLatex.c
In-Reply-To: <b9ab1e8599640541e31eaf44218fa397.squirrel@webmail.tu-dortmund.de>
References: <b9ab1e8599640541e31eaf44218fa397.squirrel@webmail.tu-dortmund.de>
Message-ID: <CE042BAE-6F34-4399-91C4-A3B585389EC9@gmail.com>

Thanks. Yes, that certainly looks like a copy/paste error when the gram* files was moved to tools. (I just wonder why we're not using $< $@ in these rules.) 

It should be harmless until someone tries actually modifying the grammar. (To avoid relying on yacc/bison, we ship the gram*.c along with gram*.y).

-pd

On May 16, 2013, at 11:26 , Ingo Korb wrote:

> Hi!
> 
> The attached patch changes the rule that describes the actions for
> gramLatex.c in src/library/tools/src/Makefile.in so it actually
> generates that file instead of "gramLatex." (no extension). The
> file name without extension is not referenced anywhere else and
> in R-2.12 the same rule still used the full name, so it appears
> that the "c" was lost in editing somewhere along the way.
> 
> The patch was generated for R-3.0.1, but also applies cleanly to
> R-devel_2013-05-14.
> 
> -ik
> <fix-gramLatex-name.patch>______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From andrea.franceschini at imls.uzh.ch  Thu May 16 14:03:34 2013
From: andrea.franceschini at imls.uzh.ch (andfra)
Date: Thu, 16 May 2013 14:03:34 +0200
Subject: [Rd] tools to document ReferenceClasses
Message-ID: <7B6354AF-B869-408E-A5E8-2735FA06854A@imls.uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130516/a64a2548/attachment.pl>

From Robert.McGehee at geodecapital.com  Thu May 16 15:06:27 2013
From: Robert.McGehee at geodecapital.com (McGehee, Robert)
Date: Thu, 16 May 2013 09:06:27 -0400
Subject: [Rd] Substitute / delayedAssign (was: Substitute unaware when
 promise objects are evaluated)
Message-ID: <17B09E7789D3104E8F5EEB0582A8D66FF25D00C072@MSGRTPCCRF2WIN.DMN1.FMR.COM>

Duncan, Thank you for the clarification on how delayedAssign works. Should R-level interfaces to promise objects ever become available, I expect they would at time come in handy.

On the subject of substitute and delayedAssign, I do have a follow-up question for the list. I'm trying to convert a named list of expression objects into an environment of promise objects. After conversion, each expression in the list will be automatically evaluated when the variable with the same name is accessed in the environment. Effectively, I'm trying to create a hash table of promise objects.

Here's the code I wrote that works just fine.

x <- list(a=3, b=expression(a+2), sleep=expression(Sys.sleep(2)))
env <- new.env()
for (i in seq(x)) {
	key <- names(x)[i]
	.Internal(delayedAssign(key,
				   eval(substitute(x[[i]], list(x=x, i=i)))[[1]],
				   eval.env=env, assign.env=env))
}	
env$b     # 3+2
[1] 5
env$sleep # Sleeps for 2 seconds
NULL  

The "problem" is that R CMD check complains that I shouldn't be using .Internal() to access the delayedAssign function. However, if I don't use .Internal(), then delayedAssign puts another substitute around my call that prevents the 'i' iterator variable from being evaluated at the correct time, which causes all variables to get the value x[[i]] for the very last value of 'i'.

Can I safely ignore this R CMD check warning about .Internal, or is there a better way to write this code?

Thanks, Robert



-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
Sent: Wednesday, May 15, 2013 6:04 PM
To: McGehee, Robert
Cc: R-Devel (r-devel at r-project.org)
Subject: Re: [Rd] Substitute unaware when promise objects are evaluated

On 13-05-15 11:54 AM, McGehee, Robert wrote:
> R-devel,
> I used the 'substitute' function to create labels for objects inside an environment, without actually evaluating the objects, as the objects might be promises.
>
> However, I was surprised to see that 'substitute' returns the expression slot of the original promise even after the promise has been forcibly evaluated. (Doesn't the promise go away after evaluation?) This behavior probably falls under the "...no guarantee that the resulting expression makes any sense" clause of the ?substitute documentation, but in case there's something actually wrong here, I thought I'd send an example.

I think you misunderstand promises.

A promise has two (or three, depending how you count) parts:  an 
expression with an associated environment, and a value.  The value isn't 
filled in until the expression is evaluated, but the expression doesn't 
go away then.  You can still see it until you change the variable that 
holds the promise.


> Here's an example showing how the evaluated expression returned by substitute does not match the actual variable value:
>
>> env <- new.env()
>> z <- 0
>> delayedAssign("var", z+2, assign.env=env)
>> substitute(var, env=env)
> z + 2

The documentation for substitute may not be clear on this, but for a 
promise, the env argument will be ignored.  It was the eval.env argument 
to delayedAssign that set the promise's environment.

>> force(env$var)
> [1] 2
>> z <- 10
>> substitute(var, env=env)
> z + 2
>> eval(substitute(var, env=env))
> [1] 12
>> force(env$var)
> [1] 2
>
> Is there any obvious way to code around this behavior, e.g. can I explicitly check if an object in an environment is an unevaluated promise?

Not at R level. In C code you could, but you probably shouldn't.  Think 
of promises as values where you can look up the expression that gave the 
value, and sometimes delay the calculation until you need it.

Duncan Murdoch


From murdoch.duncan at gmail.com  Thu May 16 15:49:07 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 16 May 2013 09:49:07 -0400
Subject: [Rd] Substitute / delayedAssign (was: Substitute unaware when
 promise objects are evaluated)
In-Reply-To: <17B09E7789D3104E8F5EEB0582A8D66FF25D00C072@MSGRTPCCRF2WIN.DMN1.FMR.COM>
References: <17B09E7789D3104E8F5EEB0582A8D66FF25D00C072@MSGRTPCCRF2WIN.DMN1.FMR.COM>
Message-ID: <5194E3D3.4010204@gmail.com>

On 16/05/2013 9:06 AM, McGehee, Robert wrote:
> Duncan, Thank you for the clarification on how delayedAssign works. Should R-level interfaces to promise objects ever become available, I expect they would at time come in handy.
>
> On the subject of substitute and delayedAssign, I do have a follow-up question for the list. I'm trying to convert a named list of expression objects into an environment of promise objects. After conversion, each expression in the list will be automatically evaluated when the variable with the same name is accessed in the environment. Effectively, I'm trying to create a hash table of promise objects.
>
> Here's the code I wrote that works just fine.
>
> x <- list(a=3, b=expression(a+2), sleep=expression(Sys.sleep(2)))
> env <- new.env()
> for (i in seq(x)) {
> 	key <- names(x)[i]
> 	.Internal(delayedAssign(key,
> 				   eval(substitute(x[[i]], list(x=x, i=i)))[[1]],
> 				   eval.env=env, assign.env=env))
> }	
> env$b     # 3+2
> [1] 5
> env$sleep # Sleeps for 2 seconds
> NULL
>
> The "problem" is that R CMD check complains that I shouldn't be using .Internal() to access the delayedAssign function. However, if I don't use .Internal(), then delayedAssign puts another substitute around my call that prevents the 'i' iterator variable from being evaluated at the correct time, which causes all variables to get the value x[[i]] for the very last value of 'i'.
>
> Can I safely ignore this R CMD check warning about .Internal, or is there a better way to write this code?

You should never call .Internal.  Arguments to internal functions may 
change without notice.

Here's one way to write your example without it.

x <- list(a=3, b=expression(a+2), sleep=expression(Sys.sleep(2)))
env <- new.env()

mydelay <- function(i) {
   expr <- x[[i]]
   name <- names(x)[i]
   do.call(delayedAssign, list(x=name, value=substitute(eval(expr), 
list(expr=expr)),
           eval.env=env, assign.env=env))
}

for (i in seq(x)) mydelay(i)

Duncan Murdoch


>
> Thanks, Robert
>
>
>
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: Wednesday, May 15, 2013 6:04 PM
> To: McGehee, Robert
> Cc: R-Devel (r-devel at r-project.org)
> Subject: Re: [Rd] Substitute unaware when promise objects are evaluated
>
> On 13-05-15 11:54 AM, McGehee, Robert wrote:
> > R-devel,
> > I used the 'substitute' function to create labels for objects inside an environment, without actually evaluating the objects, as the objects might be promises.
> >
> > However, I was surprised to see that 'substitute' returns the expression slot of the original promise even after the promise has been forcibly evaluated. (Doesn't the promise go away after evaluation?) This behavior probably falls under the "...no guarantee that the resulting expression makes any sense" clause of the ?substitute documentation, but in case there's something actually wrong here, I thought I'd send an example.
>
> I think you misunderstand promises.
>
> A promise has two (or three, depending how you count) parts:  an
> expression with an associated environment, and a value.  The value isn't
> filled in until the expression is evaluated, but the expression doesn't
> go away then.  You can still see it until you change the variable that
> holds the promise.
>
>
> > Here's an example showing how the evaluated expression returned by substitute does not match the actual variable value:
> >
> >> env <- new.env()
> >> z <- 0
> >> delayedAssign("var", z+2, assign.env=env)
> >> substitute(var, env=env)
> > z + 2
>
> The documentation for substitute may not be clear on this, but for a
> promise, the env argument will be ignored.  It was the eval.env argument
> to delayedAssign that set the promise's environment.
>
> >> force(env$var)
> > [1] 2
> >> z <- 10
> >> substitute(var, env=env)
> > z + 2
> >> eval(substitute(var, env=env))
> > [1] 12
> >> force(env$var)
> > [1] 2
> >
> > Is there any obvious way to code around this behavior, e.g. can I explicitly check if an object in an environment is an unevaluated promise?
>
> Not at R level. In C code you could, but you probably shouldn't.  Think
> of promises as values where you can look up the expression that gave the
> value, and sometimes delay the calculation until you need it.
>
> Duncan Murdoch


From jeroen.ooms at stat.ucla.edu  Thu May 16 20:12:50 2013
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Thu, 16 May 2013 11:12:50 -0700
Subject: [Rd] setTimeLimit sometimes fails to terminate idle call in R
Message-ID: <CABFfbXsBsTt4aHvTePo+0iCnkQ3df+RwcpwogXH40RmtB=BYiA@mail.gmail.com>

I would like to use setTimeLimit to abort operations that are stuck
waiting (idle) after n seconds. Below a toy example in which Sys.sleep
is a placeholder call that is idle:

testlimit <- function(){
  setTimeLimit(elapsed=3, transient=TRUE);
  Sys.sleep(10);
}
system.time(testlimit());

However this is giving inconsistent results. On windows and in
r-studio server (linux) the call is correctly aborted after 3 seconds.
However, when I run this in a terminal session in either on linux or
osx, the timeout is not triggered until after Sys.sleep() returns and
the total script takes 10+ seconds to complete.

What causes this difference? Is there something I can set in my
terminal R session such that the time limit is triggered? I am using
Ubuntu 13.04 (x64), and osx 10.8. Below three videos to illustrate the
issue:

  [1]: http://www.youtube.com/watch?v=d1qxbp2W2mY&hd=1
  [2]: http://www.youtube.com/watch?v=S0r-O9er4kU&hd=1
  [3]: http://www.youtube.com/watch?v=2D7TgtXUa3o&hd=1

> sessionInfo()
R version 3.0.1 RC (2013-05-10 r62729)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=C                 LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


From simon.urbanek at r-project.org  Thu May 16 20:56:45 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 16 May 2013 14:56:45 -0400
Subject: [Rd] setTimeLimit sometimes fails to terminate idle call in R
In-Reply-To: <CABFfbXsBsTt4aHvTePo+0iCnkQ3df+RwcpwogXH40RmtB=BYiA@mail.gmail.com>
References: <CABFfbXsBsTt4aHvTePo+0iCnkQ3df+RwcpwogXH40RmtB=BYiA@mail.gmail.com>
Message-ID: <9187D1C3-2FDD-4432-9FCE-FB4CEDC53A92@r-project.org>

Jeroen,

On May 16, 2013, at 2:12 PM, Jeroen Ooms wrote:

> I would like to use setTimeLimit to abort operations that are stuck
> waiting (idle) after n seconds. Below a toy example in which Sys.sleep
> is a placeholder call that is idle:
> 
> testlimit <- function(){
>  setTimeLimit(elapsed=3, transient=TRUE);
>  Sys.sleep(10);
> }
> system.time(testlimit());
> 
> However this is giving inconsistent results. On windows and in
> r-studio server (linux) the call is correctly aborted after 3 seconds.
> However, when I run this in a terminal session in either on linux or
> osx, the timeout is not triggered until after Sys.sleep() returns and
> the total script takes 10+ seconds to complete.
> 
> What causes this difference?

The time limit can only be checked in R_ProcessEvents() so for all practical purposes it can be only triggered by interruptible code that calls R_CheckUserInterrupt().
Now, it is entirely up to the front-end to decide how it will the the event loop. For example the terminal version of R has no other interrupts to worry about other than input handlers which trigger asynchronously, so it doesn't need to do any polling. Sys.sleep() only triggers on input handlers, so if you don't have any external event source hook as input handler, there is no reason to process any events so Sys.sleep() won't see any reason to check the time limit.


> Is there something I can set in my terminal R session such that the time limit is triggered?

On OS X it's actually very easy:

quartz(); dev.off()

will do the trick. The reason is that Quartz needs to force the event loop in order to process events from the window asynchronously. It does so by installing a timer-based input handler. This handler will make sure that Sys.sleep() will wake up every 100ms (you can change the value using QuartzCocoa_SetLatency) so it will timeout with that resolution:

> testlimit <- function(){
+  setTimeLimit(elapsed=3, transient=TRUE);
+  Sys.sleep(10);
+ }
> system.time(testlimit());
Error in Sys.sleep(10) : reached elapsed time limit
Timing stopped at: 0 0.001 10.001 
> quartz(); dev.off()
null device 
          1 
> testlimit <- function(){
+  setTimeLimit(elapsed=3, transient=TRUE);
+  Sys.sleep(10);
+ }
> system.time(testlimit());
Error in Sys.sleep(10) : reached elapsed time limit
Timing stopped at: 0.002 0.003 3.019 


On Linux, there is no built-in timer, so you'd have to add an input handler that will pre-empt Sys.sleep(). If you want a constant timer, you can simply borrow the code from Quartz (have a look at QuartzCocoa_SetupEventLoop in src/library/grDevices/src/qdCocoa.m) or the CarbonEL package. It's really just a pipe that is added as an input handler into which you write asynchronously when you want to wake up the event loop. On top of my head I can't think of a built-in solution in R at this point (even though it could be argued that R might install a handler itself when the limit is set ...).

But note that this is really just a special case of of Sys.sleep(). If you actually run R code, then ProcessEvents is triggered automatically during the evaluation (or in interruptible C code).

Cheers,
Simon


> I am using
> Ubuntu 13.04 (x64), and osx 10.8. Below three videos to illustrate the
> issue:
> 
>  [1]: http://www.youtube.com/watch?v=d1qxbp2W2mY&hd=1
>  [2]: http://www.youtube.com/watch?v=S0r-O9er4kU&hd=1
>  [3]: http://www.youtube.com/watch?v=2D7TgtXUa3o&hd=1
> 
>> sessionInfo()
> R version 3.0.1 RC (2013-05-10 r62729)
> Platform: x86_64-pc-linux-gnu (64-bit)
> 
> locale:
> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
> [7] LC_PAPER=C                 LC_NAME=C
> [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From jeroen.ooms at stat.ucla.edu  Thu May 16 21:34:13 2013
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Thu, 16 May 2013 12:34:13 -0700
Subject: [Rd] setTimeLimit sometimes fails to terminate idle call in R
In-Reply-To: <9187D1C3-2FDD-4432-9FCE-FB4CEDC53A92@r-project.org>
References: <CABFfbXsBsTt4aHvTePo+0iCnkQ3df+RwcpwogXH40RmtB=BYiA@mail.gmail.com>
	<9187D1C3-2FDD-4432-9FCE-FB4CEDC53A92@r-project.org>
Message-ID: <CABFfbXsru+qC5XRnz2aLnPkUz9XwoQtkGgDWudH3jcPDXDvTPg@mail.gmail.com>

Thank you for the elaborate response. I am going to look into the quartz code.

> On top of my head I can't think of a built-in solution in R at this point (even though it could be argued that R might install a handler itself when the limit is set ...).

Yes, I think this would greatly enhance the usability of setTimeLimit.

> But note that this is really just a special case of of Sys.sleep(). If you actually run R code, then ProcessEvents is triggered automatically during the evaluation (or in interruptible C code).

Well, the main use case that I have in mind is where the process is
stuck waiting for some child process or socket. For example, I would
like to implement a timeout parameter for psockcluster nodes,
equivalent to mccollect timeout. Below a poc that I hacked together,
which works on windows, but not linux/osx for above reasons.

eval_psock <- function(expr, envir=parent.frame(), timeout=60){
  #create a child process
  cluster <- parallel::makePSOCKcluster(1);
  child <- cluster[[1]];
  parallel:::sendCall(child, eval, list(quote(Sys.getpid())));
  pid <- parallel:::recvResult(child);

  #set the timeout
  setTimeLimit(elapsed=timeout, transient=TRUE);
  on.exit({
    setTimeLimit(cpu=Inf, elapsed=Inf, transient=FALSE);
    tools::pskill(pid); #win
    tools::pskill(pid, tools::SIGKILL); #nix
    parallel:::stopNode(child);
  });

  #send the actual call
  parallel:::sendCall(child, eval, list(expr=substitute(expr),
    envir=as.list(envir)));
  myresult <- parallel:::recvResult(child);

  #reset timelimit
  setTimeLimit(cpu=Inf, elapsed=Inf, transient=TRUE);

  #forks don't throw errors themselves
  if(is(myresult,"try-error")){
    #snow only returns the message, not an error object
    stop(myresult, call.=FALSE);
  }

  #send the buffered response
  return(myresult);
}

test <- function(){
  n <- 1e8;
  k <- 1e4;
  #this should take more than 10 sec
  eval_psock(svd(matrix(rnorm(n), k)), timeout=10);
}

system.time(test());


From peter.meilstrup at gmail.com  Fri May 17 05:17:56 2013
From: peter.meilstrup at gmail.com (Peter Meilstrup)
Date: Thu, 16 May 2013 20:17:56 -0700
Subject: [Rd] Substitute / delayedAssign (was: Substitute unaware when
 promise objects are evaluated)
In-Reply-To: <17B09E7789D3104E8F5EEB0582A8D66FF25D00C072@MSGRTPCCRF2WIN.DMN1.FMR.COM>
References: <17B09E7789D3104E8F5EEB0582A8D66FF25D00C072@MSGRTPCCRF2WIN.DMN1.FMR.COM>
Message-ID: <CAJoaRhb4cWxx6PhCO1vzajHaa9q2pNA40Y+OvxnCW3XMKt2FPg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130516/8b855f0d/attachment.pl>

From murdoch.duncan at gmail.com  Fri May 17 11:47:29 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 17 May 2013 05:47:29 -0400
Subject: [Rd] Substitute / delayedAssign (was: Substitute unaware when
 promise objects are evaluated)
In-Reply-To: <CAJoaRhb4cWxx6PhCO1vzajHaa9q2pNA40Y+OvxnCW3XMKt2FPg@mail.gmail.com>
References: <17B09E7789D3104E8F5EEB0582A8D66FF25D00C072@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<CAJoaRhb4cWxx6PhCO1vzajHaa9q2pNA40Y+OvxnCW3XMKt2FPg@mail.gmail.com>
Message-ID: <5195FCB1.30109@gmail.com>

On 13-05-16 11:17 PM, Peter Meilstrup wrote:
> On Thu, May 16, 2013 at 6:06 AM, McGehee, Robert <
> Robert.McGehee at geodecapital.com> wrote:
>
>> Duncan, Thank you for the clarification on how delayedAssign works. Should
>> R-level interfaces to promise objects ever become available, I expect they
>> would at time come in handy.
>>
>> On the subject of substitute and delayedAssign, I do have a follow-up
>> question for the list. I'm trying to convert a named list of expression
>> objects into an environment of promise objects. After conversion, each
>> expression in the list will be automatically evaluated when the variable
>> with the same name is accessed in the environment. Effectively, I'm trying
>> to create a hash table of promise objects.
>>
>
> Populating a new environment with promises happens to be what "calling a
> function" in R does anyway, so an elegant way to accomplish this goal is:
>
> makePromiseEnv <- function(expressions, parent=parent.frame()) {
>      f <- function() environment()
>      formals(f) <- as.pairlist(expressions)
>      environment(f) <- parent
>      f()
> }
>
>> e <- makePromiseEnv(alist(a = {print("hello"); 4}, b = {print("again");
> 6}))
>> e$a
> [1] "hello"
> [1] 4
>> e$a
> [1] 4
>> e$b
> [1] "again"
> [1] 6
>> e$b
> [1] 6
>

I like that solution, except for one thing:  I don't see an easy way to 
control the environment where those expressions will be executed.  Since 
you've set them as defaults on the arguments, they will be evaluated in 
the evaluation frame of f(), and that might not be what we want. An 
obvious example of the problem would be

e <- makePromiseEnv(alist(a = ls()))

I don't know what Robert would want

e$a

to print, but one somewhat natural version would be to have it evaluate 
the ls() in the environment from which makePromiseEnv was called, i.e. 
the global environment in this case.  Neither your solution nor mine do 
this, but I can see how to modify mine, since it makes the evaluation 
environment of the expression explicit.  Can you see a modification that 
would do that with your approach?

Duncan Murdoch


From peter.meilstrup at gmail.com  Fri May 17 12:08:24 2013
From: peter.meilstrup at gmail.com (Peter Meilstrup)
Date: Fri, 17 May 2013 03:08:24 -0700
Subject: [Rd] Substitute / delayedAssign (was: Substitute unaware when
 promise objects are evaluated)
In-Reply-To: <5195FCB1.30109@gmail.com>
References: <17B09E7789D3104E8F5EEB0582A8D66FF25D00C072@MSGRTPCCRF2WIN.DMN1.FMR.COM>
	<CAJoaRhb4cWxx6PhCO1vzajHaa9q2pNA40Y+OvxnCW3XMKt2FPg@mail.gmail.com>
	<5195FCB1.30109@gmail.com>
Message-ID: <CAJoaRha1ZkVu1JXFcKaMPnkv-kQzhJ1srYYN=6NucKHcaucO_A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130517/2bacbc82/attachment.pl>

From pdalgd at gmail.com  Fri May 17 12:24:20 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 17 May 2013 12:24:20 +0200
Subject: [Rd] Substitute / delayedAssign (was: Substitute unaware when
	promise objects are evaluated)
In-Reply-To: <17B09E7789D3104E8F5EEB0582A8D66FF25D00C072@MSGRTPCCRF2WIN.DMN1.FMR.COM>
References: <17B09E7789D3104E8F5EEB0582A8D66FF25D00C072@MSGRTPCCRF2WIN.DMN1.FMR.COM>
Message-ID: <64BAB786-0F3E-45BB-A940-AB9741F13B2E@gmail.com>


On May 16, 2013, at 15:06 , McGehee, Robert wrote:

> Duncan, Thank you for the clarification on how delayedAssign works. Should R-level interfaces to promise objects ever become available, I expect they would at time come in handy.
> 
> On the subject of substitute and delayedAssign, I do have a follow-up question for the list. I'm trying to convert a named list of expression objects into an environment of promise objects. After conversion, each expression in the list will be automatically evaluated when the variable with the same name is accessed in the environment. Effectively, I'm trying to create a hash table of promise objects.
> 
> Here's the code I wrote that works just fine.
> 
> x <- list(a=3, b=expression(a+2), sleep=expression(Sys.sleep(2)))
> env <- new.env()
> for (i in seq(x)) {
> 	key <- names(x)[i]
> 	.Internal(delayedAssign(key,
> 				   eval(substitute(x[[i]], list(x=x, i=i)))[[1]],
> 				   eval.env=env, assign.env=env))
> }	
> env$b     # 3+2
> [1] 5
> env$sleep # Sleeps for 2 seconds
> NULL  
> 
> The "problem" is that R CMD check complains that I shouldn't be using .Internal() to access the delayedAssign function. However, if I don't use .Internal(), then delayedAssign puts another substitute around my call that prevents the 'i' iterator variable from being evaluated at the correct time, which causes all variables to get the value x[[i]] for the very last value of 'i'.
> 
> Can I safely ignore this R CMD check warning about .Internal, or is there a better way to write this code?

These things are slippery, but the usual way out is to figure out exactly which expression you want to call, compute the expression unevaluated, and evaulate it.

Something like

e <- bquote(delayedAssign( .(names(x)[i]), .(x[[i]]), eval.env=env, assign.env=env))
print(e)
eval(e)

(of course remove the print(e) once you're sure that it is doing the right thing)



> 
> Thanks, Robert
> 
> 
> 
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
> Sent: Wednesday, May 15, 2013 6:04 PM
> To: McGehee, Robert
> Cc: R-Devel (r-devel at r-project.org)
> Subject: Re: [Rd] Substitute unaware when promise objects are evaluated
> 
> On 13-05-15 11:54 AM, McGehee, Robert wrote:
>> R-devel,
>> I used the 'substitute' function to create labels for objects inside an environment, without actually evaluating the objects, as the objects might be promises.
>> 
>> However, I was surprised to see that 'substitute' returns the expression slot of the original promise even after the promise has been forcibly evaluated. (Doesn't the promise go away after evaluation?) This behavior probably falls under the "...no guarantee that the resulting expression makes any sense" clause of the ?substitute documentation, but in case there's something actually wrong here, I thought I'd send an example.
> 
> I think you misunderstand promises.
> 
> A promise has two (or three, depending how you count) parts:  an 
> expression with an associated environment, and a value.  The value isn't 
> filled in until the expression is evaluated, but the expression doesn't 
> go away then.  You can still see it until you change the variable that 
> holds the promise.
> 
> 
>> Here's an example showing how the evaluated expression returned by substitute does not match the actual variable value:
>> 
>>> env <- new.env()
>>> z <- 0
>>> delayedAssign("var", z+2, assign.env=env)
>>> substitute(var, env=env)
>> z + 2
> 
> The documentation for substitute may not be clear on this, but for a 
> promise, the env argument will be ignored.  It was the eval.env argument 
> to delayedAssign that set the promise's environment.
> 
>>> force(env$var)
>> [1] 2
>>> z <- 10
>>> substitute(var, env=env)
>> z + 2
>>> eval(substitute(var, env=env))
>> [1] 12
>>> force(env$var)
>> [1] 2
>> 
>> Is there any obvious way to code around this behavior, e.g. can I explicitly check if an object in an environment is an unevaluated promise?
> 
> Not at R level. In C code you could, but you probably shouldn't.  Think 
> of promises as values where you can look up the expression that gave the 
> value, and sometimes delay the calculation until you need it.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pauljohn32 at gmail.com  Fri May 17 19:48:00 2013
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Fri, 17 May 2013 12:48:00 -0500
Subject: [Rd] problem in add1's F statistic when data contains NAs?
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C2EB031@PA-MBX01.na.tibco.com>
References: <E66794E69CFDE04D9A70842786030B931C2EB031@PA-MBX01.na.tibco.com>
Message-ID: <CAErODj87OkMij5iAioLgxL8DoDTowPY5tUNrvgTVgn+_2XFHUQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130517/a0019d3c/attachment.pl>

From tal.galili at gmail.com  Fri May 17 20:01:49 2013
From: tal.galili at gmail.com (Tal Galili)
Date: Fri, 17 May 2013 21:01:49 +0300
Subject: [Rd] R 3.0.1: wrong MD5 checksums for Windows?
Message-ID: <CANdJ3dW=mXYs1qv9LrMsCU6_oe+mU4Qa-9XP1gEMxJdq3sWH2w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130517/ec521563/attachment.pl>

From Berwin.Turlach at gmail.com  Sat May 18 08:54:34 2013
From: Berwin.Turlach at gmail.com (Berwin A Turlach)
Date: Sat, 18 May 2013 14:54:34 +0800
Subject: [Rd] R CMD config for R >= 3.0.1
Message-ID: <20130518145434.4194be90@bossiaea>

Dear all,

When installing the usual packages that I use, after installing R
3.0.1, I noticed that the installation of some packages that query R about
its configuration did not succeed.  The problem is exemplified by:

berwin at bossiaea:~$ R-3.0.1 CMD config CC
/opt/R/R-3.0.1/lib/R/bin/config: 222: .: Can't open /opt/R/R-3.0.1/lib/R/etc/Renviron

Prior to R 3.0.1 such commands worked fine:

berwin at bossiaea:~$ R-3.0.0 CMD config CC
gcc -std=gnu99


I noticed now that my installations of the development and
patched version of R have the same problem (since I usually do not install
packages in those versions that query the configuration, I hadn't
noticed the issue earlier).  

The problem seems to be line 222 of `R RHOME`/bin/config (when R is R
3.0.1) which reads:

	. ${R_HOME}/etc/Renviron
 
The file ${R_HOME}/etc/Renviron does not necessarily exists if one has
opted for 32/64-bit builds and installed both as sub-architectures,
which I have.  In my installation ${R_HOME}/etc/32/Renviron and
${R_HOME}/etc/64/Renviron exist, but no ${R_HOME}/etc/Renviron.

Is it necessary for R >= 3.0.1 to have one build as
"main"-architecture and the other one as sub-architecture?  I could not
find anything in the NEWS file or the Admin manual that indicated that
this would now be necessary.

Cheers,

	Berwin

For completeness:  

I am running an Ubuntu 12.04 system and:

berwin at bossiaea:~$ echo "sessionInfo()" | R-3.0.1 --slave
R version 3.0.1 (2013-05-16)
Platform: x86_64-unknown-linux-gnu/64 (64-bit)

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods    base


From pdalgd at gmail.com  Sat May 18 11:11:40 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 18 May 2013 11:11:40 +0200
Subject: [Rd] R 3.0.1: wrong MD5 checksums for Windows?
In-Reply-To: <CANdJ3dW=mXYs1qv9LrMsCU6_oe+mU4Qa-9XP1gEMxJdq3sWH2w@mail.gmail.com>
References: <CANdJ3dW=mXYs1qv9LrMsCU6_oe+mU4Qa-9XP1gEMxJdq3sWH2w@mail.gmail.com>
Message-ID: <DEC0B30D-B38E-4F16-B690-0D8C844F6C1D@gmail.com>


On May 17, 2013, at 20:01 , Tal Galili wrote:

> Hello dear R-devel,
> 
> I am not sure if this issue is tracked or not, but in case it isn't:
> It appears that R 3.0.1 reproduces the error reported for R 3.0.0 here:
> http://r.789695.n4.nabble.com/R-3-0-0-wrong-MD5-checksums-for-Windows-td4663348.html
> 
> That is, that when installing R 3.0.1 on Windows 7, and then running:
> 
> require(tools)
> checkMD5sums(dir=R.home())
> 
> It produces the error:
> files ?etc/Rconsole?, ?etc/Rprofile.site? have the wrong MD5 checksums
> [1] FALSE

As has been pointed out before, it is pretty much a non-issue. The Windows installer ships with md5 sums for some local configuration files and if they are locally configured or touched by the installer, the checksums will not match. checkMD5sums is for package checking, it is not documented to be used for checking R.home(). 

Perhaps the Windows maintainer could strip those files from the checksums, but I wouldn't put it on high priority. 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From tal.galili at gmail.com  Sat May 18 11:25:54 2013
From: tal.galili at gmail.com (Tal Galili)
Date: Sat, 18 May 2013 12:25:54 +0300
Subject: [Rd] R 3.0.1: wrong MD5 checksums for Windows?
In-Reply-To: <DEC0B30D-B38E-4F16-B690-0D8C844F6C1D@gmail.com>
References: <CANdJ3dW=mXYs1qv9LrMsCU6_oe+mU4Qa-9XP1gEMxJdq3sWH2w@mail.gmail.com>
	<DEC0B30D-B38E-4F16-B690-0D8C844F6C1D@gmail.com>
Message-ID: <CANdJ3dUygS4Zy4BqGnugrtsWepm6+W_Qn+ROE6Jh-nOjHOD=5Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130518/1cd95091/attachment.pl>

From ripley at stats.ox.ac.uk  Sat May 18 11:28:43 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 18 May 2013 10:28:43 +0100
Subject: [Rd] R CMD config for R >= 3.0.1
In-Reply-To: <20130518145434.4194be90@bossiaea>
References: <20130518145434.4194be90@bossiaea>
Message-ID: <519749CB.20408@stats.ox.ac.uk>

On 18/05/2013 07:54, Berwin A Turlach wrote:
> Dear all,
>
> When installing the usual packages that I use, after installing R
> 3.0.1, I noticed that the installation of some packages that query R about
> its configuration did not succeed.  The problem is exemplified by:
>
> berwin at bossiaea:~$ R-3.0.1 CMD config CC
> /opt/R/R-3.0.1/lib/R/bin/config: 222: .: Can't open /opt/R/R-3.0.1/lib/R/etc/Renviron
>
> Prior to R 3.0.1 such commands worked fine:
>
> berwin at bossiaea:~$ R-3.0.0 CMD config CC
> gcc -std=gnu99
>
>
> I noticed now that my installations of the development and
> patched version of R have the same problem (since I usually do not install
> packages in those versions that query the configuration, I hadn't
> noticed the issue earlier).
>
> The problem seems to be line 222 of `R RHOME`/bin/config (when R is R
> 3.0.1) which reads:
>
> 	. ${R_HOME}/etc/Renviron
>
> The file ${R_HOME}/etc/Renviron does not necessarily exists if one has
> opted for 32/64-bit builds and installed both as sub-architectures,
> which I have.  In my installation ${R_HOME}/etc/32/Renviron and
> ${R_HOME}/etc/64/Renviron exist, but no ${R_HOME}/etc/Renviron.
>
> Is it necessary for R >= 3.0.1 to have one build as
> "main"-architecture and the other one as sub-architecture?  I could not
> find anything in the NEWS file or the Admin manual that indicated that
> this would now be necessary.

Not exclusively, but as the Mac build no longer uses this, we do need 
people who do to test pre-releases.   One of us needs to build such a 
setup and test it ....


>
> Cheers,
>
> 	Berwin
>
> For completeness:
>
> I am running an Ubuntu 12.04 system and:
>
> berwin at bossiaea:~$ echo "sessionInfo()" | R-3.0.1 --slave
> R version 3.0.1 (2013-05-16)
> Platform: x86_64-unknown-linux-gnu/64 (64-bit)
>
> locale:
> [1] C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods    base
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch.duncan at gmail.com  Sat May 18 23:37:54 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 18 May 2013 17:37:54 -0400
Subject: [Rd] R 3.0.1: wrong MD5 checksums for Windows?
In-Reply-To: <CANdJ3dW=mXYs1qv9LrMsCU6_oe+mU4Qa-9XP1gEMxJdq3sWH2w@mail.gmail.com>
References: <CANdJ3dW=mXYs1qv9LrMsCU6_oe+mU4Qa-9XP1gEMxJdq3sWH2w@mail.gmail.com>
Message-ID: <5197F4B2.1050508@gmail.com>

On 13-05-17 2:01 PM, Tal Galili wrote:
> Hello dear R-devel,
>
> I am not sure if this issue is tracked or not, but in case it isn't:
> It appears that R 3.0.1 reproduces the error reported for R 3.0.0 here:
> http://r.789695.n4.nabble.com/R-3-0-0-wrong-MD5-checksums-for-Windows-td4663348.html
>
> That is, that when installing R 3.0.1 on Windows 7, and then running:
>
> require(tools)
> checkMD5sums(dir=R.home())
>
> It produces the error:
> files ???etc/Rconsole???, ???etc/Rprofile.site??? have the wrong MD5 checksums
> [1] FALSE
>

Technically speaking, that's just a message, not an error.  Those files 
were changed by the installer, so the information is correct.

 From a user point of view, it does look like an error.  We could avoid 
the message in several ways:  don't bother checking those files, or 
compute the MD5 checksums on default installed versions of those files, 
or recompute the checksums after installation.

I think the third choice is too hard, so it's not something I'd do.

I don't know which of the other two is better.  A malicious attacker 
could do a lot of damage by messing with the Rprofile.site file; maybe a 
user would want to know if that had happened.  So that suggests the 
second choice.  But then users who don't choose whatever default the 
installer picks will always get the message.

Duncan Murdoch


From Berwin.Turlach at gmail.com  Sun May 19 09:25:58 2013
From: Berwin.Turlach at gmail.com (Berwin A Turlach)
Date: Sun, 19 May 2013 15:25:58 +0800
Subject: [Rd] R CMD config for R >= 3.0.1
In-Reply-To: <519749CB.20408@stats.ox.ac.uk>
References: <20130518145434.4194be90@bossiaea> <519749CB.20408@stats.ox.ac.uk>
Message-ID: <20130519152558.25bee882@bossiaea>

G'day Brian,

On Sat, 18 May 2013 10:28:43 +0100
Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

[...]
> > Is it necessary for R >= 3.0.1 to have one build as
> > "main"-architecture and the other one as sub-architecture?  I could
> > not find anything in the NEWS file or the Admin manual that
> > indicated that this would now be necessary.
> 
> Not exclusively, but as the Mac build no longer uses this, we do need 
> people who do to test pre-releases.   One of us needs to build such a 
> setup and test it ....

Either that, or amend the administration and installation manual to
state that one installation should not be a sub-architecture
installation.  :)

But the latter solution also seems to have some problems.  My usual
install script did the following:

1) Run ./configure with 'r_arch=32' (and a few other options) using a
   config.site, configured for a 32bit build; followed by make  
2) make check ; make install 
3) `make distclean'; run ./configure with 'r_arch=64' (and a few other
   options using a config.site configured for a 64 bit build; followed
   by make
4) make check ; make install
5) make pdf info; make install-pdf install-info

When trying to install Rgraphviz afterwards (mmh, this is a
BioConductor package and not a CRAN package, so perhaps I should ask on
their lists?), Rgrahviz couldn't find the correct compiler settings as
"R CMD config ..." did not work (as reported originally).

So I changed my install script to remove the 'r_arch=64' in step 3.
(The modified script is attached.)  But now, trying to install
Rgraphviz falls over earlier when a dependencies of Rgraphviz,
BiocGenerics, is installed.  Trying to install BiocGenerics fails with:

[...]
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded
*** arch - 32
*** arch - R
ERROR: sub-architecture 'R' is not installed
ERROR: loading failed for 'R'
* removing '/opt/R/R-3.0.1/lib/R/library/BiocGenerics'

I have no idea why the process tries to check for an 'arch - R'.  But
this seems to be happening for packages that do not contain code that
needs to be compiled, another example is 'car' which is needed by 'AER'.

So I am bit puzzled how I should change my scripts.  Does step 3 needs
something stronger than 'make distclean'?  Or should the 'r_arch=32' be
dropped in step 1 but step 3 should use 'r_arch=64'?

Essentially, I would like to install 32bit and 64bit builds on my
machines, with one or both as sub-architectures (to save space) and
with the 64bit the 'default', i.e. the one that is run by
${R_HOME}/bin/R.

Cheers,
	
	Berwin
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: R-Install0
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130519/ae51a8d2/attachment.pl>

From ripley at stats.ox.ac.uk  Sun May 19 09:40:04 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 19 May 2013 08:40:04 +0100
Subject: [Rd] R CMD config for R >= 3.0.1
In-Reply-To: <20130519152558.25bee882@bossiaea>
References: <20130518145434.4194be90@bossiaea> <519749CB.20408@stats.ox.ac.uk>
	<20130519152558.25bee882@bossiaea>
Message-ID: <519881D4.3020400@stats.ox.ac.uk>

Could you try current R-patched or R-devel?  Works in my tests at least.

On 19/05/2013 08:25, Berwin A Turlach wrote:
> G'day Brian,
>
> On Sat, 18 May 2013 10:28:43 +0100
> Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>
> [...]
>>> Is it necessary for R >= 3.0.1 to have one build as
>>> "main"-architecture and the other one as sub-architecture?  I could
>>> not find anything in the NEWS file or the Admin manual that
>>> indicated that this would now be necessary.
>>
>> Not exclusively, but as the Mac build no longer uses this, we do need
>> people who do to test pre-releases.   One of us needs to build such a
>> setup and test it ....
>
> Either that, or amend the administration and installation manual to
> state that one installation should not be a sub-architecture
> installation.  :)

That is not sufficient.  AFAICS the issue only occurs after installation 
(which is probably why no one else saw it), and the Renviron files for 
the different sub-architectures will be different (in R_PLATFORM).

> But the latter solution also seems to have some problems.  My usual
> install script did the following:
>
> 1) Run ./configure with 'r_arch=32' (and a few other options) using a
>     config.site, configured for a 32bit build; followed by make
> 2) make check ; make install
> 3) `make distclean'; run ./configure with 'r_arch=64' (and a few other
>     options using a config.site configured for a 64 bit build; followed
>     by make
> 4) make check ; make install
> 5) make pdf info; make install-pdf install-info
>
> When trying to install Rgraphviz afterwards (mmh, this is a
> BioConductor package and not a CRAN package, so perhaps I should ask on
> their lists?), Rgrahviz couldn't find the correct compiler settings as
> "R CMD config ..." did not work (as reported originally).
>
> So I changed my install script to remove the 'r_arch=64' in step 3.
> (The modified script is attached.)  But now, trying to install
> Rgraphviz falls over earlier when a dependencies of Rgraphviz,
> BiocGenerics, is installed.  Trying to install BiocGenerics fails with:
>
> [...]
> ** help
> *** installing help indices
> ** building package indices
> ** testing if installed package can be loaded
> *** arch - 32
> *** arch - R
> ERROR: sub-architecture 'R' is not installed
> ERROR: loading failed for 'R'
> * removing '/opt/R/R-3.0.1/lib/R/library/BiocGenerics'
>
> I have no idea why the process tries to check for an 'arch - R'.  But
> this seems to be happening for packages that do not contain code that
> needs to be compiled, another example is 'car' which is needed by 'AER'.
>
> So I am bit puzzled how I should change my scripts.  Does step 3 needs
> something stronger than 'make distclean'?  Or should the 'r_arch=32' be
> dropped in step 1 but step 3 should use 'r_arch=64'?
>
> Essentially, I would like to install 32bit and 64bit builds on my
> machines, with one or both as sub-architectures (to save space) and
> with the 64bit the 'default', i.e. the one that is run by
> ${R_HOME}/bin/R.
>
> Cheers,
> 	
> 	Berwin
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Berwin.Turlach at gmail.com  Sun May 19 10:38:01 2013
From: Berwin.Turlach at gmail.com (Berwin A Turlach)
Date: Sun, 19 May 2013 16:38:01 +0800
Subject: [Rd] R CMD config for R >= 3.0.1
In-Reply-To: <519881D4.3020400@stats.ox.ac.uk>
References: <20130518145434.4194be90@bossiaea> <519749CB.20408@stats.ox.ac.uk>
	<20130519152558.25bee882@bossiaea>
	<519881D4.3020400@stats.ox.ac.uk>
Message-ID: <20130519163801.74ee5db7@bossiaea>

G'day Brian,

On Sun, 19 May 2013 08:40:04 +0100
Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

> Could you try current R-patched or R-devel?  Works in my tests at
> least.

Tried R-patched (2013-05-18 r62762) and R-devel (2013-05-18 r62762),
installed with my original script.  Things seem fine when I try to
install my usual selection of packages in either of those versions.
Loading under correct (and existing) architectures is tested and
packages that query the configuration get the correct answers from `R
CMD config'.

Thank you very much for the help.

Cheers,

	Berwin


From murdoch.duncan at gmail.com  Sun May 19 14:00:10 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 19 May 2013 08:00:10 -0400
Subject: [Rd] R 3.0.1: wrong MD5 checksums for Windows?
In-Reply-To: <5197F4B2.1050508@gmail.com>
References: <CANdJ3dW=mXYs1qv9LrMsCU6_oe+mU4Qa-9XP1gEMxJdq3sWH2w@mail.gmail.com>
	<5197F4B2.1050508@gmail.com>
Message-ID: <5198BECA.1090009@gmail.com>

On 13-05-18 5:37 PM, Duncan Murdoch wrote:
> On 13-05-17 2:01 PM, Tal Galili wrote:
>> Hello dear R-devel,
>>
>> I am not sure if this issue is tracked or not, but in case it isn't:
>> It appears that R 3.0.1 reproduces the error reported for R 3.0.0 here:
>> http://r.789695.n4.nabble.com/R-3-0-0-wrong-MD5-checksums-for-Windows-td4663348.html
>>
>> That is, that when installing R 3.0.1 on Windows 7, and then running:
>>
>> require(tools)
>> checkMD5sums(dir=R.home())
>>
>> It produces the error:
>> files ???etc/Rconsole???, ???etc/Rprofile.site??? have the wrong MD5 checksums
>> [1] FALSE
>>
>
> Technically speaking, that's just a message, not an error.  Those files
> were changed by the installer, so the information is correct.
>
>   From a user point of view, it does look like an error.  We could avoid
> the message in several ways:  don't bother checking those files, or
> compute the MD5 checksums on default installed versions of those files,
> or recompute the checksums after installation.
>
> I think the third choice is too hard, so it's not something I'd do.
>
> I don't know which of the other two is better.  A malicious attacker
> could do a lot of damage by messing with the Rprofile.site file; maybe a
> user would want to know if that had happened.  So that suggests the
> second choice.  But then users who don't choose whatever default the
> installer picks will always get the message.
>

I think the problem of a malicious attacker is pretty far-fetched, but 
an accidental change might be worth noting, so I've put the second 
choice in place in R-devel and R-patched.

Duncan Murdoch


From giles.percy at gmail.com  Sat May 18 23:50:52 2013
From: giles.percy at gmail.com (Giles Percy)
Date: Sat, 18 May 2013 22:50:52 +0100
Subject: [Rd] Copy on assignment to large field of reference class
Message-ID: <CAKFhz+4Jz0CTZCB-sRXbM1R11cdsWnREPxMkYchKi5wxu3-Wcg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130518/5d56a812/attachment.pl>

From bbolker at gmail.com  Sun May 19 20:16:30 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 19 May 2013 14:16:30 -0400
Subject: [Rd] locking down R
Message-ID: <519916FE.6060309@ufl.edu>


  Is anyone on this list aware of discussions about locking down/securing R?

  My colleagues and I are working with health statistics in an office
that disallows many useful tools (e.g. emacs, vim, perl, make) on the
grounds that they represent a security risk.  We are considering pushing
back, but we are worried that if we attract the attention of the Powers
That Be to the reality that R allows execution of arbitrary shell
commands, they will then disallow the use of R (SAS and Stata are our
other optiona). It might be useful to be able to give them options for
securing R.

  Possibly useful information:

* the office allows use of SAS (and Stata, MLWiN, etc.) but uses the
NOXCMD specification to prevent shell access from within SAS. They also
disallow access to the Windows shell (in the current configuration,
shell() works fine from within R, but we think this may have escaped
their notice ...) The workstations have no access to external networks,
nor to external media (thumb drives etc.) [information transfer to the
outside world is via shared drives that can be accessed by
administrators with network access].

* I stipulate that (1) the security policies don't make sense, (2)
allowing users access to arbitrary shell commands should _not_ represent
a security risk on a well-administered, modern operating system (they're
running WinXP), (3) R probably offers many other avenues for system
access to a malicious user, even in the absence of shell access,
compilers, etc..

* I suspect the answer given here will be "if you really want to secure
R, run it within a standard restricted-access shell (e.g. chroot on a
Linux system)".  If anyone has experience of 'locking down' R on Windows
(XP) in a sensitive environment, I'd be curious about the details.

 thanks
  Ben Bolker


From jmc at r-project.org  Sun May 19 23:59:33 2013
From: jmc at r-project.org (John Chambers)
Date: Sun, 19 May 2013 14:59:33 -0700
Subject: [Rd] Copy on assignment to large field of reference class
In-Reply-To: <CAKFhz+4Jz0CTZCB-sRXbM1R11cdsWnREPxMkYchKi5wxu3-Wcg@mail.gmail.com>
References: <CAKFhz+4Jz0CTZCB-sRXbM1R11cdsWnREPxMkYchKi5wxu3-Wcg@mail.gmail.com>
Message-ID: <8810B4AB-0D07-412C-9A4A-24A26D54C242@r-project.org>

This is a useful observation.  To talk about it, though, we need to re-express it in terms that make sense for R; there are too many misconceptions otherwise.

The basic observation is this:  When simple subset or element replacement is done in a loop, normally the object is only copied on the first time through the loop.  This is true whether using local assignment, <-, or global assignment, <<-.

However, if global assignment is done in a method to replace in a field, the object is copied every time.  For long loops this makes for substantial overhead.  Very relevant observation.

What's going on?

The non-copying depends on the fact that `[<-` is a primitive function.

When a field is declared with a class ("vector" in the example), its assignment is done by an R function that checks the validity (via what's called an "active binding" in R).  That causes the extra copy on each assignment.  (To be honest, I don't totally understand why, but I have no intention of messing with the active binding code.)

What to do about it?

There are two solutions; either take the attitude that field assignment is basically inefficient and don't do it in a loop, as in method modb2.

Or don't declare a class for the field, in which case no active binding is used.  Check this out by changing the class definition to setRefClass("A", fields="b").

I prefer the first solution since it retains the validity check on the field.

John


PS: A few comments.
 - it makes no sense to expect _greater_ efficiency than for a simple assignment.  The object in a$b is NOT a reference object so its manipulation obeys R's normal rules.
 - all this only applies to replacement functions that are primitives.  Otherwise you're stuck with copies each time.
 - Please don't use the term "call by value" for R; that's not how R's evaluation works and has nothing to do with when duplication takes place.  That topic is not for the faint of heart, but basically when R knows that there is only one reference to an object, it doesn't copy.  But in practice this is mainly when a primitive replacement function is used.


On May 18, 2013, at 2:50 PM, Giles Percy <giles.percy at gmail.com> wrote:

> Dear all
> 
> I am trying to find the best way to handle large fields in reference
> classes.
> 
> As the code below shows assignment via <<- causes many copies to be made if
> the subsetting is extensive (in modb1). This can cause R to run out of
> memory. Creating a local copy and using the optimisation in <- is the best
> solution I have found so far (in modb2) - but it is not really much better
> than ordinary functions using call by value and then reassigning.
> 
> Is there a reason why optimisation does not occur for <<- ? Or is their a
> better solution for reference classes?
> 
> Regards
> Giles
> 
> A <- setRefClass("A", fields=list(b="vector"))
> 
> A$methods(
>  initialize=function() {
> b <<- 1:10000
> },
>  modb1=function() {
> # simple subsetting for illustration
> for(i in 2:length(b)) b[i] <<- b[i-1] + 1
> },
>  modb2=function() {
> bb <- b
> for(i in 2:length(b)) bb[i] <- bb[i-1] + 1
> b <<- bb
> }
> )
> a <- new("A")
> tracemem(a$b)
> 
> a$modb1()
> 
> a$modb2()
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From michael.weylandt at gmail.com  Mon May 20 00:08:31 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt)
Date: Sun, 19 May 2013 23:08:31 +0100
Subject: [Rd] locking down R
In-Reply-To: <519916FE.6060309@ufl.edu>
References: <519916FE.6060309@ufl.edu>
Message-ID: <CAAmySGPw7AS5Quy2WMPXfmzkyavmi+-kqvBZnDn+xWf4eYHKpA@mail.gmail.com>

On Sun, May 19, 2013 at 7:16 PM, Ben Bolker <bbolker at gmail.com> wrote:
>
>   Is anyone on this list aware of discussions about locking down/securing R?
>
>   My colleagues and I are working with health statistics in an office
> that disallows many useful tools (e.g. emacs, vim, perl, make) on the
> grounds that they represent a security risk.  We are considering pushing
> back, but we are worried that if we attract the attention of the Powers
> That Be to the reality that R allows execution of arbitrary shell
> commands, they will then disallow the use of R (SAS and Stata are our
> other optiona). It might be useful to be able to give them options for
> securing R.
>
>   Possibly useful information:
>
> * the office allows use of SAS (and Stata, MLWiN, etc.) but uses the
> NOXCMD specification to prevent shell access from within SAS. They also
> disallow access to the Windows shell (in the current configuration,
> shell() works fine from within R, but we think this may have escaped
> their notice ...) The workstations have no access to external networks,
> nor to external media (thumb drives etc.) [information transfer to the
> outside world is via shared drives that can be accessed by
> administrators with network access].
>
> * I stipulate that (1) the security policies don't make sense, (2)
> allowing users access to arbitrary shell commands should _not_ represent
> a security risk on a well-administered, modern operating system (they're
> running WinXP), (3) R probably offers many other avenues for system
> access to a malicious user, even in the absence of shell access,
> compilers, etc..

If you really mean a "modern operating system"... ;-)

http://arxiv.org/abs/1303.4808

Cheers,
MW

>
> * I suspect the answer given here will be "if you really want to secure
> R, run it within a standard restricted-access shell (e.g. chroot on a
> Linux system)".  If anyone has experience of 'locking down' R on Windows
> (XP) in a sensitive environment, I'd be curious about the details.
>
>  thanks
>   Ben Bolker
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From suharto_anggono at yahoo.com  Mon May 20 08:39:41 2013
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Sun, 19 May 2013 23:39:41 -0700 (PDT)
Subject: [Rd] is.vector(as.vector(data.frame(a=1))) and
	is.vector(as.vector(call("c"))) are FALSE
Message-ID: <1369031981.4990.YahooMailClassic@web125103.mail.ne1.yahoo.com>

These are deviations from the convention: ?is.vector(as.vector(x, m), m)? should be true for any mode ?m?, including the default ?"any"?.


* Case 1

These are documented.
- ?is.vector? returns ?TRUE? if ?x? is a vector of the specified mode having no attributes _other than names_.  It returns ?FALSE? otherwise.
- ?as.vector? removes _all_ attributes including names for results of atomic mode (but not those of mode ?"list"? nor ?"expression"?).

Because of the quirk of 'as.vector' for result of mode "list", is.vector(as.vector(data.frame(a=1))) returns FALSE.

> is.vector(as.vector(data.frame(a=1)))
[1] FALSE
> is.vector(as.vector(data.frame(a=1), "list"), "list")
[1] FALSE


* Case 2

as.vector(call("c")) (mode="any", the default) is not an error.
On the other hand, as documented, if ?mode = "any"?, ?is.vector? may return ?TRUE? for the atomic modes, ?list? and ?expression?.
As a result, is.vector(as.vector(call("c"))) returns FALSE.

> is.vector(as.vector(call("c")))
[1] FALSE


> sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


From b.rowlingson at lancaster.ac.uk  Mon May 20 10:42:50 2013
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 20 May 2013 09:42:50 +0100
Subject: [Rd] locking down R
In-Reply-To: <779843b0fc4a4b87805fcc3aa0e5c52f@EX-0-HT0.lancs.local>
References: <779843b0fc4a4b87805fcc3aa0e5c52f@EX-0-HT0.lancs.local>
Message-ID: <CANVKczOeRyTPERTybExfOweP2jp-OnLQLSFMfBbOBbz6j5G=Ug@mail.gmail.com>

On Sun, May 19, 2013 at 7:16 PM, Ben Bolker <bbolker at gmail.com> wrote:
>
>The workstations have no access to external networks,
> nor to external media (thumb drives etc.) [information transfer to the
> outside world is via shared drives that can be accessed by
> administrators with network access].
>
> * I stipulate that (1) the security policies don't make sense,

 Correct. If the machines aren't on an external network and have no
removable media then this isn't about security from the outside
hacker, its about trust. The organisation does not trust YOU.

(2)
> allowing users access to arbitrary shell commands should _not_ represent
> a security risk on a well-administered, modern operating system (they're
> running WinXP),

 When does WinXP go out of support? Even so, the PC isn't on the
network right? So what's the security issue? Doesn't make sense. You
can't stomp on other people's files. Would it matter if you could
accidentally see other people's files because they set permissions
loosely? How compartmentalised are the projects?

 (3) R probably offers many other avenues for system
> access to a malicious user, even in the absence of shell access,
> compilers, etc..

 The 'malicious user' here is on the inside. The only way to get on
the machine is to be physically there? Then a malicious user can only
be a trusted user gone bad. A sufficiently malicious user with
hardware access can (nearly) always break the thing open and get at
the data (even if it comes down to reading data lines with a tap to
get at unencrypted streams). Tell the security guys they need to lock
the PCs up in a room and provide thin client access over a secure
private network at once. Enjoy your new Windows Client Access License
costs.

 Glad I don't work for someone like that.

Barry


From matthieu.stigler at gmail.com  Mon May 20 12:05:41 2013
From: matthieu.stigler at gmail.com (Matthieu Stigler)
Date: Mon, 20 May 2013 12:05:41 +0200
Subject: [Rd] =?utf-8?q?R_CMD_check=3A_unknown_option_=E2=80=98--outdir=3D?=
	=?utf-8?b?PVJDSEVDS+KAmQ==?=
Message-ID: <CAEYvigJdjrJVO4DFo99Cca7MUHDqi+J2S+Yq4Ra-yUG0u-ddaA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130520/d62bb7cd/attachment.pl>

From murdoch.duncan at gmail.com  Mon May 20 12:34:12 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 20 May 2013 06:34:12 -0400
Subject: [Rd]
 =?windows-1252?q?R_CMD_check=3A_unknown_option_=91--outdir?=
 =?windows-1252?q?=3D=3DRCHECK=92?=
In-Reply-To: <CAEYvigJdjrJVO4DFo99Cca7MUHDqi+J2S+Yq4Ra-yUG0u-ddaA@mail.gmail.com>
References: <CAEYvigJdjrJVO4DFo99Cca7MUHDqi+J2S+Yq4Ra-yUG0u-ddaA@mail.gmail.com>
Message-ID: <5199FC24.4020000@gmail.com>

On 13-05-20 6:05 AM, Matthieu Stigler wrote:
> Dear R devel
>
> I am experiencing a problem using R CMD check. I tried to specify the
> argument outdir, but get every time the error message:
> Warning: unknown option ???--outdir==RCHECK???
>
> This happens both on R 2.15.2 Linux, as well as R 3.0.1 Windows, with
> latest Rtools. Is it just that I am not passing the argument the right way,
> or is there an issue with R CMD check?
>
> I tried to write the argument in many differents ways, but it always fails.
> Standard way I tried is:
> $ R CMD check --outdir="RCHECK"  pkg.tar.gz
> Warning: unknown option ???--outdir=RCHECK'

There are a couple of bugs here.  First, a simple typo: the code is 
looking for --output=RCHECK, not --outdir=RCHECK.  But if you use 
--output, you'll likely get an error saying you can't change directory 
to it.

I'll take a look at both.

Duncan Murdoch


From murdoch.duncan at gmail.com  Mon May 20 12:49:40 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 20 May 2013 06:49:40 -0400
Subject: [Rd]
 =?windows-1252?q?R_CMD_check=3A_unknown_option_=91--outdir?=
 =?windows-1252?q?=3D=3DRCHECK=92?=
In-Reply-To: <5199FC24.4020000@gmail.com>
References: <CAEYvigJdjrJVO4DFo99Cca7MUHDqi+J2S+Yq4Ra-yUG0u-ddaA@mail.gmail.com>
	<5199FC24.4020000@gmail.com>
Message-ID: <5199FFC4.6070003@gmail.com>

On 13-05-20 6:34 AM, Duncan Murdoch wrote:
> On 13-05-20 6:05 AM, Matthieu Stigler wrote:
>> Dear R devel
>>
>> I am experiencing a problem using R CMD check. I tried to specify the
>> argument outdir, but get every time the error message:
>> Warning: unknown option ???--outdir==RCHECK???
>>
>> This happens both on R 2.15.2 Linux, as well as R 3.0.1 Windows, with
>> latest Rtools. Is it just that I am not passing the argument the right way,
>> or is there an issue with R CMD check?
>>
>> I tried to write the argument in many differents ways, but it always fails.
>> Standard way I tried is:
>> $ R CMD check --outdir="RCHECK"  pkg.tar.gz
>> Warning: unknown option ???--outdir=RCHECK'
>
> There are a couple of bugs here.  First, a simple typo: the code is
> looking for --output=RCHECK, not --outdir=RCHECK.  But if you use
> --output, you'll likely get an error saying you can't change directory
> to it.
>
> I'll take a look at both.

Sorry, only one bug, misleading help text.

The help text says

   -o, --outdir=DIR      directory used for logfiles, R output, etc.
			(default is 'pkg.Rcheck' in current directory,
			where 'pkg' is the name of the package checked)

but in fact DIR is the location where pkg.Rcheck will be placed.  It 
needs to exist in advance.  (This allows multiple packages to be checked 
in one command.  I've never used multiple checks at once, but it looks 
like something CRAN might need to do.)

I'll fix this by changing the help text, not the behaviour.

Duncan Murdoch


From bbolker at gmail.com  Mon May 20 17:09:20 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 20 May 2013 11:09:20 -0400
Subject: [Rd] locking down R
In-Reply-To: <CANVKczOeRyTPERTybExfOweP2jp-OnLQLSFMfBbOBbz6j5G=Ug@mail.gmail.com>
References: <779843b0fc4a4b87805fcc3aa0e5c52f@EX-0-HT0.lancs.local>
	<CANVKczOeRyTPERTybExfOweP2jp-OnLQLSFMfBbOBbz6j5G=Ug@mail.gmail.com>
Message-ID: <519A3CA0.7050108@gmail.com>

On 13-05-20 04:42 AM, Barry Rowlingson wrote:
> On Sun, May 19, 2013 at 7:16 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>
>> The workstations have no access to external networks,
>> nor to external media (thumb drives etc.) [information transfer to the
>> outside world is via shared drives that can be accessed by
>> administrators with network access].
>>
>> * I stipulate that (1) the security policies don't make sense,
> 
>  Correct. If the machines aren't on an external network and have no
> removable media then this isn't about security from the outside
> hacker, its about trust. The organisation does not trust YOU.
> 
> (2)
>> allowing users access to arbitrary shell commands should _not_ represent
>> a security risk on a well-administered, modern operating system (they're
>> running WinXP),
> 
>  When does WinXP go out of support? Even so, the PC isn't on the
> network right? So what's the security issue? Doesn't make sense. You
> can't stomp on other people's files. Would it matter if you could
> accidentally see other people's files because they set permissions
> loosely? How compartmentalised are the projects?

   That is indeed one of the major concerns.  The administrators could
certainly lock the file access down more than they have (permissions are
restricted, but I have information about the existence of lots of
directories that I don't have permission to access: the system would
probably be more secure if I couldn't even see the top level of these
directories).

>  (3) R probably offers many other avenues for system
>> access to a malicious user, even in the absence of shell access,
>> compilers, etc..
> 
>  The 'malicious user' here is on the inside. The only way to get on
> the machine is to be physically there? Then a malicious user can only
> be a trusted user gone bad. A sufficiently malicious user with
> hardware access can (nearly) always break the thing open and get at
> the data (even if it comes down to reading data lines with a tap to
> get at unencrypted streams). Tell the security guys they need to lock
> the PCs up in a room and provide thin client access over a secure
> private network at once. Enjoy your new Windows Client Access License
> costs.
> 
>  Glad I don't work for someone like that.

  For what it's worth, (1) the people I deal with directly are very
nice, but not technically astute; the problem is more one of a large
bureaucracy covering its ass in some nonsensical ways; (2) this is only
a tiny component of my work.  If I get really frustrated with this I can
just drop it.

  I agree with your analysis of the real security situation, more or
less. (The PCs are pretty secure physically; it would be pretty hard to
break into the boxes without being noticed ...), but I think this
<http://xkcd.com/651/> is  a pretty good analogy for the kind of
argument I could get into here.


From bbolker at gmail.com  Mon May 20 17:12:06 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 20 May 2013 11:12:06 -0400
Subject: [Rd] locking down R
In-Reply-To: <CAAmySGPw7AS5Quy2WMPXfmzkyavmi+-kqvBZnDn+xWf4eYHKpA@mail.gmail.com>
References: <519916FE.6060309@ufl.edu>
	<CAAmySGPw7AS5Quy2WMPXfmzkyavmi+-kqvBZnDn+xWf4eYHKpA@mail.gmail.com>
Message-ID: <519A3D46.6000609@gmail.com>

On 13-05-19 06:08 PM, R. Michael Weylandt wrote:
> On Sun, May 19, 2013 at 7:16 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>
>>   Is anyone on this list aware of discussions about locking down/securing R?
>>
>>   My colleagues and I are working with health statistics in an office
>> that disallows many useful tools (e.g. emacs, vim, perl, make) on the
>> grounds that they represent a security risk.  We are considering pushing
>> back, but we are worried that if we attract the attention of the Powers
>> That Be to the reality that R allows execution of arbitrary shell
>> commands, they will then disallow the use of R (SAS and Stata are our
>> other optiona). It might be useful to be able to give them options for
>> securing R.
>>
>>   Possibly useful information:
>>
>> * the office allows use of SAS (and Stata, MLWiN, etc.) but uses the
>> NOXCMD specification to prevent shell access from within SAS. They also
>> disallow access to the Windows shell (in the current configuration,
>> shell() works fine from within R, but we think this may have escaped
>> their notice ...) The workstations have no access to external networks,
>> nor to external media (thumb drives etc.) [information transfer to the
>> outside world is via shared drives that can be accessed by
>> administrators with network access].
>>
>> * I stipulate that (1) the security policies don't make sense, (2)
>> allowing users access to arbitrary shell commands should _not_ represent
>> a security risk on a well-administered, modern operating system (they're
>> running WinXP), (3) R probably offers many other avenues for system
>> access to a malicious user, even in the absence of shell access,
>> compilers, etc..
> 
> If you really mean a "modern operating system"... ;-)
> 
> http://arxiv.org/abs/1303.4808
> 
> Cheers,
> MW

  Interesting, of course, but WinXP is the target OS (unless your point
is that people are worrying about this even on Linux).  (Another point
not mentioned previously is that users have to sign a fairly serious
confidentiality oath to get access to this system in the first place,
which presumably includes an implied "I won't hack the system" clause ...)

  RAppArmor is an interesting idea, as is sandboxR (mentioned in the
paper); I also looked up Sandboxie (a Windows program for sandboxing).
I don't think any of these will really solve the problem, though ...

 thanks
   Ben Bolker

> 
>>
>> * I suspect the answer given here will be "if you really want to secure
>> R, run it within a standard restricted-access shell (e.g. chroot on a
>> Linux system)".  If anyone has experience of 'locking down' R on Windows
>> (XP) in a sensitive environment, I'd be curious about the details.
>>
>>  thanks
>>   Ben Bolker
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From saptarshi.guha at gmail.com  Mon May 20 18:52:18 2013
From: saptarshi.guha at gmail.com (Saptarshi Guha)
Date: Mon, 20 May 2013 09:52:18 -0700
Subject: [Rd] Accessing element of a vector using a function (as opposed to
	macro)
Message-ID: <CAJDot1r0bdb+6cJQAp3DL3QtAkJOM-eYOPesMrSEFYO9Zi=h9A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130520/3994ad92/attachment.pl>

From saptarshi.guha at gmail.com  Mon May 20 18:56:27 2013
From: saptarshi.guha at gmail.com (Saptarshi Guha)
Date: Mon, 20 May 2013 09:56:27 -0700
Subject: [Rd] Accessing i'th element of a vector without using a macro
Message-ID: <CAJDot1oyZXenjk=zgj28Oj2BqBTdM+UmjN6TMi9TJNz0DDGS=Q@mail.gmail.com>

Hello,

I have a double vector, x. I can access the i'th element as

REAL(x)[i]

Is there a function for this? I know i can write my own, but was
seeing if one already exists. I did check Rinternals.h but didn't see
one.

Cheers
Saptarshi


From gmbecker at ucdavis.edu  Mon May 20 19:03:20 2013
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Mon, 20 May 2013 10:03:20 -0700
Subject: [Rd] Accessing i'th element of a vector without using a macro
In-Reply-To: <CAJDot1oyZXenjk=zgj28Oj2BqBTdM+UmjN6TMi9TJNz0DDGS=Q@mail.gmail.com>
References: <CAJDot1oyZXenjk=zgj28Oj2BqBTdM+UmjN6TMi9TJNz0DDGS=Q@mail.gmail.com>
Message-ID: <CADwqtCNDS3yCT39c0OLqkeu_9x9xSPjeRkp8psSmm99LsMjE9Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130520/f4f26893/attachment.pl>

From saptarshi.guha at gmail.com  Mon May 20 19:35:35 2013
From: saptarshi.guha at gmail.com (Saptarshi Guha)
Date: Mon, 20 May 2013 10:35:35 -0700
Subject: [Rd] Accessing i'th element of a vector without using a macro
In-Reply-To: <CADwqtCNDS3yCT39c0OLqkeu_9x9xSPjeRkp8psSmm99LsMjE9Q@mail.gmail.com>
References: <CAJDot1oyZXenjk=zgj28Oj2BqBTdM+UmjN6TMi9TJNz0DDGS=Q@mail.gmail.com>
	<CADwqtCNDS3yCT39c0OLqkeu_9x9xSPjeRkp8psSmm99LsMjE9Q@mail.gmail.com>
Message-ID: <CAJDot1qRHSRbHeQPjUJ6cfJn9xz86-ut7WdiXpw5Dj8uD07okw@mail.gmail.com>

Exactly, that is what i use. I intend to do the operation using an FFI
library(i't s just a proof of concept, and there well might be
performance hits)
If such a function doesn't exist in libR.so, then i can write one.

Regards
Saptarshi


On Mon, May 20, 2013 at 10:03 AM, Gabriel Becker <gmbecker at ucdavis.edu> wrote:
> Saptarshi,
>
> When I need to repeatedly access data from a an R vector in C I typically
> just create a pointer to the data and just use that.
>
> double *xdat = REAL(x);
> xdat[i]; //repeat as necessary
>
> This is also displayed in 5.9.4 of the R extensions manual.
>
> Is there a reason this wouldn't work for your usecase? What exactly is it
> that you want to do?
>
> ~G
>
>
>
>
> On Mon, May 20, 2013 at 9:56 AM, Saptarshi Guha <saptarshi.guha at gmail.com>
> wrote:
>>
>> Hello,
>>
>> I have a double vector, x. I can access the i'th element as
>>
>> REAL(x)[i]
>>
>> Is there a function for this? I know i can write my own, but was
>> seeing if one already exists. I did check Rinternals.h but didn't see
>> one.
>>
>> Cheers
>> Saptarshi
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
>
> --
> Gabriel Becker
> Graduate Student
> Statistics Department
> University of California, Davis


From tim.triche at gmail.com  Mon May 20 21:50:43 2013
From: tim.triche at gmail.com (Tim Triche, Jr.)
Date: Mon, 20 May 2013 12:50:43 -0700
Subject: [Rd] locking down R
In-Reply-To: <519A3D46.6000609@gmail.com>
References: <519916FE.6060309@ufl.edu>
	<CAAmySGPw7AS5Quy2WMPXfmzkyavmi+-kqvBZnDn+xWf4eYHKpA@mail.gmail.com>
	<519A3D46.6000609@gmail.com>
Message-ID: <CAC+N9BVOrEJVt38WZJ0wmbBmKRDrAWW=5rWAZGZoUOgVBScE2Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130520/6ffab19a/attachment.pl>

From spencer.graves at structuremonitoring.com  Tue May 21 01:12:41 2013
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Mon, 20 May 2013 16:12:41 -0700
Subject: [Rd] Objects created by more than one data call?
Message-ID: <519AADE9.2000505@structuremonitoring.com>

Hello, All:


       If I use LazyData with the Ecdat package on R-Forge, "R CMD 
check" reports "no visible binding for global variable 
'nonEnglishNames'", where 'nonEnglishNames' is a dataset in Ecdat used 
as the default argument for a function.  With LazyData, that NOTE 
disappears.  However, then I get, "Warning: objects 'Hstarts', 
'Hstarts', 'MedExp' are created by more than one data call".


       What do you suggest I do to fix this problem?


       Thanks,
       Spencer Graves


 > sessionInfo()
R version 3.0.0 (2013-04-03)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods base

other attached packages:
[1] Ecdat_0.2-3

loaded via a namespace (and not attached):
[1] tools_3.0.0


From ripley at stats.ox.ac.uk  Tue May 21 07:10:47 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 21 May 2013 06:10:47 +0100
Subject: [Rd] Objects created by more than one data call?
In-Reply-To: <519AADE9.2000505@structuremonitoring.com>
References: <519AADE9.2000505@structuremonitoring.com>
Message-ID: <519B01D7.4060804@stats.ox.ac.uk>

On 21/05/2013 00:12, Spencer Graves wrote:
> Hello, All:
>
>
>        If I use LazyData with the Ecdat package on R-Forge, "R CMD
> check" reports "no visible binding for global variable
> 'nonEnglishNames'", where 'nonEnglishNames' is a dataset in Ecdat used
> as the default argument for a function.  With LazyData, that NOTE
> disappears.  However, then I get, "Warning: objects 'Hstarts',
> 'Hstarts', 'MedExp' are created by more than one data call".
>
>
>        What do you suggest I do to fix this problem?

Not create the objects in more than one data() call.

Check what each of your data() calls produces.

>
>
>        Thanks,
>        Spencer Graves
>
>
>  > sessionInfo()
> R version 3.0.0 (2013-04-03)
> Platform: i386-w64-mingw32/i386 (32-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods base
>
> other attached packages:
> [1] Ecdat_0.2-3
>
> loaded via a namespace (and not attached):
> [1] tools_3.0.0
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From davide.rambaldi at ieo.eu  Tue May 21 09:11:05 2013
From: davide.rambaldi at ieo.eu (Davide Rambaldi)
Date: Tue, 21 May 2013 09:11:05 +0200
Subject: [Rd] locking down R
In-Reply-To: <519A3CA0.7050108@gmail.com>
References: <779843b0fc4a4b87805fcc3aa0e5c52f@EX-0-HT0.lancs.local>
	<CANVKczOeRyTPERTybExfOweP2jp-OnLQLSFMfBbOBbz6j5G=Ug@mail.gmail.com>
	<519A3CA0.7050108@gmail.com>
Message-ID: <886089C9-A5A3-45A4-80D9-F41CDE2E7919@ieo.eu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130521/663a3823/attachment.pl>

From rje42 at cam.ac.uk  Mon May 20 17:12:16 2013
From: rje42 at cam.ac.uk (Robin Evans)
Date: Mon, 20 May 2013 16:12:16 +0100
Subject: [Rd] Inconsistent results from .C()
Message-ID: <CAAjYCKuW7bOzQK_3+_BfJGOgPt-MqW-MQrv9P=Nkf0x0zg9uLg@mail.gmail.com>

Hello,

I've run into a problem which is both maddening and rather hard to
replicate, therefore I wondered if someone might know of a plausible
explanation for it.  I couldn't find anything in the archives, though
maybe I'm searching for the wrong thing.

I'm calling some C code using .C, and get the vector I'm interested in
back as the 7th location in the returned list.  However I find that if
I try to inspect the contents of this entry in the list in some ways,
I get one answer, and if I look at it in others I get a different
answer.  It's quite possible that there's something wrong with the C
code, but this doesn't seem to explain why this phenomenon would occur
in R.

The problem does not always occur - I have to run the code a few times
and then call the console when it does, but the commands below show
what can happen when it does.  I apologise for not being able to get a
cleaner example.  Full code and output is below, but here is a
stylised version:

The following all give one answer (which is the wrong answer as far as
I'm concerned) :
 * printing the whole list :
          .C(...)     # and looking at the 7th entry
 * applying c() to the 7th element of the list
          c(.C(...)[[7]])
 * assigning the 7th element to a vector:
          x = .C(...)[[7]];
          x

these give a different answer (which is the answer I would hope the C
code returns):
 * using dput on the 7th entry:
          dput(.C(...)[[7]])
 * applying c() and then dput()
          dput(c(.C(...)[[7]]))
 * just printing the 7th entry of the list
          .C(...)[[7]]

The answers are consistent in the sense that I always get the same
answers from running the same command in the console.  I have tried
inspecting the returned objects to see if the objects are somehow of a
different class than I expect, or are just being printed oddly, but
have not found anything untoward.

Any suggestions would be much appreciated!

Regards,

Robin


# THESE COMMANDS GIVE ONE ANSWER
# [the correct answer always begins with 1, the incorrect with -1]

> .C("oneMargin", c(1L,1L,1L,1L,1L), c(1L,1L,1L,1L,1L), 1L, c(2L,2L,2L,2L,2L), 5L, ptr1, ptr2)[[7]]
[1]  1 -1 -1  1 -1  1  1 -1 -1  1  1 -1  1 -1 -1  1 -1  1  1 -1  1 -1
-1  1  1 -1 -1  1 -1  1  1 -1

> dput(.C("oneMargin", c(1L,1L,1L,1L,1L), c(1L,1L,1L,1L,1L), 1L, c(2L,2L,2L,2L,2L), 5L, ptr1, ptr2)[[7]])
c(1L, -1L, -1L, 1L, -1L, 1L, 1L, -1L, -1L, 1L, 1L, -1L, 1L, -1L,
-1L, 1L, -1L, 1L, 1L, -1L, 1L, -1L, -1L, 1L, 1L, -1L, -1L, 1L,
-1L, 1L, 1L, -1L)

> x=dput(c(.C("oneMargin", c(1L,1L,1L,1L,1L), c(1L,1L,1L,1L,1L), 1L, c(2L,2L,2L,2L,2L), 5L, ptr1, ptr2)[[7]]))
c(1L, -1L, -1L, 1L, -1L, 1L, 1L, -1L, -1L, 1L, 1L, -1L, 1L, -1L,
  -1L, 1L, -1L, 1L, 1L, -1L, 1L, -1L, -1L, 1L, 1L, -1L, -1L, 1L,
  -1L, 1L, 1L, -1L)
> x
[1]  1 -1 -1  1 -1  1  1 -1 -1  1  1 -1  1 -1 -1  1 -1  1  1 -1  1 -1
-1  1  1 -1 -1  1 -1  1  1 -1

# THESE ALL GIVE A DIFFERENT ONE!

> .C("oneMargin", c(1L,1L,1L,1L,1L), c(1L,1L,1L,1L,1L), 1L, c(2L,2L,2L,2L,2L), 5L, ptr1, ptr2)

# (OTHER ELEMENTS OF LIST REMOVED)
[[7]]
[1] -1 -1  1  1  1  1 -1 -1  1  1 -1 -1 -1 -1  1  1  1  1 -1 -1 -1 -1
1  1 -1 -1  1  1  1  1 -1 -1

> c(.C("oneMargin", c(1L,1L,1L,1L,1L), c(1L,1L,1L,1L,1L), 1L, c(2L,2L,2L,2L,2L), 5L, ptr1, ptr2)[[7]])
[1] -1 -1  1  1  1  1 -1 -1  1  1 -1 -1 -1 -1  1  1  1  1 -1 -1 -1 -1
1  1 -1 -1  1  1  1  1 -1 -1
> x = .C("oneMargin", c(1L,1L,1L,1L,1L), c(1L,1L,1L,1L,1L), 1L, c(2L,2L,2L,2L,2L), 5L, ptr1, ptr2)[[7]]
> x
[1] -1 -1  1  1  1  1 -1 -1  1  1 -1 -1 -1 -1  1  1  1  1 -1 -1 -1 -1
1  1 -1 -1  1  1  1  1 -1 -1


--
Robin Evans
Statistical Laboratory
University of Cambridge
blog: itsastatlife.blogspot.com
web: www.statslab.cam.ac.uk/~rje42

Causal Inference Workshop July 15th:
http://www.statslab.cam.ac.uk/~rje42/uai13/main.htm


From rje42 at cam.ac.uk  Tue May 21 11:53:13 2013
From: rje42 at cam.ac.uk (Robin Evans)
Date: Tue, 21 May 2013 10:53:13 +0100
Subject: [Rd] Inconsistent results from .C()
In-Reply-To: <CAAjYCKuW7bOzQK_3+_BfJGOgPt-MqW-MQrv9P=Nkf0x0zg9uLg@mail.gmail.com>
References: <CAAjYCKuW7bOzQK_3+_BfJGOgPt-MqW-MQrv9P=Nkf0x0zg9uLg@mail.gmail.com>
Message-ID: <CAAjYCKuDOEXSHgPMzXXyQtb_Jr7EU=iYdQ2nT8h_sOP7AO1W0A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130521/d16e8796/attachment.pl>

From d.rizopoulos at erasmusmc.nl  Tue May 21 13:19:18 2013
From: d.rizopoulos at erasmusmc.nl (D. Rizopoulos)
Date: Tue, 21 May 2013 11:19:18 +0000
Subject: [Rd] making makepredictcall() work
Message-ID: <7191AFC7255B4F49A30707E39BEAD05F3C5FFFA1@EXCH-RX03.erasmusmc.nl>

Dear All,

I'm interested in creating a function similar to ns() from package 
splines that can be passed in a model formula. The idea is to produce 
"safe" predictions from a model using this function. As I have seen, to 
do this I need to use makepredictcall(). Consider the following toy example:

myns <- function (x, df = NULL, knots = NULL, intercept = FALSE, 
Boundary.knots = range(x),
                    extraArg = 0) {
     ns.x <- if (is.null(knots)) {
         ns(x, df = df, intercept = intercept, Boundary.knots = 
Boundary.knots)
     } else {
         ns(x, knots = knots, intercept = intercept, Boundary.knots = 
Boundary.knots)
     }
     out <- ns.x + extraArg
     attr(out, "class") <- c("myns", "basis", "matrix")
     out
}

makepredictcall.myns <- function (var, call) {
     # based on splines:::makepredictcall.ns
     if (as.character(call)[1L] != "myns")
         return(call)
     at <- attributes(var)[c("knots", "Boundary.knots", "intercept", 
"extraArg")]
     xxx <- call[1L:2L]
     xxx[names(at)] <- at
     xxx
}

dd <- data.frame(y = rnorm(12))
terms(model.frame(terms(~ myns(y, df = 3, extraArg = 0.5)), data = dd))

As it can be seen, makepredictcall.myns() succeeds in correctly passing 
the knots and Boundary.knots from the original data in the "predvars" 
attribute of the terms objects but it does not work for the new argument 
'extraArg' I introduced in myns().

Any pointers on how to resolve this will be highly appreciated.

Thanks in advance.

Best,
Dimitris


-- 
Dimitris Rizopoulos
Assistant Professor
Department of Biostatistics
Erasmus University Medical Center

Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
Tel: +31/(0)10/7043478
Fax: +31/(0)10/7043014
Web: http://www.erasmusmc.nl/biostatistiek/

From renaud at mancala.cbio.uct.ac.za  Tue May 21 14:13:53 2013
From: renaud at mancala.cbio.uct.ac.za (Renaud Gaujoux)
Date: Tue, 21 May 2013 15:13:53 +0300
Subject: [Rd] R CMD check: unknown option ?--outdir==RCHECK?
Message-ID: <CAHavPHG7995M5XS9oJ2_RcGFh0JN1fbG4fVZQr9bykZEHx=3bw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130521/206e9222/attachment.pl>

From murdoch.duncan at gmail.com  Tue May 21 14:54:23 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 21 May 2013 08:54:23 -0400
Subject: [Rd] R CMD check: unknown option ?--outdir==RCHECK?
In-Reply-To: <CAHavPHG7995M5XS9oJ2_RcGFh0JN1fbG4fVZQr9bykZEHx=3bw@mail.gmail.com>
References: <CAHavPHG7995M5XS9oJ2_RcGFh0JN1fbG4fVZQr9bykZEHx=3bw@mail.gmail.com>
Message-ID: <519B6E7F.5010509@gmail.com>

On 21/05/2013 8:13 AM, Renaud Gaujoux wrote:
> Hi,
>
> I believe this is kind of a long standing bug though. In R-3.0.1, but 
> this also happened in previous versions, the long version '--outdir' 
> is not recognised:
>
> For `R CMD check --outdir=mydir pkg_0.1.tar.gz` we get:
> Warning: unknown option ?--outdir=mydir?
>
> But with `R CMD check -o mydir pkg_0.1.tar.gz` we get:
> * using log directory ?/home/renaud/Documents/projects/mydir/pkg.Rcheck?
> ...
>
> which works perfectly fine, and puts pkg.Rcheck in 'mydir'.

I don't know how long standing it was, but as I said, it is purely a 
documentation bug.  The name of the option is --output, not --outdir.

Duncan Murdoch


From renaud at mancala.cbio.uct.ac.za  Tue May 21 15:01:34 2013
From: renaud at mancala.cbio.uct.ac.za (Renaud Gaujoux)
Date: Tue, 21 May 2013 16:01:34 +0300
Subject: [Rd] R CMD check: unknown option ?--outdir==RCHECK?
In-Reply-To: <519B6E7F.5010509@gmail.com>
References: <CAHavPHG7995M5XS9oJ2_RcGFh0JN1fbG4fVZQr9bykZEHx=3bw@mail.gmail.com>
	<519B6E7F.5010509@gmail.com>
Message-ID: <CAHavPHECZqjqmrfudxuTOSWgjObvqA19S+Edmxms2satSfhv8w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130521/e9c4abdb/attachment.pl>

From michael.weylandt at gmail.com  Tue May 21 15:04:25 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt)
Date: Tue, 21 May 2013 14:04:25 +0100
Subject: [Rd] Inconsistent results from .C()
In-Reply-To: <CAAjYCKuDOEXSHgPMzXXyQtb_Jr7EU=iYdQ2nT8h_sOP7AO1W0A@mail.gmail.com>
References: <CAAjYCKuW7bOzQK_3+_BfJGOgPt-MqW-MQrv9P=Nkf0x0zg9uLg@mail.gmail.com>
	<CAAjYCKuDOEXSHgPMzXXyQtb_Jr7EU=iYdQ2nT8h_sOP7AO1W0A@mail.gmail.com>
Message-ID: <CAAmySGNr1RYDmMAMpQcMXEyrOXifPtN41JwwbfZ=iuVMt9YQ2g@mail.gmail.com>

 It might also help if you can point us to the C code to help debug.

MW

On Tue, May 21, 2013 at 10:53 AM, Robin Evans <rje42 at cam.ac.uk> wrote:
> I should add to this that I'm running on Scientific Linux 6.  I later
> noticed that the bug only seems to occur when I run the code from Rstudio,
> and not if I use the terminal directly, so this may be the key to the
> problem.
>
> Robin
>
> On 20 May 2013 16:12, Robin Evans <rje42 at cam.ac.uk> wrote:
>
>> Hello,
>>
>> I've run into a problem which is both maddening and rather hard to
>> replicate, therefore I wondered if someone might know of a plausible
>> explanation for it.  I couldn't find anything in the archives, though
>> maybe I'm searching for the wrong thing.
>>
>> I'm calling some C code using .C, and get the vector I'm interested in
>> back as the 7th location in the returned list.  However I find that if
>> I try to inspect the contents of this entry in the list in some ways,
>> I get one answer, and if I look at it in others I get a different
>> answer.  It's quite possible that there's something wrong with the C
>> code, but this doesn't seem to explain why this phenomenon would occur
>> in R.
>>
>> The problem does not always occur - I have to run the code a few times
>> and then call the console when it does, but the commands below show
>> what can happen when it does.  I apologise for not being able to get a
>> cleaner example.  Full code and output is below, but here is a
>> stylised version:
>>
>> The following all give one answer (which is the wrong answer as far as
>> I'm concerned) :
>>  * printing the whole list :
>>           .C(...)     # and looking at the 7th entry
>>  * applying c() to the 7th element of the list
>>           c(.C(...)[[7]])
>>  * assigning the 7th element to a vector:
>>           x = .C(...)[[7]];
>>           x
>>
>> these give a different answer (which is the answer I would hope the C
>> code returns):
>>  * using dput on the 7th entry:
>>           dput(.C(...)[[7]])
>>  * applying c() and then dput()
>>           dput(c(.C(...)[[7]]))
>>  * just printing the 7th entry of the list
>>           .C(...)[[7]]
>>
>> The answers are consistent in the sense that I always get the same
>> answers from running the same command in the console.  I have tried
>> inspecting the returned objects to see if the objects are somehow of a
>> different class than I expect, or are just being printed oddly, but
>> have not found anything untoward.
>>
>> Any suggestions would be much appreciated!
>>
>> Regards,
>>
>> Robin
>>
>>
>> # THESE COMMANDS GIVE ONE ANSWER
>> # [the correct answer always begins with 1, the incorrect with -1]
>>
>> > .C("oneMargin", c(1L,1L,1L,1L,1L), c(1L,1L,1L,1L,1L), 1L,
>> c(2L,2L,2L,2L,2L), 5L, ptr1, ptr2)[[7]]
>> [1]  1 -1 -1  1 -1  1  1 -1 -1  1  1 -1  1 -1 -1  1 -1  1  1 -1  1 -1
>> -1  1  1 -1 -1  1 -1  1  1 -1
>>
>> > dput(.C("oneMargin", c(1L,1L,1L,1L,1L), c(1L,1L,1L,1L,1L), 1L,
>> c(2L,2L,2L,2L,2L), 5L, ptr1, ptr2)[[7]])
>> c(1L, -1L, -1L, 1L, -1L, 1L, 1L, -1L, -1L, 1L, 1L, -1L, 1L, -1L,
>> -1L, 1L, -1L, 1L, 1L, -1L, 1L, -1L, -1L, 1L, 1L, -1L, -1L, 1L,
>> -1L, 1L, 1L, -1L)
>>
>> > x=dput(c(.C("oneMargin", c(1L,1L,1L,1L,1L), c(1L,1L,1L,1L,1L), 1L,
>> c(2L,2L,2L,2L,2L), 5L, ptr1, ptr2)[[7]]))
>> c(1L, -1L, -1L, 1L, -1L, 1L, 1L, -1L, -1L, 1L, 1L, -1L, 1L, -1L,
>>   -1L, 1L, -1L, 1L, 1L, -1L, 1L, -1L, -1L, 1L, 1L, -1L, -1L, 1L,
>>   -1L, 1L, 1L, -1L)
>> > x
>> [1]  1 -1 -1  1 -1  1  1 -1 -1  1  1 -1  1 -1 -1  1 -1  1  1 -1  1 -1
>> -1  1  1 -1 -1  1 -1  1  1 -1
>>
>> # THESE ALL GIVE A DIFFERENT ONE!
>>
>> > .C("oneMargin", c(1L,1L,1L,1L,1L), c(1L,1L,1L,1L,1L), 1L,
>> c(2L,2L,2L,2L,2L), 5L, ptr1, ptr2)
>>
>> # (OTHER ELEMENTS OF LIST REMOVED)
>> [[7]]
>> [1] -1 -1  1  1  1  1 -1 -1  1  1 -1 -1 -1 -1  1  1  1  1 -1 -1 -1 -1
>> 1  1 -1 -1  1  1  1  1 -1 -1
>>
>> > c(.C("oneMargin", c(1L,1L,1L,1L,1L), c(1L,1L,1L,1L,1L), 1L,
>> c(2L,2L,2L,2L,2L), 5L, ptr1, ptr2)[[7]])
>> [1] -1 -1  1  1  1  1 -1 -1  1  1 -1 -1 -1 -1  1  1  1  1 -1 -1 -1 -1
>> 1  1 -1 -1  1  1  1  1 -1 -1
>> > x = .C("oneMargin", c(1L,1L,1L,1L,1L), c(1L,1L,1L,1L,1L), 1L,
>> c(2L,2L,2L,2L,2L), 5L, ptr1, ptr2)[[7]]
>> > x
>> [1] -1 -1  1  1  1  1 -1 -1  1  1 -1 -1 -1 -1  1  1  1  1 -1 -1 -1 -1
>> 1  1 -1 -1  1  1  1  1 -1 -1
>>
>>
>> --
>> Robin Evans
>> Statistical Laboratory
>> University of Cambridge
>> blog: itsastatlife.blogspot.com
>> web: www.statslab.cam.ac.uk/~rje42
>>
>> Causal Inference Workshop July 15th:
>> http://www.statslab.cam.ac.uk/~rje42/uai13/main.htm
>>
>
>
>
> --
> Robin Evans
> Statistical Laboratory
> University of Cambridge
> blog: itsastatlife.blogspot.com
> web: www.statslab.cam.ac.uk/~rje42 <http://www.stat.washington.edu/~rje42>
>
> Causal Inference Workshop July 15th:
> http://www.statslab.cam.ac.uk/~rje42/uai13/main.htm
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From rje42 at cam.ac.uk  Tue May 21 15:10:24 2013
From: rje42 at cam.ac.uk (Robin Evans)
Date: Tue, 21 May 2013 14:10:24 +0100
Subject: [Rd] Inconsistent results from .C()
In-Reply-To: <CAAmySGNr1RYDmMAMpQcMXEyrOXifPtN41JwwbfZ=iuVMt9YQ2g@mail.gmail.com>
References: <CAAjYCKuW7bOzQK_3+_BfJGOgPt-MqW-MQrv9P=Nkf0x0zg9uLg@mail.gmail.com>
	<CAAjYCKuDOEXSHgPMzXXyQtb_Jr7EU=iYdQ2nT8h_sOP7AO1W0A@mail.gmail.com>
	<CAAmySGNr1RYDmMAMpQcMXEyrOXifPtN41JwwbfZ=iuVMt9YQ2g@mail.gmail.com>
Message-ID: <CAAjYCKuRL4fa-SP6dmXFeYJiOcHcTX59KGuSs=9U166bY56BkA@mail.gmail.com>

Sure!  C code is below if it helps.  The gist is that the function
oneMargin forms two matrices M and C, mostly by repeatedly taking
Kronecker products.

Robin

void kronecker (int *A, int *B, int *dima, int *dimb, int *C) {
  int k = 0;
  int i1,i2,j1,j2;

    for (i2 = 0; i2 < dima[1]; i2++) {
    for (j2 = 0; j2 < dimb[1]; j2++) {
    for (i1 = 0; i1 < dima[0]; i1++) {
    for (j1 = 0; j1 < dimb[0]; j1++) {
      C[k] = A[i1 + dima[0]*i2]*B[j1 + dimb[0]*j2];
      k++;
    }}}}
}

void iterate (int *x, int *lev) {
  bool ok = FALSE;
  int i=0;

  do {
    if(x[i] < lev[i]-1) {
      x[i]++;
      ok = TRUE;
    }
    else {
      x[i] = 0;
    }
    i++;
  }
  while (!ok);
}

void oneMargin(int *Mar, int *Eff, int *neff, int *lev, int *nvar, int
*M, int *C) {

  int *M2, *mult, *Cj, *Cj2;
  int i,j=1,k,l,m;

  /* determine size of M to output */
  for (i = 0; i < nvar[0]; i++) {
    j *= (Mar[i] == 1 ? lev[i]*lev[i] : lev[i]);
  }
  M2 = malloc(sizeof(int)*j);
  mult = malloc(sizeof(int)*j);

  M[0] = 1;
  int M_size[2] = {1,1}, mult_size[2], Cj_size[2], C_size[2] = {0,0};

  for (i = nvar[0]-1; i >= 0; i--) {
    if (Mar[i] == 1) {
      for (j = 0; j < lev[i]*lev[i]; j++) {
        mult[j] =  ((j % (lev[i]+1)) == 0) ? 1 : 0;
      }
      mult_size[0] = mult_size[1] = lev[i];
    }
    else {
      for (j = 0; j < lev[i]; j++) {
        mult[j] =  1;
      }
      mult_size[0] = 1;
      mult_size[1] = lev[i];
    }

    kronecker(M, mult, M_size, mult_size, M2);
    M_size[0] *= mult_size[0];
    M_size[1] *= mult_size[1];

    /* copy M2 over to M */
    for (j=0; j < M_size[0]*M_size[1]; j++) {
      M[j] = M2[j];
    }
  }

  free(M2);

  /* Create C matrix */
  int index[nvar[0]];
  int prod;
  int eff_size = 0;
  /*swapped = 0; */
  mult_size[0] = 1;

  C_size[0] = 1;
  for (j = 0; j < nvar[0]; j++) {
    C_size[0] *= (Mar[j] == 1 ? lev[j] : 1);
  }

  Cj = malloc(sizeof(int)*C_size[0]);
  Cj2 = malloc(sizeof(int)*C_size[0]);
  int *lev2;
  lev2 = malloc(sizeof(int)*nvar[0]);

  /* loop over effects */
  for (i = 0; i < neff[0]; i++) {
    prod = 1;
    for (j = 0; j < nvar[0]; j++) {
      if (Eff[j + i*nvar[0]]) {
        prod *= lev[j]-1;
        lev2[eff_size] = lev[j]-1;
        index[eff_size] = 0;
        eff_size++;
       }
    }

    /* loop over states of effect (excluding corner points) */
    for (j = 0; j < prod; j++) {
      Cj[0] = 1;
      Cj_size[0] = Cj_size[1] = 1;

      k = eff_size;
      /* loop over variables */
      for (l = nvar[0]-1; l >= 0; l--) {
        /* skip variables not in margin */
        if (Mar[l] == 0) continue;
        mult_size[1] = lev[l];

        /* kronecker factor depends on whether or not variable is in effect */
        if (Eff[i*nvar[0]+l] == 0) {
          /* for variables not in effect, just repeat matrix */
          for (m = 0; m < lev[l]; m++) {
            mult[m] = 1;
          }
        }
        else {
          /* otherwise multiply based on state */
          k--;
          for (m = 0; m < lev[l]; m++) {
            mult[m] = (m == index[k]) ? lev[l] - 1 : -1;
          }
        }
        kronecker(Cj, mult, Cj_size, mult_size, Cj2);

        Cj_size[1] *= mult_size[1];

        /* copy Cj2 over to Cj */
        for (k=0; k < Cj_size[0]*Cj_size[1]; k++) {
          Cj[k] = Cj2[k];
        }
        if (Cj_size[0]*Cj_size[1] > C_size[0]) Rprintf("pointer screwup");
      }

      /* copy row over to C */
      for (m = 0; m < C_size[0]; m++) C[C_size[0]*C_size[1]+m] = Cj[m];
      C_size[1] += 1;
      iterate(index, lev2);
    }
  }

  free(lev2);
  free(Cj);
  free(Cj2);
  free(mult);
}


On 21 May 2013 14:04, R. Michael Weylandt <michael.weylandt at gmail.com> wrote:
>
>  It might also help if you can point us to the C code to help debug.
>
> MW
>
> On Tue, May 21, 2013 at 10:53 AM, Robin Evans <rje42 at cam.ac.uk> wrote:
> > I should add to this that I'm running on Scientific Linux 6.  I later
> > noticed that the bug only seems to occur when I run the code from Rstudio,
> > and not if I use the terminal directly, so this may be the key to the
> > problem.
> >
> > Robin
> >
> > On 20 May 2013 16:12, Robin Evans <rje42 at cam.ac.uk> wrote:
> >
> >> Hello,
> >>
> >> I've run into a problem which is both maddening and rather hard to
> >> replicate, therefore I wondered if someone might know of a plausible
> >> explanation for it.  I couldn't find anything in the archives, though
> >> maybe I'm searching for the wrong thing.
> >>
> >> I'm calling some C code using .C, and get the vector I'm interested in
> >> back as the 7th location in the returned list.  However I find that if
> >> I try to inspect the contents of this entry in the list in some ways,
> >> I get one answer, and if I look at it in others I get a different
> >> answer.  It's quite possible that there's something wrong with the C
> >> code, but this doesn't seem to explain why this phenomenon would occur
> >> in R.
> >>
> >> The problem does not always occur - I have to run the code a few times
> >> and then call the console when it does, but the commands below show
> >> what can happen when it does.  I apologise for not being able to get a
> >> cleaner example.  Full code and output is below, but here is a
> >> stylised version:
> >>
> >> The following all give one answer (which is the wrong answer as far as
> >> I'm concerned) :
> >>  * printing the whole list :
> >>           .C(...)     # and looking at the 7th entry
> >>  * applying c() to the 7th element of the list
> >>           c(.C(...)[[7]])
> >>  * assigning the 7th element to a vector:
> >>           x = .C(...)[[7]];
> >>           x
> >>
> >> these give a different answer (which is the answer I would hope the C
> >> code returns):
> >>  * using dput on the 7th entry:
> >>           dput(.C(...)[[7]])
> >>  * applying c() and then dput()
> >>           dput(c(.C(...)[[7]]))
> >>  * just printing the 7th entry of the list
> >>           .C(...)[[7]]
> >>
> >> The answers are consistent in the sense that I always get the same
> >> answers from running the same command in the console.  I have tried
> >> inspecting the returned objects to see if the objects are somehow of a
> >> different class than I expect, or are just being printed oddly, but
> >> have not found anything untoward.
> >>
> >> Any suggestions would be much appreciated!
> >>
> >> Regards,
> >>
> >> Robin
> >>
> >>
> >> # THESE COMMANDS GIVE ONE ANSWER
> >> # [the correct answer always begins with 1, the incorrect with -1]
> >>
> >> > .C("oneMargin", c(1L,1L,1L,1L,1L), c(1L,1L,1L,1L,1L), 1L,
> >> c(2L,2L,2L,2L,2L), 5L, ptr1, ptr2)[[7]]
> >> [1]  1 -1 -1  1 -1  1  1 -1 -1  1  1 -1  1 -1 -1  1 -1  1  1 -1  1 -1
> >> -1  1  1 -1 -1  1 -1  1  1 -1
> >>
> >> > dput(.C("oneMargin", c(1L,1L,1L,1L,1L), c(1L,1L,1L,1L,1L), 1L,
> >> c(2L,2L,2L,2L,2L), 5L, ptr1, ptr2)[[7]])
> >> c(1L, -1L, -1L, 1L, -1L, 1L, 1L, -1L, -1L, 1L, 1L, -1L, 1L, -1L,
> >> -1L, 1L, -1L, 1L, 1L, -1L, 1L, -1L, -1L, 1L, 1L, -1L, -1L, 1L,
> >> -1L, 1L, 1L, -1L)
> >>
> >> > x=dput(c(.C("oneMargin", c(1L,1L,1L,1L,1L), c(1L,1L,1L,1L,1L), 1L,
> >> c(2L,2L,2L,2L,2L), 5L, ptr1, ptr2)[[7]]))
> >> c(1L, -1L, -1L, 1L, -1L, 1L, 1L, -1L, -1L, 1L, 1L, -1L, 1L, -1L,
> >>   -1L, 1L, -1L, 1L, 1L, -1L, 1L, -1L, -1L, 1L, 1L, -1L, -1L, 1L,
> >>   -1L, 1L, 1L, -1L)
> >> > x
> >> [1]  1 -1 -1  1 -1  1  1 -1 -1  1  1 -1  1 -1 -1  1 -1  1  1 -1  1 -1
> >> -1  1  1 -1 -1  1 -1  1  1 -1
> >>
> >> # THESE ALL GIVE A DIFFERENT ONE!
> >>
> >> > .C("oneMargin", c(1L,1L,1L,1L,1L), c(1L,1L,1L,1L,1L), 1L,
> >> c(2L,2L,2L,2L,2L), 5L, ptr1, ptr2)
> >>
> >> # (OTHER ELEMENTS OF LIST REMOVED)
> >> [[7]]
> >> [1] -1 -1  1  1  1  1 -1 -1  1  1 -1 -1 -1 -1  1  1  1  1 -1 -1 -1 -1
> >> 1  1 -1 -1  1  1  1  1 -1 -1
> >>
> >> > c(.C("oneMargin", c(1L,1L,1L,1L,1L), c(1L,1L,1L,1L,1L), 1L,
> >> c(2L,2L,2L,2L,2L), 5L, ptr1, ptr2)[[7]])
> >> [1] -1 -1  1  1  1  1 -1 -1  1  1 -1 -1 -1 -1  1  1  1  1 -1 -1 -1 -1
> >> 1  1 -1 -1  1  1  1  1 -1 -1
> >> > x = .C("oneMargin", c(1L,1L,1L,1L,1L), c(1L,1L,1L,1L,1L), 1L,
> >> c(2L,2L,2L,2L,2L), 5L, ptr1, ptr2)[[7]]
> >> > x
> >> [1] -1 -1  1  1  1  1 -1 -1  1  1 -1 -1 -1 -1  1  1  1  1 -1 -1 -1 -1
> >> 1  1 -1 -1  1  1  1  1 -1 -1
> >>
> >>
> >> --
> >> Robin Evans
> >> Statistical Laboratory
> >> University of Cambridge
> >> blog: itsastatlife.blogspot.com
> >> web: www.statslab.cam.ac.uk/~rje42
> >>
> >> Causal Inference Workshop July 15th:
> >> http://www.statslab.cam.ac.uk/~rje42/uai13/main.htm
> >>
> >
> >
> >
> > --
> > Robin Evans
> > Statistical Laboratory
> > University of Cambridge
> > blog: itsastatlife.blogspot.com
> > web: www.statslab.cam.ac.uk/~rje42 <http://www.stat.washington.edu/~rje42>
> >
> > Causal Inference Workshop July 15th:
> > http://www.statslab.cam.ac.uk/~rje42/uai13/main.htm
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel


From spencer.graves at prodsyse.com  Tue May 21 16:28:26 2013
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Tue, 21 May 2013 07:28:26 -0700
Subject: [Rd] Objects created by more than one data call?
In-Reply-To: <519B01D7.4060804@stats.ox.ac.uk>
References: <519AADE9.2000505@structuremonitoring.com>
	<519B01D7.4060804@stats.ox.ac.uk>
Message-ID: <519B848A.3020305@prodsyse.com>

On 5/20/2013 10:10 PM, Prof Brian Ripley wrote:
> On 21/05/2013 00:12, Spencer Graves wrote:
>> Hello, All:
>>
>>
>>        If I use LazyData with the Ecdat package on R-Forge, "R CMD
>> check" reports "no visible binding for global variable
>> 'nonEnglishNames'", where 'nonEnglishNames' is a dataset in Ecdat used
>> as the default argument for a function.  With LazyData, that NOTE
>> disappears.  However, then I get, "Warning: objects 'Hstarts',
>> 'Hstarts', 'MedExp' are created by more than one data call".
>>
>>
>>        What do you suggest I do to fix this problem?
>
> Not create the objects in more than one data() call.
>
> Check what each of your data() calls produces.


       Thanks.  How do I do that?


       In the "man" directory, I just did "grep 'data(MedExp' *.Rd", 
which identified only "MedExp.Rd:\usage{data(MedExp)}";  "grep 
'data(Hstarts *.Rd" similarly returned only 
"Hstarts.Rd:\usage(data(Hstarts)}".


       Thanks again for the reply.
       Spencer
>
>>
>>        Thanks,
>>        Spencer Graves
>>
>>
>>  > sessionInfo()
>> R version 3.0.0 (2013-04-03)
>> Platform: i386-w64-mingw32/i386 (32-bit)
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252
>> [2] LC_CTYPE=English_United States.1252
>> [3] LC_MONETARY=English_United States.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods base
>>
>> other attached packages:
>> [1] Ecdat_0.2-3
>>
>> loaded via a namespace (and not attached):
>> [1] tools_3.0.0
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Tue May 21 16:47:23 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 21 May 2013 15:47:23 +0100
Subject: [Rd] Objects created by more than one data call?
In-Reply-To: <519B848A.3020305@prodsyse.com>
References: <519AADE9.2000505@structuremonitoring.com>
	<519B01D7.4060804@stats.ox.ac.uk> <519B848A.3020305@prodsyse.com>
Message-ID: <519B88FB.2020706@stats.ox.ac.uk>

On 21/05/2013 15:28, Spencer Graves wrote:
> On 5/20/2013 10:10 PM, Prof Brian Ripley wrote:
>> On 21/05/2013 00:12, Spencer Graves wrote:
>>> Hello, All:
>>>
>>>
>>>        If I use LazyData with the Ecdat package on R-Forge, "R CMD
>>> check" reports "no visible binding for global variable
>>> 'nonEnglishNames'", where 'nonEnglishNames' is a dataset in Ecdat used
>>> as the default argument for a function.  With LazyData, that NOTE
>>> disappears.  However, then I get, "Warning: objects 'Hstarts',
>>> 'Hstarts', 'MedExp' are created by more than one data call".
>>>
>>>
>>>        What do you suggest I do to fix this problem?
>>
>> Not create the objects in more than one data() call.
>>
>> Check what each of your data() calls produces.
>
>
>        Thanks.  How do I do that?

Call data() on each in turn, and see what files get added to an empty 
workspace.

>
>
>        In the "man" directory, I just did "grep 'data(MedExp' *.Rd",
> which identified only "MedExp.Rd:\usage{data(MedExp)}";  "grep
> 'data(Hstarts *.Rd" similarly returned only
> "Hstarts.Rd:\usage(data(Hstarts)}".
>
>
>        Thanks again for the reply.
>        Spencer
>>
>>>
>>>        Thanks,
>>>        Spencer Graves
>>>
>>>
>>>  > sessionInfo()
>>> R version 3.0.0 (2013-04-03)
>>> Platform: i386-w64-mingw32/i386 (32-bit)
>>>
>>> locale:
>>> [1] LC_COLLATE=English_United States.1252
>>> [2] LC_CTYPE=English_United States.1252
>>> [3] LC_MONETARY=English_United States.1252
>>> [4] LC_NUMERIC=C
>>> [5] LC_TIME=English_United States.1252
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods base
>>>
>>> other attached packages:
>>> [1] Ecdat_0.2-3
>>>
>>> loaded via a namespace (and not attached):
>>> [1] tools_3.0.0
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From spencer.graves at prodsyse.com  Tue May 21 17:51:06 2013
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Tue, 21 May 2013 08:51:06 -0700
Subject: [Rd] Objects created by more than one data call?
In-Reply-To: <519B88FB.2020706@stats.ox.ac.uk>
References: <519AADE9.2000505@structuremonitoring.com>
	<519B01D7.4060804@stats.ox.ac.uk> <519B848A.3020305@prodsyse.com>
	<519B88FB.2020706@stats.ox.ac.uk>
Message-ID: <519B97EA.2060003@prodsyse.com>

On 5/21/2013 7:47 AM, Prof Brian Ripley wrote:
> On 21/05/2013 15:28, Spencer Graves wrote:
>> On 5/20/2013 10:10 PM, Prof Brian Ripley wrote:
>>> On 21/05/2013 00:12, Spencer Graves wrote:
>>>> Hello, All:
>>>>
>>>>
>>>>        If I use LazyData with the Ecdat package on R-Forge, "R CMD
>>>> check" reports "no visible binding for global variable
>>>> 'nonEnglishNames'", where 'nonEnglishNames' is a dataset in Ecdat used
>>>> as the default argument for a function.  With LazyData, that NOTE
>>>> disappears.  However, then I get, "Warning: objects 'Hstarts',
>>>> 'Hstarts', 'MedExp' are created by more than one data call".
>>>>
>>>>
>>>>        What do you suggest I do to fix this problem?
>>>
>>> Not create the objects in more than one data() call.
>>>
>>> Check what each of your data() calls produces.
>>
>>
>>        Thanks.  How do I do that?
>
> Call data() on each in turn, and see what files get added to an empty 
> workspace.


Like the following?


 > library(Ecdat)
 > objects()
character(0)
 > (data(Hstarts))
[1] "Hstarts"
 > (data(MedExp))
[1] "MedExp"
 > objects()
[1] "Hstarts" "MedExp"
 > sessionInfo()
R version 3.0.0 (2013-04-03)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods base

other attached packages:
[1] Ecdat_0.2-3

loaded via a namespace (and not attached):
[1] tools_3.0.0


       Thanks,
       Spencer

>
>>        In the "man" directory, I just did "grep 'data(MedExp' *.Rd",
>> which identified only "MedExp.Rd:\usage{data(MedExp)}";  "grep
>> 'data(Hstarts *.Rd" similarly returned only
>> "Hstarts.Rd:\usage(data(Hstarts)}".
>>
>>
>>        Thanks again for the reply.
>>        Spencer
>>>
>>>>
>>>>        Thanks,
>>>>        Spencer Graves
>>>>
>>>>
>>>>  > sessionInfo()
>>>> R version 3.0.0 (2013-04-03)
>>>> Platform: i386-w64-mingw32/i386 (32-bit)
>>>>
>>>> locale:
>>>> [1] LC_COLLATE=English_United States.1252
>>>> [2] LC_CTYPE=English_United States.1252
>>>> [3] LC_MONETARY=English_United States.1252
>>>> [4] LC_NUMERIC=C
>>>> [5] LC_TIME=English_United States.1252
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets methods base
>>>>
>>>> other attached packages:
>>>> [1] Ecdat_0.2-3
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] tools_3.0.0
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Tue May 21 18:03:29 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 21 May 2013 17:03:29 +0100
Subject: [Rd] Objects created by more than one data call?
In-Reply-To: <519B97EA.2060003@prodsyse.com>
References: <519AADE9.2000505@structuremonitoring.com>
	<519B01D7.4060804@stats.ox.ac.uk> <519B848A.3020305@prodsyse.com>
	<519B88FB.2020706@stats.ox.ac.uk> <519B97EA.2060003@prodsyse.com>
Message-ID: <519B9AD1.1000406@stats.ox.ac.uk>

On 21/05/2013 16:51, Spencer Graves wrote:
> On 5/21/2013 7:47 AM, Prof Brian Ripley wrote:
>> On 21/05/2013 15:28, Spencer Graves wrote:
>>> On 5/20/2013 10:10 PM, Prof Brian Ripley wrote:
>>>> On 21/05/2013 00:12, Spencer Graves wrote:
>>>>> Hello, All:
>>>>>
>>>>>
>>>>>        If I use LazyData with the Ecdat package on R-Forge, "R CMD
>>>>> check" reports "no visible binding for global variable
>>>>> 'nonEnglishNames'", where 'nonEnglishNames' is a dataset in Ecdat used
>>>>> as the default argument for a function.  With LazyData, that NOTE
>>>>> disappears.  However, then I get, "Warning: objects 'Hstarts',
>>>>> 'Hstarts', 'MedExp' are created by more than one data call".
>>>>>
>>>>>
>>>>>        What do you suggest I do to fix this problem?
>>>>
>>>> Not create the objects in more than one data() call.
>>>>
>>>> Check what each of your data() calls produces.
>>>
>>>
>>>        Thanks.  How do I do that?
>>
>> Call data() on each in turn, and see what files get added to an empty
>> workspace.
>
>
> Like the following?

You missed the 'empty'.  Look at tools:::data2LazyLoadDB to see how this 
is checked.

>
>
>  > library(Ecdat)
>  > objects()
> character(0)
>  > (data(Hstarts))
> [1] "Hstarts"
>  > (data(MedExp))
> [1] "MedExp"
>  > objects()
> [1] "Hstarts" "MedExp"
>  > sessionInfo()
> R version 3.0.0 (2013-04-03)
> Platform: i386-w64-mingw32/i386 (32-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods base
>
> other attached packages:
> [1] Ecdat_0.2-3
>
> loaded via a namespace (and not attached):
> [1] tools_3.0.0
>
>
>        Thanks,
>        Spencer
>
>>
>>>        In the "man" directory, I just did "grep 'data(MedExp' *.Rd",
>>> which identified only "MedExp.Rd:\usage{data(MedExp)}";  "grep
>>> 'data(Hstarts *.Rd" similarly returned only
>>> "Hstarts.Rd:\usage(data(Hstarts)}".
>>>
>>>
>>>        Thanks again for the reply.
>>>        Spencer
>>>>
>>>>>
>>>>>        Thanks,
>>>>>        Spencer Graves
>>>>>
>>>>>
>>>>>  > sessionInfo()
>>>>> R version 3.0.0 (2013-04-03)
>>>>> Platform: i386-w64-mingw32/i386 (32-bit)
>>>>>
>>>>> locale:
>>>>> [1] LC_COLLATE=English_United States.1252
>>>>> [2] LC_CTYPE=English_United States.1252
>>>>> [3] LC_MONETARY=English_United States.1252
>>>>> [4] LC_NUMERIC=C
>>>>> [5] LC_TIME=English_United States.1252
>>>>>
>>>>> attached base packages:
>>>>> [1] stats     graphics  grDevices utils     datasets methods base
>>>>>
>>>>> other attached packages:
>>>>> [1] Ecdat_0.2-3
>>>>>
>>>>> loaded via a namespace (and not attached):
>>>>> [1] tools_3.0.0
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Tue May 21 18:20:08 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 21 May 2013 17:20:08 +0100
Subject: [Rd] making makepredictcall() work
In-Reply-To: <7191AFC7255B4F49A30707E39BEAD05F3C5FFFA1@EXCH-RX03.erasmusmc.nl>
References: <7191AFC7255B4F49A30707E39BEAD05F3C5FFFA1@EXCH-RX03.erasmusmc.nl>
Message-ID: <519B9EB8.3030407@stats.ox.ac.uk>

On 21/05/2013 12:19, D. Rizopoulos wrote:
> Dear All,
>
> I'm interested in creating a function similar to ns() from package
> splines that can be passed in a model formula. The idea is to produce
> "safe" predictions from a model using this function. As I have seen, to
> do this I need to use makepredictcall(). Consider the following toy example:
>
> myns <- function (x, df = NULL, knots = NULL, intercept = FALSE,
> Boundary.knots = range(x),
>                      extraArg = 0) {
>       ns.x <- if (is.null(knots)) {
>           ns(x, df = df, intercept = intercept, Boundary.knots =
> Boundary.knots)
>       } else {
>           ns(x, knots = knots, intercept = intercept, Boundary.knots =
> Boundary.knots)
>       }
>       out <- ns.x + extraArg
>       attr(out, "class") <- c("myns", "basis", "matrix")
>       out
> }
>
> makepredictcall.myns <- function (var, call) {
>       # based on splines:::makepredictcall.ns
>       if (as.character(call)[1L] != "myns")
>           return(call)
>       at <- attributes(var)[c("knots", "Boundary.knots", "intercept",
> "extraArg")]
>       xxx <- call[1L:2L]
>       xxx[names(at)] <- at
>       xxx
> }
>
> dd <- data.frame(y = rnorm(12))
> terms(model.frame(terms(~ myns(y, df = 3, extraArg = 0.5)), data = dd))
>
> As it can be seen, makepredictcall.myns() succeeds in correctly passing
> the knots and Boundary.knots from the original data in the "predvars"
> attribute of the terms objects but it does not work for the new argument
> 'extraArg' I introduced in myns().

Well, you did not set that attribute in myns(), but you looked for it. 
I guess you intended

myns <- function (x, df = NULL, knots = NULL, intercept = FALSE,
Boundary.knots = range(x),
                     extraArg = 0) {
      ns.x <- if (is.null(knots)) {
          ns(x, df = df, intercept = intercept, Boundary.knots =
Boundary.knots)
      } else {
          ns(x, knots = knots, intercept = intercept, Boundary.knots =
Boundary.knots)
      }
      out <- ns.x + extraArg
      attr(out, "extraArg") <- extraArg
      attr(out, "class") <- c("myns", "basis", "matrix")
      out
}



>
> Any pointers on how to resolve this will be highly appreciated.
>
> Thanks in advance.
>
> Best,
> Dimitris
>
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From spencer.graves at prodsyse.com  Tue May 21 21:21:04 2013
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Tue, 21 May 2013 12:21:04 -0700
Subject: [Rd] Objects created by more than one data call?
In-Reply-To: <519B9AD1.1000406@stats.ox.ac.uk>
References: <519AADE9.2000505@structuremonitoring.com>
	<519B01D7.4060804@stats.ox.ac.uk> <519B848A.3020305@prodsyse.com>
	<519B88FB.2020706@stats.ox.ac.uk> <519B97EA.2060003@prodsyse.com>
	<519B9AD1.1000406@stats.ox.ac.uk>
Message-ID: <519BC920.1070005@prodsyse.com>

On 5/21/2013 9:03 AM, Prof Brian Ripley wrote:
> On 21/05/2013 16:51, Spencer Graves wrote:
>> On 5/21/2013 7:47 AM, Prof Brian Ripley wrote:
>>> On 21/05/2013 15:28, Spencer Graves wrote:
>>>> On 5/20/2013 10:10 PM, Prof Brian Ripley wrote:
>>>>> On 21/05/2013 00:12, Spencer Graves wrote:
>>>>>> Hello, All:
>>>>>>
>>>>>>
>>>>>>        If I use LazyData with the Ecdat package on R-Forge, "R CMD
>>>>>> check" reports "no visible binding for global variable
>>>>>> 'nonEnglishNames'", where 'nonEnglishNames' is a dataset in Ecdat 
>>>>>> used
>>>>>> as the default argument for a function.  With LazyData, that NOTE
>>>>>> disappears.  However, then I get, "Warning: objects 'Hstarts',
>>>>>> 'Hstarts', 'MedExp' are created by more than one data call".
>>>>>>
>>>>>>
>>>>>>        What do you suggest I do to fix this problem?
>>>>>
>>>>> Not create the objects in more than one data() call.
>>>>>
>>>>> Check what each of your data() calls produces.
>>>>
>>>>
>>>>        Thanks.  How do I do that?
>>>
>>> Call data() on each in turn, and see what files get added to an empty
>>> workspace.
>>
>>
>> Like the following?
>
> You missed the 'empty'.  Look at tools:::data2LazyLoadDB to see how 
> this is checked.


       Thanks for the suggestion.  Unfortunately, I tried that function, 
including stepping through it line by line, fixing references to other 
functions not exported from tools, without enlightenment;  see below.


       Thanks again,
       Spencer


 > lib.loc = NULL
 > package='Ecdat'
 > pkgpath <- find.package(package, lib.loc, quiet = TRUE)
 > pkgpath
[1] "C:/Users/sgraves/pgms/R/R-3.0.0/library/Ecdat"
 > dataDir <- file.path(pkgpath, "data")
 > dataDir
[1] "C:/Users/sgraves/pgms/R/R-3.0.0/library/Ecdat/data"
 > enc <- tools:::.read_description(file.path(pkgpath, 
"DESCRIPTION"))["Encoding"]
 > enc
<NA>
   NA
 > if (!is.na(enc)) {
+         op <- options(encoding = enc)
+         on.exit(options(encoding = op[[1L]]))
+     }
 > file_test("-d", dataDir)
[1] TRUE
 > file.path(dataDir, "Rdata.rds")
[1] "C:/Users/sgraves/pgms/R/R-3.0.0/library/Ecdat/data/Rdata.rds"
 > (file.exists(file.path(dataDir, "Rdata.rds")) && 
file.exists(file.path(dataDir,
+             paste(package, "rdx", sep = "."))) && 
file.exists(file.path(dataDir,
+             paste(package, "rdb", sep = "."))))
[1] FALSE
 > file.exists(file.path(dataDir,
+             paste(package, "rdx", sep = ".")))
[1] FALSE
 > file.path(dataDir,
+             paste(package, "rdx", sep = "."))
[1] "C:/Users/sgraves/pgms/R/R-3.0.0/library/Ecdat/data/Ecdat.rdx"
 > dataEnv <- new.env(hash = TRUE)
 > tmpEnv <- new.env()
 > f0 <- files <- list_files_with_type(dataDir, "data")
Error: could not find function "list_files_with_type"
 > f0 <- files <- tools:::list_files_with_type(dataDir, "data")
 > files <- unique(basename(file_path_sans_ext(files,
+                 TRUE)))
Error in basename(file_path_sans_ext(files, TRUE)) :
   could not find function "file_path_sans_ext"
 > files <- unique(basename(tools:::file_path_sans_ext(files,
+                 TRUE)))
 >             dlist <- vector("list", length(files))
 > files
character(0)
 >  names(dlist) <- files
 >             loaded <- character(0L)
 > loaded
character(0)
 > for (f in files) {
+                 utils::data(list = f, package = package, lib.loc = 
lib.loc,
+                   envir = dataEnv)
+                 utils::data(list = f, package = package, lib.loc = 
lib.loc,
+                   envir = tmpEnv)
+                 tmp <- ls(envir = tmpEnv, all.names = TRUE)
+                 rm(list = tmp, envir = tmpEnv)
+                 dlist[[f]] <- tmp
+                 loaded <- c(loaded, tmp)
+             }
 >             dup <- duplicated(loaded)
 > dup
logical(0)
 > if (any(dup))
+                 warning(sprintf(ngettext(sum(dup), "object %s is 
created by more than one data call",
+                   "objects %s are created by more than one data call"),
+                   paste(sQuote(loaded[dup]), collapse = ", ")),
+                   call. = FALSE, domain = NA)
 >             if (length(loaded)) {
+                 dbbase <- file.path(dataDir, "Rdata")
+                 makeLazyLoadDB(dataEnv, dbbase, compress = compress)
+                 saveRDS(dlist, file.path(dataDir, "Rdata.rds"),
+                   compress = compress)
+                 unlink(f0)
+                 if (file.exists(file.path(dataDir, "filelist")))
+                   unlink(file.path(dataDir, c("filelist", "Rdata.zip")))
+             }
 >

>
>>
>>
>>  > library(Ecdat)
>>  > objects()
>> character(0)
>>  > (data(Hstarts))
>> [1] "Hstarts"
>>  > (data(MedExp))
>> [1] "MedExp"
>>  > objects()
>> [1] "Hstarts" "MedExp"
>>  > sessionInfo()
>> R version 3.0.0 (2013-04-03)
>> Platform: i386-w64-mingw32/i386 (32-bit)
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252
>> [2] LC_CTYPE=English_United States.1252
>> [3] LC_MONETARY=English_United States.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods base
>>
>> other attached packages:
>> [1] Ecdat_0.2-3
>>
>> loaded via a namespace (and not attached):
>> [1] tools_3.0.0
>>
>>
>>        Thanks,
>>        Spencer
>>
>>>
>>>>        In the "man" directory, I just did "grep 'data(MedExp' *.Rd",
>>>> which identified only "MedExp.Rd:\usage{data(MedExp)}"; "grep
>>>> 'data(Hstarts *.Rd" similarly returned only
>>>> "Hstarts.Rd:\usage(data(Hstarts)}".
>>>>
>>>>
>>>>        Thanks again for the reply.
>>>>        Spencer
>>>>>
>>>>>>
>>>>>>        Thanks,
>>>>>>        Spencer Graves
>>>>>>
>>>>>>
>>>>>>  > sessionInfo()
>>>>>> R version 3.0.0 (2013-04-03)
>>>>>> Platform: i386-w64-mingw32/i386 (32-bit)
>>>>>>
>>>>>> locale:
>>>>>> [1] LC_COLLATE=English_United States.1252
>>>>>> [2] LC_CTYPE=English_United States.1252
>>>>>> [3] LC_MONETARY=English_United States.1252
>>>>>> [4] LC_NUMERIC=C
>>>>>> [5] LC_TIME=English_United States.1252
>>>>>>
>>>>>> attached base packages:
>>>>>> [1] stats     graphics  grDevices utils     datasets methods base
>>>>>>
>>>>>> other attached packages:
>>>>>> [1] Ecdat_0.2-3
>>>>>>
>>>>>> loaded via a namespace (and not attached):
>>>>>> [1] tools_3.0.0
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From wdunlap at tibco.com  Wed May 22 00:03:40 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 21 May 2013 22:03:40 +0000
Subject: [Rd] Objects created by more than one data call?
In-Reply-To: <519BC920.1070005@prodsyse.com>
References: <519AADE9.2000505@structuremonitoring.com>
	<519B01D7.4060804@stats.ox.ac.uk> <519B848A.3020305@prodsyse.com>
	<519B88FB.2020706@stats.ox.ac.uk> <519B97EA.2060003@prodsyse.com>
	<519B9AD1.1000406@stats.ox.ac.uk> <519BC920.1070005@prodsyse.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C2F786B@PA-MBX01.na.tibco.com>

If you look at
   data(package="Ecat")$results[,"Item"]
you will see the items "Hstarts", "Hstarts (Intratesm)", and "Hstarts (Intratesq)"
which I think means that the dataset Hstarts is found in 3 .rda files, "Hstarts.rda",
"Intratesq.rda", and "Intratesm.rda".  There are duplicate, modulo (filename),
items for "MedExp" as well.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf
> Of Spencer Graves
> Sent: Tuesday, May 21, 2013 12:21 PM
> To: Prof Brian Ripley
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] Objects created by more than one data call?
> 
> On 5/21/2013 9:03 AM, Prof Brian Ripley wrote:
> > On 21/05/2013 16:51, Spencer Graves wrote:
> >> On 5/21/2013 7:47 AM, Prof Brian Ripley wrote:
> >>> On 21/05/2013 15:28, Spencer Graves wrote:
> >>>> On 5/20/2013 10:10 PM, Prof Brian Ripley wrote:
> >>>>> On 21/05/2013 00:12, Spencer Graves wrote:
> >>>>>> Hello, All:
> >>>>>>
> >>>>>>
> >>>>>>        If I use LazyData with the Ecdat package on R-Forge, "R CMD
> >>>>>> check" reports "no visible binding for global variable
> >>>>>> 'nonEnglishNames'", where 'nonEnglishNames' is a dataset in Ecdat
> >>>>>> used
> >>>>>> as the default argument for a function.  With LazyData, that NOTE
> >>>>>> disappears.  However, then I get, "Warning: objects 'Hstarts',
> >>>>>> 'Hstarts', 'MedExp' are created by more than one data call".
> >>>>>>
> >>>>>>
> >>>>>>        What do you suggest I do to fix this problem?
> >>>>>
> >>>>> Not create the objects in more than one data() call.
> >>>>>
> >>>>> Check what each of your data() calls produces.
> >>>>
> >>>>
> >>>>        Thanks.  How do I do that?
> >>>
> >>> Call data() on each in turn, and see what files get added to an empty
> >>> workspace.
> >>
> >>
> >> Like the following?
> >
> > You missed the 'empty'.  Look at tools:::data2LazyLoadDB to see how
> > this is checked.
> 
> 
>        Thanks for the suggestion.  Unfortunately, I tried that function,
> including stepping through it line by line, fixing references to other
> functions not exported from tools, without enlightenment;  see below.
> 
> 
>        Thanks again,
>        Spencer
> 
> 
>  > lib.loc = NULL
>  > package='Ecdat'
>  > pkgpath <- find.package(package, lib.loc, quiet = TRUE)
>  > pkgpath
> [1] "C:/Users/sgraves/pgms/R/R-3.0.0/library/Ecdat"
>  > dataDir <- file.path(pkgpath, "data")
>  > dataDir
> [1] "C:/Users/sgraves/pgms/R/R-3.0.0/library/Ecdat/data"
>  > enc <- tools:::.read_description(file.path(pkgpath,
> "DESCRIPTION"))["Encoding"]
>  > enc
> <NA>
>    NA
>  > if (!is.na(enc)) {
> +         op <- options(encoding = enc)
> +         on.exit(options(encoding = op[[1L]]))
> +     }
>  > file_test("-d", dataDir)
> [1] TRUE
>  > file.path(dataDir, "Rdata.rds")
> [1] "C:/Users/sgraves/pgms/R/R-3.0.0/library/Ecdat/data/Rdata.rds"
>  > (file.exists(file.path(dataDir, "Rdata.rds")) &&
> file.exists(file.path(dataDir,
> +             paste(package, "rdx", sep = "."))) &&
> file.exists(file.path(dataDir,
> +             paste(package, "rdb", sep = "."))))
> [1] FALSE
>  > file.exists(file.path(dataDir,
> +             paste(package, "rdx", sep = ".")))
> [1] FALSE
>  > file.path(dataDir,
> +             paste(package, "rdx", sep = "."))
> [1] "C:/Users/sgraves/pgms/R/R-3.0.0/library/Ecdat/data/Ecdat.rdx"
>  > dataEnv <- new.env(hash = TRUE)
>  > tmpEnv <- new.env()
>  > f0 <- files <- list_files_with_type(dataDir, "data")
> Error: could not find function "list_files_with_type"
>  > f0 <- files <- tools:::list_files_with_type(dataDir, "data")
>  > files <- unique(basename(file_path_sans_ext(files,
> +                 TRUE)))
> Error in basename(file_path_sans_ext(files, TRUE)) :
>    could not find function "file_path_sans_ext"
>  > files <- unique(basename(tools:::file_path_sans_ext(files,
> +                 TRUE)))
>  >             dlist <- vector("list", length(files))
>  > files
> character(0)
>  >  names(dlist) <- files
>  >             loaded <- character(0L)
>  > loaded
> character(0)
>  > for (f in files) {
> +                 utils::data(list = f, package = package, lib.loc =
> lib.loc,
> +                   envir = dataEnv)
> +                 utils::data(list = f, package = package, lib.loc =
> lib.loc,
> +                   envir = tmpEnv)
> +                 tmp <- ls(envir = tmpEnv, all.names = TRUE)
> +                 rm(list = tmp, envir = tmpEnv)
> +                 dlist[[f]] <- tmp
> +                 loaded <- c(loaded, tmp)
> +             }
>  >             dup <- duplicated(loaded)
>  > dup
> logical(0)
>  > if (any(dup))
> +                 warning(sprintf(ngettext(sum(dup), "object %s is
> created by more than one data call",
> +                   "objects %s are created by more than one data call"),
> +                   paste(sQuote(loaded[dup]), collapse = ", ")),
> +                   call. = FALSE, domain = NA)
>  >             if (length(loaded)) {
> +                 dbbase <- file.path(dataDir, "Rdata")
> +                 makeLazyLoadDB(dataEnv, dbbase, compress = compress)
> +                 saveRDS(dlist, file.path(dataDir, "Rdata.rds"),
> +                   compress = compress)
> +                 unlink(f0)
> +                 if (file.exists(file.path(dataDir, "filelist")))
> +                   unlink(file.path(dataDir, c("filelist", "Rdata.zip")))
> +             }
>  >
> 
> >
> >>
> >>
> >>  > library(Ecdat)
> >>  > objects()
> >> character(0)
> >>  > (data(Hstarts))
> >> [1] "Hstarts"
> >>  > (data(MedExp))
> >> [1] "MedExp"
> >>  > objects()
> >> [1] "Hstarts" "MedExp"
> >>  > sessionInfo()
> >> R version 3.0.0 (2013-04-03)
> >> Platform: i386-w64-mingw32/i386 (32-bit)
> >>
> >> locale:
> >> [1] LC_COLLATE=English_United States.1252
> >> [2] LC_CTYPE=English_United States.1252
> >> [3] LC_MONETARY=English_United States.1252
> >> [4] LC_NUMERIC=C
> >> [5] LC_TIME=English_United States.1252
> >>
> >> attached base packages:
> >> [1] stats     graphics  grDevices utils     datasets  methods base
> >>
> >> other attached packages:
> >> [1] Ecdat_0.2-3
> >>
> >> loaded via a namespace (and not attached):
> >> [1] tools_3.0.0
> >>
> >>
> >>        Thanks,
> >>        Spencer
> >>
> >>>
> >>>>        In the "man" directory, I just did "grep 'data(MedExp' *.Rd",
> >>>> which identified only "MedExp.Rd:\usage{data(MedExp)}"; "grep
> >>>> 'data(Hstarts *.Rd" similarly returned only
> >>>> "Hstarts.Rd:\usage(data(Hstarts)}".
> >>>>
> >>>>
> >>>>        Thanks again for the reply.
> >>>>        Spencer
> >>>>>
> >>>>>>
> >>>>>>        Thanks,
> >>>>>>        Spencer Graves
> >>>>>>
> >>>>>>
> >>>>>>  > sessionInfo()
> >>>>>> R version 3.0.0 (2013-04-03)
> >>>>>> Platform: i386-w64-mingw32/i386 (32-bit)
> >>>>>>
> >>>>>> locale:
> >>>>>> [1] LC_COLLATE=English_United States.1252
> >>>>>> [2] LC_CTYPE=English_United States.1252
> >>>>>> [3] LC_MONETARY=English_United States.1252
> >>>>>> [4] LC_NUMERIC=C
> >>>>>> [5] LC_TIME=English_United States.1252
> >>>>>>
> >>>>>> attached base packages:
> >>>>>> [1] stats     graphics  grDevices utils     datasets methods base
> >>>>>>
> >>>>>> other attached packages:
> >>>>>> [1] Ecdat_0.2-3
> >>>>>>
> >>>>>> loaded via a namespace (and not attached):
> >>>>>> [1] tools_3.0.0
> >>>>>>
> >>>>>> ______________________________________________
> >>>>>> R-devel at r-project.org mailing list
> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From spencer.graves at prodsyse.com  Wed May 22 22:26:45 2013
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Wed, 22 May 2013 13:26:45 -0700
Subject: [Rd] Objects created by more than one data call?
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C2F786B@PA-MBX01.na.tibco.com>
References: <519AADE9.2000505@structuremonitoring.com>
	<519B01D7.4060804@stats.ox.ac.uk> <519B848A.3020305@prodsyse.com>
	<519B88FB.2020706@stats.ox.ac.uk> <519B97EA.2060003@prodsyse.com>
	<519B9AD1.1000406@stats.ox.ac.uk> <519BC920.1070005@prodsyse.com>
	<E66794E69CFDE04D9A70842786030B931C2F786B@PA-MBX01.na.tibco.com>
Message-ID: <519D2A05.8020805@prodsyse.com>

On 5/21/2013 3:03 PM, William Dunlap wrote:
> If you look at
>     data(package="Ecat")$results[,"Item"]
> you will see the items "Hstarts", "Hstarts (Intratesm)", and "Hstarts (Intratesq)"
> which I think means that the dataset Hstarts is found in 3 .rda files, "Hstarts.rda",
> "Intratesq.rda", and "Intratesm.rda".  There are duplicate, modulo (filename),
> items for "MedExp" as well.


       Thanks for this.  I may get me closer, but I still don't see it:  
(data(Intratesm)) imports only the object Intratesm, etc.  For more 
details, see below.


       Any other suggestions?


       Thanks again,
       Spencer


 > Ecdat.data <- data(package="Ecdat")$results
 > (Hstarts2 <- grep('Hstarts', Ecdat.data[, 'Item']))
[1] 47 48 49
 > (MedExp2 <- grep('MedExp', Ecdat.data[, 'Item']))
[1] 67 68
 > Ecdat.data[Hstarts2, ]
      Package LibPath Item
[1,] "Ecdat" "C:/Users/sgraves/pgms/R/R-3.0.0/library" "Hstarts"
[2,] "Ecdat" "C:/Users/sgraves/pgms/R/R-3.0.0/library" "Hstarts (Intratesm)"
[3,] "Ecdat" "C:/Users/sgraves/pgms/R/R-3.0.0/library" "Hstarts (Intratesq)"
      Title
[1,] "Housing Starts"
[2,] "Housing Starts"
[3,] "Housing Starts"
 > Ecdat.data[MedExp2,]
      Package LibPath Item
[1,] "Ecdat" "C:/Users/sgraves/pgms/R/R-3.0.0/library" "MedExp"
[2,] "Ecdat" "C:/Users/sgraves/pgms/R/R-3.0.0/library" "MedExp (VietNamH)"
      Title
[1,] "Structure of Demand for Medical Care"
[2,] "Structure of Demand for Medical Care"
 > library(Ecdat)
 > (data(Intratesm))
[1] "Intratesm"
 > (data(Intratesq))
[1] "Intratesq"


> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
>
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf
>> Of Spencer Graves
>> Sent: Tuesday, May 21, 2013 12:21 PM
>> To: Prof Brian Ripley
>> Cc: r-devel at r-project.org
>> Subject: Re: [Rd] Objects created by more than one data call?
>>
>> On 5/21/2013 9:03 AM, Prof Brian Ripley wrote:
>>> On 21/05/2013 16:51, Spencer Graves wrote:
>>>> On 5/21/2013 7:47 AM, Prof Brian Ripley wrote:
>>>>> On 21/05/2013 15:28, Spencer Graves wrote:
>>>>>> On 5/20/2013 10:10 PM, Prof Brian Ripley wrote:
>>>>>>> On 21/05/2013 00:12, Spencer Graves wrote:
>>>>>>>> Hello, All:
>>>>>>>>
>>>>>>>>
>>>>>>>>         If I use LazyData with the Ecdat package on R-Forge, "R CMD
>>>>>>>> check" reports "no visible binding for global variable
>>>>>>>> 'nonEnglishNames'", where 'nonEnglishNames' is a dataset in Ecdat
>>>>>>>> used
>>>>>>>> as the default argument for a function.  With LazyData, that NOTE
>>>>>>>> disappears.  However, then I get, "Warning: objects 'Hstarts',
>>>>>>>> 'Hstarts', 'MedExp' are created by more than one data call".
>>>>>>>>
>>>>>>>>
>>>>>>>>         What do you suggest I do to fix this problem?
>>>>>>> Not create the objects in more than one data() call.
>>>>>>>
>>>>>>> Check what each of your data() calls produces.
>>>>>>
>>>>>>         Thanks.  How do I do that?
>>>>> Call data() on each in turn, and see what files get added to an empty
>>>>> workspace.
>>>>
>>>> Like the following?
>>> You missed the 'empty'.  Look at tools:::data2LazyLoadDB to see how
>>> this is checked.
>>
>>         Thanks for the suggestion.  Unfortunately, I tried that function,
>> including stepping through it line by line, fixing references to other
>> functions not exported from tools, without enlightenment;  see below.
>>
>>
>>         Thanks again,
>>         Spencer
>>
>>
>>   > lib.loc = NULL
>>   > package='Ecdat'
>>   > pkgpath <- find.package(package, lib.loc, quiet = TRUE)
>>   > pkgpath
>> [1] "C:/Users/sgraves/pgms/R/R-3.0.0/library/Ecdat"
>>   > dataDir <- file.path(pkgpath, "data")
>>   > dataDir
>> [1] "C:/Users/sgraves/pgms/R/R-3.0.0/library/Ecdat/data"
>>   > enc <- tools:::.read_description(file.path(pkgpath,
>> "DESCRIPTION"))["Encoding"]
>>   > enc
>> <NA>
>>     NA
>>   > if (!is.na(enc)) {
>> +         op <- options(encoding = enc)
>> +         on.exit(options(encoding = op[[1L]]))
>> +     }
>>   > file_test("-d", dataDir)
>> [1] TRUE
>>   > file.path(dataDir, "Rdata.rds")
>> [1] "C:/Users/sgraves/pgms/R/R-3.0.0/library/Ecdat/data/Rdata.rds"
>>   > (file.exists(file.path(dataDir, "Rdata.rds")) &&
>> file.exists(file.path(dataDir,
>> +             paste(package, "rdx", sep = "."))) &&
>> file.exists(file.path(dataDir,
>> +             paste(package, "rdb", sep = "."))))
>> [1] FALSE
>>   > file.exists(file.path(dataDir,
>> +             paste(package, "rdx", sep = ".")))
>> [1] FALSE
>>   > file.path(dataDir,
>> +             paste(package, "rdx", sep = "."))
>> [1] "C:/Users/sgraves/pgms/R/R-3.0.0/library/Ecdat/data/Ecdat.rdx"
>>   > dataEnv <- new.env(hash = TRUE)
>>   > tmpEnv <- new.env()
>>   > f0 <- files <- list_files_with_type(dataDir, "data")
>> Error: could not find function "list_files_with_type"
>>   > f0 <- files <- tools:::list_files_with_type(dataDir, "data")
>>   > files <- unique(basename(file_path_sans_ext(files,
>> +                 TRUE)))
>> Error in basename(file_path_sans_ext(files, TRUE)) :
>>     could not find function "file_path_sans_ext"
>>   > files <- unique(basename(tools:::file_path_sans_ext(files,
>> +                 TRUE)))
>>   >             dlist <- vector("list", length(files))
>>   > files
>> character(0)
>>   >  names(dlist) <- files
>>   >             loaded <- character(0L)
>>   > loaded
>> character(0)
>>   > for (f in files) {
>> +                 utils::data(list = f, package = package, lib.loc =
>> lib.loc,
>> +                   envir = dataEnv)
>> +                 utils::data(list = f, package = package, lib.loc =
>> lib.loc,
>> +                   envir = tmpEnv)
>> +                 tmp <- ls(envir = tmpEnv, all.names = TRUE)
>> +                 rm(list = tmp, envir = tmpEnv)
>> +                 dlist[[f]] <- tmp
>> +                 loaded <- c(loaded, tmp)
>> +             }
>>   >             dup <- duplicated(loaded)
>>   > dup
>> logical(0)
>>   > if (any(dup))
>> +                 warning(sprintf(ngettext(sum(dup), "object %s is
>> created by more than one data call",
>> +                   "objects %s are created by more than one data call"),
>> +                   paste(sQuote(loaded[dup]), collapse = ", ")),
>> +                   call. = FALSE, domain = NA)
>>   >             if (length(loaded)) {
>> +                 dbbase <- file.path(dataDir, "Rdata")
>> +                 makeLazyLoadDB(dataEnv, dbbase, compress = compress)
>> +                 saveRDS(dlist, file.path(dataDir, "Rdata.rds"),
>> +                   compress = compress)
>> +                 unlink(f0)
>> +                 if (file.exists(file.path(dataDir, "filelist")))
>> +                   unlink(file.path(dataDir, c("filelist", "Rdata.zip")))
>> +             }
>>   >
>>
>>>>
>>>>   > library(Ecdat)
>>>>   > objects()
>>>> character(0)
>>>>   > (data(Hstarts))
>>>> [1] "Hstarts"
>>>>   > (data(MedExp))
>>>> [1] "MedExp"
>>>>   > objects()
>>>> [1] "Hstarts" "MedExp"
>>>>   > sessionInfo()
>>>> R version 3.0.0 (2013-04-03)
>>>> Platform: i386-w64-mingw32/i386 (32-bit)
>>>>
>>>> locale:
>>>> [1] LC_COLLATE=English_United States.1252
>>>> [2] LC_CTYPE=English_United States.1252
>>>> [3] LC_MONETARY=English_United States.1252
>>>> [4] LC_NUMERIC=C
>>>> [5] LC_TIME=English_United States.1252
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  methods base
>>>>
>>>> other attached packages:
>>>> [1] Ecdat_0.2-3
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] tools_3.0.0
>>>>
>>>>
>>>>         Thanks,
>>>>         Spencer
>>>>
>>>>>>         In the "man" directory, I just did "grep 'data(MedExp' *.Rd",
>>>>>> which identified only "MedExp.Rd:\usage{data(MedExp)}"; "grep
>>>>>> 'data(Hstarts *.Rd" similarly returned only
>>>>>> "Hstarts.Rd:\usage(data(Hstarts)}".
>>>>>>
>>>>>>
>>>>>>         Thanks again for the reply.
>>>>>>         Spencer
>>>>>>>>         Thanks,
>>>>>>>>         Spencer Graves
>>>>>>>>
>>>>>>>>
>>>>>>>>   > sessionInfo()
>>>>>>>> R version 3.0.0 (2013-04-03)
>>>>>>>> Platform: i386-w64-mingw32/i386 (32-bit)
>>>>>>>>
>>>>>>>> locale:
>>>>>>>> [1] LC_COLLATE=English_United States.1252
>>>>>>>> [2] LC_CTYPE=English_United States.1252
>>>>>>>> [3] LC_MONETARY=English_United States.1252
>>>>>>>> [4] LC_NUMERIC=C
>>>>>>>> [5] LC_TIME=English_United States.1252
>>>>>>>>
>>>>>>>> attached base packages:
>>>>>>>> [1] stats     graphics  grDevices utils     datasets methods base
>>>>>>>>
>>>>>>>> other attached packages:
>>>>>>>> [1] Ecdat_0.2-3
>>>>>>>>
>>>>>>>> loaded via a namespace (and not attached):
>>>>>>>> [1] tools_3.0.0
>>>>>>>>
>>>>>>>> ______________________________________________
>>>>>>>> R-devel at r-project.org mailing list
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel


From wdunlap at tibco.com  Wed May 22 23:12:32 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 22 May 2013 21:12:32 +0000
Subject: [Rd] Objects created by more than one data call?
In-Reply-To: <519D2A05.8020805@prodsyse.com>
References: <519AADE9.2000505@structuremonitoring.com>
	<519B01D7.4060804@stats.ox.ac.uk> <519B848A.3020305@prodsyse.com>
	<519B88FB.2020706@stats.ox.ac.uk> <519B97EA.2060003@prodsyse.com>
	<519B9AD1.1000406@stats.ox.ac.uk> <519BC920.1070005@prodsyse.com>
	<E66794E69CFDE04D9A70842786030B931C2F786B@PA-MBX01.na.tibco.com>
	<519D2A05.8020805@prodsyse.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C2F7DC7@PA-MBX01.na.tibco.com>

I used svn to copy the current version of Ecdat from Rforge to my PC
  C:\temp\packages>svn checkout svn://r-forge.r-project.org/svnroot/ecdat/
then fired up R to look at the rda files in it.

> setwd("c:/temp/packages/Ecdat/ecdat/pkg/data")
> read.dcf("../DESCRIPTION")[, c("Package","Version")]
Package Version
"Ecdat" "0.2-3"
> dir.rda <- function(rdaFile) { e <- new.env() ; load(rdaFile, envir=e) ; objects(e, all=TRUE)}
> dir.rda("VietNamH.rda")
[1] "MedExp"
> rdas <- dir(pattern="\\.rda$")
> names(rdas) <- rdas
> z <- lapply(rdas, dir.rda)
> tab <- table(unlist(z))
> tab[tab>1]

Hstarts  MedExp
      3       2
> z[sapply(z, function(zi)"Hstarts" %in% zi)]
$Hstarts.rda
[1] "Hstarts"

$Intratesm.rda
[1] "Hstarts"

$Intratesq.rda
[1] "Hstarts"

> z[sapply(z, function(zi)"MedExp" %in% zi)]
$MedExp.rda
[1] "MedExp"

$VietNamH.rda
[1] "MedExp"

It looks some files don't contain what their names suggest:
> dir.rda("VietNamH.rda")
[1] "MedExp"

The two versions of MedExp are quite different:
> load("VietNamH.rda", envViet <- new.env(parent=emptyenv()))
> load("MedExp.rda", envMed <- new.env(parent=emptyenv()))
> objects(envViet)
[1] "MedExp"
> objects(envMed)
[1] "MedExp"
> all.equal(envViet$MedExp, envMed$MedExp)
 [1] "Names: 11 string mismatches"                                 
 [2] "Length mismatch: comparison on first 11 components"          
 [3] "Component 1: 'current' is not a factor"                      
 ...
[18] "Component 10: Numeric: lengths (5999, 5574) differ"          
[19] "Component 11: 'current' is not a factor"                     

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: Spencer Graves [mailto:spencer.graves at prodsyse.com]
> Sent: Wednesday, May 22, 2013 1:27 PM
> To: William Dunlap
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] Objects created by more than one data call?
> 
> On 5/21/2013 3:03 PM, William Dunlap wrote:
> > If you look at
> >     data(package="Ecat")$results[,"Item"]
> > you will see the items "Hstarts", "Hstarts (Intratesm)", and "Hstarts (Intratesq)"
> > which I think means that the dataset Hstarts is found in 3 .rda files, "Hstarts.rda",
> > "Intratesq.rda", and "Intratesm.rda".  There are duplicate, modulo (filename),
> > items for "MedExp" as well.
> 
> 
>        Thanks for this.  I may get me closer, but I still don't see it:
> (data(Intratesm)) imports only the object Intratesm, etc.  For more
> details, see below.
> 
> 
>        Any other suggestions?
> 
> 
>        Thanks again,
>        Spencer
> 
> 
>  > Ecdat.data <- data(package="Ecdat")$results
>  > (Hstarts2 <- grep('Hstarts', Ecdat.data[, 'Item']))
> [1] 47 48 49
>  > (MedExp2 <- grep('MedExp', Ecdat.data[, 'Item']))
> [1] 67 68
>  > Ecdat.data[Hstarts2, ]
>       Package LibPath Item
> [1,] "Ecdat" "C:/Users/sgraves/pgms/R/R-3.0.0/library" "Hstarts"
> [2,] "Ecdat" "C:/Users/sgraves/pgms/R/R-3.0.0/library" "Hstarts (Intratesm)"
> [3,] "Ecdat" "C:/Users/sgraves/pgms/R/R-3.0.0/library" "Hstarts (Intratesq)"
>       Title
> [1,] "Housing Starts"
> [2,] "Housing Starts"
> [3,] "Housing Starts"
>  > Ecdat.data[MedExp2,]
>       Package LibPath Item
> [1,] "Ecdat" "C:/Users/sgraves/pgms/R/R-3.0.0/library" "MedExp"
> [2,] "Ecdat" "C:/Users/sgraves/pgms/R/R-3.0.0/library" "MedExp (VietNamH)"
>       Title
> [1,] "Structure of Demand for Medical Care"
> [2,] "Structure of Demand for Medical Care"
>  > library(Ecdat)
>  > (data(Intratesm))
> [1] "Intratesm"
>  > (data(Intratesq))
> [1] "Intratesq"
> 
> 
> > Bill Dunlap
> > Spotfire, TIBCO Software
> > wdunlap tibco.com
> >
> >
> >> -----Original Message-----
> >> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On
> Behalf
> >> Of Spencer Graves
> >> Sent: Tuesday, May 21, 2013 12:21 PM
> >> To: Prof Brian Ripley
> >> Cc: r-devel at r-project.org
> >> Subject: Re: [Rd] Objects created by more than one data call?
> >>
> >> On 5/21/2013 9:03 AM, Prof Brian Ripley wrote:
> >>> On 21/05/2013 16:51, Spencer Graves wrote:
> >>>> On 5/21/2013 7:47 AM, Prof Brian Ripley wrote:
> >>>>> On 21/05/2013 15:28, Spencer Graves wrote:
> >>>>>> On 5/20/2013 10:10 PM, Prof Brian Ripley wrote:
> >>>>>>> On 21/05/2013 00:12, Spencer Graves wrote:
> >>>>>>>> Hello, All:
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>         If I use LazyData with the Ecdat package on R-Forge, "R CMD
> >>>>>>>> check" reports "no visible binding for global variable
> >>>>>>>> 'nonEnglishNames'", where 'nonEnglishNames' is a dataset in Ecdat
> >>>>>>>> used
> >>>>>>>> as the default argument for a function.  With LazyData, that NOTE
> >>>>>>>> disappears.  However, then I get, "Warning: objects 'Hstarts',
> >>>>>>>> 'Hstarts', 'MedExp' are created by more than one data call".
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>         What do you suggest I do to fix this problem?
> >>>>>>> Not create the objects in more than one data() call.
> >>>>>>>
> >>>>>>> Check what each of your data() calls produces.
> >>>>>>
> >>>>>>         Thanks.  How do I do that?
> >>>>> Call data() on each in turn, and see what files get added to an empty
> >>>>> workspace.
> >>>>
> >>>> Like the following?
> >>> You missed the 'empty'.  Look at tools:::data2LazyLoadDB to see how
> >>> this is checked.
> >>
> >>         Thanks for the suggestion.  Unfortunately, I tried that function,
> >> including stepping through it line by line, fixing references to other
> >> functions not exported from tools, without enlightenment;  see below.
> >>
> >>
> >>         Thanks again,
> >>         Spencer
> >>
> >>
> >>   > lib.loc = NULL
> >>   > package='Ecdat'
> >>   > pkgpath <- find.package(package, lib.loc, quiet = TRUE)
> >>   > pkgpath
> >> [1] "C:/Users/sgraves/pgms/R/R-3.0.0/library/Ecdat"
> >>   > dataDir <- file.path(pkgpath, "data")
> >>   > dataDir
> >> [1] "C:/Users/sgraves/pgms/R/R-3.0.0/library/Ecdat/data"
> >>   > enc <- tools:::.read_description(file.path(pkgpath,
> >> "DESCRIPTION"))["Encoding"]
> >>   > enc
> >> <NA>
> >>     NA
> >>   > if (!is.na(enc)) {
> >> +         op <- options(encoding = enc)
> >> +         on.exit(options(encoding = op[[1L]]))
> >> +     }
> >>   > file_test("-d", dataDir)
> >> [1] TRUE
> >>   > file.path(dataDir, "Rdata.rds")
> >> [1] "C:/Users/sgraves/pgms/R/R-3.0.0/library/Ecdat/data/Rdata.rds"
> >>   > (file.exists(file.path(dataDir, "Rdata.rds")) &&
> >> file.exists(file.path(dataDir,
> >> +             paste(package, "rdx", sep = "."))) &&
> >> file.exists(file.path(dataDir,
> >> +             paste(package, "rdb", sep = "."))))
> >> [1] FALSE
> >>   > file.exists(file.path(dataDir,
> >> +             paste(package, "rdx", sep = ".")))
> >> [1] FALSE
> >>   > file.path(dataDir,
> >> +             paste(package, "rdx", sep = "."))
> >> [1] "C:/Users/sgraves/pgms/R/R-3.0.0/library/Ecdat/data/Ecdat.rdx"
> >>   > dataEnv <- new.env(hash = TRUE)
> >>   > tmpEnv <- new.env()
> >>   > f0 <- files <- list_files_with_type(dataDir, "data")
> >> Error: could not find function "list_files_with_type"
> >>   > f0 <- files <- tools:::list_files_with_type(dataDir, "data")
> >>   > files <- unique(basename(file_path_sans_ext(files,
> >> +                 TRUE)))
> >> Error in basename(file_path_sans_ext(files, TRUE)) :
> >>     could not find function "file_path_sans_ext"
> >>   > files <- unique(basename(tools:::file_path_sans_ext(files,
> >> +                 TRUE)))
> >>   >             dlist <- vector("list", length(files))
> >>   > files
> >> character(0)
> >>   >  names(dlist) <- files
> >>   >             loaded <- character(0L)
> >>   > loaded
> >> character(0)
> >>   > for (f in files) {
> >> +                 utils::data(list = f, package = package, lib.loc =
> >> lib.loc,
> >> +                   envir = dataEnv)
> >> +                 utils::data(list = f, package = package, lib.loc =
> >> lib.loc,
> >> +                   envir = tmpEnv)
> >> +                 tmp <- ls(envir = tmpEnv, all.names = TRUE)
> >> +                 rm(list = tmp, envir = tmpEnv)
> >> +                 dlist[[f]] <- tmp
> >> +                 loaded <- c(loaded, tmp)
> >> +             }
> >>   >             dup <- duplicated(loaded)
> >>   > dup
> >> logical(0)
> >>   > if (any(dup))
> >> +                 warning(sprintf(ngettext(sum(dup), "object %s is
> >> created by more than one data call",
> >> +                   "objects %s are created by more than one data call"),
> >> +                   paste(sQuote(loaded[dup]), collapse = ", ")),
> >> +                   call. = FALSE, domain = NA)
> >>   >             if (length(loaded)) {
> >> +                 dbbase <- file.path(dataDir, "Rdata")
> >> +                 makeLazyLoadDB(dataEnv, dbbase, compress = compress)
> >> +                 saveRDS(dlist, file.path(dataDir, "Rdata.rds"),
> >> +                   compress = compress)
> >> +                 unlink(f0)
> >> +                 if (file.exists(file.path(dataDir, "filelist")))
> >> +                   unlink(file.path(dataDir, c("filelist", "Rdata.zip")))
> >> +             }
> >>   >
> >>
> >>>>
> >>>>   > library(Ecdat)
> >>>>   > objects()
> >>>> character(0)
> >>>>   > (data(Hstarts))
> >>>> [1] "Hstarts"
> >>>>   > (data(MedExp))
> >>>> [1] "MedExp"
> >>>>   > objects()
> >>>> [1] "Hstarts" "MedExp"
> >>>>   > sessionInfo()
> >>>> R version 3.0.0 (2013-04-03)
> >>>> Platform: i386-w64-mingw32/i386 (32-bit)
> >>>>
> >>>> locale:
> >>>> [1] LC_COLLATE=English_United States.1252
> >>>> [2] LC_CTYPE=English_United States.1252
> >>>> [3] LC_MONETARY=English_United States.1252
> >>>> [4] LC_NUMERIC=C
> >>>> [5] LC_TIME=English_United States.1252
> >>>>
> >>>> attached base packages:
> >>>> [1] stats     graphics  grDevices utils     datasets  methods base
> >>>>
> >>>> other attached packages:
> >>>> [1] Ecdat_0.2-3
> >>>>
> >>>> loaded via a namespace (and not attached):
> >>>> [1] tools_3.0.0
> >>>>
> >>>>
> >>>>         Thanks,
> >>>>         Spencer
> >>>>
> >>>>>>         In the "man" directory, I just did "grep 'data(MedExp' *.Rd",
> >>>>>> which identified only "MedExp.Rd:\usage{data(MedExp)}"; "grep
> >>>>>> 'data(Hstarts *.Rd" similarly returned only
> >>>>>> "Hstarts.Rd:\usage(data(Hstarts)}".
> >>>>>>
> >>>>>>
> >>>>>>         Thanks again for the reply.
> >>>>>>         Spencer
> >>>>>>>>         Thanks,
> >>>>>>>>         Spencer Graves
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>   > sessionInfo()
> >>>>>>>> R version 3.0.0 (2013-04-03)
> >>>>>>>> Platform: i386-w64-mingw32/i386 (32-bit)
> >>>>>>>>
> >>>>>>>> locale:
> >>>>>>>> [1] LC_COLLATE=English_United States.1252
> >>>>>>>> [2] LC_CTYPE=English_United States.1252
> >>>>>>>> [3] LC_MONETARY=English_United States.1252
> >>>>>>>> [4] LC_NUMERIC=C
> >>>>>>>> [5] LC_TIME=English_United States.1252
> >>>>>>>>
> >>>>>>>> attached base packages:
> >>>>>>>> [1] stats     graphics  grDevices utils     datasets methods base
> >>>>>>>>
> >>>>>>>> other attached packages:
> >>>>>>>> [1] Ecdat_0.2-3
> >>>>>>>>
> >>>>>>>> loaded via a namespace (and not attached):
> >>>>>>>> [1] tools_3.0.0
> >>>>>>>>
> >>>>>>>> ______________________________________________
> >>>>>>>> R-devel at r-project.org mailing list
> >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel


From spencer.graves at prodsyse.com  Wed May 22 23:40:50 2013
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Wed, 22 May 2013 14:40:50 -0700
Subject: [Rd] Objects created by more than one data call?
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C2F7DC7@PA-MBX01.na.tibco.com>
References: <519AADE9.2000505@structuremonitoring.com>
	<519B01D7.4060804@stats.ox.ac.uk> <519B848A.3020305@prodsyse.com>
	<519B88FB.2020706@stats.ox.ac.uk> <519B97EA.2060003@prodsyse.com>
	<519B9AD1.1000406@stats.ox.ac.uk> <519BC920.1070005@prodsyse.com>
	<E66794E69CFDE04D9A70842786030B931C2F786B@PA-MBX01.na.tibco.com>
	<519D2A05.8020805@prodsyse.com>
	<E66794E69CFDE04D9A70842786030B931C2F7DC7@PA-MBX01.na.tibco.com>
Message-ID: <519D3B62.9070201@prodsyse.com>

Dear Bill:


On 5/22/2013 2:12 PM, William Dunlap wrote:
> I used svn to copy the current version of Ecdat from Rforge to my PC
>    C:\temp\packages>svn checkout svn://r-forge.r-project.org/svnroot/ecdat/
> then fired up R to look at the rda files in it.
>
>> setwd("c:/temp/packages/Ecdat/ecdat/pkg/data")
>> read.dcf("../DESCRIPTION")[, c("Package","Version")]
> Package Version
> "Ecdat" "0.2-3"
>> dir.rda <- function(rdaFile) { e <- new.env() ; load(rdaFile, envir=e) ; objects(e, all=TRUE)}
>> dir.rda("VietNamH.rda")
> [1] "MedExp"
>> rdas <- dir(pattern="\\.rda$")
>> names(rdas) <- rdas
>> z <- lapply(rdas, dir.rda)
>> tab <- table(unlist(z))
>> tab[tab>1]
> Hstarts  MedExp
>        3       2
>> z[sapply(z, function(zi)"Hstarts" %in% zi)]
> $Hstarts.rda
> [1] "Hstarts"
>
> $Intratesm.rda
> [1] "Hstarts"
>
> $Intratesq.rda
> [1] "Hstarts"
>
>> z[sapply(z, function(zi)"MedExp" %in% zi)]
> $MedExp.rda
> [1] "MedExp"
>
> $VietNamH.rda
> [1] "MedExp"
>
> It looks some files don't contain what their names suggest:
>> dir.rda("VietNamH.rda")
> [1] "MedExp"
>
> The two versions of MedExp are quite different:
>> load("VietNamH.rda", envViet <- new.env(parent=emptyenv()))
>> load("MedExp.rda", envMed <- new.env(parent=emptyenv()))
>> objects(envViet)
> [1] "MedExp"
>> objects(envMed)
> [1] "MedExp"
>> all.equal(envViet$MedExp, envMed$MedExp)
>   [1] "Names: 11 string mismatches"
>   [2] "Length mismatch: comparison on first 11 components"
>   [3] "Component 1: 'current' is not a factor"
>   ...
> [18] "Component 10: Numeric: lengths (5999, 5574) differ"
> [19] "Component 11: 'current' is not a factor"


       Thanks very much.  Now I understand the problem.  For a solution, 
I need to consult with the package author (Yves Croissant;  I'm only the 
maintainer).


       However, your work at least makes it easy for me to describe the 
problem to him.


       Thanks again.
       Spencer

> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
>
>> -----Original Message-----
>> From: Spencer Graves [mailto:spencer.graves at prodsyse.com]
>> Sent: Wednesday, May 22, 2013 1:27 PM
>> To: William Dunlap
>> Cc: r-devel at r-project.org
>> Subject: Re: [Rd] Objects created by more than one data call?
>>
>> On 5/21/2013 3:03 PM, William Dunlap wrote:
>>> If you look at
>>>      data(package="Ecat")$results[,"Item"]
>>> you will see the items "Hstarts", "Hstarts (Intratesm)", and "Hstarts (Intratesq)"
>>> which I think means that the dataset Hstarts is found in 3 .rda files, "Hstarts.rda",
>>> "Intratesq.rda", and "Intratesm.rda".  There are duplicate, modulo (filename),
>>> items for "MedExp" as well.
>>
>>         Thanks for this.  I may get me closer, but I still don't see it:
>> (data(Intratesm)) imports only the object Intratesm, etc.  For more
>> details, see below.
>>
>>
>>         Any other suggestions?
>>
>>
>>         Thanks again,
>>         Spencer
>>
>>
>>   > Ecdat.data <- data(package="Ecdat")$results
>>   > (Hstarts2 <- grep('Hstarts', Ecdat.data[, 'Item']))
>> [1] 47 48 49
>>   > (MedExp2 <- grep('MedExp', Ecdat.data[, 'Item']))
>> [1] 67 68
>>   > Ecdat.data[Hstarts2, ]
>>        Package LibPath Item
>> [1,] "Ecdat" "C:/Users/sgraves/pgms/R/R-3.0.0/library" "Hstarts"
>> [2,] "Ecdat" "C:/Users/sgraves/pgms/R/R-3.0.0/library" "Hstarts (Intratesm)"
>> [3,] "Ecdat" "C:/Users/sgraves/pgms/R/R-3.0.0/library" "Hstarts (Intratesq)"
>>        Title
>> [1,] "Housing Starts"
>> [2,] "Housing Starts"
>> [3,] "Housing Starts"
>>   > Ecdat.data[MedExp2,]
>>        Package LibPath Item
>> [1,] "Ecdat" "C:/Users/sgraves/pgms/R/R-3.0.0/library" "MedExp"
>> [2,] "Ecdat" "C:/Users/sgraves/pgms/R/R-3.0.0/library" "MedExp (VietNamH)"
>>        Title
>> [1,] "Structure of Demand for Medical Care"
>> [2,] "Structure of Demand for Medical Care"
>>   > library(Ecdat)
>>   > (data(Intratesm))
>> [1] "Intratesm"
>>   > (data(Intratesq))
>> [1] "Intratesq"
>>
>>
>>> Bill Dunlap
>>> Spotfire, TIBCO Software
>>> wdunlap tibco.com
>>>
>>>
>>>> -----Original Message-----
>>>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On
>> Behalf
>>>> Of Spencer Graves
>>>> Sent: Tuesday, May 21, 2013 12:21 PM
>>>> To: Prof Brian Ripley
>>>> Cc: r-devel at r-project.org
>>>> Subject: Re: [Rd] Objects created by more than one data call?
>>>>
>>>> On 5/21/2013 9:03 AM, Prof Brian Ripley wrote:
>>>>> On 21/05/2013 16:51, Spencer Graves wrote:
>>>>>> On 5/21/2013 7:47 AM, Prof Brian Ripley wrote:
>>>>>>> On 21/05/2013 15:28, Spencer Graves wrote:
>>>>>>>> On 5/20/2013 10:10 PM, Prof Brian Ripley wrote:
>>>>>>>>> On 21/05/2013 00:12, Spencer Graves wrote:
>>>>>>>>>> Hello, All:
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>          If I use LazyData with the Ecdat package on R-Forge, "R CMD
>>>>>>>>>> check" reports "no visible binding for global variable
>>>>>>>>>> 'nonEnglishNames'", where 'nonEnglishNames' is a dataset in Ecdat
>>>>>>>>>> used
>>>>>>>>>> as the default argument for a function.  With LazyData, that NOTE
>>>>>>>>>> disappears.  However, then I get, "Warning: objects 'Hstarts',
>>>>>>>>>> 'Hstarts', 'MedExp' are created by more than one data call".
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>          What do you suggest I do to fix this problem?
>>>>>>>>> Not create the objects in more than one data() call.
>>>>>>>>>
>>>>>>>>> Check what each of your data() calls produces.
>>>>>>>>          Thanks.  How do I do that?
>>>>>>> Call data() on each in turn, and see what files get added to an empty
>>>>>>> workspace.
>>>>>> Like the following?
>>>>> You missed the 'empty'.  Look at tools:::data2LazyLoadDB to see how
>>>>> this is checked.
>>>>          Thanks for the suggestion.  Unfortunately, I tried that function,
>>>> including stepping through it line by line, fixing references to other
>>>> functions not exported from tools, without enlightenment;  see below.
>>>>
>>>>
>>>>          Thanks again,
>>>>          Spencer
>>>>
>>>>
>>>>    > lib.loc = NULL
>>>>    > package='Ecdat'
>>>>    > pkgpath <- find.package(package, lib.loc, quiet = TRUE)
>>>>    > pkgpath
>>>> [1] "C:/Users/sgraves/pgms/R/R-3.0.0/library/Ecdat"
>>>>    > dataDir <- file.path(pkgpath, "data")
>>>>    > dataDir
>>>> [1] "C:/Users/sgraves/pgms/R/R-3.0.0/library/Ecdat/data"
>>>>    > enc <- tools:::.read_description(file.path(pkgpath,
>>>> "DESCRIPTION"))["Encoding"]
>>>>    > enc
>>>> <NA>
>>>>      NA
>>>>    > if (!is.na(enc)) {
>>>> +         op <- options(encoding = enc)
>>>> +         on.exit(options(encoding = op[[1L]]))
>>>> +     }
>>>>    > file_test("-d", dataDir)
>>>> [1] TRUE
>>>>    > file.path(dataDir, "Rdata.rds")
>>>> [1] "C:/Users/sgraves/pgms/R/R-3.0.0/library/Ecdat/data/Rdata.rds"
>>>>    > (file.exists(file.path(dataDir, "Rdata.rds")) &&
>>>> file.exists(file.path(dataDir,
>>>> +             paste(package, "rdx", sep = "."))) &&
>>>> file.exists(file.path(dataDir,
>>>> +             paste(package, "rdb", sep = "."))))
>>>> [1] FALSE
>>>>    > file.exists(file.path(dataDir,
>>>> +             paste(package, "rdx", sep = ".")))
>>>> [1] FALSE
>>>>    > file.path(dataDir,
>>>> +             paste(package, "rdx", sep = "."))
>>>> [1] "C:/Users/sgraves/pgms/R/R-3.0.0/library/Ecdat/data/Ecdat.rdx"
>>>>    > dataEnv <- new.env(hash = TRUE)
>>>>    > tmpEnv <- new.env()
>>>>    > f0 <- files <- list_files_with_type(dataDir, "data")
>>>> Error: could not find function "list_files_with_type"
>>>>    > f0 <- files <- tools:::list_files_with_type(dataDir, "data")
>>>>    > files <- unique(basename(file_path_sans_ext(files,
>>>> +                 TRUE)))
>>>> Error in basename(file_path_sans_ext(files, TRUE)) :
>>>>      could not find function "file_path_sans_ext"
>>>>    > files <- unique(basename(tools:::file_path_sans_ext(files,
>>>> +                 TRUE)))
>>>>    >             dlist <- vector("list", length(files))
>>>>    > files
>>>> character(0)
>>>>    >  names(dlist) <- files
>>>>    >             loaded <- character(0L)
>>>>    > loaded
>>>> character(0)
>>>>    > for (f in files) {
>>>> +                 utils::data(list = f, package = package, lib.loc =
>>>> lib.loc,
>>>> +                   envir = dataEnv)
>>>> +                 utils::data(list = f, package = package, lib.loc =
>>>> lib.loc,
>>>> +                   envir = tmpEnv)
>>>> +                 tmp <- ls(envir = tmpEnv, all.names = TRUE)
>>>> +                 rm(list = tmp, envir = tmpEnv)
>>>> +                 dlist[[f]] <- tmp
>>>> +                 loaded <- c(loaded, tmp)
>>>> +             }
>>>>    >             dup <- duplicated(loaded)
>>>>    > dup
>>>> logical(0)
>>>>    > if (any(dup))
>>>> +                 warning(sprintf(ngettext(sum(dup), "object %s is
>>>> created by more than one data call",
>>>> +                   "objects %s are created by more than one data call"),
>>>> +                   paste(sQuote(loaded[dup]), collapse = ", ")),
>>>> +                   call. = FALSE, domain = NA)
>>>>    >             if (length(loaded)) {
>>>> +                 dbbase <- file.path(dataDir, "Rdata")
>>>> +                 makeLazyLoadDB(dataEnv, dbbase, compress = compress)
>>>> +                 saveRDS(dlist, file.path(dataDir, "Rdata.rds"),
>>>> +                   compress = compress)
>>>> +                 unlink(f0)
>>>> +                 if (file.exists(file.path(dataDir, "filelist")))
>>>> +                   unlink(file.path(dataDir, c("filelist", "Rdata.zip")))
>>>> +             }
>>>>    >
>>>>
>>>>>>    > library(Ecdat)
>>>>>>    > objects()
>>>>>> character(0)
>>>>>>    > (data(Hstarts))
>>>>>> [1] "Hstarts"
>>>>>>    > (data(MedExp))
>>>>>> [1] "MedExp"
>>>>>>    > objects()
>>>>>> [1] "Hstarts" "MedExp"
>>>>>>    > sessionInfo()
>>>>>> R version 3.0.0 (2013-04-03)
>>>>>> Platform: i386-w64-mingw32/i386 (32-bit)
>>>>>>
>>>>>> locale:
>>>>>> [1] LC_COLLATE=English_United States.1252
>>>>>> [2] LC_CTYPE=English_United States.1252
>>>>>> [3] LC_MONETARY=English_United States.1252
>>>>>> [4] LC_NUMERIC=C
>>>>>> [5] LC_TIME=English_United States.1252
>>>>>>
>>>>>> attached base packages:
>>>>>> [1] stats     graphics  grDevices utils     datasets  methods base
>>>>>>
>>>>>> other attached packages:
>>>>>> [1] Ecdat_0.2-3
>>>>>>
>>>>>> loaded via a namespace (and not attached):
>>>>>> [1] tools_3.0.0
>>>>>>
>>>>>>
>>>>>>          Thanks,
>>>>>>          Spencer
>>>>>>
>>>>>>>>          In the "man" directory, I just did "grep 'data(MedExp' *.Rd",
>>>>>>>> which identified only "MedExp.Rd:\usage{data(MedExp)}"; "grep
>>>>>>>> 'data(Hstarts *.Rd" similarly returned only
>>>>>>>> "Hstarts.Rd:\usage(data(Hstarts)}".
>>>>>>>>
>>>>>>>>
>>>>>>>>          Thanks again for the reply.
>>>>>>>>          Spencer
>>>>>>>>>>          Thanks,
>>>>>>>>>>          Spencer Graves
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>    > sessionInfo()
>>>>>>>>>> R version 3.0.0 (2013-04-03)
>>>>>>>>>> Platform: i386-w64-mingw32/i386 (32-bit)
>>>>>>>>>>
>>>>>>>>>> locale:
>>>>>>>>>> [1] LC_COLLATE=English_United States.1252
>>>>>>>>>> [2] LC_CTYPE=English_United States.1252
>>>>>>>>>> [3] LC_MONETARY=English_United States.1252
>>>>>>>>>> [4] LC_NUMERIC=C
>>>>>>>>>> [5] LC_TIME=English_United States.1252
>>>>>>>>>>
>>>>>>>>>> attached base packages:
>>>>>>>>>> [1] stats     graphics  grDevices utils     datasets methods base
>>>>>>>>>>
>>>>>>>>>> other attached packages:
>>>>>>>>>> [1] Ecdat_0.2-3
>>>>>>>>>>
>>>>>>>>>> loaded via a namespace (and not attached):
>>>>>>>>>> [1] tools_3.0.0
>>>>>>>>>>
>>>>>>>>>> ______________________________________________
>>>>>>>>>> R-devel at r-project.org mailing list
>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel


From rje42 at cam.ac.uk  Thu May 23 01:15:48 2013
From: rje42 at cam.ac.uk (Robin Evans)
Date: Thu, 23 May 2013 00:15:48 +0100
Subject: [Rd] Inconsistent results from .C()
In-Reply-To: <CAAjYCKuRL4fa-SP6dmXFeYJiOcHcTX59KGuSs=9U166bY56BkA@mail.gmail.com>
References: <CAAjYCKuW7bOzQK_3+_BfJGOgPt-MqW-MQrv9P=Nkf0x0zg9uLg@mail.gmail.com>
	<CAAjYCKuDOEXSHgPMzXXyQtb_Jr7EU=iYdQ2nT8h_sOP7AO1W0A@mail.gmail.com>
	<CAAmySGNr1RYDmMAMpQcMXEyrOXifPtN41JwwbfZ=iuVMt9YQ2g@mail.gmail.com>
	<CAAjYCKuRL4fa-SP6dmXFeYJiOcHcTX59KGuSs=9U166bY56BkA@mail.gmail.com>
Message-ID: <CAAjYCKuBLK1-bzTATrs2eHcTACLGwmtVUfZap-D0Gy6Jg+r40g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130523/842e49fd/attachment.pl>

From wdunlap at tibco.com  Thu May 23 02:18:54 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 23 May 2013 00:18:54 +0000
Subject: [Rd] Inconsistent results from .C()
In-Reply-To: <CAAjYCKuBLK1-bzTATrs2eHcTACLGwmtVUfZap-D0Gy6Jg+r40g@mail.gmail.com>
References: <CAAjYCKuW7bOzQK_3+_BfJGOgPt-MqW-MQrv9P=Nkf0x0zg9uLg@mail.gmail.com>
	<CAAjYCKuDOEXSHgPMzXXyQtb_Jr7EU=iYdQ2nT8h_sOP7AO1W0A@mail.gmail.com>
	<CAAmySGNr1RYDmMAMpQcMXEyrOXifPtN41JwwbfZ=iuVMt9YQ2g@mail.gmail.com>
	<CAAjYCKuRL4fa-SP6dmXFeYJiOcHcTX59KGuSs=9U166bY56BkA@mail.gmail.com>
	<CAAjYCKuBLK1-bzTATrs2eHcTACLGwmtVUfZap-D0Gy6Jg+r40g@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C2F7EBA@PA-MBX01.na.tibco.com>

Had you tried using the new-to-3.0.0 options(CBoundCheck=TRUE)?

    [from the NEWS file]
    There is a new option, options(CBoundsCheck=), which controls how .C()
    and .Fortran() pass arguments to compiled code. If true (which can be
    enabled by setting the environment variable R_C_BOUNDS_CHECK to yes),
    raw, integer, double and complex arguments are always copied, and checked
    for writing off either end of the array on return from the compiled code
    (when a second copy is made). This also checks individual elements of character
    vectors passed to .C().

valgrind helps find memory misuse also.

When you write on memory that you didn't allocate, expect to get mystifying
behavior.  Nonrepeatable results are a sign of memory misuse.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf
> Of Robin Evans
> Sent: Wednesday, May 22, 2013 4:16 PM
> To: R Devel List
> Subject: Re: [Rd] Inconsistent results from .C()
> 
> Update: I did eventually discover an error in the C code which is probably
> ultimately responsible for the bug (the variable eff_size is allowed to get
> too large, and overrun the end of lev2[]).  However the behaviour of R (or
> Rstudio) in response to this is still somewhat mystifying to me!
> 
> Robin
> 
> On 21 May 2013 14:10, Robin Evans <rje42 at cam.ac.uk> wrote:
> 
> > Sure!  C code is below if it helps.  The gist is that the function
> > oneMargin forms two matrices M and C, mostly by repeatedly taking
> > Kronecker products.
> >
> > Robin
> >
> > void kronecker (int *A, int *B, int *dima, int *dimb, int *C) {
> >   int k = 0;
> >   int i1,i2,j1,j2;
> >
> >     for (i2 = 0; i2 < dima[1]; i2++) {
> >     for (j2 = 0; j2 < dimb[1]; j2++) {
> >     for (i1 = 0; i1 < dima[0]; i1++) {
> >     for (j1 = 0; j1 < dimb[0]; j1++) {
> >       C[k] = A[i1 + dima[0]*i2]*B[j1 + dimb[0]*j2];
> >       k++;
> >     }}}}
> > }
> >
> > void iterate (int *x, int *lev) {
> >   bool ok = FALSE;
> >   int i=0;
> >
> >   do {
> >     if(x[i] < lev[i]-1) {
> >       x[i]++;
> >       ok = TRUE;
> >     }
> >     else {
> >       x[i] = 0;
> >     }
> >     i++;
> >   }
> >   while (!ok);
> > }
> >
> > void oneMargin(int *Mar, int *Eff, int *neff, int *lev, int *nvar, int
> > *M, int *C) {
> >
> >   int *M2, *mult, *Cj, *Cj2;
> >   int i,j=1,k,l,m;
> >
> >   /* determine size of M to output */
> >   for (i = 0; i < nvar[0]; i++) {
> >     j *= (Mar[i] == 1 ? lev[i]*lev[i] : lev[i]);
> >   }
> >   M2 = malloc(sizeof(int)*j);
> >   mult = malloc(sizeof(int)*j);
> >
> >   M[0] = 1;
> >   int M_size[2] = {1,1}, mult_size[2], Cj_size[2], C_size[2] = {0,0};
> >
> >   for (i = nvar[0]-1; i >= 0; i--) {
> >     if (Mar[i] == 1) {
> >       for (j = 0; j < lev[i]*lev[i]; j++) {
> >         mult[j] =  ((j % (lev[i]+1)) == 0) ? 1 : 0;
> >       }
> >       mult_size[0] = mult_size[1] = lev[i];
> >     }
> >     else {
> >       for (j = 0; j < lev[i]; j++) {
> >         mult[j] =  1;
> >       }
> >       mult_size[0] = 1;
> >       mult_size[1] = lev[i];
> >     }
> >
> >     kronecker(M, mult, M_size, mult_size, M2);
> >     M_size[0] *= mult_size[0];
> >     M_size[1] *= mult_size[1];
> >
> >     /* copy M2 over to M */
> >     for (j=0; j < M_size[0]*M_size[1]; j++) {
> >       M[j] = M2[j];
> >     }
> >   }
> >
> >   free(M2);
> >
> >   /* Create C matrix */
> >   int index[nvar[0]];
> >   int prod;
> >   int eff_size = 0;
> >   /*swapped = 0; */
> >   mult_size[0] = 1;
> >
> >   C_size[0] = 1;
> >   for (j = 0; j < nvar[0]; j++) {
> >     C_size[0] *= (Mar[j] == 1 ? lev[j] : 1);
> >   }
> >
> >   Cj = malloc(sizeof(int)*C_size[0]);
> >   Cj2 = malloc(sizeof(int)*C_size[0]);
> >   int *lev2;
> >   lev2 = malloc(sizeof(int)*nvar[0]);
> >
> >   /* loop over effects */
> >   for (i = 0; i < neff[0]; i++) {
> >     prod = 1;
> >     for (j = 0; j < nvar[0]; j++) {
> >       if (Eff[j + i*nvar[0]]) {
> >         prod *= lev[j]-1;
> >         lev2[eff_size] = lev[j]-1;
> >         index[eff_size] = 0;
> >         eff_size++;
> >        }
> >     }
> >
> >     /* loop over states of effect (excluding corner points) */
> >     for (j = 0; j < prod; j++) {
> >       Cj[0] = 1;
> >       Cj_size[0] = Cj_size[1] = 1;
> >
> >       k = eff_size;
> >       /* loop over variables */
> >       for (l = nvar[0]-1; l >= 0; l--) {
> >         /* skip variables not in margin */
> >         if (Mar[l] == 0) continue;
> >         mult_size[1] = lev[l];
> >
> >         /* kronecker factor depends on whether or not variable is in
> > effect */
> >         if (Eff[i*nvar[0]+l] == 0) {
> >           /* for variables not in effect, just repeat matrix */
> >           for (m = 0; m < lev[l]; m++) {
> >             mult[m] = 1;
> >           }
> >         }
> >         else {
> >           /* otherwise multiply based on state */
> >           k--;
> >           for (m = 0; m < lev[l]; m++) {
> >             mult[m] = (m == index[k]) ? lev[l] - 1 : -1;
> >           }
> >         }
> >         kronecker(Cj, mult, Cj_size, mult_size, Cj2);
> >
> >         Cj_size[1] *= mult_size[1];
> >
> >         /* copy Cj2 over to Cj */
> >         for (k=0; k < Cj_size[0]*Cj_size[1]; k++) {
> >           Cj[k] = Cj2[k];
> >         }
> >         if (Cj_size[0]*Cj_size[1] > C_size[0]) Rprintf("pointer screwup");
> >       }
> >
> >       /* copy row over to C */
> >       for (m = 0; m < C_size[0]; m++) C[C_size[0]*C_size[1]+m] = Cj[m];
> >       C_size[1] += 1;
> >       iterate(index, lev2);
> >     }
> >   }
> >
> >   free(lev2);
> >   free(Cj);
> >   free(Cj2);
> >   free(mult);
> > }
> >
> >
> > On 21 May 2013 14:04, R. Michael Weylandt <michael.weylandt at gmail.com>
> > wrote:
> > >
> > >  It might also help if you can point us to the C code to help debug.
> > >
> > > MW
> > >
> > > On Tue, May 21, 2013 at 10:53 AM, Robin Evans <rje42 at cam.ac.uk> wrote:
> > > > I should add to this that I'm running on Scientific Linux 6.  I later
> > > > noticed that the bug only seems to occur when I run the code from
> > Rstudio,
> > > > and not if I use the terminal directly, so this may be the key to the
> > > > problem.
> > > >
> > > > Robin
> > > >
> > > > On 20 May 2013 16:12, Robin Evans <rje42 at cam.ac.uk> wrote:
> > > >
> > > >> Hello,
> > > >>
> > > >> I've run into a problem which is both maddening and rather hard to
> > > >> replicate, therefore I wondered if someone might know of a plausible
> > > >> explanation for it.  I couldn't find anything in the archives, though
> > > >> maybe I'm searching for the wrong thing.
> > > >>
> > > >> I'm calling some C code using .C, and get the vector I'm interested in
> > > >> back as the 7th location in the returned list.  However I find that if
> > > >> I try to inspect the contents of this entry in the list in some ways,
> > > >> I get one answer, and if I look at it in others I get a different
> > > >> answer.  It's quite possible that there's something wrong with the C
> > > >> code, but this doesn't seem to explain why this phenomenon would occur
> > > >> in R.
> > > >>
> > > >> The problem does not always occur - I have to run the code a few times
> > > >> and then call the console when it does, but the commands below show
> > > >> what can happen when it does.  I apologise for not being able to get a
> > > >> cleaner example.  Full code and output is below, but here is a
> > > >> stylised version:
> > > >>
> > > >> The following all give one answer (which is the wrong answer as far as
> > > >> I'm concerned) :
> > > >>  * printing the whole list :
> > > >>           .C(...)     # and looking at the 7th entry
> > > >>  * applying c() to the 7th element of the list
> > > >>           c(.C(...)[[7]])
> > > >>  * assigning the 7th element to a vector:
> > > >>           x = .C(...)[[7]];
> > > >>           x
> > > >>
> > > >> these give a different answer (which is the answer I would hope the C
> > > >> code returns):
> > > >>  * using dput on the 7th entry:
> > > >>           dput(.C(...)[[7]])
> > > >>  * applying c() and then dput()
> > > >>           dput(c(.C(...)[[7]]))
> > > >>  * just printing the 7th entry of the list
> > > >>           .C(...)[[7]]
> > > >>
> > > >> The answers are consistent in the sense that I always get the same
> > > >> answers from running the same command in the console.  I have tried
> > > >> inspecting the returned objects to see if the objects are somehow of a
> > > >> different class than I expect, or are just being printed oddly, but
> > > >> have not found anything untoward.
> > > >>
> > > >> Any suggestions would be much appreciated!
> > > >>
> > > >> Regards,
> > > >>
> > > >> Robin
> > > >>
> > > >>
> > > >> # THESE COMMANDS GIVE ONE ANSWER
> > > >> # [the correct answer always begins with 1, the incorrect with -1]
> > > >>
> > > >> > .C("oneMargin", c(1L,1L,1L,1L,1L), c(1L,1L,1L,1L,1L), 1L,
> > > >> c(2L,2L,2L,2L,2L), 5L, ptr1, ptr2)[[7]]
> > > >> [1]  1 -1 -1  1 -1  1  1 -1 -1  1  1 -1  1 -1 -1  1 -1  1  1 -1  1 -1
> > > >> -1  1  1 -1 -1  1 -1  1  1 -1
> > > >>
> > > >> > dput(.C("oneMargin", c(1L,1L,1L,1L,1L), c(1L,1L,1L,1L,1L), 1L,
> > > >> c(2L,2L,2L,2L,2L), 5L, ptr1, ptr2)[[7]])
> > > >> c(1L, -1L, -1L, 1L, -1L, 1L, 1L, -1L, -1L, 1L, 1L, -1L, 1L, -1L,
> > > >> -1L, 1L, -1L, 1L, 1L, -1L, 1L, -1L, -1L, 1L, 1L, -1L, -1L, 1L,
> > > >> -1L, 1L, 1L, -1L)
> > > >>
> > > >> > x=dput(c(.C("oneMargin", c(1L,1L,1L,1L,1L), c(1L,1L,1L,1L,1L), 1L,
> > > >> c(2L,2L,2L,2L,2L), 5L, ptr1, ptr2)[[7]]))
> > > >> c(1L, -1L, -1L, 1L, -1L, 1L, 1L, -1L, -1L, 1L, 1L, -1L, 1L, -1L,
> > > >>   -1L, 1L, -1L, 1L, 1L, -1L, 1L, -1L, -1L, 1L, 1L, -1L, -1L, 1L,
> > > >>   -1L, 1L, 1L, -1L)
> > > >> > x
> > > >> [1]  1 -1 -1  1 -1  1  1 -1 -1  1  1 -1  1 -1 -1  1 -1  1  1 -1  1 -1
> > > >> -1  1  1 -1 -1  1 -1  1  1 -1
> > > >>
> > > >> # THESE ALL GIVE A DIFFERENT ONE!
> > > >>
> > > >> > .C("oneMargin", c(1L,1L,1L,1L,1L), c(1L,1L,1L,1L,1L), 1L,
> > > >> c(2L,2L,2L,2L,2L), 5L, ptr1, ptr2)
> > > >>
> > > >> # (OTHER ELEMENTS OF LIST REMOVED)
> > > >> [[7]]
> > > >> [1] -1 -1  1  1  1  1 -1 -1  1  1 -1 -1 -1 -1  1  1  1  1 -1 -1 -1 -1
> > > >> 1  1 -1 -1  1  1  1  1 -1 -1
> > > >>
> > > >> > c(.C("oneMargin", c(1L,1L,1L,1L,1L), c(1L,1L,1L,1L,1L), 1L,
> > > >> c(2L,2L,2L,2L,2L), 5L, ptr1, ptr2)[[7]])
> > > >> [1] -1 -1  1  1  1  1 -1 -1  1  1 -1 -1 -1 -1  1  1  1  1 -1 -1 -1 -1
> > > >> 1  1 -1 -1  1  1  1  1 -1 -1
> > > >> > x = .C("oneMargin", c(1L,1L,1L,1L,1L), c(1L,1L,1L,1L,1L), 1L,
> > > >> c(2L,2L,2L,2L,2L), 5L, ptr1, ptr2)[[7]]
> > > >> > x
> > > >> [1] -1 -1  1  1  1  1 -1 -1  1  1 -1 -1 -1 -1  1  1  1  1 -1 -1 -1 -1
> > > >> 1  1 -1 -1  1  1  1  1 -1 -1
> > > >>
> > > >>
> > > >> --
> > > >> Robin Evans
> > > >> Statistical Laboratory
> > > >> University of Cambridge
> > > >> blog: itsastatlife.blogspot.com
> > > >> web: www.statslab.cam.ac.uk/~rje42
> > > >>
> > > >> Causal Inference Workshop July 15th:
> > > >> http://www.statslab.cam.ac.uk/~rje42/uai13/main.htm
> > > >>
> > > >
> > > >
> > > >
> > > > --
> > > > Robin Evans
> > > > Statistical Laboratory
> > > > University of Cambridge
> > > > blog: itsastatlife.blogspot.com
> > > > web: www.statslab.cam.ac.uk/~rje42 <
> > http://www.stat.washington.edu/~rje42>
> > > >
> > > > Causal Inference Workshop July 15th:
> > > > http://www.statslab.cam.ac.uk/~rje42/uai13/main.htm
> > > >
> > > >         [[alternative HTML version deleted]]
> > > >
> > > > ______________________________________________
> > > > R-devel at r-project.org mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Thu May 23 08:08:17 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 23 May 2013 07:08:17 +0100
Subject: [Rd] Inconsistent results from .C()
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C2F7EBA@PA-MBX01.na.tibco.com>
References: <CAAjYCKuW7bOzQK_3+_BfJGOgPt-MqW-MQrv9P=Nkf0x0zg9uLg@mail.gmail.com>
	<CAAjYCKuDOEXSHgPMzXXyQtb_Jr7EU=iYdQ2nT8h_sOP7AO1W0A@mail.gmail.com>
	<CAAmySGNr1RYDmMAMpQcMXEyrOXifPtN41JwwbfZ=iuVMt9YQ2g@mail.gmail.com>
	<CAAjYCKuRL4fa-SP6dmXFeYJiOcHcTX59KGuSs=9U166bY56BkA@mail.gmail.com>
	<CAAjYCKuBLK1-bzTATrs2eHcTACLGwmtVUfZap-D0Gy6Jg+r40g@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B931C2F7EBA@PA-MBX01.na.tibco.com>
Message-ID: <519DB251.1020703@stats.ox.ac.uk>

lev2 is malloc-ed in the code you supplied.  The new option Bill refers 
to is about input variables in .C, i.e. lev and not lev2.  Other array 
overruns can be found by other tools: Bill mentioned valgrind, and 
AddressSanitizer finds a different set of overruns.  See 
http://cran.r-project.org/doc/manuals/r-release/R-exts.html#Using-gctorture-and-memory-access 
.

On 23/05/2013 01:18, William Dunlap wrote:
> Had you tried using the new-to-3.0.0 options(CBoundCheck=TRUE)?
>
>      [from the NEWS file]
>      There is a new option, options(CBoundsCheck=), which controls how .C()
>      and .Fortran() pass arguments to compiled code. If true (which can be
>      enabled by setting the environment variable R_C_BOUNDS_CHECK to yes),
>      raw, integer, double and complex arguments are always copied, and checked
>      for writing off either end of the array on return from the compiled code
>      (when a second copy is made). This also checks individual elements of character
>      vectors passed to .C().
>
> valgrind helps find memory misuse also.
>
> When you write on memory that you didn't allocate, expect to get mystifying
> behavior.  Nonrepeatable results are a sign of memory misuse.
>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
>
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf
>> Of Robin Evans
>> Sent: Wednesday, May 22, 2013 4:16 PM
>> To: R Devel List
>> Subject: Re: [Rd] Inconsistent results from .C()
>>
>> Update: I did eventually discover an error in the C code which is probably
>> ultimately responsible for the bug (the variable eff_size is allowed to get
>> too large, and overrun the end of lev2[]).  However the behaviour of R (or
>> Rstudio) in response to this is still somewhat mystifying to me!
>>
>> Robin
>>
>> On 21 May 2013 14:10, Robin Evans <rje42 at cam.ac.uk> wrote:
>>
>>> Sure!  C code is below if it helps.  The gist is that the function
>>> oneMargin forms two matrices M and C, mostly by repeatedly taking
>>> Kronecker products.
>>>
>>> Robin
>>>
>>> void kronecker (int *A, int *B, int *dima, int *dimb, int *C) {
>>>    int k = 0;
>>>    int i1,i2,j1,j2;
>>>
>>>      for (i2 = 0; i2 < dima[1]; i2++) {
>>>      for (j2 = 0; j2 < dimb[1]; j2++) {
>>>      for (i1 = 0; i1 < dima[0]; i1++) {
>>>      for (j1 = 0; j1 < dimb[0]; j1++) {
>>>        C[k] = A[i1 + dima[0]*i2]*B[j1 + dimb[0]*j2];
>>>        k++;
>>>      }}}}
>>> }
>>>
>>> void iterate (int *x, int *lev) {
>>>    bool ok = FALSE;
>>>    int i=0;
>>>
>>>    do {
>>>      if(x[i] < lev[i]-1) {
>>>        x[i]++;
>>>        ok = TRUE;
>>>      }
>>>      else {
>>>        x[i] = 0;
>>>      }
>>>      i++;
>>>    }
>>>    while (!ok);
>>> }
>>>
>>> void oneMargin(int *Mar, int *Eff, int *neff, int *lev, int *nvar, int
>>> *M, int *C) {
>>>
>>>    int *M2, *mult, *Cj, *Cj2;
>>>    int i,j=1,k,l,m;
>>>
>>>    /* determine size of M to output */
>>>    for (i = 0; i < nvar[0]; i++) {
>>>      j *= (Mar[i] == 1 ? lev[i]*lev[i] : lev[i]);
>>>    }
>>>    M2 = malloc(sizeof(int)*j);
>>>    mult = malloc(sizeof(int)*j);
>>>
>>>    M[0] = 1;
>>>    int M_size[2] = {1,1}, mult_size[2], Cj_size[2], C_size[2] = {0,0};
>>>
>>>    for (i = nvar[0]-1; i >= 0; i--) {
>>>      if (Mar[i] == 1) {
>>>        for (j = 0; j < lev[i]*lev[i]; j++) {
>>>          mult[j] =  ((j % (lev[i]+1)) == 0) ? 1 : 0;
>>>        }
>>>        mult_size[0] = mult_size[1] = lev[i];
>>>      }
>>>      else {
>>>        for (j = 0; j < lev[i]; j++) {
>>>          mult[j] =  1;
>>>        }
>>>        mult_size[0] = 1;
>>>        mult_size[1] = lev[i];
>>>      }
>>>
>>>      kronecker(M, mult, M_size, mult_size, M2);
>>>      M_size[0] *= mult_size[0];
>>>      M_size[1] *= mult_size[1];
>>>
>>>      /* copy M2 over to M */
>>>      for (j=0; j < M_size[0]*M_size[1]; j++) {
>>>        M[j] = M2[j];
>>>      }
>>>    }
>>>
>>>    free(M2);
>>>
>>>    /* Create C matrix */
>>>    int index[nvar[0]];
>>>    int prod;
>>>    int eff_size = 0;
>>>    /*swapped = 0; */
>>>    mult_size[0] = 1;
>>>
>>>    C_size[0] = 1;
>>>    for (j = 0; j < nvar[0]; j++) {
>>>      C_size[0] *= (Mar[j] == 1 ? lev[j] : 1);
>>>    }
>>>
>>>    Cj = malloc(sizeof(int)*C_size[0]);
>>>    Cj2 = malloc(sizeof(int)*C_size[0]);
>>>    int *lev2;
>>>    lev2 = malloc(sizeof(int)*nvar[0]);
>>>
>>>    /* loop over effects */
>>>    for (i = 0; i < neff[0]; i++) {
>>>      prod = 1;
>>>      for (j = 0; j < nvar[0]; j++) {
>>>        if (Eff[j + i*nvar[0]]) {
>>>          prod *= lev[j]-1;
>>>          lev2[eff_size] = lev[j]-1;
>>>          index[eff_size] = 0;
>>>          eff_size++;
>>>         }
>>>      }
>>>
>>>      /* loop over states of effect (excluding corner points) */
>>>      for (j = 0; j < prod; j++) {
>>>        Cj[0] = 1;
>>>        Cj_size[0] = Cj_size[1] = 1;
>>>
>>>        k = eff_size;
>>>        /* loop over variables */
>>>        for (l = nvar[0]-1; l >= 0; l--) {
>>>          /* skip variables not in margin */
>>>          if (Mar[l] == 0) continue;
>>>          mult_size[1] = lev[l];
>>>
>>>          /* kronecker factor depends on whether or not variable is in
>>> effect */
>>>          if (Eff[i*nvar[0]+l] == 0) {
>>>            /* for variables not in effect, just repeat matrix */
>>>            for (m = 0; m < lev[l]; m++) {
>>>              mult[m] = 1;
>>>            }
>>>          }
>>>          else {
>>>            /* otherwise multiply based on state */
>>>            k--;
>>>            for (m = 0; m < lev[l]; m++) {
>>>              mult[m] = (m == index[k]) ? lev[l] - 1 : -1;
>>>            }
>>>          }
>>>          kronecker(Cj, mult, Cj_size, mult_size, Cj2);
>>>
>>>          Cj_size[1] *= mult_size[1];
>>>
>>>          /* copy Cj2 over to Cj */
>>>          for (k=0; k < Cj_size[0]*Cj_size[1]; k++) {
>>>            Cj[k] = Cj2[k];
>>>          }
>>>          if (Cj_size[0]*Cj_size[1] > C_size[0]) Rprintf("pointer screwup");
>>>        }
>>>
>>>        /* copy row over to C */
>>>        for (m = 0; m < C_size[0]; m++) C[C_size[0]*C_size[1]+m] = Cj[m];
>>>        C_size[1] += 1;
>>>        iterate(index, lev2);
>>>      }
>>>    }
>>>
>>>    free(lev2);
>>>    free(Cj);
>>>    free(Cj2);
>>>    free(mult);
>>> }
>>>
>>>
>>> On 21 May 2013 14:04, R. Michael Weylandt <michael.weylandt at gmail.com>
>>> wrote:
>>>>
>>>>   It might also help if you can point us to the C code to help debug.
>>>>
>>>> MW
>>>>
>>>> On Tue, May 21, 2013 at 10:53 AM, Robin Evans <rje42 at cam.ac.uk> wrote:
>>>>> I should add to this that I'm running on Scientific Linux 6.  I later
>>>>> noticed that the bug only seems to occur when I run the code from
>>> Rstudio,
>>>>> and not if I use the terminal directly, so this may be the key to the
>>>>> problem.
>>>>>
>>>>> Robin
>>>>>
>>>>> On 20 May 2013 16:12, Robin Evans <rje42 at cam.ac.uk> wrote:
>>>>>
>>>>>> Hello,
>>>>>>
>>>>>> I've run into a problem which is both maddening and rather hard to
>>>>>> replicate, therefore I wondered if someone might know of a plausible
>>>>>> explanation for it.  I couldn't find anything in the archives, though
>>>>>> maybe I'm searching for the wrong thing.
>>>>>>
>>>>>> I'm calling some C code using .C, and get the vector I'm interested in
>>>>>> back as the 7th location in the returned list.  However I find that if
>>>>>> I try to inspect the contents of this entry in the list in some ways,
>>>>>> I get one answer, and if I look at it in others I get a different
>>>>>> answer.  It's quite possible that there's something wrong with the C
>>>>>> code, but this doesn't seem to explain why this phenomenon would occur
>>>>>> in R.
>>>>>>
>>>>>> The problem does not always occur - I have to run the code a few times
>>>>>> and then call the console when it does, but the commands below show
>>>>>> what can happen when it does.  I apologise for not being able to get a
>>>>>> cleaner example.  Full code and output is below, but here is a
>>>>>> stylised version:
>>>>>>
>>>>>> The following all give one answer (which is the wrong answer as far as
>>>>>> I'm concerned) :
>>>>>>   * printing the whole list :
>>>>>>            .C(...)     # and looking at the 7th entry
>>>>>>   * applying c() to the 7th element of the list
>>>>>>            c(.C(...)[[7]])
>>>>>>   * assigning the 7th element to a vector:
>>>>>>            x = .C(...)[[7]];
>>>>>>            x
>>>>>>
>>>>>> these give a different answer (which is the answer I would hope the C
>>>>>> code returns):
>>>>>>   * using dput on the 7th entry:
>>>>>>            dput(.C(...)[[7]])
>>>>>>   * applying c() and then dput()
>>>>>>            dput(c(.C(...)[[7]]))
>>>>>>   * just printing the 7th entry of the list
>>>>>>            .C(...)[[7]]
>>>>>>
>>>>>> The answers are consistent in the sense that I always get the same
>>>>>> answers from running the same command in the console.  I have tried
>>>>>> inspecting the returned objects to see if the objects are somehow of a
>>>>>> different class than I expect, or are just being printed oddly, but
>>>>>> have not found anything untoward.
>>>>>>
>>>>>> Any suggestions would be much appreciated!
>>>>>>
>>>>>> Regards,
>>>>>>
>>>>>> Robin
>>>>>>
>>>>>>
>>>>>> # THESE COMMANDS GIVE ONE ANSWER
>>>>>> # [the correct answer always begins with 1, the incorrect with -1]
>>>>>>
>>>>>>> .C("oneMargin", c(1L,1L,1L,1L,1L), c(1L,1L,1L,1L,1L), 1L,
>>>>>> c(2L,2L,2L,2L,2L), 5L, ptr1, ptr2)[[7]]
>>>>>> [1]  1 -1 -1  1 -1  1  1 -1 -1  1  1 -1  1 -1 -1  1 -1  1  1 -1  1 -1
>>>>>> -1  1  1 -1 -1  1 -1  1  1 -1
>>>>>>
>>>>>>> dput(.C("oneMargin", c(1L,1L,1L,1L,1L), c(1L,1L,1L,1L,1L), 1L,
>>>>>> c(2L,2L,2L,2L,2L), 5L, ptr1, ptr2)[[7]])
>>>>>> c(1L, -1L, -1L, 1L, -1L, 1L, 1L, -1L, -1L, 1L, 1L, -1L, 1L, -1L,
>>>>>> -1L, 1L, -1L, 1L, 1L, -1L, 1L, -1L, -1L, 1L, 1L, -1L, -1L, 1L,
>>>>>> -1L, 1L, 1L, -1L)
>>>>>>
>>>>>>> x=dput(c(.C("oneMargin", c(1L,1L,1L,1L,1L), c(1L,1L,1L,1L,1L), 1L,
>>>>>> c(2L,2L,2L,2L,2L), 5L, ptr1, ptr2)[[7]]))
>>>>>> c(1L, -1L, -1L, 1L, -1L, 1L, 1L, -1L, -1L, 1L, 1L, -1L, 1L, -1L,
>>>>>>    -1L, 1L, -1L, 1L, 1L, -1L, 1L, -1L, -1L, 1L, 1L, -1L, -1L, 1L,
>>>>>>    -1L, 1L, 1L, -1L)
>>>>>>> x
>>>>>> [1]  1 -1 -1  1 -1  1  1 -1 -1  1  1 -1  1 -1 -1  1 -1  1  1 -1  1 -1
>>>>>> -1  1  1 -1 -1  1 -1  1  1 -1
>>>>>>
>>>>>> # THESE ALL GIVE A DIFFERENT ONE!
>>>>>>
>>>>>>> .C("oneMargin", c(1L,1L,1L,1L,1L), c(1L,1L,1L,1L,1L), 1L,
>>>>>> c(2L,2L,2L,2L,2L), 5L, ptr1, ptr2)
>>>>>>
>>>>>> # (OTHER ELEMENTS OF LIST REMOVED)
>>>>>> [[7]]
>>>>>> [1] -1 -1  1  1  1  1 -1 -1  1  1 -1 -1 -1 -1  1  1  1  1 -1 -1 -1 -1
>>>>>> 1  1 -1 -1  1  1  1  1 -1 -1
>>>>>>
>>>>>>> c(.C("oneMargin", c(1L,1L,1L,1L,1L), c(1L,1L,1L,1L,1L), 1L,
>>>>>> c(2L,2L,2L,2L,2L), 5L, ptr1, ptr2)[[7]])
>>>>>> [1] -1 -1  1  1  1  1 -1 -1  1  1 -1 -1 -1 -1  1  1  1  1 -1 -1 -1 -1
>>>>>> 1  1 -1 -1  1  1  1  1 -1 -1
>>>>>>> x = .C("oneMargin", c(1L,1L,1L,1L,1L), c(1L,1L,1L,1L,1L), 1L,
>>>>>> c(2L,2L,2L,2L,2L), 5L, ptr1, ptr2)[[7]]
>>>>>>> x
>>>>>> [1] -1 -1  1  1  1  1 -1 -1  1  1 -1 -1 -1 -1  1  1  1  1 -1 -1 -1 -1
>>>>>> 1  1 -1 -1  1  1  1  1 -1 -1
>>>>>>
>>>>>>
>>>>>> --
>>>>>> Robin Evans
>>>>>> Statistical Laboratory
>>>>>> University of Cambridge
>>>>>> blog: itsastatlife.blogspot.com
>>>>>> web: www.statslab.cam.ac.uk/~rje42
>>>>>>
>>>>>> Causal Inference Workshop July 15th:
>>>>>> http://www.statslab.cam.ac.uk/~rje42/uai13/main.htm
>>>>>>
>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> Robin Evans
>>>>> Statistical Laboratory
>>>>> University of Cambridge
>>>>> blog: itsastatlife.blogspot.com
>>>>> web: www.statslab.cam.ac.uk/~rje42 <
>>> http://www.stat.washington.edu/~rje42>
>>>>>
>>>>> Causal Inference Workshop July 15th:
>>>>> http://www.statslab.cam.ac.uk/~rje42/uai13/main.htm
>>>>>
>>>>>          [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From es at enricoschumann.net  Thu May 23 09:33:01 2013
From: es at enricoschumann.net (Enrico Schumann)
Date: Thu, 23 May 2013 09:33:01 +0200
Subject: [Rd] minor typo in docs for 'sort'
Message-ID: <87d2sif8wi.fsf@enricoschumann.net>

Dear all, 

on the help page for '?sort':


  'Method "shell" uses Shellsort ([...] from Sedgewick (1996))'


but in the references it is Sedgewick (1986). 1986 seems correct:

http://dx.doi.org/10.1016/0196-6774(86)90001-5


Thank you,
Enrico

-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From hb at biostat.ucsf.edu  Thu May 23 21:19:38 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Thu, 23 May 2013 12:19:38 -0700
Subject: [Rd] Code compilation: Drop certain statements in a function before
 calling it multiple times?
Message-ID: <CAFDcVCSPRakF+qrvRnMsFEZ_2oUjoeEKceZbkCGjQ3t+nUhmHw@mail.gmail.com>

Hi,

I make heavy use of verbose statements in my code, verbose output that
can be enabled/disabled via an argument.  Here is a dummy example:

foo <- function(n=10, verbose=FALSE) {
  res <- 0;
  for (k in 1:n) {
     if (verbose) cat("Iteration ", k, "...\n", sep="");
     res <- res + k;
     if (verbose) cat("Iteration ", k, "...done\n", sep="");  }
  }
  res;
}

Even with verbose=FALSE, one pay an noticeable overhead due to it when
calling foo(verbose=FALSE).  Thus, before calling it, i'd like to
pre-compile this function by dropping the verbose-related statements,
e.g.

if (verbose) {
  fooT <- dropVerbose(foo);
}

such that I basically get:

fooT <- function(n=10, verbose=FALSE) {
  res <- 0;
  for (k in 1:n) {
     res <- res + k;
  }
  res;
}

Just to clarify, the immediate use case for this is to compile local
functions, e.g.

bar <- function(..., verbose=FALSE) {
  foo <- function(...) { ... };
  if (verbose) {
    foo <- dropVerbose(foo);
  }
  foo(..., verbose=verbose);
}

Instead of me reinventing the wheel does anyone know of tools that
makes it easier to drop certain statements in existing functions?


RESULTS:
> t <- system.time(for (k in 1:1e5) foo());
> tT <- system.time(for (k in 1:1e5) fooT());
> tT/t
     user    system   elapsed
0.6635514       NaN 0.6605505

I am aware of the 'compiler' package, which is great, but as far as I
understand the above speed up when dropping statements still applies;

> fooC <- compiler::cmpfun(foo);
> fooTC <- compiler::cmpfun(fooT);
> tC <- system.time(for (k in 1:1e5) fooC());
> tTC <- system.time(for (k in 1:1e5) fooTC());
> tTC/tC
     user    system   elapsed
0.6521739       NaN 0.6400000


Thanks,

Henrik

PS. The same idea of compilation applies when you make heavy use of
assert statements in your development, sanity checks that are there to
make sure *your* coding is correct and that basically never fails but
you keep in just in case.  It would be nice to have an option to have
a Just-in-Time (JIT) options for dropping those assert statements,
e.g. the user runs through an analysis on some test data and confirms
everything works as it should and then launch a two-week jobs where
asserts have been dropped.


From praguewatermelon at gmail.com  Thu May 23 22:18:43 2013
From: praguewatermelon at gmail.com (Xiao He)
Date: Thu, 23 May 2013 13:18:43 -0700
Subject: [Rd] Using a shared object without installing a library required by
	the object.
Message-ID: <CAGBzz=KXMjCFkHJyW4FhkWjqtqvRt-e1YoM=N-KwFmOfpDvt_w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130523/bdaf1ff4/attachment.pl>

From jony.hudson at imperial.ac.uk  Thu May 23 23:07:40 2013
From: jony.hudson at imperial.ac.uk (Jony Hudson)
Date: Thu, 23 May 2013 22:07:40 +0100
Subject: [Rd] Minimal build of R ...
In-Reply-To: <1D5CC664-B90A-444E-9389-9ED0ABC38999@imperial.ac.uk>
References: <1D5CC664-B90A-444E-9389-9ED0ABC38999@imperial.ac.uk>
Message-ID: <5DC072E7-8795-4DEE-A13E-A8DBF35D8B99@imperial.ac.uk>

Hi,

 I'm making some progress with this, but have hit a sticking point and am looking for a hint. Most of the compilation seems to be going ok, after some liberal use of f2c, but I'm getting compile errors in src/main/connections.c :

connections.c:926:43: error: use of undeclared identifier 'SSIZE_MAX'
    if ((double) size * (double) nitems > SSIZE_MAX)
                                          ^
connections.c:937:43: error: use of undeclared identifier 'SSIZE_MAX'
    if ((double) size * (double) nitems > SSIZE_MAX)
                                          ^
connections.c:3354:21: warning: implicit conversion from 'long long' to
      'R_xlen_t' (aka 'int') changes value from 4503599627370496 to 0
      [-Wconstant-conversion]
    nnn = (n < 0) ? R_XLEN_T_MAX : n;
        ~           ^~~~~~~~~~~~
../../src/include/Rinternals.h:65:23: note: expanded from macro 'R_XLEN_T_MAX'
# define R_XLEN_T_MAX 4503599627370496
                      ^~~~~~~~~~~~~~~~
connections.c:3662:11: error: duplicate case value '4'
            case sizeof(long):
                 ^
connections.c:3660:11: note: previous case defined here
            case sizeof(int):
                 ^
connections.c:3680:11: error: duplicate case value '4'
            case sizeof(long):
                 ^
connections.c:3678:11: note: previous case defined here
            case sizeof(int):
                 ^
connections.c:3912:11: error: duplicate case value '4'
            case sizeof(long):
                 ^
connections.c:3910:11: note: previous case defined here
            case sizeof(int):
                 ^
connections.c:3956:11: error: duplicate case value '4'
            case sizeof(long):
                 ^
connections.c:3952:11: note: previous case defined here
            case sizeof(int):

Recall that I'm compiling with emscripten, which uses clang to generate LLVM bitcode, which is then converted to javascript. I'm currently using the existing autotools build scripts, which emscripten tries to twist in to doing something sensible. It's quite possible that it's ending up mis-"./configure"d though.

I appreciate this is fairly off-topic, but if anyone has any pointers where to start looking, they would be greatly appreciated :-)

Thanks,


Jony

--
Centre for Cold Matter, The Blackett Laboratory,
Imperial College London, London SW7 2BW
T: +44 (0)207 5947741
http://www.imperial.ac.uk/people/jony.hudson
http://www.imperial.ac.uk/ccm/research/edm
http://www.monkeycruncher.org
http://j-star.org/
--

On 2 May 2013, at 17:12, Jony Hudson <jony.hudson at imperial.ac.uk> wrote:

> Hi,
> 
> I'm trying to cross-compile R to javascript so that it can run in a web-browser. Take as long as you need to stop laughing. So, as I was saying - I want to try and get a build of R running in the browser. [If you're not familiar with it already, you might enjoy looking at emscripten.org. It's a remarkably capable tool for translating LLVM bitcode to javascript. Check out some of the demos!]
> 
> I'm trying to start out with the most minimal build of R possible. I can turn off various options in the configure script, but I'm wondering about the bundled R packages (base, stats etc). I'm guessing that the native code portions of these packages are dynamically loaded at runtime, which will probably need patching. To start off, I'd like to not build these packages if possible.
> 
> So, is there a way to configure which packages in the library get built or is it just a case of editing the makefile? And is there a minimal set of them that would still allow R to run (not be useful - that can come later - just run)?
> 
> Thanks in advance for any help anyone can provide :-)
> 
> 
> Jony
> 
> --
> Centre for Cold Matter, The Blackett Laboratory,
> Imperial College London, London SW7 2BW
> T: +44 (0)207 5947741
> http://www.imperial.ac.uk/people/jony.hudson
> http://www.imperial.ac.uk/ccm/research/edm
> http://www.monkeycruncher.org
> http://j-star.org/
> --
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From pdalgd at gmail.com  Thu May 23 23:55:37 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 23 May 2013 23:55:37 +0200
Subject: [Rd] Minimal build of R ...
In-Reply-To: <5DC072E7-8795-4DEE-A13E-A8DBF35D8B99@imperial.ac.uk>
References: <1D5CC664-B90A-444E-9389-9ED0ABC38999@imperial.ac.uk>
	<5DC072E7-8795-4DEE-A13E-A8DBF35D8B99@imperial.ac.uk>
Message-ID: <EB246CE8-9399-4EDD-AE16-16C4F7B0CE82@gmail.com>


On May 23, 2013, at 23:07 , Jony Hudson wrote:

> Hi,
> 
> I'm making some progress with this, but have hit a sticking point and am looking for a hint. Most of the compilation seems to be going ok, after some liberal use of f2c, but I'm getting compile errors in src/main/connections.c :
> 
> connections.c:926:43: error: use of undeclared identifier 'SSIZE_MAX'
>    if ((double) size * (double) nitems > SSIZE_MAX)
>                                          ^
> connections.c:937:43: error: use of undeclared identifier 'SSIZE_MAX'
>    if ((double) size * (double) nitems > SSIZE_MAX)
>                                          ^
> connections.c:3354:21: warning: implicit conversion from 'long long' to
>      'R_xlen_t' (aka 'int') changes value from 4503599627370496 to 0
>      [-Wconstant-conversion]
>    nnn = (n < 0) ? R_XLEN_T_MAX : n;
>        ~           ^~~~~~~~~~~~
> ../../src/include/Rinternals.h:65:23: note: expanded from macro 'R_XLEN_T_MAX'
> # define R_XLEN_T_MAX 4503599627370496
>                      ^~~~~~~~~~~~~~~~
> connections.c:3662:11: error: duplicate case value '4'
>            case sizeof(long):
>                 ^
> connections.c:3660:11: note: previous case defined here
>            case sizeof(int):
>                 ^
> connections.c:3680:11: error: duplicate case value '4'
>            case sizeof(long):
>                 ^
> connections.c:3678:11: note: previous case defined here
>            case sizeof(int):
>                 ^
> connections.c:3912:11: error: duplicate case value '4'
>            case sizeof(long):
>                 ^
> connections.c:3910:11: note: previous case defined here
>            case sizeof(int):
>                 ^
> connections.c:3956:11: error: duplicate case value '4'
>            case sizeof(long):
>                 ^
> connections.c:3952:11: note: previous case defined here
>            case sizeof(int):
> 
> Recall that I'm compiling with emscripten, which uses clang to generate LLVM bitcode, which is then converted to javascript. I'm currently using the existing autotools build scripts, which emscripten tries to twist in to doing something sensible. It's quite possible that it's ending up mis-"./configure"d though.
> 
> I appreciate this is fairly off-topic, but if anyone has any pointers where to start looking, they would be greatly appreciated :-)
> 

Looks like SSIZE_MAX is usually <*/limits.h>:

pd$ grep -r SSIZE_MAX /usr/include/
/usr/include/i386/limits.h:#define	SSIZE_MAX	LONG_MAX	/* max value for a ssize_t */
/usr/include/limits.h:#define	_POSIX_SSIZE_MAX	32767
/usr/include/ppc/limits.h:#define	SSIZE_MAX	LONG_MAX	/* max value for a ssize_t */

If R_xlen_t is int, you need to adjust R_XLEN_T_MAX to INT_MAX or so.

The case warnings look like they are bound to happen on systems where int and long have the same size, and should presumably be harmless.

 


> Thanks,
> 
> 
> Jony
> 
> --
> Centre for Cold Matter, The Blackett Laboratory,
> Imperial College London, London SW7 2BW
> T: +44 (0)207 5947741
> http://www.imperial.ac.uk/people/jony.hudson
> http://www.imperial.ac.uk/ccm/research/edm
> http://www.monkeycruncher.org
> http://j-star.org/
> --
> 
> On 2 May 2013, at 17:12, Jony Hudson <jony.hudson at imperial.ac.uk> wrote:
> 
>> Hi,
>> 
>> I'm trying to cross-compile R to javascript so that it can run in a web-browser. Take as long as you need to stop laughing. So, as I was saying - I want to try and get a build of R running in the browser. [If you're not familiar with it already, you might enjoy looking at emscripten.org. It's a remarkably capable tool for translating LLVM bitcode to javascript. Check out some of the demos!]
>> 
>> I'm trying to start out with the most minimal build of R possible. I can turn off various options in the configure script, but I'm wondering about the bundled R packages (base, stats etc). I'm guessing that the native code portions of these packages are dynamically loaded at runtime, which will probably need patching. To start off, I'd like to not build these packages if possible.
>> 
>> So, is there a way to configure which packages in the library get built or is it just a case of editing the makefile? And is there a minimal set of them that would still allow R to run (not be useful - that can come later - just run)?
>> 
>> Thanks in advance for any help anyone can provide :-)
>> 
>> 
>> Jony
>> 
>> --
>> Centre for Cold Matter, The Blackett Laboratory,
>> Imperial College London, London SW7 2BW
>> T: +44 (0)207 5947741
>> http://www.imperial.ac.uk/people/jony.hudson
>> http://www.imperial.ac.uk/ccm/research/edm
>> http://www.monkeycruncher.org
>> http://j-star.org/
>> --
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From simon.urbanek at r-project.org  Fri May 24 01:54:44 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 23 May 2013 19:54:44 -0400
Subject: [Rd] Using a shared object without installing a library
	required by the object.
In-Reply-To: <CAGBzz=KXMjCFkHJyW4FhkWjqtqvRt-e1YoM=N-KwFmOfpDvt_w@mail.gmail.com>
References: <CAGBzz=KXMjCFkHJyW4FhkWjqtqvRt-e1YoM=N-KwFmOfpDvt_w@mail.gmail.com>
Message-ID: <216071C9-5257-4E30-BE6D-664A4CE984FA@r-project.org>

On May 23, 2013, at 4:18 PM, Xiao He <praguewatermelon at gmail.com> wrote:

> Dear all,
> 
> I have a C++ code. To create a shared object from this particular code, I
> had to install a Fortran library on my computer (Mac). The compiled code
> runs fine on my computer. However,  if I try to dyn.load() said shared
> object on a computer that does not have the Fortran library installed, the
> object won't load, and instead I get a message below:
> 
> usr/local/lib/libgfortran.2.dylib
> Referenced from: /Users/xh/Downloads/foo2.so
> 
> I wonder if there is any way to compile the original C++ code such that I
> can include the necessary components of the Fortran library without having
> to install the library.
> 

The Fortran run-time is included with R, so you only need to change the path -- e.g.

install_name_tool -change /usr/local/lib/libgfortran.2.dylib /Library/Frameworks/R.framework/Resources/lib/libgfortran.2.dylib /Users/xh/Downloads/foo2.so

You can make that permanent on your build machine by running

install_name_tool -id  /Library/Frameworks/R.framework/Resources/lib/libgfortran.2.dylib /usr/local/lib/libgfortran.2.dylib

If you do that, all code compiled against it subsequently will point to the version inside R instead.

Cheers,
Simon

FWIW: There is R-SIG-Mac for Mac-specific questions.


> 
> Thank you in advance.
> 
> Best,
> Xiao
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From praguewatermelon at gmail.com  Fri May 24 02:09:40 2013
From: praguewatermelon at gmail.com (Xiao He)
Date: Thu, 23 May 2013 17:09:40 -0700
Subject: [Rd] Using a shared object without installing a library
 required by the object.
In-Reply-To: <CAGBzz=JF5fXY2MaWMfoavsyFi40ViPOZhKUP=RX72VaARE65jA@mail.gmail.com>
References: <CAGBzz=KXMjCFkHJyW4FhkWjqtqvRt-e1YoM=N-KwFmOfpDvt_w@mail.gmail.com>
	<216071C9-5257-4E30-BE6D-664A4CE984FA@r-project.org>
	<CAGBzz=JF5fXY2MaWMfoavsyFi40ViPOZhKUP=RX72VaARE65jA@mail.gmail.com>
Message-ID: <CAGBzz=J0Ryb15C=JvL_a2S6WuPV2WhEGL4EYvxby5uL24XSdww@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130523/7bcd5246/attachment.pl>

From rhelp at eoos.dds.nl  Fri May 24 08:53:15 2013
From: rhelp at eoos.dds.nl (Jan van der Laan)
Date: Fri, 24 May 2013 08:53:15 +0200
Subject: [Rd] Problem with Rboolean in c++ code
Message-ID: <20130524085315.Horde.kTXxB2EwhY5Rnw5bwgT19rA@webmailnew.dds.nl>


I am trying to use R_RegisterCFinalizerEx to ensure some c++ object is  
properly deleted after use. However, I run into some problems when  
trying to pass in the third argument which is an Rboolean.  The line  
'R_RegisterCFinalizerEx(p, finalizer, TRUE);' generates the following  
error when trying to compile using R CMD SHLIB:

g++ -I/usr/share/R/include -DNDEBUG      -fpic  -O2 -pipe -g  -c  
rboolean.cpp -o rboolean.o
rboolean.cpp: In function ?SEXPREC* create(SEXP)?:
rboolean.cpp:21:46: error: invalid conversion from ?int? to ?Rboolean?  
[-fpermissive]
In file included from /usr/share/R/include/Rdefines.h:29:0,
                  from rboolean.cpp:4:
/usr/share/R/include/Rinternals.h:764:6: error:   initializing  
argument 3 of ?void R_RegisterCFinalizerEx(SEXP, R_CFinalizer_t,  
Rboolean)? [-fpermissive]
make: *** [rboolean.o] Error 1


I have managed to reduce the problem to the example below:

===== foo.cpp =====
#include <R.h>
#include <Rdefines.h>

void foo() {
   Rboolean b = TRUE;
}
==================

With the extension .cpp this generates the error above, with the  
extension .c (don't put both in the same directory; at least not with  
the same name) it compiles without errors or warnings.

When looking at the headers (R_ext/Boolean.h and Rdefines.h) it seems  
that TRUE and FALSE are also defined as constants which seems to  
conflict with the enum values of Rboolean.

For now I use the compiler flag -fpermissive (as suggested by g++),  
but I suppose this is not acceptable when submitting to CRAN. Am I  
doing something wrong? Is there a workaround/solution?

Thanks.

Jan


From pengyu.ut at gmail.com  Fri May 24 12:00:29 2013
From: pengyu.ut at gmail.com (Peng Yu)
Date: Fri, 24 May 2013 05:00:29 -0500
Subject: [Rd] Standalone example to use eval in C (not eval in R)?
Message-ID: <CABrM6wnZRiaVnBfQCaT1z7Pn+Dh0+h0GHyrmxwnU1XOobquCSA@mail.gmail.com>

'eval' is used in optim.c, but it is used along with other things. I'm
looking for a standalone example to demonstrate the usage of eval in
C.  Does anybody have some a simple example? Thanks.

-- 
Regards,
Peng


From simon.urbanek at r-project.org  Fri May 24 14:59:53 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 24 May 2013 08:59:53 -0400
Subject: [Rd] Standalone example to use eval in C (not eval in R)?
In-Reply-To: <CABrM6wnZRiaVnBfQCaT1z7Pn+Dh0+h0GHyrmxwnU1XOobquCSA@mail.gmail.com>
References: <CABrM6wnZRiaVnBfQCaT1z7Pn+Dh0+h0GHyrmxwnU1XOobquCSA@mail.gmail.com>
Message-ID: <D05C3226-29F9-4D8E-8A1A-7A1DACDEC387@r-project.org>


On May 24, 2013, at 6:00 AM, Peng Yu wrote:

> 'eval' is used in optim.c, but it is used along with other things. I'm
> looking for a standalone example to demonstrate the usage of eval in
> C.  Does anybody have some a simple example? Thanks.
> 

Try R-exts:
"5.11 Evaluating R expressions from C"

Cheers,
S


From ripley at stats.ox.ac.uk  Fri May 24 15:36:19 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 24 May 2013 14:36:19 +0100
Subject: [Rd] Problem with Rboolean in c++ code
In-Reply-To: <20130524085315.Horde.kTXxB2EwhY5Rnw5bwgT19rA@webmailnew.dds.nl>
References: <20130524085315.Horde.kTXxB2EwhY5Rnw5bwgT19rA@webmailnew.dds.nl>
Message-ID: <519F6CD3.2000407@stats.ox.ac.uk>

On 24/05/2013 07:53, Jan van der Laan wrote:
>
> I am trying to use R_RegisterCFinalizerEx to ensure some c++ object is
> properly deleted after use. However, I run into some problems when
> trying to pass in the third argument which is an Rboolean.  The line
> 'R_RegisterCFinalizerEx(p, finalizer, TRUE);' generates the following
> error when trying to compile using R CMD SHLIB:
>
> g++ -I/usr/share/R/include -DNDEBUG      -fpic  -O2 -pipe -g  -c
> rboolean.cpp -o rboolean.o
> rboolean.cpp: In function ?SEXPREC* create(SEXP)?:
> rboolean.cpp:21:46: error: invalid conversion from ?int? to ?Rboolean?
> [-fpermissive]
> In file included from /usr/share/R/include/Rdefines.h:29:0,
>                   from rboolean.cpp:4:
> /usr/share/R/include/Rinternals.h:764:6: error:   initializing argument
> 3 of ?void R_RegisterCFinalizerEx(SEXP, R_CFinalizer_t, Rboolean)?
> [-fpermissive]
> make: *** [rboolean.o] Error 1
>
>
> I have managed to reduce the problem to the example below:
>
> ===== foo.cpp =====
> #include <R.h>
> #include <Rdefines.h>
>
> void foo() {
>    Rboolean b = TRUE;
> }
> ==================
>
> With the extension .cpp this generates the error above, with the
> extension .c (don't put both in the same directory; at least not with
> the same name) it compiles without errors or warnings.
>
> When looking at the headers (R_ext/Boolean.h and Rdefines.h) it seems
> that TRUE and FALSE are also defined as constants which seems to
> conflict with the enum values of Rboolean.
>
> For now I use the compiler flag -fpermissive (as suggested by g++), but
> I suppose this is not acceptable when submitting to CRAN. Am I doing
> something wrong? Is there a workaround/solution?

Don't use Rdefines.h: use Rinternals.h.

Rdefines.h was for compatibility with S code from the 1990s: it is not 
kept up to date.

>
> Thanks.
>
> Jan


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rhelp at eoos.dds.nl  Fri May 24 16:55:18 2013
From: rhelp at eoos.dds.nl (Jan van der Laan)
Date: Fri, 24 May 2013 16:55:18 +0200
Subject: [Rd] Problem with Rboolean in c++ code
In-Reply-To: <519F6CD3.2000407@stats.ox.ac.uk>
References: <20130524085315.Horde.kTXxB2EwhY5Rnw5bwgT19rA@webmailnew.dds.nl>
	<519F6CD3.2000407@stats.ox.ac.uk>
Message-ID: <20130524165518.Horde.av7PI2EwhY5Rn39WwjJ0HYA@webmailnew.dds.nl>


Thanks. That does the trick. Although I now have to rewrite some other  
stuff, but I have just started so better now than later.

To be honest, a first and even a second read of the r-extensions  
manual did not really make it clear, to me at least, that Rdefines.h  
is preferred above Rinternals.h. Now that I reread it again, I can see  
a slight preference for Rdefines.h, but you really have to read closely.

Thanks again.

Jan


Prof Brian Ripley <ripley at stats.ox.ac.uk> schreef:

> On 24/05/2013 07:53, Jan van der Laan wrote:
>>
>> I am trying to use R_RegisterCFinalizerEx to ensure some c++ object is
>> properly deleted after use. However, I run into some problems when
>> trying to pass in the third argument which is an Rboolean.  The line
>> 'R_RegisterCFinalizerEx(p, finalizer, TRUE);' generates the following
>> error when trying to compile using R CMD SHLIB:
>>
>> g++ -I/usr/share/R/include -DNDEBUG      -fpic  -O2 -pipe -g  -c
>> rboolean.cpp -o rboolean.o
>> rboolean.cpp: In function ?SEXPREC* create(SEXP)?:
>> rboolean.cpp:21:46: error: invalid conversion from ?int? to ?Rboolean?
>> [-fpermissive]
>> In file included from /usr/share/R/include/Rdefines.h:29:0,
>>                  from rboolean.cpp:4:
>> /usr/share/R/include/Rinternals.h:764:6: error:   initializing argument
>> 3 of ?void R_RegisterCFinalizerEx(SEXP, R_CFinalizer_t, Rboolean)?
>> [-fpermissive]
>> make: *** [rboolean.o] Error 1
>>
>>
>> I have managed to reduce the problem to the example below:
>>
>> ===== foo.cpp =====
>> #include <R.h>
>> #include <Rdefines.h>
>>
>> void foo() {
>>   Rboolean b = TRUE;
>> }
>> ==================
>>
>> With the extension .cpp this generates the error above, with the
>> extension .c (don't put both in the same directory; at least not with
>> the same name) it compiles without errors or warnings.
>>
>> When looking at the headers (R_ext/Boolean.h and Rdefines.h) it seems
>> that TRUE and FALSE are also defined as constants which seems to
>> conflict with the enum values of Rboolean.
>>
>> For now I use the compiler flag -fpermissive (as suggested by g++), but
>> I suppose this is not acceptable when submitting to CRAN. Am I doing
>> something wrong? Is there a workaround/solution?
>
> Don't use Rdefines.h: use Rinternals.h.
>
> Rdefines.h was for compatibility with S code from the 1990s: it is  
> not kept up to date.
>
>>
>> Thanks.
>>
>> Jan
>
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Fri May 24 17:02:33 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 24 May 2013 16:02:33 +0100
Subject: [Rd] Problem with Rboolean in c++ code
In-Reply-To: <20130524165518.Horde.av7PI2EwhY5Rn39WwjJ0HYA@webmailnew.dds.nl>
References: <20130524085315.Horde.kTXxB2EwhY5Rnw5bwgT19rA@webmailnew.dds.nl>
	<519F6CD3.2000407@stats.ox.ac.uk>
	<20130524165518.Horde.av7PI2EwhY5Rn39WwjJ0HYA@webmailnew.dds.nl>
Message-ID: <519F8109.2020406@stats.ox.ac.uk>

On 24/05/2013 15:55, Jan van der Laan wrote:
>
> Thanks. That does the trick. Although I now have to rewrite some other
> stuff, but I have just started so better now than later.
>
> To be honest, a first and even a second read of the r-extensions manual
> did not really make it clear, to me at least, that Rdefines.h is
> preferred above Rinternals.h. Now that I reread it again, I can see a
> slight preference for Rdefines.h, but you really have to read closely.

That's backwards.  Rinternals.h is the definitive version, used by R itself.

>
> Thanks again.
>
> Jan
>
>
> Prof Brian Ripley <ripley at stats.ox.ac.uk> schreef:
>
>> On 24/05/2013 07:53, Jan van der Laan wrote:
>>>
>>> I am trying to use R_RegisterCFinalizerEx to ensure some c++ object is
>>> properly deleted after use. However, I run into some problems when
>>> trying to pass in the third argument which is an Rboolean.  The line
>>> 'R_RegisterCFinalizerEx(p, finalizer, TRUE);' generates the following
>>> error when trying to compile using R CMD SHLIB:
>>>
>>> g++ -I/usr/share/R/include -DNDEBUG      -fpic  -O2 -pipe -g  -c
>>> rboolean.cpp -o rboolean.o
>>> rboolean.cpp: In function ?SEXPREC* create(SEXP)?:
>>> rboolean.cpp:21:46: error: invalid conversion from ?int? to ?Rboolean?
>>> [-fpermissive]
>>> In file included from /usr/share/R/include/Rdefines.h:29:0,
>>>                  from rboolean.cpp:4:
>>> /usr/share/R/include/Rinternals.h:764:6: error:   initializing argument
>>> 3 of ?void R_RegisterCFinalizerEx(SEXP, R_CFinalizer_t, Rboolean)?
>>> [-fpermissive]
>>> make: *** [rboolean.o] Error 1
>>>
>>>
>>> I have managed to reduce the problem to the example below:
>>>
>>> ===== foo.cpp =====
>>> #include <R.h>
>>> #include <Rdefines.h>
>>>
>>> void foo() {
>>>   Rboolean b = TRUE;
>>> }
>>> ==================
>>>
>>> With the extension .cpp this generates the error above, with the
>>> extension .c (don't put both in the same directory; at least not with
>>> the same name) it compiles without errors or warnings.
>>>
>>> When looking at the headers (R_ext/Boolean.h and Rdefines.h) it seems
>>> that TRUE and FALSE are also defined as constants which seems to
>>> conflict with the enum values of Rboolean.
>>>
>>> For now I use the compiler flag -fpermissive (as suggested by g++), but
>>> I suppose this is not acceptable when submitting to CRAN. Am I doing
>>> something wrong? Is there a workaround/solution?
>>
>> Don't use Rdefines.h: use Rinternals.h.
>>
>> Rdefines.h was for compatibility with S code from the 1990s: it is not
>> kept up to date.
>>
>>>
>>> Thanks.
>>>
>>> Jan
>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rhelp at eoos.dds.nl  Fri May 24 21:23:50 2013
From: rhelp at eoos.dds.nl (Jan van der Laan)
Date: Fri, 24 May 2013 21:23:50 +0200
Subject: [Rd] Problem with Rboolean in c++ code
In-Reply-To: <519F8109.2020406@stats.ox.ac.uk>
References: <20130524085315.Horde.kTXxB2EwhY5Rnw5bwgT19rA@webmailnew.dds.nl>
	<519F6CD3.2000407@stats.ox.ac.uk>
	<20130524165518.Horde.av7PI2EwhY5Rn39WwjJ0HYA@webmailnew.dds.nl>
	<519F8109.2020406@stats.ox.ac.uk>
Message-ID: <519FBE46.6020209@eoos.dds.nl>



On 05/24/2013 05:02 PM, Prof Brian Ripley wrote:
> On 24/05/2013 15:55, Jan van der Laan wrote:
>>
>> Thanks. That does the trick. Although I now have to rewrite some other
>> stuff, but I have just started so better now than later.
>>
>> To be honest, a first and even a second read of the r-extensions manual
>> did not really make it clear, to me at least, that Rdefines.h is
>> preferred above Rinternals.h. Now that I reread it again, I can see a
>> slight preference for Rdefines.h, but you really have to read closely.
>
> That's backwards.  Rinternals.h is the definitive version, used by R
> itself.


Sorry. You're right. Use Rinternals.h; don't use Rdefines.h.

Jan






>
>>
>> Thanks again.
>>
>> Jan
>>
>>
>> Prof Brian Ripley <ripley at stats.ox.ac.uk> schreef:
>>
>>> On 24/05/2013 07:53, Jan van der Laan wrote:
>>>>
>>>> I am trying to use R_RegisterCFinalizerEx to ensure some c++ object is
>>>> properly deleted after use. However, I run into some problems when
>>>> trying to pass in the third argument which is an Rboolean.  The line
>>>> 'R_RegisterCFinalizerEx(p, finalizer, TRUE);' generates the following
>>>> error when trying to compile using R CMD SHLIB:
>>>>
>>>> g++ -I/usr/share/R/include -DNDEBUG      -fpic  -O2 -pipe -g  -c
>>>> rboolean.cpp -o rboolean.o
>>>> rboolean.cpp: In function ?SEXPREC* create(SEXP)?:
>>>> rboolean.cpp:21:46: error: invalid conversion from ?int? to ?Rboolean?
>>>> [-fpermissive]
>>>> In file included from /usr/share/R/include/Rdefines.h:29:0,
>>>>                  from rboolean.cpp:4:
>>>> /usr/share/R/include/Rinternals.h:764:6: error:   initializing argument
>>>> 3 of ?void R_RegisterCFinalizerEx(SEXP, R_CFinalizer_t, Rboolean)?
>>>> [-fpermissive]
>>>> make: *** [rboolean.o] Error 1
>>>>
>>>>
>>>> I have managed to reduce the problem to the example below:
>>>>
>>>> ===== foo.cpp =====
>>>> #include <R.h>
>>>> #include <Rdefines.h>
>>>>
>>>> void foo() {
>>>>   Rboolean b = TRUE;
>>>> }
>>>> ==================
>>>>
>>>> With the extension .cpp this generates the error above, with the
>>>> extension .c (don't put both in the same directory; at least not with
>>>> the same name) it compiles without errors or warnings.
>>>>
>>>> When looking at the headers (R_ext/Boolean.h and Rdefines.h) it seems
>>>> that TRUE and FALSE are also defined as constants which seems to
>>>> conflict with the enum values of Rboolean.
>>>>
>>>> For now I use the compiler flag -fpermissive (as suggested by g++), but
>>>> I suppose this is not acceptable when submitting to CRAN. Am I doing
>>>> something wrong? Is there a workaround/solution?
>>>
>>> Don't use Rdefines.h: use Rinternals.h.
>>>
>>> Rdefines.h was for compatibility with S code from the 1990s: it is not
>>> kept up to date.
>>>
>>>>
>>>> Thanks.
>>>>
>>>> Jan
>>>
>>>
>>> --
>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>> University of Oxford,             Tel:  +44 1865 272861 (self)
>>> 1 South Parks Road,                     +44 1865 272866 (PA)
>>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>>
>>
>
>


From btyner at gmail.com  Sat May 25 02:41:23 2013
From: btyner at gmail.com (Benjamin Tyner)
Date: Fri, 24 May 2013 20:41:23 -0400
Subject: [Rd] segfault when using browser() in Rprofile.site
Message-ID: <51A008B3.9040300@gmail.com>

Hi.

It seems that if I put a browser() in my Rprofile.site, I get a
segfault. This happens on several machines, several versions of R.

Here it the valgrind output when using revision 62797:

==31314== Memcheck, a memory error detector
==31314== Copyright (C) 2002-2012, and GNU GPL'd, by Julian Seward et al.
==31314== Using Valgrind-3.8.1 and LibVEX; rerun with -h for copyright info
==31314== Command: /home/btyner/R62797/lib/R/bin/exec/R
==31314==

R version 3.0.1 Patched (2013-05-24 r62797) -- "Good Sport"
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: x86_64-unknown-linux-gnu (64-bit)

<snip>

Called from: top level
Browse[1]> ls()
==31314== Invalid write of size 1
==31314==    at 0x4CF07D: R_IoBufferPutc (iosupport.c:135)
==31314==    by 0x4D3C5C: Rf_ReplIteration (main.c:222)
==31314==    by 0x4D4047: R_ReplConsole (main.c:307)
==31314==    by 0x4D4353: do_browser (main.c:1137)
==31314==    by 0x4B1E86: Rf_eval (eval.c:639)
==31314==    by 0x4D22F0: R_ReplFile (main.c:101)
==31314==    by 0x4D23FF: R_LoadProfile (main.c:663)
==31314==    by 0x4D2965: setup_Rmainloop (main.c:892)
==31314==    by 0x4D4558: Rf_mainloop (main.c:992)
==31314==    by 0x41A4D7: main (Rmain.c:32)
==31314==  Address 0x0 is not stack'd, malloc'd or (recently) free'd
==31314==

 *** caught segfault ***
address (nil), cause 'memory not mapped'

And here is the gdb backtrace:

#0  R_IoBufferPutc (c=c at entry=108, iob=iob at entry=0x9868c0 <R_ConsoleIob>)
    at iosupport.c:135
#1  0x00000000004d3c5d in Rf_ReplIteration (rho=rho at entry=0x9b9920,
    savestack=savestack at entry=9, browselevel=browselevel at entry=1,
    state=state at entry=0x7fffffffadb0) at main.c:222
#2  0x00000000004d4048 in R_ReplConsole (rho=rho at entry=0x9b9920,
    savestack=savestack at entry=9, browselevel=browselevel at entry=1) at
main.c:307
#3  0x00000000004d4354 in do_browser (call=0x1464b20, op=<optimized out>,
    args=<optimized out>, rho=0x9b9920) at main.c:1137
#4  0x00000000004b1e87 in Rf_eval (e=0x1464b20, rho=rho at entry=0x9b9920)
    at eval.c:639
#5  0x00000000004d22f1 in R_ReplFile (fp=0x146fdb0, rho=rho at entry=0x9b9920)
    at main.c:101
#6  0x00000000004d2400 in R_LoadProfile (fparg=0x146fdb0,
    env=env at entry=0x9b9920) at main.c:663
#7  0x00000000004d2966 in setup_Rmainloop () at main.c:892
#8  0x00000000004d4559 in Rf_mainloop () at main.c:992
#9  0x000000000041a4d8 in main (ac=ac at entry=1, av=av at entry=0x7fffffffe058)
    at Rmain.c:32
#10 0x00007ffff6a87ea5 in __libc_start_main (main=0x41a4c0 <main>, argc=1,
    ubp_av=0x7fffffffe058, init=<optimized out>, fini=<optimized out>,
    rtld_fini=<optimized out>, stack_end=0x7fffffffe048) at libc-start.c:260
#11 0x000000000041a509 in _start ()


Lastly, here is my

> sessionInfo()
R version 3.0.1 Patched (2013-05-24 r62797)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C             
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8   
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8  
 [7] LC_PAPER=C                 LC_NAME=C                
 [9] LC_ADDRESS=C               LC_TELEPHONE=C           
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C      

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base    


Figured I'd mention this here first before submitting a formal bug
report, in case this is user error.

Regards,
Ben



From hb at biostat.ucsf.edu  Sat May 25 21:48:33 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sat, 25 May 2013 12:48:33 -0700
Subject: [Rd] Assigning NULL to large variables is much faster than rm() -
 any reason why I should still use rm()?
Message-ID: <CAFDcVCRXmf+gxBA2joK_V0fxM9Pmh-A-h9S+Tkx_meNtNMLtow@mail.gmail.com>

Hi,

in my packages/functions/code I tend to remove large temporary
variables as soon as possible, e.g. large intermediate vectors used in
iterations.  I sometimes also have the habit of doing this to make it
explicit in the source code when a temporary object is no longer
needed.  However, I did notice that this can add a noticeable overhead
when the rest of the iteration step does not take that much time.

Trying to speed this up, I first noticed that rm(list="a") is much
faster than rm(a).  While at it, I realized that for the purpose of
keeping the memory footprint small, I can equally well reassign the
variable the value of a small object (e.g. a <- NULL), which is
significantly faster than using rm().

SOME BENCHMARKS:
A toy example imitating an iterative algorithm with "large" temporary objects.

x <- matrix(rnorm(100e6), ncol=10e3)

t1 <- system.time(for (k in 1:ncol(x)) {
  a <- x[,k]
  colSum <- sum(a)
  rm(a) # Not needed anymore
  b <- x[k,]
  rowSum <- sum(b)
  rm(b) # Not needed anymore
})

t2 <- system.time(for (k in 1:ncol(x)) {
  a <- x[,k]
  colSum <- sum(a)
  rm(list="a") # Not needed anymore
  b <- x[k,]
  rowSum <- sum(b)
  rm(list="b") # Not needed anymore
})

t3 <- system.time(for (k in 1:ncol(x)) {
  a <- x[,k]
  colSum <- sum(a)
  a <- NULL # Not needed anymore
  b <- x[k,]
  rowSum <- sum(b)
  b <- NULL # Not needed anymore
})

> t1
   user  system elapsed
   8.03    0.00    8.08
> t1/t2
    user   system  elapsed
1.322900 0.000000 1.320261
> t1/t3
    user   system  elapsed
1.715812 0.000000 1.662551


Is there a reason why I shouldn't assign NULL instead of using rm()?
As far as I understand it, the garbage collector will be equally
efficient cleaning out the previous object when using rm(a) or a <-
NULL.  Is there anything else I'm overlooking?  Am I adding overhead
somewhere else?

/Henrik


PS. With the above toy example one can obviously be a bit smarter by using:

t4 <- system.time({for (k in 1:ncol(x)) {
  a <- x[,k]
  colSum <- sum(a)
  a <- x[k,]
  rowSum <- sum(a)
}
rm(list="a")
})

but that's not my point.


From wdunlap at tibco.com  Sat May 25 23:00:16 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 25 May 2013 21:00:16 +0000
Subject: [Rd] Assigning NULL to large variables is much faster than rm()
 - any reason why I should still use rm()?
In-Reply-To: <CAFDcVCRXmf+gxBA2joK_V0fxM9Pmh-A-h9S+Tkx_meNtNMLtow@mail.gmail.com>
References: <CAFDcVCRXmf+gxBA2joK_V0fxM9Pmh-A-h9S+Tkx_meNtNMLtow@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C2FA30B@PA-MBX01.na.tibco.com>

Another way to avoid using rm() in loops is to use throw-away
functions.  E.g., 
> t3 <- system.time(for (k in 1:ncol(x)) { # your last, fastest, example
+   a <- x[,k]
+   colSum <- sum(a)
+   a <- NULL # Not needed anymore
+   b <- x[k,]
+   rowSum <- sum(b)
+   b <- NULL # Not needed anymore
+ })
> t4 <- system.time({ # use some throw-away functions
+     colKSum <- function(k) { a <- x[,k] ; sum(a) }
+     rowKSum <- function(k) { b <- x[k,] ; sum(b) }
+     for(k in 1:ncol(x)) {
+         colSum <- colKSum(k)
+         rowSum <- rowKSum(k)
+ }})
> t3
   user  system elapsed 
   7.89    0.02    7.93 
> t4
   user  system elapsed 
   7.88    0.02    7.93
I think the code is clearer.  It might make the compiler's job easier.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf
> Of Henrik Bengtsson
> Sent: Saturday, May 25, 2013 12:49 PM
> To: R-devel
> Subject: [Rd] Assigning NULL to large variables is much faster than rm() - any reason why
> I should still use rm()?
> 
> Hi,
> 
> in my packages/functions/code I tend to remove large temporary
> variables as soon as possible, e.g. large intermediate vectors used in
> iterations.  I sometimes also have the habit of doing this to make it
> explicit in the source code when a temporary object is no longer
> needed.  However, I did notice that this can add a noticeable overhead
> when the rest of the iteration step does not take that much time.
> 
> Trying to speed this up, I first noticed that rm(list="a") is much
> faster than rm(a).  While at it, I realized that for the purpose of
> keeping the memory footprint small, I can equally well reassign the
> variable the value of a small object (e.g. a <- NULL), which is
> significantly faster than using rm().
> 
> SOME BENCHMARKS:
> A toy example imitating an iterative algorithm with "large" temporary objects.
> 
> x <- matrix(rnorm(100e6), ncol=10e3)
> 
> t1 <- system.time(for (k in 1:ncol(x)) {
>   a <- x[,k]
>   colSum <- sum(a)
>   rm(a) # Not needed anymore
>   b <- x[k,]
>   rowSum <- sum(b)
>   rm(b) # Not needed anymore
> })
> 
> t2 <- system.time(for (k in 1:ncol(x)) {
>   a <- x[,k]
>   colSum <- sum(a)
>   rm(list="a") # Not needed anymore
>   b <- x[k,]
>   rowSum <- sum(b)
>   rm(list="b") # Not needed anymore
> })
> 
> t3 <- system.time(for (k in 1:ncol(x)) {
>   a <- x[,k]
>   colSum <- sum(a)
>   a <- NULL # Not needed anymore
>   b <- x[k,]
>   rowSum <- sum(b)
>   b <- NULL # Not needed anymore
> })
> 
> > t1
>    user  system elapsed
>    8.03    0.00    8.08
> > t1/t2
>     user   system  elapsed
> 1.322900 0.000000 1.320261
> > t1/t3
>     user   system  elapsed
> 1.715812 0.000000 1.662551
> 
> 
> Is there a reason why I shouldn't assign NULL instead of using rm()?
> As far as I understand it, the garbage collector will be equally
> efficient cleaning out the previous object when using rm(a) or a <-
> NULL.  Is there anything else I'm overlooking?  Am I adding overhead
> somewhere else?
> 
> /Henrik
> 
> 
> PS. With the above toy example one can obviously be a bit smarter by using:
> 
> t4 <- system.time({for (k in 1:ncol(x)) {
>   a <- x[,k]
>   colSum <- sum(a)
>   a <- x[k,]
>   rowSum <- sum(a)
> }
> rm(list="a")
> })
> 
> but that's not my point.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jony.hudson at imperial.ac.uk  Sat May 25 23:58:28 2013
From: jony.hudson at imperial.ac.uk (Jony Hudson)
Date: Sat, 25 May 2013 22:58:28 +0100
Subject: [Rd] R in the browser ...
Message-ID: <9396DC90-49CD-41E2-A473-F12AC819E24F@imperial.ac.uk>

Hi all,

 I hope you'll forgive me - I don't plan to start using this list as my blog - but given the discussion following my last post I thought people on here might be interested to see some progress. This is a minimal build of R, cross-compiled from C/Fortran to javascript with emscripten - to be clear, nothing is running server-side, this is all running in the browser's JS engine. The user experience is rather lacking at the minute, much is missing (see below), and there are no compiler optimisations applied (also below) but still, it kind of works. Have a play here:

http://r-in-the-browser.herokuapp.com/

(WARNING: 20MB HTML file, 3.5MB gzipped  + 7MB data file). It goes without saying that you'll want to use a modern web browser to look at it! It works in the latest chrome, firefox, and safari (although I can't see the session output until after I q() in my safari :-() It also seems to run on my iPad, after a very long start-up wait, but it shares the problem of desktop safari that you have to work blind. It also runs on my Android phone, although it takes a _very_ long time to start up - something like 15 minutes!
Picture of a session running on an iPad: http://imgur.com/jzYL5wf
Picture of a session running on a Nexus 4 phone: http://imgur.com/bjDA95j

So far, it's only the core of R - the only package it is loading is "base". The other default packages build mostly, I think, but I haven't yet figured out how to patch the dynamic loading to pull the "native" code in at the right time. Also, nothing using LAPACK works as R is trying to dynamically load that too.

Getting it to build was fiddly, but that probably has a lot to do with my lack of experience building anything unix-y, and this being the first time I've used autotools (I read in the manual that their aim was not to make it user-friendly for maintainers, but rather for users. Well, chapeau to them as they've certainly achieved their aims). In rough outline (and from memory):
- I used f2c to convert the Fortran sources in appl, main and extra/blas to c, and modified the Makefile.in's accordingly - also adding instruction to link in a version of libf2c that I'd pre-compiled to LLVM bitcode.
- I had to manually hack on the configure.h file to remove references to some functions that don't seem to exist in emscripten: ccosh, cexp etc.
- I also added code to set SSIZE_MAX and R_XLEN_T_MAX to sensible values (thanks Peter).
- I hacked connections.c as there were some duplicate case statements. I think this was because the ./configure was getting confused over the size of some basic types. I suspect all of above hacks could be avoided if I understood autotools better.
- I tweaked configure.h again by hand to disable ARPA_INET. I think there's a problem in emscripten's inet header files, but am not sure yet.
- I had to hack xdr_mem.c to force it to use an appropriate ntohl and htonl. Again, probably an autotools problem that I'm not understanding.
- This was enough to run make and have it build LLVM-bitcode for the main source tree (except, bizarrely mkdtemp.c which I had to compile by hand). The make errors out before the end, but it gets far enough. I could then link all of the generated bitcode together and convert to JS. The "virtual filesystem" for the JS code was populated with the contents of /usr/local/lib/R which I trimmed down a bit to get rid of stuff that wasn't going to work.
- The emscripten libc implementation is incomplete so I had to stub out some functions that are probably quite important - glob() and globfree(). That really needs to be fixed! I also stubbed out __locale_mb_cur_max to return some value or other, as I wasn't sure where it was supposed to come from, and I was getting tired.

At the moment all compiler optimisations are turned off, which makes a big difference to code size and performance. The problem is that it appears that some of the R code uses unsafe function pointer casting, which causes trouble with the way that emscripten optimises code (I think it's that it depends on each function having a well-defined type that the JS interpreter can be sure of). I haven't looked into where these casts are, and how difficult it would be to make them safe, but hopefully they're not too pervasive. 

Anyway, it's just a start, but I'm pretty pleased with it :-)


Jony

--
Centre for Cold Matter, The Blackett Laboratory,
Imperial College London, London SW7 2BW
T: +44 (0)207 5947741
http://www.imperial.ac.uk/people/jony.hudson
http://www.imperial.ac.uk/ccm/research/edm
http://www.monkeycruncher.org
http://j-star.org/
--


From simon.urbanek at r-project.org  Sun May 26 01:38:40 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 25 May 2013 19:38:40 -0400
Subject: [Rd] Assigning NULL to large variables is much faster than rm()
	- any reason why I should still use rm()?
In-Reply-To: <CAFDcVCRXmf+gxBA2joK_V0fxM9Pmh-A-h9S+Tkx_meNtNMLtow@mail.gmail.com>
References: <CAFDcVCRXmf+gxBA2joK_V0fxM9Pmh-A-h9S+Tkx_meNtNMLtow@mail.gmail.com>
Message-ID: <5A6F918E-2B38-4E6C-A8BA-1CE28ACA6B07@r-project.org>

On May 25, 2013, at 3:48 PM, Henrik Bengtsson wrote:

> Hi,
> 
> in my packages/functions/code I tend to remove large temporary
> variables as soon as possible, e.g. large intermediate vectors used in
> iterations.  I sometimes also have the habit of doing this to make it
> explicit in the source code when a temporary object is no longer
> needed.  However, I did notice that this can add a noticeable overhead
> when the rest of the iteration step does not take that much time.
> 
> Trying to speed this up, I first noticed that rm(list="a") is much
> faster than rm(a).  While at it, I realized that for the purpose of
> keeping the memory footprint small, I can equally well reassign the
> variable the value of a small object (e.g. a <- NULL), which is
> significantly faster than using rm().
> 

Yes, as you probably noticed rm() is a quite complex function because it has to deal with different ways to specify input etc. 
When you remove that overhead (by calling .Internal(remove("a", parent.frame(), FALSE))), you get the same performance as the assignment.
If you really want to go overboard, you can define your own function:

SEXP rm(SEXP x, SEXP rho) { setVar(x, R_UnboundValue, rho); return R_NilValue; }
poof <- function(x) .Call(rm_C, substitute(x), parent.frame())

That will be faster than anything else (mainly because it avoids the trip through strings as it can use the symbol directly).

But as Bill noted - it practice I'd recommend using either local() or functions to control the scope - using rm() or assignments seems too error-prone to me.

Cheers,
Simon



> SOME BENCHMARKS:
> A toy example imitating an iterative algorithm with "large" temporary objects.
> 
> x <- matrix(rnorm(100e6), ncol=10e3)
> 
> t1 <- system.time(for (k in 1:ncol(x)) {
>  a <- x[,k]
>  colSum <- sum(a)
>  rm(a) # Not needed anymore
>  b <- x[k,]
>  rowSum <- sum(b)
>  rm(b) # Not needed anymore
> })
> 
> t2 <- system.time(for (k in 1:ncol(x)) {
>  a <- x[,k]
>  colSum <- sum(a)
>  rm(list="a") # Not needed anymore
>  b <- x[k,]
>  rowSum <- sum(b)
>  rm(list="b") # Not needed anymore
> })
> 
> t3 <- system.time(for (k in 1:ncol(x)) {
>  a <- x[,k]
>  colSum <- sum(a)
>  a <- NULL # Not needed anymore
>  b <- x[k,]
>  rowSum <- sum(b)
>  b <- NULL # Not needed anymore
> })
> 
>> t1
>   user  system elapsed
>   8.03    0.00    8.08
>> t1/t2
>    user   system  elapsed
> 1.322900 0.000000 1.320261
>> t1/t3
>    user   system  elapsed
> 1.715812 0.000000 1.662551
> 
> 
> Is there a reason why I shouldn't assign NULL instead of using rm()?
> As far as I understand it, the garbage collector will be equally
> efficient cleaning out the previous object when using rm(a) or a <-
> NULL.  Is there anything else I'm overlooking?  Am I adding overhead
> somewhere else?
> 
> /Henrik
> 
> 
> PS. With the above toy example one can obviously be a bit smarter by using:
> 
> t4 <- system.time({for (k in 1:ncol(x)) {
>  a <- x[,k]
>  colSum <- sum(a)
>  a <- x[k,]
>  rowSum <- sum(a)
> }
> rm(list="a")
> })
> 
> but that's not my point.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From hb at biostat.ucsf.edu  Sun May 26 02:10:59 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sat, 25 May 2013 17:10:59 -0700
Subject: [Rd] Assigning NULL to large variables is much faster than rm()
 - any reason why I should still use rm()?
In-Reply-To: <5A6F918E-2B38-4E6C-A8BA-1CE28ACA6B07@r-project.org>
References: <CAFDcVCRXmf+gxBA2joK_V0fxM9Pmh-A-h9S+Tkx_meNtNMLtow@mail.gmail.com>
	<5A6F918E-2B38-4E6C-A8BA-1CE28ACA6B07@r-project.org>
Message-ID: <CAFDcVCSaBqNfCEftVW1egVg0=H7tV3mAchzovmVKe8iDWYFvHw@mail.gmail.com>

On Sat, May 25, 2013 at 4:38 PM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
> On May 25, 2013, at 3:48 PM, Henrik Bengtsson wrote:
>
>> Hi,
>>
>> in my packages/functions/code I tend to remove large temporary
>> variables as soon as possible, e.g. large intermediate vectors used in
>> iterations.  I sometimes also have the habit of doing this to make it
>> explicit in the source code when a temporary object is no longer
>> needed.  However, I did notice that this can add a noticeable overhead
>> when the rest of the iteration step does not take that much time.
>>
>> Trying to speed this up, I first noticed that rm(list="a") is much
>> faster than rm(a).  While at it, I realized that for the purpose of
>> keeping the memory footprint small, I can equally well reassign the
>> variable the value of a small object (e.g. a <- NULL), which is
>> significantly faster than using rm().
>>
>
> Yes, as you probably noticed rm() is a quite complex function because it has to deal with different ways to specify input etc.
> When you remove that overhead (by calling .Internal(remove("a", parent.frame(), FALSE))), you get the same performance as the assignment.
> If you really want to go overboard, you can define your own function:
>
> SEXP rm(SEXP x, SEXP rho) { setVar(x, R_UnboundValue, rho); return R_NilValue; }
> poof <- function(x) .Call(rm_C, substitute(x), parent.frame())
>
> That will be faster than anything else (mainly because it avoids the trip through strings as it can use the symbol directly).

Thanks for this one.  This is useful - I did try to follow where
.Internal(remove, ...), but got lost in the internal structures.

Of course, I'd love to see such a function in 'base' itself.  Having
such a well defined and narrow function for removing a variable in the
current environment may also be useful for 'codetools'/'R CMD check'
such that code inspection can detect undefined variables in the case
they used to be defined but later have been removed.  Technically rm()
allows for that too, but I can see how such a task quickly gets
complicated when arguments 'list', 'envir' and 'inherits' are
involved.

>
> But as Bill noted - it practice I'd recommend using either local() or functions to control the scope - using rm() or assignments seems too error-prone to me.

I didn't mention it, but another reason I use rm() a lot is actually
so R can catch my programming mistakes (I'm maintaining 100,000+ lines
of code), i.e. the opposite to being error prone.  For instance, by
doing rm(tmp) as soon as possible, R will give me the run-time error
"Error: object 'tmp' not found" in case I use it by mistake later on.
As said above, potential the codetools/'R CMD check' will be able to
detect this already at check time [above].  With tmp <- NULL I'll
loose a bit of this protection, although another run-time error is
likely to occur a bit later.

Using local()/local functions are obviously alternatives for the above.

Thanks both (and sorry about the game - though it was an entertaining one)

/Henrik

>
> Cheers,
> Simon
>
>
>
>> SOME BENCHMARKS:
>> A toy example imitating an iterative algorithm with "large" temporary objects.
>>
>> x <- matrix(rnorm(100e6), ncol=10e3)
>>
>> t1 <- system.time(for (k in 1:ncol(x)) {
>>  a <- x[,k]
>>  colSum <- sum(a)
>>  rm(a) # Not needed anymore
>>  b <- x[k,]
>>  rowSum <- sum(b)
>>  rm(b) # Not needed anymore
>> })
>>
>> t2 <- system.time(for (k in 1:ncol(x)) {
>>  a <- x[,k]
>>  colSum <- sum(a)
>>  rm(list="a") # Not needed anymore
>>  b <- x[k,]
>>  rowSum <- sum(b)
>>  rm(list="b") # Not needed anymore
>> })
>>
>> t3 <- system.time(for (k in 1:ncol(x)) {
>>  a <- x[,k]
>>  colSum <- sum(a)
>>  a <- NULL # Not needed anymore
>>  b <- x[k,]
>>  rowSum <- sum(b)
>>  b <- NULL # Not needed anymore
>> })
>>
>>> t1
>>   user  system elapsed
>>   8.03    0.00    8.08
>>> t1/t2
>>    user   system  elapsed
>> 1.322900 0.000000 1.320261
>>> t1/t3
>>    user   system  elapsed
>> 1.715812 0.000000 1.662551
>>
>>
>> Is there a reason why I shouldn't assign NULL instead of using rm()?
>> As far as I understand it, the garbage collector will be equally
>> efficient cleaning out the previous object when using rm(a) or a <-
>> NULL.  Is there anything else I'm overlooking?  Am I adding overhead
>> somewhere else?
>>
>> /Henrik
>>
>>
>> PS. With the above toy example one can obviously be a bit smarter by using:
>>
>> t4 <- system.time({for (k in 1:ncol(x)) {
>>  a <- x[,k]
>>  colSum <- sum(a)
>>  a <- x[k,]
>>  rowSum <- sum(a)
>> }
>> rm(list="a")
>> })
>>
>> but that's not my point.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>


From suharto_anggono at yahoo.com  Mon May 27 07:36:08 2013
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Sun, 26 May 2013 22:36:08 -0700 (PDT)
Subject: [Rd] 'rbind' in example(make.unique)
Message-ID: <1369632968.15516.YahooMailClassic@web125106.mail.ne1.yahoo.com>

> rbind(data.frame(x = 1), data.frame(x = 2), data.frame(x = 3))
  x
1 1
2 2
3 3
> rbind(rbind(data.frame(x = 1), data.frame(x = 2)), data.frame(x = 3))
  x
1 1
2 2
3 3

Above is the result of running the last two lines in "Examples" of 'make.unique'. I don't see the work of 'make.unique' there. It used to work, when there is no automatic row names for data frame.

Perhaps a simpler example is adding columns.

> data.frame(x = 1, x = 2, x = 3)
  x x.1 x.2
1 1   2   3
> data.frame(data.frame(x = 1, x = 2), x = 3)
  x x.1 x.2
1 1   2   3

> sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.0.1


From bquistorff at gmail.com  Mon May 27 16:10:27 2013
From: bquistorff at gmail.com (Brian Quistorff)
Date: Mon, 27 May 2013 10:10:27 -0400
Subject: [Rd] Variable labels in a data.frame
Message-ID: <CAAEVvsBTMGbYg8D3P2xKKCVdP7VJWBJv=wqrqikbKTV0ZSrYEg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130527/33715633/attachment.pl>

From Avraham.Adler at guycarp.com  Wed May 29 00:36:47 2013
From: Avraham.Adler at guycarp.com (Adler, Avraham)
Date: Tue, 28 May 2013 17:36:47 -0500
Subject: [Rd] R-3.0.1 - "transient" make check failure in splines-EX.r
Message-ID: <93A2161604A30C4ABE14AC35CAFC8422DDFC1D81@USDFW11XM32.mercer.com>

 
Hello.

I seem to be having the same problem that Paul had in the thread titled "[Rd] R 2.15.2 make check failure on 32-bit --with-blas="-lgoto2"" from October of last year <https://stat.ethz.ch/pipermail/r-devel/2012-October/065103.html> Unfortunately, that thread ended without an answer to his last question.

Briefly, I am trying to compile an Rblas for Windows NT 32bit using OpenBlas (successor to GotoBlas) (Nehalem - corei7), and the compiled version passes all tests except for the "splines-Ex" test in the exact same place that Paul had issues:

~~~~
> stopifnot(identical(ns(x), ns(x, df = 1)),
+           identical(ns(x, df = 2), ns(x, df = 2, knots = NULL)), # not true till 2.15.2
+           !is.null(kk <- attr(ns(x), "knots")), # not true till 1.5.1
+           length(kk) == 0)
Error: identical(ns(x, df = 2), ns(x, df = 2, knots = NULL)) is not TRUE
~~~~

Yet, opening up R and running the actual code shows that the error is transient:

~~~~
> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
[1] TRUE
> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
[1] TRUE
> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
[1] TRUE
> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
[1] FALSE
> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
[1] TRUE
> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
[1] TRUE
> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
[1] TRUE
> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
[1] TRUE
> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
[1] TRUE
> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
[1] FALSE
~~~~

This is the only error I have on the 32-bit version, I believe (trying to build a blas for 64-bit on SandyBridge is a completely different kettle of fish that is causing me to pull out what little hair I have left), and if it can be solved that would be great.

Thank you,

Avraham


 


From stefan.holzheu at bayceer.uni-bayreuth.de  Tue May 28 17:18:10 2013
From: stefan.holzheu at bayceer.uni-bayreuth.de (Stefan Holzheu)
Date: Tue, 28 May 2013 17:18:10 +0200
Subject: [Rd] Customizing tab completion for package functions?
Message-ID: <51A4CAB2.6080706@bayceer.uni-bayreuth.de>

Dear all,
I've been searching around for some hours now, but did not find a solution.

Is there a way to customize the tab completion behavior of R?

In more detail. We have a R packages called bayeos. This package allows 
users to access a time series database via XML-RPC directly from R. The 
time series are organized in folders. There is a function in the 
packages called "bayeos.cd" allowing the user to change the "time series 
folder" e.g.

 > bayeos.cd('Local Gateway')
All Folders / Local Gateway /
200004 	parent_folder	..
200224 	 messung_ordner 	 Bayreuth Meteo Board
...

When typing

bayeos.cd('

and pressing tab the filename completion hooks in which gives no 
reasonable completions. So my question.
Is there a way to replace the filename completion by a custom completion 
function just for a specific package function?

Best regards

Stefan

-- 
--
Dr. Stefan Holzheu
Bayreuth Center of Ecology and Environmental Research
BayCEER
University of Bayreuth
Germany


From Avraham.Adler at guycarp.com  Wed May 29 19:23:55 2013
From: Avraham.Adler at guycarp.com (Adler, Avraham)
Date: Wed, 29 May 2013 12:23:55 -0500
Subject: [Rd] "Unable to optimize" error returned in factanal using R-3.0.1,
 Windows 64 bit, and OpenBLAS
Message-ID: <93A2161604A30C4ABE14AC35CAFC8422DE335B4B@USDFW11XM32.mercer.com>

Hello,

I have been trying for weeks to compile a 64-bit Rblas. I started with ATLAS where I have had success in the past, but 64 bit was not behaving, and as each compilation takes between 9 and 12 hours, "test, check, and revise" was not going to be really viable. I therefore switched to OpenBLas (OPBL). I was successful in compiling R-3.0.1 and an OPBL-based BLAS for Windows 64bit SANDYBRIDGE (Corei7-avx) which passes all of OPBL's internal checks, and all but *one* of R's checks (it passes the spline one failed by the 32-bit version which I asked about yesterday). Well, it fails the same procedure twice, but not all the time.

The error is found in a call to the `factanal` procedure, specifically the call to `optim` therein, and it returns an error code "NEW_X", which I have never seen before. It fails this call in the checks for both stats.R and datasets.R, but does not fail them all, and for those it works, it returns the proper answers.

The first call that fails is in statsEx.Rout

		fa <- factanal( ~., 2, data = swiss)
		Error in factanal(~., 2, data = swiss) :
		  unable to optimize from this starting value 

Interestingly, using 1 or 3 as the value for factor works fine, it is 2 which fails.

The other failed call is in datasetsEx, and it is...

		(Harman23.FA <- factanal(factors = 1, covmat = Harman23.cor)) 

		...other code...

		for(factors in 2:4) print(update(Harman23.FA, factors = factors)) 

...when the value for factors is 4 (1, 2, and 3 work fine).

I understand that "unable to optimize" can only come from no convergent "best fit" being found in the `factanal.fit.mle` procedure. Some detective work shows that the failure is in the call to `optim`. Specifically, when the  call __passes__, it returns:

		> nfit

		Call:
		NULL

		Uniquenesses:
			   Fertility      Agriculture      Examination        Education
				   0.420            0.492            0.270            0.005
				Catholic Infant.Mortality
				   0.061            0.960

		Loadings:
						 Factor1 Factor2
		Fertility        -0.674   0.356
		Agriculture      -0.648   0.297
		Examination       0.713  -0.471
		Education         0.997
		Catholic         -0.178   0.953
		Infant.Mortality -0.104   0.169

					   Factor1 Factor2
		SS loadings      2.419   1.373
		Proportion Var   0.403   0.229
		Cumulative Var   0.403   0.632

		The degrees of freedom for the model is 4 and the fit was 0.5017
		> nfit$converged
		[1] TRUE

But when it __fails__ it returns:

		> nfit

		Call:
		NULL

		Uniquenesses:
			   Fertility      Agriculture      Examination        Education
				   0.417            0.487            0.258            0.012
				Catholic Infant.Mortality
				   0.097            0.951

		Loadings:
						 Factor1 Factor2
		Fertility        -0.683   0.340
		Agriculture      -0.658   0.282
		Examination       0.728  -0.461
		Education         0.993
		Catholic         -0.203   0.929
		Infant.Mortality -0.110   0.171

					   Factor1 Factor2
		SS loadings      2.469   1.302
		Proportion Var   0.411   0.217
		Cumulative Var   0.411   0.628

		The degrees of freedom for the model is 4 and the fit was 0.5042
		> nfit$converged
		[1] FALSE

This results in a different set of starting values being passed to `optim`, namely:

__FAIL__:

		$par
							  [,1]
		Fertility        0.4180782
		Agriculture      0.4898004
		Examination      0.2608759
		Education        0.0005000
		Catholic         0.1028010
		Infant.Mortality 0.9454609

		$value
		[1] 0.5015197

		$counts
		function gradient
			 302      302

		$convergence
		[1] 1

		$message
		[1] "NEW_X"

_____________________________________________

__PASS__:

		$par
							   [,1]
		Fertility        0.41936338
		Agriculture      0.49205978
		Examination      0.26976286
		Education        0.00050000
		Catholic         0.06973751
		Infant.Mortality 0.96007318

		$value
		[1] 0.5008949

		$counts
		function gradient
			  22       22

		$convergence
		[1] 0

		$message
		[1] "CONVERGENCE: REL_REDUCTION_OF_F <= FACTR*EPSMCH"

I have never seen that particular failure message from `optim` before, "NEW_X", and I cannot locate what it means. It is possible, if not probably, that it has to do with one of the functions internal to `factanal.fit.mle`, possibly the call to `eigen` as I presume that calls Rblas, but without knowing what the error means, I'm not sure what else to do. I know the errors are significant, as the SurviveGoto2 Blas's compiled by Dr. Nakama do not exhibit these errors, but I have no idea as to what is causing it.

What I am hoping is that one of the experts on this list (perhaps one of the members of the core team who helped write `factanal`) can recognize what may be causing the call to `optim` to fails sometimes, and could suggest some possible investigatory paths or explain why it may not be possible to be solved. I'd also be happy to e-mail or post the compiled dll's if anyone wants to look at them directly, although that would require access to a SandyBridge running Windows 64 bit.

Thank you very much,

Avraham Adler

From bbolker at gmail.com  Wed May 29 19:58:03 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 29 May 2013 13:58:03 -0400
Subject: [Rd] quick question about glm() example
Message-ID: <51A641AB.1020404@gmail.com>


  I don't have a copy of Dobson (1990) from which the glm.D93 example is
taken in example("glm"), but I'm strongly suspecting that these are
made-up data rather than real data; the means of the responses within
each treatment are _identical_ (equal to 16 2/3), so two of the
parameters are estimated as being zero (within machine tolerance).  (At
this moment I don't understand why the means rather than the geometric
means being identical is what matters ...)

  This therefore feels like a somewhat strange (i.e. non-generic)
example to use (although I know it's been that way for a long time).

  Perhaps more importantly, the example illustrates the use of glm()
without a data= argument, which I think should not generally be
encouraged.  I would prefer to see the example written as:

d.AD <- data.frame(
 counts=c(18,17,15,20,10,20,25,13,12),
 outcome=gl(3,1,9),
 treatment=gl(3,3))

print(d.AD)

 glm.D93 <- glm(counts ~ outcome + treatment, family = poisson(),
       data=d.AD)

  Thoughts?

  Ben Bolker


From pdalgd at gmail.com  Wed May 29 21:05:23 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 29 May 2013 21:05:23 +0200
Subject: [Rd] quick question about glm() example
In-Reply-To: <51A641AB.1020404@gmail.com>
References: <51A641AB.1020404@gmail.com>
Message-ID: <966FB96F-7ADB-4D95-988C-FA5EBAD0CDFC@gmail.com>


On May 29, 2013, at 19:58 , Ben Bolker wrote:

> 
>  I don't have a copy of Dobson (1990) from which the glm.D93 example is
> taken in example("glm"), but I'm strongly suspecting that these are
> made-up data rather than real data; the means of the responses within
> each treatment are _identical_ (equal to 16 2/3), so two of the
> parameters are estimated as being zero (within machine tolerance).  (At
> this moment I don't understand why the means rather than the geometric
> means being identical is what matters ...)

I don't have it to hand either (although I could get to it tomorrow -- a colleague is teaching from it). However, I don't think there's anything particularly fake about the data, but they do seem to come from a designed trial, in which 3 groups of 50 people are assigned different treatments and a 3-level outcome is recorded. 

So in reality, it is a model for three multinomials, but there's a standard "trick" that this has likelihood inference equivalent to that of a multiplicative Poisson model. The likelihood for the Poisson model factorizes into the marginal distribution of the treatment totals and the conditional distribution of the table given the totals. The latter is the set of multinomials. If you ensure a suitable separation of parameters and that the model for the marginals is saturated, you end up with likelihood inference for the conditional distributions. (This may require some pen-and-paper work to become intelligible...)

The ML parameters in a multiplicative Poisson model (lambda_ij=alpha_i*beta_j) are proportional to the row and column means, and in the GLM framework parameters are the log of that, subject to some resolution of the overparametrization issue. 

The outcome parameters are likely of no interest, since they describe log-ratios of frequencies of the outcome categories, so the whole thing is about the goodness of fit, as measured by the

Residual deviance:  5.1291  on 4  degrees of freedom

which is the LRT equivalent of the Pearson Chi-square for the table:

> chisq.test(matrix(d.AD$counts,3))

	Pearson's Chi-squared test

data:  matrix(d.AD$counts, 3)
X-squared = 5.1732, df = 4, p-value = 0.27

In fact, Rao's score test for an interaction term is exactly the Pearson Chisquare:

> anova(glm.D93, update(glm.D93,~outcome*treatment), test="Rao")
Analysis of Deviance Table

Model 1: counts ~ outcome + treatment
Model 2: counts ~ outcome + treatment + outcome:treatment
  Resid. Df Resid. Dev Df Deviance    Rao Pr(>Chi)
1         4     5.1291                            
2         0     0.0000  4   5.1291 5.1732     0.27



> 
>  This therefore feels like a somewhat strange (i.e. non-generic)
> example to use (although I know it's been that way for a long time).
> 
>  Perhaps more importantly, the example illustrates the use of glm()
> without a data= argument, which I think should not generally be
> encouraged.  I would prefer to see the example written as:
> 
> d.AD <- data.frame(
> counts=c(18,17,15,20,10,20,25,13,12),
> outcome=gl(3,1,9),
> treatment=gl(3,3))
> 
> print(d.AD)
> 
> glm.D93 <- glm(counts ~ outcome + treatment, family = poisson(),
>       data=d.AD)
> 
>  Thoughts?
> 
>  Ben Bolker
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From bbolker at gmail.com  Wed May 29 22:09:09 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 29 May 2013 16:09:09 -0400
Subject: [Rd] quick question about glm() example
In-Reply-To: <966FB96F-7ADB-4D95-988C-FA5EBAD0CDFC@gmail.com>
References: <51A641AB.1020404@gmail.com>
	<966FB96F-7ADB-4D95-988C-FA5EBAD0CDFC@gmail.com>
Message-ID: <51A66065.5000804@gmail.com>

On 13-05-29 03:05 PM, peter dalgaard wrote:
> 
> On May 29, 2013, at 19:58 , Ben Bolker wrote:
> 
>> 
>> I don't have a copy of Dobson (1990) from which the glm.D93 example
>> is taken in example("glm"), but I'm strongly suspecting that these
>> are made-up data rather than real data; the means of the responses
>> within each treatment are _identical_ (equal to 16 2/3), so two of
>> the parameters are estimated as being zero (within machine
>> tolerance).  (At this moment I don't understand why the means
>> rather than the geometric means being identical is what matters
>> ...)
> 
> I don't have it to hand either (although I could get to it tomorrow
> -- a colleague is teaching from it). However, I don't think there's
> anything particularly fake about the data, but they do seem to come
> from a designed trial, in which 3 groups of 50 people are assigned
> different treatments and a 3-level outcome is recorded.
> 
> So in reality, it is a model for three multinomials, but there's a
> standard "trick" that this has likelihood inference equivalent to
> that of a multiplicative Poisson model. The likelihood for the
> Poisson model factorizes into the marginal distribution of the
> treatment totals and the conditional distribution of the table given
> the totals. The latter is the set of multinomials. If you ensure a
> suitable separation of parameters and that the model for the
> marginals is saturated, you end up with likelihood inference for the
> conditional distributions. (This may require some pen-and-paper work
> to become intelligible...)
> 
> The ML parameters in a multiplicative Poisson model
> (lambda_ij=alpha_i*beta_j) are proportional to the row and column
> means, and in the GLM framework parameters are the log of that,
> subject to some resolution of the overparametrization issue.
> 
> The outcome parameters are likely of no interest, since they describe
> log-ratios of frequencies of the outcome categories, so the whole
> thing is about the goodness of fit, as measured by the
> 
> Residual deviance:  5.1291  on 4  degrees of freedom
> 
> which is the LRT equivalent of the Pearson Chi-square for the table:
> 
>> chisq.test(matrix(d.AD$counts,3))
> 
> Pearson's Chi-squared test
> 
> data:  matrix(d.AD$counts, 3) X-squared = 5.1732, df = 4, p-value =
> 0.27
> 
> In fact, Rao's score test for an interaction term is exactly the
> Pearson Chisquare:
> 
>> anova(glm.D93, update(glm.D93,~outcome*treatment), test="Rao")
> Analysis of Deviance Table
> 
> Model 1: counts ~ outcome + treatment Model 2: counts ~ outcome +
> treatment + outcome:treatment Resid. Df Resid. Dev Df Deviance    Rao
> Pr(>Chi) 1         4     5.1291 2         0     0.0000  4   5.1291
> 5.1732     0.27

  Thanks, that's extremely helpful.  The example still seems slightly
non-generic as a very first example to use with ?glm, but it makes more
sense now. [My (increasingly tiny) nit-picks would be that
anova(glm.D93) and summary(glm.D93) are presented without comment,
implying that they would be sensible things to try in this case, rather
than the appropriate statistical tests, which would be the Rao test
above or the LRT equivalent:
anova(glm.D93,update(glm.D93,~outcome*treatment),test="Chisq").  I would
say one should try to pick an example where a simple application of the
standard accessors (anova(), summary(), drop1()) would be more easily
interpretable.]

  Any opinions about the use or non-use of the data= argument?

 Ben Bolker


> 
> 
> 
>> 
>> This therefore feels like a somewhat strange (i.e. non-generic) 
>> example to use (although I know it's been that way for a long
>> time).
>> 
>> Perhaps more importantly, the example illustrates the use of glm() 
>> without a data= argument, which I think should not generally be 
>> encouraged.  I would prefer to see the example written as:
>> 
>> d.AD <- data.frame( counts=c(18,17,15,20,10,20,25,13,12), 
>> outcome=gl(3,1,9), treatment=gl(3,3))
>> 
>> print(d.AD)
>> 
>> glm.D93 <- glm(counts ~ outcome + treatment, family = poisson(), 
>> data=d.AD)
>> 
>> Thoughts?
>> 
>> Ben Bolker
>> 
>> ______________________________________________ 
>> R-devel at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From peter.langfelder at gmail.com  Thu May 30 00:38:00 2013
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Wed, 29 May 2013 15:38:00 -0700
Subject: [Rd] What is preferable - a single large package or a few smaller
	packages?
Message-ID: <CA+hbrhVtuHJpw1SLQmqAQiXy1NBUn7qMGMrDJFG9iNoWvxPF5A@mail.gmail.com>

Hi all,

I maintain the WGCNA package which at present has nearly 200
functions. In the future there will be more. Curious whether it would
be preferable or useful to split the package into a couple different
ones with different aims. Obviously, when one calls a function in R,
package name spaces have to be traversed to find the matching name -
does the speed of this depend on how functions are  partitioned into
packages? Any other considerations? My knowledge of R internals in
this regard is pretty non-existent - thanks for any pointers.

Best,

Peter


From hpages at fhcrc.org  Thu May 30 01:48:09 2013
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Wed, 29 May 2013 16:48:09 -0700
Subject: [Rd] What is preferable - a single large package or a few
 smaller packages?
In-Reply-To: <CA+hbrhVtuHJpw1SLQmqAQiXy1NBUn7qMGMrDJFG9iNoWvxPF5A@mail.gmail.com>
References: <CA+hbrhVtuHJpw1SLQmqAQiXy1NBUn7qMGMrDJFG9iNoWvxPF5A@mail.gmail.com>
Message-ID: <51A693B9.3050006@fhcrc.org>

Hi Peter,

On 05/29/2013 03:38 PM, Peter Langfelder wrote:
> Hi all,
>
> I maintain the WGCNA package which at present has nearly 200
> functions. In the future there will be more. Curious whether it would
> be preferable or useful to split the package into a couple different
> ones with different aims. Obviously, when one calls a function in R,
> package name spaces have to be traversed to find the matching name -
> does the speed of this depend on how functions are  partitioned into
> packages? Any other considerations?

Other important considerations are maintainability and
user-friendliness. If you think the package can keep growing and still
remain relatively easy to maintain, then maybe you don't need to split
it. But if the package becomes too hard to maintain and/or can
naturally be divided into more or less independent departments, and
if the end-user generally doesn't need all functionalities from all
departments for a typical work flow, then you might want to split.
That will benefit both: the user and you. That will also make it easier
to have other people collaborate to the whole thing (if one day you
decide you need some help for that).

The impact on the speed of function name lookup would be the last thing
I would worry about.

My 2 cents.

H.

> My knowledge of R internals in
> this regard is pretty non-existent - thanks for any pointers.
>
> Best,
>
> Peter
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From pgilbert902 at gmail.com  Thu May 30 06:25:35 2013
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Thu, 30 May 2013 00:25:35 -0400
Subject: [Rd] R-3.0.1 - "transient" make check failure in splines-EX.r
In-Reply-To: <93A2161604A30C4ABE14AC35CAFC8422DDFC1D81@USDFW11XM32.mercer.com>
References: <93A2161604A30C4ABE14AC35CAFC8422DDFC1D81@USDFW11XM32.mercer.com>
Message-ID: <51A6D4BF.2080507@gmail.com>

Avraham

I resolved this only by switching to a different BLAS on the 32 bit 
machine.Since no one else seemed to be having problems, I considered it 
possible that there was a hardware issue on my old 32 bit machine. The R 
check test failed somewhat randomly, but often. most disconcertingly, it 
failed because it gives different answers. If you source the code in an 
R session a few times you have no trouble reproducing this. It gives the 
impression of an improperly zeroed matrix.

(All this from memory, I'm on the road.)

Paul

On 13-05-28 06:36 PM, Adler, Avraham wrote:
>
> Hello.
>
> I seem to be having the same problem that Paul had in the thread titled "[Rd] R 2.15.2 make check failure on 32-bit --with-blas="-lgoto2"" from October of last year <https://stat.ethz.ch/pipermail/r-devel/2012-October/065103.html> Unfortunately, that thread ended without an answer to his last question.
>
> Briefly, I am trying to compile an Rblas for Windows NT 32bit using OpenBlas (successor to GotoBlas) (Nehalem - corei7), and the compiled version passes all tests except for the "splines-Ex" test in the exact same place that Paul had issues:
>
> ~~~~
>> stopifnot(identical(ns(x), ns(x, df = 1)),
> +           identical(ns(x, df = 2), ns(x, df = 2, knots = NULL)), # not true till 2.15.2
> +           !is.null(kk <- attr(ns(x), "knots")), # not true till 1.5.1
> +           length(kk) == 0)
> Error: identical(ns(x, df = 2), ns(x, df = 2, knots = NULL)) is not TRUE
> ~~~~
>
> Yet, opening up R and running the actual code shows that the error is transient:
>
> ~~~~
>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> [1] TRUE
>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> [1] TRUE
>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> [1] TRUE
>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> [1] FALSE
>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> [1] TRUE
>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> [1] TRUE
>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> [1] TRUE
>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> [1] TRUE
>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> [1] TRUE
>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> [1] FALSE
> ~~~~
>
> This is the only error I have on the 32-bit version, I believe (trying to build a blas for 64-bit on SandyBridge is a completely different kettle of fish that is causing me to pull out what little hair I have left), and if it can be solved that would be great.
>
> Thank you,
>
> Avraham
>
>
>
>
>


From ripley at stats.ox.ac.uk  Thu May 30 10:01:14 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 30 May 2013 09:01:14 +0100
Subject: [Rd] What is preferable - a single large package or a few
 smaller packages?
In-Reply-To: <CA+hbrhVtuHJpw1SLQmqAQiXy1NBUn7qMGMrDJFG9iNoWvxPF5A@mail.gmail.com>
References: <CA+hbrhVtuHJpw1SLQmqAQiXy1NBUn7qMGMrDJFG9iNoWvxPF5A@mail.gmail.com>
Message-ID: <51A7074A.40701@stats.ox.ac.uk>

On 29/05/2013 23:38, Peter Langfelder wrote:
> Hi all,
>
> I maintain the WGCNA package which at present has nearly 200
> functions. In the future there will be more. Curious whether it would
> be preferable or useful to split the package into a couple different
> ones with different aims. Obviously, when one calls a function in R,
> package name spaces have to be traversed to find the matching name -
> does the speed of this depend on how functions are  partitioned into
> packages? Any other considerations? My knowledge of R internals in
> this regard is pretty non-existent - thanks for any pointers.

Namespace environments are hashed, so essentially lookup is independent 
of size.  And since lazy-loading the memory footprint depends far more 
on what has been used in the session than the number of functions.

In any case, 200 functions is not a 'large' package.  'stats' has nearly 
1100 in its namespace ....  Performance for really large packages was 
improved to the point of a being a non-issue before 2.0.0.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Thu May 30 10:18:27 2013
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 30 May 2013 10:18:27 +0200
Subject: [Rd] RFC: a "safe" uniroot() function for future R
Message-ID: <20903.2899.135264.914688@stat.math.ethz.ch>

With main R releases only happening yearly in spring, now is
good time to consider *and* discuss new features for what we
often call "R-devel" and more officially is
  R Under development (unstable) (.....) -- "Unsuffered Consequences"

Here is one such example I hereby expose to public scrutiny:

A few minutes ago, I've committed the following to R-devel
(the 'trunk' in the svn repository for R):

------------------------------------------------------------------------
r62834 | maechler | 2013-05-30 10:01:33 +0200 (Thu, 30 May 2013) | 1 line
Changed paths:
   M doc/NEWS.Rd
   M src/library/stats/NAMESPACE
   M src/library/stats/R/nlm.R
   M src/library/stats/man/uniroot.Rd
   M tests/Examples/stats-Ex.Rout.save

new "safe" uniroot() =: unirootS()  [may change; see R-devel e-mail]
------------------------------------------------------------------------

The help file says

     ?unirootS()? is a ?safe? version of ?uniroot()?, built on
     ?uniroot()?, also useful as drop-in replacement of ?uniroot()? in
     some cases.  ?Safe? means searching for the correct ?interval =
     c(lower,upper)? if ?sign(f(x))? does not satisfy the requirements
     at the interval end points; see the ?Details? section.

We've had this function, called  safeUroot() in our package
copula for a while now, where an earlier not-exported version
has been in my package nor1mix even longer.
When I was tempted to introduce it into yet another CRAN package
I maintain,  I decided that this may be a sign that such a
simple [ utility for / generalization of ] uniroot() should
probably rather be added to R itself.

The function definition, also visible in R's devel.sources, at the bottom of
 https://svn.r-project.org/R/trunk/src/library/stats/R/nlm.R ,
shows that unirootS() is a wrapper for uniroot() and 
is in principle 100% back compatible to uniroot() itself for all
the cases where f(lower) and f(upper) are of differing sign and
hence uniroot() does not give a quick error.
unirootS() just has three new optional arguments, all with their
defaults set such as to remain uniroot() compatible.

So, one option instead of the currently commited one would be to
adopt  unirootS() as "the new uniroot()" and rename current
uniroot to .uniroot() {and still export both}.

The capital "S" in the function name and the 'Sig' name is of
course quite a matter of taste, and this case corresponds to my
taste, but even that is part of the RFC.


unirootS <- function(f, interval, ...,
		     lower = min(interval), upper = max(interval),
		     f.lower = f(lower, ...), f.upper = f(upper, ...),
		     Sig = NULL, check.conv = FALSE,
		     tol = .Machine$double.eps^0.25, maxiter = 1000, trace = 0)
{
    if (   is.null(Sig) && f.lower * f.upper > 0 ||
	is.numeric(Sig) && (Sig*f.lower > 0 || Sig*f.upper < 0)) {
	if(trace)
	    cat(sprintf("search in [%g,%g]%s", lower, upper,
			if(trace >= 2)"\n" else " ... "))
	Delta <- function(u) 0.01* pmax(1e-7, abs(u))
	## Two cases:
	if(is.null(Sig)) {
	    ## case 1)	'Sig' unspecified --> extend (lower, upper) at the same time
	    delta <- Delta(c(lower,upper))
	    while(isTRUE(f.lower*f.upper > 0) && any(iF <- is.finite(c(lower,upper)))) {
		if(iF[1]) f.lower <- f(lower <- lower - delta[1])
		if(iF[2]) f.upper <- f(upper <- upper + delta[2])
		if(trace >= 2)
		    cat(sprintf(" .. modified lower,upper: (%15g,%15g)\n",
				lower,upper))
		delta <- 2 * delta
	    }
	} else {
	    ## case 2) 'Sig' specified --> typically change only *one* of lower, upper
	    ## make sure we have Sig*f(lower) < 0 and Sig*f(upper) > 0:
	    delta <- Delta(lower)
	    while(isTRUE(Sig*f.lower > 0)) {
		f.lower <- f(lower <- lower - delta)
		if(trace) cat(sprintf(" .. modified lower: %g\n", lower))
		delta <- 2 * delta
	    }
	    delta <- Delta(upper)
	    while(isTRUE(Sig*f.upper < 0)) {
		f.upper <- f(upper <- upper + delta)
		if(trace) cat(sprintf(" .. modified upper: %g\n", upper))
		delta <- 2 * delta
	    }
	}
	if(trace && trace < 2)
	    cat(sprintf("extended to [%g, %g]\n", lower, upper))
    }
    if(!isTRUE(f.lower * f.upper <= 0))
	stop("did not succeed extending the interval endpoints for f(lower) * f(upper) <= 0")
    if(check.conv) {
	r <- tryCatch(uniroot(f, ..., lower=lower, upper=upper,
			      f.lower=f.lower, f.upper=f.upper,
			      tol=tol, maxiter=maxiter),
		      warning = function(w)w)
	if(inherits(r, "warning"))
	    stop("convergence problem in zero finding: ", r$message)
	else r
    }
    else
	uniroot(f, ..., lower=lower, upper=upper,
		f.lower=f.lower, f.upper=f.upper,
		tol=tol, maxiter=maxiter)
}

-----------

As said, your comments are very welcome!
Note that I'm less interested in variations which gain 10-20% in
speed benchmarks, rather I'd appreciate proposals for changes
that give a "better" (in your sense) user interface.

Martin Maechler, ETH Zurich


From murdoch.duncan at gmail.com  Thu May 30 11:27:57 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 30 May 2013 05:27:57 -0400
Subject: [Rd] RFC: a "safe" uniroot() function for future R
In-Reply-To: <20903.2899.135264.914688@stat.math.ethz.ch>
References: <20903.2899.135264.914688@stat.math.ethz.ch>
Message-ID: <CA+COuteo2iQHZyneAy+x7qsfB7G_Erc2GVXpcSTyxez-FVTuOQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130530/d70adccf/attachment.pl>

From maechler at stat.math.ethz.ch  Thu May 30 12:49:33 2013
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 30 May 2013 12:49:33 +0200
Subject: [Rd] RFC: a "safe" uniroot() function for future R
In-Reply-To: <CA+COuteo2iQHZyneAy+x7qsfB7G_Erc2GVXpcSTyxez-FVTuOQ@mail.gmail.com>
References: <20903.2899.135264.914688@stat.math.ethz.ch>
	<CA+COuteo2iQHZyneAy+x7qsfB7G_Erc2GVXpcSTyxez-FVTuOQ@mail.gmail.com>
Message-ID: <20903.11965.812306.509672@stat.math.ethz.ch>

>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
>>>>>     on Thu, 30 May 2013 05:27:57 -0400 writes:

    > On Thu, May 30, 2013 at 4:18 AM, Martin Maechler <maechler at stat.math.ethz.ch
    >> wrote:

    >> With main R releases only happening yearly in spring, now is
    >> good time to consider *and* discuss new features for what we
    >> often call "R-devel" and more officially is
    >> R Under development (unstable) (.....) -- "Unsuffered Consequences"
    >> 
    >> Here is one such example I hereby expose to public scrutiny:
    >> 
    >> A few minutes ago, I've committed the following to R-devel
    >> (the 'trunk' in the svn repository for R):
    >> 
    >> ------------------------------------------------------------------------
    >> r62834 | maechler | 2013-05-30 10:01:33 +0200 (Thu, 30 May 2013) | 1 line
    >> Changed paths:
    >> M doc/NEWS.Rd
    >> M src/library/stats/NAMESPACE
    >> M src/library/stats/R/nlm.R
    >> M src/library/stats/man/uniroot.Rd
    >> M tests/Examples/stats-Ex.Rout.save
    >> 
    >> new "safe" uniroot() =: unirootS()  [may change; see R-devel e-mail]
    >> ------------------------------------------------------------------------
    >> 
    >> The help file says
    >> 
    >> ?unirootS()? is a ?safe? version of ?uniroot()?, built on
    >> ?uniroot()?, also useful as drop-in replacement of ?uniroot()? in
    >> some cases.  ?Safe? means searching for the correct ?interval =
    >> c(lower,upper)? if ?sign(f(x))? does not satisfy the requirements
    >> at the interval end points; see the ?Details? section.
    >> 
    >> We've had this function, called  safeUroot() in our package
    >> copula for a while now, where an earlier not-exported version
    >> has been in my package nor1mix even longer.
    >> When I was tempted to introduce it into yet another CRAN package
    >> I maintain,  I decided that this may be a sign that such a
    >> simple [ utility for / generalization of ] uniroot() should
    >> probably rather be added to R itself.
    >> 
    >> The function definition, also visible in R's devel.sources, at the bottom
    >> of
    >> https://svn.r-project.org/R/trunk/src/library/stats/R/nlm.R ,
    >> shows that unirootS() is a wrapper for uniroot() and
    >> is in principle 100% back compatible to uniroot() itself for all
    >> the cases where f(lower) and f(upper) are of differing sign and
    >> hence uniroot() does not give a quick error.
    >> unirootS() just has three new optional arguments, all with their
    >> defaults set such as to remain uniroot() compatible.
    >> 
    >> So, one option instead of the currently commited one would be to
    >> adopt  unirootS() as "the new uniroot()" and rename current
    >> uniroot to .uniroot() {and still export both}.
    >> 

    > I would probably prefer this.

I did originally, too, but then became less sure about possible CRAN
checking "fallout"...

Merging the two functions into one, and not keeping the original
might be even the best solution, also easiest to maintain,
including documentation.

    >> 
    >> The capital "S" in the function name and the 'Sig' name is of
    >> course quite a matter of taste, and this case corresponds to my
    >> taste, but even that is part of the RFC.
    >> 
    >> 
    >> unirootS <- function(f, interval, ...,
    >> lower = min(interval), upper = max(interval),
    >> f.lower = f(lower, ...), f.upper = f(upper, ...),
    >> Sig = NULL, check.conv = FALSE,
    >> tol = .Machine$double.eps^0.25, maxiter = 1000, trace  = 0)
    >> 

    > A few comments:

Thanks a lot, Duncan!

    > 1.  I don't think the name "Sig" conveys the meaning of that parameter
    > well.  If specified, it determines whether the function is increasing
    > or decreasing at the root, so maybe "Increasing" or "Upcrossing" (with a
    > logical value, default NA) would be better?

Good point.  Note that it's completely unused if f() changes sign.
In that case and if  f() is "down crossing" at x0 , 
it would currently *not* warn even if  Sig == 1.
For me, using  Upcrossing = TRUE (or similar) would rather
suggest differently, i.e., I'd expect a warning when that
requirement is not fulfilled.

As you propose a default of NA, we *could* consider to warn in
such cases, where the user prescribes the slope-sign at the crossing...

    > 2.  In case 2 where the interval is expanded, wouldn't we save a bit of
    > time by saving the initial values?  E.g. if Sig == 1 so we want an
    > upcrossing,  but f.lower is positive, shouldn't we set upper to lower as we
    > expand lower downwards?

good point.

    > 3.  Sometimes a user will want to force the solution to be between lower
    > and upper, and will want to signal an error if they are not acceptable.
    > If you do decide to merge this into uniroot that should be an option.

yes, I agree.
And that's actually the point for discussion if we
should allow ourself to make this into uniroot():
The back compatibility is only guaranteed in those case where
old-uniroot() did *not* fail.

    > 4.  It should count the search for the interval among the iterations, and
    > quit if it can't find an interval in that time.  For example,

    >   unirootS( function(x) 1, c(0,1) )

    > never terminates.

duh... of course!  
It shows I wrote the function for my own use, where example as the above
would not happen.

I've committed a simple change {and test} to catch such
examples.
To implement your proposal of *counting* the search
iterations among the total is trivial if we decide to change
the two functions into one uniroot(),
whereas with the current  unirootS() -> uniroot(), this would
need a bit of ugly code bloat... so I'd rather wait how this
RFC develops.

Martin



    > Duncan Murdoch

 [...........]

    >> -----------
    >> 
    >> As said, your comments are very welcome!
    >> Note that I'm less interested in variations which gain 10-20% in
    >> speed benchmarks, rather I'd appreciate proposals for changes
    >> that give a "better" (in your sense) user interface.
    >> 
    >> Martin Maechler, ETH Zurich


From therneau at mayo.edu  Thu May 30 14:44:19 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Thu, 30 May 2013 07:44:19 -0500
Subject: [Rd] RFC: a "safe" uniroot() function for future R
In-Reply-To: <mailman.25.1369908007.10369.r-devel@r-project.org>
References: <mailman.25.1369908007.10369.r-devel@r-project.org>
Message-ID: <51A749A3.9070000@mayo.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130530/d45a07f7/attachment.pl>

From wdunlap at tibco.com  Thu May 30 16:50:45 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 30 May 2013 14:50:45 +0000
Subject: [Rd] R-3.0.1 - "transient" make check failure in splines-EX.r
In-Reply-To: <51A6D4BF.2080507@gmail.com>
References: <93A2161604A30C4ABE14AC35CAFC8422DDFC1D81@USDFW11XM32.mercer.com>
	<51A6D4BF.2080507@gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C2FB811@PA-MBX01.na.tibco.com>

>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> [1] FALSE
>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> [1] TRUE

If you used a function like
   identicalOrReturnInputs <- function(x, y) {
      if (identical(x, y)) {
          TRUE
     } else {
          list(x=x, y=y)
     }
  }
instead of just identical() you could see what sort of differences you are getting.
(Put it in an lapply call and later collect all the non-TRUE results.)

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf
> Of Paul Gilbert
> Sent: Wednesday, May 29, 2013 9:26 PM
> To: Adler, Avraham
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] R-3.0.1 - "transient" make check failure in splines-EX.r
> 
> Avraham
> 
> I resolved this only by switching to a different BLAS on the 32 bit
> machine.Since no one else seemed to be having problems, I considered it
> possible that there was a hardware issue on my old 32 bit machine. The R
> check test failed somewhat randomly, but often. most disconcertingly, it
> failed because it gives different answers. If you source the code in an
> R session a few times you have no trouble reproducing this. It gives the
> impression of an improperly zeroed matrix.
> 
> (All this from memory, I'm on the road.)
> 
> Paul
> 
> On 13-05-28 06:36 PM, Adler, Avraham wrote:
> >
> > Hello.
> >
> > I seem to be having the same problem that Paul had in the thread titled "[Rd] R 2.15.2
> make check failure on 32-bit --with-blas="-lgoto2"" from October of last year
> <https://stat.ethz.ch/pipermail/r-devel/2012-October/065103.html> Unfortunately, that
> thread ended without an answer to his last question.
> >
> > Briefly, I am trying to compile an Rblas for Windows NT 32bit using OpenBlas
> (successor to GotoBlas) (Nehalem - corei7), and the compiled version passes all tests
> except for the "splines-Ex" test in the exact same place that Paul had issues:
> >
> > ~~~~
> >> stopifnot(identical(ns(x), ns(x, df = 1)),
> > +           identical(ns(x, df = 2), ns(x, df = 2, knots = NULL)), # not true till 2.15.2
> > +           !is.null(kk <- attr(ns(x), "knots")), # not true till 1.5.1
> > +           length(kk) == 0)
> > Error: identical(ns(x, df = 2), ns(x, df = 2, knots = NULL)) is not TRUE
> > ~~~~
> >
> > Yet, opening up R and running the actual code shows that the error is transient:
> >
> > ~~~~
> >> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> > [1] TRUE
> >> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> > [1] TRUE
> >> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> > [1] TRUE
> >> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> > [1] FALSE
> >> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> > [1] TRUE
> >> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> > [1] TRUE
> >> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> > [1] TRUE
> >> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> > [1] TRUE
> >> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> > [1] TRUE
> >> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> > [1] FALSE
> > ~~~~
> >
> > This is the only error I have on the 32-bit version, I believe (trying to build a blas for 64-
> bit on SandyBridge is a completely different kettle of fish that is causing me to pull out
> what little hair I have left), and if it can be solved that would be great.
> >
> > Thank you,
> >
> > Avraham
> >
> >
> >
> >
> >
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Thu May 30 17:43:47 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 30 May 2013 11:43:47 -0400
Subject: [Rd] RFC: a "safe" uniroot() function for future R
In-Reply-To: <20903.11965.812306.509672@stat.math.ethz.ch>
References: <20903.2899.135264.914688@stat.math.ethz.ch>
	<CA+COuteo2iQHZyneAy+x7qsfB7G_Erc2GVXpcSTyxez-FVTuOQ@mail.gmail.com>
	<20903.11965.812306.509672@stat.math.ethz.ch>
Message-ID: <51A773B3.8080807@gmail.com>

On 13-05-30 6:49 AM, Martin Maechler wrote:
>>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
>>>>>>      on Thu, 30 May 2013 05:27:57 -0400 writes:
>
>      > On Thu, May 30, 2013 at 4:18 AM, Martin Maechler <maechler at stat.math.ethz.ch
>      >> wrote:
>
>      >> With main R releases only happening yearly in spring, now is
>      >> good time to consider *and* discuss new features for what we
>      >> often call "R-devel" and more officially is
>      >> R Under development (unstable) (.....) -- "Unsuffered Consequences"
>      >>
>      >> Here is one such example I hereby expose to public scrutiny:
>      >>
>      >> A few minutes ago, I've committed the following to R-devel
>      >> (the 'trunk' in the svn repository for R):
>      >>
>      >> ------------------------------------------------------------------------
>      >> r62834 | maechler | 2013-05-30 10:01:33 +0200 (Thu, 30 May 2013) | 1 line
>      >> Changed paths:
>      >> M doc/NEWS.Rd
>      >> M src/library/stats/NAMESPACE
>      >> M src/library/stats/R/nlm.R
>      >> M src/library/stats/man/uniroot.Rd
>      >> M tests/Examples/stats-Ex.Rout.save
>      >>
>      >> new "safe" uniroot() =: unirootS()  [may change; see R-devel e-mail]
>      >> ------------------------------------------------------------------------
>      >>
>      >> The help file says
>      >>
>      >> ?unirootS()? is a ?safe? version of ?uniroot()?, built on
>      >> ?uniroot()?, also useful as drop-in replacement of ?uniroot()? in
>      >> some cases.  ?Safe? means searching for the correct ?interval =
>      >> c(lower,upper)? if ?sign(f(x))? does not satisfy the requirements
>      >> at the interval end points; see the ?Details? section.
>      >>
>      >> We've had this function, called  safeUroot() in our package
>      >> copula for a while now, where an earlier not-exported version
>      >> has been in my package nor1mix even longer.
>      >> When I was tempted to introduce it into yet another CRAN package
>      >> I maintain,  I decided that this may be a sign that such a
>      >> simple [ utility for / generalization of ] uniroot() should
>      >> probably rather be added to R itself.
>      >>
>      >> The function definition, also visible in R's devel.sources, at the bottom
>      >> of
>      >> https://svn.r-project.org/R/trunk/src/library/stats/R/nlm.R ,
>      >> shows that unirootS() is a wrapper for uniroot() and
>      >> is in principle 100% back compatible to uniroot() itself for all
>      >> the cases where f(lower) and f(upper) are of differing sign and
>      >> hence uniroot() does not give a quick error.
>      >> unirootS() just has three new optional arguments, all with their
>      >> defaults set such as to remain uniroot() compatible.
>      >>
>      >> So, one option instead of the currently commited one would be to
>      >> adopt  unirootS() as "the new uniroot()" and rename current
>      >> uniroot to .uniroot() {and still export both}.
>      >>
>
>      > I would probably prefer this.
>
> I did originally, too, but then became less sure about possible CRAN
> checking "fallout"...
>
> Merging the two functions into one, and not keeping the original
> might be even the best solution, also easiest to maintain,
> including documentation.
>
>      >>
>      >> The capital "S" in the function name and the 'Sig' name is of
>      >> course quite a matter of taste, and this case corresponds to my
>      >> taste, but even that is part of the RFC.
>      >>
>      >>
>      >> unirootS <- function(f, interval, ...,
>      >> lower = min(interval), upper = max(interval),
>      >> f.lower = f(lower, ...), f.upper = f(upper, ...),
>      >> Sig = NULL, check.conv = FALSE,
>      >> tol = .Machine$double.eps^0.25, maxiter = 1000, trace  = 0)
>      >>
>
>      > A few comments:
>
> Thanks a lot, Duncan!
>
>      > 1.  I don't think the name "Sig" conveys the meaning of that parameter
>      > well.  If specified, it determines whether the function is increasing
>      > or decreasing at the root, so maybe "Increasing" or "Upcrossing" (with a
>      > logical value, default NA) would be better?
>
> Good point.  Note that it's completely unused if f() changes sign.

I don't think that's true (but maybe you've changed it since I 
downloaded; I'm offline right now).  For example, try

unirootS(function(x) x, c(-1, 1), Sig=-1)

This fails after 1000 iterations, whereas Sig=+1 is fine.

Duncan Murdoch


> In that case and if  f() is "down crossing" at x0 ,
> it would currently *not* warn even if  Sig == 1.
> For me, using  Upcrossing = TRUE (or similar) would rather
> suggest differently, i.e., I'd expect a warning when that
> requirement is not fulfilled.
>
> As you propose a default of NA, we *could* consider to warn in
> such cases, where the user prescribes the slope-sign at the crossing...
>
>      > 2.  In case 2 where the interval is expanded, wouldn't we save a bit of
>      > time by saving the initial values?  E.g. if Sig == 1 so we want an
>      > upcrossing,  but f.lower is positive, shouldn't we set upper to lower as we
>      > expand lower downwards?
>
> good point.
>
>      > 3.  Sometimes a user will want to force the solution to be between lower
>      > and upper, and will want to signal an error if they are not acceptable.
>      > If you do decide to merge this into uniroot that should be an option.
>
> yes, I agree.
> And that's actually the point for discussion if we
> should allow ourself to make this into uniroot():
> The back compatibility is only guaranteed in those case where
> old-uniroot() did *not* fail.
>
>      > 4.  It should count the search for the interval among the iterations, and
>      > quit if it can't find an interval in that time.  For example,
>
>      >   unirootS( function(x) 1, c(0,1) )
>
>      > never terminates.
>
> duh... of course!
> It shows I wrote the function for my own use, where example as the above
> would not happen.
>
> I've committed a simple change {and test} to catch such
> examples.
> To implement your proposal of *counting* the search
> iterations among the total is trivial if we decide to change
> the two functions into one uniroot(),
> whereas with the current  unirootS() -> uniroot(), this would
> need a bit of ugly code bloat... so I'd rather wait how this
> RFC develops.
>
> Martin
>
>
>
>      > Duncan Murdoch
>
>   [...........]
>
>      >> -----------
>      >>
>      >> As said, your comments are very welcome!
>      >> Note that I'm less interested in variations which gain 10-20% in
>      >> speed benchmarks, rather I'd appreciate proposals for changes
>      >> that give a "better" (in your sense) user interface.
>      >>
>      >> Martin Maechler, ETH Zurich
>


From maechler at stat.math.ethz.ch  Thu May 30 20:01:47 2013
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 30 May 2013 20:01:47 +0200
Subject: [Rd] RFC: a "safe" uniroot() function for future R
In-Reply-To: <2F9EA67EF9AE1C48A147CB41BE2E15C344EA4A@DOM-EB-MAIL2.win.ad.jhu.edu>
References: <20903.2899.135264.914688@stat.math.ethz.ch>
	<CA+COuteo2iQHZyneAy+x7qsfB7G_Erc2GVXpcSTyxez-FVTuOQ@mail.gmail.com>
	<2F9EA67EF9AE1C48A147CB41BE2E15C344EA4A@DOM-EB-MAIL2.win.ad.jhu.edu>
Message-ID: <20903.37899.417870.122176@stat.math.ethz.ch>

Thank you, Ravi and Therry,

>>>>> Ravi Varadhan <ravi.varadhan at jhu.edu>
>>>>>     on Thu, 30 May 2013 14:20:19 +0000 writes:

    > Dear Martin,
    > I am not sure I like this idea of expanding the interval. It can have bad consequences.  The best feature of uniroot is that it makes the user think about the behavior of the function.  Your suggestion is in the spirit of making him unthink (if there is such a word!).

Not necessarily:
My use case is inversion of a function that I know to be
monotone, and I know  F^{-1}(a)  has one well defined solution,
but sometimes my guess for an intervall is only approximate and
then simple uniroot() will fail.  I've seen many such cases.

So, to find   F^{-1}(a)
I really want a version of uniroot()

                uniroot(function(x) F(x) - a,  *)

where my initial interval is only approximate and may be too small.


    > Here is a cautionary example:

    >> f <- function(x) exp(-x)

    >> unirootS(f, c(0,2))
    > $root
    > [1] 1312.7

    > $f.root
    > [1] 0

    > $iter
    > [1] 0

    > $estim.prec
    > [1] 0

yes; even shorter and equivalent is 

  unirootS(exp, c(-2,0))


    > The existing `uniroot' does the right thing.

    >> uniroot(f, c(0,2))
    > Error in uniroot(f, c(0, 2)) : 
    > f() values at end points not of opposite sign

yes... but

  uniroot(exp, c(-750, 0))

also gives a result like the above.

As Duncan said, and I agree,  we will keep the option to say
"do use the provided interval and do not enlarge it".

With the current version, this would be with   'Sig = 0' :

> unirootS(exp, c(-2, 0), Sig=0)
Error in unirootS(exp, c(-2, 0), Sig = 0) : 
  f() values at end points not of opposite sign


-------

We may think of extra arguments to limit the "search outside" in
some way, e.g., by an extra 'maxit' for these steps that could
be set low.
In that .. and maybe in any case, we probably should also
consider changing the way the "initial step size"  delta is computed.
I now think that the initial delta should be something like

      (upper - lower) / 16

rather than the current way, where the delta() is
computed separately and independently for 'lower' and 'upper'.

Martin

    > Best,
    > Ravi

    >> -----Original Message-----
    >> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
    >> On Behalf Of Duncan Murdoch
    >> Sent: Thursday, May 30, 2013 5:28 AM
    >> To: Martin Maechler
    >> Cc: R. Devel List
    >> Subject: Re: [Rd] RFC: a "safe" uniroot() function for future R
    >> 
    >> On Thu, May 30, 2013 at 4:18 AM, Martin Maechler
    >> <maechler at stat.math.ethz.ch
    >> > wrote:
    >> 
    >> > With main R releases only happening yearly in spring, now is good time
    >> > to consider *and* discuss new features for what we often call
    >> > "R-devel" and more officially is
    >> >   R Under development (unstable) (.....) -- "Unsuffered Consequences"
    >> >
    >> > Here is one such example I hereby expose to public scrutiny:
    >> >
    >> > A few minutes ago, I've committed the following to R-devel (the
    >> > 'trunk' in the svn repository for R):
    >> >
    >> > ----------------------------------------------------------------------
    >> > --
    >> > r62834 | maechler | 2013-05-30 10:01:33 +0200 (Thu, 30 May 2013) | 1
    >> > line Changed paths:
    >> >    M doc/NEWS.Rd
    >> >    M src/library/stats/NAMESPACE
    >> >    M src/library/stats/R/nlm.R
    >> >    M src/library/stats/man/uniroot.Rd
    >> >    M tests/Examples/stats-Ex.Rout.save
    >> >
    >> > new "safe" uniroot() =: unirootS()  [may change; see R-devel e-mail]
    >> > ----------------------------------------------------------------------
    >> > --
    >> >
    >> > The help file says
    >> >
    >> >      'unirootS()' is a "safe" version of 'uniroot()', built on
    >> >      'uniroot()', also useful as drop-in replacement of 'uniroot()' in
    >> >      some cases.  "Safe" means searching for the correct 'interval =
    >> >      c(lower,upper)' if 'sign(f(x))' does not satisfy the requirements
    >> >      at the interval end points; see the 'Details' section.
    >> >
    >> > We've had this function, called  safeUroot() in our package copula for
    >> > a while now, where an earlier not-exported version has been in my
    >> > package nor1mix even longer.
    >> > When I was tempted to introduce it into yet another CRAN package I
    >> > maintain,  I decided that this may be a sign that such a simple [
    >> > utility for / generalization of ] uniroot() should probably rather be
    >> > added to R itself.
    >> >
    >> > The function definition, also visible in R's devel.sources, at the
    >> > bottom of  https://svn.r-project.org/R/trunk/src/library/stats/R/nlm.R
    >> > , shows that unirootS() is a wrapper for uniroot() and is in principle
    >> > 100% back compatible to uniroot() itself for all the cases where
    >> > f(lower) and f(upper) are of differing sign and hence uniroot() does
    >> > not give a quick error.
    >> > unirootS() just has three new optional arguments, all with their
    >> > defaults set such as to remain uniroot() compatible.
    >> >
    >> > So, one option instead of the currently commited one would be to adopt
    >> > unirootS() as "the new uniroot()" and rename current uniroot to
    >> > .uniroot() {and still export both}.
    >> >
    >> 
    >> I would probably prefer this.
    >> 
    >> 
    >> >
    >> > The capital "S" in the function name and the 'Sig' name is of course
    >> > quite a matter of taste, and this case corresponds to my taste, but
    >> > even that is part of the RFC.
    >> >
    >> >
    >> > unirootS <- function(f, interval, ...,
    >> >                      lower = min(interval), upper = max(interval),
    >> >                      f.lower = f(lower, ...), f.upper = f(upper, ...),
    >> >                      Sig = NULL, check.conv = FALSE,
    >> >                      tol = .Machine$double.eps^0.25, maxiter = 1000,
    >> > trace = 0)
    >> >
    >> 
    >> A few comments:
    >> 
    >> 1.  I don't think the name "Sig" conveys the meaning of that parameter well.  If
    >> specified, it determines whether the function is increasing or decreasing at the
    >> root, so maybe "Increasing" or "Upcrossing" (with a logical value, default NA)
    >> would be better?
    >> 
    >> 2.  In case 2 where the interval is expanded, wouldn't we save a bit of time by
    >> saving the initial values?  E.g. if Sig == 1 so we want an upcrossing,  but f.lower
    >> is positive, shouldn't we set upper to lower as we expand lower downwards?
    >> 
    >> 3.  Sometimes a user will want to force the solution to be between lower and
    >> upper, and will want to signal an error if they are not acceptable.
    >> If you do decide to merge this into uniroot that should be an option.
    >> 
    >> 4.  It should count the search for the interval among the iterations, and quit if it
    >> can't find an interval in that time.  For example,
    >> 
    >> unirootS( function(x) 1, c(0,1) )
    >> 
    >> never terminates.
    >> 
    >> Duncan Murdoch
    >> 
    >> 
    >> 
    >> {
    >> >     if (   is.null(Sig) && f.lower * f.upper > 0 ||
    >> >         is.numeric(Sig) && (Sig*f.lower > 0 || Sig*f.upper < 0)) {
    >> >         if(trace)
    >> >             cat(sprintf("search in [%g,%g]%s", lower, upper,
    >> >                         if(trace >= 2)"\n" else " ... "))
    >> >         Delta <- function(u) 0.01* pmax(1e-7, abs(u))
    >> >         ## Two cases:
    >> >         if(is.null(Sig)) {
    >> >             ## case 1)  'Sig' unspecified --> extend (lower, upper) at
    >> > the same time
    >> >             delta <- Delta(c(lower,upper))
    >> >             while(isTRUE(f.lower*f.upper > 0) && any(iF <-
    >> > is.finite(c(lower,upper)))) {
    >> >                 if(iF[1]) f.lower <- f(lower <- lower - delta[1])
    >> >                 if(iF[2]) f.upper <- f(upper <- upper + delta[2])
    >> >                 if(trace >= 2)
    >> >                     cat(sprintf(" .. modified lower,upper: (%15g,%15g)\n",
    >> >                                 lower,upper))
    >> >                 delta <- 2 * delta
    >> >             }
    >> >         } else {
    >> >             ## case 2) 'Sig' specified --> typically change only *one*
    >> > of lower, upper
    >> >             ## make sure we have Sig*f(lower) < 0 and Sig*f(upper) > 0:
    >> >             delta <- Delta(lower)
    >> >             while(isTRUE(Sig*f.lower > 0)) {
    >> >                 f.lower <- f(lower <- lower - delta)
    >> >                 if(trace) cat(sprintf(" .. modified lower: %g\n", lower))
    >> >                 delta <- 2 * delta
    >> >             }
    >> >             delta <- Delta(upper)
    >> >             while(isTRUE(Sig*f.upper < 0)) {
    >> >                 f.upper <- f(upper <- upper + delta)
    >> >                 if(trace) cat(sprintf(" .. modified upper: %g\n", upper))
    >> >                 delta <- 2 * delta
    >> >             }
    >> >         }
    >> >         if(trace && trace < 2)
    >> >             cat(sprintf("extended to [%g, %g]\n", lower, upper))
    >> >     }
    >> >     if(!isTRUE(f.lower * f.upper <= 0))
    >> >         stop("did not succeed extending the interval endpoints for
    >> > f(lower) * f(upper) <= 0")
    >> >     if(check.conv) {
    >> >         r <- tryCatch(uniroot(f, ..., lower=lower, upper=upper,
    >> >                               f.lower=f.lower, f.upper=f.upper,
    >> >                               tol=tol, maxiter=maxiter),
    >> >                       warning = function(w)w)
    >> >         if(inherits(r, "warning"))
    >> >             stop("convergence problem in zero finding: ", r$message)
    >> >         else r
    >> >     }
    >> >     else
    >> >         uniroot(f, ..., lower=lower, upper=upper,
    >> >                 f.lower=f.lower, f.upper=f.upper,
    >> >                 tol=tol, maxiter=maxiter) }
    >> >
    >> > -----------
    >> >
    >> > As said, your comments are very welcome!
    >> > Note that I'm less interested in variations which gain 10-20% in speed
    >> > benchmarks, rather I'd appreciate proposals for changes that give a
    >> > "better" (in your sense) user interface.
    >> >
    >> > Martin Maechler, ETH Zurich


From Avraham.Adler at guycarp.com  Thu May 30 21:11:58 2013
From: Avraham.Adler at guycarp.com (Adler, Avraham)
Date: Thu, 30 May 2013 14:11:58 -0500
Subject: [Rd] R-3.0.1 - "transient" make check failure in splines-EX.r
In-Reply-To: <51A6D4BF.2080507@gmail.com>
References: <93A2161604A30C4ABE14AC35CAFC8422DDFC1D81@USDFW11XM32.mercer.com>
	<51A6D4BF.2080507@gmail.com>
Message-ID: <93A2161604A30C4ABE14AC35CAFC8422DE336742@USDFW11XM32.mercer.com>

Thank you very much, Paul.

Serendipitously, I seem to have stumbled on a solution. In my parallel (still unsuccessful) attempt to build a BLAS for a 64bit machine (see <https://stat.ethz.ch/pipermail/r-devel/2013-May/066731.html>) I remembered from ATLAS that under the newer Windows there is a divergence from the "standard" ABI (see <http://math-atlas.sourceforge.net/atlas_install/node57.html>).

Looking through the various makefiles under OpenBLAS, I found the following:

		ifeq ($(C_COMPILER), GCC)
		#Test for supporting MS_ABI
		GCCVERSIONGTEQ4 := $(shell expr `$(CC) -dumpversion | cut -f1 -d.` \>= 4)
		GCCVERSIONGT4 := $(shell expr `$(CC) -dumpversion | cut -f1 -d.` \> 4)
		GCCMINORVERSIONGTEQ7 := $(shell expr `$(CC) -dumpversion | cut -f2 -d.` \>= 7)
		ifeq ($(GCCVERSIONGT4), 1)
		# GCC Majar version > 4
		# It is compatible with MSVC ABI. 
		CCOMMON_OPT	+= -DMS_ABI
		endif
		
I had been building OPBL using gcc4.8.0, which is ostensibly "compatible" with the newer ABI, but Rtools still lives in 4.6.3, which isn't. Recompiling the BLAS with MinGW32 for 4.6.3 created a file that has passed `make check-all` twice now. I plan on comparing the speed with the ATLAS-based blas, and if it is faster, I hope to e-mail the dll and check results to Dr. Ligges.

I say "stumbled serendipitously" because when using the 64 bit version of MinGw 4.6.3 resulted in the same `optim`-based error in `factanal` which I describe in the thread linked-to above. I will try using different versions of MinGW or even trying under Cygwin, I guess.

In any event, Paul, I am curious if when you were trying to compile and had the same issue, were you using a different version or generation of gcc in the BLAS compilation than in the R compilation?

Once again, thank you very much.

Avraham Adler


-----Original Message-----
From: Paul Gilbert
Sent: Thursday, May 30, 2013 12:26 AM
To: Adler, Avraham
Subject: Re: R-3.0.1 - "transient" make check failure in splines-EX.r

Avraham

I resolved this only by switching to a different BLAS on the 32 bit machine.Since no one else seemed to be having problems, I considered it possible that there was a hardware issue on my old 32 bit machine. The R check test failed somewhat randomly, but often. most disconcertingly, it failed because it gives different answers. If you source the code in an R session a few times you have no trouble reproducing this. It gives the impression of an improperly zeroed matrix.

(All this from memory, I'm on the road.)

Paul

On 13-05-28 06:36 PM, Adler, Avraham wrote:
>
> Hello.
>
> I seem to be having the same problem that Paul had in the thread titled "[Rd] R 2.15.2 make check failure on 32-bit --with-blas="-lgoto2"" from October of last year <https://stat.ethz.ch/pipermail/r-devel/2012-October/065103.html> Unfortunately, that thread ended without an answer to his last question.
>
> Briefly, I am trying to compile an Rblas for Windows NT 32bit using OpenBlas (successor to GotoBlas) (Nehalem - corei7), and the compiled version passes all tests except for the "splines-Ex" test in the exact same place that Paul had issues:
>
> ~~~~
>> stopifnot(identical(ns(x), ns(x, df = 1)),
> +           identical(ns(x, df = 2), ns(x, df = 2, knots = NULL)), # not true till 2.15.2
> +           !is.null(kk <- attr(ns(x), "knots")), # not true till 1.5.1
> +           length(kk) == 0)
> Error: identical(ns(x, df = 2), ns(x, df = 2, knots = NULL)) is not 
> TRUE ~~~~
>
> Yet, opening up R and running the actual code shows that the error is transient:
>
> ~~~~
>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> [1] TRUE
>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> [1] TRUE
>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> [1] TRUE
>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> [1] FALSE
>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> [1] TRUE
>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> [1] TRUE
>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> [1] TRUE
>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> [1] TRUE
>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> [1] TRUE
>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> [1] FALSE
> ~~~~
>
> This is the only error I have on the 32-bit version, I believe (trying to build a blas for 64-bit on SandyBridge is a completely different kettle of fish that is causing me to pull out what little hair I have left), and if it can be solved that would be great.
>
> Thank you,
>
> Avraham

From Avraham.Adler at guycarp.com  Thu May 30 23:17:36 2013
From: Avraham.Adler at guycarp.com (Adler, Avraham)
Date: Thu, 30 May 2013 16:17:36 -0500
Subject: [Rd] R-3.0.1 - "transient" make check failure in splines-EX.r
In-Reply-To: <E2263553A9D87A41A3E0E1B6FA4F19CAE56C7BEA@USDFW11XM32.mercer.com>
References: <93A2161604A30C4ABE14AC35CAFC8422DDFC1D81@USDFW11XM32.mercer.com>
	<51A6D4BF.2080507@gmail.com>
	<E2263553A9D87A41A3E0E1B6FA4F19CAE56C7BEA@USDFW11XM32.mercer.com>
Message-ID: <93A2161604A30C4ABE14AC35CAFC8422DE40EF48@USDFW11XM32.mercer.com>

I just found this thread on StackOverflow <http://stackoverflow.com/questions/13871818/ns-varies-for-no-apparent-reason/13878936> which had the same problem with the `ns` call changing with Revolution, and the answer given by tech support was that the MKL BLAS sometime returns ever-so-slightly different floating point results than a reference BLAS. The problem with that answer is that if it is true, the runs should not change *on the same machine* but it is another example of this issue. Unfortunately, it seems to dead-end too.

Avraham


-----Original Message-----
From: Adler, Avraham 
Sent: Thursday, May 30, 2013 3:12 PM
To: Paul Gilbert
Cc: r-devel at r-project.org
Subject: RE: R-3.0.1 - "transient" make check failure in splines-EX.r

Thank you very much, Paul.

Serendipitously, I seem to have stumbled on a solution. In my parallel (still unsuccessful) attempt to build a BLAS for a 64bit machine (see <https://stat.ethz.ch/pipermail/r-devel/2013-May/066731.html>) I remembered from ATLAS that under the newer Windows there is a divergence from the "standard" ABI (see <http://math-atlas.sourceforge.net/atlas_install/node57.html>).

Looking through the various makefiles under OpenBLAS, I found the following:

		ifeq ($(C_COMPILER), GCC)
		#Test for supporting MS_ABI
		GCCVERSIONGTEQ4 := $(shell expr `$(CC) -dumpversion | cut -f1 -d.` \>= 4)
		GCCVERSIONGT4 := $(shell expr `$(CC) -dumpversion | cut -f1 -d.` \> 4)
		GCCMINORVERSIONGTEQ7 := $(shell expr `$(CC) -dumpversion | cut -f2 -d.` \>= 7)
		ifeq ($(GCCVERSIONGT4), 1)
		# GCC Majar version > 4
		# It is compatible with MSVC ABI. 
		CCOMMON_OPT	+= -DMS_ABI
		endif
		
I had been building OPBL using gcc4.8.0, which is ostensibly "compatible" with the newer ABI, but Rtools still lives in 4.6.3, which isn't. Recompiling the BLAS with MinGW32 for 4.6.3 created a file that has passed `make check-all` twice now. I plan on comparing the speed with the ATLAS-based blas, and if it is faster, I hope to e-mail the dll and check results to Dr. Ligges.

I say "stumbled serendipitously" because when using the 64 bit version of MinGw 4.6.3 resulted in the same `optim`-based error in `factanal` which I describe in the thread linked-to above. I will try using different versions of MinGW or even trying under Cygwin, I guess.

In any event, Paul, I am curious if when you were trying to compile and had the same issue, were you using a different version or generation of gcc in the BLAS compilation than in the R compilation?

Once again, thank you very much.

Avraham Adler


-----Original Message-----
From: Paul Gilbert
Sent: Thursday, May 30, 2013 12:26 AM
To: Adler, Avraham
Subject: Re: R-3.0.1 - "transient" make check failure in splines-EX.r

Avraham

I resolved this only by switching to a different BLAS on the 32 bit machine.Since no one else seemed to be having problems, I considered it possible that there was a hardware issue on my old 32 bit machine. The R check test failed somewhat randomly, but often. most disconcertingly, it failed because it gives different answers. If you source the code in an R session a few times you have no trouble reproducing this. It gives the impression of an improperly zeroed matrix.

(All this from memory, I'm on the road.)

Paul

On 13-05-28 06:36 PM, Adler, Avraham wrote:
>
> Hello.
>
> I seem to be having the same problem that Paul had in the thread titled "[Rd] R 2.15.2 make check failure on 32-bit --with-blas="-lgoto2"" from October of last year <https://stat.ethz.ch/pipermail/r-devel/2012-October/065103.html> Unfortunately, that thread ended without an answer to his last question.
>
> Briefly, I am trying to compile an Rblas for Windows NT 32bit using OpenBlas (successor to GotoBlas) (Nehalem - corei7), and the compiled version passes all tests except for the "splines-Ex" test in the exact same place that Paul had issues:
>
> ~~~~
>> stopifnot(identical(ns(x), ns(x, df = 1)),
> +           identical(ns(x, df = 2), ns(x, df = 2, knots = NULL)), # not true till 2.15.2
> +           !is.null(kk <- attr(ns(x), "knots")), # not true till 1.5.1
> +           length(kk) == 0)
> Error: identical(ns(x, df = 2), ns(x, df = 2, knots = NULL)) is not 
> TRUE ~~~~
>
> Yet, opening up R and running the actual code shows that the error is transient:
>
> ~~~~
>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> [1] TRUE
>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> [1] TRUE
>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> [1] TRUE
>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> [1] FALSE
>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> [1] TRUE
>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> [1] TRUE
>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> [1] TRUE
>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> [1] TRUE
>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> [1] TRUE
>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
> [1] FALSE
> ~~~~
>
> This is the only error I have on the 32-bit version, I believe (trying to build a blas for 64-bit on SandyBridge is a completely different kettle of fish that is causing me to pull out what little hair I have left), and if it can be solved that would be great.
>
> Thank you,
>
> Avraham

From marchywka at hotmail.com  Fri May 31 01:20:47 2013
From: marchywka at hotmail.com (Mike Marchywka)
Date: Thu, 30 May 2013 19:20:47 -0400
Subject: [Rd] R-3.0.1 - "transient" make check failure in splines-EX.r
In-Reply-To: <93A2161604A30C4ABE14AC35CAFC8422DE40EF48@USDFW11XM32.mercer.com>
References: <93A2161604A30C4ABE14AC35CAFC8422DDFC1D81@USDFW11XM32.mercer.com>,
	<51A6D4BF.2080507@gmail.com>,
	<E2263553A9D87A41A3E0E1B6FA4F19CAE56C7BEA@USDFW11XM32.mercer.com>,
	<93A2161604A30C4ABE14AC35CAFC8422DE40EF48@USDFW11XM32.mercer.com>
Message-ID: <BLU166-W517D410DB6093FAAFC770ABE910@phx.gbl>

----------------------------------------
> From: Avraham.Adler at guycarp.com
> To: r-devel at r-project.org
> Date: Thu, 30 May 2013 16:17:36 -0500
> Subject: Re: [Rd] R-3.0.1 - "transient" make check failure in splines-EX.r
>
> I just found this thread on StackOverflow <http://stackoverflow.com/questions/13871818/ns-varies-for-no-apparent-reason/13878936> which had the same problem with the `ns` call changing with Revolution, and the answer given by tech support was that the MKL BLAS sometime returns ever-so-slightly different floating point results than a reference BLAS. The problem with that answer is that if it is true, the runs should not change *on the same machine* but it is another example of this issue. Unfortunately, it seems to dead-end too.
>

Read some of the documents on the Intel site about floating point consistency and compiler optimizations. There are?
some reasons that you could get a different result from repeated runs on the same machine. One of these would
be bugs like unititialized memory but another would be things like state of FPU and issues with
multi-threaded code having some order dependencies etc. ?

( hotmail can not believe I am trying to post text but maybe you can figure it out from whatver this link eds up looking like.... )?
?href="http://www.google.com/search?biw=1253&bih=542&hl=en&q=floating+point+low+bits+vary+fpu+prior+state+site%253Aintel.com&oq=floating+point+low+bits+vary+fpu+prior+state+site%253Aintel.com"




> Avraham
>
>
> -----Original Message-----
> From: Adler, Avraham
> Sent: Thursday, May 30, 2013 3:12 PM
> To: Paul Gilbert
> Cc: r-devel at r-project.org
> Subject: RE: R-3.0.1 - "transient" make check failure in splines-EX.r
>
> Thank you very much, Paul.
>
> Serendipitously, I seem to have stumbled on a solution. In my parallel (still unsuccessful) attempt to build a BLAS for a 64bit machine (see <https://stat.ethz.ch/pipermail/r-devel/2013-May/066731.html>) I remembered from ATLAS that under the newer Windows there is a divergence from the "standard" ABI (see <http://math-atlas.sourceforge.net/atlas_install/node57.html>).
>
> Looking through the various makefiles under OpenBLAS, I found the following:
>
> ifeq ($(C_COMPILER), GCC)
> #Test for supporting MS_ABI
> GCCVERSIONGTEQ4 := $(shell expr `$(CC) -dumpversion | cut -f1 -d.` \>= 4)
> GCCVERSIONGT4 := $(shell expr `$(CC) -dumpversion | cut -f1 -d.` \> 4)
> GCCMINORVERSIONGTEQ7 := $(shell expr `$(CC) -dumpversion | cut -f2 -d.` \>= 7)
> ifeq ($(GCCVERSIONGT4), 1)
> # GCC Majar version> 4
> # It is compatible with MSVC ABI.
> CCOMMON_OPT += -DMS_ABI
> endif
>
> I had been building OPBL using gcc4.8.0, which is ostensibly "compatible" with the newer ABI, but Rtools still lives in 4.6.3, which isn't. Recompiling the BLAS with MinGW32 for 4.6.3 created a file that has passed `make check-all` twice now. I plan on comparing the speed with the ATLAS-based blas, and if it is faster, I hope to e-mail the dll and check results to Dr. Ligges.
>
> I say "stumbled serendipitously" because when using the 64 bit version of MinGw 4.6.3 resulted in the same `optim`-based error in `factanal` which I describe in the thread linked-to above. I will try using different versions of MinGW or even trying under Cygwin, I guess.
>
> In any event, Paul, I am curious if when you were trying to compile and had the same issue, were you using a different version or generation of gcc in the BLAS compilation than in the R compilation?
>
> Once again, thank you very much.
>
> Avraham Adler
>
>
> -----Original Message-----
> From: Paul Gilbert
> Sent: Thursday, May 30, 2013 12:26 AM
> To: Adler, Avraham
> Subject: Re: R-3.0.1 - "transient" make check failure in splines-EX.r
>
> Avraham
>
> I resolved this only by switching to a different BLAS on the 32 bit machine.Since no one else seemed to be having problems, I considered it possible that there was a hardware issue on my old 32 bit machine. The R check test failed somewhat randomly, but often. most disconcertingly, it failed because it gives different answers. If you source the code in an R session a few times you have no trouble reproducing this. It gives the impression of an improperly zeroed matrix.
>
> (All this from memory, I'm on the road.)
>
> Paul
>
> On 13-05-28 06:36 PM, Adler, Avraham wrote:
>>
>> Hello.
>>
>> I seem to be having the same problem that Paul had in the thread titled "[Rd] R 2.15.2 make check failure on 32-bit --with-blas="-lgoto2"" from October of last year <https://stat.ethz.ch/pipermail/r-devel/2012-October/065103.html> Unfortunately, that thread ended without an answer to his last question.
>>
>> Briefly, I am trying to compile an Rblas for Windows NT 32bit using OpenBlas (successor to GotoBlas) (Nehalem - corei7), and the compiled version passes all tests except for the "splines-Ex" test in the exact same place that Paul had issues:
>>
>> ~~~~
>>> stopifnot(identical(ns(x), ns(x, df = 1)),
>> + identical(ns(x, df = 2), ns(x, df = 2, knots = NULL)), # not true till 2.15.2
>> + !is.null(kk <- attr(ns(x), "knots")), # not true till 1.5.1
>> + length(kk) == 0)
>> Error: identical(ns(x, df = 2), ns(x, df = 2, knots = NULL)) is not
>> TRUE ~~~~
>>
>> Yet, opening up R and running the actual code shows that the error is transient:
>>
>> ~~~~
>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>> [1] TRUE
>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>> [1] TRUE
>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>> [1] TRUE
>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>> [1] FALSE
>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>> [1] TRUE
>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>> [1] TRUE
>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>> [1] TRUE
>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>> [1] TRUE
>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>> [1] TRUE
>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>> [1] FALSE
>> ~~~~
>>
>> This is the only error I have on the 32-bit version, I believe (trying to build a blas for 64-bit on SandyBridge is a completely different kettle of fish that is causing me to pull out what little hair I have left), and if it can be solved that would be great.
>>
>> Thank you,
>>
>> Avraham
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel 		 	   		  

From maechler at stat.math.ethz.ch  Fri May 31 10:34:28 2013
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 31 May 2013 10:34:28 +0200
Subject: [Rd] RFC: a "safe" uniroot() function for future R
In-Reply-To: <51A773B3.8080807@gmail.com>
References: <20903.2899.135264.914688@stat.math.ethz.ch>
	<CA+COuteo2iQHZyneAy+x7qsfB7G_Erc2GVXpcSTyxez-FVTuOQ@mail.gmail.com>
	<20903.11965.812306.509672@stat.math.ethz.ch>
	<51A773B3.8080807@gmail.com>
Message-ID: <20904.24724.932826.199873@stat.math.ethz.ch>


> On 13-05-30 6:49 AM, Martin Maechler wrote:
> >>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
> >>>>>>      on Thu, 30 May 2013 05:27:57 -0400 writes:
> >
> >      > On Thu, May 30, 2013 at 4:18 AM, Martin Maechler <maechler at stat.math.ethz.ch
> >      >> wrote:
> >
> >      >> With main R releases only happening yearly in spring, now is
> >      >> good time to consider *and* discuss new features for what we
> >      >> often call "R-devel" and more officially is
> >      >> R Under development (unstable) (.....) -- "Unsuffered Consequences"
> >      >>
> >      >> Here is one such example I hereby expose to public scrutiny:
> >      >>
> >      >> A few minutes ago, I've committed the following to R-devel
> >      >> (the 'trunk' in the svn repository for R):
> >      >>
> >      >> ------------------------------------------------------------------------
> >      >> r62834 | maechler | 2013-05-30 10:01:33 +0200 (Thu, 30 May 2013) | 1 line
> >      >> Changed paths:
> >      >> M doc/NEWS.Rd
> >      >> M src/library/stats/NAMESPACE
> >      >> M src/library/stats/R/nlm.R
> >      >> M src/library/stats/man/uniroot.Rd
> >      >> M tests/Examples/stats-Ex.Rout.save
> >      >>
> >      >> new "safe" uniroot() =: unirootS()  [may change; see R-devel e-mail]
> >      >> ------------------------------------------------------------------------
> >      >>
> >      >> The help file says
> >      >>
> >      >> ?unirootS()? is a ?safe? version of ?uniroot()?, built on
> >      >> ?uniroot()?, also useful as drop-in replacement of ?uniroot()? in
> >      >> some cases.  ?Safe? means searching for the correct ?interval =
> >      >> c(lower,upper)? if ?sign(f(x))? does not satisfy the requirements
> >      >> at the interval end points; see the ?Details? section.
> >      >>
> >      >> We've had this function, called  safeUroot() in our package
> >      >> copula for a while now, where an earlier not-exported version
> >      >> has been in my package nor1mix even longer.
> >      >> When I was tempted to introduce it into yet another CRAN package
> >      >> I maintain,  I decided that this may be a sign that such a
> >      >> simple [ utility for / generalization of ] uniroot() should
> >      >> probably rather be added to R itself.
> >      >>
> >      >> The function definition, also visible in R's devel.sources, at the bottom
> >      >> of
> >      >> https://svn.r-project.org/R/trunk/src/library/stats/R/nlm.R ,
> >      >> shows that unirootS() is a wrapper for uniroot() and
> >      >> is in principle 100% back compatible to uniroot() itself for all
> >      >> the cases where f(lower) and f(upper) are of differing sign and
> >      >> hence uniroot() does not give a quick error.
> >      >> unirootS() just has three new optional arguments, all with their
> >      >> defaults set such as to remain uniroot() compatible.
> >      >>
> >      >> So, one option instead of the currently commited one would be to
> >      >> adopt  unirootS() as "the new uniroot()" and rename current
> >      >> uniroot to .uniroot() {and still export both}.
> >      >>
> >
> >      > I would probably prefer this.
> >
> > I did originally, too, but then became less sure about possible CRAN
> > checking "fallout"...
> >
> > Merging the two functions into one, and not keeping the original
> > might be even the best solution, also easiest to maintain,
> > including documentation.
> >
> >      >>
> >      >> The capital "S" in the function name and the 'Sig' name is of
> >      >> course quite a matter of taste, and this case corresponds to my
> >      >> taste, but even that is part of the RFC.
> >      >>
> >      >>
> >      >> unirootS <- function(f, interval, ...,
> >      >> lower = min(interval), upper = max(interval),
> >      >> f.lower = f(lower, ...), f.upper = f(upper, ...),
> >      >> Sig = NULL, check.conv = FALSE,
> >      >> tol = .Machine$double.eps^0.25, maxiter = 1000, trace  = 0)
> >      >>
> >
> >      > A few comments:
> >
> > Thanks a lot, Duncan!
> >
> >      > 1.  I don't think the name "Sig" conveys the meaning of that parameter
> >      > well.  If specified, it determines whether the function is increasing
> >      > or decreasing at the root, so maybe "Increasing" or "Upcrossing" (with a
> >      > logical value, default NA) would be better?
> >
> > Good point.  Note that it's completely unused if f() changes sign.

> I don't think that's true (but maybe you've changed it since I 
> downloaded; I'm offline right now).  For example, try

> unirootS(function(x) x, c(-1, 1), Sig=-1)

> This fails after 1000 iterations, whereas Sig=+1 is fine.

Indeed.  You are entirely right, and my note was wrong.

> > In that case and if  f() is "down crossing" at x0 ,
> > it would currently *not* warn even if  Sig == 1.
> > For me, using  Upcrossing = TRUE (or similar) would rather
> > suggest differently, i.e., I'd expect a warning when that
> > requirement is not fulfilled.

so the above is moot.
>From the current feedbacks, I'd come to propose / further
discuss the following issues:

1) the goal is to remain with one function uniroot()

2) Instead of the 'Sig' = "sign(f'(x_0))" {not quite, but typically}
   with 4 different value classes, namely
   NULL, -1, 0, 1,  (where +/- 1  are equivalent to any positive
   or negative finite number respectively),

   we should either use a string with 4 different possible values
   or a {logical or NULL}, say 'upcrossing' 
   (which also gives 4 values, NULL, NA, FALSE, TRUE).


3) [I'm not sure about this:]
   The new default of the 'Sig' replacement would correspond to
   the current  Sig = NULL  which does extend the search
   interval when that does not constitute a sign change.

   Alternatively, implicitly proposed by Ravi Varadhan, the
   default would correspond to  Sig = 0, i.e. to the current
   uniroot() behavior which signals an error as soon as the initial
   interval is not large enough.

Further opinions and suggestions for  '2)' and '3)' are still
very welcome!

Martin

> >
> > As you propose a default of NA, we *could* consider to warn in
> > such cases, where the user prescribes the slope-sign at the crossing...
> >
> >      > 2.  In case 2 where the interval is expanded, wouldn't we save a bit of
> >      > time by saving the initial values?  E.g. if Sig == 1 so we want an
> >      > upcrossing,  but f.lower is positive, shouldn't we set upper to lower as we
> >      > expand lower downwards?
> >
> > good point.
> >
> >      > 3.  Sometimes a user will want to force the solution to be between lower
> >      > and upper, and will want to signal an error if they are not acceptable.
> >      > If you do decide to merge this into uniroot that should be an option.
> >
> > yes, I agree.
> > And that's actually the point for discussion if we
> > should allow ourself to make this into uniroot():
> > The back compatibility is only guaranteed in those case where
> > old-uniroot() did *not* fail.
> >
> >      > 4.  It should count the search for the interval among the iterations, and
> >      > quit if it can't find an interval in that time.  For example,
> >
> >      >   unirootS( function(x) 1, c(0,1) )
> >
> >      > never terminates.
> >
> > duh... of course!
> > It shows I wrote the function for my own use, where example as the above
> > would not happen.
> >
> > I've committed a simple change {and test} to catch such
> > examples.
> > To implement your proposal of *counting* the search
> > iterations among the total is trivial if we decide to change
> > the two functions into one uniroot(),
> > whereas with the current  unirootS() -> uniroot(), this would
> > need a bit of ugly code bloat... so I'd rather wait how this
> > RFC develops.
> >
> > Martin
> >
> >
> >
> >      > Duncan Murdoch
> >
> >   [...........]
> >
> >      >> -----------
> >      >>
> >      >> As said, your comments are very welcome!
> >      >> Note that I'm less interested in variations which gain 10-20% in
> >      >> speed benchmarks, rather I'd appreciate proposals for changes
> >      >> that give a "better" (in your sense) user interface.
> >      >>
> >      >> Martin Maechler, ETH Zurich
> >


From ravi.varadhan at jhu.edu  Thu May 30 16:20:19 2013
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Thu, 30 May 2013 14:20:19 +0000
Subject: [Rd] RFC: a "safe" uniroot() function for future R
In-Reply-To: <CA+COuteo2iQHZyneAy+x7qsfB7G_Erc2GVXpcSTyxez-FVTuOQ@mail.gmail.com>
References: <20903.2899.135264.914688@stat.math.ethz.ch>
	<CA+COuteo2iQHZyneAy+x7qsfB7G_Erc2GVXpcSTyxez-FVTuOQ@mail.gmail.com>
Message-ID: <2F9EA67EF9AE1C48A147CB41BE2E15C344EA4A@DOM-EB-MAIL2.win.ad.jhu.edu>

Dear Martin,

I am not sure I like this idea of expanding the interval. It can have bad consequences.  The best feature of uniroot is that it makes the user think about the behavior of the function.  Your suggestion is in the spirit of making him unthink (if there is such a word!).

Here is a cautionary example:

> f <- function(x) exp(-x)

> unirootS(f, c(0,2))
$root
[1] 1312.7

$f.root
[1] 0

$iter
[1] 0

$estim.prec
[1] 0

The existing `uniroot' does the right thing.

> uniroot(f, c(0,2))
Error in uniroot(f, c(0, 2)) : 
  f() values at end points not of opposite sign
>

Best,
Ravi

> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
> On Behalf Of Duncan Murdoch
> Sent: Thursday, May 30, 2013 5:28 AM
> To: Martin Maechler
> Cc: R. Devel List
> Subject: Re: [Rd] RFC: a "safe" uniroot() function for future R
> 
> On Thu, May 30, 2013 at 4:18 AM, Martin Maechler
> <maechler at stat.math.ethz.ch
> > wrote:
> 
> > With main R releases only happening yearly in spring, now is good time
> > to consider *and* discuss new features for what we often call
> > "R-devel" and more officially is
> >   R Under development (unstable) (.....) -- "Unsuffered Consequences"
> >
> > Here is one such example I hereby expose to public scrutiny:
> >
> > A few minutes ago, I've committed the following to R-devel (the
> > 'trunk' in the svn repository for R):
> >
> > ----------------------------------------------------------------------
> > --
> > r62834 | maechler | 2013-05-30 10:01:33 +0200 (Thu, 30 May 2013) | 1
> > line Changed paths:
> >    M doc/NEWS.Rd
> >    M src/library/stats/NAMESPACE
> >    M src/library/stats/R/nlm.R
> >    M src/library/stats/man/uniroot.Rd
> >    M tests/Examples/stats-Ex.Rout.save
> >
> > new "safe" uniroot() =: unirootS()  [may change; see R-devel e-mail]
> > ----------------------------------------------------------------------
> > --
> >
> > The help file says
> >
> >      'unirootS()' is a "safe" version of 'uniroot()', built on
> >      'uniroot()', also useful as drop-in replacement of 'uniroot()' in
> >      some cases.  "Safe" means searching for the correct 'interval =
> >      c(lower,upper)' if 'sign(f(x))' does not satisfy the requirements
> >      at the interval end points; see the 'Details' section.
> >
> > We've had this function, called  safeUroot() in our package copula for
> > a while now, where an earlier not-exported version has been in my
> > package nor1mix even longer.
> > When I was tempted to introduce it into yet another CRAN package I
> > maintain,  I decided that this may be a sign that such a simple [
> > utility for / generalization of ] uniroot() should probably rather be
> > added to R itself.
> >
> > The function definition, also visible in R's devel.sources, at the
> > bottom of  https://svn.r-project.org/R/trunk/src/library/stats/R/nlm.R
> > , shows that unirootS() is a wrapper for uniroot() and is in principle
> > 100% back compatible to uniroot() itself for all the cases where
> > f(lower) and f(upper) are of differing sign and hence uniroot() does
> > not give a quick error.
> > unirootS() just has three new optional arguments, all with their
> > defaults set such as to remain uniroot() compatible.
> >
> > So, one option instead of the currently commited one would be to adopt
> > unirootS() as "the new uniroot()" and rename current uniroot to
> > .uniroot() {and still export both}.
> >
> 
> I would probably prefer this.
> 
> 
> >
> > The capital "S" in the function name and the 'Sig' name is of course
> > quite a matter of taste, and this case corresponds to my taste, but
> > even that is part of the RFC.
> >
> >
> > unirootS <- function(f, interval, ...,
> >                      lower = min(interval), upper = max(interval),
> >                      f.lower = f(lower, ...), f.upper = f(upper, ...),
> >                      Sig = NULL, check.conv = FALSE,
> >                      tol = .Machine$double.eps^0.25, maxiter = 1000,
> > trace = 0)
> >
> 
> A few comments:
> 
> 1.  I don't think the name "Sig" conveys the meaning of that parameter well.  If
> specified, it determines whether the function is increasing or decreasing at the
> root, so maybe "Increasing" or "Upcrossing" (with a logical value, default NA)
> would be better?
> 
> 2.  In case 2 where the interval is expanded, wouldn't we save a bit of time by
> saving the initial values?  E.g. if Sig == 1 so we want an upcrossing,  but f.lower
> is positive, shouldn't we set upper to lower as we expand lower downwards?
> 
> 3.  Sometimes a user will want to force the solution to be between lower and
> upper, and will want to signal an error if they are not acceptable.
> If you do decide to merge this into uniroot that should be an option.
> 
> 4.  It should count the search for the interval among the iterations, and quit if it
> can't find an interval in that time.  For example,
> 
> unirootS( function(x) 1, c(0,1) )
> 
> never terminates.
> 
> Duncan Murdoch
> 
> 
> 
> {
> >     if (   is.null(Sig) && f.lower * f.upper > 0 ||
> >         is.numeric(Sig) && (Sig*f.lower > 0 || Sig*f.upper < 0)) {
> >         if(trace)
> >             cat(sprintf("search in [%g,%g]%s", lower, upper,
> >                         if(trace >= 2)"\n" else " ... "))
> >         Delta <- function(u) 0.01* pmax(1e-7, abs(u))
> >         ## Two cases:
> >         if(is.null(Sig)) {
> >             ## case 1)  'Sig' unspecified --> extend (lower, upper) at
> > the same time
> >             delta <- Delta(c(lower,upper))
> >             while(isTRUE(f.lower*f.upper > 0) && any(iF <-
> > is.finite(c(lower,upper)))) {
> >                 if(iF[1]) f.lower <- f(lower <- lower - delta[1])
> >                 if(iF[2]) f.upper <- f(upper <- upper + delta[2])
> >                 if(trace >= 2)
> >                     cat(sprintf(" .. modified lower,upper: (%15g,%15g)\n",
> >                                 lower,upper))
> >                 delta <- 2 * delta
> >             }
> >         } else {
> >             ## case 2) 'Sig' specified --> typically change only *one*
> > of lower, upper
> >             ## make sure we have Sig*f(lower) < 0 and Sig*f(upper) > 0:
> >             delta <- Delta(lower)
> >             while(isTRUE(Sig*f.lower > 0)) {
> >                 f.lower <- f(lower <- lower - delta)
> >                 if(trace) cat(sprintf(" .. modified lower: %g\n", lower))
> >                 delta <- 2 * delta
> >             }
> >             delta <- Delta(upper)
> >             while(isTRUE(Sig*f.upper < 0)) {
> >                 f.upper <- f(upper <- upper + delta)
> >                 if(trace) cat(sprintf(" .. modified upper: %g\n", upper))
> >                 delta <- 2 * delta
> >             }
> >         }
> >         if(trace && trace < 2)
> >             cat(sprintf("extended to [%g, %g]\n", lower, upper))
> >     }
> >     if(!isTRUE(f.lower * f.upper <= 0))
> >         stop("did not succeed extending the interval endpoints for
> > f(lower) * f(upper) <= 0")
> >     if(check.conv) {
> >         r <- tryCatch(uniroot(f, ..., lower=lower, upper=upper,
> >                               f.lower=f.lower, f.upper=f.upper,
> >                               tol=tol, maxiter=maxiter),
> >                       warning = function(w)w)
> >         if(inherits(r, "warning"))
> >             stop("convergence problem in zero finding: ", r$message)
> >         else r
> >     }
> >     else
> >         uniroot(f, ..., lower=lower, upper=upper,
> >                 f.lower=f.lower, f.upper=f.upper,
> >                 tol=tol, maxiter=maxiter) }
> >
> > -----------
> >
> > As said, your comments are very welcome!
> > Note that I'm less interested in variations which gain 10-20% in speed
> > benchmarks, rather I'd appreciate proposals for changes that give a
> > "better" (in your sense) user interface.
> >
> > Martin Maechler, ETH Zurich
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> 	[[alternative HTML version deleted]]


From Avraham.Adler at guycarp.com  Fri May 31 17:16:11 2013
From: Avraham.Adler at guycarp.com (Adler, Avraham)
Date: Fri, 31 May 2013 10:16:11 -0500
Subject: [Rd] R-3.0.1 - "transient" make check failure in splines-EX.r
In-Reply-To: <BLU166-W517D410DB6093FAAFC770ABE910@phx.gbl>
References: <93A2161604A30C4ABE14AC35CAFC8422DDFC1D81@USDFW11XM32.mercer.com>,
	<51A6D4BF.2080507@gmail.com>,
	<E2263553A9D87A41A3E0E1B6FA4F19CAE56C7BEA@USDFW11XM32.mercer.com>,
	<93A2161604A30C4ABE14AC35CAFC8422DE40EF48@USDFW11XM32.mercer.com>
	<BLU166-W517D410DB6093FAAFC770ABE910@phx.gbl>
Message-ID: <93A2161604A30C4ABE14AC35CAFC8422DE40F420@USDFW11XM32.mercer.com>

Thank you, Mike, I did not know that!

I tried to prevent multi-threaded issues by setting the compiler options to be single-threaded, but I know so little about this area that there may be something else going on.

Do you think that the same problem may be causing the 64-bit issue I am having (<https://stat.ethz.ch/pipermail/r-devel/2013-May/066731.html>)? I tend to think not, as I haven't seen changing results in the call to `optim`, and I still don't know what "NEW_X" means.

Once again, thank you.

Avraham Adler


-----Original Message-----
From: Mike Marchywka [mailto:marchywka at hotmail.com] 
Sent: Thursday, May 30, 2013 7:21 PM
To: Adler, Avraham; 'r-devel at r-project.org'
Subject: RE: [Rd] R-3.0.1 - "transient" make check failure in splines-EX.r

----------------------------------------
> From: Avraham.Adler at guycarp.com
> To: r-devel at r-project.org
> Date: Thu, 30 May 2013 16:17:36 -0500
> Subject: Re: [Rd] R-3.0.1 - "transient" make check failure in 
> splines-EX.r
>
> I just found this thread on StackOverflow <http://stackoverflow.com/questions/13871818/ns-varies-for-no-apparent-reason/13878936> which had the same problem with the `ns` call changing with Revolution, and the answer given by tech support was that the MKL BLAS sometime returns ever-so-slightly different floating point results than a reference BLAS. The problem with that answer is that if it is true, the runs should not change *on the same machine* but it is another example of this issue. Unfortunately, it seems to dead-end too.
>

Read some of the documents on the Intel site about floating point consistency and compiler optimizations. There are some reasons that you could get a different result from repeated runs on the same machine. One of these would be bugs like unititialized memory but another would be things like state of FPU and issues with multi-threaded code having some order dependencies etc. ?

( hotmail can not believe I am trying to post text but maybe you can figure it out from whatver this link eds up looking like.... )
?href="http://www.google.com/search?biw=1253&bih=542&hl=en&q=floating+point+low+bits+vary+fpu+prior+state+site%253Aintel.com&oq=floating+point+low+bits+vary+fpu+prior+state+site%253Aintel.com"




> Avraham
>
>
> -----Original Message-----
> From: Adler, Avraham
> Sent: Thursday, May 30, 2013 3:12 PM
> To: Paul Gilbert
> Cc: r-devel at r-project.org
> Subject: RE: R-3.0.1 - "transient" make check failure in splines-EX.r
>
> Thank you very much, Paul.
>
> Serendipitously, I seem to have stumbled on a solution. In my parallel (still unsuccessful) attempt to build a BLAS for a 64bit machine (see <https://stat.ethz.ch/pipermail/r-devel/2013-May/066731.html>) I remembered from ATLAS that under the newer Windows there is a divergence from the "standard" ABI (see <http://math-atlas.sourceforge.net/atlas_install/node57.html>).
>
> Looking through the various makefiles under OpenBLAS, I found the following:
>
> ifeq ($(C_COMPILER), GCC)
> #Test for supporting MS_ABI
> GCCVERSIONGTEQ4 := $(shell expr `$(CC) -dumpversion | cut -f1 -d.` \>= 4)
> GCCVERSIONGT4 := $(shell expr `$(CC) -dumpversion | cut -f1 -d.` \> 4)
> GCCMINORVERSIONGTEQ7 := $(shell expr `$(CC) -dumpversion | cut -f2 -d.` \>= 7)
> ifeq ($(GCCVERSIONGT4), 1)
> # GCC Majar version> 4
> # It is compatible with MSVC ABI.
> CCOMMON_OPT += -DMS_ABI
> endif
>
> I had been building OPBL using gcc4.8.0, which is ostensibly "compatible" with the newer ABI, but Rtools still lives in 4.6.3, which isn't. Recompiling the BLAS with MinGW32 for 4.6.3 created a file that has passed `make check-all` twice now. I plan on comparing the speed with the ATLAS-based blas, and if it is faster, I hope to e-mail the dll and check results to Dr. Ligges.
>
> I say "stumbled serendipitously" because when using the 64 bit version of MinGw 4.6.3 resulted in the same `optim`-based error in `factanal` which I describe in the thread linked-to above. I will try using different versions of MinGW or even trying under Cygwin, I guess.
>
> In any event, Paul, I am curious if when you were trying to compile and had the same issue, were you using a different version or generation of gcc in the BLAS compilation than in the R compilation?
>
> Once again, thank you very much.
>
> Avraham Adler
>
>
> -----Original Message-----
> From: Paul Gilbert
> Sent: Thursday, May 30, 2013 12:26 AM
> To: Adler, Avraham
> Subject: Re: R-3.0.1 - "transient" make check failure in splines-EX.r
>
> Avraham
>
> I resolved this only by switching to a different BLAS on the 32 bit machine.Since no one else seemed to be having problems, I considered it possible that there was a hardware issue on my old 32 bit machine. The R check test failed somewhat randomly, but often. most disconcertingly, it failed because it gives different answers. If you source the code in an R session a few times you have no trouble reproducing this. It gives the impression of an improperly zeroed matrix.
>
> (All this from memory, I'm on the road.)
>
> Paul
>
> On 13-05-28 06:36 PM, Adler, Avraham wrote:
>>
>> Hello.
>>
>> I seem to be having the same problem that Paul had in the thread titled "[Rd] R 2.15.2 make check failure on 32-bit --with-blas="-lgoto2"" from October of last year <https://stat.ethz.ch/pipermail/r-devel/2012-October/065103.html> Unfortunately, that thread ended without an answer to his last question.
>>
>> Briefly, I am trying to compile an Rblas for Windows NT 32bit using OpenBlas (successor to GotoBlas) (Nehalem - corei7), and the compiled version passes all tests except for the "splines-Ex" test in the exact same place that Paul had issues:
>>
>> ~~~~
>>> stopifnot(identical(ns(x), ns(x, df = 1)),
>> + identical(ns(x, df = 2), ns(x, df = 2, knots = NULL)), # not true till 2.15.2
>> + !is.null(kk <- attr(ns(x), "knots")), # not true till 1.5.1
>> + length(kk) == 0)
>> Error: identical(ns(x, df = 2), ns(x, df = 2, knots = NULL)) is not
>> TRUE ~~~~
>>
>> Yet, opening up R and running the actual code shows that the error is transient:
>>
>> ~~~~
>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>> [1] TRUE
>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>> [1] TRUE
>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>> [1] TRUE
>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>> [1] FALSE
>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>> [1] TRUE
>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>> [1] TRUE
>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>> [1] TRUE
>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>> [1] TRUE
>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>> [1] TRUE
>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>> [1] FALSE
>> ~~~~
>>
>> This is the only error I have on the 32-bit version, I believe (trying to build a blas for 64-bit on SandyBridge is a completely different kettle of fish that is causing me to pull out what little hair I have left), and if it can be solved that would be great.
>>
>> Thank you,
>>
>> Avraham
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel 		 	   		  

From marchywka at hotmail.com  Fri May 31 17:44:34 2013
From: marchywka at hotmail.com (Mike Marchywka)
Date: Fri, 31 May 2013 11:44:34 -0400
Subject: [Rd] R-3.0.1 - "transient" make check failure in splines-EX.r
In-Reply-To: <93A2161604A30C4ABE14AC35CAFC8422DE40F420@USDFW11XM32.mercer.com>
References: <93A2161604A30C4ABE14AC35CAFC8422DDFC1D81@USDFW11XM32.mercer.com>,
	<51A6D4BF.2080507@gmail.com>,
	<E2263553A9D87A41A3E0E1B6FA4F19CAE56C7BEA@USDFW11XM32.mercer.com>,
	<93A2161604A30C4ABE14AC35CAFC8422DE40EF48@USDFW11XM32.mercer.com>,
	<BLU166-W517D410DB6093FAAFC770ABE910@phx.gbl>,
	<93A2161604A30C4ABE14AC35CAFC8422DE40F420@USDFW11XM32.mercer.com>
Message-ID: <BLU166-W1050AF2EC2C3590AF18662BE920@phx.gbl>

I think I just sent a reply to you but you can reply to list if you like.
This new menu just has reply and you have hunt for reply all LOL.?


----------------------------------------
> From: Avraham.Adler at guycarp.com
> To: marchywka at hotmail.com; r-devel at r-project.org
> Date: Fri, 31 May 2013 10:16:11 -0500
> Subject: RE: [Rd] R-3.0.1 - "transient" make check failure in splines-EX.r
>
> Thank you, Mike, I did not know that!
>
> I tried to prevent multi-threaded issues by setting the compiler options to be single-threaded, but I know so little about this area that there may be something else going on.
>
> Do you think that the same problem may be causing the 64-bit issue I am having (<https://stat.ethz.ch/pipermail/r-devel/2013-May/066731.html>)? I tend to think not, as I haven't seen changing results in the call to `optim`, and I still don't know what "NEW_X" means.
>
> Once again, thank you.
>
> Avraham Adler
>
>
> -----Original Message-----
> From: Mike Marchywka [mailto:marchywka at hotmail.com]
> Sent: Thursday, May 30, 2013 7:21 PM
> To: Adler, Avraham; 'r-devel at r-project.org'
> Subject: RE: [Rd] R-3.0.1 - "transient" make check failure in splines-EX.r
>
> ----------------------------------------
>> From: Avraham.Adler at guycarp.com
>> To: r-devel at r-project.org
>> Date: Thu, 30 May 2013 16:17:36 -0500
>> Subject: Re: [Rd] R-3.0.1 - "transient" make check failure in
>> splines-EX.r
>>
>> I just found this thread on StackOverflow <http://stackoverflow.com/questions/13871818/ns-varies-for-no-apparent-reason/13878936> which had the same problem with the `ns` call changing with Revolution, and the answer given by tech support was that the MKL BLAS sometime returns ever-so-slightly different floating point results than a reference BLAS. The problem with that answer is that if it is true, the runs should not change *on the same machine* but it is another example of this issue. Unfortunately, it seems to dead-end too.
>>
>
> Read some of the documents on the Intel site about floating point consistency and compiler optimizations. There are some reasons that you could get a different result from repeated runs on the same machine. One of these would be bugs like unititialized memory but another would be things like state of FPU and issues with multi-threaded code having some order dependencies etc.
>
> ( hotmail can not believe I am trying to post text but maybe you can figure it out from whatver this link eds up looking like.... )
> href="http://www.google.com/search?biw=1253&bih=542&hl=en&q=floating+point+low+bits+vary+fpu+prior+state+site%253Aintel.com&oq=floating+point+low+bits+vary+fpu+prior+state+site%253Aintel.com"
>
>
>
>
>> Avraham
>>
>>
>> -----Original Message-----
>> From: Adler, Avraham
>> Sent: Thursday, May 30, 2013 3:12 PM
>> To: Paul Gilbert
>> Cc: r-devel at r-project.org
>> Subject: RE: R-3.0.1 - "transient" make check failure in splines-EX.r
>>
>> Thank you very much, Paul.
>>
>> Serendipitously, I seem to have stumbled on a solution. In my parallel (still unsuccessful) attempt to build a BLAS for a 64bit machine (see <https://stat.ethz.ch/pipermail/r-devel/2013-May/066731.html>) I remembered from ATLAS that under the newer Windows there is a divergence from the "standard" ABI (see <http://math-atlas.sourceforge.net/atlas_install/node57.html>).
>>
>> Looking through the various makefiles under OpenBLAS, I found the following:
>>
>> ifeq ($(C_COMPILER), GCC)
>> #Test for supporting MS_ABI
>> GCCVERSIONGTEQ4 := $(shell expr `$(CC) -dumpversion | cut -f1 -d.` \>= 4)
>> GCCVERSIONGT4 := $(shell expr `$(CC) -dumpversion | cut -f1 -d.` \> 4)
>> GCCMINORVERSIONGTEQ7 := $(shell expr `$(CC) -dumpversion | cut -f2 -d.` \>= 7)
>> ifeq ($(GCCVERSIONGT4), 1)
>> # GCC Majar version> 4
>> # It is compatible with MSVC ABI.
>> CCOMMON_OPT += -DMS_ABI
>> endif
>>
>> I had been building OPBL using gcc4.8.0, which is ostensibly "compatible" with the newer ABI, but Rtools still lives in 4.6.3, which isn't. Recompiling the BLAS with MinGW32 for 4.6.3 created a file that has passed `make check-all` twice now. I plan on comparing the speed with the ATLAS-based blas, and if it is faster, I hope to e-mail the dll and check results to Dr. Ligges.
>>
>> I say "stumbled serendipitously" because when using the 64 bit version of MinGw 4.6.3 resulted in the same `optim`-based error in `factanal` which I describe in the thread linked-to above. I will try using different versions of MinGW or even trying under Cygwin, I guess.
>>
>> In any event, Paul, I am curious if when you were trying to compile and had the same issue, were you using a different version or generation of gcc in the BLAS compilation than in the R compilation?
>>
>> Once again, thank you very much.
>>
>> Avraham Adler
>>
>>
>> -----Original Message-----
>> From: Paul Gilbert
>> Sent: Thursday, May 30, 2013 12:26 AM
>> To: Adler, Avraham
>> Subject: Re: R-3.0.1 - "transient" make check failure in splines-EX.r
>>
>> Avraham
>>
>> I resolved this only by switching to a different BLAS on the 32 bit machine.Since no one else seemed to be having problems, I considered it possible that there was a hardware issue on my old 32 bit machine. The R check test failed somewhat randomly, but often. most disconcertingly, it failed because it gives different answers. If you source the code in an R session a few times you have no trouble reproducing this. It gives the impression of an improperly zeroed matrix.
>>
>> (All this from memory, I'm on the road.)
>>
>> Paul
>>
>> On 13-05-28 06:36 PM, Adler, Avraham wrote:
>>>
>>> Hello.
>>>
>>> I seem to be having the same problem that Paul had in the thread titled "[Rd] R 2.15.2 make check failure on 32-bit --with-blas="-lgoto2"" from October of last year <https://stat.ethz.ch/pipermail/r-devel/2012-October/065103.html> Unfortunately, that thread ended without an answer to his last question.
>>>
>>> Briefly, I am trying to compile an Rblas for Windows NT 32bit using OpenBlas (successor to GotoBlas) (Nehalem - corei7), and the compiled version passes all tests except for the "splines-Ex" test in the exact same place that Paul had issues:
>>>
>>> ~~~~
>>>> stopifnot(identical(ns(x), ns(x, df = 1)),
>>> + identical(ns(x, df = 2), ns(x, df = 2, knots = NULL)), # not true till 2.15.2
>>> + !is.null(kk <- attr(ns(x), "knots")), # not true till 1.5.1
>>> + length(kk) == 0)
>>> Error: identical(ns(x, df = 2), ns(x, df = 2, knots = NULL)) is not
>>> TRUE ~~~~
>>>
>>> Yet, opening up R and running the actual code shows that the error is transient:
>>>
>>> ~~~~
>>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>>> [1] TRUE
>>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>>> [1] TRUE
>>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>>> [1] TRUE
>>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>>> [1] FALSE
>>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>>> [1] TRUE
>>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>>> [1] TRUE
>>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>>> [1] TRUE
>>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>>> [1] TRUE
>>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>>> [1] TRUE
>>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>>> [1] FALSE
>>> ~~~~
>>>
>>> This is the only error I have on the 32-bit version, I believe (trying to build a blas for 64-bit on SandyBridge is a completely different kettle of fish that is causing me to pull out what little hair I have left), and if it can be solved that would be great.
>>>
>>> Thank you,
>>>
>>> Avraham
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel 		 	   		  

From ivo.welch at anderson.ucla.edu  Fri May 31 18:14:02 2013
From: ivo.welch at anderson.ucla.edu (ivo welch)
Date: Fri, 31 May 2013 09:14:02 -0700
Subject: [Rd] R 3.0.1 : parallel collection triggers "long memory not
	supported yet"
Message-ID: <CAPr7RtU6+YBC=yifDsU0k0BScur0waDM2ZQjEz6FCv3QHvLJeg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130531/e6028944/attachment.pl>

From Avraham.Adler at guycarp.com  Fri May 31 18:43:32 2013
From: Avraham.Adler at guycarp.com (Adler, Avraham)
Date: Fri, 31 May 2013 11:43:32 -0500
Subject: [Rd] R-3.0.1 - "transient" make check failure in splines-EX.r
In-Reply-To: <BLU166-W10A8E9D67B70F1C467ABC0BE920@phx.gbl>
References: <93A2161604A30C4ABE14AC35CAFC8422DDFC1D81@USDFW11XM32.mercer.com>,
	<51A6D4BF.2080507@gmail.com>,
	<E2263553A9D87A41A3E0E1B6FA4F19CAE56C7BEA@USDFW11XM32.mercer.com>,
	<93A2161604A30C4ABE14AC35CAFC8422DE40EF48@USDFW11XM32.mercer.com>,
	<BLU166-W517D410DB6093FAAFC770ABE910@phx.gbl>,
	<93A2161604A30C4ABE14AC35CAFC8422DE40F420@USDFW11XM32.mercer.com>
	<BLU166-W10A8E9D67B70F1C467ABC0BE920@phx.gbl>
Message-ID: <93A2161604A30C4ABE14AC35CAFC8422DE40F5AB@USDFW11XM32.mercer.com>

Fascinating. Of course, I am so far out of my league now that I wouldn't have any idea of how to address the issues, let alone break down the performance into assembly calls and identify the problem.

Once again, thank you for the insight!

Avraham Adler

-----Original Message-----
From: Mike Marchywka
Sent: Friday, May 31, 2013 11:43 AM
To: Adler, Avraham
Subject: RE: [Rd] R-3.0.1 - "transient" make check failure in splines-EX.r

----------------------------------------
> From: Avraham.Adler at guycarp.com
> To: marchywka at hotmail.com; r-devel at r-project.org
> Date: Fri, 31 May 2013 10:16:11 -0500
> Subject: RE: [Rd] R-3.0.1 - "transient" make check failure in 
> splines-EX.r
>
> Thank you, Mike, I did not know that!
>
> I tried to prevent multi-threaded issues by setting the compiler options to be single-threaded, but I know so little about this area that there may be something else going on.
>
> Do you think that the same problem may be causing the 64-bit issue I am having (<https://stat.ethz.ch/pipermail/r-devel/2013-May/066731.html>)? I tend to think not, as I haven't seen changing results in the call to `optim`, and I still don't know what "NEW_X" means.
>

I really did not even know what you were trying to do and multi threading had not occured to me until I checked the latest on their site :). I'd just browse their performance related publications. Floating point is not reproducible except in java although I guess there too the mulithreading could mess it up if the order of summations changes for example.
But of course do not ignore real bugs like unitialized memory. I remember once our codec started running real slow even though the audio it was encoding still sounded ok. This turned out to be doing some processing on unitialized memory which typically cuased fp exceptions that are VERY slow. So even something not of consequence to the output could effect performance.


> Once again, thank you.
>
> Avraham Adler
>
>
> -----Original Message-----
> From: Mike Marchywka [mailto:marchywka at hotmail.com]
> Sent: Thursday, May 30, 2013 7:21 PM
> To: Adler, Avraham; 'r-devel at r-project.org'
> Subject: RE: [Rd] R-3.0.1 - "transient" make check failure in 
> splines-EX.r
>
> ----------------------------------------
>> From: Avraham.Adler at guycarp.com
>> To: r-devel at r-project.org
>> Date: Thu, 30 May 2013 16:17:36 -0500
>> Subject: Re: [Rd] R-3.0.1 - "transient" make check failure in 
>> splines-EX.r
>>
>> I just found this thread on StackOverflow <http://stackoverflow.com/questions/13871818/ns-varies-for-no-apparent-reason/13878936> which had the same problem with the `ns` call changing with Revolution, and the answer given by tech support was that the MKL BLAS sometime returns ever-so-slightly different floating point results than a reference BLAS. The problem with that answer is that if it is true, the runs should not change *on the same machine* but it is another example of this issue. Unfortunately, it seems to dead-end too.
>>
>
> Read some of the documents on the Intel site about floating point consistency and compiler optimizations. There are some reasons that you could get a different result from repeated runs on the same machine. One of these would be bugs like unititialized memory but another would be things like state of FPU and issues with multi-threaded code having some order dependencies etc.
>
> ( hotmail can not believe I am trying to post text but maybe you can 
> figure it out from whatver this link eds up looking like.... ) href="http://www.google.com/search?biw=1253&bih=542&hl=en&q=floating+point+low+bits+vary+fpu+prior+state+site%253Aintel.com&oq=floating+point+low+bits+vary+fpu+prior+state+site%253Aintel.com"
>
>
>
>
>> Avraham
>>
>>
>> -----Original Message-----
>> From: Adler, Avraham
>> Sent: Thursday, May 30, 2013 3:12 PM
>> To: Paul Gilbert
>> Cc: r-devel at r-project.org
>> Subject: RE: R-3.0.1 - "transient" make check failure in splines-EX.r
>>
>> Thank you very much, Paul.
>>
>> Serendipitously, I seem to have stumbled on a solution. In my parallel (still unsuccessful) attempt to build a BLAS for a 64bit machine (see <https://stat.ethz.ch/pipermail/r-devel/2013-May/066731.html>) I remembered from ATLAS that under the newer Windows there is a divergence from the "standard" ABI (see <http://math-atlas.sourceforge.net/atlas_install/node57.html>).
>>
>> Looking through the various makefiles under OpenBLAS, I found the following:
>>
>> ifeq ($(C_COMPILER), GCC)
>> #Test for supporting MS_ABI
>> GCCVERSIONGTEQ4 := $(shell expr `$(CC) -dumpversion | cut -f1 -d.` 
>> \>= 4)
>> GCCVERSIONGT4 := $(shell expr `$(CC) -dumpversion | cut -f1 -d.` \> 
>> 4)
>> GCCMINORVERSIONGTEQ7 := $(shell expr `$(CC) -dumpversion | cut -f2 
>> -d.` \>= 7) ifeq ($(GCCVERSIONGT4), 1) # GCC Majar version> 4 # It is
>> compatible with MSVC ABI.
>> CCOMMON_OPT += -DMS_ABI
>> endif
>>
>> I had been building OPBL using gcc4.8.0, which is ostensibly "compatible" with the newer ABI, but Rtools still lives in 4.6.3, which isn't. Recompiling the BLAS with MinGW32 for 4.6.3 created a file that has passed `make check-all` twice now. I plan on comparing the speed with the ATLAS-based blas, and if it is faster, I hope to e-mail the dll and check results to Dr. Ligges.
>>
>> I say "stumbled serendipitously" because when using the 64 bit version of MinGw 4.6.3 resulted in the same `optim`-based error in `factanal` which I describe in the thread linked-to above. I will try using different versions of MinGW or even trying under Cygwin, I guess.
>>
>> In any event, Paul, I am curious if when you were trying to compile and had the same issue, were you using a different version or generation of gcc in the BLAS compilation than in the R compilation?
>>
>> Once again, thank you very much.
>>
>> Avraham Adler
>>
>>
>> -----Original Message-----
>> From: Paul Gilbert
>> Sent: Thursday, May 30, 2013 12:26 AM
>> To: Adler, Avraham
>> Subject: Re: R-3.0.1 - "transient" make check failure in splines-EX.r
>>
>> Avraham
>>
>> I resolved this only by switching to a different BLAS on the 32 bit machine.Since no one else seemed to be having problems, I considered it possible that there was a hardware issue on my old 32 bit machine. The R check test failed somewhat randomly, but often. most disconcertingly, it failed because it gives different answers. If you source the code in an R session a few times you have no trouble reproducing this. It gives the impression of an improperly zeroed matrix.
>>
>> (All this from memory, I'm on the road.)
>>
>> Paul
>>
>> On 13-05-28 06:36 PM, Adler, Avraham wrote:
>>>
>>> Hello.
>>>
>>> I seem to be having the same problem that Paul had in the thread titled "[Rd] R 2.15.2 make check failure on 32-bit --with-blas="-lgoto2"" from October of last year <https://stat.ethz.ch/pipermail/r-devel/2012-October/065103.html> Unfortunately, that thread ended without an answer to his last question.
>>>
>>> Briefly, I am trying to compile an Rblas for Windows NT 32bit using OpenBlas (successor to GotoBlas) (Nehalem - corei7), and the compiled version passes all tests except for the "splines-Ex" test in the exact same place that Paul had issues:
>>>
>>> ~~~~
>>>> stopifnot(identical(ns(x), ns(x, df = 1)),
>>> + identical(ns(x, df = 2), ns(x, df = 2, knots = NULL)), # not true 
>>> + till 2.15.2 !is.null(kk <- attr(ns(x), "knots")), # not true till 
>>> + 1.5.1
>>> + length(kk) == 0)
>>> Error: identical(ns(x, df = 2), ns(x, df = 2, knots = NULL)) is not 
>>> TRUE ~~~~
>>>
>>> Yet, opening up R and running the actual code shows that the error is transient:
>>>
>>> ~~~~
>>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>>> [1] TRUE
>>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>>> [1] TRUE
>>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>>> [1] TRUE
>>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>>> [1] FALSE
>>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>>> [1] TRUE
>>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>>> [1] TRUE
>>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>>> [1] TRUE
>>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>>> [1] TRUE
>>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>>> [1] TRUE
>>>> identical(ns(x, df = 2), ns(x, df = 2, knots = NULL))
>>> [1] FALSE
>>> ~~~~
>>>
>>> This is the only error I have on the 32-bit version, I believe (trying to build a blas for 64-bit on SandyBridge is a completely different kettle of fish that is causing me to pull out what little hair I have left), and if it can be solved that would be great.
>>>
>>> Thank you,
>>>
>>> Avraham
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel 		 	   		  

From simon.urbanek at r-project.org  Fri May 31 18:47:01 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 31 May 2013 12:47:01 -0400
Subject: [Rd] R 3.0.1 : parallel collection triggers "long memory not
	supported yet"
In-Reply-To: <CAPr7RtU6+YBC=yifDsU0k0BScur0waDM2ZQjEz6FCv3QHvLJeg@mail.gmail.com>
References: <CAPr7RtU6+YBC=yifDsU0k0BScur0waDM2ZQjEz6FCv3QHvLJeg@mail.gmail.com>
Message-ID: <F40B4AC5-760B-4AD4-A28C-85B13183D911@r-project.org>

On May 31, 2013, at 12:14 PM, ivo welch wrote:

> Dear R developers:
> 
> ...
> 7: lapply(seq_len(cores), inner.do)
> 8: FUN(1:3[[3]], ...)
> 9: sendMaster(try(lapply(X = S, FUN = FUN, ...), silent = TRUE))
> 
> Selection: .....................Error in sendMaster(try(lapply(X = S, FUN =
> FUN, ...), silent = TRUE)) :
>  long vectors not supported yet: memory.c:3100
> 
> 
> admittedly, my outcome will be a very big list, with 30,000 elements, each
> containing data frames with 14 variables and around 200 to 5000
> observations (say, 64KB on average).  thus, I estimate that the resulting
> list is 20GB.  the specific code that triggers this is
> 
> 
>    exposures.list <- mclapply(1:length(crsp.list.by.permno),
>                          FUN=function(i, NMO=NMO) {
> 
> calcbeta.for.one.stock(crsp.list.by.permno[[i]], NMO=NMO)
>                          },
>                          NMO=NMO, mc.cores=3 )
> 
> the release docs to 3.0.0 suggest this error should occur primarily in
> unusual situations.  so, it's not really a bug.  but I thought I would
> point this out.  maybe this is a forgotten updatedlet.
> 

mclapply uses sendMaster() to send the results (serialized into a raw vector) from the worker back to the parent R session. Apparently your serialized result from one worker is more than 2Gb. The multicore part of parallel currently doesn't support long vectors for the transmission so the result for one worker cannot exceed 2Gb. I'll put long vector support on my ToDo list. In your case you should be able to work around it by disabling pre-scheduling (you may want to do some grouping if you have 30,000 short iterations, though).

Cheers,
Simon


