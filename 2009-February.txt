From jmc at r-project.org  Sun Feb  1 00:15:25 2009
From: jmc at r-project.org (John Chambers)
Date: Sat, 31 Jan 2009 15:15:25 -0800
Subject: [Rd] Inherited Methods in r-devel (for package maintainers
	mainly)
In-Reply-To: <497E6AF8.50105@r-project.org>
References: <497E6AF8.50105@r-project.org>
Message-ID: <4984DB8D.4010800@r-project.org>

The revisions below have been re-committed (r47803), and appear to be 
compatible with the current Matrix package ('0.999375-19').  Thanks to 
Martin Maechler for help with Matrix.

John Chambers wrote:
> A recently committed revison of R-devel (47740) has introduced a new 
> mechanism for ordering superclasses consistently, with related changes 
> for selecting inherited methods.
>
> As part of the process, a function testInheritedMethods has been  
> introduced that examines method selection for the relevant subclasses 
> and reports ambiguities.
>
> Maintainers of packages that have methods involving multiple arguments 
> are encouraged to run testInheritedMethods for the relevant generic 
> functions (e.g., the binary operators).  The new method selection is 
> unambiguous for single-argument selection.
>
> It's preferable  to find such ambiguities during package development 
> or revision, rather than having users encounter ambiguous method 
> selection later on.  In that spirit, ambiguous method selection is no 
> longer a warning, just a message.
>
> The new mechanism for class ordering and method selection is described 
> in a draft paper at 
> http://stat.stanford.edu/~jmc4/classInheritance.pdf (later likely to 
> be part of a submission to the R Journal).
>
> John
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From murdoch at stats.uwo.ca  Sun Feb  1 00:33:11 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 31 Jan 2009 18:33:11 -0500
Subject: [Rd] (PR#8192) [ subscripting sometimes loses names
In-Reply-To: <c0177e5a0901311226k6ec55fffk67455d5843dca4bc@mail.gmail.com>
References: <157EE908-8A6C-46E4-A9FF-A933A25DEFD9@r-project.org>	<20090131123158.GA31706@piskorski.com>
	<49845A8A.70000@stats.uwo.ca>	<49846A9A.8070308@biostat.ku.dk>
	<c0177e5a0901311226k6ec55fffk67455d5843dca4bc@mail.gmail.com>
Message-ID: <4984DFB7.9080101@stats.uwo.ca>

On 31/01/2009 3:26 PM, Christian Brechb?hler wrote:
> On Sat, Jan 31, 2009 at 10:13 AM, Peter Dalgaard
> <p.dalgaard at biostat.ku.dk>wrote:
> 
>> Duncan Murdoch wrote:
>>
>>> On 31/01/2009 7:31 AM, Andrew Piskorski wrote:
>>>
>>>> On Fri, Jan 30, 2009 at 11:51:00AM -0500, Simon Urbanek wrote:
>>>>
>>>>> Subject: Re: [Rd] (PR#13487) Segfault when mistakenly calling
>>>>> [.data.frame
>>>>>
>>>>  ever tried drop=FALSE ?
>>>> Simon, no, the drop=FALSE argument has nothing to do with what
>>>> Christian was talking about.  The kind of thing he meant is PR# 8192,
>>>> "Subject: [ subscripting sometimes loses names":
>>>>
>>>>  http://bugs.r-project.org/cgi-bin/R/wishlist?id=8192
>>>>
>>> In that bug report you were asked to provide simple examples, and you
>>> didn't.
>>> ...
>>> I just tracked this one down, and can put together this simple example:
>>>
>>>  > (1:3)["no"]
>>> [1] NA
>>>
>>> where I think you would want the name "no" attached to the output.
>> No, it has nothing to do with indexing by name.  It's about preserving
> existing names when subsetting.

I think you misread my message.

> 
> And the other two cases where you list "BAD" behaviour?  I didn't track them
>>> down.
>>>
>> I did, and they boil down to variations of
>>
>>> data.frame(val=1:3,row.names=letters[1:3])[,1]
>> [1] 1 2 3
>>
>> but it's not obvious that the result should be named using the row.names
>> and (in particular) whether or why it should differ from .....[[1]] and
>> ....$val. Given that for most purposes, extracting the relevant names would
>> just be unnecessary red tape, I'd say that we can do without it.
> 
> 
> Compare
> 
>> data.frame(val=1:3,row.names=letters[1:3])[,1]
> [1] 1 2 3
>> as.matrix(data.frame(val=1:3,row.names=letters[1:3]))[,1]
> a b c
> 1 2 3
> 
> X[,1] preserves row names if X is a matrix, and loses them if X is a data
> frame.  To me, this is ugly and inconsistent.
> 
> One might argue that having names and dimnames at all is "red tape", and
> wastes memory and computational efficiency -- after all, Fortran arrays had
> no names.  But R chose to drag along the names (sometimes), and it can be
> very helpful to us humans.  Now R should do it consistently.

In one case you're working with a matrix, and in the other, a dataframe. 
  So perfect consistency is impossible:  matrices and dataframes are not 
the same.  So it's a matter of deciding how much consistency is worth 
pursuing.  Now, it seems nobody thinks this is worth pursuing:  so it 
won't get changed.

To get it changed, you should make the change, then investigate what 
would break the change were adopted, and what would become slower, etc. 
  Or convince someone else to do that.  But the fact that you think it's 
ugly is probably not convincing.

Duncan Murdoch


From TimHesterberg at gmail.com  Sun Feb  1 18:25:50 2009
From: TimHesterberg at gmail.com (Tim Hesterberg)
Date: Sun, 01 Feb 2009 09:25:50 -0800
Subject: [Rd] (PR#8192) [ subscripting sometimes loses names
In-Reply-To: <20090131123158.GA31706@piskorski.com> (message from Andrew
	Piskorski on Sat, 31 Jan 2009 07:31:58 -0500)
References: <20090131123158.GA31706@piskorski.com>
Message-ID: <utz7eoyqp.fsf@gmail.com>

>...
>Simon, no, the drop=FALSE argument has nothing to do with what
>Christian was talking about.  The kind of thing he meant is PR# 8192,
>"Subject: [ subscripting sometimes loses names":
>
>  http://bugs.r-project.org/cgi-bin/R/wishlist?id=8192
>
>In R, subscripting with "[" USUALLY retains names, but R has various
>edge cases where it (IMNSHO) inappropriately discards them.  This
>occurs with both .Primitive("[") and "[.data.frame".  This has been
>known for years, but I have not yet tried digging into R's
>implementation to see where and how the names are actually getting
>lost.
>
>Incidentally, versions of S-Plus since approximately S-Plus 6.0 back
>in 2001 show similar buggy edge case behavior.  Older versions of
>S-Plus, c. S-Plus 3.3 and earlier, had the correct, name preserving
>behavior.  I presume that the original Bell Labs S had correct
>name-preserving behavior, and then the S-Plus developers broke it
>sometime along the way.

(Later comments on the thread pointed out the difference between
x[,1] for matrices and data frames.)

I rewrote the S-PLUS data frame code around then, to fix
various inconsistencies and improve efficiency.
This was probably my change, and I would do it again.

Note that the components of a data frame do not have names
attached to them; the row names are a separate object.
Extracting a component vector or matrix from a data frame should not
attach names to the result, because of:
* memory (attaching row names to an object can more than double the
  size of the object),
* speed
* some objects cannot take names, and attaching them could change
  the class and other behavior of an object, and
* the names are usually/often (depending on the user) meaningless,
  artifacts of an early design decision that all data frames have row names.

Data frames differ from matrices in two ways that matter here:
* columns in matrices are all the same kind, and are simple objects
  (numeric, etc.), whereas components of data frames can be nearly
  arbitrary objects, and
* row names get added to a data frame whether a user wants them or not,
  whereas row names on a matrix have to be specified.

A historical note - unique row names on data frame were a design
decision made when people worked with small data frames, and are
convenient for small data frames.  But they are a problem for large
data frames.  I was writing for all users, not just those with small
data frames and meaningful names.

I like R's 'automatic' row names.  This is a big help working with
huge data frames (and I do this often, at Google).  But this doesn't
go far enough; subscripting and other operations sometimes convert the
automatic names to real names, and check/enforce uniqueness, which is
a big waste of time when working with large data frames.  I'll comment
more on this in a new thread.

Tim Hesterberg


From TimHesterberg at gmail.com  Sun Feb  1 18:29:43 2009
From: TimHesterberg at gmail.com (Tim Hesterberg)
Date: Sun, 01 Feb 2009 09:29:43 -0800
Subject: [Rd] non-duplicate names in data frames
References: <20090131123158.GA31706@piskorski.com>
Message-ID: <uskmyoyk8.fsf@gmail.com>

I wrote on another thread
(with subject "[ subscripting sometimes loses names"):
>I like R's 'automatic' row names.  This is a big help working with
>huge data frames (and I do this often, at Google).  But this doesn't
>go far enough; subscripting and other operations sometimes convert the
>automatic names to real names, and check/enforce uniqueness, which is
>a big waste of time when working with large data frames.  I'll comment
>more on this in a new thread.

I propose (and have begun writing, in my copious spare time):
* an optional argument to data.frame and other data frame creation code
* resulting in an attribute added to the data.frame
* so that subscripting and other operations on the data frame
  * always keep artificial row names
  * do not have to check for unique row names in the result.

My current thoughts, comments welcome:

Argument name and component name 'dup.row.names'
0 or FALSE or NULL - current, require unique names
1 or TRUE          - duplicates allowed (when subscripting etc.)
2                  - always automatic   (when subscripting etc.)

Option "maxRowNames", default say 10^4
Any data frames with more than this have dup.row.names default to 2.

The name 'dup.row.names' is for consistency with S+; there the options
are NULL, F or T.

Tim Hesterberg


From andreas.fischlin at env.ethz.ch  Sun Feb  1 19:50:14 2009
From: andreas.fischlin at env.ethz.ch (andreas.fischlin at env.ethz.ch)
Date: Sun,  1 Feb 2009 19:50:14 +0100 (CET)
Subject: [Rd] R.home() of R 2.8.1 Mac OS X is wrong (PR#13494)
Message-ID: <20090201185014.59DBD282EF48@mail.pubhealth.ku.dk>

Full_Name: Andreas Fischlin
Version: 2.8.1
OS: Mac OS X 10.5.6
Submission from: (NULL) (84.75.178.229)


R.home() returns "/Library/Frameworks/R.framework/Resources" although there is
no such directory present. Inspecting the actual directory structure of the R
installation indicates that the correct value R.home() should contain is:
'/Library/Frameworks/R.framework/Versions/2.8/Resources'

Detected by af, ETH Zurich / 1.Feb.2009 using R 2.8.1 under Mac OS X 10.5.6


From simon.urbanek at r-project.org  Sun Feb  1 20:25:02 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sun, 1 Feb 2009 14:25:02 -0500
Subject: [Rd] R.home() of R 2.8.1 Mac OS X is wrong (PR#13494)
In-Reply-To: <20090201185014.59DBD282EF48@mail.pubhealth.ku.dk>
References: <20090201185014.59DBD282EF48@mail.pubhealth.ku.dk>
Message-ID: <4D1BBAD9-92CC-4BF1-9432-C6A39ECBE621@r-project.org>

On Feb 1, 2009, at 1:50 PM, andreas.fischlin at env.ethz.ch wrote:

> Full_Name: Andreas Fischlin
> Version: 2.8.1
> OS: Mac OS X 10.5.6
> Submission from: (NULL) (84.75.178.229)
>
>
> R.home() returns "/Library/Frameworks/R.framework/Resources"  
> although there is
> no such directory present.

Then your installation is broken. You should re-install R to fix your  
installation.

In R 2.8.1:
fino:~$ file /Library/Frameworks/R.framework/Resources
/Library/Frameworks/R.framework/Resources: directory

This is true for all R installations from CRAN as well as all custom  
installations with framework enabled (default on OS X).

Cheers,
S


> Inspecting the actual directory structure of the R
> installation indicates that the correct value R.home() should  
> contain is:
> '/Library/Frameworks/R.framework/Versions/2.8/Resources'
>


From ripley at stats.ox.ac.uk  Sun Feb  1 20:34:45 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 1 Feb 2009 19:34:45 +0000 (GMT)
Subject: [Rd] R.home() of R 2.8.1 Mac OS X is wrong (PR#13494)
In-Reply-To: <20090201185014.59DBD282EF48@mail.pubhealth.ku.dk>
References: <20090201185014.59DBD282EF48@mail.pubhealth.ku.dk>
Message-ID: <alpine.LFD.2.00.0902011932050.30737@gannet.stats.ox.ac.uk>

It is present on my system (R reinstalled yesterday), so it looks like 
you broke yours.

More precisely, there is a link at 
/Library/Frameworks/R.framework/Resources to the correct place.

How did you think R could possibly work with this broken?  R.home() is 
used all over the place in R's own scripts.

On Sun, 1 Feb 2009, andreas.fischlin at env.ethz.ch wrote:

> Full_Name: Andreas Fischlin
> Version: 2.8.1
> OS: Mac OS X 10.5.6
> Submission from: (NULL) (84.75.178.229)
>
>
> R.home() returns "/Library/Frameworks/R.framework/Resources" although there is
> no such directory present. Inspecting the actual directory structure of the R
> installation indicates that the correct value R.home() should contain is:
> '/Library/Frameworks/R.framework/Versions/2.8/Resources'
>
> Detected by af, ETH Zurich / 1.Feb.2009 using R 2.8.1 under Mac OS X 10.5.6
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From paciorek at hsph.harvard.edu  Sun Feb  1 22:20:59 2009
From: paciorek at hsph.harvard.edu (Christopher Paciorek)
Date: Sun, 01 Feb 2009 16:20:59 -0500
Subject: [Rd] possible memory leak involving looping, optimization, and gam
References: <49846B100200002E0006CD8B@hsph.harvard.edu>
	<4985CBEB0200002E0006CDF4@hsph.harvard.edu>
Message-ID: <4985CBFB.10CD.002E.0@hsph.harvard.edu>

When I run the gam function as part of an optimization and do the optimization many times using a loop, I'm finding that memory use increases over time (based on simply monitoring top).  Below is some example code that involves varying the penalty parameter in gam, trying to find the value that gives exactly 50 edf for a simple smoothing problem.  I thought I would post to the list to see if anyone had any ideas of what might be going on and if indeed this is a memory leak.

I'm running R2.8.0 (64-bit) under RHEL4 on a cluster as well as R2.8.1 under Fedora 10 on an individual machine, both Intel-based.  
The issue does not seem to occur on a Windows XP machine with R 2.6.1  (32-bit), nor on Mac OSX (Leopard) with R2.6.2.

mgcv versions are  1.4-1 for Linux and 1.3-29 for Windows and Mac.

n=700
x=runif(n)
dist=abs(matrix(x,n,n,byrow=TRUE)-matrix(x,n,n,byrow=FALSE))
Sigma=exp(-dist/0.3)
y=t(chol(Sigma))%*%rnorm(n)

psFun=function(spVal,dfWanted){
  return((summary(gam(y~s(x,k=400),sp=spVal))$edf-dfWanted)^2)
}

for(i in 1:10000){
  spVal=optimize(psFun,c(.00001,500),50)$minimum
  print(i)
}

Note that the same issue seems to arise regardless of whether I use uniroot, optimize, nlminb, or nlm to do the optimization.

-chris

----------------------------------------------------------------------------------------------
Chris Paciorek / Asst. Professor        Email: paciorek at hsph.harvard.edu
Department of Biostatistics             Voice: 617-432-4912
Harvard School of Public Health         Fax:   617-432-5619
655 Huntington Av., Bldg. 2-407         WWW: www.biostat.harvard.edu/~paciorek
Boston, MA 02115 USA                    Permanent forward: paciorek at alumni.cmu.edu


From andreas.fischlin at env.ethz.ch  Sun Feb  1 22:29:48 2009
From: andreas.fischlin at env.ethz.ch (Andreas Fischlin)
Date: Sun, 01 Feb 2009 22:29:48 +0100
Subject: [Rd] R.home() of R 2.8.1 Mac OS X is wrong (PR#13494)
In-Reply-To: <alpine.LFD.2.00.0902011932050.30737@gannet.stats.ox.ac.uk>
References: <20090201185014.59DBD282EF48@mail.pubhealth.ku.dk>
	<alpine.LFD.2.00.0902011932050.30737@gannet.stats.ox.ac.uk>
Message-ID: <4986144C.8020108@env.ethz.ch>

Thank you all for the replies. However, I figured it now out, there is 
nothing broken. The reason I got confused is only because there are 
symbolic links used extensively and some tests failed in my script as a 
consequence (see below).

My installation is fine and looks in fact like this:

afischli$ cd /Library/Frameworks/R.framework
afischli$ ls -l
total 40
lrwxr-xr-x  1 root  admin   24 Jan 13 15:24 Headers -> 
Versions/Current/Headers
lrwxr-xr-x  1 root  admin   30 Jan 13 15:24 Libraries -> 
Versions/Current/Resources/lib
lrwxr-xr-x  1 root  admin   31 Jan 13 15:24 PrivateHeaders -> 
Versions/Current/PrivateHeaders
lrwxr-xr-x  1 root  admin   18 Jan 13 15:24 R -> Versions/Current/R
lrwxr-xr-x  1 root  admin   26 Jan 13 15:24 Resources -> 
Versions/Current/Resources
drwxrwxr-x  7 root  admin  238 Feb  1 20:17 Versions
afischli$ cd Versions
afischli$ ls -l
total 8
drwxrwxr-x  6 root  admin  204 May 24  2007 2.5
drwxrwxr-x  6 root  admin  204 Nov 30  2007 2.6
drwxrwxr-x  6 root  admin  204 Jan 13 15:24 2.8
lrwxr-xr-x  1 root  admin    3 Jan 13 15:24 Current -> 2.8

This means there is nothing broken. The consequence is that R commands 
such as:

 > R.home()
[1] "/Library/Frameworks/R.framework/Resources"
 > setwd(R.home())
 > getwd()
[1] "/Library/Frameworks/R.framework/Versions/2.8/Resources"

give differing answers, which means that a test such as

setwd(R.home())
if (getwd() == R.home()) {

always fails, although the setwd command was actually successful. Guess 
this all explains the problem and sorry for the bandwidth waste ;-)

Regards,
Andreas Fischlin

________________________________________________________________________
ETH Zurich
Prof. Dr. Andreas Fischlin
Systems Ecology - Institute of Integrative Biology
CHN E 21.1
Universitaetstrasse 16
8092 Zurich
SWITZERLAND

andreas.fischlin at env.ethz.ch
www.sysecol.ethz.ch

+41 44 633-6090 phone
+41 44 633-1136 fax

             Make it as simple as possible, but distrust it!
________________________________________________________________________



Prof Brian Ripley wrote:
> It is present on my system (R reinstalled yesterday), so it looks like 
> you broke yours.
>
> More precisely, there is a link at 
> /Library/Frameworks/R.framework/Resources to the correct place.
>
> How did you think R could possibly work with this broken?  R.home() is 
> used all over the place in R's own scripts.
>
> On Sun, 1 Feb 2009, andreas.fischlin at env.ethz.ch wrote:
>
>> Full_Name: Andreas Fischlin
>> Version: 2.8.1
>> OS: Mac OS X 10.5.6
>> Submission from: (NULL) (84.75.178.229)
>>
>>
>> R.home() returns "/Library/Frameworks/R.framework/Resources" although 
>> there is
>> no such directory present. Inspecting the actual directory structure 
>> of the R
>> installation indicates that the correct value R.home() should contain 
>> is:
>> '/Library/Frameworks/R.framework/Versions/2.8/Resources'
>>
>> Detected by af, ETH Zurich / 1.Feb.2009 using R 2.8.1 under Mac OS X 
>> 10.5.6
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
-- 

* *

From brechbuehler at gmail.com  Mon Feb  2 03:12:27 2009
From: brechbuehler at gmail.com (=?ISO-8859-1?Q?Christian_Brechb=FChler?=)
Date: Sun, 1 Feb 2009 21:12:27 -0500
Subject: [Rd] (PR#8192) [ subscripting sometimes loses names
In-Reply-To: <utz7eoyqp.fsf@gmail.com>
References: <20090131123158.GA31706@piskorski.com> <utz7eoyqp.fsf@gmail.com>
Message-ID: <c0177e5a0902011812m775efa4bx279f94d5110d2a3e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090201/a43a2410/attachment.pl>

From mauro.andreolini at unimore.it  Mon Feb  2 12:29:13 2009
From: mauro.andreolini at unimore.it (Mauro Andreolini)
Date: Mon, 02 Feb 2009 12:29:13 +0100
Subject: [Rd] Arima_Like() and NaN - a (possible) problem, a patch, and RFC
Message-ID: <1233574153.7426.67.camel@romanella>

Hi,

recently I have started working with R (v. 2.7.2), and I have been using
R's internal ARIMA_Like() function (from the "stats" package) to
estimate some ARIMA models. In particular, I use ARIMA_Like() in a
function "fn()" that I feed to the optim() method; the main goal is to
find optimal ARIMA prediction models for some time series.
The ARIMA_Like() function returns a three elements vector; under some
conditions (that I could not yet spot), the second element of this
vector is a 'NaN'. Since fn() is using this value to compute its return
value, it suddenly returns 'NaN' and optim() warns me about it:

Error in optim(init[mask], armafn, method = "BFGS", hessian = TRUE,
control = optim.control,  :
  non-finite finite-difference value [2] 

I looked into the code (file src/arima.c of the stats package) and
noticed that this second element is a sum of logarithmic terms, computed
through the following snippet of code:

gain = M[0];
for (j = 0; j < d; j++) gain += delta[j] * M[r + j];
if(gain < 1e4) {
    nu++;
    ssq += resid * resid / gain;
    sumlog += log(gain);
}

Here, sumlog is the second element of the resulting vector. However, the
"if(gain < 1e4) {" check does not explicitly check against negative
values of the gain variable. Indeed, whenever the gain variable assumes
a negative value, the statement "sumlog += log(gain);" evalutes to NaN.
I changed the check as follows:

if (gain > 0 && gain < 1e4) {

This avoids computation of logarithms on negative values. I recompiled
and reinstalled R, and the sumlog value is no more 'NaN'. As a result,
optim() never warns about the non-finite finite-difference value.

Here is my question: does this modification make any sense? Have I
missed something big? To me, it looks reasonable to avoid computing
log(x) when x < 0, but maybe returning 'NaN' may have its purposes.
Could someone please clarify this? I searched the mailing list archives
and I could not spot anything even close to this argument, which may be
an indication that I am doing something really wrong, but I would like
to understand why.

Best regards
Mauro Andreolini


From etiennebr at gmail.com  Mon Feb  2 16:30:25 2009
From: etiennebr at gmail.com (Etienne B. Racine)
Date: Mon, 2 Feb 2009 07:30:25 -0800 (PST)
Subject: [Rd]  Roadmap ?
Message-ID: <21791647.post@talk.nabble.com>


I can't find any R roadmap. Is it available somewhere ?

Etienne
-- 
View this message in context: http://www.nabble.com/Roadmap---tp21791647p21791647.html
Sent from the R devel mailing list archive at Nabble.com.


From ripley at stats.ox.ac.uk  Mon Feb  2 16:51:03 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 2 Feb 2009 15:51:03 +0000 (GMT)
Subject: [Rd] Roadmap ?
In-Reply-To: <21791647.post@talk.nabble.com>
References: <21791647.post@talk.nabble.com>
Message-ID: <alpine.LFD.2.00.0902021548490.31687@gannet.stats.ox.ac.uk>

On Mon, 2 Feb 2009, Etienne B. Racine wrote:

> I can't find any R roadmap. Is it available somewhere ?

What are you expecting to find?

There is a lot of information on the developer site 
(developer.r-rproject.org), and planned changes in the next 2.x.0 
release are in the NEWS file in the SVN archive (and in snapshots).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From etiennebr at gmail.com  Mon Feb  2 17:13:42 2009
From: etiennebr at gmail.com (Etienne Bellemare Racine)
Date: Mon, 02 Feb 2009 11:13:42 -0500
Subject: [Rd] Roadmap ?
Message-ID: <49871BB6.9090900@gmail.com>

I was looking for something like that (as an example)

http://wiki.inkscape.org/wiki/index.php/Roadmap

I wanted to know where R was going in general. Like if there was a 
target for 3.0, etc. Maybe it would better apply to RGui, I admit I have 
some difficulties to distinguish one project from the other.

Prof Brian Ripley a ?crit :
> On Mon, 2 Feb 2009, Etienne B. Racine wrote:
>
>> I can't find any R roadmap. Is it available somewhere ?
>
> What are you expecting to find?
>
> There is a lot of information on the developer site 
> (developer.r-rproject.org), and planned changes in the next 2.x.0 
> release are in the NEWS file in the SVN archive (and in snapshots).
>


From hb at stat.berkeley.edu  Mon Feb  2 20:34:37 2009
From: hb at stat.berkeley.edu (Henrik Bengtsson)
Date: Mon, 2 Feb 2009 11:34:37 -0800
Subject: [Rd] Flag '#' in sprintf() gives an error in R v2.9.0 devel
Message-ID: <59d7961d0902021134s7061d3e7i5ce8b6fea6120518@mail.gmail.com>

Hi,

in R v2.8.1 patched (2008-12-22 r47296) the following works:

> sprintf("%#x", 1)
[1] "0x1"

whereas in R v2.9.0 devel (2009-01-08 r47515) it gives:

> sprintf("%#x", 1);
Error in sprintf("%#x", 1) :
  use format %f, %e, %g or %a for numeric objects

Not sure if this was an intended move or not.

DETAILS:
Typically, the '#' flag modifies the output of (s)printf() as follows:

"#  Used with o, x or X specifiers the value is preceeded with 0, 0x
or 0X respectively for values different than zero.
Used with e, E and f, it forces the written output to contain a
decimal point even if no digits would follow. By default, if no digits
follow, no decimal point is written. Used with g or G the result is
the same as with e or E but trailing zeros are not removed."

Source: http://www.cplusplus.com/reference/clibrary/cstdio/printf.html

I know there are many flavors of what format strings printf() supports
and I don't have the Kernighan & Ritchie book in help(sprintf).

/Henrik


From Setzer.Woodrow at epamail.epa.gov  Mon Feb  2 21:39:21 2009
From: Setzer.Woodrow at epamail.epa.gov (Setzer.Woodrow at epamail.epa.gov)
Date: Mon, 2 Feb 2009 15:39:21 -0500
Subject: [Rd] Getting 'LinkingTo' to find the right library
Message-ID: <OF513E9410.5EB7FB0A-ON85257551.006C7BAD-85257551.00717734@epamail.epa.gov>


I am experimenting with exporting pointers to some of the functions in
deSolve so that other packages may import them, using the
'R_RegisterCCallable' mechanism.  I have added a header file and some
other C code in inst/include of the deSolve source package that need to
be accessible to other packages.  I have a site-library set up in
Rprofile.site where all installed packages go, and as long as my
experimental version of deSolve is installed there,  I'd like to install
my modified copy of deSolve in a test library.  However, when I try to
install my test package (which includes both Depends: deSolve and
LinkingTo: deSolve, in its Description file, as described in 'R
Extensions'), compilation fails, because the appropriate C code cannot
be found (there is also an unrelated problem in deSolve_stubs.c
triggering the "unexpected ')' before '*' token" error).

[test]$ R CMD INSTALL -l C:/home/Rlib-test dma


---------- Making package dma ------------
  adding build stamp to DESCRIPTION
  installing NAMESPACE file and metadata
  making DLL ...
gcc  -std=gnu99  -Ic:/PROGRA~1/R/R-28~1.1PA/include
-I"C:/PROGRA~1/R/site-librar
y/deSolve/include"    -O3 -Wall  -c R_init_dma.c -o R_init_dma.o
R_init_dma.c:1:27: error: deSolve_stubs.c: No such file or directory
R_init_dma.c:3: error: expected ')' before '*' token
make[3]: *** [R_init_dma.o] Error 1
make[2]: *** [srcDynlib] Error 2
make[1]: *** [all] Error 2
make: *** [pkg-dma] Error 2
*** Installation of dma failed ***

Removing 'C:/home/Rlib-test/dma'

It seems that although the 'site-library/deSolve/include' folder is
included in the search list for included files, the
'Rlib-test/deSolve/include' folder is not.  The folder that includes
both the experimental version of deSolve and the test package dma also
contains a .Rprofile file which places 'C:/home/Rlib-test' at the front
of the library search path, and I have confirmed that this is so (in
fact, the above INSTALL command does not need the '-l ' argument; the
default install location is Rlib-test for installs from this folder).
It looks as if the code in INSTALL that sets up the -I arguments to gcc
does not find the library path defined for this folder.  Can someone
point me to the right way to do this?

System information:
Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status = Patched
 major = 2
 minor = 8.1
 year = 2009
 month = 01
 day = 04
 svn rev = 47474
 language = R
 version.string = R version 2.8.1 Patched (2009-01-04 r47474)

Windows XP (build 2600) Service Pack 2

Locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
States.1252;LC_MONETARY=English_United
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

Search Path:
 .GlobalEnv, package:stats, package:graphics, package:grDevices,
package:utils, package:datasets, package:methods, Autoloads,
package:base
R. Woodrow Setzer, Ph. D.
National Center for Computational Toxicology
http://www.epa.gov/comptox
US Environmental Protection Agency
Mail Drop B205-01/US EPA/RTP, NC 27711
Ph: (919) 541-0128    Fax: (919) 541-1194


From spencer.graves at prodsyse.com  Mon Feb  2 21:42:52 2009
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Mon, 02 Feb 2009 12:42:52 -0800
Subject: [Rd] best reference on generics
Message-ID: <49875ACC.1010805@prodsyse.com>

Hello, All:

      What would you say is the best succinct reference to cite on use
of generic functions, especially S3 generics?

      I want to add an appropriate citation on this to a forthcoming
book in the Springer "useR!" series (discussing the use of the 'fda'
package, which uses the S3 standard).

      Thanks,
      Spencer Graves


From ripley at stats.ox.ac.uk  Mon Feb  2 22:22:52 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 2 Feb 2009 21:22:52 +0000 (GMT)
Subject: [Rd] Getting 'LinkingTo' to find the right library
In-Reply-To: <OF513E9410.5EB7FB0A-ON85257551.006C7BAD-85257551.00717734@epamail.epa.gov>
References: <OF513E9410.5EB7FB0A-ON85257551.006C7BAD-85257551.00717734@epamail.epa.gov>
Message-ID: <alpine.LFD.2.00.0902022117590.19068@gannet.stats.ox.ac.uk>

Where did you get the idea that R CMD INSTALL is reading .Rprofile?
(AFAIR it does so only to find the installation library, as R CMD 
INSTALL --help says it will.)

You need to set R_LIBS in the environment to get the library path you 
want.  This is not specific to 'LinkingTo'.

On Mon, 2 Feb 2009, Setzer.Woodrow at epamail.epa.gov wrote:

>
> I am experimenting with exporting pointers to some of the functions in
> deSolve so that other packages may import them, using the
> 'R_RegisterCCallable' mechanism.  I have added a header file and some
> other C code in inst/include of the deSolve source package that need to
> be accessible to other packages.  I have a site-library set up in
> Rprofile.site where all installed packages go, and as long as my
> experimental version of deSolve is installed there,  I'd like to install
> my modified copy of deSolve in a test library.  However, when I try to
> install my test package (which includes both Depends: deSolve and
> LinkingTo: deSolve, in its Description file, as described in 'R
> Extensions'), compilation fails, because the appropriate C code cannot
> be found (there is also an unrelated problem in deSolve_stubs.c
> triggering the "unexpected ')' before '*' token" error).
>
> [test]$ R CMD INSTALL -l C:/home/Rlib-test dma
>
>
> ---------- Making package dma ------------
>  adding build stamp to DESCRIPTION
>  installing NAMESPACE file and metadata
>  making DLL ...
> gcc  -std=gnu99  -Ic:/PROGRA~1/R/R-28~1.1PA/include
> -I"C:/PROGRA~1/R/site-librar
> y/deSolve/include"    -O3 -Wall  -c R_init_dma.c -o R_init_dma.o
> R_init_dma.c:1:27: error: deSolve_stubs.c: No such file or directory
> R_init_dma.c:3: error: expected ')' before '*' token
> make[3]: *** [R_init_dma.o] Error 1
> make[2]: *** [srcDynlib] Error 2
> make[1]: *** [all] Error 2
> make: *** [pkg-dma] Error 2
> *** Installation of dma failed ***
>
> Removing 'C:/home/Rlib-test/dma'
>
> It seems that although the 'site-library/deSolve/include' folder is
> included in the search list for included files, the
> 'Rlib-test/deSolve/include' folder is not.  The folder that includes
> both the experimental version of deSolve and the test package dma also
> contains a .Rprofile file which places 'C:/home/Rlib-test' at the front
> of the library search path, and I have confirmed that this is so (in
> fact, the above INSTALL command does not need the '-l ' argument; the
> default install location is Rlib-test for installs from this folder).
> It looks as if the code in INSTALL that sets up the -I arguments to gcc
> does not find the library path defined for this folder.  Can someone
> point me to the right way to do this?
>
> System information:
> Version:
> platform = i386-pc-mingw32
> arch = i386
> os = mingw32
> system = i386, mingw32
> status = Patched
> major = 2
> minor = 8.1
> year = 2009
> month = 01
> day = 04
> svn rev = 47474
> language = R
> version.string = R version 2.8.1 Patched (2009-01-04 r47474)
>
> Windows XP (build 2600) Service Pack 2
>
> Locale:
> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
> States.1252;LC_MONETARY=English_United
> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>
> Search Path:
> .GlobalEnv, package:stats, package:graphics, package:grDevices,
> package:utils, package:datasets, package:methods, Autoloads,
> package:base
> R. Woodrow Setzer, Ph. D.
> National Center for Computational Toxicology
> http://www.epa.gov/comptox
> US Environmental Protection Agency
> Mail Drop B205-01/US EPA/RTP, NC 27711
> Ph: (919) 541-0128    Fax: (919) 541-1194
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Setzer.Woodrow at epamail.epa.gov  Mon Feb  2 22:56:57 2009
From: Setzer.Woodrow at epamail.epa.gov (Setzer.Woodrow at epamail.epa.gov)
Date: Mon, 2 Feb 2009 16:56:57 -0500
Subject: [Rd] Getting 'LinkingTo' to find the right library
In-Reply-To: <alpine.LFD.2.00.0902022117590.19068@gannet.stats.ox.ac.uk>
References: <OF513E9410.5EB7FB0A-ON85257551.006C7BAD-85257551.00717734@epamail.epa.gov>
	<alpine.LFD.2.00.0902022117590.19068@gannet.stats.ox.ac.uk>
Message-ID: <OF9980EE67.A5FB411A-ON85257551.0076417C-85257551.007891D3@epamail.epa.gov>

(I just realized that when "they" upgraded my mail program, "they" reset
my preferences to send html and text for internet mail.  I have fixed
the preferences to text only, and apologize).
Well, where would I get the idea it was NOT reading .Rprofile, since it
clearly IS reading Rprofile.site?  However, I mainly thought that the
library being installed to would be used to find the dependent package,
because of this bug fix entry for version 2.7.2:
o The use of multiple packages in 'LinkingTo' works again, and
????????????now works when the dependent packages are in the library to
be
????????????installed to (but not in the library path seen by R
--vanilla).

Also, in this paragraph from the INSTALL help item:

     To install into the library tree 'lib', use 'R CMD INSTALL -l lib
     pkgs'.  This prepends 'lib' to 'R_LIBS' for duration of the
     install, so required packages in the installation directory will
     be found (and used in preference to those in other libraries).

Setting R_LIBS works (I DID try this before, but must have fumbled
something).

R. Woodrow Setzer, Ph. D.
National Center for Computational Toxicology
http://www.epa.gov/comptox
US Environmental Protection Agency
Mail Drop B205-01/US EPA/RTP, NC 27711
Ph: (919) 541-0128    Fax: (919) 541-1194).

Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote on 02/02/2009 04:22:52
PM:

> [image removed]
>
> Re: [Rd] Getting 'LinkingTo' to find the right library
>
> Prof Brian Ripley
>
> to:
>
> Woodrow Setzer
>
> 02/02/2009 04:22 PM
>
> Cc:
>
> r-devel
>
> Where did you get the idea that R CMD INSTALL is reading .Rprofile?
> (AFAIR it does so only to find the installation library, as R CMD
> INSTALL --help says it will.)
>
> You need to set R_LIBS in the environment to get the library path you
> want.  This is not specific to 'LinkingTo'.
>
> On Mon, 2 Feb 2009, Setzer.Woodrow at epamail.epa.gov wrote:
>
> >
> > I am experimenting with exporting pointers to some of the functions
in
> > deSolve so that other packages may import them, using the
> > 'R_RegisterCCallable' mechanism.  I have added a header file and
some
> > other C code in inst/include of the deSolve source package that need
to
> > be accessible to other packages.  I have a site-library set up in
> > Rprofile.site where all installed packages go, and as long as my
> > experimental version of deSolve is installed there,  I'd like to
install
> > my modified copy of deSolve in a test library.  However, when I try
to
> > install my test package (which includes both Depends: deSolve and
> > LinkingTo: deSolve, in its Description file, as described in 'R
> > Extensions'), compilation fails, because the appropriate C code
cannot
> > be found (there is also an unrelated problem in deSolve_stubs.c
> > triggering the "unexpected ')' before '*' token" error).
> >
> > [test]$ R CMD INSTALL -l C:/home/Rlib-test dma
> >
> >
> > ---------- Making package dma ------------
> >  adding build stamp to DESCRIPTION
> >  installing NAMESPACE file and metadata
> >  making DLL ...
> > gcc  -std=gnu99  -Ic:/PROGRA~1/R/R-28~1.1PA/include
> > -I"C:/PROGRA~1/R/site-librar
> > y/deSolve/include"    -O3 -Wall  -c R_init_dma.c -o R_init_dma.o
> > R_init_dma.c:1:27: error: deSolve_stubs.c: No such file or directory
> > R_init_dma.c:3: error: expected ')' before '*' token
> > make[3]: *** [R_init_dma.o] Error 1
> > make[2]: *** [srcDynlib] Error 2
> > make[1]: *** [all] Error 2
> > make: *** [pkg-dma] Error 2
> > *** Installation of dma failed ***
> >
> > Removing 'C:/home/Rlib-test/dma'
> >
> > It seems that although the 'site-library/deSolve/include' folder is
> > included in the search list for included files, the
> > 'Rlib-test/deSolve/include' folder is not.  The folder that includes
> > both the experimental version of deSolve and the test package dma
also
> > contains a .Rprofile file which places 'C:/home/Rlib-test' at the
front
> > of the library search path, and I have confirmed that this is so (in
> > fact, the above INSTALL command does not need the '-l ' argument;
the
> > default install location is Rlib-test for installs from this
folder).
> > It looks as if the code in INSTALL that sets up the -I arguments to
gcc
> > does not find the library path defined for this folder.  Can someone
> > point me to the right way to do this?
> >
> > System information:
> > Version:
> > platform = i386-pc-mingw32
> > arch = i386
> > os = mingw32
> > system = i386, mingw32
> > status = Patched
> > major = 2
> > minor = 8.1
> > year = 2009
> > month = 01
> > day = 04
> > svn rev = 47474
> > language = R
> > version.string = R version 2.8.1 Patched (2009-01-04 r47474)
> >
> > Windows XP (build 2600) Service Pack 2
> >
> > Locale:
> > LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
> > States.1252;LC_MONETARY=English_United
> > States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
> >
> > Search Path:
> > .GlobalEnv, package:stats, package:graphics, package:grDevices,
> > package:utils, package:datasets, package:methods, Autoloads,
> > package:base
> > R. Woodrow Setzer, Ph. D.
> > National Center for Computational Toxicology
> > http://www.epa.gov/comptox
> > US Environmental Protection Agency
> > Mail Drop B205-01/US EPA/RTP, NC 27711
> > Ph: (919) 541-0128    Fax: (919) 541-1194
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Tue Feb  3 09:05:55 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 3 Feb 2009 08:05:55 +0000 (GMT)
Subject: [Rd] Packages should not only search for libraries with particular
 extensions and paths
Message-ID: <alpine.LFD.2.00.0901300941200.8685@gannet.stats.ox.ac.uk>

Every time I set up a new machine I find myself needing to circumvent 
the obstructions placed by a few package writers who don't understand 
enough about (compiled code) libraries.

Their mistakes include hardcoding a library extension (.so or .a) 
and/or a set of paths such as

         /usr/lib /usr/local/lib /opt/lib ...

Different OSes do have different conventions, especially where 
multiple architectures co-exist.  (E.g. most but not all x86_64 Linux 
use lib64, and Solaris uses lib/amd64 etc.)  This means that a library 
of the right name but the wrong architecture may be found in, say,
/usr/local/lib.

The correct dynamic library extension can be (at least) .so, .sl, 
.dylib or .dll.  (On Darwin aka Mac OS X dynamic libraries and shared 
objects are not the same thing, and can contain one or more 
architectures.)  But really only the linker needs to know that, and 
autoconf's AC_SEARCH_LIBS and similar are a much more reliable test. 
Even if your script finds what looks like a library in a non-standard 
place, it does not mean that either or both of the linker or the 
run-time loader ('ld.so') can find or use it.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From j.clayden at ucl.ac.uk  Wed Feb  4 13:59:59 2009
From: j.clayden at ucl.ac.uk (Jon Clayden)
Date: Wed, 4 Feb 2009 12:59:59 +0000
Subject: [Rd] Capturing all warnings (with messages)
Message-ID: <1F999E4C-B39B-46B4-92BC-074EFEE4B1E8@ucl.ac.uk>

Dear all,

For an open-source project that I'm working on (1), which uses R for  
all its heavy lifting but includes a wrapper shell script, I was  
hoping to find a way to capture all warnings (and, in fact, errors  
too), and handle them in my own way. I realise I can do this for a  
single expression using something like:

 > f <- function(w) print(w$message)
 > withCallingHandlers(warning("Test"),warning=f)
[1] "Test"
Warning message:
In withCallingHandlers(warning("Test"), warning = f) : Test

But I would like to capture all warnings, globally. The  
"warning.expression" option doesn't seem to allow an argument, and I  
can't seem to use "last.warning" to get at the message either:

 > g <- function() print(last.warning$message)
 > options(warning.expression=quote(g()))
 > warning("Test2")
NULL

Could anyone tell me whether there's a way to do this, please? An old  
thread on this topic seemed to go unresolved (2), and I've skimmed  
RNEWS and I don't see anything about this since then.

 > sessionInfo()
R version 2.8.1 (2008-12-22)
i386-apple-darwin8.11.1

locale:
en_GB.UTF-8/en_US.UTF-8/C/C/en_GB.UTF-8/en_GB.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  splines   methods
[8] base

other attached packages:
[1] tractor.session_1.0.0   tractor.base_1.0.3      tractor.nt_1.0.2

loaded via a namespace (and not attached):
[1] tools_2.8.1

Regards,
Jon


(1) http://code.google.com/p/tractor/
(2) http://finzi.psych.upenn.edu/R/Rhelp02/archive/61872.html


--
Jonathan D. Clayden, Ph.D.
Research Fellow
Radiology and Physics Unit
UCL Institute of Child Health
30 Guilford Street
LONDON  WC1N 1EH
United Kingdom

t | +44 (0)20 7905 2708
f | +44 (0)20 7905 2358
w | www.homepages.ucl.ac.uk/~sejjjd2/


From a.ghisla at gmail.com  Wed Feb  4 16:47:40 2009
From: a.ghisla at gmail.com (Anne Ghisla)
Date: Wed, 4 Feb 2009 16:47:40 +0100
Subject: [Rd] [SoC 2009] will R Foundation participate? project proposal:
	fractal analysis
Message-ID: <200902041647.47170.a.ghisla@gmail.com>

Hello R developers,

I know it is still a bit early to talk about Summer of Code, but I wish to 
know what are, approximately, plans for this year.
Last year I applied as a student under OSGeo with a QGIS-R project and had a 
very positive experience [0], therefore I plan to participate again.
I found an interesting hint [1], about implementing fractal analysis in R, and 
a would-be mentor has already given his availability.
But I don't know how does mentor-student binding work. In this case, how 
probable is that my project will be assigned to this particular mentor, if it 
is accepted?

Best regards,

Anne Ghisla

[0] http://wiki.qgis.org/qgiswiki/GSoC2008Rbinding
[1] http://www.faunalia.com/pipermail/animov/2009-February/000361.html
-- 
Please consider the environment before printing this email
Please do not send attachments in proprietary formats
http://www.gnu.org/philosophy/no-word-attachments.html
Use the UNI CEI Standard ISO/IEC 26300:2006
-----------------------------------------------------------
O< stop html mail - http://www.asciiribbon.org
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 197 bytes
Desc: This is a digitally signed message part.
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090204/de3f0f92/attachment.bin>

From =?windows-1256?B?38jR7dzcx8Eg3crc3Nzcx8n=?= at pubhealth.ku.dk  Wed Feb  4 17:45:05 2009
From: =?windows-1256?B?38jR7dzcx8Eg3crc3Nzcx8n=?= at pubhealth.ku.dk (=?windows-1256?B?38jR7dzcx8Eg3crc3Nzcx8n=?= at pubhealth.ku.dk)
Date: Wed,  4 Feb 2009 17:45:05 +0100 (CET)
Subject: [Rd] Problem using option packeg with new R version (PR#13498)
Message-ID: <20090204164505.8EF9A282C769@mail.pubhealth.ku.dk>



Hello, I'm facing a problem, using "optim" packeg. I've written a program and run it using the latest R version 2.8.1,but there was an error message as following: 



R version 2.7.2 (2008-08-25) # same result when I use R version 2.8.1,Copyright (C) 2008 The R Foundation for Statistical ComputingISBN 3-900051-07-0R is free software and comes with ABSOLUTELY NO WARRANTY.You are welcome to redistribute it under certain conditions.Type 'license()' or 'licence()' for distribution details.  Natural language support but running in an English localeR is a collaborative project with many contributors.Type 'contributors()' for more information and'citation()' on how to cite R or R packages in publications.Type 'demo()' for some demos, 'help()' for on-line help, or'help.start()' for an HTML browser interface to help.Type 'q()' to quit R.> #=========================================================> #3rd trial> #=========================================================> > X<-matrix(rnorm(30),5,6)> X            [,1]        [,2]        [,3]       [,4]       [,5]       [,6][1,] -0.27769355  0.54293814 -1.93856940 -1.8097458 -0.9172400 -0.5542488[2,] -0!
 .09146831  0.26066833  0.91905734  0.2981062  0.4640875 -0.1789108[3,] -0.99167996 -0.64401482 -0.08517589 -0.4101295  1.5204661  1.3439740[4,] -1.54003312 -0.03145120  0.17489151  1.1248919  0.6047474  1.1909949[5,] -0.94150604  0.19836236 -0.63982776  0.5272774 -0.4088086 -0.2593536> > n<-nrow(X)> p<-ncol(X)> n[1] 5> p[1] 6> > v<-rep(0,p-1)> v[1] 0 0 0 0 0> > fn1<-function(v) {+ a<-sum(v*v)+ u<-v/sqrt(1+a)+ b<-sum(u*u)+ u[length(v)+1]<-sqrt(1+b)+ c<<- X %*% u # also I try c<- X %*% u+ fn1<- - optim(c(0,1),fn2,NULL,method="BFGS",c)$value+ }>  > > fn2<-function(par){+ fn2<- -length(c)*log(par[2])+sum(log(par[2]*par[2]+(c-par[1])*(c-par[1])))+ }> optim(v,fn1,NULL,method="BFGS",X)Error in fn(par, ...) :   unused argument(s) (c(-0.277693546148993, -0.091468312551809, -0.99167995523182, -1.5400331178273, -0.941506038285282, 0.542938135331624, 0.260668332757676, -0.64401482390065, -0.0314512041135196, 0.198362357527128, -1.93856939573315, 0.919057338245786, -0.085175885159938, 0!
 .174891510504697, -0.639827759135, -1.80974578397221, 0.298106!
 24003356

9, -0.410129481117372, 1.12489185606582, 0.527277375478827, -0.917240000748393, 0.464087477214494, 1.52046606812109, 0.60474736264106, -0.408808568730677, -0.554248793092077, > > > c<-rnorm(10)> v<-rnorm(10)> w<-rexp(10)> fn1<-function(v) {+ for(i in 1:10){+ par[1]<-v[i]+ par[2]<-w[i]+ a[i]<-optim(par,fn2, NULL,method="BFGS",c)$value+ }+ }> fn2<-function(par){+ fn2<- -length(c)*log(par[2])+sum(log(par[2]*par[2]+(c-par[1])*(c-par[1])))+ }> > optim(v,fn1,NULL,method="BFGS",X)Error in fn(par, ...) :   unused argument(s) (c(-0.277693546148993, -0.091468312551809, -0.99167995523182, -1.5400331178273, -0.941506038285282, 0.542938135331624, 0.260668332757676, -0.64401482390065, -0.0314512041135196, 0.198362357527128, -1.93856939573315, 0.919057338245786, -0.085175885159938, 0.174891510504697, -0.639827759135, -1.80974578397221, 0.298106240033569, -0.410129481117372, 1.12489185606582, 0.527277375478827, -0.917240000748393, 0.464087477214494, 1.52046606812109, 0.60474736264106, -0.40!
 8808568730677, -0.554248793092077, > 



Wihle, when I run the same program on the old Version 1.7.1,  I've got different result as follows:R : Copyright 2003, The R Development Core TeamVersion 1.7.1  (2003-06-16)R is free software and comes with ABSOLUTELY NO WARRANTY.You are welcome to redistribute it under certain conditions.Type `license()' or `licence()' for distribution details.R is a collaborative project with many contributors.Type `contributors()' for more information.Type `demo()' for some demos, `help()' for on-line help, or`help.start()' for a HTML browser interface to help.Type `q()' to quit R.[Previously saved workspace restored]> #=========================================================> #3rd trial> #=========================================================> > X<-matrix(rnorm(30),5,6)> X           [,1]         [,2]        [,3]       [,4]        [,5]       [,6][1,]  0.3857697 -0.676798170 -1.39627127 -0.5585526  0.49491835 -1.5055718[2,] -1.3984869  0.036486347 -0.27965160  0.4181540  0.28574020 -0.!
 1874612[3,]  0.4118289  0.062688233  1.67673064  0.3231048 -0.58132802 -1.5297349[4,] -0.8236798 -2.142110808  0.07844006  2.4561737 -0.08797541  0.1006625[5,] -1.6269258  0.004665647  1.21449692 -0.5522195 -1.57935227  0.7255697> > n<-nrow(X)> p<-ncol(X)> n[1] 5> p[1] 6> > v<-rep(0,p-1)> v[1] 0 0 0 0 0> > > fn1<-function(v) {+ a<-sum(v*v)+ u<-v/sqrt(1+a)+ b<-sum(u*u)+ u[length(v)+1]<-sqrt(1+b)+ c<<- X %*% u+ #c<- X %*% u+ fn1<- - optim(c(0,1),fn2,NULL,method="BFGS",c)$value+ }>  > > fn2<-function(par){+ fn2<- -length(c)*log(par[2])+sum(log(par[2]*par[2]+(c-par[1])*(c-par[1])))+ }> optim(v,fn1,NULL,method="BFGS",X)$par[1]  0.3857697 -1.3984869  2.0925084  3.2370430 -1.6269258$value[1] -6.132011$countsfunction gradient       15       15 $convergence[1] 0$message[1] "CONVERGENCE: REL_REDUCTION_OF_F <= FACTR*EPSMCH"There were 50 or more warnings (use warnings() to see the first 50)> #=====================================================================================> > c<-rn!
 orm(10)> v<-rnorm(10)> w<-rexp(10)> fn1<-function(v) {+ for(i !
 in 1:10)

{+ par[1]<-v[i]+ par[2]<-w[i]+ a[i]<-optim(par,fn2, NULL,method="BFGS",c)$value+ }+ }> fn2<-function(par){+ fn2<- -length(c)*log(par[2])+sum(log(par[2]*par[2]+(c-par[1])*(c-par[1])))+ }> > optim(v,fn1,NULL,method="BFGS",X)Error in optim(par, fn2, NULL, method = "BFGS", c) :         L-BFGS-B needs finite values of fnIn addition: Warning messages: 1: bounds can only be used with method L-BFGS-B in: optim(v, fn1, NULL, method = "BFGS", X) 2: bounds can only be used with method L-BFGS-B in: optim(par, fn2, NULL, method = "BFGS", c) 3: bounds can only be used with method L-BFGS-B in: optim(par, fn2, NULL, method = "BFGS", c) 4: bounds can only be used with method L-BFGS-B in: optim(par, fn2, NULL, method = "BFGS", c) 5: bounds can only be used with method L-BFGS-B in: optim(par, fn2, NULL, method = "BFGS", c) 6: NaNs produced in: log(x) #======================================================================================== So, I'd be thankful  if you could help me solving this !
 problem and inform me weather there is bug in the newest version or the code is changed. Best RegardsAishaPh.D studentStatistics DeparmentUniversity of NottinghamUK
_________________________________________________________________
Windows Live Messenger just got better .Video display pics, contact updates & more.
http://www.download.live.com/messenger
	[[alternative HTML version deleted]]


From jeff.horner at vanderbilt.edu  Wed Feb  4 17:52:58 2009
From: jeff.horner at vanderbilt.edu (Jeffrey Horner)
Date: Wed, 04 Feb 2009 10:52:58 -0600
Subject: [Rd] Capturing all warnings (with messages)
In-Reply-To: <1F999E4C-B39B-46B4-92BC-074EFEE4B1E8@ucl.ac.uk>
References: <1F999E4C-B39B-46B4-92BC-074EFEE4B1E8@ucl.ac.uk>
Message-ID: <4989C7EA.1090700@vanderbilt.edu>

Jon Clayden wrote on 02/04/2009 06:59 AM:
> Dear all,
> 
> For an open-source project that I'm working on (1), which uses R for all 
> its heavy lifting but includes a wrapper shell script, I was hoping to 
> find a way to capture all warnings (and, in fact, errors too), and 
> handle them in my own way. I realise I can do this for a single 
> expression using something like:
> 
>  > f <- function(w) print(w$message)
>  > withCallingHandlers(warning("Test"),warning=f)
> [1] "Test"
> Warning message:
> In withCallingHandlers(warning("Test"), warning = f) : Test
> 
> But I would like to capture all warnings, globally. The 
> "warning.expression" option doesn't seem to allow an argument, and I 
> can't seem to use "last.warning" to get at the message either:
> 
>  > g <- function() print(last.warning$message)
>  > options(warning.expression=quote(g()))
>  > warning("Test2")
> NULL
> 
> Could anyone tell me whether there's a way to do this, please? An old 
> thread on this topic seemed to go unresolved (2), and I've skimmed RNEWS 
> and I don't see anything about this since then.

In fact, the thread did have the answer: tryCatch(). The help page is a 
bear to read and comprehend, but if you do invest the time it should 
convince you that you will want to use it. I find that I have to read 
and reread many sections of R documentation before I can reconcile what 
I want to know with what the authors are trying to tell me.

I don't comprehend everything about R's condition system, but let me see 
if I can convince you that you need tryCatch() to do what you want.

Consider:

x <- function() warning("warning message")
y <- function() call_unknown_fun()
z <- function() message('message message')

Each of these functions signal conditions of a particular condition 
class: simpleWarning, simpleError, and simpleMessage, respectively.

w <- function(e) str(e)

I'm going to use w  to trap the simpleWarning condition:

 > tryCatch(x(),simpleWarning=w)
List of 2
  $ message: chr "warning message"
  $ call   : language x()
  - attr(*, "class")= chr [1:3] "simpleWarning" "warning" "condition"

So tryCatch returned a list with two elements, the message and the call 
that signaled the condition. In fact the list is actually an S3 object 
of class simpleWarning, which inherits from warning and condition. 
Reading the help page for tryCatch(), I can actually do this:

 > tryCatch(x(),condition=w)
List of 2
  $ message: chr "warning message"
  $ call   : language x()
  - attr(*, "class")= chr [1:3] "simpleWarning" "warning" "condition"

since simpleWarning inherits from condition. And in fact I can use the 
condition class to trap everything I want.

 > tryCatch(y(),condition=w)
List of 2
  $ message: chr "could not find function \"call_unknown_fun\""
  $ call   : language y()
  - attr(*, "class")= chr [1:3] "simpleError" "error" "condition"

 > tryCatch(z(),condition=w)
List of 2
  $ message: chr "message message\n"
  $ call   : language message("message message")
  - attr(*, "class")= chr [1:3] "condition" "message" "simpleMessage"

(Side note: is the class hierarchy actually correct for this 
simpleMessage object?)

So in summary, wrap every R expression you want to run within a single 
tryCatch() call and trap all conditions with one handler for the 
abstract class named 'condition'. I think that's what you want...

Jeff


> 
>  > sessionInfo()
> R version 2.8.1 (2008-12-22)
> i386-apple-darwin8.11.1
> 
> locale:
> en_GB.UTF-8/en_US.UTF-8/C/C/en_GB.UTF-8/en_GB.UTF-8
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  splines   methods
> [8] base
> 
> other attached packages:
> [1] tractor.session_1.0.0   tractor.base_1.0.3      tractor.nt_1.0.2
> 
> loaded via a namespace (and not attached):
> [1] tools_2.8.1
> 
> Regards,
> Jon
> 
> 
> (1) http://code.google.com/p/tractor/
> (2) http://finzi.psych.upenn.edu/R/Rhelp02/archive/61872.html
> 
> 
> -- 
> Jonathan D. Clayden, Ph.D.
> Research Fellow
> Radiology and Physics Unit
> UCL Institute of Child Health
> 30 Guilford Street
> LONDON  WC1N 1EH
> United Kingdom
> 
> t | +44 (0)20 7905 2708
> f | +44 (0)20 7905 2358
> w | www.homepages.ucl.ac.uk/~sejjjd2/
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
http://biostat.mc.vanderbilt.edu/JeffreyHorner


From j.clayden at ucl.ac.uk  Wed Feb  4 19:11:56 2009
From: j.clayden at ucl.ac.uk (Jon Clayden)
Date: Wed, 4 Feb 2009 18:11:56 +0000
Subject: [Rd] Capturing all warnings (with messages)
In-Reply-To: <4989C7EA.1090700@vanderbilt.edu>
References: <1F999E4C-B39B-46B4-92BC-074EFEE4B1E8@ucl.ac.uk>
	<4989C7EA.1090700@vanderbilt.edu>
Message-ID: <68e086180902041011x53329634wf1b003c187090d3e@mail.gmail.com>

Dear Jeff,

Many thanks for the suggestion, but I don't think tryCatch() is the
answer, mainly because it causes code to stop executing when a warning
is signalled:

> f <- function(w) print(w$message)
> tryCatch({warning("Test"); print(3)},warning=f)
[1] "Test"

(The "print(3)" call is not run.) In this regard,
withCallingHandlers() is preferable. But either way it is untidy, at
best, to routinely put code inside one of these functions when I know
I always want to handle warnings my way. If I could set an appropriate
option when a package is loaded, or in an .Rprofile, then I should
never need to worry about whether a bit of code might generate
warnings and so should be wrapped.

Regards,
Jon

2009/2/4 Jeffrey Horner <jeff.horner at vanderbilt.edu>:
> Jon Clayden wrote on 02/04/2009 06:59 AM:
>>
>> Dear all,
>>
>> For an open-source project that I'm working on (1), which uses R for all
>> its heavy lifting but includes a wrapper shell script, I was hoping to find
>> a way to capture all warnings (and, in fact, errors too), and handle them in
>> my own way. I realise I can do this for a single expression using something
>> like:
>>
>>  > f <- function(w) print(w$message)
>>  > withCallingHandlers(warning("Test"),warning=f)
>> [1] "Test"
>> Warning message:
>> In withCallingHandlers(warning("Test"), warning = f) : Test
>>
>> But I would like to capture all warnings, globally. The
>> "warning.expression" option doesn't seem to allow an argument, and I can't
>> seem to use "last.warning" to get at the message either:
>>
>>  > g <- function() print(last.warning$message)
>>  > options(warning.expression=quote(g()))
>>  > warning("Test2")
>> NULL
>>
>> Could anyone tell me whether there's a way to do this, please? An old
>> thread on this topic seemed to go unresolved (2), and I've skimmed RNEWS and
>> I don't see anything about this since then.
>
> In fact, the thread did have the answer: tryCatch(). The help page is a bear
> to read and comprehend, but if you do invest the time it should convince you
> that you will want to use it. I find that I have to read and reread many
> sections of R documentation before I can reconcile what I want to know with
> what the authors are trying to tell me.
>
> I don't comprehend everything about R's condition system, but let me see if
> I can convince you that you need tryCatch() to do what you want.
>
> Consider:
>
> x <- function() warning("warning message")
> y <- function() call_unknown_fun()
> z <- function() message('message message')
>
> Each of these functions signal conditions of a particular condition class:
> simpleWarning, simpleError, and simpleMessage, respectively.
>
> w <- function(e) str(e)
>
> I'm going to use w  to trap the simpleWarning condition:
>
>> tryCatch(x(),simpleWarning=w)
> List of 2
>  $ message: chr "warning message"
>  $ call   : language x()
>  - attr(*, "class")= chr [1:3] "simpleWarning" "warning" "condition"
>
> So tryCatch returned a list with two elements, the message and the call that
> signaled the condition. In fact the list is actually an S3 object of class
> simpleWarning, which inherits from warning and condition. Reading the help
> page for tryCatch(), I can actually do this:
>
>> tryCatch(x(),condition=w)
> List of 2
>  $ message: chr "warning message"
>  $ call   : language x()
>  - attr(*, "class")= chr [1:3] "simpleWarning" "warning" "condition"
>
> since simpleWarning inherits from condition. And in fact I can use the
> condition class to trap everything I want.
>
>> tryCatch(y(),condition=w)
> List of 2
>  $ message: chr "could not find function \"call_unknown_fun\""
>  $ call   : language y()
>  - attr(*, "class")= chr [1:3] "simpleError" "error" "condition"
>
>> tryCatch(z(),condition=w)
> List of 2
>  $ message: chr "message message\n"
>  $ call   : language message("message message")
>  - attr(*, "class")= chr [1:3] "condition" "message" "simpleMessage"
>
> (Side note: is the class hierarchy actually correct for this simpleMessage
> object?)
>
> So in summary, wrap every R expression you want to run within a single
> tryCatch() call and trap all conditions with one handler for the abstract
> class named 'condition'. I think that's what you want...
>
> Jeff
>
>
>>
>>  > sessionInfo()
>> R version 2.8.1 (2008-12-22)
>> i386-apple-darwin8.11.1
>>
>> locale:
>> en_GB.UTF-8/en_US.UTF-8/C/C/en_GB.UTF-8/en_GB.UTF-8
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  splines   methods
>> [8] base
>>
>> other attached packages:
>> [1] tractor.session_1.0.0   tractor.base_1.0.3      tractor.nt_1.0.2
>>
>> loaded via a namespace (and not attached):
>> [1] tools_2.8.1
>>
>> Regards,
>> Jon
>>
>>
>> (1) http://code.google.com/p/tractor/
>> (2) http://finzi.psych.upenn.edu/R/Rhelp02/archive/61872.html
>>
>>
>> --
>> Jonathan D. Clayden, Ph.D.
>> Research Fellow
>> Radiology and Physics Unit
>> UCL Institute of Child Health
>> 30 Guilford Street
>> LONDON  WC1N 1EH
>> United Kingdom
>>
>> t | +44 (0)20 7905 2708
>> f | +44 (0)20 7905 2358
>> w | www.homepages.ucl.ac.uk/~sejjjd2/
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
> --
> http://biostat.mc.vanderbilt.edu/JeffreyHorner
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From jeff.horner at vanderbilt.edu  Wed Feb  4 20:19:01 2009
From: jeff.horner at vanderbilt.edu (Jeffrey Horner)
Date: Wed, 04 Feb 2009 13:19:01 -0600
Subject: [Rd] Capturing all warnings (with messages)
In-Reply-To: <68e086180902041011x53329634wf1b003c187090d3e@mail.gmail.com>
References: <1F999E4C-B39B-46B4-92BC-074EFEE4B1E8@ucl.ac.uk>	
	<4989C7EA.1090700@vanderbilt.edu>
	<68e086180902041011x53329634wf1b003c187090d3e@mail.gmail.com>
Message-ID: <4989EA25.8050905@vanderbilt.edu>

Jon Clayden wrote on 02/04/2009 12:11 PM:
> Dear Jeff,
> 
> Many thanks for the suggestion, but I don't think tryCatch() is the
> answer, mainly because it causes code to stop executing when a warning
> is signalled:
> 
>> f <- function(w) print(w$message)
>> tryCatch({warning("Test"); print(3)},warning=f)
> [1] "Test"
> 
> (The "print(3)" call is not run.) In this regard,
> withCallingHandlers() is preferable. But either way it is untidy, at
> best, to routinely put code inside one of these functions when I know
> I always want to handle warnings my way. If I could set an appropriate
> option when a package is loaded, or in an .Rprofile, then I should
> never need to worry about whether a bit of code might generate
> warnings and so should be wrapped.

So you want your program to handle all warnings your way, but you want 
to continue execution after you have trapped the warnings. What 
specifically do you want your program to do with a warning once you know 
what it is?

(I'd like to help you work through your problem to a solution because I 
selfishly want to learn more about R's condition and restart system for 
rapache's sake, my personal project. Right now, the way rapache notifies 
users of R warnings and errors is crude but works.)

Jeff


> 
> Regards,
> Jon
> 
> 2009/2/4 Jeffrey Horner <jeff.horner at vanderbilt.edu>:
>> Jon Clayden wrote on 02/04/2009 06:59 AM:
>>> Dear all,
>>>
>>> For an open-source project that I'm working on (1), which uses R for all
>>> its heavy lifting but includes a wrapper shell script, I was hoping to find
>>> a way to capture all warnings (and, in fact, errors too), and handle them in
>>> my own way. I realise I can do this for a single expression using something
>>> like:
>>>
>>>  > f <- function(w) print(w$message)
>>>  > withCallingHandlers(warning("Test"),warning=f)
>>> [1] "Test"
>>> Warning message:
>>> In withCallingHandlers(warning("Test"), warning = f) : Test
>>>
>>> But I would like to capture all warnings, globally. The
>>> "warning.expression" option doesn't seem to allow an argument, and I can't
>>> seem to use "last.warning" to get at the message either:
>>>
>>>  > g <- function() print(last.warning$message)
>>>  > options(warning.expression=quote(g()))
>>>  > warning("Test2")
>>> NULL
>>>
>>> Could anyone tell me whether there's a way to do this, please? An old
>>> thread on this topic seemed to go unresolved (2), and I've skimmed RNEWS and
>>> I don't see anything about this since then.
>> In fact, the thread did have the answer: tryCatch(). The help page is a bear
>> to read and comprehend, but if you do invest the time it should convince you
>> that you will want to use it. I find that I have to read and reread many
>> sections of R documentation before I can reconcile what I want to know with
>> what the authors are trying to tell me.
>>
>> I don't comprehend everything about R's condition system, but let me see if
>> I can convince you that you need tryCatch() to do what you want.
>>
>> Consider:
>>
>> x <- function() warning("warning message")
>> y <- function() call_unknown_fun()
>> z <- function() message('message message')
>>
>> Each of these functions signal conditions of a particular condition class:
>> simpleWarning, simpleError, and simpleMessage, respectively.
>>
>> w <- function(e) str(e)
>>
>> I'm going to use w  to trap the simpleWarning condition:
>>
>>> tryCatch(x(),simpleWarning=w)
>> List of 2
>>  $ message: chr "warning message"
>>  $ call   : language x()
>>  - attr(*, "class")= chr [1:3] "simpleWarning" "warning" "condition"
>>
>> So tryCatch returned a list with two elements, the message and the call that
>> signaled the condition. In fact the list is actually an S3 object of class
>> simpleWarning, which inherits from warning and condition. Reading the help
>> page for tryCatch(), I can actually do this:
>>
>>> tryCatch(x(),condition=w)
>> List of 2
>>  $ message: chr "warning message"
>>  $ call   : language x()
>>  - attr(*, "class")= chr [1:3] "simpleWarning" "warning" "condition"
>>
>> since simpleWarning inherits from condition. And in fact I can use the
>> condition class to trap everything I want.
>>
>>> tryCatch(y(),condition=w)
>> List of 2
>>  $ message: chr "could not find function \"call_unknown_fun\""
>>  $ call   : language y()
>>  - attr(*, "class")= chr [1:3] "simpleError" "error" "condition"
>>
>>> tryCatch(z(),condition=w)
>> List of 2
>>  $ message: chr "message message\n"
>>  $ call   : language message("message message")
>>  - attr(*, "class")= chr [1:3] "condition" "message" "simpleMessage"
>>
>> (Side note: is the class hierarchy actually correct for this simpleMessage
>> object?)
>>
>> So in summary, wrap every R expression you want to run within a single
>> tryCatch() call and trap all conditions with one handler for the abstract
>> class named 'condition'. I think that's what you want...
>>
>> Jeff
>>
>>
>>>  > sessionInfo()
>>> R version 2.8.1 (2008-12-22)
>>> i386-apple-darwin8.11.1
>>>
>>> locale:
>>> en_GB.UTF-8/en_US.UTF-8/C/C/en_GB.UTF-8/en_GB.UTF-8
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  splines   methods
>>> [8] base
>>>
>>> other attached packages:
>>> [1] tractor.session_1.0.0   tractor.base_1.0.3      tractor.nt_1.0.2
>>>
>>> loaded via a namespace (and not attached):
>>> [1] tools_2.8.1
>>>
>>> Regards,
>>> Jon
>>>
>>>
>>> (1) http://code.google.com/p/tractor/
>>> (2) http://finzi.psych.upenn.edu/R/Rhelp02/archive/61872.html
>>>
>>>
>>> --
>>> Jonathan D. Clayden, Ph.D.
>>> Research Fellow
>>> Radiology and Physics Unit
>>> UCL Institute of Child Health
>>> 30 Guilford Street
>>> LONDON  WC1N 1EH
>>> United Kingdom
>>>
>>> t | +44 (0)20 7905 2708
>>> f | +44 (0)20 7905 2358
>>> w | www.homepages.ucl.ac.uk/~sejjjd2/
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> --
>> http://biostat.mc.vanderbilt.edu/JeffreyHorner
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>


-- 
http://biostat.mc.vanderbilt.edu/JeffreyHorner


From jeff.horner at vanderbilt.edu  Wed Feb  4 21:16:40 2009
From: jeff.horner at vanderbilt.edu (Jeffrey Horner)
Date: Wed, 04 Feb 2009 14:16:40 -0600
Subject: [Rd] Capturing all warnings (with messages)
In-Reply-To: <4989EA25.8050905@vanderbilt.edu>
References: <1F999E4C-B39B-46B4-92BC-074EFEE4B1E8@ucl.ac.uk>		<4989C7EA.1090700@vanderbilt.edu>	<68e086180902041011x53329634wf1b003c187090d3e@mail.gmail.com>
	<4989EA25.8050905@vanderbilt.edu>
Message-ID: <4989F7A8.6060707@vanderbilt.edu>

Jeffrey Horner wrote on 02/04/2009 01:19 PM:
> Jon Clayden wrote on 02/04/2009 12:11 PM:
>> Dear Jeff,
>>
>> Many thanks for the suggestion, but I don't think tryCatch() is the
>> answer, mainly because it causes code to stop executing when a warning
>> is signalled:
>>
>>> f <- function(w) print(w$message)
>>> tryCatch({warning("Test"); print(3)},warning=f)
>> [1] "Test"
>>
>> (The "print(3)" call is not run.) In this regard,
>> withCallingHandlers() is preferable. But either way it is untidy, at
>> best, to routinely put code inside one of these functions when I know
>> I always want to handle warnings my way. If I could set an appropriate
>> option when a package is loaded, or in an .Rprofile, then I should
>> never need to worry about whether a bit of code might generate
>> warnings and so should be wrapped.
> 
> So you want your program to handle all warnings your way, but you want 
> to continue execution after you have trapped the warnings. What 
> specifically do you want your program to do with a warning once you know 
> what it is?

I'm going to take a stab in the dark and presume you want to trap 
warnings  so that they aren't displayed. Using options(warn=-1) and the 
following could trap warnings allowing you to examine them and continue 
with code execution:

 > options('warn')
$warn
[1] -1

 > system('cat /tmp/foo.R')
warning("A simple warning")
cat("continuing...\n")
 > withCallingHandlers(source('/tmp/foo.R'), warning = function(e) str(e))
List of 2
  $ message: chr "A simple warning"
  $ call   : language eval.with.vis(expr, envir, enclos)
  - attr(*, "class")= chr [1:3] "simpleWarning" "warning" "condition"
continuing...

> 
> (I'd like to help you work through your problem to a solution because I 
> selfishly want to learn more about R's condition and restart system for 
> rapache's sake, my personal project. Right now, the way rapache notifies 
> users of R warnings and errors is crude but works.)
> 
> Jeff
> 
> 
>>
>> Regards,
>> Jon
>>
>> 2009/2/4 Jeffrey Horner <jeff.horner at vanderbilt.edu>:
>>> Jon Clayden wrote on 02/04/2009 06:59 AM:
>>>> Dear all,
>>>>
>>>> For an open-source project that I'm working on (1), which uses R for 
>>>> all
>>>> its heavy lifting but includes a wrapper shell script, I was hoping 
>>>> to find
>>>> a way to capture all warnings (and, in fact, errors too), and handle 
>>>> them in
>>>> my own way. I realise I can do this for a single expression using 
>>>> something
>>>> like:
>>>>
>>>>  > f <- function(w) print(w$message)
>>>>  > withCallingHandlers(warning("Test"),warning=f)
>>>> [1] "Test"
>>>> Warning message:
>>>> In withCallingHandlers(warning("Test"), warning = f) : Test
>>>>
>>>> But I would like to capture all warnings, globally. The
>>>> "warning.expression" option doesn't seem to allow an argument, and I 
>>>> can't
>>>> seem to use "last.warning" to get at the message either:
>>>>
>>>>  > g <- function() print(last.warning$message)
>>>>  > options(warning.expression=quote(g()))
>>>>  > warning("Test2")
>>>> NULL
>>>>
>>>> Could anyone tell me whether there's a way to do this, please? An old
>>>> thread on this topic seemed to go unresolved (2), and I've skimmed 
>>>> RNEWS and
>>>> I don't see anything about this since then.
>>> In fact, the thread did have the answer: tryCatch(). The help page is 
>>> a bear
>>> to read and comprehend, but if you do invest the time it should 
>>> convince you
>>> that you will want to use it. I find that I have to read and reread many
>>> sections of R documentation before I can reconcile what I want to 
>>> know with
>>> what the authors are trying to tell me.
>>>
>>> I don't comprehend everything about R's condition system, but let me 
>>> see if
>>> I can convince you that you need tryCatch() to do what you want.
>>>
>>> Consider:
>>>
>>> x <- function() warning("warning message")
>>> y <- function() call_unknown_fun()
>>> z <- function() message('message message')
>>>
>>> Each of these functions signal conditions of a particular condition 
>>> class:
>>> simpleWarning, simpleError, and simpleMessage, respectively.
>>>
>>> w <- function(e) str(e)
>>>
>>> I'm going to use w  to trap the simpleWarning condition:
>>>
>>>> tryCatch(x(),simpleWarning=w)
>>> List of 2
>>>  $ message: chr "warning message"
>>>  $ call   : language x()
>>>  - attr(*, "class")= chr [1:3] "simpleWarning" "warning" "condition"
>>>
>>> So tryCatch returned a list with two elements, the message and the 
>>> call that
>>> signaled the condition. In fact the list is actually an S3 object of 
>>> class
>>> simpleWarning, which inherits from warning and condition. Reading the 
>>> help
>>> page for tryCatch(), I can actually do this:
>>>
>>>> tryCatch(x(),condition=w)
>>> List of 2
>>>  $ message: chr "warning message"
>>>  $ call   : language x()
>>>  - attr(*, "class")= chr [1:3] "simpleWarning" "warning" "condition"
>>>
>>> since simpleWarning inherits from condition. And in fact I can use the
>>> condition class to trap everything I want.
>>>
>>>> tryCatch(y(),condition=w)
>>> List of 2
>>>  $ message: chr "could not find function \"call_unknown_fun\""
>>>  $ call   : language y()
>>>  - attr(*, "class")= chr [1:3] "simpleError" "error" "condition"
>>>
>>>> tryCatch(z(),condition=w)
>>> List of 2
>>>  $ message: chr "message message\n"
>>>  $ call   : language message("message message")
>>>  - attr(*, "class")= chr [1:3] "condition" "message" "simpleMessage"
>>>
>>> (Side note: is the class hierarchy actually correct for this 
>>> simpleMessage
>>> object?)
>>>
>>> So in summary, wrap every R expression you want to run within a single
>>> tryCatch() call and trap all conditions with one handler for the 
>>> abstract
>>> class named 'condition'. I think that's what you want...
>>>
>>> Jeff
>>>
>>>
>>>>  > sessionInfo()
>>>> R version 2.8.1 (2008-12-22)
>>>> i386-apple-darwin8.11.1
>>>>
>>>> locale:
>>>> en_GB.UTF-8/en_US.UTF-8/C/C/en_GB.UTF-8/en_GB.UTF-8
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  splines   methods
>>>> [8] base
>>>>
>>>> other attached packages:
>>>> [1] tractor.session_1.0.0   tractor.base_1.0.3      tractor.nt_1.0.2
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] tools_2.8.1
>>>>
>>>> Regards,
>>>> Jon
>>>>
>>>>
>>>> (1) http://code.google.com/p/tractor/
>>>> (2) http://finzi.psych.upenn.edu/R/Rhelp02/archive/61872.html
>>>>
>>>>
>>>> -- 
>>>> Jonathan D. Clayden, Ph.D.
>>>> Research Fellow
>>>> Radiology and Physics Unit
>>>> UCL Institute of Child Health
>>>> 30 Guilford Street
>>>> LONDON  WC1N 1EH
>>>> United Kingdom
>>>>
>>>> t | +44 (0)20 7905 2708
>>>> f | +44 (0)20 7905 2358
>>>> w | www.homepages.ucl.ac.uk/~sejjjd2/
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>> -- 
>>> http://biostat.mc.vanderbilt.edu/JeffreyHorner
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
> 
> 


-- 
http://biostat.mc.vanderbilt.edu/JeffreyHorner


From h.wickham at gmail.com  Wed Feb  4 23:28:29 2009
From: h.wickham at gmail.com (hadley wickham)
Date: Wed, 4 Feb 2009 16:28:29 -0600
Subject: [Rd] Capturing all warnings (with messages)
In-Reply-To: <1F999E4C-B39B-46B4-92BC-074EFEE4B1E8@ucl.ac.uk>
References: <1F999E4C-B39B-46B4-92BC-074EFEE4B1E8@ucl.ac.uk>
Message-ID: <f8e6ff050902041428u69dccc81p3fb44ef688a7068b@mail.gmail.com>

Hi Jon,

I have an in-development package that attempts to do this.  It's
called eval.with.details and is available from
http://github.com/hadley/eval.with.details.  As you might guess, it's
a version of eval that captures all details like messages, warnings,
errors and output so you can do whatever you want with them.  It
captures them in the way Jeff Horner describes - but there are a lot
of fiddly details to get right.

Unfortunately there isn't any documentation yet, but the majority of
what you're interested in is present in eval.r.  The code has been
fairly well tested - I'm using it in my own implementation of a sweave
like system.

Hadley

On Wed, Feb 4, 2009 at 6:59 AM, Jon Clayden <j.clayden at ucl.ac.uk> wrote:
> Dear all,
>
> For an open-source project that I'm working on (1), which uses R for all its
> heavy lifting but includes a wrapper shell script, I was hoping to find a
> way to capture all warnings (and, in fact, errors too), and handle them in
> my own way. I realise I can do this for a single expression using something
> like:
>
>> f <- function(w) print(w$message)
>> withCallingHandlers(warning("Test"),warning=f)
> [1] "Test"
> Warning message:
> In withCallingHandlers(warning("Test"), warning = f) : Test
>
> But I would like to capture all warnings, globally. The "warning.expression"
> option doesn't seem to allow an argument, and I can't seem to use
> "last.warning" to get at the message either:
>
>> g <- function() print(last.warning$message)
>> options(warning.expression=quote(g()))
>> warning("Test2")
> NULL
>
> Could anyone tell me whether there's a way to do this, please? An old thread
> on this topic seemed to go unresolved (2), and I've skimmed RNEWS and I
> don't see anything about this since then.
>
>> sessionInfo()
> R version 2.8.1 (2008-12-22)
> i386-apple-darwin8.11.1
>
> locale:
> en_GB.UTF-8/en_US.UTF-8/C/C/en_GB.UTF-8/en_GB.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  splines   methods
> [8] base
>
> other attached packages:
> [1] tractor.session_1.0.0   tractor.base_1.0.3      tractor.nt_1.0.2
>
> loaded via a namespace (and not attached):
> [1] tools_2.8.1
>
> Regards,
> Jon
>
>
> (1) http://code.google.com/p/tractor/
> (2) http://finzi.psych.upenn.edu/R/Rhelp02/archive/61872.html
>
>
> --
> Jonathan D. Clayden, Ph.D.
> Research Fellow
> Radiology and Physics Unit
> UCL Institute of Child Health
> 30 Guilford Street
> LONDON  WC1N 1EH
> United Kingdom
>
> t | +44 (0)20 7905 2708
> f | +44 (0)20 7905 2358
> w | www.homepages.ucl.ac.uk/~sejjjd2/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
http://had.co.nz/


From j.clayden at ucl.ac.uk  Thu Feb  5 01:31:10 2009
From: j.clayden at ucl.ac.uk (Jon Clayden)
Date: Thu, 5 Feb 2009 00:31:10 +0000
Subject: [Rd] Capturing all warnings (with messages)
In-Reply-To: <f8e6ff050902041428u69dccc81p3fb44ef688a7068b@mail.gmail.com>
References: <1F999E4C-B39B-46B4-92BC-074EFEE4B1E8@ucl.ac.uk>
	<f8e6ff050902041428u69dccc81p3fb44ef688a7068b@mail.gmail.com>
Message-ID: <68e086180902041631l4c560ce8j19506f08172c765@mail.gmail.com>

Jeff, Hadley,

Many thanks for your responses. The eval.with.details package sounds
interesting and I'll certainly take a closer look, but it still seems
to me that these approaches are focussed on trapping warnings within
specific snippets of code rather than changing the way all warnings
(including those in standard packages) are reported.

This ability would surely be useful anytime that you wish to change
the reporting of warnings from the default. Say, for example, that you
wanted to include a timestamp with each warning message. You'd do it,
I would expect, by writing a function that checks the time and formats
the message appropriately. This is the kind of thing I'm after -- I
hope this clarifies things a bit more.

The warn.expression option *appears* to provide a way to do what I
want, but because the warning is not passed to the expression (or so
it seems), and last.warning is not set before the expression is
evaluated, the expression can only know that *some* warning condition
has been raised, not *which* one. Perhaps there is a reason that
last.warning cannot be set first (?), but this limits the usefulness
of the option.

Jon

2009/2/4 hadley wickham <h.wickham at gmail.com>:
> Hi Jon,
>
> I have an in-development package that attempts to do this.  It's
> called eval.with.details and is available from
> http://github.com/hadley/eval.with.details.  As you might guess, it's
> a version of eval that captures all details like messages, warnings,
> errors and output so you can do whatever you want with them.  It
> captures them in the way Jeff Horner describes - but there are a lot
> of fiddly details to get right.
>
> Unfortunately there isn't any documentation yet, but the majority of
> what you're interested in is present in eval.r.  The code has been
> fairly well tested - I'm using it in my own implementation of a sweave
> like system.
>
> Hadley
>
> On Wed, Feb 4, 2009 at 6:59 AM, Jon Clayden <j.clayden at ucl.ac.uk> wrote:
>> Dear all,
>>
>> For an open-source project that I'm working on (1), which uses R for all its
>> heavy lifting but includes a wrapper shell script, I was hoping to find a
>> way to capture all warnings (and, in fact, errors too), and handle them in
>> my own way. I realise I can do this for a single expression using something
>> like:
>>
>>> f <- function(w) print(w$message)
>>> withCallingHandlers(warning("Test"),warning=f)
>> [1] "Test"
>> Warning message:
>> In withCallingHandlers(warning("Test"), warning = f) : Test
>>
>> But I would like to capture all warnings, globally. The "warning.expression"
>> option doesn't seem to allow an argument, and I can't seem to use
>> "last.warning" to get at the message either:
>>
>>> g <- function() print(last.warning$message)
>>> options(warning.expression=quote(g()))
>>> warning("Test2")
>> NULL
>>
>> Could anyone tell me whether there's a way to do this, please? An old thread
>> on this topic seemed to go unresolved (2), and I've skimmed RNEWS and I
>> don't see anything about this since then.
>>
>>> sessionInfo()
>> R version 2.8.1 (2008-12-22)
>> i386-apple-darwin8.11.1
>>
>> locale:
>> en_GB.UTF-8/en_US.UTF-8/C/C/en_GB.UTF-8/en_GB.UTF-8
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  splines   methods
>> [8] base
>>
>> other attached packages:
>> [1] tractor.session_1.0.0   tractor.base_1.0.3      tractor.nt_1.0.2
>>
>> loaded via a namespace (and not attached):
>> [1] tools_2.8.1
>>
>> Regards,
>> Jon
>>
>>
>> (1) http://code.google.com/p/tractor/
>> (2) http://finzi.psych.upenn.edu/R/Rhelp02/archive/61872.html
>>
>>
>> --
>> Jonathan D. Clayden, Ph.D.
>> Research Fellow
>> Radiology and Physics Unit
>> UCL Institute of Child Health
>> 30 Guilford Street
>> LONDON  WC1N 1EH
>> United Kingdom
>>
>> t | +44 (0)20 7905 2708
>> f | +44 (0)20 7905 2358
>> w | www.homepages.ucl.ac.uk/~sejjjd2/
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>
> --
> http://had.co.nz/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From wdunlap at tibco.com  Thu Feb  5 02:57:31 2009
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 4 Feb 2009 17:57:31 -0800
Subject: [Rd] Capturing all warnings (with messages)
In-Reply-To: <68e086180902041631l4c560ce8j19506f08172c765@mail.gmail.com>
References: <1F999E4C-B39B-46B4-92BC-074EFEE4B1E8@ucl.ac.uk><f8e6ff050902041428u69dccc81p3fb44ef688a7068b@mail.gmail.com>
	<68e086180902041631l4c560ce8j19506f08172c765@mail.gmail.com>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D7009C8E2E@NA-PA-VBE03.na.tibco.com>

In SV3 (or Splus prior to 5.0) one could redefine
the .Program expression, which
by default was close to print(eval(parse(stdin())) along
with some extras like printing warnings and errors in
certain ways and recording input in a .Audit file.   I
once wrote toy .Programs that used select() to
listen for data arriving on a socket and for commands
from stdin.  The data would be appended to a certain
dataset as it arrived and the user could ask to replot
it whenever he wanted.  You could use options("warning.expression")
and try() to present warnings and errors to the user in
whatever way you wanted.  I think it was used in old
versions of Splus on Windows to implement the connection
to the GUI.

Is this the sort of functionality you are looking for?

If you are writing a front-end for R the .Program is not
needed, as your front end can easily wrap boilerplate,
like eval.with.details, around whatever text the user types in.


Bill Dunlap
TIBCO Software Inc - Spotfire Division
wdunlap tibco.com  

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Jon Clayden
> Sent: Wednesday, February 04, 2009 4:31 PM
> To: hadley wickham
> Cc: R-devel at r-project.org
> Subject: Re: [Rd] Capturing all warnings (with messages)
> 
> Jeff, Hadley,
> 
> Many thanks for your responses. The eval.with.details package sounds
> interesting and I'll certainly take a closer look, but it still seems
> to me that these approaches are focussed on trapping warnings within
> specific snippets of code rather than changing the way all warnings
> (including those in standard packages) are reported.
> 
> This ability would surely be useful anytime that you wish to change
> the reporting of warnings from the default. Say, for example, that you
> wanted to include a timestamp with each warning message. You'd do it,
> I would expect, by writing a function that checks the time and formats
> the message appropriately. This is the kind of thing I'm after -- I
> hope this clarifies things a bit more.
> 
> The warn.expression option *appears* to provide a way to do what I
> want, but because the warning is not passed to the expression (or so
> it seems), and last.warning is not set before the expression is
> evaluated, the expression can only know that *some* warning condition
> has been raised, not *which* one. Perhaps there is a reason that
> last.warning cannot be set first (?), but this limits the usefulness
> of the option.
> 
> Jon
> 
> 2009/2/4 hadley wickham <h.wickham at gmail.com>:
> > Hi Jon,
> >
> > I have an in-development package that attempts to do this.  It's
> > called eval.with.details and is available from
> > http://github.com/hadley/eval.with.details.  As you might 
> guess, it's
> > a version of eval that captures all details like messages, warnings,
> > errors and output so you can do whatever you want with them.  It
> > captures them in the way Jeff Horner describes - but there are a lot
> > of fiddly details to get right.
> >
> > Unfortunately there isn't any documentation yet, but the majority of
> > what you're interested in is present in eval.r.  The code has been
> > fairly well tested - I'm using it in my own implementation 
> of a sweave
> > like system.
> >
> > Hadley
> >
> > On Wed, Feb 4, 2009 at 6:59 AM, Jon Clayden 
> <j.clayden at ucl.ac.uk> wrote:
> >> Dear all,
> >>
> >> For an open-source project that I'm working on (1), which 
> uses R for all its
> >> heavy lifting but includes a wrapper shell script, I was 
> hoping to find a
> >> way to capture all warnings (and, in fact, errors too), 
> and handle them in
> >> my own way. I realise I can do this for a single 
> expression using something
> >> like:
> >>
> >>> f <- function(w) print(w$message)
> >>> withCallingHandlers(warning("Test"),warning=f)
> >> [1] "Test"
> >> Warning message:
> >> In withCallingHandlers(warning("Test"), warning = f) : Test
> >>
> >> But I would like to capture all warnings, globally. The 
> "warning.expression"
> >> option doesn't seem to allow an argument, and I can't seem to use
> >> "last.warning" to get at the message either:
> >>
> >>> g <- function() print(last.warning$message)
> >>> options(warning.expression=quote(g()))
> >>> warning("Test2")
> >> NULL
> >>
> >> Could anyone tell me whether there's a way to do this, 
> please? An old thread
> >> on this topic seemed to go unresolved (2), and I've 
> skimmed RNEWS and I
> >> don't see anything about this since then.
> >>
> >>> sessionInfo()
> >> R version 2.8.1 (2008-12-22)
> >> i386-apple-darwin8.11.1
> >>
> >> locale:
> >> en_GB.UTF-8/en_US.UTF-8/C/C/en_GB.UTF-8/en_GB.UTF-8
> >>
> >> attached base packages:
> >> [1] stats     graphics  grDevices utils     datasets  
> splines   methods
> >> [8] base
> >>
> >> other attached packages:
> >> [1] tractor.session_1.0.0   tractor.base_1.0.3      
> tractor.nt_1.0.2
> >>
> >> loaded via a namespace (and not attached):
> >> [1] tools_2.8.1
> >>
> >> Regards,
> >> Jon
> >>
> >>
> >> (1) http://code.google.com/p/tractor/
> >> (2) http://finzi.psych.upenn.edu/R/Rhelp02/archive/61872.html
> >>
> >>
> >> --
> >> Jonathan D. Clayden, Ph.D.
> >> Research Fellow
> >> Radiology and Physics Unit
> >> UCL Institute of Child Health
> >> 30 Guilford Street
> >> LONDON  WC1N 1EH
> >> United Kingdom
> >>
> >> t | +44 (0)20 7905 2708
> >> f | +44 (0)20 7905 2358
> >> w | www.homepages.ucl.ac.uk/~sejjjd2/
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >
> >
> >
> > --
> > http://had.co.nz/
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From luke at stat.uiowa.edu  Thu Feb  5 03:18:32 2009
From: luke at stat.uiowa.edu (luke at stat.uiowa.edu)
Date: Wed, 4 Feb 2009 20:18:32 -0600 (CST)
Subject: [Rd] Capturing all warnings (with messages)
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D7009C8E2E@NA-PA-VBE03.na.tibco.com>
References: <1F999E4C-B39B-46B4-92BC-074EFEE4B1E8@ucl.ac.uk><f8e6ff050902041428u69dccc81p3fb44ef688a7068b@mail.gmail.com>
	<68e086180902041631l4c560ce8j19506f08172c765@mail.gmail.com>
	<77EB52C6DD32BA4D87471DCD70C8D7009C8E2E@NA-PA-VBE03.na.tibco.com>
Message-ID: <alpine.DEB.1.00.0902042014020.16087@luke-inspiron>

Kurt Hornik and I have discussed off an on a mechanism for setting
default condition handlers.  So far we haven't come up with anything
satisfactory but we may yet.  In some ways this would be easier if the
top level was written in R, along the lines of .Program, so I've
played around with that a bit, but not to the point where it is usable
in production yet.

luke

On Wed, 4 Feb 2009, William Dunlap wrote:

> In SV3 (or Splus prior to 5.0) one could redefine
> the .Program expression, which
> by default was close to print(eval(parse(stdin())) along
> with some extras like printing warnings and errors in
> certain ways and recording input in a .Audit file.   I
> once wrote toy .Programs that used select() to
> listen for data arriving on a socket and for commands
> from stdin.  The data would be appended to a certain
> dataset as it arrived and the user could ask to replot
> it whenever he wanted.  You could use options("warning.expression")
> and try() to present warnings and errors to the user in
> whatever way you wanted.  I think it was used in old
> versions of Splus on Windows to implement the connection
> to the GUI.
>
> Is this the sort of functionality you are looking for?
>
> If you are writing a front-end for R the .Program is not
> needed, as your front end can easily wrap boilerplate,
> like eval.with.details, around whatever text the user types in.
>
>
> Bill Dunlap
> TIBCO Software Inc - Spotfire Division
> wdunlap tibco.com
>
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org
>> [mailto:r-devel-bounces at r-project.org] On Behalf Of Jon Clayden
>> Sent: Wednesday, February 04, 2009 4:31 PM
>> To: hadley wickham
>> Cc: R-devel at r-project.org
>> Subject: Re: [Rd] Capturing all warnings (with messages)
>>
>> Jeff, Hadley,
>>
>> Many thanks for your responses. The eval.with.details package sounds
>> interesting and I'll certainly take a closer look, but it still seems
>> to me that these approaches are focussed on trapping warnings within
>> specific snippets of code rather than changing the way all warnings
>> (including those in standard packages) are reported.
>>
>> This ability would surely be useful anytime that you wish to change
>> the reporting of warnings from the default. Say, for example, that you
>> wanted to include a timestamp with each warning message. You'd do it,
>> I would expect, by writing a function that checks the time and formats
>> the message appropriately. This is the kind of thing I'm after -- I
>> hope this clarifies things a bit more.
>>
>> The warn.expression option *appears* to provide a way to do what I
>> want, but because the warning is not passed to the expression (or so
>> it seems), and last.warning is not set before the expression is
>> evaluated, the expression can only know that *some* warning condition
>> has been raised, not *which* one. Perhaps there is a reason that
>> last.warning cannot be set first (?), but this limits the usefulness
>> of the option.
>>
>> Jon
>>
>> 2009/2/4 hadley wickham <h.wickham at gmail.com>:
>>> Hi Jon,
>>>
>>> I have an in-development package that attempts to do this.  It's
>>> called eval.with.details and is available from
>>> http://github.com/hadley/eval.with.details.  As you might
>> guess, it's
>>> a version of eval that captures all details like messages, warnings,
>>> errors and output so you can do whatever you want with them.  It
>>> captures them in the way Jeff Horner describes - but there are a lot
>>> of fiddly details to get right.
>>>
>>> Unfortunately there isn't any documentation yet, but the majority of
>>> what you're interested in is present in eval.r.  The code has been
>>> fairly well tested - I'm using it in my own implementation
>> of a sweave
>>> like system.
>>>
>>> Hadley
>>>
>>> On Wed, Feb 4, 2009 at 6:59 AM, Jon Clayden
>> <j.clayden at ucl.ac.uk> wrote:
>>>> Dear all,
>>>>
>>>> For an open-source project that I'm working on (1), which
>> uses R for all its
>>>> heavy lifting but includes a wrapper shell script, I was
>> hoping to find a
>>>> way to capture all warnings (and, in fact, errors too),
>> and handle them in
>>>> my own way. I realise I can do this for a single
>> expression using something
>>>> like:
>>>>
>>>>> f <- function(w) print(w$message)
>>>>> withCallingHandlers(warning("Test"),warning=f)
>>>> [1] "Test"
>>>> Warning message:
>>>> In withCallingHandlers(warning("Test"), warning = f) : Test
>>>>
>>>> But I would like to capture all warnings, globally. The
>> "warning.expression"
>>>> option doesn't seem to allow an argument, and I can't seem to use
>>>> "last.warning" to get at the message either:
>>>>
>>>>> g <- function() print(last.warning$message)
>>>>> options(warning.expression=quote(g()))
>>>>> warning("Test2")
>>>> NULL
>>>>
>>>> Could anyone tell me whether there's a way to do this,
>> please? An old thread
>>>> on this topic seemed to go unresolved (2), and I've
>> skimmed RNEWS and I
>>>> don't see anything about this since then.
>>>>
>>>>> sessionInfo()
>>>> R version 2.8.1 (2008-12-22)
>>>> i386-apple-darwin8.11.1
>>>>
>>>> locale:
>>>> en_GB.UTF-8/en_US.UTF-8/C/C/en_GB.UTF-8/en_GB.UTF-8
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets
>> splines   methods
>>>> [8] base
>>>>
>>>> other attached packages:
>>>> [1] tractor.session_1.0.0   tractor.base_1.0.3
>> tractor.nt_1.0.2
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] tools_2.8.1
>>>>
>>>> Regards,
>>>> Jon
>>>>
>>>>
>>>> (1) http://code.google.com/p/tractor/
>>>> (2) http://finzi.psych.upenn.edu/R/Rhelp02/archive/61872.html
>>>>
>>>>
>>>> --
>>>> Jonathan D. Clayden, Ph.D.
>>>> Research Fellow
>>>> Radiology and Physics Unit
>>>> UCL Institute of Child Health
>>>> 30 Guilford Street
>>>> LONDON  WC1N 1EH
>>>> United Kingdom
>>>>
>>>> t | +44 (0)20 7905 2708
>>>> f | +44 (0)20 7905 2358
>>>> w | www.homepages.ucl.ac.uk/~sejjjd2/
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>>
>>>
>>> --
>>> http://had.co.nz/
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Thu Feb  5 13:17:17 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Thu, 05 Feb 2009 13:17:17 +0100
Subject: [Rd] (PR#8192) [ subscripting sometimes loses names
In-Reply-To: <49846A9A.8070308@biostat.ku.dk>
References: <157EE908-8A6C-46E4-A9FF-A933A25DEFD9@r-project.org>	<20090131123158.GA31706@piskorski.com>	<49845A8A.70000@stats.uwo.ca>
	<49846A9A.8070308@biostat.ku.dk>
Message-ID: <498AD8CD.8000007@idi.ntnu.no>

it's becoming an old story, but here's a bit to be added.

Peter Dalgaard wrote:
> Duncan Murdoch wrote:
>> On 31/01/2009 7:31 AM, Andrew Piskorski wrote:
>>> This (tangential) discussion really should be a separate thread so I
>>> changed the subject line above.
>>>
>>> On Fri, Jan 30, 2009 at 11:51:00AM -0500, Simon Urbanek wrote:
>>>> Subject: Re: [Rd] (PR#13487) Segfault when mistakenly calling
>>>> [.data.frame
>>>
>>>>> My boss was debugging an issue in our R code.  We have our own
>>>>> "[...."
>>>>> functions, because stock R drops names when subscripting.
>>>> ... if you tell it to do so, yes. If you tell it to not do that,
>>>> it  won't ... ever tried drop=FALSE ?
>>>
>>> Simon, no, the drop=FALSE argument has nothing to do with what
>>> Christian was talking about.  The kind of thing he meant is PR# 8192,
>>> "Subject: [ subscripting sometimes loses names":
>>>
>>>   http://bugs.r-project.org/cgi-bin/R/wishlist?id=8192
>>
>> In that bug report you were asked to provide simple examples, and you
>> didn't.  I imagine that's why there was no action on it.  It is not
>> that easy for someone else to actually find the simple example that
>> led you to print
>>
>>      $vec.1
>> BAD  $vec.1[[1]]           $vec.1[[2]]
>>         a    c <NA>         a  c no
>>         1    3   NA         1  3 NA
>>
>> I just tracked this one down, and can put together this simple example:
>>
>>  > (1:3)["no"]
>> [1] NA
>>
>> where I think you would want the name "no" attached to the output. 
>> (Or maybe your more complicated example is wanted?  You don't
>> explain.)  But that looks like documented behaviour to me:  according
>> to my reading of "Indexing by vectors" in the R Language Definition
>> manual, it should give the same answer as (1:3)[4], and it does.  So
>> it's not a bug, but a wishlist item.
>>
>> And the other two cases where you list "BAD" behaviour?  I didn't
>> track them down.
>
> I did, and they boil down to variations of
>
> > data.frame(val=1:3,row.names=letters[1:3])[,1]
> [1] 1 2 3
>
> but it's not obvious that the result should be named using the
> row.names and (in particular) whether or why it should differ from
> .....[[1]] and ....$val. 

once you are saying that, be prepared to explain why it should *not*
differ from [[1]] and $val.  reading ?'[' carefully, you'll find:

"     The most important distinction between '[', '[[' and '$' is that
     the '[' can select more than one element whereas the other two
     select a single element."

that's actually quite enough to justify why [,1] (or rather [, indices],
with an arbitrary vector of indices) should differ from [[1]] and $val. 
precisely because:

a) [[index]] and $name are *guaranteed* to return one column (or fail),
so it's reasonable to *always* drop the dimension -- because it will be
done in the case of every successful selection;

b) [, indices] *may* or *may not* return one column in a successful
selection, and now dropping the dimension (and names) depends not on the
type of the indices used (positive numeric, negative numeric, character,
whatever), but on the length of the index vector.

why is external consistence of [ (being like [[ and $) when a single
index is used more important than its internal consistence (returning
the same type of data -- a data frame, or a like-dimensioned matrix --
irrespectively of the length of the index vector)?

i realize that the issue of drop=FALSE vs drop=TRUE as the default has
been discussed before, but i don't find clear arguments given for the
first option, beyond that it just is so and would break much old code if
were to be changed.  i'm actually hoping not for this to be changed, but
for users not to be blamed for assuming [,1] returns a data frame with
row names.  it's *not* their fault they are wrong.


> Given that for most purposes, extracting the relevant names would just
> be unnecessary red tape, I'd say that we can do without it.
>

would keeping the dimensions and class be just unnecessary red tape,
too?  can you know what most users' purposes are?

vQ


From Udo.Junghans at nw-fva.de  Thu Feb  5 12:30:08 2009
From: Udo.Junghans at nw-fva.de (Udo.Junghans at nw-fva.de)
Date: Thu,  5 Feb 2009 12:30:08 +0100 (CET)
Subject: [Rd] Multiple-Line Comment (PR#13503)
Message-ID: <20090205113009.218B42823A68@mail.pubhealth.ku.dk>

Hello,

sorry for writing here because my problem is not a realt bug but may be 
a solution for many people working with R:

I miss the feature for commenting some lines of code at once without 
writing a bunch of "#" in front of each line.
This is interesting for trying out some code.
I found some workarounds like

IFELSE(FALSE){} and

`!`<- function(x)
  {
    if (inherits(x, "character") == FALSE)
    .Primitive("!")(x) else invisible(x)
   }

but IFELSE needs valid code and the '!' <- function breaks when a " ' " 
appears in the comment

so it would be fine to have something like /* ...  */ or so  for 
multiple lines


with regards

Udo Junghans
-- 





















------------------------------------------------------------------------

Udo Junghans
Abteilung Waldschutz, K?fer und Mittelpr?fung
Nordwestdeutsche Forstliche Versuchsanstalt
Gr?tzelstrasse 2
D-37079 G?ttingen <mailto:udo.junghans at nw-fva.de>


From erikl at phonetik.uni-muenchen.de  Thu Feb  5 09:15:06 2009
From: erikl at phonetik.uni-muenchen.de (erikl at phonetik.uni-muenchen.de)
Date: Thu,  5 Feb 2009 09:15:06 +0100 (CET)
Subject: [Rd] JGR extension not working (PR#13501)
Message-ID: <20090205081506.2FF3F284A70C@mail.pubhealth.ku.dk>

Full_Name: Erik Lukac
Version: R version 2.8.1 (2008-12-22) 
OS: Mac OS 10.5
Submission from: (NULL) (141.84.28.167)


I tried to install JGR, but somehow it doesnt work. 


> install.packages("JGR")
Warning in install.packages("JGR") :
  argument 'lib' is missing: using
'/Users/erikl/R/i386-apple-darwin9.6.0-library/2.8'
trying URL 'http://cran.rakanu.com/src/contrib/JGR_1.6-2.tar.gz'
Content type 'application/x-gzip' length 428978 bytes (418 Kb)
opened URL
==================================================
downloaded 418 Kb

* Installing *source* package 'JGR' ...
** R
** inst
** preparing package for lazy loading
Loading required package: rJava
Loading required package: JavaGD
Loading required package: iplots
Note: On Mac OS X we strongly recommend using iplots from within JGR.
Proceed at your own risk as iplots cannot resolve potential ev.loop deadlocks.
'Yes' is assumed for all dialogs as they cannot be shown without a deadlock,
also ievent.wait() is disabled.
2009-02-05 09:04:31.028 R[6886:613] Apple AWT Java VM was loaded on first thread
-- can't start AWT.
Warning in .jnew("org/rosuda/iplots/Framework") :
  NewObject("org/rosuda/iplots/Framework","()V",...) failed
Exception in thread "main" java.lang.InternalError: Can't start the AWT because
Java was started on the first thread.  Make sure StartOnFirstThread is not
specified in your application's Info.plist or on the command line
	at java.lang.ClassLoader$NativeLibrary.load(Native Method)
	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1822)
	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1723)
	at java.lang.Runtime.loadLibrary0(Runtime.java:822)
	at java.lang.System.loadLibrary(System.java:993)
	at sun.security.action.LoadLibraryAction.run(LoadLibraryAction.java:50)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.awt.Toolkit.loadLibraries(Toolkit.java:1509)
	at java.awt.Toolkit.<clinit>(Toolkit.java:1530)
	at java.awt.Color.<clinit>(Color.java:250)
	at org.rosuda.ibase.Common.<clinit>(Common.java:47)
	at org.rosuda.iplots.Framework.<init>(Framework.java:43)
Error in .jnew("org/rosuda/iplots/Framework") : 
  Failed to create object of class `org/rosuda/iplots/Framework'
Error: package 'iplots' could not be loaded
Execution halted
ERROR: lazy loading failed for package 'JGR'
** Removing '/Users/erikl/R/i386-apple-darwin9.6.0-library/2.8/JGR'

The downloaded packages are in
	/private/var/folders/Vg/Vgf6mZdSH8mlJdsK7HKoA++++TI/-Tmp-/RtmpgsoIqo/downloaded_packages
Warning message:
In install.packages("JGR") :
  installation of package 'JGR' had non-zero exit status


From johnc.deva at yahoo.com  Thu Feb  5 14:10:04 2009
From: johnc.deva at yahoo.com (johnc.deva at yahoo.com)
Date: Thu,  5 Feb 2009 14:10:04 +0100 (CET)
Subject: [Rd] Bug in the parser (?) (PR#13504)
Message-ID: <20090205131004.AE42C283415C@mail.pubhealth.ku.dk>

Full_Name: John C. Deva
Version: 2.8.1
OS: Fedora Linux 8, 64 bit
Submission from: (NULL) (193.200.150.189)


I notice that it is possible to redefine 'if' as a function of an arbitrary
number of arguments.  Such redefined 'if' can then be used as any other user
function, except for that the parser still demands exactly three arguments to be
given to if.  Furthermore, even if 'if' is defined with three arguments, its
application must still be made with the original syntax, and not the usual
syntax of function application:

> `if` <- function(a,b,c) 
+ {
+ assign(deparse(substitute(a)), b+c, envir=parent.frame()
+ }

> if (x) 1 else 2
> x
[1] 3

> if(x, 1, 2)
Error: unexpected ',' in "if(x,"

The later expression above should be the only valid when 'if' is redefined as
above, but it is not the case.

Sincerely,
John C.


From ripley at stats.ox.ac.uk  Thu Feb  5 14:42:19 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 5 Feb 2009 13:42:19 +0000 (GMT)
Subject: [Rd] [R] Is abline misbehaving?
In-Reply-To: <B37C0A15B8FB3C468B5BC7EBC7DA14CC61C939D06F@LP-EXMBVS10.CO.IHC.COM>
References: <497AE46F.8020704@bitwrit.com.au>
	<B37C0A15B8FB3C468B5BC7EBC7DA14CC61C939D06F@LP-EXMBVS10.CO.IHC.COM>
Message-ID: <alpine.LFD.2.00.0902051333040.25207@gannet.stats.ox.ac.uk>

[Moved to R-devel, where it probably should have started and it is 
getting to C-level functions now.]

abline is not 'misbehaving' (don't be rude about the work of 
volunteers who are in your audience), but behaving in the same way as 
other graphics calls.

The real story is this (and R is Open Source, so you can read the code 
too).

Most base graphics functions call GClip to set the graphics clip state 
before drawing).  GClip only does anything if the xpd state has 
changed since the last time it was used, and in the case of a plot 
like this with axes which were drawn in the margins, it has done so.
Now, the tricky bit is 'was used', which can be very hard to 
determine.  Just setting the par is not enough: it has to be 'used'.

What I have done in R-devel is make clip() 'use' xpd, and that will 
ensure that the clip region it sets persists until xpd is next 
changed.  There the example works as I believe you intended.


On Sat, 24 Jan 2009, Greg Snow wrote:

> This is a known issue, the documentation of clip talks about some plotting functions resetting the clipping region and some don't.  abline is apparently one of those that plots first, then resets the clipping region (so the first time it doesn't acknowledge it, but does afterwards).  The function clipplot in the TeachingDemos package uses a similar kludge to what you do below (and I guess that puts my standing in the hall of fame at even higher risk than yours) except that it uses the box function with a transparent box to reset the clipping region, which means that you get strange boxes if your graphics device does not handle transparency.  It was a question like yours that I asked in order to try to eliminate the kludge from clipplot that originally lead to the clip function being added, and it does cover the initial cases that I asked about.
>
> In order to change things to work like we would like (always resetting the clipping region at the appropriate place so that clip always does what we expect) will probably require going through every basic command that could put something into the plot and figure out exactly when to have them reset the clipping region (which may not be a simple decision, doing it too early may break existing code).  The amount of tedious work required for not much return places this fairly low on the priority list, especially when there is a work around (as you have found), even if it feels like a bit of a kludge.
>
> So while this probably does not fix your problem, at least hopefully this helps you understand a bit more of what is happening here, and at least you know that you are not alone in hall of kludge infamy.
>
> -- 
> Gregory (Greg) L. Snow Ph.D.
> Statistical Data Center
> Intermountain Healthcare
> greg.snow at imail.org
> 801.408.8111
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of Jim Lemon
>> Sent: Saturday, January 24, 2009 2:51 AM
>> To: r-help at r-project.org
>> Subject: [R] Is abline misbehaving?
>>
>> Hi experts,
>> I was graciously offered a function to enhance abline by restricting
>> the
>> extent of the line to less than the plotting region. This seems a
>> useful
>> idea, and it looked like the easiest way to program it was to set up a
>> clipping region with "clip", draw the abline and then restore the
>> previous clipping region. Let us call this function ablineclip. After
>> quite a bit of testing, I have found that the first call to ablineclip
>> ignores the clipping region. It's not that simple. Successive calls to
>> ablineclip respect the clipping region, even if it changes. I can
>> reproduce the behavior like this:
>>
>> plot(-3:3,-3:3)
>> clip(-2,2,-2,2)
>> abline(v=0)
>> clip(-2,2,-2,2)
>> abline(h=0)
>>
>>
>> The first abline ignores the clip, the second respects it. I have
>> programmed around this, with the pathetic kludge of calling "abline"
>> with a line outside the plotting area, calling "clip" a second time,
>> and
>> then calling "abline" with the line that was requested. While this
>> works, my place in programming history will be ineradicably compromised
>> if the Programmers' Hall of Fame ever finds out. Any suggestions?
>>
>> R-2.7.2
>> FC9 Linux
>>
>> Jim
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From P.Dalgaard at biostat.ku.dk  Thu Feb  5 15:14:37 2009
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 05 Feb 2009 15:14:37 +0100
Subject: [Rd] Bug in the parser (?) (PR#13504)
In-Reply-To: <20090205131004.AE42C283415C@mail.pubhealth.ku.dk>
References: <20090205131004.AE42C283415C@mail.pubhealth.ku.dk>
Message-ID: <498AF44D.6080805@biostat.ku.dk>

johnc.deva at yahoo.com wrote:
> Full_Name: John C. Deva
> Version: 2.8.1
> OS: Fedora Linux 8, 64 bit
> Submission from: (NULL) (193.200.150.189)
> 
> 
> I notice that it is possible to redefine 'if' as a function of an arbitrary
> number of arguments.  Such redefined 'if' can then be used as any other user
> function, except for that the parser still demands exactly three arguments to be
> given to if.  Furthermore, even if 'if' is defined with three arguments, its
> application must still be made with the original syntax, and not the usual
> syntax of function application:
> 
>> `if` <- function(a,b,c) 
> + {
> + assign(deparse(substitute(a)), b+c, envir=parent.frame()
> + }
> 
>> if (x) 1 else 2
>> x
> [1] 3
> 
>> if(x, 1, 2)
> Error: unexpected ',' in "if(x,"
> 
> The later expression above should be the only valid when 'if' is redefined as
> above, but it is not the case.


A bug report with a ? in the title is in general ill-advised. If you are
not sure that something is a bug, then ask a question instead.

In this case, no, it is not a bug. Syntax is syntax and "if(x,1,2)" is a
syntax error no matter how if() is defined. Parsing is controlled by the
fact that "if" is a keyword, the function definition is not used at all
at that stage. `if`(x,1,2) works perfectly well, though, at least until
you try deparsing it:

> quote(`if`(x,1,2))
if (x) 1 else 2


Redefining "if" is a really Bad Idea, excepting things like code
analysis tools (which I believe are the main reason it is not explicitly
forbidden).


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Thu Feb  5 15:17:07 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Thu, 05 Feb 2009 15:17:07 +0100
Subject: [Rd] Bug in the parser (?) (PR#13504)
In-Reply-To: <20090205131004.AE42C283415C@mail.pubhealth.ku.dk>
References: <20090205131004.AE42C283415C@mail.pubhealth.ku.dk>
Message-ID: <498AF4E3.1020902@idi.ntnu.no>

johnc.deva at yahoo.com wrote:
> Full_Name: John C. Deva
> Version: 2.8.1
> OS: Fedora Linux 8, 64 bit
> Submission from: (NULL) (193.200.150.189)
>
>
> I notice that it is possible to redefine 'if' as a function of an arbitrary
> number of arguments.  Such redefined 'if' can then be used as any other user
> function, except for that the parser still demands exactly three arguments to be
> given to if.  Furthermore, even if 'if' is defined with three arguments, its
> application must still be made with the original syntax, and not the usual
> syntax of function application:
>
>   
>> `if` <- function(a,b,c) 
>>     
> + {
> + assign(deparse(substitute(a)), b+c, envir=parent.frame()
> + }
>
>   
>> if (x) 1 else 2
>> x
>>     
> [1] 3
>
>   
>> if(x, 1, 2)
>>     
> Error: unexpected ',' in "if(x,"
>
> The later expression above should be the only valid when 'if' is redefined as
> above, but it is not the case.
>   

i've had a similar question discussed with peter dalgaard (i think)
offline (i think), with a close, though less tricky and exotic example. 
the issue is, when you redefine if, it does not propagate to the parser,
which still treats every occurrence of 'if' to be a keyword with the
usual syntactic constraints.  thus, the only way to apply such redefined
if is to use the original if syntax.

arguably, the parser could be parsing 'if' as a regular name in some
syntactic contexts, thus making you happily apply it as you want:

if(x) 1else 2 # parse as the conditional keyword 'if', since '1 else 2'
is present
if(x) 1 # likewise, since otherwise '1' after 'if(x)' would be
syntactically invalid
if() # parse as a function name, in a 0-argument call
if(x) # likewise, a 1-argument call
if(x, 1) # likewise, a 2-argument call
if(x, 1, 2) # likewise, ...
...

now you could redefine and use if as follows, for example (for whatever
reason might you wish to have if perform such weird actions):

if = function(...)
    assign(deparse(substitute(a)), sum(...), envir=parent.frame())
# note, no need to quote 'if' for the assignment
# if the parser would not force 'if' to be a keyword here

x = 0
if(x) 1 else 2
# 2
if(x) 1
# NULL, invisibly
if(x)
# x is sum()
if(x, 1)
# x is 1
if(x, 1, 2)
# x is 3

or maybe

if = function(if, x) if(if(x)) x else if
if(is.integer, 2)
# .Primitive("is.integer")
if(is.integer, 2L)
# 2

you probably don't really need to redefine if this way, or any other
way, but the point is valid, imho, and applicable to any other reserved
word.  it's rather weird that you *can* redefine if and use it as a
regular function but with the original syntax, as in your example.

you'll certainly get bashed for the bug report; it's not a bug, rather a
design issue, and not necessarily a problem.

vQ


From rmh at temple.edu  Thu Feb  5 15:35:08 2009
From: rmh at temple.edu (rmh at temple.edu)
Date: Thu,  5 Feb 2009 15:35:08 +0100 (CET)
Subject: [Rd] bug in proj() (PR#13505)
Message-ID: <20090205143509.49F0B2834173@mail.pubhealth.ku.dk>

The result of proj() is not currently coerced to data.frame
when requested.  I use this capability pedagogically all the time.
It did work when I wrote proj() for the Chambers and Hastie book, and
it still works in S-Plus.  A minimal repair is in the as.data.frame.aovproj 
definition below.

Rich

> version
               _                           
platform       i386-pc-mingw32             
arch           i386                        
os             mingw32                     
system         i386, mingw32               
status                                     
major          2                           
minor          8.1                         
year           2008                        
month          12                          
day            22                          
svn rev        47281                       
language       R                           
version.string R version 2.8.1 (2008-12-22)
>

## using the example in ?aov

utils::data(npk, package="MASS")

npk.aov <- aov(yield ~ block + N * P + K, npk)
proj(npk.aov)
cbind(npk, proj(npk.aov))

as.data.frame.aovproj <- function(x, ...) as.data.frame(unclass(x), ...)

cbind(npk, proj(npk.aov))



> cbind(npk, proj(npk.aov))
Error in as.data.frame.default(x[[i]], optional = TRUE) : 
  cannot coerce class "aovproj" into a data.frame
> as.data.frame.aovproj <- function(x, ...) as.data.frame(unclass(x), ...)
> cbind(npk, proj(npk.aov))
   block N P K yield (Intercept)  block         N          P         K
1      1 0 1 1  49.5      54.875 -0.850 -2.808333 -0.5916667 -1.991667
....


From phgrosjean at sciviews.org  Thu Feb  5 15:40:41 2009
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Thu, 05 Feb 2009 15:40:41 +0100
Subject: [Rd] Capturing all warnings (with messages)
In-Reply-To: <alpine.DEB.1.00.0902042014020.16087@luke-inspiron>
References: <1F999E4C-B39B-46B4-92BC-074EFEE4B1E8@ucl.ac.uk><f8e6ff050902041428u69dccc81p3fb44ef688a7068b@mail.gmail.com>	<68e086180902041631l4c560ce8j19506f08172c765@mail.gmail.com>	<77EB52C6DD32BA4D87471DCD70C8D7009C8E2E@NA-PA-VBE03.na.tibco.com>
	<alpine.DEB.1.00.0902042014020.16087@luke-inspiron>
Message-ID: <498AFA69.3020508@sciviews.org>

Hello,

There is a function captureAll() in the svMisc package on CRAN. Although 
in its current version, it simulates textual output you got at the 
console, it should be rather easy to modify it to return separately 
output, errors and warnings. There is one point to consider: the 
function cannot catch some output from c code, and it does not work well 
with R code needing interaction at the console, like browser() for 
instance. For the rest, its handling of output (visible versus invisible 
output) and of warnings, including management of options(warn = ) is 
very similar to what is done at the console.
Best,

Philippe
..............................................<?}))><........
  ) ) ) ) )
( ( ( ( (    Prof. Philippe Grosjean
  ) ) ) ) )
( ( ( ( (    Numerical Ecology of Aquatic Systems
  ) ) ) ) )   Mons-Hainaut University, Belgium
( ( ( ( (
..............................................................

luke at stat.uiowa.edu wrote:
> Kurt Hornik and I have discussed off an on a mechanism for setting
> default condition handlers.  So far we haven't come up with anything
> satisfactory but we may yet.  In some ways this would be easier if the
> top level was written in R, along the lines of .Program, so I've
> played around with that a bit, but not to the point where it is usable
> in production yet.
> 
> luke
> 
> On Wed, 4 Feb 2009, William Dunlap wrote:
> 
>> In SV3 (or Splus prior to 5.0) one could redefine
>> the .Program expression, which
>> by default was close to print(eval(parse(stdin())) along
>> with some extras like printing warnings and errors in
>> certain ways and recording input in a .Audit file.   I
>> once wrote toy .Programs that used select() to
>> listen for data arriving on a socket and for commands
>> from stdin.  The data would be appended to a certain
>> dataset as it arrived and the user could ask to replot
>> it whenever he wanted.  You could use options("warning.expression")
>> and try() to present warnings and errors to the user in
>> whatever way you wanted.  I think it was used in old
>> versions of Splus on Windows to implement the connection
>> to the GUI.
>>
>> Is this the sort of functionality you are looking for?
>>
>> If you are writing a front-end for R the .Program is not
>> needed, as your front end can easily wrap boilerplate,
>> like eval.with.details, around whatever text the user types in.
>>
>>
>> Bill Dunlap
>> TIBCO Software Inc - Spotfire Division
>> wdunlap tibco.com
>>
>>> -----Original Message-----
>>> From: r-devel-bounces at r-project.org
>>> [mailto:r-devel-bounces at r-project.org] On Behalf Of Jon Clayden
>>> Sent: Wednesday, February 04, 2009 4:31 PM
>>> To: hadley wickham
>>> Cc: R-devel at r-project.org
>>> Subject: Re: [Rd] Capturing all warnings (with messages)
>>>
>>> Jeff, Hadley,
>>>
>>> Many thanks for your responses. The eval.with.details package sounds
>>> interesting and I'll certainly take a closer look, but it still seems
>>> to me that these approaches are focussed on trapping warnings within
>>> specific snippets of code rather than changing the way all warnings
>>> (including those in standard packages) are reported.
>>>
>>> This ability would surely be useful anytime that you wish to change
>>> the reporting of warnings from the default. Say, for example, that you
>>> wanted to include a timestamp with each warning message. You'd do it,
>>> I would expect, by writing a function that checks the time and formats
>>> the message appropriately. This is the kind of thing I'm after -- I
>>> hope this clarifies things a bit more.
>>>
>>> The warn.expression option *appears* to provide a way to do what I
>>> want, but because the warning is not passed to the expression (or so
>>> it seems), and last.warning is not set before the expression is
>>> evaluated, the expression can only know that *some* warning condition
>>> has been raised, not *which* one. Perhaps there is a reason that
>>> last.warning cannot be set first (?), but this limits the usefulness
>>> of the option.
>>>
>>> Jon
>>>
>>> 2009/2/4 hadley wickham <h.wickham at gmail.com>:
>>>> Hi Jon,
>>>>
>>>> I have an in-development package that attempts to do this.  It's
>>>> called eval.with.details and is available from
>>>> http://github.com/hadley/eval.with.details.  As you might
>>> guess, it's
>>>> a version of eval that captures all details like messages, warnings,
>>>> errors and output so you can do whatever you want with them.  It
>>>> captures them in the way Jeff Horner describes - but there are a lot
>>>> of fiddly details to get right.
>>>>
>>>> Unfortunately there isn't any documentation yet, but the majority of
>>>> what you're interested in is present in eval.r.  The code has been
>>>> fairly well tested - I'm using it in my own implementation
>>> of a sweave
>>>> like system.
>>>>
>>>> Hadley
>>>>
>>>> On Wed, Feb 4, 2009 at 6:59 AM, Jon Clayden
>>> <j.clayden at ucl.ac.uk> wrote:
>>>>> Dear all,
>>>>>
>>>>> For an open-source project that I'm working on (1), which
>>> uses R for all its
>>>>> heavy lifting but includes a wrapper shell script, I was
>>> hoping to find a
>>>>> way to capture all warnings (and, in fact, errors too),
>>> and handle them in
>>>>> my own way. I realise I can do this for a single
>>> expression using something
>>>>> like:
>>>>>
>>>>>> f <- function(w) print(w$message)
>>>>>> withCallingHandlers(warning("Test"),warning=f)
>>>>> [1] "Test"
>>>>> Warning message:
>>>>> In withCallingHandlers(warning("Test"), warning = f) : Test
>>>>>
>>>>> But I would like to capture all warnings, globally. The
>>> "warning.expression"
>>>>> option doesn't seem to allow an argument, and I can't seem to use
>>>>> "last.warning" to get at the message either:
>>>>>
>>>>>> g <- function() print(last.warning$message)
>>>>>> options(warning.expression=quote(g()))
>>>>>> warning("Test2")
>>>>> NULL
>>>>>
>>>>> Could anyone tell me whether there's a way to do this,
>>> please? An old thread
>>>>> on this topic seemed to go unresolved (2), and I've
>>> skimmed RNEWS and I
>>>>> don't see anything about this since then.
>>>>>
>>>>>> sessionInfo()
>>>>> R version 2.8.1 (2008-12-22)
>>>>> i386-apple-darwin8.11.1
>>>>>
>>>>> locale:
>>>>> en_GB.UTF-8/en_US.UTF-8/C/C/en_GB.UTF-8/en_GB.UTF-8
>>>>>
>>>>> attached base packages:
>>>>> [1] stats     graphics  grDevices utils     datasets
>>> splines   methods
>>>>> [8] base
>>>>>
>>>>> other attached packages:
>>>>> [1] tractor.session_1.0.0   tractor.base_1.0.3
>>> tractor.nt_1.0.2
>>>>>
>>>>> loaded via a namespace (and not attached):
>>>>> [1] tools_2.8.1
>>>>>
>>>>> Regards,
>>>>> Jon
>>>>>
>>>>>
>>>>> (1) http://code.google.com/p/tractor/
>>>>> (2) http://finzi.psych.upenn.edu/R/Rhelp02/archive/61872.html
>>>>>
>>>>>
>>>>> -- 
>>>>> Jonathan D. Clayden, Ph.D.
>>>>> Research Fellow
>>>>> Radiology and Physics Unit
>>>>> UCL Institute of Child Health
>>>>> 30 Guilford Street
>>>>> LONDON  WC1N 1EH
>>>>> United Kingdom
>>>>>
>>>>> t | +44 (0)20 7905 2708
>>>>> f | +44 (0)20 7905 2358
>>>>> w | www.homepages.ucl.ac.uk/~sejjjd2/
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>>
>>>>
>>>>
>>>> -- 
>>>> http://had.co.nz/
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From simon.urbanek at r-project.org  Thu Feb  5 16:00:59 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 5 Feb 2009 10:00:59 -0500
Subject: [Rd] JGR extension not working (PR#13501)
In-Reply-To: <20090205081506.2FF3F284A70C@mail.pubhealth.ku.dk>
References: <20090205081506.2FF3F284A70C@mail.pubhealth.ku.dk>
Message-ID: <BE3404C3-7C23-460A-AA0C-BFC30F1E36E9@r-project.org>

Erik,

fist, this is not a bug in R (not a bug at all, really), so we  
specifically ask you to not waste other people's time and report it to  
the maintainers. It is about a contributed package and there is a  
mailing list specifically for JGR
http://mailman.rz.uni-augsburg.de/mailman/listinfo/stats-rosuda-devel
In addition, you are apparently using a custom-built R so you are  
expected to know what you're doing. If you had used the R binary from  
CRAN all would work. If you insist on compiling it from sources you  
have to set NOAWT=1 and install latest iplots in order to prevent AWT  
from starting since it's not supported on Mac OS X 10.5 inside single- 
threaded applications (such as R).

Cheers,
Simon


On Feb 5, 2009, at 3:15 , erikl at phonetik.uni-muenchen.de wrote:

> Full_Name: Erik Lukac
> Version: R version 2.8.1 (2008-12-22)
> OS: Mac OS 10.5
> Submission from: (NULL) (141.84.28.167)
>
>
> I tried to install JGR, but somehow it doesnt work.
>
>
>> install.packages("JGR")
> Warning in install.packages("JGR") :
>  argument 'lib' is missing: using
> '/Users/erikl/R/i386-apple-darwin9.6.0-library/2.8'
> trying URL 'http://cran.rakanu.com/src/contrib/JGR_1.6-2.tar.gz'
> Content type 'application/x-gzip' length 428978 bytes (418 Kb)
> opened URL
> ==================================================
> downloaded 418 Kb
>
> * Installing *source* package 'JGR' ...
> ** R
> ** inst
> ** preparing package for lazy loading
> Loading required package: rJava
> Loading required package: JavaGD
> Loading required package: iplots
> Note: On Mac OS X we strongly recommend using iplots from within JGR.
> Proceed at your own risk as iplots cannot resolve potential ev.loop  
> deadlocks.
> 'Yes' is assumed for all dialogs as they cannot be shown without a  
> deadlock,
> also ievent.wait() is disabled.
> 2009-02-05 09:04:31.028 R[6886:613] Apple AWT Java VM was loaded on  
> first thread
> -- can't start AWT.
> Warning in .jnew("org/rosuda/iplots/Framework") :
>  NewObject("org/rosuda/iplots/Framework","()V",...) failed
> Exception in thread "main" java.lang.InternalError: Can't start the  
> AWT because
> Java was started on the first thread.  Make sure StartOnFirstThread  
> is not
> specified in your application's Info.plist or on the command line
> 	at java.lang.ClassLoader$NativeLibrary.load(Native Method)
> 	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1822)
> 	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1723)
> 	at java.lang.Runtime.loadLibrary0(Runtime.java:822)
> 	at java.lang.System.loadLibrary(System.java:993)
> 	at sun.security.action.LoadLibraryAction.run(LoadLibraryAction.java: 
> 50)
> 	at java.security.AccessController.doPrivileged(Native Method)
> 	at java.awt.Toolkit.loadLibraries(Toolkit.java:1509)
> 	at java.awt.Toolkit.<clinit>(Toolkit.java:1530)
> 	at java.awt.Color.<clinit>(Color.java:250)
> 	at org.rosuda.ibase.Common.<clinit>(Common.java:47)
> 	at org.rosuda.iplots.Framework.<init>(Framework.java:43)
> Error in .jnew("org/rosuda/iplots/Framework") :
>  Failed to create object of class `org/rosuda/iplots/Framework'
> Error: package 'iplots' could not be loaded
> Execution halted
> ERROR: lazy loading failed for package 'JGR'
> ** Removing '/Users/erikl/R/i386-apple-darwin9.6.0-library/2.8/JGR'
>
> The downloaded packages are in
> 	/private/var/folders/Vg/Vgf6mZdSH8mlJdsK7HKoA++++TI/-Tmp-/ 
> RtmpgsoIqo/downloaded_packages
> Warning message:
> In install.packages("JGR") :
>  installation of package 'JGR' had non-zero exit status
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From Greg.Snow at imail.org  Thu Feb  5 17:15:23 2009
From: Greg.Snow at imail.org (Greg Snow)
Date: Thu, 5 Feb 2009 09:15:23 -0700
Subject: [Rd] [R] Is abline misbehaving?
In-Reply-To: <alpine.LFD.2.00.0902051333040.25207@gannet.stats.ox.ac.uk>
References: <497AE46F.8020704@bitwrit.com.au>
	<B37C0A15B8FB3C468B5BC7EBC7DA14CC61C939D06F@LP-EXMBVS10.CO.IHC.COM>
	<alpine.LFD.2.00.0902051333040.25207@gannet.stats.ox.ac.uk>
Message-ID: <B37C0A15B8FB3C468B5BC7EBC7DA14CC61CA00C973@LP-EXMBVS10.CO.IHC.COM>

Apparently the fix was simpler than I anticipated (at least for Prof. Ripley).

Thanks for finding and implementing this improvement.

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
801.408.8111


> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> Sent: Thursday, February 05, 2009 6:42 AM
> To: Greg Snow
> Cc: Jim Lemon; r-devel at r-project.org
> Subject: Re: [R] Is abline misbehaving?
> 
> [Moved to R-devel, where it probably should have started and it is
> getting to C-level functions now.]
> 
> abline is not 'misbehaving' (don't be rude about the work of
> volunteers who are in your audience), but behaving in the same way as
> other graphics calls.
> 
> The real story is this (and R is Open Source, so you can read the code
> too).
> 
> Most base graphics functions call GClip to set the graphics clip state
> before drawing).  GClip only does anything if the xpd state has
> changed since the last time it was used, and in the case of a plot
> like this with axes which were drawn in the margins, it has done so.
> Now, the tricky bit is 'was used', which can be very hard to
> determine.  Just setting the par is not enough: it has to be 'used'.
> 
> What I have done in R-devel is make clip() 'use' xpd, and that will
> ensure that the clip region it sets persists until xpd is next
> changed.  There the example works as I believe you intended.
> 
> 
> On Sat, 24 Jan 2009, Greg Snow wrote:
> 
> > This is a known issue, the documentation of clip talks about some
> plotting functions resetting the clipping region and some don't.
> abline is apparently one of those that plots first, then resets the
> clipping region (so the first time it doesn't acknowledge it, but does
> afterwards).  The function clipplot in the TeachingDemos package uses a
> similar kludge to what you do below (and I guess that puts my standing
> in the hall of fame at even higher risk than yours) except that it uses
> the box function with a transparent box to reset the clipping region,
> which means that you get strange boxes if your graphics device does not
> handle transparency.  It was a question like yours that I asked in
> order to try to eliminate the kludge from clipplot that originally lead
> to the clip function being added, and it does cover the initial cases
> that I asked about.
> >
> > In order to change things to work like we would like (always
> resetting the clipping region at the appropriate place so that clip
> always does what we expect) will probably require going through every
> basic command that could put something into the plot and figure out
> exactly when to have them reset the clipping region (which may not be a
> simple decision, doing it too early may break existing code).  The
> amount of tedious work required for not much return places this fairly
> low on the priority list, especially when there is a work around (as
> you have found), even if it feels like a bit of a kludge.
> >
> > So while this probably does not fix your problem, at least hopefully
> this helps you understand a bit more of what is happening here, and at
> least you know that you are not alone in hall of kludge infamy.
> >
> > --
> > Gregory (Greg) L. Snow Ph.D.
> > Statistical Data Center
> > Intermountain Healthcare
> > greg.snow at imail.org
> > 801.408.8111
> >
> >
> >> -----Original Message-----
> >> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> >> project.org] On Behalf Of Jim Lemon
> >> Sent: Saturday, January 24, 2009 2:51 AM
> >> To: r-help at r-project.org
> >> Subject: [R] Is abline misbehaving?
> >>
> >> Hi experts,
> >> I was graciously offered a function to enhance abline by restricting
> >> the
> >> extent of the line to less than the plotting region. This seems a
> >> useful
> >> idea, and it looked like the easiest way to program it was to set up
> a
> >> clipping region with "clip", draw the abline and then restore the
> >> previous clipping region. Let us call this function ablineclip.
> After
> >> quite a bit of testing, I have found that the first call to
> ablineclip
> >> ignores the clipping region. It's not that simple. Successive calls
> to
> >> ablineclip respect the clipping region, even if it changes. I can
> >> reproduce the behavior like this:
> >>
> >> plot(-3:3,-3:3)
> >> clip(-2,2,-2,2)
> >> abline(v=0)
> >> clip(-2,2,-2,2)
> >> abline(h=0)
> >>
> >>
> >> The first abline ignores the clip, the second respects it. I have
> >> programmed around this, with the pathetic kludge of calling "abline"
> >> with a line outside the plotting area, calling "clip" a second time,
> >> and
> >> then calling "abline" with the line that was requested. While this
> >> works, my place in programming history will be ineradicably
> compromised
> >> if the Programmers' Hall of Fame ever finds out. Any suggestions?
> >>
> >> R-2.7.2
> >> FC9 Linux
> >>
> >> Jim
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-
> >> guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From khansen at stat.berkeley.edu  Thu Feb  5 17:36:59 2009
From: khansen at stat.berkeley.edu (Kasper Daniel Hansen)
Date: Thu, 5 Feb 2009 08:36:59 -0800
Subject: [Rd] Multiple-Line Comment (PR#13503)
In-Reply-To: <20090205113009.218B42823A68@mail.pubhealth.ku.dk>
References: <20090205113009.218B42823A68@mail.pubhealth.ku.dk>
Message-ID: <5C01B560-1AC2-461F-9551-C85825E8EC9A@stat.berkeley.edu>

(no cc to r-bugs)

One obvious work around is to use an editor that lets you comment/ 
uncomment many lines of code at once. ESS/Emacs for example, has this  
feature. Many other editors do as well. I actually find it easier to  
see what is commented out this way.

Clearly this does not address the question as written though.

Kasper

On Feb 5, 2009, at 3:30 , Udo.Junghans at nw-fva.de wrote:

> Hello,
>
> sorry for writing here because my problem is not a realt bug but may  
> be
> a solution for many people working with R:
>
> I miss the feature for commenting some lines of code at once without
> writing a bunch of "#" in front of each line.
> This is interesting for trying out some code.
> I found some workarounds like
>
> IFELSE(FALSE){} and
>
> `!`<- function(x)
>  {
>    if (inherits(x, "character") == FALSE)
>    .Primitive("!")(x) else invisible(x)
>   }
>
> but IFELSE needs valid code and the '!' <- function breaks when a "  
> ' "
> appears in the comment
>
> so it would be fine to have something like /* ...  */ or so  for
> multiple lines
>
>
> with regards
>
> Udo Junghans
> -- 
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
> ------------------------------------------------------------------------
>
> Udo Junghans
> Abteilung Waldschutz, K?fer und Mittelpr?fung
> Nordwestdeutsche Forstliche Versuchsanstalt
> Gr?tzelstrasse 2
> D-37079 G?ttingen <mailto:udo.junghans at nw-fva.de>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From mxkuhn at gmail.com  Thu Feb  5 20:53:40 2009
From: mxkuhn at gmail.com (Max Kuhn)
Date: Thu, 5 Feb 2009 14:53:40 -0500
Subject: [Rd] no visible binding for global variable
Message-ID: <6731304c0902051153o5a9c064do2aae7eec4e4d46df@mail.gmail.com>

Everyone,

I know that this has been discussed a few times on the list, but I
think that there is a high false positive rate of messages from
findGlobals during R CMD check (I know the help page has that "The
result is an approximation").

Here are two examples of from the caret package:

This function get the message "predictors.gbm: no visible binding for
global variable 'rel.inf'"

predictors.gbm <- function(x, ...)
  {
    library(gbm)
    varList <- if(hasTerms(x)) predictors(x$terms) else colnames(x$data$x.order)
    relImp <- summary(x, plotit = FALSE)
    varUsed <- as.character(subset(relImp, rel.inf != 0)$var)
    basicVars(varList, varUsed)
  }

So it didn't take the context into account that subset isn't
(necessarily) looking in the global environment.

Also, the package has a file splsda.R that has the message
"splsda.default: no visible binding for global variable 'ncomp'". The
oddness of this one is that there is no variable named ncomp
explicitly mentioned in the file (confirmed by grep and I checked that
the function wasn't accidentally defined twice).

In fairness, this function has caught little issues in my code that
could have led to issues, so I'm certainly not implying that it is
ineffective. Looking through the page with package check results,
there are a lot of packages with these types of notes and it makes me
wonder how many of them are real issues. Of course they are only
notes, but the extra verboseness might make people not pay as much
attention when a big issues arises.

Thanks

Max


> sessionInfo()
R version 2.9.0 Under development (unstable) (2009-01-22 r47686)
i386-apple-darwin9.6.0

locale:
en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] codetools_0.2-1


From Ted.Harding at manchester.ac.uk  Thu Feb  5 21:48:33 2009
From: Ted.Harding at manchester.ac.uk ( (Ted Harding))
Date: Thu, 05 Feb 2009 20:48:33 -0000 (GMT)
Subject: [Rd] "open-ended" plot limits?
Message-ID: <XFMail.090205204833.Ted.Harding@manchester.ac.uk>

Hi Folks,
Maybe I've missed it already being available somehow,
but if the following isn't available I'd like to suggest it.

If you're happy to let plot() choose its own limits,
then of course plot(x,y) will do it.

If you know what limits you want, then
  plot(x,y,xlim=c(x0,x1),ylim(y0,y1)
will do it.

But sometimes one would like to
a) make sure that (e.g.) the y-axis has a lower limit (say) 0
b) let plot() choose the upper limit.

In that case, something like

  plot(x,y,ylim=c(0,NA))

would be a natural way of specifying it. But of course that
does not work.

I would like to suggest that this possibility should be available.
What do people think?

Best wishes,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 05-Feb-09                                       Time: 20:48:30
------------------------------ XFMail ------------------------------


From marc_schwartz at comcast.net  Thu Feb  5 21:56:42 2009
From: marc_schwartz at comcast.net (Marc Schwartz)
Date: Thu, 05 Feb 2009 14:56:42 -0600
Subject: [Rd] "open-ended" plot limits?
In-Reply-To: <XFMail.090205204833.Ted.Harding@manchester.ac.uk>
References: <XFMail.090205204833.Ted.Harding@manchester.ac.uk>
Message-ID: <498B528A.6080105@comcast.net>

on 02/05/2009 02:48 PM (Ted Harding) wrote:
> Hi Folks,
> Maybe I've missed it already being available somehow,
> but if the following isn't available I'd like to suggest it.
> 
> If you're happy to let plot() choose its own limits,
> then of course plot(x,y) will do it.
> 
> If you know what limits you want, then
>   plot(x,y,xlim=c(x0,x1),ylim(y0,y1)
> will do it.
> 
> But sometimes one would like to
> a) make sure that (e.g.) the y-axis has a lower limit (say) 0
> b) let plot() choose the upper limit.
> 
> In that case, something like
> 
>   plot(x,y,ylim=c(0,NA))
> 
> would be a natural way of specifying it. But of course that
> does not work.
> 
> I would like to suggest that this possibility should be available.
> What do people think?
> 
> Best wishes,
> Ted.

Ted,

Unless I am mistaken in what you are looking for:

  plot(x, y, ylim = c(0, max(y)))

would seem do what you want. If otherwise unspecified, plot() uses
range(y) to define 'ylim'.

HTH,

Marc Schwartz


From murdoch at stats.uwo.ca  Thu Feb  5 22:00:16 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 05 Feb 2009 16:00:16 -0500
Subject: [Rd] "open-ended" plot limits?
In-Reply-To: <XFMail.090205204833.Ted.Harding@manchester.ac.uk>
References: <XFMail.090205204833.Ted.Harding@manchester.ac.uk>
Message-ID: <498B5360.4030303@stats.uwo.ca>

On 2/5/2009 3:48 PM, (Ted Harding) wrote:
> Hi Folks,
> Maybe I've missed it already being available somehow,
> but if the following isn't available I'd like to suggest it.
> 
> If you're happy to let plot() choose its own limits,
> then of course plot(x,y) will do it.
> 
> If you know what limits you want, then
>   plot(x,y,xlim=c(x0,x1),ylim(y0,y1)
> will do it.
> 
> But sometimes one would like to
> a) make sure that (e.g.) the y-axis has a lower limit (say) 0
> b) let plot() choose the upper limit.
> 
> In that case, something like
> 
>   plot(x,y,ylim=c(0,NA))
> 
> would be a natural way of specifying it. But of course that
> does not work.
> 
> I would like to suggest that this possibility should be available.
> What do people think?

I'd rather not assume NA is intentional since there are so many 
unintentional ways to generate it. Marc told you the simple workaround 
to get the effect you want.

Duncan Murdoch

> 
> Best wishes,
> Ted.
> 
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
> Fax-to-email: +44 (0)870 094 0861
> Date: 05-Feb-09                                       Time: 20:48:30
> ------------------------------ XFMail ------------------------------
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Greg.Snow at imail.org  Thu Feb  5 22:15:28 2009
From: Greg.Snow at imail.org (Greg Snow)
Date: Thu, 5 Feb 2009 14:15:28 -0700
Subject: [Rd] "open-ended" plot limits?
In-Reply-To: <498B528A.6080105@comcast.net>
References: <XFMail.090205204833.Ted.Harding@manchester.ac.uk>
	<498B528A.6080105@comcast.net>
Message-ID: <B37C0A15B8FB3C468B5BC7EBC7DA14CC61CA00CBC1@LP-EXMBVS10.CO.IHC.COM>

I use range( 0, y ) rather than c(0, max(y)), that way if there are any y values less than 0, the limits still include them (and it is slightly shorter :-).

This also extends to cases where you may know that you will be adding additional data using points or lines, so you can do ylim=range(0, y1, y2, y3) and it will give enough room to add the other y variables in latter.

Hope this helps, 

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
801.408.8111


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
> project.org] On Behalf Of Marc Schwartz
> Sent: Thursday, February 05, 2009 1:57 PM
> To: ted.harding at manchester.ac.uk
> Cc: R-Devel
> Subject: Re: [Rd] "open-ended" plot limits?
> 
> on 02/05/2009 02:48 PM (Ted Harding) wrote:
> > Hi Folks,
> > Maybe I've missed it already being available somehow,
> > but if the following isn't available I'd like to suggest it.
> >
> > If you're happy to let plot() choose its own limits,
> > then of course plot(x,y) will do it.
> >
> > If you know what limits you want, then
> >   plot(x,y,xlim=c(x0,x1),ylim(y0,y1)
> > will do it.
> >
> > But sometimes one would like to
> > a) make sure that (e.g.) the y-axis has a lower limit (say) 0
> > b) let plot() choose the upper limit.
> >
> > In that case, something like
> >
> >   plot(x,y,ylim=c(0,NA))
> >
> > would be a natural way of specifying it. But of course that
> > does not work.
> >
> > I would like to suggest that this possibility should be available.
> > What do people think?
> >
> > Best wishes,
> > Ted.
> 
> Ted,
> 
> Unless I am mistaken in what you are looking for:
> 
>   plot(x, y, ylim = c(0, max(y)))
> 
> would seem do what you want. If otherwise unspecified, plot() uses
> range(y) to define 'ylim'.
> 
> HTH,
> 
> Marc Schwartz
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From wdunlap at tibco.com  Thu Feb  5 22:38:01 2009
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 5 Feb 2009 13:38:01 -0800
Subject: [Rd] "open-ended" plot limits?
In-Reply-To: <B37C0A15B8FB3C468B5BC7EBC7DA14CC61CA00CBC1@LP-EXMBVS10.CO.IHC.COM>
References: <XFMail.090205204833.Ted.Harding@manchester.ac.uk><498B528A.6080105@comcast.net>
	<B37C0A15B8FB3C468B5BC7EBC7DA14CC61CA00CBC1@LP-EXMBVS10.CO.IHC.COM>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D700A87805@NA-PA-VBE03.na.tibco.com>


> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Greg Snow
> Sent: Thursday, February 05, 2009 1:15 PM
> To: marc_schwartz at comcast.net; ted.harding at manchester.ac.uk
> Cc: R-Devel
> Subject: Re: [Rd] "open-ended" plot limits?
> 
> I use range( 0, y ) rather than c(0, max(y)), that way if 
> there are any y values less than 0, the limits still include 
> them (and it is slightly shorter :-).

To mimic what plot does by default you must ignore the NA's
and Inf's in y with something like
   range(0,y[is.finite(y)])
It might be nice to have an na.rm-like argument for ignoring
the Inf's - it gets tedious to write
   range(0, y1[!is.finite(y1)], y2[!is.finite(y2)], ...)
Also, when you get into really long vectors the explicit subscripting
can run you out of memory.

Bill Dunlap
TIBCO Software Inc - Spotfire Division
wdunlap tibco.com

> 
> This also extends to cases where you may know that you will 
> be adding additional data using points or lines, so you can 
> do ylim=range(0, y1, y2, y3) and it will give enough room to 
> add the other y variables in latter.
> 
> Hope this helps, 
> 
> -- 
> Gregory (Greg) L. Snow Ph.D.
> Statistical Data Center
> Intermountain Healthcare
> greg.snow at imail.org
> 801.408.8111
> 
> 
> > -----Original Message-----
> > From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
> > project.org] On Behalf Of Marc Schwartz
> > Sent: Thursday, February 05, 2009 1:57 PM
> > To: ted.harding at manchester.ac.uk
> > Cc: R-Devel
> > Subject: Re: [Rd] "open-ended" plot limits?
> > 
> > on 02/05/2009 02:48 PM (Ted Harding) wrote:
> > > Hi Folks,
> > > Maybe I've missed it already being available somehow,
> > > but if the following isn't available I'd like to suggest it.
> > >
> > > If you're happy to let plot() choose its own limits,
> > > then of course plot(x,y) will do it.
> > >
> > > If you know what limits you want, then
> > >   plot(x,y,xlim=c(x0,x1),ylim(y0,y1)
> > > will do it.
> > >
> > > But sometimes one would like to
> > > a) make sure that (e.g.) the y-axis has a lower limit (say) 0
> > > b) let plot() choose the upper limit.
> > >
> > > In that case, something like
> > >
> > >   plot(x,y,ylim=c(0,NA))
> > >
> > > would be a natural way of specifying it. But of course that
> > > does not work.
> > >
> > > I would like to suggest that this possibility should be available.
> > > What do people think?
> > >
> > > Best wishes,
> > > Ted.
> > 
> > Ted,
> > 
> > Unless I am mistaken in what you are looking for:
> > 
> >   plot(x, y, ylim = c(0, max(y)))
> > 
> > would seem do what you want. If otherwise unspecified, plot() uses
> > range(y) to define 'ylim'.
> > 
> > HTH,
> > 
> > Marc Schwartz
> > 
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From Greg.Snow at imail.org  Thu Feb  5 22:40:28 2009
From: Greg.Snow at imail.org (Greg Snow)
Date: Thu, 5 Feb 2009 14:40:28 -0700
Subject: [Rd] "open-ended" plot limits?
In-Reply-To: <77EB52C6DD32BA4D87471DCD70C8D700A87805@NA-PA-VBE03.na.tibco.com>
References: <XFMail.090205204833.Ted.Harding@manchester.ac.uk><498B528A.6080105@comcast.net>
	<B37C0A15B8FB3C468B5BC7EBC7DA14CC61CA00CBC1@LP-EXMBVS10.CO.IHC.COM>
	<77EB52C6DD32BA4D87471DCD70C8D700A87805@NA-PA-VBE03.na.tibco.com>
Message-ID: <B37C0A15B8FB3C468B5BC7EBC7DA14CC61CA00CBE5@LP-EXMBVS10.CO.IHC.COM>

Or use range( 0, y1, y2, y3, na.rm=TRUE, finite=TRUE )

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
801.408.8111


> -----Original Message-----
> From: William Dunlap [mailto:wdunlap at tibco.com]
> Sent: Thursday, February 05, 2009 2:38 PM
> To: Greg Snow; marc_schwartz at comcast.net; ted.harding at manchester.ac.uk
> Cc: R-Devel
> Subject: RE: [Rd] "open-ended" plot limits?
> 
> 
> > -----Original Message-----
> > From: r-devel-bounces at r-project.org
> > [mailto:r-devel-bounces at r-project.org] On Behalf Of Greg Snow
> > Sent: Thursday, February 05, 2009 1:15 PM
> > To: marc_schwartz at comcast.net; ted.harding at manchester.ac.uk
> > Cc: R-Devel
> > Subject: Re: [Rd] "open-ended" plot limits?
> >
> > I use range( 0, y ) rather than c(0, max(y)), that way if
> > there are any y values less than 0, the limits still include
> > them (and it is slightly shorter :-).
> 
> To mimic what plot does by default you must ignore the NA's
> and Inf's in y with something like
>    range(0,y[is.finite(y)])
> It might be nice to have an na.rm-like argument for ignoring
> the Inf's - it gets tedious to write
>    range(0, y1[!is.finite(y1)], y2[!is.finite(y2)], ...)
> Also, when you get into really long vectors the explicit subscripting
> can run you out of memory.
> 
> Bill Dunlap
> TIBCO Software Inc - Spotfire Division
> wdunlap tibco.com
> 
> >
> > This also extends to cases where you may know that you will
> > be adding additional data using points or lines, so you can
> > do ylim=range(0, y1, y2, y3) and it will give enough room to
> > add the other y variables in latter.
> >
> > Hope this helps,
> >
> > --
> > Gregory (Greg) L. Snow Ph.D.
> > Statistical Data Center
> > Intermountain Healthcare
> > greg.snow at imail.org
> > 801.408.8111
> >
> >
> > > -----Original Message-----
> > > From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
> > > project.org] On Behalf Of Marc Schwartz
> > > Sent: Thursday, February 05, 2009 1:57 PM
> > > To: ted.harding at manchester.ac.uk
> > > Cc: R-Devel
> > > Subject: Re: [Rd] "open-ended" plot limits?
> > >
> > > on 02/05/2009 02:48 PM (Ted Harding) wrote:
> > > > Hi Folks,
> > > > Maybe I've missed it already being available somehow,
> > > > but if the following isn't available I'd like to suggest it.
> > > >
> > > > If you're happy to let plot() choose its own limits,
> > > > then of course plot(x,y) will do it.
> > > >
> > > > If you know what limits you want, then
> > > >   plot(x,y,xlim=c(x0,x1),ylim(y0,y1)
> > > > will do it.
> > > >
> > > > But sometimes one would like to
> > > > a) make sure that (e.g.) the y-axis has a lower limit (say) 0
> > > > b) let plot() choose the upper limit.
> > > >
> > > > In that case, something like
> > > >
> > > >   plot(x,y,ylim=c(0,NA))
> > > >
> > > > would be a natural way of specifying it. But of course that
> > > > does not work.
> > > >
> > > > I would like to suggest that this possibility should be
> available.
> > > > What do people think?
> > > >
> > > > Best wishes,
> > > > Ted.
> > >
> > > Ted,
> > >
> > > Unless I am mistaken in what you are looking for:
> > >
> > >   plot(x, y, ylim = c(0, max(y)))
> > >
> > > would seem do what you want. If otherwise unspecified, plot() uses
> > > range(y) to define 'ylim'.
> > >
> > > HTH,
> > >
> > > Marc Schwartz
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >


From Ted.Harding at manchester.ac.uk  Fri Feb  6 01:21:48 2009
From: Ted.Harding at manchester.ac.uk ( (Ted Harding))
Date: Fri, 06 Feb 2009 00:21:48 -0000 (GMT)
Subject: [Rd] "open-ended" plot limits?
In-Reply-To: <XFMail.090205204833.Ted.Harding@manchester.ac.uk>
Message-ID: <XFMail.090205230835.Ted.Harding@manchester.ac.uk>

Thanks, everyone, for all the responses!
Ted.

On 05-Feb-09 20:48:33, Ted Harding wrote:
> Hi Folks,
> Maybe I've missed it already being available somehow,
> but if the following isn't available I'd like to suggest it.
> 
> If you're happy to let plot() choose its own limits,
> then of course plot(x,y) will do it.
> 
> If you know what limits you want, then
>   plot(x,y,xlim=c(x0,x1),ylim(y0,y1)
> will do it.
> 
> But sometimes one would like to
> a) make sure that (e.g.) the y-axis has a lower limit (say) 0
> b) let plot() choose the upper limit.
> 
> In that case, something like
> 
>   plot(x,y,ylim=c(0,NA))
> 
> would be a natural way of specifying it. But of course that
> does not work.
> 
> I would like to suggest that this possibility should be available.
> What do people think?
> 
> Best wishes,
> Ted.
> 
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
> Fax-to-email: +44 (0)870 094 0861
> Date: 05-Feb-09                                       Time: 20:48:30
> ------------------------------ XFMail ------------------------------
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 05-Feb-09                                       Time: 23:08:25
------------------------------ XFMail ------------------------------

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 06-Feb-09                                       Time: 00:21:44
------------------------------ XFMail ------------------------------


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Fri Feb  6 11:44:40 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Fri, 06 Feb 2009 11:44:40 +0100
Subject: [Rd] Bug in the parser (?) (PR#13504)
In-Reply-To: <498AF44D.6080805@biostat.ku.dk>
References: <20090205131004.AE42C283415C@mail.pubhealth.ku.dk>
	<498AF44D.6080805@biostat.ku.dk>
Message-ID: <498C1498.6050305@idi.ntnu.no>

Peter Dalgaard wrote:
> johnc.deva at yahoo.com wrote:
>   
>> Full_Name: John C. Deva
>> Version: 2.8.1
>> OS: Fedora Linux 8, 64 bit
>> Submission from: (NULL) (193.200.150.189)
>>
>>
>> I notice that it is possible to redefine 'if' as a function of an arbitrary
>> number of arguments.  Such redefined 'if' can then be used as any other user
>> function, except for that the parser still demands exactly three arguments to be
>> given to if.  Furthermore, even if 'if' is defined with three arguments, its
>> application must still be made with the original syntax, and not the usual
>> syntax of function application:
>>
>>     
>>> `if` <- function(a,b,c) 
>>>       
>> + {
>> + assign(deparse(substitute(a)), b+c, envir=parent.frame()
>> + }
>>
>>     
>>> if (x) 1 else 2
>>> x
>>>       
>> [1] 3
>>
>>     
>>> if(x, 1, 2)
>>>       
>> Error: unexpected ',' in "if(x,"
>>
>> The later expression above should be the only valid when 'if' is redefined as
>> above, but it is not the case.
>>     
>
>
> A bug report with a ? in the title is in general ill-advised. If you are
> not sure that something is a bug, then ask a question instead.
>
> In this case, no, it is not a bug. Syntax is syntax and "if(x,1,2)" is a
> syntax error no matter how if() is defined. Parsing is controlled by the
> fact that "if" is a keyword, the function definition is not used at all
> at that stage. `if`(x,1,2) works perfectly well, though, at least until
> you try deparsing it:
>
>   
>> quote(`if`(x,1,2))
>>     
> if (x) 1 else 2
>
>
> Redefining "if" is a really Bad Idea, excepting things like code
> analysis tools (which I believe are the main reason it is not explicitly
> forbidden).
>
>   

i'm not quite sure i'm getting this last point (after that redefining
'if' is a bad idea, which it is, mostly).

on further exploration, i found that r can be used to produce fancy
patterns:

'function' = function(...) { print(list(...)); function(...) list(...) }
# a function that prints its arguments and calls itself with the
arguments and a list of the arguments

# maximize the terminal, minimize the font size, and execute:
function(whatever) NULL

enjoy.

vQ


From nashjc at uottawa.ca  Fri Feb  6 23:25:10 2009
From: nashjc at uottawa.ca (nashjc at uottawa.ca)
Date: Fri, 6 Feb 2009 17:25:10 -0500 (EST)
Subject: [Rd] Use of cfortran.h?
Message-ID: <46869.97.124.28.229.1233959110.squirrel@webmail02.uottawa.ca>

I'm planning to try to use Mike Powell's new BOBYQA optimization routine
to see if it is a good candidate to eventually replace Nelder-Mead as the
optim() default. (Don't panic -- this won't happen quickly.) Mike writes
f77 code. After some chasing about, I've realized that because
optimization codes need to call the objective function written in R, they
need to use a language that can do this. C can, Fortran cannot.

There is, however, a package cfortran that allows for mixed coding in C
and Fortran. This might not be the ultimate solution -- e.g., it may not
be Windows usable. However, it could be a useful tool to try out some
programs that are already available in Fortran.

My query is to ask if anyone has experience they can share in using
cfortran.h. I'd also welcome (off-list may be best) input on directions
for improving or at least tidying optim() and many related capabilities in
R.

John Nash


From ripley at stats.ox.ac.uk  Fri Feb  6 23:45:34 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 6 Feb 2009 22:45:34 +0000 (GMT)
Subject: [Rd] Use of cfortran.h?
In-Reply-To: <46869.97.124.28.229.1233959110.squirrel@webmail02.uottawa.ca>
References: <46869.97.124.28.229.1233959110.squirrel@webmail02.uottawa.ca>
Message-ID: <alpine.LFD.2.00.0902062234230.7397@gannet.stats.ox.ac.uk>

All you need to do is to write a fortran-callable wrapper for a C 
interface: there are F77_* macros to allow this.  They do not work on 
every possible platform, but they work on the platforms R runs on 
(since building R relies on them).

E.g. intpr (a call to R's print routines from Fortran) provides a good 
prototype.  It is in src/main/xxxpr.f an print.c (it would be simpler 
if Fortran character types were not involved).

I don't suppose you are comtemplating complex variables, but if you 
were, a great deal of care is needed in the C/Fortran interfaces.

On Fri, 6 Feb 2009, nashjc at uottawa.ca wrote:

> I'm planning to try to use Mike Powell's new BOBYQA optimization routine
> to see if it is a good candidate to eventually replace Nelder-Mead as the
> optim() default. (Don't panic -- this won't happen quickly.) Mike writes
> f77 code. After some chasing about, I've realized that because
> optimization codes need to call the objective function written in R, they
> need to use a language that can do this. C can, Fortran cannot.
>
> There is, however, a package cfortran that allows for mixed coding in C
> and Fortran. This might not be the ultimate solution -- e.g., it may not
> be Windows usable. However, it could be a useful tool to try out some
> programs that are already available in Fortran.
>
> My query is to ask if anyone has experience they can share in using
> cfortran.h. I'd also welcome (off-list may be best) input on directions
> for improving or at least tidying optim() and many related capabilities in
> R.
>
> John Nash
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Sat Feb  7 08:22:49 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 7 Feb 2009 07:22:49 +0000 (GMT)
Subject: [Rd] New package test results available
Message-ID: <alpine.LFD.2.00.0902070651160.18308@gannet.stats.ox.ac.uk>

We've added a column at

http://cran.r-project.org/web/checks/check_summary.html

of test results using the Sun Studio compiler: it is intended that 
these will be updated weekly.

The Sun Studio compiler is that used on Solaris: these runs were on 
the Linux version.  All the other platforms are using gcc 4, so this 
provides an opportunity for checking for use of gcc-specific features 
and also standards conformance (the Sun compilers have a long-time 
reputation for close conformance to the language standards).

There are known problems where packages use C++ or JNI interfaces 
(e.g. rgdal and EBImage) as the libraries and JVM were compiled under 
gcc's conventions (even though a Sun JVMi is used).  About half the 
packages using rJava segfault, which seems to a JNI issue.

Some packages use gcc-specific compiler flags:

   LogConcDEAD Matching amap geometry memisc taskPR

but the vast majority of the errors reported are C++ errors.  One 
class that may not be immediately obvious is the use of C headers in 
C++: you are supposed to write e.g.

#includd <cmath>

NOT

#include <math.h>

Symptoms of this can be seen for packages

   BayesTree EMCC MCMCfglmm MarkedPointProcess Matching Matrix
   RQuantlib RandomFields Rcpp SoPhy compHclust dpmix igraph minet
   mixer modeest monomvm multic pcaPP rgenoud robfilter segclust
   simecol subselect


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From zac at zjbnewton.demon.co.uk  Sat Feb  7 17:05:05 2009
From: zac at zjbnewton.demon.co.uk (zac at zjbnewton.demon.co.uk)
Date: Sat,  7 Feb 2009 17:05:05 +0100 (CET)
Subject: [Rd] reading SPSS .sav files (PR#13509)
Message-ID: <20090207160505.48F55283416A@mail.pubhealth.ku.dk>

Full_Name: Roger Newton
Version: 2.8.1
OS: windows 2000
Submission from: (NULL) (80.176.228.157)


I have an elderly version of SPSS (version 11) which I still use. R Version
2.6.1 would, and still will, read SPSS *.sav files produced by SPSS version 11.
R version 2.8.1 which I installed two days ago (05/02/09) reports an error and
shuts down when trying to read SPSS version 11 *.sav files using the read.spss
function in package foreign.

R version 2.8.1 will read *.sav files produced by SPSS version 13.

The problem applies to all the existing SPSS files I had before I downloaded R
2.8.1
and to several new SPSS 11 *.sav files I have produced since.


From kevin.hendricks at sympatico.ca  Sat Feb  7 17:39:13 2009
From: kevin.hendricks at sympatico.ca (Kevin Hendricks)
Date: Sat, 7 Feb 2009 11:39:13 -0500
Subject: [Rd] New package test results available
In-Reply-To: <alpine.LFD.2.00.0902070651160.18308@gannet.stats.ox.ac.uk>
References: <alpine.LFD.2.00.0902070651160.18308@gannet.stats.ox.ac.uk>
Message-ID: <BLU0-SMTP70397028D27AEF8F15281787BE0@phx.gbl>

Hi,

I am the maintainer for the Rigroup package.  Based on the e-mail  
below, I found and fixed a warning (spurious right brace) in the  
manual for my package under the new parser.

It has been a number of years since I last revised the package and I  
am not sure where and how to upload it.  I looked on the "developer"  
page but did not see anything that said where to upload revised  
packages.

Sorry for the inconvenience but could someone please direct me to  
where I find the instructions for uploading revised packages.

Thank you.

Kevin



On 7-Feb-09, at 2:22 AM, Prof Brian Ripley wrote:

> We've added a column at
>
> http://cran.r-project.org/web/checks/check_summary.html
>
> of test results using the Sun Studio compiler: it is intended that  
> these will be updated weekly.
>
> The Sun Studio compiler is that used on Solaris: these runs were on  
> the Linux version.  All the other platforms are using gcc 4, so this  
> provides an opportunity for checking for use of gcc-specific  
> features and also standards conformance (the Sun compilers have a  
> long-time reputation for close conformance to the language standards).
>
> There are known problems where packages use C++ or JNI interfaces  
> (e.g. rgdal and EBImage) as the libraries and JVM were compiled  
> under gcc's conventions (even though a Sun JVMi is used).  About  
> half the packages using rJava segfault, which seems to a JNI issue.
>
> Some packages use gcc-specific compiler flags:
>
>  LogConcDEAD Matching amap geometry memisc taskPR
>
> but the vast majority of the errors reported are C++ errors.  One  
> class that may not be immediately obvious is the use of C headers in  
> C++: you are supposed to write e.g.
>
> #includd <cmath>
>
> NOT
>
> #include <math.h>
>
> Symptoms of this can be seen for packages
>
>  BayesTree EMCC MCMCfglmm MarkedPointProcess Matching Matrix
>  RQuantlib RandomFields Rcpp SoPhy compHclust dpmix igraph minet
>  mixer modeest monomvm multic pcaPP rgenoud robfilter segclust
>  simecol subselect
>
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ripley at stats.ox.ac.uk  Sat Feb  7 18:02:58 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 7 Feb 2009 17:02:58 +0000 (GMT)
Subject: [Rd] New package test results available
In-Reply-To: <BLU0-SMTP70397028D27AEF8F15281787BE0@phx.gbl>
References: <alpine.LFD.2.00.0902070651160.18308@gannet.stats.ox.ac.uk>
	<BLU0-SMTP70397028D27AEF8F15281787BE0@phx.gbl>
Message-ID: <alpine.LFD.2.00.0902071700240.17573@gannet.stats.ox.ac.uk>

It's in 'Writing R Extensions':

   When all the testing is done, upload the .tar.gz file, using
   `anonymous' as log-in name and your e-mail address as password, to
   ftp://CRAN.R-project.org/incoming/ (note: use `ftp' and not `sftp'
   to connect to this server) and send a message to CRAN at R-project.org about
   it. The CRAN maintainers will run these tests before putting a
   submission in the main archive.



On Sat, 7 Feb 2009, Kevin Hendricks wrote:

> Hi,
>
> I am the maintainer for the Rigroup package.  Based on the e-mail below, I 
> found and fixed a warning (spurious right brace) in the manual for my package 
> under the new parser.
>
> It has been a number of years since I last revised the package and I am not 
> sure where and how to upload it.  I looked on the "developer" page but did 
> not see anything that said where to upload revised packages.
>
> Sorry for the inconvenience but could someone please direct me to where I 
> find the instructions for uploading revised packages.
>
> Thank you.
>
> Kevin
>
>
>
> On 7-Feb-09, at 2:22 AM, Prof Brian Ripley wrote:
>
>> We've added a column at
>> 
>> http://cran.r-project.org/web/checks/check_summary.html
>> 
>> of test results using the Sun Studio compiler: it is intended that these 
>> will be updated weekly.
>> 
>> The Sun Studio compiler is that used on Solaris: these runs were on the 
>> Linux version.  All the other platforms are using gcc 4, so this provides 
>> an opportunity for checking for use of gcc-specific features and also 
>> standards conformance (the Sun compilers have a long-time reputation for 
>> close conformance to the language standards).
>> 
>> There are known problems where packages use C++ or JNI interfaces (e.g. 
>> rgdal and EBImage) as the libraries and JVM were compiled under gcc's 
>> conventions (even though a Sun JVMi is used).  About half the packages 
>> using rJava segfault, which seems to a JNI issue.
>> 
>> Some packages use gcc-specific compiler flags:
>> 
>> LogConcDEAD Matching amap geometry memisc taskPR
>> 
>> but the vast majority of the errors reported are C++ errors.  One class 
>> that may not be immediately obvious is the use of C headers in C++: you are 
>> supposed to write e.g.
>> 
>> #includd <cmath>
>> 
>> NOT
>> 
>> #include <math.h>
>> 
>> Symptoms of this can be seen for packages
>> 
>> BayesTree EMCC MCMCfglmm MarkedPointProcess Matching Matrix
>> RQuantlib RandomFields Rcpp SoPhy compHclust dpmix igraph minet
>> mixer modeest monomvm multic pcaPP rgenoud robfilter segclust
>> simecol subselect
>> 
>> 
>> -- 
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From kevin.hendricks at sympatico.ca  Sat Feb  7 18:11:04 2009
From: kevin.hendricks at sympatico.ca (Kevin Hendricks)
Date: Sat, 7 Feb 2009 12:11:04 -0500
Subject: [Rd] New package test results available
In-Reply-To: <BLU0-SMTP70397028D27AEF8F15281787BE0@phx.gbl>
References: <alpine.LFD.2.00.0902070651160.18308@gannet.stats.ox.ac.uk>
	<BLU0-SMTP70397028D27AEF8F15281787BE0@phx.gbl>
Message-ID: <BLU0-SMTP87EB1E48100DDE5F755C3B87BE0@phx.gbl>

Hi,

Please ignore this request ..  I found it in the Rext.pdf manual ...   
DUH!

The revised package Rigroup_0.83.0.tar.gz has been uploaded.  It  
passes R CMD check on version R 2.8.0 and hopefully with the new  
parser in the development tree as well.

Sorry for the noise.

Kevin


On 7-Feb-09, at 11:39 AM, Kevin Hendricks wrote:

> Hi,
>
> I am the maintainer for the Rigroup package.  Based on the e-mail  
> below, I found and fixed a warning (spurious right brace) in the  
> manual for my package under the new parser.
>
> It has been a number of years since I last revised the package and I  
> am not sure where and how to upload it.  I looked on the "developer"  
> page but did not see anything that said where to upload revised  
> packages.
>
> Sorry for the inconvenience but could someone please direct me to  
> where I find the instructions for uploading revised packages.
>
> Thank you.
>
> Kevin
>
>
>
> On 7-Feb-09, at 2:22 AM, Prof Brian Ripley wrote:
>
>> We've added a column at
>>
>> http://cran.r-project.org/web/checks/check_summary.html
>>
>> of test results using the Sun Studio compiler: it is intended that  
>> these will be updated weekly.
>>
>> The Sun Studio compiler is that used on Solaris: these runs were on  
>> the Linux version.  All the other platforms are using gcc 4, so  
>> this provides an opportunity for checking for use of gcc-specific  
>> features and also standards conformance (the Sun compilers have a  
>> long-time reputation for close conformance to the language  
>> standards).
>>
>> There are known problems where packages use C++ or JNI interfaces  
>> (e.g. rgdal and EBImage) as the libraries and JVM were compiled  
>> under gcc's conventions (even though a Sun JVMi is used).  About  
>> half the packages using rJava segfault, which seems to a JNI issue.
>>
>> Some packages use gcc-specific compiler flags:
>>
>> LogConcDEAD Matching amap geometry memisc taskPR
>>
>> but the vast majority of the errors reported are C++ errors.  One  
>> class that may not be immediately obvious is the use of C headers  
>> in C++: you are supposed to write e.g.
>>
>> #includd <cmath>
>>
>> NOT
>>
>> #include <math.h>
>>
>> Symptoms of this can be seen for packages
>>
>> BayesTree EMCC MCMCfglmm MarkedPointProcess Matching Matrix
>> RQuantlib RandomFields Rcpp SoPhy compHclust dpmix igraph minet
>> mixer modeest monomvm multic pcaPP rgenoud robfilter segclust
>> simecol subselect
>>
>>
>> -- 
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From Thomas.Petzoldt at TU-Dresden.de  Sat Feb  7 18:30:35 2009
From: Thomas.Petzoldt at TU-Dresden.de (Thomas Petzoldt)
Date: Sat, 07 Feb 2009 18:30:35 +0100
Subject: [Rd] New package test results available
In-Reply-To: <alpine.LFD.2.00.0902070651160.18308@gannet.stats.ox.ac.uk>
References: <alpine.LFD.2.00.0902070651160.18308@gannet.stats.ox.ac.uk>
Message-ID: <498DC53B.9050909@TU-Dresden.de>

Prof Brian Ripley schrieb:
> We've added a column at
> 
> http://cran.r-project.org/web/checks/check_summary.html
> 
> of test results using the Sun Studio compiler: it is intended that these 
> will be updated weekly.
> 
> The Sun Studio compiler is that used on Solaris: these runs were on the 
> Linux version.  All the other platforms are using gcc 4, so this 
> provides an opportunity for checking for use of gcc-specific features 
> and also standards conformance (the Sun compilers have a long-time 
> reputation for close conformance to the language standards).
> 
> There are known problems where packages use C++ or JNI interfaces (e.g. 
> rgdal and EBImage) as the libraries and JVM were compiled under gcc's 
> conventions (even though a Sun JVMi is used).  About half the packages 
> using rJava segfault, which seems to a JNI issue.
> 
> Some packages use gcc-specific compiler flags:
> 
>   LogConcDEAD Matching amap geometry memisc taskPR
> 
> but the vast majority of the errors reported are C++ errors.  One class 
> that may not be immediately obvious is the use of C headers in C++: you 
> are supposed to write e.g.
> 
> #includd <cmath>
> 
> NOT
> 
> #include <math.h>
> 
> Symptoms of this can be seen for packages
> 
>   BayesTree EMCC MCMCfglmm MarkedPointProcess Matching Matrix
>   RQuantlib RandomFields Rcpp SoPhy compHclust dpmix igraph minet
>   mixer modeest monomvm multic pcaPP rgenoud robfilter segclust
>   simecol subselect
> 
> 

The reason can also be including <R.h> (as done in simecol) that 
includes <math.h>

Do I understand it correctly that this means that including <R.h> is 
wrong in C++?
I read "Writing R extensions" several times, but was not aware that this 
was a mistake. If I replace <R.h> by <cmath> then it works on my 
systems, but I want to be certain that there are no other side effects.

Thanks in advance for clarification!

Thomas Petzoldt


-- 
Thomas Petzoldt
Technische Universitaet Dresden
Institut fuer Hydrobiologie        thomas.petzoldt at tu-dresden.de
01062 Dresden                      http://tu-dresden.de/hydrobiologie/
GERMANY


From ripley at stats.ox.ac.uk  Sat Feb  7 19:40:24 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 7 Feb 2009 18:40:24 +0000 (GMT)
Subject: [Rd] New package test results available
In-Reply-To: <498DC53B.9050909@TU-Dresden.de>
References: <alpine.LFD.2.00.0902070651160.18308@gannet.stats.ox.ac.uk>
	<498DC53B.9050909@TU-Dresden.de>
Message-ID: <alpine.LFD.2.00.0902071817300.20320@gannet.stats.ox.ac.uk>

On Sat, 7 Feb 2009, Thomas Petzoldt wrote:

> Prof Brian Ripley schrieb:
>> We've added a column at
>> 
>> http://cran.r-project.org/web/checks/check_summary.html
>> 
>> of test results using the Sun Studio compiler: it is intended that these 
>> will be updated weekly.
>> 
>> The Sun Studio compiler is that used on Solaris: these runs were on the 
>> Linux version.  All the other platforms are using gcc 4, so this provides 
>> an opportunity for checking for use of gcc-specific features and also 
>> standards conformance (the Sun compilers have a long-time reputation for 
>> close conformance to the language standards).
>> 
>> There are known problems where packages use C++ or JNI interfaces (e.g. 
>> rgdal and EBImage) as the libraries and JVM were compiled under gcc's 
>> conventions (even though a Sun JVMi is used).  About half the packages 
>> using rJava segfault, which seems to a JNI issue.
>> 
>> Some packages use gcc-specific compiler flags:
>>
>>   LogConcDEAD Matching amap geometry memisc taskPR
>> 
>> but the vast majority of the errors reported are C++ errors.  One class 
>> that may not be immediately obvious is the use of C headers in C++: you are 
>> supposed to write e.g.
>> 
>> #includd <cmath>
>> 
>> NOT
>> 
>> #include <math.h>
>> 
>> Symptoms of this can be seen for packages
>>
>>   BayesTree EMCC MCMCfglmm MarkedPointProcess Matching Matrix
>>   RQuantlib RandomFields Rcpp SoPhy compHclust dpmix igraph minet
>>   mixer modeest monomvm multic pcaPP rgenoud robfilter segclust
>>   simecol subselect
>
> The reason can also be including <R.h> (as done in simecol) that includes 
> <math.h>

As I said (R.h is a C header).

> Do I understand it correctly that this means that including <R.h> is 
> wrong in C++? I read "Writing R extensions" several times, but was 
> not aware that this was a mistake. If I replace <R.h> by <cmath> 
> then it works on my systems, but I want to be certain that there are 
> no other side effects.

Hmm, I think you missed

   Most @R{} header files can be included within C++ programs, and they
   should @strong{not} be included within an @code{extern "C"} block
   (as they include C++ system headers).  It may not be possible to include
   some @R{} headers as they in turn include C header files that may
   cause conflicts---if this happens, define @samp{NO_C_HEADERS} before
   including the @R{} headers, and include the appropriate headers
   yourself.

Allowing R heeaders to be used in C++ was an afterthought: had it been 
preplanned I expect R.h would have included far fewer C headers.  The 
issues have got worse as C++ has evolved (and diverged from C), and 
until recently g++ has been well behind (g++ 4.3.x was a large step 
forward towards C++ standards conformance).

Including unneeded headers often comes back to bite you (another area 
is where the contents are controlled by macros such as __GNU_SOURCE__ 
and so order matters).

We did at one time experiment with R.h using cmath not math.h if 
included into C++, but that too was not 100% portable.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rhurlin at gwdg.de  Sun Feb  8 22:32:18 2009
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Sun, 08 Feb 2009 22:32:18 +0100
Subject: [Rd] Small typo in error message of R-devel
Message-ID: <498F4F62.5010100@gwdg.de>

Trying out some encodings and locales I just found a small typo in an 
error message of R 2.9.0 (2009-02-06 r47865).

In 'po/de.po' at line 5100 it has to be spelled 'Lokalisierung' instead 
of 'Lokilisierung'.

Rainer


From murdoch at stats.uwo.ca  Sun Feb  8 22:45:52 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 08 Feb 2009 16:45:52 -0500
Subject: [Rd] Small typo in error message of R-devel
In-Reply-To: <498F4F62.5010100@gwdg.de>
References: <498F4F62.5010100@gwdg.de>
Message-ID: <498F5290.5040100@stats.uwo.ca>

On 08/02/2009 4:32 PM, Rainer Hurling wrote:
> Trying out some encodings and locales I just found a small typo in an 
> error message of R 2.9.0 (2009-02-06 r47865).
> 
> In 'po/de.po' at line 5100 it has to be spelled 'Lokalisierung' instead 
> of 'Lokilisierung'.

Thanks.  For future reference, corrections to the translations should be 
sent to the translation teams listed on

http://developer.r-project.org/TranslationTeams.html

They maintain the originals.  I've cc'd Detlef Steuer on this one.

Duncan Murdoch


From cgenolin at u-paris10.fr  Sun Feb  8 23:37:24 2009
From: cgenolin at u-paris10.fr (Christophe Genolini)
Date: Sun, 08 Feb 2009 23:37:24 +0100
Subject: [Rd] Strange behavior of C compiled program
Message-ID: <498F5EA4.3060307@u-paris10.fr>

Hi the list,

I need to include some C code in R, but the behavior of the C code is 
strange : Here is my code :
--- 8< ---
    Rprintf("\n XXXX mTraj=%f 
mClus=%f",mTraj[i+nbId*c],mClustersCenter[j+nbClusters*c]);

    Rprintf("\nDistA=%d Tmp=%d",dist,tmp);
            tmp = mTraj[i+nbId* c] - mClustersCenter [j+nbClusters* c];

    Rprintf("\nDistB=%d Tmp=%d",dist,tmp);
            dist += (tmp * tmp);

    Rprintf("\nDistC=%d Tmp=%d",dist,tmp);
--- 8< ----

Herer are the stranges results it gives :

XXXX mTraj=1.000000 mClus=3.000000
DistA=0 Tmp=0
DistB=0 Tmp=0
DistC=0 Tmp=1074790400

I ask on a C chat, but no one can answer me.
Any idea of what wrong ?

Thanks
Christophe


From murdoch at stats.uwo.ca  Sun Feb  8 23:44:34 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 08 Feb 2009 17:44:34 -0500
Subject: [Rd] Strange behavior of C compiled program
In-Reply-To: <498F5EA4.3060307@u-paris10.fr>
References: <498F5EA4.3060307@u-paris10.fr>
Message-ID: <498F6052.6070506@stats.uwo.ca>

On 08/02/2009 5:37 PM, Christophe Genolini wrote:
> Hi the list,
> 
> I need to include some C code in R, but the behavior of the C code is 
> strange : Here is my code :
> --- 8< ---
>     Rprintf("\n XXXX mTraj=%f 
> mClus=%f",mTraj[i+nbId*c],mClustersCenter[j+nbClusters*c]);
> 
>     Rprintf("\nDistA=%d Tmp=%d",dist,tmp);
>             tmp = mTraj[i+nbId* c] - mClustersCenter [j+nbClusters* c];
> 
>     Rprintf("\nDistB=%d Tmp=%d",dist,tmp);
>             dist += (tmp * tmp);
> 
>     Rprintf("\nDistC=%d Tmp=%d",dist,tmp);
> --- 8< ----
> 
> Herer are the stranges results it gives :
> 
> XXXX mTraj=1.000000 mClus=3.000000
> DistA=0 Tmp=0
> DistB=0 Tmp=0
> DistC=0 Tmp=1074790400
> 
> I ask on a C chat, but no one can answer me.
> Any idea of what wrong ?

You likely have the wrong types for the variables you're printing.  In 
C, the format has to match the type of the variable; if you use the 
wrong one, you get garbage.

Duncan Murdoch


From mathieu.ribatet at epfl.ch  Sun Feb  8 23:52:30 2009
From: mathieu.ribatet at epfl.ch (Mathieu Ribatet)
Date: Sun, 08 Feb 2009 23:52:30 +0100
Subject: [Rd] Strange behavior of C compiled program
In-Reply-To: <498F5EA4.3060307@u-paris10.fr>
References: <498F5EA4.3060307@u-paris10.fr>
Message-ID: <1234133550.6331.1.camel@mathieu-laptop>

Hi Christophe,

The problem might be that you used %d when printing. I guess that your
variables dist and tmp are double so you have to use %f instead.

Best,
Mathieu

Le dimanche 08 f?vrier 2009 ? 23:37 +0100, Christophe Genolini a ?crit :
> Hi the list,
> 
> I need to include some C code in R, but the behavior of the C code is 
> strange : Here is my code :
> --- 8< ---
>     Rprintf("\n XXXX mTraj=%f 
> mClus=%f",mTraj[i+nbId*c],mClustersCenter[j+nbClusters*c]);
> 
>     Rprintf("\nDistA=%d Tmp=%d",dist,tmp);
>             tmp = mTraj[i+nbId* c] - mClustersCenter [j+nbClusters* c];
> 
>     Rprintf("\nDistB=%d Tmp=%d",dist,tmp);
>             dist += (tmp * tmp);
> 
>     Rprintf("\nDistC=%d Tmp=%d",dist,tmp);
> --- 8< ----
> 
> Herer are the stranges results it gives :
> 
> XXXX mTraj=1.000000 mClus=3.000000
> DistA=0 Tmp=0
> DistB=0 Tmp=0
> DistC=0 Tmp=1074790400
> 
> I ask on a C chat, but no one can answer me.
> Any idea of what wrong ?
> 
> Thanks
> Christophe
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
-- 
Institute of Mathematics
Ecole Polytechnique F?d?rale de Lausanne
STAT-IMA-FSB-EPFL, Station 8
CH-1015 Lausanne   Switzerland
http://stat.epfl.ch/
Tel: + 41 (0)21 693 7907


From yizhang84 at gmail.com  Mon Feb  9 04:46:06 2009
From: yizhang84 at gmail.com (Yi Zhang)
Date: Sun, 8 Feb 2009 22:46:06 -0500
Subject: [Rd] Where's code for binding values to formal arguments in
	functions?
Message-ID: <a0428ec90902081946y1298d8d5i9bd4dc4acb8e57ca@mail.gmail.com>

Hello,

Can anyone give me a pointer where to find the implementation code for
binding values to formal arguments in functions? For example, if we
have a function f <- function(x,y)... and f(1,2) is called, I want to
find the code that binds 1 to x when evaluating f(1,2). I tried eval.c
but it's too long and I was lost... Thanks!

-- 
Yi


From ripley at stats.ox.ac.uk  Mon Feb  9 07:18:56 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 9 Feb 2009 06:18:56 +0000 (GMT)
Subject: [Rd] Where's code for binding values to formal arguments in
 functions?
In-Reply-To: <a0428ec90902081946y1298d8d5i9bd4dc4acb8e57ca@mail.gmail.com>
References: <a0428ec90902081946y1298d8d5i9bd4dc4acb8e57ca@mail.gmail.com>
Message-ID: <alpine.LFD.2.00.0902090613420.12998@gannet.stats.ox.ac.uk>

Have you studied d the R-ints manual?

It is a complex process, since in fact it is promises which are bound. 
The code for that is in match.c: matchArgs.

In general, you will not find people willing to read the source code 
for you, and especially if you give no reason for your 'wants'.

On Sun, 8 Feb 2009, Yi Zhang wrote:

> Hello,
>
> Can anyone give me a pointer where to find the implementation code for
> binding values to formal arguments in functions? For example, if we
> have a function f <- function(x,y)... and f(1,2) is called, I want to
> find the code that binds 1 to x when evaluating f(1,2). I tried eval.c
> but it's too long and I was lost... Thanks!
>
> -- 
> Yi

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From cgenolin at u-paris10.fr  Mon Feb  9 10:05:36 2009
From: cgenolin at u-paris10.fr (Christophe Genolini)
Date: Mon, 09 Feb 2009 10:05:36 +0100
Subject: [Rd] Strange behavior of C compiled program
In-Reply-To: <498F6052.6070506@stats.uwo.ca>
References: <498F5EA4.3060307@u-paris10.fr> <498F6052.6070506@stats.uwo.ca>
Message-ID: <498FF1E0.2020103@u-paris10.fr>

Thanks, that was a stupid mistake (I did not know that this is so 
important).

So I still have a problem realy more complex and I do not know was is 
wrong. I am running a .C procedure in a R loop.
After 4, 5 or sometimes 6 call to the C procedure, Rgui crash (it closes 
asking me if I want to send a report to Microsoft).
Is there a debuger that can run the C code with some R in it ? And what 
kind of mistake can provoque such a crash ?

Thanks
Christophe


So I thaught that I find t
> On 08/02/2009 5:37 PM, Christophe Genolini wrote:
>> Hi the list,
>>
>> I need to include some C code in R, but the behavior of the C code is 
>> strange : Here is my code :
>> --- 8< ---
>>     Rprintf("\n XXXX mTraj=%f 
>> mClus=%f",mTraj[i+nbId*c],mClustersCenter[j+nbClusters*c]);
>>
>>     Rprintf("\nDistA=%d Tmp=%d",dist,tmp);
>>             tmp = mTraj[i+nbId* c] - mClustersCenter [j+nbClusters* c];
>>
>>     Rprintf("\nDistB=%d Tmp=%d",dist,tmp);
>>             dist += (tmp * tmp);
>>
>>     Rprintf("\nDistC=%d Tmp=%d",dist,tmp);
>> --- 8< ----
>>
>> Herer are the stranges results it gives :
>>
>> XXXX mTraj=1.000000 mClus=3.000000
>> DistA=0 Tmp=0
>> DistB=0 Tmp=0
>> DistC=0 Tmp=1074790400
>>
>> I ask on a C chat, but no one can answer me.
>> Any idea of what wrong ?
>
> You likely have the wrong types for the variables you're printing.  In 
> C, the format has to match the type of the variable; if you use the 
> wrong one, you get garbage.
>
> Duncan Murdoch
>


From maechler at stat.math.ethz.ch  Mon Feb  9 10:18:15 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 9 Feb 2009 10:18:15 +0100
Subject: [Rd] best reference on generics
In-Reply-To: <49875ACC.1010805@prodsyse.com>
References: <49875ACC.1010805@prodsyse.com>
Message-ID: <18831.62679.44766.411000@stat.math.ethz.ch>

>>>>> "SpG" == Spencer Graves <spencer.graves at prodsyse.com>
>>>>>     on Mon, 02 Feb 2009 12:42:52 -0800 writes:

    SpG> Hello, All: What would you say is the best succinct
    SpG> reference to cite on use of generic functions,
    SpG> especially S3 generics?

In a very strict sense, S3 generics don't exist; 
S4 ones do.
Less strictly, an R function that uses UseMethod() is an
S3-generic.

?UseMethod  is a pretty good reference, 
and BTW, contains

>> Note:
>> 
>>      This scheme is called _S3_ (S version 3).  For new projects, it is
>>      recommended to use the more flexible and robust _S4_ scheme
>>      provided in the 'methods' package.

[so for a forthcoming book and package, it's pity that S4 had
 not been used...

 Yes, now I go hide before the flames roar at me !
]

Martin Maechler, ETH Zurich

    SpG>       I want to add an appropriate citation on this to
    SpG> a forthcoming book in the Springer "useR!" series
    SpG> (discussing the use of the 'fda' package, which uses
    SpG> the S3 standard).

    SpG>       Thanks, Spencer Graves

    SpG> ______________________________________________
    SpG> R-devel at r-project.org mailing list
    SpG> https://stat.ethz.ch/mailman/listinfo/r-devel


From mathieu.ribatet at epfl.ch  Mon Feb  9 10:18:23 2009
From: mathieu.ribatet at epfl.ch (Mathieu Ribatet)
Date: Mon, 09 Feb 2009 10:18:23 +0100
Subject: [Rd] Strange behavior of C compiled program
In-Reply-To: <498FF1E0.2020103@u-paris10.fr>
References: <498F5EA4.3060307@u-paris10.fr> <498F6052.6070506@stats.uwo.ca>
	<498FF1E0.2020103@u-paris10.fr>
Message-ID: <1234171103.6503.8.camel@mathieu-laptop>

You might have a look at the "Writing R Extensions" manual - especially
valgrind and/or gdb.

By the way, your error is probably due to array size problem - i.e. tmp
is of size n and you call tmp[n+1] for example. Valgrind will detect in
automagically for you.

Best,
Mathieu

Le lundi 09 f?vrier 2009 ? 10:05 +0100, Christophe Genolini a ?crit :
> Thanks, that was a stupid mistake (I did not know that this is so 
> important).
> 
> So I still have a problem realy more complex and I do not know was is 
> wrong. I am running a .C procedure in a R loop.
> After 4, 5 or sometimes 6 call to the C procedure, Rgui crash (it closes 
> asking me if I want to send a report to Microsoft).
> Is there a debuger that can run the C code with some R in it ? And what 
> kind of mistake can provoque such a crash ?
> 
> Thanks
> Christophe
> 
> 
> So I thaught that I find t
> > On 08/02/2009 5:37 PM, Christophe Genolini wrote:
> >> Hi the list,
> >>
> >> I need to include some C code in R, but the behavior of the C code is 
> >> strange : Here is my code :
> >> --- 8< ---
> >>     Rprintf("\n XXXX mTraj=%f 
> >> mClus=%f",mTraj[i+nbId*c],mClustersCenter[j+nbClusters*c]);
> >>
> >>     Rprintf("\nDistA=%d Tmp=%d",dist,tmp);
> >>             tmp = mTraj[i+nbId* c] - mClustersCenter [j+nbClusters* c];
> >>
> >>     Rprintf("\nDistB=%d Tmp=%d",dist,tmp);
> >>             dist += (tmp * tmp);
> >>
> >>     Rprintf("\nDistC=%d Tmp=%d",dist,tmp);
> >> --- 8< ----
> >>
> >> Herer are the stranges results it gives :
> >>
> >> XXXX mTraj=1.000000 mClus=3.000000
> >> DistA=0 Tmp=0
> >> DistB=0 Tmp=0
> >> DistC=0 Tmp=1074790400
> >>
> >> I ask on a C chat, but no one can answer me.
> >> Any idea of what wrong ?
> >
> > You likely have the wrong types for the variables you're printing.  In 
> > C, the format has to match the type of the variable; if you use the 
> > wrong one, you get garbage.
> >
> > Duncan Murdoch
> >
> 
-- 
Institute of Mathematics
Ecole Polytechnique F?d?rale de Lausanne
STAT-IMA-FSB-EPFL, Station 8
CH-1015 Lausanne   Switzerland
http://stat.epfl.ch/
Tel: + 41 (0)21 693 7907


From murdoch at stats.uwo.ca  Mon Feb  9 11:23:52 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 09 Feb 2009 05:23:52 -0500
Subject: [Rd] Strange behavior of C compiled program
In-Reply-To: <498FF1E0.2020103@u-paris10.fr>
References: <498F5EA4.3060307@u-paris10.fr> <498F6052.6070506@stats.uwo.ca>
	<498FF1E0.2020103@u-paris10.fr>
Message-ID: <49900438.7090405@stats.uwo.ca>

On 09/02/2009 4:05 AM, Christophe Genolini wrote:
> Thanks, that was a stupid mistake (I did not know that this is so 
> important).
> 
> So I still have a problem realy more complex and I do not know was is 
> wrong. I am running a .C procedure in a R loop.
> After 4, 5 or sometimes 6 call to the C procedure, Rgui crash (it closes 
> asking me if I want to send a report to Microsoft).
> Is there a debuger that can run the C code with some R in it ? And what 
> kind of mistake can provoque such a crash ?

Debugging C code in R on Windows is a little painful.  valgrind doesn't 
run on Windows (as far as I know), and none of the commercial debuggers 
support the debug format that gcc uses.  However, you can run gdb, and 
it mostly works.  See my page

http://www.stats.uwo.ca/faculty/murdoch/software/debuggingR/

for details.  (I use the Cygwin version of gdb, but it usually gets the 
backtrace wrong if you look for a stack dump.  I understand the MinGW 
version is better at that, but I've been unable to get the Insight 
graphical front end to work with it.  I'd love to hear from someone who 
has a modern graphical front end working for debugging MinGW code on 
Windows.)

Duncan Murdoch

> 
> Thanks
> Christophe
> 
> 
> So I thaught that I find t
>> On 08/02/2009 5:37 PM, Christophe Genolini wrote:
>>> Hi the list,
>>>
>>> I need to include some C code in R, but the behavior of the C code is 
>>> strange : Here is my code :
>>> --- 8< ---
>>>     Rprintf("\n XXXX mTraj=%f 
>>> mClus=%f",mTraj[i+nbId*c],mClustersCenter[j+nbClusters*c]);
>>>
>>>     Rprintf("\nDistA=%d Tmp=%d",dist,tmp);
>>>             tmp = mTraj[i+nbId* c] - mClustersCenter [j+nbClusters* c];
>>>
>>>     Rprintf("\nDistB=%d Tmp=%d",dist,tmp);
>>>             dist += (tmp * tmp);
>>>
>>>     Rprintf("\nDistC=%d Tmp=%d",dist,tmp);
>>> --- 8< ----
>>>
>>> Herer are the stranges results it gives :
>>>
>>> XXXX mTraj=1.000000 mClus=3.000000
>>> DistA=0 Tmp=0
>>> DistB=0 Tmp=0
>>> DistC=0 Tmp=1074790400
>>>
>>> I ask on a C chat, but no one can answer me.
>>> Any idea of what wrong ?
>> You likely have the wrong types for the variables you're printing.  In 
>> C, the format has to match the type of the variable; if you use the 
>> wrong one, you get garbage.
>>
>> Duncan Murdoch
>>


From therneau at mayo.edu  Mon Feb  9 14:49:54 2009
From: therneau at mayo.edu (Terry Therneau)
Date: Mon, 9 Feb 2009 07:49:54 -0600 (CST)
Subject: [Rd] CMD check puzzle
Message-ID: <200902091349.n19DnsGr005055@rocky.mayo.edu>

I am getting an error that I don't understand from R CMD check on my current
instance of the survival code.  R2.7.1 on Linux.  Here is the last of the 
log

* checking line endings in Makefiles ... OK
* checking for portable use of $BLAS_LIBS ... OK
* creating survival-Ex.R ... OK
* checking examples ... OK
* checking tests ...
make[1]: Entering directory `/home/therneau/research/surv/Rforge/pkg/survival.Rcheck/tests'
  Running 'aareg.R'
make[1]: *** [aareg.Rout] Error 1
...
  > tfit  <- aareg(Surv(time, status) ~ x, test1)
  Error: could not find function "aareg"
  Execution halted

--------------
  The manual page aareg.Rd has a call to the function in the examples and that
runs ok, and aareg is in the NAMESPACE exports.

 I'm almost certainly missing something obvious - please point it out.

  Thanks,
   Terry T.


From therneau at mayo.edu  Mon Feb  9 14:57:36 2009
From: therneau at mayo.edu (Terry Therneau)
Date: Mon, 9 Feb 2009 07:57:36 -0600 (CST)
Subject: [Rd] One more note
Message-ID: <200902091357.n19DvaRn005778@rocky.mayo.edu>

 There are some warnings earlier in the log about my .Rd files (missing a
description of weights and subset in a couple).  The only message that I
don't completely understand is

* checking foreign function calls ... OK
* checking R code for possible problems ... NOTE
Error in firstlib(which.lib.loc, package) : 
  Tcl/Tk support is not available on this system

 I'm also curious about this.  But I get the same aareg error on the Sun server
at work, without the Tcl message, so I know it is not primary.

  Terry T


From P.Dalgaard at biostat.ku.dk  Mon Feb  9 15:13:15 2009
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Mon, 09 Feb 2009 15:13:15 +0100
Subject: [Rd] One more note
In-Reply-To: <200902091357.n19DvaRn005778@rocky.mayo.edu>
References: <200902091357.n19DvaRn005778@rocky.mayo.edu>
Message-ID: <499039FB.8000602@biostat.ku.dk>

Terry Therneau wrote:
>  There are some warnings earlier in the log about my .Rd files (missing a
> description of weights and subset in a couple).  The only message that I
> don't completely understand is
> 
> * checking foreign function calls ... OK
> * checking R code for possible problems ... NOTE
> Error in firstlib(which.lib.loc, package) : 
>   Tcl/Tk support is not available on this system
> 
>  I'm also curious about this.  But I get the same aareg error on the Sun server
> at work, without the Tcl message, so I know it is not primary.

The most obvious reason would be if Tcl/Tk support is not available on
your system....

(a) Which system?
(b) Do you have

> capabilities("tcltk")
tcltk
 TRUE


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From tlumley at u.washington.edu  Mon Feb  9 15:30:49 2009
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 9 Feb 2009 06:30:49 -0800 (PST)
Subject: [Rd] CMD check puzzle
In-Reply-To: <200902091349.n19DnsGr005055@rocky.mayo.edu>
Message-ID: <Pine.LNX.4.43.0902090630490.3821@hymn33.u.washington.edu>

On Mon, 9 Feb 2009, Terry Therneau wrote:

>  > tfit  <- aareg(Surv(time, status) ~ x, test1)
>  Error: could not find function "aareg"
>  Execution halted
>
> --------------
>  The manual page aareg.Rd has a call to the function in the examples and that
> runs ok, and aareg is in the NAMESPACE exports.
>
> I'm almost certainly missing something obvious - please point it out.
>

Based on the r-forge code it looks like you need library(survival) in R code in tests/.  It doesn't happen automatically like it does for examples.

       -thomas


Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From ripley at stats.ox.ac.uk  Mon Feb  9 15:42:21 2009
From: ripley at stats.ox.ac.uk (Brian D Ripley)
Date: Mon, 9 Feb 2009 14:42:21 +0000 (GMT)
Subject: [Rd] One more note
In-Reply-To: <499039FB.8000602@biostat.ku.dk>
References: <200902091357.n19DvaRn005778@rocky.mayo.edu>
	<499039FB.8000602@biostat.ku.dk>
Message-ID: <alpine.LFD.2.00.0902091439270.29318@toucan.stats.ox.ac.uk>

On Mon, 9 Feb 2009, Peter Dalgaard wrote:

> Terry Therneau wrote:
>>  There are some warnings earlier in the log about my .Rd files (missing a
>> description of weights and subset in a couple).  The only message that I
>> don't completely understand is
>>
>> * checking foreign function calls ... OK
>> * checking R code for possible problems ... NOTE
>> Error in firstlib(which.lib.loc, package) :
>>   Tcl/Tk support is not available on this system
>>
>>  I'm also curious about this.  But I get the same aareg error on the Sun server
>> at work, without the Tcl message, so I know it is not primary.
>
> The most obvious reason would be if Tcl/Tk support is not available on
> your system....
>
> (a) Which system?
> (b) Do you have
>
>> capabilities("tcltk")
> tcltk
> TRUE

Because so many people assume that tcltk is present, those checks look 
for unexplained symbols in package tcltk.  As it is not on your 
system, you will not be able to use the symbols and it does not 
matter. The call is inside try(), so the error is ignored.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From therneau at mayo.edu  Mon Feb  9 16:20:33 2009
From: therneau at mayo.edu (Terry Therneau)
Date: Mon, 9 Feb 2009 09:20:33 -0600 (CST)
Subject: [Rd] CMD check puzzle
Message-ID: <200902091520.n19FKXg21500@hsrnfs-101.mayo.edu>

> ... you need library(survival) in R code in tests/.  It doesn't happen 
>   automatically like it does for examples.

  Thanks Thomas, that is exactly the hint I needed.  I had read the "check" part 
of the manual 3 times in vain; once you pointed it out I was able to fine  the 
answer in the manual's description of the 'test' subdirectory.
  
  	Terry T.


From j.j.goeman at lumc.nl  Mon Feb  9 22:30:13 2009
From: j.j.goeman at lumc.nl (j.j.goeman at lumc.nl)
Date: Mon,  9 Feb 2009 22:30:13 +0100 (CET)
Subject: [Rd] heatmap without dendrogams (PR#13512)
Message-ID: <20090209213013.A74FE282EFC1@mail.pubhealth.ku.dk>

Full_Name: Jelle Goeman
Version: 2.8.1
OS: Win XP
Submission from: (NULL) (87.212.67.197)


I get the following error message when I try to make a heatmap (package stats),
without the associated dendrograms.

X <- matrix(rnorm(200),20,10)
XX <- crossprod(X)
heatmap(XX, Rowv= NA, revC=TRUE)
Error in rev(ddr) : object "ddr" not found
heatmap(XX, Rowv= NA, sym=TRUE)
Error in heatmap(XX, Rowv = NA, sym = TRUE) : object "ddr" not found
 
According to the help file, this should work; indeed it does if I set revC or
sym to FALSE. Seems like ddr should be initialized to something like 1:ncol(X)
for the no-dendrogram case.

Kind regards,

Jelle


From elff at sowi.uni-mannheim.de  Tue Feb 10 10:49:46 2009
From: elff at sowi.uni-mannheim.de (Martin Elff)
Date: Tue, 10 Feb 2009 10:49:46 +0100
Subject: [Rd] New package test results available
In-Reply-To: <alpine.LFD.2.00.0902070651160.18308@gannet.stats.ox.ac.uk>
References: <alpine.LFD.2.00.0902070651160.18308@gannet.stats.ox.ac.uk>
Message-ID: <200902101049.46516.elff@sowi.uni-mannheim.de>

Dear Professor Ripley,

as you pointed out, package 'memisc' caused a compilation error with
the Sun Studio compiler because of gcc-specific compilation flags. The obvious 
reason was that the 'src' directory had a 'Makevars' file 
containing "PKGC_FLAGS="-Wall -pedantic". 

In the new revision of my package uploaded this weekend, the Makevars
file is removed, but nevertheless according to the protocol of the
automatic package checking with Sun Studio (of 2009-02-10 05:53:33), a 
compilation error occurs because of the gcc-specific compilation 
options "-Wall -pedantic". I checked the CRAN-version of the package for any 
instances of Makefiles or Makevar files, but none is present. Also I grepped 
my sources for any instance of "-Wall", with negative results. So I wonder 
what I should do to avoid Sun Studio errors caused by these options.

Any hint is appreciated.
Thanks, 

Martin Elff


On Saturday 07 February 2009 (08:22:49), Prof Brian Ripley wrote:
> We've added a column at
>
> http://cran.r-project.org/web/checks/check_summary.html
>
> of test results using the Sun Studio compiler: it is intended that
> these will be updated weekly.
>
> The Sun Studio compiler is that used on Solaris: these runs were on
> the Linux version.  All the other platforms are using gcc 4, so this
> provides an opportunity for checking for use of gcc-specific features
> and also standards conformance (the Sun compilers have a long-time
> reputation for close conformance to the language standards).
>
> There are known problems where packages use C++ or JNI interfaces
> (e.g. rgdal and EBImage) as the libraries and JVM were compiled under
> gcc's conventions (even though a Sun JVMi is used).  About half the
> packages using rJava segfault, which seems to a JNI issue.
>
> Some packages use gcc-specific compiler flags:
>
>    LogConcDEAD Matching amap geometry memisc taskPR
>
> but the vast majority of the errors reported are C++ errors.  One
> class that may not be immediately obvious is the use of C headers in
> C++: you are supposed to write e.g.
>
> #includd <cmath>
>
> NOT
>
> #include <math.h>
>
> Symptoms of this can be seen for packages
>
>    BayesTree EMCC MCMCfglmm MarkedPointProcess Matching Matrix
>    RQuantlib RandomFields Rcpp SoPhy compHclust dpmix igraph minet
>    mixer modeest monomvm multic pcaPP rgenoud robfilter segclust
>    simecol subselec

-------------------------------------------------
Dr. Martin Elff
Lecturer
LSPWIVS (Prof. van Deth)
Department of Social Sciences
University of Mannheim
A5, 6, A 328
68131 Mannheim
Germany

Phone: +49-621-181-2093
Fax: +49-621-181-2099
E-Mail: elff at sowi.uni-mannheim.de
Web: http://webrum.uni-mannheim.de/sowi/elff/
     http://www.sowi.uni-mannheim.de/lspwivs/


From cgenolin at u-paris10.fr  Tue Feb 10 12:24:56 2009
From: cgenolin at u-paris10.fr (Christophe Genolini)
Date: Tue, 10 Feb 2009 12:24:56 +0100
Subject: [Rd] \usage without \alias
Message-ID: <49916408.2010908@u-paris10.fr>

Hi the list,

I am checking a package and I get a warnings :

--- 8< ----
Objects in \usage without \alias in documentation object 'plot,Calinski'
--- 8< ----

'Calinski' is a S4 class and I define a S4 method for ploting it. Here 
is my plotCalinski.rd file :

--- 8< ----
\name{plot,Calinski}
\alias{plot,Calinski}
\alias{plot,Calinski-method}

\title{ ~ Function: plot for Calinski ~ }
\description{
  \code{plot} the Calinski creterion.
}
\usage{
plot(x, y, ...)
}
--- 8< ----

Any idea of what is wrong ?

Thanks
Christophe


From xinlee883 at stat.math.ethz.ch  Tue Feb 10 11:25:06 2009
From: xinlee883 at stat.math.ethz.ch (xinlee883 at stat.math.ethz.ch)
Date: Tue, 10 Feb 2009 11:25:06 +0100 (CET)
Subject: [Rd] Bug in subsetting data frame (PR#13515)
Message-ID: <20090210102506.CB966282EF48@mail.pubhealth.ku.dk>

Full_Name: Xin Lee
Version: 2.8.0
OS: Windows XP
Submission from: (NULL) (193.200.150.23)


Dear developer

I discover annoying bug in subsetting data frame.  Here is reproducable
examples:

> data.frame <- data.frame(x = runif(5), y = runif(5), row.names =
c('a','b','c','d','e')

> subset <- data.frame['x']
> subset['a',]
work

> subset <- data.frame$x
> subset['a',]
not work

> subset <- data.frame['a',]
> subset[,'x']
work

> subset <- data.frame[,'x']
> subset['a',]
not work

I hope this is easy fix for you and works corectly soon.

Sincerely,
Xin Lee


From tlumley at u.washington.edu  Tue Feb 10 13:42:34 2009
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 10 Feb 2009 04:42:34 -0800 (PST)
Subject: [Rd] Bug in subsetting data frame (PR#13515)
In-Reply-To: <20090210102506.CB966282EF48@mail.pubhealth.ku.dk>
Message-ID: <Pine.LNX.4.43.0902100442340.21746@hymn34.u.washington.edu>

On Tue, 10 Feb 2009 xinlee883 at stat.math.ethz.ch wrote:

>
> I discover annoying bug in subsetting data frame.  Here is reproducable
> examples:

These are not bugs.

>> data.frame <- data.frame(x = runif(5), y = runif(5), row.names =
> c('a','b','c','d','e')
>
>> subset <- data.frame['x']
>> subset['a',]
> work
>
>> subset <- data.frame$x
>> subset['a',]
> not work

This can't possibly work, since you have explicitly requested that subset not be a data frame.

There has been recent discussion about whether row names should be added as names to vectors from a data frame, in which case subset['a'] would then work. It doesn't now, and that isn't a bug either.

>> subset <- data.frame['a',]
>> subset[,'x']
> work
>
>> subset <- data.frame[,'x']
>> subset['a',]
> not work

This is also not a bug.  The drop= option to [ controls what happens when the subset has dimensions of length 1. If you want subset to be a data frame in this context, use
   subset <- data.frame[,'x',drop=FALSE]
and then subset['a',] will do want you want.

        -thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From macrakis at alum.mit.edu  Tue Feb 10 13:59:41 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Tue, 10 Feb 2009 07:59:41 -0500
Subject: [Rd] Bug in subsetting data frame (PR#13515)
In-Reply-To: <20090210102506.CB966282EF48@mail.pubhealth.ku.dk>
References: <20090210102506.CB966282EF48@mail.pubhealth.ku.dk>
Message-ID: <8b356f880902100459n321c321ew1ee4ab3c9a7ddb0f@mail.gmail.com>

Don't know if this is the problem, but....

It is a bad idea to set data.frame <- xxx since R has a single
namespace for functions and variables.

        -s

On 2/10/09, xinlee883 at stat.math.ethz.ch <xinlee883 at stat.math.ethz.ch> wrote:
> Full_Name: Xin Lee
> Version: 2.8.0
> OS: Windows XP
> Submission from: (NULL) (193.200.150.23)
>
>
> Dear developer
>
> I discover annoying bug in subsetting data frame.  Here is reproducable
> examples:
>
>> data.frame <- data.frame(x = runif(5), y = runif(5), row.names =
> c('a','b','c','d','e')
>
>> subset <- data.frame['x']
>> subset['a',]
> work
>
>> subset <- data.frame$x
>> subset['a',]
> not work
>
>> subset <- data.frame['a',]
>> subset[,'x']
> work
>
>> subset <- data.frame[,'x']
>> subset['a',]
> not work
>
> I hope this is easy fix for you and works corectly soon.
>
> Sincerely,
> Xin Lee
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From murdoch at stats.uwo.ca  Tue Feb 10 14:31:47 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 10 Feb 2009 08:31:47 -0500
Subject: [Rd] Bug in subsetting data frame (PR#13515)
In-Reply-To: <8b356f880902100459n321c321ew1ee4ab3c9a7ddb0f@mail.gmail.com>
References: <20090210102506.CB966282EF48@mail.pubhealth.ku.dk>
	<8b356f880902100459n321c321ew1ee4ab3c9a7ddb0f@mail.gmail.com>
Message-ID: <499181C3.6000907@stats.uwo.ca>

Stavros Macrakis wrote:
> Don't know if this is the problem, but....
>
> It is a bad idea to set data.frame <- xxx since R has a single
> namespace for functions and variables.
>   
That's not quite accurate.  R mixes functions and variables in 
namespaces, but it has lots of namespaces, and it usually doesn't cause 
much trouble to have a variable named data.frame in one, and a function 
named data.frame in another.  The evaluator recognizes the context of 
usage and will get the function for a function call. If you retrieve 
data.frame without doing a function call, you'll get whichever one it 
finds first, which is typically the one in the global environment, as 
below.  Sometimes this causes trouble (e.g. if you passed data.frame to 
apply or do.call), but usually not, and I don't think it would cause 
trouble below.  What we see below is a simple misunderstanding of the 
difference between [] and $.

Duncan Murdoch


>         -s
>
> On 2/10/09, xinlee883 at stat.math.ethz.ch <xinlee883 at stat.math.ethz.ch> wrote:
>   
>> Full_Name: Xin Lee
>> Version: 2.8.0
>> OS: Windows XP
>> Submission from: (NULL) (193.200.150.23)
>>
>>
>> Dear developer
>>
>> I discover annoying bug in subsetting data frame.  Here is reproducable
>> examples:
>>
>>     
>>> data.frame <- data.frame(x = runif(5), y = runif(5), row.names =
>>>       
>> c('a','b','c','d','e')
>>
>>     
>>> subset <- data.frame['x']
>>> subset['a',]
>>>       
>> work
>>
>>     
>>> subset <- data.frame$x
>>> subset['a',]
>>>       
>> not work
>>
>>     
>>> subset <- data.frame['a',]
>>> subset[,'x']
>>>       
>> work
>>
>>     
>>> subset <- data.frame[,'x']
>>> subset['a',]
>>>       
>> not work
>>
>> I hope this is easy fix for you and works corectly soon.
>>
>> Sincerely,
>> Xin Lee
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>     
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Tue Feb 10 14:34:21 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Tue, 10 Feb 2009 14:34:21 +0100
Subject: [Rd] Bug in subsetting data frame (PR#13515)
In-Reply-To: <8b356f880902100459n321c321ew1ee4ab3c9a7ddb0f@mail.gmail.com>
References: <20090210102506.CB966282EF48@mail.pubhealth.ku.dk>
	<8b356f880902100459n321c321ew1ee4ab3c9a7ddb0f@mail.gmail.com>
Message-ID: <4991825D.7020803@idi.ntnu.no>

Stavros Macrakis wrote:
> Don't know if this is the problem, but....
>
> It is a bad idea to set data.frame <- xxx since R has a single
> namespace for functions and variables.
>
>   

it doesn't seem to be the problem.

c = c(0)
c
# 0, not the function `c`
c(1)
# 1, not an error from application of 0 to 1

but

c = `list`
c(0)
# list, not a vector
c
# the function `list`, not the value 0


the issue is, if you use a name as an operator, it's the first *function
value*, not just *value*, found on the search path that will be used. 
in the example you referred to, if you assign a non-function value to
data.frame, an attempt to apply data.frame will get the function from
package:base:

data.frame = 0
find('data.frame', mode='function')


vQ


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Tue Feb 10 14:36:56 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Tue, 10 Feb 2009 14:36:56 +0100
Subject: [Rd] Bug in subsetting data frame (PR#13515)
In-Reply-To: <8b356f880902100459n321c321ew1ee4ab3c9a7ddb0f@mail.gmail.com>
References: <20090210102506.CB966282EF48@mail.pubhealth.ku.dk>
	<8b356f880902100459n321c321ew1ee4ab3c9a7ddb0f@mail.gmail.com>
Message-ID: <499182F8.7000507@idi.ntnu.no>

Stavros Macrakis wrote:
> Don't know if this is the problem, but....
>
> It is a bad idea to set data.frame <- xxx since R has a single
> namespace for functions and variables.
>
>   

it doesn't seem to be the problem.

c = c(0)
c
# 0, not the function `c`
c(1)
# 1, not an error from application of 0 to 1

but

c = `list`
c(0)
# list, not a vector
c
# the function `list`, not the value 0


the issue is, if you use a name as an operator, it's the first *function
value*, not just *value*, found on the search path that will be used. 
in the example you referred to, if you assign a non-function value to
data.frame, an attempt to apply data.frame will get the function from
package:base:

data.frame = 0
find('data.frame')
find('data.frame', mode='function')


vQ


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Tue Feb 10 15:02:20 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Tue, 10 Feb 2009 15:02:20 +0100
Subject: [Rd] Bug in subsetting data frame (PR#13515)
In-Reply-To: <499182F8.7000507@idi.ntnu.no>
References: <20090210102506.CB966282EF48@mail.pubhealth.ku.dk>	<8b356f880902100459n321c321ew1ee4ab3c9a7ddb0f@mail.gmail.com>
	<499182F8.7000507@idi.ntnu.no>
Message-ID: <499188EC.7050700@idi.ntnu.no>

Wacek Kusnierczyk wrote:
> Stavros Macrakis wrote:
>   
>> Don't know if this is the problem, but....
>>
>> It is a bad idea to set data.frame <- xxx since R has a single
>> namespace for functions and variables.
>>
>>   
>>     
>
>
> the issue is, if you use a name as an operator, it's the first *function
> value*, not just *value*, found on the search path that will be used. 
> in the example you referred to, if you assign a non-function value to
> data.frame, an attempt to apply data.frame will get the function from
> package:base:
>
> data.frame = 0
> find('data.frame')
> find('data.frame', mode='function')
>   

... but if you really need to modify data.frame in place, you can:

pos = grep('^package:base$', search())
unlockBinding('data.frame', as.environment(pos))
assign('data.frame', function(...) NULL,  as.environment(pos))
lockBinding('data.frame',  as.environment(pos))

vQ


From macrakis at alum.mit.edu  Tue Feb 10 15:51:58 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Tue, 10 Feb 2009 09:51:58 -0500
Subject: [Rd] Bug in subsetting data frame (PR#13515)
In-Reply-To: <499181C3.6000907@stats.uwo.ca>
References: <20090210102506.CB966282EF48@mail.pubhealth.ku.dk>
	<8b356f880902100459n321c321ew1ee4ab3c9a7ddb0f@mail.gmail.com>
	<499181C3.6000907@stats.uwo.ca>
Message-ID: <8b356f880902100651n79fa3b04x5754f79e8ac17658@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090210/f676cabe/attachment.pl>

From murdoch at stats.uwo.ca  Tue Feb 10 16:11:58 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 10 Feb 2009 10:11:58 -0500
Subject: [Rd] Bug in subsetting data frame (PR#13515)
In-Reply-To: <8b356f880902100651n79fa3b04x5754f79e8ac17658@mail.gmail.com>
References: <20090210102506.CB966282EF48@mail.pubhealth.ku.dk>	
	<8b356f880902100459n321c321ew1ee4ab3c9a7ddb0f@mail.gmail.com>	
	<499181C3.6000907@stats.uwo.ca>
	<8b356f880902100651n79fa3b04x5754f79e8ac17658@mail.gmail.com>
Message-ID: <4991993E.3010204@stats.uwo.ca>

Stavros Macrakis wrote:
> On Tue, Feb 10, 2009 at 8:31 AM, Duncan Murdoch <murdoch at stats.uwo.ca>wrote:
>
>   
>> Stavros Macrakis wrote:
>>
>>     
>>> It is a bad idea to set data.frame <- xxx since R has a single
>>> namespace for functions and variables.
>>>
>>>
>>>       
>> That's not quite accurate.  R mixes functions and variables in namespaces,
>> but it has lots of namespaces, and it usually doesn't cause much trouble to
>> have a variable named data.frame in one, and a function named data.frame in
>> another.  The evaluator recognizes the context of usage and will get the
>> function for a function call. If you retrieve data.frame without doing a
>> function call, you'll get whichever one it finds first, which is typically
>> the one in the global environment, as below.
>>
>>     
>
> Interesting.  I was not aware of this rule.
>
> Can you point me to chapter and verse in the language definition (
> http://cran.r-project.org/doc/manuals/R-lang.html)?  I couldn't find it, but
> I probably looked in the wrong place.
>   

No, I'm also unable to find it.
> | Sometimes this causes trouble (e.g. if you passed data.frame to apply or
> do.call), but usually not, ...
>
> Indeed!  It is quite surprising that functions are defined using ordinary
> assignment, but function lookup is different from normal variable
> evaluation, e.g. that after c<-4, c(10) is different from (c)(10).  Was this
> inspired by some other language? I don't think it's done this way in any
> other language I can think of....
I think originally there was no difference, and it caused the obvious 
trouble when people used variable names like t and c other short 
function names, so this was added.  I don't remember whether the 
different lookup rules showed up first in R or S.

Duncan Murdoch


From camey at mat.ufrgs.br  Tue Feb 10 15:55:04 2009
From: camey at mat.ufrgs.br (camey at mat.ufrgs.br)
Date: Tue, 10 Feb 2009 15:55:04 +0100 (CET)
Subject: [Rd] Logical Error? (PR#13516)
Message-ID: <20090210145504.B22D8282C765@mail.pubhealth.ku.dk>

Full_Name: Suzi Alves Camey
Version: 2.7.2
OS: 
Submission from: (NULL) (143.54.37.254)


Using the commands bellow I expected that the answer is TRUE, but it is FALSE!

P_exposicao=.9
(1-P_exposicao)==.1


From josh.m.ulrich at gmail.com  Tue Feb 10 16:37:07 2009
From: josh.m.ulrich at gmail.com (Josh Ulrich)
Date: Tue, 10 Feb 2009 09:37:07 -0600
Subject: [Rd] Logical Error? (PR#13516)
In-Reply-To: <20090210145504.B22D8282C765@mail.pubhealth.ku.dk>
References: <20090210145504.B22D8282C765@mail.pubhealth.ku.dk>
Message-ID: <8cca69990902100737s16f677echd4eb313b722b5cd8@mail.gmail.com>

This is not a bug.  Please do read the FAQ before posting and creating
work for others.
http://cran.r-project.org/doc/FAQ/R-FAQ.html#R-Bugs
http://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f

Joshua Ulrich
--
http://quantemplation.blogspot.com



On Tue, Feb 10, 2009 at 8:55 AM,  <camey at mat.ufrgs.br> wrote:
> Full_Name: Suzi Alves Camey
> Version: 2.7.2
> OS:
> Submission from: (NULL) (143.54.37.254)
>
>
> Using the commands bellow I expected that the answer is TRUE, but it is FALSE!
>
> P_exposicao=.9
> (1-P_exposicao)==.1
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From olafm at kimberly.tako.de  Tue Feb 10 16:43:06 2009
From: olafm at kimberly.tako.de (Olaf Mersmann)
Date: Tue, 10 Feb 2009 16:43:06 +0100
Subject: [Rd] Logical Error? (PR#13516)
In-Reply-To: <20090210145504.B22D8282C765@mail.pubhealth.ku.dk>
References: <20090210145504.B22D8282C765@mail.pubhealth.ku.dk>
Message-ID: <1234280417-sup-2166@bloxx.plex>

Excerpts from camey's message of Tue Feb 10 15:55:04 +0100 2009:
> Using the commands bellow I expected that the answer is TRUE, but it is FALSE!
> 
> P_exposicao=.9
> (1-P_exposicao)==.1

Look at the difference of the two, it is much smaller than .Machine$double.eps on my computer.

This is not a bug, it's due to the limited precision of floating point numbers.

Sincerely
Olaf Mersmann


From Xavier.Robin at unige.ch  Tue Feb 10 16:52:51 2009
From: Xavier.Robin at unige.ch (Xavier Robin)
Date: Tue, 10 Feb 2009 07:52:51 -0800 (PST)
Subject: [Rd] Italics in svg output display as bold (PR#13463)
In-Reply-To: <D8D645C3-B243-4D2F-877D-8C0F98ADB1D5@pixie.org.uk>
References: <20090121220013.97061282EFC2@mail.pubhealth.ku.dk>
	<alpine.LFD.2.00.0901221153020.20762@toucan.stats.ox.ac.uk>
	<D8D645C3-B243-4D2F-877D-8C0F98ADB1D5@pixie.org.uk>
Message-ID: <21936538.post@talk.nabble.com>



Yan Wong-3 wrote:
> 
> On 22 Jan 2009, at 11:58, Brian D Ripley wrote:
> 
>> It is a bug on your system: this is done by cairographics, and I  
>> suspect that the version you have is broken (or possibly your viewer).
>> I'll attach the version I get, which does display in italics on my  
>> system.
> 
> Thanks for that. I do see italics in your file using my 2 viewers, so  
> I guess that the problem is not my viewer.
> 

At this point I should note that I can see this on Windows XP as well. Using
R 2.8.1 (CRAN binary version)  and version 1.4-4 of Cairo from CRAN (windows
binary).

It doesn't seem specific to SVG, I can reproduce it with pdf or png as well.

On R-SIG-Mac, Simon Urbanek wrote:
<https://stat.ethz.ch/pipermail/r-sig-mac/2009-January/005816.html>
> cairographics cannot locate an italic version of the font

The following testcase tends to show the contrary:

library(Cairo)
Cairo("plot.png", width=7, height=7, units="cm", dpi=100)
plot.new()
par(family="Arial")
text(0.5,0.4,labels=expression(italic("This should be in italics")))
text(0.5,0.6,labels=expression(bold("This should be in bold")))
dev.off()

The text that should be in italics is in bold, and vice versa. This makes me
think Cairo actually finds both italics and bold, but gets confused
somewhere...

I tried replacing Arial by Times or Tahoma, or removing the call to par(),
but italics and bold are always reversed (with the correct family used).
-- 
View this message in context: http://www.nabble.com/Italics-in-svg-output-display-as-bold-%28PR-13463%29-tp21602252p21936538.html
Sent from the R devel mailing list archive at Nabble.com.


From ripley at stats.ox.ac.uk  Tue Feb 10 17:05:44 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 10 Feb 2009 16:05:44 +0000 (GMT)
Subject: [Rd] Italics in svg output display as bold
In-Reply-To: <21936538.post@talk.nabble.com>
References: <20090121220013.97061282EFC2@mail.pubhealth.ku.dk>
	<alpine.LFD.2.00.0901221153020.20762@toucan.stats.ox.ac.uk>
	<D8D645C3-B243-4D2F-877D-8C0F98ADB1D5@pixie.org.uk>
	<21936538.post@talk.nabble.com>
Message-ID: <alpine.OSX.1.00.0902101601420.32473@tystie.local>

Sorry, but package Cairo is not what we were talking about here, and 
problem with that on Windowsare known (to several of us at least).

The report was about the svg() device in Unix-alike R.  Reports on the 
Cairo package need to be sent to its maintainer (Simon Urbanek) and 
I'e removed the misleading PR#.

On Tue, 10 Feb 2009, Xavier Robin wrote:

>
>
> Yan Wong-3 wrote:
>>
>> On 22 Jan 2009, at 11:58, Brian D Ripley wrote:
>>
>>> It is a bug on your system: this is done by cairographics, and I
>>> suspect that the version you have is broken (or possibly your viewer).
>>> I'll attach the version I get, which does display in italics on my
>>> system.
>>
>> Thanks for that. I do see italics in your file using my 2 viewers, so
>> I guess that the problem is not my viewer.
>>
>
> At this point I should note that I can see this on Windows XP as well. Using
> R 2.8.1 (CRAN binary version)  and version 1.4-4 of Cairo from CRAN (windows
> binary).
>
> It doesn't seem specific to SVG, I can reproduce it with pdf or png as well.
>
> On R-SIG-Mac, Simon Urbanek wrote:
> <https://stat.ethz.ch/pipermail/r-sig-mac/2009-January/005816.html>
>> cairographics cannot locate an italic version of the font
>
> The following testcase tends to show the contrary:
>
> library(Cairo)
> Cairo("plot.png", width=7, height=7, units="cm", dpi=100)
> plot.new()
> par(family="Arial")
> text(0.5,0.4,labels=expression(italic("This should be in italics")))
> text(0.5,0.6,labels=expression(bold("This should be in bold")))
> dev.off()
>
> The text that should be in italics is in bold, and vice versa. This makes me
> think Cairo actually finds both italics and bold, but gets confused
> somewhere...
>
> I tried replacing Arial by Times or Tahoma, or removing the call to par(),
> but italics and bold are always reversed (with the correct family used).
> --
> View this message in context: http://www.nabble.com/Italics-in-svg-output-display-as-bold-%28PR-13463%29-tp21602252p21936538.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From macrakis at alum.mit.edu  Tue Feb 10 18:07:36 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Tue, 10 Feb 2009 12:07:36 -0500
Subject: [Rd] Variable/function namespaces WAS: Bug in subsetting data frame
	(PR#13515)
Message-ID: <8b356f880902100907s7f21cd65vf57043f134273b20@mail.gmail.com>

On Tue, Feb 10, 2009 at 10:11 AM, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> Stavros Macrakis wrote:
>> On Tue, Feb 10, 2009 at 8:31 AM, Duncan Murdoch <murdoch at stats.uwo.ca>wrote:
>>> The evaluator recognizes the context of usage and will get the
>>> function for a function call....
>> Can you point me to chapter and verse in the language definition...
> No, I'm also unable to find it.

! This seems like a pretty fundamental thing to leave undocumented....

> ...I think originally there was no difference, and it caused the obvious trouble when people used variable names like t and c other short function names, so this was added.  I don't remember whether the different lookup rules showed up first in R or S.

There is an interesting discussion of these issues (in a Lisp context)
in "Technical Issues of Separation in Function Cells and Value Cells"
Lisp and Symbolic Computation 1:1:81 (6/1988) -- available at
http://www.nhplace.com/kent/Papers/Technical-Issues.html.  I don't
think an R-style approach is discussed there, though.

                -s


From wdunlap at tibco.com  Tue Feb 10 18:12:59 2009
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 10 Feb 2009 09:12:59 -0800
Subject: [Rd] Bug in subsetting data frame (PR#13515)
In-Reply-To: <4991993E.3010204@stats.uwo.ca>
References: <20090210102506.CB966282EF48@mail.pubhealth.ku.dk>	<8b356f880902100459n321c321ew1ee4ab3c9a7ddb0f@mail.gmail.com>	<499181C3.6000907@stats.uwo.ca><8b356f880902100651n79fa3b04x5754f79e8ac17658@mail.gmail.com>
	<4991993E.3010204@stats.uwo.ca>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D700A881F4@NA-PA-VBE03.na.tibco.com>

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Duncan Murdoch
> Sent: Tuesday, February 10, 2009 7:12 AM
> To: Stavros Macrakis
> Cc: xinlee883 at stat.math.ethz.ch; r-devel at stat.math.ethz.ch
> Subject: Re: [Rd] Bug in subsetting data frame (PR#13515)

[ lots deleted ]

> > Indeed!  It is quite surprising that functions are defined 
> using ordinary
> > assignment, but function lookup is different from normal variable
> > evaluation, e.g. that after c<-4, c(10) is different from 
> (c)(10).  Was this
> > inspired by some other language? I don't think it's done 
> this way in any
> > other language I can think of....
> I think originally there was no difference, and it caused the obvious 
> trouble when people used variable names like t and c other short 
> function names, so this was added.  I don't remember whether the 
> different lookup rules showed up first in R or S.
> 
> Duncan Murdoch

Splus 3.4 (July 1996, based on SV3 dated "Apr 30 09:54:11 EDT 1992")
distinguished function vs. non-function lookups.  E.g.,

  > f <- function(a,b,c) c(a,b,c)
  > f(11,12,13)
  [1] 11 12 13
  Warning messages:
     looking for function "c", ignored local non-function in: f(11, 12,
13)

I don't have easy access to any older version of S+.  Somewhere along
the line we dropped the warning.

Bill Dunlap
TIBCO Software Inc - Spotfire Division
wdunlap tibco.com 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From therneau at mayo.edu  Tue Feb 10 22:32:04 2009
From: therneau at mayo.edu (Terry Therneau)
Date: Tue, 10 Feb 2009 15:32:04 -0600 (CST)
Subject: [Rd] survival package
Message-ID: <200902102132.n1ALW4KM004088@crush.mayo.edu>

R core team -
  It took far, far longer than I anticipated, but I have finally finished the
next release of the survival code.  Primary changes

  1. The source has been migrated to Rforge.  This will now be the primary 
source.  I've used SCCS -> rcs -> cvs and now svn.  Further changes will be
someone else's problem.  I expect that maintaince will now begin to migrate
to a larger group and my role diminish; I hope to focus more energy on coxme.  
  I tried to carry forward the entire history of the package.  In the current
US software copyright mess we might one day have to use that long history. I
think I started the SCCS tree in around 1987.
  I expect to have survival, date, coxme, and bdsmatrix as separate packages
within the package tree.

  2. I have merged in a large number of changes/updates that had occured at
Mayo, along with all the changes I found in the R source (version 2.32 - when
I started this task, 2.34 when I finished).  Major changes
   Complete rewrite of the survfit function(s); most of the work is now done in
       S instead of C.  Added Turnbull's method for general censoring and also
       competing risk estimates.
   There are no longer any dependencies on the 'date' library, and it has been
       removed to a separate branch.  The expected survival routines now work 
       with any of Date, posix, timeDate, or date.
   Survreg was re-written to use R.h style instead of S.h.  Common code now
       works with both packages.  It's a big improvement in several ways:
       easier to code, much easier to read, less clunky.
   Aalen's additive regression model
   The survival rate tables have been updated -- the 2000 US rate tables were
       finally released in Aug 2008.
   There are 20-30 other small upgrades and fixes that had accrued over time.
	The file Changelog.09 has more details.

  3. I've tried very hard to make all the code work in both Splus and R.  Our 
group still uses Splus more than R so I have to support both.  However, I
think that with the recent change in Splus, which will focus them more on
vertical markets, and the uptake of R here due to the genetics libraries,
that this dual support will no longer be needed within 2-3 years.
   A year ago I would have defended the extra work necessary to make code
work in both dialects much more vigorously.  It isn't all that much work if
you think ahead.  Splus still has a presence in certain markets, and code that
works in both is good evangelism.  But -- said gain in utility keeps shrinking.
   In the R directory files that work with both are named whatever.S,
those tested only in R are .R.  If you think they should all be named
.R, then now is the time to do it.

  4. I am very impressed with the package system and R CMD check.  I had a 
cozy Splus/Unix enviroment with a custom makefile that made things very easy
and delayed my changeover.  This was a significant learning curve, but knowing 
what I know now I should have started earlier.   Kudos to you all.
   

  5. Known issues:
    i. An additional test suit (book5/book6) corresponding to the 
not-yet-published extension of my book's appendix of validity tests was
added.  It found an issue with "stderr of expected survival/Cox model with
noninteger case weights/Efron approximation".  Not yet addressed, of a
1/n vs 1/(n-1) size. 
   ii. The stderr of terms/survreg/penalized model is different between Splus
and R by 50% or more.  I haven't yet figured out which formula is correct.
   iii. The CMD check script still complains about some of my .Rd files; almost
all involve imperfect documentation of weights, subset, or ... options.  I've
been working on this very hard for the last month, and just can't raise any
excitment about these last few warnings at the moment.

 Both i and ii exist in the current R code, so there is no loss in updating
before working them out.


	Terry T


From murdoch at stats.uwo.ca  Wed Feb 11 00:34:26 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 10 Feb 2009 18:34:26 -0500
Subject: [Rd] Variable/function namespaces WAS: Bug in subsetting data
 frame	(PR#13515)
In-Reply-To: <8b356f880902100907s7f21cd65vf57043f134273b20@mail.gmail.com>
References: <8b356f880902100907s7f21cd65vf57043f134273b20@mail.gmail.com>
Message-ID: <49920F02.3050603@stats.uwo.ca>

On 10/02/2009 12:07 PM, Stavros Macrakis wrote:
> On Tue, Feb 10, 2009 at 10:11 AM, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>> Stavros Macrakis wrote:
>>> On Tue, Feb 10, 2009 at 8:31 AM, Duncan Murdoch <murdoch at stats.uwo.ca>wrote:
>>>> The evaluator recognizes the context of usage and will get the
>>>> function for a function call....
>>> Can you point me to chapter and verse in the language definition...
>> No, I'm also unable to find it.
> 
> ! This seems like a pretty fundamental thing to leave undocumented....

In open source nothing is undocumented, but sometimes the documentation 
is a little hard to read.  I think you want to look at the 
https://svn.r-project.org/R/trunk/src/main/eval.c section of the manual.

More seriously, I agree, but I don't have time to fix the omission.  If 
you work out a logical (from your point of view) place to put this, and 
write a first draft in texinfo format, I'll put it in.

Duncan Murdoch

> 
>> ...I think originally there was no difference, and it caused the obvious trouble when people used variable names like t and c other short function names, so this was added.  I don't remember whether the different lookup rules showed up first in R or S.
> 
> There is an interesting discussion of these issues (in a Lisp context)
> in "Technical Issues of Separation in Function Cells and Value Cells"
> Lisp and Symbolic Computation 1:1:81 (6/1988) -- available at
> http://www.nhplace.com/kent/Papers/Technical-Issues.html.  I don't
> think an R-style approach is discussed there, though.
> 
>                 -s
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From h.miller at ms.unimelb.edu.au  Wed Feb 11 00:40:10 2009
From: h.miller at ms.unimelb.edu.au (h.miller at ms.unimelb.edu.au)
Date: Wed, 11 Feb 2009 00:40:10 +0100 (CET)
Subject: [Rd] PPR crash (PR#13517)
Message-ID: <20090210234010.7DA82282EF48@mail.pubhealth.ku.dk>

Full_Name: Hugh Miller
Version: 2.8.1
OS: XP
Submission from: (NULL) (128.250.24.101)


Hi there,

I've been looking at approaches that use the projection pursuit regression
function fairly (ppr) heavily, and have discovered that it crashes my R system
on occasion. It only happens with the inputs are pathological in some way I
don't understand. I have pasted such an example below.

Any help gratefully appreciated.

Regards,
Hugh

### I run the following code to obtain the crash:
bad <- read.csv("C:\\My directories\\bad.csv")
bady <- bad[,3]
badx <- bad[,1:2]

ppr(badx,bady, nterms=1)


### This is the data I read in from the bad.csv file:
"","","bady"
"1",-0.0348207628376986,1,-0.542937988158036
"2",-0.0191633397482220,2,-0.169266091065016
"3",-0.0341944659141195,1,-0.275406839429961
"4",0.0249905933641021,2,0.384150222915368
"5",0.0155961395104161,2,0.2341732751562
"6",-0.0792878444118122,2,-0.021997198276666
"7",-0.0248000120604336,1,0.399971463068032
"8",0.108914381123697,1,-0.623493578304602
"9",0.00620168565673016,1,-0.402266282137639
"10",-0.034507614375909,2,1.08390058914255
"11",-0.0905611890362353,2,0.024273472328843
"12",0.0459715403040008,1,-0.448251018679603
"13",-0.00976888589453599,2,0.70163011189378
"14",-0.0157187066685371,1,0.123718062829826
"15",-6.12835790604833e-05,2,0.0929302960910126
"16",0.107661787276539,1,0.0445186997621552
"17",-0.0238605666750649,2,-0.268966040102523
"18",0.0494161733836856,1,-0.244466585236197
"19",-0.0194764882100115,2,-0.272492268970116
"20",-0.0113346282034837,2,0.58637312706044
"21",-0.043275771306016,2,-0.388224863429526
"22",-0.0263657543693812,1,-0.439522809120621
"23",0.00776742796567782,2,-0.354209517739221
"24",-0.0473467013092799,1,-0.166859766555732
"25",-0.0188501912864324,2,0.265535097126863
"26",0.0046359433477825,1,0.342255739372447
"27",-0.0961978613484469,2,0.328193133923304
"28",-0.0435889197678055,2,-0.738100695537103
"29",-0.0376390989938044,2,0.0492751978645918
"30",-0.0958847128866574,1,0.846962244613297
"31",-0.00757684666200928,2,-0.311395214189561
"32",-0.0536096705450705,2,-0.197180299226387
"33",-0.0129003705124313,1,0.770727634055679
"34",-0.0899348921126563,2,-0.214099277802346
"35",-0.0489124436182275,2,-0.328796268354374
"36",-0.00413221358232442,1,-0.123798883552826
"37",-0.0285577936019079,2,0.557326881019212
"38",-0.0429626228442264,2,0.910078165810043
"39",0.0754074957122168,1,0.0625474905222085
"40",0.00620168565673016,1,-0.660060421124099
"41",0.07321545647969,1,-0.648765887241763
"42",-0.072711726714232,2,-0.291387183530275
"43",-0.0235474182132754,1,-0.580764200095337
"44",-0.0100820343563255,2,-0.213881238361436
"45",0.0046359433477825,1,0.342219498341999
"46",0.00150445872988718,1,-0.627738756029472
"47",-0.0476598497710694,2,0.638490421487924
"48",-0.0742774690231797,2,0.366998080026886
"49",0.00588853719494063,1,-0.192002931323743
"50",0.00620168565673016,1,-0.42703489754501
"51",-0.0373259505320149,2,0.399143495901645
"52",-0.029184090525487,1,0.259085862758254
"53",0.0447189464568426,2,-0.52960117919881
"54",0.0221722572079963,2,-0.358445653831134
"55",0.0177881787429428,2,0.299979528574020
"56",-0.0226079728279068,2,0.34651271103047
"57",-0.0304366843726451,2,-1.28260529016723
"58",-0.104339721354975,2,-0.469681693832029
"59",-0.057993749010124,2,0.572875739287276
"60",0.048476727998317,1,0.318516539900054
"61",-0.0786615474882331,2,-0.51629774307693
"62",-0.0273051997547498,1,-0.238363914682604
"63",-0.0138398158977999,1,-0.278262054849107
"64",0.0434663526096845,2,0.240351359037258
"65",-0.0598726397808612,1,-0.439820093575709
"66",0.0149698425868371,1,-0.089734626673025
"67",0.0121515064307313,1,0.157744469530662
"68",0.00839372488925688,1,-0.147761547457720
"69",-0.0241737151368545,1,0.640629492509571
"70",-0.0614383820898088,2,0.721507998029808
"71",-0.00914258897095694,2,-0.391891463942708
"72",0.0262431872112602,2,0.409309553303869
"73",0.0487898764601065,1,0.218024247023677
"74",0.05317395492516,1,-0.149519213731968
"75",0.0171618818193638,1,-0.647105867961298
"76",-0.00100072896442909,1,-0.711807768742965
"77",-0.106844909049291,1,-0.0568622733771722
"78",-0.0276183482165393,2,0.95979439504761
"79",-0.0683276482491785,2,1.05882959546064
"80",0.0199802179754696,2,0.202513236360187
"81",0.0534871033869495,2,-0.160509136618631
"82",0.0284352264437869,1,-0.585827752105968
"83",0.0171618818193638,2,-0.346456582878112
"84",-0.0529833736214915,2,0.597901713985014
"85",-0.0301235359108556,2,-0.132649008239744
"86",-0.00100072896442909,2,-0.289025947256112
"87",-0.0150924097449580,1,-0.255121884845899
"88",0.0162224364339952,2,-0.136854078336641
"89",-0.0370128020702253,1,-0.677430950151256
"90",-0.0160318551303266,2,0.0753389806448792
"91",-0.0451546620767532,2,0.100243021636830
"92",0.0647604480113727,2,-0.125255305348025
"93",-0.0207290820571696,2,-1.0505758255551
"94",-0.0154055582067476,2,0.16885039497003
"95",-0.0135266674360104,2,-0.169309597945285
"96",-0.0288709420636975,2,0.369854431600131
"97",-0.0122740735888523,1,-0.566282851696723
"98",0.0425269072243159,2,0.556556637552114
"99",-0.0138398158977999,1,-0.343832598689341
"100",0.0375165318356834,2,-0.268130829056743
"101",0.0444057979950531,2,-0.365938550530639
"102",-0.00037443204085002,1,-0.0311681764689511
"103",0.0249905933641021,2,1.22944913120819
"104",0.0707102687853738,1,0.201090437227192
"105",-0.0172844489774848,2,-0.594182131644277
"106",-0.0216685274425382,1,-0.488925578404151
"107",-0.0348207628376986,2,0.400182859035963
"108",0.0406480164535787,2,0.0155260921851867
"109",-0.0558017097775973,1,0.1349613580299
"110",0.0375165318356834,1,-0.604279409412377
"111",-0.0401442866881206,1,0.0912229513254876
"112",0.0102726156599941,2,-0.585827187420521
"113",0.0196670695136800,2,0.821569273382661
"114",0.0202933664372591,1,0.779534939715196
"115",-0.0329418720669614,2,-0.0427576052327692
"116",0.0494161733836856,1,0.34552055454062
"117",0.0206065148990486,1,0.627600258862538
"118",0.0315667110616823,2,0.560348866635563
"119",0.0400217195299996,1,0.136561803275829
"120",-0.0429626228442264,2,0.586659396678506
"121",-0.0185370428246429,2,0.751858555892416
"122",0.0215459602844172,2,-0.0346520027699464
"123",0.0641341510877936,1,-0.475034031350191
"124",0.198787989657293,1,-0.96267443600314
"125",-0.0388916928409625,2,-0.446966403216099
"126",-0.0636304213223356,1,-0.105229435869263
"127",-0.0545491159304391,2,0.111213728568517
"128",0.0137172487396789,1,-0.225021888807548
"129",-0.005071658967693,2,0.192382971695893
"130",0.0105857641217836,2,0.544550640526851
"131",-0.00475851050590347,1,0.169227048178445
"132",-0.0107083312799046,2,0.645013058812764
"133",0.047850431074738,1,-0.0235134031161297
"134",-0.0717722813288634,1,-0.0630297490026158
"135",0.000251864882729031,2,-0.371022927651655
"136",-0.0429626228442264,2,0.481214559043027
"137",-0.068014499787389,2,0.00232117243748586
"138",-0.0163450035921162,2,0.603296973022765
"139",-0.03388131745233,1,0.689463397801391
"140",-0.0489124436182275,2,0.584785784895232
"141",-0.00131387742621863,1,-0.362779810283891
"142",0.0572448849284239,2,0.810287091899672
"143",0.0444057979950531,1,0.549297270778805
"144",0.00682798258030921,2,-0.383606471237968
"145",0.0506687672308438,1,0.0628969594709541
"146",-0.0326287236051719,2,0.307802130858709
"147",0.0315667110616823,1,-0.0491288740872056
"148",0.0234248510551544,2,-0.886174605827197
"149",0.0481635795365275,1,-0.353063829906177
"150",-0.0204159335953801,1,-0.373480626840549
"151",-0.0144661128213790,2,1.00020535625734
"152",-0.0238605666750649,2,-0.37293648383054
"153",0.0669524872438994,1,0.970846742038665
"154",0.0162224364339952,1,-0.288023336074307
"155",0.0262431872112602,1,0.234872138823723
"156",0.0863676918748504,1,-0.124107339307035
"157",-0.0357602082230672,2,-0.860582860820529
"158",0.0428400556861055,1,-0.297747269417959
"159",0.0168487333575743,2,0.109903610414647
"160",0.00714113104209875,2,-0.206224671104973
"161",-0.0132135189742209,2,-0.327867194019532
"162",0.131461070372543,1,-0.213564690106344
"163",-0.0113346282034837,2,0.188385676330015
"164",0.00557538873315109,1,-0.628807957951394
"165",-0.0135266674360104,2,0.669583796395588
"166",-0.043275771306016,2,-0.343884620646265
"167",-0.0708328359434948,1,-0.190185480431738
"168",0.00150445872988718,2,-0.320328578790684
"169",0.063194705702425,1,0.323386845722763
"170",-0.0160318551303266,2,-0.466837070291079
"171",-0.0150924097449580,1,-0.443407572986743
"172",-0.0598726397808612,2,-0.134811390846991
"173",0.0159092879722056,1,0.482090992234558
"174",-0.0664487574784414,1,-0.0170463331877988
"175",-0.0946321190394993,1,-0.190324801658185
"176",-0.0263657543693812,2,0.133819910273860
"177",0.0259300387494707,1,0.635173662501035
"178",0.0184144756665219,2,0.00228391995819166
"179",0.0162224364339952,2,-0.258437031861175
"180",0.0412743133771578,2,0.0283400108555913
"181",0.00588853719494063,1,-0.645215565877466
"182",0.0500424703072647,2,-0.291670337298211
"183",0.0891860280309562,1,-0.327065894289160
"184",-0.00162702588800815,1,0.242737144450905
"185",-0.0260526059075917,2,0.57810653696704
"186",-0.0248000120604336,1,-0.541941213451622
"187",0.0575580333902134,1,-0.633212087112255
"188",-0.082106180567918,2,0.500496715369151
"189",0.0707102687853738,2,-0.052842886971195
"190",0.00307020103883484,2,-0.244280532233061
"191",-0.005071658967693,2,1.13589518632790
"192",-0.0761563597939169,1,0.516233237416555
"193",0.0212328118226277,1,-0.120931696200069
"194",0.0838625041805342,1,-0.298112413451003
"195",-0.0495387405418066,2,-0.460823957234195
"196",0.048476727998317,1,-0.53750964944165
"197",0.0362639379885253,2,-0.222956248715534
"198",0.0134041002778894,1,-0.534628063085933
"199",-0.03388131745233,2,-0.00536312114999693
"200",-0.0157187066685371,2,-0.601310067820068
"201",0.0491030249218961,2,0.51371538232261
"202",-0.00788999512379879,1,-0.443235207931272
"203",0.0910649188016934,1,-0.0545450835543364
"204",0.0566185880048449,1,0.159594834986961
"205",-0.00726369820021974,1,0.817680352105999
"206",-0.0470335528474903,2,-0.920940961348847
"207",0.038455977221052,1,0.206785551831567
"208",-0.0138398158977999,2,0.0786089094577416
"209",0.0378296802974729,2,-0.517512336320252
"210",-0.0166581520539057,1,-0.69987268730616
"211",0.0472241341511589,2,0.594013625246057
"212",-0.0166581520539057,2,-0.832652369978527
"213",0.0312535625998928,2,-0.646413025368303
"214",-0.00100072896442909,2,-0.440536367839533
"215",-0.0811667351825494,2,-0.279369474909596
"216",-0.0320024266815928,1,-0.0452140231102436
"217",0.0741549018650587,1,0.137324260072112
"218",0.0368902349121043,2,0.699084005257896
"219",0.014343545663258,2,0.809085151068957
"220",-0.0742774690231797,2,0.605749454506367
"221",-0.0332550205287509,1,-0.124684466736664
"222",0.000878161806308105,2,-0.181486885774829
"223",-0.0476598497710694,1,1.04353748120419
"224",-0.0601857882426507,2,0.288952596833982
"225",-0.0413968805352788,2,-0.104429039490037
"226",-0.0435889197678055,1,0.0800869382183447
"227",-0.0248000120604336,1,-0.144169895377154
"228",-0.0157187066685371,1,-0.0464432100385457
"229",0.00808057642746734,2,0.478240259012026
"230",-0.000687580502639557,1,-0.467440941086978
"231",0.155886650392127,1,0.239431491079654
"232",0.00870687335104641,2,0.2562547807972
"233",0.0572448849284239,1,0.86860230418135
"234",-0.034507614375909,2,-0.423459070947301
"235",-0.0241737151368545,2,0.310211050362970
"236",-0.034507614375909,1,-0.295906130057979
"237",0.0707102687853738,2,-0.86617486548278
"238",-0.00100072896442909,2,-0.121778887044718
"239",-0.00757684666200928,1,0.776213597614415
"240",0.0387691256828415,2,0.509279639297807
"241",-0.00225332281158722,1,0.465384478561689
"242",0.0274957810584184,1,0.469496518921371
"243",-0.0677013513255995,1,-0.308746203780249
"244",-0.0160318551303266,1,-0.46235848664352
"245",-0.0489124436182275,1,0.205409229630935
"246",-0.058620045933703,2,0.261398866276518
"247",0.0509819156926333,2,-0.440149176757358
"248",-0.0185370428246429,2,-0.340825239203231
"249",0.128016437292858,2,0.273551295992088
"250",0.0293746718291555,2,-0.0150998906400583
"251",-0.039204841302752,2,0.576834918553312
"252",0.0487898764601065,1,-0.205915937224996
"253",0.0528608064633705,2,-0.553196865177558
"254",0.0566185880048449,2,-0.543721288333984
"255",-0.0122740735888523,1,0.522487158063439
"256",-0.0194764882100115,2,0.463745159249026
"257",-0.0197896366718010,2,0.841549445924151
"258",-0.0235474182132754,1,-0.453687910246368
"259",0.0528608064633705,1,-0.458440156334343
"260",0.0129343775852051,2,-0.467864695867239
"261",-0.0313761297580137,2,-0.472283529481048
"262",-0.0257394574458021,2,-0.186430934773366
"263",0.0174750302811533,1,0.321642638528018
"264",-0.0326287236051719,1,0.352069267692134
"265",-0.00976888589453599,1,0.02668959086612
"266",-0.00287961973516629,1,-0.556132391455717
"267",-0.0366996536084358,1,-0.387257292601137
"268",0.0794784257154807,2,-0.324131357308187
"269",0.0375165318356834,1,0.0827698839729645
"270",-0.0103951828181151,2,-0.093755609745107
"271",-0.0473467013092799,1,0.191572236429703
"272",-0.0210422305189592,1,-0.259424141806862
"273",-0.0664487574784414,2,0.29937915243771
"274",0.0328193049088404,1,0.376184708733085
"275",-0.00319276819695581,2,-0.683575654018569
"276",-0.0154055582067476,1,-0.64142305877968
"277",0.0916912157252725,2,0.811986459824865
"278",-0.078035250564654,2,-0.298077785935728
"279",0.0196670695136800,1,-0.0758214988112154
"280",-0.0263657543693812,1,0.827132228117798
"281",0.0105857641217836,1,0.689895342645724
"282",-0.0304366843726451,1,-0.184184898826604
"283",0.102964560349696,2,0.847194957424707
"284",-0.0363865051466462,2,0.806409840008277
"285",-0.0451546620767532,1,0.0827048684085705
"286",0.0212328118226277,2,0.552824579772346
"287",-0.0864902590329714,2,-0.354242885013583
"288",0.125198101136752,2,0.653520053265854
"289",0.0563054395430553,1,-0.235849267757233
"290",0.05317395492516,1,-1.15340165541335
"291",0.0168487333575743,1,0.961697254069715
"292",0.0428400556861055,2,0.461276319877892
"293",-0.0686407967109681,2,-0.0341884331315262
"294",0.0425269072243159,2,0.19050070101563
"295",0.0177881787429428,1,-0.320894539927312
"296",-0.0129003705124313,1,-0.687711338067914
"297",-0.024486863598644,2,-0.0112816932009854
"298",-0.024486863598644,2,-0.628420721133336
"299",-0.0755300628703378,1,0.108339202697929
"300",-0.0219816759043277,1,-0.299121148314735
"301",-0.0135266674360104,2,0.504288281290109
"302",0.0300009687527346,1,-0.49674221648836
"303",0.0271826325966288,2,-0.0648277245363391
"304",0.0202933664372591,2,0.0653229380005493
"305",0.116429944206646,1,1.09697612700141
"306",0.0162224364339952,1,-0.0578323225188244
"307",-0.0248000120604336,1,-0.716688114767039
"308",0.0356376410649462,1,0.0874474382931314
"309",-0.0814798836443389,2,0.128350908869302
"310",0.0700839718617947,1,-0.114604975474514
"311",0.0149698425868371,2,-0.62242646270281
"312",0.0606895180081088,2,0.103579664573858
"313",-0.0141529643595894,2,0.266005125434976
"314",0.0196670695136800,1,-0.413634930912108
"315",-0.00100072896442909,2,0.0151321906456678
"316",0.0206065148990486,2,-0.0673849072308246
"317",-0.0213553789807487,1,0.0135990739864607
"318",0.0741549018650587,2,0.324087630938248
"319",0.00870687335104641,2,-0.427399230946266
"320",-0.0545491159304391,2,0.042775486747467
"321",0.092004364187062,2,-0.605344789864081
"322",0.0365770864503148,2,-0.204436152405274
"323",-0.0360733566848567,1,-0.226138837001874
"324",-0.00444536204411395,1,0.170709352903985
"325",0.077912683406533,2,0.537519459868399
"326",0.0566185880048449,2,-0.147282475494555
"327",0.00119131026809764,1,-0.323430494775891
"328",0.0249905933641021,2,0.108292017818686
"329",-0.0232342697514859,2,-0.826538205190531
"330",-0.029184090525487,1,0.24584441334714
"331",0.0368902349121043,1,0.573723086073314
"332",-0.0464072559239113,1,0.79656132242823
"333",-0.0113346282034837,2,0.00946238474567895
"334",-0.00162702588800815,1,-0.124520035965299
"335",-0.0576806005483345,1,-0.259878130786406
"336",-0.00663740127664067,2,0.0555307997381935
"337",0.0894991764927457,2,0.555424791964305
"338",0.00714113104209875,1,-0.636112973637205
"339",0.0240511479787335,2,0.873339312894887
"340",0.0566185880048449,2,-0.394814482694516
"341",-0.00381906512053488,2,0.739017674428192
"342",0.00119131026809764,1,0.708961041328093
"343",0.0181013272047324,1,0.00403126578142898
"344",0.00870687335104641,2,-0.276137519375382
"345",0.0644472995495832,2,0.502910779173363
"346",0.057871181852003,1,-0.0156541427576098
"347",0.127390140369279,1,-0.461785423626198
"348",-0.0125872220506418,1,-0.169076596135421
"349",-0.0294972389872765,2,0.350512955716197
"350",-0.0470335528474903,1,-0.124228415607815
"351",-0.0175975974392743,1,-0.131461613178762
"352",-0.0695802420963367,1,-0.205628872696091
"353",-0.0971373067338155,1,-0.0878584523532161
"354",-0.00319276819695581,2,-0.495971604169367
"355",0.0888728795691667,1,0.453324913491325
"356",-0.0216685274425382,1,-0.458564307257987
"357",0.0162224364339952,1,-0.556629174086865
"358",-0.0301235359108556,1,0.169271197644518
"359",-0.0341944659141195,2,0.0657618936180249
"360",0.0174750302811533,1,1.25141355432077
"361",-0.0132135189742209,2,0.652499667425962
"362",-0.0482861466946485,2,0.704038829561223
"363",-0.0266789028311707,1,0.669786704168092
"364",-0.0282446451401184,1,-0.825099908269144
"365",0.00494909180957202,1,0.878493590561456
"366",0.00526224027136155,2,0.460202718189125
"367",0.0318798595234718,1,-0.281858889818106
"368",0.033758750294209,1,-0.235429645519174
"369",-0.0100820343563255,1,-0.749168455422644
"370",-0.00381906512053488,2,0.0138580627952098
"371",-0.0125872220506418,2,-0.222636705057443
"372",-0.0191633397482220,1,-0.102899440319366
"373",0.0127778033543103,1,-0.364792071375576
"374",-0.0570543036247554,2,0.418437419922108
"375",-0.0705196874817053,2,0.148241329965757
"376",0.0224854056697859,1,0.430891807354808
"377",0.130208476525385,2,-0.741549127948163
"378",0.0447189464568426,1,0.684173593258704
"379",0.0108989125835731,1,0.72101144786046
"380",-0.115613065979398,2,-0.657949812502163
"381",-0.0442152166913845,2,-0.896421924067635
"382",-0.0257394574458021,1,0.0962925069688172
"383",-0.072711726714232,2,-1.00276025631586
"384",-0.0288709420636975,1,-0.157806820134940
"385",0.0869939887984295,1,-0.445362055938887
"386",-0.0611252336280193,1,0.84021857926248
"387",-0.0175975974392743,2,-0.251533189535103
"388",-0.0172844489774848,2,0.758893789787943
"389",-0.005071658967693,1,-0.395976152709988
"390",-0.0166581520539057,1,-0.362704477405226
"391",-0.0232342697514859,1,0.240165673609364
"392",-0.0504781859271752,2,-0.155741439704364
"393",0.0365770864503148,1,0.0385290544410537
"394",-0.0232342697514859,2,-0.238860553149526
"395",-0.0545491159304391,2,0.293301706277455
"396",-0.0216685274425382,2,0.831706790819527
"397",-0.0542359674686496,1,-0.440514782297251
"398",-0.0583068974719135,2,0.218870588212521
"399",0.0321930079852613,2,0.500744829653927
"400",0.0118383579689417,1,0.262479865365506
"401",-0.0354470597612776,2,0.0459955002977468
"402",-0.05392281900686,2,-0.0247330661767469
"403",0.0202933664372591,1,0.170742902946737
"404",-0.0238605666750649,2,0.199286515264368
"405",-0.0279314966783289,2,1.08912576788426
"406",-0.10089508827529,1,0.114498290097875
"407",-0.0370128020702253,2,-0.0846106975545163
"408",0.0397085710682101,2,-0.341931668571862
"409",0.0193539210518905,2,0.161218178259627
"410",0.0729023080179005,1,0.0829112288198928
"411",0.0372033833738938,1,0.480091172076597
"412",-0.0723985782524425,2,-0.182281092461526
"413",0.0130909518160999,2,0.301199977328185
"414",0.00714113104209875,2,0.0875330300958936
"415",0.117056241130225,1,-0.464798937851476
"416",0.0472241341511589,2,0.0928613558403242
"417",0.0181013272047324,2,0.518938399652306
"418",-0.00131387742621863,2,-0.915794067370554
"419",0.0941964034195887,2,-0.0849758660905434
"420",-0.0573674520865449,2,-0.557819575895558
"421",0.0346981956795776,2,0.146580008210001
"422",0.0450320949186321,1,0.180578242378216
"423",0.0644472995495832,1,0.207776620969095
"424",0.0735286049414796,1,-0.392666088043916
"425",-0.00381906512053488,1,-0.627260070295178
"426",-0.112794729823292,2,0.260190647274243
"427",0.0688313780146366,1,-0.386184997207579
"428",-0.062690975936967,1,-0.503984283937765
"429",0.0215459602844172,1,0.297983166681027
"430",0.0415874618389473,2,-0.126484961821684
"431",0.0453452433804217,2,0.576267745573508
"432",-0.0470335528474903,1,-0.461945840462522
"433",0.0447189464568426,2,-0.484434347988346
"434",0.0199802179754696,2,-0.180198683463334
"435",0.0108989125835731,2,-0.556213330349359
"436",0.0046359433477825,2,-0.47603482348101
"437",-0.0470335528474903,2,-0.290496276509039
"438",-0.00256647127337676,1,-0.174951863141946
"439",0.0791652772536912,1,-0.0941605505892384
"440",-0.0138398158977999,1,0.0900586677437571
"441",0.0152829910486266,2,0.283684348322489
"442",0.0278089295202079,2,-0.215872199044323


From Thomas.Petzoldt at TU-Dresden.de  Wed Feb 11 07:50:35 2009
From: Thomas.Petzoldt at TU-Dresden.de (Thomas Petzoldt)
Date: Wed, 11 Feb 2009 07:50:35 +0100
Subject: [Rd] New package test results available
In-Reply-To: <498DC53B.9050909@TU-Dresden.de>
References: <alpine.LFD.2.00.0902070651160.18308@gannet.stats.ox.ac.uk>
	<498DC53B.9050909@TU-Dresden.de>
Message-ID: <4992753B.10304@TU-Dresden.de>

Thomas Petzoldt wrote:
> Prof Brian Ripley schrieb:
>> We've added a column at
>>
>> http://cran.r-project.org/web/checks/check_summary.html
>>
>> of test results using the Sun Studio compiler: it is intended that 
>> these will be updated weekly.
>>
>> The Sun Studio compiler is that used on Solaris: these runs were on 
>> the Linux version.  All the other platforms are using gcc 4, so this 
>> provides an opportunity for checking for use of gcc-specific features 
>> and also standards conformance (the Sun compilers have a long-time 
>> reputation for close conformance to the language standards).
>>
>> There are known problems where packages use C++ or JNI interfaces 
>> (e.g. rgdal and EBImage) as the libraries and JVM were compiled under 
>> gcc's conventions (even though a Sun JVMi is used).  About half the 
>> packages using rJava segfault, which seems to a JNI issue.
>>
>> Some packages use gcc-specific compiler flags:
>>
>>   LogConcDEAD Matching amap geometry memisc taskPR
>>
>> but the vast majority of the errors reported are C++ errors.  One 
>> class that may not be immediately obvious is the use of C headers in 
>> C++: you are supposed to write e.g.
>>
>> #includd <cmath>
>>
>> NOT
>>
>> #include <math.h>
>>
>> Symptoms of this can be seen for packages
>>
>>   BayesTree EMCC MCMCfglmm MarkedPointProcess Matching Matrix
>>   RQuantlib RandomFields Rcpp SoPhy compHclust dpmix igraph minet
>>   mixer modeest monomvm multic pcaPP rgenoud robfilter segclust
>>   simecol subselect
>>
>>
> 
> The reason can also be including <R.h> (as done in simecol) that 
> includes <math.h>
> 
> Do I understand it correctly that this means that including <R.h> is 
> wrong in C++?
> I read "Writing R extensions" several times, but was not aware that this 
> was a mistake. If I replace <R.h> by <cmath> then it works on my 
> systems, but I want to be certain that there are no other side effects.
> 
> Thanks in advance for clarification!
> 
> Thomas Petzoldt
> 
> 

I changed it as requested, and include

#include <cmath>
#include <Rinternals.h>

... but still get the same error:

"simecol.cpp", line 224: Error: Overloading ambiguity between 
"floor(double)" and "std::floor(float)".
1 Error(s) detected.

http://www.r-project.org/nosvn/R.check/r-devel-linux-x86_64-sun/simecol-00install.html

What's wrong here? My code is very short and extremely simple, without 
any new objects (yet), but fact only "plain C with some C++" extension.

What I'm making wrong? Would it be necessary that we all have a Linux 
installation with Sun Studio at hand?

Thanks a lot

Thomas P.

-- 
Thomas Petzoldt
Technische Universitaet Dresden
Institut fuer Hydrobiologie        thomas.petzoldt at tu-dresden.de
01062 Dresden                      http://tu-dresden.de/hydrobiologie/
GERMANY


From osklyar at maninvestments.com  Wed Feb 11 13:25:51 2009
From: osklyar at maninvestments.com (Sklyar, Oleg (London))
Date: Wed, 11 Feb 2009 12:25:51 -0000
Subject: [Rd] setClassUnion with numeric; extending class union
Message-ID: <1A68FCB28DE72F4BA3B967E6506CCE43047DF65F@mildnpexmb01.maninvestments.ad.man.com>

Dear list:

I am looking for a good way to create an S4 class that would extend
numeric, but would allow NULL instead of data as well. As far as I can
see there is no way at the moment to do that, but please correct me if I
am wrong. The best solution I came up with so far was the following (it
also indicates a problem of using setClassUnion with numeric as one of
the classes):

I define a class union of numeric and NULL:

Unfortunately the following works only with warnings:
setClassUnion("numericOrNULL", c("numeric","NULL"))

So I do a workaround as:

setClass("aNumeric", contains="numeric")
setClassUnion("numericOrNULL", c("aNumeric","NULL"))

Then I cannot really extend the above virtual class and can only use it
in a user-defined slot as follows:

setClass("myClass", representation(data="numericOrNULL"))
new("myClass", data=runif(20))
new("myClass", data=NULL)

and this works.

Obviously it would be nicer to have something like the following:

setClass("myClass", contains="numericOrNULL")
new("myClass", runif(20)) ## .Data is not a slot of myClass
setClass("myClass", representation("numericOrNULL"))
new("myClass", runif(20)) ## ibid

Technically I understand that the reason behind it failing to work is
that the virtual class numericOrNULL has not got the .Data slot from
numeric, but it would be nice to have such a functionality.

Any ideas about better ways for solving such a problem than the one
described above?

Thanks.

Best,
Oleg

Dr Oleg Sklyar
Research Technologist
AHL / Man Investments Ltd
+44 (0)20 7144 3107
osklyar at maninvestments.com

**********************************************************************
Please consider the environment before printing this email or its attachments.
The contents of this email are for the named addressees ...{{dropped:19}}


From lpagie at xs4all.nl  Wed Feb 11 16:10:09 2009
From: lpagie at xs4all.nl (lpagie at xs4all.nl)
Date: Wed, 11 Feb 2009 16:10:09 +0100 (CET)
Subject: [Rd] p.adjust; n > length(p) (PR#13519)
Message-ID: <20090211151009.DDC63284A70A@mail.pubhealth.ku.dk>

Full_Name: Ludo Pagie
Version: 2.8.1
OS: linux
Submission from: (NULL) (194.171.7.39)


p.adjust in stats seems to have a bug in handling n>length(p) for (at least) the
methods 'holm' and 'hochberg'.

For method 'holm' the relevant code:
        i <- 1:n
        o <- order(p)
        ro <- order(o)
        pmin(1, cummax((n - i + 1) * p[o]))[ro]

where p is the supplied vector of pvalues and n is the supplied number of
comparisons. If n>length(p) p.adjust() gives a warning:
Warning message:
In (n - i + 1) * p[o] :
  longer object length is not a multiple of shorter object length

to me it seems that instead of 'i <- 1:n', 'i <- 1:length(p)' is required.
Similar cases seem to be true for 'hochberg' and possibly other methods.

(I tried checking whether this bug has been reported but the website broke on
me. appologies if the bug is known already)

Best, Ludo

Netherlands Cancer Institute
Gene Regulation (B4)
van Steensel Group
Plesmanlaan 121
1066 CX Amsterdam
The Netherlands

Tel.: ++ 20 512 7986
Fax:  ++ 20 669 1383
email: lpagie at xs4all.nl


From macrakis at alum.mit.edu  Wed Feb 11 17:53:50 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Wed, 11 Feb 2009 11:53:50 -0500
Subject: [Rd] gc(reset=TRUE) reset timing
Message-ID: <8b356f880902110853v419c78fvbcab0aecd10b621a@mail.gmail.com>

The man page for gc reads:

     The final two columns show the maximum space used since the last
     call to 'gc(reset=TRUE)' (or since R started).

The word 'last' here is ambiguous: does it include the *current* call
to gc?  When I first read this, I assumed that it did not; indeed, I
only realized that there was an ambiguity after trying to use
reset=TRUE for some measurements and discovering that the
implementation corresponds to a reading where it *does* include the
current call to gc. (see below for transcript)

The interpretation that 'last' does *not* include the current call
seems more useful than the implemented behavior, since with the
implemented behavior, to report maximum memory usage for each of a
series of operations, you need to make *2* calls to GC between
operations, one with reset=FALSE (to return the maximum space used)
and one with reset=TRUE (to perform the reset for the next
measurement).

So I suggest that the reset happen only *after* the "max used"
calculation.  Alternatively, the documentation could be clarified.

           -s

{gc(reset=T); numeric(10^7); gc(reset=FALSE)["Vcells","max used"]}
[1] 10353316                        <<< shows max used by numeric

> {gc(reset=T); numeric(10^7); gc(reset=TRUE)["Vcells","max used"]}
[1] 353329                            <<< does not show max used by numeric


From jmc at r-project.org  Wed Feb 11 20:46:54 2009
From: jmc at r-project.org (John Chambers)
Date: Wed, 11 Feb 2009 11:46:54 -0800
Subject: [Rd] setClassUnion with numeric; extending class union
In-Reply-To: <1A68FCB28DE72F4BA3B967E6506CCE43047DF65F@mildnpexmb01.maninvestments.ad.man.com>
References: <1A68FCB28DE72F4BA3B967E6506CCE43047DF65F@mildnpexmb01.maninvestments.ad.man.com>
Message-ID: <49932B2E.5090703@r-project.org>

What warnings? Which part of the following is not what you're looking 
for? (The usual information is needed, like version of R, reproducible 
example, etc.)


 > setClassUnion("numericOrNULL", c("numeric","NULL"))
[1] "numericOrNULL"
 > setClass("foo", representation(x="numericOrNULL"))
[1] "foo"
 > ff = new("foo", x= 1:10)
 > fg = new("foo", x = NULL)
 >
 > ff
An object of class ?foo?
Slot "x":
[1] 1 2 3 4 5 6 7 8 9 10

 > fg
An object of class ?foo?
Slot "x":
NULL
 > fk = new("foo")
 > fk
An object of class ?foo?
Slot "x":
NULL

John

Sklyar, Oleg (London) wrote:
> Dear list:
>
> I am looking for a good way to create an S4 class that would extend
> numeric, but would allow NULL instead of data as well. As far as I can
> see there is no way at the moment to do that, but please correct me if I
> am wrong. The best solution I came up with so far was the following (it
> also indicates a problem of using setClassUnion with numeric as one of
> the classes):
>
> I define a class union of numeric and NULL:
>
> Unfortunately the following works only with warnings:
> setClassUnion("numericOrNULL", c("numeric","NULL"))
>
> So I do a workaround as:
>
> setClass("aNumeric", contains="numeric")
> setClassUnion("numericOrNULL", c("aNumeric","NULL"))
>
> Then I cannot really extend the above virtual class and can only use it
> in a user-defined slot as follows:
>
> setClass("myClass", representation(data="numericOrNULL"))
> new("myClass", data=runif(20))
> new("myClass", data=NULL)
>
> and this works.
>
> Obviously it would be nicer to have something like the following:
>
> setClass("myClass", contains="numericOrNULL")
> new("myClass", runif(20)) ## .Data is not a slot of myClass
> setClass("myClass", representation("numericOrNULL"))
> new("myClass", runif(20)) ## ibid
>
> Technically I understand that the reason behind it failing to work is
> that the virtual class numericOrNULL has not got the .Data slot from
> numeric, but it would be nice to have such a functionality.
>
> Any ideas about better ways for solving such a problem than the one
> described above?
>
> Thanks.
>
> Best,
> Oleg
>
> Dr Oleg Sklyar
> Research Technologist
> AHL / Man Investments Ltd
> +44 (0)20 7144 3107
> osklyar at maninvestments.com
>
> **********************************************************************
> Please consider the environment before printing this email or its attachments.
> The contents of this email are for the named addressees ...{{dropped:19}}
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From smckinney at bccrc.ca  Wed Feb 11 21:13:17 2009
From: smckinney at bccrc.ca (Steven McKinney)
Date: Wed, 11 Feb 2009 12:13:17 -0800
Subject: [Rd] p.adjust; n > length(p) (PR#13519)
In-Reply-To: <1334_1234365289_1234365289_20090211151009.DDC63284A70A@mail.pubhealth.ku.dk>
Message-ID: <0BE438149FF2254DB4199E2682C8DFEB01D5021A@crcmail1.BCCRC.CA>

Hi Ludo,

Issues such as this are best posed as
questions to the list before filing a bug
report.  (False bug reports create extra
work for volunteer R-core members.)

What is your use case for setting
n larger than length(p) (the default)?

The documentation does say
"n number of comparisons, must be at least length(p); only set this 
   (to non-default) when you know what you are doing!"

Because the default 
n = length(p)
is not evaluated until n is first needed in
the function body ('lazy evaluation') n is
by default set to length(p) after NAs
are removed in about line 8 of the function
line "stopifnot(n >= length(p))" )

and I'm not finding any problems with the
function, even when supplying p-values with NAs.

The documentation also states
"Note that you can set n larger than length(p) which means the
unobserved p-values are assumed to be greater than all the observed p
for "bonferroni" and "holm" methods and equal to 1 for the other
methods."

so it is up to the user to properly interpret the function
output when using a non-default setting for n.  The ensuing warning
is just a warning, not an error, requiring proper interpretation
and understanding by the user that chooses to set n to a non-default
setting.



> -----Original Message-----
> From: r-devel-bounces at r-project.org
[mailto:r-devel-bounces at r-project.org]
> On Behalf Of lpagie at xs4all.nl
> Sent: Wednesday, February 11, 2009 7:10 AM
> To: r-devel at stat.math.ethz.ch
> Cc: R-bugs at r-project.org
> Subject: [Rd] p.adjust; n > length(p) (PR#13519)
> 
> Full_Name: Ludo Pagie
> Version: 2.8.1
> OS: linux
> Submission from: (NULL) (194.171.7.39)
> 
> 
> p.adjust in stats seems to have a bug in handling n>length(p) for (at
> least) the
> methods 'holm' and 'hochberg'.
> 
> For method 'holm' the relevant code:
>         i <- 1:n
>         o <- order(p)
>         ro <- order(o)
>         pmin(1, cummax((n - i + 1) * p[o]))[ro]
> 
> where p is the supplied vector of pvalues and n is the supplied number
of
> comparisons. If n>length(p) p.adjust() gives a warning:
> Warning message:
> In (n - i + 1) * p[o] :
>   longer object length is not a multiple of shorter object length
> 
> to me it seems that instead of 'i <- 1:n', 'i <- 1:length(p)' is
required.

This is the case if you do not specify n.  Lazy evaluation yields
n = length(p)


> Similar cases seem to be true for 'hochberg' and possibly other
methods.
> 
> (I tried checking whether this bug has been reported but the website
broke
> on
> me. appologies if the bug is known already)
> 
> Best, Ludo
> 
> Netherlands Cancer Institute
> Gene Regulation (B4)
> van Steensel Group
> Plesmanlaan 121
> 1066 CX Amsterdam
> The Netherlands
> 
> Tel.: ++ 20 512 7986
> Fax:  ++ 20 669 1383
> email: lpagie at xs4all.nl
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


Best

Steven McKinney, Ph.D.

Statistician
Molecular Oncology and Breast Cancer Program
British Columbia Cancer Research Centre

email: smckinney at bccrc.ca
tel: 604-675-8000 x7561

BCCRC
Molecular Oncology
675 West 10th Ave, Floor 4
Vancouver B.C. 
V5Z 1L3

Canada


From jmc at r-project.org  Wed Feb 11 21:39:50 2009
From: jmc at r-project.org (John Chambers)
Date: Wed, 11 Feb 2009 12:39:50 -0800
Subject: [Rd] setClassUnion with numeric; extending class union
In-Reply-To: <49932B2E.5090703@r-project.org>
References: <1A68FCB28DE72F4BA3B967E6506CCE43047DF65F@mildnpexmb01.maninvestments.ad.man.com>
	<49932B2E.5090703@r-project.org>
Message-ID: <49933796.60809@r-project.org>

So, I was intrigued and played around a bit more.  Still can't get any 
warnings, but the following may be the issue.

One thing NOT currently possible is to have a class that has NULL as its 
data part, because type NULL is abnormal and can't have attributes.

So if you want a class that contains a union including NULL, you're in 
trouble generating a value from the class that is NULL.  It's not really 
a consequence of the setUnion() per se.

 > setClass("bar", contains = "numericOrNULL")
[1] "bar"
 > zz = new("bar", NULL)
Error in validObject(.Object) :
  invalid class "bar" object: invalid object for slot ".Data" in class 
"bar": got class "list", should be or extend class "numericOrNULL"

(How one got from the error to the message is a question, but in any 
case this can't currently work.)

As in my example and in your example with a slot called "data", no 
problem in having a slot value that is NULL.

Looking ahead, I'm working on some extensions that would allow classes 
to contain "abnormal" data types (externalptr, environment, ...) by 
using a reserved slot name, since one can not make the actual data type 
one of those types.

John Chambers wrote:
> What warnings? Which part of the following is not what you're looking 
> for? (The usual information is needed, like version of R, reproducible 
> example, etc.)
>
>
> > setClassUnion("numericOrNULL", c("numeric","NULL"))
> [1] "numericOrNULL"
> > setClass("foo", representation(x="numericOrNULL"))
> [1] "foo"
> > ff = new("foo", x= 1:10)
> > fg = new("foo", x = NULL)
> >
> > ff
> An object of class ?foo?
> Slot "x":
> [1] 1 2 3 4 5 6 7 8 9 10
>
> > fg
> An object of class ?foo?
> Slot "x":
> NULL
> > fk = new("foo")
> > fk
> An object of class ?foo?
> Slot "x":
> NULL
>
> John
>
> Sklyar, Oleg (London) wrote:
>> Dear list:
>>
>> I am looking for a good way to create an S4 class that would extend
>> numeric, but would allow NULL instead of data as well. As far as I can
>> see there is no way at the moment to do that, but please correct me if I
>> am wrong. The best solution I came up with so far was the following (it
>> also indicates a problem of using setClassUnion with numeric as one of
>> the classes):
>>
>> I define a class union of numeric and NULL:
>>
>> Unfortunately the following works only with warnings:
>> setClassUnion("numericOrNULL", c("numeric","NULL"))
>>
>> So I do a workaround as:
>>
>> setClass("aNumeric", contains="numeric")
>> setClassUnion("numericOrNULL", c("aNumeric","NULL"))
>>
>> Then I cannot really extend the above virtual class and can only use it
>> in a user-defined slot as follows:
>>
>> setClass("myClass", representation(data="numericOrNULL"))
>> new("myClass", data=runif(20))
>> new("myClass", data=NULL)
>>
>> and this works.
>>
>> Obviously it would be nicer to have something like the following:
>>
>> setClass("myClass", contains="numericOrNULL")
>> new("myClass", runif(20)) ## .Data is not a slot of myClass
>> setClass("myClass", representation("numericOrNULL"))
>> new("myClass", runif(20)) ## ibid
>>
>> Technically I understand that the reason behind it failing to work is
>> that the virtual class numericOrNULL has not got the .Data slot from
>> numeric, but it would be nice to have such a functionality.
>>
>> Any ideas about better ways for solving such a problem than the one
>> described above?
>>
>> Thanks.
>>
>> Best,
>> Oleg
>>
>> Dr Oleg Sklyar
>> Research Technologist
>> AHL / Man Investments Ltd
>> +44 (0)20 7144 3107
>> osklyar at maninvestments.com
>>
>> **********************************************************************
>> Please consider the environment before printing this email or its 
>> attachments.
>> The contents of this email are for the named addressees 
>> ...{{dropped:19}}
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From dasmailinglists at gmail.com  Wed Feb 11 22:52:13 2009
From: dasmailinglists at gmail.com (David Scherrer)
Date: Wed, 11 Feb 2009 16:52:13 -0500
Subject: [Rd] RSPython
Message-ID: <1a3e78310902111352x5431de5aoff9498a2527f7382@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090211/b85e9b38/attachment.pl>

From duncan at wald.ucdavis.edu  Thu Feb 12 00:42:58 2009
From: duncan at wald.ucdavis.edu (Duncan Temple Lang)
Date: Wed, 11 Feb 2009 15:42:58 -0800
Subject: [Rd] RSPython
In-Reply-To: <1a3e78310902111352x5431de5aoff9498a2527f7382@mail.gmail.com>
References: <1a3e78310902111352x5431de5aoff9498a2527f7382@mail.gmail.com>
Message-ID: <49936282.9060600@wald.ucdavis.edu>


Hi David.

(Sorry about not replying to your earlier mail. I have been rather
busy in the last few days.)



David Scherrer wrote:
> Hi all,
> 
> I try to utilize RSPython to invoke Python from R. For me it works pretty
> fine for basic applications, but I have 3 problems that may be related.
> 
> (1) I can't load other packages but "standard" ones also when I adjust the
> PythonPath:
> 
>        > importPythonModule('sys', all=T)
>        NULL
> 
>        > importPythonModule('numpy', all=T)
>        Error in .PythonEval(cmd) :
>        Error in Python call:
> /usr/lib/python2.5/site-packages/numpy/core/multiarray.so: undefined symbol:
> _Py_ZeroStruct


I imagine that this is as a result of the Python modules you are loading
containing compiled code and that these were not linked against the 
Python shared library when they were installed. As a result, they refer
to symbols in the Python library, but these symbols are unresolved (e.g.
use nm to look at the undefined symbols). When these modules are loaded
into Python, Python provides those symbols as part of its "main" 
library.  In our case, R is the main application/library and does not
export the Python symbols which are loaded and squirrelled away in a 
separate compartment.

The best thing to do is install the Python modules so that they link 
against libpython.so.

The practical thing to try, however, is to load libpython.so into R with

  dyn.load("/where/ever/libpython.so", local = FALSE)

before you load RSPython, or before you use importPythonModule().

> 
>        > importPythonModule('Scientific.Functions.Derivatives', all=T)
>        Error in .PythonEval(cmd) :
>        Error in Python call:
> /usr/lib/python2.5/site-packages/Scientific/linux2/Scientific_numerics_package_id.so:
> undefined symbol: PyString_InternFromString
> 
> 
> (2) I can't even load the test example provided at www.omegahat.org/*
> RSPython*/ <http://www.omegahat.org/RSPython/> .
> 
>        >
> Sys.putenv("PYTHONPATH"='/usr/local/lib/R/site-library/RSPython/tests')
>        > .PythonInit()
>        > test <- .PythonNew("RSTest", .module="method")
>        Error in .PythonNew("RSTest", .module = "method") : No such module

Is that module installed in /usr/local/lib/R/site-library/RSPython/tests

> 
> 
> (3) It doesn't find RS.so if I try dyn.load("RS.so")

      Well you'll need to give it a path. In what context are you doing 
this?

    D.

> 
> My OS is Linux Debian (kernel 2.6.27-11-generic)  .
> 
> Many thanks for you help!
> 
> David
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From nakulcg at gmail.com  Thu Feb 12 01:33:01 2009
From: nakulcg at gmail.com (Nakul Chaudhari)
Date: Thu, 12 Feb 2009 06:03:01 +0530
Subject: [Rd] how to contribute to r using c and c++
Message-ID: <248950840902111633i4040b269u20408fad3f444c84@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090212/dc98e4e5/attachment.pl>

From osklyar at maninvestments.com  Thu Feb 12 10:22:29 2009
From: osklyar at maninvestments.com (Sklyar, Oleg (London))
Date: Thu, 12 Feb 2009 09:22:29 -0000
Subject: [Rd] setClassUnion with numeric; extending class union
In-Reply-To: <49933796.60809@r-project.org>
References: <1A68FCB28DE72F4BA3B967E6506CCE43047DF65F@mildnpexmb01.maninvestments.ad.man.com>
	<49932B2E.5090703@r-project.org> <49933796.60809@r-project.org>
Message-ID: <1A68FCB28DE72F4BA3B967E6506CCE43047DF669@mildnpexmb01.maninvestments.ad.man.com>

Hi John,

sorry for not posting more info. Strangely I get warnings about
setClassUnion with numeric in a very special case: if I define it in a
clean R session then there are no warnings, however if I load a number
of my packages where there are other classes derived from numeric and
exported then I get the following warnings:

> setClassUnion("numericOrNULL", c("numeric","NULL"))
[1] "numericOrNULL"
Warning messages:
1: In .checkSubclasses(class1, classDef, class2, classDef2, where1,  :
  Subclass "TimeDateBase" of class "numeric" is not local and cannot be
updated for new inheritance information; consider setClassUnion()
2: In .checkSubclasses(class1, classDef, class2, classDef2, where1,  :
  Subclass "TimeDate" of class "numeric" is not local and cannot be
updated for new inheritance information; consider setClassUnion()
3: In .checkSubclasses(class1, classDef, class2, classDef2, where1,  :
  Subclass "Time" of class "numeric" is not local and cannot be updated
for new inheritance information; consider setClassUnion()

The class is operational even with those warnings though. Now, the above
classes are defined as follows:

## - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
- - - - 
setClass("TimeDateBase", 
    representation("numeric", mode="character"),
    prototype(mode="posix")
)

## - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
- - - - 
setClass("TimeDate",
    representation("TimeDateBase", tzone="character"),
    prototype(tzone="Europe/London")
)

## - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
- - - - 
setClass("Time", 
    representation("TimeDateBase")
)

Theses classes work perfectly fine on their own and are used throughout
our code for all possible time and date operations extending the
existing functionality of R and available third party packages by an
order of magnitude. I do not see a relation between the above class
definitions and the newly defined class union though apart from the fact
that they are in a package namespace and therefore locked. Sorry I
cannot provide more source code as the code is not yet public.

It would definitely be nice to somehow have a .Data slot in NULL or even
a data.frame, although I do understand that this is quite a substantial
piece of work to make it all robust and backward compatible.

> sessionInfo() ## of a clean session

R version 2.9.0 Under development (unstable) (2009-02-02 r47821) 
x86_64-unknown-linux-gnu 

locale:
C

attached base packages:
[1] stats     graphics  utils     datasets  grDevices methods   base


Any thoughts are greatly appreciated.

Kind regards,
Oleg

Dr Oleg Sklyar
Research Technologist
AHL / Man Investments Ltd
+44 (0)20 7144 3107
osklyar at maninvestments.com 

> -----Original Message-----
> From: John Chambers [mailto:jmc at r-project.org] 
> Sent: 11 February 2009 20:40
> To: Sklyar, Oleg (London)
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] setClassUnion with numeric; extending class union
> 
> So, I was intrigued and played around a bit more.  Still 
> can't get any 
> warnings, but the following may be the issue.
> 
> One thing NOT currently possible is to have a class that has 
> NULL as its 
> data part, because type NULL is abnormal and can't have attributes.
> 
> So if you want a class that contains a union including NULL, 
> you're in 
> trouble generating a value from the class that is NULL.  It's 
> not really 
> a consequence of the setUnion() per se.
> 
>  > setClass("bar", contains = "numericOrNULL")
> [1] "bar"
>  > zz = new("bar", NULL)
> Error in validObject(.Object) :
>   invalid class "bar" object: invalid object for slot ".Data" 
> in class 
> "bar": got class "list", should be or extend class "numericOrNULL"
> 
> (How one got from the error to the message is a question, but in any 
> case this can't currently work.)
> 
> As in my example and in your example with a slot called "data", no 
> problem in having a slot value that is NULL.
> 
> Looking ahead, I'm working on some extensions that would 
> allow classes 
> to contain "abnormal" data types (externalptr, environment, ...) by 
> using a reserved slot name, since one can not make the actual 
> data type 
> one of those types.
> 
> John Chambers wrote:
> > What warnings? Which part of the following is not what 
> you're looking 
> > for? (The usual information is needed, like version of R, 
> reproducible 
> > example, etc.)
> >
> >
> > > setClassUnion("numericOrNULL", c("numeric","NULL"))
> > [1] "numericOrNULL"
> > > setClass("foo", representation(x="numericOrNULL"))
> > [1] "foo"
> > > ff = new("foo", x= 1:10)
> > > fg = new("foo", x = NULL)
> > >
> > > ff
> > An object of class "foo"
> > Slot "x":
> > [1] 1 2 3 4 5 6 7 8 9 10
> >
> > > fg
> > An object of class "foo"
> > Slot "x":
> > NULL
> > > fk = new("foo")
> > > fk
> > An object of class "foo"
> > Slot "x":
> > NULL
> >
> > John
> >
> > Sklyar, Oleg (London) wrote:
> >> Dear list:
> >>
> >> I am looking for a good way to create an S4 class that would extend
> >> numeric, but would allow NULL instead of data as well. As 
> far as I can
> >> see there is no way at the moment to do that, but please 
> correct me if I
> >> am wrong. The best solution I came up with so far was the 
> following (it
> >> also indicates a problem of using setClassUnion with 
> numeric as one of
> >> the classes):
> >>
> >> I define a class union of numeric and NULL:
> >>
> >> Unfortunately the following works only with warnings:
> >> setClassUnion("numericOrNULL", c("numeric","NULL"))
> >>
> >> So I do a workaround as:
> >>
> >> setClass("aNumeric", contains="numeric")
> >> setClassUnion("numericOrNULL", c("aNumeric","NULL"))
> >>
> >> Then I cannot really extend the above virtual class and 
> can only use it
> >> in a user-defined slot as follows:
> >>
> >> setClass("myClass", representation(data="numericOrNULL"))
> >> new("myClass", data=runif(20))
> >> new("myClass", data=NULL)
> >>
> >> and this works.
> >>
> >> Obviously it would be nicer to have something like the following:
> >>
> >> setClass("myClass", contains="numericOrNULL")
> >> new("myClass", runif(20)) ## .Data is not a slot of myClass
> >> setClass("myClass", representation("numericOrNULL"))
> >> new("myClass", runif(20)) ## ibid
> >>
> >> Technically I understand that the reason behind it failing 
> to work is
> >> that the virtual class numericOrNULL has not got the .Data 
> slot from
> >> numeric, but it would be nice to have such a functionality.
> >>
> >> Any ideas about better ways for solving such a problem than the one
> >> described above?
> >>
> >> Thanks.
> >>
> >> Best,
> >> Oleg
> >>
> >> Dr Oleg Sklyar
> >> Research Technologist
> >> AHL / Man Investments Ltd
> >> +44 (0)20 7144 3107
> >> osklyar at maninvestments.com
> >>
> >> 
> **********************************************************************
> >> Please consider the environment before printing this email or its 
> >> attachments.
> >> The contents of this email are for the named addressees 
> >> ...{{dropped:19}}
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >>
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 

**********************************************************************
Please consider the environment before printing this email or its attachments.
The contents of this email are for the named addressees ...{{dropped:19}}


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Thu Feb 12 11:07:23 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Thu, 12 Feb 2009 11:07:23 +0100
Subject: [Rd] Patch for src/main/character.c,
	systematizing recent fix to do_grep
Message-ID: <4993F4DB.7020907@idi.ntnu.no>

The attached patch provides a modification to the recent fix/improvement
to do_grep already included in the most recent development version.

The original fix added new functionality to the grep function by adding
a new parameter, 'invert'.  In the source code for the underlying
do_grep, the value of the parameter is used to invert the logical
match-no match flag vector ind.  The modification is distributed across
several lines of code.

The patch systematizes the solution by inverting the logical match flag
vector in place, once for each element in the character vector passed to
grep as the argument 'x'.  In the patched version, the invertion appears
just once in the code.

The patch does not modify the functionality of grep in any way.  If the
respective documentation was updated to cover the new functionality
introduced by the original modification, it still applies to the patched
version.

The patch does not solve any immediate problem.  However, due to
replacing the redundantly distributed original modification with a
one-line modofication, the patch is intended to make it easier to
understand, maintain, and further modify the source code.

The patch also renames the variable 'invert' introduced in the original
modification to 'invert_opt', for consistency with how (almost) all
other logical flag parameters in do_grep are named.  This modification
is again functionally transparent and requires no modifications to the
documentation.


The patch was prepared as follows:

svn co https://svn.R-project.org/R/trunk/
cd trunk
tools/rsync-recommended
# modifications made to src/main/character.c
svn diff > do_grep.diff

The patched sources were successfully compiled and tested as follows:

svn revert -R .
patch -p0 < do_grep.diff
./configure
make
make check

Assuming that appropriate tests were prepared for the extended version
of grep as of the original modification, the patched version was
successfully tested.

The patched grep was also tested as follows:

bin/R --no-save -q <<END
x = replicate(10, paste(sample(letters, 10, replace=TRUE), collapse=''))
pattern = paste(sample(letters, 3), collapse='')
matched = grep(pattern=pattern, x=x, invert=FALSE)
unmatched = grep(pattern=pattern, x=x, invert=TRUE)
print(all.equal(1:length(x), sort(c(matched, unmatched))))
print(version)
END

with the output:

[1] TRUE

platform      
i686-pc-linux-gnu                                              
arch          
i686                                                           
os            
linux-gnu                                                      
system         i686,
linux-gnu                                                
status         Under development
(unstable)                                   
major         
2                                                              
minor         
9.0                                                            
year          
2009                                                           
month         
02                                                             
day           
12                                                             
svn rev       
47904                                                          
language      
R                                                              
version.string R version 2.9.0 Under development (unstable) (2009-02-12
r47904)


vQ

-- 
-------------------------------------------------------------------------------
Wacek Kusnierczyk, MD PhD

Email: waku at idi.ntnu.no
Phone: +47 73591875, +47 72574609

Department of Computer and Information Science (IDI)
Faculty of Information Technology, Mathematics and Electrical Engineering (IME)
Norwegian University of Science and Technology (NTNU)
Sem Saelands vei 7, 7491 Trondheim, Norway
Room itv303

Bioinformatics & Gene Regulation Group
Department of Cancer Research and Molecular Medicine (IKM)
Faculty of Medicine (DMF)
Norwegian University of Science and Technology (NTNU)
Laboratory Center, Erling Skjalgsons gt. 1, 7030 Trondheim, Norway
Room 231.05.060

-------------------------------------------------------------------------------

-------------- next part --------------
A non-text attachment was scrubbed...
Name: do_grep.diff
Type: text/x-diff
Size: 2498 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090212/16229774/attachment.bin>

From romain.francois at dbmail.com  Thu Feb 12 13:01:03 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Thu, 12 Feb 2009 13:01:03 +0100
Subject: [Rd] Why is srcref of length 6 and not 4 ?
Message-ID: <49940F7F.3090508@dbmail.com>

Hello,

Consider this file (/tmp/test.R) :

<file>
f <- function( x, y = 2 ){
   z <- x + y
   print( z )
}
</file>

I get this in R 2.7.2 :

 > p <- parse( "/tmp/test.R" )
 > str( attr( p, "srcref" ) )
List of 1
$ :Class 'srcref'  atomic [1:4] 1 1 4 1
 .. ..- attr(*, "srcfile")=Class 'srcfile' length 4 <environment>

and this in R-devel :

 > p <- parse( "/tmp/test.R" )
 > str( attr(p, "srcref") )
List of 1
$ :Class 'srcref'  atomic [1:6] 1 1 4 1 1 1
 .. ..- attr(*, "srcfile")=Class 'srcfile' <environment: 0x946b944>

What are the two last numbers ?

Romain

-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr

-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From savicky at cs.cas.cz  Thu Feb 12 13:33:33 2009
From: savicky at cs.cas.cz (Petr Savicky)
Date: Thu, 12 Feb 2009 13:33:33 +0100
Subject: [Rd] Spearman's rank correlation test
Message-ID: <20090212123333.GA28808@cs.cas.cz>

Hi All:

help(cor.test) claims
  For Spearman's test, p-values are computed using algorithm AS 89.

Algorithm AS 89 was introduced by the paper
  D. J. Best & D. E. Roberts (1975), Algorithm AS 89: The Upper Tail
  Probabilities of Spearman's rho. Applied Statistics, Vol. 24, No. 3, 377-379.
Table 1(a) in this paper presents maximum absolute error |\Delta_m|, of the
approximation for all possible values of the statistic S for samples sizes
n = 7, 9, 11, 13. The presented errors are

   n  |\Delta_m|

   7  0.0046
   9  0.0011
  11  0.0006
  13  0.0005

Due to the problem explained in detail including a patch at
  https://stat.ethz.ch/pipermail/r-devel/2009-January/051936.html
the error of R implementation of Spearman's rank correlation test is larger
than the above bounds for the sample size n = 11 and some of the values of S,
which correspond to positive correlation.

For example, for n = 11 and S = 90, we have
  x <- 1:11
  y <- c(6:1, 7, 11:8)
  out <- cor.test(x, y, method="spearman", alternative="greater")
  out$statistic # 90
  out$p.value   # 0.02921104
while the correct p-value is 0.03044548, so the absolute difference
is 0.00123444. This is larger than the absolute error 0.0006 guaranteed
for AS 89. In my opinion, this means that the claim from help(cor.test)
cited above is not correct.

To see the error of AS 89 in the example above, one can use
  cor.test(x, -y, method="spearman", alternative="less")$p.value # 0.03036413
since on the side of negative correlation, R calls AS 89 correctly.
So, for the x, y above, correctly called AS 89 has absolute error 0.00008135.

There is a package pspearman currently included to CRAN, which provides a
correction of the problem without the need to modify R base.

Petr.


From murdoch at stats.uwo.ca  Thu Feb 12 14:25:53 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 12 Feb 2009 08:25:53 -0500
Subject: [Rd] Why is srcref of length 6 and not 4 ?
In-Reply-To: <49940F7F.3090508@dbmail.com>
References: <49940F7F.3090508@dbmail.com>
Message-ID: <49942361.5090404@stats.uwo.ca>

On 12/02/2009 7:01 AM, Romain Francois wrote:
> Hello,
> 
> Consider this file (/tmp/test.R) :
> 
> <file>
> f <- function( x, y = 2 ){
>    z <- x + y
>    print( z )
> }
> </file>
> 
> I get this in R 2.7.2 :
> 
>  > p <- parse( "/tmp/test.R" )
>  > str( attr( p, "srcref" ) )
> List of 1
> $ :Class 'srcref'  atomic [1:4] 1 1 4 1
>  .. ..- attr(*, "srcfile")=Class 'srcfile' length 4 <environment>
> 
> and this in R-devel :
> 
>  > p <- parse( "/tmp/test.R" )
>  > str( attr(p, "srcref") )
> List of 1
> $ :Class 'srcref'  atomic [1:6] 1 1 4 1 1 1
>  .. ..- attr(*, "srcfile")=Class 'srcfile' <environment: 0x946b944>
> 
> What are the two last numbers ?

The original design for srcref gave 4 entries: start line, start byte, 
stop line, stop byte. However, in multibyte strings, bytes don't 
correspond to columns, so error messages could often report the wrong 
location according to what a user sees in an editor.  To support the 
more useful error messages in R-devel, I added two more values: start 
column and stop column.  With pure ASCII text these will be the same as 
start byte and stop byte; with UTF-8 text and non-ASCII characters they 
will be be different.  Other multibyte encodings are only supported if 
the platform can convert them to UTF-8 (and are not well tested; error 
reports would be welcome, if there's a way to improve the performance.)

If you are using these for error reports, I recommend using the two new 
values.  If you are trying to retrieve the text from the source file, 
use the originals.

Duncan Murdoch


From romain.francois at dbmail.com  Thu Feb 12 14:36:07 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Thu, 12 Feb 2009 14:36:07 +0100
Subject: [Rd] Why is srcref of length 6 and not 4 ?
In-Reply-To: <49942361.5090404@stats.uwo.ca>
References: <49940F7F.3090508@dbmail.com> <49942361.5090404@stats.uwo.ca>
Message-ID: <499425C7.3000100@dbmail.com>

Duncan Murdoch wrote:
> On 12/02/2009 7:01 AM, Romain Francois wrote:
>> Hello,
>>
>> Consider this file (/tmp/test.R) :
>>
>> <file>
>> f <- function( x, y = 2 ){
>>    z <- x + y
>>    print( z )
>> }
>> </file>
>>
>> I get this in R 2.7.2 :
>>
>>  > p <- parse( "/tmp/test.R" )
>>  > str( attr( p, "srcref" ) )
>> List of 1
>> $ :Class 'srcref'  atomic [1:4] 1 1 4 1
>>  .. ..- attr(*, "srcfile")=Class 'srcfile' length 4 <environment>
>>
>> and this in R-devel :
>>
>>  > p <- parse( "/tmp/test.R" )
>>  > str( attr(p, "srcref") )
>> List of 1
>> $ :Class 'srcref'  atomic [1:6] 1 1 4 1 1 1
>>  .. ..- attr(*, "srcfile")=Class 'srcfile' <environment: 0x946b944>
>>
>> What are the two last numbers ?
>
> The original design for srcref gave 4 entries: start line, start byte, 
> stop line, stop byte. However, in multibyte strings, bytes don't 
> correspond to columns, so error messages could often report the wrong 
> location according to what a user sees in an editor.  To support the 
> more useful error messages in R-devel, I added two more values: start 
> column and stop column.  With pure ASCII text these will be the same 
> as start byte and stop byte; with UTF-8 text and non-ASCII characters 
> they will be be different.  Other multibyte encodings are only 
> supported if the platform can convert them to UTF-8 (and are not well 
> tested; error reports would be welcome, if there's a way to improve 
> the performance.)
>
> If you are using these for error reports, I recommend using the two 
> new values.  If you are trying to retrieve the text from the source 
> file, use the originals.
>
> Duncan Murdoch
>
>
Thank you Duncan,

I am using this to massage the output of "parse" into a data frame to 
represent it as a tree
(see http://addictedtor.free.fr/misc/sidekick.png)

 > cat( readLines( "/tmp/test.R" ), sep = "\n" )
f <- function( x, y = 2 ){
        z <- x + y
        g <- function( x ){
          print( x )
          xx <- x + 1
        }
        g( x )
}
 >
 > sidekick( "/tmp/test.R", encoding = "utf-8" )
  id parent     mode srcref1 srcref2 srcref3 srcref4               
description
1  1      0 function       1       1       8       1 f <- function(x, y 
= 2) {
2  2      1     name       1      26       1      
26                         {
3  3      1     call       2       2       2      11                z <- 
x + y
4  4      1 function       3       2       6       2        g <- 
function(x) {
5  5      1     call       7       2       7       
7                      g(x)
6  6      4     name       3      20       3      
20                         {
7  7      4     call       4       4       4      13                  
print(x)
8  8      4     call       5       4       5      14               xx <- 
x + 1



-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr


From h.wickham at gmail.com  Thu Feb 12 15:37:44 2009
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 12 Feb 2009 08:37:44 -0600
Subject: [Rd] Why is srcref of length 6 and not 4 ?
In-Reply-To: <499425C7.3000100@dbmail.com>
References: <49940F7F.3090508@dbmail.com> <49942361.5090404@stats.uwo.ca>
	<499425C7.3000100@dbmail.com>
Message-ID: <f8e6ff050902120637o2a5e898fx57be28cd2a00228f@mail.gmail.com>

> I am using this to massage the output of "parse" into a data frame to
> represent it as a tree
> (see http://addictedtor.free.fr/misc/sidekick.png)

You might also want to take a look at
http://github.com/hadley/eval.with.details/blob/master/R/parse.r

where I'm trying to do something similar for a different purpose.

Hadley

-- 
http://had.co.nz/


From bolker at ufl.edu  Thu Feb 12 17:29:14 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 12 Feb 2009 11:29:14 -0500
Subject: [Rd] proposed simulate.glm method
Message-ID: <49944E5A.1020000@ufl.edu>


  I have found the "simulate" method (incorporated
in some packages) very handy. As far as I can tell the
only class for which simulate is actually implemented
in base R is lm ... this is actually a little dangerous
for a naive user who might be tempted to try
simulate(X) where X is a glm fit instead, because
it defaults to simulate.lm (since glm inherits from
the lm class), and the answers make no sense ...

Here is my simulate.glm(), which is modeled on
simulate.lm .  It implements simulation for poisson
and binomial (binary or non-binary) models, should
be easy to implement others if that seems necessary.

  I hereby request comments and suggest that it wouldn't
hurt to incorporate it into base R ...  (I will write
docs for it if necessary, perhaps by modifying ?simulate --
there is no specific documentation for simulate.lm)

  cheers
    Ben Bolker


simulate.glm <- function (object, nsim = 1, seed = NULL, ...)
{
  ## RNG stuff copied from simulate.lm
  if (!exists(".Random.seed", envir = .GlobalEnv, inherits = FALSE))
    runif(1)
  if (is.null(seed))
    RNGstate <- get(".Random.seed", envir = .GlobalEnv)
  else {
    R.seed <- get(".Random.seed", envir = .GlobalEnv)
    set.seed(seed)
    RNGstate <- structure(seed, kind = as.list(RNGkind()))
    on.exit(assign(".Random.seed", R.seed, envir = .GlobalEnv))
  }
  ## get probabilities/intensities
  pred <- matrix(rep(predict(object,type="response"),nsim),ncol=nsim)
  ntot <- length(pred)
  if (object$family$family=="binomial") {
    resp <- object$model[[1]]
    size <- if (is.matrix(resp)) rowSums(resp) else 1
  }
  val <- switch(object$family$family,
                poisson=rpois(ntot,pred),
                binomial=rbinom(ntot,prob=pred,size=size),
                stop("family ",object$family$family," not implemented"))
  ans <- as.data.frame(matrix(val,ncol=nsim))
  attr(ans, "seed") <- RNGstate
  ans
}

if (FALSE) {
  ## examples: modified from ?simulate
  x <- 1:10
  n <- 10
  y <- rbinom(length(x),prob=plogis((x-5)/2),size=n)
  y2 <- c("a","b")[1+rbinom(length(x),prob=plogis((x-5)/2),size=1)]
  mod1 <- glm(cbind(y,n-y) ~ x,family=binomial)
  mod2 <- glm(factor(y2) ~ x,family=binomial)
  S1 <- simulate(mod1, nsim = 4)
  S1B <- simulate(mod2, nsim = 4)
  ## repeat the simulation:
  .Random.seed <- attr(S1, "seed")
  identical(S1, simulate(mod1, nsim = 4))

  S2 <- simulate(mod1, nsim = 200, seed = 101)
  rowMeans(S2)/10 # after correcting for binomial sample size, should be
about
  fitted(mod1)

  plot(rowMeans(S2)/10)
  lines(fitted(mod1))

  ## repeat identically:
  (sseed <- attr(S2, "seed")) # seed; RNGkind as attribute
  stopifnot(identical(S2, simulate(mod1, nsim = 200, seed = sseed)))
}


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 260 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090212/fb93e658/attachment.bin>

From adamour at iq.harvard.edu  Thu Feb 12 18:11:09 2009
From: adamour at iq.harvard.edu (Alex D'Amour)
Date: Thu, 12 Feb 2009 12:11:09 -0500
Subject: [Rd] proposed simulate.glm method
In-Reply-To: <49944E5A.1020000@ufl.edu>
References: <49944E5A.1020000@ufl.edu>
Message-ID: <2ffd32cb0902120911r2a7fe6f8n93506e756a5eac46@mail.gmail.com>

There is functionality similar to this included in the Zelig package
with it's "sim" method. The "sim" method goes a step further and
replicates the fitted model's analysis on the generated datasets as
well. I would suggest taking a look -- Zelig supports most (if not
all) glm models and a wide range of others.

The Zelig maintainers' site can be found at: http://gking.harvard.edu/zelig/.

Full disclosure: I am an employee of the Institute for Quantitative
Social Science, which performs most of the development and support for
the Zelig package.

Best,
Alex D'Amour
Statistical Programmer
Harvard Institute for Quantitative Social Science


2009/2/12 Ben Bolker <bolker at ufl.edu>:
>
>  I have found the "simulate" method (incorporated
> in some packages) very handy. As far as I can tell the
> only class for which simulate is actually implemented
> in base R is lm ... this is actually a little dangerous
> for a naive user who might be tempted to try
> simulate(X) where X is a glm fit instead, because
> it defaults to simulate.lm (since glm inherits from
> the lm class), and the answers make no sense ...
>
> Here is my simulate.glm(), which is modeled on
> simulate.lm .  It implements simulation for poisson
> and binomial (binary or non-binary) models, should
> be easy to implement others if that seems necessary.
>
>  I hereby request comments and suggest that it wouldn't
> hurt to incorporate it into base R ...  (I will write
> docs for it if necessary, perhaps by modifying ?simulate --
> there is no specific documentation for simulate.lm)
>
>  cheers
>    Ben Bolker
> --
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / www.zoology.ufl.edu/bolker
> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From bolker at ufl.edu  Thu Feb 12 19:45:59 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 12 Feb 2009 13:45:59 -0500
Subject: [Rd] proposed simulate.glm method
In-Reply-To: <2ffd32cb0902120911r2a7fe6f8n93506e756a5eac46@mail.gmail.com>
References: <49944E5A.1020000@ufl.edu>
	<2ffd32cb0902120911r2a7fe6f8n93506e756a5eac46@mail.gmail.com>
Message-ID: <49946E67.6040602@ufl.edu>

  Elsewhere (at least in lme4), refit(sim(model)) does the
same thing [and so one would need something like
apply(sim(model,1000),2,refit)].

  sim() is quite interesting, as is Zelig, but I'm not
sure I am ready to leap to it yet -- this was basically
a suggestion that simulate.glm could be included in
"vanilla" R ...

  Also (for better or worse), it looks like sim() also
does parametric bootstrapping on the parameter values,
whereas simulate.[g]lm() just uses "plug-in" estimates.

  cheers
    Ben Bolker


Alex D'Amour wrote:
> There is functionality similar to this included in the Zelig package
> with it's "sim" method. The "sim" method goes a step further and
> replicates the fitted model's analysis on the generated datasets as
> well. I would suggest taking a look -- Zelig supports most (if not
> all) glm models and a wide range of others.
> 
> The Zelig maintainers' site can be found at: http://gking.harvard.edu/zelig/.
> 
> Full disclosure: I am an employee of the Institute for Quantitative
> Social Science, which performs most of the development and support for
> the Zelig package.
> 
> Best,
> Alex D'Amour
> Statistical Programmer
> Harvard Institute for Quantitative Social Science
> 
> 
> 2009/2/12 Ben Bolker <bolker at ufl.edu>:
>>  I have found the "simulate" method (incorporated
>> in some packages) very handy. As far as I can tell the
>> only class for which simulate is actually implemented
>> in base R is lm ... this is actually a little dangerous
>> for a naive user who might be tempted to try
>> simulate(X) where X is a glm fit instead, because
>> it defaults to simulate.lm (since glm inherits from
>> the lm class), and the answers make no sense ...
>>
>> Here is my simulate.glm(), which is modeled on
>> simulate.lm .  It implements simulation for poisson
>> and binomial (binary or non-binary) models, should
>> be easy to implement others if that seems necessary.
>>
>>  I hereby request comments and suggest that it wouldn't
>> hurt to incorporate it into base R ...  (I will write
>> docs for it if necessary, perhaps by modifying ?simulate --
>> there is no specific documentation for simulate.lm)
>>
>>  cheers
>>    Ben Bolker
>> --
>> Ben Bolker
>> Associate professor, Biology Dep't, Univ. of Florida
>> bolker at ufl.edu / www.zoology.ufl.edu/bolker
>> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc


From mayeul.kauffmann at ecoledelapaix.org  Thu Feb 12 17:00:07 2009
From: mayeul.kauffmann at ecoledelapaix.org (mayeul.kauffmann at ecoledelapaix.org)
Date: Thu, 12 Feb 2009 17:00:07 +0100 (CET)
Subject: [Rd] typo in example(dbEscapeStrings) (PR#13521)
Message-ID: <20090212160007.5C058282EFC1@mail.pubhealth.ku.dk>

Full_Name: Mayeul Kauffmann
Version: 2.8.1
OS: x86_64-pc-linux-gnu (kubuntu)
Submission from: (NULL) (86.200.212.40)


The file /library/RMySQL/html/dbEscapeStrings.html documents dbEscapeStrings()
In the example, an 's' is missing in line 3:

## Not run: 
tmp <- sprintf("select * from emp where lname = %s", "O'Reilly")
sql <- dbEscapeString(con, tmp)
dbGetQuery(con, sql)
## End(Not run)

sql <- dbEscapeString(con, tmp)
should be:
sql <- dbEscapeStrings(con, tmp)


From maechler at stat.math.ethz.ch  Fri Feb 13 11:38:36 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 13 Feb 2009 11:38:36 +0100
Subject: [Rd] proposed simulate.glm method
In-Reply-To: <49944E5A.1020000@ufl.edu>
References: <49944E5A.1020000@ufl.edu>
Message-ID: <18837.19884.215746.626683@stat.math.ethz.ch>

>>>>> "BB" == Ben Bolker <bolker at ufl.edu>
>>>>>     on Thu, 12 Feb 2009 11:29:14 -0500 writes:

    BB> I have found the "simulate" method (incorporated
    BB> in some packages) very handy. As far as I can tell the
    BB> only class for which simulate is actually implemented
    BB> in base R is lm ... this is actually a little dangerous
    BB> for a naive user who might be tempted to try
    BB> simulate(X) where X is a glm fit instead, because
    BB> it defaults to simulate.lm (since glm inherits from
    BB> the lm class), and the answers make no sense ...

    BB> Here is my simulate.glm(), which is modeled on
    BB> simulate.lm .  It implements simulation for poisson
    BB> and binomial (binary or non-binary) models, should
    BB> be easy to implement others if that seems necessary.

    BB> I hereby request comments and suggest that it wouldn't
    BB> hurt to incorporate it into base R ...  (I will write
    BB> docs for it if necessary, perhaps by modifying ?simulate --
    BB> there is no specific documentation for simulate.lm)

    BB> cheers
    BB> Ben Bolker

[...............]

Hi Ben,
thank you for your proposals.

I agree that  simulate.glm() has been in missing in some way,
till now, in particular, as, as you note, "glm" objects extend
"lm" ones and hence  simulate(<glm>, ...) currently dispatches to
calling simulate.lm(....) which is only correct in the case of
the gaussian family.

I have looked at your proposal a bit, already "improved" the
code slightly (e.g. re-include the comment you lost when you
``copied'' simulate.lm():  In such cases, please work from the
source, not from what you get by print()ing
stats:::simulate.lm --- the source is either a recent tarball,
or the SVN repository, in this case, file
https://svn.r-project.org/R/trunk/src/library/stats/R/lm.R ]
and am planning to look at your and some own examples; 
all with the goal to indeed include this in the R standard
'stats' package in R-devel [to become R 2.9.0 in the future].

About the help page:  At the moment, I think that only a few
words would need to be added to the simulate help page,
i.e., https://svn.r-project.org/R/trunk/src/library/stats/man/simulate.Rd
and will be happy to receive a patch against this file.

Thank you again, and best regards,
Martin Maechler, ETH Zurich


From Heather.Turner at warwick.ac.uk  Fri Feb 13 12:49:06 2009
From: Heather.Turner at warwick.ac.uk (Heather Turner)
Date: Fri, 13 Feb 2009 11:49:06 +0000
Subject: [Rd] proposed simulate.glm method
In-Reply-To: <18837.19884.215746.626683@stat.math.ethz.ch>
References: <49944E5A.1020000@ufl.edu>
	<18837.19884.215746.626683@stat.math.ethz.ch>
Message-ID: <49955E32.8010005@warwick.ac.uk>

Dear Martin,

I think a simulate.glm method ought to be able to work for gnm objects
too. David Firth and I started to work on this a long time ago, but
stopped part-way through when simulate.lm was introduced, thinking that
simulate.glm was probably in the pipeline and we were duplicating
effort. Obviously we have let this slip when a contribution might have
been useful. We developed a prototype for poisson, binomial, gaussian,
gamma and inverse gaussian models which might be usefully merged with
Ben's proposed simulate.glm. What's the best way to go about this? I
would also like to test the proposed simulate.glm to check whether it
will work with gnm objects or whether a simulate.gnm will be necessary.

Thanks and best regards,

Heather


Martin Maechler wrote:
>>>>>> "BB" == Ben Bolker <bolker at ufl.edu>
>>>>>>     on Thu, 12 Feb 2009 11:29:14 -0500 writes:
> 
>     BB> I have found the "simulate" method (incorporated
>     BB> in some packages) very handy. As far as I can tell the
>     BB> only class for which simulate is actually implemented
>     BB> in base R is lm ... this is actually a little dangerous
>     BB> for a naive user who might be tempted to try
>     BB> simulate(X) where X is a glm fit instead, because
>     BB> it defaults to simulate.lm (since glm inherits from
>     BB> the lm class), and the answers make no sense ...
> 
>     BB> Here is my simulate.glm(), which is modeled on
>     BB> simulate.lm .  It implements simulation for poisson
>     BB> and binomial (binary or non-binary) models, should
>     BB> be easy to implement others if that seems necessary.
> 
>     BB> I hereby request comments and suggest that it wouldn't
>     BB> hurt to incorporate it into base R ...  (I will write
>     BB> docs for it if necessary, perhaps by modifying ?simulate --
>     BB> there is no specific documentation for simulate.lm)
> 
>     BB> cheers
>     BB> Ben Bolker
> 
> [...............]
> 
> Hi Ben,
> thank you for your proposals.
> 
> I agree that  simulate.glm() has been in missing in some way,
> till now, in particular, as, as you note, "glm" objects extend
> "lm" ones and hence  simulate(<glm>, ...) currently dispatches to
> calling simulate.lm(....) which is only correct in the case of
> the gaussian family.
> 
> I have looked at your proposal a bit, already "improved" the
> code slightly (e.g. re-include the comment you lost when you
> ``copied'' simulate.lm():  In such cases, please work from the
> source, not from what you get by print()ing
> stats:::simulate.lm --- the source is either a recent tarball,
> or the SVN repository, in this case, file
> https://svn.r-project.org/R/trunk/src/library/stats/R/lm.R ]
> and am planning to look at your and some own examples; 
> all with the goal to indeed include this in the R standard
> 'stats' package in R-devel [to become R 2.9.0 in the future].
> 
> About the help page:  At the moment, I think that only a few
> words would need to be added to the simulate help page,
> i.e., https://svn.r-project.org/R/trunk/src/library/stats/man/simulate.Rd
> and will be happy to receive a patch against this file.
> 
> Thank you again, and best regards,
> Martin Maechler, ETH Zurich
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Fri Feb 13 15:05:33 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 13 Feb 2009 15:05:33 +0100
Subject: [Rd] proposed simulate.glm method
In-Reply-To: <49955E32.8010005@warwick.ac.uk>
References: <49944E5A.1020000@ufl.edu>
	<18837.19884.215746.626683@stat.math.ethz.ch>
	<49955E32.8010005@warwick.ac.uk>
Message-ID: <18837.32301.604378.110374@stat.math.ethz.ch>

Thanks a lot, Heather,

>>>>> "HT" == Heather Turner <Heather.Turner at warwick.ac.uk>
>>>>>     on Fri, 13 Feb 2009 11:49:06 +0000 writes:

    HT> Dear Martin,
    HT> I think a simulate.glm method ought to be able to work for gnm objects
    HT> too. David Firth and I started to work on this a long time ago, but
    HT> stopped part-way through when simulate.lm was introduced, thinking that
    HT> simulate.glm was probably in the pipeline and we were duplicating
    HT> effort. Obviously we have let this slip when a contribution might have
    HT> been useful. We developed a prototype for poisson, binomial, gaussian,
    HT> gamma and inverse gaussian models which might be usefully merged with
    HT> Ben's proposed simulate.glm. What's the best way to go about this? I
    HT> would also like to test the proposed simulate.glm to check whether it
    HT> will work with gnm objects or whether a simulate.gnm will be necessary.

In the mean time, private e-mail communications have started on
the subject, and yes, we are very insterested in finding 
``the best'' possible way, probably making use of
Heather+David's code together with Ben's. 
One alternative (not mentioned yet on R-devel), we've been
considering is to use simulate.lm() to also deal with "glm" (and
possibly "gnm") objects ``in one place''.

Martin 


    HT> Martin Maechler wrote:
    >>>>>>> "BB" == Ben Bolker <bolker at ufl.edu>
    >>>>>>> on Thu, 12 Feb 2009 11:29:14 -0500 writes:
    >> 
    BB> I have found the "simulate" method (incorporated
    BB> in some packages) very handy. As far as I can tell the
    BB> only class for which simulate is actually implemented
    BB> in base R is lm ... this is actually a little dangerous
    BB> for a naive user who might be tempted to try
    BB> simulate(X) where X is a glm fit instead, because
    BB> it defaults to simulate.lm (since glm inherits from
    BB> the lm class), and the answers make no sense ...
    >> 
    BB> Here is my simulate.glm(), which is modeled on
    BB> simulate.lm .  It implements simulation for poisson
    BB> and binomial (binary or non-binary) models, should
    BB> be easy to implement others if that seems necessary.
    >> 
    BB> I hereby request comments and suggest that it wouldn't
    BB> hurt to incorporate it into base R ...  (I will write
    BB> docs for it if necessary, perhaps by modifying ?simulate --
    BB> there is no specific documentation for simulate.lm)
    >> 
    BB> cheers
    BB> Ben Bolker
    >> 
    >> [...............]
    >> 
    >> Hi Ben,
    >> thank you for your proposals.
    >> 
    >> I agree that  simulate.glm() has been in missing in some way,
    >> till now, in particular, as, as you note, "glm" objects extend
    >> "lm" ones and hence  simulate(<glm>, ...) currently dispatches to
    >> calling simulate.lm(....) which is only correct in the case of
    >> the gaussian family.
    >> 
    >> I have looked at your proposal a bit, already "improved" the
    >> code slightly (e.g. re-include the comment you lost when you
    >> ``copied'' simulate.lm():  In such cases, please work from the
    >> source, not from what you get by print()ing
    >> stats:::simulate.lm --- the source is either a recent tarball,
    >> or the SVN repository, in this case, file
    >> https://svn.r-project.org/R/trunk/src/library/stats/R/lm.R ]
    >> and am planning to look at your and some own examples; 
    >> all with the goal to indeed include this in the R standard
    >> 'stats' package in R-devel [to become R 2.9.0 in the future].
    >> 
    >> About the help page:  At the moment, I think that only a few
    >> words would need to be added to the simulate help page,
    >> i.e., https://svn.r-project.org/R/trunk/src/library/stats/man/simulate.Rd
    >> and will be happy to receive a patch against this file.
    >> 
    >> Thank you again, and best regards,
    >> Martin Maechler, ETH Zurich


From Heather.Turner at warwick.ac.uk  Fri Feb 13 16:52:37 2009
From: Heather.Turner at warwick.ac.uk (Heather Turner)
Date: Fri, 13 Feb 2009 15:52:37 +0000
Subject: [Rd] proposed simulate.glm method
In-Reply-To: <18837.32301.604378.110374@stat.math.ethz.ch>
References: <49944E5A.1020000@ufl.edu>	<18837.19884.215746.626683@stat.math.ethz.ch>	<49955E32.8010005@warwick.ac.uk>
	<18837.32301.604378.110374@stat.math.ethz.ch>
Message-ID: <49959745.9040700@warwick.ac.uk>

Yes, thanks to Ben for getting the ball rolling. His code was more
streamlined than mine, pointing to further simplifications which I've
included in the extended version below.

The code for the additional families uses functions from MASS and
SuppDists - I wasn't sure about the best way to do this, so have just
used :: for now.

It appears to be working happily for both glm and gnm objects (no
gnm-specific code used).

Best wishes,

Heather

simulate.glm <- function (object, nsim = 1, seed = NULL, ...)
{
    fam <- object$family$family
    if(fam == "gaussian")
	return(simulate.lm(object, nsim=nsim, seed=seed, ...))
    if(!exists(".Random.seed", envir = .GlobalEnv, inherits = FALSE))
	runif(1)		       # initialize the RNG if necessary
    if(is.null(seed))
	RNGstate <- get(".Random.seed", envir = .GlobalEnv)
    else {
	R.seed <- get(".Random.seed", envir = .GlobalEnv)
	set.seed(seed)
	RNGstate <- structure(seed, kind = as.list(RNGkind()))
	on.exit(assign(".Random.seed", R.seed, envir = .GlobalEnv))
    }
    ## get probabilities/intensities
    pred <- object$fitted
    ntot <- length(pred) * nsim
    val <- switch(fam,
		  "poisson" = rpois(ntot, pred),
		  "binomial" = {
                      wts <- object$prior.weights
                      if (any(wts %% 1 != 0))
                          stop("cannot simulate from non-integer
prior.weights")
		      rbinom(ntot, size = wts, prob = pred)/wts
		  },
                  "Gamma" = {
                      shape <- MASS::gamma.shape(object)$alpha
                      rgamma(ntot, shape = shape, rate = shape/pred)
                  },
                  "inverse.gaussian" = {
                      lambda <- 1/summary(object)$dispersion
                      SuppDists::rinvGauss(ntot, nu = pred, lambda = lambda)
                  },
		  stop("family '", fam, "' not yet implemented"))
    ans <- as.data.frame(matrix(val, ncol = nsim))
    attr(ans, "seed") <- RNGstate
    ans
}


Martin Maechler wrote:
> Thanks a lot, Heather,
> 
>>>>>> "HT" == Heather Turner <Heather.Turner at warwick.ac.uk>
>>>>>>     on Fri, 13 Feb 2009 11:49:06 +0000 writes:
> 
>     HT> Dear Martin,
>     HT> I think a simulate.glm method ought to be able to work for gnm objects
>     HT> too. David Firth and I started to work on this a long time ago, but
>     HT> stopped part-way through when simulate.lm was introduced, thinking that
>     HT> simulate.glm was probably in the pipeline and we were duplicating
>     HT> effort. Obviously we have let this slip when a contribution might have
>     HT> been useful. We developed a prototype for poisson, binomial, gaussian,
>     HT> gamma and inverse gaussian models which might be usefully merged with
>     HT> Ben's proposed simulate.glm. What's the best way to go about this? I
>     HT> would also like to test the proposed simulate.glm to check whether it
>     HT> will work with gnm objects or whether a simulate.gnm will be necessary.
> 
> In the mean time, private e-mail communications have started on
> the subject, and yes, we are very insterested in finding 
> ``the best'' possible way, probably making use of
> Heather+David's code together with Ben's. 
> One alternative (not mentioned yet on R-devel), we've been
> considering is to use simulate.lm() to also deal with "glm" (and
> possibly "gnm") objects ``in one place''.
> 
> Martin 
> 
> 
>     HT> Martin Maechler wrote:
>     >>>>>>> "BB" == Ben Bolker <bolker at ufl.edu>
>     >>>>>>> on Thu, 12 Feb 2009 11:29:14 -0500 writes:
>     >> 
>     BB> I have found the "simulate" method (incorporated
>     BB> in some packages) very handy. As far as I can tell the
>     BB> only class for which simulate is actually implemented
>     BB> in base R is lm ... this is actually a little dangerous
>     BB> for a naive user who might be tempted to try
>     BB> simulate(X) where X is a glm fit instead, because
>     BB> it defaults to simulate.lm (since glm inherits from
>     BB> the lm class), and the answers make no sense ...
>     >> 
>     BB> Here is my simulate.glm(), which is modeled on
>     BB> simulate.lm .  It implements simulation for poisson
>     BB> and binomial (binary or non-binary) models, should
>     BB> be easy to implement others if that seems necessary.
>     >> 
>     BB> I hereby request comments and suggest that it wouldn't
>     BB> hurt to incorporate it into base R ...  (I will write
>     BB> docs for it if necessary, perhaps by modifying ?simulate --
>     BB> there is no specific documentation for simulate.lm)
>     >> 
>     BB> cheers
>     BB> Ben Bolker
>     >> 
>     >> [...............]
>     >> 
>     >> Hi Ben,
>     >> thank you for your proposals.
>     >> 
>     >> I agree that  simulate.glm() has been in missing in some way,
>     >> till now, in particular, as, as you note, "glm" objects extend
>     >> "lm" ones and hence  simulate(<glm>, ...) currently dispatches to
>     >> calling simulate.lm(....) which is only correct in the case of
>     >> the gaussian family.
>     >> 
>     >> I have looked at your proposal a bit, already "improved" the
>     >> code slightly (e.g. re-include the comment you lost when you
>     >> ``copied'' simulate.lm():  In such cases, please work from the
>     >> source, not from what you get by print()ing
>     >> stats:::simulate.lm --- the source is either a recent tarball,
>     >> or the SVN repository, in this case, file
>     >> https://svn.r-project.org/R/trunk/src/library/stats/R/lm.R ]
>     >> and am planning to look at your and some own examples; 
>     >> all with the goal to indeed include this in the R standard
>     >> 'stats' package in R-devel [to become R 2.9.0 in the future].
>     >> 
>     >> About the help page:  At the moment, I think that only a few
>     >> words would need to be added to the simulate help page,
>     >> i.e., https://svn.r-project.org/R/trunk/src/library/stats/man/simulate.Rd
>     >> and will be happy to receive a patch against this file.
>     >> 
>     >> Thank you again, and best regards,
>     >> Martin Maechler, ETH Zurich


From ripley at stats.ox.ac.uk  Fri Feb 13 17:08:11 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 13 Feb 2009 16:08:11 +0000 (GMT)
Subject: [Rd] reading SPSS .sav files (PR#13509)
In-Reply-To: <20090207160505.48F55283416A@mail.pubhealth.ku.dk>
References: <20090207160505.48F55283416A@mail.pubhealth.ku.dk>
Message-ID: <alpine.OSX.1.00.0902130837370.67343@tystie.local>

Please can we have the reproducible example we asked for (in the FAQ, 
the posting guide ...).

We also need to know the version of foreign that worked, so can we 
have the output of sessionInfo() for both sessions (see the posting 
guide for what we need).

read.spss is able to read the old SPSS .sav files we have as examples, 
so there has to be something different about yours -- and we have no 
idea what without seeing an example.  Hopefully with one we will be 
able to track this down.

On Sat, 7 Feb 2009, zac at zjbnewton.demon.co.uk wrote:

> Full_Name: Roger Newton
> Version: 2.8.1
> OS: windows 2000
> Submission from: (NULL) (80.176.228.157)
>
>
> I have an elderly version of SPSS (version 11) which I still use. R 
> Version 2.6.1 would, and still will, read SPSS *.sav files produced 
> by SPSS version 11. R version 2.8.1 which I installed two days ago 
> (05/02/09) reports an error and shuts down when trying to read SPSS 
> version 11 *.sav files using the read.spss function in package 
> foreign.
>
> R version 2.8.1 will read *.sav files produced by SPSS version 13.
>
> The problem applies to all the existing SPSS files I had before I 
> downloaded R 2.8.1 and to several new SPSS 11 *.sav files I have 
> produced since.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From fabio.ufla at yahoo.com.br  Fri Feb 13 17:32:03 2009
From: fabio.ufla at yahoo.com.br (Fabio Mathias)
Date: Fri, 13 Feb 2009 08:32:03 -0800 (PST)
Subject: [Rd] Generate random numbers in Fortran
Message-ID: <81334.15708.qm@web59716.mail.ac4.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090213/fb42a9ab/attachment.pl>

From kjell.konis at epfl.ch  Fri Feb 13 17:49:03 2009
From: kjell.konis at epfl.ch (Kjell Konis)
Date: Fri, 13 Feb 2009 17:49:03 +0100
Subject: [Rd] Generate random numbers in Fortran
In-Reply-To: <81334.15708.qm@web59716.mail.ac4.yahoo.com>
References: <81334.15708.qm@web59716.mail.ac4.yahoo.com>
Message-ID: <4A433411-CB1A-45FC-B8A5-EAE4FE8A6AB1@epfl.ch>

Take a look at section 6.6 in Writing R Extensions. It describes how  
to call C functions from FORTRAN. Basically it just boils down to  
this, in a C file define the functions

void F77_SUB(fseedi)(void)
{
   int x = 100;
   seed_in(&x);
}


void F77_SUB(fseedo)(void)
{
   int x = 100;
   seed_out(&x);
}


void F77_SUB(myrunif)(double* px)
{
	*px = unif_rand();
}


Then you could write a FORTRAN subroutine like

       subroutine blah()
       implicit double precision (a-h,o-z)
       call fseedi()
       call myrunif(RND)
       call fseedo()
       end

The fseed* subroutines only need to be called once, fseedi at the  
beginning of your FORTRAN code and fseedo at the end.

HTH,
Kjell


On 13 f?vr. 09, at 17:32, Fabio Mathias wrote:

> Hi!!!
> It would like to know if it exists a form to use the functions to
> generate variates in FORTRAN with the same easiness I use that them in
> C? Or not?
> If yes. They would have some example? I would like to use the  
> functions rbeta, rlnorm and others!
>
>
> Sorry my english..rsrsrs
>
> Thanks!!!
>
>
>              F?bio Mathias Corr?a    University Federal of the  
> Lavras - Brazil
>
>
>
>      Veja quais s?o os assuntos do momento no Yahoo! +Buscados
>
> 	[[alternative HTML version deleted]]
>
> <ATT00001.txt>


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Fri Feb 13 18:05:17 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Fri, 13 Feb 2009 18:05:17 +0100
Subject: [Rd] Generate random numbers in Fortran
In-Reply-To: <81334.15708.qm@web59716.mail.ac4.yahoo.com>
References: <81334.15708.qm@web59716.mail.ac4.yahoo.com>
Message-ID: <4995A84D.1020002@idi.ntnu.no>

you can always try to get hold of the extensive nag fortran libraries:

http://www.nag.co.uk/numeric/fl/FLdescription.asp

comsider also 'numerical recipes' by press et al., of which there are
fortran, c, and c++ editions (i think there was a pascal edition too),
and where there are a choice of routines for random number generation,
statistics, and much more.  a good read, too.

vQ


Fabio Mathias wrote:
> Hi!!!
> It would like to know if it exists a form to use the functions to
> generate variates in FORTRAN with the same easiness I use that them in
> C? Or not?
> If yes. They would have some example? I would like to use the functions rbeta, rlnorm and others!
>
>
> Sorry my english..rsrsrs
>
> Thanks!!! 
>
>
> ? ? ? ? ? ? ? ? ? ? ? ?  F??bio Mathias Corr??a? ? ?  University Federal of the Lavras - Brazil
>
>
>
>       Veja quais s??o os assuntos do momento no Yahoo! +Buscados
>
> 	[[alternative HTML version deleted]]
>
>   
> ------------------------------------------------------------------------
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From pgilbert at bank-banque-canada.ca  Fri Feb 13 20:06:12 2009
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Fri, 13 Feb 2009 14:06:12 -0500
Subject: [Rd] proposed simulate.glm method
In-Reply-To: <18837.32301.604378.110374@stat.math.ethz.ch>
References: <49944E5A.1020000@ufl.edu>	<18837.19884.215746.626683@stat.math.ethz.ch>	<49955E32.8010005@warwick.ac.uk>
	<18837.32301.604378.110374@stat.math.ethz.ch>
Message-ID: <4995C4A4.6020301@bank-banque-canada.ca>

If you are generalizing this, the saving of the RNG information to 
reproduce normally distribution random number also needs to save the 
normal generator information. (This looks like an omission in 
simulate.lm.) You might want to consider adding the simple functions 
setRNG and getRNG from my setRNG package. Roughly, the functions make 
the  first ten lines of simulate.lm or Ben's code into a function call, 
which may not be so important other than the missing normal information, 
but having a standardized object with all the information seems to be 
useful.

The package also has documentation and tests, which can be helpful for 
other package builders that define simulate methods. It has been around 
for a long time so has been pretty well tested.

Paul Gilbert

Martin Maechler wrote:
> Thanks a lot, Heather,
> 
> 
>>>>>>"HT" == Heather Turner <Heather.Turner at warwick.ac.uk>
>>>>>>    on Fri, 13 Feb 2009 11:49:06 +0000 writes:
> 
> 
>     HT> Dear Martin,
>     HT> I think a simulate.glm method ought to be able to work for gnm objects
>     HT> too. David Firth and I started to work on this a long time ago, but
>     HT> stopped part-way through when simulate.lm was introduced, thinking that
>     HT> simulate.glm was probably in the pipeline and we were duplicating
>     HT> effort. Obviously we have let this slip when a contribution might have
>     HT> been useful. We developed a prototype for poisson, binomial, gaussian,
>     HT> gamma and inverse gaussian models which might be usefully merged with
>     HT> Ben's proposed simulate.glm. What's the best way to go about this? I
>     HT> would also like to test the proposed simulate.glm to check whether it
>     HT> will work with gnm objects or whether a simulate.gnm will be necessary.
> 
> In the mean time, private e-mail communications have started on
> the subject, and yes, we are very insterested in finding 
> ``the best'' possible way, probably making use of
> Heather+David's code together with Ben's. 
> One alternative (not mentioned yet on R-devel), we've been
> considering is to use simulate.lm() to also deal with "glm" (and
> possibly "gnm") objects ``in one place''.
> 
> Martin 
> 
> 
>     HT> Martin Maechler wrote:
>     >>>>>>> "BB" == Ben Bolker <bolker at ufl.edu>
>     >>>>>>> on Thu, 12 Feb 2009 11:29:14 -0500 writes:
>     >> 
>     BB> I have found the "simulate" method (incorporated
>     BB> in some packages) very handy. As far as I can tell the
>     BB> only class for which simulate is actually implemented
>     BB> in base R is lm ... this is actually a little dangerous
>     BB> for a naive user who might be tempted to try
>     BB> simulate(X) where X is a glm fit instead, because
>     BB> it defaults to simulate.lm (since glm inherits from
>     BB> the lm class), and the answers make no sense ...
>     >> 
>     BB> Here is my simulate.glm(), which is modeled on
>     BB> simulate.lm .  It implements simulation for poisson
>     BB> and binomial (binary or non-binary) models, should
>     BB> be easy to implement others if that seems necessary.
>     >> 
>     BB> I hereby request comments and suggest that it wouldn't
>     BB> hurt to incorporate it into base R ...  (I will write
>     BB> docs for it if necessary, perhaps by modifying ?simulate --
>     BB> there is no specific documentation for simulate.lm)
>     >> 
>     BB> cheers
>     BB> Ben Bolker
>     >> 
>     >> [...............]
>     >> 
>     >> Hi Ben,
>     >> thank you for your proposals.
>     >> 
>     >> I agree that  simulate.glm() has been in missing in some way,
>     >> till now, in particular, as, as you note, "glm" objects extend
>     >> "lm" ones and hence  simulate(<glm>, ...) currently dispatches to
>     >> calling simulate.lm(....) which is only correct in the case of
>     >> the gaussian family.
>     >> 
>     >> I have looked at your proposal a bit, already "improved" the
>     >> code slightly (e.g. re-include the comment you lost when you
>     >> ``copied'' simulate.lm():  In such cases, please work from the
>     >> source, not from what you get by print()ing
>     >> stats:::simulate.lm --- the source is either a recent tarball,
>     >> or the SVN repository, in this case, file
>     >> https://svn.r-project.org/R/trunk/src/library/stats/R/lm.R ]
>     >> and am planning to look at your and some own examples; 
>     >> all with the goal to indeed include this in the R standard
>     >> 'stats' package in R-devel [to become R 2.9.0 in the future].
>     >> 
>     >> About the help page:  At the moment, I think that only a few
>     >> words would need to be added to the simulate help page,
>     >> i.e., https://svn.r-project.org/R/trunk/src/library/stats/man/simulate.Rd
>     >> and will be happy to receive a patch against this file.
>     >> 
>     >> Thank you again, and best regards,
>     >> Martin Maechler, ETH Zurich
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
====================================================================================

La version fran?aise suit le texte anglais.

------------------------------------------------------------------------------------

This email may contain privileged and/or confidential information, and the Bank of
Canada does not waive any related rights. Any distribution, use, or copying of this
email or the information it contains by other than the intended recipient is
unauthorized. If you received this email in error please delete it immediately from
your system and notify the sender promptly by email that you have done so. 

------------------------------------------------------------------------------------

Le pr?sent courriel peut contenir de l'information privil?gi?e ou confidentielle.
La Banque du Canada ne renonce pas aux droits qui s'y rapportent. Toute diffusion,
utilisation ou copie de ce courriel ou des renseignements qu'il contient par une
personne autre que le ou les destinataires d?sign?s est interdite. Si vous recevez
ce courriel par erreur, veuillez le supprimer imm?diatement et envoyer sans d?lai ?
l'exp?diteur un message ?lectronique pour l'aviser que vous avez ?limin? de votre
ordinateur toute copie du courriel re?u.

From maechler at stat.math.ethz.ch  Fri Feb 13 21:27:57 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 13 Feb 2009 21:27:57 +0100
Subject: [Rd] proposed simulate.glm method
In-Reply-To: <49959745.9040700@warwick.ac.uk>
References: <49944E5A.1020000@ufl.edu>
	<18837.19884.215746.626683@stat.math.ethz.ch>
	<49955E32.8010005@warwick.ac.uk>
	<18837.32301.604378.110374@stat.math.ethz.ch>
	<49959745.9040700@warwick.ac.uk>
Message-ID: <18837.55245.15158.29378@cmath-5.math.ethz.ch>

Thank you, Heather and Ben,

>>>>> "HT" == Heather Turner <Heather.Turner at warwick.ac.uk>
>>>>>     on Fri, 13 Feb 2009 15:52:37 +0000 writes:

    HT> Yes, thanks to Ben for getting the ball rolling. His
    HT> code was more streamlined than mine, pointing to further
    HT> simplifications which I've included in the extended
    HT> version below.

    HT> The code for the additional families uses functions from
    HT> MASS and SuppDists - I wasn't sure about the best way to
    HT> do this, so have just used :: for now.

    HT> It appears to be working happily for both glm and gnm
    HT> objects (no gnm-specific code used).

    HT> Best wishes,

    HT> Heather

[....]

I have now followed Brian Ripley's suggetion to just extend
simulate.lm() to also deal with "glm" objects, but using
Heather's suggestions for the different families;
I've just commited src/library/stats/R/lm.R  with the new code.
(get it from  svn.r-project.org/R/trunk/ or this night's R-devel
 tarball).

One difference to your propsal: Instead of just
    object$fitted , the code is using
    fitted(object)  ... something which should properly to the na.action
used.

For the (MASS and) SuppDists package requirement, I'm using 
the following

      if(is.null(tryCatch(loadNamespace("SuppDists"),
			  error = function(e) NULL)))
	  stop("Need CRAN package 'SuppDists' for 'inverse.gaussian' family")


I've not yet updated the help page for simulate(),
and have only tested relatively few cases for binomial, poisson
and Gamma.
I've wanted to expose this to you, so you can provide more
feedback and possibly even a patch to
   svn.r-project.org/R/trunk/src/library/stats/man/simulate.Rd

Martin


From david at revolution-computing.com  Fri Feb 13 22:15:46 2009
From: david at revolution-computing.com (David M Smith)
Date: Fri, 13 Feb 2009 13:15:46 -0800
Subject: [Rd] Identifying graphics files produced by R
Message-ID: <475a3c8f0902131315q3291de31vdd43ad92bb213cb9@mail.gmail.com>

Oftentimes, I see graphs on the web that *look* like they've been
produced by R, but I can never be sure.  Or can I?  I notice that
PostScript files include a "%%%Creator: R Software" line, but do R
graphics drivers encode any identifying information in GIF or PNG
files more commonly used on the web?  And of so, would such evidence
necessarily be obliterated in post-processing (e.g cropping)?

I'm trying to do an informal survey of R's use to create statistical
graphics on the web, and if there's a way to identify graph files I
see as coming from R it would help a lot.

Thanks,
# David Smith

--
David M Smith <david at revolution-computing.com>
Director of Community, REvolution Computing www.revolution-computing.com
Tel: +1 (206) 577-4778 x3203 (Seattle, USA)


From HBaize at buttecounty.net  Fri Feb 13 23:04:49 2009
From: HBaize at buttecounty.net (HBaize)
Date: Fri, 13 Feb 2009 14:04:49 -0800 (PST)
Subject: [Rd] re ading SPSS .sav files (PR#13509)
In-Reply-To: <20090207160505.48F55283416A@mail.pubhealth.ku.dk>
References: <20090207160505.48F55283416A@mail.pubhealth.ku.dk>
Message-ID: <22005733.post@talk.nabble.com>




I have experience the same problem reading SPSS sav files using R 2.8.0 and
2.8.1 on Windows XP and Tinn-R version 2.1.1.6. I'm using SPSS 17.0 so it is
probably not related to SPSS version 11. I might add that I have been having
problems interfacing Tinn-R 2.1.1.6 with R although it may be unrelated to
the crash that results from attempting to read SPSS "sav" files.

Here is the code that results in the crash.

## ---
library(foreign)

scoresdat<- read.spss("H:/groups/evaluations/data/10101_012709_Scores.sav",
               to.data.frame=TRUE) 
## ---

I presumed the problem was with my installation of R, but repeated
reinstalls have not corrected the problem. 



zac-14 wrote:
> 
> Full_Name: Roger Newton
> Version: 2.8.1
> OS: windows 2000
> Submission from: (NULL) (80.176.228.157)
> 
> 
> I have an elderly version of SPSS (version 11) which I still use. R
> Version
> 2.6.1 would, and still will, read SPSS *.sav files produced by SPSS
> version 11.
> R version 2.8.1 which I installed two days ago (05/02/09) reports an error
> and
> shuts down when trying to read SPSS version 11 *.sav files using the
> read.spss
> function in package foreign.
> 
> R version 2.8.1 will read *.sav files produced by SPSS version 13.
> 
> The problem applies to all the existing SPSS files I had before I
> downloaded R
> 2.8.1
> and to several new SPSS 11 *.sav files I have produced since.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
View this message in context: http://www.nabble.com/reading-SPSS-.sav-files-%28PR-13509%29-tp21889920p22005733.html
Sent from the R devel mailing list archive at Nabble.com.


From HBaize at buttecounty.net  Fri Feb 13 23:26:05 2009
From: HBaize at buttecounty.net (HBaize)
Date: Fri, 13 Feb 2009 14:26:05 -0800 (PST)
Subject: [Rd] re ading SPSS .sav files (PR#13509)
In-Reply-To: <22005733.post@talk.nabble.com>
References: <20090207160505.48F55283416A@mail.pubhealth.ku.dk>
	<22005733.post@talk.nabble.com>
Message-ID: <22006079.post@talk.nabble.com>


Correction to my earlier post. The SPSS file that I was accessing was not
produced by SPSS 17.0. It was from 13.0, specifically:

SPSS DATA FILE MS Windows Release 13.0 spssio32.dll


My R version info:
               _                           
platform       i386-pc-mingw32             
arch           i386                        
os             mingw32                     
system         i386, mingw32               
status                                     
major          2                           
minor          8.1                         
year           2008                        
month          12                          
day            22                          
svn rev        47281                       
language       R                           
version.string R version 2.8.1 (2008-12-22)

## The version of foreign used:

               Information on package 'foreign'

Description:

Package:       foreign
Priority:      recommended
Version:       0.8-30
Date:          2008-12-22
Title:         Read Data Stored by Minitab, S, SAS, SPSS, Stata,
               Systat, dBase, ...
Depends:       R (>= 2.6.0), stats
Imports:       methods, utils
Maintainer:    R-core <R-core at r-project.org>
Author:        R-core members, Saikat DebRoy <saikat at stat.wisc.edu>,
               Roger Bivand <Roger.Bivand at nhh.no> and others: see
               COPYRIGHTS file in the sources.
Description:   Functions for reading and writing data stored by
               statistical packages such as Minitab, S, SAS, SPSS,
               Stata, Systat, ..., and for reading and writing .dbf
               (dBase) files.
LazyLoad:      yes
License:       GPL (>= 2)
Packaged:      Mon Dec 22 08:06:26 2008; ripley
Built:         R 2.8.1; i386-pc-mingw32; 2008-12-23 10:21:24; windows

I am trying to be diligent in reporting. Hope this helps. 
-- 
View this message in context: http://www.nabble.com/reading-SPSS-.sav-files-%28PR-13509%29-tp21889920p22006079.html
Sent from the R devel mailing list archive at Nabble.com.


From HBaize at buttecounty.net  Fri Feb 13 23:37:39 2009
From: HBaize at buttecounty.net (HBaize)
Date: Fri, 13 Feb 2009 14:37:39 -0800 (PST)
Subject: [Rd] re ading SPSS .sav files (PR#13509)
In-Reply-To: <22006079.post@talk.nabble.com>
References: <20090207160505.48F55283416A@mail.pubhealth.ku.dk>
	<22005733.post@talk.nabble.com> <22006079.post@talk.nabble.com>
Message-ID: <22006239.post@talk.nabble.com>


Full session info as R with packages as loaded when the crash occurs (note
that the session is lost as R closes with the crash):

R version 2.8.1 (2008-12-22) 
i386-pc-mingw32 

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
States.1252;LC_MONETARY=English_United
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] foreign_0.8-30 UsingR_0.1-12  car_1.2-12     gplots_2.6.0   gdata_2.4.2   
[6] gtools_2.5.0  
R> 

-- 
View this message in context: http://www.nabble.com/reading-SPSS-.sav-files-%28PR-13509%29-tp21889920p22006239.html
Sent from the R devel mailing list archive at Nabble.com.


From p.dalgaard at biostat.ku.dk  Sat Feb 14 00:01:15 2009
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat, 14 Feb 2009 00:01:15 +0100
Subject: [Rd] re ading SPSS .sav files (PR#13509)
In-Reply-To: <22005733.post@talk.nabble.com>
References: <20090207160505.48F55283416A@mail.pubhealth.ku.dk>
	<22005733.post@talk.nabble.com>
Message-ID: <4995FBBB.9000909@biostat.ku.dk>

HBaize wrote:
> 
> 
> I have experience the same problem reading SPSS sav files using R 2.8.0 and
> 2.8.1 on Windows XP and Tinn-R version 2.1.1.6. I'm using SPSS 17.0 so it is
> probably not related to SPSS version 11. I might add that I have been having
> problems interfacing Tinn-R 2.1.1.6 with R although it may be unrelated to
> the crash that results from attempting to read SPSS "sav" files.
> 
> Here is the code that results in the crash.
> 
> ## ---
> library(foreign)
> 
> scoresdat<- read.spss("H:/groups/evaluations/data/10101_012709_Scores.sav",
>                to.data.frame=TRUE) 

And what happens next? RGui crashes?

Is it possible to put the file on a webpage (or maybe a subset showing 
the same syptoms)? Without it, the problem is not really reproducible by 
anyone but you.


-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From HBaize at buttecounty.net  Sat Feb 14 00:11:14 2009
From: HBaize at buttecounty.net (HBaize)
Date: Fri, 13 Feb 2009 15:11:14 -0800 (PST)
Subject: [Rd] re  ading SPSS .sav files (PR#13509)
In-Reply-To: <4995FBBB.9000909@biostat.ku.dk>
References: <20090207160505.48F55283416A@mail.pubhealth.ku.dk>
	<22005733.post@talk.nabble.com> <4995FBBB.9000909@biostat.ku.dk>
Message-ID: <22006704.post@talk.nabble.com>


Yes the GUI crashes with the message:
"R for Windows GUI front-end has encountered a problem and needs to close."
giving two options debug ro close. Either button will close R.

Additional information: 
I have replicated the crash using SPSS sav files from version 13.0 and 17.0.
It does not crash reading files from SPSS versions 10.0.3, 11.0, or 12.0. I
would supply a sample SPSS sav file but most of my files contain
confidential health information. I could create one and upload it in a few
hours. I can't do it from my workplace. Office security issues.

 


Peter Dalgaard wrote:
> 
> HBaize wrote:
> 
> And what happens next? RGui crashes?
> 
> Is it possible to put the file on a webpage (or maybe a subset showing 
> the same syptoms)? Without it, the problem is not really reproducible by 
> anyone but you.
> 
> 
> -- 
>     O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>    c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>   (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
View this message in context: http://www.nabble.com/reading-SPSS-.sav-files-%28PR-13509%29-tp21889920p22006704.html
Sent from the R devel mailing list archive at Nabble.com.


From HBaize at buttecounty.net  Sat Feb 14 00:53:24 2009
From: HBaize at buttecounty.net (HBaize)
Date: Fri, 13 Feb 2009 15:53:24 -0800 (PST)
Subject: [Rd] re  ading SPSS .sav files (PR#13509)
In-Reply-To: <22006704.post@talk.nabble.com>
References: <20090207160505.48F55283416A@mail.pubhealth.ku.dk>
	<22005733.post@talk.nabble.com> <4995FBBB.9000909@biostat.ku.dk>
	<22006704.post@talk.nabble.com>
Message-ID: <22007185.post@talk.nabble.com>



Repeated trials have produced no crashes with SPSS sav files from version
10.0.5, 11.0, 12.0, or 14.0. SPSS sav files from Version 17.0 consistently
crashes R. Some version 13.0 files will crash R. The version 13.0 files that
crash R were sent to me by a colleague. My locally produced 13.0 files
(generated in 2005) do not crash R. 

On a trial read of a SPSS version 17.0 file the first run produced these
messages:

Warning messages:
1: In read.spss("H:/groups/evaluations/ccoc/data/testRcrash.sav",
to.data.frame = TRUE) :
  H:/groups/evaluations/ccoc/data/testRcrash.sav: File-indicated character
representation code (1252) looks like a Windows codepage
2: In read.spss("H:/groups/evaluations/ccoc/data/testRcrash.sav",
to.data.frame = TRUE) :
  H:/groups/evaluations/ccoc/data/testRcrash.sav: Unrecognized record type
7, subtype 20 encountered in system file

These messages are similar to warnings that R use to generate in reading
SPSS files from version 12.0 and later. 

The second try to read that file in the same session crashed R. 

I will upload an SPSS 17.0 file to my web space in a few hours and post the
location.

-- 
View this message in context: http://www.nabble.com/reading-SPSS-.sav-files-%28PR-13509%29-tp21889920p22007185.html
Sent from the R devel mailing list archive at Nabble.com.


From HBaize at buttecounty.net  Sat Feb 14 03:42:12 2009
From: HBaize at buttecounty.net (HBaize)
Date: Fri, 13 Feb 2009 18:42:12 -0800 (PST)
Subject: [Rd] re  ading SPSS .sav files (PR#13509)
In-Reply-To: <22007185.post@talk.nabble.com>
References: <20090207160505.48F55283416A@mail.pubhealth.ku.dk>
	<22005733.post@talk.nabble.com> <4995FBBB.9000909@biostat.ku.dk>
	<22006704.post@talk.nabble.com> <22007185.post@talk.nabble.com>
Message-ID: <22008606.post@talk.nabble.com>



I've uploaded sample SPSS sav files to my web space. 

This file was made with SPSS verion 13.0 and does NOT crash R 2.8.1 on my
machine:
http://www.3dculture.com/images/Florida2000ElectionData.sav

This is the same file, but saved with SPSS ver 17.0, 
it does not crash but returns warnings:
http://www.3dculture.com/images/test17Florida2000election.sav

The remaining files were also saved with SPSS 17.0

This file consistently crashes R:
http://www.3dculture.com/images/testRcrash.sav

This file was also saved with SPSS 17 and is a subset of "testRcrash.sav"
yet 
it does not crash R and returns warnings like the ones in my post above:
http://www.3dculture.com/images/testRwarn.sav

Another SPSS 17.0 sav file that consistently crashes R 2.8.1:
http://www.3dculture.com/images/test17miss.sav
-- 
View this message in context: http://www.nabble.com/reading-SPSS-.sav-files-%28PR-13509%29-tp21889920p22008606.html
Sent from the R devel mailing list archive at Nabble.com.


From cowan.pd at gmail.com  Sat Feb 14 05:02:28 2009
From: cowan.pd at gmail.com (Peter Cowan)
Date: Fri, 13 Feb 2009 20:02:28 -0800
Subject: [Rd] [PATCH] typo in R-lang
Message-ID: <e1fc21b0902132002w293b01cbh396cf3c205718a2d@mail.gmail.com>

Here is a patch for a small typo in the description of do.call()

in case the inline version is unsuitable:
<http://pastie.textmate.org/388914.txt?key=ado6iu82ikvj5sk18bx5mg>



Index: /Users/peter/manual/R-lang.texi
===================================================================
--- /Users/peter/manual/R-lang.texi	(revision 47919)
+++ /Users/peter/manual/R-lang.texi	(working copy)
@@ -3683,7 +3683,7 @@
 used rather rarely, but is occasionally useful where the name of a
 function is available as a character variable.

-The function @code{do.call} is related, but evaluates the call immediate
+The function @code{do.call} is related, but evaluates the call immediately
 and takes the arguments from an object of mode @code{"list"} containing
 all the arguments.  A natural use of this is when one wants to apply a
 function like @code{cbind} to all elements of a list or data frame.


From romain.francois at dbmail.com  Sat Feb 14 09:57:58 2009
From: romain.francois at dbmail.com (Romain Francois)
Date: Sat, 14 Feb 2009 09:57:58 +0100
Subject: [Rd] Identifying graphics files produced by R
In-Reply-To: <475a3c8f0902131315q3291de31vdd43ad92bb213cb9@mail.gmail.com>
References: <475a3c8f0902131315q3291de31vdd43ad92bb213cb9@mail.gmail.com>
Message-ID: <49968796.8050501@dbmail.com>

Hi,

I don't know the answer but here is how I would try to get it from the 
source:

$ cd  R-devel/src
$ grep -R "R Software" *
Binary file library/grDevices/src/grDevices.so matches
library/grDevices/src/devPS.c:    fprintf(fp, "%%%%Creator: R Software\n");
Binary file library/grDevices/src/devPS.o matches

$ wc library/grDevices/src/*.c
   426   1928  10606 library/grDevices/src/chull.c
   195    658   5395 library/grDevices/src/devNull.c
   775   2771  24480 library/grDevices/src/devPicTeX.c
  7592  26813 212324 library/grDevices/src/devPS.c
  1375   5342  48939 library/grDevices/src/devQuartz.c
  3401  12322 100782 library/grDevices/src/devWindows.c
    75    273   2113 library/grDevices/src/init.c
   189    807   7436 library/grDevices/src/qdBitmap.c
   165    646   5416 library/grDevices/src/qdPDF.c
 14193  51560 417491 total

Somewhere in the 14193 lines of code is your answer. Probably also worth 
looking in the  modules/X11/ and unix directories

Romain

-- 
Romain Francois
Independent R Consultant
+33(0) 6 28 91 30 30
http://romainfrancois.blog.free.fr




David M Smith wrote:
> Oftentimes, I see graphs on the web that *look* like they've been
> produced by R, but I can never be sure.  Or can I?  I notice that
> PostScript files include a "%%%Creator: R Software" line, but do R
> graphics drivers encode any identifying information in GIF or PNG
> files more commonly used on the web?  And of so, would such evidence
> necessarily be obliterated in post-processing (e.g cropping)?
>
> I'm trying to do an informal survey of R's use to create statistical
> graphics on the web, and if there's a way to identify graph files I
> see as coming from R it would help a lot.
>
> Thanks,
> # David Smith
>
> --
> David M Smith <david at revolution-computing.com>
> Director of Community, REvolution Computing www.revolution-computing.com
> Tel: +1 (206) 577-4778 x3203 (Seattle, USA)
>


From maechler at stat.math.ethz.ch  Sat Feb 14 10:38:22 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 14 Feb 2009 10:38:22 +0100
Subject: [Rd] [PATCH] typo in R-lang
In-Reply-To: <e1fc21b0902132002w293b01cbh396cf3c205718a2d@mail.gmail.com>
References: <e1fc21b0902132002w293b01cbh396cf3c205718a2d@mail.gmail.com>
Message-ID: <18838.37134.787078.791757@cmath-5.math.ethz.ch>

Thank you,  Peter;
I just have committed the fix for the typo.
(The inline patch was perfectly sufficient)

Martin Maechler, ETH Zurich

>>>>> "PC" == Peter Cowan <cowan.pd at gmail.com>
>>>>>     on Fri, 13 Feb 2009 20:02:28 -0800 writes:

    PC> Here is a patch for a small typo in the description of do.call()

    PC> in case the inline version is unsuitable:
    PC> <http://pastie.textmate.org/388914.txt?key=ado6iu82ikvj5sk18bx5mg>



    PC> Index: /Users/peter/manual/R-lang.texi
    PC> ===================================================================
    PC> --- /Users/peter/manual/R-lang.texi	(revision 47919)
    PC> +++ /Users/peter/manual/R-lang.texi	(working copy)
    PC> @@ -3683,7 +3683,7 @@
    PC> used rather rarely, but is occasionally useful where the name of a
    PC> function is available as a character variable.

    PC> -The function @code{do.call} is related, but evaluates the call immediate
    PC> +The function @code{do.call} is related, but evaluates the call immediately
    PC> and takes the arguments from an object of mode @code{"list"} containing
    PC> all the arguments.  A natural use of this is when one wants to apply a
    PC> function like @code{cbind} to all elements of a list or data frame.

    PC> ______________________________________________
    PC> R-devel at r-project.org mailing list
    PC> https://stat.ethz.ch/mailman/listinfo/r-devel


From fabio.ufla at yahoo.com.br  Sat Feb 14 11:09:01 2009
From: fabio.ufla at yahoo.com.br (Fabio Mathias)
Date: Sat, 14 Feb 2009 02:09:01 -0800 (PST)
Subject: [Rd] Generate random numbers in Fortran
In-Reply-To: <4A433411-CB1A-45FC-B8A5-EAE4FE8A6AB1@epfl.ch>
Message-ID: <192595.78667.qm@web59704.mail.ac4.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090214/93727213/attachment.pl>

From ripley at stats.ox.ac.uk  Sat Feb 14 12:28:07 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 14 Feb 2009 11:28:07 +0000 (GMT)
Subject: [Rd] Generate random numbers in Fortran
In-Reply-To: <192595.78667.qm@web59704.mail.ac4.yahoo.com>
References: <192595.78667.qm@web59704.mail.ac4.yahoo.com>
Message-ID: <alpine.LFD.2.00.0902141124510.13328@gannet.stats.ox.ac.uk>

There are lots of invalid characters in your mail, but Fortran code 
starts in column 7 and that is what the compiler is telling you you 
have not done.  (Some dialects will allow tabs instead, but I see no 
sing of those either.)

If you are that unfamiliar with Fortran, why not just use C?

On Sat, 14 Feb 2009, Fabio Mathias wrote:

> As I am wanting to generate a beta, then I created a function in C to
> generate a beta, but the problem appears when I go to compile
>
> My function in C is
>
> #include <R.h>
> #include <Rmath.h>
> #include <math.h>
>
> void F77_SUB(myrbeta)(double* px)
> {
> ?????? GetRNGstate();
> ?????? *px = rbeta(1.00,3.00);
> ?????? PutRNGstate();
> }
>
> My function in Fortran is
>
> subroutine blah(a)
> double precision (a)
> call myrbeta(RND)
> end
>
> The error
>
> fmcron at fmcron-desktop:~/teste$ R CMD SHLIB mat.c blah.f
> gcc -std=gnu99 -I/usr/share/R/include?????????? -fpic?? -g -O2 -c mat.c -o mat.o
> gfortran???? -fpic?? -g -O2 -c blah.f -o blah.o
> blah.f:1.1:
>
> subroutine blah(a)??????????????????????????????????????????????????????????????????????????????????????????????????????????
> 1
> Erro: Non-numeric character in statement label at (1)
> blah.f:1.1:
>
> subroutine blah(a)??????????????????????????????????????????????????????????????????????????????????????????????????????????
> 1
> Erro: Unclassifiable statement at (1)
> blah.f:2.1:
>
> double precision (a)??????????????????????????????????????????????????????????????????????????????????????????????????????
> 1
> Erro: Non-numeric character in statement label at (1)
> blah.f:2.1:
>
> double precision (a)??????????????????????????????????????????????????????????????????????????????????????????????????????
> 1
> Erro: Unclassifiable statement at (1)
> blah.f:4.1:
>
> end????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
> 1
> Erro: Non-numeric character in statement label at (1)
> blah.f:4.1:
>
> end????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
> 1
> Erro: Unclassifiable statement at (1)
> make: ** [blah.o] Erro 1
>
>
> ???????????????????????? F??bio Mathias Corr??a???????????????????????????????????????????? UFLA
>
>
> --- Em sex, 13/2/09, Kjell Konis <kjell.konis at epfl.ch> escreveu:
> De: Kjell Konis <kjell.konis at epfl.ch>
> Assunto: Re: [Rd] Generate random numbers in Fortran
> Para: "fabio.ufla at yahoo.com.br" <fabio.ufla at yahoo.com.br>
> Cc: "r-devel at r-project.org" <r-devel at r-project.org>
> Data: Sexta-feira, 13 de Fevereiro de 2009, 16:49
>
> Take a look at section 6.6 in Writing R Extensions. It describes how to call C
> functions from FORTRAN. Basically it just boils down to this, in a C file define
> the functions
>
> void F77_SUB(fseedi)(void)
> {
>  int x = 100;
>  seed_in(&x);
> }
>
>
> void F77_SUB(fseedo)(void)
> {
>  int x = 100;
>  seed_out(&x);
> }
>
>
> void F77_SUB(myrunif)(double* px)
> {
> 	*px = unif_rand();
> }
>
>
> Then you could write a FORTRAN subroutine like
>
>      subroutine blah()
>      implicit double precision (a-h,o-z)
>      call fseedi()
>      call myrunif(RND)
>      call fseedo()
>      end
>
> The fseed* subroutines only need to be called once, fseedi at the beginning of
> your FORTRAN code and fseedo at the end.
>
> HTH,
> Kjell
>
>
> On 13 f??vr. 09, at 17:32, Fabio Mathias wrote:
>
>> Hi!!!
>> It would like to know if it exists a form to use the functions to
>> generate variates in FORTRAN with the same easiness I use that them in
>> C? Or not?
>> If yes. They would have some example? I would like to use the functions
> rbeta, rlnorm and others!
>>
>>
>> Sorry my english..rsrsrs
>>
>> Thanks!!!
>>
>>
>>              F??bio Mathias Corr??a    University Federal of the Lavras -
> Brazil
>>
>>
>>
>>      Veja quais s??o os assuntos do momento no Yahoo! +Buscados
>>
>> 	[[alternative HTML version deleted]]
>>
>> <ATT00001.txt>
>
>
>
>
>      Veja quais s??o os assuntos do momento no Yahoo! +Buscados
>
> 	[[alternative HTML version deleted]]
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From kjell.konis at epfl.ch  Sat Feb 14 12:35:57 2009
From: kjell.konis at epfl.ch (Kjell Konis)
Date: Sat, 14 Feb 2009 12:35:57 +0100
Subject: [Rd] Generate random numbers in Fortran
In-Reply-To: <192595.78667.qm@web59704.mail.ac4.yahoo.com>
References: <192595.78667.qm@web59704.mail.ac4.yahoo.com>
Message-ID: <7F49BF4A-ED11-483F-9FE8-4D4E6C406F15@epfl.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090214/d8de55cf/attachment.pl>

From nikko at hailmail.net  Sat Feb 14 17:34:45 2009
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Sat, 14 Feb 2009 08:34:45 -0800
Subject: [Rd] proposed simulate.glm method
In-Reply-To: <mailman.19.1234609204.29849.r-devel@r-project.org>
References: <mailman.19.1234609204.29849.r-devel@r-project.org>
Message-ID: <1234629285.24649.1300366683@webmail.messagingengine.com>

Hi,
For extended glms such as gams, gnm or other distributions
such as negative binomial, would there need to be a separate simulate
method?
Or, could the current framework, rather than stopping with an error
look for the appropriate model matrix, coefficients, distribution
function and family object
to simulate from? 

Nicholas 


> Message: 9
> Date: Fri, 13 Feb 2009 21:27:57 +0100
> From: Martin Maechler <maechler at stat.math.ethz.ch>
> Subject: Re: [Rd] proposed simulate.glm method
> To: Heather Turner <Heather.Turner at warwick.ac.uk>
> Cc: r-devel at r-project.org, Martin Maechler
> 	<maechler at stat.math.ethz.ch>
> Message-ID: <18837.55245.15158.29378 at cmath-5.math.ethz.ch>
> Content-Type: text/plain; charset=us-ascii
> 
> Thank you, Heather and Ben,
> 
> >>>>> "HT" == Heather Turner <Heather.Turner at warwick.ac.uk>
> >>>>>     on Fri, 13 Feb 2009 15:52:37 +0000 writes:
> 
>     HT> Yes, thanks to Ben for getting the ball rolling. His
>     HT> code was more streamlined than mine, pointing to further
>     HT> simplifications which I've included in the extended
>     HT> version below.
> 
>     HT> The code for the additional families uses functions from
>     HT> MASS and SuppDists - I wasn't sure about the best way to
>     HT> do this, so have just used :: for now.
> 
>     HT> It appears to be working happily for both glm and gnm
>     HT> objects (no gnm-specific code used).
> 
>     HT> Best wishes,
> 
>     HT> Heather
> 
> [....]
> 
> I have now followed Brian Ripley's suggetion to just extend
> simulate.lm() to also deal with "glm" objects, but using
> Heather's suggestions for the different families;
> I've just commited src/library/stats/R/lm.R  with the new code.
> (get it from  svn.r-project.org/R/trunk/ or this night's R-devel
>  tarball).
> 
> One difference to your propsal: Instead of just
>     object$fitted , the code is using
>     fitted(object)  ... something which should properly to the na.action
> used.
> 
> For the (MASS and) SuppDists package requirement, I'm using 
> the following
> 
>       if(is.null(tryCatch(loadNamespace("SuppDists"),
> 			  error = function(e) NULL)))
> 	  stop("Need CRAN package 'SuppDists' for 'inverse.gaussian' family")
> 
> 
> I've not yet updated the help page for simulate(),
> and have only tested relatively few cases for binomial, poisson
> and Gamma.
> I've wanted to expose this to you, so you can provide more
> feedback and possibly even a patch to
>    svn.r-project.org/R/trunk/src/library/stats/man/simulate.Rd
> 
> Martin
> 
> 
>


From maechler at stat.math.ethz.ch  Sat Feb 14 20:10:26 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 14 Feb 2009 20:10:26 +0100
Subject: [Rd] proposed simulate.glm method
In-Reply-To: <1234629285.24649.1300366683@webmail.messagingengine.com>
References: <mailman.19.1234609204.29849.r-devel@r-project.org>
	<1234629285.24649.1300366683@webmail.messagingengine.com>
Message-ID: <18839.5922.163409.980989@cmath-5.math.ethz.ch>

>>>>> "NicLK" == Nicholas Lewin-Koh <nikko at hailmail.net>
>>>>>     on Sat, 14 Feb 2009 08:34:45 -0800 writes:

    NicLK> Hi, For extended glms such as gams, gnm or other
    NicLK> distributions such as negative binomial, would there
    NicLK> need to be a separate simulate method?  

Not necessarily,  as I said, the "glm"s are now also dealt with
in simulate.lm() and Heather more or less confirmed that this
gives correct results for "gnm" objects.

For gam(), I'd strongly expect the same to apply, but there
maybe sophisticated gam() models where the result is currently
not correct.  That's, BTW, also true for  
    simulate(lm(...., weights), ...)

    NicLK>  Or, could the current framework, rather than
    NicLK> stopping with an error look for the appropriate model
    NicLK> matrix, coefficients, distribution function and
    NicLK> family object to simulate from?

What do you mean?
A situation where there's no supported 'family'
or a situation where  predict(<obj>) does not work as it's
supposed in the current framework,
or ????

If there are such cases, we'd have to consider them together
with the corresponding package author.  It may often make sense
fthen that the author changes his methods {predict(), ..} such
that the (now) extended simulate.lm() will work automatically;
Alternatively, the author can provide  simulate.<myclass>().

But I'm not sure I'm answering the question you've asked..
Martin

    NicLK> Nicholas


    >> Message: 9 Date: Fri, 13 Feb 2009 21:27:57 +0100 From:
    >> Martin Maechler <maechler at stat.math.ethz.ch> Subject: Re:
    >> [Rd] proposed simulate.glm method To: Heather Turner
    >> <Heather.Turner at warwick.ac.uk> Cc: r-devel at r-project.org,
    >> Martin Maechler <maechler at stat.math.ethz.ch> Message-ID:
    >> <18837.55245.15158.29378 at cmath-5.math.ethz.ch>
    >> Content-Type: text/plain; charset=us-ascii
    >> 
    >> Thank you, Heather and Ben,
    >> 
    >> >>>>> "HT" == Heather Turner
    >> <Heather.Turner at warwick.ac.uk> >>>>> on Fri, 13 Feb 2009
    >> 15:52:37 +0000 writes:
    >> 
    HT> Yes, thanks to Ben for getting the ball rolling. His
    HT> code was more streamlined than mine, pointing to further
    HT> simplifications which I've included in the extended
    HT> version below.
    >> 
    HT> The code for the additional families uses functions from
    HT> MASS and SuppDists - I wasn't sure about the best way to
    HT> do this, so have just used :: for now.
    >> 
    HT> It appears to be working happily for both glm and gnm
    HT> objects (no gnm-specific code used).
    >> 
    HT> Best wishes,
    >> 
    HT> Heather
    >> 
    >> [....]
    >> 
    >> I have now followed Brian Ripley's suggetion to just
    >> extend simulate.lm() to also deal with "glm" objects, but
    >> using Heather's suggestions for the different families;
    >> I've just commited src/library/stats/R/lm.R with the new
    >> code.  (get it from svn.r-project.org/R/trunk/ or this
    >> night's R-devel tarball).
    >> 
    >> One difference to your propsal: Instead of just
    >> object$fitted , the code is using fitted(object)
    >> ... something which should properly to the na.action
    >> used.
    >> 
    >> For the (MASS and) SuppDists package requirement, I'm
    >> using the following
    >> 
    >> if(is.null(tryCatch(loadNamespace("SuppDists"), error =
    >> function(e) NULL))) stop("Need CRAN package 'SuppDists'
    >> for 'inverse.gaussian' family")
    >> 
    >> 
    >> I've not yet updated the help page for simulate(), and
    >> have only tested relatively few cases for binomial,
    >> poisson and Gamma.  I've wanted to expose this to you, so
    >> you can provide more feedback and possibly even a patch
    >> to
    >> svn.r-project.org/R/trunk/src/library/stats/man/simulate.Rd
    >> 
    >> Martin
    >> 
    >> 
    >> 

______________________________________________
    NicLK> R-devel at r-project.org mailing list
    NicLK> https://stat.ethz.ch/mailman/listinfo/r-devel


From nikko at hailmail.net  Sat Feb 14 20:35:32 2009
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Sat, 14 Feb 2009 11:35:32 -0800
Subject: [Rd] proposed simulate.glm method
In-Reply-To: <18839.5922.163409.980989@cmath-5.math.ethz.ch>
References: <mailman.19.1234609204.29849.r-devel@r-project.org>
	<1234629285.24649.1300366683@webmail.messagingengine.com>
	<18839.5922.163409.980989@cmath-5.math.ethz.ch>
Message-ID: <1234640132.23619.1300384663@webmail.messagingengine.com>

Hi,
Well, my question wasn't that clear :-), but yes you mostly answered it.
I guess
the one case I would be concerned is in Heather's code, where the
distribution
to simulate from is chosen, that seemed to be hard coded. So if 
I built a family object, say for a model that assumes errors from a zipf
distribution,
and I did have a predict method (which is a fair assumption) would that
fail because the rzipf function would not be accessed?

Nicholas 
On Sat, 14 Feb 2009 20:10:26 +0100, "Martin Maechler"
<maechler at stat.math.ethz.ch> said:
> >>>>> "NicLK" == Nicholas Lewin-Koh <nikko at hailmail.net>
> >>>>>     on Sat, 14 Feb 2009 08:34:45 -0800 writes:
> 
>     NicLK> Hi, For extended glms such as gams, gnm or other
>     NicLK> distributions such as negative binomial, would there
>     NicLK> need to be a separate simulate method?  
> 
> Not necessarily,  as I said, the "glm"s are now also dealt with
> in simulate.lm() and Heather more or less confirmed that this
> gives correct results for "gnm" objects.
> 
> For gam(), I'd strongly expect the same to apply, but there
> maybe sophisticated gam() models where the result is currently
> not correct.  That's, BTW, also true for  
>     simulate(lm(...., weights), ...)
> 
>     NicLK>  Or, could the current framework, rather than
>     NicLK> stopping with an error look for the appropriate model
>     NicLK> matrix, coefficients, distribution function and
>     NicLK> family object to simulate from?
> 
> What do you mean?
> A situation where there's no supported 'family'
> or a situation where  predict(<obj>) does not work as it's
> supposed in the current framework,
> or ????
> 
> If there are such cases, we'd have to consider them together
> with the corresponding package author.  It may often make sense
> fthen that the author changes his methods {predict(), ..} such
> that the (now) extended simulate.lm() will work automatically;
> Alternatively, the author can provide  simulate.<myclass>().
> 
> But I'm not sure I'm answering the question you've asked..
> Martin
> 
>     NicLK> Nicholas
> 
> 
>     >> Message: 9 Date: Fri, 13 Feb 2009 21:27:57 +0100 From:
>     >> Martin Maechler <maechler at stat.math.ethz.ch> Subject: Re:
>     >> [Rd] proposed simulate.glm method To: Heather Turner
>     >> <Heather.Turner at warwick.ac.uk> Cc: r-devel at r-project.org,
>     >> Martin Maechler <maechler at stat.math.ethz.ch> Message-ID:
>     >> <18837.55245.15158.29378 at cmath-5.math.ethz.ch>
>     >> Content-Type: text/plain; charset=us-ascii
>     >> 
>     >> Thank you, Heather and Ben,
>     >> 
>     >> >>>>> "HT" == Heather Turner
>     >> <Heather.Turner at warwick.ac.uk> >>>>> on Fri, 13 Feb 2009
>     >> 15:52:37 +0000 writes:
>     >> 
>     HT> Yes, thanks to Ben for getting the ball rolling. His
>     HT> code was more streamlined than mine, pointing to further
>     HT> simplifications which I've included in the extended
>     HT> version below.
>     >> 
>     HT> The code for the additional families uses functions from
>     HT> MASS and SuppDists - I wasn't sure about the best way to
>     HT> do this, so have just used :: for now.
>     >> 
>     HT> It appears to be working happily for both glm and gnm
>     HT> objects (no gnm-specific code used).
>     >> 
>     HT> Best wishes,
>     >> 
>     HT> Heather
>     >> 
>     >> [....]
>     >> 
>     >> I have now followed Brian Ripley's suggetion to just
>     >> extend simulate.lm() to also deal with "glm" objects, but
>     >> using Heather's suggestions for the different families;
>     >> I've just commited src/library/stats/R/lm.R with the new
>     >> code.  (get it from svn.r-project.org/R/trunk/ or this
>     >> night's R-devel tarball).
>     >> 
>     >> One difference to your propsal: Instead of just
>     >> object$fitted , the code is using fitted(object)
>     >> ... something which should properly to the na.action
>     >> used.
>     >> 
>     >> For the (MASS and) SuppDists package requirement, I'm
>     >> using the following
>     >> 
>     >> if(is.null(tryCatch(loadNamespace("SuppDists"), error =
>     >> function(e) NULL))) stop("Need CRAN package 'SuppDists'
>     >> for 'inverse.gaussian' family")
>     >> 
>     >> 
>     >> I've not yet updated the help page for simulate(), and
>     >> have only tested relatively few cases for binomial,
>     >> poisson and Gamma.  I've wanted to expose this to you, so
>     >> you can provide more feedback and possibly even a patch
>     >> to
>     >> svn.r-project.org/R/trunk/src/library/stats/man/simulate.Rd
>     >> 
>     >> Martin
>     >> 
>     >> 
>     >> 
> 
> ______________________________________________
>     NicLK> R-devel at r-project.org mailing list
>     NicLK> https://stat.ethz.ch/mailman/listinfo/r-devel


From bolker at ufl.edu  Sat Feb 14 21:40:58 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Sat, 14 Feb 2009 20:40:58 +0000 (UTC)
Subject: [Rd] Generate random numbers in Fortran
References: <81334.15708.qm@web59716.mail.ac4.yahoo.com>
	<4995A84D.1020002@idi.ntnu.no>
Message-ID: <loom.20090214T203642-925@post.gmane.org>

Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk <at> idi.ntnu.no> writes:

> 
> you can always try to get hold of the extensive nag fortran libraries:
> 
> http://www.nag.co.uk/numeric/fl/FLdescription.asp
> 
> comsider also 'numerical recipes' by press et al., of which there are
> fortran, c, and c++ editions (i think there was a pascal edition too),
> and where there are a choice of routines for random number generation,
> statistics, and much more.  a good read, too.
> 
> vQ

  If one can get the R routines to work, I think they have some
advantages over NAG and Numerical Recipes routines:
 
  * source code is freely redistributable
  * I can't really claim expertise, but I believe there
has been some controversy (see the wikipedia page on NR,
http://en.wikipedia.org/wiki/Numerical_Recipes )

  The big advantage of NR is not in the algorithms, but
in the explanations in the book ...
  
  (The wikipedia page also refers to the Gnu Scientific Library,
which might be another set of options.)

  Ben Bolker


From bolker at ufl.edu  Sat Feb 14 22:05:01 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Sat, 14 Feb 2009 21:05:01 +0000 (UTC)
Subject: [Rd] Generate random numbers in Fortran
References: <81334.15708.qm@web59716.mail.ac4.yahoo.com>
	<4995A84D.1020002@idi.ntnu.no>
	<loom.20090214T203642-925@post.gmane.org>
Message-ID: <loom.20090214T210406-748@post.gmane.org>

Ben Bolker <bolker <at> ufl.edu> writes:

> > vQ
> 
>   If one can get the R routines to work, I think they have some
> advantages over NAG and Numerical Recipes routines:
> 
>   * source code is freely redistributable
>   * I can't really claim expertise, but I believe there
> has been some controversy (see the wikipedia page on NR,
> http://en.wikipedia.org/wiki/Numerical_Recipes )
> 
>   The big advantage of NR is not in the algorithms, but
> in the explanations in the book ...
> 
>   (The wikipedia page also refers to the Gnu Scientific Library,
> which might be another set of options.)
> 
>   Ben Bolker
> 
> ______________________________________________


  PS (replying to myself) there's an eloquent criticism
of NR's licensing policies at
http://www.astro.umd.edu/~bjw/software/boycottnr.html
which articulates a lot of my complaints better than I could

  Ben


From ripley at stats.ox.ac.uk  Sat Feb 14 22:43:38 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 14 Feb 2009 21:43:38 +0000 (GMT)
Subject: [Rd] proposed simulate.glm method
In-Reply-To: <1234640132.23619.1300384663@webmail.messagingengine.com>
References: <mailman.19.1234609204.29849.r-devel@r-project.org>
	<1234629285.24649.1300366683@webmail.messagingengine.com>
	<18839.5922.163409.980989@cmath-5.math.ethz.ch>
	<1234640132.23619.1300384663@webmail.messagingengine.com>
Message-ID: <alpine.OSX.1.00.0902142117570.10945@tystie.local>

On Sat, 14 Feb 2009, Nicholas Lewin-Koh wrote:

> Well, my question wasn't that clear :-), but yes you mostly answered 
> it. I guess the one case I would be concerned is in Heather's code, 
> where the distribution to simulate from is chosen, that seemed to be 
> hard coded.

Rather, all known glm families in R that correspond to actual 
probability distributions are listed.

> So if I built a family object, say for a model that assumes errors 
> from a zipf distribution,

Hmm, plese explain how you get that into the GLM framework -- it is 
pretty restrictive.

> and I did have a predict method (which is a fair assumption) would that
> fail because the rzipf function would not be accessed?

glm has a predict method, so why do you need one?  Families do not 
create additional classes of fit objects.

We could extend the definition of a family to have a 'simulate' 
element, but then existing user-contributed families (principally the 
negative binomial) would not have one and so this would not solve the 
problem .....

If you know of an actual R implementation of another glm family that 
looks generally useful we'll consider adding it (but it seems that the 
end user could also do so rather easily).


> Nicholas
> On Sat, 14 Feb 2009 20:10:26 +0100, "Martin Maechler"
> <maechler at stat.math.ethz.ch> said:
>>>>>>> "NicLK" == Nicholas Lewin-Koh <nikko at hailmail.net>
>>>>>>>     on Sat, 14 Feb 2009 08:34:45 -0800 writes:
>>
>>     NicLK> Hi, For extended glms such as gams, gnm or other
>>     NicLK> distributions such as negative binomial, would there
>>     NicLK> need to be a separate simulate method?
>>
>> Not necessarily,  as I said, the "glm"s are now also dealt with
>> in simulate.lm() and Heather more or less confirmed that this
>> gives correct results for "gnm" objects.
>>
>> For gam(), I'd strongly expect the same to apply, but there
>> maybe sophisticated gam() models where the result is currently
>> not correct.  That's, BTW, also true for
>>     simulate(lm(...., weights), ...)
>>
>>     NicLK>  Or, could the current framework, rather than
>>     NicLK> stopping with an error look for the appropriate model
>>     NicLK> matrix, coefficients, distribution function and
>>     NicLK> family object to simulate from?
>>
>> What do you mean?
>> A situation where there's no supported 'family'
>> or a situation where  predict(<obj>) does not work as it's
>> supposed in the current framework,
>> or ????
>>
>> If there are such cases, we'd have to consider them together
>> with the corresponding package author.  It may often make sense
>> fthen that the author changes his methods {predict(), ..} such
>> that the (now) extended simulate.lm() will work automatically;
>> Alternatively, the author can provide  simulate.<myclass>().
>>
>> But I'm not sure I'm answering the question you've asked..
>> Martin
>>
>>     NicLK> Nicholas
>>
>>
>>    >> Message: 9 Date: Fri, 13 Feb 2009 21:27:57 +0100 From:
>>    >> Martin Maechler <maechler at stat.math.ethz.ch> Subject: Re:
>>    >> [Rd] proposed simulate.glm method To: Heather Turner
>>    >> <Heather.Turner at warwick.ac.uk> Cc: r-devel at r-project.org,
>>    >> Martin Maechler <maechler at stat.math.ethz.ch> Message-ID:
>>    >> <18837.55245.15158.29378 at cmath-5.math.ethz.ch>
>>    >> Content-Type: text/plain; charset=us-ascii
>>    >>
>>    >> Thank you, Heather and Ben,
>>    >>
>>    >>>>>>> "HT" == Heather Turner
>>    >> <Heather.Turner at warwick.ac.uk> >>>>> on Fri, 13 Feb 2009
>>    >> 15:52:37 +0000 writes:
>>    >>
>>     HT> Yes, thanks to Ben for getting the ball rolling. His
>>     HT> code was more streamlined than mine, pointing to further
>>     HT> simplifications which I've included in the extended
>>     HT> version below.
>>    >>
>>     HT> The code for the additional families uses functions from
>>     HT> MASS and SuppDists - I wasn't sure about the best way to
>>     HT> do this, so have just used :: for now.
>>    >>
>>     HT> It appears to be working happily for both glm and gnm
>>     HT> objects (no gnm-specific code used).
>>    >>
>>     HT> Best wishes,
>>    >>
>>     HT> Heather
>>    >>
>>    >> [....]
>>    >>
>>    >> I have now followed Brian Ripley's suggetion to just
>>    >> extend simulate.lm() to also deal with "glm" objects, but
>>    >> using Heather's suggestions for the different families;
>>    >> I've just commited src/library/stats/R/lm.R with the new
>>    >> code.  (get it from svn.r-project.org/R/trunk/ or this
>>    >> night's R-devel tarball).
>>    >>
>>    >> One difference to your propsal: Instead of just
>>    >> object$fitted , the code is using fitted(object)
>>    >> ... something which should properly to the na.action
>>    >> used.
>>    >>
>>    >> For the (MASS and) SuppDists package requirement, I'm
>>    >> using the following
>>    >>
>>    >> if(is.null(tryCatch(loadNamespace("SuppDists"), error =
>>    >> function(e) NULL))) stop("Need CRAN package 'SuppDists'
>>    >> for 'inverse.gaussian' family")
>>    >>
>>    >>
>>    >> I've not yet updated the help page for simulate(), and
>>    >> have only tested relatively few cases for binomial,
>>    >> poisson and Gamma.  I've wanted to expose this to you, so
>>    >> you can provide more feedback and possibly even a patch
>>    >> to
>>    >> svn.r-project.org/R/trunk/src/library/stats/man/simulate.Rd
>>    >>
>>    >> Martin
>>    >>
>>    >>
>>    >>
>>
>> ______________________________________________
>>     NicLK> R-devel at r-project.org mailing list
>>     NicLK> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From khansen at stat.berkeley.edu  Sun Feb 15 00:39:45 2009
From: khansen at stat.berkeley.edu (Kasper Daniel Hansen)
Date: Sat, 14 Feb 2009 15:39:45 -0800
Subject: [Rd] SET_VECTOR_ELT and STRSXPs
Message-ID: <F270E6E2-47FE-41C9-8FED-49EBB6B70758@stat.berkeley.edu>

It seems (based on the NEWS file and on output from R CMD check) that  
we may no longer use SET_VECTOR_ELT on STRSXPs. So I guess that  
section 5.14 of R-extensions needs to be updated, the current phrasing  
is
"By default a certain amount of misuse is allowed where the internal  
representation is the same: for example LOGICAL can be used on a  
INTSXP and SET_VECTOR_ELT on a STRSXP"
which indicates that it is allowed to do so.

I also suggest to change the error message in line 2648-2649 of src/ 
main/memory.c from
   SET_VECTOR_ELT() can only be applied to a 'list', not a '%s'
to
   SET_VECTOR_ELT() / SET_ELEMENT() can only be applied to a 'list',  
not a '%s'
I guess I ought to have remembered that the two macros are synonymous,  
but I didn't and it took me a while to realize this when I tried to  
fix some code written by another person (who preferred to use  
SET_ELEMENT).

Kasper


From giancarlo.marra at bancaditalia.it  Sun Feb 15 18:20:15 2009
From: giancarlo.marra at bancaditalia.it (giancarlo.marra at bancaditalia.it)
Date: Sun, 15 Feb 2009 18:20:15 +0100 (CET)
Subject: [Rd] does file.show() fail with multiple files ? (PR#13528)
Message-ID: <20090215172015.DA037283415C@mail.pubhealth.ku.dk>

Full_Name: giancarlo marra
Version: 8.1
OS: Windows Vista
Submission from: (NULL) (79.36.222.186)


When calling file.show() with, say, n different files, then n windows are opened
ALL with the same content from the first file of the list.

In my tests, it seems to work fine up to version 2.6.2, opening the n files in
the n windows, as documented. It appears broken starting from version 2.7.0.


Es.
file.show("example1.out","example2.out","example3.out")
opens three windows all reading examples1.out

The same if the call is in the form:
files=c("example1.out","example2.out","example3.out")
file.show(files, header=files)

In this case, the windows headers are correctly distinct, but the contents are
still the same from the first file.


Thanks.


From nashjc at uottawa.ca  Sun Feb 15 18:35:50 2009
From: nashjc at uottawa.ca (nashjc at uottawa.ca)
Date: Sun, 15 Feb 2009 12:35:50 -0500 (EST)
Subject: [Rd] sources of code; was Generate random numbers in Fortran
In-Reply-To: <mailman.17.1234695605.18564.r-devel@r-project.org>
References: <mailman.17.1234695605.18564.r-devel@r-project.org>
Message-ID: <60076.97.124.67.225.1234719350.squirrel@webmail02.uottawa.ca>

Ben Bolker gives some reasons why Numerical Recipes may be problematic as
a starting point for R codes. CUP did a masterful job of marketing, but
the license is restrictive as the links he gives points out. In some
tests, I've also noted that some of the algorithms are less than stellar
e.g, convergence tests in one or two optimization routines.

Should we have a wiki item to help people find material? My own "Compact
Numerical Methods: linear algebra and function minimisation" codes were
first published 30 years ago this month. They are the Pascal library on
Netlib. I have some Fortran codes I could post, and BASIC versions too. In
fact, the function minimisation codes that are actually more advanced than
the routines Brian Ripley used in optim() have already been made freely
available (http://www.nashinfo.com/nlpe.htm). The codes still run right
away in DOSBOX along with GWBASIC.EXE, but I believe the more useful
aspect is providing methods and ideas.

Gnu Scientific Library has been mentioned. It has some strengths but a
number of "holes". There are some other notable collections.

The Decision Tree for Optimization (Hans Mittelman) is a helpful link,
though I am not certain all the resources are unencumbered.

Would an annotated list of such openly usable resources be helpful?
Perhaps if a couple of folk contact me off-list we can try a wiki item and
see if it "works".

JN


From murdoch at stats.uwo.ca  Sun Feb 15 19:23:37 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 15 Feb 2009 13:23:37 -0500
Subject: [Rd] does file.show() fail with multiple files ? (PR#13528)
In-Reply-To: <20090215172015.DA037283415C@mail.pubhealth.ku.dk>
References: <20090215172015.DA037283415C@mail.pubhealth.ku.dk>
Message-ID: <49985DA9.1090706@stats.uwo.ca>

On 15/02/2009 12:20 PM, giancarlo.marra at bancaditalia.it wrote:
> Full_Name: giancarlo marra
> Version: 8.1
> OS: Windows Vista
> Submission from: (NULL) (79.36.222.186)
> 
> 
> When calling file.show() with, say, n different files, then n windows are opened
> ALL with the same content from the first file of the list.
> 
> In my tests, it seems to work fine up to version 2.6.2, opening the n files in
> the n windows, as documented. It appears broken starting from version 2.7.0.
> 
> 
> Es.
> file.show("example1.out","example2.out","example3.out")
> opens three windows all reading examples1.out
> 
> The same if the call is in the form:
> files=c("example1.out","example2.out","example3.out")
> file.show(files, header=files)
> 
> In this case, the windows headers are correctly distinct, but the contents are
> still the same from the first file.

This is fixed in R-patched.  The NEWS entry is:

     o	file.show() with multiple files would only show multiple
	copies of the first one. (PR#13469)

Duncan Murdoch


From catcode at catcode.com  Sun Feb 15 20:15:23 2009
From: catcode at catcode.com (jdeisenberg)
Date: Sun, 15 Feb 2009 11:15:23 -0800 (PST)
Subject: [Rd]  Load/Save files for tk GUI
Message-ID: <22026168.post@talk.nabble.com>


The Windows GUI version of R  has menu items that allow load/save of
workspace and history. Attached is a proposed patch to tkGUI.R to give the
same capabilities for Linux users using the tk GUI. (Penguins need love
too.)

http://www.nabble.com/file/p22026168/tkGUIpatch.tgz tkGUIpatch.tgz 
-- 
View this message in context: http://www.nabble.com/Load-Save-files-for-tk-GUI-tp22026168p22026168.html
Sent from the R devel mailing list archive at Nabble.com.


From p.murrell at auckland.ac.nz  Sun Feb 15 20:48:38 2009
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Mon, 16 Feb 2009 08:48:38 +1300
Subject: [Rd] Identifying graphics files produced by R
In-Reply-To: <475a3c8f0902131315q3291de31vdd43ad92bb213cb9@mail.gmail.com>
References: <475a3c8f0902131315q3291de31vdd43ad92bb213cb9@mail.gmail.com>
Message-ID: <49987196.9050902@stat.auckland.ac.nz>

Hi


David M Smith wrote:
> Oftentimes, I see graphs on the web that *look* like they've been
> produced by R, but I can never be sure.  Or can I?  I notice that
> PostScript files include a "%%%Creator: R Software" line, but do R
> graphics drivers encode any identifying information in GIF or PNG
> files more commonly used on the web?  And of so, would such evidence
> necessarily be obliterated in post-processing (e.g cropping)?


I know that pdf() adds similar "Creator" information.  I don't recall
seeing anything like this for the raster devices, but I've worked less
with them so I don't know for sure.

Paul


> I'm trying to do an informal survey of R's use to create statistical
> graphics on the web, and if there's a way to identify graph files I
> see as coming from R it would help a lot.
> 
> Thanks,
> # David Smith
> 
> --
> David M Smith <david at revolution-computing.com>
> Director of Community, REvolution Computing www.revolution-computing.com
> Tel: +1 (206) 577-4778 x3203 (Seattle, USA)
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From jmc at r-project.org  Sun Feb 15 20:53:43 2009
From: jmc at r-project.org (John Chambers)
Date: Sun, 15 Feb 2009 11:53:43 -0800
Subject: [Rd] S4 structure classes and Ops methods
Message-ID: <499872C7.7030900@r-project.org>

The methods package has methods for group generic "Ops" for S4 classes 
that extend "array", "structure" or "vector".  The methods mainly try to 
produce a consistent result when structures and vectors are combined.  
See class?structure, section "Methods".

In the development version of R committed today (r47924),  these methods 
will be activated by loading any package with such classes.  This was 
always the intention, but up to version 2.8.1, the methods were not 
activated UNLESS the package also defined some relevant methods itself.  
(Fixing this turned out to need a whole new mechanism, to indicate that 
the package needed the methods in question.)

Note to package maintainers: if you have a package that defines such 
classes and does not define methods for operators, method selection may 
change for objects from these classes.  In some cases, the new methods 
will be stricter (returning a vector result instead of mixing up 
attributes, for example, as the base code sometimes does).  I haven't 
encountered examples, but please rerun CMD check if you think your 
package fits the description.

John


From landronimirc at gmail.com  Mon Feb 16 00:46:26 2009
From: landronimirc at gmail.com (Liviu Andronic)
Date: Mon, 16 Feb 2009 00:46:26 +0100
Subject: [Rd] Identifying graphics files produced by R
In-Reply-To: <49987196.9050902@stat.auckland.ac.nz>
References: <475a3c8f0902131315q3291de31vdd43ad92bb213cb9@mail.gmail.com>
	<49987196.9050902@stat.auckland.ac.nz>
Message-ID: <68b1e2610902151546w12970060ofd0f9ffbdba85d30@mail.gmail.com>

On Sun, Feb 15, 2009 at 8:48 PM, Paul Murrell <p.murrell at auckland.ac.nz> wrote:
> I know that pdf() adds similar "Creator" information.  I don't recall
> seeing anything like this for the raster devices, but I've worked less
> with them so I don't know for sure.
>
By default PDF vector graphs get:
> pdf.options()
[..]
$title
[1] "R Graphics Output"
[..]

Perhaps .svg gets something similar, but dunno.
Liviu


-- 
Do you know how to read?
http://www.alienetworks.com/srtest.cfm
Do you know how to write?
http://garbl.home.comcast.net/~garbl/stylemanual/e.htm#e-mail


From jgvcqa at rit.edu  Mon Feb 16 01:40:07 2009
From: jgvcqa at rit.edu (jgvcqa at rit.edu)
Date: Mon, 16 Feb 2009 01:40:07 +0100 (CET)
Subject: [Rd] rpart: ylim problem in plotcp (PR#13530)
Message-ID: <20090216004008.07891282EFC1@mail.pubhealth.ku.dk>

Full_Name: Joe Voelkel
Version: 2.8.1
OS: Window
Submission from: (NULL) (70.100.144.240)


# Use of ylim in plotcp generates this message
# Error in plot.default [more stuff]
#  formal argument "ylim" matched by multiple actual arguments

# Here is how to generate the bug (which the plotcp function tries to handle)
#   and how to patch it--but at the loss of dots in plot

library(rpart)
fit <- rpart(Kyphosis ~ Age + Number + Start, data=kyphosis)
windows(5,5)
plotcp(fit)
plotcp(fit,ylim=c(0,2))  # generates error message

plotcp2<-plotcp
fix(plotcp2) # I removed ,... from the plot function
plotcp2(fit)
plotcp2(fit,ylim=c(0,2)) # patch works, but at cost of removing dots from plot


From jpnolan at american.edu  Mon Feb 16 06:03:52 2009
From: jpnolan at american.edu (John Nolan)
Date: Mon, 16 Feb 2009 00:03:52 -0500
Subject: [Rd] sources of code; was Generate random numbers in Fortran
In-Reply-To: <60076.97.124.67.225.1234719350.squirrel@webmail02.uottawa.ca>
References: <mailman.17.1234695605.18564.r-devel@r-project.org>,
	<60076.97.124.67.225.1234719350.squirrel@webmail02.uottawa.ca>
Message-ID: <OFD1168048.1EC1BEA2-ON8525755F.001BD1D1-8525755F.001BD1ED@american.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090216/ed2e2350/attachment.pl>

From keith at wehi.EDU.AU  Mon Feb 16 07:40:27 2009
From: keith at wehi.EDU.AU (Keith Satterley)
Date: Mon, 16 Feb 2009 17:40:27 +1100
Subject: [Rd] An inconsistency in docs for file.access(base)
Message-ID: <49990A5B.2070209@wehi.edu.au>

I was chasing a "no permission to install to directory" error message. I was 
looking in the code for /R/trunk/src/library/tools/R/install.R which pointed me 
to the file.access function.

On reading the help for this function, it has the following in the Details section:

The mode value can be the exclusive or of the following values
0 test for existence.
1 test for execute permission.
2 test for write permission.
4 test for read permission.

It has the following under the Examples section:

Examples
fa <- file.access(dir("."))
table(fa) # count successes & failures
d <- dir(file.path(R.home(), "bin"))
df <- dir(file.path(R.home(), "bin"), full.names = TRUE)
d[file.access(df, 0) == 0] # all exist
d[file.access(df, 1) == 0] # some are executable, some are not
d[file.access(df, 2) == 0] # hopefully all are readable
d[file.access(df, 4) == 0] # they may or may not be writable

I presume mode = 2 is a test for writing, so could someone change the comments 
around in the Examples

 > sessionInfo()
R version 2.9.0 Under development (unstable) (2009-01-15 r47607)
i386-pc-mingw32

locale:
LC_COLLATE=English_Australia.1252;LC_CTYPE=English_Australia.1252;LC_MONETARY=English_Australia.1252;LC_NUMERIC=C;LC_TIME=English_Australia.1252

attached base packages:
[1] stats     graphics  grDevices datasets  utils     methods   base

loaded via a namespace (and not attached):
[1] tools_2.9.0

Same situation in R2.8.1


cheers,

Keith
========================
Keith Satterley
Bioinformatics Division
The Walter and Eliza Hall Institute of Medical Research
Parkville, Melbourne,
Victoria, Australia


From kjell.konis at epfl.ch  Mon Feb 16 12:20:31 2009
From: kjell.konis at epfl.ch (Kjell Konis)
Date: Mon, 16 Feb 2009 12:20:31 +0100
Subject: [Rd] demo enhancement
Message-ID: <0F20FC28-3816-4383-BE58-9608695E8706@epfl.ch>

Hello,

I have a package for working with Bayesian networks (RHugin - on R- 
Forge for those interested). It contains a function RHExample that  
does the same thing as the demo function in the utils package except  
that it does not display any output in the R console. I use it to  
build simple networks in the examples section of my .Rd documentation  
files. Anyway, I thought it would be useful if this functionality was  
also part of the demo function. The attached diff adds an echo  
argument to demo which, when set to FALSE, makes demo behave the same  
as my RHExample function. Please feel free to use it if you think it  
would be helpful.

Kjell

-------------- next part --------------


From murdoch at stats.uwo.ca  Mon Feb 16 12:35:58 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 16 Feb 2009 06:35:58 -0500
Subject: [Rd] demo enhancement
In-Reply-To: <0F20FC28-3816-4383-BE58-9608695E8706@epfl.ch>
References: <0F20FC28-3816-4383-BE58-9608695E8706@epfl.ch>
Message-ID: <49994F9E.6030109@stats.uwo.ca>

Kjell Konis wrote:
> Hello,
>
> I have a package for working with Bayesian networks (RHugin - on R- 
> Forge for those interested). It contains a function RHExample that  
> does the same thing as the demo function in the utils package except  
> that it does not display any output in the R console. I use it to  
> build simple networks in the examples section of my .Rd documentation  
> files. Anyway, I thought it would be useful if this functionality was  
> also part of the demo function. The attached diff adds an echo  
> argument to demo which, when set to FALSE, makes demo behave the same  
> as my RHExample function. Please feel free to use it if you think it  
> would be helpful.
Your attachment got lost, but by coincidence, I was wanting an 
echo=FALSE argument to demo a couple of days ago.  I didn't add it yet, 
because

 - I'd like consistency with example(), which suggests putting echo 
ahead of verbose
 - I'd rather not add a parameter in the middle of the list, just in 
case someone has used positional args
 - example() has other args not in demo(), i.e. local, setRNG, ask, 
prompt.prefix.  Should some or all of those be added at the same time?

Since the first two items above are contradictory, I decided this needed 
thinking about, but I haven't taken the time to do that yet.

Duncan Murdoch


From kjell.konis at epfl.ch  Mon Feb 16 12:42:23 2009
From: kjell.konis at epfl.ch (Kjell Konis)
Date: Mon, 16 Feb 2009 12:42:23 +0100
Subject: [Rd] demo enhancement
In-Reply-To: <49994F9E.6030109@stats.uwo.ca>
References: <0F20FC28-3816-4383-BE58-9608695E8706@epfl.ch>
	<49994F9E.6030109@stats.uwo.ca>
Message-ID: <EC8433CF-0161-4DFC-B643-6F468D24893F@epfl.ch>

I put the diff here

   http://smat.epfl.ch/~konis/grabbag/demo.diff

Kjell

On 16 f?vr. 09, at 12:35, Duncan Murdoch wrote:

> Kjell Konis wrote:
>> Hello,
>>
>> I have a package for working with Bayesian networks (RHugin - on R-
>> Forge for those interested). It contains a function RHExample that
>> does the same thing as the demo function in the utils package except
>> that it does not display any output in the R console. I use it to
>> build simple networks in the examples section of my .Rd documentation
>> files. Anyway, I thought it would be useful if this functionality was
>> also part of the demo function. The attached diff adds an echo
>> argument to demo which, when set to FALSE, makes demo behave the same
>> as my RHExample function. Please feel free to use it if you think it
>> would be helpful.
> Your attachment got lost, but by coincidence, I was wanting an
> echo=FALSE argument to demo a couple of days ago.  I didn't add it  
> yet,
> because
>
> - I'd like consistency with example(), which suggests putting echo
> ahead of verbose
> - I'd rather not add a parameter in the middle of the list, just in
> case someone has used positional args
> - example() has other args not in demo(), i.e. local, setRNG, ask,
> prompt.prefix.  Should some or all of those be added at the same time?
>
> Since the first two items above are contradictory, I decided this  
> needed
> thinking about, but I haven't taken the time to do that yet.
>
> Duncan Murdoch


From jukka.nyblom at jyu.fi  Mon Feb 16 08:50:04 2009
From: jukka.nyblom at jyu.fi (jukka.nyblom at jyu.fi)
Date: Mon, 16 Feb 2009 08:50:04 +0100 (CET)
Subject: [Rd] Box.test (PR#13532)
Message-ID: <20090216075004.89337282EFC2@mail.pubhealth.ku.dk>

Full_Name: Jukka Nyblom
Version: 2.8.0
OS: 
Submission from: (NULL) (130.234.5.137)


In Box.test function it is now possible to give the degrees of freedom  due to
estimation of ARMA parameters. The p value is correct but the df in the output
component is without subtraction.

Jukka Nyblom


From Fraser_Sim at URMC.Rochester.edu  Mon Feb 16 20:43:47 2009
From: Fraser_Sim at URMC.Rochester.edu (Sim, Fraser)
Date: Mon, 16 Feb 2009 14:43:47 -0500
Subject: [Rd] Newbie - how do I debug a crash of RGUI.EXE
Message-ID: <82377DC24E19614291D0B5A4A89DAD74DBAD4B@e2k3ms5.urmc-sh.rochester.edu>

Hi-

I'm running Vista64 Business and trying to use a package called
RGraphViz. Unfortunately, when I try to plot a graph using this package
it causes RGUI.EXE to crash. This package has no problem working in
WinXP 32-bit. 

Is there any way to get useful information as to why it crashes?

Here's my commands:

> library(Rgraphviz)
Loading required package: graph
Loading required package: grid
Warning message:
In fun(...) : Rgraphviz built with Graphviz version 2.20.
Found Graphviz version 2.21.

> sessionInfo()
R version 2.9.0 Under development (unstable) (2009-01-21 r47661)
i386-pc-mingw32 

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
States.1252;LC_MONETARY=English_United
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] grid      stats     graphics  grDevices utils     datasets  methods

[8] base     

other attached packages:
[1] Rgraphviz_1.21.7 graph_1.21.3    

loaded via a namespace (and not attached):
[1] cluster_1.11.12 tools_2.9.0    
>


I then define a graph using the following

G = new("graphNEL", nodes = c("A","B","C"))
plot(G)

And RUI.exe crashes...

Any help would be most appreciated.

Thanks,
Fraser


From rubin at msu.edu  Mon Feb 16 20:10:19 2009
From: rubin at msu.edu (rubin at msu.edu)
Date: Mon, 16 Feb 2009 20:10:19 +0100 (CET)
Subject: [Rd] Update today broke foreign package (PR#13533)
Message-ID: <20090216191019.8E152282EFC1@mail.pubhealth.ku.dk>

Hi,

I'm running R 2.8.1 on Ubuntu, and today I got updates for a couple of 
packages, including foreign (r-cran-foreign, now at version 0.8.32).  
Subsequent to the upgrade, attempts to invoke read.spss produce the 
following error:

Error in inherits(x, "factor") : object "cp" not found

and the call to read.spss fails.  I forced a downgrade to 0.8.26, and 
read.spss works again.

Cheers,
Paul Rubin


From mtmorgan at fhcrc.org  Mon Feb 16 22:06:29 2009
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Mon, 16 Feb 2009 13:06:29 -0800
Subject: [Rd] Newbie - how do I debug a crash of RGUI.EXE
In-Reply-To: <82377DC24E19614291D0B5A4A89DAD74DBAD4B@e2k3ms5.urmc-sh.rochester.edu>
	(Fraser Sim's message of "Mon, 16 Feb 2009 14:43:47 -0500")
References: <82377DC24E19614291D0B5A4A89DAD74DBAD4B@e2k3ms5.urmc-sh.rochester.edu>
Message-ID: <6phprhixfai.fsf@gopher4.fhcrc.org>

"Sim, Fraser" <Fraser_Sim at urmc.rochester.edu> writes:

> Hi-
>
> I'm running Vista64 Business and trying to use a package called
> RGraphViz. Unfortunately, when I try to plot a graph using this package
> it causes RGUI.EXE to crash. This package has no problem working in
> WinXP 32-bit. 
>
> Is there any way to get useful information as to why it crashes?
>
> Here's my commands:
>
>> library(Rgraphviz)
> Loading required package: graph
> Loading required package: grid
> Warning message:
> In fun(...) : Rgraphviz built with Graphviz version 2.20.
> Found Graphviz version 2.21.

It might be worth while to match your Graphviz with the one Rgraphviz
was built against (2.20) -- the problem is almost certainly at the C
level where this could matter.

Duncan Murdoch has hints here

http://www.stats.uwo.ca/faculty/murdoch/software/debuggingR/

If 'newbie' means an inexperienced C programmer then this will be a
lot of work. A first step will be to install tools required to build R
from source, and to rebuild Rgraphviz from source with flags set to
generate debugging information. Again Duncan's pages will come in
handy.

Hope that helps.

Martin

>> sessionInfo()
> R version 2.9.0 Under development (unstable) (2009-01-21 r47661)
> i386-pc-mingw32 
>
> locale:
> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
> States.1252;LC_MONETARY=English_United
> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>
> attached base packages:
> [1] grid      stats     graphics  grDevices utils     datasets  methods
>
> [8] base     
>
> other attached packages:
> [1] Rgraphviz_1.21.7 graph_1.21.3    
>
> loaded via a namespace (and not attached):
> [1] cluster_1.11.12 tools_2.9.0    
>>
>
>
> I then define a graph using the following
>
> G = new("graphNEL", nodes = c("A","B","C"))
> plot(G)
>
> And RUI.exe crashes...
>
> Any help would be most appreciated.
>
> Thanks,
> Fraser
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Martin Morgan
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M2 B169
Phone: (206) 667-2793


From david at revolution-computing.com  Mon Feb 16 23:02:11 2009
From: david at revolution-computing.com (David M Smith)
Date: Mon, 16 Feb 2009 14:02:11 -0800
Subject: [Rd] Summary: Identifying graphics files produced by R
Message-ID: <475a3c8f0902161402i79203560v32533b443b000750@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090216/ba78c76e/attachment.pl>

From jmc at r-project.org  Tue Feb 17 00:54:28 2009
From: jmc at r-project.org (John Chambers)
Date: Mon, 16 Feb 2009 15:54:28 -0800
Subject: [Rd] Inheriting from "environment" and similar object types
Message-ID: <4999FCB4.8090500@r-project.org>

Attributes can't be assigned to objects of type "environment" or similar 
types such as external pointers or names (symbols).  The objects are 
references, not normal R objects, and are not copied by the internal 
duplicate() routine, so any attribute (including "class") overwrites the 
same object.  This means that classes, either S4 or S3, can't inherit 
from these types directly.

A mechanism has been added to r-devel (version r47933) that allows S4 
classes to contain "environment" and similar types.  The mechanism uses 
a reserved slot name to hold the reference.  Code in various places 
recognizes S4 objects with this slot and coerces the object to the 
corresponding type. See ?setClass.

The mechanism is transparent for quite a few computations, but there 
can't be a full guarantee, since low-level code can operate directly 
using the object type, which of course will not correspond to 
"environment".  Usually, a workaround is to pass in as(object, 
"environment") instead of object.

The same mechanism is used to allow extending  "externalptr" and "name", 
and other similar types will likely be added after some more testing.

Details of the mechanism are still experimental,  and may change.

John


From ripley at stats.ox.ac.uk  Tue Feb 17 07:54:05 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 17 Feb 2009 06:54:05 +0000 (GMT)
Subject: [Rd] Update today broke foreign package (PR#13533)
In-Reply-To: <20090216191019.8E152282EFC1@mail.pubhealth.ku.dk>
References: <20090216191019.8E152282EFC1@mail.pubhealth.ku.dk>
Message-ID: <alpine.LFD.2.00.0902170636050.31377@gannet.stats.ox.ac.uk>

foregin_0.8-32 was testsd aginst 2.8.1 prior to release, and I've just 
tested it again.

This might be a locale issue (but I also tested in a latin1 and C 
locale), but I think it is specific to some files.

So can we have both the output of sessionInfo() and a file that 
causes the problem (it appears not to be one of the test files in the 
'tests' subdirectory), and I'll investigate further.

On Mon, 16 Feb 2009, rubin at msu.edu wrote:

> Hi,
>
> I'm running R 2.8.1 on Ubuntu, and today I got updates for a couple of
> packages, including foreign (r-cran-foreign, now at version 0.8.32).
> Subsequent to the upgrade, attempts to invoke read.spss produce the
> following error:
>
> Error in inherits(x, "factor") : object "cp" not found
>
> and the call to read.spss fails.  I forced a downgrade to 0.8.26, and
> read.spss works again.
>
> Cheers,
> Paul Rubin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From HBaize at buttecounty.net  Tue Feb 17 08:35:24 2009
From: HBaize at buttecounty.net (HBaize)
Date: Mon, 16 Feb 2009 23:35:24 -0800 (PST)
Subject: [Rd] Update today broke foreign package (PR#13533)
In-Reply-To: <alpine.LFD.2.00.0902170636050.31377@gannet.stats.ox.ac.uk>
References: <20090216191019.8E152282EFC1@mail.pubhealth.ku.dk>
	<alpine.LFD.2.00.0902170636050.31377@gannet.stats.ox.ac.uk>
Message-ID: <22052065.post@talk.nabble.com>



I posted links to five SPSS .sav files in response to a very similar problem
with read.spss(). 
Maybe you can use them to test the function. 

http://www.nabble.com/reading-SPSS-.sav-files-(PR-13509)-td21889920.html 

So can we have both the output of sessionInfo() and a file that 
causes the problem (it appears not to be one of the test files in the 
'tests' subdirectory), and I'll investigate further.

On Mon, 16 Feb 2009, rubin at msu.edu wrote:


-- 
View this message in context: http://www.nabble.com/Update-today-broke-foreign-package-%28PR-13533%29-tp22045004p22052065.html
Sent from the R devel mailing list archive at Nabble.com.


From ashrafi at ucdavis.edu  Tue Feb 17 09:29:46 2009
From: ashrafi at ucdavis.edu (Hamid Ashafi)
Date: Tue, 17 Feb 2009 00:29:46 -0800
Subject: [Rd] allocMatrix error
Message-ID: <000b01c990d9$e47add10$ad709730$@edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090217/1119b1c7/attachment.pl>

From ripley at stats.ox.ac.uk  Tue Feb 17 09:52:47 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 17 Feb 2009 08:52:47 +0000 (GMT)
Subject: [Rd] allocMatrix error
In-Reply-To: <000b01c990d9$e47add10$ad709730$@edu>
References: <000b01c990d9$e47add10$ad709730$@edu>
Message-ID: <alpine.LFD.2.00.0902170834300.24542@gannet.stats.ox.ac.uk>

On Tue, 17 Feb 2009, Hamid Ashafi wrote:

> On Sat, Feb 14, 2009 at 00:17,  <ashrafi at ucdavis.edu> wrote:
>
> Hi,
>
> I was trying to read ~400 chips in an affybatch and I got the same message.
> Could you find a remedy for that. My server has 128 GB of RAM. However, R
> halted ever before it uses the memory.

We don't have anything like sufficient details (please do read the 
posting guide).

If the issue is the size of matrices, you possibly (depending on the 
compiler) could arrange to compile R (and any relevant system 
libraries) to use 64-bit ints.  For C code in R there is typedef to 
change, and you would need integer*8 in the Fortran.  We would be 
interested to know the results if you do so, but the developers are 
unlikely to do so for you.

In any case, since you mention 'affybatch' it looks like this might 
be a design issue in that BioC package and the BioC lists might be the 
appropriate place to discuss it.  It is not obvious to me why ~400 
datasets need a single large R object rather than, say, a list of 400 
smaller ones, if that is indeed the problem.  So, to return to my
first point:

> We don't have anything like sufficient details.

Please give us the full details of your system, the memory in use (see 
?gc) and what you were trying to do.


> I have been able to load upto 250 CEL files but this time I wanted to test
> what would happen if I want to normalize 400 chips.

R can handle up to 16GB objects, which even for a 64-bit OS and 128GB 
of RAM are pretty large objects and do not arise naturally from many 
small files.

> Thanks for your prompt response.
>
>
>
> Hamid
>
>>
>
>>
>
>>
>
>> Martin Maechler wrote:
>
>>>
>
>>>>>>>> "VK" == Vadim Kutsyy <vadim at kutsyy.com>
>
>>>>>>>>     on Fri, 01 Aug 2008 07:35:01 -0700 writes:
>
>>>
>
>>>     VK> Martin Maechler wrote:
>
>>>    >>
>
>>>     VK> The problem is in array.c, where allocMatrix check for
>
>>>     VK> "if ((double)nrow * (double)ncol > INT_MAX)".  But why
>
>>>     VK> itn is used and not long int for indexing? (max int is
>
>>>     VK> 2147483647, max long int is 9223372036854775807)
>
>>>    >>
>
>>>    >> Well, Brian gave you all info:
>
>>>    >>
>
>>>     VK> exactly, and given that most modern system used for
>
>>>     VK> computations (i.e.  64bit system) have long int which is
>
>>>     VK> much larger than int, I am wondering why long int is not
>
>>>     VK> used for indexing (I don't think that 4 bit vs 8 bit
>
>>>     VK> storage is an issue).
>
>>>    >> Did you really carefully read ?Memory-limits ??
>
>>>    >>
>
>>>     VK> Yes, it is specify that 4 bit int is used for indexing
>
>>>     VK> in all version of R, but why? I think 2147483647
>
>>>     VK> elements for a single vector is OK, but not as total
>
>>>     VK> number of elements for the matrix.  I am running out of
>
>>>     VK> indexing at mere 10% memory consumption.
>
>>>
>
>>> Hmm, do you have 160 GBytes of RAM?
>
>>> But anyway, let's move this topic from R-help to R-devel.
>
>>>
>
>>>    [...........]
>
>>>
>
>>>     VK> PS: I have no problem to go and modify C code, but I am
>
>>>     VK> just wondering what are the reasons for having such
>
>>>     VK> limitation.
>
>>>
>
>>> This limitation and its possible remedies are an interesting topic,
>
>>> but really not for R-help:
>
>>>
>
>>> It will be a lot about C programming the internal represenation of R
>
>>> objects, etc.
>
>>> Very fascinating .... but for R-devel.
>
>>>
>
>>> "See you there!"
>
>>> Martin
>
>>>
>
>>> ______________________________________________
>
>>> R-help at r-project.org mailing list
>
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>
>>> PLEASE do read the posting guide
>
>>> http://www.R-project.org/posting-guide.html
>
>>> and provide commented, minimal, self-contained, reproducible code.
>
>>>
>
>>>
>
>> Quoted from:
>
>> http://www.nabble.com/allocMatrix-limits-tp18763791p18776531.html
>
>>
>
>>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From cgenolin at u-paris10.fr  Tue Feb 17 13:07:05 2009
From: cgenolin at u-paris10.fr (Christophe Genolini)
Date: Tue, 17 Feb 2009 13:07:05 +0100
Subject: [Rd] getGraphicsEvent in an example
Message-ID: <499AA869.1040400@u-paris10.fr>

Hi the list,
Is there a way to include a function using a getGraphicsEvent in the 
\examples section?
Christophe


From murdoch at stats.uwo.ca  Tue Feb 17 13:25:53 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 17 Feb 2009 07:25:53 -0500
Subject: [Rd] demo enhancement
In-Reply-To: <EC8433CF-0161-4DFC-B643-6F468D24893F@epfl.ch>
References: <0F20FC28-3816-4383-BE58-9608695E8706@epfl.ch>
	<49994F9E.6030109@stats.uwo.ca>
	<EC8433CF-0161-4DFC-B643-6F468D24893F@epfl.ch>
Message-ID: <499AACD1.6020202@stats.uwo.ca>

On 16/02/2009 6:42 AM, Kjell Konis wrote:
> I put the diff here
> 
>    http://smat.epfl.ch/~konis/grabbag/demo.diff
> 
> Kjell

I've added this in R-devel, and also added "ask" at the same time.

Duncan Murdoch

> On 16 f?vr. 09, at 12:35, Duncan Murdoch wrote:
> 
>> Kjell Konis wrote:
>>> Hello,
>>>
>>> I have a package for working with Bayesian networks (RHugin - on R-
>>> Forge for those interested). It contains a function RHExample that
>>> does the same thing as the demo function in the utils package except
>>> that it does not display any output in the R console. I use it to
>>> build simple networks in the examples section of my .Rd documentation
>>> files. Anyway, I thought it would be useful if this functionality was
>>> also part of the demo function. The attached diff adds an echo
>>> argument to demo which, when set to FALSE, makes demo behave the same
>>> as my RHExample function. Please feel free to use it if you think it
>>> would be helpful.
>> Your attachment got lost, but by coincidence, I was wanting an
>> echo=FALSE argument to demo a couple of days ago.  I didn't add it  
>> yet,
>> because
>>
>> - I'd like consistency with example(), which suggests putting echo
>> ahead of verbose
>> - I'd rather not add a parameter in the middle of the list, just in
>> case someone has used positional args
>> - example() has other args not in demo(), i.e. local, setRNG, ask,
>> prompt.prefix.  Should some or all of those be added at the same time?
>>
>> Since the first two items above are contradictory, I decided this  
>> needed
>> thinking about, but I haven't taken the time to do that yet.
>>
>> Duncan Murdoch
>


From mtmorgan at fhcrc.org  Tue Feb 17 14:46:08 2009
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Tue, 17 Feb 2009 05:46:08 -0800
Subject: [Rd] allocMatrix error
In-Reply-To: <alpine.LFD.2.00.0902170834300.24542@gannet.stats.ox.ac.uk> (Brian
	Ripley's message of "Tue, 17 Feb 2009 08:52:47 +0000 (GMT)")
References: <000b01c990d9$e47add10$ad709730$@edu>
	<alpine.LFD.2.00.0902170834300.24542@gannet.stats.ox.ac.uk>
Message-ID: <6phab8li3bz.fsf@gopher4.fhcrc.org>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> On Tue, 17 Feb 2009, Hamid Ashafi wrote:
>
>> On Sat, Feb 14, 2009 at 00:17,  <ashrafi at ucdavis.edu> wrote:
>>
>> Hi,
>>
>> I was trying to read ~400 chips in an affybatch and I got the same message.
>> Could you find a remedy for that. My server has 128 GB of RAM. However, R
>> halted ever before it uses the memory.
>
> We don't have anything like sufficient details (please do read the
> posting guide).
>
> If the issue is the size of matrices, you possibly (depending on the
> compiler) could arrange to compile R (and any relevant system
> libraries) to use 64-bit ints.  For C code in R there is typedef to
> change, and you would need integer*8 in the Fortran.  We would be
> interested to know the results if you do so, but the developers are
> unlikely to do so for you.
>
> In any case, since you mention 'affybatch' it looks like this might be
> a design issue in that BioC package and the BioC lists might be the
> appropriate place to discuss it.  It is not obvious to me why ~400
> datasets need a single large R object rather than, say, a list of 400
> smaller ones, if that is indeed the problem.  So, to return to my
> first point:
>
>> We don't have anything like sufficient details.
>
> Please give us the full details of your system, the memory in use (see
> ?gc) and what you were trying to do.
>
>
>> I have been able to load upto 250 CEL files but this time I wanted to test
>> what would happen if I want to normalize 400 chips.
>
> R can handle up to 16GB objects, which even for a 64-bit OS and 128GB
> of RAM are pretty large objects and do not arise naturally from many
> small files.

Hamid -- Prof. Ripley is correct in pointing you toward the
Bioconductor mailing list

  http://bioconductor.org/docs/mailList.html

The usual solution for very large sets of array is to use packages
like aroma.affymetrix or xps that do not put the objects entirely in
memory, or the AffyPara package to divide large jobs into smaller ones
that are processed in parallel. Also of course to think about whether
it is statistically reasonable to normalize across all arrays.  There
are discussions of this topic on the Bioc mailing list, so look in the
archive for additional hints.

Martin

>> Thanks for your prompt response.
>>
>>
>>
>> Hamid
>>
>>>
>>
>>>
>>
>>>
>>
>>> Martin Maechler wrote:
>>
>>>>
>>
>>>>>>>>> "VK" == Vadim Kutsyy <vadim at kutsyy.com>
>>
>>>>>>>>>     on Fri, 01 Aug 2008 07:35:01 -0700 writes:
>>
>>>>
>>
>>>>     VK> Martin Maechler wrote:
>>
>>>>    >>
>>
>>>>     VK> The problem is in array.c, where allocMatrix check for
>>
>>>>     VK> "if ((double)nrow * (double)ncol > INT_MAX)".  But why
>>
>>>>     VK> itn is used and not long int for indexing? (max int is
>>
>>>>     VK> 2147483647, max long int is 9223372036854775807)
>>
>>>>    >>
>>
>>>>    >> Well, Brian gave you all info:
>>
>>>>    >>
>>
>>>>     VK> exactly, and given that most modern system used for
>>
>>>>     VK> computations (i.e.  64bit system) have long int which is
>>
>>>>     VK> much larger than int, I am wondering why long int is not
>>
>>>>     VK> used for indexing (I don't think that 4 bit vs 8 bit
>>
>>>>     VK> storage is an issue).
>>
>>>>    >> Did you really carefully read ?Memory-limits ??
>>
>>>>    >>
>>
>>>>     VK> Yes, it is specify that 4 bit int is used for indexing
>>
>>>>     VK> in all version of R, but why? I think 2147483647
>>
>>>>     VK> elements for a single vector is OK, but not as total
>>
>>>>     VK> number of elements for the matrix.  I am running out of
>>
>>>>     VK> indexing at mere 10% memory consumption.
>>
>>>>
>>
>>>> Hmm, do you have 160 GBytes of RAM?
>>
>>>> But anyway, let's move this topic from R-help to R-devel.
>>
>>>>
>>
>>>>    [...........]
>>
>>>>
>>
>>>>     VK> PS: I have no problem to go and modify C code, but I am
>>
>>>>     VK> just wondering what are the reasons for having such
>>
>>>>     VK> limitation.
>>
>>>>
>>
>>>> This limitation and its possible remedies are an interesting topic,
>>
>>>> but really not for R-help:
>>
>>>>
>>
>>>> It will be a lot about C programming the internal represenation of R
>>
>>>> objects, etc.
>>
>>>> Very fascinating .... but for R-devel.
>>
>>>>
>>
>>>> "See you there!"
>>
>>>> Martin
>>
>>>>
>>
>>>> ______________________________________________
>>
>>>> R-help at r-project.org mailing list
>>
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>
>>>> PLEASE do read the posting guide
>>
>>>> http://www.R-project.org/posting-guide.html
>>
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>>>
>>
>>>>
>>
>>> Quoted from:
>>
>>> http://www.nabble.com/allocMatrix-limits-tp18763791p18776531.html
>>
>>>
>>
>>>
>>
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Martin Morgan
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M2 B169
Phone: (206) 667-2793


From P.Dalgaard at biostat.ku.dk  Tue Feb 17 17:17:08 2009
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 17 Feb 2009 17:17:08 +0100
Subject: [Rd] Update today broke foreign package (PR#13533)
In-Reply-To: <alpine.LFD.2.00.0902170636050.31377@gannet.stats.ox.ac.uk>
References: <20090216191019.8E152282EFC1@mail.pubhealth.ku.dk>
	<alpine.LFD.2.00.0902170636050.31377@gannet.stats.ox.ac.uk>
Message-ID: <499AE304.7040200@biostat.ku.dk>

Prof Brian Ripley wrote:
> foregin_0.8-32 was testsd aginst 2.8.1 prior to release, and I've just
> tested it again.
> 
> This might be a locale issue (but I also tested in a latin1 and C
> locale), but I think it is specific to some files.

I have this with a codepage 1252 file as well. From my reply to Harry
Haupt on R-help (copied here for the sake of the bug repository):

Yes, something in the logic appears to have gotten garbled.

It's in this part of read,spss:

    if (is.character(reencode)) {
        cp <- reencode
        reencode <- TRUE
    }
    else if (codepage <= 500 || codepage >= 2000) {
        attr(rval, "codepage") <- NULL
        reencode <- FALSE
    }
    else if (m <- match(cp, knownCP, 0L))
        cp <- names(knownCP)[m]

if you get to the 2nd "else if" then cp is unset. Possible the attempted
match should be of codepage? But it still looks wrong: Why restrict to
codepages between 500 and 2000 when knownCP contains several values
above 10000???

A workaround is to set reencode="ascii" (or whatever is relevant).




> So can we have both the output of sessionInfo() and a file that causes
> the problem (it appears not to be one of the test files in the 'tests'
> subdirectory), and I'll investigate further.
> 
> On Mon, 16 Feb 2009, rubin at msu.edu wrote:
> 
>> Hi,
>>
>> I'm running R 2.8.1 on Ubuntu, and today I got updates for a couple of
>> packages, including foreign (r-cran-foreign, now at version 0.8.32).
>> Subsequent to the upgrade, attempts to invoke read.spss produce the
>> following error:
>>
>> Error in inherits(x, "factor") : object "cp" not found
>>
>> and the call to read.spss fails.  I forced a downgrade to 0.8.26, and
>> read.spss works again.
>>
>> Cheers,
>> Paul Rubin
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From Greg.Snow at imail.org  Tue Feb 17 18:01:46 2009
From: Greg.Snow at imail.org (Greg Snow)
Date: Tue, 17 Feb 2009 10:01:46 -0700
Subject: [Rd] getGraphicsEvent in an example
In-Reply-To: <499AA869.1040400@u-paris10.fr>
References: <499AA869.1040400@u-paris10.fr>
Message-ID: <B37C0A15B8FB3C468B5BC7EBC7DA14CC61CA2A09C4@LP-EXMBVS10.CO.IHC.COM>

Just wrap the example in either \dontrun{} or
if(interactive()){

}

That way that example will be skipped when the automatic tests are done, but will still be available for a reader to run by copy/paste or the examples function (2nd case above).

This has worked for me, examples using these are playSudoku in the sudoku package and dynIdentify in TeachingDemos.

Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
801.408.8111


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
> project.org] On Behalf Of Christophe Genolini
> Sent: Tuesday, February 17, 2009 5:07 AM
> To: r-devel at r-project.org
> Subject: [Rd] getGraphicsEvent in an example
> 
> Hi the list,
> Is there a way to include a function using a getGraphicsEvent in the
> \examples section?
> Christophe
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ggrothendieck at gmail.com  Tue Feb 17 19:12:19 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 17 Feb 2009 13:12:19 -0500
Subject: [Rd] getGraphicsEvent in an example
In-Reply-To: <B37C0A15B8FB3C468B5BC7EBC7DA14CC61CA2A09C4@LP-EXMBVS10.CO.IHC.COM>
References: <499AA869.1040400@u-paris10.fr>
	<B37C0A15B8FB3C468B5BC7EBC7DA14CC61CA2A09C4@LP-EXMBVS10.CO.IHC.COM>
Message-ID: <971536df0902171012l1153cc2ld141266305bda1de@mail.gmail.com>

Also any demos in the demo directory will be skipped by
the automated checks.

On Tue, Feb 17, 2009 at 12:01 PM, Greg Snow <Greg.Snow at imail.org> wrote:
> Just wrap the example in either \dontrun{} or
> if(interactive()){
>
> }
>
> That way that example will be skipped when the automatic tests are done, but will still be available for a reader to run by copy/paste or the examples function (2nd case above).
>
> This has worked for me, examples using these are playSudoku in the sudoku package and dynIdentify in TeachingDemos.
>
> Hope this helps,
>
> --
> Gregory (Greg) L. Snow Ph.D.
> Statistical Data Center
> Intermountain Healthcare
> greg.snow at imail.org
> 801.408.8111
>
>
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
>> project.org] On Behalf Of Christophe Genolini
>> Sent: Tuesday, February 17, 2009 5:07 AM
>> To: r-devel at r-project.org
>> Subject: [Rd] getGraphicsEvent in an example
>>
>> Hi the list,
>> Is there a way to include a function using a getGraphicsEvent in the
>> \examples section?
>> Christophe
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From gb at stat.umu.se  Tue Feb 17 23:03:50 2009
From: gb at stat.umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Tue, 17 Feb 2009 23:03:50 +0100
Subject: [Rd] C basic indentation
Message-ID: <499B3446.1080505@stat.umu.se>

I use the recommendations in "R coding standards", i.e., I put

      ;;; C
      (add-hook 'c-mode-hook
                (lambda () (c-set-style "bsd")))
      ;;; ESS
      (add-hook 'ess-mode-hook
                (lambda ()
                  (ess-set-style 'C++ 'quiet)
                  (add-hook 'local-write-file-hooks
                            (lambda ()
                              (ess-nuke-trailing-whitespace)))))
      (setq ess-nuke-trailing-whitespace-p 'ask)
      ;;; Perl
      (add-hook 'perl-mode-hook
                (lambda () (setq perl-indent-level 4)))

into my .emacs file. IIRC, back in 2005 it gave me a basic indentation 
of 4 in C (good), but only 2 in R (not so good, but I fixed it with the 
aid of this excellent list). But now it gives me a basic indentation of 
eight (8!) in C code. This is not what I want. I think I saw somewhere 
that the bsd standard actually has changed from four to eight recently 
(but I cannot find it now).

Two points given that the standard really has changed: (i) The text in 
"R coding standards" should be changed accordingly. (ii) How do I get 
back to a basic indentation of 4 in C and R code?

G?ran

 > sessionInfo()
R version 2.8.1 Patched (2009-01-03 r47458)
i686-pc-linux-gnu

locale:
LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;
LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;
LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

GNU Emacs 22.2.1 on Ubuntu 8.10 x64
-- 
G?ran Brostr?m               phone: 46 90 786 5223; 46 705 197 507
Department of Statistics     fax: 46 90 786 6614
Ume? University              email: gb at stat.umu.se
SE-90187 Ume?, Sweden        http://tal.stat.umu.se/~gb


From john.maindonald at anu.edu.au  Tue Feb 17 23:53:39 2009
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Wed, 18 Feb 2009 09:53:39 +1100
Subject: [Rd] plot.lm: "Cook's distance" label can overplot point labels
Message-ID: <19E18CBA-23C1-4749-BD74-EDC1B8FC24B1@anu.edu.au>

The following code demonstrates an annoyance with plot.lm():

library(DAAGxtras)
x11(width=3.75, height=4)
nihills.lm <- lm(log(time) ~ log(dist) + log(climb), data = nihills)
plot(nihills.lm, which=5)

OR try the following
xy <- data.frame(x=c(3,1:5), y=c(-2, 1:5))
plot(lm(y ~ x, data=xy), which=5)

The "Cook's distance" text overplots the label for the point with the  
smallest residual.  This is an issue when the size of the plot is much  
less than the default, and the pointsize is not reduced proportionately.


I suggest the following:
       xx <- hii
       xx[xx >= 1] <- NA
## Insert new code
       fracht <- (1.25*par()$cin[2])/par()$pin[2]
       ylim[1] <- ylim[1] - diff(ylim)*max(0, fracht-0.04)
## End insert new code
       plot(xx, rsp, xlim = c(0, max(xx, na.rm = TRUE)),
            ylim = ylim, main = main, xlab = "Leverage",
            ylab = ylab5, type = "n", ...)

Then, about 15 lines further down, replace
         legend("bottomleft", legend = "Cook's distance",
                lty = 2, col = 2, bty = "n")

by
         legend("bottomleft", legend = "Cook's distance",
                lty = 2, col = 2, bty = "n", y.intersp=0.5)

If this second change is not made, then one wants fracht <- (1.5*par() 
$cin[2])/par()$pin[2]
I prefer the "Cook's distance" text to be a bit closer to the x-axis,  
as it separates it more clearly from any point labels.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


From jfox at mcmaster.ca  Wed Feb 18 02:27:21 2009
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 17 Feb 2009 20:27:21 -0500
Subject: [Rd] plot.lm: "Cook's distance" label can overplot point labels
In-Reply-To: <19E18CBA-23C1-4749-BD74-EDC1B8FC24B1@anu.edu.au>
References: <19E18CBA-23C1-4749-BD74-EDC1B8FC24B1@anu.edu.au>
Message-ID: <006a01c99168$0c3f9690$24bec3b0$@ca>

Dear John,

It occurs to me that the title above the graph, "Residuals vs. Leverage," is
entirely redundant since the x-axis is labelled "Leverage" and the y-axis
"Studentized residuals." Why not use the title above the graph for "Cook's
distance countours"?

Regards,
 John

> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
On
> Behalf Of John Maindonald
> Sent: February-17-09 5:54 PM
> To: r-devel at r-project.org
> Cc: Martin Maechler
> Subject: [Rd] plot.lm: "Cook's distance" label can overplot point labels
> 
> The following code demonstrates an annoyance with plot.lm():
> 
> library(DAAGxtras)
> x11(width=3.75, height=4)
> nihills.lm <- lm(log(time) ~ log(dist) + log(climb), data = nihills)
> plot(nihills.lm, which=5)
> 
> OR try the following
> xy <- data.frame(x=c(3,1:5), y=c(-2, 1:5))
> plot(lm(y ~ x, data=xy), which=5)
> 
> The "Cook's distance" text overplots the label for the point with the
> smallest residual.  This is an issue when the size of the plot is much
> less than the default, and the pointsize is not reduced proportionately.
> 
> 
> I suggest the following:
>        xx <- hii
>        xx[xx >= 1] <- NA
> ## Insert new code
>        fracht <- (1.25*par()$cin[2])/par()$pin[2]
>        ylim[1] <- ylim[1] - diff(ylim)*max(0, fracht-0.04)
> ## End insert new code
>        plot(xx, rsp, xlim = c(0, max(xx, na.rm = TRUE)),
>             ylim = ylim, main = main, xlab = "Leverage",
>             ylab = ylab5, type = "n", ...)
> 
> Then, about 15 lines further down, replace
>          legend("bottomleft", legend = "Cook's distance",
>                 lty = 2, col = 2, bty = "n")
> 
> by
>          legend("bottomleft", legend = "Cook's distance",
>                 lty = 2, col = 2, bty = "n", y.intersp=0.5)
> 
> If this second change is not made, then one wants fracht <- (1.5*par()
> $cin[2])/par()$pin[2]
> I prefer the "Cook's distance" text to be a bit closer to the x-axis,
> as it separates it more clearly from any point labels.
> 
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Wed Feb 18 05:50:59 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 18 Feb 2009 04:50:59 +0000 (GMT)
Subject: [Rd] C basic indentation
In-Reply-To: <499B3446.1080505@stat.umu.se>
References: <499B3446.1080505@stat.umu.se>
Message-ID: <alpine.LFD.2.00.0902180438060.7442@gannet.stats.ox.ac.uk>

This seems a question for the ESS-help list.

But you should be using Emacs customization these days: I have in my 
.emacs

  '(c-basic-offset 4)
  '(c-default-style "bsd")

in custom-set-variables, and that is what the 'R Internals' manual 
says for Emacs >= 21.  (You can set that from the 'Customize Emacs' 
menu item, Programming, Languages, C group.)


On Tue, 17 Feb 2009, G?ran Brostr?m wrote:

> I use the recommendations in "R coding standards", i.e., I put

Those are recommendations for Emacs < 21.

>     ;;; C
>     (add-hook 'c-mode-hook
>               (lambda () (c-set-style "bsd")))
>     ;;; ESS
>     (add-hook 'ess-mode-hook
>               (lambda ()
>                 (ess-set-style 'C++ 'quiet)
>                 (add-hook 'local-write-file-hooks
>                           (lambda ()
>                             (ess-nuke-trailing-whitespace)))))
>     (setq ess-nuke-trailing-whitespace-p 'ask)
>     ;;; Perl
>     (add-hook 'perl-mode-hook
>               (lambda () (setq perl-indent-level 4)))
>
> into my .emacs file. IIRC, back in 2005 it gave me a basic indentation of 4 
> in C (good), but only 2 in R (not so good, but I fixed it with the aid of 
> this excellent list). But now it gives me a basic indentation of eight (8!) 
> in C code. This is not what I want. I think I saw somewhere that the bsd 
> standard actually has changed from four to eight recently (but I cannot find 
> it now).

> Two points given that the standard really has changed: (i) The text in "R 
> coding standards" should be changed accordingly.

It has been (long ago):

   Alternatively, (for @acronym{GNU} Emacs 21 or later),
   use customization to set the @code{c-default-style} to @code{"bsd"}
   and @code{c-basic-offset} to @code{4}.)


> (ii) How do I get back to a 
> basic indentation of 4 in C and R code?

Follow the above.

>
> G?ran
>
>> sessionInfo()
> R version 2.8.1 Patched (2009-01-03 r47458)
> i686-pc-linux-gnu
>
> locale:
> LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;
> LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;
> LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> GNU Emacs 22.2.1 on Ubuntu 8.10 x64
> -- 
> G?ran Brostr?m               phone: 46 90 786 5223; 46 705 197 507
> Department of Statistics     fax: 46 90 786 6614
> Ume? University              email: gb at stat.umu.se
> SE-90187 Ume?, Sweden        http://tal.stat.umu.se/~gb
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From gb at stat.umu.se  Wed Feb 18 08:45:43 2009
From: gb at stat.umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Wed, 18 Feb 2009 08:45:43 +0100
Subject: [Rd] C basic indentation
In-Reply-To: <alpine.LFD.2.00.0902180438060.7442@gannet.stats.ox.ac.uk>
References: <499B3446.1080505@stat.umu.se>
	<alpine.LFD.2.00.0902180438060.7442@gannet.stats.ox.ac.uk>
Message-ID: <499BBCA7.3060605@stat.umu.se>



Prof Brian Ripley wrote:

> This seems a question for the ESS-help list.
> 
> But you should be using Emacs customization these days: I have in my .emacs
> 
>  '(c-basic-offset 4)
>  '(c-default-style "bsd")
> 
> in custom-set-variables, and that is what the 'R Internals' manual says 
> for Emacs >= 21.  (You can set that from the 'Customize Emacs' menu 
> item, Programming, Languages, C group.)
> 
> 
> On Tue, 17 Feb 2009, G?ran Brostr?m wrote:
> 
>> I use the recommendations in "R coding standards", i.e., I put
> 
> Those are recommendations for Emacs < 21.

IMHO, this is not clear from the text, see below.

> 
>>     ;;; C
>>     (add-hook 'c-mode-hook
>>               (lambda () (c-set-style "bsd")))
>>     ;;; ESS
>>     (add-hook 'ess-mode-hook
>>               (lambda ()
>>                 (ess-set-style 'C++ 'quiet)
>>                 (add-hook 'local-write-file-hooks
>>                           (lambda ()
>>                             (ess-nuke-trailing-whitespace)))))
>>     (setq ess-nuke-trailing-whitespace-p 'ask)
>>     ;;; Perl
>>     (add-hook 'perl-mode-hook
>>               (lambda () (setq perl-indent-level 4)))
>>
>> into my .emacs file. IIRC, back in 2005 it gave me a basic indentation 
>> of 4 in C (good), but only 2 in R (not so good, but I fixed it with 
>> the aid of this excellent list). But now it gives me a basic 
>> indentation of eight (8!) in C code. This is not what I want. I think 
>> I saw somewhere that the bsd standard actually has changed from four 
>> to eight recently (but I cannot find it now).
> 
>> Two points given that the standard really has changed: (i) The text in 
>> "R coding standards" should be changed accordingly.
> 
> It has been (long ago):
> 
>   Alternatively, (for @acronym{GNU} Emacs 21 or later),
>   use customization to set the @code{c-default-style} to @code{"bsd"}
>   and @code{c-basic-offset} to @code{4}.)
> 
To me, the word "Alternatively" suggests that I can do it either way. My 
suggestion was to change this sentence, maybe by simply deleting the 
first word.

> 
>> (ii) How do I get back to a basic indentation of 4 in C and R code?
> 
> Follow the above.
> 

Thanks for the help, as usual much appreciated!

G?ran


From Kurt.Hornik at wu-wien.ac.at  Wed Feb 18 11:28:05 2009
From: Kurt.Hornik at wu-wien.ac.at (Kurt Hornik)
Date: Wed, 18 Feb 2009 11:28:05 +0100
Subject: [Rd] CRAN packages with invalid maintainer address
Message-ID: <18843.58037.273683.642630@fangorn.hornik.net>

Emails to the maintainers of the CRAN packages listed below recently
bounced:

  adbrook2 at stat.ncsu.edu: Rlab
  adbrook2 at unity.ncsu.edu VIA atina.brooks at alumni.ncsu.edu: knnflex
  adinno at hsph.harvard.edu: LoopAnalyst
  aet21 at hutchison-mrc.cam.ac.ac: mlica
  alexandra.imbert at met.no: anm
  amy_kapp at hotmail.com: clusterRepro
  andrea.lehnert-batar at web.de: pARtial
  baayen at mpi.nl: languageR
  bernard.boulerice at sympatico.ca: moc
  bfbraum at fas.harvard.edu: boolean
  cbouveyr at exchange.acadiau.ca VIA charles.bouveyron at acadiau.ca: LLN
  clifford at galton.uchicago.edu: regress
  danw at sussex.ac.uk: sdtalt
  e.motakis at bris.ac.uk: DDHFm
  ebarrios at wisc.edu: BsMD
  gregoire.thomas at ugent.be: HTMLapplets
  h.andersson at nioo.knaw.nl: femmeR
  hengl at fdm.uni-freiburg.de: mota
  henschel at ibe.med.uni-muenchen.de: intcox survBayes
  info at tomprice.net: cgh titan waveclock
  jboik at stanford.edu: mixlow
  julian.taylor at adelaide.edu.au: hett
  marina.knight at bristol.ac.uk: nlt
  miyamura at sigmath.es.osaka-u.ac.jp: rggm
  mounir at good.ibl.fr: Rmdr
  mylesenglish at rockhead.biz: hydrogeo
  nemad at stat.washington.edu: clustvarsel
  o.briet_antispam_ at gmail.com: gsarima
  oyvind.langsrud at matforsk.no VIA ffmanova at mevik.net: ffmanova
  raph at stat.washington.edu: EMV
  rory.michelland at gmail.fr: StatFingerprints
  rtmoore at fas.harvard.edu: blockTools
  rxg218 at psu.edu VIA rajarshi at presidency.com: spe
  ryota.suzuki at is.titech.ac.jp: pvclust
  savin at savba.sk: tdist
  sekemp at glam.ac.uk: knnFinder
  thoffman at hsph.harvard.edu: fbati fgui pbatR
  veronica at stat.washington.edu: ProbForecastGOP
  yaqiang at stat.stanford.edu: rda
  yucel at schoolph.umass.edu: mlmmm
  ssirkia at maths.jyu.fi: SpatialNP
  telford at progsoc.uts.edu.au: gafit

If you are one of these, or know how to reach these, pls let me know.

-k


From cgenolin at u-paris10.fr  Wed Feb 18 16:35:17 2009
From: cgenolin at u-paris10.fr (Christophe Genolini)
Date: Wed, 18 Feb 2009 16:35:17 +0100
Subject: [Rd] getGraphicsEvent in an example
In-Reply-To: <B37C0A15B8FB3C468B5BC7EBC7DA14CC61CA2A09C4@LP-EXMBVS10.CO.IHC.COM>
References: <499AA869.1040400@u-paris10.fr>
	<B37C0A15B8FB3C468B5BC7EBC7DA14CC61CA2A09C4@LP-EXMBVS10.CO.IHC.COM>
Message-ID: <499C2AB5.50300@u-paris10.fr>

Greg Snow a ?crit :
> Just wrap the example in either \dontrun{} or
> if(interactive()){
>
> }
>   
Thanks. Your solution gives me an other idea :
try(myFunction) works as well.

Christophe


> That way that example will be skipped when the automatic tests are done, but will still be available for a reader to run by copy/paste or the examples function (2nd case above).
>
> This has worked for me, examples using these are playSudoku in the sudoku package and dynIdentify in TeachingDemos.
>
> Hope this helps,
>
>


From dasmailinglists at gmail.com  Wed Feb 18 21:02:10 2009
From: dasmailinglists at gmail.com (David Scherrer)
Date: Wed, 18 Feb 2009 15:02:10 -0500
Subject: [Rd] interior point methods, automatic differentiation in R
Message-ID: <1a3e78310902181202y452593ceoe621821e01e31566@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090218/fc48087c/attachment.pl>

From John.Maindonald at anu.edu.au  Wed Feb 18 22:56:57 2009
From: John.Maindonald at anu.edu.au (John Maindonald)
Date: Thu, 19 Feb 2009 08:56:57 +1100
Subject: [Rd] plot.lm: "Cook's distance" label can overplot point labels
In-Reply-To: <006a01c99168$0c3f9690$24bec3b0$@ca>
References: <19E18CBA-23C1-4749-BD74-EDC1B8FC24B1@anu.edu.au>
	<006a01c99168$0c3f9690$24bec3b0$@ca>
Message-ID: <78A5258B-37C7-4D07-A176-8CFB20812293@anu.edu.au>

Dear John -
The title above the graph is also redundant for the first of the  
plots; do we want to be totally consistent?  I am not sure.

It occurs to me that the text "Cook's distance", as well as the  
contours, might be in red.
Regards
John.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 18/02/2009, at 12:27 PM, John Fox wrote:

> Dear John,
>
> It occurs to me that the title above the graph, "Residuals vs.  
> Leverage," is
> entirely redundant since the x-axis is labelled "Leverage" and the y- 
> axis
> "Studentized residuals." Why not use the title above the graph for  
> "Cook's
> distance countours"?
>
> Regards,
> John
>
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org 
>> ]
> On
>> Behalf Of John Maindonald
>> Sent: February-17-09 5:54 PM
>> To: r-devel at r-project.org
>> Cc: Martin Maechler
>> Subject: [Rd] plot.lm: "Cook's distance" label can overplot point  
>> labels
>>
>> The following code demonstrates an annoyance with plot.lm():
>>
>> library(DAAGxtras)
>> x11(width=3.75, height=4)
>> nihills.lm <- lm(log(time) ~ log(dist) + log(climb), data = nihills)
>> plot(nihills.lm, which=5)
>>
>> OR try the following
>> xy <- data.frame(x=c(3,1:5), y=c(-2, 1:5))
>> plot(lm(y ~ x, data=xy), which=5)
>>
>> The "Cook's distance" text overplots the label for the point with the
>> smallest residual.  This is an issue when the size of the plot is  
>> much
>> less than the default, and the pointsize is not reduced  
>> proportionately.
>>
>>
>> I suggest the following:
>>      xx <- hii
>>      xx[xx >= 1] <- NA
>> ## Insert new code
>>      fracht <- (1.25*par()$cin[2])/par()$pin[2]
>>      ylim[1] <- ylim[1] - diff(ylim)*max(0, fracht-0.04)
>> ## End insert new code
>>      plot(xx, rsp, xlim = c(0, max(xx, na.rm = TRUE)),
>>           ylim = ylim, main = main, xlab = "Leverage",
>>           ylab = ylab5, type = "n", ...)
>>
>> Then, about 15 lines further down, replace
>>        legend("bottomleft", legend = "Cook's distance",
>>               lty = 2, col = 2, bty = "n")
>>
>> by
>>        legend("bottomleft", legend = "Cook's distance",
>>               lty = 2, col = 2, bty = "n", y.intersp=0.5)
>>
>> If this second change is not made, then one wants fracht <-  
>> (1.5*par()
>> $cin[2])/par()$pin[2]
>> I prefer the "Cook's distance" text to be a bit closer to the x-axis,
>> as it separates it more clearly from any point labels.
>>
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics & Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From jfox at mcmaster.ca  Wed Feb 18 23:27:51 2009
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 18 Feb 2009 17:27:51 -0500
Subject: [Rd] plot.lm: "Cook's distance" label can overplot point labels
In-Reply-To: <78A5258B-37C7-4D07-A176-8CFB20812293@anu.edu.au>
References: <19E18CBA-23C1-4749-BD74-EDC1B8FC24B1@anu.edu.au>
	<006a01c99168$0c3f9690$24bec3b0$@ca>
	<78A5258B-37C7-4D07-A176-8CFB20812293@anu.edu.au>
Message-ID: <00a301c99218$232c5c70$69851550$@ca>

Dear John,

> -----Original Message-----
> From: John Maindonald [mailto:John.Maindonald at anu.edu.au]
> Sent: February-18-09 4:57 PM
> To: John Fox
> Cc: 'Martin Maechler'; r-devel at r-project.org
> Subject: Re: [Rd] plot.lm: "Cook's distance" label can overplot point
labels
> 
> Dear John -
> The title above the graph is also redundant for the first of the
> plots; do we want to be totally consistent?  I am not sure.

Why not? "A foolish consistency is the hobgoblin of little minds," but maybe
this isn't a foolish consistency.

> 
> It occurs to me that the text "Cook's distance", as well as the
> contours, might be in red.

That would provide a nice visual cue (for those who aren't colour blind).

Best,
 John

> Regards
> John.
> 
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> 
> 
> On 18/02/2009, at 12:27 PM, John Fox wrote:
> 
> > Dear John,
> >
> > It occurs to me that the title above the graph, "Residuals vs.
> > Leverage," is
> > entirely redundant since the x-axis is labelled "Leverage" and the y-
> > axis
> > "Studentized residuals." Why not use the title above the graph for
> > "Cook's
> > distance countours"?
> >
> > Regards,
> > John
> >
> >> -----Original Message-----
> >> From: r-devel-bounces at r-project.org
[mailto:r-devel-bounces at r-project.org
> >> ]
> > On
> >> Behalf Of John Maindonald
> >> Sent: February-17-09 5:54 PM
> >> To: r-devel at r-project.org
> >> Cc: Martin Maechler
> >> Subject: [Rd] plot.lm: "Cook's distance" label can overplot point
> >> labels
> >>
> >> The following code demonstrates an annoyance with plot.lm():
> >>
> >> library(DAAGxtras)
> >> x11(width=3.75, height=4)
> >> nihills.lm <- lm(log(time) ~ log(dist) + log(climb), data = nihills)
> >> plot(nihills.lm, which=5)
> >>
> >> OR try the following
> >> xy <- data.frame(x=c(3,1:5), y=c(-2, 1:5))
> >> plot(lm(y ~ x, data=xy), which=5)
> >>
> >> The "Cook's distance" text overplots the label for the point with the
> >> smallest residual.  This is an issue when the size of the plot is
> >> much
> >> less than the default, and the pointsize is not reduced
> >> proportionately.
> >>
> >>
> >> I suggest the following:
> >>      xx <- hii
> >>      xx[xx >= 1] <- NA
> >> ## Insert new code
> >>      fracht <- (1.25*par()$cin[2])/par()$pin[2]
> >>      ylim[1] <- ylim[1] - diff(ylim)*max(0, fracht-0.04)
> >> ## End insert new code
> >>      plot(xx, rsp, xlim = c(0, max(xx, na.rm = TRUE)),
> >>           ylim = ylim, main = main, xlab = "Leverage",
> >>           ylab = ylab5, type = "n", ...)
> >>
> >> Then, about 15 lines further down, replace
> >>        legend("bottomleft", legend = "Cook's distance",
> >>               lty = 2, col = 2, bty = "n")
> >>
> >> by
> >>        legend("bottomleft", legend = "Cook's distance",
> >>               lty = 2, col = 2, bty = "n", y.intersp=0.5)
> >>
> >> If this second change is not made, then one wants fracht <-
> >> (1.5*par()
> >> $cin[2])/par()$pin[2]
> >> I prefer the "Cook's distance" text to be a bit closer to the x-axis,
> >> as it separates it more clearly from any point labels.
> >>
> >> John Maindonald             email: john.maindonald at anu.edu.au
> >> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> >> Centre for Mathematics & Its Applications, Room 1194,
> >> John Dedman Mathematical Sciences Building (Building 27)
> >> Australian National University, Canberra ACT 0200.
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >


From Friedrich.Leisch at stat.uni-muenchen.de  Wed Feb 18 23:53:42 2009
From: Friedrich.Leisch at stat.uni-muenchen.de (Friedrich Leisch)
Date: Thu, 19 Feb 2009 09:53:42 +1100
Subject: [Rd] Google Summer of Code 2009
Message-ID: <18844.37238.384954.744812@ridcully.stat.uni-muenchen.de>


Hi,

in approximately one months time mentoring institutions can propose
projects for the Google Summer of Code 2009, see

  http://code.google.com/soc/

Last year the R Foundation succesfully participated with 4 projects,
see http://www.r-project.org/SoC08/ for details.  We want to
participate again this year. Our project proposals will be managed by
Manuel Eugster (email address in CC). Manuel is one of my PhD students
and mentored the Roxygen project last year. This mail is mainly
intended to make you aware of the program, Manuel will send a followup
email with more technical details in the next days.

In this phase we are looking for potential mentors who can offer
interesting projects to students.  I don't think that we will get much
more than 4-6 projects, so don't be disappointed if you propose
something and don't get selected.

There are two selection steps involved: (a) The R Foundation has to
compile an official "ideas list" of projects, for which students can
apply. Last year we had 8 of those. After that, we (b) get a certain
number of slots from Google (4 last year) and all prospective project
mentors can vote on which projects actually get funding.

Currently we are looking for good ideas for phase (a). I give no
guarantees that all ideas will get on our official ideas list, what we
pick depends on the number of submissions and topics, respectively. We
want to make sure to have a broad range of themes, it is unlikely,
that we will, e.g., pick 10 database projects. Also keep in mind that
students have only three months time. This is not a research exercise
for the students, you should have a rough idea what needs to be done.

Last year we had a majority of "infrastructure projects", and only few
with focus on statistical algorithms. We got a lot of applications for
the latter, so don't hesitate to formulate projects in that
direction. Important infrastructure may get precedence over
specialized algorithms, though, because the whole community can benfit
from those. But that will be a decision in phase (b), and we are not
there yet.

Please don't send any ideas to me right now, wait for the above
mentioned email by Manuel on the technical details for idea submission.

Best,
Fritz

-- 
-----------------------------------------------------------------------
Prof. Dr. Friedrich Leisch 

Institut f?r Statistik                          Tel: (+49 89) 2180 3165
Ludwig-Maximilians-Universit?t                  Fax: (+49 89) 2180 5308
Ludwigstra?e 33
D-80539 M?nchen                     http://www.statistik.lmu.de/~leisch
-----------------------------------------------------------------------
   Journal Computational Statistics --- http://www.springer.com/180 
          M?nchner R Kurse --- http://www.statistik.lmu.de/R


From ianfiske at gmail.com  Thu Feb 19 05:23:04 2009
From: ianfiske at gmail.com (Ian Fiske)
Date: Wed, 18 Feb 2009 20:23:04 -0800 (PST)
Subject: [Rd] interior point methods, automatic differentiation in R
In-Reply-To: <1a3e78310902181202y452593ceoe621821e01e31566@mail.gmail.com>
References: <1a3e78310902181202y452593ceoe621821e01e31566@mail.gmail.com>
Message-ID: <22093775.post@talk.nabble.com>


Regarding interior point methods, you can find a list of relevant packages in
the Optimization and Mathematical Programming Task View at
http://mirrors.ibiblio.org/pub/mirrors/CRAN/web/views/Optimization.html. 
But it doesn't look like there is anything like an interface to a
comprehensive interior point method program.  Linking to ipopt might be a
worthwhile investment of someone's time...

Ian Fiske



David Scherrer-2 wrote:
> 
> Dear all,
> 
> I'm wondering if there are some ongoing projects for interior point
> methods
> in R (e.g. linking ipopt from Coin written in C++ to R) and for automatic
> differentiation in R (e.g. linking openAD available in C++ and Fortran) ?
> 
> Many thanks,
> David
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 

-- 
View this message in context: http://www.nabble.com/interior-point-methods%2C-automatic-differentiation-in-R-tp22087073p22093775.html
Sent from the R devel mailing list archive at Nabble.com.


From ripley at stats.ox.ac.uk  Thu Feb 19 07:58:14 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 19 Feb 2009 06:58:14 +0000 (GMT)
Subject: [Rd] plot.lm: "Cook's distance" label can overplot point labels
In-Reply-To: <00a301c99218$232c5c70$69851550$@ca>
References: <19E18CBA-23C1-4749-BD74-EDC1B8FC24B1@anu.edu.au>
	<006a01c99168$0c3f9690$24bec3b0$@ca>
	<78A5258B-37C7-4D07-A176-8CFB20812293@anu.edu.au>
	<00a301c99218$232c5c70$69851550$@ca>
Message-ID: <alpine.OSX.1.00.0902190647490.60510@tystie.local>

On Wed, 18 Feb 2009, John Fox wrote:

> Dear John,
>
>> -----Original Message-----
>> From: John Maindonald [mailto:John.Maindonald at anu.edu.au]
>> Sent: February-18-09 4:57 PM
>> To: John Fox
>> Cc: 'Martin Maechler'; r-devel at r-project.org
>> Subject: Re: [Rd] plot.lm: "Cook's distance" label can overplot point
> labels
>>
>> Dear John -
>> The title above the graph is also redundant for the first of the
>> plots; do we want to be totally consistent?  I am not sure.
>
> Why not? "A foolish consistency is the hobgoblin of little minds," but maybe
> this isn't a foolish consistency.
>
>>
>> It occurs to me that the text "Cook's distance", as well as the
>> contours, might be in red.
>
> That would provide a nice visual cue (for those who aren't colour blind).

Or using a black-and-white device.  We have not hitherto assumed a 
colour device in 'stats' graphics, and given how often they are 
printed I don't think we want to start.

As so often, it seems that what looks good is in the eye of the 
beholder.  If the two of you can agree on something that you both see 
is a definite improvement, please provide a patch and examples to try 
to persuade everyone else.  (As a Wishlist item on R-bugs, so it gets 
recorded.)

>
> Best,
> John
>
>> Regards
>> John.
>>
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics & Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>>
>>
>> On 18/02/2009, at 12:27 PM, John Fox wrote:
>>
>>> Dear John,
>>>
>>> It occurs to me that the title above the graph, "Residuals vs.
>>> Leverage," is
>>> entirely redundant since the x-axis is labelled "Leverage" and the y-
>>> axis
>>> "Studentized residuals." Why not use the title above the graph for
>>> "Cook's
>>> distance countours"?
>>>
>>> Regards,
>>> John
>>>
>>>> -----Original Message-----
>>>> From: r-devel-bounces at r-project.org
> [mailto:r-devel-bounces at r-project.org
>>>> ]
>>> On
>>>> Behalf Of John Maindonald
>>>> Sent: February-17-09 5:54 PM
>>>> To: r-devel at r-project.org
>>>> Cc: Martin Maechler
>>>> Subject: [Rd] plot.lm: "Cook's distance" label can overplot point
>>>> labels
>>>>
>>>> The following code demonstrates an annoyance with plot.lm():
>>>>
>>>> library(DAAGxtras)
>>>> x11(width=3.75, height=4)
>>>> nihills.lm <- lm(log(time) ~ log(dist) + log(climb), data = nihills)
>>>> plot(nihills.lm, which=5)
>>>>
>>>> OR try the following
>>>> xy <- data.frame(x=c(3,1:5), y=c(-2, 1:5))
>>>> plot(lm(y ~ x, data=xy), which=5)
>>>>
>>>> The "Cook's distance" text overplots the label for the point with the
>>>> smallest residual.  This is an issue when the size of the plot is
>>>> much
>>>> less than the default, and the pointsize is not reduced
>>>> proportionately.
>>>>
>>>>
>>>> I suggest the following:
>>>>      xx <- hii
>>>>      xx[xx >= 1] <- NA
>>>> ## Insert new code
>>>>      fracht <- (1.25*par()$cin[2])/par()$pin[2]
>>>>      ylim[1] <- ylim[1] - diff(ylim)*max(0, fracht-0.04)
>>>> ## End insert new code
>>>>      plot(xx, rsp, xlim = c(0, max(xx, na.rm = TRUE)),
>>>>           ylim = ylim, main = main, xlab = "Leverage",
>>>>           ylab = ylab5, type = "n", ...)
>>>>
>>>> Then, about 15 lines further down, replace
>>>>        legend("bottomleft", legend = "Cook's distance",
>>>>               lty = 2, col = 2, bty = "n")
>>>>
>>>> by
>>>>        legend("bottomleft", legend = "Cook's distance",
>>>>               lty = 2, col = 2, bty = "n", y.intersp=0.5)
>>>>
>>>> If this second change is not made, then one wants fracht <-
>>>> (1.5*par()
>>>> $cin[2])/par()$pin[2]
>>>> I prefer the "Cook's distance" text to be a bit closer to the x-axis,
>>>> as it separates it more clearly from any point labels.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From John.Maindonald at anu.edu.au  Thu Feb 19 08:53:39 2009
From: John.Maindonald at anu.edu.au (John Maindonald)
Date: Thu, 19 Feb 2009 18:53:39 +1100
Subject: [Rd] plot.lm: "Cook's distance" label can overplot point labels
In-Reply-To: <alpine.OSX.1.00.0902190647490.60510@tystie.local>
References: <19E18CBA-23C1-4749-BD74-EDC1B8FC24B1@anu.edu.au>
	<006a01c99168$0c3f9690$24bec3b0$@ca>
	<78A5258B-37C7-4D07-A176-8CFB20812293@anu.edu.au>
	<00a301c99218$232c5c70$69851550$@ca>
	<alpine.OSX.1.00.0902190647490.60510@tystie.local>
Message-ID: <68F4BAFB-148B-44D4-86BD-89E13AD1AA58@anu.edu.au>

Actually, the contours and the smooth are currently printed with  
col=2.  This prints satisfactorily in grayscale.    Colours ("orange"  
and "darkred" as well as col=2) are also used in termplot.

Does the stricture against "colour" extend to grayscale?  Does it  
apply to lines as well as text?

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 19/02/2009, at 5:58 PM, Prof Brian Ripley wrote:

> On Wed, 18 Feb 2009, John Fox wrote:
>
>> Dear John,
>>
>>> -----Original Message-----
>>> From: John Maindonald [mailto:John.Maindonald at anu.edu.au]
>>> Sent: February-18-09 4:57 PM
>>> To: John Fox
>>> Cc: 'Martin Maechler'; r-devel at r-project.org
>>> Subject: Re: [Rd] plot.lm: "Cook's distance" label can overplot  
>>> point
>> labels
>>>
>>> Dear John -
>>> The title above the graph is also redundant for the first of the
>>> plots; do we want to be totally consistent?  I am not sure.
>>
>> Why not? "A foolish consistency is the hobgoblin of little minds,"  
>> but maybe
>> this isn't a foolish consistency.
>>
>>>
>>> It occurs to me that the text "Cook's distance", as well as the
>>> contours, might be in red.
>>
>> That would provide a nice visual cue (for those who aren't colour  
>> blind).
>
> Or using a black-and-white device.  We have not hitherto assumed a  
> colour device in 'stats' graphics, and given how often they are  
> printed I don't think we want to start.
>
> As so often, it seems that what looks good is in the eye of the  
> beholder.  If the two of you can agree on something that you both  
> see is a definite improvement, please provide a patch and examples  
> to try to persuade everyone else.  (As a Wishlist item on R-bugs, so  
> it gets recorded.)
>
>>
>> Best,
>> John
>>
>>> Regards
>>> John.
>>>
>>> John Maindonald             email: john.maindonald at anu.edu.au
>>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>>> Centre for Mathematics & Its Applications, Room 1194,
>>> John Dedman Mathematical Sciences Building (Building 27)
>>> Australian National University, Canberra ACT 0200.
>>>
>>>
>>> On 18/02/2009, at 12:27 PM, John Fox wrote:
>>>
>>>> Dear John,
>>>>
>>>> It occurs to me that the title above the graph, "Residuals vs.
>>>> Leverage," is
>>>> entirely redundant since the x-axis is labelled "Leverage" and  
>>>> the y-
>>>> axis
>>>> "Studentized residuals." Why not use the title above the graph for
>>>> "Cook's
>>>> distance countours"?
>>>>
>>>> Regards,
>>>> John
>>>>
>>>>> -----Original Message-----
>>>>> From: r-devel-bounces at r-project.org
>> [mailto:r-devel-bounces at r-project.org
>>>>> ]
>>>> On
>>>>> Behalf Of John Maindonald
>>>>> Sent: February-17-09 5:54 PM
>>>>> To: r-devel at r-project.org
>>>>> Cc: Martin Maechler
>>>>> Subject: [Rd] plot.lm: "Cook's distance" label can overplot point
>>>>> labels
>>>>>
>>>>> The following code demonstrates an annoyance with plot.lm():
>>>>>
>>>>> library(DAAGxtras)
>>>>> x11(width=3.75, height=4)
>>>>> nihills.lm <- lm(log(time) ~ log(dist) + log(climb), data =  
>>>>> nihills)
>>>>> plot(nihills.lm, which=5)
>>>>>
>>>>> OR try the following
>>>>> xy <- data.frame(x=c(3,1:5), y=c(-2, 1:5))
>>>>> plot(lm(y ~ x, data=xy), which=5)
>>>>>
>>>>> The "Cook's distance" text overplots the label for the point  
>>>>> with the
>>>>> smallest residual.  This is an issue when the size of the plot is
>>>>> much
>>>>> less than the default, and the pointsize is not reduced
>>>>> proportionately.
>>>>>
>>>>>
>>>>> I suggest the following:
>>>>>    xx <- hii
>>>>>    xx[xx >= 1] <- NA
>>>>> ## Insert new code
>>>>>    fracht <- (1.25*par()$cin[2])/par()$pin[2]
>>>>>    ylim[1] <- ylim[1] - diff(ylim)*max(0, fracht-0.04)
>>>>> ## End insert new code
>>>>>    plot(xx, rsp, xlim = c(0, max(xx, na.rm = TRUE)),
>>>>>         ylim = ylim, main = main, xlab = "Leverage",
>>>>>         ylab = ylab5, type = "n", ...)
>>>>>
>>>>> Then, about 15 lines further down, replace
>>>>>      legend("bottomleft", legend = "Cook's distance",
>>>>>             lty = 2, col = 2, bty = "n")
>>>>>
>>>>> by
>>>>>      legend("bottomleft", legend = "Cook's distance",
>>>>>             lty = 2, col = 2, bty = "n", y.intersp=0.5)
>>>>>
>>>>> If this second change is not made, then one wants fracht <-
>>>>> (1.5*par()
>>>>> $cin[2])/par()$pin[2]
>>>>> I prefer the "Cook's distance" text to be a bit closer to the x- 
>>>>> axis,
>>>>> as it separates it more clearly from any point labels.
>
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From lengyel.at at gmail.com  Wed Feb 18 21:15:13 2009
From: lengyel.at at gmail.com (lengyel.at at gmail.com)
Date: Wed, 18 Feb 2009 21:15:13 +0100 (CET)
Subject: [Rd] Inaccurate result for 0. (PR#13538)
Message-ID: <20090218201513.7C383282EF48@mail.pubhealth.ku.dk>

Full_Name: Attila Lengyel
Version: 2.8.0
OS: WinXP
Submission from: (NULL) (81.182.224.160)


> -0.3+0.1+0.1+0.1
[1] 2.775558e-17


From csardi at rmki.kfki.hu  Thu Feb 19 12:01:42 2009
From: csardi at rmki.kfki.hu (=?ISO-8859-1?B?R+Fib3IgQ3PhcmRp?=)
Date: Thu, 19 Feb 2009 12:01:42 +0100
Subject: [Rd] Inaccurate result for 0. (PR#13538)
In-Reply-To: <20090218201513.7C383282EF48@mail.pubhealth.ku.dk>
References: <20090218201513.7C383282EF48@mail.pubhealth.ku.dk>
Message-ID: <d70c15d40902190301q479ea1ddi58ed2df361183ef0@mail.gmail.com>

Hmmm, the favorite.

http://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f

G.

On Wed, Feb 18, 2009 at 9:15 PM,  <lengyel.at at gmail.com> wrote:
> Full_Name: Attila Lengyel
> Version: 2.8.0
> OS: WinXP
> Submission from: (NULL) (81.182.224.160)
>
>
>> -0.3+0.1+0.1+0.1
> [1] 2.775558e-17
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Gabor Csardi <Gabor.Csardi at unil.ch>     UNIL DGM


From ripley at stats.ox.ac.uk  Thu Feb 19 12:06:21 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 19 Feb 2009 11:06:21 +0000 (GMT)
Subject: [Rd] Inaccurate result for 0. (PR#13538)
In-Reply-To: <20090218201513.7C383282EF48@mail.pubhealth.ku.dk>
References: <20090218201513.7C383282EF48@mail.pubhealth.ku.dk>
Message-ID: <alpine.LFD.2.00.0902191106120.3232@gannet.stats.ox.ac.uk>

FAQ 7.31

On Wed, 18 Feb 2009, lengyel.at at gmail.com wrote:

> Full_Name: Attila Lengyel
> Version: 2.8.0
> OS: WinXP
> Submission from: (NULL) (81.182.224.160)
>
>
>> -0.3+0.1+0.1+0.1
> [1] 2.775558e-17
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch at stats.uwo.ca  Thu Feb 19 12:06:30 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 19 Feb 2009 06:06:30 -0500
Subject: [Rd] Inaccurate result for 0. (PR#13538)
In-Reply-To: <20090218201513.7C383282EF48@mail.pubhealth.ku.dk>
References: <20090218201513.7C383282EF48@mail.pubhealth.ku.dk>
Message-ID: <499D3D36.4080501@stats.uwo.ca>

On 18/02/2009 3:15 PM, lengyel.at at gmail.com wrote:
> Full_Name: Attila Lengyel
> Version: 2.8.0
> OS: WinXP
> Submission from: (NULL) (81.182.224.160)
> 
> 
>> -0.3+0.1+0.1+0.1
> [1] 2.775558e-17

This is not a bug, it's FAQ 7.31.

Duncan Murdoch


From rksh1 at cam.ac.uk  Thu Feb 19 12:10:45 2009
From: rksh1 at cam.ac.uk (Robin Hankin)
Date: Thu, 19 Feb 2009 11:10:45 +0000
Subject: [Rd] vignette compilation times
Message-ID: <499D3E35.4050300@cam.ac.uk>

Dear All

I am preparing a number of vignettes that require a very  long time to
process with Sweave.  The longest one takes 10 hours.  I love the weaver
package!

Is a package that includes such a computationally intensive vignette
acceptable on CRAN?  Are there any guidelines here? 



-- 
Robin K. S. Hankin
Uncertainty Analyst
University of Cambridge
19 Silver Street
Cambridge CB3 9EP
01223-764877


From ligges at statistik.tu-dortmund.de  Thu Feb 19 12:11:41 2009
From: ligges at statistik.tu-dortmund.de (ligges at statistik.tu-dortmund.de)
Date: Thu, 19 Feb 2009 12:11:41 +0100 (CET)
Subject: [Rd] Inaccurate result for 0. (PR#13538)
Message-ID: <20090219111141.81C6C282EFC1@mail.pubhealth.ku.dk>

Please read documentation and how to submit busg before you submit bugs 
to the bug repository.

See FAQ "Why doesn't R think these numbers are equal?".

Uwe Ligges

lengyel.at at gmail.com wrote:
> Full_Name: Attila Lengyel
> Version: 2.8.0
> OS: WinXP
> Submission from: (NULL) (81.182.224.160)
> 
> 
>> -0.3+0.1+0.1+0.1
> [1] 2.775558e-17
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Thu Feb 19 12:30:44 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Thu, 19 Feb 2009 12:30:44 +0100
Subject: [Rd] Inaccurate result for 0. (PR#13538)
In-Reply-To: <d70c15d40902190301q479ea1ddi58ed2df361183ef0@mail.gmail.com>
References: <20090218201513.7C383282EF48@mail.pubhealth.ku.dk>
	<d70c15d40902190301q479ea1ddi58ed2df361183ef0@mail.gmail.com>
Message-ID: <499D42E4.4060208@idi.ntnu.no>

G?bor Cs?rdi wrote:
> Hmmm, the favorite.
>
> http://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f
>   
hmm, an interesting quote:

"
To quote from ?The Elements of Programming Style? by Kernighan and Plauger:

    /10.0 times 0.1 is hardly ever 1.0/. 

"

so here's one example where 10.0 times 0.1 *is* 1.0:

perl -Mbignum -le 'print (10.0 * 0.1 == 1.0)'
# 1, for true

not an isolated idiosyncrazy, for that matter.

vQ


From ligges at statistik.tu-dortmund.de  Thu Feb 19 12:36:10 2009
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 19 Feb 2009 12:36:10 +0100
Subject: [Rd] vignette compilation times
In-Reply-To: <499D3E35.4050300@cam.ac.uk>
References: <499D3E35.4050300@cam.ac.uk>
Message-ID: <499D442A.20605@statistik.tu-dortmund.de>



Robin Hankin wrote:
> Dear All
> 
> I am preparing a number of vignettes that require a very  long time to
> process with Sweave.  The longest one takes 10 hours.  I love the weaver
> package!
> 
> Is a package that includes such a computationally intensive vignette
> acceptable on CRAN?  Are there any guidelines here?

Robin,

please try to keep a package below 5 minutes check time. You know, it's 
hard to perform daily checks for 1700 packages if just one already runs 
for 10 hours.
In reasonable circumstances, we do have exclude lists, but it probably 
does not make sense to provide that computational intensive vignettes.
Perhaps you can provide some intermediate results in form of Rdata files 
  in order to reduce runtime of your vignette's creation (and checks!).

Best wishes,
Uwe


From osklyar at maninvestments.com  Thu Feb 19 12:38:20 2009
From: osklyar at maninvestments.com (Sklyar, Oleg (London))
Date: Thu, 19 Feb 2009 11:38:20 -0000
Subject: [Rd] Google Summer of Code 2009
In-Reply-To: <18844.37238.384954.744812@ridcully.stat.uni-muenchen.de>
References: <18844.37238.384954.744812@ridcully.stat.uni-muenchen.de>
Message-ID: <1A68FCB28DE72F4BA3B967E6506CCE43047DF6A4@mildnpexmb01.maninvestments.ad.man.com>

Two ideas:

1) A library for interactive plots in R

R lacks functionality that would allow displaying of interactive plots with two distinct functionalities: zooming and panning. This functionality is extremely important for the analysis of large, high frequency, data sets spanning over large ranges (in time as well). The functionality should acknowledge Axis methods in callbacks on rescale (so that it could be extended to user-specific classes for axis generation) and should have a native C interface to R (i.e. no Java, but such cross platform widgets like GTK or QT or anything similar that does not require heavy-weight add-ons). GTK has been used successfully from within R in many applications (RGtk, rgobby, EBImage etc) on both *nix and Windows, and thus could be a preferential option, it is also extremely easy to integrate into R. The existing tools (e.g. iplots) are slow, unstable and lack support for time/date plots (or actually any non-standard axes) and they are all Java. We are looking into stanard xy-plots as well as image and 3D plots. Obviously one can think of further interactivity, but this would be too much for the Summer of Code project. A good prototype would already be a step forward.

2) Cross platform GUI debugger, preferably further Eclipse integration (beyond StatET capabilities)

Tibco has recently released the S+ workbench for eclipse which has a reasonable support for non-command line debugging. In the R community, the StatET eclipse plugin mimics a lot of code development functionality of S+ workbench, but has poor support for in-line execution of R sessions in eclipse and does not have debugging capabilities. Supporting this project further, or developing a GUI debugger independent of eclipse, are both acceptable options. The debugger should allow breakpoints, variable views etc.

For both of the above, our interest is mostly on the Linux side, but one should look into cross-platform solutions.

Regards,
Oleg

Dr Oleg Sklyar
Research Technologist
AHL / Man Investments Ltd
+44 (0)20 7144 3107
osklyar at maninvestments.com 

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Friedrich Leisch
> Sent: 18 February 2009 22:54
> To: r-devel at r-project.org
> Cc: Manuel.Eugster at stat.uni-muenchen.de
> Subject: [Rd] Google Summer of Code 2009
> 
> 
> Hi,
> 
> in approximately one months time mentoring institutions can propose
> projects for the Google Summer of Code 2009, see
> 
>   http://code.google.com/soc/
> 
> Last year the R Foundation succesfully participated with 4 projects,
> see http://www.r-project.org/SoC08/ for details.  We want to
> participate again this year. Our project proposals will be managed by
> Manuel Eugster (email address in CC). Manuel is one of my PhD students
> and mentored the Roxygen project last year. This mail is mainly
> intended to make you aware of the program, Manuel will send a followup
> email with more technical details in the next days.
> 
> In this phase we are looking for potential mentors who can offer
> interesting projects to students.  I don't think that we will get much
> more than 4-6 projects, so don't be disappointed if you propose
> something and don't get selected.
> 
> There are two selection steps involved: (a) The R Foundation has to
> compile an official "ideas list" of projects, for which students can
> apply. Last year we had 8 of those. After that, we (b) get a certain
> number of slots from Google (4 last year) and all prospective project
> mentors can vote on which projects actually get funding.
> 
> Currently we are looking for good ideas for phase (a). I give no
> guarantees that all ideas will get on our official ideas list, what we
> pick depends on the number of submissions and topics, respectively. We
> want to make sure to have a broad range of themes, it is unlikely,
> that we will, e.g., pick 10 database projects. Also keep in mind that
> students have only three months time. This is not a research exercise
> for the students, you should have a rough idea what needs to be done.
> 
> Last year we had a majority of "infrastructure projects", and only few
> with focus on statistical algorithms. We got a lot of applications for
> the latter, so don't hesitate to formulate projects in that
> direction. Important infrastructure may get precedence over
> specialized algorithms, though, because the whole community can benfit
> from those. But that will be a decision in phase (b), and we are not
> there yet.
> 
> Please don't send any ideas to me right now, wait for the above
> mentioned email by Manuel on the technical details for idea 
> submission.
> 
> Best,
> Fritz
> 
> -- 
> --------------------------------------------------------------
> ---------
> Prof. Dr. Friedrich Leisch 
> 
> Institut f?r Statistik                          Tel: (+49 89) 
> 2180 3165
> Ludwig-Maximilians-Universit?t                  Fax: (+49 89) 
> 2180 5308
> Ludwigstra?e 33
> D-80539 M?nchen                     
> http://www.statistik.lmu.de/~leisch
> --------------------------------------------------------------
> ---------
>    Journal Computational Statistics --- http://www.springer.com/180 
>           M?nchner R Kurse --- http://www.statistik.lmu.de/R
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

**********************************************************************
Please consider the environment before printing this email or its attachments.
The contents of this email are for the named addressees ...{{dropped:19}}


From rksh1 at cam.ac.uk  Thu Feb 19 12:47:12 2009
From: rksh1 at cam.ac.uk (Robin Hankin)
Date: Thu, 19 Feb 2009 11:47:12 +0000
Subject: [Rd] vignette compilation times
In-Reply-To: <499D442A.20605@statistik.tu-dortmund.de>
References: <499D3E35.4050300@cam.ac.uk>
	<499D442A.20605@statistik.tu-dortmund.de>
Message-ID: <499D46C0.10404@cam.ac.uk>

thanks for this clarification Uwe

Could I include the r_env_cache/  directory in the package
and then assume that the CRAN checks use

Sweave(.... , driver=weaver())

in which case the process takes about 10 seconds?

rksh





Uwe Ligges wrote:
>
>
> Robin Hankin wrote:
>> Dear All
>>
>> I am preparing a number of vignettes that require a very  long time to
>> process with Sweave.  The longest one takes 10 hours.  I love the weaver
>> package!
>>
>> Is a package that includes such a computationally intensive vignette
>> acceptable on CRAN?  Are there any guidelines here?
>
> Robin,
>
> please try to keep a package below 5 minutes check time. You know, 
> it's hard to perform daily checks for 1700 packages if just one 
> already runs for 10 hours.
> In reasonable circumstances, we do have exclude lists, but it probably 
> does not make sense to provide that computational intensive vignettes.
> Perhaps you can provide some intermediate results in form of Rdata 
> files  in order to reduce runtime of your vignette's creation (and 
> checks!).
>
> Best wishes,
> Uwe


-- 
Robin K. S. Hankin
Uncertainty Analyst
University of Cambridge
19 Silver Street
Cambridge CB3 9EP
01223-764877


From jfox at mcmaster.ca  Thu Feb 19 13:57:06 2009
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 19 Feb 2009 07:57:06 -0500
Subject: [Rd] plot.lm: "Cook's distance" label can overplot point labels
In-Reply-To: <68F4BAFB-148B-44D4-86BD-89E13AD1AA58@anu.edu.au>
References: <19E18CBA-23C1-4749-BD74-EDC1B8FC24B1@anu.edu.au>
	<006a01c99168$0c3f9690$24bec3b0$@ca>
	<78A5258B-37C7-4D07-A176-8CFB20812293@anu.edu.au>
	<00a301c99218$232c5c70$69851550$@ca>
	<alpine.OSX.1.00.0902190647490.60510@tystie.local>
	<68F4BAFB-148B-44D4-86BD-89E13AD1AA58@anu.edu.au>
Message-ID: <002501c99291$91e161f0$b5a425d0$@ca>

Dear John and Brian,

My point about colour-blindness was partly tongue-in-cheek, but I think that
it's a bad choice to have the second and third colours in the default
palette as red and green.

Regards,
 John


> -----Original Message-----
> From: John Maindonald [mailto:John.Maindonald at anu.edu.au]
> Sent: February-19-09 2:54 AM
> To: Prof Brian Ripley
> Cc: John Fox; r-devel at r-project.org; 'Martin Maechler'
> Subject: Re: [Rd] plot.lm: "Cook's distance" label can overplot point
labels
> 
> Actually, the contours and the smooth are currently printed with
> col=2.  This prints satisfactorily in grayscale.    Colours ("orange"
> and "darkred" as well as col=2) are also used in termplot.
> 
> Does the stricture against "colour" extend to grayscale?  Does it
> apply to lines as well as text?
> 
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> 
> 
> On 19/02/2009, at 5:58 PM, Prof Brian Ripley wrote:
> 
> > On Wed, 18 Feb 2009, John Fox wrote:
> >
> >> Dear John,
> >>
> >>> -----Original Message-----
> >>> From: John Maindonald [mailto:John.Maindonald at anu.edu.au]
> >>> Sent: February-18-09 4:57 PM
> >>> To: John Fox
> >>> Cc: 'Martin Maechler'; r-devel at r-project.org
> >>> Subject: Re: [Rd] plot.lm: "Cook's distance" label can overplot
> >>> point
> >> labels
> >>>
> >>> Dear John -
> >>> The title above the graph is also redundant for the first of the
> >>> plots; do we want to be totally consistent?  I am not sure.
> >>
> >> Why not? "A foolish consistency is the hobgoblin of little minds,"
> >> but maybe
> >> this isn't a foolish consistency.
> >>
> >>>
> >>> It occurs to me that the text "Cook's distance", as well as the
> >>> contours, might be in red.
> >>
> >> That would provide a nice visual cue (for those who aren't colour
> >> blind).
> >
> > Or using a black-and-white device.  We have not hitherto assumed a
> > colour device in 'stats' graphics, and given how often they are
> > printed I don't think we want to start.
> >
> > As so often, it seems that what looks good is in the eye of the
> > beholder.  If the two of you can agree on something that you both
> > see is a definite improvement, please provide a patch and examples
> > to try to persuade everyone else.  (As a Wishlist item on R-bugs, so
> > it gets recorded.)
> >
> >>
> >> Best,
> >> John
> >>
> >>> Regards
> >>> John.
> >>>
> >>> John Maindonald             email: john.maindonald at anu.edu.au
> >>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> >>> Centre for Mathematics & Its Applications, Room 1194,
> >>> John Dedman Mathematical Sciences Building (Building 27)
> >>> Australian National University, Canberra ACT 0200.
> >>>
> >>>
> >>> On 18/02/2009, at 12:27 PM, John Fox wrote:
> >>>
> >>>> Dear John,
> >>>>
> >>>> It occurs to me that the title above the graph, "Residuals vs.
> >>>> Leverage," is
> >>>> entirely redundant since the x-axis is labelled "Leverage" and
> >>>> the y-
> >>>> axis
> >>>> "Studentized residuals." Why not use the title above the graph for
> >>>> "Cook's
> >>>> distance countours"?
> >>>>
> >>>> Regards,
> >>>> John
> >>>>
> >>>>> -----Original Message-----
> >>>>> From: r-devel-bounces at r-project.org
> >> [mailto:r-devel-bounces at r-project.org
> >>>>> ]
> >>>> On
> >>>>> Behalf Of John Maindonald
> >>>>> Sent: February-17-09 5:54 PM
> >>>>> To: r-devel at r-project.org
> >>>>> Cc: Martin Maechler
> >>>>> Subject: [Rd] plot.lm: "Cook's distance" label can overplot point
> >>>>> labels
> >>>>>
> >>>>> The following code demonstrates an annoyance with plot.lm():
> >>>>>
> >>>>> library(DAAGxtras)
> >>>>> x11(width=3.75, height=4)
> >>>>> nihills.lm <- lm(log(time) ~ log(dist) + log(climb), data =
> >>>>> nihills)
> >>>>> plot(nihills.lm, which=5)
> >>>>>
> >>>>> OR try the following
> >>>>> xy <- data.frame(x=c(3,1:5), y=c(-2, 1:5))
> >>>>> plot(lm(y ~ x, data=xy), which=5)
> >>>>>
> >>>>> The "Cook's distance" text overplots the label for the point
> >>>>> with the
> >>>>> smallest residual.  This is an issue when the size of the plot is
> >>>>> much
> >>>>> less than the default, and the pointsize is not reduced
> >>>>> proportionately.
> >>>>>
> >>>>>
> >>>>> I suggest the following:
> >>>>>    xx <- hii
> >>>>>    xx[xx >= 1] <- NA
> >>>>> ## Insert new code
> >>>>>    fracht <- (1.25*par()$cin[2])/par()$pin[2]
> >>>>>    ylim[1] <- ylim[1] - diff(ylim)*max(0, fracht-0.04)
> >>>>> ## End insert new code
> >>>>>    plot(xx, rsp, xlim = c(0, max(xx, na.rm = TRUE)),
> >>>>>         ylim = ylim, main = main, xlab = "Leverage",
> >>>>>         ylab = ylab5, type = "n", ...)
> >>>>>
> >>>>> Then, about 15 lines further down, replace
> >>>>>      legend("bottomleft", legend = "Cook's distance",
> >>>>>             lty = 2, col = 2, bty = "n")
> >>>>>
> >>>>> by
> >>>>>      legend("bottomleft", legend = "Cook's distance",
> >>>>>             lty = 2, col = 2, bty = "n", y.intersp=0.5)
> >>>>>
> >>>>> If this second change is not made, then one wants fracht <-
> >>>>> (1.5*par()
> >>>>> $cin[2])/par()$pin[2]
> >>>>> I prefer the "Cook's distance" text to be a bit closer to the x-
> >>>>> axis,
> >>>>> as it separates it more clearly from any point labels.
> >
> >
> > --
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Norman.Rubin at amd.com  Thu Feb 19 14:35:12 2009
From: Norman.Rubin at amd.com (Rubin, Norman)
Date: Thu, 19 Feb 2009 08:35:12 -0500
Subject: [Rd] cpu bound cases
Message-ID: <049C4E48B10A854FB9D3B3C9DFAB506B011D5A1A@smarexmb1.amd.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090219/037cf89a/attachment.pl>

From simon.urbanek at r-project.org  Thu Feb 19 15:33:36 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 19 Feb 2009 09:33:36 -0500
Subject: [Rd] Google Summer of Code 2009
In-Reply-To: <1A68FCB28DE72F4BA3B967E6506CCE43047DF6A4@mildnpexmb01.maninvestments.ad.man.com>
References: <18844.37238.384954.744812@ridcully.stat.uni-muenchen.de>
	<1A68FCB28DE72F4BA3B967E6506CCE43047DF6A4@mildnpexmb01.maninvestments.ad.man.com>
Message-ID: <AF924562-B299-47E3-B3A6-83B668D7050F@r-project.org>


On Feb 19, 2009, at 6:38 , Sklyar, Oleg (London) wrote:

> Two ideas:
>
> 1) A library for interactive plots in R
>
> R lacks functionality that would allow displaying of interactive  
> plots with two distinct functionalities: zooming and panning. This  
> functionality is extremely important for the analysis of large, high  
> frequency, data sets spanning over large ranges (in time as well).  
> The functionality should acknowledge Axis methods in callbacks on  
> rescale (so that it could be extended to user-specific classes for  
> axis generation) and should have a native C interface to R (i.e. no  
> Java, but such cross platform widgets like GTK or QT or anything  
> similar that does not require heavy-weight add-ons). GTK has been  
> used successfully from within R in many applications (RGtk, rgobby,  
> EBImage etc) on both *nix and Windows, and thus could be a  
> preferential option, it is also extremely easy to integrate into R.  
> The existing tools (e.g. iplots) are slow, unstable and lack support  
> for time/date plots (or actually any non-standard axes) and they are  
> all Java. We are looking into stanard xy-plots as well as image and  
> 3D plots. Obviously one can think of further interactivity, but this  
> would be too much for the Summer of Code project. A good prototype  
> would already be a step forward.
>

If primitive 3d scatterplot interactivity is all you want, go with  
rggobi. It's GTK and has all this already and much more. However,  
ggobi also shows why GTK is not a good choice for general interactive  
graphics toolkit - it [GTK] is slow and lacks reasonable graphics  
support. OpenGL is IMHO a better way to go since IG don't really  
leverage any of the widgets (you get them for free via R widgets  
packages anyway) and OpenGL gives you excellent speed, alpha-support  
and anti-aliasing etc.

As you can imagine I don't agree with most of your statements above  
and I'm happy to discuss them in a separate thread. Just as an aside  
iPlots 3.0 (announced for useR!/DSC) are no longer Java based and have  
a native C interface.

Cheers,
S


> 2) Cross platform GUI debugger, preferably further Eclipse  
> integration (beyond StatET capabilities)
>
> Tibco has recently released the S+ workbench for eclipse which has a  
> reasonable support for non-command line debugging. In the R  
> community, the StatET eclipse plugin mimics a lot of code  
> development functionality of S+ workbench, but has poor support for  
> in-line execution of R sessions in eclipse and does not have  
> debugging capabilities. Supporting this project further, or  
> developing a GUI debugger independent of eclipse, are both  
> acceptable options. The debugger should allow breakpoints, variable  
> views etc.
>
> For both of the above, our interest is mostly on the Linux side, but  
> one should look into cross-platform solutions.
>
> Regards,
> Oleg
>
> Dr Oleg Sklyar
> Research Technologist
> AHL / Man Investments Ltd
> +44 (0)20 7144 3107
> osklyar at maninvestments.com
>
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org
>> [mailto:r-devel-bounces at r-project.org] On Behalf Of Friedrich Leisch
>> Sent: 18 February 2009 22:54
>> To: r-devel at r-project.org
>> Cc: Manuel.Eugster at stat.uni-muenchen.de
>> Subject: [Rd] Google Summer of Code 2009
>>
>>
>> Hi,
>>
>> in approximately one months time mentoring institutions can propose
>> projects for the Google Summer of Code 2009, see
>>
>>  http://code.google.com/soc/
>>
>> Last year the R Foundation succesfully participated with 4 projects,
>> see http://www.r-project.org/SoC08/ for details.  We want to
>> participate again this year. Our project proposals will be managed by
>> Manuel Eugster (email address in CC). Manuel is one of my PhD  
>> students
>> and mentored the Roxygen project last year. This mail is mainly
>> intended to make you aware of the program, Manuel will send a  
>> followup
>> email with more technical details in the next days.
>>
>> In this phase we are looking for potential mentors who can offer
>> interesting projects to students.  I don't think that we will get  
>> much
>> more than 4-6 projects, so don't be disappointed if you propose
>> something and don't get selected.
>>
>> There are two selection steps involved: (a) The R Foundation has to
>> compile an official "ideas list" of projects, for which students can
>> apply. Last year we had 8 of those. After that, we (b) get a certain
>> number of slots from Google (4 last year) and all prospective project
>> mentors can vote on which projects actually get funding.
>>
>> Currently we are looking for good ideas for phase (a). I give no
>> guarantees that all ideas will get on our official ideas list, what  
>> we
>> pick depends on the number of submissions and topics, respectively.  
>> We
>> want to make sure to have a broad range of themes, it is unlikely,
>> that we will, e.g., pick 10 database projects. Also keep in mind that
>> students have only three months time. This is not a research exercise
>> for the students, you should have a rough idea what needs to be done.
>>
>> Last year we had a majority of "infrastructure projects", and only  
>> few
>> with focus on statistical algorithms. We got a lot of applications  
>> for
>> the latter, so don't hesitate to formulate projects in that
>> direction. Important infrastructure may get precedence over
>> specialized algorithms, though, because the whole community can  
>> benfit
>> from those. But that will be a decision in phase (b), and we are not
>> there yet.
>>
>> Please don't send any ideas to me right now, wait for the above
>> mentioned email by Manuel on the technical details for idea
>> submission.
>>
>> Best,
>> Fritz
>>
>> -- 
>> --------------------------------------------------------------
>> ---------
>> Prof. Dr. Friedrich Leisch
>>
>> Institut f?r Statistik                          Tel: (+49 89)
>> 2180 3165
>> Ludwig-Maximilians-Universit?t                  Fax: (+49 89)
>> 2180 5308
>> Ludwigstra?e 33
>> D-80539 M?nchen
>> http://www.statistik.lmu.de/~leisch
>> --------------------------------------------------------------
>> ---------
>>   Journal Computational Statistics --- http://www.springer.com/180
>>          M?nchner R Kurse --- http://www.statistik.lmu.de/R
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> **********************************************************************
> Please consider the environment before printing this email or its  
> attachments.
> The contents of this email are for the named addressees ...{{dropped: 
> 19}}
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From osklyar at maninvestments.com  Thu Feb 19 15:47:23 2009
From: osklyar at maninvestments.com (Sklyar, Oleg (London))
Date: Thu, 19 Feb 2009 14:47:23 -0000
Subject: [Rd] Google Summer of Code 2009
In-Reply-To: <AF924562-B299-47E3-B3A6-83B668D7050F@r-project.org>
References: <18844.37238.384954.744812@ridcully.stat.uni-muenchen.de> 
	<1A68FCB28DE72F4BA3B967E6506CCE43047DF6A4@mildnpexmb01.maninvestments.ad.man.com>
	<AF924562-B299-47E3-B3A6-83B668D7050F@r-project.org>
Message-ID: <1A68FCB28DE72F4BA3B967E6506CCE43047DF6A8@mildnpexmb01.maninvestments.ad.man.com>

Simon,

I would not like to take it offline as I disagree with your points and think it is fair to let other users know why. To make it clear first, I am most interested in 2D, not 3D plots, and rgobbi is not a good enough solution, unfortunately.

1) I spent loads of time looking for good, if any at all, interactive graphics packages for R. There are hardly many, and apart from rgl there are no good ones as I see it. I do accept that this can be subjective, but I think many people will share my opinion.

2) With respect to iplots:

http://cran.r-project.org/web/packages/iplots/index.html states:
Version: 	1.1-3
Depends: 	R (? 1.5.0), methods, rJava (? 0.5-0)

http://www.rosuda.org/iplots/ states:
News:

    * 2007/08/07 Released iplots_1.1-1 on CRAN...

There might be version 3 available somewhere, but it is not obvious where and the above one is Java based. I have tried the above version about 4 months ago -- it was slow, unstable and did not have any support for time axis at all. If I find it, I will give it a try and will be able to post corresponding comments.

2) rggobi is not a solution for 2D graphics at all and this is what is missing in R. I would not mention rgobbi myself having had no look at it first. However, if somebody works on interactive 2D plots, there is no reason why this person should think of 3D as well to have all in one framework.

3) I have a prototype using gtkdatabox for very fast interactive plots in R using GTK, but it is limited by the capabilities of the gtkdatabox widget, not that of R or GTK as such.

I do think there is a need for an interactive graphics package for R.

Dr Oleg Sklyar
Research Technologist
AHL / Man Investments Ltd
+44 (0)20 7144 3107
osklyar at maninvestments.com 

> -----Original Message-----
> From: Simon Urbanek [mailto:simon.urbanek at r-project.org] 
> Sent: 19 February 2009 14:34
> To: Sklyar, Oleg (London)
> Cc: Friedrich Leisch; r-devel at r-project.org; 
> Manuel.Eugster at stat.uni-muenchen.de
> Subject: Re: [Rd] Google Summer of Code 2009
> 
> 
> On Feb 19, 2009, at 6:38 , Sklyar, Oleg (London) wrote:
> 
> > Two ideas:
> >
> > 1) A library for interactive plots in R
> >
> > R lacks functionality that would allow displaying of interactive  
> > plots with two distinct functionalities: zooming and panning. This  
> > functionality is extremely important for the analysis of 
> large, high  
> > frequency, data sets spanning over large ranges (in time as well).  
> > The functionality should acknowledge Axis methods in callbacks on  
> > rescale (so that it could be extended to user-specific classes for  
> > axis generation) and should have a native C interface to R 
> (i.e. no  
> > Java, but such cross platform widgets like GTK or QT or anything  
> > similar that does not require heavy-weight add-ons). GTK has been  
> > used successfully from within R in many applications (RGtk, 
> rgobby,  
> > EBImage etc) on both *nix and Windows, and thus could be a  
> > preferential option, it is also extremely easy to integrate 
> into R.  
> > The existing tools (e.g. iplots) are slow, unstable and 
> lack support  
> > for time/date plots (or actually any non-standard axes) and 
> they are  
> > all Java. We are looking into stanard xy-plots as well as 
> image and  
> > 3D plots. Obviously one can think of further interactivity, 
> but this  
> > would be too much for the Summer of Code project. A good prototype  
> > would already be a step forward.
> >
> 
> If primitive 3d scatterplot interactivity is all you want, go with  
> rggobi. It's GTK and has all this already and much more. However,  
> ggobi also shows why GTK is not a good choice for general 
> interactive  
> graphics toolkit - it [GTK] is slow and lacks reasonable graphics  
> support. OpenGL is IMHO a better way to go since IG don't really  
> leverage any of the widgets (you get them for free via R widgets  
> packages anyway) and OpenGL gives you excellent speed, alpha-support  
> and anti-aliasing etc.
> 
> As you can imagine I don't agree with most of your statements above  
> and I'm happy to discuss them in a separate thread. Just as an aside  
> iPlots 3.0 (announced for useR!/DSC) are no longer Java based 
> and have  
> a native C interface.
> 
> Cheers,
> S
> 
> 
> > 2) Cross platform GUI debugger, preferably further Eclipse  
> > integration (beyond StatET capabilities)
> >
> > Tibco has recently released the S+ workbench for eclipse 
> which has a  
> > reasonable support for non-command line debugging. In the R  
> > community, the StatET eclipse plugin mimics a lot of code  
> > development functionality of S+ workbench, but has poor 
> support for  
> > in-line execution of R sessions in eclipse and does not have  
> > debugging capabilities. Supporting this project further, or  
> > developing a GUI debugger independent of eclipse, are both  
> > acceptable options. The debugger should allow breakpoints, 
> variable  
> > views etc.
> >
> > For both of the above, our interest is mostly on the Linux 
> side, but  
> > one should look into cross-platform solutions.
> >
> > Regards,
> > Oleg
> >
> > Dr Oleg Sklyar
> > Research Technologist
> > AHL / Man Investments Ltd
> > +44 (0)20 7144 3107
> > osklyar at maninvestments.com
> >
> >> -----Original Message-----
> >> From: r-devel-bounces at r-project.org
> >> [mailto:r-devel-bounces at r-project.org] On Behalf Of 
> Friedrich Leisch
> >> Sent: 18 February 2009 22:54
> >> To: r-devel at r-project.org
> >> Cc: Manuel.Eugster at stat.uni-muenchen.de
> >> Subject: [Rd] Google Summer of Code 2009
> >>
> >>
> >> Hi,
> >>
> >> in approximately one months time mentoring institutions can propose
> >> projects for the Google Summer of Code 2009, see
> >>
> >>  http://code.google.com/soc/
> >>
> >> Last year the R Foundation succesfully participated with 4 
> projects,
> >> see http://www.r-project.org/SoC08/ for details.  We want to
> >> participate again this year. Our project proposals will be 
> managed by
> >> Manuel Eugster (email address in CC). Manuel is one of my PhD  
> >> students
> >> and mentored the Roxygen project last year. This mail is mainly
> >> intended to make you aware of the program, Manuel will send a  
> >> followup
> >> email with more technical details in the next days.
> >>
> >> In this phase we are looking for potential mentors who can offer
> >> interesting projects to students.  I don't think that we will get  
> >> much
> >> more than 4-6 projects, so don't be disappointed if you propose
> >> something and don't get selected.
> >>
> >> There are two selection steps involved: (a) The R Foundation has to
> >> compile an official "ideas list" of projects, for which 
> students can
> >> apply. Last year we had 8 of those. After that, we (b) get 
> a certain
> >> number of slots from Google (4 last year) and all 
> prospective project
> >> mentors can vote on which projects actually get funding.
> >>
> >> Currently we are looking for good ideas for phase (a). I give no
> >> guarantees that all ideas will get on our official ideas 
> list, what  
> >> we
> >> pick depends on the number of submissions and topics, 
> respectively.  
> >> We
> >> want to make sure to have a broad range of themes, it is unlikely,
> >> that we will, e.g., pick 10 database projects. Also keep 
> in mind that
> >> students have only three months time. This is not a 
> research exercise
> >> for the students, you should have a rough idea what needs 
> to be done.
> >>
> >> Last year we had a majority of "infrastructure projects", 
> and only  
> >> few
> >> with focus on statistical algorithms. We got a lot of 
> applications  
> >> for
> >> the latter, so don't hesitate to formulate projects in that
> >> direction. Important infrastructure may get precedence over
> >> specialized algorithms, though, because the whole community can  
> >> benfit
> >> from those. But that will be a decision in phase (b), and 
> we are not
> >> there yet.
> >>
> >> Please don't send any ideas to me right now, wait for the above
> >> mentioned email by Manuel on the technical details for idea
> >> submission.
> >>
> >> Best,
> >> Fritz
> >>
> >> -- 
> >> --------------------------------------------------------------
> >> ---------
> >> Prof. Dr. Friedrich Leisch
> >>
> >> Institut f?r Statistik                          Tel: (+49 89)
> >> 2180 3165
> >> Ludwig-Maximilians-Universit?t                  Fax: (+49 89)
> >> 2180 5308
> >> Ludwigstra?e 33
> >> D-80539 M?nchen
> >> http://www.statistik.lmu.de/~leisch
> >> --------------------------------------------------------------
> >> ---------
> >>   Journal Computational Statistics --- http://www.springer.com/180
> >>          M?nchner R Kurse --- http://www.statistik.lmu.de/R
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >
> > 
> **********************************************************************
> > Please consider the environment before printing this email or its  
> > attachments.
> > The contents of this email are for the named addressees 
> ...{{dropped: 
> > 19}}
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
> 
> 

**********************************************************************
Please consider the environment before printing this email or its attachments.
The contents of this email are for the named addressees only.  It contains information which may be confidential and privileged.  If you are not the intended recipient, please notify the sender immediately, destroy this email and any attachments and do not otherwise disclose or use them. Email transmission is not a secure method of communication and Man Investments cannot accept responsibility for the completeness or accuracy of this email or any attachments. Whilst Man Investments makes every effort to keep its network free from viruses, it does not accept responsibility for any computer virus which might be transferred by way of this email or any attachments. This email does not constitute a request, offer, recommendation or solicitation of any kind to buy, subscribe, sell or redeem any investment instruments or to perform other such transactions of any kind. Man Investments reserves the right to monitor, record and retain all electronic communications through its network to ensure the integrity of its systems, for record keeping and regulatory purposes. 
Visit us at: www.maninvestments.com 
TG0908
**********************************************************************


From landronimirc at gmail.com  Thu Feb 19 16:11:02 2009
From: landronimirc at gmail.com (Liviu Andronic)
Date: Thu, 19 Feb 2009 16:11:02 +0100
Subject: [Rd] Google Summer of Code 2009
In-Reply-To: <1A68FCB28DE72F4BA3B967E6506CCE43047DF6A8@mildnpexmb01.maninvestments.ad.man.com>
References: <18844.37238.384954.744812@ridcully.stat.uni-muenchen.de>
	<1A68FCB28DE72F4BA3B967E6506CCE43047DF6A4@mildnpexmb01.maninvestments.ad.man.com>
	<AF924562-B299-47E3-B3A6-83B668D7050F@r-project.org>
	<1A68FCB28DE72F4BA3B967E6506CCE43047DF6A8@mildnpexmb01.maninvestments.ad.man.com>
Message-ID: <68b1e2610902190711n3a99dc18ofa17c8df2ede6eec@mail.gmail.com>

On Thu, Feb 19, 2009 at 3:47 PM, Sklyar, Oleg (London)
<osklyar at maninvestments.com> wrote:
> I do think there is a need for an interactive graphics package for R.
>
There are also the GTK-based playwith, and latticist; unsure though
whether they fit your requirements.
Liviu



-- 
Do you know how to read?
http://www.alienetworks.com/srtest.cfm
Do you know how to write?
http://garbl.home.comcast.net/~garbl/stylemanual/e.htm#e-mail


From osklyar at maninvestments.com  Thu Feb 19 16:23:31 2009
From: osklyar at maninvestments.com (Sklyar, Oleg (London))
Date: Thu, 19 Feb 2009 15:23:31 -0000
Subject: [Rd] Google Summer of Code 2009
In-Reply-To: <68b1e2610902190711n3a99dc18ofa17c8df2ede6eec@mail.gmail.com>
References: <18844.37238.384954.744812@ridcully.stat.uni-muenchen.de> 
	<1A68FCB28DE72F4BA3B967E6506CCE43047DF6A4@mildnpexmb01.maninvestments.ad.man.com>
	<AF924562-B299-47E3-B3A6-83B668D7050F@r-project.org> 
	<1A68FCB28DE72F4BA3B967E6506CCE43047DF6A8@mildnpexmb01.maninvestments.ad.man.com>
	<68b1e2610902190711n3a99dc18ofa17c8df2ede6eec@mail.gmail.com>
Message-ID: <1A68FCB28DE72F4BA3B967E6506CCE43047DF6AB@mildnpexmb01.maninvestments.ad.man.com>

Thanks for pointing out. playwith looks quite interesting

Dr Oleg Sklyar
Research Technologist
AHL / Man Investments Ltd
+44 (0)20 7144 3107
osklyar at maninvestments.com 

> -----Original Message-----
> From: Liviu Andronic [mailto:landronimirc at gmail.com] 
> Sent: 19 February 2009 15:11
> To: Sklyar, Oleg (London)
> Cc: Simon Urbanek; Friedrich Leisch; 
> Manuel.Eugster at stat.uni-muenchen.de; r-devel at r-project.org
> Subject: Re: [Rd] Google Summer of Code 2009
> 
> On Thu, Feb 19, 2009 at 3:47 PM, Sklyar, Oleg (London)
> <osklyar at maninvestments.com> wrote:
> > I do think there is a need for an interactive graphics 
> package for R.
> >
> There are also the GTK-based playwith, and latticist; unsure though
> whether they fit your requirements.
> Liviu
> 
> 
> 
> -- 
> Do you know how to read?
> http://www.alienetworks.com/srtest.cfm
> Do you know how to write?
> http://garbl.home.comcast.net/~garbl/stylemanual/e.htm#e-mail
> 

**********************************************************************
Please consider the environment before printing this email or its attachments.
The contents of this email are for the named addressees ...{{dropped:19}}


From xieyihui at gmail.com  Thu Feb 19 17:20:04 2009
From: xieyihui at gmail.com (Yihui Xie)
Date: Fri, 20 Feb 2009 00:20:04 +0800
Subject: [Rd] Google Summer of Code 2009
In-Reply-To: <1A68FCB28DE72F4BA3B967E6506CCE43047DF6A4@mildnpexmb01.maninvestments.ad.man.com>
References: <18844.37238.384954.744812@ridcully.stat.uni-muenchen.de>
	<1A68FCB28DE72F4BA3B967E6506CCE43047DF6A4@mildnpexmb01.maninvestments.ad.man.com>
Message-ID: <89b6b8c90902190820p54ddb6a0w69003fdddfe73d4b@mail.gmail.com>

Well, for the first idea, isn't it easy enough to fulfill zooming or
panning using getGraphicsEvent() in the grDevices package? For example
(using keys +/-/Left/Right/Up/Down/* to zoom and pan):

##################################################################
# a demo for zooming and panning in R graphics
# by Yihui Xie <xieyihui at gmail.com> Feb 20, 2009
##################################################################
# a large number of points
plot(x <- rnorm(5000), y <- rnorm(5000), xlab = "x", ylab = "y")
xylim <- c(range(x), range(y))
zoom <- function(d, speed = 0.05) {
    rx <- speed * (xylim[2] - xylim[1])
    ry <- speed * (xylim[4] - xylim[3])
    # global assignment '<<-' here!
    xylim <<- xylim + d * c(rx, -rx, ry, -ry)
    plot(x, y, xlim = xylim[1:2], ylim = xylim[3:4])
    NULL
}
# Key `+`: zoom in; `-`: zoom out
# Left, Right, Up, Down: self-explaining
# `*`: reset
# Press other keys to quit
keybd <- function(key) {
    switch(key, `+` = zoom(1), `-` = zoom(-1), Left = zoom(c(-1,
        1, 0, 0)), Right = zoom(c(1, -1, 0, 0)), Up = zoom(c(0,
        0, 1, -1)), Down = zoom(c(0, 0, -1, 1)), `*` = plot(x,
        y), "Quit the program")
}
getGraphicsEvent(onKeybd = keybd)
##################################################################

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: +86-(0)10-82509086 Fax: +86-(0)10-82509086
Mobile: +86-15810805877
Homepage: http://www.yihui.name
School of Statistics, Room 1037, Mingde Main Building,
Renmin University of China, Beijing, 100872, China



On Thu, Feb 19, 2009 at 7:38 PM, Sklyar, Oleg (London)
<osklyar at maninvestments.com> wrote:
> Two ideas:
>
> 1) A library for interactive plots in R
>
> R lacks functionality that would allow displaying of interactive plots with two distinct functionalities: zooming and panning. This functionality is extremely important for the analysis of large, high frequency, data sets spanning over large ranges (in time as well). The functionality should acknowledge Axis methods in callbacks on rescale (so that it could be extended to user-specific classes for axis generation) and should have a native C interface to R (i.e. no Java, but such cross platform widgets like GTK or QT or anything similar that does not require heavy-weight add-ons). GTK has been used successfully from within R in many applications (RGtk, rgobby, EBImage etc) on both *nix and Windows, and thus could be a preferential option, it is also extremely easy to integrate into R. The existing tools (e.g. iplots) are slow, unstable and lack support for time/date plots (or actually any non-standard axes) and they are all Java. We are looking into stanard xy-plots as well as image and 3D plots. Obviously one can think of further interactivity, but this would be too much for the Summer of Code project. A good prototype would already be a step forward.
>
> 2) Cross platform GUI debugger, preferably further Eclipse integration (beyond StatET capabilities)
>
> Tibco has recently released the S+ workbench for eclipse which has a reasonable support for non-command line debugging. In the R community, the StatET eclipse plugin mimics a lot of code development functionality of S+ workbench, but has poor support for in-line execution of R sessions in eclipse and does not have debugging capabilities. Supporting this project further, or developing a GUI debugger independent of eclipse, are both acceptable options. The debugger should allow breakpoints, variable views etc.
>
> For both of the above, our interest is mostly on the Linux side, but one should look into cross-platform solutions.
>
> Regards,
> Oleg
>
> Dr Oleg Sklyar
> Research Technologist
> AHL / Man Investments Ltd
> +44 (0)20 7144 3107
> osklyar at maninvestments.com
>
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org
>> [mailto:r-devel-bounces at r-project.org] On Behalf Of Friedrich Leisch
>> Sent: 18 February 2009 22:54
>> To: r-devel at r-project.org
>> Cc: Manuel.Eugster at stat.uni-muenchen.de
>> Subject: [Rd] Google Summer of Code 2009
>>
>>
>> Hi,
>>
>> in approximately one months time mentoring institutions can propose
>> projects for the Google Summer of Code 2009, see
>>
>>   http://code.google.com/soc/
>>
>> Last year the R Foundation succesfully participated with 4 projects,
>> see http://www.r-project.org/SoC08/ for details.  We want to
>> participate again this year. Our project proposals will be managed by
>> Manuel Eugster (email address in CC). Manuel is one of my PhD students
>> and mentored the Roxygen project last year. This mail is mainly
>> intended to make you aware of the program, Manuel will send a followup
>> email with more technical details in the next days.
>>
>> In this phase we are looking for potential mentors who can offer
>> interesting projects to students.  I don't think that we will get much
>> more than 4-6 projects, so don't be disappointed if you propose
>> something and don't get selected.
>>
>> There are two selection steps involved: (a) The R Foundation has to
>> compile an official "ideas list" of projects, for which students can
>> apply. Last year we had 8 of those. After that, we (b) get a certain
>> number of slots from Google (4 last year) and all prospective project
>> mentors can vote on which projects actually get funding.
>>
>> Currently we are looking for good ideas for phase (a). I give no
>> guarantees that all ideas will get on our official ideas list, what we
>> pick depends on the number of submissions and topics, respectively. We
>> want to make sure to have a broad range of themes, it is unlikely,
>> that we will, e.g., pick 10 database projects. Also keep in mind that
>> students have only three months time. This is not a research exercise
>> for the students, you should have a rough idea what needs to be done.
>>
>> Last year we had a majority of "infrastructure projects", and only few
>> with focus on statistical algorithms. We got a lot of applications for
>> the latter, so don't hesitate to formulate projects in that
>> direction. Important infrastructure may get precedence over
>> specialized algorithms, though, because the whole community can benfit
>> from those. But that will be a decision in phase (b), and we are not
>> there yet.
>>
>> Please don't send any ideas to me right now, wait for the above
>> mentioned email by Manuel on the technical details for idea
>> submission.
>>
>> Best,
>> Fritz
>>
>> --
>> --------------------------------------------------------------
>> ---------
>> Prof. Dr. Friedrich Leisch
>>
>> Institut f?r Statistik                          Tel: (+49 89)
>> 2180 3165
>> Ludwig-Maximilians-Universit?t                  Fax: (+49 89)
>> 2180 5308
>> Ludwigstra?e 33
>> D-80539 M?nchen
>> http://www.statistik.lmu.de/~leisch
>> --------------------------------------------------------------
>> ---------
>>    Journal Computational Statistics --- http://www.springer.com/180
>>           M?nchner R Kurse --- http://www.statistik.lmu.de/R
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> **********************************************************************
> Please consider the environment before printing this email or its attachments.
> The contents of this email are for the named addressees ...{{dropped:19}}
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

From osklyar at maninvestments.com  Thu Feb 19 17:26:29 2009
From: osklyar at maninvestments.com (Sklyar, Oleg (London))
Date: Thu, 19 Feb 2009 16:26:29 -0000
Subject: [Rd] Google Summer of Code 2009
In-Reply-To: <89b6b8c90902190820p54ddb6a0w69003fdddfe73d4b@mail.gmail.com>
References: <18844.37238.384954.744812@ridcully.stat.uni-muenchen.de> 
	<1A68FCB28DE72F4BA3B967E6506CCE43047DF6A4@mildnpexmb01.maninvestments.ad.man.com>
	<89b6b8c90902190820p54ddb6a0w69003fdddfe73d4b@mail.gmail.com>
Message-ID: <1A68FCB28DE72F4BA3B967E6506CCE43047DF6AD@mildnpexmb01.maninvestments.ad.man.com>

Dear Yihui,

I am sure there are many possibilities available, but I am not looking for a hack and rather for a versatile high-quality solution. It solution should be fast, reliable and developed to a high standard. Moreover, on my X11 RHEL5 x86_64 I get the following:

> getGraphicsEvent(onKeybd = keybd)
Error in getGraphicsEvent(onKeybd = keybd) : 
  graphics device does not support graphics events

Furthermore, one could think of a library displaying multiple plots, for multivariate data, allowing simultaneous zoom into all of the plots.

Dr Oleg Sklyar
Research Technologist
AHL / Man Investments Ltd
+44 (0)20 7144 3107
osklyar at maninvestments.com 

> -----Original Message-----
> From: Yihui Xie [mailto:xieyihui at gmail.com] 
> Sent: 19 February 2009 16:20
> To: Sklyar, Oleg (London)
> Cc: Liviu Andronic; Friedrich Leisch; Simon Urbanek; 
> Manuel.Eugster at stat.uni-muenchen.de; r-devel at r-project.org
> Subject: Re: [Rd] Google Summer of Code 2009
> 
> Well, for the first idea, isn't it easy enough to fulfill zooming or
> panning using getGraphicsEvent() in the grDevices package? For example
> (using keys +/-/Left/Right/Up/Down/* to zoom and pan):
> 
> ##################################################################
> # a demo for zooming and panning in R graphics
> # by Yihui Xie <xieyihui at gmail.com> Feb 20, 2009
> ##################################################################
> # a large number of points
> plot(x <- rnorm(5000), y <- rnorm(5000), xlab = "x", ylab = "y")
> xylim <- c(range(x), range(y))
> zoom <- function(d, speed = 0.05) {
>     rx <- speed * (xylim[2] - xylim[1])
>     ry <- speed * (xylim[4] - xylim[3])
>     # global assignment '<<-' here!
>     xylim <<- xylim + d * c(rx, -rx, ry, -ry)
>     plot(x, y, xlim = xylim[1:2], ylim = xylim[3:4])
>     NULL
> }
> # Key `+`: zoom in; `-`: zoom out
> # Left, Right, Up, Down: self-explaining
> # `*`: reset
> # Press other keys to quit
> keybd <- function(key) {
>     switch(key, `+` = zoom(1), `-` = zoom(-1), Left = zoom(c(-1,
>         1, 0, 0)), Right = zoom(c(1, -1, 0, 0)), Up = zoom(c(0,
>         0, 1, -1)), Down = zoom(c(0, 0, -1, 1)), `*` = plot(x,
>         y), "Quit the program")
> }
> getGraphicsEvent(onKeybd = keybd)
> ##################################################################
> 
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Phone: +86-(0)10-82509086 Fax: +86-(0)10-82509086
> Mobile: +86-15810805877
> Homepage: http://www.yihui.name
> School of Statistics, Room 1037, Mingde Main Building,
> Renmin University of China, Beijing, 100872, China
> 
> 
> 
> On Thu, Feb 19, 2009 at 7:38 PM, Sklyar, Oleg (London)
> <osklyar at maninvestments.com> wrote:
> > Two ideas:
> >
> > 1) A library for interactive plots in R
> >
> > R lacks functionality that would allow displaying of 
> interactive plots with two distinct functionalities: zooming 
> and panning. This functionality is extremely important for 
> the analysis of large, high frequency, data sets spanning 
> over large ranges (in time as well). The functionality should 
> acknowledge Axis methods in callbacks on rescale (so that it 
> could be extended to user-specific classes for axis 
> generation) and should have a native C interface to R (i.e. 
> no Java, but such cross platform widgets like GTK or QT or 
> anything similar that does not require heavy-weight add-ons). 
> GTK has been used successfully from within R in many 
> applications (RGtk, rgobby, EBImage etc) on both *nix and 
> Windows, and thus could be a preferential option, it is also 
> extremely easy to integrate into R. The existing tools (e.g. 
> iplots) are slow, unstable and lack support for time/date 
> plots (or actually any non-standard axes) and they are all 
> Java. We are looking into stanard xy-plots as well as image 
> and 3D plots. Obviously one can think of further 
> interactivity, but this would be too much for the Summer of 
> Code project. A good prototype would already be a step forward.
> >
> > 2) Cross platform GUI debugger, preferably further Eclipse 
> integration (beyond StatET capabilities)
> >
> > Tibco has recently released the S+ workbench for eclipse 
> which has a reasonable support for non-command line 
> debugging. In the R community, the StatET eclipse plugin 
> mimics a lot of code development functionality of S+ 
> workbench, but has poor support for in-line execution of R 
> sessions in eclipse and does not have debugging capabilities. 
> Supporting this project further, or developing a GUI debugger 
> independent of eclipse, are both acceptable options. The 
> debugger should allow breakpoints, variable views etc.
> >
> > For both of the above, our interest is mostly on the Linux 
> side, but one should look into cross-platform solutions.
> >
> > Regards,
> > Oleg
> >
> > Dr Oleg Sklyar
> > Research Technologist
> > AHL / Man Investments Ltd
> > +44 (0)20 7144 3107
> > osklyar at maninvestments.com
> >
> >> -----Original Message-----
> >> From: r-devel-bounces at r-project.org
> >> [mailto:r-devel-bounces at r-project.org] On Behalf Of 
> Friedrich Leisch
> >> Sent: 18 February 2009 22:54
> >> To: r-devel at r-project.org
> >> Cc: Manuel.Eugster at stat.uni-muenchen.de
> >> Subject: [Rd] Google Summer of Code 2009
> >>
> >>
> >> Hi,
> >>
> >> in approximately one months time mentoring institutions can propose
> >> projects for the Google Summer of Code 2009, see
> >>
> >>   http://code.google.com/soc/
> >>
> >> Last year the R Foundation succesfully participated with 4 
> projects,
> >> see http://www.r-project.org/SoC08/ for details.  We want to
> >> participate again this year. Our project proposals will be 
> managed by
> >> Manuel Eugster (email address in CC). Manuel is one of my 
> PhD students
> >> and mentored the Roxygen project last year. This mail is mainly
> >> intended to make you aware of the program, Manuel will 
> send a followup
> >> email with more technical details in the next days.
> >>
> >> In this phase we are looking for potential mentors who can offer
> >> interesting projects to students.  I don't think that we 
> will get much
> >> more than 4-6 projects, so don't be disappointed if you propose
> >> something and don't get selected.
> >>
> >> There are two selection steps involved: (a) The R Foundation has to
> >> compile an official "ideas list" of projects, for which 
> students can
> >> apply. Last year we had 8 of those. After that, we (b) get 
> a certain
> >> number of slots from Google (4 last year) and all 
> prospective project
> >> mentors can vote on which projects actually get funding.
> >>
> >> Currently we are looking for good ideas for phase (a). I give no
> >> guarantees that all ideas will get on our official ideas 
> list, what we
> >> pick depends on the number of submissions and topics, 
> respectively. We
> >> want to make sure to have a broad range of themes, it is unlikely,
> >> that we will, e.g., pick 10 database projects. Also keep 
> in mind that
> >> students have only three months time. This is not a 
> research exercise
> >> for the students, you should have a rough idea what needs 
> to be done.
> >>
> >> Last year we had a majority of "infrastructure projects", 
> and only few
> >> with focus on statistical algorithms. We got a lot of 
> applications for
> >> the latter, so don't hesitate to formulate projects in that
> >> direction. Important infrastructure may get precedence over
> >> specialized algorithms, though, because the whole 
> community can benfit
> >> from those. But that will be a decision in phase (b), and 
> we are not
> >> there yet.
> >>
> >> Please don't send any ideas to me right now, wait for the above
> >> mentioned email by Manuel on the technical details for idea
> >> submission.
> >>
> >> Best,
> >> Fritz
> >>
> >> --
> >> --------------------------------------------------------------
> >> ---------
> >> Prof. Dr. Friedrich Leisch
> >>
> >> Institut f?r Statistik                          Tel: (+49 89)
> >> 2180 3165
> >> Ludwig-Maximilians-Universit?t                  Fax: (+49 89)
> >> 2180 5308
> >> Ludwigstra?e 33
> >> D-80539 M?nchen
> >> http://www.statistik.lmu.de/~leisch
> >> --------------------------------------------------------------
> >> ---------
> >>    Journal Computational Statistics --- http://www.springer.com/180
> >>           M?nchner R Kurse --- http://www.statistik.lmu.de/R
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >
> > 
> **********************************************************************
> > Please consider the environment before printing this email 
> or its attachments.
> > The contents of this email are for the named addressees 
> ...{{dropped:19}}
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 

**********************************************************************
Please consider the environment before printing this email or its attachments.
The contents of this email are for the named addressees ...{{dropped:19}}


From simon.urbanek at r-project.org  Thu Feb 19 17:46:47 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 19 Feb 2009 11:46:47 -0500
Subject: [Rd] Google Summer of Code 2009
In-Reply-To: <1A68FCB28DE72F4BA3B967E6506CCE43047DF6A8@mildnpexmb01.maninvestments.ad.man.com>
References: <18844.37238.384954.744812@ridcully.stat.uni-muenchen.de>
	<1A68FCB28DE72F4BA3B967E6506CCE43047DF6A4@mildnpexmb01.maninvestments.ad.man.com>
	<AF924562-B299-47E3-B3A6-83B668D7050F@r-project.org>
	<1A68FCB28DE72F4BA3B967E6506CCE43047DF6A8@mildnpexmb01.maninvestments.ad.man.com>
Message-ID: <DEC00D2A-55A3-465E-AEF4-7B9E29BAA44E@r-project.org>

Oleg,

On Feb 19, 2009, at 9:47 , Sklyar, Oleg (London) wrote:

> Simon,
>
> I would not like to take it offline as I disagree with your points  
> and think it is fair to let other users know why.

I didn't say offline, I said other thread, since this is not really  
about GSOC so I think this is getting OT ...


> To make it clear first, I am most interested in 2D, not 3D plots,  
> and rgobbi is not a good enough solution, unfortunately.
>
> 1) I spent loads of time looking for good, if any at all,  
> interactive graphics packages for R. There are hardly many, and  
> apart from rgl there are no good ones as I see it.

Maybe we are talking about entirely different things here - rgl is not  
interactive graphics at all - it is essentially a 3d renderer/viewer,  
not a data analytic tool [although it can be (ab)used as a very  
limited one for very specific tasks] - see literature on interactive  
graphics ...


> I do accept that this can be subjective, but I think many people  
> will share my opinion.
>
> 2) With respect to iplots:
>
> http://cran.r-project.org/web/packages/iplots/index.html states:
> Version: 	1.1-3
> Depends: 	R (? 1.5.0), methods, rJava (? 0.5-0)
>
> http://www.rosuda.org/iplots/ states:
> News:
>
>    * 2007/08/07 Released iplots_1.1-1 on CRAN...
>
> There might be version 3 available somewhere, but it is not obvious  
> where and the above one is Java based. I have tried the above  
> version about 4 months ago -- it was slow, unstable and did not have  
> any support for time axis at all. If I find it, I will give it a try  
> and will be able to post corresponding comments.
>

<free-software-author's rant>
At the very least it is polite to report any such issues (with  
details) to the authors. Comments like "X is bad, slow and crashes"   
are completely useless since they are unsubstantiated claims that  
don't help in creating better software -- neither are they helpful as  
a starting point for creating new software. If you want to be of any  
use to the community you should be more specific as of what you are  
talking about, what are the data examples etc. and talk to the authors.
</free-software-author's rant>
Given your comments I suspect you have very specific ideas of use, but  
we can only know when you tell us. In general, Java graphics are not  
slow, in fact they are often faster than conventional "native"  
implementations and are far more flexible.
[[split off to Java for graphics thread if you wish]]

As for iPlots, the development has shifted a while ago from the 'old'  
iPlots to the new ones which are in development stage (as I said they  
are announced for the useR! conference). My point was not about  
telling you to use a specific software, it was rather about making you  
aware of the fact that what you describe already exists (ggobi  
definitely is IG in GTK) and/or is worked on (iPlots 3.0) with  
possibly better approach.

I do fully support a GSOC proposal for interactive graphics software,  
it's just I think your formulation included some unnecessarily  
restricting details and personal opinions as well as misunderstandings  
as of what interactive graphics are. If we get that right, I think  
it's a great opportunity.
[[only this is really for the GSOC thread]]


> 2) rggobi is not a solution for 2D graphics at all and this is what  
> is missing in R. I would not mention rgobbi myself having had no  
> look at it first. However, if somebody works on interactive 2D  
> plots, there is no reason why this person should think of 3D as well  
> to have all in one framework.
>

I'll let ggobi authors respond to that, but ggobi is not about 3d at  
all - in fact 3d is just a very small part of ggobi. Again, I suspect  
it's not really interactive graphics that you have in mind and/or you  
are not familiar with it ...
[[split off to ggobi thread]]


> 3) I have a prototype using gtkdatabox for very fast interactive  
> plots in R using GTK, but it is limited by the capabilities of the  
> gtkdatabox widget, not that of R or GTK as such.
>

I don't know about your prototype, so I cannot really comment on that,  
but gtkdatabox is not IG, either.


> I do think there is a need for an interactive graphics package for R.
>

I do completely agree with that, but interactive means it satisfies  
basic requirements on IG such as the availability of selection,  
highlighting, queries, interactive change of parameters etc. This is  
not about 2d/3d clouds at all - that we have for decades already. Also  
this is not about "hacks" to glue on interactivity to existing  
graphics systems with a chewing gum. We need a versatile (possible  
extensible) set of interactive statistical plots -- at least that's  
what our experience shows.

Cheers,
Simon


>
>> -----Original Message-----
>> From: Simon Urbanek [mailto:simon.urbanek at r-project.org]
>> Sent: 19 February 2009 14:34
>> To: Sklyar, Oleg (London)
>> Cc: Friedrich Leisch; r-devel at r-project.org;
>> Manuel.Eugster at stat.uni-muenchen.de
>> Subject: Re: [Rd] Google Summer of Code 2009
>>
>>
>> On Feb 19, 2009, at 6:38 , Sklyar, Oleg (London) wrote:
>>
>>> Two ideas:
>>>
>>> 1) A library for interactive plots in R
>>>
>>> R lacks functionality that would allow displaying of interactive
>>> plots with two distinct functionalities: zooming and panning. This
>>> functionality is extremely important for the analysis of
>> large, high
>>> frequency, data sets spanning over large ranges (in time as well).
>>> The functionality should acknowledge Axis methods in callbacks on
>>> rescale (so that it could be extended to user-specific classes for
>>> axis generation) and should have a native C interface to R
>> (i.e. no
>>> Java, but such cross platform widgets like GTK or QT or anything
>>> similar that does not require heavy-weight add-ons). GTK has been
>>> used successfully from within R in many applications (RGtk,
>> rgobby,
>>> EBImage etc) on both *nix and Windows, and thus could be a
>>> preferential option, it is also extremely easy to integrate
>> into R.
>>> The existing tools (e.g. iplots) are slow, unstable and
>> lack support
>>> for time/date plots (or actually any non-standard axes) and
>> they are
>>> all Java. We are looking into stanard xy-plots as well as
>> image and
>>> 3D plots. Obviously one can think of further interactivity,
>> but this
>>> would be too much for the Summer of Code project. A good prototype
>>> would already be a step forward.
>>>
>>
>> If primitive 3d scatterplot interactivity is all you want, go with
>> rggobi. It's GTK and has all this already and much more. However,
>> ggobi also shows why GTK is not a good choice for general
>> interactive
>> graphics toolkit - it [GTK] is slow and lacks reasonable graphics
>> support. OpenGL is IMHO a better way to go since IG don't really
>> leverage any of the widgets (you get them for free via R widgets
>> packages anyway) and OpenGL gives you excellent speed, alpha-support
>> and anti-aliasing etc.
>>
>> As you can imagine I don't agree with most of your statements above
>> and I'm happy to discuss them in a separate thread. Just as an aside
>> iPlots 3.0 (announced for useR!/DSC) are no longer Java based
>> and have
>> a native C interface.
>>
>> Cheers,
>> S
>>
>>
>>> 2) Cross platform GUI debugger, preferably further Eclipse
>>> integration (beyond StatET capabilities)
>>>
>>> Tibco has recently released the S+ workbench for eclipse
>> which has a
>>> reasonable support for non-command line debugging. In the R
>>> community, the StatET eclipse plugin mimics a lot of code
>>> development functionality of S+ workbench, but has poor
>> support for
>>> in-line execution of R sessions in eclipse and does not have
>>> debugging capabilities. Supporting this project further, or
>>> developing a GUI debugger independent of eclipse, are both
>>> acceptable options. The debugger should allow breakpoints,
>> variable
>>> views etc.
>>>
>>> For both of the above, our interest is mostly on the Linux
>> side, but
>>> one should look into cross-platform solutions.
>>>
>>> Regards,
>>> Oleg
>>>
>>> Dr Oleg Sklyar
>>> Research Technologist
>>> AHL / Man Investments Ltd
>>> +44 (0)20 7144 3107
>>> osklyar at maninvestments.com
>>>
>>>> -----Original Message-----
>>>> From: r-devel-bounces at r-project.org
>>>> [mailto:r-devel-bounces at r-project.org] On Behalf Of
>> Friedrich Leisch
>>>> Sent: 18 February 2009 22:54
>>>> To: r-devel at r-project.org
>>>> Cc: Manuel.Eugster at stat.uni-muenchen.de
>>>> Subject: [Rd] Google Summer of Code 2009
>>>>
>>>>
>>>> Hi,
>>>>
>>>> in approximately one months time mentoring institutions can propose
>>>> projects for the Google Summer of Code 2009, see
>>>>
>>>> http://code.google.com/soc/
>>>>
>>>> Last year the R Foundation succesfully participated with 4
>> projects,
>>>> see http://www.r-project.org/SoC08/ for details.  We want to
>>>> participate again this year. Our project proposals will be
>> managed by
>>>> Manuel Eugster (email address in CC). Manuel is one of my PhD
>>>> students
>>>> and mentored the Roxygen project last year. This mail is mainly
>>>> intended to make you aware of the program, Manuel will send a
>>>> followup
>>>> email with more technical details in the next days.
>>>>
>>>> In this phase we are looking for potential mentors who can offer
>>>> interesting projects to students.  I don't think that we will get
>>>> much
>>>> more than 4-6 projects, so don't be disappointed if you propose
>>>> something and don't get selected.
>>>>
>>>> There are two selection steps involved: (a) The R Foundation has to
>>>> compile an official "ideas list" of projects, for which
>> students can
>>>> apply. Last year we had 8 of those. After that, we (b) get
>> a certain
>>>> number of slots from Google (4 last year) and all
>> prospective project
>>>> mentors can vote on which projects actually get funding.
>>>>
>>>> Currently we are looking for good ideas for phase (a). I give no
>>>> guarantees that all ideas will get on our official ideas
>> list, what
>>>> we
>>>> pick depends on the number of submissions and topics,
>> respectively.
>>>> We
>>>> want to make sure to have a broad range of themes, it is unlikely,
>>>> that we will, e.g., pick 10 database projects. Also keep
>> in mind that
>>>> students have only three months time. This is not a
>> research exercise
>>>> for the students, you should have a rough idea what needs
>> to be done.
>>>>
>>>> Last year we had a majority of "infrastructure projects",
>> and only
>>>> few
>>>> with focus on statistical algorithms. We got a lot of
>> applications
>>>> for
>>>> the latter, so don't hesitate to formulate projects in that
>>>> direction. Important infrastructure may get precedence over
>>>> specialized algorithms, though, because the whole community can
>>>> benfit
>>>> from those. But that will be a decision in phase (b), and
>> we are not
>>>> there yet.
>>>>
>>>> Please don't send any ideas to me right now, wait for the above
>>>> mentioned email by Manuel on the technical details for idea
>>>> submission.
>>>>
>>>> Best,
>>>> Fritz
>>>>
>>>> -- 
>>>> --------------------------------------------------------------
>>>> ---------
>>>> Prof. Dr. Friedrich Leisch
>>>>
>>>> Institut f?r Statistik                          Tel: (+49 89)
>>>> 2180 3165
>>>> Ludwig-Maximilians-Universit?t                  Fax: (+49 89)
>>>> 2180 5308
>>>> Ludwigstra?e 33
>>>> D-80539 M?nchen
>>>> http://www.statistik.lmu.de/~leisch
>>>> --------------------------------------------------------------
>>>> ---------
>>>>  Journal Computational Statistics --- http://www.springer.com/180
>>>>         M?nchner R Kurse --- http://www.statistik.lmu.de/R
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>>
>> **********************************************************************
>>> Please consider the environment before printing this email or its
>>> attachments.
>>> The contents of this email are for the named addressees
>> ...{{dropped:
>>> 19}}
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>
>>
>
> **********************************************************************
> Please consider the environment before printing this email or its  
> attachments.
> The contents of this email are for the named addressees only.  It  
> contains information which may be confidential and privileged.  If  
> you are not the intended recipient, please notify the sender  
> immediately, destroy this email and any attachments and do not  
> otherwise disclose or use them. Email transmission is not a secure  
> method of communication and Man Investments cannot accept  
> responsibility for the completeness or accuracy of this email or any  
> attachments. Whilst Man Investments makes every effort to keep its  
> network free from viruses, it does not accept responsibility for any  
> computer virus which might be transferred by way of this email or  
> any attachments. This email does not constitute a request, offer,  
> recommendation or solicitation of any kind to buy, subscribe, sell  
> or redeem any investment instruments or to perform other such  
> transactions of any kind. Man Investments reserves the right to  
> monitor, record and retain all electronic communications through its  
> network to ensure the integrity of its systems, for record keeping  
> and regulatory purposes.
> Visit us at: www.maninvestments.com
> TG0908
> **********************************************************************
>


From edd at debian.org  Thu Feb 19 17:52:19 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 19 Feb 2009 10:52:19 -0600
Subject: [Rd] Google Summer of Code 2009
In-Reply-To: <AF924562-B299-47E3-B3A6-83B668D7050F@r-project.org>
References: <18844.37238.384954.744812@ridcully.stat.uni-muenchen.de>
	<1A68FCB28DE72F4BA3B967E6506CCE43047DF6A4@mildnpexmb01.maninvestments.ad.man.com>
	<AF924562-B299-47E3-B3A6-83B668D7050F@r-project.org>
Message-ID: <18845.36419.535730.419023@ron.nulle.part>


[ Cool how nobody cared about Fritz' request not to post ideas yet :) ]

[ I broadly share Oleg's "wouldn't it be nice to have better plot devices"
  wish.  But I don't think it is a three-month summer target, and it's not 
  on the side of things Fritz / Manuel prefer as it is infrastructure rather
  than pure statistics ... Then again, maybe we should put that up to a wider
  discussion.  I like 'infrastructure' as R is a platform to me. ]

On 19 February 2009 at 09:33, Simon Urbanek wrote:
| If primitive 3d scatterplot interactivity is all you want, go with  
| rggobi. It's GTK and has all this already and much more. However,  
| ggobi also shows why GTK is not a good choice for general interactive  
| graphics toolkit - it [GTK] is slow and lacks reasonable graphics  
| support. OpenGL is IMHO a better way to go since IG don't really  
| leverage any of the widgets (you get them for free via R widgets  
| packages anyway) and OpenGL gives you excellent speed, alpha-support  
| and anti-aliasing etc.

I don't want to turn this into an all-out 'vi versus emacs' slugfest but:

-- GTk it not the only choice, and I have been very happy with Qt (and Qwt
   for a simple yet nice plot widget) on both Linux and Windows; I don't have
   access to a Mac so I didn't test there.

-- Qt supports OpenGL natively. The demos are very impressive (for OpenGL as
   well as the other widgets).

-- Deepayan has been working on Qt-based code to enhance R, as that appears
   to be 'unannounced' I won't post the SVN repo but allow me to state that 
   the code already ran all (or almost all) examples from the lattice book.

Dirk

-- 
Three out of two people have difficulties with fractions.


From osklyar at maninvestments.com  Thu Feb 19 18:27:45 2009
From: osklyar at maninvestments.com (Sklyar, Oleg (London))
Date: Thu, 19 Feb 2009 17:27:45 -0000
Subject: [Rd] interactive graphics for R: was Google Summer of Code 2009
In-Reply-To: <DEC00D2A-55A3-465E-AEF4-7B9E29BAA44E@r-project.org>
References: <18844.37238.384954.744812@ridcully.stat.uni-muenchen.de>
	<1A68FCB28DE72F4BA3B967E6506CCE43047DF6A4@mildnpexmb01.maninvestments.ad.man.com>
	<AF924562-B299-47E3-B3A6-83B668D7050F@r-project.org>
	<1A68FCB28DE72F4BA3B967E6506CCE43047DF6A8@mildnpexmb01.maninvestments.ad.man.com>
	<DEC00D2A-55A3-465E-AEF4-7B9E29BAA44E@r-project.org>
Message-ID: <1A68FCB28DE72F4BA3B967E6506CCE43047DF6AE@mildnpexmb01.maninvestments.ad.man.com>

Dear Simon, 

thanks for comments.

I better give a bit of a background first. We are analysing time series of financial data, often multivariate and with say 200K samples. It is quite a frequent situation that one needs to display multivariate time series of say 200K rows and 10 columns over the whole time range and be able to zoom in to look for effects of interest. The obvious choice of plots is a multiplot window with a shared x-axis, in this case time, zooming should be done simultaneously in all time series displayed.

I do understand this is a very specific example, but I am sure similar problems arise in other discilines: think of a genomic browser, sequencing or any other non-financial time series data etc. 

Essentially, no matter what the graphying or rendering technology used beneath (GTK, QT or anything else), my requirements, and yes they are in a way subjective, but on the other hand quite generic, would be a possibliity to produce multiplot windows (similar to say setting mfrow in par) with two simple features: zooming and panning simultaneously on all plots or independently. The support for Axis/pretty method callbacks is required because those are the methods that provide correct axis labeling independently on the class of the data. This is essentially the only thing that is not supported by the gtkdatabox widget as the rulers can only display numbers.

On the other issues of interactivity, I agree it is quite a broad term, but the functionality I describe above is pretty much basic.

As for Java objections: this is not because Java is slow on its own, but the interface is not native, requires a huge JVM for a fairly simple task and the interface is relatively slow and cumbersome. As soon as I see a package demonstrating good performance via rJava, I will be happy to say I was wrong. But essentially the same problem with 'playwith' package mentioned earlier -- it uses RGtk, gWidgets and therefore it is slow -- it is not that GTK is slow, but the complex binding from R via RGtk to GTK. If used natively, it is very fast.

> As for iPlots, the development has shifted a while ago from 
> the 'old'  
> iPlots to the new ones which are in development stage (as I 
> said they  
> are announced for the useR! conference). My point was not about  
> telling you to use a specific software, it was rather about 
> making you  
> aware of the fact that what you describe already exists (ggobi  
> definitely is IG in GTK) and/or is worked on (iPlots 3.0) with  
> possibly better approach.

Where can I find it to have a look? No matter that it is in development, if it fits the needs, I will only be happy to contribute what I can.

> 
> > 3) I have a prototype using gtkdatabox for very fast interactive  
> > plots in R using GTK, but it is limited by the capabilities of the  
> > gtkdatabox widget, not that of R or GTK as such.
> >
> 
> I don't know about your prototype, so I cannot really comment 
> on that,  
> but gtkdatabox is not IG, either.
> 

I cannot send you an example of an R package using gtkdatabox from the office, but I will create a small demo pack at home and will send it to you separately as to indicate what I am looking into. Possibly it is not IG, but this is essentially what I described above, although quite primitive (but it was a one-day project for me, not 3-months).

> 
> > I do think there is a need for an interactive graphics 
> package for R.
> >
> 
> I do completely agree with that, but interactive means it satisfies  
> basic requirements on IG such as the availability of selection,  
> highlighting, queries, interactive change of parameters etc. This is  
> not about 2d/3d clouds at all - that we have for decades 
> already. Also  
> this is not about "hacks" to glue on interactivity to existing  
> graphics systems with a chewing gum. We need a versatile (possible  
> extensible) set of interactive statistical plots -- at least that's  
> what our experience shows.

Agree completely.

> 
> Cheers,
> Simon
> 
> 
> >
> >> -----Original Message-----
> >> From: Simon Urbanek [mailto:simon.urbanek at r-project.org]
> >> Sent: 19 February 2009 14:34
> >> To: Sklyar, Oleg (London)
> >> Cc: Friedrich Leisch; r-devel at r-project.org;
> >> Manuel.Eugster at stat.uni-muenchen.de
> >> Subject: Re: [Rd] Google Summer of Code 2009
> >>
> >>
> >> On Feb 19, 2009, at 6:38 , Sklyar, Oleg (London) wrote:
> >>
> >>> Two ideas:
> >>>
> >>> 1) A library for interactive plots in R
> >>>
> >>> R lacks functionality that would allow displaying of interactive
> >>> plots with two distinct functionalities: zooming and panning. This
> >>> functionality is extremely important for the analysis of
> >> large, high
> >>> frequency, data sets spanning over large ranges (in time as well).
> >>> The functionality should acknowledge Axis methods in callbacks on
> >>> rescale (so that it could be extended to user-specific classes for
> >>> axis generation) and should have a native C interface to R
> >> (i.e. no
> >>> Java, but such cross platform widgets like GTK or QT or anything
> >>> similar that does not require heavy-weight add-ons). GTK has been
> >>> used successfully from within R in many applications (RGtk,
> >> rgobby,
> >>> EBImage etc) on both *nix and Windows, and thus could be a
> >>> preferential option, it is also extremely easy to integrate
> >> into R.
> >>> The existing tools (e.g. iplots) are slow, unstable and
> >> lack support
> >>> for time/date plots (or actually any non-standard axes) and
> >> they are
> >>> all Java. We are looking into stanard xy-plots as well as
> >> image and
> >>> 3D plots. Obviously one can think of further interactivity,
> >> but this
> >>> would be too much for the Summer of Code project. A good prototype
> >>> would already be a step forward.
> >>>
> >>
> >> If primitive 3d scatterplot interactivity is all you want, go with
> >> rggobi. It's GTK and has all this already and much more. However,
> >> ggobi also shows why GTK is not a good choice for general
> >> interactive
> >> graphics toolkit - it [GTK] is slow and lacks reasonable graphics
> >> support. OpenGL is IMHO a better way to go since IG don't really
> >> leverage any of the widgets (you get them for free via R widgets
> >> packages anyway) and OpenGL gives you excellent speed, 
> alpha-support
> >> and anti-aliasing etc.
> >>
> >> As you can imagine I don't agree with most of your statements above
> >> and I'm happy to discuss them in a separate thread. Just 
> as an aside
> >> iPlots 3.0 (announced for useR!/DSC) are no longer Java based
> >> and have
> >> a native C interface.
> >>
> >> Cheers,
> >> S
> >>
> >>
> >>> 2) Cross platform GUI debugger, preferably further Eclipse
> >>> integration (beyond StatET capabilities)
> >>>
> >>> Tibco has recently released the S+ workbench for eclipse
> >> which has a
> >>> reasonable support for non-command line debugging. In the R
> >>> community, the StatET eclipse plugin mimics a lot of code
> >>> development functionality of S+ workbench, but has poor
> >> support for
> >>> in-line execution of R sessions in eclipse and does not have
> >>> debugging capabilities. Supporting this project further, or
> >>> developing a GUI debugger independent of eclipse, are both
> >>> acceptable options. The debugger should allow breakpoints,
> >> variable
> >>> views etc.
> >>>
> >>> For both of the above, our interest is mostly on the Linux
> >> side, but
> >>> one should look into cross-platform solutions.
> >>>
> >>> Regards,
> >>> Oleg
> >>>
> >>> Dr Oleg Sklyar
> >>> Research Technologist
> >>> AHL / Man Investments Ltd
> >>> +44 (0)20 7144 3107
> >>> osklyar at maninvestments.com
> >>>
> >>>> -----Original Message-----
> >>>> From: r-devel-bounces at r-project.org
> >>>> [mailto:r-devel-bounces at r-project.org] On Behalf Of
> >> Friedrich Leisch
> >>>> Sent: 18 February 2009 22:54
> >>>> To: r-devel at r-project.org
> >>>> Cc: Manuel.Eugster at stat.uni-muenchen.de
> >>>> Subject: [Rd] Google Summer of Code 2009
> >>>>
> >>>>
> >>>> Hi,
> >>>>
> >>>> in approximately one months time mentoring institutions 
> can propose
> >>>> projects for the Google Summer of Code 2009, see
> >>>>
> >>>> http://code.google.com/soc/
> >>>>
> >>>> Last year the R Foundation succesfully participated with 4
> >> projects,
> >>>> see http://www.r-project.org/SoC08/ for details.  We want to
> >>>> participate again this year. Our project proposals will be
> >> managed by
> >>>> Manuel Eugster (email address in CC). Manuel is one of my PhD
> >>>> students
> >>>> and mentored the Roxygen project last year. This mail is mainly
> >>>> intended to make you aware of the program, Manuel will send a
> >>>> followup
> >>>> email with more technical details in the next days.
> >>>>
> >>>> In this phase we are looking for potential mentors who can offer
> >>>> interesting projects to students.  I don't think that we will get
> >>>> much
> >>>> more than 4-6 projects, so don't be disappointed if you propose
> >>>> something and don't get selected.
> >>>>
> >>>> There are two selection steps involved: (a) The R 
> Foundation has to
> >>>> compile an official "ideas list" of projects, for which
> >> students can
> >>>> apply. Last year we had 8 of those. After that, we (b) get
> >> a certain
> >>>> number of slots from Google (4 last year) and all
> >> prospective project
> >>>> mentors can vote on which projects actually get funding.
> >>>>
> >>>> Currently we are looking for good ideas for phase (a). I give no
> >>>> guarantees that all ideas will get on our official ideas
> >> list, what
> >>>> we
> >>>> pick depends on the number of submissions and topics,
> >> respectively.
> >>>> We
> >>>> want to make sure to have a broad range of themes, it is 
> unlikely,
> >>>> that we will, e.g., pick 10 database projects. Also keep
> >> in mind that
> >>>> students have only three months time. This is not a
> >> research exercise
> >>>> for the students, you should have a rough idea what needs
> >> to be done.
> >>>>
> >>>> Last year we had a majority of "infrastructure projects",
> >> and only
> >>>> few
> >>>> with focus on statistical algorithms. We got a lot of
> >> applications
> >>>> for
> >>>> the latter, so don't hesitate to formulate projects in that
> >>>> direction. Important infrastructure may get precedence over
> >>>> specialized algorithms, though, because the whole community can
> >>>> benfit
> >>>> from those. But that will be a decision in phase (b), and
> >> we are not
> >>>> there yet.
> >>>>
> >>>> Please don't send any ideas to me right now, wait for the above
> >>>> mentioned email by Manuel on the technical details for idea
> >>>> submission.
> >>>>
> >>>> Best,
> >>>> Fritz
> >>>>
> >>>> -- 
> >>>> --------------------------------------------------------------
> >>>> ---------
> >>>> Prof. Dr. Friedrich Leisch
> >>>>
> >>>> Institut f?r Statistik                          Tel: (+49 89)
> >>>> 2180 3165
> >>>> Ludwig-Maximilians-Universit?t                  Fax: (+49 89)
> >>>> 2180 5308
> >>>> Ludwigstra?e 33
> >>>> D-80539 M?nchen
> >>>> http://www.statistik.lmu.de/~leisch
> >>>> --------------------------------------------------------------
> >>>> ---------
> >>>>  Journal Computational Statistics --- http://www.springer.com/180
> >>>>         M?nchner R Kurse --- http://www.statistik.lmu.de/R
> >>>>
> >>>> ______________________________________________
> >>>> R-devel at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>>
> >>>
> >>>
> >> 
> **********************************************************************
> >>> Please consider the environment before printing this email or its
> >>> attachments.
> >>> The contents of this email are for the named addressees
> >> ...{{dropped:
> >>> 19}}
> >>>
> >>> ______________________________________________
> >>> R-devel at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>
> >>>
> >>
> >>
> >
> > 
> **********************************************************************
> > Please consider the environment before printing this email or its  
> > attachments.
> > The contents of this email are for the named addressees only.  It  
> > contains information which may be confidential and privileged.  If  
> > you are not the intended recipient, please notify the sender  
> > immediately, destroy this email and any attachments and do not  
> > otherwise disclose or use them. Email transmission is not a secure  
> > method of communication and Man Investments cannot accept  
> > responsibility for the completeness or accuracy of this 
> email or any  
> > attachments. Whilst Man Investments makes every effort to keep its  
> > network free from viruses, it does not accept 
> responsibility for any  
> > computer virus which might be transferred by way of this email or  
> > any attachments. This email does not constitute a request, offer,  
> > recommendation or solicitation of any kind to buy, subscribe, sell  
> > or redeem any investment instruments or to perform other such  
> > transactions of any kind. Man Investments reserves the right to  
> > monitor, record and retain all electronic communications 
> through its  
> > network to ensure the integrity of its systems, for record keeping  
> > and regulatory purposes.
> > Visit us at: www.maninvestments.com
> > TG0908
> > 
> **********************************************************************
> >
> 
> 


From simon.urbanek at r-project.org  Thu Feb 19 18:38:01 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 19 Feb 2009 12:38:01 -0500
Subject: [Rd] Interactive Graphics in R [Was: Google Summer of Code 2009]
In-Reply-To: <89b6b8c90902190820p54ddb6a0w69003fdddfe73d4b@mail.gmail.com>
References: <18844.37238.384954.744812@ridcully.stat.uni-muenchen.de>
	<1A68FCB28DE72F4BA3B967E6506CCE43047DF6A4@mildnpexmb01.maninvestments.ad.man.com>
	<89b6b8c90902190820p54ddb6a0w69003fdddfe73d4b@mail.gmail.com>
Message-ID: <7794A7C8-4261-4CF7-8FBA-9C6777961ED2@r-project.org>


On Feb 19, 2009, at 11:20 , Yihui Xie wrote:

> Well, for the first idea, isn't it easy enough to fulfill zooming or  
> panning using getGraphicsEvent() in the grDevices package?

Yes, but that's exactly what interactive graphics are NOT about (you  
just posted a good "chewing gum" reference from my previous e- 
mail ;)). You can put together ad-hoc hacks (and many have tried it in  
R before), but the result will not be general interactive graphics.  
What people don't realize is that a lot in IG software is about user  
interface and HCI. Having one-shot tools for very specific tasks  
doesn't really help to solve the big picture (although it may sort of  
solve your specific immediate problem). There are many good  
interactive software applications out there, but just linking them to  
R is just half of the story.

What we need is a more general framework for interactive graphics -  
this requires more than just a graphics subsystem - you have to depart  
from the concept of graphics objects and include "statistical objects"  
in the mix such that the underlying data/statistics etc. can be  
identified by linking back though the graphics. This is something we  
still lack in R --- but I hope we will get there sooner or later...

Cheers,
Simon



> For example
> (using keys +/-/Left/Right/Up/Down/* to zoom and pan):
>
> ##################################################################
> # a demo for zooming and panning in R graphics
> # by Yihui Xie <xieyihui at gmail.com> Feb 20, 2009
> ##################################################################
> # a large number of points
> plot(x <- rnorm(5000), y <- rnorm(5000), xlab = "x", ylab = "y")
> xylim <- c(range(x), range(y))
> zoom <- function(d, speed = 0.05) {
>    rx <- speed * (xylim[2] - xylim[1])
>    ry <- speed * (xylim[4] - xylim[3])
>    # global assignment '<<-' here!
>    xylim <<- xylim + d * c(rx, -rx, ry, -ry)
>    plot(x, y, xlim = xylim[1:2], ylim = xylim[3:4])
>    NULL
> }
> # Key `+`: zoom in; `-`: zoom out
> # Left, Right, Up, Down: self-explaining
> # `*`: reset
> # Press other keys to quit
> keybd <- function(key) {
>    switch(key, `+` = zoom(1), `-` = zoom(-1), Left = zoom(c(-1,
>        1, 0, 0)), Right = zoom(c(1, -1, 0, 0)), Up = zoom(c(0,
>        0, 1, -1)), Down = zoom(c(0, 0, -1, 1)), `*` = plot(x,
>        y), "Quit the program")
> }
> getGraphicsEvent(onKeybd = keybd)
> ##################################################################
>
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Phone: +86-(0)10-82509086 Fax: +86-(0)10-82509086
> Mobile: +86-15810805877
> Homepage: http://www.yihui.name
> School of Statistics, Room 1037, Mingde Main Building,
> Renmin University of China, Beijing, 100872, China
>
>
>
> On Thu, Feb 19, 2009 at 7:38 PM, Sklyar, Oleg (London)
> <osklyar at maninvestments.com> wrote:
>> Two ideas:
>>
>> 1) A library for interactive plots in R
>>
>> R lacks functionality that would allow displaying of interactive  
>> plots with two distinct functionalities: zooming and panning. This  
>> functionality is extremely important for the analysis of large,  
>> high frequency, data sets spanning over large ranges (in time as  
>> well). The functionality should acknowledge Axis methods in  
>> callbacks on rescale (so that it could be extended to user-specific  
>> classes for axis generation) and should have a native C interface  
>> to R (i.e. no Java, but such cross platform widgets like GTK or QT  
>> or anything similar that does not require heavy-weight add-ons).  
>> GTK has been used successfully from within R in many applications  
>> (RGtk, rgobby, EBImage etc) on both *nix and Windows, and thus  
>> could be a preferential option, it is also extremely easy to  
>> integrate into R. The existing tools (e.g. iplots) are slow,  
>> unstable and lack support for time/date plots (or actually any non- 
>> standard axes) and they are all Java. We are looking into stanard  
>> xy-plots as well as image and 3D plots. Obviously one can think of  
>> further interactivity, but this would be too much for the Summer of  
>> Code project. A good prototype would already be a step forward.
>>
>> 2) Cross platform GUI debugger, preferably further Eclipse  
>> integration (beyond StatET capabilities)
>>
>> Tibco has recently released the S+ workbench for eclipse which has  
>> a reasonable support for non-command line debugging. In the R  
>> community, the StatET eclipse plugin mimics a lot of code  
>> development functionality of S+ workbench, but has poor support for  
>> in-line execution of R sessions in eclipse and does not have  
>> debugging capabilities. Supporting this project further, or  
>> developing a GUI debugger independent of eclipse, are both  
>> acceptable options. The debugger should allow breakpoints, variable  
>> views etc.
>>
>> For both of the above, our interest is mostly on the Linux side,  
>> but one should look into cross-platform solutions.
>>
>> Regards,
>> Oleg
>>
>> Dr Oleg Sklyar
>> Research Technologist
>> AHL / Man Investments Ltd
>> +44 (0)20 7144 3107
>> osklyar at maninvestments.com
>>
>>> -----Original Message-----
>>> From: r-devel-bounces at r-project.org
>>> [mailto:r-devel-bounces at r-project.org] On Behalf Of Friedrich Leisch
>>> Sent: 18 February 2009 22:54
>>> To: r-devel at r-project.org
>>> Cc: Manuel.Eugster at stat.uni-muenchen.de
>>> Subject: [Rd] Google Summer of Code 2009
>>>
>>>
>>> Hi,
>>>
>>> in approximately one months time mentoring institutions can propose
>>> projects for the Google Summer of Code 2009, see
>>>
>>>  http://code.google.com/soc/
>>>
>>> Last year the R Foundation succesfully participated with 4 projects,
>>> see http://www.r-project.org/SoC08/ for details.  We want to
>>> participate again this year. Our project proposals will be managed  
>>> by
>>> Manuel Eugster (email address in CC). Manuel is one of my PhD  
>>> students
>>> and mentored the Roxygen project last year. This mail is mainly
>>> intended to make you aware of the program, Manuel will send a  
>>> followup
>>> email with more technical details in the next days.
>>>
>>> In this phase we are looking for potential mentors who can offer
>>> interesting projects to students.  I don't think that we will get  
>>> much
>>> more than 4-6 projects, so don't be disappointed if you propose
>>> something and don't get selected.
>>>
>>> There are two selection steps involved: (a) The R Foundation has to
>>> compile an official "ideas list" of projects, for which students can
>>> apply. Last year we had 8 of those. After that, we (b) get a certain
>>> number of slots from Google (4 last year) and all prospective  
>>> project
>>> mentors can vote on which projects actually get funding.
>>>
>>> Currently we are looking for good ideas for phase (a). I give no
>>> guarantees that all ideas will get on our official ideas list,  
>>> what we
>>> pick depends on the number of submissions and topics,  
>>> respectively. We
>>> want to make sure to have a broad range of themes, it is unlikely,
>>> that we will, e.g., pick 10 database projects. Also keep in mind  
>>> that
>>> students have only three months time. This is not a research  
>>> exercise
>>> for the students, you should have a rough idea what needs to be  
>>> done.
>>>
>>> Last year we had a majority of "infrastructure projects", and only  
>>> few
>>> with focus on statistical algorithms. We got a lot of applications  
>>> for
>>> the latter, so don't hesitate to formulate projects in that
>>> direction. Important infrastructure may get precedence over
>>> specialized algorithms, though, because the whole community can  
>>> benfit
>>> from those. But that will be a decision in phase (b), and we are not
>>> there yet.
>>>
>>> Please don't send any ideas to me right now, wait for the above
>>> mentioned email by Manuel on the technical details for idea
>>> submission.
>>>
>>> Best,
>>> Fritz
>>>
>>> --
>>> --------------------------------------------------------------
>>> ---------
>>> Prof. Dr. Friedrich Leisch
>>>
>>> Institut f?r Statistik                          Tel: (+49 89)
>>> 2180 3165
>>> Ludwig-Maximilians-Universit?t                  Fax: (+49 89)
>>> 2180 5308
>>> Ludwigstra?e 33
>>> D-80539 M?nchen
>>> http://www.statistik.lmu.de/~leisch
>>> --------------------------------------------------------------
>>> ---------
>>>   Journal Computational Statistics --- http://www.springer.com/180
>>>          M?nchner R Kurse --- http://www.statistik.lmu.de/R
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> **********************************************************************
>> Please consider the environment before printing this email or its  
>> attachments.
>> The contents of this email are for the named addressees ... 
>> {{dropped:19}}
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> <zoom.pan.r>


From ligges at statistik.tu-dortmund.de  Thu Feb 19 19:00:38 2009
From: ligges at statistik.tu-dortmund.de (ligges at statistik.tu-dortmund.de)
Date: Thu, 19 Feb 2009 19:00:38 +0100 (CET)
Subject: [Rd] heatmap without dendrogams (PR#13512)
Message-ID: <20090219180038.947CF2834155@mail.pubhealth.ku.dk>



j.j.goeman at lumc.nl wrote:
> Full_Name: Jelle Goeman
> Version: 2.8.1
> OS: Win XP
> Submission from: (NULL) (87.212.67.197)
> 
> 
> I get the following error message when I try to make a heatmap (package stats),
> without the associated dendrograms.
> 
> X <- matrix(rnorm(200),20,10)
> XX <- crossprod(X)
> heatmap(XX, Rowv= NA, revC=TRUE)
> Error in rev(ddr) : object "ddr" not found
> heatmap(XX, Rowv= NA, sym=TRUE)
> Error in heatmap(XX, Rowv = NA, sym = TRUE) : object "ddr" not found
>  
> According to the help file, this should work; indeed it does if I set revC or
> sym to FALSE. Seems like ddr should be initialized to something like 1:ncol(X)
> for the no-dendrogram case.
> 
> Kind regards,
> 
> Jelle
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



Since it looks like nobody answered so far, let me suggest a patch:



D:\RCompile\recent\R\src\library\stats\R>diff -u  dendrogram.R 
dendrogram.R-new
--- dendrogram.R        2009-02-19 18:54:18.832062400 +0100
+++ dendrogram.R-new    2009-02-19 18:52:29.612961900 +0100
@@ -699,7 +699,7 @@
      x <- t(x)
      if(revC) { # x columns reversed
      iy <- nr:1
-    ddr <- rev(ddr)
+    if(doRdend) ddr <- rev(ddr)
      x <- x[,iy]
      } else iy <- 1L:nr



Best wishes,
Uwe Ligges


From Manuel.A.Morales at williams.edu  Thu Feb 19 20:55:13 2009
From: Manuel.A.Morales at williams.edu (Manuel.A.Morales at williams.edu)
Date: Thu, 19 Feb 2009 20:55:13 +0100 (CET)
Subject: [Rd] bugfix for nls with port algorithm (PR#13540)
Message-ID: <20090219195514.17727282C765@mail.pubhealth.ku.dk>

Full_Name: Manuel A. Morales
Version: 2.8.1
OS: Linux
Submission from: (NULL) (137.165.199.246)


When fitting a model in nls using the algorithm port with constraints and the
shorthand parameter[factor] in the model, I get the following error message:

"Error in nls_port_fit(m, start, lower, upper, control, trace) : 
  (list) object cannot be coerced to type 'double'
In addition: Warning message:
In start < low :
  longer object length is not a multiple of shorter object length"

This error can be fixed by changing line 423 in nls.R from:

if(any(start < low || start > upp)) {

to:

if(any(unlist(start) < low || unlist(start) > upp)) {

The following code will generate the error:
x = runif(200)
b0 = c(rep(0,100),runif(100))
b1 = 1
fac <- as.factor(rep(c(0,1), each=100))
y = b0+b1*x+rnorm(200,sd=0.05)
nls(y~b0[fac]+b1*x, start=list(b0=c(1,1),b1=1), algorithm="port",
    upper=c(100,100,100))

Manuel


From wdunlap at tibco.com  Thu Feb 19 21:21:53 2009
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 19 Feb 2009 12:21:53 -0800
Subject: [Rd] bugfix for nls with port algorithm (PR#13540)
In-Reply-To: <20090219195514.17727282C765@mail.pubhealth.ku.dk>
References: <20090219195514.17727282C765@mail.pubhealth.ku.dk>
Message-ID: <77EB52C6DD32BA4D87471DCD70C8D700BE9776@NA-PA-VBE03.na.tibco.com>

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of 
> Manuel.A.Morales at williams.edu
> Sent: Thursday, February 19, 2009 11:55 AM
> To: r-devel at stat.math.ethz.ch
> Cc: R-bugs at r-project.org
> Subject: [Rd] bugfix for nls with port algorithm (PR#13540)
> 
> Full_Name: Manuel A. Morales
> Version: 2.8.1
> OS: Linux
> Submission from: (NULL) (137.165.199.246)
> 
> 
> When fitting a model in nls using the algorithm port with 
> constraints and the
> shorthand parameter[factor] in the model, I get the following 
> error message:
> 
> "Error in nls_port_fit(m, start, lower, upper, control, trace) : 
>   (list) object cannot be coerced to type 'double'
> In addition: Warning message:
> In start < low :
>   longer object length is not a multiple of shorter object length"
> 
> This error can be fixed by changing line 423 in nls.R from:
> 
> if(any(start < low || start > upp)) {
> 
> to:
> 
> if(any(unlist(start) < low || unlist(start) > upp)) {

The || should be changed to | or this should be converted
to 2 calls to any() joined by a ||.  (I prefer the latter.)
Otherwise you get no notice that your start value is out
of bounds in many cases.  E.g., with your data and fix the
following ought to complain:
  nls(y~b0[fac]+b1*x, start=list(b0=c(1,-1),b1=101), algorithm="port",
    upper=c(100,100,100), lower=c(0,0,0))
Changing that line to
  if (any(unlist(start) < low) || any(unlist(start) > upp)) {
makes it give a proper complaint:
  > nls(y~b0[fac]+b1*x, start=list(b0=c(1,-1),b1=101), algorithm="port",
  +   upper=c(100,100,100), lower=c(0,0,0))
  Error in nls(y ~ b0[fac] + b1 * x, start = list(b0 = c(1, -1), b1 =
101),  :
    Convergence failure: initial par violates constraints

Should '||' and '&&' warn if their arguments are not scalar (or perhaps
0-long also)?  The related 'if' does:
  > if(c(TRUE,FALSE)) cat("yes\n") else cat("no\n")
  yes
  Warning message:
  In if (c(TRUE, FALSE)) cat("yes\n") else cat("no\n") :
    the condition has length > 1 and only the first element will be used

Bill Dunlap
TIBCO Software Inc - Spotfire Division
wdunlap tibco.com 
> 
> The following code will generate the error:
> x = runif(200)
> b0 = c(rep(0,100),runif(100))
> b1 = 1
> fac <- as.factor(rep(c(0,1), each=100))
> y = b0+b1*x+rnorm(200,sd=0.05)
> nls(y~b0[fac]+b1*x, start=list(b0=c(1,1),b1=1), algorithm="port",
>     upper=c(100,100,100))
> 
> Manuel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From wdunlap at tibco.com  Thu Feb 19 21:25:30 2009
From: wdunlap at tibco.com (wdunlap at tibco.com)
Date: Thu, 19 Feb 2009 21:25:30 +0100 (CET)
Subject: [Rd] bugfix for nls with port algorithm (PR#13540)
Message-ID: <20090219202531.55922282C765@mail.pubhealth.ku.dk>

> -----Original Message-----
> From: r-devel-bounces at r-project.org=20
> [mailto:r-devel-bounces at r-project.org] On Behalf Of=20
> Manuel.A.Morales at williams.edu
> Sent: Thursday, February 19, 2009 11:55 AM
> To: r-devel at stat.math.ethz.ch
> Cc: R-bugs at r-project.org
> Subject: [Rd] bugfix for nls with port algorithm (PR#13540)
>=20
> Full_Name: Manuel A. Morales
> Version: 2.8.1
> OS: Linux
> Submission from: (NULL) (137.165.199.246)
>=20
>=20
> When fitting a model in nls using the algorithm port with=20
> constraints and the
> shorthand parameter[factor] in the model, I get the following=20
> error message:
>=20
> "Error in nls_port_fit(m, start, lower, upper, control, trace) :=20
>   (list) object cannot be coerced to type 'double'
> In addition: Warning message:
> In start < low :
>   longer object length is not a multiple of shorter object length"
>=20
> This error can be fixed by changing line 423 in nls.R from:
>=20
> if(any(start < low || start > upp)) {
>=20
> to:
>=20
> if(any(unlist(start) < low || unlist(start) > upp)) {

The || should be changed to | or this should be converted
to 2 calls to any() joined by a ||.  (I prefer the latter.)
Otherwise you get no notice that your start value is out
of bounds in many cases.  E.g., with your data and fix the
following ought to complain:
  nls(y~b0[fac]+b1*x, start=3Dlist(b0=3Dc(1,-1),b1=3D101), =
algorithm=3D"port",
    upper=3Dc(100,100,100), lower=3Dc(0,0,0))
Changing that line to
  if (any(unlist(start) < low) || any(unlist(start) > upp)) {
makes it give a proper complaint:
  > nls(y~b0[fac]+b1*x, start=3Dlist(b0=3Dc(1,-1),b1=3D101), =
algorithm=3D"port",
  +   upper=3Dc(100,100,100), lower=3Dc(0,0,0))
  Error in nls(y ~ b0[fac] + b1 * x, start =3D list(b0 =3D c(1, -1), b1 =
=3D
101),  :
    Convergence failure: initial par violates constraints

Should '||' and '&&' warn if their arguments are not scalar (or perhaps
0-long also)?  The related 'if' does:
  > if(c(TRUE,FALSE)) cat("yes\n") else cat("no\n")
  yes
  Warning message:
  In if (c(TRUE, FALSE)) cat("yes\n") else cat("no\n") :
    the condition has length > 1 and only the first element will be used

Bill Dunlap
TIBCO Software Inc - Spotfire Division
wdunlap tibco.com=20
>=20
> The following code will generate the error:
> x =3D runif(200)
> b0 =3D c(rep(0,100),runif(100))
> b1 =3D 1
> fac <- as.factor(rep(c(0,1), each=3D100))
> y =3D b0+b1*x+rnorm(200,sd=3D0.05)
> nls(y~b0[fac]+b1*x, start=3Dlist(b0=3Dc(1,1),b1=3D1), =
algorithm=3D"port",
>     upper=3Dc(100,100,100))
>=20
> Manuel
>=20
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>=20


From h.wickham at gmail.com  Thu Feb 19 22:36:10 2009
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 19 Feb 2009 15:36:10 -0600
Subject: [Rd] Interactive Graphics in R [Was: Google Summer of Code 2009]
In-Reply-To: <7794A7C8-4261-4CF7-8FBA-9C6777961ED2@r-project.org>
References: <18844.37238.384954.744812@ridcully.stat.uni-muenchen.de>
	<1A68FCB28DE72F4BA3B967E6506CCE43047DF6A4@mildnpexmb01.maninvestments.ad.man.com>
	<89b6b8c90902190820p54ddb6a0w69003fdddfe73d4b@mail.gmail.com>
	<7794A7C8-4261-4CF7-8FBA-9C6777961ED2@r-project.org>
Message-ID: <f8e6ff050902191336j4b3cc99ds97ddc08c6820d914@mail.gmail.com>

> What we need is a more general framework for interactive graphics - this
> requires more than just a graphics subsystem - you have to depart from the
> concept of graphics objects and include "statistical objects" in the mix
> such that the underlying data/statistics etc. can be identified by linking
> back though the graphics. This is something we still lack in R --- but I
> hope we will get there sooner or later...

Well apart from the interactivity, you have that with ggplot2.

Hadley

-- 
http://had.co.nz/


From osklyar at ebi.ac.uk  Thu Feb 19 23:16:47 2009
From: osklyar at ebi.ac.uk (Oleg Sklyar)
Date: Thu, 19 Feb 2009 22:16:47 +0000
Subject: [Rd] Interactive Graphics in R [Was: Google Summer of Code 2009]
In-Reply-To: <f8e6ff050902191336j4b3cc99ds97ddc08c6820d914@mail.gmail.com>
References: <18844.37238.384954.744812@ridcully.stat.uni-muenchen.de>	<1A68FCB28DE72F4BA3B967E6506CCE43047DF6A4@mildnpexmb01.maninvestments.ad.man.com>	<89b6b8c90902190820p54ddb6a0w69003fdddfe73d4b@mail.gmail.com>	<7794A7C8-4261-4CF7-8FBA-9C6777961ED2@r-project.org>
	<f8e6ff050902191336j4b3cc99ds97ddc08c6820d914@mail.gmail.com>
Message-ID: <499DDA4F.4060306@ebi.ac.uk>

Simon,

as promised I attach a simple package that utilises gtkdatabox. It is
Linux only, sorry for that: as it was hacked together in the last two
hours I did not have time for Windows stuff.

Under my Ubuntu I only had to install libgtkdatabox-dev from standard
repos (which would pull libgtk2-dev where necessary). The package relies
on gtkdatabox being found under the standard pkg-config path (i.e.
custom path installs would be difficult until compiler flags are
manually changed). This is for simplicity of ./configure

After installing, simply run example(databox) and use your mouse for
zooming-in with quite a standard left mouse click for drawing a
selection box (a click is required within a selection to zoom in); right
mouse click zooms out. I think it is CTRL-right or SHIFT-right to zoom
out to full scale.

This is a kind of functionality I would like to see. I do not mean the
gtkdatabox, but the idea.

With this one it is quite easy to add more plots to the window and as
the user has control over callbacks it is easy to do autorescale on
multiple plots if required. The limitation is the ruler of the
gtkdatabox itself (no time), no NA treatment, implementation via
increases pix buffer on zoom (rather than off-screen) etc.

I do not know if r-devel will allow a tar.gz source through, but if
anybody else is interested, please let me know and I will send the
source directly.

Best,
Oleg

-------------- next part --------------
A non-text attachment was scrubbed...
Name: databox_0.0.1.tar.gz
Type: application/x-gzip
Size: 24621 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090219/bc5611b8/attachment.gz>

From Friedrich.Leisch at stat.uni-muenchen.de  Thu Feb 19 23:36:58 2009
From: Friedrich.Leisch at stat.uni-muenchen.de (Friedrich Leisch)
Date: Fri, 20 Feb 2009 09:36:58 +1100
Subject: [Rd] vignette compilation times
In-Reply-To: <499D46C0.10404@cam.ac.uk>
References: <499D3E35.4050300@cam.ac.uk>
	<499D442A.20605@statistik.tu-dortmund.de>
	<499D46C0.10404@cam.ac.uk>
Message-ID: <18845.57098.447677.624190@ridcully.stat.uni-muenchen.de>

>>>>> On Thu, 19 Feb 2009 11:47:12 +0000,
>>>>> Robin Hankin (RH) wrote:

  > thanks for this clarification Uwe
  > Could I include the r_env_cache/  directory in the package
  > and then assume that the CRAN checks use

  > Sweave(.... , driver=weaver())

  > in which case the process takes about 10 seconds?

That makes no sense, because then there are no checks done at all: if
the code in your vignette does not change, weaver will not recompute
anything, hence the cached results are used. But in that case you
could as well include only the PDF (or the generated .tex if you like
that better) ...

The whole point of checking vignettes on CRAN is that we can track
errors due to changes in R or other packages. The second benefit is
that users can easily play around with your code and use itr as
examples ... how good an example with 10 hour runtime is depends of
course on the application.

Best,
Fritz


From ggrothendieck at gmail.com  Thu Feb 19 23:47:53 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 19 Feb 2009 17:47:53 -0500
Subject: [Rd] vignette compilation times
In-Reply-To: <18845.57098.447677.624190@ridcully.stat.uni-muenchen.de>
References: <499D3E35.4050300@cam.ac.uk>
	<499D442A.20605@statistik.tu-dortmund.de> <499D46C0.10404@cam.ac.uk>
	<18845.57098.447677.624190@ridcully.stat.uni-muenchen.de>
Message-ID: <971536df0902191447x62b7c879h348b08e629c85bf0@mail.gmail.com>

On Thu, Feb 19, 2009 at 5:36 PM, Friedrich Leisch
<Friedrich.Leisch at stat.uni-muenchen.de> wrote:
>>>>>> On Thu, 19 Feb 2009 11:47:12 +0000,
>>>>>> Robin Hankin (RH) wrote:
>
>  > thanks for this clarification Uwe
>  > Could I include the r_env_cache/  directory in the package
>  > and then assume that the CRAN checks use
>
>  > Sweave(.... , driver=weaver())
>
>  > in which case the process takes about 10 seconds?
>
> That makes no sense, because then there are no checks done at all: if
> the code in your vignette does not change, weaver will not recompute
> anything, hence the cached results are used. But in that case you
> could as well include only the PDF (or the generated .tex if you like
> that better) ...
>

Unless this has changed recently,I've tried including a PDF but it does not
appear in library(help = myPackage) nor on the CRAN site on
http://cran.r-project.org/package=myPackage
while Sweave'd PDFs do.


From simon.urbanek at r-project.org  Fri Feb 20 00:00:41 2009
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 19 Feb 2009 18:00:41 -0500
Subject: [Rd] Interactive Graphics in R [Was: Google Summer of Code 2009]
In-Reply-To: <f8e6ff050902191336j4b3cc99ds97ddc08c6820d914@mail.gmail.com>
References: <18844.37238.384954.744812@ridcully.stat.uni-muenchen.de>
	<1A68FCB28DE72F4BA3B967E6506CCE43047DF6A4@mildnpexmb01.maninvestments.ad.man.com>
	<89b6b8c90902190820p54ddb6a0w69003fdddfe73d4b@mail.gmail.com>
	<7794A7C8-4261-4CF7-8FBA-9C6777961ED2@r-project.org>
	<f8e6ff050902191336j4b3cc99ds97ddc08c6820d914@mail.gmail.com>
Message-ID: <34316703-7765-4C70-92EE-C77AAA391F67@r-project.org>


On Feb 19, 2009, at 16:36 , hadley wickham wrote:

>> What we need is a more general framework for interactive graphics -  
>> this
>> requires more than just a graphics subsystem - you have to depart  
>> from the
>> concept of graphics objects and include "statistical objects" in  
>> the mix
>> such that the underlying data/statistics etc. can be identified by  
>> linking
>> back though the graphics. This is something we still lack in R ---  
>> but I
>> hope we will get there sooner or later...
>
> Well apart from the interactivity, you have that with ggplot2.
>

Ehm - interactivity is the point here ...

Cheers,
S


From Friedrich.Leisch at stat.uni-muenchen.de  Fri Feb 20 02:06:46 2009
From: Friedrich.Leisch at stat.uni-muenchen.de (Friedrich Leisch)
Date: Fri, 20 Feb 2009 12:06:46 +1100
Subject: [Rd] Google Summer of Code 2009
In-Reply-To: <18845.36419.535730.419023@ron.nulle.part>
References: <18844.37238.384954.744812@ridcully.stat.uni-muenchen.de>
	<1A68FCB28DE72F4BA3B967E6506CCE43047DF6A4@mildnpexmb01.maninvestments.ad.man.com>
	<AF924562-B299-47E3-B3A6-83B668D7050F@r-project.org>
	<18845.36419.535730.419023@ron.nulle.part>
Message-ID: <18846.550.837563.639677@ridcully.stat.uni-muenchen.de>

>>>>> On Thu, 19 Feb 2009 10:52:19 -0600,
>>>>> Dirk Eddelbuettel (DE) wrote:

  > [ Cool how nobody cared about Fritz' request not to post ideas yet :) ]

Well, I kind of expected that ;-)

See also below.
  
  > [ I broadly share Oleg's "wouldn't it be nice to have better plot devices"
  >   wish.  But I don't think it is a three-month summer target,

Yes, that's exactly what came to my mind first: As usual, please do
read docs before you post ... in this case the format of SOC (I
included the link in my original email, googling for "summer of code"
will also take you there): a student is paid to code three months for
us, the 3 months inlcude writing documentation. The student will not
be an expert in R internals, and no magic wizard. The student should
familiarize himself with the project before the actual coding period,
but there is only so much you can do in limited time. I think you can
expect a similar amount of code as in a master/diploma thesis (but
NOT a dissertation).

If you had waited for Manuels email you would also have learned about
another VERY IMPORTANT POINT: The collection of ideas for summer of
code is not like writing a list of wishes to Santa Claus (or the
Christkind or whatever your local variation may be): we only need
ideas which YOU ARE WILLING TO MENTOR, i.e., you write the specs for
the project, communicate with students interested in the project,
select the best applicant and supervise the student during the coding
period. I am not sure everyone on this thread is aware about this (if
all of you were I apologize). If you propose an idea, you
simultaneously agree to volunteer a considerable amount of your own
time. But that time can really be worth the effort (otherwise we
wouldn't be doing it).




  > and it's not on the side of things Fritz / Manuel prefer as it is
  >   infrastructure rather than pure statistics ... Then again, maybe
  >   we should put that up to a wider discussion.  I like
  >   'infrastructure' as R is a platform to me. ]


I have no "preference" for pure statistics: last year we had 75%
infrastructure ideas and 25% statistics. I simply want to shift the
percentages to a more even ratio, because we had many application on
the statistical side and I don't want to waste talent. It is also our
USP in the summer of code.



Best,
Fritz


From Friedrich.Leisch at stat.uni-muenchen.de  Fri Feb 20 02:46:49 2009
From: Friedrich.Leisch at stat.uni-muenchen.de (Friedrich Leisch)
Date: Fri, 20 Feb 2009 12:46:49 +1100
Subject: [Rd] vignette compilation times
In-Reply-To: <971536df0902191447x62b7c879h348b08e629c85bf0@mail.gmail.com>
References: <499D3E35.4050300@cam.ac.uk>
	<499D442A.20605@statistik.tu-dortmund.de>
	<499D46C0.10404@cam.ac.uk>
	<18845.57098.447677.624190@ridcully.stat.uni-muenchen.de>
	<971536df0902191447x62b7c879h348b08e629c85bf0@mail.gmail.com>
Message-ID: <18846.2953.134949.620375@ridcully.stat.uni-muenchen.de>

>>>>> On Thu, 19 Feb 2009 17:47:53 -0500,
>>>>> Gabor Grothendieck (GG) wrote:

  > On Thu, Feb 19, 2009 at 5:36 PM, Friedrich Leisch
  > <Friedrich.Leisch at stat.uni-muenchen.de> wrote:
  >>>>>>> On Thu, 19 Feb 2009 11:47:12 +0000,
  >>>>>>> Robin Hankin (RH) wrote:
  >> 
  >> > thanks for this clarification Uwe
  >> > Could I include the r_env_cache/  directory in the package
  >> > and then assume that the CRAN checks use
  >> 
  >> > Sweave(.... , driver=weaver())
  >> 
  >> > in which case the process takes about 10 seconds?
  >> 
  >> That makes no sense, because then there are no checks done at all: if
  >> the code in your vignette does not change, weaver will not recompute
  >> anything, hence the cached results are used. But in that case you
  >> could as well include only the PDF (or the generated .tex if you like
  >> that better) ...
  >> 

  > Unless this has changed recently,I've tried including a PDF but it does not
  > appear in library(help = myPackage) nor on the CRAN site on
  > http://cran.r-project.org/package=myPackage
  > while Sweave'd PDFs do.

That was not the point of my email: If we process vignettes using the
weaver package during check, then in fact no checking is done at all
-> the whole purpose of vignettes is circumvented.

For vignettes you can be sure that all computations have been done
using the latest version of R and the package, i.e., the doc is up to
date. For a PDF this is not necessarily the case. There is a good
reason why we (more or less gently) try to push people writing docs as
Sweave files.  It is also unclear to me whether including a PDF
without sources in a GPLed package isn't a violation of the GPL (I
know people who very strongly think so). And source according to the
GPL means "the preferred form of the work for making modifications to
it." So for a PDF showing R output that would mean the text plus R
code plus data ... which boils down to XXXweave anyway.

But we really had this discussion several times ... perhaps somebody
volunteers to write an RFC for a more general system of including
manuals in R and volunteers to send patches implementing the mechanism
afterwards? Note that such a system needs to be compatible with the
package metadata system and work on all platforms.

Best,
Fritz


From edd at debian.org  Fri Feb 20 03:25:35 2009
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 19 Feb 2009 20:25:35 -0600
Subject: [Rd] Google Summer of Code 2009
In-Reply-To: <18846.550.837563.639677@ridcully.stat.uni-muenchen.de>
References: <18844.37238.384954.744812@ridcully.stat.uni-muenchen.de>
	<1A68FCB28DE72F4BA3B967E6506CCE43047DF6A4@mildnpexmb01.maninvestments.ad.man.com>
	<AF924562-B299-47E3-B3A6-83B668D7050F@r-project.org>
	<18845.36419.535730.419023@ron.nulle.part>
	<18846.550.837563.639677@ridcully.stat.uni-muenchen.de>
Message-ID: <18846.5279.808020.519032@ron.nulle.part>


On 20 February 2009 at 12:06, Friedrich Leisch wrote:
| >>>>> On Thu, 19 Feb 2009 10:52:19 -0600,
| >>>>> Dirk Eddelbuettel (DE) wrote:
| 
|   > [ Cool how nobody cared about Fritz' request not to post ideas yet :) ]
| 
| Well, I kind of expected that ;-)
| 
| See also below.
|   
|   > [ I broadly share Oleg's "wouldn't it be nice to have better plot devices"
|   >   wish.  But I don't think it is a three-month summer target,
| 
| Yes, that's exactly what came to my mind first: As usual, please do
| read docs before you post ... in this case the format of SOC (I
| included the link in my original email, googling for "summer of code"
| will also take you there): a student is paid to code three months for
| us, the 3 months inlcude writing documentation. The student will not
| be an expert in R internals, and no magic wizard. The student should
| familiarize himself with the project before the actual coding period,
| but there is only so much you can do in limited time. I think you can
| expect a similar amount of code as in a master/diploma thesis (but
| NOT a dissertation).
| 
| If you had waited for Manuels email you would also have learned about
| another VERY IMPORTANT POINT: The collection of ideas for summer of
| code is not like writing a list of wishes to Santa Claus (or the
| Christkind or whatever your local variation may be): we only need
| ideas which YOU ARE WILLING TO MENTOR, i.e., you write the specs for
| the project, communicate with students interested in the project,
| select the best applicant and supervise the student during the coding
| period. I am not sure everyone on this thread is aware about this (if
| all of you were I apologize). If you propose an idea, you
| simultaneously agree to volunteer a considerable amount of your own
| time. But that time can really be worth the effort (otherwise we
| wouldn't be doing it).

I am not sure if you're lecturing just to me or the audience at large; if it
just me allow me to remind you that I mentored last year and helped to bring
a project from proposal to inclusion onto CRAN and into user's hands.  In
fact, I mentored another one (on cran source to deb package automation) at
Debian as well.  So yes, I am in fact fully aware of most of these points.

I would at this point also like to correct something you said in the earlier
mail where you said that may get "four to six slots". I am doubtful about
that. O verall number of GSoC slots are _down_ as per Leslie. We have no
priors on whether more or less organisations are admitted or not. If I were a
betting man, I'd say three to four slots.

So let's make them count.

Dirk

-- 
Three out of two people have difficulties with fractions.


From Friedrich.Leisch at stat.uni-muenchen.de  Fri Feb 20 04:08:02 2009
From: Friedrich.Leisch at stat.uni-muenchen.de (Friedrich Leisch)
Date: Fri, 20 Feb 2009 14:08:02 +1100
Subject: [Rd] Google Summer of Code 2009
In-Reply-To: <18846.5279.808020.519032@ron.nulle.part>
References: <18844.37238.384954.744812@ridcully.stat.uni-muenchen.de>
	<1A68FCB28DE72F4BA3B967E6506CCE43047DF6A4@mildnpexmb01.maninvestments.ad.man.com>
	<AF924562-B299-47E3-B3A6-83B668D7050F@r-project.org>
	<18845.36419.535730.419023@ron.nulle.part>
	<18846.550.837563.639677@ridcully.stat.uni-muenchen.de>
	<18846.5279.808020.519032@ron.nulle.part>
Message-ID: <18846.7826.25597.28678@ridcully.stat.uni-muenchen.de>

>>>>> On Thu, 19 Feb 2009 20:25:35 -0600,
>>>>> Dirk Eddelbuettel (DE) wrote:

  > On 20 February 2009 at 12:06, Friedrich Leisch wrote:
  > | >>>>> On Thu, 19 Feb 2009 10:52:19 -0600,
  > | >>>>> Dirk Eddelbuettel (DE) wrote:
  > | 
  > |   > [ Cool how nobody cared about Fritz' request not to post ideas yet :) ]
  > | 
  > | Well, I kind of expected that ;-)
  > | 
  > | See also below.
  > |   
  > |   > [ I broadly share Oleg's "wouldn't it be nice to have better plot devices"
  > |   >   wish.  But I don't think it is a three-month summer target,
  > | 
  > | Yes, that's exactly what came to my mind first: As usual, please do
  > | read docs before you post ... in this case the format of SOC (I
  > | included the link in my original email, googling for "summer of code"
  > | will also take you there): a student is paid to code three months for
  > | us, the 3 months inlcude writing documentation. The student will not
  > | be an expert in R internals, and no magic wizard. The student should
  > | familiarize himself with the project before the actual coding period,
  > | but there is only so much you can do in limited time. I think you can
  > | expect a similar amount of code as in a master/diploma thesis (but
  > | NOT a dissertation).
  > | 
  > | If you had waited for Manuels email you would also have learned about
  > | another VERY IMPORTANT POINT: The collection of ideas for summer of
  > | code is not like writing a list of wishes to Santa Claus (or the
  > | Christkind or whatever your local variation may be): we only need
  > | ideas which YOU ARE WILLING TO MENTOR, i.e., you write the specs for
  > | the project, communicate with students interested in the project,
  > | select the best applicant and supervise the student during the coding
  > | period. I am not sure everyone on this thread is aware about this (if
  > | all of you were I apologize). If you propose an idea, you
  > | simultaneously agree to volunteer a considerable amount of your own
  > | time. But that time can really be worth the effort (otherwise we
  > | wouldn't be doing it).

  > I am not sure if you're lecturing just to me or the audience at
  > large;

Of course to the audfiance at large, I know that you know the rules of
the game. That I answered your email, in the thread was more or less
chance. Sorry if I gave a wrong impression (wouldn't have possibly
thought that you could feel addressed personally).

My sincere apologies!!!



  > I would at this point also like to correct something you said in
  > the earlier mail where you said that may get "four to six
  > slots". I am doubtful about that. O verall number of GSoC slots
  > are _down_ as per Leslie. We have no priors on whether more or
  > less organisations are admitted or not. If I were a betting man,
  > I'd say three to four slots.

OK, didn't know that number of slots is down (should probably read the
docs better myself). I was assuming that the number of slots is approx
the same, and hoping for more slots in the second year (because I know
that all organizations get fewer in their first year).

Best,
Fritz


From ripley at stats.ox.ac.uk  Fri Feb 20 05:01:07 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 20 Feb 2009 04:01:07 +0000 (GMT)
Subject: [Rd] [R] How to unload a dll loaded via library.dynam()?
In-Reply-To: <d70c15d40902191643v4cba511ds794869eaf51d20d2@mail.gmail.com>
References: <30070-82496@sneakemail.com> <499DFA13.4060600@stats.uwo.ca>
	<d70c15d40902191643v4cba511ds794869eaf51d20d2@mail.gmail.com>
Message-ID: <alpine.LFD.2.00.0902200338010.10231@gannet.stats.ox.ac.uk>

[Moved to R-devel as suggested.]

library.dynam.unload() does work if the OS is cooperative.  And if you 
have your package set up correctly and unload the namespace (and not 
just detach the package if there is a namespace) then the shared 
object/DLL will be unloaded. There are examples in several base R 
packages (grDevices, grid, methods, splines, stats, tools).

However, there are several instances on Windows (tcltk is one) where 
reloading the package DLL does not work, and this seems to be because 
dependent DLLs are already loaded and do not run their initializations 
correctly.  I've not seen problems on Linux.  On Solaris reloading a 
different shared object of the same name into a process used not to 
work (you got the first version under that name): I've not checked 
recently.

On Fri, 20 Feb 2009, G?bor Cs?rdi wrote:

> Hmmm, I think restarting R is not a very good solution. It is rather
> ugly in the first place. But perhaps even more importantly, it can be
> rather inconvenient if one has a large data set in the memory and
> needs to save/load it just to reload a package that was updated in the
> meanwhile.
>
> This happens to me quite often with 20-40Gb of data, so I would really
> love to have a solution for proper detach/unload.

Why not use the one already provided?

>
> Best,
> Gabor
>
> On Fri, Feb 20, 2009 at 1:32 AM, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>> On 19/02/2009 6:19 PM, Alex F. Bokov wrote:
>>>
>>> Hello. To save the hassle of quitting and restarting R every time I
>>> rebuild the package I'm working on (for the purposes of this question called
>>> "roots") I would like to write a script cleanly remove the package from my R
>>> session and then load it again. Of course detach("package:roots") works for
>>> the native R objects in the package. However, the compiled C library remains
>>> loaded. Using library.dynam.unload as documented results in:
>>>
>>> Error in library.dynam.unload("roots.so",
>>> "~/R/x86_64-pc-linux-gnu-library/2.8/roots/libs/") :
>>>  shared library 'roots' was not loaded
>>>
>>> I also tried the above command with the file extension omitted and the
>>> last one and two levels of the directory path omitted. In both cases I still
>>> get the "not loaded" error. I've also Googled the list archives and while
>>> there were several questions like mine, none of them were answered by the
>>> list. Am I to believe that this is something hardly anybody does? Does this
>>> mean everybody sits around waiting for R to start up everytime they make a
>>> minor change to the C source?
>>>
>>> If there is a tutorial for doing this, I'd much appreciate the link.
>>
>>
>> This is more of an R-devel question than R-help, so if this doesn't answer
>> your question, please follow up there.
>>
>> On Windows, the following sort of works:
>>
>>> library(rgl)
>>> .dynLibs()
>>                                           Filename Dynamic.Lookup
>> 1     F:/R/R-2.8.1/library/methods/libs/methods.dll          FALSE
>> 2 F:/R/R-2.8.1/library/grDevices/libs/grDevices.dll          FALSE
>> 3         F:/R/R-2.8.1/library/stats/libs/stats.dll          FALSE
>> 4             F:/R/R-2.8.1/library/rgl/libs/rgl.dll           TRUE
>>
>>> library.dynam.unload("rgl", "F:/R/R-2.8.1/library/rgl")
>>
>> I say "sort of", in that I get no error messages and the dll is no longer
>> locked in use as it normally would be in Windows, but reloading the package
>> doesn't function properly. It's possible some combination of detach() and
>> unloadNamespace() would get a clean unload, but really, I normally just quit
>> R and restart.  It's pretty quick to start up, compared to the recompile
>> time for the package.
>>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> -- 
> Gabor Csardi <Gabor.Csardi at unil.ch>     UNIL DGM
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From xieyihui at gmail.com  Fri Feb 20 07:51:48 2009
From: xieyihui at gmail.com (Yihui Xie)
Date: Fri, 20 Feb 2009 14:51:48 +0800
Subject: [Rd] Interactive Graphics in R [Was: Google Summer of Code 2009]
In-Reply-To: <7794A7C8-4261-4CF7-8FBA-9C6777961ED2@r-project.org>
References: <18844.37238.384954.744812@ridcully.stat.uni-muenchen.de>
	<1A68FCB28DE72F4BA3B967E6506CCE43047DF6A4@mildnpexmb01.maninvestments.ad.man.com>
	<89b6b8c90902190820p54ddb6a0w69003fdddfe73d4b@mail.gmail.com>
	<7794A7C8-4261-4CF7-8FBA-9C6777961ED2@r-project.org>
Message-ID: <89b6b8c90902192251r7dac493eub477744da15dab3a@mail.gmail.com>

Hi Simon,

Yes I agree with you on the definition of IG (selection, data query,
...), but I only meant to respond to Oleg's "R lacks functionality
that would allow displaying of interactive plots with two distinct
functionalities: zooming and panning." I thought that was just a
problem to adjust the x and y limits, so I posted the "chewing gum"
:-)

For Oleg: sorry I forgot to mention that currently getGraphicsEvent()
only works for Windows screen display.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: +86-(0)10-82509086 Fax: +86-(0)10-82509086
Mobile: +86-15810805877
Homepage: http://www.yihui.name
School of Statistics, Room 1037, Mingde Main Building,
Renmin University of China, Beijing, 100872, China



On Fri, Feb 20, 2009 at 1:38 AM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
>
> On Feb 19, 2009, at 11:20 , Yihui Xie wrote:
>
>> Well, for the first idea, isn't it easy enough to fulfill zooming or
>> panning using getGraphicsEvent() in the grDevices package?
>
> Yes, but that's exactly what interactive graphics are NOT about (you just
> posted a good "chewing gum" reference from my previous e-mail ;)). You can
> put together ad-hoc hacks (and many have tried it in R before), but the
> result will not be general interactive graphics. What people don't realize
> is that a lot in IG software is about user interface and HCI. Having
> one-shot tools for very specific tasks doesn't really help to solve the big
> picture (although it may sort of solve your specific immediate problem).
> There are many good interactive software applications out there, but just
> linking them to R is just half of the story.
>
> What we need is a more general framework for interactive graphics - this
> requires more than just a graphics subsystem - you have to depart from the
> concept of graphics objects and include "statistical objects" in the mix
> such that the underlying data/statistics etc. can be identified by linking
> back though the graphics. This is something we still lack in R --- but I
> hope we will get there sooner or later...
>
> Cheers,
> Simon
>


From deepayan.sarkar at gmail.com  Fri Feb 20 09:08:36 2009
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Fri, 20 Feb 2009 00:08:36 -0800
Subject: [Rd] Google Summer of Code 2009
In-Reply-To: <18845.36419.535730.419023@ron.nulle.part>
References: <18844.37238.384954.744812@ridcully.stat.uni-muenchen.de>
	<1A68FCB28DE72F4BA3B967E6506CCE43047DF6A4@mildnpexmb01.maninvestments.ad.man.com>
	<AF924562-B299-47E3-B3A6-83B668D7050F@r-project.org>
	<18845.36419.535730.419023@ron.nulle.part>
Message-ID: <eb555e660902200008j194248e4m38a002bcb5dfe54a@mail.gmail.com>

On 2/19/09, Dirk Eddelbuettel <edd at debian.org> wrote:

[...]

> On 19 February 2009 at 09:33, Simon Urbanek wrote:
> | If primitive 3d scatterplot interactivity is all you want, go with
> | rggobi. It's GTK and has all this already and much more. However,
> | ggobi also shows why GTK is not a good choice for general interactive
> | graphics toolkit - it [GTK] is slow and lacks reasonable graphics
> | support. OpenGL is IMHO a better way to go since IG don't really
> | leverage any of the widgets (you get them for free via R widgets
> | packages anyway) and OpenGL gives you excellent speed, alpha-support
> | and anti-aliasing etc.
>
> I don't want to turn this into an all-out 'vi versus emacs' slugfest but:
>
> -- GTk it not the only choice, and I have been very happy with Qt (and Qwt
>    for a simple yet nice plot widget) on both Linux and Windows; I don't
> have
>    access to a Mac so I didn't test there.
>
> -- Qt supports OpenGL natively. The demos are very impressive (for OpenGL as
>    well as the other widgets).
>
> -- Deepayan has been working on Qt-based code to enhance R, as that appears
>    to be 'unannounced' I won't post the SVN repo but allow me to state that
>    the code already ran all (or almost all) examples from the lattice book.

Just to expand on that: yes, I have been working on a Qt-based
infrastructure, and Michael Lawrence is also involved now, and has
been working on refining and optimizing it for more general uses. The
details are still in flux, but we hope to have something to show at
DSC.

Which is not to say that other alternatives wouldn't be good, of course.

-Deepayan


From tlumley at u.washington.edu  Fri Feb 20 09:14:19 2009
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 20 Feb 2009 00:14:19 -0800 (PST)
Subject: [Rd] Google Summer of Code 2009
In-Reply-To: <18846.550.837563.639677@ridcully.stat.uni-muenchen.de>
Message-ID: <Pine.LNX.4.43.0902200014190.27978@hymn13.u.washington.edu>

On Fri, 20 Feb 2009, Friedrich Leisch wrote:

>>>>>> On Thu, 19 Feb 2009 10:52:19 -0600,
>>>>>> Dirk Eddelbuettel (DE) wrote:
>
>  > [ Cool how nobody cared about Fritz' request not to post ideas yet :) ]
>
> Well, I kind of expected that ;-)
>
> See also below.
>
>  > [ I broadly share Oleg's "wouldn't it be nice to have better plot devices"
>  >   wish.  But I don't think it is a three-month summer target,
>
> Yes, that's exactly what came to my mind first

The principle applies to some extent to all "wouldn't it be nice if R did..." comments.  If something would obviously be a widely appreciated addition to R (such as good interactive graphics), there is probably some good reason that it is hard.  It's relatively unlikely that no-one had thought of it or had realized it would be worth having.

For ideas like that we are likely to need some way to make the implementation easier (money, code, new approaches to the programming,...).


         -thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From tlumley at u.washington.edu  Fri Feb 20 10:32:15 2009
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 20 Feb 2009 01:32:15 -0800 (PST)
Subject: [Rd] plot.lm: "Cook's distance" label can overplot point labels
In-Reply-To: <002501c99291$91e161f0$b5a425d0$@ca>
Message-ID: <Pine.LNX.4.43.0902200132150.19096@hymn12.u.washington.edu>

On Thu, 19 Feb 2009, John Fox wrote:

> Dear John and Brian,
>
> My point about colour-blindness was partly tongue-in-cheek, but I think that
> it's a bad choice to have the second and third colours in the default
> palette as red and green.
>

Looking at the standard palette with dichromat::dichromat() it seems that it depends on which flavour of red-green anomaly you have. For deuteranopia the red and green are quite close. For protanopia they are pretty distinct and the confusion is between colours 3 and 7 (yellow vs green) and between 4 and 6 (blue and magenta).

I agree that the standard palette isn't ideal, though.

      -thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From berwin at maths.uwa.edu.au  Fri Feb 20 11:02:05 2009
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Fri, 20 Feb 2009 18:02:05 +0800
Subject: [Rd] unloadNamespace (Was: How to unload a dll loaded via
 library.dynam()?)
In-Reply-To: <alpine.LFD.2.00.0902200338010.10231@gannet.stats.ox.ac.uk>
References: <30070-82496@sneakemail.com> <499DFA13.4060600@stats.uwo.ca>
	<d70c15d40902191643v4cba511ds794869eaf51d20d2@mail.gmail.com>
	<alpine.LFD.2.00.0902200338010.10231@gannet.stats.ox.ac.uk>
Message-ID: <20090220180205.634c86d8@berwin-nus1>

G'day all,

On Fri, 20 Feb 2009 04:01:07 +0000 (GMT)
Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

> library.dynam.unload() does work if the OS is cooperative.  And if
> you have your package set up correctly and unload the namespace (and
> not just detach the package if there is a namespace) then the shared 
> object/DLL will be unloaded. [...]

I guess I have a similar code-install-test development cycle as Alex;
and I seem to work on a cooperative OS (Kubuntu 8.04).

My set up is that I install packages on which I work into a separate
library.  To test changes to such packages, I start R in a directory
which contains a .Rprofile file which, via .libPaths(), adds the above
library to the library path.  In this R session I then test the changes.

I also used to quit and restart R whenever I re-installed a package with
namespace to test the changes made.  Somehow I got the impression that
this was the way to proceed when namespaces were introduced; and I did
not realise until recently that better ways (unloading the namespace)
exist.

However, I noticed the following behaviour under R 2.8.1 and "R version
2.9.0 Under development (unstable) (2009-02-19 r47958)" which I found
surprising:

1) In the running R session, issue the command "unloadNamespace(XXX)"
2) Do changes to the code of the package; e.g. add a "print("hello
   world")" statement to one of the R functions.
3) Install the new package
4) In the running R session, issue the command "library(XXX)" and call
   the R function that was changed.  
   
Result: "Hello world" is not printed, somehow the old R function is
still used.  If I issue the commands "unloadNamespace(XXX)" and
"library(XXX)" once more then a call to the R function that was changed
will print "Hello world"; i.e. the new code is used.

If the above sequence is changed to 2), 3) and then 1), then 4) behaves
"as expected" and the new R code is used immediately.

As far as I can tell, if via the .onUnload() hook the shared object is
unloaded via library.dynam.unload(), changes in the C code take effect
no matter whether I perform the above steps in the sequence 1-2-3-4 or
2-3-1-4.

My preference is to use the sequence 1-2-3-4 since it seems to be the
"more logical and cleaner" sequence; and I have vague memories that I
managed to crash R in the past after using 2-3 and then trying to quit
R.

I am wondering why does it make a difference with respect to R code in
which order these steps are done but not with respect to compiled
code.  Well, I guess I understand why the order does not matter for
compiled code, but I do not understand why the order matters for R
code.  I could not find anything in the documentation that would
explain this behaviour, or indicate that this is the intended
behaviour.  

Enlightening comments and/or pointers to where this behaviour is
documented would be welcome.

Cheers,

	Berwin

=========================== Full address =============================
Berwin A Turlach                            Tel.: +65 6516 4416 (secr)
Dept of Statistics and Applied Probability        +65 6516 6650 (self)
Faculty of Science                          FAX : +65 6872 3919       
National University of Singapore     
6 Science Drive 2, Blk S16, Level 7          e-mail: statba at nus.edu.sg
Singapore 117546                    http://www.stat.nus.edu.sg/~statba


From clyde at stat.duke.edu  Fri Feb 20 04:00:05 2009
From: clyde at stat.duke.edu (clyde at stat.duke.edu)
Date: Fri, 20 Feb 2009 04:00:05 +0100 (CET)
Subject: [Rd] X11 fails to open (PR#13543)
Message-ID: <20090220030005.2B170284A70C@mail.pubhealth.ku.dk>

Full_Name: Merlise Clyde
Version: 2.8.1
OS: MAC OS X 10.4.1
Submission from: (NULL) (24.199.155.61)


I am running R under X11 on the MAC OS X 10.4.11 and have been having
problems with X11 graphics since upgrading to  2.8.+ 


> plot(1:10)
Error in X11(d$display, d$width, d$height, d$pointsize, d$gamma, d$colortype,  :

  unable to start device X11cairo
In addition: Warning messages:
1: In function (display = "", width, height, pointsize, gamma, bg,  :
  X11 protocol error: BadValue (integer parameter out of range for operation)
2: In function (display = "", width, height, pointsize, gamma, bg,  :
  cairo error 'out of memory'
> 

I run R under emacs so the display is being set correctly and the device would
open
under previous verions.  
I am also encoutering a related problem with running R  2.8.0/2.8.1 on a
remote unix box and displaying back to the MAC, where any attempts to
open an X11() device causes R to hang.

Thanks,
Merlise Clyde



--please do not edit the information below--

Version:
 platform = i386-apple-darwin8.11.1
 arch = i386
 os = darwin8.11.1
 system = i386, darwin8.11.1
 status = 
 major = 2
 minor = 8.1
 year = 2008
 month = 12
 day = 22
 svn rev = 47281
 language = R
 version.string = R version 2.8.1 (2008-12-22)

Locale:
C

Search Path:
 .GlobalEnv, package:stats, package:graphics, package:grDevices, package:utils,
package:datasets, package:methods, Autoloads, package:base


From kbarton at zbs.bialowieza.pl  Fri Feb 20 02:20:09 2009
From: kbarton at zbs.bialowieza.pl (kbarton at zbs.bialowieza.pl)
Date: Fri, 20 Feb 2009 02:20:09 +0100 (CET)
Subject: [Rd] "source" fails to handle non-ascii variable names (PR#13541)
Message-ID: <20090220012009.AE408282EFF8@mail.pubhealth.ku.dk>

If there is variable name in the source file which contains non-ascii cha=
racters, "source" gives an=20
"unexpected $end" error after first such character (even if proper file e=
ncoding is provided).
This also happens with parse, when "file" is a textConnection, but not if=
 the same code is provided=20
by "text" argument.
This problem seems to occur only on Windows.

Examples:

 > con <- textConnection("=C4=85=C4=99=C4=87=C5=BA <- 12345")
 > parse(con)
Error in parse(con) : unexpected $end at
1: =C4=85

# backtick quoted names are parsed correctly:

 > con <- textConnection("`=C4=85=C4=99=C4=87=C5=BA` <- 12345")
 > parse(con)
expression(=C4=85=C4=99=C4=87=C5=BA <- 12345)


# also, parsing as text works:

 > con <- textConnection("=C4=85=C4=99=C4=87=C5=BA <- 12345")
 > parse(text=3DreadLines(con))
expression(=C4=85=C4=99=C4=87=C5=BA <- 12345)
attr(,"srcfile")
<text>



Version:
  platform =3D i386-pc-mingw32
  arch =3D i386
  os =3D mingw32
  system =3D i386, mingw32
  status =3D
  major =3D 2
  minor =3D 8.1
  year =3D 2008
  month =3D 12
  day =3D 22
  svn rev =3D 47281
  language =3D R
  version.string =3D R version 2.8.1 (2008-12-22)

Windows XP (build 2600) Service Pack 3

Locale:
LC_COLLATE=3DPolish_Poland.1250;LC_CTYPE=3DPolish_Poland.1250;LC_MONETARY=
=3DPolish_Poland.1250;LC_NUMERIC=3DC;LC_TIME=3DPolish_Poland.1250


From Sachinthaka.Abeywardana at csiro.au  Fri Feb 20 04:15:12 2009
From: Sachinthaka.Abeywardana at csiro.au (sachin1234)
Date: Thu, 19 Feb 2009 19:15:12 -0800 (PST)
Subject: [Rd]  Faster Blas Library
Message-ID: <22114095.post@talk.nabble.com>


Hi everyone,

I have made a faster BLAS library thanks to Nvidia CUBLAS library. I was
wondering how I could upload this new Rblas.dll. I've included a powerpoint
presentation I made on the project.

Highlights include upto 2000% improvement in matrix multiplication timings.

Unfortunately the link included in the presentation is only accessible by
CSIRO employees only. I will gladly include the source code as well.

However for the moment could someone simply tell me where and how to upload
these files

Thanks
Sachin http://www.nabble.com/file/p22114095/R3.ppt R3.ppt 
-- 
View this message in context: http://www.nabble.com/Faster-Blas-Library-tp22114095p22114095.html
Sent from the R devel mailing list archive at Nabble.com.


From ripley at stats.ox.ac.uk  Fri Feb 20 11:45:52 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 20 Feb 2009 10:45:52 +0000 (GMT)
Subject: [Rd] Faster Blas Library
In-Reply-To: <22114095.post@talk.nabble.com>
References: <22114095.post@talk.nabble.com>
Message-ID: <alpine.LFD.2.00.0902201031140.7889@auk.stats.ox.ac.uk>

I presume this is on Windows (you did not actually say).

The section http://cran.r-project.org/bin/windows/contrib/ is managed 
by Uwe Ligges, and you could send him the Rblas.dll, the sources, a 
description file and a license (the last being rather important if 
this is to be hosted on CRAN).

On Thu, 19 Feb 2009, sachin1234 wrote:

> Hi everyone,
>
> I have made a faster BLAS library thanks to Nvidia CUBLAS library. I was
> wondering how I could upload this new Rblas.dll. I've included a powerpoint
> presentation I made on the project.
>
> Highlights include upto 2000% improvement in matrix multiplication timings.

> Unfortunately the link included in the presentation is only accessible by
> CSIRO employees only. I will gladly include the source code as well.
>
> However for the moment could someone simply tell me where and how to upload
> these files
>
> Thanks
> Sachin http://www.nabble.com/file/p22114095/R3.ppt R3.ppt

> -- 
> View this message in context: http://www.nabble.com/Faster-Blas-Library-tp22114095p22114095.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ligges at statistik.tu-dortmund.de  Fri Feb 20 12:15:01 2009
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 20 Feb 2009 12:15:01 +0100
Subject: [Rd] Faster Blas Library
In-Reply-To: <alpine.LFD.2.00.0902201031140.7889@auk.stats.ox.ac.uk>
References: <22114095.post@talk.nabble.com>
	<alpine.LFD.2.00.0902201031140.7889@auk.stats.ox.ac.uk>
Message-ID: <499E90B5.8030103@statistik.tu-dortmund.de>



Prof Brian Ripley wrote:
> I presume this is on Windows (you did not actually say).
> 
> The section http://cran.r-project.org/bin/windows/contrib/ is managed by 
> Uwe Ligges, and you could send him the Rblas.dll, the sources, a 
> description file and a license (the last being rather important if this 
> is to be hosted on CRAN).


Yes, please do so. We are really interested.

Note: I doubt that double prec. floating point ops are faster than 
single prec. (according to your slides).
Moreover, I'd like to see speed comparisons related to matrix sizes on 
some logarithmic scale in order to compare the quite relevant gains for 
small sized vectors.

Best wishes,
Uwe


> On Thu, 19 Feb 2009, sachin1234 wrote:
> 
>> Hi everyone,
>>
>> I have made a faster BLAS library thanks to Nvidia CUBLAS library. I was
>> wondering how I could upload this new Rblas.dll. I've included a 
>> powerpoint
>> presentation I made on the project.
>>
>> Highlights include upto 2000% improvement in matrix multiplication 
>> timings.
> 
>> Unfortunately the link included in the presentation is only accessible by
>> CSIRO employees only. I will gladly include the source code as well.
>>
>> However for the moment could someone simply tell me where and how to 
>> upload
>> these files
>>
>> Thanks
>> Sachin http://www.nabble.com/file/p22114095/R3.ppt R3.ppt
> 
>> -- 
>> View this message in context: 
>> http://www.nabble.com/Faster-Blas-Library-tp22114095p22114095.html
>> Sent from the R devel mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From ripley at stats.ox.ac.uk  Fri Feb 20 12:37:18 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 20 Feb 2009 11:37:18 +0000 (GMT)
Subject: [Rd] unloadNamespace (Was: How to unload a dll loaded via
 library.dynam()?)
In-Reply-To: <20090220180205.634c86d8@berwin-nus1>
References: <30070-82496@sneakemail.com> <499DFA13.4060600@stats.uwo.ca>
	<d70c15d40902191643v4cba511ds794869eaf51d20d2@mail.gmail.com>
	<alpine.LFD.2.00.0902200338010.10231@gannet.stats.ox.ac.uk>
	<20090220180205.634c86d8@berwin-nus1>
Message-ID: <alpine.LFD.2.00.0902201128280.11172@toucan.stats.ox.ac.uk>

This was rather a large shift of subject, so I've pruned the 
recipients list.

Is lazy loading involved?  If so I have an idea that may or may not be 
relevant.  We do cache in memory the lazy-loading database for speed 
on slow (network-mounted or USB drive) file systems.  Now the cache is 
flushed at least if you do detach(foo, unload = TRUE) or but I can 
envisage a set of circumstances in which it might not be.

So perhaps try detach(foo, unload = TRUE) or not using lazy-loading 
when developing the package?

On Fri, 20 Feb 2009, Berwin A Turlach wrote:

> G'day all,
>
> On Fri, 20 Feb 2009 04:01:07 +0000 (GMT)
> Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>
>> library.dynam.unload() does work if the OS is cooperative.  And if
>> you have your package set up correctly and unload the namespace (and
>> not just detach the package if there is a namespace) then the shared
>> object/DLL will be unloaded. [...]
>
> I guess I have a similar code-install-test development cycle as Alex;
> and I seem to work on a cooperative OS (Kubuntu 8.04).
>
> My set up is that I install packages on which I work into a separate
> library.  To test changes to such packages, I start R in a directory
> which contains a .Rprofile file which, via .libPaths(), adds the above
> library to the library path.  In this R session I then test the changes.
>
> I also used to quit and restart R whenever I re-installed a package with
> namespace to test the changes made.  Somehow I got the impression that
> this was the way to proceed when namespaces were introduced; and I did
> not realise until recently that better ways (unloading the namespace)
> exist.
>
> However, I noticed the following behaviour under R 2.8.1 and "R version
> 2.9.0 Under development (unstable) (2009-02-19 r47958)" which I found
> surprising:
>
> 1) In the running R session, issue the command "unloadNamespace(XXX)"
> 2) Do changes to the code of the package; e.g. add a "print("hello
>   world")" statement to one of the R functions.
> 3) Install the new package
> 4) In the running R session, issue the command "library(XXX)" and call
>   the R function that was changed.
>
> Result: "Hello world" is not printed, somehow the old R function is
> still used.  If I issue the commands "unloadNamespace(XXX)" and
> "library(XXX)" once more then a call to the R function that was changed
> will print "Hello world"; i.e. the new code is used.
>
> If the above sequence is changed to 2), 3) and then 1), then 4) behaves
> "as expected" and the new R code is used immediately.
>
> As far as I can tell, if via the .onUnload() hook the shared object is
> unloaded via library.dynam.unload(), changes in the C code take effect
> no matter whether I perform the above steps in the sequence 1-2-3-4 or
> 2-3-1-4.
>
> My preference is to use the sequence 1-2-3-4 since it seems to be the
> "more logical and cleaner" sequence; and I have vague memories that I
> managed to crash R in the past after using 2-3 and then trying to quit
> R.
>
> I am wondering why does it make a difference with respect to R code in
> which order these steps are done but not with respect to compiled
> code.  Well, I guess I understand why the order does not matter for
> compiled code, but I do not understand why the order matters for R
> code.  I could not find anything in the documentation that would
> explain this behaviour, or indicate that this is the intended
> behaviour.
>
> Enlightening comments and/or pointers to where this behaviour is
> documented would be welcome.
>
> Cheers,
>
> 	Berwin
>
> =========================== Full address =============================
> Berwin A Turlach                            Tel.: +65 6516 4416 (secr)
> Dept of Statistics and Applied Probability        +65 6516 6650 (self)
> Faculty of Science                          FAX : +65 6872 3919
> National University of Singapore
> 6 Science Drive 2, Blk S16, Level 7          e-mail: statba at nus.edu.sg
> Singapore 117546                    http://www.stat.nus.edu.sg/~statba
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tlumley at u.washington.edu  Fri Feb 20 13:10:24 2009
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 20 Feb 2009 04:10:24 -0800 (PST)
Subject: [Rd] cpu bound cases
In-Reply-To: <049C4E48B10A854FB9D3B3C9DFAB506B011D5A1A@smarexmb1.amd.com>
Message-ID: <Pine.LNX.4.43.0902200410240.19096@hymn12.u.washington.edu>

On Thu, 19 Feb 2009, Rubin, Norman wrote:

> I'm considering some things AMD could do to accelerate R using GPU
> processors. In an internal discussion I was asked
>
> "Are there interesting R computations which are currently cpu bound?"
> I'm sure there are lots but I'd like to be able to name some real world
> cases.
>

It depends a bit on what you mean by cpu-bound.  Some of the arithmetic and mathematical functions are fairly clearly cpu bound, since Luke Tierney's multithreaded math library speeds them up.

The matrix operations in regression can easily push the CPU usage to 100%, but the success of ATLAS suggests that they may really be limited more by cpu memory bandwidth. I don't know if this counts.

Other people may have different suggestions.

        -thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From jfox at mcmaster.ca  Fri Feb 20 14:05:59 2009
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 20 Feb 2009 08:05:59 -0500
Subject: [Rd] plot.lm: "Cook's distance" label can overplot point labels
In-Reply-To: <Pine.LNX.4.43.0902200132150.19096@hymn12.u.washington.edu>
References: <002501c99291$91e161f0$b5a425d0$@ca>
	<Pine.LNX.4.43.0902200132150.19096@hymn12.u.washington.edu>
Message-ID: <004601c9935b$f9f41600$eddc4200$@ca>

Dear Thomas,

Though far from an expert on the matter, it's my understanding that
red-green confusion is the most common form of colour-blindness. I guess
that the best way to put it is that it would be desirable to choose colours
for the standard palette that minimize the probability of perceptual
problems.

Regards,
 John


> -----Original Message-----
> From: Thomas Lumley [mailto:tlumley at u.washington.edu]
> Sent: February-20-09 4:32 AM
> To: John Fox
> Cc: 'John Maindonald'; 'Prof Brian Ripley'; r-devel at r-project.org; 'Martin
> Maechler'
> Subject: Re: [Rd] plot.lm: "Cook's distance" label can overplot point
labels
> 
> On Thu, 19 Feb 2009, John Fox wrote:
> 
> > Dear John and Brian,
> >
> > My point about colour-blindness was partly tongue-in-cheek, but I think
> that
> > it's a bad choice to have the second and third colours in the default
> > palette as red and green.
> >
> 
> Looking at the standard palette with dichromat::dichromat() it seems that
it
> depends on which flavour of red-green anomaly you have. For deuteranopia
the
> red and green are quite close. For protanopia they are pretty distinct and
> the confusion is between colours 3 and 7 (yellow vs green) and between 4
and
> 6 (blue and magenta).
> 
> I agree that the standard palette isn't ideal, though.
> 
>       -thomas
> 
> Thomas Lumley			Assoc. Professor, Biostatistics
> tlumley at u.washington.edu	University of Washington, Seattle
>


From Manuel.Eugster at stat.uni-muenchen.de  Fri Feb 20 16:33:14 2009
From: Manuel.Eugster at stat.uni-muenchen.de (Manuel J. A. Eugster)
Date: Fri, 20 Feb 2009 16:33:14 +0100
Subject: [Rd] [SoC09-Info] Idea submission.
Message-ID: <499ECD3A.1030707@stat.uni-muenchen.de>

Hi everybody,

as Fritz mentioned in his introducing "Google Summer of Code 2009"
email, I will manage the organizational part of the R-Project
application and (hopfully) participation.

Google's timeline schedules March 9-13 as date for organizations to
make an application as mentoring organization. The idea is now to
collect as many project ideas in a brainstorming phase and submit
these by March 10.

A project proposal consists of:
   (1) a short description,
   (2) a detailed description,
   (3) required skills and
   (4) the mentors name.

   I propose, that for each idea, a
   (5) short programming exercise is defined, which students have to
       solve before they can apply. Many other projects do this to
       reduce "noise". It also allows an evaluation and ranking if more
       than one student applies to the same project. But this is up to
       the mentor and hence is optional to include.

I thus encourage you to send such project proposals to me with a CC to
the r-devel list with [SoC09-Idea] as start of the subject line. I
will collect the ideas on a tentative list, see
http://www.r-project.org/soc09. The r-devel CC allows an active
discussion (as we already saw :-)). Just to clarify: in this
brainstorming phase, we collect ideas and there is no need to rank or
evaluate them!

I will monitor the different Google SoC information sources and mail
important informations with [SoC09-Info] as start of the subject line
to this list to keep you updated.


So, kick-off for idea proposals until March 10!

Best,
Manuel.


From info at aghmed.fsnet.co.uk  Fri Feb 20 18:22:37 2009
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Fri, 20 Feb 2009 17:22:37 +0000
Subject: [Rd] plot.lm: "Cook's distance" label can overplot point labels
In-Reply-To: <004601c9935b$f9f41600$eddc4200$@ca>
References: <002501c99291$91e161f0$b5a425d0$@ca>
	<Pine.LNX.4.43.0902200132150.19096@hymn12.u.washington.edu>
	<004601c9935b$f9f41600$eddc4200$@ca>
Message-ID: <Zen-1LaZ5J-0007QG-4p@smarthost03.mail.zen.net.uk>

At 13:05 20/02/2009, John Fox wrote:

>Dear Thomas,
>
>Though far from an expert on the matter, it's my understanding that
>red-green confusion is the most common form of colour-blindness. I guess
>that the best way to put it is that it would be desirable to choose colours
>for the standard palette that minimize the probability of perceptual
>problems.

I wonder whether there are two separate issues: what is the best 
standard palette and whether mainstream plots should use colour to 
carry essential information. For instance there seems little problem 
in biplot having red arrows and black points because the colour is redundant.

I am not an expert on colour vision either but there certainly are 
people who report difficulty at scientific meetings with interpreting 
the slides.


>Regards,
>  John
>
>
> > -----Original Message-----
> > From: Thomas Lumley [mailto:tlumley at u.washington.edu]
> > Sent: February-20-09 4:32 AM
> > To: John Fox
> > Cc: 'John Maindonald'; 'Prof Brian Ripley'; r-devel at r-project.org; 'Martin
> > Maechler'
> > Subject: Re: [Rd] plot.lm: "Cook's distance" label can overplot point
>labels
> >
> > On Thu, 19 Feb 2009, John Fox wrote:
> >
> > > Dear John and Brian,
> > >
> > > My point about colour-blindness was partly tongue-in-cheek, but I think
> > that
> > > it's a bad choice to have the second and third colours in the default
> > > palette as red and green.
> > >
> >
> > Looking at the standard palette with dichromat::dichromat() it seems that
>it
> > depends on which flavour of red-green anomaly you have. For deuteranopia
>the
> > red and green are quite close. For protanopia they are pretty distinct and
> > the confusion is between colours 3 and 7 (yellow vs green) and between 4
>and
> > 6 (blue and magenta).
> >
> > I agree that the standard palette isn't ideal, though.
> >
> >       -thomas
> >
> > Thomas Lumley                 Assoc. Professor, Biostatistics
> > tlumley at u.washington.edu      University of Washington, Seattle
> >
>
>______________________________________________
>R-devel at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>No virus found in this incoming message.
>Checked by AVG - www.avg.com
>Version: 8.0.237 / Virus Database: 270.11.1/1961 - Release Date: 
>02/19/09 18:45:00

Michael Dewey
http://www.aghmed.fsnet.co.uk


From berwin at maths.uwa.edu.au  Fri Feb 20 18:52:13 2009
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Sat, 21 Feb 2009 01:52:13 +0800
Subject: [Rd] unloadNamespace (Was: How to unload a dll loaded via
 library.dynam()?)
In-Reply-To: <alpine.LFD.2.00.0902201128280.11172@toucan.stats.ox.ac.uk>
References: <30070-82496@sneakemail.com> <499DFA13.4060600@stats.uwo.ca>
	<d70c15d40902191643v4cba511ds794869eaf51d20d2@mail.gmail.com>
	<alpine.LFD.2.00.0902200338010.10231@gannet.stats.ox.ac.uk>
	<20090220180205.634c86d8@berwin-nus1>
	<alpine.LFD.2.00.0902201128280.11172@toucan.stats.ox.ac.uk>
Message-ID: <20090221015213.07267e80@berwin5>

G'day Brian,

On Fri, 20 Feb 2009 11:37:18 +0000 (GMT)
Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

> This was rather a large shift of subject, [...] 

Well, yes, from the clean unloading of compiled code to the clean
unloading of R code.  :-)  
Though, I also confirmed that the former is possible on a cooperative
OS when library.dynam.unload() is correctly used via an .onUnload()
hook. 

> Is lazy loading involved? 

Yes, the DESCRIPTION file has the default "LazyLoad: yes" entry. 

If I set "LazyLoad: no", then both sequences use the new version of the
R code immediately.

> If so I have an idea that may or may not be relevant.  We do cache in
> memory the lazy-loading database for speed on slow (network-mounted
> or USB drive) file systems.  Now the cache is flushed at least if you
> do detach(foo, unload = TRUE) or but I can envisage a set of
> circumstances in which it might not be.

As far as I can tell, "detach(foo, unload=TRUE)" and
"unloadNamespace(foo)" behave identical on my machines (while the
DESCRIPTION file has "LazyLoad: yes"); the modified R code is only used
if either of this command is given (followed by "library(foo)") after
the new version of the package was installed. 

> So perhaps try detach(foo, unload = TRUE) or not using lazy-loading 
> when developing the package?

Unfortunately, the former does not work and although the latter works I
am hesitant to use it since:

a) as I understand it, most packages that use S4 methods need
lazy-loading (though the particular package with which I noticed the
behaviour does not have S4 methods); and

b) it seems that these days the DESCRIPTION file is the only way of
switching lazy loading on and off and that there is no way of
overriding that value.  Knowing myself, I would forget changing the
DESCRIPTION file back to "LazyLoad: yes" before building the .tar.gz
file for distribution (once the package is ready).  As it is, I have
already to remember to take "-Wall -pedantic" out of the Makevars file
in the src/ directory; but I am reminded of that by R CMD check.

Well, thinking a bit more about b), I could probably complicate my
Makefile a bit more such that a "make install" first modifies the
DESCRIPTION file to "LazyLoad: no" before installing the package to the
local library and that "make build" first modifies the DESCRIPTION in
the opposite way.  But this would still leave concern a).

Cheers,

	Berwin


From berwin at maths.uwa.edu.au  Fri Feb 20 19:23:52 2009
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Sat, 21 Feb 2009 02:23:52 +0800
Subject: [Rd] vignette compilation times
In-Reply-To: <499D3E35.4050300@cam.ac.uk>
References: <499D3E35.4050300@cam.ac.uk>
Message-ID: <20090221022352.6cc3892d@berwin5>

G'day Robin,

On Thu, 19 Feb 2009 11:10:45 +0000
Robin Hankin <rksh1 at cam.ac.uk> wrote:

> I am preparing a number of vignettes that require a very  long time to
> process with Sweave.  The longest one takes 10 hours.  

Is the sum of all chunks taking this time?  Or is it mostly the code in
only a view chunks?  And if so, are there chunks following that depend
on the result of these time-intensive chunks?

I wonder if it is feasible to construct your vignette according to the
lines.
1) have a file, say, vignette1.Rnw.in that contains:
--------------------
#ifdef BUILDVERSION
you may want to try the commands
\begin{Sinput}
> command1
> command2
\end{Sinput}
but be aware that his might take a long time.
#else
Now we run the commands
<<>>=
command1
command2
@
#endif
--------------------------

2) Now construct a Makefile that, using a preprocesser like cpp,
produces vignette1.Rnw from vignette1.Rnw.in using the first version
before an "R CMD build" but otherwise (for your own testing) the
second version.  Using .Rbuildignore, you can ensure that
vignett1.Rnw.in would not be distributed. 

> I love the weaver package!

Thanks for pointing this package out.  I was aware of cacheSweave, but
that package seems to require that each chunk has a label which I find
kind of inconvenient.  weaver does not seem to have such a requirement.

Cheers,

	Berwin


From berwin at maths.uwa.edu.au  Fri Feb 20 19:37:38 2009
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Sat, 21 Feb 2009 02:37:38 +0800
Subject: [Rd] vignette compilation times
In-Reply-To: <971536df0902191447x62b7c879h348b08e629c85bf0@mail.gmail.com>
References: <499D3E35.4050300@cam.ac.uk>
	<499D442A.20605@statistik.tu-dortmund.de>
	<499D46C0.10404@cam.ac.uk>
	<18845.57098.447677.624190@ridcully.stat.uni-muenchen.de>
	<971536df0902191447x62b7c879h348b08e629c85bf0@mail.gmail.com>
Message-ID: <20090221023738.0853af60@berwin5>

G'day Gabor,

On Thu, 19 Feb 2009 17:47:53 -0500
Gabor Grothendieck <ggrothendieck at gmail.com> wrote:

> [...]
> Unless this has changed recently,I've tried including a PDF but it
> does not appear in library(help = myPackage) nor on the CRAN site on
> http://cran.r-project.org/package=myPackage
> while Sweave'd PDFs do.

If you want a PDF file to appear in library(help=myPackage), then you
can write a vignette that just includes that PDF file via \includepdf
from the LaTeX package(?) pdfpages.

You will, of course, end up with two PDF files that are practically
identical.  So you might want to exclude the original PDF file from the
build package via .Rbuildignore.

If you do so, the next problem is that since R 2.6.0 "R CMD check" is
trying to latex the vignette and not just checks the code in the
vignette.  And in current TeX systems latex will hang if \includepdf
does not find the specified PDF file; latex does not stop with an
error, it hangs.  

So the vignette has to be written smart enough to try to include the
PDF file via \includepdf only if the file really exists, but that can
easily be done.  See the package lasso2 for an example.  

If you follow this set up, your PDF file will show up in
library(help=myPackage) and your package will pass "R CMD check" on
CRAN.

HTH.

Cheers,
	
	Berwin


From berwin at maths.uwa.edu.au  Fri Feb 20 20:07:34 2009
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Sat, 21 Feb 2009 03:07:34 +0800
Subject: [Rd] vignette compilation times
In-Reply-To: <18846.2953.134949.620375@ridcully.stat.uni-muenchen.de>
References: <499D3E35.4050300@cam.ac.uk>
	<499D442A.20605@statistik.tu-dortmund.de>
	<499D46C0.10404@cam.ac.uk>
	<18845.57098.447677.624190@ridcully.stat.uni-muenchen.de>
	<971536df0902191447x62b7c879h348b08e629c85bf0@mail.gmail.com>
	<18846.2953.134949.620375@ridcully.stat.uni-muenchen.de>
Message-ID: <20090221030734.383cfdab@berwin5>

G'day Fritz,

On Fri, 20 Feb 2009 12:46:49 +1100
Friedrich Leisch <Friedrich.Leisch at stat.uni-muenchen.de> wrote:

[...]
> It is also unclear to me whether including a PDF without sources in a
> GPLed package isn't a violation of the GPL (I know people who very
> strongly think so). And source according to the GPL means "the
> preferred form of the work for making modifications to it." So for a
> PDF showing R output that would mean the text plus R code plus
> data ... which boils down to XXXweave anyway.

Well, GPL-2 says "This License applies to any program or other work
which contains a notice placed by the copyright holder saying it may be
distributed under the terms of this General Public License".   I am
somehow unable to locate the equivalent statement in GPL-3.  

Thus, under GPL-2, if the source that produces the PDF file does not
contain a statement that it may be distributed under the terms of the
GPL, then, in my understanding, you do not have to distribute the
source.  On occasions I wondered whether stating in the DESCRIPTION
file that your package is GPL-2 extends this license to all other
files and to those in inst/doc in particular.  Or whether one should
better slap a GPL-2 notice (or a GNU Free Documentation License)
explicitly on the documentation.

Actually, the fact that the GNU Free Documentation License exists makes
me wonder whether it is tenable to apply GPL to documentation such as
PDF files.  But the phrase "or other work" in the above cite part
of GPL-2 and the explicit `"The Program" refers to any copyrightable
work' in GPL-3 seem to indicate that it is possible.  Though, I guess
you would still have to state *within* the (source of) vignette that it
is under the GPL.

But then IANAL.

Cheers,

	Berwin


From mflawren at fhcrc.org  Fri Feb 20 20:48:16 2009
From: mflawren at fhcrc.org (Michael Lawrence)
Date: Fri, 20 Feb 2009 11:48:16 -0800
Subject: [Rd] interactive graphics for R: was Google Summer of Code 2009
In-Reply-To: <1A68FCB28DE72F4BA3B967E6506CCE43047DF6AE@mildnpexmb01.maninvestments.ad.man.com>
References: <18844.37238.384954.744812@ridcully.stat.uni-muenchen.de>
	<1A68FCB28DE72F4BA3B967E6506CCE43047DF6A4@mildnpexmb01.maninvestments.ad.man.com>
	<AF924562-B299-47E3-B3A6-83B668D7050F@r-project.org>
	<1A68FCB28DE72F4BA3B967E6506CCE43047DF6A8@mildnpexmb01.maninvestments.ad.man.com>
	<DEC00D2A-55A3-465E-AEF4-7B9E29BAA44E@r-project.org>
	<1A68FCB28DE72F4BA3B967E6506CCE43047DF6AE@mildnpexmb01.maninvestments.ad.man.com>
Message-ID: <509e0620902201148p397a1ca8wc87e83f2e0644db2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090220/1bfe6b78/attachment.pl>

From ggrothendieck at gmail.com  Sat Feb 21 03:50:05 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 20 Feb 2009 21:50:05 -0500
Subject: [Rd] vignette compilation times
In-Reply-To: <20090221023738.0853af60@berwin5>
References: <499D3E35.4050300@cam.ac.uk>
	<499D442A.20605@statistik.tu-dortmund.de> <499D46C0.10404@cam.ac.uk>
	<18845.57098.447677.624190@ridcully.stat.uni-muenchen.de>
	<971536df0902191447x62b7c879h348b08e629c85bf0@mail.gmail.com>
	<20090221023738.0853af60@berwin5>
Message-ID: <971536df0902201850r4d0aeb25g8732239896d33895@mail.gmail.com>

Thanks for the inventive workaround.

On Fri, Feb 20, 2009 at 1:37 PM, Berwin A Turlach
<berwin at maths.uwa.edu.au> wrote:
> G'day Gabor,
>
> On Thu, 19 Feb 2009 17:47:53 -0500
> Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
>
>> [...]
>> Unless this has changed recently,I've tried including a PDF but it
>> does not appear in library(help = myPackage) nor on the CRAN site on
>> http://cran.r-project.org/package=myPackage
>> while Sweave'd PDFs do.
>
> If you want a PDF file to appear in library(help=myPackage), then you
> can write a vignette that just includes that PDF file via \includepdf
> from the LaTeX package(?) pdfpages.
>
> You will, of course, end up with two PDF files that are practically
> identical.  So you might want to exclude the original PDF file from the
> build package via .Rbuildignore.
>
> If you do so, the next problem is that since R 2.6.0 "R CMD check" is
> trying to latex the vignette and not just checks the code in the
> vignette.  And in current TeX systems latex will hang if \includepdf
> does not find the specified PDF file; latex does not stop with an
> error, it hangs.
>
> So the vignette has to be written smart enough to try to include the
> PDF file via \includepdf only if the file really exists, but that can
> easily be done.  See the package lasso2 for an example.
>
> If you follow this set up, your PDF file will show up in
> library(help=myPackage) and your package will pass "R CMD check" on
> CRAN.
>
> HTH.
>
> Cheers,
>
>        Berwin
>


From Thomas.Petzoldt at TU-Dresden.de  Sat Feb 21 09:46:52 2009
From: Thomas.Petzoldt at TU-Dresden.de (Thomas Petzoldt)
Date: Sat, 21 Feb 2009 09:46:52 +0100
Subject: [Rd] R-devel/Linux x64/Sun Studio 12: Problem with Matrix
Message-ID: <1235206012.3854.24.camel@localhost.localdomain>

Dear Developers,

motivated by the new Sun Studio checks I compiled R-devel and several of
our packages with Sun Studio 12 on Fedora x64.

Everything worked fine and R-devel runs, with the exception of package
Matrix where compilation crashes with the following message. The error
occurs during building of the recommended packages and also if Matrix is
compiled separately:

[...]
CC -G -lCstd  -L/opt/sun/sunstudio12/lib/amd64 -o Matrix.so CHMfactor.o
Csparse.o TMatrix_as.o Tsparse.o init.o Mutils.o chm_common.o cs.o
cs_utils.o dense.o dgCMatrix.o dgTMatrix.o dgeMatrix.o dpoMatrix.o
dppMatrix.o dsCMatrix.o dsyMatrix.o dspMatrix.o dtCMatrix.o dtTMatrix.o
dtrMatrix.o dtpMatrix.o factorizations.o ldense.o lgCMatrix.o sparseQR.o
CHOLMOD.a COLAMD.a AMD.a -L/home/user/R/R-devel/lib -lRlapack
-L/home/user/R/R-devel/lib -lRblas
-R/opt/sun/sunstudio12/lib/amd64:/opt/sun/sunstudio12/lib/amd64:/opt/sun/lib/rtlibs/amd64:/opt/sun/lib/rtlibs/amd64 -L/opt/sun/sunstudio12/rtlibs/amd64 -L/opt/sun/sunstudio12/prod/lib/amd64 -lfui -lfai -lfsu -lmtsk -lpthread -lm /opt/sun/sunstudio12/prod/lib/amd64/libc_supp.a  
/lib64/libpthread.so.0: file not recognized: File format not recognized
make: *** [Matrix.so] Error 1
ERROR: compilation failed for package ?Matrix?
* Removing ?/home/user/R/R-devel/library/Matrix?

Can someone help me or give me a pointer what I'm making wrong? How can
I get/include the missing shared library?

Many thanks in advance

Thomas Petzoldt


#file: config.site

CC=cc
CFLAGS="-xO5 -xc99 -xlibmil -nofstore"
CPICFLAGS=-Kpic
F77=f95
FFLAGS="-O5 -libmil -nofstore"
FPICFLAGS=-Kpic
CXX=CC
CXXFLAGS="-xO5 -xlibmil -nofstore"
CXXPICFLAGS=-Kpic
FC=f95
FCFLAGS=$FFLAGS
FCPICFLAGS=-Kpic
LDFLAGS=-L/opt/sun/sunstudio12/lib/amd64
SHLIB_LDFLAGS=-shared
SHLIB_CXXLDFLAGS="-G -lCstd"
SHLIB_FCLDFLAGS=-G
SAFE_FFLAGS="-O5 -libmil"

platform 86_64-unknown-linux-gnu                                        
arch x86_64                                                          
os linux-gnu                                                       
system x86_64, linux-gnu                                               
status Under development (unstable)                                    
major 2                                                               
minor 9.0                                                             
year  2009                                                            
month 02                                                              
day   20                                                              
svn rev 47964                                                           
language R
version.string R version 2.9.0 Under development (unstable) (2009-02-20
r47964)


From ripley at stats.ox.ac.uk  Sat Feb 21 09:44:33 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 21 Feb 2009 08:44:33 +0000 (GMT)
Subject: [Rd] R-devel/Linux x64/Sun Studio 12: Problem with Matrix
In-Reply-To: <1235206012.3854.24.camel@localhost.localdomain>
References: <1235206012.3854.24.camel@localhost.localdomain>
Message-ID: <alpine.LFD.2.00.0902210840260.5612@gannet.stats.ox.ac.uk>

This seems to be a problem with your OS installation. I have

gannet% file /lib64/libpthread.so.0
/lib64/libpthread.so.0: symbolic link to `libpthread-2.9.so'
gannet% file /lib64/libpthread-2.9.so
/lib64/libpthread-2.9.so: ELF 64-bit LSB shared object, x86-64, 
version 1 (SYSV), dynamically linked (uses shared libs), for GNU/Linux 
2.6.9, not stripped

gannet% rpm -q --whatprovides /lib64/libpthread-2.9.so
glibc-2.9-3.x86_64

and of course building (current) Matrix works for me.

On Sat, 21 Feb 2009, Thomas Petzoldt wrote:

> Dear Developers,
>
> motivated by the new Sun Studio checks I compiled R-devel and several of
> our packages with Sun Studio 12 on Fedora x64.
>
> Everything worked fine and R-devel runs, with the exception of package
> Matrix where compilation crashes with the following message. The error
> occurs during building of the recommended packages and also if Matrix is
> compiled separately:
>
> [...]
> CC -G -lCstd  -L/opt/sun/sunstudio12/lib/amd64 -o Matrix.so CHMfactor.o
> Csparse.o TMatrix_as.o Tsparse.o init.o Mutils.o chm_common.o cs.o
> cs_utils.o dense.o dgCMatrix.o dgTMatrix.o dgeMatrix.o dpoMatrix.o
> dppMatrix.o dsCMatrix.o dsyMatrix.o dspMatrix.o dtCMatrix.o dtTMatrix.o
> dtrMatrix.o dtpMatrix.o factorizations.o ldense.o lgCMatrix.o sparseQR.o
> CHOLMOD.a COLAMD.a AMD.a -L/home/user/R/R-devel/lib -lRlapack
> -L/home/user/R/R-devel/lib -lRblas
> -R/opt/sun/sunstudio12/lib/amd64:/opt/sun/sunstudio12/lib/amd64:/opt/sun/lib/rtlibs/amd64:/opt/sun/lib/rtlibs/amd64 -L/opt/sun/sunstudio12/rtlibs/amd64 -L/opt/sun/sunstudio12/prod/lib/amd64 -lfui -lfai -lfsu -lmtsk -lpthread -lm /opt/sun/sunstudio12/prod/lib/amd64/libc_supp.a
> /lib64/libpthread.so.0: file not recognized: File format not recognized
> make: *** [Matrix.so] Error 1
> ERROR: compilation failed for package ?Matrix?
> * Removing ?/home/user/R/R-devel/library/Matrix?
>
> Can someone help me or give me a pointer what I'm making wrong? How can
> I get/include the missing shared library?
>
> Many thanks in advance
>
> Thomas Petzoldt
>
>
> #file: config.site
>
> CC=cc
> CFLAGS="-xO5 -xc99 -xlibmil -nofstore"
> CPICFLAGS=-Kpic
> F77=f95
> FFLAGS="-O5 -libmil -nofstore"
> FPICFLAGS=-Kpic
> CXX=CC
> CXXFLAGS="-xO5 -xlibmil -nofstore"
> CXXPICFLAGS=-Kpic
> FC=f95
> FCFLAGS=$FFLAGS
> FCPICFLAGS=-Kpic
> LDFLAGS=-L/opt/sun/sunstudio12/lib/amd64
> SHLIB_LDFLAGS=-shared
> SHLIB_CXXLDFLAGS="-G -lCstd"
> SHLIB_FCLDFLAGS=-G
> SAFE_FFLAGS="-O5 -libmil"
>
> platform 86_64-unknown-linux-gnu
> arch x86_64
> os linux-gnu
> system x86_64, linux-gnu
> status Under development (unstable)
> major 2
> minor 9.0
> year  2009
> month 02
> day   20
> svn rev 47964
> language R
> version.string R version 2.9.0 Under development (unstable) (2009-02-20
> r47964)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From Thomas.Petzoldt at TU-Dresden.de  Sat Feb 21 11:41:31 2009
From: Thomas.Petzoldt at TU-Dresden.de (Thomas Petzoldt)
Date: Sat, 21 Feb 2009 11:41:31 +0100
Subject: [Rd] R-devel/Linux x64/Sun Studio 12: Problem with Matrix
In-Reply-To: <alpine.LFD.2.00.0902210840260.5612@gannet.stats.ox.ac.uk>
References: <1235206012.3854.24.camel@localhost.localdomain>
	<alpine.LFD.2.00.0902210840260.5612@gannet.stats.ox.ac.uk>
Message-ID: <499FDA5B.3050000@TU-Dresden.de>

Prof Brian Ripley wrote:
> This seems to be a problem with your OS installation. I have
> 
> gannet% file /lib64/libpthread.so.0
> /lib64/libpthread.so.0: symbolic link to `libpthread-2.9.so'
> gannet% file /lib64/libpthread-2.9.so
> /lib64/libpthread-2.9.so: ELF 64-bit LSB shared object, x86-64, version 
> 1 (SYSV), dynamically linked (uses shared libs), for GNU/Linux 2.6.9, 
> not stripped
> 
> gannet% rpm -q --whatprovides /lib64/libpthread-2.9.so
> glibc-2.9-3.x86_64
> 
> and of course building (current) Matrix works for me.
> 

Dear Prof. Ripley,

O.K. thanks for your quick answer, its good to know that its not an 
obvious error in config.site. Maybe it's because I started from a rather 
minimal Fedora version, so I'll try to fix my installation.

Thank you

Thomas P.


-- 
Thomas Petzoldt
Technische Universitaet Dresden
Institut fuer Hydrobiologie        thomas.petzoldt at tu-dresden.de
01062 Dresden                      http://tu-dresden.de/hydrobiologie/
GERMANY


From bob at spltrak.com  Sat Feb 21 22:25:09 2009
From: bob at spltrak.com (bob at spltrak.com)
Date: Sat, 21 Feb 2009 22:25:09 +0100 (CET)
Subject: [Rd] Install failure (PR#13545)
Message-ID: <20090221212509.F0944282C76F@mail.pubhealth.ku.dk>

Hello:
Encountered a problem installing R on
CentOS release 5.2

 This is a 64bit OS
I need to know if this will work on this server or do I need to change OS>

Thanks
Bob

I downloaded the source ( R-2.8.1.tar.gz ) due to no release being available
for CentOS.
My ./configure --with-x=no --with-readline=no R_PAPERSIZE='letter'

Failed:
./configure --with-x=no --with-readline=no R_PAPERSIZE='letter'
195 lines deleted from log
configure:5105: checking whether we are using the GNU C compiler
configure:5134: gcc -c  -I/usr/local/include conftest.c >&5
configure:5140: $? = 0
configure:5157: result: yes
configure:5162: checking whether gcc accepts -g
configure:5192: gcc -c -g -I/usr/local/include conftest.c >&5
configure:5198: $? = 0
configure:5297: result: yes
configure:5314: checking for gcc option to accept ISO C89
configure:5388: gcc  -c -g -O2 -I/usr/local/include conftest.c >&5
configure:5394: $? = 0
configure:5417: result: none needed
configure:5442: checking how to run the C preprocessor
configure:5482: gcc -E -I/usr/local/include conftest.c
configure:5488: $? = 0
configure:5519: gcc -E -I/usr/local/include conftest.c
conftest.c:16:28: error: ac_nonexistent.h: No such file or directory
configure:5525: $? = 1
configure: failed program was:
| /* confdefs.h.  */
| #define PACKAGE_NAME "R"
| #define PACKAGE_TARNAME "R"
| #define PACKAGE_VERSION "2.8.1"
| #define PACKAGE_STRING "R 2.8.1"
| #define PACKAGE_BUGREPORT "r-bugs at R-project.org"
| #define PACKAGE "R"
| #define VERSION "2.8.1"
| #define R_PLATFORM "x86_64-unknown-linux-gnu"
| #define R_CPU "x86_64"
| #define R_VENDOR "unknown"
| #define R_OS "linux-gnu"
| #define Unix 1
| #define R_ARCH ""
| /* end confdefs.h.  */
| #include <ac_nonexistent.h>
configure:5558: result: gcc -E
configure:5587: gcc -E -I/usr/local/include conftest.c
configure:5593: $? = 0
configure:5624: gcc -E -I/usr/local/include conftest.c
conftest.c:16:28: error: ac_nonexistent.h: No such file or directory
configure:5630: $? = 1
configure: failed program was:
| /* confdefs.h.  */
| #define PACKAGE_NAME "R"
| #define PACKAGE_TARNAME "R"
| #define PACKAGE_VERSION "2.8.1"
| #define PACKAGE_STRING "R 2.8.1"
| #define PACKAGE_BUGREPORT "r-bugs at R-project.org"
| #define PACKAGE "R"
| #define VERSION "2.8.1"
| #define R_PLATFORM "x86_64-unknown-linux-gnu"
| #define R_CPU "x86_64"
| #define R_VENDOR "unknown"
| #define R_OS "linux-gnu"
| #define Unix 1
| #define R_ARCH ""
| /* end confdefs.h.  */
| #include <ac_nonexistent.h>
configure:5669: checking whether gcc needs -traditional
configure:5711: result: no
configure:5723: checking how to run the C preprocessor
configure:5839: result: gcc -E
configure:5868: gcc -E -I/usr/local/include conftest.c
configure:5874: $? = 0
configure:5905: gcc -E -I/usr/local/include conftest.c
conftest.c:16:28: error: ac_nonexistent.h: No such file or directory
configure:5911: $? = 1
configure: failed program was:
| /* confdefs.h.  */
| #define PACKAGE_NAME "R"
| #define PACKAGE_TARNAME "R"
| #define PACKAGE_VERSION "2.8.1"
| #define PACKAGE_STRING "R 2.8.1"
| #define PACKAGE_BUGREPORT "r-bugs at R-project.org"
| #define PACKAGE "R"
| #define VERSION "2.8.1"
| #define R_PLATFORM "x86_64-unknown-linux-gnu"
| #define R_CPU "x86_64"
| #define R_VENDOR "unknown"
| #define R_OS "linux-gnu"
| #define Unix 1
| #define R_ARCH ""
| /* end confdefs.h.  */
| #include <ac_nonexistent.h>



FULL LOG FILE FOLLOWS
./configure --with-x=no --with-readline=no R_PAPERSIZE=letter

## --------- ##
## Platform. ##
## --------- ##

hostname = ip-216-55-136-29.dedicated.abac.net
uname -m = x86_64
uname -r = 2.6.18-92.el5
uname -s = Linux
uname -v = #1 SMP Tue Jun 10 18:51:06 EDT 2008

/usr/bin/uname -p = unknown
/bin/uname -X     = unknown

/bin/arch              = x86_64
/usr/bin/arch -k       = unknown
/usr/convex/getsysinfo = unknown
/usr/bin/hostinfo      = unknown
/bin/machine           = unknown
/usr/bin/oslevel       = unknown
/bin/universe          = unknown

PATH: /usr/kerberos/sbin
PATH: /usr/kerberos/bin
PATH: //sbin
PATH: //bin
PATH: /usr/local/sbin
PATH: /usr/local/bin
PATH: /sbin
PATH: /bin
PATH: /usr/sbin
PATH: /usr/bin
PATH: /root/bin


## ----------- ##
## Core tests. ##
## ----------- ##

configure:2376: checking build system type
configure:2394: result: x86_64-unknown-linux-gnu
configure:2416: checking host system type
configure:2431: result: x86_64-unknown-linux-gnu
configure:3062: checking for pwd
configure:3080: found //bin/pwd
configure:3093: result: //bin/pwd
configure:3101: checking whether builddir is srcdir
configure:3109: result: yes
configure:3114: checking for working aclocal
configure:3122: result: missing
configure:3127: checking for working autoconf
configure:3135: result: missing
configure:3140: checking for working automake
configure:3148: result: missing
configure:3153: checking for working autoheader
configure:3161: result: missing
configure:3170: checking for gawk
configure:3186: found //bin/gawk
configure:3197: result: gawk
configure:3208: checking for grep that handles long lines and -e
configure:3282: result: //bin/grep
configure:3287: checking for egrep
configure:3365: result: //bin/grep -E
configure:3370: checking whether ln -s works
configure:3374: result: yes
configure:3386: checking for bison
configure:3416: result: no
configure:3386: checking for byacc
configure:3416: result: no
configure:3429: checking for ar
configure:3445: found /usr/bin/ar
configure:3456: result: ar
configure:3483: checking for a BSD-compatible install
configure:3539: result: /usr/bin/install -c
configure:3574: checking for sed
configure:3593: found //bin/sed
configure:3605: result: //bin/sed
configure:3625: checking for less
configure:3643: found /usr/bin/less
configure:3655: result: /usr/bin/less
configure:3678: checking for perl
configure:3696: found /usr/bin/perl
configure:3708: result: /usr/bin/perl
configure:3720: checking whether perl version is at least 5.8.0
configure:3731: result: yes
configure:3750: checking for dvips
configure:3783: result: no
configure:3796: checking for tex
configure:3829: result: no
configure:3842: checking for latex
configure:3875: result: no
configure:3890: WARNING: you cannot build DVI versions of the R manuals
configure:3897: checking for makeindex
configure:3930: result: no
configure:3943: checking for pdftex
configure:3976: result: no
configure:3989: checking for pdflatex
configure:4022: result: no
configure:4037: WARNING: you cannot build PDF versions of the R manuals
configure:4044: checking for makeinfo
configure:4077: result: no
configure:4112: WARNING: you cannot build info or HTML versions of the R
manuals
configure:4123: checking for texi2dvi
configure:4156: result: no
configure:4227: checking for unzip
configure:4245: found /usr/bin/unzip
configure:4257: result: /usr/bin/unzip
configure:4273: checking for zip
configure:4291: found /usr/bin/zip
configure:4303: result: /usr/bin/zip
configure:4319: checking for gzip
configure:4337: found //bin/gzip
configure:4349: result: //bin/gzip
configure:4367: checking for firefox
configure:4400: result: no
configure:4367: checking for mozilla
configure:4400: result: no
configure:4367: checking for galeon
configure:4400: result: no
configure:4367: checking for opera
configure:4400: result: no
configure:4367: checking for xdg-open
configure:4400: result: no
configure:4367: checking for kfmclient
configure:4400: result: no
configure:4367: checking for gnome-moz-remote
configure:4400: result: no
configure:4367: checking for open
configure:4385: found /usr/bin/open
configure:4397: result: /usr/bin/open
configure:4414: result: using default browser ... /usr/bin/open
configure:4424: checking for acroread
configure:4457: result: no
configure:4424: checking for acroread4
configure:4457: result: no
configure:4424: checking for evince
configure:4457: result: no
configure:4424: checking for xpdf
configure:4457: result: no
configure:4424: checking for gv
configure:4457: result: no
configure:4424: checking for gnome-gv
configure:4457: result: no
configure:4424: checking for ggv
configure:4457: result: no
configure:4424: checking for kghostview
configure:4457: result: no
configure:4424: checking for open
configure:4442: found /usr/bin/open
configure:4454: result: /usr/bin/open
configure:4476: checking for pkg-config
configure:4495: found /usr/bin/pkg-config
configure:4507: result: /usr/bin/pkg-config
configure:4564: checking for gcc
configure:4580: found /usr/bin/gcc
configure:4591: result: gcc
configure:4829: checking for C compiler version
configure:4836: gcc --version >&5
gcc (GCC) 4.1.2 20071124 (Red Hat 4.1.2-42)
Copyright (C) 2006 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

configure:4839: $? = 0
configure:4846: gcc -v >&5
Using built-in specs.
Target: x86_64-redhat-linux
Configured with: ../configure --prefix=/usr --mandir=/usr/share/man
--infodir=/usr/share/info --enable-shared --enable-threads=posix --enabl
e-checking=release --with-system-zlib --enable-__cxa_atexit
--disable-libunwind-exceptions --enable-libgcj-multifile
--enable-languages=c,c+
+,objc,obj-c++,java,fortran,ada --enable-java-awt=gtk --disable-dssi
--enable-plugin --with-java-home=/usr/lib/jvm/java-1.4.2-gcj-1.4.2.0/jr
e --with-cpu=generic --host=x86_64-redhat-linux
Thread model: posix
gcc version 4.1.2 20071124 (Red Hat 4.1.2-42)
configure:4849: $? = 0
configure:4856: gcc -V >&5
gcc: '-V' option must have argument
configure:4859: $? = 1
configure:4882: checking for C compiler default output file name
configure:4909: gcc  -I/usr/local/include -L/usr/local/lib64 conftest.c  >&5
configure:4912: $? = 0
configure:4950: result: a.out
configure:4967: checking whether the C compiler works
configure:4977: ./a.out
configure:4980: $? = 0
configure:4997: result: yes
configure:5004: checking whether we are cross compiling
configure:5006: result: no
configure:5009: checking for suffix of executables
configure:5016: gcc -o conftest  -I/usr/local/include -L/usr/local/lib64
conftest.c  >&5
configure:5019: $? = 0
configure:5043: result:
configure:5049: checking for suffix of object files
configure:5075: gcc -c  -I/usr/local/include conftest.c >&5
configure:5078: $? = 0
configure:5101: result: o
configure:5105: checking whether we are using the GNU C compiler
configure:5134: gcc -c  -I/usr/local/include conftest.c >&5
configure:5140: $? = 0
configure:5157: result: yes
configure:5162: checking whether gcc accepts -g
configure:5192: gcc -c -g -I/usr/local/include conftest.c >&5
configure:5198: $? = 0
configure:5297: result: yes
configure:5314: checking for gcc option to accept ISO C89
configure:5388: gcc  -c -g -O2 -I/usr/local/include conftest.c >&5
configure:5394: $? = 0
configure:5417: result: none needed
configure:5442: checking how to run the C preprocessor
configure:5482: gcc -E -I/usr/local/include conftest.c
configure:5488: $? = 0
configure:5519: gcc -E -I/usr/local/include conftest.c
conftest.c:16:28: error: ac_nonexistent.h: No such file or directory
configure:5525: $? = 1
configure: failed program was:
| /* confdefs.h.  */
| #define PACKAGE_NAME "R"
| #define PACKAGE_TARNAME "R"
| #define PACKAGE_VERSION "2.8.1"
| #define PACKAGE_STRING "R 2.8.1"
| #define PACKAGE_BUGREPORT "r-bugs at R-project.org"
| #define PACKAGE "R"
| #define VERSION "2.8.1"
| #define R_PLATFORM "x86_64-unknown-linux-gnu"
| #define R_CPU "x86_64"
| #define R_VENDOR "unknown"
| #define R_OS "linux-gnu"
| #define Unix 1
| #define R_ARCH ""
| /* end confdefs.h.  */
| #include <ac_nonexistent.h>
configure:5558: result: gcc -E
configure:5587: gcc -E -I/usr/local/include conftest.c
configure:5593: $? = 0
configure:5624: gcc -E -I/usr/local/include conftest.c
conftest.c:16:28: error: ac_nonexistent.h: No such file or directory
configure:5630: $? = 1
configure: failed program was:
| /* confdefs.h.  */
| #define PACKAGE_NAME "R"
| #define PACKAGE_TARNAME "R"
| #define PACKAGE_VERSION "2.8.1"
| #define PACKAGE_STRING "R 2.8.1"
| #define PACKAGE_BUGREPORT "r-bugs at R-project.org"
| #define PACKAGE "R"
| #define VERSION "2.8.1"
| #define R_PLATFORM "x86_64-unknown-linux-gnu"
| #define R_CPU "x86_64"
| #define R_VENDOR "unknown"
| #define R_OS "linux-gnu"
| #define Unix 1
| #define R_ARCH ""
| /* end confdefs.h.  */
| #include <ac_nonexistent.h>
configure:5669: checking whether gcc needs -traditional
configure:5711: result: no
configure:5723: checking how to run the C preprocessor
configure:5839: result: gcc -E
configure:5868: gcc -E -I/usr/local/include conftest.c
configure:5874: $? = 0
configure:5905: gcc -E -I/usr/local/include conftest.c
conftest.c:16:28: error: ac_nonexistent.h: No such file or directory
configure:5911: $? = 1
configure: failed program was:
| /* confdefs.h.  */
| #define PACKAGE_NAME "R"
| #define PACKAGE_TARNAME "R"
| #define PACKAGE_VERSION "2.8.1"
| #define PACKAGE_STRING "R 2.8.1"
| #define PACKAGE_BUGREPORT "r-bugs at R-project.org"
| #define PACKAGE "R"
| #define VERSION "2.8.1"
| #define R_PLATFORM "x86_64-unknown-linux-gnu"
| #define R_CPU "x86_64"
| #define R_VENDOR "unknown"
| #define R_OS "linux-gnu"
| #define Unix 1
| #define R_ARCH ""
| /* end confdefs.h.  */
| #include <ac_nonexistent.h>
configure:6018: checking for gfortran
configure:6034: found /usr/bin/gfortran
configure:6045: result: gfortran
configure:6170: checking for Fortran 77 compiler version
configure:6177: gfortran --version >&5
GNU Fortran (GCC) 4.1.2 20071124 (Red Hat 4.1.2-42)
Copyright (C) 2007 Free Software Foundation, Inc.

GNU Fortran comes with NO WARRANTY, to the extent permitted by law.
You may redistribute copies of GNU Fortran
under the terms of the GNU General Public License.
For more information about these matters, see the file named COPYING

configure:6180: $? = 0
configure:6187: gfortran -v >&5
Using built-in specs.
Target: x86_64-redhat-linux
Configured with: ../configure --prefix=/usr --mandir=/usr/share/man
--infodir=/usr/share/info --enable-shared --enable-threads=posix --enabl
e-checking=release --with-system-zlib --enable-__cxa_atexit
--disable-libunwind-exceptions --enable-libgcj-multifile
--enable-languages=c,c+
+,objc,obj-c++,java,fortran,ada --enable-java-awt=gtk --disable-dssi
--enable-plugin --with-java-home=/usr/lib/jvm/java-1.4.2-gcj-1.4.2.0/jr
e --with-cpu=generic --host=x86_64-redhat-linux
Thread model: posix
gcc version 4.1.2 20071124 (Red Hat 4.1.2-42)
configure:6190: $? = 0
configure:6197: gfortran -V >&5
gfortran: '-V' option must have argument
configure:6200: $? = 1
configure:6208: checking whether we are using the GNU Fortran 77 compiler
configure:6227: gfortran -c  conftest.F >&5
configure:6233: $? = 0
configure:6250: result: yes
configure:6256: checking whether gfortran accepts -g
configure:6273: gfortran -c -g conftest.f >&5
configure:6279: $? = 0
configure:6295: result: yes
configure:6384: checking for g++
configure:6414: result: no
configure:6384: checking for c++
configure:6414: result: no
configure:6384: checking for gpp
configure:6414: result: no
configure:6384: checking for aCC
configure:6414: result: no
configure:6384: checking for CC
configure:6414: result: no
configure:6384: checking for cxx
configure:6414: result: no
configure:6384: checking for cc++
configure:6414: result: no
configure:6384: checking for cl.exe
configure:6414: result: no
configure:6384: checking for FCC
configure:6414: result: no
configure:6384: checking for KCC
configure:6414: result: no
configure:6384: checking for RCC
configure:6414: result: no
configure:6384: checking for xlC_r
configure:6414: result: no
configure:6384: checking for xlC
configure:6414: result: no
configure:6442: checking for C++ compiler version
configure:6449: g++ --version >&5
./configure: line 6450: g++: command not found
configure:6452: $? = 127
configure:6459: g++ -v >&5
./configure: line 6460: g++: command not found
configure:6462: $? = 127
configure:6469: g++ -V >&5
./configure: line 6470: g++: command not found
configure:6472: $? = 127
configure:6475: checking whether we are using the GNU C++ compiler
configure:6504: g++ -c  -I/usr/local/include conftest.cpp >&5
./configure: line 6505: g++: command not found
configure:6510: $? = 127
configure: failed program was:
| /* confdefs.h.  */
| #define PACKAGE_NAME "R"
| #define PACKAGE_TARNAME "R"
| #define PACKAGE_VERSION "2.8.1"
| #define PACKAGE_STRING "R 2.8.1"
| #define PACKAGE_BUGREPORT "r-bugs at R-project.org"
| #define PACKAGE "R"
| #define VERSION "2.8.1"
| #define R_PLATFORM "x86_64-unknown-linux-gnu"
| #define R_CPU "x86_64"
| #define R_VENDOR "unknown"
| #define R_OS "linux-gnu"
| #define Unix 1
| #define R_ARCH ""
| /* end confdefs.h.  */
| 
| int
| main ()
| {
| #ifndef __GNUC__
|        choke me
| #endif
| 
|   ;
|   return 0;
| }
configure:6527: result: no
configure:6532: checking whether g++ accepts -g
configure:6562: g++ -c -g -I/usr/local/include conftest.cpp >&5
./configure: line 6563: g++: command not found
configure:6568: $? = 127
configure: failed program was:
| /* confdefs.h.  */
| #define PACKAGE_NAME "R"
| #define PACKAGE_TARNAME "R"
| #define PACKAGE_VERSION "2.8.1"
| #define PACKAGE_STRING "R 2.8.1"
| #define PACKAGE_BUGREPORT "r-bugs at R-project.org"
| #define PACKAGE "R"
| #define VERSION "2.8.1"
| #define R_PLATFORM "x86_64-unknown-linux-gnu"
| #define R_CPU "x86_64"
| #define R_VENDOR "unknown"
| #define R_OS "linux-gnu"
| #define Unix 1
| #define R_ARCH ""
| /* end confdefs.h.  */
| 
| int
| main ()
| {
| 
|   ;
|   return 0;
| }
configure:6600: g++ -c  -I/usr/local/include conftest.cpp >&5
./configure: line 6601: g++: command not found
configure:6606: $? = 127
configure: failed program was:
| /* confdefs.h.  */
| #define PACKAGE_NAME "R"
| #define PACKAGE_TARNAME "R"
| #define PACKAGE_VERSION "2.8.1"
| #define PACKAGE_STRING "R 2.8.1"
| #define PACKAGE_BUGREPORT "r-bugs at R-project.org"
| #define PACKAGE "R"
| #define VERSION "2.8.1"
| #define R_PLATFORM "x86_64-unknown-linux-gnu"
| #define R_CPU "x86_64"
| #define R_VENDOR "unknown"
| #define R_OS "linux-gnu"
| #define Unix 1
| #define R_ARCH ""
| /* end confdefs.h.  */
| 
| int
| main ()
| {
| 
|   ;
|   return 0;
| }
configure:6639: g++ -c -g -I/usr/local/include conftest.cpp >&5
./configure: line 6640: g++: command not found
configure:6645: $? = 127
configure: failed program was:
| /* confdefs.h.  */
| #define PACKAGE_NAME "R"
| #define PACKAGE_TARNAME "R"
| #define PACKAGE_VERSION "2.8.1"
| #define PACKAGE_STRING "R 2.8.1"
| #define PACKAGE_BUGREPORT "r-bugs at R-project.org"
| #define PACKAGE "R"
| #define VERSION "2.8.1"
| #define R_PLATFORM "x86_64-unknown-linux-gnu"
| #define R_CPU "x86_64"
| #define R_VENDOR "unknown"
| #define R_OS "linux-gnu"
| #define Unix 1
| #define R_ARCH ""
| /* end confdefs.h.  */
| 
| int
| main ()
| {
| 
|   ;
|   return 0;
| }
configure:6667: result: no
configure:6695: checking how to run the C++ preprocessor
configure:6731: g++ -E -I/usr/local/include conftest.cpp
./configure: line 6732: g++: command not found
configure:6737: $? = 127
configure: failed program was:
| /* confdefs.h.  */
| #define PACKAGE_NAME "R"
| #define PACKAGE_TARNAME "R"
| #define PACKAGE_VERSION "2.8.1"
| #define PACKAGE_STRING "R 2.8.1"
| #define PACKAGE_BUGREPORT "r-bugs at R-project.org"
| #define PACKAGE "R"
| #define VERSION "2.8.1"
| #define R_PLATFORM "x86_64-unknown-linux-gnu"
| #define R_CPU "x86_64"
| #define R_VENDOR "unknown"
| #define R_OS "linux-gnu"
| #define Unix 1
| #define R_ARCH ""
| /* end confdefs.h.  */
| #ifdef __STDC__
| # include <limits.h>
| #else
| # include <assert.h>
| #endif
|              Syntax error
configure:6731: g++ -E -I/usr/local/include conftest.cpp
./configure: line 6732: g++: command not found
configure:6737: $? = 127
configure: failed program was:
| /* confdefs.h.  */
| #define PACKAGE_NAME "R"
| #define PACKAGE_TARNAME "R"
| #define PACKAGE_VERSION "2.8.1"
| #define PACKAGE_STRING "R 2.8.1"
| #define PACKAGE_BUGREPORT "r-bugs at R-project.org"
| #define PACKAGE "R"
| #define VERSION "2.8.1"
| #define R_PLATFORM "x86_64-unknown-linux-gnu"
| #define R_CPU "x86_64"
| #define R_VENDOR "unknown"
| #define R_OS "linux-gnu"
| #define Unix 1
| #define R_ARCH ""
| /* end confdefs.h.  */
| #ifdef __STDC__
| # include <limits.h>
| #else
| # include <assert.h>
| #endif
|              Syntax error
configure:6731: /lib/cpp -I/usr/local/include conftest.cpp
cpp: error trying to exec 'cc1plus': execvp: No such file or directory
configure:6737: $? = 1
configure: failed program was:
| /* confdefs.h.  */
| #define PACKAGE_NAME "R"
| #define PACKAGE_TARNAME "R"
| #define PACKAGE_VERSION "2.8.1"
| #define PACKAGE_STRING "R 2.8.1"
| #define PACKAGE_BUGREPORT "r-bugs at R-project.org"
| #define PACKAGE "R"
| #define VERSION "2.8.1"
| #define R_PLATFORM "x86_64-unknown-linux-gnu"
| #define R_CPU "x86_64"
| #define R_VENDOR "unknown"
| #define R_OS "linux-gnu"
| #define Unix 1
| #define R_ARCH ""
| /* end confdefs.h.  */
| #ifdef __STDC__
| # include <limits.h>
| #else
| # include <assert.h>
| #endif
|              Syntax error
configure:6731: /lib/cpp -I/usr/local/include conftest.cpp
cpp: error trying to exec 'cc1plus': execvp: No such file or directory
configure:6737: $? = 1
configure: failed program was:
| /* confdefs.h.  */
| #define PACKAGE_NAME "R"
| #define PACKAGE_TARNAME "R"
| #define PACKAGE_VERSION "2.8.1"
| #define PACKAGE_STRING "R 2.8.1"
| #define PACKAGE_BUGREPORT "r-bugs at R-project.org"
| #define PACKAGE "R"
| #define VERSION "2.8.1"
| #define R_PLATFORM "x86_64-unknown-linux-gnu"
| #define R_CPU "x86_64"
| #define R_VENDOR "unknown"
| #define R_OS "linux-gnu"
| #define Unix 1
| #define R_ARCH ""
| /* end confdefs.h.  */
| #ifdef __STDC__
| # include <limits.h>
| #else
| # include <assert.h>
| #endif
|              Syntax error
configure:6807: result: /lib/cpp
configure:6836: /lib/cpp -I/usr/local/include conftest.cpp
cpp: error trying to exec 'cc1plus': execvp: No such file or directory
configure:6842: $? = 1
configure: failed program was:
| /* confdefs.h.  */
| #define PACKAGE_NAME "R"
| #define PACKAGE_TARNAME "R"
| #define PACKAGE_VERSION "2.8.1"
| #define PACKAGE_STRING "R 2.8.1"
| #define PACKAGE_BUGREPORT "r-bugs at R-project.org"
| #define PACKAGE "R"
| #define VERSION "2.8.1"
| #define R_PLATFORM "x86_64-unknown-linux-gnu"
| #define R_CPU "x86_64"
| #define R_VENDOR "unknown"
| #define R_OS "linux-gnu"
| #define Unix 1
| #define R_ARCH ""
| /* end confdefs.h.  */
| #ifdef __STDC__
| # include <limits.h>
| #else
| # include <assert.h>
| #endif
|              Syntax error
configure:6836: /lib/cpp -I/usr/local/include conftest.cpp
cpp: error trying to exec 'cc1plus': execvp: No such file or directory
configure:6842: $? = 1
configure: failed program was:
| /* confdefs.h.  */
| #define PACKAGE_NAME "R"
| #define PACKAGE_TARNAME "R"
| #define PACKAGE_VERSION "2.8.1"
| #define PACKAGE_STRING "R 2.8.1"
| #define PACKAGE_BUGREPORT "r-bugs at R-project.org"
| #define PACKAGE "R"
| #define VERSION "2.8.1"
| #define R_PLATFORM "x86_64-unknown-linux-gnu"
| #define R_CPU "x86_64"
| #define R_VENDOR "unknown"
| #define R_OS "linux-gnu"
| #define Unix 1
| #define R_ARCH ""
| /* end confdefs.h.  */
| #ifdef __STDC__
| # include <limits.h>
| #else
| # include <assert.h>
| #endif
|              Syntax error
configure:6904: error: C++ preprocessor "/lib/cpp" fails sanity check
See `config.log' for more details.

## ---------------- ##
## Cache variables. ##
## ---------------- ##

ac_cv_build=x86_64-unknown-linux-gnu
ac_cv_c_compiler_gnu=yes
ac_cv_cxx_compiler_gnu=no
ac_cv_env_BLAS_LIBS_set=
ac_cv_env_BLAS_LIBS_value=
ac_cv_env_CCC_set=
ac_cv_env_CCC_value=
ac_cv_env_CC_set=
ac_cv_env_CC_value=
ac_cv_env_CFLAGS_set=
ac_cv_env_CFLAGS_value=
ac_cv_env_CPICFLAGS_set=
ac_cv_env_CPICFLAGS_value=
ac_cv_env_CPPFLAGS_set=
ac_cv_env_CPPFLAGS_value=
ac_cv_env_CPP_set=
ac_cv_env_CPP_value=
ac_cv_env_CXXCPP_set=
ac_cv_env_CXXCPP_value=
ac_cv_env_CXXFLAGS_set=
ac_cv_env_CXXFLAGS_value=
ac_cv_env_CXXPICFLAGS_set=
ac_cv_env_CXXPICFLAGS_value=
ac_cv_env_CXX_set=
ac_cv_env_CXX_value=
ac_cv_env_DEFS_set=
ac_cv_env_DEFS_value=
ac_cv_env_DYLIB_LDFLAGS_set=
ac_cv_env_DYLIB_LDFLAGS_value=
ac_cv_env_DYLIB_LD_set=
ac_cv_env_DYLIB_LD_value=
ac_cv_env_F77_set=
ac_cv_env_F77_value=
ac_cv_env_FCFLAGS_set=
ac_cv_env_FCFLAGS_value=
ac_cv_env_FCPICFLAGS_set=
ac_cv_env_FCPICFLAGS_value=
ac_cv_env_FC_set=
ac_cv_env_FC_value=
ac_cv_env_FFLAGS_set=
ac_cv_env_FFLAGS_value=
ac_cv_env_FPICFLAGS_set=
ac_cv_env_FPICFLAGS_value=
ac_cv_env_JAVA_HOME_set=
ac_cv_env_JAVA_HOME_value=
ac_cv_env_LAPACK_LIBS_set=
ac_cv_env_LAPACK_LIBS_value=
ac_cv_env_LDFLAGS_set=
ac_cv_env_LDFLAGS_value=
ac_cv_env_LIBS_set=
ac_cv_env_LIBS_value=
ac_cv_env_LIBnn_set=
ac_cv_env_LIBnn_value=
ac_cv_env_MAIN_CFLAGS_set=
ac_cv_env_MAIN_CFLAGS_value=
ac_cv_env_MAIN_FFLAGS_set=
ac_cv_env_MAIN_FFLAGS_value=
ac_cv_env_MAIN_LDFLAGS_set=
ac_cv_env_MAIN_LDFLAGS_value=
ac_cv_env_MAIN_LD_set=
ac_cv_env_MAIN_LD_value=
ac_cv_env_MAKE_set=
ac_cv_env_MAKE_value=
ac_cv_env_OBJCFLAGS_set=
ac_cv_env_OBJCFLAGS_value=
ac_cv_env_OBJC_set=
ac_cv_env_OBJC_value=
ac_cv_env_R_BATCHSAVE_set=
ac_cv_env_R_BATCHSAVE_value=
ac_cv_env_R_BROWSER_set=
ac_cv_env_R_BROWSER_value=
ac_cv_env_R_PAPERSIZE_set=set
ac_cv_env_R_PAPERSIZE_value=letter
ac_cv_env_R_PRINTCMD_set=
ac_cv_env_R_PRINTCMD_value=
ac_cv_env_SAFE_FFLAGS_set=
ac_cv_env_SAFE_FFLAGS_value=
ac_cv_env_SHLIB_CFLAGS_set=
ac_cv_env_SHLIB_CFLAGS_value=
ac_cv_env_SHLIB_CXXLDFLAGS_set=
ac_cv_env_SHLIB_CXXLDFLAGS_value=
ac_cv_env_SHLIB_CXXLD_set=
ac_cv_env_SHLIB_CXXLD_value=
ac_cv_env_SHLIB_FCD_set=
ac_cv_env_SHLIB_FCD_value=
ac_cv_env_SHLIB_FCLDFLAGS_set=
ac_cv_env_SHLIB_FCLDFLAGS_value=
ac_cv_env_SHLIB_FFLAGS_set=
ac_cv_env_SHLIB_FFLAGS_value=
ac_cv_env_SHLIB_LDFLAGS_set=
ac_cv_env_SHLIB_LDFLAGS_value=
ac_cv_env_SHLIB_LD_set=
ac_cv_env_SHLIB_LD_value=
ac_cv_env_TCLTK_CPPFLAGS_set=
ac_cv_env_TCLTK_CPPFLAGS_value=
ac_cv_env_TCLTK_LIBS_set=
ac_cv_env_TCLTK_LIBS_value=
ac_cv_env_XMKMF_set=
ac_cv_env_XMKMF_value=
ac_cv_env_YACC_set=
ac_cv_env_YACC_value=
ac_cv_env_YFLAGS_set=
ac_cv_env_YFLAGS_value=
ac_cv_env_build_alias_set=
ac_cv_env_build_alias_value=
ac_cv_env_host_alias_set=
ac_cv_env_host_alias_value=
ac_cv_env_r_arch_set=
ac_cv_env_r_arch_value=
ac_cv_env_target_alias_set=
ac_cv_env_target_alias_value=
ac_cv_f77_compiler_gnu=yes
ac_cv_host=x86_64-unknown-linux-gnu
ac_cv_objext=o
ac_cv_path_EGREP='//bin/grep -E'
ac_cv_path_GETWD=//bin/pwd
ac_cv_path_GREP=//bin/grep
ac_cv_path_PAGER=/usr/bin/less
ac_cv_path_PERL=/usr/bin/perl
ac_cv_path_PKGCONF=/usr/bin/pkg-config
ac_cv_path_R_BROWSER=/usr/bin/open
ac_cv_path_R_GZIPCMD=//bin/gzip
ac_cv_path_R_PDFVIEWER=/usr/bin/open
ac_cv_path_R_UNZIPCMD=/usr/bin/unzip
ac_cv_path_R_ZIPCMD=/usr/bin/zip
ac_cv_path_SED=//bin/sed
ac_cv_path_install='/usr/bin/install -c'
ac_cv_prog_AR=ar
ac_cv_prog_AWK=gawk
ac_cv_prog_CPP='gcc -E'
ac_cv_prog_CXXCPP=/lib/cpp
ac_cv_prog_F77=gfortran
ac_cv_prog_ac_ct_CC=gcc
ac_cv_prog_cc_c89=
ac_cv_prog_cc_g=yes
ac_cv_prog_cxx_g=no
ac_cv_prog_f77_g=yes
ac_cv_prog_gcc_traditional=no
r_cv_prog_perl_v5=yes

## ----------------- ##
## Output variables. ##
## ----------------- ##

ACLOCAL='$(SHELL) $(top_srcdir)/tools/missing aclocal'
ALLOCA=''
AR='ar'
ARFLAGS='rc'
AUTOCONF='$(SHELL) $(top_srcdir)/tools/missing autoconf'
AUTOHEADER='$(SHELL) $(top_srcdir)/tools/missing autoheader'
AUTOMAKE='$(SHELL) $(top_srcdir)/tools/missing automake'
AWK='gawk'
BITMAP_LIBS=''
BLAS_LIBS0=''
BLAS_LIBS=''
BLAS_SHLIB_FALSE=''
BLAS_SHLIB_TRUE=''
BUILDDIR_IS_SRCDIR='yes'
BUILD_AQUA_FALSE=''
BUILD_AQUA_TRUE=''
BUILD_BZLIB_FALSE=''
BUILD_BZLIB_TRUE=''
BUILD_CC=''
BUILD_CYGWIN_FALSE=''
BUILD_CYGWIN_TRUE=''
BUILD_INCLUDED_LIBINTL=''
BUILD_JAVA14_FALSE=''
BUILD_JAVA14_TRUE=''
BUILD_LIBINTL_FALSE=''
BUILD_LIBINTL_TRUE=''
BUILD_PCRE_FALSE=''
BUILD_PCRE_TRUE=''
BUILD_R=''
BUILD_XDR_FALSE=''
BUILD_XDR_TRUE=''
BUILD_ZLIB_FALSE=''
BUILD_ZLIB_TRUE=''
CAIRO_CPPFLAGS=''
CAIRO_LIBS=''
CATOBJEXT=''
CC='gcc'
CFLAGS='-g -O2'
CFLAG_VISIBILITY=''
COMPILE_FORTRAN_DOUBLE_COMPLEX_FALSE=''
COMPILE_FORTRAN_DOUBLE_COMPLEX_TRUE=''
CPICFLAGS=''
CPP='gcc -E'
CPPFLAGS='-I/usr/local/include'
CROSS_COMPILING_FALSE=''
CROSS_COMPILING_TRUE=''
CXX='g++'
CXXCPP='/lib/cpp'
CXXFLAGS=''
CXXPICFLAGS=''
C_VISIBILITY=''
DATADIRNAME=''
DEFS=''
DSYMUTIL=''
DUMPBIN=''
DVIPS='false'
DYLIB_EXT=''
DYLIB_LD=''
DYLIB_LDFLAGS=''
DYLIB_UNDEFINED_ALLOWED_FALSE=''
DYLIB_UNDEFINED_ALLOWED_TRUE=''
ECHO_C=''
ECHO_N='-n'
ECHO_T=''
EGREP='//bin/grep -E'
EXEEXT=''
F77='gfortran'
F77_VISIBILITY=''
FC=''
FCFLAGS=''
FCFLAGS_f90=''
FCFLAGS_f95=''
FCPICFLAGS=''
FFLAGS='-g -O2'
FGREP=''
FLIBS=''
FOUNDATION_CPPFLAGS=''
FOUNDATION_LIBS=''
FPICFLAGS=''
FW_VERSION=''
GENCAT=''
GETWD='//bin/pwd'
GLIBC21=''
GLIBC2=''
GMSGFMT=''
GMSGFMT_015=''
GREP='//bin/grep'
HAVE_ASPRINTF=''
HAVE_C99_COMPLEX=''
HAVE_FORTRAN_DOUBLE_COMPLEX=''
HAVE_POSIX_PRINTF=''
HAVE_SNPRINTF=''
HAVE_VISIBILITY=''
HAVE_WPRINTF=''
INSTALL_DATA='${INSTALL} -m 644'
INSTALL_INFO='$(PERL) $(top_srcdir)/tools/install-info.pl'
INSTALL_PROGRAM='${INSTALL}'
INSTALL_SCRIPT='${INSTALL}'
INSTOBJEXT=''
INTLBISON=''
INTLLIBS=''
INTLOBJS=''
INTL_LIBTOOL_SUFFIX_PREFIX=''
INTL_MACOSX_LIBS=''
JAR=''
JAVA=''
JAVAC14=''
JAVAC=''
JAVAH=''
JAVA_CPPFLAGS0=''
JAVA_HOME=''
JAVA_LD_LIBRARY_PATH=''
JAVA_LIBS0=''
LAPACK_LDFLAGS=''
LAPACK_LIBS=''
LATEX='false'
LD=''
LDFLAGS='-L/usr/local/lib64'
LIBICONV=''
LIBINTL=''
LIBM=''
LIBMULTITHREAD=''
LIBOBJS=''
LIBPTH=''
LIBR=''
LIBR_LDFLAGS=''
LIBS=''
LIBTHREAD=''
LIBTOOL=''
LIBTOOL_DEPS=''
LIBnn='lib64'
LN_S='ln -s'
LTLIBICONV=''
LTLIBINTL=''
LTLIBMULTITHREAD=''
LTLIBOBJS=''
LTLIBPTH=''
LTLIBTHREAD=''
MAINTAINER_MODE_FALSE=''
MAINTAINER_MODE_TRUE='#'
MAIN_CFLAGS=''
MAIN_FFLAGS=''
MAIN_LD=''
MAIN_LDFLAGS=''
MAJ_MIN_VERSION='2.8'
MAKE='make'
MAKEINDEX='false'
MAKEINFO='false'
MSGFMT=''
MSGFMT_015=''
MSGMERGE=''
NM=''
NMEDIT=''
OBJC=''
OBJCFLAGS=''
OBJCXX=''
OBJCXXFLAGS=''
OBJC_LIBS=''
OBJEXT='o'
OSF_SH_BUG=''
PACKAGE='R'
PACKAGE_BUGREPORT='r-bugs at R-project.org'
PACKAGE_NAME='R'
PACKAGE_STRING='R 2.8.1'
PACKAGE_TARNAME='R'
PACKAGE_VERSION='2.8.1'
PAGER='/usr/bin/less'
PAPERCONF=''
PATH_SEPARATOR=':'
PDFLATEX='false'
PDFTEX='false'
PERL='/usr/bin/perl'
PKGCONF='/usr/bin/pkg-config'
POSUB=''
PRI_MACROS_BROKEN=''
RANLIB=''
RBLAS_LDFLAGS=''
READLINE_LIBS=''
RLAPACK_LDFLAGS=''
RMATH_HAVE_EXPM1=''
RMATH_HAVE_LOG1P=''
RMATH_HAVE_WORKING_LOG1P=''
R_ARCH=''
R_BATCHSAVE=''
R_BROWSER='/usr/bin/open'
R_DEFS=''
R_GZIPCMD='//bin/gzip'
R_JAVA_LD_LIBRARY_PATH=''
R_LD_LIBRARY_PATH=''
R_MODULES=''
R_OS='linux-gnu'
R_OSTYPE='unix'
R_PAPERSIZE='letter'
R_PDFVIEWER='/usr/bin/open'
R_PLATFORM='x86_64-unknown-linux-gnu'
R_PRINTCMD=''
R_PROFILING=''
R_RD4DVI='ae'
R_RD4PDF='times,hyper'
R_UNZIPCMD='/usr/bin/unzip'
R_XTRA_CFLAGS=''
R_XTRA_CPPFLAGS2='-I$(R_INCLUDE_DIR)'
R_XTRA_CPPFLAGS=''
R_XTRA_CXXFLAGS=''
R_XTRA_FFLAGS=''
R_XTRA_LIBS=''
R_ZIPCMD='/usr/bin/zip'
SAFE_FFLAGS=''
SED='//bin/sed'
SET_MAKE=''
SHELL='/bin/sh'
SHLIB_CFLAGS=''
SHLIB_CXXFLAGS=''
SHLIB_CXXLD=''
SHLIB_CXXLDFLAGS=''
SHLIB_EXT=''
SHLIB_FCD=''
SHLIB_FCLD=''
SHLIB_FCLDFLAGS=''
SHLIB_FFLAGS=''
SHLIB_LD=''
SHLIB_LDFLAGS=''
SHLIB_LIBADD=''
STRIP=''
SUPPORT_MBCS=''
SUPPORT_UTF8=''
TAR='tar'
TCLTK_CPPFLAGS=''
TCLTK_LIBS=''
TCL_CONFIG=''
TEX='false'
TEXI2DVI='false'
TIFF_LIBS=''
TK_CONFIG=''
USE_EXPORTFILES_FALSE=''
USE_EXPORTFILES_TRUE=''
USE_EXTERNAL_BLAS_FALSE=''
USE_EXTERNAL_BLAS_TRUE=''
USE_EXTERNAL_LAPACK_FALSE=''
USE_EXTERNAL_LAPACK_TRUE=''
USE_ICU=''
USE_INCLUDED_LIBINTL=''
USE_MMAP_ZLIB_FALSE=''
USE_MMAP_ZLIB_TRUE=''
USE_NLS=''
USE_NLS_FALSE=''
USE_NLS_TRUE=''
USE_RECOMMENDED_PACKAGES_FALSE=''
USE_RECOMMENDED_PACKAGES_TRUE=''
USE_VECLIB_G95FIX_FALSE=''
USE_VECLIB_G95FIX_TRUE=''
VERSION='2.8.1'
WANT_R_FRAMEWORK_FALSE=''
WANT_R_FRAMEWORK_TRUE='#'
WANT_R_SHLIB_FALSE=''
WANT_R_SHLIB_TRUE='#'
WANT_R_STATIC_FALSE=''
WANT_R_STATIC_TRUE='#'
WOE32DLL=''
XGETTEXT=''
XGETTEXT_015=''
XMKMF=''
XTRA_INTL_CPPFLAGS=''
X_CFLAGS=''
X_EXTRA_LIBS=''
X_LIBS=''
X_PRE_LIBS=''
YACC='yacc'
YFLAGS=''
ac_ct_CC='gcc'
ac_ct_CXX=''
ac_ct_DUMPBIN=''
ac_ct_F77=''
ac_ct_FC=''
ac_ct_OBJC=''
bindir='${exec_prefix}/bin'
build='x86_64-unknown-linux-gnu'
build_alias=''
build_cpu='x86_64'
build_os='linux-gnu'
build_vendor='unknown'
config_opts=' '\''--with-x=no'\'' '\''--with-readline=no'\''
'\''R_PAPERSIZE=letter'\'''
datadir='${datarootdir}'
datarootdir='${prefix}/share'
docdir='${datarootdir}/doc/${PACKAGE_TARNAME}'
dvidir='${docdir}'
exec_prefix='NONE'
host='x86_64-unknown-linux-gnu'
host_alias=''
host_cpu='x86_64'
host_os='linux-gnu'
host_vendor='unknown'
htmldir='${docdir}'
includedir='${prefix}/include'
infodir='${datarootdir}/info'
libdir='${exec_prefix}/${LIBnn}'
libexecdir='${exec_prefix}/libexec'
localedir='${datarootdir}/locale'
localstatedir='${prefix}/var'
lt_ECHO='echo'
mandir='${datarootdir}/man'
mkdir_p=''
oldincludedir='/usr/include'
pdfdir='${docdir}'
prefix='NONE'
program_transform_name='s,x,x,'
psdir='${docdir}'
r_arch=''
rdocdir='${rhome}/doc'
rincludedir='${rhome}/include'
rsharedir='${rhome}/share'
sbindir='${exec_prefix}/sbin'
sharedstatedir='${prefix}/com'
shlibpath_var=''
striplib=''
stripstaticlib=''
sysconfdir='${prefix}/etc'
target_alias=''
use_aqua=''
use_tcltk=''

## ------------------- ##
## File substitutions. ##
## ------------------- ##

r_cc_lo_rules_frag=''
r_cc_rules_frag=''
r_cxx_rules_frag=''
r_objc_rules_frag=''

## ----------- ##
## confdefs.h. ##
## ----------- ##

#define PACKAGE_NAME "R"
#define PACKAGE_TARNAME "R"
#define PACKAGE_VERSION "2.8.1"
#define PACKAGE_STRING "R 2.8.1"
#define PACKAGE_BUGREPORT "r-bugs at R-project.org"
#define PACKAGE "R"
#define VERSION "2.8.1"
#define R_PLATFORM "x86_64-unknown-linux-gnu"
#define R_CPU "x86_64"
#define R_VENDOR "unknown"
#define R_OS "linux-gnu"
#define Unix 1
#define R_ARCH ""

configure: exit 1
[root at ip-216-55-136-29 R-2.8.1]# 
[root at ip-216-55-136-29 R-2.8.1]# 
[root at ip-216-55-136-29 R-2.8.1]#


From p.dalgaard at biostat.ku.dk  Sat Feb 21 23:25:30 2009
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sat, 21 Feb 2009 23:25:30 +0100
Subject: [Rd] Install failure (PR#13545)
In-Reply-To: <20090221212509.F0944282C76F@mail.pubhealth.ku.dk>
References: <20090221212509.F0944282C76F@mail.pubhealth.ku.dk>
Message-ID: <49A07F5A.6070508@biostat.ku.dk>

bob at spltrak.com wrote:
> Hello:
> Encountered a problem installing R on
> CentOS release 5.2
> 
>  This is a 64bit OS
> I need to know if this will work on this server or do I need to change OS>
> 
> Thanks
> Bob
> 
> I downloaded the source ( R-2.8.1.tar.gz ) due to no release being available
> for CentOS.
> My ./configure --with-x=no --with-readline=no R_PAPERSIZE='letter'

And the problem is? (Failure to compile conftest.c is not necessarily a 
problem. Configure deliberately uses non-compilable files in a number of 
places.)

What was the final result of running configure?

(Please don't file as bugs in R issues when you are not sure that they 
are.)


> Failed:
> ./configure --with-x=no --with-readline=no R_PAPERSIZE='letter'
> 195 lines deleted from log
> configure:5105: checking whether we are using the GNU C compiler
> configure:5134: gcc -c  -I/usr/local/include conftest.c >&5
> configure:5140: $? = 0
> configure:5157: result: yes
> configure:5162: checking whether gcc accepts -g
> configure:5192: gcc -c -g -I/usr/local/include conftest.c >&5
> configure:5198: $? = 0
> configure:5297: result: yes
> configure:5314: checking for gcc option to accept ISO C89
> configure:5388: gcc  -c -g -O2 -I/usr/local/include conftest.c >&5
> configure:5394: $? = 0
> configure:5417: result: none needed
> configure:5442: checking how to run the C preprocessor
> configure:5482: gcc -E -I/usr/local/include conftest.c
> configure:5488: $? = 0
> configure:5519: gcc -E -I/usr/local/include conftest.c
> conftest.c:16:28: error: ac_nonexistent.h: No such file or directory
> configure:5525: $? = 1
> configure: failed program was:
> | /* confdefs.h.  */
> | #define PACKAGE_NAME "R"
> | #define PACKAGE_TARNAME "R"
> | #define PACKAGE_VERSION "2.8.1"
...etc...

-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From dutangc at gmail.com  Sun Feb 22 14:44:27 2009
From: dutangc at gmail.com (Christophe Dutang)
Date: Sun, 22 Feb 2009 14:44:27 +0100
Subject: [Rd] R tutorial
Message-ID: <69D43B64-5E8B-4A5E-8911-59BF9771DDB9@gmail.com>

Dear all,

I have just found a 'good' tutorial R for datamining. I think it  
should be on the contributed docs.
http://cran.r-project.org/other-docs.html

Here is the link
http://www.liaad.up.pt/~ltorgo/DataMiningWithR/

What do you think?

Kind regards

Christophe


--
Christophe Dutang
Ph. D. student at ISFA, Lyon, France
website: http://dutangc.free.fr


From macrakis at alum.mit.edu  Sun Feb 22 20:15:18 2009
From: macrakis at alum.mit.edu (macrakis at alum.mit.edu)
Date: Sun, 22 Feb 2009 20:15:18 +0100 (CET)
Subject: [Rd] 'unique' error message is printed despite silent=TRUE
	(PR#13547)
Message-ID: <20090222191519.17912282C76C@mail.pubhealth.ku.dk>

In 2.8.0/Windows Vista:

When 'unique' gives a type error message, it prints out even if errors
are being caught:

> try(unique(quote(hello)),silent=TRUE)
hello

This comes from the .Internal unique routine:

> try(.Internal(unique(quote(hello),NULL,NULL)),silent=TRUE)
hello

I guess it is using the internal equivalent of print rather than the
internal equivalent of stop.

           -s


From murdoch at stats.uwo.ca  Sun Feb 22 21:06:03 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 22 Feb 2009 15:06:03 -0500
Subject: [Rd] 'unique' error message is printed despite
	silent=TRUE	(PR#13547)
In-Reply-To: <20090222191519.17912282C76C@mail.pubhealth.ku.dk>
References: <20090222191519.17912282C76C@mail.pubhealth.ku.dk>
Message-ID: <49A1B02B.3020607@stats.uwo.ca>

On 22/02/2009 2:15 PM, macrakis at alum.mit.edu wrote:
> In 2.8.0/Windows Vista:
> 
> When 'unique' gives a type error message, it prints out even if errors
> are being caught:
> 
>> try(unique(quote(hello)),silent=TRUE)
> hello
> 
> This comes from the .Internal unique routine:
> 
>> try(.Internal(unique(quote(hello),NULL,NULL)),silent=TRUE)
> hello
> 
> I guess it is using the internal equivalent of print rather than the
> internal equivalent of stop.

Still there in R-devel; I'll see if I can fix it.

Duncan Murdoch


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Sun Feb 22 21:06:03 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Sun, 22 Feb 2009 21:06:03 +0100
Subject: [Rd] 'unique' error message is printed despite
	silent=TRUE	(PR#13547)
In-Reply-To: <20090222191519.17912282C76C@mail.pubhealth.ku.dk>
References: <20090222191519.17912282C76C@mail.pubhealth.ku.dk>
Message-ID: <49A1B02B.4060903@idi.ntnu.no>

macrakis at alum.mit.edu wrote:
> In 2.8.0/Windows Vista:
>
> When 'unique' gives a type error message, it prints out even if errors
> are being caught:
>
>   
>> try(unique(quote(hello)),silent=TRUE)
>>     
> hello
>
> This comes from the .Internal unique routine:
>
>   
>> try(.Internal(unique(quote(hello),NULL,NULL)),silent=TRUE)
>>     
> hello
>
> I guess it is using the internal equivalent of print rather than the
> internal equivalent of stop.
>
>   
line 454+ in src/main/unique.c:

    if (!isVector(x)) {
    PrintValue(x);
    error(_("%s() applies only to vectors"),
          (PRIMVAL(op) == 0 ? "duplicated" : "unique"));
    }

in your example, quote() produces a non-vector, hence the output before
the error message.

vQ


From p.dalgaard at biostat.ku.dk  Sun Feb 22 21:16:18 2009
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Sun, 22 Feb 2009 21:16:18 +0100
Subject: [Rd] 'unique' error message is printed despite
	silent=TRUE	(PR#13547)
In-Reply-To: <20090222191519.17912282C76C@mail.pubhealth.ku.dk>
References: <20090222191519.17912282C76C@mail.pubhealth.ku.dk>
Message-ID: <49A1B292.1070908@biostat.ku.dk>

macrakis at alum.mit.edu wrote:
> In 2.8.0/Windows Vista:
> 
> When 'unique' gives a type error message, it prints out even if errors
> are being caught:
> 
>> try(unique(quote(hello)),silent=TRUE)
> hello
> 
> This comes from the .Internal unique routine:
> 
>> try(.Internal(unique(quote(hello),NULL,NULL)),silent=TRUE)
> hello
> 
> I guess it is using the internal equivalent of print rather than the
> internal equivalent of stop.
> 

silent=TRUE is a red herring (this has nothing to do with try()).

However, inside do_duplicated (unique.c) we have

     if (!isVector(x)) {
	PrintValue(x);
	error(_("%s() applies only to vectors"),
	      (PRIMVAL(op) == 0 ? "duplicated" : "unique"));
     }

This is due to

------------------------------------------------------------------------
r32306 | ripley | 2004-12-23 22:06:27 +0100 (Thu, 23 Dec 2004) | 2 lines

Apparently unique/duplicated are supposed to work on NULL, despite their 
help!

...which makes little sense to explain the PrintValue(x). I suspect this 
is a debugging printout that was inadvertently left in.


-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From murdoch at stats.uwo.ca  Sun Feb 22 21:25:26 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 22 Feb 2009 15:25:26 -0500
Subject: [Rd] 'unique' error message is printed
	despite	silent=TRUE	(PR#13547)
In-Reply-To: <49A1B292.1070908@biostat.ku.dk>
References: <20090222191519.17912282C76C@mail.pubhealth.ku.dk>
	<49A1B292.1070908@biostat.ku.dk>
Message-ID: <49A1B4B6.40400@stats.uwo.ca>

On 22/02/2009 3:16 PM, Peter Dalgaard wrote:
> macrakis at alum.mit.edu wrote:
>> In 2.8.0/Windows Vista:
>>
>> When 'unique' gives a type error message, it prints out even if errors
>> are being caught:
>>
>>> try(unique(quote(hello)),silent=TRUE)
>> hello
>>
>> This comes from the .Internal unique routine:
>>
>>> try(.Internal(unique(quote(hello),NULL,NULL)),silent=TRUE)
>> hello
>>
>> I guess it is using the internal equivalent of print rather than the
>> internal equivalent of stop.
>>
> 
> silent=TRUE is a red herring (this has nothing to do with try()).
> 
> However, inside do_duplicated (unique.c) we have
> 
>      if (!isVector(x)) {
> 	PrintValue(x);
> 	error(_("%s() applies only to vectors"),
> 	      (PRIMVAL(op) == 0 ? "duplicated" : "unique"));
>      }
> 
> This is due to
> 
> ------------------------------------------------------------------------
> r32306 | ripley | 2004-12-23 22:06:27 +0100 (Thu, 23 Dec 2004) | 2 lines
> 
> Apparently unique/duplicated are supposed to work on NULL, despite their 
> help!
> 
> ...which makes little sense to explain the PrintValue(x). I suspect this 
> is a debugging printout that was inadvertently left in.

Now removed.

Duncan Murdoch


From bates at stat.wisc.edu  Sun Feb 22 22:05:07 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 22 Feb 2009 15:05:07 -0600
Subject: [Rd] [SoC09-Info] An IPopt interface for R
Message-ID: <40e66e0b0902221305s768d6e77u608f04fcfb83b8d5@mail.gmail.com>

There have been several messages on R-devel mentioning the interior
point optimization software Ipopt, https://projects.coin-op/Ipopt/.
This C++ library is released under a license called the Common Public
License.

I have two questions that readers of R-devel may be able to answer.

1) Would creating an Ipopt interface for R be duplicating existing
efforts?  That is, has someone already done so or is already working
on this project.

2) Could a package incorporating Ipopt be released under some version
of the GPL or LGPL?

Assuming that the answers to those questions are no and yes, I would
be willing to mentor a student in a Google Summer of Code project to
create such a package.  However, I don't have a whole lot of time to
do so and would not object at all if another potential mentor, or
perhaps a co-mentor, were to volunteer.  Failing that I will create an
application, including a programming exercise.


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Sun Feb 22 22:08:05 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Sun, 22 Feb 2009 22:08:05 +0100
Subject: [Rd] 'unique' error message is printed
	despite	silent=TRUE	(PR#13547)
In-Reply-To: <49A1B292.1070908@biostat.ku.dk>
References: <20090222191519.17912282C76C@mail.pubhealth.ku.dk>
	<49A1B292.1070908@biostat.ku.dk>
Message-ID: <49A1BEB5.6050701@idi.ntnu.no>

Peter Dalgaard wrote:
> macrakis at alum.mit.edu wrote:
>>

<snip>

>>> try(.Internal(unique(quote(hello),NULL,NULL)),silent=TRUE)
>> hello
>>
>> I guess it is using the internal equivalent of print rather than the
>> internal equivalent of stop.
>>
>
> silent=TRUE is a red herring (this has nothing to do with try()).
>
> However, inside do_duplicated (unique.c) we have
>
>     if (!isVector(x)) {
>     PrintValue(x);
>     error(_("%s() applies only to vectors"),
>           (PRIMVAL(op) == 0 ? "duplicated" : "unique"));
>     }
>
> This is due to
>
> ------------------------------------------------------------------------
> r32306 | ripley | 2004-12-23 22:06:27 +0100 (Thu, 23 Dec 2004) | 2 lines
>
> Apparently unique/duplicated are supposed to work on NULL, despite
> their help!
>
> ...which makes little sense to explain the PrintValue(x). I suspect
> this is a debugging printout that was inadvertently left in.

hmm, why wouldn't you use something like

    DEBUG(x)

with DEBUG being a macro defined so that it's replacement is void unless
a specific flag or environment variable is set specifically for the
purpose of debugging?  you would then avoid confusing users' code just
because one PrintValue has been inadvertently left in the sources.


vQ


From murdoch at stats.uwo.ca  Sun Feb 22 22:18:55 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 22 Feb 2009 16:18:55 -0500
Subject: [Rd] 'unique' error message is
	printed	despite	silent=TRUE	(PR#13547)
In-Reply-To: <49A1BEB5.6050701@idi.ntnu.no>
References: <20090222191519.17912282C76C@mail.pubhealth.ku.dk>	<49A1B292.1070908@biostat.ku.dk>
	<49A1BEB5.6050701@idi.ntnu.no>
Message-ID: <49A1C13F.5090109@stats.uwo.ca>

On 22/02/2009 4:08 PM, Wacek Kusnierczyk wrote:
> Peter Dalgaard wrote:
>> macrakis at alum.mit.edu wrote:
> 
> <snip>
> 
>>>> try(.Internal(unique(quote(hello),NULL,NULL)),silent=TRUE)
>>> hello
>>>
>>> I guess it is using the internal equivalent of print rather than the
>>> internal equivalent of stop.
>>>
>> silent=TRUE is a red herring (this has nothing to do with try()).
>>
>> However, inside do_duplicated (unique.c) we have
>>
>>     if (!isVector(x)) {
>>     PrintValue(x);
>>     error(_("%s() applies only to vectors"),
>>           (PRIMVAL(op) == 0 ? "duplicated" : "unique"));
>>     }
>>
>> This is due to
>>
>> ------------------------------------------------------------------------
>> r32306 | ripley | 2004-12-23 22:06:27 +0100 (Thu, 23 Dec 2004) | 2 lines
>>
>> Apparently unique/duplicated are supposed to work on NULL, despite
>> their help!
>>
>> ...which makes little sense to explain the PrintValue(x). I suspect
>> this is a debugging printout that was inadvertently left in.
> 
> hmm, why wouldn't you use something like
> 
>     DEBUG(x)
> 
> with DEBUG being a macro defined so that it's replacement is void unless
> a specific flag or environment variable is set specifically for the
> purpose of debugging?  you would then avoid confusing users' code just
> because one PrintValue has been inadvertently left in the sources.

But then we'd confuse developers, who would see a huge dump of messages
from every other debugging session, when they just wanted to see their 
own, and who would be forced to wade through leftover never-used 
DEBUG(x) calls in code when they were reading the source.

This is not a common error:  as far as I know, there are no other 
unintentional PrintValue calls anywhere in the source.  So I think the 
current system (just take them out before committing) is working.

Duncan Murdoch


From murdoch at stats.uwo.ca  Sun Feb 22 22:20:23 2009
From: murdoch at stats.uwo.ca (murdoch at stats.uwo.ca)
Date: Sun, 22 Feb 2009 22:20:23 +0100 (CET)
Subject: [Rd] 'unique' error message is
	printed	despite	silent=TRUE	(PR#13547)
Message-ID: <20090222212023.8E622282EFF0@mail.pubhealth.ku.dk>

On 22/02/2009 4:08 PM, Wacek Kusnierczyk wrote:
> Peter Dalgaard wrote:
>> macrakis at alum.mit.edu wrote:
> 
> <snip>
> 
>>>> try(.Internal(unique(quote(hello),NULL,NULL)),silent=TRUE)
>>> hello
>>>
>>> I guess it is using the internal equivalent of print rather than the
>>> internal equivalent of stop.
>>>
>> silent=TRUE is a red herring (this has nothing to do with try()).
>>
>> However, inside do_duplicated (unique.c) we have
>>
>>     if (!isVector(x)) {
>>     PrintValue(x);
>>     error(_("%s() applies only to vectors"),
>>           (PRIMVAL(op) == 0 ? "duplicated" : "unique"));
>>     }
>>
>> This is due to
>>
>> ------------------------------------------------------------------------
>> r32306 | ripley | 2004-12-23 22:06:27 +0100 (Thu, 23 Dec 2004) | 2 lines
>>
>> Apparently unique/duplicated are supposed to work on NULL, despite
>> their help!
>>
>> ...which makes little sense to explain the PrintValue(x). I suspect
>> this is a debugging printout that was inadvertently left in.
> 
> hmm, why wouldn't you use something like
> 
>     DEBUG(x)
> 
> with DEBUG being a macro defined so that it's replacement is void unless
> a specific flag or environment variable is set specifically for the
> purpose of debugging?  you would then avoid confusing users' code just
> because one PrintValue has been inadvertently left in the sources.

But then we'd confuse developers, who would see a huge dump of messages
from every other debugging session, when they just wanted to see their 
own, and who would be forced to wade through leftover never-used 
DEBUG(x) calls in code when they were reading the source.

This is not a common error:  as far as I know, there are no other 
unintentional PrintValue calls anywhere in the source.  So I think the 
current system (just take them out before committing) is working.

Duncan Murdoch


From bates at stat.wisc.edu  Sun Feb 22 22:34:07 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 22 Feb 2009 15:34:07 -0600
Subject: [Rd] R tutorial
In-Reply-To: <69D43B64-5E8B-4A5E-8911-59BF9771DDB9@gmail.com>
References: <69D43B64-5E8B-4A5E-8911-59BF9771DDB9@gmail.com>
Message-ID: <40e66e0b0902221334h5254c5efnfef0752be48badc3@mail.gmail.com>

On Sun, Feb 22, 2009 at 7:44 AM, Christophe Dutang <dutangc at gmail.com> wrote:
> Dear all,

> I have just found a 'good' tutorial R for datamining. I think it should be
> on the contributed docs.
> http://cran.r-project.org/other-docs.html

> Here is the link
> http://www.liaad.up.pt/~ltorgo/DataMiningWithR/

> What do you think?

A quick glance indicates that the last updates were in 2003.   Most
introductory material from then would still apply but details may have
changed and often there are now better ways of doing things than there
were then.

Do you know if the author has plans for updating the book at all?


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Sun Feb 22 22:38:01 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Sun, 22 Feb 2009 22:38:01 +0100
Subject: [Rd] 'unique' error message is
	printed	despite	silent=TRUE	(PR#13547)
In-Reply-To: <49A1C13F.5090109@stats.uwo.ca>
References: <20090222191519.17912282C76C@mail.pubhealth.ku.dk>	<49A1B292.1070908@biostat.ku.dk>
	<49A1BEB5.6050701@idi.ntnu.no> <49A1C13F.5090109@stats.uwo.ca>
Message-ID: <49A1C5B9.9050905@idi.ntnu.no>

Duncan Murdoch wrote:
>
>>
>> hmm, why wouldn't you use something like
>>
>>     DEBUG(x)
>>
>> with DEBUG being a macro defined so that it's replacement is void unless
>> a specific flag or environment variable is set specifically for the
>> purpose of debugging?  you would then avoid confusing users' code just
>> because one PrintValue has been inadvertently left in the sources.
>
> But then we'd confuse developers, who would see a huge dump of messages
> from every other debugging session, when they just wanted to see their
> own, and who would be forced to wade through leftover never-used
> DEBUG(x) calls in code when they were reading the source.
>

my point was not that such DEBUG statements should be left there in the
code for all eternity.  to the contrary, their role would be quite the
same as that of the PrintValue discussed here.  it would, however, be
easier to switch between printing and not printing such debugging
messages, and also easier to spot DEBUG statements inadvertently left in
the code. 

> This is not a common error:  as far as I know, there are no other
> unintentional PrintValue calls anywhere in the source.  So I think the
> current system (just take them out before committing) is working.

grep --include=*.c -R '\bPrintValue\b' src | wc -l

reports 21 occurrences of PrintValue, though of course i cannot say
anything about their being intentional or not unless i examine the
sources.  if they were DEBUGs, you'd know for sure they're not supposed
to stay there in a release version.

it's just to wish that those who introduce debugging PrintValues
examined diffs carefully before their code is released.  given the size
of r sources (and their fairly ad hoc shape here and there), few others
than the author will know for sure whether the PrintValue is a debugger
or not?  apparently, no one has noticed in this case.  were it DEBUG
instead of PrintValue, it would suffice to run a grep to catch it.

vQ


From macrakis at alum.mit.edu  Sun Feb 22 22:50:13 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Sun, 22 Feb 2009 16:50:13 -0500
Subject: [Rd] [R] Semantics of sequences in R
In-Reply-To: <49A1BFC7.9060503@stats.uwo.ca>
References: <8b356f880902221242r47cdb138w9b1ac05cc5e5e317@mail.gmail.com>
	<49A1BFC7.9060503@stats.uwo.ca>
Message-ID: <8b356f880902221350q4a976bfr19b0d5b01a989250@mail.gmail.com>

On Sun, Feb 22, 2009 at 4:12 PM, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> I think this was posted to the wrong list, so my followup is going to
> R-devel.

OK.

> On 22/02/2009 3:42 PM, Stavros Macrakis wrote:
>>
>> Inspired by the exchange between Rolf Turner and Wacek Kusnierczyk, I
>> thought I'd clear up for myself the exact relationship among the
>> various sequence concepts in R, including not only generic vectors
>> (lists) and atomic vectors, but also pairlists, factor sequences,
>> date/time sequences, and difftime sequences.
>>
>> I tabulated type of sequence vs. property to see if I could make sense
>> of all this.  The properties I looked at were the predicates
>> is.{vector,list,pairlist}; whether various sequence operations (c,
>> rev, unique, sort, rle) can be used on objects of the various types,
>> and if relevant, whether they preserve the type of the input; and what
>> the length of class( as.XXX (1:2) ) is.
>>
>> Here are the results (code to reproduce at end of email):
>>
>>             numer list  plist fact  POSIXct difft
>> is.vector    TRUE  TRUE  FALSE FALSE FALSE   FALSE
>> is.list      FALSE TRUE  TRUE  FALSE FALSE   FALSE
>> is.pairlist  FALSE FALSE TRUE  FALSE FALSE   FALSE
>> c_keep?      TRUE  TRUE  FALSE FALSE TRUE    FALSE
>> rev_keep?    TRUE  TRUE  FALSE TRUE  TRUE    TRUE
>> unique_keep? TRUE  TRUE  "Err" TRUE  TRUE    FALSE
>> sort_keep?   TRUE  "Err" "Err" TRUE  TRUE    TRUE
>> rle_len      2     "Err" "Err" "Err" "Err"   "Err"
>>
>> Alas, this tabulation, rather than clarifying things for me, just
>> confused me more -- the diverse treatment of sequences by various
>> operations is all rather bewildering.
>
> But you are asking lots of different questions, so of course you should get
> different answers.  For example, the first three rows are behaving exactly
> as documented.

Yes, I wasn't questioning that.  This started out as an exploration of
Rolf's claim that "vectors can be considered to be lists", which I
think the table shows pretty clearly not to be true.  He did qualify
the claim with "At a certain level.", but I don't know what that level
is....

> (Perhaps the functions should have been designed
> differently, but a pretty-looking matrix isn't an argument for that. Give
> some examples of how the documented behaviour is causing problems.)

>From my own experience, and the experience of colleagues who have
tried to learn R, I can tell you that these idiosyncracies make
learning the system more difficult.  A "pretty-looking matrix" is a
reflection of an orthogonal design, which is generally considered to
be a good thing. Many of the missing operations are perfectly
meaningful and useful.

> ...But it may make more sense to completely hide pairlists,

I agree that the pairlist cases are the least interesting.

> (BTW, your description of your last row doesn't match what you did, as far as I can see.)

Yes, sorry, older draft....

>> Wouldn't it be easier to teach, learn, and use R if there were more
>> consistency in the treatment of sequences?
>
> Which ones in particular should change?  What should they change to? What
> will break when you do that?

In many cases, the orthogonal design is pretty straightforward.  And
in the cases where the operation is currently an error (e.g.
sort(list(...))), I'd hope that wouldn't break existing code. There
are certainly cases which would be hard to change without breaking
existing code....

> Generally R core members are reluctant to take on work just because someone
> else thinks it would be nice if they did.

I understand this principle quite well, having been a contributor to
other similar projects.  I was simply starting the discussion.  After
all, if the core group disagrees that the functions should be made
more orthogonal, it is a waste of my time to submit code.

>  If you want to do this, that's one thing,

I have already suggested code changes in some (pretty trivial) cases
-- see r-help Feb 6, 2009 6:17 PM "Operations on difftime (abs, /, c)"
-- but perhaps r-help was the wrong place to send them.  I will
forward to r-devel.  And I will be happy to work on some of the
consistency issues I've mentioned here.

             -s


From macrakis at alum.mit.edu  Sun Feb 22 22:51:49 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Sun, 22 Feb 2009 16:51:49 -0500
Subject: [Rd] Operations on difftime (abs, /, c)
In-Reply-To: <8b356f880902061517v66a364fenc2c0e7725ea6578c@mail.gmail.com>
References: <8b356f880902061517v66a364fenc2c0e7725ea6578c@mail.gmail.com>
Message-ID: <8b356f880902221351y7016e787pa8d27cdfdd57ad39@mail.gmail.com>

Forwarded from the r-help group -- r-devel seems more appropriate per
Duncan's recent email.

              -s

---------- Forwarded message ----------
From: Stavros Macrakis <macrakis at alum.mit.edu>
Date: Fri, Feb 6, 2009 at 6:17 PM
Subject: Operations on difftime (abs, /, c)
To: "r-help at r-project.org" <r-help at r-project.org>


Since both comparison and negation are well-defined for time
differences, I wonder why abs and division are not defined for class
difftime. This behavior is clearly documented on the man page:
"limited arithmetic is available on 'difftime' objects"; but why? Both
are natural, semantically sound, and useful operations and I see no
obvious reason that they should give an error:

     sec <- as.difftime(-3:3,units="secs")
     hour <- as.difftime(-3:3,units="hours")

     abs( sec ) => error  ... why not 3 2 1 0 1 2 3 secs?
     hour/sec => error   ... why not 3600, 3600, ... (dimensionless numbers)?

Of course, it is trivial to overload these operations for
difftime-class arguments:

     abs.difftime <- function(x) ifelse(x<0,-x,x)

    > abs(sec)
   [1] 3 2 1 0 1 2 3

   `/.difftime` <-
      function (e1, e2)
      {
       if (!inherits(e2, "difftime"))
     structure(unclass(e1)/e2, units = attr(e1, "units"), class = "difftime")
       else if (inherits(e1, "difftime"))
     as.numeric(e1,attr(e2, units = "units"))/as.numeric(e2)
       else
     stop("second argument of / cannot be a \"difftime\" object")    #
1/hour remains incorrect
      }

   > hour/sec
   [1] 3600 3600 3600  NaN 3600 3600 3600

Along the same lines, I don't understand why concatenation (c) should
strip the class of difftime, but not of POSIXt/ct:

    class( c(sec) ) => integer            <<< class and units
attribute are stripped
    class( c(sec,hour) ) => integer    <<< doesn't convert to common
unit, giving meaningless result
    class( c(Sys.time()) ) => "POSIXt" "POSIXct"

Again, c.difftime would be easy enough to define if it's the right thing to do.

So why wouldn't it be the right thing to do? Is there some semantic or
stylistic issue I'm missing here?

            -s


From Friedrich.Leisch at stat.uni-muenchen.de  Sun Feb 22 23:13:08 2009
From: Friedrich.Leisch at stat.uni-muenchen.de (Friedrich Leisch)
Date: Mon, 23 Feb 2009 09:13:08 +1100
Subject: [Rd] R tutorial
In-Reply-To: <69D43B64-5E8B-4A5E-8911-59BF9771DDB9@gmail.com>
References: <69D43B64-5E8B-4A5E-8911-59BF9771DDB9@gmail.com>
Message-ID: <18849.52724.439121.353724@ridcully.stat.uni-muenchen.de>

>>>>> On Sun, 22 Feb 2009 14:44:27 +0100,
>>>>> Christophe Dutang (CD) wrote:

  > Dear all,
  > I have just found a 'good' tutorial R for datamining. I think it  
  > should be on the contributed docs.
  > http://cran.r-project.org/other-docs.html

  > Here is the link
  > http://www.liaad.up.pt/~ltorgo/DataMiningWithR/

  > What do you think?

Looks intersting (although may be outdated as Doug already
mentioned). In any case, we don't simply "harvest" docs off the web,
we only put docs on CRAN which get sent to us by the original
authors. So if you want to see it on CRAN, please contact the author
(and perhaps ask for the status while doing so).

Best,
Fritz

-- 
-----------------------------------------------------------------------
Prof. Dr. Friedrich Leisch 

Institut f?r Statistik                          Tel: (+49 89) 2180 3165
Ludwig-Maximilians-Universit?t                  Fax: (+49 89) 2180 5308
Ludwigstra?e 33
D-80539 M?nchen                     http://www.statistik.lmu.de/~leisch
-----------------------------------------------------------------------
   Journal Computational Statistics --- http://www.springer.com/180 
          M?nchner R Kurse --- http://www.statistik.lmu.de/R


From murdoch at stats.uwo.ca  Sun Feb 22 23:58:41 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 22 Feb 2009 17:58:41 -0500
Subject: [Rd] 'unique' error message
	is	printed	despite	silent=TRUE	(PR#13547)
In-Reply-To: <49A1C5B9.9050905@idi.ntnu.no>
References: <20090222191519.17912282C76C@mail.pubhealth.ku.dk>	<49A1B292.1070908@biostat.ku.dk>	<49A1BEB5.6050701@idi.ntnu.no>
	<49A1C13F.5090109@stats.uwo.ca> <49A1C5B9.9050905@idi.ntnu.no>
Message-ID: <49A1D8A1.2070203@stats.uwo.ca>

On 22/02/2009 4:38 PM, Wacek Kusnierczyk wrote:
> Duncan Murdoch wrote:
>>> hmm, why wouldn't you use something like
>>>
>>>     DEBUG(x)
>>>
>>> with DEBUG being a macro defined so that it's replacement is void unless
>>> a specific flag or environment variable is set specifically for the
>>> purpose of debugging?  you would then avoid confusing users' code just
>>> because one PrintValue has been inadvertently left in the sources.
>> But then we'd confuse developers, who would see a huge dump of messages
>> from every other debugging session, when they just wanted to see their
>> own, and who would be forced to wade through leftover never-used
>> DEBUG(x) calls in code when they were reading the source.
>>
> 
> my point was not that such DEBUG statements should be left there in the
> code for all eternity.  to the contrary, their role would be quite the
> same as that of the PrintValue discussed here.  it would, however, be
> easier to switch between printing and not printing such debugging
> messages, and also easier to spot DEBUG statements inadvertently left in
> the code. 

Sorry, I misunderstood.  Yes, that might be handy.

The main problem is agreeing on what macros to write, and what should 
happen when the external flag is set. In my experience, people who are 
good at debugging have long-established idiosyncratic habits, and are 
just annoyed when things change.

For example, a number of people have suggested that compiles should 
switch to optimization level 0 when compiling for debugging.  This makes 
stepping through code easier, because (as far as I recall) variables 
aren't optimized out, code isn't rearranged, etc.  But it means some 
bugs change their behaviour:  and I really hate that.  So I wouldn't 
mind if it were possible to request that, but I'd want to make sure the 
default is to ask for debugging support without it:  I don't want to 
waste my time looking at a different program when I'm trying to track 
something down.

If we had DEBUG(x) which became PrintValue(x) when a certain flag was 
set, I probably wouldn't use it, because it requires two things:  set 
the flag as well as add the statement.  I'd find that just irritating.
(I rarely use PrintValue in any case:  most of the types of bugs I'm 
looking for need Rprintf or REprintf instead.  So we'd need at least 
three macros.)

>> This is not a common error:  as far as I know, there are no other
>> unintentional PrintValue calls anywhere in the source.  So I think the
>> current system (just take them out before committing) is working.
> 
> grep --include=*.c -R '\bPrintValue\b' src | wc -l
> 
> reports 21 occurrences of PrintValue, though of course i cannot say
> anything about their being intentional or not unless i examine the
> sources.  if they were DEBUGs, you'd know for sure they're not supposed
> to stay there in a release version.

I did a quick examination of the source and I think the ones that aren't 
commented out look intentional.  (I was following my rule 5 of 
debugging:  look for similar errors elsewhere.)

> it's just to wish that those who introduce debugging PrintValues
> examined diffs carefully before their code is released.  given the size
> of r sources (and their fairly ad hoc shape here and there), few others
> than the author will know for sure whether the PrintValue is a debugger
> or not?  apparently, no one has noticed in this case.  were it DEBUG
> instead of PrintValue, it would suffice to run a grep to catch it.

People who commit any changes should examine them carefully, and in 
general they do.  Sometimes things slip by.  In this case, the slip was 
there for 5 years before anyone noticed it, and I don't think it caused 
a lot of harm:  it was an error message that printed incorrectly.

Duncan Murdoch


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Mon Feb 23 00:22:10 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Mon, 23 Feb 2009 00:22:10 +0100
Subject: [Rd] 'unique' error message
	is	printed	despite	silent=TRUE	(PR#13547)
In-Reply-To: <49A1D8A1.2070203@stats.uwo.ca>
References: <20090222191519.17912282C76C@mail.pubhealth.ku.dk>	<49A1B292.1070908@biostat.ku.dk>	<49A1BEB5.6050701@idi.ntnu.no>
	<49A1C13F.5090109@stats.uwo.ca> <49A1C5B9.9050905@idi.ntnu.no>
	<49A1D8A1.2070203@stats.uwo.ca>
Message-ID: <49A1DE22.50900@idi.ntnu.no>

Duncan Murdoch wrote:
> On 22/02/2009 4:38 PM, Wacek Kusnierczyk wrote:
>> Duncan Murdoch wrote:
>>>> hmm, why wouldn't you use something like
>>>>
>>>>     DEBUG(x)
>>>>
>>>> with DEBUG being a macro defined so that it's replacement is void
>>>> unless
>>>> a specific flag or environment variable is set specifically for the
>>>> purpose of debugging?  you would then avoid confusing users' code just
>>>> because one PrintValue has been inadvertently left in the sources.
>>> But then we'd confuse developers, who would see a huge dump of messages
>>> from every other debugging session, when they just wanted to see their
>>> own, and who would be forced to wade through leftover never-used
>>> DEBUG(x) calls in code when they were reading the source.
>>>
>>
>> my point was not that such DEBUG statements should be left there in the
>> code for all eternity.  to the contrary, their role would be quite the
>> same as that of the PrintValue discussed here.  it would, however, be
>> easier to switch between printing and not printing such debugging
>> messages, and also easier to spot DEBUG statements inadvertently left in
>> the code. 
>
> Sorry, I misunderstood.  Yes, that might be handy.
>
> The main problem is agreeing on what macros to write, and what should
> happen when the external flag is set. In my experience, people who are
> good at debugging have long-established idiosyncratic habits, and are
> just annoyed when things change.
>

well, ok, but it sounds odd to me that in a large multideveloper project
where not only people are allowed to use their idiosyncratic habits (and
leave bug-inducing footprints behind), but even the idea of having a
consistent way of printing debug messages seems not to have been
discussed (how much am i off here?).

> For example, a number of people have suggested that compiles should
> switch to optimization level 0 when compiling for debugging.  This
> makes stepping through code easier, because (as far as I recall)
> variables aren't optimized out, code isn't rearranged, etc.  But it
> means some bugs change their behaviour:  and I really hate that.  So I
> wouldn't mind if it were possible to request that, but I'd want to
> make sure the default is to ask for debugging support without it:  I
> don't want to waste my time looking at a different program when I'm
> trying to track something down.

>
> If we had DEBUG(x) which became PrintValue(x) when a certain flag was
> set, I probably wouldn't use it, because it requires two things:  set
> the flag as well as add the statement.  I'd find that just irritating.
> (I rarely use PrintValue in any case:  most of the types of bugs I'm
> looking for need Rprintf or REprintf instead.  So we'd need at least
> three macros.)
>

it was just a loose suggestion, and you certainly know better both the r
sources and the developers' habits.  i have no vote.

>>> This is not a common error:  as far as I know, there are no other
>>> unintentional PrintValue calls anywhere in the source.  So I think the
>>> current system (just take them out before committing) is working.
>>
>> grep --include=*.c -R '\bPrintValue\b' src | wc -l
>>
>> reports 21 occurrences of PrintValue, though of course i cannot say
>> anything about their being intentional or not unless i examine the
>> sources.  if they were DEBUGs, you'd know for sure they're not supposed
>> to stay there in a release version.
>
> I did a quick examination of the source and I think the ones that
> aren't commented out look intentional.  (I was following my rule 5 of
> debugging:  look for similar errors elsewhere.)
>
>> it's just to wish that those who introduce debugging PrintValues
>> examined diffs carefully before their code is released.  given the size
>> of r sources (and their fairly ad hoc shape here and there), few others
>> than the author will know for sure whether the PrintValue is a debugger
>> or not?  apparently, no one has noticed in this case.  were it DEBUG
>> instead of PrintValue, it would suffice to run a grep to catch it.
>
> People who commit any changes should examine them carefully, and in
> general they do.  Sometimes things slip by.  In this case, the slip
> was there for 5 years before anyone noticed it, and I don't think it
> caused a lot of harm:  it was an error message that printed incorrectly.

yes, though irrespectively of the consequences, it still was a bug, no? 
(have you thanked stavros for reporting it?)

vQ


From bates at stat.wisc.edu  Mon Feb 23 00:22:15 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 22 Feb 2009 17:22:15 -0600
Subject: [Rd] [SoC09-Info] An IPopt interface for R
In-Reply-To: <40e66e0b0902221305s768d6e77u608f04fcfb83b8d5@mail.gmail.com>
References: <40e66e0b0902221305s768d6e77u608f04fcfb83b8d5@mail.gmail.com>
Message-ID: <40e66e0b0902221522i37576296jdd14fb17d00ee7e9@mail.gmail.com>

On Sun, Feb 22, 2009 at 3:05 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
> There have been several messages on R-devel mentioning the interior
> point optimization software Ipopt, https://projects.coin-op/Ipopt/.
> This C++ library is released under a license called the Common Public
> License.
>
> I have two questions that readers of R-devel may be able to answer.
>
> 1) Would creating an Ipopt interface for R be duplicating existing
> efforts?  That is, has someone already done so or is already working
> on this project.
>
> 2) Could a package incorporating Ipopt be released under some version
> of the GPL or LGPL?
>
> Assuming that the answers to those questions are no and yes, I would
> be willing to mentor a student in a Google Summer of Code project to
> create such a package.  However, I don't have a whole lot of time to
> do so and would not object at all if another potential mentor, or
> perhaps a co-mentor, were to volunteer.  Failing that I will create an
> application, including a programming exercise.

Having looked in more detail at the Ipopt sources and installation
instructions I think there will be a problem.  While Ipopt itself is
covered by the Common Public License it requires a sparse indefinite
solver such as MUMPS, Pardiso or one of the Harwell Subroutine
Libraries, http://www.coin-or.org/Ipopt/documentation/node6.html .  As
far as I can see, none of these are covered by a license that allows
redistribution so they can't be included in a package on CRAN or, I
think, in an SoC project.

It's too bad.  I am encouraged by projects like COIN, www.coin-or.org,
and Ipopt that do recognize the importance of open source software
covered by a suitable license but so much of the numerical analysis
community still misses the boat on that one.

By the way, the URL in the quoted message was garbled.  It should have been

https://projects.coin-or.org/Ipopt


From murdoch at stats.uwo.ca  Mon Feb 23 01:18:00 2009
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 22 Feb 2009 19:18:00 -0500
Subject: [Rd] 'unique' error message
	is	printed	despite	silent=TRUE	(PR#13547)
In-Reply-To: <49A1DE22.50900@idi.ntnu.no>
References: <20090222191519.17912282C76C@mail.pubhealth.ku.dk>	<49A1B292.1070908@biostat.ku.dk>	<49A1BEB5.6050701@idi.ntnu.no>
	<49A1C13F.5090109@stats.uwo.ca> <49A1C5B9.9050905@idi.ntnu.no>
	<49A1D8A1.2070203@stats.uwo.ca> <49A1DE22.50900@idi.ntnu.no>
Message-ID: <49A1EB38.4030805@stats.uwo.ca>

On 22/02/2009 6:22 PM, Wacek Kusnierczyk wrote:
> Duncan Murdoch wrote:
>> On 22/02/2009 4:38 PM, Wacek Kusnierczyk wrote:
>>> Duncan Murdoch wrote:
>>>>> hmm, why wouldn't you use something like
>>>>>
>>>>>     DEBUG(x)
>>>>>
>>>>> with DEBUG being a macro defined so that it's replacement is void
>>>>> unless
>>>>> a specific flag or environment variable is set specifically for the
>>>>> purpose of debugging?  you would then avoid confusing users' code just
>>>>> because one PrintValue has been inadvertently left in the sources.
>>>> But then we'd confuse developers, who would see a huge dump of messages
>>>> from every other debugging session, when they just wanted to see their
>>>> own, and who would be forced to wade through leftover never-used
>>>> DEBUG(x) calls in code when they were reading the source.
>>>>
>>> my point was not that such DEBUG statements should be left there in the
>>> code for all eternity.  to the contrary, their role would be quite the
>>> same as that of the PrintValue discussed here.  it would, however, be
>>> easier to switch between printing and not printing such debugging
>>> messages, and also easier to spot DEBUG statements inadvertently left in
>>> the code. 
>> Sorry, I misunderstood.  Yes, that might be handy.
>>
>> The main problem is agreeing on what macros to write, and what should
>> happen when the external flag is set. In my experience, people who are
>> good at debugging have long-established idiosyncratic habits, and are
>> just annoyed when things change.
>>
> 
> well, ok, but it sounds odd to me that in a large multideveloper project
> where not only people are allowed to use their idiosyncratic habits (and
> leave bug-inducing footprints behind), but even the idea of having a
> consistent way of printing debug messages seems not to have been
> discussed (how much am i off here?).

I think you are just trolling now.  How could we stop people from using 
whatever method they wanted when debugging?  And we don't "allow" people 
to leave bugs behind, but sometimes (being fallible) they do anyways.

> 
>> For example, a number of people have suggested that compiles should
>> switch to optimization level 0 when compiling for debugging.  This
>> makes stepping through code easier, because (as far as I recall)
>> variables aren't optimized out, code isn't rearranged, etc.  But it
>> means some bugs change their behaviour:  and I really hate that.  So I
>> wouldn't mind if it were possible to request that, but I'd want to
>> make sure the default is to ask for debugging support without it:  I
>> don't want to waste my time looking at a different program when I'm
>> trying to track something down.
> 
>> If we had DEBUG(x) which became PrintValue(x) when a certain flag was
>> set, I probably wouldn't use it, because it requires two things:  set
>> the flag as well as add the statement.  I'd find that just irritating.
>> (I rarely use PrintValue in any case:  most of the types of bugs I'm
>> looking for need Rprintf or REprintf instead.  So we'd need at least
>> three macros.)
>>
> 
> it was just a loose suggestion, and you certainly know better both the r
> sources and the developers' habits.  i have no vote.
> 
>>>> This is not a common error:  as far as I know, there are no other
>>>> unintentional PrintValue calls anywhere in the source.  So I think the
>>>> current system (just take them out before committing) is working.
>>> grep --include=*.c -R '\bPrintValue\b' src | wc -l
>>>
>>> reports 21 occurrences of PrintValue, though of course i cannot say
>>> anything about their being intentional or not unless i examine the
>>> sources.  if they were DEBUGs, you'd know for sure they're not supposed
>>> to stay there in a release version.
>> I did a quick examination of the source and I think the ones that
>> aren't commented out look intentional.  (I was following my rule 5 of
>> debugging:  look for similar errors elsewhere.)
>>
>>> it's just to wish that those who introduce debugging PrintValues
>>> examined diffs carefully before their code is released.  given the size
>>> of r sources (and their fairly ad hoc shape here and there), few others
>>> than the author will know for sure whether the PrintValue is a debugger
>>> or not?  apparently, no one has noticed in this case.  were it DEBUG
>>> instead of PrintValue, it would suffice to run a grep to catch it.
>> People who commit any changes should examine them carefully, and in
>> general they do.  Sometimes things slip by.  In this case, the slip
>> was there for 5 years before anyone noticed it, and I don't think it
>> caused a lot of harm:  it was an error message that printed incorrectly.
> 
> yes, though irrespectively of the consequences, it still was a bug, no? 
> (have you thanked stavros for reporting it?)

I hope he realizes that we do appreciate the report.  That's why it got 
such quick attention.  (I don't expect him to thank me for fixing it, 
either.)

Duncan Murdoch


From macrakis at alum.mit.edu  Mon Feb 23 02:51:21 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Sun, 22 Feb 2009 20:51:21 -0500
Subject: [Rd] 'unique' error message is printed despite silent=TRUE
	(PR#13547)
In-Reply-To: <49A1EB38.4030805@stats.uwo.ca>
References: <20090222191519.17912282C76C@mail.pubhealth.ku.dk>
	<49A1B292.1070908@biostat.ku.dk> <49A1BEB5.6050701@idi.ntnu.no>
	<49A1C13F.5090109@stats.uwo.ca> <49A1C5B9.9050905@idi.ntnu.no>
	<49A1D8A1.2070203@stats.uwo.ca> <49A1DE22.50900@idi.ntnu.no>
	<49A1EB38.4030805@stats.uwo.ca>
Message-ID: <8b356f880902221751o2eecb80fnc4a68d230fe2872c@mail.gmail.com>

> I hope he realizes that we do appreciate the report.  That's why it got such
> quick attention.  (I don't expect him to thank me for fixing it, either.)

Thanks for the amazingly quick fix.

           -s


From berwin at maths.uwa.edu.au  Mon Feb 23 04:34:22 2009
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Mon, 23 Feb 2009 11:34:22 +0800
Subject: [Rd] [R] Semantics of sequences in R
In-Reply-To: <8b356f880902221350q4a976bfr19b0d5b01a989250@mail.gmail.com>
References: <8b356f880902221242r47cdb138w9b1ac05cc5e5e317@mail.gmail.com>
	<49A1BFC7.9060503@stats.uwo.ca>
	<8b356f880902221350q4a976bfr19b0d5b01a989250@mail.gmail.com>
Message-ID: <20090223113422.76cc1494@absentia>

G'day Stavros,

On Sun, 22 Feb 2009 16:50:13 -0500
Stavros Macrakis <macrakis at alum.mit.edu> wrote:

> On Sun, Feb 22, 2009 at 4:12 PM, Duncan Murdoch
> <murdoch at stats.uwo.ca> wrote:

[....]

> > Which ones in particular should change?  What should they change
> > to? What will break when you do that?
> 
> In many cases, the orthogonal design is pretty straightforward.  And
> in the cases where the operation is currently an error (e.g.
> sort(list(...))), I'd hope that wouldn't break existing code. [...]

This could actually be an example that would break a lot of existing
code.

sort is a generic function, and for sort(list(...)) to work, it would
have to dispatch to a function called sort.list; and as Patrick Burns'
"The R Inferno" points out, such a function exists already and it is not
for sorting list.  

In fact, currently you get:

R> cc <- list(a=runif(4), b=rnorm(6))
R> sort(cc)
Error in sort.list(cc) : 'x' must be atomic for 'sort.list'
Have you called 'sort' on a list?

Thus, to make sort(list()) work, you would have to rename the existing
sort.list and then change every call to that function to the new name.
I guess this might break quite a few packages on CRAN.

Cheers,
	
	Berwin

=========================== Full address =============================
Berwin A Turlach                            Tel.: +65 6516 4416 (secr)
Dept of Statistics and Applied Probability        +65 6516 6650 (self)
Faculty of Science                          FAX : +65 6872 3919       
National University of Singapore     
6 Science Drive 2, Blk S16, Level 7          e-mail: statba at nus.edu.sg
Singapore 117546                    http://www.stat.nus.edu.sg/~statba


From macrakis at alum.mit.edu  Mon Feb 23 06:21:57 2009
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Mon, 23 Feb 2009 00:21:57 -0500
Subject: [Rd] [R] Semantics of sequences in R
In-Reply-To: <20090223113422.76cc1494@absentia>
References: <8b356f880902221242r47cdb138w9b1ac05cc5e5e317@mail.gmail.com>
	<49A1BFC7.9060503@stats.uwo.ca>
	<8b356f880902221350q4a976bfr19b0d5b01a989250@mail.gmail.com>
	<20090223113422.76cc1494@absentia>
Message-ID: <8b356f880902222121taee8506sf21a0a532345dfb0@mail.gmail.com>

On Sun, Feb 22, 2009 at 10:34 PM, Berwin A Turlach
<berwin at maths.uwa.edu.au> wrote:
> G'day Stavros,

Hello, Berwin,

> On Sun, 22 Feb 2009 16:50:13 -0500
> Stavros Macrakis <macrakis at alum.mit.edu> wrote:

>> ...sort(list(...))), I'd hope that wouldn't break existing code. [...]

> ...sort is a generic function, and for sort(list(...)) to work, it would
> have to dispatch to a function called sort.list;... such a function exists
> already and it is not for sorting list.

Omigod.  There is a function called 'sort' which doesn't sort, and
which follows the S3 conventions for sorting lists, but doesn't allow
lists as an argument type.  That *is* a mess!

Well, if it's OK for sort.list to violate S3 naming conventions
(presumably because it was defined before S3 was), then I suppose it
would be OK for sort to violate S3 coding conventions in return, and
dispatch in a non-standard way, e.g.

      if (is.list(x)) sort.S3.list(...) else UseMethod("sort")

Ugly, but then so is sort.list....

           -s


From dutangc at gmail.com  Mon Feb 23 07:30:51 2009
From: dutangc at gmail.com (Christophe Dutang)
Date: Mon, 23 Feb 2009 07:30:51 +0100
Subject: [Rd] R tutorial
In-Reply-To: <18849.52724.439121.353724@ridcully.stat.uni-muenchen.de>
References: <69D43B64-5E8B-4A5E-8911-59BF9771DDB9@gmail.com>
	<18849.52724.439121.353724@ridcully.stat.uni-muenchen.de>
Message-ID: <C0BD356C-8215-450C-BFDC-F807B98AFD96@gmail.com>

Ok

I will stop sending you stuff I found on the web... but just asking  
the authors to contact us.

It is true that the page is quite old... So i will directly contact  
the author.

Thanks for your comments

Christophe

iPhone.fan

Le 22 f?vr. 09 ? 23:13, Friedrich Leisch <Friedrich.Leisch at stat.uni-muenchen. 
de> a ?crit :

>>>>>> On Sun, 22 Feb 2009 14:44:27 +0100,
>>>>>> Christophe Dutang (CD) wrote:
>
>> Dear all,
>> I have just found a 'good' tutorial R for datamining. I think it
>> should be on the contributed docs.
>> http://cran.r-project.org/other-docs.html
>
>> Here is the link
>> http://www.liaad.up.pt/~ltorgo/DataMiningWithR/
>
>> What do you think?
>
> Looks intersting (although may be outdated as Doug already
> mentioned). In any case, we don't simply "harvest" docs off the web,
> we only put docs on CRAN which get sent to us by the original
> authors. So if you want to see it on CRAN, please contact the author
> (and perhaps ask for the status while doing so).
>
> Best,
> Fritz
>
> -- 
> --- 
> --------------------------------------------------------------------
> Prof. Dr. Friedrich Leisch
>
> Institut f?r Statistik                          Tel: (+49 89) 2180 3 
> 165
> Ludwig-Maximilians-Universit?t                  Fax: (+49 89) 2180 5 
> 308
> Ludwigstra?e 33
> D-80539 M?nchen                     http://www.statistik.lmu.de/~lei 
> sch
> --- 
> --------------------------------------------------------------------
>   Journal Computational Statistics --- http://www.springer.com/180
>          M?nchner R Kurse --- http://www.statistik.lmu.de/R
> --- 
> --------------------------------------------------------------------
>


From Thomas.Petzoldt at TU-Dresden.de  Mon Feb 23 08:21:58 2009
From: Thomas.Petzoldt at TU-Dresden.de (Thomas Petzoldt)
Date: Mon, 23 Feb 2009 08:21:58 +0100
Subject: [Rd] R-devel/Linux x64/Sun Studio 12: Problem with Matrix
In-Reply-To: <499FDA5B.3050000@TU-Dresden.de>
References: <1235206012.3854.24.camel@localhost.localdomain>	<alpine.LFD.2.00.0902210840260.5612@gannet.stats.ox.ac.uk>
	<499FDA5B.3050000@TU-Dresden.de>
Message-ID: <49A24E96.4080609@TU-Dresden.de>

Just for the record:

Thomas Petzoldt wrote:
> Prof Brian Ripley wrote:
>> This seems to be a problem with your OS installation. I have

I tested compilation on another Fedora 10 installation:

1) fresh installation from the installation DVD 
(Fedora-10-x86_64-DVD.iso instead of the harddisk installation based on 
the the live CD)

2) online patches and updates

3) install of Java 386 packages instead of Java x64 because sunstudio 
installer did not run with default Java (was the same with the life CD)

4) downloaded R-devel svn rev 47981; rsync-recommended

5) PATH to sunstudio appended to default PATH in .bashrc;
    config.site like described in R-admin,
    note however that IMHO it should be "suncc"
    instead of "csunc" -- a typo in R-admin.texi ??

6) configure

7) make

=> everything compiled fine with the exception of Matrix which breaks 
with exactly the same error message as my former report.

>> gannet% file /lib64/libpthread.so.0
>> /lib64/libpthread.so.0: symbolic link to `libpthread-2.9.so'
>> gannet% file /lib64/libpthread-2.9.so
>> /lib64/libpthread-2.9.so: ELF 64-bit LSB shared object, x86-64, 
>> version 1 (SYSV), dynamically linked (uses shared libs), for GNU/Linux 
>> 2.6.9, not stripped
>>
>> gannet% rpm -q --whatprovides /lib64/libpthread-2.9.so
>> glibc-2.9-3.x86_64

I got exactly the same.

>> and of course building (current) Matrix works for me.

Not yet for me with Sun Studio 12; however everything was fine when 
switching back to the Gnu compilers.

As said, just for the record. The installation was intended for checking 
our own packages which now compile well with both compilers.

>>
> 
> Dear Prof. Ripley,
> 
> O.K. thanks for your quick answer, its good to know that its not an 
> obvious error in config.site. Maybe it's because I started from a rather 
> minimal Fedora version, so I'll try to fix my installation.
> 
> Thank you
> 
> Thomas P.


Thomas P.



-- 
Thomas Petzoldt
Technische Universitaet Dresden
Institut fuer Hydrobiologie        thomas.petzoldt at tu-dresden.de
01062 Dresden                      http://tu-dresden.de/hydrobiologie/
GERMANY


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Mon Feb 23 08:46:03 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Mon, 23 Feb 2009 08:46:03 +0100
Subject: [Rd] 'unique' error message
	is	printed	despite	silent=TRUE	(PR#13547)
In-Reply-To: <49A1EB38.4030805@stats.uwo.ca>
References: <20090222191519.17912282C76C@mail.pubhealth.ku.dk>	<49A1B292.1070908@biostat.ku.dk>	<49A1BEB5.6050701@idi.ntnu.no>
	<49A1C13F.5090109@stats.uwo.ca> <49A1C5B9.9050905@idi.ntnu.no>
	<49A1D8A1.2070203@stats.uwo.ca> <49A1DE22.50900@idi.ntnu.no>
	<49A1EB38.4030805@stats.uwo.ca>
Message-ID: <49A2543B.4030409@idi.ntnu.no>

Duncan Murdoch wrote:

<snip>

> On 22/02/2009 6:22 PM, Wacek Kusnierczyk wrote:
>> well, ok, but it sounds odd to me that in a large multideveloper project
>> where not only people are allowed to use their idiosyncratic habits (and
>> leave bug-inducing footprints behind), but even the idea of having a
>> consistent way of printing debug messages seems not to have been
>> discussed (how much am i off here?).
>
> I think you are just trolling now.  How could we stop people from
> using whatever method they wanted when debugging?  And we don't
> "allow" people to leave bugs behind, but sometimes (being fallible)
> they do anyways.

i wasn't trolling, it was a genuine question.  you're probably too
sensitive.  i don't see anything wrong in at least trying to achieve
consensus on policies for how code is altered by various developers.


<snip>
>
>>
>> yes, though irrespectively of the consequences, it still was a bug,
>> no? (have you thanked stavros for reporting it?)
>
> I hope he realizes that we do appreciate the report.  That's why it
> got such quick attention.  (I don't expect him to thank me for fixing
> it, either.)

and why not?  is it usual (an polite) to make (and express) the
assumption that no one will thank you for removing a bug?

vQ


From tlumley at u.washington.edu  Mon Feb 23 08:49:23 2009
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sun, 22 Feb 2009 23:49:23 -0800 (PST)
Subject: [Rd] [SoC09-Info] An IPopt interface for R
In-Reply-To: <40e66e0b0902221522i37576296jdd14fb17d00ee7e9@mail.gmail.com>
Message-ID: <Pine.LNX.4.43.0902222349230.25511@hymn13.u.washington.edu>

On Sun, 22 Feb 2009, Douglas Bates wrote:

> On Sun, Feb 22, 2009 at 3:05 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
>> There have been several messages on R-devel mentioning the interior
>> point optimization software Ipopt, https://projects.coin-op/Ipopt/.
>> This C++ library is released under a license called the Common Public
>> License.
>>
>> I have two questions that readers of R-devel may be able to answer.
>>
>> 1) Would creating an Ipopt interface for R be duplicating existing
>> efforts?  That is, has someone already done so or is already working
>> on this project.
>>
>> 2) Could a package incorporating Ipopt be released under some version
>> of the GPL or LGPL?
>>

Also, according to the FSF, the CPL used in Ipopt is technically incompatible with the GPL because of its choice of law clause.

       -thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Mon Feb 23 08:52:05 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Mon, 23 Feb 2009 08:52:05 +0100
Subject: [Rd] [R] Semantics of sequences in R
In-Reply-To: <20090223113422.76cc1494@absentia>
References: <8b356f880902221242r47cdb138w9b1ac05cc5e5e317@mail.gmail.com>	<49A1BFC7.9060503@stats.uwo.ca>	<8b356f880902221350q4a976bfr19b0d5b01a989250@mail.gmail.com>
	<20090223113422.76cc1494@absentia>
Message-ID: <49A255A5.1010506@idi.ntnu.no>

g'orning,

Berwin A Turlach wrote:
> G'day Stavros,
>
>
>   

<snip>

>> In many cases, the orthogonal design is pretty straightforward.  And
>> in the cases where the operation is currently an error (e.g.
>> sort(list(...))), I'd hope that wouldn't break existing code. [...]
>>     
>
> This could actually be an example that would break a lot of existing
> code.
>
> sort is a generic function, and for sort(list(...)) to work, it would
> have to dispatch to a function called sort.list; and as Patrick Burns'
> "The R Inferno" points out, such a function exists already and it is not
> for sorting list.  
>   

and you mean that sort.list not being applicable to lists is a) good
design, and b) something that by noe means should be fixed, right?


> In fact, currently you get:
>
> R> cc <- list(a=runif(4), b=rnorm(6))
> R> sort(cc)
> Error in sort.list(cc) : 'x' must be atomic for 'sort.list'
> Have you called 'sort' on a list?
>   

one of the most funny error messages you get in r.  note also that,
following rolf turner's lists and vectors unproven theorem, a vector can
be considered a list -- hence sort.list should raise the error on any
vector input, no?


> Thus, to make sort(list()) work, you would have to rename the existing
> sort.list and then change every call to that function to the new name.
> I guess this might break quite a few packages on CRAN.
>   

scary!  it's much preferred to confuse new users.

vQ


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Mon Feb 23 09:35:20 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Mon, 23 Feb 2009 09:35:20 +0100
Subject: [Rd] [R] Semantics of sequences in R
In-Reply-To: <8b356f880902222121taee8506sf21a0a532345dfb0@mail.gmail.com>
References: <8b356f880902221242r47cdb138w9b1ac05cc5e5e317@mail.gmail.com>	<49A1BFC7.9060503@stats.uwo.ca>	<8b356f880902221350q4a976bfr19b0d5b01a989250@mail.gmail.com>	<20090223113422.76cc1494@absentia>
	<8b356f880902222121taee8506sf21a0a532345dfb0@mail.gmail.com>
Message-ID: <49A25FC8.2060903@idi.ntnu.no>

Stavros Macrakis wrote:
>
>>> ...sort(list(...))), I'd hope that wouldn't break existing code. [...]
>>>       
>
>   
>> ...sort is a generic function, and for sort(list(...)) to work, it would
>> have to dispatch to a function called sort.list;... such a function exists
>> already and it is not for sorting list.
>>     
>
> Omigod.  There is a function called 'sort' which doesn't sort, and
> which follows the S3 conventions for sorting lists, but doesn't allow
> lists as an argument type.  That *is* a mess!
>
> Well, if it's OK for sort.list to violate S3 naming conventions
> (presumably because it was defined before S3 was), then I suppose it
> would be OK for sort to violate S3 coding conventions in return, and
> dispatch in a non-standard way, e.g.
>
>       if (is.list(x)) sort.S3.list(...) else UseMethod("sort")
>
> Ugly, but then so is sort.list....
>   

according to svn, sort.list was introduced in late 1999 by Prof Brian
Ripley (revision 6598, 'add sort.list for S compatibility').

however, the fancy 'have you called sort on a list' error message was
added by Prof Brian Ripley in 2006, replacing the less confusing but
still odd (to a naive user) message 'x must be atomic' produced when you
call sort.list on a list.

btw. it's interesting that in revision 38438 (2006) Prof Brian Ripley
introduced (or so does the commit message say) sorting complex numbers,
and now you have things like:

    1i > 0i
    # Error in 0+0i > 0+1i : invalid comparison with complex values

    sort(c(1i, 0i))
    # 0i 1i

vQ


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Mon Feb 23 10:09:44 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Mon, 23 Feb 2009 10:09:44 +0100
Subject: [Rd] [R] Semantics of sequences in R
In-Reply-To: <49A25FC8.2060903@idi.ntnu.no>
References: <8b356f880902221242r47cdb138w9b1ac05cc5e5e317@mail.gmail.com>	<49A1BFC7.9060503@stats.uwo.ca>	<8b356f880902221350q4a976bfr19b0d5b01a989250@mail.gmail.com>	<20090223113422.76cc1494@absentia>	<8b356f880902222121taee8506sf21a0a532345dfb0@mail.gmail.com>
	<49A25FC8.2060903@idi.ntnu.no>
Message-ID: <49A267D8.4060108@idi.ntnu.no>

Wacek Kusnierczyk wrote:
>
> btw. it's interesting that in revision 38438 (2006) Prof Brian Ripley
> introduced (or so does the commit message say) sorting complex numbers,
> and now you have things like:
>
>     1i > 0i
>     # Error in 0+0i > 0+1i : invalid comparison with complex values
>
>     sort(c(1i, 0i))
>     # 0i 1i
>
>   

it's interesting also because one of the arguments for why sort does not
operate on lists is that it is not clear how to compare their elements
(see, e.g., [1]).  so why would sort sort complex numbers, if r cannot
compare them?

arguing that sort cannot operate on lists because it does not know how
to compare the elements is based on a misconception.  algorithms for
sorting are in essence ignorant of what the elements of the sequences to
be sorted are;  sorting works equally well with numbers, strings,
functions, plants, waste, etc., provided that an appropriate comparator
is specified.

i think that the right design for sort and sort.list would be to have
the former operate on atomic vectors (``real'' vectors, those that can
be considered lists but they're not) with defaults for the respective
types, and the latter operate on lists with no default for the
comparator, even when all elements happen to be of the same type:

    sort(1:10)
    # fine

    sort(as.list(1:10))
    # error: no comparator specified

    sort(as.list(1:10), `<`)
    # fine

vQ



[1] http://tolstoy.newcastle.edu.au/R/e4/help/08/07/16231.html


From berwin at maths.uwa.edu.au  Mon Feb 23 10:56:23 2009
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Mon, 23 Feb 2009 17:56:23 +0800
Subject: [Rd] [R] Semantics of sequences in R
In-Reply-To: <49A255A5.1010506@idi.ntnu.no>
References: <8b356f880902221242r47cdb138w9b1ac05cc5e5e317@mail.gmail.com>
	<49A1BFC7.9060503@stats.uwo.ca>
	<8b356f880902221350q4a976bfr19b0d5b01a989250@mail.gmail.com>
	<20090223113422.76cc1494@absentia> <49A255A5.1010506@idi.ntnu.no>
Message-ID: <20090223175623.6106add2@berwin-nus1>

On Mon, 23 Feb 2009 08:52:05 +0100
Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:
 
> Berwin A Turlach wrote:
> > G'day Stavros,
> <snip>
> >> In many cases, the orthogonal design is pretty straightforward.
> >> And in the cases where the operation is currently an error (e.g.
> >> sort(list(...))), I'd hope that wouldn't break existing code. [...]
> >>     
> >
> > This could actually be an example that would break a lot of existing
> > code.
> >
> > sort is a generic function, and for sort(list(...)) to work, it
> > would have to dispatch to a function called sort.list; and as
> > Patrick Burns' "The R Inferno" points out, such a function exists
> > already and it is not for sorting list.  
> >   
> 
> and you mean that sort.list not being applicable to lists is a) good
> design, and b) something that by noe means should be fixed, right?

I neither said nor meant this and I do not see how what I said could be
interpreted in such a way.  I was just commenting to Stavros that the
example he picked, hoping that it would not break existing code, was
actually a bad one which potentially will break a lot (?) of existing
code.

Also, until reading Patrick Burns' "The R Inferno" I was not aware of
sort.list.  That function had not registered with me since I hardly
used it.  And I also have no need of calling sort() on lists.  For em a
lists is a flexible enough data structure such that defining a sort()
command for them makes no sense; it could only work in very specific
circumstances.

> > In fact, currently you get:
> >
> > R> cc <- list(a=runif(4), b=rnorm(6))
> > R> sort(cc)
> > Error in sort.list(cc) : 'x' must be atomic for 'sort.list'
> > Have you called 'sort' on a list?
> >   
> 
> one of the most funny error messages you get in r.  note also that,
> following rolf turner's lists and vectors unproven theorem, a vector
> can be considered a list 

I do not remember the exact context of Rolf's comments, but I believe
he was talking in a more general sense and not in technical terms.  I
find it perfectly valid, even when talking about R, to say something
like "vectors are stored as a list of numbers in consecutive memory
locations in memory".  Clearly, in a phrase like this, we are not
talking about "vectors" and "list" as defined by the "R Language
Definition" or "R Internals", or what functions like is.vector(),
is.list() &c return for various R objects.

BTW, as I mentioned once before, you might want to consider to lose
these chips on your shoulders.

> -- hence sort.list should raise the error on any vector input, no?

You will have to take that up with the designers of sort.list.

> > Thus, to make sort(list()) work, you would have to rename the
> > existing sort.list and then change every call to that function to
> > the new name. I guess this might break quite a few packages on CRAN.
> >   
> 
> scary!  it's much preferred to confuse new users.

I usually learn a lot when I get confused about some issues/concept.
Confusion forces one to sit down, think deeply and, thus, gain some
understanding.  So I am not so much concerned with new users being
confused.  It is, of course, a problem if the new user never comes out
of his or her confusion.

Cheers,

	Berwin


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Mon Feb 23 11:31:16 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Mon, 23 Feb 2009 11:31:16 +0100
Subject: [Rd] [R] Semantics of sequences in R
In-Reply-To: <20090223175623.6106add2@berwin-nus1>
References: <8b356f880902221242r47cdb138w9b1ac05cc5e5e317@mail.gmail.com>	<49A1BFC7.9060503@stats.uwo.ca>	<8b356f880902221350q4a976bfr19b0d5b01a989250@mail.gmail.com>	<20090223113422.76cc1494@absentia>	<49A255A5.1010506@idi.ntnu.no>
	<20090223175623.6106add2@berwin-nus1>
Message-ID: <49A27AF4.307@idi.ntnu.no>

Berwin A Turlach wrote:
> On Mon, 23 Feb 2009 08:52:05 +0100
> Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:
>  
>   
>> Berwin A Turlach wrote:
>>     
>>> G'day Stavros,
>>>       
>> <snip>
>>     
>>>> In many cases, the orthogonal design is pretty straightforward.
>>>> And in the cases where the operation is currently an error (e.g.
>>>> sort(list(...))), I'd hope that wouldn't break existing code. [...]
>>>>     
>>>>         
>>> This could actually be an example that would break a lot of existing
>>> code.
>>>
>>> sort is a generic function, and for sort(list(...)) to work, it
>>> would have to dispatch to a function called sort.list; and as
>>> Patrick Burns' "The R Inferno" points out, such a function exists
>>> already and it is not for sorting list.  
>>>   
>>>       
>> and you mean that sort.list not being applicable to lists is a) good
>> design, and b) something that by noe means should be fixed, right?
>>     
>
> I neither said nor meant this and I do not see how what I said could be
> interpreted in such a way.  I was just commenting to Stavros that the
> example he picked, hoping that it would not break existing code, was
> actually a bad one which potentially will break a lot (?) of existing
> code.
>   

would it, really?  if sort.list were, in addition to sorting atomic
vectors (can-be-considered-lists), able to sort lists, how likely would
this be to break old code?  can you give one concrete example, and
suggest how to estimate how much old code would involve the same issue?

sort.list, to be applied to an atomic vector, must be called explicitly
on the vector, because calling sort will not automatically dispatch to
sort.list (right?).   so allowing sort.list to sort lists does not
change anything in this respect -- except for that, as i suggested, if
sort.list were requiring an explicit comparator, you'd have to add one
wherever sort.list is called, but to accomodate for old code sort.list
could actually check whether the argument is not an atomic vector.

how much old code could be relying on the fact that sort.list raises an
error when given a list?  i suspect it's fairly unlikely that any single
piece of code does;  and if so, allowing sort.list to sort lists would
not change anything here either.




> Also, until reading Patrick Burns' "The R Inferno" I was not aware of
> sort.list.  That function had not registered with me since I hardly
> used it.  

which hints that "potentially will break a lot (?) of existing code" is
a rather unlikely event.

> And I also have no need of calling sort() on lists.  For em a
> lists is a flexible enough data structure such that defining a sort()
> command for them makes no sense; it could only work in very specific
> circumstances.
>   

i don't understand the first part:  "flexible enough data structure such
that defining a sort() command for them makes no sense" makes no sense.

as to "it could only work in very specific circumstances" -- no, it
would work for any list whatsoever, provided the user has a correctly
implemented comparator.  for example, i'd like to sort a list of vectors
by the vectors' length -- is this a very exotic idea?


>   
>>> In fact, currently you get:
>>>
>>> R> cc <- list(a=runif(4), b=rnorm(6))
>>> R> sort(cc)
>>> Error in sort.list(cc) : 'x' must be atomic for 'sort.list'
>>> Have you called 'sort' on a list?
>>>   
>>>       
>> one of the most funny error messages you get in r.  note also that,
>> following rolf turner's lists and vectors unproven theorem, a vector
>> can be considered a list 
>>     
>
> I do not remember the exact context of Rolf's comments, but I believe
> he was talking in a more general sense and not in technical terms. 

indeed, he was blurring the concepts instead of referring to concrete
documentation with clear specified meaning of the terms he used.


>  I
> find it perfectly valid, even when talking about R, to say something
> like "vectors are stored as a list of numbers in consecutive memory
> locations in memory".  

yes;  and you can always say that 'vectors can be considered electrical
charges', or better, 'vectors can be considered electrical charges, in
some sense'.

what sense of 'list' are you using here?  i'd rather use the term
'array', unless confusing the user is the real purpose.  (and to be
really picky, you do not store numbers.)


> Clearly, in a phrase like this, we are not
> talking about "vectors" and "list" as defined by the "R Language
> Definition" or "R Internals", or what functions like is.vector(),
> is.list() &c return for various R objects.
>   

clearly, you can say anything you like, and then add 'i was not talking
about x as defined by y'.  the art  is to talk about x as defined by y.

> BTW, as I mentioned once before, you might want to consider to lose
> these chips on your shoulders.
>   

berwin, it's been a tradition on this list to discourage people from
commenting on the design and implementation of r whenever they think
it's wrong.  you really should be doing the opposite.  as a chinese
proverb says, a gem cannot be polished without friction.  friction seems
to be what you fear a lot.


>   
>> -- hence sort.list should raise the error on any vector input, no?
>>     
>
> You will have to take that up with the designers of sort.list.
>   
>   
>>> Thus, to make sort(list()) work, you would have to rename the
>>> existing sort.list and then change every call to that function to
>>> the new name. I guess this might break quite a few packages on CRAN.
>>>   
>>>       
>> scary!  it's much preferred to confuse new users.
>>     
>
> I usually learn a lot when I get confused about some issues/concept.
> Confusion forces one to sit down, think deeply and, thus, gain some
> understanding.  So I am not so much concerned with new users being
> confused.  It is, of course, a problem if the new user never comes out
> of his or her confusion.
>   

the problem, is, r users have to learn lots and lots of *bad* and
*messy* design to get up and running without devils catching them behind
every corner.  in principle, you're absolutely right;  the problem lies
in the amount of effort a user has to make to avoid confusion while
using r  (where 'using' means a bit more than simply fitting and
plotting a model).

cheers,
vQ


From stefan.evert at uos.de  Mon Feb 23 12:12:39 2009
From: stefan.evert at uos.de (Stefan Evert)
Date: Mon, 23 Feb 2009 12:12:39 +0100
Subject: [Rd] [R] Semantics of sequences in R
In-Reply-To: <49A27AF4.307@idi.ntnu.no>
References: <8b356f880902221242r47cdb138w9b1ac05cc5e5e317@mail.gmail.com>	<49A1BFC7.9060503@stats.uwo.ca>	<8b356f880902221350q4a976bfr19b0d5b01a989250@mail.gmail.com>	<20090223113422.76cc1494@absentia>	<49A255A5.1010506@idi.ntnu.no>
	<20090223175623.6106add2@berwin-nus1> <49A27AF4.307@idi.ntnu.no>
Message-ID: <91A643DD-EBED-4584-B0FD-2DA2025256FD@uos.de>

Dear vQ,

> vectors (can-be-considered-lists),

can you please stop repeating this nonsense?  I don't think anybody  
ever claimed that vectors can be considered list.  It's rather the  
other way round: lists can also be seen as vectors to R (possibly they  
are implemented as such, but I don't much about the internals of R).

 > a <- as.list(1:10)
 > b <- 1:10
 > is.vector(a)
[1] TRUE
 > is.list(a)
[1] TRUE
 > is.vector(b)
[1] TRUE
 > is.list(b)
[1] FALSE

Hence the confusion about

 > mode(as.vector(a))
[1] "list"

which prompted the original comment that you are taking so much  
exception to.

> as to "it could only work in very specific circumstances" -- no, it
> would work for any list whatsoever, provided the user has a correctly
> implemented comparator.  for example, i'd like to sort a list of  
> vectors
> by the vectors' length -- is this a very exotic idea?

Honestly, I can't think of a situation where I would want to do than  
in R.  In a Perl script, quite likely; but this is a kind of data  
manipulation that R wasn't really designed for IMHO.

Not that I'd mind having sort() operate properly on lists; it just  
isn't something I miss in the language.

Best,
Stefan

[ stefan.evert at uos.de | http://purl.org/stefan.evert ]


From berwin at maths.uwa.edu.au  Mon Feb 23 12:27:57 2009
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Mon, 23 Feb 2009 19:27:57 +0800
Subject: [Rd] [R] Semantics of sequences in R
In-Reply-To: <49A27AF4.307@idi.ntnu.no>
References: <8b356f880902221242r47cdb138w9b1ac05cc5e5e317@mail.gmail.com>
	<49A1BFC7.9060503@stats.uwo.ca>
	<8b356f880902221350q4a976bfr19b0d5b01a989250@mail.gmail.com>
	<20090223113422.76cc1494@absentia> <49A255A5.1010506@idi.ntnu.no>
	<20090223175623.6106add2@berwin-nus1> <49A27AF4.307@idi.ntnu.no>
Message-ID: <20090223192757.2ff7f629@berwin-nus1>

On Mon, 23 Feb 2009 11:31:16 +0100
Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:

> Berwin A Turlach wrote:
> > On Mon, 23 Feb 2009 08:52:05 +0100
> > Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:
[...]
> >> and you mean that sort.list not being applicable to lists is a)
> >> good design, and b) something that by noe means should be fixed,
> >> right? 
> >
> > I neither said nor meant this and I do not see how what I said
> > could be interpreted in such a way.  I was just commenting to
> > Stavros that the example he picked, hoping that it would not break
> > existing code, was actually a bad one which potentially will break
> > a lot (?) of existing code. 
> 
> would it, really?  if sort.list were, in addition to sorting atomic
> vectors (can-be-considered-lists), able to sort lists, how likely
> would this be to break old code?  

Presumably not.

> can you give one concrete example, and suggest how to estimate how
> much old code would involve the same issue?

Check out the svn source of R, run configure, do whatever change you
want to sort.list, "make", "make check FORCE=FORCE".  That should give
you an idea how much would break.  

Additionally, you could try to install all CRAN packages with your
modified version and see how many of them break when their
examples/demos/&c is run.  

AFAIK, Brian is doing something like this on his machine.  I am sure
that if you ask nicely he will share his scripts with you.

If this sounds too time consuming, you might just want to unpack the
sources and grep for "sort.list" on all .R files;  I am sure you know
how to use find and grep to do this.

> > Also, until reading Patrick Burns' "The R Inferno" I was not aware
> > of sort.list.  That function had not registered with me since I
> > hardly used it.  
> 
> which hints that "potentially will break a lot (?) of existing code"
> is a rather unlikely event.

Only for code that I wrote; other people's need and knowledge of R may
vary.
 
> > And I also have no need of calling sort() on lists.  For em a
> > lists is a flexible enough data structure such that defining a
> > sort() command for them makes no sense; it could only work in very
> > specific circumstances.
> >   
> 
> i don't understand the first part:  "flexible enough data structure
> such that defining a sort() command for them makes no sense" makes no
> sense.

lists are very flexible structure whose component must not be of equal
type.  So how do you want to compare components?  How to you compare a
vector of numbers to a vector of character strings?  Or a list of
lists?  

Or should the sorting be on the length of the components?  Or their
names?  Or should sort(myList) sort each component of myList?  But for
that case we have already lapply(myList, sort).

> as to "it could only work in very specific circumstances" -- no, it
> would work for any list whatsoever, provided the user has a correctly
> implemented comparator.  for example, i'd like to sort a list of
> vectors by the vectors' length -- is this a very exotic idea?

No, if that is what you want.  And I guess it is one way of sorting a
list.  The question is what should be the default way?  

> > BTW, as I mentioned once before, you might want to consider to lose
> > these chips on your shoulders.
> >   
> 
> berwin, it's been a tradition on this list to discourage people from
> commenting on the design and implementation of r whenever they think
> it's wrong.  

I am not aware of any such tradition and I subscribed to R-help on 15
April 1998.  

The point is rather that by commenting only one will not achieve much,
in particular if the comments look more like complaints and the same
comments are done again and again (along with dragging up previous
comments or comments received on previous comments).

R is open source.  Check out the svn version, fix what you consider
needs fixing, submit a patch, convince R core that the patch fixes a
real problem/is an improvement/does not break too much.  Then you have
a better chance in achieving something.  

Alternatively, if it turns out that something that bugs you cannot be
changed without breaking too much existing code, start from scratch
that with a better design.  Apparently the GAP project
(http://www.gap-system.org/) is doing something like this, as
someone closely associated with that project once told me.  While
developing a version of GAP they collect information on how to improve
the design, data structures &c; then, at some point, they start to
write the next version from scratch.
  
> >> scary!  it's much preferred to confuse new users.
> >
> > I usually learn a lot when I get confused about some issues/concept.
> > Confusion forces one to sit down, think deeply and, thus, gain some
> > understanding.  So I am not so much concerned with new users being
> > confused.  It is, of course, a problem if the new user never comes
> > out of his or her confusion.
> 
> the problem, is, r users have to learn lots [...]

Indeed, and I guess in this age of instant gratification that that is a
real bummer for new users.

Best,

	Berwin


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Mon Feb 23 13:27:08 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Mon, 23 Feb 2009 13:27:08 +0100
Subject: [Rd] [R] Semantics of sequences in R
In-Reply-To: <20090223192757.2ff7f629@berwin-nus1>
References: <8b356f880902221242r47cdb138w9b1ac05cc5e5e317@mail.gmail.com>	<49A1BFC7.9060503@stats.uwo.ca>	<8b356f880902221350q4a976bfr19b0d5b01a989250@mail.gmail.com>	<20090223113422.76cc1494@absentia>	<49A255A5.1010506@idi.ntnu.no>	<20090223175623.6106add2@berwin-nus1>	<49A27AF4.307@idi.ntnu.no>
	<20090223192757.2ff7f629@berwin-nus1>
Message-ID: <49A2961C.3020405@idi.ntnu.no>

Berwin A Turlach wrote:

<snip>

>> can you give one concrete example, and suggest how to estimate how
>> much old code would involve the same issue?
>>     
>
> Check out the svn source of R, run configure, do whatever change you
> want to sort.list, "make", "make check FORCE=FORCE".  That should give
> you an idea how much would break.  
>   

it's not just making changes to sort.list, berwin.  sort.list calls
.Internal order, and this one would have to be modified in order to
accommodate for the additional comparator argument.  not that it is
impossible or even difficult, i just haven't found time yet to learn how
to implement internal functions in r.

> Additionally, you could try to install all CRAN packages with your
> modified version and see how many of them break when their
> examples/demos/&c is run.  
>   

that's not a good benchmark;  this are third-party stuff, and where
people are willing to rely on poor design they should be prepared to
suffer.  but maybe not in r, where protection of old code seems more
important than progress.


> AFAIK, Brian is doing something like this on his machine.  I am sure
> that if you ask nicely he will share his scripts with you.
>   

:)


> If this sounds too time consuming, you might just want to unpack the
> sources and grep for "sort.list" on all .R files;  I am sure you know
> how to use find and grep to do this.
>   

of course i've done it in the first place;  there are 52 such entries in
r-devel, and i can't see any where allowing sort.list to sort lists
would break the code.  it does not mean, of course, that it wouldn't.

>   
>>> Also, until reading Patrick Burns' "The R Inferno" I was not aware
>>> of sort.list.  That function had not registered with me since I
>>> hardly used it.  
>>>       
>> which hints that "potentially will break a lot (?) of existing code"
>> is a rather unlikely event.
>>     
>
> Only for code that I wrote; other people's need and knowledge of R may
> vary.
>   

hence 'hints', not 'proves'.

>  
>   
>>> And I also have no need of calling sort() on lists.  For em a
>>> lists is a flexible enough data structure such that defining a
>>> sort() command for them makes no sense; it could only work in very
>>> specific circumstances.
>>>   
>>>       
>> i don't understand the first part:  "flexible enough data structure
>> such that defining a sort() command for them makes no sense" makes no
>> sense.
>>     
>
> lists are very flexible structure whose component must not be of equal
> type.  So how do you want to compare components?  How to you compare a
> vector of numbers to a vector of character strings?  Or a list of
> lists?  
>   

*very* easy:  by applying a suitable comparator.

in your specific example, the possibilities are virtually limitless. 
you can convert the numbers to strings, or parse the strings into
numbers.  you can compute the lengths of the lists, compare their
elements pairwise, or whatever you wish.  all this done by a comparator
which is a function fullfilling just one requirement:  that it returns,
say, -1, 0, or 1, depending on how the two items it gets compare.  (and
it has to work for the type of items you happen to have in your lists --
all this *your* business, not sort's.)

judging from your question, you couldn't possibly see sorting routines
in other languages.


> Or should the sorting be on the length of the components?  

why not?

> Or their
> names?  

why not?

> Or should sort(myList) sort each component of myList?  

that's a design decision.  you can always have a parameter like
recursive=TRUE/FALSE, no?  so you could sort or not both between and
within lists.  what's the problem, again?

> But for
> that case we have already lapply(myList, sort).
>   

so?

>   
>> as to "it could only work in very specific circumstances" -- no, it
>> would work for any list whatsoever, provided the user has a correctly
>> implemented comparator.  for example, i'd like to sort a list of
>> vectors by the vectors' length -- is this a very exotic idea?
>>     
>
> No, if that is what you want.  And I guess it is one way of sorting a
> list.  The question is what should be the default way?  
>   

one possible answer is: none.  (i have already given this answer
previously, if you read carefully it's still there).  sort.list *should*
demand an additional comparator argument.  at least, it should demand it
if the argument to be sorted is a list, rather than a non-list vector
(if you still need to use sort.list on non-lists).

>   
>>> BTW, as I mentioned once before, you might want to consider to lose
>>> these chips on your shoulders.
>>>   
>>>       
>> berwin, it's been a tradition on this list to discourage people from
>> commenting on the design and implementation of r whenever they think
>> it's wrong.  
>>     
>
> I am not aware of any such tradition and I subscribed to R-help on 15
> April 1998.  
>
> The point is rather that by commenting only one will not achieve much,
> in particular if the comments look more like complaints and the same
> comments are done again and again (along with dragging up previous
> comments or comments received on previous comments).
>   

again and again because you seem to be immune to critique.  open you
mind, and it will suffice complain just once.  besides, i am certainly
*not* just complaining.  i am providing concrete arguments, examples,
and suggestions.  you're being unreasonably unfair.

> R is open source.  Check out the svn version, fix what you consider
> needs fixing, submit a patch, convince R core that the patch fixes a
> real problem/is an improvement/does not break too much.  Then you have
> a better chance in achieving something.  
>   

no, berwin.  this is a serious bug in thinking.  people should be
allowed -- *encouraged* -- to discuss the design *before* they even
attempt to write patches.  writing one patch which will never be
considered -- well, never responded to -- is about enough to stop people
from sending patches.  maybe that's what you want, anyway -- the fewer
incoming patches the more you're entitled to think your product is just
great.


> Alternatively, if it turns out that something that bugs you cannot be
> changed without breaking too much existing code, start from scratch
> that with a better design.  Apparently the GAP project
> (http://www.gap-system.org/) is doing something like this, as
> someone closely associated with that project once told me.  While
> developing a version of GAP they collect information on how to improve
> the design, data structures &c; then, at some point, they start to
> write the next version from scratch.
>   

can't see it online.


>   
>   
>>>> scary!  it's much preferred to confuse new users.
>>>>         
>>> I usually learn a lot when I get confused about some issues/concept.
>>> Confusion forces one to sit down, think deeply and, thus, gain some
>>> understanding.  So I am not so much concerned with new users being
>>> confused.  It is, of course, a problem if the new user never comes
>>> out of his or her confusion.
>>>       
>> the problem, is, r users have to learn lots [...]
>>     
>
> Indeed, and I guess in this age of instant gratification that that is a
> real bummer for new users.
>   

why be rude to your users?  "I am not so much concerned with new users
being confused." is an explanation -- but maybe you really should?

vQ


From berwin at maths.uwa.edu.au  Mon Feb 23 17:12:47 2009
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Tue, 24 Feb 2009 00:12:47 +0800
Subject: [Rd] [R] Semantics of sequences in R
In-Reply-To: <49A2961C.3020405@idi.ntnu.no>
References: <8b356f880902221242r47cdb138w9b1ac05cc5e5e317@mail.gmail.com>
	<49A1BFC7.9060503@stats.uwo.ca>
	<8b356f880902221350q4a976bfr19b0d5b01a989250@mail.gmail.com>
	<20090223113422.76cc1494@absentia> <49A255A5.1010506@idi.ntnu.no>
	<20090223175623.6106add2@berwin-nus1> <49A27AF4.307@idi.ntnu.no>
	<20090223192757.2ff7f629@berwin-nus1>
	<49A2961C.3020405@idi.ntnu.no>
Message-ID: <20090224001247.5d2e3db9@berwin5>

On Mon, 23 Feb 2009 13:27:08 +0100
Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:

> Berwin A Turlach wrote:
> 
> <snip>
> 
> >> can you give one concrete example, and suggest how to estimate how
> >> much old code would involve the same issue?
> >>     
> >
> > Check out the svn source of R, run configure, do whatever change you
> > want to sort.list, "make", "make check FORCE=FORCE".  That should
> > give you an idea how much would break.  
> >   
> 
> it's not just making changes to sort.list, berwin.  sort.list calls
> .Internal order, and this one would have to be modified in order to
> accommodate for the additional comparator argument. [...]

Well, you could start of with an R only implementation and then start
to move things to compiled code as needed for efficiency ....

> > Additionally, you could try to install all CRAN packages with your
> > modified version and see how many of them break when their
> > examples/demos/&c is run.  
> >   
> 
> that's not a good benchmark;  this are third-party stuff, and where
> people are willing to rely on poor design they should be prepared to
> suffer.  [...]

I do not believe that those developers are relying on poor design.
Rather, they rely on things to work as documented (and how they are
used for them to work) and that the behaviour is not gratuitously
changed just because it is considered bad design by some. 

> [...]
> judging from your question, you couldn't possibly see sorting routines
> in other languages.

Quite likely, or the other languages that I regularly use (C, Fortran)
have even more primitive sorting facilities. 

[...]
> > No, if that is what you want.  And I guess it is one way of sorting
> > a list.  The question is what should be the default way?   
> 
> one possible answer is: none.  (i have already given this answer
> previously, if you read carefully it's still there).  sort.list
> *should* demand an additional comparator argument.  at least, it
> should demand it if the argument to be sorted is a list, rather than
> a non-list vector (if you still need to use sort.list on non-lists).

So when are you sending your patch to implement this facility?

[...]
> > The point is rather that by commenting only one will not achieve
> > much, in particular if the comments look more like complaints and
> > the same comments are done again and again (along with dragging up
> > previous comments or comments received on previous comments).
> >   
> 
> again and again because you seem to be immune to critique.  

You obviously do not know me.

> open you mind, and it will suffice complain just once.  besides, i am
> certainly *not* just complaining.  i am providing concrete arguments,
> examples, and suggestions.  you're being unreasonably unfair.

I gladly admit that I am not reading every thread in which you are
active, so these comments might have been based on a biased a sample.

[...]
> > R is open source.  Check out the svn version, fix what you consider
> > needs fixing, submit a patch, convince R core that the patch fixes a
> > real problem/is an improvement/does not break too much.  Then you
> > have a better chance in achieving something.  
> 
> no, berwin.  this is a serious bug in thinking.  people should be
> allowed -- *encouraged* -- to discuss the design *before* they even
> attempt to write patches. 

And what makes you believe this is not the case?   I have seen over the
years e-mails to R-devel along the lines "I am thinking of a change
along [lots of details and reasoning for the change]; would patches
that implement this be accepted?" and these e-mails were discussed more
often than not.  However, in the end, the only people who can commit
changes to the R code are the members of R-core, thus they will have
the final word of design issues (and, as I assume, they discuss, among
other things, design issues on the private mailing list of R-core
member).  But you can discuss this issues before writing a patch.  

> writing one patch which will never be considered -- well, never
> responded to -- is about enough to stop people from sending patches.

While it is unfortunate if this happens, and such persons might just be
too thin-skinned, worse can happen; e.g. being flamed for sending in a
patch that is considered not to address any problems and with a sloppy
description of what it tries to address (happened to me).  

Yes, patches are ignored; patches are gratefully acknowledged and
applied; patches are completely re-written and still attributed to the
provider of the patch...   That does not mean that I stop sending in a
patch if I feel it is warranted...

And I am sure that if you had sent an e-mail to r-devel pointing out
that the binary operator <, when called in the non-standard way 
'<'(1,2,3), does not check the number of arguments while other binary
operators (e.g. '+'(1,2,3) or '*'(1,2,3)) do such checks, and provided
a patch that implemented such a check for '<' (and presumably other
comparison operators), then that patch would have been acknowledged and
applied.

> maybe that's what you want, anyway -- the fewer incoming patches the
> more you're entitled to think your product is just great.

If the "you"s and "your" are referring to me, then you are completely
off track.

IIRC, this discussion started off because I was not enthused of having
words put into my month in a public forum.  But then it turned into
another opportunity to correct your misunderstandings about the ways in
which the R community works.  Let me assure you, one you figure that
one out, you will be able to interact more productively/satisfactorily
with that community.  And, again, it does not help to say "this is how
the culture should be and I behave as if it is this way".  As the
saying goes, when in Rome do as the Romans.

> >>>> scary!  it's much preferred to confuse new users.
> >>>>         
> >>> I usually learn a lot when I get confused about some
> >>> issues/concept. Confusion forces one to sit down, think deeply
> >>> and, thus, gain some understanding.  So I am not so much
> >>> concerned with new users being confused.  It is, of course, a
> >>> problem if the new user never comes out of his or her confusion.
> >>>       
> >> the problem, is, r users have to learn lots [...]
> >>     
> >
> > Indeed, and I guess in this age of instant gratification that that
> > is a real bummer for new users.
> >   
> 
> why be rude to your users?  "I am not so much concerned with new users
> being confused." is an explanation -- but maybe you really should?

As I said, I believe confusion is a great way of gaining understanding
and knowledge and in that sense I am not so much concerned with new
users being confused.  I acknowledged that it is a problem if they
never come out of their confusion.  

Also, r-help would only be half the fun without confused (new) users. :)

Cheers,
	
	Berwin


From kjell.konis at epfl.ch  Mon Feb 23 18:37:24 2009
From: kjell.konis at epfl.ch (Kjell Konis)
Date: Mon, 23 Feb 2009 18:37:24 +0100
Subject: [Rd] copy an external pointer on assignment
Message-ID: <BED4CCBD-5F6A-4B69-92DE-FD2263645CDA@epfl.ch>

Is there a mechanism in R for copying the business end of an external  
pointer on assignment?  For instance, if x is an external pointer and  
I enter

   > y <- x

I would like to make a copy of the structure that x refers to and  
assign its address to y.

Thanks,
Kjell


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Mon Feb 23 20:27:23 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Mon, 23 Feb 2009 20:27:23 +0100
Subject: [Rd] [R] Semantics of sequences in R
In-Reply-To: <20090224001247.5d2e3db9@berwin5>
References: <8b356f880902221242r47cdb138w9b1ac05cc5e5e317@mail.gmail.com>	<49A1BFC7.9060503@stats.uwo.ca>	<8b356f880902221350q4a976bfr19b0d5b01a989250@mail.gmail.com>	<20090223113422.76cc1494@absentia>	<49A255A5.1010506@idi.ntnu.no>	<20090223175623.6106add2@berwin-nus1>	<49A27AF4.307@idi.ntnu.no>	<20090223192757.2ff7f629@berwin-nus1>	<49A2961C.3020405@idi.ntnu.no>
	<20090224001247.5d2e3db9@berwin5>
Message-ID: <49A2F89B.10900@idi.ntnu.no>

Berwin A Turlach wrote:
>
>> it's not just making changes to sort.list, berwin.  sort.list calls
>> .Internal order, and this one would have to be modified in order to
>> accommodate for the additional comparator argument. [...]
>>     
>
> Well, you could start of with an R only implementation and then start
> to move things to compiled code as needed for efficiency ....
>
>   

sure.  this would be a rewrite rather than a modification, though.  but
surely a possibility.  thanks for pointing this out.

>>> Additionally, you could try to install all CRAN packages with your
>>> modified version and see how many of them break when their
>>> examples/demos/&c is run.  
>>>   
>>>       
>> that's not a good benchmark;  this are third-party stuff, and where
>> people are willing to rely on poor design they should be prepared to
>> suffer.  [...]
>>     
>
> I do not believe that those developers are relying on poor design.
> Rather, they rely on things to work as documented (and how they are
> used for them to work) and that the behaviour is not gratuitously
> changed just because it is considered bad design by some. 
>   

you're right.  they're willing to rely on the existing design, often
unconscious of its flaws. 


>   
>> [...]
>> judging from your question, you couldn't possibly see sorting routines
>> in other languages.
>>     
>
> Quite likely, or the other languages that I regularly use (C, Fortran)
> have even more primitive sorting facilities. 
>   

i apologize, this was an unacceptably imprecise expression, which i
realized too late.  i meant that you must have never used sorting
routines in a language from the class that r purports to belong to --
high level functional programming languages.  i was sort of clear than
you must have used c and fortran, and i had no intention to say that you
haven't used *any* other language.

for your interest, here are two relevant examples.  scheme is older than
r, and yet already its developers got the idea that lists of arbitrary
objects could be subject to sorting (by whatever magic).  you only need
to provide a comparator, e.g.:

    mit-scheme <<< "(sort (list 1 '(2 3) (lambda () '())) (lambda (x y)
(> (random 2) 0)))"
    # (#[compound-procedure] (2 3) 1)

(which is a convoluted approach to using sort to actually scramble the
list.)  see, e.g., sec. 7.9 miscellaneous list operations in the mit
scheme reference manual [1].

python folks -- be it guido van rossum or whoever else -- have gone even
further, letting you sort lists of arbitrary items with a default
comparator:

    python <<< 'print sorted([1, (2, 3), lambda x: x])'
    # [1, <function <lambda> at 0x81a1f44>, [2, 3]]

the point being:  when you're trying to sell the idea that sorting lists
of arbitrary items is a silly idea, it's silly.

[1] http://www.gnu.org/software/mit-scheme/documentation/mit-scheme-ref/


> [...]
>   
>>> No, if that is what you want.  And I guess it is one way of sorting
>>> a list.  The question is what should be the default way?   
>>>       
>> one possible answer is: none.  (i have already given this answer
>> previously, if you read carefully it's still there).  sort.list
>> *should* demand an additional comparator argument.  at least, it
>> should demand it if the argument to be sorted is a list, rather than
>> a non-list vector (if you still need to use sort.list on non-lists).
>>     
>
> So when are you sending your patch to implement this facility?
>   

as i said, you seem to have a severe bug in thinking about collaborative
development.

i am sending *no* patch for this.  the issue has to be first discussed
on the design level, and only then, if accepted, should anyone -- me,
for example -- make an attempt to implement it.  tell me you want to
listen to what i have to say, and we can discuss.  telling me i have a
chip on my shoulder is rather unhelpful.


> [...]
>   
>>> The point is rather that by commenting only one will not achieve
>>> much, in particular if the comments look more like complaints and
>>> the same comments are done again and again (along with dragging up
>>> previous comments or comments received on previous comments).
>>>   
>>>       
>> again and again because you seem to be immune to critique.  
>>     
>
> You obviously do not know me.
>   

obviously, i can judge only from what you write. 


<snip>
>   
>>> R is open source.  Check out the svn version, fix what you consider
>>> needs fixing, submit a patch, convince R core that the patch fixes a
>>> real problem/is an improvement/does not break too much.  Then you
>>> have a better chance in achieving something.  
>>>       
>> no, berwin.  this is a serious bug in thinking.  people should be
>> allowed -- *encouraged* -- to discuss the design *before* they even
>> attempt to write patches. 
>>     
>
> And what makes you believe this is not the case?   I have seen over the
> years e-mails to R-devel along the lines "I am thinking of a change
> along [lots of details and reasoning for the change]; would patches
> that implement this be accepted?" and these e-mails were discussed more
> often than not.  However, in the end, the only people who can commit
> changes to the R code are the members of R-core, thus they will have
> the final word of design issues (and, as I assume, they discuss, among
> other things, design issues on the private mailing list of R-core
> member).  But you can discuss this issues before writing a patch.  
>   

how many such mails have you seen?  i've been on r-devel for six months,
and haven't seen many.  (maybe i just haven't noticed.)
on the other hand, i have seen quite a few responses that were bashing a
user for reporting a non-existent bug or submitting an annoying patch.


>   
>> writing one patch which will never be considered -- well, never
>> responded to -- is about enough to stop people from sending patches.
>>     
>
> While it is unfortunate if this happens, and such persons might just be
> too thin-skinned, worse can happen; e.g. being flamed for sending in a
> patch that is considered not to address any problems and with a sloppy
> description of what it tries to address (happened to me).  
>   

well, conscious people choose the way they respond to others.


> Yes, patches are ignored; patches are gratefully acknowledged and
> applied; patches are completely re-written and still attributed to the
> provider of the patch...   That does not mean that I stop sending in a
> patch if I feel it is warranted...
>
> And I am sure that if you had sent an e-mail to r-devel pointing out
> that the binary operator <, when called in the non-standard way 
> '<'(1,2,3), does not check the number of arguments while other binary
> operators (e.g. '+'(1,2,3) or '*'(1,2,3)) do such checks, and provided
> a patch that implemented such a check for '<' (and presumably other
> comparison operators), then that patch would have been acknowledged and
> applied.
>   

it has been fixed immediately by martin. 

a few months back my immediate reaction would be to send a bug report. 
what i have learned here, though, is that first you send a polite
question, because the word 'bug' makes you hot.

>   
>> maybe that's what you want, anyway -- the fewer incoming patches the
>> more you're entitled to think your product is just great.
>>     
>
> If the "you"s and "your" are referring to me, then you are completely
> off track.
>   

no, it was a general reflection.

> IIRC, this discussion started off because I was not enthused of having
> words put into my month in a public forum.  But then it turned into
> another opportunity to correct your misunderstandings about the ways in
> which the R community works.  Let me assure you, one you figure that
> one out, you will be able to interact more productively/satisfactorily
> with that community.  And, again, it does not help to say "this is how
> the culture should be and I behave as if it is this way".  As the
> saying goes, when in Rome do as the Romans.
>   

objection.  exactly the same as to 'when in norway act as norwegians'.


>   
>>>>>> scary!  it's much preferred to confuse new users.
>>>>>>         
>>>>>>             
>>>>> I usually learn a lot when I get confused about some
>>>>> issues/concept. Confusion forces one to sit down, think deeply
>>>>> and, thus, gain some understanding.  So I am not so much
>>>>> concerned with new users being confused.  It is, of course, a
>>>>> problem if the new user never comes out of his or her confusion.
>>>>>       
>>>>>           
>>>> the problem, is, r users have to learn lots [...]
>>>>     
>>>>         
>>> Indeed, and I guess in this age of instant gratification that that
>>> is a real bummer for new users.
>>>   
>>>       
>> why be rude to your users?  "I am not so much concerned with new users
>> being confused." is an explanation -- but maybe you really should?
>>     
>
> As I said, I believe confusion is a great way of gaining understanding
> and knowledge and in that sense I am not so much concerned with new
> users being confused.  I acknowledged that it is a problem if they
> never come out of their confusion.
>   

you should start developing in malbolge instead of r.  your users would
undoubtedly gain immense understanding.

> Also, r-help would only be half the fun without confused (new) users. :)
>   

it would be without me, and you'de be able to continue your great work
in piece.  maybe it's worth it?

vQ


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Mon Feb 23 21:05:26 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Mon, 23 Feb 2009 21:05:26 +0100
Subject: [Rd] a question about (
Message-ID: <49A30186.7040000@idi.ntnu.no>

i wonder why the following approach to make an 'object' executable could
not be made to work:

    foo = 1:3
    class(object) = c('foo', class(foo))
    '(.foo' = function(foo, fun) sapply(foo, fun)

    foo
    # 1 2 3
   
    foo(function(x) x^2)
    # error: no function foo defined

the actual example is inessential, and is inspired by the __call__
method available in python.

what happens is, as of my understanding, that r sees an application
expression with the operator 'foo', and so tries to find a so-named
function, and there is none, hence the error.  however, there *is* an
object named 'foo' there, and so it would, in principle, be possible to
make r try in turn dispatching '(' on the object's type.  this would
lead to the function (.foo, and a successful application.

    isGeneric('(')
    # error: methods may not be defined for primitive function "(" in
this version of R

makes me wonder whether making ( a generic function that would work
along the lines sketched above was actually considered for future
versions of r.  (or has it actually been removed?)

vQ


From h.wickham at gmail.com  Mon Feb 23 21:44:33 2009
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 23 Feb 2009 14:44:33 -0600
Subject: [Rd] [SoC09-Idea] Development of crantastic.org
Message-ID: <f8e6ff050902231244o5a9670d9xf91a8b7049ac7ec9@mail.gmail.com>

Hi all,

Here's my idea for the google summer of code - it's a resubmission
from last year.  We had a couple of interested students, but their
proposals weren't quite competitive enough to get funding.

Regards,

Hadley


Summary: Create an information portal for the fast growing list of R
packages, integrating package documentation and journal publications
with feedback from the useR community.

Required skills: Familiarity with Ruby and R, and web development in
general (html, css, js, ...). knowledge of RSS/Atom could be useful.

Description: The CRAN archives contain over 1300 source packages of
very high-quality, and BioConductor has another 200+. For many data
analytic tasks there is more than one package offering a solution,
often using different names for similar functionality, because
different research communities may use different vocabulary for
similar methods (e.g., statistics vs. machine learning jargon). Hence
it is often hard for users to find the packages they really need. CRAN
task views offer some help, but are edited by designated maintainers
and hence cannot cover all fields and aspects.

crantastic.org implements a first step in complementing this with
package reviews from the useR community, but it still lacks many
features we would like to have: integration with task views,
vignettes, and journal publications; match authors and users based on
email address; list top users and authors on respective pages;
implement a rating system; event streams for packages and users;
integration with CRANberries RSS feed, etc.

If you're interested in this project take a look at the current code,
available at https://github.com/hadley/crantastic/tree, and include a
couple of concrete suggestions as to how you would improve the current
code, and how you plan to implement the additional features.

-- 
http://had.co.nz/


From berwin at maths.uwa.edu.au  Tue Feb 24 09:02:52 2009
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Tue, 24 Feb 2009 16:02:52 +0800
Subject: [Rd] [R] Semantics of sequences in R
In-Reply-To: <49A2F89B.10900@idi.ntnu.no>
References: <8b356f880902221242r47cdb138w9b1ac05cc5e5e317@mail.gmail.com>
	<49A1BFC7.9060503@stats.uwo.ca>
	<8b356f880902221350q4a976bfr19b0d5b01a989250@mail.gmail.com>
	<20090223113422.76cc1494@absentia> <49A255A5.1010506@idi.ntnu.no>
	<20090223175623.6106add2@berwin-nus1> <49A27AF4.307@idi.ntnu.no>
	<20090223192757.2ff7f629@berwin-nus1>
	<49A2961C.3020405@idi.ntnu.no> <20090224001247.5d2e3db9@berwin5>
	<49A2F89B.10900@idi.ntnu.no>
Message-ID: <20090224160252.154a7d75@berwin-nus1>

On Mon, 23 Feb 2009 20:27:23 +0100
Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:

> Berwin A Turlach wrote:

> >> [...]
> >> judging from your question, you couldn't possibly see sorting
> >> routines in other languages.
> >>     
> >
> > Quite likely, or the other languages that I regularly use (C,
> > Fortran) have even more primitive sorting facilities. 
> >   
> 
> i apologize, [...]

Apology accepted.

[...]
> >>> No, if that is what you want.  And I guess it is one way of
> >>> sorting a list.  The question is what should be the default
> >>> way? 
> >> one possible answer is: none.  (i have already given this answer
> >> previously, if you read carefully it's still there).  sort.list
> >> *should* demand an additional comparator argument.  at least, it
> >> should demand it if the argument to be sorted is a list, rather
> >> than a non-list vector (if you still need to use sort.list on
> >> non-lists). 
> >
> > So when are you sending your patch to implement this facility?
> 
> as i said, you seem to have a severe bug in thinking about
> collaborative development.
> 
> i am sending *no* patch for this.  the issue has to be first discussed
> on the design level, and only then, if accepted, should anyone -- me,
> for example -- make an attempt to implement it.  tell me you want to
> listen to what i have to say, and we can discuss.  

I could tell you that I will listen and we can discuss this until the
cows come home.  This will not change one iota since neither of us have
the power to implement changes in R.  You keep barking up the wrong
tree.  

So far I have seen only one posting of an R-core member in this thread
(but perhaps he has started further discussion on the R-core mailing
list to which we are not privy), but if you want to have discussion and
acceptance before you do anything, you have to get R core involved.

Since for the kind of work for which I am using R a facility for
sorting lists is not crucial, I am rather indifferent about whether
such a facility should exist and, if so, how it should be designed.

> telling me i have a chip on my shoulder is rather unhelpful.

Well, then stop acting as if you are running around with chips on your
shoulders.  Behaving in such a manner is rather counter productive in
the R community (at least from my experience/observation).  The same
with publicly stating that you do certain things with the purpose of
annoying certain persons.  I am just pointing out that your behaviour
is counter productive but it is really up to you on whether you change
or want to continue in your ways.

There is a nice German proverb that sums all this up "wie man in den
Wald reinruft so schallt es heraus".  Unfortunately, an equivalent
English proverb does not exist, but perhaps the Norwegians have
something similar....

> <snip>
> >   
> >>> R is open source.  Check out the svn version, fix what you
> >>> consider needs fixing, submit a patch, convince R core that the
> >>> patch fixes a real problem/is an improvement/does not break too
> >>> much.  Then you have a better chance in achieving something.  
> >>>       
> >> no, berwin.  this is a serious bug in thinking.  people should be
> >> allowed -- *encouraged* -- to discuss the design *before* they even
> >> attempt to write patches. 
> >>     
> >
> > And what makes you believe this is not the case?   I have seen over
> > the years e-mails to R-devel along the lines "I am thinking of a
> > change along [lots of details and reasoning for the change]; would
> > patches that implement this be accepted?" and these e-mails were
> > discussed more often than not.  However, in the end, the only
> > people who can commit changes to the R code are the members of
> > R-core, thus they will have the final word of design issues (and,
> > as I assume, they discuss, among other things, design issues on the
> > private mailing list of R-core member).  But you can discuss this
> > issues before writing a patch. 
> 
> how many such mails have you seen?  

A few over the years, but the more R progresses/matures the less of
such e-mail happens.

> i've been on r-devel for six months, and haven't seen many.  

Well, six month is a rather narrow sampling window....

> on the other hand, i have seen quite a few responses that were
> bashing a user for reporting a non-existent bug or submitting an
> annoying patch.

In didactic terms those are "negative motivations/reinforcements";
opinion differ on how effective they are to reach certain learning
outcomes.   

> > And I am sure that if you had sent an e-mail to r-devel pointing out
> > that the binary operator <, when called in the non-standard way 
> > '<'(1,2,3), does not check the number of arguments while other
> > binary operators (e.g. '+'(1,2,3) or '*'(1,2,3)) do such checks,
> > and provided a patch that implemented such a check for '<' (and
> > presumably other comparison operators), then that patch would have
> > been acknowledged and applied.
> >   
> 
> it has been fixed immediately by martin. 

Yes, and, again, you could not help yourself telling the developers
what you think they should do, could you?  As I try to tell you, that
is not the way it works.  R comes already with extensive tests that are
run with "make check".  If you think some are missing, you could send a
script and propose that they are included.  But telling others that
they should write such tests is unlikely to make it happen.

> a few months back my immediate reaction would be to send a bug
> report. what i have learned here, though, is that first you send a
> polite question, because the word 'bug' makes you hot.

I do not remember that people have been criticised for calling a bug a
bug when reporting it; especially not if a patch to fix the bug was
included.  

Reporting documented behaviour as bug is a totally different matter.  
  
[...]
> you should start developing in malbolge instead of r. 

Once you bring that system onto the level of R with the functionality I
need, I might consider this.

Best wishes,

	Berwin


From maechler at stat.math.ethz.ch  Tue Feb 24 09:06:54 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 24 Feb 2009 09:06:54 +0100
Subject: [Rd] [R] are arithmetic comparison operators binary?
In-Reply-To: <49A2EB0B.5000409@idi.ntnu.no>
References: <49A28338.1080009@idi.ntnu.no>
	<18850.47461.374326.854888@stat.math.ethz.ch>
	<49A2EB0B.5000409@idi.ntnu.no>
Message-ID: <18851.43678.942938.967721@stat.math.ethz.ch>

>>>>> "WK" == Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no>
>>>>>     on Mon, 23 Feb 2009 19:29:31 +0100 writes:

    WK> Martin Maechler wrote:
    >>>>>>> "WK" == Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no>
    >>>>>>> on Mon, 23 Feb 2009 12:06:32 +0100 writes:
    >>>>>>> 
    >> 
    >> Thank you, Wacek, 
    >> though .. "wrong mailing list" 
    >> 

    WK> apologies.  i was actually asking for explanation, assuming that it
    WK> might be my misunderstanding, rather than reporting a bug.

( yes; but it is really a technical topic, also touching on
  extending R [below], hence --> R-devel )

    WK> the man page for relational operators (see, e.g., ?'<') says:
    WK> "
    WK> Binary operators which allow the comparison of values in atomic vectors.
    >> 
    WK> Arguments:
    >> 
    WK> x, y: atomic vectors, symbols, calls, or other objects for which
    WK> methods have been written.
    WK> "
    >> 
    WK> it is somewhat surprizing that the following works:
    >> 
    WK> '<'(1)
    WK> # logical(0)
    >> 
    WK> '<'()
    WK> # logical(0)
    >> 
    WK> '<'(1,2,3)
    WK> # TRUE
    >> 
    >> a bit surprising (sic!), indeed, even for me.
    >> Thanks for your notice and report!
    >> 

    WK> you're welcome. 

    WK> shouldn't the tests have captured it?  i think you should have a check
    WK> for every feature following from the docs.  

yes, we should.  

  >> R is free software and comes with ABSOLUTELY NO WARRANTY.
  >> You are welcome to ......................
  >>   .............

  >> R is a collaborative project with many contributors.

I think we'd gladly accept well-written & commented extra
  <R-x.y.z>/tests/foo.R  
files or patches to existing ./tests/*.R 
particularly if the contributor shows the new tests are
systematically covering currently untested areas...
Again: this really belongs to R-devel

--> I'm CCing there  {and write a quick reply on R-help about
    the mailing list redirection}

    WK> plus those undocumented, but assumed by the developers.

  ;-) :-)

Indeed, we are also grateful for (concise!) patches to  man/*.Rd
help files.

    >> If you'd looked a bit in the sources, you'd seen that they
    >> really are supposed to be binary only.
    >> 

    WK> it wouldn't be nonsensical to let them be of arbitrary arity (in a
    WK> well-documented manner), though it might confuse users.

Yes (to the latter).  One of the beauties of S and R is the
syntax closeness to  mathematical notation.
Many of us know that  Lisp  has beauties that S can never have,
but that's really in different beauty-space. 


    >> A very small change in the sources does accomplish this, passes
    >> the standard checks (and I cannot imagine reasonable code that
    >> would have relied on the more lenient behavior), so
    >> this will have changed in one of the next versions of R-devel.
    >> 

    WK> thanks.

    WK> just a question (i haven't checked the sources, maybe i should):  what
    WK> is it that happens when one of the operators is called with n = 0 or 1
    WK> argument?  how does it come up with logical(0) rather than NA?

In some of the cases  e.g. 
   '<'(1)   

it basically does   [empty] < 1  and hence returns the same as

   NULL < 1

Regards,
Martin Maechler, ETH Zurich


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Tue Feb 24 09:39:51 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Tue, 24 Feb 2009 09:39:51 +0100
Subject: [Rd] [R] Semantics of sequences in R
In-Reply-To: <20090224160252.154a7d75@berwin-nus1>
References: <8b356f880902221242r47cdb138w9b1ac05cc5e5e317@mail.gmail.com>	<49A1BFC7.9060503@stats.uwo.ca>	<8b356f880902221350q4a976bfr19b0d5b01a989250@mail.gmail.com>	<20090223113422.76cc1494@absentia>	<49A255A5.1010506@idi.ntnu.no>	<20090223175623.6106add2@berwin-nus1>	<49A27AF4.307@idi.ntnu.no>	<20090223192757.2ff7f629@berwin-nus1>	<49A2961C.3020405@idi.ntnu.no>	<20090224001247.5d2e3db9@berwin5>	<49A2F89B.10900@idi.ntnu.no>
	<20090224160252.154a7d75@berwin-nus1>
Message-ID: <49A3B257.2000103@idi.ntnu.no>

Berwin A Turlach wrote:
>
>> i am sending *no* patch for this.  the issue has to be first discussed
>> on the design level, and only then, if accepted, should anyone -- me,
>> for example -- make an attempt to implement it.  tell me you want to
>> listen to what i have to say, and we can discuss.  
>>     
>
> I could tell you that I will listen and we can discuss this until the
> cows come home.  This will not change one iota since neither of us have
> the power to implement changes in R.  You keep barking up the wrong
> tree.  
>   

i am barking on the list;  whoever is the appropriate person to react,
has the chance to read and react.  i don't think it's appropriate to
send my messages to x or y personally.  what is the right tree, you say?

> So far I have seen only one posting of an R-core member in this thread
> (but perhaps he has started further discussion on the R-core mailing
> list to which we are not privy), but if you want to have discussion and
> acceptance before you do anything, you have to get R core involved.
>
> Since for the kind of work for which I am using R a facility for
> sorting lists is not crucial, I am rather indifferent about whether
> such a facility should exist and, if so, how it should be designed.
>
>   

i discussed these things with you, because you responded.  this made me
think you were not indifferent, but anyway i kept ccing to the list
precisely because because i don't think you're the right person to make
a decision or suggest the next steps.

>> telling me i have a chip on my shoulder is rather unhelpful.
>>     
>
> Well, then stop acting as if you are running around with chips on your
> shoulders.  Behaving in such a manner is rather counter productive in
> the R community (at least from my experience/observation).  

why not read some fortunes?

"When a Certain Guru rips strips off people (God knows he's done it to
me often
enough) on this list, there's a damned good reason for it.
   -- Rolf Turner (in a discussion about whether a friendly mailing list
with
      more 'customer service' attitude than R-help was needed)
      R-help (December 2003)"

when gurus are ripped strips off on this list, there's a damned good
reason for it.
(and i'm actually not doing it.)  or:

"You may have not been long enough on this list to see that some of the
old-time
gurus have reached a demigod like status. Demigods have all rights to be
'rude'
(that's almost a definition of a demi-deity).
   -- Jari Oksanen (in a discussion on whether answers on R-help should
be more
      polite)
      R-help (December 2004)"

which certainly documents a very productive approach to communication
with users.
<snip>

>>> And what makes you believe this is not the case?   I have seen over
>>> the years e-mails to R-devel along the lines "I am thinking of a
>>> change along [lots of details and reasoning for the change]; would
>>> patches that implement this be accepted?" and these e-mails were
>>> discussed more often than not.  However, in the end, the only
>>> people who can commit changes to the R code are the members of
>>> R-core, thus they will have the final word of design issues (and,
>>> as I assume, they discuss, among other things, design issues on the
>>> private mailing list of R-core member).  But you can discuss this
>>> issues before writing a patch. 
>>>       
>> how many such mails have you seen?  
>>     
>
> A few over the years, but the more R progresses/matures the less of
> such e-mail happens.
>
>   

a few over the years?

>> i've been on r-devel for six months, and haven't seen many.  
>>     
>
> Well, six month is a rather narrow sampling window....
>   

your sampling window does not seem to provide better results.


>   
>> on the other hand, i have seen quite a few responses that were
>> bashing a user for reporting a non-existent bug or submitting an
>> annoying patch.
>>     
>
> In didactic terms those are "negative motivations/reinforcements";
> opinion differ on how effective they are to reach certain learning
> outcomes.   
>   

ah, so what's the difference between the way i pinpoint design flaws and
the way r gurus respond to people, so that i am running with a chip on
my shoulder, and they are being 'negatively motivating/reinforcing' in
didactic terms?  (am i correct, is the 'negative
motivation/reinforcement' the same stuff jari oksanen talked about?)


>   
>>> And I am sure that if you had sent an e-mail to r-devel pointing out
>>> that the binary operator <, when called in the non-standard way 
>>> '<'(1,2,3), does not check the number of arguments while other
>>> binary operators (e.g. '+'(1,2,3) or '*'(1,2,3)) do such checks,
>>> and provided a patch that implemented such a check for '<' (and
>>> presumably other comparison operators), then that patch would have
>>> been acknowledged and applied.
>>>   
>>>       
>> it has been fixed immediately by martin. 
>>     
>
> Yes, and, again, you could not help yourself telling the developers
> what you think they should do, could you?  

was this really running with a chip:

"shouldn't the tests have captured it? i think you should have a check
for every feature following from the docs."

to which marting responded "yes, we should"


> As I try to tell you, that
> is not the way it works.  R comes already with extensive tests that are
> run with "make check".  If you think some are missing, you could send a
> script and propose that they are included.  But telling others that
> they should write such tests is unlikely to make it happen.
>   

haven't done the thing.

vQ


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Tue Feb 24 10:13:22 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Tue, 24 Feb 2009 10:13:22 +0100
Subject: [Rd] [R] are arithmetic comparison operators binary?
In-Reply-To: <18851.43678.942938.967721@stat.math.ethz.ch>
References: <49A28338.1080009@idi.ntnu.no>	<18850.47461.374326.854888@stat.math.ethz.ch>	<49A2EB0B.5000409@idi.ntnu.no>
	<18851.43678.942938.967721@stat.math.ethz.ch>
Message-ID: <49A3BA32.3060108@idi.ntnu.no>

Martin Maechler wrote:
>
>     >> Thank you, Wacek, 
>     >> though .. "wrong mailing list" 
>     >> 
>
>     WK> apologies.  i was actually asking for explanation, assuming that it
>     WK> might be my misunderstanding, rather than reporting a bug.
>
> ( yes; but it is really a technical topic, also touching on
>   extending R [below], hence --> R-devel )
>   

point taken.

> I think we'd gladly accept well-written & commented extra
>   <R-x.y.z>/tests/foo.R  
> files or patches to existing ./tests/*.R 
> particularly if the contributor shows the new tests are
> systematically covering currently untested areas...
> Again: this really belongs to R-devel
>
>   

ok.

>     WK> plus those undocumented, but assumed by the developers.
>
>   ;-) :-)
>
> Indeed, we are also grateful for (concise!) patches to  man/*.Rd
> help files.
>   

ok.

>     >> If you'd looked a bit in the sources, you'd seen that they
>     >> really are supposed to be binary only.
>     >> 
>
>     WK> it wouldn't be nonsensical to let them be of arbitrary arity (in a
>     WK> well-documented manner), though it might confuse users.
>
> Yes (to the latter).  One of the beauties of S and R is the
> syntax closeness to  mathematical notation.
> Many of us know that  Lisp  has beauties that S can never have,
> but that's really in different beauty-space. 
>   

not quite sure what you mean by 'closeness to mathematical notation' here.


>     WK> just a question (i haven't checked the sources, maybe i should):  what
>     WK> is it that happens when one of the operators is called with n = 0 or 1
>     WK> argument?  how does it come up with logical(0) rather than NA?
>
> In some of the cases  e.g. 
>    '<'(1)   
>
> it basically does   [empty] < 1  and hence returns the same as
>
>    NULL < 1
>   
which is consistent with NULL + 1.  btw:

1. you might want to keep the error message from applying < and other
relops to an inappropriate number of arguments in sync with the message
one gets from, e.g., '+'(1,2,3).  (you may want to actually update the
message from '+' and relatives, as it seems that there are more
operators that give an error message similar to that of '<'.  the
attached patch fixes this; it has been compiled and successfully tested
-- see below.)

2. '+'() and '+'(1,2,3) say the operator needs one or two arguments, but
again, '+' is documented as a *binary* operator.  i guess the intention
here is to have them unary or binary, and it's the docs that should be
updated.

vQ


The patch for src/main/arithmetic.c was prepared as follows:

svn co https://svn.R-project.org/R/trunk/
cd trunk
tools/rsync-recommended
# modifications made to src/main/character.c
svn diff > do_grep.diff

The patched sources were successfully compiled and tested as follows:

svn revert -R .
patch -p0 < do_grep.diff
./configure
make
make check



-------------- next part --------------
A non-text attachment was scrubbed...
Name: arithmetic.diff
Type: text/x-diff
Size: 509 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090224/d06f659d/attachment.bin>

From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Tue Feb 24 10:17:49 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Tue, 24 Feb 2009 10:17:49 +0100
Subject: [Rd] [R] are arithmetic comparison operators binary?
In-Reply-To: <49A3BA32.3060108@idi.ntnu.no>
References: <49A28338.1080009@idi.ntnu.no>	<18850.47461.374326.854888@stat.math.ethz.ch>	<49A2EB0B.5000409@idi.ntnu.no>
	<18851.43678.942938.967721@stat.math.ethz.ch>
	<49A3BA32.3060108@idi.ntnu.no>
Message-ID: <49A3BB3D.3090604@idi.ntnu.no>

Wacek Kusnierczyk wrote:
>
> The patch for src/main/arithmetic.c was prepared as follows:
>
> svn co https://svn.R-project.org/R/trunk/
> cd trunk
> tools/rsync-recommended
> # modifications made to src/main/character.c
> svn diff > do_grep.diff
>
> The patched sources were successfully compiled and tested as follows:
>
> svn revert -R .
> patch -p0 < do_grep.diff
> ./configure
> make
> make check
>
>   

obviously, i forgot to replace 'do_grep' with 'arithmetic'.

vQ


From berwin at maths.uwa.edu.au  Tue Feb 24 10:52:15 2009
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Tue, 24 Feb 2009 17:52:15 +0800
Subject: [Rd] [R] Semantics of sequences in R
In-Reply-To: <49A3B257.2000103@idi.ntnu.no>
References: <8b356f880902221242r47cdb138w9b1ac05cc5e5e317@mail.gmail.com>
	<49A1BFC7.9060503@stats.uwo.ca>
	<8b356f880902221350q4a976bfr19b0d5b01a989250@mail.gmail.com>
	<20090223113422.76cc1494@absentia> <49A255A5.1010506@idi.ntnu.no>
	<20090223175623.6106add2@berwin-nus1> <49A27AF4.307@idi.ntnu.no>
	<20090223192757.2ff7f629@berwin-nus1>
	<49A2961C.3020405@idi.ntnu.no> <20090224001247.5d2e3db9@berwin5>
	<49A2F89B.10900@idi.ntnu.no> <20090224160252.154a7d75@berwin-nus1>
	<49A3B257.2000103@idi.ntnu.no>
Message-ID: <20090224175215.1336a820@berwin-nus1>

On Tue, 24 Feb 2009 09:39:51 +0100
Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:

> Berwin A Turlach wrote:

[...]
> why not read some fortunes?
I am well aware of those fortunes and maybe you missed the one:

> fortune("Watson")

Getting flamed for asking dumb questions on a public mailing list is
all part of growing up and being a man/woman.
   -- Michael Watson (in a discussion on whether answers on R-help
      should be more polite)
      R-help (December 2004)

I am actually wondering where the corresponding fortunes from December
2005, December 2006, December 2007 and December 2009 are since they
started of be produced on an annual basis.

[...]
> >> on the other hand, i have seen quite a few responses that were
> >> bashing a user for reporting a non-existent bug or submitting an
> >> annoying patch.
> >>     
> >
> > In didactic terms those are "negative motivations/reinforcements";
> > opinion differ on how effective they are to reach certain learning
> > outcomes.   
> >   
> 
> ah, so what's the difference between the way i pinpoint design flaws
> and the way r gurus respond to people, so that i am running with a
> chip on my shoulder, and they are being 'negatively
> motivating/reinforcing' in didactic terms?  [...]

Your goal is, presumably, that you want to have the design flaws
fixed/discussed/&c.  The goal of the R gurus is to avoid having to
waste their time on unproductive issues because people do not read
documentation/behave contrary to how they are asked to behave/&c.

To reach your goal, the controversial approach is counter productive.
To reach their goal, the controversial approach can be quite effective.

[...]
> >> it has been fixed immediately by martin. 
> >>     
> >
> > Yes, and, again, you could not help yourself telling the developers
> > what you think they should do, could you?  
> 
> was this really running with a chip:

Look up what "running with a chip on your shoulder means" and reflect
on the occasions in which I suggested to you that you give the
impression of doing so.   On this occasion nobody said that you were
running around with a chip on your shoulder.

> "shouldn't the tests have captured it? i think you should have a check
> for every feature following from the docs."
> 
> to which marting responded "yes, we should"

But he also made it clear that it would be unlikely that he or any
other R-core member would write those tests and that this would
probably be left to you; with any contribution being welcome.  Consider
yourself lucky that this exchange was with Martin, other members of R
core might have communicated a similar message in quite another way.
That exchange is very much confirming my understanding of the culture
of the R community.

> > As I try to tell you, that
> > is not the way it works.  R comes already with extensive tests that
> > are run with "make check".  If you think some are missing, you
> > could send a script and propose that they are included.  But
> > telling others that they should write such tests is unlikely to
> > make it happen. 
> 
> haven't done the thing.

Come on, read your own quote above:  "Shouldn't the tests have captured
this?  I think you should have a check for every feature following from
the docs",  If this is not "telling others that they should write such
test", then what is?  

Cheers,

	Berwin


From d.rizopoulos at erasmusmc.nl  Tue Feb 24 11:19:15 2009
From: d.rizopoulos at erasmusmc.nl (Dimitris Rizopoulos)
Date: Tue, 24 Feb 2009 11:19:15 +0100
Subject: [Rd] [R] Semantics of sequences in R
In-Reply-To: <20090224175215.1336a820@berwin-nus1>
References: <8b356f880902221242r47cdb138w9b1ac05cc5e5e317@mail.gmail.com>	<49A1BFC7.9060503@stats.uwo.ca>	<8b356f880902221350q4a976bfr19b0d5b01a989250@mail.gmail.com>	<20090223113422.76cc1494@absentia>
	<49A255A5.1010506@idi.ntnu.no>	<20090223175623.6106add2@berwin-nus1>
	<49A27AF4.307@idi.ntnu.no>	<20090223192757.2ff7f629@berwin-nus1>	<49A2961C.3020405@idi.ntnu.no>
	<20090224001247.5d2e3db9@berwin5>	<49A2F89B.10900@idi.ntnu.no>
	<20090224160252.154a7d75@berwin-nus1>	<49A3B257.2000103@idi.ntnu.no>
	<20090224175215.1336a820@berwin-nus1>
Message-ID: <49A3C9A3.80506@erasmusmc.nl>



Berwin A Turlach wrote:
> On Tue, 24 Feb 2009 09:39:51 +0100
> Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:
> 
>> Berwin A Turlach wrote:
> 
> [...]
>> why not read some fortunes?
> I am well aware of those fortunes and maybe you missed the one:
> 
>> fortune("Watson")
> 
> Getting flamed for asking dumb questions on a public mailing list is
> all part of growing up and being a man/woman.
>    -- Michael Watson (in a discussion on whether answers on R-help
>       should be more polite)
>       R-help (December 2004)
> 
> I am actually wondering where the corresponding fortunes from December
> 2005, December 2006, December 2007 and December 2009 are since they
> started of be produced on an annual basis.
> 
> [...]
>>>> on the other hand, i have seen quite a few responses that were
>>>> bashing a user for reporting a non-existent bug or submitting an
>>>> annoying patch.
>>>>     
>>> In didactic terms those are "negative motivations/reinforcements";
>>> opinion differ on how effective they are to reach certain learning
>>> outcomes.   
>>>   
>> ah, so what's the difference between the way i pinpoint design flaws
>> and the way r gurus respond to people, so that i am running with a
>> chip on my shoulder, and they are being 'negatively
>> motivating/reinforcing' in didactic terms?  [...]
> 
> Your goal is, presumably, that you want to have the design flaws
> fixed/discussed/&c.  The goal of the R gurus is to avoid having to
> waste their time on unproductive issues because people do not read
> documentation/behave contrary to how they are asked to behave/&c.
> 
> To reach your goal, the controversial approach is counter productive.
> To reach their goal, the controversial approach can be quite effective.

in my opinion the point of the whole discussion could be summarized by 
the question, what is a design flaw? This is totally subjective, and it 
happens almost everywhere in life. Take human languages as an example 
and in particular, English. I do not know the history of the English 
language but I can guess at some point some people decided that the past 
tense for "give" should be "gave" and not "gived" according to the 
standard rule, possibly because they thought it has better acoustic.

Is this a design flaw of English? Some might argue yes, maybe they would 
think "gived" does not have a that bad acoustic or they could have come 
up with another possibility than "gave". Does this confuse new users of 
English? Of course it does -- I had to spent many hours learning the 
past tense and past particle of the irregular verbs. Should it be 
changed? Then almost all existing code (i.e., English texts) should be 
rewritten, which I think demonstrates why some people are a bit 
reluctant in design changes.

To close I'd like to share with you a Greek saying (maybe also a saying 
in other parts of the world) that goes, for every rule there is an 
exception. The important thing, in my opinion, is that these exceptions 
are documented.

Best,
Dimitris


> [...]
>>>> it has been fixed immediately by martin. 
>>>>     
>>> Yes, and, again, you could not help yourself telling the developers
>>> what you think they should do, could you?  
>> was this really running with a chip:
> 
> Look up what "running with a chip on your shoulder means" and reflect
> on the occasions in which I suggested to you that you give the
> impression of doing so.   On this occasion nobody said that you were
> running around with a chip on your shoulder.
> 
>> "shouldn't the tests have captured it? i think you should have a check
>> for every feature following from the docs."
>>
>> to which marting responded "yes, we should"
> 
> But he also made it clear that it would be unlikely that he or any
> other R-core member would write those tests and that this would
> probably be left to you; with any contribution being welcome.  Consider
> yourself lucky that this exchange was with Martin, other members of R
> core might have communicated a similar message in quite another way.
> That exchange is very much confirming my understanding of the culture
> of the R community.
> 
>>> As I try to tell you, that
>>> is not the way it works.  R comes already with extensive tests that
>>> are run with "make check".  If you think some are missing, you
>>> could send a script and propose that they are included.  But
>>> telling others that they should write such tests is unlikely to
>>> make it happen. 
>> haven't done the thing.
> 
> Come on, read your own quote above:  "Shouldn't the tests have captured
> this?  I think you should have a check for every feature following from
> the docs",  If this is not "telling others that they should write such
> test", then what is?  
> 
> Cheers,
> 
> 	Berwin
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Dimitris Rizopoulos
Assistant Professor
Department of Biostatistics
Erasmus University Medical Center

Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
Tel: +31/(0)10/7043478
Fax: +31/(0)10/7043014


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Tue Feb 24 11:27:08 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Tue, 24 Feb 2009 11:27:08 +0100
Subject: [Rd] [R] Semantics of sequences in R
In-Reply-To: <20090224175215.1336a820@berwin-nus1>
References: <8b356f880902221242r47cdb138w9b1ac05cc5e5e317@mail.gmail.com>	<49A1BFC7.9060503@stats.uwo.ca>	<8b356f880902221350q4a976bfr19b0d5b01a989250@mail.gmail.com>	<20090223113422.76cc1494@absentia>
	<49A255A5.1010506@idi.ntnu.no>	<20090223175623.6106add2@berwin-nus1>
	<49A27AF4.307@idi.ntnu.no>	<20090223192757.2ff7f629@berwin-nus1>	<49A2961C.3020405@idi.ntnu.no>
	<20090224001247.5d2e3db9@berwin5>	<49A2F89B.10900@idi.ntnu.no>
	<20090224160252.154a7d75@berwin-nus1>	<49A3B257.2000103@idi.ntnu.no>
	<20090224175215.1336a820@berwin-nus1>
Message-ID: <49A3CB7C.4090105@idi.ntnu.no>

Berwin A Turlach wrote:
>
> I am well aware of those fortunes and maybe you missed the one:
>
>   
>> fortune("Watson")
>>     
>
> Getting flamed for asking dumb questions on a public mailing list is
> all part of growing up and being a man/woman.
>    -- Michael Watson (in a discussion on whether answers on R-help
>       should be more polite)
>       R-help (December 2004)
>   

i did miss it.  i'm gladly including it in my collection of quotes
documenting your approach to your users.  thanks.

>
>> ah, so what's the difference between the way i pinpoint design flaws
>> and the way r gurus respond to people, so that i am running with a
>> chip on my shoulder, and they are being 'negatively
>> motivating/reinforcing' in didactic terms?  [...]
>>     
>
> Your goal is, presumably, that you want to have the design flaws
> fixed/discussed/&c.  The goal of the R gurus is to avoid having to
> waste their time on unproductive issues because people do not read
> documentation/behave contrary to how they are asked to behave/&c.
>
> To reach your goal, the controversial approach is counter productive.
> To reach their goal, the controversial approach can be quite effective.
>
>   

nice summary.  you rule, we crawl.

> Come on, read your own quote above:  "Shouldn't the tests have captured
> this?  I think you should have a check for every feature following from
> the docs",  If this is not "telling others that they should write such
> test", then what is?  
>   

employing the recent trick of duncan's, i'd say that i wasn't telling
anyone that they should do something.  i said 'i think', which is
explaining what i think, not telling to do.

but even without the trick, even if i said 'you should' instead of 'i
think you should', if you were not oversensitive, exaggerating, and
prejudiced, you would be able to read it as a suggestion.  we clearly
differ in our understanding of 'tell' -- and it's of course my fault, as
my english is certainly more unlike the official than yours.

vQ


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Tue Feb 24 11:31:13 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Tue, 24 Feb 2009 11:31:13 +0100
Subject: [Rd] [R] Semantics of sequences in R
In-Reply-To: <49A3C9A3.80506@erasmusmc.nl>
References: <8b356f880902221242r47cdb138w9b1ac05cc5e5e317@mail.gmail.com>	<49A1BFC7.9060503@stats.uwo.ca>	<8b356f880902221350q4a976bfr19b0d5b01a989250@mail.gmail.com>	<20090223113422.76cc1494@absentia>	<49A255A5.1010506@idi.ntnu.no>	<20090223175623.6106add2@berwin-nus1>	<49A27AF4.307@idi.ntnu.no>	<20090223192757.2ff7f629@berwin-nus1>	<49A2961C.3020405@idi.ntnu.no>	<20090224001247.5d2e3db9@berwin5>	<49A2F89B.10900@idi.ntnu.no>	<20090224160252.154a7d75@berwin-nus1>	<49A3B257.2000103@idi.ntnu.no>	<20090224175215.1336a820@berwin-nus1>
	<49A3C9A3.80506@erasmusmc.nl>
Message-ID: <49A3CC71.6050207@idi.ntnu.no>

Dimitris Rizopoulos wrote:
> in my opinion the point of the whole discussion could be summarized by
> the question, what is a design flaw? This is totally subjective, and
> it happens almost everywhere in life. Take human languages as an
> example and in particular, English. I do not know the history of the
> English language but I can guess at some point some people decided
> that the past tense for "give" should be "gave" and not "gived"
> according to the standard rule, possibly because they thought it has
> better acoustic.
>
> Is this a design flaw of English? Some might argue yes, maybe they
> would think "gived" does not have a that bad acoustic or they could
> have come up with another possibility than "gave". Does this confuse
> new users of English? Of course it does -- I had to spent many hours
> learning the past tense and past particle of the irregular verbs.
> Should it be changed? Then almost all existing code (i.e., English
> texts) should be rewritten, which I think demonstrates why some people
> are a bit reluctant in design changes.
>
> To close I'd like to share with you a Greek saying (maybe also a
> saying in other parts of the world) that goes, for every rule there is
> an exception. The important thing, in my opinion, is that these
> exceptions are documented.

all this is true;  however, programming languages are not natural
languages, there are substantial differences, and conclusions valid for
natural languages are not necessarily valid for programming languages.

vQ


From romain.francois at dbmail.com  Tue Feb 24 12:03:41 2009
From: romain.francois at dbmail.com (romain.francois at dbmail.com)
Date: Tue, 24 Feb 2009 12:03:41 +0100 (CET)
Subject: [Rd] sys.source and encoding
Message-ID: <26211296.643721235473421155.JavaMail.www@wwumf0206>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090224/bb282538/attachment.pl>

From berwin at maths.uwa.edu.au  Tue Feb 24 14:14:36 2009
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Tue, 24 Feb 2009 21:14:36 +0800
Subject: [Rd] [R] Semantics of sequences in R
In-Reply-To: <49A3C9A3.80506@erasmusmc.nl>
References: <8b356f880902221242r47cdb138w9b1ac05cc5e5e317@mail.gmail.com>
	<49A1BFC7.9060503@stats.uwo.ca>
	<8b356f880902221350q4a976bfr19b0d5b01a989250@mail.gmail.com>
	<20090223113422.76cc1494@absentia> <49A255A5.1010506@idi.ntnu.no>
	<20090223175623.6106add2@berwin-nus1> <49A27AF4.307@idi.ntnu.no>
	<20090223192757.2ff7f629@berwin-nus1>
	<49A2961C.3020405@idi.ntnu.no> <20090224001247.5d2e3db9@berwin5>
	<49A2F89B.10900@idi.ntnu.no> <20090224160252.154a7d75@berwin-nus1>
	<49A3B257.2000103@idi.ntnu.no>
	<20090224175215.1336a820@berwin-nus1> <49A3C9A3.80506@erasmusmc.nl>
Message-ID: <20090224211436.2e145e95@berwin5>

G'day Dimitris,

On Tue, 24 Feb 2009 11:19:15 +0100
Dimitris Rizopoulos <d.rizopoulos at erasmusmc.nl> wrote:

> in my opinion the point of the whole discussion could be summarized
> by the question, what is a design flaw? This is totally subjective,
> and it happens almost everywhere in life. [...]

Beautifully summarised and I completely agree.  Not surprisingly,
others don't.

[...]
> To close I'd like to share with you a Greek saying (maybe also a
> saying in other parts of the world) that goes, for every rule there
> is an exception. [...]

As far as I know, the same saying exist in English.  It definitely
exist in German.  Actually, in German it is "every rule has its
exception including this rule".  In German there is one grammar rule
that does not have an exception.  At least there used to be one; I am
not really sure whether that rule survived the recent reform of the
German grammar rules.

Cheers,

	Berwin


From prea at uninsubria.it  Tue Feb 24 15:34:55 2009
From: prea at uninsubria.it (Damiano G. Preatoni)
Date: Tue, 24 Feb 2009 15:34:55 +0100
Subject: [Rd] [SoC09-Idea] Movement Ecology add-ons for adehabitat package
Message-ID: <200902241535.04068.prea@uninsubria.it>

Hi all,
  here's a proposal for a SoC project on wildlife movement patterns analysis.
A MSc student is available to anwser the call, of course. The idea has already 
been briefly discussed with the mantainer of the adehabitat package and the 
AniMov project community.


Short description
Develop some add-on functions to use the adehabitat package to perform basic 
movement ecology analysis, in particular analysis of fractal dimension D. 
Developed functions could possibly be included in a future release of the 
adehabitat package itself.

Detailed description
Fractal dimension analysis is an useful tool to better understand not just 
the 'path tortuosity', in an animal's trajectory, but also the scale level at 
which 'search patterns' occur, i.e. an indirect index of the scale at which 
habtat resources are 'perceived'.
It has already been shown using simulations (Nams 2005; Oecologia 143: 
179-188) that the fractal dimension D of a trajectory changes within scales, 
and that the fractal dimension could be a valuable tool in multiscale 
analysis of wildlife movement patterns.
The adehabitat package, increasingly used as a free-open source alternative in 
radiiotracking and animal habitat selection studies, already has base 
functions to deal with trajectories in time and space, both as regular 
samples (e.g. data from GPS radio tags) and as irregular ones (as 
in 'classic' VHF radiotraking). The implementation of the algorithms devised 
by Nams could widen the range of analytical instruments that already make 
adehabitat an almost complete tool.
Moreover, the author of the sole existing software to do fractal analysis (V. 
O. Nams [0]) has expressed no objection towards such a porting (as reported 
by Paolo Cavallini in the AniMov mailing list [1]), suggesting that a 
complete rewrite could be a better solution.
In detail, the project objectives will be to port (or rewrite) into R 
the 'standard' methods offered by the FRACTAL program:
- fractal dimension estimation (D) using the basic divider method
- estimation of D the resampling divider method (Nams 2006: Acta Biotheoretica 
54:1-11)
- estimation of D using the VFractal estimator (Nams, 1996: Landscape Ecology 
11:289-297).
- production of other relevant movement ecology statistics useful in spetial 
scale perception by animals (Nams 2006: Animal Behaviour. 72: 1197-1203).
- optionally, in conjunction with the random movement simulators already 
present in adehabitat (in particular simm.levy and simm.crw), test for 
deviations from a CRW model (Nams and Bourgeois 2004: Can J. Zool, 
82:1738-1747) and detect if oriented movements occur (Nams 2006: Animal 
Behaviour. 72: 1197-1203)

Required skills
The candidate should be both familiar with R programming and wildlife 
radiotracking data analysis. A minimal familiarity with the adehabitat code 
could be desirable.

Mentor
Damiano G. Preatoni, PhD.
Research Associate
Unit? di Analisi e Gestione delle Risorse Ambientali
Dipartimento Ambiente-Salute-Sicurezza
Universit? degli Studi dell'Insubria
(see signature for details)

And, finally, the programming exercise [2]:
the candidate should demonstrate to be able to transform raw irregular VHF 
radiotracking data into an adehabitat ltraj object, which could be the base 
data structure to work with in the proposed package.


[0] http://nsac.ca/envsci/staff/vnams/Fractal.htm
[1] http://www.nabble.com/fractals-to21875728.html
[2] http://xkcd.com/74/
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 197 bytes
Desc: This is a digitally signed message part.
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090224/33013710/attachment.bin>

From maechler at stat.math.ethz.ch  Tue Feb 24 15:38:21 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 24 Feb 2009 15:38:21 +0100
Subject: [Rd] [R] Semantics of sequences in R
In-Reply-To: <49A3CC71.6050207@idi.ntnu.no>
References: <8b356f880902221242r47cdb138w9b1ac05cc5e5e317@mail.gmail.com>
	<49A1BFC7.9060503@stats.uwo.ca>
	<8b356f880902221350q4a976bfr19b0d5b01a989250@mail.gmail.com>
	<20090223113422.76cc1494@absentia> <49A255A5.1010506@idi.ntnu.no>
	<20090223175623.6106add2@berwin-nus1> <49A27AF4.307@idi.ntnu.no>
	<20090223192757.2ff7f629@berwin-nus1>
	<49A2961C.3020405@idi.ntnu.no> <20090224001247.5d2e3db9@berwin5>
	<49A2F89B.10900@idi.ntnu.no> <20090224160252.154a7d75@berwin-nus1>
	<49A3B257.2000103@idi.ntnu.no>
	<20090224175215.1336a820@berwin-nus1> <49A3C9A3.80506@erasmusmc.nl>
	<49A3CC71.6050207@idi.ntnu.no>
Message-ID: <18852.1629.899995.62048@stat.math.ethz.ch>

>>>>> "WK" == Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no>
>>>>>     on Tue, 24 Feb 2009 11:31:13 +0100 writes:

    WK> Dimitris Rizopoulos wrote:
    >> in my opinion the point of the whole discussion could be summarized by
    >> the question, what is a design flaw? This is totally subjective, and
    >> it happens almost everywhere in life. Take human languages as an
    >> example and in particular, English. I do not know the history of the
    >> English language but I can guess at some point some people decided
    >> that the past tense for "give" should be "gave" and not "gived"
    >> according to the standard rule, possibly because they thought it has
    >> better acoustic.
    >> 
    >> Is this a design flaw of English? Some might argue yes, maybe they
    >> would think "gived" does not have a that bad acoustic or they could
    >> have come up with another possibility than "gave". Does this confuse
    >> new users of English? Of course it does -- I had to spent many hours
    >> learning the past tense and past particle of the irregular verbs.
    >> Should it be changed? Then almost all existing code (i.e., English
    >> texts) should be rewritten, which I think demonstrates why some people
    >> are a bit reluctant in design changes.
    >> 
    >> To close I'd like to share with you a Greek saying (maybe also a
    >> saying in other parts of the world) that goes, for every rule there is
    >> an exception. The important thing, in my opinion, is that these
    >> exceptions are documented.

    WK> all this is true;  however, programming languages are not natural
    WK> languages, there are substantial differences, and conclusions valid for
    WK> natural languages are not necessarily valid for programming languages.

You are are right, Wacek.

However, Dimitris' comparison is still a valuable one, and I
think I know that you don't quite agree :

The S language has a long history and a relatively large user
base that goes back many years (say 20). As you know, the vast
majority are not professional programmers, not even
semi-professional ones. 
Rather  applied statisticians, scientists in many fields, also
mathematicians, most very happy about how productively they can
apply the S language by using R.
The books they have written do exist however (namely mostly collections
of "R script" files), and for almost all of them it would just
lead to considerable frustration if one of 
the "exceptions in the language" was replaced by "the rule" in a
way that makes their books contain "typos".

We very occasionally do this, i.e., back-incompatible
improvements to R, inspite, but only rarely, when we are
convinced that the costs (user frustration, need to re-write
books) seem to be outweighed by the benefits. 

I think this is one of the big differences between (S and) R
and other computer languages you've mentioned.
So, indeed, Dimitris' parabola was more to the point than you
may have appreciated.

Hmm, but now let's return to something a bit more
productive, please...

Martin


From Ted.Harding at manchester.ac.uk  Tue Feb 24 15:44:25 2009
From: Ted.Harding at manchester.ac.uk ( (Ted Harding))
Date: Tue, 24 Feb 2009 14:44:25 -0000 (GMT)
Subject: [Rd] [R] Semantics of sequences in R
In-Reply-To: <20090224211436.2e145e95@berwin5>
Message-ID: <XFMail.090224144425.Ted.Harding@manchester.ac.uk>

On 24-Feb-09 13:14:36, Berwin A Turlach wrote:
> G'day Dimitris,
> 
> On Tue, 24 Feb 2009 11:19:15 +0100
> Dimitris Rizopoulos <d.rizopoulos at erasmusmc.nl> wrote:
> 
>> in my opinion the point of the whole discussion could be summarized
>> by the question, what is a design flaw? This is totally subjective,
>> and it happens almost everywhere in life. [...]
> 
> Beautifully summarised and I completely agree.  Not surprisingly,
> others don't.
> 
> [...]
>> To close I'd like to share with you a Greek saying (maybe also a
>> saying in other parts of the world) that goes, for every rule there
>> is an exception. [...]
> 
> As far as I know, the same saying exist in English.  It definitely
> exist in German.  Actually, in German it is "every rule has its
> exception including this rule".

Or, as my mother used to say, "Moderation in all things!"
To which, as I grew up, I adjoined " ... including moderation."
Ted.

> In German there is one grammar rule
> that does not have an exception.  At least there used to be one; I am
> not really sure whether that rule survived the recent reform of the
> German grammar rules.
> 
> Cheers,
>       Berwin

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at manchester.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 24-Feb-09                                       Time: 14:44:21
------------------------------ XFMail ------------------------------


From ligges at statistik.tu-dortmund.de  Tue Feb 24 18:20:10 2009
From: ligges at statistik.tu-dortmund.de (ligges at statistik.tu-dortmund.de)
Date: Tue, 24 Feb 2009 18:20:10 +0100 (CET)
Subject: [Rd] wishlist boxplot (PR#13553)
Message-ID: <20090224172010.2E6C1282EF2D@mail.pubhealth.ku.dk>

[CCing Martin and Brian who had both done most svn commits of boxplot.R 
so far]


A very minor wishlist item that I should have already reported years ago:

All the time when I need presentation/publication quality boxplots, I 
add par(lend=1) in my code in order to suppress the ugly median line 
that does not stop at the end of the box given the rounded line endings.

Ugly example:

boxplot(1:10, lwd=30)



I'd like the following very minor change for boxplots:

D:\Rcompile\recent\R\src\library\graphics\R>diff -u boxplot.R boxplot-new.R
--- boxplot.R   2009-02-24 18:04:47.265625000 +0100
+++ boxplot-new.R       2009-02-24 18:10:02.000000000 +0100
@@ -148,7 +148,7 @@
          ## Median
          xysegments(xP(x, -wntch), stats[3L],
                 xP(x, +wntch), stats[3L],
-               lty = medlty[i], lwd = medlwd[i], col = medcol[i])
+               lty = medlty[i], lwd = medlwd[i], col = medcol[i], lend=1)
          xypoints(x, stats[3L],
               pch = medpch[i], cex = medcex[i], col= medcol[i], bg = 
medbg[i])
          ## Whiskers



Best wishes,
Uwe Ligges


From alexandre.courtiol at gmail.com  Tue Feb 24 14:55:23 2009
From: alexandre.courtiol at gmail.com (alexandre.courtiol at gmail.com)
Date: Tue, 24 Feb 2009 14:55:23 +0100 (CET)
Subject: [Rd] invalid comparison in numeric sequence (PR#13551)
Message-ID: <20090224135524.0113D284A70B@mail.pubhealth.ku.dk>

Full_Name: alex
Version: 2.8.1
OS: Ubuntu / MacOSX
Submission from: (NULL) (162.38.183.51)


> 0.6==0.6
[1] TRUE
> seq(0,1,0.1)==0.4
 [1] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE
> seq(0,1,0.1)==0.6
 [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> seq(0,1,0.1)==0.8
 [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE


What is wrong with 0.6 ??? (TRUE is missing)
I tried 3 differents computers (2 Ubuntu with R 2.8.1, and one Mac with R 2.8).


From solymos at stat.math.ethz.ch  Tue Feb 24 22:00:11 2009
From: solymos at stat.math.ethz.ch (solymos at stat.math.ethz.ch)
Date: Tue, 24 Feb 2009 22:00:11 +0100 (CET)
Subject: [Rd] Box.test reference correction (PR#13554)
Message-ID: <20090224210011.2CA5C282EF2D@mail.pubhealth.ku.dk>

Full_Name: Peter Solymos
Version: 2.8.1
OS: Windows
Submission from: (NULL) (129.128.141.92)


The help page of the Box.test function (stats) states that the Ljung-Box test
was published in:

Ljung, G. M. and Box, G. E. P. (1978), On a measure of lack of fit in time
series models. Biometrika 65, 553--564. 

The page numbers are incorrect. The correct citation should be as follows:

Ljung, G. M. and Box, G. E. P. (1978), On a measure of lack of fit in time
series models. Biometrika 65, 297--303. 

Yours,

Peter


From mark_difford at yahoo.co.uk  Tue Feb 24 17:31:23 2009
From: mark_difford at yahoo.co.uk (Mark Difford)
Date: Tue, 24 Feb 2009 08:31:23 -0800 (PST)
Subject: [Rd] [R] Semantics of sequences in R
In-Reply-To: <49A3C9A3.80506@erasmusmc.nl>
References: <8b356f880902221350q4a976bfr19b0d5b01a989250@mail.gmail.com>
	<20090223113422.76cc1494@absentia> <49A255A5.1010506@idi.ntnu.no>
	<20090223175623.6106add2@berwin-nus1> <49A27AF4.307@idi.ntnu.no>
	<20090223192757.2ff7f629@berwin-nus1>
	<49A2961C.3020405@idi.ntnu.no>
	<20090224001247.5d2e3db9@berwin5> <49A2F89B.10900@idi.ntnu.no>
	<20090224160252.154a7d75@berwin-nus1>
	<49A3B257.2000103@idi.ntnu.no>
	<20090224175215.1336a820@berwin-nus1> <49A3C9A3.80506@erasmusmc.nl>
Message-ID: <22183297.post@talk.nabble.com>


Dimitris Rizopoulos wrote:

>> in my opinion the point of the whole discussion could be summarized by
>> the question, what 
>> is a design flaw? This is totally subjective, and it happens almost
>> everywhere in life. 

This [what constitutes a design flaw, and the suggestion that all design
flaws are subjective] needs to be more carefully defined, and cannot, or
should not, be allowed to fly untested. People do die from time to time
because of design flaws. In recent times, two well-known car companies had
serious design flaws that led to several deaths.

Needless to say [perhaps], design flaws in software can have serious
consequences. So-called "design flaws" in a language are unlikely to. So
there are some fundamental, and important, differences between them.
Usually, respondents on this list are very careful not to confuse apples
with birds, or to try to compare them.

Regards, Mark.


Berwin A Turlach wrote:
> On Tue, 24 Feb 2009 09:39:51 +0100
> Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:
> 
>> Berwin A Turlach wrote:
> 
> [...]
>> why not read some fortunes?
> I am well aware of those fortunes and maybe you missed the one:
> 
>> fortune("Watson")
> 
> Getting flamed for asking dumb questions on a public mailing list is
> all part of growing up and being a man/woman.
>    -- Michael Watson (in a discussion on whether answers on R-help
>       should be more polite)
>       R-help (December 2004)
> 
> I am actually wondering where the corresponding fortunes from December
> 2005, December 2006, December 2007 and December 2009 are since they
> started of be produced on an annual basis.
> 
> [...]
>>>> on the other hand, i have seen quite a few responses that were
>>>> bashing a user for reporting a non-existent bug or submitting an
>>>> annoying patch.
>>>>     
>>> In didactic terms those are "negative motivations/reinforcements";
>>> opinion differ on how effective they are to reach certain learning
>>> outcomes.   
>>>   
>> ah, so what's the difference between the way i pinpoint design flaws
>> and the way r gurus respond to people, so that i am running with a
>> chip on my shoulder, and they are being 'negatively
>> motivating/reinforcing' in didactic terms?  [...]
> 
> Your goal is, presumably, that you want to have the design flaws
> fixed/discussed/&c.  The goal of the R gurus is to avoid having to
> waste their time on unproductive issues because people do not read
> documentation/behave contrary to how they are asked to behave/&c.
> 
> To reach your goal, the controversial approach is counter productive.
> To reach their goal, the controversial approach can be quite effective.

in my opinion the point of the whole discussion could be summarized by 
the question, what is a design flaw? This is totally subjective, and it 
happens almost everywhere in life. Take human languages as an example 
and in particular, English. I do not know the history of the English 
language but I can guess at some point some people decided that the past 
tense for "give" should be "gave" and not "gived" according to the 
standard rule, possibly because they thought it has better acoustic.

Is this a design flaw of English? Some might argue yes, maybe they would 
think "gived" does not have a that bad acoustic or they could have come 
up with another possibility than "gave". Does this confuse new users of 
English? Of course it does -- I had to spent many hours learning the 
past tense and past particle of the irregular verbs. Should it be 
changed? Then almost all existing code (i.e., English texts) should be 
rewritten, which I think demonstrates why some people are a bit 
reluctant in design changes.

To close I'd like to share with you a Greek saying (maybe also a saying 
in other parts of the world) that goes, for every rule there is an 
exception. The important thing, in my opinion, is that these exceptions 
are documented.

Best,
Dimitris


> [...]
>>>> it has been fixed immediately by martin. 
>>>>     
>>> Yes, and, again, you could not help yourself telling the developers
>>> what you think they should do, could you?  
>> was this really running with a chip:
> 
> Look up what "running with a chip on your shoulder means" and reflect
> on the occasions in which I suggested to you that you give the
> impression of doing so.   On this occasion nobody said that you were
> running around with a chip on your shoulder.
> 
>> "shouldn't the tests have captured it? i think you should have a check
>> for every feature following from the docs."
>>
>> to which marting responded "yes, we should"
> 
> But he also made it clear that it would be unlikely that he or any
> other R-core member would write those tests and that this would
> probably be left to you; with any contribution being welcome.  Consider
> yourself lucky that this exchange was with Martin, other members of R
> core might have communicated a similar message in quite another way.
> That exchange is very much confirming my understanding of the culture
> of the R community.
> 
>>> As I try to tell you, that
>>> is not the way it works.  R comes already with extensive tests that
>>> are run with "make check".  If you think some are missing, you
>>> could send a script and propose that they are included.  But
>>> telling others that they should write such tests is unlikely to
>>> make it happen. 
>> haven't done the thing.
> 
> Come on, read your own quote above:  "Shouldn't the tests have captured
> this?  I think you should have a check for every feature following from
> the docs",  If this is not "telling others that they should write such
> test", then what is?  
> 
> Cheers,
> 
> 	Berwin
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Dimitris Rizopoulos
Assistant Professor
Department of Biostatistics
Erasmus University Medical Center

Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
Tel: +31/(0)10/7043478
Fax: +31/(0)10/7043014

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
View this message in context: http://www.nabble.com/Re%3A--R--Semantics-of-sequences-in-R-tp22152063p22183297.html
Sent from the R devel mailing list archive at Nabble.com.


From mark_difford at yahoo.co.uk  Tue Feb 24 17:52:59 2009
From: mark_difford at yahoo.co.uk (Mark Difford)
Date: Tue, 24 Feb 2009 08:52:59 -0800 (PST)
Subject: [Rd] [R] Semantics of sequences in R
In-Reply-To: <22183297.post@talk.nabble.com>
References: <8b356f880902221350q4a976bfr19b0d5b01a989250@mail.gmail.com>
	<20090223113422.76cc1494@absentia> <49A255A5.1010506@idi.ntnu.no>
	<20090223175623.6106add2@berwin-nus1> <49A27AF4.307@idi.ntnu.no>
	<20090223192757.2ff7f629@berwin-nus1>
	<49A2961C.3020405@idi.ntnu.no>
	<20090224001247.5d2e3db9@berwin5> <49A2F89B.10900@idi.ntnu.no>
	<20090224160252.154a7d75@berwin-nus1>
	<49A3B257.2000103@idi.ntnu.no>
	<20090224175215.1336a820@berwin-nus1>
	<49A3C9A3.80506@erasmusmc.nl> <22183297.post@talk.nabble.com>
Message-ID: <22184447.post@talk.nabble.com>


...
My earlier email requires too much reading between the lines. This one puts
the finger more closely on the issues: There are historical inconsistencies
and there are design flaws. Naturally, there often is an overlap, but there
is also a clear area of excellence. These are largely different things and
they should not be so easily confused.

Regards, Mark.


Mark Difford wrote:
> 
> Dimitris Rizopoulos wrote:
> 
>>> in my opinion the point of the whole discussion could be summarized by
>>> the question, what 
>>> is a design flaw? This is totally subjective, and it happens almost
>>> everywhere in life. 
> 
> This [what constitutes a design flaw, and the suggestion that all design
> flaws are subjective] needs to be more carefully defined, and cannot, or
> should not, be allowed to fly untested. People do die from time to time
> because of design flaws. In recent times, two well-known car companies had
> serious design flaws that led to several deaths.
> 
> Needless to say [perhaps], design flaws in software can have serious
> consequences. So-called "design flaws" in a language are unlikely to. So
> there are some fundamental, and important, differences between them.
> Usually, respondents on this list are very careful not to confuse apples
> with birds, or to try to compare them.
> 
> Regards, Mark.
> 
> 
> Berwin A Turlach wrote:
>> On Tue, 24 Feb 2009 09:39:51 +0100
>> Wacek Kusnierczyk <Waclaw.Marcin.Kusnierczyk at idi.ntnu.no> wrote:
>> 
>>> Berwin A Turlach wrote:
>> 
>> [...]
>>> why not read some fortunes?
>> I am well aware of those fortunes and maybe you missed the one:
>> 
>>> fortune("Watson")
>> 
>> Getting flamed for asking dumb questions on a public mailing list is
>> all part of growing up and being a man/woman.
>>    -- Michael Watson (in a discussion on whether answers on R-help
>>       should be more polite)
>>       R-help (December 2004)
>> 
>> I am actually wondering where the corresponding fortunes from December
>> 2005, December 2006, December 2007 and December 2009 are since they
>> started of be produced on an annual basis.
>> 
>> [...]
>>>>> on the other hand, i have seen quite a few responses that were
>>>>> bashing a user for reporting a non-existent bug or submitting an
>>>>> annoying patch.
>>>>>     
>>>> In didactic terms those are "negative motivations/reinforcements";
>>>> opinion differ on how effective they are to reach certain learning
>>>> outcomes.   
>>>>   
>>> ah, so what's the difference between the way i pinpoint design flaws
>>> and the way r gurus respond to people, so that i am running with a
>>> chip on my shoulder, and they are being 'negatively
>>> motivating/reinforcing' in didactic terms?  [...]
>> 
>> Your goal is, presumably, that you want to have the design flaws
>> fixed/discussed/&c.  The goal of the R gurus is to avoid having to
>> waste their time on unproductive issues because people do not read
>> documentation/behave contrary to how they are asked to behave/&c.
>> 
>> To reach your goal, the controversial approach is counter productive.
>> To reach their goal, the controversial approach can be quite effective.
> 
> in my opinion the point of the whole discussion could be summarized by 
> the question, what is a design flaw? This is totally subjective, and it 
> happens almost everywhere in life. Take human languages as an example 
> and in particular, English. I do not know the history of the English 
> language but I can guess at some point some people decided that the past 
> tense for "give" should be "gave" and not "gived" according to the 
> standard rule, possibly because they thought it has better acoustic.
> 
> Is this a design flaw of English? Some might argue yes, maybe they would 
> think "gived" does not have a that bad acoustic or they could have come 
> up with another possibility than "gave". Does this confuse new users of 
> English? Of course it does -- I had to spent many hours learning the 
> past tense and past particle of the irregular verbs. Should it be 
> changed? Then almost all existing code (i.e., English texts) should be 
> rewritten, which I think demonstrates why some people are a bit 
> reluctant in design changes.
> 
> To close I'd like to share with you a Greek saying (maybe also a saying 
> in other parts of the world) that goes, for every rule there is an 
> exception. The important thing, in my opinion, is that these exceptions 
> are documented.
> 
> Best,
> Dimitris
> 
> 
>> [...]
>>>>> it has been fixed immediately by martin. 
>>>>>     
>>>> Yes, and, again, you could not help yourself telling the developers
>>>> what you think they should do, could you?  
>>> was this really running with a chip:
>> 
>> Look up what "running with a chip on your shoulder means" and reflect
>> on the occasions in which I suggested to you that you give the
>> impression of doing so.   On this occasion nobody said that you were
>> running around with a chip on your shoulder.
>> 
>>> "shouldn't the tests have captured it? i think you should have a check
>>> for every feature following from the docs."
>>>
>>> to which marting responded "yes, we should"
>> 
>> But he also made it clear that it would be unlikely that he or any
>> other R-core member would write those tests and that this would
>> probably be left to you; with any contribution being welcome.  Consider
>> yourself lucky that this exchange was with Martin, other members of R
>> core might have communicated a similar message in quite another way.
>> That exchange is very much confirming my understanding of the culture
>> of the R community.
>> 
>>>> As I try to tell you, that
>>>> is not the way it works.  R comes already with extensive tests that
>>>> are run with "make check".  If you think some are missing, you
>>>> could send a script and propose that they are included.  But
>>>> telling others that they should write such tests is unlikely to
>>>> make it happen. 
>>> haven't done the thing.
>> 
>> Come on, read your own quote above:  "Shouldn't the tests have captured
>> this?  I think you should have a check for every feature following from
>> the docs",  If this is not "telling others that they should write such
>> test", then what is?  
>> 
>> Cheers,
>> 
>> 	Berwin
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
> 
> -- 
> Dimitris Rizopoulos
> Assistant Professor
> Department of Biostatistics
> Erasmus University Medical Center
> 
> Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
> Tel: +31/(0)10/7043478
> Fax: +31/(0)10/7043014
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 



-- 
View this message in context: http://www.nabble.com/Re%3A--R--Semantics-of-sequences-in-R-tp22152063p22184447.html
Sent from the R devel mailing list archive at Nabble.com.


From ripley at stats.ox.ac.uk  Wed Feb 25 09:19:30 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 25 Feb 2009 08:19:30 +0000 (GMT)
Subject: [Rd] Box.test reference correction (PR#13554)
In-Reply-To: <20090224210011.2CA5C282EF2D@mail.pubhealth.ku.dk>
References: <20090224210011.2CA5C282EF2D@mail.pubhealth.ku.dk>
Message-ID: <alpine.LFD.2.00.0902250815470.20258@gannet.stats.ox.ac.uk>

Thank you, incorporated now.

(My memory says we've been here before, so perhaps the correction did 
not get picked up last time around.)

On Tue, 24 Feb 2009, solymos at stat.math.ethz.ch wrote:

> Full_Name: Peter Solymos
> Version: 2.8.1
> OS: Windows
> Submission from: (NULL) (129.128.141.92)
>
>
> The help page of the Box.test function (stats) states that the Ljung-Box test
> was published in:
>
> Ljung, G. M. and Box, G. E. P. (1978), On a measure of lack of fit in time
> series models. Biometrika 65, 553--564.
>
> The page numbers are incorrect. The correct citation should be as follows:
>
> Ljung, G. M. and Box, G. E. P. (1978), On a measure of lack of fit in time
> series models. Biometrika 65, 297--303.
>
> Yours,
>
> Peter
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Wed Feb 25 10:32:03 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Wed, 25 Feb 2009 10:32:03 +0100
Subject: [Rd] [R] learning R
In-Reply-To: <49A5046A.1010801@idi.ntnu.no>
References: <B011ECE5-387C-41D3-B710-C221D4BF9FB2@gmail.com>	<6E853AE7-8581-4EF1-B64A-A351AA96D79B@comcast.net>
	<49A5046A.1010801@idi.ntnu.no>
Message-ID: <49A51013.6020703@idi.ntnu.no>

a quick follow-up:

    e = new.env()
    e$a = 1
    names(e)
    # NULL
    names(e) = 'a'
    # error in names(e) = "foo" : names() applied to a non-vector

this is surprising.  names(e) 'works', there is no complaint, but when
names<- is used, the error is about the use of names, not names<-.

btw. ?names says:

"Description:

     Functions to get or set the names of an object.

Usage:

     names(x)
     names(x) <- value

Arguments:

       x: an R object.
"

and there is no clarification in the rest of the page that x cannot be
an environment, or that it has to be a vector.  furthermore:

    p = pairlist(a=1)
    names(p)
    # "a"
    names(p) = 'b'
    # fine
    is.vector(p)
    # FALSE

which is incoherent with the above error message, in that p is *not* a
vector.

vQ



Wacek Kusnierczyk wrote:
>
> the following:
>
>     names(a[2]) = 'foo'
>
> has (partially) a functional flavour, in that you assign to the names of
> a *copy* of a part of a, while
>
>     names(a)[2] = 'foo'
>
> does not have the flavour, in that you assign to the names of a;  it
> seems, according to the man page you quote, to be equivalent to:
>
>     a = 'names<-'(a, '[<-.'(names(a), 2, 'foo'))
>
> which proceeds as follows:
>
>     tmp1 = names(a)
>     # get a copy of the names of a, no effect on a
>
>     tmp2 = '[<-'(tmp1, 2, 'foo')
>     # get a copy of tmp1 with the second element replaced with 'foo'
>     # no effect on either a or tmp1
>
>     tmp3 = 'names<-'(a, tmp2)
>     # get a copy of a with its names replaced with tmp2
>     # no effect on either a, tmp1, or tmp2
>
>     a = tmp3
>     # backassign the result to a
>


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Wed Feb 25 10:39:06 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Wed, 25 Feb 2009 10:39:06 +0100
Subject: [Rd] [R] Semantics of sequences in R
In-Reply-To: <20090224175215.1336a820@berwin-nus1>
References: <8b356f880902221242r47cdb138w9b1ac05cc5e5e317@mail.gmail.com>	<49A1BFC7.9060503@stats.uwo.ca>	<8b356f880902221350q4a976bfr19b0d5b01a989250@mail.gmail.com>	<20090223113422.76cc1494@absentia>
	<49A255A5.1010506@idi.ntnu.no>	<20090223175623.6106add2@berwin-nus1>
	<49A27AF4.307@idi.ntnu.no>	<20090223192757.2ff7f629@berwin-nus1>	<49A2961C.3020405@idi.ntnu.no>
	<20090224001247.5d2e3db9@berwin5>	<49A2F89B.10900@idi.ntnu.no>
	<20090224160252.154a7d75@berwin-nus1>	<49A3B257.2000103@idi.ntnu.no>
	<20090224175215.1336a820@berwin-nus1>
Message-ID: <49A511BA.7090306@idi.ntnu.no>

Berwin A Turlach wrote:

<snip>

>>>> on the other hand, i have seen quite a few responses that were
>>>> bashing a user for reporting a non-existent bug or submitting an
>>>> annoying patch.
>>>>     
>>>>         
>>> In didactic terms those are "negative motivations/reinforcements";
>>> opinion differ on how effective they are to reach certain learning
>>> outcomes.   
>>>   
>>>       
>> ah, so what's the difference between the way i pinpoint design flaws
>> and the way r gurus respond to people, so that i am running with a
>> chip on my shoulder, and they are being 'negatively
>> motivating/reinforcing' in didactic terms?  [...]
>>     
>
> Your goal is, presumably, that you want to have the design flaws
> fixed/discussed/&c.  The goal of the R gurus is to avoid having to
> waste their time on unproductive issues because people do not read
> documentation/behave contrary to how they are asked to behave/&c.
>
> To reach your goal, the controversial approach is counter productive.
> To reach their goal, the controversial approach can be quite effective.
>   

berwin, i have an additional reflection which i'd like to share with
thee.  glad to see thy opinion.

there certainly is a difference between the r gurus who develop and
maintain an impressive software system, and the average user who has
limited understanding of both the internals and the interface.  but this
difference is in the amount of knowledge about this specific product; 
in interpersonal communication, the developers and the users are
essentially *peers*. 

offline, i have been told that some of the r gurus can be equally
arrogant (read: negatively motivating/reinforcing) to other developers
as they are to users;  but why should a user care, especially that there
is no hierarchical dependence between the developers and the users,
while there may be between the developers?  (which would still not
justify arrogance, but some bosses just cannot let it be.)

when you seem to sanction and support the rudeness with which some r
gurus tend to respond to certain posts, and which is clearly documented
in a number of fortunes, you have no point in objecting to how certain
users write to you.  irrespectively of your achievements with r, you are
due to all users the same respect you expect to be treated with.  to
paraphrase from duncan's, you cannot demand anything from the users, and
if you expect them to be kind, be kind too.  or live with it.

vQ


From markleeds at verizon.net  Wed Feb 25 10:39:27 2009
From: markleeds at verizon.net (markleeds at verizon.net)
Date: Wed, 25 Feb 2009 03:39:27 -0600 (CST)
Subject: [Rd] [R] learning R
Message-ID: <589927733.6635181235554767208.JavaMail.javamailuser@localhost>

  Hi Wacek: Somewhere I remember reading that environments have 
functionality like lists EXCEPT for the names part. IIRC, I think that I 
read this in the R Language Reference manual also.



On Wed, Feb 25, 2009 at  4:32 AM, Wacek Kusnierczyk wrote:

> a quick follow-up:
>
>     e = new.env()
>     e$a = 1
>     names(e)
>     # NULL
>     names(e) = 'a'
>     # error in names(e) = "foo" : names() applied to a non-vector
>
> this is surprising.  names(e) 'works', there is no complaint, but when
> names<- is used, the error is about the use of names, not names<-.
>
> btw. ?names says:
>
> "Description:
>
>      Functions to get or set the names of an object.
>
> Usage:
>
>      names(x)
>      names(x) <- value
>
> Arguments:
>
>        x: an R object.
> "
>
> and there is no clarification in the rest of the page that x cannot be
> an environment, or that it has to be a vector.  furthermore:
>
>     p = pairlist(a=1)
>     names(p)
>     # "a"
>     names(p) = 'b'
>     # fine
>     is.vector(p)
>     # FALSE
>
> which is incoherent with the above error message, in that p is *not* a
> vector.
>
> vQ
>
>
>
> Wacek Kusnierczyk wrote:
>>
>> the following:
>>
>>     names(a[2]) = 'foo'
>>
>> has (partially) a functional flavour, in that you assign to the names 
>> of
>> a *copy* of a part of a, while
>>
>>     names(a)[2] = 'foo'
>>
>> does not have the flavour, in that you assign to the names of a;  it
>> seems, according to the man page you quote, to be equivalent to:
>>
>>     a = 'names<-'(a, '[<-.'(names(a), 2, 'foo'))
>>
>> which proceeds as follows:
>>
>>     tmp1 = names(a)
>>     # get a copy of the names of a, no effect on a
>>
>>     tmp2 = '[<-'(tmp1, 2, 'foo')
>>     # get a copy of tmp1 with the second element replaced with 'foo'
>>     # no effect on either a or tmp1
>>
>>     tmp3 = 'names<-'(a, tmp2)
>>     # get a copy of a with its names replaced with tmp2
>>     # no effect on either a, tmp1, or tmp2
>>
>>     a = tmp3
>>     # backassign the result to a
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From P.Dalgaard at biostat.ku.dk  Wed Feb 25 11:30:49 2009
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 25 Feb 2009 11:30:49 +0100
Subject: [Rd] invalid comparison in numeric sequence (PR#13551)
In-Reply-To: <20090224135524.0113D284A70B@mail.pubhealth.ku.dk>
References: <20090224135524.0113D284A70B@mail.pubhealth.ku.dk>
Message-ID: <49A51DD9.2000704@biostat.ku.dk>

alexandre.courtiol at gmail.com wrote:
>
>> 0.6==0.6
> [1] TRUE
>> seq(0,1,0.1)==0.4
>  [1] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE
>> seq(0,1,0.1)==0.6
>  [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
>> seq(0,1,0.1)==0.8
>  [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE
> 
> 
> What is wrong with 0.6 ??? (TRUE is missing)
> I tried 3 differents computers (2 Ubuntu with R 2.8.1, and one Mac with R 2.8).

FAQ 7.31, not a bug. Expect about 10 people to tell you so.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From grgoswami at gmail.com  Wed Feb 25 12:59:38 2009
From: grgoswami at gmail.com (Gopi Goswami)
Date: Wed, 25 Feb 2009 06:59:38 -0500
Subject: [Rd] S4 helper functions: regular or generic?
Message-ID: <5811e0170902250359k3de97428h8f92f5882dcdab87@mail.gmail.com>

Hi there,


I want to write helper functions for a base class, which will be used
by its subclasses in the S4 world. This function ___will___ update
certain slots of its argument object. Please help me decide which one
of the following is a better approach with respect to coding style,
memory usage and speed:

o   Write a regular function.
o   Declare a generic and implement it just for the base class.


Thanks for sharing your insight and time,
gopi.
http://gopi-goswami.net/


From Heather.Turner at warwick.ac.uk  Wed Feb 25 13:48:27 2009
From: Heather.Turner at warwick.ac.uk (Heather Turner)
Date: Wed, 25 Feb 2009 12:48:27 +0000
Subject: [Rd] [R] length 1 offset in glm (& lm)
Message-ID: <49A53E1B.4090004@warwick.ac.uk>

This post about length 1 offsets on R help seems to have been ignored
(sorry deleted original email - is there a way to continue thread in
this case?)

https://stat.ethz.ch/pipermail/r-help/2009-February/189352.html

It does seem to be a bug, in that glm does not behave as documented. In
fact the same bug applies to lm as well.

I don't think the suggested fix works though - Y isn't available until
the model frame is evaluated. Moreover you would want to evaluate the
offset as part of the model frame, to take care of the search path,
subset and na.action.

One possibility would be to modify model.frame to recycle variables of
length one. This would be a potentially useful feature from my point of
view as offset(constant) could replace Const(constant) in gnm, which is
basically a work around for this problem in the case of specifying a
constant in a nonlinear term. However, this solution may have undesired
side-effects and I don't feel too strongly about it as there are various
 work-arounds. Perhaps the simplest solution would be to modify the docs
so that offsets of length one are disallowed - it is easy enough for the
user to create a vector of the right length as necessary.

Best regards,

Heather


From ripley at stats.ox.ac.uk  Wed Feb 25 14:10:06 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 25 Feb 2009 13:10:06 +0000 (GMT)
Subject: [Rd] [R] length 1 offset in glm (& lm)
In-Reply-To: <49A53E1B.4090004@warwick.ac.uk>
References: <49A53E1B.4090004@warwick.ac.uk>
Message-ID: <alpine.OSX.1.00.0902251252010.70608@tystie.local>

On Wed, 25 Feb 2009, Heather Turner wrote:

> This post about length 1 offsets on R help seems to have been ignored
> (sorry deleted original email - is there a way to continue thread in
> this case?)
>
> https://stat.ethz.ch/pipermail/r-help/2009-February/189352.html

So let's be clear: this was the 'offset' argument' and not the 
offset() function as you refer to below.

> It does seem to be a bug, in that glm does not behave as documented. In
> fact the same bug applies to lm as well.

Not ignored, just not yet resolved so nothing really useful to say as 
yet.  I suspect the documentation was once correct but the offset 
argument had some rather undesirable prperties at the time.  And there 
appears to be some legacy code to do the recycling.

So quite a bit of work is needed on the history to deal wth what is 
rather a small point: sorting out some problems with failing packages 
(rgdal and friends) has been a much higher priority (let alone the day 
jobs).

> I don't think the suggested fix works though - Y isn't available until
> the model frame is evaluated. Moreover you would want to evaluate the
> offset as part of the model frame, to take care of the search path,
> subset and na.action.

That used not to be the case for the offset _argument_, so probably 
where the docs came from.

> One possibility would be to modify model.frame to recycle variables of
> length one. This would be a potentially useful feature from my point of
> view as offset(constant) could replace Const(constant) in gnm, which is
> basically a work around for this problem in the case of specifying a
> constant in a nonlinear term. However, this solution may have undesired
> side-effects and I don't feel too strongly about it as there are various
> work-arounds. Perhaps the simplest solution would be to modify the docs
> so that offsets of length one are disallowed - it is easy enough for the
> user to create a vector of the right length as necessary.
>
> Best regards,
>
> Heather
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Wed Feb 25 14:19:15 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 25 Feb 2009 13:19:15 +0000 (GMT)
Subject: [Rd] [R] length 1 offset in glm (& lm)
In-Reply-To: <20090225141510.vzf0j0passoso4sw@imp.inserm.fr>
References: <49A53E1B.4090004@warwick.ac.uk>
	<alpine.OSX.1.00.0902251252010.70608@tystie.local>
	<20090225141510.vzf0j0passoso4sw@imp.inserm.fr>
Message-ID: <alpine.OSX.1.00.0902251316340.70608@tystie.local>

On Wed, 25 Feb 2009, Kenneth Knoblauch wrote:

> Hi
>
> Quoting Prof Brian Ripley <ripley at stats.ox.ac.uk>:
>
>> On Wed, 25 Feb 2009, Heather Turner wrote:
>> 
>>> This post about length 1 offsets on R help seems to have been ignored
>>> (sorry deleted original email - is there a way to continue thread in
>>> this case?)
>>> 
>>> https://stat.ethz.ch/pipermail/r-help/2009-February/189352.html
>> 
>> So let's be clear: this was the 'offset' argument' and not the offset()
>> function as you refer to below.
>
> It occurs for both

Yes (I knew). but no one (AFAICS) said the function allows length-1 
arguments: Heather is raising the possibility that it should as new 
functionality, I believe.

> c1 <- structure(list(Contr = c(0.028, 0.043, 0.064, 0.097, 0.146, 0.219
> ), Correct = c(34L, 57L, 94L, 152L, 160L, 160L), Incorrect = c(126L,
> 103L, 66L, 8L, 0L, 0L)), .Names = c("Contr", "Correct", "Incorrect"
> ), row.names = c(NA, 6L), class = "data.frame")
>
> glm(cbind(Correct, Incorrect) ~ Contr + offset(qlogis(0.25)) - 1, binomial,
> 	data = c1)
> Error in model.frame.default(formula = cbind(Correct, Incorrect) ~ Contr +  :
> variable lengths differ (found for 'offset(qlogis(0.25))')
> +
>
> Thanks for looking into this when time permits.
>
> Ken
>
> --- remaining deleted

> -- 
> Ken Knoblauch
> Inserm U846
> Stem-cell and Brain Research Institute
> Department of Integrative Neurosciences
> 18 avenue du Doyen L?pine
> 69500 Bron
> France
> tel: +33 (0)4 72 91 34 77
> fax: +33 (0)4 72 91 34 61
> portable: +33 (0)6 84 10 64 10
> http://www.sbri.fr/members/kenneth-knoblauch.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From P.Dalgaard at biostat.ku.dk  Wed Feb 25 14:41:34 2009
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Wed, 25 Feb 2009 14:41:34 +0100
Subject: [Rd] [R] length 1 offset in glm (& lm)
In-Reply-To: <alpine.OSX.1.00.0902251316340.70608@tystie.local>
References: <49A53E1B.4090004@warwick.ac.uk>	<alpine.OSX.1.00.0902251252010.70608@tystie.local>	<20090225141510.vzf0j0passoso4sw@imp.inserm.fr>
	<alpine.OSX.1.00.0902251316340.70608@tystie.local>
Message-ID: <49A54A8E.3000904@biostat.ku.dk>

Prof Brian Ripley wrote:
> On Wed, 25 Feb 2009, Kenneth Knoblauch wrote:
> 
>> Hi
>>
>> Quoting Prof Brian Ripley <ripley at stats.ox.ac.uk>:
>>
>>> On Wed, 25 Feb 2009, Heather Turner wrote:
>>>
>>>> This post about length 1 offsets on R help seems to have been ignored
>>>> (sorry deleted original email - is there a way to continue thread in
>>>> this case?)
>>>>
>>>> https://stat.ethz.ch/pipermail/r-help/2009-February/189352.html
>>>
>>> So let's be clear: this was the 'offset' argument' and not the offset()
>>> function as you refer to below.
>>
>> It occurs for both
> 
> Yes (I knew). but no one (AFAICS) said the function allows length-1
> arguments: Heather is raising the possibility that it should as new
> functionality, I believe.

Makes sense to have them consistent though, and we we do advertise that
recycling works for the argument. Looks like this could be fixed at the
level of model.frame.default, but the sticky bit is where to get the
repeat count in case the formula is something like "~-1". I don't quite
fathom the current rules:

> model.frame(~-1,offset=1)
  (offset)
1        1
> model.frame(~-1,offset=1,data=aq)
  (offset)
1        1
> model.frame(Ozone~-1,offset=1,data=aq)
Error in model.frame.default(Ozone ~ -1, offset = 1, data = aq) :
  variable lengths differ (found for '(offset)')
> model.frame(Ozone~-1,data=aq)
  Ozone
1    41
2    36
3    12
4    18
6    28
> model.frame(~-1,data=aq)
data frame with 0 columns and 6 rows

> foo <- 2:3
> model.frame(~foo-1,data=aq)
   foo
1    2
2    3
3 <NA>
4 <NA>
5 <NA>
6 <NA>
Warning message:
In format.data.frame(x, digits = digits, na.encode = FALSE) :
  corrupt data frame: columns will be truncated or padded with NAs
> foo <- 2
> model.frame(~foo-1,data=aq)
  foo
1   2




-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907


From Heather.Turner at warwick.ac.uk  Wed Feb 25 14:48:07 2009
From: Heather.Turner at warwick.ac.uk (Heather Turner)
Date: Wed, 25 Feb 2009 13:48:07 +0000
Subject: [Rd] [R] length 1 offset in glm (& lm)
In-Reply-To: <alpine.OSX.1.00.0902251316340.70608@tystie.local>
References: <49A53E1B.4090004@warwick.ac.uk>
	<alpine.OSX.1.00.0902251252010.70608@tystie.local>
	<20090225141510.vzf0j0passoso4sw@imp.inserm.fr>
	<alpine.OSX.1.00.0902251316340.70608@tystie.local>
Message-ID: <49A54C17.4070502@warwick.ac.uk>


Prof Brian Ripley wrote:
> On Wed, 25 Feb 2009, Kenneth Knoblauch wrote:
> 
>> Hi
>>
>> Quoting Prof Brian Ripley <ripley at stats.ox.ac.uk>:
>>
>>> On Wed, 25 Feb 2009, Heather Turner wrote:
>>>
>>>> This post about length 1 offsets on R help seems to have been ignored
>>>> (sorry deleted original email - is there a way to continue thread in
>>>> this case?)
>>>>
>>>> https://stat.ethz.ch/pipermail/r-help/2009-February/189352.html
>>>
>>> So let's be clear: this was the 'offset' argument' and not the offset()
>>> function as you refer to below.
>>
>> It occurs for both
> 
> Yes (I knew). but no one (AFAICS) said the function allows length-1
> arguments: Heather is raising the possibility that it should as new
> functionality, I believe.
> 
Not particularly, just observing that if the problem of handling a
length one offset passed to the offset argument is solved by model.frame
doing the necessary recycling, then offset() would also work with length
one arguments (I think) and this could be a useful feature. If the
problem is solved by dealing with the offset argument separately, then
you wouldn't get this side-benefit, so it's just something to bear in
mind when deciding on a fix.

>> c1 <- structure(list(Contr = c(0.028, 0.043, 0.064, 0.097, 0.146, 0.219
>> ), Correct = c(34L, 57L, 94L, 152L, 160L, 160L), Incorrect = c(126L,
>> 103L, 66L, 8L, 0L, 0L)), .Names = c("Contr", "Correct", "Incorrect"
>> ), row.names = c(NA, 6L), class = "data.frame")
>>
>> glm(cbind(Correct, Incorrect) ~ Contr + offset(qlogis(0.25)) - 1,
>> binomial,
>>     data = c1)
>> Error in model.frame.default(formula = cbind(Correct, Incorrect) ~
>> Contr +  :
>> variable lengths differ (found for 'offset(qlogis(0.25))')
>> +
>>
>> Thanks for looking into this when time permits.
>>
>> Ken
>>
>> --- remaining deleted
> 
>> -- 
>> Ken Knoblauch
>> Inserm U846
>> Stem-cell and Brain Research Institute
>> Department of Integrative Neurosciences
>> 18 avenue du Doyen L?pine
>> 69500 Bron
>> France
>> tel: +33 (0)4 72 91 34 77
>> fax: +33 (0)4 72 91 34 61
>> portable: +33 (0)6 84 10 64 10
>> http://www.sbri.fr/members/kenneth-knoblauch.html
>>
>


From jpnolan at american.edu  Wed Feb 25 14:54:32 2009
From: jpnolan at american.edu (John Nolan)
Date: Wed, 25 Feb 2009 08:54:32 -0500
Subject: [Rd] invalid comparison in numeric sequence (PR#13551)
In-Reply-To: <20090224135524.0113D284A70B@mail.pubhealth.ku.dk>
References: <20090224135524.0113D284A70B@mail.pubhealth.ku.dk>
Message-ID: <OF9C09A16C.3B7C2CC8-ON85257568.004C675A-85257568.004C676F@american.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090225/10b55d8e/attachment.pl>

From mtmorgan at fhcrc.org  Wed Feb 25 15:36:08 2009
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Wed, 25 Feb 2009 06:36:08 -0800
Subject: [Rd] S4 helper functions: regular or generic?
In-Reply-To: <5811e0170902250359k3de97428h8f92f5882dcdab87@mail.gmail.com>
	(Gopi Goswami's message of "Wed, 25 Feb 2009 06:59:38 -0500")
References: <5811e0170902250359k3de97428h8f92f5882dcdab87@mail.gmail.com>
Message-ID: <6phzlgar3c7.fsf@gopher4.fhcrc.org>

Hi Gopi --

Gopi Goswami <grgoswami at gmail.com> writes:

> Hi there,
>
>
> I want to write helper functions for a base class, which will be used
> by its subclasses in the S4 world. This function ___will___ update
> certain slots of its argument object. Please help me decide which one
> of the following is a better approach with respect to coding style,
> memory usage and speed:
>

My opinion:

> o   Write a regular function.

memory and speed

> o   Declare a generic and implement it just for the base class.

coding 'style', but style is subjective.

There are other aspects of S4, e.g., type checking, method dispatch,
programmatically defined and discoverable API, ... (positives),
cumbersome documentation (negative).

My usual pattern of development is to be seduced by the siren of
speed, only to regret boxing myself in.

I find that my S4 objects typically serve as containers for
coordinating other entities.  The important methods typically extract
R 'base' objects from the S4 class, manipulate them, and repackage the
result as S4. The time and speed issues are in the manipulation, not
in the extraction / repackaging. This is contrast to, say, an
implementation of a tree-like data structure with a collection of
'Node' objects, where tree operations would require access to each
object and would be horribly slow in S4 (and perhaps R when nodes were
represented as a list, say, at least compared to a C-level
representation, or an alternative representation that took advantage
of R's language characteristics).

Martin

>
> Thanks for sharing your insight and time,
> gopi.
> http://gopi-goswami.net/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Martin Morgan
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M2 B169
Phone: (206) 667-2793


From ripley at stats.ox.ac.uk  Wed Feb 25 15:40:17 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 25 Feb 2009 14:40:17 +0000 (GMT)
Subject: [Rd] [R] length 1 offset in glm (& lm)
In-Reply-To: <alpine.OSX.1.00.0902251252010.70608@tystie.local>
References: <49A53E1B.4090004@warwick.ac.uk>
	<alpine.OSX.1.00.0902251252010.70608@tystie.local>
Message-ID: <alpine.LFD.2.00.0902251434060.22430@gannet.stats.ox.ac.uk>

Some digging showed that this has not worked for a long time and the 
documentation is either legacy or wishful thinking.  So for R-patched 
the right approach is to fix the documentation and I will do so 
shortly.

As for model.frame() recycling: that sounds an appealing idea and I 
don't think I would want to confine it to case of length one: exact 
repeats recycling are allowed in a number of places.  And re Peter's 
example, this could be done only when it is unambiguous, or only where 
there is a response or ....  But that will have to wait for another 
day (or another hand).

On Wed, 25 Feb 2009, Prof Brian Ripley wrote:

> On Wed, 25 Feb 2009, Heather Turner wrote:
>
>> This post about length 1 offsets on R help seems to have been ignored
>> (sorry deleted original email - is there a way to continue thread in
>> this case?)
>> 
>> https://stat.ethz.ch/pipermail/r-help/2009-February/189352.html
>
> So let's be clear: this was the 'offset' argument' and not the offset() 
> function as you refer to below.
>
>> It does seem to be a bug, in that glm does not behave as documented. In
>> fact the same bug applies to lm as well.
>
> Not ignored, just not yet resolved so nothing really useful to say as yet.  I 
> suspect the documentation was once correct but the offset argument had some 
> rather undesirable prperties at the time.  And there appears to be some 
> legacy code to do the recycling.
>
> So quite a bit of work is needed on the history to deal wth what is rather a 
> small point: sorting out some problems with failing packages (rgdal and 
> friends) has been a much higher priority (let alone the day jobs).
>
>> I don't think the suggested fix works though - Y isn't available until
>> the model frame is evaluated. Moreover you would want to evaluate the
>> offset as part of the model frame, to take care of the search path,
>> subset and na.action.
>
> That used not to be the case for the offset _argument_, so probably where the 
> docs came from.
>
>> One possibility would be to modify model.frame to recycle variables of
>> length one. This would be a potentially useful feature from my point of
>> view as offset(constant) could replace Const(constant) in gnm, which is
>> basically a work around for this problem in the case of specifying a
>> constant in a nonlinear term. However, this solution may have undesired
>> side-effects and I don't feel too strongly about it as there are various
>> work-arounds. Perhaps the simplest solution would be to modify the docs
>> so that offsets of length one are disallowed - it is easy enough for the
>> user to create a vector of the right length as necessary.
>> 
>> Best regards,
>> 
>> Heather
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From savicky at cs.cas.cz  Wed Feb 25 18:08:25 2009
From: savicky at cs.cas.cz (Petr Savicky)
Date: Wed, 25 Feb 2009 18:08:25 +0100
Subject: [Rd] invalid comparison in numeric sequence (PR#13551)
In-Reply-To: <OF9C09A16C.3B7C2CC8-ON85257568.004C675A-85257568.004C676F@american.edu>
References: <20090224135524.0113D284A70B@mail.pubhealth.ku.dk>
	<OF9C09A16C.3B7C2CC8-ON85257568.004C675A-85257568.004C676F@american.edu>
Message-ID: <20090225170825.GA23092@cs.cas.cz>

> > seq(0,1,0.1)==0.4
>  [1] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE
> > seq(0,1,0.1)==0.6
>  [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> > seq(0,1,0.1)==0.8
>  [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE
> 
> What is wrong with 0.6 ??? (TRUE is missing)
> I tried 3 differents computers (2 Ubuntu with R 2.8.1, and one Mac with R 2.8).

If you know that all the numbers in a sequence should have a given decimal
precision, then you obtain a better result using round(,digits=...).
For example,

  x <- round(seq(0,1,0.1), digits=1)
  rbind(x == 0.4, x == 0.6, x ==0.8)

produces

        [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10] [,11]
  [1,] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE
  [2,] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE
  [3,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE

This does not mean, that x[7] is now equal to 0.6, however both x[7] and 0.6
are represented by the same 53-bit floating point number

  formatC(x[7], digits=20) # "0.5999999999999999778"
  formatC(0.6, digits=20)  # "0.5999999999999999778"

Petr.


From huber at ebi.ac.uk  Wed Feb 25 19:15:03 2009
From: huber at ebi.ac.uk (Wolfgang Huber)
Date: Wed, 25 Feb 2009 18:15:03 +0000
Subject: [Rd] Unexpected side effect of the ":::" operator on the value of
	isGeneric
Message-ID: <49A58AA7.8030500@ebi.ac.uk>

Hi,

when running the following on a fresh R,


  library("IRanges")
  annotation
  showMethods("annotation")
  Biobase:::annotation
  showMethods("annotation")


I get (see the "^^^^^" marked output at the bottom):


> library("IRanges")

Carico il pacchetto richiesto: 'IRanges'

	The following object(s) are masked from package:base :

	 cbind,
	 order,
	 pmax,
	 pmax.int,
	 pmin,
	 pmin.int,
	 rbind,
	 rep.int,
	 table

> annotation
standardGeneric for "annotation" defined from package "IRanges"

function (x, ...)
standardGeneric("annotation")
<environment: 0x1a302b0>
Methods may be defined for arguments: x
Use  showMethods("annotation")  for currently available ones.

> showMethods("annotation")
Function: annotation (package IRanges)
x="AnnotatedList"

> Biobase:::annotation
standardGeneric for "annotation" defined from package "Biobase"

function (object)
standardGeneric("annotation")
<environment: 0x205cee0>
Methods may be defined for arguments: object
Use  showMethods("annotation")  for currently available ones.

> showMethods("annotation")

Function "annotation":
 <not a generic function>
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


It seems that the value of isGeneric("annotation"), when it is called
within showMethods, is FALSE, while it is TRUE when called outside.



> sessionInfo()
R version 2.9.0 Under development (unstable) (2009-02-25 r48007)
x86_64-unknown-linux-gnu

locale:
LC_CTYPE=it_IT.UTF-8;LC_NUMERIC=C;LC_TIME=it_IT.UTF-8;LC_COLLATE=it_IT.UTF-8;LC_MONETARY=C;LC_MESSAGES=it_IT.UTF-8;LC_PAPER=it_IT.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=it_IT.UTF-8;LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] IRanges_1.1.40

loaded via a namespace (and not attached):
[1] Biobase_2.3.10



Best wishes
 Wolfgang

------------------------------------------------------------------
Wolfgang Huber  EBI/EMBL  Cambridge UK  http://www.ebi.ac.uk/huber


From ripley at stats.ox.ac.uk  Wed Feb 25 20:52:54 2009
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 25 Feb 2009 19:52:54 +0000 (GMT)
Subject: [Rd] [R] make check reg-tests-1.R error on solaris
In-Reply-To: <B20800AA-5D61-4DA6-B664-4EB898BAEF7C@cchmc.org>
References: <B20800AA-5D61-4DA6-B664-4EB898BAEF7C@cchmc.org>
Message-ID: <alpine.LFD.2.00.0902251940180.11350@gannet.stats.ox.ac.uk>

Do you have a ZFS file system?  That seems to be the common factor 
where people have actually told us. However, other Solaris 
9/10/OpenSolaris systems work, as you will see from the R-admin 
manual.  We cannot help with errors we cannot reproduce: rather we 
need someone with the problem to help us.

Such questions are far more apporpriate to the R-devel list: see the 
posting guide.  So I have diverted this there.

On Wed, 25 Feb 2009, Karen Noel wrote:

> R 2.5.1 compiled, passed the make check and has been successfully running for 
> a couple years on a Sun Fire V490 running Solaris 9. I need a newer version 
> of R, but can't get a newer version of R to pass the make check. I've tried 
> 2.8.1, 2.7.2, 2.6.2 and 2.6.0. (2.5.1 still passes on this server) At this 
> point I thought I'd try to compile it on another Sun server (Solaris 10), but 
> it had the same problem. Configuring with no options didn't help. I commented 
> out the failed test from the Makefile to see if it would pass the rest of the 
> tests. It passes all the rest of the tests. Here is the failure error from 
> make check.
>
> make[2]: Entering directory `/usr/local/src/R-2.8.1/tests'
> running regression tests
> make[3]: Entering directory `/usr/local/src/R-2.8.1/tests'
> running code in 'reg-tests-1.R' ...make[3]: *** [reg-tests-1.Rout] Error 1
> make[3]: Leaving directory `/usr/local/src/R-2.8.1/tests'
> make[2]: *** [test-Reg] Error 2
> make[2]: Leaving directory `/usr/local/src/R-2.8.1/tests'
> make[1]: *** [test-all-basics] Error 1
> make[1]: Leaving directory `/usr/local/src/R-2.8.1/tests'
> make: *** [check] Error 2
> bash-2.05#
>
> Here is output from reg-tests-1.Rout.fail.
>
> [1] "41c6167e"     "dir1"         "dir2"         "dirs" 
> "file275c23f2"
> [6] "file33f963f2" "moredirs"
>> file.create(file.path(dd, "somefile"))
> [1] TRUE TRUE TRUE TRUE
>> dir(".", recursive=TRUE)
> [1] "41c6167e"          "dir1/somefile"     "dir2/somefile"
> [4] "dirs/somefile"     "file275c23f2"      "file33f963f2"
> [7] "moredirs/somefile"
>> stopifnot(unlink("dir?") == 1) # not an error
> Error: unlink("dir?") == 1 is not TRUE
> Execution halted
> rm: Cannot remove any directory in the path of the current working directory
> /tmp/RtmprBjF6W
>
> Looking through the archives I did find a couple other people with this 
> error, both running Solaris 10. PR#10501 and PR#11738 have quite a lot of 
> information about this error, but I don't see any resolution for them.
>
> This looks like it could possibly be enough of a problem that I haven't put 
> 2.8.1 in production. Can you help me with a resolution or let me know if it 
> is safe to ignore? I'd appreciate it.
>
> Thank you!
> Karen
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Thu Feb 26 09:49:46 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Thu, 26 Feb 2009 09:49:46 +0100
Subject: [Rd] [R] Problems with ARIMA models?
In-Reply-To: <2d91b0b20902251249y6444cbbaja0f53df25b06db3d@mail.gmail.com>
References: <2d91b0b20902251249y6444cbbaja0f53df25b06db3d@mail.gmail.com>
Message-ID: <49A657AA.8020400@idi.ntnu.no>

that's interesting, marie.

on his webpage [1], david s. stoffer provides concrete arguments for why
the r arima function in the stats package should be considered to
produce misleading, if not just wrong results. 

david (cc:ed for reference) reported the issue in october 2005, bug
report #8231 [2], and then again in april 2006, same bug report id [3]. 
a search through the maling list's archives reveals that there are only
two messages matching the pattern '8231', namely the two mentioned
above.  that is, there has been *no public response* posted.

after a few lessons, i have learned that you can't demand anything from
r developers (which isn't quite accurate:  you can demand, but they're
likely to ignore you), so it's hard to demand that this issue be
appropriately addressed.  however, one can, and should, expect that such
bug reports, correct or not, are addressed in public, leaving no doubt
as to the accuracy of the design and implementation of any functionality
in r.

responding to bug reports is an important part of the open source
culture (in this particular case, it's not really about sources) which r
folks do not hesitate to refer to.  it is surprising that david's
concrete and polite (please prove me wrong) post hasn't received the
treatment it deserved.  it hasn't any! 

a brief look at some of the respective sources:

    svn log http://svn.r-project.org/R/trunk/src/library/stats/R/arima.R
    svn log http://svn.r-project.org/R/trunk/src/library/stats/src/arima.c

hints that they've been edited mostly by one single developer.  if the
responsibility, as it seems, is not diffused among many, why wouldn't
the author provide a clear and convincing answer to david's comments? 
as far as i can see, david has sufficient expertise in both the
particular field and r in general, not to be treated as a naive user
asking dumb questions (see fortune('dumb'), for example).

is ignoring concrete critique part of the official strategy?  can't see
this documented on r's website.

vQ


[1] http://www.stat.pitt.edu/stoffer/tsa2/Rissues.htm
[2] http://tolstoy.newcastle.edu.au/R/devel/05/10/2885.html
[3] http://tolstoy.newcastle.edu.au/R/devel/06/04/4756.html



Marie Sivertsen wrote:
> Dear R,
>
> I have find a website where they report problem with ARIMA models in R.  I
> run the examples there and they give result as shown on the website.  Does
> this mean that nothing has corrected in R?  Maybe you not have seen the
> page, but the author said he contacted you.
>
> Here is the URL: http://www.stat.pitt.edu/stoffer/tsa2/Rissues.htm
>
> I like to know your opinion.
>
> Mvh.
> Marie
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ken.knoblauch at inserm.fr  Thu Feb 26 15:15:08 2009
From: ken.knoblauch at inserm.fr (Kenneth Knoblauch)
Date: Thu, 26 Feb 2009 15:15:08 +0100
Subject: [Rd] using predict method with an offset
Message-ID: <20090226151508.3x9abc7i0wgssk4k@imp.inserm.fr>

Hi,

I have run into another problem using offsets, this time with
the predict function, where there seems to be a contradiction
again between the behavior and the help page.

On the man page for predict.lm, it says

Offsets specified by offset in the fit by lm will not be included in
predictions, whereas those specified by an offset term in the formula
will be.

While it indicates nothings about offsets under ?predict.glm, predict.glm
calls predict.lm. when there is a newdata argument.

In the example below, the behavior is the opposite of the help
page, if I am understanding it correctly, and a warning is thrown
when it does seem to work as desired.

c1 <- structure(list(Contr = c(0.028, 0.043, 0.064, 0.097, 0.146, 0.219
), Correct = c(34L, 57L, 94L, 152L, 160L, 160L), Incorrect = c(126L,
103L, 66L, 8L, 0L, 0L)), .Names = c("Contr", "Correct", "Incorrect"
), row.names = c("13", "15", "17", "19", "21", "23"), class = "data.frame")

q25 <- rep( qlogis( 0.25 ), nrow(c1) )

# offset defined in arguments
c1.glm <- glm( cbind(Correct, Incorrect) ~ Contr - 1, binomial,
	c1, offset = q25 )
# offset defined in formula
c1f.glm <- glm( cbind(Correct, Incorrect) ~ Contr + offset(q25) -1,
	binomial, c1 )
cc <- seq( 0, 1, len = 10 )
nd <- data.frame( Contr = cc )

When predict used with model for which offset was defined in
the arguments, offset is taken into account and a warning
is emitted.

predict(c1.glm, newdata = nd, type = "response")

         1         2         3         4         5         6         7
0.2500000 0.8859251 0.9945037 0.9997628 0.9999898 0.9999996 1.0000000
         8         9        10
1.0000000 1.0000000 1.0000000
Warning message:
In predictor + offset :
   longer object length is not a multiple of shorter object length

When predict used with model for which offset was defined in
the formula, an error occurs

predict( c1f.glm, newdata = nd )

Error in model.frame.default(Terms, newdata, na.action = na.action,  
xlev = object$xlevels) :
   variable lengths differ (found for 'offset(q25)')

even if a column for offset is included in newdata,

ndf <- cbind( nd, "offset(q25)" = rep( qlogis(0.25), length(cc) ) )
predict( c1f.glm, newdata = ndf )

Error in model.frame.default(Terms, newdata, na.action = na.action,  
xlev = object$xlevels) :
   variable lengths differ (found for 'offset(q25)')

unless there is a special way to specify the offset to predict
that I haven't been able to figure out.

traceback indicates the problem, again, with model.frame.default

Thank you for any clarification.

best,

Ken


-- 
Ken Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html


From clyde at stat.duke.edu  Wed Feb 25 16:27:16 2009
From: clyde at stat.duke.edu (MerliseClyde)
Date: Wed, 25 Feb 2009 07:27:16 -0800 (PST)
Subject: [Rd]  Fontconfig warning with X11() on MAC OS X 10.4
Message-ID: <22205067.post@talk.nabble.com>


I posted previously about problems with X11() on my MAC using R 2.8.1 . 
After installing the securilty update for Tiger this morning, X11() now
works from an xterm :-)

However, I receive the following warnings with any plotting command using
the default X11 settings.
Fontconfig warning: no <cachedir> elements found. Check configuration.
Fontconfig warning: adding
<cachedir>/Library/Frameworks/R.framework/Resources/fontconfig/cache</cachedir>
Fontconfig warning: adding <cachedir>~/.fontconfig</cachedir>

Everything works fine with the Xlib option:

> X11(type="Xlib")
> plot(1:10)  # no problems!
> X11(type="cairo")
> plot(1:10)
Fontconfig warning: no <cachedir> elements found. Check configuration.
Fontconfig warning: adding
<cachedir>/Library/Frameworks/R.framework/Resources/fontconfig/cache</cachedir>
Fontconfig warning: adding <cachedir>~/.fontconfig</cachedir>

subsequent commands with X11/cairo plot with no errors.

If I quit R, and start a new session I continue to receive the Fontconfig
warning.

Any suggestions on what is wrong with my font configuration?
(mainly annoying :-)

Thanks!
Merlise
Version: 
 platform = i386-apple-darwin8.11.1 
 arch = i386 
 os = darwin8.11.1 
 system = i386, darwin8.11.1 
 status = 
 major = 2 
 minor = 8.1 
 year = 2008 
 month = 12 
 day = 22 
 svn rev = 47281 
 language = R 
 version.string = R version 2.8.1 (2008-12-22) 


-- 
View this message in context: http://www.nabble.com/Fontconfig-warning-with-X11%28%29-on-MAC-OS-X-10.4-tp22205067p22205067.html
Sent from the R devel mailing list archive at Nabble.com.


From Jerry.Lewis at biogenidec.com  Thu Feb 26 16:15:11 2009
From: Jerry.Lewis at biogenidec.com (Jerry.Lewis at biogenidec.com)
Date: Thu, 26 Feb 2009 16:15:11 +0100 (CET)
Subject: [Rd] besselI inaccurate for negative integer order (PR#13556)
Message-ID: <20090226151511.C1D272834311@mail.pubhealth.ku.dk>

Full_Name: Jerry W. Lewis
Version: 2.8.1
OS: Windows XP Professional
Submission from: (NULL) (198.180.131.16)


It should be the case that
  besselI(x,-nu) == besselI(x,nu) == besselI(x,abs(nu))
for integer nu, yet R currently can return ridiculous values when nu is a
negative integer.

For instance, besselI(9.6,-44) returns -234626490 instead of the correct value
of 5.9041042646307223e-25, while besselI(9.6,44) gives essentially machine
accuracy.

This is more than an idle mathematical curiosity, since one consequence is that
dskellam in the VGAM package can return values <0 or >1.


From Heather.Turner at warwick.ac.uk  Fri Feb 27 10:57:38 2009
From: Heather.Turner at warwick.ac.uk (Heather Turner)
Date: Fri, 27 Feb 2009 09:57:38 +0000
Subject: [Rd] using predict method with an offset
In-Reply-To: <20090226151508.3x9abc7i0wgssk4k@imp.inserm.fr>
References: <20090226151508.3x9abc7i0wgssk4k@imp.inserm.fr>
Message-ID: <49A7B912.2090907@warwick.ac.uk>

Hi Ken,

First of all, whether you specify the offset by the argument or in the
formula, your code requires that q25 is the same length as the variable
Contr. You can set this up by defining your new data as follows:

nd <- data.frame( Contr = cc , q25 = qlogis(0.25))

This sorts out the problem of the warnings/errors. Secondly your two
calls to predict give different results because you have not specified
the same type - the first is predicting on the response scale and the
second is predicting on the link scale. If you use

predict(c1.glm, newdata = nd, type = "response")
predict(c1f.glm, newdata = nd, type = "response")

you get the same result. This does seem to go against the documentation
however, so it would seem that the paragraph you quoted should be taken
out of the help file for predict.lm.

Best wishes,

Heather

Kenneth Knoblauch wrote:
> Hi,
> 
> I have run into another problem using offsets, this time with
> the predict function, where there seems to be a contradiction
> again between the behavior and the help page.
> 
> On the man page for predict.lm, it says
> 
> Offsets specified by offset in the fit by lm will not be included in
> predictions, whereas those specified by an offset term in the formula
> will be.
> 
> While it indicates nothings about offsets under ?predict.glm, predict.glm
> calls predict.lm. when there is a newdata argument.
> 
> In the example below, the behavior is the opposite of the help
> page, if I am understanding it correctly, and a warning is thrown
> when it does seem to work as desired.
> 
> c1 <- structure(list(Contr = c(0.028, 0.043, 0.064, 0.097, 0.146, 0.219
> ), Correct = c(34L, 57L, 94L, 152L, 160L, 160L), Incorrect = c(126L,
> 103L, 66L, 8L, 0L, 0L)), .Names = c("Contr", "Correct", "Incorrect"
> ), row.names = c("13", "15", "17", "19", "21", "23"), class = "data.frame")
> 
> q25 <- rep( qlogis( 0.25 ), nrow(c1) )
> 
> # offset defined in arguments
> c1.glm <- glm( cbind(Correct, Incorrect) ~ Contr - 1, binomial,
>     c1, offset = q25 )
> # offset defined in formula
> c1f.glm <- glm( cbind(Correct, Incorrect) ~ Contr + offset(q25) -1,
>     binomial, c1 )
> cc <- seq( 0, 1, len = 10 )
> nd <- data.frame( Contr = cc )
> 
> When predict used with model for which offset was defined in
> the arguments, offset is taken into account and a warning
> is emitted.
> 
> predict(c1.glm, newdata = nd, type = "response")
> 
>         1         2         3         4         5         6         7
> 0.2500000 0.8859251 0.9945037 0.9997628 0.9999898 0.9999996 1.0000000
>         8         9        10
> 1.0000000 1.0000000 1.0000000
> Warning message:
> In predictor + offset :
>   longer object length is not a multiple of shorter object length
> 
> When predict used with model for which offset was defined in
> the formula, an error occurs
> 
> predict( c1f.glm, newdata = nd )
> 
> Error in model.frame.default(Terms, newdata, na.action = na.action, xlev
> = object$xlevels) :
>   variable lengths differ (found for 'offset(q25)')
> 
> even if a column for offset is included in newdata,
> 
> ndf <- cbind( nd, "offset(q25)" = rep( qlogis(0.25), length(cc) ) )
> predict( c1f.glm, newdata = ndf )
> 
> Error in model.frame.default(Terms, newdata, na.action = na.action, xlev
> = object$xlevels) :
>   variable lengths differ (found for 'offset(q25)')
> 
> unless there is a special way to specify the offset to predict
> that I haven't been able to figure out.
> 
> traceback indicates the problem, again, with model.frame.default
> 
> Thank you for any clarification.
> 
> best,
> 
> Ken
> 
>


From Torsten.Hothorn at stat.uni-muenchen.de  Fri Feb 27 11:45:05 2009
From: Torsten.Hothorn at stat.uni-muenchen.de (Torsten Hothorn)
Date: Fri, 27 Feb 2009 11:45:05 +0100 (CET)
Subject: [Rd] [SoC09-Idea] Party On!
In-Reply-To: <499ECD73.9060008@stat.uni-muenchen.de>
References: <499ECD73.9060008@stat.uni-muenchen.de>
Message-ID: <alpine.DEB.2.00.0902271142500.16984@artemis.stat.uni-muenchen.de>


Hi Manuel,

find our SoC proposal below.

Best wishes,

Torsten & Achim

_______________________________________________________________________


Party On! New Recursive Partytioning Tools.

Mentor: Torsten Hothorn & Achim Zeileis

Short Description:
The aim of the project is the implementation of recursive partitioning
methods ("trees") which aren't available in R at the moment. The student
can choose a method to begin with from a larger set of interesting algorithms.

Detailed Description:
Recursive partitioning methods, or simply "trees", are simple yet powerful
methods for capturing regression relationships. Since the publication of the
automated interaction detection (AID) algorithm in 1964, many extensions,
modifications, and new approaches have been suggested in both the statistics
and machine learning communities. Most of the standard algorithms are
available to the R user, e.g., through packages rpart, party, mvpart, and
RWeka.

However, no common infrastructure is available for representing trees
fitted by different packages. Consequently, the capabilities for extraction
of information - such as predictions, printed summaries, or
visualizations - vary between packages and come with somewhat different user
interfaces. Furthermore, extensions or modifications often require considerable
programming effort, e.g., if the median instead of the mean of a numerical
response should be predicted in each leaf of an rpart tree.
Similarly, implementations of new tree algorithms might also require new
infrastructure if they have features not available in the above-mentioned
packages, e.g., multi-way splits or more complex models in the leafs.

To overcome these difficulties, the partykit package has been started on
R-Forge. It is still being developed but already contains a stable class
"party" for representing trees. It is a very flexible class with unified
predict(), print(), and plot() methods, and can, in principle, capture
all trees mentioned. But going beyond that, it can also accommodate
multi-way or functional splits, as well as complex models in (leaf) nodes.

We aim at making more recursive partitioning methods available
to the R community. A first step in this direction is the CHAID package 
(also hosted on R-Forge). Much more prominent procedures come to mind,
for example exhaustive CHAID, C4.5, GUIDE, CRUISE, LOTUS, and many others.
Students can choose among these and other recursive partitioning methods
they want to implement based on the partykit infrastructure.

Required Skills:
Good R programming skills, depending on the complexity of the chosen
algorithm C programming might be required as well. A basic understanding
of statistics and machine learning would be helpful.

Programming Exercise:
Consider the "GlaucomaM" dataset from package ipred. Write a small R function 
that searches for the best binary split in variable "vari" when "Class" is
the response variable. Implement any method you like but without using any 
add-on package.


From h.wickham at gmail.com  Fri Feb 27 12:09:00 2009
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 27 Feb 2009 05:09:00 -0600
Subject: [Rd] Persistent data structures for R
Message-ID: <f8e6ff050902270309pfa05583ue28e10887731fbf6@mail.gmail.com>

Hi all,

Has anyone thought about developing persistent
(http://en.wikipedia.org/wiki/Persistent_data_structure) "functional"
data structures for R?  A persistent data frame, for example, would
seem like a possible way of drastically reducing memory consumption
for many common problems.  Would developing a family of a few such
algorithms make for a good summer of code project?

Regards,

Hadley

-- 
http://had.co.nz/


From Waclaw.Marcin.Kusnierczyk at idi.ntnu.no  Fri Feb 27 12:32:21 2009
From: Waclaw.Marcin.Kusnierczyk at idi.ntnu.no (Wacek Kusnierczyk)
Date: Fri, 27 Feb 2009 12:32:21 +0100
Subject: [Rd] Persistent data structures for R
In-Reply-To: <f8e6ff050902270309pfa05583ue28e10887731fbf6@mail.gmail.com>
References: <f8e6ff050902270309pfa05583ue28e10887731fbf6@mail.gmail.com>
Message-ID: <49A7CF45.1080008@idi.ntnu.no>

hadley wickham wrote:
> Hi all,
>
> Has anyone thought about developing persistent
> (http://en.wikipedia.org/wiki/Persistent_data_structure) "functional"
> data structures for R?  A persistent data frame, for example, would
> seem like a possible way of drastically reducing memory consumption
> for many common problems.  Would developing a family of a few such
> algorithms make for a good summer of code project?
>   

the book 'purely functional data structures' by chris okasaki [1] could
be a good resource.  it describes a number of algorithms adapted to
computing with persistent data structures, and also discusses lazy
evaluation in this context.

vQ

[1]
http://www.amazon.com/Purely-Functional-Structures-Chris-Okasaki/dp/0521663504


From fjbuch at gmail.com  Fri Feb 27 15:02:51 2009
From: fjbuch at gmail.com (Farrel Buchinsky)
Date: Fri, 27 Feb 2009 09:02:51 -0500
Subject: [Rd] R-Google interface: Google summer of code
Message-ID: <bd93cdad0902270602mc4dede7w58635467e711c56d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090227/f04b6020/attachment.pl>

From adrian_d at eskimo.com  Fri Feb 27 15:26:00 2009
From: adrian_d at eskimo.com (Adrian Dragulescu)
Date: Fri, 27 Feb 2009 06:26:00 -0800 (PST)
Subject: [Rd] R-Google interface: Google summer of code
In-Reply-To: <bd93cdad0902270602mc4dede7w58635467e711c56d@mail.gmail.com>
References: <bd93cdad0902270602mc4dede7w58635467e711c56d@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0902270620010.2887@shell.eskimo.com>


There is an R package that does what you want.

http://www.omegahat.org/RGoogleDocs/ by Duncan Temple Lang.

It is still in beta but can be used.  I've run into some issues when 
google changes the location of your spreadsheet and redirects you to 
another site.  I could not make it follow the new link.  I'm sure little 
kinks like this can all be worked out if one only has time.

If there is a student out there that wants to work on this, it would be a 
great project.

Adrian Dragulescu



On Fri, 27 Feb 2009, Farrel Buchinsky wrote:

> I use R for data management and ongoing data analysis for amongst other
> things, a multi-center medical research project. I have found Google
> spreadsheets to be a fantastic way for all collaborators to be on the same
> page. Furthermore, Google Forms allows one to capture data from respondents
> and effortlessly write it to a google spreadsheet.
> Currently, one has to manually download the spreadsheet as a csv file and
> then read that into R. Since data changes frequently and is almost never
> final it would be far preferable for R to read a google spreadsheet
> directly. RODBC package does something similar for Microsoft Access and
> Microsoft Excel.
>
> I am a surgeon-scientist whose programing experience is extremely limited.
> Is there a willing mentor who would want to take such a project and propose
> it for the Google summer of code project?
>
> The mentor could chose his or her scope. For instance at it's most basic the
> project's goal could be to simply read a spreadsheet from google spreadsheet
> into a R dataframe. The scope could widen to allow R to also write to Google
> spreadsheet. If one wanted something even more challenging then one could
> create code that allows one to post R script to a R server allowing the
> server to read Google Spreadsheets, processes the data and present the
> output to a web client.
>
>
> Farrel Buchinsky
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From bernd.schoeller at comerge.net  Fri Feb 27 17:08:15 2009
From: bernd.schoeller at comerge.net (Bernd Schoeller)
Date: Fri, 27 Feb 2009 17:08:15 +0100
Subject: [Rd] Accessing browser() in an embedded R
Message-ID: <49A80FEF.9070800@comerge.net>

Dear List,

I have embedded an R interpreter into an application. This works very 
well until now.

As a next step, I would like to make the 'browser()' debugging 
infrastructure available. Currently, I am executing R code running 
'try_eval'. My main application blocks until the try_eval terminates.

What happens to my try_eval when it runs into browser()? How can I read 
and write to the browser?

Any hints are welcome. Thanks,
   Bernd


From ken.knoblauch at inserm.fr  Wed Feb 25 14:10:43 2009
From: ken.knoblauch at inserm.fr (Kenneth Knoblauch)
Date: Wed, 25 Feb 2009 14:10:43 +0100
Subject: [Rd] [R] length 1 offset in glm (& lm)
In-Reply-To: <49A53E1B.4090004@warwick.ac.uk>
References: <49A53E1B.4090004@warwick.ac.uk>
Message-ID: <20090225141043.nbuf8d5pts0s0wgk@imp.inserm.fr>

Hi,

Thanks for responding/noticing.  I was going to wait a few more days
while contemplating how to get more notice for the post.
It occurred to me later that it should have gone to R-devel as you
have forwarded it.  I'll include my example (with a fix) for refresher

c1 <- structure(list(Contr = c(0.028, 0.043, 0.064, 0.097, 0.146, 0.219
  ), Correct = c(34L, 57L, 94L, 152L, 160L, 160L), Incorrect = c(126L,
  103L, 66L, 8L, 0L, 0L)), .Names = c("Contr", "Correct", "Incorrect"
  ), row.names = c(NA, 6L), class = "data.frame")

glm(cbind(Correct, Incorrect) ~ Contr - 1, binomial,
         data = c1, offset = qlogis(0.25))

Error in model.frame.default(formula = cbind(Correct, Incorrect) ~ Contr -  :
    variable lengths differ (found for '(offset)')

lm(cbind(Correct, Incorrect) ~ Contr - 1, binomial,
         data = c1, offset = rep(qlogis(0.25), nrow(c1))) ## which works

The line which throws the error is:

mf <- eval(mf, parent.frame())

I must have done something additional of which I did not keep a record,
but if I change the nrow(Y) in the code fragment to nrow(data),
that works, as in

if (!is.null(offset)) {
          if (length(offset) == 1)
              offset <- rep(offset, NROW(data))
          else if (length(offset) != NROW(data))
              stop(gettextf("number of offsets is %d should equal %d
(number of observations)",
                  length(offset), NROW(data)), domain = NA)
      }
     mf$offset <- offset
     mf <- eval(mf, parent.frame())

Thank you.

Ken



Quoting Heather Turner <Heather.Turner at warwick.ac.uk>:

> This post about length 1 offsets on R help seems to have been ignored
> (sorry deleted original email - is there a way to continue thread in
> this case?)
>
> https://stat.ethz.ch/pipermail/r-help/2009-February/189352.html
>
> It does seem to be a bug, in that glm does not behave as documented. In
> fact the same bug applies to lm as well.
>
> I don't think the suggested fix works though - Y isn't available until
> the model frame is evaluated. Moreover you would want to evaluate the
> offset as part of the model frame, to take care of the search path,
> subset and na.action.
>
> One possibility would be to modify model.frame to recycle variables of
> length one. This would be a potentially useful feature from my point of
> view as offset(constant) could replace Const(constant) in gnm, which is
> basically a work around for this problem in the case of specifying a
> constant in a nonlinear term. However, this solution may have undesired
> side-effects and I don't feel too strongly about it as there are various
>  work-arounds. Perhaps the simplest solution would be to modify the docs
> so that offsets of length one are disallowed - it is easy enough for the
> user to create a vector of the right length as necessary.
>
> Best regards,
>
> Heather
>



-- 
Ken Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html


From ken.knoblauch at inserm.fr  Wed Feb 25 14:15:10 2009
From: ken.knoblauch at inserm.fr (Kenneth Knoblauch)
Date: Wed, 25 Feb 2009 14:15:10 +0100
Subject: [Rd] [R] length 1 offset in glm (& lm)
In-Reply-To: <alpine.OSX.1.00.0902251252010.70608@tystie.local>
References: <49A53E1B.4090004@warwick.ac.uk>
	<alpine.OSX.1.00.0902251252010.70608@tystie.local>
Message-ID: <20090225141510.vzf0j0passoso4sw@imp.inserm.fr>

Hi

Quoting Prof Brian Ripley <ripley at stats.ox.ac.uk>:

> On Wed, 25 Feb 2009, Heather Turner wrote:
>
>> This post about length 1 offsets on R help seems to have been ignored
>> (sorry deleted original email - is there a way to continue thread in
>> this case?)
>>
>> https://stat.ethz.ch/pipermail/r-help/2009-February/189352.html
>
> So let's be clear: this was the 'offset' argument' and not the offset()
> function as you refer to below.

It occurs for both

c1 <- structure(list(Contr = c(0.028, 0.043, 0.064, 0.097, 0.146, 0.219
), Correct = c(34L, 57L, 94L, 152L, 160L, 160L), Incorrect = c(126L,
103L, 66L, 8L, 0L, 0L)), .Names = c("Contr", "Correct", "Incorrect"
), row.names = c(NA, 6L), class = "data.frame")

glm(cbind(Correct, Incorrect) ~ Contr + offset(qlogis(0.25)) - 1, binomial,
	data = c1)
Error in model.frame.default(formula = cbind(Correct, Incorrect) ~ Contr +  :
   variable lengths differ (found for 'offset(qlogis(0.25))')
+

Thanks for looking into this when time permits.

Ken

--- remaining deleted



>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595



-- 
Ken Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html


From jeff.a.ryan at gmail.com  Fri Feb 27 19:06:18 2009
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Fri, 27 Feb 2009 12:06:18 -0600
Subject: [Rd] POSIXlt, POSIXct, strptime, GMT and 1969-12-31 23:59:59
Message-ID: <e8e755250902271006k11d9e278g2a96758645da9029@mail.gmail.com>

R-devel:

Some very inconsistent behavior, that I can't seem to find documented.

Sys.setenv(TZ="GMT")

str(unclass(strptime("1969-12-31 23:59:59","%Y-%m-%d %H:%M:%S")))
List of 9
 $ sec  : num 59
 $ min  : int 59
 $ hour : int 23
 $ mday : int 31
 $ mon  : int 11
 $ year : int 69
 $ wday : int 3
 $ yday : int 364
 $ isdst: int 0
 - attr(*, "tzone")= chr "GMT"

# setting to 59 seconds now reports 0
str(unclass(as.POSIXlt("1969-12-31 23:59:59")))
List of 9
 $ sec  : num 0
 $ min  : int 59
 $ hour : int 23
 $ mday : int 31
 $ mon  : int 11
 $ year : int 69
 $ wday : int 3
 $ yday : int 364
 $ isdst: int 0
 - attr(*, "tzone")= chr "GMT"
>

Setting the secs in the string to 58 returns a correct structure:
str(unclass(as.POSIXlt("1969-12-31 23:59:58")))
List of 9
 $ sec  : num 58
 $ min  : int 59
 $ hour : int 23
 $ mday : int 31
 $ mon  : int 11
 $ year : int 69
 $ wday : int 3
 $ yday : int 364
 $ isdst: int 0
 - attr(*, "tzone")= chr "GMT"

Some additional strangeness occurs once as.POSIXct is called:

str(as.POSIXct(as.POSIXlt("1969-12-31 23:59:58")))
 POSIXct[1:1], format: "1969-12-31 23:59:58"

# this incorrectly ignores the secs
str(as.POSIXct(as.POSIXlt("1969-12-31 23:59:59")))
 POSIXct[1:1], format: "1969-12-31 23:59:00"

# this should be -1, if I am not mistaken
str(as.POSIXct(strptime("1969-12-31 23:59:59","%Y-%m-%d %H:%M:%S")))
 POSIXct[1:1], format: NA

According to ?strptime NA should be returned if the time doesn't
exist.  As far as I can tell, 1969-12-31 23:59:59 does exists.

Using a simple C program (source follows this message):

[veblen:~/Rforge/xts] jryan% ./a.out
Date as tm struct (POSIXlt):1969-12-31 23:59:59
   sec: 59
   min: 59
  hour: 23
  mday: 31
   mon: 11
  year: 69
  wday: 3
  yday: 364
seconds since the Epoch: -1

Which gives the -1. This is all run on a Intel Mac, though has been
tested on FreeBSD and Ubuntu as well with the same outcome.  It does
seem to work fine on Windows though.  I think the workaround for
Windows is what is causing the failure elsewhere.

As far as I can see, the code that is causing this is do_asPOSIXct in
datetime.c:

 695     if(!R_FINITE(secs) || tm.tm_min == NA_INTEGER ||
 696        tm.tm_hour == NA_INTEGER || tm.tm_mday == NA_INTEGER ||
 697        tm.tm_mon == NA_INTEGER || tm.tm_year == NA_INTEGER)
 698         REAL(ans)[i] = NA_REAL;
 699     else {
 700         errno = 0;
 701         tmp = mktime0(&tm, 1 - isgmt);
 702 #ifdef MKTIME_SETS_ERRNO
 703         REAL(ans)[i] = errno ? NA_REAL : tmp + (secs - fsecs);
 704 #else
 705         REAL(ans)[i] = (tmp == (double)(-1)) ?
 706         NA_REAL : tmp + (secs - fsecs);
 707 #endif
 708     }

I haven't been able to look further into this logic, but the test for
-1 strikes me as where this is happening.

Thank you for any insight you can provide.

Jeff

> sessionInfo()
R version 2.9.0 Under development (unstable) (2009-02-27 r48020)
i386-apple-darwin8.11.1

locale:
C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


######### C PROGRAM #########

#include <time.h>
#include <stdio.h>
/*
   code modified from:

   http://www.opengroup.org/onlinepubs/009695399/functions/strptime.html
   by Jeff Ryan
*/

struct tm tm;
time_t t;


int main()
{
char DATE[] = "1969-12-31 23:59:59";
printf("Date as tm struct (POSIXlt):%s\n", DATE);

strptime(DATE, "%Y-%m-%d %H:%M:%S", &tm);

tm.tm_isdst = -1;      /* Not set by strptime(); tells mktime()
                          to determine whether daylight saving time
                          is in effect */
t = mktime(&tm);
printf(
       "   sec: %d\n"
       "   min: %d\n"
       "  hour: %d\n"
       "  mday: %d\n"
       "   mon: %d\n"
       "  year: %d\n"
       "  wday: %d\n"
       "  yday: %d\n",
       tm.tm_sec,
       tm.tm_min,
       tm.tm_hour,
       tm.tm_mday,
       tm.tm_mon,
       tm.tm_year,
       tm.tm_wday,
       tm.tm_yday);

printf("seconds since the Epoch: %d\n", t);
return 0;
}


-- 
Jeffrey Ryan
jeffrey.ryan at insightalgo.com

ia: insight algorithmics
www.insightalgo.com


From jeff.hamann at forestinformatics.com  Sat Feb 28 00:36:16 2009
From: jeff.hamann at forestinformatics.com (Jeff Hamann)
Date: Fri, 27 Feb 2009 15:36:16 -0800
Subject: [Rd] R_CHAR + 21 (memory.c:2573) in crash report...
Message-ID: <49A878F0.5070600@forestinformatics.com>

I'm not sure if this is the best subject line, and I apologize in
advanced for the cross-posting, but I've been trying to get past a piece
of code for two days now, and seem to have narrowed where a show
stopping crash is occurring...

I keep getting:

psql:../sql/schedpak.sql:257: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.
psql:../sql/schedpak.sql:257: connection to server was lost

Process SQL exited abnormally with code 2

when I return from a plr function:

select * from pareto_set_as_gpx( 1, 20678 );

I'm a little handicapped as I'm not used to debugging by trial and
error, and just don't know what else I can do. I've attached a crash
report, and don't know if this is a problem with the PL/R module, the
libR.dylib module, or something I'm doing incorrectly. I've been using
this code for months now, and added another column to the type
definition, which seemed to break something.


Does the following indicate that libR.dylib is causing this crash?

Thread 0 Crashed:
0   libR.dylib                    	0x015d4a35 R_CHAR + 21 (memory.c:2573)
1   plr.so                        	0x007ce329 get_frame_tuplestore + 1001
2   plr.so                        	0x007ce854 r_get_pg + 356
3   plr.so                        	0x007cc2ab plr_call_handler + 363
4   postgres                      	0x0010483a
ExecMakeTableFunctionResult + 314
5   postgres                      	0x00112dc0 FunctionNext + 128
6   postgres                      	0x00107325 ExecScan + 357
7   postgres                      	0x001129e2 ExecFunctionScan + 34
8   postgres                      	0x000ffc2f ExecProcNode + 447
9   postgres                      	0x000fd9eb ExecutorRun + 827
10  postgres                      	0x001abf5f PortalRunSelect + 655
11  postgres                      	0x001acd41 PortalRun + 433
12  postgres                      	0x001a7b45 exec_simple_query + 661
13  postgres                      	0x001a97ff PostgresMain + 4751
14  postgres                      	0x00178774 ServerLoop + 2964
15  postgres                      	0x00179798 PostmasterMain + 2760
16  postgres                      	0x0012329b main + 1227
17  postgres                      	0x00001676 start + 54


-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: postgres_2009-02-27-151418_jeff-hamanns-macbook-pro.crash
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090227/fbaadc28/attachment.pl>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 258 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20090227/fbaadc28/attachment.bin>

From mail at joeconway.com  Sat Feb 28 02:43:15 2009
From: mail at joeconway.com (Joe Conway)
Date: Fri, 27 Feb 2009 17:43:15 -0800
Subject: [Rd] [Plr-general] R_CHAR + 21 (memory.c:2573) in crash
	report...
In-Reply-To: <49A878F0.5070600@forestinformatics.com>
References: <49A878F0.5070600@forestinformatics.com>
Message-ID: <49A896B3.6030203@joeconway.com>

Jeff Hamann wrote:
> I've been using
> this code for months now, and added another column to the type
> definition, which seemed to break something.

Undoubtedly the above has something to do with the problem, and I would 
guess the issue is in PL/R, not R.

However, in order to get to the bottom of it I'll need a self contained 
minimal test case that will reproduce the crash (i.e. related table 
definitions, some sample data, PL/R function, and other functions that 
are dependencies, sample use of said function).

If you want you can send it to me off list. In any case, please drop 
r-devel from the thread from this point forward (I only maintained the 
cross-post so they could see that I was responding).

Joe


From maechler at stat.math.ethz.ch  Sat Feb 28 12:34:39 2009
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 28 Feb 2009 12:34:39 +0100
Subject: [Rd] Unexpected side effect of the ":::" operator on the value
	of isGeneric
In-Reply-To: <49A58AA7.8030500@ebi.ac.uk>
References: <49A58AA7.8030500@ebi.ac.uk>
Message-ID: <18857.8527.746773.902464@cmath-5.math.ethz.ch>

>>>>> "Wolfi" == Wolfgang Huber <huber at ebi.ac.uk>
>>>>>     on Wed, 25 Feb 2009 18:15:03 +0000 writes:

    Wolfi> Hi,
    Wolfi> when running the following on a fresh R,


    Wolfi> library("IRanges")
    Wolfi> annotation
    Wolfi> showMethods("annotation")
    Wolfi> Biobase:::annotation
    Wolfi> showMethods("annotation")


    Wolfi> I get (see the "^^^^^" marked output at the bottom):


    >> library("IRanges")

    Wolfi> Carico il pacchetto richiesto: 'IRanges'

    Wolfi> The following object(s) are masked from package:base :

    Wolfi> cbind,
    Wolfi> order,
    Wolfi> pmax,
    Wolfi> pmax.int,
    Wolfi> pmin,
    Wolfi> pmin.int,
    Wolfi> rbind,
    Wolfi> rep.int,
    Wolfi> table

    >> annotation
    Wolfi> standardGeneric for "annotation" defined from package "IRanges"

    Wolfi> function (x, ...)
    Wolfi> standardGeneric("annotation")
    Wolfi> <environment: 0x1a302b0>
    Wolfi> Methods may be defined for arguments: x
    Wolfi> Use  showMethods("annotation")  for currently available ones.

    >> showMethods("annotation")
    Wolfi> Function: annotation (package IRanges)
    Wolfi> x="AnnotatedList"

    >> Biobase:::annotation
    Wolfi> standardGeneric for "annotation" defined from package "Biobase"

    Wolfi> function (object)
    Wolfi> standardGeneric("annotation")
    Wolfi> <environment: 0x205cee0>
    Wolfi> Methods may be defined for arguments: object
    Wolfi> Use  showMethods("annotation")  for currently available ones.

    >> showMethods("annotation")

    Wolfi> Function "annotation":
    Wolfi> <not a generic function>
    Wolfi> ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


    Wolfi> It seems that the value of isGeneric("annotation"), when it is called
    Wolfi> within showMethods, is FALSE, while it is TRUE when called outside.

Hi Wolfgang,

I have looked at the NAMESPACE files of the two packages  
Biobase and IRanges, (the Bioconductor development version in SVN),
and I think the problem might result from the fact
that IRanges  does export the  annotation  generic, does not 
exportMethods( ...  annotation ...).

OTOH,  Biobase  exportMethods(  annotation ) only [but not the generic].
and then both packages do not at all mention each other,
neither in DESCRIPTION nor NAMESPACE.

Either you are talking about conceptually the same generic
annotation(); in that case one package needs to import*() it
from the other, 
or then you have two completely different animals, but then
(masking) problems are unavoidable 
-- in spite of the fact that I vaguely remember that some
   Bioconductor developers repeatedly emphasize that these
   problems are not problems for them
 
Martin

    >> sessionInfo()
    Wolfi> R version 2.9.0 Under development (unstable) (2009-02-25 r48007)
    Wolfi> x86_64-unknown-linux-gnu

    Wolfi> locale:
    Wolfi> LC_CTYPE=it_IT.UTF-8;LC_NUMERIC=C;LC_TIME=it_IT.UTF-8;LC_COLLATE=it_IT.UTF-8;LC_MONETARY=C;LC_MESSAGES=it_IT.UTF-8;LC_PAPER=it_IT.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=it_IT.UTF-8;LC_IDENTIFICATION=C

    Wolfi> attached base packages:
    Wolfi> [1] stats     graphics  grDevices utils     datasets  methods   base

    Wolfi> other attached packages:
    Wolfi> [1] IRanges_1.1.40

    Wolfi> loaded via a namespace (and not attached):
    Wolfi> [1] Biobase_2.3.10



    Wolfi> Best wishes
    Wolfi> Wolfgang

    Wolfi> ------------------------------------------------------------------
    Wolfi> Wolfgang Huber  EBI/EMBL  Cambridge UK  http://www.ebi.ac.uk/huber

    Wolfi> ______________________________________________
    Wolfi> R-devel at r-project.org mailing list
    Wolfi> https://stat.ethz.ch/mailman/listinfo/r-devel


From huber at ebi.ac.uk  Sat Feb 28 19:01:19 2009
From: huber at ebi.ac.uk (Wolfgang Huber)
Date: Sat, 28 Feb 2009 18:01:19 +0000
Subject: [Rd] Unexpected side effect of the ":::" operator on the value
 of isGeneric
In-Reply-To: <18857.8527.746773.902464@cmath-5.math.ethz.ch>
References: <49A58AA7.8030500@ebi.ac.uk>
	<18857.8527.746773.902464@cmath-5.math.ethz.ch>
Message-ID: <49A97BEF.60907@ebi.ac.uk>

Dear Martin

name masking is a separate issue, which I do not want to explore here.

If one accepts the notion that unrelated generics of the same name may
exist in different namespaces (user confusion aside, I don't see a
technical reason why one shouldn't), then I find the behaviour of R in
the below case puzzling: the value of "showMethods(something)" called
from the global environment depends on whether or not the expression
"package::something" has previously been evaluated. The value of
isGeneric(something) is different when called from top-level and when
called within showMethods.

Best wishes
 Wolfgang


PS1: I do apologize if this behaviour is intentional, and documented
somewhere. I would then be puzzled even more though.

PS2: My code example used ":::", and there are some vague warnings in
its man page that ":::" is "dangerous". The problem also occurs with "::".

------------------------------------------------------------------
Wolfgang Huber  EBI/EMBL  Cambridge UK  http://www.ebi.ac.uk/huber


28/02/2009 11:34 Martin Maechler scripsit
>>>>>> "Wolfi" == Wolfgang Huber <huber at ebi.ac.uk>
>>>>>>     on Wed, 25 Feb 2009 18:15:03 +0000 writes:
> 
>     Wolfi> Hi,
>     Wolfi> when running the following on a fresh R,
> 
> 
>     Wolfi> library("IRanges")
>     Wolfi> annotation
>     Wolfi> showMethods("annotation")
>     Wolfi> Biobase:::annotation
>     Wolfi> showMethods("annotation")
> 
> 
>     Wolfi> I get (see the "^^^^^" marked output at the bottom):
> 
> 
>     >> library("IRanges")
> 
>     Wolfi> Carico il pacchetto richiesto: 'IRanges'
> 
>     Wolfi> The following object(s) are masked from package:base :
> 
>     Wolfi> cbind,
>     Wolfi> order,
>     Wolfi> pmax,
>     Wolfi> pmax.int,
>     Wolfi> pmin,
>     Wolfi> pmin.int,
>     Wolfi> rbind,
>     Wolfi> rep.int,
>     Wolfi> table
> 
>     >> annotation
>     Wolfi> standardGeneric for "annotation" defined from package "IRanges"
> 
>     Wolfi> function (x, ...)
>     Wolfi> standardGeneric("annotation")
>     Wolfi> <environment: 0x1a302b0>
>     Wolfi> Methods may be defined for arguments: x
>     Wolfi> Use  showMethods("annotation")  for currently available ones.
> 
>     >> showMethods("annotation")
>     Wolfi> Function: annotation (package IRanges)
>     Wolfi> x="AnnotatedList"
> 
>     >> Biobase:::annotation
>     Wolfi> standardGeneric for "annotation" defined from package "Biobase"
> 
>     Wolfi> function (object)
>     Wolfi> standardGeneric("annotation")
>     Wolfi> <environment: 0x205cee0>
>     Wolfi> Methods may be defined for arguments: object
>     Wolfi> Use  showMethods("annotation")  for currently available ones.
> 
>     >> showMethods("annotation")
> 
>     Wolfi> Function "annotation":
>     Wolfi> <not a generic function>
>     Wolfi> ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> 
> 
>     Wolfi> It seems that the value of isGeneric("annotation"), when it is called
>     Wolfi> within showMethods, is FALSE, while it is TRUE when called outside.
> 
> Hi Wolfgang,
> 
> I have looked at the NAMESPACE files of the two packages  
> Biobase and IRanges, (the Bioconductor development version in SVN),
> and I think the problem might result from the fact
> that IRanges  does export the  annotation  generic, does not 
> exportMethods( ...  annotation ...).
> 
> OTOH,  Biobase  exportMethods(  annotation ) only [but not the generic].
> and then both packages do not at all mention each other,
> neither in DESCRIPTION nor NAMESPACE.
> 
> Either you are talking about conceptually the same generic
> annotation(); in that case one package needs to import*() it
> from the other, 
> or then you have two completely different animals, but then
> (masking) problems are unavoidable 
> -- in spite of the fact that I vaguely remember that some
>    Bioconductor developers repeatedly emphasize that these
>    problems are not problems for them
>  
> Martin
> 
>     >> sessionInfo()
>     Wolfi> R version 2.9.0 Under development (unstable) (2009-02-25 r48007)
>     Wolfi> x86_64-unknown-linux-gnu
> 
>     Wolfi> locale:
>     Wolfi> LC_CTYPE=it_IT.UTF-8;LC_NUMERIC=C;LC_TIME=it_IT.UTF-8;LC_COLLATE=it_IT.UTF-8;LC_MONETARY=C;LC_MESSAGES=it_IT.UTF-8;LC_PAPER=it_IT.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=it_IT.UTF-8;LC_IDENTIFICATION=C
> 
>     Wolfi> attached base packages:
>     Wolfi> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
>     Wolfi> other attached packages:
>     Wolfi> [1] IRanges_1.1.40
> 
>     Wolfi> loaded via a namespace (and not attached):
>     Wolfi> [1] Biobase_2.3.10
> 
> 
> 
>     Wolfi> Best wishes
>     Wolfi> Wolfgang
> 
>     Wolfi> ------------------------------------------------------------------
>     Wolfi> Wolfgang Huber  EBI/EMBL  Cambridge UK  http://www.ebi.ac.uk/huber
> 
>     Wolfi> ______________________________________________
>     Wolfi> R-devel at r-project.org mailing list
>     Wolfi> https://stat.ethz.ch/mailman/listinfo/r-devel


From robert.peck1 at myfairpoint.net  Sat Feb 28 15:50:04 2009
From: robert.peck1 at myfairpoint.net (robert.peck1 at myfairpoint.net)
Date: Sat, 28 Feb 2009 15:50:04 +0100 (CET)
Subject: [Rd] Cannot install some packages (PR#13559)
Message-ID: <20090228145004.61FC2282C768@mail.pubhealth.ku.dk>

Full_Name: Robert Peck
Version: 2.8.1
OS: XP Home
Submission from: (NULL) (71.168.114.196)


There are some packages that I cannot install on my PC.

Example: LearnBayes

The following output is sent back:

> utils:::menuInstallPkgs()
trying URL 'http://www.ibiblio.org/pub/languages/R/CRAN/bin/windows/contrib/2.8/LearnBayes_2.0.zip'
Content type 'application/zip' length 379068 bytes (370 Kb)
opened URL
downloaded 370 Kb

package 'LearnBayes' successfully unpacked and MD5 sums checked
Error in normalizePath(path) : 
  path[1]: The system cannot find the file specified
> 


   I have reinstalled R several times and tried different mirror sites.

   Robert Peck


