From nakama at ki.rim.or.jp  Thu Dec  1 06:39:55 2016
From: nakama at ki.rim.or.jp (Ei-ji Nakama)
Date: Thu, 1 Dec 2016 14:39:55 +0900
Subject: [Rd] Different results for cos,sin,tan and cospi,sinpi,tanpi
Message-ID: <CAJqeyYZ2jozkWyvpBk9m=zeunh25ciFCfJdBx10ge3hbRUV_cg@mail.gmail.com>

Hi,

i try sin, cos, and tan.

> sapply(c(cos,sin,tan),function(x,y)x(y),1.23e45*pi)
[1] 0.5444181 0.8388140 1.5407532

However, *pi results the following

> sapply(c(cospi,sinpi,tanpi),function(x,y)x(y),1.23e45)
[1] 1 0 0

Please try whether the following becomes all right.

diff -ruN R-3.3.2.orig/src/nmath/cospi.c R-3.3.2/src/nmath/cospi.c
--- R-3.3.2.orig/src/nmath/cospi.c      2016-09-15 07:15:31.000000000 +0900
+++ R-3.3.2/src/nmath/cospi.c   2016-12-01 13:54:38.863357149 +0900
@@ -35,7 +35,11 @@
 #endif
     if(!R_FINITE(x)) ML_ERR_return_NAN;

-    x = fmod(fabs(x), 2.);// cos() symmetric; cos(pi(x + 2k)) ==
cos(pi x) for all integer k
+    x = fabs(x);
+    if ( x > 9007199254740991 ) /* 2^53-1 */
+        return cos(M_PI * x);
+
+    x = fmod(x, 2.);// cos() symmetric; cos(pi(x + 2k)) == cos(pi x)
for all integer k
     if(fmod(x, 1.) == 0.5) return 0.;
     if( x == 1.)       return -1.;
     if( x == 0.)       return  1.;
@@ -57,6 +61,9 @@
 #endif
     if(!R_FINITE(x)) ML_ERR_return_NAN;

+    if (( x >  9007199254740991 )||  /*  2^53-1 */
+        ( x < -9007199254740991 )  ) /* -2^53-1 */
+        return sin(M_PI * x);
     x = fmod(x, 2.); // sin(pi(x + 2k)) == sin(pi x)  for all integer k
     // map (-2,2) --> (-1,1] :
     if(x <= -1) x += 2.; else if (x > 1.) x -= 2.;
@@ -81,6 +88,10 @@
 #endif
     if(!R_FINITE(x)) ML_ERR_return_NAN;

+    if (( x >  9007199254740991 )||  /*  2^53-1 */
+        ( x < -9007199254740991 )  ) /* -2^53-1 */
+        return tan(M_PI * x);
+
     x = fmod(x, 1.); // tan(pi(x + k)) == tan(pi x)  for all integer k
     // map (-1,1) --> (-1/2, 1/2] :
     if(x <= -0.5) x++; else if(x > 0.5) x--;

-- 
Best Regards,
--
Eiji NAKAMA <nakama (a) ki.rim.or.jp>
"\u4e2d\u9593\u6804\u6cbb"  <nakama (a) ki.rim.or.jp>


From maechler at stat.math.ethz.ch  Thu Dec  1 09:36:10 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 1 Dec 2016 09:36:10 +0100
Subject: [Rd] Different results for cos,sin,tan and cospi,sinpi,tanpi
In-Reply-To: <CAJqeyYZ2jozkWyvpBk9m=zeunh25ciFCfJdBx10ge3hbRUV_cg@mail.gmail.com>
References: <CAJqeyYZ2jozkWyvpBk9m=zeunh25ciFCfJdBx10ge3hbRUV_cg@mail.gmail.com>
Message-ID: <22591.57594.122801.713377@stat.math.ethz.ch>

>>>>> Ei-ji Nakama <nakama at ki.rim.or.jp>
>>>>>     on Thu, 1 Dec 2016 14:39:55 +0900 writes:

    > Hi,
    > i try sin, cos, and tan.

    >> sapply(c(cos,sin,tan),function(x,y)x(y),1.23e45*pi)
    > [1] 0.5444181 0.8388140 1.5407532

    > However, *pi results the following

    >> sapply(c(cospi,sinpi,tanpi),function(x,y)x(y),1.23e45)
    > [1] 1 0 0

    > Please try whether the following becomes all right.

    [..............................]

Yes, it does  -- the fix will be in all future versions of R.

Thank you very much Ei-ji Nakama, for this valuable contribution
to make R better!

Martin Maechler,
ETH Zurich


    > -- 
    > Best Regards,
    > --
    > Eiji NAKAMA <nakama (a) ki.rim.or.jp>
    > "\u4e2d\u9593\u6804\u6cbb"  <nakama (a) ki.rim.or.jp>


From maechler at stat.math.ethz.ch  Thu Dec  1 10:12:51 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 1 Dec 2016 10:12:51 +0100
Subject: [Rd] Different results for cos,sin,tan and cospi,sinpi,tanpi
In-Reply-To: <22591.57594.122801.713377@stat.math.ethz.ch>
References: <CAJqeyYZ2jozkWyvpBk9m=zeunh25ciFCfJdBx10ge3hbRUV_cg@mail.gmail.com>
	<22591.57594.122801.713377@stat.math.ethz.ch>
Message-ID: <22591.59795.613756.145797@stat.math.ethz.ch>

>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Thu, 1 Dec 2016 09:36:10 +0100 writes:

>>>>> Ei-ji Nakama <nakama at ki.rim.or.jp>
>>>>>     on Thu, 1 Dec 2016 14:39:55 +0900 writes:

    >> Hi,
    >> i try sin, cos, and tan.

    >>> sapply(c(cos,sin,tan),function(x,y)x(y),1.23e45*pi)
    >> [1] 0.5444181 0.8388140 1.5407532

    >> However, *pi results the following

    >>> sapply(c(cospi,sinpi,tanpi),function(x,y)x(y),1.23e45)
    >> [1] 1 0 0

    >> Please try whether the following becomes all right.

    > [..............................]

    > Yes, it does  -- the fix will be in all future versions of R.

oops.... not so quickly, Martin!

Of course, the results then coincide,  by sheer implementation.

*BUT* it is not at all clear which of the two results is better;
e.g., if you replace '1.23' by '1' in the above examples, the
result of the unchnaged  *pi() functions is 100% accurate,
whereas

 R> sapply(c(cos,sin,tan), function(Fn) Fn(1e45*pi))
 [1] -0.8847035 -0.4661541  0.5269043

is "garbage".  After all,  1e45 is an even integer and so, the
(2pi)-periodic functions should give the same as for 0  which
*is*  (1, 0, 0).

For such very large arguments, the results of all of sin() ,
cos() and tan()  are in some sense "random garbage" by
necessity:
Such large numbers have zero information about the resolution modulo
[0, 2pi)  or (-pi, pi]  and hence any (non-trivial) periodic
function with such a "small" period can only return "random noise".


    > Thank you very much Ei-ji Nakama, for this valuable contribution
    > to make R better!

That is still true!  It raises the issue to all of us and will
improve the documentation at least!

At the moment, I'm not sure where we should go.
Of course, I could start experiments using my own 'Rmpfr'
package where I can (with increasing computational effort!) get
correct values (for increasingly larger arguments) but at the
moment, I don't see how this would help.

Martin

    > Martin Maechler,
    > ETH Zurich


    >> -- 
    >> Best Regards,
    >> --
    >> Eiji NAKAMA <nakama (a) ki.rim.or.jp>
    >> "\u4e2d\u9593\u6804\u6cbb"  <nakama (a) ki.rim.or.jp>

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Thu Dec  1 10:31:00 2016
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 1 Dec 2016 09:31:00 +0000
Subject: [Rd] Different results for cos,sin,tan and cospi,sinpi,tanpi
In-Reply-To: <22591.59795.613756.145797@stat.math.ethz.ch>
References: <CAJqeyYZ2jozkWyvpBk9m=zeunh25ciFCfJdBx10ge3hbRUV_cg@mail.gmail.com>
	<22591.57594.122801.713377@stat.math.ethz.ch>
	<22591.59795.613756.145797@stat.math.ethz.ch>
Message-ID: <af030acd-b3fb-be11-3449-52301a46b053@stats.ox.ac.uk>

Please note that you need to report your platforms (as per the posting 
guide), as the C function starts

#ifdef HAVE_COSPI
#elif defined HAVE___COSPI
double cospi(double x) {
     return __cospi(x);
}

And AFAICS the system versions on Solaris and OS X behave the same way 
as R's substitute.



On 01/12/2016 09:12, Martin Maechler wrote:
>>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>>     on Thu, 1 Dec 2016 09:36:10 +0100 writes:
>
>>>>>> Ei-ji Nakama <nakama at ki.rim.or.jp>
>>>>>>     on Thu, 1 Dec 2016 14:39:55 +0900 writes:
>
>     >> Hi,
>     >> i try sin, cos, and tan.
>
>     >>> sapply(c(cos,sin,tan),function(x,y)x(y),1.23e45*pi)
>     >> [1] 0.5444181 0.8388140 1.5407532
>
>     >> However, *pi results the following
>
>     >>> sapply(c(cospi,sinpi,tanpi),function(x,y)x(y),1.23e45)
>     >> [1] 1 0 0
>
>     >> Please try whether the following becomes all right.
>
>     > [..............................]
>
>     > Yes, it does  -- the fix will be in all future versions of R.
>
> oops.... not so quickly, Martin!
>
> Of course, the results then coincide,  by sheer implementation.
>
> *BUT* it is not at all clear which of the two results is better;
> e.g., if you replace '1.23' by '1' in the above examples, the
> result of the unchnaged  *pi() functions is 100% accurate,
> whereas
>
>  R> sapply(c(cos,sin,tan), function(Fn) Fn(1e45*pi))
>  [1] -0.8847035 -0.4661541  0.5269043
>
> is "garbage".  After all,  1e45 is an even integer and so, the
> (2pi)-periodic functions should give the same as for 0  which
> *is*  (1, 0, 0).
>
> For such very large arguments, the results of all of sin() ,
> cos() and tan()  are in some sense "random garbage" by
> necessity:
> Such large numbers have zero information about the resolution modulo
> [0, 2pi)  or (-pi, pi]  and hence any (non-trivial) periodic
> function with such a "small" period can only return "random noise".
>
>
>     > Thank you very much Ei-ji Nakama, for this valuable contribution
>     > to make R better!
>
> That is still true!  It raises the issue to all of us and will
> improve the documentation at least!
>
> At the moment, I'm not sure where we should go.
> Of course, I could start experiments using my own 'Rmpfr'
> package where I can (with increasing computational effort!) get
> correct values (for increasingly larger arguments) but at the
> moment, I don't see how this would help.
>
> Martin


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford


From maechler at stat.math.ethz.ch  Thu Dec  1 10:34:17 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 1 Dec 2016 10:34:17 +0100
Subject: [Rd] problem with normalizePath()
In-Reply-To: <CABKQe-a0KKkF-CjbbEJjg0fHJum53JQMtys=pX+2Eqa7Nqh9pA@mail.gmail.com>
References: <e6592864a7b34cca92711b6c3c309484@dhhs.nh.gov>
	<CABKQe-Zh+xoX5geKqYvGMpO1bPx5BjwD61cTY-1tKagLw-KJMA@mail.gmail.com>
	<22575.26225.614494.711839@stat.math.ethz.ch>
	<cbb1cb742eae4ed298f82b03642c9259@dhhs.nh.gov>
	<CABKQe-a0KKkF-CjbbEJjg0fHJum53JQMtys=pX+2Eqa7Nqh9pA@mail.gmail.com>
Message-ID: <22591.61081.364775.478736@stat.math.ethz.ch>

>>>>> Evan Cortens <ecortens at mtroyal.ca>
>>>>>     on Wed, 30 Nov 2016 09:58:59 -0700 writes:

    > I found this as well. At our institution, our home directories are on
    > network shares that are mapped to local drives. The default, it appears, is
    > to set the location for libraries (etc) to the network share name
    > (//computer//share/director/a/b/user) rather than the local drive mapping
    > (H:/). Given the issue with dir.create(), this means it's impossible to
    > install packages (since it tries to "create" the share, not the highest
    > directory). This can be fixed in the same way Michael found, namely, set
    > the environment variables to use the local mapping rather than the network
    > share. But ideally, the fix would be to treat Windows network paths
    > correctly.

Yes, and why shouldn't Microsoft be the institution who can best
judge how to do that,  now that they sell a "Microsoft R"  ?????? !??!?!??!?!??!?
(trying again with BCC;  next time, I'll use CC).

(a slowly increasingly frustrated)
Martin Maechler
ETH Zurich

    > Best,
    > Evan

    > On Wed, Nov 30, 2016 at 7:16 AM, Laviolette, Michael <
    > Michael.Laviolette at dhhs.nh.gov> wrote:

    >> In researching another issue, I discovered a workaround: the network drive
    >> folder needs to be mapped to the local PC.
    >> 
    >> setwd("//Hzndhhsvf2/data/OCPH/EPI/BHSDM/Group/Michael Laviolette/Stat
    >> tools")
    >> df1 <- readxl::read_excel("addrlist-4-MikeL.xls", 2)
    >> # fails, throws same error
    >> df2 <- readxl::read_excel("Z:/Stat tools/addrlist-4-MikeL.xls", 2)      #
    >> works
    >> 
    >> -----Original Message-----
    >> From: Martin Maechler [mailto:maechler at stat.math.ethz.ch]
    >> Sent: Friday, November 18, 2016 3:37 PM
    >> To: Evan Cortens
    >> Cc: Laviolette, Michael; r-devel at r-project.org
    >> Subject: Re: [Rd] problem with normalizePath()
    >> 
    >> >>>>> Evan Cortens <ecortens at mtroyal.ca>
    >> >>>>>     on Thu, 17 Nov 2016 15:51:03 -0700 writes:
    >> 
    >> > I wonder if this could be related to the issue that I
    >> > submitted to bugzilla about two months ago? (
    >> > https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=17159)
    >> 
    >> > That is to say, could it be that it's treating the first
    >> > path after the single backslash as an actual directory,
    >> > rather than as the name of the share?
    >> 
    >> > --
    >> > Evan Cortens, PhD Institutional Analyst - Office of
    >> > Institutional Analysis Mount Royal University 403-440-6529
    >> 
    >> Could well be.  Thank you, Evan, also for your bug report including patch
    >> proposal.
    >> 
    >> In such situations we (R core) would be really happy if Microsoft showed
    >> another facet of their investment into R:
    >> Ideally there should be enough staff who can judge and test such bugs and
    >> bug fixes?
    >> 
    --> I'm BCC'ing this to one place at least.
    >> 
    >> Best,
    >> Martin Maechler  ETH Zurich
    >> 
    >> > On Thu, Nov 17, 2016 at 2:28 PM, Laviolette, Michael <
    >> > Michael.Laviolette at dhhs.nh.gov> wrote:
    >> 
    >> >> The packages "readxl" and "haven" (and possibly others)
    >> >> no longer access files on shared network drives. The
    >> >> problem appears to be in the normalizePath()
    >> >> function. The file can be read from a local drive or by
    >> >> functions that don't call normalizePath(). The error
    >> >> thrown is
    >> >>
    >> >> Error:
    >> >> path[1]="\\Hzndhhsvf2/data/OCPH/EPI/BHSDM/Group/17.xls":
    >> >> The system cannot find the file specified
    >> >>
    >> >> Here's my session:
    >> >>
    >> >> library(readxl) library(XLConnect)
    >> >>
    >> >> # attempting to read file from network drive df1 <-
    >> >> read_excel("//Hzndhhsvf2/data/OCPH/EPI/BHSDM/Group/17.xls")
    >> >> # pathname is fully qualified, but error thrown as above
    >> >>
    >> >> cat(normalizePath("//Hzndhhsvf2/data/OCPH/EPI/BHSDM/Group/17.xls"))
    >> >> # throws same error
    >> >>
    >> >> # reading same file with different function df2 <-
    >> >> readWorksheetFromFile("//Hzndhhsvf2/data/OCPH/EPI/
    >> BHSDM/Group/17.xls",
    >> >> 1) # completes successfully
    >> >>
    >> >> # reading same file from local drive df3 <-
    >> >> read_excel("C:/17.xls") # completes successfully
    >> >>
    >> >> sessionInfo() R version 3.3.2 (2016-10-31) Platform:
    >> >> x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 7
    >> >> x64 (build 7601) Service Pack 1
    >> >>
    >> >> locale: [1] LC_COLLATE=English_United States.1252
    >> >> LC_CTYPE=English_United States.1252 [3]
    >> >> LC_MONETARY=English_United States.1252 LC_NUMERIC=C [5]
    >> >> LC_TIME=English_United States.1252
    >> >>
    >> >> attached base packages: [1] stats graphics grDevices
    >> >> utils datasets methods base
    >> >>
    >> >> other attached packages: [1] readxl_0.1.1 dplyr_0.5.0
    >> >> XLConnect_0.2-12 [4] XLConnectJars_0.2-12 ROracle_1.2-1
    >> >> DBI_0.5-1
    >> >>
    >> >> loaded via a namespace (and not attached): [1]
    >> >> magrittr_1.5 R6_2.2.0 assertthat_0.1 tools_3.3.2
    >> >> haven_1.0.0 [6] tibble_1.2 Rcpp_0.12.7 rJava_0.9-8
    >> >>
    >> >> Please advise.  Thanks,
    >> >>
    >> >> Michael Laviolette PhD MPH Public Health Statistician
    >> >> Bureau of Public Health Statistics and Informatics New
    >> >> Hampshire Division of Public Health Services 29 Hazen
    >> >> Drive Concord, NH 03301-6504 Phone: 603-271-5688 Fax:
    >> >> 603-271-7623 Email: Michael.Laviolette at dhhs.nh.gov
    >> >>
    >> >>
    >> >>
    >> >> [[alternative HTML version deleted]]
    >> >>
    >> >> ______________________________________________
    >> >> R-devel at r-project.org mailing list
    >> >> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> >>
    >> 
    >> >   [[alternative HTML version deleted]]
    >> 
    >> > ______________________________________________
    >> > R-devel at r-project.org mailing list
    >> > https://stat.ethz.ch/mailman/listinfo/r-devel
    >> 



    > -- 
    > Evan Cortens, PhD
    > Institutional Analyst - Office of Institutional Analysis
    > Mount Royal University
    > 403-440-6529

    > [[alternative HTML version deleted]]


From nakama at ki.rim.or.jp  Thu Dec  1 10:45:43 2016
From: nakama at ki.rim.or.jp (Ei-ji Nakama)
Date: Thu, 1 Dec 2016 18:45:43 +0900
Subject: [Rd] Different results for cos,sin,tan and cospi,sinpi,tanpi
In-Reply-To: <af030acd-b3fb-be11-3449-52301a46b053@stats.ox.ac.uk>
References: <CAJqeyYZ2jozkWyvpBk9m=zeunh25ciFCfJdBx10ge3hbRUV_cg@mail.gmail.com>
	<22591.57594.122801.713377@stat.math.ethz.ch>
	<22591.59795.613756.145797@stat.math.ethz.ch>
	<af030acd-b3fb-be11-3449-52301a46b053@stats.ox.ac.uk>
Message-ID: <CAJqeyYY+boNQGDOrH2uSyAg9zFGFW5WFsGEgSDWJkptED5LXdw@mail.gmail.com>

hi,

my environment...
> sessionInfo()
R version 3.3.2 (2016-10-31)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Debian GNU/Linux 8 (jessie)

locale:
 [1] LC_CTYPE=ja_JP.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=ja_JP.UTF-8        LC_COLLATE=ja_JP.UTF-8
 [5] LC_MONETARY=ja_JP.UTF-8    LC_MESSAGES=ja_JP.UTF-8
 [7] LC_PAPER=ja_JP.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=ja_JP.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

It's not a very good example...

f0<-function(x,y)exp(complex(real=x,imag=y))
f1<-function(x,y)complex(real=exp(1)^x*cos(y),imag=exp(1)^x*sin(y))
f2<-function(x,y)complex(real=exp(1)^x*cospi(y/pi),imag=exp(1)^x*sinpi(y/pi))

f0(700,1.23)
f1(700,1.23)
f2(700,1.23)

f0(700,1.23e23)
f1(700,1.23e23)
f2(700,1.23e23)

Garbage number is required.

Thank you!

2016-12-01 18:31 GMT+09:00 Prof Brian Ripley <ripley at stats.ox.ac.uk>:
> Please note that you need to report your platforms (as per the posting
> guide), as the C function starts
>
> #ifdef HAVE_COSPI
> #elif defined HAVE___COSPI
> double cospi(double x) {
>     return __cospi(x);
> }
>
> And AFAICS the system versions on Solaris and OS X behave the same way as
> R's substitute.
>
>
>
>
> On 01/12/2016 09:12, Martin Maechler wrote:
>>>>>>>
>>>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>>>     on Thu, 1 Dec 2016 09:36:10 +0100 writes:
>>
>>
>>>>>>> Ei-ji Nakama <nakama at ki.rim.or.jp>
>>>>>>>     on Thu, 1 Dec 2016 14:39:55 +0900 writes:
>>
>>
>>     >> Hi,
>>     >> i try sin, cos, and tan.
>>
>>     >>> sapply(c(cos,sin,tan),function(x,y)x(y),1.23e45*pi)
>>     >> [1] 0.5444181 0.8388140 1.5407532
>>
>>     >> However, *pi results the following
>>
>>     >>> sapply(c(cospi,sinpi,tanpi),function(x,y)x(y),1.23e45)
>>     >> [1] 1 0 0
>>
>>     >> Please try whether the following becomes all right.
>>
>>     > [..............................]
>>
>>     > Yes, it does  -- the fix will be in all future versions of R.
>>
>> oops.... not so quickly, Martin!
>>
>> Of course, the results then coincide,  by sheer implementation.
>>
>> *BUT* it is not at all clear which of the two results is better;
>> e.g., if you replace '1.23' by '1' in the above examples, the
>> result of the unchnaged  *pi() functions is 100% accurate,
>> whereas
>>
>>  R> sapply(c(cos,sin,tan), function(Fn) Fn(1e45*pi))
>>  [1] -0.8847035 -0.4661541  0.5269043
>>
>> is "garbage".  After all,  1e45 is an even integer and so, the
>> (2pi)-periodic functions should give the same as for 0  which
>> *is*  (1, 0, 0).
>>
>> For such very large arguments, the results of all of sin() ,
>> cos() and tan()  are in some sense "random garbage" by
>> necessity:
>> Such large numbers have zero information about the resolution modulo
>> [0, 2pi)  or (-pi, pi]  and hence any (non-trivial) periodic
>> function with such a "small" period can only return "random noise".
>>
>>
>>     > Thank you very much Ei-ji Nakama, for this valuable contribution
>>     > to make R better!
>>
>> That is still true!  It raises the issue to all of us and will
>> improve the documentation at least!
>>
>> At the moment, I'm not sure where we should go.
>> Of course, I could start experiments using my own 'Rmpfr'
>> package where I can (with increasing computational effort!) get
>> correct values (for increasingly larger arguments) but at the
>> moment, I don't see how this would help.
>>
>> Martin
>
>
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Emeritus Professor of Applied Statistics, University of Oxford



-- 
Best Regards,
--
Eiji NAKAMA <nakama (a) ki.rim.or.jp>
"\u4e2d\u9593\u6804\u6cbb"  <nakama (a) ki.rim.or.jp>


From kmbell56 at gmail.com  Fri Dec  2 19:45:42 2016
From: kmbell56 at gmail.com (Kenny Bell)
Date: Fri, 2 Dec 2016 10:45:42 -0800
Subject: [Rd] unlist strips date class
Message-ID: <CAPekMC=Od4ib7QJbpk8iGm9woUB4bzM+5BYq3vLqH_4u9ApXNA@mail.gmail.com>

Is this a bug?

> unlist(list(as.Date("2015-01-01")))
[1] 16436

	[[alternative HTML version deleted]]


From edd at debian.org  Fri Dec  2 19:54:25 2016
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 2 Dec 2016 12:54:25 -0600
Subject: [Rd] unlist strips date class
In-Reply-To: <CAPekMC=Od4ib7QJbpk8iGm9woUB4bzM+5BYq3vLqH_4u9ApXNA@mail.gmail.com>
References: <CAPekMC=Od4ib7QJbpk8iGm9woUB4bzM+5BYq3vLqH_4u9ApXNA@mail.gmail.com>
Message-ID: <22593.50017.30472.297070@max.nulle.part>


On 2 December 2016 at 10:45, Kenny Bell wrote:
| Is this a bug?
| 
| > unlist(list(as.Date("2015-01-01")))
| [1] 16436

Not really, it is documented.

S3 classes operate via an attribute tag, and attributes get dropped by
certain base functions. I must have hit something like the following about a
thousand times by now:

R> for (i in as.Date("2015-01-01")+ 0:2) print(i)
[1] 16436
[1] 16437
[1] 16438
R>

Live and learn.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From kmbell56 at gmail.com  Fri Dec  2 20:31:56 2016
From: kmbell56 at gmail.com (Kenny Bell)
Date: Fri, 2 Dec 2016 11:31:56 -0800
Subject: [Rd] Spam messages
Message-ID: <CAPekMC=bnLjuMDijY1nAMSLfOzDh7t54ektbV14_MsVrgLh0kg@mail.gmail.com>

Have others received spam messages after posting to this list?

The two problem emails are HodgesDonna485 at yahoo.com and
amykristen4003 at octbm.com.

	[[alternative HTML version deleted]]


From hpages at fredhutch.org  Fri Dec  2 23:13:59 2016
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Fri, 2 Dec 2016 14:13:59 -0800
Subject: [Rd] unlist strips date class
In-Reply-To: <CAPekMC=Od4ib7QJbpk8iGm9woUB4bzM+5BYq3vLqH_4u9ApXNA@mail.gmail.com>
References: <CAPekMC=Od4ib7QJbpk8iGm9woUB4bzM+5BYq3vLqH_4u9ApXNA@mail.gmail.com>
Message-ID: <84139199-8a1f-28f9-2ab0-fae8cd90976b@fredhutch.org>

Hi,

On 12/02/2016 10:45 AM, Kenny Bell wrote:
> Is this a bug?
>
>> unlist(list(as.Date("2015-01-01")))
> [1] 16436

Good question.

More generally one might reasonably expect 'unlist(x)' to be equivalent
to 'do.call(c, x)' on a list 'x' where all the list elements are atomic
vectors:

   x <- list(1:3, letters[1:2])
   unlist(x)
   # [1] "1" "2" "3" "a" "b"
   do.call(c, x)
   # [1] "1" "2" "3" "a" "b"

However, if the list contains dates:

   x <- list(as.Date("2015-01-01") + 0:2, as.Date("2016-12-02"))
   unlist(x)
   # [1] 16436 16437 16438 17137
   do.call(c, x)
   # [1] "2015-01-01" "2015-01-02" "2015-01-03" "2016-12-02"

then 'unlist(x)' drops the attributes and 'do.call(c, x)' does not.

And if the list contains factors:

   x <- list(factor("Z"), factor(c("a", "Z", "b")))
   unlist(x)
   # [1] Z a Z b
   # Levels: Z a b
   do.call(c, x)
   # [1] 1 1 3 2

then it's the other way around. Also note that the fact that the first
2 numbers in the result of 'do.call(c, x)' are the same is
confusing/misleading. Hard to see how this result could be useful
to anybody.

These inconsistencies might well be documented but hopefully they can
be addressed.

Cheers,
H.

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From pdalgd at gmail.com  Mon Dec  5 10:05:14 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 5 Dec 2016 10:05:14 +0100
Subject: [Rd] unlist strips date class
In-Reply-To: <84139199-8a1f-28f9-2ab0-fae8cd90976b@fredhutch.org>
References: <CAPekMC=Od4ib7QJbpk8iGm9woUB4bzM+5BYq3vLqH_4u9ApXNA@mail.gmail.com>
	<84139199-8a1f-28f9-2ab0-fae8cd90976b@fredhutch.org>
Message-ID: <F1791DAB-5420-480B-AC49-ADF672B28DB8@gmail.com>


On 02 Dec 2016, at 23:13 , Herv? Pag?s <hpages at fredhutch.org> wrote:

> More generally one might reasonably expect 'unlist(x)' to be equivalent
> to 'do.call(c, x)' on a list 'x' where all the list elements are atomic
> vectors:

Well, both are generic, and e.g. there is no "Date" method for unlist(), but there is for c(). It is not clear that the two should be kept in lockstep and there is certainly no mechanism to enforce that.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From nakama at ki.rim.or.jp  Mon Dec  5 14:04:02 2016
From: nakama at ki.rim.or.jp (Ei-ji Nakama)
Date: Mon, 5 Dec 2016 22:04:02 +0900
Subject: [Rd] Different results for cos,sin,tan and cospi,sinpi,tanpi
In-Reply-To: <CAJqeyYY+boNQGDOrH2uSyAg9zFGFW5WFsGEgSDWJkptED5LXdw@mail.gmail.com>
References: <CAJqeyYZ2jozkWyvpBk9m=zeunh25ciFCfJdBx10ge3hbRUV_cg@mail.gmail.com>
	<22591.57594.122801.713377@stat.math.ethz.ch>
	<22591.59795.613756.145797@stat.math.ethz.ch>
	<af030acd-b3fb-be11-3449-52301a46b053@stats.ox.ac.uk>
	<CAJqeyYY+boNQGDOrH2uSyAg9zFGFW5WFsGEgSDWJkptED5LXdw@mail.gmail.com>
Message-ID: <CAJqeyYbbwABt-Ro1eAgsY6u4d4dPcJiFPwuocCPwGn9wyNMfkg@mail.gmail.com>

hello,

i read this pdf (http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1950.pdf)
i think ... x to be integer only(more accurate value).

following test code and patch.
### F.10.1.12 The cospi functions
## cospi(+-0)                      : 1, 1
cospi(c(+0,-0))
## cospi(n + 1/2)                  : all 0
cospi((-4:4)+.5)
## cospi(+-Inf)                    : NaN
cospi(c(+Inf,-Inf))
## cospi(n)
cospi((-4:4))

### F.10.1.13 The sinpi functions
## sinpi(+-0)                      :+0,-0
sprintf("%a",sinpi(c(+0,-0)))
## sinpi(n + 1/2)                  : all 0
sinpi((-4:4))
## sinpi(+-Inf)                    : NaN
sinpi(c(+Inf,-Inf))
## sinpi(n)                        :1 -1  1 -1  1 -1  1 -1  1
sinpi((-4:4+.5))

### F.10.1.14 The tanpi functions
## tanpi(+-0)                       :+0,-0
sprintf("%a",tanpi(c(+0,-0)))
## tanpi(pos even and neg odd)      :+0
sprintf("%a",tanpi(c(-3,-1,2,4)))
## tanpi(pos odd and ned even)      :-0
sprintf("%a",tanpi(c(-4,-2,1,3)))
## tanpi(n+1/2) n = even            :+Inf
tanpi(c(1:3*2)+.5)
tanpi(c(1:3*2)*-1+.5)
## tanpi(n+1/2) n = odd             :-Inf
tanpi(c(1:3*2+1)+.5)
tanpi(c(1:3*2+1)*-1+.5)

## tanpi(+-Inf)                     :NaN NaN
tanpi(c(+Inf,-Inf))

## no integer
sinpi(1.23e23) # 0.4652223
cospi(1.23e23) # 0.8851939
tanpi(1.23e23) # 0.5255597



--- R-3.3.2.orig/src/nmath/cospi.c    2016-09-15 07:15:31.000000000 +0900
+++ R-3.3.2/src/nmath/cospi.c    2016-12-05 21:29:20.764593514 +0900
@@ -21,13 +21,10 @@
    The __cospi etc variants are from macOS (and perhaps other
BSD-based systems).
 */

-#ifdef HAVE_COSPI
-#elif defined HAVE___COSPI
-double cospi(double x) {
-    return __cospi(x);
-}
+
+#if defined(__STDC_WANT_IEC_60559_FUNCS_EXT__) &&
__STDC_WANT_IEC_60559_FUNCS_EXT__ >= 201506L
+/* use standard cospi */
 #else
-// cos(pi * x)  -- exact when x = k/2  for all integer k
 double cospi(double x) {
 #ifdef IEEE_754
     /* NaNs propagated correctly */
@@ -35,7 +32,11 @@
 #endif
     if(!R_FINITE(x)) ML_ERR_return_NAN;

-    x = fmod(fabs(x), 2.);// cos() symmetric; cos(pi(x + 2k)) ==
cos(pi x) for all integer k
+    x = fabs(x);
+    if ( x > 9007199254740991 ) /* 2^53-1 */
+        return cos(M_PI * x);
+
+    x = fmod(x, 2.);// cos() symmetric; cos(pi(x + 2k)) == cos(pi x)
for all integer k
     if(fmod(x, 1.) == 0.5) return 0.;
     if( x == 1.)    return -1.;
     if( x == 0.)    return  1.;
@@ -44,11 +45,8 @@
 }
 #endif

-#ifdef HAVE_SINPI
-#elif defined HAVE___SINPI
-double sinpi(double x) {
-    return __sinpi(x);
-}
+#if defined(__STDC_WANT_IEC_60559_FUNCS_EXT__) &&
__STDC_WANT_IEC_60559_FUNCS_EXT__ >= 201506L
+/* use standard cospi */
 #else
 // sin(pi * x)  -- exact when x = k/2  for all integer k
 double sinpi(double x) {
@@ -57,6 +55,12 @@
 #endif
     if(!R_FINITE(x)) ML_ERR_return_NAN;

+    if (( x >  9007199254740991 )||  /*  2^53-1 */
+        ( x < -9007199254740991 )  ) /* -2^53-1 */
+        return sin(M_PI * x);
+
+    if( x == 0 || x == -0 )
+        return(x);
     x = fmod(x, 2.); // sin(pi(x + 2k)) == sin(pi x)  for all integer k
     // map (-2,2) --> (-1,1] :
     if(x <= -1) x += 2.; else if (x > 1.) x -= 2.;
@@ -69,26 +73,50 @@
 #endif

 // tan(pi * x)  -- exact when x = k/2  for all integer k
-#if defined(HAVE_TANPI) || defined(HAVE___TANPI)
+#if defined(__STDC_WANT_IEC_60559_FUNCS_EXT__) &&
__STDC_WANT_IEC_60559_FUNCS_EXT__ >= 201506L
+/* use standard cospi */
 // for use in arithmetic.c, half-values documented to give NaN
-double Rtanpi(double x)
 #else
 double tanpi(double x)
-#endif
 {
+  int _sig=0;
+  int _even=0;
+  int _odd=0;
+  int _int=0;
 #ifdef IEEE_754
     if (ISNAN(x)) return x;
 #endif
     if(!R_FINITE(x)) ML_ERR_return_NAN;

-    x = fmod(x, 1.); // tan(pi(x + k)) == tan(pi x)  for all integer k
-    // map (-1,1) --> (-1/2, 1/2] :
-    if(x <= -0.5) x++; else if(x > 0.5) x--;
-    return (x == 0.) ? 0. : ((x == 0.5) ? ML_NAN : tan(M_PI * x));
+    if (( x >  9007199254740991 )||  /*  2^53-1 */
+        ( x < -9007199254740991 )  ) /* -2^53-1 */
+        return tan(M_PI * x);
+
+    if( x == 0. || x == -0. )
+        return(x);
+    if(x>0) _sig = 1;
+    if(x<0) _sig =-1;
+
+    x = fmod(x, 2.);
+    if(( x == 0.0 )||( x == -0.0)){ _even = 1; _int=1;}
+    if(( x == 0.5 )||( x == -0.5))  _even = 1;
+    if(( x == 1.0 )||( x == -1.0)){ _odd = 1;  _int=1;}
+    if(( x == 1.5 )||( x == -1.5))  _odd = 1;
+    if(_int){
+      if( _sig ==  1 && _even ) return(  0.);
+      if( _sig == -1 && _odd  ) return(  0.);
+      if( _sig ==  1 && _odd  ) return( -0.);
+      if( _sig == -1 && _even ) return( -0.);
+    }
+    if(_even){
+        if ( x ==  0.5 ) return(R_PosInf);
+    if ( x == -0.5 ) return(R_NegInf);
+    }else if (_odd){
+    if ( x ==  1.5 ) return(R_NegInf);
+    if ( x == -1.5 ) return(R_PosInf);
+    }
+    // otherwise
+    return tan(M_PI * x);
 }

-#if !defined(HAVE_TANPI) && defined(HAVE___TANPI)
-double tanpi(double x) {
-    return __tanpi(x);
-}
 #endif




2016-12-01 18:45 GMT+09:00 Ei-ji Nakama <nakama at ki.rim.or.jp>:
> hi,
>
> my environment...
>> sessionInfo()
> R version 3.3.2 (2016-10-31)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Debian GNU/Linux 8 (jessie)
>
> locale:
>  [1] LC_CTYPE=ja_JP.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=ja_JP.UTF-8        LC_COLLATE=ja_JP.UTF-8
>  [5] LC_MONETARY=ja_JP.UTF-8    LC_MESSAGES=ja_JP.UTF-8
>  [7] LC_PAPER=ja_JP.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=ja_JP.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> It's not a very good example...
>
> f0<-function(x,y)exp(complex(real=x,imag=y))
> f1<-function(x,y)complex(real=exp(1)^x*cos(y),imag=exp(1)^x*sin(y))
> f2<-function(x,y)complex(real=exp(1)^x*cospi(y/pi),imag=exp(1)^x*sinpi(y/pi))
>
> f0(700,1.23)
> f1(700,1.23)
> f2(700,1.23)
>
> f0(700,1.23e23)
> f1(700,1.23e23)
> f2(700,1.23e23)
>
> Garbage number is required.
>
> Thank you!
>
> 2016-12-01 18:31 GMT+09:00 Prof Brian Ripley <ripley at stats.ox.ac.uk>:
>> Please note that you need to report your platforms (as per the posting
>> guide), as the C function starts
>>
>> #ifdef HAVE_COSPI
>> #elif defined HAVE___COSPI
>> double cospi(double x) {
>>     return __cospi(x);
>> }
>>
>> And AFAICS the system versions on Solaris and OS X behave the same way as
>> R's substitute.
>>
>>
>>
>>
>> On 01/12/2016 09:12, Martin Maechler wrote:
>>>>>>>>
>>>>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>>>>     on Thu, 1 Dec 2016 09:36:10 +0100 writes:
>>>
>>>
>>>>>>>> Ei-ji Nakama <nakama at ki.rim.or.jp>
>>>>>>>>     on Thu, 1 Dec 2016 14:39:55 +0900 writes:
>>>
>>>
>>>     >> Hi,
>>>     >> i try sin, cos, and tan.
>>>
>>>     >>> sapply(c(cos,sin,tan),function(x,y)x(y),1.23e45*pi)
>>>     >> [1] 0.5444181 0.8388140 1.5407532
>>>
>>>     >> However, *pi results the following
>>>
>>>     >>> sapply(c(cospi,sinpi,tanpi),function(x,y)x(y),1.23e45)
>>>     >> [1] 1 0 0
>>>
>>>     >> Please try whether the following becomes all right.
>>>
>>>     > [..............................]
>>>
>>>     > Yes, it does  -- the fix will be in all future versions of R.
>>>
>>> oops.... not so quickly, Martin!
>>>
>>> Of course, the results then coincide,  by sheer implementation.
>>>
>>> *BUT* it is not at all clear which of the two results is better;
>>> e.g., if you replace '1.23' by '1' in the above examples, the
>>> result of the unchnaged  *pi() functions is 100% accurate,
>>> whereas
>>>
>>>  R> sapply(c(cos,sin,tan), function(Fn) Fn(1e45*pi))
>>>  [1] -0.8847035 -0.4661541  0.5269043
>>>
>>> is "garbage".  After all,  1e45 is an even integer and so, the
>>> (2pi)-periodic functions should give the same as for 0  which
>>> *is*  (1, 0, 0).
>>>
>>> For such very large arguments, the results of all of sin() ,
>>> cos() and tan()  are in some sense "random garbage" by
>>> necessity:
>>> Such large numbers have zero information about the resolution modulo
>>> [0, 2pi)  or (-pi, pi]  and hence any (non-trivial) periodic
>>> function with such a "small" period can only return "random noise".
>>>
>>>
>>>     > Thank you very much Ei-ji Nakama, for this valuable contribution
>>>     > to make R better!
>>>
>>> That is still true!  It raises the issue to all of us and will
>>> improve the documentation at least!
>>>
>>> At the moment, I'm not sure where we should go.
>>> Of course, I could start experiments using my own 'Rmpfr'
>>> package where I can (with increasing computational effort!) get
>>> correct values (for increasingly larger arguments) but at the
>>> moment, I don't see how this would help.
>>>
>>> Martin
>>
>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Emeritus Professor of Applied Statistics, University of Oxford
>
>
>
> --
> Best Regards,
> --
> Eiji NAKAMA <nakama (a) ki.rim.or.jp>
> "\u4e2d\u9593\u6804\u6cbb"  <nakama (a) ki.rim.or.jp>



-- 
Best Regards,
--
Eiji NAKAMA <nakama (a) ki.rim.or.jp>
"\u4e2d\u9593\u6804\u6cbb"  <nakama (a) ki.rim.or.jp>


From frederik at ofb.net  Tue Dec  6 13:37:20 2016
From: frederik at ofb.net (frederik at ofb.net)
Date: Tue, 6 Dec 2016 04:37:20 -0800
Subject: [Rd] segfault with POSIXlt zone=NULL zone=""
Message-ID: <20161206123720.GA21285@ofb.net>

Hi all,

I ran into a segfault while playing with dates.

    $ R --no-init-file
    ...
    > library(lubridate); d=as.POSIXlt(floor_date(Sys.time(),"year")); d$zone=NULL; d$zone=""; d

    Attaching package: ?lubridate?

    The following object is masked from ?package:base?:

        date

    Warning message:
    package ?lubridate? was built under R version 3.4.0 

     *** caught segfault ***
    address (nil), cause 'unknown'

    Traceback:
     1: format.POSIXlt(x, usetz = TRUE)
     2: format(x, usetz = TRUE)
     3: print(format(x, usetz = TRUE), ...)
     4: print.POSIXlt(x)
     5: function (x, ...) UseMethod("print")(x)

    Possible actions:
    ...

Hope I'm not doing something illegal...

Thanks,

Frederick


From frederik at ofb.net  Tue Dec  6 14:13:19 2016
From: frederik at ofb.net (frederik at ofb.net)
Date: Tue, 6 Dec 2016 05:13:19 -0800
Subject: [Rd] Spam messages
In-Reply-To: <CAPekMC=bnLjuMDijY1nAMSLfOzDh7t54ektbV14_MsVrgLh0kg@mail.gmail.com>
References: <CAPekMC=bnLjuMDijY1nAMSLfOzDh7t54ektbV14_MsVrgLh0kg@mail.gmail.com>
Message-ID: <20161206131319.GA21582@ofb.net>

Yes, I just heard from Amy Kristen who is "looking to meet new
guys"...

On Fri, Dec 02, 2016 at 11:31:56AM -0800, Kenny Bell wrote:
> Have others received spam messages after posting to this list?
> 
> The two problem emails are HodgesDonna485 at yahoo.com and
> amykristen4003 at octbm.com.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From frederik at ofb.net  Tue Dec  6 15:48:13 2016
From: frederik at ofb.net (frederik at ofb.net)
Date: Tue, 6 Dec 2016 06:48:13 -0800
Subject: [Rd] Spam messages
In-Reply-To: <CANMhtdzmaiG=R140x86icaGS4Hej88Y7nv0LSW3HvzTqM0xbrg@mail.gmail.com>
References: <CAPekMC=bnLjuMDijY1nAMSLfOzDh7t54ektbV14_MsVrgLh0kg@mail.gmail.com>
	<20161206131319.GA21582@ofb.net>
	<CANMhtdwRUVXqjMzjVyWtiT_XNeuVh-a2Ogcy7ekuFQm3Ro1dNA@mail.gmail.com>
	<CANMhtdzsM6-Q=dUdwRoVEfBFgBnaCaaiWcY-wjH6DRdMxtTRPw@mail.gmail.com>
	<CANMhtdzmaiG=R140x86icaGS4Hej88Y7nv0LSW3HvzTqM0xbrg@mail.gmail.com>
Message-ID: <20161206144813.GB21582@ofb.net>

> new package, R_spam

Oh, you got my hopes up!

On Tue, Dec 06, 2016 at 12:24:20PM -0200, Marcelo Perlin wrote:
> Perhpas amy needs help with her new package, R_spam,which is not working
> well with R_scam.  ??
> 
> Em 6 de dez de 2016 11:16, <frederik at ofb.net> escreveu:
> 
> Yes, I just heard from Amy Kristen who is "looking to meet new
> guys"...
> 
> On Fri, Dec 02, 2016 at 11:31:56AM -0800, Kenny Bell wrote:
> > Have others received spam messages after posting to this list?
> >
> > The two problem emails are HodgesDonna485 at yahoo.com and
> > amykristen4003 at octbm.com.
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From JARauh at web.de  Tue Dec  6 16:28:32 2016
From: JARauh at web.de (Johannes Rauh)
Date: Tue, 6 Dec 2016 16:28:32 +0100
Subject: [Rd] system2 fails with quiet=TRUE,
	but runs through with quiet=FALSE
Message-ID: <trinity-aaf3f5f8-1f55-4987-b755-b1ea583914a9-1481038112088@3capp-webde-bs03>

Hi,

I have recently tried to check the test coverage using library("covr") and, interestingly, the command

> covr::package_coverage()

fails, while

> covr::package_coverage(quiet = FALSE)

runs through without problem.  I traced the problem to a call to utils::install.packages(), where the option quiet is passed on.  In utils::install.packages(), the problem seems to lie in the following call of system2():

  output <- if (quiet)
    FALSE else ""
  [...]
  status <- system2(cmd0, args, env = env, stdout = output,
                        stderr = output)

Manually changing stdout to "" makes the program run through without error (but then the output is there again, of course...).

The function system2 seems to be a wrapper around

  .Internal(system(command, flags, f, stdout, stderr))

In this call, if quiet = TRUE, then flags <- 21, otherwise flags <- 22.  stdout and stderr are passed through from system2.

I should mention that I am working with R 3.3.1 on Windows 8.

Does anyone have an idea what the flags mean and how they can make a system call fail?

Best
Johannes


From mario at emmenlauer.de  Tue Dec  6 14:52:27 2016
From: mario at emmenlauer.de (Mario Emmenlauer)
Date: Tue, 6 Dec 2016 14:52:27 +0100
Subject: [Rd] Spam messages
In-Reply-To: <20161206131319.GA21582@ofb.net>
References: <CAPekMC=bnLjuMDijY1nAMSLfOzDh7t54ektbV14_MsVrgLh0kg@mail.gmail.com>
	<20161206131319.GA21582@ofb.net>
Message-ID: <736705db-26a5-4e2d-df67-f84c3d5f4ab4@emmenlauer.de>


The problem is not specific to this list. Any kind of public
list may mean that other subscribers (or even the whole world)
can see your email address. So whenever you mail to a (public)
list there is a good chance that afterwards, you will get more
spam. Not really much can be done about it, at least not on
the side of the list, since any of the subscribers may be a
spammer, who can know...

All the best,

    Mario



On 06.12.2016 14:13, frederik at ofb.net wrote:
> Yes, I just heard from Amy Kristen who is "looking to meet new
> guys"...
> 
> On Fri, Dec 02, 2016 at 11:31:56AM -0800, Kenny Bell wrote:
>> Have others received spam messages after posting to this list?
>>
>> The two problem emails are HodgesDonna485 at yahoo.com and
>> amykristen4003 at octbm.com.
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 



Viele Gruesse,

    Mario Emmenlauer


--
BioDataAnalysis GmbH, Mario Emmenlauer      Tel. Buero: +49-89-74677203
Balanstr. 43                   mailto: memmenlauer * biodataanalysis.de
D-81669 M?nchen                          http://www.biodataanalysis.de/


From marceloperlin at gmail.com  Tue Dec  6 15:24:20 2016
From: marceloperlin at gmail.com (Marcelo Perlin)
Date: Tue, 6 Dec 2016 12:24:20 -0200
Subject: [Rd] Spam messages
In-Reply-To: <CANMhtdzsM6-Q=dUdwRoVEfBFgBnaCaaiWcY-wjH6DRdMxtTRPw@mail.gmail.com>
References: <CAPekMC=bnLjuMDijY1nAMSLfOzDh7t54ektbV14_MsVrgLh0kg@mail.gmail.com>
	<20161206131319.GA21582@ofb.net>
	<CANMhtdwRUVXqjMzjVyWtiT_XNeuVh-a2Ogcy7ekuFQm3Ro1dNA@mail.gmail.com>
	<CANMhtdzsM6-Q=dUdwRoVEfBFgBnaCaaiWcY-wjH6DRdMxtTRPw@mail.gmail.com>
Message-ID: <CANMhtdzmaiG=R140x86icaGS4Hej88Y7nv0LSW3HvzTqM0xbrg@mail.gmail.com>

Perhpas amy needs help with her new package, R_spam,which is not working
well with R_scam.  ??

Em 6 de dez de 2016 11:16, <frederik at ofb.net> escreveu:

Yes, I just heard from Amy Kristen who is "looking to meet new
guys"...

On Fri, Dec 02, 2016 at 11:31:56AM -0800, Kenny Bell wrote:
> Have others received spam messages after posting to this list?
>
> The two problem emails are HodgesDonna485 at yahoo.com and
> amykristen4003 at octbm.com.
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Tue Dec  6 16:51:16 2016
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Tue, 6 Dec 2016 09:51:16 -0600
Subject: [Rd] segfault with POSIXlt zone=NULL zone=""
In-Reply-To: <20161206123720.GA21285@ofb.net>
References: <20161206123720.GA21285@ofb.net>
Message-ID: <CAPPM_gRX8zWeDk=jiL2=goqFhbcw12OCW0NXDbnCB9Er6hTdVA@mail.gmail.com>

On Tue, Dec 6, 2016 at 6:37 AM,  <frederik at ofb.net> wrote:
> Hi all,
>
> I ran into a segfault while playing with dates.
>
>     $ R --no-init-file
>     ...
>     > library(lubridate); d=as.POSIXlt(floor_date(Sys.time(),"year")); d$zone=NULL; d$zone=""; d
>
If you're asking about a bug in R, you should provide a *minimal*
reproducible example (i.e. one without any package dependencies).
This has nothing to do with lubridate, so you can reproduce the
behavior with:

d <- as.POSIXlt(Sys.time())
d$zone <- NULL
d$zone <- ""
d

>     Attaching package: ?lubridate?
>
>     The following object is masked from ?package:base?:
>
>         date
>
>     Warning message:
>     package ?lubridate? was built under R version 3.4.0
>
>      *** caught segfault ***
>     address (nil), cause 'unknown'
>
>     Traceback:
>      1: format.POSIXlt(x, usetz = TRUE)
>      2: format(x, usetz = TRUE)
>      3: print(format(x, usetz = TRUE), ...)
>      4: print.POSIXlt(x)
>      5: function (x, ...) UseMethod("print")(x)
>
>     Possible actions:
>     ...
>
> Hope I'm not doing something illegal...
>
You are.  You're changing the internal structure of a POSIXlt object
by re-ordering the list elements.  You should not expect a malformed
POSIXlt object to behave as if it's correctly formed.  You can see
it's malformed by comparing it's unclass()'d output.

d <- as.POSIXlt(Sys.time())
unclass(d)  # valid POSIXlt object
d$zone <- NULL
d$zone <- ""
unclass(d)  # your malformed POSIXlt object

> Thanks,
>
> Frederick
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2016 | www.rinfinance.com


From marc_schwartz at me.com  Tue Dec  6 17:02:11 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 06 Dec 2016 10:02:11 -0600
Subject: [Rd] Spam messages
In-Reply-To: <736705db-26a5-4e2d-df67-f84c3d5f4ab4@emmenlauer.de>
References: <CAPekMC=bnLjuMDijY1nAMSLfOzDh7t54ektbV14_MsVrgLh0kg@mail.gmail.com>
	<20161206131319.GA21582@ofb.net>
	<736705db-26a5-4e2d-df67-f84c3d5f4ab4@emmenlauer.de>
Message-ID: <CC2B015F-DE23-45AE-A1C8-F5B30CD28816@me.com>

Hi,

This topic has come up previously, across the R e-mail lists and the spammers need not be subscribers (but could be), but simply reasonably competent HTML scrapers.

If you look at the online archives of the R lists, for example R-Devel for this month:

    https://stat.ethz.ch/pipermail/r-devel/2016-December/thread.html <https://stat.ethz.ch/pipermail/r-devel/2016-December/thread.html>

and look at the individual posts, there is only minimal munging of e-mail addresses, which is easily overcome with basic scripting.

This is further compounded by there being a multitude of other places on the web, where actively updated archives of the R lists exist, providing additional sources of e-mail addresses for spammers.

Some of the prior discussions had considered that we might preserve only the list address in the posts sent out (as some groups do) and fully scrape the sender's e-mail address from the post when distributed and archived. However, that approach is not without it's own limitations (e.g. would make cc's and reply-all largely useless, except for off-list discussion) and so no action has been taken since this seems to be a transient issue.

Regards,

Marc Schwartz


> On Dec 6, 2016, at 7:52 AM, Mario Emmenlauer <mario at emmenlauer.de> wrote:
> 
> 
> The problem is not specific to this list. Any kind of public
> list may mean that other subscribers (or even the whole world)
> can see your email address. So whenever you mail to a (public)
> list there is a good chance that afterwards, you will get more
> spam. Not really much can be done about it, at least not on
> the side of the list, since any of the subscribers may be a
> spammer, who can know...
> 
> All the best,
> 
>    Mario
> 
> 
> 
> On 06.12.2016 14:13, frederik at ofb.net wrote:
>> Yes, I just heard from Amy Kristen who is "looking to meet new
>> guys"...
>> 
>> On Fri, Dec 02, 2016 at 11:31:56AM -0800, Kenny Bell wrote:
>>> Have others received spam messages after posting to this list?
>>> 
>>> The two problem emails are HodgesDonna485 at yahoo.com and
>>> amykristen4003 at octbm.com.
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
> 
> 
> 
> Viele Gruesse,
> 
>    Mario Emmenlauer
> 
> 
> --
> BioDataAnalysis GmbH, Mario Emmenlauer      Tel. Buero: +49-89-74677203
> Balanstr. 43                   mailto: memmenlauer * biodataanalysis.de
> D-81669 M?nchen                          http://www.biodataanalysis.de/
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


	[[alternative HTML version deleted]]


From frederik at ofb.net  Tue Dec  6 17:20:21 2016
From: frederik at ofb.net (frederik at ofb.net)
Date: Tue, 6 Dec 2016 08:20:21 -0800
Subject: [Rd] Spam messages
In-Reply-To: <CC2B015F-DE23-45AE-A1C8-F5B30CD28816@me.com>
References: <CAPekMC=bnLjuMDijY1nAMSLfOzDh7t54ektbV14_MsVrgLh0kg@mail.gmail.com>
	<20161206131319.GA21582@ofb.net>
	<736705db-26a5-4e2d-df67-f84c3d5f4ab4@emmenlauer.de>
	<CC2B015F-DE23-45AE-A1C8-F5B30CD28816@me.com>
Message-ID: <20161206162020.GA8476@ofb.net>

I agree that no action should be taken.

It's somewhat mystifying that the robot known as "Amy Kristen"
responds so quickly after my post, and with such regularity (so far
twice per hour), using perhaps several email addresses - and using the
correct "Reply-To" headers. But more mystifying is that she keeps the
same name the whole time. And lucky, I guess, because otherwise I
wouldn't know how to filter her out...

On Tue, Dec 06, 2016 at 10:02:11AM -0600, Marc Schwartz wrote:
> Hi,
> 
> This topic has come up previously, across the R e-mail lists and the spammers need not be subscribers (but could be), but simply reasonably competent HTML scrapers.
> 
> If you look at the online archives of the R lists, for example R-Devel for this month:
> 
>     https://stat.ethz.ch/pipermail/r-devel/2016-December/thread.html <https://stat.ethz.ch/pipermail/r-devel/2016-December/thread.html>
> 
> and look at the individual posts, there is only minimal munging of e-mail addresses, which is easily overcome with basic scripting.
> 
> This is further compounded by there being a multitude of other places on the web, where actively updated archives of the R lists exist, providing additional sources of e-mail addresses for spammers.
> 
> Some of the prior discussions had considered that we might preserve only the list address in the posts sent out (as some groups do) and fully scrape the sender's e-mail address from the post when distributed and archived. However, that approach is not without it's own limitations (e.g. would make cc's and reply-all largely useless, except for off-list discussion) and so no action has been taken since this seems to be a transient issue.
> 
> Regards,
> 
> Marc Schwartz
> 
> 
> > On Dec 6, 2016, at 7:52 AM, Mario Emmenlauer <mario at emmenlauer.de> wrote:
> > 
> > 
> > The problem is not specific to this list. Any kind of public
> > list may mean that other subscribers (or even the whole world)
> > can see your email address. So whenever you mail to a (public)
> > list there is a good chance that afterwards, you will get more
> > spam. Not really much can be done about it, at least not on
> > the side of the list, since any of the subscribers may be a
> > spammer, who can know...
> > 
> > All the best,
> > 
> >    Mario
> > 
> > 
> > 
> > On 06.12.2016 14:13, frederik at ofb.net wrote:
> >> Yes, I just heard from Amy Kristen who is "looking to meet new
> >> guys"...
> >> 
> >> On Fri, Dec 02, 2016 at 11:31:56AM -0800, Kenny Bell wrote:
> >>> Have others received spam messages after posting to this list?
> >>> 
> >>> The two problem emails are HodgesDonna485 at yahoo.com and
> >>> amykristen4003 at octbm.com.
> >>> 
> >>> 	[[alternative HTML version deleted]]
> >>> 
> >>> ______________________________________________
> >>> R-devel at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>> 
> >> 
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >> 
> > 
> > 
> > 
> > Viele Gruesse,
> > 
> >    Mario Emmenlauer
> > 
> > 
> > --
> > BioDataAnalysis GmbH, Mario Emmenlauer      Tel. Buero: +49-89-74677203
> > Balanstr. 43                   mailto: memmenlauer * biodataanalysis.de
> > D-81669 M?nchen                          http://www.biodataanalysis.de/
> > 
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>


From frederik at ofb.net  Tue Dec  6 17:30:36 2016
From: frederik at ofb.net (frederik at ofb.net)
Date: Tue, 6 Dec 2016 08:30:36 -0800
Subject: [Rd] segfault with POSIXlt zone=NULL zone=""
In-Reply-To: <CAPPM_gRX8zWeDk=jiL2=goqFhbcw12OCW0NXDbnCB9Er6hTdVA@mail.gmail.com>
References: <20161206123720.GA21285@ofb.net>
	<CAPPM_gRX8zWeDk=jiL2=goqFhbcw12OCW0NXDbnCB9Er6hTdVA@mail.gmail.com>
Message-ID: <20161206163036.GB8476@ofb.net>

Hi Joshua,

Thank you for minimizing my test case.

> > Hope I'm not doing something illegal...
> >
> You are.  You're changing the internal structure of a POSIXlt object
> by re-ordering the list elements.  You should not expect a malformed
> POSIXlt object to behave as if it's correctly formed.  You can see
> it's malformed by comparing it's unclass()'d output.
> 
> d <- as.POSIXlt(Sys.time())
> unclass(d)  # valid POSIXlt object
> d$zone <- NULL
> d$zone <- ""
> unclass(d)  # your malformed POSIXlt object

I don't know if these questions are not already obvious, but:

1. Is there a reasonable way to fail more elegantly when a user makes
this mistake?

2. Should we update the documentation for POSIXlt to warn people that
the optional "zone" list element must precede the optional "gmtoff"
list element, in cases where both are present?

Thanks,

Frederick


From marc_schwartz at me.com  Tue Dec  6 17:41:36 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 06 Dec 2016 10:41:36 -0600
Subject: [Rd] Spam messages
In-Reply-To: <20161206162020.GA8476@ofb.net>
References: <CAPekMC=bnLjuMDijY1nAMSLfOzDh7t54ektbV14_MsVrgLh0kg@mail.gmail.com>
	<20161206131319.GA21582@ofb.net>
	<736705db-26a5-4e2d-df67-f84c3d5f4ab4@emmenlauer.de>
	<CC2B015F-DE23-45AE-A1C8-F5B30CD28816@me.com>
	<20161206162020.GA8476@ofb.net>
Message-ID: <6BB6F393-D266-4167-A20F-07D0E214CF56@me.com>

Hi,

FWIW, I checked the R-Devel subscriber list of e-mail addresses (as Co-Admin with Martin I have access). There are presently 1,296 subscribers to individual posts and 746 to post digests on R-Devel.

Neither of the two e-mail addresses referenced below as being the sources of spam are listed as subscribers.

A Google search of those two e-mail addresses also came up empty. The "octbm.com <http://octbm.com/>" domain is legitimate, though the web site is "under construction" and the whois information shows that it was registered earlier this year by a person in Bangladesh who seems to own a large number of domains:

  http://www.domainiq.com/email?mesba.cit06 at gmail.com

There are a lot of technical ways of falsely generating those two e-mail addresses of course and an inspection of the full e-mail headers might be fruitful, although there are ways of manipulating those as well.

Regards,

Marc


> On Dec 6, 2016, at 10:20 AM, frederik at ofb.net wrote:
> 
> I agree that no action should be taken.
> 
> It's somewhat mystifying that the robot known as "Amy Kristen"
> responds so quickly after my post, and with such regularity (so far
> twice per hour), using perhaps several email addresses - and using the
> correct "Reply-To" headers. But more mystifying is that she keeps the
> same name the whole time. And lucky, I guess, because otherwise I
> wouldn't know how to filter her out...
> 
> On Tue, Dec 06, 2016 at 10:02:11AM -0600, Marc Schwartz wrote:
>> Hi,
>> 
>> This topic has come up previously, across the R e-mail lists and the spammers need not be subscribers (but could be), but simply reasonably competent HTML scrapers.
>> 
>> If you look at the online archives of the R lists, for example R-Devel for this month:
>> 
>>    https://stat.ethz.ch/pipermail/r-devel/2016-December/thread.html <https://stat.ethz.ch/pipermail/r-devel/2016-December/thread.html>
>> 
>> and look at the individual posts, there is only minimal munging of e-mail addresses, which is easily overcome with basic scripting.
>> 
>> This is further compounded by there being a multitude of other places on the web, where actively updated archives of the R lists exist, providing additional sources of e-mail addresses for spammers.
>> 
>> Some of the prior discussions had considered that we might preserve only the list address in the posts sent out (as some groups do) and fully scrape the sender's e-mail address from the post when distributed and archived. However, that approach is not without it's own limitations (e.g. would make cc's and reply-all largely useless, except for off-list discussion) and so no action has been taken since this seems to be a transient issue.
>> 
>> Regards,
>> 
>> Marc Schwartz
>> 
>> 
>>> On Dec 6, 2016, at 7:52 AM, Mario Emmenlauer <mario at emmenlauer.de> wrote:
>>> 
>>> 
>>> The problem is not specific to this list. Any kind of public
>>> list may mean that other subscribers (or even the whole world)
>>> can see your email address. So whenever you mail to a (public)
>>> list there is a good chance that afterwards, you will get more
>>> spam. Not really much can be done about it, at least not on
>>> the side of the list, since any of the subscribers may be a
>>> spammer, who can know...
>>> 
>>> All the best,
>>> 
>>>   Mario
>>> 
>>> 
>>> 
>>> On 06.12.2016 14:13, frederik at ofb.net wrote:
>>>> Yes, I just heard from Amy Kristen who is "looking to meet new
>>>> guys"...
>>>> 
>>>> On Fri, Dec 02, 2016 at 11:31:56AM -0800, Kenny Bell wrote:
>>>>> Have others received spam messages after posting to this list?
>>>>> 
>>>>> The two problem emails are HodgesDonna485 at yahoo.com and
>>>>> amykristen4003 at octbm.com.
>>>>> 
>>>>> 	[[alternative HTML version deleted]]
>>>>> 
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>> 
>>>> 
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> 
>>> 
>>> 
>>> 
>>> Viele Gruesse,
>>> 
>>>   Mario Emmenlauer
>>> 
>>> 
>>> --
>>> BioDataAnalysis GmbH, Mario Emmenlauer      Tel. Buero: +49-89-74677203
>>> Balanstr. 43                   mailto: memmenlauer * biodataanalysis.de
>>> D-81669 M?nchen                          http://www.biodataanalysis.de/
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 


	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Tue Dec  6 17:43:38 2016
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Tue, 6 Dec 2016 10:43:38 -0600
Subject: [Rd] segfault with POSIXlt zone=NULL zone=""
In-Reply-To: <20161206163036.GB8476@ofb.net>
References: <20161206123720.GA21285@ofb.net>
	<CAPPM_gRX8zWeDk=jiL2=goqFhbcw12OCW0NXDbnCB9Er6hTdVA@mail.gmail.com>
	<20161206163036.GB8476@ofb.net>
Message-ID: <CAPPM_gQk3km4C9yPs_HzbDHdbyQg0WmxK-Bk=q1a99PVk27GqQ@mail.gmail.com>

On Tue, Dec 6, 2016 at 10:30 AM,  <frederik at ofb.net> wrote:
> Hi Joshua,
>
> Thank you for minimizing my test case.
>
>> > Hope I'm not doing something illegal...
>> >
>> You are.  You're changing the internal structure of a POSIXlt object
>> by re-ordering the list elements.  You should not expect a malformed
>> POSIXlt object to behave as if it's correctly formed.  You can see
>> it's malformed by comparing it's unclass()'d output.
>>
>> d <- as.POSIXlt(Sys.time())
>> unclass(d)  # valid POSIXlt object
>> d$zone <- NULL
>> d$zone <- ""
>> unclass(d)  # your malformed POSIXlt object
>
> I don't know if these questions are not already obvious, but:
>
> 1. Is there a reasonable way to fail more elegantly when a user makes
> this mistake?
>
It's not just "this mistake".  See below.

> 2. Should we update the documentation for POSIXlt to warn people that
> the optional "zone" list element must precede the optional "gmtoff"
> list element, in cases where both are present?
>
No, because that's not the only way to create a malformed POSIXlt
object. Reordering *any* of the elements results in a segfault, and
there are probably other things you could do to the internal structure
of POSIXlt objects to cause segfaults.

Maybe update the documentation to say, "If you update the internal
structure of a POSIXlt object, you deserve whatever happens."? ;-)

> Thanks,
>
> Frederick



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2016 | www.rinfinance.com


From frederik at ofb.net  Tue Dec  6 18:27:43 2016
From: frederik at ofb.net (frederik at ofb.net)
Date: Tue, 6 Dec 2016 09:27:43 -0800
Subject: [Rd] ok to segfault with POSIXlt zone=NULL zone=""?
In-Reply-To: <20161206123720.GA21285@ofb.net>
References: <20161206123720.GA21285@ofb.net>
Message-ID: <20161206172743.GC8476@ofb.net>

Hi all,

Here's a more minimal version of my earlier bug report (thanks, Joshua
Ulrich):

d=as.POSIXlt(Sys.time()); d$zone=NULL; d$zone=""; d

I got some helpful, if glib, feedback from Joshua that the segfault
may be caused by the changing of the order of the list elements in 'd'
(representing the "internal structure" of the POSIXlt object).

He seems to think that it's OK for R to segfault - I was wondering if
someone else could lend a second opinion. My understanding is that we
should try to avoid segfaulting as a way of handling errors, if only
because they become much more difficult to debug when the R session is
forced to quit.

I don't know exactly which line is causing the bug, but looking at the
code for do_formatPOSIXlt in "src/main/datetime.c", it seems that
there would not be a huge performance penalty to add an extra sanity
check to prevent this from occurring.

Thank you,

Frederick

On Tue, Dec 06, 2016 at 04:37:20AM -0800, frederik at ofb.net wrote:
> Hi all,
> 
> I ran into a segfault while playing with dates.
> 
>     $ R --no-init-file
>     ...
>     > library(lubridate); d=as.POSIXlt(floor_date(Sys.time(),"year")); d$zone=NULL; d$zone=""; d
> 
>     Attaching package: ?lubridate?
> 
>     The following object is masked from ?package:base?:
> 
>         date
> 
>     Warning message:
>     package ?lubridate? was built under R version 3.4.0 
> 
>      *** caught segfault ***
>     address (nil), cause 'unknown'
> 
>     Traceback:
>      1: format.POSIXlt(x, usetz = TRUE)
>      2: format(x, usetz = TRUE)
>      3: print(format(x, usetz = TRUE), ...)
>      4: print.POSIXlt(x)
>      5: function (x, ...) UseMethod("print")(x)
> 
>     Possible actions:
>     ...
> 
> Hope I'm not doing something illegal...
> 
> Thanks,
> 
> Frederick
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Tue Dec  6 18:39:32 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 6 Dec 2016 12:39:32 -0500
Subject: [Rd] ok to segfault with POSIXlt zone=NULL zone=""?
In-Reply-To: <20161206172743.GC8476@ofb.net>
References: <20161206123720.GA21285@ofb.net> <20161206172743.GC8476@ofb.net>
Message-ID: <b7c7c189-0eb6-3fb2-7dfe-eabfdb2daa64@gmail.com>

I agree this is a bug; R should never segfault.  I wouldn't call it a 
high priority one, since you can avoid the problem by not messing with 
R's internal structures.

It's unlikely to get fixed unless someone posts it as a bug report to 
bugs.r-project.org (because low priority bugs reported only on mailing 
lists get forgotten).

So please post a minimal example there, possibly accompanied with a 
patch.  If you don't have an account, you can write to me privately and 
I'll set one up for you.  (We no longer allow people to create their own 
accounts because of abuse by spammers.)

Duncan Murdoch

On 06/12/2016 12:27 PM, frederik at ofb.net wrote:
> Hi all,
>
> Here's a more minimal version of my earlier bug report (thanks, Joshua
> Ulrich):
>
> d=as.POSIXlt(Sys.time()); d$zone=NULL; d$zone=""; d
>
> I got some helpful, if glib, feedback from Joshua that the segfault
> may be caused by the changing of the order of the list elements in 'd'
> (representing the "internal structure" of the POSIXlt object).
>
> He seems to think that it's OK for R to segfault - I was wondering if
> someone else could lend a second opinion. My understanding is that we
> should try to avoid segfaulting as a way of handling errors, if only
> because they become much more difficult to debug when the R session is
> forced to quit.
>
> I don't know exactly which line is causing the bug, but looking at the
> code for do_formatPOSIXlt in "src/main/datetime.c", it seems that
> there would not be a huge performance penalty to add an extra sanity
> check to prevent this from occurring.
>
> Thank you,
>
> Frederick
>
> On Tue, Dec 06, 2016 at 04:37:20AM -0800, frederik at ofb.net wrote:
>> Hi all,
>>
>> I ran into a segfault while playing with dates.
>>
>>     $ R --no-init-file
>>     ...
>>     > library(lubridate); d=as.POSIXlt(floor_date(Sys.time(),"year")); d$zone=NULL; d$zone=""; d
>>
>>     Attaching package: ?lubridate?
>>
>>     The following object is masked from ?package:base?:
>>
>>         date
>>
>>     Warning message:
>>     package ?lubridate? was built under R version 3.4.0
>>
>>      *** caught segfault ***
>>     address (nil), cause 'unknown'
>>
>>     Traceback:
>>      1: format.POSIXlt(x, usetz = TRUE)
>>      2: format(x, usetz = TRUE)
>>      3: print(format(x, usetz = TRUE), ...)
>>      4: print.POSIXlt(x)
>>      5: function (x, ...) UseMethod("print")(x)
>>
>>     Possible actions:
>>     ...
>>
>> Hope I'm not doing something illegal...
>>
>> Thanks,
>>
>> Frederick
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From maechler at stat.math.ethz.ch  Tue Dec  6 18:49:05 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 6 Dec 2016 18:49:05 +0100
Subject: [Rd] segfault with POSIXlt zone=NULL zone=""
In-Reply-To: <CAPPM_gRX8zWeDk=jiL2=goqFhbcw12OCW0NXDbnCB9Er6hTdVA@mail.gmail.com>
References: <20161206123720.GA21285@ofb.net>
	<CAPPM_gRX8zWeDk=jiL2=goqFhbcw12OCW0NXDbnCB9Er6hTdVA@mail.gmail.com>
Message-ID: <22598.64017.586103.632493@stat.math.ethz.ch>

>>>>> Joshua Ulrich <josh.m.ulrich at gmail.com>
>>>>>     on Tue, 6 Dec 2016 09:51:16 -0600 writes:

    > On Tue, Dec 6, 2016 at 6:37 AM,  <frederik at ofb.net> wrote:
    >> Hi all,
    >> 
    >> I ran into a segfault while playing with dates.
    >> 
    >> $ R --no-init-file
    >> ...
    >> > library(lubridate); d=as.POSIXlt(floor_date(Sys.time(),"year")); d$zone=NULL; d$zone=""; d
    >> 
    > If you're asking about a bug in R, you should provide a *minimal*
    > reproducible example (i.e. one without any package dependencies).
    > This has nothing to do with lubridate, so you can reproduce the
    > behavior with:

    > d <- as.POSIXlt(Sys.time())
    > d$zone <- NULL
    > d$zone <- ""
    > d

    [..........]
    
    >> Hope I'm not doing something illegal...
    >> 
    > You are.  You're changing the internal structure of a POSIXlt object
    > by re-ordering the list elements.  You should not expect a malformed
    > POSIXlt object to behave as if it's correctly formed.  You can see
    > it's malformed by comparing it's unclass()'d output.

    > d <- as.POSIXlt(Sys.time())
    > unclass(d)  # valid POSIXlt object
    > d$zone <- NULL
    > d$zone <- ""
    > unclass(d)  # your malformed POSIXlt object

Indeed, really illegal, i.e. "against the law" ... ;-)

Thank you, Joshua!

Still, if R segfaults without the user explicitly
calling .Call(), .Internal()  or similar -- as here --
we usually acknowledge there *is* a bug in R .. even if it is
only triggered by a users "illegal" messing around.

an MRE for the above, where I really only re-order the "internal" list:

d <- as.POSIXlt("2016-12-06"); dz <- d$zone; d$zone <- NULL; d$zone <- dz; f <- format(d)

>  *** caught segfault ***
> address 0x80000020, cause 'memory not mapped'

> Traceback:
>  1: format.POSIXlt(d)
>  2: format(d)

The current code is "optimized for speed" (not perfectly), and
a patch should hopefully address the C code.

Note that a smaller MRE -- which does *not* re-order, but just
invalidate the time zone is

  d <- as.POSIXlt("2016-12-06"); d$zone <- 1; f <- format(d)

------

I have now committed a "minimal" patch (to the C code) which for
the above two cases gives a sensible error rather than a
seg.fault :

  > d <- as.POSIXlt("2016-12-06"); d$zone <- 1 ; f <- format(d)
  Error in format.POSIXlt(d) : 
    invalid 'zone' component in "POSIXlt" structure

  > d <- as.POSIXlt("2016-12-06"); dz <- d$zone; d$zone <- NULL; d$zone <- dz; f <- format(d)
  Error in format.POSIXlt(d) : 
    invalid 'zone' component in "POSIXlt" structure
  > 

I guess that it should still be possible to produce a segfault
with invalid 'POSIXlt' structures though.

Martin


From spencer.graves at prodsyse.com  Tue Dec  6 18:51:10 2016
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Tue, 6 Dec 2016 11:51:10 -0600
Subject: [Rd] ok to segfault with POSIXlt zone=NULL zone=""?
In-Reply-To: <20161206172743.GC8476@ofb.net>
References: <20161206123720.GA21285@ofb.net> <20161206172743.GC8476@ofb.net>
Message-ID: <a300256e-7253-ecc8-8d68-193ce493aa68@prodsyse.com>

I got a similar result from R-Studio 1.0.44 with

 > sessionInfo()
R version 3.3.2 (2016-10-31)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X El Capitan 10.11.6

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils
[5] datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.3.2

 > d <- as.POSIXlt(Sys.time())
 > d$zone <- NULL
 > d$zone <- ""

:  "R Session Aborted.  R encountered a fatal error.  The session was 
terminated.  Start New Session".


       I got essentially the same result with R 3.3.1.  Then I installed 
3.3.2 and got the above.


       Spencer Graves


On 12/6/2016 11:27 AM, frederik at ofb.net wrote:
> Hi all,
>
> Here's a more minimal version of my earlier bug report (thanks, Joshua
> Ulrich):
>
> d=as.POSIXlt(Sys.time()); d$zone=NULL; d$zone=""; d
>
> I got some helpful, if glib, feedback from Joshua that the segfault
> may be caused by the changing of the order of the list elements in 'd'
> (representing the "internal structure" of the POSIXlt object).
>
> He seems to think that it's OK for R to segfault - I was wondering if
> someone else could lend a second opinion. My understanding is that we
> should try to avoid segfaulting as a way of handling errors, if only
> because they become much more difficult to debug when the R session is
> forced to quit.
>
> I don't know exactly which line is causing the bug, but looking at the
> code for do_formatPOSIXlt in "src/main/datetime.c", it seems that
> there would not be a huge performance penalty to add an extra sanity
> check to prevent this from occurring.
>
> Thank you,
>
> Frederick
>
> On Tue, Dec 06, 2016 at 04:37:20AM -0800, frederik at ofb.net wrote:
>> Hi all,
>>
>> I ran into a segfault while playing with dates.
>>
>>      $ R --no-init-file
>>      ...
>>      > library(lubridate); d=as.POSIXlt(floor_date(Sys.time(),"year")); d$zone=NULL; d$zone=""; d
>>
>>      Attaching package: ?lubridate?
>>
>>      The following object is masked from ?package:base?:
>>
>>          date
>>
>>      Warning message:
>>      package ?lubridate? was built under R version 3.4.0
>>
>>       *** caught segfault ***
>>      address (nil), cause 'unknown'
>>
>>      Traceback:
>>       1: format.POSIXlt(x, usetz = TRUE)
>>       2: format(x, usetz = TRUE)
>>       3: print(format(x, usetz = TRUE), ...)
>>       4: print.POSIXlt(x)
>>       5: function (x, ...) UseMethod("print")(x)
>>
>>      Possible actions:
>>      ...
>>
>> Hope I'm not doing something illegal...
>>
>> Thanks,
>>
>> Frederick
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hpages at fredhutch.org  Tue Dec  6 18:56:35 2016
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Tue, 6 Dec 2016 09:56:35 -0800
Subject: [Rd] unlist strips date class
In-Reply-To: <F1791DAB-5420-480B-AC49-ADF672B28DB8@gmail.com>
References: <CAPekMC=Od4ib7QJbpk8iGm9woUB4bzM+5BYq3vLqH_4u9ApXNA@mail.gmail.com>
	<84139199-8a1f-28f9-2ab0-fae8cd90976b@fredhutch.org>
	<F1791DAB-5420-480B-AC49-ADF672B28DB8@gmail.com>
Message-ID: <22a90bab-1f0e-b713-4366-69bad565990c@fredhutch.org>

On 12/05/2016 01:05 AM, peter dalgaard wrote:
>
> On 02 Dec 2016, at 23:13 , Herv? Pag?s <hpages at fredhutch.org> wrote:
>
>> More generally one might reasonably expect 'unlist(x)' to be equivalent
>> to 'do.call(c, x)' on a list 'x' where all the list elements are atomic
>> vectors:
>
> Well, both are generic, and e.g. there is no "Date" method for unlist(), but there is for c(). It is not clear that the two should be kept in lockstep and there is certainly no mechanism to enforce that.

If unlist() was based on c(), or c() was based on unlist(), or
unlist() and c() were sharing more code internally, then they would
naturally be kept in lockstep and you wouldn't need any mechanism to 
enforce that.

Note that the arguments of the default S3 method for c() are:

   c(..., recursive = FALSE, use.names = TRUE)

i.e. exactly the same as unlist() (except for the default value).
This suggests that implementing one on top of the other is kind of a
natural thing to do.

H.

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From frederik at ofb.net  Tue Dec  6 18:58:41 2016
From: frederik at ofb.net (frederik at ofb.net)
Date: Tue, 6 Dec 2016 09:58:41 -0800
Subject: [Rd] segfault with POSIXlt zone=NULL zone=""
In-Reply-To: <b7c7c189-0eb6-3fb2-7dfe-eabfdb2daa64@gmail.com>
	<22598.64017.586103.632493@stat.math.ethz.ch>
Message-ID: <20161206175841.GD8476@ofb.net>

Thanks for the reply, Duncan.

It looks like Martin can commit a patch faster than I can open a bug
report...

Frederick

On Tue, Dec 06, 2016 at 12:39:32PM -0500, Duncan Murdoch wrote:
> I agree this is a bug; R should never segfault.  I wouldn't call it a high
> priority one, since you can avoid the problem by not messing with R's
> internal structures.
> 
> It's unlikely to get fixed unless someone posts it as a bug report to
> bugs.r-project.org (because low priority bugs reported only on mailing lists
> get forgotten).
> 
> So please post a minimal example there, possibly accompanied with a patch.
> If you don't have an account, you can write to me privately and I'll set one
> up for you.  (We no longer allow people to create their own accounts because
> of abuse by spammers.)
> 
> Duncan Murdoch

On Tue, Dec 06, 2016 at 06:49:05PM +0100, Martin Maechler wrote:
> >>>>> Joshua Ulrich <josh.m.ulrich at gmail.com>
> >>>>>     on Tue, 6 Dec 2016 09:51:16 -0600 writes:
> 
>     > On Tue, Dec 6, 2016 at 6:37 AM,  <frederik at ofb.net> wrote:
>     >> Hi all,
>     >> 
>     >> I ran into a segfault while playing with dates.
>     >> 
>     >> $ R --no-init-file
>     >> ...
>     >> > library(lubridate); d=as.POSIXlt(floor_date(Sys.time(),"year")); d$zone=NULL; d$zone=""; d
>     >> 
>     > If you're asking about a bug in R, you should provide a *minimal*
>     > reproducible example (i.e. one without any package dependencies).
>     > This has nothing to do with lubridate, so you can reproduce the
>     > behavior with:
> 
>     > d <- as.POSIXlt(Sys.time())
>     > d$zone <- NULL
>     > d$zone <- ""
>     > d
> 
>     [..........]
>     
>     >> Hope I'm not doing something illegal...
>     >> 
>     > You are.  You're changing the internal structure of a POSIXlt object
>     > by re-ordering the list elements.  You should not expect a malformed
>     > POSIXlt object to behave as if it's correctly formed.  You can see
>     > it's malformed by comparing it's unclass()'d output.
> 
>     > d <- as.POSIXlt(Sys.time())
>     > unclass(d)  # valid POSIXlt object
>     > d$zone <- NULL
>     > d$zone <- ""
>     > unclass(d)  # your malformed POSIXlt object
> 
> Indeed, really illegal, i.e. "against the law" ... ;-)
> 
> Thank you, Joshua!
> 
> Still, if R segfaults without the user explicitly
> calling .Call(), .Internal()  or similar -- as here --
> we usually acknowledge there *is* a bug in R .. even if it is
> only triggered by a users "illegal" messing around.
> 
> an MRE for the above, where I really only re-order the "internal" list:
> 
> d <- as.POSIXlt("2016-12-06"); dz <- d$zone; d$zone <- NULL; d$zone <- dz; f <- format(d)
> 
> >  *** caught segfault ***
> > address 0x80000020, cause 'memory not mapped'
> 
> > Traceback:
> >  1: format.POSIXlt(d)
> >  2: format(d)
> 
> The current code is "optimized for speed" (not perfectly), and
> a patch should hopefully address the C code.
> 
> Note that a smaller MRE -- which does *not* re-order, but just
> invalidate the time zone is
> 
>   d <- as.POSIXlt("2016-12-06"); d$zone <- 1; f <- format(d)
> 
> ------
> 
> I have now committed a "minimal" patch (to the C code) which for
> the above two cases gives a sensible error rather than a
> seg.fault :
> 
>   > d <- as.POSIXlt("2016-12-06"); d$zone <- 1 ; f <- format(d)
>   Error in format.POSIXlt(d) : 
>     invalid 'zone' component in "POSIXlt" structure
> 
>   > d <- as.POSIXlt("2016-12-06"); dz <- d$zone; d$zone <- NULL; d$zone <- dz; f <- format(d)
>   Error in format.POSIXlt(d) : 
>     invalid 'zone' component in "POSIXlt" structure
>   > 
> 
> I guess that it should still be possible to produce a segfault
> with invalid 'POSIXlt' structures though.
> 
> Martin
>


From jon.skoien at jrc.ec.europa.eu  Wed Dec  7 11:04:04 2016
From: jon.skoien at jrc.ec.europa.eu (Jon Skoien)
Date: Wed, 07 Dec 2016 11:04:04 +0100
Subject: [Rd] Strange behavior when using progress bar (Fwd: Re: [R] The
 code itself disappears after starting to execute the for loop)
In-Reply-To: <fdd2811e-60af-e322-4e33-0c1ad5eab0ee@jrc.ec.europa.eu>
References: <54b8d998-9299-4034-be0a-9c9ad7169974@jrc.ec.europa.eu>
	<fdd2811e-60af-e322-4e33-0c1ad5eab0ee@jrc.ec.europa.eu>
Message-ID: <ec37a17e-b2ee-b1df-2490-6006f49b886c@jrc.ec.europa.eu>

I would like to ask once more if this is reproducible also for others? 
If yes, should I submit it as a bug-report?

Best,
Jon

On 11/28/2016 11:26 AM, Jon Skoien wrote:
> I first answered to the email below in r-help, but as I did not see 
> any response, and it looks like a bug/unwanted behavior, I am also 
> posting here. I have observed this in RGui, whereas it seems not to 
> happen in RStudio.
>
> Similar to OP, I sometimes have a problem with functions using the 
> progress bar. Frequently, the console is cleared after x iterations 
> when the progress bar is called in a function which is wrapped in a 
> loop. In the example below, this happened for me every ~44th 
> iteration. Interestingly, it seems that reduction of the sleep times 
> in this function increases the number of iterations before clearing. 
> In my real application, where the progress bar is used in a much 
> slower function, the console is cleared every 2-3 iteration, which 
> means that I cannot scroll back to check the output.
>
>
> testit <- function(x = sort(runif(20)), ...)
> {
>   pb <- txtProgressBar(...)
>   for(i in c(0, x, 1)) {Sys.sleep(0.2); setTxtProgressBar(pb, i)}
>   Sys.sleep(1)
>   close(pb)
> }
>
> iter = 0
> while (TRUE) {testit(style = 3); iter = iter + 1; print(paste("done", 
> iter))}
>
> Is this only a problem for a few, or is it reproducible? Any hints to
> what the problem could be, or if it can be fixed? I have seen this in 
> some versions of R, and could also reproduce in 3.3.2.
>
> Best wishes,
> Jon
>
> R version 3.3.2 (2016-10-31)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 8.1 x64 (build 9600)
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods base
>
>
>
>
> On 11/23/2016 5:22 PM, Maram SAlem wrote:
>> Thanks a lot Bert , will check out your suggestions.
>>
>> I've unchecked the buffer output option in GUI but still have the 
>> same problem.
>>
>> Thanks for your time and concern.
>>
>> Maram Salem
>>
>> Sent from my iPhone
>>
>>> On Nov 23, 2016, at 5:55 PM, Bert Gunter <bgunter.4567 at gmail.com> 
>>> wrote:
>>>
>>> In addition to Jim's comments, which you have not yet satisfactorily
>>> addressed (buffering in GUI??),
>>>
>>> 1. Show your code!
>>>
>>> 2. Show ouput of sessionInfo()
>>>
>>> 3. Upgrade to the latest R version maybe
>>>
>>> 4. Perhaps write to package maintainer (see ?maintainer) if nothing or
>>> no one helps.
>>>
>>> Cheers,
>>> Bert
>>>
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>>> On Tue, Nov 22, 2016 at 10:05 AM, Maram SAlem 
>>>> <marammagdysalem at gmail.com> wrote:
>>>> Thanks for helping Jim.
>>>>
>>>> I'm actually using the pbapply function together with the print 
>>>> function within a loop. In earlier versions, the progress bar and 
>>>> the output of the print function used to appear after each 
>>>> iteration of the loop. But with the 3.3.1. Version nothing appears, 
>>>> instead the console turns white and thecursor turns blue ( busy) 
>>>> and I know nothing about the progress of the running code.
>>>>
>>>> I just want to see the bar and the output of the print function as 
>>>> I used to, any help?
>>>>
>>>> Thanks in advance.
>>>> Maram Salem
>>>>
>>>>
>>>>
>>>> Sent from my iPhone
>>>>
>>>>> On Nov 3, 2016, at 8:30 PM, jim holtman <jholtman at gmail.com> wrote:
>>>>>
>>>>> A little more information would help.  How exactly are out 
>>>>> creating the output to the console?  Are you using 'print', 'cat' 
>>>>> or something else?  Do you have buffered output checked on the GUI 
>>>>> (you probably don't want it checked or you output will be delayed 
>>>>> till the buffer is full -- this mightbe the cause of your problem.
>>>>>
>>>>>
>>>>> Jim Holtman
>>>>> Data Munger Guru
>>>>>
>>>>> What is the problem that you are trying to solve?
>>>>> Tell me what you want to do, not how you want to do it.
>>>>>
>>>>>> On Thu, Nov 3, 2016 at 1:55 PM, Maram SAlem 
>>>>>> <marammagdysalem at gmail.com> wrote:
>>>>>> Hi all,
>>>>>>
>>>>>> I've a question concerning the R 3.3.1 version. I have a long 
>>>>>> code that I used to run on versions earlier to the 3.3.1 version, 
>>>>>> and when I copied the code to the R console, I can still see the 
>>>>>> code while the loop is executing , along with the output printed 
>>>>>> after each iteration of the loop.
>>>>>>
>>>>>> Now, on the 3.3.1 version, after I copy the code to the console, 
>>>>>> it disappears and I only see the printed output of only one 
>>>>>> iteration at a time, that is, after the first iteration the 
>>>>>> printed output disappears ( thoughit's only 6 lines, just giving 
>>>>>> me some guidance, not a long output).
>>>>>> This is causing me some problems, so I don't know if there is a 
>>>>>> general option for R that enables me to still see the code and 
>>>>>> the output of allthe iterations till the loop is over, as was the 
>>>>>> case with earlier R versions.
>>>>>>
>>>>>> I didn't include the code as it's a long one.
>>>>>>
>>>>>> Thanks a lot in advance,
>>>>>>
>>>>>> Maram
>>>>>>
>>>>>>
>>>>>> Sent from my iPhone
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide 
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide 
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Jon Olav Sk?ien
Joint Research Centre - European Commission
Institute for Space, Security & Migration
Disaster Risk Management Unit

Via E. Fermi 2749, TP 122,  I-21027 Ispra (VA), ITALY

jon.skoien at jrc.ec.europa.eu
Tel:  +39 0332 789205

Disclaimer: Views expressed in this email are those of the individual and do not necessarily represent official views of the European Commission.


From maechler at stat.math.ethz.ch  Wed Dec  7 11:58:02 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 7 Dec 2016 11:58:02 +0100
Subject: [Rd] Strange behavior when using progress bar (Fwd: Re: [R] The
 code itself disappears after starting to execute the for loop)
In-Reply-To: <ec37a17e-b2ee-b1df-2490-6006f49b886c@jrc.ec.europa.eu>
References: <54b8d998-9299-4034-be0a-9c9ad7169974@jrc.ec.europa.eu>
	<fdd2811e-60af-e322-4e33-0c1ad5eab0ee@jrc.ec.europa.eu>
	<ec37a17e-b2ee-b1df-2490-6006f49b886c@jrc.ec.europa.eu>
Message-ID: <22599.60218.182964.817869@stat.math.ethz.ch>

>>>>> Jon Skoien <jon.skoien at jrc.ec.europa.eu>
>>>>>     on Wed, 7 Dec 2016 11:04:04 +0100 writes:

    > I would like to ask once more if this is reproducible also for others? 
    > If yes, should I submit it as a bug-report?

    > Best,
    > Jon

Please  Windows users .. this is possibly only for you!

Note that I do *not* see problems on Linux (in ESS; did not try RStudio).

Please also indicate in which form you are running R.
Here it does depend if this is inside RStudio, ESS, the "Windows
GUI", the "Windows terminal", ...

Martin Maechler,
ETH Zurich


    > On 11/28/2016 11:26 AM, Jon Skoien wrote:
    >> I first answered to the email below in r-help, but as I did not see 
    >> any response, and it looks like a bug/unwanted behavior, I am also 
    >> posting here. I have observed this in RGui, whereas it seems not to 
    >> happen in RStudio.
    >> 
    >> Similar to OP, I sometimes have a problem with functions using the 
    >> progress bar. Frequently, the console is cleared after x iterations 
    >> when the progress bar is called in a function which is wrapped in a 
    >> loop. In the example below, this happened for me every ~44th 
    >> iteration. Interestingly, it seems that reduction of the sleep times 
    >> in this function increases the number of iterations before clearing. 
    >> In my real application, where the progress bar is used in a much 
    >> slower function, the console is cleared every 2-3 iteration, which 
    >> means that I cannot scroll back to check the output.

 testit <- function(x = sort(runif(20)), ...) {
   pb <- txtProgressBar(...)
   for(i in c(0, x, 1)) {Sys.sleep(0.2); setTxtProgressBar(pb, i)}
   Sys.sleep(1)
   close(pb)
 }
 
 it <- 0
 while (TRUE) {testit(style = 3); it <- it + 1; print(paste("done", it))}

    >> Is this only a problem for a few, or is it reproducible? Any hints to
    >> what the problem could be, or if it can be fixed? I have seen this in 
    >> some versions of R, and could also reproduce in 3.3.2.

"some versions of R" ... all on Windows ?

    >> 
    >> Best wishes,
    >> Jon
    >> 
    >> R version 3.3.2 (2016-10-31)
    >> Platform: x86_64-w64-mingw32/x64 (64-bit)
    >> Running under: Windows 8.1 x64 (build 9600)
    >> 
    >> locale:
    >> [1] LC_COLLATE=English_United States.1252
    >> [2] LC_CTYPE=English_United States.1252
    >> [3] LC_MONETARY=English_United States.1252
    >> [4] LC_NUMERIC=C
    >> [5] LC_TIME=English_United States.1252
    >> 
    >> attached base packages:
    >> [1] stats     graphics  grDevices utils     datasets  methods base

[.....................]

    > Jon Olav Sk?ien
    > Joint Research Centre - European Commission
    > Institute for Space, Security & Migration
    > Disaster Risk Management Unit

    > Via E. Fermi 2749, TP 122,  I-21027 Ispra (VA), ITALY

    > jon.skoien at jrc.ec.europa.eu
    > Tel:  +39 0332 789205


From jfox at mcmaster.ca  Wed Dec  7 14:59:05 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Wed, 7 Dec 2016 13:59:05 +0000
Subject: [Rd] Strange behavior when using progress bar (Fwd: Re: [R] The
 code itself disappears after starting to execute the for loop)
In-Reply-To: <22599.60218.182964.817869@stat.math.ethz.ch>
References: <54b8d998-9299-4034-be0a-9c9ad7169974@jrc.ec.europa.eu>
	<fdd2811e-60af-e322-4e33-0c1ad5eab0ee@jrc.ec.europa.eu>
	<ec37a17e-b2ee-b1df-2490-6006f49b886c@jrc.ec.europa.eu>
	<22599.60218.182964.817869@stat.math.ethz.ch>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8365A6B4A@FHSDB2D11-2.csu.mcmaster.ca>

Dear Martin and Jon,

I can reproduce this problem in the Windows GUI, where I observed it using Jon's program after 75 iterations. I didn't observe the problem in a Windows terminal or under RStudio, letting the program run for more than 200 iterations in each case.

My system and session info:

------------- snip ---------

> Sys.info()
         sysname          release          version         nodename 
       "Windows"         "10 x64"    "build 14393" "JOHN-CARBON-X1" 
         machine            login             user   effective_user 
        "x86-64"       "John Fox"       "John Fox"       "John Fox" 

> sessionInfo()
R version 3.3.2 (2016-10-31)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 14393)

locale:
[1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252   
[3] LC_MONETARY=English_Canada.1252 LC_NUMERIC=C                   
[5] LC_TIME=English_Canada.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

------------- snip ---------

I hope this helps,
 John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
Web: socserv.mcmaster.ca/jfox


> -----Original Message-----
> From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of Martin
> Maechler
> Sent: December 7, 2016 5:58 AM
> To: Jon Skoien <jon.skoien at jrc.ec.europa.eu>
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] Strange behavior when using progress bar (Fwd: Re: [R] The
> code itself disappears after starting to execute the for loop)
> 
> >>>>> Jon Skoien <jon.skoien at jrc.ec.europa.eu>
> >>>>>     on Wed, 7 Dec 2016 11:04:04 +0100 writes:
> 
>     > I would like to ask once more if this is reproducible also for others?
>     > If yes, should I submit it as a bug-report?
> 
>     > Best,
>     > Jon
> 
> Please  Windows users .. this is possibly only for you!
> 
> Note that I do *not* see problems on Linux (in ESS; did not try RStudio).
> 
> Please also indicate in which form you are running R.
> Here it does depend if this is inside RStudio, ESS, the "Windows GUI", the
> "Windows terminal", ...
> 
> Martin Maechler,
> ETH Zurich
> 
> 
>     > On 11/28/2016 11:26 AM, Jon Skoien wrote:
>     >> I first answered to the email below in r-help, but as I did not see
>     >> any response, and it looks like a bug/unwanted behavior, I am also
>     >> posting here. I have observed this in RGui, whereas it seems not to
>     >> happen in RStudio.
>     >>
>     >> Similar to OP, I sometimes have a problem with functions using the
>     >> progress bar. Frequently, the console is cleared after x iterations
>     >> when the progress bar is called in a function which is wrapped in a
>     >> loop. In the example below, this happened for me every ~44th
>     >> iteration. Interestingly, it seems that reduction of the sleep times
>     >> in this function increases the number of iterations before clearing.
>     >> In my real application, where the progress bar is used in a much
>     >> slower function, the console is cleared every 2-3 iteration, which
>     >> means that I cannot scroll back to check the output.
> 
>  testit <- function(x = sort(runif(20)), ...) {
>    pb <- txtProgressBar(...)
>    for(i in c(0, x, 1)) {Sys.sleep(0.2); setTxtProgressBar(pb, i)}
>    Sys.sleep(1)
>    close(pb)
>  }
> 
>  it <- 0
>  while (TRUE) {testit(style = 3); it <- it + 1; print(paste("done", it))}
> 
>     >> Is this only a problem for a few, or is it reproducible? Any hints to
>     >> what the problem could be, or if it can be fixed? I have seen this in
>     >> some versions of R, and could also reproduce in 3.3.2.
> 
> "some versions of R" ... all on Windows ?
> 
>     >>
>     >> Best wishes,
>     >> Jon
>     >>
>     >> R version 3.3.2 (2016-10-31)
>     >> Platform: x86_64-w64-mingw32/x64 (64-bit)
>     >> Running under: Windows 8.1 x64 (build 9600)
>     >>
>     >> locale:
>     >> [1] LC_COLLATE=English_United States.1252
>     >> [2] LC_CTYPE=English_United States.1252
>     >> [3] LC_MONETARY=English_United States.1252
>     >> [4] LC_NUMERIC=C
>     >> [5] LC_TIME=English_United States.1252
>     >>
>     >> attached base packages:
>     >> [1] stats     graphics  grDevices utils     datasets  methods base
> 
> [.....................]
> 
>     > Jon Olav Sk?ien
>     > Joint Research Centre - European Commission
>     > Institute for Space, Security & Migration
>     > Disaster Risk Management Unit
> 
>     > Via E. Fermi 2749, TP 122,  I-21027 Ispra (VA), ITALY
> 
>     > jon.skoien at jrc.ec.europa.eu
>     > Tel:  +39 0332 789205
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jon.skoien at jrc.ec.europa.eu  Wed Dec  7 15:12:00 2016
From: jon.skoien at jrc.ec.europa.eu (Jon Skoien)
Date: Wed, 07 Dec 2016 15:12:00 +0100
Subject: [Rd] Strange behavior when using progress bar (Fwd: Re: [R] The
 code itself disappears after starting to execute the for loop)
In-Reply-To: <22599.60218.182964.817869@stat.math.ethz.ch>
References: <54b8d998-9299-4034-be0a-9c9ad7169974@jrc.ec.europa.eu>
	<fdd2811e-60af-e322-4e33-0c1ad5eab0ee@jrc.ec.europa.eu>
	<ec37a17e-b2ee-b1df-2490-6006f49b886c@jrc.ec.europa.eu>
	<22599.60218.182964.817869@stat.math.ethz.ch>
Message-ID: <fdf7af16-87d7-dbea-2705-87fbbe0ec6c9@jrc.ec.europa.eu>



On 12/7/2016 11:58 AM, Martin Maechler wrote:
>>>>>> Jon Skoien <jon.skoien at jrc.ec.europa.eu>
>>>>>>      on Wed, 7 Dec 2016 11:04:04 +0100 writes:
>
>
>      >> Is this only a problem for a few, or is it reproducible? Any hints to
>      >> what the problem could be, or if it can be fixed? I have seen this in
>      >> some versions of R, and could also reproduce in 3.3.2.
>
> "some versions of R" ... all on Windows ?

Yes, I should have clarified, several versions of R, all running on the 
same Windows 8.1 computer.

Jon
>
>      >>
>      >> Best wishes,
>      >> Jon
>      >>
>      >> R version 3.3.2 (2016-10-31)
>      >> Platform: x86_64-w64-mingw32/x64 (64-bit)
>      >> Running under: Windows 8.1 x64 (build 9600)
>      >>
>      >> locale:
>      >> [1] LC_COLLATE=English_United States.1252
>      >> [2] LC_CTYPE=English_United States.1252
>      >> [3] LC_MONETARY=English_United States.1252
>      >> [4] LC_NUMERIC=C
>      >> [5] LC_TIME=English_United States.1252
>      >>
>      >> attached base packages:
>      >> [1] stats     graphics  grDevices utils     datasets  methods base
>
> [.....................]
>
>      > Jon Olav Sk?ien
>      > Joint Research Centre - European Commission
>      > Institute for Space, Security & Migration
>      > Disaster Risk Management Unit
>
>      > Via E. Fermi 2749, TP 122,  I-21027 Ispra (VA), ITALY
>
>      > jon.skoien at jrc.ec.europa.eu
>      > Tel:  +39 0332 789205
>

-- 
Jon Olav Sk?ien
Joint Research Centre - European Commission
Institute for Space, Security & Migration
Disaster Risk Management Unit

Via E. Fermi 2749, TP 122,  I-21027 Ispra (VA), ITALY

jon.skoien at jrc.ec.europa.eu
Tel:  +39 0332 789205

Disclaimer: Views expressed in this email are those of the individual and do not necessarily represent official views of the European Commission.


From dtenenba at fredhutch.org  Thu Dec  8 20:43:02 2016
From: dtenenba at fredhutch.org (Dan Tenenbaum)
Date: Thu, 8 Dec 2016 11:43:02 -0800 (PST)
Subject: [Rd] require(..., quietly=TRUE) does not suppress warning
Message-ID: <1804590771.4159744.1481226182222.JavaMail.zimbra@fredhutch.org>

Hi,

The `quietly` argument of `require` is documented as follows:

 quietly: a logical.  If ?TRUE?, no message confirming package
          attaching is printed, and most often, no errors/warnings are
          printed if package attaching fails.

However:

> require(foo, quietly=TRUE)
Warning message:
In library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE,  :
  there is no package called ?foo?

Am I misreading the docs or is R misbehaving?

> sessionInfo()
R version 3.3.2 (2016-10-31)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: macOS Sierra 10.12.1

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

Dan


From jpnolan at american.edu  Thu Dec  8 21:09:13 2016
From: jpnolan at american.edu (John P. Nolan)
Date: Thu, 8 Dec 2016 20:09:13 +0000
Subject: [Rd] wish list:  generalized apply
Message-ID: <DM2PR0601MB8110B86F5689F2B1AF7CE0FC6840@DM2PR0601MB811.namprd06.prod.outlook.com>

Dear All,

I regularly want to "apply" some function to an array in a way that the arguments to the user function depend on the index on which the apply is working.  A simple example is:

A <- array( runif(160), dim=c(5,4,8) )
x <- matrix( runif(32), nrow=4, ncol=8 ) 
b <- runif(8)
f1 <- function( A, x, b ) { sum( A %*% x ) + b } 
result <- rep(0.0,8) 
for (i in 1:8) {
  result[i] <- f1( A[,,i], x[,i] , b[i] )
}

This works, but is slow.  I'd like to be able to do something like:
    generalized.apply( A, MARGIN=3, FUN=f1, list(x=x,MARGIN=2), list(b=b,MARGIN=1) ), where the lists tell generalized.apply to pass x[,i] and b[i] to FUN in addition to A[,,i].  

Does such a generalized.apply already exist somewhere?  While I can write a C function to do a particular case, it would be nice if there was a fast, general way to do this.  

John

............................................................................................

John P. Nolan
Math/Stat Dept., American University
Gray Hall, 4400 Massachusetts Ave, NW
Washington, DC 20016-8050
Phone: 202-885-3140
E-mail:  jpnolan at american.edu
Web:   http://fs2.american.edu/jpnolan/www/


From jpnolan at american.edu  Thu Dec  8 21:37:02 2016
From: jpnolan at american.edu (John P. Nolan)
Date: Thu, 8 Dec 2016 20:37:02 +0000
Subject: [Rd] require(..., quietly=TRUE) does not suppress warning
In-Reply-To: <1804590771.4159744.1481226182222.JavaMail.zimbra@fredhutch.org>
References: <1804590771.4159744.1481226182222.JavaMail.zimbra@fredhutch.org>
Message-ID: <DM2PR0601MB8114F4AC698C3C0F291AA68C6840@DM2PR0601MB811.namprd06.prod.outlook.com>

Well, it says "most often" no errors/warnings are given, so it is not contradicting the docs!   It looks like the person/team that coded  require( ) decided you should get an error when the package doesn't exist.

If you want a silent loading, consider
     aaa <- try( library(foo,verbose=FALSE,quietly=TRUE),silent=TRUE)
and then check to see if aaa is of class "try-error" and check for failure

John
??????????????????????????????..

John P. Nolan
Math/Stat Dept., American University
Gray Hall, 4400 Massachusetts Ave, NW
Washington, DC 20016-8050
Phone: 202-885-3140
E-mail:  jpnolan at american.edu
Web:   http://fs2.american.edu/jpnolan/www/



-----Original Message----
From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of Dan Tenenbaum
Sent: Thursday, December 8, 2016 2:43 PM
To: R-devel <r-devel at r-project.org>
Subject: [Rd] require(..., quietly=TRUE) does not suppress warning

Hi,

The `quietly` argument of `require` is documented as follows:

 quietly: a logical.  If ?TRUE?, no message confirming package
          attaching is printed, and most often, no errors/warnings are
          printed if package attaching fails.

However:

> require(foo, quietly=TRUE)
Warning message:
In library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE,  :
  there is no package called ?foo?

Am I misreading the docs or is R misbehaving?

> sessionInfo()
R version 3.3.2 (2016-10-31)
Platform: x86_64-apple-darwin13.4.0 (64-bit) Running under: macOS Sierra 10.12.1

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

Dan

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

From dtenenba at fredhutch.org  Thu Dec  8 21:51:32 2016
From: dtenenba at fredhutch.org (Dan Tenenbaum)
Date: Thu, 8 Dec 2016 12:51:32 -0800 (PST)
Subject: [Rd] require(..., quietly=TRUE) does not suppress warning
In-Reply-To: <DM2PR0601MB8114F4AC698C3C0F291AA68C6840@DM2PR0601MB811.namprd06.prod.outlook.com>
References: <1804590771.4159744.1481226182222.JavaMail.zimbra@fredhutch.org>
	<DM2PR0601MB8114F4AC698C3C0F291AA68C6840@DM2PR0601MB811.namprd06.prod.outlook.com>
Message-ID: <1410984607.4160978.1481230292736.JavaMail.zimbra@fredhutch.org>

Well, I'm getting a warning (not an error) when the package doesn't exist.
I interpreted "most often" to mean that suppressing warnings/errors is why you'd most often use this argument, as most packages don't emit startup messages. 

And technically there isn't a problem with attaching the package, since we don't even try to attach packages that don't exist.

So yes, very careful parsing of the docs suggests that the behavior is correct, but it does seem to violate the 'spirit' of what a user might expect. I am pretty sure I have used the 'if (!require("pkg")) install.packages("pkg")' pattern before without seeing this warning, so I wondered if the behavior had changed, and that's what prompted me to write.

I know I can squelch the warning by wrapping the require() in suppressWarnings(). 

Dan


----- Original Message -----
> From: "John P. Nolan" <jpnolan at american.edu>
> To: "Dan Tenenbaum" <dtenenba at fredhutch.org>, "R-devel" <r-devel at r-project.org>
> Sent: Thursday, December 8, 2016 12:37:02 PM
> Subject: RE: require(..., quietly=TRUE) does not suppress warning

> Well, it says "most often" no errors/warnings are given, so it is not
> contradicting the docs!   It looks like the person/team that coded  require( )
> decided you should get an error when the package doesn't exist.
> 
> If you want a silent loading, consider
>     aaa <- try( library(foo,verbose=FALSE,quietly=TRUE),silent=TRUE)
> and then check to see if aaa is of class "try-error" and check for failure
> 
> John
> ??????????????????????????????..
> 
> John P. Nolan
> Math/Stat Dept., American University
> Gray Hall, 4400 Massachusetts Ave, NW
> Washington, DC 20016-8050
> Phone: 202-885-3140
> E-mail:  jpnolan at american.edu
> Web:   http://fs2.american.edu/jpnolan/www/
> 
> 
> 
> -----Original Message----
> From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of Dan Tenenbaum
> Sent: Thursday, December 8, 2016 2:43 PM
> To: R-devel <r-devel at r-project.org>
> Subject: [Rd] require(..., quietly=TRUE) does not suppress warning
> 
> Hi,
> 
> The `quietly` argument of `require` is documented as follows:
> 
> quietly: a logical.  If ?TRUE?, no message confirming package
>          attaching is printed, and most often, no errors/warnings are
>          printed if package attaching fails.
> 
> However:
> 
>> require(foo, quietly=TRUE)
> Warning message:
> In library(package, lib.loc = lib.loc, character.only = TRUE, logical.return =
> TRUE,  :
>  there is no package called ?foo?
> 
> Am I misreading the docs or is R misbehaving?
> 
>> sessionInfo()
> R version 3.3.2 (2016-10-31)
> Platform: x86_64-apple-darwin13.4.0 (64-bit) Running under: macOS Sierra 10.12.1
> 
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> Dan
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From kevinushey at gmail.com  Thu Dec  8 22:52:39 2016
From: kevinushey at gmail.com (Kevin Ushey)
Date: Thu, 8 Dec 2016 13:52:39 -0800
Subject: [Rd] require(..., quietly=TRUE) does not suppress warning
In-Reply-To: <1410984607.4160978.1481230292736.JavaMail.zimbra@fredhutch.org>
References: <1804590771.4159744.1481226182222.JavaMail.zimbra@fredhutch.org>
	<DM2PR0601MB8114F4AC698C3C0F291AA68C6840@DM2PR0601MB811.namprd06.prod.outlook.com>
	<1410984607.4160978.1481230292736.JavaMail.zimbra@fredhutch.org>
Message-ID: <CAJXgQP3HLRuWPGtZAXUOW-ohNzQmPScNizJN2xZ-RGZKmTsyDw@mail.gmail.com>

IMHO the strongest argument for suppressing the warning message here is the
fact that

    requireNamespace("foo", quietly = TRUE)

does not emit any warning message when the package 'foo' does not exist.

On Thu, Dec 8, 2016 at 12:51 PM, Dan Tenenbaum <dtenenba at fredhutch.org>
wrote:

> Well, I'm getting a warning (not an error) when the package doesn't exist.
> I interpreted "most often" to mean that suppressing warnings/errors is why
> you'd most often use this argument, as most packages don't emit startup
> messages.
>
> And technically there isn't a problem with attaching the package, since we
> don't even try to attach packages that don't exist.
>
> So yes, very careful parsing of the docs suggests that the behavior is
> correct, but it does seem to violate the 'spirit' of what a user might
> expect. I am pretty sure I have used the 'if (!require("pkg"))
> install.packages("pkg")' pattern before without seeing this warning, so I
> wondered if the behavior had changed, and that's what prompted me to write.
>
> I know I can squelch the warning by wrapping the require() in
> suppressWarnings().
>
> Dan
>
>
> ----- Original Message -----
> > From: "John P. Nolan" <jpnolan at american.edu>
> > To: "Dan Tenenbaum" <dtenenba at fredhutch.org>, "R-devel" <
> r-devel at r-project.org>
> > Sent: Thursday, December 8, 2016 12:37:02 PM
> > Subject: RE: require(..., quietly=TRUE) does not suppress warning
>
> > Well, it says "most often" no errors/warnings are given, so it is not
> > contradicting the docs!   It looks like the person/team that coded
> require( )
> > decided you should get an error when the package doesn't exist.
> >
> > If you want a silent loading, consider
> >     aaa <- try( library(foo,verbose=FALSE,quietly=TRUE),silent=TRUE)
> > and then check to see if aaa is of class "try-error" and check for
> failure
> >
> > John
> > ??????????????????????????????..
> >
> > John P. Nolan
> > Math/Stat Dept., American University
> > Gray Hall, 4400 Massachusetts Ave, NW
> > Washington, DC 20016-8050
> > Phone: 202-885-3140
> > E-mail:  jpnolan at american.edu
> > Web:   http://fs2.american.edu/jpnolan/www/
> >
> >
> >
> > -----Original Message----
> > From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of Dan
> Tenenbaum
> > Sent: Thursday, December 8, 2016 2:43 PM
> > To: R-devel <r-devel at r-project.org>
> > Subject: [Rd] require(..., quietly=TRUE) does not suppress warning
> >
> > Hi,
> >
> > The `quietly` argument of `require` is documented as follows:
> >
> > quietly: a logical.  If ?TRUE?, no message confirming package
> >          attaching is printed, and most often, no errors/warnings are
> >          printed if package attaching fails.
> >
> > However:
> >
> >> require(foo, quietly=TRUE)
> > Warning message:
> > In library(package, lib.loc = lib.loc, character.only = TRUE,
> logical.return =
> > TRUE,  :
> >  there is no package called ?foo?
> >
> > Am I misreading the docs or is R misbehaving?
> >
> >> sessionInfo()
> > R version 3.3.2 (2016-10-31)
> > Platform: x86_64-apple-darwin13.4.0 (64-bit) Running under: macOS Sierra
> 10.12.1
> >
> > locale:
> > [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > Dan
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Dec  8 22:59:20 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 8 Dec 2016 13:59:20 -0800
Subject: [Rd] wish list:  generalized apply
In-Reply-To: <DM2PR0601MB8110B86F5689F2B1AF7CE0FC6840@DM2PR0601MB811.namprd06.prod.outlook.com>
References: <DM2PR0601MB8110B86F5689F2B1AF7CE0FC6840@DM2PR0601MB811.namprd06.prod.outlook.com>
Message-ID: <8A85542C-24AF-47ED-AFB9-AE4EAB3CF32C@comcast.net>


> On Dec 8, 2016, at 12:09 PM, John P. Nolan <jpnolan at american.edu> wrote:
> 
> Dear All,
> 
> I regularly want to "apply" some function to an array in a way that the arguments to the user function depend on the index on which the apply is working.  A simple example is:
> 
> A <- array( runif(160), dim=c(5,4,8) )
> x <- matrix( runif(32), nrow=4, ncol=8 ) 
> b <- runif(8)
> f1 <- function( A, x, b ) { sum( A %*% x ) + b } 
> result <- rep(0.0,8) 
> for (i in 1:8) {
>  result[i] <- f1( A[,,i], x[,i] , b[i] )
> }
> 
> This works, but is slow.  I'd like to be able to do something like:
>    generalized.apply( A, MARGIN=3, FUN=f1, list(x=x,MARGIN=2), list(b=b,MARGIN=1) ), where the lists tell generalized.apply to pass x[,i] and b[i] to FUN in addition to A[,,i].  
> 
> Does such a generalized.apply already exist somewhere?  While I can write a C function to do a particular case, it would be nice if there was a fast, general way to do this.  

I would have thought that this would achieve the same result:

result <- sapply( seq_along(b) , function(i) { f1( A[,,i], x[,i] , b[i] )} )

Or: 

result <- sapply( seq.int( dim(A)[3] ) , function(i) { f1( A[,,i], x[,i] , b[i] )} )

(I doubt it will be any faster, but if 'i' is large, parallelism might help. The inner function appears to be fairly efficient.)
-- 

David Winsemius
Alameda, CA, USA


From frederik at ofb.net  Thu Dec  8 23:16:10 2016
From: frederik at ofb.net (frederik at ofb.net)
Date: Thu, 8 Dec 2016 14:16:10 -0800
Subject: [Rd] methods(`|`) lists all functions?
Message-ID: <20161208221610.GJ6368@ofb.net>

Dear R-Devel,

I was attempting an exercise in Hadley Wickam's book "Advanced R". The
exercise is to find the generic with the greatest number of methods.

I found that 'methods(`|`)' produces a list of length 2506, in R
3.3.1. Similar behavior is found in 3.4.0. It seems to include all
functions and methods. I imagine something is being passed to "grep"
without being escaped.

I hope I didn't miss something in the documentation, and that I'm good
to report this as a bug. I can send it to Bugzilla if that's better.

By the way, how do I produce such a list of functions (or variables)
in a "normal" way? I used 'ls("package:base")' for the exercise,
because I saw this call used somewhere as an example, but I couldn't
find that "package:" syntax documented under ls()... Also found this
confusing:

    > environmentName(globalenv())
    [1] "R_GlobalEnv"
    > ls("R_GlobalEnv")
    Error in as.environment(pos) :
      no item called "R_GlobalEnv" on the search list

So I'm not sure if "package:base" is naming an environment, or if
there are different ways to name environments and ls() is using one
form while environmentName is returning another ... It might be good
to add some clarifying examples under "?ls".

Thanks,

Frederick


From frederik at ofb.net  Thu Dec  8 23:19:49 2016
From: frederik at ofb.net (frederik at ofb.net)
Date: Thu, 8 Dec 2016 14:19:49 -0800
Subject: [Rd] getGraphicsEvent() alternative for cairo graphics device?
In-Reply-To: <2e6f0306-da86-211a-05dd-aff3d744df40@stat.auckland.ac.nz>
References: <CAN_GHySs42vK5U1xZYP8h7ZPdFyOcHnEZK4Sn91e7htv=7E54A@mail.gmail.com>
	<20160725191747.GB18530@ofb.net>
	<57968357.2030509@stat.auckland.ac.nz>
	<20161112200028.GD24681@ofb.net>
	<2e6f0306-da86-211a-05dd-aff3d744df40@stat.auckland.ac.nz>
Message-ID: <20161208221949.GK6368@ofb.net>

Hi Paul,

Thanks for your efforts. Do you have an idea when my patch(es) might
be committed? Is there anything I can do to help move this along?

Thanks,

Frederick

On Mon, Nov 14, 2016 at 08:55:20AM +1300, Paul Murrell wrote:
> Hi
> 
> The current status is that I am keen for people to contribute some testing
> code (see https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16951)
> 
> There were also some getGraphicsEvent() changes/fixes suggested by Richard
> Bodewits (cc'ed), for which I am also seeking test code.
> 
> Paul
> 
> On 13/11/16 09:00, frederik at ofb.net wrote:
> > Hi Paul,
> > 
> > Just checking in to see what the status is.
> > 
> > From my perspective it seems logical to split off X11 into a separate
> > package, so development can proceed at a reasonable rate, but I
> > haven't yet tried to see if that's even possible.
> > 
> > Thanks,
> > 
> > Frederick
> > 
> > On Tue, Jul 26, 2016 at 09:23:35AM +1200, Paul Murrell wrote:
> > > Hi
> > > 
> > > Taking a look at those patches is now on my todo list, so I may be in touch
> > > with both of you at some point to request some testing.
> > > 
> > > Paul
> > > 
> > > On 26/07/16 07:17, frederik at ofb.net wrote:
> > > > Dear Daniel Greenidge,
> > > > 
> > > > To enable getGraphicsEvent on Cairo, you have two patches to choose
> > > > from:
> > > > 
> > > > https://bugs.r-project.org/bugzilla/show_bug.cgi?id=14364
> > > > https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16951
> > > > 
> > > > The second one is by me, and the first one is from five years ago by
> > > > Hugo Mildenberger.
> > > > 
> > > > Both patches are very simple, they move some lines enabling
> > > > getGrahpicsEvent outside of a if(!cairo) statement. My patch also adds
> > > > the ability to execute code (e.g. for animation) while the interface
> > > > is idle.
> > > > 
> > > > Top guy Duncan Murdoch has expressed that he doesn't have time to work
> > > > on applying these patches, and I haven't had any responses from the
> > > > rest of the R Core Team. I was thinking that perhaps your best bet is
> > > > to try to create a package called e.g. "X11-fixes" which people can
> > > > use to get a better X11 library (there is also a bug waiting to be
> > > > fixed from 2001:
> > > > https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16702).
> > > > 
> > > > I don't know if CRAN would accept such a package, or if you'd have to
> > > > distribute it via GitHub, but R has excellent tools to facilitate the
> > > > distribution of code via packages. Whether the R kernel exports enough
> > > > functions to allow a package to take over event handling, I'm not
> > > > sure. I was intending to look more into the details of this
> > > > possibility but haven't had time.
> > > > 
> > > > Best wishes,
> > > > 
> > > > Frederick
> > > > 
> > > > On Mon, Jul 25, 2016 at 02:15:59PM -0400, Daniel Greenidge wrote:
> > > > > Hi all,
> > > > > 
> > > > > I'm writing an interactive plotting function for viewing fMRI
> > > > > datasets. Currently, I get keypresses using
> > > > > grDevices::getGraphicsEvent().
> > > > > 
> > > > > Unfortunately getGraphicsEvent() only supports the X11(type="Xlib")
> > > > > graphics device on Unix systems. The Xlib device doesn't support
> > > > > buffering (i.e. dev.hold() and dev.flush()), so redrawing the plots
> > > > > causes lots of flickering.
> > > > > 
> > > > > Is there a way to get keypresses while using the cairo graphics
> > > > > device? Alternatively, is there a way to prevent flickering with the
> > > > > Xlib graphics device?
> > > > > 
> > > > > Best,
> > > > > Daniel Greenidge
> > > > > 
> > > > > ______________________________________________
> > > > > R-devel at r-project.org mailing list
> > > > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > > > > 
> > > > 
> > > > ______________________________________________
> > > > R-devel at r-project.org mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > > > 
> > > 
> > > --
> > > Dr Paul Murrell
> > > Department of Statistics
> > > The University of Auckland
> > > Private Bag 92019
> > > Auckland
> > > New Zealand
> > > 64 9 3737599 x85392
> > > paul at stat.auckland.ac.nz
> > > http://www.stat.auckland.ac.nz/~paul/
> > > 
> 
> -- 
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/
>


From paul at stat.auckland.ac.nz  Fri Dec  9 00:01:55 2016
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Fri, 9 Dec 2016 12:01:55 +1300
Subject: [Rd] getGraphicsEvent() alternative for cairo graphics device?
In-Reply-To: <20161208221949.GK6368@ofb.net>
References: <CAN_GHySs42vK5U1xZYP8h7ZPdFyOcHnEZK4Sn91e7htv=7E54A@mail.gmail.com>
	<20160725191747.GB18530@ofb.net> <57968357.2030509@stat.auckland.ac.nz>
	<20161112200028.GD24681@ofb.net>
	<2e6f0306-da86-211a-05dd-aff3d744df40@stat.auckland.ac.nz>
	<20161208221949.GK6368@ofb.net>
Message-ID: <148093cd-8556-a56e-0e2e-e799bab3ed4d@stat.auckland.ac.nz>

Hi

Just taking a bit more of a look at this today (currently fixated on 
making sure I can build some good regression tests).

The best thing you can do is to keep reminding me like this :)

Paul

On 09/12/16 11:19, frederik at ofb.net wrote:
> Hi Paul,
>
> Thanks for your efforts. Do you have an idea when my patch(es) might
> be committed? Is there anything I can do to help move this along?
>
> Thanks,
>
> Frederick
>
> On Mon, Nov 14, 2016 at 08:55:20AM +1300, Paul Murrell wrote:
>> Hi
>>
>> The current status is that I am keen for people to contribute some testing
>> code (see https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16951)
>>
>> There were also some getGraphicsEvent() changes/fixes suggested by Richard
>> Bodewits (cc'ed), for which I am also seeking test code.
>>
>> Paul
>>
>> On 13/11/16 09:00, frederik at ofb.net wrote:
>>> Hi Paul,
>>>
>>> Just checking in to see what the status is.
>>>
>>> From my perspective it seems logical to split off X11 into a separate
>>> package, so development can proceed at a reasonable rate, but I
>>> haven't yet tried to see if that's even possible.
>>>
>>> Thanks,
>>>
>>> Frederick
>>>
>>> On Tue, Jul 26, 2016 at 09:23:35AM +1200, Paul Murrell wrote:
>>>> Hi
>>>>
>>>> Taking a look at those patches is now on my todo list, so I may be in touch
>>>> with both of you at some point to request some testing.
>>>>
>>>> Paul
>>>>
>>>> On 26/07/16 07:17, frederik at ofb.net wrote:
>>>>> Dear Daniel Greenidge,
>>>>>
>>>>> To enable getGraphicsEvent on Cairo, you have two patches to choose
>>>>> from:
>>>>>
>>>>> https://bugs.r-project.org/bugzilla/show_bug.cgi?id=14364
>>>>> https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16951
>>>>>
>>>>> The second one is by me, and the first one is from five years ago by
>>>>> Hugo Mildenberger.
>>>>>
>>>>> Both patches are very simple, they move some lines enabling
>>>>> getGrahpicsEvent outside of a if(!cairo) statement. My patch also adds
>>>>> the ability to execute code (e.g. for animation) while the interface
>>>>> is idle.
>>>>>
>>>>> Top guy Duncan Murdoch has expressed that he doesn't have time to work
>>>>> on applying these patches, and I haven't had any responses from the
>>>>> rest of the R Core Team. I was thinking that perhaps your best bet is
>>>>> to try to create a package called e.g. "X11-fixes" which people can
>>>>> use to get a better X11 library (there is also a bug waiting to be
>>>>> fixed from 2001:
>>>>> https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16702).
>>>>>
>>>>> I don't know if CRAN would accept such a package, or if you'd have to
>>>>> distribute it via GitHub, but R has excellent tools to facilitate the
>>>>> distribution of code via packages. Whether the R kernel exports enough
>>>>> functions to allow a package to take over event handling, I'm not
>>>>> sure. I was intending to look more into the details of this
>>>>> possibility but haven't had time.
>>>>>
>>>>> Best wishes,
>>>>>
>>>>> Frederick
>>>>>
>>>>> On Mon, Jul 25, 2016 at 02:15:59PM -0400, Daniel Greenidge wrote:
>>>>>> Hi all,
>>>>>>
>>>>>> I'm writing an interactive plotting function for viewing fMRI
>>>>>> datasets. Currently, I get keypresses using
>>>>>> grDevices::getGraphicsEvent().
>>>>>>
>>>>>> Unfortunately getGraphicsEvent() only supports the X11(type="Xlib")
>>>>>> graphics device on Unix systems. The Xlib device doesn't support
>>>>>> buffering (i.e. dev.hold() and dev.flush()), so redrawing the plots
>>>>>> causes lots of flickering.
>>>>>>
>>>>>> Is there a way to get keypresses while using the cairo graphics
>>>>>> device? Alternatively, is there a way to prevent flickering with the
>>>>>> Xlib graphics device?
>>>>>>
>>>>>> Best,
>>>>>> Daniel Greenidge
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>>
>>>> --
>>>> Dr Paul Murrell
>>>> Department of Statistics
>>>> The University of Auckland
>>>> Private Bag 92019
>>>> Auckland
>>>> New Zealand
>>>> 64 9 3737599 x85392
>>>> paul at stat.auckland.ac.nz
>>>> http://www.stat.auckland.ac.nz/~paul/
>>>>
>>
>> --
>> Dr Paul Murrell
>> Department of Statistics
>> The University of Auckland
>> Private Bag 92019
>> Auckland
>> New Zealand
>> 64 9 3737599 x85392
>> paul at stat.auckland.ac.nz
>> http://www.stat.auckland.ac.nz/~paul/
>>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From frederik at ofb.net  Fri Dec  9 00:58:59 2016
From: frederik at ofb.net (frederik at ofb.net)
Date: Thu, 8 Dec 2016 15:58:59 -0800
Subject: [Rd] getGraphicsEvent() alternative for cairo graphics device?
In-Reply-To: <148093cd-8556-a56e-0e2e-e799bab3ed4d@stat.auckland.ac.nz>
References: <CAN_GHySs42vK5U1xZYP8h7ZPdFyOcHnEZK4Sn91e7htv=7E54A@mail.gmail.com>
	<20160725191747.GB18530@ofb.net>
	<57968357.2030509@stat.auckland.ac.nz>
	<20161112200028.GD24681@ofb.net>
	<2e6f0306-da86-211a-05dd-aff3d744df40@stat.auckland.ac.nz>
	<20161208221949.GK6368@ofb.net>
	<148093cd-8556-a56e-0e2e-e799bab3ed4d@stat.auckland.ac.nz>
Message-ID: <20161208235859.GM6368@ofb.net>

Hi Paul,

Thanks for keeping me posted and letting me know what I should do.

Are there regression tests for other graphics functions in R? To me
that sounds a bit unnecessary. I think you get more testing from
people who use R; and having a good turnaround for applying patches
(some have been waiting 5 years) would invite better participation.

Thank you,

Frederick

On Fri, Dec 09, 2016 at 12:01:55PM +1300, Paul Murrell wrote:
> Hi
> 
> Just taking a bit more of a look at this today (currently fixated on making
> sure I can build some good regression tests).
> 
> The best thing you can do is to keep reminding me like this :)
> 
> Paul
> 
> On 09/12/16 11:19, frederik at ofb.net wrote:
> > Hi Paul,
> > 
> > Thanks for your efforts. Do you have an idea when my patch(es) might
> > be committed? Is there anything I can do to help move this along?
> > 
> > Thanks,
> > 
> > Frederick
> > 
> > On Mon, Nov 14, 2016 at 08:55:20AM +1300, Paul Murrell wrote:
> > > Hi
> > > 
> > > The current status is that I am keen for people to contribute some testing
> > > code (see https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16951)
> > > 
> > > There were also some getGraphicsEvent() changes/fixes suggested by Richard
> > > Bodewits (cc'ed), for which I am also seeking test code.
> > > 
> > > Paul
> > > 
> > > On 13/11/16 09:00, frederik at ofb.net wrote:
> > > > Hi Paul,
> > > > 
> > > > Just checking in to see what the status is.
> > > > 
> > > > From my perspective it seems logical to split off X11 into a separate
> > > > package, so development can proceed at a reasonable rate, but I
> > > > haven't yet tried to see if that's even possible.
> > > > 
> > > > Thanks,
> > > > 
> > > > Frederick
> > > > 
> > > > On Tue, Jul 26, 2016 at 09:23:35AM +1200, Paul Murrell wrote:
> > > > > Hi
> > > > > 
> > > > > Taking a look at those patches is now on my todo list, so I may be in touch
> > > > > with both of you at some point to request some testing.
> > > > > 
> > > > > Paul
> > > > > 
> > > > > On 26/07/16 07:17, frederik at ofb.net wrote:
> > > > > > Dear Daniel Greenidge,
> > > > > > 
> > > > > > To enable getGraphicsEvent on Cairo, you have two patches to choose
> > > > > > from:
> > > > > > 
> > > > > > https://bugs.r-project.org/bugzilla/show_bug.cgi?id=14364
> > > > > > https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16951
> > > > > > 
> > > > > > The second one is by me, and the first one is from five years ago by
> > > > > > Hugo Mildenberger.
> > > > > > 
> > > > > > Both patches are very simple, they move some lines enabling
> > > > > > getGrahpicsEvent outside of a if(!cairo) statement. My patch also adds
> > > > > > the ability to execute code (e.g. for animation) while the interface
> > > > > > is idle.
> > > > > > 
> > > > > > Top guy Duncan Murdoch has expressed that he doesn't have time to work
> > > > > > on applying these patches, and I haven't had any responses from the
> > > > > > rest of the R Core Team. I was thinking that perhaps your best bet is
> > > > > > to try to create a package called e.g. "X11-fixes" which people can
> > > > > > use to get a better X11 library (there is also a bug waiting to be
> > > > > > fixed from 2001:
> > > > > > https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16702).
> > > > > > 
> > > > > > I don't know if CRAN would accept such a package, or if you'd have to
> > > > > > distribute it via GitHub, but R has excellent tools to facilitate the
> > > > > > distribution of code via packages. Whether the R kernel exports enough
> > > > > > functions to allow a package to take over event handling, I'm not
> > > > > > sure. I was intending to look more into the details of this
> > > > > > possibility but haven't had time.
> > > > > > 
> > > > > > Best wishes,
> > > > > > 
> > > > > > Frederick
> > > > > > 
> > > > > > On Mon, Jul 25, 2016 at 02:15:59PM -0400, Daniel Greenidge wrote:
> > > > > > > Hi all,
> > > > > > > 
> > > > > > > I'm writing an interactive plotting function for viewing fMRI
> > > > > > > datasets. Currently, I get keypresses using
> > > > > > > grDevices::getGraphicsEvent().
> > > > > > > 
> > > > > > > Unfortunately getGraphicsEvent() only supports the X11(type="Xlib")
> > > > > > > graphics device on Unix systems. The Xlib device doesn't support
> > > > > > > buffering (i.e. dev.hold() and dev.flush()), so redrawing the plots
> > > > > > > causes lots of flickering.
> > > > > > > 
> > > > > > > Is there a way to get keypresses while using the cairo graphics
> > > > > > > device? Alternatively, is there a way to prevent flickering with the
> > > > > > > Xlib graphics device?
> > > > > > > 
> > > > > > > Best,
> > > > > > > Daniel Greenidge
> > > > > > > 
> > > > > > > ______________________________________________
> > > > > > > R-devel at r-project.org mailing list
> > > > > > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > > > > > > 
> > > > > > 
> > > > > > ______________________________________________
> > > > > > R-devel at r-project.org mailing list
> > > > > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > > > > > 
> > > > > 
> > > > > --
> > > > > Dr Paul Murrell
> > > > > Department of Statistics
> > > > > The University of Auckland
> > > > > Private Bag 92019
> > > > > Auckland
> > > > > New Zealand
> > > > > 64 9 3737599 x85392
> > > > > paul at stat.auckland.ac.nz
> > > > > http://www.stat.auckland.ac.nz/~paul/
> > > > > 
> > > 
> > > --
> > > Dr Paul Murrell
> > > Department of Statistics
> > > The University of Auckland
> > > Private Bag 92019
> > > Auckland
> > > New Zealand
> > > 64 9 3737599 x85392
> > > paul at stat.auckland.ac.nz
> > > http://www.stat.auckland.ac.nz/~paul/
> > > 
> 
> -- 
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/
>


From paul at stat.auckland.ac.nz  Fri Dec  9 01:20:17 2016
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Fri, 9 Dec 2016 13:20:17 +1300
Subject: [Rd] getGraphicsEvent() alternative for cairo graphics device?
In-Reply-To: <20161208235859.GM6368@ofb.net>
References: <CAN_GHySs42vK5U1xZYP8h7ZPdFyOcHnEZK4Sn91e7htv=7E54A@mail.gmail.com>
	<20160725191747.GB18530@ofb.net> <57968357.2030509@stat.auckland.ac.nz>
	<20161112200028.GD24681@ofb.net>
	<2e6f0306-da86-211a-05dd-aff3d744df40@stat.auckland.ac.nz>
	<20161208221949.GK6368@ofb.net>
	<148093cd-8556-a56e-0e2e-e799bab3ed4d@stat.auckland.ac.nz>
	<20161208235859.GM6368@ofb.net>
Message-ID: <a9b4a1dd-44ea-532f-23f7-c3589d457df5@stat.auckland.ac.nz>

Hi

Yes, we have regression tests for graphics.

In general, but especially for core R code, I would rather have 
confidence that a fix has not broken existing behaviour before I commit it.

I cannot argue with the point that we could respond to some bug reports 
faster.

Paul

On 09/12/16 12:58, frederik at ofb.net wrote:
> Hi Paul,
>
> Thanks for keeping me posted and letting me know what I should do.
>
> Are there regression tests for other graphics functions in R? To me
> that sounds a bit unnecessary. I think you get more testing from
> people who use R; and having a good turnaround for applying patches
> (some have been waiting 5 years) would invite better participation.
>
> Thank you,
>
> Frederick
>
> On Fri, Dec 09, 2016 at 12:01:55PM +1300, Paul Murrell wrote:
>> Hi
>>
>> Just taking a bit more of a look at this today (currently fixated on making
>> sure I can build some good regression tests).
>>
>> The best thing you can do is to keep reminding me like this :)
>>
>> Paul
>>
>> On 09/12/16 11:19, frederik at ofb.net wrote:
>>> Hi Paul,
>>>
>>> Thanks for your efforts. Do you have an idea when my patch(es) might
>>> be committed? Is there anything I can do to help move this along?
>>>
>>> Thanks,
>>>
>>> Frederick
>>>
>>> On Mon, Nov 14, 2016 at 08:55:20AM +1300, Paul Murrell wrote:
>>>> Hi
>>>>
>>>> The current status is that I am keen for people to contribute some testing
>>>> code (see https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16951)
>>>>
>>>> There were also some getGraphicsEvent() changes/fixes suggested by Richard
>>>> Bodewits (cc'ed), for which I am also seeking test code.
>>>>
>>>> Paul
>>>>
>>>> On 13/11/16 09:00, frederik at ofb.net wrote:
>>>>> Hi Paul,
>>>>>
>>>>> Just checking in to see what the status is.
>>>>>
>>>>> From my perspective it seems logical to split off X11 into a separate
>>>>> package, so development can proceed at a reasonable rate, but I
>>>>> haven't yet tried to see if that's even possible.
>>>>>
>>>>> Thanks,
>>>>>
>>>>> Frederick
>>>>>
>>>>> On Tue, Jul 26, 2016 at 09:23:35AM +1200, Paul Murrell wrote:
>>>>>> Hi
>>>>>>
>>>>>> Taking a look at those patches is now on my todo list, so I may be in touch
>>>>>> with both of you at some point to request some testing.
>>>>>>
>>>>>> Paul
>>>>>>
>>>>>> On 26/07/16 07:17, frederik at ofb.net wrote:
>>>>>>> Dear Daniel Greenidge,
>>>>>>>
>>>>>>> To enable getGraphicsEvent on Cairo, you have two patches to choose
>>>>>>> from:
>>>>>>>
>>>>>>> https://bugs.r-project.org/bugzilla/show_bug.cgi?id=14364
>>>>>>> https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16951
>>>>>>>
>>>>>>> The second one is by me, and the first one is from five years ago by
>>>>>>> Hugo Mildenberger.
>>>>>>>
>>>>>>> Both patches are very simple, they move some lines enabling
>>>>>>> getGrahpicsEvent outside of a if(!cairo) statement. My patch also adds
>>>>>>> the ability to execute code (e.g. for animation) while the interface
>>>>>>> is idle.
>>>>>>>
>>>>>>> Top guy Duncan Murdoch has expressed that he doesn't have time to work
>>>>>>> on applying these patches, and I haven't had any responses from the
>>>>>>> rest of the R Core Team. I was thinking that perhaps your best bet is
>>>>>>> to try to create a package called e.g. "X11-fixes" which people can
>>>>>>> use to get a better X11 library (there is also a bug waiting to be
>>>>>>> fixed from 2001:
>>>>>>> https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16702).
>>>>>>>
>>>>>>> I don't know if CRAN would accept such a package, or if you'd have to
>>>>>>> distribute it via GitHub, but R has excellent tools to facilitate the
>>>>>>> distribution of code via packages. Whether the R kernel exports enough
>>>>>>> functions to allow a package to take over event handling, I'm not
>>>>>>> sure. I was intending to look more into the details of this
>>>>>>> possibility but haven't had time.
>>>>>>>
>>>>>>> Best wishes,
>>>>>>>
>>>>>>> Frederick
>>>>>>>
>>>>>>> On Mon, Jul 25, 2016 at 02:15:59PM -0400, Daniel Greenidge wrote:
>>>>>>>> Hi all,
>>>>>>>>
>>>>>>>> I'm writing an interactive plotting function for viewing fMRI
>>>>>>>> datasets. Currently, I get keypresses using
>>>>>>>> grDevices::getGraphicsEvent().
>>>>>>>>
>>>>>>>> Unfortunately getGraphicsEvent() only supports the X11(type="Xlib")
>>>>>>>> graphics device on Unix systems. The Xlib device doesn't support
>>>>>>>> buffering (i.e. dev.hold() and dev.flush()), so redrawing the plots
>>>>>>>> causes lots of flickering.
>>>>>>>>
>>>>>>>> Is there a way to get keypresses while using the cairo graphics
>>>>>>>> device? Alternatively, is there a way to prevent flickering with the
>>>>>>>> Xlib graphics device?
>>>>>>>>
>>>>>>>> Best,
>>>>>>>> Daniel Greenidge
>>>>>>>>
>>>>>>>> ______________________________________________
>>>>>>>> R-devel at r-project.org mailing list
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>>>
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-devel at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>>
>>>>>>
>>>>>> --
>>>>>> Dr Paul Murrell
>>>>>> Department of Statistics
>>>>>> The University of Auckland
>>>>>> Private Bag 92019
>>>>>> Auckland
>>>>>> New Zealand
>>>>>> 64 9 3737599 x85392
>>>>>> paul at stat.auckland.ac.nz
>>>>>> http://www.stat.auckland.ac.nz/~paul/
>>>>>>
>>>>
>>>> --
>>>> Dr Paul Murrell
>>>> Department of Statistics
>>>> The University of Auckland
>>>> Private Bag 92019
>>>> Auckland
>>>> New Zealand
>>>> 64 9 3737599 x85392
>>>> paul at stat.auckland.ac.nz
>>>> http://www.stat.auckland.ac.nz/~paul/
>>>>
>>
>> --
>> Dr Paul Murrell
>> Department of Statistics
>> The University of Auckland
>> Private Bag 92019
>> Auckland
>> New Zealand
>> 64 9 3737599 x85392
>> paul at stat.auckland.ac.nz
>> http://www.stat.auckland.ac.nz/~paul/
>>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From jpnolan at american.edu  Fri Dec  9 02:00:22 2016
From: jpnolan at american.edu (John P. Nolan)
Date: Fri, 9 Dec 2016 01:00:22 +0000
Subject: [Rd] wish list:  generalized apply
In-Reply-To: <8A85542C-24AF-47ED-AFB9-AE4EAB3CF32C@comcast.net>
References: <DM2PR0601MB8110B86F5689F2B1AF7CE0FC6840@DM2PR0601MB811.namprd06.prod.outlook.com>
	<8A85542C-24AF-47ED-AFB9-AE4EAB3CF32C@comcast.net>
Message-ID: <DM2PR0601MB811A1C4AF8142846219B7C5C6870@DM2PR0601MB811.namprd06.prod.outlook.com>



-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net] 
Sent: Thursday, December 8, 2016 4:59 PM
To: John P. Nolan <jpnolan at american.edu>
Cc: Charles C. Berry <R-devel at r-project.org>
Subject: Re: [Rd] wish list: generalized apply


> On Dec 8, 2016, at 12:09 PM, John P. Nolan <jpnolan at american.edu> wrote:
> 
> Dear All,
> 
> I regularly want to "apply" some function to an array in a way that the arguments to the user function depend on the index on which the apply is working.  A simple example is:
> 
> A <- array( runif(160), dim=c(5,4,8) ) x <- matrix( runif(32), nrow=4, 
> ncol=8 ) b <- runif(8)
> f1 <- function( A, x, b ) { sum( A %*% x ) + b } result <- rep(0.0,8) 
> for (i in 1:8) {  result[i] <- f1( A[,,i], x[,i] , b[i] ) }
> 
> This works, but is slow.  I'd like to be able to do something like:
>    generalized.apply( A, MARGIN=3, FUN=f1, list(x=x,MARGIN=2), list(b=b,MARGIN=1) ), where the lists tell generalized.apply to pass x[,i] and b[i] to FUN in addition to A[,,i].  
> 
> Does such a generalized.apply already exist somewhere?  While I can write a C function to do a particular case, it would be nice if there was a fast, general way to do this.  

I would have thought that this would achieve the same result:

result <- sapply( seq_along(b) , function(i) { f1( A[,,i], x[,i] , b[i] )} )

Or: 

result <- sapply( seq.int( dim(A)[3] ) , function(i) { f1( A[,,i], x[,i] , b[i] )} )

(I doubt it will be any faster, but if 'i' is large, parallelism might help. The inner function appears to be fairly efficient.)
-- 

David Winsemius
Alameda, CA, USA

====================================================================================

Thanks for the response.  I gave a toy example with 8 iterations to illustrate the point,  so I thought I would bump it up to make my point about speed.  But to my surprise, using a 'for' loop is FASTER than using 'sapply' as David suggest or even 'apply'  on a bit simpler problem.   Here is the example:

n <- 800000; m <- 10; k <- 10
A <- array( 1:(m*n*k), dim=c(m,k,n) )
y <- matrix( 1:(k*n), nrow=k, ncol=n )
b <- 1:n
f1 <- function( A, y, b ) { sum( A %*% y ) + b }

# use a for loop
time1 <- system.time( {
result <- rep(0.0,n)
for (i in 1:n) {
  result[i] <- f1( A[,,i], y[,i] , b[i] )
}
result } )

#  use sapply
time2 <- system.time( result2 <- sapply( seq.int( dim(A)[3] ) , function(i) { f1( A[,,i], y[,i] , b[i] )} ))

# fix y and b, and use standard apply
time3 <- system.time( result3 <- apply( A, MARGIN=3, FUN=f1, y=y[,1], b=b[1] ) ) 

# user times, then ratios of user times
c( time1[1], time2[1],time3[1]); c( time2[1]/time1[1], time3[1]/time1[1] )  
#   4.84      5.22      5.32 
#   1.078512  1.099174

So using a for loop saves 8-10% of the execution time as compared to sapply and apply!?  Years ago I experimented and found out I could speed things up noticeably by replacing loops with apply.  This is no longer the case, at least in this simple experiment.  Is this a result of byte code?  Can someone tell us when a for loop is going to be slower than using apply?  A more complicated loop that computes multiple quantities?  

John


From martin.morgan at roswellpark.org  Fri Dec  9 03:37:59 2016
From: martin.morgan at roswellpark.org (Martin Morgan)
Date: Thu, 8 Dec 2016 21:37:59 -0500
Subject: [Rd] methods(`|`) lists all functions?
In-Reply-To: <20161208221610.GJ6368@ofb.net>
References: <20161208221610.GJ6368@ofb.net>
Message-ID: <5d9ae4e0-85d1-daa4-a57e-0c5e6681ae12@roswellpark.org>

On 12/08/2016 05:16 PM, frederik at ofb.net wrote:
> Dear R-Devel,
>
> I was attempting an exercise in Hadley Wickam's book "Advanced R". The
> exercise is to find the generic with the greatest number of methods.
>
> I found that 'methods(`|`)' produces a list of length 2506, in R
> 3.3.1. Similar behavior is found in 3.4.0. It seems to include all
> functions and methods. I imagine something is being passed to "grep"
> without being escaped.

Exactly; I've fixed this in r71763 (R-devel).

Martin Morgan

>
> I hope I didn't miss something in the documentation, and that I'm good
> to report this as a bug. I can send it to Bugzilla if that's better.
>
> By the way, how do I produce such a list of functions (or variables)
> in a "normal" way? I used 'ls("package:base")' for the exercise,
> because I saw this call used somewhere as an example, but I couldn't
> find that "package:" syntax documented under ls()... Also found this
> confusing:
>
>     > environmentName(globalenv())
>     [1] "R_GlobalEnv"
>     > ls("R_GlobalEnv")
>     Error in as.environment(pos) :
>       no item called "R_GlobalEnv" on the search list
>
> So I'm not sure if "package:base" is naming an environment, or if
> there are different ways to name environments and ls() is using one
> form while environmentName is returning another ... It might be good
> to add some clarifying examples under "?ls".
>
> Thanks,
>
> Frederick
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


This email message may contain legally privileged and/or...{{dropped:2}}


From frederik at ofb.net  Fri Dec  9 03:47:16 2016
From: frederik at ofb.net (frederik at ofb.net)
Date: Thu, 8 Dec 2016 18:47:16 -0800
Subject: [Rd] methods(`|`) lists all functions?
In-Reply-To: <5d9ae4e0-85d1-daa4-a57e-0c5e6681ae12@roswellpark.org>
References: <20161208221610.GJ6368@ofb.net>
	<5d9ae4e0-85d1-daa4-a57e-0c5e6681ae12@roswellpark.org>
Message-ID: <20161209024716.GP6368@ofb.net>

On Thu, Dec 08, 2016 at 09:37:59PM -0500, Martin Morgan wrote:
> On 12/08/2016 05:16 PM, frederik at ofb.net wrote:
> > Dear R-Devel,
> > 
> > I was attempting an exercise in Hadley Wickam's book "Advanced R". The
> > exercise is to find the generic with the greatest number of methods.
> > 
> > I found that 'methods(`|`)' produces a list of length 2506, in R
> > 3.3.1. Similar behavior is found in 3.4.0. It seems to include all
> > functions and methods. I imagine something is being passed to "grep"
> > without being escaped.
> 
> Exactly; I've fixed this in r71763 (R-devel).
> 
> Martin Morgan

Thank you.


From boccigionata at gmail.com  Fri Dec  9 15:56:00 2016
From: boccigionata at gmail.com (Gionata Bocci)
Date: Fri, 9 Dec 2016 15:56:00 +0100
Subject: [Rd] Check package issue on mavericks
Message-ID: <CADGFu48DsF0j4VxLjHrODOXSpA8c0A7LafuPexZAw=oFs-6dNw@mail.gmail.com>

Dear List,

  I've realized that the "CRAN Checking Package" system returns some
Warnings for my package TR8 under "r-release-osx-x86_64-mavericks"; all the
warnings include the following message "Invalid MIT-MAGIC-COOKIE-1 key"
which I find a little cryptic.
  After some web searches, I understood that "MIT-MAGIC-COOKIE" is related
to the X server and most of the messages reporting issues with that are
related to R packages having problems with "mavericks" (either NOTES or
Warnings resulting from the "checking process").
  Not having a Mac available where I could try to explore this issue (and
not being familiar with Mac in general), I've set up a Travis CI account in
order to check whether the package was built and "checked --as-cran" on
both Linux (my OS) and Mac OSX (Travis is using OS X versions >= 10.10): it
looks like everything is fine, correctly built and checked.
  I am thus writing to ask if other developers on the list have found and
fixed this issue (so that I could fix that as well and tick the checkbox "I
have fixed all problems shown on the package check page" before submitting
a new version to CRAN).
  Best,


Gionata.

	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Fri Dec  9 16:31:34 2016
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Fri, 9 Dec 2016 09:31:34 -0600
Subject: [Rd] wish list: generalized apply
In-Reply-To: <8A85542C-24AF-47ED-AFB9-AE4EAB3CF32C@comcast.net>
References: <DM2PR0601MB8110B86F5689F2B1AF7CE0FC6840@DM2PR0601MB811.namprd06.prod.outlook.com>
	<8A85542C-24AF-47ED-AFB9-AE4EAB3CF32C@comcast.net>
Message-ID: <CAPPM_gS6sXLqeKchKVu5pq01_h-DcEu4aofMOHcx6tFa87gY2A@mail.gmail.com>

On Thu, Dec 8, 2016 at 3:59 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On Dec 8, 2016, at 12:09 PM, John P. Nolan <jpnolan at american.edu> wrote:
>>
>> Dear All,
>>
>> I regularly want to "apply" some function to an array in a way that the arguments to the user function depend on the index on which the apply is working.  A simple example is:
>>
>> A <- array( runif(160), dim=c(5,4,8) )
>> x <- matrix( runif(32), nrow=4, ncol=8 )
>> b <- runif(8)
>> f1 <- function( A, x, b ) { sum( A %*% x ) + b }
>> result <- rep(0.0,8)
>> for (i in 1:8) {
>>  result[i] <- f1( A[,,i], x[,i] , b[i] )
>> }
>>
>> This works, but is slow.  I'd like to be able to do something like:
>>    generalized.apply( A, MARGIN=3, FUN=f1, list(x=x,MARGIN=2), list(b=b,MARGIN=1) ), where the lists tell generalized.apply to pass x[,i] and b[i] to FUN in addition to A[,,i].
>>
>> Does such a generalized.apply already exist somewhere?  While I can write a C function to do a particular case, it would be nice if there was a fast, general way to do this.
>
> I would have thought that this would achieve the same result:
>
> result <- sapply( seq_along(b) , function(i) { f1( A[,,i], x[,i] , b[i] )} )
>
> Or:
>
> result <- sapply( seq.int( dim(A)[3] ) , function(i) { f1( A[,,i], x[,i] , b[i] )} )
>
> (I doubt it will be any faster, but if 'i' is large, parallelism might help. The inner function appears to be fairly efficient.)

You're right, it's slower.  Despite how often it's repeated that
"loops in R are slow", they're not *that* slow.  They're often faster
than the *apply functions, especially if they have been "compiled" by
compiler::cmpfun().

You really need to know *why* code is slow before trying to make it
faster.  I profiled an example that would have a loop with 1e6
iterations and 80%+ of the time was still spent inside f1().

set.seed(21)
nc <- 1e6
nr <- 10
A <- array( runif(5*nr*nc), dim=c(5,nr,nc) )
x <- matrix( runif(nr*nc), nrow=nr, ncol=nc )
b <- runif(nc)
f1 <- compiler::cmpfun(function( A, x, b ) { sum( A %*% x ) + b })
f2 <- compiler::cmpfun({
  function(A, x, b, FUN) {
    result <- numeric(length(b))
    for (i in seq_along(b)) {
      result[i] <- FUN( A[,,i], x[,i] , b[i] )
    }
    return(result)
  }
})
Rprof(interval=0.01)
result <- f2(A,x,b,f1)
Rprof(NULL)
summaryRprof()

$by.self
      self.time self.pct total.time total.pct
"FUN"      4.29    84.28       4.76     93.52
"%*%"      0.47     9.23       0.47      9.23
"f2"       0.33     6.48       5.09    100.00

$by.total
      total.time total.pct self.time self.pct
"f2"        5.09    100.00      0.33     6.48
"FUN"       4.76     93.52      4.29    84.28
"%*%"       0.47      9.23      0.47     9.23

$sample.interval
[1] 0.01

$sampling.time
[1] 5.09

In this case, almost all the time is spent evaluating f1() ("FUN"),
even after calling compiler::cmpfun on f1() and on a function
containing the loop.  Making the looping construct faster is not going
to improve the performance of this code by a significant amount.
I.e., dropping to compiled code will only help if you avoid the R
function call, but then that's not a general solution...

> --
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2016 | www.rinfinance.com


From pgilbert902 at gmail.com  Fri Dec  9 23:22:01 2016
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Fri, 9 Dec 2016 17:22:01 -0500
Subject: [Rd] parallel::detectCores() bug on Raspberry Pi B+
Message-ID: <cc0d1047-de96-d6a0-0254-f54a2bedb7ec@gmail.com>

In R 3.3.2 detectCores() in package parallel reports 2 rather than 1 on 
Raspberry Pi B+ running Raspbian. (This report is just 'for the record'. 
The model is superseded and I think no longer produced.)  The problem 
seems to be caused by

  grep processor /proc/cpuinfo
processor	: 0
model name	: ARMv6-compatible processor rev 7 (v6l)

(On Raspberry Pi 2 and 3 there is no error because the model name lines are

  model name	: ARMv7 Processor rev 5 (v7l)
  model name	: ARMv7 Processor rev 4 (v7l)
)


From wewolski at gmail.com  Sat Dec 10 19:24:30 2016
From: wewolski at gmail.com (Witold E Wolski)
Date: Sat, 10 Dec 2016 19:24:30 +0100
Subject: [Rd] Fwd: Error: XYZ is not an exported object
In-Reply-To: <CAAjnpdgeQQAW0+WO1B6g9dA2-S_GTGLh-2APFEg8O3MRc3TFBw@mail.gmail.com>
References: <CAAjnpdgeQQAW0+WO1B6g9dA2-S_GTGLh-2APFEg8O3MRc3TFBw@mail.gmail.com>
Message-ID: <CAAjnpdiGw18QuZpb-2BwLGVw1tkKvo=_R+adh304TZcbRT8JWw@mail.gmail.com>

I am wrting a package.
I have a dataset in data/AminoAcids.tsv and would like to be able to
access it with

bibliospec::AminoAcids

from within my package code.

R CMD build gives me the error:
Error : 'AminoAcids' is not an exported object from 'namespace:bibliospec'

I am able to access the data in package code with
data(AminoAcids)
AminoAcids

but this will give me a NOTE with R CMD check

Also when using the package I am able to access the data with
bibliospec::AminoAcids


So why can't I access bibliospec::AminoAcids from within package code?


This is how my roxygen doc for the data object looks like:
#' Data frame with amino acid masses
#'
#' @name AminoAcids
#' @docType data
#' @keywords data
NULL

Help highly appreciated.

Thank you

--
Witold Eryk Wolski


-- 
Witold Eryk Wolski


From jeroenooms at gmail.com  Sun Dec 11 18:09:19 2016
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Sun, 11 Dec 2016 18:09:19 +0100
Subject: [Rd] Check package issue on mavericks
In-Reply-To: <CADGFu48DsF0j4VxLjHrODOXSpA8c0A7LafuPexZAw=oFs-6dNw@mail.gmail.com>
References: <CADGFu48DsF0j4VxLjHrODOXSpA8c0A7LafuPexZAw=oFs-6dNw@mail.gmail.com>
Message-ID: <CABFfbXsT3b4HG35Fybub-w5N+vM24cuLRmUh5vF9cEN4F4A6sw@mail.gmail.com>

I just checked your package on a mavericks VM and it seems fine, so I
wouldn't worry about it. Probably some configuration issue on the CRAN
server, perhaps xquartz is outdated.

Unfortunately there is no easy way anymore to check on Mavericks.
Travis used to support it, but they have deprecated mavericks (along
with Apple and homebrew). Hopefully CRAN will update to the current
MacOS for the next release of R.




On Fri, Dec 9, 2016 at 3:56 PM, Gionata Bocci <boccigionata at gmail.com> wrote:
>
> Dear List,
>
>   I've realized that the "CRAN Checking Package" system returns some
> Warnings for my package TR8 under "r-release-osx-x86_64-mavericks"; all the
> warnings include the following message "Invalid MIT-MAGIC-COOKIE-1 key"
> which I find a little cryptic.
>   After some web searches, I understood that "MIT-MAGIC-COOKIE" is related
> to the X server and most of the messages reporting issues with that are
> related to R packages having problems with "mavericks" (either NOTES or
> Warnings resulting from the "checking process").
>   Not having a Mac available where I could try to explore this issue (and
> not being familiar with Mac in general), I've set up a Travis CI account in
> order to check whether the package was built and "checked --as-cran" on
> both Linux (my OS) and Mac OSX (Travis is using OS X versions >= 10.10): it
> looks like everything is fine, correctly built and checked.
>   I am thus writing to ask if other developers on the list have found and
> fixed this issue (so that I could fix that as well and tick the checkbox "I
> have fixed all problems shown on the package check page" before submitting
> a new version to CRAN).
>   Best,
>
>
> Gionata.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From frederik at ofb.net  Mon Dec 12 06:54:41 2016
From: frederik at ofb.net (frederik at ofb.net)
Date: Sun, 11 Dec 2016 21:54:41 -0800
Subject: [Rd] why does parent.frame() cycle when called from inside
 capture.output()?
Message-ID: <20161212055441.GA11787@ofb.net>

Hello R devel/help,

I ran into this strange behavior:

    # showstack is supposed to walk through the stack of parent
    # environments when it is called:
    showstack = function() {
      env = environment()
      for(i in 1:12) {
        env = do.call(parent.frame, list(), env=env)
        print(env)
      }
    }

    # a simple chain of functions:
    g3=function(t) showstack()
    g2=function(w) g3(w)
    g1=function(z) g2(z)
    g=function(y) g1(y)

    g()
    # outputs:
    # <environment: 0xb5ef810>
    # <environment: 0xb5ef6f8>
    # <environment: 0xb5ef5e0>
    # <environment: 0xb5ef4c8>
    # <environment: R_GlobalEnv>
    # <environment: R_GlobalEnv>
    # <environment: R_GlobalEnv>
    # <environment: R_GlobalEnv>
    # <environment: R_GlobalEnv>
    # ...

    cat(capture.output(g()),sep="\n")
    # outputs:
    # <environment: 0x8106a30>
    # <environment: 0x8106918>
    # <environment: 0x8106800>
    # <environment: 0x81066e8>
    # <environment: R_GlobalEnv>
    # <environment: 0x8107458>
    # <environment: 0x81071b8>
    # <environment: 0x80c6a08>
    # <environment: R_GlobalEnv>
    # <environment: 0x8107458>
    # <environment: 0x81071b8>
    # <environment: 0x80c6a08>

The strange thing of course is that the second call doesn't stay with
R_GlobalEnv, but in fact goes into a loop of period 4. I'm not so
surprised that the parent frame of the global environment is itself,
as in the first call, but it seems weird to have a loop of period 4...
Using `ls()` shows that two of the "loop" environments belong to
capture.output() and eval().

But if capture.output is really evaluating its input in the parent
frame, as it appears to be doing from its source code, then I would
have expected the output to be the same as the output I get by
evaluating the same expression in this frame.

I was trying to debug a function which attempts to be a multi-frame
version of deparse(substitute(...)). I'm attaching this function in
case anyone is curious. Perhaps my attachment can shed more light on
the problem I'm having.

Apologies if this is not a bug - I wasn't sure which mailing list to
send this to, and I took a guess.

Thanks,

Frederick
-------------- next part --------------
desubN <- function(y,n=1) {
  env=environment();
  for(i in 1:n) {
    y = do.call(substitute, list(substitute(y)), env=env)
    env = do.call(parent.frame, list(), env=env)
  }
  deparse(y)
}
g2=function(t) {
  for(i in 1:5) {
    print(desubN(t,i))
    print(capture.output(desubN(t,i)))
  }
}
g1=function(z) g2(z)
g=function(y) g1(y)

g(log)
# output: (why does it stop at "z"?)
## [1] "t"
## [1] "[1] \"t\""
## [1] "z"
## [1] "[1] \"z\""
## [1] "y"
## [1] "[1] \"z\""
## [1] "log"
## [1] "[1] \"z\""
## [1] "log"
## [1] "[1] \"z\""

From frederik at ofb.net  Mon Dec 12 09:23:32 2016
From: frederik at ofb.net (frederik at ofb.net)
Date: Mon, 12 Dec 2016 00:23:32 -0800
Subject: [Rd] [RE: why does parent.frame() cycle when called from inside
 capture.output()?]
In-Reply-To: <20161212055441.GA11787@ofb.net>
Message-ID: <20161212082332.GC11787@ofb.net>

Thanks, Mark - I'm taking up your invitation to forward your message
to the list just because it gives us some valuable data on (1) how
long the behavior has been around, and (2) how many other people
(don't) understand the behavior, and (3) how we might fix or work
around it.

I notice some other people also seem to be diffident about posting on
R-devel; perhaps I should conclude that bugs like this are below the
radar for busy statisticians.

FWIW, after playing around a bit with mvbutils::mvb.parent.frame, I
now have a working "desubN" (see the attachment on my original
message, and this one). I don't really have a good understanding of
*why* it now works, and why the original version didn't work...

Thanks again Mark. Also, nice hacking.

Frederick

----- Forwarded message from Mark.Bravington at data61.csiro.au -----

Date: Mon, 12 Dec 2016 06:20:17 +0000
From: Mark.Bravington at data61.csiro.au
To: frederik at ofb.net
Subject: RE: [Rd] why does parent.frame() cycle when called from inside
	capture.output()?
X-Spam-Status: No, score=-2.0 required=5.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID,DKIM_VALID_AU,T_SPF_HELO_TEMPERROR,T_SPF_TEMPERROR autolearn=ham
	autolearn_force=no version=3.4.1
X-Spam-Level: 
X-My-Tags: inbox r-devel

Hi Frederik

[ I'm replying off-list in case you, or the rest of R-devel, don't find this reply useful... please fwd to the list if it does help you ]

I'm the author of the 'debug' package. When I wrote it--- many years ago now--- I encountered some fairly strange behaviour with frames in the call stack, which is reminiscent of what you're seeing. The debug package still works fine, so I presume nothing has changed much.

If you load debug and then do ?mvb.sys.parent (and look at the code), you might get *some* idea of what's going on. TBH I can't remember the details now...

HTH
Mark

Mark Bravington
CSIRO Marine Lab
Hobart
Australia

________________________________________
From: R-devel [r-devel-bounces at r-project.org] on behalf of frederik at ofb.net [frederik at ofb.net]
Sent: 12 December 2016 16:54
To: r-devel at r-project.org
Cc: r-help at r-project.org
Subject: [Rd] why does parent.frame() cycle when called from inside capture.output()?

Hello R devel/help,

I ran into this strange behavior:

    # showstack is supposed to walk through the stack of parent
    # environments when it is called:
    showstack = function() {
      env = environment()
      for(i in 1:12) {
        env = do.call(parent.frame, list(), env=env)
        print(env)
      }
    }

    # a simple chain of functions:
    g3=function(t) showstack()
    g2=function(w) g3(w)
    g1=function(z) g2(z)
    g=function(y) g1(y)

    g()
    # outputs:
    # <environment: 0xb5ef810>
    # <environment: 0xb5ef6f8>
    # <environment: 0xb5ef5e0>
    # <environment: 0xb5ef4c8>
    # <environment: R_GlobalEnv>
    # <environment: R_GlobalEnv>
    # <environment: R_GlobalEnv>
    # <environment: R_GlobalEnv>
    # <environment: R_GlobalEnv>
    # ...

    cat(capture.output(g()),sep="\n")
    # outputs:
    # <environment: 0x8106a30>
    # <environment: 0x8106918>
    # <environment: 0x8106800>
    # <environment: 0x81066e8>
    # <environment: R_GlobalEnv>
    # <environment: 0x8107458>
    # <environment: 0x81071b8>
    # <environment: 0x80c6a08>
    # <environment: R_GlobalEnv>
    # <environment: 0x8107458>
    # <environment: 0x81071b8>
    # <environment: 0x80c6a08>

The strange thing of course is that the second call doesn't stay with
R_GlobalEnv, but in fact goes into a loop of period 4. I'm not so
surprised that the parent frame of the global environment is itself,
as in the first call, but it seems weird to have a loop of period 4...
Using `ls()` shows that two of the "loop" environments belong to
capture.output() and eval().

But if capture.output is really evaluating its input in the parent
frame, as it appears to be doing from its source code, then I would
have expected the output to be the same as the output I get by
evaluating the same expression in this frame.

I was trying to debug a function which attempts to be a multi-frame
version of deparse(substitute(...)). I'm attaching this function in
case anyone is curious. Perhaps my attachment can shed more light on
the problem I'm having.

Apologies if this is not a bug - I wasn't sure which mailing list to
send this to, and I took a guess.

Thanks,

Frederick


----- End forwarded message -----
-------------- next part --------------
# We can't just use `mvb.parent.frame` as a replacement for
# `parent.frame`, because the former throws an error when there is no
# parent frame - while we had relied on the latter gracefully giving
# us the global environment. So here's a wrapper which gives
# mvb.parent.frame the behavior we want:

my_mvb_parent=function() {
  tryCatch(
    mvb.parent.frame(2),
    error=function(e) { globalenv()})
}

desubN <- function(y,n=1) {
  env=environment();
  for(i in 1:n) {
    y = do.call(substitute, list(substitute(y)), env=env)
    env = do.call(my_mvb_parent, list(), env=env)
  }
  deparse(y)
}
g2=function(t) {
  for(i in 1:5) {
    print(desubN(t,i))
    print(capture.output(desubN(t,i)))
  }
}
g1=function(z) g2(z)
g=function(y) g1(y)

g(log)

# now capture.output seems to give the same results as the bare
# expression
## [1] "t"
## [1] "[1] \"t\""
## [1] "z"
## [1] "[1] \"z\""
## [1] "y"
## [1] "[1] \"y\""
## [1] "log"
## [1] "[1] \"log\""
## [1] "log"
## [1] "[1] \"log\""

From jon.skoien at jrc.ec.europa.eu  Mon Dec 12 17:31:06 2016
From: jon.skoien at jrc.ec.europa.eu (Jon Skoien)
Date: Mon, 12 Dec 2016 17:31:06 +0100
Subject: [Rd] Strange behavior when using progress bar (Fwd: Re: [R] The
 code itself disappears after starting to execute the for loop)
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8365A6B4A@FHSDB2D11-2.csu.mcmaster.ca>
References: <54b8d998-9299-4034-be0a-9c9ad7169974@jrc.ec.europa.eu>
	<fdd2811e-60af-e322-4e33-0c1ad5eab0ee@jrc.ec.europa.eu>
	<ec37a17e-b2ee-b1df-2490-6006f49b886c@jrc.ec.europa.eu>
	<22599.60218.182964.817869@stat.math.ethz.ch>
	<ACD1644AA6C67E4FBD0C350625508EC8365A6B4A@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <1a06d87d-9cc0-8f3d-21fc-5c4c7eb29c46@jrc.ec.europa.eu>

Thanks John,

As the problem can be reproduced, I would like to submit this as a bug 
report. But I think someone will have to add me to Bugzilla first.
Given the few responses, I am not expecting that this will get a high 
priority though...

Jon

On 12/7/2016 2:59 PM, Fox, John wrote:
> Dear Martin and Jon,
>
> I can reproduce this problem in the Windows GUI, where I observed it using Jon's program after 75 iterations. I didn't observe the problem in a Windows terminal or under RStudio, letting the program run for more than 200 iterations in each case.
>
> My system and session info:
>
> ------------- snip ---------
>
>> Sys.info()
>           sysname          release          version         nodename
>         "Windows"         "10 x64"    "build 14393" "JOHN-CARBON-X1"
>           machine            login             user   effective_user
>          "x86-64"       "John Fox"       "John Fox"       "John Fox"
>
>> sessionInfo()
> R version 3.3.2 (2016-10-31)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 10 x64 (build 14393)
>
> locale:
> [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252
> [3] LC_MONETARY=English_Canada.1252 LC_NUMERIC=C
> [5] LC_TIME=English_Canada.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> ------------- snip ---------
>
> I hope this helps,
>   John
>
> -----------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> Web: socserv.mcmaster.ca/jfox
>
>
>> -----Original Message-----
>> From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of Martin
>> Maechler
>> Sent: December 7, 2016 5:58 AM
>> To: Jon Skoien <jon.skoien at jrc.ec.europa.eu>
>> Cc: r-devel at r-project.org
>> Subject: Re: [Rd] Strange behavior when using progress bar (Fwd: Re: [R] The
>> code itself disappears after starting to execute the for loop)
>>
>>>>>>> Jon Skoien <jon.skoien at jrc.ec.europa.eu>
>>>>>>>      on Wed, 7 Dec 2016 11:04:04 +0100 writes:
>>      > I would like to ask once more if this is reproducible also for others?
>>      > If yes, should I submit it as a bug-report?
>>
>>      > Best,
>>      > Jon
>>
>> Please  Windows users .. this is possibly only for you!
>>
>> Note that I do *not* see problems on Linux (in ESS; did not try RStudio).
>>
>> Please also indicate in which form you are running R.
>> Here it does depend if this is inside RStudio, ESS, the "Windows GUI", the
>> "Windows terminal", ...
>>
>> Martin Maechler,
>> ETH Zurich
>>
>>
>>      > On 11/28/2016 11:26 AM, Jon Skoien wrote:
>>      >> I first answered to the email below in r-help, but as I did not see
>>      >> any response, and it looks like a bug/unwanted behavior, I am also
>>      >> posting here. I have observed this in RGui, whereas it seems not to
>>      >> happen in RStudio.
>>      >>
>>      >> Similar to OP, I sometimes have a problem with functions using the
>>      >> progress bar. Frequently, the console is cleared after x iterations
>>      >> when the progress bar is called in a function which is wrapped in a
>>      >> loop. In the example below, this happened for me every ~44th
>>      >> iteration. Interestingly, it seems that reduction of the sleep times
>>      >> in this function increases the number of iterations before clearing.
>>      >> In my real application, where the progress bar is used in a much
>>      >> slower function, the console is cleared every 2-3 iteration, which
>>      >> means that I cannot scroll back to check the output.
>>
>>   testit <- function(x = sort(runif(20)), ...) {
>>     pb <- txtProgressBar(...)
>>     for(i in c(0, x, 1)) {Sys.sleep(0.2); setTxtProgressBar(pb, i)}
>>     Sys.sleep(1)
>>     close(pb)
>>   }
>>
>>   it <- 0
>>   while (TRUE) {testit(style = 3); it <- it + 1; print(paste("done", it))}
>>
>>      >> Is this only a problem for a few, or is it reproducible? Any hints to
>>      >> what the problem could be, or if it can be fixed? I have seen this in
>>      >> some versions of R, and could also reproduce in 3.3.2.
>>
>> "some versions of R" ... all on Windows ?
>>
>>      >>
>>      >> Best wishes,
>>      >> Jon
>>      >>
>>      >> R version 3.3.2 (2016-10-31)
>>      >> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>      >> Running under: Windows 8.1 x64 (build 9600)
>>      >>
>>      >> locale:
>>      >> [1] LC_COLLATE=English_United States.1252
>>      >> [2] LC_CTYPE=English_United States.1252
>>      >> [3] LC_MONETARY=English_United States.1252
>>      >> [4] LC_NUMERIC=C
>>      >> [5] LC_TIME=English_United States.1252
>>      >>
>>      >> attached base packages:
>>      >> [1] stats     graphics  grDevices utils     datasets  methods base
>>
>> [.....................]
>>
>>      > Jon Olav Sk?ien
>>      > Joint Research Centre - European Commission
>>      > Institute for Space, Security & Migration
>>      > Disaster Risk Management Unit
>>
>>      > Via E. Fermi 2749, TP 122,  I-21027 Ispra (VA), ITALY
>>
>>      > jon.skoien at jrc.ec.europa.eu
>>      > Tel:  +39 0332 789205
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Jon Olav Sk?ien
Joint Research Centre - European Commission
Institute for Space, Security & Migration
Disaster Risk Management Unit

Via E. Fermi 2749, TP 122,  I-21027 Ispra (VA), ITALY

jon.skoien at jrc.ec.europa.eu
Tel:  +39 0332 789205

Disclaimer: Views expressed in this email are those of the individual and do not necessarily represent official views of the European Commission.


From wewolski at gmail.com  Mon Dec 12 21:34:36 2016
From: wewolski at gmail.com (Witold E Wolski)
Date: Mon, 12 Dec 2016 21:34:36 +0100
Subject: [Rd] accessing data by packagename::dataname from within
	package code fails.
In-Reply-To: <CAAjnpdh91sMKbUYk6Tv8CYEJs9jA+Ztc2msEzsnJwX422nPVtw@mail.gmail.com>
References: <CAAjnpdh91sMKbUYk6Tv8CYEJs9jA+Ztc2msEzsnJwX422nPVtw@mail.gmail.com>
Message-ID: <CAAjnpdjdaVn6DcTzs9echKg4XFCGBXt2FVqZBMnFM6VPOc4=4w@mail.gmail.com>

I have narrowed down the problem.
The error
Error : 'AminoAcids' is not an exported object from 'namespace:bibliospec'
Error : unable to load R code in package 'bibliospec'

occurs only if I try to access the data using bibliospec::AminoAcids

within the initialize method of an R reference class.
It does work, as far as I tested everywhere else. In other methods of
a reference class as well as in free functions.
It also does not work in the initialization list to the initialize function.
So I also can't do something like
initialize = function(aminoAcids=bibliospec::AminoAcids){


I guess this is an R FEATURE.

But then where and how is the best practice to initialize class
members with default values?

Thank you.





On 12 December 2016 at 15:45, Witold E Wolski <wewolski at gmail.com> wrote:
> I am wrting a package called bibliospec.
> I have a dataset in data/AminoAcids.tsv and would like to be able to
> access it with
>
> bibliospec::AminoAcids
>
> from within my package code.
>
> R CMD build gives me the error:
> Error : 'AminoAcids' is not an exported object from 'namespace:bibliospec'
>
> I am able to access the data in package code with
> data(AminoAcids)
> AminoAcids
>
> but this will give me a NOTE with R CMD check
>
> Also, after loading the packagepackage I am able to access the data with
> bibliospec::AminoAcids
>
> But I can't access it from the package bibliospec code.
> So why can't I access bibliospec::AminoAcids from within package code?
>
> Help appreciated
>
> Witold
> --
> Witold Eryk Wolski



-- 
Witold Eryk Wolski


From wdunlap at tibco.com  Mon Dec 12 21:54:50 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 12 Dec 2016 12:54:50 -0800
Subject: [Rd] [R-pkg-devel] accessing data by packagename::dataname from
 within package code fails.
In-Reply-To: <CAAjnpdjdaVn6DcTzs9echKg4XFCGBXt2FVqZBMnFM6VPOc4=4w@mail.gmail.com>
References: <CAAjnpdh91sMKbUYk6Tv8CYEJs9jA+Ztc2msEzsnJwX422nPVtw@mail.gmail.com>
	<CAAjnpdjdaVn6DcTzs9echKg4XFCGBXt2FVqZBMnFM6VPOc4=4w@mail.gmail.com>
Message-ID: <CAF8bMcY-OgUEaC1Ajv8pubFiFZ5Xo-5YN9aXn43yhjJ8Dc1Erw@mail.gmail.com>

You can define the data in the R directory.  You can keep it all in a *.R
file
by wrapping the text of the *.csv file in quotes and using
read.table(text="quoted stuff"), as in:

theData <- read.csv(header=TRUE, text="
English,Digit
One,1
Two,2
Three,3")
N <- nrow(theData)

You need to make sure 'theData' is defined before using it so put
everything requiring
it in one file or use the Collate: directive in the DESCRIPTION file.



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Dec 12, 2016 at 12:34 PM, Witold E Wolski <wewolski at gmail.com>
wrote:

> I have narrowed down the problem.
> The error
> Error : 'AminoAcids' is not an exported object from 'namespace:bibliospec'
> Error : unable to load R code in package 'bibliospec'
>
> occurs only if I try to access the data using bibliospec::AminoAcids
>
> within the initialize method of an R reference class.
> It does work, as far as I tested everywhere else. In other methods of
> a reference class as well as in free functions.
> It also does not work in the initialization list to the initialize
> function.
> So I also can't do something like
> initialize = function(aminoAcids=bibliospec::AminoAcids){
>
>
> I guess this is an R FEATURE.
>
> But then where and how is the best practice to initialize class
> members with default values?
>
> Thank you.
>
>
>
>
>
> On 12 December 2016 at 15:45, Witold E Wolski <wewolski at gmail.com> wrote:
> > I am wrting a package called bibliospec.
> > I have a dataset in data/AminoAcids.tsv and would like to be able to
> > access it with
> >
> > bibliospec::AminoAcids
> >
> > from within my package code.
> >
> > R CMD build gives me the error:
> > Error : 'AminoAcids' is not an exported object from
> 'namespace:bibliospec'
> >
> > I am able to access the data in package code with
> > data(AminoAcids)
> > AminoAcids
> >
> > but this will give me a NOTE with R CMD check
> >
> > Also, after loading the packagepackage I am able to access the data with
> > bibliospec::AminoAcids
> >
> > But I can't access it from the package bibliospec code.
> > So why can't I access bibliospec::AminoAcids from within package code?
> >
> > Help appreciated
> >
> > Witold
> > --
> > Witold Eryk Wolski
>
>
>
> --
> Witold Eryk Wolski
>
> ______________________________________________
> R-package-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-package-devel
>

	[[alternative HTML version deleted]]


From gmbecker at ucdavis.edu  Mon Dec 12 21:57:01 2016
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Mon, 12 Dec 2016 12:57:01 -0800
Subject: [Rd] accessing data by packagename::dataname from within
 package code fails.
In-Reply-To: <CAAjnpdjdaVn6DcTzs9echKg4XFCGBXt2FVqZBMnFM6VPOc4=4w@mail.gmail.com>
References: <CAAjnpdh91sMKbUYk6Tv8CYEJs9jA+Ztc2msEzsnJwX422nPVtw@mail.gmail.com>
	<CAAjnpdjdaVn6DcTzs9echKg4XFCGBXt2FVqZBMnFM6VPOc4=4w@mail.gmail.com>
Message-ID: <CADwqtCOWqEWLMFJhKO4ydq4z+awE4KA59WVY8=h4E7X2KH5twQ@mail.gmail.com>

Witold,

Are you using the sys data approach to actually put your data into your
package's namespace? From ?data (Good practices section)

Use of ?data? within a function without an ?envir? argument has

     the almost always undesirable side-effect of putting an object in

     the user's workspace (and indeed, of replacing any object of that

     name already there).  It would almost always be better to put the

     object in the current evaluation environment by ?data(..., envir =

     environment())?.  However, two alternatives are usually

     preferable, both described in the ?Writing R Extensions? manual.


        ? For sets of data, set up a package to use lazy-loading of

          data.


        ? For objects which are system data, for example lookup tables

          used in calculations within the function, use a file

          ?R/sysdata.rda? in the package sources or create the objects

          by R code at package installation time.


     A sometimes important distinction is that the second approach

     places objects in the namespace but the first does not.  So if it

     is important that the function sees ?mytable? as an object from

     the package, it is system data and the second approach should be

     used.  In the unusual case that a package uses a lazy-loaded

     dataset as a default argument to a function, that needs to be

     specified by ?::?, e.g., ?survival::survexp.us?.


It does seem a bit strange that the :: works elsewhere but not in
initialize, but I don't have time to track that down atm.

Best,
~G

On Mon, Dec 12, 2016 at 12:34 PM, Witold E Wolski <wewolski at gmail.com>
wrote:

> I have narrowed down the problem.
> The error
> Error : 'AminoAcids' is not an exported object from 'namespace:bibliospec'
> Error : unable to load R code in package 'bibliospec'
>
> occurs only if I try to access the data using bibliospec::AminoAcids
>
> within the initialize method of an R reference class.
> It does work, as far as I tested everywhere else. In other methods of
> a reference class as well as in free functions.
> It also does not work in the initialization list to the initialize
> function.
> So I also can't do something like
> initialize = function(aminoAcids=bibliospec::AminoAcids){
>
>
> I guess this is an R FEATURE.
>
> But then where and how is the best practice to initialize class
> members with default values?
>
> Thank you.
>
>
>
>
>
> On 12 December 2016 at 15:45, Witold E Wolski <wewolski at gmail.com> wrote:
> > I am wrting a package called bibliospec.
> > I have a dataset in data/AminoAcids.tsv and would like to be able to
> > access it with
> >
> > bibliospec::AminoAcids
> >
> > from within my package code.
> >
> > R CMD build gives me the error:
> > Error : 'AminoAcids' is not an exported object from
> 'namespace:bibliospec'
> >
> > I am able to access the data in package code with
> > data(AminoAcids)
> > AminoAcids
> >
> > but this will give me a NOTE with R CMD check
> >
> > Also, after loading the packagepackage I am able to access the data with
> > bibliospec::AminoAcids
> >
> > But I can't access it from the package bibliospec code.
> > So why can't I access bibliospec::AminoAcids from within package code?
> >
> > Help appreciated
> >
> > Witold
> > --
> > Witold Eryk Wolski
>
>
>
> --
> Witold Eryk Wolski
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Gabriel Becker, PhD
Associate Scientist (Bioinformatics)
Genentech Research

	[[alternative HTML version deleted]]


From Mark.Bravington at data61.csiro.au  Mon Dec 12 23:36:00 2016
From: Mark.Bravington at data61.csiro.au (Mark.Bravington at data61.csiro.au)
Date: Mon, 12 Dec 2016 22:36:00 +0000
Subject: [Rd] [RE: why does parent.frame() cycle when called from inside
 capture.output()?]
In-Reply-To: <20161212082332.GC11787@ofb.net>
References: <20161212055441.GA11787@ofb.net>,<20161212082332.GC11787@ofb.net>
Message-ID: <4aea0ecaeaa448c29e6c2b2b99d403fb@exch1-cdc.nexus.csiro.au>

Hi Frederik

Goodo, glad you found mvbutils::mvb.parent.frame useful. I had forgotten that it's in mvbutils rather than debug package. This all dates back about 15 years...

To be fair, I don't think R's behaviour with duplicated-but-aliased frames in the call stack is a "bug"--- everything normal just works--- and it's not something to be "fixed" IMO, since it's clearly built-in by design and who knows what else would break if it got changed? But, working round it is indeed sometimes necessary...

[ BTW I'm not particularly diffident about posting to R-devel--- eg here I am!--- but I'm generally too busy to check out my own answers thoroughly, so rather than risk opening up blind alleys, I tend to suggest things off-list. In the cases where I'm sure that I do have a good answer, someone else has already usually responded... ]

bye
mark

Mark Bravington
CSIRO Marine Lab
Hobart
Australia

________________________________________
From: frederik at ofb.net [frederik at ofb.net]
Sent: 12 December 2016 19:23
To: R-devel at r-project.org
Cc: Bravington, Mark (Data61, Hobart); r-help at r-project.org
Subject: [RE: [Rd] why does parent.frame() cycle when called from inside capture.output()?]

Thanks, Mark - I'm taking up your invitation to forward your message
to the list just because it gives us some valuable data on (1) how
long the behavior has been around, and (2) how many other people
(don't) understand the behavior, and (3) how we might fix or work
around it.

I notice some other people also seem to be diffident about posting on
R-devel; perhaps I should conclude that bugs like this are below the
radar for busy statisticians.

FWIW, after playing around a bit with mvbutils::mvb.parent.frame, I
now have a working "desubN" (see the attachment on my original
message, and this one). I don't really have a good understanding of
*why* it now works, and why the original version didn't work...

Thanks again Mark. Also, nice hacking.

Frederick

----- Forwarded message from Mark.Bravington at data61.csiro.au -----

Date: Mon, 12 Dec 2016 06:20:17 +0000
From: Mark.Bravington at data61.csiro.au
To: frederik at ofb.net
Subject: RE: [Rd] why does parent.frame() cycle when called from inside
        capture.output()?
X-Spam-Status: No, score=-2.0 required=5.0 tests=BAYES_00,DKIM_SIGNED,
        DKIM_VALID,DKIM_VALID_AU,T_SPF_HELO_TEMPERROR,T_SPF_TEMPERROR autolearn=ham
        autolearn_force=no version=3.4.1
X-Spam-Level:
X-My-Tags: inbox r-devel

Hi Frederik

[ I'm replying off-list in case you, or the rest of R-devel, don't find this reply useful... please fwd to the list if it does help you ]

I'm the author of the 'debug' package. When I wrote it--- many years ago now--- I encountered some fairly strange behaviour with frames in the call stack, which is reminiscent of what you're seeing. The debug package still works fine, so I presume nothing has changed much.

If you load debug and then do ?mvb.sys.parent (and look at the code), you might get *some* idea of what's going on. TBH I can't remember the details now...

HTH
Mark

Mark Bravington
CSIRO Marine Lab
Hobart
Australia

________________________________________
From: R-devel [r-devel-bounces at r-project.org] on behalf of frederik at ofb.net [frederik at ofb.net]
Sent: 12 December 2016 16:54
To: r-devel at r-project.org
Cc: r-help at r-project.org
Subject: [Rd] why does parent.frame() cycle when called from inside capture.output()?

Hello R devel/help,

I ran into this strange behavior:

    # showstack is supposed to walk through the stack of parent
    # environments when it is called:
    showstack = function() {
      env = environment()
      for(i in 1:12) {
        env = do.call(parent.frame, list(), env=env)
        print(env)
      }
    }

    # a simple chain of functions:
    g3=function(t) showstack()
    g2=function(w) g3(w)
    g1=function(z) g2(z)
    g=function(y) g1(y)

    g()
    # outputs:
    # <environment: 0xb5ef810>
    # <environment: 0xb5ef6f8>
    # <environment: 0xb5ef5e0>
    # <environment: 0xb5ef4c8>
    # <environment: R_GlobalEnv>
    # <environment: R_GlobalEnv>
    # <environment: R_GlobalEnv>
    # <environment: R_GlobalEnv>
    # <environment: R_GlobalEnv>
    # ...

    cat(capture.output(g()),sep="\n")
    # outputs:
    # <environment: 0x8106a30>
    # <environment: 0x8106918>
    # <environment: 0x8106800>
    # <environment: 0x81066e8>
    # <environment: R_GlobalEnv>
    # <environment: 0x8107458>
    # <environment: 0x81071b8>
    # <environment: 0x80c6a08>
    # <environment: R_GlobalEnv>
    # <environment: 0x8107458>
    # <environment: 0x81071b8>
    # <environment: 0x80c6a08>

The strange thing of course is that the second call doesn't stay with
R_GlobalEnv, but in fact goes into a loop of period 4. I'm not so
surprised that the parent frame of the global environment is itself,
as in the first call, but it seems weird to have a loop of period 4...
Using `ls()` shows that two of the "loop" environments belong to
capture.output() and eval().

But if capture.output is really evaluating its input in the parent
frame, as it appears to be doing from its source code, then I would
have expected the output to be the same as the output I get by
evaluating the same expression in this frame.

I was trying to debug a function which attempts to be a multi-frame
version of deparse(substitute(...)). I'm attaching this function in
case anyone is curious. Perhaps my attachment can shed more light on
the problem I'm having.

Apologies if this is not a bug - I wasn't sure which mailing list to
send this to, and I took a guess.

Thanks,

Frederick


----- End forwarded message -----


From pauljohn32 at gmail.com  Tue Dec 13 18:05:23 2016
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Tue, 13 Dec 2016 11:05:23 -0600
Subject: [Rd] syntax difference clusterExport in parallel and snow
Message-ID: <CAErODj-ZqYvuvvS3wdF7L2O7-JJwSi7-wi6Jtp4UPmrZ4j+aQA@mail.gmail.com>

We got some errors and eventually figured out that
parallel::clusterExport second argument is "varlist" while in
snow::clusterExport it is "list".

The user had loaded parallel first, but did something else which
inadvertently loaded snow, then clusterExport failed because we had
"varlist" and not "list".

Are these different on purpose?

pj

-- 
Paul E. Johnson   http://pj.freefaculty.org
Director, Center for Research Methods and Data Analysis http://crmda.ku.edu

To write to me directly, please address me at pauljohn at ku.edu.


From ripley at stats.ox.ac.uk  Tue Dec 13 18:33:11 2016
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 13 Dec 2016 17:33:11 +0000
Subject: [Rd] syntax difference clusterExport in parallel and snow
In-Reply-To: <CAErODj-ZqYvuvvS3wdF7L2O7-JJwSi7-wi6Jtp4UPmrZ4j+aQA@mail.gmail.com>
References: <CAErODj-ZqYvuvvS3wdF7L2O7-JJwSi7-wi6Jtp4UPmrZ4j+aQA@mail.gmail.com>
Message-ID: <ea0a9ca1-39bd-1407-3458-de4cd5259596@stats.ox.ac.uk>

On 13/12/2016 17:05, Paul Johnson wrote:
> We got some errors and eventually figured out that
> parallel::clusterExport second argument is "varlist" while in
> snow::clusterExport it is "list".
>
> The user had loaded parallel first, but did something else which
> inadvertently loaded snow, then clusterExport failed because we had
> "varlist" and not "list".
>
> Are these different on purpose?

Yes.

('list' is an unhelpful name for an argument that is not a list.)


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford


From boccigionata at gmail.com  Wed Dec 14 10:10:27 2016
From: boccigionata at gmail.com (Gionata Bocci)
Date: Wed, 14 Dec 2016 10:10:27 +0100
Subject: [Rd] Check package issue on mavericks
In-Reply-To: <CABFfbXsT3b4HG35Fybub-w5N+vM24cuLRmUh5vF9cEN4F4A6sw@mail.gmail.com>
References: <CADGFu48DsF0j4VxLjHrODOXSpA8c0A7LafuPexZAw=oFs-6dNw@mail.gmail.com>
	<CABFfbXsT3b4HG35Fybub-w5N+vM24cuLRmUh5vF9cEN4F4A6sw@mail.gmail.com>
Message-ID: <CADGFu48oe8BWgzh9wpoXCZGRfu3sTEFAnNT=Ha+xSdNxKu+bXg@mail.gmail.com>

Dear Jeroen,

   Thank you very much for the time you spent checking my package; I think
I will upload the package to CRAN hoping that this will be considered as a
non-existing issue.
   Thanks again,

Gionata.

2016-12-11 18:09 GMT+01:00 Jeroen Ooms <jeroenooms at gmail.com>:

> I just checked your package on a mavericks VM and it seems fine, so I
> wouldn't worry about it. Probably some configuration issue on the CRAN
> server, perhaps xquartz is outdated.
>
> Unfortunately there is no easy way anymore to check on Mavericks.
> Travis used to support it, but they have deprecated mavericks (along
> with Apple and homebrew). Hopefully CRAN will update to the current
> MacOS for the next release of R.
>
>
>
>
> On Fri, Dec 9, 2016 at 3:56 PM, Gionata Bocci <boccigionata at gmail.com>
> wrote:
> >
> > Dear List,
> >
> >   I've realized that the "CRAN Checking Package" system returns some
> > Warnings for my package TR8 under "r-release-osx-x86_64-mavericks"; all
> the
> > warnings include the following message "Invalid MIT-MAGIC-COOKIE-1 key"
> > which I find a little cryptic.
> >   After some web searches, I understood that "MIT-MAGIC-COOKIE" is
> related
> > to the X server and most of the messages reporting issues with that are
> > related to R packages having problems with "mavericks" (either NOTES or
> > Warnings resulting from the "checking process").
> >   Not having a Mac available where I could try to explore this issue (and
> > not being familiar with Mac in general), I've set up a Travis CI account
> in
> > order to check whether the package was built and "checked --as-cran" on
> > both Linux (my OS) and Mac OSX (Travis is using OS X versions >= 10.10):
> it
> > looks like everything is fine, correctly built and checked.
> >   I am thus writing to ask if other developers on the list have found and
> > fixed this issue (so that I could fix that as well and tick the checkbox
> "I
> > have fixed all problems shown on the package check page" before
> submitting
> > a new version to CRAN).
> >   Best,
> >
> >
> > Gionata.
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Wed Dec 14 17:04:22 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 14 Dec 2016 17:04:22 +0100
Subject: [Rd] New leap second end of 2016 / beginning 2017 (depending on TZ)
Message-ID: <CAPRP4-ewTBVtMKb7Lhec8=YvDscFePTH-Lqif69osgOjdRkbbg@mail.gmail.com>

As R is sophisticated enough to track leap seconds,

   ?.leap.seconds

we'd need to update our codes real soon now again:

https://en.wikipedia.org/wiki/Leap_second

(and those of you who want second precision in R in 2017 need to start
working with 'R patched' or 'R devel' ...)


From kmb56 at berkeley.edu  Thu Dec 15 06:08:17 2016
From: kmb56 at berkeley.edu (Kenny Bell)
Date: Wed, 14 Dec 2016 21:08:17 -0800
Subject: [Rd] Parallel compression support for saving to rds/rdata files?
Message-ID: <CALOjXYSFfDo_gG6c3RqaYJ-A0Kzcpmkfa27_QkAGHKy1c8b8-Q@mail.gmail.com>

Hi,

I have tried to follow the instructions in the ``save`` documentation and
it doesn't seem to work (see below):

mydata <- do.call(rbind, rep(iris, 10000))
con <- pipe("pigz -p8 > fname.gz", "wb");
save(mydata, file = con); close(con) # This runs

R.utils::gunzip("fname.gz", "fname.RData", overwrite = TRUE)
load("fname.RData") # Error: error reading from connection

First question: Should the above work?

Second question: Is it possible to make this dummy friendly by allowing
"pigz" as an option for ``compress`` in saveRDS and save? And in such a way
that the decompressing is hidden from the user like normal?

Thanks!
Kenny


-- 
Kendon Bell
Email: kmb56 at berkeley.edu
Phone: (510) 612-3375

Ph.D. Candidate
Department of Agricultural & Resource Economics
University of California, Berkeley

	[[alternative HTML version deleted]]


From simon.urbanek at r-project.org  Thu Dec 15 16:43:12 2016
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 15 Dec 2016 10:43:12 -0500
Subject: [Rd] Parallel compression support for saving to rds/rdata files?
In-Reply-To: <CALOjXYSFfDo_gG6c3RqaYJ-A0Kzcpmkfa27_QkAGHKy1c8b8-Q@mail.gmail.com>
References: <CALOjXYSFfDo_gG6c3RqaYJ-A0Kzcpmkfa27_QkAGHKy1c8b8-Q@mail.gmail.com>
Message-ID: <C2736D72-EB8A-4345-AC74-078021099827@r-project.org>


> On Dec 15, 2016, at 12:08 AM, Kenny Bell <kmb56 at berkeley.edu> wrote:
> 
> Hi,
> 
> I have tried to follow the instructions in the ``save`` documentation and
> it doesn't seem to work (see below):
> 
> mydata <- do.call(rbind, rep(iris, 10000))
> con <- pipe("pigz -p8 > fname.gz", "wb");
> save(mydata, file = con); close(con) # This runs
> 
> R.utils::gunzip("fname.gz", "fname.RData", overwrite = TRUE)
> load("fname.RData") # Error: error reading from connection
> 
> First question: Should the above work?
> 


Not really, gzip is a bad example, because it doesn't really support parallel compression (since a gzip stream cannot be chopped into blocks by design), but you can do it with bzip2:

mydata <- do.call(rbind, rep(iris, 10000))
con <- pipe("pbzip2 -p8 > fname.bz2", "wb")
save(mydata, file = con)
close(con) 

load("fname.bz2")

you can also use parallel read:

load(pipe("pbzip2 -dc fname.bz2"))

Cheers,
Simon



> Second question: Is it possible to make this dummy friendly by allowing
> "pigz" as an option for ``compress`` in saveRDS and save? And in such a way
> that the decompressing is hidden from the user like normal?
> 
> Thanks!
> Kenny
> 
> 
> -- 
> Kendon Bell
> Email: kmb56 at berkeley.edu
> Phone: (510) 612-3375
> 
> Ph.D. Candidate
> Department of Agricultural & Resource Economics
> University of California, Berkeley
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From jennifer.s.lyon at gmail.com  Thu Dec 15 17:33:30 2016
From: jennifer.s.lyon at gmail.com (Jennifer Lyon)
Date: Thu, 15 Dec 2016 09:33:30 -0700
Subject: [Rd] print.POSIXct doesn't seem to use tz argument,
	as per its example
Message-ID: <CAKstpn7h88=OUpNjV6ZKCEbivWTZfAqhEDAzj01wodBYdcJThQ@mail.gmail.com>

On the documentation page for DateTimeClasses, in the Examples section,
there are the following two lines:

format(.leap.seconds)         # the leap seconds in your time zone
print(.leap.seconds, tz = "PST8PDT")  # and in Seattle's

The second line (using print) seems to ignore the tz argument, and prints
the dates in my time zone, while:

format(.leap.seconds, tz = "PST8PDT")

does print the dates in PST. The code in
https://github.com/wch/r-source/blob/trunk/src/library/base/R/datetime.R
around line 234 looks like the ... argument is passed to print, not to
format.

print.POSIXct <-
print.POSIXlt <- function(x, ...)
{
    max.print <- getOption("max.print", 9999L)
    if(max.print < length(x)) {
        print(format(x[seq_len(max.print)], usetz = TRUE), ...)
        cat(' [ reached getOption("max.print") -- omitted',
            length(x) - max.print, 'entries ]\n')
    } else print(if(length(x)) format(x, usetz = TRUE)
                 else paste(class(x)[1L], "of length 0"), ...)
    invisible(x)
}

The documentation for print() on this page seems to be silent on tz as an
argument, but I do believe the example using print() does not work as
advertised.

Thanks.

Jen
sessionInfo()
R version 3.3.2 (2016-10-31)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.5 LTS

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Thu Dec 15 18:02:02 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 15 Dec 2016 18:02:02 +0100
Subject: [Rd] New leap second end of 2016 / beginning 2017 (depending on
	TZ)
In-Reply-To: <CAPRP4-ewTBVtMKb7Lhec8=YvDscFePTH-Lqif69osgOjdRkbbg@mail.gmail.com>
References: <CAPRP4-ewTBVtMKb7Lhec8=YvDscFePTH-Lqif69osgOjdRkbbg@mail.gmail.com>
Message-ID: <22610.52362.296054.565812@stat.math.ethz.ch>

>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Wed, 14 Dec 2016 17:04:22 +0100 writes:

    > As R is sophisticated enough to track leap seconds,
    > ?.leap.seconds

    > we'd need to update our codes real soon now again:

    > https://en.wikipedia.org/wiki/Leap_second

    > (and those of you who want second precision in R in 2017 need to start
    > working with 'R patched' or 'R devel' ...)

I've been told offline, that the above could be considered as
FUD .. which I hope nobody read from it.

Furthermore, there seems to be wide disagreement about the
usefulness of leap seconds, and how computers (and OSs) should
deal with them.
One recent approach (e.g. by Google) is to "smear the leap
second" into the system (by somehow "throttling" time servers ;-)..

(and no, I even less would want this to become a long thread, so
 please refrain if you can ...)

Martin


From maechler at stat.math.ethz.ch  Fri Dec 16 10:19:08 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 16 Dec 2016 10:19:08 +0100
Subject: [Rd] print.POSIXct doesn't seem to use tz argument,
	as per its example
In-Reply-To: <CAKstpn7h88=OUpNjV6ZKCEbivWTZfAqhEDAzj01wodBYdcJThQ@mail.gmail.com>
References: <CAKstpn7h88=OUpNjV6ZKCEbivWTZfAqhEDAzj01wodBYdcJThQ@mail.gmail.com>
Message-ID: <22611.45452.303730.470838@stat.math.ethz.ch>

>>>>> Jennifer Lyon <jennifer.s.lyon at gmail.com>
>>>>>     on Thu, 15 Dec 2016 09:33:30 -0700 writes:

> On the documentation page for DateTimeClasses, in the Examples section,
> there are the following two lines:
> 
> format(.leap.seconds)         # the leap seconds in your time zone
> print(.leap.seconds, tz = "PST8PDT")  # and in Seattle's
> 
> The second line (using print) seems to ignore the tz argument, and prints
> the dates in my time zone, while:
> 
> format(.leap.seconds, tz = "PST8PDT")
> 
> does print the dates in PST. The code in
> https://github.com/wch/r-source/blob/trunk/src/library/base/R/datetime.R
> around line 234 looks like the ... argument is passed to print, not to
> format.
> 
> print.POSIXct <-
> print.POSIXlt <- function(x, ...)
> {
>     max.print <- getOption("max.print", 9999L)
>     if(max.print < length(x)) {
>         print(format(x[seq_len(max.print)], usetz = TRUE), ...)
>         cat(' [ reached getOption("max.print") -- omitted',
>             length(x) - max.print, 'entries ]\n')
>     } else print(if(length(x)) format(x, usetz = TRUE)
>                  else paste(class(x)[1L], "of length 0"), ...)
>     invisible(x)
> }
> 
> The documentation for print() on this page seems to be silent on tz as an
> argument, but I do believe the example using print() does not work as
> advertised.

> Thanks.
> 
> Jen

Thank you, Jen!
Indeed,  both your observation and your diagnosis are correct:
This has been a misleading example and needs amending (or the
code is changed, see below).

The most simple fix would be to replace  'print('  by
'format('; then the example would work as advertized.
That change has two drawbacks still:

1) format(.) examples on the help of print.POSIXct() where
   format.POSIXct() is *not* documented 

2) It *would* make sense that print.POSIXct() allowed for a 'tz' argument
   (and maybe 'usetz' too).  This/these would be (an) extra
   argument(s) rather than passing '...' not just to print() but
   also to format()rathere

My personal preference would tend to add both
     tz = ""
and  usetz = TRUE
to the formal arguments of print.POSIXct and pass them to the
format(.) calls.

Martin


> sessionInfo()
> R version 3.3.2 (2016-10-31)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 14.04.5 LTS
> 
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base


From kirill.mueller at ivt.baug.ethz.ch  Fri Dec 16 11:35:08 2016
From: kirill.mueller at ivt.baug.ethz.ch (=?UTF-8?Q?Kirill_M=c3=bcller?=)
Date: Fri, 16 Dec 2016 11:35:08 +0100
Subject: [Rd] Upgrading a package to which other packages are LinkingTo
Message-ID: <e04b65b6-bb5e-b0ae-9c30-761c20ad24a4@ivt.baug.ethz.ch>

Hi


I'd like to suggest to make R more informative when a user updates a 
package A where there's at least one package B that has "LinkingTo: A" 
in its description.

To illustrate the problem, assume package A is updated so that its C/C++ 
header interface (in inst/include) is changed. For package B to pick up 
these changes, we need to reinstall package A. In extreme cases, if B 
also imports A and uses functions from A's shared library, failure to 
reinstall B may lead to all sorts of undefined behavior.

I've stumbled over this recently for A = Rcpp 0.12.8 and B = dplyr 0.5.0 
[1], with a bug fix available in Rcpp 0.12.8.2. Simply upgrading Rcpp to 
0.12.8.2 wasn't enough to propagate the bug fix to dplyr; we need to 
reinstall dplyr 0.5.0 too.

I've prepared an example with R-devel r71799. The initial configuration 
[2] is Rcpp 0.12.8 and dplyr 0.5.0. There is no warning from R after 
upgrading Rcpp to 0.12.8.2 [3], and no warning when loading the (now 
"broken") dplyr 0.5.0 linked against Rcpp 0.12.8 but importing Rcpp 
0.12.8.2 [4].

As a remedy, I'd like to suggest that upgrading Rcpp gives a warning 
about installed packages that are LinkingTo it [3], and that loading 
dplyr gives a warning that it has been built against a different version 
of Rcpp [4], just like the warning when packages are built against a 
different version of R.

Thanks.


Best regards

Kirill


[1] https://github.com/hadley/dplyr/issues/2308#issuecomment-267495075
[2] https://travis-ci.org/krlmlr/pkg.upgrade.test#L589-L593
[3] https://travis-ci.org/krlmlr/pkg.upgrade.test#L619-L645
[4] https://travis-ci.org/krlmlr/pkg.upgrade.test#L671-L703


From edd at debian.org  Fri Dec 16 13:00:19 2016
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 16 Dec 2016 06:00:19 -0600
Subject: [Rd] print.POSIXct doesn't seem to use tz argument,
	as per its example
In-Reply-To: <22611.45452.303730.470838@stat.math.ethz.ch>
References: <CAKstpn7h88=OUpNjV6ZKCEbivWTZfAqhEDAzj01wodBYdcJThQ@mail.gmail.com>
	<22611.45452.303730.470838@stat.math.ethz.ch>
Message-ID: <22611.55123.728240.315623@max.nulle.part>


On 16 December 2016 at 10:19, Martin Maechler wrote:
| >>>>> Jennifer Lyon <jennifer.s.lyon at gmail.com>
| >>>>>     on Thu, 15 Dec 2016 09:33:30 -0700 writes:
| 
| > On the documentation page for DateTimeClasses, in the Examples section,
| > there are the following two lines:
| > 
| > format(.leap.seconds)         # the leap seconds in your time zone
| > print(.leap.seconds, tz = "PST8PDT")  # and in Seattle's
| > 
| > The second line (using print) seems to ignore the tz argument, and prints
| > the dates in my time zone, while:
| > 
| > format(.leap.seconds, tz = "PST8PDT")
| > 
| > does print the dates in PST. The code in
| > https://github.com/wch/r-source/blob/trunk/src/library/base/R/datetime.R
| > around line 234 looks like the ... argument is passed to print, not to
| > format.
| > 
| > print.POSIXct <-
| > print.POSIXlt <- function(x, ...)
| > {
| >     max.print <- getOption("max.print", 9999L)
| >     if(max.print < length(x)) {
| >         print(format(x[seq_len(max.print)], usetz = TRUE), ...)
| >         cat(' [ reached getOption("max.print") -- omitted',
| >             length(x) - max.print, 'entries ]\n')
| >     } else print(if(length(x)) format(x, usetz = TRUE)
| >                  else paste(class(x)[1L], "of length 0"), ...)
| >     invisible(x)
| > }
| > 
| > The documentation for print() on this page seems to be silent on tz as an
| > argument, but I do believe the example using print() does not work as
| > advertised.
| 
| > Thanks.
| > 
| > Jen
| 
| Thank you, Jen!
| Indeed,  both your observation and your diagnosis are correct:
| This has been a misleading example and needs amending (or the
| code is changed, see below).
| 
| The most simple fix would be to replace  'print('  by
| 'format('; then the example would work as advertized.
| That change has two drawbacks still:
| 
| 1) format(.) examples on the help of print.POSIXct() where
|    format.POSIXct() is *not* documented 
| 
| 2) It *would* make sense that print.POSIXct() allowed for a 'tz' argument
|    (and maybe 'usetz' too).  This/these would be (an) extra
|    argument(s) rather than passing '...' not just to print() but
|    also to format()rathere
| 
| My personal preference would tend to add both
|      tz = ""
| and  usetz = TRUE
| to the formal arguments of print.POSIXct and pass them to the
| format(.) calls.

I think that is a good idea. I have been by this a few times too.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From murdoch.duncan at gmail.com  Fri Dec 16 14:20:48 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 16 Dec 2016 08:20:48 -0500
Subject: [Rd] Upgrading a package to which other packages are LinkingTo
In-Reply-To: <e04b65b6-bb5e-b0ae-9c30-761c20ad24a4@ivt.baug.ethz.ch>
References: <e04b65b6-bb5e-b0ae-9c30-761c20ad24a4@ivt.baug.ethz.ch>
Message-ID: <341cb7cf-03f6-d70d-464f-a87c77617c9b@gmail.com>

I think there's one typo in your post which may confuse some readers; 
I've edited it inline below.  My comments on the suggestion are at the 
bottom of the message.


On 16/12/2016 5:35 AM, Kirill M?ller wrote:
> Hi
>
>
> I'd like to suggest to make R more informative when a user updates a
> package A where there's at least one package B that has "LinkingTo: A"
> in its description.
>
> To illustrate the problem, assume package A is updated so that its C/C++
> header interface (in inst/include) is changed. For package B to pick up
> these changes, we need to reinstall package A.

This should be "reinstall package B", I think.

 > In extreme cases, if B
> also imports A and uses functions from A's shared library, failure to
> reinstall B may lead to all sorts of undefined behavior.
>
> I've stumbled over this recently for A = Rcpp 0.12.8 and B = dplyr 0.5.0
> [1], with a bug fix available in Rcpp 0.12.8.2. Simply upgrading Rcpp to
> 0.12.8.2 wasn't enough to propagate the bug fix to dplyr; we need to
> reinstall dplyr 0.5.0 too.
>
> I've prepared an example with R-devel r71799. The initial configuration
> [2] is Rcpp 0.12.8 and dplyr 0.5.0. There is no warning from R after
> upgrading Rcpp to 0.12.8.2 [3], and no warning when loading the (now
> "broken") dplyr 0.5.0 linked against Rcpp 0.12.8 but importing Rcpp
> 0.12.8.2 [4].
>
> As a remedy, I'd like to suggest that upgrading Rcpp gives a warning
> about installed packages that are LinkingTo it [3], and that loading
> dplyr gives a warning that it has been built against a different version
> of Rcpp [4], just like the warning when packages are built against a
> different version of R.

I'd call it a bug that we allow the situation to exist without some sort 
of warning or error.

Your suggestion is one remedy, but might lead to too many warnings (or 
too many unnecessary recompiles).

An argument could be made that it's a bug in package A that it has 
updated its interface in a way that breaks packages that use it.

Perhaps the solution is to recommend that packages which export their 
C-level entry points either guarantee them not to change or offer 
(require?) version checks by user code.  So dplyr should start out by 
saying "I'm using Rcpp interface 0.12.8".  If Rcpp has a new version 
with a compatible interface, it replies "that's fine".  If Rcpp has 
changed its interface, it says "Sorry, I don't support that any more."

Duncan Murdoch

>
> Thanks.
>
>
> Best regards
>
> Kirill
>
>
> [1] https://github.com/hadley/dplyr/issues/2308#issuecomment-267495075
> [2] https://travis-ci.org/krlmlr/pkg.upgrade.test#L589-L593
> [3] https://travis-ci.org/krlmlr/pkg.upgrade.test#L619-L645
> [4] https://travis-ci.org/krlmlr/pkg.upgrade.test#L671-L703
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From edd at debian.org  Fri Dec 16 14:37:54 2016
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 16 Dec 2016 07:37:54 -0600
Subject: [Rd] Upgrading a package to which other packages are LinkingTo
In-Reply-To: <341cb7cf-03f6-d70d-464f-a87c77617c9b@gmail.com>
References: <e04b65b6-bb5e-b0ae-9c30-761c20ad24a4@ivt.baug.ethz.ch>
	<341cb7cf-03f6-d70d-464f-a87c77617c9b@gmail.com>
Message-ID: <22611.60978.786479.630863@max.nulle.part>


On 16 December 2016 at 08:20, Duncan Murdoch wrote:
| Perhaps the solution is to recommend that packages which export their 
| C-level entry points either guarantee them not to change or offer 
| (require?) version checks by user code.  So dplyr should start out by 
| saying "I'm using Rcpp interface 0.12.8".  If Rcpp has a new version 
| with a compatible interface, it replies "that's fine".  If Rcpp has 
| changed its interface, it says "Sorry, I don't support that any more."

We try. But it's hard, and I'd argue, likely impossible.

For example I even added a "frozen" package [1] in the sources / unit tests
to test for just this. In practice you just cannot hit every possible access
point of the (rich, in our case) API so the tests pass too often.

Which is why we relentlessly test against reverse-depends to _at least ensure
buildability_ from our releases.

As for seamless binary upgrade, I don't think in can work in practice.  Ask
Uwe one day we he rebuilds everything every time on Windows. And for what it
is worth, we essentially do the same in Debian.

Sometimes you just need to rebuild.  That may be the price of admission for
using the convenience of rich C++ interfaces.

Dirk

[1] https://github.com/RcppCore/Rcpp/tree/master/inst/unitTests/testRcppPackage


| Duncan Murdoch
| 
| >
| > Thanks.
| >
| >
| > Best regards
| >
| > Kirill
| >
| >
| > [1] https://github.com/hadley/dplyr/issues/2308#issuecomment-267495075
| > [2] https://travis-ci.org/krlmlr/pkg.upgrade.test#L589-L593
| > [3] https://travis-ci.org/krlmlr/pkg.upgrade.test#L619-L645
| > [4] https://travis-ci.org/krlmlr/pkg.upgrade.test#L671-L703
| >
| > ______________________________________________
| > R-devel at r-project.org mailing list
| > https://stat.ethz.ch/mailman/listinfo/r-devel
| >
| 
| ______________________________________________
| R-devel at r-project.org mailing list
| https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From murdoch.duncan at gmail.com  Fri Dec 16 16:14:18 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 16 Dec 2016 10:14:18 -0500
Subject: [Rd] Upgrading a package to which other packages are LinkingTo
In-Reply-To: <22611.60978.786479.630863@max.nulle.part>
References: <e04b65b6-bb5e-b0ae-9c30-761c20ad24a4@ivt.baug.ethz.ch>
	<341cb7cf-03f6-d70d-464f-a87c77617c9b@gmail.com>
	<22611.60978.786479.630863@max.nulle.part>
Message-ID: <8555d7b8-e2da-38f7-f133-9e7d46cf74b6@gmail.com>

On 16/12/2016 8:37 AM, Dirk Eddelbuettel wrote:
>
> On 16 December 2016 at 08:20, Duncan Murdoch wrote:
> | Perhaps the solution is to recommend that packages which export their
> | C-level entry points either guarantee them not to change or offer
> | (require?) version checks by user code.  So dplyr should start out by
> | saying "I'm using Rcpp interface 0.12.8".  If Rcpp has a new version
> | with a compatible interface, it replies "that's fine".  If Rcpp has
> | changed its interface, it says "Sorry, I don't support that any more."
>
> We try. But it's hard, and I'd argue, likely impossible.
>
> For example I even added a "frozen" package [1] in the sources / unit tests
> to test for just this. In practice you just cannot hit every possible access
> point of the (rich, in our case) API so the tests pass too often.
>
> Which is why we relentlessly test against reverse-depends to _at least ensure
> buildability_ from our releases.
>
> As for seamless binary upgrade, I don't think in can work in practice.  Ask
> Uwe one day we he rebuilds everything every time on Windows. And for what it
> is worth, we essentially do the same in Debian.
>
> Sometimes you just need to rebuild.  That may be the price of admission for
> using the convenience of rich C++ interfaces.
>

Okay, so would you say that Kirill's suggestion is not overkill?  Every 
time package B uses LinkingTo: A, R should assume it needs to rebuild B 
when A is updated?

Duncan Murdoch


From edd at debian.org  Fri Dec 16 16:40:25 2016
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 16 Dec 2016 09:40:25 -0600
Subject: [Rd] Upgrading a package to which other packages are LinkingTo
In-Reply-To: <8555d7b8-e2da-38f7-f133-9e7d46cf74b6@gmail.com>
References: <e04b65b6-bb5e-b0ae-9c30-761c20ad24a4@ivt.baug.ethz.ch>
	<341cb7cf-03f6-d70d-464f-a87c77617c9b@gmail.com>
	<22611.60978.786479.630863@max.nulle.part>
	<8555d7b8-e2da-38f7-f133-9e7d46cf74b6@gmail.com>
Message-ID: <22612.2793.857104.239264@max.nulle.part>


On 16 December 2016 at 10:14, Duncan Murdoch wrote:
| On 16/12/2016 8:37 AM, Dirk Eddelbuettel wrote:
| >
| > On 16 December 2016 at 08:20, Duncan Murdoch wrote:
| > | Perhaps the solution is to recommend that packages which export their
| > | C-level entry points either guarantee them not to change or offer
| > | (require?) version checks by user code.  So dplyr should start out by
| > | saying "I'm using Rcpp interface 0.12.8".  If Rcpp has a new version
| > | with a compatible interface, it replies "that's fine".  If Rcpp has
| > | changed its interface, it says "Sorry, I don't support that any more."
| >
| > We try. But it's hard, and I'd argue, likely impossible.
| >
| > For example I even added a "frozen" package [1] in the sources / unit tests
| > to test for just this. In practice you just cannot hit every possible access
| > point of the (rich, in our case) API so the tests pass too often.
| >
| > Which is why we relentlessly test against reverse-depends to _at least ensure
| > buildability_ from our releases.

I meant to also add:  "... against a large corpus of other packages."
The intent is to empirically answer this.

| > As for seamless binary upgrade, I don't think in can work in practice.  Ask
| > Uwe one day we he rebuilds everything every time on Windows. And for what it
| > is worth, we essentially do the same in Debian.
| >
| > Sometimes you just need to rebuild.  That may be the price of admission for
| > using the convenience of rich C++ interfaces.
| >
| 
| Okay, so would you say that Kirill's suggestion is not overkill?  Every 
| time package B uses LinkingTo: A, R should assume it needs to rebuild B 
| when A is updated?

Based on my experience is a "halting problem" -- i.e. cannot know ex ante.

So "every time" would be overkill to me.  Sometimes you know you must
recompile (but try to be very prudent with public-facing API).  Many times
you do not. It is hard to pin down.

At work we have a bunch of servers with Rcpp and many packages against them
(installed system-wide for all users). We _very really_ needs rebuild.  

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From murdoch.duncan at gmail.com  Fri Dec 16 17:00:42 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 16 Dec 2016 11:00:42 -0500
Subject: [Rd] Upgrading a package to which other packages are LinkingTo
In-Reply-To: <22612.2793.857104.239264@max.nulle.part>
References: <e04b65b6-bb5e-b0ae-9c30-761c20ad24a4@ivt.baug.ethz.ch>
	<341cb7cf-03f6-d70d-464f-a87c77617c9b@gmail.com>
	<22611.60978.786479.630863@max.nulle.part>
	<8555d7b8-e2da-38f7-f133-9e7d46cf74b6@gmail.com>
	<22612.2793.857104.239264@max.nulle.part>
Message-ID: <52a8bf02-b3d0-51a4-3bb3-162758156623@gmail.com>

On 16/12/2016 10:40 AM, Dirk Eddelbuettel wrote:
> On 16 December 2016 at 10:14, Duncan Murdoch wrote:
> | On 16/12/2016 8:37 AM, Dirk Eddelbuettel wrote:
> | >
> | > On 16 December 2016 at 08:20, Duncan Murdoch wrote:
> | > | Perhaps the solution is to recommend that packages which export their
> | > | C-level entry points either guarantee them not to change or offer
> | > | (require?) version checks by user code.  So dplyr should start out by
> | > | saying "I'm using Rcpp interface 0.12.8".  If Rcpp has a new version
> | > | with a compatible interface, it replies "that's fine".  If Rcpp has
> | > | changed its interface, it says "Sorry, I don't support that any more."
> | >
> | > We try. But it's hard, and I'd argue, likely impossible.
> | >
> | > For example I even added a "frozen" package [1] in the sources / unit tests
> | > to test for just this. In practice you just cannot hit every possible access
> | > point of the (rich, in our case) API so the tests pass too often.
> | >
> | > Which is why we relentlessly test against reverse-depends to _at least ensure
> | > buildability_ from our releases.
>
> I meant to also add:  "... against a large corpus of other packages."
> The intent is to empirically answer this.
>
> | > As for seamless binary upgrade, I don't think in can work in practice.  Ask
> | > Uwe one day we he rebuilds everything every time on Windows. And for what it
> | > is worth, we essentially do the same in Debian.
> | >
> | > Sometimes you just need to rebuild.  That may be the price of admission for
> | > using the convenience of rich C++ interfaces.
> | >
> |
> | Okay, so would you say that Kirill's suggestion is not overkill?  Every
> | time package B uses LinkingTo: A, R should assume it needs to rebuild B
> | when A is updated?
>
> Based on my experience is a "halting problem" -- i.e. cannot know ex ante.
>
> So "every time" would be overkill to me.  Sometimes you know you must
> recompile (but try to be very prudent with public-facing API).  Many times
> you do not. It is hard to pin down.
>
> At work we have a bunch of servers with Rcpp and many packages against them
> (installed system-wide for all users). We _very really_ needs rebuild.

So that comes back to my suggestion:  you should provide a way for a 
dependent package to ask if your API has changed.  If you say it hasn't, 
the package is fine.  If you say it has, the package should abort, 
telling the user they need to reinstall it.  (Because it's a hard 
question to answer, you might get it wrong and say it's fine when it's 
not.  But that's easy to fix:  just make a new release that does require 
a rebuild.)

Duncan Murdoch


From edd at debian.org  Fri Dec 16 17:19:06 2016
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 16 Dec 2016 10:19:06 -0600
Subject: [Rd] Upgrading a package to which other packages are LinkingTo
In-Reply-To: <52a8bf02-b3d0-51a4-3bb3-162758156623@gmail.com>
References: <e04b65b6-bb5e-b0ae-9c30-761c20ad24a4@ivt.baug.ethz.ch>
	<341cb7cf-03f6-d70d-464f-a87c77617c9b@gmail.com>
	<22611.60978.786479.630863@max.nulle.part>
	<8555d7b8-e2da-38f7-f133-9e7d46cf74b6@gmail.com>
	<22612.2793.857104.239264@max.nulle.part>
	<52a8bf02-b3d0-51a4-3bb3-162758156623@gmail.com>
Message-ID: <22612.5114.200686.241246@max.nulle.part>


On 16 December 2016 at 11:00, Duncan Murdoch wrote:
| On 16/12/2016 10:40 AM, Dirk Eddelbuettel wrote:
| > On 16 December 2016 at 10:14, Duncan Murdoch wrote:
| > | On 16/12/2016 8:37 AM, Dirk Eddelbuettel wrote:
| > | >
| > | > On 16 December 2016 at 08:20, Duncan Murdoch wrote:
| > | > | Perhaps the solution is to recommend that packages which export their
| > | > | C-level entry points either guarantee them not to change or offer
| > | > | (require?) version checks by user code.  So dplyr should start out by
| > | > | saying "I'm using Rcpp interface 0.12.8".  If Rcpp has a new version
| > | > | with a compatible interface, it replies "that's fine".  If Rcpp has
| > | > | changed its interface, it says "Sorry, I don't support that any more."
| > | >
| > | > We try. But it's hard, and I'd argue, likely impossible.
| > | >
| > | > For example I even added a "frozen" package [1] in the sources / unit tests
| > | > to test for just this. In practice you just cannot hit every possible access
| > | > point of the (rich, in our case) API so the tests pass too often.
| > | >
| > | > Which is why we relentlessly test against reverse-depends to _at least ensure
| > | > buildability_ from our releases.
| >
| > I meant to also add:  "... against a large corpus of other packages."
| > The intent is to empirically answer this.
| >
| > | > As for seamless binary upgrade, I don't think in can work in practice.  Ask
| > | > Uwe one day we he rebuilds everything every time on Windows. And for what it
| > | > is worth, we essentially do the same in Debian.
| > | >
| > | > Sometimes you just need to rebuild.  That may be the price of admission for
| > | > using the convenience of rich C++ interfaces.
| > | >
| > |
| > | Okay, so would you say that Kirill's suggestion is not overkill?  Every
| > | time package B uses LinkingTo: A, R should assume it needs to rebuild B
| > | when A is updated?
| >
| > Based on my experience is a "halting problem" -- i.e. cannot know ex ante.
| >
| > So "every time" would be overkill to me.  Sometimes you know you must
| > recompile (but try to be very prudent with public-facing API).  Many times
| > you do not. It is hard to pin down.
| >
| > At work we have a bunch of servers with Rcpp and many packages against them
| > (installed system-wide for all users). We _very really_ needs rebuild.

Edit:  "We _very rarely_ need rebuilds" is what was meant there.
 
| So that comes back to my suggestion:  you should provide a way for a 
| dependent package to ask if your API has changed.  If you say it hasn't, 
| the package is fine.  If you say it has, the package should abort, 
| telling the user they need to reinstall it.  (Because it's a hard 
| question to answer, you might get it wrong and say it's fine when it's 
| not.  But that's easy to fix:  just make a new release that does require 

Sure.

We have always increased the higher-order version number when that is needed.

One problem with your proposal is that the testing code may run after the
package load, and in the case where it matters ... that very code may not get
reached because the package didn't load.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From kirill.mueller at ivt.baug.ethz.ch  Fri Dec 16 18:34:42 2016
From: kirill.mueller at ivt.baug.ethz.ch (=?UTF-8?Q?Kirill_M=c3=bcller?=)
Date: Fri, 16 Dec 2016 18:34:42 +0100
Subject: [Rd] Upgrading a package to which other packages are LinkingTo
In-Reply-To: <22612.5114.200686.241246@max.nulle.part>
References: <e04b65b6-bb5e-b0ae-9c30-761c20ad24a4@ivt.baug.ethz.ch>
	<341cb7cf-03f6-d70d-464f-a87c77617c9b@gmail.com>
	<22611.60978.786479.630863@max.nulle.part>
	<8555d7b8-e2da-38f7-f133-9e7d46cf74b6@gmail.com>
	<22612.2793.857104.239264@max.nulle.part>
	<52a8bf02-b3d0-51a4-3bb3-162758156623@gmail.com>
	<22612.5114.200686.241246@max.nulle.part>
Message-ID: <491cc6a5-19c4-4b81-8ec6-e64abfdabacd@ivt.baug.ethz.ch>

Thanks for discussing this.

On 16.12.2016 17:19, Dirk Eddelbuettel wrote:
> On 16 December 2016 at 11:00, Duncan Murdoch wrote:
> | On 16/12/2016 10:40 AM, Dirk Eddelbuettel wrote:
> | > On 16 December 2016 at 10:14, Duncan Murdoch wrote:
> | > | On 16/12/2016 8:37 AM, Dirk Eddelbuettel wrote:
> | > | >
> | > | > On 16 December 2016 at 08:20, Duncan Murdoch wrote:
> | > | > | Perhaps the solution is to recommend that packages which export their
> | > | > | C-level entry points either guarantee them not to change or offer
> | > | > | (require?) version checks by user code.  So dplyr should start out by
> | > | > | saying "I'm using Rcpp interface 0.12.8".  If Rcpp has a new version
> | > | > | with a compatible interface, it replies "that's fine".  If Rcpp has
> | > | > | changed its interface, it says "Sorry, I don't support that any more."
Sounds good to me, I was considering something similar. dplyr can simply 
query Rcpp's current version in .onLoad(), compare it to the version at 
installation time and act accordingly.
> | > | >
> | > | > We try. But it's hard, and I'd argue, likely impossible.
> | > | >
> | > | > For example I even added a "frozen" package [1] in the sources / unit tests
> | > | > to test for just this. In practice you just cannot hit every possible access
> | > | > point of the (rich, in our case) API so the tests pass too often.
> | > | >
> | > | > Which is why we relentlessly test against reverse-depends to _at least ensure
> | > | > buildability_ from our releases.
> | >
> | > I meant to also add:  "... against a large corpus of other packages."
> | > The intent is to empirically answer this.
> | >
> | > | > As for seamless binary upgrade, I don't think in can work in practice.  Ask
> | > | > Uwe one day we he rebuilds everything every time on Windows. And for what it
> | > | > is worth, we essentially do the same in Debian.
> | > | >
> | > | > Sometimes you just need to rebuild.  That may be the price of admission for
> | > | > using the convenience of rich C++ interfaces.
> | > | >
> | > |
> | > | Okay, so would you say that Kirill's suggestion is not overkill?  Every
> | > | time package B uses LinkingTo: A, R should assume it needs to rebuild B
> | > | when A is updated?
> | >
> | > Based on my experience is a "halting problem" -- i.e. cannot know ex ante.
> | >
> | > So "every time" would be overkill to me.  Sometimes you know you must
> | > recompile (but try to be very prudent with public-facing API).  Many times
> | > you do not. It is hard to pin down.
I'd argue that recompiling/reinstalling B is cheap enough and the safest 
option. So unless there is a risk, why not simply do it every time A 
updates? This could be implemented with a perhaps small change in R: 
When installing A, treat all packages that have A in both LinkingTo and 
Imports as dependencies that need to be reinstalled.


-Kirill
> | >
> | > At work we have a bunch of servers with Rcpp and many packages against them
> | > (installed system-wide for all users). We _very really_ needs rebuild.
>
> Edit:  "We _very rarely_ need rebuilds" is what was meant there.
>   
> | So that comes back to my suggestion:  you should provide a way for a
> | dependent package to ask if your API has changed.  If you say it hasn't,
> | the package is fine.  If you say it has, the package should abort,
> | telling the user they need to reinstall it.  (Because it's a hard
> | question to answer, you might get it wrong and say it's fine when it's
> | not.  But that's easy to fix:  just make a new release that does require
>
> Sure.
>
> We have always increased the higher-order version number when that is needed.
>
> One problem with your proposal is that the testing code may run after the
> package load, and in the case where it matters ... that very code may not get
> reached because the package didn't load.
>
> Dirk
>


From kmillar at google.com  Fri Dec 16 18:35:39 2016
From: kmillar at google.com (Karl Millar)
Date: Fri, 16 Dec 2016 09:35:39 -0800
Subject: [Rd] Upgrading a package to which other packages are LinkingTo
In-Reply-To: <22612.5114.200686.241246@max.nulle.part>
References: <e04b65b6-bb5e-b0ae-9c30-761c20ad24a4@ivt.baug.ethz.ch>
	<341cb7cf-03f6-d70d-464f-a87c77617c9b@gmail.com>
	<22611.60978.786479.630863@max.nulle.part>
	<8555d7b8-e2da-38f7-f133-9e7d46cf74b6@gmail.com>
	<22612.2793.857104.239264@max.nulle.part>
	<52a8bf02-b3d0-51a4-3bb3-162758156623@gmail.com>
	<22612.5114.200686.241246@max.nulle.part>
Message-ID: <CABz6aZfAHMVLNo2hnYk8j8mjLyqq2LXvAUmqLVnj7cE7E8dQtw@mail.gmail.com>

A couple of points:
  - rebuilding dependent packages is needed if there is an ABI change,
not just an API change.  For packages like Rcpp which export inline
functions or macros that might have changed, this is potentially any
change to existing functions, but for packages like Matrix, it isn't
really an issue at all IIUC.

  - If we're looking into a way to check if package APIs are
compatible, then that's something that's relevant for all packages,
since they all export an R API.  I believe that CRAN only tests
package compatibility with the most recent versions of packages on
CRAN that import or depend on it.  There's no guarantee that a package
update won't contain API or behaviour changes that breaks older
versions of packages, packages not on CRAN or any scripts that use the
package, and these sorts of breakages do happen semi-regularly.

 - AFAICT, the only difference with packages like Rcpp is that you can
potentially have all of your CRAN packages at the latest version, but
some of them might have inlined code from an older version of Rcpp
even after running update.packages().  While that is an issue, in my
experience that's been a lot less trouble than the general case of
backwards compatibility.

Karl

On Fri, Dec 16, 2016 at 8:19 AM, Dirk Eddelbuettel <edd at debian.org> wrote:
>
> On 16 December 2016 at 11:00, Duncan Murdoch wrote:
> | On 16/12/2016 10:40 AM, Dirk Eddelbuettel wrote:
> | > On 16 December 2016 at 10:14, Duncan Murdoch wrote:
> | > | On 16/12/2016 8:37 AM, Dirk Eddelbuettel wrote:
> | > | >
> | > | > On 16 December 2016 at 08:20, Duncan Murdoch wrote:
> | > | > | Perhaps the solution is to recommend that packages which export their
> | > | > | C-level entry points either guarantee them not to change or offer
> | > | > | (require?) version checks by user code.  So dplyr should start out by
> | > | > | saying "I'm using Rcpp interface 0.12.8".  If Rcpp has a new version
> | > | > | with a compatible interface, it replies "that's fine".  If Rcpp has
> | > | > | changed its interface, it says "Sorry, I don't support that any more."
> | > | >
> | > | > We try. But it's hard, and I'd argue, likely impossible.
> | > | >
> | > | > For example I even added a "frozen" package [1] in the sources / unit tests
> | > | > to test for just this. In practice you just cannot hit every possible access
> | > | > point of the (rich, in our case) API so the tests pass too often.
> | > | >
> | > | > Which is why we relentlessly test against reverse-depends to _at least ensure
> | > | > buildability_ from our releases.
> | >
> | > I meant to also add:  "... against a large corpus of other packages."
> | > The intent is to empirically answer this.
> | >
> | > | > As for seamless binary upgrade, I don't think in can work in practice.  Ask
> | > | > Uwe one day we he rebuilds everything every time on Windows. And for what it
> | > | > is worth, we essentially do the same in Debian.
> | > | >
> | > | > Sometimes you just need to rebuild.  That may be the price of admission for
> | > | > using the convenience of rich C++ interfaces.
> | > | >
> | > |
> | > | Okay, so would you say that Kirill's suggestion is not overkill?  Every
> | > | time package B uses LinkingTo: A, R should assume it needs to rebuild B
> | > | when A is updated?
> | >
> | > Based on my experience is a "halting problem" -- i.e. cannot know ex ante.
> | >
> | > So "every time" would be overkill to me.  Sometimes you know you must
> | > recompile (but try to be very prudent with public-facing API).  Many times
> | > you do not. It is hard to pin down.
> | >
> | > At work we have a bunch of servers with Rcpp and many packages against them
> | > (installed system-wide for all users). We _very really_ needs rebuild.
>
> Edit:  "We _very rarely_ need rebuilds" is what was meant there.
>
> | So that comes back to my suggestion:  you should provide a way for a
> | dependent package to ask if your API has changed.  If you say it hasn't,
> | the package is fine.  If you say it has, the package should abort,
> | telling the user they need to reinstall it.  (Because it's a hard
> | question to answer, you might get it wrong and say it's fine when it's
> | not.  But that's easy to fix:  just make a new release that does require
>
> Sure.
>
> We have always increased the higher-order version number when that is needed.
>
> One problem with your proposal is that the testing code may run after the
> package load, and in the case where it matters ... that very code may not get
> reached because the package didn't load.
>
> Dirk
>
> --
> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Fri Dec 16 19:29:16 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 16 Dec 2016 13:29:16 -0500
Subject: [Rd] Upgrading a package to which other packages are LinkingTo
In-Reply-To: <CABz6aZfAHMVLNo2hnYk8j8mjLyqq2LXvAUmqLVnj7cE7E8dQtw@mail.gmail.com>
References: <e04b65b6-bb5e-b0ae-9c30-761c20ad24a4@ivt.baug.ethz.ch>
	<341cb7cf-03f6-d70d-464f-a87c77617c9b@gmail.com>
	<22611.60978.786479.630863@max.nulle.part>
	<8555d7b8-e2da-38f7-f133-9e7d46cf74b6@gmail.com>
	<22612.2793.857104.239264@max.nulle.part>
	<52a8bf02-b3d0-51a4-3bb3-162758156623@gmail.com>
	<22612.5114.200686.241246@max.nulle.part>
	<CABz6aZfAHMVLNo2hnYk8j8mjLyqq2LXvAUmqLVnj7cE7E8dQtw@mail.gmail.com>
Message-ID: <4bc01854-5884-3566-d300-1675ecca518c@gmail.com>

On 16/12/2016 12:35 PM, Karl Millar wrote:
> A couple of points:
>   - rebuilding dependent packages is needed if there is an ABI change,
> not just an API change.  For packages like Rcpp which export inline
> functions or macros that might have changed, this is potentially any
> change to existing functions, but for packages like Matrix, it isn't
> really an issue at all IIUC.

This is why someone else needs to do this, not me.  I know the three 
words that ABI stands for, but not what they mean in practice.

>
>   - If we're looking into a way to check if package APIs are
> compatible, then that's something that's relevant for all packages,
> since they all export an R API.  I believe that CRAN only tests
> package compatibility with the most recent versions of packages on
> CRAN that import or depend on it.  There's no guarantee that a package
> update won't contain API or behaviour changes that breaks older
> versions of packages, packages not on CRAN or any scripts that use the
> package, and these sorts of breakages do happen semi-regularly.

That's correct.
>
>  - AFAICT, the only difference with packages like Rcpp is that you can
> potentially have all of your CRAN packages at the latest version, but
> some of them might have inlined code from an older version of Rcpp
> even after running update.packages().  While that is an issue, in my
> experience that's been a lot less trouble than the general case of
> backwards compatibility.

I think that's an important difference.  Package authors can play nicely 
with each other and keep their sources completely compatible, and 
package users can still end up with broken libraries that aren't fixed 
by anything simpler than re-installing everything.

We do have (imperfect) processes in place to help with the general 
compatibility problem, but nothing to help with this one.

Duncan Murdoch

>
> Karl
>
> On Fri, Dec 16, 2016 at 8:19 AM, Dirk Eddelbuettel <edd at debian.org> wrote:
>>
>> On 16 December 2016 at 11:00, Duncan Murdoch wrote:
>> | On 16/12/2016 10:40 AM, Dirk Eddelbuettel wrote:
>> | > On 16 December 2016 at 10:14, Duncan Murdoch wrote:
>> | > | On 16/12/2016 8:37 AM, Dirk Eddelbuettel wrote:
>> | > | >
>> | > | > On 16 December 2016 at 08:20, Duncan Murdoch wrote:
>> | > | > | Perhaps the solution is to recommend that packages which export their
>> | > | > | C-level entry points either guarantee them not to change or offer
>> | > | > | (require?) version checks by user code.  So dplyr should start out by
>> | > | > | saying "I'm using Rcpp interface 0.12.8".  If Rcpp has a new version
>> | > | > | with a compatible interface, it replies "that's fine".  If Rcpp has
>> | > | > | changed its interface, it says "Sorry, I don't support that any more."
>> | > | >
>> | > | > We try. But it's hard, and I'd argue, likely impossible.
>> | > | >
>> | > | > For example I even added a "frozen" package [1] in the sources / unit tests
>> | > | > to test for just this. In practice you just cannot hit every possible access
>> | > | > point of the (rich, in our case) API so the tests pass too often.
>> | > | >
>> | > | > Which is why we relentlessly test against reverse-depends to _at least ensure
>> | > | > buildability_ from our releases.
>> | >
>> | > I meant to also add:  "... against a large corpus of other packages."
>> | > The intent is to empirically answer this.
>> | >
>> | > | > As for seamless binary upgrade, I don't think in can work in practice.  Ask
>> | > | > Uwe one day we he rebuilds everything every time on Windows. And for what it
>> | > | > is worth, we essentially do the same in Debian.
>> | > | >
>> | > | > Sometimes you just need to rebuild.  That may be the price of admission for
>> | > | > using the convenience of rich C++ interfaces.
>> | > | >
>> | > |
>> | > | Okay, so would you say that Kirill's suggestion is not overkill?  Every
>> | > | time package B uses LinkingTo: A, R should assume it needs to rebuild B
>> | > | when A is updated?
>> | >
>> | > Based on my experience is a "halting problem" -- i.e. cannot know ex ante.
>> | >
>> | > So "every time" would be overkill to me.  Sometimes you know you must
>> | > recompile (but try to be very prudent with public-facing API).  Many times
>> | > you do not. It is hard to pin down.
>> | >
>> | > At work we have a bunch of servers with Rcpp and many packages against them
>> | > (installed system-wide for all users). We _very really_ needs rebuild.
>>
>> Edit:  "We _very rarely_ need rebuilds" is what was meant there.
>>
>> | So that comes back to my suggestion:  you should provide a way for a
>> | dependent package to ask if your API has changed.  If you say it hasn't,
>> | the package is fine.  If you say it has, the package should abort,
>> | telling the user they need to reinstall it.  (Because it's a hard
>> | question to answer, you might get it wrong and say it's fine when it's
>> | not.  But that's easy to fix:  just make a new release that does require
>>
>> Sure.
>>
>> We have always increased the higher-order version number when that is needed.
>>
>> One problem with your proposal is that the testing code may run after the
>> package load, and in the case where it matters ... that very code may not get
>> reached because the package didn't load.
>>
>> Dirk
>>
>> --
>> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From csardi.gabor at gmail.com  Fri Dec 16 22:27:28 2016
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Fri, 16 Dec 2016 21:27:28 +0000
Subject: [Rd] Upgrading a package to which other packages are LinkingTo
In-Reply-To: <4bc01854-5884-3566-d300-1675ecca518c@gmail.com>
References: <e04b65b6-bb5e-b0ae-9c30-761c20ad24a4@ivt.baug.ethz.ch>
	<341cb7cf-03f6-d70d-464f-a87c77617c9b@gmail.com>
	<22611.60978.786479.630863@max.nulle.part>
	<8555d7b8-e2da-38f7-f133-9e7d46cf74b6@gmail.com>
	<22612.2793.857104.239264@max.nulle.part>
	<52a8bf02-b3d0-51a4-3bb3-162758156623@gmail.com>
	<22612.5114.200686.241246@max.nulle.part>
	<CABz6aZfAHMVLNo2hnYk8j8mjLyqq2LXvAUmqLVnj7cE7E8dQtw@mail.gmail.com>
	<4bc01854-5884-3566-d300-1675ecca518c@gmail.com>
Message-ID: <CABtg=Kno5kv+YcisXc+UmEQv0xS33re3MGOZXYus=U=qeGz9Dw@mail.gmail.com>

I think that this problem is actually more general than just ABI
versioning. The common definition of ABI refers to compiled code, but
with R packages similar problems might happen (and they to happen)
without any compiled code.

I think the key issue is the concept of build-time dependencies. While
R packages usually does not distinguish between build-time and
run-time dependencies, they still do exist, and I think ideally we
would need to treat them differently.

AFAIK LinkingTo is the only form of a build-time dependency, that is
completely explicit, so it is relatively easy to handle. The other
frequent of build-time dependency is a function call to the other
package, that happens at install time. E.g. with references or R6*
classes you frequently include code like this in yourpackage:

myclass <- R6::R6Class(...)

and this code is evaluated at install time. So if the R6 package is
updated, the installed version myclass in yourpackage is not affected
at all. In fact, if the new version of R6 is not compatible with the
myclass object created by the old version, then yourpackage will be
broken. (This AFAIK cannot happen with R6, so it is not the best
example, but it can happen in other similar cases.)

The key here is that R6 is a build-time dependency of yourpackage,
similarly to packages linking to (i.e. LinkingTo) Rpp.

Another possible type of build-time dependency is if you put objects
from another package in yourpackage. E.g.

myfun <- otherpkg::fun

Then a copy of otherpkg::fun will be saved in yourpackage. If you
install a new version of otherpkg, yourpackage is unaffected, and if
otherpkg::fun uses some (possibly internal) API from otherpkg, that
has changed in the new version of otherpkg, you might easily end up
with a broken yourpackage again.

I think one lesson is to avoid running code at install time. This is
not a new thing, AFAIR it is even mentioned in 'Writing R extensions'.
Instead of running code at install time, you might consider running it
in `.onLoad()`, and then these "problems" go away. But you obviously
cannot always avoid it.

Gabor

* I think the R6 package is great, and I am not speaking in any way
against it. I just needed an example, and I know R6 much better than
reference classes, or other similar packages.


From hpages at fredhutch.org  Sat Dec 17 02:07:10 2016
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Fri, 16 Dec 2016 17:07:10 -0800
Subject: [Rd] syntax difference clusterExport in parallel and snow
In-Reply-To: <ea0a9ca1-39bd-1407-3458-de4cd5259596@stats.ox.ac.uk>
References: <CAErODj-ZqYvuvvS3wdF7L2O7-JJwSi7-wi6Jtp4UPmrZ4j+aQA@mail.gmail.com>
	<ea0a9ca1-39bd-1407-3458-de4cd5259596@stats.ox.ac.uk>
Message-ID: <96989ce0-87c9-cd8d-edd2-a057b9a1ddef@fredhutch.org>

On 12/13/2016 09:33 AM, Prof Brian Ripley wrote:
> On 13/12/2016 17:05, Paul Johnson wrote:
>> We got some errors and eventually figured out that
>> parallel::clusterExport second argument is "varlist" while in
>> snow::clusterExport it is "list".
>>
>> The user had loaded parallel first, but did something else which
>> inadvertently loaded snow, then clusterExport failed because we had
>> "varlist" and not "list".
>>
>> Are these different on purpose?
>
> Yes.
>
> ('list' is an unhelpful name for an argument that is not a list.)
>
>

Yes 'list' is a misleading name for a character vector. OTOH I guess
snow::clusterExport() was just following the lead of base::save() and
base::remove() on this.

I don't see 'varlist' as being much less confusing though: it still
suggests that the thing is a list and parallel::clusterExport() is
now inconsistent with snow::clusterExport(). So it doesn't really
address the 1st problem and introduces a new one. Sounds like using
a plural form instead of the "list" prefix would be less confusing
e.g. 'vars', 'varnames', 'objnames' or something like that.

H.

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From spencer.graves at prodsyse.com  Sat Dec 17 22:44:51 2016
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Sat, 17 Dec 2016 15:44:51 -0600
Subject: [Rd] Fwd: Re: RSiteSearch, sos, rdocumentation.org, ...?
In-Reply-To: <20161217203224.GA15075@upenn.edu>
References: <20160907201522.GA12554@psych.upenn.edu>
	<20518b79-b272-b848-a736-a9acf225626b@prodsyse.com>
	<20160907205321.GB24417@psych.upenn.edu>
	<20160908020657.GA27642@psych.upenn.edu>
	<20160908100100.GA30732@psych.upenn.edu>
	<b7e7da04-0154-3dcb-fda9-be1d0dc13929@prodsyse.com>
	<20161217203224.GA15075@upenn.edu>
Message-ID: <07ea49f0-2d70-615b-96c2-cbcf45aa5034@prodsyse.com>

Hi, Jonathan:


       Thanks for letting us know.  I can't imagine that the 
unavailability of RSiteSearch would be more than an inconvenience.


       When you get time, I'd like to know more about what you know 
about how it was hacked, the host operating system, any anti-virus / 
Internet protection software that failed and anything you think might 
reduce the risk of a repeat in the future.


       Best Wishes,
       Spencer Graves


On 12/17/2016 2:32 PM, Jonathan Baron wrote:
> Spencer and others.
>
> I am going to have to take down the server for RSiteSearch, which is
> finzi.psych.upenn.edu, for at least a couple of days starting Sunday
> morning. It has been hacked. And I have another server that has also
> been hacked, which is higher priority (sjdm.org). On Monday, I will
> probably have time to rebuild that one, but I may not have time to
> rebuild finzi for another week. I will try to get it all done in one
> day, but I don't know if I can.
>
> Sorry about this.
>
> I thought that there was an alternative to this site, namely
> http://rdocumentation.org/
> but, as bad is my site is, that one, I think, is worse.
>
> Jon


From baron at upenn.edu  Sat Dec 17 21:32:24 2016
From: baron at upenn.edu (Jonathan Baron)
Date: Sat, 17 Dec 2016 15:32:24 -0500
Subject: [Rd] Fwd: Re: RSiteSearch, sos, rdocumentation.org, ...?
In-Reply-To: <b7e7da04-0154-3dcb-fda9-be1d0dc13929@prodsyse.com>
References: <20160907201522.GA12554@psych.upenn.edu>
	<20518b79-b272-b848-a736-a9acf225626b@prodsyse.com>
	<20160907205321.GB24417@psych.upenn.edu>
	<20160908020657.GA27642@psych.upenn.edu>
	<20160908100100.GA30732@psych.upenn.edu>
	<b7e7da04-0154-3dcb-fda9-be1d0dc13929@prodsyse.com>
Message-ID: <20161217203224.GA15075@upenn.edu>

Spencer and others.

I am going to have to take down the server for RSiteSearch, which is
finzi.psych.upenn.edu, for at least a couple of days starting Sunday
morning. It has been hacked. And I have another server that has also
been hacked, which is higher priority (sjdm.org). On Monday, I will
probably have time to rebuild that one, but I may not have time to
rebuild finzi for another week. I will try to get it all done in one
day, but I don't know if I can.

Sorry about this.

I thought that there was an alternative to this site, namely
http://rdocumentation.org/
but, as bad is my site is, that one, I think, is worse.

Jon


From henrik.bengtsson at gmail.com  Mon Dec 19 17:55:10 2016
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Mon, 19 Dec 2016 08:55:10 -0800
Subject: [Rd] Startup process: Objects are automatically print():ed
Message-ID: <CAFDcVCSGoTQATTGzYd3GiZC6xkcWsaW3zWmg-Nj8nRcTx4=4Ww@mail.gmail.com>

Consider a `~/.Rprofile` file containing:

print("hello")
"world"
invisible("!")

This will output the following:

[1] "hello"
[1] "world"

when R is started.  Note that "world" is also print():ed.  In
contrast, if you'd source() the same file, then you'd need to use
argument print.eval = TRUE to get the same behavior:

> source("~/.Rprofile")
[1] "hello"
> source("~/.Rprofile", print.eval = TRUE)
[1] "hello"
[1] "world"
```

I am aware that the R startup process is special in many ways, e.g. it
happens very early on and only the base package is loaded.  However,
is the automatic print():ing of objects by design, a side effect, or a
bug?  It appears to not be documented, at least not in help("Startup",
package = "base").

/Henrik

PS. I've got a bit of a deja vu while writing this - I might have
already brought this one up many years ago.

> sessionInfo()
R version 3.3.2 (2016-10-31)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 16.04.1 LTS

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


From J.Gorecki at wit.edu.pl  Tue Dec 20 02:27:02 2016
From: J.Gorecki at wit.edu.pl (Jan Gorecki)
Date: Tue, 20 Dec 2016 01:27:02 +0000
Subject: [Rd] colnames for data.frame could be greatly improved
Message-ID: <CABE2sp5=-rL8_EkwSngruhfrF8mEDn_-RO6UN2PA538S+Revpw@mail.gmail.com>

Hello,

colnames seems to be not optimized well for data.frame. It escapes
processing for data.frame in

  if (is.data.frame(x) && do.NULL)
    return(names(x))

but only when do.NULL true. This makes huge difference when do.NULL
false. Minimal edit to `colnames`:

    if (is.data.frame(x)) {
        nm <- names(x)
        if (do.NULL || !is.null(nm))
            return(nm)
        else
            return(paste0(prefix, seq_along(x)))
    }

Script and timings:

N=1e7; K=100
set.seed(1)
DF <- data.frame(
    id1 = sample(sprintf("id%03d",1:K), N, TRUE),      # large groups (char)
    id2 = sample(sprintf("id%03d",1:K), N, TRUE),      # large groups (char)
    id3 = sample(sprintf("id%010d",1:(N/K)), N, TRUE), # small groups (char)
    id4 = sample(K, N, TRUE),                          # large groups (int)
    id5 = sample(K, N, TRUE),                          # large groups (int)
    id6 = sample(N/K, N, TRUE),                        # small groups (int)
    v1 =  sample(5, N, TRUE),                          # int in range [1,5]
    v2 =  sample(5, N, TRUE),                          # int in range [1,5]
    v3 =  sample(round(runif(100,max=100),4), N, TRUE) # numeric e.g. 23.5749
)
cat("GB =", round(sum(gc()[,2])/1024, 3), "\n")
#GB = 0.397
colnames(DF) = NULL
system.time(nm1<-colnames(DF, FALSE))
#   user  system elapsed
# 22.158   0.299  22.498
print(nm1)
#[1] "col1" "col2" "col3" "col4" "col5" "col6" "col7" "col8" "col9"

### restart R

colnames <- function (x, do.NULL = TRUE, prefix = "col")
{
    if (is.data.frame(x)) {
        nm <- names(x)
        if (do.NULL || !is.null(nm))
            return(nm)
        else
            return(paste0(prefix, seq_along(x)))
    }
    dn <- dimnames(x)
    if (!is.null(dn[[2L]]))
        dn[[2L]]
    else {
        nc <- NCOL(x)
        if (do.NULL)
            NULL
        else if (nc > 0L)
            paste0(prefix, seq_len(nc))
        else character()
    }
}
N=1e7; K=100
set.seed(1)
DF <- data.frame(
    id1 = sample(sprintf("id%03d",1:K), N, TRUE),      # large groups (char)
    id2 = sample(sprintf("id%03d",1:K), N, TRUE),      # large groups (char)
    id3 = sample(sprintf("id%010d",1:(N/K)), N, TRUE), # small groups (char)
    id4 = sample(K, N, TRUE),                          # large groups (int)
    id5 = sample(K, N, TRUE),                          # large groups (int)
    id6 = sample(N/K, N, TRUE),                        # small groups (int)
    v1 =  sample(5, N, TRUE),                          # int in range [1,5]
    v2 =  sample(5, N, TRUE),                          # int in range [1,5]
    v3 =  sample(round(runif(100,max=100),4), N, TRUE) # numeric e.g. 23.5749
)
cat("GB =", round(sum(gc()[,2])/1024, 3), "\n")
#GB = 0.397
colnames(DF) = NULL
system.time(nm1<-colnames(DF, FALSE))
#   user  system elapsed
#  0.001   0.000   0.000
print(nm1)
#[1] "col1" "col2" "col3" "col4" "col5" "col6" "col7" "col8" "col9"

sessionInfo()
#R Under development (unstable) (2016-12-19 r71815)
#Platform: x86_64-pc-linux-gnu (64-bit)
#Running under: Debian GNU/Linux stretch/sid
#
#locale:
# [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
# [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
# [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
# [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
# [9] LC_ADDRESS=C               LC_TELEPHONE=C
#[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
#
#attached base packages:
#[1] stats     graphics  grDevices utils     datasets  methods   base  #
#
#loaded via a namespace (and not attached):
#[1] compiler_3.4.0


From sbronder at stevebronder.com  Tue Dec 20 03:01:44 2016
From: sbronder at stevebronder.com (Steve Bronder)
Date: Mon, 19 Dec 2016 21:01:44 -0500
Subject: [Rd] Request: Increasing MAX_NUM_DLLS in Rdynload.c
Message-ID: <CAAVP=akpmJ2gDdDXNPTOh-fFNAy-B52v0QRp6FaNRfhW9F_ZKw@mail.gmail.com>

This is a request to increase MAX_NUM_DLLS in Rdynload.c in from 100 to 500.

On line 131 of Rdynload.c, changing

#define MAX_NUM_DLLS 100

 to

#define MAX_NUM_DLLS 500


In development of the mlr package, there have been several episodes in the
past where we have had to break up unit tests because of the "maximum
number of DLLs reached" error. This error has been an inconvenience that is
going to keep happening as the package continues to grow. Is there more
than meets the eye with this error or would everything be okay if the above
line changes? Would that have a larger effect in other parts of R?

As R grows, we are likely to see more 'meta-packages' such as the
Hadley-verse, caret, mlr, etc. need an increasing amount of DLLs loaded at
any point in time to conduct effective unit tests. If  MAX_NUM_DLLS is set
to 100 for a very particular reason than I apologize, but if it is possible
to increase MAX_NUM_DLLS it would at least make the testing at mlr much
easier.

I understand you are all very busy and thank you for your time.


Regards,

Steve Bronder
Website: stevebronder.com
Phone: 412-719-1282
Email: sbronder at stevebronder.com

	[[alternative HTML version deleted]]


From henrik.bengtsson at gmail.com  Tue Dec 20 07:04:28 2016
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Mon, 19 Dec 2016 22:04:28 -0800
Subject: [Rd] Request: Increasing MAX_NUM_DLLS in Rdynload.c
In-Reply-To: <CAAVP=akpmJ2gDdDXNPTOh-fFNAy-B52v0QRp6FaNRfhW9F_ZKw@mail.gmail.com>
References: <CAAVP=akpmJ2gDdDXNPTOh-fFNAy-B52v0QRp6FaNRfhW9F_ZKw@mail.gmail.com>
Message-ID: <CAFDcVCTOtaX0cxAZo8hh3mZdp75Xx7UZ4Kry5C+EUxZoqhA8Dw@mail.gmail.com>

On reason for hitting the MAX_NUM_DLLS (= 100) limit is because some
packages don't unload their DLLs when they being unloaded themselves.
In other words, there may be left-over DLLs just sitting there doing
nothing but occupying space.  You can remove these, using:

   R.utils::gcDLLs()

Maybe that will help you get through your tests (as long as you're
unloading packages).  gcDLLs() will look at base::getLoadedDLLs() and
its content and compare to loadedNamespaces() and unregister any
"stray" DLLs that remain after corresponding packages have been
unloaded.

I think it would be useful if R CMD check would also check that DLLs
are unregistered when a package is unloaded
(https://github.com/HenrikBengtsson/Wishlist-for-R/issues/29), but of
course, someone needs to write the code / a patch for this to happen.

/Henrik

On Mon, Dec 19, 2016 at 6:01 PM, Steve Bronder
<sbronder at stevebronder.com> wrote:
> This is a request to increase MAX_NUM_DLLS in Rdynload.c in from 100 to 500.
>
> On line 131 of Rdynload.c, changing
>
> #define MAX_NUM_DLLS 100
>
>  to
>
> #define MAX_NUM_DLLS 500
>
>
> In development of the mlr package, there have been several episodes in the
> past where we have had to break up unit tests because of the "maximum
> number of DLLs reached" error. This error has been an inconvenience that is
> going to keep happening as the package continues to grow. Is there more
> than meets the eye with this error or would everything be okay if the above
> line changes? Would that have a larger effect in other parts of R?
>
> As R grows, we are likely to see more 'meta-packages' such as the
> Hadley-verse, caret, mlr, etc. need an increasing amount of DLLs loaded at
> any point in time to conduct effective unit tests. If  MAX_NUM_DLLS is set
> to 100 for a very particular reason than I apologize, but if it is possible
> to increase MAX_NUM_DLLS it would at least make the testing at mlr much
> easier.
>
> I understand you are all very busy and thank you for your time.
>
>
> Regards,
>
> Steve Bronder
> Website: stevebronder.com
> Phone: 412-719-1282
> Email: sbronder at stevebronder.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From sbronder at stevebronder.com  Tue Dec 20 07:34:31 2016
From: sbronder at stevebronder.com (Steve Bronder)
Date: Tue, 20 Dec 2016 01:34:31 -0500
Subject: [Rd] Request: Increasing MAX_NUM_DLLS in Rdynload.c
In-Reply-To: <CAFDcVCTOtaX0cxAZo8hh3mZdp75Xx7UZ4Kry5C+EUxZoqhA8Dw@mail.gmail.com>
References: <CAAVP=akpmJ2gDdDXNPTOh-fFNAy-B52v0QRp6FaNRfhW9F_ZKw@mail.gmail.com>
	<CAFDcVCTOtaX0cxAZo8hh3mZdp75Xx7UZ4Kry5C+EUxZoqhA8Dw@mail.gmail.com>
Message-ID: <CAAVP=an9yD_E22KF3q-Bh-XxVzyaEYaic-iTpzCZVxv25G2QnA@mail.gmail.com>

Thanks Henrik this is very helpful! I will try this out on our tests and
see if gcDLLs() has a positive effect.

mlr currently has tests broken down by learner type such as classification,
regression, forecasting, clustering, etc.. There are 83 classifiers alone
so even when loading and unloading across learner types we can still hit
the MAX_NUM_DLLS error, meaning we'll have to break them down further (or
maybe we can be clever with gcDLLs()?). I'm CC'ing Lars Kotthoff and Bernd
Bischl to make sure I am representing the issue well.

Regards,

Steve Bronder
Website: stevebronder.com
Phone: 412-719-1282
Email: sbronder at stevebronder.com


On Tue, Dec 20, 2016 at 1:04 AM, Henrik Bengtsson <
henrik.bengtsson at gmail.com> wrote:

> On reason for hitting the MAX_NUM_DLLS (= 100) limit is because some
> packages don't unload their DLLs when they being unloaded themselves.
> In other words, there may be left-over DLLs just sitting there doing
> nothing but occupying space.  You can remove these, using:
>
>    R.utils::gcDLLs()
>
> Maybe that will help you get through your tests (as long as you're
> unloading packages).  gcDLLs() will look at base::getLoadedDLLs() and
> its content and compare to loadedNamespaces() and unregister any
> "stray" DLLs that remain after corresponding packages have been
> unloaded.
>
> I think it would be useful if R CMD check would also check that DLLs
> are unregistered when a package is unloaded
> (https://github.com/HenrikBengtsson/Wishlist-for-R/issues/29), but of
> course, someone needs to write the code / a patch for this to happen.
>
> /Henrik
>
> On Mon, Dec 19, 2016 at 6:01 PM, Steve Bronder
> <sbronder at stevebronder.com> wrote:
> > This is a request to increase MAX_NUM_DLLS in Rdynload.c in from 100 to
> 500.
> >
> > On line 131 of Rdynload.c, changing
> >
> > #define MAX_NUM_DLLS 100
> >
> >  to
> >
> > #define MAX_NUM_DLLS 500
> >
> >
> > In development of the mlr package, there have been several episodes in
> the
> > past where we have had to break up unit tests because of the "maximum
> > number of DLLs reached" error. This error has been an inconvenience that
> is
> > going to keep happening as the package continues to grow. Is there more
> > than meets the eye with this error or would everything be okay if the
> above
> > line changes? Would that have a larger effect in other parts of R?
> >
> > As R grows, we are likely to see more 'meta-packages' such as the
> > Hadley-verse, caret, mlr, etc. need an increasing amount of DLLs loaded
> at
> > any point in time to conduct effective unit tests. If  MAX_NUM_DLLS is
> set
> > to 100 for a very particular reason than I apologize, but if it is
> possible
> > to increase MAX_NUM_DLLS it would at least make the testing at mlr much
> > easier.
> >
> > I understand you are all very busy and thank you for your time.
> >
> >
> > Regards,
> >
> > Steve Bronder
> > Website: stevebronder.com
> > Phone: 412-719-1282
> > Email: sbronder at stevebronder.com
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From jeroen.ooms at stat.ucla.edu  Tue Dec 20 12:40:44 2016
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Tue, 20 Dec 2016 12:40:44 +0100
Subject: [Rd] Request: Increasing MAX_NUM_DLLS in Rdynload.c
In-Reply-To: <CAFDcVCTOtaX0cxAZo8hh3mZdp75Xx7UZ4Kry5C+EUxZoqhA8Dw@mail.gmail.com>
References: <CAAVP=akpmJ2gDdDXNPTOh-fFNAy-B52v0QRp6FaNRfhW9F_ZKw@mail.gmail.com>
	<CAFDcVCTOtaX0cxAZo8hh3mZdp75Xx7UZ4Kry5C+EUxZoqhA8Dw@mail.gmail.com>
Message-ID: <CABFfbXttbp1JCad8XztMfzgmLDBPm6o8Wz8wXSC72iXhT2Ab8g@mail.gmail.com>

On Tue, Dec 20, 2016 at 7:04 AM, Henrik Bengtsson
<henrik.bengtsson at gmail.com> wrote:
> On reason for hitting the MAX_NUM_DLLS (= 100) limit is because some
> packages don't unload their DLLs when they being unloaded themselves.

I am surprised by this. Why does R not do this automatically? What is
the case for keeping the DLL loaded after the package has been
unloaded? What happens if you reload another version of the same
package from a different library after unloading?


From florent.angly at gmail.com  Tue Dec 20 13:26:36 2016
From: florent.angly at gmail.com (Florent Angly)
Date: Tue, 20 Dec 2016 13:26:36 +0100
Subject: [Rd] Very small numbers in hexadecimal notation parsed as zero
Message-ID: <CAOiMVK3atf7-Vj96VMcfqDdRMnM2_9fU5t2DoZC_TNeMxo=toQ@mail.gmail.com>

Hi all,

I have noticed incorrect parsing of very small hexadecimal numbers
like "0x1.00000000d0000p-987". Such a hexadecimal representation can
can be produced by sprintf() using the %a flag. The return value is
incorrectly reported as 0 when coercing these numbers to double using
as.double()/as.numeric(), as illustrated in the three examples below:

as.double("0x1.00000000d0000p-987")    # should be 7.645296e-298
as.double("0x1.0000000000000p-1022")  # should be 2.225074e-308
as.double("0x1.f89fc1a6f6613p-974")      # should be 1.23456e-293

The culprit seems to be the src/main/util.c:R_strtod function and in
some cases, removing the zeroes directly before the 'p' leads to
correct parsing:

as.double("0x1.00000000dp-987") # 7.645296e-298, as expected
as.double("0x1.p-1022")               # 2.225074e-308, as expected

I wrote a small program (in a file called "strtod.c") to compare the R
stdtod implementation to a C implementation. The C implementation
never reported 0 in the examples given above:

#include <stdlib.h>
#include <stdio.h>
int main(void)
{
   char *string, *stopstring;
   double x;

   string = "0x1.00000000d0000p-987";
   x = strtod(string, &stopstring);
   printf("string = \"%s\"\n", string);
   printf("strtod = %.17g\n\n", x);

   string = "0x1.00000000dp-987";
   x = strtod(string, &stopstring);
   printf("string = \"%s\"\n", string);
   printf("strtod = %.17g\n\n", x);
}

$ gcc -o strtod.exe strtod.c
$ ./strtod.exe
string = "0x1.00000000d0000p-987"
strtod = 7.6452955642246671e-298

string = "0x1.00000000dp-987"
strtod = 7.6452955642246671e-298

string = "0x1.0000000000000p-1022"
strtod = 2.2250738585072014e-308

string = "0x1.p-1022"
strtod = 2.2250738585072014e-308

string = "0x1.f89fc1a6f6613p-974"
strtod = 1.23456e-293


My sessionInfo() returns:
R version 3.3.2 (2016-10-31)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=German_Switzerland.1252
LC_CTYPE=German_Switzerland.1252
LC_MONETARY=German_Switzerland.1252 LC_NUMERIC=C
 LC_TIME=German_Switzerland.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


Regards,
Florent


From florent.angly at gmail.com  Tue Dec 20 13:42:37 2016
From: florent.angly at gmail.com (Florent Angly)
Date: Tue, 20 Dec 2016 13:42:37 +0100
Subject: [Rd] Unexpected I(NULL) output
Message-ID: <CAOiMVK21fs6VpZnQZ0jH0t5YeJ6TvcLyO7digyXBmzV23yEbpg@mail.gmail.com>

Hi all,

I believe there is an issue with passing NULL to the function I().

class(NULL)  # "NULL"  (as expected)
print(NULL)   # NULL  (as expected)
is.null(NULL) # TRUE  (as expected)

According to the documentation I() should return a copy of its input
with class "AsIs" preprended:

class(I(NULL))  # "AsIs"  (as expected)
print(I(NULL))   # list()  (not expected! should be NULL)
is.null(I(NULL)) # FALSE  (not expected! should be TRUE)

So, I() does not behave according to its documentation. In R, it is
not possible to give NULL attributes, but I(NULL) attempts to do that
nonetheless, using the structure() function. Probably:
1/ structure() should not accept NULL as input since the goal of
structure() is to set some attributes, something cannot be done on
NULL.
2/ I() could accept NULL, but, as an exception, not set an "AsIs"
class attribute on it. This would be in line with the philosophy of
the I() function to return an object that is functionally equivalent
to the input object.


My sessionInfo() returns:
> sessionInfo()
R version 3.3.2 (2016-10-31)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=German_Switzerland.1252
LC_CTYPE=German_Switzerland.1252
LC_MONETARY=German_Switzerland.1252 LC_NUMERIC=C
[5] LC_TIME=German_Switzerland.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

Best regards,

Florent


From kmillar at google.com  Tue Dec 20 16:39:32 2016
From: kmillar at google.com (Karl Millar)
Date: Tue, 20 Dec 2016 07:39:32 -0800
Subject: [Rd] Request: Increasing MAX_NUM_DLLS in Rdynload.c
In-Reply-To: <CABFfbXttbp1JCad8XztMfzgmLDBPm6o8Wz8wXSC72iXhT2Ab8g@mail.gmail.com>
References: <CAAVP=akpmJ2gDdDXNPTOh-fFNAy-B52v0QRp6FaNRfhW9F_ZKw@mail.gmail.com>
	<CAFDcVCTOtaX0cxAZo8hh3mZdp75Xx7UZ4Kry5C+EUxZoqhA8Dw@mail.gmail.com>
	<CABFfbXttbp1JCad8XztMfzgmLDBPm6o8Wz8wXSC72iXhT2Ab8g@mail.gmail.com>
Message-ID: <CABz6aZeVV+hzQtkD+9z2irKiVQBkVugwCthPum7=Ft3wmjyXig@mail.gmail.com>

It's not always clear when it's safe to remove the DLL.

The main problem that I'm aware of is that native objects with
finalizers might still exist (created by R_RegisterCFinalizer etc).
Even if there are no live references to such objects (which would be
hard to verify), it still wouldn't be safe to unload the DLL until a
full garbage collection has been done.

If the DLL is unloaded, then the function pointer that was registered
now becomes a pointer into the memory where the DLL was, leading to an
almost certain crash when such objects get garbage collected.

A better approach would be to just remove the limit on the number of
DLLs, dynamically expanding the array if/when needed.


On Tue, Dec 20, 2016 at 3:40 AM, Jeroen Ooms <jeroen.ooms at stat.ucla.edu> wrote:
> On Tue, Dec 20, 2016 at 7:04 AM, Henrik Bengtsson
> <henrik.bengtsson at gmail.com> wrote:
>> On reason for hitting the MAX_NUM_DLLS (= 100) limit is because some
>> packages don't unload their DLLs when they being unloaded themselves.
>
> I am surprised by this. Why does R not do this automatically? What is
> the case for keeping the DLL loaded after the package has been
> unloaded? What happens if you reload another version of the same
> package from a different library after unloading?
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Tue Dec 20 17:40:00 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 20 Dec 2016 17:40:00 +0100
Subject: [Rd] Request: Increasing MAX_NUM_DLLS in Rdynload.c
In-Reply-To: <CAAVP=an9yD_E22KF3q-Bh-XxVzyaEYaic-iTpzCZVxv25G2QnA@mail.gmail.com>
References: <CAAVP=akpmJ2gDdDXNPTOh-fFNAy-B52v0QRp6FaNRfhW9F_ZKw@mail.gmail.com>
	<CAFDcVCTOtaX0cxAZo8hh3mZdp75Xx7UZ4Kry5C+EUxZoqhA8Dw@mail.gmail.com>
	<CAAVP=an9yD_E22KF3q-Bh-XxVzyaEYaic-iTpzCZVxv25G2QnA@mail.gmail.com>
Message-ID: <22617.24288.140314.653221@stat.math.ethz.ch>

>>>>> Steve Bronder <sbronder at stevebronder.com>
>>>>>     on Tue, 20 Dec 2016 01:34:31 -0500 writes:

    > Thanks Henrik this is very helpful! I will try this out on our tests and
    > see if gcDLLs() has a positive effect.

    > mlr currently has tests broken down by learner type such as classification,
    > regression, forecasting, clustering, etc.. There are 83 classifiers alone
    > so even when loading and unloading across learner types we can still hit
    > the MAX_NUM_DLLS error, meaning we'll have to break them down further (or
    > maybe we can be clever with gcDLLs()?). I'm CC'ing Lars Kotthoff and Bernd
    > Bischl to make sure I am representing the issue well.

This came up *here* in May 2015
and then May 2016 ... did you not find it when googling.

Hint:  Use  
       site:stat.ethz.ch MAX_NUM_DLLS
as search string in Google, so it will basically only search the
R mailing list archives

Here's the start of that thread :

  https://stat.ethz.ch/pipermail/r-devel/2016-May/072637.html

There was not a clear conclusion back then, notably as
Prof Brian Ripley noted that 100 had already been an increase
and that a large number of loaded DLLs decreases look up speed.

OTOH (I think others have noted that) a large number of DLLs
only penalizes those who *do* load many, and we should probably
increase it.

Your use case of "hyper packages" which load many others
simultaneously is somewhat convincing to me... in so far as the
general feeling is that memory should be cheap and limits should
not be low.

(In spite of Brian Ripleys good reasons against it, I'd still
 aim for a *dynamic*, i.e. automatically increased list here).

Martin Maechler

    > Regards,

    > Steve Bronder
    > Website: stevebronder.com
    > Phone: 412-719-1282
    > Email: sbronder at stevebronder.com


    > On Tue, Dec 20, 2016 at 1:04 AM, Henrik Bengtsson <
    > henrik.bengtsson at gmail.com> wrote:

    >> On reason for hitting the MAX_NUM_DLLS (= 100) limit is because some
    >> packages don't unload their DLLs when they being unloaded themselves.
    >> In other words, there may be left-over DLLs just sitting there doing
    >> nothing but occupying space.  You can remove these, using:
    >> 
    >> R.utils::gcDLLs()
    >> 
    >> Maybe that will help you get through your tests (as long as you're
    >> unloading packages).  gcDLLs() will look at base::getLoadedDLLs() and
    >> its content and compare to loadedNamespaces() and unregister any
    >> "stray" DLLs that remain after corresponding packages have been
    >> unloaded.
    >> 
    >> I think it would be useful if R CMD check would also check that DLLs
    >> are unregistered when a package is unloaded
    >> (https://github.com/HenrikBengtsson/Wishlist-for-R/issues/29), but of
    >> course, someone needs to write the code / a patch for this to happen.
    >> 
    >> /Henrik
    >> 
    >> On Mon, Dec 19, 2016 at 6:01 PM, Steve Bronder
    >> <sbronder at stevebronder.com> wrote:
    >> > This is a request to increase MAX_NUM_DLLS in Rdynload.c in from 100 to
    >> 500.
    >> >
    >> > On line 131 of Rdynload.c, changing
    >> >
    >> > #define MAX_NUM_DLLS 100
    >> >
    >> >  to
    >> >
    >> > #define MAX_NUM_DLLS 500
    >> >
    >> >
    >> > In development of the mlr package, there have been several episodes in
    >> the
    >> > past where we have had to break up unit tests because of the "maximum
    >> > number of DLLs reached" error. This error has been an inconvenience that
    >> is
    >> > going to keep happening as the package continues to grow. Is there more
    >> > than meets the eye with this error or would everything be okay if the
    >> above
    >> > line changes? Would that have a larger effect in other parts of R?
    >> >
    >> > As R grows, we are likely to see more 'meta-packages' such as the
    >> > Hadley-verse, caret, mlr, etc. need an increasing amount of DLLs loaded
    >> at
    >> > any point in time to conduct effective unit tests. If  MAX_NUM_DLLS is
    >> set
    >> > to 100 for a very particular reason than I apologize, but if it is
    >> possible
    >> > to increase MAX_NUM_DLLS it would at least make the testing at mlr much
    >> > easier.
    >> >
    >> > I understand you are all very busy and thank you for your time.
    >> >
    >> >
    >> > Regards,
    >> >
    >> > Steve Bronder
    >> > Website: stevebronder.com
    >> > Phone: 412-719-1282
    >> > Email: sbronder at stevebronder.com
    >> >
    >> >         [[alternative HTML version deleted]]
    >> >
    >> > ______________________________________________
    >> > R-devel at r-project.org mailing list
    >> > https://stat.ethz.ch/mailman/listinfo/r-devel
    >> 

    > [[alternative HTML version deleted]]

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From edd at debian.org  Tue Dec 20 17:56:10 2016
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 20 Dec 2016 10:56:10 -0600
Subject: [Rd] Request: Increasing MAX_NUM_DLLS in Rdynload.c
In-Reply-To: <22617.24288.140314.653221@stat.math.ethz.ch>
References: <CAAVP=akpmJ2gDdDXNPTOh-fFNAy-B52v0QRp6FaNRfhW9F_ZKw@mail.gmail.com>
	<CAFDcVCTOtaX0cxAZo8hh3mZdp75Xx7UZ4Kry5C+EUxZoqhA8Dw@mail.gmail.com>
	<CAAVP=an9yD_E22KF3q-Bh-XxVzyaEYaic-iTpzCZVxv25G2QnA@mail.gmail.com>
	<22617.24288.140314.653221@stat.math.ethz.ch>
Message-ID: <22617.25258.765788.878896@max.nulle.part>


On 20 December 2016 at 17:40, Martin Maechler wrote:
| >>>>> Steve Bronder <sbronder at stevebronder.com>
| >>>>>     on Tue, 20 Dec 2016 01:34:31 -0500 writes:
| 
|     > Thanks Henrik this is very helpful! I will try this out on our tests and
|     > see if gcDLLs() has a positive effect.
| 
|     > mlr currently has tests broken down by learner type such as classification,
|     > regression, forecasting, clustering, etc.. There are 83 classifiers alone
|     > so even when loading and unloading across learner types we can still hit
|     > the MAX_NUM_DLLS error, meaning we'll have to break them down further (or
|     > maybe we can be clever with gcDLLs()?). I'm CC'ing Lars Kotthoff and Bernd
|     > Bischl to make sure I am representing the issue well.
| 
| This came up *here* in May 2015
| and then May 2016 ... did you not find it when googling.
| 
| Hint:  Use  
|        site:stat.ethz.ch MAX_NUM_DLLS
| as search string in Google, so it will basically only search the
| R mailing list archives
| 
| Here's the start of that thread :
| 
|   https://stat.ethz.ch/pipermail/r-devel/2016-May/072637.html
| 
| There was not a clear conclusion back then, notably as
| Prof Brian Ripley noted that 100 had already been an increase
| and that a large number of loaded DLLs decreases look up speed.
| 
| OTOH (I think others have noted that) a large number of DLLs
| only penalizes those who *do* load many, and we should probably
| increase it.
| 
| Your use case of "hyper packages" which load many others
| simultaneously is somewhat convincing to me... in so far as the
| general feeling is that memory should be cheap and limits should
| not be low.
| 
| (In spite of Brian Ripleys good reasons against it, I'd still
|  aim for a *dynamic*, i.e. automatically increased list here).

Yes.  Start with 10 or 20, add 10 as needed.  Still fast in the 'small N'
case and no longer a road block for the 'big N' case required by mlr et al.

As a C++ programmer, I am now going to hug my std::vector and quietly retreat.

Dirk

 
| Martin Maechler
| 
|     > Regards,
| 
|     > Steve Bronder
|     > Website: stevebronder.com
|     > Phone: 412-719-1282
|     > Email: sbronder at stevebronder.com
| 
| 
|     > On Tue, Dec 20, 2016 at 1:04 AM, Henrik Bengtsson <
|     > henrik.bengtsson at gmail.com> wrote:
| 
|     >> On reason for hitting the MAX_NUM_DLLS (= 100) limit is because some
|     >> packages don't unload their DLLs when they being unloaded themselves.
|     >> In other words, there may be left-over DLLs just sitting there doing
|     >> nothing but occupying space.  You can remove these, using:
|     >> 
|     >> R.utils::gcDLLs()
|     >> 
|     >> Maybe that will help you get through your tests (as long as you're
|     >> unloading packages).  gcDLLs() will look at base::getLoadedDLLs() and
|     >> its content and compare to loadedNamespaces() and unregister any
|     >> "stray" DLLs that remain after corresponding packages have been
|     >> unloaded.
|     >> 
|     >> I think it would be useful if R CMD check would also check that DLLs
|     >> are unregistered when a package is unloaded
|     >> (https://github.com/HenrikBengtsson/Wishlist-for-R/issues/29), but of
|     >> course, someone needs to write the code / a patch for this to happen.
|     >> 
|     >> /Henrik
|     >> 
|     >> On Mon, Dec 19, 2016 at 6:01 PM, Steve Bronder
|     >> <sbronder at stevebronder.com> wrote:
|     >> > This is a request to increase MAX_NUM_DLLS in Rdynload.c in from 100 to
|     >> 500.
|     >> >
|     >> > On line 131 of Rdynload.c, changing
|     >> >
|     >> > #define MAX_NUM_DLLS 100
|     >> >
|     >> >  to
|     >> >
|     >> > #define MAX_NUM_DLLS 500
|     >> >
|     >> >
|     >> > In development of the mlr package, there have been several episodes in
|     >> the
|     >> > past where we have had to break up unit tests because of the "maximum
|     >> > number of DLLs reached" error. This error has been an inconvenience that
|     >> is
|     >> > going to keep happening as the package continues to grow. Is there more
|     >> > than meets the eye with this error or would everything be okay if the
|     >> above
|     >> > line changes? Would that have a larger effect in other parts of R?
|     >> >
|     >> > As R grows, we are likely to see more 'meta-packages' such as the
|     >> > Hadley-verse, caret, mlr, etc. need an increasing amount of DLLs loaded
|     >> at
|     >> > any point in time to conduct effective unit tests. If  MAX_NUM_DLLS is
|     >> set
|     >> > to 100 for a very particular reason than I apologize, but if it is
|     >> possible
|     >> > to increase MAX_NUM_DLLS it would at least make the testing at mlr much
|     >> > easier.
|     >> >
|     >> > I understand you are all very busy and thank you for your time.
|     >> >
|     >> >
|     >> > Regards,
|     >> >
|     >> > Steve Bronder
|     >> > Website: stevebronder.com
|     >> > Phone: 412-719-1282
|     >> > Email: sbronder at stevebronder.com
|     >> >
|     >> >         [[alternative HTML version deleted]]
|     >> >
|     >> > ______________________________________________
|     >> > R-devel at r-project.org mailing list
|     >> > https://stat.ethz.ch/mailman/listinfo/r-devel
|     >> 
| 
|     > [[alternative HTML version deleted]]
| 
|     > ______________________________________________
|     > R-devel at r-project.org mailing list
|     > https://stat.ethz.ch/mailman/listinfo/r-devel
| 
| ______________________________________________
| R-devel at r-project.org mailing list
| https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From spencer.graves at prodsyse.com  Tue Dec 20 18:14:58 2016
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Tue, 20 Dec 2016 11:14:58 -0600
Subject: [Rd] Request: Increasing MAX_NUM_DLLS in Rdynload.c
In-Reply-To: <22617.25258.765788.878896@max.nulle.part>
References: <CAAVP=akpmJ2gDdDXNPTOh-fFNAy-B52v0QRp6FaNRfhW9F_ZKw@mail.gmail.com>
	<CAFDcVCTOtaX0cxAZo8hh3mZdp75Xx7UZ4Kry5C+EUxZoqhA8Dw@mail.gmail.com>
	<CAAVP=an9yD_E22KF3q-Bh-XxVzyaEYaic-iTpzCZVxv25G2QnA@mail.gmail.com>
	<22617.24288.140314.653221@stat.math.ethz.ch>
	<22617.25258.765788.878896@max.nulle.part>
Message-ID: <d140e7e2-4a76-31c8-1940-17c1ad17c4ad@prodsyse.com>

Hi, Dirk:


On 12/20/2016 10:56 AM, Dirk Eddelbuettel wrote:
> On 20 December 2016 at 17:40, Martin Maechler wrote:
> | >>>>> Steve Bronder <sbronder at stevebronder.com>
> | >>>>>     on Tue, 20 Dec 2016 01:34:31 -0500 writes:
> |
> |     > Thanks Henrik this is very helpful! I will try this out on our tests and
> |     > see if gcDLLs() has a positive effect.
> |
> |     > mlr currently has tests broken down by learner type such as classification,
> |     > regression, forecasting, clustering, etc.. There are 83 classifiers alone
> |     > so even when loading and unloading across learner types we can still hit
> |     > the MAX_NUM_DLLS error, meaning we'll have to break them down further (or
> |     > maybe we can be clever with gcDLLs()?). I'm CC'ing Lars Kotthoff and Bernd
> |     > Bischl to make sure I am representing the issue well.
> |
> | This came up *here* in May 2015
> | and then May 2016 ... did you not find it when googling.
> |
> | Hint:  Use
> |        site:stat.ethz.ch MAX_NUM_DLLS
> | as search string in Google, so it will basically only search the
> | R mailing list archives
> |
> | Here's the start of that thread :
> |
> |   https://stat.ethz.ch/pipermail/r-devel/2016-May/072637.html
> |
> | There was not a clear conclusion back then, notably as
> | Prof Brian Ripley noted that 100 had already been an increase
> | and that a large number of loaded DLLs decreases look up speed.
> |
> | OTOH (I think others have noted that) a large number of DLLs
> | only penalizes those who *do* load many, and we should probably
> | increase it.
> |
> | Your use case of "hyper packages" which load many others
> | simultaneously is somewhat convincing to me... in so far as the
> | general feeling is that memory should be cheap and limits should
> | not be low.
> |
> | (In spite of Brian Ripleys good reasons against it, I'd still
> |  aim for a *dynamic*, i.e. automatically increased list here).
>
> Yes.  Start with 10 or 20, add 10 as needed.  Still fast in the 'small N'
> case and no longer a road block for the 'big N' case required by mlr et al.
>
> As a C++ programmer, I am now going to hug my std::vector and quietly retreat.


May I humbly request a translation of "std::vector" for people like me 
who are not familiar with C++?


I got the following:


 > install.packages('std')
Warning in install.packages :
   package ?std? is not available (for R version 3.3.2)


       Thanks,
       Spencer Graves
>
> Dirk
>
>   
> | Martin Maechler
> |
> |     > Regards,
> |
> |     > Steve Bronder
> |     > Website: stevebronder.com
> |     > Phone: 412-719-1282
> |     > Email: sbronder at stevebronder.com
> |
> |
> |     > On Tue, Dec 20, 2016 at 1:04 AM, Henrik Bengtsson <
> |     > henrik.bengtsson at gmail.com> wrote:
> |
> |     >> On reason for hitting the MAX_NUM_DLLS (= 100) limit is because some
> |     >> packages don't unload their DLLs when they being unloaded themselves.
> |     >> In other words, there may be left-over DLLs just sitting there doing
> |     >> nothing but occupying space.  You can remove these, using:
> |     >>
> |     >> R.utils::gcDLLs()
> |     >>
> |     >> Maybe that will help you get through your tests (as long as you're
> |     >> unloading packages).  gcDLLs() will look at base::getLoadedDLLs() and
> |     >> its content and compare to loadedNamespaces() and unregister any
> |     >> "stray" DLLs that remain after corresponding packages have been
> |     >> unloaded.
> |     >>
> |     >> I think it would be useful if R CMD check would also check that DLLs
> |     >> are unregistered when a package is unloaded
> |     >> (https://github.com/HenrikBengtsson/Wishlist-for-R/issues/29), but of
> |     >> course, someone needs to write the code / a patch for this to happen.
> |     >>
> |     >> /Henrik
> |     >>
> |     >> On Mon, Dec 19, 2016 at 6:01 PM, Steve Bronder
> |     >> <sbronder at stevebronder.com> wrote:
> |     >> > This is a request to increase MAX_NUM_DLLS in Rdynload.c in from 100 to
> |     >> 500.
> |     >> >
> |     >> > On line 131 of Rdynload.c, changing
> |     >> >
> |     >> > #define MAX_NUM_DLLS 100
> |     >> >
> |     >> >  to
> |     >> >
> |     >> > #define MAX_NUM_DLLS 500
> |     >> >
> |     >> >
> |     >> > In development of the mlr package, there have been several episodes in
> |     >> the
> |     >> > past where we have had to break up unit tests because of the "maximum
> |     >> > number of DLLs reached" error. This error has been an inconvenience that
> |     >> is
> |     >> > going to keep happening as the package continues to grow. Is there more
> |     >> > than meets the eye with this error or would everything be okay if the
> |     >> above
> |     >> > line changes? Would that have a larger effect in other parts of R?
> |     >> >
> |     >> > As R grows, we are likely to see more 'meta-packages' such as the
> |     >> > Hadley-verse, caret, mlr, etc. need an increasing amount of DLLs loaded
> |     >> at
> |     >> > any point in time to conduct effective unit tests. If  MAX_NUM_DLLS is
> |     >> set
> |     >> > to 100 for a very particular reason than I apologize, but if it is
> |     >> possible
> |     >> > to increase MAX_NUM_DLLS it would at least make the testing at mlr much
> |     >> > easier.
> |     >> >
> |     >> > I understand you are all very busy and thank you for your time.
> |     >> >
> |     >> >
> |     >> > Regards,
> |     >> >
> |     >> > Steve Bronder
> |     >> > Website: stevebronder.com
> |     >> > Phone: 412-719-1282
> |     >> > Email: sbronder at stevebronder.com
> |     >> >
> |     >> >         [[alternative HTML version deleted]]
> |     >> >
> |     >> > ______________________________________________
> |     >> > R-devel at r-project.org mailing list
> |     >> > https://stat.ethz.ch/mailman/listinfo/r-devel
> |     >>
> |
> |     > [[alternative HTML version deleted]]
> |
> |     > ______________________________________________
> |     > R-devel at r-project.org mailing list
> |     > https://stat.ethz.ch/mailman/listinfo/r-devel
> |
> | ______________________________________________
> | R-devel at r-project.org mailing list
> | https://stat.ethz.ch/mailman/listinfo/r-devel
>


From sbronder at stevebronder.com  Tue Dec 20 21:08:09 2016
From: sbronder at stevebronder.com (Steve Bronder)
Date: Tue, 20 Dec 2016 15:08:09 -0500
Subject: [Rd] Request: Increasing MAX_NUM_DLLS in Rdynload.c
In-Reply-To: <d140e7e2-4a76-31c8-1940-17c1ad17c4ad@prodsyse.com>
References: <CAAVP=akpmJ2gDdDXNPTOh-fFNAy-B52v0QRp6FaNRfhW9F_ZKw@mail.gmail.com>
	<CAFDcVCTOtaX0cxAZo8hh3mZdp75Xx7UZ4Kry5C+EUxZoqhA8Dw@mail.gmail.com>
	<CAAVP=an9yD_E22KF3q-Bh-XxVzyaEYaic-iTpzCZVxv25G2QnA@mail.gmail.com>
	<22617.24288.140314.653221@stat.math.ethz.ch>
	<22617.25258.765788.878896@max.nulle.part>
	<d140e7e2-4a76-31c8-1940-17c1ad17c4ad@prodsyse.com>
Message-ID: <CAAVP=anCh97HHWvHnK3_A0P=mdDz8+L2H7MiU2K4zkQxUZLL-w@mail.gmail.com>

See inlin
?e?


On Tue, Dec 20, 2016 at 12:14 PM, Spencer Graves <
spencer.graves at prodsyse.com> wrote:

> Hi, Dirk:
>
>
>
> On 12/20/2016 10:56 AM, Dirk Eddelbuettel wrote:
>
>> On 20 December 2016 at 17:40, Martin Maechler wrote:
>> | >>>>> Steve Bronder <sbronder at stevebronder.com>
>> | >>>>>     on Tue, 20 Dec 2016 01:34:31 -0500 writes:
>> |
>> |     > Thanks Henrik this is very helpful! I will try this out on our
>> tests and
>> |     > see if gcDLLs() has a positive effect.
>> |
>> |     > mlr currently has tests broken down by learner type such as
>> classification,
>> |     > regression, forecasting, clustering, etc.. There are 83
>> classifiers alone
>> |     > so even when loading and unloading across learner types we can
>> still hit
>> |     > the MAX_NUM_DLLS error, meaning we'll have to break them down
>> further (or
>> |     > maybe we can be clever with gcDLLs()?). I'm CC'ing Lars Kotthoff
>> and Bernd
>> |     > Bischl to make sure I am representing the issue well.
>> |
>> | This came up *here* in May 2015
>> | and then May 2016 ... did you not find it when googling.
>
> |
>> | Hint:  Use
>> |        site:stat.ethz.ch MAX_NUM_DLLS
>> | as search string in Google, so it will basically only search the
>> | R mailing list archives
>>
> ?I did not know this and apologize. I starred this email so I can use it
next time I have a question or request. I did find (and left a comment) on
the stackoverflow question in which you left an answer to this question.
http://stackoverflow.com/a/37021455/2269255

> |
>> | Here's the start of that thread :
>> |
>> |
>> ??
>> ??
>>  https://stat.ethz.ch/pipermail/r-devel/2016-May/072637.html
>> |
>> | There was not a clear conclusion back then, notably as
>> | Prof Brian Ripley noted that 100 had already been an increase
>> | and that a large number of loaded DLLs decreases look up speed.
>
> |
>> | OTOH (I think others have noted that) a large number of DLLs
>> | only penalizes those who *do* load many, and we should probably
>> | increase it.
>>
> ?Am I correct in understanding that the decrease in lookup speed only
happens when a large number of DLLs are loaded? If so, this is an expected
cost to having many DLLs and one that I, and I would guess other
developers, would be willing to pay to have more DLLs available. If
increasing MAX_NUM_DLLS would increase R's fixed memory footprint a
significant amount then I think that's a reasonable argument against the
increase in MAX_NUM_DLLS. ?


> |
>> | Your use case of "hyper packages" which load many others
>> | simultaneously is somewhat convincing to me... in so far as the
>> | general feeling is that memory should be cheap and limits should
>> | not be low.
>>
> ?It should also be pointed out that even in the case of "hyper packages"
like mlr, this is only an issue during unit testing. I wonder if there is
some middle ground here? Would it be difficult to have a compile flag that
would change the number of MAX_NUM_DLLS when compiling R from source? I
believe this would allow us to increase MAX_NUM_DLLS when testing in Travis
and Jenkins while keeping the same footprint for regular users.?


> |
>> | (In spite of Brian Ripleys good reasons against it, I'd still
>> |  aim for a *dynamic*, i.e. automatically increased list here).
>>
>> Yes.  Start with 10 or 20, add 10 as needed.  Still fast in the 'small N'
>> case and no longer a road block for the 'big N' case required by mlr et
>> al.
>>
> ?This would be nice! Though my concern is the R-core team's time. This is
the best answer, but I don't feel comfortable requesting it because I can't
help with this and do not want to take up R-core's time without a very
significant reason.?

?Unit testing for a meta-package is a particular case, though I think an
important one which will impact R over the long term. The answers from
least to most complex are something like:
1. Do nothing
2. Increase MAX_NUM_DLLS
3. Compiler flag for MAX_NUM_DLLS ( I actually have no reference to how
difficult this would be)
4. Change to dynamic loading
I'm requesting (2) because I think it's a simple short term answer until
someone has time to sit down and work out (4).?

>
>> As a C++ programmer, I am now going to hug my
>> ??
>> std::vector and quietly retreat.
>>
>
>
> May I humbly request a translation of "std::vector" for people like me who
> are not familiar with C++?
>
>
> I got the following:
>
>
> > install.packages('std')
> Warning in install.packages :
>   package ?std? is not available (for R version 3.3.2)
>
>
>       Thanks,
>       Spencer Graves
>
>
>> Dirk
>>
>>   | Martin Maechler
>> |
>> |     > Regards,
>> |
>> |     > Steve Bronder
>> |     > Website: stevebronder.com
>> |     > Phone: 412-719-1282
>> |     > Email: sbronder at stevebronder.com
>> |
>> |
>> |     > On Tue, Dec 20, 2016 at 1:04 AM, Henrik Bengtsson <
>> |     > henrik.bengtsson at gmail.com> wrote:
>> |
>> |     >> On reason for hitting the MAX_NUM_DLLS (= 100) limit is because
>> some
>> |     >> packages don't unload their DLLs when they being unloaded
>> themselves.
>> |     >> In other words, there may be left-over DLLs just sitting there
>> doing
>> |     >> nothing but occupying space.  You can remove these, using:
>> |     >>
>> |     >> R.utils::gcDLLs()
>> |     >>
>> |     >> Maybe that will help you get through your tests (as long as
>> you're
>> |     >> unloading packages).  gcDLLs() will look at
>> base::getLoadedDLLs() and
>> |     >> its content and compare to loadedNamespaces() and unregister any
>> |     >> "stray" DLLs that remain after corresponding packages have been
>> |     >> unloaded.
>> |     >>
>> |     >> I think it would be useful if R CMD check would also check that
>> DLLs
>> |     >> are unregistered when a package is unloaded
>> |     >> (https://github.com/HenrikBengtsson/Wishlist-for-R/issues/29),
>> but of
>> |     >> course, someone needs to write the code / a patch for this to
>> happen.
>> |     >>
>> |     >> /Henrik
>> |     >>
>> |     >> On Mon, Dec 19, 2016 at 6:01 PM, Steve Bronder
>> |     >> <sbronder at stevebronder.com> wrote:
>> |     >> > This is a request to increase MAX_NUM_DLLS in Rdynload.c in
>> from 100 to
>> |     >> 500.
>> |     >> >
>> |     >> > On line 131 of Rdynload.c, changing
>> |     >> >
>> |     >> > #define MAX_NUM_DLLS 100
>> |     >> >
>> |     >> >  to
>> |     >> >
>> |     >> > #define MAX_NUM_DLLS 500
>> |     >> >
>> |     >> >
>> |     >> > In development of the mlr package, there have been several
>> episodes in
>> |     >> the
>> |     >> > past where we have had to break up unit tests because of the
>> "maximum
>> |     >> > number of DLLs reached" error. This error has been an
>> inconvenience that
>> |     >> is
>> |     >> > going to keep happening as the package continues to grow. Is
>> there more
>> |     >> > than meets the eye with this error or would everything be okay
>> if the
>> |     >> above
>> |     >> > line changes? Would that have a larger effect in other parts
>> of R?
>> |     >> >
>> |     >> > As R grows, we are likely to see more 'meta-packages' such as
>> the
>> |     >> > Hadley-verse, caret, mlr, etc. need an increasing amount of
>> DLLs loaded
>> |     >> at
>> |     >> > any point in time to conduct effective unit tests. If
>> MAX_NUM_DLLS is
>> |     >> set
>> |     >> > to 100 for a very particular reason than I apologize, but if
>> it is
>> |     >> possible
>> |     >> > to increase MAX_NUM_DLLS it would at least make the testing at
>> mlr much
>> |     >> > easier.
>> |     >> >
>> |     >> > I understand you are all very busy and thank you for your time.
>> |     >> >
>> |     >> >
>> |     >> > Regards,
>> |     >> >
>> |     >> > Steve Bronder
>> |     >> > Website: stevebronder.com
>> |     >> > Phone: 412-719-1282
>> |     >> > Email: sbronder at stevebronder.com
>> |     >> >
>> |     >> >         [[alternative HTML version deleted]]
>> |     >> >
>> |     >> > ______________________________________________
>> |     >> > R-devel at r-project.org mailing list
>> |     >> > https://stat.ethz.ch/mailman/listinfo/r-devel
>> |     >>
>> |
>> |     > [[alternative HTML version deleted]]
>> |
>> |     > ______________________________________________
>> |     > R-devel at r-project.org mailing list
>> |     > https://stat.ethz.ch/mailman/listinfo/r-devel
>> |
>> | ______________________________________________
>> | R-devel at r-project.org mailing list
>> | https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-
? Steve Bronder?

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Wed Dec 21 12:28:11 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 21 Dec 2016 12:28:11 +0100
Subject: [Rd] Very small numbers in hexadecimal notation parsed as zero
In-Reply-To: <CAOiMVK3atf7-Vj96VMcfqDdRMnM2_9fU5t2DoZC_TNeMxo=toQ@mail.gmail.com>
References: <CAOiMVK3atf7-Vj96VMcfqDdRMnM2_9fU5t2DoZC_TNeMxo=toQ@mail.gmail.com>
Message-ID: <22618.26443.81856.947714@stat.math.ethz.ch>

>>>>> Florent Angly <florent.angly at gmail.com>
>>>>>     on Tue, 20 Dec 2016 13:26:36 +0100 writes:

    > Hi all,
    > I have noticed incorrect parsing of very small hexadecimal numbers
    > like "0x1.00000000d0000p-987". Such a hexadecimal representation can
    > can be produced by sprintf() using the %a flag. The return value is
    > incorrectly reported as 0 when coercing these numbers to double using
    > as.double()/as.numeric(), as illustrated in the three examples below:

    > as.double("0x1.00000000d0000p-987")    # should be 7.645296e-298
    > as.double("0x1.0000000000000p-1022")  # should be 2.225074e-308
    > as.double("0x1.f89fc1a6f6613p-974")      # should be 1.23456e-293

    > The culprit seems to be the src/main/util.c:R_strtod function and in
    > some cases, removing the zeroes directly before the 'p' leads to
    > correct parsing:

    > as.double("0x1.00000000dp-987") # 7.645296e-298, as expected
    > as.double("0x1.p-1022")         # 2.225074e-308, as expected

Yes, this looks like a bug, indeed.
Similarly convincing is a simple comparison (of even less extreme)

> as.double("0x1p-987")
[1] 7.645296e-298
> as.double("0x1.0000000000p-987")
[1] 0
> 

The "bug boundary" seems around here:

> as.double("0x1.000000000000000000000000p-928") # fails
[1] 0
> as.double("0x1p-928")
[1] 4.407213e-280
> 

> as.double("0x1.000000000000000000000000p-927") # works
[1] 8.814426e-280

but then adding more zeros before "p-927" also underflows.

--> I have created an R bugzilla account for you; so you now
 can submit bug reports (including patch proposals to the source (hint!) ;-)

Thank you, Florent!
Martin


From peljasz at yahoo.co.uk  Wed Dec 21 18:00:36 2016
From: peljasz at yahoo.co.uk (lejeczek)
Date: Wed, 21 Dec 2016 17:00:36 +0000
Subject: [Rd] different compilers and mzR build fails
Message-ID: <967bf4dd-8f1a-0c16-a09f-1a4df61ac9a7@yahoo.co.uk>

I'm not sure if I should bother you team with this, 
apologies in case it's a bother.

I'm trying gcc 6.2.1 (from devtoolset-6) with R, everything 
seems to work just fine, except for mzR.
Here is failed build:

g++ -m64 -shared -L/usr/lib64/R/lib -Wl,-z,relro -o mzR.so 
cramp.o ramp_base64.o ramp.o RcppRamp.o RcppRampModule.o 
rnetCDF.o RcppPwiz.o RcppPwizModule.o RcppIdent.o 
RcppIdentModule.o ./boost/system/src/error_code.o 
./boost/regex/src/posix_api.o ./boost/regex/src/fileiter.o 
./boost/regex/src/regex_raw_buffer.o 
./boost/regex/src/cregex.o ./boost/regex/src/regex_debug.o 
./boost/regex/src/instances.o ./boost/regex/src/icu.o 
./boost/regex/src/usinstances.o ./boost/regex/src/regex.o 
./boost/regex/src/wide_posix_api.o 
./boost/regex/src/regex_traits_defaults.o 
./boost/regex/src/winstances.o 
./boost/regex/src/wc_regex_traits.o 
./boost/regex/src/c_regex_traits.o 
./boost/regex/src/cpp_regex_traits.o 
./boost/regex/src/static_mutex.o 
./boost/regex/src/w32_regex_traits.o 
./boost/iostreams/src/zlib.o 
./boost/iostreams/src/file_descriptor.o 
./boost/thread/pthread/once.o 
./boost/thread/pthread/thread.o 
./boost/filesystem/src/operations.o 
./boost/filesystem/src/path.o 
./boost/filesystem/src/utf8_codecvt_facet.o 
./boost/chrono/src/chrono.o 
./boost/chrono/src/process_cpu_clocks.o 
./boost/chrono/src/thread_clock.o 
./pwiz/data/msdata/Version.o 
./pwiz/data/common/MemoryIndex.o 
./pwiz/data/common/CVTranslator.o ./pwiz/data/common/cv.o 
./pwiz/data/common/ParamTypes.o 
./pwiz/data/common/BinaryIndexStream.o 
./pwiz/data/common/diff_std.o ./pwiz/data/common/Unimod.o 
./pwiz/data/msdata/SpectrumList_MGF.o 
./pwiz/data/msdata/DefaultReaderList.o 
./pwiz/data/msdata/ChromatogramList_mzML.o 
./pwiz/data/msdata/examples.o 
./pwiz/data/msdata/Serializer_mzML.o 
./pwiz/data/msdata/Serializer_MSn.o 
./pwiz/data/msdata/Reader.o 
./pwiz/data/msdata/Serializer_MGF.o 
./pwiz/data/msdata/Serializer_mzXML.o 
./pwiz/data/msdata/SpectrumList_mzML.o 
./pwiz/data/msdata/SpectrumList_MSn.o 
./pwiz/data/msdata/BinaryDataEncoder.o 
./pwiz/data/msdata/Diff.o ./pwiz/data/msdata/MSData.o 
./pwiz/data/msdata/References.o 
./pwiz/data/msdata/SpectrumList_mzXML.o 
./pwiz/data/msdata/IO.o 
./pwiz/data/msdata/SpectrumList_BTDX.o 
./pwiz/data/msdata/SpectrumInfo.o 
./pwiz/data/msdata/RAMPAdapter.o 
./pwiz/data/msdata/LegacyAdapter.o 
./pwiz/data/msdata/SpectrumIterator.o 
./pwiz/data/msdata/MSDataFile.o 
./pwiz/data/msdata/MSNumpress.o 
./pwiz/data/msdata/SpectrumListCache.o 
./pwiz/data/msdata/Index_mzML.o 
./pwiz/data/msdata/SpectrumWorkerThreads.o 
./pwiz/data/identdata/IdentDataFile.o 
./pwiz/data/identdata/IdentData.o 
./pwiz/data/identdata/DefaultReaderList.o 
./pwiz/data/identdata/Reader.o 
./pwiz/data/identdata/Serializer_protXML.o 
./pwiz/data/identdata/Serializer_pepXML.o 
./pwiz/data/identdata/Serializer_mzid.o 
./pwiz/data/identdata/IO.o 
./pwiz/data/identdata/References.o 
./pwiz/data/identdata/MascotReader.o 
./pwiz/data/proteome/Modification.o 
./pwiz/data/proteome/Digestion.o 
./pwiz/data/proteome/Peptide.o 
./pwiz/data/proteome/AminoAcid.o 
./pwiz/utility/minimxml/XMLWriter.o 
./pwiz/utility/minimxml/SAXParser.o 
./pwiz/utility/chemistry/Chemistry.o 
./pwiz/utility/chemistry/ChemistryData.o 
./pwiz/utility/chemistry/MZTolerance.o 
./pwiz/utility/misc/IntegerSet.o 
./pwiz/utility/misc/Base64.o 
./pwiz/utility/misc/IterationListener.o 
./pwiz/utility/misc/MSIHandler.o 
./pwiz/utility/misc/Filesystem.o 
./pwiz/utility/misc/TabReader.o 
./pwiz/utility/misc/random_access_compressed_ifstream.o 
./pwiz/utility/misc/SHA1.o 
./pwiz/utility/misc/SHA1Calculator.o 
./pwiz/utility/misc/sha1calc.o ./random_access_gzFile.o 
./RcppExports.o rampR.o R_init_mzR.o -lpthread -lnetcdf 
-L/usr/lib64/R/lib -lR
g++: error: cramp.o: No such file or directory
g++: error: ramp_base64.o: No such file or directory
g++: error: ramp.o: No such file or directory
g++: error: RcppRamp.o: No such file or directory
g++: error: RcppRampModule.o: No such file or directory
g++: error: rnetCDF.o: No such file or directory
g++: error: RcppPwiz.o: No such file or directory
g++: error: RcppPwizModule.o: No such file or directory
g++: error: RcppIdent.o: No such file or directory
g++: error: RcppIdentModule.o: No such file or directory
/usr/share/R/make/shlib.mk:6: recipe for target 'mzR.so' failed
make: *** [mzR.so] Error 1

It did compile with 5.2.x (from devtoolset-4) and worked fine.
I'm hoping you guys could confirm it is purely compiler 
problem? Or point me(not a real programmer) a way to 
troubleshoot it properly?
many thanks,
L.


From martin.morgan at roswellpark.org  Wed Dec 21 18:06:59 2016
From: martin.morgan at roswellpark.org (Martin Morgan)
Date: Wed, 21 Dec 2016 12:06:59 -0500
Subject: [Rd] different compilers and mzR build fails
In-Reply-To: <967bf4dd-8f1a-0c16-a09f-1a4df61ac9a7@yahoo.co.uk>
References: <967bf4dd-8f1a-0c16-a09f-1a4df61ac9a7@yahoo.co.uk>
Message-ID: <e28262f5-e03f-15b0-c4d2-dacb52898a51@roswellpark.org>

mzR is a Bioconductor package, so better to ask on the Bioconductor 
support forum

   https://support.bioconductor.org

Oh, I see you did, and then the advice is to avoid cross-posting!

The missing .o files would have been produced in an earlier compilation 
step; they likely failed in some way, so you need to provide the 
complete compilation output.

Did you do this on a version of the package that did not have any 
previous build artifacts (e.g., via biocLite() or from a fresh svn 
checkout)?

Martin

On 12/21/2016 12:00 PM, lejeczek via R-devel wrote:
> I'm not sure if I should bother you team with this, apologies in case
> it's a bother.
>
> I'm trying gcc 6.2.1 (from devtoolset-6) with R, everything seems to
> work just fine, except for mzR.
> Here is failed build:
>
> g++ -m64 -shared -L/usr/lib64/R/lib -Wl,-z,relro -o mzR.so cramp.o
> ramp_base64.o ramp.o RcppRamp.o RcppRampModule.o rnetCDF.o RcppPwiz.o
> RcppPwizModule.o RcppIdent.o RcppIdentModule.o
> ./boost/system/src/error_code.o ./boost/regex/src/posix_api.o
> ./boost/regex/src/fileiter.o ./boost/regex/src/regex_raw_buffer.o
> ./boost/regex/src/cregex.o ./boost/regex/src/regex_debug.o
> ./boost/regex/src/instances.o ./boost/regex/src/icu.o
> ./boost/regex/src/usinstances.o ./boost/regex/src/regex.o
> ./boost/regex/src/wide_posix_api.o
> ./boost/regex/src/regex_traits_defaults.o ./boost/regex/src/winstances.o
> ./boost/regex/src/wc_regex_traits.o ./boost/regex/src/c_regex_traits.o
> ./boost/regex/src/cpp_regex_traits.o ./boost/regex/src/static_mutex.o
> ./boost/regex/src/w32_regex_traits.o ./boost/iostreams/src/zlib.o
> ./boost/iostreams/src/file_descriptor.o ./boost/thread/pthread/once.o
> ./boost/thread/pthread/thread.o ./boost/filesystem/src/operations.o
> ./boost/filesystem/src/path.o
> ./boost/filesystem/src/utf8_codecvt_facet.o ./boost/chrono/src/chrono.o
> ./boost/chrono/src/process_cpu_clocks.o
> ./boost/chrono/src/thread_clock.o ./pwiz/data/msdata/Version.o
> ./pwiz/data/common/MemoryIndex.o ./pwiz/data/common/CVTranslator.o
> ./pwiz/data/common/cv.o ./pwiz/data/common/ParamTypes.o
> ./pwiz/data/common/BinaryIndexStream.o ./pwiz/data/common/diff_std.o
> ./pwiz/data/common/Unimod.o ./pwiz/data/msdata/SpectrumList_MGF.o
> ./pwiz/data/msdata/DefaultReaderList.o
> ./pwiz/data/msdata/ChromatogramList_mzML.o ./pwiz/data/msdata/examples.o
> ./pwiz/data/msdata/Serializer_mzML.o ./pwiz/data/msdata/Serializer_MSn.o
> ./pwiz/data/msdata/Reader.o ./pwiz/data/msdata/Serializer_MGF.o
> ./pwiz/data/msdata/Serializer_mzXML.o
> ./pwiz/data/msdata/SpectrumList_mzML.o
> ./pwiz/data/msdata/SpectrumList_MSn.o
> ./pwiz/data/msdata/BinaryDataEncoder.o ./pwiz/data/msdata/Diff.o
> ./pwiz/data/msdata/MSData.o ./pwiz/data/msdata/References.o
> ./pwiz/data/msdata/SpectrumList_mzXML.o ./pwiz/data/msdata/IO.o
> ./pwiz/data/msdata/SpectrumList_BTDX.o ./pwiz/data/msdata/SpectrumInfo.o
> ./pwiz/data/msdata/RAMPAdapter.o ./pwiz/data/msdata/LegacyAdapter.o
> ./pwiz/data/msdata/SpectrumIterator.o ./pwiz/data/msdata/MSDataFile.o
> ./pwiz/data/msdata/MSNumpress.o ./pwiz/data/msdata/SpectrumListCache.o
> ./pwiz/data/msdata/Index_mzML.o
> ./pwiz/data/msdata/SpectrumWorkerThreads.o
> ./pwiz/data/identdata/IdentDataFile.o ./pwiz/data/identdata/IdentData.o
> ./pwiz/data/identdata/DefaultReaderList.o ./pwiz/data/identdata/Reader.o
> ./pwiz/data/identdata/Serializer_protXML.o
> ./pwiz/data/identdata/Serializer_pepXML.o
> ./pwiz/data/identdata/Serializer_mzid.o ./pwiz/data/identdata/IO.o
> ./pwiz/data/identdata/References.o ./pwiz/data/identdata/MascotReader.o
> ./pwiz/data/proteome/Modification.o ./pwiz/data/proteome/Digestion.o
> ./pwiz/data/proteome/Peptide.o ./pwiz/data/proteome/AminoAcid.o
> ./pwiz/utility/minimxml/XMLWriter.o ./pwiz/utility/minimxml/SAXParser.o
> ./pwiz/utility/chemistry/Chemistry.o
> ./pwiz/utility/chemistry/ChemistryData.o
> ./pwiz/utility/chemistry/MZTolerance.o ./pwiz/utility/misc/IntegerSet.o
> ./pwiz/utility/misc/Base64.o ./pwiz/utility/misc/IterationListener.o
> ./pwiz/utility/misc/MSIHandler.o ./pwiz/utility/misc/Filesystem.o
> ./pwiz/utility/misc/TabReader.o
> ./pwiz/utility/misc/random_access_compressed_ifstream.o
> ./pwiz/utility/misc/SHA1.o ./pwiz/utility/misc/SHA1Calculator.o
> ./pwiz/utility/misc/sha1calc.o ./random_access_gzFile.o ./RcppExports.o
> rampR.o R_init_mzR.o -lpthread -lnetcdf -L/usr/lib64/R/lib -lR
> g++: error: cramp.o: No such file or directory
> g++: error: ramp_base64.o: No such file or directory
> g++: error: ramp.o: No such file or directory
> g++: error: RcppRamp.o: No such file or directory
> g++: error: RcppRampModule.o: No such file or directory
> g++: error: rnetCDF.o: No such file or directory
> g++: error: RcppPwiz.o: No such file or directory
> g++: error: RcppPwizModule.o: No such file or directory
> g++: error: RcppIdent.o: No such file or directory
> g++: error: RcppIdentModule.o: No such file or directory
> /usr/share/R/make/shlib.mk:6: recipe for target 'mzR.so' failed
> make: *** [mzR.so] Error 1
>
> It did compile with 5.2.x (from devtoolset-4) and worked fine.
> I'm hoping you guys could confirm it is purely compiler problem? Or
> point me(not a real programmer) a way to troubleshoot it properly?
> many thanks,
> L.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


This email message may contain legally privileged and/or...{{dropped:2}}


From henrik.bengtsson at gmail.com  Wed Dec 21 18:10:33 2016
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Wed, 21 Dec 2016 09:10:33 -0800
Subject: [Rd] Request: Increasing MAX_NUM_DLLS in Rdynload.c
In-Reply-To: <CABz6aZeVV+hzQtkD+9z2irKiVQBkVugwCthPum7=Ft3wmjyXig@mail.gmail.com>
References: <CAAVP=akpmJ2gDdDXNPTOh-fFNAy-B52v0QRp6FaNRfhW9F_ZKw@mail.gmail.com>
	<CAFDcVCTOtaX0cxAZo8hh3mZdp75Xx7UZ4Kry5C+EUxZoqhA8Dw@mail.gmail.com>
	<CABFfbXttbp1JCad8XztMfzgmLDBPm6o8Wz8wXSC72iXhT2Ab8g@mail.gmail.com>
	<CABz6aZeVV+hzQtkD+9z2irKiVQBkVugwCthPum7=Ft3wmjyXig@mail.gmail.com>
Message-ID: <CAFDcVCRmgosE-rn1vUVf9uR4JPTdnSzJzQsdrj13w_xWhcO-ww@mail.gmail.com>

On Tue, Dec 20, 2016 at 7:39 AM, Karl Millar <kmillar at google.com> wrote:
> It's not always clear when it's safe to remove the DLL.
>
> The main problem that I'm aware of is that native objects with
> finalizers might still exist (created by R_RegisterCFinalizer etc).
> Even if there are no live references to such objects (which would be
> hard to verify), it still wouldn't be safe to unload the DLL until a
> full garbage collection has been done.
>
> If the DLL is unloaded, then the function pointer that was registered
> now becomes a pointer into the memory where the DLL was, leading to an
> almost certain crash when such objects get garbage collected.

Very good point.

Does base::gc() perform such a *full* garbage collection and thereby
trigger all remaining finalizers to be called?  In other words, do you
think an explicit call to base::gc() prior to cleaning out left-over
DLLs (e.g. R.utils::gcDLLs()) would be sufficient?

/Henrik

>
> A better approach would be to just remove the limit on the number of
> DLLs, dynamically expanding the array if/when needed.
>
>
> On Tue, Dec 20, 2016 at 3:40 AM, Jeroen Ooms <jeroen.ooms at stat.ucla.edu> wrote:
>> On Tue, Dec 20, 2016 at 7:04 AM, Henrik Bengtsson
>> <henrik.bengtsson at gmail.com> wrote:
>>> On reason for hitting the MAX_NUM_DLLS (= 100) limit is because some
>>> packages don't unload their DLLs when they being unloaded themselves.
>>
>> I am surprised by this. Why does R not do this automatically? What is
>> the case for keeping the DLL loaded after the package has been
>> unloaded? What happens if you reload another version of the same
>> package from a different library after unloading?
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From kmillar at google.com  Wed Dec 21 18:42:44 2016
From: kmillar at google.com (Karl Millar)
Date: Wed, 21 Dec 2016 09:42:44 -0800
Subject: [Rd] Request: Increasing MAX_NUM_DLLS in Rdynload.c
In-Reply-To: <CAFDcVCRmgosE-rn1vUVf9uR4JPTdnSzJzQsdrj13w_xWhcO-ww@mail.gmail.com>
References: <CAAVP=akpmJ2gDdDXNPTOh-fFNAy-B52v0QRp6FaNRfhW9F_ZKw@mail.gmail.com>
	<CAFDcVCTOtaX0cxAZo8hh3mZdp75Xx7UZ4Kry5C+EUxZoqhA8Dw@mail.gmail.com>
	<CABFfbXttbp1JCad8XztMfzgmLDBPm6o8Wz8wXSC72iXhT2Ab8g@mail.gmail.com>
	<CABz6aZeVV+hzQtkD+9z2irKiVQBkVugwCthPum7=Ft3wmjyXig@mail.gmail.com>
	<CAFDcVCRmgosE-rn1vUVf9uR4JPTdnSzJzQsdrj13w_xWhcO-ww@mail.gmail.com>
Message-ID: <CABz6aZcVFp8WFZn3SqS3d0Fg3oh96PFadyLwwW_APT7+SDUHAA@mail.gmail.com>

It does, but you'd still be relying on the R code ensuring that all of
these objects are dead prior to unloading the DLL, otherwise they'll
survive the GC.  Maybe if the package counted how many such objects
exist, it could work out when it's safe to remove the DLL.  I'm not
sure that it can be done automatically.

What could be done is to to keep the DLL loaded, but remove it from
R's table of loaded DLLs.  That way, there's no risk of dangling
function pointers and a new DLL of the same name could be loaded.  You
could still run into issues though as some DLLs assume that the
associated namespace exists.

Currently what I do is to never unload DLLs.  If I need to replace
one, then I just restart R.  It's less convenient, but it's always
correct.


On Wed, Dec 21, 2016 at 9:10 AM, Henrik Bengtsson
<henrik.bengtsson at gmail.com> wrote:
> On Tue, Dec 20, 2016 at 7:39 AM, Karl Millar <kmillar at google.com> wrote:
>> It's not always clear when it's safe to remove the DLL.
>>
>> The main problem that I'm aware of is that native objects with
>> finalizers might still exist (created by R_RegisterCFinalizer etc).
>> Even if there are no live references to such objects (which would be
>> hard to verify), it still wouldn't be safe to unload the DLL until a
>> full garbage collection has been done.
>>
>> If the DLL is unloaded, then the function pointer that was registered
>> now becomes a pointer into the memory where the DLL was, leading to an
>> almost certain crash when such objects get garbage collected.
>
> Very good point.
>
> Does base::gc() perform such a *full* garbage collection and thereby
> trigger all remaining finalizers to be called?  In other words, do you
> think an explicit call to base::gc() prior to cleaning out left-over
> DLLs (e.g. R.utils::gcDLLs()) would be sufficient?
>
> /Henrik
>
>>
>> A better approach would be to just remove the limit on the number of
>> DLLs, dynamically expanding the array if/when needed.
>>
>>
>> On Tue, Dec 20, 2016 at 3:40 AM, Jeroen Ooms <jeroen.ooms at stat.ucla.edu> wrote:
>>> On Tue, Dec 20, 2016 at 7:04 AM, Henrik Bengtsson
>>> <henrik.bengtsson at gmail.com> wrote:
>>>> On reason for hitting the MAX_NUM_DLLS (= 100) limit is because some
>>>> packages don't unload their DLLs when they being unloaded themselves.
>>>
>>> I am surprised by this. Why does R not do this automatically? What is
>>> the case for keeping the DLL loaded after the package has been
>>> unloaded? What happens if you reload another version of the same
>>> package from a different library after unloading?
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel


From edd at debian.org  Wed Dec 21 18:58:27 2016
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 21 Dec 2016 11:58:27 -0600
Subject: [Rd] Request: Increasing MAX_NUM_DLLS in Rdynload.c
In-Reply-To: <CABz6aZcVFp8WFZn3SqS3d0Fg3oh96PFadyLwwW_APT7+SDUHAA@mail.gmail.com>
References: <CAAVP=akpmJ2gDdDXNPTOh-fFNAy-B52v0QRp6FaNRfhW9F_ZKw@mail.gmail.com>
	<CAFDcVCTOtaX0cxAZo8hh3mZdp75Xx7UZ4Kry5C+EUxZoqhA8Dw@mail.gmail.com>
	<CABFfbXttbp1JCad8XztMfzgmLDBPm6o8Wz8wXSC72iXhT2Ab8g@mail.gmail.com>
	<CABz6aZeVV+hzQtkD+9z2irKiVQBkVugwCthPum7=Ft3wmjyXig@mail.gmail.com>
	<CAFDcVCRmgosE-rn1vUVf9uR4JPTdnSzJzQsdrj13w_xWhcO-ww@mail.gmail.com>
	<CABz6aZcVFp8WFZn3SqS3d0Fg3oh96PFadyLwwW_APT7+SDUHAA@mail.gmail.com>
Message-ID: <22618.49859.72280.758356@max.nulle.part>


On 21 December 2016 at 09:42, Karl Millar via R-devel wrote:
| Currently what I do is to never unload DLLs.  If I need to replace
| one, then I just restart R.  It's less convenient, but it's always
| correct.

Same here. Ever since we built littler in 2006 (!!) I have been doing tests
at the command-line with fresh 'r' processes.  No surprises, no side effects.

Dirk

PS Spencer, if you are still reading, std::vector is describe inter alia here
http://en.cppreference.com/w/cpp/container/vector  My point of bringing it up
was a deeper one because that (really widely used) data structure grows as
needed. No pointers, no malloc, no horror stories you may have heard from C.

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From peljasz at yahoo.co.uk  Wed Dec 21 19:56:32 2016
From: peljasz at yahoo.co.uk (lejeczek)
Date: Wed, 21 Dec 2016 18:56:32 +0000
Subject: [Rd] different compilers and mzR build fails
In-Reply-To: <e28262f5-e03f-15b0-c4d2-dacb52898a51@roswellpark.org>
References: <967bf4dd-8f1a-0c16-a09f-1a4df61ac9a7@yahoo.co.uk>
	<e28262f5-e03f-15b0-c4d2-dacb52898a51@roswellpark.org>
Message-ID: <657a3fd6-465c-d2e8-5568-6941f596f078@yahoo.co.uk>


I do this on a vanilla-clean R installation, simply:
 > biocLite("mzR")
it pulls some deps in which compile fine, only mzR fails.
... meanwhile...
I grabbed devtools and comiled github master - still fails.
Should I attach build log? One should not send attachments 
to the list.. I don't suppose?

On 21/12/16 17:06, Martin Morgan wrote:
> mzR is a Bioconductor package, so better to ask on the 
> Bioconductor support forum
>
>   https://support.bioconductor.org
>
> Oh, I see you did, and then the advice is to avoid 
> cross-posting!
>
> The missing .o files would have been produced in an 
> earlier compilation step; they likely failed in some way, 
> so you need to provide the complete compilation output.
>
> Did you do this on a version of the package that did not 
> have any previous build artifacts (e.g., via biocLite() or 
> from a fresh svn checkout)?
>
> Martin
>
> On 12/21/2016 12:00 PM, lejeczek via R-devel wrote:
>> I'm not sure if I should bother you team with this, 
>> apologies in case
>> it's a bother.
>>
>> I'm trying gcc 6.2.1 (from devtoolset-6) with R, 
>> everything seems to
>> work just fine, except for mzR.
>> Here is failed build:
>>
>> g++ -m64 -shared -L/usr/lib64/R/lib -Wl,-z,relro -o 
>> mzR.so cramp.o
>> ramp_base64.o ramp.o RcppRamp.o RcppRampModule.o 
>> rnetCDF.o RcppPwiz.o
>> RcppPwizModule.o RcppIdent.o RcppIdentModule.o
>> ./boost/system/src/error_code.o 
>> ./boost/regex/src/posix_api.o
>> ./boost/regex/src/fileiter.o 
>> ./boost/regex/src/regex_raw_buffer.o
>> ./boost/regex/src/cregex.o ./boost/regex/src/regex_debug.o
>> ./boost/regex/src/instances.o ./boost/regex/src/icu.o
>> ./boost/regex/src/usinstances.o ./boost/regex/src/regex.o
>> ./boost/regex/src/wide_posix_api.o
>> ./boost/regex/src/regex_traits_defaults.o 
>> ./boost/regex/src/winstances.o
>> ./boost/regex/src/wc_regex_traits.o 
>> ./boost/regex/src/c_regex_traits.o
>> ./boost/regex/src/cpp_regex_traits.o 
>> ./boost/regex/src/static_mutex.o
>> ./boost/regex/src/w32_regex_traits.o 
>> ./boost/iostreams/src/zlib.o
>> ./boost/iostreams/src/file_descriptor.o 
>> ./boost/thread/pthread/once.o
>> ./boost/thread/pthread/thread.o 
>> ./boost/filesystem/src/operations.o
>> ./boost/filesystem/src/path.o
>> ./boost/filesystem/src/utf8_codecvt_facet.o 
>> ./boost/chrono/src/chrono.o
>> ./boost/chrono/src/process_cpu_clocks.o
>> ./boost/chrono/src/thread_clock.o 
>> ./pwiz/data/msdata/Version.o
>> ./pwiz/data/common/MemoryIndex.o 
>> ./pwiz/data/common/CVTranslator.o
>> ./pwiz/data/common/cv.o ./pwiz/data/common/ParamTypes.o
>> ./pwiz/data/common/BinaryIndexStream.o 
>> ./pwiz/data/common/diff_std.o
>> ./pwiz/data/common/Unimod.o 
>> ./pwiz/data/msdata/SpectrumList_MGF.o
>> ./pwiz/data/msdata/DefaultReaderList.o
>> ./pwiz/data/msdata/ChromatogramList_mzML.o 
>> ./pwiz/data/msdata/examples.o
>> ./pwiz/data/msdata/Serializer_mzML.o 
>> ./pwiz/data/msdata/Serializer_MSn.o
>> ./pwiz/data/msdata/Reader.o 
>> ./pwiz/data/msdata/Serializer_MGF.o
>> ./pwiz/data/msdata/Serializer_mzXML.o
>> ./pwiz/data/msdata/SpectrumList_mzML.o
>> ./pwiz/data/msdata/SpectrumList_MSn.o
>> ./pwiz/data/msdata/BinaryDataEncoder.o 
>> ./pwiz/data/msdata/Diff.o
>> ./pwiz/data/msdata/MSData.o ./pwiz/data/msdata/References.o
>> ./pwiz/data/msdata/SpectrumList_mzXML.o 
>> ./pwiz/data/msdata/IO.o
>> ./pwiz/data/msdata/SpectrumList_BTDX.o 
>> ./pwiz/data/msdata/SpectrumInfo.o
>> ./pwiz/data/msdata/RAMPAdapter.o 
>> ./pwiz/data/msdata/LegacyAdapter.o
>> ./pwiz/data/msdata/SpectrumIterator.o 
>> ./pwiz/data/msdata/MSDataFile.o
>> ./pwiz/data/msdata/MSNumpress.o 
>> ./pwiz/data/msdata/SpectrumListCache.o
>> ./pwiz/data/msdata/Index_mzML.o
>> ./pwiz/data/msdata/SpectrumWorkerThreads.o
>> ./pwiz/data/identdata/IdentDataFile.o 
>> ./pwiz/data/identdata/IdentData.o
>> ./pwiz/data/identdata/DefaultReaderList.o 
>> ./pwiz/data/identdata/Reader.o
>> ./pwiz/data/identdata/Serializer_protXML.o
>> ./pwiz/data/identdata/Serializer_pepXML.o
>> ./pwiz/data/identdata/Serializer_mzid.o 
>> ./pwiz/data/identdata/IO.o
>> ./pwiz/data/identdata/References.o 
>> ./pwiz/data/identdata/MascotReader.o
>> ./pwiz/data/proteome/Modification.o 
>> ./pwiz/data/proteome/Digestion.o
>> ./pwiz/data/proteome/Peptide.o 
>> ./pwiz/data/proteome/AminoAcid.o
>> ./pwiz/utility/minimxml/XMLWriter.o 
>> ./pwiz/utility/minimxml/SAXParser.o
>> ./pwiz/utility/chemistry/Chemistry.o
>> ./pwiz/utility/chemistry/ChemistryData.o
>> ./pwiz/utility/chemistry/MZTolerance.o 
>> ./pwiz/utility/misc/IntegerSet.o
>> ./pwiz/utility/misc/Base64.o 
>> ./pwiz/utility/misc/IterationListener.o
>> ./pwiz/utility/misc/MSIHandler.o 
>> ./pwiz/utility/misc/Filesystem.o
>> ./pwiz/utility/misc/TabReader.o
>> ./pwiz/utility/misc/random_access_compressed_ifstream.o
>> ./pwiz/utility/misc/SHA1.o 
>> ./pwiz/utility/misc/SHA1Calculator.o
>> ./pwiz/utility/misc/sha1calc.o ./random_access_gzFile.o 
>> ./RcppExports.o
>> rampR.o R_init_mzR.o -lpthread -lnetcdf 
>> -L/usr/lib64/R/lib -lR
>> g++: error: cramp.o: No such file or directory
>> g++: error: ramp_base64.o: No such file or directory
>> g++: error: ramp.o: No such file or directory
>> g++: error: RcppRamp.o: No such file or directory
>> g++: error: RcppRampModule.o: No such file or directory
>> g++: error: rnetCDF.o: No such file or directory
>> g++: error: RcppPwiz.o: No such file or directory
>> g++: error: RcppPwizModule.o: No such file or directory
>> g++: error: RcppIdent.o: No such file or directory
>> g++: error: RcppIdentModule.o: No such file or directory
>> /usr/share/R/make/shlib.mk:6: recipe for target 'mzR.so' 
>> failed
>> make: *** [mzR.so] Error 1
>>
>> It did compile with 5.2.x (from devtoolset-4) and worked 
>> fine.
>> I'm hoping you guys could confirm it is purely compiler 
>> problem? Or
>> point me(not a real programmer) a way to troubleshoot it 
>> properly?
>> many thanks,
>> L.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
> This email message may contain legally privileged and/or 
> confidential information.  If you are not the intended 
> recipient(s), or the employee or agent responsible for the 
> delivery of this message to the intended recipient(s), you 
> are hereby notified that any disclosure, copying, 
> distribution, or use of this email message is prohibited.  
> If you have received this message in error, please notify 
> the sender immediately by e-mail and delete this email 
> message from your computer. Thank you.


From martin.morgan at roswellpark.org  Wed Dec 21 22:08:05 2016
From: martin.morgan at roswellpark.org (Martin Morgan)
Date: Wed, 21 Dec 2016 16:08:05 -0500
Subject: [Rd] different compilers and mzR build fails
In-Reply-To: <657a3fd6-465c-d2e8-5568-6941f596f078@yahoo.co.uk>
References: <967bf4dd-8f1a-0c16-a09f-1a4df61ac9a7@yahoo.co.uk>
	<e28262f5-e03f-15b0-c4d2-dacb52898a51@roswellpark.org>
	<657a3fd6-465c-d2e8-5568-6941f596f078@yahoo.co.uk>
Message-ID: <e40dfd75-c93b-cd4d-7b59-bcbed5d168d4@roswellpark.org>

On 12/21/2016 01:56 PM, lejeczek wrote:
>
> I do this on a vanilla-clean R installation, simply:
>> biocLite("mzR")
> it pulls some deps in which compile fine, only mzR fails.
> ... meanwhile...
> I grabbed devtools and comiled github master - still fails.
> Should I attach build log? One should not send attachments to the list..
> I don't suppose?

My opinion is that the appropriate forum is the Bioconductor support 
site. I think you should EDIT your question on the Bioconductor support 
site to add the compiler output. If you feel like you can spot where 
things are going wrong, then edited to include those parts otherwise 
post the output in its entirety; the support site can mangle formatting, 
so I'd copy-and-paste the compiler output, and then select it and format 
it as 'code'.

If you feel that the current forum is more appropriate, then 
cut-and-paste the compiler output into an email message, avoding 
attachments.

Martin

>
> On 21/12/16 17:06, Martin Morgan wrote:
>> mzR is a Bioconductor package, so better to ask on the Bioconductor
>> support forum
>>
>>   https://support.bioconductor.org
>>
>> Oh, I see you did, and then the advice is to avoid cross-posting!
>>
>> The missing .o files would have been produced in an earlier
>> compilation step; they likely failed in some way, so you need to
>> provide the complete compilation output.
>>
>> Did you do this on a version of the package that did not have any
>> previous build artifacts (e.g., via biocLite() or from a fresh svn
>> checkout)?
>>
>> Martin
>>
>> On 12/21/2016 12:00 PM, lejeczek via R-devel wrote:
>>> I'm not sure if I should bother you team with this, apologies in case
>>> it's a bother.
>>>
>>> I'm trying gcc 6.2.1 (from devtoolset-6) with R, everything seems to
>>> work just fine, except for mzR.
>>> Here is failed build:
>>>
>>> g++ -m64 -shared -L/usr/lib64/R/lib -Wl,-z,relro -o mzR.so cramp.o
>>> ramp_base64.o ramp.o RcppRamp.o RcppRampModule.o rnetCDF.o RcppPwiz.o
>>> RcppPwizModule.o RcppIdent.o RcppIdentModule.o
>>> ./boost/system/src/error_code.o ./boost/regex/src/posix_api.o
>>> ./boost/regex/src/fileiter.o ./boost/regex/src/regex_raw_buffer.o
>>> ./boost/regex/src/cregex.o ./boost/regex/src/regex_debug.o
>>> ./boost/regex/src/instances.o ./boost/regex/src/icu.o
>>> ./boost/regex/src/usinstances.o ./boost/regex/src/regex.o
>>> ./boost/regex/src/wide_posix_api.o
>>> ./boost/regex/src/regex_traits_defaults.o ./boost/regex/src/winstances.o
>>> ./boost/regex/src/wc_regex_traits.o ./boost/regex/src/c_regex_traits.o
>>> ./boost/regex/src/cpp_regex_traits.o ./boost/regex/src/static_mutex.o
>>> ./boost/regex/src/w32_regex_traits.o ./boost/iostreams/src/zlib.o
>>> ./boost/iostreams/src/file_descriptor.o ./boost/thread/pthread/once.o
>>> ./boost/thread/pthread/thread.o ./boost/filesystem/src/operations.o
>>> ./boost/filesystem/src/path.o
>>> ./boost/filesystem/src/utf8_codecvt_facet.o ./boost/chrono/src/chrono.o
>>> ./boost/chrono/src/process_cpu_clocks.o
>>> ./boost/chrono/src/thread_clock.o ./pwiz/data/msdata/Version.o
>>> ./pwiz/data/common/MemoryIndex.o ./pwiz/data/common/CVTranslator.o
>>> ./pwiz/data/common/cv.o ./pwiz/data/common/ParamTypes.o
>>> ./pwiz/data/common/BinaryIndexStream.o ./pwiz/data/common/diff_std.o
>>> ./pwiz/data/common/Unimod.o ./pwiz/data/msdata/SpectrumList_MGF.o
>>> ./pwiz/data/msdata/DefaultReaderList.o
>>> ./pwiz/data/msdata/ChromatogramList_mzML.o ./pwiz/data/msdata/examples.o
>>> ./pwiz/data/msdata/Serializer_mzML.o ./pwiz/data/msdata/Serializer_MSn.o
>>> ./pwiz/data/msdata/Reader.o ./pwiz/data/msdata/Serializer_MGF.o
>>> ./pwiz/data/msdata/Serializer_mzXML.o
>>> ./pwiz/data/msdata/SpectrumList_mzML.o
>>> ./pwiz/data/msdata/SpectrumList_MSn.o
>>> ./pwiz/data/msdata/BinaryDataEncoder.o ./pwiz/data/msdata/Diff.o
>>> ./pwiz/data/msdata/MSData.o ./pwiz/data/msdata/References.o
>>> ./pwiz/data/msdata/SpectrumList_mzXML.o ./pwiz/data/msdata/IO.o
>>> ./pwiz/data/msdata/SpectrumList_BTDX.o ./pwiz/data/msdata/SpectrumInfo.o
>>> ./pwiz/data/msdata/RAMPAdapter.o ./pwiz/data/msdata/LegacyAdapter.o
>>> ./pwiz/data/msdata/SpectrumIterator.o ./pwiz/data/msdata/MSDataFile.o
>>> ./pwiz/data/msdata/MSNumpress.o ./pwiz/data/msdata/SpectrumListCache.o
>>> ./pwiz/data/msdata/Index_mzML.o
>>> ./pwiz/data/msdata/SpectrumWorkerThreads.o
>>> ./pwiz/data/identdata/IdentDataFile.o ./pwiz/data/identdata/IdentData.o
>>> ./pwiz/data/identdata/DefaultReaderList.o ./pwiz/data/identdata/Reader.o
>>> ./pwiz/data/identdata/Serializer_protXML.o
>>> ./pwiz/data/identdata/Serializer_pepXML.o
>>> ./pwiz/data/identdata/Serializer_mzid.o ./pwiz/data/identdata/IO.o
>>> ./pwiz/data/identdata/References.o ./pwiz/data/identdata/MascotReader.o
>>> ./pwiz/data/proteome/Modification.o ./pwiz/data/proteome/Digestion.o
>>> ./pwiz/data/proteome/Peptide.o ./pwiz/data/proteome/AminoAcid.o
>>> ./pwiz/utility/minimxml/XMLWriter.o ./pwiz/utility/minimxml/SAXParser.o
>>> ./pwiz/utility/chemistry/Chemistry.o
>>> ./pwiz/utility/chemistry/ChemistryData.o
>>> ./pwiz/utility/chemistry/MZTolerance.o ./pwiz/utility/misc/IntegerSet.o
>>> ./pwiz/utility/misc/Base64.o ./pwiz/utility/misc/IterationListener.o
>>> ./pwiz/utility/misc/MSIHandler.o ./pwiz/utility/misc/Filesystem.o
>>> ./pwiz/utility/misc/TabReader.o
>>> ./pwiz/utility/misc/random_access_compressed_ifstream.o
>>> ./pwiz/utility/misc/SHA1.o ./pwiz/utility/misc/SHA1Calculator.o
>>> ./pwiz/utility/misc/sha1calc.o ./random_access_gzFile.o ./RcppExports.o
>>> rampR.o R_init_mzR.o -lpthread -lnetcdf -L/usr/lib64/R/lib -lR
>>> g++: error: cramp.o: No such file or directory
>>> g++: error: ramp_base64.o: No such file or directory
>>> g++: error: ramp.o: No such file or directory
>>> g++: error: RcppRamp.o: No such file or directory
>>> g++: error: RcppRampModule.o: No such file or directory
>>> g++: error: rnetCDF.o: No such file or directory
>>> g++: error: RcppPwiz.o: No such file or directory
>>> g++: error: RcppPwizModule.o: No such file or directory
>>> g++: error: RcppIdent.o: No such file or directory
>>> g++: error: RcppIdentModule.o: No such file or directory
>>> /usr/share/R/make/shlib.mk:6: recipe for target 'mzR.so' failed
>>> make: *** [mzR.so] Error 1
>>>
>>> It did compile with 5.2.x (from devtoolset-4) and worked fine.
>>> I'm hoping you guys could confirm it is purely compiler problem? Or
>>> point me(not a real programmer) a way to troubleshoot it properly?
>>> many thanks,
>>> L.
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>> This email message may contain legally privileged and/or confidential
>> information.  If you are not the intended recipient(s), or the
>> employee or agent responsible for the delivery of this message to the
>> intended recipient(s), you are hereby notified that any disclosure,
>> copying, distribution, or use of this email message is prohibited.  If
>> you have received this message in error, please notify the sender
>> immediately by e-mail and delete this email message from your
>> computer. Thank you.
>


This email message may contain legally privileged and/or...{{dropped:2}}


From baron at upenn.edu  Thu Dec 22 00:22:08 2016
From: baron at upenn.edu (Jonathan Baron)
Date: Wed, 21 Dec 2016 18:22:08 -0500
Subject: [Rd] Fwd: Re: RSiteSearch, sos, rdocumentation.org, ...?
In-Reply-To: <20161217203224.GA15075@upenn.edu>
References: <20160907201522.GA12554@psych.upenn.edu>
	<20518b79-b272-b848-a736-a9acf225626b@prodsyse.com>
	<20160907205321.GB24417@psych.upenn.edu>
	<20160908020657.GA27642@psych.upenn.edu>
	<20160908100100.GA30732@psych.upenn.edu>
	<b7e7da04-0154-3dcb-fda9-be1d0dc13929@prodsyse.com>
	<20161217203224.GA15075@upenn.edu>
Message-ID: <20161221232208.GA25197@upenn.edu>

Unfortunately, I am unable to get this search site working again. (The
message below explains why I had to rebuild it.)

The computer worked for the better part of a day downloading and
installing all the help files from all CRAN packages. Somehow it
failed to get the vignettes this time. But I pushed ahead and ran the
part of namazu that makes the search indices: mknmz. And you can see
the results if you go to finzi.psych.upenn.edu. The search works, but
then you can't get the actual help pages.

The problem seems to be that namazu search is ignoring the "Replace"
rules in the configuration file, namazurc. I have tried 4 versions of
that file, in combination with 3 versions of namazu-cgi, and nothing
works. Note that the last version of namzu was about 2009, the result
of some fixes by linux distribution maintainers, not by the original
creators, who gave up a few years before.

If someone wants to replace namazu with a different search engine, let
me know. I do have a server with all the help files.

And I can tell you how I made them if you want to do this somewhere
else. The trick is:

update.packages(dependencies=FALSE,INSTALL_opts=c("--no-configure","--no-test-load","--no-R","--no-clean-on-error","--no-libs","--no-data","--no-demo","--no-exec","--html"),repos=biocinstallRepos(),ask=F)

and

install.packages(m3,dependencies=FALSE,INSTALL_opts=c("--no-configure","--no-test-load","--no-R","--no-clean-on-error","--no-libs","--no-data","--no-demo","--no-exec","--html"),repos=biocinstallRepos())

This works as is in the fedora version of R, which I think is modified
(for my benefit, about 10 years ago) from the distribution version,
and I think I know what the modification is. The first is for packages
I already have. The second can be used to build the site.

(I use the bioconductor repository because most of the time it doesn't
matter, but there were once a few packages that were only there, ones
that I used myself, like multtest.)

Of course, if there is a human being who reads this and wants to
fiddle with namazu, he or she should contact me.

Jon

On 12/17/16 15:32, Jonathan Baron wrote:
>Spencer and others.
>
>I am going to have to take down the server for RSiteSearch, which is
>finzi.psych.upenn.edu, for at least a couple of days starting Sunday
>morning. It has been hacked. And I have another server that has also
>been hacked, which is higher priority (sjdm.org). On Monday, I will
>probably have time to rebuild that one, but I may not have time to
>rebuild finzi for another week. I will try to get it all done in one
>day, but I don't know if I can.
>
>Sorry about this.
>
>I thought that there was an alternative to this site, namely
>http://rdocumentation.org/
>but, as bad is my site is, that one, I think, is worse.
>
>Jon

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
Editor: Judgment and Decision Making (http://journal.sjdm.org)


From dcdillon at gmail.com  Thu Dec 22 04:57:45 2016
From: dcdillon at gmail.com (Dan Dillon)
Date: Wed, 21 Dec 2016 21:57:45 -0600
Subject: [Rd] Is it possible to increase MAX_NUM_DLLS in future R releases?
Message-ID: <CAEWw9xUVqpmmQ9JCgfvA9PT3t_zKF_SCE+vVsKEQScg-WKVr7g@mail.gmail.com>

I have read both the historical r-devel threads and the most recent one
regarding this.  After reviewing the code, it would seem to beg for a
linked-list implementation vs. an array implementation.

This has several interesting consequences.

Cons:

1) We pay for dynamic allocation every time we register a DLL.  This isn't
a problem in the grand scheme of things as registering a DLL results in
other allocations (and is fairly infrequent).
2) Traversing the linked list is marginally more expensive than traversing
an array due to memory locality and prefetching.

Pros:

1) For the average R usage we decrease the memory footprint as we only
allocate what is needed.
2) For extreme use cases, we support it, but user beware (as symbol lookup
time will scale with number of loaded DLLs)
3) We open up the possibility of more dynamic ordering of the LoadedDLL
structure.  Essentially we can very cheaply move the most recently "used"
DLL to the front of the list.

The cons, I think, are small in this situation.  We already dynamically
allocate strings and arrays in the DllInfo strucutre so those are already
not memory-local.  Additionally, R is frequently operating on large
datasets so cache thrashing is almost a given.  The negligible time
increase in traversing the list, I believe, will be offset by the more
dynamic sorting that we are able to give that list.

I have written a patch that does this, however, I have not yet extensively
tested it.  If there is interest in including this in R for the future, I
am more than happy to do the testing necessary, however, if there is a
compelling reason to avoid this sort of implementation, I don't want to
spend hours testing.

The patch is available at
https://gist.github.com/dcdillon/814e769adbf53ff43961f106008b3312

Additionally, this will require cleanup at shutdown which I haven't yet
added, but will add it if it gets any traction.

Any feedback you have would be wonderful, and thank you for your time.

Dan Dillon

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Thu Dec 22 10:24:43 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 22 Dec 2016 10:24:43 +0100
Subject: [Rd] Unexpected I(NULL) output
In-Reply-To: <CAOiMVK21fs6VpZnQZ0jH0t5YeJ6TvcLyO7digyXBmzV23yEbpg@mail.gmail.com>
References: <CAOiMVK21fs6VpZnQZ0jH0t5YeJ6TvcLyO7digyXBmzV23yEbpg@mail.gmail.com>
Message-ID: <22619.39899.159293.404959@stat.math.ethz.ch>

>>>>> Florent Angly <florent.angly at gmail.com>
>>>>>     on Tue, 20 Dec 2016 13:42:37 +0100 writes:

    > Hi all,
    > I believe there is an issue with passing NULL to the function I().

    > class(NULL)  # "NULL"  (as expected)
    > print(NULL)   # NULL  (as expected)
    > is.null(NULL) # TRUE  (as expected)

    > According to the documentation I() should return a copy of its input
    > with class "AsIs" preprended:

    > class(I(NULL))  # "AsIs"  (as expected)
    > print(I(NULL))   # list()  (not expected! should be NULL)
    > is.null(I(NULL)) # FALSE  (not expected! should be TRUE)

    > So, I() does not behave according to its documentation. 

yes.

    > In R, it is
    > not possible to give NULL attributes, but I(NULL) attempts to do that
    > nonetheless, using the structure() function. Probably:
    > 1/ structure() should not accept NULL as input since the goal of
    > structure() is to set some attributes, something cannot be done on
    > NULL.

I tend to agree.  However if we gave an error now, I notice that
even our own code, e.g., in stats:::formula.default()  would fail.

Still, I think we should consider *deprecating*  structure(NULL, *),
so it would give a *warning* (and continue working otherwise)
(for a while before giving an error a year later).

    > 2/ I() could accept NULL, but, as an exception, not set an "AsIs"
    > class attribute on it. This would be in line with the philosophy of
    > the I() function to return an object that is functionally equivalent
    > to the input object.

If we'd adopt 2, the I(.) function would become slightly more
complicated and slower...  but possibly not practically
noticeable.

A last option would be

3/  The help page for I() could note what happens in the NULL case.

That would be the least work for everyone,
but at the moment, I tend to agree that '1/' is worth the pain to
have R's structure() become more consistent.

Martin Maechler
ETH Zurich

    > My sessionInfo() returns:
    >> sessionInfo()
    > R version 3.3.2 (2016-10-31)
    > Platform: x86_64-w64-mingw32/x64 (64-bit)
    > Running under: Windows 7 x64 (build 7601) Service Pack 1

    > locale:
    > [1] LC_COLLATE=German_Switzerland.1252
    > LC_CTYPE=German_Switzerland.1252
    > LC_MONETARY=German_Switzerland.1252 LC_NUMERIC=C
    > [5] LC_TIME=German_Switzerland.1252

    > attached base packages:
    > [1] stats     graphics  grDevices utils     datasets  methods   base

    > Best regards,

    > Florent

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From baron at upenn.edu  Thu Dec 22 18:29:10 2016
From: baron at upenn.edu (Jonathan Baron)
Date: Thu, 22 Dec 2016 12:29:10 -0500
Subject: [Rd] Fwd: Re: RSiteSearch, sos, rdocumentation.org, ...?
In-Reply-To: <20161221232208.GA25197@upenn.edu>
References: <20160907201522.GA12554@psych.upenn.edu>
	<20518b79-b272-b848-a736-a9acf225626b@prodsyse.com>
	<20160907205321.GB24417@psych.upenn.edu>
	<20160908020657.GA27642@psych.upenn.edu>
	<20160908100100.GA30732@psych.upenn.edu>
	<b7e7da04-0154-3dcb-fda9-be1d0dc13929@prodsyse.com>
	<20161217203224.GA15075@upenn.edu>
	<20161221232208.GA25197@upenn.edu>
Message-ID: <20161222172910.GA19180@upenn.edu>

The site is working again, although for some reason it did not
download any vignettes. I think that is OK.

On 12/21/16 18:22, Jonathan Baron wrote:
>Unfortunately, I am unable to get this search site working again. (The
>message below explains why I had to rebuild it.)

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
Editor: Judgment and Decision Making (http://journal.sjdm.org)


From richierocks at gmail.com  Sat Dec 24 00:24:53 2016
From: richierocks at gmail.com (Richard Cotton)
Date: Fri, 23 Dec 2016 18:24:53 -0500
Subject: [Rd] R-ints Argument Evaluation has out of date examples
Message-ID: <CAPp_+=dmK9-jbBcvBFVqGDqWBvxBko2pECVhESP9JwEQE2WJWg@mail.gmail.com>

In R-ints section 1.5

https://cran.r-project.org/doc/manuals/r-devel/R-ints.html#Argument-evaluation

it states

> Note that being a special/builtin is separate from being primitive
> or .Internal: quote is a special primitive, + is a builtin primitive,
> cbind is a special .Internal and grep is a builtin .Internal.

I think that the examples of cbind and grep might be out of date since
these both appear to be closures now.

typeof(cbind)
## "closure"
typeof(grep)
## "closure"

In fact, as far as I can tell, all the special and builtin functions
now use the primitive interface.  The following code returns an empty
list in R 3.3.2:

e <- as.environment("package:base")
vars <- mget(ls(e), e)
Filter(
  function(x) {
    typeof(x) %in% c("special", "builtin") && Negate(is.primitive)(x)
  },
  vars
)

Is it true to say that "being a special/builtin is separate from being
primitive on .Internal, however in practice all special and builtin
functions are primitive"?

-- 
Regards,
Richie

Learning R
4dpiecharts.com


From florent.angly at gmail.com  Sat Dec 24 14:27:49 2016
From: florent.angly at gmail.com (Florent Angly)
Date: Sat, 24 Dec 2016 14:27:49 +0100
Subject: [Rd] Unexpected I(NULL) output
In-Reply-To: <22619.39899.159293.404959@stat.math.ethz.ch>
References: <CAOiMVK21fs6VpZnQZ0jH0t5YeJ6TvcLyO7digyXBmzV23yEbpg@mail.gmail.com>
	<22619.39899.159293.404959@stat.math.ethz.ch>
Message-ID: <CAOiMVK0CVuRSi3L+wc_chWAiVmcNPgT-zJ3C3omEF_61-g55Gw@mail.gmail.com>

Thank you for the feedback, Martin. Of course, deprecating would be a
sensible way to go.
I filed this issue on BugZilla under # 17198.
Florent

On 22 December 2016 at 10:24, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>>>>>> Florent Angly <florent.angly at gmail.com>
>>>>>>     on Tue, 20 Dec 2016 13:42:37 +0100 writes:
>
>     > Hi all,
>     > I believe there is an issue with passing NULL to the function I().
>
>     > class(NULL)  # "NULL"  (as expected)
>     > print(NULL)   # NULL  (as expected)
>     > is.null(NULL) # TRUE  (as expected)
>
>     > According to the documentation I() should return a copy of its input
>     > with class "AsIs" preprended:
>
>     > class(I(NULL))  # "AsIs"  (as expected)
>     > print(I(NULL))   # list()  (not expected! should be NULL)
>     > is.null(I(NULL)) # FALSE  (not expected! should be TRUE)
>
>     > So, I() does not behave according to its documentation.
>
> yes.
>
>     > In R, it is
>     > not possible to give NULL attributes, but I(NULL) attempts to do that
>     > nonetheless, using the structure() function. Probably:
>     > 1/ structure() should not accept NULL as input since the goal of
>     > structure() is to set some attributes, something cannot be done on
>     > NULL.
>
> I tend to agree.  However if we gave an error now, I notice that
> even our own code, e.g., in stats:::formula.default()  would fail.
>
> Still, I think we should consider *deprecating*  structure(NULL, *),
> so it would give a *warning* (and continue working otherwise)
> (for a while before giving an error a year later).
>
>     > 2/ I() could accept NULL, but, as an exception, not set an "AsIs"
>     > class attribute on it. This would be in line with the philosophy of
>     > the I() function to return an object that is functionally equivalent
>     > to the input object.
>
> If we'd adopt 2, the I(.) function would become slightly more
> complicated and slower...  but possibly not practically
> noticeable.
>
> A last option would be
>
> 3/  The help page for I() could note what happens in the NULL case.
>
> That would be the least work for everyone,
> but at the moment, I tend to agree that '1/' is worth the pain to
> have R's structure() become more consistent.
>
> Martin Maechler
> ETH Zurich
>
>     > My sessionInfo() returns:
>     >> sessionInfo()
>     > R version 3.3.2 (2016-10-31)
>     > Platform: x86_64-w64-mingw32/x64 (64-bit)
>     > Running under: Windows 7 x64 (build 7601) Service Pack 1
>
>     > locale:
>     > [1] LC_COLLATE=German_Switzerland.1252
>     > LC_CTYPE=German_Switzerland.1252
>     > LC_MONETARY=German_Switzerland.1252 LC_NUMERIC=C
>     > [5] LC_TIME=German_Switzerland.1252
>
>     > attached base packages:
>     > [1] stats     graphics  grDevices utils     datasets  methods   base
>
>     > Best regards,
>
>     > Florent
>
>     > ______________________________________________
>     > R-devel at r-project.org mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-devel


From florent.angly at gmail.com  Sat Dec 24 14:33:26 2016
From: florent.angly at gmail.com (Florent Angly)
Date: Sat, 24 Dec 2016 14:33:26 +0100
Subject: [Rd] Very small numbers in hexadecimal notation parsed as zero
In-Reply-To: <22618.26443.81856.947714@stat.math.ethz.ch>
References: <CAOiMVK3atf7-Vj96VMcfqDdRMnM2_9fU5t2DoZC_TNeMxo=toQ@mail.gmail.com>
	<22618.26443.81856.947714@stat.math.ethz.ch>
Message-ID: <CAOiMVK10y1TaP-=6Gf8Hff=p6BpbpXeeV3q3jcSkqsHV8VHWCQ@mail.gmail.com>

Hi Martin,
Thanks for the Bugzilla account. I have filed this bug under number 17199.
Cheers,
Florent

On 21 December 2016 at 12:28, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>>>>>> Florent Angly <florent.angly at gmail.com>
>>>>>>     on Tue, 20 Dec 2016 13:26:36 +0100 writes:
>
>     > Hi all,
>     > I have noticed incorrect parsing of very small hexadecimal numbers
>     > like "0x1.00000000d0000p-987". Such a hexadecimal representation can
>     > can be produced by sprintf() using the %a flag. The return value is
>     > incorrectly reported as 0 when coercing these numbers to double using
>     > as.double()/as.numeric(), as illustrated in the three examples below:
>
>     > as.double("0x1.00000000d0000p-987")    # should be 7.645296e-298
>     > as.double("0x1.0000000000000p-1022")  # should be 2.225074e-308
>     > as.double("0x1.f89fc1a6f6613p-974")      # should be 1.23456e-293
>
>     > The culprit seems to be the src/main/util.c:R_strtod function and in
>     > some cases, removing the zeroes directly before the 'p' leads to
>     > correct parsing:
>
>     > as.double("0x1.00000000dp-987") # 7.645296e-298, as expected
>     > as.double("0x1.p-1022")         # 2.225074e-308, as expected
>
> Yes, this looks like a bug, indeed.
> Similarly convincing is a simple comparison (of even less extreme)
>
>> as.double("0x1p-987")
> [1] 7.645296e-298
>> as.double("0x1.0000000000p-987")
> [1] 0
>>
>
> The "bug boundary" seems around here:
>
>> as.double("0x1.000000000000000000000000p-928") # fails
> [1] 0
>> as.double("0x1p-928")
> [1] 4.407213e-280
>>
>
>> as.double("0x1.000000000000000000000000p-927") # works
> [1] 8.814426e-280
>
> but then adding more zeros before "p-927" also underflows.
>
> --> I have created an R bugzilla account for you; so you now
>  can submit bug reports (including patch proposals to the source (hint!) ;-)
>
> Thank you, Florent!
> Martin


From lgautier at gmail.com  Tue Dec 27 05:25:26 2016
From: lgautier at gmail.com (Laurent Gautier)
Date: Mon, 26 Dec 2016 23:25:26 -0500
Subject: [Rd] Definition of uintptr_t in Rinterface.h
Message-ID: <CA+JCgN0pwwmtPZ+p4Yf2fi1uXb2r-0H1jD+hOj1iWi58EiO-_A@mail.gmail.com>

Hi,

I was recently pointed out that a definition in Rinterface.h can be conflicting
with a definition in stdint.h:

/usr/include/R/Rinterface.h has:
 typedef unsigned long uintptr_t;

/usr/include/stdint.h has:
 typedef unsigned int uintptr_t;
 (when 32bit platform complete definition is:

#if __WORDSIZE == 64
# ifndef __intptr_t_defined
typedef long int                intptr_t;
#  define __intptr_t_defined
# endif
typedef unsigned long int       uintptr_t;
#else
# ifndef __intptr_t_defined
typedef int                     intptr_t;
#  define __intptr_t_defined
# endif
typedef unsigned int            uintptr_t;
#endif

)

Is this expected ? Shouldn't R rely on the definition in stdint.h
rather than define its own ?


(report for the issue:
https://bitbucket.org/rpy2/rpy2/issues/389/failed-to-compile-with-python-360-on-32
)


Laurent

	[[alternative HTML version deleted]]


From hanson at depauw.edu  Tue Dec 27 16:00:36 2016
From: hanson at depauw.edu (Bryan Hanson)
Date: Tue, 27 Dec 2016 10:00:36 -0500
Subject: [Rd] Proper attribution in Authors@R for the d3.js library by Mike
	Bostock
Message-ID: <3EB21FE6-56D2-49D9-820A-55FBDEDD1F65@depauw.edu>

I have a couple of packages that use the d3.js library developed (and copyrighted) by Mike Bostock.  One package uses it extensively, another only for one function.  I use R to piece together parts files containing JavaScript that I have written, which use d3.js functions and eventually the d3 library is called from a temporary web page.

To date, I have pointed to Bostock's library in the Rd files.  However, there are a growing number of packages that use d3.js now, and the habit (standard?) now seems to be to put Bostock in Authors at R, but they do so in different ways.  Here are a few examples:

D3partitionR:  Mike Bostock [aut, cph] (d3.js library in htmlwidgets/lib, http://d3js.org. The partitionChart, sunburst, the treemap, the zoomable circlePacking, the collapsible indented tree and the collapsible tree are all derived from his works.)

scatterD3:  Mike Bostock [aut, cph] (d3.js library, http://d3js.org)

qrage:  Michael Bostock [ctb, cph] (D3.js library)

And there are others.

?person offers the following options that seem relevant:

"aut"
(Author) Use for full authors who have made substantial contributions to the package and should show up in the package citation.

"com"
(Compiler) Use for persons who collected code (potentially in other languages) but did not make further substantial contributions to the package.

"ctb"
(Contributor) Use for authors who have made smaller contributions (such as code patches etc.) but should not show up in the package citation.

"cph"
(Copyright holder) Use for all copyright holders.

Questions: What is the proper attribution in this case?  Bostock is clearly cph.  Is that sufficient?  I'm not completely certain about the intentions of "com" but it may fit.  "ctb" sounds insufficient and "aut" seems to be a bit much (can you be an author of an R package and not know about it?).  Is there a CRAN policy about this?

Thanks for any thoughts and guidance.  Bryan
****************
Prof. Bryan Hanson
Dept of Chemistry & Biochemistry
DePauw University
Greencastle IN 46135 USA
academic.depauw.edu/~hanson/index.html
github.com/bryanhanson


From J.Gorecki at wit.edu.pl  Tue Dec 27 18:48:01 2016
From: J.Gorecki at wit.edu.pl (Jan Gorecki)
Date: Tue, 27 Dec 2016 17:48:01 +0000
Subject: [Rd] colnames for data.frame could be greatly improved
In-Reply-To: <CABE2sp5=-rL8_EkwSngruhfrF8mEDn_-RO6UN2PA538S+Revpw@mail.gmail.com>
References: <CABE2sp5=-rL8_EkwSngruhfrF8mEDn_-RO6UN2PA538S+Revpw@mail.gmail.com>
Message-ID: <CABE2sp4_x6RsD=b20QbkypeP4+82SnE1AKfVz1sHaAvsUPCyag@mail.gmail.com>

Hi there,
Any update on this?
Should I create bugzilla ticket and submit patch?
Regards
Jan Gorecki

On 20 December 2016 at 01:27, Jan Gorecki <J.Gorecki at wit.edu.pl> wrote:
> Hello,
>
> colnames seems to be not optimized well for data.frame. It escapes
> processing for data.frame in
>
>   if (is.data.frame(x) && do.NULL)
>     return(names(x))
>
> but only when do.NULL true. This makes huge difference when do.NULL
> false. Minimal edit to `colnames`:
>
>     if (is.data.frame(x)) {
>         nm <- names(x)
>         if (do.NULL || !is.null(nm))
>             return(nm)
>         else
>             return(paste0(prefix, seq_along(x)))
>     }
>
> Script and timings:
>
> N=1e7; K=100
> set.seed(1)
> DF <- data.frame(
>     id1 = sample(sprintf("id%03d",1:K), N, TRUE),      # large groups (char)
>     id2 = sample(sprintf("id%03d",1:K), N, TRUE),      # large groups (char)
>     id3 = sample(sprintf("id%010d",1:(N/K)), N, TRUE), # small groups (char)
>     id4 = sample(K, N, TRUE),                          # large groups (int)
>     id5 = sample(K, N, TRUE),                          # large groups (int)
>     id6 = sample(N/K, N, TRUE),                        # small groups (int)
>     v1 =  sample(5, N, TRUE),                          # int in range [1,5]
>     v2 =  sample(5, N, TRUE),                          # int in range [1,5]
>     v3 =  sample(round(runif(100,max=100),4), N, TRUE) # numeric e.g. 23.5749
> )
> cat("GB =", round(sum(gc()[,2])/1024, 3), "\n")
> #GB = 0.397
> colnames(DF) = NULL
> system.time(nm1<-colnames(DF, FALSE))
> #   user  system elapsed
> # 22.158   0.299  22.498
> print(nm1)
> #[1] "col1" "col2" "col3" "col4" "col5" "col6" "col7" "col8" "col9"
>
> ### restart R
>
> colnames <- function (x, do.NULL = TRUE, prefix = "col")
> {
>     if (is.data.frame(x)) {
>         nm <- names(x)
>         if (do.NULL || !is.null(nm))
>             return(nm)
>         else
>             return(paste0(prefix, seq_along(x)))
>     }
>     dn <- dimnames(x)
>     if (!is.null(dn[[2L]]))
>         dn[[2L]]
>     else {
>         nc <- NCOL(x)
>         if (do.NULL)
>             NULL
>         else if (nc > 0L)
>             paste0(prefix, seq_len(nc))
>         else character()
>     }
> }
> N=1e7; K=100
> set.seed(1)
> DF <- data.frame(
>     id1 = sample(sprintf("id%03d",1:K), N, TRUE),      # large groups (char)
>     id2 = sample(sprintf("id%03d",1:K), N, TRUE),      # large groups (char)
>     id3 = sample(sprintf("id%010d",1:(N/K)), N, TRUE), # small groups (char)
>     id4 = sample(K, N, TRUE),                          # large groups (int)
>     id5 = sample(K, N, TRUE),                          # large groups (int)
>     id6 = sample(N/K, N, TRUE),                        # small groups (int)
>     v1 =  sample(5, N, TRUE),                          # int in range [1,5]
>     v2 =  sample(5, N, TRUE),                          # int in range [1,5]
>     v3 =  sample(round(runif(100,max=100),4), N, TRUE) # numeric e.g. 23.5749
> )
> cat("GB =", round(sum(gc()[,2])/1024, 3), "\n")
> #GB = 0.397
> colnames(DF) = NULL
> system.time(nm1<-colnames(DF, FALSE))
> #   user  system elapsed
> #  0.001   0.000   0.000
> print(nm1)
> #[1] "col1" "col2" "col3" "col4" "col5" "col6" "col7" "col8" "col9"
>
> sessionInfo()
> #R Under development (unstable) (2016-12-19 r71815)
> #Platform: x86_64-pc-linux-gnu (64-bit)
> #Running under: Debian GNU/Linux stretch/sid
> #
> #locale:
> # [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> # [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
> # [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
> # [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
> # [9] LC_ADDRESS=C               LC_TELEPHONE=C
> #[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> #
> #attached base packages:
> #[1] stats     graphics  grDevices utils     datasets  methods   base  #
> #
> #loaded via a namespace (and not attached):
> #[1] compiler_3.4.0


From simon.urbanek at r-project.org  Thu Dec 29 16:55:36 2016
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 29 Dec 2016 10:55:36 -0500
Subject: [Rd] Definition of uintptr_t in Rinterface.h
In-Reply-To: <CA+JCgN0pwwmtPZ+p4Yf2fi1uXb2r-0H1jD+hOj1iWi58EiO-_A@mail.gmail.com>
References: <CA+JCgN0pwwmtPZ+p4Yf2fi1uXb2r-0H1jD+hOj1iWi58EiO-_A@mail.gmail.com>
Message-ID: <3ECD3048-DC04-467B-BD33-787A4E70FE67@r-project.org>

The problem is elsewhere - Rinterface.h guards the ultima-ratio fallback with HAVE_UINTPTR_T but that config flag is not exported in Rconfig.h. Should be now fixed in R-devel - please check if that works for you.

Thanks,
Simon



> On Dec 26, 2016, at 11:25 PM, Laurent Gautier <lgautier at gmail.com> wrote:
> 
> Hi,
> 
> I was recently pointed out that a definition in Rinterface.h can be conflicting
> with a definition in stdint.h:
> 
> /usr/include/R/Rinterface.h has:
> typedef unsigned long uintptr_t;
> 
> /usr/include/stdint.h has:
> typedef unsigned int uintptr_t;
> (when 32bit platform complete definition is:
> 
> #if __WORDSIZE == 64
> # ifndef __intptr_t_defined
> typedef long int                intptr_t;
> #  define __intptr_t_defined
> # endif
> typedef unsigned long int       uintptr_t;
> #else
> # ifndef __intptr_t_defined
> typedef int                     intptr_t;
> #  define __intptr_t_defined
> # endif
> typedef unsigned int            uintptr_t;
> #endif
> 
> )
> 
> Is this expected ? Shouldn't R rely on the definition in stdint.h
> rather than define its own ?
> 
> 
> (report for the issue:
> https://bitbucket.org/rpy2/rpy2/issues/389/failed-to-compile-with-python-360-on-32
> )
> 
> 
> Laurent
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From lgautier at gmail.com  Thu Dec 29 19:00:22 2016
From: lgautier at gmail.com (Laurent Gautier)
Date: Thu, 29 Dec 2016 13:00:22 -0500
Subject: [Rd] Definition of uintptr_t in Rinterface.h
In-Reply-To: <3ECD3048-DC04-467B-BD33-787A4E70FE67@r-project.org>
References: <CA+JCgN0pwwmtPZ+p4Yf2fi1uXb2r-0H1jD+hOj1iWi58EiO-_A@mail.gmail.com>
	<3ECD3048-DC04-467B-BD33-787A4E70FE67@r-project.org>
Message-ID: <CA+JCgN20Ezopbu=dEuJjoces9=fS06sYHrgDG=sALfHO=pPSBg@mail.gmail.com>

Thanks for looking at it. Having  HAVE_UINTPTR_T defined in Rconfig.h
should fix the issue. Will the fix make it to R-3.3.3 (if that point
release is planned, or R-3.3.2-patched), or will it only be with R-3.4 ?


L.

PS: I am forwarding a thank you note to the reporter of the problem on the
rpy2 issue tracker.


2016-12-29 10:55 GMT-05:00 Simon Urbanek <simon.urbanek at r-project.org>:

> The problem is elsewhere - Rinterface.h guards the ultima-ratio fallback
> with HAVE_UINTPTR_T but that config flag is not exported in Rconfig.h.
> Should be now fixed in R-devel - please check if that works for you.
>
> Thanks,
> Simon
>
>
>
> > On Dec 26, 2016, at 11:25 PM, Laurent Gautier <lgautier at gmail.com>
> wrote:
> >
> > Hi,
> >
> > I was recently pointed out that a definition in Rinterface.h can be
> conflicting
> > with a definition in stdint.h:
> >
> > /usr/include/R/Rinterface.h has:
> > typedef unsigned long uintptr_t;
> >
> > /usr/include/stdint.h has:
> > typedef unsigned int uintptr_t;
> > (when 32bit platform complete definition is:
> >
> > #if __WORDSIZE == 64
> > # ifndef __intptr_t_defined
> > typedef long int                intptr_t;
> > #  define __intptr_t_defined
> > # endif
> > typedef unsigned long int       uintptr_t;
> > #else
> > # ifndef __intptr_t_defined
> > typedef int                     intptr_t;
> > #  define __intptr_t_defined
> > # endif
> > typedef unsigned int            uintptr_t;
> > #endif
> >
> > )
> >
> > Is this expected ? Shouldn't R rely on the definition in stdint.h
> > rather than define its own ?
> >
> >
> > (report for the issue:
> > https://bitbucket.org/rpy2/rpy2/issues/389/failed-to-
> compile-with-python-360-on-32
> > )
> >
> >
> > Laurent
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Thu Dec 29 19:13:39 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 29 Dec 2016 19:13:39 +0100
Subject: [Rd] colnames for data.frame could be greatly improved
In-Reply-To: <CABE2sp4_x6RsD=b20QbkypeP4+82SnE1AKfVz1sHaAvsUPCyag@mail.gmail.com>
References: <CABE2sp5=-rL8_EkwSngruhfrF8mEDn_-RO6UN2PA538S+Revpw@mail.gmail.com>
	<CABE2sp4_x6RsD=b20QbkypeP4+82SnE1AKfVz1sHaAvsUPCyag@mail.gmail.com>
Message-ID: <22629.21075.207022.633766@stat.math.ethz.ch>

> Hi there,
> Any update on this?
> Should I create bugzilla ticket and submit patch?

> Regards
> Jan Gorecki

Hi Jan,

Why should we care that the  do.NULL = FALSE case is slower?
After all do.NULL = TRUE is the default.

In other words, where are use cases where it is problematic that
do.NULL = FALSE is relatively slow?

Shorter code  *is* nicer than longer code,  so I need a bit more
conviction why we should add more code for that special case ..

Martin Maechler, ETH Zurich

> On 20 December 2016 at 01:27, Jan Gorecki <J.Gorecki at wit.edu.pl> wrote:
> > Hello,
> >
> > colnames seems to be not optimized well for data.frame. It escapes
> > processing for data.frame in
> >
> >   if (is.data.frame(x) && do.NULL)
> >     return(names(x))
> >
> > but only when do.NULL true. This makes huge difference when do.NULL
> > false. Minimal edit to `colnames`:
> >
> >     if (is.data.frame(x)) {
> >         nm <- names(x)
> >         if (do.NULL || !is.null(nm))
> >             return(nm)
> >         else
> >             return(paste0(prefix, seq_along(x)))
> >     }
> >
> > Script and timings:
> >
> > N=1e7; K=100
> > set.seed(1)
> > DF <- data.frame(
> >     id1 = sample(sprintf("id%03d",1:K), N, TRUE),      # large groups (char)
> >     id2 = sample(sprintf("id%03d",1:K), N, TRUE),      # large groups (char)
> >     id3 = sample(sprintf("id%010d",1:(N/K)), N, TRUE), # small groups (char)
> >     id4 = sample(K, N, TRUE),                          # large groups (int)
> >     id5 = sample(K, N, TRUE),                          # large groups (int)
> >     id6 = sample(N/K, N, TRUE),                        # small groups (int)
> >     v1 =  sample(5, N, TRUE),                          # int in range [1,5]
> >     v2 =  sample(5, N, TRUE),                          # int in range [1,5]
> >     v3 =  sample(round(runif(100,max=100),4), N, TRUE) # numeric e.g. 23.5749
> > )
> > cat("GB =", round(sum(gc()[,2])/1024, 3), "\n")
> > #GB = 0.397
> > colnames(DF) = NULL
> > system.time(nm1<-colnames(DF, FALSE))
> > #   user  system elapsed
> > # 22.158   0.299  22.498
> > print(nm1)
> > #[1] "col1" "col2" "col3" "col4" "col5" "col6" "col7" "col8" "col9"
> >
> > ### restart R
> >
> > colnames <- function (x, do.NULL = TRUE, prefix = "col")
> > {
> >     if (is.data.frame(x)) {
> >         nm <- names(x)
> >         if (do.NULL || !is.null(nm))
> >             return(nm)
> >         else
> >             return(paste0(prefix, seq_along(x)))
> >     }
> >     dn <- dimnames(x)
> >     if (!is.null(dn[[2L]]))
> >         dn[[2L]]
> >     else {
> >         nc <- NCOL(x)
> >         if (do.NULL)
> >             NULL
> >         else if (nc > 0L)
> >             paste0(prefix, seq_len(nc))
> >         else character()
> >     }
> > }
> > N=1e7; K=100
> > set.seed(1)
> > DF <- data.frame(
> >     id1 = sample(sprintf("id%03d",1:K), N, TRUE),      # large groups (char)
> >     id2 = sample(sprintf("id%03d",1:K), N, TRUE),      # large groups (char)
> >     id3 = sample(sprintf("id%010d",1:(N/K)), N, TRUE), # small groups (char)
> >     id4 = sample(K, N, TRUE),                          # large groups (int)
> >     id5 = sample(K, N, TRUE),                          # large groups (int)
> >     id6 = sample(N/K, N, TRUE),                        # small groups (int)
> >     v1 =  sample(5, N, TRUE),                          # int in range [1,5]
> >     v2 =  sample(5, N, TRUE),                          # int in range [1,5]
> >     v3 =  sample(round(runif(100,max=100),4), N, TRUE) # numeric e.g. 23.5749
> > )
> > cat("GB =", round(sum(gc()[,2])/1024, 3), "\n")
> > #GB = 0.397
> > colnames(DF) = NULL
> > system.time(nm1<-colnames(DF, FALSE))
> > #   user  system elapsed
> > #  0.001   0.000   0.000
> > print(nm1)
> > #[1] "col1" "col2" "col3" "col4" "col5" "col6" "col7" "col8" "col9"
> >
> > sessionInfo()
> > #R Under development (unstable) (2016-12-19 r71815)
> > #Platform: x86_64-pc-linux-gnu (64-bit)
> > #Running under: Debian GNU/Linux stretch/sid
> > #
> > #locale:
> > # [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> > # [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
> > # [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
> > # [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
> > # [9] LC_ADDRESS=C               LC_TELEPHONE=C
> > #[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> > #
> > #attached base packages:
> > #[1] stats     graphics  grDevices utils     datasets  methods   base  #
> > #
> > #loaded via a namespace (and not attached):
> > #[1] compiler_3.4.0
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Thu Dec 29 22:32:08 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 29 Dec 2016 22:32:08 +0100
Subject: [Rd] structure(NULL,
	*) is deprecated [was: Unexpected I(NULL) output]
In-Reply-To: <22619.39899.159293.404959@stat.math.ethz.ch>
References: <CAOiMVK21fs6VpZnQZ0jH0t5YeJ6TvcLyO7digyXBmzV23yEbpg@mail.gmail.com>
	<22619.39899.159293.404959@stat.math.ethz.ch>
Message-ID: <22629.32984.972882.101335@stat.math.ethz.ch>

>>>>> Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Thu, 22 Dec 2016 10:24:43 +0100 writes:

>>>>> Florent Angly <florent.angly at gmail.com>
>>>>>     on Tue, 20 Dec 2016 13:42:37 +0100 writes:

    >> Hi all,
    >> I believe there is an issue with passing NULL to the function I().

    >> class(NULL)  # "NULL"  (as expected)
    >> print(NULL)   # NULL  (as expected)
    >> is.null(NULL) # TRUE  (as expected)

    >> According to the documentation I() should return a copy of its input
    >> with class "AsIs" preprended:

    >> class(I(NULL))  # "AsIs"  (as expected)
    >> print(I(NULL))   # list()  (not expected! should be NULL)
    >> is.null(I(NULL)) # FALSE  (not expected! should be TRUE)

    >> So, I() does not behave according to its documentation. 

    > yes.

    >> In R, it is
    >> not possible to give NULL attributes, but I(NULL) attempts to do that
    >> nonetheless, using the structure() function. Probably:
    >> 1/ structure() should not accept NULL as input since the goal of
    >> structure() is to set some attributes, something cannot be done on
    >> NULL.

    > I tend to agree.  However if we gave an error now, I notice that
    > even our own code, e.g., in stats:::formula.default()  would fail.

    > Still, I think we should consider *deprecating*  structure(NULL, *),
    > so it would give a *warning* (and continue working otherwise)
    > (for a while before giving an error a year later).

 [......................]

    > Martin Maechler
    > ETH Zurich

Since svn rev 71841,   structure(NULL, *) now __is__ deprecated
in R-devel, i.e.,

  > structure(NULL, foo = 2)
  list()
  attr(,"foo")
  [1] 2
  Warning message:
  In structure(NULL, foo = 2) :
    Calling 'structure(NULL, *)' is deprecated, as NULL cannot have attributes.
    Consider 'structure(list(), *)' instead.
  > 

A dozen or so CRAN packages now not only give warnings but
partially also  ERRORS in their checks,  which I find strange,
but it may be because of too stringent checks (e.g. checks were
all warnings are turned into errors).

The most prominent packages now giving errors are
data.table and ggplot2,  then also GGally.

Of course, we (the R core team) could make the deprecation even
milder by not giving a warning() but only a message(.) aka
"NOTE";  however, that renders the deprecation process longer and more
complicated (notably for us),  and there is still a few months' time
before this version of R will be released...
and really, as I said,... a new warning should rarely cause
*errors* but rather warnings.

OTOH, some of us have now seen / read on the  R-package-devel  mailing list
that it seems ggplot2 has stopped working correctly (under
R-devel only!) in building packages because of this warning.. 

The current plan is it will eventually, i.e., after the
deprecation period, become an error, so ideally packages are
patched and re-released ASAP.  It's bedtime here now and we will
see tomorrow how to continue.

My current plan is to an e-mail to the package maintainers of CRAN
packages that are affected, at least for those packages that are "easy to find".

Martin Maechler,
ETH Zurich


