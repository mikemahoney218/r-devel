From murdoch.duncan at gmail.com  Sat Sep  1 02:48:19 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 31 Aug 2012 20:48:19 -0400
Subject: [Rd] CRAN check error with no example?
In-Reply-To: <50383113.9090401@prodsyse.com>
References: <5037E65D.3020501@prodsyse.com>
	<CAFDcVCRaPpu5rFPndrEo=fJa4Jbpe2j01Qh3pNoV5pONnsgdCw@mail.gmail.com>
	<50383113.9090401@prodsyse.com>
Message-ID: <50415B53.7090008@gmail.com>

On 12-08-24 9:57 PM, Spencer Graves wrote:
> Hi, Henrik:
>
>
>         Thanks.  That suggests I should ignore this error message. That
> was my tentative plan, but I felt a need to mention it to this group
> before I did.

Brian Ripley tracked this to a bug in the parser, and I got a 
reproducible version of it to work on today.  Turns out it was a fairly 
obscure garbage collection/protection bug in the parser, which should 
now be fixed.  I don't think it really has anything to do with your 
code, you just got lucky and triggered a garbage collection at the right 
(wrong?) time.

If you see it again, please don't ignore it, please let me know.

Duncan Murdoch

>
>
>         Best Wishes,
>         Spencer
>
>
> On 8/24/2012 3:35 PM, Henrik Bengtsson wrote:
>> For what it's worth, I got that exact same error the other day when
>> running R CMD check --as-cran on fda v2.2.8 and 'hyperSpec
>> v0.98-20120713 (out of 84 other packages) when using R Under
>> development (unstable) (2012-08-14 r60264) [Platform:
>> x86_64-w64-mingw32/x64 (64-bit)].  Those errors did not show with R
>> version 2.15.1 Patched (2012-08-16 r60282) [Platform:
>> x86_64-w64-mingw32/x64 (64-bit)].
>>
>> /Henrik
>>
>> On Fri, Aug 24, 2012 at 1:38 PM, Spencer Graves
>> <spencer.graves at prodsyse.com> wrote:
>>> Hello, All:
>>>
>>>
>>>          The CRAN checks for the "fda" package includes one error:
>>>
>>>
>>> The error most likely occurred in ... file.copy2
>>> ...
>>>
>>> Error: unprotect_ptr: pointer not found
>>> Execution halted
>>>
>>>
>>> (http://www.r-project.org/nosvn/R.check/r-devel-linux-x86_64-debian/fda-00check.html)
>>>
>>>
>>>          The help page for "file.copy2" includes "\examples" with
>>> everything wrapped in "\dontrun".
>>>
>>>
>>>          I'm unable to replicate this error.  I'm about to submit a new
>>> version of the fda package to CRAN, but I felt a need to ask about this
>>> first.
>>>
>>>
>>>          Thanks,
>>>          Spencer
>>>
>>>
>>>           [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From spencer.graves at prodsyse.com  Sat Sep  1 03:20:18 2012
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Fri, 31 Aug 2012 18:20:18 -0700
Subject: [Rd] CRAN check error with no example?
In-Reply-To: <50415B53.7090008@gmail.com>
References: <5037E65D.3020501@prodsyse.com>
	<CAFDcVCRaPpu5rFPndrEo=fJa4Jbpe2j01Qh3pNoV5pONnsgdCw@mail.gmail.com>
	<50383113.9090401@prodsyse.com> <50415B53.7090008@gmail.com>
Message-ID: <504162D2.2090906@prodsyse.com>

On 8/31/2012 5:48 PM, Duncan Murdoch wrote:
> On 12-08-24 9:57 PM, Spencer Graves wrote:
>> Hi, Henrik:
>>
>>
>>         Thanks.  That suggests I should ignore this error message. That
>> was my tentative plan, but I felt a need to mention it to this group
>> before I did.
>
> Brian Ripley tracked this to a bug in the parser, and I got a 
> reproducible version of it to work on today.  Turns out it was a 
> fairly obscure garbage collection/protection bug in the parser, which 
> should now be fixed.  I don't think it really has anything to do with 
> your code, you just got lucky and triggered a garbage collection at 
> the right (wrong?) time.


       Thanks for tracking this down.  Spencer

>
> If you see it again, please don't ignore it, please let me know.
>
> Duncan Murdoch
>
>>
>>
>>         Best Wishes,
>>         Spencer
>>
>>
>> On 8/24/2012 3:35 PM, Henrik Bengtsson wrote:
>>> For what it's worth, I got that exact same error the other day when
>>> running R CMD check --as-cran on fda v2.2.8 and 'hyperSpec
>>> v0.98-20120713 (out of 84 other packages) when using R Under
>>> development (unstable) (2012-08-14 r60264) [Platform:
>>> x86_64-w64-mingw32/x64 (64-bit)].  Those errors did not show with R
>>> version 2.15.1 Patched (2012-08-16 r60282) [Platform:
>>> x86_64-w64-mingw32/x64 (64-bit)].
>>>
>>> /Henrik
>>>
>>> On Fri, Aug 24, 2012 at 1:38 PM, Spencer Graves
>>> <spencer.graves at prodsyse.com> wrote:
>>>> Hello, All:
>>>>
>>>>
>>>>          The CRAN checks for the "fda" package includes one error:
>>>>
>>>>
>>>> The error most likely occurred in ... file.copy2
>>>> ...
>>>>
>>>> Error: unprotect_ptr: pointer not found
>>>> Execution halted
>>>>
>>>>
>>>> (http://www.r-project.org/nosvn/R.check/r-devel-linux-x86_64-debian/fda-00check.html) 
>>>>
>>>>
>>>>
>>>>          The help page for "file.copy2" includes "\examples" with
>>>> everything wrapped in "\dontrun".
>>>>
>>>>
>>>>          I'm unable to replicate this error.  I'm about to submit a 
>>>> new
>>>> version of the fda package to CRAN, but I felt a need to ask about 
>>>> this
>>>> first.
>>>>
>>>>
>>>>          Thanks,
>>>>          Spencer
>>>>
>>>>
>>>>           [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>


From winstonchang1 at gmail.com  Sun Sep  2 06:25:15 2012
From: winstonchang1 at gmail.com (Winston Chang)
Date: Sat, 1 Sep 2012 23:25:15 -0500
Subject: [Rd] Environment when NextMethod is used
Message-ID: <CAFOpNVFVEeQcJM5GZ154dnjjpH7MtXk8uX7joM6FkP5mGjQW-A@mail.gmail.com>

I'm running into some hard-to-understand behavior with the evaluation
environment when NextMethod is used. I'm using square-bracket indexing
into objects, and the evaluation environment of the expression inside
the square brackets seems to change depending on what kind of
comparison operators are used.

This behavior happens when the following conditions are met (this is
what I've found; I'm sure that these aren't necessary and sufficient
conditions):
- I call a function from an attached package.
- The function uses square bracket indexing with a class that has its
own definition of the operator, such as `[.factor` or `[.POSIXct`. (If
a vector of numerics is used, the error doesn't happen.)
- The indexing function uses NextMethod("[").
- An S3 method is used within the square brackets. (When a regular
function is used, there's no error.)
- The S3 method is from a package that is an import for the original
function's package, but this package is not attached. (If the package
is attached, then the error doesn't happen because R finds the method
in the standard search path.)
- An operator like == is used. (If the %in% operator is used, the
error doesn't happen.)


This may sound very abstract. I've created a sample package that
illustrates the behavior. The package is called envtest, and it has a
function called envtest(), which uses an S3 method from the nlme
package. nlme is listed as an import.

You can either clone the repository here:
  https://github.com/wch/envtest
Or you can install it with devtools, using:
  library(devtools)
  dev_mode()
  install_github('envtest', 'wch')



The envtest() function tries to index into a factor in different ways,
and prints the output for each one. This is the content of the
function. (If you load it from the global environment, it won't have
the same error, since the issue has to do with an import):

envtest <- function() {
  dat <- data.frame(x = 0, y = 0)
  f <- factor(c("a", "b"))

  # Print the starting data
  cat("\nf                                                : ")
  cat(f)

  cat("\n\nTests with %in% operator ----------------------------")

  # OK
  cat('\n"x" %in% Names(y ~ x, data = dat)                : ')
  cat("x" %in% Names(y ~ x, data = dat))

  # OK: Save boolean values to idx, then use f[idx]
  cat('\nidx <- "x" %in% Names(y ~ x, data = dat); f[idx] : ')
  cat({idx <- "x" %in% Names(y ~ x, data = dat); f[idx]})

  # OK: Use the expression with S3 function Names directly inside of []
  cat('\nf["x" %in% Names(y ~ x, data = dat)]             : ')
  cat(f["x" %in% Names(y ~ x, data = dat)])


  cat("\n\nTests with == operator ------------------------------")

  # OK
  cat('\n"x" == Names(y ~ x, data = dat)                  : ')
  cat("x" == Names(y ~ x, data = dat))

  # OK: Save boolean values to idx, then use f[idx]
  cat('\nidx <- "x" == Names(y ~ x, data = dat); f[idx]   : ')
  cat({idx <- "x" == Names(y ~ x, data = dat); f[idx]})

  # Error: Use the expression with S3 function Names directly inside of []
  cat('\nf["x" == Names(y ~ x, data = dat)]               : ')
  cat(f["x" == Names(y ~ x, data = dat)])

  invisible()
}



This is what happens when I run the envtest() function. All the
indexing operations work, except the last one, where, inside the
square brackets, the == operator is used, and it calls the S3 method
from an imported package.

> library(envtest)
> envtest()
f                                                : 1 2

Tests with %in% operator ----------------------------
"x" %in% Names(y ~ x, data = dat)                : TRUE
idx <- "x" %in% Names(y ~ x, data = dat); f[idx] : 1 2
f["x" %in% Names(y ~ x, data = dat)]             : 1 2

Tests with == operator ------------------------------
"x" == Names(y ~ x, data = dat)                  : FALSE TRUE
idx <- "x" == Names(y ~ x, data = dat); f[idx]   : 2
f["x" == Names(y ~ x, data = dat)]               : Error in Names(y ~
x, data = dat) : could not find function "Names"


When I set options(error=recover), it's possible to investigate the
environment where it's trying to evaluate the expression Names(....),
when it runs into the error:

Enter a frame number, or 0 to exit

1: envtest()
2: envtest.r#40: cat(f["x" == Names(y ~ x, data = dat)])
3: f["x" == Names(y ~ x, data = dat)]
4: `[.factor`(f, "x" == Names(y ~ x, data = dat))
5: NextMethod("[")
6: Names(y ~ x, data = dat)

Selection: 5

Browse[1]> environment()
<environment: 0x104421a78>
Browse[1]> parent.env(environment())
<environment: namespace:base>
Browse[1]> parent.env(parent.env(environment()))
<environment: R_GlobalEnv>


When == is used, it tries to evaluate the expression Names(....) in
the environment namespace:base, and it fails because it can't find the
function.
However, when %in% is used, it tries to evaluate the expression
Names(....) in the environment namespace:nlme, which makes more sense
to me.


Is this expected behavior? And if so, could someone explain why it
should be expected? I'm confused as to why the evaluation environment
should change when a certain narrow set of conditions is met.


-Winston


From mdowle at mdowle.plus.com  Mon Sep  3 04:04:56 2012
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Mon, 3 Sep 2012 03:04:56 +0100
Subject: [Rd] Possible page inefficiency in do_matrix in array.c
Message-ID: <7b0e4d32a6be42cf33560f51195ee706.squirrel@webmail.plus.net>


In do_matrix in src/array.c there is a type switch containing :

case LGLSXP :
    for (i = 0; i < nr; i++)
    for (j = 0; j < nc; j++)
        LOGICAL(ans)[i + j * NR] = NA_LOGICAL;

That seems page inefficient, iiuc. Think it should be :

case LGLSXP :
    for (j = 0; j < nc; j++)
    for (i = 0; i < nr; i++)
        LOGICAL(ans)[i + j * NR] = NA_LOGICAL;

or more simply :

case LGLSXP :
    for (i = 0; i < nc*nr; i++)
        LOGICAL(ans)[i] = NA_LOGICAL;

( with some fine tuning required since NR is type R_xlen_t whilst i, nc
and nr are type int ).

Same goes for all the other types in that switch.

This came up on Stack Overflow here :
http://stackoverflow.com/questions/12220128/reason-for-faster-matrix-allocation-in-r

Matthew


From simon.urbanek at r-project.org  Mon Sep  3 04:32:55 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sun, 2 Sep 2012 22:32:55 -0400
Subject: [Rd] Possible page inefficiency in do_matrix in array.c
In-Reply-To: <7b0e4d32a6be42cf33560f51195ee706.squirrel@webmail.plus.net>
References: <7b0e4d32a6be42cf33560f51195ee706.squirrel@webmail.plus.net>
Message-ID: <B7325928-6863-420C-A04A-C4AC5CDD2339@r-project.org>

On Sep 2, 2012, at 10:04 PM, Matthew Dowle wrote:

> 
> In do_matrix in src/array.c there is a type switch containing :
> 
> case LGLSXP :
>    for (i = 0; i < nr; i++)
>    for (j = 0; j < nc; j++)
>        LOGICAL(ans)[i + j * NR] = NA_LOGICAL;
> 
> That seems page inefficient, iiuc. Think it should be :
> 
> case LGLSXP :
>    for (j = 0; j < nc; j++)
>    for (i = 0; i < nr; i++)
>        LOGICAL(ans)[i + j * NR] = NA_LOGICAL;
> 
> or more simply :
> 
> case LGLSXP :
>    for (i = 0; i < nc*nr; i++)
>        LOGICAL(ans)[i] = NA_LOGICAL;
> 
> ( with some fine tuning required since NR is type R_xlen_t whilst i, nc
> and nr are type int ).
> 
> Same goes for all the other types in that switch.
> 
> This came up on Stack Overflow here :
> http://stackoverflow.com/questions/12220128/reason-for-faster-matrix-allocation-in-r
> 

That is completely irrelevant - modern compilers will optimize the loops accordingly and there is no difference in speed. If you don't believe it, run benchmarks ;)

original
> microbenchmark(matrix(nrow=10000, ncol=9999), times=10)
Unit: milliseconds
                               expr      min       lq  median       uq      max
1 matrix(nrow = 10000, ncol = 9999) 940.5519 940.6644 941.136 954.7196 1409.901


swapped
> microbenchmark(matrix(nrow=10000, ncol=9999), times=10)
Unit: milliseconds
                               expr      min       lq   median      uq      max
1 matrix(nrow = 10000, ncol = 9999) 949.9638 950.6642 952.7497 961.001 1246.573

Cheers,
Simon


> Matthew
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From simon.urbanek at r-project.org  Mon Sep  3 05:47:29 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sun, 2 Sep 2012 23:47:29 -0400
Subject: [Rd] Possible page inefficiency in do_matrix in array.c
In-Reply-To: <B7325928-6863-420C-A04A-C4AC5CDD2339@r-project.org>
References: <7b0e4d32a6be42cf33560f51195ee706.squirrel@webmail.plus.net>
	<B7325928-6863-420C-A04A-C4AC5CDD2339@r-project.org>
Message-ID: <5644F8CD-4120-46F0-BD00-918925650843@r-project.org>

Actually, my apologies, I was assuming that your example was based on the SO question while it is not at all (the code is not involved in that test case). Reversing the order does indeed cause a delay. Switching to a single index doesn't seem to have any impact. R-devel has the faster version now (which now also works with large vectors).

Cheers,
Simon

On Sep 2, 2012, at 10:32 PM, Simon Urbanek wrote:

> On Sep 2, 2012, at 10:04 PM, Matthew Dowle wrote:
> 
>> 
>> In do_matrix in src/array.c there is a type switch containing :
>> 
>> case LGLSXP :
>>   for (i = 0; i < nr; i++)
>>   for (j = 0; j < nc; j++)
>>       LOGICAL(ans)[i + j * NR] = NA_LOGICAL;
>> 
>> That seems page inefficient, iiuc. Think it should be :
>> 
>> case LGLSXP :
>>   for (j = 0; j < nc; j++)
>>   for (i = 0; i < nr; i++)
>>       LOGICAL(ans)[i + j * NR] = NA_LOGICAL;
>> 
>> or more simply :
>> 
>> case LGLSXP :
>>   for (i = 0; i < nc*nr; i++)
>>       LOGICAL(ans)[i] = NA_LOGICAL;
>> 
>> ( with some fine tuning required since NR is type R_xlen_t whilst i, nc
>> and nr are type int ).
>> 
>> Same goes for all the other types in that switch.
>> 
>> This came up on Stack Overflow here :
>> http://stackoverflow.com/questions/12220128/reason-for-faster-matrix-allocation-in-r
>> 
> 
> That is completely irrelevant - modern compilers will optimize the loops accordingly and there is no difference in speed. If you don't believe it, run benchmarks ;)
> 
> original
>> microbenchmark(matrix(nrow=10000, ncol=9999), times=10)
> Unit: milliseconds
>                               expr      min       lq  median       uq      max
> 1 matrix(nrow = 10000, ncol = 9999) 940.5519 940.6644 941.136 954.7196 1409.901
> 
> 
> swapped
>> microbenchmark(matrix(nrow=10000, ncol=9999), times=10)
> Unit: milliseconds
>                               expr      min       lq   median      uq      max
> 1 matrix(nrow = 10000, ncol = 9999) 949.9638 950.6642 952.7497 961.001 1246.573
> 
> Cheers,
> Simon
> 
> 
>> Matthew
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From spencer.graves at prodsyse.com  Mon Sep  3 07:43:16 2012
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Sun, 02 Sep 2012 22:43:16 -0700
Subject: [Rd] if(--as-cran)?
Message-ID: <50444374.50709@prodsyse.com>

Hello, All:


       The fda package has tests that run too long for CRAN's current 
rules.  I'd like to wrap some examples in a construct like the following:


if(!CRAN()){
...
}


       I tried the following:


CRAN <- function(x='_R_CHECK_CRAN_INCOMING_'){
     x. <- Sys.getenv(x)
     xl <- as.logical(x.)
     notCRAN <- is.na(xl) || xl
#
     return(!notCRAN)
}


       The companion help page included the following example:


if(CRAN()){
   stop('CRAN')
} else {
   stop('NOT CRAN')
}


       This reported "NOT CRAN" even with "R CMD check --as-cran".


       Suggestions?
       Thanks,
       Spencer

 > sessionInfo()
R version 2.15.1 (2012-06-22)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods base

other attached packages:
[1] sos_1.3-5  brew_1.0-6

loaded via a namespace (and not attached):
[1] tools_2.15.1


From hb at biostat.ucsf.edu  Mon Sep  3 09:49:35 2012
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Mon, 3 Sep 2012 00:49:35 -0700
Subject: [Rd] if(--as-cran)?
In-Reply-To: <50444374.50709@prodsyse.com>
References: <50444374.50709@prodsyse.com>
Message-ID: <CAFDcVCTF9xCqpo-1rUiKaooHf43-V_zfkUOi2k+0jzogW+xNXQ@mail.gmail.com>

Hi, see thread "[Rd] Proposal: Mechanism for controlling the amount of
testing 'R CMD check' performs" on April 8, 2012:

  https://stat.ethz.ch/pipermail/r-devel/2012-April/063809.html

/Henrik


On Sun, Sep 2, 2012 at 10:43 PM, Spencer Graves
<spencer.graves at prodsyse.com> wrote:
> Hello, All:
>
>
>       The fda package has tests that run too long for CRAN's current rules.
> I'd like to wrap some examples in a construct like the following:
>
>
> if(!CRAN()){
> ...
> }
>
>
>       I tried the following:
>
>
> CRAN <- function(x='_R_CHECK_CRAN_INCOMING_'){
>     x. <- Sys.getenv(x)
>     xl <- as.logical(x.)
>     notCRAN <- is.na(xl) || xl
> #
>     return(!notCRAN)
> }
>
>
>       The companion help page included the following example:
>
>
> if(CRAN()){
>   stop('CRAN')
> } else {
>   stop('NOT CRAN')
> }
>
>
>       This reported "NOT CRAN" even with "R CMD check --as-cran".
>
>
>       Suggestions?
>       Thanks,
>       Spencer
>
>> sessionInfo()
> R version 2.15.1 (2012-06-22)
> Platform: i386-pc-mingw32/i386 (32-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods base
>
> other attached packages:
> [1] sos_1.3-5  brew_1.0-6
>
> loaded via a namespace (and not attached):
> [1] tools_2.15.1
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From suharto_anggono at yahoo.com  Mon Sep  3 11:06:56 2012
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Mon, 3 Sep 2012 02:06:56 -0700 (PDT)
Subject: [Rd] Typo (?) in 'aggregate.formula'
Message-ID: <1346663216.98684.YahooMailClassic@web125102.mail.ne1.yahoo.com>

In the code for 'aggregate.formula', there is
if (as.character(formula[[2L]] == "."))
I believe that it is meant to be
if (as.character(formula[[2L]]) == ".")

However,
if (as.character(formula[[2L]] == "."))
gives the expected result.
Tracing:
- formula[[2L]] == "."
is equivalent to
as.character(formula[[2L]]) == "."
From the help page for '==' (Comparison), "Language objects such as symbols and calls are deparsed to character strings before comparison."
- By applying 'as.character', the TRUE/FALSE result of
formula[[2L]] == "."
is converted to character, becomes "TRUE"/"FALSE".
- Then, for 'if', it is implicitly converted back to logical.


> sessionInfo()
R version 2.14.2 (2012-02-29)
Platform: i386-pc-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252 
[2] LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     


I see that, in R 2.15.1, the code for 'aggregate.formula' is still the same.


From pdalgd at gmail.com  Mon Sep  3 11:43:39 2012
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 3 Sep 2012 11:43:39 +0200
Subject: [Rd] Typo (?) in 'aggregate.formula'
In-Reply-To: <1346663216.98684.YahooMailClassic@web125102.mail.ne1.yahoo.com>
References: <1346663216.98684.YahooMailClassic@web125102.mail.ne1.yahoo.com>
Message-ID: <0FF0E2BB-CCCA-40D0-9A32-AB6F3BC10860@gmail.com>

This (and more) was fixed in r-devel back in May. Did you actually get bitten by this? (The code has been there for years, so it hasn't been slated for R-patched.)

-pd 

On Sep 3, 2012, at 11:06 , Suharto Anggono Suharto Anggono wrote:

> In the code for 'aggregate.formula', there is
> if (as.character(formula[[2L]] == "."))
> I believe that it is meant to be
> if (as.character(formula[[2L]]) == ".")
> 
> However,
> if (as.character(formula[[2L]] == "."))
> gives the expected result.
> Tracing:
> - formula[[2L]] == "."
> is equivalent to
> as.character(formula[[2L]]) == "."
> From the help page for '==' (Comparison), "Language objects such as symbols and calls are deparsed to character strings before comparison."
> - By applying 'as.character', the TRUE/FALSE result of
> formula[[2L]] == "."
> is converted to character, becomes "TRUE"/"FALSE".
> - Then, for 'if', it is implicitly converted back to logical.
> 
> 
>> sessionInfo()
> R version 2.14.2 (2012-02-29)
> Platform: i386-pc-mingw32/i386 (32-bit)
> 
> locale:
> [1] LC_COLLATE=English_United States.1252 
> [2] LC_CTYPE=English_United States.1252   
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C                          
> [5] LC_TIME=English_United States.1252    
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base     
> 
> 
> I see that, in R 2.15.1, the code for 'aggregate.formula' is still the same.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From suharto_anggono at yahoo.com  Mon Sep  3 12:05:56 2012
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Mon, 3 Sep 2012 03:05:56 -0700 (PDT)
Subject: [Rd] Typo (?) in 'aggregate.formula'
In-Reply-To: <0FF0E2BB-CCCA-40D0-9A32-AB6F3BC10860@gmail.com>
Message-ID: <1346666756.62489.YahooMailClassic@web125106.mail.ne1.yahoo.com>

No, I didn't actually get bitten by this. I used 'aggregate.formula' only recently. I saw this when trying to know how 'aggregate.formula' worked, especially in accepting dot (.) in left-hand side of formula.
Thanks for the fix.

--- On Mon, 3/9/12, peter dalgaard <pdalgd at gmail.com> wrote:

> From: peter dalgaard <pdalgd at gmail.com>
> Subject: Re: [Rd] Typo (?) in 'aggregate.formula'
> To: "Suharto Anggono Suharto Anggono" <suharto_anggono at yahoo.com>
> Cc: R-devel at r-project.org
> Date: Monday, 3 September, 2012, 4:43 PM
> This (and more) was fixed in r-devel
> back in May. Did you actually get bitten by this? (The code
> has been there for years, so it hasn't been slated for
> R-patched.)
> 
> -pd 
> 
> On Sep 3, 2012, at 11:06 , Suharto Anggono Suharto Anggono
> wrote:
> 
> > In the code for 'aggregate.formula', there is
> > if (as.character(formula[[2L]] == "."))
> > I believe that it is meant to be
> > if (as.character(formula[[2L]]) == ".")
> > 
> > However,
> > if (as.character(formula[[2L]] == "."))
> > gives the expected result.
> > Tracing:
> > - formula[[2L]] == "."
> > is equivalent to
> > as.character(formula[[2L]]) == "."
> > From the help page for '==' (Comparison), "Language
> objects such as symbols and calls are deparsed to character
> strings before comparison."
> > - By applying 'as.character', the TRUE/FALSE result of
> > formula[[2L]] == "."
> > is converted to character, becomes "TRUE"/"FALSE".
> > - Then, for 'if', it is implicitly converted back to
> logical.
> > 
> > 
> >> sessionInfo()
> > R version 2.14.2 (2012-02-29)
> > Platform: i386-pc-mingw32/i386 (32-bit)
> > 
> > locale:
> > [1] LC_COLLATE=English_United States.1252 
> > [2] LC_CTYPE=English_United
> States.1252???
> > [3] LC_MONETARY=English_United States.1252
> > [4] LC_NUMERIC=C? ? ? ? ?
> ? ? ? ? ? ? ? ? 
> > [5] LC_TIME=English_United States.1252? ? 
> > 
> > attached base packages:
> > [1] stats? ???graphics?
> grDevices utils? ???datasets?
> methods???base? ???
> > 
> > 
> > I see that, in R 2.15.1, the code for
> 'aggregate.formula' is still the same.
> > 
> > ______________________________________________
> > R-devel at r-project.org
> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> -- 
> Peter Dalgaard, Professor
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk?
> Priv: PDalgd at gmail.com
> 
>


From murdoch.duncan at gmail.com  Mon Sep  3 13:41:25 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 03 Sep 2012 07:41:25 -0400
Subject: [Rd] if(--as-cran)?
In-Reply-To: <50444374.50709@prodsyse.com>
References: <50444374.50709@prodsyse.com>
Message-ID: <50449765.4030208@gmail.com>

On 12-09-03 1:43 AM, Spencer Graves wrote:
> Hello, All:
>
>
>         The fda package has tests that run too long for CRAN's current
> rules.  I'd like to wrap some examples in a construct like the following:
>
>
> if(!CRAN()){
> ...
> }
>
>
>         I tried the following:
>
>
> CRAN <- function(x='_R_CHECK_CRAN_INCOMING_'){
>       x. <- Sys.getenv(x)
>       xl <- as.logical(x.)
>       notCRAN <- is.na(xl) || xl
> #
>       return(!notCRAN)
> }
>
>
>         The companion help page included the following example:
>
>
> if(CRAN()){
>     stop('CRAN')
> } else {
>     stop('NOT CRAN')
> }
>
>
>         This reported "NOT CRAN" even with "R CMD check --as-cran".

There's no user-visible setting for --as-cran, because it just sets a 
number of other options.  You could query one of those.  The settings 
that are visible are

_R_CHECK_TIMINGS_  (which seems most relevant to you)
_R_CHECK_INSTALL_DEPENDS_
_R_CHECK_NO_RECOMMENDED_
_R_SHLIB_BUILD_OBJECTS_SYMBOL_TABLES_

So I'd check the value in _R_CHECK_TIMINGS_, or maybe just its existence.

Duncan Murdoch


From edd at debian.org  Mon Sep  3 16:34:06 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 3 Sep 2012 09:34:06 -0500
Subject: [Rd] if(--as-cran)?
In-Reply-To: <CAFDcVCTF9xCqpo-1rUiKaooHf43-V_zfkUOi2k+0jzogW+xNXQ@mail.gmail.com>
References: <50444374.50709@prodsyse.com>
	<CAFDcVCTF9xCqpo-1rUiKaooHf43-V_zfkUOi2k+0jzogW+xNXQ@mail.gmail.com>
Message-ID: <20548.49118.496081.738932@max.nulle.part>


On 3 September 2012 at 00:49, Henrik Bengtsson wrote:
| Hi, see thread "[Rd] Proposal: Mechanism for controlling the amount of
| testing 'R CMD check' performs" on April 8, 2012:
| 
|   https://stat.ethz.ch/pipermail/r-devel/2012-April/063809.html

Good proposal, somehow I missed that at the time.  Something like this ought
be to implemented in R proper.

In Rcpp, I am now using a similar environment-variable-based approach, and it
doesn't scale particularly well if every (large) package does its own thing.

Dirk
 
| /Henrik

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From maechler at stat.math.ethz.ch  Mon Sep  3 17:18:43 2012
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 3 Sep 2012 17:18:43 +0200
Subject: [Rd] if(--as-cran)?
In-Reply-To: <20548.49118.496081.738932@max.nulle.part>
References: <50444374.50709@prodsyse.com>
	<CAFDcVCTF9xCqpo-1rUiKaooHf43-V_zfkUOi2k+0jzogW+xNXQ@mail.gmail.com>
	<20548.49118.496081.738932@max.nulle.part>
Message-ID: <20548.51795.593805.264617@stat.math.ethz.ch>

>>>>> Dirk Eddelbuettel <edd at debian.org>
>>>>>     on Mon, 3 Sep 2012 09:34:06 -0500 writes:

    > On 3 September 2012 at 00:49, Henrik Bengtsson wrote:
    > | Hi, see thread "[Rd] Proposal: Mechanism for controlling the amount of
    > | testing 'R CMD check' performs" on April 8, 2012:
    > | 
    > |   https://stat.ethz.ch/pipermail/r-devel/2012-April/063809.html

    > Good proposal, somehow I missed that at the time.
    > Something like this ought be to implemented in R proper.

I agree.... but the CRAN maintainers have to agree too.


    > In Rcpp, I am now using a similar
    > environment-variable-based approach, and it doesn't scale
    > particularly well if every (large) package does its own thing.

yes, my packages do their own thing too, now, e.g., Matrix
(not yet released):

doExtras <- interactive() || nzchar(Sys.getenv("R_MATRIX_CHECK_EXTRA")) ||
    identical("true", unname(Sys.getenv("R_PKG_CHECKING_doExtras")))

and then I use  if(doExtras) { .... }
but I agree with Henrik that it would make sense to have more
than just two levels for the amount of testing, not just for CRAN.

An additional, slightly more interesting feature request that
you may also want in these cases, is the following:
Assume, that we have a function testingLevel()
and the following code should only be run, if the testing level
is 2 or higher

if(testingLevel() > 2) {
 .......1
 .......2
 ........
 ........
 .......n
}

Now what we all really wanted was that the ........ code
ran just as in toplevel.
While I think that's almost impossible,
as the .....1 to .....n must first be parsed all, and then
evaluated (which is already different from top level),
I would at least want that  the auto-printing worked like in
toplevel, so I don't have to write a  print(.) around every
......i that would autoprint if in toplevel, and of course does
*not* autoprint inside if(.) { .. }.

Martin Maechler, ETH Zurich

    > Dirk
 
    > | /Henrik

    > -- 
    > Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From edd at debian.org  Mon Sep  3 17:58:32 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 3 Sep 2012 10:58:32 -0500
Subject: [Rd] [Patch] Minor glitch in 'Writing R Extensions'
Message-ID: <20548.54184.169036.440589@max.nulle.part>


The (marked up in info mode) manual Writing R Extensions says in 6.1.3

 -- Function: double fprec (double X, double DIGITS)
     Returns the value of X rounded to DIGITS decimal digits (after the
     decimal point).

     This is the function used by R's `round()'.
                                      ^^^^^^^^^^

 -- Function: double fround (double X, double DIGITS)
     Returns the value of X rounded to DIGITS _significant_ decimal
     digits.

     This is the function used by R's `signif()'.
                                      ^^^^^^^^^^^

I think that is crossed vis-a-vis the the corresponding R functions, ie

   'double fprec is used by 'signif (not round)

   'double fround' is used by 'round' (not signif)

as I just found out by trying to unit-test wrappers just added to Rcpp.

Sources seem to agree -- src/main/arithmetic.c has

    case 10001: return Math2(args, fround);/* round(), src/nmath/fround.c */
    case 10004: return Math2(args, fprec); /* signif(), src/nmath/fprec.c */

So with that I suggest to alter the R-exts.texi as the patch below does.

Hope this helps, Dirk


edd at max:/tmp$ diff -u R-exts.texi.orig R-exts.texi
--- R-exts.texi.orig    2012-09-03 10:56:21.219528679 -0500
+++ R-exts.texi 2012-09-03 10:56:42.359529056 -0500
@@ -10659,14 +10659,14 @@
 Returns the value of @var{x} rounded to @var{digits} decimal digits
 (after the decimal point).
 
-This is the function used by @R{}'s @code{round()}.
+This is the function used by @R{}'s @code{signif()}.
 @end deftypefun
 
 @deftypefun double fround (double @var{x}, double @var{digits})
 Returns the value of @var{x} rounded to @var{digits} @emph{significant}
 decimal digits.
 
-This is the function used by @R{}'s @code{signif()}.
+This is the function used by @R{}'s @code{round()}.
 @end deftypefun
 
 @deftypefun double ftrunc (double @var{x})
edd at max:/tmp$ 



-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From murdoch.duncan at gmail.com  Mon Sep  3 19:41:10 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 03 Sep 2012 13:41:10 -0400
Subject: [Rd] if(--as-cran)?
In-Reply-To: <20548.51795.593805.264617@stat.math.ethz.ch>
References: <50444374.50709@prodsyse.com>
	<CAFDcVCTF9xCqpo-1rUiKaooHf43-V_zfkUOi2k+0jzogW+xNXQ@mail.gmail.com>
	<20548.49118.496081.738932@max.nulle.part>
	<20548.51795.593805.264617@stat.math.ethz.ch>
Message-ID: <5044EBB6.4040509@gmail.com>

On 12-09-03 11:18 AM, Martin Maechler wrote:
>>>>>> Dirk Eddelbuettel <edd at debian.org>
>>>>>>      on Mon, 3 Sep 2012 09:34:06 -0500 writes:
>
>      > On 3 September 2012 at 00:49, Henrik Bengtsson wrote:
>      > | Hi, see thread "[Rd] Proposal: Mechanism for controlling the amount of
>      > | testing 'R CMD check' performs" on April 8, 2012:
>      > |
>      > |   https://stat.ethz.ch/pipermail/r-devel/2012-April/063809.html
>
>      > Good proposal, somehow I missed that at the time.
>      > Something like this ought be to implemented in R proper.
>
> I agree.... but the CRAN maintainers have to agree too.
>
>
>      > In Rcpp, I am now using a similar
>      > environment-variable-based approach, and it doesn't scale
>      > particularly well if every (large) package does its own thing.
>
> yes, my packages do their own thing too, now, e.g., Matrix
> (not yet released):
>
> doExtras <- interactive() || nzchar(Sys.getenv("R_MATRIX_CHECK_EXTRA")) ||
>      identical("true", unname(Sys.getenv("R_PKG_CHECKING_doExtras")))
>
> and then I use  if(doExtras) { .... }
> but I agree with Henrik that it would make sense to have more
> than just two levels for the amount of testing, not just for CRAN.
>
> An additional, slightly more interesting feature request that
> you may also want in these cases, is the following:
> Assume, that we have a function testingLevel()
> and the following code should only be run, if the testing level
> is 2 or higher
>
> if(testingLevel() > 2) {
>   .......1
>   .......2
>   ........
>   ........
>   .......n
> }
>
> Now what we all really wanted was that the ........ code
> ran just as in toplevel.
> While I think that's almost impossible,
> as the .....1 to .....n must first be parsed all, and then
> evaluated (which is already different from top level),
> I would at least want that  the auto-printing worked like in
> toplevel, so I don't have to write a  print(.) around every
> ......i that would autoprint if in toplevel, and of course does
> *not* autoprint inside if(.) { .. }.
>

I prefer the current scheme where individual tests can be turned on and 
off.  The space of tests is a 2^N factorial space, not a chain of n 
possible levels.

The only problem I see with the current scheme is that code being tested 
can't find out which tests are being run.  In some cases, that's fine: 
there's no point in example code knowing about tests for consistency 
between documentation and implementation.  In other cases it might even 
be a good thing:  do you want packages to be able to hide dependencies 
on non-CRAN packages, for example?

Duncan Murdoch


From spencer.graves at prodsyse.com  Tue Sep  4 01:25:58 2012
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Mon, 03 Sep 2012 16:25:58 -0700
Subject: [Rd] if(--as-cran)?
In-Reply-To: <50449765.4030208@gmail.com>
References: <50444374.50709@prodsyse.com> <50449765.4030208@gmail.com>
Message-ID: <50453C86.1020708@prodsyse.com>

Hi, Duncan et al.:


       I modified my CRAN() function (see below) to look for 
"_R_CHECK_TIMINGS_" and "R_CHECK_TIMINGS", but got "NOT CRAN" with "R 
CMD check --as-cran" from both.


       Suggestions?
       Thanks,
       Spencer
p.s.  This is fda available from R-Forge via "svn checkout 
svn://svn.r-forge.r-project.org/svnroot/fda/".  It currently is 
programmed to stop no matter what.  I want it to give an error "CRAN" 
with "R CMD check --as-cran" and "NOT CRAN" without "--as-cran".  
Currently, I get "NOT CRAN" for both.


On 9/3/2012 4:41 AM, Duncan Murdoch wrote:
> On 12-09-03 1:43 AM, Spencer Graves wrote:
>> Hello, All:
>>
>>
>>         The fda package has tests that run too long for CRAN's current
>> rules.  I'd like to wrap some examples in a construct like the 
>> following:
>>
>>
>> if(!CRAN()){
>> ...
>> }
>>
>>
>>         I tried the following:
>>
>>
>> CRAN <- function(x='_R_CHECK_CRAN_INCOMING_'){
>>       x. <- Sys.getenv(x)
>>       xl <- as.logical(x.)
>>       notCRAN <- is.na(xl) || xl
>> #
>>       return(!notCRAN)
>> }
>>
>>
>>         The companion help page included the following example:
>>
>>
>> if(CRAN()){
>>     stop('CRAN')
>> } else {
>>     stop('NOT CRAN')
>> }
>>
>>
>>         This reported "NOT CRAN" even with "R CMD check --as-cran".
>
> There's no user-visible setting for --as-cran, because it just sets a 
> number of other options.  You could query one of those. The settings 
> that are visible are
>
> _R_CHECK_TIMINGS_  (which seems most relevant to you)
> _R_CHECK_INSTALL_DEPENDS_
> _R_CHECK_NO_RECOMMENDED_
> _R_SHLIB_BUILD_OBJECTS_SYMBOL_TABLES_
>
> So I'd check the value in _R_CHECK_TIMINGS_, or maybe just its existence.
>
> Duncan Murdoch
>


From murdoch.duncan at gmail.com  Tue Sep  4 01:52:59 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 03 Sep 2012 19:52:59 -0400
Subject: [Rd] if(--as-cran)?
In-Reply-To: <50453C86.1020708@prodsyse.com>
References: <50444374.50709@prodsyse.com> <50449765.4030208@gmail.com>
	<50453C86.1020708@prodsyse.com>
Message-ID: <504542DB.1020202@gmail.com>

On 12-09-03 7:25 PM, Spencer Graves wrote:
> Hi, Duncan et al.:
>
>
>         I modified my CRAN() function (see below) to look for
> "_R_CHECK_TIMINGS_" and "R_CHECK_TIMINGS", but got "NOT CRAN" with "R
> CMD check --as-cran" from both.
>
>
>         Suggestions?
>         Thanks,
>         Spencer
> p.s.  This is fda available from R-Forge via "svn checkout
> svn://svn.r-forge.r-project.org/svnroot/fda/".  It currently is
> programmed to stop no matter what.  I want it to give an error "CRAN"
> with "R CMD check --as-cran" and "NOT CRAN" without "--as-cran".
> Currently, I get "NOT CRAN" for both.

The problem is with your test.  If I put print(names(Sys.getenv())) into 
an example, I see _R_CHECK_TIMINGS_ if and only if I do the check with 
--as-cran.  The value is supposed to be a number, not a logical.

Duncan Murdoch


>
>
> On 9/3/2012 4:41 AM, Duncan Murdoch wrote:
>> On 12-09-03 1:43 AM, Spencer Graves wrote:
>>> Hello, All:
>>>
>>>
>>>          The fda package has tests that run too long for CRAN's current
>>> rules.  I'd like to wrap some examples in a construct like the
>>> following:
>>>
>>>
>>> if(!CRAN()){
>>> ...
>>> }
>>>
>>>
>>>          I tried the following:
>>>
>>>
>>> CRAN <- function(x='_R_CHECK_CRAN_INCOMING_'){
>>>        x. <- Sys.getenv(x)
>>>        xl <- as.logical(x.)
>>>        notCRAN <- is.na(xl) || xl
>>> #
>>>        return(!notCRAN)
>>> }
>>>
>>>
>>>          The companion help page included the following example:
>>>
>>>
>>> if(CRAN()){
>>>      stop('CRAN')
>>> } else {
>>>      stop('NOT CRAN')
>>> }
>>>
>>>
>>>          This reported "NOT CRAN" even with "R CMD check --as-cran".
>>
>> There's no user-visible setting for --as-cran, because it just sets a
>> number of other options.  You could query one of those. The settings
>> that are visible are
>>
>> _R_CHECK_TIMINGS_  (which seems most relevant to you)
>> _R_CHECK_INSTALL_DEPENDS_
>> _R_CHECK_NO_RECOMMENDED_
>> _R_SHLIB_BUILD_OBJECTS_SYMBOL_TABLES_
>>
>> So I'd check the value in _R_CHECK_TIMINGS_, or maybe just its existence.
>>
>> Duncan Murdoch
>>
>


From spencer.graves at prodsyse.com  Tue Sep  4 03:39:47 2012
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Mon, 03 Sep 2012 18:39:47 -0700
Subject: [Rd] if(--as-cran)?
In-Reply-To: <504542DB.1020202@gmail.com>
References: <50444374.50709@prodsyse.com> <50449765.4030208@gmail.com>
	<50453C86.1020708@prodsyse.com> <504542DB.1020202@gmail.com>
Message-ID: <50455BE3.90704@prodsyse.com>

Hi, Duncan:


       Duh... Thanks.  I should have been able to figure that out for 
myself.  Your help produced a solution much quicker.


       Thank again.
       Spencer


On 9/3/2012 4:52 PM, Duncan Murdoch wrote:
> On 12-09-03 7:25 PM, Spencer Graves wrote:
>> Hi, Duncan et al.:
>>
>>
>>         I modified my CRAN() function (see below) to look for
>> "_R_CHECK_TIMINGS_" and "R_CHECK_TIMINGS", but got "NOT CRAN" with "R
>> CMD check --as-cran" from both.
>>
>>
>>         Suggestions?
>>         Thanks,
>>         Spencer
>> p.s.  This is fda available from R-Forge via "svn checkout
>> svn://svn.r-forge.r-project.org/svnroot/fda/".  It currently is
>> programmed to stop no matter what.  I want it to give an error "CRAN"
>> with "R CMD check --as-cran" and "NOT CRAN" without "--as-cran".
>> Currently, I get "NOT CRAN" for both.
>
> The problem is with your test.  If I put print(names(Sys.getenv())) 
> into an example, I see _R_CHECK_TIMINGS_ if and only if I do the check 
> with --as-cran. The value is supposed to be a number, not a logical.
>
> Duncan Murdoch
>
>
>>
>>
>> On 9/3/2012 4:41 AM, Duncan Murdoch wrote:
>>> On 12-09-03 1:43 AM, Spencer Graves wrote:
>>>> Hello, All:
>>>>
>>>>
>>>>          The fda package has tests that run too long for CRAN's 
>>>> current
>>>> rules.  I'd like to wrap some examples in a construct like the
>>>> following:
>>>>
>>>>
>>>> if(!CRAN()){
>>>> ...
>>>> }
>>>>
>>>>
>>>>          I tried the following:
>>>>
>>>>
>>>> CRAN <- function(x='_R_CHECK_CRAN_INCOMING_'){
>>>>        x. <- Sys.getenv(x)
>>>>        xl <- as.logical(x.)
>>>>        notCRAN <- is.na(xl) || xl
>>>> #
>>>>        return(!notCRAN)
>>>> }
>>>>
>>>>
>>>>          The companion help page included the following example:
>>>>
>>>>
>>>> if(CRAN()){
>>>>      stop('CRAN')
>>>> } else {
>>>>      stop('NOT CRAN')
>>>> }
>>>>
>>>>
>>>>          This reported "NOT CRAN" even with "R CMD check --as-cran".
>>>
>>> There's no user-visible setting for --as-cran, because it just sets a
>>> number of other options.  You could query one of those. The settings
>>> that are visible are
>>>
>>> _R_CHECK_TIMINGS_  (which seems most relevant to you)
>>> _R_CHECK_INSTALL_DEPENDS_
>>> _R_CHECK_NO_RECOMMENDED_
>>> _R_SHLIB_BUILD_OBJECTS_SYMBOL_TABLES_
>>>
>>> So I'd check the value in _R_CHECK_TIMINGS_, or maybe just its 
>>> existence.
>>>
>>> Duncan Murdoch
>>>
>>
>


-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567
web:  www.structuremonitoring.com


From hadley at rice.edu  Tue Sep  4 04:50:57 2012
From: hadley at rice.edu (Hadley Wickham)
Date: Mon, 3 Sep 2012 21:50:57 -0500
Subject: [Rd] Environment when NextMethod is used
In-Reply-To: <CAFOpNVFVEeQcJM5GZ154dnjjpH7MtXk8uX7joM6FkP5mGjQW-A@mail.gmail.com>
References: <CAFOpNVFVEeQcJM5GZ154dnjjpH7MtXk8uX7joM6FkP5mGjQW-A@mail.gmail.com>
Message-ID: <CABdHhvEfAWuo72kiNSfDdb4fSiayVq5knwnBtR7H++r9Bj72tg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120903/c4e93bd9/attachment.pl>

From hadley at rice.edu  Tue Sep  4 04:59:59 2012
From: hadley at rice.edu (Hadley Wickham)
Date: Mon, 3 Sep 2012 21:59:59 -0500
Subject: [Rd] if(--as-cran)?
In-Reply-To: <20548.49118.496081.738932@max.nulle.part>
References: <50444374.50709@prodsyse.com>
	<CAFDcVCTF9xCqpo-1rUiKaooHf43-V_zfkUOi2k+0jzogW+xNXQ@mail.gmail.com>
	<20548.49118.496081.738932@max.nulle.part>
Message-ID: <CABdHhvHLWwBxz03z2CAxnfuBC=RNYvnXMam3nsCXycr5pe7-Kg@mail.gmail.com>

> | Hi, see thread "[Rd] Proposal: Mechanism for controlling the amount of
> | testing 'R CMD check' performs" on April 8, 2012:
> |
> |   https://stat.ethz.ch/pipermail/r-devel/2012-April/063809.html
>
> Good proposal, somehow I missed that at the time.  Something like this ought
> be to implemented in R proper.
>
> In Rcpp, I am now using a similar environment-variable-based approach, and it
> doesn't scale particularly well if every (large) package does its own thing.

Is there any approach that's going to be particularly better than
scaling out CRAN's build servers?  As a particularly profuse package
author, I'd be happy to pay for the computing time that it takes to
run a full set of tests on my package (and this seems feasible in the
era of on-demand cloud computing).

Hadley

-- 
Assistant Professor
Department of Statistics / Rice University
http://had.co.nz/


From spencer.graves at prodsyse.com  Tue Sep  4 06:58:59 2012
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Mon, 03 Sep 2012 21:58:59 -0700
Subject: [Rd] if(--as-cran)?
In-Reply-To: <CABdHhvHLWwBxz03z2CAxnfuBC=RNYvnXMam3nsCXycr5pe7-Kg@mail.gmail.com>
References: <50444374.50709@prodsyse.com>
	<CAFDcVCTF9xCqpo-1rUiKaooHf43-V_zfkUOi2k+0jzogW+xNXQ@mail.gmail.com>
	<20548.49118.496081.738932@max.nulle.part>
	<CABdHhvHLWwBxz03z2CAxnfuBC=RNYvnXMam3nsCXycr5pe7-Kg@mail.gmail.com>
Message-ID: <50458A93.9040201@prodsyse.com>

On 9/3/2012 7:59 PM, Hadley Wickham wrote:
>> | Hi, see thread "[Rd] Proposal: Mechanism for controlling the amount of
>> | testing 'R CMD check' performs" on April 8, 2012:
>> |
>> |   https://stat.ethz.ch/pipermail/r-devel/2012-April/063809.html
>>
>> Good proposal, somehow I missed that at the time.  Something like this ought
>> be to implemented in R proper.
>>
>> In Rcpp, I am now using a similar environment-variable-based approach, and it
>> doesn't scale particularly well if every (large) package does its own thing.
> Is there any approach that's going to be particularly better than
> scaling out CRAN's build servers?  As a particularly profuse package
> author, I'd be happy to pay for the computing time that it takes to
> run a full set of tests on my package (and this seems feasible in the
> era of on-demand cloud computing).
>
> Hadley
>
       Jim Ramsay suggested we have CRAN generate a pro-forma invoice 
when a package is first submitted to CRAN and on each anniversary 
thereafter that would be like page charges for journals:  If you work 
for an organization that knows how to pay invoices, you submit the 
invoice to that system.  Ramsay said he has grant money and would be 
happy to pay a reasonable fee, but he needs an invoice.  If you aren't 
in such an organization, you are free to plead poverty and pay anything 
or nothing.  I think we should do the same for R-Forge.


       I think the fee should be set high enough that the money 
generated would be enough to pay for more hardware AND for someone to 
maintain the system.  The entirety of humanity will benefit if Ripley, 
Hornik, Ligges, Theussl, Zeileis and others spend more time developing 
better statistical algorithms and less struggling with computer hardware 
and operating systems just to keep CRAN and R-Forge functioning.  These 
folks and others have done a great job in bringing R to where it is 
today.  There are now over 4,000 packages on CRAN.  If 25% of those pay, 
say, 200 (Euros or dollars) per year, for example, that should be enough 
to hire a competent sys admin or two with an adequate hardware budget to 
keep it all running, I think.


       Thanks, Hadley.
       Spencer


-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567
web:  www.structuremonitoring.com


From Jan.Mueller at ipsos.com  Tue Sep  4 09:56:11 2012
From: Jan.Mueller at ipsos.com (Jan Mueller)
Date: Tue, 4 Sep 2012 08:56:11 +0100
Subject: [Rd] Reference classes use a lot more memory after
 serialization/unserialization
Message-ID: <7249BACCE76BA1458041342A9A6846D754D44C3B9B@EMEAEML1.eu.ipsos>

Hello All,

I posted this earlier on R-help but received no answers. This touches the implementation of reference classes so maybe R-devel is a better place.
The memory consumption of reference classes seems to increase dramatically (roughly 10x in the example below) with serialization/unserialization.
S4 - classes are apparently not affected. 
Any ideas how this could be solved or at least circumvented?

Best
Jan

# start new R session, empty workspace

gc();
MySmallClass = setRefClass("MySmallClass",
       fields = list(
 myField = "numeric"
       ),
       methods = list(
    initialize = function(f) {
      myField<<- f;
           })
 );

# Generate 10K instances
o = lapply(rnorm(10000), MySmallClass$new)

gc()
s=serialize(o, connection=NULL)
gc();
p=unserialize(s);
gc();


Output:
1st gc():
         used (Mb) gc trigger (Mb) max used (Mb)
Ncells 170895  4.6     350000  9.4   350000  9.4
Vcells 162042  1.3     905753  7.0   786155  6.0

2nd gc():
         used (Mb) gc trigger (Mb) max used (Mb)
Ncells 720320 19.3     984024 26.3   899071 24.1
Vcells 588993  4.5    1162592  8.9   786155  6.0

3rd gc():
          used (Mb) gc trigger (Mb) max used (Mb)
Ncells  720472 19.3    1166886 31.2   899071 24.1
Vcells 9941697 75.9   11298137 86.2  9941716 75.9

4th gc():
           used  (Mb) gc trigger  (Mb) max used  (Mb)
Ncells  6980212 186.4    7700734 205.7  6981388 186.5
Vcells 11744776  89.7   17456418 133.2 11754663  89.7

# Platform info:
# R version 2.15.1
# Platform: i386-pc-mingw32/i386 (32-bit)
# Binary package from CRAN
# Windows 7 32 Bit 
#  (I observed a similar behavior on Linux 64 Bit, same R version)


From maechler at stat.math.ethz.ch  Tue Sep  4 10:45:56 2012
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 4 Sep 2012 10:45:56 +0200
Subject: [Rd] if(--as-cran)?
In-Reply-To: <50455BE3.90704@prodsyse.com>
References: <50444374.50709@prodsyse.com> <50449765.4030208@gmail.com>
	<50453C86.1020708@prodsyse.com> <504542DB.1020202@gmail.com>
	<50455BE3.90704@prodsyse.com>
Message-ID: <20549.49092.211155.310666@stat.math.ethz.ch>

>>>>> Spencer Graves <spencer.graves at prodsyse.com>
>>>>>     on Mon, 3 Sep 2012 18:39:47 -0700 writes:

    > Hi, Duncan:
    > Duh... Thanks.  I should have been able to figure that out for 
    > myself.  Your help produced a solution much quicker.

    > Thank again.
    > Spencer


    > On 9/3/2012 4:52 PM, Duncan Murdoch wrote:
    >> On 12-09-03 7:25 PM, Spencer Graves wrote:
    >>> Hi, Duncan et al.:
    >>> 
    >>> 
    >>> I modified my CRAN() function (see below) to look for
    >>> "_R_CHECK_TIMINGS_" and "R_CHECK_TIMINGS", but got "NOT CRAN" with "R
    >>> CMD check --as-cran" from both.
    >>> 
    >>> 
    >>> Suggestions?
    >>> Thanks,
    >>> Spencer
    >>> p.s.  This is fda available from R-Forge via "svn checkout
    >>> svn://svn.r-forge.r-project.org/svnroot/fda/".  It currently is
    >>> programmed to stop no matter what.  I want it to give an error "CRAN"
    >>> with "R CMD check --as-cran" and "NOT CRAN" without "--as-cran".
    >>> Currently, I get "NOT CRAN" for both.
    >> 
    >> The problem is with your test.  If I put print(names(Sys.getenv())) 
    >> into an example, I see _R_CHECK_TIMINGS_ if and only if I do the check 
    >> with --as-cran. The value is supposed to be a number, not a logical.
    >> 
    >> Duncan Murdoch

But back to the original question.
Checking for these variables is not at all a general solution;
If I use  'R CMD check --timings' I want to time my tests and
actually I find this so reasonable that I've made it the default
for me.

I strongly believe we should follow the thread  Henrik has
started and Dirk and I had followed up.

The issue is not just about "CRAN" vs "off CRAN".
It is good to think about a more general scheme of
"light testing" vs "normal testing" vs "extensive testing",
e.g.,  for the situation where the package implements
(simulation/bootstrap/ ..) based inference, and the developer
(but not only) should be able to run the extensive tests.

Martin

    >>> On 9/3/2012 4:41 AM, Duncan Murdoch wrote:
    >>>> On 12-09-03 1:43 AM, Spencer Graves wrote:
    >>>>> Hello, All:
    >>>>> 
    >>>>> 
    >>>>> The fda package has tests that run too long for CRAN's 
    >>>>> current
    >>>>> rules.  I'd like to wrap some examples in a construct like the
    >>>>> following:
    >>>>> 
    >>>>> 
    >>>>> if(!CRAN()){
    >>>>> ...
    >>>>> }
    >>>>> 
    >>>>> 
    >>>>> I tried the following:
    >>>>> 
    >>>>> 
    >>>>> CRAN <- function(x='_R_CHECK_CRAN_INCOMING_'){
    >>>>> x. <- Sys.getenv(x)
    >>>>> xl <- as.logical(x.)
    >>>>> notCRAN <- is.na(xl) || xl
    >>>>> #
    >>>>> return(!notCRAN)
    >>>>> }
    >>>>> 
    >>>>> 
    >>>>> The companion help page included the following example:
    >>>>> 
    >>>>> 
    >>>>> if(CRAN()){
    >>>>> stop('CRAN')
    >>>>> } else {
    >>>>> stop('NOT CRAN')
    >>>>> }
    >>>>> 
    >>>>> 
    >>>>> This reported "NOT CRAN" even with "R CMD check --as-cran".
    >>>> 
    >>>> There's no user-visible setting for --as-cran, because it just sets a
    >>>> number of other options.  You could query one of those. The settings
    >>>> that are visible are
    >>>> 
    >>>> _R_CHECK_TIMINGS_  (which seems most relevant to you)
    >>>> _R_CHECK_INSTALL_DEPENDS_
    >>>> _R_CHECK_NO_RECOMMENDED_
    >>>> _R_SHLIB_BUILD_OBJECTS_SYMBOL_TABLES_
    >>>> 
    >>>> So I'd check the value in _R_CHECK_TIMINGS_, or maybe just its 
    >>>> existence.
    >>>> 
    >>>> Duncan Murdoch
    >>>> 
    >>> 
    >> 


    > -- 
    > Spencer Graves, PE, PhD
    > President and Chief Technology Officer
    > Structure Inspection and Monitoring, Inc.
    > 751 Emerson Ct.
    > San Jos?, CA 95126
    > ph:  408-655-4567
    > web:  www.structuremonitoring.com

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Tue Sep  4 13:16:34 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 04 Sep 2012 07:16:34 -0400
Subject: [Rd] if(--as-cran)?
In-Reply-To: <20549.49092.211155.310666@stat.math.ethz.ch>
References: <50444374.50709@prodsyse.com> <50449765.4030208@gmail.com>
	<50453C86.1020708@prodsyse.com> <504542DB.1020202@gmail.com>
	<50455BE3.90704@prodsyse.com>
	<20549.49092.211155.310666@stat.math.ethz.ch>
Message-ID: <5045E312.4080902@gmail.com>

On 12-09-04 4:45 AM, Martin Maechler wrote:
>>>>>> Spencer Graves <spencer.graves at prodsyse.com>
>>>>>>      on Mon, 3 Sep 2012 18:39:47 -0700 writes:
>
>      > Hi, Duncan:
>      > Duh... Thanks.  I should have been able to figure that out for
>      > myself.  Your help produced a solution much quicker.
>
>      > Thank again.
>      > Spencer
>
>
>      > On 9/3/2012 4:52 PM, Duncan Murdoch wrote:
>      >> On 12-09-03 7:25 PM, Spencer Graves wrote:
>      >>> Hi, Duncan et al.:
>      >>>
>      >>>
>      >>> I modified my CRAN() function (see below) to look for
>      >>> "_R_CHECK_TIMINGS_" and "R_CHECK_TIMINGS", but got "NOT CRAN" with "R
>      >>> CMD check --as-cran" from both.
>      >>>
>      >>>
>      >>> Suggestions?
>      >>> Thanks,
>      >>> Spencer
>      >>> p.s.  This is fda available from R-Forge via "svn checkout
>      >>> svn://svn.r-forge.r-project.org/svnroot/fda/".  It currently is
>      >>> programmed to stop no matter what.  I want it to give an error "CRAN"
>      >>> with "R CMD check --as-cran" and "NOT CRAN" without "--as-cran".
>      >>> Currently, I get "NOT CRAN" for both.
>      >>
>      >> The problem is with your test.  If I put print(names(Sys.getenv()))
>      >> into an example, I see _R_CHECK_TIMINGS_ if and only if I do the check
>      >> with --as-cran. The value is supposed to be a number, not a logical.
>      >>
>      >> Duncan Murdoch
>
> But back to the original question.
> Checking for these variables is not at all a general solution;
> If I use  'R CMD check --timings' I want to time my tests and
> actually I find this so reasonable that I've made it the default
> for me.
>
> I strongly believe we should follow the thread  Henrik has
> started and Dirk and I had followed up.

As did I.

>
> The issue is not just about "CRAN" vs "off CRAN".
> It is good to think about a more general scheme of
> "light testing" vs "normal testing" vs "extensive testing",
> e.g.,  for the situation where the package implements
> (simulation/bootstrap/ ..) based inference, and the developer
> (but not only) should be able to run the extensive tests.

I don't agree that it is good to think of it that way, as I wrote 
before.  Tests don't have a natural ordering.  I do agree that example 
(or test) code should be able to determine if certain tests have been 
enabled.  I don't know if there are any such tests where it isn't 
currently possible.

Duncan Murdoch

>
> Martin
>
>      >>> On 9/3/2012 4:41 AM, Duncan Murdoch wrote:
>      >>>> On 12-09-03 1:43 AM, Spencer Graves wrote:
>      >>>>> Hello, All:
>      >>>>>
>      >>>>>
>      >>>>> The fda package has tests that run too long for CRAN's
>      >>>>> current
>      >>>>> rules.  I'd like to wrap some examples in a construct like the
>      >>>>> following:
>      >>>>>
>      >>>>>
>      >>>>> if(!CRAN()){
>      >>>>> ...
>      >>>>> }
>      >>>>>
>      >>>>>
>      >>>>> I tried the following:
>      >>>>>
>      >>>>>
>      >>>>> CRAN <- function(x='_R_CHECK_CRAN_INCOMING_'){
>      >>>>> x. <- Sys.getenv(x)
>      >>>>> xl <- as.logical(x.)
>      >>>>> notCRAN <- is.na(xl) || xl
>      >>>>> #
>      >>>>> return(!notCRAN)
>      >>>>> }
>      >>>>>
>      >>>>>
>      >>>>> The companion help page included the following example:
>      >>>>>
>      >>>>>
>      >>>>> if(CRAN()){
>      >>>>> stop('CRAN')
>      >>>>> } else {
>      >>>>> stop('NOT CRAN')
>      >>>>> }
>      >>>>>
>      >>>>>
>      >>>>> This reported "NOT CRAN" even with "R CMD check --as-cran".
>      >>>>
>      >>>> There's no user-visible setting for --as-cran, because it just sets a
>      >>>> number of other options.  You could query one of those. The settings
>      >>>> that are visible are
>      >>>>
>      >>>> _R_CHECK_TIMINGS_  (which seems most relevant to you)
>      >>>> _R_CHECK_INSTALL_DEPENDS_
>      >>>> _R_CHECK_NO_RECOMMENDED_
>      >>>> _R_SHLIB_BUILD_OBJECTS_SYMBOL_TABLES_
>      >>>>
>      >>>> So I'd check the value in _R_CHECK_TIMINGS_, or maybe just its
>      >>>> existence.
>      >>>>
>      >>>> Duncan Murdoch
>      >>>>
>      >>>
>      >>
>
>
>      > --
>      > Spencer Graves, PE, PhD
>      > President and Chief Technology Officer
>      > Structure Inspection and Monitoring, Inc.
>      > 751 Emerson Ct.
>      > San Jos?, CA 95126
>      > ph:  408-655-4567
>      > web:  www.structuremonitoring.com
>
>      > ______________________________________________
>      > R-devel at r-project.org mailing list
>      > https://stat.ethz.ch/mailman/listinfo/r-devel
>


From mdowle at mdowle.plus.com  Tue Sep  4 14:07:32 2012
From: mdowle at mdowle.plus.com (Matthew Dowle)
Date: Tue, 4 Sep 2012 13:07:32 +0100
Subject: [Rd] Possible page inefficiency in do_matrix in array.c
In-Reply-To: <5644F8CD-4120-46F0-BD00-918925650843@r-project.org>
References: <7b0e4d32a6be42cf33560f51195ee706.squirrel@webmail.plus.net>
	<B7325928-6863-420C-A04A-C4AC5CDD2339@r-project.org>
	<5644F8CD-4120-46F0-BD00-918925650843@r-project.org>
Message-ID: <d4a1a290ecf9463e63b98bf37add625f.squirrel@webmail.plus.net>


> Actually, my apologies, I was assuming that your example was based on the
> SO question while it is not at all (the code is not involved in that test
> case). Reversing the order does indeed cause a delay. Switching to a
> single index doesn't seem to have any impact. R-devel has the faster
> version now (which now also works with large vectors).
>
> Cheers,
> Simon

I was intrigued why the compiler doesn't swap the loops when you thought
it should, though. You're not usually wrong! From GCC's documentation (end
of last paragraph is the most significant) :

====

-floop-interchange
Perform loop interchange transformations on loops. Interchanging two
nested loops switches the inner and outer loops. For example, given a loop
like:
          DO J = 1, M
            DO I = 1, N
              A(J, I) = A(J, I) * C
            ENDDO
          ENDDO

loop interchange transforms the loop as if it were written:

          DO I = 1, N
            DO J = 1, M
              A(J, I) = A(J, I) * C
            ENDDO
          ENDDO

which can be beneficial when N is larger than the caches, because in
Fortran, the elements of an array are stored in memory contiguously by
column, and the original loop iterates over rows, potentially creating at
each access a cache miss. This optimization applies to all the languages
supported by GCC and is not limited to Fortran. To use this code
transformation, GCC has to be configured with --with-ppl and --with-cloog
to enable the Graphite loop transformation infrastructure.

====

Could R build scripts be configured to set these gcc flags to turn on
"Graphite", then? I guess one downside could be the time to compile.

Matthew


>
> On Sep 2, 2012, at 10:32 PM, Simon Urbanek wrote:
>
>> On Sep 2, 2012, at 10:04 PM, Matthew Dowle wrote:
>>
>>>
>>> In do_matrix in src/array.c there is a type switch containing :
>>>
>>> case LGLSXP :
>>>   for (i = 0; i < nr; i++)
>>>   for (j = 0; j < nc; j++)
>>>       LOGICAL(ans)[i + j * NR] = NA_LOGICAL;
>>>
>>> That seems page inefficient, iiuc. Think it should be :
>>>
>>> case LGLSXP :
>>>   for (j = 0; j < nc; j++)
>>>   for (i = 0; i < nr; i++)
>>>       LOGICAL(ans)[i + j * NR] = NA_LOGICAL;
>>>
>>> or more simply :
>>>
>>> case LGLSXP :
>>>   for (i = 0; i < nc*nr; i++)
>>>       LOGICAL(ans)[i] = NA_LOGICAL;
>>>
>>> ( with some fine tuning required since NR is type R_xlen_t whilst i, nc
>>> and nr are type int ).
>>>
>>> Same goes for all the other types in that switch.
>>>
>>> This came up on Stack Overflow here :
>>> http://stackoverflow.com/questions/12220128/reason-for-faster-matrix-allocation-in-r
>>>
>>
>> That is completely irrelevant - modern compilers will optimize the loops
>> accordingly and there is no difference in speed. If you don't believe
>> it, run benchmarks ;)
>>
>> original
>>> microbenchmark(matrix(nrow=10000, ncol=9999), times=10)
>> Unit: milliseconds
>>                               expr      min       lq  median       uq
>>   max
>> 1 matrix(nrow = 10000, ncol = 9999) 940.5519 940.6644 941.136 954.7196
>> 1409.901
>>
>>
>> swapped
>>> microbenchmark(matrix(nrow=10000, ncol=9999), times=10)
>> Unit: milliseconds
>>                               expr      min       lq   median      uq
>>   max
>> 1 matrix(nrow = 10000, ncol = 9999) 949.9638 950.6642 952.7497 961.001
>> 1246.573
>>
>> Cheers,
>> Simon
>>
>>
>>> Matthew
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
>


From therneau at mayo.edu  Tue Sep  4 14:20:49 2012
From: therneau at mayo.edu (Terry Therneau)
Date: Tue, 04 Sep 2012 07:20:49 -0500
Subject: [Rd] if(--as-cran)?
In-Reply-To: <mailman.17.1346752805.30578.r-devel@r-project.org>
References: <mailman.17.1346752805.30578.r-devel@r-project.org>
Message-ID: <5045F221.7050600@mayo.edu>



On 09/04/2012 05:00 AM, r-devel-request at r-project.org wrote:
> The issue is not just about "CRAN" vs "off CRAN".
> It is good to think about a more general scheme of
> "light testing" vs "normal testing" vs "extensive testing",
> e.g.,  for the situation where the package implements
> (simulation/bootstrap/ ..) based inference, and the developer
> (but not only) should be able to run the extensive tests.
>
> Martin

I agree with Martin.  A mechanism to specify testing level would be the best.
Then CRAN can choose to set that variable to "3" say, with level 1 for extensive and 2 for 
usual.
   I'm quite willing to put up with the nuisance of print() enclosures.  I prefer it to 
having yet another way to subvert the evaluation model.

   I'm a believer in testing everything possible in my packages, and wear it it as a badge 
of honor that the survival package has 4 lines of R code in the tests directory for every 
3 in the R directory.  But CRAN only needs to run a small subset of this.

Terry T


From murdoch.duncan at gmail.com  Tue Sep  4 14:38:56 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 04 Sep 2012 08:38:56 -0400
Subject: [Rd] if(--as-cran)?
In-Reply-To: <5045F221.7050600@mayo.edu>
References: <mailman.17.1346752805.30578.r-devel@r-project.org>
	<5045F221.7050600@mayo.edu>
Message-ID: <5045F660.6030706@gmail.com>

On 04/09/2012 8:20 AM, Terry Therneau wrote:
>
> On 09/04/2012 05:00 AM, r-devel-request at r-project.org wrote:
> > The issue is not just about "CRAN" vs "off CRAN".
> > It is good to think about a more general scheme of
> > "light testing" vs "normal testing" vs "extensive testing",
> > e.g.,  for the situation where the package implements
> > (simulation/bootstrap/ ..) based inference, and the developer
> > (but not only) should be able to run the extensive tests.
> >
> > Martin
>
> I agree with Martin.  A mechanism to specify testing level would be the best.
> Then CRAN can choose to set that variable to "3" say, with level 1 for extensive and 2 for
> usual.
>     I'm quite willing to put up with the nuisance of print() enclosures.  I prefer it to
> having yet another way to subvert the evaluation model.
>
>     I'm a believer in testing everything possible in my packages, and wear it it as a badge
> of honor that the survival package has 4 lines of R code in the tests directory for every
> 3 in the R directory.  But CRAN only needs to run a small subset of this.

We have a mechanism to specify testing level:  the --as-cran flag. We 
could presumably make it more elaborate by adding other flags, or option 
levels, or whatever.

What I think we shouldn't do is try to create an R-level test that says

  if (testingLevel() > 3) {
    doSomething
}

because tests can be turned on and off, individually.  If testingLevel 3 
specified tests (A, B, C), then is our testingLevel higher if we are 
running tests (A, B, D, E, F, G)?  Why not just test for the presence of 
whichever test is most relevant to that particular code block, e.g.

  if ("D" %in% tests()) {
   doSomething
}

Duncan Murdoch


From lorenz at usgs.gov  Tue Sep  4 15:47:10 2012
From: lorenz at usgs.gov (David L Lorenz)
Date: Tue, 4 Sep 2012 08:47:10 -0500
Subject: [Rd] Vignette question
In-Reply-To: <5045F221.7050600@mayo.edu>
References: <mailman.17.1346752805.30578.r-devel@r-project.org>
	<5045F221.7050600@mayo.edu>
Message-ID: <OF16428985.E6D7F237-ON86257A6F.0045BFC3-86257A6F.004BBB53@usgs.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120904/285221b5/attachment.pl>

From murdoch.duncan at gmail.com  Tue Sep  4 16:33:25 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 04 Sep 2012 10:33:25 -0400
Subject: [Rd] Vignette question
In-Reply-To: <OF16428985.E6D7F237-ON86257A6F.0045BFC3-86257A6F.004BBB53@usgs.gov>
References: <mailman.17.1346752805.30578.r-devel@r-project.org>
	<5045F221.7050600@mayo.edu>
	<OF16428985.E6D7F237-ON86257A6F.0045BFC3-86257A6F.004BBB53@usgs.gov>
Message-ID: <50461135.6010307@gmail.com>

On 04/09/2012 9:47 AM, David L Lorenz wrote:
> All,
>    I seem to be missing some key point about the construction of vignettes.
> I have created a vignette script that works fine when run interactively
> using Sweave. The top part of the .Rnw file is below.
>
> \documentclass{article}
> \parskip 3pt
> \parindent 30pt
> %\VignetteIndexEntry{Box Plot Examples}
> %\VignetteDepends{USGSgraphs}
>
> \begin{document}
>
> \title{Box Plot Examples}
>
> \author{Dave Lorenz}
>
> \maketitle
>
> ... text omittted from this example ...
> <<echo=TRUE>>=
> # Generate a random sample for the box plot
> set.seed(27036)
> BP <- rchisq(32, 3)
> # setSweave is a specialized function that sets up the graphics page
> setSweave("boxplot01", 6 ,6)
> # Set layout for 4 graphs
> AA.lo <- setLayout(width=rep(1.25, 4), height=4, xtop=1.5)
>
> ... remainder omitted ...
>
>    The functions setSweave and setLayout are functions within the
> USGSgraphs library that I am building. As I said, the script runs just
> fine when I run interactively. I do have a version of the USGSgraphs
> library attached when I run the script. When I run R CMD check, or R CMD
> build on the source, I get the error:
>
> Error: processing vignette 'boxplots.Rnw' failed with diagnostics:
>   chunk 1
> Error in eval(expr, envir, enclos) : could not find function "setSweave"
> Execution halted
>
>    I would have expected that the contents of the library being built would
> have been available to the script (based on section 1.3.2 in R-exts.html).
> Barring that, I expected that "%\VignetteDepends{USGSgraphs}" would have
> made those functions available to the script. I have found that if I
> include this code before the first real example, it will run.
>
> <<echo=FALSE>>=
> library(USGSgraphs)
> @
>
>    But I have no reason to believe that it would run on any system that did
> not already have a version of USGSgraphs installed. Note that if I use the
> default graphics output, then I get the same error on setLayout.
>    I use the default process for building the vignettes--no makefile.
>    What do I need to do to get this vignette to run? I know I can set
> BuildVignettes to FALSE in the DESCRIPTION file or try to build with the
> --no-vignettes option, but that does not really address the more general
> issue.

Vignettes are run in pretty standard R sessions when the package is 
built, so you need the explicit library(USGSgraphs) call to make 
functions from your package available in that session.  What the manual 
is saying is just that that call will succeed:  R will install a copy of 
your package in order to build the vignette.  It goes into a "temporary 
library tree", because you might not want that particular version 
installed in your main tree.

Duncan Murdoch


From lorenz at usgs.gov  Tue Sep  4 16:54:02 2012
From: lorenz at usgs.gov (David L Lorenz)
Date: Tue, 4 Sep 2012 09:54:02 -0500
Subject: [Rd] Vignette question
In-Reply-To: <50461135.6010307@gmail.com>
References: <mailman.17.1346752805.30578.r-devel@r-project.org>
	<5045F221.7050600@mayo.edu>
	<OF16428985.E6D7F237-ON86257A6F.0045BFC3-86257A6F.004BBB53@usgs.gov>
	<50461135.6010307@gmail.com>
Message-ID: <OF25814930.7B34DFC2-ON86257A6F.0051B408-86257A6F.0051DAD3@usgs.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120904/78bdf0a4/attachment.pl>

From murdoch.duncan at gmail.com  Tue Sep  4 19:40:11 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 04 Sep 2012 13:40:11 -0400
Subject: [Rd] Vignette question
In-Reply-To: <OF25814930.7B34DFC2-ON86257A6F.0051B408-86257A6F.0051DAD3@usgs.gov>
References: <mailman.17.1346752805.30578.r-devel@r-project.org>
	<5045F221.7050600@mayo.edu>
	<OF16428985.E6D7F237-ON86257A6F.0045BFC3-86257A6F.004BBB53@usgs.gov>
	<50461135.6010307@gmail.com>
	<OF25814930.7B34DFC2-ON86257A6F.0051B408-86257A6F.0051DAD3@usgs.gov>
Message-ID: <50463CFB.6040901@gmail.com>

On 04/09/2012 10:54 AM, David L Lorenz wrote:
> Duncan,
>    That does make sense. But then what does %\VignetteDepends{USGSgraphs}
> do if it does not actually make the library available from the temporary
> library tree?

It's not documented to do anything.  I think it is supported purely for 
back compatibility.

Duncan Murdoch

> Dave
>
>
>
> From:
> Duncan Murdoch <murdoch.duncan at gmail.com>
> To:
> David L Lorenz <lorenz at usgs.gov>
> Cc:
> r-devel at r-project.org
> Date:
> 09/04/2012 09:34 AM
> Subject:
> Re: [Rd] Vignette question
>
>
>
> On 04/09/2012 9:47 AM, David L Lorenz wrote:
> > All,
> >    I seem to be missing some key point about the construction of
> vignettes.
> > I have created a vignette script that works fine when run interactively
> > using Sweave. The top part of the .Rnw file is below.
> >
> > \documentclass{article}
> > \parskip 3pt
> > \parindent 30pt
> > %\VignetteIndexEntry{Box Plot Examples}
> > %\VignetteDepends{USGSgraphs}
> >
> > \begin{document}
> >
> > \title{Box Plot Examples}
> >
> > \author{Dave Lorenz}
> >
> > \maketitle
> >
> > ... text omittted from this example ...
> > <<echo=TRUE>>=
> > # Generate a random sample for the box plot
> > set.seed(27036)
> > BP <- rchisq(32, 3)
> > # setSweave is a specialized function that sets up the graphics page
> > setSweave("boxplot01", 6 ,6)
> > # Set layout for 4 graphs
> > AA.lo <- setLayout(width=rep(1.25, 4), height=4, xtop=1.5)
> >
> > ... remainder omitted ...
> >
> >    The functions setSweave and setLayout are functions within the
> > USGSgraphs library that I am building. As I said, the script runs just
> > fine when I run interactively. I do have a version of the USGSgraphs
> > library attached when I run the script. When I run R CMD check, or R CMD
> > build on the source, I get the error:
> >
> > Error: processing vignette 'boxplots.Rnw' failed with diagnostics:
> >   chunk 1
> > Error in eval(expr, envir, enclos) : could not find function "setSweave"
> > Execution halted
> >
> >    I would have expected that the contents of the library being built
> would
> > have been available to the script (based on section 1.3.2 in
> R-exts.html).
> > Barring that, I expected that "%\VignetteDepends{USGSgraphs}" would have
> > made those functions available to the script. I have found that if I
> > include this code before the first real example, it will run.
> >
> > <<echo=FALSE>>=
> > library(USGSgraphs)
> > @
> >
> >    But I have no reason to believe that it would run on any system that
> did
> > not already have a version of USGSgraphs installed. Note that if I use
> the
> > default graphics output, then I get the same error on setLayout.
> >    I use the default process for building the vignettes--no makefile.
> >    What do I need to do to get this vignette to run? I know I can set
> > BuildVignettes to FALSE in the DESCRIPTION file or try to build with the
> > --no-vignettes option, but that does not really address the more general
> > issue.
>
> Vignettes are run in pretty standard R sessions when the package is
> built, so you need the explicit library(USGSgraphs) call to make
> functions from your package available in that session.  What the manual
> is saying is just that that call will succeed:  R will install a copy of
> your package in order to build the vignette.  It goes into a "temporary
> library tree", because you might not want that particular version
> installed in your main tree.
>
> Duncan Murdoch
>
>
>


From gregory.warnes at novartis.com  Tue Sep  4 20:36:43 2012
From: gregory.warnes at novartis.com (Warnes, Gregory)
Date: Tue, 4 Sep 2012 18:36:43 +0000
Subject: [Rd] if(--as-cran)?
In-Reply-To: <5045F660.6030706@gmail.com>
Message-ID: <0CAEE2B1235DF643B0F5E1EAE1487B530946C41E@023-CH1MPN1-043.023d.mgd.msft.net>


On 9/4/12 8:38 AM, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:


>On 04/09/2012 8:20 AM, Terry Therneau wrote:
>>
>> On 09/04/2012 05:00 AM, r-devel-request at r-project.org wrote:
>> > The issue is not just about "CRAN" vs "off CRAN".
>> > It is good to think about a more general scheme of
>> > "light testing" vs "normal testing" vs "extensive testing",
>> > e.g.,  for the situation where the package implements
>> > (simulation/bootstrap/ ..) based inference, and the developer
>> > (but not only) should be able to run the extensive tests.
>> >
>> > Martin
>>
>> I agree with Martin.  A mechanism to specify testing level would be the
>>best.
>> Then CRAN can choose to set that variable to "3" say, with level 1 for
>>extensive and 2 for
>> usual.
>>     I'm quite willing to put up with the nuisance of print()
>>enclosures.  I prefer it to
>> having yet another way to subvert the evaluation model.
>>
>>     I'm a believer in testing everything possible in my packages, and
>>wear it it as a badge
>> of honor that the survival package has 4 lines of R code in the tests
>>directory for every
>> 3 in the R directory.  But CRAN only needs to run a small subset of
>>this.
>
>We have a mechanism to specify testing level:  the --as-cran flag. We
>could presumably make it more elaborate by adding other flags, or option
>levels, or whatever.
>
>What I think we shouldn't do is try to create an R-level test that says
>
>  if (testingLevel() > 3) {
>    doSomething
>}
>
>because tests can be turned on and off, individually.  If testingLevel 3
>specified tests (A, B, C), then is our testingLevel higher if we are
>running tests (A, B, D, E, F, G)?  Why not just test for the presence of
>whichever test is most relevant to that particular code block, e.g.
>
>  if ("D" %in% tests()) {
>   doSomething
>}


I would prefer the testingLevel() approach of the "D" %in% tests()
approach, since testingLevel() provides a natural way to add successively
greater test details without having to dig into the code to determine the
set of tests.  

-Greg


From murdoch.duncan at gmail.com  Tue Sep  4 20:57:43 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 04 Sep 2012 14:57:43 -0400
Subject: [Rd] if(--as-cran)?
In-Reply-To: <0CAEE2B1235DF643B0F5E1EAE1487B530946C41E@023-CH1MPN1-043.023d.mgd.msft.net>
References: <0CAEE2B1235DF643B0F5E1EAE1487B530946C41E@023-CH1MPN1-043.023d.mgd.msft.net>
Message-ID: <50464F27.2050003@gmail.com>

On 04/09/2012 2:36 PM, Warnes, Gregory wrote:
> On 9/4/12 8:38 AM, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>
>
> >On 04/09/2012 8:20 AM, Terry Therneau wrote:
> >>
> >> On 09/04/2012 05:00 AM, r-devel-request at r-project.org wrote:
> >> > The issue is not just about "CRAN" vs "off CRAN".
> >> > It is good to think about a more general scheme of
> >> > "light testing" vs "normal testing" vs "extensive testing",
> >> > e.g.,  for the situation where the package implements
> >> > (simulation/bootstrap/ ..) based inference, and the developer
> >> > (but not only) should be able to run the extensive tests.
> >> >
> >> > Martin
> >>
> >> I agree with Martin.  A mechanism to specify testing level would be the
> >>best.
> >> Then CRAN can choose to set that variable to "3" say, with level 1 for
> >>extensive and 2 for
> >> usual.
> >>     I'm quite willing to put up with the nuisance of print()
> >>enclosures.  I prefer it to
> >> having yet another way to subvert the evaluation model.
> >>
> >>     I'm a believer in testing everything possible in my packages, and
> >>wear it it as a badge
> >> of honor that the survival package has 4 lines of R code in the tests
> >>directory for every
> >> 3 in the R directory.  But CRAN only needs to run a small subset of
> >>this.
> >
> >We have a mechanism to specify testing level:  the --as-cran flag. We
> >could presumably make it more elaborate by adding other flags, or option
> >levels, or whatever.
> >
> >What I think we shouldn't do is try to create an R-level test that says
> >
> >  if (testingLevel() > 3) {
> >    doSomething
> >}
> >
> >because tests can be turned on and off, individually.  If testingLevel 3
> >specified tests (A, B, C), then is our testingLevel higher if we are
> >running tests (A, B, D, E, F, G)?  Why not just test for the presence of
> >whichever test is most relevant to that particular code block, e.g.
> >
> >  if ("D" %in% tests()) {
> >   doSomething
> >}
>
>
> I would prefer the testingLevel() approach of the "D" %in% tests()
> approach, since testingLevel() provides a natural way to add successively
> greater test details without having to dig into the code to determine the
> set of tests.

I don't see how you could possibly calculate a single number in a 
reasonable way.  What is the number that should be returned for (A, B, 
D, E, F, G)?

Duncan Murdoch


From therneau at mayo.edu  Tue Sep  4 21:44:05 2012
From: therneau at mayo.edu (Terry Therneau)
Date: Tue, 04 Sep 2012 14:44:05 -0500
Subject: [Rd] if(--as-cran)?
In-Reply-To: <50464F27.2050003@gmail.com>
References: <0CAEE2B1235DF643B0F5E1EAE1487B530946C41E@023-CH1MPN1-043.023d.mgd.msft.net>
	<50464F27.2050003@gmail.com>
Message-ID: <50465A05.70700@mayo.edu>



On 09/04/2012 01:57 PM, Duncan Murdoch wrote:
> On 04/09/2012 2:36 PM, Warnes, Gregory wrote:
>> On 9/4/12 8:38 AM, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>>
>>
>> >On 04/09/2012 8:20 AM, Terry Therneau wrote:
>> >>
>> >> On 09/04/2012 05:00 AM, r-devel-request at r-project.org wrote:
>> >> > The issue is not just about "CRAN" vs "off CRAN".
>> >> > It is good to think about a more general scheme of
>> >> > "light testing" vs "normal testing" vs "extensive testing",
>> >> > e.g., for the situation where the package implements
>> >> > (simulation/bootstrap/ ..) based inference, and the developer
>> >> > (but not only) should be able to run the extensive tests.
>> >> >
>> >> > Martin
>> >>
>> >> I agree with Martin. A mechanism to specify testing level would be the
>> >>best.
>> >> Then CRAN can choose to set that variable to "3" say, with level 1 for
>> >>extensive and 2 for
>> >> usual.
>> >> I'm quite willing to put up with the nuisance of print()
>> >>enclosures. I prefer it to
>> >> having yet another way to subvert the evaluation model.
>> >>
>> >> I'm a believer in testing everything possible in my packages, and
>> >>wear it it as a badge
>> >> of honor that the survival package has 4 lines of R code in the tests
>> >>directory for every
>> >> 3 in the R directory. But CRAN only needs to run a small subset of
>> >>this.
>> >
>> >We have a mechanism to specify testing level: the --as-cran flag. We
>> >could presumably make it more elaborate by adding other flags, or option
>> >levels, or whatever.
>> >
>> >What I think we shouldn't do is try to create an R-level test that says
>> >
>> > if (testingLevel() > 3) {
>> > doSomething
>> >}
>> >
>> >because tests can be turned on and off, individually. If testingLevel 3
>> >specified tests (A, B, C), then is our testingLevel higher if we are
>> >running tests (A, B, D, E, F, G)? Why not just test for the presence of
>> >whichever test is most relevant to that particular code block, e.g.
>> >
>> > if ("D" %in% tests()) {
>> > doSomething
>> >}
>>
>>
>> I would prefer the testingLevel() approach of the "D" %in% tests()
>> approach, since testingLevel() provides a natural way to add successively
>> greater test details without having to dig into the code to determine the
>> set of tests.
>
> I don't see how you could possibly calculate a single number in a reasonable way. What is
> the number that should be returned for (A, B, D, E, F, G)?
>
> Duncan Murdoch

Duncan is leapfrogging ahead to another level that I hadn't thought of.  An example would 
be to divide my survival package as "cox", "parametric", "survfit", "all", some of whaich 
overlap. Interesting idea, but beyond what I'd use.  When I'm focused on a detail I run 
the test of interest directly, not through CMD check.  For me low, med, high intensity 
suffices with as-cran invoking the first level and high including those that take an 
exceptionally long time.
  If you went to an A, B, C, ... approach what would be the as-cran default?

Of course there is then the furthest level, which I recently instituted for survival due
to the large number of dependencies: before posting a change download all the other
dependent packages and run their tests too.  It's an overnighter, and in that case I'd 
want level=high.  Forewarned is forearmed.

Terry T.


From murdoch.duncan at gmail.com  Tue Sep  4 21:58:55 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 04 Sep 2012 15:58:55 -0400
Subject: [Rd] if(--as-cran)?
In-Reply-To: <50465A05.70700@mayo.edu>
References: <0CAEE2B1235DF643B0F5E1EAE1487B530946C41E@023-CH1MPN1-043.023d.mgd.msft.net>
	<50464F27.2050003@gmail.com> <50465A05.70700@mayo.edu>
Message-ID: <50465D7F.5060004@gmail.com>

On 04/09/2012 3:44 PM, Terry Therneau wrote:
>
> On 09/04/2012 01:57 PM, Duncan Murdoch wrote:
> > On 04/09/2012 2:36 PM, Warnes, Gregory wrote:
> >> On 9/4/12 8:38 AM, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
> >>
> >>
> >> >On 04/09/2012 8:20 AM, Terry Therneau wrote:
> >> >>
> >> >> On 09/04/2012 05:00 AM, r-devel-request at r-project.org wrote:
> >> >> > The issue is not just about "CRAN" vs "off CRAN".
> >> >> > It is good to think about a more general scheme of
> >> >> > "light testing" vs "normal testing" vs "extensive testing",
> >> >> > e.g., for the situation where the package implements
> >> >> > (simulation/bootstrap/ ..) based inference, and the developer
> >> >> > (but not only) should be able to run the extensive tests.
> >> >> >
> >> >> > Martin
> >> >>
> >> >> I agree with Martin. A mechanism to specify testing level would be the
> >> >>best.
> >> >> Then CRAN can choose to set that variable to "3" say, with level 1 for
> >> >>extensive and 2 for
> >> >> usual.
> >> >> I'm quite willing to put up with the nuisance of print()
> >> >>enclosures. I prefer it to
> >> >> having yet another way to subvert the evaluation model.
> >> >>
> >> >> I'm a believer in testing everything possible in my packages, and
> >> >>wear it it as a badge
> >> >> of honor that the survival package has 4 lines of R code in the tests
> >> >>directory for every
> >> >> 3 in the R directory. But CRAN only needs to run a small subset of
> >> >>this.
> >> >
> >> >We have a mechanism to specify testing level: the --as-cran flag. We
> >> >could presumably make it more elaborate by adding other flags, or option
> >> >levels, or whatever.
> >> >
> >> >What I think we shouldn't do is try to create an R-level test that says
> >> >
> >> > if (testingLevel() > 3) {
> >> > doSomething
> >> >}
> >> >
> >> >because tests can be turned on and off, individually. If testingLevel 3
> >> >specified tests (A, B, C), then is our testingLevel higher if we are
> >> >running tests (A, B, D, E, F, G)? Why not just test for the presence of
> >> >whichever test is most relevant to that particular code block, e.g.
> >> >
> >> > if ("D" %in% tests()) {
> >> > doSomething
> >> >}
> >>
> >>
> >> I would prefer the testingLevel() approach of the "D" %in% tests()
> >> approach, since testingLevel() provides a natural way to add successively
> >> greater test details without having to dig into the code to determine the
> >> set of tests.
> >
> > I don't see how you could possibly calculate a single number in a reasonable way. What is
> > the number that should be returned for (A, B, D, E, F, G)?
> >
> > Duncan Murdoch
>
> Duncan is leapfrogging ahead to another level that I hadn't thought of.  An example would
> be to divide my survival package as "cox", "parametric", "survfit", "all", some of whaich
> overlap. Interesting idea, but beyond what I'd use.  When I'm focused on a detail I run
> the test of interest directly, not through CMD check.  For me low, med, high intensity
> suffices with as-cran invoking the first level and high including those that take an
> exceptionally long time.
>    If you went to an A, B, C, ... approach what would be the as-cran default?
>
> Of course there is then the furthest level, which I recently instituted for survival due
> to the large number of dependencies: before posting a change download all the other
> dependent packages and run their tests too.  It's an overnighter, and in that case I'd
> want level=high.  Forewarned is forearmed.

I don't think I'm leapfrogging, I think you're asking about something 
new.  The thread was started by Spencer asking how to determine within 
an example whether he was being tested by CRAN, because he didn't want 
to run a long test there (it caused a timeout).  This is an instance of 
the general problem of tailoring example and test code to the tests 
being run.

The testingLevel() function is supposed to be a way to know that a 
certain level of testing is being done, to allow such tailoring. 
However, I don't think it's practical.  I think you can ask whether a 
specific test is being run (my "D" %in% tests() example), but you can't 
reasonably convert the set of tests chosen by a tester into a single number.

What I think you and Greg are talking about is something different. You 
are asking that we set up more suites of tests, corresponding to 
numerical levels.  Currently we have two suites:  the default, and the 
--as-cran suite.  But we also have completely customized suites, set by 
users who want to check specific things.  They can do that the way you 
do (by calling the tests explicitly), or by setting environment 
variables (as described in the Tools chapter of the R Internals manual).

Duncan Murdoch


From gregory.warnes at novartis.com  Tue Sep  4 22:53:54 2012
From: gregory.warnes at novartis.com (Warnes, Gregory)
Date: Tue, 4 Sep 2012 20:53:54 +0000
Subject: [Rd] if(--as-cran)?
In-Reply-To: <50465D7F.5060004@gmail.com>
Message-ID: <0CAEE2B1235DF643B0F5E1EAE1487B530946D655@023-CH1MPN1-043.023d.mgd.msft.net>


On 9/4/12 3:58 PM, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:

>On 04/09/2012 3:44 PM, Terry Therneau wrote:
>>ly in
>> On 09/04/2012 01:57 PM, Duncan Murdoch wrote:
>> > On 04/09/2012 2:36 PM, Warnes, Gregory wrote:
>> >> On 9/4/12 8:38 AM, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>> >>
>> >>
>> >> >On 04/09/2012 8:20 AM, Terry Therneau wrote:
>> >> >>
>> >> >> On 09/04/2012 05:00 AM, M
>><mailto:r-devel-request at r-project.org>artin wrote:
>> >> >> > The issue is not just about "CRAN" vs "off CRAN".
>> >> >> > It is good to think about a more general scheme of
>> >> >> > "light testing" vs "normal testing" vs "extensive testing",
>> >> >> > e.g., for the situation where the package implements
>> >> >> > (simulation/bootstrap/ ..) based inference, and the developer
>> >> >> > (but not only) should be able to run the extensive tests.
>> >> >> >
>> >> >> > Martin
>> >> >>
>> >> >> I agree with Martin. A mechanism to specify testing level would
>>be the
>> >> >> best. Then CRAN can choose to set that variable to "3" say, with
>>level 
>> >> >> 1 for extensive and 2 for usual.
>>>> >>
>>
>>[snip] 

>The testingLevel() function is supposed to be a way to know that a
>certain level of testing is being done, to allow such tailoring.
>However, I don't think it's practical.  I think you can ask whether a
>specific test is being run (my "D" %in% tests() example), but you can't
>reasonably convert the set of tests chosen by a tester into a single
>number.
>
>What I think you and Greg are talking about is something different. You
>are asking that we set up more suites of tests, corresponding to
>numerical levels.  Currently we have two suites:  the default, and the
>--as-cran suite.  But we also have completely customized suites, set by
>users who want to check specific things.  They can do that the way you
>do (by calling the tests explicitly), or by setting environment
>variables (as described in the Tools chapter of the R Internals manual).

No!  We're not asking for the r-core to create more test suites, or even
to do anything different based on the test intensity level.

We're just asking for a standard way to control the intensity of the tests
*we* write to prevent us from duplicating this functionality in our own
packages, probably in incompatible ways.

-Greg


From simon.urbanek at r-project.org  Tue Sep  4 23:05:14 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 4 Sep 2012 17:05:14 -0400
Subject: [Rd] Possible page inefficiency in do_matrix in array.c
In-Reply-To: <d4a1a290ecf9463e63b98bf37add625f.squirrel@webmail.plus.net>
References: <7b0e4d32a6be42cf33560f51195ee706.squirrel@webmail.plus.net>
	<B7325928-6863-420C-A04A-C4AC5CDD2339@r-project.org>
	<5644F8CD-4120-46F0-BD00-918925650843@r-project.org>
	<d4a1a290ecf9463e63b98bf37add625f.squirrel@webmail.plus.net>
Message-ID: <4FC659F5-83E7-4033-A984-47F2C9A78167@r-project.org>

On Sep 4, 2012, at 8:07 AM, "Matthew Dowle" <mdowle at mdowle.plus.com> wrote:

> 
>> Actually, my apologies, I was assuming that your example was based on the
>> SO question while it is not at all (the code is not involved in that test
>> case). Reversing the order does indeed cause a delay. Switching to a
>> single index doesn't seem to have any impact. R-devel has the faster
>> version now (which now also works with large vectors).
>> 
>> Cheers,
>> Simon
> 
> I was intrigued why the compiler doesn't swap the loops when you thought
> it should, though. You're not usually wrong! From GCC's documentation (end
> of last paragraph is the most significant) :
> 
> ====
> 
> -floop-interchange
> Perform loop interchange transformations on loops. Interchanging two
> nested loops switches the inner and outer loops. For example, given a loop
> like:
>          DO J = 1, M
>            DO I = 1, N
>              A(J, I) = A(J, I) * C
>            ENDDO
>          ENDDO
> 
> loop interchange transforms the loop as if it were written:
> 
>          DO I = 1, N
>            DO J = 1, M
>              A(J, I) = A(J, I) * C
>            ENDDO
>          ENDDO
> 
> which can be beneficial when N is larger than the caches, because in
> Fortran, the elements of an array are stored in memory contiguously by
> column, and the original loop iterates over rows, potentially creating at
> each access a cache miss. This optimization applies to all the languages
> supported by GCC and is not limited to Fortran. To use this code
> transformation, GCC has to be configured with --with-ppl and --with-cloog
> to enable the Graphite loop transformation infrastructure.
> 
> ====
> 
> Could R build scripts be configured to set these gcc flags to turn on
> "Graphite", then? I guess one downside could be the time to compile.
> 

The is something odd happening - when I use stand-alone code it works: 

$ gcc -o t2 -O3 t2.c

$ time ./t2
0x7fbae3b4f010
real	0m1.045s
user	0m0.784s
sys	0m0.260s

$ gcc -o t2 -floop-interchange -O3 t2.c

$ time ./t2
0x7f4e516f2010
real	0m0.418s
user	0m0.044s
sys	0m0.372s

However, when I split off the loop into a parametrized function it doesn't:

$ gcc -floop-interchange -O3 t.c tt.c -o t && ./t
0x7fdd37cca010
loop time = 1772.085ms
$ gcc -O3 t.c tt.c -o t && ./t
0x7f3aa8777010
loop time = 1763.888ms

For comparison , manually swapping i and j:
$ gcc -floop-interchange -O3 t.c tt.c -o t && ./t
0x7feecd4c9010
loop time = 451.744ms

For the same reason, it doesn't work for the old R code. I wonder what's happening there - I guess the optimizer is not smart enough to realize the coverage is the entire m*n span despite the fact that m and n are parameters ... But it's certainly something it should optimize as it did when used directly in a function... Odd ...

Cheers,
Simon

--

PS:  Note this has nothing to do with "R builds scripts" - it is user's responsibility to add optimization flags since they are very much compiler and architecture-dependent. Also optimizations are occasionally known to backfire, so the default is always more conservative.

FWIW this is my latest incarnation of configuring optimized R on E5 machines (minus BLAS and prefix flags which will vary by system):

'--enable-lto' '--enable-R-shlib' 'CFLAGS=-g -O3 -fgcse-las -fgcse-sm -fgraphite-identity -floop-interchange -floop-strip-mine -floop-block -ftree-loop-distribution -mavx -march=native -mtune=native' 'CXXFLAGS=-g -O3 -fgcse-las -fgcse-sm -fgraphite-identity -floop-interchange -floop-strip-mine -floop-block -ftree-loop-distribution -mavx -march=native -mtune=native' 'FFLAGS=-g -O3 -fgcse-las -fgcse-sm -fgraphite-identity -floop-interchange -floop-strip-mine -floop-block -ftree-loop-distribution -mavx -march=native -mtune=native' 'FCFLAGS=-g -O3 -fgcse-las -fgcse-sm -fgraphite-identity -floop-interchange -floop-strip-mine -floop-block -ftree-loop-distribution -mavx -march=native -mtune=native' 


-- test code (test compiled with gcc (Ubuntu/Linaro 4.7.1-7ubuntu1) 4.7.1 20120814 (prerelease))

t.c:

void foo(int *x, const unsigned int m, const unsigned int n) {
    int i, j;
    for (i = 0; i < m; i++)
	for(j = 0; j < n; j++)
	    x[i + j * m] = 1;
}

tt.c:

#include <sys/time.h>
#include <stdlib.h>
#include <stdio.h>

void foo(int *, int, int);

static double ts() {
    struct timeval tv;
    gettimeofday(&tv, 0);
    return (double)tv.tv_sec + ((double) tv.tv_usec) / 1000000.0;
}

int main() {
    int m = 10000, n = 10000;
    int *x = (int*) malloc(m * n * sizeof(int));
    double a = ts(), b;
    foo(x, m , n);
    b = ts();
    printf("%p\nloop time = %.3fms\n", x, (b - a) * 1000);
    return 0;
}

t2.c:

#include <stdio.h>
#include <stdlib.h>

int *foo() {
    int m = 10000, n = 10000;
    int *x = (int*) malloc(m * n * sizeof(int));
    int i, j;
    for (i = 0; i < m; i++)
	for(j = 0; j < n; j++)
	    x[i + j * m] = 1;
    return x;
}

int main() {
    printf("%p", foo());
    return 0;
}


> Matthew
> 
> 
>> 
>> On Sep 2, 2012, at 10:32 PM, Simon Urbanek wrote:
>> 
>>> On Sep 2, 2012, at 10:04 PM, Matthew Dowle wrote:
>>> 
>>>> 
>>>> In do_matrix in src/array.c there is a type switch containing :
>>>> 
>>>> case LGLSXP :
>>>>  for (i = 0; i < nr; i++)
>>>>  for (j = 0; j < nc; j++)
>>>>      LOGICAL(ans)[i + j * NR] = NA_LOGICAL;
>>>> 
>>>> That seems page inefficient, iiuc. Think it should be :
>>>> 
>>>> case LGLSXP :
>>>>  for (j = 0; j < nc; j++)
>>>>  for (i = 0; i < nr; i++)
>>>>      LOGICAL(ans)[i + j * NR] = NA_LOGICAL;
>>>> 
>>>> or more simply :
>>>> 
>>>> case LGLSXP :
>>>>  for (i = 0; i < nc*nr; i++)
>>>>      LOGICAL(ans)[i] = NA_LOGICAL;
>>>> 
>>>> ( with some fine tuning required since NR is type R_xlen_t whilst i, nc
>>>> and nr are type int ).
>>>> 
>>>> Same goes for all the other types in that switch.
>>>> 
>>>> This came up on Stack Overflow here :
>>>> http://stackoverflow.com/questions/12220128/reason-for-faster-matrix-allocation-in-r
>>>> 
>>> 
>>> That is completely irrelevant - modern compilers will optimize the loops
>>> accordingly and there is no difference in speed. If you don't believe
>>> it, run benchmarks ;)
>>> 
>>> original
>>>> microbenchmark(matrix(nrow=10000, ncol=9999), times=10)
>>> Unit: milliseconds
>>>                              expr      min       lq  median       uq
>>>  max
>>> 1 matrix(nrow = 10000, ncol = 9999) 940.5519 940.6644 941.136 954.7196
>>> 1409.901
>>> 
>>> 
>>> swapped
>>>> microbenchmark(matrix(nrow=10000, ncol=9999), times=10)
>>> Unit: milliseconds
>>>                              expr      min       lq   median      uq
>>>  max
>>> 1 matrix(nrow = 10000, ncol = 9999) 949.9638 950.6642 952.7497 961.001
>>> 1246.573
>>> 
>>> Cheers,
>>> Simon
>>> 
>>> 
>>>> Matthew
>>>> 
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> 
>>>> 
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>> 
>> 
>> 
> 
> 
> 


From kasperdanielhansen at gmail.com  Tue Sep  4 23:12:14 2012
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Tue, 4 Sep 2012 17:12:14 -0400
Subject: [Rd] if(--as-cran)?
In-Reply-To: <0CAEE2B1235DF643B0F5E1EAE1487B530946D655@023-CH1MPN1-043.023d.mgd.msft.net>
References: <50465D7F.5060004@gmail.com>
	<0CAEE2B1235DF643B0F5E1EAE1487B530946D655@023-CH1MPN1-043.023d.mgd.msft.net>
Message-ID: <CAC2h7utRwFeb5_z5_gLUF=6b_cMw+CAgPnfqU_utMR7TPwu7zg@mail.gmail.com>

On Tue, Sep 4, 2012 at 4:53 PM, Warnes, Gregory
<gregory.warnes at novartis.com> wrote:
>
> On 9/4/12 3:58 PM, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>
>>On 04/09/2012 3:44 PM, Terry Therneau wrote:
>>>ly in
>>> On 09/04/2012 01:57 PM, Duncan Murdoch wrote:
>>> > On 04/09/2012 2:36 PM, Warnes, Gregory wrote:
>>> >> On 9/4/12 8:38 AM, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>>> >>
>>> >>
>>> >> >On 04/09/2012 8:20 AM, Terry Therneau wrote:
>>> >> >>
>>> >> >> On 09/04/2012 05:00 AM, M
>>><mailto:r-devel-request at r-project.org>artin wrote:
>>> >> >> > The issue is not just about "CRAN" vs "off CRAN".
>>> >> >> > It is good to think about a more general scheme of
>>> >> >> > "light testing" vs "normal testing" vs "extensive testing",
>>> >> >> > e.g., for the situation where the package implements
>>> >> >> > (simulation/bootstrap/ ..) based inference, and the developer
>>> >> >> > (but not only) should be able to run the extensive tests.
>>> >> >> >
>>> >> >> > Martin
>>> >> >>
>>> >> >> I agree with Martin. A mechanism to specify testing level would
>>>be the
>>> >> >> best. Then CRAN can choose to set that variable to "3" say, with
>>>level
>>> >> >> 1 for extensive and 2 for usual.
>>>>> >>
>>>
>>>[snip]
>
>>The testingLevel() function is supposed to be a way to know that a
>>certain level of testing is being done, to allow such tailoring.
>>However, I don't think it's practical.  I think you can ask whether a
>>specific test is being run (my "D" %in% tests() example), but you can't
>>reasonably convert the set of tests chosen by a tester into a single
>>number.
>>
>>What I think you and Greg are talking about is something different. You
>>are asking that we set up more suites of tests, corresponding to
>>numerical levels.  Currently we have two suites:  the default, and the
>>--as-cran suite.  But we also have completely customized suites, set by
>>users who want to check specific things.  They can do that the way you
>>do (by calling the tests explicitly), or by setting environment
>>variables (as described in the Tools chapter of the R Internals manual).
>
> No!  We're not asking for the r-core to create more test suites, or even
> to do anything different based on the test intensity level.
>
> We're just asking for a standard way to control the intensity of the tests
> *we* write to prevent us from duplicating this functionality in our own
> packages, probably in incompatible ways.

And given that CRAN recently put down timing requirements (and
Bioconductor has had them for a long time), it could be extremely
useful to have one system.  It is not clear to me whether it needs
more than 2 levels ("slow" and "fast"), but I'll leave that up to
people who have thought longer about this.

I could certainly use it in several packages to differentiate between
slow and quick tests.

Kasper


From edd at debian.org  Tue Sep  4 23:14:05 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 4 Sep 2012 16:14:05 -0500
Subject: [Rd] if(--as-cran)?
In-Reply-To: <0CAEE2B1235DF643B0F5E1EAE1487B530946D655@023-CH1MPN1-043.023d.mgd.msft.net>
References: <50465D7F.5060004@gmail.com>
	<0CAEE2B1235DF643B0F5E1EAE1487B530946D655@023-CH1MPN1-043.023d.mgd.msft.net>
Message-ID: <20550.28445.956167.112449@max.nulle.part>


On 4 September 2012 at 20:53, Warnes, Gregory wrote:
| No!  We're not asking for the r-core to create more test suites, or even
| to do anything different based on the test intensity level.
| 
| We're just asking for a standard way to control the intensity of the tests
| *we* write to prevent us from duplicating this functionality in our own
| packages, probably in incompatible ways.

Seconded.  

An add-on argument to the already established option --as-cran may be the
best.

And to iterate, what bugs me is that for _me_ on _my_ machine developing _my_
package I have remember how to enable what is now (as per CRAN's decree)
"non-standard behaviour" of full testing.  I fully agree with what Terry had
said: more tests are better (when we develop).  I want the full suite at my
end; that is after all why we wrote it!

The "non-standard" behaviour really is CRAN, and as it is already being
accounted for, we may as well add a hook we all can use to disable some tests
so that the runtime at CRAN remains within desired bounds.  But that is the
special case, and --as-cran should enable it (unless overridden).

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From murdoch.duncan at gmail.com  Tue Sep  4 23:15:27 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 04 Sep 2012 17:15:27 -0400
Subject: [Rd] if(--as-cran)?
In-Reply-To: <0CAEE2B1235DF643B0F5E1EAE1487B530946D655@023-CH1MPN1-043.023d.mgd.msft.net>
References: <0CAEE2B1235DF643B0F5E1EAE1487B530946D655@023-CH1MPN1-043.023d.mgd.msft.net>
Message-ID: <50466F6F.5030402@gmail.com>

On 04/09/2012 4:53 PM, Warnes, Gregory wrote:
> On 9/4/12 3:58 PM, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>
> >On 04/09/2012 3:44 PM, Terry Therneau wrote:
> >>ly in
> >> On 09/04/2012 01:57 PM, Duncan Murdoch wrote:
> >> > On 04/09/2012 2:36 PM, Warnes, Gregory wrote:
> >> >> On 9/4/12 8:38 AM, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
> >> >>
> >> >>
> >> >> >On 04/09/2012 8:20 AM, Terry Therneau wrote:
> >> >> >>
> >> >> >> On 09/04/2012 05:00 AM, M
> >><mailto:r-devel-request at r-project.org>artin wrote:
> >> >> >> > The issue is not just about "CRAN" vs "off CRAN".
> >> >> >> > It is good to think about a more general scheme of
> >> >> >> > "light testing" vs "normal testing" vs "extensive testing",
> >> >> >> > e.g., for the situation where the package implements
> >> >> >> > (simulation/bootstrap/ ..) based inference, and the developer
> >> >> >> > (but not only) should be able to run the extensive tests.
> >> >> >> >
> >> >> >> > Martin
> >> >> >>
> >> >> >> I agree with Martin. A mechanism to specify testing level would
> >>be the
> >> >> >> best. Then CRAN can choose to set that variable to "3" say, with
> >>level
> >> >> >> 1 for extensive and 2 for usual.
> >>>> >>
> >>
> >>[snip]
>
> >The testingLevel() function is supposed to be a way to know that a
> >certain level of testing is being done, to allow such tailoring.
> >However, I don't think it's practical.  I think you can ask whether a
> >specific test is being run (my "D" %in% tests() example), but you can't
> >reasonably convert the set of tests chosen by a tester into a single
> >number.
> >
> >What I think you and Greg are talking about is something different. You
> >are asking that we set up more suites of tests, corresponding to
> >numerical levels.  Currently we have two suites:  the default, and the
> >--as-cran suite.  But we also have completely customized suites, set by
> >users who want to check specific things.  They can do that the way you
> >do (by calling the tests explicitly), or by setting environment
> >variables (as described in the Tools chapter of the R Internals manual).
>
> No!  We're not asking for the r-core to create more test suites, or even
> to do anything different based on the test intensity level.
>
> We're just asking for a standard way to control the intensity of the tests
> *we* write to prevent us from duplicating this functionality in our own
> packages, probably in incompatible ways.

But you do have ways to control the tests you write.  The standard way 
is to set an environment variable, private to your needs.  If you see 
the variable, do what it says.  If you don't see it, do the default.

What I think is being asked for is a way to detect the suite of tests 
that CRAN runs (i.e. the --as-cran test), or perhaps to detect that it's 
actually CRAN doing the testing.  I've given a way to detect --as-cran, 
and despite what Martin says, it doesn't conflict with his practice.  I 
don't think it's a good idea to detect who is doing the testing, because 
I'd like to be able to duplicate the CRAN results for your package.

Duncan Murdoch


From murdoch.duncan at gmail.com  Tue Sep  4 23:26:20 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 04 Sep 2012 17:26:20 -0400
Subject: [Rd] if(--as-cran)?
In-Reply-To: <20550.28445.956167.112449@max.nulle.part>
References: <50465D7F.5060004@gmail.com>
	<0CAEE2B1235DF643B0F5E1EAE1487B530946D655@023-CH1MPN1-043.023d.mgd.msft.net>
	<20550.28445.956167.112449@max.nulle.part>
Message-ID: <504671FC.9030800@gmail.com>

On 04/09/2012 5:14 PM, Dirk Eddelbuettel wrote:
> On 4 September 2012 at 20:53, Warnes, Gregory wrote:
> | No!  We're not asking for the r-core to create more test suites, or even
> | to do anything different based on the test intensity level.
> |
> | We're just asking for a standard way to control the intensity of the tests
> | *we* write to prevent us from duplicating this functionality in our own
> | packages, probably in incompatible ways.
>
> Seconded.
>
> An add-on argument to the already established option --as-cran may be the
> best.
>
> And to iterate, what bugs me is that for _me_ on _my_ machine developing _my_
> package I have remember how to enable what is now (as per CRAN's decree)
> "non-standard behaviour" of full testing.  I fully agree with what Terry had
> said: more tests are better (when we develop).  I want the full suite at my
> end; that is after all why we wrote it!

You don't have to remember that, you need to figure it out once, write a 
script that sets the environment variables that enable it, and then you 
can forget it.

>
> The "non-standard" behaviour really is CRAN, and as it is already being
> accounted for, we may as well add a hook we all can use to disable some tests
> so that the runtime at CRAN remains within desired bounds.  But that is the
> special case, and --as-cran should enable it (unless overridden).

There are already hooks you can use to enable or disable lots of tests, 
maybe all of them (I haven't checked).  It probably doesn't make sense 
to set the --as-cran tests as the default:  would you want to be warned 
about version numbers if you're playing with a package locally, or if 
you have no intention to send it CRAN?

It might make sense to be able to detect that you're running within a 
time limit, which is where this thread started.  I don't know if it's 
possible to write a HowMuchTimeLeftBeforeTimeout() function, but if so, 
it would be useful in lots of contexts, not just for CRAN checks.   In 
general, there are lots of specific reasons to want to know about 
specific tests, and it's reasonable to ask for those. It's not 
reasonable to ask for an "intensity" number.

Duncan Murdoch


From jfox at mcmaster.ca  Tue Sep  4 23:21:33 2012
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 4 Sep 2012 17:21:33 -0400
Subject: [Rd] if(--as-cran)?
In-Reply-To: <CAC2h7utRwFeb5_z5_gLUF=6b_cMw+CAgPnfqU_utMR7TPwu7zg@mail.gmail.com>
References: <50465D7F.5060004@gmail.com>	<0CAEE2B1235DF643B0F5E1EAE1487B530946D655@023-CH1MPN1-043.023d.mgd.msft.net>
	<CAC2h7utRwFeb5_z5_gLUF=6b_cMw+CAgPnfqU_utMR7TPwu7zg@mail.gmail.com>
Message-ID: <000301cd8ae3$44a362a0$cdea27e0$@mcmaster.ca>

Dear all,

I'd like to second this fairly simple request. I currently enclosed some of
the examples in the effects package in \donttest{} blocks to satisfy the
CRAN timing requirements for examples. It would be nice to have something
like a \donttestcran{} block that suppresses the tests when --as-cran is set
(and on CRAN itself).

I'm sure that I've missed many of the nuances in this discussion, but this
seems like a simple solution to me.

Best,
 John

> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
> project.org] On Behalf Of Kasper Daniel Hansen
> Sent: Tuesday, September 04, 2012 5:12 PM
> To: Warnes, Gregory
> Cc: Terry Therneau; r-devel at r-project.org
> Subject: Re: [Rd] if(--as-cran)?
> 
> On Tue, Sep 4, 2012 at 4:53 PM, Warnes, Gregory
> <gregory.warnes at novartis.com> wrote:
> >
> > On 9/4/12 3:58 PM, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
> >
> >>On 04/09/2012 3:44 PM, Terry Therneau wrote:
> >>>ly in
> >>> On 09/04/2012 01:57 PM, Duncan Murdoch wrote:
> >>> > On 04/09/2012 2:36 PM, Warnes, Gregory wrote:
> >>> >> On 9/4/12 8:38 AM, "Duncan Murdoch" <murdoch.duncan at gmail.com>
> wrote:
> >>> >>
> >>> >>
> >>> >> >On 04/09/2012 8:20 AM, Terry Therneau wrote:
> >>> >> >>
> >>> >> >> On 09/04/2012 05:00 AM, M
> >>><mailto:r-devel-request at r-project.org>artin wrote:
> >>> >> >> > The issue is not just about "CRAN" vs "off CRAN".
> >>> >> >> > It is good to think about a more general scheme of
> >>> >> >> > "light testing" vs "normal testing" vs "extensive testing",
> >>> >> >> > e.g., for the situation where the package implements
> >>> >> >> > (simulation/bootstrap/ ..) based inference, and the
> developer
> >>> >> >> > (but not only) should be able to run the extensive tests.
> >>> >> >> >
> >>> >> >> > Martin
> >>> >> >>
> >>> >> >> I agree with Martin. A mechanism to specify testing level
> would
> >>>be the
> >>> >> >> best. Then CRAN can choose to set that variable to "3" say,
> with
> >>>level
> >>> >> >> 1 for extensive and 2 for usual.
> >>>>> >>
> >>>
> >>>[snip]
> >
> >>The testingLevel() function is supposed to be a way to know that a
> >>certain level of testing is being done, to allow such tailoring.
> >>However, I don't think it's practical.  I think you can ask whether a
> >>specific test is being run (my "D" %in% tests() example), but you
> can't
> >>reasonably convert the set of tests chosen by a tester into a single
> >>number.
> >>
> >>What I think you and Greg are talking about is something different.
> You
> >>are asking that we set up more suites of tests, corresponding to
> >>numerical levels.  Currently we have two suites:  the default, and the
> >>--as-cran suite.  But we also have completely customized suites, set
> by
> >>users who want to check specific things.  They can do that the way you
> >>do (by calling the tests explicitly), or by setting environment
> >>variables (as described in the Tools chapter of the R Internals
> manual).
> >
> > No!  We're not asking for the r-core to create more test suites, or
> even
> > to do anything different based on the test intensity level.
> >
> > We're just asking for a standard way to control the intensity of the
> tests
> > *we* write to prevent us from duplicating this functionality in our
> own
> > packages, probably in incompatible ways.
> 
> And given that CRAN recently put down timing requirements (and
> Bioconductor has had them for a long time), it could be extremely
> useful to have one system.  It is not clear to me whether it needs
> more than 2 levels ("slow" and "fast"), but I'll leave that up to
> people who have thought longer about this.
> 
> I could certainly use it in several packages to differentiate between
> slow and quick tests.
> 
> Kasper
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Tue Sep  4 23:32:55 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 04 Sep 2012 17:32:55 -0400
Subject: [Rd] if(--as-cran)?
In-Reply-To: <000301cd8ae3$44a362a0$cdea27e0$@mcmaster.ca>
References: <50465D7F.5060004@gmail.com>	<0CAEE2B1235DF643B0F5E1EAE1487B530946D655@023-CH1MPN1-043.023d.mgd.msft.net>
	<CAC2h7utRwFeb5_z5_gLUF=6b_cMw+CAgPnfqU_utMR7TPwu7zg@mail.gmail.com>
	<000301cd8ae3$44a362a0$cdea27e0$@mcmaster.ca>
Message-ID: <50467387.3030508@gmail.com>

On 04/09/2012 5:21 PM, John Fox wrote:
> Dear all,
>
> I'd like to second this fairly simple request. I currently enclosed some of
> the examples in the effects package in \donttest{} blocks to satisfy the
> CRAN timing requirements for examples. It would be nice to have something
> like a \donttestcran{} block that suppresses the tests when --as-cran is set
> (and on CRAN itself).
>
> I'm sure that I've missed many of the nuances in this discussion, but this
> seems like a simple solution to me.

That would work for examples, but not tests.  Many packages have scripts 
that are in the tests directory, not just test code in the .Rd files.  
What I think you should use is my suggested 
HowMuchTimeLeftBeforeTimeout() function, but if that's not writeable, 
then simply having a TIMELIMIT environment variable or similar, so your 
code could see if the there's a timeout pending.

Duncan Murdoch

>
> Best,
>   John
>
> > -----Original Message-----
> > From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
> > project.org] On Behalf Of Kasper Daniel Hansen
> > Sent: Tuesday, September 04, 2012 5:12 PM
> > To: Warnes, Gregory
> > Cc: Terry Therneau; r-devel at r-project.org
> > Subject: Re: [Rd] if(--as-cran)?
> >
> > On Tue, Sep 4, 2012 at 4:53 PM, Warnes, Gregory
> > <gregory.warnes at novartis.com> wrote:
> > >
> > > On 9/4/12 3:58 PM, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
> > >
> > >>On 04/09/2012 3:44 PM, Terry Therneau wrote:
> > >>>ly in
> > >>> On 09/04/2012 01:57 PM, Duncan Murdoch wrote:
> > >>> > On 04/09/2012 2:36 PM, Warnes, Gregory wrote:
> > >>> >> On 9/4/12 8:38 AM, "Duncan Murdoch" <murdoch.duncan at gmail.com>
> > wrote:
> > >>> >>
> > >>> >>
> > >>> >> >On 04/09/2012 8:20 AM, Terry Therneau wrote:
> > >>> >> >>
> > >>> >> >> On 09/04/2012 05:00 AM, M
> > >>><mailto:r-devel-request at r-project.org>artin wrote:
> > >>> >> >> > The issue is not just about "CRAN" vs "off CRAN".
> > >>> >> >> > It is good to think about a more general scheme of
> > >>> >> >> > "light testing" vs "normal testing" vs "extensive testing",
> > >>> >> >> > e.g., for the situation where the package implements
> > >>> >> >> > (simulation/bootstrap/ ..) based inference, and the
> > developer
> > >>> >> >> > (but not only) should be able to run the extensive tests.
> > >>> >> >> >
> > >>> >> >> > Martin
> > >>> >> >>
> > >>> >> >> I agree with Martin. A mechanism to specify testing level
> > would
> > >>>be the
> > >>> >> >> best. Then CRAN can choose to set that variable to "3" say,
> > with
> > >>>level
> > >>> >> >> 1 for extensive and 2 for usual.
> > >>>>> >>
> > >>>
> > >>>[snip]
> > >
> > >>The testingLevel() function is supposed to be a way to know that a
> > >>certain level of testing is being done, to allow such tailoring.
> > >>However, I don't think it's practical.  I think you can ask whether a
> > >>specific test is being run (my "D" %in% tests() example), but you
> > can't
> > >>reasonably convert the set of tests chosen by a tester into a single
> > >>number.
> > >>
> > >>What I think you and Greg are talking about is something different.
> > You
> > >>are asking that we set up more suites of tests, corresponding to
> > >>numerical levels.  Currently we have two suites:  the default, and the
> > >>--as-cran suite.  But we also have completely customized suites, set
> > by
> > >>users who want to check specific things.  They can do that the way you
> > >>do (by calling the tests explicitly), or by setting environment
> > >>variables (as described in the Tools chapter of the R Internals
> > manual).
> > >
> > > No!  We're not asking for the r-core to create more test suites, or
> > even
> > > to do anything different based on the test intensity level.
> > >
> > > We're just asking for a standard way to control the intensity of the
> > tests
> > > *we* write to prevent us from duplicating this functionality in our
> > own
> > > packages, probably in incompatible ways.
> >
> > And given that CRAN recently put down timing requirements (and
> > Bioconductor has had them for a long time), it could be extremely
> > useful to have one system.  It is not clear to me whether it needs
> > more than 2 levels ("slow" and "fast"), but I'll leave that up to
> > people who have thought longer about this.
> >
> > I could certainly use it in several packages to differentiate between
> > slow and quick tests.
> >
> > Kasper
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>


From edd at debian.org  Tue Sep  4 23:42:35 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 4 Sep 2012 16:42:35 -0500
Subject: [Rd] if(--as-cran)?
In-Reply-To: <504671FC.9030800@gmail.com>
References: <50465D7F.5060004@gmail.com>
	<0CAEE2B1235DF643B0F5E1EAE1487B530946D655@023-CH1MPN1-043.023d.mgd.msft.net>
	<20550.28445.956167.112449@max.nulle.part>
	<504671FC.9030800@gmail.com>
Message-ID: <20550.30155.399375.438614@max.nulle.part>


On 4 September 2012 at 17:26, Duncan Murdoch wrote:
| On 04/09/2012 5:14 PM, Dirk Eddelbuettel wrote:
| > An add-on argument to the already established option --as-cran may be the
| > best.
| >
| > And to iterate, what bugs me is that for _me_ on _my_ machine developing _my_
| > package I have remember how to enable what is now (as per CRAN's decree)
| > "non-standard behaviour" of full testing.  I fully agree with what Terry had
| > said: more tests are better (when we develop).  I want the full suite at my
| > end; that is after all why we wrote it!
| 
| You don't have to remember that, you need to figure it out once, write a 
| script that sets the environment variables that enable it, and then you 
| can forget it.

"In theory, theory and practice are the same. In practice, they are not."

The main test script long had exactly such a setting; I wrote what I wrote
because it is _still the wrong way around_ and as I happen to have added to
unit tests this weekend _having suffered through precisely this setting_.

But we are on different wavelengths here and I evidently do not get my point
across to you.  And as you are the one who could make a change where it
matters, I have no choice but to rest my case in frustration.

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From kasperdanielhansen at gmail.com  Tue Sep  4 23:46:06 2012
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Tue, 4 Sep 2012 17:46:06 -0400
Subject: [Rd] if(--as-cran)?
In-Reply-To: <50467387.3030508@gmail.com>
References: <50465D7F.5060004@gmail.com>
	<0CAEE2B1235DF643B0F5E1EAE1487B530946D655@023-CH1MPN1-043.023d.mgd.msft.net>
	<CAC2h7utRwFeb5_z5_gLUF=6b_cMw+CAgPnfqU_utMR7TPwu7zg@mail.gmail.com>
	<000301cd8ae3$44a362a0$cdea27e0$@mcmaster.ca>
	<50467387.3030508@gmail.com>
Message-ID: <CAC2h7uvSU_K6wu4i7C7Px1v-VSJ4bT_C2C9eeZ+mJF=eaxdX2w@mail.gmail.com>

On Tue, Sep 4, 2012 at 5:32 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 04/09/2012 5:21 PM, John Fox wrote:
>>
>> Dear all,
>>
>> I'd like to second this fairly simple request. I currently enclosed some
>> of
>> the examples in the effects package in \donttest{} blocks to satisfy the
>> CRAN timing requirements for examples. It would be nice to have something
>> like a \donttestcran{} block that suppresses the tests when --as-cran is
>> set
>> (and on CRAN itself).
>>
>> I'm sure that I've missed many of the nuances in this discussion, but this
>> seems like a simple solution to me.
>
>
> That would work for examples, but not tests.  Many packages have scripts
> that are in the tests directory, not just test code in the .Rd files.  What
> I think you should use is my suggested HowMuchTimeLeftBeforeTimeout()
> function, but if that's not writeable, then simply having a TIMELIMIT
> environment variable or similar, so your code could see if the there's a
> timeout pending.

I don't like this idea, because then I need to think about the order
in which the tests are run.

You are right that we could simulate this by having an environment
variable, and if that variable is set, we could do the full tests.
Like Dirk is mentioning, the (sensible, I might add) requirement that
the tests should be "quick" suddenly makes the quick testing the
default.

What I - and I think a lot of other people - would like, is to do this
in a standard way so it would be uniform across packages.  I don't
think it would be good if I start using R_LONG_TESTS and Dirk starts
to use __NON_CRAN_TESTS or whatever.  Then all of us need to know the
package-specific variables when we test other people packages (and
that happens occasionally, for example when you have a package that
other packages depend upon).

In this use case, standardization would be hugely beneficial in my
opinion.  In my reading of the discussion, this is really what all of
us are saying.

>
> Duncan Murdoch
>
>
>>
>> Best,
>>   John
>>
>> > -----Original Message-----
>> > From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
>> > project.org] On Behalf Of Kasper Daniel Hansen
>> > Sent: Tuesday, September 04, 2012 5:12 PM
>> > To: Warnes, Gregory
>> > Cc: Terry Therneau; r-devel at r-project.org
>> > Subject: Re: [Rd] if(--as-cran)?
>> >
>> > On Tue, Sep 4, 2012 at 4:53 PM, Warnes, Gregory
>> > <gregory.warnes at novartis.com> wrote:
>> > >
>> > > On 9/4/12 3:58 PM, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>> > >
>> > >>On 04/09/2012 3:44 PM, Terry Therneau wrote:
>> > >>>ly in
>> > >>> On 09/04/2012 01:57 PM, Duncan Murdoch wrote:
>> > >>> > On 04/09/2012 2:36 PM, Warnes, Gregory wrote:
>> > >>> >> On 9/4/12 8:38 AM, "Duncan Murdoch" <murdoch.duncan at gmail.com>
>> > wrote:
>> > >>> >>
>> > >>> >>
>> > >>> >> >On 04/09/2012 8:20 AM, Terry Therneau wrote:
>> > >>> >> >>
>> > >>> >> >> On 09/04/2012 05:00 AM, M
>> > >>><mailto:r-devel-request at r-project.org>artin wrote:
>> > >>> >> >> > The issue is not just about "CRAN" vs "off CRAN".
>> > >>> >> >> > It is good to think about a more general scheme of
>> > >>> >> >> > "light testing" vs "normal testing" vs "extensive testing",
>> > >>> >> >> > e.g., for the situation where the package implements
>> > >>> >> >> > (simulation/bootstrap/ ..) based inference, and the
>> > developer
>> > >>> >> >> > (but not only) should be able to run the extensive tests.
>> > >>> >> >> >
>> > >>> >> >> > Martin
>> > >>> >> >>
>> > >>> >> >> I agree with Martin. A mechanism to specify testing level
>> > would
>> > >>>be the
>> > >>> >> >> best. Then CRAN can choose to set that variable to "3" say,
>> > with
>> > >>>level
>> > >>> >> >> 1 for extensive and 2 for usual.
>> > >>>>> >>
>> > >>>
>> > >>>[snip]
>> > >
>> > >>The testingLevel() function is supposed to be a way to know that a
>> > >>certain level of testing is being done, to allow such tailoring.
>> > >>However, I don't think it's practical.  I think you can ask whether a
>> > >>specific test is being run (my "D" %in% tests() example), but you
>> > can't
>> > >>reasonably convert the set of tests chosen by a tester into a single
>> > >>number.
>> > >>
>> > >>What I think you and Greg are talking about is something different.
>> > You
>> > >>are asking that we set up more suites of tests, corresponding to
>> > >>numerical levels.  Currently we have two suites:  the default, and the
>> > >>--as-cran suite.  But we also have completely customized suites, set
>> > by
>> > >>users who want to check specific things.  They can do that the way you
>> > >>do (by calling the tests explicitly), or by setting environment
>> > >>variables (as described in the Tools chapter of the R Internals
>> > manual).
>> > >
>> > > No!  We're not asking for the r-core to create more test suites, or
>> > even
>> > > to do anything different based on the test intensity level.
>> > >
>> > > We're just asking for a standard way to control the intensity of the
>> > tests
>> > > *we* write to prevent us from duplicating this functionality in our
>> > own
>> > > packages, probably in incompatible ways.
>> >
>> > And given that CRAN recently put down timing requirements (and
>> > Bioconductor has had them for a long time), it could be extremely
>> > useful to have one system.  It is not clear to me whether it needs
>> > more than 2 levels ("slow" and "fast"), but I'll leave that up to
>> > people who have thought longer about this.
>> >
>> > I could certainly use it in several packages to differentiate between
>> > slow and quick tests.
>> >
>> > Kasper
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From murdoch.duncan at gmail.com  Wed Sep  5 00:02:06 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 04 Sep 2012 18:02:06 -0400
Subject: [Rd] if(--as-cran)?
In-Reply-To: <20550.30155.399375.438614@max.nulle.part>
References: <50465D7F.5060004@gmail.com>
	<0CAEE2B1235DF643B0F5E1EAE1487B530946D655@023-CH1MPN1-043.023d.mgd.msft.net>
	<20550.28445.956167.112449@max.nulle.part>
	<504671FC.9030800@gmail.com>
	<20550.30155.399375.438614@max.nulle.part>
Message-ID: <50467A5E.2080106@gmail.com>

On 04/09/2012 5:42 PM, Dirk Eddelbuettel wrote:
> On 4 September 2012 at 17:26, Duncan Murdoch wrote:
> | On 04/09/2012 5:14 PM, Dirk Eddelbuettel wrote:
> | > An add-on argument to the already established option --as-cran may be the
> | > best.
> | >
> | > And to iterate, what bugs me is that for _me_ on _my_ machine developing _my_
> | > package I have remember how to enable what is now (as per CRAN's decree)
> | > "non-standard behaviour" of full testing.  I fully agree with what Terry had
> | > said: more tests are better (when we develop).  I want the full suite at my
> | > end; that is after all why we wrote it!
> |
> | You don't have to remember that, you need to figure it out once, write a
> | script that sets the environment variables that enable it, and then you
> | can forget it.
>
> "In theory, theory and practice are the same. In practice, they are not."
>
> The main test script long had exactly such a setting; I wrote what I wrote
> because it is _still the wrong way around_ and as I happen to have added to
> unit tests this weekend _having suffered through precisely this setting_.
>
> But we are on different wavelengths here and I evidently do not get my point
> across to you.  And as you are the one who could make a change where it
> matters, I have no choice but to rest my case in frustration.

If you want to give up, then give up, but then don't complain about the 
current behaviour.  If you want to fix it, then continue the discussion.

You're right that we're on different wavelengths.  If you want some 
tests to run at home but not on CRAN, then somewhere there has to be a 
conditional.  I'm suggesting that the conditional should be "if there's 
a tight time limit, skip this".

I don't remember if this was your suggestion, but someone has suggested 
"if we're running with the --as-cran option, skip this" and others have 
suggested "if we're running on CRAN, skip this".   I don't see why you 
find my suggestion so objectionable.  If you want, I'll repeat why I 
find the other two suggestions objectionable.

Duncan Murdoch


From kasperdanielhansen at gmail.com  Wed Sep  5 02:19:47 2012
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Tue, 4 Sep 2012 20:19:47 -0400
Subject: [Rd] if(--as-cran)?
In-Reply-To: <50467A5E.2080106@gmail.com>
References: <50465D7F.5060004@gmail.com>
	<0CAEE2B1235DF643B0F5E1EAE1487B530946D655@023-CH1MPN1-043.023d.mgd.msft.net>
	<20550.28445.956167.112449@max.nulle.part> <504671FC.9030800@gmail.com>
	<20550.30155.399375.438614@max.nulle.part> <50467A5E.2080106@gmail.com>
Message-ID: <CAC2h7usPuepziN4ngNg2F_9jOPPF_doTJR7bnfFbpX_0gowHtw@mail.gmail.com>

On Tue, Sep 4, 2012 at 6:02 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 04/09/2012 5:42 PM, Dirk Eddelbuettel wrote:
>>
>> On 4 September 2012 at 17:26, Duncan Murdoch wrote:
>> | On 04/09/2012 5:14 PM, Dirk Eddelbuettel wrote:
>> | > An add-on argument to the already established option --as-cran may be
>> the
>> | > best.
>> | >
>> | > And to iterate, what bugs me is that for _me_ on _my_ machine
>> developing _my_
>> | > package I have remember how to enable what is now (as per CRAN's
>> decree)
>> | > "non-standard behaviour" of full testing.  I fully agree with what
>> Terry had
>> | > said: more tests are better (when we develop).  I want the full suite
>> at my
>> | > end; that is after all why we wrote it!
>> |
>> | You don't have to remember that, you need to figure it out once, write a
>> | script that sets the environment variables that enable it, and then you
>> | can forget it.
>>
>> "In theory, theory and practice are the same. In practice, they are not."
>>
>> The main test script long had exactly such a setting; I wrote what I wrote
>> because it is _still the wrong way around_ and as I happen to have added
>> to
>> unit tests this weekend _having suffered through precisely this setting_.
>>
>> But we are on different wavelengths here and I evidently do not get my
>> point
>> across to you.  And as you are the one who could make a change where it
>> matters, I have no choice but to rest my case in frustration.
>
>
> If you want to give up, then give up, but then don't complain about the
> current behaviour.  If you want to fix it, then continue the discussion.
>
> You're right that we're on different wavelengths.  If you want some tests to
> run at home but not on CRAN, then somewhere there has to be a conditional.
> I'm suggesting that the conditional should be "if there's a tight time
> limit, skip this".
>
> I don't remember if this was your suggestion, but someone has suggested "if
> we're running with the --as-cran option, skip this" and others have
> suggested "if we're running on CRAN, skip this".   I don't see why you find
> my suggestion so objectionable.  If you want, I'll repeat why I find the
> other two suggestions objectionable.

I agree with Duncan that having an option long/short makes more sense
than with/without cran, as long as cran sets that option to be short.
I would also prefer a command line switch to R CMD check to an
environment variable, but I'll be very happy with a standardized
environment variable.

Kasper

>
> Duncan Murdoch
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Wed Sep  5 08:11:23 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 05 Sep 2012 02:11:23 -0400
Subject: [Rd] if(--as-cran)?
In-Reply-To: <CAC2h7usPuepziN4ngNg2F_9jOPPF_doTJR7bnfFbpX_0gowHtw@mail.gmail.com>
References: <50465D7F.5060004@gmail.com>
	<0CAEE2B1235DF643B0F5E1EAE1487B530946D655@023-CH1MPN1-043.023d.mgd.msft.net>
	<20550.28445.956167.112449@max.nulle.part>
	<504671FC.9030800@gmail.com>
	<20550.30155.399375.438614@max.nulle.part>
	<50467A5E.2080106@gmail.com>
	<CAC2h7usPuepziN4ngNg2F_9jOPPF_doTJR7bnfFbpX_0gowHtw@mail.gmail.com>
Message-ID: <5046ED0B.4060506@gmail.com>

On 12-09-04 8:19 PM, Kasper Daniel Hansen wrote:
> On Tue, Sep 4, 2012 at 6:02 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> On 04/09/2012 5:42 PM, Dirk Eddelbuettel wrote:
>>>
>>> On 4 September 2012 at 17:26, Duncan Murdoch wrote:
>>> | On 04/09/2012 5:14 PM, Dirk Eddelbuettel wrote:
>>> | > An add-on argument to the already established option --as-cran may be
>>> the
>>> | > best.
>>> | >
>>> | > And to iterate, what bugs me is that for _me_ on _my_ machine
>>> developing _my_
>>> | > package I have remember how to enable what is now (as per CRAN's
>>> decree)
>>> | > "non-standard behaviour" of full testing.  I fully agree with what
>>> Terry had
>>> | > said: more tests are better (when we develop).  I want the full suite
>>> at my
>>> | > end; that is after all why we wrote it!
>>> |
>>> | You don't have to remember that, you need to figure it out once, write a
>>> | script that sets the environment variables that enable it, and then you
>>> | can forget it.
>>>
>>> "In theory, theory and practice are the same. In practice, they are not."
>>>
>>> The main test script long had exactly such a setting; I wrote what I wrote
>>> because it is _still the wrong way around_ and as I happen to have added
>>> to
>>> unit tests this weekend _having suffered through precisely this setting_.
>>>
>>> But we are on different wavelengths here and I evidently do not get my
>>> point
>>> across to you.  And as you are the one who could make a change where it
>>> matters, I have no choice but to rest my case in frustration.
>>
>>
>> If you want to give up, then give up, but then don't complain about the
>> current behaviour.  If you want to fix it, then continue the discussion.
>>
>> You're right that we're on different wavelengths.  If you want some tests to
>> run at home but not on CRAN, then somewhere there has to be a conditional.
>> I'm suggesting that the conditional should be "if there's a tight time
>> limit, skip this".
>>
>> I don't remember if this was your suggestion, but someone has suggested "if
>> we're running with the --as-cran option, skip this" and others have
>> suggested "if we're running on CRAN, skip this".   I don't see why you find
>> my suggestion so objectionable.  If you want, I'll repeat why I find the
>> other two suggestions objectionable.
>
> I agree with Duncan that having an option long/short makes more sense
> than with/without cran, as long as cran sets that option to be short.
 >
> I would also prefer a command line switch to R CMD check to an
> environment variable, but I'll be very happy with a standardized
> environment variable.

I honestly don't see the need for a standardized variable.  I've told 
you how to detect that you are running --as-cran; if that isn't 
sufficient information, then you, the package author, need to set up 
something more elaborate, and assume that if it's not set up, then 
someone else (maybe CRAN) is running the test.

I asked the CRAN powers-that-be about the possibility of querying the 
amount of time remaining before a timeout; since the different platforms 
all use different mechanisms to enforce a timeout, that's not really 
practical.  So the best you could hope for is to know that a timeout is 
in effect.  Before I wrote any code, I'd need to hear why --as-cran 
detection isn't sufficient.

Duncan Murdoch


>
> Kasper
>
>>
>> Duncan Murdoch
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From deepayan.sarkar at gmail.com  Wed Sep  5 08:19:37 2012
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Wed, 5 Sep 2012 11:49:37 +0530
Subject: [Rd] if(--as-cran)?
In-Reply-To: <5046ED0B.4060506@gmail.com>
References: <50465D7F.5060004@gmail.com>
	<0CAEE2B1235DF643B0F5E1EAE1487B530946D655@023-CH1MPN1-043.023d.mgd.msft.net>
	<20550.28445.956167.112449@max.nulle.part>
	<504671FC.9030800@gmail.com>
	<20550.30155.399375.438614@max.nulle.part>
	<50467A5E.2080106@gmail.com>
	<CAC2h7usPuepziN4ngNg2F_9jOPPF_doTJR7bnfFbpX_0gowHtw@mail.gmail.com>
	<5046ED0B.4060506@gmail.com>
Message-ID: <CADfFDC55XL5P8ytALSeCT5QK5DCXfbfo7z7AmJRaOZiU_-R3EQ@mail.gmail.com>

On Wed, Sep 5, 2012 at 11:41 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 12-09-04 8:19 PM, Kasper Daniel Hansen wrote:
>>
>> On Tue, Sep 4, 2012 at 6:02 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
>> wrote:
>>>
>>> On 04/09/2012 5:42 PM, Dirk Eddelbuettel wrote:
>>>>
>>>>
>>>> On 4 September 2012 at 17:26, Duncan Murdoch wrote:
>>>> | On 04/09/2012 5:14 PM, Dirk Eddelbuettel wrote:
>>>> | > An add-on argument to the already established option --as-cran may
>>>> be
>>>> the
>>>> | > best.
>>>> | >
>>>> | > And to iterate, what bugs me is that for _me_ on _my_ machine
>>>> developing _my_
>>>> | > package I have remember how to enable what is now (as per CRAN's
>>>> decree)
>>>> | > "non-standard behaviour" of full testing.  I fully agree with what
>>>> Terry had
>>>> | > said: more tests are better (when we develop).  I want the full
>>>> suite
>>>> at my
>>>> | > end; that is after all why we wrote it!
>>>> |
>>>> | You don't have to remember that, you need to figure it out once, write
>>>> a
>>>> | script that sets the environment variables that enable it, and then
>>>> you
>>>> | can forget it.
>>>>
>>>> "In theory, theory and practice are the same. In practice, they are
>>>> not."
>>>>
>>>> The main test script long had exactly such a setting; I wrote what I
>>>> wrote
>>>> because it is _still the wrong way around_ and as I happen to have added
>>>> to
>>>> unit tests this weekend _having suffered through precisely this
>>>> setting_.
>>>>
>>>> But we are on different wavelengths here and I evidently do not get my
>>>> point
>>>> across to you.  And as you are the one who could make a change where it
>>>> matters, I have no choice but to rest my case in frustration.
>>>
>>>
>>>
>>> If you want to give up, then give up, but then don't complain about the
>>> current behaviour.  If you want to fix it, then continue the discussion.
>>>
>>> You're right that we're on different wavelengths.  If you want some tests
>>> to
>>> run at home but not on CRAN, then somewhere there has to be a
>>> conditional.
>>> I'm suggesting that the conditional should be "if there's a tight time
>>> limit, skip this".
>>>
>>> I don't remember if this was your suggestion, but someone has suggested
>>> "if
>>> we're running with the --as-cran option, skip this" and others have
>>> suggested "if we're running on CRAN, skip this".   I don't see why you
>>> find
>>> my suggestion so objectionable.  If you want, I'll repeat why I find the
>>> other two suggestions objectionable.
>>
>>
>> I agree with Duncan that having an option long/short makes more sense
>> than with/without cran, as long as cran sets that option to be short.
>
>>
>>
>> I would also prefer a command line switch to R CMD check to an
>> environment variable, but I'll be very happy with a standardized
>> environment variable.
>
>
> I honestly don't see the need for a standardized variable.  I've told you
> how to detect that you are running --as-cran; if that isn't sufficient
> information, then you, the package author, need to set up something more
> elaborate, and assume that if it's not set up, then someone else (maybe
> CRAN) is running the test.

So maybe documenting that (_R_CHECK_TIMINGS_) more formally in R-exts
would be sufficient?

-Deepayan


> I asked the CRAN powers-that-be about the possibility of querying the amount
> of time remaining before a timeout; since the different platforms all use
> different mechanisms to enforce a timeout, that's not really practical.  So
> the best you could hope for is to know that a timeout is in effect.  Before
> I wrote any code, I'd need to hear why --as-cran detection isn't sufficient.


From maechler at stat.math.ethz.ch  Wed Sep  5 09:48:04 2012
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 5 Sep 2012 09:48:04 +0200
Subject: [Rd] if(--as-cran)?
In-Reply-To: <CAC2h7ut23XbkXj6ddzt5rJWX_abn13TH2OPHRaw8OfTCfRmRRw@mail.gmail.com>
References: <50465D7F.5060004@gmail.com>
	<0CAEE2B1235DF643B0F5E1EAE1487B530946D655@023-CH1MPN1-043.023d.mgd.msft.net>
	<CAC2h7utRwFeb5_z5_gLUF=6b_cMw+CAgPnfqU_utMR7TPwu7zg@mail.gmail.com>
	<000301cd8ae3$44a362a0$cdea27e0$@mcmaster.ca>
	<50467387.3030508@gmail.com>
	<CAC2h7ut23XbkXj6ddzt5rJWX_abn13TH2OPHRaw8OfTCfRmRRw@mail.gmail.com>
Message-ID: <20551.948.480320.538435@stat.math.ethz.ch>

>>>>> Kasper Daniel Hansen <kasperdanielhansen at gmail.com>
>>>>>     on Tue, 4 Sep 2012 17:41:38 -0400 writes:

    > On Tue, Sep 4, 2012 at 5:32 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
    >> On 04/09/2012 5:21 PM, John Fox wrote:
    >>> 
    >>> Dear all,
    >>> 
    >>> I'd like to second this fairly simple request. I currently enclosed some
    >>> of
    >>> the examples in the effects package in \donttest{} blocks to satisfy the
    >>> CRAN timing requirements for examples. It would be nice to have something
    >>> like a \donttestcran{} block that suppresses the tests when --as-cran is
    >>> set
    >>> (and on CRAN itself).
    >>> 
    >>> I'm sure that I've missed many of the nuances in this discussion, but this
    >>> seems like a simple solution to me.
    >> 
    >> 
    >> That would work for examples, but not tests.  Many packages have scripts
    >> that are in the tests directory, not just test code in the .Rd files.  What
    >> I think you should use is my suggested HowMuchTimeLeftBeforeTimeout()
    >> function, but if that's not writeable, then simply having a TIMELIMIT
    >> environment variable or similar, so your code could see if the there's a
    >> timeout pending.

    > I don't like this idea, because then I need to think about the order
    > in which the tests are run.

    > You are right that we could simulate this by having an environment
    > variable, and if that variable is set, we could do the full tests.
    > Like Dirk is mentioning, the (sensible, I might add) requirement that
    > the tests should be "quick" suddenly makes the quick testing the
    > default.

    > What I - and I think a lot of other people - would like, is to do this
    > in a standard way so it would be uniform across packages.  I don't
    > think it would be good if I start using R_LONG_TESTS and Dirk starts
    > to use __NON_CRAN_TESTS or whatever.  Then all of us need to know the
    > package-specific variables when we test other people packages (and
    > that happens occasionally, for example when you have a package that
    > other packages depend upon).

    > In this use case, standardization would be hugely beneficial in my
    > opinion.  In my reading of the discussion, this is really what all of
    > us are saying.

    > Kasper

Yes!  

... plus the idea to go one  step further:

Instead of just two levels  ( quick tests / extensive tests ),
one could use 3 or 4 (or 5) such levels, e.g.,
   1: very quick 
   2: CRAN-ok-quick
   3: package-developer-usual
   4: extensive

   *and* the CRAN maintainers would say which level is the one
   that runs daily on CRAN and hence needs to meet Duncan's
   TIMELIMIT.

   So instead of just setting an environment variable to
   non-zero length, or "true" (as in my example), one could set
   that environment variable to an  1, 2, ...

Martin


    >>> > -----Original Message-----
    >>> > From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
    >>> > project.org] On Behalf Of Kasper Daniel Hansen
    >>> > Sent: Tuesday, September 04, 2012 5:12 PM
    >>> > To: Warnes, Gregory
    >>> > Cc: Terry Therneau; r-devel at r-project.org
    >>> > Subject: Re: [Rd] if(--as-cran)?
    >>> >
    >>> > On Tue, Sep 4, 2012 at 4:53 PM, Warnes, Gregory
    >>> > <gregory.warnes at novartis.com> wrote:
    >>> > >
    >>> > > On 9/4/12 3:58 PM, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
    >>> > >
    >>> > >>On 04/09/2012 3:44 PM, Terry Therneau wrote:
    >>> > >>>ly in
    >>> > >>> On 09/04/2012 01:57 PM, Duncan Murdoch wrote:
    >>> > >>> > On 04/09/2012 2:36 PM, Warnes, Gregory wrote:
    >>> > >>> >> On 9/4/12 8:38 AM, "Duncan Murdoch" <murdoch.duncan at gmail.com>
    >>> > wrote:
    >>> > >>> >>
    >>> > >>> >>
    >>> > >>> >> >On 04/09/2012 8:20 AM, Terry Therneau wrote:
    >>> > >>> >> >>
    >>> > >>> >> >> On 09/04/2012 05:00 AM, M
    >>> > >>><mailto:r-devel-request at r-project.org>artin wrote:
    >>> > >>> >> >> > The issue is not just about "CRAN" vs "off CRAN".
    >>> > >>> >> >> > It is good to think about a more general scheme of
    >>> > >>> >> >> > "light testing" vs "normal testing" vs "extensive testing",
    >>> > >>> >> >> > e.g., for the situation where the package implements
    >>> > >>> >> >> > (simulation/bootstrap/ ..) based inference, and the
    >>> > developer
    >>> > >>> >> >> > (but not only) should be able to run the extensive tests.
    >>> > >>> >> >> >
    >>> > >>> >> >> > Martin
    >>> > >>> >> >>
    >>> > >>> >> >> I agree with Martin. A mechanism to specify testing level
    >>> > would
    >>> > >>>be the
    >>> > >>> >> >> best. Then CRAN can choose to set that variable to "3" say,
    >>> > with
    >>> > >>>level
    >>> > >>> >> >> 1 for extensive and 2 for usual.
    >>> > >>>>> >>
    >>> > >>>
    >>> > >>>[snip]
    >>> > >
    >>> > >>The testingLevel() function is supposed to be a way to know that a
    >>> > >>certain level of testing is being done, to allow such tailoring.
    >>> > >>However, I don't think it's practical.  I think you can ask whether a
    >>> > >>specific test is being run (my "D" %in% tests() example), but you
    >>> > can't
    >>> > >>reasonably convert the set of tests chosen by a tester into a single
    >>> > >>number.
    >>> > >>
    >>> > >>What I think you and Greg are talking about is something different.
    >>> > You
    >>> > >>are asking that we set up more suites of tests, corresponding to
    >>> > >>numerical levels.  Currently we have two suites:  the default, and the
    >>> > >>--as-cran suite.  But we also have completely customized suites, set
    >>> > by
    >>> > >>users who want to check specific things.  They can do that the way you
    >>> > >>do (by calling the tests explicitly), or by setting environment
    >>> > >>variables (as described in the Tools chapter of the R Internals
    >>> > manual).
    >>> > >
    >>> > > No!  We're not asking for the r-core to create more test suites, or
    >>> > even
    >>> > > to do anything different based on the test intensity level.
    >>> > >
    >>> > > We're just asking for a standard way to control the intensity of the
    >>> > tests
    >>> > > *we* write to prevent us from duplicating this functionality in our
    >>> > own
    >>> > > packages, probably in incompatible ways.
    >>> >
    >>> > And given that CRAN recently put down timing requirements (and
    >>> > Bioconductor has had them for a long time), it could be extremely
    >>> > useful to have one system.  It is not clear to me whether it needs
    >>> > more than 2 levels ("slow" and "fast"), but I'll leave that up to
    >>> > people who have thought longer about this.
    >>> >
    >>> > I could certainly use it in several packages to differentiate between
    >>> > slow and quick tests.
    >>> >
    >>> > Kasper
    >>> >
    >>> > ______________________________________________
    >>> > R-devel at r-project.org mailing list
    >>> > https://stat.ethz.ch/mailman/listinfo/r-devel
    >>> 
    >>


From maechler at stat.math.ethz.ch  Wed Sep  5 12:25:47 2012
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 5 Sep 2012 12:25:47 +0200
Subject: [Rd] if(--as-cran)?
In-Reply-To: <CADfFDC55XL5P8ytALSeCT5QK5DCXfbfo7z7AmJRaOZiU_-R3EQ@mail.gmail.com>
References: <50465D7F.5060004@gmail.com>
	<0CAEE2B1235DF643B0F5E1EAE1487B530946D655@023-CH1MPN1-043.023d.mgd.msft.net>
	<20550.28445.956167.112449@max.nulle.part>
	<504671FC.9030800@gmail.com>
	<20550.30155.399375.438614@max.nulle.part>
	<50467A5E.2080106@gmail.com>
	<CAC2h7usPuepziN4ngNg2F_9jOPPF_doTJR7bnfFbpX_0gowHtw@mail.gmail.com>
	<5046ED0B.4060506@gmail.com>
	<CADfFDC55XL5P8ytALSeCT5QK5DCXfbfo7z7AmJRaOZiU_-R3EQ@mail.gmail.com>
Message-ID: <20551.10411.168210.290864@stat.math.ethz.ch>

>>>>> Deepayan Sarkar <deepayan.sarkar at gmail.com>
>>>>>     on Wed, 5 Sep 2012 11:49:37 +0530 writes:

    > On Wed, Sep 5, 2012 at 11:41 AM, Duncan Murdoch
    > <murdoch.duncan at gmail.com> wrote:
    >> On 12-09-04 8:19 PM, Kasper Daniel Hansen wrote:
    >>> 
    >>> On Tue, Sep 4, 2012 at 6:02 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
    >>> wrote:
    >>>> 
    >>>> On 04/09/2012 5:42 PM, Dirk Eddelbuettel wrote:
    >>>>> 
    >>>>> 
    >>>>> On 4 September 2012 at 17:26, Duncan Murdoch wrote:
    >>>>> | On 04/09/2012 5:14 PM, Dirk Eddelbuettel wrote:
    >>>>> | > An add-on argument to the already established option --as-cran may
    >>>>> be
    >>>>> the
    >>>>> | > best.
    >>>>> | >
    >>>>> | > And to iterate, what bugs me is that for _me_ on _my_ machine
    >>>>> developing _my_
    >>>>> | > package I have remember how to enable what is now (as per CRAN's
    >>>>> decree)
    >>>>> | > "non-standard behaviour" of full testing.  I fully agree with what
    >>>>> Terry had
    >>>>> | > said: more tests are better (when we develop).  I want the full
    >>>>> suite
    >>>>> at my
    >>>>> | > end; that is after all why we wrote it!
    >>>>> |
    >>>>> | You don't have to remember that, you need to figure it out once, write
    >>>>> a
    >>>>> | script that sets the environment variables that enable it, and then
    >>>>> you
    >>>>> | can forget it.
    >>>>> 
    >>>>> "In theory, theory and practice are the same. In practice, they are
    >>>>> not."
    >>>>> 
    >>>>> The main test script long had exactly such a setting; I wrote what I
    >>>>> wrote
    >>>>> because it is _still the wrong way around_ and as I happen to have added
    >>>>> to
    >>>>> unit tests this weekend _having suffered through precisely this
    >>>>> setting_.
    >>>>> 
    >>>>> But we are on different wavelengths here and I evidently do not get my
    >>>>> point
    >>>>> across to you.  And as you are the one who could make a change where it
    >>>>> matters, I have no choice but to rest my case in frustration.
    >>>> 
    >>>> 
    >>>> 
    >>>> If you want to give up, then give up, but then don't complain about the
    >>>> current behaviour.  If you want to fix it, then continue the discussion.
    >>>> 
    >>>> You're right that we're on different wavelengths.  If you want some tests
    >>>> to
    >>>> run at home but not on CRAN, then somewhere there has to be a
    >>>> conditional.
    >>>> I'm suggesting that the conditional should be "if there's a tight time
    >>>> limit, skip this".
    >>>> 
    >>>> I don't remember if this was your suggestion, but someone has suggested
    >>>> "if
    >>>> we're running with the --as-cran option, skip this" and others have
    >>>> suggested "if we're running on CRAN, skip this".   I don't see why you
    >>>> find
    >>>> my suggestion so objectionable.  If you want, I'll repeat why I find the
    >>>> other two suggestions objectionable.
    >>> 
    >>> 
    >>> I agree with Duncan that having an option long/short makes more sense
    >>> than with/without cran, as long as cran sets that option to be short.
    >> 
    >>> 
    >>> 
    >>> I would also prefer a command line switch to R CMD check to an
    >>> environment variable, but I'll be very happy with a standardized
    >>> environment variable.
    >> 
    >> 
    >> I honestly don't see the need for a standardized variable.  I've told you
    >> how to detect that you are running --as-cran; if that isn't sufficient
    >> information, then you, the package author, need to set up something more
    >> elaborate, and assume that if it's not set up, then someone else (maybe
    >> CRAN) is running the test.

    > So maybe documenting that (_R_CHECK_TIMINGS_) more formally in R-exts
    > would be sufficient?

    > -Deepayan

yes and no.
As Duncan said very early,  --as-cran is just turning on several
already existing options, one of them being the
_R_CHECK_TIMINGS_  -- which you can *also* enable by  --timings.

So, checking for  _R_CHECK_TIMINGS_ is *not* checking for
the presence of  --as-cran !
.. in the sense that it is necessary but not sufficient.
Also, if I run the "long checks" I may still want to use
 --timings. For me as package developer, the timings may be even more
important in the "long" than in the "short" checks case.

So, one solution that is little work would be that  --as-cran
sets an *extra* environment variable that is *only* set by
--as-cran, but by no other command line switch.

Still a pity that it seems people want to live in a  0/1
setting when it would be very natural to adopt a  0/1/2/3
(or so) one.
It's a bit like prefering  verbose = FALSE/TRUE  as argument to
an R function where eventually I often found that using a
tracing = 0/1/2  (or then  'verbose' = 0/1/2  which is almost
back compatible to FALSE/TRUE) 
was more useful.



    >> I asked the CRAN powers-that-be about the possibility of querying the amount
    >> of time remaining before a timeout; since the different platforms all use
    >> different mechanisms to enforce a timeout, that's not really practical.  So
    >> the best you could hope for is to know that a timeout is in effect.  Before
    >> I wrote any code, I'd need to hear why --as-cran detection isn't sufficient.

I agree that *reliable*  --as-cran  detection  solves the OP's 
and most other correspondents problem.
But as argued above,  _R_CHECK_TIMINGS_  is not sufficient.

Martin


From murdoch.duncan at gmail.com  Wed Sep  5 15:10:06 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 05 Sep 2012 09:10:06 -0400
Subject: [Rd] if(--as-cran)?
In-Reply-To: <20551.10411.168210.290864@stat.math.ethz.ch>
References: <50465D7F.5060004@gmail.com>
	<0CAEE2B1235DF643B0F5E1EAE1487B530946D655@023-CH1MPN1-043.023d.mgd.msft.net>
	<20550.28445.956167.112449@max.nulle.part>
	<504671FC.9030800@gmail.com>
	<20550.30155.399375.438614@max.nulle.part>
	<50467A5E.2080106@gmail.com>
	<CAC2h7usPuepziN4ngNg2F_9jOPPF_doTJR7bnfFbpX_0gowHtw@mail.gmail.com>
	<5046ED0B.4060506@gmail.com>
	<CADfFDC55XL5P8ytALSeCT5QK5DCXfbfo7z7AmJRaOZiU_-R3EQ@mail.gmail.com>
	<20551.10411.168210.290864@stat.math.ethz.ch>
Message-ID: <50474F2E.9000600@gmail.com>

This post contains two incorrect statements.  Since Martin is too busy 
to post a retraction, I will point them out:

  --timings and --as-cran do not set _R_CHECK_TIMINGS_ in the same way.

As far as I recall, nobody has suggested that package writers be limited 
to two choices for test suites.  I certainly haven't.

Duncan Murdoch

On 05/09/2012 6:25 AM, Martin Maechler wrote:
> >>>>> Deepayan Sarkar <deepayan.sarkar at gmail.com>
> >>>>>     on Wed, 5 Sep 2012 11:49:37 +0530 writes:
>
>      > On Wed, Sep 5, 2012 at 11:41 AM, Duncan Murdoch
>      > <murdoch.duncan at gmail.com> wrote:
>      >> On 12-09-04 8:19 PM, Kasper Daniel Hansen wrote:
>      >>>
>      >>> On Tue, Sep 4, 2012 at 6:02 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
>      >>> wrote:
>      >>>>
>      >>>> On 04/09/2012 5:42 PM, Dirk Eddelbuettel wrote:
>      >>>>>
>      >>>>>
>      >>>>> On 4 September 2012 at 17:26, Duncan Murdoch wrote:
>      >>>>> | On 04/09/2012 5:14 PM, Dirk Eddelbuettel wrote:
>      >>>>> | > An add-on argument to the already established option --as-cran may
>      >>>>> be
>      >>>>> the
>      >>>>> | > best.
>      >>>>> | >
>      >>>>> | > And to iterate, what bugs me is that for _me_ on _my_ machine
>      >>>>> developing _my_
>      >>>>> | > package I have remember how to enable what is now (as per CRAN's
>      >>>>> decree)
>      >>>>> | > "non-standard behaviour" of full testing.  I fully agree with what
>      >>>>> Terry had
>      >>>>> | > said: more tests are better (when we develop).  I want the full
>      >>>>> suite
>      >>>>> at my
>      >>>>> | > end; that is after all why we wrote it!
>      >>>>> |
>      >>>>> | You don't have to remember that, you need to figure it out once, write
>      >>>>> a
>      >>>>> | script that sets the environment variables that enable it, and then
>      >>>>> you
>      >>>>> | can forget it.
>      >>>>>
>      >>>>> "In theory, theory and practice are the same. In practice, they are
>      >>>>> not."
>      >>>>>
>      >>>>> The main test script long had exactly such a setting; I wrote what I
>      >>>>> wrote
>      >>>>> because it is _still the wrong way around_ and as I happen to have added
>      >>>>> to
>      >>>>> unit tests this weekend _having suffered through precisely this
>      >>>>> setting_.
>      >>>>>
>      >>>>> But we are on different wavelengths here and I evidently do not get my
>      >>>>> point
>      >>>>> across to you.  And as you are the one who could make a change where it
>      >>>>> matters, I have no choice but to rest my case in frustration.
>      >>>>
>      >>>>
>      >>>>
>      >>>> If you want to give up, then give up, but then don't complain about the
>      >>>> current behaviour.  If you want to fix it, then continue the discussion.
>      >>>>
>      >>>> You're right that we're on different wavelengths.  If you want some tests
>      >>>> to
>      >>>> run at home but not on CRAN, then somewhere there has to be a
>      >>>> conditional.
>      >>>> I'm suggesting that the conditional should be "if there's a tight time
>      >>>> limit, skip this".
>      >>>>
>      >>>> I don't remember if this was your suggestion, but someone has suggested
>      >>>> "if
>      >>>> we're running with the --as-cran option, skip this" and others have
>      >>>> suggested "if we're running on CRAN, skip this".   I don't see why you
>      >>>> find
>      >>>> my suggestion so objectionable.  If you want, I'll repeat why I find the
>      >>>> other two suggestions objectionable.
>      >>>
>      >>>
>      >>> I agree with Duncan that having an option long/short makes more sense
>      >>> than with/without cran, as long as cran sets that option to be short.
>      >>
>      >>>
>      >>>
>      >>> I would also prefer a command line switch to R CMD check to an
>      >>> environment variable, but I'll be very happy with a standardized
>      >>> environment variable.
>      >>
>      >>
>      >> I honestly don't see the need for a standardized variable.  I've told you
>      >> how to detect that you are running --as-cran; if that isn't sufficient
>      >> information, then you, the package author, need to set up something more
>      >> elaborate, and assume that if it's not set up, then someone else (maybe
>      >> CRAN) is running the test.
>
>      > So maybe documenting that (_R_CHECK_TIMINGS_) more formally in R-exts
>      > would be sufficient?
>
>      > -Deepayan
>
> yes and no.
> As Duncan said very early,  --as-cran is just turning on several
> already existing options, one of them being the
> _R_CHECK_TIMINGS_  -- which you can *also* enable by  --timings.
>
> So, checking for  _R_CHECK_TIMINGS_ is *not* checking for
> the presence of  --as-cran !
> .. in the sense that it is necessary but not sufficient.
> Also, if I run the "long checks" I may still want to use
>   --timings. For me as package developer, the timings may be even more
> important in the "long" than in the "short" checks case.
>
> So, one solution that is little work would be that  --as-cran
> sets an *extra* environment variable that is *only* set by
> --as-cran, but by no other command line switch.
>
> Still a pity that it seems people want to live in a  0/1
> setting when it would be very natural to adopt a  0/1/2/3
> (or so) one.
> It's a bit like prefering  verbose = FALSE/TRUE  as argument to
> an R function where eventually I often found that using a
> tracing = 0/1/2  (or then  'verbose' = 0/1/2  which is almost
> back compatible to FALSE/TRUE)
> was more useful.
>
>
>
>      >> I asked the CRAN powers-that-be about the possibility of querying the amount
>      >> of time remaining before a timeout; since the different platforms all use
>      >> different mechanisms to enforce a timeout, that's not really practical.  So
>      >> the best you could hope for is to know that a timeout is in effect.  Before
>      >> I wrote any code, I'd need to hear why --as-cran detection isn't sufficient.
>
> I agree that *reliable*  --as-cran  detection  solves the OP's
> and most other correspondents problem.
> But as argued above,  _R_CHECK_TIMINGS_  is not sufficient.
>
> Martin


From therneau at mayo.edu  Wed Sep  5 18:08:05 2012
From: therneau at mayo.edu (Terry Therneau)
Date: Wed, 05 Sep 2012 11:08:05 -0500
Subject: [Rd] Cran package checks
Message-ID: <504778E5.80507@mayo.edu>

Some questions motivated by this discussion.

 From the CRAN policy page:
"Checking the package should take as little CPU time as possible, as the CRAN check farm 
is a very limited resource and there are thousands of packages. Long-running tests and 
vignette code can be made optional for checking, but do ensure that the checks that are 
left do exercise all the features of the package."

  Is there a further document that elucidates more on this?
  	What is "little CPU time".
   	Is there a documented variable that I can check and then reduce the test set for CRAN? 
Duncan mentioned one in the dicussion, but I'll end up forgetting the details.  A static 
reference would help.
	"Test all the features". The test directory for survival has 75 files and still doesn't 
test everything: I'm about to add a new one today in response to a bug report.
How do I adjucate between "little time" and "test all"?

Footnote: the manual page for R CMD check (?check) has the line "Many of the checks in R 
CMD check can be turned off or on by environment variables: see Chapter 6 of the ?R 
Internals? manual".  The reference should be chapter 7.  That chapter does document the 
use of _R_CHECK_TIMINGS_=10.  But it seems dangerous to use this as an indirect test, ie. 
"if timings is 10 then this must be CRAN running".

  My biggest time offender is in the vignettes.  After multiple readings of the docs I 
still can't quite figure out how to specify
	- pdf files that should be in the vignettes index, but are not .Rnw source
	- how to tell R which ones to redo, and which to just accept the pdf
	- per the policy line "all source for pdf should be available", non-inclusion of the Rnw 
file isn't an answer.
Again, is there another document I'm missing?


Terry T.


From moshersteven at gmail.com  Wed Sep  5 18:39:48 2012
From: moshersteven at gmail.com (steven mosher)
Date: Wed, 5 Sep 2012 09:39:48 -0700
Subject: [Rd] Suggestion: Change default to download.file(...,
 mode="wb") ...instead of mode="w" with some bells and whistles
In-Reply-To: <CAFDcVCSthCJGyvvVZBnWJqYb-F4Z8ZT_YZA7E0GK1Mx5CoNYkw@mail.gmail.com>
References: <CAFDcVCSthCJGyvvVZBnWJqYb-F4Z8ZT_YZA7E0GK1Mx5CoNYkw@mail.gmail.com>
Message-ID: <CAFFLneTfAAVhRhNjzXV=SweL_Yko=1KjCWoK9UZwLRm-DM946Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120905/4b246313/attachment.pl>

From mtmorgan at fhcrc.org  Wed Sep  5 22:50:19 2012
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Wed, 05 Sep 2012 13:50:19 -0700
Subject: [Rd] all.equal on external pointers and environments
Message-ID: <5047BB0B.60906@fhcrc.org>

For an external pointer

 > xp
<pointer: (nil)>

one might expect all.equal to behave as for environments

 > e = new.env()
 > all.equal(e, e)
[1] TRUE

but it does not

 > all.equal(xp, xp)
Error in unclass(target) : cannot unclass an external pointer

A solution is to dispatch to all.equal.language (?) in

src/library/base/R/all.equal.R:26

but this requires an is.expternalptr primitive.

In some respects, one might expect all.equal for environments to be more 
thorough

   e = new.env(); e[["a"]] = 1
   all.equal(e, new.env())          ## expect FALSE, as in next line
   all.equal(as.list(e), as.list(new.env()))
   all.equal(new.env(), new.env())  ## TRUE; ok?

Martin
-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From kasperdanielhansen at gmail.com  Thu Sep  6 03:17:47 2012
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Wed, 5 Sep 2012 21:17:47 -0400
Subject: [Rd] Cran package checks
In-Reply-To: <504778E5.80507@mayo.edu>
References: <504778E5.80507@mayo.edu>
Message-ID: <CAC2h7usg0zkdYAjrJTh0Oo8U_LBKRgxkSXm6DuVKFyc_Apkkjw@mail.gmail.com>

On Wed, Sep 5, 2012 at 12:08 PM, Terry Therneau <therneau at mayo.edu> wrote:
>  My biggest time offender is in the vignettes.  After multiple readings of
> the docs I still can't quite figure out how to specify
>         - pdf files that should be in the vignettes index, but are not .Rnw
> source
>         - how to tell R which ones to redo, and which to just accept the pdf
>         - per the policy line "all source for pdf should be available",
> non-inclusion of the Rnw file isn't an answer.
> Again, is there another document I'm missing?

If you have multiple Rnw files producing pdfs, and you only want some
of them to be run, you do the following.  Say we have
  big.Rnw (takes a long time to run)
  small.Rnw (is quick)
You run yourself big.Rnw and produce big.pdf.  Then you put
  small.Rnw in /vignettes
  big.Rnw and big.pdf in inst/doc
That way, big.Rnw will not get run.  And the package installation will
contain both Rnw files and pdf files for both vignettes.

Note that this only works if you have both a quick and a long
vignette.  If you only have big.Rnw and big.pdf in inst/doc and
nothing in vignettes, R would still run Sweave on big.Rnw.

I agree the section on this in R-exts is a bit opaque: "By default R
CMD build will run Sweave on all files in Sweave format in vignettes,
or if that does not exist, inst/doc (but not in sub-directories)."
(R-exts 1.4)

Kasper


From kasperdanielhansen at gmail.com  Thu Sep  6 03:51:01 2012
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Wed, 5 Sep 2012 21:51:01 -0400
Subject: [Rd] if(--as-cran)?
In-Reply-To: <50474F2E.9000600@gmail.com>
References: <50465D7F.5060004@gmail.com>
	<0CAEE2B1235DF643B0F5E1EAE1487B530946D655@023-CH1MPN1-043.023d.mgd.msft.net>
	<20550.28445.956167.112449@max.nulle.part> <504671FC.9030800@gmail.com>
	<20550.30155.399375.438614@max.nulle.part> <50467A5E.2080106@gmail.com>
	<CAC2h7usPuepziN4ngNg2F_9jOPPF_doTJR7bnfFbpX_0gowHtw@mail.gmail.com>
	<5046ED0B.4060506@gmail.com>
	<CADfFDC55XL5P8ytALSeCT5QK5DCXfbfo7z7AmJRaOZiU_-R3EQ@mail.gmail.com>
	<20551.10411.168210.290864@stat.math.ethz.ch>
	<50474F2E.9000600@gmail.com>
Message-ID: <CAC2h7uvFWmjUfA0yxMNXtGwR4rZGdXZW_reBvP9n74=vOgwH0g@mail.gmail.com>

Duncan,

you are right that from the perspective of a single developer: it is
entirely possible to make tests conditional and ensure that 'long'
tests does not get run by CRAN.

What I, and several others, advocate is a uniform set of conventions,
so we avoid having multiple package specific solutions.

Martin has explained one reason for why using _R_CHECK_TIMINGS_ is not
ideal (the fact that we - at least I and Martin - are most interested
in the timings for the long tests).  Another reason is that I (and I
suspect most others) would prefer something that looks a bit more
official and supported.  High-jacking an environment variable set for
(what appears to be) a different reason does not seem like something
that could be considered supported long-term, and which have a uniform
interface (across packages).

Of course, adding an extra environment variable or an extra function
(as suggested by Henrik) is additional work, and I know it is easy for
us to suggest things.  My perspective is that I would like something
that will continue to be supported in the future, and where I can use
the same interface across the packages I maintain and others outside
my control that I occasionally test.  Testing is not just being done
by the package author(s) or CRAN.   I suspect many packages already
have half-baked solutions to the 'long' test vs 'short' test issue,
and I don't think we will see any movement toward a unified interface
without support in base R.

And let me end by saying that I do agree with Martin: having numerical
levels is better (together with a clear statement what --as-cran sets
the level to).  But I would rather have a binary state than nothing.

Kasper


On Wed, Sep 5, 2012 at 9:10 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> This post contains two incorrect statements.  Since Martin is too busy to
> post a retraction, I will point them out:
>
>  --timings and --as-cran do not set _R_CHECK_TIMINGS_ in the same way.
>
> As far as I recall, nobody has suggested that package writers be limited to
> two choices for test suites.  I certainly haven't.
>
> Duncan Murdoch
>
>
> On 05/09/2012 6:25 AM, Martin Maechler wrote:
>>
>> >>>>> Deepayan Sarkar <deepayan.sarkar at gmail.com>
>> >>>>>     on Wed, 5 Sep 2012 11:49:37 +0530 writes:
>>
>>      > On Wed, Sep 5, 2012 at 11:41 AM, Duncan Murdoch
>>      > <murdoch.duncan at gmail.com> wrote:
>>      >> On 12-09-04 8:19 PM, Kasper Daniel Hansen wrote:
>>      >>>
>>      >>> On Tue, Sep 4, 2012 at 6:02 PM, Duncan Murdoch
>> <murdoch.duncan at gmail.com>
>>      >>> wrote:
>>      >>>>
>>      >>>> On 04/09/2012 5:42 PM, Dirk Eddelbuettel wrote:
>>      >>>>>
>>      >>>>>
>>      >>>>> On 4 September 2012 at 17:26, Duncan Murdoch wrote:
>>      >>>>> | On 04/09/2012 5:14 PM, Dirk Eddelbuettel wrote:
>>      >>>>> | > An add-on argument to the already established option
>> --as-cran may
>>      >>>>> be
>>      >>>>> the
>>      >>>>> | > best.
>>      >>>>> | >
>>      >>>>> | > And to iterate, what bugs me is that for _me_ on _my_
>> machine
>>      >>>>> developing _my_
>>      >>>>> | > package I have remember how to enable what is now (as per
>> CRAN's
>>      >>>>> decree)
>>      >>>>> | > "non-standard behaviour" of full testing.  I fully agree
>> with what
>>      >>>>> Terry had
>>      >>>>> | > said: more tests are better (when we develop).  I want the
>> full
>>      >>>>> suite
>>      >>>>> at my
>>      >>>>> | > end; that is after all why we wrote it!
>>      >>>>> |
>>      >>>>> | You don't have to remember that, you need to figure it out
>> once, write
>>      >>>>> a
>>      >>>>> | script that sets the environment variables that enable it,
>> and then
>>      >>>>> you
>>      >>>>> | can forget it.
>>      >>>>>
>>      >>>>> "In theory, theory and practice are the same. In practice, they
>> are
>>      >>>>> not."
>>      >>>>>
>>      >>>>> The main test script long had exactly such a setting; I wrote
>> what I
>>      >>>>> wrote
>>      >>>>> because it is _still the wrong way around_ and as I happen to
>> have added
>>      >>>>> to
>>      >>>>> unit tests this weekend _having suffered through precisely this
>>      >>>>> setting_.
>>      >>>>>
>>      >>>>> But we are on different wavelengths here and I evidently do not
>> get my
>>      >>>>> point
>>      >>>>> across to you.  And as you are the one who could make a change
>> where it
>>      >>>>> matters, I have no choice but to rest my case in frustration.
>>      >>>>
>>      >>>>
>>      >>>>
>>      >>>> If you want to give up, then give up, but then don't complain
>> about the
>>      >>>> current behaviour.  If you want to fix it, then continue the
>> discussion.
>>      >>>>
>>      >>>> You're right that we're on different wavelengths.  If you want
>> some tests
>>      >>>> to
>>      >>>> run at home but not on CRAN, then somewhere there has to be a
>>      >>>> conditional.
>>      >>>> I'm suggesting that the conditional should be "if there's a
>> tight time
>>      >>>> limit, skip this".
>>      >>>>
>>      >>>> I don't remember if this was your suggestion, but someone has
>> suggested
>>      >>>> "if
>>      >>>> we're running with the --as-cran option, skip this" and others
>> have
>>      >>>> suggested "if we're running on CRAN, skip this".   I don't see
>> why you
>>      >>>> find
>>      >>>> my suggestion so objectionable.  If you want, I'll repeat why I
>> find the
>>      >>>> other two suggestions objectionable.
>>      >>>
>>      >>>
>>      >>> I agree with Duncan that having an option long/short makes more
>> sense
>>      >>> than with/without cran, as long as cran sets that option to be
>> short.
>>      >>
>>      >>>
>>      >>>
>>      >>> I would also prefer a command line switch to R CMD check to an
>>      >>> environment variable, but I'll be very happy with a standardized
>>      >>> environment variable.
>>      >>
>>      >>
>>      >> I honestly don't see the need for a standardized variable.  I've
>> told you
>>      >> how to detect that you are running --as-cran; if that isn't
>> sufficient
>>      >> information, then you, the package author, need to set up
>> something more
>>      >> elaborate, and assume that if it's not set up, then someone else
>> (maybe
>>      >> CRAN) is running the test.
>>
>>      > So maybe documenting that (_R_CHECK_TIMINGS_) more formally in
>> R-exts
>>      > would be sufficient?
>>
>>      > -Deepayan
>>
>> yes and no.
>> As Duncan said very early,  --as-cran is just turning on several
>> already existing options, one of them being the
>> _R_CHECK_TIMINGS_  -- which you can *also* enable by  --timings.
>>
>> So, checking for  _R_CHECK_TIMINGS_ is *not* checking for
>> the presence of  --as-cran !
>> .. in the sense that it is necessary but not sufficient.
>> Also, if I run the "long checks" I may still want to use
>>   --timings. For me as package developer, the timings may be even more
>> important in the "long" than in the "short" checks case.
>>
>> So, one solution that is little work would be that  --as-cran
>> sets an *extra* environment variable that is *only* set by
>> --as-cran, but by no other command line switch.
>>
>> Still a pity that it seems people want to live in a  0/1
>> setting when it would be very natural to adopt a  0/1/2/3
>> (or so) one.
>> It's a bit like prefering  verbose = FALSE/TRUE  as argument to
>> an R function where eventually I often found that using a
>> tracing = 0/1/2  (or then  'verbose' = 0/1/2  which is almost
>> back compatible to FALSE/TRUE)
>> was more useful.
>>
>>
>>
>>      >> I asked the CRAN powers-that-be about the possibility of querying
>> the amount
>>      >> of time remaining before a timeout; since the different platforms
>> all use
>>      >> different mechanisms to enforce a timeout, that's not really
>> practical.  So
>>      >> the best you could hope for is to know that a timeout is in
>> effect.  Before
>>      >> I wrote any code, I'd need to hear why --as-cran detection isn't
>> sufficient.
>>
>> I agree that *reliable*  --as-cran  detection  solves the OP's
>> and most other correspondents problem.
>> But as argued above,  _R_CHECK_TIMINGS_  is not sufficient.
>>
>> Martin
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Thu Sep  6 13:41:06 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 06 Sep 2012 07:41:06 -0400
Subject: [Rd] if(--as-cran)?
In-Reply-To: <CAC2h7uvFWmjUfA0yxMNXtGwR4rZGdXZW_reBvP9n74=vOgwH0g@mail.gmail.com>
References: <50465D7F.5060004@gmail.com>
	<0CAEE2B1235DF643B0F5E1EAE1487B530946D655@023-CH1MPN1-043.023d.mgd.msft.net>
	<20550.28445.956167.112449@max.nulle.part>
	<504671FC.9030800@gmail.com>
	<20550.30155.399375.438614@max.nulle.part>
	<50467A5E.2080106@gmail.com>
	<CAC2h7usPuepziN4ngNg2F_9jOPPF_doTJR7bnfFbpX_0gowHtw@mail.gmail.com>
	<5046ED0B.4060506@gmail.com>
	<CADfFDC55XL5P8ytALSeCT5QK5DCXfbfo7z7AmJRaOZiU_-R3EQ@mail.gmail.com>
	<20551.10411.168210.290864@stat.math.ethz.ch>
	<50474F2E.9000600@gmail.com>
	<CAC2h7uvFWmjUfA0yxMNXtGwR4rZGdXZW_reBvP9n74=vOgwH0g@mail.gmail.com>
Message-ID: <50488BD2.2090200@gmail.com>

On 12-09-05 9:51 PM, Kasper Daniel Hansen wrote:
> Duncan,
>
> you are right that from the perspective of a single developer: it is
> entirely possible to make tests conditional and ensure that 'long'
> tests does not get run by CRAN.
>
> What I, and several others, advocate is a uniform set of conventions,
> so we avoid having multiple package specific solutions.
>
> Martin has explained one reason for why using _R_CHECK_TIMINGS_ is not
> ideal (the fact that we - at least I and Martin - are most interested
> in the timings for the long tests).

You do realize that his objections were wrong, don't you?


  Another reason is that I (and I
> suspect most others) would prefer something that looks a bit more
> official and supported.

The _R_CHECK_TIMINGS_ environment variable is documented and official.


  High-jacking an environment variable set for
> (what appears to be) a different reason does not seem like something
> that could be considered supported long-term, and which have a uniform
> interface (across packages).

Using it to detect reports about long-running examples is exactly what 
it is designed for.  It is not "high-jacking".

>
> Of course, adding an extra environment variable or an extra function
> (as suggested by Henrik) is additional work, and I know it is easy for
> us to suggest things.  My perspective is that I would like something
> that will continue to be supported in the future, and where I can use
> the same interface across the packages I maintain and others outside
> my control that I occasionally test.  Testing is not just being done
> by the package author(s) or CRAN.   I suspect many packages already
> have half-baked solutions to the 'long' test vs 'short' test issue,
> and I don't think we will see any movement toward a unified interface
> without support in base R.

If Martin or I added a new environment variable _R_CHECK_LEVEL_, and 
perhaps support code to let you set it in R CMD check or elsewhere, and 
support functions to let you read it without the work of calling 
Sys.getenv(), and documentation for its purpose -- that doesn't mean it 
would be ever be used.  I would have no objection whatsoever if he wants 
to do that work, but I won't, as I think everyone who would ever use it 
has already invented their own method for doing the same thing.  It 
would waste my time to implement it and would waste their time making 
their code compatible with the new system.

> And let me end by saying that I do agree with Martin: having numerical
> levels is better (together with a clear statement what --as-cran sets
> the level to).  But I would rather have a binary state than nothing.

It was pointed out to me by a member of CRAN that detecting --as-cran is 
insufficient.  CRAN only runs incoming tests with settings equivalent to 
that.  The daily tests use different options.  I don't know what those 
are, and CRAN is unwilling to discuss their internal policies on this 
list.  (I would guess they find the tantrums and false claims here to be 
frustrating.  I do.)

So if Martin wants to implement something, I'd suggest that he 
coordinate offline with CRAN.

Duncan Murdoch

>
> Kasper
>
>
> On Wed, Sep 5, 2012 at 9:10 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> This post contains two incorrect statements.  Since Martin is too busy to
>> post a retraction, I will point them out:
>>
>>   --timings and --as-cran do not set _R_CHECK_TIMINGS_ in the same way.
>>
>> As far as I recall, nobody has suggested that package writers be limited to
>> two choices for test suites.  I certainly haven't.
>>
>> Duncan Murdoch
>>
>>
>> On 05/09/2012 6:25 AM, Martin Maechler wrote:
>>>
>>>>>>>> Deepayan Sarkar <deepayan.sarkar at gmail.com>
>>>>>>>>      on Wed, 5 Sep 2012 11:49:37 +0530 writes:
>>>
>>>       > On Wed, Sep 5, 2012 at 11:41 AM, Duncan Murdoch
>>>       > <murdoch.duncan at gmail.com> wrote:
>>>       >> On 12-09-04 8:19 PM, Kasper Daniel Hansen wrote:
>>>       >>>
>>>       >>> On Tue, Sep 4, 2012 at 6:02 PM, Duncan Murdoch
>>> <murdoch.duncan at gmail.com>
>>>       >>> wrote:
>>>       >>>>
>>>       >>>> On 04/09/2012 5:42 PM, Dirk Eddelbuettel wrote:
>>>       >>>>>
>>>       >>>>>
>>>       >>>>> On 4 September 2012 at 17:26, Duncan Murdoch wrote:
>>>       >>>>> | On 04/09/2012 5:14 PM, Dirk Eddelbuettel wrote:
>>>       >>>>> | > An add-on argument to the already established option
>>> --as-cran may
>>>       >>>>> be
>>>       >>>>> the
>>>       >>>>> | > best.
>>>       >>>>> | >
>>>       >>>>> | > And to iterate, what bugs me is that for _me_ on _my_
>>> machine
>>>       >>>>> developing _my_
>>>       >>>>> | > package I have remember how to enable what is now (as per
>>> CRAN's
>>>       >>>>> decree)
>>>       >>>>> | > "non-standard behaviour" of full testing.  I fully agree
>>> with what
>>>       >>>>> Terry had
>>>       >>>>> | > said: more tests are better (when we develop).  I want the
>>> full
>>>       >>>>> suite
>>>       >>>>> at my
>>>       >>>>> | > end; that is after all why we wrote it!
>>>       >>>>> |
>>>       >>>>> | You don't have to remember that, you need to figure it out
>>> once, write
>>>       >>>>> a
>>>       >>>>> | script that sets the environment variables that enable it,
>>> and then
>>>       >>>>> you
>>>       >>>>> | can forget it.
>>>       >>>>>
>>>       >>>>> "In theory, theory and practice are the same. In practice, they
>>> are
>>>       >>>>> not."
>>>       >>>>>
>>>       >>>>> The main test script long had exactly such a setting; I wrote
>>> what I
>>>       >>>>> wrote
>>>       >>>>> because it is _still the wrong way around_ and as I happen to
>>> have added
>>>       >>>>> to
>>>       >>>>> unit tests this weekend _having suffered through precisely this
>>>       >>>>> setting_.
>>>       >>>>>
>>>       >>>>> But we are on different wavelengths here and I evidently do not
>>> get my
>>>       >>>>> point
>>>       >>>>> across to you.  And as you are the one who could make a change
>>> where it
>>>       >>>>> matters, I have no choice but to rest my case in frustration.
>>>       >>>>
>>>       >>>>
>>>       >>>>
>>>       >>>> If you want to give up, then give up, but then don't complain
>>> about the
>>>       >>>> current behaviour.  If you want to fix it, then continue the
>>> discussion.
>>>       >>>>
>>>       >>>> You're right that we're on different wavelengths.  If you want
>>> some tests
>>>       >>>> to
>>>       >>>> run at home but not on CRAN, then somewhere there has to be a
>>>       >>>> conditional.
>>>       >>>> I'm suggesting that the conditional should be "if there's a
>>> tight time
>>>       >>>> limit, skip this".
>>>       >>>>
>>>       >>>> I don't remember if this was your suggestion, but someone has
>>> suggested
>>>       >>>> "if
>>>       >>>> we're running with the --as-cran option, skip this" and others
>>> have
>>>       >>>> suggested "if we're running on CRAN, skip this".   I don't see
>>> why you
>>>       >>>> find
>>>       >>>> my suggestion so objectionable.  If you want, I'll repeat why I
>>> find the
>>>       >>>> other two suggestions objectionable.
>>>       >>>
>>>       >>>
>>>       >>> I agree with Duncan that having an option long/short makes more
>>> sense
>>>       >>> than with/without cran, as long as cran sets that option to be
>>> short.
>>>       >>
>>>       >>>
>>>       >>>
>>>       >>> I would also prefer a command line switch to R CMD check to an
>>>       >>> environment variable, but I'll be very happy with a standardized
>>>       >>> environment variable.
>>>       >>
>>>       >>
>>>       >> I honestly don't see the need for a standardized variable.  I've
>>> told you
>>>       >> how to detect that you are running --as-cran; if that isn't
>>> sufficient
>>>       >> information, then you, the package author, need to set up
>>> something more
>>>       >> elaborate, and assume that if it's not set up, then someone else
>>> (maybe
>>>       >> CRAN) is running the test.
>>>
>>>       > So maybe documenting that (_R_CHECK_TIMINGS_) more formally in
>>> R-exts
>>>       > would be sufficient?
>>>
>>>       > -Deepayan
>>>
>>> yes and no.
>>> As Duncan said very early,  --as-cran is just turning on several
>>> already existing options, one of them being the
>>> _R_CHECK_TIMINGS_  -- which you can *also* enable by  --timings.
>>>
>>> So, checking for  _R_CHECK_TIMINGS_ is *not* checking for
>>> the presence of  --as-cran !
>>> .. in the sense that it is necessary but not sufficient.
>>> Also, if I run the "long checks" I may still want to use
>>>    --timings. For me as package developer, the timings may be even more
>>> important in the "long" than in the "short" checks case.
>>>
>>> So, one solution that is little work would be that  --as-cran
>>> sets an *extra* environment variable that is *only* set by
>>> --as-cran, but by no other command line switch.
>>>
>>> Still a pity that it seems people want to live in a  0/1
>>> setting when it would be very natural to adopt a  0/1/2/3
>>> (or so) one.
>>> It's a bit like prefering  verbose = FALSE/TRUE  as argument to
>>> an R function where eventually I often found that using a
>>> tracing = 0/1/2  (or then  'verbose' = 0/1/2  which is almost
>>> back compatible to FALSE/TRUE)
>>> was more useful.
>>>
>>>
>>>
>>>       >> I asked the CRAN powers-that-be about the possibility of querying
>>> the amount
>>>       >> of time remaining before a timeout; since the different platforms
>>> all use
>>>       >> different mechanisms to enforce a timeout, that's not really
>>> practical.  So
>>>       >> the best you could hope for is to know that a timeout is in
>>> effect.  Before
>>>       >> I wrote any code, I'd need to hear why --as-cran detection isn't
>>> sufficient.
>>>
>>> I agree that *reliable*  --as-cran  detection  solves the OP's
>>> and most other correspondents problem.
>>> But as argued above,  _R_CHECK_TIMINGS_  is not sufficient.
>>>
>>> Martin
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From hadley at rice.edu  Thu Sep  6 15:25:52 2012
From: hadley at rice.edu (Hadley Wickham)
Date: Thu, 6 Sep 2012 08:25:52 -0500
Subject: [Rd] if(--as-cran)?
In-Reply-To: <50488BD2.2090200@gmail.com>
References: <50465D7F.5060004@gmail.com>
	<0CAEE2B1235DF643B0F5E1EAE1487B530946D655@023-CH1MPN1-043.023d.mgd.msft.net>
	<20550.28445.956167.112449@max.nulle.part> <504671FC.9030800@gmail.com>
	<20550.30155.399375.438614@max.nulle.part> <50467A5E.2080106@gmail.com>
	<CAC2h7usPuepziN4ngNg2F_9jOPPF_doTJR7bnfFbpX_0gowHtw@mail.gmail.com>
	<5046ED0B.4060506@gmail.com>
	<CADfFDC55XL5P8ytALSeCT5QK5DCXfbfo7z7AmJRaOZiU_-R3EQ@mail.gmail.com>
	<20551.10411.168210.290864@stat.math.ethz.ch>
	<50474F2E.9000600@gmail.com>
	<CAC2h7uvFWmjUfA0yxMNXtGwR4rZGdXZW_reBvP9n74=vOgwH0g@mail.gmail.com>
	<50488BD2.2090200@gmail.com>
Message-ID: <CABdHhvH2DtQWau0ebepCy0NhYh8MmufcPOA7pwVgkfcnw7ZNHg@mail.gmail.com>

> It was pointed out to me by a member of CRAN that detecting --as-cran is
> insufficient.  CRAN only runs incoming tests with settings equivalent to
> that.  The daily tests use different options.  I don't know what those are,
> and CRAN is unwilling to discuss their internal policies on this list.  (I
> would guess they find the tantrums and false claims here to be frustrating.
> I do.)

It's equally frustrating to not know how CRAN works. I feel like we
share common goals (making quality software) but somehow there is a
communication gap that has lead to an overly combative stance between
package authors and CRAN. I appreciate that the CRAN maintainers are
busy, but I would hope that communicating exactly what's going on
publicly would save time by avoiding individual conversations with
package authors.

Hadley

-- 
Assistant Professor
Department of Statistics / Rice University
http://had.co.nz/


From gregory.warnes at novartis.com  Thu Sep  6 15:33:54 2012
From: gregory.warnes at novartis.com (Warnes, Gregory)
Date: Thu, 6 Sep 2012 13:33:54 +0000
Subject: [Rd] if(--as-cran)?
In-Reply-To: <50488BD2.2090200@gmail.com>
Message-ID: <0CAEE2B1235DF643B0F5E1EAE1487B53094715C0@023-CH1MPN1-043.023d.mgd.msft.net>


On 9/6/12 7:41 AM, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:

>
>If Martin or I added a new environment variable _R_CHECK_LEVEL_, and
>perhaps support code to let you set it in R CMD check or elsewhere, and
>support functions to let you read it without the work of calling
>Sys.getenv(), and documentation for its purpose -- that doesn't mean it
>would be ever be used.  I would have no objection whatsoever if he wants
>to do that work, [..]
>[...]
>So if Martin wants to implement something, I'd suggest that he
>coordinate offline with CRAN.

With this in mind, I've taken the time to create a proposed implementation:

1) New environement variable _R_CHECK_LEVEL_ which can take values from
{NONE, MINOR, CRAN, DEFAULT, MAJOR, FULL}
2) New R CMD CHECK flag --level={NONE, MINOR, CRAN, DEFAULT, MAJOR, FULL},
which sets  the value of _R_CHECK_LEVEL_, defaulting to "DEFAULT".

3) R CMD CHECK flag --as-cran sets _R_CHECK_LEVEL_ to CRAN (overwriting
any previous environment variable or --level setting)
4) A new function: tools::getCheckLevel() that returns an ordered factor
with levels {NONE, MINOR, CRAN, DEFAULT, MAJOR, FULL}.
5) An associated man page, with the example:

	if(getCheckLevel() > "CRAN") {
	    cat("## Do time-intenstive test ##\n")
	} else {
	    cat("## Do brief test\n")
	}

Duncan, how should I coordinate this with CRAN, simply drop an email to
cran at r-project.org?

Everyone: I'll post a pointer to the patch as soon as I've tested it.

-Greg
     


From timhesterberg at gmail.com  Fri Sep  7 17:05:51 2012
From: timhesterberg at gmail.com (Tim Hesterberg)
Date: Fri, 7 Sep 2012 08:05:51 -0700
Subject: [Rd] Need to tell R CMD check that a function qr.R is not a method
Message-ID: <CAAWNEwbx+hp3xJn9Sbb_cPkX3rCc1tZb7ku8AgewbXtDyDg-yg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120907/6a842ce7/attachment.pl>

From timhesterberg at gmail.com  Fri Sep  7 17:16:25 2012
From: timhesterberg at gmail.com (Tim Hesterberg)
Date: Fri, 7 Sep 2012 08:16:25 -0700
Subject: [Rd] Suggest adding a 'pivot' argument to qr.R
Message-ID: <CAAWNEwaZoBbM+V2eiLtWADX+7SEBZ1seX3iE0AeHGkdZMK4sJQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120907/477f479e/attachment.pl>

From ligges at statistik.tu-dortmund.de  Fri Sep  7 18:55:10 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 07 Sep 2012 18:55:10 +0200
Subject: [Rd] Need to tell R CMD check that a function qr.R is not a
	method
In-Reply-To: <CAAWNEwbx+hp3xJn9Sbb_cPkX3rCc1tZb7ku8AgewbXtDyDg-yg@mail.gmail.com>
References: <CAAWNEwbx+hp3xJn9Sbb_cPkX3rCc1tZb7ku8AgewbXtDyDg-yg@mail.gmail.com>
Message-ID: <504A26EE.3000702@statistik.tu-dortmund.de>



On 07.09.2012 17:05, Tim Hesterberg wrote:
> When creating a package, I would like a way to tell R that
> a function with a period in its name is not a method.

You can't. There are few exception for historic names (S definitions) 
hardcoded in R.

Best,
Uwe



>
> I'm writing a package now with a modified version of qr.R.
> R CMD check gives warnings:
>
> * checking S3 generic/method consistency ... WARNING
> qr:
>    function(x, ...)
> qr.R:
>    function(qr, complete, pivot)
>
> See section ?Generic functions and methods? of the ?Writing R
> Extensions? manual.
>
> * checking Rd \usage sections ... NOTE
> S3 methods shown with full name in documentation object 'QR.Auxiliaries':
>    ?qr.R?
>
> The \usage entries for S3 methods should use the \method markup and
> not their full name.
> See the chapter ?Writing R documentation files? in the ?Writing R
> Extensions? manual.
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From gregory.warnes at novartis.com  Fri Sep  7 18:59:43 2012
From: gregory.warnes at novartis.com (Warnes, Gregory)
Date: Fri, 7 Sep 2012 16:59:43 +0000
Subject: [Rd] Need to tell R CMD check that a function qr.R is not a
 method
In-Reply-To: <504A26EE.3000702@statistik.tu-dortmund.de>
Message-ID: <0CAEE2B1235DF643B0F5E1EAE1487B5309472AFD@023-CH1MPN1-043.023d.mgd.msft.net>


On 9/7/12 12:55 PM, "Uwe Ligges" <ligges at statistik.tu-dortmund.de> wrote:

>On 07.09.2012 17:05, Tim Hesterberg wrote:
>> When creating a package, I would like a way to tell R that
>> a function with a period in its name is not a method.
>
>You can't. There are few exception for historic names (S definitions)
>hardcoded in R.
>

Would it be possible to add a \notmethod{} decorator to allow package
maintainers to avoid these messages?


-Greg


From hb at biostat.ucsf.edu  Fri Sep  7 19:18:56 2012
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Fri, 7 Sep 2012 10:18:56 -0700
Subject: [Rd] Need to tell R CMD check that a function qr.R is not a
	method
In-Reply-To: <504A26EE.3000702@statistik.tu-dortmund.de>
References: <CAAWNEwbx+hp3xJn9Sbb_cPkX3rCc1tZb7ku8AgewbXtDyDg-yg@mail.gmail.com>
	<504A26EE.3000702@statistik.tu-dortmund.de>
Message-ID: <CAFDcVCTvQCvgxTCZ1AiWSOQj9X6uA6ZXjBAF__Owwiw7GXnYvg@mail.gmail.com>

Would a workaround (for pleasing R CMD check) be to do:

qr.R <- function(...) UseMethod("qr.R", ...)

qr.R.qr <- function(qr, complete, pivot) {
  # No need to assert the class of 'qr' here.
  ...
}

Haven't tried it.  Method dispatching may also add unnecessary
overhead if called lots of times.

/Henrik


On Fri, Sep 7, 2012 at 9:55 AM, Uwe Ligges
<ligges at statistik.tu-dortmund.de> wrote:
>
>
> On 07.09.2012 17:05, Tim Hesterberg wrote:
>>
>> When creating a package, I would like a way to tell R that
>> a function with a period in its name is not a method.
>
>
> You can't. There are few exception for historic names (S definitions)
> hardcoded in R.
>
> Best,
> Uwe
>
>
>
>>
>> I'm writing a package now with a modified version of qr.R.
>> R CMD check gives warnings:
>>
>> * checking S3 generic/method consistency ... WARNING
>> qr:
>>    function(x, ...)
>> qr.R:
>>    function(qr, complete, pivot)
>>
>> See section ?Generic functions and methods? of the ?Writing R
>> Extensions? manual.
>>
>> * checking Rd \usage sections ... NOTE
>> S3 methods shown with full name in documentation object 'QR.Auxiliaries':
>>    ?qr.R?
>>
>> The \usage entries for S3 methods should use the \method markup and
>> not their full name.
>> See the chapter ?Writing R documentation files? in the ?Writing R
>> Extensions? manual.
>>
>>         [[alternative HTML version deleted]]
>>
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From simon.urbanek at r-project.org  Fri Sep  7 20:00:10 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 7 Sep 2012 14:00:10 -0400
Subject: [Rd] Need to tell R CMD check that a function qr.R is not a
	method
In-Reply-To: <0CAEE2B1235DF643B0F5E1EAE1487B5309472AFD@023-CH1MPN1-043.023d.mgd.msft.net>
References: <0CAEE2B1235DF643B0F5E1EAE1487B5309472AFD@023-CH1MPN1-043.023d.mgd.msft.net>
Message-ID: <12FFEEBD-0124-49ED-82DB-8E8C8B241D14@r-project.org>

On Sep 7, 2012, at 12:59 PM, "Warnes, Gregory" <gregory.warnes at novartis.com> wrote:

> 
> On 9/7/12 12:55 PM, "Uwe Ligges" <ligges at statistik.tu-dortmund.de> wrote:
> 
>> On 07.09.2012 17:05, Tim Hesterberg wrote:
>>> When creating a package, I would like a way to tell R that
>>> a function with a period in its name is not a method.
>> 
>> You can't. There are few exception for historic names (S definitions)
>> hardcoded in R.
>> 
> 
> Would it be possible to add a \notmethod{} decorator to allow package maintainers to avoid these messages?
> 

I would strongly support any solution since it has bitten me as well...


From murdoch.duncan at gmail.com  Fri Sep  7 20:14:01 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 07 Sep 2012 14:14:01 -0400
Subject: [Rd] Need to tell R CMD check that a function qr.R is not a
	method
In-Reply-To: <12FFEEBD-0124-49ED-82DB-8E8C8B241D14@r-project.org>
References: <0CAEE2B1235DF643B0F5E1EAE1487B5309472AFD@023-CH1MPN1-043.023d.mgd.msft.net>
	<12FFEEBD-0124-49ED-82DB-8E8C8B241D14@r-project.org>
Message-ID: <504A3969.4050607@gmail.com>

On 07/09/2012 2:00 PM, Simon Urbanek wrote:
> On Sep 7, 2012, at 12:59 PM, "Warnes, Gregory" <gregory.warnes at novartis.com> wrote:
>
> >
> > On 9/7/12 12:55 PM, "Uwe Ligges" <ligges at statistik.tu-dortmund.de> wrote:
> >
> >> On 07.09.2012 17:05, Tim Hesterberg wrote:
> >>> When creating a package, I would like a way to tell R that
> >>> a function with a period in its name is not a method.
> >>
> >> You can't. There are few exception for historic names (S definitions)
> >> hardcoded in R.
> >>
> >
> > Would it be possible to add a \notmethod{} decorator to allow package maintainers to avoid these messages?
> >
>
> I would strongly support any solution since it has bitten me as well...

An alternative would be to say that if it's not declared to be a method 
in the NAMESPACE file, it's not one.  I think that would actually be 
more work though, since it would probably break a lot of packages...

Duncan Murdoch


From simon.urbanek at r-project.org  Fri Sep  7 20:30:20 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 7 Sep 2012 14:30:20 -0400
Subject: [Rd] Need to tell R CMD check that a function qr.R is not a
	method
In-Reply-To: <504A3969.4050607@gmail.com>
References: <0CAEE2B1235DF643B0F5E1EAE1487B5309472AFD@023-CH1MPN1-043.023d.mgd.msft.net>
	<12FFEEBD-0124-49ED-82DB-8E8C8B241D14@r-project.org>
	<504A3969.4050607@gmail.com>
Message-ID: <01DDD529-8C55-49C0-A761-0AC06F57380A@r-project.org>

On Sep 7, 2012, at 2:14 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 07/09/2012 2:00 PM, Simon Urbanek wrote:
>> On Sep 7, 2012, at 12:59 PM, "Warnes, Gregory" <gregory.warnes at novartis.com> wrote:
>> 
>> >
>> > On 9/7/12 12:55 PM, "Uwe Ligges" <ligges at statistik.tu-dortmund.de> wrote:
>> >
>> >> On 07.09.2012 17:05, Tim Hesterberg wrote:
>> >>> When creating a package, I would like a way to tell R that
>> >>> a function with a period in its name is not a method.
>> >>
>> >> You can't. There are few exception for historic names (S definitions)
>> >> hardcoded in R.
>> >>
>> >
>> > Would it be possible to add a \notmethod{} decorator to allow package maintainers to avoid these messages?
>> >
>> 
>> I would strongly support any solution since it has bitten me as well...
> 
> An alternative would be to say that if it's not declared to be a method in the NAMESPACE file, it's not one.

Yes, that's what I was expecting in the first place ...

(BTW: \function{} may be more natural than \notmethod{})


>  I think that would actually be more work though, since it would probably break a lot of packages...
> 

I wonder - those would already get a warning that they don't declare S3 methods properly so it may not be as surprising. Moreover it won't actually break anything at this point, just silence some warnings (unless we get to distinguish S3 methods from functions in S3 dispatch, but I last time I was told we are not anywhere close to a solution on that one ...).


From pdalgd at gmail.com  Fri Sep  7 20:42:31 2012
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 7 Sep 2012 20:42:31 +0200
Subject: [Rd] Suggest adding a 'pivot' argument to qr.R
In-Reply-To: <CAAWNEwaZoBbM+V2eiLtWADX+7SEBZ1seX3iE0AeHGkdZMK4sJQ@mail.gmail.com>
References: <CAAWNEwaZoBbM+V2eiLtWADX+7SEBZ1seX3iE0AeHGkdZMK4sJQ@mail.gmail.com>
Message-ID: <92D135CB-9634-4BAD-A8B8-F21A0A38B5C3@gmail.com>


On Sep 7, 2012, at 17:16 , Tim Hesterberg wrote:

> I suggest adding a 'pivot' argument to qr.R, to obtain columns in the
> same order as the original x, so that
>  a <- qr(x)
>  qr.Q(a) %*% qr.R(a, pivot=TRUE)
> returns x.

That would come spiraling down in flames the first time someone tried to use backsolve on it, wouldn't it? I mean, a major point of QR is that R is triangular; doesn't make much sense to permute the columns without retaining the pivoting permutation. 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From whuber at embl.de  Sun Sep  9 11:17:18 2012
From: whuber at embl.de (Wolfgang Huber)
Date: Sun, 09 Sep 2012 11:17:18 +0200
Subject: [Rd] Arrays Partial unserialization
In-Reply-To: <CADwqtCN-w_BGErdHPLwoU0sumH=ejXFCg0u8a8WCsJP21Cyhow@mail.gmail.com>
References: <5040C084.1070305@gmail.com>
	<CADwqtCN-w_BGErdHPLwoU0sumH=ejXFCg0u8a8WCsJP21Cyhow@mail.gmail.com>
Message-ID: <504C5E9E.9030401@embl.de>


Yet another option is provided by the 'rhdf5' package on Bioconductor, 
which interfaces to HDF5, a cross-platform infrastructure for exactly 
this purpose: http://www.hdfgroup.org/HDF5/whatishdf5.html

	Best wishes
	Wolfgang

Aug/31/12 4:44 PM, Gabriel Becker scripsit:
> I'm not an expert in its use, but I believe the bigmemory package offers
> the functionality you are looking for (or at least similar functionality
> that can be co-opted for your use-case). See the sub.big.matrix function.
> Depending on what you mean by "huge" it may offer other benefits as well.
>
> HTH,
> ~G
>
> On Fri, Aug 31, 2012 at 6:47 AM, Damien Georges
> <damien.georges2 at gmail.com>wrote:
>
>> Hi all,
>>
>> I'm working with some huge array in R and I need to load several ones to
>> apply some functions that requires to have all my arrays values for each
>> cell...
>>
>> To make it possible, I would like to load only a part (for example 100
>> cells) of all my arrays, apply my function, delete all cells loaded, loaded
>> following cells and so on.
>>
>> Is it possible to unserialize (or load) only a defined part of an R array ?
>> Do you know some tools that might help me?
>>
>> Finally, I did lot of research to find the way array (and all other R
>> object) are serialized into binary object, but I found nothing explaining
>> really algorithms involved. If someone has some information on this topic,
>> I'm interesting in.
>>
>> Hoping my request is understandable,
>>
>> All the best,
>>
>> Damien.G
>>
>> ______________________________**________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/**listinfo/r-devel<https://stat.ethz.ch/mailman/listinfo/r-devel>
>>
>
>
>


-- 
Best wishes
	Wolfgang

Wolfgang Huber
EMBL
http://www.embl.de/research/units/genome_biology/huber


From kevin.r.coombes at gmail.com  Mon Sep 10 20:15:16 2012
From: kevin.r.coombes at gmail.com (Kevin R. Coombes)
Date: Mon, 10 Sep 2012 13:15:16 -0500
Subject: [Rd] problem building vignette
Message-ID: <504E2E34.3080605@gmail.com>

Hi,

I'm trying to get a package to pass through "R CMD check --as-cran" and 
have run into a problem that gives me no idea where to look to fix it. 
I'm running R version 15.1 on a Windows 7 64-bit machine, with the 
current set of Rtools.  An attempt to check the package dies at the 
following step:

* checking running R code from vignettes ...
    'SIBER.Rnw' ...Warning in file(con, "r") :
   cannot open file 'SIBER.Rnw.log': Permission denied
Error in file(con, "r") : cannot open the connection
Execution halted

The file "SIBER.Rnw.log" was successfully created.  All of the R code 
from the Sweave file was excuted; the last exceutable line was a call to 
sessionInfo().  The last lines of the log file are:

 > sessionInfo()
R version 2.15.1 (2012-06-22)
Platform: x86_64-pc-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=C
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] doSNOW_1.0.6    snow_0.3-9      iterators_1.0.6 foreach_1.4.0
[5] edgeR_2.6.12    limma_3.10.2    SIBER_0.9.2     mclust_3.4.11

loaded via a namespace (and not attached):
[1] codetools_0.2-8 compiler_2.15.1 tools_2.15.1

  *** Run successfully completed ***
 > proc.time()
    user  system elapsed
    1.12    0.14    2.57

We have about a dozen other packages that we maintain, and all of the 
others check, build, and install with no problems.

Does anyone have any idea why this file permission issue would crop up 
here? Or what I can do to fix it?

Thanks,
     Kevin


From murdoch.duncan at gmail.com  Mon Sep 10 20:24:56 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 10 Sep 2012 14:24:56 -0400
Subject: [Rd] problem building vignette
In-Reply-To: <504E2E34.3080605@gmail.com>
References: <504E2E34.3080605@gmail.com>
Message-ID: <504E3078.6040102@gmail.com>

On 10/09/2012 2:15 PM, Kevin R. Coombes wrote:
> Hi,
>
> I'm trying to get a package to pass through "R CMD check --as-cran" and
> have run into a problem that gives me no idea where to look to fix it.
> I'm running R version 15.1 on a Windows 7 64-bit machine, with the
> current set of Rtools.  An attempt to check the package dies at the
> following step:
>
> * checking running R code from vignettes ...
>      'SIBER.Rnw' ...Warning in file(con, "r") :
>     cannot open file 'SIBER.Rnw.log': Permission denied
> Error in file(con, "r") : cannot open the connection
> Execution halted
>
> The file "SIBER.Rnw.log" was successfully created.  All of the R code
> from the Sweave file was excuted; the last exceutable line was a call to
> sessionInfo().  The last lines of the log file are:
>
>   > sessionInfo()
> R version 2.15.1 (2012-06-22)
> Platform: x86_64-pc-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=C
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] doSNOW_1.0.6    snow_0.3-9      iterators_1.0.6 foreach_1.4.0
> [5] edgeR_2.6.12    limma_3.10.2    SIBER_0.9.2     mclust_3.4.11
>
> loaded via a namespace (and not attached):
> [1] codetools_0.2-8 compiler_2.15.1 tools_2.15.1
>
>    *** Run successfully completed ***
>   > proc.time()
>      user  system elapsed
>      1.12    0.14    2.57
>
> We have about a dozen other packages that we maintain, and all of the
> others check, build, and install with no problems.
>
> Does anyone have any idea why this file permission issue would crop up
> here? Or what I can do to fix it?

Windows machines sometimes have permission problems when a virus checker 
opens a file in an exclusive mode for checking.  If this applies to you, 
you may be able to configure the checks to ignore the directory you're 
working in, or temporarily disable it completely.  Or you could switch 
virus checkers to one that is less hostile to your work.

Duncan Murdoch


From kevin.r.coombes at gmail.com  Mon Sep 10 20:29:19 2012
From: kevin.r.coombes at gmail.com (Kevin R. Coombes)
Date: Mon, 10 Sep 2012 13:29:19 -0500
Subject: [Rd] problem building vignette
In-Reply-To: <504E3078.6040102@gmail.com>
References: <504E2E34.3080605@gmail.com> <504E3078.6040102@gmail.com>
Message-ID: <504E317F.1040308@gmail.com>

Why would the virus checker cause a problem with this package, and not 
any of the dozen other packaqes?

On 9/10/2012 1:24 PM, Duncan Murdoch wrote:
> On 10/09/2012 2:15 PM, Kevin R. Coombes wrote:
>> Hi,
>>
>> I'm trying to get a package to pass through "R CMD check --as-cran" and
>> have run into a problem that gives me no idea where to look to fix it.
>> I'm running R version 15.1 on a Windows 7 64-bit machine, with the
>> current set of Rtools.  An attempt to check the package dies at the
>> following step:
>>
>> * checking running R code from vignettes ...
>>      'SIBER.Rnw' ...Warning in file(con, "r") :
>>     cannot open file 'SIBER.Rnw.log': Permission denied
>> Error in file(con, "r") : cannot open the connection
>> Execution halted
>>
>> The file "SIBER.Rnw.log" was successfully created.  All of the R code
>> from the Sweave file was excuted; the last exceutable line was a call to
>> sessionInfo().  The last lines of the log file are:
>>
>> > sessionInfo()
>> R version 2.15.1 (2012-06-22)
>> Platform: x86_64-pc-mingw32/x64 (64-bit)
>>
>> locale:
>> [1] LC_COLLATE=C
>> [2] LC_CTYPE=English_United States.1252
>> [3] LC_MONETARY=English_United States.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] doSNOW_1.0.6    snow_0.3-9      iterators_1.0.6 foreach_1.4.0
>> [5] edgeR_2.6.12    limma_3.10.2    SIBER_0.9.2     mclust_3.4.11
>>
>> loaded via a namespace (and not attached):
>> [1] codetools_0.2-8 compiler_2.15.1 tools_2.15.1
>>
>>    *** Run successfully completed ***
>> > proc.time()
>>      user  system elapsed
>>      1.12    0.14    2.57
>>
>> We have about a dozen other packages that we maintain, and all of the
>> others check, build, and install with no problems.
>>
>> Does anyone have any idea why this file permission issue would crop up
>> here? Or what I can do to fix it?
>
> Windows machines sometimes have permission problems when a virus 
> checker opens a file in an exclusive mode for checking.  If this 
> applies to you, you may be able to configure the checks to ignore the 
> directory you're working in, or temporarily disable it completely.  Or 
> you could switch virus checkers to one that is less hostile to your work.
>
> Duncan Murdoch


From Jean-Michel.Perraud at csiro.au  Mon Sep 10 01:51:54 2012
From: Jean-Michel.Perraud at csiro.au (Jean-Michel.Perraud at csiro.au)
Date: Mon, 10 Sep 2012 09:51:54 +1000
Subject: [Rd] Different behavior of the "showArgs" example (R extension
 manual) between gcc and Visual C++ compiled code
Message-ID: <F3AAB43D90409041B7DED35E79F2CF651408119DD4@exvic-mbx05.nexus.csiro.au>

Hi,

I am trying to implement on a Win7 box the showArgs example of section 5.10.2 "Calling .External" of the R extension manual. I am using interchangeably gcc (RTools) and Visual C++ (via Makefile.win) to build a package. I get a couple of runtime oddities when the dll compiled with Visual C++. I'd value comments, observations and tips from interested readers. I tried my best to find proper compilation settings for VCPP, from a variety of source incl. Duncan Murdoch's advice.

Cheers,
J-M

OBSERVATIONS
============
1/ The for() loop does not hit the termination condition on args being R_NilValue, and ends up stuck on pointers as shown below, equality never reached.
		args	0x020e24a0	SEXPREC *
		R_NilValue	0x835425ff	SEXPREC *
2/ If I force it out of the endless loop, after the function returns, I get a nasty "Unhandled exception at 0x6c799419 in Rgui: 0xC0000005: Access violation writing location 0x0009eee9." with a call stack as follow. I did check that the cdecl calling convention is used.
	R.dll!6c799419() 	
 	[Frames below may be incorrect and/or missing, no symbols loaded for R.dll]	
 	R.dll!6c797736() 	
 	user32.dll!7633cd90() 	
 	user32.dll!7636c1c2() 	
 	Rgraphapp.dll!63551cba() 	

CODE
====
// R code
library(showArgs)
blah = as.Date('2000-01-01')
printArgs(a=1:3, b=LETTERS[1:3], blah=blah)
// END R code

// C/Cpp code:
extern "C" { // because I compile the code 'as C++' for Visual C++, for in-code variable declaration
	SEXP __cdecl showArgs_ext(SEXP args);
}

SEXP __cdecl showArgs_ext(SEXP args)
{
// snip
	args = CDR(args); /* skip 'name' */
	for(int i = 0; args != R_NilValue; i++, args = CDR(args)) {
		// verbatim from the manual
	}
	return R_NilValue;
}
// END C/Cpp code


Vcc Compilation settings:
/I"C:\bin\R\R\include" /ZI /nologo /W3 /WX- /Od /Oy- /D "_WINDLL" /D "_MBCS" /Gm /EHsc /RTC1 /GS /fp:precise /Za /Zc:wchar_t /Zc:forScope /Fp"Debug\showArgs.pch" /Fa"Debug\" /Fo"Debug\" /Fd"Debug\vc100.pdb" /Gd /TP /analyze- /errorReport:queue 

/OUT:"C:\XXXX\Debug\showArgs.dll" /NOLOGO /LIBPATH:"C:\bin\R\R\bin\i386" /DLL "Rdll.lib" "kernel32.lib" "user32.lib" "gdi32.lib" "winspool.lib" "comdlg32.lib" "advapi32.lib" "shell32.lib" "ole32.lib" "oleaut32.lib" "uuid.lib" "odbc32.lib" "odbccp32.lib" /DEF:"showArgs-win.def" /MANIFEST /ManifestFile:"Debug\showArgs.dll.intermediate.manifest" /ALLOWISOLATION /MANIFESTUAC:"level='asInvoker' uiAccess='false'" /DEBUG /PDB:"C:\XXXX\Debug\showArgs.pdb" /PGD:"C:\XXXX\Debug\showArgs.pgd" /TLBID:1 /DYNAMICBASE /NXCOMPAT /MACHINE:X86 /ERRORREPORT:QUEUE 


ENVIRONMENT
===========
- Windows 7 32 bits
- R version 2.15.0 (2012-03-30) Platform: i386-pc-mingw32/i386 (32-bit)
- RTools 2.15.0
- MS Visual Cpp 2010 (express edition)


From gunter.berton at gene.com  Mon Sep 10 18:11:28 2012
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 10 Sep 2012 09:11:28 -0700
Subject: [Rd] Advice on Namespaces
Message-ID: <CACk-te1iwmwtQC6MRh7WmTXbx1iL-d=9UF=wXGaXOGUDjtRS3Q@mail.gmail.com>

Hi Folks:

I'm writing a little package that may not ever hit CRAN or even be
distributed beyond a relatively narrow audience at my company.
Nevertheless, I have tried to adhere to practices that would work if
it were. With that in mind, I have read the Writing R Extensions
Manual (and my humble kudos to its writers, as it has  successfully
guided even an ignoramus like myself ) and Luke Tierney's R Newsletter
documentation on Namespaces. However, it is still not clear to me (see
above ignoramus comment!) what functions -- and especially which S3
methods whose generics I define in my package -- should be exported
and which should not. Perusing other packages also didn't reveal any
clear patterns from which I could infer best practice.

So may I ask for advice or any references that would provide such
guidelines. Feel free to keep replies private if this query in not
appropriate for this list. Many thanks.

Cheers,
Bert

-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From murdoch.duncan at gmail.com  Tue Sep 11 13:05:33 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 11 Sep 2012 07:05:33 -0400
Subject: [Rd] Advice on Namespaces
In-Reply-To: <CACk-te1iwmwtQC6MRh7WmTXbx1iL-d=9UF=wXGaXOGUDjtRS3Q@mail.gmail.com>
References: <CACk-te1iwmwtQC6MRh7WmTXbx1iL-d=9UF=wXGaXOGUDjtRS3Q@mail.gmail.com>
Message-ID: <504F1AFD.1010509@gmail.com>

On 12-09-10 12:11 PM, Bert Gunter wrote:
> Hi Folks:
>
> I'm writing a little package that may not ever hit CRAN or even be
> distributed beyond a relatively narrow audience at my company.
> Nevertheless, I have tried to adhere to practices that would work if
> it were. With that in mind, I have read the Writing R Extensions
> Manual (and my humble kudos to its writers, as it has  successfully
> guided even an ignoramus like myself ) and Luke Tierney's R Newsletter
> documentation on Namespaces. However, it is still not clear to me (see
> above ignoramus comment!) what functions -- and especially which S3
> methods whose generics I define in my package -- should be exported
> and which should not. Perusing other packages also didn't reveal any
> clear patterns from which I could infer best practice.
>
> So may I ask for advice or any references that would provide such
> guidelines. Feel free to keep replies private if this query in not
> appropriate for this list. Many thanks.

If you export it, then you need to document it, and it needs to be 
usable by others.

Often you'll have specialized functions in a package that do what you 
need, but they are too specialized to be useful to others:  don't export 
those.

Once you export a function, people (or maybe just yourself in some other 
package or script) will start using it, so you tend to get locked in to 
the interface.  So don't export functions unless you want to support 
them in their current form for the life of the package.

If you export a function with the same name as one exported from another 
package, it becomes inconvenient to use either function once both 
packages are attached.  (Which one you get depends on the order of 
attaching the packages.) So don't export trivial functions, and think 
carefully about the names you use for the ones you do export.

It is slightly less convenient to test or inspect functions if you don't 
export them (you need the package:::foo style to refer to them from the 
console).  So during early development, you may want to export more, and 
limit the exports when you are happy with the package.

Duncan Murdoch


From gregory.warnes at novartis.com  Tue Sep 11 16:02:15 2012
From: gregory.warnes at novartis.com (Warnes, Gregory)
Date: Tue, 11 Sep 2012 14:02:15 +0000
Subject: [Rd] Suggest adding a 'pivot' argument to qr.R
In-Reply-To: <92D135CB-9634-4BAD-A8B8-F21A0A38B5C3@gmail.com>
Message-ID: <0CAEE2B1235DF643B0F5E1EAE1487B53094747F7@023-CH1MPN1-043.023d.mgd.msft.net>


On 9/7/12 2:42 PM, "peter dalgaard" <pdalgd at gmail.com> wrote:

>
>On Sep 7, 2012, at 17:16 , Tim Hesterberg wrote:
>
>> I suggest adding a 'pivot' argument to qr.R, to obtain columns in the
>> same order as the original x, so that
>>  a <- qr(x)
>>  qr.Q(a) %*% qr.R(a, pivot=TRUE)
>> returns x.
>
>That would come spiraling down in flames the first time someone tried to
>use backsolve on it, wouldn't it? I mean, a major point of QR is that R
>is triangular; doesn't make much sense to permute the columns without
>retaining the pivoting permutation.

As I understand Tim's proposal, the pivot argument defaults to FALSE, so
the new behavior would only be activated at the user's request.

-Greg

-- 
Gregory Warnes, Ph.D.
Sr. Expert Modeler
Modeling and Simulation
CA Phone: +1 617 871-8498
gregory.warnes at novartis.com


From Basil.Abou-El-Komboz at stat.uni-muenchen.de  Tue Sep 11 16:53:45 2012
From: Basil.Abou-El-Komboz at stat.uni-muenchen.de (Basil Abou El-Komboz)
Date: Tue, 11 Sep 2012 16:53:45 +0200
Subject: [Rd] R crashes when printing a named numeric vector of a specific
	class - Bug?
Message-ID: <soutxv4r4p2.fsf@gmx.de>

Dear useR's,

today I stumbled over an interesting phenomenon: First, I created a
named numeric vector with a certain class and several attributes via the
structure() function. After that, I implemented a simple print method
for this class. When calling this function it produces an endless loop
of print calls until R crashes. :/

What is going on here? Is this a bug or have I done something completely
wrong? :)

Below is a minimal example which reproduces the behavior. Be careful
when calling foo() as this automatically calls print.bar() which causes
R to crash (at least on my PC, see further informations about my system below.)

Greetings,
Basil

--------------------------------------------------

Minimal example:

foo <- function () {
 x <- c("A" = 1.3, "B" = 0.7, "C" = -0.3)
 structure(x, class = "bar")
}

print.bar <- function (x, ...) {
  print(x, ...)
}

--------------------------------------------------

Further informations about my system:

> version
              _                            
platform       x86_64-unknown-linux-gnu     
arch           x86_64                       
os             linux-gnu                    
system         x86_64, linux-gnu            
status                                      
major          2                            
minor          15.1                         
year           2012                         
month          06                           
day            22                           
svn rev        59600                        
language       R                            
version.string R version 2.15.1 (2012-06-22)
nickname       Roasted Marshmallows         

> sessionInfo()

R version 2.15.1 (2012-06-22)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-8   
 [6] LC_MESSAGES=en_US.UTF-8    LC_PAPER=C                 LC_NAME=C                  LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] compiler_2.15.1 tools_2.15.1


From gunter.berton at gene.com  Tue Sep 11 14:22:36 2012
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 11 Sep 2012 05:22:36 -0700
Subject: [Rd] Advice on Namespaces
In-Reply-To: <504F1AFD.1010509@gmail.com>
References: <CACk-te1iwmwtQC6MRh7WmTXbx1iL-d=9UF=wXGaXOGUDjtRS3Q@mail.gmail.com>
	<504F1AFD.1010509@gmail.com>
Message-ID: <CACk-te0Y1xMdUSaMC+2LsMPpB=Wxf_HBXoYesKy3hLC+-iL8hg@mail.gmail.com>

Thanks Duncan. This was very helpful.

-- Bert

On Tue, Sep 11, 2012 at 4:05 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 12-09-10 12:11 PM, Bert Gunter wrote:
>>
>> Hi Folks:
>>
>> I'm writing a little package that may not ever hit CRAN or even be
>> distributed beyond a relatively narrow audience at my company.
>> Nevertheless, I have tried to adhere to practices that would work if
>> it were. With that in mind, I have read the Writing R Extensions
>> Manual (and my humble kudos to its writers, as it has  successfully
>> guided even an ignoramus like myself ) and Luke Tierney's R Newsletter
>> documentation on Namespaces. However, it is still not clear to me (see
>> above ignoramus comment!) what functions -- and especially which S3
>> methods whose generics I define in my package -- should be exported
>> and which should not. Perusing other packages also didn't reveal any
>> clear patterns from which I could infer best practice.
>>
>> So may I ask for advice or any references that would provide such
>> guidelines. Feel free to keep replies private if this query in not
>> appropriate for this list. Many thanks.
>
>
> If you export it, then you need to document it, and it needs to be usable by
> others.
>
> Often you'll have specialized functions in a package that do what you need,
> but they are too specialized to be useful to others:  don't export those.
>
> Once you export a function, people (or maybe just yourself in some other
> package or script) will start using it, so you tend to get locked in to the
> interface.  So don't export functions unless you want to support them in
> their current form for the life of the package.
>
> If you export a function with the same name as one exported from another
> package, it becomes inconvenient to use either function once both packages
> are attached.  (Which one you get depends on the order of attaching the
> packages.) So don't export trivial functions, and think carefully about the
> names you use for the ones you do export.
>
> It is slightly less convenient to test or inspect functions if you don't
> export them (you need the package:::foo style to refer to them from the
> console).  So during early development, you may want to export more, and
> limit the exports when you are happy with the package.
>
> Duncan Murdoch



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From jeff.a.ryan at gmail.com  Tue Sep 11 17:30:14 2012
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Tue, 11 Sep 2012 10:30:14 -0500
Subject: [Rd] R crashes when printing a named numeric vector of a
 specific class - Bug?
In-Reply-To: <soutxv4r4p2.fsf@gmx.de>
References: <soutxv4r4p2.fsf@gmx.de>
Message-ID: <CABDUZc-uUV8ea7YvPQ2Xtj95x8Dfc0c5nLvXDBPdzvQw+ojFuA@mail.gmail.com>

print(x) in print.bar is calling print.bar again.

You need to do something like print(unclass(x))

HTH
Jeff

On Tue, Sep 11, 2012 at 9:53 AM, Basil Abou El-Komboz
<Basil.Abou-El-Komboz at stat.uni-muenchen.de> wrote:
> Dear useR's,
>
> today I stumbled over an interesting phenomenon: First, I created a
> named numeric vector with a certain class and several attributes via the
> structure() function. After that, I implemented a simple print method
> for this class. When calling this function it produces an endless loop
> of print calls until R crashes. :/
>
> What is going on here? Is this a bug or have I done something completely
> wrong? :)
>
> Below is a minimal example which reproduces the behavior. Be careful
> when calling foo() as this automatically calls print.bar() which causes
> R to crash (at least on my PC, see further informations about my system below.)
>
> Greetings,
> Basil
>
> --------------------------------------------------
>
> Minimal example:
>
> foo <- function () {
>  x <- c("A" = 1.3, "B" = 0.7, "C" = -0.3)
>  structure(x, class = "bar")
> }
>
> print.bar <- function (x, ...) {
>   print(x, ...)
> }
>
> --------------------------------------------------
>
> Further informations about my system:
>
>> version
>               _
> platform       x86_64-unknown-linux-gnu
> arch           x86_64
> os             linux-gnu
> system         x86_64, linux-gnu
> status
> major          2
> minor          15.1
> year           2012
> month          06
> day            22
> svn rev        59600
> language       R
> version.string R version 2.15.1 (2012-06-22)
> nickname       Roasted Marshmallows
>
>> sessionInfo()
>
> R version 2.15.1 (2012-06-22)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-8
>  [6] LC_MESSAGES=en_US.UTF-8    LC_PAPER=C                 LC_NAME=C                  LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_2.15.1 tools_2.15.1
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Jeffrey Ryan
jeffrey.ryan at lemnica.com

www.lemnica.com


From nalimilan at club.fr  Tue Sep 11 17:35:48 2012
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Tue, 11 Sep 2012 17:35:48 +0200
Subject: [Rd] R crashes when printing a named numeric vector of a
 specific class - Bug?
In-Reply-To: <soutxv4r4p2.fsf@gmx.de>
References: <soutxv4r4p2.fsf@gmx.de>
Message-ID: <1347377748.1805.41.camel@milan>

Le mardi 11 septembre 2012 ? 16:53 +0200, Basil Abou El-Komboz a ?crit :
> Dear useR's,
> 
> today I stumbled over an interesting phenomenon: First, I created a
> named numeric vector with a certain class and several attributes via the
> structure() function. After that, I implemented a simple print method
> for this class. When calling this function it produces an endless loop
> of print calls until R crashes. :/
> 
> What is going on here? Is this a bug or have I done something completely
> wrong? :)
> 
> Below is a minimal example which reproduces the behavior. Be careful
> when calling foo() as this automatically calls print.bar() which causes
> R to crash (at least on my PC, see further informations about my system below.)
> 
> Greetings,
> Basil
> 
> --------------------------------------------------
> 
> Minimal example:
> 
> foo <- function () {
>  x <- c("A" = 1.3, "B" = 0.7, "C" = -0.3)
>  structure(x, class = "bar")
> }
> 
> print.bar <- function (x, ...) {
>   print(x, ...)
> }
What is your code supposed to do exactly? ;-)

You're calling print() in your class' print.bar() function, so calling
print() on such an object will call print.bar(), which calls print(),
which calls print.bar()... In a few moments the recursion will have gone
so deep that some system limit about the stack size must be reached, and
R is killed.

If you just want to print the object as a vector, you do not need to
define any function. Or, at least, call print.default() instead of the
generic print().


My two cents

> --------------------------------------------------
> 
> Further informations about my system:
> 
> > version
>               _                            
> platform       x86_64-unknown-linux-gnu     
> arch           x86_64                       
> os             linux-gnu                    
> system         x86_64, linux-gnu            
> status                                      
> major          2                            
> minor          15.1                         
> year           2012                         
> month          06                           
> day            22                           
> svn rev        59600                        
> language       R                            
> version.string R version 2.15.1 (2012-06-22)
> nickname       Roasted Marshmallows         
> 
> > sessionInfo()
> 
> R version 2.15.1 (2012-06-22)
> Platform: x86_64-unknown-linux-gnu (64-bit)
> 
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-8   
>  [6] LC_MESSAGES=en_US.UTF-8    LC_PAPER=C                 LC_NAME=C                  LC_ADDRESS=C               LC_TELEPHONE=C            
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base     
> 
> loaded via a namespace (and not attached):
> [1] compiler_2.15.1 tools_2.15.1
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From michael.weylandt at gmail.com  Tue Sep 11 17:52:00 2012
From: michael.weylandt at gmail.com (R. Michael Weylandt)
Date: Tue, 11 Sep 2012 16:52:00 +0100
Subject: [Rd] R crashes when printing a named numeric vector of a
 specific class - Bug?
In-Reply-To: <1347377748.1805.41.camel@milan>
References: <soutxv4r4p2.fsf@gmx.de> <1347377748.1805.41.camel@milan>
Message-ID: <CAAmySGPZu8fR3+paPs=Hii_EL7UmUy6vMPN8DWQnUtKszx0d7Q@mail.gmail.com>

On Tue, Sep 11, 2012 at 4:35 PM, Milan Bouchet-Valat <nalimilan at club.fr> wrote:
> Le mardi 11 septembre 2012 ? 16:53 +0200, Basil Abou El-Komboz a ?crit :
>> Dear useR's,
>>
>> today I stumbled over an interesting phenomenon: First, I created a
>> named numeric vector with a certain class and several attributes via the
>> structure() function. After that, I implemented a simple print method
>> for this class. When calling this function it produces an endless loop
>> of print calls until R crashes. :/
>>
>> What is going on here? Is this a bug or have I done something completely
>> wrong? :)
>>
>> Below is a minimal example which reproduces the behavior. Be careful
>> when calling foo() as this automatically calls print.bar() which causes
>> R to crash (at least on my PC, see further informations about my system below.)
>>
>> Greetings,
>> Basil
>>
>> --------------------------------------------------
>>
>> Minimal example:
>>
>> foo <- function () {
>>  x <- c("A" = 1.3, "B" = 0.7, "C" = -0.3)
>>  structure(x, class = "bar")
>> }
>>
>> print.bar <- function (x, ...) {
>>   print(x, ...)
>> }
> What is your code supposed to do exactly? ;-)
>
> You're calling print() in your class' print.bar() function, so calling
> print() on such an object will call print.bar(), which calls print(),
> which calls print.bar()... In a few moments the recursion will have gone
> so deep that some system limit about the stack size must be reached, and
> R is killed.
>
> If you just want to print the object as a vector, you do not need to
> define any function. Or, at least, call print.default() instead of the
> generic print().
>
>
> My two cents
>

NextMethod() may also be of some help here, depending on the
inheritance you're envisioning.

Michael


From pdalgd at gmail.com  Tue Sep 11 18:03:53 2012
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 11 Sep 2012 18:03:53 +0200
Subject: [Rd] Suggest adding a 'pivot' argument to qr.R
In-Reply-To: <0CAEE2B1235DF643B0F5E1EAE1487B53094747F7@023-CH1MPN1-043.023d.mgd.msft.net>
References: <0CAEE2B1235DF643B0F5E1EAE1487B53094747F7@023-CH1MPN1-043.023d.mgd.msft.net>
Message-ID: <40D65328-9CBA-4E2D-AAEA-DAC0636A18F8@gmail.com>


On Sep 11, 2012, at 16:02 , Warnes, Gregory wrote:

> 
> On 9/7/12 2:42 PM, "peter dalgaard" <pdalgd at gmail.com> wrote:
> 
>> 
>> On Sep 7, 2012, at 17:16 , Tim Hesterberg wrote:
>> 
>>> I suggest adding a 'pivot' argument to qr.R, to obtain columns in the
>>> same order as the original x, so that
>>> a <- qr(x)
>>> qr.Q(a) %*% qr.R(a, pivot=TRUE)
>>> returns x.
>> 
>> That would come spiraling down in flames the first time someone tried to
>> use backsolve on it, wouldn't it? I mean, a major point of QR is that R
>> is triangular; doesn't make much sense to permute the columns without
>> retaining the pivoting permutation.
> 
> As I understand Tim's proposal, the pivot argument defaults to FALSE, so
> the new behavior would only be activated at the user's request.

Sure. I'm just saying that I see little use for the un-pivoted qr.R because, generically, the first thing you want to do with qr.R is to invert it, which is easier when it is triangular.

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From hb at biostat.ucsf.edu  Wed Sep 12 01:19:53 2012
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Tue, 11 Sep 2012 16:19:53 -0700
Subject: [Rd] Is invokeRestart("abort") unstoppable?
Message-ID: <CAFDcVCQCEUGuWcD2nqpzAxMwsao=QT=nkhzG5OZop5hostjsKw@mail.gmail.com>

Hi,

I'm trying to implement an abort() method that works just like stop()
but does not signal the condition such that try() and tryCatch(...,
condition=...) are, contrary to stop(), effectively non-working with
abort() calls.

In order to achieve this, I stumbled upon invokeRestart("abort"), cf.
help("invokeRestart", package="base") that reads "Restarts are used
for establishing recovery protocols. They can be established using
withRestarts. One pre-established restart is an abort restart that
represents a jump to top level.".

So, my current implementation is (roughly):

abort <- function(...) {
 # handling messages etc

 # Fully abort the R evaluation and return to the top level
 invokeRestart("abort")
}

I've tested it in various setups with and without tryCatch(...,
condition=...) and so on and it appears to work.  Does anyone know if
I'm overlooking something or can I count on  invokeRestart("abort") to
always stop any currently evaluated R code?

Also, does anyone know how far back (in R versions) invokeRestart("abort") goes?

Thxs,

Henrik


From hb at biostat.ucsf.edu  Wed Sep 12 01:57:55 2012
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Tue, 11 Sep 2012 16:57:55 -0700
Subject: [Rd] R crashes when printing a named numeric vector of a
 specific class - Bug?
In-Reply-To: <soutxv4r4p2.fsf@gmx.de>
References: <soutxv4r4p2.fsf@gmx.de>
Message-ID: <CAFDcVCSV6mmo=AcAcndvQQcoGK6uDSqZfxLmTAagd4OVDnNM2Q@mail.gmail.com>

For whoever is going to troubleshoot this, I cannot reproduce this
endless-loop crash on Windows (Platform: x86_64-w64-mingw32/x64
(64-bit)).  With:

> foo <- function () {
+  x <- c("A" = 1.3, "B" = 0.7, "C" = -0.3)
+  structure(x, class = "bar")
+ }
>
> print.bar <- function (x, ...) {
+   print(x, ...)
+ }

I get:

> foo()
Error: C stack usage is too close to the limit

on R version 2.14.2 (2012-02-29) and R version 2.15.1 Patched
(2012-09-10 r60659), and

> foo()
Error: evaluation nested too deeply: infinite recursion / options(expressions=)?

on R Under development (unstable) (2012-09-10 r60659)

/Henrik

On Tue, Sep 11, 2012 at 7:53 AM, Basil Abou El-Komboz
<Basil.Abou-El-Komboz at stat.uni-muenchen.de> wrote:
> Dear useR's,
>
> today I stumbled over an interesting phenomenon: First, I created a
> named numeric vector with a certain class and several attributes via the
> structure() function. After that, I implemented a simple print method
> for this class. When calling this function it produces an endless loop
> of print calls until R crashes. :/
>
> What is going on here? Is this a bug or have I done something completely
> wrong? :)
>
> Below is a minimal example which reproduces the behavior. Be careful
> when calling foo() as this automatically calls print.bar() which causes
> R to crash (at least on my PC, see further informations about my system below.)
>
> Greetings,
> Basil
>
> --------------------------------------------------
>
> Minimal example:
>
> foo <- function () {
>  x <- c("A" = 1.3, "B" = 0.7, "C" = -0.3)
>  structure(x, class = "bar")
> }
>
> print.bar <- function (x, ...) {
>   print(x, ...)
> }
>
> --------------------------------------------------
>
> Further informations about my system:
>
>> version
>               _
> platform       x86_64-unknown-linux-gnu
> arch           x86_64
> os             linux-gnu
> system         x86_64, linux-gnu
> status
> major          2
> minor          15.1
> year           2012
> month          06
> day            22
> svn rev        59600
> language       R
> version.string R version 2.15.1 (2012-06-22)
> nickname       Roasted Marshmallows
>
>> sessionInfo()
>
> R version 2.15.1 (2012-06-22)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-8
>  [6] LC_MESSAGES=en_US.UTF-8    LC_PAPER=C                 LC_NAME=C                  LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_2.15.1 tools_2.15.1
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From mtmorgan at fhcrc.org  Wed Sep 12 05:22:24 2012
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Tue, 11 Sep 2012 20:22:24 -0700
Subject: [Rd] Is invokeRestart("abort") unstoppable?
In-Reply-To: <CAFDcVCQCEUGuWcD2nqpzAxMwsao=QT=nkhzG5OZop5hostjsKw@mail.gmail.com>
References: <CAFDcVCQCEUGuWcD2nqpzAxMwsao=QT=nkhzG5OZop5hostjsKw@mail.gmail.com>
Message-ID: <504FFFF0.4080602@fhcrc.org>

On 09/11/2012 04:19 PM, Henrik Bengtsson wrote:
> Hi,
>
> I'm trying to implement an abort() method that works just like stop()
> but does not signal the condition such that try() and tryCatch(...,
> condition=...) are, contrary to stop(), effectively non-working with
> abort() calls.
>
> In order to achieve this, I stumbled upon invokeRestart("abort"), cf.
> help("invokeRestart", package="base") that reads "Restarts are used
> for establishing recovery protocols. They can be established using
> withRestarts. One pre-established restart is an abort restart that
> represents a jump to top level.".
>
> So, my current implementation is (roughly):
>
> abort <- function(...) {
>   # handling messages etc
>
>   # Fully abort the R evaluation and return to the top level
>   invokeRestart("abort")
> }
>
> I've tested it in various setups with and without tryCatch(...,
> condition=...) and so on and it appears to work.  Does anyone know if
> I'm overlooking something or can I count on  invokeRestart("abort") to
> always stop any currently evaluated R code?

Not sure what 'currently evaluating R code' means, but

   f = function(x) {
       on.exit(cat("not dead yet\n"))
       invokeRestart("abort")
   }

 > f()
never say die

   g = function() {
       reg.finalizer(new.env(), function(...)
           cat("not dead yet\n"))
       invokeRestart("abort")
   }
 > g()
 > gc()
not dead yet
          used (Mb) gc trigger (Mb) max used (Mb)
Ncells 170841  9.2   47185920 2520   709729 38.0
Vcells 145992  1.2  268435456 2048  1023614  7.9

   h = function() {
       withRestarts(f(), abort=function(...) {
           cat("I'm sorry Henrik, I can't do that\n")
           TRUE
        })
   }

 > h()
never say die
I'm sorry Henrik, I can't do that
[1] TRUE

all evaluate code after invoking abort.

>
> Also, does anyone know how far back (in R versions) invokeRestart("abort") goes?

$ svn blame conditions.Rd

says that the line you quote is from r25527 (which is when tryCatch 
appears to have been introduced), and

$ svn info -r25527
Path: man
URL: https://svn.r-project.org/R/trunk/src/library/base/man
Repository Root: https://svn.r-project.org/R
Repository UUID: 00db46b3-68df-0310-9c12-caf00c1e9a41
Revision: 25527
Node Kind: directory
Last Changed Author: luke
Last Changed Rev: 25527
Last Changed Date: 2003-07-31 12:35:18 -0700 (Thu, 31 Jul 2003)

>
> Thxs,
>
> Henrik
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From timhesterberg at gmail.com  Wed Sep 12 07:23:14 2012
From: timhesterberg at gmail.com (Tim Hesterberg)
Date: Tue, 11 Sep 2012 22:23:14 -0700
Subject: [Rd] Suggest adding a 'pivot' argument to qr.R
In-Reply-To: <40D65328-9CBA-4E2D-AAEA-DAC0636A18F8@gmail.com> (message from
	peter dalgaard on Tue, 11 Sep 2012 18:03:53 +0200)
References: <0CAEE2B1235DF643B0F5E1EAE1487B53094747F7@023-CH1MPN1-043.023d.mgd.msft.net>
	<40D65328-9CBA-4E2D-AAEA-DAC0636A18F8@gmail.com>
Message-ID: <yajfipbj95ml.fsf@gmail.com>

>On Sep 11, 2012, at 16:02 , Warnes, Gregory wrote:
>
>>
>> On 9/7/12 2:42 PM, "peter dalgaard" <pdalgd at gmail.com> wrote:
>>
>>>
>>> On Sep 7, 2012, at 17:16 , Tim Hesterberg wrote:
>>>
>>>> I suggest adding a 'pivot' argument to qr.R, to obtain columns in the
>>>> same order as the original x, so that
>>>> a <- qr(x)
>>>> qr.Q(a) %*% qr.R(a, pivot=TRUE)
>>>> returns x.
>>>
>>> That would come spiraling down in flames the first time someone tried to
>>> use backsolve on it, wouldn't it? I mean, a major point of QR is that R
>>> is triangular; doesn't make much sense to permute the columns without
>>> retaining the pivoting permutation.
>>
>> As I understand Tim's proposal, the pivot argument defaults to FALSE, so
>> the new behavior would only be activated at the user's request.
>
>Sure. I'm just saying that I see little use for the un-pivoted qr.R because, generically, the first thing you want to do with qr.R is to invert it, which is easier when it is triangular.

Greg Warnes is correct, I propose keeping the default FALSE, for backward
compatibility.

My use for the pivoted R is in computing a covariance matrix, using
  R <- qr.R(QR, pivot = TRUE)
  Rinv <- ginverse(R)
  covTerm <- Rinv %*% t(Rinv)

But I see that lm() and glm() use chol2inv, that may be preferable.


From pleydell at supagro.inra.fr  Wed Sep 12 07:38:50 2012
From: pleydell at supagro.inra.fr (David)
Date: Wed, 12 Sep 2012 01:38:50 -0400
Subject: [Rd] valgrind crashing
In-Reply-To: <mailman.21.1347098407.5750.r-devel@r-project.org>
References: <mailman.21.1347098407.5750.r-devel@r-project.org>
Message-ID: <50501FEA.4030200@supagro.inra.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120912/538a0e1f/attachment.pl>

From pleydell at supagro.inra.fr  Wed Sep 12 07:56:54 2012
From: pleydell at supagro.inra.fr (David)
Date: Wed, 12 Sep 2012 01:56:54 -0400
Subject: [Rd] valgrind crashing
In-Reply-To: <50501FEA.4030200@supagro.inra.fr>
References: <mailman.21.1347098407.5750.r-devel@r-project.org>
	<50501FEA.4030200@supagro.inra.fr>
Message-ID: <50502426.40207@supagro.inra.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120912/701bad84/attachment.pl>

From ripley at stats.ox.ac.uk  Wed Sep 12 08:47:58 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 12 Sep 2012 07:47:58 +0100
Subject: [Rd] valgrind crashing
In-Reply-To: <50502426.40207@supagro.inra.fr>
References: <mailman.21.1347098407.5750.r-devel@r-project.org>
	<50501FEA.4030200@supagro.inra.fr> <50502426.40207@supagro.inra.fr>
Message-ID: <5050301E.50507@stats.ox.ac.uk>

On 12/09/2012 06:56, David wrote:
>> I am trying to do a classic
>>
>> R -d valgrind --vanilla < mypkg-Ex.R
>>
>> as described in
>> http://cs.swan.ac.uk/~csoliver/ok-sat-library/internet_html/doc/doc/R/2.9.1/doc/manual/R-exts.html#Using-valgrind
>>
>> The problem is valgrind crashes imediately.
>>
>> I am using Ubuntu 10.04 LST (actually Biolinux) on a 64bit Dell
>> Precision laptop with 4 core-i5 Intel processors. I have R-2-15-0
>> installed from source and configured using
>>
>> ./configure --enable-memory-profiling
>> --with-valgrind-instrumentation=2 --prefix=/usr/local/lib64/R-2.15.0-vg2
>>
>> in  /usr/local/bin there's a dynamic link
>>
>> R-2.15.0-vg2 -> /usr/local/lib64/R-2.15.0-vg2/bin/R
>>
>> I can run R in bash using
>>
>> $ R-2.15.0-vg2
>>
>> Valgrind was installed from the Ubuntu repositories using apt-get.
>
> Simply removing this version and installing from source got things working.

Yes, I was about to comment that your valgrind is far too old for an 
x86_64 system.  Even 3.7.x gave spurious reports.

>
> all the best
> David
>
>> But ...
>>
>> $ R-2.15.0-vg2 -d valgrind --vanilla
>> R-2.15.0-vg2 -d valgrind --vanilla
>> ==29007== Memcheck, a memory error detector
>> ==29007== Copyright (C) 2002-2009, and GNU GPL'd, by Julian Seward et al.
>> ==29007== Using Valgrind-3.6.0.SVN-Debian and LibVEX; rerun with -h
>> for copyright info
>> ==29007== Command: /usr/local/lib64/R-2.15.0-vg2/lib64/R/bin/exec/R
>> --vanilla
>> ==29007==
>> --29007-- Warning: DWARF2 CFI reader: unhandled DW_OP_ opcode 0x2a
>>
>> valgrind: m_debuginfo/readdwarf.c:2292 (copy_convert_CfiExpr_tree):
>> Assertion 'srcix >= 0 && srcix < VG_(sizeXA)(srcxa)' failed.
>> ==29007==    at 0x3802B1F7: ??? (in
>> /usr/lib/valgrind/memcheck-amd64-linux)
>>
>> sched status:
>>    running_tid=0
>>
>>
>> Note: see also the FAQ in the source distribution.
>> It contains workarounds to several common problems.
>> In particular, if Valgrind aborted or crashed after
>> identifying problems in your program, there's a good chance
>> that fixing those problems will prevent Valgrind aborting or
>> crashing, especially if it happened in m_mallocfree.c.
>>
>> If that doesn't help, please report this bug to: www.valgrind.org
>>
>> In the bug report, send all the above text, the valgrind
>> version, and what OS and version you are using.  Thanks.
>>
>>
>> I've used valgrind in the past on other computer without problem, but
>> I have no idea what's failling here (the FAQ didn't help). Does anyone
>> have any idea?
>>
>> many thanks
>> David
>>
>> p.s. I also have 2.15.1 installed in a near-identical manner as 2.15.0
>> with just the difference --with-valgrind-instrumentation=1, the result
>> is the same though.
>>
>
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Basil.Abou-El-Komboz at stat.uni-muenchen.de  Tue Sep 11 22:04:13 2012
From: Basil.Abou-El-Komboz at stat.uni-muenchen.de (Basil Abou El-Komboz)
Date: Tue, 11 Sep 2012 22:04:13 +0200
Subject: [Rd] R crashes when printing a named numeric vector of a
	specific class - Bug?
In-Reply-To: <CAAmySGPZu8fR3+paPs=Hii_EL7UmUy6vMPN8DWQnUtKszx0d7Q@mail.gmail.com>
	(R. Michael Weylandt's message of "Tue, 11 Sep 2012 16:52:00 +0100")
References: <soutxv4r4p2.fsf@gmx.de> <1347377748.1805.41.camel@milan>
	<CAAmySGPZu8fR3+paPs=Hii_EL7UmUy6vMPN8DWQnUtKszx0d7Q@mail.gmail.com>
Message-ID: <soubohc5nsy.fsf@gmx.de>


    >> Le mardi 11 septembre 2012 ? 16:53 +0200, Basil Abou El-Komboz a
    >> ?crit :
    >>> Dear useR's,
    >>> 
    >>> today I stumbled over an interesting phenomenon: First, I
    >>> created a named numeric vector with a certain class and several
    >>> attributes via the structure() function. After that, I
    >>> implemented a simple print method for this class. When calling
    >>> this function it produces an endless loop of print calls until R
    >>> crashes. :/
    >>> 
    >>> What is going on here? Is this a bug or have I done something
    >>> completely wrong? :)
    >>> 
    >>> Below is a minimal example which reproduces the behavior. Be
    >>> careful when calling foo() as this automatically calls
    >>> print.bar() which causes R to crash (at least on my PC, see
    >>> further informations about my system below.)
    >>> 
    >>> Greetings, Basil
    >>> 
    >>> --------------------------------------------------
    >>> 
    >>> Minimal example:
    >>> 
    >>> foo <- function () { x <- c("A" = 1.3, "B" = 0.7, "C" = -0.3)
    >>> structure(x, class = "bar") }
    >>> 
    >>> print.bar <- function (x, ...) { print(x, ...)  }
    >> What is your code supposed to do exactly? ;-)
    >> 
    >> You're calling print() in your class' print.bar() function, so
    >> calling print() on such an object will call print.bar(), which
    >> calls print(), which calls print.bar()... In a few moments the
    >> recursion will have gone so deep that some system limit about the
    >> stack size must be reached, and R is killed.
    >> 
    >> If you just want to print the object as a vector, you do not need
    >> to define any function. Or, at least, call print.default()
    >> instead of the generic print().
    >> 
    >> 
    >> My two cents
    >> 

    R> NextMethod() may also be of some help here, depending on the
    R> inheritance you're envisioning.

    R> Michael

Oops, I was blind. Thanks for the answers and pointing me in the right
direction. Of course, this is not a problem of R but a problem of my
coding. ;)

Greetings,
Basil


From hb at biostat.ucsf.edu  Wed Sep 12 19:08:42 2012
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Wed, 12 Sep 2012 10:08:42 -0700
Subject: [Rd] Is invokeRestart("abort") unstoppable?
In-Reply-To: <504FFFF0.4080602@fhcrc.org>
References: <CAFDcVCQCEUGuWcD2nqpzAxMwsao=QT=nkhzG5OZop5hostjsKw@mail.gmail.com>
	<504FFFF0.4080602@fhcrc.org>
Message-ID: <CAFDcVCRquP1BvmO87TadEVxZx=pZGTwrqa=2i0zoGVOzJC=88w@mail.gmail.com>

Thanks for you help Martin,

On Tue, Sep 11, 2012 at 8:22 PM, Martin Morgan <mtmorgan at fhcrc.org> wrote:
> On 09/11/2012 04:19 PM, Henrik Bengtsson wrote:
>>
>> Hi,
>>
>> I'm trying to implement an abort() method that works just like stop()
>> but does not signal the condition such that try() and tryCatch(...,
>> condition=...) are, contrary to stop(), effectively non-working with
>> abort() calls.
>>
>> In order to achieve this, I stumbled upon invokeRestart("abort"), cf.
>> help("invokeRestart", package="base") that reads "Restarts are used
>> for establishing recovery protocols. They can be established using
>> withRestarts. One pre-established restart is an abort restart that
>> represents a jump to top level.".
>>
>> So, my current implementation is (roughly):
>>
>> abort <- function(...) {
>>   # handling messages etc
>>
>>   # Fully abort the R evaluation and return to the top level
>>   invokeRestart("abort")
>> }
>>
>> I've tested it in various setups with and without tryCatch(...,
>> condition=...) and so on and it appears to work.  Does anyone know if
>> I'm overlooking something or can I count on  invokeRestart("abort") to
>> always stop any currently evaluated R code?
>
>
> Not sure what 'currently evaluating R code' means, but
>
>   f = function(x) {
>       on.exit(cat("never say die\n"))
>       invokeRestart("abort")
>   }
>
>> f()
> never say die

I forgot about on.exit(), though this is how I'd like abort() to
behave, i.e. abort() = stop() minus signalling.

>
>   g = function() {
>       reg.finalizer(new.env(), function(...)
>           cat("not dead yet\n"))
>       invokeRestart("abort")
>   }
>> g()
>> gc()
> not dead yet
>          used (Mb) gc trigger (Mb) max used (Mb)
> Ncells 170841  9.2   47185920 2520   709729 38.0
> Vcells 145992  1.2  268435456 2048  1023614  7.9

This one too.

>
>   h = function() {
>       withRestarts(f(), abort=function(...) {
>           cat("I'm sorry Henrik, I can't do that\n")
>           TRUE
>        })
>   }
>
>> h()
> never say die
> I'm sorry Henrik, I can't do that
> [1] TRUE
>
> all evaluate code after invoking abort.

This one I would never figure out/think of myself.  Although the abort
is caught here, at least the behavior of abort() is consistent with
stop() here too.  So for now, I'm (still) satisfied.

>
>
>>
>> Also, does anyone know how far back (in R versions) invokeRestart("abort")
>> goes?
>
>
> $ svn blame conditions.Rd
>
> says that the line you quote is from r25527 (which is when tryCatch appears
> to have been introduced), and
>
> $ svn info -r25527
> Path: man
> URL: https://svn.r-project.org/R/trunk/src/library/base/man
> Repository Root: https://svn.r-project.org/R
> Repository UUID: 00db46b3-68df-0310-9c12-caf00c1e9a41
> Revision: 25527
> Node Kind: directory
> Last Changed Author: luke
> Last Changed Rev: 25527
> Last Changed Date: 2003-07-31 12:35:18 -0700 (Thu, 31 Jul 2003)

Perfect.

/Henrik

>
>>
>> Thxs,
>>
>> Henrik
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
> --
> Computational Biology / Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N.
> PO Box 19024 Seattle, WA 98109
>
> Location: Arnold Building M1 B861
> Phone: (206) 667-2793


From mtmorgan at fhcrc.org  Thu Sep 13 00:23:02 2012
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Wed, 12 Sep 2012 15:23:02 -0700
Subject: [Rd] methods cbind2 bind_activation disrupts cbind everywhere
Message-ID: <50510B46.90601@fhcrc.org>

The methods package ?cbind2 includes the instruction to use via 
methods:::bind_activation(TRUE). This changes the default definition of 
cbind globally, disrupting proper evaluation in packages not using 
cbind2. Is cbind2 a hold-over from a time when ... could not be used for 
dispatch? What is a safe way for a package to use cbind2?

This came up in the context of complex package dependencies in 
Bioconductor, as detailed in this thread (sorry for the html).

https://stat.ethz.ch/pipermail/bioc-devel/2012-September/003617.html
-- 
Dr. Martin Morgan
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109


From wdunlap at tibco.com  Thu Sep 13 22:32:40 2012
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 13 Sep 2012 20:32:40 +0000
Subject: [Rd] as.data.frame.character lacks nm= argument
Message-ID: <E66794E69CFDE04D9A70842786030B9331BFED@PA-MBX04.na.tibco.com>

Is the following behavior with as.data.frame(nm=...) a bug?  It is an inconsistency:

> as.data.frame(LETTERS[1:10], nm="FirstTenLetters")
Error in as.data.frame.vector(x, ..., nm = nm) : 
  formal argument "nm" matched by multiple actual arguments

nm= works for integer arguments:

> as.data.frame(1:10, nm="OneToTen")
   OneToTen
1         1
2         2
3         3
4         4
5         5
6         6
7         7
8         8
9         9
10       10

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


From maechler at stat.math.ethz.ch  Fri Sep 14 10:00:56 2012
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 14 Sep 2012 10:00:56 +0200
Subject: [Rd] methods cbind2 bind_activation disrupts cbind everywhere
In-Reply-To: <50510B46.90601@fhcrc.org>
References: <50510B46.90601@fhcrc.org>
Message-ID: <20562.58424.868283.735077@stat.math.ethz.ch>

>>>>> Martin Morgan <mtmorgan at fhcrc.org>
>>>>>     on Wed, 12 Sep 2012 15:23:02 -0700 writes:

    > The methods package ?cbind2 includes the instruction to
    > use via methods:::bind_activation(TRUE). 

well, "instruction" only if one wants to magically enable its
use for cbind(), rbind()

    > use via methods:::bind_activation(TRUE). This changes the
    > default definition of cbind globally, disrupting proper
    > evaluation in packages not using cbind2. 

{ really disrupting?  I seem to only recall examples of
  performance loss, but that memory is fading.. }

    > evaluation in packages not using cbind2. Is cbind2 a
    > hold-over from a time when ... could not be used for
    > dispatch? 

Yes, exactly.

As I'm sure you know well, and   ?dotMethods  explains,
the ... dispatch was introduced only in R 2.8.0,
*and* if you read that help page, it is alluded to several times
that the implementation is still not "perfect" because it
entails restrictions, and also because its implementation in
pure R rather than (partially) C.

I had hoped (but not spent work myself, alas!) that there would
be evolution from there on, but it seems we forgot about it.

    > What is a safe way for a package to use cbind2?

to define methods for cbind2 / rbind2, with nice multiple
dispatch on both arguments,  as the 'Matrix' package has been
doing for many years (long before R 2.8.0) --> Matrix/R/bind.R

And then, instead of "bind_activation", 
Matrix now also defines  cBind() & rBind()
as substitutes for cbind(), rbind(),
simply as using  methods:::cbind()  which recursively calls
cbind2(), rbind2().

This has still the big drawback that  cbind() fails on "Matrix"
matrices {and even with quite an unhelpful error message!}, 
and useRs must learn to use cBind() instead....
not ideal, at all.


In an ideal R world, 
1) the "..." S4 dispatch would be improved and made faster
2) that part of Matrix would be rewritten, so that  cbind() and rbind()
   would work via '...' dispatch on both "Matrix" matrices and
   all standard R objects (atomic vectors, "matrix", data.frame,...),
   and the use of cBind() and rBind() could be deprecated.

I also have a vague recollection that '2)' was not just a job to
be done with finite some effort, but rather seemed not easily
achievable with the current restriction of "..." dispatch
needing all arguments to be of the same superclass.
We would have to define

 setGeneric("cbind", signature = "...")
 setGeneric("rbind", signature = "...")

 setMethod("cbind", "Mnumber", function(..., deparse.level=1) {
 ........
 ........
 })

similarly to what I do in the Rmpfr package,
and where "Mnumber" is a *large* class union... defined in
Rmpfr/R/AllClasses.R and if you look in there, you see comments
with FIXME ... basically the solution was +- ok, but not really 
entirely satisfactory to me.

Still, we maybe should really discuss to have the above two
setGeneric()s in 'methods', and possibly also some class union /
superclass  definitions there (that other packages could use!) possibly even
with   
setMethod("cbind", <large-mother-class>, 
          function(..., deparse.level=1) {
	  ......
	  })
and of course the same with rbind().


    > This came up in the context of complex package
    > dependencies in Bioconductor, as detailed in this thread
    > (sorry for the html).

    > https://stat.ethz.ch/pipermail/bioc-devel/2012-September/003617.html

    > -- 
    > Dr. Martin Morgan Fred Hutchinson Cancer Research Center
    > 1100 Fairview Ave. N.  PO Box 19024 Seattle, WA 98109

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From gunter.berton at gene.com  Thu Sep 13 22:48:29 2012
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 13 Sep 2012 13:48:29 -0700
Subject: [Rd] as.data.frame.character lacks nm= argument
In-Reply-To: <E66794E69CFDE04D9A70842786030B9331BFED@PA-MBX04.na.tibco.com>
References: <E66794E69CFDE04D9A70842786030B9331BFED@PA-MBX04.na.tibco.com>
Message-ID: <CACk-te1N4cN=cNeunL8zSn6SUVRis+rgbb8gvVg7mx61b2wdbQ@mail.gmail.com>

Bill:

as.data.frame.character() has no nm, argument, so providing one causes
the error as you can see from the code. Presumably, this is what you
meant by bug/inconsistency, right?

-- Bert

On Thu, Sep 13, 2012 at 1:32 PM, William Dunlap <wdunlap at tibco.com> wrote:
> Is the following behavior with as.data.frame(nm=...) a bug?  It is an inconsistency:
>
>> as.data.frame(LETTERS[1:10], nm="FirstTenLetters")
> Error in as.data.frame.vector(x, ..., nm = nm) :
>   formal argument "nm" matched by multiple actual arguments
>
> nm= works for integer arguments:
>
>> as.data.frame(1:10, nm="OneToTen")
>    OneToTen
> 1         1
> 2         2
> 3         3
> 4         4
> 5         5
> 6         6
> 7         7
> 8         8
> 9         9
> 10       10
>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From ripley at stats.ox.ac.uk  Fri Sep 14 15:25:12 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 14 Sep 2012 14:25:12 +0100
Subject: [Rd] as.data.frame.character lacks nm= argument
In-Reply-To: <CACk-te1N4cN=cNeunL8zSn6SUVRis+rgbb8gvVg7mx61b2wdbQ@mail.gmail.com>
References: <E66794E69CFDE04D9A70842786030B9331BFED@PA-MBX04.na.tibco.com>
	<CACk-te1N4cN=cNeunL8zSn6SUVRis+rgbb8gvVg7mx61b2wdbQ@mail.gmail.com>
Message-ID: <50533038.9040808@stats.ox.ac.uk>

On 13/09/2012 21:48, Bert Gunter wrote:
> Bill:
>
> as.data.frame.character() has no nm, argument, so providing one causes
> the error as you can see from the code. Presumably, this is what you
> meant by bug/inconsistency, right?

This is using an undocumented argument, 'nm'.  I don't believe anything 
is said about what might happen if you do that except that it will be 
passed to methods -- they are not obliged to accept it.

If it were intended for this to be a feature, I think the author might 
have chosen a less opaque name than 'nm'.

Where we go from here is under discussion in R-core.

>
> -- Bert
>
> On Thu, Sep 13, 2012 at 1:32 PM, William Dunlap <wdunlap at tibco.com> wrote:
>> Is the following behavior with as.data.frame(nm=...) a bug?  It is an inconsistency:
>>
>>> as.data.frame(LETTERS[1:10], nm="FirstTenLetters")
>> Error in as.data.frame.vector(x, ..., nm = nm) :
>>    formal argument "nm" matched by multiple actual arguments
>>
>> nm= works for integer arguments:
>>
>>> as.data.frame(1:10, nm="OneToTen")
>>     OneToTen
>> 1         1
>> 2         2
>> 3         3
>> 4         4
>> 5         5
>> 6         6
>> 7         7
>> 8         8
>> 9         9
>> 10       10
>>
>> Bill Dunlap
>> Spotfire, TIBCO Software
>> wdunlap tibco.com
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jeff.a.ryan at gmail.com  Fri Sep 14 16:16:42 2012
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Fri, 14 Sep 2012 09:16:42 -0500
Subject: [Rd] methods cbind2 bind_activation disrupts cbind everywhere
In-Reply-To: <20562.58424.868283.735077@stat.math.ethz.ch>
References: <50510B46.90601@fhcrc.org>
	<20562.58424.868283.735077@stat.math.ethz.ch>
Message-ID: <CABDUZc8VbDFa5UKTEyZPFg19dVR-Y-7deBAMg_ZKKgTL+q3bkg@mail.gmail.com>

Refreshing the memory on performance:

http://r.789695.n4.nabble.com/reduce-limit-number-of-arguments-in-methods-cbind-td921600.html#a921601

My issue had been resolved by a more careful approach taken by timeSeries.

The other option is wholesale deprecation of S4 ... but I won't start
that conversation with either of you ;-)

Jeff

On Fri, Sep 14, 2012 at 3:00 AM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>>>>>> Martin Morgan <mtmorgan at fhcrc.org>
>>>>>>     on Wed, 12 Sep 2012 15:23:02 -0700 writes:
>
>     > The methods package ?cbind2 includes the instruction to
>     > use via methods:::bind_activation(TRUE).
>
> well, "instruction" only if one wants to magically enable its
> use for cbind(), rbind()
>
>     > use via methods:::bind_activation(TRUE). This changes the
>     > default definition of cbind globally, disrupting proper
>     > evaluation in packages not using cbind2.
>
> { really disrupting?  I seem to only recall examples of
>   performance loss, but that memory is fading.. }
>
>     > evaluation in packages not using cbind2. Is cbind2 a
>     > hold-over from a time when ... could not be used for
>     > dispatch?
>
> Yes, exactly.
>
> As I'm sure you know well, and   ?dotMethods  explains,
> the ... dispatch was introduced only in R 2.8.0,
> *and* if you read that help page, it is alluded to several times
> that the implementation is still not "perfect" because it
> entails restrictions, and also because its implementation in
> pure R rather than (partially) C.
>
> I had hoped (but not spent work myself, alas!) that there would
> be evolution from there on, but it seems we forgot about it.
>
>     > What is a safe way for a package to use cbind2?
>
> to define methods for cbind2 / rbind2, with nice multiple
> dispatch on both arguments,  as the 'Matrix' package has been
> doing for many years (long before R 2.8.0) --> Matrix/R/bind.R
>
> And then, instead of "bind_activation",
> Matrix now also defines  cBind() & rBind()
> as substitutes for cbind(), rbind(),
> simply as using  methods:::cbind()  which recursively calls
> cbind2(), rbind2().
>
> This has still the big drawback that  cbind() fails on "Matrix"
> matrices {and even with quite an unhelpful error message!},
> and useRs must learn to use cBind() instead....
> not ideal, at all.
>
>
> In an ideal R world,
> 1) the "..." S4 dispatch would be improved and made faster
> 2) that part of Matrix would be rewritten, so that  cbind() and rbind()
>    would work via '...' dispatch on both "Matrix" matrices and
>    all standard R objects (atomic vectors, "matrix", data.frame,...),
>    and the use of cBind() and rBind() could be deprecated.
>
> I also have a vague recollection that '2)' was not just a job to
> be done with finite some effort, but rather seemed not easily
> achievable with the current restriction of "..." dispatch
> needing all arguments to be of the same superclass.
> We would have to define
>
>  setGeneric("cbind", signature = "...")
>  setGeneric("rbind", signature = "...")
>
>  setMethod("cbind", "Mnumber", function(..., deparse.level=1) {
>  ........
>  ........
>  })
>
> similarly to what I do in the Rmpfr package,
> and where "Mnumber" is a *large* class union... defined in
> Rmpfr/R/AllClasses.R and if you look in there, you see comments
> with FIXME ... basically the solution was +- ok, but not really
> entirely satisfactory to me.
>
> Still, we maybe should really discuss to have the above two
> setGeneric()s in 'methods', and possibly also some class union /
> superclass  definitions there (that other packages could use!) possibly even
> with
> setMethod("cbind", <large-mother-class>,
>           function(..., deparse.level=1) {
>           ......
>           })
> and of course the same with rbind().
>
>
>     > This came up in the context of complex package
>     > dependencies in Bioconductor, as detailed in this thread
>     > (sorry for the html).
>
>     > https://stat.ethz.ch/pipermail/bioc-devel/2012-September/003617.html
>
>     > --
>     > Dr. Martin Morgan Fred Hutchinson Cancer Research Center
>     > 1100 Fairview Ave. N.  PO Box 19024 Seattle, WA 98109
>
>     > ______________________________________________
>     > R-devel at r-project.org mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Jeffrey Ryan
jeffrey.ryan at lemnica.com

www.lemnica.com


From wdunlap at tibco.com  Fri Sep 14 16:43:15 2012
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 14 Sep 2012 14:43:15 +0000
Subject: [Rd] as.data.frame.character lacks nm= argument
In-Reply-To: <50533038.9040808@stats.ox.ac.uk>
References: <E66794E69CFDE04D9A70842786030B9331BFED@PA-MBX04.na.tibco.com>
	<CACk-te1N4cN=cNeunL8zSn6SUVRis+rgbb8gvVg7mx61b2wdbQ@mail.gmail.com>
	<50533038.9040808@stats.ox.ac.uk>
Message-ID: <E66794E69CFDE04D9A70842786030B9331C41E@PA-MBX04.na.tibco.com>

Thanks Brian,

I am not sure why the user who ran into this problem was using
   as.data.frame(theColumn, nm=theName)
but it may have been an attempt to make a data.frame with a
variable for a column name, which is a pain when calling data.frame.

It also is faster, but I doubt that was the reason:
  > system.time(for(i in 1:1e4)data.frame(x=log(seq_len(100))))
     user  system elapsed 
     1.06    0.00    1.06 
  > system.time(for(i in 1:1e4)as.data.frame(log(seq_len(100))))
     user  system elapsed 
     0.62    0.00    0.63 
  > system.time(for(i in 1:1e4)as.data.frame(log(seq_len(100)), nm="x"))
     user  system elapsed 
     0.17    0.00    0.17  

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> Sent: Friday, September 14, 2012 6:25 AM
> To: Bert Gunter
> Cc: William Dunlap; r-devel at r-project.org
> Subject: Re: [Rd] as.data.frame.character lacks nm= argument
> 
> On 13/09/2012 21:48, Bert Gunter wrote:
> > Bill:
> >
> > as.data.frame.character() has no nm, argument, so providing one causes
> > the error as you can see from the code. Presumably, this is what you
> > meant by bug/inconsistency, right?
> 
> This is using an undocumented argument, 'nm'.  I don't believe anything
> is said about what might happen if you do that except that it will be
> passed to methods -- they are not obliged to accept it.
> 
> If it were intended for this to be a feature, I think the author might
> have chosen a less opaque name than 'nm'.
> 
> Where we go from here is under discussion in R-core.
> 
> >
> > -- Bert
> >
> > On Thu, Sep 13, 2012 at 1:32 PM, William Dunlap <wdunlap at tibco.com> wrote:
> >> Is the following behavior with as.data.frame(nm=...) a bug?  It is an inconsistency:
> >>
> >>> as.data.frame(LETTERS[1:10], nm="FirstTenLetters")
> >> Error in as.data.frame.vector(x, ..., nm = nm) :
> >>    formal argument "nm" matched by multiple actual arguments
> >>
> >> nm= works for integer arguments:
> >>
> >>> as.data.frame(1:10, nm="OneToTen")
> >>     OneToTen
> >> 1         1
> >> 2         2
> >> 3         3
> >> 4         4
> >> 5         5
> >> 6         6
> >> 7         7
> >> 8         8
> >> 9         9
> >> 10       10
> >>
> >> Bill Dunlap
> >> Spotfire, TIBCO Software
> >> wdunlap tibco.com
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
> >
> 
> 
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pdalgd at gmail.com  Fri Sep 14 17:10:48 2012
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 14 Sep 2012 17:10:48 +0200
Subject: [Rd] as.data.frame.character lacks nm= argument
In-Reply-To: <50533038.9040808@stats.ox.ac.uk>
References: <E66794E69CFDE04D9A70842786030B9331BFED@PA-MBX04.na.tibco.com>
	<CACk-te1N4cN=cNeunL8zSn6SUVRis+rgbb8gvVg7mx61b2wdbQ@mail.gmail.com>
	<50533038.9040808@stats.ox.ac.uk>
Message-ID: <B4FD85E3-D3B0-4DD0-86E2-F23EEEFAE681@gmail.com>


On Sep 14, 2012, at 15:25 , Prof Brian Ripley wrote:

> On 13/09/2012 21:48, Bert Gunter wrote:
>> Bill:
>> 
>> as.data.frame.character() has no nm, argument, so providing one causes
>> the error as you can see from the code. Presumably, this is what you
>> meant by bug/inconsistency, right?
> 
> This is using an undocumented argument, 'nm'.  I don't believe anything is said about what might happen if you do that except that it will be passed to methods -- they are not obliged to accept it.
> 
> If it were intended for this to be a feature, I think the author might have chosen a less opaque name than 'nm'.

It wasn't, but the author (me) might have chosen a _more_ opaque name if he had thought it necessary to keep people from using undocumented arguments. As it happened, I think I just promoted a variable name inside as.data.frame.vector to become an argument.

But it was a long time ago, in a different job, and besides....

> 
> Where we go from here is under discussion in R-core.
> 
>> 
>> -- Bert
>> 
>> On Thu, Sep 13, 2012 at 1:32 PM, William Dunlap <wdunlap at tibco.com> wrote:
>>> Is the following behavior with as.data.frame(nm=...) a bug?  It is an inconsistency:
>>> 
>>>> as.data.frame(LETTERS[1:10], nm="FirstTenLetters")
>>> Error in as.data.frame.vector(x, ..., nm = nm) :
>>>   formal argument "nm" matched by multiple actual arguments
>>> 
>>> nm= works for integer arguments:
>>> 
>>>> as.data.frame(1:10, nm="OneToTen")
>>>    OneToTen
>>> 1         1
>>> 2         2
>>> 3         3
>>> 4         4
>>> 5         5
>>> 6         6
>>> 7         7
>>> 8         8
>>> 9         9
>>> 10       10
>>> 
>>> Bill Dunlap
>>> Spotfire, TIBCO Software
>>> wdunlap tibco.com
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> 
>> 
> 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From simon.knapp at anu.edu.au  Sat Sep 15 05:10:05 2012
From: simon.knapp at anu.edu.au (Simon Knapp)
Date: Sat, 15 Sep 2012 13:10:05 +1000
Subject: [Rd] Question about copying arguments in C.
Message-ID: <CAA+5f=0UFS3d-mqcpFizY6=WnRES8_0AoPQ7N6hYP-5QgUHWvQ@mail.gmail.com>

Hi List,

I'd imagine this is a question that has been answered before, but I
can't seem to track it down, sorry for the duplication if it has.

I am writing an interface for a C library and want to return an S4
class from the 'constructing' method. One of the slots of the argument
to be returned will be filled with one of the arguments passed to the
function. My question is about whether I can directly pass arguments
to the function directly to slots of the returned object (or to a
return value more generally for that matter), or whether I have to
copy them. If it is the latter, then how may I do this. The question
is phrased in the following (simplified) code.

int constructThingy(int thingysInteger);

SEXP constructThingy(SEXP thingysInteger) {
    SEXP ans, TClass, ti;
    if(!isInteger(thingysInteger)) error("thingysIntegermust be an integer.");
    if(constructThingy(INTEGER(thingysInteger)[0])) error("error in
getting a thingy");
    TClass = MAKE_CLASS("thingy");
    PROTECT(ans = NEW_OBJECT(TClass));


    // *****QUESTION STARTS HERE*****
    // CAN I SAY:
    SET_SLOT(ans, Rf_install("myInteger"), thingysInteger);

    // IF NOT, CAN I SAY
    SET_SLOT(ans, Rf_install("myInteger"), AS_INTEGER(thingysInteger));

    // OR DO I NEED TO SAY
    PROTECT(ti = allocVector(INTSXP, 1)); INTEGER(pns)[0] =
INTEGER(thingysInteger)[0];
    SET_SLOT(ans, Rf_install("myInteger"), ti);
    // *****END OF QUESTION*****

    UNPROTECT(1); // or UNPROTECT(2) in latter case.
    return ans;
}



I think this is the same as asking whether the following is OK:

SEXP func(SEXP arg) {
    return arg;
}




Thanks in advance,
Simon


From simon.urbanek at r-project.org  Sat Sep 15 14:40:29 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 15 Sep 2012 08:40:29 -0400
Subject: [Rd] Question about copying arguments in C.
In-Reply-To: <CAA+5f=0UFS3d-mqcpFizY6=WnRES8_0AoPQ7N6hYP-5QgUHWvQ@mail.gmail.com>
References: <CAA+5f=0UFS3d-mqcpFizY6=WnRES8_0AoPQ7N6hYP-5QgUHWvQ@mail.gmail.com>
Message-ID: <0D319C1D-CA32-4FDC-96C1-B97D40A31DCC@r-project.org>


On Sep 14, 2012, at 11:10 PM, Simon Knapp wrote:

> Hi List,
> 
> I'd imagine this is a question that has been answered before, but I
> can't seem to track it down, sorry for the duplication if it has.
> 
> I am writing an interface for a C library and want to return an S4
> class from the 'constructing' method. One of the slots of the argument
> to be returned will be filled with one of the arguments passed to the
> function. My question is about whether I can directly pass arguments
> to the function directly to slots of the returned object (or to a
> return value more generally for that matter), or whether I have to
> copy them. If it is the latter, then how may I do this. The question
> is phrased in the following (simplified) code.
> 
> int constructThingy(int thingysInteger);
> 
> SEXP constructThingy(SEXP thingysInteger) {
>    SEXP ans, TClass, ti;
>    if(!isInteger(thingysInteger)) error("thingysIntegermust be an integer.");
>    if(constructThingy(INTEGER(thingysInteger)[0])) error("error in
> getting a thingy");
>    TClass = MAKE_CLASS("thingy");
>    PROTECT(ans = NEW_OBJECT(TClass));
> 
> 
>    // *****QUESTION STARTS HERE*****
>    // CAN I SAY:
>    SET_SLOT(ans, Rf_install("myInteger"), thingysInteger);
> 
>    // IF NOT, CAN I SAY
>    SET_SLOT(ans, Rf_install("myInteger"), AS_INTEGER(thingysInteger));
> 
>    // OR DO I NEED TO SAY
>    PROTECT(ti = allocVector(INTSXP, 1)); INTEGER(pns)[0] =
> INTEGER(thingysInteger)[0];
>    SET_SLOT(ans, Rf_install("myInteger"), ti);
>    // *****END OF QUESTION*****
> 
>    UNPROTECT(1); // or UNPROTECT(2) in latter case.
>    return ans;
> }
> 
> 
> 
> I think this is the same as asking whether the following is OK:
> 
> SEXP func(SEXP arg) {
>    return arg;
> }
> 

Yes.

In fact if you wanted to duplicate (e.g, if you want to modify an incoming argument and return the modified result), the proper way would be to use duplicate() and not the contortions your were trying.

Cheers,
Simon


> 
> 
> 
> 
> Thanks in advance,
> Simon
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From simon.knapp at anu.edu.au  Sat Sep 15 17:28:02 2012
From: simon.knapp at anu.edu.au (Simon Knapp)
Date: Sun, 16 Sep 2012 01:28:02 +1000
Subject: [Rd] Question about copying arguments in C.
In-Reply-To: <0D319C1D-CA32-4FDC-96C1-B97D40A31DCC@r-project.org>
References: <CAA+5f=0UFS3d-mqcpFizY6=WnRES8_0AoPQ7N6hYP-5QgUHWvQ@mail.gmail.com>
	<0D319C1D-CA32-4FDC-96C1-B97D40A31DCC@r-project.org>
Message-ID: <CAA+5f=2kTQv1rhGG4u=d_XFaSOHi3avYFW9x2dmiObWQkDQpcQ@mail.gmail.com>

Hi Simon,

Thanks for your advice, but I'm still not clear. In my case I don't
want to modify the result - the integer acts as a handle for indexing
an array in later calls back into my library.

As I understand it, returning result like

SEXP func(SEXP arg) {return arg;}

would not copy arg and hence I would have two pointers to the same
object immediately after the call... and (if this is the case) I'm not
sure whether this is OK.


Just to be clear, are you saying that the proper way to do things is
(at the end of my function in the original post):

SET_SLOT(ans, Rf_install("myInteger"), duplicate(thingysInteger));
return ans;

rather than

SET_SLOT(ans, Rf_install("myInteger"), thingysInteger);
return ans;

?

The last thing I'm not clear on is if it is OK to create a new SEXP
(with a call like duplicate) in a call to another function (as in the
first case above) or does this leave it unprotected?

Thanx again for your help,
Simon

On Sat, Sep 15, 2012 at 10:40 PM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
>
> On Sep 14, 2012, at 11:10 PM, Simon Knapp wrote:
>
>> Hi List,
>>
>> I'd imagine this is a question that has been answered before, but I
>> can't seem to track it down, sorry for the duplication if it has.
>>
>> I am writing an interface for a C library and want to return an S4
>> class from the 'constructing' method. One of the slots of the argument
>> to be returned will be filled with one of the arguments passed to the
>> function. My question is about whether I can directly pass arguments
>> to the function directly to slots of the returned object (or to a
>> return value more generally for that matter), or whether I have to
>> copy them. If it is the latter, then how may I do this. The question
>> is phrased in the following (simplified) code.
>>
>> int constructThingy(int thingysInteger);
>>
>> SEXP constructThingy(SEXP thingysInteger) {
>>    SEXP ans, TClass, ti;
>>    if(!isInteger(thingysInteger)) error("thingysIntegermust be an integer.");
>>    if(constructThingy(INTEGER(thingysInteger)[0])) error("error in
>> getting a thingy");
>>    TClass = MAKE_CLASS("thingy");
>>    PROTECT(ans = NEW_OBJECT(TClass));
>>
>>
>>    // *****QUESTION STARTS HERE*****
>>    // CAN I SAY:
>>    SET_SLOT(ans, Rf_install("myInteger"), thingysInteger);
>>
>>    // IF NOT, CAN I SAY
>>    SET_SLOT(ans, Rf_install("myInteger"), AS_INTEGER(thingysInteger));
>>
>>    // OR DO I NEED TO SAY
>>    PROTECT(ti = allocVector(INTSXP, 1)); INTEGER(pns)[0] =
>> INTEGER(thingysInteger)[0];
>>    SET_SLOT(ans, Rf_install("myInteger"), ti);
>>    // *****END OF QUESTION*****
>>
>>    UNPROTECT(1); // or UNPROTECT(2) in latter case.
>>    return ans;
>> }
>>
>>
>>
>> I think this is the same as asking whether the following is OK:
>>
>> SEXP func(SEXP arg) {
>>    return arg;
>> }
>>
>
> Yes.
>
> In fact if you wanted to duplicate (e.g, if you want to modify an incoming argument and return the modified result), the proper way would be to use duplicate() and not the contortions your were trying.
>
> Cheers,
> Simon
>
>
>>
>>
>>
>>
>> Thanks in advance,
>> Simon
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>


From hb at biostat.ucsf.edu  Sat Sep 15 19:21:51 2012
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sat, 15 Sep 2012 10:21:51 -0700
Subject: [Rd] Risk of readRDS() not detecting race conditions with parallel
	saveRDS()?
Message-ID: <CAFDcVCRH=oX+=cHdy5aCo7KmpYvo7pfDS5xpr3bwP23rtamK7A@mail.gmail.com>

I hardly know anything about the format used in (non-compressed)
serialization/RDS, but hoping someone with more knowledge could give
me some feedback;

Consider two R processes running in parallel on the same unknown file
system.  Both of them write and read to the same RDS file foo.rds
(without compression) at random times using saveRDS(object,
file="foo.rds", compress=FALSE) and object2 <-
readRDS(file="foo.rds").  This happens frequently enough such that
there is a risk for the two processes to write to the same "foo.rds"
file at the same time (here one needs to acknowledge that file updates
are not atomic nor instant).

To simulate the event that two processes writes to the same file at
the same time (and non-atomically) results in a interweaved/appended
"foo.rds" file, I manually corrupted "foo.rds" by
inserting/dropping/replacing a single random byte.  It appears that
readRDS() will detect this simple event, by throwing an error on
"unknown input format", which is what I want.  My question is now, is
it reasonable to assume that if two or more processes happen to write
to the same RDS file at the same time, it is extremely unlikely (*)
that they would generate a file that would pass as valid by readRDS()?
 (*) extremely unlikely = if all of us would run this toy example we
would not end up with a non-detect but still corrupt "foo.rds" file
in, say, 10000 years.

Background: The R.cache package allows memoization (caching of
results) to file such that the cache is persistent across R sessions.
The persistent part is achieved by writing cache files to the same
file directory.  This is safe when you run a single process, and even
if readRDS() would fail to read a cache file it is no big deal; the
memoization will just fail and the results will be recalculated and be
resaved.  The questions is what happens if you run this in parallel
and push it to the extreme; is there a risk that the memoization will
properly return but with invalid results.  I prefer not having to
synchronize this with a mutex/semaphore/common server, but instead
rely on this try-an-see approach (cf. the Ethernet protocol on shared
medium).  My guess (and hope) is that the risk is extremely unlikely
(*), but I'd like to hear if someone else thinks otherwise.

Thanks,

Henrik


From mtmorgan at fhcrc.org  Sat Sep 15 19:35:46 2012
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Sat, 15 Sep 2012 10:35:46 -0700
Subject: [Rd] methods cbind2 bind_activation disrupts cbind everywhere
In-Reply-To: <CABDUZc8VbDFa5UKTEyZPFg19dVR-Y-7deBAMg_ZKKgTL+q3bkg@mail.gmail.com>
References: <50510B46.90601@fhcrc.org>
	<20562.58424.868283.735077@stat.math.ethz.ch>
	<CABDUZc8VbDFa5UKTEyZPFg19dVR-Y-7deBAMg_ZKKgTL+q3bkg@mail.gmail.com>
Message-ID: <5054BC72.3000507@fhcrc.org>

On 09/14/2012 07:16 AM, Jeff Ryan wrote:
> Refreshing the memory on performance:
>
> http://r.789695.n4.nabble.com/reduce-limit-number-of-arguments-in-methods-cbind-td921600.html#a921601

short comment below...

>
> My issue had been resolved by a more careful approach taken by timeSeries.
>
> The other option is wholesale deprecation of S4 ... but I won't start
> that conversation with either of you ;-)
>
> Jeff
>
> On Fri, Sep 14, 2012 at 3:00 AM, Martin Maechler
> <maechler at stat.math.ethz.ch> wrote:
>>>>>>> Martin Morgan <mtmorgan at fhcrc.org>
>>>>>>>      on Wed, 12 Sep 2012 15:23:02 -0700 writes:
>>
>>      > The methods package ?cbind2 includes the instruction to
>>      > use via methods:::bind_activation(TRUE).
>>
>> well, "instruction" only if one wants to magically enable its
>> use for cbind(), rbind()
>>
>>      > use via methods:::bind_activation(TRUE). This changes the
>>      > default definition of cbind globally, disrupting proper
>>      > evaluation in packages not using cbind2.
>>
>> { really disrupting?  I seem to only recall examples of
>>    performance loss, but that memory is fading.. }

the problem came up here

 > library(ggplot2)
 > xx = qplot(x = mpg, y = cyl, data = mtcars, facets = . ~ cyl)
 > xx ## pretty picture
 > methods:::bind_activation(TRUE)   ## done in .onLoad of 2nd package
[1] FALSE
 > xx
Error in rep.int("", ncol(r)) : incorrect type for second argument

with methods:::bind_activation(TRUE) begin set by an unrelated package 
in .onLoad(). So I guess to the extent that the default method does not 
"use R's internal code" as advertised on the man page this could be 
considered a bug report.

>>
>>      > evaluation in packages not using cbind2. Is cbind2 a
>>      > hold-over from a time when ... could not be used for
>>      > dispatch?
>>
>> Yes, exactly.
>>
>> As I'm sure you know well, and   ?dotMethods  explains,
>> the ... dispatch was introduced only in R 2.8.0,
>> *and* if you read that help page, it is alluded to several times
>> that the implementation is still not "perfect" because it
>> entails restrictions, and also because its implementation in
>> pure R rather than (partially) C.
>>
>> I had hoped (but not spent work myself, alas!) that there would
>> be evolution from there on, but it seems we forgot about it.
>>
>>      > What is a safe way for a package to use cbind2?
>>
>> to define methods for cbind2 / rbind2, with nice multiple
>> dispatch on both arguments,  as the 'Matrix' package has been

OK, from this I won't hesitate to advise against bind_activation.

@Jeff -- that was a useful reminder of the performance consequences of 
S4 dispatch, even in the more usual case where the dispatch is correct, 
thanks.

Thanks Martin, Martin.

>> doing for many years (long before R 2.8.0) --> Matrix/R/bind.R
>>
>> And then, instead of "bind_activation",
>> Matrix now also defines  cBind() & rBind()
>> as substitutes for cbind(), rbind(),
>> simply as using  methods:::cbind()  which recursively calls
>> cbind2(), rbind2().
>>
>> This has still the big drawback that  cbind() fails on "Matrix"
>> matrices {and even with quite an unhelpful error message!},
>> and useRs must learn to use cBind() instead....
>> not ideal, at all.
>>
>>
>> In an ideal R world,
>> 1) the "..." S4 dispatch would be improved and made faster
>> 2) that part of Matrix would be rewritten, so that  cbind() and rbind()
>>     would work via '...' dispatch on both "Matrix" matrices and
>>     all standard R objects (atomic vectors, "matrix", data.frame,...),
>>     and the use of cBind() and rBind() could be deprecated.
>>
>> I also have a vague recollection that '2)' was not just a job to
>> be done with finite some effort, but rather seemed not easily
>> achievable with the current restriction of "..." dispatch
>> needing all arguments to be of the same superclass.
>> We would have to define
>>
>>   setGeneric("cbind", signature = "...")
>>   setGeneric("rbind", signature = "...")
>>
>>   setMethod("cbind", "Mnumber", function(..., deparse.level=1) {
>>   ........
>>   ........
>>   })
>>
>> similarly to what I do in the Rmpfr package,
>> and where "Mnumber" is a *large* class union... defined in
>> Rmpfr/R/AllClasses.R and if you look in there, you see comments
>> with FIXME ... basically the solution was +- ok, but not really
>> entirely satisfactory to me.
>>
>> Still, we maybe should really discuss to have the above two
>> setGeneric()s in 'methods', and possibly also some class union /
>> superclass  definitions there (that other packages could use!) possibly even
>> with
>> setMethod("cbind", <large-mother-class>,
>>            function(..., deparse.level=1) {
>>            ......
>>            })
>> and of course the same with rbind().
>>
>>
>>      > This came up in the context of complex package
>>      > dependencies in Bioconductor, as detailed in this thread
>>      > (sorry for the html).
>>
>>      > https://stat.ethz.ch/pipermail/bioc-devel/2012-September/003617.html
>>
>>      > --
>>      > Dr. Martin Morgan Fred Hutchinson Cancer Research Center
>>      > 1100 Fairview Ave. N.  PO Box 19024 Seattle, WA 98109
>>
>>      > ______________________________________________
>>      > R-devel at r-project.org mailing list
>>      > https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From edd at debian.org  Sat Sep 15 20:37:08 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 15 Sep 2012 13:37:08 -0500
Subject: [Rd] Reposting mails to R-Core / R-Devel
Message-ID: <20564.51924.980100.566871@max.nulle.part>


Over the last few months, I had sent emails with follow-up suggestions,
questions and (minimal) patches to R Core (two) and R-Devel (one).

Not one of these emails was met with any follow-up I am aware of.

I will resend them here so that they will at least get archived in case
someone else ponders similar questions at a different point in time.

Thanks,  Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From edd at debian.org  Sat Sep 15 20:37:13 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 15 Sep 2012 13:37:13 -0500
Subject: [Rd] [Repost 1/3] The X11 device patch
Message-ID: <20564.51929.179523.847136@max.nulle.part>


[ Email resend 1 of 3 ]

  From: Dirk Eddelbuettel <edd at debian.org>
  To: R-core <R-core at r-project.org>
  CC: Philip Johnson <plfjohnson at emory.edu>, edd at debian.org
  Subject: The X11 device patch
  Date: Wed, 27 Jun 2012 11:53:13 -0500
  
  
  R Core,
  
  *Great* to see this bubble up in the NEWS aggregation:
  
    2.15.1 patched NEW FEATURES
  
    The X11() window gains an icon: the latter may be especially useful on
    Ubuntu's Unity interface.
  
    The WM_CLASS should be set in circumstances where the Window Manager failed
    to make use of Xt settings.
  
  As you may know, I also applied these changes by Philip (CC'ed) to the Debian
  package and am enjoying them tremendously. This is useful beyond Unity -- I
  am currently (at work) at a Windows 7 box and even its taskbar now shows an R
  logo when I send an x11() plot device over ssh.
  
  You may need to also include two more files:  an icon png file, and a
  .desktop file.  I can help off-list, as can Philip who guided me through this
  too. 
  
  Dirk, glad to see the "delta" between the Debian build and R minimized again
  
  -- 
  Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com  
  

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From edd at debian.org  Sat Sep 15 20:37:17 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 15 Sep 2012 13:37:17 -0500
Subject: [Rd] [Repost 2/3] Why fix all.equal for POSIXct at 1 msec?
Message-ID: <20564.51933.43755.889225@max.nulle.part>


[ Email repost 2 of 3 ]

  From: Dirk Eddelbuettel <edd at debian.org>
  To: R-core <R-core at r-project.org>, Prof Brian D Ripley <ripley at stats.ox.ac.uk>
  Subject: Why fix all.equal for POSIXct at 1 msec? 
  Date: Sat, 28 Jul 2012 10:29:52 -0500
  
  
  In R-devel as of today, the following simple loop
  
  edd at max:~/svn/r-devel$ ~/bin/R-devel.sh
  
  R Under development (unstable) (2012-07-28 r60021) -- "Unsuffered
  Consequenc  es"
  [...]
  
  R> now <- Sys.time();  for (d in seq(-1,-9,by=-1)) { then <- now + 10^d;
  cat  ("10^", d, " identical(): ", identical(now, then), " and all.equal():
  "  , all.equal(now, then), " diff of ", difftime(then, now), "\n", sep="")
  }   
  10^-1 identical(): FALSE and all.equal(): Mean scaled difference: 0.0999999
   diff of 0.0999999
  10^-2 identical(): FALSE and all.equal(): Mean scaled difference:
  0.00999999   diff of 0.00999999
  10^-3 identical(): FALSE and all.equal(): TRUE diff of 0.000999928
  10^-4 identical(): FALSE and all.equal(): TRUE diff of 9.98974e-05
  10^-5 identical(): FALSE and all.equal(): TRUE diff of 1.00136e-05
  10^-6 identical(): FALSE and all.equal(): TRUE diff of 9.53674e-07
  10^-7 identical(): TRUE and all.equal(): TRUE diff of 0
  10^-8 identical(): TRUE and all.equal(): TRUE diff of 0
  10^-9 identical(): TRUE and all.equal(): TRUE diff of 0
  R> 
  
  starts reporting all.equal results up to a millisec when identical()
  clearly  
  shows that a measurable difference is detectable much further.  
  
  Why stop at a msec?  I have using POSIXct to store microsecond data for
  half  
  a decade, and have been very grateful for how well R supports this. I fear
  that having all.equal define such an arbitrary bound will lead people to
  infer that R cannot go further than 10^-2 which is clearly wrong.
  
  For completeness, on r-release I get
  
  
  R> now <- Sys.time();  for (d in seq(-1,-9,by=-1)) { then <- now + 10^d;
  cat  ("10^", d, " identical(): ", identical(now, then), " and all.equal():
  "  , all.equal(now, then), " diff of ", difftime(then, now), "\n", sep="")
  }   
  10^-1 identical(): FALSE and all.equal(): TRUE diff of 0.0999999
  10^-2 identical(): FALSE and all.equal(): TRUE diff of 0.00999999
  10^-3 identical(): FALSE and all.equal(): TRUE diff of 0.000999928
  10^-4 identical(): FALSE and all.equal(): TRUE diff of 9.98974e-05
  10^-5 identical(): FALSE and all.equal(): TRUE diff of 1.00136e-05
  10^-6 identical(): FALSE and all.equal(): TRUE diff of 9.53674e-07
  10^-7 identical(): TRUE and all.equal(): TRUE diff of 0
  10^-8 identical(): TRUE and all.equal(): TRUE diff of 0
  10^-9 identical(): TRUE and all.equal(): TRUE diff of 0
  R> R.Version()["version.string"]
  $version.string
  [1] "R version 2.15.1 (2012-06-22)"
  
  R> 
  
  
  Thanks, Dirk
  
  -- 
  Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com  


-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From edd at debian.org  Sat Sep 15 20:37:21 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 15 Sep 2012 13:37:21 -0500
Subject: [Rd] [Repost 3/3] Minor glitch in 'Writing R Extensions'
Message-ID: <20564.51937.907638.654708@max.nulle.part>


[ Email repost 3 of 3 ]

  From: Dirk Eddelbuettel <edd at debian.org>
  To: R-devel org <r-devel at r-project.org>
  Subject: [Patch] Minor glitch in 'Writing R Extensions'
  Date: Mon, 3 Sep 2012 10:58:32 -0500
  
  
  The (marked up in info mode) manual Writing R Extensions says in 6.1.3
  
   -- Function: double fprec (double X, double DIGITS)
       Returns the value of X rounded to DIGITS decimal digits (after the
       decimal point).
  
       This is the function used by R's `round()'.
                                        ^^^^^^^^^^
  
   -- Function: double fround (double X, double DIGITS)
       Returns the value of X rounded to DIGITS _significant_ decimal
       digits.
  
       This is the function used by R's `signif()'.
                                        ^^^^^^^^^^^
  
  I think that is crossed vis-a-vis the the corresponding R functions, ie
  
     'double fprec is used by 'signif (not round)
  
     'double fround' is used by 'round' (not signif)
  
  as I just found out by trying to unit-test wrappers just added to Rcpp.
  
  Sources seem to agree -- src/main/arithmetic.c has
  
      case 10001: return Math2(args, fround);/* round(), src/nmath/fround.c */
      case 10004: return Math2(args, fprec); /* signif(), src/nmath/fprec.c */
  
  So with that I suggest to alter the R-exts.texi as the patch below does.
  
  Hope this helps, Dirk
  
  
  edd at max:/tmp$ diff -u R-exts.texi.orig R-exts.texi
  --- R-exts.texi.orig    2012-09-03 10:56:21.219528679 -0500
  +++ R-exts.texi 2012-09-03 10:56:42.359529056 -0500
  @@ -10659,14 +10659,14 @@
   Returns the value of @var{x} rounded to @var{digits} decimal digits
   (after the decimal point).
   
  -This is the function used by @R{}'s @code{round()}.
  +This is the function used by @R{}'s @code{signif()}.
   @end deftypefun
   
   @deftypefun double fround (double @var{x}, double @var{digits})
   Returns the value of @var{x} rounded to @var{digits} @emph{significant}
   decimal digits.
   
  -This is the function used by @R{}'s @code{signif()}.
  +This is the function used by @R{}'s @code{round()}.
   @end deftypefun
   
   @deftypefun double ftrunc (double @var{x})
  edd at max:/tmp$ 
  
  
  
  -- 
  Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com  

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From simon.urbanek at r-project.org  Sat Sep 15 20:57:27 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 15 Sep 2012 14:57:27 -0400
Subject: [Rd] Question about copying arguments in C.
In-Reply-To: <CAA+5f=2kTQv1rhGG4u=d_XFaSOHi3avYFW9x2dmiObWQkDQpcQ@mail.gmail.com>
References: <CAA+5f=0UFS3d-mqcpFizY6=WnRES8_0AoPQ7N6hYP-5QgUHWvQ@mail.gmail.com>
	<0D319C1D-CA32-4FDC-96C1-B97D40A31DCC@r-project.org>
	<CAA+5f=2kTQv1rhGG4u=d_XFaSOHi3avYFW9x2dmiObWQkDQpcQ@mail.gmail.com>
Message-ID: <FDC086B4-3137-479B-A407-683C4E9C8B21@r-project.org>


On Sep 15, 2012, at 11:28 AM, Simon Knapp wrote:

> Hi Simon,
> 
> Thanks for your advice, but I'm still not clear. In my case I don't
> want to modify the result - the integer acts as a handle for indexing
> an array in later calls back into my library.
> 
> As I understand it, returning result like
> 
> SEXP func(SEXP arg) {return arg;}
> 
> would not copy arg and hence I would have two pointers to the same
> object immediately after the call... and (if this is the case) I'm not
> sure whether this is OK.
> 

My answer is was, yes, it's ok.


> Just to be clear, are you saying that the proper way to do things is
> (at the end of my function in the original post):
> 
> SET_SLOT(ans, Rf_install("myInteger"), duplicate(thingysInteger));
> return ans;
> 
> rather than
> 
> SET_SLOT(ans, Rf_install("myInteger"), thingysInteger);
> return ans;
> 
> ?
> 

No, because you're not modifying anything in that case.


> The last thing I'm not clear on is if it is OK to create a new SEXP
> (with a call like duplicate) in a call to another function (as in the
> first case above) or does this leave it unprotected?
> 

Most functions (but not all - a notable exception is eval) protect their arguments, so it's ok in most cases. But this is no different than any other SEXP result - not specific to duplicate() in particular.

Cheers,
Simon



> Thanx again for your help,
> Simon
> 
> On Sat, Sep 15, 2012 at 10:40 PM, Simon Urbanek
> <simon.urbanek at r-project.org> wrote:
>> 
>> On Sep 14, 2012, at 11:10 PM, Simon Knapp wrote:
>> 
>>> Hi List,
>>> 
>>> I'd imagine this is a question that has been answered before, but I
>>> can't seem to track it down, sorry for the duplication if it has.
>>> 
>>> I am writing an interface for a C library and want to return an S4
>>> class from the 'constructing' method. One of the slots of the argument
>>> to be returned will be filled with one of the arguments passed to the
>>> function. My question is about whether I can directly pass arguments
>>> to the function directly to slots of the returned object (or to a
>>> return value more generally for that matter), or whether I have to
>>> copy them. If it is the latter, then how may I do this. The question
>>> is phrased in the following (simplified) code.
>>> 
>>> int constructThingy(int thingysInteger);
>>> 
>>> SEXP constructThingy(SEXP thingysInteger) {
>>>   SEXP ans, TClass, ti;
>>>   if(!isInteger(thingysInteger)) error("thingysIntegermust be an integer.");
>>>   if(constructThingy(INTEGER(thingysInteger)[0])) error("error in
>>> getting a thingy");
>>>   TClass = MAKE_CLASS("thingy");
>>>   PROTECT(ans = NEW_OBJECT(TClass));
>>> 
>>> 
>>>   // *****QUESTION STARTS HERE*****
>>>   // CAN I SAY:
>>>   SET_SLOT(ans, Rf_install("myInteger"), thingysInteger);
>>> 
>>>   // IF NOT, CAN I SAY
>>>   SET_SLOT(ans, Rf_install("myInteger"), AS_INTEGER(thingysInteger));
>>> 
>>>   // OR DO I NEED TO SAY
>>>   PROTECT(ti = allocVector(INTSXP, 1)); INTEGER(pns)[0] =
>>> INTEGER(thingysInteger)[0];
>>>   SET_SLOT(ans, Rf_install("myInteger"), ti);
>>>   // *****END OF QUESTION*****
>>> 
>>>   UNPROTECT(1); // or UNPROTECT(2) in latter case.
>>>   return ans;
>>> }
>>> 
>>> 
>>> 
>>> I think this is the same as asking whether the following is OK:
>>> 
>>> SEXP func(SEXP arg) {
>>>   return arg;
>>> }
>>> 
>> 
>> Yes.
>> 
>> In fact if you wanted to duplicate (e.g, if you want to modify an incoming argument and return the modified result), the proper way would be to use duplicate() and not the contortions your were trying.
>> 
>> Cheers,
>> Simon
>> 
>> 
>>> 
>>> 
>>> 
>>> 
>>> Thanks in advance,
>>> Simon
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>> 
>> 
> 
> 


From simon.urbanek at r-project.org  Sat Sep 15 21:08:31 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 15 Sep 2012 15:08:31 -0400
Subject: [Rd] Question about copying arguments in C.
In-Reply-To: <FDC086B4-3137-479B-A407-683C4E9C8B21@r-project.org>
References: <CAA+5f=0UFS3d-mqcpFizY6=WnRES8_0AoPQ7N6hYP-5QgUHWvQ@mail.gmail.com>
	<0D319C1D-CA32-4FDC-96C1-B97D40A31DCC@r-project.org>
	<CAA+5f=2kTQv1rhGG4u=d_XFaSOHi3avYFW9x2dmiObWQkDQpcQ@mail.gmail.com>
	<FDC086B4-3137-479B-A407-683C4E9C8B21@r-project.org>
Message-ID: <B8786FE7-D663-4830-BAC6-248F948F124E@r-project.org>


On Sep 15, 2012, at 2:57 PM, Simon Urbanek wrote:

> 
> On Sep 15, 2012, at 11:28 AM, Simon Knapp wrote:
> 
>> Hi Simon,
>> 
>> Thanks for your advice, but I'm still not clear. In my case I don't
>> want to modify the result - the integer acts as a handle for indexing
>> an array in later calls back into my library.
>> 
>> As I understand it, returning result like
>> 
>> SEXP func(SEXP arg) {return arg;}
>> 
>> would not copy arg and hence I would have two pointers to the same
>> object immediately after the call... and (if this is the case) I'm not
>> sure whether this is OK.
>> 
> 
> My answer is was, yes, it's ok.
> 
> 
>> Just to be clear, are you saying that the proper way to do things is
>> (at the end of my function in the original post):
>> 
>> SET_SLOT(ans, Rf_install("myInteger"), duplicate(thingysInteger));
>> return ans;
>> 
>> rather than
>> 
>> SET_SLOT(ans, Rf_install("myInteger"), thingysInteger);
>> return ans;
>> 
>> ?
>> 
> 
> No, because you're not modifying anything in that case.
> 
> 
>> The last thing I'm not clear on is if it is OK to create a new SEXP
>> (with a call like duplicate) in a call to another function (as in the
>> first case above) or does this leave it unprotected?
>> 
> 
> Most functions (but not all - a notable exception is eval) protect their arguments, so it's ok in most cases. But this is no different than any other SEXP result - not specific to duplicate() in particular.
> 

Actually, I should explain a bit, because the above case is not about SET_SLOT protecting or not protecting arguments. In fact it does protect its arguments, but even when you are calling a function that protects its arguments, you can get into trouble. But let's take a more common example (since you really don't want to call duplicate() in your example) - let's say you want to do something like

setAttrib(foo, install("bar"), mkString("bar"));

Although setAttrib() is friendly an protects its arguments, the above is bad, because the mkString() is unprotected while install() is called. Now, symbols don't need protection, but it is possible that install() will trigger allocation, so the mkString() result is in danger. The best way around is something like

SEXP bar = install("bar")
setAttrib(foo, bar, mkString("bar"));

Here mkString() is fine, because there cannot be an allocation before setAttrib() protects its arguments. Also bar is a symbol so it doesn't need to be protected, so the above is ok.

Cheers,
Simon



> Cheers,
> Simon
> 
> 
> 
>> Thanx again for your help,
>> Simon
>> 
>> On Sat, Sep 15, 2012 at 10:40 PM, Simon Urbanek
>> <simon.urbanek at r-project.org> wrote:
>>> 
>>> On Sep 14, 2012, at 11:10 PM, Simon Knapp wrote:
>>> 
>>>> Hi List,
>>>> 
>>>> I'd imagine this is a question that has been answered before, but I
>>>> can't seem to track it down, sorry for the duplication if it has.
>>>> 
>>>> I am writing an interface for a C library and want to return an S4
>>>> class from the 'constructing' method. One of the slots of the argument
>>>> to be returned will be filled with one of the arguments passed to the
>>>> function. My question is about whether I can directly pass arguments
>>>> to the function directly to slots of the returned object (or to a
>>>> return value more generally for that matter), or whether I have to
>>>> copy them. If it is the latter, then how may I do this. The question
>>>> is phrased in the following (simplified) code.
>>>> 
>>>> int constructThingy(int thingysInteger);
>>>> 
>>>> SEXP constructThingy(SEXP thingysInteger) {
>>>>  SEXP ans, TClass, ti;
>>>>  if(!isInteger(thingysInteger)) error("thingysIntegermust be an integer.");
>>>>  if(constructThingy(INTEGER(thingysInteger)[0])) error("error in
>>>> getting a thingy");
>>>>  TClass = MAKE_CLASS("thingy");
>>>>  PROTECT(ans = NEW_OBJECT(TClass));
>>>> 
>>>> 
>>>>  // *****QUESTION STARTS HERE*****
>>>>  // CAN I SAY:
>>>>  SET_SLOT(ans, Rf_install("myInteger"), thingysInteger);
>>>> 
>>>>  // IF NOT, CAN I SAY
>>>>  SET_SLOT(ans, Rf_install("myInteger"), AS_INTEGER(thingysInteger));
>>>> 
>>>>  // OR DO I NEED TO SAY
>>>>  PROTECT(ti = allocVector(INTSXP, 1)); INTEGER(pns)[0] =
>>>> INTEGER(thingysInteger)[0];
>>>>  SET_SLOT(ans, Rf_install("myInteger"), ti);
>>>>  // *****END OF QUESTION*****
>>>> 
>>>>  UNPROTECT(1); // or UNPROTECT(2) in latter case.
>>>>  return ans;
>>>> }
>>>> 
>>>> 
>>>> 
>>>> I think this is the same as asking whether the following is OK:
>>>> 
>>>> SEXP func(SEXP arg) {
>>>>  return arg;
>>>> }
>>>> 
>>> 
>>> Yes.
>>> 
>>> In fact if you wanted to duplicate (e.g, if you want to modify an incoming argument and return the modified result), the proper way would be to use duplicate() and not the contortions your were trying.
>>> 
>>> Cheers,
>>> Simon
>>> 
>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> Thanks in advance,
>>>> Simon
>>>> 
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> 
>>>> 
>>> 
>> 
>> 
> 


From simon.urbanek at r-project.org  Sat Sep 15 21:17:51 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 15 Sep 2012 15:17:51 -0400
Subject: [Rd] Risk of readRDS() not detecting race conditions with
	parallel saveRDS()?
In-Reply-To: <CAFDcVCRH=oX+=cHdy5aCo7KmpYvo7pfDS5xpr3bwP23rtamK7A@mail.gmail.com>
References: <CAFDcVCRH=oX+=cHdy5aCo7KmpYvo7pfDS5xpr3bwP23rtamK7A@mail.gmail.com>
Message-ID: <2A32BE85-4132-4C2F-86E5-75236A6FCE5D@r-project.org>


On Sep 15, 2012, at 1:21 PM, Henrik Bengtsson wrote:

> I hardly know anything about the format used in (non-compressed)
> serialization/RDS, but hoping someone with more knowledge could give
> me some feedback;
> 
> Consider two R processes running in parallel on the same unknown file
> system.  Both of them write and read to the same RDS file foo.rds
> (without compression) at random times using saveRDS(object,
> file="foo.rds", compress=FALSE) and object2 <-
> readRDS(file="foo.rds").  This happens frequently enough such that
> there is a risk for the two processes to write to the same "foo.rds"
> file at the same time (here one needs to acknowledge that file updates
> are not atomic nor instant).
> 
> To simulate the event that two processes writes to the same file at
> the same time (and non-atomically) results in a interweaved/appended
> "foo.rds" file, I manually corrupted "foo.rds" by
> inserting/dropping/replacing a single random byte.  It appears that
> readRDS() will detect this simple event, by throwing an error on
> "unknown input format", which is what I want.  My question is now, is
> it reasonable to assume that if two or more processes happen to write
> to the same RDS file at the same time, it is extremely unlikely (*)
> that they would generate a file that would pass as valid by readRDS()?
> (*) extremely unlikely = if all of us would run this toy example we
> would not end up with a non-detect but still corrupt "foo.rds" file
> in, say, 10000 years.
> 

It's actually very probable that it will go undetected. In fact the probability in very high is you have large vectors, because you can corrupt almost the entire file and there will be no sign of corruption, because there is no checksum, so you can changed the the whole vector payload without any consequence. Just try saveRDS(rep(0L,100), "foo.rds", compress=T) and you can mess with anything after byte 21 and it will result in no error.

Cheers,
S


> Background: The R.cache package allows memoization (caching of
> results) to file such that the cache is persistent across R sessions.
> The persistent part is achieved by writing cache files to the same
> file directory.  This is safe when you run a single process, and even
> if readRDS() would fail to read a cache file it is no big deal; the
> memoization will just fail and the results will be recalculated and be
> resaved.  The questions is what happens if you run this in parallel
> and push it to the extreme; is there a risk that the memoization will
> properly return but with invalid results.  I prefer not having to
> synchronize this with a mutex/semaphore/common server, but instead
> rely on this try-an-see approach (cf. the Ethernet protocol on shared
> medium).  My guess (and hope) is that the risk is extremely unlikely
> (*), but I'd like to hear if someone else thinks otherwise.
> 
> Thanks,
> 
> Henrik
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From wdunlap at tibco.com  Sat Sep 15 21:44:13 2012
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 15 Sep 2012 19:44:13 +0000
Subject: [Rd] Risk of readRDS() not detecting race conditions with
 parallel	saveRDS()?
In-Reply-To: <CAFDcVCRH=oX+=cHdy5aCo7KmpYvo7pfDS5xpr3bwP23rtamK7A@mail.gmail.com>
References: <CAFDcVCRH=oX+=cHdy5aCo7KmpYvo7pfDS5xpr3bwP23rtamK7A@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B9331CA51@PA-MBX04.na.tibco.com>

Why not write the RDS file more atomically - write it to a
temporary file and rename that file to its final name when
it is completely written?  E.g.,

saveRDS.atomically
function (object, file, ...) 
{
    tfile <- tempfile(basename(file), dirname(file))
    on.exit(if (file.exists(tfile)) unlink(tfile))
    retval <- saveRDS(object, tfile, ...)
    if (!file.rename(tfile, file)) { # perhaps want an if(file.exists(file))unlink(file) first
        stop("Cannot rename temporary file ", tfile, " to ", 
            file)
    }
    invisible(retval)
}

(The file.rename may be tripped up by an overeager virus checker looking
at the newly created tfile.  I don't know the best way to deal with that.)

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf
> Of Henrik Bengtsson
> Sent: Saturday, September 15, 2012 10:22 AM
> To: R-devel
> Subject: [Rd] Risk of readRDS() not detecting race conditions with parallel saveRDS()?
> 
> I hardly know anything about the format used in (non-compressed)
> serialization/RDS, but hoping someone with more knowledge could give
> me some feedback;
> 
> Consider two R processes running in parallel on the same unknown file
> system.  Both of them write and read to the same RDS file foo.rds
> (without compression) at random times using saveRDS(object,
> file="foo.rds", compress=FALSE) and object2 <-
> readRDS(file="foo.rds").  This happens frequently enough such that
> there is a risk for the two processes to write to the same "foo.rds"
> file at the same time (here one needs to acknowledge that file updates
> are not atomic nor instant).
> 
> To simulate the event that two processes writes to the same file at
> the same time (and non-atomically) results in a interweaved/appended
> "foo.rds" file, I manually corrupted "foo.rds" by
> inserting/dropping/replacing a single random byte.  It appears that
> readRDS() will detect this simple event, by throwing an error on
> "unknown input format", which is what I want.  My question is now, is
> it reasonable to assume that if two or more processes happen to write
> to the same RDS file at the same time, it is extremely unlikely (*)
> that they would generate a file that would pass as valid by readRDS()?
>  (*) extremely unlikely = if all of us would run this toy example we
> would not end up with a non-detect but still corrupt "foo.rds" file
> in, say, 10000 years.
> 
> Background: The R.cache package allows memoization (caching of
> results) to file such that the cache is persistent across R sessions.
> The persistent part is achieved by writing cache files to the same
> file directory.  This is safe when you run a single process, and even
> if readRDS() would fail to read a cache file it is no big deal; the
> memoization will just fail and the results will be recalculated and be
> resaved.  The questions is what happens if you run this in parallel
> and push it to the extreme; is there a risk that the memoization will
> properly return but with invalid results.  I prefer not having to
> synchronize this with a mutex/semaphore/common server, but instead
> rely on this try-an-see approach (cf. the Ethernet protocol on shared
> medium).  My guess (and hope) is that the risk is extremely unlikely
> (*), but I'd like to hear if someone else thinks otherwise.
> 
> Thanks,
> 
> Henrik
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hb at biostat.ucsf.edu  Sat Sep 15 23:21:33 2012
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sat, 15 Sep 2012 14:21:33 -0700
Subject: [Rd] Risk of readRDS() not detecting race conditions with
 parallel saveRDS()?
In-Reply-To: <2A32BE85-4132-4C2F-86E5-75236A6FCE5D@r-project.org>
References: <CAFDcVCRH=oX+=cHdy5aCo7KmpYvo7pfDS5xpr3bwP23rtamK7A@mail.gmail.com>
	<2A32BE85-4132-4C2F-86E5-75236A6FCE5D@r-project.org>
Message-ID: <CAFDcVCQDt9q-VRxTvfym2hKbztDkn_yYkMZwmSC0PNc7m033iA@mail.gmail.com>

On Sat, Sep 15, 2012 at 12:17 PM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
>
> On Sep 15, 2012, at 1:21 PM, Henrik Bengtsson wrote:
>
>> I hardly know anything about the format used in (non-compressed)
>> serialization/RDS, but hoping someone with more knowledge could give
>> me some feedback;
>>
>> Consider two R processes running in parallel on the same unknown file
>> system.  Both of them write and read to the same RDS file foo.rds
>> (without compression) at random times using saveRDS(object,
>> file="foo.rds", compress=FALSE) and object2 <-
>> readRDS(file="foo.rds").  This happens frequently enough such that
>> there is a risk for the two processes to write to the same "foo.rds"
>> file at the same time (here one needs to acknowledge that file updates
>> are not atomic nor instant).
>>
>> To simulate the event that two processes writes to the same file at
>> the same time (and non-atomically) results in a interweaved/appended
>> "foo.rds" file, I manually corrupted "foo.rds" by
>> inserting/dropping/replacing a single random byte.  It appears that
>> readRDS() will detect this simple event, by throwing an error on
>> "unknown input format", which is what I want.  My question is now, is
>> it reasonable to assume that if two or more processes happen to write
>> to the same RDS file at the same time, it is extremely unlikely (*)
>> that they would generate a file that would pass as valid by readRDS()?
>> (*) extremely unlikely = if all of us would run this toy example we
>> would not end up with a non-detect but still corrupt "foo.rds" file
>> in, say, 10000 years.
>>
>
> It's actually very probable that it will go undetected. In fact the probability in very high is you have large vectors, because you can corrupt almost the entire file and there will be no sign of corruption, because there is no checksum, so you can changed the the whole vector payload without any consequence. Just try saveRDS(rep(0L,100), "foo.rds", compress=T) and you can mess with anything after byte 21 and it will result in no error.

Wow, I guess my "random" testing were modifying the header, because
your example clearly shows that readRDS() is not detecting "mutations"
of the data section itself.  This is exactly the type of feedback I
was looking for.

I guess I should enhance my cache file format with checksums.

Thanks Simon

/Henrik

>
> Cheers,
> S
>
>
>> Background: The R.cache package allows memoization (caching of
>> results) to file such that the cache is persistent across R sessions.
>> The persistent part is achieved by writing cache files to the same
>> file directory.  This is safe when you run a single process, and even
>> if readRDS() would fail to read a cache file it is no big deal; the
>> memoization will just fail and the results will be recalculated and be
>> resaved.  The questions is what happens if you run this in parallel
>> and push it to the extreme; is there a risk that the memoization will
>> properly return but with invalid results.  I prefer not having to
>> synchronize this with a mutex/semaphore/common server, but instead
>> rely on this try-an-see approach (cf. the Ethernet protocol on shared
>> medium).  My guess (and hope) is that the risk is extremely unlikely
>> (*), but I'd like to hear if someone else thinks otherwise.
>>
>> Thanks,
>>
>> Henrik
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>


From hb at biostat.ucsf.edu  Sat Sep 15 23:42:17 2012
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sat, 15 Sep 2012 14:42:17 -0700
Subject: [Rd] Risk of readRDS() not detecting race conditions with
 parallel saveRDS()?
In-Reply-To: <E66794E69CFDE04D9A70842786030B9331CA51@PA-MBX04.na.tibco.com>
References: <CAFDcVCRH=oX+=cHdy5aCo7KmpYvo7pfDS5xpr3bwP23rtamK7A@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B9331CA51@PA-MBX04.na.tibco.com>
Message-ID: <CAFDcVCRf7fK8GWLW+rVa0bkmrRT9-2_BFU7TY88YkY2NCTN01A@mail.gmail.com>

Hi Bill,

yes, emulating atomic writing by writing to a temporary file and then
renaming definitely lowers the risk for corruptions.  I actually take
a similar approach in the Aroma Project (aroma.affymetrix et al.),
R.utils::saveObject(), R.utils::downloadFile() and more, and it
provides a great protection against user-interrupts, power failures
and so on.  I've been considering adding it to R.cache as well.

However, I'm not sure that it is guaranteed to be truly atomic.  I'm
saying this because ~8 years I was running batch jobs on 50 computers
on a shared file system.  Each R process was looking for remaining
"job" directory (=one job) and if found, it renamed/moved it
immediately so no other process would find/grab the same job.
However, it turned out that occasionally two separate R processes (on
different machines) could grab and move that same directory at the
"same" time (holding on to the same file target), proceed with the
analysis and write the results to file (which then would contain
interweaved results from the two parallel runs).  From that I learned
that on certain NFS file systems, it can take up to 30 seconds(!)
before file updates are seen by all computers.  Of course, what you're
proposing is somewhat different - first creating a unique temporary
file for each process which is then renamed to a common file.  The
question is how this is affected by above file system delays etc.

So to summarize my strategy, I'd like to add all possible layers of
protection (that are not too expensive) against race conditions in
order to minimize any risks for errors and if errors still occur I'd
like to be able to detect them, and all this without assuming to much
about the file systems.  It's only as a last resort I want to turn to
coordinated approaches via a main server (mutex handler; TCPIP is
guaranteed to truly atomic everywhere) ...and I don't want to reinvent
cluster OSes.

Thanks for you feedback

/Henrik

On Sat, Sep 15, 2012 at 12:44 PM, William Dunlap <wdunlap at tibco.com> wrote:
> Why not write the RDS file more atomically - write it to a
> temporary file and rename that file to its final name when
> it is completely written?  E.g.,
>
> saveRDS.atomically
> function (object, file, ...)
> {
>     tfile <- tempfile(basename(file), dirname(file))
>     on.exit(if (file.exists(tfile)) unlink(tfile))
>     retval <- saveRDS(object, tfile, ...)
>     if (!file.rename(tfile, file)) { # perhaps want an if(file.exists(file))unlink(file) first
>         stop("Cannot rename temporary file ", tfile, " to ",
>             file)
>     }
>     invisible(retval)
> }
>
> (The file.rename may be tripped up by an overeager virus checker looking
> at the newly created tfile.  I don't know the best way to deal with that.)
>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
>
>> -----Original Message-----
>> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf
>> Of Henrik Bengtsson
>> Sent: Saturday, September 15, 2012 10:22 AM
>> To: R-devel
>> Subject: [Rd] Risk of readRDS() not detecting race conditions with parallel saveRDS()?
>>
>> I hardly know anything about the format used in (non-compressed)
>> serialization/RDS, but hoping someone with more knowledge could give
>> me some feedback;
>>
>> Consider two R processes running in parallel on the same unknown file
>> system.  Both of them write and read to the same RDS file foo.rds
>> (without compression) at random times using saveRDS(object,
>> file="foo.rds", compress=FALSE) and object2 <-
>> readRDS(file="foo.rds").  This happens frequently enough such that
>> there is a risk for the two processes to write to the same "foo.rds"
>> file at the same time (here one needs to acknowledge that file updates
>> are not atomic nor instant).
>>
>> To simulate the event that two processes writes to the same file at
>> the same time (and non-atomically) results in a interweaved/appended
>> "foo.rds" file, I manually corrupted "foo.rds" by
>> inserting/dropping/replacing a single random byte.  It appears that
>> readRDS() will detect this simple event, by throwing an error on
>> "unknown input format", which is what I want.  My question is now, is
>> it reasonable to assume that if two or more processes happen to write
>> to the same RDS file at the same time, it is extremely unlikely (*)
>> that they would generate a file that would pass as valid by readRDS()?
>>  (*) extremely unlikely = if all of us would run this toy example we
>> would not end up with a non-detect but still corrupt "foo.rds" file
>> in, say, 10000 years.
>>
>> Background: The R.cache package allows memoization (caching of
>> results) to file such that the cache is persistent across R sessions.
>> The persistent part is achieved by writing cache files to the same
>> file directory.  This is safe when you run a single process, and even
>> if readRDS() would fail to read a cache file it is no big deal; the
>> memoization will just fail and the results will be recalculated and be
>> resaved.  The questions is what happens if you run this in parallel
>> and push it to the extreme; is there a risk that the memoization will
>> properly return but with invalid results.  I prefer not having to
>> synchronize this with a mutex/semaphore/common server, but instead
>> rely on this try-an-see approach (cf. the Ethernet protocol on shared
>> medium).  My guess (and hope) is that the risk is extremely unlikely
>> (*), but I'd like to hear if someone else thinks otherwise.
>>
>> Thanks,
>>
>> Henrik
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From simon.knapp at anu.edu.au  Sun Sep 16 04:50:38 2012
From: simon.knapp at anu.edu.au (Simon Knapp)
Date: Sun, 16 Sep 2012 12:50:38 +1000
Subject: [Rd] Question about copying arguments in C.
In-Reply-To: <B8786FE7-D663-4830-BAC6-248F948F124E@r-project.org>
References: <CAA+5f=0UFS3d-mqcpFizY6=WnRES8_0AoPQ7N6hYP-5QgUHWvQ@mail.gmail.com>
	<0D319C1D-CA32-4FDC-96C1-B97D40A31DCC@r-project.org>
	<CAA+5f=2kTQv1rhGG4u=d_XFaSOHi3avYFW9x2dmiObWQkDQpcQ@mail.gmail.com>
	<FDC086B4-3137-479B-A407-683C4E9C8B21@r-project.org>
	<B8786FE7-D663-4830-BAC6-248F948F124E@r-project.org>
Message-ID: <CAA+5f=2rDc=DO1fbfWoV173HfLyfmAhgJjYrpdEWuQMoVfo5dw@mail.gmail.com>

OK I think I'm getting it, but one more question if I may...

When I write a function, I don't protect the arguments explicitly (I
understand that they should be protected within the calling function)
- are my functions examples of functions that "protect their
arguments"? Looking at the code for setAttrib, which does explicitly
protect its first two arguments (why not the third???), I'd presume
the answer is no and hence that I should protect new SEXPs before
passing them to such functions.

Yet more thanks :-)
Simon



On Sun, Sep 16, 2012 at 5:08 AM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
>
> On Sep 15, 2012, at 2:57 PM, Simon Urbanek wrote:
>
>>
>> On Sep 15, 2012, at 11:28 AM, Simon Knapp wrote:
>>
>>> Hi Simon,
>>>
>>> Thanks for your advice, but I'm still not clear. In my case I don't
>>> want to modify the result - the integer acts as a handle for indexing
>>> an array in later calls back into my library.
>>>
>>> As I understand it, returning result like
>>>
>>> SEXP func(SEXP arg) {return arg;}
>>>
>>> would not copy arg and hence I would have two pointers to the same
>>> object immediately after the call... and (if this is the case) I'm not
>>> sure whether this is OK.
>>>
>>
>> My answer is was, yes, it's ok.
>>
>>
>>> Just to be clear, are you saying that the proper way to do things is
>>> (at the end of my function in the original post):
>>>
>>> SET_SLOT(ans, Rf_install("myInteger"), duplicate(thingysInteger));
>>> return ans;
>>>
>>> rather than
>>>
>>> SET_SLOT(ans, Rf_install("myInteger"), thingysInteger);
>>> return ans;
>>>
>>> ?
>>>
>>
>> No, because you're not modifying anything in that case.
>>
>>
>>> The last thing I'm not clear on is if it is OK to create a new SEXP
>>> (with a call like duplicate) in a call to another function (as in the
>>> first case above) or does this leave it unprotected?
>>>
>>
>> Most functions (but not all - a notable exception is eval) protect their arguments, so it's ok in most cases. But this is no different than any other SEXP result - not specific to duplicate() in particular.
>>
>
> Actually, I should explain a bit, because the above case is not about SET_SLOT protecting or not protecting arguments. In fact it does protect its arguments, but even when you are calling a function that protects its arguments, you can get into trouble. But let's take a more common example (since you really don't want to call duplicate() in your example) - let's say you want to do something like
>
> setAttrib(foo, install("bar"), mkString("bar"));
>
> Although setAttrib() is friendly an protects its arguments, the above is bad, because the mkString() is unprotected while install() is called. Now, symbols don't need protection, but it is possible that install() will trigger allocation, so the mkString() result is in danger. The best way around is something like
>
> SEXP bar = install("bar")
> setAttrib(foo, bar, mkString("bar"));
>
> Here mkString() is fine, because there cannot be an allocation before setAttrib() protects its arguments. Also bar is a symbol so it doesn't need to be protected, so the above is ok.


From simon.urbanek at r-project.org  Sun Sep 16 16:00:38 2012
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sun, 16 Sep 2012 10:00:38 -0400
Subject: [Rd] Question about copying arguments in C.
In-Reply-To: <CAA+5f=2rDc=DO1fbfWoV173HfLyfmAhgJjYrpdEWuQMoVfo5dw@mail.gmail.com>
References: <CAA+5f=0UFS3d-mqcpFizY6=WnRES8_0AoPQ7N6hYP-5QgUHWvQ@mail.gmail.com>
	<0D319C1D-CA32-4FDC-96C1-B97D40A31DCC@r-project.org>
	<CAA+5f=2kTQv1rhGG4u=d_XFaSOHi3avYFW9x2dmiObWQkDQpcQ@mail.gmail.com>
	<FDC086B4-3137-479B-A407-683C4E9C8B21@r-project.org>
	<B8786FE7-D663-4830-BAC6-248F948F124E@r-project.org>
	<CAA+5f=2rDc=DO1fbfWoV173HfLyfmAhgJjYrpdEWuQMoVfo5dw@mail.gmail.com>
Message-ID: <20FC2C95-76C9-4B3B-9581-7B8CD35F1F92@r-project.org>


On Sep 15, 2012, at 10:50 PM, Simon Knapp wrote:

> OK I think I'm getting it, but one more question if I may...
> 
> When I write a function, I don't protect the arguments explicitly (I understand that they should be protected within the calling function) - are my functions examples of functions that "protect their arguments"?

The way I understand your question, no. 


> Looking at the code for setAttrib, which does explicitly protect its first two arguments (why not the third???

That's actually  a good question :) - for the case of TYPEOF(name) == SYMSXP it doesn't need to because there is no allocation in the path until val is used, but for TYPEOF(name) == STRSXP there is a potential allocation in the handling of name. That could very well be a bug ...


> ), I'd presume the answer is no and hence that I should protect new SEXPs before
> passing them to such functions.
> 

Yes. Note that PROTECT has a fairly low cost so if in doubt, it's better to over-protect.

Cheers,
Simon


> Yet more thanks :-)
> Simon
> 
> 
> 
> On Sun, Sep 16, 2012 at 5:08 AM, Simon Urbanek
> <simon.urbanek at r-project.org> wrote:
>> 
>> On Sep 15, 2012, at 2:57 PM, Simon Urbanek wrote:
>> 
>>> 
>>> On Sep 15, 2012, at 11:28 AM, Simon Knapp wrote:
>>> 
>>>> Hi Simon,
>>>> 
>>>> Thanks for your advice, but I'm still not clear. In my case I don't
>>>> want to modify the result - the integer acts as a handle for indexing
>>>> an array in later calls back into my library.
>>>> 
>>>> As I understand it, returning result like
>>>> 
>>>> SEXP func(SEXP arg) {return arg;}
>>>> 
>>>> would not copy arg and hence I would have two pointers to the same
>>>> object immediately after the call... and (if this is the case) I'm not
>>>> sure whether this is OK.
>>>> 
>>> 
>>> My answer is was, yes, it's ok.
>>> 
>>> 
>>>> Just to be clear, are you saying that the proper way to do things is
>>>> (at the end of my function in the original post):
>>>> 
>>>> SET_SLOT(ans, Rf_install("myInteger"), duplicate(thingysInteger));
>>>> return ans;
>>>> 
>>>> rather than
>>>> 
>>>> SET_SLOT(ans, Rf_install("myInteger"), thingysInteger);
>>>> return ans;
>>>> 
>>>> ?
>>>> 
>>> 
>>> No, because you're not modifying anything in that case.
>>> 
>>> 
>>>> The last thing I'm not clear on is if it is OK to create a new SEXP
>>>> (with a call like duplicate) in a call to another function (as in the
>>>> first case above) or does this leave it unprotected?
>>>> 
>>> 
>>> Most functions (but not all - a notable exception is eval) protect their arguments, so it's ok in most cases. But this is no different than any other SEXP result - not specific to duplicate() in particular.
>>> 
>> 
>> Actually, I should explain a bit, because the above case is not about SET_SLOT protecting or not protecting arguments. In fact it does protect its arguments, but even when you are calling a function that protects its arguments, you can get into trouble. But let's take a more common example (since you really don't want to call duplicate() in your example) - let's say you want to do something like
>> 
>> setAttrib(foo, install("bar"), mkString("bar"));
>> 
>> Although setAttrib() is friendly an protects its arguments, the above is bad, because the mkString() is unprotected while install() is called. Now, symbols don't need protection, but it is possible that install() will trigger allocation, so the mkString() result is in danger. The best way around is something like
>> 
>> SEXP bar = install("bar")
>> setAttrib(foo, bar, mkString("bar"));
>> 
>> Here mkString() is fine, because there cannot be an allocation before setAttrib() protects its arguments. Also bar is a symbol so it doesn't need to be protected, so the above is ok.
> 
> 


From tcallawa at redhat.com  Mon Sep 17 19:30:17 2012
From: tcallawa at redhat.com (Tom Callaway)
Date: Mon, 17 Sep 2012 13:30:17 -0400
Subject: [Rd] R Segfault reported in Fedora 17
Message-ID: <50575E29.7050605@redhat.com>

Full details, including all sorts of logs here:

https://bugzilla.redhat.com/show_bug.cgi?id=857655

A very quick look doesn't show anything obvious, in fact, it might be a
readline bug, but readline is remarkably stable and boring these days.

~tom

==
Fedora Project


From pdalgd at gmail.com  Mon Sep 17 19:55:07 2012
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 17 Sep 2012 19:55:07 +0200
Subject: [Rd] R Segfault reported in Fedora 17
In-Reply-To: <50575E29.7050605@redhat.com>
References: <50575E29.7050605@redhat.com>
Message-ID: <7CA6DF2E-4909-4827-A954-6E60C0240A4D@gmail.com>


On Sep 17, 2012, at 19:30 , Tom Callaway wrote:

> Full details, including all sorts of logs here:
> 
> https://bugzilla.redhat.com/show_bug.cgi?id=857655
> 
> A very quick look doesn't show anything obvious, in fact, it might be a
> readline bug, but readline is remarkably stable and boring these days.

Very hard to find this sort of bug without reproducibility instructions.

But the bug report says that it is a SIGABRT, not SIGSEGV. That's a different kettle of fish isn't it?

> 
> ~tom
> 
> ==
> Fedora Project
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From tcallawa at redhat.com  Mon Sep 17 20:59:57 2012
From: tcallawa at redhat.com (Tom Callaway)
Date: Mon, 17 Sep 2012 14:59:57 -0400
Subject: [Rd] R Segfault reported in Fedora 17
In-Reply-To: <7CA6DF2E-4909-4827-A954-6E60C0240A4D@gmail.com>
References: <50575E29.7050605@redhat.com>
	<7CA6DF2E-4909-4827-A954-6E60C0240A4D@gmail.com>
Message-ID: <5057732D.30008@redhat.com>

On 09/17/2012 01:55 PM, peter dalgaard wrote:
> Very hard to find this sort of bug without reproducibility instructions.

I agree, especially if the bug is in readline somewhere.

> But the bug report says that it is a SIGABRT, not SIGSEGV. That's a different kettle of fish isn't it?

Yep. It sure is. Just wanted to put in on your radar in case it ends up
being helpful. I don't have any real plans to try to dig deeper into it,
since this is the first such report (and Fedora has automated mechanisms
for reporting crashed apps).

~tom

==
Fedora Project


From pgilbert902 at gmail.com  Tue Sep 18 23:40:36 2012
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Tue, 18 Sep 2012 17:40:36 -0400
Subject: [Rd] problem with vignettes when S4 classes in packages overlap
Message-ID: <5058EA54.8050305@gmail.com>


( A similar problem is also reported by Sebastian P. Luque with
   library(maptools)
   library(trip)
in the vignette as below ).

I am writing a vignette which loads RMySQL and RPostgreSQL. This 
produces the warning:

Loading required package: DBI
Warning in .simpleDuplicateClass(def, prev) :
   A specification for class ?dbObjectId? in package ?RPostgreSQL? seems 
equivalent to one from package ?RMySQL? and is not turning on duplicate 
class definitions for this class

This can be reproduced by running
   R CMD Sweave --pdf Atest.Stex

where the file Atest.Stex has the lines

\documentclass{article}
\usepackage{Sweave}
\begin{document}
\begin{Scode}
library("RMySQL")
library("RPostgreSQL")
\end{Scode}
\end{document}

These warnings only happen in a vignette. They are not produced if the 
lines are entered in an R session.

(Using R version 2.15.1 (2012-06-22) -- "Roasted Marshmallows" on Ubuntu)

Paul


From murdoch.duncan at gmail.com  Wed Sep 19 01:23:47 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 18 Sep 2012 19:23:47 -0400
Subject: [Rd] problem with vignettes when S4 classes in packages overlap
In-Reply-To: <5058EA54.8050305@gmail.com>
References: <5058EA54.8050305@gmail.com>
Message-ID: <50590283.4030700@gmail.com>

On 12-09-18 5:40 PM, Paul Gilbert wrote:
>
> ( A similar problem is also reported by Sebastian P. Luque with
>     library(maptools)
>     library(trip)
> in the vignette as below ).
>
> I am writing a vignette which loads RMySQL and RPostgreSQL. This
> produces the warning:
>
> Loading required package: DBI
> Warning in .simpleDuplicateClass(def, prev) :
>     A specification for class ?dbObjectId? in package ?RPostgreSQL? seems
> equivalent to one from package ?RMySQL? and is not turning on duplicate
> class definitions for this class
>
> This can be reproduced by running
>     R CMD Sweave --pdf Atest.Stex
>
> where the file Atest.Stex has the lines
>
> \documentclass{article}
> \usepackage{Sweave}
> \begin{document}
> \begin{Scode}
> library("RMySQL")
> library("RPostgreSQL")
> \end{Scode}
> \end{document}
>
> These warnings only happen in a vignette. They are not produced if the
> lines are entered in an R session.
>
> (Using R version 2.15.1 (2012-06-22) -- "Roasted Marshmallows" on Ubunt

You'll get the warning in a regular session if you set options(warn=1). 
  I think Sweave is probably doing this so that warnings show up around 
the time of the chunk they correspond to.  It does it in the command 
line version, but not in the Sweave() function (which would save them up 
to the end).

I don't know if the warning is something you should worry about or not.

Duncan Murdoch


From spencer.graves at prodsyse.com  Wed Sep 19 01:50:30 2012
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Tue, 18 Sep 2012 16:50:30 -0700
Subject: [Rd] problem with vignettes when S4 classes in packages overlap
In-Reply-To: <50590283.4030700@gmail.com>
References: <5058EA54.8050305@gmail.com> <50590283.4030700@gmail.com>
Message-ID: <505908C6.2090602@prodsyse.com>

On 9/18/2012 4:23 PM, Duncan Murdoch wrote:
> On 12-09-18 5:40 PM, Paul Gilbert wrote:
>>
>> ( A similar problem is also reported by Sebastian P. Luque with
>>     library(maptools)
>>     library(trip)
>> in the vignette as below ).
>>
>> I am writing a vignette which loads RMySQL and RPostgreSQL. This
>> produces the warning:
>>
>> Loading required package: DBI
>> Warning in .simpleDuplicateClass(def, prev) :
>>     A specification for class ?dbObjectId? in package ?RPostgreSQL? 
>> seems
>> equivalent to one from package ?RMySQL? and is not turning on duplicate
>> class definitions for this class
>>
>> This can be reproduced by running
>>     R CMD Sweave --pdf Atest.Stex
>>
>> where the file Atest.Stex has the lines
>>
>> \documentclass{article}
>> \usepackage{Sweave}
>> \begin{document}
>> \begin{Scode}
>> library("RMySQL")
>> library("RPostgreSQL")
>> \end{Scode}
>> \end{document}
>>
>> These warnings only happen in a vignette. They are not produced if the
>> lines are entered in an R session.
>>
>> (Using R version 2.15.1 (2012-06-22) -- "Roasted Marshmallows" on Ubunt
>
> You'll get the warning in a regular session if you set 
> options(warn=1).  I think Sweave is probably doing this so that 
> warnings show up around the time of the chunk they correspond to. It 
> does it in the command line version, but not in the Sweave() function 
> (which would save them up to the end).
>
> I don't know if the warning is something you should worry about or not.


       On August 30, 2012, CRAN maintainers rejected the latest version 
of "fda", and I understood them to say it was rejected because the 
current CRAN policy did not accept packages reporting either "Notes" or 
"Warnings".  As part of my efforts to comply with this, I started the 
thread on [Rd] subject:  "if(--as-cran)?"  I added a function "CRAN" to 
"fda", and I thought someone had added a more general function to the 
development version of R. Unfortunately, I can't find documentation of 
that more general function now.


       Spencer

>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From pgilbert902 at gmail.com  Wed Sep 19 01:56:23 2012
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Tue, 18 Sep 2012 19:56:23 -0400
Subject: [Rd] problem with vignettes when S4 classes in packages overlap
In-Reply-To: <50590283.4030700@gmail.com>
References: <5058EA54.8050305@gmail.com> <50590283.4030700@gmail.com>
Message-ID: <50590A27.8010709@gmail.com>



On 12-09-18 07:23 PM, Duncan Murdoch wrote:
> On 12-09-18 5:40 PM, Paul Gilbert wrote:
>>
>> ( A similar problem is also reported by Sebastian P. Luque with
>>     library(maptools)
>>     library(trip)
>> in the vignette as below ).
>>
>> I am writing a vignette which loads RMySQL and RPostgreSQL. This
>> produces the warning:
>>
>> Loading required package: DBI
>> Warning in .simpleDuplicateClass(def, prev) :
>>     A specification for class ?dbObjectId? in package ?RPostgreSQL? seems
>> equivalent to one from package ?RMySQL? and is not turning on duplicate
>> class definitions for this class
>>
>> This can be reproduced by running
>>     R CMD Sweave --pdf Atest.Stex
>>
>> where the file Atest.Stex has the lines
>>
>> \documentclass{article}
>> \usepackage{Sweave}
>> \begin{document}
>> \begin{Scode}
>> library("RMySQL")
>> library("RPostgreSQL")
>> \end{Scode}
>> \end{document}
>>
>> These warnings only happen in a vignette. They are not produced if the
>> lines are entered in an R session.
>>
>> (Using R version 2.15.1 (2012-06-22) -- "Roasted Marshmallows" on Ubunt
>
> You'll get the warning in a regular session if you set options(warn=1).
>   I think Sweave is probably doing this so that warnings show up around
> the time of the chunk they correspond to.  It does it in the command
> line version, but not in the Sweave() function (which would save them up
> to the end).
>
> I don't know if the warning is something you should worry about or not.

It doesn't interfere with producing the vignette, but for submitting to 
CRAN it is better not to have warnings coming from my package, even 
though they are caused by a problem with other packages. Now that I know 
why it only happens in the vignette, I guess I can suppress it (but it 
would be nice to see the other packages fixed).

Thanks,
Paul
>
> Duncan Murdoch


From murdoch.duncan at gmail.com  Wed Sep 19 02:53:35 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 18 Sep 2012 20:53:35 -0400
Subject: [Rd] problem with vignettes when S4 classes in packages overlap
In-Reply-To: <505908C6.2090602@prodsyse.com>
References: <5058EA54.8050305@gmail.com> <50590283.4030700@gmail.com>
	<505908C6.2090602@prodsyse.com>
Message-ID: <5059178F.8010302@gmail.com>

On 12-09-18 7:50 PM, Spencer Graves wrote:
> On 9/18/2012 4:23 PM, Duncan Murdoch wrote:
>> On 12-09-18 5:40 PM, Paul Gilbert wrote:
>>>
>>> ( A similar problem is also reported by Sebastian P. Luque with
>>>      library(maptools)
>>>      library(trip)
>>> in the vignette as below ).
>>>
>>> I am writing a vignette which loads RMySQL and RPostgreSQL. This
>>> produces the warning:
>>>
>>> Loading required package: DBI
>>> Warning in .simpleDuplicateClass(def, prev) :
>>>      A specification for class ?dbObjectId? in package ?RPostgreSQL?
>>> seems
>>> equivalent to one from package ?RMySQL? and is not turning on duplicate
>>> class definitions for this class
>>>
>>> This can be reproduced by running
>>>      R CMD Sweave --pdf Atest.Stex
>>>
>>> where the file Atest.Stex has the lines
>>>
>>> \documentclass{article}
>>> \usepackage{Sweave}
>>> \begin{document}
>>> \begin{Scode}
>>> library("RMySQL")
>>> library("RPostgreSQL")
>>> \end{Scode}
>>> \end{document}
>>>
>>> These warnings only happen in a vignette. They are not produced if the
>>> lines are entered in an R session.
>>>
>>> (Using R version 2.15.1 (2012-06-22) -- "Roasted Marshmallows" on Ubunt
>>
>> You'll get the warning in a regular session if you set
>> options(warn=1).  I think Sweave is probably doing this so that
>> warnings show up around the time of the chunk they correspond to. It
>> does it in the command line version, but not in the Sweave() function
>> (which would save them up to the end).
>>
>> I don't know if the warning is something you should worry about or not.
>
>
>         On August 30, 2012, CRAN maintainers rejected the latest version
> of "fda", and I understood them to say it was rejected because the
> current CRAN policy did not accept packages reporting either "Notes" or
> "Warnings".  As part of my efforts to comply with this, I started the
> thread on [Rd] subject:  "if(--as-cran)?"  I added a function "CRAN" to
> "fda", and I thought someone had added a more general function to the
> development version of R. Unfortunately, I can't find documentation of
> that more general function now.

I don't remember for sure, but I don't think your warning or note was 
the same as Paul's.  Generally it's not a good idea to suppress 
warnings.  Someone should fix things so there's no warning.  I don't 
know if that should be RCore because the methods package is issuing a 
bogus warning, or the maintainer of one of the database packages, or 
Paul.   (From his example, it doesn't look like it should be Paul, 
unless docs somewhere say that RMySQL and RPostgreSQL can't be used 
together.)

In general, as a package user, I don't want people to be able to 
suppress checks on CRAN.  I want things fixed.

So I am pretty sure there won't ever be a reliable "CRAN-detector" put 
into R.  It would devalue the brand.

Duncan Murdoch


From edd at debian.org  Wed Sep 19 03:44:39 2012
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 18 Sep 2012 20:44:39 -0500
Subject: [Rd] problem with vignettes when S4 classes in packages overlap
In-Reply-To: <505908C6.2090602@prodsyse.com>
References: <5058EA54.8050305@gmail.com> <50590283.4030700@gmail.com>
	<505908C6.2090602@prodsyse.com>
Message-ID: <20569.9095.692619.290161@max.nulle.part>


On 18 September 2012 at 16:50, Spencer Graves wrote:
|        On August 30, 2012, CRAN maintainers rejected the latest version 
| of "fda", and I understood them to say it was rejected because the 
| current CRAN policy did not accept packages reporting either "Notes" or 
| "Warnings".  

That is not what the "CRAN Repository Policy" document says:

  * Please ensure that R CMD check --as-cran has been run on the tarball to
    be uploaded before submission. This should be done with the current release
    of R or (preferably) R-devel or R-patched. As ?Writing R Extensions? says

       Please ensure that you can run through the complete procedure with
       only warnings that you understand and have reasons not to
       eliminate. In principle, packages must pass R CMD check without
       warnings or significant notes to be admitted to the main CRAN package
       area. If there are warnings or notes you cannot eliminate (for example
       because you believe them to be spurious) send an explanatory note as
       part of your covering email.

Notr the qualifier "significant" in front of notes, so it is not "all notes" as
you imply. 

Now, if would of course help if CRAN could specify what "significant notes" were ...

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com  


From spencer.graves at prodsyse.com  Wed Sep 19 04:02:49 2012
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Tue, 18 Sep 2012 19:02:49 -0700
Subject: [Rd] problem with vignettes when S4 classes in packages overlap
In-Reply-To: <5059178F.8010302@gmail.com>
References: <5058EA54.8050305@gmail.com> <50590283.4030700@gmail.com>
	<505908C6.2090602@prodsyse.com> <5059178F.8010302@gmail.com>
Message-ID: <505927C9.8090909@prodsyse.com>

On 9/18/2012 5:53 PM, Duncan Murdoch wrote:
> On 12-09-18 7:50 PM, Spencer Graves wrote:
>> On 9/18/2012 4:23 PM, Duncan Murdoch wrote:
>>> On 12-09-18 5:40 PM, Paul Gilbert wrote:
>>>>
>>>> ( A similar problem is also reported by Sebastian P. Luque with
>>>>      library(maptools)
>>>>      library(trip)
>>>> in the vignette as below ).
>>>>
>>>> I am writing a vignette which loads RMySQL and RPostgreSQL. This
>>>> produces the warning:
>>>>
>>>> Loading required package: DBI
>>>> Warning in .simpleDuplicateClass(def, prev) :
>>>>      A specification for class ?dbObjectId? in package ?RPostgreSQL?
>>>> seems
>>>> equivalent to one from package ?RMySQL? and is not turning on 
>>>> duplicate
>>>> class definitions for this class
>>>>
>>>> This can be reproduced by running
>>>>      R CMD Sweave --pdf Atest.Stex
>>>>
>>>> where the file Atest.Stex has the lines
>>>>
>>>> \documentclass{article}
>>>> \usepackage{Sweave}
>>>> \begin{document}
>>>> \begin{Scode}
>>>> library("RMySQL")
>>>> library("RPostgreSQL")
>>>> \end{Scode}
>>>> \end{document}
>>>>
>>>> These warnings only happen in a vignette. They are not produced if the
>>>> lines are entered in an R session.
>>>>
>>>> (Using R version 2.15.1 (2012-06-22) -- "Roasted Marshmallows" on 
>>>> Ubunt
>>>
>>> You'll get the warning in a regular session if you set
>>> options(warn=1).  I think Sweave is probably doing this so that
>>> warnings show up around the time of the chunk they correspond to. It
>>> does it in the command line version, but not in the Sweave() function
>>> (which would save them up to the end).
>>>
>>> I don't know if the warning is something you should worry about or not.
>>
>>
>>         On August 30, 2012, CRAN maintainers rejected the latest version
>> of "fda", and I understood them to say it was rejected because the
>> current CRAN policy did not accept packages reporting either "Notes" or
>> "Warnings".  As part of my efforts to comply with this, I started the
>> thread on [Rd] subject:  "if(--as-cran)?"  I added a function "CRAN" to
>> "fda", and I thought someone had added a more general function to the
>> development version of R. Unfortunately, I can't find documentation of
>> that more general function now.
>
> I don't remember for sure, but I don't think your warning or note was 
> the same as Paul's.  Generally it's not a good idea to suppress 
> warnings.  Someone should fix things so there's no warning.  I don't 
> know if that should be RCore because the methods package is issuing a 
> bogus warning, or the maintainer of one of the database packages, or 
> Paul.   (From his example, it doesn't look like it should be Paul, 
> unless docs somewhere say that RMySQL and RPostgreSQL can't be used 
> together.)
>
> In general, as a package user, I don't want people to be able to 
> suppress checks on CRAN.  I want things fixed.
>
> So I am pretty sure there won't ever be a reliable "CRAN-detector" put 
> into R.  It would devalue the brand.


       Our primary use of the "CRAN" function is to reduce test time:  
Some of our "\examples" ran over 10 seconds on CRAN, and the package was 
rejected on that basis.


       With now over 4,000 packages on CRAN, maintaining it is taxing 
the commitments of our volunteer CRAN maintainers.  I believe the world 
would be better off if people like Brian Ripley, Kurt Hornik, and Uwe 
Ligges could hire (more) competent systems administrators and buy (more) 
hardware to manage the details, so Ripley, Hornik, Ligges and others 
could spend more time developing new statistical algorithms and helping 
others with their responses on this list.


       Assuming money is part of the problem, Jim Ramsay suggested that 
CRAN issue a pro forma invoice to CRAN package maintainers for, say, 100 
Euros each.  Maintainers would be asked to pay it if they have a grant 
that would support that but would be invited to plead poverty if they 
don't.  This would be similar to the current page charges with some 
journals, which are forgiven for authors who would have to pay out of 
their own pockets.  Ramsay said he would happily pay some reasonable 
amount, but he needs an invoice.


       The same goes for R-Forge:  It's a great service to the R 
Community -- benefiting the entirety of humanity through the improved 
decisions that R facilitates.  They, too, could offer a better service 
if they had a larger budget, I think.


       Best Wishes,
       Spencer

>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567
web:  www.structuremonitoring.com


From Roger.Bivand at nhh.no  Wed Sep 19 10:06:10 2012
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 19 Sep 2012 10:06:10 +0200 (CEST)
Subject: [Rd] problem with vignettes when S4 classes in packages overlap
In-Reply-To: <5058EA54.8050305@gmail.com>
References: <5058EA54.8050305@gmail.com>
Message-ID: <alpine.LRH.2.02.1209190946151.1094@reclus.nhh.no>

On Tue, 18 Sep 2012, Paul Gilbert wrote:

>
> ( A similar problem is also reported by Sebastian P. Luque with
>  library(maptools)
>  library(trip)
> in the vignette as below ).

Thanks for bringing this up. This is caused by maptools avoiding: Depends: 
spatstat, which might create circularities. maptools and spatstat (which 
defines the classes that maptools and trip augment by adding coercion to 
and from their own or sp classes) mutually Suggest: each other. trip 
Depends: spatstat, but out of the box has no NAMESPACE - I haven't 
investigated whether adding one helps.

Adding maptools to trip::Depends removes the warnings; check passes as 
before, so no side-effects I can see. The auto-generated NAMESPACE is 
then:

# Default NAMESPACE created by R
# Remove the previous line if you edit this file

# Export all names
exportPattern(".")

# Import all packages listed as Imports or Depends
import(
   methods,
   sp,
   spatstat,
   maptools
)

Since trip was last updated in May 2011, it is missing both a NAMESPACE 
file, and suggestion of the correct adehabitat?? package(s) - adehabitat 
is deprecated. I don't think that this is an S4 problem, I think it is 
about keeping packages in sync with the R engine, especially with regard 
to NAMESPACE, etc., and with packages named in DESCRIPTION. This may carry 
over to the main case here, but I haven't checked.

Roger

>
> I am writing a vignette which loads RMySQL and RPostgreSQL. This produces the 
> warning:
>
> Loading required package: DBI
> Warning in .simpleDuplicateClass(def, prev) :
>  A specification for class ?dbObjectId? in package ?RPostgreSQL? seems 
> equivalent to one from package ?RMySQL? and is not turning on duplicate class 
> definitions for this class
>
> This can be reproduced by running
>  R CMD Sweave --pdf Atest.Stex
>
> where the file Atest.Stex has the lines
>
> \documentclass{article}
> \usepackage{Sweave}
> \begin{document}
> \begin{Scode}
> library("RMySQL")
> library("RPostgreSQL")
> \end{Scode}
> \end{document}
>
> These warnings only happen in a vignette. They are not produced if the lines 
> are entered in an R session.
>
> (Using R version 2.15.1 (2012-06-22) -- "Roasted Marshmallows" on Ubuntu)
>
> Paul
>

-- 
Roger Bivand
Department of Economics, NHH Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From karlmzhang at gmail.com  Wed Sep 19 02:55:40 2012
From: karlmzhang at gmail.com (Qi Zhang)
Date: Tue, 18 Sep 2012 20:55:40 -0400
Subject: [Rd] Rcmd check problem
Message-ID: <CAHMG3xfpO3WOUb=kv1TFD6Cq1n8H+tyb9y5K=c8mEtnV_yZAyA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120918/89e558c4/attachment.pl>

From murdoch.duncan at gmail.com  Wed Sep 19 14:12:14 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 19 Sep 2012 08:12:14 -0400
Subject: [Rd] Rcmd check problem
In-Reply-To: <CAHMG3xfpO3WOUb=kv1TFD6Cq1n8H+tyb9y5K=c8mEtnV_yZAyA@mail.gmail.com>
References: <CAHMG3xfpO3WOUb=kv1TFD6Cq1n8H+tyb9y5K=c8mEtnV_yZAyA@mail.gmail.com>
Message-ID: <5059B69E.2050609@gmail.com>

On 18/09/2012 8:55 PM, Qi Zhang wrote:
> Hi, all.
>
> I was trying to build my R package with R 2.15.1 32bit and win7.
>
> I basically follow the routine in Steven Mosher's blog
> http://stevemosher.wordpress.com/step-10-build/
>
> After I fixed the path, and built the skeleton of the package, I started
> command prompt and used the following commands in building my package
>
> Rcmd check myPackageName
>
> Rcmd build myPackageName
>
> Rcmd check myPackageName.tar.gz
>
> Rcmd INSTALL --build myPackageName.tar.gz
>
> Rcmd check myPackageName.zip

The check process is designed to work on source tar files, but also 
works (sometimes with some extra warnings) on package directories. It 
won't work on binary packages at all.

I recommend reading the documentation.  Blogs are often out of date or 
wrong for other reasons.  (If you were following instructions there, 
this is an example of the latter.  It has never been correct to run 
check on a .zip file.)

Duncan Murdoch

>
> The last check command return me an error
>
> Rcmd check myPackageName.zip
>
> Error in rawToChar(block[seq_len(ns)]) :
>    embedded nul in string:
> 'PK\003\004\n\0\0\0\0\0}?1A\0\0\0\0\0\0\0\0\0\0\0\0\f\
> 0\0\0myPackageName/PK\003\004\n\0\0\0\0\0y?1A\0\0\0\0\0\0\0\0\0\0\0\0\021\0\0\0myPackageName/demo/PK\003\004\024\0\002\0\b\0y'
> Execution halted
>
> I do not know what it means. On the other hand, we I
> load  myPackageName.zip as a package from the local zip file, it works. I
> did not get any error from my other two Rcmd check commands neither.
>
> I am wondering whether the returned error of Rcmd check means anything, and
> whether my package can be uploaded to CRAN without much trouble.
>
> Thanks.
>
> Best,
>
> Qi
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.tu-dortmund.de  Wed Sep 19 14:14:16 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 19 Sep 2012 14:14:16 +0200
Subject: [Rd] Rcmd check problem
In-Reply-To: <CAHMG3xfpO3WOUb=kv1TFD6Cq1n8H+tyb9y5K=c8mEtnV_yZAyA@mail.gmail.com>
References: <CAHMG3xfpO3WOUb=kv1TFD6Cq1n8H+tyb9y5K=c8mEtnV_yZAyA@mail.gmail.com>
Message-ID: <5059B718.2090105@statistik.tu-dortmund.de>



On 19.09.2012 02:55, Qi Zhang wrote:
> Hi, all.
>
> I was trying to build my R package with R 2.15.1 32bit and win7.
>
> I basically follow the routine in Steven Mosher's blog
> http://stevemosher.wordpress.com/step-10-build/
>
> After I fixed the path, and built the skeleton of the package, I started
> command prompt and used the following commands in building my package
>
> Rcmd check myPackageName
>
> Rcmd build myPackageName
>
> Rcmd check myPackageName.tar.gz
>
> Rcmd INSTALL --build myPackageName.tar.gz
>
> Rcmd check myPackageName.zip
>
> The last check command return me an error
>
> Rcmd check myPackageName.zip


You cannot run R CMD check on a binary package. Just run it on the 
source package.

Uwe Ligges



> Error in rawToChar(block[seq_len(ns)]) :
>    embedded nul in string:
> 'PK\003\004\n\0\0\0\0\0}?1A\0\0\0\0\0\0\0\0\0\0\0\0\f\
> 0\0\0myPackageName/PK\003\004\n\0\0\0\0\0y?1A\0\0\0\0\0\0\0\0\0\0\0\0\021\0\0\0myPackageName/demo/PK\003\004\024\0\002\0\b\0y'
> Execution halted
>
> I do not know what it means. On the other hand, we I
> load  myPackageName.zip as a package from the local zip file, it works. I
> did not get any error from my other two Rcmd check commands neither.
>
> I am wondering whether the returned error of Rcmd check means anything, and
> whether my package can be uploaded to CRAN without much trouble.
>
> Thanks.
>
> Best,
>
> Qi
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From mdsumner at gmail.com  Wed Sep 19 14:44:12 2012
From: mdsumner at gmail.com (Michael Sumner)
Date: Wed, 19 Sep 2012 22:44:12 +1000
Subject: [Rd] problem with vignettes when S4 classes in packages overlap
In-Reply-To: <alpine.LRH.2.02.1209190946151.1094@reclus.nhh.no>
References: <5058EA54.8050305@gmail.com>
	<alpine.LRH.2.02.1209190946151.1094@reclus.nhh.no>
Message-ID: <CAAcGz984fRpbw86Xmxrt9iC7_mE9AFLfjyP2JVOHARXFPKk0Sg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120919/040ee264/attachment.pl>

From therneau at mayo.edu  Wed Sep 19 16:08:56 2012
From: therneau at mayo.edu (Terry Therneau)
Date: Wed, 19 Sep 2012 09:08:56 -0500
Subject: [Rd] R-devel Digest, Vol 115, Issue 18
In-Reply-To: <mailman.29.1348048809.29913.r-devel@r-project.org>
References: <mailman.29.1348048809.29913.r-devel@r-project.org>
Message-ID: <5059D1F8.1070501@mayo.edu>

> In general, as a package user, I don't want people to be able to
> suppress checks on CRAN.  I want things fixed.
>
> So I am pretty sure there won't ever be a reliable "CRAN-detector" put
> into R.  It would devalue the brand.
>
> Duncan Murdoch

My problem is that CRAN demands that I suppress a large fraction of my checks, in order to 
fit within time constraints.  This leaves me with 3 choices.

1. Add lines to my code that tries to guess if CRAN is invoker.  A cat and mouse game per 
your desire above.

2. Remove large portions of my test suite.  I consider the survival package to be one of 
the pre-eminent current code sets in the world precisely because of the extensive 
validations, this action would change it to a second class citizen.

3. Add a magic environment variable to my local world, only do the full tests if it is 
present, and make the dumbed down version the default.  Others who want to run the full 
set are then SOL, which I very much don't like.

I agree that CRAN avoidence, other than the time constraint, should be verboten.  But I 
don't think that security through obscurity is the answer.  And note that under scenario 
3, which is essentially what is currently being forced on us, I can do such micshief as 
easily as under number 1.

Terry Therneau


From murdoch.duncan at gmail.com  Wed Sep 19 16:22:52 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 19 Sep 2012 10:22:52 -0400
Subject: [Rd] R-devel Digest, Vol 115, Issue 18
In-Reply-To: <5059D1F8.1070501@mayo.edu>
References: <mailman.29.1348048809.29913.r-devel@r-project.org>
	<5059D1F8.1070501@mayo.edu>
Message-ID: <5059D53C.2090007@gmail.com>

On 19/09/2012 10:08 AM, Terry Therneau wrote:
> > In general, as a package user, I don't want people to be able to
> > suppress checks on CRAN.  I want things fixed.
> >
> > So I am pretty sure there won't ever be a reliable "CRAN-detector" put
> > into R.  It would devalue the brand.
> >
> > Duncan Murdoch
>
> My problem is that CRAN demands that I suppress a large fraction of my checks, in order to
> fit within time constraints.  This leaves me with 3 choices.
>
> 1. Add lines to my code that tries to guess if CRAN is invoker.  A cat and mouse game per
> your desire above.
>
> 2. Remove large portions of my test suite.  I consider the survival package to be one of
> the pre-eminent current code sets in the world precisely because of the extensive
> validations, this action would change it to a second class citizen.
>
> 3. Add a magic environment variable to my local world, only do the full tests if it is
> present, and make the dumbed down version the default.  Others who want to run the full
> set are then SOL, which I very much don't like.
>
> I agree that CRAN avoidence, other than the time constraint, should be verboten.  But I
> don't think that security through obscurity is the answer.  And note that under scenario
> 3, which is essentially what is currently being forced on us, I can do such micshief as
> easily as under number 1.
>
> Terry Therneau

I understand the issue with time constraints on checks, and I think 
there are discussions in progress about that.  My suggestion has been to 
put in place a way for a tester to say that checks need to be run within 
a tight time limit, and CRAN as tester will do that in cases where it 
cares about the timing.

But even with the current (or past, it may have changed already) 
behaviour of tight limits for CRAN testing, you can put in code in your 
package that allows for longer tests in certain conditions. You'll run 
them, and if you advertise them, others will run them too.

Duncan Murdoch


From pgilbert902 at gmail.com  Wed Sep 19 17:06:28 2012
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Wed, 19 Sep 2012 11:06:28 -0400
Subject: [Rd] CRAN test  / avoidance
In-Reply-To: <5059D1F8.1070501@mayo.edu>
References: <mailman.29.1348048809.29913.r-devel@r-project.org>
	<5059D1F8.1070501@mayo.edu>
Message-ID: <5059DF74.3070200@gmail.com>

( subject changed from Re: [Rd] R-devel Digest, Vol 115, Issue 18 )

I have the impression from this, and previous discussions on the 
subject, that package developers and CRAN maintainers are talking at 
cross-purposes. Many package maintainers are thinking that they should 
be responsible for choosing which tests are run and which are not run by 
CRAN, whereas CRAN maintainers may want to run all possible tests 
sometimes, or a trimmed down set when time constraints demand this. With 
good reason, CRAN may want to run all possible tests sometimes. There 
are too many packages on CRAN that remain there because they don't have 
any testing or vignettes, and very few examples. Encouraging more of 
that is a bad thing.

If I understand correctly, the --as-cran option was introduced to help 
developers specify options that CRAN uses, so they would find problems 
that CRAN would notice, and correct before submitting. The Rd 
discussions of this have morphed into a discussion of how package 
developers can use --as-cran to control which tests are run by CRAN.

I tend to be more sympathetic with what I call the CRAN maintainer view 
above, even though I am a package developer. I think packages should 
have extensive testing and that all the tests should go in the source 
package on CRAN, so the testing is available for CRAN and everyone else. 
(Although, it is sometimes not clear if CRAN maintainers like me doing 
this, because they are torn between time demands and maintaining quality 
- that is part of the confusion.)

The question becomes: how does information get passed along to indicate 
things that may take a long time to run. The discussion so far has 
focused on developers setting, or using, some flags to indicate tests 
and examples that take a long time. Another option would be to have the 
check/build process generate a file with information about the time it 
took to run tests, vignettes, and examples, probably with some 
information about the speed of the machine it was run on. Then CRAN and 
anyone else that wants to run tests can take this information into 
consideration.

Paul

On 12-09-19 10:08 AM, Terry Therneau wrote:
>> In general, as a package user, I don't want people to be able to
>> suppress checks on CRAN.  I want things fixed.
>>
>> So I am pretty sure there won't ever be a reliable "CRAN-detector" put
>> into R.  It would devalue the brand.
>>
>> Duncan Murdoch
>
> My problem is that CRAN demands that I suppress a large fraction of my
> checks, in order to fit within time constraints.  This leaves me with 3
> choices.
>
> 1. Add lines to my code that tries to guess if CRAN is invoker.  A cat
> and mouse game per your desire above.
>
> 2. Remove large portions of my test suite.  I consider the survival
> package to be one of the pre-eminent current code sets in the world
> precisely because of the extensive validations, this action would change
> it to a second class citizen.
>
> 3. Add a magic environment variable to my local world, only do the full
> tests if it is present, and make the dumbed down version the default.
> Others who want to run the full set are then SOL, which I very much
> don't like.
>
> I agree that CRAN avoidence, other than the time constraint, should be
> verboten.  But I don't think that security through obscurity is the
> answer.  And note that under scenario 3, which is essentially what is
> currently being forced on us, I can do such micshief as easily as under
> number 1.
>
> Terry Therneau
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From therneau at mayo.edu  Wed Sep 19 17:19:50 2012
From: therneau at mayo.edu (Terry Therneau)
Date: Wed, 19 Sep 2012 10:19:50 -0500
Subject: [Rd] R-devel Digest, Vol 115, Issue 18
In-Reply-To: <5059D53C.2090007@gmail.com>
References: <mailman.29.1348048809.29913.r-devel@r-project.org>
	<5059D1F8.1070501@mayo.edu> <5059D53C.2090007@gmail.com>
Message-ID: <5059E296.20004@mayo.edu>



On 09/19/2012 09:22 AM, Duncan Murdoch wrote:
> I understand the issue with time constraints on checks, and I think there are discussions
> in progress about that.  My suggestion has been to put in place a way for a tester to say
> that checks need to be run within a tight time limit, and CRAN as tester will do that in
> cases where it cares about the timing.
>
Sounds good.

> But even with the current (or past, it may have changed already) behaviour of tight limits
> for CRAN testing, you can put in code in your package that allows for longer tests in
> certain conditions. You'll run them, and if you advertise them, others will run them too.
>
For me this applies to certain vignettes.  Thanks to a pointer from K Hansen, I'm told I 
can handle this by putting the long one in inst/doc and the short ones in vignettes.
I'll be trying this out soon.

> Duncan Murdoch


From h.wickham at gmail.com  Wed Sep 19 20:51:09 2012
From: h.wickham at gmail.com (Hadley Wickham)
Date: Wed, 19 Sep 2012 13:51:09 -0500
Subject: [Rd] CRAN test / avoidance
In-Reply-To: <5059DF74.3070200@gmail.com>
References: <mailman.29.1348048809.29913.r-devel@r-project.org>
	<5059D1F8.1070501@mayo.edu> <5059DF74.3070200@gmail.com>
Message-ID: <CABdHhvEDZTU_Wum4jKbf3Y+EbH6udm=Ts09TraCLxiRMjDo=dQ@mail.gmail.com>

> The question becomes: how does information get passed along to indicate
> things that may take a long time to run. The discussion so far has focused
> on developers setting, or using, some flags to indicate tests and examples
> that take a long time. Another option would be to have the check/build
> process generate a file with information about the time it took to run
> tests, vignettes, and examples, probably with some information about the
> speed of the machine it was run on. Then CRAN and anyone else that wants to
> run tests can take this information into consideration.

To paraphrase Uwe (fortunes::fortune(192)): computing is cheap and
thinking hurts.

I don't understand why we are spending so much time discussing what
probably amounts (at most) to a couple of thousand of dollars of
compute time.

Hadley

-- 
RStudio / Rice University
http://had.co.nz/


From spencer.graves at prodsyse.com  Wed Sep 19 20:57:32 2012
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Wed, 19 Sep 2012 11:57:32 -0700
Subject: [Rd] CRAN test / avoidance
In-Reply-To: <CABdHhvEDZTU_Wum4jKbf3Y+EbH6udm=Ts09TraCLxiRMjDo=dQ@mail.gmail.com>
References: <mailman.29.1348048809.29913.r-devel@r-project.org>
	<5059D1F8.1070501@mayo.edu> <5059DF74.3070200@gmail.com>
	<CABdHhvEDZTU_Wum4jKbf3Y+EbH6udm=Ts09TraCLxiRMjDo=dQ@mail.gmail.com>
Message-ID: <505A159C.1020303@prodsyse.com>

On 9/19/2012 11:51 AM, Hadley Wickham wrote:
>> The question becomes: how does information get passed along to indicate
>> things that may take a long time to run. The discussion so far has focused
>> on developers setting, or using, some flags to indicate tests and examples
>> that take a long time. Another option would be to have the check/build
>> process generate a file with information about the time it took to run
>> tests, vignettes, and examples, probably with some information about the
>> speed of the machine it was run on. Then CRAN and anyone else that wants to
>> run tests can take this information into consideration.
> To paraphrase Uwe (fortunes::fortune(192)): computing is cheap and
> thinking hurts.
>
> I don't understand why we are spending so much time discussing what
> probably amounts (at most) to a couple of thousand of dollars of
> compute time.


       I raised the question, because CRAN maintainers rejected the 
latest version of "fda" because some of the examples took too long to 
run on their computers.


       Spencer

>
> Hadley
>


-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567
web:  www.structuremonitoring.com


From hpages at fhcrc.org  Wed Sep 19 22:41:31 2012
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Wed, 19 Sep 2012 13:41:31 -0700
Subject: [Rd] example(smooth.spline) fails when function is NOT byte-compiled
Message-ID: <505A2DFB.8010000@fhcrc.org>

Hi,

example(smooth.spline) fails with the non byte-compiled version of the
smooth.spline function:

   > example(smooth.spline)

   smth.s> require(graphics)

   smth.s> attach(cars)

   smth.s> plot(speed, dist, main = "data(cars)  &  smoothing splines")

   [... more output deleted...]

   smth.s> lines(smooth.spline(speed, dist, df=10), lty=2, col = "red")
   Error in smooth.spline(speed, dist, df = 10) :
     smoothing parameter value too small

More precisely, here is what happens on a fresh R session (R-2.15.1
configured with --disable-byte-compiled-packages):

  ** Checking that smooth.spline() is not compiled:

   > smooth.spline
   [... output deleted...]
   <environment: namespace:stats>

  ** 1st call works:

   > res <- smooth.spline(c(4, 4, 7, 7, 8, 9), c(2, 10, 4, 22, 16, 10))


  ** 2nd call fails:

   > res <- smooth.spline(c(4, 4, 7, 7, 8, 9), c(2, 10, 4, 22, 16, 10))
   Error in smooth.spline(c(4, 4, 7, 7, 8, 9), c(2, 10, 4, 22, 16, 10)) :
     smoothing parameter value too small

  ** 3rd call (but now with the compiled version of the function) still
     fails:

   > library(compiler)

   > smooth.spline2 <- cmpfun(smooth.spline)

   > smooth.spline2
   [... output deleted...]
   <bytecode: 0x16813a0>
   <environment: namespace:stats>

   > res2 <- smooth.spline2(c(4, 4, 7, 7, 8, 9), c(2, 10, 4, 22, 16, 10))
   Error in smooth.spline2(c(4, 4, 7, 7, 8, 9), c(2, 10, 4, 22, 16, 10)) :
     smoothing parameter value too small

Thanks,
H.

My session info:

 > sessionInfo()
R version 2.15.1 (2012-06-22)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=C                 LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] compiler  stats     graphics  grDevices utils     datasets  methods
[8] base

loaded via a namespace (and not attached):
[1] tools_2.15.1


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From stnava at gmail.com  Wed Sep 19 22:06:39 2012
From: stnava at gmail.com (brian avants)
Date: Wed, 19 Sep 2012 16:06:39 -0400
Subject: [Rd] different behavior accessing type-specific as.data.frame
 inside a function vs inside R shell
Message-ID: <CABWzF4XemzZQ+hL89mcf20oN17SToE+q+YL7UzGUkhMfWUmKeA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120919/247b8e7c/attachment.pl>

From mtmorgan at fhcrc.org  Thu Sep 20 00:11:27 2012
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Wed, 19 Sep 2012 15:11:27 -0700
Subject: [Rd] different behavior accessing type-specific as.data.frame
 inside a function vs inside R shell
In-Reply-To: <CABWzF4XemzZQ+hL89mcf20oN17SToE+q+YL7UzGUkhMfWUmKeA@mail.gmail.com>
References: <CABWzF4XemzZQ+hL89mcf20oN17SToE+q+YL7UzGUkhMfWUmKeA@mail.gmail.com>
Message-ID: <505A430F.3080807@fhcrc.org>

Hi Brian --

On 9/19/2012 1:06 PM, brian avants wrote:
> hello
>
> we are developing an R package called ANTsR for which we have some special
> types.
>
> one of these types is an " antsMatrix " type.
>
> we implemented a "as.data.frame" function that casts an antsMatrix to a
> data.frame
>
> this works fine in a basic shell script.   for instance:
>
> # install
> R CMD INSTALL ANTsR
> # open
> R
> # in R do
> library(ANTsR)
> a <- new( "antsMatrix", "float" )
> b <- as.data.frame( a )
>
> this all works fine and i am pleased.
>
> fyi, the implementation of as.data.frame is:
>
> setMethod( f = "as.data.frame" ,
>     signature( x = "antsMatrix" ) ,
>     definition = function( x )
>            {
>    lst = .Call( "antsMatrix_asList" , x )
>   names(lst)[ 1 : (length(lst)) ] <- lst[[ length(lst) ]]
> lst[[ length(lst) ]] <- NULL
>                          as.data.frame(lst)
> }
>     )

S4 uses setAs() to establish coercion between types. "Methods for S3 
Generic Functions" of the help page ?Methods recommends defining both an 
S3 and an S4 version of the coerce method. So for this toy 
implementation of your class

   setClass("antsMatrix",
            representation=representation(values="numeric"))

I defined an S3 and an S4 coercion, reusing the S3 function as much as 
possible.

   as.data.frame.antsMatrix <-
       function(x, row.names=NULL, optional = FALSE, ...)
   {
       ## lst = .Call( "antsMatrix_asList" , x )
       ## names(lst)[ 1 : (length(lst)) ] <- lst[[ length(lst) ]]
       ## lst[[ length(lst) ]] <- NULL
       ## as.data.frame(lst)
       data.frame(values=x at values)
   }

   setAs("antsMatrix", "data.frame", function(from) {
       as.data.frame.antsMatrix(from)
   })

in the NAMESPACE file you would export both methods

   S3method(as.data.frame, antsMatrix)
   exportMethods(coerce)

This supports both forms of coercion

 > m <- new("antsMatrix", values=1:5)
 > as.data.frame(m)
   values
1      1
2      2
3      3
4      4
5      5
 > as(m, "data.frame")
   values
1      1
2      2
3      3
4      4
5      5


>
> now the problem comes when i try to access the same functionality in a
> function that is within my package R source.
>
> i.e. the function is defined in   ANTsR/R/test.R   which reads
>
> test <- function(...)
> {
>    a <- new( "antsMatrix", "float" )
>    b <- as.data.frame( a )
> }
>
> this should produce the same behavior as above, i would think.
>
> but somehow , i get different behavior:
>
> library(ANTsR)
> test()
>
> produces :
>
> Error in as.data.frame.default(a) :
>    cannot coerce class 'structure("antsMatrix", package = "ANTsR")' into a
> data.frame
>
> it is clear to me what's happening ----- R is trying to use the default
> implementation of as.data.frame
>
> which clearly won't work on an antsMatrix type.
>
> the issue is --- i do not know why R is not using the correct type-specific
> implementation when
>
> this function is called as opposed to when the same operations are called
> within the shell.
>
> certainly there must be some simple error on our part in implementation but
> i cannot find
>
> what it is --- i am the 3rd person who has looked into this.   it's true
> that we are all novice R
>
> developers .... am hoping someone on the list can provide some insight.
>
> many thanks for your time,
>
> brian
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Dr. Martin Morgan, PhD
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109


From ripley at stats.ox.ac.uk  Thu Sep 20 08:58:29 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 20 Sep 2012 07:58:29 +0100
Subject: [Rd] example(smooth.spline) fails when function is NOT
	byte-compiled
In-Reply-To: <505A2DFB.8010000@fhcrc.org>
References: <505A2DFB.8010000@fhcrc.org>
Message-ID: <505ABE95.8060108@stats.ox.ac.uk>

As the posting guide asked of you, try R-patched or R-devel before 
posting, and check the bug repository.

     ? smooth.spline() used DUP = FALSE which allowed its compiled C
       code to change the function: this was masked by the default
       byte-compilation. (PR#14965.)


On 19/09/2012 21:41, Herv? Pag?s wrote:
> Hi,
>
> example(smooth.spline) fails with the non byte-compiled version of the
> smooth.spline function:
>
>    > example(smooth.spline)
>
>    smth.s> require(graphics)
>
>    smth.s> attach(cars)
>
>    smth.s> plot(speed, dist, main = "data(cars)  &  smoothing splines")
>
>    [... more output deleted...]
>
>    smth.s> lines(smooth.spline(speed, dist, df=10), lty=2, col = "red")
>    Error in smooth.spline(speed, dist, df = 10) :
>      smoothing parameter value too small
>
> More precisely, here is what happens on a fresh R session (R-2.15.1
> configured with --disable-byte-compiled-packages):
>
>   ** Checking that smooth.spline() is not compiled:
>
>    > smooth.spline
>    [... output deleted...]
>    <environment: namespace:stats>
>
>   ** 1st call works:
>
>    > res <- smooth.spline(c(4, 4, 7, 7, 8, 9), c(2, 10, 4, 22, 16, 10))
>
>
>   ** 2nd call fails:
>
>    > res <- smooth.spline(c(4, 4, 7, 7, 8, 9), c(2, 10, 4, 22, 16, 10))
>    Error in smooth.spline(c(4, 4, 7, 7, 8, 9), c(2, 10, 4, 22, 16, 10)) :
>      smoothing parameter value too small
>
>   ** 3rd call (but now with the compiled version of the function) still
>      fails:
>
>    > library(compiler)
>
>    > smooth.spline2 <- cmpfun(smooth.spline)
>
>    > smooth.spline2
>    [... output deleted...]
>    <bytecode: 0x16813a0>
>    <environment: namespace:stats>
>
>    > res2 <- smooth.spline2(c(4, 4, 7, 7, 8, 9), c(2, 10, 4, 22, 16, 10))
>    Error in smooth.spline2(c(4, 4, 7, 7, 8, 9), c(2, 10, 4, 22, 16, 10)) :
>      smoothing parameter value too small
>
> Thanks,
> H.
>
> My session info:
>
>  > sessionInfo()
> R version 2.15.1 (2012-06-22)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>   [7] LC_PAPER=C                 LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] compiler  stats     graphics  grDevices utils     datasets  methods
> [8] base
>
> loaded via a namespace (and not attached):
> [1] tools_2.15.1
>
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From therneau at mayo.edu  Thu Sep 20 19:43:36 2012
From: therneau at mayo.edu (Terry Therneau)
Date: Thu, 20 Sep 2012 12:43:36 -0500
Subject: [Rd] Rbuildignore question
Message-ID: <505B55C8.4070104@mayo.edu>

I'm touching up changes to rpart and have a question with .Rbuildignore.  Here is my file

tmt1014% more .Rbuildignore
test.local
\.hg
src/print_tree.c


  The source code included a module "print_tree.c", used for dubugging.  Commented
out calls to can be found here and there.  I want to leave it in the source tree
even though no submitted copy of rpart will use it.

  Even with the ignore line above, R CMD check still compiles it, and gives a "bad
boy" NOTE about use of printf.  Can I/ should I/ how do I get rid of this?

(R 2.15.1)


From murdoch.duncan at gmail.com  Thu Sep 20 19:57:48 2012
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 20 Sep 2012 13:57:48 -0400
Subject: [Rd] Rbuildignore question
In-Reply-To: <505B55C8.4070104@mayo.edu>
References: <505B55C8.4070104@mayo.edu>
Message-ID: <505B591C.9000804@gmail.com>

On 20/09/2012 1:43 PM, Terry Therneau wrote:
> I'm touching up changes to rpart and have a question with .Rbuildignore.  Here is my file
>
> tmt1014% more .Rbuildignore
> test.local
> \.hg
> src/print_tree.c
>
>
>    The source code included a module "print_tree.c", used for dubugging.  Commented
> out calls to can be found here and there.  I want to leave it in the source tree
> even though no submitted copy of rpart will use it.
>
>    Even with the ignore line above, R CMD check still compiles it, and gives a "bad
> boy" NOTE about use of printf.  Can I/ should I/ how do I get rid of this?

What do you mean, "leave it in the source tree"?  Since you're telling 
build to ignore it, I assume that's just for your own use, not for users 
of your package.  And what did you run check on, the tarball or the 
directory?  If you ran it on the tarball, then there's something wrong 
with your tarball, because it shouldn't be there (you said to ignore 
it).  If you're running check on the directory, then ignore the NOTE, 
because it shouldn't appear when you run it on the tarball.

Duncan Murdoch


From therneau at mayo.edu  Thu Sep 20 22:37:21 2012
From: therneau at mayo.edu (Terry Therneau)
Date: Thu, 20 Sep 2012 15:37:21 -0500
Subject: [Rd] Rbuildignore question
In-Reply-To: <505B591C.9000804@gmail.com>
References: <505B55C8.4070104@mayo.edu> <505B591C.9000804@gmail.com>
Message-ID: <505B7E81.30809@mayo.edu>

Thanks, that answers my question.
   1. I was running on the source tree.  And by "leave in the source tree" I mean just 
that, with local source code control managment.  It's in a place I can find it when needed.
It would appear on Rforge. But per your comment, not on the CRAN source.  Ok

   2. I'll check the tarball soon, but I'm guessing you are right about the error going
away.

On 09/20/2012 12:57 PM, Duncan Murdoch wrote:
> On 20/09/2012 1:43 PM, Terry Therneau wrote:
>> I'm touching up changes to rpart and have a question with .Rbuildignore. Here is my file
>>
>> tmt1014% more .Rbuildignore
>> test.local
>> \.hg
>> src/print_tree.c
>>
>>
>> The source code included a module "print_tree.c", used for dubugging. Commented
>> out calls to can be found here and there. I want to leave it in the source tree
>> even though no submitted copy of rpart will use it.
>>
>> Even with the ignore line above, R CMD check still compiles it, and gives a "bad
>> boy" NOTE about use of printf. Can I/ should I/ how do I get rid of this?
>
> What do you mean, "leave it in the source tree"? Since you're telling build to ignore it,
> I assume that's just for your own use, not for users of your package. And what did you run
> check on, the tarball or the directory? If you ran it on the tarball, then there's
> something wrong with your tarball, because it shouldn't be there (you said to ignore it).
> If you're running check on the directory, then ignore the NOTE, because it shouldn't
> appear when you run it on the tarball.
>
> Duncan Murdoch


From wdunlap at tibco.com  Fri Sep 21 19:57:02 2012
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 21 Sep 2012 17:57:02 +0000
Subject: [Rd] should delete.response(response~predictor) return ~predictor?
Message-ID: <E66794E69CFDE04D9A70842786030B93332700@PA-MBX04.na.tibco.com>

Thomas,

I noticed the delete.response() just returns its input if the input
is not of class "terms".   Hence we get surprising (to me) results like

  > env <- new.env()
  > env # formulae have an environment, calls do not
  <environment: 0x3244788>
  > with(env, delete.response(y ~ x1 + x2)) # class "formula"
  y ~ x1 + x2
  <environment: 0x3244788>
  > with(env, delete.response(quote(y ~ x1 + x2))) # class "call" (to `~`)
  y ~ x1 + x2

Without reading the help file, I would have expected ~x1+x2, as in
  > with(env, formula(delete.response(terms(y ~ x1 + x2))))
  ~x1 + x2
  <environment: 0x3244788>

survey:::summary.svytable (ver. 3.28-2) seems to expect delete.response
to work on calls, as it calls delete.response() on the call object which is
the "formula" argument in the "call" attribute of its input.

> survey:::summary.svytable
function (object, statistic = c("F", "Chisq", "Wald", "adjWald",
    "lincom", "saddlepoint"), ...)
{
    statistic <- match.arg(statistic)
    call <- attr(object, "call")
    ff <- call$formula
    if (is.null(environment(ff)))
        env <- parent.frame()
    else env <- environment(ff)
    ff <- delete.response(ff)
    ...

(Perhaps it was intended to get a real formula or terms object here, as the
environment of a call is NULL, unless the user attached the  ".Environment"
attribute.)

If delete.response doesn't do anything with non-terms objects, should it
throw an error if it is given such a thing?

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


From saleumd at yahoo.com  Fri Sep 21 23:52:36 2012
From: saleumd at yahoo.com (qwumd)
Date: Fri, 21 Sep 2012 14:52:36 -0700 (PDT)
Subject: [Rd] Defunct of --max-vsize and mem.limits
Message-ID: <1348264356.46280.YahooMailNeo@web163802.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120921/6b05a1b0/attachment.pl>

From deepayan.sarkar at r-project.org  Mon Sep 24 19:00:38 2012
From: deepayan.sarkar at r-project.org (Deepayan Sarkar)
Date: Mon, 24 Sep 2012 22:30:38 +0530
Subject: [Rd] Question lattice SplomT
In-Reply-To: <506081BE.1030901@sunrise.ch>
References: <506081BE.1030901@sunrise.ch>
Message-ID: <CADfFDC4ym2Si79YgEgj=WXJF7sFzGkQ7NndGg3V=u5pauRGYLA@mail.gmail.com>

On Mon, Sep 24, 2012 at 9:22 PM, Christian Hoffmann
<c-w.hoffmann at sunrise.ch> wrote:
> Dear Deepayan Sarkar,
>
> I have (again) a question concerning "panel" and my function "SplomT", see
> attachments. Some time ago you helped me to write this function, thanks
> again. I have used it to great advantage in my statistics instructions. Now
> the problem I encounter is that the .pdf figure generated in Sweave consists
> of
>
> one extra empty page at the start.

This seems to be due to the get.gpar() call in the SplomT() function
-- it produces a new page if it is called before any graphics output
is drawn.

That's not quite correct: The point is that grid.newpage() does some
magic to NOT create a new page if it realizes that it is being called
with a fresh device with nothing drawn on it yet. Calling get.gpar()
is enough to make that magic fail, so the grid.newpage() call inside
print.trellis() is actually creating a new page.

Your options are:

(1) get rid of the get.gpar()$cex call (can it be anything other than
1 on a new device?), or

(2) call print(splom(...), newpage=FALSE)

-Deepayan

> This prevents it from showing up in the final .pdf document. I am not sure
> whether this has any thing to do with Sweave. (If the statement is executed
> on the command line, the plot in the Quartz window looks allright.)
>
> Since I have no full version of Adobe Acrobat I cannot eliminate the empty
> first page. I tried to fiddle around with the panel functions, but was not
> table to mimic my function.
>
> Thanks for your attention and for looking at my problem.
>
> Christian Hoffmann
>
> PS: for *r-devel*: Could this be an Sweave problem?
>
> Files attached:
> SplomT.Rnw  : File containing the Functiond and an example,
> SplomT.tex   : Result from Sweave of .Rnw,
> SplomT.pdf  : Result from TeXing the .tex,
> Fig_A.pdf    : Resulting figure from Sweave
> SplomT.png  : Screenshot of Fig_A.pdf
>
> sessionInfo()
> R version 2.15.1 (2012-06-22)
> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>
> locale:
> [1] C
>
> attached base packages:
>  [1] tools     tcltk     stats4    splines   parallel  datasets compiler
>  [8] graphics  grDevices stats     grid      utils     methods base
>
> other attached packages:
>  [1] survival_2.36-14  spatial_7.3-3     rpart_3.1-53 nnet_7.3-1
>  [5] nlme_3.1-104      mgcv_1.7-18       foreign_0.8-50 codetools_0.2-8
>  [9] cluster_1.14.2    class_7.3-3       boot_1.3-4 Matrix_1.0-6
> [13] MASS_7.3-18       KernSmooth_2.23-7 cwhmisc_3.0 lattice_0.20-6
>>
>
> --
> Christian W. Hoffmann,
> CH - 8915 Hausen am Albis, Switzerland
> Rigiblickstrasse 15 b, Tel.+41-44-7640853
> c-w.hoffmann at sunrise.ch,
> christian at echoffmann.ch,
> www.echoffmann.ch
>


From kasperdanielhansen at gmail.com  Mon Sep 24 19:30:20 2012
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Mon, 24 Sep 2012 13:30:20 -0400
Subject: [Rd] license
Message-ID: <CAC2h7uusMhf9B4JaROucvqGUr1FyitSoZvRgVLoHz9yMgCT2yQ@mail.gmail.com>

R-devel now gives a warning for a non-standard license (this may have
happened for a while).

In Rgraphviz we include the Graphviz source code, which is under
Eclipse.  But the rest of the R package is under Artistic-2.0 or at
least contains code from past contributors which were licensed under
Artistic-2.0.

The standard licenses does not really give an option for this
situation, apart from using 'file LICENSE' (with details on this).

However, this situation - including an external piece of software -
seems to me to be increasingly common.  It may be worthwhile to have
the possibility of specifying this in a more machine readable way.
But it may also be too complicated.  I just wanted to bring attention
to the issue.

Kasper


From ligges at statistik.tu-dortmund.de  Mon Sep 24 23:17:43 2012
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 24 Sep 2012 23:17:43 +0200
Subject: [Rd] license
In-Reply-To: <CAC2h7uusMhf9B4JaROucvqGUr1FyitSoZvRgVLoHz9yMgCT2yQ@mail.gmail.com>
References: <CAC2h7uusMhf9B4JaROucvqGUr1FyitSoZvRgVLoHz9yMgCT2yQ@mail.gmail.com>
Message-ID: <5060CDF7.70701@statistik.tu-dortmund.de>



On 24.09.2012 19:30, Kasper Daniel Hansen wrote:
> R-devel now gives a warning for a non-standard license (this may have
> happened for a while).

Yes, for several years now.

> In Rgraphviz we include the Graphviz source code, which is under
> Eclipse.  But the rest of the R package is under Artistic-2.0 or at
> least contains code from past contributors which were licensed under
> Artistic-2.0.

If it is possible to mix these two at all (I do not know the details)...

>
> The standard licenses does not really give an option for this
> situation, apart from using 'file LICENSE' (with details on this).

Yes, that's why it has been introduced: Describing non trivial license 
situations.

Best,
Uwe Ligges


> However, this situation - including an external piece of software -
> seems to me to be increasingly common.  It may be worthwhile to have
> the possibility of specifying this in a more machine readable way.
> But it may also be too complicated.  I just wanted to bring attention
> to the issue.
>
> Kasper
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From mtmorgan at fhcrc.org  Tue Sep 25 01:42:32 2012
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Mon, 24 Sep 2012 16:42:32 -0700
Subject: [Rd] Segmentation fault when options(max.print =
	.Machine$integer.max)
Message-ID: <5060EFE8.60609@fhcrc.org>

Seemed like a good idea at the time, but

 >   options(max.print = .Machine$integer.max)
 >   1:10
          [1]
Program received signal SIGSEGV, Segmentation fault.

because of an integer overflow at src/main/printvector.c:176

 > sessionInfo()
R Under development (unstable) (2012-09-24 r60800)
Platform: x86_64-unknown-linux-gnu (64-bit)
...

also R-patched, etc.

Martin
-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From tlumley at uw.edu  Tue Sep 25 04:45:13 2012
From: tlumley at uw.edu (Thomas Lumley)
Date: Tue, 25 Sep 2012 14:45:13 +1200
Subject: [Rd] error on uneven recycling?
Message-ID: <CAJ55+dJ8zbqK-7RvTO-8K-y=e1BMKG8aHm-HML3F+FQm1EfutA@mail.gmail.com>

Is there some reason why

> (1:2)+(1:3)
[1] 2 4 4
Warning message:
In (1:2) + (1:3) :
  longer object length is not a multiple of shorter object length

can't be made into an error?  I realise it was there in S-PLUS, but
since it produces a warning there can't be many examples on CRAN or
Bioconductor using it, and I can't think of any situation where it
would be used deliberately.

    -thomas

-- 
Thomas Lumley
Professor of Biostatistics
University of Auckland


From wdunlap at tibco.com  Tue Sep 25 07:15:14 2012
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 25 Sep 2012 05:15:14 +0000
Subject: [Rd] error on uneven recycling?
In-Reply-To: <CAJ55+dJ8zbqK-7RvTO-8K-y=e1BMKG8aHm-HML3F+FQm1EfutA@mail.gmail.com>
References: <CAJ55+dJ8zbqK-7RvTO-8K-y=e1BMKG8aHm-HML3F+FQm1EfutA@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B93342B40@PA-MBX04.na.tibco.com>

That is an error in Splus 8.3.  It must have changed quite a while
ago - it was an error in Splus 5.1, released in 1999 and I don't have
an older version handy right now.  Current behavior is
> 1:10 + 0:1
 [1]  1  3  3  5  5  7  7  9  9 11
> 1:10 + 0:2
Problem in 1:10 + 0:2: length of longer operand (10) should be a multiple of length of shorter (3)
Use traceback() to see the call stack

I vaguley recall running into some problems when we made the change,
but I think it was only in our internal test suite, using a trick like the above
to produce a patterned sequence.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf
> Of Thomas Lumley
> Sent: Monday, September 24, 2012 7:45 PM
> To: R-devel
> Subject: [Rd] error on uneven recycling?
> 
> Is there some reason why
> 
> > (1:2)+(1:3)
> [1] 2 4 4
> Warning message:
> In (1:2) + (1:3) :
>   longer object length is not a multiple of shorter object length
> 
> can't be made into an error?  I realise it was there in S-PLUS, but
> since it produces a warning there can't be many examples on CRAN or
> Bioconductor using it, and I can't think of any situation where it
> would be used deliberately.
> 
>     -thomas
> 
> --
> Thomas Lumley
> Professor of Biostatistics
> University of Auckland
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Tue Sep 25 09:12:11 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 25 Sep 2012 08:12:11 +0100
Subject: [Rd] error on uneven recycling?
In-Reply-To: <CAJ55+dJ8zbqK-7RvTO-8K-y=e1BMKG8aHm-HML3F+FQm1EfutA@mail.gmail.com>
References: <CAJ55+dJ8zbqK-7RvTO-8K-y=e1BMKG8aHm-HML3F+FQm1EfutA@mail.gmail.com>
Message-ID: <5061594B.9050903@stats.ox.ac.uk>

On 25/09/2012 03:45, Thomas Lumley wrote:
> Is there some reason why
>
>> (1:2)+(1:3)
> [1] 2 4 4
> Warning message:
> In (1:2) + (1:3) :
>    longer object length is not a multiple of shorter object length
>
> can't be made into an error?  I realise it was there in S-PLUS, but
> since it produces a warning there can't be many examples on CRAN or
> Bioconductor using it, and I can't think of any situation where it
> would be used deliberately.

It produces a warning, not an R CMD check warning.  There are lots of 
instances on CRAN, for example when running the examples for

CollocInfer DiceOptim FitAR LaplacesDemon MethComp OUwie ROptEst
RandVar RiDMC SweaveListingUtils TeachingSampling adlift
arulesViz caret cyclones depth disp2D gstat hyperSpec igraph
igraph0 iid influence irtoys isotone ldDesign libamtrack lqmm
mixtools phylobase polynom replicationDemos reporttools robustX
rsem sfsmisc spam spatstat survival tcltk2 tsDyn

let alone tests and vignettes.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Tue Sep 25 09:22:49 2012
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 25 Sep 2012 08:22:49 +0100
Subject: [Rd] error on uneven recycling?
In-Reply-To: <5061594B.9050903@stats.ox.ac.uk>
References: <CAJ55+dJ8zbqK-7RvTO-8K-y=e1BMKG8aHm-HML3F+FQm1EfutA@mail.gmail.com>
	<5061594B.9050903@stats.ox.ac.uk>
Message-ID: <50615BC9.4080306@stats.ox.ac.uk>

On 25/09/2012 08:12, Prof Brian Ripley wrote:
> On 25/09/2012 03:45, Thomas Lumley wrote:
>> Is there some reason why
>>
>>> (1:2)+(1:3)
>> [1] 2 4 4
>> Warning message:
>> In (1:2) + (1:3) :
>>    longer object length is not a multiple of shorter object length
>>
>> can't be made into an error?  I realise it was there in S-PLUS, but
>> since it produces a warning there can't be many examples on CRAN or
>> Bioconductor using it, and I can't think of any situation where it
>> would be used deliberately.
>
> It produces a warning, not an R CMD check warning.  There are lots of
> instances on CRAN, for example when running the examples for
>
> CollocInfer DiceOptim FitAR LaplacesDemon MethComp OUwie ROptEst
> RandVar RiDMC SweaveListingUtils TeachingSampling adlift
> arulesViz caret cyclones depth disp2D gstat hyperSpec igraph
> igraph0 iid influence irtoys isotone ldDesign libamtrack lqmm
> mixtools phylobase polynom replicationDemos reporttools robustX
> rsem sfsmisc spam spatstat survival tcltk2 tsDyn
>
> let alone tests and vignettes.

I caught some some similar ones in that search:

CollocInfer DiceOptim RandVar TeachingSampling hyperSpec igraph igraph0 
influence lqmm mixtool phylobase polynom robustX sfsmisc spam survival 
tcltk2 tsDyn

are exactly that warning.  I think for example the one in 'survival' is 
an error.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pdalgd at gmail.com  Tue Sep 25 09:39:39 2012
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 25 Sep 2012 09:39:39 +0200
Subject: [Rd] error on uneven recycling?
In-Reply-To: <CAJ55+dJ8zbqK-7RvTO-8K-y=e1BMKG8aHm-HML3F+FQm1EfutA@mail.gmail.com>
References: <CAJ55+dJ8zbqK-7RvTO-8K-y=e1BMKG8aHm-HML3F+FQm1EfutA@mail.gmail.com>
Message-ID: <F7F7C9E1-4224-4A92-84EF-57331BD9EF65@gmail.com>


On Sep 25, 2012, at 04:45 , Thomas Lumley wrote:

> Is there some reason why
> 
>> (1:2)+(1:3)
> [1] 2 4 4
> Warning message:
> In (1:2) + (1:3) :
>  longer object length is not a multiple of shorter object length
> 
> can't be made into an error?  I realise it was there in S-PLUS, but
> since it produces a warning there can't be many examples on CRAN or
> Bioconductor using it, and I can't think of any situation where it
> would be used deliberately.
> 
>    -thomas

I always thought it was retained in case you needed to add something with cyclic behavior to a time series not necessarily containing an even number of cycles. If it has been outlawed in S-PLUS for a decade, that's probably not a big need...

-p

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From c-w.hoffmann at sunrise.ch  Mon Sep 24 17:52:30 2012
From: c-w.hoffmann at sunrise.ch (Christian Hoffmann)
Date: Mon, 24 Sep 2012 17:52:30 +0200
Subject: [Rd] Question lattice SplomT
Message-ID: <506081BE.1030901@sunrise.ch>

Dear Deepayan Sarkar,

I have (again) a question concerning "panel" and my function "SplomT", 
see attachments. Some time ago you helped me to write this function, 
thanks again. I have used it to great advantage in my statistics 
instructions. Now the problem I encounter is that the .pdf figure 
generated in Sweave consists of

one extra empty page at the start.

This prevents it from showing up in the final .pdf document. I am not 
sure whether this has any thing to do with Sweave. (If the statement is 
executed on the command line, the plot in the Quartz window looks allright.)

Since I have no full version of Adobe Acrobat I cannot eliminate the 
empty first page. I tried to fiddle around with the panel functions, but 
was not table to mimic my function.

Thanks for your attention and for looking at my problem.

Christian Hoffmann

PS: for *r-devel*: Could this be an Sweave problem?

Files attached:
SplomT.Rnw  : File containing the Functiond and an example,
SplomT.tex   : Result from Sweave of .Rnw,
SplomT.pdf  : Result from TeXing the .tex,
Fig_A.pdf    : Resulting figure from Sweave
SplomT.png  : Screenshot of Fig_A.pdf

sessionInfo()
R version 2.15.1 (2012-06-22)
Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)

locale:
[1] C

attached base packages:
  [1] tools     tcltk     stats4    splines   parallel  datasets compiler
  [8] graphics  grDevices stats     grid      utils     methods base

other attached packages:
  [1] survival_2.36-14  spatial_7.3-3     rpart_3.1-53 nnet_7.3-1
  [5] nlme_3.1-104      mgcv_1.7-18       foreign_0.8-50 codetools_0.2-8
  [9] cluster_1.14.2    class_7.3-3       boot_1.3-4 Matrix_1.0-6
[13] MASS_7.3-18       KernSmooth_2.23-7 cwhmisc_3.0 lattice_0.20-6
 >

-- 
Christian W. Hoffmann,
CH - 8915 Hausen am Albis, Switzerland
Rigiblickstrasse 15 b, Tel.+41-44-7640853
c-w.hoffmann at sunrise.ch,
christian at echoffmann.ch,
www.echoffmann.ch

-------------- next part --------------
%% Test SplomT
\documentclass[a4paper,11pt,leqno]{scrbook}
\usepackage[OT2,OT1]{fontenc}
\usepackage[russian,ngerman,english]{babel}
%% \usepackage[displaymath]{lineno}
\usepackage{graphicx}
\usepackage{textcomp}  % special symbols
\usepackage{geometry}
\geometry{verbose,a4paper,tmargin=2.4cm,bmargin=2.5cm,lmargin=2.5cm,rmargin=2cm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{longtable}
\usepackage{psfrag}  % for greek letters etc.
\usepackage{Sweave} %% /Users/hoffmann/R/Rtest/Sweave


\begin{document}
\SweaveOpts{prefix.string=fig/Fig}

\title{\textbf{Test SplomT}
 }
\author{Christian W. Hoffmann}
\maketitle
<<O,fig=TRUE>>=
plot(0,xlab="This is for test purposes only")
@ 
<<A,fig=TRUE>>=
SplomT <- function (data, mainL = deparse(substitute(data)), xlabL = "", 
    hist = "h", adjust = 1, hist.col = trellis.par.get("strip.background")$col[5], cex.diag = 1, h.diag=0.4, colYonX = "red", colXonY = "blue", ...) {
  stopifnot (hist %in% c("h", "d", "b")) 
  data  <- data.frame(data)
  mxnam <- max(nchar(names(data)))
  lnam  <- ncol(data)
  ce    <- 100*cex.diag*get.gpar()$cex/lnam
  cexd  <- ce/mxnam
  cexn  <- ce/5
  print(splom(~data, as.matrix = TRUE, main = mainL, xlab = xlabL,
    upper.panel = function(x, y, breaks = NULL, ...) {
      minS <- 0.05
      ccr <- cor(x, y, use = "complete.obs")
      ccq <- sqrt(max(abs(ccr), minS))
      if (is.na(ccr)) {ccr <- 0; ccq <- sqrt(minS)}
      grid.text(round(ccr, 2), gp = gpar(cex = cexn*ccq))
    },
    lower.panel = function(x, y, ...) {
      options(show.error.messages = FALSE)
      try(panel.xyplot(x, y, type = c("p", "smooth"), col.line = colYonX, 
          pch = 3, cex = 1.5/dim(data)[2], ...))
      lo <- try(loess.smooth(y, x, ...))
      if (!inherits(lo,"try-error")) panel.lines(lo$y, lo$x, col.line = colXonY, ...)
      options(show.error.messages = TRUE)
    },
    diag.panel = function(x, varname, limits, ...) {
      d <- density(x[!is.na(x)])
      yrng <- range(d$y)
      ylim <- yrng + 0.07 * c(-1, 1) * diff(yrng)
      xlim <- current.panel.limits()$xlim
      pushViewport(viewport(xscale = xlim, yscale = ylim))
      if (hist %in% c("h", "b")) {
        panel.histogram(x[!is.na(x)], breaks = NULL, col = hist.col, type = "density", ...)
      }
      if (hist %in% c("d", "b")) {
        llines(d)
      }
      grid.text(varname,  y=unit(h.diag,"npc"), gp = gpar(cex = cexd))
      popViewport()
    }, varnames = abbreviate(names(data)), pscales = 0 )
  )
}  ## end SplomT  2012-09-24, 16:25

  nr <- 100; nc <- 8;
  data <- as.data.frame(matrix(rnorm(nr*nc),nrow=nr,ncol=nc))
  data[,nc]   <- data[,nc-2] + 0.3*data[,nc-1] #generate higher correlations
  data[,nc-1] <- data[,nc-1] + 0.9*data[,nc]
  colnames(data)<-paste("vw",letters[1:nc],sep="")
  SplomT(data,mainL="",hist="d",cex.diag=0.6,hist.col="green")
@

\end{document}
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Fig-A.pdf
Type: application/pdf
Size: 97743 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120924/72d3c347/attachment.pdf>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: SplomT0.pdf
Type: application/pdf
Size: 57365 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120924/72d3c347/attachment-0001.pdf>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: SplomT.png
Type: image/png
Size: 154910 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120924/72d3c347/attachment.png>

From maechler at stat.math.ethz.ch  Tue Sep 25 14:26:24 2012
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 25 Sep 2012 14:26:24 +0200
Subject: [Rd] Segmentation fault when options(max.print
	=	.Machine$integer.max)
In-Reply-To: <5060EFE8.60609@fhcrc.org>
References: <5060EFE8.60609@fhcrc.org>
Message-ID: <20577.41712.251060.307898@stat.math.ethz.ch>


> Seemed like a good idea at the time,

I'm curious.  Why is it (setting max.print much too large)
a good idea?

> but
>  >   options(max.print = .Machine$integer.max)
>  >   1:10
>           [1]
> Program received signal SIGSEGV, Segmentation fault.

> because of an integer overflow at src/main/printvector.c:176

>  > sessionInfo()
> R Under development (unstable) (2012-09-24 r60800)
> Platform: x86_64-unknown-linux-gnu (64-bit)
> ...

> also R-patched, etc.

Thank you, Martin.   I'm about to commit fixes for this.
"another" Martin.


> Martin
> -- 
> Computational Biology / Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N.
> PO Box 19024 Seattle, WA 98109


From mtmorgan at fhcrc.org  Tue Sep 25 14:34:12 2012
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Tue, 25 Sep 2012 05:34:12 -0700
Subject: [Rd] Segmentation fault when options(max.print =
	.Machine$integer.max)
In-Reply-To: <20577.41712.251060.307898@stat.math.ethz.ch>
References: <5060EFE8.60609@fhcrc.org>
	<20577.41712.251060.307898@stat.math.ethz.ch>
Message-ID: <5061A4C4.6030103@fhcrc.org>

On 09/25/2012 05:26 AM, Martin Maechler wrote:
>
>> Seemed like a good idea at the time,
>
> I'm curious.  Why is it (setting max.print much too large)
> a good idea?

I usually set it considerably smaller (50) than default to conserve 
screen real estate, but then occasionally need to see more than my small 
setting (e.g., ls(getNamespace("Matrix"))) and don't want to guess at 
how much I want to see.

Thanks for your fix.

Martin

>
>> but
>>   >   options(max.print = .Machine$integer.max)
>>   >   1:10
>>            [1]
>> Program received signal SIGSEGV, Segmentation fault.
>
>> because of an integer overflow at src/main/printvector.c:176
>
>>   > sessionInfo()
>> R Under development (unstable) (2012-09-24 r60800)
>> Platform: x86_64-unknown-linux-gnu (64-bit)
>> ...
>
>> also R-patched, etc.
>
> Thank you, Martin.   I'm about to commit fixes for this.
> "another" Martin.
>
>
>> Martin
>> --
>> Computational Biology / Fred Hutchinson Cancer Research Center
>> 1100 Fairview Ave. N.
>> PO Box 19024 Seattle, WA 98109


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From maechler at stat.math.ethz.ch  Tue Sep 25 17:29:59 2012
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 25 Sep 2012 17:29:59 +0200
Subject: [Rd] Segmentation fault when options(max.print =
	.Machine$integer.max)
In-Reply-To: <5061A4C4.6030103@fhcrc.org>
References: <5060EFE8.60609@fhcrc.org>
	<20577.41712.251060.307898@stat.math.ethz.ch>
	<5061A4C4.6030103@fhcrc.org>
Message-ID: <20577.52727.514774.510618@stat.math.ethz.ch>

>>>>> Martin Morgan <mtmorgan at fhcrc.org>
>>>>>     on Tue, 25 Sep 2012 05:34:12 -0700 writes:

    > On 09/25/2012 05:26 AM, Martin Maechler wrote:
    >> 
    >>> Seemed like a good idea at the time,
    >> 
    >> I'm curious.  Why is it (setting max.print much too
    >> large) a good idea?

    > I usually set it considerably smaller (50) than default to
    > conserve screen real estate, but then occasionally need to
    > see more than my small setting (e.g.,
    > ls(getNamespace("Matrix"))) 

:-)  :-)   that's a good one...

but even for that and for the longer  
ls(getNamespace("Matrix")), all=TRUE) 

  options(max.print = 1000)

is sufficient.

    > and don't want to guess at how much I want to see.

I understand.   But really the reason we had introduced it,
*was* exactly equivalent to saying that setting it to
"practically Inf" is unreseasonable.
If you want it really large, use a million which is already more
than you want, and '1e6' is really faster typing than .Machine$..


    > Thanks for your fix.

de nada,
Martin



    > Martin

    >> 
    >>> but > options(max.print = .Machine$integer.max) > 1:10
    >>> [1] Program received signal SIGSEGV, Segmentation fault.
    >> 
    >>> because of an integer overflow at
    >>> src/main/printvector.c:176
    >> 
    >>> > sessionInfo() R Under development (unstable)
    >>> (2012-09-24 r60800) Platform: x86_64-unknown-linux-gnu
    >>> (64-bit) ...
    >> 
    >>> also R-patched, etc.
    >> 
    >> Thank you, Martin.  I'm about to commit fixes for this.
    >> "another" Martin.
    >> 
    >> 
    >>> Martin
    >>> --
    >>> Computational Biology / Fred Hutchinson Cancer Research
    >>> Center 1100 Fairview Ave. N.  PO Box 19024 Seattle, WA
    >>> 98109


    > -- 
    > Computational Biology / Fred Hutchinson Cancer Research
    > Center 1100 Fairview Ave. N.  PO Box 19024 Seattle, WA
    > 98109

    > Location: Arnold Building M1 B861 Phone: (206) 667-2793


From oliver at first.in-berlin.de  Wed Sep 26 00:03:18 2012
From: oliver at first.in-berlin.de (Oliver Bandel)
Date: Wed, 26 Sep 2012 00:03:18 +0200
Subject: [Rd] valgrind crashing
In-Reply-To: <50501FEA.4030200@supagro.inra.fr>
References: <mailman.21.1347098407.5750.r-devel@r-project.org>
	<50501FEA.4030200@supagro.inra.fr>
Message-ID: <20120926000318.13075oeus5tuggme@webmail.in-berlin.de>

Zitat von David <pleydell at supagro.inra.fr> (Wed, 12 Sep 2012 01:38:50 -0400)

> I am trying to do a classic
>
> R -d valgrind --vanilla < mypkg-Ex.R
>
> as described in
> http://cs.swan.ac.uk/~csoliver/ok-sat-library/internet_html/doc/doc/R/2.9.1/doc/manual/R-exts.html#Using-valgrind
>
> The problem is valgrind crashes imediately.
[...]


LOL.

...maybe you can use valgrind to debug valgrind... :->

Ciao,
    Oliver


From Sebastian.Meyer at ifspm.uzh.ch  Wed Sep 26 11:13:49 2012
From: Sebastian.Meyer at ifspm.uzh.ch (Sebastian Meyer)
Date: Wed, 26 Sep 2012 11:13:49 +0200
Subject: [Rd] non-differentiable evaluation points in nlminb(),
	follow-up of PR#15052
Message-ID: <5062C74D.3010002@ifspm.uzh.ch>

This is a follow-up question for PR#15052
<http://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15052>

There is another thing I would like to discuss wrt how nlminb() should
proceed with NAs. The question is: What would be a successful way to
deal with an evaluation point of the objective function where the
gradient and the hessian are not well defined?

If the gradient and the hessian both return NA values (assuming R <
r60789, e.g. R 2.15.1), and also if both return +Inf values, nlminb
steps to an NA parameter vector.
Here is a really artificial one-dimensional example for demonstration:

f <- function (x) {
  cat("evaluating f(", x, ")\n")
  if(is.na(x)) {Inf   # to prevent an infinite loop for R < r60789
  } else abs(x)
}
gr <- function (x) if (abs(x) < 1e-5) Inf else sign(x)
hess <- function (x) matrix(if (abs(x) < 1e-5) Inf else 0, 1L, 1L)
trace(gr)
trace(hess)
nlminb(5, f, gr, hess, control=list(eval.max=30, trace=1))

Thus, if nlminb reaches a point where the derivatives are not defined,
optimization is effectively lost. Is there a way to deal with such
points in nlminb? Otherwise, the objective function is doomed to
emergency stop() if it receives NA parameters because nlminb won't pick
up courage - regardless of the following return value of the objective
function.
As far as I would assess the situation, nlminb is currently not capable
of optimizing objective functions with non-differentiable points.

Best regards,
  Sebastian Meyer

-- 
Sebastian Meyer
Division of Biostatistics
Institute of Social and Preventive Medicine
University of Zurich


From pauljohn32 at gmail.com  Thu Sep 27 20:18:30 2012
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Thu, 27 Sep 2012 13:18:30 -0500
Subject: [Rd] tcltk capability
In-Reply-To: <CAP01uRn1EdG0cGyzoDPwmSaK2wiUWQ3mrOY3GrjMOT2qeSCXjQ@mail.gmail.com>
References: <CAP01uRn1EdG0cGyzoDPwmSaK2wiUWQ3mrOY3GrjMOT2qeSCXjQ@mail.gmail.com>
Message-ID: <CAErODj_0BLVxjTZ7tM6FKnJGhrwWOeMJ+ivQLV9srBb2JveKoQ@mail.gmail.com>

Sorry I did not see this sooner.  Response below:

On Thu, Aug 30, 2012 at 2:48 PM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> There are quite a few packages that make use of tcltk and although
>
> - most R distributions have tcltk capability
> - its possible to query this via capabilities()[["tcltk"]]
> - attempting to build a package that needs it on such an R
> distribution will give a message letting one know
>
> users still seem to have problems with this.

I agree that packages are using tcltk, but users do so at their peril.
 Just loading tcltk breaks multicore functions like mclapply. I don't
understand why, you might be able to explain it to me.

http://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15040

tcltk is discouraged, at least to some in R core.

I would really appreciate some guidance on what graphics library I
should use to develop GUI for R programs.  There's no future in tcltk,
apparently, but I don't know what to work with.

pj

pj

>
> There was recently an R bug report submitted that likely stemmed from
> the user having such a build of R and recently there was also an R
> help post that seemed to be related to this as well.  As more and more
> packages add GUI capability these incidents are bound to increase.
>
> The best situation would be to arrange that every distribution of R
> have tcltk capability but if this is difficult to arrange then I
> suggest there be a message at start up similar to the existing locale
> message letting the user know that the R distribution they are running
> lacks tcltk capability.  Preferably the message would be somewhat
> menacing so that users are encouraged to get a different distribution
> of R right from the start.
>
> This might reduce such problem reports somewhat.
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Paul E. Johnson
Professor, Political Science    Assoc. Director
1541 Lilac Lane, Room 504     Center for Research Methods
University of Kansas               University of Kansas
http://pj.freefaculty.org            http://quant.ku.edu


From ggrothendieck at gmail.com  Thu Sep 27 21:48:17 2012
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 27 Sep 2012 15:48:17 -0400
Subject: [Rd] tcltk capability
In-Reply-To: <CAErODj_0BLVxjTZ7tM6FKnJGhrwWOeMJ+ivQLV9srBb2JveKoQ@mail.gmail.com>
References: <CAP01uRn1EdG0cGyzoDPwmSaK2wiUWQ3mrOY3GrjMOT2qeSCXjQ@mail.gmail.com>
	<CAErODj_0BLVxjTZ7tM6FKnJGhrwWOeMJ+ivQLV9srBb2JveKoQ@mail.gmail.com>
Message-ID: <CAP01uRmxzLbuTbLJLEQnLkA6DB+AWhDb7qwthjpf7VuGUHrOGg@mail.gmail.com>

On Thu, Sep 27, 2012 at 2:18 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:
> Sorry I did not see this sooner.  Response below:
>
> On Thu, Aug 30, 2012 at 2:48 PM, Gabor Grothendieck
> <ggrothendieck at gmail.com> wrote:
>> There are quite a few packages that make use of tcltk and although
>>
>> - most R distributions have tcltk capability
>> - its possible to query this via capabilities()[["tcltk"]]
>> - attempting to build a package that needs it on such an R
>> distribution will give a message letting one know
>>
>> users still seem to have problems with this.
>
> I agree that packages are using tcltk, but users do so at their peril.
>  Just loading tcltk breaks multicore functions like mclapply. I don't
> understand why, you might be able to explain it to me.
>
> http://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15040
>
> tcltk is discouraged, at least to some in R core.
>
> I would really appreciate some guidance on what graphics library I
> should use to develop GUI for R programs.  There's no future in tcltk,
> apparently, but I don't know what to work with.

R aside, tcl/tk itself is far from dead. Although not as popular as in
its heyday there is still a core group that works on it and keeps
issuing new versions.  The versions are quite a few years apart but on
the other hand they tend to have major improvements to them which
would seem to justify a longer cycle.  In terms of the tcl/tk
community, new or updated packages for tcl/tk keep coming out. Looking
at some of the tcl/tk packages that I have used in the last year I
notice that several of them have a last release date of this year.
Also at least some books on tcl/tk keep coming out, the tcltk mailing
list is active, there continues to be tcl/tk conferences and there is
a very active tcl/tk wiki.

The above was for the tcl/tk language only but if we look at the tcltk
R package then its bundled with most versions of R so its the easiest
way to have a GUI with minimal installation hassle on most platforms.
On Windows and most Linux distributions just issue library(tcltk) in
your session and you have it with nothing else to do in terms of
installation.  Furthermore there is a reasonably large infrastructure
of R packages either built on tcltk or that can use tcltk as well as a
number of addon R packages that can ease development.

If you can't decide on which GUI toolkit to use have a look at
gWidgets.  It provides a common layer over multiple GUI toolkits which
subject to some limitations based on which features were used lets the
user switch at will among the various toolkits.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From nalimilan at club.fr  Fri Sep 28 09:37:39 2012
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Fri, 28 Sep 2012 09:37:39 +0200
Subject: [Rd] French Toulouse CRAN mirror always down
Message-ID: <1348817859.31596.98.camel@milan>

Hi!

One of the three French CRAN mirrors, cran.cict.fr (Toulouse) seems to
be down most of the time, and at least really not reliable. It has
currently been down for 28 days (!) [1], and I know that over two years
I've rarely been able to use it (no response, slow, hangs...).

I'm sure the maintainers of this mirror mean well, but the result is
really negative for French R users. This week I observed one user that
failed to install a package because she selected that mirror and it was
not available. Such a minor detail can give a very poor impression to
beginners.

I suggest that either the maintainers of this mirror explain why it does
not work and provide solutions to improve the situation, or it should be
removed from the list until it works reliably. Not as a punishment of
course, but for practical considerations.

At the very least this mirror should be moved down the list: at the
moment it's the first of the three French mirrors, while the two others
work very well. If the mirrors were sorted by the alphabetical order of
their full names, it would be the last one, and it would be bite French
users less often, while still acting as a fallback solution.


Thanks for taking care of this list



1: http://cran.r-project.org/mirmon_report.html#fr


From Friedrich.Leisch at r-project.org  Fri Sep 28 10:14:17 2012
From: Friedrich.Leisch at r-project.org (Friedrich.Leisch at r-project.org)
Date: Fri, 28 Sep 2012 10:14:17 +0200
Subject: [Rd] French Toulouse CRAN mirror always down
In-Reply-To: <1348817859.31596.98.camel@milan>
References: <1348817859.31596.98.camel@milan>
Message-ID: <20581.23641.717287.744772@worblehat.boku.ac.at>

>>>>> On Fri, 28 Sep 2012 09:37:39 +0200,
>>>>> Milan Bouchet-Valat (MB) wrote:

  > Hi!
  > One of the three French CRAN mirrors, cran.cict.fr (Toulouse) seems to
  > be down most of the time, and at least really not reliable. It has
  > currently been down for 28 days (!) [1], and I know that over two years
  > I've rarely been able to use it (no response, slow, hangs...).

  > I'm sure the maintainers of this mirror mean well, but the result is
  > really negative for French R users. This week I observed one user that
  > failed to install a package because she selected that mirror and it was
  > not available. Such a minor detail can give a very poor impression to
  > beginners.

  > I suggest that either the maintainers of this mirror explain why it does
  > not work and provide solutions to improve the situation, or it should be
  > removed from the list until it works reliably. Not as a punishment of
  > course, but for practical considerations.

  > At the very least this mirror should be moved down the list: at the
  > moment it's the first of the three French mirrors, while the two others
  > work very well. If the mirrors were sorted by the alphabetical order of
  > their full names, it would be the last one, and it would be bite French
  > users less often, while still acting as a fallback solution.

It has already been removed a couple of days ago, have a look e.g. at

http://cran.r-project.org/mirrors.html

will need some time to propagate to all places.

Best,
Fritz


From spencer.graves at prodsyse.com  Fri Sep 28 10:53:41 2012
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Fri, 28 Sep 2012 01:53:41 -0700
Subject: [Rd] non-differentiable evaluation points in nlminb(),
 follow-up of PR#15052
In-Reply-To: <5062C74D.3010002@ifspm.uzh.ch>
References: <5062C74D.3010002@ifspm.uzh.ch>
Message-ID: <50656595.5050508@prodsyse.com>

On 9/26/2012 2:13 AM, Sebastian Meyer wrote:
> This is a follow-up question for PR#15052
> <http://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15052>
>
> There is another thing I would like to discuss wrt how nlminb() should
> proceed with NAs. The question is: What would be a successful way to
> deal with an evaluation point of the objective function where the
> gradient and the hessian are not well defined?
>
> If the gradient and the hessian both return NA values (assuming R <
> r60789, e.g. R 2.15.1), and also if both return +Inf values, nlminb
> steps to an NA parameter vector.
> Here is a really artificial one-dimensional example for demonstration:
>
> f <- function (x) {
>    cat("evaluating f(", x, ")\n")
>    if(is.na(x)) {Inf   # to prevent an infinite loop for R < r60789
>    } else abs(x)
> }
> gr <- function (x) if (abs(x) < 1e-5) Inf else sign(x)
> hess <- function (x) matrix(if (abs(x) < 1e-5) Inf else 0, 1L, 1L)
> trace(gr)
> trace(hess)
> nlminb(5, f, gr, hess, control=list(eval.max=30, trace=1))
>
> Thus, if nlminb reaches a point where the derivatives are not defined,
> optimization is effectively lost. Is there a way to deal with such
> points in nlminb? Otherwise, the objective function is doomed to
> emergency stop() if it receives NA parameters because nlminb won't pick
> up courage - regardless of the following return value of the objective
> function.
> As far as I would assess the situation, nlminb is currently not capable
> of optimizing objective functions with non-differentiable points.

       Are you familiar with the CRAN Task View on Optimization and 
Mathematical Programming?  I ask, because as far as I know, "nlminb" is 
one of the oldest nonlinear optimizer in R.  If I understand the 
history, it was ported from S-Plus after at least one individual in the 
R Core team decided it was better for a certain task than "optim", and 
it seemed politically too difficult to enhance "optim".  Other nonlinear 
optimizers have been developed more recently and are available in 
specialized packages.


       In my opinion, functions like "nlminb" should never stop because 
it gets NA for a derivative at some point -- unless that honestly 
happened to be a local optimum.  If a function like "nlminb" computes an 
NA for a derivative not at a local optimum, it should then call a 
derivative-free optimizer, then try to compute the derivative at a local 
optimum.


       Also, any general optimizer that uses analytic derivatives should 
check to make sure that the analytic derivatives computed are reasonably 
close to numeric derivatives.  This can easily be done using the 
compareDerivatives function in the maxLik package.


       Hope this helps.
       Spencer

> Best regards,
>    Sebastian Meyer


-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567
web:www.structuremonitoring.com


From ravi.varadhan at jhu.edu  Thu Sep 27 16:27:37 2012
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Thu, 27 Sep 2012 14:27:37 +0000
Subject: [Rd] non-differentiable evaluation points in nlminb(),
	follow-up of PR#15052
In-Reply-To: <5062C74D.3010002@ifspm.uzh.ch>
References: <5062C74D.3010002@ifspm.uzh.ch>
Message-ID: <2F9EA67EF9AE1C48A147CB41BE2E15C32AFE2D@DOM-EB-MAIL1.win.ad.jhu.edu>

Can you provide a correct/sensible example that illustrates the problem?

Your gradient function is wrong.  So, how do you expect the algorithms to work?  

Why is the gradient Inf when |x| < 1.e-5?   It should be 0.

Here the following works fine:

require(optimx)

f <- function (x) {
if(is.na(x)) Inf else abs(x)
}

gr <- function (x) if (abs(x) < 1e-5) 0 else sign(x)

hess <- function (x) matrix(if (abs(x) < 1e-5) 0 else 0, 1L, 1L)

nlminb(5, f, gr, hess, control=list(eval.max=30, trace=1))

ans <- optimx(par=5, fn=f, gr=gr, control=list(all.methods=TRUE))

Ravi
________________________________________
From: r-devel-bounces at r-project.org [r-devel-bounces at r-project.org] on behalf of Sebastian Meyer [Sebastian.Meyer at ifspm.uzh.ch]
Sent: Wednesday, September 26, 2012 5:13 AM
To: r-devel at r-project.org
Subject: [Rd] non-differentiable evaluation points in nlminb(), follow-up of PR#15052

This is a follow-up question for PR#15052
<http://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15052>

There is another thing I would like to discuss wrt how nlminb() should
proceed with NAs. The question is: What would be a successful way to
deal with an evaluation point of the objective function where the
gradient and the hessian are not well defined?

If the gradient and the hessian both return NA values (assuming R <
r60789, e.g. R 2.15.1), and also if both return +Inf values, nlminb
steps to an NA parameter vector.
Here is a really artificial one-dimensional example for demonstration:

f <- function (x) {
  cat("evaluating f(", x, ")\n")
  if(is.na(x)) {Inf   # to prevent an infinite loop for R < r60789
  } else abs(x)
}
gr <- function (x) if (abs(x) < 1e-5) Inf else sign(x)
hess <- function (x) matrix(if (abs(x) < 1e-5) Inf else 0, 1L, 1L)
trace(gr)
trace(hess)
nlminb(5, f, gr, hess, control=list(eval.max=30, trace=1))

Thus, if nlminb reaches a point where the derivatives are not defined,
optimization is effectively lost. Is there a way to deal with such
points in nlminb? Otherwise, the objective function is doomed to
emergency stop() if it receives NA parameters because nlminb won't pick
up courage - regardless of the following return value of the objective
function.
As far as I would assess the situation, nlminb is currently not capable
of optimizing objective functions with non-differentiable points.

Best regards,
  Sebastian Meyer

--
Sebastian Meyer
Division of Biostatistics
Institute of Social and Preventive Medicine
University of Zurich

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

From nalimilan at club.fr  Fri Sep 28 15:14:15 2012
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Fri, 28 Sep 2012 15:14:15 +0200
Subject: [Rd] French Toulouse CRAN mirror always down
In-Reply-To: <20581.23641.717287.744772@worblehat.boku.ac.at>
References: <1348817859.31596.98.camel@milan>
	<20581.23641.717287.744772@worblehat.boku.ac.at>
Message-ID: <1348838055.31596.101.camel@milan>

Le vendredi 28 septembre 2012 ? 10:14 +0200,
Friedrich.Leisch at R-project.org a ?crit :
> >>>>> On Fri, 28 Sep 2012 09:37:39 +0200,
> >>>>> Milan Bouchet-Valat (MB) wrote:
> 
>   > Hi!
>   > One of the three French CRAN mirrors, cran.cict.fr (Toulouse) seems to
>   > be down most of the time, and at least really not reliable. It has
>   > currently been down for 28 days (!) [1], and I know that over two years
>   > I've rarely been able to use it (no response, slow, hangs...).
> 
>   > I'm sure the maintainers of this mirror mean well, but the result is
>   > really negative for French R users. This week I observed one user that
>   > failed to install a package because she selected that mirror and it was
>   > not available. Such a minor detail can give a very poor impression to
>   > beginners.
> 
>   > I suggest that either the maintainers of this mirror explain why it does
>   > not work and provide solutions to improve the situation, or it should be
>   > removed from the list until it works reliably. Not as a punishment of
>   > course, but for practical considerations.
> 
>   > At the very least this mirror should be moved down the list: at the
>   > moment it's the first of the three French mirrors, while the two others
>   > work very well. If the mirrors were sorted by the alphabetical order of
>   > their full names, it would be the last one, and it would be bite French
>   > users less often, while still acting as a fallback solution.
> 
> It has already been removed a couple of days ago, have a look e.g. at
> 
> http://cran.r-project.org/mirrors.html
> 
> will need some time to propagate to all places.
I had noticed it was not in the list, but I thought that was done
automatically when a mirror was not responding. What a coincidence it
was removed right before I write this message! ;-)

Glad to know this problem will no longer exist in the future.


Regards


From lorenz at usgs.gov  Fri Sep 28 20:57:57 2012
From: lorenz at usgs.gov (David L Lorenz)
Date: Fri, 28 Sep 2012 13:57:57 -0500
Subject: [Rd] S4method
In-Reply-To: <CAP01uRmxzLbuTbLJLEQnLkA6DB+AWhDb7qwthjpf7VuGUHrOGg@mail.gmail.com>
References: <CAP01uRn1EdG0cGyzoDPwmSaK2wiUWQ3mrOY3GrjMOT2qeSCXjQ@mail.gmail.com>	<CAErODj_0BLVxjTZ7tM6FKnJGhrwWOeMJ+ivQLV9srBb2JveKoQ@mail.gmail.com>
	<CAP01uRmxzLbuTbLJLEQnLkA6DB+AWhDb7qwthjpf7VuGUHrOGg@mail.gmail.com>
Message-ID: <OFA3B703F8.D1968544-ON86257A87.0067672B-86257A87.00682F19@usgs.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120928/000edece/attachment.pl>

From mtmorgan at fhcrc.org  Fri Sep 28 21:39:52 2012
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Fri, 28 Sep 2012 12:39:52 -0700
Subject: [Rd] S4method
In-Reply-To: <OFA3B703F8.D1968544-ON86257A87.0067672B-86257A87.00682F19@usgs.gov>
References: <CAP01uRn1EdG0cGyzoDPwmSaK2wiUWQ3mrOY3GrjMOT2qeSCXjQ@mail.gmail.com>	<CAErODj_0BLVxjTZ7tM6FKnJGhrwWOeMJ+ivQLV9srBb2JveKoQ@mail.gmail.com>
	<CAP01uRmxzLbuTbLJLEQnLkA6DB+AWhDb7qwthjpf7VuGUHrOGg@mail.gmail.com>
	<OFA3B703F8.D1968544-ON86257A87.0067672B-86257A87.00682F19@usgs.gov>
Message-ID: <5065FD08.8090305@fhcrc.org>

On 09/28/2012 11:57 AM, David L Lorenz wrote:
> I get an error when I try to use \S4method in a usage section in an Rd
> file for a function. I tried to duplicate exactly how stats4 documents its
> method functions, but I must be missing something. Here is the top part of
> the Rd file:
>
> \name{xyPlot-methods}
> \docType{methods}
> \alias{xyPlot-methods}
> \alias{xyPlot,numeric,numeric-method}
> \title{Methods for Function \code{xyPlot}}
> \description{
> Create a line or scatter plot.
> }
> \usage{
> \S4method{xyPlot}{numeric, numeric}(x, y,
> Plot = list(name = "", what = "lines", type = "solid", width = "standard",
>
>   symbol = "circle", filled = TRUE, size = 0.09, color = "black"),
> yaxis.log = FALSE, yaxis.rev = FALSE, yaxis.range = c(NA, NA),
> xaxis.log = FALSE, xaxis.range = c(NA, NA), ylabels = 7, xlabels = 7,
> xtitle = deparse(substitute(x)), ytitle = deparse(substitute(y)),
> caption = "", margin = c(NA, NA, NA, NA))
> }
>
>    The error I get is
>
> Bad \usage lines found in documentation object 'xyPlot-methods':
>    <unescaped bksl>S4method{xyPlot}{numeric, numeric}(x, y,

Hi David - R is being picky about spaces; use {numeric,numeric}. Martin

>    Plot = list(name = "", what = "lines", type = "solid", width =
> "standard",
>     symbol = "circle", filled = TRUE, size = 0.09, color = "black"),
>    yaxis.log = FALSE, yaxis.rev = FALSE, yaxis.range = c(NA, NA),
>    xaxis.log = FALSE, xaxis.range = c(NA, NA), ylabels = 7, xlabels = 7,
>    xtitle = deparse(substitute(x)), ytitle = deparse(substitute(y)),
>    caption = "", margin = c(NA, NA, NA, NA))
>
>    Here's my R info:
>
> R version 2.15.1 (2012-06-22) -- "Roasted Marshmallows"
> Copyright (C) 2012 The R Foundation for Statistical Computing
> ISBN 3-900051-07-0
> Platform: x86_64-pc-mingw32/x64 (64-bit)
>
>    The error is treated as a WARNING, so I can build and install the
> package and the documentation file looks fine when I ask for help on
> xyPlot-methods. What am I missing?
>    Thanks.
> Dave
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From lorenz at usgs.gov  Fri Sep 28 22:06:09 2012
From: lorenz at usgs.gov (David L Lorenz)
Date: Fri, 28 Sep 2012 15:06:09 -0500
Subject: [Rd] S4method
In-Reply-To: <5065FD08.8090305@fhcrc.org>
References: <CAP01uRn1EdG0cGyzoDPwmSaK2wiUWQ3mrOY3GrjMOT2qeSCXjQ@mail.gmail.com>	<CAErODj_0BLVxjTZ7tM6FKnJGhrwWOeMJ+ivQLV9srBb2JveKoQ@mail.gmail.com>
	<CAP01uRmxzLbuTbLJLEQnLkA6DB+AWhDb7qwthjpf7VuGUHrOGg@mail.gmail.com>
	<OFA3B703F8.D1968544-ON86257A87.0067672B-86257A87.00682F19@usgs.gov>
	<5065FD08.8090305@fhcrc.org>
Message-ID: <OF7D2557B0.376B5A60-ON86257A87.006E62FD-86257A87.006E6D49@usgs.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20120928/56639c1f/attachment.pl>

From alserkli at inbox.ru  Sat Sep 29 20:44:31 2012
From: alserkli at inbox.ru (Alexander Klimov)
Date: Sat, 29 Sep 2012 20:44:31 +0200
Subject: [Rd] Mirror selection Was: French Toulouse CRAN mirror always down
In-Reply-To: <1348838055.31596.101.camel@milan>
References: <1348817859.31596.98.camel@milan>
	<20581.23641.717287.744772@worblehat.boku.ac.at>
	<1348838055.31596.101.camel@milan>
Message-ID: <TheMailAgent.7a025862@30ad6e73>

On Fri, 28 Sep 2012, Milan Bouchet-Valat wrote:
> Glad to know this problem will no longer exist in the future.

To ensure that, the model of mirror selection should be reworked: if 
user wants, he may state his preferences, but by default the mirror 
should be chosen automatically and if the mirror is not accessible a 
new one should be tried.

-- 
Regards,
ASK


From Sebastian.Meyer at ifspm.uzh.ch  Sat Sep 29 21:40:10 2012
From: Sebastian.Meyer at ifspm.uzh.ch (Sebastian Meyer)
Date: Sat, 29 Sep 2012 21:40:10 +0200
Subject: [Rd] non-differentiable evaluation points in nlminb(),
 follow-up of PR#15052
In-Reply-To: <50656595.5050508@prodsyse.com>
References: <5062C74D.3010002@ifspm.uzh.ch> <50656595.5050508@prodsyse.com>
Message-ID: <50674E9A.6060401@ifspm.uzh.ch>

Thanks for the pointers to the packages optimx and maxLik.
Up to now, I actually did not spend much time in searching for elaborate
R packages specifically dealing with optimization problems, but was just
satisfied using the optim methods or nlminb. I chose nlminb, because it
can take advantage of the analytical hessian which optim cannot. In my
experience with numerical log-likelihood maximizations it works pretty
good and is more efficient (in the sense of fast and precise) in finding
an optimum than the optim methods (if both analytical derivatives are
provided).

The situation where I was confronted with non-differentiable evaluation
points involved an iterative optimization between a penalized likelihood
of regression coefficients (about 430) and a marginal likelihood of 6
variance parameters for spatio-temporal data (I won't bother you with
any more details). If the starting values of the regression coefficients
were bad, the marginal likelihood looked really irregular with multiple
local non-differentiable maxima, where my analytical gradient and
hessian were not well-defined (an implicit high-dimensional matrix which
needs inversion was (numerically) singular). However, returning NA from
the gradient or hessian function to nlminb was not helpful as
illustrated by my very simple _artificial_ example (@Ravi: I know that
the gradient is not correct, but it illustrates how nlminb might get
lost in NA's). Meanwhile I probably solved the problem by simply
continuing with the generalized inverse implemented in MASS::ginv, which
pushed the algorithm back to work in my case. A proper alternative would
be to exit from nlminb and to switch to Nelder-Mead at that point.

Best regards,
   Sebastian


On 28.09.2012 10:53, Spencer Graves wrote:
> On 9/26/2012 2:13 AM, Sebastian Meyer wrote:
>> This is a follow-up question for PR#15052
>> <http://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15052>
>>
>> There is another thing I would like to discuss wrt how nlminb() should
>> proceed with NAs. The question is: What would be a successful way to
>> deal with an evaluation point of the objective function where the
>> gradient and the hessian are not well defined?
>>
>> If the gradient and the hessian both return NA values (assuming R <
>> r60789, e.g. R 2.15.1), and also if both return +Inf values, nlminb
>> steps to an NA parameter vector.
>> Here is a really artificial one-dimensional example for demonstration:
>>
>> f <- function (x) {
>>    cat("evaluating f(", x, ")\n")
>>    if(is.na(x)) {Inf   # to prevent an infinite loop for R < r60789
>>    } else abs(x)
>> }
>> gr <- function (x) if (abs(x) < 1e-5) Inf else sign(x)
>> hess <- function (x) matrix(if (abs(x) < 1e-5) Inf else 0, 1L, 1L)
>> trace(gr)
>> trace(hess)
>> nlminb(5, f, gr, hess, control=list(eval.max=30, trace=1))
>>
>> Thus, if nlminb reaches a point where the derivatives are not defined,
>> optimization is effectively lost. Is there a way to deal with such
>> points in nlminb? Otherwise, the objective function is doomed to
>> emergency stop() if it receives NA parameters because nlminb won't pick
>> up courage - regardless of the following return value of the objective
>> function.
>> As far as I would assess the situation, nlminb is currently not capable
>> of optimizing objective functions with non-differentiable points.
> 
>       Are you familiar with the CRAN Task View on Optimization and
> Mathematical Programming?  I ask, because as far as I know, "nlminb" is
> one of the oldest nonlinear optimizer in R.  If I understand the
> history, it was ported from S-Plus after at least one individual in the
> R Core team decided it was better for a certain task than "optim", and
> it seemed politically too difficult to enhance "optim".  Other nonlinear
> optimizers have been developed more recently and are available in
> specialized packages.
> 
> 
>       In my opinion, functions like "nlminb" should never stop because
> it gets NA for a derivative at some point -- unless that honestly
> happened to be a local optimum.  If a function like "nlminb" computes an
> NA for a derivative not at a local optimum, it should then call a
> derivative-free optimizer, then try to compute the derivative at a local
> optimum.
> 
> 
>       Also, any general optimizer that uses analytic derivatives should
> check to make sure that the analytic derivatives computed are reasonably
> close to numeric derivatives.  This can easily be done using the
> compareDerivatives function in the maxLik package.
> 
> 
>       Hope this helps.
>       Spencer
> 
>> Best regards,
>>    Sebastian Meyer
> 
>


From michael.weylandt at gmail.com  Sun Sep 30 18:55:28 2012
From: michael.weylandt at gmail.com (R. Michael Weylandt)
Date: Sun, 30 Sep 2012 17:55:28 +0100
Subject: [Rd] Small Extension to license()/licence()
Message-ID: <CAAmySGObKffG2r4gceZNVcqXm_=gfHjaE9bssprFzeqLqh+uYQ@mail.gmail.com>

By analogy with maintainer(), I suggest extending license() to give
the licensing terms of packages as well as R itself when prompted.
Below is a small patch in that direction. This won't break anything
and imposes no significant maintenance burden; it has the advantage of
making it ever so marginally easier to know package licenses.

Given the existence of license forms like GPL >=2, I don't see a easy
programmatic way of identifying what RShowDoc() can provide and what
it can't, so I've left that out.

Cheers,

Michael

-------------------------------------------------

Index: src/library/base/R/license.R
===================================================================
--- src/library/base/R/license.R	(revision 60839)
+++ src/library/base/R/license.R	(working copy)
@@ -16,8 +16,14 @@
 #  A copy of the GNU General Public License is available at
 #  http://www.r-project.org/Licenses/

-licence <- license <- function() {
-    cat("\nThis software is distributed under the terms of the GNU General\n")
+licence <- license <- function(pkg = NULL) {
+  if(!is.null(pkg)) pkgd <- packageDescription(pkg)
+  if(is.null(pkg) || pkgd[["Priority"]] == "base"){
+    if(is.null(pkg)){
+      cat("\nThis software is distributed under the terms of the GNU
General\n")
+    } else {
+      cat(pkg, "is part of R and distributed under the terms of the
GNU General\n")
+    }
     cat("Public License, either Version 2, June 1991 or Version 3,
June 2007.\n")
     cat("The terms of version 2 of the license are in a file called
COPYING\nwhich you should have received with\n")
     cat("this software and which can be displayed by RShowDoc(\"COPYING\").\n")
@@ -34,4 +40,9 @@
     cat("Version 3 of the license can be displayed by RShowDoc(\"LGPL-3\").\n")
     cat("\n")
     cat("'Share and Enjoy.'\n\n")
+  } else {
+    cat(pkg, "is distributed under the", pkgd[["License"]],"License.\n")
+  }
+
+  invisible(NULL)
 }
Index: src/library/base/man/license.Rd
===================================================================
--- src/library/base/man/license.Rd	(revision 60839)
+++ src/library/base/man/license.Rd	(working copy)
@@ -8,13 +8,18 @@
 \alias{license}
 \alias{licence}
 \description{
-  The license terms under which \R is distributed.
+  The license terms under which \R or a contributed package is distributed.
 }
 \usage{
-license()
-licence()
+license(pkg = NULL)
+licence(pkg = NULL)
 }
 \details{
+  If pkg is "NULL", the licensing terms of R are given; else, the
+  license of the package (as taken from the package DESCRIPTION file) is
+  returned. Major open-source licenses can be found in
+  \file{\var{\link{R_HOME}}/share/licenses} and viewed with \link{RShowDoc}.
+
   \R is distributed under the terms of the GNU GENERAL PUBLIC LICENSE,
   either Version 2, June 1991 or Version 3, June 2007.  A copy of the
   version 2 license is in file \file{\var{\link{R_HOME}}/COPYING} and


