From muzenda80 at yahoo.co.uk  Thu Dec  1 03:46:52 2005
From: muzenda80 at yahoo.co.uk (muzenda80@yahoo.co.uk)
Date: Thu,  1 Dec 2005 03:46:52 +0100 (CET)
Subject: [Rd] =?iso-8859-1?q?Gesch=E4ftliches_Angebot_=28PR=238359=29?=
Message-ID: <20051201024652.78EC5281E3@slim.kubism.ku.dk>


This is a multi-part message in MIME format
--9b396eac-f0a5-492b-8e98-d4ee4e744c2e
Content-Type: text/plain; charset=iso-8859-1
Content-Transfer-Encoding: quoted-printable

Gesch=E4ftliches Angebot

Sie m=F6gen =FCberrascht sein, diesen Brief von mir zu erhalten, da Sie
mich nicht pers=F6nlich kennen. Der Grund meiner Vorstellung ist, dass
ich Simon Muzenda der =E4lteste Sohn von Paul Muzenda bin , einem Farmer 
in Simbabwe, der k=FCrzlich im Landstreit in meinem Land ermordet wurde.
Ich bekam den Kontakt zu Ihnen =FCber das Internet, daher beschloss ich
Ihnen zu schreiben.
Vor dem Tod meines Vaters hatte er mich mit nach Johannesburg genommen,
um 20,5 Millionen US-$ in einer privaten Sicherheitsfirma zu
hinterlegen, da er die lauernde Gefahr in Simbabwe voraussah, legte er 
sein  Geld in Form von Edelsteinen an. Die Summe war gedacht zum Erwerb
neuer Maschinen und Chemikalien f=FCr die Farmen und zur Etablierung einer =
neuen Farm in
Swaziland.
Die Landprobleme begannen, als unser Pr=E4sident Robert Mugabe eine
Landreform einf=FChrte, die sich vorwiegend auf wei=DFe reiche Farmer und
einige wenige schwarze Farmer auswirkte und in der Ermordung und
=DCberf=E4llen durch Kriegsveteranen und einige andere Geistesgest=F6rte
gipfelte. Tats=E4chlich wurden eine Menge Menschen ermordet, eines der 
Opfer  war mein Vater.
Wegen dieses Hintergrundes floh ich mit meiner Familie aus Simbabwe, um
unsre Leben zu retten und lebe vor=FCbergehend in Holland wo
wir um politisches Asyl ersuchen und beschlossen haben, das Geld meines
Vaters   zu transferieren auf ein besser erreichbares ausl=E4ndisches
Konto, da die Gesetze im Holland einem Fl=FCchtling verbieten ein Konto 
zu er=F6ffnen oder in irgendwelche finanziellen Transaktionen innerhalb
der Neiderland nvolviert zu sein.
Als dem =E4ltesten Sohn meines Vaters bin ich verantwortlich f=FCr die
Suche nach einem geeigneten ausl=E4ndischen Konto, wohin wir unser Geld 
ohne Wissen meiner Regierung, die uns alles nehmen will was wir
besitzen, transferieren  k=F6nnen.
Die s=FCdafrikanische Regierung scheint gemeinsame Sache mit ihnen zu
machen. Ich bin konfrontiert mit dem Dilemma, diesen Geldbetrag aus
S=FCdafrika zu holen in der Angst, die gleichen Erfahrungen noch einmal 
zu  machen, beide L=E4nder haben die gleiche politische Geschichte.
Als Gesch=E4ftsmann suche ich einen Partner, dem ich meine Zukunft
anvertrauen kann und die meiner Familie.
Ich muss Ihnen noch mitteilen, dass diese Transaktion risikolos ist.
Wenn Sie mir und meiner Familie beistehen wollen, m=F6chte ich von Ihnen
nur, dass Sie ein Arrangement mit der Sicherheitsfirma machen f=FCr die
=DCbergabe (der Fonds) von deren Tochtergesellschaft in London da ich
bereits die Anweisung f=FCr die =DCberf=FChrung in  den Neiderland aus 
S=FCdafrika gegeben habe. Vorher m=FCssen die Modalit=E4ten zum Wechsel des
Besitzes der Anlagen und noch wichtiger des Geldes, das ich zu investieren 
gedachte, stattgefunden haben. 
Ich habe zwei Optionen f=FCr Sie, erstens k=F6nnen Sie  w=E4hlen, einen
bestimmten Prozentsatz des Geldes f=FCr die Nutzung Ihres Kontos f=FCr die
Transaktion zu bekommen. Oder Sie k=F6nnen zweitens in eine Partnerschaft
mit mir  treten um das Geld sehr viel profitabler in Ihrem Land zu 
investieren. Welche Option Sie auch w=E4hlen, f=FChlen Sie sich frei, sich =
bei mir zu 
melden.
Ich plane 5% des Geldes f=FCr alle Arten von Unkosten im Prozess der
Transaktionen zu verwenden. Sollten Sie keine Partnerschaft bevorzugen,
bin ich gewillt 10% des Geldes zu bezahlen, w=E4hrend die restlichen 85%
f=FCr Investitionen in Ihrem Land gedacht sind.
Nehmen Sie Kontakt mit mir auf =FCber die obige E-mail -Adresse, ich
bitte Sie inst=E4ndig absolutes Stillschweigen =FCber diese Transaktion zu
wahren.

Danke, Gott segne Sie!

Muzenda  
--9b396eac-f0a5-492b-8e98-d4ee4e744c2e--


From ripley at stats.ox.ac.uk  Thu Dec  1 08:14:35 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 1 Dec 2005 07:14:35 +0000 (GMT)
Subject: [Rd] \dQuote{} in \code{} not processed
In-Reply-To: <1133368877.9803.63.camel@gsimpson.geog.ucl.ac.uk>
References: <1133368877.9803.63.camel@gsimpson.geog.ucl.ac.uk>
Message-ID: <Pine.LNX.4.61.0512010703540.17563@gannet.stats>

On Wed, 30 Nov 2005, Gavin Simpson wrote:

> Just wondering if this is the expected behaviour.

Yes.  The only command processed inside \code is \link (plus support for 
\example and \usage which go through the same processing).


> I was wanting to produce quoted text within \code{}, without manually
> entering the '"'. \dQuote{} seems advisable after reading the Writing R
> Extensions manual, so I tried \code{\dQuote{mytext}} expecting it to
> produce "mytext" in monospace font (with ' ' round it in the R help
> files) but it appears that \dQuote{mytext} is not processed within \code
> {} as \dQuote{mytext} is printed literally in the produced
> documentation.
>
> Is this intended? I didn't see any statements suggesting \code{} could
> not include other markup, and \code{\link{}} works...

Hmm, \dQuote is described in a section called

 	Marking text

   The following logical markup commands are available for emphasizing or
   quoting text.

and \code is described as

   Indicate text that is a literal example of a piece of a program, e.g., a
   fragment of @R{} code or the name of an @R{} object, using
   @code{typewriter} font if possible.

Is `literal example' not warning enough?  I'll add an explicit statement, 
but this is the first time I have seen any indication that anyone thought 
otherwise.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From gavin.simpson at ucl.ac.uk  Thu Dec  1 08:56:16 2005
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Thu, 01 Dec 2005 07:56:16 +0000
Subject: [Rd] \dQuote{} in \code{} not processed
In-Reply-To: <Pine.LNX.4.61.0512010703540.17563@gannet.stats>
References: <1133368877.9803.63.camel@gsimpson.geog.ucl.ac.uk>
	<Pine.LNX.4.61.0512010703540.17563@gannet.stats>
Message-ID: <1133423776.2575.9.camel@dsl-217-155-166-107.zen.co.uk>

On Thu, 2005-12-01 at 07:14 +0000, Prof Brian Ripley wrote:
> On Wed, 30 Nov 2005, Gavin Simpson wrote:
> 
> > Just wondering if this is the expected behaviour.
> 
> Yes.  The only command processed inside \code is \link (plus support for 
> \example and \usage which go through the same processing).
> 
> 
> > I was wanting to produce quoted text within \code{}, without manually
> > entering the '"'. \dQuote{} seems advisable after reading the Writing R
> > Extensions manual, so I tried \code{\dQuote{mytext}} expecting it to
> > produce "mytext" in monospace font (with ' ' round it in the R help
> > files) but it appears that \dQuote{mytext} is not processed within \code
> > {} as \dQuote{mytext} is printed literally in the produced
> > documentation.
> >
> > Is this intended? I didn't see any statements suggesting \code{} could
> > not include other markup, and \code{\link{}} works...
> 
> Hmm, \dQuote is described in a section called
> 
>  	Marking text
> 
>    The following logical markup commands are available for emphasizing or
>    quoting text.
> 
> and \code is described as
> 
>    Indicate text that is a literal example of a piece of a program, e.g., a
>    fragment of @R{} code or the name of an @R{} object, using
>    @code{typewriter} font if possible.
> 
> Is `literal example' not warning enough?  I'll add an explicit statement, 
> but this is the first time I have seen any indication that anyone thought 
> otherwise.

Thanks for confirming this - it was the fact that \link{} works that
caused confusion. Such \link{} usage is not a 'literal example'.

Cheers,

G

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From briscoee at slamdek.com  Thu Dec  1 10:54:50 2005
From: briscoee at slamdek.com (briscoee@slamdek.com)
Date: Thu,  1 Dec 2005 10:54:50 +0100 (CET)
Subject: [Rd] Edwin Private web case review and big savin's on our
	health enhancers. (PR#8360)
Message-ID: <20051201095450.3BC4D283A4@slim.kubism.ku.dk>

Edwin

Just what I was searching for. Thanks for sending it to me.

Kataniya

 -------Original Message-------
 
From: Maire [mailto:ob at qx.com] 
Sent: Wed, 30 Nov 2005 19:56:08 +0100
To: Tommy
Subject: Eulah Purchase your health aids for less money here.


Good Day Treva,


Express transport service makes sure that you get your supplements shipped
to you in the smallest amount of time necessary. Our webpage provides
thousands of products for many embarrassing afflictions. It's time you were
in the know and got your treatments from the most trusted site.
http://geocities.yahoo.com.br/waldo_noll/

Purchasing meds is no joy, but at least you don't have to get up if you get
them from us. 

Stop by our site where the service administration gives more than what's
expected.


Best

Shawn


the notes are the same as others add and some are deny different but I
should seem to dry add adjust me at all.'   Na  
proceed Crayford. "You needn't be afraid about humble me, old friend. I am
going


From dave at kanecap.com  Thu Dec  1 15:46:55 2005
From: dave at kanecap.com (David Kane)
Date: Thu, 1 Dec 2005 09:46:55 -0500
Subject: [Rd] guidelines on "depends" versus "suggests" and R versions
Message-ID: <17295.3295.695063.29555@gargle.gargle.HOWL>

On the topic of when to use "suggests" and "depends" and on R version requirements.

I have cc'd this message to R-devel because I am curious about what
senior developpers think about these issues. The problem arises
because we are using some functions from the package "matchit" in a
new version of our package "portfolio". We are listing the matchit in
"suggests" rather than "depends" becuase much of the package works
without it. If a user wants the functionality which requires matchit
functions, we prompt them to install it.

Our problem is that when a user loads up matchit, it requires MASS and
Zelig via depends. Moreover, Zelig itself requires MASS and boot. So,
just to use our package portfolio, a user is now required to load up
three packages even though, I think, only a single function from one
of these packages it actually required.

Kosuke Imai writes:
 > We have MASS and Zelig in there because some functions are borrowed from 
 > those packages. 

The right way to handle this is only to make these packages as
"suggests" rather than "depends" and then install them if needed, as
you do correctly with optmatch. Note that Writing R Extensions says:

"Packages that need to be attached to successfully load the package
using library(pkgname) must be listed in the Depends field."

Although this is not directlty on point, my interpretation is that you
need a "good reason" to list a package in Depends rather than
Suggests.

 > MASS is a standard package, and so i don't think it's a 
 > big problem to require it. 

True. But is there some reason that this could not just be a suggest?

 > And, some of us including myself hope that 
 > Zelig will become a standard package in the future! :) 

But it isn't yet. Moreover, if you really want this to happen there is
a lot you should be doing with the code base, like test cases and S-4
classes and . . . .

 > As for the requirement of R 2.2.0, we do it simply because we only
 > test it against the most recent version of R. 

I do not *think* that this is the way cool package authors do
things. (Nor do you yourself do it for Zelig.) It is easy to check (if
you have test cases!) that a package works with the current version of
R since checks are run on CRAN each day.

 > Some functions are not backward compatible because R is not
 > generally not backward compatible.

R is amazingly backward compatible, I would say. I do not *think* that
there is any reason why matchit requires anything prior to 2.0.0. By
having a 2.2.0 requiremnt, you make it impossible for people using
earlier versions of R to use the package. This is a problem for me
because, if I want to use matchit, the same constraint will apply to
*my* package.

I think that the cool people handle this by ensuring that the package
works with version X and then leaving that as constraint in
depends. Since R automates the testing of packages, one can easily
check that the package still works (if you have test cases!) as more
versions of R come out. Now, there is a dilemma in that, as you
fix/improve the package, you may not *know* for a fact that it *still*
works with version X but the vast majority of things will. Major
changes are highlighted in the release notes. 

Why does any of this whining matter to you? Well, if all of the above
gets annoying enough, then other package authors like me will not
bother to include matchit. We will just copy and paste the subset of
the code that we want to use into our own package. This is not
desirable but is allowed. We would prefer not to do this with our
portfolio package, but we have users who are running R 2.1.0 that we
want our package to work for  . . .

In any event, thanks for your time and for a useful piece of open
source software. I am a big fan of matchit (and Zelig). The point of
all the above is to make some suggestions that I *think* will result
in wider use of the program. But, again, I am curious about what more
senior/experienced R developpers think.

Dave Kane


From mtmorgan at fhcrc.org  Thu Dec  1 18:34:55 2005
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Thu, 01 Dec 2005 09:34:55 -0800
Subject: [Rd] (not just!) Windows R CMD build <pkg> leftovers
In-Reply-To: <6phacftq4r9.fsf@gopher3.fhcrc.org> (Martin Morgan's message of
	"Thu, 24 Nov 2005 10:28:58 -0800")
References: <6phacftq4r9.fsf@gopher3.fhcrc.org>
Message-ID: <6phvey8yb40.fsf@gopher3.fhcrc.org>

Perhaps this earlier post slipped through the cracks? My apologies if
it's still 'in process', or I missed a response, or if the
contribution isn't helpful.

At any rate, I realized that the problem is not windows-specific.

Also, generating $libdir by calling (a sligthly modified) R_tempfile
might give installation more of a fighting chance in a cluttered TMPDIR.

Index: src/scripts/build.in
===================================================================
--- src/scripts/build.in        (revision 36565)
+++ src/scripts/build.in        (working copy)
@@ -76,7 +76,7 @@
 my $R_platform = R_getenv("R_PLATFORM", "unknown-binary");
 my $gzip = R_getenv("R_GZIPCMD", "gzip");
 my $tar = R_getenv("TAR", "tar");
-my $libdir = &file_path(${R::Vars::TMPDIR}, "Rinst.$$");
+my $libdir = R_tempfile("Rinst.");
 
 my $INSTALL_opts = "";
 $INSTALL_opts .= " --use-zip" if $opt_use_zip;
@@ -434,6 +434,8 @@
            if($doit && R_system($cmd)) {
                $log->error();
                $log->print("Installation failed.\n");
+               $log->print("Removing '$libdir'\n");
+               rmtree($libdir);
                exit(1);
            }
            my $R_LIBS = $ENV{'R_LIBS'};
Index: share/perl/R/Utils.pm
===================================================================
--- share/perl/R/Utils.pm       (revision 36565)
+++ share/perl/R/Utils.pm       (working copy)
@@ -75,7 +75,7 @@
                           $pat . $$ . sprintf("%05d", rand(10**5)));
 
     my $n=0;
-    while(-f $retval){
+    while(-e $retval){
        $retval = file_path($R::Vars::TMPDIR,
                            $pat . $$ . sprintf("%05d", rand(10**5)));
        croak "Cannot find unused name for temporary file"


Martin Morgan <mtmorgan at fhcrc.org> writes:

> A command
>
> R CMD build  <pkg>
>
> that fails, e.g., because of C code compilation errors, leaves a
> directory %TMPDIR%/Rinst.xxx containing the file R.css. Although R
> CMD INSTALL --build cleans up after itself, build does not. A fix is
> below. Also, build.in references Rcmd.exe, which I thought was no
> longer necessary?
>
> Index: build.in
> ===================================================================
> --- build.in	(revision 36450)
> +++ build.in	(working copy)
> @@ -434,6 +434,8 @@
>  	    if($doit && R_system($cmd)) {
>  		$log->error();
>  		$log->print("Installation failed.\n");
> +		$log->print("Removing '$libdir'\n");
> +		rmtree($libdir);
>  		exit(1);
>  	    }
>  	    my $R_LIBS = $ENV{'R_LIBS'};
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From rpeng at jhsph.edu  Thu Dec  1 20:46:58 2005
From: rpeng at jhsph.edu (Roger Peng)
Date: Thu, 01 Dec 2005 14:46:58 -0500
Subject: [Rd] import of Namespaces
In-Reply-To: <438AE711.4000708@stamats.de>
References: <438AE711.4000708@stamats.de>
Message-ID: <438F5332.2080902@jhsph.edu>

My understanding is of your questions is below:

Matthias Kohl wrote:
> Dear R devels,
> 
> let's say I have three packages "pkg1", "pkg2" and "pkg3" which all 
> contain new S4 classes and methods. Where "pkg3" depends on "pkg2" and 
> "pkg2" depends on "pkg1". Moreover, all three packages have namespaces.
> 
> 1) I use ".onLoad <- function(lib, pkg) require(methods)". Do I also 
> have to import the namespace of "methods" package?

No.

> 
> 2) If I use import("pkg1") in the namespace of "pkg2", does this also 
> (correctly) import the S4 classes and methods of "pkg1"? Or do I 
> explicitly have to use importClassesFrom resp. importMethodsFrom?

Importing an entire package namespace will import all of the exported 
classes/methods from "pkg1".

> 
> 3) If I import the Namespace of "pkg2" in "pkg3", where the namespace of 
> "pkg2" has import("pkg1") (or maybe importClassesFrom, 
> importMethodsFrom) and I also want to use S4 classes and methods of 
> "pkg1" in "pkg3". Is it sufficient to have import("pkg2") in the 
> Namespace of "pkg3" or do I need import("pkg1") and import("pkg2")?

I believe you need to import each separately since the S4 
classes/methods from "pkg1" will not be available to you simple because 
you imported "pgk2" (i.e. I don't think the chain rule applies here).

> 
> Many thanks for your help and advice
> Matthias
> 

-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/


From ripley at stats.ox.ac.uk  Thu Dec  1 22:09:31 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 1 Dec 2005 21:09:31 +0000 (GMT)
Subject: [Rd] tuned BLAS
Message-ID: <Pine.LNX.4.61.0512012034460.31653@gannet.stats>

I've been updating the information on tuned BLAS for R-admin in R-patched 
and R-devel.  We have

ATLAS 	(widely available, including for Windows)
MKL	(licensed on ix86 and x86_64 Linux and Windows)
ACML	(by AMD, but for all ix86 and x86_64 chips, Linux and Windows.
          Now available for gfortran.)
Goto	(academic use only, only some chips, only Linux)

MKL and ACML provide full LAPACK, the other two some optimized LAPACK 
routines.  (We have an MKL licence with our icc/ifort licences but it has 
not been delivered yet so I used a non-commercial Linux-only download. 
Hence I have not tried Windows.)

On 32-bit Linux I used my dual Athlon 2600 MP desktop (about to be 
replaced).  Goto no longer supports that chip, and ACML is not threaded 
(for gcc).  ACML was a little faster than ATLAS, which was faster than 
MKL.  However, MKL exploited the two processors to halve the elapsed time. 
MKL on that chip is poor on complex linear algehra.

On 64-bit Linux I used a dual Athlon 248.  Here the Goto BLAS was the 
fastest, but only just faster than ACML when using one CPU.  ATLAS was 
slightly slower, and MKL perhaps 20% slower but good at exploiting 2 
CPUs.  This time it was not relatively slower at complex algebra.

On Windows ACML is effective.  I tested my laptop, a 2GHz Pentium M
(such chips are far faster than their GHz would suggest).
ACML outperformed ATLAS by 10-25%.

These comparisons are biased as I have not compared MKL on Intel 
processors.  That's lack of interest as all our current compute servers 
are AMD.

The revelation was ACML: fast, easy to use even on Windows and completely
gcc-compatible.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Fri Dec  2 11:28:19 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 2 Dec 2005 10:28:19 +0000 (GMT)
Subject: [Rd] (not just!) Windows R CMD build <pkg> leftovers
In-Reply-To: <6phvey8yb40.fsf@gopher3.fhcrc.org>
References: <6phacftq4r9.fsf@gopher3.fhcrc.org>
	<6phvey8yb40.fsf@gopher3.fhcrc.org>
Message-ID: <Pine.LNX.4.61.0512011856390.6674@gannet.stats>

On Thu, 1 Dec 2005, Martin Morgan wrote:

> Perhaps this earlier post slipped through the cracks? My apologies if
> it's still 'in process', or I missed a response, or if the
> contribution isn't helpful.

Have patience, it is `in process'.  But if you consider such things 
important (and clearly you do enough to pester) you should file a bug 
report, not post to R-devel.  This one appears to be a minor infelicity in 
a procedure only for packages with broken vignettes.  (It _would_ have 
helped to have a clearer description of the problem being addressed: 
INSTALL --build is nothing to do with vignettes, and not many CRAN 
packages have vignettes and AFAIK none are broken.  Think abut supplying 
a NEWS entry to describe the fix.)

R.exe CMD is just a roundabout way of doing what Rcmd.exe does. Don't 
confuse `necessary' with `recommended' or `efficient'.

> At any rate, I realized that the problem is not windows-specific.
>
> Also, generating $libdir by calling (a sligthly modified) R_tempfile
> might give installation more of a fighting chance in a cluttered TMPDIR.

Not sure we should be encouraging such bad housekeeping!

> Index: src/scripts/build.in
> ===================================================================
> --- src/scripts/build.in        (revision 36565)
> +++ src/scripts/build.in        (working copy)
> @@ -76,7 +76,7 @@
> my $R_platform = R_getenv("R_PLATFORM", "unknown-binary");
> my $gzip = R_getenv("R_GZIPCMD", "gzip");
> my $tar = R_getenv("TAR", "tar");
> -my $libdir = &file_path(${R::Vars::TMPDIR}, "Rinst.$$");
> +my $libdir = R_tempfile("Rinst.");
>
> my $INSTALL_opts = "";
> $INSTALL_opts .= " --use-zip" if $opt_use_zip;
> @@ -434,6 +434,8 @@
>            if($doit && R_system($cmd)) {
>                $log->error();
>                $log->print("Installation failed.\n");
> +               $log->print("Removing '$libdir'\n");
> +               rmtree($libdir);
>                exit(1);
>            }
>            my $R_LIBS = $ENV{'R_LIBS'};
> Index: share/perl/R/Utils.pm
> ===================================================================
> --- share/perl/R/Utils.pm       (revision 36565)
> +++ share/perl/R/Utils.pm       (working copy)
> @@ -75,7 +75,7 @@
>                           $pat . $$ . sprintf("%05d", rand(10**5)));
>
>     my $n=0;
> -    while(-f $retval){
> +    while(-e $retval){
>        $retval = file_path($R::Vars::TMPDIR,
>                            $pat . $$ . sprintf("%05d", rand(10**5)));
>        croak "Cannot find unused name for temporary file"
>
>
> Martin Morgan <mtmorgan at fhcrc.org> writes:
>
>> A command
>>
>> R CMD build  <pkg>
>>
>> that fails, e.g., because of C code compilation errors, leaves a
>> directory %TMPDIR%/Rinst.xxx containing the file R.css. Although R
>> CMD INSTALL --build cleans up after itself, build does not. A fix is
>> below. Also, build.in references Rcmd.exe, which I thought was no
>> longer necessary?
>>
>> Index: build.in
>> ===================================================================
>> --- build.in	(revision 36450)
>> +++ build.in	(working copy)
>> @@ -434,6 +434,8 @@
>>  	    if($doit && R_system($cmd)) {
>>  		$log->error();
>>  		$log->print("Installation failed.\n");
>> +		$log->print("Removing '$libdir'\n");
>> +		rmtree($libdir);
>>  		exit(1);
>>  	    }
>>  	    my $R_LIBS = $ENV{'R_LIBS'};
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From berwin at maths.uwa.edu.au  Fri Dec  2 11:31:13 2005
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Fri, 2 Dec 2005 18:31:13 +0800
Subject: [Rd] Enlightenment sought and a possible buglet in vector.Rd
Message-ID: <17296.8817.937646.30624@bossiaea.maths.uwa.edu.au>

Dear all,

First, I recently had reasons to read the help page of as.vector() and
noticed in the example section the following example:

     x <- c(a = 1, b = 2)
     is.vector(x)
     as.vector(x)
     all.equal(x, as.vector(x)) ## FALSE

However, in all versions of R in which I executed this example, the
all.equal command returned TRUE which suggest that either the comment
in the help file is wrong or the all.equal/as.vector combination does
not work as intended in this case.  For the former case, I attach
below a patch which would fix vector.Rd.

Secondly, I stumbled across two behaviours of R that I cannot explain
but would like to know why R behaves as it does.  But since I expect
the explanations to be quite technical, I though that r-devel is the
more appropriate list to ask on than r-help.

The first example is the following:

       > f1
       function(){
           par.def <- par(no.readonly=TRUE)
           on.exit(par(par.def))
           tt <- sys.on.exit()
           print(tt)
           str(tt)
           invisible()
         }
       > f1()
       par(par.def)
        language par(par.def)
       > f2
       function(){
           par.def <- par(no.readonly=TRUE)
           on.exit(par(par.def))
           print(tt <- sys.on.exit())
           str(tt)
           invisible()
         }
       > f2()
       NULL
        NULL

I found in the R language definition manual the passage that
discourages users of assigning objects within function calls since it
is not guaranteed that the assignment is ever made because of R's lazy
evaluation model.  But this does not seem to explain the above
behaviour since the argument to print is evaluated.  If I replace
sys.on.exit() with, say, ls() in both functions, then they produce the
same output (and the output that I expect).  Why does f2() not work
with sys.on.exit()?

The second behaviour that I cannot explain was produced by code
written by somebody else, namely: 

      > foo
      function(x){
          z <- x/4
          while( abs(z*z*z-x) > 1e-10 ){
             z <- (2*z+x/z^2)/3
          }
      }

The documentation of function() says that if "the end of a function is
reached without calling 'return', the value of the last evaluated
expression is returned."  And this seems to happen in this case:

      > z <- foo(3)
      > z
      [1] 1.442250

However, my understanding was always that the return value of a
function issued on the command line will be printed; except, of
course, if invisible() is used to return the value.  This is not the
case for the above function:

      > foo(3)

produces no output.  And this had us stunned for some time.  On the
other hand:

      > ( foo(3) )
      [1] 1.442250

So my question is why does R, when "foo(3)" is issued on the command
line, not print the value returned by the function?

Any enlightening comments are highly appreciated.

Cheers,

        Berwin


-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: R-patch
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20051202/5340f532/R-patch.pl

From darius at wog.com.au  Fri Dec  2 11:46:43 2005
From: darius at wog.com.au (darius@wog.com.au)
Date: Fri,  2 Dec 2005 11:46:43 +0100 (CET)
Subject: [Rd] Bernie Now you can enjoy the convenience of ordering
	mitigating products from your house at a time that is
	convenient for you. (PR#8362)
Message-ID: <20051202104643.27CCD28EB5@slim.kubism.ku.dk>

Bernie

Much thanks for letting me see this. It is just what I was trying to find

Rumiko

 -------Original Message-------
 
From: Lindsey [mailto:yqqvog at ohavso.com] 
Sent: Fri, 02 Dec 2005 03:57:42 -0400
To: Aleta
Subject: Chang This on line health products e outlet is the greatest I have
ever used.


Hi Nicol,


Manage your PMS by consuming our item. You will definitely find all the
brand name supplements and more in our outlet. Our chemist is based out of
country, so no prior doctor's note is requested. This is the center of top
treatment, worth & services.
http://geocities.yahoo.com.br/isidro_dumesnil/

Any inquiries? Get hold of us 24/7. Your trust is all to us.  Want your
effective aid right now? Have it delivered lightning fast to your door with
our rush transport service.

Ordering meds at our e-pharmacy means spending less dough and more time at
home.


We can talk more later

Kathi


This drew me into the conversation, which now took family a everything more
conventional indirectly from any of the turn following lamp post that you do
or cause:   wu  
pizza Chapter building far 7.


From ripley at stats.ox.ac.uk  Fri Dec  2 11:46:38 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 2 Dec 2005 10:46:38 +0000 (GMT)
Subject: [Rd] Enlightenment sought and a possible buglet in vector.Rd
In-Reply-To: <17296.8817.937646.30624@bossiaea.maths.uwa.edu.au>
References: <17296.8817.937646.30624@bossiaea.maths.uwa.edu.au>
Message-ID: <Pine.LNX.4.61.0512021039350.18448@gannet.stats>

On Fri, 2 Dec 2005, Berwin A Turlach wrote:

[...]

> The second behaviour that I cannot explain was produced by code
> written by somebody else, namely:
>
>      > foo
>      function(x){
>          z <- x/4
>          while( abs(z*z*z-x) > 1e-10 ){
>             z <- (2*z+x/z^2)/3
>          }
>      }
>
> The documentation of function() says that if "the end of a function is
> reached without calling 'return', the value of the last evaluated
> expression is returned."  And this seems to happen in this case:

Yes, but that value can be returned with R_Visible set to 0, by calling 
invisible() _or otherwise_.

>      > z <- foo(3)
>      > z
>      [1] 1.442250
>
> However, my understanding was always that the return value of a
> function issued on the command line will be printed; except, of
> course, if invisible() is used to return the value.  This is not the
> case for the above function:
>
>      > foo(3)
>
> produces no output.  And this had us stunned for some time.  On the
> other hand:
>
>      > ( foo(3) )
>      [1] 1.442250
>
> So my question is why does R, when "foo(3)" is issued on the command
> line, not print the value returned by the function?

R does not print the value of a while() loop.  Try

x <-3
z <- x/4
while( abs(z*z*z-x) > 1e-10 ){
   z <- (2*z+x/z^2)/3
}
.Last.value

and you are seeing no different.  (Look up the code of do_while for why.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Fri Dec  2 12:37:37 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 2 Dec 2005 11:37:37 +0000 (GMT)
Subject: [Rd] Enlightenment sought and a possible buglet in vector.Rd
In-Reply-To: <17296.8817.937646.30624@bossiaea.maths.uwa.edu.au>
References: <17296.8817.937646.30624@bossiaea.maths.uwa.edu.au>
Message-ID: <Pine.LNX.4.61.0512021120450.25330@gannet.stats>

On Fri, 2 Dec 2005, Berwin A Turlach wrote:

> Secondly, I stumbled across two behaviours of R that I cannot explain
> but would like to know why R behaves as it does.  But since I expect
> the explanations to be quite technical, I though that r-devel is the
> more appropriate list to ask on than r-help.
>
> The first example is the following:
>
>       > f1
>       function(){
>           par.def <- par(no.readonly=TRUE)
>           on.exit(par(par.def))
>           tt <- sys.on.exit()
>           print(tt)
>           str(tt)
>           invisible()
>         }
>       > f1()
>       par(par.def)
>        language par(par.def)
>       > f2
>       function(){
>           par.def <- par(no.readonly=TRUE)
>           on.exit(par(par.def))
>           print(tt <- sys.on.exit())
>           str(tt)
>           invisible()
>         }
>       > f2()
>       NULL
>        NULL
>
> I found in the R language definition manual the passage that
> discourages users of assigning objects within function calls since it
> is not guaranteed that the assignment is ever made because of R's lazy
> evaluation model.  But this does not seem to explain the above
> behaviour since the argument to print is evaluated.  If I replace
> sys.on.exit() with, say, ls() in both functions, then they produce the
> same output (and the output that I expect).  Why does f2() not work
> with sys.on.exit()?

It does work, but you seems to have misunderstood what it does.  See e.g. 
the `bug' report discussed at

 	http://tolstoy.newcastle.edu.au/~rking/R/devel/05/02/2112.html

You might find

g <- function(test) {}
f2 <- function(){
        par.def <- par(no.readonly=TRUE)
        on.exit(par(par.def))
        g(tt <- sys.on.exit())
        str(tt)
        invisible()
}
f2()

illuminating.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Fri Dec  2 14:44:22 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 2 Dec 2005 14:44:22 +0100
Subject: [Rd] all.equal() for mismatching names {was "Enlightenment
	sought..."}
In-Reply-To: <17296.8817.937646.30624@bossiaea.maths.uwa.edu.au>
References: <17296.8817.937646.30624@bossiaea.maths.uwa.edu.au>
Message-ID: <17296.20406.853935.686989@stat.math.ethz.ch>

>>>>> "BeT" == Berwin A Turlach <berwin at maths.uwa.edu.au>
>>>>>     on Fri, 2 Dec 2005 18:31:13 +0800 writes:

    BeT> First, I recently had reasons to read the help page of as.vector() and
    BeT> noticed in the example section the following example:

    BeT> x <- c(a = 1, b = 2)
    BeT> is.vector(x)
    BeT> as.vector(x)
    BeT> all.equal(x, as.vector(x)) ## FALSE

actually 'FALSE' was never the case,  but "non-TRUE" once was, see below.

    BeT> However, in all versions of R in which I executed this example, the
    BeT> all.equal command returned TRUE which suggest that either the comment
    BeT> in the help file is wrong or the all.equal/as.vector combination does
    BeT> not work as intended in this case.  For the former case, I attach
    BeT> below a patch which would fix vector.Rd.

We recently had the following posting on R-devel
https://stat.ethz.ch/pipermail/r-devel/2005-October/034962.html
(Subject: [Rd] all.equal() improvements (PR#8191))
where Andrew Piskorsky proposed a (quite
extensive) patch to all.equal()  in order to  make sure that
things like names must match for all.equal() to return TRUE.


I did agree back then, and Brian partly disagreed with the very
valid argument that all.equal() has been used in code testing
(particularly R CMD check for packges), and that changes to make all.equal()
more "picky" might well have bad consequences for package
testing.  Also Andy didn't provide the necessary patches to the
documentation that would have been entailed.  
Well, all that's just an excuse for the fact that I had really
lost the topic out of sight ;-)

However, I'd like to take up the case, and I believe we should
fix all.equal() for at at least the following reasons:

1- logical consistency

2- earlier R versions were more picky about name mismatch
   (upto R version 1.6.2) :

  > x <- c(a=1, b=pi); all.equal(x, as.vector(x))
  [1] "names for target but not for current"
  [2] "TRUE"

3- two versions of S-plus were more picky too,
   in particular, S+3.4 which used to be our prototype:
 
   > x <- c(a=1, b=pi); all.equal(x, as.vector(x))
   [1] "names for target but not for current"
   attr(, "continue"):
   [1] T

   Here's Splus 6.2 :

   > x <- c(a=1, b=pi); all.equal(x, as.vector(x))
   [1] "target, current classes differ: named : numeric"
   [2] "class of target is \"named\", class of current is \"numeric\" (coercing target to class of current)"

----

I really don't expect package checkings to fail because of a
change.
If some would start failing, a fix should be quiet simple for
the package author and would help find inconsistencies in their
own code IMO.

Martin Maechler, ETH Zurich


From p.lijnzaad at med.uu.nl  Fri Dec  2 17:42:05 2005
From: p.lijnzaad at med.uu.nl (p.lijnzaad@med.uu.nl)
Date: Fri,  2 Dec 2005 17:42:05 +0100 (CET)
Subject: [Rd] R CMD INSTALL fails if cd prints stuff to stdout ... (PR#8363)
Message-ID: <20051202164205.4E5B815ADE@slim.kubism.ku.dk>


--Boundary_(ID_erFAa+o6kWefQxXf6GD2RA)
Content-type: text/plain; charset="us-ascii"
Content-disposition: inline
Content-transfer-encoding: 7bit

Dear all,

I came across puzzling behaviour of R CMD INSTALL, which I tracked down to the 
fact that in some shells (or in some user customizations of them), the cd 
command prints out the new directory. As a result, the $pkgs variable gets a 
wrong value, e.g.in the following transcript: 

philip at gen031:tmp$ R CMD INSTALL  GlobalAncova          
/usr/lib/R/bin/INSTALL: line 873: cd: /home/philip/tmp/GlobalAncova
/var/tmp/philip/misc/GlobalAncova: No such file or directory
sed: can't read DESCRIPTION: No such file or directory
ERROR: no 'Package' field in 'DESCRIPTION'
philip at gen031:tmp$ 

The error at line 873 is due to the variable $pkgs containing the string 
'/home/philip/tmp/GlobalAncova
/var/tmp/philip/misc/GlobalAncova'

(i.e. including the new line. Incidentally, /home/philip/tmp dir is a symlink 
to /var/tmp/philip/misc; hence the non-identical directory names). 

A simple fix (cd "${1}" > /dev/null 2>&1 && ${GETWD}) takes care of this, and 
should work under sh, ksh, bourne shell, zsh. A context diff is attached; I 
hope this will prove useful. Kind regards,


                                                                       Philip

-- 
Philip Lijnzaad
Genomics Laboratory
Dept. of Biomedical Genetics
University Medical Center (UMC), Utrecht
Stratenum room 2.201 (on Mondays and Thursdays not in after 14.45)
MSN chat (*NOT* email): philip_lijnzaad at hotmail.com
P.O. Box 85060, 3508 AB Utrecht
(Universiteitsweg 100, 3584 CG Utrecht)
The Netherlands
tel: +31 (0)30 253 8464
fax: +31 (0)30 253 8479

--Boundary_(ID_erFAa+o6kWefQxXf6GD2RA)
Content-type: text/x-diff; charset="us-ascii"; name="INSTALL.patch"
Content-disposition: attachment; filename="INSTALL.patch"
Content-transfer-encoding: 7bit

*** INSTALL~	Wed Jun 22 11:09:59 2005
--- INSTALL	Fri Dec  2 17:08:50 2005
***************
*** 127,136 ****
  get_packages () {
    ## get the full path names to all packages contained in $1.
    ## NOTE: modifies pkgs!
    if grep "^Contains:" "${1}/DESCRIPTION" >/dev/null; then
      bundlepkg=`get_dcf_field Contains "${1}/DESCRIPTION"`
      for p in ${bundlepkg}; do
!       pkgs="${pkgs} \"`cd "${1}/${p}" && ${GETWD}`\""
        if test -f "${1}/${p}/DESCRIPTION.in"; then
          ## Try being defensive about missing final newlines, or extra
  	## empty lines.
--- 127,138 ----
  get_packages () {
    ## get the full path names to all packages contained in $1.
    ## NOTE: modifies pkgs!
+   PROMPT_COMMAND=
+   BASH_COMMAND=
    if grep "^Contains:" "${1}/DESCRIPTION" >/dev/null; then
      bundlepkg=`get_dcf_field Contains "${1}/DESCRIPTION"`
      for p in ${bundlepkg}; do
!       pkgs="${pkgs} \"`cd "${1}/${p}>/dev/null 2>&1" && ${GETWD}`\""
        if test -f "${1}/${p}/DESCRIPTION.in"; then
          ## Try being defensive about missing final newlines, or extra
  	## empty lines.
***************
*** 139,145 ****
        fi
      done
    else
!     pkgs="${pkgs} \"`cd "${1}" && ${GETWD}`\""
    fi
  }
  
--- 141,147 ----
        fi
      done
    else
!     pkgs="${pkgs} \"`cd "${1}" > /dev/null 2>&1 && ${GETWD}`\""
    fi
  }
  

--Boundary_(ID_erFAa+o6kWefQxXf6GD2RA)--


From maechler at stat.math.ethz.ch  Fri Dec  2 17:56:31 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 2 Dec 2005 17:56:31 +0100
Subject: [Rd] t() dropping NULL dimnames {was "all.equal() for mismatching
	names..."}
In-Reply-To: <17296.20406.853935.686989@stat.math.ethz.ch>
References: <17296.8817.937646.30624@bossiaea.maths.uwa.edu.au>
	<17296.20406.853935.686989@stat.math.ethz.ch>
Message-ID: <17296.31935.139175.48521@stat.math.ethz.ch>

>>>>> "MM" == Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Fri, 2 Dec 2005 14:44:22 +0100 writes:

>>>>> "BeT" == Berwin A Turlach <berwin at maths.uwa.edu.au>
>>>>>     on Fri, 2 Dec 2005 18:31:13 +0800 writes:

    BeT> First, I recently had reasons to read the help page of as.vector() and
    BeT> noticed in the example section the following example:

    BeT> x <- c(a = 1, b = 2)
    BeT> is.vector(x)
    BeT> as.vector(x)
    BeT> all.equal(x, as.vector(x)) ## FALSE

   MM> actually 'FALSE' was never the case,  but "non-TRUE" once was, see below.

    BeT> However, in all versions of R in which I executed this example, the
    BeT> all.equal command returned TRUE which suggest that either the comment
    BeT> in the help file is wrong or the all.equal/as.vector combination does
    BeT> not work as intended in this case.  For the former case, I attach
    BeT> below a patch which would fix vector.Rd.

    MM> We recently had the following posting on R-devel
    MM> https://stat.ethz.ch/pipermail/r-devel/2005-October/034962.html
    MM> (Subject: [Rd] all.equal() improvements (PR#8191))
    MM> where Andrew Piskorsky proposed a (quite
    MM> extensive) patch to all.equal()  in order to  make sure that
    MM> things like names must match for all.equal() to return TRUE.

I'm testing the first part of Andy's proposition
{the 2nd part was about making the result strings more informative for
 the case where all.equal() does *not* return TRUE}.

Interestingly, it did break 'make check' and because of a
somewhat subtle reason;  
something we could consider an other (typically inconsequential) 
inconsistency :

t() drops dimnames when they are list(NULL,NULL) 
and has been doing so at least since R version 1.0.0 :

 x <- cbind(1:2, 2:1); dimnames(x) <- list(NULL, NULL) 
 identical(x, t(x))  ## -> FALSE !
 str(t(x)) # "no dimnames" (i.e. dimnames(x) === NULL)

Now I'm looking into changing that one....

Martin


From ripley at stats.ox.ac.uk  Fri Dec  2 18:20:33 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri,  2 Dec 2005 18:20:33 +0100 (CET)
Subject: [Rd] (PR#8363) R CMD INSTALL fails if cd prints stuff to stdout
Message-ID: <20051202172033.94391281E8@slim.kubism.ku.dk>

What shells are these?  You don't give an example that causes trouble, and 
in particular no way to reproduce this.

The behaviour you describe is prohibited by the POSIX standard, so the 
problem would appear to be with the unnamed shell.  I can see how it could 
happen if a user redefines 'cd', but then a user could redefine all the 
commands in his OS and we have to make some reasonable assumptions

You seem not to have submitted a patch against the R sources, which 
contain src/scripts/INSTALL.in, not INSTALL, and it contains changes you 
do not mention.

On Fri, 2 Dec 2005 p.lijnzaad at med.uu.nl wrote:

>
> --Boundary_(ID_erFAa+o6kWefQxXf6GD2RA)
> Content-type: text/plain; charset="us-ascii"
> Content-disposition: inline
> Content-transfer-encoding: 7bit
>
> Dear all,
>
> I came across puzzling behaviour of R CMD INSTALL, which I tracked down to the
> fact that in some shells (or in some user customizations of them), the cd
> command prints out the new directory. As a result, the $pkgs variable gets a
> wrong value, e.g.in the following transcript:
>
> philip at gen031:tmp$ R CMD INSTALL  GlobalAncova
> /usr/lib/R/bin/INSTALL: line 873: cd: /home/philip/tmp/GlobalAncova
> /var/tmp/philip/misc/GlobalAncova: No such file or directory
> sed: can't read DESCRIPTION: No such file or directory
> ERROR: no 'Package' field in 'DESCRIPTION'
> philip at gen031:tmp$
>
> The error at line 873 is due to the variable $pkgs containing the string
> '/home/philip/tmp/GlobalAncova
> /var/tmp/philip/misc/GlobalAncova'
>
> (i.e. including the new line. Incidentally, /home/philip/tmp dir is a symlink
> to /var/tmp/philip/misc; hence the non-identical directory names).
>
> A simple fix (cd "${1}" > /dev/null 2>&1 && ${GETWD}) takes care of this, and
> should work under sh, ksh, bourne shell, zsh. A context diff is attached; I
> hope this will prove useful. Kind regards,
>
>
>                                                                       Philip
>
> -- 
> Philip Lijnzaad
> Genomics Laboratory
> Dept. of Biomedical Genetics
> University Medical Center (UMC), Utrecht
> Stratenum room 2.201 (on Mondays and Thursdays not in after 14.45)
> MSN chat (*NOT* email): philip_lijnzaad at hotmail.com
> P.O. Box 85060, 3508 AB Utrecht
> (Universiteitsweg 100, 3584 CG Utrecht)
> The Netherlands
> tel: +31 (0)30 253 8464
> fax: +31 (0)30 253 8479
>
> --Boundary_(ID_erFAa+o6kWefQxXf6GD2RA)
> Content-type: text/x-diff; charset="us-ascii"; name="INSTALL.patch"
> Content-disposition: attachment; filename="INSTALL.patch"
> Content-transfer-encoding: 7bit
>
> *** INSTALL~	Wed Jun 22 11:09:59 2005
> --- INSTALL	Fri Dec  2 17:08:50 2005
> ***************
> *** 127,136 ****
>  get_packages () {
>    ## get the full path names to all packages contained in $1.
>    ## NOTE: modifies pkgs!
>    if grep "^Contains:" "${1}/DESCRIPTION" >/dev/null; then
>      bundlepkg=`get_dcf_field Contains "${1}/DESCRIPTION"`
>      for p in ${bundlepkg}; do
> !       pkgs="${pkgs} \"`cd "${1}/${p}" && ${GETWD}`\""
>        if test -f "${1}/${p}/DESCRIPTION.in"; then
>          ## Try being defensive about missing final newlines, or extra
>  	## empty lines.
> --- 127,138 ----
>  get_packages () {
>    ## get the full path names to all packages contained in $1.
>    ## NOTE: modifies pkgs!
> +   PROMPT_COMMAND=
> +   BASH_COMMAND=
>    if grep "^Contains:" "${1}/DESCRIPTION" >/dev/null; then
>      bundlepkg=`get_dcf_field Contains "${1}/DESCRIPTION"`
>      for p in ${bundlepkg}; do
> !       pkgs="${pkgs} \"`cd "${1}/${p}>/dev/null 2>&1" && ${GETWD}`\""
>        if test -f "${1}/${p}/DESCRIPTION.in"; then
>          ## Try being defensive about missing final newlines, or extra
>  	## empty lines.
> ***************
> *** 139,145 ****
>        fi
>      done
>    else
> !     pkgs="${pkgs} \"`cd "${1}" && ${GETWD}`\""
>    fi
>  }
>
> --- 141,147 ----
>        fi
>      done
>    else
> !     pkgs="${pkgs} \"`cd "${1}" > /dev/null 2>&1 && ${GETWD}`\""
>    fi
>  }
>
>
> --Boundary_(ID_erFAa+o6kWefQxXf6GD2RA)--
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From atp at piskorski.com  Fri Dec  2 18:43:01 2005
From: atp at piskorski.com (Andrew Piskorski)
Date: Fri, 2 Dec 2005 12:43:01 -0500
Subject: [Rd] t() dropping NULL dimnames {was "all.equal() for
	mismatching names..."}
In-Reply-To: <17296.31935.139175.48521@stat.math.ethz.ch>
References: <17296.8817.937646.30624@bossiaea.maths.uwa.edu.au>
	<17296.20406.853935.686989@stat.math.ethz.ch>
	<17296.31935.139175.48521@stat.math.ethz.ch>
Message-ID: <20051202174301.GA35670@tehun.pair.com>

On Fri, Dec 02, 2005 at 05:56:31PM +0100, Martin Maechler wrote:

>     BeT> x <- c(a = 1, b = 2)
>     BeT> is.vector(x)
>     BeT> as.vector(x)
>     BeT> all.equal(x, as.vector(x)) ## FALSE

>     BeT> However, in all versions of R in which I executed this example, the
>     BeT> all.equal command returned TRUE which suggest that either the comment

My PR#8191 patch to all.equal() does fix that, e.g.:

  > x <- c(a = 1, b = 2) 
  > is.vector(x) 
  [1] TRUE 
  > all.equal(x, as.vector(x)) 
  [1] "names"                          "for Target but not for Current" 
  > x 
  a b  
  1 2  
  > as.vector(x) 
  [1] 1 2 

>     MM> We recently had the following posting on R-devel
>     MM> https://stat.ethz.ch/pipermail/r-devel/2005-October/034962.html
>     MM> (Subject: [Rd] all.equal() improvements (PR#8191))

> I'm testing the first part of Andy's proposition
> {the 2nd part was about making the result strings more informative for
>  the case where all.equal() does *not* return TRUE}.

Excellent, thank you for digging into this, Martin!

> t() drops dimnames when they are list(NULL,NULL) 
> and has been doing so at least since R version 1.0.0 :
> 
>  x <- cbind(1:2, 2:1); dimnames(x) <- list(NULL, NULL) 
>  identical(x, t(x))  ## -> FALSE !
>  str(t(x)) # "no dimnames" (i.e. dimnames(x) === NULL)
> 
> Now I'm looking into changing that one....

Interesting.  FYI, my PR#8192 "subscripting sometimes loses names"
hack does NOT fix or change that, I get the same result as you do
above - t(x) is losing dimnames in that case.

  http://bugs.r-project.org/cgi-bin/R/wishlist?id=8192

S-Plus 6.2.1 (or at least my somewhat patched version of it) does not
seem to have that bug:

  > x <- cbind(1:2, 2:1); dimnames(x) <- list(NULL, NULL)  
  > identical(x, t(x)) 
  [1] T 

  > dimnames(x) 
  [[1]]: 
  character(0) 
  [[2]]: 
  character(0) 

  > dimnames(t(x)) 
  [[1]]: 
  character(0) 
  [[2]]: 
  character(0) 

-- 
Andrew Piskorski <atp at piskorski.com>
http://www.piskorski.com/


From iwomm03ox at digdat.com  Sat Dec  3 17:04:10 2005
From: iwomm03ox at digdat.com (iwomm03ox@digdat.com)
Date: Sat,  3 Dec 2005 17:04:10 +0100 (CET)
Subject: [Rd] H0T DEMANDING MEDs AT 8O% OFF FOR 2 DAYS 0NLY letter (PR#8365)
Message-ID: <20051203160410.924FD28E9B@slim.kubism.ku.dk>

----00001041_58630838260340
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 8bit

seven awhile scene went sorry whom. tying taught truly allowed,
pretty welcome as age side. board sale awhile. sandwich comes kept fascinate effect,
corner better miserable force summary greater.
but side how blue knew worthy, side affect keeping situation disappoint,
friends i saying next necessary use, build burst saying,

----00001041_58630838260340
Content-Type: text/html; charset=us-ascii
Content-Transfer-Encoding: 8bit

<html>
<head>
<meta http-equiv="Content-Type" content="text; charset=iso-8859-1">
</head>
<body>
<font color=F5A7FE size=1>wish development sense, pride added as leader tears easy. fool pronunciation pie independent leader east.</font>
<center><table border=5 cellspacing=0 cellpadding=10 width=550 bordercolor=00CA00>
<tr><td bgcolor=ffffff align=center>
<font size=1 face=verdana color=000000>
<font size=4 color=FF8000><b>:) Meds At Low Price That U Can Smile About<br><font color=C4C400>No Questionaire Form To Fill, Just Pay & We Ship<br><font color=9F9F9F>WE SHIP ALL COUNTRIES!</font></b></font></font><br><font color=000000 size=2>Va1iu*, Xana*, Ambieen, U1tram, Viagr*, Cia111is, Levitr*. Xeniical, Slimming Patch For Men, Meriidia, Herbaal Phentermin*, Som*. Attract-Mate, Hair-Remova1, Carbo-B1ocker board circumstances</font><br><br>
<center>
<a href=http://uk.geocities.com/Sharyl24235Mellie25341/ target=_blank><font size=5 color=0000E8><b><u>C11ick Here To ()rder</font></u></b></a><br>The site might slow on loading, Please A11ow 10-15 sec for site fully loaded<br><br><a href=http://lazdud.bridgeground.comrm/ target=_blank>NoThaanks</a></center></td></tr></table><font color=F5A7FE size=1>quarter parents being. oh either advantage prettier day discuss.</font>
</body>
</html>

----00001041_58630838260340--


From phgrosjean at sciviews.org  Sun Dec  4 12:49:21 2005
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Sun, 04 Dec 2005 12:49:21 +0100
Subject: [Rd] download.file() online help
Message-ID: <4392D7C1.80302@sciviews.org>

Hello,

Online help of download.file() refers to CRAN.packages() (in R 2.2.0) 
which is deprecated in favor of available.packages(). May be should it 
be better updated?
Best,

Philippe Grosjean
-- 
..............................................<?}))><........
  ) ) ) ) )
( ( ( ( (    Prof. Philippe Grosjean
  ) ) ) ) )
( ( ( ( (    Numerical Ecology of Aquatic Systems
  ) ) ) ) )   Mons-Hainaut University, Pentagone (3D08)
( ( ( ( (    Academie Universitaire Wallonie-Bruxelles
  ) ) ) ) )   8, av du Champ de Mars, 7000 Mons, Belgium
( ( ( ( (
  ) ) ) ) )   phone: + 32.65.37.34.97, fax: + 32.65.37.30.54
( ( ( ( (    email: Philippe.Grosjean at umh.ac.be
  ) ) ) ) )
( ( ( ( (    web:   http://www.umh.ac.be/~econum
  ) ) ) ) )          http://www.sciviews.org
( ( ( ( (
..............................................................


From murdoch at stats.uwo.ca  Sun Dec  4 14:23:30 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 04 Dec 2005 08:23:30 -0500
Subject: [Rd] download.file() online help
In-Reply-To: <4392D7C1.80302@sciviews.org>
References: <4392D7C1.80302@sciviews.org>
Message-ID: <4392EDD2.4050703@stats.uwo.ca>

On 12/4/2005 6:49 AM, Philippe Grosjean wrote:
> Hello,
> 
> Online help of download.file() refers to CRAN.packages() (in R 2.2.0) 
> which is deprecated in favor of available.packages(). May be should it 
> be better updated?
> Best,
> 
> Philippe Grosjean

Yes, there and in ?package.dependencies.  I'll fix it.  Thanks!

Duncan Murdoch


From ivowel at gmail.com  Sun Dec  4 18:34:22 2005
From: ivowel at gmail.com (ivo welch)
Date: Sun, 4 Dec 2005 12:34:22 -0500
Subject: [Rd] font inclusions in pdf files
Message-ID: <50d1c22d0512040934r2f09e1aewbdeb23ca48da060d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20051204/a6d5678d/attachment.pl

From berwin at maths.uwa.edu.au  Mon Dec  5 05:05:19 2005
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Mon, 5 Dec 2005 12:05:19 +0800
Subject: [Rd] Enlightenment sought and a possible buglet in vector.Rd
In-Reply-To: <Pine.LNX.4.61.0512021039350.18448@gannet.stats>
References: <17296.8817.937646.30624@bossiaea.maths.uwa.edu.au>
	<Pine.LNX.4.61.0512021039350.18448@gannet.stats>
Message-ID: <17299.48255.524708.64340@bossiaea.maths.uwa.edu.au>

G'day Brian,

>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

    BDR> On Fri, 2 Dec 2005, Berwin A Turlach wrote: [...]

    >> The second behaviour that I cannot explain was produced by code
    >> written by somebody else, namely:
    [...]
    >> The documentation of function() says that if "the end of a
    >> function is reached without calling 'return', the value of the
    >> last evaluated expression is returned."  And this seems to
    >> happen in this case:

    BDR> Yes, but that value can be returned with R_Visible set to 0,
    BDR> by calling invisible() _or otherwise_.
Thanks for the clarification.  I had the sneaking suspicion that
something like this was happening, but couldn't find anything in the
documentation.

I vaguely remember that S has a mechanism to switch auto-printing
on/off via a variable, whose name started with ".", but couldn't find
anything in the blue book (by now I found .Auto.print in Suesselbeck
and VR "S programming).  Since we don't have a license for S-plus
anymore, I couldn't check S-Plus and I didn't find anything similar in
R.  I take it that R handles all this via R_Visible at the C level?

    BDR> R does not print the value of a while() loop.  [...]  (Look
    BDR> up the code of do_while for why.)
I can see that in the code of do_while the variable R_Visible is set
to zero, but there is no explanation for why this is done.  But I
guess it is for compatibility reasons with S, since by now I found in
various books on the S language that the  while() loop returns its
value invisible.

Thanks for adding the value section to the help page to clarify this
issue in the R documentation.

Cheers,

        Berwin


From berwin at maths.uwa.edu.au  Mon Dec  5 05:23:47 2005
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Mon, 5 Dec 2005 12:23:47 +0800
Subject: [Rd] Enlightenment sought and a possible buglet in vector.Rd
In-Reply-To: <Pine.LNX.4.61.0512021120450.25330@gannet.stats>
References: <17296.8817.937646.30624@bossiaea.maths.uwa.edu.au>
	<Pine.LNX.4.61.0512021120450.25330@gannet.stats>
Message-ID: <17299.49363.577811.326018@bossiaea.maths.uwa.edu.au>

G'day Brian,

>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

    >> I found in the R language definition manual the passage that
    >> discourages users of assigning objects within function calls
    >> since it is not guaranteed that the assignment is ever made
    >> because of R's lazy evaluation model.  But this does not seem
    >> to explain the above behaviour since the argument to print is
    >> evaluated.  If I replace sys.on.exit() with, say, ls() in both
    >> functions, then they produce the same output (and the output
    >> that I expect).  Why does f2() not work with sys.on.exit()?

    BDR> It does work, but you seems to have misunderstood what it
    BDR> does.  See e.g.  the `bug' report discussed at
    BDR> http://tolstoy.newcastle.edu.au/~rking/R/devel/05/02/2112.html
Mmh, mea culpa, I am a bit red-faced here, in my quest to find out
what was going on, I checked about everything (including a private
e-mail to an R-core member) but the bug repository and the help page
of sys.on.exit().  I guess that if I have read the latter, I would
have figured out what was going on.  Instead I was satisfied with what
the on.exit() help page stated in its "see also" section:

     \seealso{
         \code{\link{sys.on.exit}} to see the current expression.
     }

May I request that this help page is changed according to the patch
attached below to clarify on the on.exit() help page what it is that
sys.on.exit() is returning?

    BDR> You might find

    BDR> g <- function(test) {}
    BDR> f2 <- function(){
    BDR> par.def <- par(no.readonly=TRUE)
    BDR> on.exit(par(par.def))
    BDR> g(tt <- sys.on.exit())
    BDR> str(tt)
    BDR> invisible()
    BDR> }
    BDR> f2()

    BDR> illuminating.
Mmh, in this code the function g is not evaluating its argument.  So I
would expect an error message in f2() that tt is not defined no matter
which function (sys.on.exit, ls, ...) I am using in the call to g()
within f().  Exactly the situation about which the R language
definition is warning, so this seems to be a different trap than the
one I stepped into....

Cheers,

        Berwin

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: R-patch
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20051205/78465d21/R-patch.ksh

From p.lijnzaad at med.uu.nl  Mon Dec  5 13:28:52 2005
From: p.lijnzaad at med.uu.nl (p.lijnzaad@med.uu.nl)
Date: Mon,  5 Dec 2005 13:28:52 +0100 (CET)
Subject: [Rd] ???UNSURE??? Re: (PR#8363) R CMD INSTALL fails if cd prints
Message-ID: <20051205122852.C76F41CA0A@slim.kubism.ku.dk>

On Friday 02 December 2005 18:20, Prof Brian Ripley wrote:

> What shells are these?  

Bash, mostly, but also ksh and zsh; sorry for not mentioning this. I now see 
that the root account usually does not change the behaviour of cd, so we may 
as well forget about the matter. My thought was: if a small change helps 
avoid this problem (which I think can occur easily enough), it could be 
helpful. Incidentally, IMHO the way it is coded in INSTALL.in (I didn't know 
about INSTALL.in, sorry) is a bit unusual; cd does not seem to be required by 
the POSIX standard to have non-zero exit status when it fails (and in fact, 
on older SunOSes, 'cd non/existant/directory' returns 0). But that is 
probably more a matter of style, more than anything else. Regards,

                                                                       Philip

-- 
Philip Lijnzaad
Genomics Laboratory
Dept. of Biomedical Genetics
University Medical Center (UMC), Utrecht
Stratenum room 2.201 (on Mondays and Thursdays not in after 14.45)
MSN chat (*NOT* email): philip_lijnzaad at hotmail.com
P.O. Box 85060, 3508 AB Utrecht
(Universiteitsweg 100, 3584 CG Utrecht)
The Netherlands
tel: +31 (0)30 253 8464
fax: +31 (0)30 253 8479


From ripley at stats.ox.ac.uk  Mon Dec  5 14:28:28 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Mon,  5 Dec 2005 14:28:28 +0100 (CET)
Subject: [Rd] ???UNSURE??? Re: (PR#8363) R CMD INSTALL fails if cd prints
Message-ID: <20051205132828.2DCA128EBD@slim.kubism.ku.dk>

On Mon, 5 Dec 2005, Philip Lijnzaad wrote:

> On Friday 02 December 2005 18:20, Prof Brian Ripley wrote:
>
>> What shells are these?
>
> Bash, mostly, but also ksh and zsh; sorry for not mentioning this.

I still don't know what you did to be able to reproduce this (and I did 
ask).  And as it is a shell script running under /bin/sh, it must be 
whatever is masquerading as Bourne shell on your system(s) that is 
affected.

> I now see that the root account usually does not change the behaviour of 
> cd, so we may as well forget about the matter. My thought was: if a 
> small change helps avoid this problem (which I think can occur easily 
> enough), it could be helpful. Incidentally, IMHO the way it is coded in 
> INSTALL.in (I didn't know about INSTALL.in, sorry) is a bit unusual; cd 
> does not seem to be required by the POSIX standard to have non-zero exit 
> status when it fails (and in fact, on older SunOSes, 'cd 
> non/existant/directory' returns 0). But that is

But it _is_ so required:

http://www.opengroup.org/onlinepubs/009695399/utilities/cd.html

How old are `older SunOSes'?  Solaris 8 (which is 4 years old) is 
POSIX-compilant here, and I would be surprised if any from the last decade 
was not (at least with suitable paths set).

> probably more a matter of style, more than anything else.

Our philosphy is to assume that the users tools are standard (e.g. POSIX) 
unless there is widespread evidence to the contrary.  First off, we need 
to know what was done and to be able to reproduce it.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ivowel at gmail.com  Mon Dec  5 14:30:45 2005
From: ivowel at gmail.com (ivo welch)
Date: Mon, 5 Dec 2005 08:30:45 -0500
Subject: [Rd] R-devel Digest, Vol 34, Issue 5
In-Reply-To: <mailman.7.1133780401.27269.r-devel@r-project.org>
References: <mailman.7.1133780401.27269.r-devel@r-project.org>
Message-ID: <50d1c22d0512050530l159d0a07g5ec3276838dd8278@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20051205/9871047e/attachment.pl

From reinhard.sy at berlin.de  Mon Dec  5 16:23:12 2005
From: reinhard.sy at berlin.de (Reinhard Sy)
Date: Mon, 05 Dec 2005 16:23:12 +0100
Subject: [Rd] Compiling R under AIX 4.3
Message-ID: <1133796193.3159.7.camel@localhost.localdomain>

Hi,

I have some Problems compiling/linking R under AIX 4.3

Here what kind of compilers I use:

$ /usr/local/bin/gcc -v
Reading specs from /usr/local/lib/gcc/powerpc-ibm-aix4.3.2.0/3.4.3/specs
Configured with: ../gcc-3.4.3/configure --disable-nls --disable-aix64
Thread model: aix
gcc version 3.4.3
$ /usr/local/bin/ld -v
GNU ld version 2.16

and then the IBM Fortran Compiler 'xlf95'

I run configure. then start make (gnu-make)

Had problem in pcre but fixed this if I use:

/usr/local/bin/make MAIN_LD="/usr/local/bin/gcc" 


then I run into the following problem with dynamic linking:

make[4]: Entering directory `/home/mau/sy/R-2.2.0/src/modules/X11'
/usr/local/bin/gcc -Wl,-bM:SRE -Wl,-H512 -Wl,-T512 -Wl,-bnoentry
-Wl,-bexpall -Wl,-bI:../../../etc/R.exp -L/usr/local/lib -o R_X11.so
dataentry.lo devX11.lo rotated.lo rbitmap.lo  -lSM -lICE -lX11  -ljpeg
-lpng -lz 
/usr/local/lib/gcc/powerpc-ibm-aix4.3.2.0/3.4.3/../../../../powerpc-ibm-aix4.3.2.0/bin/ld: -static and -shared may not be used together
collect2: ld returned 1 exit status
make[4]: *** [R_X11.so] Error 1

If I add -Wl,-G the same error!

If I unset SHLIB_LDFLAGS

% $MAKE SHLIB_LDFLAGS=" "
make[4]: Entering directory `/home/mau/sy/R-2.2.0/src/modules/X11'
/usr/local/bin/gcc  -L/usr/local/lib -o R_X11.so  dataentry.lo devX11.lo
rotated.lo rbitmap.lo  -lSM -lICE -lX11  -ljpeg -lpng -lz 
/lib/crt0.o: :(.pr+0x88): undefined reference to `.main'
collect2: ld returned 1 exit status

SHLIB_LDFLAGS="-Wl,-Bdynamic"

Entering directory `/home/mau/sy/R-2.2.0/src/modules/X11'
/usr/local/bin/gcc -Wl,-Bdynamic -L/usr/local/lib -o R_X11.so
dataentry.lo devX11.lo rotated.lo rbitmap.lo  -lSM -lICE -lX11  -ljpeg
-lpng -lz 
/lib/crt0.o: :(.pr+0x88): undefined reference to `.main'
collect2: ld returned 1 exit status
make[4]: *** [R_X11.so] Error 1
make[4]: Leaving directory `/home/mau/sy/R-2.2.0/src/modules/X11'


That it until now. Does anbody has compiled and linked R under AIX 4.3 ?
Should I try to get the IBM C Compiler will this work better ?

Thanks for an information 

Reinhard


From maechler at stat.math.ethz.ch  Mon Dec  5 19:10:08 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 5 Dec 2005 19:10:08 +0100
Subject: [Rd] [R] computing the variance
In-Reply-To: <4394071F.5080509@statistik.uni-dortmund.de>
References: <4393FFEC.3040008@bii-sg.org>
	<4394071F.5080509@statistik.uni-dortmund.de>
Message-ID: <17300.33408.391936.240032@stat.math.ethz.ch>

{from R-help, diverted to R-devel}:

    UweL> Wang Tian Hua wrote:

    UweL> hi, when i was computing the variance of a simple
    UweL> vector, i found unexpect result. not sure whether it
    UweL> is a bug.

    UweL> Not a bug! ?var:

    UweL> "The denominator n - 1 is used which gives an unbiased
    UweL>  estimator of the (co)variance for
    UweL>  i.i.d. observations."


    UweL> > var(c(1,2,3))
    UweL> [1] 1  #which should be 2/3.
    UweL> > var(c(1,2,3,4,5))
    UweL> [1] 2.5 #which should be 10/5=2
    UweL> 
    UweL> it seems to me that the program uses (sample size -1) instead of sample 
    UweL> size at the denominator. how can i rectify this?

    UweL> Simply change it by:

    UweL> x <- c(1,2,3,4,5)
    UweL> n <- length(x)
    UweL> var(x)*(n-1)/n

    UweL> if you really want it.

It seems Insightful at some point in time have given in to
this user request, and S-plus nowadays has
an argument  "unbiased = TRUE"
where the user can choose {to shoot (him/her)self in the leg and}
require 'unbiased = FALSE'.
{and there's also 'SumSquraes = FALSE' which allows to not
 require any division (by N or N-1)}

Since in some ``schools of statistics'' people are really still
taught to use a 1/N variance, we could envisage to provide such an
argument to var() {and cov()} as well.  Otherwise, people define
their own variance function such as  
      VAR <- function(x,....) .. N/(N-1)*var(x,...)
Should we?

BTW: S+ even has the 'unbiased' argument for cor() where of course it
really doesn't make any difference (!), and actually I think is
rather misleading, since the sample correlation is not unbiased
in almost all cases AFAICS.

Martin


From Ted.Harding at nessie.mcc.ac.uk  Mon Dec  5 20:25:42 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Mon, 05 Dec 2005 19:25:42 -0000 (GMT)
Subject: [Rd] [R] computing the variance
In-Reply-To: <17300.33408.391936.240032@stat.math.ethz.ch>
Message-ID: <XFMail.051205192542.Ted.Harding@nessie.mcc.ac.uk>

On 05-Dec-05 Martin Maechler wrote:
>     UweL> x <- c(1,2,3,4,5)
>     UweL> n <- length(x)
>     UweL> var(x)*(n-1)/n
> 
>     UweL> if you really want it.
> 
> It seems Insightful at some point in time have given in to
> this user request, and S-plus nowadays has
> an argument  "unbiased = TRUE"
> where the user can choose {to shoot (him/her)self in the leg and}
> require 'unbiased = FALSE'.
> {and there's also 'SumSquraes = FALSE' which allows to not
> require any division (by N or N-1)}
> 
> Since in some ``schools of statistics'' people are really still
> taught to use a 1/N variance, we could envisage to provide such an
> argument to var() {and cov()} as well.  Otherwise, people define
> their own variance function such as  
>       VAR <- function(x,....) .. N/(N-1)*var(x,...)
> Should we?

If people need to do this, such an option would be a convenience,
but I don't see that it has much further merit than that.

My view of how to calculate a "variance" is based, not directly
on the the "unbiased" issue, but on the following.

Suppose you define a RV X as a single value sampled from a finite
population of values X1,...,XN.

The variance of X is (or damn well should be) defined as

  Var(X) = E(X^2) - (E(X))^2

and this comes to (Sum(X^2) - (Sum(X)/N)^2))/(N-1).

So this is the variance of the set of values {X1,...,XN} from
that point of view. Similarly I like to preserve the analogy
by calling the "variance" of a set of sampled values {x1,...,xn}
the quantity caluclated by dividing by (n-1).

This of course links with "unbiased" in that when you use the
"1/(n-1)" definition you do have an unbiased estimator of Var(X).

And it ties in nicely with what I call "The Fundamental Formula
of the Analysis of Variance" (coincidentally mentioned recently
on R-help):

  Var[X](X) = E[J](Var[X|J](X|J)) + Var[J](E[X|J](X|J))

for two random variables Y, J (where "E[Y](...)", "E[X|Y](...)"
mean "Expectation using the distribution of Y or the conditional
distribution of X|Y respectively").

Now, for instance, take a set of samples of sizes n1,...,nk
indexed by j=1,...,k and pick a value X at random from the
N = n1+...+nk sample values. This gives rise also to a random
value of J (sample index) with P(J=j) = nj/N. Now apply the
FFAOV and you get the usual breakdown of the sum of squares.
And so on.

All that sort of thing is too fundamental to be undermined by
making more than the minimum necessary concession (i.e. convenient
for those who must) to the "1/n" view of the matter.

I think the confusion (and it does exist) arises (a) from the
hisytorical notion that "variance" = the mean squared deviation from
the mean (which I prefer to name by its description); together
with (b) that the Mean, Variance and such occur very early on in
even the least mathematical of introductory statistics courses,
and participants in these are invariaboy puzzled by the somewhat
mysterious appearnce on stage of "1/(n-1)" -- it can be easier
to sweep this under the carpet by saying "it doesn't make any
difference in large samples" etc.

> BTW: S+ even has the 'unbiased' argument for cor() where of course
> it really doesn't make any difference (!), and actually I think is
> rather misleading, since the sample correlation is not unbiased
> in almost all cases AFAICS.

Agreed. I wasn't aware of this -- what is the S-plus default?
(not that it matters ... ). A simply silly distinction, and
possibly a carry-over from the "confusion" described above
(e.g. "Since sample correlation is calculated as
 Cov(X,Y)/sqrt(Var(X)*Var(Y)), should we use the unbiased
or the biased versions of the Cov and the Vars?").

Hmmm.
Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 05-Dec-05                                       Time: 19:19:20
------------------------------ XFMail ------------------------------


From p.dalgaard at biostat.ku.dk  Mon Dec  5 20:33:16 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 05 Dec 2005 20:33:16 +0100
Subject: [Rd] [R] computing the variance
In-Reply-To: <17300.33408.391936.240032@stat.math.ethz.ch>
References: <4393FFEC.3040008@bii-sg.org>
	<4394071F.5080509@statistik.uni-dortmund.de>
	<17300.33408.391936.240032@stat.math.ethz.ch>
Message-ID: <x2fyp7mj9f.fsf@turmalin.kubism.ku.dk>

Martin Maechler <maechler at stat.math.ethz.ch> writes:

> It seems Insightful at some point in time have given in to
> this user request, and S-plus nowadays has
> an argument  "unbiased = TRUE"
> where the user can choose {to shoot (him/her)self in the leg and}
> require 'unbiased = FALSE'.
> {and there's also 'SumSquraes = FALSE' which allows to not
>  require any division (by N or N-1)}
> 
> Since in some ``schools of statistics'' people are really still
> taught to use a 1/N variance, we could envisage to provide such an
> argument to var() {and cov()} as well.  Otherwise, people define
> their own variance function such as  
>       VAR <- function(x,....) .. N/(N-1)*var(x,...)
> Should we?

Using the biased variance just because it is the MLE (if that is the
argument) seems confused to me. However, there's another point:

> var(sample(1:3, 100000, replace=TRUE))
[1] 0.6680556

i.e. if we are considering x as the entire population, then the
variance when sampling from it is indeed 1/N*E(X-EX)^2, which is why
some presentations distinguish between the "population" and "sample"
variances. We might want to support this distinction somehow.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From murdoch at stats.uwo.ca  Mon Dec  5 20:37:50 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 05 Dec 2005 14:37:50 -0500
Subject: [Rd] [R] computing the variance
In-Reply-To: <XFMail.051205192542.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.051205192542.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <4394970E.6090708@stats.uwo.ca>

On 12/5/2005 2:25 PM, (Ted Harding) wrote:
> On 05-Dec-05 Martin Maechler wrote:
>>     UweL> x <- c(1,2,3,4,5)
>>     UweL> n <- length(x)
>>     UweL> var(x)*(n-1)/n
>> 
>>     UweL> if you really want it.
>> 
>> It seems Insightful at some point in time have given in to
>> this user request, and S-plus nowadays has
>> an argument  "unbiased = TRUE"
>> where the user can choose {to shoot (him/her)self in the leg and}
>> require 'unbiased = FALSE'.
>> {and there's also 'SumSquraes = FALSE' which allows to not
>> require any division (by N or N-1)}
>> 
>> Since in some ``schools of statistics'' people are really still
>> taught to use a 1/N variance, we could envisage to provide such an
>> argument to var() {and cov()} as well.  Otherwise, people define
>> their own variance function such as  
>>       VAR <- function(x,....) .. N/(N-1)*var(x,...)
>> Should we?
> 
> If people need to do this, such an option would be a convenience,
> but I don't see that it has much further merit than that.
> 
> My view of how to calculate a "variance" is based, not directly
> on the the "unbiased" issue, but on the following.
> 
> Suppose you define a RV X as a single value sampled from a finite
> population of values X1,...,XN.
> 
> The variance of X is (or damn well should be) defined as
> 
>   Var(X) = E(X^2) - (E(X))^2
> 
> and this comes to (Sum(X^2) - (Sum(X)/N)^2))/(N-1).

I don't follow this.  I agree with the first line (though I prefer to 
write it differently), but I don't see how it leads to the second.  For 
example, consider a distribution which is equally likely to be +/- 1, 
and a sample from it consisting of a single 1 and a single -1.  The 
first formula gives 1 (which is the variance), the second gives 2.

The second formula is unbiased because in a random sample I am just as 
likely to get a 0 from the second formula, but I'm curious about what 
you mean by "this comes to".

Duncan


From Ted.Harding at nessie.mcc.ac.uk  Mon Dec  5 21:08:41 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Mon, 05 Dec 2005 20:08:41 -0000 (GMT)
Subject: [Rd] [R] computing the variance
In-Reply-To: <4394970E.6090708@stats.uwo.ca>
Message-ID: <XFMail.051205200841.Ted.Harding@nessie.mcc.ac.uk>

On 05-Dec-05 Duncan Murdoch wrote:
>> The variance of X is (or damn well should be) defined as
>> 
>>   Var(X) = E(X^2) - (E(X))^2
>> 
>> and this comes to (Sum(X^2) - (Sum(X)/N)^2))/(N-1).
> 
> I don't follow this.  I agree with the first line (though I prefer to 
> write it differently), but I don't see how it leads to the second.  For
> example, consider a distribution which is equally likely to be +/- 1, 
> and a sample from it consisting of a single 1 and a single -1.  The 
> first formula gives 1 (which is the variance), the second gives 2.
> 
> The second formula is unbiased because in a random sample I am just as 
> likely to get a 0 from the second formula, but I'm curious about what 
> you mean by "this comes to".
> 
> Duncan

Sorry, you're of course right -- I was being a bit hasty and
maganed to tangle this with a standard definition of the
"variance" of a finite population which uses the 1/(N-1)
divisor!



--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 05-Dec-05                                       Time: 20:08:38
------------------------------ XFMail ------------------------------


From p.murrell at auckland.ac.nz  Mon Dec  5 21:12:14 2005
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Tue, 06 Dec 2005 09:12:14 +1300
Subject: [Rd] font inclusions in pdf files
In-Reply-To: <50d1c22d0512040934r2f09e1aewbdeb23ca48da060d@mail.gmail.com>
References: <50d1c22d0512040934r2f09e1aewbdeb23ca48da060d@mail.gmail.com>
Message-ID: <43949F1E.1070608@stat.auckland.ac.nz>

Hi


ivo welch wrote:
> I am stumbling into external font issues here and there.  I presume using
> external lucida fonts is fairly rare, so I am more likely to stumble onto
> issues here.  (of course, I often think I have stumbled onto bugs/features
> that are not.)  So, I hope I am not imposing by reporting the following.
> 
> [1] can R please not include fonts that it is not using?
> 
> luafmfiles <- c("/usr/share/texmf/fonts/afm/yandy/lubright/lbr.afm",
>                 "/usr/share/texmf/fonts/afm/yandy/lubright/lbd.afm",
>                 "/usr/share/texmf/fonts/afm/yandy/lubright/lbi.afm",
>                 "/usr/share/texmf/fonts/afm/yandy/lucida/lbc.afm",
>                                 #
> "/usr/share/texmf/fonts/afm/yandy/lumath/lbms.afm",
>                 "/usr/share/texmf/fonts/afm/yandy/lubright/lbr.afm")
> grDevices::postscriptFonts(lucida=grDevices::postscriptFont("Lucida",
> metrics=luafmfiles));
> pdf(file="testincfonts.pdf");
> par(family="lucida");
> plot( c(0,0), c(1,1) );
> dev.off();
> 
> # pdffonts testincfonts.pdf
> name                                 type         emb sub uni object ID
> ------------------------------------ ------------ --- --- --- ---------
> ZapfDingbats                         Type 1       no  no  no       5  0
> Helvetica                            Type 1       no  no  no      10  0
> Helvetica-Bold                       Type 1       no  no  no      11  0
> Helvetica-Oblique                    Type 1       no  no  no      12  0
> Helvetica-BoldOblique                Type 1       no  no  no      13  0
> Symbol                               Type 1       no  no  no      14  0
> LucidaBright                         Type 1       no  no  no      15  0
> LucidaBright-Demi                    Type 1       no  no  no      16  0
> LucidaBright-Italic                  Type 1       no  no  no      17  0
> LucidaCalligraphy-Italic             Type 1       no  no  no      18  0
> LucidaBright                         Type 1       no  no  no      19  0
> 
>     distill from testincfonts.pdf into testincfonts.pdf.pdf to see what is
> really used:
> 
> # pdffonts testincfonts.pdf.pdf
> name                                 type         emb sub uni object ID
> ------------------------------------ ------------ --- --- --- ---------
> KWYJNC+LucidaBright                  Type 1C      yes yes no       9  0
> 
> (Including unused fonts can trip up programs that check whether pdf
> documents have embedded all fonts, and which are not smart enough to typeset
> [incl. all recursively embedded pdf files] to realize when a font is never
> used.)


Helvetica is being included because it is the default font for the 
device.  Changes for R 2.3.0 will mean that it is possible to specify 
something non-standard like Lucida as the default font for the device. 
However, it's going to require more work to get rid of Zapf Dingbats 
because R always includes it for drawing small circles.

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From tlumley at u.washington.edu  Mon Dec  5 22:18:06 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 5 Dec 2005 13:18:06 -0800 (PST)
Subject: [Rd] [R] computing the variance
In-Reply-To: <x2fyp7mj9f.fsf@turmalin.kubism.ku.dk>
References: <4393FFEC.3040008@bii-sg.org>
	<4394071F.5080509@statistik.uni-dortmund.de>
	<17300.33408.391936.240032@stat.math.ethz.ch>
	<x2fyp7mj9f.fsf@turmalin.kubism.ku.dk>
Message-ID: <Pine.LNX.4.64.0512051316470.14262@homer24.u.washington.edu>

>
> Using the biased variance just because it is the MLE (if that is the
> argument) seems confused to me. However, there's another point:
>
>> var(sample(1:3, 100000, replace=TRUE))
> [1] 0.6680556
>
> i.e. if we are considering x as the entire population, then the
> variance when sampling from it is indeed 1/N*E(X-EX)^2, which is why
> some presentations distinguish between the "population" and "sample"
> variances. We might want to support this distinction somehow.
>

We might also consider that the purpose of computing the variance is often 
to take the square root, and that using 1/(n-1) as the divisor does not 
give any particular optimality as an estimator of the standard deviation.

 	-thomas


From p.dalgaard at biostat.ku.dk  Mon Dec  5 23:51:47 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 05 Dec 2005 23:51:47 +0100
Subject: [Rd] R 2.2.1 scheduled for Dec 20.
Message-ID: <x27jajma2k.fsf@turmalin.kubism.ku.dk>


Dear testers,

We plan to release version 2.2.1 on December 20. Beta tarballs will
be available daily, starting tomorrow.

As usual, we strongly prefer to hear about bugs before release rather
than after.

        -pd
-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ripley at stats.ox.ac.uk  Tue Dec  6 12:22:27 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 6 Dec 2005 11:22:27 +0000 (GMT)
Subject: [Rd] Problem with fitdistr for gamma in R 2.2.0
In-Reply-To: <437CF2BE.7000602@math.ucalgary.ca>
References: <7FFEE688B57D7346BC6241C55900E730F31ABB@pollux.bfro.uni-lj.si>
	<437C95EA.9050502@math.ucalgary.ca> <x2br0jffpc.fsf@viggo.kubism.ku.dk>
	<437CF2BE.7000602@math.ucalgary.ca>
Message-ID: <Pine.LNX.4.61.0512061120050.23130@gannet.stats>

The problem lies in dgamma, the function which is stated to be implicated. 
See the following NEWS item:

     o	[dpqr]gamma now returns NaN for an invalid 'shape' parameter
 	(rather than throw an error), for consistency with other
 	distribution functions.

That setting lower/upper works is just intelligence in the function to 
choose an appropriate method.

On Thu, 17 Nov 2005, P Ehlers wrote:

> I think the problem may lie with fitdistr().
> Specifically, replacing the code in fitdistr.R (VR_7.2-20)
> (line 137 to end) with the code in VR_7.2-8 (line 92 to end)
> seems to handle
>
>   fitdistr(otm, "gamma")
>
> just fine. But I haven't done much testing.
>
> Peter Ehlers
>
> Peter Dalgaard wrote:
>> P Ehlers <ehlers at math.ucalgary.ca> writes:
>>
>>
>>> Gregor,
>>>
>>>  fitdistr(otm, "gamma", method="L-BFGS-B")
>>>
>>> works for me (on WinXP). Or you could specify "lower = 0".
>>
>>
>> The really odd thing is that it even works with
>>
>>
>>> fitdistr(otm, "gamma",lower=-Inf)
>>
>>      shape         rate
>>   1.03081094   0.18924370
>>  (0.09055117) (0.02117350)
>>
>> or even
>>
>>
>>> fitdistr(otm, "gamma",upper=Inf)
>>
>>      shape         rate
>>   1.03081094   0.18924370
>>  (0.09055117) (0.02117350)
>>
>>
>> Also
>>
>>
>>> fitdistr(otm, "gamma",control=list(parscale=c(.1,.1)))
>>
>>      shape         rate
>>   1.03079500   0.18923897
>>  (0.09055106) (0.02117363)
>>
>> and quite amusingly:
>>
>>
>>
>>> fitdistr(otm, "gamma",method="BFGS",lower=0)
>>
>>      shape         rate
>>   1.03081096   0.18924371
>>  (0.09055118) (0.02117350)
>> Warning message:
>> bounds can only be used with method L-BFGS-B in: optim(x = c(0.059610966029577, 0.0591496321922168, 0.14, 0.18,
>>
>>> fitdistr(otm, "gamma",method="CG",lower=0)
>>
>>      shape         rate
>>   1.03081096   0.18924371
>>  (0.09055118) (0.02117350)
>> Warning message:
>> bounds can only be used with method L-BFGS-B in: optim(x = c(0.059610966029577, 0.0591496321922168, 0.14, 0.18,
>>
>> whereas the same calls without the dysfunctional lower= gives the
>> warning about `shape` needing to be positive.
>>
>> This probably all indicates that something inside optim() is broken.
>>
>>
>>
>>
>>> I no longer have 2.1.0 running, so I don't know why this
>>> wasn't needed in 2.1.0.
>>>
>>> "R version 2.2.0, 2005-10-24"
>>> MASS version: 7.2-20
>>>
>>> -peter
>>>
>>> Gorjanc Gregor wrote:
>>>
>>>> Dear R developers,
>>>>
>>>> I have encountered strange behaviour of fitdistr for gamma in recent R
>>>> build i.e. 2.2.0. I have attached the code for data at the end of this mail
>>>> so you can reproduce the problem. In short, I am able to run fitdistr under
>>>> 2.1.0 without problems, while I get the following error under 2.2.0
>>>> (Version 2.2.0 Patched (2005-11-15 r36348))
>>>>
>>>>
>>>>
>>>>> fitdistr(otm, "gamma")
>>>>
>>>> Error in densfun(x, parm[1], parm[2], ...) :
>>>>        'shape' must be strictly positive
>>>>
>>>> The results on 2.1.1 (Version 2.1.1 (2005-06-20)) are
>>>>
>>>>
>>>>
>>>>> fitdistr(otm, "gamma")
>>>>
>>>>    shape       rate
>>>>  1.030667   0.189177
>>>> (0.090537) (0.021166)
>>>>
>>>> Platform: Windows XP
>>>>
>>>> Thank you in advance for your effort on this remarkable tool!
>>>>
>>>> Here is the data for above problem/results:
>>>>
>>>> "otm" <-
>>>> c(0.059610966029577, 0.0591496321922168, 0.14, 0.18, 0.24, 0.25,
>>>> 0.270071982912719, 0.270758049933706, 0.269911804412492, 0.280138451903593,
>>>> 0.279787947586738, 0.279429937571753, 0.3, 0.320746235495899,
>>>> 0.319553311037365, 0.51, 0.54, 0.56, 0.6, 0.609812622915953,
>>>> 0.609198293855879, 0.64, 0.69, 0.74, 0.76, 0.770972826186568,
>>>> 0.769288654833566, 0.78, 0.789181584270671, 0.78991363293305,
>>>> 0.8, 0.89, 0.900691718998831, 0.8991656800583, 0.92, 0.93, 0.94,
>>>> 1.01, 1.02, 1.13, 1.18, 1.26, 1.29, 1.33, 1.42, 1.43, 1.47, 1.47940529614314,
>>>> 1.47920716832764, 1.6, 1.61, 1.63, 1.68938231960637, 1.6894849291523,
>>>> 1.82, 1.88088044053270, 1.8792804789003, 1.89, 1.92, 2, 2.04,
>>>> 2.07, 2.12, 2.17, 2.18, 2.22, 2.23, 2.27, 2.28, 2.3, 2.32092240267433,
>>>> 2.31912300181622, 2.38, 2.39, 2.43, 2.46, 2.51, 2.52, 2.55, 2.56,
>>>> 2.61, 2.66091404781397, 2.6595832825806, 2.67, 2.7, 2.77, 2.8,
>>>> 2.81, 2.86, 2.87, 2.93, 3.01, 3.05, 3.14, 3.15, 3.17, 3.18, 3.24,
>>>> 3.26, 3.33, 3.44, 3.45, 3.52, 3.55, 3.63, 3.73, 3.9, 4, 4.01,
>>>> 4.04, 4.13, 4.15934497380769, 4.16094719917513, 4.3, 4.33, 4.34,
>>>> 4.66, 4.76, 4.82, 4.83, 4.89, 4.92, 5.06, 5.14, 5.16, 5.26, 5.31,
>>>> 5.36, 5.48, 5.66, 5.79, 5.8, 5.85, 5.87, 5.92952534468565, 5.92962284128508,
>>>> 6.04, 6.11, 6.13, 6.16, 6.19, 6.42, 6.66, 6.69, 7.11, 7.16, 7.29,
>>>> 7.3, 7.31, 7.33, 7.72, 7.82, 7.87, 7.91, 8.01, 8.17, 8.45, 8.49,
>>>> 8.73, 8.86, 8.95, 9, 9.05, 9.13, 9.22, 9.52, 9.82, 9.88, 9.91,
>>>> 9.99, 10.03, 10.4, 10.59, 10.83, 11.06, 11.64, 11.85, 12.02,
>>>> 12.4, 12.64, 12.96, 13.44, 14.06, 14.07, 14.37, 15.4, 15.6, 15.92,
>>>> 16.23, 16.6, 16.97, 17.06, 17.8, 18.69, 18.73, 19.2, 19.51, 19.54,
>>>> 20.57, 21.05, 22.23, 27.02)
>>>>
>>>> Lep pozdrav / With regards,
>>>>    Gregor Gorjanc
>>>>
>>>> ----------------------------------------------------------------------
>>>> University of Ljubljana
>>>> Biotechnical Faculty        URI: http://www.bfro.uni-lj.si/MR/ggorjan
>>>> Zootechnical Department     mail: gregor.gorjanc <at> bfro.uni-lj.si
>>>> Groblje 3                   tel: +386 (0)1 72 17 861
>>>> SI-1230 Domzale             fax: +386 (0)1 72 17 888
>>>> Slovenia, Europe
>>>> ----------------------------------------------------------------------
>>>> "One must learn by doing the thing; for though you think you know it,
>>>> you have no certainty until you try." Sophocles ~ 450 B.C.
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>> Peter Ehlers
>>> University of Calgary
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>
>
> -- 
> Peter Ehlers
> Department of Mathematics and Statistics
> University of Calgary, 2500 University Dr. NW
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Matthias.Kohl at stamats.de  Tue Dec  6 13:36:29 2005
From: Matthias.Kohl at stamats.de (Matthias Kohl)
Date: Tue, 06 Dec 2005 13:36:29 +0100
Subject: [Rd] problems with initialize-method,
	difference between Win XP & Linux
Message-ID: <439585CD.1080800@stamats.de>

Dear R devels,

I have some questions concerning the use of "initialize".

Situation:
There are two packages "S4pkg1" and "S4pkg2" which include S4 classes 
and methods where the first one contains a new S4 class "S4pkg1Class".
Then, in "S4pkg2" there is a new S4 class "S4pkg2Class" which has a slot 
of class "S4pkg1Class". Both packages have a namespace where I use 
exportClasses("S4pkg1Class") in the namespace of "S4pkg1" and 
import("S4pkg1") in the namespace of "S4pkg2".

#############
1. Solution:
I provide a prototype argument in the definition of "S4pkg1Class" and 
use new("S4pkg1Class") in the prototype of "S4pkg2Class".
Then, everything works fine under Windows XP and (Suse 9.3) Linux using 
R 2.2.0 and R 2.3.0 devel; i.e., calling "new("S4pkg2Class")" returns an 
object of class "S4pkg2Class" and the slot of class "S4pkg1Class" is 
filled with the corresponding prototype.

#############
2. Solution:
I don't provide a prototype argument in the definition of "S4pkg1Class". 
Instead, I define an "initialize"-method for class "S4pkg1Class" with 
default arguments for the slots of "S4pkg1Class" and again I use 
"new("S4pkg1Class")" in the prototype of class "S4pkg2Class".
Moreover, I use exportMethods("initialize") in the namespace of package 
"S4pkg1".

Then, everything seems to work fine (at least on my PC) under Windows XP 
using R 2.2.0 and R 2.3.0 devel; i.e., calling "new("S4pkg2Class")" 
returns an object of class "S4pkg2Class" where the slot of class 
"S4pkg1Class" now is filled with the default object generated by the 
initialize-method of class "S4pkg1Class".
However, under (Suse 9.3) Linux using R 2.2.0 and R 2.3.0 devel 
"new("S4pkg2Class")" returns an object of class "S4pkg2Class" where the 
slot of class "S4pkg1Class" is not filled with the default object 
generated by the initialize-method of class "S4pkg1Class" but with a 
"default-protoype" (slots are filled with "numeric(0)", "character(0)", 
...).

Can someone confirm this behavior?

The sources of two sample packages can be found under:
http://www.stamats.de/S4pkg1_0.1-1.tar.gz
and
http://www.stamats.de/S4pkg2_0.1-1.tar.gz

After installation please try:
require(S4pkg1)
new("S4pkg1Class") # o.k., default values of initialize are used

require(S4pkg2)
new("S4pkg2Class") # is slot "pkg1" filled with the output of 
new("S4pkg1Class") given above???

Why does this work under Windows XP but not under (Suse 9.3) Linux?
Am I doing something wrong - or is this a bug?

Many thanks for any help!
Matthias

-- 
StaMatS - Statistik + Mathematik Service
Dipl.Math.(Univ.) Matthias Kohl
www.stamats.de


From Heather.Turner at warwick.ac.uk  Tue Dec  6 15:52:30 2005
From: Heather.Turner at warwick.ac.uk (Heather.Turner@warwick.ac.uk)
Date: Tue,  6 Dec 2005 15:52:30 +0100 (CET)
Subject: [Rd] standardized residuals (rstandard & plot.lm) (PR#8367)
Message-ID: <20051206145230.0AE6C15AD7@slim.kubism.ku.dk>

Full_Name: Heather Turner
Version: 2.2.0
OS: Windows XP
Submission from: (NULL) (137.205.240.44)


Standardized residuals as calculated by rstandard.lm, rstandard.glm and plot.lm
are Inf/NaN rather than zero when the un-standardized residuals are zero. This
causes plot.lm to break when calculating 'ylim' for any of the plots of
standardized residuals. Example:

"occupationalStatus" <-
    structure(as.integer(c(50, 16, 12, 11, 2, 12, 0, 0, 19, 40, 35, 
                           20, 8, 28, 6, 3, 26, 34, 65, 58, 12, 102, 19, 14, 8,
                           18, 66, 110, 23, 162, 40, 32, 7, 11, 35, 40, 25, 90,
                           21, 15, 11, 20, 88, 183, 46, 554, 158, 126, 6, 8,
23,
                           64, 28, 230, 143, 91, 2, 3, 21, 32, 12, 177, 71,
106)
                         ), .Dim = as.integer(c(8, 8)), .Dimnames =
              structure(list(origin = c("1", "2", "3", "4", "5", "6", "7",
"8"),
                             destination = c("1", "2", "3", "4", "5", "6", "7",
                             "8")), .Names = c("origin", "destination")),
              class = "table")
Diag <- as.factor(diag(1:8))
Rscore <- scale(as.numeric(row(occupationalStatus)), scale = FALSE)
Cscore <- scale(as.numeric(col(occupationalStatus)), scale = FALSE)
Uniform <- glm(Freq ~ origin + destination + Diag + 
               Rscore:Cscore, family = poisson, data = occupationalStatus)
residuals(Uniform)[as.logical(diag(8))] #zero/near-zero
rstandard(Uniform)[as.logical(diag(8))] #mostly Inf/NaN
plot(Uniform) #breaks on qqnorm plot (or any 'which' > 1)

This could be fixed by replacing standardized residuals with zero where the hat
value is one, e.g.
rstandard.glm <- function (model,
                            infl = lm.influence(model, do.coef = FALSE),
                            ...) {
     res <- infl$wt.res
     hat <- infl$hat
     ifelse(hat == 1, 0, res/sqrt(summary(model)$dispersion * (1 - 
infl$hat)))
}
etc.


From ripley at stats.ox.ac.uk  Tue Dec  6 17:10:33 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue,  6 Dec 2005 17:10:33 +0100 (CET)
Subject: [Rd] standardized residuals (rstandard & plot.lm) (PR#8367)
Message-ID: <20051206161033.520AD2843F@slim.kubism.ku.dk>

Curiously, I was just looking at that, since I believe the answer should 
be NaN, and some optimizing compilers/fast BLASes are not giving that.
(There's an example in reg-test-3.R.)  So I think we need to return NaN 
when hat is within rounding error of 1.

My take is that plot.lm should handle this: you will see most but not all 
cases have na.rm=TRUE in calculating ylim, but as Inf is theoretically
impossible it has not been considered.

Note that plot.lm does not use rstandard and so needs a separate fix.

Thanks for the report

On Tue, 6 Dec 2005 Heather.Turner at warwick.ac.uk wrote:

> Full_Name: Heather Turner
> Version: 2.2.0
> OS: Windows XP
> Submission from: (NULL) (137.205.240.44)
>
>
> Standardized residuals as calculated by rstandard.lm, rstandard.glm and plot.lm
> are Inf/NaN rather than zero when the un-standardized residuals are zero. This
> causes plot.lm to break when calculating 'ylim' for any of the plots of
> standardized residuals. Example:
>
> "occupationalStatus" <-
>    structure(as.integer(c(50, 16, 12, 11, 2, 12, 0, 0, 19, 40, 35,
>                           20, 8, 28, 6, 3, 26, 34, 65, 58, 12, 102, 19, 14, 8,
>                           18, 66, 110, 23, 162, 40, 32, 7, 11, 35, 40, 25, 90,
>                           21, 15, 11, 20, 88, 183, 46, 554, 158, 126, 6, 8,
> 23,
>                           64, 28, 230, 143, 91, 2, 3, 21, 32, 12, 177, 71,
> 106)
>                         ), .Dim = as.integer(c(8, 8)), .Dimnames =
>              structure(list(origin = c("1", "2", "3", "4", "5", "6", "7",
> "8"),
>                             destination = c("1", "2", "3", "4", "5", "6", "7",
>                             "8")), .Names = c("origin", "destination")),
>              class = "table")
> Diag <- as.factor(diag(1:8))
> Rscore <- scale(as.numeric(row(occupationalStatus)), scale = FALSE)
> Cscore <- scale(as.numeric(col(occupationalStatus)), scale = FALSE)
> Uniform <- glm(Freq ~ origin + destination + Diag +
>               Rscore:Cscore, family = poisson, data = occupationalStatus)
> residuals(Uniform)[as.logical(diag(8))] #zero/near-zero
> rstandard(Uniform)[as.logical(diag(8))] #mostly Inf/NaN
> plot(Uniform) #breaks on qqnorm plot (or any 'which' > 1)
>
> This could be fixed by replacing standardized residuals with zero where the hat
> value is one, e.g.
> rstandard.glm <- function (model,
>                            infl = lm.influence(model, do.coef = FALSE),
>                            ...) {
>     res <- infl$wt.res
>     hat <- infl$hat
>     ifelse(hat == 1, 0, res/sqrt(summary(model)$dispersion * (1 -
> infl$hat)))
> }
> etc.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.lijnzaad at med.uu.nl  Wed Dec  7 13:34:55 2005
From: p.lijnzaad at med.uu.nl (p.lijnzaad@med.uu.nl)
Date: Wed,  7 Dec 2005 13:34:55 +0100 (CET)
Subject: [Rd] ???UNSURE??? Re: (PR#8363) R CMD INSTALL fails if cd prints
Message-ID: <20051207123455.188802941D@slim.kubism.ku.dk>

On Monday 05 December 2005 14:28, Prof Brian Ripley wrote:
> >> What shells are these?
> >
> > Bash, mostly, but also ksh and zsh; sorry for not mentioning this.
>
> I still don't know what you did to be able to reproduce this (and I did
> ask).  

It turns ou that I was not quite correct regarding the cause of cd printing 
the 'new' directory. It is due to having the CDPATH set. If it is,
the POSIX standard requires 'cd' to print to stdout the new directory.
So to reproduce, run a bash  or ksh shell,  and do 

  CDPATH='.:..'               # a commonly used value for $CDPATH
  R CMD INSTALL SomePackage

> And as it is a shell script running under /bin/sh, it must be 
> whatever is masquerading as Bourne shell on your system(s) that is
> affected.

yes; it is fairly common for Linux systems to have have /bin/sh be a symlink 
to /bin/bash (which I'm not sure is always a good idea). But the issue will 
affect any POSIX-compliant shell.

> But it _is_ so required:
>
> http://www.opengroup.org/onlinepubs/009695399/utilities/cd.html

Sorry, I missed that. And I agree that it's the most logical thing to do when 
cd fails. 

> How old are `older SunOSes'?  Solaris 8 (which is 4 years old) is
> POSIX-compilant here, and I would be surprised if any from the last decade
> was not (at least with suitable paths set).

SunOS 5.7 (which admittedly is ancient; I can't find the year, google.com is 
currently unreachable for me) doesn't do it.

> Our philosphy is to assume that the users tools are standard (e.g. POSIX)
> unless there is widespread evidence to the contrary.  

The  INSTALL.in script already contains various '> /dev/null'; my patch just 
adds another two, inside the get_packages function, just to avoid any output 
that the cd-command might happen to have. I would not have thought this to be 
so controversial. Regards,

                                                                       Philip

-- 
Philip Lijnzaad
Genomics Laboratory
Dept. of Biomedical Genetics
University Medical Center (UMC), Utrecht
Stratenum room 2.201 (on Mondays and Thursdays not in after 14.45)
MSN chat (*NOT* email): philip_lijnzaad at hotmail.com
P.O. Box 85060, 3508 AB Utrecht
(Universiteitsweg 100, 3584 CG Utrecht)
The Netherlands
tel: +31 (0)30 253 8464
fax: +31 (0)30 253 8479


From Torsten.Hothorn at rzmail.uni-erlangen.de  Wed Dec  7 18:54:38 2005
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Wed, 7 Dec 2005 18:54:38 +0100 (CET)
Subject: [Rd] typo in `eurodist'
Message-ID: <Pine.LNX.4.51.0512071853390.13205@artemis.imbe.med.uni-erlangen.de>


R> attributes(eurodist)$Labels[9]
[1] "Gibralta"

should be `Gibraltar'.

Best,

Torsten


From ripley at stats.ox.ac.uk  Wed Dec  7 19:21:50 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 7 Dec 2005 18:21:50 +0000 (GMT)
Subject: [Rd] typo in `eurodist'
In-Reply-To: <Pine.LNX.4.51.0512071853390.13205@artemis.imbe.med.uni-erlangen.de>
References: <Pine.LNX.4.51.0512071853390.13205@artemis.imbe.med.uni-erlangen.de>
Message-ID: <Pine.LNX.4.61.0512071818450.6977@gannet.stats>

I've often wondered about that.  I've presumed that the names were 
deliberate, so have you checked the stated source?  It's not readily 
available to me (as one would expect in Oxford)?

Does the original author know?

On Wed, 7 Dec 2005, Torsten Hothorn wrote:

> R> attributes(eurodist)$Labels[9]
> [1] "Gibralta"
>
> should be `Gibraltar'.

labels(eurodist) is clearer.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From torsten at hothorn.de  Thu Dec  8 08:51:57 2005
From: torsten at hothorn.de (torsten@hothorn.de)
Date: Thu, 8 Dec 2005 08:51:57 +0100 (CET)
Subject: [Rd] typo in `eurodist'
In-Reply-To: <Pine.LNX.4.61.0512071818450.6977@gannet.stats>
References: <Pine.LNX.4.51.0512071853390.13205@artemis.imbe.med.uni-erlangen.de>
	<Pine.LNX.4.61.0512071818450.6977@gannet.stats>
Message-ID: <Pine.LNX.4.51.0512080844510.23271@artemis.imbe.med.uni-erlangen.de>


On Wed, 7 Dec 2005, Prof Brian Ripley wrote:

> I've often wondered about that.

and the copy editor did too :-)

> I've presumed that the names were
> deliberate, so have you checked the stated source?  It's not readily
> available to me (as one would expect in Oxford)?

our library doesn't seems to have a copy of `The Cambridge
Encyclopaedia', so I can't check either. Google has 74.900 hits for
`Gibralta' (more than one would expect for a typo, I think)
and 57.700.000 for `Gibraltar'.

So maybe both spellings are in use.

Best,

Torsten

>
> Does the original author know?
>
> On Wed, 7 Dec 2005, Torsten Hothorn wrote:
>
> > R> attributes(eurodist)$Labels[9]
> > [1] "Gibralta"
> >
> > should be `Gibraltar'.
>
> labels(eurodist) is clearer.
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>


From maechler at stat.math.ethz.ch  Thu Dec  8 09:00:27 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 8 Dec 2005 09:00:27 +0100
Subject: [Rd] typo in `eurodist'
In-Reply-To: <Pine.LNX.4.51.0512080844510.23271@artemis.imbe.med.uni-erlangen.de>
References: <Pine.LNX.4.51.0512071853390.13205@artemis.imbe.med.uni-erlangen.de>
	<Pine.LNX.4.61.0512071818450.6977@gannet.stats>
	<Pine.LNX.4.51.0512080844510.23271@artemis.imbe.med.uni-erlangen.de>
Message-ID: <17303.59419.897644.817290@stat.math.ethz.ch>

>>>>> "Torsten" == Torsten Hothorn <torsten at hothorn.de>
>>>>>     on Thu, 8 Dec 2005 08:51:57 +0100 (CET) writes:

    Torsten> On Wed, 7 Dec 2005, Prof Brian Ripley wrote:

    >> I've often wondered about that.

    Torsten> and the copy editor did too :-)

    >> I've presumed that the names were
    >> deliberate, so have you checked the stated source?  It's not readily
    >> available to me (as one would expect in Oxford)?

    Torsten> our library doesn't seems to have a copy of `The Cambridge
    Torsten> Encyclopaedia', so I can't check either. Google has 74.900 hits for
    Torsten> `Gibralta' (more than one would expect for a typo, I think)
    Torsten> and 57.700.000 for `Gibraltar'.

    Torsten> So maybe both spellings are in use.

Well,  do you expect web authors to have a much lower rate of
typos than 1:770 ?
My limited experience on "google voting for spelling correction"
has rather lowered my expectation on webauthors' education in
orthography...

Martin


From rkoenker at uiuc.edu  Thu Dec  8 17:26:03 2005
From: rkoenker at uiuc.edu (roger koenker)
Date: Thu, 8 Dec 2005 10:26:03 -0600
Subject: [Rd] qt for df < 1
Message-ID: <FD963C8B-71E1-4322-AE17-98303ED6B0D8@uiuc.edu>

I was experimenting yesterday with a binomial make.link option
for estimating student t binary response models, tentatively
called gossit, and I noticed eventually that the R qt function doesn't
like df < 1.  Vaguely recalling that Splus didn't seem to mind such
weirdness,  I checked on our soon to be defunct Splus6.2 and
sure enough, it produced plausible answers instead of R's NA's.
Of course, I have no way of judging the quality of these answers,
but I'm curious about whether someone has already looked into
this can of worms.


url:    www.econ.uiuc.edu/~roger            Roger Koenker
email    rkoenker at uiuc.edu            Department of Economics
vox:     217-333-4558                University of Illinois
fax:       217-244-6678                Champaign, IL 61820


From spencer.graves at pdf.com  Thu Dec  8 18:28:59 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 08 Dec 2005 09:28:59 -0800
Subject: [Rd] typo in `eurodist'
In-Reply-To: <17303.59419.897644.817290@stat.math.ethz.ch>
References: <Pine.LNX.4.51.0512071853390.13205@artemis.imbe.med.uni-erlangen.de>	<Pine.LNX.4.61.0512071818450.6977@gannet.stats>	<Pine.LNX.4.51.0512080844510.23271@artemis.imbe.med.uni-erlangen.de>
	<17303.59419.897644.817290@stat.math.ethz.ch>
Message-ID: <43986D5B.8040604@pdf.com>

	  I'm with Martin:  When I get the same number of hits for two 
spellings, I believe that both are acceptable.  When I get substantially 
different numbers of hits, I generally go with the one with the most 
hits -- unless the different spellings carry different meanings, of 
course.
	
	  Example:  "gage" vs. "gauge" vs. "guage":  24e6 vs. 32e6 vs 3e6.  The 
last is a typo.  The first has a special meaning, though "gauge" is 
sometimes used in that context.  However, when discussing repeatability 
and reproducibility, I prefer "gage", because it's more restrictive and 
therefore seems clearer to me.

	  spencer graves

Martin Maechler wrote:

>>>>>>"Torsten" == Torsten Hothorn <torsten at hothorn.de>
>>>>>>    on Thu, 8 Dec 2005 08:51:57 +0100 (CET) writes:
> 
> 
>     Torsten> On Wed, 7 Dec 2005, Prof Brian Ripley wrote:
> 
>     >> I've often wondered about that.
> 
>     Torsten> and the copy editor did too :-)
> 
>     >> I've presumed that the names were
>     >> deliberate, so have you checked the stated source?  It's not readily
>     >> available to me (as one would expect in Oxford)?
> 
>     Torsten> our library doesn't seems to have a copy of `The Cambridge
>     Torsten> Encyclopaedia', so I can't check either. Google has 74.900 hits for
>     Torsten> `Gibralta' (more than one would expect for a typo, I think)
>     Torsten> and 57.700.000 for `Gibraltar'.
> 
>     Torsten> So maybe both spellings are in use.
> 
> Well,  do you expect web authors to have a much lower rate of
> typos than 1:770 ?
> My limited experience on "google voting for spelling correction"
> has rather lowered my expectation on webauthors' education in
> orthography...
> 
> Martin
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915


From p.dalgaard at biostat.ku.dk  Thu Dec  8 19:09:29 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 08 Dec 2005 19:09:29 +0100
Subject: [Rd] qt for df < 1
In-Reply-To: <FD963C8B-71E1-4322-AE17-98303ED6B0D8@uiuc.edu>
References: <FD963C8B-71E1-4322-AE17-98303ED6B0D8@uiuc.edu>
Message-ID: <x2k6efbgva.fsf@viggo.kubism.ku.dk>

roger koenker <rkoenker at uiuc.edu> writes:

> I was experimenting yesterday with a binomial make.link option
> for estimating student t binary response models, tentatively
> called gossit, and I noticed eventually that the R qt function doesn't
> like df < 1.  Vaguely recalling that Splus didn't seem to mind such
> weirdness,  I checked on our soon to be defunct Splus6.2 and
> sure enough, it produced plausible answers instead of R's NA's.
> Of course, I have no way of judging the quality of these answers,
> but I'm curious about whether someone has already looked into
> this can of worms.

Well the help page has:

For 'qt' only values of at least one are currently supported.

and someone must have written that...

R does have pt for df < 1, so a temporary fix using uniroot() seems
doable.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From ripley at stats.ox.ac.uk  Thu Dec  8 19:41:22 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 8 Dec 2005 18:41:22 +0000 (GMT)
Subject: [Rd] qt for df < 1
In-Reply-To: <FD963C8B-71E1-4322-AE17-98303ED6B0D8@uiuc.edu>
References: <FD963C8B-71E1-4322-AE17-98303ED6B0D8@uiuc.edu>
Message-ID: <Pine.LNX.4.61.0512081838060.24202@gannet.stats>

On Thu, 8 Dec 2005, roger koenker wrote:

> I was experimenting yesterday with a binomial make.link option
> for estimating student t binary response models, tentatively
> called gossit, and I noticed eventually that the R qt function doesn't
> like df < 1.  Vaguely recalling that Splus didn't seem to mind such
> weirdness,  I checked on our soon to be defunct Splus6.2 and
> sure enough, it produced plausible answers instead of R's NA's.
> Of course, I have no way of judging the quality of these answers,

Why not?: qt is the inverse of pt.

> but I'm curious about whether someone has already looked into
> this can of worms.

Note from the help page:

       df: degrees of freedom (> 0, maybe non-integer).  'df = Inf' is
           allowed.  For 'qt' only values of at least one are currently
           supported.

so, yes, it is known about.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Ted.Harding at nessie.mcc.ac.uk  Thu Dec  8 19:58:07 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Thu, 08 Dec 2005 18:58:07 -0000 (GMT)
Subject: [Rd] typo in `eurodist'
In-Reply-To: <17303.59419.897644.817290@stat.math.ethz.ch>
Message-ID: <XFMail.051208185807.Ted.Harding@nessie.mcc.ac.uk>

On 08-Dec-05 Martin Maechler wrote:
>>>>>> "Torsten" == Torsten Hothorn <torsten at hothorn.de>
>>>>>>     on Thu, 8 Dec 2005 08:51:57 +0100 (CET) writes:
> 
>     Torsten> On Wed, 7 Dec 2005, Prof Brian Ripley wrote:
>     >> I've often wondered about that.
>     Torsten> and the copy editor did too :-)
> 
>     >> I've presumed that the names were
>     >> deliberate, so have you checked the stated source?  It's not
>     >> readily available to me (as one would expect in Oxford)?
> 
>     Torsten> our library doesn't seems to have a copy of `The
>     Torsten> Cambridge Encyclopaedia', so I can't check
>     Torsten> either. Google has 74.900 hits for `Gibralta'
>     Torsten> (more than one would expect for a typo, I think)
>     Torsten> and 57.700.000 for `Gibraltar'.
> 
>     Torsten> So maybe both spellings are in use.
> 
> Well,  do you expect web authors to have a much lower rate of
> typos than 1:770 ?
> My limited experience on "google voting for spelling correction"
> has rather lowered my expectation on webauthors' education in
> orthography...
> 
> Martin

Hmmm ... Using my Google's "Results ... of about xxx":


  Gibraltar 50,700,000 
  Gibralta      75,200
  Gibraltr         573
  Gibralar         836
  Gibratar       1,020
  Gibrltar         349
  Gibaltar       1,850
  Giraltar         530
  Gbraltar         352
  ibralter         576

I'm not proposing to get exhaustive about this, but a few further
experiments suggest that other specific typos are typically O(500)
in frequency:

  Gibralatar   589
  Gibrlatar    618
  Gibrltar     349
  Gobraltar    652


So -- if anyone can find a typo of "Gibraltar" which googles to
more than 5000 hits (excepting "Gibralta")?

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 08-Dec-05                                       Time: 18:58:04
------------------------------ XFMail ------------------------------


From f.hahne at dkfz.de  Thu Dec  8 20:22:11 2005
From: f.hahne at dkfz.de (Florian Hahne)
Date: Thu, 08 Dec 2005 19:22:11 +0000
Subject: [Rd] grid graphics gpar(fill) argument and jpeg device
Message-ID: <439887E3.7050309@dkfz.de>

Hi everybody,
I just notice a strange behaviour of gpar's fill argument when using 
non-postscript devices:
The default of the argument is transparent (according to get.gpar("fill")).
So as expected, the following code draws a nice red rectangle in the 
middle of my X11 or postscript device.

pushViewport(viewport(width=0.5, height=0.5))
grid.rect(gp=gpar(fill="red"))
grid.rect()

However, when plotting on  a jpeg device (or any other pixel device), 
the output of the above code is an empty (=white) rectangle. Obviously 
the second grid.rect() which should produce a transparent rectangle 
turns out to be filled white on the jpeg device. When I set the fill 
argument to NA, the second rectangle is transparent as it is supposed to be.

grid.rect(gp=gpar(fill="red"))
grid.rect(gp=gpar(fill=NA))

Is this a bug or a feature???
I'm using R version 2.2.0 on a SUSE 10.0 linux machine.

Cheers,
Florian


From ggrothendieck at gmail.com  Thu Dec  8 20:41:01 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 8 Dec 2005 14:41:01 -0500
Subject: [Rd] typo in `eurodist'
In-Reply-To: <XFMail.051208185807.Ted.Harding@nessie.mcc.ac.uk>
References: <17303.59419.897644.817290@stat.math.ethz.ch>
	<XFMail.051208185807.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <971536df0512081141i121230b7t652b137e9ec660f5@mail.gmail.com>

This makes it pretty clear which are the meaningful ones:

g <- structure(c(50700000, 75200, 573, 836, 1020, 349, 1850, 530,
352, 576, 589, 618, 349, 652), .Names = c("Gibraltar", "Gibralta",
"Gibraltr", "Gibralar", "Gibratar", "Gibrltar", "Gibaltar", "Giraltar",
"Gbraltar", "ibralter", "Gibralatar", "Gibrlatar", "Gibrltar",
"Gobraltar"))
plot(lm(log(g) ~ 1), which = 2)


On 12/8/05, Ted Harding <Ted.Harding at nessie.mcc.ac.uk> wrote:
> On 08-Dec-05 Martin Maechler wrote:
> >>>>>> "Torsten" == Torsten Hothorn <torsten at hothorn.de>
> >>>>>>     on Thu, 8 Dec 2005 08:51:57 +0100 (CET) writes:
> >
> >     Torsten> On Wed, 7 Dec 2005, Prof Brian Ripley wrote:
> >     >> I've often wondered about that.
> >     Torsten> and the copy editor did too :-)
> >
> >     >> I've presumed that the names were
> >     >> deliberate, so have you checked the stated source?  It's not
> >     >> readily available to me (as one would expect in Oxford)?
> >
> >     Torsten> our library doesn't seems to have a copy of `The
> >     Torsten> Cambridge Encyclopaedia', so I can't check
> >     Torsten> either. Google has 74.900 hits for `Gibralta'
> >     Torsten> (more than one would expect for a typo, I think)
> >     Torsten> and 57.700.000 for `Gibraltar'.
> >
> >     Torsten> So maybe both spellings are in use.
> >
> > Well,  do you expect web authors to have a much lower rate of
> > typos than 1:770 ?
> > My limited experience on "google voting for spelling correction"
> > has rather lowered my expectation on webauthors' education in
> > orthography...
> >
> > Martin
>
> Hmmm ... Using my Google's "Results ... of about xxx":
>
>
>  Gibraltar 50,700,000
>  Gibralta      75,200
>  Gibraltr         573
>  Gibralar         836
>  Gibratar       1,020
>  Gibrltar         349
>  Gibaltar       1,850
>  Giraltar         530
>  Gbraltar         352
>  ibralter         576
>
> I'm not proposing to get exhaustive about this, but a few further
> experiments suggest that other specific typos are typically O(500)
> in frequency:
>
>  Gibralatar   589
>  Gibrlatar    618
>  Gibrltar     349
>  Gobraltar    652
>
>
> So -- if anyone can find a typo of "Gibraltar" which googles to
> more than 5000 hits (excepting "Gibralta")?
>
> Best wishes,
> Ted.
>
>
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 094 0861
> Date: 08-Dec-05                                       Time: 18:58:04
> ------------------------------ XFMail ------------------------------
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From tplate at acm.org  Thu Dec  8 21:12:58 2005
From: tplate at acm.org (Tony Plate)
Date: Thu, 08 Dec 2005 13:12:58 -0700
Subject: [Rd] typo in `eurodist'
In-Reply-To: <XFMail.051208185807.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.051208185807.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <439893CA.70809@acm.org>

I would be wary of taking frequency of misspelling as an indication of 
"correctness".

Witness the following Google counts:

Amateur (correct): 52,300,000
Amature: 2,800,000
Amatuer: 2,660,000
Ameteur: 619,000
Ameture: 941,000
Ametuer: 574,000

Here's a common misspelling at > %10

Collectible (correct): 26,900,000
Collectable: 4,140,000

More targets at
http://www.yourdictionary.com/library/misspelled.html

(BTW, one can find a list of "commonly misspelt wods" using Google :-)

-- Tony Plate

(Ted Harding) wrote:
> On 08-Dec-05 Martin Maechler wrote:
> 
>>>>>>>"Torsten" == Torsten Hothorn <torsten at hothorn.de>
>>>>>>>    on Thu, 8 Dec 2005 08:51:57 +0100 (CET) writes:
>>
>>    Torsten> On Wed, 7 Dec 2005, Prof Brian Ripley wrote:
>>    >> I've often wondered about that.
>>    Torsten> and the copy editor did too :-)
>>
>>    >> I've presumed that the names were
>>    >> deliberate, so have you checked the stated source?  It's not
>>    >> readily available to me (as one would expect in Oxford)?
>>
>>    Torsten> our library doesn't seems to have a copy of `The
>>    Torsten> Cambridge Encyclopaedia', so I can't check
>>    Torsten> either. Google has 74.900 hits for `Gibralta'
>>    Torsten> (more than one would expect for a typo, I think)
>>    Torsten> and 57.700.000 for `Gibraltar'.
>>
>>    Torsten> So maybe both spellings are in use.
>>
>>Well,  do you expect web authors to have a much lower rate of
>>typos than 1:770 ?
>>My limited experience on "google voting for spelling correction"
>>has rather lowered my expectation on webauthors' education in
>>orthography...
>>
>>Martin
> 
> 
> Hmmm ... Using my Google's "Results ... of about xxx":
> 
> 
>   Gibraltar 50,700,000 
>   Gibralta      75,200
>   Gibraltr         573
>   Gibralar         836
>   Gibratar       1,020
>   Gibrltar         349
>   Gibaltar       1,850
>   Giraltar         530
>   Gbraltar         352
>   ibralter         576
> 
> I'm not proposing to get exhaustive about this, but a few further
> experiments suggest that other specific typos are typically O(500)
> in frequency:
> 
>   Gibralatar   589
>   Gibrlatar    618
>   Gibrltar     349
>   Gobraltar    652
> 
> 
> So -- if anyone can find a typo of "Gibraltar" which googles to
> more than 5000 hits (excepting "Gibralta")?
> 
> Best wishes,
> Ted.
> 
> 
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 094 0861
> Date: 08-Dec-05                                       Time: 18:58:04
> ------------------------------ XFMail ------------------------------
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ggrothendieck at gmail.com  Thu Dec  8 21:20:30 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 8 Dec 2005 15:20:30 -0500
Subject: [Rd] typo in `eurodist'
In-Reply-To: <439893CA.70809@acm.org>
References: <XFMail.051208185807.Ted.Harding@nessie.mcc.ac.uk>
	<439893CA.70809@acm.org>
Message-ID: <971536df0512081220t2061f995w16152d4adfd47239@mail.gmail.com>

Yet the methodology of my prior post seems to pick out the
correct one:

a <- c(Amateur = 52300000,
Amature = 2800000,
Amatuer = 2660000,
Ameteur = 619000,
Ameture = 941000,
Ametuer = 574000)
plot(lm(log(a) ~ 1), which = 2)


On 12/8/05, Tony Plate <tplate at acm.org> wrote:
> I would be wary of taking frequency of misspelling as an indication of
> "correctness".
>
> Witness the following Google counts:
>
> Amateur (correct): 52,300,000
> Amature: 2,800,000
> Amatuer: 2,660,000
> Ameteur: 619,000
> Ameture: 941,000
> Ametuer: 574,000
>
> Here's a common misspelling at > %10
>
> Collectible (correct): 26,900,000
> Collectable: 4,140,000
>
> More targets at
> http://www.yourdictionary.com/library/misspelled.html
>
> (BTW, one can find a list of "commonly misspelt wods" using Google :-)
>
> -- Tony Plate
>
> (Ted Harding) wrote:
> > On 08-Dec-05 Martin Maechler wrote:
> >
> >>>>>>>"Torsten" == Torsten Hothorn <torsten at hothorn.de>
> >>>>>>>    on Thu, 8 Dec 2005 08:51:57 +0100 (CET) writes:
> >>
> >>    Torsten> On Wed, 7 Dec 2005, Prof Brian Ripley wrote:
> >>    >> I've often wondered about that.
> >>    Torsten> and the copy editor did too :-)
> >>
> >>    >> I've presumed that the names were
> >>    >> deliberate, so have you checked the stated source?  It's not
> >>    >> readily available to me (as one would expect in Oxford)?
> >>
> >>    Torsten> our library doesn't seems to have a copy of `The
> >>    Torsten> Cambridge Encyclopaedia', so I can't check
> >>    Torsten> either. Google has 74.900 hits for `Gibralta'
> >>    Torsten> (more than one would expect for a typo, I think)
> >>    Torsten> and 57.700.000 for `Gibraltar'.
> >>
> >>    Torsten> So maybe both spellings are in use.
> >>
> >>Well,  do you expect web authors to have a much lower rate of
> >>typos than 1:770 ?
> >>My limited experience on "google voting for spelling correction"
> >>has rather lowered my expectation on webauthors' education in
> >>orthography...
> >>
> >>Martin
> >
> >
> > Hmmm ... Using my Google's "Results ... of about xxx":
> >
> >
> >   Gibraltar 50,700,000
> >   Gibralta      75,200
> >   Gibraltr         573
> >   Gibralar         836
> >   Gibratar       1,020
> >   Gibrltar         349
> >   Gibaltar       1,850
> >   Giraltar         530
> >   Gbraltar         352
> >   ibralter         576
> >
> > I'm not proposing to get exhaustive about this, but a few further
> > experiments suggest that other specific typos are typically O(500)
> > in frequency:
> >
> >   Gibralatar   589
> >   Gibrlatar    618
> >   Gibrltar     349
> >   Gobraltar    652
> >
> >
> > So -- if anyone can find a typo of "Gibraltar" which googles to
> > more than 5000 hits (excepting "Gibralta")?
> >
> > Best wishes,
> > Ted.
> >
> >
> > --------------------------------------------------------------------
> > E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
> > Fax-to-email: +44 (0)870 094 0861
> > Date: 08-Dec-05                                       Time: 18:58:04
> > ------------------------------ XFMail ------------------------------
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From p.murrell at auckland.ac.nz  Thu Dec  8 22:32:46 2005
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Fri, 09 Dec 2005 10:32:46 +1300
Subject: [Rd] grid graphics gpar(fill) argument and jpeg device
In-Reply-To: <439887E3.7050309@dkfz.de>
References: <439887E3.7050309@dkfz.de>
Message-ID: <4398A67E.1090203@stat.auckland.ac.nz>

Hi


Florian Hahne wrote:
> Hi everybody,
> I just notice a strange behaviour of gpar's fill argument when using 
> non-postscript devices:
> The default of the argument is transparent (according to get.gpar("fill")).
> So as expected, the following code draws a nice red rectangle in the 
> middle of my X11 or postscript device.
> 
> pushViewport(viewport(width=0.5, height=0.5))
> grid.rect(gp=gpar(fill="red"))
> grid.rect()
> 
> However, when plotting on  a jpeg device (or any other pixel device), 
> the output of the above code is an empty (=white) rectangle. Obviously 
> the second grid.rect() which should produce a transparent rectangle 
> turns out to be filled white on the jpeg device. When I set the fill 
> argument to NA, the second rectangle is transparent as it is supposed to be.
> 
> grid.rect(gp=gpar(fill="red"))
> grid.rect(gp=gpar(fill=NA))
> 
> Is this a bug or a feature???
> I'm using R version 2.2.0 on a SUSE 10.0 linux machine.


Feature.  The top-level grid viewport (representing the entire device) 
takes starting values for things like text size, background colour, etc 
from the device;  from R version 2.2, this includes using 'fg' and 'bg' 
from the device for gpar(col) and gpar(fill).  This is so that if you 
start a device using something like postscript(bg="red"), the gpar(fill) 
for the top-level grid viewport will be "red".

The default 'bg' for PostScript is "transparent", but for jpeg the 
default 'bg' is "white".

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From jarioksa at sun3.oulu.fi  Fri Dec  9 09:02:13 2005
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: Fri, 09 Dec 2005 10:02:13 +0200
Subject: [Rd] typo in `eurodist'
In-Reply-To: <971536df0512081220t2061f995w16152d4adfd47239@mail.gmail.com>
References: <XFMail.051208185807.Ted.Harding@nessie.mcc.ac.uk>
	<439893CA.70809@acm.org>
	<971536df0512081220t2061f995w16152d4adfd47239@mail.gmail.com>
Message-ID: <1134115333.27417.18.camel@biol102145.oulu.fi>

Dear all,

There really seem to be many exciting issues in spelling and in
detecting spelling errors. However, a more disturbing feature in
'eurodist' to me is that the distances seem to be wrong. There are
several cases where the triangle inequality is violated so that a trip
from A to B is shorter when you make a detour via X instead of going
directly (see require(fortunes); fortune("eurodist") for an example). A
quick look revealed that you can find such a shorter detour for 104 of
210 "distances" of 'eurodist'. There is no guarantee that these shortest
path distances would be correct, but at least they are metric.

Just for fun, here are the differences between actual eurodist's and
shortest paths among the towns in the eurodist data:

                Athens Barcelona Brussels Calais Cherbourg
Barcelona         1036
Brussels           635         0
Calais             705        13        0
Cherbourg          819         0        0      0
Cologne            448       139        0      0         0
Copenhagen         507       459      525    537       545
Geneva             879         0        0      0         0
Gibralta          1037         0        0      0         2
Hamburg            438       214        0      0         0
Hook of Holland    530         0        0      0         0
Lisbon            1623         1      216    135         0
Lyons             1022         0        0      0         0
Madrid            1036         0        0      0         0
Marseilles        1037         0        1      0         0
Milan              879        41        0     10        92
Munich             445        61        0     26         0
Paris              798         0        0      0         0
Rome                 0         0        0      9        91
Stockholm          508       459      525    537       546
Vienna               0        70       32     35         0
                Cologne Copenhagen Geneva Gibralta Hamburg
Barcelona
Brussels
Calais
Cherbourg
Cologne
Copenhagen          222
Geneva              790        300
Gibralta              0        499      0
Hamburg               0          0      0       49
Hook of Holland       0          0     46        0       0
Lisbon              398        662    600        0     334
Lyons                 0        327      0        0       0
Madrid               26        499      0        0      48
Marseilles            1        327      0        0       0
Milan                 0        171      0       40     102
Munich                0          0      0       89       0
Paris                 0        450      0        0       0
Rome                  0         98     81        0      29
Stockholm           215          0    300      539       0
Vienna                0          0      0       70       0
                Hook of Holland Lisbon Lyons Madrid Marseilles
Barcelona
Brussels
Calais
Cherbourg
Cologne
Copenhagen
Geneva
Gibralta
Hamburg
Hook of Holland
Lisbon                      240
Lyons                         1      0
Madrid                        0      0     0
Marseilles                    1    264     0      0
Milan                         1    744     0    115          0
Munich                        0    670    65     70        160
Paris                         0    150     0      0          1
Rome                          0    608   134      1          0
Stockholm                   581    272   327    539        327
Vienna                        0    672    70     41          0
                Milan Munich Paris Rome Stockholm
Barcelona
Brussels
Calais
Cherbourg
Cologne
Copenhagen
Geneva
Gibralta
Hamburg
Hook of Holland
Lisbon
Lyons
Madrid
Marseilles
Milan
Munich              0
Paris              57      0
Rome                0     29    91
Stockholm         171      0   451  105
Vienna            139      0     0    0         1

It seems that "marginal" towns (Athens, Lisbon, Stockholm, Copenhagen)
have largest discrepancies.

It also seems that the names are not 'localized', but weird English
forms are used for places like K?benhavn and Wien so dear to the R core
developers.

cheers, jari oksanen


From sleepingwell at gmail.com  Fri Dec  9 10:18:56 2005
From: sleepingwell at gmail.com (Simon Knapp)
Date: Fri, 9 Dec 2005 20:18:56 +1100
Subject: [Rd] Blocking problem with embeded R (windows)
Message-ID: <4f8ec3aa0512090118h6c7700d3v1c2a1a5278aa9f4d@mail.gmail.com>

Hi all,

I am trying to make calls to R from an MFC application running on XP
and am having problems blocking the application while the call
executes.

I have tried the following approaches to using R from the application
(note that I set a wait cursor while R is executing).

1) call rcmd in BATCH mode using system(). This works well, except
that I get the cmd window popping up... which makes the app look
pretty tacky.

2) use the com interface. This works OK... sometimes. When I call
R_Proxy_evaluate_noreturn by pressing OK in the dialog that starts the
execution, if the cursor happens to be over the applications window
when the dialog disappears, then I get my wait cursor and the
application blocks. If the cursor is not over the applications window,
then I don't get the wait cursor and the application seems to block
after the first mouse click within the applications window.

3) use Rproxy.dll directly. The application does not block and I don't
get a wait cursor at all.

4) integrate the code used by Rproxy into my application (in
verbatim). The application does not block and I don't get a wait
cursor at all.

The things I have read about DLLs make statements like "a dll is just
code and data loaded into your applications process", which I have
taken to imply that the application should block while R is executing.
This also seems to be implied by the discussion around the rtest
example r-ext.pdf.

Can someone offer any advice on whether there is some way to make my
application block when configuring R? If not, is there a simple way to
make the app block (I have never coded using threads before, am a
relative newbie to MFC and am struggling to figure out how I would to
block otherwise).

Help would be greatly appreciated,
Simon Knapp


From ripley at stats.ox.ac.uk  Fri Dec  9 10:27:36 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 9 Dec 2005 09:27:36 +0000 (GMT)
Subject: [Rd] Blocking problem with embeded R (windows)
In-Reply-To: <4f8ec3aa0512090118h6c7700d3v1c2a1a5278aa9f4d@mail.gmail.com>
References: <4f8ec3aa0512090118h6c7700d3v1c2a1a5278aa9f4d@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0512090925100.27801@gannet.stats>

You are not calling R, but rproxy.dll, part of a (D)COM interface.  Try 
calling R itself (via R.dll).

On Fri, 9 Dec 2005, Simon Knapp wrote:

> Hi all,
>
> I am trying to make calls to R from an MFC application running on XP
> and am having problems blocking the application while the call
> executes.
>
> I have tried the following approaches to using R from the application
> (note that I set a wait cursor while R is executing).
>
> 1) call rcmd in BATCH mode using system(). This works well, except
> that I get the cmd window popping up... which makes the app look
> pretty tacky.
>
> 2) use the com interface. This works OK... sometimes. When I call
> R_Proxy_evaluate_noreturn by pressing OK in the dialog that starts the
> execution, if the cursor happens to be over the applications window
> when the dialog disappears, then I get my wait cursor and the
> application blocks. If the cursor is not over the applications window,
> then I don't get the wait cursor and the application seems to block
> after the first mouse click within the applications window.
>
> 3) use Rproxy.dll directly. The application does not block and I don't
> get a wait cursor at all.
>
> 4) integrate the code used by Rproxy into my application (in
> verbatim). The application does not block and I don't get a wait
> cursor at all.
>
> The things I have read about DLLs make statements like "a dll is just
> code and data loaded into your applications process", which I have
> taken to imply that the application should block while R is executing.
> This also seems to be implied by the discussion around the rtest
> example r-ext.pdf.
>
> Can someone offer any advice on whether there is some way to make my
> application block when configuring R? If not, is there a simple way to
> make the app block (I have never coded using threads before, am a
> relative newbie to MFC and am struggling to figure out how I would to
> block otherwise).
>
> Help would be greatly appreciated,
> Simon Knapp
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From sleepingwell at gmail.com  Fri Dec  9 12:39:40 2005
From: sleepingwell at gmail.com (Simon Knapp)
Date: Fri, 9 Dec 2005 22:39:40 +1100
Subject: [Rd]  Blocking problem with embeded R (windows)
Message-ID: <000201c5fcb5$45ffa870$0501010a@SIMON>

Thanks for that rapid reply!

In the fourth approach, I have compiled the functions R_proxy_init(), 
R_proxy_evaluate_noreturn(), R_proxy_term() and the callback functions 
defined in Baiers code directly into my application (I got them from the R 
source distribution and commented out the other functions). Rproxy.dll is 
not on my path.

When I look through the R_proxy_init() it does the same things that are done 
in the rtest example (as far as I can tell). Hence, I thought that I was 
calling R itself when initialising the dll.

I am using Baiers function R_proxy_evaluate_noreturn() because it seemed 
wiser to use code that was written by someone who knows what they are doing 
than roll my own! I don't understand enough about R IO functions to feel 
comfortable using them and am having trouble finding doco on them. I'm 
slowly learning about them, and the rest of R, by reading the code. Is there 
any doco on around on these and the R source in general?

Thanks again for the rapid reply
Simon Knapp


From bhs2 at mevik.net  Fri Dec  9 12:40:11 2005
From: bhs2 at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge_Mevik?=)
Date: Fri, 09 Dec 2005 12:40:11 +0100
Subject: [Rd] How to implement package-specific options?
Message-ID: <m0zmnav6qs.fsf@bar.nemo-project.org>

Dear developeRs,

What is the preferred way to implement package-specific options?

Should one simply use options() -- e.g. options(myoption = myvalue)?
(And how should one document such options?)

Or is it better to implement a separate mechanismn, perhaps something
like ps.options()?


-- 
Bj?rn-Helge Mevik


From ripley at stats.ox.ac.uk  Fri Dec  9 12:52:46 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 9 Dec 2005 11:52:46 +0000 (GMT)
Subject: [Rd] How to implement package-specific options?
In-Reply-To: <m0zmnav6qs.fsf@bar.nemo-project.org>
References: <m0zmnav6qs.fsf@bar.nemo-project.org>
Message-ID: <Pine.LNX.4.61.0512091150320.10509@gannet.stats>

On Fri, 9 Dec 2005, Bj?rn-Helge Mevik wrote:

> Dear developeRs,
>
> What is the preferred way to implement package-specific options?
>
> Should one simply use options() -- e.g. options(myoption = myvalue)?
> (And how should one document such options?)

You can, but documentation is the problem.  It is possible to have your 
own options.Rd and help() will detect this and report there are two or 
more, but end-users may be confused.

> Or is it better to implement a separate mechanismn, perhaps something
> like ps.options()?

I think package sm() has a good solution.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From murdoch at stats.uwo.ca  Fri Dec  9 15:31:02 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 09 Dec 2005 09:31:02 -0500
Subject: [Rd] ID for machine?
Message-ID: <43999526.8040500@stats.uwo.ca>

Does R have a function to obtain a name of the machine that it is 
running on?  I'm going to be writing results to a database from several 
different machines, and I'd like to be able to identify where they came 
from.

Duncan Murdoch


From Robert.McGehee at geodecapital.com  Fri Dec  9 15:43:37 2005
From: Robert.McGehee at geodecapital.com (McGehee, Robert)
Date: Fri, 9 Dec 2005 09:43:37 -0500
Subject: [Rd] ID for machine?
Message-ID: <67DCA285A2D7754280D3B8E88EB548020C94672C@MSGBOSCLB2WIN.DMN1.FMR.COM>

Not an R function, per se, but
> system("uname -n", intern = TRUE)
returns my computer's network node hostname on both Windows and Linux.

You can use 'uname -a' for more information.

-----Original Message-----
From: Duncan Murdoch [mailto:murdoch at stats.uwo.ca] 
Sent: Friday, December 09, 2005 9:31 AM
To: R-devel
Subject: [Rd] ID for machine?


Does R have a function to obtain a name of the machine that it is 
running on?  I'm going to be writing results to a database from several 
different machines, and I'd like to be able to identify where they came 
from.

Duncan Murdoch

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From dimitris.rizopoulos at med.kuleuven.be  Fri Dec  9 15:48:28 2005
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Fri, 9 Dec 2005 15:48:28 +0100
Subject: [Rd] ID for machine?
References: <43999526.8040500@stats.uwo.ca>
Message-ID: <001801c5fccf$9d8276d0$0540210a@www.domain>

maybe

Sys.info()["nodename"]

could be helpfull in Windows.

Best,
Dimitris


----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Duncan Murdoch" <murdoch at stats.uwo.ca>
To: "R-devel" <r-devel at stat.math.ethz.ch>
Sent: Friday, December 09, 2005 3:31 PM
Subject: [Rd] ID for machine?


> Does R have a function to obtain a name of the machine that it is
> running on?  I'm going to be writing results to a database from 
> several
> different machines, and I'd like to be able to identify where they 
> came
> from.
>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm


From sfalcon at fhcrc.org  Fri Dec  9 15:49:07 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Fri, 09 Dec 2005 06:49:07 -0800
Subject: [Rd] ID for machine?
In-Reply-To: <43999526.8040500@stats.uwo.ca> (Duncan Murdoch's message of "Fri,
	09 Dec 2005 09:31:02 -0500")
References: <43999526.8040500@stats.uwo.ca>
Message-ID: <m24q5i9vh8.fsf@fhcrc.org>

On  9 Dec 2005, murdoch at stats.uwo.ca wrote:
> Does R have a function to obtain a name of the machine that it is
> running on?  I'm going to be writing results to a database from
> several different machines, and I'd like to be able to identify
> where they came from.

Sys.info has nodename which should be the hostname.


From jkawczak at uncc.edu  Fri Dec  9 15:55:36 2005
From: jkawczak at uncc.edu (Janusz Kawczak)
Date: Fri, 9 Dec 2005 09:55:36 -0500 (EST)
Subject: [Rd] ID for machine?
In-Reply-To: <43999526.8040500@stats.uwo.ca>
References: <43999526.8040500@stats.uwo.ca>
Message-ID: <Pine.GSO.4.55.0512090951420.23556@is-sm1.uncc.edu>

How about something as trivial as
>system('hostname')? Is this for the Wind****s system?

Janusz.

On Fri, 9 Dec 2005, Duncan Murdoch wrote:

> Does R have a function to obtain a name of the machine that it is
> running on?  I'm going to be writing results to a database from several
> different machines, and I'd like to be able to identify where they came
> from.
>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From murdoch at stats.uwo.ca  Fri Dec  9 16:02:03 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 09 Dec 2005 10:02:03 -0500
Subject: [Rd] ID for machine?
In-Reply-To: <001801c5fccf$9d8276d0$0540210a@www.domain>
References: <43999526.8040500@stats.uwo.ca>
	<001801c5fccf$9d8276d0$0540210a@www.domain>
Message-ID: <43999C6B.3060300@stats.uwo.ca>

On 12/9/2005 9:48 AM, Dimitris Rizopoulos wrote:
> maybe
> 
> Sys.info()["nodename"]
> 
> could be helpfull in Windows.

Thanks to all who replied.  This seems like the most portable solution. 
  (The code will be running on all sorts of machines, and this isn't 
guaranteed to work, but I think it's pretty likely to, whereas some of 
the system() calls are a little more fragile.)

Duncan


From luke at stat.uiowa.edu  Fri Dec  9 17:05:26 2005
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Fri, 9 Dec 2005 10:05:26 -0600 (CST)
Subject: [Rd] qt for df < 1
In-Reply-To: <x2k6efbgva.fsf@viggo.kubism.ku.dk>
References: <FD963C8B-71E1-4322-AE17-98303ED6B0D8@uiuc.edu>
	<x2k6efbgva.fsf@viggo.kubism.ku.dk>
Message-ID: <Pine.LNX.4.63.0512091003150.20896@nokomis.stat.uiowa.edu>

On Thu, 8 Dec 2005, Peter Dalgaard wrote:

> roger koenker <rkoenker at uiuc.edu> writes:
>
>> I was experimenting yesterday with a binomial make.link option
>> for estimating student t binary response models, tentatively
>> called gossit, and I noticed eventually that the R qt function doesn't
>> like df < 1.  Vaguely recalling that Splus didn't seem to mind such
>> weirdness,  I checked on our soon to be defunct Splus6.2 and
>> sure enough, it produced plausible answers instead of R's NA's.
>> Of course, I have no way of judging the quality of these answers,
>> but I'm curious about whether someone has already looked into
>> this can of worms.
>
> Well the help page has:
>
> For 'qt' only values of at least one are currently supported.
>
> and someone must have written that...
>
> R does have pt for df < 1, so a temporary fix using uniroot() seems
> doable.
>
>

Something like

     qqt<-function(p,df) sign(p-0.5)*sqrt(qf(1-2*pmin(p,1-p),1,df))

seems to do reasonably, at least in terms of consistency with pt, down
to 0.2 or mayby 0.1 df based on

     f<-function(d, n = 101) {
 	x<-seq(0, 1, len = n)
 	max(abs(pt(qqt(x, d), d) - x))
     }
     plot(function(d) log10(sapply(d, f)), .01,1)

luke

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From mdowle at concordiafunds.com  Fri Dec  9 18:35:41 2005
From: mdowle at concordiafunds.com (Matthew Dowle)
Date: Fri, 9 Dec 2005 17:35:41 -0000 
Subject: [Rd] [R] data.frame() size
Message-ID: <78166BFC5165D811AA0400065BF0324BF07B2C@wisconsin.concordia>


Hi,

Please see below for post on r-help regarding data.frame() and the
possibility of dropping rownames, for space and time reasons.
I've made some changes, attached, and it seems to be working well. I see the
expected space (90% saved) and time (10 times faster) savings. There are no
doubt some bugs, and needs more work and testing, but I thought I would post
first at this stage.

Could some changes along these lines be made to R ? I'm happy to help with
testing and further work if required. In the meantime I can work with
overloaded functions which fixes the problems in my case.

Functions effected :

   dim.data.frame
   format.data.frame
   print.data.frame
   data.frame
   [.data.frame
   as.matrix.data.frame

Modified source code attached.

Regards,
Matthew


-----Original Message-----
From: Matthew Dowle 
Sent: 09 December 2005 09:44
To: 'Peter Dalgaard'
Cc: 'r-help at stat.math.ethz.ch'
Subject: RE: [R] data.frame() size



That explains it. Thanks. I don't need rownames though, as I'll only ever
use integer subscripts. Is there anyway to drop them, or even better not
create them in the first place? The memory saved (90%) by not having them
and 10 times speed up would be very useful. I think I need a data.frame
rather than a matrix because I have columns of different types in real life.

> rownames(d) = NULL
Error in "dimnames<-.data.frame"(`*tmp*`, value = list(NULL, c("a", "b" : 
        invalid 'dimnames' given for data frame


-----Original Message-----
From: pd at pubhealth.ku.dk [mailto:pd at pubhealth.ku.dk] On Behalf Of Peter
Dalgaard
Sent: 08 December 2005 18:57
To: Matthew Dowle
Cc: 'r-help at stat.math.ethz.ch'
Subject: Re: [R] data.frame() size


Matthew Dowle <mdowle at concordiafunds.com> writes:

> Hi,
> 
> In the example below why is d 10 times bigger than m, according to
> object.size ? It also takes around 10 times as long to create, which 
> fits with object.size() being truthful.  gcinfo(TRUE) also indicates a 
> great deal more garbage collector activity caused by data.frame() than 
> matrix().
> 
> $ R --vanilla
> ....
> > nr = 1000000
> > system.time(m<<-matrix(integer(1), nrow=nr, ncol=2))
> [1] 0.22 0.01 0.23 0.00 0.00
> > system.time(d<<-data.frame(a=integer(nr), b=integer(nr)))
> [1] 2.81 0.20 3.01 0.00 0.00			# 10 times longer
> 
> > dim(m)
> [1] 1000000       2
> > dim(d)
> [1] 1000000       2				# same dimensions
> 
> > storage.mode(m)
> [1] "integer"
> > sapply(d, storage.mode)
>         a         b 
> "integer" "integer" 				# same storage.mode
> 
> > object.size(m)/1024^2
> [1] 7.629616
> > object.size(d)/1024^2
> [1] 76.29482					# but 10 times bigger
> 
> > sum(sapply(d, object.size))/1024^2
> [1] 7.629501					# or is it ?    If its not
> really 10 times bigger, why 10 times longer above ?

Row names!!


> r <- as.character(1:1e6)
> object.size(r)
[1] 72000056
> object.size(r)/1024^2
[1] 68.6646

'nuff said?

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From rkoenker at uiuc.edu  Fri Dec  9 18:36:24 2005
From: rkoenker at uiuc.edu (roger koenker)
Date: Fri, 9 Dec 2005 11:36:24 -0600
Subject: [Rd] qt for df < 1
In-Reply-To: <Pine.LNX.4.63.0512091003150.20896@nokomis.stat.uiowa.edu>
References: <FD963C8B-71E1-4322-AE17-98303ED6B0D8@uiuc.edu>
	<x2k6efbgva.fsf@viggo.kubism.ku.dk>
	<Pine.LNX.4.63.0512091003150.20896@nokomis.stat.uiowa.edu>
Message-ID: <9E24B8EC-FA36-4773-98D3-59D517985243@uiuc.edu>

On Dec 9, 2005, at 10:05 AM, Luke Tierney wrote:

> On Thu, 8 Dec 2005, Peter Dalgaard wrote:
>
>> roger koenker <rkoenker at uiuc.edu> writes:
>>
>>> I was experimenting yesterday with a binomial make.link option
>>> for estimating student t binary response models, tentatively
>>> called gossit, and I noticed eventually that the R qt function  
>>> doesn't
>>> like df < 1.  Vaguely recalling that Splus didn't seem to mind such
>>> weirdness,  I checked on our soon to be defunct Splus6.2 and
>>> sure enough, it produced plausible answers instead of R's NA's.
>>> Of course, I have no way of judging the quality of these answers,
>>> but I'm curious about whether someone has already looked into
>>> this can of worms.
>>
>> Well the help page has:
>>
>> For 'qt' only values of at least one are currently supported.
>>
>> and someone must have written that...
>>
>> R does have pt for df < 1, so a temporary fix using uniroot() seems
>> doable.
>>
>>
>
> Something like
>
>     qqt<-function(p,df) sign(p-0.5)*sqrt(qf(1-2*pmin(p,1-p),1,df))
>
> seems to do reasonably, at least in terms of consistency with pt, down
> to 0.2 or mayby 0.1 df based on
>
>     f<-function(d, n = 101) {
> 	x<-seq(0, 1, len = n)
> 	max(abs(pt(qqt(x, d), d) - x))
>     }
>     plot(function(d) log10(sapply(d, f)), .01,1)
>
> luke

Splus6.2 seems to be using just this approach based on similar testing.

Pure schadenfreude makes it hard to resist mentioning that in Splus6.2
qf(0, df1, df2)  gives -Inf  rather than 0, which caused some  
difficulties initially with my
attempt to replicate the comparison.

Roger


>
> -- 
> Luke Tierney
> Chair, Statistics and Actuarial Science
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>    Actuarial Science
> 241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From ggrothendieck at gmail.com  Fri Dec  9 18:37:30 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 9 Dec 2005 12:37:30 -0500
Subject: [Rd] [R] data.frame() size
In-Reply-To: <78166BFC5165D811AA0400065BF0324BF07B2C@wisconsin.concordia>
References: <78166BFC5165D811AA0400065BF0324BF07B2C@wisconsin.concordia>
Message-ID: <971536df0512090937u12ca6913xa0d98484a790b277@mail.gmail.com>

There was nothing attached in the copy that came through
to me.

By the way, there was some discussion earlier this year
on a light-weight data.frame class but I don't think anyone
ever posted any code.

On 12/9/05, Matthew Dowle <mdowle at concordiafunds.com> wrote:
>
> Hi,
>
> Please see below for post on r-help regarding data.frame() and the
> possibility of dropping rownames, for space and time reasons.
> I've made some changes, attached, and it seems to be working well. I see the
> expected space (90% saved) and time (10 times faster) savings. There are no
> doubt some bugs, and needs more work and testing, but I thought I would post
> first at this stage.
>
> Could some changes along these lines be made to R ? I'm happy to help with
> testing and further work if required. In the meantime I can work with
> overloaded functions which fixes the problems in my case.
>
> Functions effected :
>
>   dim.data.frame
>   format.data.frame
>   print.data.frame
>   data.frame
>   [.data.frame
>   as.matrix.data.frame
>
> Modified source code attached.
>
> Regards,
> Matthew
>
>
> -----Original Message-----
> From: Matthew Dowle
> Sent: 09 December 2005 09:44
> To: 'Peter Dalgaard'
> Cc: 'r-help at stat.math.ethz.ch'
> Subject: RE: [R] data.frame() size
>
>
>
> That explains it. Thanks. I don't need rownames though, as I'll only ever
> use integer subscripts. Is there anyway to drop them, or even better not
> create them in the first place? The memory saved (90%) by not having them
> and 10 times speed up would be very useful. I think I need a data.frame
> rather than a matrix because I have columns of different types in real life.
>
> > rownames(d) = NULL
> Error in "dimnames<-.data.frame"(`*tmp*`, value = list(NULL, c("a", "b" :
>        invalid 'dimnames' given for data frame
>
>
> -----Original Message-----
> From: pd at pubhealth.ku.dk [mailto:pd at pubhealth.ku.dk] On Behalf Of Peter
> Dalgaard
> Sent: 08 December 2005 18:57
> To: Matthew Dowle
> Cc: 'r-help at stat.math.ethz.ch'
> Subject: Re: [R] data.frame() size
>
>
> Matthew Dowle <mdowle at concordiafunds.com> writes:
>
> > Hi,
> >
> > In the example below why is d 10 times bigger than m, according to
> > object.size ? It also takes around 10 times as long to create, which
> > fits with object.size() being truthful.  gcinfo(TRUE) also indicates a
> > great deal more garbage collector activity caused by data.frame() than
> > matrix().
> >
> > $ R --vanilla
> > ....
> > > nr = 1000000
> > > system.time(m<<-matrix(integer(1), nrow=nr, ncol=2))
> > [1] 0.22 0.01 0.23 0.00 0.00
> > > system.time(d<<-data.frame(a=integer(nr), b=integer(nr)))
> > [1] 2.81 0.20 3.01 0.00 0.00                  # 10 times longer
> >
> > > dim(m)
> > [1] 1000000       2
> > > dim(d)
> > [1] 1000000       2                           # same dimensions
> >
> > > storage.mode(m)
> > [1] "integer"
> > > sapply(d, storage.mode)
> >         a         b
> > "integer" "integer"                           # same storage.mode
> >
> > > object.size(m)/1024^2
> > [1] 7.629616
> > > object.size(d)/1024^2
> > [1] 76.29482                                  # but 10 times bigger
> >
> > > sum(sapply(d, object.size))/1024^2
> > [1] 7.629501                                  # or is it ?    If its not
> > really 10 times bigger, why 10 times longer above ?
>
> Row names!!
>
>
> > r <- as.character(1:1e6)
> > object.size(r)
> [1] 72000056
> > object.size(r)/1024^2
> [1] 68.6646
>
> 'nuff said?
>
> --
>   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907
>
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>


From hin-tak.leung at cimr.cam.ac.uk  Fri Dec  9 19:40:33 2005
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Fri, 09 Dec 2005 18:40:33 +0000
Subject: [Rd] [R] data.frame() size
In-Reply-To: <971536df0512090937u12ca6913xa0d98484a790b277@mail.gmail.com>
References: <78166BFC5165D811AA0400065BF0324BF07B2C@wisconsin.concordia>
	<971536df0512090937u12ca6913xa0d98484a790b277@mail.gmail.com>
Message-ID: <4399CFA1.4000000@cimr.cam.ac.uk>

Gabor Grothendieck wrote:
> There was nothing attached in the copy that came through
> to me.

I like to see that patch also.

> By the way, there was some discussion earlier this year
> on a light-weight data.frame class but I don't think anyone
> ever posted any code.

It may have been me. I am working on a bit-packed data.frame
which only uses 2-bits per unit of data, so it is 4 units per RAWSXP.
(work in progress, nothing to show).

So I am very interested to see the patch.

Yes, I took a couple of weeks reading/learning where have all the
memory gone in data.frame. The rowname/column names allocation is
a bit stupid. Each rowname and each column name is a full
R object, so there is a 32(or 28) byte overhead just from managing
that, before the STRSXP for the actual string, which is another X bytes.
so for an 1 x N data.frame with integers for content, the
the content is 4-byte * N, but the rowname/columnname is 32 * N -ish.
(a 9x increase). Word is 32-bit on most people's machines, and
I am counting the extra one from which you have to keep the address
of each SEXPREC somewhere, so it is 7+1 = 8, if I understand it correctly.

Here is the relevant comment, quoted verbatum from around line 225 of 
"src/include/Rinternals.h":

/* The generational collector uses a reduced version of SEXPREC as a
    header in vector nodes.  The layout MUST be kept consistent with
    the SEXPREC definition.  The standard SEXPREC takes up 7 words on
    most hardware; this reduced version should take up only 6 words.
    In addition to slightly reducing memory use, this can lead to more
    favorable data alignment on 32-bit architectures like the Intel
    Pentium III where odd word alignment of doubles is allowed but much
    less efficient than even word alignment. */

Hin-Tak Leung

> On 12/9/05, Matthew Dowle <mdowle at concordiafunds.com> wrote:
> 
>>Hi,
>>
>>Please see below for post on r-help regarding data.frame() and the
>>possibility of dropping rownames, for space and time reasons.
>>I've made some changes, attached, and it seems to be working well. I see the
>>expected space (90% saved) and time (10 times faster) savings. There are no
>>doubt some bugs, and needs more work and testing, but I thought I would post
>>first at this stage.
>>
>>Could some changes along these lines be made to R ? I'm happy to help with
>>testing and further work if required. In the meantime I can work with
>>overloaded functions which fixes the problems in my case.
>>
>>Functions effected :
>>
>>  dim.data.frame
>>  format.data.frame
>>  print.data.frame
>>  data.frame
>>  [.data.frame
>>  as.matrix.data.frame
>>
>>Modified source code attached.
>>
>>Regards,
>>Matthew
>>
>>
>>-----Original Message-----
>>From: Matthew Dowle
>>Sent: 09 December 2005 09:44
>>To: 'Peter Dalgaard'
>>Cc: 'r-help at stat.math.ethz.ch'
>>Subject: RE: [R] data.frame() size
>>
>>
>>
>>That explains it. Thanks. I don't need rownames though, as I'll only ever
>>use integer subscripts. Is there anyway to drop them, or even better not
>>create them in the first place? The memory saved (90%) by not having them
>>and 10 times speed up would be very useful. I think I need a data.frame
>>rather than a matrix because I have columns of different types in real life.
>>
>>
>>>rownames(d) = NULL
>>
>>Error in "dimnames<-.data.frame"(`*tmp*`, value = list(NULL, c("a", "b" :
>>       invalid 'dimnames' given for data frame
>>
>>
>>-----Original Message-----
>>From: pd at pubhealth.ku.dk [mailto:pd at pubhealth.ku.dk] On Behalf Of Peter
>>Dalgaard
>>Sent: 08 December 2005 18:57
>>To: Matthew Dowle
>>Cc: 'r-help at stat.math.ethz.ch'
>>Subject: Re: [R] data.frame() size
>>
>>
>>Matthew Dowle <mdowle at concordiafunds.com> writes:
>>
>>
>>>Hi,
>>>
>>>In the example below why is d 10 times bigger than m, according to
>>>object.size ? It also takes around 10 times as long to create, which
>>>fits with object.size() being truthful.  gcinfo(TRUE) also indicates a
>>>great deal more garbage collector activity caused by data.frame() than
>>>matrix().
>>>
>>>$ R --vanilla
>>>....
>>>
>>>>nr = 1000000
>>>>system.time(m<<-matrix(integer(1), nrow=nr, ncol=2))
>>>
>>>[1] 0.22 0.01 0.23 0.00 0.00
>>>
>>>>system.time(d<<-data.frame(a=integer(nr), b=integer(nr)))
>>>
>>>[1] 2.81 0.20 3.01 0.00 0.00                  # 10 times longer
>>>
>>>
>>>>dim(m)
>>>
>>>[1] 1000000       2
>>>
>>>>dim(d)
>>>
>>>[1] 1000000       2                           # same dimensions
>>>
>>>
>>>>storage.mode(m)
>>>
>>>[1] "integer"
>>>
>>>>sapply(d, storage.mode)
>>>
>>>        a         b
>>>"integer" "integer"                           # same storage.mode
>>>
>>>
>>>>object.size(m)/1024^2
>>>
>>>[1] 7.629616
>>>
>>>>object.size(d)/1024^2
>>>
>>>[1] 76.29482                                  # but 10 times bigger
>>>
>>>
>>>>sum(sapply(d, object.size))/1024^2
>>>
>>>[1] 7.629501                                  # or is it ?    If its not
>>>really 10 times bigger, why 10 times longer above ?
>>
>>Row names!!
>>
>>
>>
>>>r <- as.character(1:1e6)
>>>object.size(r)
>>
>>[1] 72000056
>>
>>>object.size(r)/1024^2
>>
>>[1] 68.6646
>>
>>'nuff said?
>>
>>--
>>  O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>> c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>> (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
>>~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907
>>
>>
>>
>>
>>______________________________________________
>>R-devel at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>>
> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From andy_liaw at merck.com  Fri Dec  9 20:13:49 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 9 Dec 2005 14:13:49 -0500
Subject: [Rd] [R] data.frame() size
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED65C@usctmx1106.merck.com>

I believe Gabor was referring to this:

http://tolstoy.newcastle.edu.au/R/devel/05/05/0837.html

Andy

From: Hin-Tak Leung
> 
> Gabor Grothendieck wrote:
> > There was nothing attached in the copy that came through
> > to me.
> 
> I like to see that patch also.
> 
> > By the way, there was some discussion earlier this year
> > on a light-weight data.frame class but I don't think anyone
> > ever posted any code.
> 
> It may have been me. I am working on a bit-packed data.frame
> which only uses 2-bits per unit of data, so it is 4 units per RAWSXP.
> (work in progress, nothing to show).
> 
> So I am very interested to see the patch.
> 
> Yes, I took a couple of weeks reading/learning where have all the
> memory gone in data.frame. The rowname/column names allocation is
> a bit stupid. Each rowname and each column name is a full
> R object, so there is a 32(or 28) byte overhead just from managing
> that, before the STRSXP for the actual string, which is 
> another X bytes.
> so for an 1 x N data.frame with integers for content, the
> the content is 4-byte * N, but the rowname/columnname is 32 * N -ish.
> (a 9x increase). Word is 32-bit on most people's machines, and
> I am counting the extra one from which you have to keep the address
> of each SEXPREC somewhere, so it is 7+1 = 8, if I understand 
> it correctly.
> 
> Here is the relevant comment, quoted verbatum from around line 225 of 
> "src/include/Rinternals.h":
> 
> /* The generational collector uses a reduced version of SEXPREC as a
>     header in vector nodes.  The layout MUST be kept consistent with
>     the SEXPREC definition.  The standard SEXPREC takes up 7 words on
>     most hardware; this reduced version should take up only 6 words.
>     In addition to slightly reducing memory use, this can lead to more
>     favorable data alignment on 32-bit architectures like the Intel
>     Pentium III where odd word alignment of doubles is 
> allowed but much
>     less efficient than even word alignment. */
> 
> Hin-Tak Leung
> 
> > On 12/9/05, Matthew Dowle <mdowle at concordiafunds.com> wrote:
> > 
> >>Hi,
> >>
> >>Please see below for post on r-help regarding data.frame() and the
> >>possibility of dropping rownames, for space and time reasons.
> >>I've made some changes, attached, and it seems to be 
> working well. I see the
> >>expected space (90% saved) and time (10 times faster) 
> savings. There are no
> >>doubt some bugs, and needs more work and testing, but I 
> thought I would post
> >>first at this stage.
> >>
> >>Could some changes along these lines be made to R ? I'm 
> happy to help with
> >>testing and further work if required. In the meantime I can 
> work with
> >>overloaded functions which fixes the problems in my case.
> >>
> >>Functions effected :
> >>
> >>  dim.data.frame
> >>  format.data.frame
> >>  print.data.frame
> >>  data.frame
> >>  [.data.frame
> >>  as.matrix.data.frame
> >>
> >>Modified source code attached.
> >>
> >>Regards,
> >>Matthew
> >>
> >>
> >>-----Original Message-----
> >>From: Matthew Dowle
> >>Sent: 09 December 2005 09:44
> >>To: 'Peter Dalgaard'
> >>Cc: 'r-help at stat.math.ethz.ch'
> >>Subject: RE: [R] data.frame() size
> >>
> >>
> >>
> >>That explains it. Thanks. I don't need rownames though, as 
> I'll only ever
> >>use integer subscripts. Is there anyway to drop them, or 
> even better not
> >>create them in the first place? The memory saved (90%) by 
> not having them
> >>and 10 times speed up would be very useful. I think I need 
> a data.frame
> >>rather than a matrix because I have columns of different 
> types in real life.
> >>
> >>
> >>>rownames(d) = NULL
> >>
> >>Error in "dimnames<-.data.frame"(`*tmp*`, value = 
> list(NULL, c("a", "b" :
> >>       invalid 'dimnames' given for data frame
> >>
> >>
> >>-----Original Message-----
> >>From: pd at pubhealth.ku.dk [mailto:pd at pubhealth.ku.dk] On 
> Behalf Of Peter
> >>Dalgaard
> >>Sent: 08 December 2005 18:57
> >>To: Matthew Dowle
> >>Cc: 'r-help at stat.math.ethz.ch'
> >>Subject: Re: [R] data.frame() size
> >>
> >>
> >>Matthew Dowle <mdowle at concordiafunds.com> writes:
> >>
> >>
> >>>Hi,
> >>>
> >>>In the example below why is d 10 times bigger than m, according to
> >>>object.size ? It also takes around 10 times as long to 
> create, which
> >>>fits with object.size() being truthful.  gcinfo(TRUE) also 
> indicates a
> >>>great deal more garbage collector activity caused by 
> data.frame() than
> >>>matrix().
> >>>
> >>>$ R --vanilla
> >>>....
> >>>
> >>>>nr = 1000000
> >>>>system.time(m<<-matrix(integer(1), nrow=nr, ncol=2))
> >>>
> >>>[1] 0.22 0.01 0.23 0.00 0.00
> >>>
> >>>>system.time(d<<-data.frame(a=integer(nr), b=integer(nr)))
> >>>
> >>>[1] 2.81 0.20 3.01 0.00 0.00                  # 10 times longer
> >>>
> >>>
> >>>>dim(m)
> >>>
> >>>[1] 1000000       2
> >>>
> >>>>dim(d)
> >>>
> >>>[1] 1000000       2                           # same dimensions
> >>>
> >>>
> >>>>storage.mode(m)
> >>>
> >>>[1] "integer"
> >>>
> >>>>sapply(d, storage.mode)
> >>>
> >>>        a         b
> >>>"integer" "integer"                           # same storage.mode
> >>>
> >>>
> >>>>object.size(m)/1024^2
> >>>
> >>>[1] 7.629616
> >>>
> >>>>object.size(d)/1024^2
> >>>
> >>>[1] 76.29482                                  # but 10 times bigger
> >>>
> >>>
> >>>>sum(sapply(d, object.size))/1024^2
> >>>
> >>>[1] 7.629501                                  # or is it ? 
>    If its not
> >>>really 10 times bigger, why 10 times longer above ?
> >>
> >>Row names!!
> >>
> >>
> >>
> >>>r <- as.character(1:1e6)
> >>>object.size(r)
> >>
> >>[1] 72000056
> >>
> >>>object.size(r)/1024^2
> >>
> >>[1] 68.6646
> >>
> >>'nuff said?
> >>
> >>--
> >>  O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
> >> c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
> >> (*) \(*) -- University of Copenhagen   Denmark          
> Ph:  (+45) 35327918
> >>~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  
> FAX: (+45) 35327907
> >>
> >>
> >>
> >>
> >>______________________________________________
> >>R-devel at r-project.org mailing list
> >>https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >>
> >>
> > 
> > 
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From bullard at berkeley.edu  Fri Dec  9 20:18:55 2005
From: bullard at berkeley.edu (James Bullard)
Date: Fri, 09 Dec 2005 11:18:55 -0800
Subject: [Rd] segfault following a detach
Message-ID: <4399D89F.7050806@berkeley.edu>

Hello, first off, thanks for all of the previous help; hopefully someone 
will have some insight on this question. I am attempting to track down a 
segmentation fault which occurs only after a detach(2) is called in the 
code (I have replaced the detach(2) with detach(package:DSA) and that 
fails as well (furthermore, I have removed the detach calls and it does 
not segfault)). It has proved difficult to track down (at least for me) 
because it does not happen when the call is made, detach returns and 
then some seconds (~ 30 seconds - 1 minute) later a segmentation fault 
occurrs. I have run it in the debugger and the backtrace is below. When 
I step through the code of do_detach it does not appear to be happening 
at any consistent location. I assume this means that some worker thread 
is involved, but the bactrace is not helpful (at least to me).

1.) Can I improve the backtrace message after the segfault to increase 
message potential.
2.) Can I set some breakpoints elsewhere which might be more instructive 
as I do not see much going on in do_detach? suggestions?

The library I am working with is in C and uses Nag, it uses the 
registration facilities, although I have the problem when I do not use 
the registration facilities. Specifically, I have defined the method: 
void R_init_DSA(DllInfo *info). However, as I said if I comment this out 
it appears to behave identically.

Also, I have run the whole test case using valgrind to see if I could 
track down the problem there (I assume I am trashing some of R's memory) 
however, the only messages I get from valgrind are below - all related 
to the registration code. It does not appear to seg fault when I run it 
in valgrind, but I have no idea why this would be the case as I am 
*very* new to valgrind.

I am a little out of my league here so any help would be greatly 
appreciated. OS and R version information is below. Thanks as always for 
all of the help.

thanks, jim

 > R.version
             
platform i686-pc-linux-gnu
arch     i686            
os       linux-gnu       
system   i686, linux-gnu 
status                   
major    2               
minor    2.0             
year     2005            
month    10              
day      06              
svn rev  35749           
language R               


(gdb) backtrace
#0  0xb71655d0 in ?? ()
#1  0x0872fc70 in ?? ()
#2  0x0872fc58 in ?? ()
#3  0xb69b7ab8 in ?? ()
#4  0xb71654d5 in ?? ()
#5  0x00000000 in ?? ()
#6  0x00000000 in ?? ()
#7  0x4399ca09 in ?? ()
#8  0x00000000 in ?? ()
#9  0x00000000 in ?? ()
#10 0x00000000 in ?? ()
#11 0x0872fc18 in ?? ()
#12 0x08ee0fe0 in ?? ()
#13 0x00000000 in ?? ()
#14 0xb69c5c30 in __JCR_LIST__ () from /lib/tls/i686/cmov/libpthread.so.0
#15 0xb69b7b4c in ?? ()
#16 0xb69bcae0 in start_thread () from /lib/tls/i686/cmov/libpthread.so.0
#17 0xb69bcae0 in start_thread () from /lib/tls/i686/cmov/libpthread.so.0
#18 0xb7d09c9a in clone () from /lib/tls/i686/cmov/libc.so.6

-------------------------------------------------------------------------------------------------------------------------------------------
------------------------- valgrind output, after detach(.) is called 
---------------------------------------------
-------------------------------------------------------------------------------------------------------------------------------------------
==20262== Conditional jump or move depends on uninitialised value(s)
==20262==    at 0x1B92D888: R_getDLLRegisteredSymbol (Rdynload.c:665)
==20262==    by 0x1B92D9C5: R_dlsym (Rdynload.c:735)
==20262==    by 0x1B92D0BD: R_callDLLUnload (Rdynload.c:412)
==20262==    by 0x1B92D15B: DeleteDLL (Rdynload.c:439)
==20262==
==20262== Conditional jump or move depends on uninitialised value(s)
==20262==    at 0x1B92D8D2: R_getDLLRegisteredSymbol (Rdynload.c:681)
==20262==    by 0x1B92D9C5: R_dlsym (Rdynload.c:735)
==20262==    by 0x1B92D0BD: R_callDLLUnload (Rdynload.c:412)
==20262==    by 0x1B92D15B: DeleteDLL (Rdynload.c:439)
==20262==
==20262== Conditional jump or move depends on uninitialised value(s)
==20262==    at 0x1B92D8D7: R_getDLLRegisteredSymbol (Rdynload.c:681)
==20262==    by 0x1B92D9C5: R_dlsym (Rdynload.c:735)
==20262==    by 0x1B92D0BD: R_callDLLUnload (Rdynload.c:412)
==20262==    by 0x1B92D15B: DeleteDLL (Rdynload.c:439)
==20262==
==20262== Conditional jump or move depends on uninitialised value(s)
==20262==    at 0x1B92D8DB: R_getDLLRegisteredSymbol (Rdynload.c:696)
==20262==    by 0x1B92D9C5: R_dlsym (Rdynload.c:735)
==20262==    by 0x1B92D0BD: R_callDLLUnload (Rdynload.c:412)
==20262==    by 0x1B92D15B: DeleteDLL (Rdynload.c:439)
==20262==
==20262== Conditional jump or move depends on uninitialised value(s)
==20262==    at 0x1B92D8E0: R_getDLLRegisteredSymbol (Rdynload.c:696)
==20262==    by 0x1B92D9C5: R_dlsym (Rdynload.c:735)
==20262==    by 0x1B92D0BD: R_callDLLUnload (Rdynload.c:412)
==20262==    by 0x1B92D15B: DeleteDLL (Rdynload.c:439)
==20262==
==20262== Conditional jump or move depends on uninitialised value(s)
==20262==    at 0x1B92D8E4: R_getDLLRegisteredSymbol (Rdynload.c:711)
==20262==    by 0x1B92D9C5: R_dlsym (Rdynload.c:735)
==20262==    by 0x1B92D0BD: R_callDLLUnload (Rdynload.c:412)
==20262==    by 0x1B92D15B: DeleteDLL (Rdynload.c:439)
==20262==
==20262== Conditional jump or move depends on uninitialised value(s)
==20262==    at 0x1B92D8E9: R_getDLLRegisteredSymbol (Rdynload.c:711)
==20262==    by 0x1B92D9C5: R_dlsym (Rdynload.c:735)
==20262==    by 0x1B92D0BD: R_callDLLUnload (Rdynload.c:412)
==20262==    by 0x1B92D15B: DeleteDLL (Rdynload.c:439)
==20262==
==20262== Conditional jump or move depends on uninitialised value(s)
==20262==    at 0x1B92DA11: R_dlsym (Rdynload.c:749)
==20262==    by 0x1B92D0BD: R_callDLLUnload (Rdynload.c:412)
==20262==    by 0x1B92D15B: DeleteDLL (Rdynload.c:439)
==20262==    by 0x1B92DD94: do_dynunload (Rdynload.c:863)


From duncan at wald.ucdavis.edu  Fri Dec  9 20:39:05 2005
From: duncan at wald.ucdavis.edu (Duncan Temple Lang)
Date: Fri, 09 Dec 2005 11:39:05 -0800
Subject: [Rd] segfault following a detach
In-Reply-To: <4399D89F.7050806@berkeley.edu>
References: <4399D89F.7050806@berkeley.edu>
Message-ID: <4399DD59.1060909@wald.ucdavis.edu>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1


Hi Jim,

 Can you send me a copy of the package and an R script
that causes the problem and I'll take a look at it.

 D.

James Bullard wrote:
> Hello, first off, thanks for all of the previous help; hopefully someone 
> will have some insight on this question. I am attempting to track down a 
> segmentation fault which occurs only after a detach(2) is called in the 
> code (I have replaced the detach(2) with detach(package:DSA) and that 
> fails as well (furthermore, I have removed the detach calls and it does 
> not segfault)). It has proved difficult to track down (at least for me) 
> because it does not happen when the call is made, detach returns and 
> then some seconds (~ 30 seconds - 1 minute) later a segmentation fault 
> occurrs. I have run it in the debugger and the backtrace is below. When 
> I step through the code of do_detach it does not appear to be happening 
> at any consistent location. I assume this means that some worker thread 
> is involved, but the bactrace is not helpful (at least to me).
> 
> 1.) Can I improve the backtrace message after the segfault to increase 
> message potential.
> 2.) Can I set some breakpoints elsewhere which might be more instructive 
> as I do not see much going on in do_detach? suggestions?
> 
> The library I am working with is in C and uses Nag, it uses the 
> registration facilities, although I have the problem when I do not use 
> the registration facilities. Specifically, I have defined the method: 
> void R_init_DSA(DllInfo *info). However, as I said if I comment this out 
> it appears to behave identically.
> 
> Also, I have run the whole test case using valgrind to see if I could 
> track down the problem there (I assume I am trashing some of R's memory) 
> however, the only messages I get from valgrind are below - all related 
> to the registration code. It does not appear to seg fault when I run it 
> in valgrind, but I have no idea why this would be the case as I am 
> *very* new to valgrind.
> 
> I am a little out of my league here so any help would be greatly 
> appreciated. OS and R version information is below. Thanks as always for 
> all of the help.
> 
> thanks, jim
> 
>  > R.version
>              
> platform i686-pc-linux-gnu
> arch     i686            
> os       linux-gnu       
> system   i686, linux-gnu 
> status                   
> major    2               
> minor    2.0             
> year     2005            
> month    10              
> day      06              
> svn rev  35749           
> language R               
> 
> 
> (gdb) backtrace
> #0  0xb71655d0 in ?? ()
> #1  0x0872fc70 in ?? ()
> #2  0x0872fc58 in ?? ()
> #3  0xb69b7ab8 in ?? ()
> #4  0xb71654d5 in ?? ()
> #5  0x00000000 in ?? ()
> #6  0x00000000 in ?? ()
> #7  0x4399ca09 in ?? ()
> #8  0x00000000 in ?? ()
> #9  0x00000000 in ?? ()
> #10 0x00000000 in ?? ()
> #11 0x0872fc18 in ?? ()
> #12 0x08ee0fe0 in ?? ()
> #13 0x00000000 in ?? ()
> #14 0xb69c5c30 in __JCR_LIST__ () from /lib/tls/i686/cmov/libpthread.so.0
> #15 0xb69b7b4c in ?? ()
> #16 0xb69bcae0 in start_thread () from /lib/tls/i686/cmov/libpthread.so.0
> #17 0xb69bcae0 in start_thread () from /lib/tls/i686/cmov/libpthread.so.0
> #18 0xb7d09c9a in clone () from /lib/tls/i686/cmov/libc.so.6
> 
> -------------------------------------------------------------------------------------------------------------------------------------------
> ------------------------- valgrind output, after detach(.) is called 
> ---------------------------------------------
> -------------------------------------------------------------------------------------------------------------------------------------------
> ==20262== Conditional jump or move depends on uninitialised value(s)
> ==20262==    at 0x1B92D888: R_getDLLRegisteredSymbol (Rdynload.c:665)
> ==20262==    by 0x1B92D9C5: R_dlsym (Rdynload.c:735)
> ==20262==    by 0x1B92D0BD: R_callDLLUnload (Rdynload.c:412)
> ==20262==    by 0x1B92D15B: DeleteDLL (Rdynload.c:439)
> ==20262==
> ==20262== Conditional jump or move depends on uninitialised value(s)
> ==20262==    at 0x1B92D8D2: R_getDLLRegisteredSymbol (Rdynload.c:681)
> ==20262==    by 0x1B92D9C5: R_dlsym (Rdynload.c:735)
> ==20262==    by 0x1B92D0BD: R_callDLLUnload (Rdynload.c:412)
> ==20262==    by 0x1B92D15B: DeleteDLL (Rdynload.c:439)
> ==20262==
> ==20262== Conditional jump or move depends on uninitialised value(s)
> ==20262==    at 0x1B92D8D7: R_getDLLRegisteredSymbol (Rdynload.c:681)
> ==20262==    by 0x1B92D9C5: R_dlsym (Rdynload.c:735)
> ==20262==    by 0x1B92D0BD: R_callDLLUnload (Rdynload.c:412)
> ==20262==    by 0x1B92D15B: DeleteDLL (Rdynload.c:439)
> ==20262==
> ==20262== Conditional jump or move depends on uninitialised value(s)
> ==20262==    at 0x1B92D8DB: R_getDLLRegisteredSymbol (Rdynload.c:696)
> ==20262==    by 0x1B92D9C5: R_dlsym (Rdynload.c:735)
> ==20262==    by 0x1B92D0BD: R_callDLLUnload (Rdynload.c:412)
> ==20262==    by 0x1B92D15B: DeleteDLL (Rdynload.c:439)
> ==20262==
> ==20262== Conditional jump or move depends on uninitialised value(s)
> ==20262==    at 0x1B92D8E0: R_getDLLRegisteredSymbol (Rdynload.c:696)
> ==20262==    by 0x1B92D9C5: R_dlsym (Rdynload.c:735)
> ==20262==    by 0x1B92D0BD: R_callDLLUnload (Rdynload.c:412)
> ==20262==    by 0x1B92D15B: DeleteDLL (Rdynload.c:439)
> ==20262==
> ==20262== Conditional jump or move depends on uninitialised value(s)
> ==20262==    at 0x1B92D8E4: R_getDLLRegisteredSymbol (Rdynload.c:711)
> ==20262==    by 0x1B92D9C5: R_dlsym (Rdynload.c:735)
> ==20262==    by 0x1B92D0BD: R_callDLLUnload (Rdynload.c:412)
> ==20262==    by 0x1B92D15B: DeleteDLL (Rdynload.c:439)
> ==20262==
> ==20262== Conditional jump or move depends on uninitialised value(s)
> ==20262==    at 0x1B92D8E9: R_getDLLRegisteredSymbol (Rdynload.c:711)
> ==20262==    by 0x1B92D9C5: R_dlsym (Rdynload.c:735)
> ==20262==    by 0x1B92D0BD: R_callDLLUnload (Rdynload.c:412)
> ==20262==    by 0x1B92D15B: DeleteDLL (Rdynload.c:439)
> ==20262==
> ==20262== Conditional jump or move depends on uninitialised value(s)
> ==20262==    at 0x1B92DA11: R_dlsym (Rdynload.c:749)
> ==20262==    by 0x1B92D0BD: R_callDLLUnload (Rdynload.c:412)
> ==20262==    by 0x1B92D15B: DeleteDLL (Rdynload.c:439)
> ==20262==    by 0x1B92DD94: do_dynunload (Rdynload.c:863)
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

- --
Duncan Temple Lang                duncan at wald.ucdavis.edu
Department of Statistics          work:  (530) 752-4782
371 Kerr Hall                     fax:   (530) 752-7099
One Shields Ave.
University of California at Davis
Davis, CA 95616, USA
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.2 (Darwin)

iD8DBQFDmd1Z9p/Jzwa2QP4RAlsUAJ9C2NyYwUPQW3WkRf4TpRANoKhv0ACfSMxi
TKpfiZg0JFYhFOPqvc67Bc4=
=5eTz
-----END PGP SIGNATURE-----


From izmirlig at mail.nih.gov  Fri Dec  9 21:14:13 2005
From: izmirlig at mail.nih.gov (Izmirlian, Grant (NIH/NCI) [E])
Date: Fri, 9 Dec 2005 15:14:13 -0500
Subject: [Rd] an Update on the "Woods" package--classification and
	constrained L1 regression for binary response
Message-ID: <CE0E73903DB53F43B4B0938747F34F8A01242CDD@nihexchange7.nih.gov>

Hello R-devel:

This is an update on my R package, "woods" that does bagged classification trees
using data structures in C. Most of the comments of my earlier post still
apply, with some additions (noted *)

    (i) fits a single classification tree to dataset (R function CT)
   (ii) basic functionality of Random Forest, e.g. bagged trees with choices
        about sample size, with/without replacement, size of (random) subset
        of covariates drawn when nodes are split.  Result contains the oob votes,
        and a matrix representing the forest structure.
 *(iii) for each element of the sample, discovers all unique paths from a root node to 
        a terminal node as a sequence of splits on covariates and uses these to fit
        a lasso regresssion to the binary response using a full c-implementation of
        the Turlach lasso2 function gl1ce.

It is now available at http://mysite.verizon.net/izmirlian/woods_1.00.tar.gz


Grant Izmirlian
NCI


From patrick at burns-stat.com  Fri Dec  9 21:34:56 2005
From: patrick at burns-stat.com (Patrick Burns)
Date: Fri, 09 Dec 2005 20:34:56 +0000
Subject: [Rd] weights in nls
Message-ID: <4399EA70.5040000@burns-stat.com>

It would probably be more polite to give a warning
in 'nls' that the 'weights' argument is ignored.  Something
like the following should do:

if(missing(weights)) warning("weights are not currently implemented")

 > version
         _                          
platform i386-pc-mingw32            
arch     i386                       
os       mingw32                    
system   i386, mingw32              
status   Under development (unstable)
major    2                          
minor    3.0                        
year     2005                       
month    12                         
day      07                         
svn rev  36656                      
language R                 


Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")


From ross at biostat.ucsf.edu  Sat Dec 10 00:04:28 2005
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Fri, 09 Dec 2005 15:04:28 -0800
Subject: [Rd] external pointers
Message-ID: <1134169468.10966.56.camel@iron.psg.net>

I have some C data I want to pass back to R opaquely, and then back to
C.  I understand external pointers are the way to do so.

I'm trying to find how they interact with garbage collection and object
lifetime, and what I need to do so that the memory lives until the
calling R process ends.

Could anyone give me some pointers?  I haven't found much documentation.
An earlier message suggested looking at simpleref.nw, but I can't find
that file.

So the overall pattern, from R, would look like
opaque <- setup(arg1, arg2, ....)  # setup calls a C fn
docompute(arg1, argb, opaque)  # many times. docompute also calls C
# and then when I return opaque and  the memory it's wrapping get
#cleaned up.  If necessary I could do
teardown(opaque)  # at the end

"C" is actually C++ via a C interface, if that matters.  In particular,
the memory allocated will likely be from the C++ run-time, and needs C++
destructors.

-- 
Ross Boylan                                      wk:  (415) 514-8146
185 Berry St #5700                               ross at biostat.ucsf.edu
Dept of Epidemiology and Biostatistics           fax: (415) 514-8150
University of California, San Francisco
San Francisco, CA 94107-1739                     hm:  (415) 550-1062


From ellis at stat.harvard.edu  Sat Dec 10 01:23:55 2005
From: ellis at stat.harvard.edu (Byron Ellis)
Date: Fri, 9 Dec 2005 16:23:55 -0800
Subject: [Rd] external pointers
In-Reply-To: <1134169468.10966.56.camel@iron.psg.net>
References: <1134169468.10966.56.camel@iron.psg.net>
Message-ID: <B91129D0-D505-4D2F-A5A7-D6DBE9E98CBB@stat.harvard.edu>

use a C finalizer...

void MyObject_finalize(SEXP opaque) {
	MyObject *obj = (MyObject*)R_ExternalPtrAddr(opaque);
	if(NULL != obj) delete obj;
}

and in your setup code...

PROTECT(p = R_MakeExternalPtr(...));
R_RegisterCFinalizer(p,MyObject_finalize);






On Dec 9, 2005, at 3:04 PM, Ross Boylan wrote:

> I have some C data I want to pass back to R opaquely, and then back to
> C.  I understand external pointers are the way to do so.
>
> I'm trying to find how they interact with garbage collection and  
> object
> lifetime, and what I need to do so that the memory lives until the
> calling R process ends.
>
> Could anyone give me some pointers?  I haven't found much  
> documentation.
> An earlier message suggested looking at simpleref.nw, but I can't find
> that file.
>
> So the overall pattern, from R, would look like
> opaque <- setup(arg1, arg2, ....)  # setup calls a C fn
> docompute(arg1, argb, opaque)  # many times. docompute also calls C
> # and then when I return opaque and  the memory it's wrapping get
> #cleaned up.  If necessary I could do
> teardown(opaque)  # at the end
>
> "C" is actually C++ via a C interface, if that matters.  In  
> particular,
> the memory allocated will likely be from the C++ run-time, and  
> needs C++
> destructors.
>
> -- 
> Ross Boylan                                      wk:  (415) 514-8146
> 185 Berry St #5700                               ross at biostat.ucsf.edu
> Dept of Epidemiology and Biostatistics           fax: (415) 514-8150
> University of California, San Francisco
> San Francisco, CA 94107-1739                     hm:  (415) 550-1062
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

---
Byron Ellis (ellis at stat.harvard.edu)
"Oook" -- The Librarian


From izmirlig at mail.nih.gov  Sat Dec 10 01:28:34 2005
From: izmirlig at mail.nih.gov (Izmirlian, Grant (NIH/NCI) [E])
Date: Fri, 9 Dec 2005 19:28:34 -0500
Subject: [Rd] segfault following a detach
Message-ID: <CE0E73903DB53F43B4B0938747F34F8A01242CDF@nihexchange7.nih.gov>

Jim:

This reminds me of problems I've had before, but usually they occur when I quit R
i.e. q(), because when testing and developing I can't remember actually detaching
a package. I can however think of countless times I get a segmentation fault upon 
quiting R. Usually this boils down to a hidden return argumen that is given an
insufficient allocation of memory. For example

  "foo" <- function(x, y, z){
     nx <- length(x)
     ny <- length(y)
     nz <- length(z)
     ans <- .C("bar",
            x = as.double(x),
            y = as.double(y),
            z = as.double(z),
            res1 = as.double(rep(0, nx)),
            res2 = as.double(rep(0, nx*ny)),
            PACKAGE = "FooBar")
     list(result = asn$res1)
}

Notice that only ans$res1 is returned so that it is easy to forget about ans$res2, 
as I have often done! Now suppose that the C routine actually needs nx*ny*nz space 
(say) for the pointer to double at the position indicated by res2 instead of just 
the nx*ny provided. Although you would expect a segmentation fault at runtime, it 
is my experience that sometimes the function completes and the segmentation fault 
doesn't happen until I quit R.

I hope that these comments are helpful,

Grant Izmirlian,
NCI


From ellis at stat.harvard.edu  Sat Dec 10 06:58:21 2005
From: ellis at stat.harvard.edu (Byron Ellis)
Date: Fri, 9 Dec 2005 21:58:21 -0800
Subject: [Rd] segfault following a detach
In-Reply-To: <CE0E73903DB53F43B4B0938747F34F8A01242CDF@nihexchange7.nih.gov>
References: <CE0E73903DB53F43B4B0938747F34F8A01242CDF@nihexchange7.nih.gov>
Message-ID: <EFCA9526-1C2A-4BD7-8C65-DFE48BCA1484@stat.harvard.edu>

That sounds like your C function is smashing some of the header  
information in a chunk of memory somewhere past res2 so that cleanup  
during quit fails.

On Dec 9, 2005, at 4:28 PM, Izmirlian, Grant (NIH/NCI) [E] wrote:

> Jim:
>
> This reminds me of problems I've had before, but usually they occur  
> when I quit R
> i.e. q(), because when testing and developing I can't remember  
> actually detaching
> a package. I can however think of countless times I get a  
> segmentation fault upon
> quiting R. Usually this boils down to a hidden return argumen that  
> is given an
> insufficient allocation of memory. For example
>
>   "foo" <- function(x, y, z){
>      nx <- length(x)
>      ny <- length(y)
>      nz <- length(z)
>      ans <- .C("bar",
>             x = as.double(x),
>             y = as.double(y),
>             z = as.double(z),
>             res1 = as.double(rep(0, nx)),
>             res2 = as.double(rep(0, nx*ny)),
>             PACKAGE = "FooBar")
>      list(result = asn$res1)
> }
>
> Notice that only ans$res1 is returned so that it is easy to forget  
> about ans$res2,
> as I have often done! Now suppose that the C routine actually needs  
> nx*ny*nz space
> (say) for the pointer to double at the position indicated by res2  
> instead of just
> the nx*ny provided. Although you would expect a segmentation fault  
> at runtime, it
> is my experience that sometimes the function completes and the  
> segmentation fault
> doesn't happen until I quit R.
>
> I hope that these comments are helpful,
>
> Grant Izmirlian,
> NCI
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

---
Byron Ellis (ellis at stat.harvard.edu)
"Oook" -- The Librarian


From clausen at econ.upenn.edu  Sun Dec 11 01:03:48 2005
From: clausen at econ.upenn.edu (clausen@econ.upenn.edu)
Date: Sun, 11 Dec 2005 01:03:48 +0100 (CET)
Subject: [Rd] inconsistency between plot(hist(...)) and hist(...) (PR#8376)
Message-ID: <20051211000348.4F155E7BB@slim.kubism.ku.dk>

Full_Name: Andrew Clausen
Version: 2.1.0
OS: Debian GNU/Linux
Submission from: (NULL) (71.242.192.73)


Hi,

When I type

    hist(x, freq=F)

I get a density function, as I expect.  However, if I type

    plot(hist(x, freq=F))

then I get the same output as if I had typed:

    hist(x, freq=T)

I expect that the second command should have the same semantics as the first.

Cheers,
Andrew


From ripley at stats.ox.ac.uk  Sun Dec 11 05:35:07 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Sun, 11 Dec 2005 05:35:07 +0100 (CET)
Subject: [Rd] (PR#8376 inconsistency between plot(hist(...)) and
	hist(...)
Message-ID: <20051211043507.41A4A15AA7@slim.kubism.ku.dk>

On Sun, 11 Dec 2005 clausen at econ.upenn.edu wrote:

> Full_Name: Andrew Clausen
> Version: 2.1.0
> OS: Debian GNU/Linux
> Submission from: (NULL) (71.242.192.73)
>
>
> Hi,
>
> When I type
>
>    hist(x, freq=F)
>
> I get a density function, as I expect.  However, if I type
>
>    plot(hist(x, freq=F))
>
> then I get the same output as if I had typed:
>
>    hist(x, freq=T)
>
> I expect that the second command should have the same semantics as the first.

And it actually does, but your usage does not.

Did you check the help page?  ?plot.histogram shows plot.histogram has a 
'freq' argument, and the correct usage is

plot(hist(x), freq=FALSE)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From clausen at econ.upenn.edu  Sun Dec 11 08:40:01 2005
From: clausen at econ.upenn.edu (clausen@econ.upenn.edu)
Date: Sun, 11 Dec 2005 08:40:01 +0100 (CET)
Subject: [Rd] (PR#8376 inconsistency between plot(hist(...)) and
	hist(...)
Message-ID: <20051211074001.C7AFB15AA7@slim.kubism.ku.dk>

Hi Brian,

On Sun, Dec 11, 2005 at 04:34:50AM +0000, Prof Brian Ripley wrote:
> Did you check the help page?  ?plot.histogram shows plot.histogram has a 
> 'freq' argument, and the correct usage is
> 
> plot(hist(x), freq=FALSE)

Ah, thanks for the explanation.

I didn't occur to me to check the plot.histogram() help page.  Besides,
even if I had read it, I still don't think the semantics would have been
clear to me without additional experimentation.

Perhaps it might be helpful to document in the hist() help page which
attributes are stored in the hist() object.  Alternatively/additionally, 
hist() could emit a warning or error if plot=FALSE and irrelevant
(non-stored) attributes are set.

Cheers,
Andrew


From Mark.Bravington at csiro.au  Sun Dec 11 23:48:21 2005
From: Mark.Bravington at csiro.au (Mark.Bravington@csiro.au)
Date: Mon, 12 Dec 2005 09:48:21 +1100
Subject: [Rd] external pointers
Message-ID: <D79013E40FEF254AAF0D72DFC94F274803D957@extas4-hba.tas.csiro.au>

I don't entirely follow Ross's outline below (?how does the R object
'opaque' get to feature in the call to 'docompute'?), but I have written
large amounts of R-linked Delphi code with persistent Delphi objects,
using only the '.C' interface and no external pointers. You might find
this useful if you want to avoid the complexities of '.Call' and SEXPs
etc. NB the C/Delphi distincition is not important here.

(i)The first '.C' call uses Delphi code to allocate (using Delphi's own
memory manager) and set up a persistent object that R doesn't know
about. The Delphi code then returns an "opaque" integer-valued handle to
R, which is the address of the object in the Delphi DLL's world.

(ii) For subsequent '.C' calls to Delphi from R, I pass in the handle,
which I then typecast to an object pointer inside Delphi. Hence I can
"find" the persistent object. This way there can be several persistent
objects simultaneously-- I'm not limited to global variables in the
Delphi DLL.

(iii) There is a final cleanup '.C' call which deallocates the
persistent object. I sometimes also automate the destruction in the
cleanup code of the DLL, just in case the R user forgets to cleanup. 

I have also gotten this to work after replacing Delphi's memory manager
with R's own-- there was no difference (but apparently no point either,
from what I've been told).

There are some further notes inside a PDF on Duncan Murdoch's page:

http://www.stats.uwo.ca/faculty/murdoch/software/compilingDLLs/pascal.ht
ml

The notes are very Delphi-flavoured (and refer to S not R, since I've
used the method both with S-plus and R) but the point should-- or
might-- be clear.

HTH

Mark

Mark Bravington
CSIRO Mathematical & Information Sciences
Marine Laboratory
Castray Esplanade
Hobart 7001
TAS

ph (+61) 3 6232 5118
fax (+61) 3 6232 5012
mob (+61) 438 315 623
 

> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org] On Behalf Of Byron Ellis
> Sent: Saturday, 10 December 2005 11:24 AM
> To: Ross Boylan
> Cc: R Development List
> Subject: Re: [Rd] external pointers
> 
> use a C finalizer...
> 
> void MyObject_finalize(SEXP opaque) {
> 	MyObject *obj = (MyObject*)R_ExternalPtrAddr(opaque);
> 	if(NULL != obj) delete obj;
> }
> 
> and in your setup code...
> 
> PROTECT(p = R_MakeExternalPtr(...));
> R_RegisterCFinalizer(p,MyObject_finalize);
> 
> 
> 
> 
> 
> 
> On Dec 9, 2005, at 3:04 PM, Ross Boylan wrote:
> 
> > I have some C data I want to pass back to R opaquely, and 
> then back to 
> > C.  I understand external pointers are the way to do so.
> >
> > I'm trying to find how they interact with garbage collection and 
> > object lifetime, and what I need to do so that the memory 
> lives until 
> > the calling R process ends.
> >
> > Could anyone give me some pointers?  I haven't found much 
> > documentation.
> > An earlier message suggested looking at simpleref.nw, but I 
> can't find 
> > that file.
> >
> > So the overall pattern, from R, would look like opaque <- 
> setup(arg1, 
> > arg2, ....)  # setup calls a C fn docompute(arg1, argb, opaque)  # 
> > many times. docompute also calls C # and then when I return 
> opaque and  
> > the memory it's wrapping get #cleaned up.  If necessary I could do
> > teardown(opaque)  # at the end
> >
> > "C" is actually C++ via a C interface, if that matters.  In 
> > particular, the memory allocated will likely be from the 
> C++ run-time, 
> > and needs C++ destructors.
> >
> > -- 
> > Ross Boylan                                      wk:  (415) 514-8146
> > 185 Berry St #5700                               
> ross at biostat.ucsf.edu
> > Dept of Epidemiology and Biostatistics           fax: (415) 514-8150
> > University of California, San Francisco
> > San Francisco, CA 94107-1739                     hm:  (415) 550-1062
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ---
> Byron Ellis (ellis at stat.harvard.edu)
> "Oook" -- The Librarian
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From simon.urbanek at r-project.org  Mon Dec 12 05:38:54 2005
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 12 Dec 2005 13:38:54 +0900
Subject: [Rd] external pointers
In-Reply-To: <D79013E40FEF254AAF0D72DFC94F274803D957@extas4-hba.tas.csiro.au>
References: <D79013E40FEF254AAF0D72DFC94F274803D957@extas4-hba.tas.csiro.au>
Message-ID: <1DA96B7D-F52C-49AB-A109-9186E3E694C7@r-project.org>

Mark,

On Dec 12, 2005, at 7:48 AM, <Mark.Bravington at csiro.au> wrote:

> (i)The first '.C' call uses Delphi code to allocate (using Delphi's  
> own memory manager) and set up a persistent object that R doesn't  
> know about. The Delphi code then returns an "opaque" integer-valued  
> handle to R, which is the address of the object in the Delphi DLL's  
> world.

That's a bad idea for a couple of reasons, the main being that  
integer is not guaranteed to be able to hold a pointer - it won't  
work on any 64-bit platform. Second drawback is that you have no way  
to link the life of the R object to your Delphi object, because there  
is no way gc will tell you that the object is gone. This will lead to  
memory leaks. [Been there, done that ;)] Both issues are solved by  
the external pointers.

> (iii) There is a final cleanup '.C' call which deallocates the  
> persistent object. I sometimes also automate the destruction in the  
> cleanup code of the DLL, just in case the R user forgets to cleanup.

How do you make sure the no one uses the now invalid integer value?  
There can be many copies of your proxy object around and they all  
point to nirvana ...

Cheers,
Simon


From Mark.Bravington at csiro.au  Mon Dec 12 08:37:54 2005
From: Mark.Bravington at csiro.au (Mark.Bravington@csiro.au)
Date: Mon, 12 Dec 2005 18:37:54 +1100
Subject: [Rd] external pointers
Message-ID: <D79013E40FEF254AAF0D72DFC94F274803D95C@extas4-hba.tas.csiro.au>

Hi Simon

Thanks for that... see below for my feeble counterblasts! (And two
questions.)

> Mark,
> 
> On Dec 12, 2005, at 7:48 AM, <Mark.Bravington at csiro.au> wrote:
> 
> > (i)The first '.C' call uses Delphi code to allocate (using Delphi's 
> > own memory manager) and set up a persistent object that R 
> doesn't know 
> > about. The Delphi code then returns an "opaque" 
> integer-valued handle 
> > to R, which is the address of the object in the Delphi DLL's world.
> 
> That's a bad idea for a couple of reasons, the main being 
> that integer is not guaranteed to be able to hold a pointer - 
> it won't work on any 64-bit platform. 

Very true, though 64 bit systems are not a big worry for Delphi 6.0
writers... ;) I did once speculate about hacking around this sort of
thing by encoding into character strings instead of integers, uggg.

> Second drawback is that 
> you have no way to link the life of the R object to your 
> Delphi object, because there is no way gc will tell you that 
> the object is gone. This will lead to memory leaks. [Been 
> there, done that ;)] Both issues are solved by the external pointers.

> 
> > (iii) There is a final cleanup '.C' call which deallocates the 
> > persistent object. I sometimes also automate the destruction in the 
> > cleanup code of the DLL, just in case the R user forgets to cleanup.
> 
> How do you make sure the no one uses the now invalid integer value?  
> There can be many copies of your proxy object around and they 
> all point to nirvana ...

Sorry, that was lack of clarity on my part about what I meant by
"persistent". Whenever I use this mechanism, I'm careful to ensure that
the C/Delphi objects only have lifetimes *within* a function, and to
include an 'on.exit' call to the "destructor"-- I would never  create
global objects pointing to ephemeral C structures. Admittedly, this
relies on programming self-discipline, and has no cast-iron anti-nirvana
mechanism! Ross' original query seems very much along these lines,
though.

If I was really creating global persistent objects, then 'externalptr'
would definitely be much better.

Where would be best to read about externalptr? I'm having trouble
finding material in the manuals or the site-search.

And would I need to use all the .Call machinery and C headers and SEXP
etc in order to handle externalptr objects?

> 
> Cheers,
> Simon

bye
Mark


From Roger.Bivand at nhh.no  Mon Dec 12 08:54:49 2005
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 12 Dec 2005 08:54:49 +0100 (CET)
Subject: [Rd] external pointers
In-Reply-To: <D79013E40FEF254AAF0D72DFC94F274803D95C@extas4-hba.tas.csiro.au>
Message-ID: <Pine.LNX.4.44.0512120849200.26218-100000@reclus.nhh.no>

On Mon, 12 Dec 2005 Mark.Bravington at csiro.au wrote:

> Hi Simon
> 
> Thanks for that... see below for my feeble counterblasts! (And two
> questions.)
> 
> > Mark,
> > 
> > On Dec 12, 2005, at 7:48 AM, <Mark.Bravington at csiro.au> wrote:
> > 
> > > (i)The first '.C' call uses Delphi code to allocate (using Delphi's 
> > > own memory manager) and set up a persistent object that R 
> > doesn't know 
> > > about. The Delphi code then returns an "opaque" 
> > integer-valued handle 
> > > to R, which is the address of the object in the Delphi DLL's world.
> > 
> > That's a bad idea for a couple of reasons, the main being 
> > that integer is not guaranteed to be able to hold a pointer - 
> > it won't work on any 64-bit platform. 
> 
> Very true, though 64 bit systems are not a big worry for Delphi 6.0
> writers... ;) I did once speculate about hacking around this sort of
> thing by encoding into character strings instead of integers, uggg.
> 
> > Second drawback is that 
> > you have no way to link the life of the R object to your 
> > Delphi object, because there is no way gc will tell you that 
> > the object is gone. This will lead to memory leaks. [Been 
> > there, done that ;)] Both issues are solved by the external pointers.
> 
> > 
> > > (iii) There is a final cleanup '.C' call which deallocates the 
> > > persistent object. I sometimes also automate the destruction in the 
> > > cleanup code of the DLL, just in case the R user forgets to cleanup.
> > 
> > How do you make sure the no one uses the now invalid integer value?  
> > There can be many copies of your proxy object around and they 
> > all point to nirvana ...
> 
> Sorry, that was lack of clarity on my part about what I meant by
> "persistent". Whenever I use this mechanism, I'm careful to ensure that
> the C/Delphi objects only have lifetimes *within* a function, and to
> include an 'on.exit' call to the "destructor"-- I would never  create
> global objects pointing to ephemeral C structures. Admittedly, this
> relies on programming self-discipline, and has no cast-iron anti-nirvana
> mechanism! Ross' original query seems very much along these lines,
> though.
> 
> If I was really creating global persistent objects, then 'externalptr'
> would definitely be much better.
> 
> Where would be best to read about externalptr? I'm having trouble
> finding material in the manuals or the site-search.
> 
> And would I need to use all the .Call machinery and C headers and SEXP
> etc in order to handle externalptr objects?

One package using externalptr is rgdal - Tim Keitt wrote the bindings to
the external GDAL library for reading raster images to first return a
pointer to a dataset (on disk) opened by GDAL, then to use the object to
retrieve (parts of) the data. Most of the .Call/SEXP machinery is there
(for the C++ case, GDAL is C++, so GDAL manages its own memory for its
objects). The package also uses S4 classes, which may be overkill for your
purposes.

Roger

> 
> > 
> > Cheers,
> > Simon
> 
> bye
> Mark
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From ripley at stats.ox.ac.uk  Mon Dec 12 09:16:55 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 12 Dec 2005 08:16:55 +0000 (GMT)
Subject: [Rd] external pointers
In-Reply-To: <Pine.LNX.4.44.0512120849200.26218-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0512120849200.26218-100000@reclus.nhh.no>
Message-ID: <Pine.LNX.4.61.0512120812060.4551@gannet.stats>

On Mon, 12 Dec 2005, Roger Bivand wrote:

>> Where would be best to read about externalptr? I'm having trouble
>> finding material in the manuals or the site-search.
>>
>> And would I need to use all the .Call machinery and C headers and SEXP
>> etc in order to handle externalptr objects?
>
> One package using externalptr is rgdal - Tim Keitt wrote the bindings to
> the external GDAL library for reading raster images to first return a
> pointer to a dataset (on disk) opened by GDAL, then to use the object to
> retrieve (parts of) the data. Most of the .Call/SEXP machinery is there
> (for the C++ case, GDAL is C++, so GDAL manages its own memory for its
> objects). The package also uses S4 classes, which may be overkill for your
> purposes.

RODBC is another, somewhat simpler, one.

There is documentation on developer.r-project.org, but my recollection is 
that is was not up to date (and in particular not re finalizers).  On my 
TODO list is to add end-user documentation to `Writing R Extensions'.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Mon Dec 12 12:20:06 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 12 Dec 2005 12:20:06 +0100
Subject: [Rd] extension to missing()? {was "hist() ... helpful warning?
	(PR#8376)"}
In-Reply-To: <20051211074001.C7AFB15AA7@slim.kubism.ku.dk>
References: <20051211074001.C7AFB15AA7@slim.kubism.ku.dk>
Message-ID: <17309.23782.691038.586796@stat.math.ethz.ch>

       [taken off R-bugs as a non-bug]

>>>>> "AndrewC" == clausen  <clausen at econ.upenn.edu>
>>>>>     on Sun, 11 Dec 2005 08:40:01 +0100 (CET) writes:

    AndrewC> Hi Brian,
    AndrewC> On Sun, Dec 11, 2005 at 04:34:50AM +0000, Prof Brian Ripley wrote:
    >> Did you check the help page?  ?plot.histogram shows plot.histogram has a 
    >> 'freq' argument, and the correct usage is
    >> 
    >> plot(hist(x), freq=FALSE)

    AndrewC> Ah, thanks for the explanation.

    AndrewC> I didn't occur to me to check the plot.histogram()
    AndrewC> help page.  

[ even though it's prominently mentioned on  help(hist)  ?? ]

    AndrewC> Besides, even if I had read it, I still don't think
    AndrewC> the semantics would have been clear to me without
    AndrewC> additional experimentation.

    AndrewC> Perhaps it might be helpful to document in the
    AndrewC> hist() help page which attributes are stored in the
    AndrewC> hist() object.  
you mean the 'histogram' object.

Yes, that might be helpful; diffs against
  https://svn.R-project.org/R/trunk/src/library/graphics/man/hist.Rd
are welcome.

    AndrewC> Alternatively/additionally, hist()
    AndrewC> could emit a warning or error if plot=FALSE and
    AndrewC> irrelevant (non-stored) attributes are set.

interesting proposal.
I've looked at it for a bit, and found that it seems not to be
doable both easily and elegantly, at least not along the first
line I've tried, and so I think it raises a slightly more
general somewhat interesting problem:

Since *most* arguments of hist.default, including '...' are only
made use of when plot = TRUE, and the code with the warning would
have to look at all of them, and we want to have a nicely
maintainable solution, I had wanted to have a solution which
looks at {almost} all formals() and which of them are missing().
Since formals() is a list,
    is.miss <- lapply(formals(), missing)
was the one I've tried but failed with
 Error in lapply(fm, missing) : 2 arguments passed to 'missing' which requires 1

which might be a bit astonishing {missing is Primitive though..}
and of course
    is.miss <- lapply(formals(), function(n) missing(n))
``works'' but trivially {why ?} and hence not usefully.

I've needed to make use of eval and substitute in order to make
use of missing() here.
Hence, I'm wondering if we maybe could generalize missing()
by something like   missing(all.formals = TRUE)  {or better syntax}
which would make the following a bit easier.

Here's a context diff of my working version of hist.default()
which implements the above proposal:

--- hist.R	(Revision 36695)
+++ hist.R	(working copy)
@@ -108,7 +108,19 @@
 	     axes = axes, labels = labels, ...)
 	invisible(r)
     }
-    else r
+    else { ## plot is FALSE
+        nf <- names(formals()) ## all formals but those 4:
+        nf <- nf[match(nf, c("x", "breaks", "nclass", "plot"), nomatch=0) == 0]
+        missE <- lapply(nf, function(n)
+                        substitute(missing(.), list(. = as.name(n))))
+        not.miss <- ! sapply(missE, eval, envir = environment())
+        if(any(not.miss))
+            warning(sprintf(ngettext(sum(not.miss),
+                                     "argument %s is not made use of",
+                                     "arguments %s are not made use of"),
+                            paste(sQuote(nf[not.miss]), collapse=", ")))
+        r
+    }
 }
 
 plot.histogram <-


From mdowle at concordiafunds.com  Mon Dec 12 12:34:31 2005
From: mdowle at concordiafunds.com (Matthew Dowle)
Date: Mon, 12 Dec 2005 11:34:31 -0000
Subject: [Rd] [R] data.frame() size
Message-ID: <78166BFC5165D811AA0400065BF0324BF07B36@wisconsin.concordia>


I guess the mail list precludes attachments then, makes sense. I have sent
the modified source directly to anyone who has asked.

I had a look at the light-weight data.frame class post
(http://tolstoy.newcastle.edu.au/R/devel/05/05/0837.html) :

> Now the transcript itself: 
> # the motivation: subscription of a data.frame is *much* (almost 20 
times) slower than that of a list 
> # compare 
> n = 1e6 
> i = seq(n) 
> x = data.frame(a=seq(n), b=seq(n)) 
> system.time(x[i,], gcFirst=TRUE) 
[1] 1.01 0.14 1.14 0.00 0.00 
> 
> x = list(a=seq(n), b=seq(n)) 
> system.time(lapply(x, function(col) col[i]), gcFirst=TRUE) 
[1] 0.06 0.00 0.06 0.00 0.00 
> 
> # the solution: define methods for the light-weight data.frame class 
> lwdf = function(...) structure(list(...), class = "lwdf") 
> ...

But if I have understood correctly I think the time difference here is just
down to the rownames. The rownames are 1:n stored in character form. This
takes the most time and space in this example, but are never used. I'm not
sure why 1:n in character form would ever be useful in fact. Running the
example above with my modifications appears to fix the problem ie negligible
time difference. I needed to make a one line change to [.data.frame, and
I've sent that to anyone who requested the code.

I can see the problem :

> apropos("data.frame")
 [1] "[.data.frame"                  "as.matrix.data.frame"
"data.frame"                    "dim.data.frame"               
 [5] "format.data.frame"             "print.data.frame"
".__C__data.frame"              "aggregate.data.frame"         
 [9] "$<-.data.frame"                "Math.data.frame"
"Ops.data.frame"                "Summary.data.frame"           
[13] "[.data.frame"                  "[<-.data.frame"
"[[.data.frame"                 "[[<-.data.frame"              
[17] "as.data.frame"                 "as.data.frame.AsIs"
"as.data.frame.Date"            "as.data.frame.POSIXct"        
[21] "as.data.frame.POSIXlt"         "as.data.frame.array"
"as.data.frame.character"       "as.data.frame.complex"        
[25] "as.data.frame.data.frame"      "as.data.frame.default"
"as.data.frame.factor"          "as.data.frame.integer"        
[29] "as.data.frame.list"            "as.data.frame.logical"
"as.data.frame.matrix"          "as.data.frame.model.matrix"   
[33] "as.data.frame.numeric"         "as.data.frame.ordered"
"as.data.frame.package_version" "as.data.frame.raw"            
[37] "as.data.frame.table"           "as.data.frame.ts"
"as.data.frame.vector"          "as.list.data.frame"           
[41] "as.matrix.data.frame"          "by.data.frame"
"cbind.data.frame"              "data.frame"                   
[45] "dim.data.frame"                "dimnames.data.frame"
"dimnames<-.data.frame"         "duplicated.data.frame"        
[49] "format.data.frame"             "is.data.frame"
"is.na.data.frame"              "mean.data.frame"              
[53] "merge.data.frame"              "print.data.frame"
"rbind.data.frame"              "row.names.data.frame"         
[57] "row.names<-.data.frame"        "rowsum.data.frame"
"split.data.frame"              "split<-.data.frame"           
[61] "stack.data.frame"              "subset.data.frame"
"summary.data.frame"            "t.data.frame"                 
[65] "transform.data.frame"          "unique.data.frame"
"unstack.data.frame"            "xpdrows.data.frame"           
> 

But I think the changes would be quick to make. Is anything else effected?
Do any test suites exist to confirm R hasn't broken?
On the face of it allowing data frames to have null row names seems a small
change, and would make them consistent with matrices, with large time and
space benefits. However, I can see the argument for a new class instead for
safety. Whats the consenus?



-----Original Message-----
From: Hin-Tak Leung [mailto:hin-tak.leung at cimr.cam.ac.uk] 
Sent: 09 December 2005 18:41
To: Gabor Grothendieck
Cc: Matthew Dowle; r-devel at r-project.org; Peter Dalgaard
Subject: Re: [Rd] [R] data.frame() size


Gabor Grothendieck wrote:
> There was nothing attached in the copy that came through
> to me.

I like to see that patch also.

> By the way, there was some discussion earlier this year
> on a light-weight data.frame class but I don't think anyone ever 
> posted any code.

It may have been me. I am working on a bit-packed data.frame which only uses
2-bits per unit of data, so it is 4 units per RAWSXP. (work in progress,
nothing to show).

So I am very interested to see the patch.

Yes, I took a couple of weeks reading/learning where have all the memory
gone in data.frame. The rowname/column names allocation is a bit stupid.
Each rowname and each column name is a full R object, so there is a 32(or
28) byte overhead just from managing that, before the STRSXP for the actual
string, which is another X bytes. so for an 1 x N data.frame with integers
for content, the the content is 4-byte * N, but the rowname/columnname is 32
* N -ish. (a 9x increase). Word is 32-bit on most people's machines, and I
am counting the extra one from which you have to keep the address of each
SEXPREC somewhere, so it is 7+1 = 8, if I understand it correctly.

Here is the relevant comment, quoted verbatum from around line 225 of 
"src/include/Rinternals.h":

/* The generational collector uses a reduced version of SEXPREC as a
    header in vector nodes.  The layout MUST be kept consistent with
    the SEXPREC definition.  The standard SEXPREC takes up 7 words on
    most hardware; this reduced version should take up only 6 words.
    In addition to slightly reducing memory use, this can lead to more
    favorable data alignment on 32-bit architectures like the Intel
    Pentium III where odd word alignment of doubles is allowed but much
    less efficient than even word alignment. */

Hin-Tak Leung

> On 12/9/05, Matthew Dowle <mdowle at concordiafunds.com> wrote:
> 
>>Hi,
>>
>>Please see below for post on r-help regarding data.frame() and the 
>>possibility of dropping rownames, for space and time reasons. I've 
>>made some changes, attached, and it seems to be working well. I see 
>>the expected space (90% saved) and time (10 times faster) savings. 
>>There are no doubt some bugs, and needs more work and testing, but I 
>>thought I would post first at this stage.
>>
>>Could some changes along these lines be made to R ? I'm happy to help 
>>with testing and further work if required. In the meantime I can work 
>>with overloaded functions which fixes the problems in my case.
>>
>>Functions effected :
>>
>>  dim.data.frame
>>  format.data.frame
>>  print.data.frame
>>  data.frame
>>  [.data.frame
>>  as.matrix.data.frame
>>
>>Modified source code attached.
>>
>>Regards,
>>Matthew
>>
>>
>>-----Original Message-----
>>From: Matthew Dowle
>>Sent: 09 December 2005 09:44
>>To: 'Peter Dalgaard'
>>Cc: 'r-help at stat.math.ethz.ch'
>>Subject: RE: [R] data.frame() size
>>
>>
>>
>>That explains it. Thanks. I don't need rownames though, as I'll only 
>>ever use integer subscripts. Is there anyway to drop them, or even 
>>better not create them in the first place? The memory saved (90%) by 
>>not having them and 10 times speed up would be very useful. I think I 
>>need a data.frame rather than a matrix because I have columns of 
>>different types in real life.
>>
>>
>>>rownames(d) = NULL
>>
>>Error in "dimnames<-.data.frame"(`*tmp*`, value = list(NULL, c("a", "b" :
>>       invalid 'dimnames' given for data frame
>>
>>
>>-----Original Message-----
>>From: pd at pubhealth.ku.dk [mailto:pd at pubhealth.ku.dk] On Behalf Of 
>>Peter Dalgaard
>>Sent: 08 December 2005 18:57
>>To: Matthew Dowle
>>Cc: 'r-help at stat.math.ethz.ch'
>>Subject: Re: [R] data.frame() size
>>
>>
>>Matthew Dowle <mdowle at concordiafunds.com> writes:
>>
>>
>>>Hi,
>>>
>>>In the example below why is d 10 times bigger than m, according to 
>>>object.size ? It also takes around 10 times as long to create, which 
>>>fits with object.size() being truthful.  gcinfo(TRUE) also indicates 
>>>a great deal more garbage collector activity caused by data.frame() 
>>>than matrix().
>>>
>>>$ R --vanilla
>>>....
>>>
>>>>nr = 1000000
>>>>system.time(m<<-matrix(integer(1), nrow=nr, ncol=2))
>>>
>>>[1] 0.22 0.01 0.23 0.00 0.00
>>>
>>>>system.time(d<<-data.frame(a=integer(nr), b=integer(nr)))
>>>
>>>[1] 2.81 0.20 3.01 0.00 0.00                  # 10 times longer
>>>
>>>
>>>>dim(m)
>>>
>>>[1] 1000000       2
>>>
>>>>dim(d)
>>>
>>>[1] 1000000       2                           # same dimensions
>>>
>>>
>>>>storage.mode(m)
>>>
>>>[1] "integer"
>>>
>>>>sapply(d, storage.mode)
>>>
>>>        a         b
>>>"integer" "integer"                           # same storage.mode
>>>
>>>
>>>>object.size(m)/1024^2
>>>
>>>[1] 7.629616
>>>
>>>>object.size(d)/1024^2
>>>
>>>[1] 76.29482                                  # but 10 times bigger
>>>
>>>
>>>>sum(sapply(d, object.size))/1024^2
>>>
>>>[1] 7.629501                                  # or is it ?    If its not
>>>really 10 times bigger, why 10 times longer above ?
>>
>>Row names!!
>>
>>
>>
>>>r <- as.character(1:1e6)
>>>object.size(r)
>>
>>[1] 72000056
>>
>>>object.size(r)/1024^2
>>
>>[1] 68.6646
>>
>>'nuff said?
>>
>>--
>>  O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>> c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>> (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45)
35327918
>>~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45)
35327907
>>
>>
>>
>>
>>______________________________________________
>>R-devel at r-project.org mailing list 
>>https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>>
> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Mon Dec 12 13:06:20 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 12 Dec 2005 12:06:20 +0000 (GMT)
Subject: [Rd] [R] data.frame() size
In-Reply-To: <78166BFC5165D811AA0400065BF0324BF07B36@wisconsin.concordia>
References: <78166BFC5165D811AA0400065BF0324BF07B36@wisconsin.concordia>
Message-ID: <Pine.LNX.4.61.0512121134080.17506@gannet.stats>

Data frames have unique row names *by definition* (White Book p.57).

Note that R is extensible, so any package writer has (for 14 years since 
the White Book) been entitled to assume that.  A minimum test suite is to 
run R CMD check on all CRAN packages, and to read all the relevant 
documentation.  That would reveal a large number of uses of row names and 
of their uniqueness.

On Mon, 12 Dec 2005, Matthew Dowle wrote:

>
> I guess the mail list precludes attachments then, makes sense. I have sent
> the modified source directly to anyone who has asked.
>
> I had a look at the light-weight data.frame class post
> (http://tolstoy.newcastle.edu.au/R/devel/05/05/0837.html) :
>
>> Now the transcript itself:
>> # the motivation: subscription of a data.frame is *much* (almost 20
> times) slower than that of a list
>> # compare
>> n = 1e6
>> i = seq(n)
>> x = data.frame(a=seq(n), b=seq(n))
>> system.time(x[i,], gcFirst=TRUE)
> [1] 1.01 0.14 1.14 0.00 0.00
>>
>> x = list(a=seq(n), b=seq(n))
>> system.time(lapply(x, function(col) col[i]), gcFirst=TRUE)
> [1] 0.06 0.00 0.06 0.00 0.00
>>
>> # the solution: define methods for the light-weight data.frame class
>> lwdf = function(...) structure(list(...), class = "lwdf")
>> ...
>
> But if I have understood correctly I think the time difference here is just
> down to the rownames. The rownames are 1:n stored in character form. This
> takes the most time and space in this example, but are never used. I'm not
> sure why 1:n in character form would ever be useful in fact. Running the
> example above with my modifications appears to fix the problem ie negligible
> time difference. I needed to make a one line change to [.data.frame, and
> I've sent that to anyone who requested the code.
>
> I can see the problem :
>
>> apropos("data.frame")
> [1] "[.data.frame"                  "as.matrix.data.frame"
> "data.frame"                    "dim.data.frame"
> [5] "format.data.frame"             "print.data.frame"
> ".__C__data.frame"              "aggregate.data.frame"
> [9] "$<-.data.frame"                "Math.data.frame"
> "Ops.data.frame"                "Summary.data.frame"
> [13] "[.data.frame"                  "[<-.data.frame"
> "[[.data.frame"                 "[[<-.data.frame"
> [17] "as.data.frame"                 "as.data.frame.AsIs"
> "as.data.frame.Date"            "as.data.frame.POSIXct"
> [21] "as.data.frame.POSIXlt"         "as.data.frame.array"
> "as.data.frame.character"       "as.data.frame.complex"
> [25] "as.data.frame.data.frame"      "as.data.frame.default"
> "as.data.frame.factor"          "as.data.frame.integer"
> [29] "as.data.frame.list"            "as.data.frame.logical"
> "as.data.frame.matrix"          "as.data.frame.model.matrix"
> [33] "as.data.frame.numeric"         "as.data.frame.ordered"
> "as.data.frame.package_version" "as.data.frame.raw"
> [37] "as.data.frame.table"           "as.data.frame.ts"
> "as.data.frame.vector"          "as.list.data.frame"
> [41] "as.matrix.data.frame"          "by.data.frame"
> "cbind.data.frame"              "data.frame"
> [45] "dim.data.frame"                "dimnames.data.frame"
> "dimnames<-.data.frame"         "duplicated.data.frame"
> [49] "format.data.frame"             "is.data.frame"
> "is.na.data.frame"              "mean.data.frame"
> [53] "merge.data.frame"              "print.data.frame"
> "rbind.data.frame"              "row.names.data.frame"
> [57] "row.names<-.data.frame"        "rowsum.data.frame"
> "split.data.frame"              "split<-.data.frame"
> [61] "stack.data.frame"              "subset.data.frame"
> "summary.data.frame"            "t.data.frame"
> [65] "transform.data.frame"          "unique.data.frame"
> "unstack.data.frame"            "xpdrows.data.frame"
>>
>
> But I think the changes would be quick to make. Is anything else effected?
> Do any test suites exist to confirm R hasn't broken?
> On the face of it allowing data frames to have null row names seems a small
> change, and would make them consistent with matrices, with large time and
> space benefits. However, I can see the argument for a new class instead for
> safety. Whats the consenus?
>
>
>
> -----Original Message-----
> From: Hin-Tak Leung [mailto:hin-tak.leung at cimr.cam.ac.uk]
> Sent: 09 December 2005 18:41
> To: Gabor Grothendieck
> Cc: Matthew Dowle; r-devel at r-project.org; Peter Dalgaard
> Subject: Re: [Rd] [R] data.frame() size
>
>
> Gabor Grothendieck wrote:
>> There was nothing attached in the copy that came through
>> to me.
>
> I like to see that patch also.
>
>> By the way, there was some discussion earlier this year
>> on a light-weight data.frame class but I don't think anyone ever
>> posted any code.
>
> It may have been me. I am working on a bit-packed data.frame which only uses
> 2-bits per unit of data, so it is 4 units per RAWSXP. (work in progress,
> nothing to show).
>
> So I am very interested to see the patch.
>
> Yes, I took a couple of weeks reading/learning where have all the memory
> gone in data.frame. The rowname/column names allocation is a bit stupid.
> Each rowname and each column name is a full R object, so there is a 32(or
> 28) byte overhead just from managing that, before the STRSXP for the actual
> string, which is another X bytes. so for an 1 x N data.frame with integers
> for content, the the content is 4-byte * N, but the rowname/columnname is 32
> * N -ish. (a 9x increase). Word is 32-bit on most people's machines, and I
> am counting the extra one from which you have to keep the address of each
> SEXPREC somewhere, so it is 7+1 = 8, if I understand it correctly.
>
> Here is the relevant comment, quoted verbatum from around line 225 of
> "src/include/Rinternals.h":
>
> /* The generational collector uses a reduced version of SEXPREC as a
>    header in vector nodes.  The layout MUST be kept consistent with
>    the SEXPREC definition.  The standard SEXPREC takes up 7 words on
>    most hardware; this reduced version should take up only 6 words.
>    In addition to slightly reducing memory use, this can lead to more
>    favorable data alignment on 32-bit architectures like the Intel
>    Pentium III where odd word alignment of doubles is allowed but much
>    less efficient than even word alignment. */
>
> Hin-Tak Leung
>
>> On 12/9/05, Matthew Dowle <mdowle at concordiafunds.com> wrote:
>>
>>> Hi,
>>>
>>> Please see below for post on r-help regarding data.frame() and the
>>> possibility of dropping rownames, for space and time reasons. I've
>>> made some changes, attached, and it seems to be working well. I see
>>> the expected space (90% saved) and time (10 times faster) savings.
>>> There are no doubt some bugs, and needs more work and testing, but I
>>> thought I would post first at this stage.
>>>
>>> Could some changes along these lines be made to R ? I'm happy to help
>>> with testing and further work if required. In the meantime I can work
>>> with overloaded functions which fixes the problems in my case.
>>>
>>> Functions effected :
>>>
>>>  dim.data.frame
>>>  format.data.frame
>>>  print.data.frame
>>>  data.frame
>>>  [.data.frame
>>>  as.matrix.data.frame
>>>
>>> Modified source code attached.
>>>
>>> Regards,
>>> Matthew
>>>
>>>
>>> -----Original Message-----
>>> From: Matthew Dowle
>>> Sent: 09 December 2005 09:44
>>> To: 'Peter Dalgaard'
>>> Cc: 'r-help at stat.math.ethz.ch'
>>> Subject: RE: [R] data.frame() size
>>>
>>>
>>>
>>> That explains it. Thanks. I don't need rownames though, as I'll only
>>> ever use integer subscripts. Is there anyway to drop them, or even
>>> better not create them in the first place? The memory saved (90%) by
>>> not having them and 10 times speed up would be very useful. I think I
>>> need a data.frame rather than a matrix because I have columns of
>>> different types in real life.
>>>
>>>
>>>> rownames(d) = NULL
>>>
>>> Error in "dimnames<-.data.frame"(`*tmp*`, value = list(NULL, c("a", "b" :
>>>       invalid 'dimnames' given for data frame
>>>
>>>
>>> -----Original Message-----
>>> From: pd at pubhealth.ku.dk [mailto:pd at pubhealth.ku.dk] On Behalf Of
>>> Peter Dalgaard
>>> Sent: 08 December 2005 18:57
>>> To: Matthew Dowle
>>> Cc: 'r-help at stat.math.ethz.ch'
>>> Subject: Re: [R] data.frame() size
>>>
>>>
>>> Matthew Dowle <mdowle at concordiafunds.com> writes:
>>>
>>>
>>>> Hi,
>>>>
>>>> In the example below why is d 10 times bigger than m, according to
>>>> object.size ? It also takes around 10 times as long to create, which
>>>> fits with object.size() being truthful.  gcinfo(TRUE) also indicates
>>>> a great deal more garbage collector activity caused by data.frame()
>>>> than matrix().
>>>>
>>>> $ R --vanilla
>>>> ....
>>>>
>>>>> nr = 1000000
>>>>> system.time(m<<-matrix(integer(1), nrow=nr, ncol=2))
>>>>
>>>> [1] 0.22 0.01 0.23 0.00 0.00
>>>>
>>>>> system.time(d<<-data.frame(a=integer(nr), b=integer(nr)))
>>>>
>>>> [1] 2.81 0.20 3.01 0.00 0.00                  # 10 times longer
>>>>
>>>>
>>>>> dim(m)
>>>>
>>>> [1] 1000000       2
>>>>
>>>>> dim(d)
>>>>
>>>> [1] 1000000       2                           # same dimensions
>>>>
>>>>
>>>>> storage.mode(m)
>>>>
>>>> [1] "integer"
>>>>
>>>>> sapply(d, storage.mode)
>>>>
>>>>        a         b
>>>> "integer" "integer"                           # same storage.mode
>>>>
>>>>
>>>>> object.size(m)/1024^2
>>>>
>>>> [1] 7.629616
>>>>
>>>>> object.size(d)/1024^2
>>>>
>>>> [1] 76.29482                                  # but 10 times bigger
>>>>
>>>>
>>>>> sum(sapply(d, object.size))/1024^2
>>>>
>>>> [1] 7.629501                                  # or is it ?    If its not
>>>> really 10 times bigger, why 10 times longer above ?
>>>
>>> Row names!!
>>>
>>>
>>>
>>>> r <- as.character(1:1e6)
>>>> object.size(r)
>>>
>>> [1] 72000056
>>>
>>>> object.size(r)/1024^2
>>>
>>> [1] 68.6646
>>>
>>> 'nuff said?
>>>
>>> --
>>>  O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
>>> c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>>> (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45)
> 35327918
>>> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45)
> 35327907
>>>
>>>
>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>>
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From hin-tak.leung at cimr.cam.ac.uk  Mon Dec 12 13:45:11 2005
From: hin-tak.leung at cimr.cam.ac.uk (Hin-Tak Leung)
Date: Mon, 12 Dec 2005 12:45:11 +0000
Subject: [Rd] [R] data.frame() size
In-Reply-To: <Pine.LNX.4.61.0512121134080.17506@gannet.stats>
References: <78166BFC5165D811AA0400065BF0324BF07B36@wisconsin.concordia>
	<Pine.LNX.4.61.0512121134080.17506@gannet.stats>
Message-ID: <439D70D7.1070705@cimr.cam.ac.uk>

Prof Brian Ripley wrote:
> Data frames have unique row names *by definition* (White Book p.57).

Yes - I happened to have the White Book on my desk (not mine...)
- indeed, the first sentence on page 57 is (quote verbatim, the
"never" is in italic in the book, which I have added the "*" before and 
after):

    If all else fails, the row names are just the row numbers. They
    are *never* null and must be unique.

So patching data.frame.R is quite wrong. However, the rowname/colname
overhead is definitely an issue for processing of large data sets,
both for speed and amount of memory consumed. So it is probably best
to extend the data.frame class and call it something else instead,
for those who needs to go that route.

(What I am doing is already called a different name so it isn't
affected by this argument).

Hin-Tak


From p.dalgaard at biostat.ku.dk  Mon Dec 12 14:11:00 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 12 Dec 2005 14:11:00 +0100
Subject: [Rd] [R] data.frame() size
In-Reply-To: <439D70D7.1070705@cimr.cam.ac.uk>
References: <78166BFC5165D811AA0400065BF0324BF07B36@wisconsin.concordia>
	<Pine.LNX.4.61.0512121134080.17506@gannet.stats>
	<439D70D7.1070705@cimr.cam.ac.uk>
Message-ID: <x21x0io3yz.fsf@viggo.kubism.ku.dk>

Hin-Tak Leung <hin-tak.leung at cimr.cam.ac.uk> writes:

> Prof Brian Ripley wrote:
> > Data frames have unique row names *by definition* (White Book p.57).
> 
> Yes - I happened to have the White Book on my desk (not mine...)
> - indeed, the first sentence on page 57 is (quote verbatim, the
> "never" is in italic in the book, which I have added the "*" before
> and after):
> 
>     If all else fails, the row names are just the row numbers. They
>     are *never* null and must be unique.
> 
> So patching data.frame.R is quite wrong. However, the rowname/colname
> overhead is definitely an issue for processing of large data sets,
> both for speed and amount of memory consumed. So it is probably best
> to extend the data.frame class and call it something else instead,
> for those who needs to go that route.


Exactly. I recall from the Insightful people at the DSC in Seattle
that something is going to happen with the rownames in S-PLUS or has
happened in the latest release, but I don't remember exactly how they
did it, and if and how it had to do with their "big dataframe" code.
We might want R to follow suit in this respect.

Other options might include doing something about the string-storage
of rownames, which is quite wasteful in R (every string is an R
object, a string vector is really a list of CHARSXP objects). Either
one could improve on the internal storage format, or one could allow
rownames to be integers with semantics like "virtual strings" so that
x["123",] still works.
 
> (What I am doing is already called a different name so it isn't
> affected by this argument).
> 
> Hin-Tak
> 
> 
> 

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From aleszib at gmail.com  Mon Dec 12 15:04:18 2005
From: aleszib at gmail.com (Ales Ziberna)
Date: Mon, 12 Dec 2005 15:04:18 +0100
Subject: [Rd] Problems with sending data to FORTRAN subrutine
Message-ID: <00e301c5ff24$f428d770$0100a8c0@ALES>

Dear ExpeRts!

I have problem with sending data to FORTRAN subroutine on Windows XP and R 
2.1.1. When I call it using .Fortran, I get the following error:

R for Windows GUI front-end has encountered a problem and needs to close. We 
are sorry for the inconvenience.

Error signature
AppName: rgui.exe  AppVer: 2.11.50620.0           ModName: read.dll
ModVer: 0.0.0.0      Offset: 00001683


It seams that the error is somehow related to the size of the data. Here are
the calls:
dyn.load("C:/ales/b_for/read.dll")
#The FORTRUN subroutine used to create the "read.dll" ("read.f") is attached 
(and in case something happens to the attachment also at the end of the 
mail.

n<-as.integer(134);k<-as.integer(2);M<-matrix(as.double(rnorm(n=n^2)),nrow=n,ncol=n);.Fortran("read",M=M,n=as.integer(n),clu=as.integer(sample(1:k,size=n,replace=TRUE)), 
k=as.integer(k),diag=as.integer(1),err=as.double(0.0),E=matrix(as.double(0),ncol=k,nrow=k), 
BM=matrix(as.double(0),ncol=k,nrow=k))
#This works ok

n<-as.integer(134);k<-as.integer(4);M<-matrix(as.double(rnorm(n=n^2)), 
nrow=n,ncol=n);.Fortran("read",M=M,n=as.integer(n),clu=as.integer(sample(1:k,size=n,replace=TRUE)), 
k=as.integer(k),diag=as.integer(1),err=as.double(0.0),E=matrix(as.double(0),ncol=k,nrow=k), 
BM=matrix(as.double(0),ncol=k,nrow=k))
#Now the k is incrised form 2 to 4 and the error occours.

n<-as.integer(40);k<-as.integer(4);M<-matrix(as.double(rnorm(n=n^2)),nrow=n,ncol=n);.Fortran("read",M=M,n=as.integer(n),clu=as.integer(sample(1:k,size=n,replace=TRUE)), 
k=as.integer(k),diag=as.integer(1),err=as.double(0.0),E=matrix(as.double(0),ncol=k,nrow=k), 
BM=matrix(as.double(0),ncol=k,nrow=k))
#If I leave the k at 4 and reduce the n to 40, then it works.


Any suggestions are welcomed. Thank you in advance!


Best regards,
Ales Ziberna


The commands used to generate "read.dll".
g77 -c read.f
R CMD SHLIB read.o


The FORTRAN subroutine ("read.f"):
        subroutine read(M,n,clu,k,diag,err,E,BM)
        INTEGER n, clu, k, i, j, ii, nA, nAD
        DOUBLE PRECISION M, E, BM, A, AD, vecA, vecAD, err, mean, temp, ss
        LOGICAL diag
        DIMENSION M(n,n), clu(n), E(k,k), BM(k,k), A(k,k,n*n), AD(k,n), 
nA(k,k), nAD(k), vecA(n*n), vecAD(n)

        end

From patricia.peter at virgin.net  Mon Dec 12 19:19:43 2005
From: patricia.peter at virgin.net (patricia.peter@virgin.net)
Date: Mon, 12 Dec 2005 19:19:43 +0100 (CET)
Subject: [Rd] notification (PR#8383)
Message-ID: <20051212181943.F30CAA220@slim.kubism.ku.dk>

------=_Part_37369_7912743.1134408569488
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

The Gardener Humanitarian Project,Van-gennelaan 371,4512DT,Delft,Holland
PIN No:627462128TW,
 
        I wish to bring to your information that at the just concluded end of year draw of above named humanitarian firm held on the 9th of December,2005.
Be informed also that the  identification number fixed to your  email address propelled out of the third jump,making you the winner of the slated sum of two hundred and fifty thousand USD($250,000).
 
The source of fund is majorly from well meaning companies and humananitarian sprited industries selected from european community.Based on the joint management guideline,a reasonable proportion of your win(10% at the minumum) should be disbursed to a selfless activity in your locality ,on the reception of your fund.
Application  should be forwarded to Mrs Marina Van Kleiweg via e-mail ;(marina at gardener.com.)
Accept my heart felt congratulations.
 
Mrs Patricia Peter
 
PS:Kindly state your PIN No in your expected application.
------=_Part_37369_7912743.1134408569488
Content-Type: text/html;charset="UTF-8"
Content-Transfer-Encoding: 7bit

<DIV><FONT color=blue><FONT size=4>The Gardener&nbsp;Humanitarian Project,<BR></FONT>Van-gennelaan 371,<BR>4512DT,Delft,Holland</FONT><FONT color=black><BR></FONT></DIV>
<DIV><FONT color=black>PIN No:627462128TW,</FONT></DIV>
<DIV>&nbsp;</DIV>
<DIV>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; I wish to bring to your information that at the just concluded end of year draw of above named humanitarian firm held on the 9th of December,2005.</DIV>
<DIV>Be informed also that the&nbsp; identification number fixed to your&nbsp;&nbsp;email&nbsp;address&nbsp;propelled out of the third jump,making you the winner of the slated sum of two hundred and fifty thousand USD($250,000).</DIV>
<DIV>&nbsp;</DIV>
<DIV>The source of fund is majorly from well meaning companies and humananitarian sprited industries selected from european community.Based on the joint management guideline,a reasonable proportion of your win(10% at the minumum) should be disbursed to a selfless activity in your locality ,on the reception of your fund.</DIV>
<DIV>Application&nbsp; should be forwarded to&nbsp;Mrs&nbsp;Marina Van Kleiweg&nbsp;via e-mail ;(<A href="mailto:marina at gardener.com">marina at gardener.com</A>.)</DIV>
<DIV>Accept my heart felt congratulations.</DIV>
<DIV>&nbsp;</DIV>
<DIV>Mrs Patricia Peter</DIV>
<DIV>&nbsp;</DIV>
<DIV>PS:Kindly state your PIN No in your expected application.<BR></DIV>
------=_Part_37369_7912743.1134408569488--


From gregory.warnes at gmail.com  Mon Dec 12 20:03:00 2005
From: gregory.warnes at gmail.com (Gregory Warnes)
Date: Mon, 12 Dec 2005 14:03:00 -0500
Subject: [Rd] FW: Bug in sum() with named data frame arguments
In-Reply-To: <915D2D65A9986440A277AC5C98AA466F018636BD@groamrexm02.amer.pfizer.com>
References: <915D2D65A9986440A277AC5C98AA466F018636BD@groamrexm02.amer.pfizer.com>
Message-ID: <9c9494ea0512121103q41aeba0ew3042522cb9263623@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20051212/4b3e1119/attachment.pl

From clausen at econ.upenn.edu  Mon Dec 12 22:16:20 2005
From: clausen at econ.upenn.edu (Andrew Clausen)
Date: Mon, 12 Dec 2005 16:16:20 -0500
Subject: [Rd] extension to missing()? {was "hist() ... helpful warning?
	(PR#8376)"}
In-Reply-To: <17309.23782.691038.586796@stat.math.ethz.ch>
References: <20051211074001.C7AFB15AA7@slim.kubism.ku.dk>
	<17309.23782.691038.586796@stat.math.ethz.ch>
Message-ID: <20051212211620.GB27693@econ.upenn.edu>

Hi Martin,

On Mon, Dec 12, 2005 at 12:20:06PM +0100, Martin Maechler wrote:
>     AndrewC> I didn't occur to me to check the plot.histogram()
>     AndrewC> help page.  
> 
> [ even though it's prominently mentioned on  help(hist)  ?? ]

Yes.  I expected plot.histogram() was something that no-one ever
calls directly (and I still expect that!), and I expected hist()
to pass everything on to plot.histogram().

I guess I think the most elegant design would be to remove all
plotting functionality from hist(), and put all arguments into
plot.histogram().  Or make histogram objects store everything.
But, I expect you can't changed this now, for compatability / user 
familiarity reasons...

>     AndrewC> Perhaps it might be helpful to document in the
>     AndrewC> hist() help page which attributes are stored in the
>     AndrewC> hist() object.  
> you mean the 'histogram' object.

Yes.

> Yes, that might be helpful; diffs against
>   https://svn.R-project.org/R/trunk/src/library/graphics/man/hist.Rd
> are welcome.

I added it to my R-TODO.  (I doubt I will be able to get to this
for about a year... I am at the oppressive beginning of an obnoxious
degree program!)

> and of course
>     is.miss <- lapply(formals(), function(n) missing(n))
> ``works'' but trivially {why ?} and hence not usefully.

R's introspection capabilities are a little mysterious to me.

The missing() docs mention that it should be improved in future.
That might be a better long-term solution?

Cheers,
Andrew


From ellis at stat.harvard.edu  Mon Dec 12 22:20:45 2005
From: ellis at stat.harvard.edu (Byron Ellis)
Date: Mon, 12 Dec 2005 13:20:45 -0800
Subject: [Rd] external pointers
In-Reply-To: <Pine.LNX.4.61.0512120812060.4551@gannet.stats>
References: <Pine.LNX.4.44.0512120849200.26218-100000@reclus.nhh.no>
	<Pine.LNX.4.61.0512120812060.4551@gannet.stats>
Message-ID: <343504DC-4112-4E6C-B695-BDF1999D033C@stat.harvard.edu>

There's also Luke's own site, in particular http://www.stat.uiowa.edu/ 
~luke/R/weakfinex.html

On Dec 12, 2005, at 12:16 AM, Prof Brian Ripley wrote:

> On Mon, 12 Dec 2005, Roger Bivand wrote:
>
>>> Where would be best to read about externalptr? I'm having trouble
>>> finding material in the manuals or the site-search.
>>>
>>> And would I need to use all the .Call machinery and C headers and  
>>> SEXP
>>> etc in order to handle externalptr objects?
>>
>> One package using externalptr is rgdal - Tim Keitt wrote the  
>> bindings to
>> the external GDAL library for reading raster images to first return a
>> pointer to a dataset (on disk) opened by GDAL, then to use the  
>> object to
>> retrieve (parts of) the data. Most of the .Call/SEXP machinery is  
>> there
>> (for the C++ case, GDAL is C++, so GDAL manages its own memory for  
>> its
>> objects). The package also uses S4 classes, which may be overkill  
>> for your
>> purposes.
>
> RODBC is another, somewhat simpler, one.
>
> There is documentation on developer.r-project.org, but my  
> recollection is
> that is was not up to date (and in particular not re finalizers).   
> On my
> TODO list is to add end-user documentation to `Writing R Extensions'.
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

---
Byron Ellis (ellis at stat.harvard.edu)
"Oook" -- The Librarian


From ripley at stats.ox.ac.uk  Mon Dec 12 23:05:02 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 12 Dec 2005 22:05:02 +0000 (GMT)
Subject: [Rd] external pointers
In-Reply-To: <343504DC-4112-4E6C-B695-BDF1999D033C@stat.harvard.edu>
References: <Pine.LNX.4.44.0512120849200.26218-100000@reclus.nhh.no>
	<Pine.LNX.4.61.0512120812060.4551@gannet.stats>
	<343504DC-4112-4E6C-B695-BDF1999D033C@stat.harvard.edu>
Message-ID: <Pine.LNX.4.61.0512122202560.25764@gannet.stats>

On Mon, 12 Dec 2005, Byron Ellis wrote:

> There's also Luke's own site, in particular http://www.stat.uiowa.edu/ 
> ~luke/R/weakfinex.html

Hmm, that _is_ a link on the page I pointed you to, under its actual 
subject, weak references.

> On Dec 12, 2005, at 12:16 AM, Prof Brian Ripley wrote:
>
>> On Mon, 12 Dec 2005, Roger Bivand wrote:
>> 
>>>> Where would be best to read about externalptr? I'm having trouble
>>>> finding material in the manuals or the site-search.
>>>> 
>>>> And would I need to use all the .Call machinery and C headers and SEXP
>>>> etc in order to handle externalptr objects?
>>> 
>>> One package using externalptr is rgdal - Tim Keitt wrote the bindings to
>>> the external GDAL library for reading raster images to first return a
>>> pointer to a dataset (on disk) opened by GDAL, then to use the object to
>>> retrieve (parts of) the data. Most of the .Call/SEXP machinery is there
>>> (for the C++ case, GDAL is C++, so GDAL manages its own memory for its
>>> objects). The package also uses S4 classes, which may be overkill for your
>>> purposes.
>> 
>> RODBC is another, somewhat simpler, one.
>> 
>> There is documentation on developer.r-project.org, but my recollection is
>> that is was not up to date (and in particular not re finalizers).  On my
>> TODO list is to add end-user documentation to `Writing R Extensions'.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Tue Dec 13 11:16:44 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 13 Dec 2005 11:16:44 +0100
Subject: [Rd] correct address for R-bugs ..
In-Reply-To: <9c9494ea0512121103q41aeba0ew3042522cb9263623@mail.gmail.com>
References: <915D2D65A9986440A277AC5C98AA466F018636BD@groamrexm02.amer.pfizer.com>
	<9c9494ea0512121103q41aeba0ew3042522cb9263623@mail.gmail.com>
Message-ID: <17310.40844.507687.530727@stat.math.ethz.ch>

>>>>> "Greg" == Gregory Warnes <gregory.warnes at gmail.com>
>>>>>     on Mon, 12 Dec 2005 14:03:00 -0500 writes:

    Greg> I got an email error message when I attempted to
    Greg> send this from my work account.  I have manually
    Greg> added it to the bug tracker, and am resending from
    Greg> my personal account.


    Greg> -G

    Greg> On 12/12/05, Warnes, Gregory R <gregory.r.warnes at pfizer.com> wrote:
    >> 
    >> 
    >> 
    >> >  -----Original Message-----
    >> > From:         Warnes, Gregory R
    >> > Sent: Monday, December 12, 2005 1:53 PM
    >> > To:   'bugs at cran.r-project.org'
	        ^^^^^^^^^^^^^^^^^^^^^^^

	Can you tell where you took this address from?

We'd very much like that R bug reports be sent to
     R-bugs at r-project.org

(from where they are forwarded to the repository in Denmark,
 *after* having been virus- and spam-filtered).

Martin Maechler, ETH ZUrich


From rasche at molgen.mpg.de  Tue Dec 13 16:05:15 2005
From: rasche at molgen.mpg.de (rasche@molgen.mpg.de)
Date: Tue, 13 Dec 2005 16:05:15 +0100 (CET)
Subject: [Rd] 0/1 vector for indexing leads to funny behaviour (PR#8389)
Message-ID: <20051213150515.175B8A3C7@slim.kubism.ku.dk>

Full_Name: Axel Rasche
Version: 2.2.0
OS: Linux
Submission from: (NULL) (141.14.21.81)


Dear Debuggers,

This is not a serious problem. Are 0/1 vectors intended to be used as index
vectors? If yes, there is a bug. If not, it leads just to some funny behaviour
rather than an error message.

In the appendix is some simple code to reproduce the problem. A logical vector
as.logic(a) helps by indexing the vector b. The 0/1 vector a just returns the
first value "a". But as many times as there is a 1 in a.

Best regards,
Axel


Appendix:

b = c("a","b","c","d")
a = c(0,1,1,0)
b[as.logical(a)]
b[a]
a = c(1,0,1,0)
b[as.logical(a)]
b[a]
a = c(0,1,1,1)
b[as.logical(a)]
b[a]


From p.dalgaard at biostat.ku.dk  Tue Dec 13 17:37:36 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 13 Dec 2005 17:37:36 +0100
Subject: [Rd] 0/1 vector for indexing leads to funny behaviour (PR#8389)
In-Reply-To: <20051213150515.175B8A3C7@slim.kubism.ku.dk>
References: <20051213150515.175B8A3C7@slim.kubism.ku.dk>
Message-ID: <x23bkxar73.fsf@viggo.kubism.ku.dk>

rasche at molgen.mpg.de writes:

> Full_Name: Axel Rasche
> Version: 2.2.0
> OS: Linux
> Submission from: (NULL) (141.14.21.81)
> 
> 
> Dear Debuggers,
> 
> This is not a serious problem. Are 0/1 vectors intended to be used as index
> vectors? If yes, there is a bug. If not, it leads just to some funny behaviour
> rather than an error message.
> 
> In the appendix is some simple code to reproduce the problem. A logical vector
> as.logic(a) helps by indexing the vector b. The 0/1 vector a just returns the
> first value "a". But as many times as there is a 1 in a.


Yes, that is completely as intended. Zeros in a numerical index vector
produce nothing and ones produce the first element. The documentation
could arguably be better on this point though.

 
> Best regards,
> Axel
> 
> 
> Appendix:
> 
> b = c("a","b","c","d")
> a = c(0,1,1,0)
> b[as.logical(a)]
> b[a]
> a = c(1,0,1,0)
> b[as.logical(a)]
> b[a]
> a = c(0,1,1,1)
> b[as.logical(a)]
> b[a]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From tplate at acm.org  Tue Dec 13 19:04:20 2005
From: tplate at acm.org (Tony Plate)
Date: Tue, 13 Dec 2005 11:04:20 -0700
Subject: [Rd] 0/1 vector for indexing leads to funny behaviour (PR#8389)
 (maybe a documentation deficiency?)
In-Reply-To: <20051213150515.175B8A3C7@slim.kubism.ku.dk>
References: <20051213150515.175B8A3C7@slim.kubism.ku.dk>
Message-ID: <439F0D24.1080701@acm.org>

Yes, 0/1 (numeric) are intended to be used as index vectors -- and they 
have the semantics of numeric indices, which is that 0 elements in the 
index are omitted from the result.  This can be a very useful mode of 
operation in many situations.

I was going to write "This is described in both the introduction to R, 
and in the documentation for '['", except that I checked before I wrote 
and was surprised to be unable to any discussion of zeros in indexing in 
any of the first three places I looked:

(1) help page for '[' (There is discussion of zero indices here, but 
only in the context of using matrices to index matrices, not in the 
context of ordinary vector indices).

(2) Section 2.7 "Index vectors: selecting and modifying subsets of a 
data set" in "An Introduction to R", which does say this about numeric 
indices:
     2. A vector of positive integral quantities. In
        this case the values in the index vector must
        lie in the set {1, 2, . . . , length(x)}
(This seems to commit the sin of not telling the whole truth.)

(3) Section 5.5 "Array Indexing.  Subsections of an array" (In "An 
Introduction to R")

Question for others: did I miss something obvious, or is this a 
documentation deficiency that zeros in indices are not discussed in 3 of 
some obvious first places to look?

If indeed this is a documentation deficiency, I'm happy to contribute 
documentation patch, but I await other opinions before spending any time 
on that.

-- Tony Plate

rasche at molgen.mpg.de wrote:
> Full_Name: Axel Rasche
> Version: 2.2.0
> OS: Linux
> Submission from: (NULL) (141.14.21.81)
> 
> 
> Dear Debuggers,
> 
> This is not a serious problem. Are 0/1 vectors intended to be used as index
> vectors? If yes, there is a bug. If not, it leads just to some funny behaviour
> rather than an error message.
> 
> In the appendix is some simple code to reproduce the problem. A logical vector
> as.logic(a) helps by indexing the vector b. The 0/1 vector a just returns the
> first value "a". But as many times as there is a 1 in a.
> 
> Best regards,
> Axel
> 
> 
> Appendix:
> 
> b = c("a","b","c","d")
> a = c(0,1,1,0)
> b[as.logical(a)]
> b[a]
> a = c(1,0,1,0)
> b[as.logical(a)]
> b[a]
> a = c(0,1,1,1)
> b[as.logical(a)]
> b[a]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From rasche at molgen.mpg.de  Tue Dec 13 19:09:23 2005
From: rasche at molgen.mpg.de (rasche@molgen.mpg.de)
Date: Tue, 13 Dec 2005 19:09:23 +0100 (CET)
Subject: [Rd] 0/1 vector for indexing leads to funny behaviour (PR#8389)
Message-ID: <20051213180923.C804CA21B@slim.kubism.ku.dk>

Hi,

OK, no bug. I got stuck into to much indexing. Now I understand this 
point definitely better.

Sorry for disturbing you,
Axel

Tony Plate wrote:
> Yes, 0/1 (numeric) are intended to be used as index vectors -- and they 
> have the semantics of numeric indices, which is that 0 elements in the 
> index are omitted from the result.  This can be a very useful mode of 
> operation in many situations.
> 
> I was going to write "This is described in both the introduction to R, 
> and in the documentation for '['", except that I checked before I wrote 
> and was surprised to be unable to any discussion of zeros in indexing in 
> any of the first three places I looked:
> 
> (1) help page for '[' (There is discussion of zero indices here, but 
> only in the context of using matrices to index matrices, not in the 
> context of ordinary vector indices).
> 
> (2) Section 2.7 "Index vectors: selecting and modifying subsets of a 
> data set" in "An Introduction to R", which does say this about numeric 
> indices:
>     2. A vector of positive integral quantities. In
>        this case the values in the index vector must
>        lie in the set {1, 2, . . . , length(x)}
> (This seems to commit the sin of not telling the whole truth.)
> 
> (3) Section 5.5 "Array Indexing.  Subsections of an array" (In "An 
> Introduction to R")
> 
> Question for others: did I miss something obvious, or is this a 
> documentation deficiency that zeros in indices are not discussed in 3 of 
> some obvious first places to look?
> 
> If indeed this is a documentation deficiency, I'm happy to contribute 
> documentation patch, but I await other opinions before spending any time 
> on that.
> 
> -- Tony Plate
> 
> rasche at molgen.mpg.de wrote:
> 
>> Full_Name: Axel Rasche
>> Version: 2.2.0
>> OS: Linux
>> Submission from: (NULL) (141.14.21.81)
>>
>>
>> Dear Debuggers,
>>
>> This is not a serious problem. Are 0/1 vectors intended to be used as 
>> index
>> vectors? If yes, there is a bug. If not, it leads just to some funny 
>> behaviour
>> rather than an error message.
>>
>> In the appendix is some simple code to reproduce the problem. A 
>> logical vector
>> as.logic(a) helps by indexing the vector b. The 0/1 vector a just 
>> returns the
>> first value "a". But as many times as there is a 1 in a.
>>
>> Best regards,
>> Axel
>>
>>
>> Appendix:
>>
>> b = c("a","b","c","d")
>> a = c(0,1,1,0)
>> b[as.logical(a)]
>> b[a]
>> a = c(1,0,1,0)
>> b[as.logical(a)]
>> b[a]
>> a = c(0,1,1,1)
>> b[as.logical(a)]
>> b[a]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 

-- 
*******************************************
Dipl. Math. ETH Axel Rasche
Max-Planck-Institute for Molecular Genetics
Department Lehrach (Vertebrate Genomics)
Ihnestrasse 63-73
D-14195 Berlin-Dahlem
GERMANY

Tel. ++49-30-8413-1289
Fax  ++49-30-8413-1380


From ripley at stats.ox.ac.uk  Tue Dec 13 19:10:14 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 13 Dec 2005 19:10:14 +0100 (CET)
Subject: [Rd] 0/1 vector for indexing leads to funny behaviour (PR#8389)
Message-ID: <20051213181014.703A4A21B@slim.kubism.ku.dk>

It is peculiar behaviour on your part, but the developers do not find it 
at all `funny'.

On Tue, 13 Dec 2005 rasche at molgen.mpg.de wrote:

> Full_Name: Axel Rasche
> Version: 2.2.0
> OS: Linux
> Submission from: (NULL) (141.14.21.81)
>
>
> Dear Debuggers,
>
> This is not a serious problem. Are 0/1 vectors intended to be used as index
> vectors? If yes, there is a bug. If not, it leads just to some funny behaviour
> rather than an error message.

They are, and in your example they work as documented.  You have not even 
told us what you think the bug is.

What happens in clearly stated in the R Language Definition and in all 
good reference books on R.

> In the appendix is some simple code to reproduce the problem. A logical vector
> as.logic(a) helps by indexing the vector b. The 0/1 vector a just returns the
> first value "a". But as many times as there is a 1 in a.

As it should.

>
> Best regards,
> Axel
>
>
> Appendix:
>
> b = c("a","b","c","d")
> a = c(0,1,1,0)
> b[as.logical(a)]
> b[a]
> a = c(1,0,1,0)
> b[as.logical(a)]
> b[a]
> a = c(0,1,1,1)
> b[as.logical(a)]
> b[a]


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From academic at feferraz.net  Tue Dec 13 19:16:20 2005
From: academic at feferraz.net (Fernando Henrique Ferraz P. da Rosa)
Date: Tue, 13 Dec 2005 16:16:20 -0200
Subject: [Rd] R_PROFILE on Windows
Message-ID: <20051213181620.GA18323@ime.usp.br>

  Dear R-devel,

        There seems to be a bug in the Startup section, regarding the
R_PROFILE environment variable in Windows. If not a bug in the Startup
itself, perhaps a bug in the documentation.

        According to ?Startup:

       Then R searches for the site-wide startup profile unless the
       command line option '--no-site-file' was given.  The name of this
       file is taken from the value of the 'R_PROFILE' environment
       variable. If this variable is unset, the default is
       '$R_HOME/etc/Rprofile.site'
        
        On Windows XP, I created a batch file with the following lines:

        SET R_PROFILE="C:\fernando\R.profile"
        "C:\progs\R-2.2.0\bin\Rgui.exe"
        
        On c:\fernando\R.profile I had:

        options(foo='bar')

        Running the batch file I created I get, in R:

        > options()$foo
        NULL
        >Sys.getenv("R_PROFILE")
                           R_PROFILE 
        "\"c:\\fernando\\R.profile\"" 
               
        I've tried using slashes instead of backslashes
(fernando/R.profile), double blackslashes (fernando\\R.profile) but it
seems there's no way to make it work.

        The only way I could manage to have R read the profile was
renaming R.profile to .Rprofile and starting R on the directory the
.Rprofile was located.

        Is this really the intended behaviour? If so, what's the
correct way to specify the R_PROFILE variable and have R use it on
Windows?

        Ps: I've tested it on R 2.2.0 and on r-devel r36675, on Windows
XP SP2. Sorry if this is a non-bug. I'm a poor linux user trying to
survive on Windows, so I might have overloooked something.

        Thank you, 




--
"Though this be randomness, yet there is structure in't."
                                           Rosa, F.H.F.P

Instituto de Matem?tica e Estat?stica
Universidade de S?o Paulo
Fernando Henrique Ferraz P. da Rosa
http://www.feferraz.net


From ggrothendieck at gmail.com  Tue Dec 13 20:56:11 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 13 Dec 2005 14:56:11 -0500
Subject: [Rd] 0/1 vector for indexing leads to funny behaviour (PR#8389)
	(maybe a documentation deficiency?)
In-Reply-To: <439F0D24.1080701@acm.org>
References: <20051213150515.175B8A3C7@slim.kubism.ku.dk>
	<439F0D24.1080701@acm.org>
Message-ID: <971536df0512131156j3e618715ne1d6859113dce2f5@mail.gmail.com>

The other place its discussed is in 3.4.1 of the R Language Definition:

http://finzi.psych.upenn.edu/R/doc/manual/R-lang.html#Indexing-by-vectors

On 12/13/05, Tony Plate <tplate at acm.org> wrote:
> Yes, 0/1 (numeric) are intended to be used as index vectors -- and they
> have the semantics of numeric indices, which is that 0 elements in the
> index are omitted from the result.  This can be a very useful mode of
> operation in many situations.
>
> I was going to write "This is described in both the introduction to R,
> and in the documentation for '['", except that I checked before I wrote
> and was surprised to be unable to any discussion of zeros in indexing in
> any of the first three places I looked:
>
> (1) help page for '[' (There is discussion of zero indices here, but
> only in the context of using matrices to index matrices, not in the
> context of ordinary vector indices).
>
> (2) Section 2.7 "Index vectors: selecting and modifying subsets of a
> data set" in "An Introduction to R", which does say this about numeric
> indices:
>     2. A vector of positive integral quantities. In
>        this case the values in the index vector must
>        lie in the set {1, 2, . . . , length(x)}
> (This seems to commit the sin of not telling the whole truth.)
>
> (3) Section 5.5 "Array Indexing.  Subsections of an array" (In "An
> Introduction to R")
>
> Question for others: did I miss something obvious, or is this a
> documentation deficiency that zeros in indices are not discussed in 3 of
> some obvious first places to look?
>
> If indeed this is a documentation deficiency, I'm happy to contribute
> documentation patch, but I await other opinions before spending any time
> on that.
>
> -- Tony Plate
>
> rasche at molgen.mpg.de wrote:
> > Full_Name: Axel Rasche
> > Version: 2.2.0
> > OS: Linux
> > Submission from: (NULL) (141.14.21.81)
> >
> >
> > Dear Debuggers,
> >
> > This is not a serious problem. Are 0/1 vectors intended to be used as index
> > vectors? If yes, there is a bug. If not, it leads just to some funny behaviour
> > rather than an error message.
> >
> > In the appendix is some simple code to reproduce the problem. A logical vector
> > as.logic(a) helps by indexing the vector b. The 0/1 vector a just returns the
> > first value "a". But as many times as there is a 1 in a.
> >
> > Best regards,
> > Axel
> >
> >
> > Appendix:
> >
> > b = c("a","b","c","d")
> > a = c(0,1,1,0)
> > b[as.logical(a)]
> > b[a]
> > a = c(1,0,1,0)
> > b[as.logical(a)]
> > b[a]
> > a = c(0,1,1,1)
> > b[as.logical(a)]
> > b[a]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ggrothendieck at gmail.com  Tue Dec 13 20:56:23 2005
From: ggrothendieck at gmail.com (ggrothendieck@gmail.com)
Date: Tue, 13 Dec 2005 20:56:23 +0100 (CET)
Subject: [Rd] 0/1 vector for indexing leads to funny behaviour (PR#8389)
	(maybe a documentation deficiency?)
Message-ID: <20051213195623.DDB1715AA7@slim.kubism.ku.dk>

The other place its discussed is in 3.4.1 of the R Language Definition:

http://finzi.psych.upenn.edu/R/doc/manual/R-lang.html#Indexing-by-vectors

On 12/13/05, Tony Plate <tplate at acm.org> wrote:
> Yes, 0/1 (numeric) are intended to be used as index vectors -- and they
> have the semantics of numeric indices, which is that 0 elements in the
> index are omitted from the result.  This can be a very useful mode of
> operation in many situations.
>
> I was going to write "This is described in both the introduction to R,
> and in the documentation for '['", except that I checked before I wrote
> and was surprised to be unable to any discussion of zeros in indexing in
> any of the first three places I looked:
>
> (1) help page for '[' (There is discussion of zero indices here, but
> only in the context of using matrices to index matrices, not in the
> context of ordinary vector indices).
>
> (2) Section 2.7 "Index vectors: selecting and modifying subsets of a
> data set" in "An Introduction to R", which does say this about numeric
> indices:
>     2. A vector of positive integral quantities. In
>        this case the values in the index vector must
>        lie in the set {1, 2, . . . , length(x)}
> (This seems to commit the sin of not telling the whole truth.)
>
> (3) Section 5.5 "Array Indexing.  Subsections of an array" (In "An
> Introduction to R")
>
> Question for others: did I miss something obvious, or is this a
> documentation deficiency that zeros in indices are not discussed in 3 of
> some obvious first places to look?
>
> If indeed this is a documentation deficiency, I'm happy to contribute
> documentation patch, but I await other opinions before spending any time
> on that.
>
> -- Tony Plate
>
> rasche at molgen.mpg.de wrote:
> > Full_Name: Axel Rasche
> > Version: 2.2.0
> > OS: Linux
> > Submission from: (NULL) (141.14.21.81)
> >
> >
> > Dear Debuggers,
> >
> > This is not a serious problem. Are 0/1 vectors intended to be used as i=
ndex
> > vectors? If yes, there is a bug. If not, it leads just to some funny be=
haviour
> > rather than an error message.
> >
> > In the appendix is some simple code to reproduce the problem. A logical=
 vector
> > as.logic(a) helps by indexing the vector b. The 0/1 vector a just retur=
ns the
> > first value "a". But as many times as there is a 1 in a.
> >
> > Best regards,
> > Axel
> >
> >
> > Appendix:
> >
> > b =3D c("a","b","c","d")
> > a =3D c(0,1,1,0)
> > b[as.logical(a)]
> > b[a]
> > a =3D c(1,0,1,0)
> > b[as.logical(a)]
> > b[a]
> > a =3D c(0,1,1,1)
> > b[as.logical(a)]
> > b[a]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From ripley at stats.ox.ac.uk  Tue Dec 13 22:08:34 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 13 Dec 2005 21:08:34 +0000 (GMT)
Subject: [Rd] 0/1 vector for indexing leads to funny behaviour (PR#8389)
 (maybe a documentation deficiency?)
In-Reply-To: <439F0D24.1080701@acm.org>
References: <20051213150515.175B8A3C7@slim.kubism.ku.dk>
	<439F0D24.1080701@acm.org>
Message-ID: <Pine.LNX.4.61.0512132104090.9376@gannet.stats>

?"[" says

See Also:

      'list', 'array', 'matrix'.

      '[.data.frame' and '[.factor' for the behaviour when applied to
      data.frame and factors.

      'Syntax' for operator precedence, and the _R Language_ reference
      manual about indexing details.

and the `indexing details' are indeed where it says they are.

This is not an introductory topic, and it makes sense to have the details 
in only one place and refer to it.  That help page is already over-loaded.


On Tue, 13 Dec 2005, Tony Plate wrote:

> Yes, 0/1 (numeric) are intended to be used as index vectors -- and they
> have the semantics of numeric indices, which is that 0 elements in the
> index are omitted from the result.  This can be a very useful mode of
> operation in many situations.
>
> I was going to write "This is described in both the introduction to R,
> and in the documentation for '['", except that I checked before I wrote
> and was surprised to be unable to any discussion of zeros in indexing in
> any of the first three places I looked:
>
> (1) help page for '[' (There is discussion of zero indices here, but
> only in the context of using matrices to index matrices, not in the
> context of ordinary vector indices).
>
> (2) Section 2.7 "Index vectors: selecting and modifying subsets of a
> data set" in "An Introduction to R", which does say this about numeric
> indices:
>     2. A vector of positive integral quantities. In
>        this case the values in the index vector must
>        lie in the set {1, 2, . . . , length(x)}
> (This seems to commit the sin of not telling the whole truth.)

No. Zero is not a positive integer.

> (3) Section 5.5 "Array Indexing.  Subsections of an array" (In "An
> Introduction to R")
>
> Question for others: did I miss something obvious, or is this a
> documentation deficiency that zeros in indices are not discussed in 3 of
> some obvious first places to look?
>
> If indeed this is a documentation deficiency, I'm happy to contribute
> documentation patch, but I await other opinions before spending any time
> on that.
>
> -- Tony Plate
>
> rasche at molgen.mpg.de wrote:
>> Full_Name: Axel Rasche
>> Version: 2.2.0
>> OS: Linux
>> Submission from: (NULL) (141.14.21.81)
>>
>>
>> Dear Debuggers,
>>
>> This is not a serious problem. Are 0/1 vectors intended to be used as index
>> vectors? If yes, there is a bug. If not, it leads just to some funny behaviour
>> rather than an error message.
>>
>> In the appendix is some simple code to reproduce the problem. A logical vector
>> as.logic(a) helps by indexing the vector b. The 0/1 vector a just returns the
>> first value "a". But as many times as there is a 1 in a.
>>
>> Best regards,
>> Axel
>>
>>
>> Appendix:
>>
>> b = c("a","b","c","d")
>> a = c(0,1,1,0)
>> b[as.logical(a)]
>> b[a]
>> a = c(1,0,1,0)
>> b[as.logical(a)]
>> b[a]
>> a = c(0,1,1,1)
>> b[as.logical(a)]
>> b[a]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Tue Dec 13 22:15:52 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 13 Dec 2005 21:15:52 +0000 (GMT)
Subject: [Rd] R_PROFILE on Windows
In-Reply-To: <20051213181620.GA18323@ime.usp.br>
References: <20051213181620.GA18323@ime.usp.br>
Message-ID: <Pine.LNX.4.61.0512132110470.30916@gannet.stats>

On Tue, 13 Dec 2005, Fernando Henrique Ferraz P. da Rosa wrote:

>        There seems to be a bug in the Startup section, regarding the
> R_PROFILE environment variable in Windows. If not a bug in the Startup
> itself, perhaps a bug in the documentation.

Nope, it works as documented, using exactly the same code as on Linux. 
You do not tell us your shell here (so I presume it is XP's cmd.exe), but 
you seem to have set R_PROFILE to a string enclosed in quotes (as the R 
output shows).  Try

 	RGui.exe R_PROFILE=C:/fernando/R.profile

I am in the same boat, and so I use tcsh/sh on Windows to be sure I 
understand the quoting rules.

>        According to ?Startup:
>
>       Then R searches for the site-wide startup profile unless the
>       command line option '--no-site-file' was given.  The name of this
>       file is taken from the value of the 'R_PROFILE' environment
>       variable. If this variable is unset, the default is
>       '$R_HOME/etc/Rprofile.site'
>
>        On Windows XP, I created a batch file with the following lines:
>
>        SET R_PROFILE="C:\fernando\R.profile"
>        "C:\progs\R-2.2.0\bin\Rgui.exe"
>
>        On c:\fernando\R.profile I had:
>
>        options(foo='bar')
>
>        Running the batch file I created I get, in R:
>
>        > options()$foo
>        NULL
>        >Sys.getenv("R_PROFILE")
>                           R_PROFILE
>        "\"c:\\fernando\\R.profile\""
           ^^                       ^^

>
>        I've tried using slashes instead of backslashes
> (fernando/R.profile), double blackslashes (fernando\\R.profile) but it
> seems there's no way to make it work.
>
>        The only way I could manage to have R read the profile was
> renaming R.profile to .Rprofile and starting R on the directory the
> .Rprofile was located.
>
>        Is this really the intended behaviour? If so, what's the
> correct way to specify the R_PROFILE variable and have R use it on
> Windows?
>
>        Ps: I've tested it on R 2.2.0 and on r-devel r36675, on Windows
> XP SP2. Sorry if this is a non-bug. I'm a poor linux user trying to
> survive on Windows, so I might have overloooked something.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Tue Dec 13 22:48:56 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 13 Dec 2005 21:48:56 +0000 (GMT)
Subject: [Rd] Building R with f2c - still needed?
Message-ID: <Pine.LNX.4.61.0512132144190.15384@gannet.stats>

Does anyone have a need to use f2c rather than a Fortran compiler to build 
R?

It is yet one more thing to test, and as it only works on 32-bit platforms 
it is something that I will shortly no longer be able to test.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.dalgaard at biostat.ku.dk  Wed Dec 14 00:26:49 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 14 Dec 2005 00:26:49 +0100
Subject: [Rd] Building R with f2c - still needed?
In-Reply-To: <Pine.LNX.4.61.0512132144190.15384@gannet.stats>
References: <Pine.LNX.4.61.0512132144190.15384@gannet.stats>
Message-ID: <x2oe3ky3wm.fsf@turmalin.kubism.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> Does anyone have a need to use f2c rather than a Fortran compiler to build 
> R?
> 
> It is yet one more thing to test, and as it only works on 32-bit platforms 
> it is something that I will shortly no longer be able to test.


The only candidate that I can think of is the PDA scene, which R has
been just a little too hard to build for till now (Linux based Zaurus
excepted). For those platforms you could be stuck with only a C/C++
compiler, but probably also without all the rest of the toolchain, so
building will be a major headache anyway.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From edd at debian.org  Wed Dec 14 00:37:10 2005
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 13 Dec 2005 17:37:10 -0600
Subject: [Rd] Building R with f2c - still needed?
In-Reply-To: <Pine.LNX.4.61.0512132144190.15384@gannet.stats>
References: <Pine.LNX.4.61.0512132144190.15384@gannet.stats>
Message-ID: <20051213233710.GA470@eddelbuettel.com>

On Tue, Dec 13, 2005 at 09:48:56PM +0000, Prof Brian Ripley wrote:
> Does anyone have a need to use f2c rather than a Fortran compiler to build 
> R?

We used f2c up until a few months ago as a last line of defence against
crappy Fg77 code on m68k/arm (one or both, it changed at times).

I'd be hesitant about throwing it out, but it is of course your call.

Thanks, Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From nakama at ki.rim.or.jp  Wed Dec 14 02:16:13 2005
From: nakama at ki.rim.or.jp (Ei-ji Nakama)
Date: Wed, 14 Dec 2005 10:16:13 +0900 (JST)
Subject: [Rd] R-beta on AIX5.2
Message-ID: <20051214.101613.607958713.nakama@ki.rim.or.jp>

I build R-beta on AIX5.2 is failed.

make[3]: Entering directory
`/home/nakama/Rbeta/R-beta/src/nmath'
xlc_r -I. -I../../src/include -I../../src/include -I/usr/local/include
-I/opt/freeware/include -DHAVE_CONFIG_H   -q64 -I/usr/local/include
-I/opt/freeware/include -O2 -D_ALL_SOURCE -D_LINUX_SOURCE_COMPAT -c
mlutils.c -o mlutils.o
"nmath.h", line 50.9: 1506-213 (S) Macro name calloc cannot be
redefined.
"nmath.h", line 50.9: 1506-358 (I) "calloc" is defined on line 641 of
/usr/include/stdlib.h.
make[3]: *** [mlutils.o] Error 1


--- R-beta.orig/src/nmath/nmath.h	2005-10-06 19:25:25.000000000 +0900
+++ R-beta/src/nmath/nmath.h	2005-12-13 19:33:59.000000000 +0900
@@ -47,6 +47,7 @@
 #define ML_NAN		R_NaN
 
 void R_CheckUserInterrupt(void);
+#undef  calloc
 #define calloc R_chk_calloc
 #define free R_chk_free
 

--
http://www.nakama.ne.jp, http://r.nakama.ne.jp
e-mail : EIJI Nakama <nakama at ki.rim.or.jp>


From ripley at stats.ox.ac.uk  Wed Dec 14 08:06:07 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 14 Dec 2005 07:06:07 +0000 (GMT)
Subject: [Rd] R-beta on AIX5.2
In-Reply-To: <20051214.101613.607958713.nakama@ki.rim.or.jp>
References: <20051214.101613.607958713.nakama@ki.rim.or.jp>
Message-ID: <Pine.LNX.4.61.0512140702520.21960@gannet.stats>

Thank you.  To avoid error messages on other platforms, we will use

#ifdef calloc
# undef calloc
#endif

(and similarly for free for completeness).

On Wed, 14 Dec 2005, Ei-ji Nakama wrote:

> I build R-beta on AIX5.2 is failed.
>
> make[3]: Entering directory
> `/home/nakama/Rbeta/R-beta/src/nmath'
> xlc_r -I. -I../../src/include -I../../src/include -I/usr/local/include
> -I/opt/freeware/include -DHAVE_CONFIG_H   -q64 -I/usr/local/include
> -I/opt/freeware/include -O2 -D_ALL_SOURCE -D_LINUX_SOURCE_COMPAT -c
> mlutils.c -o mlutils.o
> "nmath.h", line 50.9: 1506-213 (S) Macro name calloc cannot be
> redefined.
> "nmath.h", line 50.9: 1506-358 (I) "calloc" is defined on line 641 of
> /usr/include/stdlib.h.
> make[3]: *** [mlutils.o] Error 1
>
>
> --- R-beta.orig/src/nmath/nmath.h	2005-10-06 19:25:25.000000000 +0900
> +++ R-beta/src/nmath/nmath.h	2005-12-13 19:33:59.000000000 +0900
> @@ -47,6 +47,7 @@
> #define ML_NAN		R_NaN
>
> void R_CheckUserInterrupt(void);
> +#undef  calloc
> #define calloc R_chk_calloc
> #define free R_chk_free
>
>
> --
> http://www.nakama.ne.jp, http://r.nakama.ne.jp
> e-mail : EIJI Nakama <nakama at ki.rim.or.jp>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From paul.hewson at plymouth.ac.uk  Wed Dec 14 09:35:07 2005
From: paul.hewson at plymouth.ac.uk (Paul Hewson)
Date: Wed, 14 Dec 2005 08:35:07 -0000
Subject: [Rd] CRAN task view: Multivariate
Message-ID: <52A8091888A23F47A013223014B6E9FE074B22AA@03-CSEXCH.uopnet.plymouth.ac.uk>

Hello,

I've assembled a Multivariate ctv (with a lot of help from Achim Zeleis,
who has now posted the view on CRAN).

I'd be grateful for comments regarding missing packages / functions.
Opinions on the organisation of the view would also be appreciated, as
well as having any errors pointed out.   I've adopted a rather broad and
vague definition of "multivariate", which may not be optimal.

Thanks

Paul

-=-=-=-=-=-=-=-=-=-=-=-=
Paul Hewson 
Senior Lecturer in Statistics 
School of Mathematics and Statistics 
University of Plymouth 
Drake Circus 
Plymouth PL4 8AA 

tel (01752) 232778 (Campus) 
tel (01752) 764437 (Tamar Science Park) 
fax (01752) 232780 

email: paul.hewson at plymouth.ac.uk
web: http://www.plymouth.ac.uk/staff/phewson


From bhs2 at mevik.net  Wed Dec 14 13:12:10 2005
From: bhs2 at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge_Mevik?=)
Date: Wed, 14 Dec 2005 13:12:10 +0100
Subject: [Rd] R-beta: configure problem (tcltk) on 64 bit Red Hat EL
Message-ID: <m0irtryj1h.fsf@bar.nemo-project.org>

Dear developeRs,

I use Red Hat Enterprise Linux WS release 4 (Nahant Update 2) on an
x86_64 machine (two Intel P4 CPUs with 64 bit support), and
R-beta_2005-12-12_r36712.tar.gz.

If I run configure without any options, it does not list tcltk among
the supported interfaces:

./configure
[...]
R is now configured for x86_64-unknown-linux-gnu

  Source directory:          .
  Installation directory:    /usr/local

  C compiler:                gcc  -g -O2
  C++ compiler:              g++  -g -O2
  Fortran compiler:          g77  -g -O2

  Interfaces supported:      X11
  External libraries:        readline, BLAS(generic)
  Additional capabilities:   PNG, JPEG, iconv, MBCS, NLS
  Options enabled:           R profiling

  Recommended packages:      yes

It seems to find tcl and tk, but not be able to compile/link them:
[...]
checking /usr/include/tcl.h usability... yes
checking /usr/include/tcl.h presence... yes
checking for /usr/include/tcl.h... yes
[...]
checking /usr/include/tk.h usability... yes
checking /usr/include/tk.h presence... yes
checking for /usr/include/tk.h... yes
checking whether compiling/linking Tcl/Tk code works... no


Looking in config.log, it seems that even though libX11 has been found
in /usr/X11R6/lib64, it is not searched for in that directory when
testing compiling/linking Tcl/Tk:

configure:35654: checking for X
configure:35892: result: libraries /usr/X11R6/lib64, headers /usr/X11R6/include
configure:36088: gcc -o conftest -g -O2  -I/usr/local/include -L/usr/local/lib64 conftest.c -ldl -lm   -L/usr/X11R6/lib64 -lX11 >&5
configure:36094: $? = 0
configure:36098: test -z
                         || test ! -s conftest.err
configure:36101: $? = 0
configure:36104: test -s conftest
configure:36107: $? = 0
[...]
configure:38437: checking whether compiling/linking Tcl/Tk code works
configure:38480: gcc -o conftest -g -O2  -I/usr/local/include -I/usr/include -I/usr/include -I/usr/X11R6/include -L/usr/local/lib64 conftest.c -ldl -lm  -L/usr/lib -ltcl8.4 -L/usr/lib -ltk8.4 -L/usr/X11R6/lib -lX11 >&5
/usr/bin/ld: skipping incompatible /usr/lib/libtcl8.4.so when searching for -ltcl8.4
/usr/bin/ld: skipping incompatible /usr/lib/libtcl8.4.so when searching for -ltcl8.4
/usr/bin/ld: skipping incompatible /usr/lib/libtk8.4.so when searching for -ltk8.4
/usr/bin/ld: skipping incompatible /usr/lib/libtk8.4.so when searching for -ltk8.4
/usr/bin/ld: cannot find -lX11
collect2: ld returned 1 exit status
configure:38486: $? = 1

Running ./configure LDFLAGS="-L/usr/local/lib64  -L/usr/X11R6/lib64"
solves/avoids the problem for me.

I thought I'd report the problem anyway, since I don't know if it is the
intended behaviour of configure.


-- 
Sincerely,
Bj?rn-Helge Mevik


From ripley at stats.ox.ac.uk  Wed Dec 14 13:58:22 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 14 Dec 2005 12:58:22 +0000 (GMT)
Subject: [Rd] R-beta: configure problem (tcltk) on 64 bit Red Hat EL
In-Reply-To: <m0irtryj1h.fsf@bar.nemo-project.org>
References: <m0irtryj1h.fsf@bar.nemo-project.org>
Message-ID: <Pine.LNX.4.61.0512141251510.27887@gannet.stats>

Yes, the R-admin manual warns of this.

It is a problem with your particular OS, as e.g. FC3 does

checking for tclConfig.sh... no
checking for tclConfig.sh in library (sub)directories... 
/usr/lib64/tclConfig.sh
checking for tkConfig.sh... no
checking for tkConfig.sh in library (sub)directories... 
/usr/lib64/tkConfig.sh

and that config file has

# Additional libraries to use when linking Tk.
TK_LIBS='-L/usr/X11R6/lib64 -lX11 -ldl  -lieee -lm'

Unfortunately you have removed the crucial parts of where your configure 
got the configuration info from.


On Wed, 14 Dec 2005, Bj?rn-Helge Mevik wrote:

> Dear developeRs,
>
> I use Red Hat Enterprise Linux WS release 4 (Nahant Update 2) on an
> x86_64 machine (two Intel P4 CPUs with 64 bit support), and
> R-beta_2005-12-12_r36712.tar.gz.
>
> If I run configure without any options, it does not list tcltk among
> the supported interfaces:
>
> ./configure
> [...]
> R is now configured for x86_64-unknown-linux-gnu
>
>  Source directory:          .
>  Installation directory:    /usr/local
>
>  C compiler:                gcc  -g -O2
>  C++ compiler:              g++  -g -O2
>  Fortran compiler:          g77  -g -O2
>
>  Interfaces supported:      X11
>  External libraries:        readline, BLAS(generic)
>  Additional capabilities:   PNG, JPEG, iconv, MBCS, NLS
>  Options enabled:           R profiling
>
>  Recommended packages:      yes
>
> It seems to find tcl and tk, but not be able to compile/link them:
> [...]
> checking /usr/include/tcl.h usability... yes
> checking /usr/include/tcl.h presence... yes
> checking for /usr/include/tcl.h... yes
> [...]
> checking /usr/include/tk.h usability... yes
> checking /usr/include/tk.h presence... yes
> checking for /usr/include/tk.h... yes
> checking whether compiling/linking Tcl/Tk code works... no
>
>
> Looking in config.log, it seems that even though libX11 has been found
> in /usr/X11R6/lib64, it is not searched for in that directory when
> testing compiling/linking Tcl/Tk:
>
> configure:35654: checking for X
> configure:35892: result: libraries /usr/X11R6/lib64, headers /usr/X11R6/include
> configure:36088: gcc -o conftest -g -O2  -I/usr/local/include -L/usr/local/lib64 conftest.c -ldl -lm   -L/usr/X11R6/lib64 -lX11 >&5
> configure:36094: $? = 0
> configure:36098: test -z
>                         || test ! -s conftest.err
> configure:36101: $? = 0
> configure:36104: test -s conftest
> configure:36107: $? = 0
> [...]
> configure:38437: checking whether compiling/linking Tcl/Tk code works
> configure:38480: gcc -o conftest -g -O2  -I/usr/local/include -I/usr/include -I/usr/include -I/usr/X11R6/include -L/usr/local/lib64 conftest.c -ldl -lm  -L/usr/lib -ltcl8.4 -L/usr/lib -ltk8.4 -L/usr/X11R6/lib -lX11 >&5
> /usr/bin/ld: skipping incompatible /usr/lib/libtcl8.4.so when searching for -ltcl8.4
> /usr/bin/ld: skipping incompatible /usr/lib/libtcl8.4.so when searching for -ltcl8.4
> /usr/bin/ld: skipping incompatible /usr/lib/libtk8.4.so when searching for -ltk8.4
> /usr/bin/ld: skipping incompatible /usr/lib/libtk8.4.so when searching for -ltk8.4
> /usr/bin/ld: cannot find -lX11
> collect2: ld returned 1 exit status
> configure:38486: $? = 1
>
> Running ./configure LDFLAGS="-L/usr/local/lib64  -L/usr/X11R6/lib64"
> solves/avoids the problem for me.
>
> I thought I'd report the problem anyway, since I don't know if it is the
> intended behaviour of configure.
>
>
> -- 
> Sincerely,
> Bj?rn-Helge Mevik
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From rpeng at jhsph.edu  Wed Dec 14 15:19:07 2005
From: rpeng at jhsph.edu (Roger Peng)
Date: Wed, 14 Dec 2005 09:19:07 -0500
Subject: [Rd] Building R-devel with ACML
Message-ID: <43A029DB.9090709@jhsph.edu>

I'm trying to build R-devel with AMD's ACML.  I downloaded version 3.0.0 
64bit for gfortran (acml-3-0-0-gfortran-64bit.tgz) and copied the 
libraries to /usr/local/lib.  When I configure R to build against the 
ACML library, how do I know if the library has been detected and will be 
used?

I run 'configure' with the '--with-blas=-lacml' flag and am using gcc 
4.0.2 (with gfortran) on FC4.

Thanks,
-roger
-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/


From ripley at stats.ox.ac.uk  Wed Dec 14 15:43:56 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 14 Dec 2005 14:43:56 +0000 (GMT)
Subject: [Rd] Building R-devel with ACML
In-Reply-To: <43A029DB.9090709@jhsph.edu>
References: <43A029DB.9090709@jhsph.edu>
Message-ID: <Pine.LNX.4.61.0512141440430.2917@gannet.stats>

On Wed, 14 Dec 2005, Roger Peng wrote:

> I'm trying to build R-devel with AMD's ACML.  I downloaded version 3.0.0
> 64bit for gfortran (acml-3-0-0-gfortran-64bit.tgz) and copied the
> libraries to /usr/local/lib.  When I configure R to build against the
> ACML library, how do I know if the library has been detected and will be
> used?

Look at the end of the output (will say BLAS(generic)) and at BLAS_LIBS in 
Makeconf.

> I run 'configure' with the '--with-blas=-lacml' flag and am using gcc
> 4.0.2 (with gfortran) on FC4.

On my such system with --with-lapack I got

   External libraries:        readline, BLAS(generic), LAPACK(in blas)

BLAS_LIBS = -L/usr/local/acml/gnu64/lib -lacml

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Chad.P.Jenness at wellsfargo.com  Wed Dec 14 15:52:08 2005
From: Chad.P.Jenness at wellsfargo.com (Chad.P.Jenness@wellsfargo.com)
Date: Wed, 14 Dec 2005 08:52:08 -0600
Subject: [Rd] Linking C/C++ GUI to R.dll
Message-ID: <FB8EAA6054D93C468B34261C0F0673D748CE44@msgswbmnmsp23.wellsfargo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20051214/0318615f/attachment.pl

From ripley at stats.ox.ac.uk  Wed Dec 14 16:49:10 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 14 Dec 2005 15:49:10 +0000 (GMT)
Subject: [Rd] Linking C/C++ GUI to R.dll
In-Reply-To: <FB8EAA6054D93C468B34261C0F0673D748CE44@msgswbmnmsp23.wellsfargo.com>
References: <FB8EAA6054D93C468B34261C0F0673D748CE44@msgswbmnmsp23.wellsfargo.com>
Message-ID: <Pine.LNX.4.61.0512141547420.3755@gannet.stats>

On Wed, 14 Dec 2005 Chad.P.Jenness at wellsfargo.com wrote:

> Hi,
>
> I am in the process of linking a C/C++ application to the R.dll
> directly.  I have obtained the R source code and compiled it
> successfully.  I have also successfully linked the R.dll directly into
> our application and have made calls successfully into the R.dll that are
> included in the sample rtest.c and in the "Writing R Extensions - The R
> API".
>
> The R functionality that we are interested in embedding into our
> application is the data analysis and graphics.  However, I did not see
> any references to this in the R API section of the documentation.  Is
> this functionality available from our C/C++ application via the R.dll?
> If so, how do we access this functionality?

By reading the section on 'linking GUIs and other front-ends'.  It is not 
in the C-level API.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.dalgaard at biostat.ku.dk  Wed Dec 14 16:50:55 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 14 Dec 2005 16:50:55 +0100
Subject: [Rd] CRAN task view: Multivariate
In-Reply-To: <52A8091888A23F47A013223014B6E9FE074B22AA@03-CSEXCH.uopnet.plymouth.ac.uk>
References: <52A8091888A23F47A013223014B6E9FE074B22AA@03-CSEXCH.uopnet.plymouth.ac.uk>
Message-ID: <x2d5jz7k4g.fsf@viggo.kubism.ku.dk>

"Paul Hewson" <paul.hewson at plymouth.ac.uk> writes:

> Hello,
> 
> I've assembled a Multivariate ctv (with a lot of help from Achim Zeleis,
> who has now posted the view on CRAN).
> 
> I'd be grateful for comments regarding missing packages / functions.
> Opinions on the organisation of the view would also be appreciated, as
> well as having any errors pointed out.   I've adopted a rather broad and
> vague definition of "multivariate", which may not be optimal.

Anova.mlm and mauchley.test from stats seem conspicuously absent.

 
> Thanks
> 
> Paul
> 
> -=-=-=-=-=-=-=-=-=-=-=-=
> Paul Hewson 
> Senior Lecturer in Statistics 
> School of Mathematics and Statistics 
> University of Plymouth 
> Drake Circus 
> Plymouth PL4 8AA 
> 
> tel (01752) 232778 (Campus) 
> tel (01752) 764437 (Tamar Science Park) 
> fax (01752) 232780 
> 
> email: paul.hewson at plymouth.ac.uk
> web: http://www.plymouth.ac.uk/staff/phewson
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From Chad.P.Jenness at wellsfargo.com  Wed Dec 14 17:39:31 2005
From: Chad.P.Jenness at wellsfargo.com (Chad.P.Jenness@wellsfargo.com)
Date: Wed, 14 Dec 2005 10:39:31 -0600
Subject: [Rd] Linking C/C++ GUI to R.dll
Message-ID: <FB8EAA6054D93C468B34261C0F0673D779612E@msgswbmnmsp23.wellsfargo.com>

Is there any way that we can get it to the C level API?  Or is there a C
level API function that will give us access to more of the R
functionality?

Chad Jenness
Electronic Payment Business Services
Office: 612-667-9782
Email: Chad.P.Jenness at WellsFargo.com

"This message may contain confidential and/or privileged information.
If you are not the addressee or authorized to receive this for the
addressee, you must not use, copy, disclose, or take any action based on
this message or any information herein.  If you have received this
message in error, please advise the sender immediately by reply e-mail
and delete this message.  Thank you for your cooperation"


-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
Sent: Wednesday, December 14, 2005 9:49 AM
To: Jenness, Chad P.
Cc: r-devel at stat.math.ethz.ch
Subject: Re: [Rd] Linking C/C++ GUI to R.dll


On Wed, 14 Dec 2005 Chad.P.Jenness at wellsfargo.com wrote:

> Hi,
>
> I am in the process of linking a C/C++ application to the R.dll 
> directly.  I have obtained the R source code and compiled it 
> successfully.  I have also successfully linked the R.dll directly into

> our application and have made calls successfully into the R.dll that 
> are included in the sample rtest.c and in the "Writing R Extensions - 
> The R API".
>
> The R functionality that we are interested in embedding into our 
> application is the data analysis and graphics.  However, I did not see

> any references to this in the R API section of the documentation.  Is 
> this functionality available from our C/C++ application via the R.dll?

> If so, how do we access this functionality?

By reading the section on 'linking GUIs and other front-ends'.  It is
not 
in the C-level API.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jinghuazhao at hotmail.com  Wed Dec 14 17:57:55 2005
From: jinghuazhao at hotmail.com (jing hua zhao)
Date: Wed, 14 Dec 2005 16:57:55 +0000
Subject: [Rd] R 2.2.0 + Oracle 10g + Windows XP
Message-ID: <BAY108-F35974059F2D2C95CE18CB2A5380@phx.gbl>

Dear R-devlopers,

I am experiencing problem with R 2.2.0 after installing Oracle 10g on my 
Windows XP system. It simply crashes but Rgui appears to be functioning. 
After I deinstalling Oracle 10g, R.exe start to function again. Any idea how 
to make them both working?

Many thanks,


Jinghua


From tplate at acm.org  Wed Dec 14 18:39:24 2005
From: tplate at acm.org (Tony Plate)
Date: Wed, 14 Dec 2005 10:39:24 -0700
Subject: [Rd] 0/1 vector for indexing leads to funny behaviour (PR#8389)
 (maybe a documentation deficiency?)
In-Reply-To: <Pine.LNX.4.61.0512132104090.9376@gannet.stats>
References: <20051213150515.175B8A3C7@slim.kubism.ku.dk>
	<439F0D24.1080701@acm.org>
	<Pine.LNX.4.61.0512132104090.9376@gannet.stats>
Message-ID: <43A058CC.4010605@acm.org>

I appreciate the explanation that some details should not appear in the 
help pages or the Introduction to R manual.

However, I am puzzled by this part of Prof Ripley's response:

TP> [...] "An Introduction to R" [...] says this about
TP> numeric indices:
TP>     2. A vector of positive integral quantities. In
TP>        this case the values in the index vector must
TP>        lie in the set {1, 2, . . . , length(x)}
TP> (This seems to commit the sin of not telling the whole truth.)

BDR> No. Zero is not a positive integer.

That's what I was trying to say: the whole truth is that numeric index 
vectors that contain positive integral quantities can also contain 
zeros.  Upon rereading this passage yet again, I think it is more 
misleading than merely incomplete: the phrasings "positive integral 
quantities", and "*must* lie in the set ..." rule out the possibility of 
the vector containing zeros.

In this Section 2.7 in "An Introduction to R", the four types of index 
vectors are introduced with "Such index vectors can be any of four 
distinct types:". There is not even a hint that other types of index 
vectors can be used (e.g., positive integral quantities and zeros).  Is 
this really correct and helpful?  (The only way that I can see that this 
section can be interpreted as correct is to claim that that the phrasing 
"can be any of four distinct types" permits the existence of other types 
that are neither described nor hinted at.  However, this interpretation 
feels more clever than helpful.)

Tony Plate

Prof Brian Ripley wrote:
> ?"[" says
> 
> See Also:
> 
>      'list', 'array', 'matrix'.
> 
>      '[.data.frame' and '[.factor' for the behaviour when applied to
>      data.frame and factors.
> 
>      'Syntax' for operator precedence, and the _R Language_ reference
>      manual about indexing details.
> 
> and the `indexing details' are indeed where it says they are.
> 
> This is not an introductory topic, and it makes sense to have the 
> details in only one place and refer to it.  That help page is already 
> over-loaded.
> 
> 
> On Tue, 13 Dec 2005, Tony Plate wrote:
> 
>> Yes, 0/1 (numeric) are intended to be used as index vectors -- and they
>> have the semantics of numeric indices, which is that 0 elements in the
>> index are omitted from the result.  This can be a very useful mode of
>> operation in many situations.
>>
>> I was going to write "This is described in both the introduction to R,
>> and in the documentation for '['", except that I checked before I wrote
>> and was surprised to be unable to any discussion of zeros in indexing in
>> any of the first three places I looked:
>>
>> (1) help page for '[' (There is discussion of zero indices here, but
>> only in the context of using matrices to index matrices, not in the
>> context of ordinary vector indices).
>>
>> (2) Section 2.7 "Index vectors: selecting and modifying subsets of a
>> data set" in "An Introduction to R", which does say this about numeric
>> indices:
>>     2. A vector of positive integral quantities. In
>>        this case the values in the index vector must
>>        lie in the set {1, 2, . . . , length(x)}
>> (This seems to commit the sin of not telling the whole truth.)
> 
> 
> No. Zero is not a positive integer.
> 
>> (3) Section 5.5 "Array Indexing.  Subsections of an array" (In "An
>> Introduction to R")
>>
>> Question for others: did I miss something obvious, or is this a
>> documentation deficiency that zeros in indices are not discussed in 3 of
>> some obvious first places to look?
>>
>> If indeed this is a documentation deficiency, I'm happy to contribute
>> documentation patch, but I await other opinions before spending any time
>> on that.
>>
>> -- Tony Plate
>>
>> rasche at molgen.mpg.de wrote:
>>
>>> Full_Name: Axel Rasche
>>> Version: 2.2.0
>>> OS: Linux
>>> Submission from: (NULL) (141.14.21.81)
>>>
>>>
>>> Dear Debuggers,
>>>
>>> This is not a serious problem. Are 0/1 vectors intended to be used as 
>>> index
>>> vectors? If yes, there is a bug. If not, it leads just to some funny 
>>> behaviour
>>> rather than an error message.
>>>
>>> In the appendix is some simple code to reproduce the problem. A 
>>> logical vector
>>> as.logic(a) helps by indexing the vector b. The 0/1 vector a just 
>>> returns the
>>> first value "a". But as many times as there is a 1 in a.
>>>
>>> Best regards,
>>> Axel
>>>
>>>
>>> Appendix:
>>>
>>> b = c("a","b","c","d")
>>> a = c(0,1,1,0)
>>> b[as.logical(a)]
>>> b[a]
>>> a = c(1,0,1,0)
>>> b[as.logical(a)]
>>> b[a]
>>> a = c(0,1,1,1)
>>> b[as.logical(a)]
>>> b[a]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>


From p.dalgaard at biostat.ku.dk  Wed Dec 14 18:56:52 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 14 Dec 2005 18:56:52 +0100
Subject: [Rd] 0/1 vector for indexing leads to funny behaviour (PR#8389)
	(maybe a documentation deficiency?)
In-Reply-To: <43A058CC.4010605@acm.org>
References: <20051213150515.175B8A3C7@slim.kubism.ku.dk>
	<439F0D24.1080701@acm.org>
	<Pine.LNX.4.61.0512132104090.9376@gannet.stats>
	<43A058CC.4010605@acm.org>
Message-ID: <x27ja7imu3.fsf@turmalin.kubism.ku.dk>

Tony Plate <tplate at acm.org> writes:

> I appreciate the explanation that some details should not appear in the 
> help pages or the Introduction to R manual.
> 
> However, I am puzzled by this part of Prof Ripley's response:
> 
> TP> [...] "An Introduction to R" [...] says this about
> TP> numeric indices:
> TP>     2. A vector of positive integral quantities. In
> TP>        this case the values in the index vector must
> TP>        lie in the set {1, 2, . . . , length(x)}
> TP> (This seems to commit the sin of not telling the whole truth.)
> 
> BDR> No. Zero is not a positive integer.

I wondered too. I suppose one interpretation is, No, it's not just not
telling the whole truth, it's outright false! Alternatively, it could
be that 2. is OK as written, but there needs to be entries for the
nonnegative/nonpositive cases. Or - perish the thought - that Brian
made a blunder...
 
> That's what I was trying to say: the whole truth is that numeric index 
> vectors that contain positive integral quantities can also contain 
> zeros.  Upon rereading this passage yet again, I think it is more 
> misleading than merely incomplete: the phrasings "positive integral 
> quantities", and "*must* lie in the set ..." rule out the possibility of 
> the vector containing zeros.
> 
> In this Section 2.7 in "An Introduction to R", the four types of index 
> vectors are introduced with "Such index vectors can be any of four 
> distinct types:". There is not even a hint that other types of index 
> vectors can be used (e.g., positive integral quantities and zeros).  Is 
> this really correct and helpful?  (The only way that I can see that this 
> section can be interpreted as correct is to claim that that the phrasing 
> "can be any of four distinct types" permits the existence of other types 
> that are neither described nor hinted at.  However, this interpretation 
> feels more clever than helpful.)
> 
> Tony Plate
> 
> Prof Brian Ripley wrote:
> > ?"[" says
> > 
> > See Also:
> > 
> >      'list', 'array', 'matrix'.
> > 
> >      '[.data.frame' and '[.factor' for the behaviour when applied to
> >      data.frame and factors.
> > 
> >      'Syntax' for operator precedence, and the _R Language_ reference
> >      manual about indexing details.
> > 
> > and the `indexing details' are indeed where it says they are.
> > 
> > This is not an introductory topic, and it makes sense to have the 
> > details in only one place and refer to it.  That help page is already 
> > over-loaded.
> > 
> > 
> > On Tue, 13 Dec 2005, Tony Plate wrote:
> > 
> >> Yes, 0/1 (numeric) are intended to be used as index vectors -- and they
> >> have the semantics of numeric indices, which is that 0 elements in the
> >> index are omitted from the result.  This can be a very useful mode of
> >> operation in many situations.
> >>
> >> I was going to write "This is described in both the introduction to R,
> >> and in the documentation for '['", except that I checked before I wrote
> >> and was surprised to be unable to any discussion of zeros in indexing in
> >> any of the first three places I looked:
> >>
> >> (1) help page for '[' (There is discussion of zero indices here, but
> >> only in the context of using matrices to index matrices, not in the
> >> context of ordinary vector indices).
> >>
> >> (2) Section 2.7 "Index vectors: selecting and modifying subsets of a
> >> data set" in "An Introduction to R", which does say this about numeric
> >> indices:
> >>     2. A vector of positive integral quantities. In
> >>        this case the values in the index vector must
> >>        lie in the set {1, 2, . . . , length(x)}
> >> (This seems to commit the sin of not telling the whole truth.)
> > 
> > 
> > No. Zero is not a positive integer.
> > 
> >> (3) Section 5.5 "Array Indexing.  Subsections of an array" (In "An
> >> Introduction to R")
> >>
> >> Question for others: did I miss something obvious, or is this a
> >> documentation deficiency that zeros in indices are not discussed in 3 of
> >> some obvious first places to look?
> >>
> >> If indeed this is a documentation deficiency, I'm happy to contribute
> >> documentation patch, but I await other opinions before spending any time
> >> on that.
> >>
> >> -- Tony Plate
> >>
> >> rasche at molgen.mpg.de wrote:
> >>
> >>> Full_Name: Axel Rasche
> >>> Version: 2.2.0
> >>> OS: Linux
> >>> Submission from: (NULL) (141.14.21.81)
> >>>
> >>>
> >>> Dear Debuggers,
> >>>
> >>> This is not a serious problem. Are 0/1 vectors intended to be used as 
> >>> index
> >>> vectors? If yes, there is a bug. If not, it leads just to some funny 
> >>> behaviour
> >>> rather than an error message.
> >>>
> >>> In the appendix is some simple code to reproduce the problem. A 
> >>> logical vector
> >>> as.logic(a) helps by indexing the vector b. The 0/1 vector a just 
> >>> returns the
> >>> first value "a". But as many times as there is a 1 in a.
> >>>
> >>> Best regards,
> >>> Axel
> >>>
> >>>
> >>> Appendix:
> >>>
> >>> b = c("a","b","c","d")
> >>> a = c(0,1,1,0)
> >>> b[as.logical(a)]
> >>> b[a]
> >>> a = c(1,0,1,0)
> >>> b[as.logical(a)]
> >>> b[a]
> >>> a = c(0,1,1,1)
> >>> b[as.logical(a)]
> >>> b[a]
> >>>
> >>> ______________________________________________
> >>> R-devel at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >>
> >
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From Chad.P.Jenness at wellsfargo.com  Wed Dec 14 19:27:06 2005
From: Chad.P.Jenness at wellsfargo.com (Chad.P.Jenness@wellsfargo.com)
Date: Wed, 14 Dec 2005 12:27:06 -0600
Subject: [Rd] Linking C/C++ GUI to R.dll
Message-ID: <FB8EAA6054D93C468B34261C0F0673D7796133@msgswbmnmsp23.wellsfargo.com>

Is there any way that we can get it to the C level API?  Or is there a C
level API function that will give us access to more of the R
functionality?  Also, is there a series of examples on how to use the C
level API?

Chad Jenness
Electronic Payment Business Services
Office: 612-667-9782
Email: Chad.P.Jenness at WellsFargo.com

"This message may contain confidential and/or privileged information.
If you are not the addressee or authorized to receive this for the
addressee, you must not use, copy, disclose, or take any action based on
this message or any information herein.  If you have received this
message in error, please advise the sender immediately by reply e-mail
and delete this message.  Thank you for your cooperation"


-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
Sent: Wednesday, December 14, 2005 9:49 AM
To: Jenness, Chad P.
Cc: r-devel at stat.math.ethz.ch
Subject: Re: [Rd] Linking C/C++ GUI to R.dll


On Wed, 14 Dec 2005 Chad.P.Jenness at wellsfargo.com wrote:

> Hi,
>
> I am in the process of linking a C/C++ application to the R.dll
> directly.  I have obtained the R source code and compiled it 
> successfully.  I have also successfully linked the R.dll directly into

> our application and have made calls successfully into the R.dll that 
> are included in the sample rtest.c and in the "Writing R Extensions - 
> The R API".
>
> The R functionality that we are interested in embedding into our
> application is the data analysis and graphics.  However, I did not see

> any references to this in the R API section of the documentation.  Is 
> this functionality available from our C/C++ application via the R.dll?

> If so, how do we access this functionality?

By reading the section on 'linking GUIs and other front-ends'.  It is
not 
in the C-level API.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tlumley at u.washington.edu  Wed Dec 14 20:48:21 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 14 Dec 2005 11:48:21 -0800 (PST)
Subject: [Rd] 0/1 vector for indexing leads to funny behaviour (PR#8389)
 (maybe a documentation deficiency?)
In-Reply-To: <43A058CC.4010605@acm.org>
References: <20051213150515.175B8A3C7@slim.kubism.ku.dk>
	<439F0D24.1080701@acm.org>
	<Pine.LNX.4.61.0512132104090.9376@gannet.stats>
	<43A058CC.4010605@acm.org>
Message-ID: <Pine.LNX.4.64.0512141143590.14365@homer24.u.washington.edu>

On Wed, 14 Dec 2005, Tony Plate wrote:
>
> That's what I was trying to say: the whole truth is that numeric index
> vectors that contain positive integral quantities can also contain
> zeros.  Upon rereading this passage yet again, I think it is more
> misleading than merely incomplete: the phrasings "positive integral
> quantities", and "*must* lie in the set ..." rule out the possibility of
> the vector containing zeros.
>

"Someone told me that you can't run without bouncing the ball in 
basketball. I got a basketball and tried it and it worked fine. He must be 
wrong"  -- a comp.lang.c standard

It doesn't rule out the the possibility of the vector containing zeros, it 
tells you that you should not put zeros in the vector.

 	-thomas


From bhs2 at mevik.net  Wed Dec 14 21:05:56 2005
From: bhs2 at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge_Mevik?=)
Date: Wed, 14 Dec 2005 21:05:56 +0100
Subject: [Rd] R-beta: configure problem (tcltk) on 64 bit Red Hat EL
In-Reply-To: <1134564372.31436.3.camel@seurat> (Martyn Plummer's message of
	"Wed, 14 Dec 2005 13:46:12 +0100")
References: <m0irtryj1h.fsf@bar.nemo-project.org>
	<1134564372.31436.3.camel@seurat>
Message-ID: <m0fyovwijf.fsf@bar.nemo-project.org>

Martyn Plummer wrote:

> It looks like you have the i386 RPMs for tcl and tk installed.

You are right.  I have both the i386 and x86_64 RPMs installed.

> ./configure --with-tcl-config=/usr/lib64/tclConfig.sh \
>             --with-tk-config=/usr/lib64/tkConfig.sh

Thank you!  This works like a charm.


Prof Brian Ripley wrote:

> It is a problem with your particular OS,

You are right.  As Martyn suggested, configure picked up
/usr/lib/{tcl,tk}Config.sh instead of /usr/lib64/{tcl,tk}Config.sh
because I have both i386 and x86_64 versions of the RPMs installed.

> Unfortunately you have removed the crucial parts of where your
> configure got the configuration info from.

Typically me! :-)


Thanks, both of you!

-- 
Bj?rn-Helge Mevik


From ereeves at freepatentsonline.com  Thu Dec 15 03:47:46 2005
From: ereeves at freepatentsonline.com (ereeves@freepatentsonline.com)
Date: Thu, 15 Dec 2005 03:47:46 +0100 (CET)
Subject: [Rd] Free patent searching (PR#8396)
Message-ID: <20051215024746.4B69D29C2C@slim.kubism.ku.dk>

Hi,

I saw that you have some information on R&D at http://bugs.r-project.org/cgi-bin/R and I wanted to let you know about a free patent searching site, www.FreePatentsOnline.com.

The site has more data and features than the US PTO, and we are continuing to work on expanding the site until it has world-wide patent coverage.

If you have an appropriate place on your web site, a link would be much appreciated!

Thanks for your time, and please fee free to let me know if you have any suggestions for improving the site.

Sincerely,
Erik Reeves
FreePatentsOnline.com


From ripley at stats.ox.ac.uk  Thu Dec 15 08:26:38 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 15 Dec 2005 07:26:38 +0000 (GMT)
Subject: [Rd] R-beta: configure problem (tcltk) on 64 bit Red Hat EL
In-Reply-To: <m0fyovwijf.fsf@bar.nemo-project.org>
References: <m0irtryj1h.fsf@bar.nemo-project.org>
	<1134564372.31436.3.camel@seurat>
	<m0fyovwijf.fsf@bar.nemo-project.org>
Message-ID: <Pine.LNX.4.61.0512150722470.13950@gannet.stats>

On Wed, 14 Dec 2005, Bj?rn-Helge Mevik wrote:

> Martyn Plummer wrote:
>
>> It looks like you have the i386 RPMs for tcl and tk installed.
>
> You are right.  I have both the i386 and x86_64 RPMs installed.
>
>> ./configure --with-tcl-config=/usr/lib64/tclConfig.sh \
>>             --with-tk-config=/usr/lib64/tkConfig.sh
>
> Thank you!  This works like a charm.

At a closer look, R was searching /usr/lib before /usr/lib64 which seems 
sub-optimal, so I have reversed this (and added /usr/local/lib64 to the 
list before /usr/local/lib).  Nevertheless, for some builds (e.g.
32-bit R on 64-bit Linux) you will need to specify the paths as the manual 
says.

> Prof Brian Ripley wrote:
>
>> It is a problem with your particular OS,
>
> You are right.  As Martyn suggested, configure picked up
> /usr/lib/{tcl,tk}Config.sh instead of /usr/lib64/{tcl,tk}Config.sh
> because I have both i386 and x86_64 versions of the RPMs installed.
>
>> Unfortunately you have removed the crucial parts of where your
>> configure got the configuration info from.
>
> Typically me! :-)
>
>
> Thanks, both of you!
>
> -- 
> Bj?rn-Helge Mevik
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Thu Dec 15 09:09:49 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 15 Dec 2005 08:09:49 +0000 (GMT)
Subject: [Rd] Building R with f2c - still needed?
In-Reply-To: <20051213233710.GA470@eddelbuettel.com>
References: <Pine.LNX.4.61.0512132144190.15384@gannet.stats>
	<20051213233710.GA470@eddelbuettel.com>
Message-ID: <Pine.LNX.4.61.0512150803010.4189@gannet.stats>

Thank you both for the comments.  The problem is that we have a lot of 
special-casing for f2c in the configure code, and I think it is becoming 
unmaintainable.  (I've been doing some cleaning up after discovering 
several errors in little-used cases, e.g. a substitute for alloca was 
compiled iff --enable-R-shlib was not specified.)

A cleaner solution would be to use a wrapper for f2c as a pseudo-compiler. 
I'll test that, and if it works then start to strip the special-casing 
out.

On Tue, 13 Dec 2005, Dirk Eddelbuettel wrote:

> On Tue, Dec 13, 2005 at 09:48:56PM +0000, Prof Brian Ripley wrote:
>> Does anyone have a need to use f2c rather than a Fortran compiler to build
>> R?
>
> We used f2c up until a few months ago as a last line of defence against
> crappy Fg77 code on m68k/arm (one or both, it changed at times).
>
> I'd be hesitant about throwing it out, but it is of course your call.
>
> Thanks, Dirk
>
> -- 
> Hell, there are no rules here - we're trying to accomplish something.
>                                                  -- Thomas A. Edison
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maureen.vins at virgin.net  Thu Dec 15 18:05:14 2005
From: maureen.vins at virgin.net (maureen.vins@virgin.net)
Date: Thu, 15 Dec 2005 18:05:14 +0100 (CET)
Subject: [Rd] notification (PR#8400)
Message-ID: <20051215170514.F11E629D0D@slim.kubism.ku.dk>

------=_Part_84061_2932887.1134662536598
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

The Gardener Humanitarian Project,Van-gennelaan 371,4512DT,Delft.Royal Dutch Republic.
 
Ticket No;627462128TW,
 
This is to inform you that, base on our end of year promotion of The Gardener Humanitarian Firm carried out on the 13th ,December,'05,your e-mail address attached with the above ticket No. popped out in the third stake.
 
This automatically declares you the winner of our third prize of two hundred and fifty thou-sand USD(US$250,000:00) in the open charity ballot device.
 
The source of fund is majorly from well meaning companies and humananitarian sprited industries selected from european community.
 
Be informed that in line with the sponsors' regulation,you are to contribute a substantial amount(at least 10%) to a recognized non-governmental charity project in your environ.This should be given only after your fund has been acknowledged by you.
 
Application and inquiries should be forwarded to Mrs Marina Van Kleiweg via e-mail ;(marina02 at gardener.com).
 
Accept my heart felt congratulations.
 
Mrs Maureen VinsPS:Kindly state your Ticket No in your expected application
------=_Part_84061_2932887.1134662536598
Content-Type: text/html;charset="UTF-8"
Content-Transfer-Encoding: 7bit

<DIV id=RTEContent>The Gardener Humanitarian Project,<BR>Van-gennelaan 371,<BR>4512DT,Delft.<BR>Royal Dutch Republic.</DIV>
<DIV>&nbsp;</DIV>
<DIV>Ticket No;627462128TW,</DIV>
<DIV>&nbsp;</DIV>
<DIV>This is to inform you that, base on our end of year promotion of The Gardener Humanitarian Firm carried out on the 13th ,December,'05,your e-mail address attached with the above ticket No. popped out in the third stake.</DIV>
<DIV>&nbsp;</DIV>
<DIV>This automatically declares you the winner of our third prize of two hundred and fifty thou-sand USD(US$250,000:00) in the open charity ballot device.</DIV>
<DIV>&nbsp;</DIV>
<DIV>The source of fund is majorly from well meaning companies and humananitarian sprited industries selected from european community.</DIV>
<DIV>&nbsp;</DIV>
<DIV>Be informed that in line with the sponsors' regulation,you are to contribute a substantial amount(at least 10%) to a recognized non-governmental charity project in your environ.This should be given only after your fund has been acknowledged by you.</DIV>
<DIV>&nbsp;</DIV>
<DIV>Application and inquiries should be forwarded to Mrs&nbsp;Marina Van Kleiweg&nbsp;via e-mail ;(<A href="mailto:marina02 at gardener.com">marina02 at gardener.com</A>).</DIV>
<DIV>&nbsp;</DIV>
<DIV>Accept my heart felt congratulations.</DIV>
<DIV>&nbsp;</DIV>
<DIV>Mrs Maureen Vins<BR>PS:Kindly state your Ticket No in your expected application</DIV>
------=_Part_84061_2932887.1134662536598--


From pathikpa at usc.edu  Thu Dec 15 21:42:59 2005
From: pathikpa at usc.edu (Pathik)
Date: Thu, 15 Dec 2005 12:42:59 -0800
Subject: [Rd] R for Windows GUI Front-End Problem (PR#3364)
Message-ID: <43A1D553.8060600@usc.edu>

Dear Programmers,

    I encounter following error,while loading vector.

 > pam_Test<- ReadAffy()
Error: cannot allocate vector of size 312879 Kb
In addition: Warning messages:
1: Reached total allocation of 1024Mb: see help(memory.size)
2: Reached total allocation of 1024Mb: see help( memory.size)

I also changed headers to use maximum memory as i am having 4GB of 
physical memory in my machine.but still i am facing problem.

Is ther any other soution?

-- 
Pathik Patel
Graduate Student,
Ph-213-321-1360
=======================================================================
UNIX is an operating system, OS/2 is half an operating system, Windows is a shell, and DOS is a boot partition virus


From bolker at zoo.ufl.edu  Thu Dec 15 20:40:37 2005
From: bolker at zoo.ufl.edu (bolker@zoo.ufl.edu)
Date: Thu, 15 Dec 2005 20:40:37 +0100 (CET)
Subject: [Rd] nls: constraints (lower/upper) (PR#8401)
Message-ID: <20051215194037.7673F29D16@slim.kubism.ku.dk>


    I found what seems to be a glaring bug in nls when using
constraints, but it is so glaring that I'm a bit nervous
about having been stupid.  I have (1) tried to make sure
I'm up to date:

platform i486-pc-linux-gnu
arch     i486
os       linux-gnu
system   i486, linux-gnu
status
major    2
minor    2.0
year     2005
month    10
day      06
svn rev  35749

  (2) skimmed through the SVN logs; (3) skimmed the bug
reporting system for references to "lower" or "constraint"

    The problem is that nls() doesn't seem to work with
constraints.  Specifically, it seems to fail to set
the "lower" and "upper" components of match.call() to NULL
before trying to evaluate the formula.
There is a simple fix that makes it work
fine (for me at least -- I haven't tested extensively).

   I would submit a bug report but I'm gun-shy ...

   Sample problem and fix:
--------------
x = runif(200)
a =1
b = 1
c = -0.1
y = a+b*x+c*x^2+rnorm(200,sd=0.05)
plot(x,y)
curve(a+b*x+c*x^2,add=TRUE)
nls(y~a+b*x+c*I(x^2),start=c(a=1,b=1,c=0.1),algorithm="port")
nls(y~a+b*x+c*I(x^2),start=c(a=1,b=1,c=0.1),algorithm="port",lower=c(0,0,0))
## Error in model.frame(formula, rownames, variables, varnames, extras, 
## extranames,  :
##      variable lengths differ

## hack nls()
sink("mynls.R")
nls
sink()

## replace line 34:
## ORIGINAL:
##  mf$start <- mf$control <- mf$algorithm <-
##  mf$trace <- mf$model <- NULL
##    REVISED:
##  mf$start <- mf$control <- mf$algorithm <- mf$trace <- mf$model <-
##      mf$lower <- mf$upper <- NULL
## add "mynls <- " at the beginning, delete namespace code at the end
source("mynls.R")
mynls(y~a+b*x+c*I(x^2),start=c(a=1,b=1,c=0.1),algorithm="port",lower=c(0,0,0))

## works beautifully


-- 
620B Bartram Hall                            bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704


From jp-www at dcs.gla.ac.uk  Fri Dec 16 13:30:41 2005
From: jp-www at dcs.gla.ac.uk (jp-www@dcs.gla.ac.uk)
Date: Fri, 16 Dec 2005 13:30:41 +0100 (CET)
Subject: [Rd] AppleScript commands don't execute until mouse over console
	window (PR#8405)
Message-ID: <20051216123041.2BB8D19A33@slim.kubism.ku.dk>

Full_Name: Jonathan Paisley
Version: 2.2.0
OS: Mac OS X 10.4.3
Submission from: (NULL) (81.178.69.159)


I am sending commands to R via AppleScript (specifically, from SubEthaEdit to
instruct it to source the file I'm currently editing). R doesn't respond tothe
AppleScript until I move the mouse over R's console window.

The following patch to the Mac GUI (against current svn trunk) resolves the
problem, by posting a dummy event to wake up the event queue after the command
has been stuffed into the input buffer.

--- RController.m	(revision 2076)
+++ RController.m	(working copy)
@@ -1104,7 +1104,18 @@
 The input replaces what the user is currently typing.
 */
 - (void) sendInput: (NSString*) text {
+	NSPoint null = {0,0};
 	[self consoleInput:text interactive:YES];
+    	[NSApp postEvent:[NSEvent otherEventWithType: NSApplicationDefined 
+                                            location: null
+                                       modifierFlags: 0 
+                                           timestamp: 0
+                                        windowNumber: 0
+                                             context: NULL
+                                             subtype: 0
+                                               data1: 0
+                                               data2: 0
+            ] atStart: YES]; 
 	/*
 	 unsigned textLength = [[RTextView textStorage] length];
 	 [RTextView setSelectedRange:NSMakeRange(textLength, 0)];


From simon.urbanek at r-project.org  Fri Dec 16 20:30:11 2005
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 16 Dec 2005 14:30:11 -0500
Subject: [Rd] AppleScript commands don't execute until mouse over
	console window (PR#8405)
In-Reply-To: <20051216123041.2BB8D19A33@slim.kubism.ku.dk>
References: <20051216123041.2BB8D19A33@slim.kubism.ku.dk>
Message-ID: <04B567B0-F091-4DB1-821F-386503D4E803@r-project.org>

Thanks, Jonathan! I have now committed a slight variation of your  
patch in the current Mac-GUI.

Cheers,
Simon

On Dec 16, 2005, at 7:30 AM, jp-www at dcs.gla.ac.uk wrote:

> I am sending commands to R via AppleScript (specifically, from  
> SubEthaEdit to instruct it to source the file I'm currently  
> editing). R doesn't respond to the AppleScript until I move the  
> mouse over R's console window.
>
> The following patch to the Mac GUI (against current svn trunk)  
> resolves the problem, by posting a dummy event to wake up the event  
> queue after the command has been stuffed into the input buffer.


From vikram at mayin.org  Sat Dec 17 00:47:05 2005
From: vikram at mayin.org (vikram@mayin.org)
Date: Sat, 17 Dec 2005 00:47:05 +0100 (CET)
Subject: [Rd] Bug in acepack (PR#2352)
Message-ID: <20051216234705.AD05117541@slim.kubism.ku.dk>

This ancient bug was tracked to  the acepack library, line 556 in line
src/avas.f

 The troublesome line is:
	if (x(n).gt.x(1)) go to 30

 Since the input arguments are  empty, referencing x(1) and x(n) cause
a  Segmentation fault,  and  cause  R to  crash.   Acepack author  and
maintainer Rob Tibshirani <tibs at utstat.toronto.edu> has been contacted
with this  information.  This is not  a bug with R,  but with acepack,
and should be closed.

Neha Pandey <neha.pandey at gmail.com>
Vikram Aggarwal <vikram at mayin.org>
-- 
Vikram Aggarwal: http://www.mayin.org/~aragorn/


From ripley at stats.ox.ac.uk  Sat Dec 17 08:51:10 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 17 Dec 2005 07:51:10 +0000 (GMT)
Subject: [Rd] Bug in acepack (PR#2352)
In-Reply-To: <20051216234705.AD05117541@slim.kubism.ku.dk>
References: <20051216234705.AD05117541@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0512170735580.23036@gannet.stats>

library(help=acepack) says

Maintainer:    Thomas Lumley <tlumley at u.washington.edu>

and I doubt if sending Rob Tibshirani mail to an address he left a decade 
ago for a package he does not maintain is going to help resolve the bug.

The issue is not knowing what the bug is, but getting the maintainer to 
fix it.  If you send him a tested patch it might help.

[Incidentally, if you read the FAQ you will see that reports on 
contributed packages should not be sent to R-bugs except by the 
maintainer, and only the maintainer `should' be issuing instructions to 
close a report.  It is in the section for 'Addon packages', that is not a 
bug in R.]

On Sat, 17 Dec 2005 vikram at mayin.org wrote:

> This ancient bug was tracked to  the acepack library, line 556 in line
> src/avas.f
>
> The troublesome line is:
> 	if (x(n).gt.x(1)) go to 30
>
> Since the input arguments are  empty, referencing x(1) and x(n) cause
> a  Segmentation fault,  and  cause  R to  crash.   Acepack author  and
> maintainer Rob Tibshirani <tibs at utstat.toronto.edu> has been contacted
> with this  information.  This is not  a bug with R,  but with acepack,
> and should be closed.
>
> Neha Pandey <neha.pandey at gmail.com>
> Vikram Aggarwal <vikram at mayin.org>
> -- 
> Vikram Aggarwal: http://www.mayin.org/~aragorn/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From khansen at stat.Berkeley.EDU  Sun Dec 18 03:52:12 2005
From: khansen at stat.Berkeley.EDU (Kasper Daniel Hansen)
Date: Sat, 17 Dec 2005 18:52:12 -0800
Subject: [Rd] R for Windows GUI Front-End Problem (PR#3364)
In-Reply-To: <43A1D553.8060600@usc.edu>
References: <43A1D553.8060600@usc.edu>
Message-ID: <FDE1C963-6178-4F3F-B1A1-FADD8A8EB5DF@stat.berkeley.edu>

Please use the BioC list for questions such as this. It has been  
discussed numerous times there. I am cc: my answer to that list.

On Dec 15, 2005, at 12:42 PM, Pathik wrote:

> Dear Programmers,
>
>     I encounter following error,while loading vector.
>
>> pam_Test<- ReadAffy()
> Error: cannot allocate vector of size 312879 Kb
> In addition: Warning messages:
> 1: Reached total allocation of 1024Mb: see help(memory.size)
> 2: Reached total allocation of 1024Mb: see help( memory.size)

This just means you do not have enough memory. Do not fret over the  
specific values, R just bangs out at some kind of assignment  
somewhere in the code.

> I also changed headers to use maximum memory as i am having 4GB of
> physical memory in my machine.but still i am facing problem.

Well, you still do not have enough ram. Note though that R cannot use  
all of the 4GB due to limitations of the OS. So it will not help to  
add more RAM.

> Is ther any other soution?

Install an OS which can actually use all your RAM.

You could try reading in smaller subsets of the data, instead of  
everything in one go, although you will probably have problems when  
you normalize (at least if you want to normalize all chips together).  
How many chips are you looking at (and how big are they?)

Kasper

> -- 
> Pathik Patel
> Graduate Student,
> Ph-213-321-1360
> ====================================================================== 
> =
> UNIX is an operating system, OS/2 is half an operating system,  
> Windows is a shell, and DOS is a boot partition virus
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From chtorres at linux.ime.usp.br  Sun Dec 18 15:31:21 2005
From: chtorres at linux.ime.usp.br (chtorres@linux.ime.usp.br)
Date: Sun, 18 Dec 2005 15:31:21 +0100 (CET)
Subject: [Rd] package unlisted (PR#8410)
Message-ID: <20051218143121.7DAEB19A3B@slim.kubism.ku.dk>

Full_Name: Cesar Henrique Torres
Version: 2.2.0
OS: winXP-pro
Submission from: (NULL) (201.1.196.50)


Hi developer's!

I'd like to know were gtools package is, because in the link below it isn't:
http://cran.r-project.org/bin/windows/contrib/r-release/
This package is used in gplots and I'm trying to make a balloonplot.

Thanks a lot,
Cesar Torres.


From MSchwartz at mn.rr.com  Sun Dec 18 16:18:40 2005
From: MSchwartz at mn.rr.com (MSchwartz@mn.rr.com)
Date: Sun, 18 Dec 2005 16:18:40 +0100 (CET)
Subject: [Rd] package unlisted (PR#8410)
Message-ID: <20051218151840.2C17519A3B@slim.kubism.ku.dk>

On Sun, 2005-12-18 at 15:31 +0100, chtorres at linux.ime.usp.br wrote:
> Full_Name: Cesar Henrique Torres
> Version: 2.2.0
> OS: winXP-pro
> Submission from: (NULL) (201.1.196.50)
> 
> 
> Hi developer's!
> 
> I'd like to know were gtools package is, because in the link below it isn't:
> http://cran.r-project.org/bin/windows/contrib/r-release/
> This package is used in gplots and I'm trying to make a balloonplot.
> 
> Thanks a lot,
> Cesar Torres.

Please do not post bugs on Contributed packages to the main R-bugs repo.
This now requires intervention by a member of R Core, none of whom are
in a position to resolve the problem. You should contact the package
maintainer instead. In this case it is Nitin Jain
(nitin.jain at pfizer.com) who I have cc'd here.

The problem here is that the current version of gtools for Windows is
not passing the required checks before it can be allowed to be included
in the main CRAN repo.  This can be seen here:

http://cran.r-project.org/bin/windows/contrib/checkSummaryWin.html

On the above, scroll down to gtools and you will see links for the
following error log and interim resolution:

http://cran.r-project.org/bin/windows/contrib/2.2/check/gtools-check.log

http://cran.r-project.org/bin/windows/contrib/2.2/last/ReadMe


This brings you to:

http://cran.r-project.org/bin/windows/contrib/2.2/last/

where you will find the last version of gtools for Windows that passed
the required checks. This will need to be manually downloaded and may or
may not work in the presence of the other related packages given the
potential for version related conflicts. I suspect Nitin will have more
definitive comments.

HTH,

Marc Schwartz


From hpages at fhcrc.org  Tue Dec 20 02:10:58 2005
From: hpages at fhcrc.org (Herve Pages)
Date: Mon, 19 Dec 2005 17:10:58 -0800
Subject: [Rd] SVN-REVSION altered when building R-devel out of tree from
	last snapshot
Message-ID: <43A75A22.90404@fhcrc.org>

Hi,


Today I downloaded and compiled the last R-devel snapshot.
The SVN-REVISION in the tarball contains the following:

  Revision: 36792
  Last Changed Date: 2005-12-18

But after compiling on Unix (I compiled out of tree), I ended up
with an SVN-REVSION file containing:

  Revision: unknown
  Last Changed Date: Today

in the build tree.

Then when I start R, I get:

  R : Copyright Today, The R Foundation for Statistical Computing
  Version 2.3.0 Under development (unstable) (Today-Today-Today)
  ISBN 3-900051-07-0

even if I naively edit the SVN-REVISION in the build tree before to
start R.

I got this problem on a 64-bit SUSE Linux 9.2, a 32-bit SUSE Linux 9.2
and a Solaris 2.9 sparc system.
On Windows however (where I built R directly in the source tree) I don't
have this problem.

We need to update R-devel on our various build machines in order to test
Bioconductor devel packages with last R-devel and we try to have the exact
same R revision number on every test-machine. Last time I updated R-devel
was 12/01/2005 and I used the same procedure that I am using today but
I didn't have the SVN-REVISION problem.

Also I didn't try to build R-devel from SVN. Maybe this could solve the
problem. It's just that using the tarball was easier to manage.
Anyway I thought it might be worth reporting.

Regards,

Herv?
 

-- 
------------------------
Herv? Pag?s
E-mail: hpages at fhcrc.org
Phone: (206) 667-5791
Fax: (206) 667-1319


From maechler at stat.math.ethz.ch  Tue Dec 20 09:40:47 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 20 Dec 2005 09:40:47 +0100
Subject: [Rd] SVN-REVSION altered when building R-devel out of tree from
 last snapshot
In-Reply-To: <43A75A22.90404@fhcrc.org>
References: <43A75A22.90404@fhcrc.org>
Message-ID: <17319.50063.990876.191012@stat.math.ethz.ch>

>>>>> "Herve" == Herve Pages <hpages at fhcrc.org>
>>>>>     on Mon, 19 Dec 2005 17:10:58 -0800 writes:

    Herve> Hi,
    Herve> Today I downloaded and compiled the last R-devel snapshot.
    Herve> The SVN-REVISION in the tarball contains the following:

    Herve> Revision: 36792
    Herve> Last Changed Date: 2005-12-18

    Herve> But after compiling on Unix (I compiled out of tree), 

i.e. "in a separate build directory tree"

    Herve> I ended up with an SVN-REVSION file containing:

    Herve> Revision: unknown
    Herve> Last Changed Date: Today

    Herve> in the build tree.

I can confirm this wrong behavior (Linux Redhat EL4).
There must be something not yet perfect in our 'make' setup
there.  If we are not in the srcdir, we create a 'non-tarball'
file which I think is wrong;  in any case, this is buglet we'll fix.

Thank you, Herve!

    Herve> Then when I start R, I get:

    Herve> R : Copyright Today, The R Foundation for Statistical Computing
    Herve> Version 2.3.0 Under development (unstable) (Today-Today-Today)
    Herve> ISBN 3-900051-07-0

    Herve> even if I naively edit the SVN-REVISION in the build tree before to
    Herve> start R.

    Herve> I got this problem on a 64-bit SUSE Linux 9.2, a 32-bit SUSE Linux 9.2
    Herve> and a Solaris 2.9 sparc system.
    Herve> On Windows however (where I built R directly in the source tree) I don't
    Herve> have this problem.

    Herve> We need to update R-devel on our various build machines in order to test
    Herve> Bioconductor devel packages with last R-devel and we try to have the exact
    Herve> same R revision number on every test-machine. Last time I updated R-devel
    Herve> was 12/01/2005 and I used the same procedure that I

[ you mean 12th of January? ;-)  {yes, it would help to use
  international 2005-12-01 or then Dec 01, 2005}
]

    Herve> am using today but
    Herve> I didn't have the SVN-REVISION problem.

    Herve> Also I didn't try to build R-devel from SVN. Maybe
    Herve> this could solve the problem.

that would definitely solve it, since that's what all of R-core
do "all the time".  
But the way you did, should also work; that's what the tarballs
are for!

    Herve> It's just that using the tarball was easier to manage.
    Herve> Anyway I thought it might be worth reporting.

Definitely.
Thank you again, Herv? !

    Herve> Regards,

    Herve> Herv?
 

    Herve> -- 
    Herve> ------------------------
    Herve> Herv? Pag?s
    Herve> E-mail: hpages at fhcrc.org
    Herve> Phone: (206) 667-5791
    Herve> Fax: (206) 667-1319

    Herve> ______________________________________________
    Herve> R-devel at r-project.org mailing list
    Herve> https://stat.ethz.ch/mailman/listinfo/r-devel


From ernesto at ipimar.pt  Tue Dec 20 11:31:38 2005
From: ernesto at ipimar.pt (ernesto)
Date: Tue, 20 Dec 2005 10:31:38 +0000
Subject: [Rd] Overlaying lattice plots
In-Reply-To: <CAAD15FC4F69AC419F16028EBBCCC36F138EF0@icex1.ic.ac.uk>
References: <CAAD15FC4F69AC419F16028EBBCCC36F138EF0@icex1.ic.ac.uk>
Message-ID: <43A7DD8A.9050400@ipimar.pt>

Hillary, Richard M wrote:

> Morning chaps, I have a little question for your capable minds... Say
> I have an observed and predicted set of quants (in my case, length
> frequencies by year and age/length), is there a way to use lattice
> plots to plot the observed and predicted data together, panel by panel?
> Obrigado/gracias (thankyou in Galego is?...)
> Rich

Hi Richard,

If you want to plot both datasets on the same plot just make use of the
xyplot for FLQuants, something like

flqs <- FLQuants(list(pred=pred.quant, res=res.quant))
xyplot(data~age, data=flqs)

now tune it the way you want and change the formula to fit your needs.

Regards

EJ

ps: I'm cc'ing this to the mailing lists, I find it usefull for others.


From r.hillary at imperial.ac.uk  Tue Dec 20 11:31:58 2005
From: r.hillary at imperial.ac.uk (Hillary, Richard M)
Date: Tue, 20 Dec 2005 10:31:58 -0000
Subject: [Rd] Overlaying lattice plots
Message-ID: <CAAD15FC4F69AC419F16028EBBCCC36F138EF1@icex1.ic.ac.uk>

Excellent, thanks man!
Rich 

-----Original Message-----
From: ernesto [mailto:ernesto at ipimar.pt] 
Sent: 20 December 2005 10:32
To: Hillary, Richard M; Iago Mosqueira; Mailing List R; R-devel
Subject: Re: Overlaying lattice plots

Hillary, Richard M wrote:

> Morning chaps, I have a little question for your capable minds... Say 
> I have an observed and predicted set of quants (in my case, length 
> frequencies by year and age/length), is there a way to use lattice 
> plots to plot the observed and predicted data together, panel by
panel?
> Obrigado/gracias (thankyou in Galego is?...) Rich

Hi Richard,

If you want to plot both datasets on the same plot just make use of the
xyplot for FLQuants, something like

flqs <- FLQuants(list(pred=pred.quant, res=res.quant)) xyplot(data~age,
data=flqs)

now tune it the way you want and change the formula to fit your needs.

Regards

EJ

ps: I'm cc'ing this to the mailing lists, I find it usefull for others.


From ernesto at ipimar.pt  Tue Dec 20 11:41:48 2005
From: ernesto at ipimar.pt (ernesto)
Date: Tue, 20 Dec 2005 10:41:48 +0000
Subject: [Rd] Overlaying lattice plots - SORRY,
	WRONG MAILING LIST ADDRESS
In-Reply-To: <43A7DD8A.9050400@ipimar.pt>
References: <CAAD15FC4F69AC419F16028EBBCCC36F138EF0@icex1.ic.ac.uk>
	<43A7DD8A.9050400@ipimar.pt>
Message-ID: <43A7DFEC.9030707@ipimar.pt>

ernesto wrote:

>Hillary, Richard M wrote:
>
>  
>
>>Morning chaps, I have a little question for your capable minds... Say
>>I have an observed and predicted set of quants (in my case, length
>>frequencies by year and age/length), is there a way to use lattice
>>plots to plot the observed and predicted data together, panel by panel?
>>Obrigado/gracias (thankyou in Galego is?...)
>>Rich
>>    
>>
>
>Hi Richard,
>
>If you want to plot both datasets on the same plot just make use of the
>xyplot for FLQuants, something like
>
>flqs <- FLQuants(list(pred=pred.quant, res=res.quant))
>xyplot(data~age, data=flqs)
>
>now tune it the way you want and change the formula to fit your needs.
>
>Regards
>
>EJ
>
>ps: I'm cc'ing this to the mailing lists, I find it usefull for others.
>  
>

Hi,

Sorry for this message, wrong address. I wanted to send it to
FLR-mailing list.

Regards

EJ


From r.hillary at imperial.ac.uk  Tue Dec 20 12:21:56 2005
From: r.hillary at imperial.ac.uk (Hillary, Richard M)
Date: Tue, 20 Dec 2005 11:21:56 -0000
Subject: [Rd] Overlaying lattice plots
Message-ID: <CAAD15FC4F69AC419F16028EBBCCC36F138EF4@icex1.ic.ac.uk>

There seems to be a problem here, probably of my own making... 

flqs <- FLQuants(list(observed=obs, fitted=fits))
xyplot(data~age,data=flqs)
Error in tmp[subset] : object is not subsettable
?     

-----Original Message-----
From: ernesto [mailto:ernesto at ipimar.pt] 
Sent: 20 December 2005 10:32
To: Hillary, Richard M; Iago Mosqueira; Mailing List R; R-devel
Subject: Re: Overlaying lattice plots

Hillary, Richard M wrote:

> Morning chaps, I have a little question for your capable minds... Say 
> I have an observed and predicted set of quants (in my case, length 
> frequencies by year and age/length), is there a way to use lattice 
> plots to plot the observed and predicted data together, panel by
panel?
> Obrigado/gracias (thankyou in Galego is?...) Rich

Hi Richard,

If you want to plot both datasets on the same plot just make use of the
xyplot for FLQuants, something like

flqs <- FLQuants(list(pred=pred.quant, res=res.quant)) xyplot(data~age,
data=flqs)

now tune it the way you want and change the formula to fit your needs.

Regards

EJ

ps: I'm cc'ing this to the mailing lists, I find it usefull for others.


From cig69410 at syd.odn.ne.jp  Tue Dec 20 14:28:01 2005
From: cig69410 at syd.odn.ne.jp (cig69410@syd.odn.ne.jp)
Date: Tue, 20 Dec 2005 14:28:01 +0100 (CET)
Subject: [Rd] 2 x 2 chisq.test (PR#8415)
Message-ID: <20051220132801.5314619A39@slim.kubism.ku.dk>

Full_Name: nobody
Version: 2.2.0
OS: any
Submission from: (NULL) (219.66.34.183)


2 x 2 table, such as

> x
     [,1] [,2]
[1,]   10   12
[2,]   11   13

> chisq.test(x)

	Pearson's Chi-squared test with Yates'
	continuity correction

data:  x 
X-squared = 0.0732, df = 1, p-value = 0.7868

but, X-squared = 0.0732 is over corrected.

when abs(a*d-b*c) <= sum(a,b,c,d), chisq.value must be 0!, and P-value must be
1!

code of chisq.test must be as follows

 #           if (correct && nrow(x) == 2 && ncol(x) == 2) {
 #               YATES <- 0.5
 #               METHOD <- paste(METHOD, "with Yates' continuity correction")
 #           }
 #           else YATES <- 0
 #           STATISTIC <- sum((abs(x - E) - YATES)^2/E)
 ## replace begin
             if (correct && nrow(x) == 2 && ncol(x) == 2) {
                 STATISTIC <- if (abs(x[1,1]*x[2,2]-x[1,2]*x[2,1]) < sum(x)/2) 0
   
                              else sum((abs(x - E) - 0.5)^2/E)
                 METHOD <- paste(METHOD, "with Yates' continuity correction")
             }
             else STATISTIC <- sum((abs(x - E))^2/E)
 ## replace end


From ripley at stats.ox.ac.uk  Tue Dec 20 17:01:03 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Tue, 20 Dec 2005 17:01:03 +0100 (CET)
Subject: [Rd] 2 x 2 chisq.test (PR#8415)
Message-ID: <20051220160103.DFB7419A65@slim.kubism.ku.dk>

This is the same as PR#8265, from a person also not giving his/her name 
but sharing your ISP.  Please don't submit a repeat, as the FAQ asks.

After last time this was raised, I checked Yates' original paper and 
Fisher's book and it seems that R's formula follows what they say.

Do remember that 0 is an impossible value for a chisq-distributed 
variable, and so one would not expect the corrected distribution to take 
that value with positive probability.

On Tue, 20 Dec 2005 cig69410 at syd.odn.ne.jp wrote:

> Full_Name: nobody

Do you expect us to take the word of `nobody' as to the correct definition 
of a statistic?  We need your credentials and references.

> Version: 2.2.0
> OS: any
> Submission from: (NULL) (219.66.34.183)
>
>
> 2 x 2 table, such as
>
>> x
>     [,1] [,2]
> [1,]   10   12
> [2,]   11   13
>
>> chisq.test(x)
>
> 	Pearson's Chi-squared test with Yates'
> 	continuity correction
>
> data:  x
> X-squared = 0.0732, df = 1, p-value = 0.7868
>
> but, X-squared = 0.0732 is over corrected.
>
> when abs(a*d-b*c) <= sum(a,b,c,d), chisq.value must be 0!, and P-value must be
> 1!
>
> code of chisq.test must be as follows
>
> #           if (correct && nrow(x) == 2 && ncol(x) == 2) {
> #               YATES <- 0.5
> #               METHOD <- paste(METHOD, "with Yates' continuity correction")
> #           }
> #           else YATES <- 0
> #           STATISTIC <- sum((abs(x - E) - YATES)^2/E)
> ## replace begin
>             if (correct && nrow(x) == 2 && ncol(x) == 2) {
>                 STATISTIC <- if (abs(x[1,1]*x[2,2]-x[1,2]*x[2,1]) < sum(x)/2) 0
>
>                              else sum((abs(x - E) - 0.5)^2/E)
>                 METHOD <- paste(METHOD, "with Yates' continuity correction")
>             }
>             else STATISTIC <- sum((abs(x - E))^2/E)
> ## replace end

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tlumley at u.washington.edu  Tue Dec 20 17:18:34 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 20 Dec 2005 08:18:34 -0800 (PST)
Subject: [Rd] 2 x 2 chisq.test (PR#8415)
In-Reply-To: <20051220132801.5314619A39@slim.kubism.ku.dk>
References: <20051220132801.5314619A39@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.64.0512200813190.15386@homer24.u.washington.edu>


This is the same as PR#8265, which was reported two months ago by someone 
else from syd.odn.ne.jp.  It still isn't a bug. According to Brian 
Ripley's response at that time, "almost all" the sources he checked gave 
the correction that R uses.

 	-thomas

On Tue, 20 Dec 2005, cig69410 at syd.odn.ne.jp wrote:

> Full_Name: nobody
> Version: 2.2.0
> OS: any
> Submission from: (NULL) (219.66.34.183)
>
>
> 2 x 2 table, such as
>
>> x
>     [,1] [,2]
> [1,]   10   12
> [2,]   11   13
>
>> chisq.test(x)
>
> 	Pearson's Chi-squared test with Yates'
> 	continuity correction
>
> data:  x
> X-squared = 0.0732, df = 1, p-value = 0.7868
>
> but, X-squared = 0.0732 is over corrected.
>
> when abs(a*d-b*c) <= sum(a,b,c,d), chisq.value must be 0!, and P-value must be
> 1!
>
> code of chisq.test must be as follows
>
> #           if (correct && nrow(x) == 2 && ncol(x) == 2) {
> #               YATES <- 0.5
> #               METHOD <- paste(METHOD, "with Yates' continuity correction")
> #           }
> #           else YATES <- 0
> #           STATISTIC <- sum((abs(x - E) - YATES)^2/E)
> ## replace begin
>             if (correct && nrow(x) == 2 && ncol(x) == 2) {
>                 STATISTIC <- if (abs(x[1,1]*x[2,2]-x[1,2]*x[2,1]) < sum(x)/2) 0
>
>                              else sum((abs(x - E) - 0.5)^2/E)
>                 METHOD <- paste(METHOD, "with Yates' continuity correction")
>             }
>             else STATISTIC <- sum((abs(x - E))^2/E)
> ## replace end
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From gregory.r.warnes at pfizer.com  Tue Dec 20 18:51:43 2005
From: gregory.r.warnes at pfizer.com (Warnes, Gregory R)
Date: Tue, 20 Dec 2005 12:51:43 -0500
Subject: [Rd] Problems with Windows Cross compile
Message-ID: <915D2D65A9986440A277AC5C98AA466F01863726@groamrexm02.amer.pfizer.com>


Well, I'm finally getting around to setting up a cross-compiler for Windows on my local Linux box.   I'm using the Yan & Rossini's docuimentation and the latest 'http://cran.r-project.org/doc/contrib/Makefile-rcb' , which is working of the R-2.2.0 sources.

After discovering that "cp -p" doesn't work on the filesystem I'm using and removing the '-p's in the R makefiles using perl, I've gotten things to run pretty far through.  Unfortunately, I get stopped by this error when building the base packages:

	writing help indices for package: base tools utils grDevices graphics stats datasets methods grid splines stats4 tcltk

	---------- Making package base ------------
	  adding build stamp to DESCRIPTION
	  installing inst files
	  installing indices
	Error in get(x, envir, mode, inherits) : variable "win.packages.html" was not found
	Execution halted

Any ideas?

-Greg

Gregory R. Warnes, Ph.D.
Associate Director, Non-Clinical Statistics
Pfizer Global Research and Development

----------------------------------------------------------------------
LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}


From maechler at stat.math.ethz.ch  Tue Dec 20 18:51:59 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 20 Dec 2005 18:51:59 +0100
Subject: [Rd] pmin(), pmax() - slower than necessary for common cases
Message-ID: <17320.17599.679275.168777@stat.math.ethz.ch>

A few hours ago, I was making a small point on the R-SIG-robust
mailing list on the point that  ifelse() was not too efficient
in a situation where  pmax() could easily be used instead.

However, this has reminded me of some timing experiments that I
did 13 years ago with S-plus -- where I found that pmin() /
pmax() were really relatively slow for the most common case
where they are used with only two arguments {and typically one
of the arguments is a scalar; but that's not even important here}.
The main reason is that the function accept an arbitrary number
of arguments and that they do recycling.
Their source is at
  https://svn.R-project.org/R/trunk/src/library/base/R/pmax.R

In April 2001 (as I see), I had repeated my timings with R (1.2.2)
which confirmed the picture more or less,  but for some reason I
never drew "proper" consequences of my findings.
Of course one can argue  pmax() & pmin() are still quite fast
functions; OTOH the experiment below shows that -- at least the
special case with 2 (matching) arguments could be made faster by
about a factor of 19 ...

I don't have yet a constructive proposition; just note the fact that

  pmin. <- function(k,x) (x+k - abs(x-k))/2
  pmax. <- function(k,x) (x+k + abs(x-k))/2

are probably the fastest way of computing  pmin() and pmax() of
two arguments {yes, they "suffer" from rounding error of about 1
to 2 bits...} currently in R. 
One "solution" could be to provide  pmin2() and pmax2()
functions based on trival .Internal() versions.

The experiments below are for the special case of  k=0  where I
found the above mentioned factor of 19 which is a bit
overoptimistic for the general case; here is my  pmax-ex.R  source file
(as text/plain attachment ASCII-code --> easy cut & paste)
demonstrating what I claim above.

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: pmax-ex.R
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20051220/1cca8998/pmax-ex.pl
-------------- next part --------------


Martin Maechler, ETH Zurich

From jyan at stat.uiowa.edu  Tue Dec 20 19:07:07 2005
From: jyan at stat.uiowa.edu (Jun Yan)
Date: Tue, 20 Dec 2005 12:07:07 -0600 (CST)
Subject: [Rd] Problems with Windows Cross compile
In-Reply-To: <915D2D65A9986440A277AC5C98AA466F01863726@groamrexm02.amer.pfizer.com>
References: <915D2D65A9986440A277AC5C98AA466F01863726@groamrexm02.amer.pfizer.com>
Message-ID: <Pine.LNX.4.63.0512201203270.3449@p-lnx401.stat.uiowa.edu>

I've seen that error before. It has to do with the setup of R_EXE. A 
current linux R is required. The following order worked for me:

make linuxR
make LinuxFresh=YES mkrules
make R


Jun

On Tue, 20 Dec 2005, Warnes, Gregory R wrote:

>
> Well, I'm finally getting around to setting up a cross-compiler for Windows on my local Linux box.   I'm using the Yan & Rossini's docuimentation and the latest 'http://cran.r-project.org/doc/contrib/Makefile-rcb' , which is working of the R-2.2.0 sources.
>
> After discovering that "cp -p" doesn't work on the filesystem I'm using and removing the '-p's in the R makefiles using perl, I've gotten things to run pretty far through.  Unfortunately, I get stopped by this error when building the base packages:
>
> 	writing help indices for package: base tools utils grDevices graphics stats datasets methods grid splines stats4 tcltk
>
> 	---------- Making package base ------------
> 	  adding build stamp to DESCRIPTION
> 	  installing inst files
> 	  installing indices
> 	Error in get(x, envir, mode, inherits) : variable "win.packages.html" was not found
> 	Execution halted
>
> Any ideas?
>
> -Greg
>
> Gregory R. Warnes, Ph.D.
> Associate Director, Non-Clinical Statistics
> Pfizer Global Research and Development
>
> ----------------------------------------------------------------------
> LEGAL NOTICE
> Unless expressly stated otherwise, this message is confidential and may be privileged.  It is intended for the addressee(s) only.  Access to this E-mail by anyone else is unauthorized.  If you are not an addressee, any disclosure or copying of the contents of this E-mail or any action taken (or not taken) in reliance on it is unauthorized and may be unlawful.  If you are not an addressee, please inform the sender immediately.
>


From gregory.r.warnes at pfizer.com  Tue Dec 20 21:27:44 2005
From: gregory.r.warnes at pfizer.com (Warnes, Gregory R)
Date: Tue, 20 Dec 2005 15:27:44 -0500
Subject: [Rd] Problems with Windows Cross compile
Message-ID: <915D2D65A9986440A277AC5C98AA466F0186372E@groamrexm02.amer.pfizer.com>

Thanks, the default version of R here is 2.1.0, so that must have been the problem.  Everything is working now. 

-Greg

> -----Original Message-----
> From: Jun Yan [mailto:jyan at stat.uiowa.edu]
> Sent: Tuesday, December 20, 2005 1:07 PM
> To: Warnes, Gregory R
> Cc: R-devel (E-mail); Anthony Rossini (E-mail)
> Subject: Re: Problems with Windows Cross compile
> 
> 
> I've seen that error before. It has to do with the setup of R_EXE. A 
> current linux R is required. The following order worked for me:
> 
> make linuxR
> make LinuxFresh=YES mkrules
> make R
> 
> 
> Jun
> 
> On Tue, 20 Dec 2005, Warnes, Gregory R wrote:
> 
> >
> > Well, I'm finally getting around to setting up a 
> cross-compiler for Windows on my local Linux box.   I'm using 
> the Yan & Rossini's docuimentation and the latest 
> 'http://cran.r-project.org/doc/contrib/Makefile-rcb' , which 
> is working of the R-2.2.0 sources.
> >
> > After discovering that "cp -p" doesn't work on the 
> filesystem I'm using and removing the '-p's in the R 
> makefiles using perl, I've gotten things to run pretty far 
> through.  Unfortunately, I get stopped by this error when 
> building the base packages:
> >
> > 	writing help indices for package: base tools utils 
> grDevices graphics stats datasets methods grid splines stats4 tcltk
> >
> > 	---------- Making package base ------------
> > 	  adding build stamp to DESCRIPTION
> > 	  installing inst files
> > 	  installing indices
> > 	Error in get(x, envir, mode, inherits) : variable 
> "win.packages.html" was not found
> > 	Execution halted
> >
> > Any ideas?
> >
> > -Greg
> >
> > Gregory R. Warnes, Ph.D.
> > Associate Director, Non-Clinical Statistics
> > Pfizer Global Research and Development
> >
> > 
> ----------------------------------------------------------------------
> > LEGAL NOTICE
> > Unless expressly stated otherwise, this message is 
> confidential and may be privileged.  It is intended for the 
> addressee(s) only.  Access to this E-mail by anyone else is 
> unauthorized.  If you are not an addressee, any disclosure or 
> copying of the contents of this E-mail or any action taken 
> (or not taken) in reliance on it is unauthorized and may be 
> unlawful.  If you are not an addressee, please inform the 
> sender immediately.
> >
> 
----------------------------------------------------------------------
LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}


From ehlers at math.ucalgary.ca  Wed Dec 21 00:27:30 2005
From: ehlers at math.ucalgary.ca (P Ehlers)
Date: Tue, 20 Dec 2005 16:27:30 -0700
Subject: [Rd] suggestion: link oneway.test on kruskal.test page
Message-ID: <43A89362.8020909@math.ucalgary.ca>

DevelopeRs:

I think it might be useful to add a link to oneway.test() on
the kruskal.test() help page.

("R version 2.3.0, 2005-12-09")

Peter Ehlers
U of Calgary


From Bill.Venables at csiro.au  Wed Dec 21 04:32:54 2005
From: Bill.Venables at csiro.au (Bill.Venables@csiro.au)
Date: Wed, 21 Dec 2005 04:32:54 +0100 (CET)
Subject: [Rd] NextMethod causes R 2.2.0 to crash (PR#8416)
Message-ID: <20051221033254.4736A19A3C@slim.kubism.ku.dk>

I found writing the following default method the for the generic
function "julian" causes R to crash.


julian.default <- function(x, ...) {
        x <- as.Date(x)
        NextMethod("julian", x, ...)
}

Here is a test example 

> m <- as.Date("1972-09-27") + 0:10
> m 
 [1] "1972-09-27" "1972-09-28" "1972-09-29" "1972-09-30" "1972-10-01"
"1972-10-02" "1972-10-03"
 [8] "1972-10-04" "1972-10-05" "1972-10-06" "1972-10-07"
> class(m)
[1] "Date"
> julian(m)
 [1] 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010
attr(,"origin")
[1] "1970-01-01"

> m <- as.character(m)
> class(m)
[1] "character"

> julian(m)

< R crashes>

--please do not edit the information below--

Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status = 
 major = 2
 minor = 2.0
 year = 2005
 month = 10
 day = 06
 svn rev = 35749
 language = R



Bill Venables, 
CMIS, CSIRO Laboratories, 
PO Box 120, Cleveland, Qld. 4163 
AUSTRALIA 
Office Phone (email preferred): +61 7 3826 7251 
Fax (if absolutely necessary):    +61 7 3826 7304 
Mobile (rarely used):                +61 4 1963 4642 
Home Phone:                          +61 7 3286 7700 
mailto:Bill.Venables at csiro.au 
http://www.cmis.csiro.au/bill.venables/


From kolby at netcityhk.com  Wed Dec 21 04:41:16 2005
From: kolby at netcityhk.com (kolby@netcityhk.com)
Date: Wed, 21 Dec 2005 04:41:16 +0100 (CET)
Subject: [Rd] I do understand there are other plans to do,
	but this one is truly significant. (PR#8417)
Message-ID: <20051221034116.E919C19A2A@slim.kubism.ku.dk>

I'm really excited about these deals as we can spend spare cash on a sports
car.
This place can help us customize the perfect plan in a short time.
I learned that we can also (if we want) acquire bucks too.

Turns out that we do not have the most optimal loan, but our home is very
valuable.

I have pored over a lot of websites, and I like this one best. It responds
to the applications of leads in less than 45 minutes.
I've researched a lot of information, and it all attests that now is the
best time for us to get a new house loan.
http://geocities.yahoo.com.br/elbert_botts/


Catch up with you next time,

Maiysile





at present property rights turn dominating pretty his thoughts? The
Tarmangani A responsibility It is my fault. cannibal! His little boy a
savage man-eater! It was too horrible to contemplate.  
lady, and cheerfully senior had rich colleague friends."


From hb at maths.lth.se  Wed Dec 21 04:48:24 2005
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Wed, 21 Dec 2005 14:48:24 +1100
Subject: [Rd] NextMethod causes R 2.2.0 to crash (PR#8416)
In-Reply-To: <20051221033254.4736A19A3C@slim.kubism.ku.dk>
References: <20051221033254.4736A19A3C@slim.kubism.ku.dk>
Message-ID: <43A8D088.5000408@maths.lth.se>

Bill.Venables at csiro.au wrote:
> I found writing the following default method the for the generic
> function "julian" causes R to crash.
> 
> 
> julian.default <- function(x, ...) {
>         x <- as.Date(x)
>         NextMethod("julian", x, ...)
> }

On Windows XP R 2.2.0 Patched (2005-11-21 r36410) you get:

Error: evaluation nested too deeply: infinite recursion / 
options(expressions=)?

and on Windows XP R 2.1.1 Patched (2005-09-19) you get:

Error: protect(): protection stack overflow

It seems that the R.2.2.0 revision you have does not protect against 
this.  I agree that it should not be possible to crash R, but is it 
valid to call NextMethod() in a default function? [R core, should this 
ever be allowed?]

I do not know exactly how NextMethod() is expected to work here, but I 
could imaging that 'x' has class 'Date' when NextMethod() is called and 
the "next" class will the be the default one so you call 
julian.default() again ending up in an infinite call.  This makes sense 
from the errors I get above.  Try this and see what you get in your version:

julian.default <- function(x, ...) {
   cat("In julian.default()\n")
   x <- as.Date(x)
   NextMethod("julian", x, ...)
}

Was you intention to do the following instead

  julian.default <- function(x, ...) {
    x <- as.Date(x)
    julian(x, ...)
  }

where julian() is the generic function?

Cheers

Henrik


> Here is a test example 
> 
> 
>>m <- as.Date("1972-09-27") + 0:10
>>m 
> 
>  [1] "1972-09-27" "1972-09-28" "1972-09-29" "1972-09-30" "1972-10-01"
> "1972-10-02" "1972-10-03"
>  [8] "1972-10-04" "1972-10-05" "1972-10-06" "1972-10-07"
> 
>>class(m)
> 
> [1] "Date"
> 
>>julian(m)
> 
>  [1] 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010
> attr(,"origin")
> [1] "1970-01-01"
> 
> 
>>m <- as.character(m)
>>class(m)
> 
> [1] "character"
> 
> 
>>julian(m)
> 
> 
> < R crashes>
> 
> --please do not edit the information below--
> 
> Version:
>  platform = i386-pc-mingw32
>  arch = i386
>  os = mingw32
>  system = i386, mingw32
>  status = 
>  major = 2
>  minor = 2.0
>  year = 2005
>  month = 10
>  day = 06
>  svn rev = 35749
>  language = R
> 
> 
> 
> Bill Venables, 
> CMIS, CSIRO Laboratories, 
> PO Box 120, Cleveland, Qld. 4163 
> AUSTRALIA 
> Office Phone (email preferred): +61 7 3826 7251 
> Fax (if absolutely necessary):    +61 7 3826 7304 
> Mobile (rarely used):                +61 4 1963 4642 
> Home Phone:                          +61 7 3286 7700 
> mailto:Bill.Venables at csiro.au 
> http://www.cmis.csiro.au/bill.venables/
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From Bill.Venables at csiro.au  Wed Dec 21 06:06:42 2005
From: Bill.Venables at csiro.au (Bill.Venables@csiro.au)
Date: Wed, 21 Dec 2005 16:06:42 +1100
Subject: [Rd] NextMethod causes R 2.2.0 to crash (PR#8416)
Message-ID: <B998A44C8986644EA8029CFE6396A92454671E@exqld2-bne.qld.csiro.au>

Thanks Hendrik.

My main concern is that it should not be so easy to crash R.

On whether or not NextMethod from within the default method is kosher or
not - I would have thought so, but clearly I'm wrong here.  Perhaps
NextMethod within a default method should be something that at least
attracts a warning.

Regards,

Bill Venables, 
CMIS, CSIRO Laboratories, 
PO Box 120, Cleveland, Qld. 4163 
AUSTRALIA 
Office Phone (email preferred): +61 7 3826 7251 
Fax (if absolutely necessary):    +61 7 3826 7304 
Mobile (rarely used):                +61 4 1963 4642 
Home Phone:                          +61 7 3286 7700 
mailto:Bill.Venables at csiro.au 
http://www.cmis.csiro.au/bill.venables/ 



-----Original Message-----
From: Henrik Bengtsson [mailto:hb at maths.lth.se] 
Sent: Wednesday, 21 December 2005 1:48 PM
To: Venables, Bill (CMIS, Cleveland)
Cc: r-devel at stat.math.ethz.ch; R-bugs at biostat.ku.dk
Subject: Re: [Rd] NextMethod causes R 2.2.0 to crash (PR#8416)


Bill.Venables at csiro.au wrote:
> I found writing the following default method the for the generic
> function "julian" causes R to crash.
> 
> 
> julian.default <- function(x, ...) {
>         x <- as.Date(x)
>         NextMethod("julian", x, ...)
> }

On Windows XP R 2.2.0 Patched (2005-11-21 r36410) you get:

Error: evaluation nested too deeply: infinite recursion / 
options(expressions=)?

and on Windows XP R 2.1.1 Patched (2005-09-19) you get:

Error: protect(): protection stack overflow

It seems that the R.2.2.0 revision you have does not protect against 
this.  I agree that it should not be possible to crash R, but is it 
valid to call NextMethod() in a default function? [R core, should this 
ever be allowed?]

I do not know exactly how NextMethod() is expected to work here, but I 
could imaging that 'x' has class 'Date' when NextMethod() is called and 
the "next" class will the be the default one so you call 
julian.default() again ending up in an infinite call.  This makes sense 
from the errors I get above.  Try this and see what you get in your
version:

julian.default <- function(x, ...) {
   cat("In julian.default()\n")
   x <- as.Date(x)
   NextMethod("julian", x, ...)
}

Was you intention to do the following instead

  julian.default <- function(x, ...) {
    x <- as.Date(x)
    julian(x, ...)
  }

where julian() is the generic function?

Cheers

Henrik


> Here is a test example 
> 
> 
>>m <- as.Date("1972-09-27") + 0:10
>>m 
> 
>  [1] "1972-09-27" "1972-09-28" "1972-09-29" "1972-09-30" "1972-10-01"
> "1972-10-02" "1972-10-03"
>  [8] "1972-10-04" "1972-10-05" "1972-10-06" "1972-10-07"
> 
>>class(m)
> 
> [1] "Date"
> 
>>julian(m)
> 
>  [1] 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010
> attr(,"origin")
> [1] "1970-01-01"
> 
> 
>>m <- as.character(m)
>>class(m)
> 
> [1] "character"
> 
> 
>>julian(m)
> 
> 
> < R crashes>
> 
> --please do not edit the information below--
> 
> Version:
>  platform = i386-pc-mingw32
>  arch = i386
>  os = mingw32
>  system = i386, mingw32
>  status = 
>  major = 2
>  minor = 2.0
>  year = 2005
>  month = 10
>  day = 06
>  svn rev = 35749
>  language = R
> 
> 
> 
> Bill Venables, 
> CMIS, CSIRO Laboratories, 
> PO Box 120, Cleveland, Qld. 4163 
> AUSTRALIA 
> Office Phone (email preferred): +61 7 3826 7251 
> Fax (if absolutely necessary):    +61 7 3826 7304 
> Mobile (rarely used):                +61 4 1963 4642 
> Home Phone:                          +61 7 3286 7700 
> mailto:Bill.Venables at csiro.au 
> http://www.cmis.csiro.au/bill.venables/
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From ripley at stats.ox.ac.uk  Wed Dec 21 10:48:48 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 21 Dec 2005 10:48:48 +0100 (CET)
Subject: [Rd] NextMethod causes R 2.2.0 to crash (PR#8416)
Message-ID: <20051221094848.0CB2219A78@slim.kubism.ku.dk>

Bill,

This is a 2.2.0 Windows problem, solved in 2.2.1.  What happened was that 
someone trying to be helpful increased the evaluation nesting limit in 
2.1.0, and Windows has a small C stack (2Mb) which can easily be exceeded.
I now get

> julian(m)

Error: evaluation nested too deeply: infinite recursion / options(expressions=)?

as I should.  The nesting limit has been reduced and the C stack size 
increased.

It is legitimate to call NextMethod in a default method, but it is all too 
easy to get loops.  In your case you want the Date method, not the next 
method (which since there is only one class will be the default).

I would advise Windows users of 2.2.0 to

1) update
2) if that is not possible, set options(expressions=1000).

Brian

On Wed, 21 Dec 2005 Bill.Venables at csiro.au wrote:

> I found writing the following default method the for the generic
> function "julian" causes R to crash.
>
>
> julian.default <- function(x, ...) {
>        x <- as.Date(x)
>        NextMethod("julian", x, ...)
> }
>
> Here is a test example
>
>> m <- as.Date("1972-09-27") + 0:10
>> m
> [1] "1972-09-27" "1972-09-28" "1972-09-29" "1972-09-30" "1972-10-01"
> "1972-10-02" "1972-10-03"
> [8] "1972-10-04" "1972-10-05" "1972-10-06" "1972-10-07"
>> class(m)
> [1] "Date"
>> julian(m)
> [1] 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010
> attr(,"origin")
> [1] "1970-01-01"
>
>> m <- as.character(m)
>> class(m)
> [1] "character"
>
>> julian(m)
>
> < R crashes>
>
> --please do not edit the information below--
>
> Version:
> platform = i386-pc-mingw32
> arch = i386
> os = mingw32
> system = i386, mingw32
> status =
> major = 2
> minor = 2.0
> year = 2005
> month = 10
> day = 06
> svn rev = 35749
> language = R
>
>
>
> Bill Venables,
> CMIS, CSIRO Laboratories,
> PO Box 120, Cleveland, Qld. 4163
> AUSTRALIA
> Office Phone (email preferred): +61 7 3826 7251
> Fax (if absolutely necessary):    +61 7 3826 7304
> Mobile (rarely used):                +61 4 1963 4642
> Home Phone:                          +61 7 3286 7700
> mailto:Bill.Venables at csiro.au
> http://www.cmis.csiro.au/bill.venables/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From edd at debian.org  Wed Dec 21 15:00:09 2005
From: edd at debian.org (edd@debian.org)
Date: Wed, 21 Dec 2005 15:00:09 +0100 (CET)
Subject: [Rd] (Debian Bug 344248): R segfaults when pressing Delete (PR#8420)
Message-ID: <20051221140009.D28A219A87@slim.kubism.ku.dk>


--CE+1k2dSO48ffgeK
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline

Resend after type in mailheader.  I have the bug on my system with
yesterday's R 2.2.1. A library mismatch is still a likely cause.

Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison

--CE+1k2dSO48ffgeK
Content-Type: message/rfc822
Content-Disposition: inline

Return-path: <>
X-Spam-Checker-Version: SpamAssassin 3.1.0 (2005-09-13) on basebud.nulle.part
X-Spam-Level: 
X-Spam-Status: No, score=-2.5 required=4.9 tests=BAYES_00,FORGED_RCVD_HELO 
	autolearn=ham version=3.1.0
Received: from sccrmhc11.comcast.net ([63.240.77.81])
	by master.debian.org with esmtp (Exim 4.50)
	id 1Ep3A7-0001sJ-Py
	for edd at debian.org; Wed, 21 Dec 2005 06:33:43 -0600
Received: from basebud.nulle.part (c-67-174-11-185.hsd1.il.comcast.net[67.174.11.185])
          by comcast.net (sccrmhc11) with ESMTP
          id <20051221123308011005fbjme>; Wed, 21 Dec 2005 12:33:13 +0000
Received: from Debian-exim by basebud.nulle.part with local (Exim 4.60)
	id 1Ep39X-0005dm-5V
	for edd at debian.org; Wed, 21 Dec 2005 06:33:07 -0600
Auto-Submitted: auto-replied
From: Mail Delivery System <Mailer-Daemon at eddelbuettel.com>
To: edd at debian.org
Subject: Mail failure - malformed recipient address
Message-Id: <E1Ep39X-0005dm-5V at basebud.nulle.part>
Date: Wed, 21 Dec 2005 06:33:07 -0600
Delivered-To: edd at debian.org

A message that you sent contained one or more recipient addresses that were
incorrectly constructed:

  r-bugs at biostat@ku.dk: malformed address: @ku.dk may not follow r-bugs at biostat

This address has been ignored. The other addresses in the message were
syntactically valid and have been passed on for an attempt at delivery.

------ This is a copy of your message, including all the headers. ------

MIME-Version: 1.0
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit
Message-ID: <17321.19331.86463.766759 at basebud.nulle.part>
Date: Wed, 21 Dec 2005 06:33:07 -0600
To: r-bugs at biostat@ku.dk
CC: Ethan Glasser-Camp <glasse at rpi.edu>, 344248-forwarded at bugs.debian.org, 
Subject: Re: Bug#344248: R crashes when I press "Delete"
In-Reply-To: <43A8FB28.8000607 at rpi.edu>
References: <43A8FB28.8000607 at rpi.edu>
X-Mailer: VM 7.19 under Emacs 21.4.1
From: Dirk Eddelbuettel <edd at debian.org>
X-rewrote-sender: edd at eddelbuettel.com


On 21 December 2005 at 01:50, Ethan Glasser-Camp wrote:
| Package: r-base-core
| Version: 2.2.1-1
| 
| When I run R, I can cause a crash by simply pressing Delete. Backspace works
| fine, and I can use ESS without problems.

Uh-oh.

| ethan at sundance:~$ R
| 
| R : Copyright 2005, The R Foundation for Statistical Computing
| Version 2.2.1  (2005-12-20 r36812)
| ISBN 3-900051-07-0
| 
| R is free software and comes with ABSOLUTELY NO WARRANTY.
| You are welcome to redistribute it under certain conditions.
| Type 'license()' or 'licence()' for distribution details.
| 
| R is a collaborative project with many contributors.
| Type 'contributors()' for more information and
| 'citation()' on how to cite R or R packages in publications.
| 
| Type 'demo()' for some demos, 'help()' for on-line help, or
| 'help.start()' for an HTML browser interface to help.
| Type 'q()' to quit R.
| 
| [Previously saved workspace restored]

Could you (temporarily) remove that file?

| > Segmentation fault
| ethan at sundance:~$

That said, I just tried this where I seemed to have no ~/.RData file.
Pressing <Deletet><Return> leads to a SegFault.

I will pass this on R Core. 

Thanks for the bug report.
 
Dirk

| 
| 
| Here is a list of packages I thought might be relevant:
| 
| $ dpkg -l r-* libreadline*
| Desired=Unknown/Install/Remove/Purge/Hold
| | Status=Not/Installed/Config-files/Unpacked/Failed-config/Half-installed
| |/ Err?=(none)/Hold/Reinst-required/X=both-problems (Status,Err: uppercase=bad)
| ||/ Name           Version        Description
| +++-==============-==============-============================================
| un  libreadline-co <none>         (no description available)
| un  libreadline-de <none>         (no description available)
| ii  libreadline-ru 1.8.3+1.8.4pre Readline interface for Ruby 1.8
| ii  libreadline4   4.3-18         GNU readline and history libraries, run-time
| un  libreadline4-d <none>         (no description available)
| ii  libreadline5   5.1-1          GNU readline and history libraries, run-time
| ii  libreadline5-d 5.1-1          GNU readline and history libraries, developm
| ii  r-base         2.2.1-1        GNU R statistical computing language and env
| ii  r-base-core    2.2.1-1        GNU R core of statistical computing language
| un  r-base-dev     <none>         (no description available)
| ii  r-base-html    2.2.1-1        GNU R html docs for statistical computing sy
| ii  r-base-latex   2.2.1-1        GNU R LaTeX docs for statistical computing s
| ii  r-cran-boot    1.2.24-1       GNU R package for bootstrapping functions fr
| ii  r-cran-cluster 1.10.2-1       GNU R package for cluster analysis by Rousse
| ii  r-cran-foreign 0.8.12-1       GNU R package to read/write data from other
| ii  r-cran-gdata   2.1.2-1        GNU R package with data manipulation tools b
| ii  r-cran-gplots  2.2.0-1        GNU R package with tools for plotting data b
| un  r-cran-gregmis <none>         (no description available)
| ii  r-cran-gtools  2.2.2-1        GNU R package with R programming tools by Gr
| ii  r-cran-kernsmo 2.22.15-1      GNU R package for kernel smoothing and densi
| ii  r-cran-lattice 0.12-11.1-1    GNU R package for 'Trellis' graphics
| ii  r-cran-lattice 0.1.1-1        GNU R package of additional graphical displa
| ii  r-cran-mgcv    1.3-12-1       GNU R package for multiple parameter smoothi
| ii  r-cran-misc3d  0.3-1-1        GNU R collection of 3d plot functions and rg
| ii  r-cran-nlme    3.1.62-1       GNU R package for (non-)linear mixed effects
| ii  r-cran-quadpro 1.4.7-2        GNU R package for solving quadratic programm
| ii  r-cran-rgl     0.65-1         GNU R package for three-dimensional visualis
| ii  r-cran-rpart   3.1.27-1       GNU R package for recursive partitioning and
| ii  r-cran-surviva 2.20-1         GNU R package for survival analysis
| un  r-cran-tkrplot <none>         (no description available)
| ii  r-cran-vr      7.2.23-1       GNU R package accompanying the Venables and
| un  r-doc-html     <none>         (no description available)
| ii  r-doc-info     2.2.1-1        GNU R info manuals statistical computing sys
| un  r-doc-pdf      <none>         (no description available)
| un  r-mathlib      <none>         (no description available)
| ii  r-recommended  2.2.1-1        GNU R collection of recommended packages [me
| 
| 
| Please let me know if there is anything else I can do to help.
| 
| Ethan

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison

--CE+1k2dSO48ffgeK--


From MSchwartz at mn.rr.com  Wed Dec 21 15:27:21 2005
From: MSchwartz at mn.rr.com (MSchwartz@mn.rr.com)
Date: Wed, 21 Dec 2005 15:27:21 +0100 (CET)
Subject: [Rd] (Debian Bug 344248): R segfaults when pressing Delete
	(PR#8421)
Message-ID: <20051221142721.CA58219A76@slim.kubism.ku.dk>

On Wed, 2005-12-21 at 15:00 +0100, edd at debian.org wrote:
> --CE+1k2dSO48ffgeK
> Content-Type: text/plain; charset=us-ascii
> Content-Disposition: inline
> 
> Resend after type in mailheader.  I have the bug on my system with
> yesterday's R 2.2.1. A library mismatch is still a likely cause.
> 
> Dirk

<SNIP>

> On 21 December 2005 at 01:50, Ethan Glasser-Camp wrote:
> | Package: r-base-core
> | Version: 2.2.1-1
> | 
> | When I run R, I can cause a crash by simply pressing Delete. Backspace works
> | fine, and I can use ESS without problems.
> 
> Uh-oh.
> 
> | ethan at sundance:~$ R
> | 
> | R : Copyright 2005, The R Foundation for Statistical Computing
> | Version 2.2.1  (2005-12-20 r36812)
> | ISBN 3-900051-07-0
> | 
> | R is free software and comes with ABSOLUTELY NO WARRANTY.
> | You are welcome to redistribute it under certain conditions.
> | Type 'license()' or 'licence()' for distribution details.
> | 
> | R is a collaborative project with many contributors.
> | Type 'contributors()' for more information and
> | 'citation()' on how to cite R or R packages in publications.
> | 
> | Type 'demo()' for some demos, 'help()' for on-line help, or
> | 'help.start()' for an HTML browser interface to help.
> | Type 'q()' to quit R.
> | 
> | [Previously saved workspace restored]
> 
> Could you (temporarily) remove that file?
> 
> | > Segmentation fault
> | ethan at sundance:~$
> 
> That said, I just tried this where I seemed to have no ~/.RData file.
> Pressing <Deletet><Return> leads to a SegFault.
> 
> I will pass this on R Core. 
> 
> Thanks for the bug report.
>  
> Dirk
> 
> | 
> | 
> | Here is a list of packages I thought might be relevant:
> | 
> | $ dpkg -l r-* libreadline*
> | Desired=Unknown/Install/Remove/Purge/Hold
> | | Status=Not/Installed/Config-files/Unpacked/Failed-config/Half-installed
> | |/ Err?=(none)/Hold/Reinst-required/X=both-problems (Status,Err: uppercase=bad)
> | ||/ Name           Version        Description
> | +++-==============-==============-============================================
> | un  libreadline-co <none>         (no description available)
> | un  libreadline-de <none>         (no description available)
> | ii  libreadline-ru 1.8.3+1.8.4pre Readline interface for Ruby 1.8
> | ii  libreadline4   4.3-18         GNU readline and history libraries, run-time
> | un  libreadline4-d <none>         (no description available)
> | ii  libreadline5   5.1-1          GNU readline and history libraries, run-time
> | ii  libreadline5-d 5.1-1          GNU readline and history libraries, developm
> | ii  r-base         2.2.1-1        GNU R statistical computing language and env
> | ii  r-base-core    2.2.1-1        GNU R core of statistical computing language
> | un  r-base-dev     <none>         (no description available)
> | ii  r-base-html    2.2.1-1        GNU R html docs for statistical computing sy
> | ii  r-base-latex   2.2.1-1        GNU R LaTeX docs for statistical computing s
> | ii  r-cran-boot    1.2.24-1       GNU R package for bootstrapping functions fr
> | ii  r-cran-cluster 1.10.2-1       GNU R package for cluster analysis by Rousse
> | ii  r-cran-foreign 0.8.12-1       GNU R package to read/write data from other
> | ii  r-cran-gdata   2.1.2-1        GNU R package with data manipulation tools b
> | ii  r-cran-gplots  2.2.0-1        GNU R package with tools for plotting data b
> | un  r-cran-gregmis <none>         (no description available)
> | ii  r-cran-gtools  2.2.2-1        GNU R package with R programming tools by Gr
> | ii  r-cran-kernsmo 2.22.15-1      GNU R package for kernel smoothing and densi
> | ii  r-cran-lattice 0.12-11.1-1    GNU R package for 'Trellis' graphics
> | ii  r-cran-lattice 0.1.1-1        GNU R package of additional graphical displa
> | ii  r-cran-mgcv    1.3-12-1       GNU R package for multiple parameter smoothi
> | ii  r-cran-misc3d  0.3-1-1        GNU R collection of 3d plot functions and rg
> | ii  r-cran-nlme    3.1.62-1       GNU R package for (non-)linear mixed effects
> | ii  r-cran-quadpro 1.4.7-2        GNU R package for solving quadratic programm
> | ii  r-cran-rgl     0.65-1         GNU R package for three-dimensional visualis
> | ii  r-cran-rpart   3.1.27-1       GNU R package for recursive partitioning and
> | ii  r-cran-surviva 2.20-1         GNU R package for survival analysis
> | un  r-cran-tkrplot <none>         (no description available)
> | ii  r-cran-vr      7.2.23-1       GNU R package accompanying the Venables and
> | un  r-doc-html     <none>         (no description available)
> | ii  r-doc-info     2.2.1-1        GNU R info manuals statistical computing sys
> | un  r-doc-pdf      <none>         (no description available)
> | un  r-mathlib      <none>         (no description available)
> | ii  r-recommended  2.2.1-1        GNU R collection of recommended packages [me
> | 
> | 
> | Please let me know if there is anything else I can do to help.
> | 
> | Ethan


FWIW, I cannot replicate the segfault on FC4, with:

  Version 2.2.1  (2005-12-20 r36812)

compiled from source yesterday.

I have:

$ rpm -qa | grep readline
readline-5.0-3
readline-devel-5.0-3
compat-readline43-4.3-2

I tried in gnome-terminal, konsole and xterm, using 'R' (with and
without a .RData file) as well as 'R --vanilla'.

HTH,

Marc Schwartz


From ripley at stats.ox.ac.uk  Wed Dec 21 15:33:04 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Wed, 21 Dec 2005 15:33:04 +0100 (CET)
Subject: [Rd] (Debian Bug 344248): R segfaults when pressing Delete
	(PR#8422)
Message-ID: <20051221143304.3A57319A76@slim.kubism.ku.dk>

On Wed, 21 Dec 2005 edd at debian.org wrote:

>
> --CE+1k2dSO48ffgeK
> Content-Type: text/plain; charset=us-ascii
> Content-Disposition: inline
>
> Resend after type in mailheader.  I have the bug on my system with
> yesterday's R 2.2.1. A library mismatch is still a likely cause.

This seems to be a readline 5.1 error.  I was unable to reproduce it with
4.3 or 5.0.

gdb) bt
#0  0xb7f4c942 in _rl_dispatch_callback () from 
/usr/local/lib/libreadline.so.5
#1  0xb7f5fd82 in rl_callback_read_char () from 
/usr/local/lib/libreadline.so.5
#2  0x0816b98b in Rstd_ReadConsole (prompt=0xb7f6fafc "", buf=0xbf8bb1ec "", len=1024,
     addtohistory=0) at /users/ripley/R/svn/R-devel/src/unix/sys-std.c:663

Switching the link from libreadline.so.5 back to libreadline.so.5.0 made 
this behave again.

Can you confirm you are running rl5.1?  Given the segfault is readline not 
in R itself, it is at the very least a change in behaviour in a supposedly 
compatible version of a dynamic library so it seems to me the bug should 
be assigned to readline not R.

Brian


>
> Dirk
>
> -- 
> Hell, there are no rules here - we're trying to accomplish something.
>                                                  -- Thomas A. Edison
>
> --CE+1k2dSO48ffgeK
> Content-Type: message/rfc822
> Content-Disposition: inline
>
> Return-path: <>
> X-Spam-Checker-Version: SpamAssassin 3.1.0 (2005-09-13) on basebud.nulle.part
> X-Spam-Level:
> X-Spam-Status: No, score=-2.5 required=4.9 tests=BAYES_00,FORGED_RCVD_HELO
> 	autolearn=ham version=3.1.0
> Received: from sccrmhc11.comcast.net ([63.240.77.81])
> 	by master.debian.org with esmtp (Exim 4.50)
> 	id 1Ep3A7-0001sJ-Py
> 	for edd at debian.org; Wed, 21 Dec 2005 06:33:43 -0600
> Received: from basebud.nulle.part (c-67-174-11-185.hsd1.il.comcast.net[67.174.11.185])
>          by comcast.net (sccrmhc11) with ESMTP
>          id <20051221123308011005fbjme>; Wed, 21 Dec 2005 12:33:13 +0000
> Received: from Debian-exim by basebud.nulle.part with local (Exim 4.60)
> 	id 1Ep39X-0005dm-5V
> 	for edd at debian.org; Wed, 21 Dec 2005 06:33:07 -0600
> Auto-Submitted: auto-replied
> From: Mail Delivery System <Mailer-Daemon at eddelbuettel.com>
> To: edd at debian.org
> Subject: Mail failure - malformed recipient address
> Message-Id: <E1Ep39X-0005dm-5V at basebud.nulle.part>
> Date: Wed, 21 Dec 2005 06:33:07 -0600
> Delivered-To: edd at debian.org
>
> A message that you sent contained one or more recipient addresses that were
> incorrectly constructed:
>
>  r-bugs at biostat@ku.dk: malformed address: @ku.dk may not follow r-bugs at biostat
>
> This address has been ignored. The other addresses in the message were
> syntactically valid and have been passed on for an attempt at delivery.
>
> ------ This is a copy of your message, including all the headers. ------
>
> MIME-Version: 1.0
> Content-Type: text/plain; charset=us-ascii
> Content-Transfer-Encoding: 7bit
> Message-ID: <17321.19331.86463.766759 at basebud.nulle.part>
> Date: Wed, 21 Dec 2005 06:33:07 -0600
> To: r-bugs at biostat@ku.dk
> CC: Ethan Glasser-Camp <glasse at rpi.edu>, 344248-forwarded at bugs.debian.org,
> Subject: Re: Bug#344248: R crashes when I press "Delete"
> In-Reply-To: <43A8FB28.8000607 at rpi.edu>
> References: <43A8FB28.8000607 at rpi.edu>
> X-Mailer: VM 7.19 under Emacs 21.4.1
> From: Dirk Eddelbuettel <edd at debian.org>
> X-rewrote-sender: edd at eddelbuettel.com
>
>
> On 21 December 2005 at 01:50, Ethan Glasser-Camp wrote:
> | Package: r-base-core
> | Version: 2.2.1-1
> |
> | When I run R, I can cause a crash by simply pressing Delete. Backspace works
> | fine, and I can use ESS without problems.
>
> Uh-oh.
>
> | ethan at sundance:~$ R
> |
> | R : Copyright 2005, The R Foundation for Statistical Computing
> | Version 2.2.1  (2005-12-20 r36812)
> | ISBN 3-900051-07-0
> |
> | R is free software and comes with ABSOLUTELY NO WARRANTY.
> | You are welcome to redistribute it under certain conditions.
> | Type 'license()' or 'licence()' for distribution details.
> |
> | R is a collaborative project with many contributors.
> | Type 'contributors()' for more information and
> | 'citation()' on how to cite R or R packages in publications.
> |
> | Type 'demo()' for some demos, 'help()' for on-line help, or
> | 'help.start()' for an HTML browser interface to help.
> | Type 'q()' to quit R.
> |
> | [Previously saved workspace restored]
>
> Could you (temporarily) remove that file?
>
> | > Segmentation fault
> | ethan at sundance:~$
>
> That said, I just tried this where I seemed to have no ~/.RData file.
> Pressing <Deletet><Return> leads to a SegFault.
>
> I will pass this on R Core.
>
> Thanks for the bug report.
>
> Dirk
>
> |
> |
> | Here is a list of packages I thought might be relevant:
> |
> | $ dpkg -l r-* libreadline*
> | Desired=Unknown/Install/Remove/Purge/Hold
> | | Status=Not/Installed/Config-files/Unpacked/Failed-config/Half-installed
> | |/ Err?=(none)/Hold/Reinst-required/X=both-problems (Status,Err: uppercase=bad)
> | ||/ Name           Version        Description
> | +++-==============-==============-============================================
> | un  libreadline-co <none>         (no description available)
> | un  libreadline-de <none>         (no description available)
> | ii  libreadline-ru 1.8.3+1.8.4pre Readline interface for Ruby 1.8
> | ii  libreadline4   4.3-18         GNU readline and history libraries, run-time
> | un  libreadline4-d <none>         (no description available)
> | ii  libreadline5   5.1-1          GNU readline and history libraries, run-time
> | ii  libreadline5-d 5.1-1          GNU readline and history libraries, developm
> | ii  r-base         2.2.1-1        GNU R statistical computing language and env
> | ii  r-base-core    2.2.1-1        GNU R core of statistical computing language
> | un  r-base-dev     <none>         (no description available)
> | ii  r-base-html    2.2.1-1        GNU R html docs for statistical computing sy
> | ii  r-base-latex   2.2.1-1        GNU R LaTeX docs for statistical computing s
> | ii  r-cran-boot    1.2.24-1       GNU R package for bootstrapping functions fr
> | ii  r-cran-cluster 1.10.2-1       GNU R package for cluster analysis by Rousse
> | ii  r-cran-foreign 0.8.12-1       GNU R package to read/write data from other
> | ii  r-cran-gdata   2.1.2-1        GNU R package with data manipulation tools b
> | ii  r-cran-gplots  2.2.0-1        GNU R package with tools for plotting data b
> | un  r-cran-gregmis <none>         (no description available)
> | ii  r-cran-gtools  2.2.2-1        GNU R package with R programming tools by Gr
> | ii  r-cran-kernsmo 2.22.15-1      GNU R package for kernel smoothing and densi
> | ii  r-cran-lattice 0.12-11.1-1    GNU R package for 'Trellis' graphics
> | ii  r-cran-lattice 0.1.1-1        GNU R package of additional graphical displa
> | ii  r-cran-mgcv    1.3-12-1       GNU R package for multiple parameter smoothi
> | ii  r-cran-misc3d  0.3-1-1        GNU R collection of 3d plot functions and rg
> | ii  r-cran-nlme    3.1.62-1       GNU R package for (non-)linear mixed effects
> | ii  r-cran-quadpro 1.4.7-2        GNU R package for solving quadratic programm
> | ii  r-cran-rgl     0.65-1         GNU R package for three-dimensional visualis
> | ii  r-cran-rpart   3.1.27-1       GNU R package for recursive partitioning and
> | ii  r-cran-surviva 2.20-1         GNU R package for survival analysis
> | un  r-cran-tkrplot <none>         (no description available)
> | ii  r-cran-vr      7.2.23-1       GNU R package accompanying the Venables and
> | un  r-doc-html     <none>         (no description available)
> | ii  r-doc-info     2.2.1-1        GNU R info manuals statistical computing sys
> | un  r-doc-pdf      <none>         (no description available)
> | un  r-mathlib      <none>         (no description available)
> | ii  r-recommended  2.2.1-1        GNU R collection of recommended packages [me
> |
> |
> | Please let me know if there is anything else I can do to help.
> |
> | Ethan
>
> -- 
> Hell, there are no rules here - we're trying to accomplish something.
>                                                  -- Thomas A. Edison
>
> --CE+1k2dSO48ffgeK--
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Wed Dec 21 15:41:38 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 21 Dec 2005 15:41:38 +0100
Subject: [Rd] R-bugs e-mail {was ...  (Debian Bug 344248): ...}
In-Reply-To: <20051221140009.D28A219A87@slim.kubism.ku.dk>
References: <20051221140009.D28A219A87@slim.kubism.ku.dk>
Message-ID: <17321.27042.31819.692232@stat.math.ethz.ch>

PLEASE, PLEASE:
do use
	R-bugs at R-project.org
and nothing else
(It will go to Kopenhagen alright currently,
 but if we could ensure everyone used the above address,
 it would become quite a bit easier to prevent most spam to get
 into the R bug repository)

Martin


From edd at debian.org  Wed Dec 21 15:48:25 2005
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 21 Dec 2005 14:48:25 +0000 (UTC)
Subject: [Rd]
	=?utf-8?q?=28Debian_Bug_344248=29=3A_R_segfaults_when_pressi?=
	=?utf-8?q?ng_Delete=09=28PR=238422=29?=
References: <20051221143304.3A57319A76@slim.kubism.ku.dk>
Message-ID: <loom.20051221T154124-205@post.gmane.org>

<ripley <at> stats.ox.ac.uk> writes:
> Can you confirm you are running rl5.1?  Given the segfault is readline not 

Yes: readline 5.1, just like the bug submitter (see at the very bottom).

> compatible version of a dynamic library so it seems to me the bug should 
> be assigned to readline not R.

Looks like it, yes. And from looking at http://bugs.debian.org/libreadline5
it seems that the same behaviour was just found with gdb.

Thanks for the quick replies!

Dirk

> > | ii  libreadline-ru 1.8.3+1.8.4pre Readline interface for Ruby 1.8
> > | ii  libreadline4   4.3-18         GNU readline and history libraries, 
run-time
> > | un  libreadline4-d <none>         (no description available)
> > | ii  libreadline5   5.1-1          GNU readline and history libraries, 
run-time
> > | ii  libreadline5-d 5.1-1          GNU readline and history libraries, 
developm
> > | ii  r-base         2.2.1-1        GNU R statistical computing language 
and env
> > | ii  r-base-core    2.2.1-1        GNU R core of statistical computing 
language


From hb at maths.lth.se  Wed Dec 21 16:21:56 2005
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Thu, 22 Dec 2005 02:21:56 +1100
Subject: [Rd] CRAN and R v2.2.1 for Windows
Message-ID: <43A97314.6060100@maths.lth.se>

Thanks for the new updates in v2.2.1.

I just noticed a few "problems" on 
http://cran.r-project.org/bin/windows/base/.

1) The CHANGES and NEWS files for v2.2.1 does not include info on v2.2.1 
but only details up until v2.2.0, cf. 
http://cran.r-project.org/src/base/NEWS

2) The patched version is now denoted "beta" (files and installation 
directory), which I believe is misleading since it is a patch of the 
"stable" version.

Cheers

Henrik


From murdoch at stats.uwo.ca  Wed Dec 21 16:38:29 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 21 Dec 2005 10:38:29 -0500
Subject: [Rd] CRAN and R v2.2.1 for Windows
In-Reply-To: <43A97314.6060100@maths.lth.se>
References: <43A97314.6060100@maths.lth.se>
Message-ID: <43A976F5.9040501@stats.uwo.ca>

On 12/21/2005 10:21 AM, Henrik Bengtsson wrote:
> Thanks for the new updates in v2.2.1.
> 
> I just noticed a few "problems" on 
> http://cran.r-project.org/bin/windows/base/.
> 
> 1) The CHANGES and NEWS files for v2.2.1 does not include info on v2.2.1 
> but only details up until v2.2.0, cf. 
> http://cran.r-project.org/src/base/NEWS

Yes, we noticed that just after packaging; the patches will fix it.

> 2) The patched version is now denoted "beta" (files and installation 
> directory), which I believe is misleading since it is a patch of the 
> "stable" version.

That should be fixed soon.  The handling for betas and patch versions is 
different, and sometimes there's a bit of a delay in the switchover as 
things fail on one or two builds.

Duncan Murdoch


From p.dalgaard at biostat.ku.dk  Wed Dec 21 16:49:47 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 21 Dec 2005 16:49:47 +0100
Subject: [Rd] CRAN and R v2.2.1 for Windows
In-Reply-To: <43A97314.6060100@maths.lth.se>
References: <43A97314.6060100@maths.lth.se>
Message-ID: <x2r786pi04.fsf@viggo.kubism.ku.dk>

Henrik Bengtsson <hb at maths.lth.se> writes:

> Thanks for the new updates in v2.2.1.
> 
> I just noticed a few "problems" on 
> http://cran.r-project.org/bin/windows/base/.
> 
> 1) The CHANGES and NEWS files for v2.2.1 does not include info on v2.2.1 
> but only details up until v2.2.0, cf. 
> http://cran.r-project.org/src/base/NEWS

They have info for "R 2.2.0 patched" and 2.2.1 is just a frozen
version of that. I.e., the only problem is that we forgot to change
the heading (and that nobody bothered to check for this sort of thing
in the 2-week beta period!).

I noticed the issue just after building the release, but decided that
it wasn't worth messing with the SVN tags for something as small as
this. 

 
> 2) The patched version is now denoted "beta" (files and installation 
> directory), which I believe is misleading since it is a patch of the 
> "stable" version.

"2.2.0 Patched" is changed to "2.2.1 beta" during the beta period. The
release script ends with

cd $SRCDIR
echo $REL "Patched"  > VERSION
svn commit -m "setup patch version"

so I believe this is a temporary situation and that r-patched will
become "2.2.1 Patched" next time around.

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From hpages at fhcrc.org  Wed Dec 21 22:14:56 2005
From: hpages at fhcrc.org (Herve Pages)
Date: Wed, 21 Dec 2005 13:14:56 -0800
Subject: [Rd] SVN-REVSION altered when building R-devel out of tree from
 last snapshot
In-Reply-To: <17319.50063.990876.191012@stat.math.ethz.ch>
References: <43A75A22.90404@fhcrc.org>
	<17319.50063.990876.191012@stat.math.ethz.ch>
Message-ID: <43A9C5D0.5030704@fhcrc.org>

Martin Maechler wrote:

>    Herve> Today I downloaded and compiled the last R-devel snapshot.
>    Herve> The SVN-REVISION in the tarball contains the following:
>
>    Herve> Revision: 36792
>    Herve> Last Changed Date: 2005-12-18
>
>    Herve> But after compiling on Unix (I compiled out of tree), 
>
>i.e. "in a separate build directory tree"
>
>    Herve> I ended up with an SVN-REVSION file containing:
>
>    Herve> Revision: unknown
>    Herve> Last Changed Date: Today
>
>    Herve> in the build tree.
>
>I can confirm this wrong behavior (Linux Redhat EL4).
>There must be something not yet perfect in our 'make' setup
>there.  If we are not in the srcdir, we create a 'non-tarball'
>file which I think is wrong;  in any case, this is buglet we'll fix.
>  
>
Hi Martin,

This problem was fixed in today's R-devel tarball 
(R-devel_2005-12-20.tar.bz2).
Thanks!

H.

-- 
------------------------
Herv? Pag?s
E-mail: hpages at fhcrc.org
 Phone: (206) 667-5791
   Fax: (206) 667-1319


From rpeng at jhsph.edu  Wed Dec 21 22:37:22 2005
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed, 21 Dec 2005 16:37:22 -0500
Subject: [Rd] random output with sub(fixed = TRUE)
Message-ID: <43A9CB12.1020803@jhsph.edu>

I've noticed what I think is curious behavior in using 'sub(fixed = TRUE)' and 
was wondering if my expectation is incorrect.  Here is one example:

v <- paste(0:10, "asdf", sep = ".")
sub(".asdf", "", v, fixed = TRUE)

The results I get are

 > sub(".asdf", "", v, fixed = TRUE)
  [1] "0"               "1\0st\0\0"       "2\0<af>\001\0\0" "3\0<af>\001\0\0"
  [5] "4\0mes\0"        "5\0<ba>\001\0\0" "6\0\0\0\0\0"     "7\0\0\0m\0"
  [9] "8\0\0\0t\0"      "9\0<fe>\0\0\0"   "10\0\0\0\0\0"
 >

I expected "0" in the first entry and everything else would be unchanged.  Your 
results may vary since every time I run 'sub()' in this way, I get a slightly 
different answer in entires 2 through 11.

As it turns out, 'gsub(fixed = TRUE)' gives me the answer I *actually* wanted, 
which was to replace the string in every entry.  But I still think the behavior 
of 'sub(fixed = TRUE) is a bit odd.

 > version
          _
platform x86_64-unknown-linux-gnu
arch     x86_64
os       linux-gnu
system   x86_64, linux-gnu
status
major    2
minor    2.1
year     2005
month    12
day      20
svn rev  36812
language R
 >

-roger
-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/


From p.dalgaard at biostat.ku.dk  Wed Dec 21 22:59:24 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 21 Dec 2005 22:59:24 +0100
Subject: [Rd] random output with sub(fixed = TRUE)
In-Reply-To: <43A9CB12.1020803@jhsph.edu>
References: <43A9CB12.1020803@jhsph.edu>
Message-ID: <x23bkmun5v.fsf@turmalin.kubism.ku.dk>

"Roger D. Peng" <rpeng at jhsph.edu> writes:

> I've noticed what I think is curious behavior in using 'sub(fixed = TRUE)' and 
> was wondering if my expectation is incorrect.  Here is one example:
> 
> v <- paste(0:10, "asdf", sep = ".")
> sub(".asdf", "", v, fixed = TRUE)
> 
> The results I get are
> 
>  > sub(".asdf", "", v, fixed = TRUE)
>   [1] "0"               "1\0st\0\0"       "2\0<af>\001\0\0" "3\0<af>\001\0\0"
>   [5] "4\0mes\0"        "5\0<ba>\001\0\0" "6\0\0\0\0\0"     "7\0\0\0m\0"
>   [9] "8\0\0\0t\0"      "9\0<fe>\0\0\0"   "10\0\0\0\0\0"
>  >
> 
> I expected "0" in the first entry and everything else would be unchanged.  Your 
> results may vary since every time I run 'sub()' in this way, I get a slightly 
> different answer in entires 2 through 11.
> 
> As it turns out, 'gsub(fixed = TRUE)' gives me the answer I *actually* wanted, 
> which was to replace the string in every entry.  But I still think the behavior 
> of 'sub(fixed = TRUE) is a bit odd.
> 
>  > version
>           _
> platform x86_64-unknown-linux-gnu
> arch     x86_64
> os       linux-gnu
> system   x86_64, linux-gnu
> status
> major    2
> minor    2.1
> year     2005
> month    12
> day      20
> svn rev  36812
> language R
>  >

Argh... 

year     2005
month    12
day      21

and something like this gets discovered. It's a ritual, I tell ya, a ritual!

If you look at the output and terminate all strings at the embedded
\0, it looks much more sensible, so it should be fairly easy to spot
the cause of this bug...

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From rpeng at jhsph.edu  Wed Dec 21 23:13:54 2005
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed, 21 Dec 2005 17:13:54 -0500
Subject: [Rd] random output with sub(fixed = TRUE)
In-Reply-To: <x23bkmun5v.fsf@turmalin.kubism.ku.dk>
References: <43A9CB12.1020803@jhsph.edu> <x23bkmun5v.fsf@turmalin.kubism.ku.dk>
Message-ID: <43A9D3A2.6040103@jhsph.edu>

Well, who am I to break this long-standing ritual? :)

Interestingly, while the printed output looks wrong, I get

 > v <- paste(0:10, "asdf", sep = ".")
 > a <- sub(".asdf", "", v, fixed = TRUE)
 > b <- as.character(0:10)
 > identical(a, b)
[1] TRUE
 >

-roger

Peter Dalgaard wrote:
> "Roger D. Peng" <rpeng at jhsph.edu> writes:
> 
> 
>>I've noticed what I think is curious behavior in using 'sub(fixed = TRUE)' and 
>>was wondering if my expectation is incorrect.  Here is one example:
>>
>>v <- paste(0:10, "asdf", sep = ".")
>>sub(".asdf", "", v, fixed = TRUE)
>>
>>The results I get are
>>
>> > sub(".asdf", "", v, fixed = TRUE)
>>  [1] "0"               "1\0st\0\0"       "2\0<af>\001\0\0" "3\0<af>\001\0\0"
>>  [5] "4\0mes\0"        "5\0<ba>\001\0\0" "6\0\0\0\0\0"     "7\0\0\0m\0"
>>  [9] "8\0\0\0t\0"      "9\0<fe>\0\0\0"   "10\0\0\0\0\0"
>> >
>>
>>I expected "0" in the first entry and everything else would be unchanged.  Your 
>>results may vary since every time I run 'sub()' in this way, I get a slightly 
>>different answer in entires 2 through 11.
>>
>>As it turns out, 'gsub(fixed = TRUE)' gives me the answer I *actually* wanted, 
>>which was to replace the string in every entry.  But I still think the behavior 
>>of 'sub(fixed = TRUE) is a bit odd.
>>
>> > version
>>          _
>>platform x86_64-unknown-linux-gnu
>>arch     x86_64
>>os       linux-gnu
>>system   x86_64, linux-gnu
>>status
>>major    2
>>minor    2.1
>>year     2005
>>month    12
>>day      20
>>svn rev  36812
>>language R
>> >
> 
> 
> Argh... 
> 
> year     2005
> month    12
> day      21
> 
> and something like this gets discovered. It's a ritual, I tell ya, a ritual!
> 
> If you look at the output and terminate all strings at the embedded
> \0, it looks much more sensible, so it should be fairly easy to spot
> the cause of this bug...
> 

-- 
Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/


From ripley at stats.ox.ac.uk  Wed Dec 21 23:29:54 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 21 Dec 2005 22:29:54 +0000 (GMT)
Subject: [Rd] random output with sub(fixed = TRUE)
In-Reply-To: <43A9D3A2.6040103@jhsph.edu>
References: <43A9CB12.1020803@jhsph.edu> <x23bkmun5v.fsf@turmalin.kubism.ku.dk>
	<43A9D3A2.6040103@jhsph.edu>
Message-ID: <Pine.LNX.4.61.0512212222510.26393@gannet.stats>

On Wed, 21 Dec 2005, Roger D. Peng wrote:

> Well, who am I to break this long-standing ritual? :)
>
> Interestingly, while the printed output looks wrong, I get
>
> > v <- paste(0:10, "asdf", sep = ".")
> > a <- sub(".asdf", "", v, fixed = TRUE)
> > b <- as.character(0:10)
> > identical(a, b)
> [1] TRUE
> >

identical is wrong!  R character strings have a true length and a C-style
length: print() prints the all the characters, even those after embedded 
nuls.  identical uses

 	    if(strcmp(CHAR(STRING_ELT(x, i)),
 		      CHAR(STRING_ELT(y, i))) != 0)

which is C-style.

The issue is character.c:1015 whose nr gets trashed: note the first answer 
in the vector is correct.  So easy to fix.

This code has been as currently for years, so I don't think this is at all 
related to the release of 2.2.1.

> Peter Dalgaard wrote:
>> "Roger D. Peng" <rpeng at jhsph.edu> writes:
>>
>>
>>> I've noticed what I think is curious behavior in using 'sub(fixed = TRUE)' and
>>> was wondering if my expectation is incorrect.  Here is one example:
>>>
>>> v <- paste(0:10, "asdf", sep = ".")
>>> sub(".asdf", "", v, fixed = TRUE)
>>>
>>> The results I get are
>>>
>>>> sub(".asdf", "", v, fixed = TRUE)
>>>  [1] "0"               "1\0st\0\0"       "2\0<af>\001\0\0" "3\0<af>\001\0\0"
>>>  [5] "4\0mes\0"        "5\0<ba>\001\0\0" "6\0\0\0\0\0"     "7\0\0\0m\0"
>>>  [9] "8\0\0\0t\0"      "9\0<fe>\0\0\0"   "10\0\0\0\0\0"
>>>>
>>>
>>> I expected "0" in the first entry and everything else would be unchanged.  Your
>>> results may vary since every time I run 'sub()' in this way, I get a slightly
>>> different answer in entires 2 through 11.
>>>
>>> As it turns out, 'gsub(fixed = TRUE)' gives me the answer I *actually* wanted,
>>> which was to replace the string in every entry.  But I still think the behavior
>>> of 'sub(fixed = TRUE) is a bit odd.
>>>
>>>> version
>>>          _
>>> platform x86_64-unknown-linux-gnu
>>> arch     x86_64
>>> os       linux-gnu
>>> system   x86_64, linux-gnu
>>> status
>>> major    2
>>> minor    2.1
>>> year     2005
>>> month    12
>>> day      20
>>> svn rev  36812
>>> language R
>>>>
>>
>>
>> Argh...
>>
>> year     2005
>> month    12
>> day      21
>>
>> and something like this gets discovered. It's a ritual, I tell ya, a ritual!
>>
>> If you look at the output and terminate all strings at the embedded
>> \0, it looks much more sensible, so it should be fairly easy to spot
>> the cause of this bug...
>>
>
> -- 
> Roger D. Peng  |  http://www.biostat.jhsph.edu/~rpeng/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hpages at fhcrc.org  Thu Dec 22 00:12:15 2005
From: hpages at fhcrc.org (Herve Pages)
Date: Wed, 21 Dec 2005 15:12:15 -0800
Subject: [Rd] Build error on Mac OS X
Message-ID: <43A9E14F.5060405@fhcrc.org>

Hi,


The following commands:

 > tar zxvf R-devel_2005-12-14.tar.gz
 > mv R-devel R-2.3
 > cd R-2.3
 > ./configure --with-blas='-framework vecLib' --with-lapack
 > make

give me the following error on my Mac OS X system:

...
g77  -fno-common  -g -O2 -c xxxpr.f -o xxxpr.o
make[3]: *** No rule to make target `-lintl', needed by `libR.dylib'.  Stop.
make[2]: *** [R] Error 2
make[1]: *** [R] Error 1
make: *** [R] Error 1


I don't get that problem with R-devel daily snapshots from before 2005-12-14
and I get it with (almost) all snaphots between 2005-12-14 and today.


 > uname -a
Darwin possum2.fhcrc.org 7.9.0 Darwin Kernel Version 7.9.0: Wed Mar 30 
20:11:17 PST 2005; root:xnu/xnu-517.12.7.obj~1/RELEASE_PPC  Power 
Macintosh powerpc


Regards,


H.

-- 
------------------------
Herv? Pag?s
E-mail: hpages at fhcrc.org
 Phone: (206) 667-5791
   Fax: (206) 667-1319


From h.wickham at gmail.com  Thu Dec 22 04:45:30 2005
From: h.wickham at gmail.com (hadley wickham)
Date: Wed, 21 Dec 2005 21:45:30 -0600
Subject: [Rd] R-bugs e-mail {was ... (Debian Bug 344248): ...}
In-Reply-To: <17321.27042.31819.692232@stat.math.ethz.ch>
References: <20051221140009.D28A219A87@slim.kubism.ku.dk>
	<17321.27042.31819.692232@stat.math.ethz.ch>
Message-ID: <f8e6ff050512211945y7fa6b3fat7e5e22a2cd487f15@mail.gmail.com>

> PLEASE, PLEASE:
> do use
>         R-bugs at R-project.org
> and nothing else

Perhaps
http://bugs.r-project.org/cgi-bin/R
should be updated then?

Hadley


From murdoch at stats.uwo.ca  Thu Dec 22 05:24:05 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 21 Dec 2005 23:24:05 -0500
Subject: [Rd] random output with sub(fixed = TRUE)
In-Reply-To: <43A9D3A2.6040103@jhsph.edu>
References: <43A9CB12.1020803@jhsph.edu> <x23bkmun5v.fsf@turmalin.kubism.ku.dk>
	<43A9D3A2.6040103@jhsph.edu>
Message-ID: <43AA2A65.9060009@stats.uwo.ca>

On 12/21/2005 5:13 PM, Roger D. Peng wrote:
> Well, who am I to break this long-standing ritual? :)
> 
> Interestingly, while the printed output looks wrong, I get
> 
>  > v <- paste(0:10, "asdf", sep = ".")
>  > a <- sub(".asdf", "", v, fixed = TRUE)
>  > b <- as.character(0:10)
>  > identical(a, b)
> [1] TRUE
>  >
> 
> -roger

I think finding two separate bugs on the day after the release goes a 
bit beyond what is necessary to satisfy the ritual.

Duncan Murdoch

> 
> Peter Dalgaard wrote:
> 
>>"Roger D. Peng" <rpeng at jhsph.edu> writes:
>>
>>
>>
>>>I've noticed what I think is curious behavior in using 'sub(fixed = TRUE)' and 
>>>was wondering if my expectation is incorrect.  Here is one example:
>>>
>>>v <- paste(0:10, "asdf", sep = ".")
>>>sub(".asdf", "", v, fixed = TRUE)
>>>
>>>The results I get are
>>>
>>>
>>>>sub(".asdf", "", v, fixed = TRUE)
>>>
>>> [1] "0"               "1\0st\0\0"       "2\0<af>\001\0\0" "3\0<af>\001\0\0"
>>> [5] "4\0mes\0"        "5\0<ba>\001\0\0" "6\0\0\0\0\0"     "7\0\0\0m\0"
>>> [9] "8\0\0\0t\0"      "9\0<fe>\0\0\0"   "10\0\0\0\0\0"
>>>
>>>I expected "0" in the first entry and everything else would be unchanged.  Your 
>>>results may vary since every time I run 'sub()' in this way, I get a slightly 
>>>different answer in entires 2 through 11.
>>>
>>>As it turns out, 'gsub(fixed = TRUE)' gives me the answer I *actually* wanted, 
>>>which was to replace the string in every entry.  But I still think the behavior 
>>>of 'sub(fixed = TRUE) is a bit odd.
>>>
>>>
>>>>version
>>>
>>>         _
>>>platform x86_64-unknown-linux-gnu
>>>arch     x86_64
>>>os       linux-gnu
>>>system   x86_64, linux-gnu
>>>status
>>>major    2
>>>minor    2.1
>>>year     2005
>>>month    12
>>>day      20
>>>svn rev  36812
>>>language R
>>>
>>
>>Argh... 
>>
>>year     2005
>>month    12
>>day      21
>>
>>and something like this gets discovered. It's a ritual, I tell ya, a ritual!
>>
>>If you look at the output and terminate all strings at the embedded
>>\0, it looks much more sensible, so it should be fairly easy to spot
>>the cause of this bug...
>>
> 
>


From simon.urbanek at r-project.org  Thu Dec 22 06:41:51 2005
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 22 Dec 2005 00:41:51 -0500
Subject: [Rd] Build error on Mac OS X
In-Reply-To: <43A9E14F.5060405@fhcrc.org>
References: <43A9E14F.5060405@fhcrc.org>
Message-ID: <9C6D483D-3F6B-4B90-A033-611FC474BF2C@r-project.org>

Herv?,

On Dec 21, 2005, at 6:12 PM, Herve Pages wrote:

> I don't get that problem with R-devel daily snapshots from before  
> 2005-12-14
> and I get it with (almost) all snaphots between 2005-12-14 and today.

Strange - I have only failure on 2005/12/17 - all others built fine  
(same system: 7.9.0). Did you try the SVN checkout? I can't test the  
current tar-ball on the Panther machine, because it's running the  
nightly builds right now...

(FWIW those configure parameters are both superfluous on OS X as of R  
2.2.0)

Cheers,
Simon


From p.dalgaard at biostat.ku.dk  Thu Dec 22 09:57:49 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 22 Dec 2005 09:57:49 +0100
Subject: [Rd] R-bugs e-mail {was ... (Debian Bug 344248): ...}
In-Reply-To: <f8e6ff050512211945y7fa6b3fat7e5e22a2cd487f15@mail.gmail.com>
References: <20051221140009.D28A219A87@slim.kubism.ku.dk>
	<17321.27042.31819.692232@stat.math.ethz.ch>
	<f8e6ff050512211945y7fa6b3fat7e5e22a2cd487f15@mail.gmail.com>
Message-ID: <x2oe397ble.fsf@turmalin.kubism.ku.dk>

hadley wickham <h.wickham at gmail.com> writes:

> > PLEASE, PLEASE:
> > do use
> >         R-bugs at R-project.org
> > and nothing else
> 
> Perhaps
> http://bugs.r-project.org/cgi-bin/R
> should be updated then?
> 
> Hadley

That's internal to the bug repository. It does everything by email,
and at some point messages need to reach the program invoked by the
mail server. Sending things to Zurich and back seems a bit silly....

        -p

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From p.dalgaard at biostat.ku.dk  Thu Dec 22 10:10:20 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 22 Dec 2005 10:10:20 +0100
Subject: [Rd] R-bugs e-mail {was ... (Debian Bug 344248): ...}
In-Reply-To: <x2oe397ble.fsf@turmalin.kubism.ku.dk>
References: <20051221140009.D28A219A87@slim.kubism.ku.dk>
	<17321.27042.31819.692232@stat.math.ethz.ch>
	<f8e6ff050512211945y7fa6b3fat7e5e22a2cd487f15@mail.gmail.com>
	<x2oe397ble.fsf@turmalin.kubism.ku.dk>
Message-ID: <x2bqz97b0j.fsf@turmalin.kubism.ku.dk>

Peter Dalgaard <p.dalgaard at biostat.ku.dk> writes:

> hadley wickham <h.wickham at gmail.com> writes:
> 
> > > PLEASE, PLEASE:
> > > do use
> > >         R-bugs at R-project.org
> > > and nothing else
> > 
> > Perhaps
> > http://bugs.r-project.org/cgi-bin/R
> > should be updated then?
> > 
> > Hadley
> 
> That's internal to the bug repository. It does everything by email,
> and at some point messages need to reach the program invoked by the
> mail server. Sending things to Zurich and back seems a bit silly....
> 
>         -p

Oops. You were talking about the email address on the front page? I'll
fix that one to point to Zurich.

        -p
-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907


From sbrohee at ulb.ac.be  Thu Dec 22 11:47:21 2005
From: sbrohee at ulb.ac.be (sbrohee@ulb.ac.be)
Date: Thu, 22 Dec 2005 11:47:21 +0100 (CET)
Subject: [Rd] png support for R 2.2.1 (PR#8425)
Message-ID: <20051222104721.2052619A86@slim.kubism.ku.dk>

Full_Name: Sylvain Broh?e
Version: 2.2.1
OS: Suse Linux 9.2
Submission from: (NULL) (164.15.109.58)


I recently went to a new version of R  (2.2.1) but now,  when trying to save a
plot in the png format, I got this error message :

> png("my_plot.png")
Error in X11(paste("png::", filename, sep = ""), width, height, pointsize,  :
        unable to start device PNG
In addition: Warning message:
no png support in this version of R

What can I do?

Sylvain


From ligges at statistik.uni-dortmund.de  Thu Dec 22 12:59:09 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 22 Dec 2005 12:59:09 +0100
Subject: [Rd] png support for R 2.2.1 (PR#8425)
In-Reply-To: <20051222104721.2052619A86@slim.kubism.ku.dk>
References: <20051222104721.2052619A86@slim.kubism.ku.dk>
Message-ID: <43AA950D.8020205@statistik.uni-dortmund.de>

sbrohee at ulb.ac.be wrote:

> Full_Name: Sylvain Broh?e
> Version: 2.2.1
> OS: Suse Linux 9.2
> Submission from: (NULL) (164.15.109.58)
> 
> 
> I recently went to a new version of R  (2.2.1) but now,  when trying to save a
> plot in the png format, I got this error message :
> 
> 
>>png("my_plot.png")
> 
> Error in X11(paste("png::", filename, sep = ""), width, height, pointsize,  :
>         unable to start device PNG
> In addition: Warning message:
> no png support in this version of R
> 
> What can I do?


1. Do not send a bug report if there is no bug! Please read the FAQs and 
learn what a bug is.
2. Do not send identical messages a couple of times to many mailing lists.
3. Do read the installation manuals.
4. Install both "libpng" and "libpng-devel" in a way that it will be 
found by R's configure scripts (e.g. into standard locations).
5. Run R's ./configure and check the last lines of the output, png 
support should be mentioned, if not, check what ./configure told you at 
the point where it looked for libpng.

Uwe Ligges



> Sylvain
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From sdavis2 at mail.nih.gov  Thu Dec 22 13:35:32 2005
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Thu, 22 Dec 2005 07:35:32 -0500
Subject: [Rd] Coercing from a local class to a foreign one
Message-ID: <BFD007C4.230B%sdavis2@mail.nih.gov>

I am working on writing a fairly simple package that defines several
classes.  However, there are several other packages that deal with the same
types of data, so I would like to methods for coercing my classes to those
of the other packages.  Easy enough.  However, I would really like to just
"suggest" those other packages, as my own doesn't rely on them at all.  If I
do so and the other packages are not available and loaded, I get warnings on
loading my own package that the classes from the foreign packages are not
available.  I understand that these messages are not significant, but is
there a way to suppress them on loading.  As far as I can tell, this is
specific to S4 coercion methods where the classes to coerce to or from may
not be loaded or defined at the time of loading a package.

Any hints?  (In other words, what did I miss in the documentation....)

Thanks,
Sean


From bolker at zoo.ufl.edu  Thu Dec 22 19:23:54 2005
From: bolker at zoo.ufl.edu (bolker@zoo.ufl.edu)
Date: Thu, 22 Dec 2005 19:23:54 +0100 (CET)
Subject: [Rd] Windows crash in confint() with nls fit (PR#8428)
Message-ID: <20051222182354.E90F119A83@slim.kubism.ku.dk>

Full_Name: Ben Bolker
Version: 2.2.1
OS: Windows XP and 2000
Submission from: (NULL) (128.227.60.124)


  The following code, using confint() to try
to get confidence intervals on an nls object
that has been fitted with algorithm="port"
reliably crashes R 2.2.0 and 2.2.1 with the
latest version of MASS on a Windows 2000 and
a Windows XP machine here.  I *think* earlier
versions of MASS may not have crashed, but
I have now updated the versions on most of
my machines and don't have a test version handy.

 On XP, I get an error-report-do-you-want-
to-send-this-to-Microsoft dialog box.  On 2000
I get a "Rgui has generated errors ..." dialog box.

  I can get this far:

debug: profiledModel <- .Call("nls_iter", fittedModel, ctrl, trace, 
    PACKAGE = "stats")

Browse[1]> where
where 1: prof$getProfile()
where 2: profile.nls(object, which = parm, alphamax = (1 - level)/4)
where 3: profile(object, which = parm, alphamax = (1 - level)/4)
where 4: confint.nls(n1)
where 5: confint(n1)

  I'm not set up to debug compiled code on Windows, and I haven't
been able to reproduce the problem on Linux.

set.seed(1001)
x = runif(200)
a =1
b = 1
c = -0.1
y = a+b*x+c*x^2+rnorm(200,sd=0.05)
plot(x,y)
curve(a+b*x+c*x^2,add=TRUE)
n1 = nls(y~a+b*x+c*I(x^2),start=c(a=1,b=1,c=0.1),algorithm="port")
confint(n1)  ## boom

  N.B.: It only crashes if algorithm="port" is specified.

## [1] "Windows 2000 Professional (build 2195) Service Pack 4.0"
## 
## > R.version
##          _              
## platform i386-pc-mingw32
## arch     i386           
## os       mingw32        
## system   i386, mingw32  
## status                  
## major    2              
## minor    2.0            
## year     2005           
## month    10             
## day      06             
## svn rev  35749          
## language R        
##    
## MASS 
##                      
## Version:             7.2-23
## Date:                2005-12-08
## 
##  

##  "Windows XP Professional (build 2600) Service Pack 2.0"
      ##               _              
##platform i386-pc-mingw32
##arch     i386           
##os       mingw32        
##system   i386, mingw32  
##status                  
##major    2              
##minor    2.0            
##year     2005           
##month    10             
##day      06             
##svn rev  35749          
##language R        

##
##Version:             7.2-23
##Date:                2005-12-08      ## CRASH
   
##> R.version
##         _              
##platform i386-pc-mingw32
##arch     i386           
##os       mingw32        
##system   i386, mingw32  
##status                  
##major    2              
##minor    2.1            
##year     2005           
##month    12             
##day      20             
##svn rev  36812          
##language R         
## CRASH


From hpages at fhcrc.org  Thu Dec 22 20:08:56 2005
From: hpages at fhcrc.org (Herve Pages)
Date: Thu, 22 Dec 2005 11:08:56 -0800
Subject: [Rd] Build error on Mac OS X
In-Reply-To: <9C6D483D-3F6B-4B90-A033-611FC474BF2C@r-project.org>
References: <43A9E14F.5060405@fhcrc.org>
	<9C6D483D-3F6B-4B90-A033-611FC474BF2C@r-project.org>
Message-ID: <43AAF9C8.4080007@fhcrc.org>

Simon Urbanek wrote:

> On Dec 21, 2005, at 6:12 PM, Herve Pages wrote:
>
>> I don't get that problem with R-devel daily snapshots from before  
>> 2005-12-14
>> and I get it with (almost) all snaphots between 2005-12-14 and today.
>
>
> Strange - I have only failure on 2005/12/17 - all others built fine  
> (same system: 7.9.0). Did you try the SVN checkout? I can't test the  
> current tar-ball on the Panther machine, because it's running the  
> nightly builds right now...


Hi Simon,

I just tried with the SVN checkout (Revision: 36833) of R-devel
and got the same problem. I also have this problem with today's
R-devel tarball on the 2 Mac OS X machines where I could make
a test. But on these 2 machines, R-devel tarball from 2005-12-13
builds fine.

Machine 1:
 > uname -a
Darwin possum1.fhcrc.org 7.9.0 Darwin Kernel Version 7.9.0: Wed Mar 30 
20:11:17 PST 2005; root:xnu/xnu-517.12.7.obj~1/RELEASE_PPC  Power 
Macintosh powerpc


Machine 2:
 > uname -a
Darwin possum2.fhcrc.org 7.9.0 Darwin Kernel Version 7.9.0: Wed Mar 30 
20:11:17 PST 2005; root:xnu/xnu-517.12.7.obj~1/RELEASE_PPC  Power 
Macintosh powerpc


On both machines:

GNU Make version 3.79
gcc version 3.3 20030304 (Apple Computer, Inc. build 1671)

 > g77 -v
Reading specs from /usr/local/lib/gcc/powerpc-apple-darwin6.8/3.4.2/specs
Configured with: ../gcc/configure --enable-threads=posix 
--enable-languages=f77 --disable-shared --enable-static
Thread model: posix
gcc version 3.4.2


Hope this helps,

H.

-- 
------------------------
Herv? Pag?s
E-mail: hpages at fhcrc.org
 Phone: (206) 667-5791
   Fax: (206) 667-1319


From murdoch at stats.uwo.ca  Thu Dec 22 20:19:27 2005
From: murdoch at stats.uwo.ca (murdoch@stats.uwo.ca)
Date: Thu, 22 Dec 2005 20:19:27 +0100 (CET)
Subject: [Rd] Windows crash in confint() with nls fit (PR#8428)
Message-ID: <20051222191927.EA7E719A74@slim.kubism.ku.dk>

On 12/22/2005 1:23 PM, bolker at zoo.ufl.edu wrote:
> Full_Name: Ben Bolker
> Version: 2.2.1
> OS: Windows XP and 2000
> Submission from: (NULL) (128.227.60.124)
> 
> 
>   The following code, using confint() to try
> to get confidence intervals on an nls object
> that has been fitted with algorithm="port"
> reliably crashes R 2.2.0 and 2.2.1 with the
> latest version of MASS on a Windows 2000 and
> a Windows XP machine here.  I *think* earlier
> versions of MASS may not have crashed, but
> I have now updated the versions on most of
> my machines and don't have a test version handy.
> 
>  On XP, I get an error-report-do-you-want-
> to-send-this-to-Microsoft dialog box.  On 2000
> I get a "Rgui has generated errors ..." dialog box.
> 
>   I can get this far:
> 
> debug: profiledModel <- .Call("nls_iter", fittedModel, ctrl, trace, 
>     PACKAGE = "stats")
> 
> Browse[1]> where
> where 1: prof$getProfile()
> where 2: profile.nls(object, which = parm, alphamax = (1 - level)/4)
> where 3: profile(object, which = parm, alphamax = (1 - level)/4)
> where 4: confint.nls(n1)
> where 5: confint(n1)
> 
>   I'm not set up to debug compiled code on Windows, and I haven't
> been able to reproduce the problem on Linux.

I see it in R-devel too.  It's in a strcmp; I'll see if I can track down 
the cause.

Duncan Murdoch

> 
> set.seed(1001)
> x = runif(200)
> a =1
> b = 1
> c = -0.1
> y = a+b*x+c*x^2+rnorm(200,sd=0.05)
> plot(x,y)
> curve(a+b*x+c*x^2,add=TRUE)
> n1 = nls(y~a+b*x+c*I(x^2),start=c(a=1,b=1,c=0.1),algorithm="port")
> confint(n1)  ## boom
> 
>   N.B.: It only crashes if algorithm="port" is specified.
> 
> ## [1] "Windows 2000 Professional (build 2195) Service Pack 4.0"
> ## 
> ## > R.version
> ##          _              
> ## platform i386-pc-mingw32
> ## arch     i386           
> ## os       mingw32        
> ## system   i386, mingw32  
> ## status                  
> ## major    2              
> ## minor    2.0            
> ## year     2005           
> ## month    10             
> ## day      06             
> ## svn rev  35749          
> ## language R        
> ##    
> ## MASS 
> ##                      
> ## Version:             7.2-23
> ## Date:                2005-12-08
> ## 
> ##  
> 
> ##  "Windows XP Professional (build 2600) Service Pack 2.0"
>       ##               _              
> ##platform i386-pc-mingw32
> ##arch     i386           
> ##os       mingw32        
> ##system   i386, mingw32  
> ##status                  
> ##major    2              
> ##minor    2.0            
> ##year     2005           
> ##month    10             
> ##day      06             
> ##svn rev  35749          
> ##language R        
> 
> ##
> ##Version:             7.2-23
> ##Date:                2005-12-08      ## CRASH
>    
> ##> R.version
> ##         _              
> ##platform i386-pc-mingw32
> ##arch     i386           
> ##os       mingw32        
> ##system   i386, mingw32  
> ##status                  
> ##major    2              
> ##minor    2.1            
> ##year     2005           
> ##month    12             
> ##day      20             
> ##svn rev  36812          
> ##language R         
> ## CRASH
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch at stats.uwo.ca  Thu Dec 22 20:51:24 2005
From: murdoch at stats.uwo.ca (murdoch@stats.uwo.ca)
Date: Thu, 22 Dec 2005 20:51:24 +0100 (CET)
Subject: [Rd] Windows crash in confint() with nls fit (PR#8428)
Message-ID: <20051222195124.A6ABF19A83@slim.kubism.ku.dk>

I've found the problem, but someone who knows more about nls() will have 
to fix it.

The problem is that in the demo code below, n1 ends up being an nls 
object, but n1$call$control is NULL.  profiler.nls() assumed that the 
nls object passed to it has a non-NULL element there, and doesn't check.

I've fixed the code so now it doesn't crash, but it now dies with this 
error instead:

 > confint(n1)  ## boom
Waiting for profiling to be done...
Error in prof$getProfile() : 'control$maxiter' absent

I'll commmit my change to R-devel and R-patched shortly.

Duncan Murdoch





On 12/22/2005 1:23 PM, bolker at zoo.ufl.edu wrote:
> Full_Name: Ben Bolker
> Version: 2.2.1
> OS: Windows XP and 2000
> Submission from: (NULL) (128.227.60.124)
> 
> 
>   The following code, using confint() to try
> to get confidence intervals on an nls object
> that has been fitted with algorithm="port"
> reliably crashes R 2.2.0 and 2.2.1 with the
> latest version of MASS on a Windows 2000 and
> a Windows XP machine here.  I *think* earlier
> versions of MASS may not have crashed, but
> I have now updated the versions on most of
> my machines and don't have a test version handy.
> 
>  On XP, I get an error-report-do-you-want-
> to-send-this-to-Microsoft dialog box.  On 2000
> I get a "Rgui has generated errors ..." dialog box.
> 
>   I can get this far:
> 
> debug: profiledModel <- .Call("nls_iter", fittedModel, ctrl, trace, 
>     PACKAGE = "stats")
> 
> Browse[1]> where
> where 1: prof$getProfile()
> where 2: profile.nls(object, which = parm, alphamax = (1 - level)/4)
> where 3: profile(object, which = parm, alphamax = (1 - level)/4)
> where 4: confint.nls(n1)
> where 5: confint(n1)
> 
>   I'm not set up to debug compiled code on Windows, and I haven't
> been able to reproduce the problem on Linux.
> 
> set.seed(1001)
> x = runif(200)
> a =1
> b = 1
> c = -0.1
> y = a+b*x+c*x^2+rnorm(200,sd=0.05)
> plot(x,y)
> curve(a+b*x+c*x^2,add=TRUE)
> n1 = nls(y~a+b*x+c*I(x^2),start=c(a=1,b=1,c=0.1),algorithm="port")
> confint(n1)  ## boom
> 
>   N.B.: It only crashes if algorithm="port" is specified.
> 
> ## [1] "Windows 2000 Professional (build 2195) Service Pack 4.0"
> ## 
> ## > R.version
> ##          _              
> ## platform i386-pc-mingw32
> ## arch     i386           
> ## os       mingw32        
> ## system   i386, mingw32  
> ## status                  
> ## major    2              
> ## minor    2.0            
> ## year     2005           
> ## month    10             
> ## day      06             
> ## svn rev  35749          
> ## language R        
> ##    
> ## MASS 
> ##                      
> ## Version:             7.2-23
> ## Date:                2005-12-08
> ## 
> ##  
> 
> ##  "Windows XP Professional (build 2600) Service Pack 2.0"
>       ##               _              
> ##platform i386-pc-mingw32
> ##arch     i386           
> ##os       mingw32        
> ##system   i386, mingw32  
> ##status                  
> ##major    2              
> ##minor    2.0            
> ##year     2005           
> ##month    10             
> ##day      06             
> ##svn rev  35749          
> ##language R        
> 
> ##
> ##Version:             7.2-23
> ##Date:                2005-12-08      ## CRASH
>    
> ##> R.version
> ##         _              
> ##platform i386-pc-mingw32
> ##arch     i386           
> ##os       mingw32        
> ##system   i386, mingw32  
> ##status                  
> ##major    2              
> ##minor    2.1            
> ##year     2005           
> ##month    12             
> ##day      20             
> ##svn rev  36812          
> ##language R         
> ## CRASH
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From bolker at zoo.ufl.edu  Thu Dec 22 21:24:01 2005
From: bolker at zoo.ufl.edu (bolker@zoo.ufl.edu)
Date: Thu, 22 Dec 2005 21:24:01 +0100 (CET)
Subject: [Rd] Windows crash in confint() with nls fit (PR#8428)
Message-ID: <20051222202401.4393019A9B@slim.kubism.ku.dk>

Duncan Murdoch wrote:
> I've found the problem, but someone who knows more about nls() will have 
> to fix it.
> 
> The problem is that in the demo code below, n1 ends up being an nls 
> object, but n1$call$control is NULL.  profiler.nls() assumed that the 
> nls object passed to it has a non-NULL element there, and doesn't check.
> 
> I've fixed the code so now it doesn't crash, but it now dies with this 
> error instead:
> 
>  > confint(n1)  ## boom
> Waiting for profiling to be done...
> Error in prof$getProfile() : 'control$maxiter' absent
> 
> I'll commmit my change to R-devel and R-patched shortly.
> 
> Duncan Murdoch
> 

   thank you for the quick response!

    actually, I discovered I'm wrong -- bug affects Linux as well,
gives a segmentation fault
(I must have tried it without the algorithm="port" argument by
accident.)  I've looked at the code but I regretfully concur
that someone else will have to work on this -- I can hack nls
so it reinserts a "control" element in n1$call, but $tol
and $minFactor are explicitly deleted from the control list,
and so we only get one step farther.  I don't know what assumptions
nls_iter is really making and whether it's safe to make them
when the port algorithm is being used or not ...

   My best guess at this point, poking around, is that profiler.nls
in src/library/stats/R/nls-profile.R has to be changed in parallel
with nls to call port_nlsb instead of nls_iter when the port
algorithm is being used, but this is all getting a bit deep for
me ...

    Ben


From ehlers at math.ucalgary.ca  Thu Dec 22 21:47:53 2005
From: ehlers at math.ucalgary.ca (P Ehlers)
Date: Thu, 22 Dec 2005 13:47:53 -0700
Subject: [Rd] Windows crash in confint() with nls fit (PR#8428)
In-Reply-To: <20051222202401.4393019A9B@slim.kubism.ku.dk>
References: <20051222202401.4393019A9B@slim.kubism.ku.dk>
Message-ID: <43AB10F9.6020203@math.ucalgary.ca>

You don't actually need Ben's example. The problem occurs
also for the first example in ?nls if algorithm = "port" is
used.

Peter Ehlers

bolker at zoo.ufl.edu wrote:

> Duncan Murdoch wrote:
> 
>>I've found the problem, but someone who knows more about nls() will have 
>>to fix it.
>>
>>The problem is that in the demo code below, n1 ends up being an nls 
>>object, but n1$call$control is NULL.  profiler.nls() assumed that the 
>>nls object passed to it has a non-NULL element there, and doesn't check.
>>
>>I've fixed the code so now it doesn't crash, but it now dies with this 
>>error instead:
>>
>> > confint(n1)  ## boom
>>Waiting for profiling to be done...
>>Error in prof$getProfile() : 'control$maxiter' absent
>>
>>I'll commmit my change to R-devel and R-patched shortly.
>>
>>Duncan Murdoch
>>
> 
> 
>    thank you for the quick response!
> 
>     actually, I discovered I'm wrong -- bug affects Linux as well,
> gives a segmentation fault
> (I must have tried it without the algorithm="port" argument by
> accident.)  I've looked at the code but I regretfully concur
> that someone else will have to work on this -- I can hack nls
> so it reinserts a "control" element in n1$call, but $tol
> and $minFactor are explicitly deleted from the control list,
> and so we only get one step farther.  I don't know what assumptions
> nls_iter is really making and whether it's safe to make them
> when the port algorithm is being used or not ...
> 
>    My best guess at this point, poking around, is that profiler.nls
> in src/library/stats/R/nls-profile.R has to be changed in parallel
> with nls to call port_nlsb instead of nls_iter when the port
> algorithm is being used, but this is all getting a bit deep for
> me ...
> 
>     Ben
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Ehlers
Department of Mathematics and Statistics
University of Calgary


From andrew at demandresponse.com  Thu Dec 22 22:14:05 2005
From: andrew at demandresponse.com (andrew@demandresponse.com)
Date: Thu, 22 Dec 2005 22:14:05 +0100 (CET)
Subject: [Rd] minor windows dialogue box problem-"File/Change dir..."
	(PR#8430)
Message-ID: <20051222211405.04C3019A30@slim.kubism.ku.dk>

Full_Name: Andrew Corson
Version: 2.2.0
OS: win XP
Submission from: (NULL) (222.152.185.145)


If you are not using a mouse, you use the tab key to move between fields in a
dialogue box. If you go File/Change dir... and then press tab to move to cursor
from the path text box to the Browse button it appears that the focus moves
correctly, but when you press Enter to activate the browse button the resulting
action is the same as if you had used the mouse and clicked on OK instead.

If you enter some non-existant path in the path box and use the keys to select
the Browse button, you get the error "Unable to set '...' as working directory"

The problem was present in R 2.0.1, I have just upgraded to R 2.2.0 and it still
exists.

> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    2              
minor    2.0            
year     2005           
month    10             
day      06             
svn rev  35749          
language R


From hpages at fhcrc.org  Thu Dec 22 22:40:44 2005
From: hpages at fhcrc.org (Herve Pages)
Date: Thu, 22 Dec 2005 13:40:44 -0800
Subject: [Rd] Build error on Mac OS X
In-Reply-To: <9C6D483D-3F6B-4B90-A033-611FC474BF2C@r-project.org>
References: <43A9E14F.5060405@fhcrc.org>
	<9C6D483D-3F6B-4B90-A033-611FC474BF2C@r-project.org>
Message-ID: <43AB1D5C.3040409@fhcrc.org>

Simon Urbanek wrote:

> On Dec 21, 2005, at 6:12 PM, Herve Pages wrote:
>
>> I don't get that problem with R-devel daily snapshots from before  
>> 2005-12-14
>> and I get it with (almost) all snaphots between 2005-12-14 and today.
>
>
> Strange - I have only failure on 2005/12/17 - all others built fine  
> (same system: 7.9.0). Did you try the SVN checkout? I can't test the  
> current tar-ball on the Panther machine, because it's running the  
> nightly builds right now...
>
Simon,

This error occurs in src/main/Makefile.
I'm not really understanding what's going on here but I was wondering why
'-lintl' would be a target. It became a target in R-devel r36724 
(2005-12-13).
In fact, a big change occured in src/main/Makefile.in between r36723 and
r36724. One of them is the introduction of the COMMON_DEPENDENCIES
variable:

+COMMON_DEPENDENCIES = $(R_XTRA_LIBS) $(R_ZLIBS)        $(R_BZLIBS) 
$(R_PCRE) \
+       $(R_XDR) @LIBINTL@ \
+       @USE_EXPORTFILES_TRUE@ $(top_builddir)/etc/R.exp

If I remove @LIBINTL@ from this definition, it happens that I can build 
and run
last R-devel on all platforms I have access to: Windows, 64-bit SuSE 
Linux 9.2,
32-bit SuSE Linux 9.2, Solaris 2.9 AND Mac OS X.
Not sure what this @LIBINTL@ dependency is needed for however...

I attached the file containing my svn diff output.

Regards,

H.

-- 
------------------------
Herv? Pag?s
E-mail: hpages at fhcrc.org
 Phone: (206) 667-5791
   Fax: (206) 667-1319
------------------------


From ellis at stat.harvard.edu  Fri Dec 23 02:07:12 2005
From: ellis at stat.harvard.edu (Byron Ellis)
Date: Thu, 22 Dec 2005 17:07:12 -0800
Subject: [Rd] cairo anyone?
Message-ID: <8EF1732A-F59B-438C-AA78-AC070AD277A3@stat.harvard.edu>

Has anyone taken a shot at a Cairo graphics device yet? I half  
expected to see one on either Paul's pages or Omegahat. :-)

---
Byron Ellis (ellis at stat.harvard.edu)
"Oook" -- The Librarian


From duncan at wald.ucdavis.edu  Fri Dec 23 02:19:01 2005
From: duncan at wald.ucdavis.edu (Duncan Temple Lang)
Date: Thu, 22 Dec 2005 17:19:01 -0800
Subject: [Rd] cairo anyone?
In-Reply-To: <8EF1732A-F59B-438C-AA78-AC070AD277A3@stat.harvard.edu>
References: <8EF1732A-F59B-438C-AA78-AC070AD277A3@stat.harvard.edu>
Message-ID: <43AB5085.3070801@wald.ucdavis.edu>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1


Michael Lawrence has as part of RGtk2.

 D.

Byron Ellis wrote:
> Has anyone taken a shot at a Cairo graphics device yet? I half  
> expected to see one on either Paul's pages or Omegahat. :-)
> 
> ---
> Byron Ellis (ellis at stat.harvard.edu)
> "Oook" -- The Librarian
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

- --
Duncan Temple Lang                    duncan at wald.ucdavis.edu
Department of Statistics              work:  (530) 752-4782
4210 Mathematical Sciences Building   fax:   (530) 752-7099
One Shields Ave.
University of California at Davis
Davis,
CA 95616,
USA
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.2 (Darwin)

iD8DBQFDq1CF9p/Jzwa2QP4RAh3dAJ9cL4unVFk8lHGCQPrbOo+PQgWpeQCePduO
5OeLK5ctgvYXFKZvQRwROeE=
=tPs9
-----END PGP SIGNATURE-----


From edd at debian.org  Fri Dec 23 02:38:10 2005
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 22 Dec 2005 19:38:10 -0600
Subject: [Rd] cairo anyone?
In-Reply-To: <43AB5085.3070801@wald.ucdavis.edu>
References: <8EF1732A-F59B-438C-AA78-AC070AD277A3@stat.harvard.edu>
	<43AB5085.3070801@wald.ucdavis.edu>
Message-ID: <17323.21762.987703.732136@basebud.nulle.part>


On 22 December 2005 at 17:19, Duncan Temple Lang wrote:
| Michael Lawrence has as part of RGtk2.

Speaking of which -- I tried to find his code anywhere on the "Internets"
following his very nice DSC presentation, but no beans.  Why is this in
hiding?  Is it expected to surface at some point?  Any insights, Duncan?

Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From ripley at stats.ox.ac.uk  Fri Dec 23 08:35:42 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 23 Dec 2005 07:35:42 +0000 (GMT)
Subject: [Rd] Build error on Mac OS X
In-Reply-To: <43AB1D5C.3040409@fhcrc.org>
References: <43A9E14F.5060405@fhcrc.org>
	<9C6D483D-3F6B-4B90-A033-611FC474BF2C@r-project.org>
	<43AB1D5C.3040409@fhcrc.org>
Message-ID: <Pine.LNX.4.61.0512222230360.20456@gannet.stats>

The updating of gettext support is currently in mid-progress (and 
specifically what is required for MacOS X).  It looks as if your system 
has another version of gettext installed: please configure R not to use 
such a version for now (see configure --help for how to do so).

Once the update is complete you may be able to use your installed version 
again (although likely it will not be current enough).


On Thu, 22 Dec 2005, Herve Pages wrote:

> Simon Urbanek wrote:
>
>> On Dec 21, 2005, at 6:12 PM, Herve Pages wrote:
>> 
>>> I don't get that problem with R-devel daily snapshots from before 
>>> 2005-12-14
>>> and I get it with (almost) all snaphots between 2005-12-14 and today.
>> 
>> 
>> Strange - I have only failure on 2005/12/17 - all others built fine  (same 
>> system: 7.9.0). Did you try the SVN checkout? I can't test the  current 
>> tar-ball on the Panther machine, because it's running the  nightly builds 
>> right now...
>> 
> Simon,
>
> This error occurs in src/main/Makefile.
> I'm not really understanding what's going on here but I was wondering why
> '-lintl' would be a target. It became a target in R-devel r36724 
> (2005-12-13).
> In fact, a big change occured in src/main/Makefile.in between r36723 and
> r36724. One of them is the introduction of the COMMON_DEPENDENCIES
> variable:
>
> +COMMON_DEPENDENCIES = $(R_XTRA_LIBS) $(R_ZLIBS)        $(R_BZLIBS) $(R_PCRE) 
> \
> +       $(R_XDR) @LIBINTL@ \
> +       @USE_EXPORTFILES_TRUE@ $(top_builddir)/etc/R.exp
>
> If I remove @LIBINTL@ from this definition, it happens that I can build and 
> run
> last R-devel on all platforms I have access to: Windows, 64-bit SuSE Linux 
> 9.2,
> 32-bit SuSE Linux 9.2, Solaris 2.9 AND Mac OS X.
> Not sure what this @LIBINTL@ dependency is needed for however...
>
> I attached the file containing my svn diff output.
>
> Regards,
>
> H.
>
> -- 
> ------------------------
> Herv? Pag?s
> E-mail: hpages at fhcrc.org
> Phone: (206) 667-5791
>  Fax: (206) 667-1319
> ------------------------
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From h.wickham at gmail.com  Fri Dec 23 12:04:49 2005
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 23 Dec 2005 11:04:49 +0000
Subject: [Rd] cairo anyone?
In-Reply-To: <17323.21762.987703.732136@basebud.nulle.part>
References: <8EF1732A-F59B-438C-AA78-AC070AD277A3@stat.harvard.edu>
	<43AB5085.3070801@wald.ucdavis.edu>
	<17323.21762.987703.732136@basebud.nulle.part>
Message-ID: <f8e6ff050512230304t7fa9cdb7q1c021dc6ab59b2c6@mail.gmail.com>

> | Michael Lawrence has as part of RGtk2.
>
> Speaking of which -- I tried to find his code anywhere on the "Internets"
> following his very nice DSC presentation, but no beans.  Why is this in
> hiding?  Is it expected to surface at some point?  Any insights, Duncan?

Michael is currently working on autogenerated documentation, and I
think will be ready to release early next year.

Hadley


From ripley at stats.ox.ac.uk  Fri Dec 23 16:09:21 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 23 Dec 2005 15:09:21 +0000 (GMT)
Subject: [Rd] Windows crash in confint() with nls fit (PR#8428)
In-Reply-To: <20051222195124.A6ABF19A83@slim.kubism.ku.dk>
References: <20051222195124.A6ABF19A83@slim.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0512231503160.8175@gannet.stats>

Actually, only the default algorithm is supported: algorithm="plinear" is 
broken too.  I've just added a check for the default algorithm in 
R-patched, as the fix is better done on the R-devel code base (which 
supports weights).

On Thu, 22 Dec 2005 murdoch at stats.uwo.ca wrote:

> I've found the problem, but someone who knows more about nls() will have
> to fix it.
>
> The problem is that in the demo code below, n1 ends up being an nls
> object, but n1$call$control is NULL.  profiler.nls() assumed that the
> nls object passed to it has a non-NULL element there, and doesn't check.
>
> I've fixed the code so now it doesn't crash, but it now dies with this
> error instead:
>
> > confint(n1)  ## boom
> Waiting for profiling to be done...
> Error in prof$getProfile() : 'control$maxiter' absent
>
> I'll commmit my change to R-devel and R-patched shortly.
>
> Duncan Murdoch
>
>
>
>
>
> On 12/22/2005 1:23 PM, bolker at zoo.ufl.edu wrote:
>> Full_Name: Ben Bolker
>> Version: 2.2.1
>> OS: Windows XP and 2000
>> Submission from: (NULL) (128.227.60.124)
>>
>>
>>   The following code, using confint() to try
>> to get confidence intervals on an nls object
>> that has been fitted with algorithm="port"
>> reliably crashes R 2.2.0 and 2.2.1 with the
>> latest version of MASS on a Windows 2000 and
>> a Windows XP machine here.  I *think* earlier
>> versions of MASS may not have crashed, but
>> I have now updated the versions on most of
>> my machines and don't have a test version handy.
>>
>>  On XP, I get an error-report-do-you-want-
>> to-send-this-to-Microsoft dialog box.  On 2000
>> I get a "Rgui has generated errors ..." dialog box.
>>
>>   I can get this far:
>>
>> debug: profiledModel <- .Call("nls_iter", fittedModel, ctrl, trace,
>>     PACKAGE = "stats")
>>
>> Browse[1]> where
>> where 1: prof$getProfile()
>> where 2: profile.nls(object, which = parm, alphamax = (1 - level)/4)
>> where 3: profile(object, which = parm, alphamax = (1 - level)/4)
>> where 4: confint.nls(n1)
>> where 5: confint(n1)
>>
>>   I'm not set up to debug compiled code on Windows, and I haven't
>> been able to reproduce the problem on Linux.
>>
>> set.seed(1001)
>> x = runif(200)
>> a =1
>> b = 1
>> c = -0.1
>> y = a+b*x+c*x^2+rnorm(200,sd=0.05)
>> plot(x,y)
>> curve(a+b*x+c*x^2,add=TRUE)
>> n1 = nls(y~a+b*x+c*I(x^2),start=c(a=1,b=1,c=0.1),algorithm="port")
>> confint(n1)  ## boom
>>
>>   N.B.: It only crashes if algorithm="port" is specified.
>>
>> ## [1] "Windows 2000 Professional (build 2195) Service Pack 4.0"
>> ##
>> ## > R.version
>> ##          _
>> ## platform i386-pc-mingw32
>> ## arch     i386
>> ## os       mingw32
>> ## system   i386, mingw32
>> ## status
>> ## major    2
>> ## minor    2.0
>> ## year     2005
>> ## month    10
>> ## day      06
>> ## svn rev  35749
>> ## language R
>> ##
>> ## MASS
>> ##
>> ## Version:             7.2-23
>> ## Date:                2005-12-08
>> ##
>> ##
>>
>> ##  "Windows XP Professional (build 2600) Service Pack 2.0"
>>       ##               _
>> ##platform i386-pc-mingw32
>> ##arch     i386
>> ##os       mingw32
>> ##system   i386, mingw32
>> ##status
>> ##major    2
>> ##minor    2.0
>> ##year     2005
>> ##month    10
>> ##day      06
>> ##svn rev  35749
>> ##language R
>>
>> ##
>> ##Version:             7.2-23
>> ##Date:                2005-12-08      ## CRASH
>>
>> ##> R.version
>> ##         _
>> ##platform i386-pc-mingw32
>> ##arch     i386
>> ##os       mingw32
>> ##system   i386, mingw32
>> ##status
>> ##major    2
>> ##minor    2.1
>> ##year     2005
>> ##month    12
>> ##day      20
>> ##svn rev  36812
>> ##language R
>> ## CRASH
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From izmirlig at mail.nih.gov  Fri Dec 23 19:31:04 2005
From: izmirlig at mail.nih.gov (Izmirlian, Grant (NIH/NCI) [E])
Date: Fri, 23 Dec 2005 13:31:04 -0500
Subject: [Rd] can someone help me understand LAM/MPI and Rmpi for use on a
	cluster
Message-ID: <CE0E73903DB53F43B4B0938747F34F8A01242D08@nihexchange7.nih.gov>

I'm fairly astute at C and R but new to parallelization. Would someone
be willing to provide help in the form of a simple example that parallelizes
an R function from the inside of a C routine?

If so, write me back at izmirlig at mail.nih.gov

Thanks!


From hpages at fhcrc.org  Fri Dec 23 19:49:39 2005
From: hpages at fhcrc.org (Herve Pages)
Date: Fri, 23 Dec 2005 10:49:39 -0800
Subject: [Rd] Build error on Mac OS X
In-Reply-To: <Pine.LNX.4.61.0512222230360.20456@gannet.stats>
References: <43A9E14F.5060405@fhcrc.org>
	<9C6D483D-3F6B-4B90-A033-611FC474BF2C@r-project.org>
	<43AB1D5C.3040409@fhcrc.org>
	<Pine.LNX.4.61.0512222230360.20456@gannet.stats>
Message-ID: <43AC46C3.8060303@fhcrc.org>

Prof Brian Ripley wrote:

> The updating of gettext support is currently in mid-progress (and 
> specifically what is required for MacOS X).  It looks as if your 
> system has another version of gettext installed: please configure R 
> not to use such a version for now (see configure --help for how to do 
> so).


This worked just fine. Thanks!

-- 
------------------------
Herv? Pag?s
E-mail: hpages at fhcrc.org
 Phone: (206) 667-5791
   Fax: (206) 667-1319


From simon.urbanek at r-project.org  Sat Dec 24 00:25:06 2005
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 23 Dec 2005 18:25:06 -0500
Subject: [Rd] cairo anyone?
In-Reply-To: <8EF1732A-F59B-438C-AA78-AC070AD277A3@stat.harvard.edu>
References: <8EF1732A-F59B-438C-AA78-AC070AD277A3@stat.harvard.edu>
Message-ID: <7953CC30-7290-46DC-A6A0-5292CBFF9F2F@r-project.org>

Byron,

On Dec 22, 2005, at 8:07 PM, Byron Ellis wrote:

> Has anyone taken a shot at a Cairo graphics device yet?

*opens a drawer* You can try this:
http://www.rosuda.org/R/Cairo_0.1-1.tar.gz

I'm using it for generating bitmap files (PNG), that's why only the  
image-backned is used. It should be easy to add other formats like  
PDF or maybe even other surfaces like Win32, Quartz or XLib, because  
the back-end part is modular, but I didn't bother (yet?).

Cheers,
Simon


From mandoid at comcast.net  Sat Dec 24 00:26:42 2005
From: mandoid at comcast.net (AJB)
Date: Fri, 23 Dec 2005 15:26:42 -0800
Subject: [Rd] make pkg-* R-2.2.1 Windows
Message-ID: <43AC87B2.3060601@comcast.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20051223/99f30ab1/attachment.pl

From edd at debian.org  Sat Dec 24 02:37:50 2005
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 23 Dec 2005 19:37:50 -0600
Subject: [Rd] (Debian Bug 344248): R segfaults when pressing
	Delete	(PR#8422)
In-Reply-To: <loom.20051221T154124-205@post.gmane.org>
References: <20051221143304.3A57319A76@slim.kubism.ku.dk>
	<loom.20051221T154124-205@post.gmane.org>
Message-ID: <20051224013750.GA6994@eddelbuettel.com>

On Wed, Dec 21, 2005 at 02:48:25PM +0000, Dirk Eddelbuettel wrote:
> <ripley <at> stats.ox.ac.uk> writes:
> > Can you confirm you are running rl5.1?  Given the segfault is readline not 
> 
> Yes: readline 5.1, just like the bug submitter (see at the very bottom).

And a new Debian version libreadline5.1-3 (and now 5.1-4) fixes it. I assume
the patch makes it upstream too.

Dirk

> > compatible version of a dynamic library so it seems to me the bug should 
> > be assigned to readline not R.
> 
> Looks like it, yes. And from looking at http://bugs.debian.org/libreadline5
> it seems that the same behaviour was just found with gdb.
> 
> Thanks for the quick replies!
> 
> Dirk
> 
> > > | ii  libreadline-ru 1.8.3+1.8.4pre Readline interface for Ruby 1.8
> > > | ii  libreadline4   4.3-18         GNU readline and history libraries, 
> run-time
> > > | un  libreadline4-d <none>         (no description available)
> > > | ii  libreadline5   5.1-1          GNU readline and history libraries, 
> run-time
> > > | ii  libreadline5-d 5.1-1          GNU readline and history libraries, 
> developm
> > > | ii  r-base         2.2.1-1        GNU R statistical computing language 
> and env
> > > | ii  r-base-core    2.2.1-1        GNU R core of statistical computing 
> language
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison


From ellis at stat.harvard.edu  Sat Dec 24 07:47:36 2005
From: ellis at stat.harvard.edu (Byron Ellis)
Date: Fri, 23 Dec 2005 22:47:36 -0800
Subject: [Rd] cairo anyone?
In-Reply-To: <7953CC30-7290-46DC-A6A0-5292CBFF9F2F@r-project.org>
References: <8EF1732A-F59B-438C-AA78-AC070AD277A3@stat.harvard.edu>
	<7953CC30-7290-46DC-A6A0-5292CBFF9F2F@r-project.org>
Message-ID: <678DA1AC-8576-4E81-B470-498733C1A48A@stat.harvard.edu>

Ah, that should work, every now and again I think to myself "ah ha! I  
should just generate some pngs..." until, invariably...

Error in X11(paste("png::",....

then I swear for a bit and go off to do something else because I  
can't be bothered. If I end up doing anything cool (IIRC cairo  
handles all your major backing surfaces... including OpenGL via  
Glitz, which could be handy for RGL) I'll shoot you a patch.



On Dec 23, 2005, at 3:25 PM, Simon Urbanek wrote:

> Byron,
>
> On Dec 22, 2005, at 8:07 PM, Byron Ellis wrote:
>
>> Has anyone taken a shot at a Cairo graphics device yet?
>
> *opens a drawer* You can try this:
> http://www.rosuda.org/R/Cairo_0.1-1.tar.gz
>
> I'm using it for generating bitmap files (PNG), that's why only the  
> image-backned is used. It should be easy to add other formats like  
> PDF or maybe even other surfaces like Win32, Quartz or XLib,  
> because the back-end part is modular, but I didn't bother (yet?).
>
> Cheers,
> Simon
>

---
Byron Ellis (ellis at stat.harvard.edu)
"Oook" -- The Librarian


From ripley at stats.ox.ac.uk  Sat Dec 24 08:38:18 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 24 Dec 2005 07:38:18 +0000 (GMT)
Subject: [Rd] make pkg-* R-2.2.1 Windows
In-Reply-To: <43AC87B2.3060601@comcast.net>
References: <43AC87B2.3060601@comcast.net>
Message-ID: <Pine.LNX.4.61.0512240737000.5311@gannet.stats>

Please use the recommended tools!
We do not support MSYS nor that old compiler suite.

On Fri, 23 Dec 2005, AJB wrote:

> I just installed R-2.2.1 on Windows
>
> Now when I change directories to C:\Program Files\R\R-2.2.1\src\gnuwin32
> and try
> make pkg-*, e.g., make pkg-designs, I get
>
>
> ---------- Making package designs ------------
>  adding build stamp to DESCRIPTION
>  making DLL ...
> making rand_exch.d from rand_exch.c
> making read_array_dyn.d from read_array_dyn.c
> making stard.d from stard.c
> making symmd.d from symmd.c
> cat: rand_exch.d: No such file or directory
> cat: read_array_dyn.d: No such file or directory
> cat: stard.d: No such file or directory
> cat: symmd.d: No such file or directory
> make[3]: *** [makeMakedeps] Error 1
> make[2]: *** [srcDynlib] Error 2
> make[1]: *** [all] Error 2
> make: *** [pkg-designs] Error 2
>
>
> The ".d" files are not created. If they are already there then the next
> step is object files, and they aren't created.
> This worked in previous versions of R ...
>
> I'm using:
>
> MSYS 1.0.10, GNU Make version 3.79.1
>
> MINGW 3.1.0 (gcc (GCC) 3.2.3 (mingw special 20030504-1))
>
> and "tools.zip"
>
> My path is set up as
> PATH=c:\msys\1.0\bin;C:\MinGW\bin;C:\MinGW\lib;c:\tools;"C:\Program
> Files\R\R-2.2.1\bin"
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jeff.hamann at forestinformatics.com  Sun Dec 25 01:37:07 2005
From: jeff.hamann at forestinformatics.com (Jeff D. Hamann)
Date: Sat, 24 Dec 2005 16:37:07 -0800
Subject: [Rd] cygwin and tar -- still?
Message-ID: <001501c608eb$59a23fe0$0a00a8c0@mothra>

I've upgraded laptops and have put a new version of R on the new machine as 
well as the tools for building packages. I know R has required a 
"non-broken" version of tar for some time now and was hoping to not have to 
install any cygwin tools. Since building packages requires the use of MinGW 
and MSYS, why can't we simply use the tar that's part of msys?

After looking at the following results:

E:\conifers>rcmd build --binary rconifers
* checking for file 'rconifers/DESCRIPTION' ... OK
* preparing 'rconifers':
* checking DESCRIPTION meta-information ... OK
* cleaning src
* checking whether 'INDEX' is up-to-date ... NO
* use '--force' to overwrite the existing 'INDEX'
* removing junk files
tar: /cygdrive/E/conifers/rconifers_0.0-5.tar: Cannot open: No such file or 
directory
tar: Error is not recoverable: exiting now
tar: /cygdrive/E/conifers/rconifers_0.0-5.tar: Cannot open: No such file or 
directory
tar: Error is not recoverable: exiting now
Error: cannot open file 'rconifers/DESCRIPTION' for reading

E:\conifers>

I still don't understand why the cygwin tool is required. I'm just a mere 
simpleton and haven't spent the time required to become king-fu master with 
this particular minutiae. Could the script that builds the package be fixed? 
Is it broken? If it's not broken, what's with the cygdrive stuff? why does 
the entire path need to be there?

Is the tar that's in the tools.zip from 
http://www.murdoch-sutherland.com/Rtools/ any different than the one with 
MSYS?

Jeff.


From ligges at statistik.uni-dortmund.de  Sun Dec 25 11:03:23 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 25 Dec 2005 11:03:23 +0100
Subject: [Rd] cygwin and tar -- still?
In-Reply-To: <001501c608eb$59a23fe0$0a00a8c0@mothra>
References: <001501c608eb$59a23fe0$0a00a8c0@mothra>
Message-ID: <43AE6E6B.5080904@statistik.uni-dortmund.de>

Jeff D. Hamann wrote:
> I've upgraded laptops and have put a new version of R on the new machine as 
> well as the tools for building packages. I know R has required a 
> "non-broken" version of tar for some time now and was hoping to not have to 
> install any cygwin tools. Since building packages requires the use of MinGW 
> and MSYS, why can't we simply use the tar that's part of msys?

No, "MSYS" is not required nor supported.


> After looking at the following results:
> 
> E:\conifers>rcmd build --binary rconifers
> * checking for file 'rconifers/DESCRIPTION' ... OK
> * preparing 'rconifers':
> * checking DESCRIPTION meta-information ... OK
> * cleaning src
> * checking whether 'INDEX' is up-to-date ... NO
> * use '--force' to overwrite the existing 'INDEX'
> * removing junk files
> tar: /cygdrive/E/conifers/rconifers_0.0-5.tar: Cannot open: No such file or 
> directory
> tar: Error is not recoverable: exiting now
> tar: /cygdrive/E/conifers/rconifers_0.0-5.tar: Cannot open: No such file or 
> directory
> tar: Error is not recoverable: exiting now
> Error: cannot open file 'rconifers/DESCRIPTION' for reading
> 
> E:\conifers>
> 
> I still don't understand why the cygwin tool is required. I'm just a mere 
> simpleton and haven't spent the time required to become king-fu master with 
> this particular minutiae. Could the script that builds the package be fixed? 
> Is it broken? If it's not broken, what's with the cygdrive stuff? why does 
> the entire path need to be there?
> 
> Is the tar that's in the tools.zip from 
> http://www.murdoch-sutherland.com/Rtools/ any different than the one with 
> MSYS?

Yes, it is different and it works.

Simply don't use MSYS, but use the recommended tools.


Uwe Ligges



> 
> Jeff.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From KNygren at us.imshealth.com  Sun Dec 25 20:35:28 2005
From: KNygren at us.imshealth.com (KNygren@us.imshealth.com)
Date: Sun, 25 Dec 2005 14:35:28 -0500
Subject: [Rd] Portability and Memory Issues for R-package
Message-ID: <5A0AA3EF31FA5545B010F180E03F929A042E119D@UNISMSX02.internal.imsglobal.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20051225/22f3548d/attachment.pl

From cburke at jsoftware.com  Mon Dec 26 11:57:33 2005
From: cburke at jsoftware.com (Chris Burke)
Date: Mon, 26 Dec 2005 18:57:33 +0800
Subject: [Rd] Rserve setSEXP command
Message-ID: <43AFCC9D.1040501@jsoftware.com>

Can any valid SEXP expression be given in the setSEXP command?

I tried to send a numeric matrix by including the dim attribute with the
data, but get an error code 68 (some parameters are invalid). Is the dim
attribute not supported by setSEXP? If so, does this mean a matrix
should be sent as a list, then a dim command sent in a second step?


From simon.urbanek at r-project.org  Mon Dec 26 19:34:15 2005
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 26 Dec 2005 13:34:15 -0500
Subject: [Rd] Rserve setSEXP command
In-Reply-To: <43AFCC9D.1040501@jsoftware.com>
References: <43AFCC9D.1040501@jsoftware.com>
Message-ID: <0B42BEC6-F137-4B11-8CF2-E210ECC22087@r-project.org>

Hi Chris,

On Dec 26, 2005, at 5:57 AM, Chris Burke wrote:

> Can any valid SEXP expression be given in the setSEXP command?
>
> I tried to send a numeric matrix by including the dim attribute  
> with the data, but get an error code 68 (some parameters are  
> invalid). Is the dim attribute not supported by setSEXP? If so,  
> does this mean a matrix should be sent as a list, then a dim  
> command sent in a second step?

It's a combination of a bug and missing feature. The bug is that the  
attribute of an expression is not decoded at all. The missing feature  
is that (dotted-pair) lists are not supported in decode, so you can't  
pass an attribute anyway, because they are stored in dotted-pair  
lists. So, for now, yes, you have to assign the names in a separate  
step - I'll need to fix that ... I'll keep you posted.

Thanks for spotting this!

Cheers,
Simon


From cburke at jsoftware.com  Mon Dec 26 21:43:47 2005
From: cburke at jsoftware.com (Chris Burke)
Date: Tue, 27 Dec 2005 04:43:47 +0800
Subject: [Rd] Rserve setSEXP command
In-Reply-To: <0B42BEC6-F137-4B11-8CF2-E210ECC22087@r-project.org>
References: <43AFCC9D.1040501@jsoftware.com>
	<0B42BEC6-F137-4B11-8CF2-E210ECC22087@r-project.org>
Message-ID: <43B05603.2040309@jsoftware.com>

Simon Urbanek wrote:
>> Can any valid SEXP expression be given in the setSEXP command?
>>
>> I tried to send a numeric matrix by including the dim attribute  with
>> the data, but get an error code 68 (some parameters are  invalid). Is
>> the dim attribute not supported by setSEXP? If so,  does this mean a
>> matrix should be sent as a list, then a dim  command sent in a second
>> step?
> 
> 
> It's a combination of a bug and missing feature. The bug is that the 
> attribute of an expression is not decoded at all. The missing feature 
> is that (dotted-pair) lists are not supported in decode, so you can't 
> pass an attribute anyway, because they are stored in dotted-pair  lists.
> So, for now, yes, you have to assign the names in a separate  step -
> I'll need to fix that ... I'll keep you posted.

Hi Simon

Thanks for the quick response.

A couple of other things I noticed:

1. It would be useful to support the complex datatype. I suspect this
would be straightforward for Rserve and it would be up to the client to
make proper use of it.

2. The documentation and behaviour when sending character strings could
be improved. For example, suppose the character string is 'abcde'. You
need to send the length, but is the length 5 (=number of characters), 6
(5 + the zero character), or 8 (actual length of transmitted data
rounded to 4 byte boundary?

I had expected it to be 8, which is the length of data the programmer
needs to pick up, before moving on to the next block. The character
string would then be read up to the first 0. Actually, if you give a len
of 8, then:

  CMD_setSEXP 'var';'abcde'

assigns the value as in:

  var=c("abcde","","")

This means that the two additional zeros that are padding, are
interpreted as empty strings. So in practice, a len of 6 is needed (i.e.
length of string plus the zero character).

It is probably worth documenting which is correct, and also, for
zero-terminated strings, always reading them up to the first zero only,
and discarding the rest.

Incidentally, this is for the XT_STR expression. For DT_STR, lengths of
either 6 or 8 work correctly.

Great program, by the way.

Chris


From KNygren at us.imshealth.com  Tue Dec 27 07:46:05 2005
From: KNygren at us.imshealth.com (KNygren@us.imshealth.com)
Date: Tue, 27 Dec 2005 01:46:05 -0500
Subject: [Rd] Portability and Memory Issues for R-package
Message-ID: <5A0AA3EF31FA5545B010F180E03F929A042E119E@UNISMSX02.internal.imsglobal.com>

I was able to get the memory issues resolved, so no need to post a response in that regards.   When it comes to the portability issues, I would still like to understand how to best deal with it in regards to the gsl library. 

-----Original Message-----
From: r-devel-bounces at r-project.org
[mailto:r-devel-bounces at r-project.org]On Behalf Of Nygren, Kjell (Union
Meeting)
Sent: Sunday, December 25, 2005 2:35 PM
To: r-devel at r-project.org
Subject: [Rd] Portability and Memory Issues for R-package


I have an upcoming JASA paper with an iid sampling algorithm for Bayesian Generalized Linear models (e.g., Logit, Poisson Regression, and Conditional Logit models with multivariate normal priors). At this point, I have implemented the algorithms in C and hope to make the functions and corresponding source code available through an R package.   I have successfully created the code necessary to create and install a package with most of the functions on my local machine (using R CMD check,R CMD build, and R CMD INSTALL).  As my code makes extensive use of the GSL matrix library, however, I have some questions regarding portability of my package. I am also running into some memory issues when making repeated calls to my functions which I would hope to be able to fix before making a formal distribution of the package. More specifically, the issues are the following:

I. Portability-

Since I make extensive use of the gsl library in my C code, I have the gsl library installed (within the MinGw directory so it is included in the path) on my local machine. Within the package, I am then including a Makevars file with the following code in order to link to the gsl library:

PKG_LIBS=-lgsl -lgslcblas

I also know that there is an R package (gsl) making use of some gsl functions which contains a Makevars.win file with the following code:

PKG_LIBS=-LF:/MinGW/usr/local/lib -lgsl -lgslcblas
# CPPFLAGS=-I$(R_HOME)/include -IF:/MinGW/usr/local/include
PKG_CPPFLAGS=-IF:/MinGW/usr/local/include

For my package to install properly on other machines, however, I take it they would have to have the gsl library files already installed in the proper location (or am I mistaken here?).  In order to make it fully portable on other machines, it thus seems like I would need to either include instructions for how to first install the gsl library prior to installation (which would have to be platform specific), or to somehow have the gsl library files installed during the R package installation. Is the latter even possible? If so, how could it be done (the key files are likely the two library files)?  I believe the gsl package requires the user to have the gsl library preinstalled.  

I guess long-term, an option is for me to rework my C code to eliminate the dependence on  the gsl library. This could, however, be a time consuming effort. In the meantime would it be possible to contribute the package with the existing dependence (as I think is the case for the gsl library).

II.  Memory Issue-

The functions in my package are generally fast and seem to work well if I make a limited number of calls to them from my R code. If I try to make use of them as part of an R MCMC implementation (say updating each Gibbs block 10,000 times in an R loop), I run into memory issues.  Despite the fact that my underlying C code frees memory to all pointers, it does not seem like windows recognizes that the memory has been freed.  This is apparent as the Mem Usage for RGUI.exe in the windows task manager keeps growing throughout the loop and the code slows down and eventually makes virtually no progress. I have noticed similar issues in the past when calling Winbugs repeatedly using Gelmans functions, so it is likely not an issue that is coming just from my code.
I suspect that the memory issues could have something to do with the fact that my C code makes repeated use of the gsl_matrix_alloc and gsl_matrix_free functions rather than the R_alloc function (I suspect that the memory is not Garbage collected).   I searched the web and found the following suggestion from Bryan Gouch in response to a similar question posted on the gsl discussion forum.
"If you want to return an R object containing a gsl_matrix which can be garbage collected then you could use a C++ wrapper, as the C++ interface in R allows the use of separate constructors and destructors. "  
Would this be a possible solution?  If so, how can I find information on how to write such wrapper functions that will work for gsl matrices? I must admit that I am not familiar with how the use of separate constructors and destructors would work.  If that is not the solution, would anyone have any other ideas as to how I can solve the memory issues.
Kjell Nygren

Kjell Nygren,  Ph.D.
Director Pricing and Advanced Analytics
Statistical Services
IMS Health?
960 Harvest Drive, Building A
Blue Bell, PA 19422 USA
voice: 610.832.5586 *  fax: 610.832.5850
email: <mailto:knygren at us.imshealth.com>      
www.imshealth.com
 
The information contained in this communication is confident...{{dropped}}


From murdoch at stats.uwo.ca  Tue Dec 27 21:03:32 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 27 Dec 2005 15:03:32 -0500
Subject: [Rd] Portability and Memory Issues for R-package
In-Reply-To: <5A0AA3EF31FA5545B010F180E03F929A042E119D@UNISMSX02.internal.imsglobal.com>
References: <5A0AA3EF31FA5545B010F180E03F929A042E119D@UNISMSX02.internal.imsglobal.com>
Message-ID: <43B19E14.1010607@stats.uwo.ca>

On 12/25/2005 2:35 PM, KNygren at us.imshealth.com wrote:
> I have an upcoming JASA paper with an iid sampling algorithm for Bayesian Generalized Linear models (e.g., Logit, Poisson Regression, and Conditional Logit models with multivariate normal priors). At this point, I have implemented the algorithms in C and hope to make the functions and corresponding source code available through an R package.   I have successfully created the code necessary to create and install a package with most of the functions on my local machine (using R CMD check,R CMD build, and R CMD INSTALL).  As my code makes extensive use of the GSL matrix library, however, I have some questions regarding portability of my package. I am also running into some memory issues when making repeated calls to my functions which I would hope to be able to fix before making a formal distribution of the package. More specifically, the issues are the following:
> 
> I. Portability-
> 
> Since I make extensive use of the gsl library in my C code, I have the gsl library installed (within the MinGw directory so it is included in the path) on my local machine. Within the package, I am then including a Makevars file with the following code in order to link to the gsl library:
> 
> PKG_LIBS=-lgsl -lgslcblas
> 
> I also know that there is an R package (gsl) making use of some gsl functions which contains a Makevars.win file with the following code:

This package requires manual handling to build for Windows, and probably 
for some other platforms if they don't come with gsl by default.

My recommendation would be to work with its author (Robin Hankin, see 
the DESCRIPTION file for contact information) to add whatever functions 
are not already there, and then just make your package depend on the R 
package, rather than on the GSL library directly.

This will mean that all the manual work that has been done to get gsl to 
build will not need to be repeated by anyone who wants to install your 
package.

Duncan Murdoch

> PKG_LIBS=-LF:/MinGW/usr/local/lib -lgsl -lgslcblas
> # CPPFLAGS=-I$(R_HOME)/include -IF:/MinGW/usr/local/include
> PKG_CPPFLAGS=-IF:/MinGW/usr/local/include
> 
> For my package to install properly on other machines, however, I take it they would have to have the gsl library files already installed in the proper location (or am I mistaken here?).  In order to make it fully portable on other machines, it thus seems like I would need to either include instructions for how to first install the gsl library prior to installation (which would have to be platform specific), or to somehow have the gsl library files installed during the R package installation. Is the latter even possible? If so, how could it be done (the key files are likely the two library files)?  I believe the gsl package requires the user to have the gsl library preinstalled.  
> 
> I guess long-term, an option is for me to rework my C code to eliminate the dependence on  the gsl library. This could, however, be a time consuming effort. In the meantime would it be possible to contribute the package with the existing dependence (as I think is the case for the gsl library).
> 
> II.  Memory Issue-
> 
> The functions in my package are generally fast and seem to work well if I make a limited number of calls to them from my R code. If I try to make use of them as part of an R MCMC implementation (say updating each Gibbs block 10,000 times in an R loop), I run into memory issues.  Despite the fact that my underlying C code frees memory to all pointers, it does not seem like windows recognizes that the memory has been freed.  This is apparent as the Mem Usage for RGUI.exe in the windows task manager keeps growing throughout the loop and the code slows down and eventually makes virtually no progress. I have noticed similar issues in the past when calling Winbugs repeatedly using Gelmans functions, so it is likely not an issue that is coming just from my code.
> I suspect that the memory issues could have something to do with the fact that my C code makes repeated use of the gsl_matrix_alloc and gsl_matrix_free functions rather than the R_alloc function (I suspect that the memory is not Garbage collected).   I searched the web and found the following suggestion from Bryan Gouch in response to a similar question posted on the gsl discussion forum.
> "If you want to return an R object containing a gsl_matrix which can be garbage collected then you could use a C++ wrapper, as the C++ interface in R allows the use of separate constructors and destructors. "  
> Would this be a possible solution?  If so, how can I find information on how to write such wrapper functions that will work for gsl matrices? I must admit that I am not familiar with how the use of separate constructors and destructors would work.  If that is not the solution, would anyone have any other ideas as to how I can solve the memory issues.
> Kjell Nygren
> 
> Kjell Nygren,  Ph.D.
> Director Pricing and Advanced Analytics
> Statistical Services
> IMS Health?
> 960 Harvest Drive, Building A
> Blue Bell, PA 19422 USA
> voice: 610.832.5586 *  fax: 610.832.5850
> email: <mailto:knygren at us.imshealth.com>      
> www.imshealth.com
>  
> The information contained in this communication is confident...{{dropped}}
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From KNygren at us.imshealth.com  Tue Dec 27 21:44:27 2005
From: KNygren at us.imshealth.com (KNygren@us.imshealth.com)
Date: Tue, 27 Dec 2005 15:44:27 -0500
Subject: [Rd] Portability and Memory Issues for R-package
Message-ID: <5A0AA3EF31FA5545B010F180E03F929A042E11AF@UNISMSX02.internal.imsglobal.com>

My guess is that the key step for a user to be able to use my package still would be to install the gsl library first so it can be accessed during the build. I am not sure if Robin has a set of instructions for platform specific installation of his package (which would likely include the pre-installation of the gsl library). I may follow up with him in regards to this and to see if it makes sense to link to his library. I will also look into the possibility of adding a configure script (as per Jan's suggestion). I know that the use of the gsl library is not ideal, and may eventually try to replace the gsl dependent code, perhaps by making use of the R matrix package (though I don't know if it has all the features I am currently using).    


Kjell Nygren 
 
> I. Portability-
> 
> Since I make extensive use of the gsl library in my C code, I have the gsl library installed (within the MinGw directory so it is included in the path) on my local machine. Within the package, I am then including a Makevars file with the following code in order to link to the gsl library:
> 
> PKG_LIBS=-lgsl -lgslcblas
> 
> I also know that there is an R package (gsl) making use of some gsl functions which contains a Makevars.win file with the following code:

This package requires manual handling to build for Windows, and probably 
for some other platforms if they don't come with gsl by default.

My recommendation would be to work with its author (Robin Hankin, see 
the DESCRIPTION file for contact information) to add whatever functions 
are not already there, and then just make your package depend on the R 
package, rather than on the GSL library directly.

This will mean that all the manual work that has been done to get gsl to 
build will not need to be repeated by anyone who wants to install your 
package.

Duncan Murdoch


From murdoch at stats.uwo.ca  Tue Dec 27 22:57:40 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 27 Dec 2005 16:57:40 -0500
Subject: [Rd] Portability and Memory Issues for R-package
In-Reply-To: <5A0AA3EF31FA5545B010F180E03F929A042E11AF@UNISMSX02.internal.imsglobal.com>
References: <5A0AA3EF31FA5545B010F180E03F929A042E11AF@UNISMSX02.internal.imsglobal.com>
Message-ID: <43B1B8D4.5080005@stats.uwo.ca>

On 12/27/2005 3:44 PM, KNygren at us.imshealth.com wrote:
> My guess is that the key step for a user to be able to use my package still would be to install the gsl library first so it can be accessed during the build. I am not sure if Robin has a set of instructions for platform specific installation of his package (which would likely include the pre-installation of the gsl library).

This is not necessary on Windows, where most users install binary builds 
of packages, because Brian Ripley has done the work to put together a 
binary build that includes the necessary GSL routines.  I would expect 
that if you require users to install GSL and compile your package 
themselves, you'll get almost no Windows users.  I don't know what is 
involved in installing the package on other platforms.

Duncan Murdoch

> I may follow up with him in regards to this and to see if it makes sense to link to his library. I will also look into the possibility of adding a configure script (as per Jan's suggestion). I know that the use of the gsl library is not ideal, and may eventually try to replace the gsl dependent code, perhaps by making use of the R matrix package (though I don't know if it has all the features I am currently using).    
> 
> 
> Kjell Nygren 
>  
> 
>>I. Portability-
>>
>>Since I make extensive use of the gsl library in my C code, I have the gsl library installed (within the MinGw directory so it is included in the path) on my local machine. Within the package, I am then including a Makevars file with the following code in order to link to the gsl library:
>>
>>PKG_LIBS=-lgsl -lgslcblas
>>
>>I also know that there is an R package (gsl) making use of some gsl functions which contains a Makevars.win file with the following code:
> 
> 
> This package requires manual handling to build for Windows, and probably 
> for some other platforms if they don't come with gsl by default.
> 
> My recommendation would be to work with its author (Robin Hankin, see 
> the DESCRIPTION file for contact information) to add whatever functions 
> are not already there, and then just make your package depend on the R 
> package, rather than on the GSL library directly.
> 
> This will mean that all the manual work that has been done to get gsl to 
> build will not need to be repeated by anyone who wants to install your 
> package.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From KNygren at us.imshealth.com  Tue Dec 27 23:18:25 2005
From: KNygren at us.imshealth.com (KNygren@us.imshealth.com)
Date: Tue, 27 Dec 2005 17:18:25 -0500
Subject: [Rd] Portability and Memory Issues for R-package
Message-ID: <5A0AA3EF31FA5545B010F180E03F929A042E11B0@UNISMSX02.internal.imsglobal.com>

Not getting users was one of my main concern.  So let me make sure I understand the suggestions correctly.

A. I should check if the GSL routines I make use of are part of Brian's binary build.  If not, I should look into having the required routines added to that build (going through Robin (or perhaps Brian?)). 

B. If the required routines are included in the binary build for the GSL package, I can then link my package to the gsl packages and it should work fine on windows for any user who has done the installation of the gsl package. I take it the binary build also eliminates the need for each user to do the manual handling required to build on windows?  

Kjell Nygren      

-----Original Message-----
From: Duncan Murdoch [mailto:murdoch at stats.uwo.ca]
Sent: Tuesday, December 27, 2005 4:58 PM
To: Nygren, Kjell (Union Meeting)
Cc: r-devel at r-project.org
Subject: Re: [Rd] Portability and Memory Issues for R-package


On 12/27/2005 3:44 PM, KNygren at us.imshealth.com wrote:
> My guess is that the key step for a user to be able to use my package still would be to install the gsl library first so it can be accessed during the build. I am not sure if Robin has a set of instructions for platform specific installation of his package (which would likely include the pre-installation of the gsl library).

This is not necessary on Windows, where most users install binary builds 
of packages, because Brian Ripley has done the work to put together a 
binary build that includes the necessary GSL routines.  I would expect 
that if you require users to install GSL and compile your package 
themselves, you'll get almost no Windows users.  I don't know what is 
involved in installing the package on other platforms.

Duncan Murdoch

> I may follow up with him in regards to this and to see if it makes sense to link to his library. I will also look into the possibility of adding a configure script (as per Jan's suggestion). I know that the use of the gsl library is not ideal, and may eventually try to replace the gsl dependent code, perhaps by making use of the R matrix package (though I don't know if it has all the features I am currently using).    
> 
> 
> Kjell Nygren 
>  
> 
>>I. Portability-
>>
>>Since I make extensive use of the gsl library in my C code, I have the gsl library installed (within the MinGw directory so it is included in the path) on my local machine. Within the package, I am then including a Makevars file with the following code in order to link to the gsl library:
>>
>>PKG_LIBS=-lgsl -lgslcblas
>>
>>I also know that there is an R package (gsl) making use of some gsl functions which contains a Makevars.win file with the following code:
> 
> 
> This package requires manual handling to build for Windows, and probably 
> for some other platforms if they don't come with gsl by default.
> 
> My recommendation would be to work with its author (Robin Hankin, see 
> the DESCRIPTION file for contact information) to add whatever functions 
> are not already there, and then just make your package depend on the R 
> package, rather than on the GSL library directly.
> 
> This will mean that all the manual work that has been done to get gsl to 
> build will not need to be repeated by anyone who wants to install your 
> package.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From sfalcon at fhcrc.org  Wed Dec 28 01:59:28 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Tue, 27 Dec 2005 16:59:28 -0800
Subject: [Rd] Enhancement request: anonymous connections
Message-ID: <m2mzimc9zj.fsf@fhcrc.org>

I would like to be able to use anonymous connections in R and have
them close themselves when they go out of scope.

Here is an example of what I think should work, but does not at
present:

## create test file 
x <- 1:10
fn <- "anon-con-test-x.rda"
save(x, file=fn)
testUrl <- paste("file:/", getwd(), fn, sep="/")

## use an anonymous connection to load data from
## the URL as suggested in help(load).
for (i in 1:50) {
    print(load(url(testUrl)))
}

[snip some output]
Error in url(testUrl) : all connections are in use

If such a feature is not possible/desired for the next release, it
might be good to add a note to the documentation for connections that
mentions this issue with anonymous connections.


--
 + seth


From murdoch at stats.uwo.ca  Wed Dec 28 02:44:40 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 27 Dec 2005 20:44:40 -0500
Subject: [Rd] Enhancement request: anonymous connections
In-Reply-To: <m2mzimc9zj.fsf@fhcrc.org>
References: <m2mzimc9zj.fsf@fhcrc.org>
Message-ID: <43B1EE08.4090003@stats.uwo.ca>

On 12/27/2005 7:59 PM, Seth Falcon wrote:
> I would like to be able to use anonymous connections in R and have
> them close themselves when they go out of scope.
> 
> Here is an example of what I think should work, but does not at
> present:
> 
> ## create test file 
> x <- 1:10
> fn <- "anon-con-test-x.rda"
> save(x, file=fn)
> testUrl <- paste("file:/", getwd(), fn, sep="/")
> 
> ## use an anonymous connection to load data from
> ## the URL as suggested in help(load).
> for (i in 1:50) {
>     print(load(url(testUrl)))
> }
> 
> [snip some output]
> Error in url(testUrl) : all connections are in use
> 
> If such a feature is not possible/desired for the next release, it
> might be good to add a note to the documentation for connections that
> mentions this issue with anonymous connections.

This is a bug in load, isn't it?  load() opens the connection but 
doesn't close it.

I think a fix is to add a line to load() as shown below:

Index: load.R
===================================================================
--- load.R      (revision 36884)
+++ load.R      (working copy)
@@ -11,6 +11,7 @@
      if(!isOpen(con)) {
          ## code below assumes that the connection is open ...
          open(con, "rb")
+        on.exit(close(con))
      }

      magic <- readChar(con, 5)

Duncan Murdoch


From gregor.gorjanc at bfro.uni-lj.si  Wed Dec 28 11:46:56 2005
From: gregor.gorjanc at bfro.uni-lj.si (gregor.gorjanc@bfro.uni-lj.si)
Date: Wed, 28 Dec 2005 11:46:56 +0100 (CET)
Subject: [Rd] update.packages() and loaded packages (PR#8448)
Message-ID: <20051228104656.27A9619A7E@slim.kubism.ku.dk>

Hello!

This is not a severe bug, but an inconsistency in update.packages(). I 
updated packages and I was not carefull enough to detach loaded 
packages. The update.packages() warrned me about this, which is fine, 
but at the end of the update the following warrning was issued (the 
whole session output can be found at the end of this mail):

...
The downloaded packages are in
         C:\Documents and Settings\GGorjan\Local 
Settings\Temp\RtmpVwI1ob\downloaded_packages
updating HTML package descriptions
Warning message:
number of rows of result
         is not a multiple of vector length (arg 1) in: cbind(1, pkgs, lib)

R> version
          _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status   Patched
major    2
minor    2.1
year     2005
month    12
day      26
svn rev  36870
language R

-- 
Lep pozdrav / With regards,
     Gregor Gorjanc

----------------------------------------------------------------------
University of Ljubljana     PhD student
Biotechnical Faculty
Zootechnical Department     URI: http://www.bfro.uni-lj.si/MR/ggorjan
Groblje 3                   mail: gregor.gorjanc <at> bfro.uni-lj.si 

SI-1230 Domzale             tel: +386 (0)1 72 17 861
Slovenia, Europe            fax: +386 (0)1 72 17 888 

----------------------------------------------------------------------
"One must learn by doing the thing; for though you think you know it,
  you have no certainty until you try." Sophocles ~ 450 B.C.
----------------------------------------------------------------------

R> update.packages(ask='graphics')
--- Please select a CRAN mirror for use in this session ---
Warning: packages 'gdata, gplots, gtools, R2WinBUGS' are in use and will 
not be installed
trying URL 
'http://www.fastmirrors.org/cran/bin/windows/contrib/2.2/coda_0.10-3.zip'
Content type 'application/zip' length 288711 bytes
opened URL
downloaded 281Kb

trying URL 
'http://www.fastmirrors.org/cran/bin/windows/contrib/2.2/hdrcde_1.01.zip'
Content type 'application/zip' length 102191 bytes
opened URL
downloaded 99Kb

trying URL 
'http://www.fastmirrors.org/cran/bin/windows/contrib/2.2/limma_2.4.4.zip'
Content type 'application/zip' length 1331703 bytes
opened URL
downloaded 1300Kb

trying URL 
'http://www.fastmirrors.org/cran/bin/windows/contrib/2.2/locfit_1.5-2.zip'
Content type 'application/zip' length 577663 bytes
opened URL
downloaded 564Kb

trying URL 
'http://www.fastmirrors.org/cran/bin/windows/contrib/2.2/Matrix_0.99-3.zip'
Content type 'application/zip' length 2395983 bytes
opened URL
downloaded 2339Kb

trying URL 
'http://www.fastmirrors.org/cran/bin/windows/contrib/2.2/vcd_0.9-7.zip'
Content type 'application/zip' length 1278635 bytes
opened URL
downloaded 1248Kb

package 'coda' successfully unpacked and MD5 sums checked
package 'hdrcde' successfully unpacked and MD5 sums checked
package 'limma' successfully unpacked and MD5 sums checked
package 'locfit' successfully unpacked and MD5 sums checked
package 'Matrix' successfully unpacked and MD5 sums checked
package 'vcd' successfully unpacked and MD5 sums checked

The downloaded packages are in
         C:\Documents and Settings\GGorjan\Local 
Settings\Temp\RtmpVwI1ob\downloaded_packages
updating HTML package descriptions
Warning message:
number of rows of result
         is not a multiple of vector length (arg 1) in: cbind(1, pkgs, lib)

R> detach(package:gdata)
R> detach(package:gplots)
R> detach(package:gtools)
R> detach(package:R2WinBUGS)
R> update.packages(ask='graphics')
trying URL 
'http://www.fastmirrors.org/cran/bin/windows/contrib/2.2/gdata_2.1.2.zip'
Content type 'application/zip' length 336256 bytes
opened URL
downloaded 328Kb

trying URL 
'http://www.fastmirrors.org/cran/bin/windows/contrib/2.2/gplots_2.2.0.zip'
Content type 'application/zip' length 441270 bytes
opened URL
downloaded 430Kb

trying URL 
'http://www.fastmirrors.org/cran/bin/windows/contrib/2.2/gtools_2.2.3.zip'
Content type 'application/zip' length 127243 bytes
opened URL
downloaded 124Kb

trying URL 
'http://www.fastmirrors.org/cran/bin/windows/contrib/2.2/R2WinBUGS_1.1-0.zip'
Content type 'application/zip' length 1188431 bytes
opened URL
downloaded 1160Kb

package 'gdata' successfully unpacked and MD5 sums checked
package 'gplots' successfully unpacked and MD5 sums checked
package 'gtools' successfully unpacked and MD5 sums checked
package 'R2WinBUGS' successfully unpacked and MD5 sums checked

The downloaded packages are in
         C:\Documents and Settings\GGorjan\Local 
Settings\Temp\RtmpVwI1ob\downloaded_packages
updating HTML package descriptions


From gregor.gorjanc at bfro.uni-lj.si  Wed Dec 28 12:25:31 2005
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Wed, 28 Dec 2005 12:25:31 +0100
Subject: [Rd] NaN in R distribution functions
Message-ID: <43B2762B.20403@bfro.uni-lj.si>

Dear R developers,

I noticed that core R distribution functions return NaN, when parameter 
values are out of parameter space. I have looked in source code and 
found that warnings and return of NaN are done internally in C code. For 
dgamma.c the line 49 is:

     if (shape <= 0 || scale <= 0) ML_ERR_return_NAN;

OK. How should this be implemented if distribution functions are written 
directly in R? I came up with this

     if (any(shape <= 0)) {
         warning("shape must be positive")
         return(NaN)
     }

I think that it would be nice that returning NaN for undefined parameter 
values in distribution functions would also be documented in Writing R 
Extension.

-- 
Lep pozdrav / With regards,
     Gregor Gorjanc

----------------------------------------------------------------------
University of Ljubljana     PhD student
Biotechnical Faculty
Zootechnical Department     URI: http://www.bfro.uni-lj.si/MR/ggorjan
Groblje 3                   mail: gregor.gorjanc <at> bfro.uni-lj.si 

SI-1230 Domzale             tel: +386 (0)1 72 17 861
Slovenia, Europe            fax: +386 (0)1 72 17 888 

----------------------------------------------------------------------
"One must learn by doing the thing; for though you think you know it,
  you have no certainty until you try." Sophocles ~ 450 B.C.


From ripley at stats.ox.ac.uk  Wed Dec 28 12:35:57 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 28 Dec 2005 11:35:57 +0000 (GMT)
Subject: [Rd] NaN in R distribution functions
In-Reply-To: <43B2762B.20403@bfro.uni-lj.si>
References: <43B2762B.20403@bfro.uni-lj.si>
Message-ID: <Pine.LNX.4.61.0512281130200.22424@gannet.stats>

On Wed, 28 Dec 2005, Gregor Gorjanc wrote:

> Dear R developers,
>
> I noticed that core R distribution functions return NaN, when parameter
> values are out of parameter space. I have looked in source code and
> found that warnings and return of NaN are done internally in C code. For
> dgamma.c the line 49 is:
>
>     if (shape <= 0 || scale <= 0) ML_ERR_return_NAN;
>
> OK. How should this be implemented if distribution functions are written
> directly in R? I came up with this
>
>     if (any(shape <= 0)) {
>         warning("shape must be positive")
>         return(NaN)
>     }

As the R-level code is vectorized, NaN is unlikely to be the appropriate 
return value. You will find that only the relevant entries are NaN, for 
example

> dgamma(1, shape=-1:2)
[1]       NaN       NaN 0.3678794 0.3678794
Warning message:
NaNs produced in: dgamma(x, shape, scale, log)

> I think that it would be nice that returning NaN for undefined parameter
> values in distribution functions would also be documented in Writing R
> Extension.

It is purely a convention for use in the standalone libRmath with which 
the code is shared.  Otherwise returning NA or giving an error would seem 
more appropriate.

`Writing R Extensions' does not cover writing distribution functions, and 
is certainly not intended to mandate how such extensions are written.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From sfalcon at fhcrc.org  Wed Dec 28 15:50:25 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed, 28 Dec 2005 06:50:25 -0800
Subject: [Rd] Enhancement request: anonymous connections
In-Reply-To: <43B1EE08.4090003@stats.uwo.ca> (Duncan Murdoch's message of "Tue,
	27 Dec 2005 20:44:40 -0500")
References: <m2mzimc9zj.fsf@fhcrc.org> <43B1EE08.4090003@stats.uwo.ca>
Message-ID: <m2ek3xcm32.fsf@fhcrc.org>

On 27 Dec 2005, murdoch at stats.uwo.ca wrote:
> This is a bug in load, isn't it?  load() opens the connection but
> doesn't close it.

Well, it may be that load needs a small fix, but that doesn't fix
anonymous connections in general, IMO.

The loop could easily have been:

for (i in 1:50) {
    print(load(url(testUrl, open="r")))
}

And it doesn't need to be related to url or load:

cat("a line of text\n", file="another-example.txt")
z <- NULL
for (i in 1:50) {
    z <- c(z, readLines(file("another-example.txt", open="r")))
}

Also, connections are "in use" even if they are closed:

for (i in 1:50) {
    if (isOpen(file("another-example.txt")))
        stop("you will not get here")
}


--
+ seth


From murdoch at stats.uwo.ca  Wed Dec 28 20:32:19 2005
From: murdoch at stats.uwo.ca (murdoch@stats.uwo.ca)
Date: Wed, 28 Dec 2005 20:32:19 +0100 (CET)
Subject: [Rd] .Call not counting parameters consistently (PR#8450)
Message-ID: <20051228193219.52B4519A2F@slim.kubism.ku.dk>

The R_registerRoutines C function allows the number of parameters to a
.Call function to be registered.  For example, the tools package
function md5sum() calls "Rmd5", which has been registered to require
just one parameter.

But if it is called with the wrong number of parameters, only the first
error gets caught:

  > library(tools)
  > .Call("Rmd5",1,2,PACKAGE="tools")
Error: Incorrect number of arguments (2), expecting 1 for Rmd5
  > .Call("Rmd5",1,2,PACKAGE="tools")
Error: argument 'files' must be character

This happens in Windows versions of R-patched and R-devel.  Charlie
Geyer was bitten by this in his fuzzyRankTests package (version 0.3),
which fails check because of it on Windows, but not on Unix.  I haven't
done any testing on Unix.

I've traced into the do_dotcall function in src/main/dotcode.c, and I
see that on the second call the "symbol.symbol.call" member is NULL, so
no test is done, but I don't see why this is happening.  The
resolveNativeRoutine function does some strange stuff.

Duncan Murdoch


From duncan at wald.ucdavis.edu  Wed Dec 28 21:01:20 2005
From: duncan at wald.ucdavis.edu (Duncan Temple Lang)
Date: Wed, 28 Dec 2005 12:01:20 -0800
Subject: [Rd] .Call not counting parameters consistently (PR#8450)
In-Reply-To: <20051228193219.52B4519A2F@slim.kubism.ku.dk>
References: <20051228193219.52B4519A2F@slim.kubism.ku.dk>
Message-ID: <43B2EF10.807@wald.ucdavis.edu>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

Coincidentally, I am in the process of working on a related aspect of
symbol resolution.

The issue is likely to be the caching of native symbols
that we do. We do not cache the registration information,
just the address of the routine.  And so the test is not
repeated.  We can fix this, but it will make things more
complex. This is a good example of where using the new mechanism
within namespaces to resolve the symbols when the package
is loaded and making them into regular R objects that
are passed to .Call/.C/... makes things more rational.
In that case, the caching is done in R and type information
is more directly available.


Off hand, I don't see why this would behave differently
on Windows and Unix, so I'd appreciate if you could let
us know the specific call that raises the error on Windows
and not on Unix.


D.


murdoch at stats.uwo.ca wrote:
> The R_registerRoutines C function allows the number of parameters to a
> .Call function to be registered.  For example, the tools package
> function md5sum() calls "Rmd5", which has been registered to require
> just one parameter.
> 
> But if it is called with the wrong number of parameters, only the first
> error gets caught:
> 
>   > library(tools)
>   > .Call("Rmd5",1,2,PACKAGE="tools")
> Error: Incorrect number of arguments (2), expecting 1 for Rmd5
>   > .Call("Rmd5",1,2,PACKAGE="tools")
> Error: argument 'files' must be character
> 
> This happens in Windows versions of R-patched and R-devel.  Charlie
> Geyer was bitten by this in his fuzzyRankTests package (version 0.3),
> which fails check because of it on Windows, but not on Unix.  I haven't
> done any testing on Unix.
> 
> I've traced into the do_dotcall function in src/main/dotcode.c, and I
> see that on the second call the "symbol.symbol.call" member is NULL, so
> no test is done, but I don't see why this is happening.  The
> resolveNativeRoutine function does some strange stuff.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

- --
Duncan Temple Lang                    duncan at wald.ucdavis.edu
Department of Statistics              work:  (530) 752-4782
4210 Mathematical Sciences Building   fax:   (530) 752-7099
One Shields Ave.
University of California at Davis
Davis,
CA 95616,
USA
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.2 (Darwin)

iD8DBQFDsu8Q9p/Jzwa2QP4RAuqGAJ9oHP7lhmb7IN9c/3WoRL5qimCTSACfaNhr
WFY6NLnh2dfDTOGcaStbgNo=
=rCZg
-----END PGP SIGNATURE-----


From ligges at statistik.uni-dortmund.de  Wed Dec 28 22:39:54 2005
From: ligges at statistik.uni-dortmund.de (ligges@statistik.uni-dortmund.de)
Date: Wed, 28 Dec 2005 22:39:54 +0100 (CET)
Subject: [Rd] .Call not counting parameters consistently (PR#8450)
Message-ID: <20051228213954.3DD4419A45@slim.kubism.ku.dk>

Duncan Temple Lang wrote:

> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
> 
> Coincidentally, I am in the process of working on a related aspect of
> symbol resolution.
> 
> The issue is likely to be the caching of native symbols
> that we do. We do not cache the registration information,
> just the address of the routine.  And so the test is not
> repeated.  We can fix this, but it will make things more
> complex. This is a good example of where using the new mechanism
> within namespaces to resolve the symbols when the package
> is loaded and making them into regular R objects that
> are passed to .Call/.C/... makes things more rational.
> In that case, the caching is done in R and type information
> is more directly available.
> 
> 
> Off hand, I don't see why this would behave differently
> on Windows and Unix, so I'd appreciate if you could let
> us know the specific call that raises the error on Windows
> and not on Unix.


In principle, the code where this came up in the tests for the new CRAN 
package fuzzyRankTests is:

   library(fuzzyRankTests)
   set.seed(123)
   mu <- 0
   x <- rnorm(10)
   y <- rnorm(10) + 1.5
   try(.Call("fpvranksum", y, x, mu, "great",
      PACKAGE = "fuzzyRankTests"))

Uwe



> 
> D.
> 
> 
> murdoch at stats.uwo.ca wrote:
> 
>>The R_registerRoutines C function allows the number of parameters to a
>>.Call function to be registered.  For example, the tools package
>>function md5sum() calls "Rmd5", which has been registered to require
>>just one parameter.
>>
>>But if it is called with the wrong number of parameters, only the first
>>error gets caught:
>>
>>  > library(tools)
>>  > .Call("Rmd5",1,2,PACKAGE="tools")
>>Error: Incorrect number of arguments (2), expecting 1 for Rmd5
>>  > .Call("Rmd5",1,2,PACKAGE="tools")
>>Error: argument 'files' must be character
>>
>>This happens in Windows versions of R-patched and R-devel.  Charlie
>>Geyer was bitten by this in his fuzzyRankTests package (version 0.3),
>>which fails check because of it on Windows, but not on Unix.  I haven't
>>done any testing on Unix.
>>
>>I've traced into the do_dotcall function in src/main/dotcode.c, and I
>>see that on the second call the "symbol.symbol.call" member is NULL, so
>>no test is done, but I don't see why this is happening.  The
>>resolveNativeRoutine function does some strange stuff.
>>
>>Duncan Murdoch
>>
>>______________________________________________
>>R-devel at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> - --
> Duncan Temple Lang                    duncan at wald.ucdavis.edu
> Department of Statistics              work:  (530) 752-4782
> 4210 Mathematical Sciences Building   fax:   (530) 752-7099
> One Shields Ave.
> University of California at Davis
> Davis,
> CA 95616,
> USA
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.2 (Darwin)
> 
> iD8DBQFDsu8Q9p/Jzwa2QP4RAuqGAJ9oHP7lhmb7IN9c/3WoRL5qimCTSACfaNhr
> WFY6NLnh2dfDTOGcaStbgNo=
> =rCZg
> -----END PGP SIGNATURE-----
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch at stats.uwo.ca  Wed Dec 28 23:58:21 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 28 Dec 2005 17:58:21 -0500
Subject: [Rd] .Call not counting parameters consistently (PR#8450)
In-Reply-To: <43B2EF10.807@wald.ucdavis.edu>
References: <20051228193219.52B4519A2F@slim.kubism.ku.dk>
	<43B2EF10.807@wald.ucdavis.edu>
Message-ID: <43B3188D.40401@stats.uwo.ca>

On 12/28/2005 3:01 PM, Duncan Temple Lang wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
> 
> Coincidentally, I am in the process of working on a related aspect of
> symbol resolution.
> 
> The issue is likely to be the caching of native symbols
> that we do. We do not cache the registration information,
> just the address of the routine.  And so the test is not
> repeated.  We can fix this, but it will make things more
> complex. This is a good example of where using the new mechanism
> within namespaces to resolve the symbols when the package
> is loaded and making them into regular R objects that
> are passed to .Call/.C/... makes things more rational.
> In that case, the caching is done in R and type information
> is more directly available.
> 
> 
> Off hand, I don't see why this would behave differently
> on Windows and Unix, so I'd appreciate if you could let
> us know the specific call that raises the error on Windows
> and not on Unix.

I just checked 2.1.1 on a Unix box, and didn't see the error (though I 
do see it in 2.1.1 on Windows).  I don't really know how to narrow down 
the error any more than I did below:  resolveNativeRoutine isn't 
returning the same answer both times.  It returns enough for a 
successful call the second time, but not enough to test that the 
parameters are right.

Duncan
> 
> 
> D.
> 
> 
> murdoch at stats.uwo.ca wrote:
> 
>>The R_registerRoutines C function allows the number of parameters to a
>>.Call function to be registered.  For example, the tools package
>>function md5sum() calls "Rmd5", which has been registered to require
>>just one parameter.
>>
>>But if it is called with the wrong number of parameters, only the first
>>error gets caught:
>>
>>  > library(tools)
>>  > .Call("Rmd5",1,2,PACKAGE="tools")
>>Error: Incorrect number of arguments (2), expecting 1 for Rmd5
>>  > .Call("Rmd5",1,2,PACKAGE="tools")
>>Error: argument 'files' must be character
>>
>>This happens in Windows versions of R-patched and R-devel.  Charlie
>>Geyer was bitten by this in his fuzzyRankTests package (version 0.3),
>>which fails check because of it on Windows, but not on Unix.  I haven't
>>done any testing on Unix.
>>
>>I've traced into the do_dotcall function in src/main/dotcode.c, and I
>>see that on the second call the "symbol.symbol.call" member is NULL, so
>>no test is done, but I don't see why this is happening.  The
>>resolveNativeRoutine function does some strange stuff.
>>
>>Duncan Murdoch
>>
>>______________________________________________
>>R-devel at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> - --
> Duncan Temple Lang                    duncan at wald.ucdavis.edu
> Department of Statistics              work:  (530) 752-4782
> 4210 Mathematical Sciences Building   fax:   (530) 752-7099
> One Shields Ave.
> University of California at Davis
> Davis,
> CA 95616,
> USA
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v1.4.2 (Darwin)
> 
> iD8DBQFDsu8Q9p/Jzwa2QP4RAuqGAJ9oHP7lhmb7IN9c/3WoRL5qimCTSACfaNhr
> WFY6NLnh2dfDTOGcaStbgNo=
> =rCZg
> -----END PGP SIGNATURE-----
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ellis at stat.harvard.edu  Thu Dec 29 06:17:44 2005
From: ellis at stat.harvard.edu (Byron Ellis)
Date: Wed, 28 Dec 2005 21:17:44 -0800
Subject: [Rd] Enhancement request: anonymous connections
In-Reply-To: <m2ek3xcm32.fsf@fhcrc.org>
References: <m2mzimc9zj.fsf@fhcrc.org> <43B1EE08.4090003@stats.uwo.ca>
	<m2ek3xcm32.fsf@fhcrc.org>
Message-ID: <33A6B5DE-C44D-42F8-933C-7C707FB6FF31@stat.harvard.edu>

I think what you're suggesting is that connections should become  
first-class citizens in the R world by becoming a CONSXP, an  
EXTPTRSXP + Finalizer or whatever (which wouldn't bother me a bit,  
BTW). Then they'd play by the same rules as everything else, although  
you might want to have an explicit close as well as a close on  
finalize, that way you could close and then reopen if you keep a  
reference around (It also really annoys me that close NULLs the value  
of the symbol right now). It'd also be nice to *gasp* have an API for  
I/O from the C side of things as well.

If we wanted to be truly radical we'd just accept that graphics  
devices and event loops are just special cases of the connection and  
merge the whole thing, thus more-or-less reinventing CLIM. :-)

On Dec 28, 2005, at 6:50 AM, Seth Falcon wrote:

> On 27 Dec 2005, murdoch at stats.uwo.ca wrote:
>> This is a bug in load, isn't it?  load() opens the connection but
>> doesn't close it.
>
> Well, it may be that load needs a small fix, but that doesn't fix
> anonymous connections in general, IMO.
>
> The loop could easily have been:
>
> for (i in 1:50) {
>     print(load(url(testUrl, open="r")))
> }
>
> And it doesn't need to be related to url or load:
>
> cat("a line of text\n", file="another-example.txt")
> z <- NULL
> for (i in 1:50) {
>     z <- c(z, readLines(file("another-example.txt", open="r")))
> }
>
> Also, connections are "in use" even if they are closed:
>
> for (i in 1:50) {
>     if (isOpen(file("another-example.txt")))
>         stop("you will not get here")
> }
>
>
> --
> + seth
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

---
Byron Ellis (ellis at stat.harvard.edu)
"Oook" -- The Librarian


From gregor.gorjanc at bfro.uni-lj.si  Thu Dec 29 09:48:14 2005
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Thu, 29 Dec 2005 09:48:14 +0100
Subject: [Rd] NaN in R distribution functions
In-Reply-To: <Pine.LNX.4.61.0512281130200.22424@gannet.stats>
References: <43B2762B.20403@bfro.uni-lj.si>
	<Pine.LNX.4.61.0512281130200.22424@gannet.stats>
Message-ID: <43B3A2CE.9000109@bfro.uni-lj.si>

Prof Brian Ripley wrote:
> On Wed, 28 Dec 2005, Gregor Gorjanc wrote:
> 
>> Dear R developers,
>>
>> I noticed that core R distribution functions return NaN, when parameter
>> values are out of parameter space. I have looked in source code and
>> found that warnings and return of NaN are done internally in C code. For
>> dgamma.c the line 49 is:
>>
>>     if (shape <= 0 || scale <= 0) ML_ERR_return_NAN;
>>
>> OK. How should this be implemented if distribution functions are written
>> directly in R? I came up with this
>>
>>     if (any(shape <= 0)) {
>>         warning("shape must be positive")
>>         return(NaN)
>>     }
> 
> 
> As the R-level code is vectorized, NaN is unlikely to be the appropriate 
> return value. You will find that only the relevant entries are NaN, for 
> example
> 
>> dgamma(1, shape=-1:2)
> 
> [1]       NaN       NaN 0.3678794 0.3678794
> Warning message:
> NaNs produced in: dgamma(x, shape, scale, log)
>

Yes, you are right.

>> I think that it would be nice that returning NaN for undefined parameter
>> values in distribution functions would also be documented in Writing R
>> Extension.
> 
> It is purely a convention for use in the standalone libRmath with which 
> the code is shared.  Otherwise returning NA or giving an error would 
> seem more appropriate.
> 
> `Writing R Extensions' does not cover writing distribution functions, 
> and is certainly not intended to mandate how such extensions are written.

I understand, however it would be really nice to have some guideline so 
that developers would write more or less similar code. I had a problem 
with one such functions, since it stopped if parameters values were out 
of parameter space. I used that function in optim() and it was 
annoyingly stopping the optimization. It was not much to change the 
function to return NaN (this could be as well NA as you have pointed 
out), but it would be nice that this would be the default.

-- 
Lep pozdrav / With regards,
     Gregor Gorjanc

----------------------------------------------------------------------
University of Ljubljana     PhD student
Biotechnical Faculty
Zootechnical Department     URI: http://www.bfro.uni-lj.si/MR/ggorjan
Groblje 3                   mail: gregor.gorjanc <at> bfro.uni-lj.si 

SI-1230 Domzale             tel: +386 (0)1 72 17 861
Slovenia, Europe            fax: +386 (0)1 72 17 888 

----------------------------------------------------------------------
"One must learn by doing the thing; for though you think you know it,
  you have no certainty until you try." Sophocles ~ 450 B.C.


From blindglobe at gmail.com  Thu Dec 29 13:37:14 2005
From: blindglobe at gmail.com (A.J. Rossini)
Date: Thu, 29 Dec 2005 13:37:14 +0100
Subject: [Rd] reinventing the wheel....
Message-ID: <1abe3fa90512290437g6595c5e1pbca342caedff6a6c@mail.gmail.com>

> ---------- Forwarded message ----------
> From: Byron Ellis <ellis at stat.harvard.edu>

> If we wanted to be truly radical we'd just accept that graphics
> devices and event loops are just special cases of the connection and
> merge the whole thing, thus more-or-less reinventing CLIM. :-)

Eventually, all programming languages grow up and become Lisp.

(progress, progress, and more joyful progress on CLS).

best,
-tony

blindglobe at gmail.com
Muttenz, Switzerland.
"Commit early,commit often, and commit in a repository from which we can easily
roll-back your mistakes" (AJR, 4Jan05).


From marcelodamasceno at gmail.com  Thu Dec 29 15:49:17 2005
From: marcelodamasceno at gmail.com (Marcelo Damasceno)
Date: Thu, 29 Dec 2005 12:49:17 -0200
Subject: [Rd] Problems with calloc function.
Message-ID: <a55593730512290649w497ffc10p75c5fd7f71af402b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-devel/attachments/20051229/c76a4183/attachment.pl

From ripley at stats.ox.ac.uk  Thu Dec 29 18:40:37 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 29 Dec 2005 17:40:37 +0000 (GMT)
Subject: [Rd] Problems with calloc function.
In-Reply-To: <a55593730512290649w497ffc10p75c5fd7f71af402b@mail.gmail.com>
References: <a55593730512290649w497ffc10p75c5fd7f71af402b@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0512291524370.31762@gannet.stats>

Rather than trying to reinvent the wheel, why not make use of the 
functions documented in Writing R Extensions, especially Calloc/Free?

And definitely do not call exit() from code linked into R: it is 
antisocial behaviour to terminate your host's process.

Your example is incomplete, and for some values of 'col' you will run out 
of memory.  (It is also not legal C as written, since you mix code and 
declarations.)

On Thu, 29 Dec 2005, Marcelo Damasceno wrote:

> Hi all,
>
> I have a C code in Linux, it has 7 pointers and compile e run OK, but when I
> run in R happens problems with calloc function, it returns NULL.
> ###############################################
>> int *temp1,*temp2,*temp3,*temp4;
>
> temp1 = (int *)calloc(col,sizeof(int));
> if(temp1 == NULL){
>     printf("\n\n No Memory1!");
>     exit(1);
> }
>
>  temp2 = (int *)calloc(col,sizeof(int));
>  if(temp2 == NULL){
>        >printf("\n\n No Memory2!");
>        >exit(1);
>    }
>
>    temp3 = (int *)calloc(col,sizeof(int));
>    if(temp3 == NULL){
>        >printf("\n\n No Memory3!");
>        >exit(1);
>    }
>
>    temp4 = (int *)calloc(col,sizeof(int));
>    if(temp4 == NULL){
>        printf("\n\n No Memory4!");
>        exit(1);
>    }
>
>    int *cvector;
>    cvector = (int *)calloc(col,sizeof(int));
>    if(cvector == NULL){
>        printf("\n\n No Memory5!");
>        exit(1);
>    }
>
>    tam=ntam;
>
>    int **matrix;
>    matrix=(int**)calloc(row,sizeof(int*));
>    if(matrix == NULL){
>        printf("\n\n No Memory6!");
>        exit(1);
>    }
>
>    temp=(int*)calloc(tam,sizeof(int));
>    if(temp == NULL){
>        printf("\n\n No Memory7!");
>        exit(1);
>    }
>
>    iia = (int *)calloc(row-1,sizeof(int));
>    if(iia == NULL){
>        printf("\n\n No Memory8!");
>        exit(1);
>    }
>
>    iib = (int *)calloc(row-1,sizeof(int));
>    if(iib == NULL){
>        printf("\n\n No Memory9!");
>        exit(1);
>    }
> ############################################
> In output !
>> No Memory5!
>> [marcelo at cocada01 home] $
>
> What's wrong?
> Thanks!
>
> --
> Marcelo Damasceno de Melo
> Graduando em Ci?ncia da Computa??o
> Departamento de Tecnologia da Informa??o - TCI
> Universidade Federal de Alagoas - UFAL
> Macei? - Alagoas - Brasil
> Projeto CoCADa - Constru??o do Conhecimento por Agrupamento de dados
> +55 82 8801-2119
>
> 	[[alternative HTML version deleted]]
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From rkoenker at uiuc.edu  Thu Dec 29 21:07:19 2005
From: rkoenker at uiuc.edu (roger koenker)
Date: Thu, 29 Dec 2005 14:07:19 -0600
Subject: [Rd] 'sessionInfo()' instead of 'version'
References: <43B42B58.6010400@acm.org>
Message-ID: <7DB3F7A9-DC60-41D5-BC21-A0C264CEEDD1@uiuc.edu>


In a private response to Tony Plate's suggestion to replace version()
output with sessionInfo() in R-help requests,

> roger koenker wrote:
>> Thanks for this, it would seem useful to have version numbers for
>> the packages too?

and Tony replied,
>
> Sounds sensible to me!  If I were you I'd send a message to R-devel  
> suggesting this.  AFAIK, some changes to sessionInfo() are already  
> being considered, so this is a good time to suggest that.

So, for what it is worth....

Roger

PS  My notion is that it is sometimes useful to document the state of  
play
when a particular object was created, much like the recent thread on
date stamping of objects in R-help.

url:    www.econ.uiuc.edu/~roger            Roger Koenker
email    rkoenker at uiuc.edu            Department of Economics
vox:     217-333-4558                University of Illinois
fax:       217-244-6678                Champaign, IL 61820


From murdoch at stats.uwo.ca  Thu Dec 29 22:09:31 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 29 Dec 2005 16:09:31 -0500
Subject: [Rd] 'sessionInfo()' instead of 'version'
In-Reply-To: <7DB3F7A9-DC60-41D5-BC21-A0C264CEEDD1@uiuc.edu>
References: <43B42B58.6010400@acm.org>
	<7DB3F7A9-DC60-41D5-BC21-A0C264CEEDD1@uiuc.edu>
Message-ID: <43B4508B.2080209@stats.uwo.ca>

On 12/29/2005 3:07 PM, roger koenker wrote:
> In a private response to Tony Plate's suggestion to replace version()
> output with sessionInfo() in R-help requests,
> 
> 
>>roger koenker wrote:
>>
>>>Thanks for this, it would seem useful to have version numbers for
>>>the packages too?
> 
> 
> and Tony replied,
> 
>>Sounds sensible to me!  If I were you I'd send a message to R-devel  
>>suggesting this.  AFAIK, some changes to sessionInfo() are already  
>>being considered, so this is a good time to suggest that.
> 
> 
> So, for what it is worth....
> 
> Roger
> 
> PS  My notion is that it is sometimes useful to document the state of  
> play
> when a particular object was created, much like the recent thread on
> date stamping of objects in R-help.

I'm not sure what you're asking for.  This is what I see in R-patched; 
it's very similar to what 2.1.1 shows:

 > sessionInfo()
R version 2.2.1, 2005-12-27, i386-pc-mingw32

attached base packages:
[1] "splines"   "methods"   "stats"     "graphics"  "grDevices" "utils"
[7] "datasets"  "base"

other attached packages:
multtest survival
  "1.8.0"   "2.20"

There's no point showing the versions of base packages, because they 
match the R version.  What other information would you like to see?

So far the following reasonable suggestions have been made.  I forget 
where they were posted, so you may not have seen them:

  - the Subversion revision number, at least for non-released versions
  - the version number of the GUI, at least for OS X (where it changes 
independently of R).

Duncan Murdoch


From Micah_Altman at harvard.edu  Thu Dec 29 22:10:30 2005
From: Micah_Altman at harvard.edu (Micah_Altman@harvard.edu)
Date: Thu, 29 Dec 2005 22:10:30 +0100 (CET)
Subject: [Rd] Inconsistent IEEE 754/IEC 60559 rounding behavior (PR#8452)
Message-ID: <20051229211030.154B219A99@slim.kubism.ku.dk>

Full_Name: Micah Altman
Version: 2.2
OS: Windows/Linux (RHELv3)
Submission from: (NULL) (71.243.63.53)


Documentation for round()/signif() indicates that  IEC 60559 standard is used, 
"_go to the even digit_" is used for rounding off a 5. However, signif(),
round() and sprintf() do not behave consistently -- rounding using round()
follows this rule, signif() does not, and sprintf() follows the rule on Linux
but not on Windows(): 

> version
         _                      
platform x86_64-redhat-linux-gnu
arch     x86_64                 
os       linux-gnu              
system   x86_64, linux-gnu      
status                          
major    2                      
minor    2.0                    
year     2005                   
month    10                     
day      06                     
svn rev  35749                  
language R                      
> sessionInfo()
R version 2.2.0, 2005-10-06, x86_64-redhat-linux-gnu 

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets" 
[7] "base"    

> sprintf("%#.1g",as.double(0.25))
[1] "0.2"
> round(.25,digits=1)
[1] 0.2
> signif(.25,digits=1)   
[1] 0.3


> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    2              
minor    2.0            
year     2005           
month    10             
day      06             
svn rev  35749          
language R              
> sessionInfo()
R version 2.2.0, 2005-10-06, i386-pc-mingw32 

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets" 
"base"     
> sprintf("%#.1g",as.double(0.25))
[1] "0.3"
> round(.25,digits=1)
[1] 0.2
> signif(.25,digits=1) 
[1] 0.3
>


From maechler at stat.math.ethz.ch  Thu Dec 29 22:15:27 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 29 Dec 2005 22:15:27 +0100
Subject: [Rd] 'sessionInfo()' instead of 'version'
In-Reply-To: <7DB3F7A9-DC60-41D5-BC21-A0C264CEEDD1@uiuc.edu>
References: <43B42B58.6010400@acm.org>
	<7DB3F7A9-DC60-41D5-BC21-A0C264CEEDD1@uiuc.edu>
Message-ID: <17332.20975.207876.446224@stat.math.ethz.ch>

>>>>> "roger" == roger koenker <rkoenker at uiuc.edu>
>>>>>     on Thu, 29 Dec 2005 14:07:19 -0600 writes:

    roger> In a private response to Tony Plate's suggestion to
    roger> replace version() output with sessionInfo() in R-help
    roger> requests,

    >> roger koenker wrote:
    >>> Thanks for this, it would seem useful to have version
    >>> numbers for the packages too?

    roger> and Tony replied,
    >>  Sounds sensible to me!  If I were you I'd send a message
    >> to R-devel suggesting this.  AFAIK, some changes to
    >> sessionInfo() are already being considered, so this is a
    >> good time to suggest that.

    roger> So, for what it is worth....

but the version numbers of the non-standard packages are
*there* -- so what do you mean ?

  > sessionInfo()
  R version 2.2.1, 2005-12-20, x86_64-unknown-linux-gnu 

  attached base packages:
  [1] "graphics"  "grDevices" "datasets"  "utils"     "methods"   "stats"    
  [7] "base"     

  other attached packages:
   cluster fortunes  sfsmisc 
  "1.10.2"  "1.2-0" "0.95-2" 
  >


From rkoenker at uiuc.edu  Thu Dec 29 22:17:39 2005
From: rkoenker at uiuc.edu (roger koenker)
Date: Thu, 29 Dec 2005 15:17:39 -0600
Subject: [Rd] 'sessionInfo()' instead of 'version'
In-Reply-To: <43B4508B.2080209@stats.uwo.ca>
References: <43B42B58.6010400@acm.org>
	<7DB3F7A9-DC60-41D5-BC21-A0C264CEEDD1@uiuc.edu>
	<43B4508B.2080209@stats.uwo.ca>
Message-ID: <6523D671-A49F-46B3-A145-7A18CB60E8D5@uiuc.edu>

My fault,  what you show is exactly what I wanted...

url:    www.econ.uiuc.edu/~roger            Roger Koenker
email    rkoenker at uiuc.edu            Department of Economics
vox:     217-333-4558                University of Illinois
fax:       217-244-6678                Champaign, IL 61820


On Dec 29, 2005, at 3:09 PM, Duncan Murdoch wrote:

> On 12/29/2005 3:07 PM, roger koenker wrote:
>> In a private response to Tony Plate's suggestion to replace version()
>> output with sessionInfo() in R-help requests,
>>> roger koenker wrote:
>>>
>>>> Thanks for this, it would seem useful to have version numbers for
>>>> the packages too?
>> and Tony replied,
>>> Sounds sensible to me!  If I were you I'd send a message to R- 
>>> devel  suggesting this.  AFAIK, some changes to sessionInfo() are  
>>> already  being considered, so this is a good time to suggest that.
>> So, for what it is worth....
>> Roger
>> PS  My notion is that it is sometimes useful to document the state  
>> of  play
>> when a particular object was created, much like the recent thread on
>> date stamping of objects in R-help.
>
> I'm not sure what you're asking for.  This is what I see in R- 
> patched; it's very similar to what 2.1.1 shows:
>
> > sessionInfo()
> R version 2.2.1, 2005-12-27, i386-pc-mingw32
>
> attached base packages:
> [1] "splines"   "methods"   "stats"     "graphics"  "grDevices"  
> "utils"
> [7] "datasets"  "base"
>
> other attached packages:
> multtest survival
>  "1.8.0"   "2.20"
>
> There's no point showing the versions of base packages, because  
> they match the R version.  What other information would you like to  
> see?
>
> So far the following reasonable suggestions have been made.  I  
> forget where they were posted, so you may not have seen them:
>
>  - the Subversion revision number, at least for non-released versions
>  - the version number of the GUI, at least for OS X (where it  
> changes independently of R).
>
> Duncan Murdoch


From sfalcon at fhcrc.org  Thu Dec 29 23:13:48 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Thu, 29 Dec 2005 14:13:48 -0800
Subject: [Rd] 'sessionInfo()' instead of 'version'
In-Reply-To: <43B4508B.2080209@stats.uwo.ca> (Duncan Murdoch's message of "Thu,
	29 Dec 2005 16:09:31 -0500")
References: <43B42B58.6010400@acm.org>
	<7DB3F7A9-DC60-41D5-BC21-A0C264CEEDD1@uiuc.edu>
	<43B4508B.2080209@stats.uwo.ca>
Message-ID: <m2vex75z6r.fsf@fhcrc.org>

On 29 Dec 2005, murdoch at stats.uwo.ca wrote:
> So far the following reasonable suggestions have been made.  I
> forget where they were posted, so you may not have seen them:
>
> - the Subversion revision number, at least for non-released versions
> - the version number of the GUI, at least for OS X (where it changes
> independently of R).

Perhaps it doesn't count as reasonable, but another suggestion (made
by me) was:

 - Include output of loadedNamespaces().

+ seth


From murdoch at stats.uwo.ca  Thu Dec 29 23:55:00 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 29 Dec 2005 17:55:00 -0500
Subject: [Rd] 'sessionInfo()' instead of 'version'
In-Reply-To: <m2vex75z6r.fsf@fhcrc.org>
References: <43B42B58.6010400@acm.org>	<7DB3F7A9-DC60-41D5-BC21-A0C264CEEDD1@uiuc.edu>	<43B4508B.2080209@stats.uwo.ca>
	<m2vex75z6r.fsf@fhcrc.org>
Message-ID: <43B46944.4060203@stats.uwo.ca>

On 12/29/2005 5:13 PM, Seth Falcon wrote:
> On 29 Dec 2005, murdoch at stats.uwo.ca wrote:
> 
>>So far the following reasonable suggestions have been made.  I
>>forget where they were posted, so you may not have seen them:
>>
>>- the Subversion revision number, at least for non-released versions
>>- the version number of the GUI, at least for OS X (where it changes
>>independently of R).
> 
> 
> Perhaps it doesn't count as reasonable, but another suggestion (made
> by me) was:
> 
>  - Include output of loadedNamespaces().

I didn't see that one (or forgot I did), its omission wasn't an 
editorial judgement.

Duncan Murdoch


From winjohn at webone.com.au  Thu Dec 29 23:59:57 2005
From: winjohn at webone.com.au (winjohn@webone.com.au)
Date: Thu, 29 Dec 2005 23:59:57 +0100 (CET)
Subject: [Rd] 'last.warning' problem at startup; package Matrix (PR#8453)
Message-ID: <20051229225957.A710519A67@slim.kubism.ku.dk>

On starting an R session, I get the messages:

  Fatal errir: unable to restore save data in .RData

  Error in fun(...): couldn't find function "assignInNamespace"

  Error: .onLoad failed in 'loadNamespace' for 'Matrix'

The only object in my .RData is last.warning, thus:

  > last.warning
  $"optim or nlminb returned message false convergence (8)"
  "LMEoptimize<-"(`*tmp*`, value = list(maxIter = 200, tolerance = 
1.49011611938477e-08,
      msMaxIter = 200, msVerbose = 0, niterEM = 15, EMverbose = FALSE,
      PQLmaxIt = 30, analyticGradient = TRUE, analyticHessian = FALSE))

This was generated by a call, in a previous session,to lmer()
There may be a problem with the package Matrix, but it seems a bit
extreme that this prevents restoration of the session.

John Maindonald
john.maindonald at anu.edu.au

--please do not edit the information below--

Version:
 platform = i386-pc-mingw32
 arch = i386
 os = mingw32
 system = i386, mingw32
 status =
 major = 2
 minor = 2.1
 year = 2005
 month = 12
 day = 20
 svn rev = 36812
 language = R

Windows XP Home Edition (build 2600) Service Pack 2.0

Locale:
LC_COLLATE=English_Australia.1252;LC_CTYPE=English_Australia.1252;LC_MONETARY=English_Australia.1252;LC_NUMERIC=C;LC_TIME=English_Australia.1252

Search Path:
 .GlobalEnv, package:methods, package:stats, package:graphics, 
package:grDevices, package:utils, package:datasets, Autoloads, package:base


From ripley at stats.ox.ac.uk  Fri Dec 30 00:00:21 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 29 Dec 2005 23:00:21 +0000 (GMT)
Subject: [Rd] 'sessionInfo()' instead of 'version'
In-Reply-To: <m2vex75z6r.fsf@fhcrc.org>
References: <43B42B58.6010400@acm.org>
	<7DB3F7A9-DC60-41D5-BC21-A0C264CEEDD1@uiuc.edu>
	<43B4508B.2080209@stats.uwo.ca> <m2vex75z6r.fsf@fhcrc.org>
Message-ID: <Pine.LNX.4.61.0512292254060.4008@gannet.stats>

Are there known instances of this helping the diagnosis of a problem?

My impression is that more details of the OS/compilers used is the thing 
which is most commonly needed to help with remote diagnosis.

On Thu, 29 Dec 2005, Seth Falcon wrote:

> On 29 Dec 2005, murdoch at stats.uwo.ca wrote:
>> So far the following reasonable suggestions have been made.  I
>> forget where they were posted, so you may not have seen them:
>>
>> - the Subversion revision number, at least for non-released versions
>> - the version number of the GUI, at least for OS X (where it changes
>> independently of R).
>
> Perhaps it doesn't count as reasonable, but another suggestion (made
> by me) was:
>
> - Include output of loadedNamespaces().
>
> + seth
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Fri Dec 30 00:22:37 2005
From: ripley at stats.ox.ac.uk (ripley@stats.ox.ac.uk)
Date: Fri, 30 Dec 2005 00:22:37 +0100 (CET)
Subject: [Rd] 'last.warning' problem at startup; package Matrix (PR#8453)
Message-ID: <20051229232237.00E3019A67@slim.kubism.ku.dk>

This *is* a bug in package Matrix and yes, bugs in packages can be bad 
enough to stop a saved image (sic) being loaded.  You could have started R 
--no-restore and load()ed it later.

Matrix has several uses of assignInNamespace in .onLoad and .onUnload, and 
that is in package utils and so not necessarily loaded.  Try loading 
Matrix with R_DEFAULT_PACKAGES=NULL to reproduce this.

R-bugs was not the appropriate place to report this, as the FAQ makes 
quite clear.

On Thu, 29 Dec 2005 winjohn at webone.com.au wrote:

> On starting an R session, I get the messages:
>
>  Fatal errir: unable to restore save data in .RData
>
>  Error in fun(...): couldn't find function "assignInNamespace"
>
>  Error: .onLoad failed in 'loadNamespace' for 'Matrix'
>
> The only object in my .RData is last.warning, thus:
>
>  > last.warning
>  $"optim or nlminb returned message false convergence (8)"
>  "LMEoptimize<-"(`*tmp*`, value = list(maxIter = 200, tolerance =
> 1.49011611938477e-08,
>      msMaxIter = 200, msVerbose = 0, niterEM = 15, EMverbose = FALSE,
>      PQLmaxIt = 30, analyticGradient = TRUE, analyticHessian = FALSE))
>
> This was generated by a call, in a previous session,to lmer()
> There may be a problem with the package Matrix, but it seems a bit
> extreme that this prevents restoration of the session.
>
> John Maindonald
> john.maindonald at anu.edu.au
>
> --please do not edit the information below--
>
> Version:
> platform = i386-pc-mingw32
> arch = i386
> os = mingw32
> system = i386, mingw32
> status =
> major = 2
> minor = 2.1
> year = 2005
> month = 12
> day = 20
> svn rev = 36812
> language = R
>
> Windows XP Home Edition (build 2600) Service Pack 2.0
>
> Locale:
> LC_COLLATE=English_Australia.1252;LC_CTYPE=English_Australia.1252;LC_MONETARY=English_Australia.1252;LC_NUMERIC=C;LC_TIME=English_Australia.1252
>
> Search Path:
> .GlobalEnv, package:methods, package:stats, package:graphics,
> package:grDevices, package:utils, package:datasets, Autoloads, package:base
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jeff at kanecap.com  Fri Dec 30 06:15:00 2005
From: jeff at kanecap.com (Jeff Enos)
Date: Fri, 30 Dec 2005 00:15:00 -0500
Subject: [Rd] Acknowledgments in package documentation
Message-ID: <17332.49748.569499.536117@gargle.gargle.HOWL>

R-devel,

I've received permission from a third party to incorporate some of
their data in a data set in my 'portfolio' package.  I'd like to
include an acknowledgment of the third party, and perhaps a "used with
permission" somewhere in the package documentation.

Where's the best spot in the package docs for such an acknowledgment?
Is there a place preferable to the \description or \source sections of
the data set's .Rd file?

Thanks in advance,

Jeff


From ligges at statistik.uni-dortmund.de  Fri Dec 30 09:37:46 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 30 Dec 2005 09:37:46 +0100
Subject: [Rd] Acknowledgments in package documentation
In-Reply-To: <17332.49748.569499.536117@gargle.gargle.HOWL>
References: <17332.49748.569499.536117@gargle.gargle.HOWL>
Message-ID: <43B4F1DA.8040802@statistik.uni-dortmund.de>

Jeff Enos wrote:

> R-devel,
> 
> I've received permission from a third party to incorporate some of
> their data in a data set in my 'portfolio' package.  I'd like to
> include an acknowledgment of the third party, and perhaps a "used with
> permission" somewhere in the package documentation.
> 
> Where's the best spot in the package docs for such an acknowledgment?
> Is there a place preferable to the \description or \source sections of
> the data set's .Rd file?

No, that's perfect.

If for the data a special license applies different from the rest of the 
package, document it in thge License field of DESCRIPTION. You may also 
mention the other "author" in the DESCRIPTION file. All details on the 
author should go into the corresponding Rd file.

Uwe Ligges

> Thanks in advance,
> 
> Jeff
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From finle014 at umn.edu  Fri Dec 30 17:59:31 2005
From: finle014 at umn.edu (finle014)
Date: Fri, 30 Dec 2005 10:59:31 CST
Subject: [Rd] PROTECT SEXP in stl map
Message-ID: <200512301659.jBUGxV67032352@sarge.software.umn.edu>

Hello All,

Im sure this question is basic but Im just getting started with R/c++
calls.

I would like to use an standard template library (STL) map to organize some
SEXP types in my program.  The map is map<int, SEXP> paramMap.  To insert
values into the value portion of this map I make a call to the function
getListElement (as defined on page 52 in Writing R Extensions). So the
insert looks like:

paramMap.insert(pair<int,SEXP>( some int, getListElement( some args )));

This statement is set in a for loop so that several map elements are
inserted.  On insert the return from getListElement is copied.

My question is, do I need to somehow PROTECT the SEXP value portion of this
map?  Or this this not necessary?

Thanks-
Andy


From ggrothendieck at gmail.com  Sat Dec 31 04:10:53 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 30 Dec 2005 22:10:53 -0500
Subject: [Rd] xy.coords
Message-ID: <971536df0512301910k1e98e8e9pd4aa00149fedf1af@mail.gmail.com>

In ?xy.coords it says:

     If 'y' is missing and 'x' is a

     formula: of the form 'yvar ~ xvar'. 'xvar' and 'yvar' are used as
          x and y variables.

     list: containing components 'x' and 'y', these are used to define
          plotting coordinates.

     time series: the x values are taken to be 'time(x)' and the y
          values to be the time series.

     matrix with two columns: the first is assumed to contain the x
          values and the second the y values.

however, in fact, if y is missing an error is given. e.g.

x <- 1:3
y <- 4:6
xy.coords(y ~ x) # error
xy.coords(cbind(x, y)) # error
xy.coords(ts(y)) # error

Looking at the code, is.null(y) in the first line of the
body should be missing(y) .


From ellis at stat.harvard.edu  Sat Dec 31 06:37:16 2005
From: ellis at stat.harvard.edu (Byron Ellis)
Date: Fri, 30 Dec 2005 21:37:16 -0800
Subject: [Rd] reinventing the wheel....
In-Reply-To: <1abe3fa90512290437g6595c5e1pbca342caedff6a6c@mail.gmail.com>
References: <1abe3fa90512290437g6595c5e1pbca342caedff6a6c@mail.gmail.com>
Message-ID: <5B398E1B-EA67-4374-86E9-AAC720AA8A41@stat.harvard.edu>

Untrue! They may also become Smalltalk ;-)

On Dec 29, 2005, at 4:37 AM, A.J. Rossini wrote:

>> ---------- Forwarded message ----------
>> From: Byron Ellis <ellis at stat.harvard.edu>
>
>> If we wanted to be truly radical we'd just accept that graphics
>> devices and event loops are just special cases of the connection and
>> merge the whole thing, thus more-or-less reinventing CLIM. :-)
>
> Eventually, all programming languages grow up and become Lisp.
>
> (progress, progress, and more joyful progress on CLS).
>
> best,
> -tony
>
> blindglobe at gmail.com
> Muttenz, Switzerland.
> "Commit early,commit often, and commit in a repository from which  
> we can easily
> roll-back your mistakes" (AJR, 4Jan05).
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

---
Byron Ellis (ellis at stat.harvard.edu)
"Oook" -- The Librarian


From murdoch at stats.uwo.ca  Sat Dec 31 14:19:16 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 31 Dec 2005 08:19:16 -0500
Subject: [Rd] xy.coords
In-Reply-To: <971536df0512301910k1e98e8e9pd4aa00149fedf1af@mail.gmail.com>
References: <971536df0512301910k1e98e8e9pd4aa00149fedf1af@mail.gmail.com>
Message-ID: <43B68554.9030505@stats.uwo.ca>

On 12/30/2005 10:10 PM, Gabor Grothendieck wrote:
> In ?xy.coords it says:
> 
>      If 'y' is missing and 'x' is a
> 
>      formula: of the form 'yvar ~ xvar'. 'xvar' and 'yvar' are used as
>           x and y variables.
> 
>      list: containing components 'x' and 'y', these are used to define
>           plotting coordinates.
> 
>      time series: the x values are taken to be 'time(x)' and the y
>           values to be the time series.
> 
>      matrix with two columns: the first is assumed to contain the x
>           values and the second the y values.
> 
> however, in fact, if y is missing an error is given. e.g.
> 
> x <- 1:3
> y <- 4:6
> xy.coords(y ~ x) # error
> xy.coords(cbind(x, y)) # error
> xy.coords(ts(y)) # error
> 
> Looking at the code, is.null(y) in the first line of the
> body should be missing(y) .

It would be better to change the docs to say "if 'y' is NULL ...".  The 
code has been the way it is for years and years, and is widely used.

Changing the test to missing(y) would mean all existing uses that put a 
NULL there would need to be changed.

Adding a default value of NULL to y would have less impact, but I'd 
still be worried about it having long-range bad effects.

Duncan Murdoch


From ggrothendieck at gmail.com  Sat Dec 31 14:57:43 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 31 Dec 2005 08:57:43 -0500
Subject: [Rd] xy.coords
In-Reply-To: <43B68554.9030505@stats.uwo.ca>
References: <971536df0512301910k1e98e8e9pd4aa00149fedf1af@mail.gmail.com>
	<43B68554.9030505@stats.uwo.ca>
Message-ID: <971536df0512310557l1e3ea702ic9f4444b7583f4a7@mail.gmail.com>

It could be changed to missing(y) || is.null(y) and the docs amended.
That way existing code will continue to work and code that otherwise
gives an error currently, but should have worked, will now work too.

On 12/31/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 12/30/2005 10:10 PM, Gabor Grothendieck wrote:
> > In ?xy.coords it says:
> >
> >      If 'y' is missing and 'x' is a
> >
> >      formula: of the form 'yvar ~ xvar'. 'xvar' and 'yvar' are used as
> >           x and y variables.
> >
> >      list: containing components 'x' and 'y', these are used to define
> >           plotting coordinates.
> >
> >      time series: the x values are taken to be 'time(x)' and the y
> >           values to be the time series.
> >
> >      matrix with two columns: the first is assumed to contain the x
> >           values and the second the y values.
> >
> > however, in fact, if y is missing an error is given. e.g.
> >
> > x <- 1:3
> > y <- 4:6
> > xy.coords(y ~ x) # error
> > xy.coords(cbind(x, y)) # error
> > xy.coords(ts(y)) # error
> >
> > Looking at the code, is.null(y) in the first line of the
> > body should be missing(y) .
>
> It would be better to change the docs to say "if 'y' is NULL ...".  The
> code has been the way it is for years and years, and is widely used.
>
> Changing the test to missing(y) would mean all existing uses that put a
> NULL there would need to be changed.
>
> Adding a default value of NULL to y would have less impact, but I'd
> still be worried about it having long-range bad effects.
>
> Duncan Murdoch
>


From murdoch at stats.uwo.ca  Sat Dec 31 18:01:55 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 31 Dec 2005 12:01:55 -0500
Subject: [Rd] xy.coords
In-Reply-To: <971536df0512310557l1e3ea702ic9f4444b7583f4a7@mail.gmail.com>
References: <971536df0512301910k1e98e8e9pd4aa00149fedf1af@mail.gmail.com>	
	<43B68554.9030505@stats.uwo.ca>
	<971536df0512310557l1e3ea702ic9f4444b7583f4a7@mail.gmail.com>
Message-ID: <43B6B983.1060408@stats.uwo.ca>

On 12/31/2005 8:57 AM, Gabor Grothendieck wrote:
> It could be changed to missing(y) || is.null(y) and the docs amended.
> That way existing code will continue to work and code that otherwise
> gives an error currently, but should have worked, will now work too.

Can you give an example where you would want to use xy.coords(y ~ x)? 
Normally xy.coords() is used in other functions, and they can default y 
to NULL (see plot.default, for example).

Duncan Murdoch
> 
> On 12/31/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> 
>>On 12/30/2005 10:10 PM, Gabor Grothendieck wrote:
>>
>>>In ?xy.coords it says:
>>>
>>>     If 'y' is missing and 'x' is a
>>>
>>>     formula: of the form 'yvar ~ xvar'. 'xvar' and 'yvar' are used as
>>>          x and y variables.
>>>
>>>     list: containing components 'x' and 'y', these are used to define
>>>          plotting coordinates.
>>>
>>>     time series: the x values are taken to be 'time(x)' and the y
>>>          values to be the time series.
>>>
>>>     matrix with two columns: the first is assumed to contain the x
>>>          values and the second the y values.
>>>
>>>however, in fact, if y is missing an error is given. e.g.
>>>
>>>x <- 1:3
>>>y <- 4:6
>>>xy.coords(y ~ x) # error
>>>xy.coords(cbind(x, y)) # error
>>>xy.coords(ts(y)) # error
>>>
>>>Looking at the code, is.null(y) in the first line of the
>>>body should be missing(y) .
>>
>>It would be better to change the docs to say "if 'y' is NULL ...".  The
>>code has been the way it is for years and years, and is widely used.
>>
>>Changing the test to missing(y) would mean all existing uses that put a
>>NULL there would need to be changed.
>>
>>Adding a default value of NULL to y would have less impact, but I'd
>>still be worried about it having long-range bad effects.
>>
>>Duncan Murdoch
>>


From ggrothendieck at gmail.com  Sat Dec 31 18:21:17 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 31 Dec 2005 12:21:17 -0500
Subject: [Rd] xy.coords
In-Reply-To: <43B6B983.1060408@stats.uwo.ca>
References: <971536df0512301910k1e98e8e9pd4aa00149fedf1af@mail.gmail.com>
	<43B68554.9030505@stats.uwo.ca>
	<971536df0512310557l1e3ea702ic9f4444b7583f4a7@mail.gmail.com>
	<43B6B983.1060408@stats.uwo.ca>
Message-ID: <971536df0512310921g43f340e6ufec047b7c07f53da@mail.gmail.com>

I think the point is that (1) it does not work as documented and (2) in
most functions one can omit unnecessary args without having
to specify NULL so its behvaior seems inconsistent from a design
viewpoint.  By allowing either missing or NULL it will work as documented,
and probably intended, yet continue to be backward compatible with
existing usages.

On 12/31/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 12/31/2005 8:57 AM, Gabor Grothendieck wrote:
> > It could be changed to missing(y) || is.null(y) and the docs amended.
> > That way existing code will continue to work and code that otherwise
> > gives an error currently, but should have worked, will now work too.
>
> Can you give an example where you would want to use xy.coords(y ~ x)?
> Normally xy.coords() is used in other functions, and they can default y
> to NULL (see plot.default, for example).
>
> Duncan Murdoch
> >
> > On 12/31/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> >
> >>On 12/30/2005 10:10 PM, Gabor Grothendieck wrote:
> >>
> >>>In ?xy.coords it says:
> >>>
> >>>     If 'y' is missing and 'x' is a
> >>>
> >>>     formula: of the form 'yvar ~ xvar'. 'xvar' and 'yvar' are used as
> >>>          x and y variables.
> >>>
> >>>     list: containing components 'x' and 'y', these are used to define
> >>>          plotting coordinates.
> >>>
> >>>     time series: the x values are taken to be 'time(x)' and the y
> >>>          values to be the time series.
> >>>
> >>>     matrix with two columns: the first is assumed to contain the x
> >>>          values and the second the y values.
> >>>
> >>>however, in fact, if y is missing an error is given. e.g.
> >>>
> >>>x <- 1:3
> >>>y <- 4:6
> >>>xy.coords(y ~ x) # error
> >>>xy.coords(cbind(x, y)) # error
> >>>xy.coords(ts(y)) # error
> >>>
> >>>Looking at the code, is.null(y) in the first line of the
> >>>body should be missing(y) .
> >>
> >>It would be better to change the docs to say "if 'y' is NULL ...".  The
> >>code has been the way it is for years and years, and is widely used.
> >>
> >>Changing the test to missing(y) would mean all existing uses that put a
> >>NULL there would need to be changed.
> >>
> >>Adding a default value of NULL to y would have less impact, but I'd
> >>still be worried about it having long-range bad effects.
> >>
> >>Duncan Murdoch
> >>
>
>


From murdoch at stats.uwo.ca  Sat Dec 31 18:47:54 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 31 Dec 2005 12:47:54 -0500
Subject: [Rd] xy.coords
In-Reply-To: <971536df0512310921g43f340e6ufec047b7c07f53da@mail.gmail.com>
References: <971536df0512301910k1e98e8e9pd4aa00149fedf1af@mail.gmail.com>	
	<43B68554.9030505@stats.uwo.ca>	
	<971536df0512310557l1e3ea702ic9f4444b7583f4a7@mail.gmail.com>	
	<43B6B983.1060408@stats.uwo.ca>
	<971536df0512310921g43f340e6ufec047b7c07f53da@mail.gmail.com>
Message-ID: <43B6C44A.10103@stats.uwo.ca>

On 12/31/2005 12:21 PM, Gabor Grothendieck wrote:
> I think the point is that (1) it does not work as documented and (2) in
> most functions one can omit unnecessary args without having
> to specify NULL so its behvaior seems inconsistent from a design
> viewpoint.  By allowing either missing or NULL it will work as documented,
> and probably intended, yet continue to be backward compatible with
> existing usages.

But a simpler change is to change the documentation, and it achieves all 
of those objectives.

Duncan Murdoch
> 
> On 12/31/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> 
>>On 12/31/2005 8:57 AM, Gabor Grothendieck wrote:
>>
>>>It could be changed to missing(y) || is.null(y) and the docs amended.
>>>That way existing code will continue to work and code that otherwise
>>>gives an error currently, but should have worked, will now work too.
>>
>>Can you give an example where you would want to use xy.coords(y ~ x)?
>>Normally xy.coords() is used in other functions, and they can default y
>>to NULL (see plot.default, for example).
>>
>>Duncan Murdoch
>>
>>>On 12/31/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>>>
>>>
>>>>On 12/30/2005 10:10 PM, Gabor Grothendieck wrote:
>>>>
>>>>
>>>>>In ?xy.coords it says:
>>>>>
>>>>>    If 'y' is missing and 'x' is a
>>>>>
>>>>>    formula: of the form 'yvar ~ xvar'. 'xvar' and 'yvar' are used as
>>>>>         x and y variables.
>>>>>
>>>>>    list: containing components 'x' and 'y', these are used to define
>>>>>         plotting coordinates.
>>>>>
>>>>>    time series: the x values are taken to be 'time(x)' and the y
>>>>>         values to be the time series.
>>>>>
>>>>>    matrix with two columns: the first is assumed to contain the x
>>>>>         values and the second the y values.
>>>>>
>>>>>however, in fact, if y is missing an error is given. e.g.
>>>>>
>>>>>x <- 1:3
>>>>>y <- 4:6
>>>>>xy.coords(y ~ x) # error
>>>>>xy.coords(cbind(x, y)) # error
>>>>>xy.coords(ts(y)) # error
>>>>>
>>>>>Looking at the code, is.null(y) in the first line of the
>>>>>body should be missing(y) .
>>>>
>>>>It would be better to change the docs to say "if 'y' is NULL ...".  The
>>>>code has been the way it is for years and years, and is widely used.
>>>>
>>>>Changing the test to missing(y) would mean all existing uses that put a
>>>>NULL there would need to be changed.
>>>>
>>>>Adding a default value of NULL to y would have less impact, but I'd
>>>>still be worried about it having long-range bad effects.
>>>>
>>>>Duncan Murdoch
>>>>
>>
>>


From ggrothendieck at gmail.com  Sat Dec 31 18:57:14 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 31 Dec 2005 12:57:14 -0500
Subject: [Rd] xy.coords
In-Reply-To: <43B6C44A.10103@stats.uwo.ca>
References: <971536df0512301910k1e98e8e9pd4aa00149fedf1af@mail.gmail.com>
	<43B68554.9030505@stats.uwo.ca>
	<971536df0512310557l1e3ea702ic9f4444b7583f4a7@mail.gmail.com>
	<43B6B983.1060408@stats.uwo.ca>
	<971536df0512310921g43f340e6ufec047b7c07f53da@mail.gmail.com>
	<43B6C44A.10103@stats.uwo.ca>
Message-ID: <971536df0512310957y750d8eb7oa23f38aa39db647c@mail.gmail.com>

It does not achieve design consistency.  One would have to
specify NULL but that should not really be necessary.

On 12/31/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 12/31/2005 12:21 PM, Gabor Grothendieck wrote:
> > I think the point is that (1) it does not work as documented and (2) in
> > most functions one can omit unnecessary args without having
> > to specify NULL so its behvaior seems inconsistent from a design
> > viewpoint.  By allowing either missing or NULL it will work as documented,
> > and probably intended, yet continue to be backward compatible with
> > existing usages.
>
> But a simpler change is to change the documentation, and it achieves all
> of those objectives.
>
> Duncan Murdoch
> >
> > On 12/31/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> >
> >>On 12/31/2005 8:57 AM, Gabor Grothendieck wrote:
> >>
> >>>It could be changed to missing(y) || is.null(y) and the docs amended.
> >>>That way existing code will continue to work and code that otherwise
> >>>gives an error currently, but should have worked, will now work too.
> >>
> >>Can you give an example where you would want to use xy.coords(y ~ x)?
> >>Normally xy.coords() is used in other functions, and they can default y
> >>to NULL (see plot.default, for example).
> >>
> >>Duncan Murdoch
> >>
> >>>On 12/31/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> >>>
> >>>
> >>>>On 12/30/2005 10:10 PM, Gabor Grothendieck wrote:
> >>>>
> >>>>
> >>>>>In ?xy.coords it says:
> >>>>>
> >>>>>    If 'y' is missing and 'x' is a
> >>>>>
> >>>>>    formula: of the form 'yvar ~ xvar'. 'xvar' and 'yvar' are used as
> >>>>>         x and y variables.
> >>>>>
> >>>>>    list: containing components 'x' and 'y', these are used to define
> >>>>>         plotting coordinates.
> >>>>>
> >>>>>    time series: the x values are taken to be 'time(x)' and the y
> >>>>>         values to be the time series.
> >>>>>
> >>>>>    matrix with two columns: the first is assumed to contain the x
> >>>>>         values and the second the y values.
> >>>>>
> >>>>>however, in fact, if y is missing an error is given. e.g.
> >>>>>
> >>>>>x <- 1:3
> >>>>>y <- 4:6
> >>>>>xy.coords(y ~ x) # error
> >>>>>xy.coords(cbind(x, y)) # error
> >>>>>xy.coords(ts(y)) # error
> >>>>>
> >>>>>Looking at the code, is.null(y) in the first line of the
> >>>>>body should be missing(y) .
> >>>>
> >>>>It would be better to change the docs to say "if 'y' is NULL ...".  The
> >>>>code has been the way it is for years and years, and is widely used.
> >>>>
> >>>>Changing the test to missing(y) would mean all existing uses that put a
> >>>>NULL there would need to be changed.
> >>>>
> >>>>Adding a default value of NULL to y would have less impact, but I'd
> >>>>still be worried about it having long-range bad effects.
> >>>>
> >>>>Duncan Murdoch
> >>>>
> >>
> >>
>
>


From murdoch at stats.uwo.ca  Sat Dec 31 19:26:35 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 31 Dec 2005 13:26:35 -0500
Subject: [Rd] xy.coords
In-Reply-To: <971536df0512310957y750d8eb7oa23f38aa39db647c@mail.gmail.com>
References: <971536df0512301910k1e98e8e9pd4aa00149fedf1af@mail.gmail.com>	<43B68554.9030505@stats.uwo.ca>	<971536df0512310557l1e3ea702ic9f4444b7583f4a7@mail.gmail.com>	<43B6B983.1060408@stats.uwo.ca>	<971536df0512310921g43f340e6ufec047b7c07f53da@mail.gmail.com>	<43B6C44A.10103@stats.uwo.ca>
	<971536df0512310957y750d8eb7oa23f38aa39db647c@mail.gmail.com>
Message-ID: <43B6CD5B.4040307@stats.uwo.ca>

On 12/31/2005 12:57 PM, Gabor Grothendieck wrote:
> It does not achieve design consistency.  

It's consistent with the way it has been for at least 7 years, and is 
consistent with xyz.coords().

One would have to
> specify NULL but that should not really be necessary.

In fact, one almost never needs to specify NULL there.  It's the default 
value for y in the high level functions that call xy.coords, so it is 
put there automatically.

Duncan Murdoch

> 
> On 12/31/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> 
>>On 12/31/2005 12:21 PM, Gabor Grothendieck wrote:
>>
>>>I think the point is that (1) it does not work as documented and (2) in
>>>most functions one can omit unnecessary args without having
>>>to specify NULL so its behvaior seems inconsistent from a design
>>>viewpoint.  By allowing either missing or NULL it will work as documented,
>>>and probably intended, yet continue to be backward compatible with
>>>existing usages.
>>
>>But a simpler change is to change the documentation, and it achieves all
>>of those objectives.
>>
>>Duncan Murdoch
>>
>>>On 12/31/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>>>
>>>
>>>>On 12/31/2005 8:57 AM, Gabor Grothendieck wrote:
>>>>
>>>>
>>>>>It could be changed to missing(y) || is.null(y) and the docs amended.
>>>>>That way existing code will continue to work and code that otherwise
>>>>>gives an error currently, but should have worked, will now work too.
>>>>
>>>>Can you give an example where you would want to use xy.coords(y ~ x)?
>>>>Normally xy.coords() is used in other functions, and they can default y
>>>>to NULL (see plot.default, for example).
>>>>
>>>>Duncan Murdoch
>>>>
>>>>
>>>>>On 12/31/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>>>>>
>>>>>
>>>>>
>>>>>>On 12/30/2005 10:10 PM, Gabor Grothendieck wrote:
>>>>>>
>>>>>>
>>>>>>
>>>>>>>In ?xy.coords it says:
>>>>>>>
>>>>>>>   If 'y' is missing and 'x' is a
>>>>>>>
>>>>>>>   formula: of the form 'yvar ~ xvar'. 'xvar' and 'yvar' are used as
>>>>>>>        x and y variables.
>>>>>>>
>>>>>>>   list: containing components 'x' and 'y', these are used to define
>>>>>>>        plotting coordinates.
>>>>>>>
>>>>>>>   time series: the x values are taken to be 'time(x)' and the y
>>>>>>>        values to be the time series.
>>>>>>>
>>>>>>>   matrix with two columns: the first is assumed to contain the x
>>>>>>>        values and the second the y values.
>>>>>>>
>>>>>>>however, in fact, if y is missing an error is given. e.g.
>>>>>>>
>>>>>>>x <- 1:3
>>>>>>>y <- 4:6
>>>>>>>xy.coords(y ~ x) # error
>>>>>>>xy.coords(cbind(x, y)) # error
>>>>>>>xy.coords(ts(y)) # error
>>>>>>>
>>>>>>>Looking at the code, is.null(y) in the first line of the
>>>>>>>body should be missing(y) .
>>>>>>
>>>>>>It would be better to change the docs to say "if 'y' is NULL ...".  The
>>>>>>code has been the way it is for years and years, and is widely used.
>>>>>>
>>>>>>Changing the test to missing(y) would mean all existing uses that put a
>>>>>>NULL there would need to be changed.
>>>>>>
>>>>>>Adding a default value of NULL to y would have less impact, but I'd
>>>>>>still be worried about it having long-range bad effects.
>>>>>>
>>>>>>Duncan Murdoch
>>>>>>
>>>>
>>>>
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From pigood at verizon.net  Sat Dec 31 20:04:45 2005
From: pigood at verizon.net (Phillip Good)
Date: Sat, 31 Dec 2005 11:04:45 -0800
Subject: [Rd] Collaborator Wanted: permutation test package
Message-ID: <GHEKKACNLEADPKCNEEDFIEFJCHAA.pigood@verizon.net>

Recent simulation findings reveal that permutation tests are more powerful
than ANOV when data are drawn from non-normal populations such as mixtures
of normals or Weibull distributions.  I would like to offer my code in
package form and am looking for a collaborator who will:
  a. verify results
  b. simplify code where appropriate
  c. suggest option format for routines
  c. help me offer code in package form 

Phillip Good
Huntington Beach CA


From ggrothendieck at gmail.com  Sat Dec 31 21:26:21 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 31 Dec 2005 15:26:21 -0500
Subject: [Rd] xy.coords
In-Reply-To: <43B6CD5B.4040307@stats.uwo.ca>
References: <971536df0512301910k1e98e8e9pd4aa00149fedf1af@mail.gmail.com>
	<43B68554.9030505@stats.uwo.ca>
	<971536df0512310557l1e3ea702ic9f4444b7583f4a7@mail.gmail.com>
	<43B6B983.1060408@stats.uwo.ca>
	<971536df0512310921g43f340e6ufec047b7c07f53da@mail.gmail.com>
	<43B6C44A.10103@stats.uwo.ca>
	<971536df0512310957y750d8eb7oa23f38aa39db647c@mail.gmail.com>
	<43B6CD5B.4040307@stats.uwo.ca>
Message-ID: <971536df0512311226r1b9817a1q206bbe1a72a7d800@mail.gmail.com>

I think this is just playng with words.  The fact that its always been
like that is not sufficient and is not related to consistency.
xyz.coords also does not work in accordance with the help file
so the fact that the error extends to it just means they are both
in error.

Modularity means loose coupling -- i.e. a function should be
as independent as possible from its surroundings.  The fact
that the second argument is not missing in uses within R base
is not a valid argument for appropriate attention to this principle.

Furthermore, its clear that the current way it works is not even
the intended way -- the intended and better way is as documented
and the software, not the documentation, ought to be changed.


On 12/31/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 12/31/2005 12:57 PM, Gabor Grothendieck wrote:
> > It does not achieve design consistency.
>
> It's consistent with the way it has been for at least 7 years, and is
> consistent with xyz.coords().
>
> One would have to
> > specify NULL but that should not really be necessary.
>
> In fact, one almost never needs to specify NULL there.  It's the default
> value for y in the high level functions that call xy.coords, so it is
> put there automatically.
>
> Duncan Murdoch
>
> >
> > On 12/31/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> >
> >>On 12/31/2005 12:21 PM, Gabor Grothendieck wrote:
> >>
> >>>I think the point is that (1) it does not work as documented and (2) in
> >>>most functions one can omit unnecessary args without having
> >>>to specify NULL so its behvaior seems inconsistent from a design
> >>>viewpoint.  By allowing either missing or NULL it will work as documented,
> >>>and probably intended, yet continue to be backward compatible with
> >>>existing usages.
> >>
> >>But a simpler change is to change the documentation, and it achieves all
> >>of those objectives.
> >>
> >>Duncan Murdoch
> >>
> >>>On 12/31/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> >>>
> >>>
> >>>>On 12/31/2005 8:57 AM, Gabor Grothendieck wrote:
> >>>>
> >>>>
> >>>>>It could be changed to missing(y) || is.null(y) and the docs amended.
> >>>>>That way existing code will continue to work and code that otherwise
> >>>>>gives an error currently, but should have worked, will now work too.
> >>>>
> >>>>Can you give an example where you would want to use xy.coords(y ~ x)?
> >>>>Normally xy.coords() is used in other functions, and they can default y
> >>>>to NULL (see plot.default, for example).
> >>>>
> >>>>Duncan Murdoch
> >>>>
> >>>>
> >>>>>On 12/31/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> >>>>>
> >>>>>
> >>>>>
> >>>>>>On 12/30/2005 10:10 PM, Gabor Grothendieck wrote:
> >>>>>>
> >>>>>>
> >>>>>>
> >>>>>>>In ?xy.coords it says:
> >>>>>>>
> >>>>>>>   If 'y' is missing and 'x' is a
> >>>>>>>
> >>>>>>>   formula: of the form 'yvar ~ xvar'. 'xvar' and 'yvar' are used as
> >>>>>>>        x and y variables.
> >>>>>>>
> >>>>>>>   list: containing components 'x' and 'y', these are used to define
> >>>>>>>        plotting coordinates.
> >>>>>>>
> >>>>>>>   time series: the x values are taken to be 'time(x)' and the y
> >>>>>>>        values to be the time series.
> >>>>>>>
> >>>>>>>   matrix with two columns: the first is assumed to contain the x
> >>>>>>>        values and the second the y values.
> >>>>>>>
> >>>>>>>however, in fact, if y is missing an error is given. e.g.
> >>>>>>>
> >>>>>>>x <- 1:3
> >>>>>>>y <- 4:6
> >>>>>>>xy.coords(y ~ x) # error
> >>>>>>>xy.coords(cbind(x, y)) # error
> >>>>>>>xy.coords(ts(y)) # error
> >>>>>>>
> >>>>>>>Looking at the code, is.null(y) in the first line of the
> >>>>>>>body should be missing(y) .
> >>>>>>
> >>>>>>It would be better to change the docs to say "if 'y' is NULL ...".  The
> >>>>>>code has been the way it is for years and years, and is widely used.
> >>>>>>
> >>>>>>Changing the test to missing(y) would mean all existing uses that put a
> >>>>>>NULL there would need to be changed.
> >>>>>>
> >>>>>>Adding a default value of NULL to y would have less impact, but I'd
> >>>>>>still be worried about it having long-range bad effects.
> >>>>>>
> >>>>>>Duncan Murdoch
> >>>>>>
> >>>>
> >>>>
> >>
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From murdoch at stats.uwo.ca  Sat Dec 31 21:39:28 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 31 Dec 2005 15:39:28 -0500
Subject: [Rd] xy.coords
In-Reply-To: <971536df0512311226r1b9817a1q206bbe1a72a7d800@mail.gmail.com>
References: <971536df0512301910k1e98e8e9pd4aa00149fedf1af@mail.gmail.com>	<43B68554.9030505@stats.uwo.ca>	<971536df0512310557l1e3ea702ic9f4444b7583f4a7@mail.gmail.com>	<43B6B983.1060408@stats.uwo.ca>	<971536df0512310921g43f340e6ufec047b7c07f53da@mail.gmail.com>	<43B6C44A.10103@stats.uwo.ca>	<971536df0512310957y750d8eb7oa23f38aa39db647c@mail.gmail.com>	<43B6CD5B.4040307@stats.uwo.ca>
	<971536df0512311226r1b9817a1q206bbe1a72a7d800@mail.gmail.com>
Message-ID: <43B6EC80.7080202@stats.uwo.ca>

On 12/31/2005 3:26 PM, Gabor Grothendieck wrote:
> I think this is just playng with words.  

I'm starting to be convinced of that by the fact that you haven't posted 
any sample code where using a single parameter would be desirable.

The fact that its always been
> like that is not sufficient and is not related to consistency.
> xyz.coords also does not work in accordance with the help file
> so the fact that the error extends to it just means they are both
> in error.

> 
> Modularity means loose coupling -- i.e. a function should be
> as independent as possible from its surroundings.  The fact
> that the second argument is not missing in uses within R base
> is not a valid argument for appropriate attention to this principle.
> 
> Furthermore, its clear that the current way it works is not even
> the intended way -- the intended and better way is as documented
> and the software, not the documentation, ought to be changed.

Take a look at the examples.  It's pretty clear that it is working as 
intended, and the documentation incorrectly says "missing" where it 
means "NULL".

Duncan Murdoch
> 
> 
> On 12/31/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> 
>>On 12/31/2005 12:57 PM, Gabor Grothendieck wrote:
>>
>>>It does not achieve design consistency.
>>
>>It's consistent with the way it has been for at least 7 years, and is
>>consistent with xyz.coords().
>>
>>One would have to
>>
>>>specify NULL but that should not really be necessary.
>>
>>In fact, one almost never needs to specify NULL there.  It's the default
>>value for y in the high level functions that call xy.coords, so it is
>>put there automatically.
>>
>>Duncan Murdoch
>>
>>
>>>On 12/31/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>>>
>>>
>>>>On 12/31/2005 12:21 PM, Gabor Grothendieck wrote:
>>>>
>>>>
>>>>>I think the point is that (1) it does not work as documented and (2) in
>>>>>most functions one can omit unnecessary args without having
>>>>>to specify NULL so its behvaior seems inconsistent from a design
>>>>>viewpoint.  By allowing either missing or NULL it will work as documented,
>>>>>and probably intended, yet continue to be backward compatible with
>>>>>existing usages.
>>>>
>>>>But a simpler change is to change the documentation, and it achieves all
>>>>of those objectives.
>>>>
>>>>Duncan Murdoch
>>>>
>>>>
>>>>>On 12/31/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>>>>>
>>>>>
>>>>>
>>>>>>On 12/31/2005 8:57 AM, Gabor Grothendieck wrote:
>>>>>>
>>>>>>
>>>>>>
>>>>>>>It could be changed to missing(y) || is.null(y) and the docs amended.
>>>>>>>That way existing code will continue to work and code that otherwise
>>>>>>>gives an error currently, but should have worked, will now work too.
>>>>>>
>>>>>>Can you give an example where you would want to use xy.coords(y ~ x)?
>>>>>>Normally xy.coords() is used in other functions, and they can default y
>>>>>>to NULL (see plot.default, for example).
>>>>>>
>>>>>>Duncan Murdoch
>>>>>>
>>>>>>
>>>>>>
>>>>>>>On 12/31/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>>On 12/30/2005 10:10 PM, Gabor Grothendieck wrote:
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>>In ?xy.coords it says:
>>>>>>>>>
>>>>>>>>>  If 'y' is missing and 'x' is a
>>>>>>>>>
>>>>>>>>>  formula: of the form 'yvar ~ xvar'. 'xvar' and 'yvar' are used as
>>>>>>>>>       x and y variables.
>>>>>>>>>
>>>>>>>>>  list: containing components 'x' and 'y', these are used to define
>>>>>>>>>       plotting coordinates.
>>>>>>>>>
>>>>>>>>>  time series: the x values are taken to be 'time(x)' and the y
>>>>>>>>>       values to be the time series.
>>>>>>>>>
>>>>>>>>>  matrix with two columns: the first is assumed to contain the x
>>>>>>>>>       values and the second the y values.
>>>>>>>>>
>>>>>>>>>however, in fact, if y is missing an error is given. e.g.
>>>>>>>>>
>>>>>>>>>x <- 1:3
>>>>>>>>>y <- 4:6
>>>>>>>>>xy.coords(y ~ x) # error
>>>>>>>>>xy.coords(cbind(x, y)) # error
>>>>>>>>>xy.coords(ts(y)) # error
>>>>>>>>>
>>>>>>>>>Looking at the code, is.null(y) in the first line of the
>>>>>>>>>body should be missing(y) .
>>>>>>>>
>>>>>>>>It would be better to change the docs to say "if 'y' is NULL ...".  The
>>>>>>>>code has been the way it is for years and years, and is widely used.
>>>>>>>>
>>>>>>>>Changing the test to missing(y) would mean all existing uses that put a
>>>>>>>>NULL there would need to be changed.
>>>>>>>>
>>>>>>>>Adding a default value of NULL to y would have less impact, but I'd
>>>>>>>>still be worried about it having long-range bad effects.
>>>>>>>>
>>>>>>>>Duncan Murdoch
>>>>>>>>
>>>>>>
>>>>>>
>>>______________________________________________
>>>R-devel at r-project.org mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ggrothendieck at gmail.com  Sat Dec 31 21:59:05 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 31 Dec 2005 15:59:05 -0500
Subject: [Rd] New R folder names bring out Windows batch file bug
Message-ID: <971536df0512311259k1afaf23td65b6b942b4172bb@mail.gmail.com>

Just wanted to point out to anyone trying to write Windows
batch files that the new R-whatever folder names bring out
a bug in Windows batch files related to short file names.

In particular, this code (which is to the best of my understanding,
valid) gives an error. The solution appears to be to use long file
names, and make sure you quote them, rather than short ones.
That does require that R be able to handle such long names and
I think R does, in fact, handle them but at one time it did not in
all cases so use of short file names is likely just a workaround
from older times.  This does not affect R itself as far as I know
but did affect my batchfiles which I have revised.  I am using
Windows XP.

   C:\>set apath=\Program Files\R\R-2.2.1
   C:\>for /f "delims=" %a in ("%apath%") do set AA=%~sa
   C:\>set aa
   AA=C:\PROGRA~1\R\R-22~1.1.2.1
   C:\>cd %aa%
   The system cannot find the path specified.


From murdoch at stats.uwo.ca  Sat Dec 31 22:06:16 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 31 Dec 2005 16:06:16 -0500
Subject: [Rd] New R folder names bring out Windows batch file bug
In-Reply-To: <971536df0512311259k1afaf23td65b6b942b4172bb@mail.gmail.com>
References: <971536df0512311259k1afaf23td65b6b942b4172bb@mail.gmail.com>
Message-ID: <43B6F2C8.9020301@stats.uwo.ca>

On 12/31/2005 3:59 PM, Gabor Grothendieck wrote:
> Just wanted to point out to anyone trying to write Windows
> batch files that the new R-whatever folder names bring out
> a bug in Windows batch files related to short file names.
> 
> In particular, this code (which is to the best of my understanding,
> valid) gives an error. The solution appears to be to use long file
> names, and make sure you quote them, rather than short ones.
> That does require that R be able to handle such long names and
> I think R does, in fact, handle them but at one time it did not in
> all cases so use of short file names is likely just a workaround
> from older times.  This does not affect R itself as far as I know
> but did affect my batchfiles which I have revised.  I am using
> Windows XP.
> 
>    C:\>set apath=\Program Files\R\R-2.2.1
>    C:\>for /f "delims=" %a in ("%apath%") do set AA=%~sa
>    C:\>set aa
>    AA=C:\PROGRA~1\R\R-22~1.1.2.1
>    C:\>cd %aa%
>    The system cannot find the path specified.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

Please let us know Microsoft's response to your bug report.

Duncan Murdoch


From ggrothendieck at gmail.com  Sat Dec 31 22:09:01 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 31 Dec 2005 16:09:01 -0500
Subject: [Rd] xy.coords
In-Reply-To: <43B6EC80.7080202@stats.uwo.ca>
References: <971536df0512301910k1e98e8e9pd4aa00149fedf1af@mail.gmail.com>
	<43B68554.9030505@stats.uwo.ca>
	<971536df0512310557l1e3ea702ic9f4444b7583f4a7@mail.gmail.com>
	<43B6B983.1060408@stats.uwo.ca>
	<971536df0512310921g43f340e6ufec047b7c07f53da@mail.gmail.com>
	<43B6C44A.10103@stats.uwo.ca>
	<971536df0512310957y750d8eb7oa23f38aa39db647c@mail.gmail.com>
	<43B6CD5B.4040307@stats.uwo.ca>
	<971536df0512311226r1b9817a1q206bbe1a72a7d800@mail.gmail.com>
	<43B6EC80.7080202@stats.uwo.ca>
Message-ID: <971536df0512311309v1d39103am90f10759932e509c@mail.gmail.com>

On 12/31/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 12/31/2005 3:26 PM, Gabor Grothendieck wrote:
> > I think this is just playng with words.
>
> I'm starting to be convinced of that by the fact that you haven't posted
> any sample code where using a single parameter would be desirable.

Loose coupling is a general principle that should be followed as a matter
of course and does not need case by case justification.  If there were
a performance issue, say, one might justify circumventing
otherwise desirable principles but there is no conflicting tradeoff here.


>
> The fact that its always been
> > like that is not sufficient and is not related to consistency.
> > xyz.coords also does not work in accordance with the help file
> > so the fact that the error extends to it just means they are both
> > in error.
>
> >
> > Modularity means loose coupling -- i.e. a function should be
> > as independent as possible from its surroundings.  The fact
> > that the second argument is not missing in uses within R base
> > is not a valid argument for appropriate attention to this principle.
> >
> > Furthermore, its clear that the current way it works is not even
> > the intended way -- the intended and better way is as documented
> > and the software, not the documentation, ought to be changed.
>
> Take a look at the examples.  It's pretty clear that it is working as
> intended, and the documentation incorrectly says "missing" where it
> means "NULL".
>
> Duncan Murdoch
> >
> >
> > On 12/31/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> >
> >>On 12/31/2005 12:57 PM, Gabor Grothendieck wrote:
> >>
> >>>It does not achieve design consistency.
> >>
> >>It's consistent with the way it has been for at least 7 years, and is
> >>consistent with xyz.coords().
> >>
> >>One would have to
> >>
> >>>specify NULL but that should not really be necessary.
> >>
> >>In fact, one almost never needs to specify NULL there.  It's the default
> >>value for y in the high level functions that call xy.coords, so it is
> >>put there automatically.
> >>
> >>Duncan Murdoch
> >>
> >>
> >>>On 12/31/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> >>>
> >>>
> >>>>On 12/31/2005 12:21 PM, Gabor Grothendieck wrote:
> >>>>
> >>>>
> >>>>>I think the point is that (1) it does not work as documented and (2) in
> >>>>>most functions one can omit unnecessary args without having
> >>>>>to specify NULL so its behvaior seems inconsistent from a design
> >>>>>viewpoint.  By allowing either missing or NULL it will work as documented,
> >>>>>and probably intended, yet continue to be backward compatible with
> >>>>>existing usages.
> >>>>
> >>>>But a simpler change is to change the documentation, and it achieves all
> >>>>of those objectives.
> >>>>
> >>>>Duncan Murdoch
> >>>>
> >>>>
> >>>>>On 12/31/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> >>>>>
> >>>>>
> >>>>>
> >>>>>>On 12/31/2005 8:57 AM, Gabor Grothendieck wrote:
> >>>>>>
> >>>>>>
> >>>>>>
> >>>>>>>It could be changed to missing(y) || is.null(y) and the docs amended.
> >>>>>>>That way existing code will continue to work and code that otherwise
> >>>>>>>gives an error currently, but should have worked, will now work too.
> >>>>>>
> >>>>>>Can you give an example where you would want to use xy.coords(y ~ x)?
> >>>>>>Normally xy.coords() is used in other functions, and they can default y
> >>>>>>to NULL (see plot.default, for example).
> >>>>>>
> >>>>>>Duncan Murdoch
> >>>>>>
> >>>>>>
> >>>>>>
> >>>>>>>On 12/31/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>>On 12/30/2005 10:10 PM, Gabor Grothendieck wrote:
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>>In ?xy.coords it says:
> >>>>>>>>>
> >>>>>>>>>  If 'y' is missing and 'x' is a
> >>>>>>>>>
> >>>>>>>>>  formula: of the form 'yvar ~ xvar'. 'xvar' and 'yvar' are used as
> >>>>>>>>>       x and y variables.
> >>>>>>>>>
> >>>>>>>>>  list: containing components 'x' and 'y', these are used to define
> >>>>>>>>>       plotting coordinates.
> >>>>>>>>>
> >>>>>>>>>  time series: the x values are taken to be 'time(x)' and the y
> >>>>>>>>>       values to be the time series.
> >>>>>>>>>
> >>>>>>>>>  matrix with two columns: the first is assumed to contain the x
> >>>>>>>>>       values and the second the y values.
> >>>>>>>>>
> >>>>>>>>>however, in fact, if y is missing an error is given. e.g.
> >>>>>>>>>
> >>>>>>>>>x <- 1:3
> >>>>>>>>>y <- 4:6
> >>>>>>>>>xy.coords(y ~ x) # error
> >>>>>>>>>xy.coords(cbind(x, y)) # error
> >>>>>>>>>xy.coords(ts(y)) # error
> >>>>>>>>>
> >>>>>>>>>Looking at the code, is.null(y) in the first line of the
> >>>>>>>>>body should be missing(y) .
> >>>>>>>>
> >>>>>>>>It would be better to change the docs to say "if 'y' is NULL ...".  The
> >>>>>>>>code has been the way it is for years and years, and is widely used.
> >>>>>>>>
> >>>>>>>>Changing the test to missing(y) would mean all existing uses that put a
> >>>>>>>>NULL there would need to be changed.
> >>>>>>>>
> >>>>>>>>Adding a default value of NULL to y would have less impact, but I'd
> >>>>>>>>still be worried about it having long-range bad effects.
> >>>>>>>>
> >>>>>>>>Duncan Murdoch
> >>>>>>>>
> >>>>>>
> >>>>>>
> >>>______________________________________________
> >>>R-devel at r-project.org mailing list
> >>>https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >>
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From ggrothendieck at gmail.com  Sat Dec 31 22:12:27 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 31 Dec 2005 16:12:27 -0500
Subject: [Rd] New R folder names bring out Windows batch file bug
In-Reply-To: <43B6F2C8.9020301@stats.uwo.ca>
References: <971536df0512311259k1afaf23td65b6b942b4172bb@mail.gmail.com>
	<43B6F2C8.9020301@stats.uwo.ca>
Message-ID: <971536df0512311312k260cfc94t9e55737ec3f5f3ab@mail.gmail.com>

Although I independently discovered this bug; its apparently
well known to the experts.  I asked about it on the batch
newsgroup and those knowledgable on this immediately identified
it as such.  I think all one can do is work around it.

On 12/31/05, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 12/31/2005 3:59 PM, Gabor Grothendieck wrote:
> > Just wanted to point out to anyone trying to write Windows
> > batch files that the new R-whatever folder names bring out
> > a bug in Windows batch files related to short file names.
> >
> > In particular, this code (which is to the best of my understanding,
> > valid) gives an error. The solution appears to be to use long file
> > names, and make sure you quote them, rather than short ones.
> > That does require that R be able to handle such long names and
> > I think R does, in fact, handle them but at one time it did not in
> > all cases so use of short file names is likely just a workaround
> > from older times.  This does not affect R itself as far as I know
> > but did affect my batchfiles which I have revised.  I am using
> > Windows XP.
> >
> >    C:\>set apath=\Program Files\R\R-2.2.1
> >    C:\>for /f "delims=" %a in ("%apath%") do set AA=%~sa
> >    C:\>set aa
> >    AA=C:\PROGRA~1\R\R-22~1.1.2.1
> >    C:\>cd %aa%
> >    The system cannot find the path specified.
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> Please let us know Microsoft's response to your bug report.
>
> Duncan Murdoch
>


