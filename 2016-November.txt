From jeroen.ooms at stat.ucla.edu  Tue Nov  1 12:45:25 2016
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Tue, 1 Nov 2016 12:45:25 +0100
Subject: [Rd] Support for signing R packages with GPG
In-Reply-To: <1477416100.16944.377.camel@iarc.fr>
References: <CABFfbXv=ERj+1atPDP_6ZjYE9xi6r+CVEk4sEqHjSMEZz21Qbw@mail.gmail.com>
	<1477416100.16944.377.camel@iarc.fr>
Message-ID: <CABFfbXvF8YLdoumOH66cowRdEfVz+Pkq1=_oZ3FD6VzasfA9+Q@mail.gmail.com>

On Tue, Oct 25, 2016 at 7:22 PM, Martyn Plummer <plummerm at iarc.fr> wrote:
> Thanks Jeroen. The R Foundation has recently formed a working group to
> look into package authentication. There are basically two models. One
> is the GPG based model you describe; the other is to use X.509 as
> implemented in the PKI package. It's not yet clear which way to go but
> we are thinking about it.

I look forward to hearing what the working group comes up with. I
suppose if you go with x509, CRAN is going to perform CA duties?

Let me know if I can help with implementation, either via gpg or x509.
I am actively developing the openssl package which includes many more
x509 utilities, supporting all common key types (dsa, rsa, ec),
certificate bundles, ssl, etc. The main difference with PKI is that
openssl uses the native pem/der parsers from libssl which are more
robust and also recognize the less common formats, so that we don't
have to deal with parsing/decoding ASN.1 in R.

I will be happy to adapt/extend it further to fit the needs of the
workgroup and help this move forward.


From henrik.bengtsson at gmail.com  Tue Nov  1 19:29:31 2016
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Tue, 1 Nov 2016 11:29:31 -0700
Subject: [Rd] BUG?: On Linux setTimeLimit() fails to propagate timeout
 error when it occurs (works on Windows)
In-Reply-To: <alpine.OSX.2.20.1610311132070.4633@lukes-macbook-air.local>
References: <CAFDcVCStodbQMS4TffimW69qvVutCX8FheDNxf1o_Ejpmu9NQg@mail.gmail.com>
	<8995051E-628D-4536-A64C-517A9188F416@xs4all.nl>
	<CAFDcVCQmAAq_GYB5WUE2O25RkzCCpeMudJwQ3pCucp5MATAkXw@mail.gmail.com>
	<57E7E96A-D3F9-42F4-877D-56109CD38CC8@gmail.com>
	<alpine.DEB.2.20.1610271113550.2355@luke-Latitude>
	<CAFDcVCQ7QyNs2ZJ8YxEyHZHmX3iOcDEV0SbydptchSBJFt5sHA@mail.gmail.com>
	<alpine.OSX.2.20.1610311132070.4633@lukes-macbook-air.local>
Message-ID: <CAFDcVCSwmopxdsnmxSLWp3pB=-_U9ofrM16+8UNKr9noXaHeSg@mail.gmail.com>

On Mon, Oct 31, 2016 at 9:36 AM,  <luke-tierney at uiowa.edu> wrote:
> On Mon, 31 Oct 2016, Henrik Bengtsson wrote:
>
>> Thank you for looking into this Luke.
>>
>> On Thu, Oct 27, 2016 at 9:26 AM,  <luke-tierney at uiowa.edu> wrote:
>>>
>>> On unix, unless event polling is enabled Sys.sleep just waits in a
>>> select() call (with a SIGINT handler in place) so the elapsed time
>>> isn't checked until after the select call is complete. Rstudio uses
>>> event polling, and in particular sets R_wait_usec to 10000, which
>>> means event and interrupt checks happen during a Sys.seep call.  The R
>>> GUI on macOS doesn't seem to do this (but my lldb skills aren't up to
>>> checking). Now that we have this elapsed time limit mechanism it might
>>> be a good idea to set the default for R_wait_usec to something
>>> reasonable on unix in general. 100000 might be a good value.
>>>
>>
>>> A more worrying thing I noticed while looking at this is that blocking
>>> reads on fifos and pipes and probably sockets are not interruptable --
>>> that should probably be looked into.
>
>
> I'll address the sleep issue sometime soon but I won't be able to look
> into the blocking read issue for many months. SOmeone else might have
> a chance to look earlier.

Thanks.

So, if I understand it correctly, my example showing that
setTimeLimit() doesn't work properly on Linux was unfortunately
misleading, mainly due to me choosing Sys.sleep() and it does indeed
work in most cases (except connections).  For example, this works

slowfcn <- function(time) { t0 <- Sys.time(); while(Sys.time() - t0 <
time) Sys.sleep(0.1); TRUE }
setTimeLimit(elapsed = 1.0)
system.time(slowfcn(3))
## Error in Sys.sleep(0.1) : reached elapsed time limit
## Timing stopped at: 0.004 0 1.008

> But for the situation you describe below using setTimeLimit doesn't
> seem like the right approach. The parallel code is not written for
> situations that need this kind of fault tolerance; it is not robust to
> user interrupts and would not be to timer interrupts either. If you
> are concerned that some potential workers might not be available then
> you would be better checking that with a ping or simple ssh commend
> first before starting a cluster on the available nodes.

Yes, true. I didn't want to sidetrack the discussion too much, but
I've started to make some standalone improvements based on
parallel:::newPSOCKnode() & parallel:::.slaveRSOCK(), e.g. more
control options for launching remote workers, say, over SSH with
reverse tunneling (no need for port forwarding) and then running
Rscript within a Docker container, e.g.

https://github.com/HenrikBengtsson/future/blob/develop/R/makeClusterPSOCK.R
https://github.com/HenrikBengtsson/future/blob/develop/incl/makeClusterPSOCK.R

This part is fully backward compatible with makePSOCKcluster() and
could be eventually be implemented in parallel itself.  The next level
up could be to make the worker loop to handle connection-setup
timeouts and similar.

By now I'm fairly ok with testing and validating remote SSH access
etc, but I think it's possible to make exception handling a little bit
more automatic and informative, particularly the part detecting when
the connection and worker setup actually never happens.  For a
newcomer, it can be quite a challenge to troubleshoot why the setup of
remote workers doesn't work.

Thanks,

Henrik

>
> Best,
>
> luke
>
>
>>
>> This is actually related to the use case where I want to use
>> setTimeLimit().  When using parallel:::newPSOCKnode(), there's a
>> 30-day timeout associated with the socket connection.  Now, this long
>> timeout is needed in order for long-running tasks to not to timeout
>> the master-worker connection.   However, when it comes to the actual
>> setup of the connection, then it would be able to detect connection
>> issues earlier than that.  For example, if the socket connection
>> cannot be established within 60 seconds, then it is very likely that
>> the worker machine couldn't be reached, especially for connecting to
>> remote machines over SSH.
>>
>> The current code of parallel:::newPSOCKnode() basically does:
>>
>> system("ssh remote.server.org Rscript -e <launch worker and connect
>> back>", wait = FALSE)
>> con <- socketConnection("localhost", port = 11000, server = TRUE,
>> blocking = TRUE, open = "a+b", timeout = 30*24*60*60)
>>
>> If the remote SSH system call fails to reach or set up the worker, the
>> following call to socketConnection() will sit there and wait for 30
>> days.  Ideally one could solve this as:
>>
>> system("ssh remote.server.org Rscript -e <launch worker and connect
>> back>", wait = FALSE)
>> setTimeLimit(elapsed=60)
>> con <- socketConnection("localhost", port = 11000, server = TRUE,
>> blocking = TRUE, open = "a+b", timeout = 30*24*60*60)
>>
>> Thanks,
>>
>> Henrik
>>
>>>
>>> Best,
>>>
>>> luke
>>>
>>>
>>> On Wed, 26 Oct 2016, peter dalgaard wrote:
>>>
>>>> Spencer also had tools and rsconnect loaded (via a namespace) but it
>>>> doesn't seem to make a difference for me if I load them. It also doesn't
>>>> seem to matter for me whether it is CRAN R, locally built R, Terminal,
>>>> R.app. However, RStudio differs
>>>>
>>>>> setTimeLimit(elapsed=1)
>>>>
>>>>
>>>> Error: reached elapsed time limit
>>>>>
>>>>>
>>>>> setTimeLimit(elapsed=1)
>>>>
>>>>
>>>> Error: reached elapsed time limit
>>>>>
>>>>>
>>>>> setTimeLimit(elapsed=1); system.time({Sys.sleep(10);message("done")})
>>>>
>>>>
>>>> Error in Sys.sleep(10) : reached elapsed time limit
>>>> Timing stopped at: 0.003 0.003 0.733
>>>>
>>>> -pd
>>>>
>>>>
>>>>> On 26 Oct 2016, at 21:54 , Henrik Bengtsson
>>>>> <henrik.bengtsson at gmail.com>
>>>>> wrote:
>>>>>
>>>>> Thank you for the feedback and confirmations.  Interesting to see that
>>>>> it's also reproducible on macOS expect for Spencer; that might
>>>>> indicate a difference in builds.
>>>>>
>>>>> BTW, my original post suggested that timeout error was for sure
>>>>> detected while running Sys.sleep(10).  However, it could of course
>>>>> also be that it is only detected after it finishes.
>>>>>
>>>>>
>>>>> For troubleshooting, the help("setTimeLimit", package = "base") says
>>>>> that:
>>>>>
>>>>> * "Time limits are checked whenever a user interrupt could occur. This
>>>>> will happen frequently in R code and during Sys.sleep, but only at
>>>>> points in compiled C and Fortran code identified by the code author."
>>>>>
>>>>> The example here uses Sys.sleep(), which supports and detects user
>>>>> interrupts.
>>>>>
>>>>>
>>>>> The timeout error message is thrown by the R_ProcessEvents(void)
>>>>> function as defined in:
>>>>>
>>>>> * src/unix/sys-unix.c
>>>>>
>>>>>
>>>>> (https://github.com/wch/r-source/blob/trunk/src/unix/sys-unix.c#L421-L453)
>>>>> * src/gnuwin32/system.c
>>>>>
>>>>>
>>>>> (https://github.com/wch/r-source/blob/trunk/src/gnuwin32/system.c#L110-L140)
>>>>>
>>>>> So, they're clearly different implementations on Windows and Unix.
>>>>> Also, for the Unix implementation, the code differ based on
>>>>> preprocessing directive HAVE_AQUA, which could explain why Spencer
>>>>> observes a different behavior than Peter and Berend (all on macOS).
>>>>>
>>>>>
>>>>> Whenever the R_CheckUserInterrupt() function is called it in turn
>>>>> always calls R_ProcessEvents().  At the end, there is a code snippet -
>>>>> if (R_interrupts_pending) onintr(); - which is Windows specific and
>>>>> could be another important difference between Windows and Unix.  This
>>>>> function is defined in:
>>>>>
>>>>> * src/main/errors.c
>>>>>
>>>>> (https://github.com/wch/r-source/blob/trunk/src/main/errors.c#L114-L134)
>>>>>
>>>>>
>>>>> The do_setTimeLimit() function controls global variables cpuLimitValue
>>>>> and elapsedLimitValue, which are checked in R_ProcessEvents(), but
>>>>> other than setting the timeout limits I don't think it's involved in
>>>>> the runtime checks. The do_setTimeLimit() is defined in:
>>>>>
>>>>> * src/main/sysutils.c
>>>>>
>>>>>
>>>>> (https://github.com/wch/r-source/blob/trunk/src/main/sysutils.c#L1692-L1736)
>>>>>
>>>>>
>>>>> Unfortunately, right now, I've got little extra time to troubleshoot
>>>>> this further.
>>>>>
>>>>> /Henrik
>>>>>
>>>>> On Wed, Oct 26, 2016 at 2:22 AM, Berend Hasselman <bhh at xs4all.nl>
>>>>> wrote:
>>>>>>
>>>>>>
>>>>>>
>>>>>>> On 26 Oct 2016, at 04:44, Henrik Bengtsson
>>>>>>> <henrik.bengtsson at gmail.com>
>>>>>>> wrote:
>>>>>>> .......
>>>>>>> This looks like a bug to me.  Can anyone on macOS confirm whether
>>>>>>> this
>>>>>>> is also a problem there or not?
>>>>>>>
>>>>>>
>>>>>>
>>>>>> Tried it on macOS El Capitan and got this (running in R.app with R
>>>>>> version 3.3.2 RC (2016-10-23 r71574):
>>>>>>
>>>>>>> setTimeLimit(elapsed=1)
>>>>>>> system.time({ Sys.sleep(10); message("done") })
>>>>>>
>>>>>>
>>>>>> Error in Sys.sleep(10) : reached elapsed time limit
>>>>>> Timing stopped at: 0.113 0.042 10.038
>>>>>>
>>>>>> Berend
>>>>>>
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>>
>>>>
>>>>
>>>
>>> --
>>> Luke Tierney
>>> Ralph E. Wareham Professor of Mathematical Sciences
>>> University of Iowa                  Phone:             319-335-3386
>>> Department of Statistics and        Fax:               319-335-3017
>>>    Actuarial Science
>>> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
>>> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>>
>>
>
> --
> Luke Tierney
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>    Actuarial Science
> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From atajti at gmail.com  Tue Nov  1 20:54:01 2016
From: atajti at gmail.com (=?UTF-8?Q?Andr=C3=A1s_Tajti?=)
Date: Tue, 1 Nov 2016 20:54:01 +0100
Subject: [Rd] as.formula("x") error on C stack limit
Message-ID: <CALCQKuX2NrpsjtPkJUgbUboQAcSstghps6bHxY_mes9a_AKz2A@mail.gmail.com>

Dear all,
I tried to run as.formula("x") and got an error message "Error: C stack
usage  7971120 is too close to the limit" whether x exists or not. This is
not the case in as.formula("y"), where "object 'y'  not found" is the error
message if y not exists, or "invalid formula" error or a formula depending
on y. Can anyone confirm this is not my special problem, or if it is, why
it can happen?

Thank you:
Andr?s

Below the output of sessionInfo():

R version 3.3.1 (2016-06-21)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.5 LTS

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=hu_HU.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=hu_HU.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=hu_HU.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=hu_HU.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Tue Nov  1 21:48:54 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 1 Nov 2016 13:48:54 -0700
Subject: [Rd] as.formula("x") error on C stack limit
In-Reply-To: <CALCQKuX2NrpsjtPkJUgbUboQAcSstghps6bHxY_mes9a_AKz2A@mail.gmail.com>
References: <CALCQKuX2NrpsjtPkJUgbUboQAcSstghps6bHxY_mes9a_AKz2A@mail.gmail.com>
Message-ID: <CAF8bMcbF4mRVKK-ecJBmKbDE=t5ajh6MYtEbSR1-vMPtpTccYA@mail.gmail.com>

Another example uses formula.character's other arguments:
> as.formula("env")
Error: object of type 'special' is not subsettable
> as.formula("...")
Error in eval(expr, envir, enclos) : '...' used in an incorrect context


It may happen for the same reason that the following does not give an error:
> y <- "response ~ pred1 + pred2"
> as.formula("y")
response ~ pred1 + pred2

and that the followings give a somewhat surprising result

> f <- function(x) { y <- "foo ~ bar" ; as.formula(x) }
> f("y")
response ~ pred1 + pred2
<environment: 0x1e87978>

The character method for formula works well if its 'x' argument looks like
a formula, but it doesn't act consistently otherwise.



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Nov 1, 2016 at 12:54 PM, Andr?s Tajti <atajti at gmail.com> wrote:

> Dear all,
> I tried to run as.formula("x") and got an error message "Error: C stack
> usage  7971120 is too close to the limit" whether x exists or not. This is
> not the case in as.formula("y"), where "object 'y'  not found" is the error
> message if y not exists, or "invalid formula" error or a formula depending
> on y. Can anyone confirm this is not my special problem, or if it is, why
> it can happen?
>
> Thank you:
> Andr?s
>
> Below the output of sessionInfo():
>
> R version 3.3.1 (2016-06-21)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 14.04.5 LTS
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=hu_HU.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=hu_HU.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=hu_HU.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=hu_HU.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

	[[alternative HTML version deleted]]


From atajti at gmail.com  Tue Nov  1 22:41:55 2016
From: atajti at gmail.com (=?UTF-8?Q?Andr=C3=A1s_Tajti?=)
Date: Tue, 1 Nov 2016 22:41:55 +0100
Subject: [Rd] as.formula("x") error on C stack limit
In-Reply-To: <CAF8bMcbF4mRVKK-ecJBmKbDE=t5ajh6MYtEbSR1-vMPtpTccYA@mail.gmail.com>
References: <CALCQKuX2NrpsjtPkJUgbUboQAcSstghps6bHxY_mes9a_AKz2A@mail.gmail.com>
	<CAF8bMcbF4mRVKK-ecJBmKbDE=t5ajh6MYtEbSR1-vMPtpTccYA@mail.gmail.com>
Message-ID: <CALCQKuXbw0z_EV1-2XyS_-S10N4UnxSAmYgF4MVo7-D7iXQ1Mg@mail.gmail.com>

Thank you for the exhausting answer.

Is it possible to add a note to the help page regarding the conclusion (or
even the edge cases)?

is it possible to add any validation for x in formula.character?

On 1 November 2016 at 21:48, William Dunlap <wdunlap at tibco.com> wrote:

> Another example uses formula.character's other arguments:
> > as.formula("env")
> Error: object of type 'special' is not subsettable
> > as.formula("...")
> Error in eval(expr, envir, enclos) : '...' used in an incorrect context
>
>
> It may happen for the same reason that the following does not give an
> error:
> > y <- "response ~ pred1 + pred2"
> > as.formula("y")
> response ~ pred1 + pred2
>
> and that the followings give a somewhat surprising result
>
> > f <- function(x) { y <- "foo ~ bar" ; as.formula(x) }
> > f("y")
> response ~ pred1 + pred2
> <environment: 0x1e87978>
>
> The character method for formula works well if its 'x' argument looks like
> a formula, but it doesn't act consistently otherwise.
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Tue, Nov 1, 2016 at 12:54 PM, Andr?s Tajti <atajti at gmail.com> wrote:
>
>> Dear all,
>> I tried to run as.formula("x") and got an error message "Error: C stack
>> usage  7971120 is too close to the limit" whether x exists or not. This is
>> not the case in as.formula("y"), where "object 'y'  not found" is the
>> error
>> message if y not exists, or "invalid formula" error or a formula depending
>> on y. Can anyone confirm this is not my special problem, or if it is, why
>> it can happen?
>>
>> Thank you:
>> Andr?s
>>
>> Below the output of sessionInfo():
>>
>> R version 3.3.1 (2016-06-21)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Ubuntu 14.04.5 LTS
>>
>> locale:
>>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>  [3] LC_TIME=hu_HU.UTF-8        LC_COLLATE=en_US.UTF-8
>>  [5] LC_MONETARY=hu_HU.UTF-8    LC_MESSAGES=en_US.UTF-8
>>  [7] LC_PAPER=hu_HU.UTF-8       LC_NAME=C
>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=hu_HU.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>

	[[alternative HTML version deleted]]


From J.Gorecki at wit.edu.pl  Tue Nov  1 23:51:28 2016
From: J.Gorecki at wit.edu.pl (Jan Gorecki)
Date: Tue, 1 Nov 2016 22:51:28 +0000
Subject: [Rd] Running package tests and not stop on first fail
Message-ID: <CABE2sp66ywzHW9LFOJ-Z0mRWWro62ZFGXppiFxPVqJC0gpssdQ@mail.gmail.com>

Hello community/devs,
Is there an option to run package tests during R CMD check and not stop on
first error? I know that testing frameworks (testhat and others) can do
that but asking about just R and base packages. Currently when package
check runs test scripts in ./tests directory it will stop after first fail.
Do you think it could be optionally available to continue to run tests
after failures?
Regards,
Jan Gorecki

	[[alternative HTML version deleted]]


From kmillar at google.com  Thu Nov  3 00:26:40 2016
From: kmillar at google.com (Karl Millar)
Date: Wed, 2 Nov 2016 16:26:40 -0700
Subject: [Rd] Is importMethodsFrom actually needed?
Message-ID: <CABz6aZdGhoXrtqfROE9VBEo1mK4hC5SZraKT6qayZjSHc+b=vg@mail.gmail.com>

IIUC, loading a namespace automatically registers all the exported
methods as long as the generic can be found when the namespace gets
loaded.  Generics can be exported and imported as regular functions.

In that case, code in a package should be able to simply import the
generic and the methods will automatically work correctly without any
need for importMethodsFrom.

Is there something that I'm missing here?  What breaks if you don't
explicitly import methods?

Thanks,

Karl


From richierocks at gmail.com  Thu Nov  3 09:07:26 2016
From: richierocks at gmail.com (Richard Cotton)
Date: Thu, 3 Nov 2016 11:07:26 +0300
Subject: [Rd] .S4methods inconsistent behavior with methods, .S3methods
Message-ID: <CAPp_+=fwQf6VbNK4mb9sAWnJOKBuAJgWDMGNwJ9u-5FqdwOAMw@mail.gmail.com>

If I call

.S4methods(sd)

I get the error

## Error in getGeneric(generic.function) :
##   argument 'f' must be a string, generic function, or primitive:
got an ordinary function

By contrast, methods and .S3methods just state that no methods are found.

methods(sd)
## no methods found
S3methods(sd)
## no methods found

It seems like the behavior of these functions ought to be consistent.

Maybe they should split the difference and say no methods are found,
but warn the the input is not generic?

-- 
Regards,
Richie

Learning R
4dpiecharts.com


From maechler at stat.math.ethz.ch  Thu Nov  3 11:45:15 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 3 Nov 2016 11:45:15 +0100
Subject: [Rd] Running package tests and not stop on first fail
In-Reply-To: <CABE2sp66ywzHW9LFOJ-Z0mRWWro62ZFGXppiFxPVqJC0gpssdQ@mail.gmail.com>
References: <CABE2sp66ywzHW9LFOJ-Z0mRWWro62ZFGXppiFxPVqJC0gpssdQ@mail.gmail.com>
Message-ID: <22555.5435.945673.692470@stat.math.ethz.ch>

>>>>> Jan Gorecki <J.Gorecki at wit.edu.pl>
>>>>>     on Tue, 1 Nov 2016 22:51:28 +0000 writes:

    > Hello community/devs, Is there an option to run package
    > tests during R CMD check and not stop on first error? I
    > know that testing frameworks (testhat and others) can do
    > that but asking about just R and base packages. Currently
    > when package check runs test scripts in ./tests directory
    > it will stop after first fail.  Do you think it could be
    > optionally available to continue to run tests after
    > failures?  Regards, Jan Gorecki

I agree that this would be a useful option sometimes.

So I would be supportive to get such an option, say,

   R CMD check --no-stop-on-error  <pkg>

into R if someone provided (relatively small) patches to the R
sources (i.e. subversion repos at https://svn.r-project.org/R/trunk/ ).
The relevant source code should basically all be in
    src/library/tools/R/testing.R

Note that this may be complicated, also because "parallel"
checking is available in parts, via the TEST_MC_CORES
environment variable ((which is currently only quickly
documented in the 'R Administration ..' manual))


Martin Maechler
ETH Zurich


From hpages at fredhutch.org  Thu Nov  3 18:25:44 2016
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Thu, 3 Nov 2016 10:25:44 -0700
Subject: [Rd] Running package tests and not stop on first fail
In-Reply-To: <22555.5435.945673.692470@stat.math.ethz.ch>
References: <CABE2sp66ywzHW9LFOJ-Z0mRWWro62ZFGXppiFxPVqJC0gpssdQ@mail.gmail.com>
	<22555.5435.945673.692470@stat.math.ethz.ch>
Message-ID: <4527a200-d3a1-bbed-6687-697aabef5b89@fredhutch.org>

Hi Martin, Jan,

On 11/03/2016 03:45 AM, Martin Maechler wrote:
>>>>>> Jan Gorecki <J.Gorecki at wit.edu.pl>
>>>>>>     on Tue, 1 Nov 2016 22:51:28 +0000 writes:
>
>     > Hello community/devs, Is there an option to run package
>     > tests during R CMD check and not stop on first error? I
>     > know that testing frameworks (testhat and others) can do
>     > that but asking about just R and base packages. Currently
>     > when package check runs test scripts in ./tests directory
>     > it will stop after first fail.  Do you think it could be
>     > optionally available to continue to run tests after
>     > failures?  Regards, Jan Gorecki
>
> I agree that this would be a useful option sometimes.
>
> So I would be supportive to get such an option, say,
>
>    R CMD check --no-stop-on-error  <pkg>

A couple of years ago the behavior of 'R CMD check' was changed to
continue checking (e.g. the examples) after many types of errors, and
to output a summary count of errors at the end if any have occurred.
So --no-stop-on-error could easily be interpreted as an option that
controls this behavior (and would also suggest that the default has
been reverted back to what it was prior to R 3.2.0), rather than an
option that specifically controls what should happen while running
the tests.

Cheers,
H.

>
> into R if someone provided (relatively small) patches to the R
> sources (i.e. subversion repos at https://svn.r-project.org/R/trunk/ ).
> The relevant source code should basically all be in
>     src/library/tools/R/testing.R
>
> Note that this may be complicated, also because "parallel"
> checking is available in parts, via the TEST_MC_CORES
> environment variable ((which is currently only quickly
> documented in the 'R Administration ..' manual))
>
>
> Martin Maechler
> ETH Zurich
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From J.Gorecki at wit.edu.pl  Fri Nov  4 12:20:37 2016
From: J.Gorecki at wit.edu.pl (Jan Gorecki)
Date: Fri, 4 Nov 2016 11:20:37 +0000
Subject: [Rd] Running package tests and not stop on first fail
In-Reply-To: <4527a200-d3a1-bbed-6687-697aabef5b89@fredhutch.org>
References: <CABE2sp66ywzHW9LFOJ-Z0mRWWro62ZFGXppiFxPVqJC0gpssdQ@mail.gmail.com>
	<22555.5435.945673.692470@stat.math.ethz.ch>
	<4527a200-d3a1-bbed-6687-697aabef5b89@fredhutch.org>
Message-ID: <CABE2sp5Da4vc8Qksk8nD_bn-pv2+MJcrYaB-2J44HGo5eow3pg@mail.gmail.com>

Martin,
I submitted very simple patch on
https://bugs.r-project.org/bugzilla/show_bug.cgi?id=17176

Herve,
While I like your idea, I prefer to keep my patch simple, it is now
exactly what Martin mentions. I think it is a good start that can
eventually be extended later for what you are asking.

Regards,
Jan

On 3 November 2016 at 17:25, Herv? Pag?s <hpages at fredhutch.org> wrote:
>
> Hi Martin, Jan,
>
> On 11/03/2016 03:45 AM, Martin Maechler wrote:
>>>>>>>
>>>>>>> Jan Gorecki <J.Gorecki at wit.edu.pl>
>>>>>>>     on Tue, 1 Nov 2016 22:51:28 +0000 writes:
>>
>>
>>     > Hello community/devs, Is there an option to run package
>>     > tests during R CMD check and not stop on first error? I
>>     > know that testing frameworks (testhat and others) can do
>>     > that but asking about just R and base packages. Currently
>>     > when package check runs test scripts in ./tests directory
>>     > it will stop after first fail.  Do you think it could be
>>     > optionally available to continue to run tests after
>>     > failures?  Regards, Jan Gorecki
>>
>> I agree that this would be a useful option sometimes.
>>
>> So I would be supportive to get such an option, say,
>>
>>    R CMD check --no-stop-on-error  <pkg>
>
>
> A couple of years ago the behavior of 'R CMD check' was changed to
> continue checking (e.g. the examples) after many types of errors, and
> to output a summary count of errors at the end if any have occurred.
> So --no-stop-on-error could easily be interpreted as an option that
> controls this behavior (and would also suggest that the default has
> been reverted back to what it was prior to R 3.2.0), rather than an
> option that specifically controls what should happen while running
> the tests.
>
> Cheers,
> H.
>
>>
>> into R if someone provided (relatively small) patches to the R
>> sources (i.e. subversion repos at https://svn.r-project.org/R/trunk/ ).
>> The relevant source code should basically all be in
>>     src/library/tools/R/testing.R
>>
>> Note that this may be complicated, also because "parallel"
>> checking is available in parts, via the TEST_MC_CORES
>> environment variable ((which is currently only quickly
>> documented in the 'R Administration ..' manual))
>>
>>
>> Martin Maechler
>> ETH Zurich
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> --
> Herv? Pag?s
>
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
>
> E-mail: hpages at fredhutch.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319


From maechler at stat.math.ethz.ch  Fri Nov  4 16:24:49 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 4 Nov 2016 16:24:49 +0100
Subject: [Rd] Running package tests and not stop on first fail
In-Reply-To: <CABE2sp5Da4vc8Qksk8nD_bn-pv2+MJcrYaB-2J44HGo5eow3pg@mail.gmail.com>
References: <CABE2sp66ywzHW9LFOJ-Z0mRWWro62ZFGXppiFxPVqJC0gpssdQ@mail.gmail.com>
	<22555.5435.945673.692470@stat.math.ethz.ch>
	<4527a200-d3a1-bbed-6687-697aabef5b89@fredhutch.org>
	<CABE2sp5Da4vc8Qksk8nD_bn-pv2+MJcrYaB-2J44HGo5eow3pg@mail.gmail.com>
Message-ID: <22556.43073.490072.801815@stat.math.ethz.ch>

>>>>> Jan Gorecki <J.Gorecki at wit.edu.pl>
>>>>>     on Fri, 4 Nov 2016 11:20:37 +0000 writes:

    > Martin, I submitted very simple patch on
    > https://bugs.r-project.org/bugzilla/show_bug.cgi?id=17176

    > Herve, While I like your idea, I prefer to keep my patch
    > simple, it is now exactly what Martin mentions. I think it
    > is a good start that can eventually be extended later for
    > what you are asking.

I tend to agree; this seems indeed much easier than I
anticipated.  Thank you, Jan!

I'm testing a version which uses the logical variable
'stop_on_error' rather than 'no_stop_on_error' (because
!no_stop_on_error is hard to mentally parse quickly).

My proposed name  '--no-stop-on-error'  was a quick shot; if
somebody has a more concise or better "English style" wording
(which is somewhat compatible with all the other options you see
from 'R CMD check --help'),
please speak up.

Martin

    > Regards, Jan

    > On 3 November 2016 at 17:25, Herv? Pag?s
    > <hpages at fredhutch.org> wrote:
    >> 
    >> Hi Martin, Jan,
    >> 
    >> On 11/03/2016 03:45 AM, Martin Maechler wrote:
    >>>>>>>> 
    >>>>>>>> Jan Gorecki <J.Gorecki at wit.edu.pl> on Tue, 1 Nov
    >>>>>>>> 2016 22:51:28 +0000 writes:
    >>> 
    >>> 
    >>> > Hello community/devs, Is there an option to run
    >>> package > tests during R CMD check and not stop on first
    >>> error? I > know that testing frameworks (testhat and
    >>> others) can do > that but asking about just R and base
    >>> packages. Currently > when package check runs test
    >>> scripts in ./tests directory > it will stop after first
    >>> fail.  Do you think it could be > optionally available
    >>> to continue to run tests after > failures?  Regards, Jan
    >>> Gorecki
    >>> 
    >>> I agree that this would be a useful option sometimes.
    >>> 
    >>> So I would be supportive to get such an option, say,
    >>> 
    >>> R CMD check --no-stop-on-error <pkg>
    >> 
    >> 
    >> A couple of years ago the behavior of 'R CMD check' was
    >> changed to continue checking (e.g. the examples) after
    >> many types of errors, and to output a summary count of
    >> errors at the end if any have occurred.  So
    >> --no-stop-on-error could easily be interpreted as an
    >> option that controls this behavior (and would also
    >> suggest that the default has been reverted back to what
    >> it was prior to R 3.2.0), rather than an option that
    >> specifically controls what should happen while running
    >> the tests.
    >> 
    >> Cheers, H.
    >> 
    >>> 
    >>> into R if someone provided (relatively small) patches to
    >>> the R sources (i.e. subversion repos at
    >>> https://svn.r-project.org/R/trunk/ ).  The relevant
    >>> source code should basically all be in
    >>> src/library/tools/R/testing.R
    >>> 
    >>> Note that this may be complicated, also because
    >>> "parallel" checking is available in parts, via the
    >>> TEST_MC_CORES environment variable ((which is currently
    >>> only quickly documented in the 'R Administration ..'
    >>> manual))
    >>> 
    >>> 
    >>> Martin Maechler ETH Zurich
    >>> 
    >>> ______________________________________________
    >>> R-devel at r-project.org mailing list
    >>> https://stat.ethz.ch/mailman/listinfo/r-devel
    >>> 
    >> 
    >> --
    >> Herv? Pag?s
    >> 
    >> Program in Computational Biology Division of Public
    >> Health Sciences Fred Hutchinson Cancer Research Center
    >> 1100 Fairview Ave. N, M1-B514 P.O. Box 19024 Seattle, WA
    >> 98109-1024
    >> 
    >> E-mail: hpages at fredhutch.org Phone: (206) 667-5791 Fax:
    >> (206) 667-1319


From edd at debian.org  Fri Nov  4 16:36:52 2016
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 4 Nov 2016 10:36:52 -0500
Subject: [Rd] Running package tests and not stop on first fail
In-Reply-To: <22556.43073.490072.801815@stat.math.ethz.ch>
References: <CABE2sp66ywzHW9LFOJ-Z0mRWWro62ZFGXppiFxPVqJC0gpssdQ@mail.gmail.com>
	<22555.5435.945673.692470@stat.math.ethz.ch>
	<4527a200-d3a1-bbed-6687-697aabef5b89@fredhutch.org>
	<CABE2sp5Da4vc8Qksk8nD_bn-pv2+MJcrYaB-2J44HGo5eow3pg@mail.gmail.com>
	<22556.43073.490072.801815@stat.math.ethz.ch>
Message-ID: <22556.43796.305280.635245@max.nulle.part>


On 4 November 2016 at 16:24, Martin Maechler wrote:
| My proposed name  '--no-stop-on-error'  was a quick shot; if
| somebody has a more concise or better "English style" wording
| (which is somewhat compatible with all the other options you see
| from 'R CMD check --help'),
| please speak up.

Why not keep it simple?  The similar feature this most resembles is 'make -k'
and its help page has

       -k, --keep-going
       
                   Continue as much as possible after an error.  While the
                   target that failed, and those that depend on it, cannot be
                   remade, the other dependencies of these targets can be
                   processed all the same.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From brian at braverock.com  Fri Nov  4 16:37:18 2016
From: brian at braverock.com (Brian G. Peterson)
Date: Fri, 04 Nov 2016 10:37:18 -0500
Subject: [Rd] Running package tests and not stop on first fail
In-Reply-To: <22556.43073.490072.801815@stat.math.ethz.ch>
References: <CABE2sp66ywzHW9LFOJ-Z0mRWWro62ZFGXppiFxPVqJC0gpssdQ@mail.gmail.com>
	<22555.5435.945673.692470@stat.math.ethz.ch>
	<4527a200-d3a1-bbed-6687-697aabef5b89@fredhutch.org>
	<CABE2sp5Da4vc8Qksk8nD_bn-pv2+MJcrYaB-2J44HGo5eow3pg@mail.gmail.com>
	<22556.43073.490072.801815@stat.math.ethz.ch>
Message-ID: <1478273838.17774.87.camel@brian-rcg>

On Fri, 2016-11-04 at 16:24 +0100, Martin Maechler wrote:
> >>>>> Jan Gorecki <J.Gorecki at wit.edu.pl>
> >>>>>     on Fri, 4 Nov 2016 11:20:37 +0000 writes:
> 
>     > Martin, I submitted very simple patch on
>     > https://bugs.r-project.org/bugzilla/show_bug.cgi?id=17176
> 
>     > Herve, While I like your idea, I prefer to keep my patch
>     > simple, it is now exactly what Martin mentions. I think it
>     > is a good start that can eventually be extended later for
>     > what you are asking.
> 
> I tend to agree; this seems indeed much easier than I
> anticipated.  Thank you, Jan!
> 
> I'm testing a version which uses the logical variable
> 'stop_on_error' rather than 'no_stop_on_error' (because
> !no_stop_on_error is hard to mentally parse quickly).
> 
> My proposed name  '--no-stop-on-error'  was a quick shot; if
> somebody has a more concise or better "English style" wording
> (which is somewhat compatible with all the other options you see
> from 'R CMD check --help'),
> please speak up.

I might suggest 

--stop-tests-on-error

with default=TRUE to match current functionality.

This might avoid any confusion related to the behavior of continuing to
run examples on error in R CMD check.

Regards,

Brian


From maechler at stat.math.ethz.ch  Fri Nov  4 16:53:54 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 4 Nov 2016 16:53:54 +0100
Subject: [Rd] Running package tests and not stop on first fail
In-Reply-To: <1478273838.17774.87.camel@brian-rcg>
References: <CABE2sp66ywzHW9LFOJ-Z0mRWWro62ZFGXppiFxPVqJC0gpssdQ@mail.gmail.com>
	<22555.5435.945673.692470@stat.math.ethz.ch>
	<4527a200-d3a1-bbed-6687-697aabef5b89@fredhutch.org>
	<CABE2sp5Da4vc8Qksk8nD_bn-pv2+MJcrYaB-2J44HGo5eow3pg@mail.gmail.com>
	<22556.43073.490072.801815@stat.math.ethz.ch>
	<1478273838.17774.87.camel@brian-rcg>
Message-ID: <22556.44818.946547.306930@stat.math.ethz.ch>

>>>>> Brian G Peterson <brian at braverock.com>
>>>>>     on Fri, 4 Nov 2016 10:37:18 -0500 writes:

    > On Fri, 2016-11-04 at 16:24 +0100, Martin Maechler wrote:
    >> >>>>> Jan Gorecki <J.Gorecki at wit.edu.pl> >>>>> on Fri, 4
    >> Nov 2016 11:20:37 +0000 writes:
    >> 
    >> > Martin, I submitted very simple patch on >
    >> https://bugs.r-project.org/bugzilla/show_bug.cgi?id=17176
    >> 
    >> > Herve, While I like your idea, I prefer to keep my
    >> patch > simple, it is now exactly what Martin mentions. I
    >> think it > is a good start that can eventually be
    >> extended later for > what you are asking.
    >> 
    >> I tend to agree; this seems indeed much easier than I
    >> anticipated.  Thank you, Jan!
    >> 
    >> I'm testing a version which uses the logical variable
    >> 'stop_on_error' rather than 'no_stop_on_error' (because
    >> !no_stop_on_error is hard to mentally parse quickly).
    >> 
    >> My proposed name '--no-stop-on-error' was a quick shot;
    >> if somebody has a more concise or better "English style"
    >> wording (which is somewhat compatible with all the other
    >> options you see from 'R CMD check --help'), please speak
    >> up.

    > I might suggest

    > --stop-tests-on-error

    > with default=TRUE to match current functionality.

Thank you, Brian.

though that would be less concise and I think less matching the
'R CMD check' philosophy with many '--no-*' options to turn
*off* defaults. Note that most options have no " = <value>" part, because
they are binary and I think that's easiest for use (when the 'binary' case 
is general enough). Also   R CMD check --help      
ends saying  "By default, all test sections are turned on."
which does fit the use of all those '--no-*' options.

OTOH, we also have  '--ignore-vignettes'
so we could consider

   --ignore-tests-errors

?


    > This might avoid any confusion related to the behavior of
    > continuing to run examples on error in R CMD check.

You are quite right on that, indeed.
Martin

    > Regards,
    > Brian


From maechler at stat.math.ethz.ch  Fri Nov  4 16:56:58 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 4 Nov 2016 16:56:58 +0100
Subject: [Rd] Running package tests and not stop on first fail
In-Reply-To: <22556.43796.305280.635245@max.nulle.part>
References: <CABE2sp66ywzHW9LFOJ-Z0mRWWro62ZFGXppiFxPVqJC0gpssdQ@mail.gmail.com>
	<22555.5435.945673.692470@stat.math.ethz.ch>
	<4527a200-d3a1-bbed-6687-697aabef5b89@fredhutch.org>
	<CABE2sp5Da4vc8Qksk8nD_bn-pv2+MJcrYaB-2J44HGo5eow3pg@mail.gmail.com>
	<22556.43073.490072.801815@stat.math.ethz.ch>
	<22556.43796.305280.635245@max.nulle.part>
Message-ID: <22556.45002.81234.741856@stat.math.ethz.ch>

>>>>> Dirk Eddelbuettel <edd at debian.org>
>>>>>     on Fri, 4 Nov 2016 10:36:52 -0500 writes:

    > On 4 November 2016 at 16:24, Martin Maechler wrote: | My
    > proposed name '--no-stop-on-error' was a quick shot; if |
    > somebody has a more concise or better "English style"
    > wording | (which is somewhat compatible with all the other
    > options you see | from 'R CMD check --help'), | please
    > speak up.

    > Why not keep it simple?  The similar feature this most
    > resembles is 'make -k' and its help page has

    >        -k, --keep-going
       
    >                    Continue as much as possible after an
    > error.  While the target that failed, and those that
    > depend on it, cannot be remade, the other dependencies of
    > these targets can be processed all the same.

Yes, that would be quite a bit simpler and nice in my view.
One may think it to be too vague,
notably from Brian Pedersen's mentioning that the examples are
already continued in any case if they lead to an error.

Other opinions?


From ironholds at gmail.com  Fri Nov  4 17:42:54 2016
From: ironholds at gmail.com (Oliver Keyes)
Date: Fri, 4 Nov 2016 12:42:54 -0400
Subject: [Rd] Running package tests and not stop on first fail
In-Reply-To: <22556.45002.81234.741856@stat.math.ethz.ch>
References: <CABE2sp66ywzHW9LFOJ-Z0mRWWro62ZFGXppiFxPVqJC0gpssdQ@mail.gmail.com>
	<22555.5435.945673.692470@stat.math.ethz.ch>
	<4527a200-d3a1-bbed-6687-697aabef5b89@fredhutch.org>
	<CABE2sp5Da4vc8Qksk8nD_bn-pv2+MJcrYaB-2J44HGo5eow3pg@mail.gmail.com>
	<22556.43073.490072.801815@stat.math.ethz.ch>
	<22556.43796.305280.635245@max.nulle.part>
	<22556.45002.81234.741856@stat.math.ethz.ch>
Message-ID: <CADRwj9-eK4tufYNnKazU_cpVuKb=ac9FXCTKx63DFGm+wqPM1A@mail.gmail.com>

On Friday, 4 November 2016, Martin Maechler <maechler at stat.math.ethz.ch>
wrote:

> >>>>> Dirk Eddelbuettel <edd at debian.org <javascript:;>>
> >>>>>     on Fri, 4 Nov 2016 10:36:52 -0500 writes:
>
>     > On 4 November 2016 at 16:24, Martin Maechler wrote: | My
>     > proposed name '--no-stop-on-error' was a quick shot; if |
>     > somebody has a more concise or better "English style"
>     > wording | (which is somewhat compatible with all the other
>     > options you see | from 'R CMD check --help'), | please
>     > speak up.
>
>     > Why not keep it simple?  The similar feature this most
>     > resembles is 'make -k' and its help page has
>
>     >        -k, --keep-going
>
>     >                    Continue as much as possible after an
>     > error.  While the target that failed, and those that
>     > depend on it, cannot be remade, the other dependencies of
>     > these targets can be processed all the same.
>
> Yes, that would be quite a bit simpler and nice in my view.
> One may think it to be too vague,


Mmn, I would agree on vagueness (and it breaks the pattern set by other
flags of human-readability). Deep familiarity with make is probably not
something we should ask of everyone who needs to test a package, too.

I quite like stop-on-error=true (exactly the same as the previous
suggestion but shaves off some characters by inverting the Boolean)

notably from Brian Pedersen's mentioning that the examples are
> already continued in any case if they lead to an error.
>
> Other opinions?
>
> ______________________________________________
> R-devel at r-project.org <javascript:;> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Sat Nov  5 21:53:08 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 5 Nov 2016 21:53:08 +0100
Subject: [Rd] Running package tests and not stop on first fail
In-Reply-To: <CADRwj9-eK4tufYNnKazU_cpVuKb=ac9FXCTKx63DFGm+wqPM1A@mail.gmail.com>
References: <CABE2sp66ywzHW9LFOJ-Z0mRWWro62ZFGXppiFxPVqJC0gpssdQ@mail.gmail.com>
	<22555.5435.945673.692470@stat.math.ethz.ch>
	<4527a200-d3a1-bbed-6687-697aabef5b89@fredhutch.org>
	<CABE2sp5Da4vc8Qksk8nD_bn-pv2+MJcrYaB-2J44HGo5eow3pg@mail.gmail.com>
	<22556.43073.490072.801815@stat.math.ethz.ch>
	<22556.43796.305280.635245@max.nulle.part>
	<22556.45002.81234.741856@stat.math.ethz.ch>
	<CADRwj9-eK4tufYNnKazU_cpVuKb=ac9FXCTKx63DFGm+wqPM1A@mail.gmail.com>
Message-ID: <20161105205308.2E1FB140692@ion-3.math.ethz.ch>

>>>>> Oliver Keyes <ironholds at gmail.com>
>>>>>     on Fri, 4 Nov 2016 12:42:54 -0400 writes:

    > On Friday, 4 November 2016, Martin Maechler
    > <maechler at stat.math.ethz.ch> wrote:

    >> >>>>> Dirk Eddelbuettel <edd at debian.org <javascript:;>>
    >> >>>>> on Fri, 4 Nov 2016 10:36:52 -0500 writes:
    >> 
    >> > On 4 November 2016 at 16:24, Martin Maechler wrote: |
    >> My > proposed name '--no-stop-on-error' was a quick shot;
    >> if | > somebody has a more concise or better "English
    >> style" > wording | (which is somewhat compatible with all
    >> the other > options you see | from 'R CMD check --help'),
    >> | please > speak up.
    >> 
    >> > Why not keep it simple?  The similar feature this most
    >> > resembles is 'make -k' and its help page has
    >> 
    >> > -k, --keep-going
    >> 
    >> > Continue as much as possible after an > error.  While
    >> the target that failed, and those that > depend on it,
    >> cannot be remade, the other dependencies of > these
    >> targets can be processed all the same.
    >> 
    >> Yes, that would be quite a bit simpler and nice in my
    >> view.  One may think it to be too vague,

    > Mmn, I would agree on vagueness (and it breaks the pattern
    > set by other flags of human-readability). Deep familiarity
    > with make is probably not something we should ask of
    > everyone who needs to test a package, too.

    > I quite like stop-on-error=true (exactly the same as the
    > previous suggestion but shaves off some characters by
    > inverting the Boolean)

Thank you, Brian, Dirk and Oliver for these (and some offline)
thoughts and suggestions!

My current summary:

1) I really don't want a  --<option-key>=value
   but rather stay with logical/binary variables that "express
   themselves"... in the same way I strongly prefer

       if (A_is_special)       ....
   to
       if (A_special == TRUE)  ....

   for a logical variable A_* .   Yes, this is mostly a matter
   of taste,.. but related to how R style itself "works"

2) Brian mentioned that this is only about ./tests/ tests which
   are continued, not about the Examples which are treated separately.
   That's why we had contemplated additionally using 'tests' (because that's 
   the directory name used for unit/regression/.. tests) in the option
   name.

Even though Brian is correct, ideally we *would* want to also influence the
examples' running to *not* stop on a first error..   However that would
need more work, reorganizing how the examples are run and that may not be
worth the pain.   However it should be considered a goal in the long run.

After all that, I tend to remain with the original proposed name. It is at
least easy to pronounce and spell correctly...

Martin


From henrik.bengtsson at gmail.com  Mon Nov  7 22:43:15 2016
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Mon, 7 Nov 2016 13:43:15 -0800
Subject: [Rd] R CMD check --as-cran: sslv3 alert handshake failure
Message-ID: <CAFDcVCR4i5pOCSVgRNze9BWWPJyyOVy9Fs13poZV=k2HYdkWdQ@mail.gmail.com>

On R 3.2.5, 3.3.2 and devel for Windows, R CMD check --as-cran gives me:

Found the following (possibly) invalid URLs:
  URL: https://www.stat.auckland.ac.nz/~paul/Reports/DisplayList/dl-record.html
    From: man/capturePlot.Rd
    Status: Error
    Message: libcurl error code 35
    error:14077410:SSL routines:SSL23_GET_SERVER_HELLO:sslv3 alert
handshake failure

This is reported both by the win-builder and the rhub services:

* R 3.3.2: https://win-builder.r-project.org/xj8fwadE4K31/00check.log
* R devel: https://win-builder.r-project.org/xj8fwadE4K31/00check.log
* R 3.2.5: https://builder.r-hub.io/status/R.devices_2.14.0-9000.tar.gz-a252b2d919124c63bc976d78befce161

AFAIU, this is due to the HTTPS webserver not having SSL3 disabled,
e.g. http://unix.stackexchange.com/questions/192944/how-to-fix-curl-sslv3-alert-handshake-failure.

Is this something that should be fixed in R CMD check --as-cran itself?

The only workaround I can see as a package maintainer is to drop the
\url{} / turn the URL into a plain text element, or just mention it my
CRAN submission note.

Thanks,

Henrik


From hpages at fredhutch.org  Mon Nov  7 23:37:15 2016
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Mon, 7 Nov 2016 14:37:15 -0800
Subject: [Rd] Running package tests and not stop on first fail
In-Reply-To: <20161105205308.2E1FB140692@ion-3.math.ethz.ch>
References: <CABE2sp66ywzHW9LFOJ-Z0mRWWro62ZFGXppiFxPVqJC0gpssdQ@mail.gmail.com>
	<22555.5435.945673.692470@stat.math.ethz.ch>
	<4527a200-d3a1-bbed-6687-697aabef5b89@fredhutch.org>
	<CABE2sp5Da4vc8Qksk8nD_bn-pv2+MJcrYaB-2J44HGo5eow3pg@mail.gmail.com>
	<22556.43073.490072.801815@stat.math.ethz.ch>
	<22556.43796.305280.635245@max.nulle.part>
	<22556.45002.81234.741856@stat.math.ethz.ch>
	<CADRwj9-eK4tufYNnKazU_cpVuKb=ac9FXCTKx63DFGm+wqPM1A@mail.gmail.com>
	<20161105205308.2E1FB140692@ion-3.math.ethz.ch>
Message-ID: <e7b32111-aa37-4470-8b54-b752a9a914ae@fredhutch.org>



On 11/05/2016 01:53 PM, Martin Maechler wrote:
>>>>>> Oliver Keyes <ironholds at gmail.com>
>>>>>>     on Fri, 4 Nov 2016 12:42:54 -0400 writes:
>
>     > On Friday, 4 November 2016, Martin Maechler
>     > <maechler at stat.math.ethz.ch> wrote:
>
>     >> >>>>> Dirk Eddelbuettel <edd at debian.org <javascript:;>>
>     >> >>>>> on Fri, 4 Nov 2016 10:36:52 -0500 writes:
>     >>
>     >> > On 4 November 2016 at 16:24, Martin Maechler wrote: |
>     >> My > proposed name '--no-stop-on-error' was a quick shot;
>     >> if | > somebody has a more concise or better "English
>     >> style" > wording | (which is somewhat compatible with all
>     >> the other > options you see | from 'R CMD check --help'),
>     >> | please > speak up.
>     >>
>     >> > Why not keep it simple?  The similar feature this most
>     >> > resembles is 'make -k' and its help page has
>     >>
>     >> > -k, --keep-going
>     >>
>     >> > Continue as much as possible after an > error.  While
>     >> the target that failed, and those that > depend on it,
>     >> cannot be remade, the other dependencies of > these
>     >> targets can be processed all the same.
>     >>
>     >> Yes, that would be quite a bit simpler and nice in my
>     >> view.  One may think it to be too vague,
>
>     > Mmn, I would agree on vagueness (and it breaks the pattern
>     > set by other flags of human-readability). Deep familiarity
>     > with make is probably not something we should ask of
>     > everyone who needs to test a package, too.
>
>     > I quite like stop-on-error=true (exactly the same as the
>     > previous suggestion but shaves off some characters by
>     > inverting the Boolean)
>
> Thank you, Brian, Dirk and Oliver for these (and some offline)
> thoughts and suggestions!
>
> My current summary:
>
> 1) I really don't want a  --<option-key>=value
>    but rather stay with logical/binary variables that "express
>    themselves"... in the same way I strongly prefer
>
>        if (A_is_special)       ....
>    to
>        if (A_special == TRUE)  ....
>
>    for a logical variable A_* .   Yes, this is mostly a matter
>    of taste,.. but related to how R style itself "works"
>
> 2) Brian mentioned that this is only about ./tests/ tests which
>    are continued, not about the Examples which are treated separately.
>    That's why we had contemplated additionally using 'tests' (because that's
>    the directory name used for unit/regression/.. tests) in the option
>    name.
>
> Even though Brian is correct, ideally we *would* want to also influence the
> examples' running to *not* stop on a first error..   However that would
> need more work, reorganizing how the examples are run and that may not be
> worth the pain.   However it should be considered a goal in the long run.

My name is Herv?, and I was not suggesting that what happens with the
examples should be changed. I was just preaching consistency (again
sorry) between what happens with the examples and what happens with
the tests. Why not simply change the latter? Do we really need an option
to control this? The behavior was changed for the examples a couple of
years ago and nobody felt the need to introduce an option to control
this at the time.

>
> After all that, I tend to remain with the original proposed name. It is at
> least easy to pronounce and spell correctly...

Unless --no-stop-on-error controls both (i.e. examples and tests), and 
both behave the same way by default, this is a misnomer.

If this option controls the tests only, it should be more something like
--no-stop-on-test-error. If in the long run, another option is added to
control the examples, then could be --no-stop-on-example-error.

But again, maybe all this is not needed at all. Maybe changing what
happens with the tests would be enough.

Cheers,
H.

>
> Martin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From ligges at statistik.tu-dortmund.de  Tue Nov  8 00:32:45 2016
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 8 Nov 2016 00:32:45 +0100
Subject: [Rd] R CMD check --as-cran: sslv3 alert handshake failure
In-Reply-To: <CAFDcVCR4i5pOCSVgRNze9BWWPJyyOVy9Fs13poZV=k2HYdkWdQ@mail.gmail.com>
References: <CAFDcVCR4i5pOCSVgRNze9BWWPJyyOVy9Fs13poZV=k2HYdkWdQ@mail.gmail.com>
Message-ID: <fd161ca2-dd6a-fdbd-065f-2af3dea2f5b7@statistik.tu-dortmund.de>



On 07.11.2016 22:43, Henrik Bengtsson wrote:
> On R 3.2.5, 3.3.2 and devel for Windows, R CMD check --as-cran gives me:
>
> Found the following (possibly) invalid URLs:
>   URL: https://www.stat.auckland.ac.nz/~paul/Reports/DisplayList/dl-record.html
>     From: man/capturePlot.Rd
>     Status: Error
>     Message: libcurl error code 35
>     error:14077410:SSL routines:SSL23_GET_SERVER_HELLO:sslv3 alert
> handshake failure
>
> This is reported both by the win-builder and the rhub services:
>
> * R 3.3.2: https://win-builder.r-project.org/xj8fwadE4K31/00check.log
> * R devel: https://win-builder.r-project.org/xj8fwadE4K31/00check.log
> * R 3.2.5: https://builder.r-hub.io/status/R.devices_2.14.0-9000.tar.gz-a252b2d919124c63bc976d78befce161
>
> AFAIU, this is due to the HTTPS webserver not having SSL3 disabled,
> e.g. http://unix.stackexchange.com/questions/192944/how-to-fix-curl-sslv3-alert-handshake-failure.
>
> Is this something that should be fixed in R CMD check --as-cran itself?
>
> The only workaround I can see as a package maintainer is to drop the
> \url{} / turn the URL into a plain text element, or just mention it my
> CRAN submission note.

The latter,
Uwe



> Thanks,
>
> Henrik
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From maechler at stat.math.ethz.ch  Tue Nov  8 10:34:53 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 8 Nov 2016 10:34:53 +0100
Subject: [Rd] Running package tests and not stop on first fail
In-Reply-To: <e7b32111-aa37-4470-8b54-b752a9a914ae@fredhutch.org>
References: <CABE2sp66ywzHW9LFOJ-Z0mRWWro62ZFGXppiFxPVqJC0gpssdQ@mail.gmail.com>
	<22555.5435.945673.692470@stat.math.ethz.ch>
	<4527a200-d3a1-bbed-6687-697aabef5b89@fredhutch.org>
	<CABE2sp5Da4vc8Qksk8nD_bn-pv2+MJcrYaB-2J44HGo5eow3pg@mail.gmail.com>
	<22556.43073.490072.801815@stat.math.ethz.ch>
	<22556.43796.305280.635245@max.nulle.part>
	<22556.45002.81234.741856@stat.math.ethz.ch>
	<CADRwj9-eK4tufYNnKazU_cpVuKb=ac9FXCTKx63DFGm+wqPM1A@mail.gmail.com>
	<20161105205308.2E1FB140692@ion-3.math.ethz.ch>
	<e7b32111-aa37-4470-8b54-b752a9a914ae@fredhutch.org>
Message-ID: <22561.39997.738866.706206@stat.math.ethz.ch>

>>>>> Herv? Pag?s <hpages at fredhutch.org>
>>>>>     on Mon, 7 Nov 2016 14:37:15 -0800 writes:

    > On 11/05/2016 01:53 PM, Martin Maechler wrote:
    >>>>>>> Oliver Keyes <ironholds at gmail.com>
    >>>>>>> on Fri, 4 Nov 2016 12:42:54 -0400 writes:
    >> 
    >> > On Friday, 4 November 2016, Martin Maechler
    >> > <maechler at stat.math.ethz.ch> wrote:
    >> 
    >> >> >>>>> Dirk Eddelbuettel <edd at debian.org <javascript:;>>
    >> >> >>>>> on Fri, 4 Nov 2016 10:36:52 -0500 writes:
    >> >>
    >> >> > On 4 November 2016 at 16:24, Martin Maechler wrote: |
    >> >> My > proposed name '--no-stop-on-error' was a quick shot;
    >> >> if | > somebody has a more concise or better "English
    >> >> style" > wording | (which is somewhat compatible with all
    >> >> the other > options you see | from 'R CMD check --help'),
    >> >> | please > speak up.
    >> >>
    >> >> > Why not keep it simple?  The similar feature this most
    >> >> > resembles is 'make -k' and its help page has
    >> >>
    >> >> > -k, --keep-going
    >> >>
    >> >> > Continue as much as possible after an > error.  While
    >> >> the target that failed, and those that > depend on it,
    >> >> cannot be remade, the other dependencies of > these
    >> >> targets can be processed all the same.
    >> >>
    >> >> Yes, that would be quite a bit simpler and nice in my
    >> >> view.  One may think it to be too vague,
    >> 
    >> > Mmn, I would agree on vagueness (and it breaks the pattern
    >> > set by other flags of human-readability). Deep familiarity
    >> > with make is probably not something we should ask of
    >> > everyone who needs to test a package, too.
    >> 
    >> > I quite like stop-on-error=true (exactly the same as the
    >> > previous suggestion but shaves off some characters by
    >> > inverting the Boolean)
    >> 
    >> Thank you, Brian, Dirk and Oliver for these (and some offline)
    >> thoughts and suggestions!
    >> 
    >> My current summary:
    >> 
    >> 1) I really don't want a  --<option-key>=value
    >> but rather stay with logical/binary variables that "express
    >> themselves"... in the same way I strongly prefer
    >> 
    >> if (A_is_special)       ....
    >> to
    >> if (A_special == TRUE)  ....
    >> 
    >> for a logical variable A_* .   Yes, this is mostly a matter
    >> of taste,.. but related to how R style itself "works"
    >> 
    >> 2) Brian mentioned that this is only about ./tests/ tests which
    >> are continued, not about the Examples which are treated separately.
    >> That's why we had contemplated additionally using 'tests' (because that's
    >> the directory name used for unit/regression/.. tests) in the option
    >> name.
    >> 
    >> Even though Brian is correct, ideally we *would* want to also influence the
    >> examples' running to *not* stop on a first error..   However that would
    >> need more work, reorganizing how the examples are run and that may not be
    >> worth the pain.   However it should be considered a goal in the long run.

    > My name is Herv?, and I was not suggesting that what happens with the
    > examples should be changed. I was just preaching consistency (again
    > sorry) between what happens with the examples and what happens with
    > the tests. 

Thank you, Herv? and excuse me for not answering more focused on
what you said.
I think I do understand what you say (at least by now :-)) and
agree that consistency is something important and to be strived for,
also with these options.

    > Why not simply change the latter?
    > Do we really need an option to control this? 

Very good questions.  If the change could be made much better,
I'd agree we'd not need a new option because the change could be
considerided uniformly better than the current (R 3.3.2, say) behavior.
However the change as it is currently, is not good enough to be
the only option (see below). 

    > The behavior was changed for the examples a couple of
    > years ago and nobody felt the need to introduce an option
    > to control this at the time.

Yes, that change was made very nicely (not by me) and I'd say
the result *was* uniformly better than the previous behavior, so
there did not seem much of a reason to still provide the old behavior.

      >> After all that, I tend to remain with the original proposed name. It is at
      >> least easy to pronounce and spell correctly...

    > Unless --no-stop-on-error controls both (i.e. examples and tests), and 
    > both behave the same way by default, this is a misnomer.

Well, if you choose the option, there *is* no stop on errors anymore
... because the examples nowadays never stop the (R CMD check Pkg) 
from running on an error as we've mentioned above.

[[--- Digression on  Examples' checking 

  However / on the other hand: Because of the way the examples
  are run --- efficiently from one single R source file --- it
  is not so easy there, to let them run further: The first error
  from all the examples stops running the example-checks, i.e.,
  the <pkg>-Ex.R script, but at least *does* continue to run the
  next 'R CMD check ...' steps.
 
  To change this without incurring considerable drawbacks, or
  involve a lot of changes does not seem easy:

  - If each example would be run in a separate R process, R has to
    be restarted once for every man/*.Rd file.. which easily adds
    one minute or rather several minutes to the total testing time
    (and a I think quite a bit of the checking code had to be re-written).

  - Alternatively, all examples are parsed (fail-safe!) first and put together
    into an R list (or environment), and then each run via tryCatch(.).
    This is nicer and more efficient conceptually, but needs even
    more code changes and tends to lose the transparent *-Ex.R -> *-Ex.Rout
    interface we have now.

 --- end of digression ---]]
 
    > If this option controls the tests only, it should be more something like
    > --no-stop-on-test-error.  If in the long run, another option is added to
    > control the examples, then could be --no-stop-on-example-error.

    > But again, maybe all this is not needed at all. Maybe changing what
    > happens with the tests would be enough.

I agree: it would be enough, if the change was better than what we currently have
(in R-devel):  On
    https://bugs.r-project.org/bugzilla/show_bug.cgi?id=17176,
Jan mentions that the patch is simple but suffers a deficiency
(my wording) in that the error *reporting* is not correct:

If you have three  tests/*.R  test scripts producing an error,
still only the first of these is reported (and counted in the
final 'Status: ..' line), and the package checker has to
manually look at the   tests/*.Rout.fail files to see which of
the checks failed exactly.... and the reporting of the first
error is *after* running all the tests/*.R scripts which is also
far from ideal.


Consequently, for now, it does need an option there, and it
should not be default because of the "inconsistent" report
output.

I don't mind to  add  the extra  "-test" to the option string,
i.e., change
from
      --no-stop-on-error
to    --no-stop-on-test-error  

Others?


    > Cheers,
    > H.

    > -- 
    > Herv? Pag?s

    > Program in Computational Biology
    > Division of Public Health Sciences
    > Fred Hutchinson Cancer Research Center
    > 1100 Fairview Ave. N, M1-B514
    > P.O. Box 19024
    > Seattle, WA 98109-1024

    > E-mail: hpages at fredhutch.org
    > Phone:  (206) 667-5791
    > Fax:    (206) 667-1319


From bbolker at gmail.com  Tue Nov  8 18:51:23 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 8 Nov 2016 12:51:23 -0500
Subject: [Rd] confusing error from model.frame when var name=function name
Message-ID: <49b2f49d-ba00-c602-9417-94ec12c11832@gmail.com>


  This took me a few minutes of head-scratching:

Normally model.frame() gives an easily interpretable error if a variable
can't be found (in the data frame *or* elsewhere in the environment):

model.frame(~a,data=data.frame(x=1:5))
## Error in eval(predvars, data, env) : object 'a' not found

Now suppose you happen to have a variable name that matches an R
function name:

model.frame(~replicate,data=data.frame(x=1:5))
## Error in model.frame.default(~replicate, data = data.frame(x = 1:5)) :
##  object is not a matrix

   This happens somewhere inside a .External() call:

data <- .External2(C_modelframe, formula, rownames, variables,
    varnames, extras, extranames, subset, na.action)

so I haven't had the heart to track it all the way to its source yet.

  FWIW this happens whether the function is built-in or user-created.

  I don't think the possibly forthcoming "well just don't name your
variables that way" advice is entirely reasonable here ('replicate' is a
perfectly respectable variable name, as are many names that happen to
coincide with R function names (like 'c' !)

  I can easily implement my own checking function, at least for the
contents of the data frame (all(all.vars(formula) %in% names(data)):
checking for *non-function variables only* that exist anywhere in the
searchable environment is a bigger task), but this seems to me to be an
infelicity that would be lovely to have corrected ...

  I will post to R-bugs if this is not shot down in flames here.

  cheers
    Ben Bolker


From hpages at fredhutch.org  Tue Nov  8 18:59:37 2016
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Tue, 8 Nov 2016 09:59:37 -0800
Subject: [Rd] Running package tests and not stop on first fail
In-Reply-To: <22561.39997.738866.706206@stat.math.ethz.ch>
References: <CABE2sp66ywzHW9LFOJ-Z0mRWWro62ZFGXppiFxPVqJC0gpssdQ@mail.gmail.com>
	<22555.5435.945673.692470@stat.math.ethz.ch>
	<4527a200-d3a1-bbed-6687-697aabef5b89@fredhutch.org>
	<CABE2sp5Da4vc8Qksk8nD_bn-pv2+MJcrYaB-2J44HGo5eow3pg@mail.gmail.com>
	<22556.43073.490072.801815@stat.math.ethz.ch>
	<22556.43796.305280.635245@max.nulle.part>
	<22556.45002.81234.741856@stat.math.ethz.ch>
	<CADRwj9-eK4tufYNnKazU_cpVuKb=ac9FXCTKx63DFGm+wqPM1A@mail.gmail.com>
	<20161105205308.2E1FB140692@ion-3.math.ethz.ch>
	<e7b32111-aa37-4470-8b54-b752a9a914ae@fredhutch.org>
	<22561.39997.738866.706206@stat.math.ethz.ch>
Message-ID: <0d678886-6690-88e6-d791-3fdfa9484a01@fredhutch.org>

Thanks Martin.

These changes are great and improve the usefulness of 'R CMD check'.
Especially in the context of the Bioconductor daily builds where
we'll use --no-stop-on-test-error so developers will get a full
picture of all the errors in their package at once.

Cheers,
H.

To provide some context to my special interest for this,

On 11/08/2016 01:34 AM, Martin Maechler wrote:
>>>>>> Herv? Pag?s <hpages at fredhutch.org>
>>>>>>     on Mon, 7 Nov 2016 14:37:15 -0800 writes:
>
>     > On 11/05/2016 01:53 PM, Martin Maechler wrote:
>     >>>>>>> Oliver Keyes <ironholds at gmail.com>
>     >>>>>>> on Fri, 4 Nov 2016 12:42:54 -0400 writes:
>     >>
>     >> > On Friday, 4 November 2016, Martin Maechler
>     >> > <maechler at stat.math.ethz.ch> wrote:
>     >>
>     >> >> >>>>> Dirk Eddelbuettel <edd at debian.org <javascript:;>>
>     >> >> >>>>> on Fri, 4 Nov 2016 10:36:52 -0500 writes:
>     >> >>
>     >> >> > On 4 November 2016 at 16:24, Martin Maechler wrote: |
>     >> >> My > proposed name '--no-stop-on-error' was a quick shot;
>     >> >> if | > somebody has a more concise or better "English
>     >> >> style" > wording | (which is somewhat compatible with all
>     >> >> the other > options you see | from 'R CMD check --help'),
>     >> >> | please > speak up.
>     >> >>
>     >> >> > Why not keep it simple?  The similar feature this most
>     >> >> > resembles is 'make -k' and its help page has
>     >> >>
>     >> >> > -k, --keep-going
>     >> >>
>     >> >> > Continue as much as possible after an > error.  While
>     >> >> the target that failed, and those that > depend on it,
>     >> >> cannot be remade, the other dependencies of > these
>     >> >> targets can be processed all the same.
>     >> >>
>     >> >> Yes, that would be quite a bit simpler and nice in my
>     >> >> view.  One may think it to be too vague,
>     >>
>     >> > Mmn, I would agree on vagueness (and it breaks the pattern
>     >> > set by other flags of human-readability). Deep familiarity
>     >> > with make is probably not something we should ask of
>     >> > everyone who needs to test a package, too.
>     >>
>     >> > I quite like stop-on-error=true (exactly the same as the
>     >> > previous suggestion but shaves off some characters by
>     >> > inverting the Boolean)
>     >>
>     >> Thank you, Brian, Dirk and Oliver for these (and some offline)
>     >> thoughts and suggestions!
>     >>
>     >> My current summary:
>     >>
>     >> 1) I really don't want a  --<option-key>=value
>     >> but rather stay with logical/binary variables that "express
>     >> themselves"... in the same way I strongly prefer
>     >>
>     >> if (A_is_special)       ....
>     >> to
>     >> if (A_special == TRUE)  ....
>     >>
>     >> for a logical variable A_* .   Yes, this is mostly a matter
>     >> of taste,.. but related to how R style itself "works"
>     >>
>     >> 2) Brian mentioned that this is only about ./tests/ tests which
>     >> are continued, not about the Examples which are treated separately.
>     >> That's why we had contemplated additionally using 'tests' (because that's
>     >> the directory name used for unit/regression/.. tests) in the option
>     >> name.
>     >>
>     >> Even though Brian is correct, ideally we *would* want to also influence the
>     >> examples' running to *not* stop on a first error..   However that would
>     >> need more work, reorganizing how the examples are run and that may not be
>     >> worth the pain.   However it should be considered a goal in the long run.
>
>     > My name is Herv?, and I was not suggesting that what happens with the
>     > examples should be changed. I was just preaching consistency (again
>     > sorry) between what happens with the examples and what happens with
>     > the tests.
>
> Thank you, Herv? and excuse me for not answering more focused on
> what you said.
> I think I do understand what you say (at least by now :-)) and
> agree that consistency is something important and to be strived for,
> also with these options.
>
>     > Why not simply change the latter?
>     > Do we really need an option to control this?
>
> Very good questions.  If the change could be made much better,
> I'd agree we'd not need a new option because the change could be
> considerided uniformly better than the current (R 3.3.2, say) behavior.
> However the change as it is currently, is not good enough to be
> the only option (see below).
>
>     > The behavior was changed for the examples a couple of
>     > years ago and nobody felt the need to introduce an option
>     > to control this at the time.
>
> Yes, that change was made very nicely (not by me) and I'd say
> the result *was* uniformly better than the previous behavior, so
> there did not seem much of a reason to still provide the old behavior.
>
>       >> After all that, I tend to remain with the original proposed name. It is at
>       >> least easy to pronounce and spell correctly...
>
>     > Unless --no-stop-on-error controls both (i.e. examples and tests), and
>     > both behave the same way by default, this is a misnomer.
>
> Well, if you choose the option, there *is* no stop on errors anymore
> ... because the examples nowadays never stop the (R CMD check Pkg)
> from running on an error as we've mentioned above.
>
> [[--- Digression on  Examples' checking
>
>   However / on the other hand: Because of the way the examples
>   are run --- efficiently from one single R source file --- it
>   is not so easy there, to let them run further: The first error
>   from all the examples stops running the example-checks, i.e.,
>   the <pkg>-Ex.R script, but at least *does* continue to run the
>   next 'R CMD check ...' steps.
>
>   To change this without incurring considerable drawbacks, or
>   involve a lot of changes does not seem easy:
>
>   - If each example would be run in a separate R process, R has to
>     be restarted once for every man/*.Rd file.. which easily adds
>     one minute or rather several minutes to the total testing time
>     (and a I think quite a bit of the checking code had to be re-written).
>
>   - Alternatively, all examples are parsed (fail-safe!) first and put together
>     into an R list (or environment), and then each run via tryCatch(.).
>     This is nicer and more efficient conceptually, but needs even
>     more code changes and tends to lose the transparent *-Ex.R -> *-Ex.Rout
>     interface we have now.
>
>  --- end of digression ---]]
>
>     > If this option controls the tests only, it should be more something like
>     > --no-stop-on-test-error.  If in the long run, another option is added to
>     > control the examples, then could be --no-stop-on-example-error.
>
>     > But again, maybe all this is not needed at all. Maybe changing what
>     > happens with the tests would be enough.
>
> I agree: it would be enough, if the change was better than what we currently have
> (in R-devel):  On
>     https://bugs.r-project.org/bugzilla/show_bug.cgi?id=17176,
> Jan mentions that the patch is simple but suffers a deficiency
> (my wording) in that the error *reporting* is not correct:
>
> If you have three  tests/*.R  test scripts producing an error,
> still only the first of these is reported (and counted in the
> final 'Status: ..' line), and the package checker has to
> manually look at the   tests/*.Rout.fail files to see which of
> the checks failed exactly.... and the reporting of the first
> error is *after* running all the tests/*.R scripts which is also
> far from ideal.
>
>
> Consequently, for now, it does need an option there, and it
> should not be default because of the "inconsistent" report
> output.
>
> I don't mind to  add  the extra  "-test" to the option string,
> i.e., change
> from
>       --no-stop-on-error
> to    --no-stop-on-test-error
>
> Others?
>
>
>     > Cheers,
>     > H.
>
>     > --
>     > Herv? Pag?s
>
>     > Program in Computational Biology
>     > Division of Public Health Sciences
>     > Fred Hutchinson Cancer Research Center
>     > 1100 Fairview Ave. N, M1-B514
>     > P.O. Box 19024
>     > Seattle, WA 98109-1024
>
>     > E-mail: hpages at fredhutch.org
>     > Phone:  (206) 667-5791
>     > Fax:    (206) 667-1319
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From J.Gorecki at wit.edu.pl  Wed Nov  9 06:54:18 2016
From: J.Gorecki at wit.edu.pl (Jan Gorecki)
Date: Tue, 8 Nov 2016 21:54:18 -0800
Subject: [Rd] Running package tests and not stop on first fail
In-Reply-To: <CADRwj9-eK4tufYNnKazU_cpVuKb=ac9FXCTKx63DFGm+wqPM1A@mail.gmail.com>
References: <CABE2sp66ywzHW9LFOJ-Z0mRWWro62ZFGXppiFxPVqJC0gpssdQ@mail.gmail.com>
	<22555.5435.945673.692470@stat.math.ethz.ch>
	<4527a200-d3a1-bbed-6687-697aabef5b89@fredhutch.org>
	<CABE2sp5Da4vc8Qksk8nD_bn-pv2+MJcrYaB-2J44HGo5eow3pg@mail.gmail.com>
	<22556.43073.490072.801815@stat.math.ethz.ch>
	<22556.43796.305280.635245@max.nulle.part>
	<22556.45002.81234.741856@stat.math.ethz.ch>
	<CADRwj9-eK4tufYNnKazU_cpVuKb=ac9FXCTKx63DFGm+wqPM1A@mail.gmail.com>
Message-ID: <CABE2sp5D8426FPns_svjQGFRMRO8hV8RDgupqxGZXbbGgiEHVw@mail.gmail.com>

Sorry for late reply. I like the stop-on-error.
Thanks for merging.
Glad to be R contributor!

On 4 November 2016 at 09:42, Oliver Keyes <ironholds at gmail.com> wrote:
> On Friday, 4 November 2016, Martin Maechler <maechler at stat.math.ethz.ch>
> wrote:
>>
>> >>>>> Dirk Eddelbuettel <edd at debian.org>
>> >>>>>     on Fri, 4 Nov 2016 10:36:52 -0500 writes:
>>
>>     > On 4 November 2016 at 16:24, Martin Maechler wrote: | My
>>     > proposed name '--no-stop-on-error' was a quick shot; if |
>>     > somebody has a more concise or better "English style"
>>     > wording | (which is somewhat compatible with all the other
>>     > options you see | from 'R CMD check --help'), | please
>>     > speak up.
>>
>>     > Why not keep it simple?  The similar feature this most
>>     > resembles is 'make -k' and its help page has
>>
>>     >        -k, --keep-going
>>
>>     >                    Continue as much as possible after an
>>     > error.  While the target that failed, and those that
>>     > depend on it, cannot be remade, the other dependencies of
>>     > these targets can be processed all the same.
>>
>> Yes, that would be quite a bit simpler and nice in my view.
>> One may think it to be too vague,
>
>
> Mmn, I would agree on vagueness (and it breaks the pattern set by other
> flags of human-readability). Deep familiarity with make is probably not
> something we should ask of everyone who needs to test a package, too.
>
> I quite like stop-on-error=true (exactly the same as the previous suggestion
> but shaves off some characters by inverting the Boolean)
>
>> notably from Brian Pedersen's mentioning that the examples are
>> already continued in any case if they lead to an error.
>>
>> Other opinions?
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From daroczig at rapporter.net  Thu Nov 10 16:48:12 2016
From: daroczig at rapporter.net (=?UTF-8?Q?Gergely_Dar=C3=B3czi?=)
Date: Thu, 10 Nov 2016 16:48:12 +0100
Subject: [Rd] Memory leak with tons of closed connections
Message-ID: <CAPvvxJV3922JWG--M3CPFMu5n4_+nN+CU7umaRKQ8yJPF5t=dw@mail.gmail.com>

Dear All,

I'm developing an R application running inside of a Java daemon on
multiple threads, and interacting with the parent daemon via stdin and
stdout.

Everything works perfectly fine except for having some memory leaks
somewhere. Simplified version of the R app:

    while (TRUE) {
        con <- file('stdin', open = 'r', blocking = TRUE)
        line <- scan(con, what = character(0), nlines = 1, quiet = TRUE)
        close(con)
    }

This loop uses more and more RAM as time passes (see more on this
below), not sure why, and I have no idea currently on how to debug
this further. Can someone please try to reproduce it and give me some
hints on what is the problem?

Sample bash script to trigger an R process with such memory leak:

    Rscript --vanilla -e "while(TRUE)cat(runif(1),'\n')" | Rscript
--vanilla -e "cat(Sys.getpid(),'\n');while(TRUE){con<-file('stdin',open='r',blocking=TRUE);line<-scan(con,what=character(0),nlines=1,quiet=TRUE);close(con);rm(con);gc()}"

Maybe you have to escape '\n' depending on your shell.

Thanks for reading this and any hints would be highly appreciated!

Best,
Gergely

PS1 see the image posted at
http://stackoverflow.com/questions/40522584/memory-leak-with-closed-connections
on memory usage over time
PS2 the issue doesn't seem to be due to writing more data in the first
R app compared to what the second R app can handle, as I tried the
same with adding a Sys.sleep(0.01) in the first app and that's not an
issue at all in the real application
PS3 I also tried using stdin() instead of file('stdin'), but that did
not work well for the stream running on multiple threads started by
the same parent Java daemon
PS4 I've tried this on Linux using R 3.2.3 and 3.3.2


From maechler at stat.math.ethz.ch  Fri Nov 11 12:08:05 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 11 Nov 2016 12:08:05 +0100
Subject: [Rd] Memory leak with tons of closed connections
In-Reply-To: <CAPvvxJV3922JWG--M3CPFMu5n4_+nN+CU7umaRKQ8yJPF5t=dw@mail.gmail.com>
References: <CAPvvxJV3922JWG--M3CPFMu5n4_+nN+CU7umaRKQ8yJPF5t=dw@mail.gmail.com>
Message-ID: <22565.42645.436216.547440@stat.math.ethz.ch>

>>>>> Gergely Dar?czi <daroczig at rapporter.net>
>>>>>     on Thu, 10 Nov 2016 16:48:12 +0100 writes:

    > Dear All,
    > I'm developing an R application running inside of a Java daemon on
    > multiple threads, and interacting with the parent daemon via stdin and
    > stdout.

    > Everything works perfectly fine except for having some memory leaks
    > somewhere. Simplified version of the R app:

    > while (TRUE) {
    > con <- file('stdin', open = 'r', blocking = TRUE)
    > line <- scan(con, what = character(0), nlines = 1, quiet = TRUE)
    > close(con)
    > }

    > This loop uses more and more RAM as time passes (see more on this
    > below), not sure why, and I have no idea currently on how to debug
    > this further. Can someone please try to reproduce it and give me some
    > hints on what is the problem?

    > Sample bash script to trigger an R process with such memory leak:

    > Rscript --vanilla -e "while(TRUE)cat(runif(1),'\n')" | Rscript
    > --vanilla -e "cat(Sys.getpid(),'\n');while(TRUE){con<-file('stdin',open='r',blocking=TRUE);line<-scan(con,what=character(0),nlines=1,quiet=TRUE);close(con);rm(con);gc()}"

    > Maybe you have to escape '\n' depending on your shell.

    > Thanks for reading this and any hints would be highly appreciated!

I have no hints, sorry... but give some more "data":

I've changed the above to *print* the gc() result every 1000th
iteration, and after 100'000 iterations, there is still no
memory increase from the point of view of R itself.

However, monitoring the process (via 'htop', e.g.) shows about
1 MB per second increase in memory foot print of the process.

One could argue that the error is with the OS / pipe / bash
rather than with R itself... but I'm not expert enough to do
argue  here at all.

Here's my version of your sample bash script and its output:

$  Rscript --vanilla -e "while(TRUE)cat(runif(1),'\n')" | Rscript --vanilla -e "cat(Sys.getpid(),'\n');i <- 0; while(TRUE){con<-file('stdin',open='r',blocking=TRUE);line<-scan(con,what=character(0),nlines=1,quiet=TRUE);close(con);rm(con);a <- gc(); i <- i+1; if(i %% 1000 == 1) {cat('i=',i,'\\n'); print(a)} }"

11059 
i= 1 
         used (Mb) gc trigger  (Mb) max used (Mb)
Ncells  83216  4.5   10000000 534.1   213529 11.5
Vcells 172923  1.4   16777216 128.0   562476  4.3
i= 1001 
         used (Mb) gc trigger  (Mb) max used (Mb)
Ncells  83255  4.5   10000000 534.1   213529 11.5
Vcells 172958  1.4   16777216 128.0   562476  4.3
.......
...............................................
...............................................
...............................................
i= 80001 
         used (Mb) gc trigger  (Mb) max used (Mb)
Ncells  83255  4.5   10000000 534.1   213529 11.5
Vcells 172958  1.4   16777216 128.0   562476  4.3
i= 81001 
         used (Mb) gc trigger  (Mb) max used (Mb)
Ncells  83255  4.5   10000000 534.1   213529 11.5
Vcells 172959  1.4   16777216 128.0   562476  4.3
i= 82001 
         used (Mb) gc trigger  (Mb) max used (Mb)
Ncells  83255  4.5   10000000 534.1   213529 11.5
Vcells 172959  1.4   16777216 128.0   562476  4.3
i= 83001 
         used (Mb) gc trigger  (Mb) max used (Mb)
Ncells  83255  4.5   10000000 534.1   213529 11.5
Vcells 172958  1.4   16777216 128.0   562476  4.3
i= 84001 
         used (Mb) gc trigger  (Mb) max used (Mb)
Ncells  83255  4.5   10000000 534.1   213529 11.5
Vcells 172958  1.4   16777216 128.0   562476  4.3


    > Best,
    > Gergely

    > PS1 see the image posted at
    > http://stackoverflow.com/questions/40522584/memory-leak-with-closed-connections
    > on memory usage over time
    > PS2 the issue doesn't seem to be due to writing more data in the first
    > R app compared to what the second R app can handle, as I tried the
    > same with adding a Sys.sleep(0.01) in the first app and that's not an
    > issue at all in the real application
    > PS3 I also tried using stdin() instead of file('stdin'), but that did
    > not work well for the stream running on multiple threads started by
    > the same parent Java daemon
    > PS4 I've tried this on Linux using R 3.2.3 and 3.3.2

For me, it's Linux, too (Fedora 24), using  'R 3.3.2 patched'..

Martin


From daroczig at rapporter.net  Fri Nov 11 13:46:39 2016
From: daroczig at rapporter.net (=?UTF-8?Q?Gergely_Dar=C3=B3czi?=)
Date: Fri, 11 Nov 2016 13:46:39 +0100
Subject: [Rd] Memory leak with tons of closed connections
In-Reply-To: <22565.42645.436216.547440@stat.math.ethz.ch>
References: <CAPvvxJV3922JWG--M3CPFMu5n4_+nN+CU7umaRKQ8yJPF5t=dw@mail.gmail.com>
	<22565.42645.436216.547440@stat.math.ethz.ch>
Message-ID: <CAPvvxJU2v9XaxtUp1Nt9W5dEhRLKEvtZQpHfh=cXRMCKkYL8Zg@mail.gmail.com>

On Fri, Nov 11, 2016 at 12:08 PM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>>>>>> Gergely Dar?czi <daroczig at rapporter.net>
>>>>>>     on Thu, 10 Nov 2016 16:48:12 +0100 writes:
>
>     > Dear All,
>     > I'm developing an R application running inside of a Java daemon on
>     > multiple threads, and interacting with the parent daemon via stdin and
>     > stdout.
>
>     > Everything works perfectly fine except for having some memory leaks
>     > somewhere. Simplified version of the R app:
>
>     > while (TRUE) {
>     > con <- file('stdin', open = 'r', blocking = TRUE)
>     > line <- scan(con, what = character(0), nlines = 1, quiet = TRUE)
>     > close(con)
>     > }
>
>     > This loop uses more and more RAM as time passes (see more on this
>     > below), not sure why, and I have no idea currently on how to debug
>     > this further. Can someone please try to reproduce it and give me some
>     > hints on what is the problem?
>
>     > Sample bash script to trigger an R process with such memory leak:
>
>     > Rscript --vanilla -e "while(TRUE)cat(runif(1),'\n')" | Rscript
>     > --vanilla -e "cat(Sys.getpid(),'\n');while(TRUE){con<-file('stdin',open='r',blocking=TRUE);line<-scan(con,what=character(0),nlines=1,quiet=TRUE);close(con);rm(con);gc()}"
>
>     > Maybe you have to escape '\n' depending on your shell.
>
>     > Thanks for reading this and any hints would be highly appreciated!
>
> I have no hints, sorry... but give some more "data":
>
> I've changed the above to *print* the gc() result every 1000th
> iteration, and after 100'000 iterations, there is still no
> memory increase from the point of view of R itself.
>
> However, monitoring the process (via 'htop', e.g.) shows about
> 1 MB per second increase in memory foot print of the process.
>
> One could argue that the error is with the OS / pipe / bash
> rather than with R itself... but I'm not expert enough to do
> argue  here at all.
>
> Here's my version of your sample bash script and its output:
>
> $  Rscript --vanilla -e "while(TRUE)cat(runif(1),'\n')" | Rscript --vanilla -e "cat(Sys.getpid(),'\n');i <- 0; while(TRUE){con<-file('stdin',open='r',blocking=TRUE);line<-scan(con,what=character(0),nlines=1,quiet=TRUE);close(con);rm(con);a <- gc(); i <- i+1; if(i %% 1000 == 1) {cat('i=',i,'\\n'); print(a)} }"
>
> 11059
> i= 1
>          used (Mb) gc trigger  (Mb) max used (Mb)
> Ncells  83216  4.5   10000000 534.1   213529 11.5
> Vcells 172923  1.4   16777216 128.0   562476  4.3
> i= 1001
>          used (Mb) gc trigger  (Mb) max used (Mb)
> Ncells  83255  4.5   10000000 534.1   213529 11.5
> Vcells 172958  1.4   16777216 128.0   562476  4.3
> .......
> ...............................................
> ...............................................
> ...............................................
> i= 80001
>          used (Mb) gc trigger  (Mb) max used (Mb)
> Ncells  83255  4.5   10000000 534.1   213529 11.5
> Vcells 172958  1.4   16777216 128.0   562476  4.3
> i= 81001
>          used (Mb) gc trigger  (Mb) max used (Mb)
> Ncells  83255  4.5   10000000 534.1   213529 11.5
> Vcells 172959  1.4   16777216 128.0   562476  4.3
> i= 82001
>          used (Mb) gc trigger  (Mb) max used (Mb)
> Ncells  83255  4.5   10000000 534.1   213529 11.5
> Vcells 172959  1.4   16777216 128.0   562476  4.3
> i= 83001
>          used (Mb) gc trigger  (Mb) max used (Mb)
> Ncells  83255  4.5   10000000 534.1   213529 11.5
> Vcells 172958  1.4   16777216 128.0   562476  4.3
> i= 84001
>          used (Mb) gc trigger  (Mb) max used (Mb)
> Ncells  83255  4.5   10000000 534.1   213529 11.5
> Vcells 172958  1.4   16777216 128.0   562476  4.3
>

Thank you very much, this was very useful!

I tried to do some more research on this, as Gabor Csardi also
suspected that the memory grow might be due to the writer being faster
than the reader, so data is simply accumulating in the input buffer of
the reader. I double checked this via:

    Rscript --vanilla -e
"i<-1;while(TRUE){cat(runif(1),'\n');i<-i+1;if(i==1e6){Sys.sleep(15);i<-1}}"
| Rscript --vanilla -e
"cat(Sys.getpid(),'\n');i<-0;while(TRUE){con<-file('stdin',open='r',blocking=TRUE);line<-scan(con,what=character(0),nlines=1,quiet=TRUE);close(con);rm(con);a<-gc();i<-i+1;if(i%%1e3==1){cat('i=',i,'\\n');print(a)}}"scan(con,what=character(0),nlines=1,quiet=TRUE);close(con);rm(con);gc()}"

So the writer generates a good number of lines, but sleeps for 15
seconds after a while so that the reader can catch up. Monitoring the
memory footprint of the process (by the way gc reported no memory
increase in the reader, just like in Martin's output) shows that the
memory grows when the writer sends data, and it's constant when the
writer is sleeping, but it never decreases: http://imgur.com/r7T02pK

Maybe it's more like an OS-specific question based on this, you are
absolutely right, but I was not able to reproduce the same memory
issue in plain bash via:

    while :;do echo '1';done | bash -c "while :;do read;done"

But I'm not sure if this does exactly the same as the original R
script, so this is rather just a guess.

On the other hand, I tried to modify the original minimal R script in
other ways as well to see which part might result in the strange
memory growth, and it seems that opening the connection once but
keeping the rest of the script (so still generating and reading tons
of lines without any sleep), did not show any memory leak:

    Rscript --vanilla -e "while(TRUE)cat(runif(1),'\n')" | Rscript
--vanilla -e "cat(Sys.getpid(),'\n');con<-file('stdin',open='r',blocking=TRUE);while(TRUE){line<-scan(con,what=character(0),nlines=1,quiet=TRUE);};close(con)"

Based on this, I think I can (should) modify my R application to open
stdin only once and read from that connection in the infinite loop,
but I'm still interested in understanding what's causing the extra
memory usage when opening and closing many connections (if my above
findings are correct).

Thank you very much again, and I'm still looking for any suggestion or
advice on how to debug this further.

>
>     > Best,
>     > Gergely
>
>     > PS1 see the image posted at
>     > http://stackoverflow.com/questions/40522584/memory-leak-with-closed-connections
>     > on memory usage over time
>     > PS2 the issue doesn't seem to be due to writing more data in the first
>     > R app compared to what the second R app can handle, as I tried the
>     > same with adding a Sys.sleep(0.01) in the first app and that's not an
>     > issue at all in the real application
>     > PS3 I also tried using stdin() instead of file('stdin'), but that did
>     > not work well for the stream running on multiple threads started by
>     > the same parent Java daemon
>     > PS4 I've tried this on Linux using R 3.2.3 and 3.3.2
>
> For me, it's Linux, too (Fedora 24), using  'R 3.3.2 patched'..
>
> Martin


From renaud at techunix.technion.ac.il  Fri Nov 11 13:56:52 2016
From: renaud at techunix.technion.ac.il (Renaud Gaujoux)
Date: Fri, 11 Nov 2016 14:56:52 +0200
Subject: [Rd] .S3methods: issue in content of info data.frame
Message-ID: <CAHavPHEdCwPZ4nQGL=nto7CCyaewD1spauFjUqzw-E2gjWFaMg@mail.gmail.com>

Hi,

I was trying to get a list of S3 method for a given generic, along with the
package in which they are defined, and I came across what looks like an
issue in the data.frame returned in attribute 'info'. The column 'from'
mostly gets the value "registered S3method for ..." except for visible
methods. Is this the expected behavior?
See code and output below.

Thank you.

Bests,
Renaud

$ Rscript -e "library(xtable); attr(.S3methods('plot'), 'info');
sessionInfo()"
                   visible                         from generic  isS4
plot.acf             FALSE registered S3method for plot    plot FALSE
plot.data.frame      FALSE registered S3method for plot    plot FALSE
plot.decomposed.ts   FALSE registered S3method for plot    plot FALSE
plot.default          TRUE                     graphics    plot FALSE
plot.dendrogram      FALSE registered S3method for plot    plot FALSE
plot.density         FALSE registered S3method for plot    plot FALSE
plot.ecdf             TRUE                        stats    plot FALSE
plot.factor          FALSE registered S3method for plot    plot FALSE
plot.formula         FALSE registered S3method for plot    plot FALSE
plot.function         TRUE                     graphics    plot FALSE
plot.hclust          FALSE registered S3method for plot    plot FALSE
plot.histogram       FALSE registered S3method for plot    plot FALSE
plot.HoltWinters     FALSE registered S3method for plot    plot FALSE
plot.isoreg          FALSE registered S3method for plot    plot FALSE
plot.lm              FALSE registered S3method for plot    plot FALSE
plot.medpolish       FALSE registered S3method for plot    plot FALSE
plot.mlm             FALSE registered S3method for plot    plot FALSE
plot.ppr             FALSE registered S3method for plot    plot FALSE
plot.prcomp          FALSE registered S3method for plot    plot FALSE
plot.princomp        FALSE registered S3method for plot    plot FALSE
plot.profile.nls     FALSE registered S3method for plot    plot FALSE
plot.raster          FALSE registered S3method for plot    plot FALSE
plot.spec            FALSE registered S3method for plot    plot FALSE
plot.stepfun          TRUE                        stats    plot FALSE
plot.stl             FALSE registered S3method for plot    plot FALSE
plot.table           FALSE registered S3method for plot    plot FALSE
plot.ts               TRUE                        stats    plot FALSE
plot.tskernel        FALSE registered S3method for plot    plot FALSE
plot.TukeyHSD        FALSE registered S3method for plot    plot FALSE
R version 3.3.2 (2016-10-31)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 16.04.1 LTS

locale:
 [1] LC_CTYPE=en_ZA.UTF-8       LC_NUMERIC=C
LC_TIME=en_ZA.UTF-8        LC_COLLATE=en_ZA.UTF-8
LC_MONETARY=en_ZA.UTF-8
 [6] LC_MESSAGES=en_ZA.UTF-8    LC_PAPER=en_ZA.UTF-8
LC_NAME=C                  LC_ADDRESS=C
LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_ZA.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  base

other attached packages:
[1] xtable_1.8-2

loaded via a namespace (and not attached):
[1] tools_3.3.2

	[[alternative HTML version deleted]]


From csardi.gabor at gmail.com  Fri Nov 11 14:12:33 2016
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Fri, 11 Nov 2016 13:12:33 +0000
Subject: [Rd] Memory leak with tons of closed connections
In-Reply-To: <CAPvvxJU2v9XaxtUp1Nt9W5dEhRLKEvtZQpHfh=cXRMCKkYL8Zg@mail.gmail.com>
References: <CAPvvxJV3922JWG--M3CPFMu5n4_+nN+CU7umaRKQ8yJPF5t=dw@mail.gmail.com>
	<22565.42645.436216.547440@stat.math.ethz.ch>
	<CAPvvxJU2v9XaxtUp1Nt9W5dEhRLKEvtZQpHfh=cXRMCKkYL8Zg@mail.gmail.com>
Message-ID: <CABtg=K=FrfpKi67N-ChH6HuuEqY6c-4ymQ9+YCRtbSx8CsUopA@mail.gmail.com>

On Fri, Nov 11, 2016 at 12:46 PM, Gergely Dar?czi
<daroczig at rapporter.net> wrote:
[...]
>> I've changed the above to *print* the gc() result every 1000th
>> iteration, and after 100'000 iterations, there is still no
>> memory increase from the point of view of R itself.

Yes, R does not know about it, it does not manage this memory (any
more), but the R process requested this memory from the OS, and never
gave it back, which is basically the definition of a memory leak. No?

I think the leak is because 'stdin' is special and R opens it with fdopen():
https://github.com/wch/r-source/blob/f8cdadb769561970cc42776f563043ea5e12fe05/src/main/connections.c#L561-L579

and then it does not close it:
https://github.com/wch/r-source/blob/f8cdadb769561970cc42776f563043ea5e12fe05/src/main/connections.c#L636

I understand that R cannot fclose the FILE*, because that would also
close the file descriptor, but anyway, this causes a memory leak. I
think.

It seems that you cannot close the FILE* without closing the
descriptor, so maybe a workaround would be to keep one FILE* open,
instead of calling fdopen() to create new ones every time. Another
possible workaround is to use dup(), but I don't know enough about the
details to be sure.

Gabor

[...]


From brodie.gaslam at yahoo.com  Fri Nov 11 20:13:23 2016
From: brodie.gaslam at yahoo.com (brodie gaslam)
Date: Fri, 11 Nov 2016 19:13:23 +0000 (UTC)
Subject: [Rd] Frames in compiled functions
References: <1209438475.1993878.1478891603236.ref@mail.yahoo.com>
Message-ID: <1209438475.1993878.1478891603236@mail.yahoo.com>

I noticed some problems that cropped in the latest versions of R-devel (2016-11-08 r71639 in my case) for one of my packages.  I _think_ I have narrowed it down to the changes to what gets byte-compiled by default.  The following example run illustrates the problem I'm having:

  compiler::enableJIT(0)
  fun <- function(x) local(as.list(parent.frame(2)))
  fun(1)
  ## $x
  ## [1] 1
  ## 

  

  compiler::cmpfun(fun)(1)
  ## <contents of .GlobalEnv>


Is this considered problematic at all?  If so, might it make sense to broaden the list of functions that disable JIT compilation beyond `browser`?  I'm pretty sure I can work around this issue in my specific use case, but figured it is worth mentioning here since it is a change in behavior.


Regards,

B.


From winstonchang1 at gmail.com  Fri Nov 11 21:07:36 2016
From: winstonchang1 at gmail.com (Winston Chang)
Date: Fri, 11 Nov 2016 14:07:36 -0600
Subject: [Rd] Frames in compiled functions
In-Reply-To: <1209438475.1993878.1478891603236@mail.yahoo.com>
References: <1209438475.1993878.1478891603236.ref@mail.yahoo.com>
	<1209438475.1993878.1478891603236@mail.yahoo.com>
Message-ID: <CAFOpNVHo4xwVayMdwQ+srM80L1ckEh=yiQSLaYOVA0vb2pU8mg@mail.gmail.com>

It looks like the byte compiler is optimizing local() to an
immediately-invoked function, instead of using eval() and substitute(). I
don't know if that's exactly how it's implemented internally, but that's
what it looks like here:

compiler::enableJIT(0)

fun <- function(x) {
   local(sys.calls())
}
fun(1)
## [[1]]
## fun(1)
##
## [[2]]
## local(sys.calls())
##
## [[3]]
## eval.parent(substitute(eval(quote(expr), envir)))
##
## [[4]]
## eval(expr, p)
##
## [[5]]
## eval(expr, envir, enclos)
## call
## [[6]]
## eval(quote(sys.calls()), new.env())
##
## [[7]]
## eval(expr, envir, enclos)


compiler::cmpfun(fun)(1)
## [[1]]
## (compiler::cmpfun(fun))(1)
##
## [[2]]
## (function() sys.calls())()


-Winston


On Fri, Nov 11, 2016 at 1:13 PM, brodie gaslam via R-devel <
r-devel at r-project.org> wrote:

> I noticed some problems that cropped in the latest versions of R-devel
> (2016-11-08 r71639 in my case) for one of my packages.  I _think_ I have
> narrowed it down to the changes to what gets byte-compiled by default.  The
> following example run illustrates the problem I'm having:
>
>   compiler::enableJIT(0)
>   fun <- function(x) local(as.list(parent.frame(2)))
>   fun(1)
>   ## $x
>   ## [1] 1
>   ##
>
>
>
>   compiler::cmpfun(fun)(1)
>   ## <contents of .GlobalEnv>
>
>
> Is this considered problematic at all?  If so, might it make sense to
> broaden the list of functions that disable JIT compilation beyond
> `browser`?  I'm pretty sure I can work around this issue in my specific use
> case, but figured it is worth mentioning here since it is a change in
> behavior.
>
>
> Regards,
>
> B.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From luke-tierney at uiowa.edu  Fri Nov 11 21:36:48 2016
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Fri, 11 Nov 2016 14:36:48 -0600
Subject: [Rd] Frames in compiled functions
In-Reply-To: <CAFOpNVHo4xwVayMdwQ+srM80L1ckEh=yiQSLaYOVA0vb2pU8mg@mail.gmail.com>
References: <1209438475.1993878.1478891603236.ref@mail.yahoo.com>
	<1209438475.1993878.1478891603236@mail.yahoo.com>
	<CAFOpNVHo4xwVayMdwQ+srM80L1ckEh=yiQSLaYOVA0vb2pU8mg@mail.gmail.com>
Message-ID: <alpine.DEB.2.20.1611111435210.2513@luke-Latitude>

That's about it. The plan is to modify the interpreter to do the same
so the inconsistency will go away. Code that is affected by this is
making assumptions that it should not.

Best,

luke

On Fri, 11 Nov 2016, Winston Chang wrote:

> It looks like the byte compiler is optimizing local() to an
> immediately-invoked function, instead of using eval() and substitute(). I
> don't know if that's exactly how it's implemented internally, but that's
> what it looks like here:
>
> compiler::enableJIT(0)
>
> fun <- function(x) {
>   local(sys.calls())
> }
> fun(1)
> ## [[1]]
> ## fun(1)
> ##
> ## [[2]]
> ## local(sys.calls())
> ##
> ## [[3]]
> ## eval.parent(substitute(eval(quote(expr), envir)))
> ##
> ## [[4]]
> ## eval(expr, p)
> ##
> ## [[5]]
> ## eval(expr, envir, enclos)
> ## call
> ## [[6]]
> ## eval(quote(sys.calls()), new.env())
> ##
> ## [[7]]
> ## eval(expr, envir, enclos)
>
>
> compiler::cmpfun(fun)(1)
> ## [[1]]
> ## (compiler::cmpfun(fun))(1)
> ##
> ## [[2]]
> ## (function() sys.calls())()
>
>
> -Winston
>
>
> On Fri, Nov 11, 2016 at 1:13 PM, brodie gaslam via R-devel <
> r-devel at r-project.org> wrote:
>
>> I noticed some problems that cropped in the latest versions of R-devel
>> (2016-11-08 r71639 in my case) for one of my packages.  I _think_ I have
>> narrowed it down to the changes to what gets byte-compiled by default.  The
>> following example run illustrates the problem I'm having:
>>
>>   compiler::enableJIT(0)
>>   fun <- function(x) local(as.list(parent.frame(2)))
>>   fun(1)
>>   ## $x
>>   ## [1] 1
>>   ##
>>
>>
>>
>>   compiler::cmpfun(fun)(1)
>>   ## <contents of .GlobalEnv>
>>
>>
>> Is this considered problematic at all?  If so, might it make sense to
>> broaden the list of functions that disable JIT compilation beyond
>> `browser`?  I'm pretty sure I can work around this issue in my specific use
>> case, but figured it is worth mentioning here since it is a change in
>> behavior.
>>
>>
>> Regards,
>>
>> B.
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From frederik at ofb.net  Sat Nov 12 21:00:28 2016
From: frederik at ofb.net (frederik at ofb.net)
Date: Sat, 12 Nov 2016 12:00:28 -0800
Subject: [Rd] getGraphicsEvent() alternative for cairo graphics device?
In-Reply-To: <57968357.2030509@stat.auckland.ac.nz>
References: <CAN_GHySs42vK5U1xZYP8h7ZPdFyOcHnEZK4Sn91e7htv=7E54A@mail.gmail.com>
	<20160725191747.GB18530@ofb.net>
	<57968357.2030509@stat.auckland.ac.nz>
Message-ID: <20161112200028.GD24681@ofb.net>

Hi Paul,

Just checking in to see what the status is.

>From my perspective it seems logical to split off X11 into a separate
package, so development can proceed at a reasonable rate, but I
haven't yet tried to see if that's even possible.

Thanks,

Frederick

On Tue, Jul 26, 2016 at 09:23:35AM +1200, Paul Murrell wrote:
> Hi
> 
> Taking a look at those patches is now on my todo list, so I may be in touch
> with both of you at some point to request some testing.
> 
> Paul
> 
> On 26/07/16 07:17, frederik at ofb.net wrote:
> > Dear Daniel Greenidge,
> > 
> > To enable getGraphicsEvent on Cairo, you have two patches to choose
> > from:
> > 
> > https://bugs.r-project.org/bugzilla/show_bug.cgi?id=14364
> > https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16951
> > 
> > The second one is by me, and the first one is from five years ago by
> > Hugo Mildenberger.
> > 
> > Both patches are very simple, they move some lines enabling
> > getGrahpicsEvent outside of a if(!cairo) statement. My patch also adds
> > the ability to execute code (e.g. for animation) while the interface
> > is idle.
> > 
> > Top guy Duncan Murdoch has expressed that he doesn't have time to work
> > on applying these patches, and I haven't had any responses from the
> > rest of the R Core Team. I was thinking that perhaps your best bet is
> > to try to create a package called e.g. "X11-fixes" which people can
> > use to get a better X11 library (there is also a bug waiting to be
> > fixed from 2001:
> > https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16702).
> > 
> > I don't know if CRAN would accept such a package, or if you'd have to
> > distribute it via GitHub, but R has excellent tools to facilitate the
> > distribution of code via packages. Whether the R kernel exports enough
> > functions to allow a package to take over event handling, I'm not
> > sure. I was intending to look more into the details of this
> > possibility but haven't had time.
> > 
> > Best wishes,
> > 
> > Frederick
> > 
> > On Mon, Jul 25, 2016 at 02:15:59PM -0400, Daniel Greenidge wrote:
> > > Hi all,
> > > 
> > > I'm writing an interactive plotting function for viewing fMRI
> > > datasets. Currently, I get keypresses using
> > > grDevices::getGraphicsEvent().
> > > 
> > > Unfortunately getGraphicsEvent() only supports the X11(type="Xlib")
> > > graphics device on Unix systems. The Xlib device doesn't support
> > > buffering (i.e. dev.hold() and dev.flush()), so redrawing the plots
> > > causes lots of flickering.
> > > 
> > > Is there a way to get keypresses while using the cairo graphics
> > > device? Alternatively, is there a way to prevent flickering with the
> > > Xlib graphics device?
> > > 
> > > Best,
> > > Daniel Greenidge
> > > 
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > > 
> > 
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> > 
> 
> -- 
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/
>


From nospam at altfeld-im.de  Sun Nov 13 13:11:38 2016
From: nospam at altfeld-im.de (nospam at altfeld-im.de)
Date: Sun, 13 Nov 2016 13:11:38 +0100
Subject: [Rd] Missing objects using dump.frames for post-mortem debugging of
 crashed batch jobs. Bug or gap in documentation?
Message-ID: <1479039098.10901.21.camel@i3770>

Dear R friends,

to allow post-mortem debugging In my Rscript based batch jobs I use

   tryCatch( <R expression>,
          error = function(e)
          {
            dump.frames(to.file = TRUE)
          }) 

to write the called frames into a dump file.

This is similar to the method recommended in the "Writing R extensions"
manual in section 4.2 Debugging R code (page 96):

https://cran.r-project.org/doc/manuals/R-exts.pdf

> options(error = quote({dump.frames(to.file=TRUE); q()}))



When I load the dump later in a new R session to examine the error I use

    load(file = "last.dump.rda")
    debugger(last.dump)

My problem is that the global objects in the workspace are NOT contained
in the dump since "dump.frames" does not save the workspace.

This makes debugging difficult.



For more details see the stackoverflow question + answer in:
https://stackoverflow.com/questions/40421552/r-how-make-dump-frames-include-all-variables-for-later-post-mortem-debugging/40431711#40431711



I think the reason of the problem is:
------------------------------------

If you use dump.files(to.file = FALSE) in an interactive session
debugging works as expected because it creates a global variable called
"last.dump" and the workspace is still loaded.

In the batch job scenario however the workspace is NOT saved in the dump
and therefore lost if you debug the dump in a new session.


Options to solve the issue:
--------------------------

1. Improve the documentation of the R help for "dump.frames" and the
   R_exts manual to propose another code snippet for batch
   job scenarios:

      dump.frames()
      save.image(file = "last.dump.rda")

2. Change the semantics of "dump.frames(to.file = TRUE)" to include
   the workspace in the dump.
   This would change the semantics implied by the function name
   but makes the semantics consistent for both "to.file" param values.


From burnakov at yandex.ru  Sun Nov 13 19:43:03 2016
From: burnakov at yandex.ru (Alexey Burnakov)
Date: Sun, 13 Nov 2016 21:43:03 +0300
Subject: [Rd] dgamma density values in extreme point
Message-ID: <5828B437.6070308@yandex.ru>

Dear R-Devel group,

My name is Alexey, a data scientist from Moscow, currently working for 
Align Technology Inc.

We have recently had a discussion of the results that the dgamma 
function (stats) returns for an extreme point (x == 0).


<dgamma(0,1,1,log = FALSE)

[1] 1


and

<dgamma(0,0.5,1,log = FALSE)
[1] Inf

Density appears to be defined in point zero for the distribution with 
the said parameters.

It looks like the returned value is a limit of f(x) where x --> inf.

Although several other "big" statistics engines like Wolfram and Matlab 
return 0 (zero) for gamma density with the same function parameters 
where x == 0. Which looks like a convention rather than exact answer, in 
our opinion. Is this a correct assumption?

When studies scrupulously, it appears that the density is undefined when 
we get x^0 where x == 0, for example.

As I could not have reached the author of the code for dgamma, could you 
comment on this behavior of the dgamma function in zero? Is it safe to 
use the function given such behaviour. Is it prudent to report density = 
inf in zero? Is there a preferable way to estimate the gamma density in 
zero otherwise?

Regards,
Alexey Burnakov


From murdoch.duncan at gmail.com  Sun Nov 13 20:28:52 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 13 Nov 2016 14:28:52 -0500
Subject: [Rd] dgamma density values in extreme point
In-Reply-To: <5828B437.6070308@yandex.ru>
References: <5828B437.6070308@yandex.ru>
Message-ID: <47ebd9b9-da3d-ca44-b816-9a08069a6dd5@gmail.com>

On 13/11/2016 1:43 PM, Alexey Burnakov wrote:
> Dear R-Devel group,
>
> My name is Alexey, a data scientist from Moscow, currently working for
> Align Technology Inc.
>
> We have recently had a discussion of the results that the dgamma
> function (stats) returns for an extreme point (x == 0).
>
>
> <dgamma(0,1,1,log = FALSE)
>
> [1] 1
>
>
> and
>
> <dgamma(0,0.5,1,log = FALSE)
> [1] Inf
>
> Density appears to be defined in point zero for the distribution with
> the said parameters.
>
> It looks like the returned value is a limit of f(x) where x --> inf.

It's the limit as x --> 0.

>
> Although several other "big" statistics engines like Wolfram and Matlab
> return 0 (zero) for gamma density with the same function parameters
> where x == 0. Which looks like a convention rather than exact answer, in
> our opinion. Is this a correct assumption?
>
> When studies scrupulously, it appears that the density is undefined when
> we get x^0 where x == 0, for example.
>
> As I could not have reached the author of the code for dgamma, could you
> comment on this behavior of the dgamma function in zero? Is it safe to
> use the function given such behaviour. Is it prudent to report density =
> inf in zero? Is there a preferable way to estimate the gamma density in
> zero otherwise?

Using the limit is the most sensible method.  Having a discontinuity in 
the density will cause more problems, e.g. if the density is used in 
quadrature.

As to the "correctness", we all know that the value of a density at any 
particular point is irrelevant.  Only the integrals of densities have 
any meaning.

Duncan Murdoch


From paul at stat.auckland.ac.nz  Sun Nov 13 20:55:20 2016
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Mon, 14 Nov 2016 08:55:20 +1300
Subject: [Rd] getGraphicsEvent() alternative for cairo graphics device?
In-Reply-To: <20161112200028.GD24681@ofb.net>
References: <CAN_GHySs42vK5U1xZYP8h7ZPdFyOcHnEZK4Sn91e7htv=7E54A@mail.gmail.com>
	<20160725191747.GB18530@ofb.net> <57968357.2030509@stat.auckland.ac.nz>
	<20161112200028.GD24681@ofb.net>
Message-ID: <2e6f0306-da86-211a-05dd-aff3d744df40@stat.auckland.ac.nz>

Hi

The current status is that I am keen for people to contribute some 
testing code (see https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16951)

There were also some getGraphicsEvent() changes/fixes suggested by 
Richard Bodewits (cc'ed), for which I am also seeking test code.

Paul

On 13/11/16 09:00, frederik at ofb.net wrote:
> Hi Paul,
>
> Just checking in to see what the status is.
>
> From my perspective it seems logical to split off X11 into a separate
> package, so development can proceed at a reasonable rate, but I
> haven't yet tried to see if that's even possible.
>
> Thanks,
>
> Frederick
>
> On Tue, Jul 26, 2016 at 09:23:35AM +1200, Paul Murrell wrote:
>> Hi
>>
>> Taking a look at those patches is now on my todo list, so I may be in touch
>> with both of you at some point to request some testing.
>>
>> Paul
>>
>> On 26/07/16 07:17, frederik at ofb.net wrote:
>>> Dear Daniel Greenidge,
>>>
>>> To enable getGraphicsEvent on Cairo, you have two patches to choose
>>> from:
>>>
>>> https://bugs.r-project.org/bugzilla/show_bug.cgi?id=14364
>>> https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16951
>>>
>>> The second one is by me, and the first one is from five years ago by
>>> Hugo Mildenberger.
>>>
>>> Both patches are very simple, they move some lines enabling
>>> getGrahpicsEvent outside of a if(!cairo) statement. My patch also adds
>>> the ability to execute code (e.g. for animation) while the interface
>>> is idle.
>>>
>>> Top guy Duncan Murdoch has expressed that he doesn't have time to work
>>> on applying these patches, and I haven't had any responses from the
>>> rest of the R Core Team. I was thinking that perhaps your best bet is
>>> to try to create a package called e.g. "X11-fixes" which people can
>>> use to get a better X11 library (there is also a bug waiting to be
>>> fixed from 2001:
>>> https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16702).
>>>
>>> I don't know if CRAN would accept such a package, or if you'd have to
>>> distribute it via GitHub, but R has excellent tools to facilitate the
>>> distribution of code via packages. Whether the R kernel exports enough
>>> functions to allow a package to take over event handling, I'm not
>>> sure. I was intending to look more into the details of this
>>> possibility but haven't had time.
>>>
>>> Best wishes,
>>>
>>> Frederick
>>>
>>> On Mon, Jul 25, 2016 at 02:15:59PM -0400, Daniel Greenidge wrote:
>>>> Hi all,
>>>>
>>>> I'm writing an interactive plotting function for viewing fMRI
>>>> datasets. Currently, I get keypresses using
>>>> grDevices::getGraphicsEvent().
>>>>
>>>> Unfortunately getGraphicsEvent() only supports the X11(type="Xlib")
>>>> graphics device on Unix systems. The Xlib device doesn't support
>>>> buffering (i.e. dev.hold() and dev.flush()), so redrawing the plots
>>>> causes lots of flickering.
>>>>
>>>> Is there a way to get keypresses while using the cairo graphics
>>>> device? Alternatively, is there a way to prevent flickering with the
>>>> Xlib graphics device?
>>>>
>>>> Best,
>>>> Daniel Greenidge
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> --
>> Dr Paul Murrell
>> Department of Statistics
>> The University of Auckland
>> Private Bag 92019
>> Auckland
>> New Zealand
>> 64 9 3737599 x85392
>> paul at stat.auckland.ac.nz
>> http://www.stat.auckland.ac.nz/~paul/
>>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From csardi.gabor at gmail.com  Sun Nov 13 21:49:57 2016
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Sun, 13 Nov 2016 20:49:57 +0000
Subject: [Rd] Memory leak with tons of closed connections
In-Reply-To: <CABtg=K=FrfpKi67N-ChH6HuuEqY6c-4ymQ9+YCRtbSx8CsUopA@mail.gmail.com>
References: <CAPvvxJV3922JWG--M3CPFMu5n4_+nN+CU7umaRKQ8yJPF5t=dw@mail.gmail.com>
	<22565.42645.436216.547440@stat.math.ethz.ch>
	<CAPvvxJU2v9XaxtUp1Nt9W5dEhRLKEvtZQpHfh=cXRMCKkYL8Zg@mail.gmail.com>
	<CABtg=K=FrfpKi67N-ChH6HuuEqY6c-4ymQ9+YCRtbSx8CsUopA@mail.gmail.com>
Message-ID: <CABtg=KnCS0GcP2zYBG2sbj+A0o9N-hdv94Mq5qrCY4xZn7J+AA@mail.gmail.com>

Using dup() before fdopen() (and calling fclose() on the connection
when it is closed) indeed fixes the memory leak.

FYI,
Gabor

Index: src/main/connections.c
===================================================================
--- src/main/connections.c (revision 71653)
+++ src/main/connections.c (working copy)
@@ -576,7 +576,7 @@
     fp = R_fopen(name, con->mode);
     } else {  /* use file("stdin") to refer to the file and not the console */
 #ifdef HAVE_FDOPEN
- fp = fdopen(0, con->mode);
+        fp = fdopen(dup(0), con->mode);
 #else
  warning(_("cannot open file '%s': %s"), name,
  "fdopen is not supported on this platform");
@@ -633,8 +633,7 @@
 static void file_close(Rconnection con)
 {
     Rfileconn this = con->private;
-    if(con->isopen && strcmp(con->description, "stdin"))
- con->status = fclose(this->fp);
+    con->status = fclose(this->fp);
     con->isopen = FALSE;
 #ifdef Win32
     if(this->anon_file) unlink(this->name);

On Fri, Nov 11, 2016 at 1:12 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
> On Fri, Nov 11, 2016 at 12:46 PM, Gergely Dar?czi
> <daroczig at rapporter.net> wrote:
> [...]
>>> I've changed the above to *print* the gc() result every 1000th
>>> iteration, and after 100'000 iterations, there is still no
>>> memory increase from the point of view of R itself.
>
> Yes, R does not know about it, it does not manage this memory (any
> more), but the R process requested this memory from the OS, and never
> gave it back, which is basically the definition of a memory leak. No?
>
> I think the leak is because 'stdin' is special and R opens it with fdopen():
> https://github.com/wch/r-source/blob/f8cdadb769561970cc42776f563043ea5e12fe05/src/main/connections.c#L561-L579
>
> and then it does not close it:
> https://github.com/wch/r-source/blob/f8cdadb769561970cc42776f563043ea5e12fe05/src/main/connections.c#L636
>
> I understand that R cannot fclose the FILE*, because that would also
> close the file descriptor, but anyway, this causes a memory leak. I
> think.
>
> It seems that you cannot close the FILE* without closing the
> descriptor, so maybe a workaround would be to keep one FILE* open,
> instead of calling fdopen() to create new ones every time. Another
> possible workaround is to use dup(), but I don't know enough about the
> details to be sure.
>
> Gabor
>
> [...]


From frederik at ofb.net  Mon Nov 14 01:41:37 2016
From: frederik at ofb.net (frederik at ofb.net)
Date: Sun, 13 Nov 2016 16:41:37 -0800
Subject: [Rd] getGraphicsEvent() alternative for cairo graphics device?
In-Reply-To: <2e6f0306-da86-211a-05dd-aff3d744df40@stat.auckland.ac.nz>
References: <CAN_GHySs42vK5U1xZYP8h7ZPdFyOcHnEZK4Sn91e7htv=7E54A@mail.gmail.com>
	<20160725191747.GB18530@ofb.net>
	<57968357.2030509@stat.auckland.ac.nz>
	<20161112200028.GD24681@ofb.net>
	<2e6f0306-da86-211a-05dd-aff3d744df40@stat.auckland.ac.nz>
Message-ID: <20161114004137.GA21456@ofb.net>

Hi Paul,

Thank you, for some reason I didn't seem to get an email notification
for your bugzilla comment!

I will try to send you something shortly.

Frederick

On Mon, Nov 14, 2016 at 08:55:20AM +1300, Paul Murrell wrote:
> Hi
> 
> The current status is that I am keen for people to contribute some testing
> code (see https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16951)
> 
> There were also some getGraphicsEvent() changes/fixes suggested by Richard
> Bodewits (cc'ed), for which I am also seeking test code.
> 
> Paul
> 
> On 13/11/16 09:00, frederik at ofb.net wrote:
> > Hi Paul,
> > 
> > Just checking in to see what the status is.
> > 
> > From my perspective it seems logical to split off X11 into a separate
> > package, so development can proceed at a reasonable rate, but I
> > haven't yet tried to see if that's even possible.
> > 
> > Thanks,
> > 
> > Frederick
> > 
> > On Tue, Jul 26, 2016 at 09:23:35AM +1200, Paul Murrell wrote:
> > > Hi
> > > 
> > > Taking a look at those patches is now on my todo list, so I may be in touch
> > > with both of you at some point to request some testing.
> > > 
> > > Paul
> > > 
> > > On 26/07/16 07:17, frederik at ofb.net wrote:
> > > > Dear Daniel Greenidge,
> > > > 
> > > > To enable getGraphicsEvent on Cairo, you have two patches to choose
> > > > from:
> > > > 
> > > > https://bugs.r-project.org/bugzilla/show_bug.cgi?id=14364
> > > > https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16951
> > > > 
> > > > The second one is by me, and the first one is from five years ago by
> > > > Hugo Mildenberger.
> > > > 
> > > > Both patches are very simple, they move some lines enabling
> > > > getGrahpicsEvent outside of a if(!cairo) statement. My patch also adds
> > > > the ability to execute code (e.g. for animation) while the interface
> > > > is idle.
> > > > 
> > > > Top guy Duncan Murdoch has expressed that he doesn't have time to work
> > > > on applying these patches, and I haven't had any responses from the
> > > > rest of the R Core Team. I was thinking that perhaps your best bet is
> > > > to try to create a package called e.g. "X11-fixes" which people can
> > > > use to get a better X11 library (there is also a bug waiting to be
> > > > fixed from 2001:
> > > > https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16702).
> > > > 
> > > > I don't know if CRAN would accept such a package, or if you'd have to
> > > > distribute it via GitHub, but R has excellent tools to facilitate the
> > > > distribution of code via packages. Whether the R kernel exports enough
> > > > functions to allow a package to take over event handling, I'm not
> > > > sure. I was intending to look more into the details of this
> > > > possibility but haven't had time.
> > > > 
> > > > Best wishes,
> > > > 
> > > > Frederick
> > > > 
> > > > On Mon, Jul 25, 2016 at 02:15:59PM -0400, Daniel Greenidge wrote:
> > > > > Hi all,
> > > > > 
> > > > > I'm writing an interactive plotting function for viewing fMRI
> > > > > datasets. Currently, I get keypresses using
> > > > > grDevices::getGraphicsEvent().
> > > > > 
> > > > > Unfortunately getGraphicsEvent() only supports the X11(type="Xlib")
> > > > > graphics device on Unix systems. The Xlib device doesn't support
> > > > > buffering (i.e. dev.hold() and dev.flush()), so redrawing the plots
> > > > > causes lots of flickering.
> > > > > 
> > > > > Is there a way to get keypresses while using the cairo graphics
> > > > > device? Alternatively, is there a way to prevent flickering with the
> > > > > Xlib graphics device?
> > > > > 
> > > > > Best,
> > > > > Daniel Greenidge
> > > > > 
> > > > > ______________________________________________
> > > > > R-devel at r-project.org mailing list
> > > > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > > > > 
> > > > 
> > > > ______________________________________________
> > > > R-devel at r-project.org mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > > > 
> > > 
> > > --
> > > Dr Paul Murrell
> > > Department of Statistics
> > > The University of Auckland
> > > Private Bag 92019
> > > Auckland
> > > New Zealand
> > > 64 9 3737599 x85392
> > > paul at stat.auckland.ac.nz
> > > http://www.stat.auckland.ac.nz/~paul/
> > > 
> 
> -- 
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/
>


From paul at stat.auckland.ac.nz  Mon Nov 14 01:51:08 2016
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Mon, 14 Nov 2016 13:51:08 +1300
Subject: [Rd] getGraphicsEvent() alternative for cairo graphics device?
In-Reply-To: <20161114004137.GA21456@ofb.net>
References: <CAN_GHySs42vK5U1xZYP8h7ZPdFyOcHnEZK4Sn91e7htv=7E54A@mail.gmail.com>
	<20160725191747.GB18530@ofb.net> <57968357.2030509@stat.auckland.ac.nz>
	<20161112200028.GD24681@ofb.net>
	<2e6f0306-da86-211a-05dd-aff3d744df40@stat.auckland.ac.nz>
	<20161114004137.GA21456@ofb.net>
Message-ID: <25bfd94c-28f6-595e-ffb1-2ae2421b5135@stat.auckland.ac.nz>


Great.  Thanks!

Paul

On 14/11/16 13:41, frederik at ofb.net wrote:
> Hi Paul,
>
> Thank you, for some reason I didn't seem to get an email notification
> for your bugzilla comment!
>
> I will try to send you something shortly.
>
> Frederick
>
> On Mon, Nov 14, 2016 at 08:55:20AM +1300, Paul Murrell wrote:
>> Hi
>>
>> The current status is that I am keen for people to contribute some testing
>> code (see https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16951)
>>
>> There were also some getGraphicsEvent() changes/fixes suggested by Richard
>> Bodewits (cc'ed), for which I am also seeking test code.
>>
>> Paul
>>
>> On 13/11/16 09:00, frederik at ofb.net wrote:
>>> Hi Paul,
>>>
>>> Just checking in to see what the status is.
>>>
>>> From my perspective it seems logical to split off X11 into a separate
>>> package, so development can proceed at a reasonable rate, but I
>>> haven't yet tried to see if that's even possible.
>>>
>>> Thanks,
>>>
>>> Frederick
>>>
>>> On Tue, Jul 26, 2016 at 09:23:35AM +1200, Paul Murrell wrote:
>>>> Hi
>>>>
>>>> Taking a look at those patches is now on my todo list, so I may be in touch
>>>> with both of you at some point to request some testing.
>>>>
>>>> Paul
>>>>
>>>> On 26/07/16 07:17, frederik at ofb.net wrote:
>>>>> Dear Daniel Greenidge,
>>>>>
>>>>> To enable getGraphicsEvent on Cairo, you have two patches to choose
>>>>> from:
>>>>>
>>>>> https://bugs.r-project.org/bugzilla/show_bug.cgi?id=14364
>>>>> https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16951
>>>>>
>>>>> The second one is by me, and the first one is from five years ago by
>>>>> Hugo Mildenberger.
>>>>>
>>>>> Both patches are very simple, they move some lines enabling
>>>>> getGrahpicsEvent outside of a if(!cairo) statement. My patch also adds
>>>>> the ability to execute code (e.g. for animation) while the interface
>>>>> is idle.
>>>>>
>>>>> Top guy Duncan Murdoch has expressed that he doesn't have time to work
>>>>> on applying these patches, and I haven't had any responses from the
>>>>> rest of the R Core Team. I was thinking that perhaps your best bet is
>>>>> to try to create a package called e.g. "X11-fixes" which people can
>>>>> use to get a better X11 library (there is also a bug waiting to be
>>>>> fixed from 2001:
>>>>> https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16702).
>>>>>
>>>>> I don't know if CRAN would accept such a package, or if you'd have to
>>>>> distribute it via GitHub, but R has excellent tools to facilitate the
>>>>> distribution of code via packages. Whether the R kernel exports enough
>>>>> functions to allow a package to take over event handling, I'm not
>>>>> sure. I was intending to look more into the details of this
>>>>> possibility but haven't had time.
>>>>>
>>>>> Best wishes,
>>>>>
>>>>> Frederick
>>>>>
>>>>> On Mon, Jul 25, 2016 at 02:15:59PM -0400, Daniel Greenidge wrote:
>>>>>> Hi all,
>>>>>>
>>>>>> I'm writing an interactive plotting function for viewing fMRI
>>>>>> datasets. Currently, I get keypresses using
>>>>>> grDevices::getGraphicsEvent().
>>>>>>
>>>>>> Unfortunately getGraphicsEvent() only supports the X11(type="Xlib")
>>>>>> graphics device on Unix systems. The Xlib device doesn't support
>>>>>> buffering (i.e. dev.hold() and dev.flush()), so redrawing the plots
>>>>>> causes lots of flickering.
>>>>>>
>>>>>> Is there a way to get keypresses while using the cairo graphics
>>>>>> device? Alternatively, is there a way to prevent flickering with the
>>>>>> Xlib graphics device?
>>>>>>
>>>>>> Best,
>>>>>> Daniel Greenidge
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>>
>>>> --
>>>> Dr Paul Murrell
>>>> Department of Statistics
>>>> The University of Auckland
>>>> Private Bag 92019
>>>> Auckland
>>>> New Zealand
>>>> 64 9 3737599 x85392
>>>> paul at stat.auckland.ac.nz
>>>> http://www.stat.auckland.ac.nz/~paul/
>>>>
>>
>> --
>> Dr Paul Murrell
>> Department of Statistics
>> The University of Auckland
>> Private Bag 92019
>> Auckland
>> New Zealand
>> 64 9 3737599 x85392
>> paul at stat.auckland.ac.nz
>> http://www.stat.auckland.ac.nz/~paul/
>>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From frederik at ofb.net  Mon Nov 14 02:53:25 2016
From: frederik at ofb.net (frederik at ofb.net)
Date: Sun, 13 Nov 2016 17:53:25 -0800
Subject: [Rd] getGraphicsEvent() alternative for cairo graphics device?
In-Reply-To: <25bfd94c-28f6-595e-ffb1-2ae2421b5135@stat.auckland.ac.nz>
References: <CAN_GHySs42vK5U1xZYP8h7ZPdFyOcHnEZK4Sn91e7htv=7E54A@mail.gmail.com>
	<20160725191747.GB18530@ofb.net>
	<57968357.2030509@stat.auckland.ac.nz>
	<20161112200028.GD24681@ofb.net>
	<2e6f0306-da86-211a-05dd-aff3d744df40@stat.auckland.ac.nz>
	<20161114004137.GA21456@ofb.net>
	<25bfd94c-28f6-595e-ffb1-2ae2421b5135@stat.auckland.ac.nz>
Message-ID: <20161114015325.GB21456@ofb.net>

Hi Paul,

OK I tried not to make the examples too fancy.

Please let me know what you think. They should probably be amended to
support the Windows platform, but I think that task would be much
easier for someone with access to Windows...

By the way I'm Cc'ing Mark O'Connell who shared with me some great
getGraphicsEvent examples - well, I found them useful, perhaps if
these are going to the R distro somewhere, then his examples should be
included as well.

Thank you,

Frederick

On Mon, Nov 14, 2016 at 01:51:08PM +1300, Paul Murrell wrote:
> 
> Great.  Thanks!
> 
> Paul
> 
> On 14/11/16 13:41, frederik at ofb.net wrote:
> > Hi Paul,
> > 
> > Thank you, for some reason I didn't seem to get an email notification
> > for your bugzilla comment!
> > 
> > I will try to send you something shortly.
> > 
> > Frederick
> > 
> > On Mon, Nov 14, 2016 at 08:55:20AM +1300, Paul Murrell wrote:
> > > Hi
> > > 
> > > The current status is that I am keen for people to contribute some testing
> > > code (see https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16951)
> > > 
> > > There were also some getGraphicsEvent() changes/fixes suggested by Richard
> > > Bodewits (cc'ed), for which I am also seeking test code.
> > > 
> > > Paul
> > > 
> > > On 13/11/16 09:00, frederik at ofb.net wrote:
> > > > Hi Paul,
> > > > 
> > > > Just checking in to see what the status is.
> > > > 
> > > > From my perspective it seems logical to split off X11 into a separate
> > > > package, so development can proceed at a reasonable rate, but I
> > > > haven't yet tried to see if that's even possible.
> > > > 
> > > > Thanks,
> > > > 
> > > > Frederick
> > > > 
> > > > On Tue, Jul 26, 2016 at 09:23:35AM +1200, Paul Murrell wrote:
> > > > > Hi
> > > > > 
> > > > > Taking a look at those patches is now on my todo list, so I may be in touch
> > > > > with both of you at some point to request some testing.
> > > > > 
> > > > > Paul
> > > > > 
> > > > > On 26/07/16 07:17, frederik at ofb.net wrote:
> > > > > > Dear Daniel Greenidge,
> > > > > > 
> > > > > > To enable getGraphicsEvent on Cairo, you have two patches to choose
> > > > > > from:
> > > > > > 
> > > > > > https://bugs.r-project.org/bugzilla/show_bug.cgi?id=14364
> > > > > > https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16951
> > > > > > 
> > > > > > The second one is by me, and the first one is from five years ago by
> > > > > > Hugo Mildenberger.
> > > > > > 
> > > > > > Both patches are very simple, they move some lines enabling
> > > > > > getGrahpicsEvent outside of a if(!cairo) statement. My patch also adds
> > > > > > the ability to execute code (e.g. for animation) while the interface
> > > > > > is idle.
> > > > > > 
> > > > > > Top guy Duncan Murdoch has expressed that he doesn't have time to work
> > > > > > on applying these patches, and I haven't had any responses from the
> > > > > > rest of the R Core Team. I was thinking that perhaps your best bet is
> > > > > > to try to create a package called e.g. "X11-fixes" which people can
> > > > > > use to get a better X11 library (there is also a bug waiting to be
> > > > > > fixed from 2001:
> > > > > > https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16702).
> > > > > > 
> > > > > > I don't know if CRAN would accept such a package, or if you'd have to
> > > > > > distribute it via GitHub, but R has excellent tools to facilitate the
> > > > > > distribution of code via packages. Whether the R kernel exports enough
> > > > > > functions to allow a package to take over event handling, I'm not
> > > > > > sure. I was intending to look more into the details of this
> > > > > > possibility but haven't had time.
> > > > > > 
> > > > > > Best wishes,
> > > > > > 
> > > > > > Frederick
> > > > > > 
> > > > > > On Mon, Jul 25, 2016 at 02:15:59PM -0400, Daniel Greenidge wrote:
> > > > > > > Hi all,
> > > > > > > 
> > > > > > > I'm writing an interactive plotting function for viewing fMRI
> > > > > > > datasets. Currently, I get keypresses using
> > > > > > > grDevices::getGraphicsEvent().
> > > > > > > 
> > > > > > > Unfortunately getGraphicsEvent() only supports the X11(type="Xlib")
> > > > > > > graphics device on Unix systems. The Xlib device doesn't support
> > > > > > > buffering (i.e. dev.hold() and dev.flush()), so redrawing the plots
> > > > > > > causes lots of flickering.
> > > > > > > 
> > > > > > > Is there a way to get keypresses while using the cairo graphics
> > > > > > > device? Alternatively, is there a way to prevent flickering with the
> > > > > > > Xlib graphics device?
> > > > > > > 
> > > > > > > Best,
> > > > > > > Daniel Greenidge
> > > > > > > 
> > > > > > > ______________________________________________
> > > > > > > R-devel at r-project.org mailing list
> > > > > > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > > > > > > 
> > > > > > 
> > > > > > ______________________________________________
> > > > > > R-devel at r-project.org mailing list
> > > > > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > > > > > 
> > > > > 
> > > > > --
> > > > > Dr Paul Murrell
> > > > > Department of Statistics
> > > > > The University of Auckland
> > > > > Private Bag 92019
> > > > > Auckland
> > > > > New Zealand
> > > > > 64 9 3737599 x85392
> > > > > paul at stat.auckland.ac.nz
> > > > > http://www.stat.auckland.ac.nz/~paul/
> > > > > 
> > > 
> > > --
> > > Dr Paul Murrell
> > > Department of Statistics
> > > The University of Auckland
> > > Private Bag 92019
> > > Auckland
> > > New Zealand
> > > 64 9 3737599 x85392
> > > paul at stat.auckland.ac.nz
> > > http://www.stat.auckland.ac.nz/~paul/
> > > 
> 
> -- 
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/
> 
-------------- next part --------------
# Examples for "onIdle" function in getGraphicsEvent
# FHE 13 Nov 2016 - public domain

# This should produce a "plot" display with 50 random points connected
# by lines. The points will scroll to the right at a fixed speed,
# which depends on how fast your computer is. Closing the plot window
# should terminate the function cleanly, and pressing Ctrl-C at the
# prompt should have the same effect.
testIdle1 = function() {
  # cairo is the flicker-free option for X11
  X11(type="cairo");
  on.exit(dev.off());

  ps=matrix(runif(100),ncol=2)
  getGraphicsEvent(
                   onIdle=function() {
                     plot(ps[,1],ps[,2],type="b",
                          xlim=c(0,1),ylim=c(0,1));
                     ps<<-t(t(ps)+c(0.001,0)) %% 1
                     NULL
                   }
                   );
}

# This is a more interactive example. You have to move the mouse to
# start, and then the mouse will leave a trail which shrinks and
# rotates towards the center of the screen. There is a 0.01 second
# delay (currently Linux-specific, since Sys.sleep() can't be used in
# onIdle) between successive updates, so, unlike the first example,
# this shouldn't use 100% of your CPU (I measured 20% on a 3.7GHz
# Xeon). Closing the window or pressing "q" should terminate the
# function, but sometimes Ctrl-C at the prompt is ignored due to the
# system() call.
testIdle2 = function(factor=0.99,theta=0.03) {
  n=200;

  xform=factor*
    rbind(c(cos(theta),-sin(theta)),
          c(sin(theta),cos(theta)));
  
  lastp=c(0,0);
  ps=matrix(lastp,ncol=2);

  # cairo is the flicker-free option for X11
  X11(type="cairo");
  on.exit(dev.off());

  getGraphicsEvent(
                   onIdle=function() {
                     plot(ps[,1],ps[,2],
                          xlim=c(-1,1),ylim=c(-1,1),type="l");
                     
                     ps<<-head(rbind(lastp,ps%*%xform),n);

                     # for Windows, comment or change appropriately
                     system("sleep 0.02");
                     
                     NULL
                   },
                   onMouseMove=function(buttons,x,y) {
                     newX=grconvertX(x,"ndc","user");
                     newY=grconvertY(y,"ndc","user");
                     lastp<<-c(newX,newY);
                     NULL;
                   },
                   onKeybd=function(key) {
                     if(key=="q") { 1 }
                     else { NULL }
                   }
                   );
}

From maechler at stat.math.ethz.ch  Mon Nov 14 11:05:15 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 14 Nov 2016 11:05:15 +0100
Subject: [Rd] Memory leak with tons of closed connections
In-Reply-To: <CABtg=KnCS0GcP2zYBG2sbj+A0o9N-hdv94Mq5qrCY4xZn7J+AA@mail.gmail.com>
References: <CAPvvxJV3922JWG--M3CPFMu5n4_+nN+CU7umaRKQ8yJPF5t=dw@mail.gmail.com>
	<22565.42645.436216.547440@stat.math.ethz.ch>
	<CAPvvxJU2v9XaxtUp1Nt9W5dEhRLKEvtZQpHfh=cXRMCKkYL8Zg@mail.gmail.com>
	<CABtg=K=FrfpKi67N-ChH6HuuEqY6c-4ymQ9+YCRtbSx8CsUopA@mail.gmail.com>
	<CABtg=KnCS0GcP2zYBG2sbj+A0o9N-hdv94Mq5qrCY4xZn7J+AA@mail.gmail.com>
Message-ID: <22569.35931.449103.667281@stat.math.ethz.ch>

>>>>> G?bor Cs?rdi <csardi.gabor at gmail.com>
>>>>>     on Sun, 13 Nov 2016 20:49:57 +0000 writes:

> Using dup() before fdopen() (and calling fclose() on the connection
> when it is closed) indeed fixes the memory leak.
> 

Thank you, G?bor!
Yes I can confirm that this fixes the memory leak.

I'm testing ('make check-all') currently and then (probably) will
commit the patch.... R-devel only for the time being.

Martin

> FYI,
> Gabor
> 
> Index: src/main/connections.c
> ===================================================================
> --- src/main/connections.c (revision 71653)
> +++ src/main/connections.c (working copy)
> @@ -576,7 +576,7 @@
>      fp = R_fopen(name, con->mode);
>      } else {  /* use file("stdin") to refer to the file and not the console */
>  #ifdef HAVE_FDOPEN
> - fp = fdopen(0, con->mode);
> +        fp = fdopen(dup(0), con->mode);
>  #else
>   warning(_("cannot open file '%s': %s"), name,
>   "fdopen is not supported on this platform");
> @@ -633,8 +633,7 @@
>  static void file_close(Rconnection con)
>  {
>      Rfileconn this = con->private;
> -    if(con->isopen && strcmp(con->description, "stdin"))
> - con->status = fclose(this->fp);
> +    con->status = fclose(this->fp);
>      con->isopen = FALSE;
>  #ifdef Win32
>      if(this->anon_file) unlink(this->name);
> 
> On Fri, Nov 11, 2016 at 1:12 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
> > On Fri, Nov 11, 2016 at 12:46 PM, Gergely Dar?czi
> > <daroczig at rapporter.net> wrote:
> > [...]
> >>> I've changed the above to *print* the gc() result every 1000th
> >>> iteration, and after 100'000 iterations, there is still no
> >>> memory increase from the point of view of R itself.
> >
> > Yes, R does not know about it, it does not manage this memory (any
> > more), but the R process requested this memory from the OS, and never
> > gave it back, which is basically the definition of a memory leak. No?
> >
> > I think the leak is because 'stdin' is special and R opens it with fdopen():
> > https://github.com/wch/r-source/blob/f8cdadb769561970cc42776f563043ea5e12fe05/src/main/connections.c#L561-L579
> >
> > and then it does not close it:
> > https://github.com/wch/r-source/blob/f8cdadb769561970cc42776f563043ea5e12fe05/src/main/connections.c#L636
> >
> > I understand that R cannot fclose the FILE*, because that would also
> > close the file descriptor, but anyway, this causes a memory leak. I
> > think.
> >
> > It seems that you cannot close the FILE* without closing the
> > descriptor, so maybe a workaround would be to keep one FILE* open,
> > instead of calling fdopen() to create new ones every time. Another
> > possible workaround is to use dup(), but I don't know enough about the
> > details to be sure.
> >
> > Gabor
> >
> > [...]


From maechler at stat.math.ethz.ch  Mon Nov 14 11:34:30 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 14 Nov 2016 11:34:30 +0100
Subject: [Rd] Missing objects using dump.frames for post-mortem
 debugging of crashed batch jobs. Bug or gap in documentation?
In-Reply-To: <1479039098.10901.21.camel@i3770>
References: <1479039098.10901.21.camel@i3770>
Message-ID: <22569.37686.138034.62176@stat.math.ethz.ch>

>>>>> nospam at altfeld-im de <nospam at altfeld-im.de>
>>>>>     on Sun, 13 Nov 2016 13:11:38 +0100 writes:

    > Dear R friends, to allow post-mortem debugging In my
    > Rscript based batch jobs I use

    >    tryCatch( <R expression>, error = function(e) {
    > dump.frames(to.file = TRUE) })

    > to write the called frames into a dump file.

    > This is similar to the method recommended in the "Writing
    > R extensions" manual in section 4.2 Debugging R code (page
    > 96):

    > https://cran.r-project.org/doc/manuals/R-exts.pdf

    >> options(error = quote({dump.frames(to.file=TRUE); q()}))



    > When I load the dump later in a new R session to examine
    > the error I use

    >     load(file = "last.dump.rda") debugger(last.dump)

    > My problem is that the global objects in the workspace are
    > NOT contained in the dump since "dump.frames" does not
    > save the workspace.

    > This makes debugging difficult.



    > For more details see the stackoverflow question + answer
    > in:
    > https://stackoverflow.com/questions/40421552/r-how-make-dump-frames-include-all-variables-for-later-post-mortem-debugging/40431711#40431711



    > I think the reason of the problem is:
    > ------------------------------------

    > If you use dump.files(to.file = FALSE) in an interactive
    > session debugging works as expected because it creates a
    > global variable called "last.dump" and the workspace is
    > still loaded.

    > In the batch job scenario however the workspace is NOT
    > saved in the dump and therefore lost if you debug the dump
    > in a new session.


    > Options to solve the issue:
    > --------------------------

    > 1. Improve the documentation of the R help for
    > "dump.frames" and the R_exts manual to propose another
    > code snippet for batch job scenarios:

    >       dump.frames() save.image(file = "last.dump.rda")

    > 2. Change the semantics of "dump.frames(to.file = TRUE)"
    > to include the workspace in the dump.  This would change
    > the semantics implied by the function name but makes the
    > semantics consistent for both "to.file" param values.

There is a third option, already in place for three months now:
Andreas Kersting did propose it (nicely, as a wish),
	https://bugs.r-project.org/bugzilla/show_bug.cgi?id=17116
and I had added it to the development version of R back then :

------------------------------------------------------------------------
r71102 | maechler | 2016-08-16 17:36:10 +0200 (Tue, 16 Aug 2016) | 1 line

dump.frames(*, include.GlobalEnv)
------------------------------------------------------------------------

So, if you (or others) want to use this before next spring,
you should install a version of R-devel
and you use that, with

  tryCatch( <R expression>,
           error = function(e)
	           dump.frames(to.file = TRUE, include.GlobalEnv = TRUE))

Using R-devel is nice and helpful for the R community, as you
will help finding bugs/problems in the new features (and
possibly changed features) we've introduced there. 


Best regards,
Martin


From muschellij2 at gmail.com  Mon Nov 14 16:32:16 2016
From: muschellij2 at gmail.com (John Muschelli)
Date: Mon, 14 Nov 2016 10:32:16 -0500
Subject: [Rd] Read.dcf with no newline ending: gzfile drops last line
Message-ID: <CAFsq6G8h+HUb9qQK2TfkKZUvPqM-7VsTz=AEWsESvdL4-az+LA@mail.gmail.com>

I don't know if this is a bug per se, but an undesired behavior in
read.dcf.  read.dcf takes a file argument and passes it to gzfile if
it's a character:
    if (is.character(file)) {
        file <- gzfile(file)
        on.exit(close(file))
    }
This gzfile connection is passed to readLines (line #39):
lines <- readLines(file)

If no newline is at the end of the file, readLines doesn't give a
warning (I think appropriate behavior).  If a DESCRIPTION file doesn't
happen to have a newline at the end of it (odd, but it may happen),
then the last tag is dropped:

> x = "Package: test
+ Type: Package"
>
> ######################################
> # No Newline in file
> ######################################
> fname = tempfile()
> writeLines(x, fname, sep = "")
>
> ### readlines with character - warning but all fields
> readLines(fname)
[1] "Package: test" "Type: Package"
Warning message:
In readLines(fname) :
  incomplete final line found on
'/var/folders/1s/wrtqcpxn685_zk570bnx9_rr0000gr/T//Rtmpz95dsT/file180a65a6b745'
> ### readlines with file connection - warning but all fields
> file_con <- file(fname)
> readLines(file_con)
[1] "Package: test" "Type: Package"
Warning message:
In readLines(file_con) :
  incomplete final line found on
'/var/folders/1s/wrtqcpxn685_zk570bnx9_rr0000gr/T//Rtmpz95dsT/file180a65a6b745'
>
> ### readlines with gzfile connection
> ## no warning and drops last field
> gz_con = gzfile(fname)
> readLines(gz_con) # ONLY 1 lines!
[1] "Package: test"
>
> ######################################
> # No Newline in file - fine
> ######################################
> ### readlines with gzfile connection
> ## no warning and drops last field but OK
> writeLines(x, fname, sep = "\n")
> gz_con = gzfile(fname)
> readLines(gz_con)
[1] "Package: test" "Type: Package"

Currently I use file(fname) before read.dcf to be sure a warning
occurs, but all fields are read.  I didn't see anything in read.dcf
help about this.  readLines states clearly:
"If the final line is incomplete (no final EOL marker) the behaviour
depends on whether the connection is blocking or not", but it's not
100% clear that read.dcf uses gzfile if the file is not compressed.


Thanks
John


From suharto_anggono at yahoo.com  Mon Nov 14 17:12:22 2016
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Mon, 14 Nov 2016 16:12:22 +0000 (UTC)
Subject: [Rd] Potential integer overflow in 'do_mapply'
References: <554070662.3822241.1479139942826.ref@mail.yahoo.com>
Message-ID: <554070662.3822241.1479139942826@mail.yahoo.com>

Function 'do_mapply' in mapply.c has the following fragment.
    for (int i = 0; i < longest; i++) {

Variable 'longest' is declared as R_xlen_t. Its value can be larger than the maximum int.

In the fragment, when 'longest' is larger than the maximum int, when 'i' reaches the maximum int, i++ will lead to overflow.


From paul at stat.auckland.ac.nz  Mon Nov 14 20:43:30 2016
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Tue, 15 Nov 2016 08:43:30 +1300
Subject: [Rd] getGraphicsEvent() alternative for cairo graphics device?
In-Reply-To: <20161114015325.GB21456@ofb.net>
References: <CAN_GHySs42vK5U1xZYP8h7ZPdFyOcHnEZK4Sn91e7htv=7E54A@mail.gmail.com>
	<20160725191747.GB18530@ofb.net> <57968357.2030509@stat.auckland.ac.nz>
	<20161112200028.GD24681@ofb.net>
	<2e6f0306-da86-211a-05dd-aff3d744df40@stat.auckland.ac.nz>
	<20161114004137.GA21456@ofb.net>
	<25bfd94c-28f6-595e-ffb1-2ae2421b5135@stat.auckland.ac.nz>
	<20161114015325.GB21456@ofb.net>
Message-ID: <039e4e77-d905-b407-ddfa-1578720b694b@stat.auckland.ac.nz>


Thanks Frederick.

Mark, if you have any examples to share, they would also be gratefully 
received.

Paul

On 14/11/16 14:53, frederik at ofb.net wrote:
> Hi Paul,
>
> OK I tried not to make the examples too fancy.
>
> Please let me know what you think. They should probably be amended to
> support the Windows platform, but I think that task would be much
> easier for someone with access to Windows...
>
> By the way I'm Cc'ing Mark O'Connell who shared with me some great
> getGraphicsEvent examples - well, I found them useful, perhaps if
> these are going to the R distro somewhere, then his examples should be
> included as well.
>
> Thank you,
>
> Frederick
>
> On Mon, Nov 14, 2016 at 01:51:08PM +1300, Paul Murrell wrote:
>>
>> Great.  Thanks!
>>
>> Paul
>>
>> On 14/11/16 13:41, frederik at ofb.net wrote:
>>> Hi Paul,
>>>
>>> Thank you, for some reason I didn't seem to get an email notification
>>> for your bugzilla comment!
>>>
>>> I will try to send you something shortly.
>>>
>>> Frederick
>>>
>>> On Mon, Nov 14, 2016 at 08:55:20AM +1300, Paul Murrell wrote:
>>>> Hi
>>>>
>>>> The current status is that I am keen for people to contribute some testing
>>>> code (see https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16951)
>>>>
>>>> There were also some getGraphicsEvent() changes/fixes suggested by Richard
>>>> Bodewits (cc'ed), for which I am also seeking test code.
>>>>
>>>> Paul
>>>>
>>>> On 13/11/16 09:00, frederik at ofb.net wrote:
>>>>> Hi Paul,
>>>>>
>>>>> Just checking in to see what the status is.
>>>>>
>>>>> From my perspective it seems logical to split off X11 into a separate
>>>>> package, so development can proceed at a reasonable rate, but I
>>>>> haven't yet tried to see if that's even possible.
>>>>>
>>>>> Thanks,
>>>>>
>>>>> Frederick
>>>>>
>>>>> On Tue, Jul 26, 2016 at 09:23:35AM +1200, Paul Murrell wrote:
>>>>>> Hi
>>>>>>
>>>>>> Taking a look at those patches is now on my todo list, so I may be in touch
>>>>>> with both of you at some point to request some testing.
>>>>>>
>>>>>> Paul
>>>>>>
>>>>>> On 26/07/16 07:17, frederik at ofb.net wrote:
>>>>>>> Dear Daniel Greenidge,
>>>>>>>
>>>>>>> To enable getGraphicsEvent on Cairo, you have two patches to choose
>>>>>>> from:
>>>>>>>
>>>>>>> https://bugs.r-project.org/bugzilla/show_bug.cgi?id=14364
>>>>>>> https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16951
>>>>>>>
>>>>>>> The second one is by me, and the first one is from five years ago by
>>>>>>> Hugo Mildenberger.
>>>>>>>
>>>>>>> Both patches are very simple, they move some lines enabling
>>>>>>> getGrahpicsEvent outside of a if(!cairo) statement. My patch also adds
>>>>>>> the ability to execute code (e.g. for animation) while the interface
>>>>>>> is idle.
>>>>>>>
>>>>>>> Top guy Duncan Murdoch has expressed that he doesn't have time to work
>>>>>>> on applying these patches, and I haven't had any responses from the
>>>>>>> rest of the R Core Team. I was thinking that perhaps your best bet is
>>>>>>> to try to create a package called e.g. "X11-fixes" which people can
>>>>>>> use to get a better X11 library (there is also a bug waiting to be
>>>>>>> fixed from 2001:
>>>>>>> https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16702).
>>>>>>>
>>>>>>> I don't know if CRAN would accept such a package, or if you'd have to
>>>>>>> distribute it via GitHub, but R has excellent tools to facilitate the
>>>>>>> distribution of code via packages. Whether the R kernel exports enough
>>>>>>> functions to allow a package to take over event handling, I'm not
>>>>>>> sure. I was intending to look more into the details of this
>>>>>>> possibility but haven't had time.
>>>>>>>
>>>>>>> Best wishes,
>>>>>>>
>>>>>>> Frederick
>>>>>>>
>>>>>>> On Mon, Jul 25, 2016 at 02:15:59PM -0400, Daniel Greenidge wrote:
>>>>>>>> Hi all,
>>>>>>>>
>>>>>>>> I'm writing an interactive plotting function for viewing fMRI
>>>>>>>> datasets. Currently, I get keypresses using
>>>>>>>> grDevices::getGraphicsEvent().
>>>>>>>>
>>>>>>>> Unfortunately getGraphicsEvent() only supports the X11(type="Xlib")
>>>>>>>> graphics device on Unix systems. The Xlib device doesn't support
>>>>>>>> buffering (i.e. dev.hold() and dev.flush()), so redrawing the plots
>>>>>>>> causes lots of flickering.
>>>>>>>>
>>>>>>>> Is there a way to get keypresses while using the cairo graphics
>>>>>>>> device? Alternatively, is there a way to prevent flickering with the
>>>>>>>> Xlib graphics device?
>>>>>>>>
>>>>>>>> Best,
>>>>>>>> Daniel Greenidge
>>>>>>>>
>>>>>>>> ______________________________________________
>>>>>>>> R-devel at r-project.org mailing list
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>>>
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-devel at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>>
>>>>>>
>>>>>> --
>>>>>> Dr Paul Murrell
>>>>>> Department of Statistics
>>>>>> The University of Auckland
>>>>>> Private Bag 92019
>>>>>> Auckland
>>>>>> New Zealand
>>>>>> 64 9 3737599 x85392
>>>>>> paul at stat.auckland.ac.nz
>>>>>> http://www.stat.auckland.ac.nz/~paul/
>>>>>>
>>>>
>>>> --
>>>> Dr Paul Murrell
>>>> Department of Statistics
>>>> The University of Auckland
>>>> Private Bag 92019
>>>> Auckland
>>>> New Zealand
>>>> 64 9 3737599 x85392
>>>> paul at stat.auckland.ac.nz
>>>> http://www.stat.auckland.ac.nz/~paul/
>>>>
>>
>> --
>> Dr Paul Murrell
>> Department of Statistics
>> The University of Auckland
>> Private Bag 92019
>> Auckland
>> New Zealand
>> 64 9 3737599 x85392
>> paul at stat.auckland.ac.nz
>> http://www.stat.auckland.ac.nz/~paul/
>>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From nospam at altfeld-im.de  Tue Nov 15 01:15:46 2016
From: nospam at altfeld-im.de (nospam at altfeld-im.de)
Date: Tue, 15 Nov 2016 01:15:46 +0100
Subject: [Rd] Missing objects using dump.frames for post-mortem
 debugging of crashed batch jobs. Bug or gap in documentation?
In-Reply-To: <22569.37686.138034.62176@stat.math.ethz.ch>
References: <1479039098.10901.21.camel@i3770>
	<22569.37686.138034.62176@stat.math.ethz.ch>
Message-ID: <1479168946.10901.48.camel@i3770>

Martin, thanks for the good news and sorry for wasting your (and others
time) by not doing my homework and query bugzilla first (lesson learned!
).

I have tested the new implementation from R-devel and observe a semantic
difference when playing with the parameters:

  # Test script 1
  g <- "global"
  f <- function(p) {
    l <- "local"
    dump.frames()
  }
  f("parameter")

results in
  # > debugger()
  # Message:  object 'server' not foundAvailable environments had calls:
  # 1: source("~/.active-rstudio-document", echo = TRUE)
  # 2: withVisible(eval(ei, envir))
  # 3: eval(ei, envir)
  # 4: eval(expr, envir, enclos)
  # 5: .active-rstudio-document#9: f("parameter")
  # 
  # Enter an environment number, or 0 to exit  
  # Selection: 5
  # Browsing in the environment with call:
  #   .active-rstudio-document#9: f("parameter")
  # Called from: debugger.look(ind)
  # Browse[1]> g
  # [1] "global"
  # Browse[1]> 

while dumping to a file

  # Test script 2
  g <- "global"
  f <- function(p) {
    l <- "local"
    dump.frames(to.file = TRUE, include.GlobalEnv = TRUE)
  }
  f("parameter")

results in
  # > load("last.dump.rda")
  # > debugger()
  # Message:  object 'server' not foundAvailable environments had calls:
  # 1: .GlobalEnv
  # 2: source("~/.active-rstudio-document", echo = TRUE)
  # 3: withVisible(eval(ei, envir))
  # 4: eval(ei, envir)
  # 5: eval(expr, envir, enclos)
  # 6: .active-rstudio-document#11: f("parameter")
  # 
  # Enter an environment number, or 0 to exit  
  # Selection: 6
  # Browsing in the environment with call:
  #   .active-rstudio-document#11: f("parameter")
  # Called from: debugger.look(ind)
  # Browse[1]> g
  # Error: object 'g' not found
  # Browse[1]> 

The semantic difference is that the global variable "g" is visible
within the function "f" in the first version, but not in the second
version.

If I dump to a file and load and debug it then the search path through
the
frames is not the same during run time vs. debug time.

An implementation with the same semantics could be achieved
by applying this workaround currently:

  dump.frames()
  save.image(file = "last.dump.rda")

Does it possibly make sense to unify the semantics?

THX!


On Mon, 2016-11-14 at 11:34 +0100, Martin Maechler wrote:
> >>>>> nospam at altfeld-im de <nospam at altfeld-im.de>
> >>>>>     on Sun, 13 Nov 2016 13:11:38 +0100 writes:
> 
>     > Dear R friends, to allow post-mortem debugging In my
>     > Rscript based batch jobs I use
> 
>     >    tryCatch( <R expression>, error = function(e) {
>     > dump.frames(to.file = TRUE) })
> 
>     > to write the called frames into a dump file.
> 
>     > This is similar to the method recommended in the "Writing
>     > R extensions" manual in section 4.2 Debugging R code (page
>     > 96):
> 
>     > https://cran.r-project.org/doc/manuals/R-exts.pdf
> 
>     >> options(error = quote({dump.frames(to.file=TRUE); q()}))
> 
> 
> 
>     > When I load the dump later in a new R session to examine
>     > the error I use
> 
>     >     load(file = "last.dump.rda") debugger(last.dump)
> 
>     > My problem is that the global objects in the workspace are
>     > NOT contained in the dump since "dump.frames" does not
>     > save the workspace.
> 
>     > This makes debugging difficult.
> 
> 
> 
>     > For more details see the stackoverflow question + answer
>     > in:
>     > https://stackoverflow.com/questions/40421552/r-how-make-dump-frames-include-all-variables-for-later-post-mortem-debugging/40431711#40431711
> 
> 
> 
>     > I think the reason of the problem is:
>     > ------------------------------------
> 
>     > If you use dump.files(to.file = FALSE) in an interactive
>     > session debugging works as expected because it creates a
>     > global variable called "last.dump" and the workspace is
>     > still loaded.
> 
>     > In the batch job scenario however the workspace is NOT
>     > saved in the dump and therefore lost if you debug the dump
>     > in a new session.
> 
> 
>     > Options to solve the issue:
>     > --------------------------
> 
>     > 1. Improve the documentation of the R help for
>     > "dump.frames" and the R_exts manual to propose another
>     > code snippet for batch job scenarios:
> 
>     >       dump.frames() save.image(file = "last.dump.rda")
> 
>     > 2. Change the semantics of "dump.frames(to.file = TRUE)"
>     > to include the workspace in the dump.  This would change
>     > the semantics implied by the function name but makes the
>     > semantics consistent for both "to.file" param values.
> 
> There is a third option, already in place for three months now:
> Andreas Kersting did propose it (nicely, as a wish),
> 	https://bugs.r-project.org/bugzilla/show_bug.cgi?id=17116
> and I had added it to the development version of R back then :
> 
> ------------------------------------------------------------------------
> r71102 | maechler | 2016-08-16 17:36:10 +0200 (Tue, 16 Aug 2016) | 1 line
> 
> dump.frames(*, include.GlobalEnv)
> ------------------------------------------------------------------------
> 
> So, if you (or others) want to use this before next spring,
> you should install a version of R-devel
> and you use that, with
> 
>   tryCatch( <R expression>,
>            error = function(e)
> 	           dump.frames(to.file = TRUE, include.GlobalEnv = TRUE))
> 
> Using R-devel is nice and helpful for the R community, as you
> will help finding bugs/problems in the new features (and
> possibly changed features) we've introduced there. 
> 
> 
> Best regards,
> Martin


From hpages at fredhutch.org  Tue Nov 15 07:10:08 2016
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Mon, 14 Nov 2016 22:10:08 -0800
Subject: [Rd] creating a long list puts R in a state where many things stop
	working
Message-ID: <3fc0697c-2c5b-f18c-22f8-76d0104ffefc@fredhutch.org>

Hi,

After I create a long list e.g. with

   x <- vector(mode="list", length=3e9)

many bad things start to happen e.g. some things stop working with a
spurious error message:

   gc()
   # Error in gc() :
   #   long vectors not supported yet: 
/home/hpages/src/R-3.3.2/src/main/memory.c:1137

   x_lens <- lengths(x)
   # Error in lengths(x) :
   #  long vectors not supported yet: 
/home/hpages/src/R-3.3.2/src/main/memory.c:1668

But then some of them work again:

   gc()
   #          used (Mb) gc trigger    (Mb)   max used    (Mb)
   # Ncells  57046  3.1     368000    19.7     350000    18.7
   # Vcells 138060  1.1 4320596678 32963.6 4500397915 34335.4

while others still fail but now with a different error message:

   x_lens <- lengths(x)
   # Error: evaluation nested too deeply: infinite recursion / 
options(expressions=)?

etc...

The more I go, the more weird things I see so clearly my session
got corrupted. Finally, and not too surprisingly, after playing a
little bit more, my session eventually crashed.

Thanks,
H.

 > sessionInfo()
R version 3.3.2 (2016-10-31)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.3 LTS

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From maechler at stat.math.ethz.ch  Tue Nov 15 09:24:15 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 15 Nov 2016 09:24:15 +0100
Subject: [Rd] Missing objects using dump.frames for post-mortem
 debugging of crashed batch jobs. Bug or gap in documentation?
In-Reply-To: <1479168946.10901.48.camel@i3770>
References: <1479039098.10901.21.camel@i3770>
	<22569.37686.138034.62176@stat.math.ethz.ch>
	<1479168946.10901.48.camel@i3770>
Message-ID: <22570.50735.695455.828208@stat.math.ethz.ch>

>>>>> nospam at altfeld-im de <nospam at altfeld-im.de>
>>>>>     on Tue, 15 Nov 2016 01:15:46 +0100 writes:

> Martin, thanks for the good news and sorry for wasting your (and others
> time) by not doing my homework and query bugzilla first (lesson learned!
> ).
> 
> I have tested the new implementation from R-devel and observe a semantic
> difference when playing with the parameters:
> 
>   # Test script 1
>   g <- "global"
>   f <- function(p) {
>     l <- "local"
>     dump.frames()
>   }
>   f("parameter")
> 
> results in
>   # > debugger()
>   # Message:  object 'server' not foundAvailable environments had calls:
>   # 1: source("~/.active-rstudio-document", echo = TRUE)
>   # 2: withVisible(eval(ei, envir))
>   # 3: eval(ei, envir)
>   # 4: eval(expr, envir, enclos)
>   # 5: .active-rstudio-document#9: f("parameter")
>   # 
>   # Enter an environment number, or 0 to exit  
>   # Selection: 5
>   # Browsing in the environment with call:
>   #   .active-rstudio-document#9: f("parameter")
>   # Called from: debugger.look(ind)
>   # Browse[1]> g
>   # [1] "global"
>   # Browse[1]> 
> 
> while dumping to a file
> 
>   # Test script 2
>   g <- "global"
>   f <- function(p) {
>     l <- "local"
>     dump.frames(to.file = TRUE, include.GlobalEnv = TRUE)
>   }
>   f("parameter")
> 
> results in
>   # > load("last.dump.rda")
>   # > debugger()

>   # Message:  object 'server' not foundAvailable environments had calls:
>   # 1: .GlobalEnv
>   # 2: source("~/.active-rstudio-document", echo = TRUE)
>   # 3: withVisible(eval(ei, envir))
>   # 4: eval(ei, envir)
>   # 5: eval(expr, envir, enclos)
>   # 6: .active-rstudio-document#11: f("parameter")
>   # 
>   # Enter an environment number, or 0 to exit  
>   # Selection: 6
>   # Browsing in the environment with call:
>   #   .active-rstudio-document#11: f("parameter")
>   # Called from: debugger.look(ind)
>   # Browse[1]> g
>   # Error: object 'g' not found
>   # Browse[1]> 

Your call to f() and the corresponding dump is heavily
obfuscated by all the wrap paper that Rstudio seems to wrap around a
simple function call (or just around using debugger() ?).

All this was to get the correct environments when things are run
in a batch job... and there's no Rstudio gift wrapping in that case.

In my simple use of the above, "g" is clearly available in the .GlobalEnv
component of last.dump :

> exists("g", last.dump$.GlobalEnv)
[1] TRUE
> get("g", last.dump$.GlobalEnv)
[1] "global"
> 

and that's all what's promised, right?
In such a post mortem debugging, notably from a batch job (!),
you don't want your .GlobalEnv to be *replaced* by the
.GlobalEnv from 'last.dump', do you?

I think in the end, I think you are indirectly asking for new features to be
added to  debugger(), namely that it works more seemlessly with
a last.dump object that has been created via 'include.GlobalEnv = TRUE'.

This wish for a new feature may be a very sensible wish.
I think it's fine if you add it as wish (for a new feature to
debugger()) to the R bugzilla site
( https://bugs.r-project.org/ -- after asking one of R core to
  add you to the list of "registered ones" there, see the
  boldface note in https://www.r-project.org/bugs.html )

Personally, I would only look into this issue if we also get a patch
proposal (see also https://www.r-project.org/bugs.html), because
already now you can easily get to "g" in your example.

Martin

> The semantic difference is that the global variable "g" is visible
> within the function "f" in the first version, but not in the second
> version.
> 
> If I dump to a file and load and debug it then the search path through
> the
> frames is not the same during run time vs. debug time.
> 
> An implementation with the same semantics could be achieved
> by applying this workaround currently:
> 
>   dump.frames()
>   save.image(file = "last.dump.rda")
> 
> Does it possibly make sense to unify the semantics?
> 
> THX!
> 
> 
> On Mon, 2016-11-14 at 11:34 +0100, Martin Maechler wrote:
> > >>>>> nospam at altfeld-im de <nospam at altfeld-im.de>
> > >>>>>     on Sun, 13 Nov 2016 13:11:38 +0100 writes:
> > 
> >     > Dear R friends, to allow post-mortem debugging In my
> >     > Rscript based batch jobs I use
> > 
> >     >    tryCatch( <R expression>, error = function(e) {
> >     > dump.frames(to.file = TRUE) })
> > 
> >     > to write the called frames into a dump file.
> > 
> >     > This is similar to the method recommended in the "Writing
> >     > R extensions" manual in section 4.2 Debugging R code (page
> >     > 96):
> > 
> >     > https://cran.r-project.org/doc/manuals/R-exts.pdf
> > 
> >     >> options(error = quote({dump.frames(to.file=TRUE); q()}))
> > 
> > 
> > 
> >     > When I load the dump later in a new R session to examine
> >     > the error I use
> > 
> >     >     load(file = "last.dump.rda") debugger(last.dump)
> > 
> >     > My problem is that the global objects in the workspace are
> >     > NOT contained in the dump since "dump.frames" does not
> >     > save the workspace.
> > 
> >     > This makes debugging difficult.
> > 
> > 
> > 
> >     > For more details see the stackoverflow question + answer
> >     > in:
> >     > https://stackoverflow.com/questions/40421552/r-how-make-dump-frames-include-all-variables-for-later-post-mortem-debugging/40431711#40431711
> > 
> > 
> > 
> >     > I think the reason of the problem is:
> >     > ------------------------------------
> > 
> >     > If you use dump.files(to.file = FALSE) in an interactive
> >     > session debugging works as expected because it creates a
> >     > global variable called "last.dump" and the workspace is
> >     > still loaded.
> > 
> >     > In the batch job scenario however the workspace is NOT
> >     > saved in the dump and therefore lost if you debug the dump
> >     > in a new session.
> > 
> > 
> >     > Options to solve the issue:
> >     > --------------------------
> > 
> >     > 1. Improve the documentation of the R help for
> >     > "dump.frames" and the R_exts manual to propose another
> >     > code snippet for batch job scenarios:
> > 
> >     >       dump.frames() save.image(file = "last.dump.rda")
> > 
> >     > 2. Change the semantics of "dump.frames(to.file = TRUE)"
> >     > to include the workspace in the dump.  This would change
> >     > the semantics implied by the function name but makes the
> >     > semantics consistent for both "to.file" param values.
> > 
> > There is a third option, already in place for three months now:
> > Andreas Kersting did propose it (nicely, as a wish),
> > 	https://bugs.r-project.org/bugzilla/show_bug.cgi?id=17116
> > and I had added it to the development version of R back then :
> > 
> > ------------------------------------------------------------------------
> > r71102 | maechler | 2016-08-16 17:36:10 +0200 (Tue, 16 Aug 2016) | 1 line
> > 
> > dump.frames(*, include.GlobalEnv)
> > ------------------------------------------------------------------------
> > 
> > So, if you (or others) want to use this before next spring,
> > you should install a version of R-devel
> > and you use that, with
> > 
> >   tryCatch( <R expression>,
> >            error = function(e)
> > 	           dump.frames(to.file = TRUE, include.GlobalEnv = TRUE))
> > 
> > Using R-devel is nice and helpful for the R community, as you
> > will help finding bugs/problems in the new features (and
> > possibly changed features) we've introduced there. 
> > 
> > 
> > Best regards,
> > Martin


From maechler at stat.math.ethz.ch  Tue Nov 15 12:58:36 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 15 Nov 2016 12:58:36 +0100
Subject: [Rd] ifelse() woes ... can we agree on a ifelse2() ?
In-Reply-To: <CABdHhvHniPZ1P5SKWJ=trkufv6feFSfsc1Aq4k7v=AAaok32AQ@mail.gmail.com>
References: <22437.61893.901739.933100@stat.math.ethz.ch>
	<deb934cc-d781-8011-d29b-f1cbcf60407e@gmail.com>
	<22445.44128.203938.13068@stat.math.ethz.ch>
	<CABdHhvEtBu5=zPuhXNxtTH_5vBbmqbr-U0j3WH9ftjUeABqEWA@mail.gmail.com>
	<CABdHhvHniPZ1P5SKWJ=trkufv6feFSfsc1Aq4k7v=AAaok32AQ@mail.gmail.com>
Message-ID: <20161115115836.CF93C1CB503@lynne.stat.math.ethz.ch>

Finally getting back to this :

>>>>> Hadley Wickham <h.wickham at gmail.com>
>>>>>     on Mon, 15 Aug 2016 07:51:35 -0500 writes:

    > On Fri, Aug 12, 2016 at 11:31 AM, Hadley Wickham
    > <h.wickham at gmail.com> wrote:
    >>> >> One possibility would also be to consider a
    >>> "numbers-only" or >> rather "same type"-only {e.g.,
    >>> would also work for characters} >> version.
    >>>
    >>> > I don't know what you mean by these.
    >>>
    >>> In the mean time, Bob Rudis mentioned dplyr::if_else(),
    >>> which is very relevant, thank you Bob!
    >>>
    >>> As I have found, that actually works in such a "same
    >>> type"-only way: It does not try to coerce, but gives an
    >>> error when the classes differ, even in this somewhat
    >>> debatable case :
    >>>
    >>> > dplyr::if_else(c(TRUE, FALSE), 2:3, 0+10:11) Error:
    >>> `false` has type 'double' not 'integer'
    >>> >
    >>>
    >>> As documented, if_else() is clearly stricter than
    >>> ifelse() and e.g., also does no recycling (but of
    >>> length() 1).
    >>
    >> I agree that if_else() is currently too strict - it's
    >> particularly annoying if you want to replace some values
    >> with a missing:
    >>
    >> x <- sample(10) if_else(x > 5, NA, x) # Error: `false`
    >> has type 'integer' not 'logical'
    >>
    >> But I would like to make sure that this remains an error:
    >>
    >> if_else(x > 5, x, "BLAH")
    >>
    >> Because that seems more likely to be a user error (but
    >> reasonable people might certainly believe that it should
    >> just work)
    >>
    >> dplyr is more accommodating in other places (i.e. in
    >> bind_rows(), collapse() and the joins) but it's
    >> surprisingly hard to get all the details right. For
    >> example, what should the result of this call be?
    >>
    >> if_else(c(TRUE, FALSE), factor(c("a", "b")),
    >> factor(c("c", "b"))
    >>
    >> Strictly speaking I think you could argue it's an error,
    >> but that's not very user-friendly. Should it be a factor
    >> with the union of the levels? Should it be a character
    >> vector + warning? Should the behaviour change if one set
    >> of levels is a subset of the other set?
    >>
    >> There are similar issues for POSIXct (if the time zones
    >> are different, which should win?), and difftimes
    >> (similarly for units).  Ideally you'd like the behaviour
    >> to be extensible for new S3 classes, which suggests it
    >> should be a generic (and for the most general case, it
    >> would need to dispatch on both arguments).

    > One possible principle would be to use c() -
    > i.e. construct out as

    > out <- c(yes[0], no[0]
    > length(out) <- max(length(yes), length(no))

yes; this would require that a  `length<-` method works for the
class of the result.

Duncan Murdoch mentioned a version of this, in his very
first reply:

    ans <- c(yes, no)[seq_along(test)]
    ans <- ans[seq_along(test)]

which is less efficient for atomic vectors, but requires
less from the class: it "only" needs `c` and `[` to work

and a mixture of your two proposals would be possible too:

    ans <- c(yes[0], no[0])
    ans <- ans[seq_along(test)]

which does *not* work for my "mpfr" numbers (CRAN package 'Rmpfr'),
but that's a buglet in the  c.mpfr() implementation of my Rmpfr
package... (which has already been fixed in the development version on R-forge,
	    https://r-forge.r-project.org/R/?group_id=386)

    > But of course that wouldn't help with factor responses.

Yes.  However, a version of Duncan's suggestion -- of treating 'yes' first
-- does help in that case.

For once, mainly as "feasability experiment",
I have created a github gist to make my current ifelse2() proposal available
for commenting, cloning, pullrequesting, etc:

Consisting of 2 files
- ifelse-def.R :  Functions definitions only, basically all the current
	        proposals, called  ifelse*()
- ifelse-checks.R : A simplistic checking function
 	and examples calling it, notably demonstrating that my
	ifelse2()  does work with
	"Date", <dateTime> (i.e. "POSIXct" and "POSIXlt"), factors,
	and "mpfr" (the arbitrary-precision numbers in my package "Rmpfr")

Also if you are not on github, you can quickly get to the ifelse2()
definition :

https://gist.github.com/mmaechler/9cfc3219c4b89649313bfe6853d87894#file-ifelse-def-r-L168

    > Also, if you're considering an improved ifelse(), I'd
    > strongly urge you to consider adding an `na` argument,

I now did (called it 'NA.').

    > so that you can use ifelse() to transform all three
    > possible values in a logical vector.

    > Hadley
    > -- http://hadley.nz

For those who really hate GH (and don't want or cannot easily follow the
above URL), here's my current definition: 


##' Martin Maechler, 14. Nov 2016 --- taking into account Duncan M. and Hadley's
##' ideas in the R-devel thread starting at (my mom's 86th birthday):
##' https://stat.ethz.ch/pipermail/r-devel/2016-August/072970.html
ifelse2 <- function (test, yes, no, NA. = NA) {
    if(!is.logical(test)) {
        if(is.atomic(test))
            storage.mode(test) <- "logical"
        else ## typically a "class"; storage.mode<-() typically fails
            test <- if(isS4(test)) methods::as(test, "logical") else as.logical(test)
    }

    ## No longer optimize the  "if (a) x else y"  cases:
    ## Only "non-good" R users use ifelse(.) instead of if(.) in these cases.

    ans <-
	tryCatch(rep(if(is.object(yes) && identical(class(yes), class(no)))
			 ## as c(o) or o[0] may not work for the class
			 yes else c(yes[0], no[0]), length.out = length(test)),
		 error = function(e) { ## try asymmetric, yes-leaning
		     r <- yes
		     r[!test] <- no[!test]
		     r
		 })
    ok <- !(nas <- is.na(test))
    if (any(test[ok]))
	ans[test & ok] <- rep(yes, length.out = length(ans))[test & ok]
    if (any(!test[ok]))
	ans[!test & ok] <- rep(no, length.out = length(ans))[!test & ok]
    ans[nas] <- NA. # possibly coerced to class(ans)
    ans
}


From mark.oconnell at maths.nuim.ie  Tue Nov 15 12:13:14 2016
From: mark.oconnell at maths.nuim.ie (Mark O'Connell)
Date: Tue, 15 Nov 2016 11:13:14 +0000 (GMT)
Subject: [Rd] getGraphicsEvent() alternative for cairo graphics device?
In-Reply-To: <039e4e77-d905-b407-ddfa-1578720b694b@stat.auckland.ac.nz>
References: <CAN_GHySs42vK5U1xZYP8h7ZPdFyOcHnEZK4Sn91e7htv=7E54A@mail.gmail.com>
	<57968357.2030509@stat.auckland.ac.nz>
	<20161112200028.GD24681@ofb.net>
	<2e6f0306-da86-211a-05dd-aff3d744df40@stat.auckland.ac.nz>
	<20161114004137.GA21456@ofb.net>
	<25bfd94c-28f6-595e-ffb1-2ae2421b5135@stat.auckland.ac.nz>
	<20161114015325.GB21456@ofb.net>
	<039e4e77-d905-b407-ddfa-1578720b694b@stat.auckland.ac.nz>
Message-ID: <1406859886.21862.1479208394402.JavaMail.zimbra@maths.nuim.ie>

Hi Paul,

No problem. Is it best if I post examples to the bug report 16951?

Kind regards,
Mark

--

Mark O'Connell, PhD student
Department of Mathematics & Statistics
231 Top Logic
National University of Ireland, Maynooth

----- Paul Murrell <paul at stat.auckland.ac.nz> wrote:
> 
> Thanks Frederick.
> 
> Mark, if you have any examples to share, they would also be gratefully 
> received.
> 
> Paul
> 
> On 14/11/16 14:53, frederik at ofb.net wrote:
> > Hi Paul,
> >
> > OK I tried not to make the examples too fancy.
> >
> > Please let me know what you think. They should probably be amended to
> > support the Windows platform, but I think that task would be much
> > easier for someone with access to Windows...
> >
> > By the way I'm Cc'ing Mark O'Connell who shared with me some great
> > getGraphicsEvent examples - well, I found them useful, perhaps if
> > these are going to the R distro somewhere, then his examples should be
> > included as well.
> >
> > Thank you,
> >
> > Frederick
> >
> > On Mon, Nov 14, 2016 at 01:51:08PM +1300, Paul Murrell wrote:
> >>
> >> Great.  Thanks!
> >>
> >> Paul
> >>
> >> On 14/11/16 13:41, frederik at ofb.net wrote:
> >>> Hi Paul,
> >>>
> >>> Thank you, for some reason I didn't seem to get an email notification
> >>> for your bugzilla comment!
> >>>
> >>> I will try to send you something shortly.
> >>>
> >>> Frederick
> >>>
> >>> On Mon, Nov 14, 2016 at 08:55:20AM +1300, Paul Murrell wrote:
> >>>> Hi
> >>>>
> >>>> The current status is that I am keen for people to contribute some testing
> >>>> code (see https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16951)
> >>>>
> >>>> There were also some getGraphicsEvent() changes/fixes suggested by Richard
> >>>> Bodewits (cc'ed), for which I am also seeking test code.
> >>>>
> >>>> Paul
> >>>>
> >>>> On 13/11/16 09:00, frederik at ofb.net wrote:
> >>>>> Hi Paul,
> >>>>>
> >>>>> Just checking in to see what the status is.
> >>>>>
> >>>>> From my perspective it seems logical to split off X11 into a separate
> >>>>> package, so development can proceed at a reasonable rate, but I
> >>>>> haven't yet tried to see if that's even possible.
> >>>>>
> >>>>> Thanks,
> >>>>>
> >>>>> Frederick
> >>>>>
> >>>>> On Tue, Jul 26, 2016 at 09:23:35AM +1200, Paul Murrell wrote:
> >>>>>> Hi
> >>>>>>
> >>>>>> Taking a look at those patches is now on my todo list, so I may be in touch
> >>>>>> with both of you at some point to request some testing.
> >>>>>>
> >>>>>> Paul
> >>>>>>
> >>>>>> On 26/07/16 07:17, frederik at ofb.net wrote:
> >>>>>>> Dear Daniel Greenidge,
> >>>>>>>
> >>>>>>> To enable getGraphicsEvent on Cairo, you have two patches to choose
> >>>>>>> from:
> >>>>>>>
> >>>>>>> https://bugs.r-project.org/bugzilla/show_bug.cgi?id=14364
> >>>>>>> https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16951
> >>>>>>>
> >>>>>>> The second one is by me, and the first one is from five years ago by
> >>>>>>> Hugo Mildenberger.
> >>>>>>>
> >>>>>>> Both patches are very simple, they move some lines enabling
> >>>>>>> getGrahpicsEvent outside of a if(!cairo) statement. My patch also adds
> >>>>>>> the ability to execute code (e.g. for animation) while the interface
> >>>>>>> is idle.
> >>>>>>>
> >>>>>>> Top guy Duncan Murdoch has expressed that he doesn't have time to work
> >>>>>>> on applying these patches, and I haven't had any responses from the
> >>>>>>> rest of the R Core Team. I was thinking that perhaps your best bet is
> >>>>>>> to try to create a package called e.g. "X11-fixes" which people can
> >>>>>>> use to get a better X11 library (there is also a bug waiting to be
> >>>>>>> fixed from 2001:
> >>>>>>> https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16702).
> >>>>>>>
> >>>>>>> I don't know if CRAN would accept such a package, or if you'd have to
> >>>>>>> distribute it via GitHub, but R has excellent tools to facilitate the
> >>>>>>> distribution of code via packages. Whether the R kernel exports enough
> >>>>>>> functions to allow a package to take over event handling, I'm not
> >>>>>>> sure. I was intending to look more into the details of this
> >>>>>>> possibility but haven't had time.
> >>>>>>>
> >>>>>>> Best wishes,
> >>>>>>>
> >>>>>>> Frederick
> >>>>>>>
> >>>>>>> On Mon, Jul 25, 2016 at 02:15:59PM -0400, Daniel Greenidge wrote:
> >>>>>>>> Hi all,
> >>>>>>>>
> >>>>>>>> I'm writing an interactive plotting function for viewing fMRI
> >>>>>>>> datasets. Currently, I get keypresses using
> >>>>>>>> grDevices::getGraphicsEvent().
> >>>>>>>>
> >>>>>>>> Unfortunately getGraphicsEvent() only supports the X11(type="Xlib")
> >>>>>>>> graphics device on Unix systems. The Xlib device doesn't support
> >>>>>>>> buffering (i.e. dev.hold() and dev.flush()), so redrawing the plots
> >>>>>>>> causes lots of flickering.
> >>>>>>>>
> >>>>>>>> Is there a way to get keypresses while using the cairo graphics
> >>>>>>>> device? Alternatively, is there a way to prevent flickering with the
> >>>>>>>> Xlib graphics device?
> >>>>>>>>
> >>>>>>>> Best,
> >>>>>>>> Daniel Greenidge
> >>>>>>>>
> >>>>>>>> ______________________________________________
> >>>>>>>> R-devel at r-project.org mailing list
> >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>>>>>>
> >>>>>>>
> >>>>>>> ______________________________________________
> >>>>>>> R-devel at r-project.org mailing list
> >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>>>>>
> >>>>>>
> >>>>>> --
> >>>>>> Dr Paul Murrell
> >>>>>> Department of Statistics
> >>>>>> The University of Auckland
> >>>>>> Private Bag 92019
> >>>>>> Auckland
> >>>>>> New Zealand
> >>>>>> 64 9 3737599 x85392
> >>>>>> paul at stat.auckland.ac.nz
> >>>>>> http://www.stat.auckland.ac.nz/~paul/
> >>>>>>
> >>>>
> >>>> --
> >>>> Dr Paul Murrell
> >>>> Department of Statistics
> >>>> The University of Auckland
> >>>> Private Bag 92019
> >>>> Auckland
> >>>> New Zealand
> >>>> 64 9 3737599 x85392
> >>>> paul at stat.auckland.ac.nz
> >>>> http://www.stat.auckland.ac.nz/~paul/
> >>>>
> >>
> >> --
> >> Dr Paul Murrell
> >> Department of Statistics
> >> The University of Auckland
> >> Private Bag 92019
> >> Auckland
> >> New Zealand
> >> 64 9 3737599 x85392
> >> paul at stat.auckland.ac.nz
> >> http://www.stat.auckland.ac.nz/~paul/
> >>
> 
> -- 
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/


From paul at stat.auckland.ac.nz  Tue Nov 15 20:02:38 2016
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Wed, 16 Nov 2016 08:02:38 +1300
Subject: [Rd] getGraphicsEvent() alternative for cairo graphics device?
In-Reply-To: <1406859886.21862.1479208394402.JavaMail.zimbra@maths.nuim.ie>
References: <CAN_GHySs42vK5U1xZYP8h7ZPdFyOcHnEZK4Sn91e7htv=7E54A@mail.gmail.com>
	<57968357.2030509@stat.auckland.ac.nz> <20161112200028.GD24681@ofb.net>
	<2e6f0306-da86-211a-05dd-aff3d744df40@stat.auckland.ac.nz>
	<20161114004137.GA21456@ofb.net>
	<25bfd94c-28f6-595e-ffb1-2ae2421b5135@stat.auckland.ac.nz>
	<20161114015325.GB21456@ofb.net>
	<039e4e77-d905-b407-ddfa-1578720b694b@stat.auckland.ac.nz>
	<1406859886.21862.1479208394402.JavaMail.zimbra@maths.nuim.ie>
Message-ID: <5e4e99bc-9657-52b1-f8f3-d6f6f0852a54@stat.auckland.ac.nz>

Hi

That sounds good - somewhere public like that would be best.

Thanks!

Paul

On 16/11/16 00:13, Mark O'Connell wrote:
> Hi Paul,
>
> No problem. Is it best if I post examples to the bug report 16951?
>
> Kind regards,
> Mark
>
> --
>
> Mark O'Connell, PhD student
> Department of Mathematics & Statistics
> 231 Top Logic
> National University of Ireland, Maynooth
>
> ----- Paul Murrell <paul at stat.auckland.ac.nz> wrote:
>>
>> Thanks Frederick.
>>
>> Mark, if you have any examples to share, they would also be gratefully
>> received.
>>
>> Paul
>>
>> On 14/11/16 14:53, frederik at ofb.net wrote:
>>> Hi Paul,
>>>
>>> OK I tried not to make the examples too fancy.
>>>
>>> Please let me know what you think. They should probably be amended to
>>> support the Windows platform, but I think that task would be much
>>> easier for someone with access to Windows...
>>>
>>> By the way I'm Cc'ing Mark O'Connell who shared with me some great
>>> getGraphicsEvent examples - well, I found them useful, perhaps if
>>> these are going to the R distro somewhere, then his examples should be
>>> included as well.
>>>
>>> Thank you,
>>>
>>> Frederick
>>>
>>> On Mon, Nov 14, 2016 at 01:51:08PM +1300, Paul Murrell wrote:
>>>>
>>>> Great.  Thanks!
>>>>
>>>> Paul
>>>>
>>>> On 14/11/16 13:41, frederik at ofb.net wrote:
>>>>> Hi Paul,
>>>>>
>>>>> Thank you, for some reason I didn't seem to get an email notification
>>>>> for your bugzilla comment!
>>>>>
>>>>> I will try to send you something shortly.
>>>>>
>>>>> Frederick
>>>>>
>>>>> On Mon, Nov 14, 2016 at 08:55:20AM +1300, Paul Murrell wrote:
>>>>>> Hi
>>>>>>
>>>>>> The current status is that I am keen for people to contribute some testing
>>>>>> code (see https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16951)
>>>>>>
>>>>>> There were also some getGraphicsEvent() changes/fixes suggested by Richard
>>>>>> Bodewits (cc'ed), for which I am also seeking test code.
>>>>>>
>>>>>> Paul
>>>>>>
>>>>>> On 13/11/16 09:00, frederik at ofb.net wrote:
>>>>>>> Hi Paul,
>>>>>>>
>>>>>>> Just checking in to see what the status is.
>>>>>>>
>>>>>>> From my perspective it seems logical to split off X11 into a separate
>>>>>>> package, so development can proceed at a reasonable rate, but I
>>>>>>> haven't yet tried to see if that's even possible.
>>>>>>>
>>>>>>> Thanks,
>>>>>>>
>>>>>>> Frederick
>>>>>>>
>>>>>>> On Tue, Jul 26, 2016 at 09:23:35AM +1200, Paul Murrell wrote:
>>>>>>>> Hi
>>>>>>>>
>>>>>>>> Taking a look at those patches is now on my todo list, so I may be in touch
>>>>>>>> with both of you at some point to request some testing.
>>>>>>>>
>>>>>>>> Paul
>>>>>>>>
>>>>>>>> On 26/07/16 07:17, frederik at ofb.net wrote:
>>>>>>>>> Dear Daniel Greenidge,
>>>>>>>>>
>>>>>>>>> To enable getGraphicsEvent on Cairo, you have two patches to choose
>>>>>>>>> from:
>>>>>>>>>
>>>>>>>>> https://bugs.r-project.org/bugzilla/show_bug.cgi?id=14364
>>>>>>>>> https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16951
>>>>>>>>>
>>>>>>>>> The second one is by me, and the first one is from five years ago by
>>>>>>>>> Hugo Mildenberger.
>>>>>>>>>
>>>>>>>>> Both patches are very simple, they move some lines enabling
>>>>>>>>> getGrahpicsEvent outside of a if(!cairo) statement. My patch also adds
>>>>>>>>> the ability to execute code (e.g. for animation) while the interface
>>>>>>>>> is idle.
>>>>>>>>>
>>>>>>>>> Top guy Duncan Murdoch has expressed that he doesn't have time to work
>>>>>>>>> on applying these patches, and I haven't had any responses from the
>>>>>>>>> rest of the R Core Team. I was thinking that perhaps your best bet is
>>>>>>>>> to try to create a package called e.g. "X11-fixes" which people can
>>>>>>>>> use to get a better X11 library (there is also a bug waiting to be
>>>>>>>>> fixed from 2001:
>>>>>>>>> https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16702).
>>>>>>>>>
>>>>>>>>> I don't know if CRAN would accept such a package, or if you'd have to
>>>>>>>>> distribute it via GitHub, but R has excellent tools to facilitate the
>>>>>>>>> distribution of code via packages. Whether the R kernel exports enough
>>>>>>>>> functions to allow a package to take over event handling, I'm not
>>>>>>>>> sure. I was intending to look more into the details of this
>>>>>>>>> possibility but haven't had time.
>>>>>>>>>
>>>>>>>>> Best wishes,
>>>>>>>>>
>>>>>>>>> Frederick
>>>>>>>>>
>>>>>>>>> On Mon, Jul 25, 2016 at 02:15:59PM -0400, Daniel Greenidge wrote:
>>>>>>>>>> Hi all,
>>>>>>>>>>
>>>>>>>>>> I'm writing an interactive plotting function for viewing fMRI
>>>>>>>>>> datasets. Currently, I get keypresses using
>>>>>>>>>> grDevices::getGraphicsEvent().
>>>>>>>>>>
>>>>>>>>>> Unfortunately getGraphicsEvent() only supports the X11(type="Xlib")
>>>>>>>>>> graphics device on Unix systems. The Xlib device doesn't support
>>>>>>>>>> buffering (i.e. dev.hold() and dev.flush()), so redrawing the plots
>>>>>>>>>> causes lots of flickering.
>>>>>>>>>>
>>>>>>>>>> Is there a way to get keypresses while using the cairo graphics
>>>>>>>>>> device? Alternatively, is there a way to prevent flickering with the
>>>>>>>>>> Xlib graphics device?
>>>>>>>>>>
>>>>>>>>>> Best,
>>>>>>>>>> Daniel Greenidge
>>>>>>>>>>
>>>>>>>>>> ______________________________________________
>>>>>>>>>> R-devel at r-project.org mailing list
>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>>>>>
>>>>>>>>>
>>>>>>>>> ______________________________________________
>>>>>>>>> R-devel at r-project.org mailing list
>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>>>>
>>>>>>>>
>>>>>>>> --
>>>>>>>> Dr Paul Murrell
>>>>>>>> Department of Statistics
>>>>>>>> The University of Auckland
>>>>>>>> Private Bag 92019
>>>>>>>> Auckland
>>>>>>>> New Zealand
>>>>>>>> 64 9 3737599 x85392
>>>>>>>> paul at stat.auckland.ac.nz
>>>>>>>> http://www.stat.auckland.ac.nz/~paul/
>>>>>>>>
>>>>>>
>>>>>> --
>>>>>> Dr Paul Murrell
>>>>>> Department of Statistics
>>>>>> The University of Auckland
>>>>>> Private Bag 92019
>>>>>> Auckland
>>>>>> New Zealand
>>>>>> 64 9 3737599 x85392
>>>>>> paul at stat.auckland.ac.nz
>>>>>> http://www.stat.auckland.ac.nz/~paul/
>>>>>>
>>>>
>>>> --
>>>> Dr Paul Murrell
>>>> Department of Statistics
>>>> The University of Auckland
>>>> Private Bag 92019
>>>> Auckland
>>>> New Zealand
>>>> 64 9 3737599 x85392
>>>> paul at stat.auckland.ac.nz
>>>> http://www.stat.auckland.ac.nz/~paul/
>>>>
>>
>> --
>> Dr Paul Murrell
>> Department of Statistics
>> The University of Auckland
>> Private Bag 92019
>> Auckland
>> New Zealand
>> 64 9 3737599 x85392
>> paul at stat.auckland.ac.nz
>> http://www.stat.auckland.ac.nz/~paul/
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From gmbecker at ucdavis.edu  Tue Nov 15 20:56:04 2016
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Tue, 15 Nov 2016 11:56:04 -0800
Subject: [Rd] ifelse() woes ... can we agree on a ifelse2() ?
In-Reply-To: <20161115115836.CF93C1CB503@lynne.stat.math.ethz.ch>
References: <22437.61893.901739.933100@stat.math.ethz.ch>
	<deb934cc-d781-8011-d29b-f1cbcf60407e@gmail.com>
	<22445.44128.203938.13068@stat.math.ethz.ch>
	<CABdHhvEtBu5=zPuhXNxtTH_5vBbmqbr-U0j3WH9ftjUeABqEWA@mail.gmail.com>
	<CABdHhvHniPZ1P5SKWJ=trkufv6feFSfsc1Aq4k7v=AAaok32AQ@mail.gmail.com>
	<20161115115836.CF93C1CB503@lynne.stat.math.ethz.ch>
Message-ID: <CADwqtCOKRLEFW0wkEy1B8CO+VYJbQ64uEWkNgKS1EXoWedA0Jw@mail.gmail.com>

All,

Martin: Thanks for this and all the other things you are doing to both
drive R forward and engage more with the community about things like this.

Apologies for missing this discussion the first time it came around and if
anything here has already been brought up, but I wonder what exactly you
mean when you want recycling behavior.

Specifically, based on an unrelated discussion with Henrik Bengtsson on
Twitter, I wonder if preserving the recycling behavior test is longer than
yes, no, but making the case where

length( test ) < max(length( yes ), length( no ))

would simplify usage for userRs in a useful way. I suspect it's easy to
forget that the result is not guaranteed to be the length of  test, even
for intermediate and advanced users familiar with ifelse and it's
strengths/weaknesses.

I certainly agree (for what that's worth...) that

x = rnorm(100)

y = ifelse2(x > 0, 1L, 2L)

should continue to work.

Also, If we combine a stricter contract that the output will always be of
length with the suggestion of a specified output class the pseudo code
could be

ifelse2 = function(test, yes, no, outclass) {

lenout  = length(test)

out = as( rep(yes, length.out = lenout), outclass)

out[!test] = as(rep(no, length.out = lenout)[!test], outclass)

#handle NA stuff

out

}


NAs could be tricky if outclass were allowed to be completely general, but
doable, I think? Another approach  if we ARE fast-passing while leaving
ifelse intact is that maybe NA's in test just aren't allowed in ifelse2.
I'm not saying we should definitely do that, but it's possible and would
make things faster.

Finally, In terms of efficiency, with the stuff that Luke and I are working
on, the NA detection could be virtually free in certain cases, which could
give a nice boost for long vectors  that don't have any NAs (and 'know'
that they don't).

Best,
~G

On Tue, Nov 15, 2016 at 3:58 AM, Martin Maechler <maechler at stat.math.ethz.ch
> wrote:

> Finally getting back to this :
>
> >>>>> Hadley Wickham <h.wickham at gmail.com>
> >>>>>     on Mon, 15 Aug 2016 07:51:35 -0500 writes:
>
>     > On Fri, Aug 12, 2016 at 11:31 AM, Hadley Wickham
>     > <h.wickham at gmail.com> wrote:
>     >>> >> One possibility would also be to consider a
>     >>> "numbers-only" or >> rather "same type"-only {e.g.,
>     >>> would also work for characters} >> version.
>     >>>
>     >>> > I don't know what you mean by these.
>     >>>
>     >>> In the mean time, Bob Rudis mentioned dplyr::if_else(),
>     >>> which is very relevant, thank you Bob!
>     >>>
>     >>> As I have found, that actually works in such a "same
>     >>> type"-only way: It does not try to coerce, but gives an
>     >>> error when the classes differ, even in this somewhat
>     >>> debatable case :
>     >>>
>     >>> > dplyr::if_else(c(TRUE, FALSE), 2:3, 0+10:11) Error:
>     >>> `false` has type 'double' not 'integer'
>     >>> >
>     >>>
>     >>> As documented, if_else() is clearly stricter than
>     >>> ifelse() and e.g., also does no recycling (but of
>     >>> length() 1).
>     >>
>     >> I agree that if_else() is currently too strict - it's
>     >> particularly annoying if you want to replace some values
>     >> with a missing:
>     >>
>     >> x <- sample(10) if_else(x > 5, NA, x) # Error: `false`
>     >> has type 'integer' not 'logical'
>     >>
>     >> But I would like to make sure that this remains an error:
>     >>
>     >> if_else(x > 5, x, "BLAH")
>     >>
>     >> Because that seems more likely to be a user error (but
>     >> reasonable people might certainly believe that it should
>     >> just work)
>     >>
>     >> dplyr is more accommodating in other places (i.e. in
>     >> bind_rows(), collapse() and the joins) but it's
>     >> surprisingly hard to get all the details right. For
>     >> example, what should the result of this call be?
>     >>
>     >> if_else(c(TRUE, FALSE), factor(c("a", "b")),
>     >> factor(c("c", "b"))
>     >>
>     >> Strictly speaking I think you could argue it's an error,
>     >> but that's not very user-friendly. Should it be a factor
>     >> with the union of the levels? Should it be a character
>     >> vector + warning? Should the behaviour change if one set
>     >> of levels is a subset of the other set?
>     >>
>     >> There are similar issues for POSIXct (if the time zones
>     >> are different, which should win?), and difftimes
>     >> (similarly for units).  Ideally you'd like the behaviour
>     >> to be extensible for new S3 classes, which suggests it
>     >> should be a generic (and for the most general case, it
>     >> would need to dispatch on both arguments).
>
>     > One possible principle would be to use c() -
>     > i.e. construct out as
>
>     > out <- c(yes[0], no[0]
>     > length(out) <- max(length(yes), length(no))
>
> yes; this would require that a  `length<-` method works for the
> class of the result.
>
> Duncan Murdoch mentioned a version of this, in his very
> first reply:
>
>     ans <- c(yes, no)[seq_along(test)]
>     ans <- ans[seq_along(test)]
>
> which is less efficient for atomic vectors, but requires
> less from the class: it "only" needs `c` and `[` to work
>
> and a mixture of your two proposals would be possible too:
>
>     ans <- c(yes[0], no[0])
>     ans <- ans[seq_along(test)]
>
> which does *not* work for my "mpfr" numbers (CRAN package 'Rmpfr'),
> but that's a buglet in the  c.mpfr() implementation of my Rmpfr
> package... (which has already been fixed in the development version on
> R-forge,
>             https://r-forge.r-project.org/R/?group_id=386)
>
>     > But of course that wouldn't help with factor responses.
>
> Yes.  However, a version of Duncan's suggestion -- of treating 'yes' first
> -- does help in that case.
>
> For once, mainly as "feasability experiment",
> I have created a github gist to make my current ifelse2() proposal
> available
> for commenting, cloning, pullrequesting, etc:
>
> Consisting of 2 files
> - ifelse-def.R :  Functions definitions only, basically all the current
>                 proposals, called  ifelse*()
> - ifelse-checks.R : A simplistic checking function
>         and examples calling it, notably demonstrating that my
>         ifelse2()  does work with
>         "Date", <dateTime> (i.e. "POSIXct" and "POSIXlt"), factors,
>         and "mpfr" (the arbitrary-precision numbers in my package "Rmpfr")
>
> Also if you are not on github, you can quickly get to the ifelse2()
> definition :
>
> https://gist.github.com/mmaechler/9cfc3219c4b89649313bfe6853d878
> 94#file-ifelse-def-r-L168
>
>     > Also, if you're considering an improved ifelse(), I'd
>     > strongly urge you to consider adding an `na` argument,
>
> I now did (called it 'NA.').
>
>     > so that you can use ifelse() to transform all three
>     > possible values in a logical vector.
>
>     > Hadley
>     > -- http://hadley.nz
>
> For those who really hate GH (and don't want or cannot easily follow the
> above URL), here's my current definition:
>
>
> ##' Martin Maechler, 14. Nov 2016 --- taking into account Duncan M. and
> Hadley's
> ##' ideas in the R-devel thread starting at (my mom's 86th birthday):
> ##' https://stat.ethz.ch/pipermail/r-devel/2016-August/072970.html
> ifelse2 <- function (test, yes, no, NA. = NA) {
>     if(!is.logical(test)) {
>         if(is.atomic(test))
>             storage.mode(test) <- "logical"
>         else ## typically a "class"; storage.mode<-() typically fails
>             test <- if(isS4(test)) methods::as(test, "logical") else
> as.logical(test)
>     }
>
>     ## No longer optimize the  "if (a) x else y"  cases:
>     ## Only "non-good" R users use ifelse(.) instead of if(.) in these
> cases.
>
>     ans <-
>         tryCatch(rep(if(is.object(yes) && identical(class(yes), class(no)))
>                          ## as c(o) or o[0] may not work for the class
>                          yes else c(yes[0], no[0]), length.out =
> length(test)),
>                  error = function(e) { ## try asymmetric, yes-leaning
>                      r <- yes
>                      r[!test] <- no[!test]
>                      r
>                  })
>     ok <- !(nas <- is.na(test))
>     if (any(test[ok]))
>         ans[test & ok] <- rep(yes, length.out = length(ans))[test & ok]
>     if (any(!test[ok]))
>         ans[!test & ok] <- rep(no, length.out = length(ans))[!test & ok]
>     ans[nas] <- NA. # possibly coerced to class(ans)
>     ans
> }
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Gabriel Becker, PhD
Associate Scientist (Bioinformatics)
Genentech Research

	[[alternative HTML version deleted]]


From kevinushey at gmail.com  Tue Nov 15 21:26:26 2016
From: kevinushey at gmail.com (Kevin Ushey)
Date: Tue, 15 Nov 2016 12:26:26 -0800
Subject: [Rd] creating a long list puts R in a state where many things
 stop working
In-Reply-To: <3fc0697c-2c5b-f18c-22f8-76d0104ffefc@fredhutch.org>
References: <3fc0697c-2c5b-f18c-22f8-76d0104ffefc@fredhutch.org>
Message-ID: <CAJXgQP0mu4hzu1DjHpJ664pWvzACLzNRYsaPhh6_XND9ynpOGA@mail.gmail.com>

For reference, running your code in a build of R-devel with sanitizers:

> x <- vector(mode="list", length=3e9)
memory.c:2747:27: runtime error: signed integer overflow: 2147483647 + 1
cannot be represented in type 'R_len_t' (aka 'int')
SUMMARY: AddressSanitizer: undefined-behavior memory.c:2747:27 in
ASAN:DEADLYSIGNAL
=================================================================
==50159==ERROR: AddressSanitizer: SEGV on unknown address 0x000000000000
(pc 0x00010b3452a7 bp 0x7fff5669d2b0 sp 0x7fff5669cd80 T0)
==50159==The signal is caused by a READ memory access.
==50159==Hint: address points to the zero page.
    #0 0x10b3452a6 in Rf_allocVector3 memory.c:2748
    #1 0x10afc13b1 in do_makevector builtin.c:789
    #2 0x10b238868 in bcEval eval.c:6041
    #3 0x10b2241b8 in Rf_eval eval.c:626
    #4 0x10b2794d4 in Rf_applyClosure eval.c:1160
    #5 0x10b224d16 in Rf_eval eval.c:742
    #6 0x10b286591 in do_set eval.c:2227
    #7 0x10b2246ae in Rf_eval eval.c:695
    #8 0x10b3229ef in Rf_ReplIteration main.c:258
    #9 0x10b327280 in R_ReplConsole main.c:308
    #10 0x10b327087 in run_Rmainloop main.c:1059
    #11 0x10955fea4 in main Rmain.c:29
    #12 0x7fffcabf3254 in start (libdyld.dylib+0x5254)

AddressSanitizer can not provide additional info.
SUMMARY: AddressSanitizer: SEGV memory.c:2748 in Rf_allocVector3
==50159==ABORTING
Abort trap: 6

Looks like there's an index here that needs to be R_xlen_t?
https://github.com/wch/r-source/blob/6e7a2ed989027f3800d2e2d64e60e6d700034c6b/src/main/memory.c#L2747

Declared at
https://github.com/wch/r-source/blob/6e7a2ed989027f3800d2e2d64e60e6d700034c6b/src/main/memory.c#L2476
-- could this index safely become R_xlen_t?

Kevin

On Mon, Nov 14, 2016 at 10:10 PM, Herv? Pag?s <hpages at fredhutch.org> wrote:

> Hi,
>
> After I create a long list e.g. with
>
>   x <- vector(mode="list", length=3e9)
>
> many bad things start to happen e.g. some things stop working with a
> spurious error message:
>
>   gc()
>   # Error in gc() :
>   #   long vectors not supported yet: /home/hpages/src/R-3.3.2/src/m
> ain/memory.c:1137
>
>   x_lens <- lengths(x)
>   # Error in lengths(x) :
>   #  long vectors not supported yet: /home/hpages/src/R-3.3.2/src/m
> ain/memory.c:1668
>
> But then some of them work again:
>
>   gc()
>   #          used (Mb) gc trigger    (Mb)   max used    (Mb)
>   # Ncells  57046  3.1     368000    19.7     350000    18.7
>   # Vcells 138060  1.1 4320596678 32963.6 4500397915 34335.4
>
> while others still fail but now with a different error message:
>
>   x_lens <- lengths(x)
>   # Error: evaluation nested too deeply: infinite recursion /
> options(expressions=)?
>
> etc...
>
> The more I go, the more weird things I see so clearly my session
> got corrupted. Finally, and not too surprisingly, after playing a
> little bit more, my session eventually crashed.
>
> Thanks,
> H.
>
> > sessionInfo()
> R version 3.3.2 (2016-10-31)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 14.04.3 LTS
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
>
> --
> Herv? Pag?s
>
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
>
> E-mail: hpages at fredhutch.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

	[[alternative HTML version deleted]]


From Michael.Laviolette at dhhs.nh.gov  Thu Nov 17 22:28:14 2016
From: Michael.Laviolette at dhhs.nh.gov (Laviolette, Michael)
Date: Thu, 17 Nov 2016 21:28:14 +0000
Subject: [Rd] problem with normalizePath()
Message-ID: <e6592864a7b34cca92711b6c3c309484@dhhs.nh.gov>

The packages "readxl" and "haven" (and possibly others) no longer access files on shared network drives. The problem appears to be in the normalizePath() function. The file can be read from a local drive or by functions that don't call normalizePath(). The error thrown is

Error: path[1]="\\Hzndhhsvf2/data/OCPH/EPI/BHSDM/Group/17.xls": The system cannot find the file specified

Here's my session:

library(readxl)
library(XLConnect)

# attempting to read file from network drive
df1 <- read_excel("//Hzndhhsvf2/data/OCPH/EPI/BHSDM/Group/17.xls")
# pathname is fully qualified, but error thrown as above

cat(normalizePath("//Hzndhhsvf2/data/OCPH/EPI/BHSDM/Group/17.xls"))
# throws same error

# reading same file with different function
df2 <- readWorksheetFromFile("//Hzndhhsvf2/data/OCPH/EPI/BHSDM/Group/17.xls", 1)
# completes successfully

# reading same file from local drive
df3 <- read_excel("C:/17.xls")
# completes successfully

sessionInfo()
R version 3.3.2 (2016-10-31)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] readxl_0.1.1         dplyr_0.5.0          XLConnect_0.2-12
[4] XLConnectJars_0.2-12 ROracle_1.2-1        DBI_0.5-1

loaded via a namespace (and not attached):
[1] magrittr_1.5   R6_2.2.0       assertthat_0.1 tools_3.3.2    haven_1.0.0
[6] tibble_1.2     Rcpp_0.12.7    rJava_0.9-8

Please advise.
Thanks,

Michael Laviolette PhD MPH
Public Health Statistician
Bureau of Public Health Statistics and Informatics
New Hampshire Division of Public Health Services
29 Hazen Drive
Concord, NH 03301-6504
Phone: 603-271-5688
Fax: 603-271-7623
Email: Michael.Laviolette at dhhs.nh.gov



	[[alternative HTML version deleted]]


From J.Gorecki at wit.edu.pl  Thu Nov 17 22:40:15 2016
From: J.Gorecki at wit.edu.pl (Jan Gorecki)
Date: Thu, 17 Nov 2016 21:40:15 +0000
Subject: [Rd] new function to tools/utils package: dependencies based on
 DESCRIPTION file
In-Reply-To: <CAOQ5NyccwgSaL9VD0aWDZovm7gq0FT2OCoQh_3RfeBBUm2kqGA@mail.gmail.com>
References: <CABE2sp6e_kyX4vhR-uLAqpwNZxDyG-FD+AMBHE0uXp=c+UPQhw@mail.gmail.com>
	<CAJuCY5zfVudo7gyCi3NY1X012WgLyL7Tbkt7QeHy6zf0ZrQ2CA@mail.gmail.com>
	<CABE2sp7SrJtPDg-yZwdBDuNmSDoXv936i2biZzxUUaVEeQLa+g@mail.gmail.com>
	<CAO1zAVY9uAi3qEFUSBVDGdn50ijuhBDmJGHRL7cRNjaU01s6kA@mail.gmail.com>
	<CAO1zAVa69_0kh1ioXuqwq=R2t=5SeOHEZn0h7UJqjcKup45=xA@mail.gmail.com>
	<CAO1zAVZ9Crr370SsRM9y17JJPsLBcV_GT7P4LT7Cv5Zh2xy48Q@mail.gmail.com>
	<CABE2sp4XfD8oSOdMdKEmxT=BFh05ZEPtKif7h+KdACLEWYuLDw@mail.gmail.com>
	<CAOQ5NyccwgSaL9VD0aWDZovm7gq0FT2OCoQh_3RfeBBUm2kqGA@mail.gmail.com>
Message-ID: <CABE2sp4RJcC-dykbv1YynrOFj=9RzUinjUj0KW0mOBrgQQhwsg@mail.gmail.com>

Hi Michael,
Are you willing to accept patch for this? I'm already using this and
few related functions for a while, it plays well. I could wrap it as
patch to utils, or tools?
Best,
Jan

On 16 June 2016 at 14:00, Michael Lawrence <lawrence.michael at gene.com> wrote:
> I agree that the utils package needs some improvements related to
> this, and hope to make them eventually. This type of feedback is very
> helpful.
>
> Thanks,
> Michael
>
>
>
> On Thu, Jun 16, 2016 at 1:42 AM, Jan G?recki <J.Gorecki at wit.edu.pl> wrote:
>> Dear Joris,
>>
>> So it does looks like the proposed function makes a lot sense then, isn't it?
>>
>> Cheers,
>> Jan
>>
>> On 16 June 2016 at 08:37, Joris Meys <jorismeys at gmail.com> wrote:
>>> Dear Jan,
>>>
>>> It is unavoidable to have OS and R dependencies for devtools. The building
>>> process for packages is both OS and R dependent, so devtools has to be too
>>> according to my understanding.
>>>
>>> Cheers
>>> Joris
>>>
>>> On 14 Jun 2016 18:56, "Jan G?recki" <J.Gorecki at wit.edu.pl> wrote:
>>>
>>> Hi Thierry,
>>>
>>> I'm perfectly aware of it. Any idea when devtools would be shipped as
>>> a base R package, or at least recommended package? To actually answer
>>> the problem described in my email.
>>> I have range of useful functions available tools/utils packages which
>>> are shipped together with R. They doesn't require any OS dependencies
>>> or R dependencies, unlike devtools which requires both. Installing
>>> unnecessary OS dependencies and R dependencies just for such a simple
>>> wrapper doesn't seem to be an elegant way to address it, therefore my
>>> proposal to include that simple function in tools, or utils package.
>>>
>>> Regards,
>>> Jan Gorecki
>>>
>>> On 14 June 2016 at 16:17, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
>>>> Dear Jan,
>>>>
>>>> Similar functionality is available in devtools::dev_package_deps()
>>>>
>>>> Best regards,
>>>>
>>>> ir. Thierry Onkelinx
>>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
>>>> Forest
>>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>>> Kliniekstraat 25
>>>> 1070 Anderlecht
>>>> Belgium
>>>>
>>>> To call in the statistician after the experiment is done may be no more
>>>> than
>>>> asking him to perform a post-mortem examination: he may be able to say
>>>> what
>>>> the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>> The combination of some data and an aching desire for an answer does not
>>>> ensure that a reasonable answer can be extracted from a given body of
>>>> data.
>>>> ~ John Tukey
>>>>
>>>> 2016-06-14 16:54 GMT+02:00 Jan G?recki <J.Gorecki at wit.edu.pl>:
>>>>>
>>>>> Hi all,
>>>>>
>>>>> Packages tools and utils have a lot of useful stuff for R developers.
>>>>> I find one task still not as straightforward as it could. Simply to
>>>>> extract dependencies of a package from DESCRIPTION file (before it is
>>>>> even installed to library). This would be valuable in automation of CI
>>>>> setup in a more meta-data driven way.
>>>>> The simple function below, I know it is short and simple, but having
>>>>> it to be defined in each CI workflow is a pain, it could be already
>>>>> available in tools or utils namespace.
>>>>>
>>>>> package.dependencies.dcf <- function(file = "DESCRIPTION", which =
>>>>> c("Depends","Imports","LinkingTo")) {
>>>>>     stopifnot(file.exists(file), is.character(which))
>>>>>     which_all <- c("Depends", "Imports", "LinkingTo", "Suggests",
>>>>> "Enhances")
>>>>>     if (identical(which, "all"))
>>>>>         which <- which_all
>>>>>     else if (identical(which, "most"))
>>>>>         which <- c("Depends", "Imports", "LinkingTo", "Suggests")
>>>>>     stopifnot(which %in% which_all)
>>>>>     dcf <- read.dcf(file, which)
>>>>>     # parse fields
>>>>>     raw.deps <- unlist(strsplit(dcf[!is.na(dcf)], ",", fixed = TRUE))
>>>>>     # strip stated dependency version
>>>>>     deps <- trimws(sapply(strsplit(trimws(raw.deps), "(", fixed =
>>>>> TRUE), `[[`, 1L))
>>>>>     # exclude base R pkgs
>>>>>     base.pkgs <- c("R", rownames(installed.packages(priority = "base")))
>>>>>     setdiff(deps, base.pkgs)
>>>>> }
>>>>>
>>>>> This allows to easily install all package dependencies just based on
>>>>> DESCRIPTION file, so simplify that in custom CI workflows to:
>>>>>
>>>>> if (length(pkgs<-package.dependencies.dcf(which="all")))
>>>>> install.packages(pkgs)
>>>>>
>>>>> And would not require to install custom packages or shell scripts.
>>>>>
>>>>> Regards,
>>>>> Jan Gorecki
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From lawrence.michael at gene.com  Thu Nov 17 22:54:21 2016
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Thu, 17 Nov 2016 13:54:21 -0800
Subject: [Rd] new function to tools/utils package: dependencies based on
 DESCRIPTION file
In-Reply-To: <CABE2sp4RJcC-dykbv1YynrOFj=9RzUinjUj0KW0mOBrgQQhwsg@mail.gmail.com>
References: <CABE2sp6e_kyX4vhR-uLAqpwNZxDyG-FD+AMBHE0uXp=c+UPQhw@mail.gmail.com>
	<CAJuCY5zfVudo7gyCi3NY1X012WgLyL7Tbkt7QeHy6zf0ZrQ2CA@mail.gmail.com>
	<CABE2sp7SrJtPDg-yZwdBDuNmSDoXv936i2biZzxUUaVEeQLa+g@mail.gmail.com>
	<CAO1zAVY9uAi3qEFUSBVDGdn50ijuhBDmJGHRL7cRNjaU01s6kA@mail.gmail.com>
	<CAO1zAVa69_0kh1ioXuqwq=R2t=5SeOHEZn0h7UJqjcKup45=xA@mail.gmail.com>
	<CAO1zAVZ9Crr370SsRM9y17JJPsLBcV_GT7P4LT7Cv5Zh2xy48Q@mail.gmail.com>
	<CABE2sp4XfD8oSOdMdKEmxT=BFh05ZEPtKif7h+KdACLEWYuLDw@mail.gmail.com>
	<CAOQ5NyccwgSaL9VD0aWDZovm7gq0FT2OCoQh_3RfeBBUm2kqGA@mail.gmail.com>
	<CABE2sp4RJcC-dykbv1YynrOFj=9RzUinjUj0KW0mOBrgQQhwsg@mail.gmail.com>
Message-ID: <CAOQ5NycnEMkVaGNq4eJzrfo4Nenf67xLiXif0tbz072V1Fcz_w@mail.gmail.com>

Hi Jan,

Thanks for volunteering. You, me, Duncan Murdoch (if interested) and
anyone else who is interested should setup an informal chat. We need
to ensure that the API is right and that it fits in well with other
ongoing efforts.

Michael

On Thu, Nov 17, 2016 at 1:40 PM, Jan Gorecki <J.Gorecki at wit.edu.pl> wrote:
> Hi Michael,
> Are you willing to accept patch for this? I'm already using this and
> few related functions for a while, it plays well. I could wrap it as
> patch to utils, or tools?
> Best,
> Jan
>
> On 16 June 2016 at 14:00, Michael Lawrence <lawrence.michael at gene.com> wrote:
>> I agree that the utils package needs some improvements related to
>> this, and hope to make them eventually. This type of feedback is very
>> helpful.
>>
>> Thanks,
>> Michael
>>
>>
>>
>> On Thu, Jun 16, 2016 at 1:42 AM, Jan G?recki <J.Gorecki at wit.edu.pl> wrote:
>>> Dear Joris,
>>>
>>> So it does looks like the proposed function makes a lot sense then, isn't it?
>>>
>>> Cheers,
>>> Jan
>>>
>>> On 16 June 2016 at 08:37, Joris Meys <jorismeys at gmail.com> wrote:
>>>> Dear Jan,
>>>>
>>>> It is unavoidable to have OS and R dependencies for devtools. The building
>>>> process for packages is both OS and R dependent, so devtools has to be too
>>>> according to my understanding.
>>>>
>>>> Cheers
>>>> Joris
>>>>
>>>> On 14 Jun 2016 18:56, "Jan G?recki" <J.Gorecki at wit.edu.pl> wrote:
>>>>
>>>> Hi Thierry,
>>>>
>>>> I'm perfectly aware of it. Any idea when devtools would be shipped as
>>>> a base R package, or at least recommended package? To actually answer
>>>> the problem described in my email.
>>>> I have range of useful functions available tools/utils packages which
>>>> are shipped together with R. They doesn't require any OS dependencies
>>>> or R dependencies, unlike devtools which requires both. Installing
>>>> unnecessary OS dependencies and R dependencies just for such a simple
>>>> wrapper doesn't seem to be an elegant way to address it, therefore my
>>>> proposal to include that simple function in tools, or utils package.
>>>>
>>>> Regards,
>>>> Jan Gorecki
>>>>
>>>> On 14 June 2016 at 16:17, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
>>>>> Dear Jan,
>>>>>
>>>>> Similar functionality is available in devtools::dev_package_deps()
>>>>>
>>>>> Best regards,
>>>>>
>>>>> ir. Thierry Onkelinx
>>>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
>>>>> Forest
>>>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>>>> Kliniekstraat 25
>>>>> 1070 Anderlecht
>>>>> Belgium
>>>>>
>>>>> To call in the statistician after the experiment is done may be no more
>>>>> than
>>>>> asking him to perform a post-mortem examination: he may be able to say
>>>>> what
>>>>> the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>>> The combination of some data and an aching desire for an answer does not
>>>>> ensure that a reasonable answer can be extracted from a given body of
>>>>> data.
>>>>> ~ John Tukey
>>>>>
>>>>> 2016-06-14 16:54 GMT+02:00 Jan G?recki <J.Gorecki at wit.edu.pl>:
>>>>>>
>>>>>> Hi all,
>>>>>>
>>>>>> Packages tools and utils have a lot of useful stuff for R developers.
>>>>>> I find one task still not as straightforward as it could. Simply to
>>>>>> extract dependencies of a package from DESCRIPTION file (before it is
>>>>>> even installed to library). This would be valuable in automation of CI
>>>>>> setup in a more meta-data driven way.
>>>>>> The simple function below, I know it is short and simple, but having
>>>>>> it to be defined in each CI workflow is a pain, it could be already
>>>>>> available in tools or utils namespace.
>>>>>>
>>>>>> package.dependencies.dcf <- function(file = "DESCRIPTION", which =
>>>>>> c("Depends","Imports","LinkingTo")) {
>>>>>>     stopifnot(file.exists(file), is.character(which))
>>>>>>     which_all <- c("Depends", "Imports", "LinkingTo", "Suggests",
>>>>>> "Enhances")
>>>>>>     if (identical(which, "all"))
>>>>>>         which <- which_all
>>>>>>     else if (identical(which, "most"))
>>>>>>         which <- c("Depends", "Imports", "LinkingTo", "Suggests")
>>>>>>     stopifnot(which %in% which_all)
>>>>>>     dcf <- read.dcf(file, which)
>>>>>>     # parse fields
>>>>>>     raw.deps <- unlist(strsplit(dcf[!is.na(dcf)], ",", fixed = TRUE))
>>>>>>     # strip stated dependency version
>>>>>>     deps <- trimws(sapply(strsplit(trimws(raw.deps), "(", fixed =
>>>>>> TRUE), `[[`, 1L))
>>>>>>     # exclude base R pkgs
>>>>>>     base.pkgs <- c("R", rownames(installed.packages(priority = "base")))
>>>>>>     setdiff(deps, base.pkgs)
>>>>>> }
>>>>>>
>>>>>> This allows to easily install all package dependencies just based on
>>>>>> DESCRIPTION file, so simplify that in custom CI workflows to:
>>>>>>
>>>>>> if (length(pkgs<-package.dependencies.dcf(which="all")))
>>>>>> install.packages(pkgs)
>>>>>>
>>>>>> And would not require to install custom packages or shell scripts.
>>>>>>
>>>>>> Regards,
>>>>>> Jan Gorecki
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>>>
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel


From ecortens at mtroyal.ca  Thu Nov 17 23:51:03 2016
From: ecortens at mtroyal.ca (Evan Cortens)
Date: Thu, 17 Nov 2016 15:51:03 -0700
Subject: [Rd] problem with normalizePath()
In-Reply-To: <e6592864a7b34cca92711b6c3c309484@dhhs.nh.gov>
References: <e6592864a7b34cca92711b6c3c309484@dhhs.nh.gov>
Message-ID: <CABKQe-Zh+xoX5geKqYvGMpO1bPx5BjwD61cTY-1tKagLw-KJMA@mail.gmail.com>

I wonder if this could be related to the issue that I submitted to bugzilla
about two months ago? (
https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=17159)

That is to say, could it be that it's treating the first path after the
single backslash as an actual directory, rather than as the name of the
share?

-- 
Evan Cortens, PhD
Institutional Analyst - Office of Institutional Analysis
Mount Royal University
403-440-6529

On Thu, Nov 17, 2016 at 2:28 PM, Laviolette, Michael <
Michael.Laviolette at dhhs.nh.gov> wrote:

> The packages "readxl" and "haven" (and possibly others) no longer access
> files on shared network drives. The problem appears to be in the
> normalizePath() function. The file can be read from a local drive or by
> functions that don't call normalizePath(). The error thrown is
>
> Error: path[1]="\\Hzndhhsvf2/data/OCPH/EPI/BHSDM/Group/17.xls": The
> system cannot find the file specified
>
> Here's my session:
>
> library(readxl)
> library(XLConnect)
>
> # attempting to read file from network drive
> df1 <- read_excel("//Hzndhhsvf2/data/OCPH/EPI/BHSDM/Group/17.xls")
> # pathname is fully qualified, but error thrown as above
>
> cat(normalizePath("//Hzndhhsvf2/data/OCPH/EPI/BHSDM/Group/17.xls"))
> # throws same error
>
> # reading same file with different function
> df2 <- readWorksheetFromFile("//Hzndhhsvf2/data/OCPH/EPI/BHSDM/Group/17.xls",
> 1)
> # completes successfully
>
> # reading same file from local drive
> df3 <- read_excel("C:/17.xls")
> # completes successfully
>
> sessionInfo()
> R version 3.3.2 (2016-10-31)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> States.1252
> [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] readxl_0.1.1         dplyr_0.5.0          XLConnect_0.2-12
> [4] XLConnectJars_0.2-12 ROracle_1.2-1        DBI_0.5-1
>
> loaded via a namespace (and not attached):
> [1] magrittr_1.5   R6_2.2.0       assertthat_0.1 tools_3.3.2    haven_1.0.0
> [6] tibble_1.2     Rcpp_0.12.7    rJava_0.9-8
>
> Please advise.
> Thanks,
>
> Michael Laviolette PhD MPH
> Public Health Statistician
> Bureau of Public Health Statistics and Informatics
> New Hampshire Division of Public Health Services
> 29 Hazen Drive
> Concord, NH 03301-6504
> Phone: 603-271-5688
> Fax: 603-271-7623
> Email: Michael.Laviolette at dhhs.nh.gov
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From efmphone at gmail.com  Fri Nov 18 01:01:53 2016
From: efmphone at gmail.com (Evelyn Mitchell)
Date: Thu, 17 Nov 2016 17:01:53 -0700
Subject: [Rd] R-intro.texi patch
Message-ID: <CABD0H0u93=OxHVZGbRq_cv_+gKgJCtCGCC6vXehKDsW-i69fOQ@mail.gmail.com>

Note, the R-intro.R is correct.

svn diff R-intro.texi
Index: R-intro.texi
===================================================================
--- R-intro.texi        (revision 71664)
+++ R-intro.texi        (working copy)
@@ -1525,7 +1525,7 @@
After this assignment, the standard errors are calculated by

@example
-> incster <- tapply(incomes, statef, stderr)
+> incster <- tapply(incomes, statef, stdError)
@end example

@noindent



Evelyn Mitchell

	[[alternative HTML version deleted]]


From henrik.bengtsson at gmail.com  Fri Nov 18 11:08:19 2016
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Fri, 18 Nov 2016 11:08:19 +0100
Subject: [Rd] Tell whether ./.Rprofile or ~/.Rprofile is being processed?
Message-ID: <CAFDcVCSFPAyZAZrfKqzETc416rg2trw1K2jw-Uzt9pqqmZpQ+g@mail.gmail.com>

Hi.

Assume I have one ~/.Rprofile (in my home directory) and one
./.Rprofile (in my current working directory).  In this case, the
latter will have higher priority and will be the script that R uses
during the startup process.

Is there a *generic* way to programmatically from within ./.Rprofile
and ~/.Rprofile to tell what their absolute pathnames are or
equivalently what directories they are located in?  Conceptually
something like:

  path <- directoryOfRprofile()
  message("Running ", file.path(path, ".Rprofile"))
  message(".Rprofile is in the home directory: ", normalizePath(path)
== normalizePath("~"))

I don't want to / cannot manually set the `path` variable.

Since .Rprofile is sourced very early on when R starts up (e.g.
sys.calls() is NULL), I suspect the answer to my question is no, but
maybe someone else can prove me wrong.

Thanks,

Henrik


From maechler at stat.math.ethz.ch  Fri Nov 18 21:37:05 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 18 Nov 2016 21:37:05 +0100
Subject: [Rd] problem with normalizePath()
In-Reply-To: <CABKQe-Zh+xoX5geKqYvGMpO1bPx5BjwD61cTY-1tKagLw-KJMA@mail.gmail.com>
References: <e6592864a7b34cca92711b6c3c309484@dhhs.nh.gov>
	<CABKQe-Zh+xoX5geKqYvGMpO1bPx5BjwD61cTY-1tKagLw-KJMA@mail.gmail.com>
Message-ID: <22575.26225.614494.711839@stat.math.ethz.ch>

>>>>> Evan Cortens <ecortens at mtroyal.ca>
>>>>>     on Thu, 17 Nov 2016 15:51:03 -0700 writes:

    > I wonder if this could be related to the issue that I
    > submitted to bugzilla about two months ago? (
    > https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=17159)

    > That is to say, could it be that it's treating the first
    > path after the single backslash as an actual directory,
    > rather than as the name of the share?

    > -- 
    > Evan Cortens, PhD Institutional Analyst - Office of
    > Institutional Analysis Mount Royal University 403-440-6529

Could well be.  Thank you, Evan, also for your bug report
including patch proposal.

In such situations we (R core) would be really happy if
Microsoft showed another facet of their investment into R:
Ideally there should be enough staff who can judge and test such
bugs and bug fixes? 

--> I'm BCC'ing this to one place at least.

Best,
Martin Maechler  ETH Zurich

    > On Thu, Nov 17, 2016 at 2:28 PM, Laviolette, Michael <
    > Michael.Laviolette at dhhs.nh.gov> wrote:

    >> The packages "readxl" and "haven" (and possibly others)
    >> no longer access files on shared network drives. The
    >> problem appears to be in the normalizePath()
    >> function. The file can be read from a local drive or by
    >> functions that don't call normalizePath(). The error
    >> thrown is
    >> 
    >> Error:
    >> path[1]="\\Hzndhhsvf2/data/OCPH/EPI/BHSDM/Group/17.xls":
    >> The system cannot find the file specified
    >> 
    >> Here's my session:
    >> 
    >> library(readxl) library(XLConnect)
    >> 
    >> # attempting to read file from network drive df1 <-
    >> read_excel("//Hzndhhsvf2/data/OCPH/EPI/BHSDM/Group/17.xls")
    >> # pathname is fully qualified, but error thrown as above
    >> 
    >> cat(normalizePath("//Hzndhhsvf2/data/OCPH/EPI/BHSDM/Group/17.xls"))
    >> # throws same error
    >> 
    >> # reading same file with different function df2 <-
    >> readWorksheetFromFile("//Hzndhhsvf2/data/OCPH/EPI/BHSDM/Group/17.xls",
    >> 1) # completes successfully
    >> 
    >> # reading same file from local drive df3 <-
    >> read_excel("C:/17.xls") # completes successfully
    >> 
    >> sessionInfo() R version 3.3.2 (2016-10-31) Platform:
    >> x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 7
    >> x64 (build 7601) Service Pack 1
    >> 
    >> locale: [1] LC_COLLATE=English_United States.1252
    >> LC_CTYPE=English_United States.1252 [3]
    >> LC_MONETARY=English_United States.1252 LC_NUMERIC=C [5]
    >> LC_TIME=English_United States.1252
    >> 
    >> attached base packages: [1] stats graphics grDevices
    >> utils datasets methods base
    >> 
    >> other attached packages: [1] readxl_0.1.1 dplyr_0.5.0
    >> XLConnect_0.2-12 [4] XLConnectJars_0.2-12 ROracle_1.2-1
    >> DBI_0.5-1
    >> 
    >> loaded via a namespace (and not attached): [1]
    >> magrittr_1.5 R6_2.2.0 assertthat_0.1 tools_3.3.2
    >> haven_1.0.0 [6] tibble_1.2 Rcpp_0.12.7 rJava_0.9-8
    >> 
    >> Please advise.  Thanks,
    >> 
    >> Michael Laviolette PhD MPH Public Health Statistician
    >> Bureau of Public Health Statistics and Informatics New
    >> Hampshire Division of Public Health Services 29 Hazen
    >> Drive Concord, NH 03301-6504 Phone: 603-271-5688 Fax:
    >> 603-271-7623 Email: Michael.Laviolette at dhhs.nh.gov
    >> 
    >> 
    >> 
    >> [[alternative HTML version deleted]]
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> 

    > 	[[alternative HTML version deleted]]

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From jrm at ftfl.ca  Mon Nov 21 00:28:01 2016
From: jrm at ftfl.ca (Joseph Mingrone)
Date: Sun, 20 Nov 2016 19:28:01 -0400
Subject: [Rd] shared libraries: missing soname
Message-ID: <868tsdohoe.fsf@phe.ftfl.ca>

Hello,

R's shared libraries are linked without setting the soname.  This is causing problems for some consumers.

        Error: /usr/local/lib/R/library/tseries/libs/tseries.so is linked to
        /usr/local/lib/R/lib/libRblas.so which does not have a SONAME.  math/R needs
        to be fixed.

What's the correct way to add the necessary linker flags?  I believe it should be something like this.

       cc -shared -Wl,-soname,...

Regards,

Joseph
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 930 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20161120/5df39727/attachment.bin>

From edd at debian.org  Mon Nov 21 02:06:45 2016
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 20 Nov 2016 19:06:45 -0600
Subject: [Rd] shared libraries: missing soname
In-Reply-To: <868tsdohoe.fsf@phe.ftfl.ca>
References: <868tsdohoe.fsf@phe.ftfl.ca>
Message-ID: <22578.18597.717387.458240@max.nulle.part>


On 20 November 2016 at 19:28, Joseph Mingrone wrote:
| Hello,
| 
| R's shared libraries are linked without setting the soname.  This is causing problems for some consumers.
| 
|         Error: /usr/local/lib/R/library/tseries/libs/tseries.so is linked to
|         /usr/local/lib/R/lib/libRblas.so which does not have a SONAME.  math/R needs
|         to be fixed.
| 
| What's the correct way to add the necessary linker flags?  I believe it should be something like this.
| 
|        cc -shared -Wl,-soname,...

I think that may be true "in theory" (for libraries loaded by ldd(8) via
`/etc/ld.conf`) but not "in practice" for R which loads these shared
libraries itself (via dlopen(3) etc).

For what it is worth, I have been providing the Debian packages "as is" for
now 15+ years and nobody has complained. 

What system are you on to get that complaint?

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From jrm at ftfl.ca  Mon Nov 21 02:49:18 2016
From: jrm at ftfl.ca (Joseph Mingrone)
Date: Sun, 20 Nov 2016 21:49:18 -0400
Subject: [Rd] shared libraries: missing soname
In-Reply-To: <22578.18597.717387.458240@max.nulle.part> (Dirk Eddelbuettel's
	message of "Sun, 20 Nov 2016 19:06:45 -0600")
References: <868tsdohoe.fsf@phe.ftfl.ca>
	<22578.18597.717387.458240@max.nulle.part>
Message-ID: <864m31ob4x.fsf@phe.ftfl.ca>

Hello Dirk,

Dirk Eddelbuettel <edd at debian.org> writes:

> On 20 November 2016 at 19:28, Joseph Mingrone wrote:
> | Hello,
> | 
> | R's shared libraries are linked without setting the soname.  This is causing problems for some consumers.
> | 
> |         Error: /usr/local/lib/R/library/tseries/libs/tseries.so is linked to
> |         /usr/local/lib/R/lib/libRblas.so which does not have a SONAME.  math/R needs
> |         to be fixed.
> | 
> | What's the correct way to add the necessary linker flags?  I believe it should be something like this.
> | 
> |        cc -shared -Wl,-soname,...

> I think that may be true "in theory" (for libraries loaded by ldd(8) via
> `/etc/ld.conf`) but not "in practice" for R which loads these shared
> libraries itself (via dlopen(3) etc).

R may use dlopen() but other customers may not.

> For what it is worth, I have been providing the Debian packages "as is" for
> now 15+ years and nobody has complained. 

> What system are you on to get that complaint?

This is on FreeBSD.  Our apt-get, pkg, will not register shared library dependencies if the shared library does not have a soname.  If the library gets changed and is no longer compatible with the previous version, and there is no soname to check, pkg will not know that all its dependencies need to be reinstalled.

Regards,

Joseph
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 930 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20161120/c61e4bd8/attachment.bin>

From edd at debian.org  Mon Nov 21 03:33:23 2016
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 20 Nov 2016 20:33:23 -0600
Subject: [Rd] shared libraries: missing soname
In-Reply-To: <864m31ob4x.fsf@phe.ftfl.ca>
References: <868tsdohoe.fsf@phe.ftfl.ca>
	<22578.18597.717387.458240@max.nulle.part>
	<864m31ob4x.fsf@phe.ftfl.ca>
Message-ID: <22578.23795.540869.831235@max.nulle.part>


On 20 November 2016 at 21:49, Joseph Mingrone wrote:
| Hello Dirk,
| 
| Dirk Eddelbuettel <edd at debian.org> writes:
| 
| > On 20 November 2016 at 19:28, Joseph Mingrone wrote:
| > | Hello,
| > | 
| > | R's shared libraries are linked without setting the soname.  This is causing problems for some consumers.
| > | 
| > |         Error: /usr/local/lib/R/library/tseries/libs/tseries.so is linked to
| > |         /usr/local/lib/R/lib/libRblas.so which does not have a SONAME.  math/R needs
| > |         to be fixed.
| > | 
| > | What's the correct way to add the necessary linker flags?  I believe it should be something like this.
| > | 
| > |        cc -shared -Wl,-soname,...
| 
| > I think that may be true "in theory" (for libraries loaded by ldd(8) via
| > `/etc/ld.conf`) but not "in practice" for R which loads these shared
| > libraries itself (via dlopen(3) etc).
| 
| R may use dlopen() but other customers may not.

Yes, well, but are there other customers?
 
| > For what it is worth, I have been providing the Debian packages "as is" for
| > now 15+ years and nobody has complained. 
| 
| > What system are you on to get that complaint?
| 
| This is on FreeBSD.  Our apt-get, pkg, will not register shared library dependencies if the shared library does not have a soname.  If the library gets changed and is no longer compatible with the previous version, and there is no soname to check, pkg will not know that all its dependencies need to be reinstalled.

Hmpf. No mechanism for fallback / default soname?  In that case you (or
whoever acts as FreeBSD maintainer) may have to supply one.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From jrm at ftfl.ca  Tue Nov 22 04:24:30 2016
From: jrm at ftfl.ca (Joseph Mingrone)
Date: Mon, 21 Nov 2016 23:24:30 -0400
Subject: [Rd] shared libraries: missing soname
In-Reply-To: <22578.23795.540869.831235@max.nulle.part> (Dirk Eddelbuettel's
	message of "Sun, 20 Nov 2016 20:33:23 -0600")
References: <868tsdohoe.fsf@phe.ftfl.ca>
	<22578.18597.717387.458240@max.nulle.part>
	<864m31ob4x.fsf@phe.ftfl.ca>
	<22578.23795.540869.831235@max.nulle.part>
Message-ID: <86y40cgpsh.fsf@phe.ftfl.ca>

Dirk,

Dirk Eddelbuettel <edd at debian.org> writes:
> On 20 November 2016 at 21:49, Joseph Mingrone wrote:
> | Hello Dirk,
> | 
> | Dirk Eddelbuettel <edd at debian.org> writes:
> | 
> | > On 20 November 2016 at 19:28, Joseph Mingrone wrote:
> | > | Hello,
> | > | 
> | > | R's shared libraries are linked without setting the soname.  This is causing problems for some consumers.
> | > | 
> | > |         Error: /usr/local/lib/R/library/tseries/libs/tseries.so is linked to
> | > |         /usr/local/lib/R/lib/libRblas.so which does not have a SONAME.  math/R needs
> | > |         to be fixed.
> | > | 
> | > | What's the correct way to add the necessary linker flags?  I believe it should be something like this.
> | > | 
> | > |        cc -shared -Wl,-soname,...
> | 
> | > I think that may be true "in theory" (for libraries loaded by ldd(8) via
> | > `/etc/ld.conf`) but not "in practice" for R which loads these shared
> | > libraries itself (via dlopen(3) etc).
> | 
> | R may use dlopen() but other customers may not.

> Yes, well, but are there other customers?

Yes.  Here is one example. https://rkward.kde.org/

> | > For what it is worth, I have been providing the Debian packages "as is" for
> | > now 15+ years and nobody has complained. 
> | 
> | > What system are you on to get that complaint?
> | 
> | This is on FreeBSD.  Our apt-get, pkg, will not register shared library dependencies if the shared library does not have a soname.  If the library
> | gets changed and is no longer compatible with the previous version, and there is no soname to check, pkg will not know that all its dependencies
> | need to be reinstalled.

> Hmpf. No mechanism for fallback / default soname?  In that case you (or
> whoever acts as FreeBSD maintainer) may have to supply one.

Using a fallback or default soname would defeat the purpose, which is to detect
when the library's interface has changed, so that the proper action can be
taken.  I could provide a local patch for R's autotools, but as a package
maintainer yourself, I expect you also prefer when upstream get's it right.

Are there any constructive reasons not to include a proper soname?

Regards,

Joseph
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 930 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20161121/edc08748/attachment.bin>

From edd at debian.org  Tue Nov 22 04:42:04 2016
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 21 Nov 2016 21:42:04 -0600
Subject: [Rd] shared libraries: missing soname
In-Reply-To: <86y40cgpsh.fsf@phe.ftfl.ca>
References: <868tsdohoe.fsf@phe.ftfl.ca>
	<22578.18597.717387.458240@max.nulle.part>
	<864m31ob4x.fsf@phe.ftfl.ca>
	<22578.23795.540869.831235@max.nulle.part>
	<86y40cgpsh.fsf@phe.ftfl.ca>
Message-ID: <22579.48780.66762.666285@max.nulle.part>


On 21 November 2016 at 23:24, Joseph Mingrone wrote:
| Dirk Eddelbuettel <edd at debian.org> writes:
| > On 20 November 2016 at 21:49, Joseph Mingrone wrote:
| > | Hello Dirk,
| > | 
| > | Dirk Eddelbuettel <edd at debian.org> writes:
| > | 
| > | > On 20 November 2016 at 19:28, Joseph Mingrone wrote:
| > | > | Hello,
| > | > | 
| > | > | R's shared libraries are linked without setting the soname.  This is causing problems for some consumers.
| > | > | 
| > | > |         Error: /usr/local/lib/R/library/tseries/libs/tseries.so is linked to
| > | > |         /usr/local/lib/R/lib/libRblas.so which does not have a SONAME.  math/R needs
| > | > |         to be fixed.
| > | > | 
| > | > | What's the correct way to add the necessary linker flags?  I believe it should be something like this.
| > | > | 
| > | > |        cc -shared -Wl,-soname,...
| > | 
| > | > I think that may be true "in theory" (for libraries loaded by ldd(8) via
| > | > `/etc/ld.conf`) but not "in practice" for R which loads these shared
| > | > libraries itself (via dlopen(3) etc).
| > | 
| > | R may use dlopen() but other customers may not.
| 
| > Yes, well, but are there other customers?
| 
| Yes.  Here is one example. https://rkward.kde.org/

Really?  We had that eg in Debian too for a decade plus and it works just
fine _as is_ and finds its libraries. Without requiring a change.

It (AFAIK) just embeds R "as is" (as does my much smaller RInside).

  edd at bud:~$ ldd /usr/bin/rkward | grep R      # no R libs known to ldd
  edd at bud:~$ ldd /usr/bin/rkward | wc -l       # lots other shared libraries
  40
  edd at bud:~$ 
 
| > | > For what it is worth, I have been providing the Debian packages "as is" for
| > | > now 15+ years and nobody has complained. 
| > | 
| > | > What system are you on to get that complaint?
| > | 
| > | This is on FreeBSD.  Our apt-get, pkg, will not register shared library dependencies if the shared library does not have a soname.  If the library
| > | gets changed and is no longer compatible with the previous version, and there is no soname to check, pkg will not know that all its dependencies
| > | need to be reinstalled.
| 
| > Hmpf. No mechanism for fallback / default soname?  In that case you (or
| > whoever acts as FreeBSD maintainer) may have to supply one.
| 
| Using a fallback or default soname would defeat the purpose, which is to detect
| when the library's interface has changed, so that the proper action can be
| taken.  I could provide a local patch for R's autotools, but as a package
| maintainer yourself, I expect you also prefer when upstream get's it right.
| 
| Are there any constructive reasons not to include a proper soname?

I fear you are complaining to the wrong person. I am not a committer; just a
happy user, packager, and contributor. But as my first email tried to state:
nobody here seems to see a problem yet.

Best of luck,  Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From jrm at ftfl.ca  Tue Nov 22 05:02:59 2016
From: jrm at ftfl.ca (Joseph Mingrone)
Date: Tue, 22 Nov 2016 00:02:59 -0400
Subject: [Rd] shared libraries: missing soname
In-Reply-To: <22579.48780.66762.666285@max.nulle.part> (Dirk Eddelbuettel's
	message of "Mon, 21 Nov 2016 21:42:04 -0600")
References: <868tsdohoe.fsf@phe.ftfl.ca>
	<22578.18597.717387.458240@max.nulle.part>
	<864m31ob4x.fsf@phe.ftfl.ca>
	<22578.23795.540869.831235@max.nulle.part>
	<86y40cgpsh.fsf@phe.ftfl.ca> <22579.48780.66762.666285@max.nulle.part>
Message-ID: <86twb0go0c.fsf@phe.ftfl.ca>

Dirk,

Dirk Eddelbuettel <edd at debian.org> writes:
> On 21 November 2016 at 23:24, Joseph Mingrone wrote:
> | Dirk Eddelbuettel <edd at debian.org> writes:
> | > On 20 November 2016 at 21:49, Joseph Mingrone wrote:
> | > | Hello Dirk,
> | > | 
> | > | Dirk Eddelbuettel <edd at debian.org> writes:
> | > | 
> | > | > On 20 November 2016 at 19:28, Joseph Mingrone wrote:
> | > | > | Hello,
> | > | > | 
> | > | > | R's shared libraries are linked without setting the soname.  This is causing problems for some consumers.
> | > | > | 
> | > | > |         Error: /usr/local/lib/R/library/tseries/libs/tseries.so is linked to
> | > | > |         /usr/local/lib/R/lib/libRblas.so which does not have a SONAME.  math/R needs
> | > | > |         to be fixed.
> | > | > | 
> | > | > | What's the correct way to add the necessary linker flags?  I believe it should be something like this.
> | > | > | 
> | > | > |        cc -shared -Wl,-soname,...
> | > | 
> | > | > I think that may be true "in theory" (for libraries loaded by ldd(8) via
> | > | > `/etc/ld.conf`) but not "in practice" for R which loads these shared
> | > | > libraries itself (via dlopen(3) etc).
> | > | 
> | > | R may use dlopen() but other customers may not.
> | 
> | > Yes, well, but are there other customers?
> | 
> | Yes.  Here is one example. https://rkward.kde.org/

> Really?  We had that eg in Debian too for a decade plus and it works just
> fine _as is_ and finds its libraries. Without requiring a change.

These are also not fatal errors on FreeBSD, where everything, for now, also just
works.  ...until a library's interface changes.  You seem to be arguing that
sonmaes are pointless.  We disagree.

> It (AFAIK) just embeds R "as is" (as does my much smaller RInside).

>   edd at bud:~$ ldd /usr/bin/rkward | grep R      # no R libs known to ldd
>   edd at bud:~$ ldd /usr/bin/rkward | wc -l       # lots other shared libraries
>   40
>   edd at bud:~$

I can't say for certain (I'm not an rkward user), but looking at the build
log, it seems to.  Do you have R built as a shared library?

Here are select lines from rkward's build log:

...
-- Checking for existence of R shared library
-- Exists at /usr/local/lib/R/lib/libR.so
-- Checking whether we should link against Rlapack library
-- Yes, /usr/local/lib/R/lib/libRlapack.so exists
-- Checking whether we should link against Rblas library
...
...
/usr/bin/c++   -O2 -pipe -I/usr/local/include -fstack-protector -fno-strict-aliasing -Wnon-virtual-dtor -Wno-long-long -Wundef -Wcast-align -Wchar-subscripts -Wall -W -Wpointer-arith -Wformat-security -Woverloaded-virtual -fno-common -fvisibility=hidden -Werror=return-type -fvisibility-inlines-hidden -Wno-return-type-c-linkage -O2 -DNDEBUG -DQT_NO_DEBUG   -Wl,-rpath=/usr/local/lib/gcc48  -L/usr/local/lib/gcc48 -B/usr/local/bin -fstack-protector CMakeFiles/rkward.rbackend.dir/rkrbackend.o CMakeFiles/rkward.rbackend.dir/rksignalsupport.o CMakeFiles/rkward.rbackend.dir/rklocalesupport.o CMakeFiles/rkward.rbackend.dir/rkrsupport.o CMakeFiles/rkward.rbackend.dir/rkstructuregetter.o CMakeFiles/rkward.rbackend.dir/rkrbackendprotocol_backend.o CMakeFiles/rkward.rbackend.dir/rkreventloop.o CMakeFiles/rkward.rbackend.dir/rkrbackendprotocol_shared.o CMakeFiles/rkward.rbackend.dir/rdata.o CMakeFiles/rkward.rbackend.dir/rkbackendtransmitter.o CMakeFiles/rkward.rbackend.dir/rktransmitter.o  -o rkward.rbackend  -L/usr/local/lib  -L/usr/local/lib/R/lib  -L/wrkdirs/usr/ports/math/rkward-kde4/work/rkward-0.6.5/lib  -L/usr/local/lib/qt4  ../../lib/librkgraphicsdevice.backend.a -lR -lRlapack -lRblas -pthread /usr/local/lib/qt4/libQtNetwork.so /usr/local/lib/qt4/libQtCore.so -pthread /usr/local/lib/libintl.so -Wl,-rpath,/usr/local/lib:/usr/local/lib/R/lib:/usr/local/lib/qt4:
...

> | > | > For what it is worth, I have been providing the Debian packages "as is" for
> | > | > now 15+ years and nobody has complained. 
> | > | 
> | > | > What system are you on to get that complaint?
> | > | 
> | > | This is on FreeBSD.  Our apt-get, pkg, will not register shared library dependencies if the shared library does not have a soname.  If the library
> | > | gets changed and is no longer compatible with the previous version, and there is no soname to check, pkg will not know that all its dependencies
> | > | need to be reinstalled.
> | 
> | > Hmpf. No mechanism for fallback / default soname?  In that case you (or
> | > whoever acts as FreeBSD maintainer) may have to supply one.
> | 
> | Using a fallback or default soname would defeat the purpose, which is to detect
> | when the library's interface has changed, so that the proper action can be
> | taken.  I could provide a local patch for R's autotools, but as a package
> | maintainer yourself, I expect you also prefer when upstream get's it right.
> | 
> | Are there any constructive reasons not to include a proper soname?
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 930 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20161122/b3de9c71/attachment.bin>

From edd at debian.org  Tue Nov 22 05:17:35 2016
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 21 Nov 2016 22:17:35 -0600
Subject: [Rd] shared libraries: missing soname
In-Reply-To: <86twb0go0c.fsf@phe.ftfl.ca>
References: <868tsdohoe.fsf@phe.ftfl.ca>
	<22578.18597.717387.458240@max.nulle.part>
	<864m31ob4x.fsf@phe.ftfl.ca>
	<22578.23795.540869.831235@max.nulle.part>
	<86y40cgpsh.fsf@phe.ftfl.ca>
	<22579.48780.66762.666285@max.nulle.part>
	<86twb0go0c.fsf@phe.ftfl.ca>
Message-ID: <22579.50911.667739.32126@max.nulle.part>


Joseph,

I will try to let this be my last message in this thread.  Just to clarify:

On 22 November 2016 at 00:02, Joseph Mingrone wrote:
| These are also not fatal errors on FreeBSD, where everything, for now, also just
| works.  ...until a library's interface changes.  You seem to be arguing that
| sonmaes are pointless.  We disagree.

You are putting words in my mouth. In my very first reply to you, I pointed
out that (for non-BSD systems at least) the sonames do not matter as R loads
the libraries itself, rather than via ldd.  No more, no less.

Just like just about everybody else, I believe strongly in common use of
sonames _for normal libraries_. R, however, uses dynamic loading of _its
extension modules_ outside of the system use and has its own system of
dependency management and versioning.

| I can't say for certain (I'm not an rkward user), but looking at the build

Why did _you_ then bring up rkward as an example? That was your suggestion.

| log, it seems to.  Do you have R built as a shared library?

Yes, always.
 
| Here are select lines from rkward's build log:

I am not sure what point you are trying to make.


Please consider myself withdrawn from this discussion.

Thank you,  Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From maechler at stat.math.ethz.ch  Tue Nov 22 11:12:51 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 22 Nov 2016 11:12:51 +0100
Subject: [Rd] ifelse() woes ... can we agree on a ifelse2() ?
In-Reply-To: <CADwqtCOKRLEFW0wkEy1B8CO+VYJbQ64uEWkNgKS1EXoWedA0Jw@mail.gmail.com>
References: <22437.61893.901739.933100@stat.math.ethz.ch>
	<deb934cc-d781-8011-d29b-f1cbcf60407e@gmail.com>
	<22445.44128.203938.13068@stat.math.ethz.ch>
	<CABdHhvEtBu5=zPuhXNxtTH_5vBbmqbr-U0j3WH9ftjUeABqEWA@mail.gmail.com>
	<CABdHhvHniPZ1P5SKWJ=trkufv6feFSfsc1Aq4k7v=AAaok32AQ@mail.gmail.com>
	<20161115115836.CF93C1CB503@lynne.stat.math.ethz.ch>
	<CADwqtCOKRLEFW0wkEy1B8CO+VYJbQ64uEWkNgKS1EXoWedA0Jw@mail.gmail.com>
Message-ID: <22580.6691.701229.463172@stat.math.ethz.ch>

>>>>> Gabriel Becker <gmbecker at ucdavis.edu>
>>>>>     on Tue, 15 Nov 2016 11:56:04 -0800 writes:

    > All,
    > Martin: Thanks for this and all the other things you are doing to both
    > drive R forward and engage more with the community about things like this.

    > Apologies for missing this discussion the first time it came around and if
    > anything here has already been brought up, but I wonder what exactly you
    > mean when you want recycling behavior.

Thank you, Gabe.

Note that my premise was really to get *away* from inheriting
too much from 'test'.
Hence, I have *not* been talking about replacing ifelse() but
rather of providing a new  ifelse2()

       [ or if_else()  if Hadley was willing to ditch the dplyr one
       	  	       in favor of a base one]

    > Specifically, based on an unrelated discussion with Henrik Bengtsson on
    > Twitter, I wonder if preserving the recycling behavior test is longer than
    > yes, no, but making the case where

    > length( test ) < max(length( yes ), length( no ))

    > would simplify usage for userRs in a useful way.

I'm sorry I don't understand the sentence above.

    > I suspect it's easy to
    > forget that the result is not guaranteed to be the length of  test, even
    > for intermediate and advanced users familiar with ifelse and it's
    > strengths/weaknesses.

    > I certainly agree (for what that's worth...) that

    > x = rnorm(100)

    > y = ifelse2(x > 0, 1L, 2L)

    > should continue to work.

(and give a a length 10 result).
Also
	ifelse2(x > 0, sqrt(x), 0L)

should work even though  class(sqrt(x)) is "numeric" and the one
of 0L is "integer", and I'd argue

	ifelse2(x < 0, sqrt(x + 0i), sqrt(x))

should also continue to work as with ifelse().

    > Also, If we combine a stricter contract that the output will always be of
    > length with the suggestion of a specified output class 

that was not my intent here.... but would be another interesting
extension. However, I would like to keep  R-semantic silent coercions
such as
	  logical < integer < double < complex

and your pseudo code below would not work so easily I think.

    > the pseudo code could be

(I'm changing assignment '=' to  '<-' ...  [please!] )

    > ifelse2 <- function(test, yes, no, outclass) {
    >   lenout  <- length(test)
    >   out <- as( rep(yes, length.out <- lenout), outclass)
    >   out[!test] <- as(rep(no, length.out = lenout)[!test], outclass)
    >   # handle NA stuff
    >   out
    > }


    > NAs could be tricky if outclass were allowed to be completely general, but
    > doable, I think? Another approach  if we ARE fast-passing while leaving
    > ifelse intact is that maybe NA's in test just aren't allowed in ifelse2.
    > I'm not saying we should definitely do that, but it's possible and would
    > make things faster.

    > Finally, In terms of efficiency, with the stuff that Luke and I are working
    > on, the NA detection could be virtually free in certain cases, which could
    > give a nice boost for long vectors  that don't have any NAs (and 'know'
    > that they don't).

That *is* indeed a very promising prospect!
Thank you in advance! 

    > Best,
    > ~G

I still am bit disappointed by the fact that it seems nobody has
taken a good look at my ifelse2() proposal.

I really would like an alternative to ifelse() in *addition* to
the current ifelse(), but hopefully in the future being used in
quite a few places instead of ifelse()
efficiency but for changed semantics, namely working for considerably
more "vector like" classes of  'yes' and 'no'  than the current
ifelse().

As I said, the current proposal works for objects of class
   "Date", "POSIXct", "POSIXlt", "factor",  "mpfr" (pkg 'Rmpfr')
and hopefully for "sparseVector" (in a next version of the 'Matrix' pkg).

Martin

    > On Tue, Nov 15, 2016 at 3:58 AM, Martin Maechler <maechler at stat.math.ethz.ch
    >> wrote:

    >> Finally getting back to this :
    >> 
    >> >>>>> Hadley Wickham <h.wickham at gmail.com>
    >> >>>>>     on Mon, 15 Aug 2016 07:51:35 -0500 writes:
    >> 
    >> > On Fri, Aug 12, 2016 at 11:31 AM, Hadley Wickham
    >> > <h.wickham at gmail.com> wrote:
    >> >>> >> One possibility would also be to consider a
    >> >>> "numbers-only" or >> rather "same type"-only {e.g.,
    >> >>> would also work for characters} >> version.
    >> >>>
    >> >>> > I don't know what you mean by these.
    >> >>>
    >> >>> In the mean time, Bob Rudis mentioned dplyr::if_else(),
    >> >>> which is very relevant, thank you Bob!
    >> >>>
    >> >>> As I have found, that actually works in such a "same
    >> >>> type"-only way: It does not try to coerce, but gives an
    >> >>> error when the classes differ, even in this somewhat
    >> >>> debatable case :
    >> >>>
    >> >>> > dplyr::if_else(c(TRUE, FALSE), 2:3, 0+10:11) Error:
    >> >>> `false` has type 'double' not 'integer'
    >> >>> >
    >> >>>
    >> >>> As documented, if_else() is clearly stricter than
    >> >>> ifelse() and e.g., also does no recycling (but of
    >> >>> length() 1).
    >> >>
    >> >> I agree that if_else() is currently too strict - it's
    >> >> particularly annoying if you want to replace some values
    >> >> with a missing:
    >> >>
    >> >> x <- sample(10) if_else(x > 5, NA, x) # Error: `false`
    >> >> has type 'integer' not 'logical'
    >> >>
    >> >> But I would like to make sure that this remains an error:
    >> >>
    >> >> if_else(x > 5, x, "BLAH")
    >> >>
    >> >> Because that seems more likely to be a user error (but
    >> >> reasonable people might certainly believe that it should
    >> >> just work)
    >> >>
    >> >> dplyr is more accommodating in other places (i.e. in
    >> >> bind_rows(), collapse() and the joins) but it's
    >> >> surprisingly hard to get all the details right. For
    >> >> example, what should the result of this call be?
    >> >>
    >> >> if_else(c(TRUE, FALSE), factor(c("a", "b")),
    >> >> factor(c("c", "b"))
    >> >>
    >> >> Strictly speaking I think you could argue it's an error,
    >> >> but that's not very user-friendly. Should it be a factor
    >> >> with the union of the levels? Should it be a character
    >> >> vector + warning? Should the behaviour change if one set
    >> >> of levels is a subset of the other set?
    >> >>
    >> >> There are similar issues for POSIXct (if the time zones
    >> >> are different, which should win?), and difftimes
    >> >> (similarly for units).  Ideally you'd like the behaviour
    >> >> to be extensible for new S3 classes, which suggests it
    >> >> should be a generic (and for the most general case, it
    >> >> would need to dispatch on both arguments).
    >> 
    >> > One possible principle would be to use c() -
    >> > i.e. construct out as
    >> 
    >> > out <- c(yes[0], no[0]
    >> > length(out) <- max(length(yes), length(no))
    >> 
    >> yes; this would require that a  `length<-` method works for the
    >> class of the result.
    >> 
    >> Duncan Murdoch mentioned a version of this, in his very
    >> first reply:
    >> 
    >> ans <- c(yes, no)[seq_along(test)]
    >> ans <- ans[seq_along(test)]
    >> 
    >> which is less efficient for atomic vectors, but requires
    >> less from the class: it "only" needs `c` and `[` to work
    >> 
    >> and a mixture of your two proposals would be possible too:
    >> 
    >> ans <- c(yes[0], no[0])
    >> ans <- ans[seq_along(test)]
    >> 
    >> which does *not* work for my "mpfr" numbers (CRAN package 'Rmpfr'),
    >> but that's a buglet in the  c.mpfr() implementation of my Rmpfr
    >> package... (which has already been fixed in the development version on
    >> R-forge,
    >> https://r-forge.r-project.org/R/?group_id=386)
    >> 
    >> > But of course that wouldn't help with factor responses.
    >> 
    >> Yes.  However, a version of Duncan's suggestion -- of treating 'yes' first
    >> -- does help in that case.
    >> 
    >> For once, mainly as "feasability experiment",
    >> I have created a github gist to make my current ifelse2() proposal
    >> available
    >> for commenting, cloning, pullrequesting, etc:
    >> 
    >> Consisting of 2 files
    >> - ifelse-def.R :  Functions definitions only, basically all the current
    >> proposals, called  ifelse*()
    >> - ifelse-checks.R : A simplistic checking function
    >> and examples calling it, notably demonstrating that my
    >> ifelse2()  does work with
    >> "Date", <dateTime> (i.e. "POSIXct" and "POSIXlt"), factors,
    >> and "mpfr" (the arbitrary-precision numbers in my package "Rmpfr")
    >> 
    >> Also if you are not on github, you can quickly get to the ifelse2()
    >> definition :
    >> 
    >> https://gist.github.com/mmaechler/9cfc3219c4b89649313bfe6853d878
    >> 94#file-ifelse-def-r-L168
    >> 
    >> > Also, if you're considering an improved ifelse(), I'd
    >> > strongly urge you to consider adding an `na` argument,
    >> 
    >> I now did (called it 'NA.').
    >> 
    >> > so that you can use ifelse() to transform all three
    >> > possible values in a logical vector.
    >> 
    >> > Hadley
    >> > -- http://hadley.nz
    >> 
    >> For those who really hate GH (and don't want or cannot easily follow the
    >> above URL), here's my current definition:
    >> 
    >> 
    >> ##' Martin Maechler, 14. Nov 2016 --- taking into account Duncan M. and
    >> Hadley's
    >> ##' ideas in the R-devel thread starting at (my mom's 86th birthday):
    >> ##' https://stat.ethz.ch/pipermail/r-devel/2016-August/072970.html
    >> ifelse2 <- function (test, yes, no, NA. = NA) {
    >> if(!is.logical(test)) {
    >> if(is.atomic(test))
    >> storage.mode(test) <- "logical"
    >> else ## typically a "class"; storage.mode<-() typically fails
    >> test <- if(isS4(test)) methods::as(test, "logical") else
    >> as.logical(test)
    >> }
    >> 
    >> ## No longer optimize the  "if (a) x else y"  cases:
    >> ## Only "non-good" R users use ifelse(.) instead of if(.) in these
    >> cases.
    >> 
    >> ans <-
    >> tryCatch(rep(if(is.object(yes) && identical(class(yes), class(no)))
    >> ## as c(o) or o[0] may not work for the class
    >> yes else c(yes[0], no[0]), length.out =
    >> length(test)),
    >> error = function(e) { ## try asymmetric, yes-leaning
    >> r <- yes
    >> r[!test] <- no[!test]
    >> r
    >> })
    >> ok <- !(nas <- is.na(test))
    >> if (any(test[ok]))
    >> ans[test & ok] <- rep(yes, length.out = length(ans))[test & ok]
    >> if (any(!test[ok]))
    >> ans[!test & ok] <- rep(no, length.out = length(ans))[!test & ok]
    >> ans[nas] <- NA. # possibly coerced to class(ans)
    >> ans
    >> }
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> 



    > -- 
    > Gabriel Becker, PhD
    > Associate Scientist (Bioinformatics)
    > Genentech Research

    > [[alternative HTML version deleted]]


From gmbecker at ucdavis.edu  Tue Nov 22 15:44:05 2016
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Tue, 22 Nov 2016 06:44:05 -0800
Subject: [Rd] ifelse() woes ... can we agree on a ifelse2() ?
In-Reply-To: <22580.6691.701229.463172@stat.math.ethz.ch>
References: <22437.61893.901739.933100@stat.math.ethz.ch>
	<deb934cc-d781-8011-d29b-f1cbcf60407e@gmail.com>
	<22445.44128.203938.13068@stat.math.ethz.ch>
	<CABdHhvEtBu5=zPuhXNxtTH_5vBbmqbr-U0j3WH9ftjUeABqEWA@mail.gmail.com>
	<CABdHhvHniPZ1P5SKWJ=trkufv6feFSfsc1Aq4k7v=AAaok32AQ@mail.gmail.com>
	<20161115115836.CF93C1CB503@lynne.stat.math.ethz.ch>
	<CADwqtCOKRLEFW0wkEy1B8CO+VYJbQ64uEWkNgKS1EXoWedA0Jw@mail.gmail.com>
	<22580.6691.701229.463172@stat.math.ethz.ch>
Message-ID: <CADwqtCNftiAb51367pxYH8fn3BSjtPxvpZiJ6JkPivEhJv8vfQ@mail.gmail.com>

Martin et al.,




On Tue, Nov 22, 2016 at 2:12 AM, Martin Maechler <maechler at stat.math.ethz.ch
> wrote:

>
> Note that my premise was really to get *away* from inheriting
> too much from 'test'.
> Hence, I have *not* been talking about replacing ifelse() but
> rather of providing a new  ifelse2()
>
>        [ or if_else()  if Hadley was willing to ditch the dplyr one
>                        in favor of a base one]
>
>     > Specifically, based on an unrelated discussion with Henrik Bengtsson
> on
>     > Twitter, I wonder if preserving the recycling behavior test is
> longer than
>     > yes, no, but making the case where
>
>     > length( test ) < max(length( yes ), length( no ))
>
>     > would simplify usage for userRs in a useful way.
>

That was a copyediting bug on my part, it seems I hit send with my message
only half-edited/proofread. Apologies.

 That should have said that making the case where test is the one that will
be recycled (because it is shorter than either yes or no) an error. My
claim is that the fact that test itself can be recycled, rather than just
yes or no, is confusing to many R users. If we are writing an ifelse2 we
might want to drop that feature and just throw an error in that case.
(Users could still use the original ifelse if they understand and
specifically want that behavior).

Does that make more sense?



>
>     > Also, If we combine a stricter contract that the output will always
> be of
>     > length with the suggestion of a specified output class
>
>
Here, again, I was talking about the restriction that the output be
guaranteed to be the length of test, regardless of the length of yes and
no. That, combined with a specific, guaranteed output class would make a
much narrower/more restricted but also (I argue) much easier to understand
function. Particularly for beginning and intermediate users.

I do hear what you're saying about silent conversion, though, so what I'm
describing might be a third function (ifelse3 for lack of a better name for
now), as you pointed out.


> that was not my intent here.... but would be another interesting
> extension. However, I would like to keep  R-semantic silent coercions
> such as
>           logical < integer < double < complex
>
> and your pseudo code below would not work so easily I think.
>
>     > the pseudo code could be
>
> (I'm changing assignment '=' to  '<-' ...  [please!] )
>
>     > ifelse2 <- function(test, yes, no, outclass) {
>     >   lenout  <- length(test)
>     >   out <- as( rep(yes, length.out <- lenout), outclass)
>     >   out[!test] <- as(rep(no, length.out = lenout)[!test], outclass)
>     >   # handle NA stuff
>     >   out
>     > }
>
>
>     > NAs could be tricky if outclass were allowed to be completely
> general, but
>     > doable, I think? Another approach  if we ARE fast-passing while
> leaving
>     > ifelse intact is that maybe NA's in test just aren't allowed in
> ifelse2.
>     > I'm not saying we should definitely do that, but it's possible and
> would
>     > make things faster.
>
>     > Finally, In terms of efficiency, with the stuff that Luke and I are
> working
>     > on, the NA detection could be virtually free in certain cases, which
> could
>     > give a nice boost for long vectors  that don't have any NAs (and
> 'know'
>     > that they don't).
>
> That *is* indeed a very promising prospect!
> Thank you in advance!
>
>     > Best,
>     > ~G
>
> I still am bit disappointed by the fact that it seems nobody has
> taken a good look at my ifelse2() proposal.
>

I plan to look at it soon. Thanks again for all your work.

~G


>
> I really would like an alternative to ifelse() in *addition* to
> the current ifelse(), but hopefully in the future being used in
> quite a few places instead of ifelse()
> efficiency but for changed semantics, namely working for considerably
> more "vector like" classes of  'yes' and 'no'  than the current
> ifelse().
>
> As I said, the current proposal works for objects of class
>    "Date", "POSIXct", "POSIXlt", "factor",  "mpfr" (pkg 'Rmpfr')
> and hopefully for "sparseVector" (in a next version of the 'Matrix' pkg).
>
> Martin
>
>     > On Tue, Nov 15, 2016 at 3:58 AM, Martin Maechler <
> maechler at stat.math.ethz.ch
>     >> wrote:
>
>     >> Finally getting back to this :
>     >>
>     >> >>>>> Hadley Wickham <h.wickham at gmail.com>
>     >> >>>>>     on Mon, 15 Aug 2016 07:51:35 -0500 writes:
>     >>
>     >> > On Fri, Aug 12, 2016 at 11:31 AM, Hadley Wickham
>     >> > <h.wickham at gmail.com> wrote:
>     >> >>> >> One possibility would also be to consider a
>     >> >>> "numbers-only" or >> rather "same type"-only {e.g.,
>     >> >>> would also work for characters} >> version.
>     >> >>>
>     >> >>> > I don't know what you mean by these.
>     >> >>>
>     >> >>> In the mean time, Bob Rudis mentioned dplyr::if_else(),
>     >> >>> which is very relevant, thank you Bob!
>     >> >>>
>     >> >>> As I have found, that actually works in such a "same
>     >> >>> type"-only way: It does not try to coerce, but gives an
>     >> >>> error when the classes differ, even in this somewhat
>     >> >>> debatable case :
>     >> >>>
>     >> >>> > dplyr::if_else(c(TRUE, FALSE), 2:3, 0+10:11) Error:
>     >> >>> `false` has type 'double' not 'integer'
>     >> >>> >
>     >> >>>
>     >> >>> As documented, if_else() is clearly stricter than
>     >> >>> ifelse() and e.g., also does no recycling (but of
>     >> >>> length() 1).
>     >> >>
>     >> >> I agree that if_else() is currently too strict - it's
>     >> >> particularly annoying if you want to replace some values
>     >> >> with a missing:
>     >> >>
>     >> >> x <- sample(10) if_else(x > 5, NA, x) # Error: `false`
>     >> >> has type 'integer' not 'logical'
>     >> >>
>     >> >> But I would like to make sure that this remains an error:
>     >> >>
>     >> >> if_else(x > 5, x, "BLAH")
>     >> >>
>     >> >> Because that seems more likely to be a user error (but
>     >> >> reasonable people might certainly believe that it should
>     >> >> just work)
>     >> >>
>     >> >> dplyr is more accommodating in other places (i.e. in
>     >> >> bind_rows(), collapse() and the joins) but it's
>     >> >> surprisingly hard to get all the details right. For
>     >> >> example, what should the result of this call be?
>     >> >>
>     >> >> if_else(c(TRUE, FALSE), factor(c("a", "b")),
>     >> >> factor(c("c", "b"))
>     >> >>
>     >> >> Strictly speaking I think you could argue it's an error,
>     >> >> but that's not very user-friendly. Should it be a factor
>     >> >> with the union of the levels? Should it be a character
>     >> >> vector + warning? Should the behaviour change if one set
>     >> >> of levels is a subset of the other set?
>     >> >>
>     >> >> There are similar issues for POSIXct (if the time zones
>     >> >> are different, which should win?), and difftimes
>     >> >> (similarly for units).  Ideally you'd like the behaviour
>     >> >> to be extensible for new S3 classes, which suggests it
>     >> >> should be a generic (and for the most general case, it
>     >> >> would need to dispatch on both arguments).
>     >>
>     >> > One possible principle would be to use c() -
>     >> > i.e. construct out as
>     >>
>     >> > out <- c(yes[0], no[0]
>     >> > length(out) <- max(length(yes), length(no))
>     >>
>     >> yes; this would require that a  `length<-` method works for the
>     >> class of the result.
>     >>
>     >> Duncan Murdoch mentioned a version of this, in his very
>     >> first reply:
>     >>
>     >> ans <- c(yes, no)[seq_along(test)]
>     >> ans <- ans[seq_along(test)]
>     >>
>     >> which is less efficient for atomic vectors, but requires
>     >> less from the class: it "only" needs `c` and `[` to work
>     >>
>     >> and a mixture of your two proposals would be possible too:
>     >>
>     >> ans <- c(yes[0], no[0])
>     >> ans <- ans[seq_along(test)]
>     >>
>     >> which does *not* work for my "mpfr" numbers (CRAN package 'Rmpfr'),
>     >> but that's a buglet in the  c.mpfr() implementation of my Rmpfr
>     >> package... (which has already been fixed in the development version
> on
>     >> R-forge,
>     >> https://r-forge.r-project.org/R/?group_id=386)
>     >>
>     >> > But of course that wouldn't help with factor responses.
>     >>
>     >> Yes.  However, a version of Duncan's suggestion -- of treating
> 'yes' first
>     >> -- does help in that case.
>     >>
>     >> For once, mainly as "feasability experiment",
>     >> I have created a github gist to make my current ifelse2() proposal
>     >> available
>     >> for commenting, cloning, pullrequesting, etc:
>     >>
>     >> Consisting of 2 files
>     >> - ifelse-def.R :  Functions definitions only, basically all the
> current
>     >> proposals, called  ifelse*()
>     >> - ifelse-checks.R : A simplistic checking function
>     >> and examples calling it, notably demonstrating that my
>     >> ifelse2()  does work with
>     >> "Date", <dateTime> (i.e. "POSIXct" and "POSIXlt"), factors,
>     >> and "mpfr" (the arbitrary-precision numbers in my package "Rmpfr")
>     >>
>     >> Also if you are not on github, you can quickly get to the ifelse2()
>     >> definition :
>     >>
>     >> https://gist.github.com/mmaechler/9cfc3219c4b89649313bfe6853d878
>     >> 94#file-ifelse-def-r-L168
>     >>
>     >> > Also, if you're considering an improved ifelse(), I'd
>     >> > strongly urge you to consider adding an `na` argument,
>     >>
>     >> I now did (called it 'NA.').
>     >>
>     >> > so that you can use ifelse() to transform all three
>     >> > possible values in a logical vector.
>     >>
>     >> > Hadley
>     >> > -- http://hadley.nz
>     >>
>     >> For those who really hate GH (and don't want or cannot easily
> follow the
>     >> above URL), here's my current definition:
>     >>
>     >>
>     >> ##' Martin Maechler, 14. Nov 2016 --- taking into account Duncan M.
> and
>     >> Hadley's
>     >> ##' ideas in the R-devel thread starting at (my mom's 86th
> birthday):
>     >> ##' https://stat.ethz.ch/pipermail/r-devel/2016-August/072970.html
>     >> ifelse2 <- function (test, yes, no, NA. = NA) {
>     >> if(!is.logical(test)) {
>     >> if(is.atomic(test))
>     >> storage.mode(test) <- "logical"
>     >> else ## typically a "class"; storage.mode<-() typically fails
>     >> test <- if(isS4(test)) methods::as(test, "logical") else
>     >> as.logical(test)
>     >> }
>     >>
>     >> ## No longer optimize the  "if (a) x else y"  cases:
>     >> ## Only "non-good" R users use ifelse(.) instead of if(.) in these
>     >> cases.
>     >>
>     >> ans <-
>     >> tryCatch(rep(if(is.object(yes) && identical(class(yes), class(no)))
>     >> ## as c(o) or o[0] may not work for the class
>     >> yes else c(yes[0], no[0]), length.out =
>     >> length(test)),
>     >> error = function(e) { ## try asymmetric, yes-leaning
>     >> r <- yes
>     >> r[!test] <- no[!test]
>     >> r
>     >> })
>     >> ok <- !(nas <- is.na(test))
>     >> if (any(test[ok]))
>     >> ans[test & ok] <- rep(yes, length.out = length(ans))[test & ok]
>     >> if (any(!test[ok]))
>     >> ans[!test & ok] <- rep(no, length.out = length(ans))[!test & ok]
>     >> ans[nas] <- NA. # possibly coerced to class(ans)
>     >> ans
>     >> }
>     >>
>     >> ______________________________________________
>     >> R-devel at r-project.org mailing list
>     >> https://stat.ethz.ch/mailman/listinfo/r-devel
>     >>
>
>
>
>     > --
>     > Gabriel Becker, PhD
>     > Associate Scientist (Bioinformatics)
>     > Genentech Research
>
>     > [[alternative HTML version deleted]]
>
>


-- 
Gabriel Becker, PhD
Associate Scientist (Bioinformatics)
Genentech Research

	[[alternative HTML version deleted]]


From jrm at ftfl.ca  Wed Nov 23 03:21:49 2016
From: jrm at ftfl.ca (Joseph Mingrone)
Date: Tue, 22 Nov 2016 22:21:49 -0400
Subject: [Rd] shared libraries: missing soname
In-Reply-To: <22579.50911.667739.32126@max.nulle.part> (Dirk Eddelbuettel's
	message of "Mon, 21 Nov 2016 22:17:35 -0600")
References: <868tsdohoe.fsf@phe.ftfl.ca>
	<22578.18597.717387.458240@max.nulle.part>
	<864m31ob4x.fsf@phe.ftfl.ca>
	<22578.23795.540869.831235@max.nulle.part>
	<86y40cgpsh.fsf@phe.ftfl.ca> <22579.48780.66762.666285@max.nulle.part>
	<86twb0go0c.fsf@phe.ftfl.ca> <22579.50911.667739.32126@max.nulle.part>
Message-ID: <86twazaqbm.fsf@phe.ftfl.ca>

Dirk Eddelbuettel <edd at debian.org> writes:

> On 22 November 2016 at 00:02, Joseph Mingrone wrote:
> | These are also not fatal errors on FreeBSD, where everything, for now, also just
> | works.  ...until a library's interface changes.  You seem to be arguing that
> | sonmaes are pointless.  We disagree.

> You are putting words in my mouth. In my very first reply to you, I pointed
> out that (for non-BSD systems at least) the sonames do not matter as R loads
> the libraries itself, rather than via ldd.  No more, no less.

Let me restate.  You seem to be arguing that, because R itself doesn't consume
it's shared libraries via ldd(), sonames serve no purpose, in this case.  Please
correct me if I'm putting words in your mouth.

> | I can't say for certain (I'm not an rkward user), but looking at the build

> Why did _you_ then bring up rkward as an example? That was your suggestion.

Because you asked, "Yes, well, but are there other customers?"  Also, I'm trying
to put myself in the perspective of package users.

Is this a more appropriate example?

# ldd /usr/local/lib/R/library/tseries/libs/tseries.so | grep libR
libRblas.so => /usr/local/lib/R/lib/libRblas.so (0x80120c000)
libR.so => /usr/local/lib/R/lib/libR.so (0x801c00000)
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 930 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20161122/3c7c773a/attachment.bin>

From maechler at stat.math.ethz.ch  Wed Nov 23 10:16:50 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 23 Nov 2016 10:16:50 +0100
Subject: [Rd] shared libraries: missing soname
In-Reply-To: <86twazaqbm.fsf@phe.ftfl.ca>
References: <868tsdohoe.fsf@phe.ftfl.ca>
	<22578.18597.717387.458240@max.nulle.part>
	<864m31ob4x.fsf@phe.ftfl.ca>
	<22578.23795.540869.831235@max.nulle.part>
	<86y40cgpsh.fsf@phe.ftfl.ca>
	<22579.48780.66762.666285@max.nulle.part>
	<86twb0go0c.fsf@phe.ftfl.ca>
	<22579.50911.667739.32126@max.nulle.part>
	<86twazaqbm.fsf@phe.ftfl.ca>
Message-ID: <22581.24194.824366.415231@stat.math.ethz.ch>

>>>>> Joseph Mingrone <jrm at ftfl.ca>
>>>>>     on Tue, 22 Nov 2016 22:21:49 -0400 writes:

    > Dirk Eddelbuettel <edd at debian.org> writes:
    >> On 22 November 2016 at 00:02, Joseph Mingrone wrote:
    >> | These are also not fatal errors on FreeBSD, where everything, for now, also just
    >> | works.  ...until a library's interface changes.  You seem to be arguing that
    >> | sonmaes are pointless.  We disagree.

    >> You are putting words in my mouth. In my very first reply to you, I pointed
    >> out that (for non-BSD systems at least) the sonames do not matter as R loads
    >> the libraries itself, rather than via ldd.  No more, no less.

    > Let me restate.  You seem to be arguing that, because R itself doesn't consume
    > it's shared libraries via ldd(), sonames serve no purpose, in this case.  Please
    > correct me if I'm putting words in your mouth.

    >> | I can't say for certain (I'm not an rkward user), but looking at the build

    >> Why did _you_ then bring up rkward as an example? That was your suggestion.

    > Because you asked, "Yes, well, but are there other customers?"  Also, I'm trying
    > to put myself in the perspective of package users.

    > Is this a more appropriate example?

    > # ldd /usr/local/lib/R/library/tseries/libs/tseries.so | grep libR
    > libRblas.so => /usr/local/lib/R/lib/libRblas.so (0x80120c000)
    > libR.so => /usr/local/lib/R/lib/libR.so (0x801c00000)

Well, Dirk has said to have given his last reply on this thread.
I (as a member of R-core) am glad about people like Dirk who
take some of our load and helpfully answer such
questions/reports on R-devel.

To the issue:  I also don't see what your point is.
R works with these so libraries  as intended  in all cases as
far as we know, and so I don't understand why anything needs to
be changed.
All these libraries "belong to R" and are tied to a specific
version of R  and are not be used outside of R,  so I also don't see
your point.

Best regards,

Martin Maechler
ETH Zurich


From jrm at ftfl.ca  Wed Nov 23 11:22:41 2016
From: jrm at ftfl.ca (Joseph Mingrone)
Date: Wed, 23 Nov 2016 06:22:41 -0400
Subject: [Rd] shared libraries: missing soname
In-Reply-To: <22581.24194.824366.415231@stat.math.ethz.ch> (Martin Maechler's
	message of "Wed, 23 Nov 2016 10:16:50 +0100")
References: <868tsdohoe.fsf@phe.ftfl.ca>
	<22578.18597.717387.458240@max.nulle.part>
	<864m31ob4x.fsf@phe.ftfl.ca>
	<22578.23795.540869.831235@max.nulle.part>
	<86y40cgpsh.fsf@phe.ftfl.ca> <22579.48780.66762.666285@max.nulle.part>
	<86twb0go0c.fsf@phe.ftfl.ca> <22579.50911.667739.32126@max.nulle.part>
	<86twazaqbm.fsf@phe.ftfl.ca>
	<22581.24194.824366.415231@stat.math.ethz.ch>
Message-ID: <86h96ybimm.fsf@phe.ftfl.ca>

Martin Maechler <maechler at stat.math.ethz.ch> writes:
> To the issue:  I also don't see what your point is.
> R works with these so libraries  as intended  in all cases as
> far as we know, and so I don't understand why anything needs to
> be changed.
> All these libraries "belong to R" and are tied to a specific
> version of R  and are not be used outside of R,  so I also don't see
> your point.

"are not to be used outside of R".  You are distributing shared libraries that
aren't meant to be shared (outside of R)?  But they are.  And I gave an example.

This is the first sentence of section 3.1.1 [1] of the Linux Documentation
Project's -Program Library HOWTO-, "Every shared library has a special name
called the 'soname'".  I'll ask again, since this was ignored the two previous
times I asked it (but I don't expect an answer).  Are there any constructive
reasons not to include a proper soname in the shared libraries?

I will just patch the FreeBSD port.

Joseph

[1] http://www.tldp.org/HOWTO/Program-Library-HOWTO/shared-libraries.html#AEN46
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 930 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20161123/395db973/attachment.bin>

From edd at debian.org  Wed Nov 23 17:41:14 2016
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 23 Nov 2016 10:41:14 -0600
Subject: [Rd] shared libraries: missing soname
In-Reply-To: <86h96ybimm.fsf@phe.ftfl.ca>
References: <868tsdohoe.fsf@phe.ftfl.ca>
	<22578.18597.717387.458240@max.nulle.part>
	<864m31ob4x.fsf@phe.ftfl.ca>
	<22578.23795.540869.831235@max.nulle.part>
	<86y40cgpsh.fsf@phe.ftfl.ca>
	<22579.48780.66762.666285@max.nulle.part>
	<86twb0go0c.fsf@phe.ftfl.ca>
	<22579.50911.667739.32126@max.nulle.part>
	<86twazaqbm.fsf@phe.ftfl.ca>
	<22581.24194.824366.415231@stat.math.ethz.ch>
	<86h96ybimm.fsf@phe.ftfl.ca>
Message-ID: <22581.50858.767147.808685@max.nulle.part>


On 22 November 2016 at 22:21, Joseph Mingrone wrote:
| Is this a more appropriate example?
| 
| # ldd /usr/local/lib/R/library/tseries/libs/tseries.so | grep libR
| libRblas.so => /usr/local/lib/R/lib/libRblas.so (0x80120c000)
| libR.so => /usr/local/lib/R/lib/libR.so (0x801c00000)

No it is not.  Do you see the /usr/local/lib/R/lib here?

The trailing R/lib is what Martin and talk about. It means ldd / ldconfig
does not know about it -- if you do `ldconfig -p | grep libR` chances are you
see nothing.

On 23 November 2016 at 06:22, Joseph Mingrone wrote:
| Martin Maechler <maechler at stat.math.ethz.ch> writes:
| > To the issue:  I also don't see what your point is.
| > R works with these so libraries  as intended  in all cases as
| > far as we know, and so I don't understand why anything needs to
| > be changed.
| > All these libraries "belong to R" and are tied to a specific
| > version of R  and are not be used outside of R,  so I also don't see
| > your point.
| 
| "are not to be used outside of R".  You are distributing shared libraries that
| aren't meant to be shared (outside of R)?  But they are.  And I gave an example.

A wrong one though.
 
| I will just patch the FreeBSD port.

Please do.

You currently are the only one with an itch to scratch, and everybody else is
busy. If / when you have a patch which puts a token soname onto every shared
library produced [ internally ] by R feel free to offer it to R Core.

As Martin told you, so far there is no reason to take it but maybe that will
change. Or not. 

Consider eg this:

  edd at max:~$ locate Matrix.so
  /usr/lib/R/library/Matrix/libs/Matrix.so
  /usr/local/lib/R/site-library/Matrix/libs/Matrix.so
  /usr/local/lib/R-devel/lib/R/library/Matrix/libs/Matrix.so
  edd at max:~$

I have three versions of Matrix.so. And still not problem.  The third one
only enters for R-devel, not R.  The first two are distinguished by R itself
_by virtue of different paths_ just like Martin and I told you.

And _no_ other program on my system knows about Matrix.so:

  edd at max:~$ ldconfig -p | grep Matrix.so
  edd at max:~$ ldconfig -p | wc -l
  2814
  edd at max:~$

ldd / ldconfig do NOT know Matrix.so -- as I told you before -- despite the
fact that they know thousands of other things on this (development) machine.

All that you said or quoted about soname is fine and handy, and we all
respect it __for public libraries like libpng or libxml2.

R is different. So if FreeBSD has a problem with that you may indeed have to
work around that on the FreeBSD side of things.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From christian.krause at idiv.de  Thu Nov 24 08:30:52 2016
From: christian.krause at idiv.de (Christian Krause)
Date: Thu, 24 Nov 2016 08:30:52 +0100
Subject: [Rd] [parallel-package] feature request: set default cluster type
 via environment variable
Message-ID: <3458b75c-fbb7-f9c1-b05a-f06c399f4443@idiv.de>

Dear all,

I?m working as an administrator of a High-Performance Computing (HPC) Cluster which runs on Linux. A lot of people are using R on this Linux cluster and, of course, the *parallel* package to speed up their computations.

It has been our collective experience, that using |makeForkCluster| yields an overall better experience /on Linux/ than the |makePSOCKcluster|, for whatever definition of better. Let me just summarize that it works smoother. I believe, other people working with *parallel* on Linux can share this experience

Also, we did really welcome the environment variable |MC_CORES|, to be able to specify (in job submit scripts) the amount of CPU cores a user has been granted, most importantly for /dynamic resource requests/ (see below for an example).

What we would also appreciate - and now we finally get to the feature request - is another environment variable to choose the used cluster, as in:

|export MC_CLUSTER_TYPE=FORK |

Do you think something like this could be implemented in future releases?


      Parallel R job submit script

This works with the Univa Grid Engine and should work with other * Grid Engine products:

|#!/bin/bash # request a "parallel environment" with 2 to 20 cores #$ -pe smp 2-20 # set number of cores for the R cluster to the granted value (between 2 and 20) export MC_CORES=$NSLOTS # we want this: export MC_CLUSTER_TYPE=FORK Rscript /path/to/script.R |

Best Regards

?
-- 

Christian Krause

Scientific Computing Administration and Support

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Phone: +49 341 97 33144

Email: christian.krause at idiv.de

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

German Centre for Integrative Biodiversity Research (iDiv) Halle-Jena-Leipzig

Deutscher Platz 5e

04103 Leipzig

Germany

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

iDiv is a research centre of the DFG ? Deutsche Forschungsgemeinschaft

iDiv ist eine zentrale Einrichtung der Universit?t Leipzig im Sinne des ? 92 Abs. 1 S?chsHSFG und wird zusammen mit der Martin-Luther-Universit?t Halle-Wittenberg und der Friedrich-Schiller-Universit?t Jena betrieben sowie in Kooperation mit dem Helmholtz-Zentrum f?r Umweltforschung GmbH ? UFZ. Beteiligte Kooperationspartner sind die folgenden au?eruniversit?ren Forschungseinrichtungen: das Helmholtz-Zentrum f?r Umweltforschung GmbH - UFZ, das Max-Planck-Institut f?r Biogeochemie (MPI BGC), das Max-Planck-Institut f?r chemische ?kologie (MPI CE), das Max-Planck-Institut f?r evolution?re Anthropologie (MPI EVA), das Leibniz-Institut Deutsche Sammlung von Mikroorganismen und Zellkulturen (DSMZ), das Leibniz-Institut f?r Pflanzenbiochemie (IPB), das Leibniz-Institut f?r Pflanzengenetik und Kulturpflanzenforschung (IPK) und das Leibniz-Institut Senckenberg Museum f?r Naturkunde G?rlitz (SMNG). USt-IdNr. DE 141510383


	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Thu Nov 24 15:42:53 2016
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 24 Nov 2016 14:42:53 +0000
Subject: [Rd] [parallel-package] feature request: set default cluster
 type via environment variable
In-Reply-To: <3458b75c-fbb7-f9c1-b05a-f06c399f4443@idiv.de>
References: <3458b75c-fbb7-f9c1-b05a-f06c399f4443@idiv.de>
Message-ID: <f35856b3-4b5e-6e7b-cf06-2af0e6875a3f@stats.ox.ac.uk>

On 24/11/2016 07:30, Christian Krause wrote:
> Dear all,
>
> I?m working as an administrator of a High-Performance Computing (HPC) Cluster which runs on Linux. A lot of people are using R on this Linux cluster and, of course, the *parallel* package to speed up their computations.
>
> It has been our collective experience, that using |makeForkCluster| yields an overall better experience /on Linux/ than the |makePSOCKcluster|, for whatever definition of better. Let me just summarize that it works smoother. I believe, other people working with *parallel* on Linux can share this experience

Usually, but not always.  And the differences are mainly in 
initialization time, so small once workers are given a reasonable amount 
of work (tens of seconds each).  However, as forked workers have a copy 
of the whole master process, forking workers can lead to excessive 
memory usage.

> Also, we did really welcome the environment variable |MC_CORES|, to be able to specify (in job submit scripts) the amount of CPU cores a user has been granted, most importantly for /dynamic resource requests/ (see below for an example).

Hmm, MC_CORES is primarily for mclapply() and friends, not 
makeCluster().  makeForkCluster() is a 'friend' so uses it, but 
makePSOCKcluster() was designed for distributing across a cluster of 
machines (whereas makeForkCluster is restricted to a single multicore 
machine).

> What we would also appreciate - and now we finally get to the feature request - is another environment variable to choose the used cluster, as in:
>
> |export MC_CLUSTER_TYPE=FORK |
>
> Do you think something like this could be implemented in future releases?

No.  (Not least as 'MC_' refers to the former 'multicore' package.)

PSOCK and Fork clusters are not interchangeable, and the author of the 
code has to check if Fork can be substituted for PSOCK (which starts 
with a clean R environment, and that may well be assumed).

So rather, you need to ask your users to implement this in their calls 
to parallel::makeCluster.



>
>
>       Parallel R job submit script
>
> This works with the Univa Grid Engine and should work with other * Grid Engine products:
>
> |#!/bin/bash # request a "parallel environment" with 2 to 20 cores #$ -pe smp 2-20 # set number of cores for the R cluster to the granted value (between 2 and 20) export MC_CORES=$NSLOTS # we want this: export MC_CLUSTER_TYPE=FORK Rscript /path/to/script.R |
>
> Best Regards
>
> ?
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford


From jrm at ftfl.ca  Fri Nov 25 03:09:36 2016
From: jrm at ftfl.ca (Joseph Mingrone)
Date: Thu, 24 Nov 2016 22:09:36 -0400
Subject: [Rd] shared libraries: missing soname
References: <868tsdohoe.fsf@phe.ftfl.ca>
	<22578.18597.717387.458240@max.nulle.part>
	<864m31ob4x.fsf@phe.ftfl.ca>
	<22578.23795.540869.831235@max.nulle.part>
	<86y40cgpsh.fsf@phe.ftfl.ca> <22579.48780.66762.666285@max.nulle.part>
	<86twb0go0c.fsf@phe.ftfl.ca> <22579.50911.667739.32126@max.nulle.part>
	<86twazaqbm.fsf@phe.ftfl.ca>
	<22581.24194.824366.415231@stat.math.ethz.ch>
	<86h96ybimm.fsf@phe.ftfl.ca>
	<22581.50858.767147.808685@max.nulle.part>
Message-ID: <868ts8nwdb.fsf@phe.ftfl.ca>

Martin Maechler <maechler at stat.math.ethz.ch> writes:
> Well, Dirk has said to have given his last reply on this thread.
> I (as a member of R-core) am glad about people like Dirk who
> take some of our load and helpfully answer such
> questions/reports on R-devel.

I am glad too.  Thank you.  My ultimate goal is to ensure that R works as well
on FreeBSD as it does elsewhere.  It mostly just works (again, appreciative),
but there are a few challenges because some R conventions and some FreeBSD
conventions may collide.

Dirk Eddelbuettel <edd at debian.org> writes:
> Consider eg this:

>   edd at max:~$ locate Matrix.so
>   /usr/lib/R/library/Matrix/libs/Matrix.so
>   /usr/local/lib/R/site-library/Matrix/libs/Matrix.so
>   /usr/local/lib/R-devel/lib/R/library/Matrix/libs/Matrix.so
>   edd at max:~$

> I have three versions of Matrix.so. And still not problem.  The third one
> only enters for R-devel, not R.  The first two are distinguished by R itself
> _by virtue of different paths_ just like Martin and I told you.

> And _no_ other program on my system knows about Matrix.so:

>   edd at max:~$ ldconfig -p | grep Matrix.so
>   edd at max:~$ ldconfig -p | wc -l
>   2814
>   edd at max:~$

> ldd / ldconfig do NOT know Matrix.so -- as I told you before -- despite the
> fact that they know thousands of other things on this (development) machine.

For a frequently-updated Debian package repository, I assume you _manually_ bump
all the Debian R packages whenever the main R package is upgraded.  Is that
correct?  That is, when a Debian user upgrades the r-base package from, say,
version 3.2.5 to 3.3.1, then r-cran-tseries must/should be rebuilt/reinstalled
against the new R package?  If so, maybe there is something useful we could
submit.  I will have to study how R uses autotools, because that also seems a
bit different than I am used to.

I also notice that on Debian you make a soft link of /usr/lib/R/lib/libR.so to
/usr/lib/libR.so.  Given all that has been discussed, I am unclear why.

Thank you for sticking with the thread,

Joseph
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 930 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20161124/be4da4d3/attachment.bin>

From edd at debian.org  Fri Nov 25 03:43:35 2016
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 24 Nov 2016 20:43:35 -0600
Subject: [Rd] shared libraries: missing soname
In-Reply-To: <868ts8nwdb.fsf@phe.ftfl.ca>
References: <868tsdohoe.fsf@phe.ftfl.ca>
	<22578.18597.717387.458240@max.nulle.part>
	<864m31ob4x.fsf@phe.ftfl.ca>
	<22578.23795.540869.831235@max.nulle.part>
	<86y40cgpsh.fsf@phe.ftfl.ca>
	<22579.48780.66762.666285@max.nulle.part>
	<86twb0go0c.fsf@phe.ftfl.ca>
	<22579.50911.667739.32126@max.nulle.part>
	<86twazaqbm.fsf@phe.ftfl.ca>
	<22581.24194.824366.415231@stat.math.ethz.ch>
	<86h96ybimm.fsf@phe.ftfl.ca>
	<22581.50858.767147.808685@max.nulle.part>
	<868ts8nwdb.fsf@phe.ftfl.ca>
Message-ID: <22583.42327.521157.462124@max.nulle.part>


On 24 November 2016 at 22:09, Joseph Mingrone wrote:
| For a frequently-updated Debian package repository, I assume you _manually_ bump
| all the Debian R packages whenever the main R package is upgraded.  Is that
| correct?  That is, when a Debian user upgrades the r-base package from, say,
| version 3.2.5 to 3.3.1, then r-cran-tseries must/should be rebuilt/reinstalled
| against the new R package?  If so, maybe there is something useful we could

You assume that change == breakage.  Yet that assumption is baseless.

Which is what someone like Martin (R Core, and "at it" since the 80s pre-R
and 90s with the almost very beginning of R) and myself (around R since the
late 90s, somewhat involved since the early 00s) keep telling you.

At some point it might appear to be approproiiate for you to actually take
our word for it.

| submit.  I will have to study how R uses autotools, because that also seems a
| bit different than I am used to.
| 
| I also notice that on Debian you make a soft link of /usr/lib/R/lib/libR.so to
| /usr/lib/libR.so.  Given all that has been discussed, I am unclear why.

Well noticed -- yet a stricly personaly reason via two projects I have been
(co-)authoring: littler and RInside. They both "embed" R via libR and we do
both rpath ("somewhat" verboten by Debian Policy as it hard codes a path,
hence the alternate of placing it where ldd / ldconfig find it).

But please note that that is _me_ doing this, and the R Core gospel we have
been trying for you to understand still stand: __what you insist is needed
actually is not__.

| Thank you for sticking with the thread,

Sorry for coming through as pedantic but you (and we're now at what, six
posts in and counting?)  still start from the wrong (at least outside of the
gilded confines of FreeBSD) premise. It. Just. Works.

Just give us and the unknown-but-sometimes-estimated-to-be-in-the-millions of
R users some credit. What is there __works__. Seriously.  Debian folks are
pendantic for technical excellence __and even they have no issue with
per-package and local shared libraries__.  Which is what this is. Really.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From jrm at ftfl.ca  Fri Nov 25 04:29:09 2016
From: jrm at ftfl.ca (Joseph Mingrone)
Date: Thu, 24 Nov 2016 23:29:09 -0400
Subject: [Rd] shared libraries: missing soname
In-Reply-To: <22583.42327.521157.462124@max.nulle.part> (Dirk Eddelbuettel's
	message of "Thu, 24 Nov 2016 20:43:35 -0600")
References: <868tsdohoe.fsf@phe.ftfl.ca>
	<22578.18597.717387.458240@max.nulle.part>
	<864m31ob4x.fsf@phe.ftfl.ca>
	<22578.23795.540869.831235@max.nulle.part>
	<86y40cgpsh.fsf@phe.ftfl.ca> <22579.48780.66762.666285@max.nulle.part>
	<86twb0go0c.fsf@phe.ftfl.ca> <22579.50911.667739.32126@max.nulle.part>
	<86twazaqbm.fsf@phe.ftfl.ca>
	<22581.24194.824366.415231@stat.math.ethz.ch>
	<86h96ybimm.fsf@phe.ftfl.ca>
	<22581.50858.767147.808685@max.nulle.part>
	<868ts8nwdb.fsf@phe.ftfl.ca>
	<22583.42327.521157.462124@max.nulle.part>
Message-ID: <86zikome4a.fsf@phe.ftfl.ca>

Dirk,

Dirk Eddelbuettel <edd at debian.org> writes:
> You assume that change == breakage.  Yet that assumption is baseless.

> Which is what someone like Martin (R Core, and "at it" since the 80s pre-R
> and 90s with the almost very beginning of R) and myself (around R since the
> late 90s, somewhat involved since the early 00s) keep telling you.

> At some point it might appear to be approproiiate for you to actually take
> our word for it.

It is not that I am not taking your word.  There are some unique (to me)
approaches in R and some of them are subtle.  I am also taking criticism from
the other side, because, as I said, some conventions collide.  When Martin said,

> All these libraries "belong to R" and are tied to a specific version of R...

I understood that "tied to a specific version of R" meant that (Debian/FreeBSD)
R packages should be updated in lock step with R.  So, on Debian, changes in the
r-core package never necessitate a bump of r-cran-*?  In other words, the
libR.so interface is guaranteed to be stable across releases?

> | I also notice that on Debian you make a soft link of /usr/lib/R/lib/libR.so to
> | /usr/lib/libR.so.  Given all that has been discussed, I am unclear why.

> Well noticed -- yet a stricly personaly reason via two projects I have been
> (co-)authoring: littler and RInside. They both "embed" R via libR and we do
> both rpath ("somewhat" verboten by Debian Policy as it hard codes a path,
> hence the alternate of placing it where ldd / ldconfig find it).

> But please note that that is _me_ doing this, and the R Core gospel we have
> been trying for you to understand still stand: __what you insist is needed
> actually is not__.

Understood.

> | Thank you for sticking with the thread,

> Sorry for coming through as pedantic but you (and we're now at what, six
> posts in and counting?)  still start from the wrong (at least outside of the
> gilded confines of FreeBSD) premise. It. Just. Works.

> Just give us and the unknown-but-sometimes-estimated-to-be-in-the-millions of
> R users some credit. What is there __works__. Seriously.  Debian folks are
> pendantic for technical excellence __and even they have no issue with
> per-package and local shared libraries__.  Which is what this is. Really.

Pedantic is fine.  I give credit!  I would not be investing my (comparatively
minuscule) time if I did not appreciate R.  I would also not be doing anyone a
service if I released a flawed FreeBSD package that did not do the project
justice.

Joseph
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 930 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20161124/770de6ee/attachment.bin>

From suharto_anggono at yahoo.com  Sat Nov 26 18:14:01 2016
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Sat, 26 Nov 2016 17:14:01 +0000 (UTC)
Subject: [Rd] ifelse() woes ... can we agree on a ifelse2() ?
References: <1188177957.798916.1480180441229.ref@mail.yahoo.com>
Message-ID: <1188177957.798916.1480180441229@mail.yahoo.com>

Just stating, in 'ifelse', 'test' is not recycled. As I said in "R-intro: length of 'ifelse' result" (https://stat.ethz.ch/pipermail/r-devel/2016-September/073136.html), ifelse(condition, a, b) returns a vector of the length of 'condition', even if 'a' or 'b' is longer.

On current 'ifelse' code in R:
* The part
ans[nas] <- NA
could be omitted because NA's are already in place.
If the part is removed, variable 'nas' is no longer used.
* The any(*) part actually checks the thing that is used as the index vector. The index vector could be stored and then repeatedly used, like the following.
? ? if (any(sel <- test & ok))
??? ans[sel] <- rep(yes, length.out = length(ans))[sel]
* If 'test' is a factor, doing
storage.mode(test) <- "logical"
is not appropriate, but is.atomic(test) returns TRUE. Maybe use
if(!is.object(test))
instead of
if(is.atomic(test)) .

On ifelse-checks.R:
* In function 'chkIfelse', if the fourth function argument names is not "NA.", the argument name is changed, but the function body still uses the old name. That makes error in chkIfelse(ifelseHW) .
A fix:
? ? ? ? if(names(formals(FUN))[[4]] != "NA.") {
? ? ? ? ? ? body(FUN) <- do.call(substitute, list(body(FUN),
? ? ? ? ? ? ? ? setNames(list(quote(NA.)), names(formals(FUN))[[4]])))
? ? ? ? ? ? names(formals(FUN))[[4]] <- "NA."
? ? ? ? }
After fixing, chkIfelse(ifelseHW) just fails at identical(iflt, as.POSIXlt(ifct)) .
'iflt' has NA as 'tzone' and 'isdst' components.
* Because function 'chkIfelse' continues checking after failure,
as.POSIXlt(ifct)
may give error. The error happens, for example, in chkIfelse(ifelseR) . Maybe place it inside try(...).
* If 'lt' is a "POSIXlt" object, (lt-100) is a "POSIXct" object.
So,
FUN(c(TRUE, FALSE, NA, TRUE), lt, lt-100)
is an example of mixed class.
* The part of function 'chkIfelse' in
for(i in seq_len(nFact))
uses 'NA.' function argument. That makes error when 'chkIfelse' is applied to function without fourth argument.
The part should be wrapped in
if(has.4th) .
* Function 'ifelseJH' has fourth argument, but the argument is not for value if NA. So, instead of
chkIfelse(ifelseJH) ,
maybe call
chkIfelse(function(test, yes, no) ifelseJH(test, yes, no)) .

A concrete version of 'ifelse2' that starts the result from 'yes':
function(test, yes, no, NA. = NA) {
? ? if(!is.logical(test))
? ? ? ? test <- if(isS4(test)) methods::as(test, "logical") else as.logical(test)
? ? n <- length(test)
? ? ans <- rep(yes, length.out = n)
? ? ans[!test & !is.na(test)] <- rep(no, length.out = n)[!test & !is.na(test)]
? ? ans[is.na(test)] <- rep(NA., length.out = n)[is.na(test)]
? ? ans
}

It requires 'rep' method that is compatible with subsetting. It also works with "POSIXlt" in R 2.7.2, when 'length' gives 9, and gives an appropriate result if time zones are the same.
For coercion of 'test', there is no need of keeping attributes. So, it doesn't do
storage.mode(test) <- "logical"
and goes directly to 'as.logical'.
It relies on subassignment for silent coercions of
logical < integer < double < complex .
Unlike 'ifelse', it never skips any subassignment. So, phenomenon as in "example of different return modes" in ?ifelse doesn't happen.

Another version, for keeping attributes as pointed out by Duncan Murdoch:
function(test, yes, no, NA. = NA) {
? ? if(!is.logical(test))
? ? ? ? test <- if(isS4(test)) methods::as(test, "logical") else as.logical(test)
? ? n <- length(test)
? ? n.yes <- length(yes); n.no <- length(no)
? ? if (n.yes != n) {
? ? ? ? if (n.no == n) {? # swap yes <-> no
? ? ? ? ? ? test <- !test
? ? ? ? ? ? ans <- yes; yes <- no; no <- ans
? ? ? ? ? ? n.no <- n.yes
? ? ? ? } else yes <- yes[rep_len(seq_len(n.yes), n)]
? ? }
? ? ans <- yes
? ? if (n.no == 1L)
? ? ? ? ans[!test] <- no
? ? else
? ? ? ? ans[!test & !is.na(test)] <- no[
? ? ? ? ? ? if (n.no == n) !test & !is.na(test)
? ? ? ? ? ? else rep_len(seq_len(n.no), n)[!test & !is.na(test)]]
? ? stopifnot(length(NA.) == 1L)
? ? ans[is.na(test)] <- NA.
? ? ans
}

Note argument evaluation order: 'test', 'yes', 'no', 'NA.'.
First, it chooses the first of 'yes' and 'no' that has the same length as the result. If none of 'yes' and 'no' matches the length of the result, it chooses recycled (or truncated) 'yes'.
It uses 'rep' on the index and subsetting as a substitute for 'rep' on the value.
It requires 'length' method that is compatible with subsetting.
Additionally, it uses the same idea as dplyr::if_else, or more precisely the helper function 'replace_with'. It doesn't use 'rep' if the length of 'no' is 1 or is the same as the length of the result. For subassignment with value of length 1, recycling happens by itself and NA in index is OK.
It limits 'NA.' to be of length 1, considering 'NA.' just as a label for NA.

Cases where the last version above or 'ifelse2 or 'ifelseHW' in ifelse-def.R gives inappropriate answers:
- 'yes' and 'no' are "difftime" objects with different "units" attribute
- 'yes' and 'no' are "POSIXlt" objects with different time zone
Example: 'yes' in "UTC" and 'no' in "EST5EDT". The reverse, 'yes' in "EST5EDT" and 'no' in "UTC" gives error.

For the cases, c(yes, no) helps. Function 'ifelseJH' in ifelse-def.R gives a right answer for "POSIXlt" case.
---------------------
Martin et al.,




On Tue, Nov 22, 2016 at 2:12 AM, Martin Maechler <maechler at stat.math.ethz.ch
> wrote:

>
> Note that my premise was really to get *away* from inheriting
> too much from 'test'.
> Hence, I have *not* been talking about replacing ifelse() but
> rather of providing a new? ifelse2()
>
>? ? ? ? [ or if_else()? if Hadley was willing to ditch the dplyr one
>? ? ? ? ? ? ? ? ? ? ? ? in favor of a base one]
>
>? ???> Specifically, based on an unrelated discussion with Henrik Bengtsson
> on
>? ???> Twitter, I wonder if preserving the recycling behavior test is
> longer than
>? ???> yes, no, but making the case where
>
>? ???> length( test ) < max(length( yes ), length( no ))
>
>? ???> would simplify usage for userRs in a useful way.
>

That was a copyediting bug on my part, it seems I hit send with my message
only half-edited/proofread. Apologies.

 That should have said that making the case where test is the one that will
be recycled (because it is shorter than either yes or no) an error. My
claim is that the fact that test itself can be recycled, rather than just
yes or no, is confusing to many R users. If we are writing an ifelse2 we
might want to drop that feature and just throw an error in that case.
(Users could still use the original ifelse if they understand and
specifically want that behavior).

Does that make more sense?



>
>? ???> Also, If we combine a stricter contract that the output will always
> be of
>? ???> length with the suggestion of a specified output class
>
>
Here, again, I was talking about the restriction that the output be
guaranteed to be the length of test, regardless of the length of yes and
no. That, combined with a specific, guaranteed output class would make a
much narrower/more restricted but also (I argue) much easier to understand
function. Particularly for beginning and intermediate users.

I do hear what you're saying about silent conversion, though, so what I'm
describing might be a third function (ifelse3 for lack of a better name for
now), as you pointed out.


> that was not my intent here.... but would be another interesting
> extension. However, I would like to keep? R-semantic silent coercions
> such as
>? ? ? ? ???logical < integer < double < complex
>
> and your pseudo code below would not work so easily I think.
>
>? ???> the pseudo code could be
>
> (I'm changing assignment '=' to? '<-' ...? [please!] )
>
>? ???> ifelse2 <- function(test, yes, no, outclass) {
>? ???>???lenout? <- length(test)
>? ???>???out <- as( rep(yes, length.out <- lenout), outclass)
>? ???>???out[!test] <- as(rep(no, length.out = lenout)[!test], outclass)
>? ???>???# handle NA stuff
>? ???>???out
>? ???> }
>
>
>? ???> NAs could be tricky if outclass were allowed to be completely
> general, but
>? ???> doable, I think? Another approach? if we ARE fast-passing while
> leaving
>? ???> ifelse intact is that maybe NA's in test just aren't allowed in
> ifelse2.
>? ???> I'm not saying we should definitely do that, but it's possible and
> would
>? ???> make things faster.
>
>? ???> Finally, In terms of efficiency, with the stuff that Luke and I are
> working
>? ???> on, the NA detection could be virtually free in certain cases, which
> could
>? ???> give a nice boost for long vectors? that don't have any NAs (and
> 'know'
>? ???> that they don't).
>
> That *is* indeed a very promising prospect!
> Thank you in advance!
>
>? ???> Best,
>? ???> ~G
>
> I still am bit disappointed by the fact that it seems nobody has
> taken a good look at my ifelse2() proposal.
>

I plan to look at it soon. Thanks again for all your work.

~G


>
> I really would like an alternative to ifelse() in *addition* to
> the current ifelse(), but hopefully in the future being used in
> quite a few places instead of ifelse()
> efficiency but for changed semantics, namely working for considerably
> more "vector like" classes of? 'yes' and 'no'? than the current
> ifelse().
>
> As I said, the current proposal works for objects of class
>? ? "Date", "POSIXct", "POSIXlt", "factor",? "mpfr" (pkg 'Rmpfr')
> and hopefully for "sparseVector" (in a next version of the 'Matrix' pkg).
>
> Martin
>
>? ???> On Tue, Nov 15, 2016 at 3:58 AM, Martin Maechler <
> maechler at stat.math.ethz.ch
>? ???>> wrote:
>
>? ???>> Finally getting back to this :
>? ???>>
>? ???>> >>>>> Hadley Wickham <h.wickham at gmail.com>
>? ???>> >>>>>? ???on Mon, 15 Aug 2016 07:51:35 -0500 writes:
>? ???>>
>? ???>> > On Fri, Aug 12, 2016 at 11:31 AM, Hadley Wickham
>? ???>> > <h.wickham at gmail.com> wrote:
>? ???>> >>> >> One possibility would also be to consider a
>? ???>> >>> "numbers-only" or >> rather "same type"-only {e.g.,
>? ???>> >>> would also work for characters} >> version.
>? ???>> >>>
>? ???>> >>> > I don't know what you mean by these.
>? ???>> >>>
>? ???>> >>> In the mean time, Bob Rudis mentioned dplyr::if_else(),
>? ???>> >>> which is very relevant, thank you Bob!
>? ???>> >>>
>? ???>> >>> As I have found, that actually works in such a "same
>? ???>> >>> type"-only way: It does not try to coerce, but gives an
>? ???>> >>> error when the classes differ, even in this somewhat
>? ???>> >>> debatable case :
>? ???>> >>>
>? ???>> >>> > dplyr::if_else(c(TRUE, FALSE), 2:3, 0+10:11) Error:
>? ???>> >>> `false` has type 'double' not 'integer'
>? ???>> >>> >
>? ???>> >>>
>? ???>> >>> As documented, if_else() is clearly stricter than
>? ???>> >>> ifelse() and e.g., also does no recycling (but of
>? ???>> >>> length() 1).
>? ???>> >>
>? ???>> >> I agree that if_else() is currently too strict - it's
>? ???>> >> particularly annoying if you want to replace some values
>? ???>> >> with a missing:
>? ???>> >>
>? ???>> >> x <- sample(10) if_else(x > 5, NA, x) # Error: `false`
>? ???>> >> has type 'integer' not 'logical'
>? ???>> >>
>? ???>> >> But I would like to make sure that this remains an error:
>? ???>> >>
>? ???>> >> if_else(x > 5, x, "BLAH")
>? ???>> >>
>? ???>> >> Because that seems more likely to be a user error (but
>? ???>> >> reasonable people might certainly believe that it should
>? ???>> >> just work)
>? ???>> >>
>? ???>> >> dplyr is more accommodating in other places (i.e. in
>? ???>> >> bind_rows(), collapse() and the joins) but it's
>? ???>> >> surprisingly hard to get all the details right. For
>? ???>> >> example, what should the result of this call be?
>? ???>> >>
>? ???>> >> if_else(c(TRUE, FALSE), factor(c("a", "b")),
>? ???>> >> factor(c("c", "b"))
>? ???>> >>
>? ???>> >> Strictly speaking I think you could argue it's an error,
>? ???>> >> but that's not very user-friendly. Should it be a factor
>? ???>> >> with the union of the levels? Should it be a character
>? ???>> >> vector + warning? Should the behaviour change if one set
>? ???>> >> of levels is a subset of the other set?
>? ???>> >>
>? ???>> >> There are similar issues for POSIXct (if the time zones
>? ???>> >> are different, which should win?), and difftimes
>? ???>> >> (similarly for units).? Ideally you'd like the behaviour
>? ???>> >> to be extensible for new S3 classes, which suggests it
>? ???>> >> should be a generic (and for the most general case, it
>? ???>> >> would need to dispatch on both arguments).
>? ???>>
>? ???>> > One possible principle would be to use c() -
>? ???>> > i.e. construct out as
>? ???>>
>? ???>> > out <- c(yes[0], no[0]
>? ???>> > length(out) <- max(length(yes), length(no))
>? ???>>
>? ???>> yes; this would require that a? `length<-` method works for the
>? ???>> class of the result.
>? ???>>
>? ???>> Duncan Murdoch mentioned a version of this, in his very
>? ???>> first reply:
>? ???>>
>? ???>> ans <- c(yes, no)[seq_along(test)]
>? ???>> ans <- ans[seq_along(test)]
>? ???>>
>? ???>> which is less efficient for atomic vectors, but requires
>? ???>> less from the class: it "only" needs `c` and `[` to work
>? ???>>
>? ???>> and a mixture of your two proposals would be possible too:
>? ???>>
>? ???>> ans <- c(yes[0], no[0])
>? ???>> ans <- ans[seq_along(test)]
>? ???>>
>? ???>> which does *not* work for my "mpfr" numbers (CRAN package 'Rmpfr'),
>? ???>> but that's a buglet in the? c.mpfr() implementation of my Rmpfr
>? ???>> package... (which has already been fixed in the development version
> on
>? ???>> R-forge,
>? ???>> https://r-forge.r-project.org/R/?group_id=386)
>? ???>>
>? ???>> > But of course that wouldn't help with factor responses.
>? ???>>
>? ???>> Yes.? However, a version of Duncan's suggestion -- of treating
> 'yes' first
>? ???>> -- does help in that case.
>? ???>>
>? ???>> For once, mainly as "feasability experiment",
>? ???>> I have created a github gist to make my current ifelse2() proposal
>? ???>> available
>? ???>> for commenting, cloning, pullrequesting, etc:
>? ???>>
>? ???>> Consisting of 2 files
>? ???>> - ifelse-def.R :? Functions definitions only, basically all the
> current
>? ???>> proposals, called? ifelse*()
>? ???>> - ifelse-checks.R : A simplistic checking function
>? ???>> and examples calling it, notably demonstrating that my
>? ???>> ifelse2()? does work with
>? ???>> "Date", <dateTime> (i.e. "POSIXct" and "POSIXlt"), factors,
>? ???>> and "mpfr" (the arbitrary-precision numbers in my package "Rmpfr")
>? ???>>
>? ???>> Also if you are not on github, you can quickly get to the ifelse2()
>? ???>> definition :
>? ???>>
>? ???>> https://gist.github.com/mmaechler/9cfc3219c4b89649313bfe6853d878
>? ???>> 94#file-ifelse-def-r-L168
>? ???>>
>? ???>> > Also, if you're considering an improved ifelse(), I'd
>? ???>> > strongly urge you to consider adding an `na` argument,
>? ???>>
>? ???>> I now did (called it 'NA.').
>? ???>>
>? ???>> > so that you can use ifelse() to transform all three
>? ???>> > possible values in a logical vector.
>? ???>>
>? ???>> > Hadley
>? ???>> > -- http://hadley.nz
>? ???>>
>? ???>> For those who really hate GH (and don't want or cannot easily
> follow the
>? ???>> above URL), here's my current definition:
>? ???>>
>? ???>>
>? ???>> ##' Martin Maechler, 14. Nov 2016 --- taking into account Duncan M.
> and
>? ???>> Hadley's
>? ???>> ##' ideas in the R-devel thread starting at (my mom's 86th
> birthday):
>? ???>> ##' https://stat.ethz.ch/pipermail/r-devel/2016-August/072970.html
>? ???>> ifelse2 <- function (test, yes, no, NA. = NA) {
>? ???>> if(!is.logical(test)) {
>? ???>> if(is.atomic(test))
>? ???>> storage.mode(test) <- "logical"
>? ???>> else ## typically a "class"; storage.mode<-() typically fails
>? ???>> test <- if(isS4(test)) methods::as(test, "logical") else
>? ???>> as.logical(test)
>? ???>> }
>? ???>>
>? ???>> ## No longer optimize the? "if (a) x else y"? cases:
>? ???>> ## Only "non-good" R users use ifelse(.) instead of if(.) in these
>? ???>> cases.
>? ???>>
>? ???>> ans <-
>? ???>> tryCatch(rep(if(is.object(yes) && identical(class(yes), class(no)))
>? ???>> ## as c(o) or o[0] may not work for the class
>? ???>> yes else c(yes[0], no[0]), length.out =
>? ???>> length(test)),
>? ???>> error = function(e) { ## try asymmetric, yes-leaning
>? ???>> r <- yes
>? ???>> r[!test] <- no[!test]
>? ???>> r
>? ???>> })
>? ???>> ok <- !(nas <- is.na(test))
>? ???>> if (any(test[ok]))
>? ???>> ans[test & ok] <- rep(yes, length.out = length(ans))[test & ok]
>? ???>> if (any(!test[ok]))
>? ???>> ans[!test & ok] <- rep(no, length.out = length(ans))[!test & ok]
>? ???>> ans[nas] <- NA. # possibly coerced to class(ans)
>? ???>> ans
>? ???>> }
>? ???>>
>? ???>> ______________________________________________
>? ???>> R-devel at r-project.org mailing list
>? ???>> https://stat.ethz.ch/mailman/listinfo/r-devel
>? ???>>
>
>
>
>? ???> --
>? ???> Gabriel Becker, PhD
>? ???> Associate Scientist (Bioinformatics)
>? ???> Genentech Research
>
>? ???> [[alternative HTML version deleted]]
>
>


-- 
Gabriel Becker, PhD
Associate Scientist (Bioinformatics)
Genentech Research

??? [[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Sat Nov 26 19:52:15 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Sat, 26 Nov 2016 18:52:15 +0000
Subject: [Rd] ifelse() woes ... can we agree on a ifelse2() ?
In-Reply-To: <1188177957.798916.1480180441229@mail.yahoo.com>
References: <1188177957.798916.1480180441229.ref@mail.yahoo.com>,
	<1188177957.798916.1480180441229@mail.yahoo.com>
Message-ID: <1A8C1289955EF649A09086A153E267240404109186@GBTEDVPEXCMB04.corp.lgc-group.com>

> Just stating, in 'ifelse', 'test' is not recycled. As I said in "R-intro: length of 'ifelse' result" 
> (https://stat.ethz.ch/pipermail/r-devel/2016-September/073136.html), ifelse(condition, a, b) 
> returns a vector of the length of 'condition', even if 'a' or 'b' is longer.

That is indeed (almost) the documented behaviour. The documented behaviour is slightly more complex; '... returns a value _of the same shape_ as 'test''. IN principle, test can be a matrix, for example.

> A concrete version of 'ifelse2' that starts the result from 'yes':
> .. still a bit disappointed that nobody has taken a look ...

I took a look. The idea leaves (at least) me very uneasy. If you are recycling 'test' as well as arbitrary-length yes and no, results will become frighteningly hard to predict except in very simple cases where you have well-defined and consistent regularities in the data. And where you do, surely passing ifelse a vetor of the right length, generated by rep() applied to a short 'test' vector, will do what you want without messing around with new functions that hide what you're doing.

Do you really have a case where 'test' is neither a single logical (that could be used with 'if') nor a vector that can be readily replicated to the desired length with 'rep'?

If not, I'd drop the attempt to generate new ifelse-like functions. 

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From suharto_anggono at yahoo.com  Sun Nov 27 02:50:30 2016
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Sun, 27 Nov 2016 01:50:30 +0000 (UTC)
Subject: [Rd] ifelse() woes ... can we agree on a ifelse2() ?
References: <1234570420.932536.1480211430119.ref@mail.yahoo.com>
Message-ID: <1234570420.932536.1480211430119@mail.yahoo.com>

For S Ellison, just clarifying, I am Suharto Anggono, not Martin Maechler. "Martin et al.," from my previous E-mail was the beginning of message from Gabriel Becker, that I quoted.
The quoted "still a bit disappointed that nobody has taken a look" is from Martin Maechler.
In all of the proposed 'ifelse'-like functions so far, including from me (that I labeled as 'ifelse2', following Martin Maechler) and from Martin Maechler, the length of the result equals the length of 'test', like in 'ifelse'. There is no recycling of 'test'.



-----------------------------------------
> Just stating, in 'ifelse', 'test' is not recycled. As I said in "R-intro: length of 'ifelse' result" 
> (https://stat.ethz.ch/pipermail/r-devel/2016-September/073136.html), ifelse(condition, a, b) 
> returns a vector of the length of 'condition', even if 'a' or 'b' is longer.

That is indeed (almost) the documented behaviour. The documented behaviour is slightly more complex; '... returns a value _of the same shape_ as 'test''. IN principle, test can be a matrix, for example.

> A concrete version of 'ifelse2' that starts the result from 'yes':
> .. still a bit disappointed that nobody has taken a look ...

I took a look. The idea leaves (at least) me very uneasy. If you are recycling 'test' as well as arbitrary-length yes and no, results will become frighteningly hard to predict except in very simple cases where you have well-defined and consistent regularities in the data. And where you do, surely passing ifelse a vetor of the right length, generated by rep() applied to a short 'test' vector, will do what you want without messing around with new functions that hide what you're doing.

Do you really have a case where 'test' is neither a single logical (that could be used with 'if') nor a vector that can be readily replicated to the desired length with 'rep'?

If not, I'd drop the attempt to generate new ifelse-like functions. 

S Ellison


From suharto_anggono at yahoo.com  Sun Nov 27 03:27:14 2016
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Sun, 27 Nov 2016 02:27:14 +0000 (UTC)
Subject: [Rd] ifelse() woes ... can we agree on a ifelse2() ?
References: <879999629.947686.1480213634160.ref@mail.yahoo.com>
Message-ID: <879999629.947686.1480213634160@mail.yahoo.com>

Related to the length of 'ifelse' result, I want to say that "example of different return modes" in ?ifelse led me to perceive a wrong thing in the past.

     ## example of different return modes:
     yes <- 1:3
     no <- pi^(0:3)
     typeof(ifelse(NA,    yes, no)) # logical
     typeof(ifelse(TRUE,  yes, no)) # integer
     typeof(ifelse(FALSE, yes, no)) # double

As the result of each 'ifelse' call is not printed, I thought that the length of the result is 3. In fact, the length of the result is 1.
I realize just now that the length of 'no' is different from 'yes'. The length of 'yes' is 3, the length of 'no' is 4.



--------------------------------------------


 Subject: Re: ifelse() woes ... can we agree on a ifelse2() ?
 To: R-devel at lists.R-project.org
 Date: Sunday, 27 November, 2016, 8:50 AM
 
In all of the proposed 'ifelse'-like functions so far, including from me (that I labeled as 'ifelse2', following Martin Maechler) and from Martin Maechler, the length of the result equals the length of 'test', like in 'ifelse'. There is no recycling of 'test'.


From brodie.gaslam at yahoo.com  Sun Nov 27 17:34:39 2016
From: brodie.gaslam at yahoo.com (brodie gaslam)
Date: Sun, 27 Nov 2016 16:34:39 +0000 (UTC)
Subject: [Rd] Changes in error reporting in r-devel
References: <820896809.998306.1480264479807.ref@mail.yahoo.com>
Message-ID: <820896809.998306.1480264479807@mail.yahoo.com>

Minor issue, but the following changed as of R3.3.2 from:

    > a <- function() b()
    > a()
    Error in a() : could not find function "b"

To (at least in R Under development (unstable) (2016-11-20 r71670)):

    Error in b() : could not find function "b"

Notice the "Error in **b**() :" part.  The original error message seems more correct to me, although I can see how you can argue for either one.

Best regards,

B.


From murdoch.duncan at gmail.com  Sun Nov 27 19:20:53 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 27 Nov 2016 13:20:53 -0500
Subject: [Rd] Changes in error reporting in r-devel
In-Reply-To: <820896809.998306.1480264479807@mail.yahoo.com>
References: <820896809.998306.1480264479807.ref@mail.yahoo.com>
	<820896809.998306.1480264479807@mail.yahoo.com>
Message-ID: <41a24c90-9837-3ff8-ab78-6745b1d91535@gmail.com>

On 27/11/2016 11:34 AM, brodie gaslam via R-devel wrote:
> Minor issue, but the following changed as of R3.3.2 from:
>
>     > a <- function() b()
>     > a()
>     Error in a() : could not find function "b"
>
> To (at least in R Under development (unstable) (2016-11-20 r71670)):
>
>     Error in b() : could not find function "b"
>
> Notice the "Error in **b**() :" part.  The original error message seems more correct to me, although I can see how you can argue for either one.

I'm not seeing that in R-devel r71694.  Could you update and try again?

Duncan Murdoch


From edd at debian.org  Sun Nov 27 20:44:15 2016
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 27 Nov 2016 13:44:15 -0600
Subject: [Rd] Changes in error reporting in r-devel
In-Reply-To: <41a24c90-9837-3ff8-ab78-6745b1d91535@gmail.com>
References: <820896809.998306.1480264479807.ref@mail.yahoo.com>
	<820896809.998306.1480264479807@mail.yahoo.com>
	<41a24c90-9837-3ff8-ab78-6745b1d91535@gmail.com>
Message-ID: <22587.14223.950504.314087@max.nulle.part>


On 27 November 2016 at 13:20, Duncan Murdoch wrote:
| On 27/11/2016 11:34 AM, brodie gaslam via R-devel wrote:
| > Minor issue, but the following changed as of R3.3.2 from:
| >
| >     > a <- function() b()
| >     > a()
| >     Error in a() : could not find function "b"
| >
| > To (at least in R Under development (unstable) (2016-11-20 r71670)):
| >
| >     Error in b() : could not find function "b"
| >
| > Notice the "Error in **b**() :" part.  The original error message seems more correct to me, although I can see how you can argue for either one.
| 
| I'm not seeing that in R-devel r71694.  Could you update and try again?

I am at r71690 and I don't see it either:

edd at max:~/src/debian RD

R Under development (unstable) (2016-11-24 r71690) -- "Unsuffered Consequences"
Copyright (C) 2016 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

R> a <- function() b()
R> a()
Error in a() : could not find function "b"
R> 

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From brodie.gaslam at yahoo.com  Sun Nov 27 21:10:32 2016
From: brodie.gaslam at yahoo.com (brodie gaslam)
Date: Sun, 27 Nov 2016 20:10:32 +0000 (UTC)
Subject: [Rd] Changes in error reporting in r-devel
In-Reply-To: <22587.14223.950504.314087@max.nulle.part>
References: <820896809.998306.1480264479807.ref@mail.yahoo.com>
	<820896809.998306.1480264479807@mail.yahoo.com>
	<41a24c90-9837-3ff8-ab78-6745b1d91535@gmail.com>
	<22587.14223.950504.314087@max.nulle.part>
Message-ID: <1609758138.1062052.1480277432877@mail.yahoo.com>

I'm running of off the rocker/drd docker image.  As soon as that updates to a fresher version I'll run again, although given what both of you see I must have caught some fleeting state in the particular revision I'm on.

Best regards,

B.




----- Original Message -----
From: Dirk Eddelbuettel <edd at debian.org>
To: Duncan Murdoch <murdoch.duncan at gmail.com>
Cc: brodie gaslam <brodie.gaslam at yahoo.com>; "r-devel at r-project.org" <r-devel at r-project.org>
Sent: Sunday, November 27, 2016 2:44 PM
Subject: Re: [Rd] Changes in error reporting in r-devel


On 27 November 2016 at 13:20, Duncan Murdoch wrote:
| On 27/11/2016 11:34 AM, brodie gaslam via R-devel wrote:
| > Minor issue, but the following changed as of R3.3.2 from:
| >
| >     > a <- function() b()
| >     > a()
| >     Error in a() : could not find function "b"
| >
| > To (at least in R Under development (unstable) (2016-11-20 r71670)):
| >
| >     Error in b() : could not find function "b"
| >
| > Notice the "Error in **b**() :" part.  The original error message seems more correct to me, although I can see how you can argue for either one.
| 
| I'm not seeing that in R-devel r71694.  Could you update and try again?

I am at r71690 and I don't see it either:

edd at max:~/src/debian RD

R Under development (unstable) (2016-11-24 r71690) -- "Unsuffered Consequences"
Copyright (C) 2016 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

R> a <- function() b()
R> a()

Error in a() : could not find function "b"
R> 

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From luke-tierney at uiowa.edu  Sun Nov 27 23:30:34 2016
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Sun, 27 Nov 2016 16:30:34 -0600
Subject: [Rd] Changes in error reporting in r-devel
In-Reply-To: <41a24c90-9837-3ff8-ab78-6745b1d91535@gmail.com>
References: <820896809.998306.1480264479807.ref@mail.yahoo.com>
	<820896809.998306.1480264479807@mail.yahoo.com>
	<41a24c90-9837-3ff8-ab78-6745b1d91535@gmail.com>
Message-ID: <alpine.DEB.2.20.1611271625160.2864@luke-Latitude>

Its a compiled/interpreted difference. At the moment a small function
like this is only compiled on the second call. That is in flux as we
tune the JIT. But we should try to get rid of the difference. I
actually prefer seeing the more specific call b() since you can get
the larger context from traceback(), and showing b() is more
consistent with argument errors in builin calls.

Best,

luke


On Sun, 27 Nov 2016, Duncan Murdoch wrote:

> On 27/11/2016 11:34 AM, brodie gaslam via R-devel wrote:
>> Minor issue, but the following changed as of R3.3.2 from:
>>
>>     > a <- function() b()
>>     > a()
>>     Error in a() : could not find function "b"
>> 
>> To (at least in R Under development (unstable) (2016-11-20 r71670)):
>>
>>     Error in b() : could not find function "b"
>> 
>> Notice the "Error in **b**() :" part.  The original error message seems 
>> more correct to me, although I can see how you can argue for either one.
>
> I'm not seeing that in R-devel r71694.  Could you update and try again?
>
> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From francois.rousset at umontpellier.fr  Sun Nov 27 00:06:19 2016
From: francois.rousset at umontpellier.fr (=?UTF-8?Q?Fran=c3=a7ois_Rousset?=)
Date: Sun, 27 Nov 2016 00:06:19 +0100
Subject: [Rd] methods:::.selectSuperClasses and byte compilation
Message-ID: <a8968e28-e91a-1596-aa29-b1e807cd8344@umontpellier.fr>

Dear R-devel list,

Running the following example on a recent R-devel (here, 2016-11-22 
r71672) shows that the byte compiler can cause some significant 
performance drops (here, computation time increasing from 0.01s to 0.31s 
...)
=================================
library(Matrix)
someMatrix <- new("dtCMatrix", i= c(1L, 0:3), p=c(0L,0L,0:2, 5L), Dim = 
c(5L, 5L),
                   x = rep(1, 5), diag = "U")
compiler::enableJIT(3) ## R-devel default
system.time(replicate(100,Matrix::crossprod(someMatrix))) ## slow !
compiler::enableJIT(0)
system.time(replicate(100,Matrix::crossprod(someMatrix))) ## fast
==================================
By tracing compiler::cmpfun, I found that the reason may be that 
invoking Matrix::crossprod calls methods:::.selectSuperClasses which 
creates and runs the following function
function (exti) {!isVirtualExt(exti) && length(exti at by) == 0 && exti at simple}
and thus that this function is byte-compiled each time Matrix::crossprod 
is called.

Is there a straightforward way for users / R package writers to avoid 
such problems, or shouldn't it be fixed in the R sources ?

Thanks,

F.


From r-devel at akersting.de  Sun Nov 27 14:02:59 2016
From: r-devel at akersting.de (Andreas Kersting)
Date: Sun, 27 Nov 2016 14:02:59 +0100
Subject: [Rd] Missing objects using dump.frames for post-mortem
 debugging of crashed batch jobs. Bug or gap in documentation?
In-Reply-To: <22570.50735.695455.828208@stat.math.ethz.ch>
References: <22570.50735.695455.828208@stat.math.ethz.ch>
Message-ID: <a8f3c868-8ff1-fbcd-764b-ea47c09d9ee2@akersting.de>

>> Martin, thanks for the good news and sorry for wasting your (and others
>> time) by not doing my homework and query bugzilla first (lesson learned!
>> ).
>>
>> I have tested the new implementation from R-devel and observe a semantic
>> difference when playing with the parameters:
>>
>>   # Test script 1
>>   g <- "global"
>>   f <- function(p) {
>>     l <- "local"
>>     dump.frames()
>>   }
>>   f("parameter")
>>
>> results in
>>   # > debugger()
>>   # Message:  object 'server' not foundAvailable environments had calls:
>>   # 1: source("~/.active-rstudio-document", echo = TRUE)
>>   # 2: withVisible(eval(ei, envir))
>>   # 3: eval(ei, envir)
>>   # 4: eval(expr, envir, enclos)
>>   # 5: .active-rstudio-document#9: f("parameter")
>>   #
>>   # Enter an environment number, or 0 to exit
>>   # Selection: 5
>>   # Browsing in the environment with call:
>>   #   .active-rstudio-document#9: f("parameter")
>>   # Called from: debugger.look(ind)
>>   # Browse[1]> g
>>   # [1] "global"
>>   # Browse[1]>
>>
>> while dumping to a file
>>
>>   # Test script 2
>>   g <- "global"
>>   f <- function(p) {
>>     l <- "local"
>>     dump.frames(to.file = TRUE, include.GlobalEnv = TRUE)
>>   }
>>   f("parameter")
>>
>> results in
>>   # > load("last.dump.rda")
>>   # > debugger()
>
>>   # Message:  object 'server' not foundAvailable environments had calls:
>>   # 1: .GlobalEnv
>>   # 2: source("~/.active-rstudio-document", echo = TRUE)
>>   # 3: withVisible(eval(ei, envir))
>>   # 4: eval(ei, envir)
>>   # 5: eval(expr, envir, enclos)
>>   # 6: .active-rstudio-document#11: f("parameter")
>>   #
>>   # Enter an environment number, or 0 to exit
>>   # Selection: 6
>>   # Browsing in the environment with call:
>>   #   .active-rstudio-document#11: f("parameter")
>>   # Called from: debugger.look(ind)
>>   # Browse[1]> g
>>   # Error: object 'g' not found
>>   # Browse[1]>
>
> Your call to f() and the corresponding dump is heavily
> obfuscated by all the wrap paper that Rstudio seems to wrap around a
> simple function call (or just around using debugger() ?).
>
> All this was to get the correct environments when things are run
> in a batch job... and there's no Rstudio gift wrapping in that case.
>
> In my simple use of the above, "g" is clearly available in the .GlobalEnv
> component of last.dump :
>
>> exists("g", last.dump$.GlobalEnv)
> [1] TRUE
>> get("g", last.dump$.GlobalEnv)
> [1] "global"
>>
>
> and that's all what's promised, right?
> In such a post mortem debugging, notably from a batch job (!),
> you don't want your .GlobalEnv to be *replaced* by the
> .GlobalEnv from 'last.dump', do you?
>
> I think in the end, I think you are indirectly asking for new features to be
> added to  debugger(), namely that it works more seemlessly with
> a last.dump object that has been created via 'include.GlobalEnv = TRUE'.
>
> This wish for a new feature may be a very sensible wish.
> I think it's fine if you add it as wish (for a new feature to
> debugger()) to the R bugzilla site
> ( https://bugs.r-project.org/ -- after asking one of R core to
>   add you to the list of "registered ones" there, see the
>   boldface note in https://www.r-project.org/bugs.html )
>
> Personally, I would only look into this issue if we also get a patch
> proposal (see also https://www.r-project.org/bugs.html), because
> already now you can easily get to "g" in your example.
>
> Martin
>

Hi,

how about changing debugger() to something along the lines:

debugger <- function(dump = last.dump)
{
     # debugger.look <- function(.selection)
     # {
     #     ## allow e.g. '...' to fail
     #     for(.obj in ls(envir=dump[[.selection]], all.names=TRUE))
     #         tryCatch(assign(.obj, get(.obj,envir=dump[[.selection]])),
     #                  error=function(e) {})
     #     cat(gettext("Browsing in the environment with call:\n   "),
     #         calls[.selection], "\n", sep = "")
     #     rm(.obj, .selection)
     #     browser()
     # }
     if (!inherits(dump, "dump.frames")) {
         cat(gettextf("'dump' is not an object of class %s\n",
                      dQuote("dump.frames")))
         return(invisible())
     }
     err.action <- getOption("error")
     on.exit(options(error=err.action))
     if (length(msg <- attr(dump, "error.message")))
         cat(gettext("Message: "), msg)
     n <- length(dump)
     if (!n) {
	cat(gettextf("'dump' is empty\n"))
	return(invisible())
     }
     calls <- names(dump)

     if (calls[1] == ".GlobalEnv") {
         parent.env(dump[[1]]) <- parent.env(.GlobalEnv)
         for (i in seq_along(dump)[-1]) {
             if (identical(parent.env(dump[[i]]), .GlobalEnv)) {
                 parent.env(dump[[i]]) <- dump[[1]]
             }
         }
     }

     repeat {
         cat(gettext("Available environments had calls:\n"))
         cat(paste0(1L:n, ": ", calls), sep = "\n")
         cat(gettext("\nEnter an environment number, or 0 to exit  "))
         repeat {
             ind <- .Call(C_menu, as.character(calls))
             if(ind <= n) break
         }
         if(ind == 0L) return(invisible())
         # debugger.look(ind)
         cat(gettext("Browsing in the environment with call:\n   "),
             calls[ind], "\n", sep = "")
         evalq(browser(), envir = dump[[ind]])
     }
}

So instead of copying all objects of the chosen frame to some new 
environment, i.e. the frame of debugger.look(), we directly inspect the 
dumped one with evalq(browser(), envir = dump[[ind]]). This way we do 
not alter the enclosing environment of the frame.

If the global environment was included in the dump, we change the 
enclosing environment of the dumped .GlobalEnv to search()[2]. For all 
other dumped frames which have the global environment as their enclosing 
one, we change their enclosing environment to the dumped .GlobalEnv.

By doing so we should get an environment tree which is closer to the one 
when dump.frames() was called, with an obvious (potential) difference 
being the search path.

Andreas

>> The semantic difference is that the global variable "g" is visible
>> within the function "f" in the first version, but not in the second
>> version.
>>
>> If I dump to a file and load and debug it then the search path through
>> the
>> frames is not the same during run time vs. debug time.
>>
>> An implementation with the same semantics could be achieved
>> by applying this workaround currently:
>>
>>   dump.frames()
>>   save.image(file = "last.dump.rda")
>>
>> Does it possibly make sense to unify the semantics?
>>
>> THX!
>>
>>
>> On Mon, 2016-11-14 at 11:34 +0100, Martin Maechler wrote:
>> > >>>>> nospam at altfeld-im de <nospam at altfeld-im.de>
>> > >>>>>     on Sun, 13 Nov 2016 13:11:38 +0100 writes:
>> >
>> >     > Dear R friends, to allow post-mortem debugging In my
>> >     > Rscript based batch jobs I use
>> >
>> >     >    tryCatch( <R expression>, error = function(e) {
>> >     > dump.frames(to.file = TRUE) })
>> >
>> >     > to write the called frames into a dump file.
>> >
>> >     > This is similar to the method recommended in the "Writing
>> >     > R extensions" manual in section 4.2 Debugging R code (page
>> >     > 96):
>> >
>> >     > https://cran.r-project.org/doc/manuals/R-exts.pdf
>> >
>> >     >> options(error = quote({dump.frames(to.file=TRUE); q()}))
>> >
>> >
>> >
>> >     > When I load the dump later in a new R session to examine
>> >     > the error I use
>> >
>> >     >     load(file = "last.dump.rda") debugger(last.dump)
>> >
>> >     > My problem is that the global objects in the workspace are
>> >     > NOT contained in the dump since "dump.frames" does not
>> >     > save the workspace.
>> >
>> >     > This makes debugging difficult.
>> >
>> >
>> >
>> >     > For more details see the stackoverflow question + answer
>> >     > in:
>> >     > https://stackoverflow.com/questions/40421552/r-how-make-dump-frames-include-all-variables-for-later-post-mortem-debugging/40431711#40431711
>> >
>> >
>> >
>> >     > I think the reason of the problem is:
>> >     > ------------------------------------
>> >
>> >     > If you use dump.files(to.file = FALSE) in an interactive
>> >     > session debugging works as expected because it creates a
>> >     > global variable called "last.dump" and the workspace is
>> >     > still loaded.
>> >
>> >     > In the batch job scenario however the workspace is NOT
>> >     > saved in the dump and therefore lost if you debug the dump
>> >     > in a new session.
>> >
>> >
>> >     > Options to solve the issue:
>> >     > --------------------------
>> >
>> >     > 1. Improve the documentation of the R help for
>> >     > "dump.frames" and the R_exts manual to propose another
>> >     > code snippet for batch job scenarios:
>> >
>> >     >       dump.frames() save.image(file = "last.dump.rda")
>> >
>> >     > 2. Change the semantics of "dump.frames(to.file = TRUE)"
>> >     > to include the workspace in the dump.  This would change
>> >     > the semantics implied by the function name but makes the
>> >     > semantics consistent for both "to.file" param values.
>> >
>> > There is a third option, already in place for three months now:
>> > Andreas Kersting did propose it (nicely, as a wish),
>> > 	https://bugs.r-project.org/bugzilla/show_bug.cgi?id=17116
>> > and I had added it to the development version of R back then :
>> >
>> > ------------------------------------------------------------------------
>> > r71102 | maechler | 2016-08-16 17:36:10 +0200 (Tue, 16 Aug 2016) | 1 line
>> >
>> > dump.frames(*, include.GlobalEnv)
>> > ------------------------------------------------------------------------
>> >
>> > So, if you (or others) want to use this before next spring,
>> > you should install a version of R-devel
>> > and you use that, with
>> >
>> >   tryCatch( <R expression>,
>> >            error = function(e)
>> > 	           dump.frames(to.file = TRUE, include.GlobalEnv = TRUE))
>> >
>> > Using R-devel is nice and helpful for the R community, as you
>> > will help finding bugs/problems in the new features (and
>> > possibly changed features) we've introduced there.
>> >
>> >
>> > Best regards,
>> > Martin


From maechler at stat.math.ethz.ch  Mon Nov 28 10:48:39 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 28 Nov 2016 10:48:39 +0100
Subject: [Rd] ifelse() woes ... can we agree on a ifelse2() ?
In-Reply-To: <879999629.947686.1480213634160@mail.yahoo.com>
References: <879999629.947686.1480213634160.ref@mail.yahoo.com>
	<879999629.947686.1480213634160@mail.yahoo.com>
Message-ID: <22587.64887.844012.761038@stat.math.ethz.ch>


> Related to the length of 'ifelse' result, I want to say that "example of different return modes" in ?ifelse led me to perceive a wrong thing in the past.
>      ## example of different return modes:
>      yes <- 1:3
>      no <- pi^(0:3)
>      typeof(ifelse(NA,    yes, no)) # logical
>      typeof(ifelse(TRUE,  yes, no)) # integer
>      typeof(ifelse(FALSE, yes, no)) # double
> 
> As the result of each 'ifelse' call is not printed, I thought that the length of the result is 3. In fact, the length of the result is 1.

"of course"... (;-)

But this indeed proves that the example is too sophisticated and
not helpful/clear enough.
Is this better?

## example of different return modes (and 'test' alone determining length):
yes <- 1:3
no  <- pi^(1:4)
utils::str( ifelse(NA,    yes, no) ) # logical, length 1
utils::str( ifelse(TRUE,  yes, no) ) # integer, length 1
utils::str( ifelse(FALSE, yes, no) ) # double,  length 1



> I realize just now that the length of 'no' is different from 'yes'. The length of 'yes' is 3, the length of 'no' is 4.


From jon.skoien at jrc.ec.europa.eu  Mon Nov 28 11:26:45 2016
From: jon.skoien at jrc.ec.europa.eu (Jon Skoien)
Date: Mon, 28 Nov 2016 11:26:45 +0100
Subject: [Rd] Strange behavior when using progress bar (Fwd: Re: [R] The
 code itself disappears after starting to execute the for loop)
In-Reply-To: <54b8d998-9299-4034-be0a-9c9ad7169974@jrc.ec.europa.eu>
References: <54b8d998-9299-4034-be0a-9c9ad7169974@jrc.ec.europa.eu>
Message-ID: <fdd2811e-60af-e322-4e33-0c1ad5eab0ee@jrc.ec.europa.eu>

I first answered to the email below in r-help, but as I did not see any 
response, and it looks like a bug/unwanted behavior, I am also posting 
here. I have observed this in RGui, whereas it seems not to happen in 
RStudio.

Similar to OP, I sometimes have a problem with functions using the 
progress bar. Frequently, the console is cleared after x iterations when 
the progress bar is called in a function which is wrapped in a loop. In 
the example below, this happened for me every ~44th iteration. 
Interestingly, it seems that reduction of the sleep times in this 
function increases the number of iterations before clearing. In my real 
application, where the progress bar is used in a much slower function, 
the console is cleared every 2-3 iteration, which means that I cannot 
scroll back to check the output.


testit <- function(x = sort(runif(20)), ...)
{
   pb <- txtProgressBar(...)
   for(i in c(0, x, 1)) {Sys.sleep(0.2); setTxtProgressBar(pb, i)}
   Sys.sleep(1)
   close(pb)
}

iter = 0
while (TRUE) {testit(style = 3); iter = iter + 1; print(paste("done", 
iter))}

Is this only a problem for a few, or is it reproducible? Any hints to
what the problem could be, or if it can be fixed? I have seen this in 
some versions of R, and could also reproduce in 3.3.2.

Best wishes,
Jon

R version 3.3.2 (2016-10-31)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 8.1 x64 (build 9600)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods base




On 11/23/2016 5:22 PM, Maram SAlem wrote:
> Thanks a lot Bert , will check out your suggestions.
>
> I've unchecked the buffer output option in GUI but still have the same problem.
>
> Thanks for your time and concern.
>
> Maram Salem
>
> Sent from my iPhone
>
>> On Nov 23, 2016, at 5:55 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> In addition to Jim's comments, which you have not yet satisfactorily
>> addressed (buffering in GUI??),
>>
>> 1. Show your code!
>>
>> 2. Show ouput of sessionInfo()
>>
>> 3. Upgrade to the latest R version maybe
>>
>> 4. Perhaps write to package maintainer (see ?maintainer) if nothing or
>> no one helps.
>>
>> Cheers,
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>>> On Tue, Nov 22, 2016 at 10:05 AM, Maram SAlem <marammagdysalem at gmail.com> wrote:
>>> Thanks for helping Jim.
>>>
>>> I'm actually using the pbapply function together with the print function within a loop. In earlier versions, the progress bar and the output of the print function used to appear after each iteration of the loop. But with the 3.3.1. Version nothing appears, instead the console turns white and thecursor turns blue ( busy) and I know nothing about the progress of the running code.
>>>
>>> I just want to see the bar and the output of the print function as I used to, any help?
>>>
>>> Thanks in advance.
>>> Maram Salem
>>>
>>>
>>>
>>> Sent from my iPhone
>>>
>>>> On Nov 3, 2016, at 8:30 PM, jim holtman <jholtman at gmail.com> wrote:
>>>>
>>>> A little more information would help.  How exactly are out creating the output to the console?  Are you using 'print', 'cat' or something else?  Do you have buffered output checked on the GUI (you probably don't want it checked or you output will be delayed till the buffer is full -- this mightbe the cause of your problem.
>>>>
>>>>
>>>> Jim Holtman
>>>> Data Munger Guru
>>>>
>>>> What is the problem that you are trying to solve?
>>>> Tell me what you want to do, not how you want to do it.
>>>>
>>>>> On Thu, Nov 3, 2016 at 1:55 PM, Maram SAlem <marammagdysalem at gmail.com> wrote:
>>>>> Hi all,
>>>>>
>>>>> I've a question concerning the R 3.3.1 version. I have a long code that I used to run on versions earlier to the 3.3.1 version, and when I copied the code to the R console, I can still see the code while the loop is executing , along with the output printed after each iteration of the loop.
>>>>>
>>>>> Now, on the 3.3.1 version, after I copy the code to the console, it disappears and I only see the printed output of only one iteration at a time, that is, after the first iteration the printed output disappears ( thoughit's only 6 lines, just giving me some guidance, not a long output).
>>>>> This is causing me some problems, so I don't know if there is a general option for R that enables me to still see the code and the output of allthe iterations till the loop is over, as was the case with earlier R versions.
>>>>>
>>>>> I didn't include the code as it's a long one.
>>>>>
>>>>> Thanks a lot in advance,
>>>>>
>>>>> Maram
>>>>>
>>>>>
>>>>> Sent from my iPhone
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Jon Olav Sk?ien
Joint Research Centre - European Commission
Institute for Space, Security & Migration
Disaster Risk Management Unit

Via E. Fermi 2749, TP 122,  I-21027 Ispra (VA), ITALY

jon.skoien at jrc.ec.europa.eu
Tel:  +39 0332 789205

Disclaimer: Views expressed in this email are those of the individual 
and do not necessarily represent official views of the European Commission.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From mikko.korpela at helsinki.fi  Mon Nov 28 15:26:45 2016
From: mikko.korpela at helsinki.fi (Mikko Korpela)
Date: Mon, 28 Nov 2016 16:26:45 +0200
Subject: [Rd] Two typos in manuals
Message-ID: <9a8fb5df-beba-6b9a-3ec5-1819b040ef6d@helsinki.fi>

I think that in doc/manual/R-intro.texi, "used a part of an even larger 
expression" should be "used as part of an even larger expression".

Another suspected typo is in doc/manual/R-ints.texi, where "dialects of 
TeX and used for different purposes" should probably be "dialects of TeX 
are used for different purposes".

A patch file against R-devel revision 71696 is included.

-- 
Mikko Korpela
Department of Geosciences and Geography
University of Helsinki
-------------- next part --------------
A non-text attachment was scrubbed...
Name: manuals.diff
Type: text/x-patch
Size: 1364 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20161128/4cf9f02c/attachment.bin>

From maechler at stat.math.ethz.ch  Mon Nov 28 16:00:49 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 28 Nov 2016 16:00:49 +0100
Subject: [Rd] ifelse() woes ... can we agree on a ifelse2() ?
In-Reply-To: <1188177957.798916.1480180441229@mail.yahoo.com>
References: <1188177957.798916.1480180441229.ref@mail.yahoo.com>
	<1188177957.798916.1480180441229@mail.yahoo.com>
Message-ID: <20161128150049.0D9CF1C1526@lynne.stat.math.ethz.ch>

>>>>> Suharto Anggono Suharto Anggono via R-devel <r-devel at r-project.org>
>>>>>     on Sat, 26 Nov 2016 17:14:01 +0000 writes:

    > Just stating, in 'ifelse', 'test' is not recycled. As I said in "R-intro: length of 'ifelse' result" (https://stat.ethz.ch/pipermail/r-devel/2016-September/073136.html), ifelse(condition, a, b) returns a vector of the length of 'condition', even if 'a' or 'b' is longer.

yes and  ?ifelse (the help page) also does not say that test is
recycled, rather

   >>  If \code{yes} or \code{no} are too short, their elements are recycled.

(*and* the problem you wrote the above has been corrected in the
 R-intro manual shortly after).


    > On current 'ifelse' code in R:

    > * The part
    > ans[nas] <- NA
    > could be omitted because NA's are already in place.
    > If the part is removed, variable 'nas' is no longer used.

I agree that this seems logical.  If I apply the change, R's own
full checks do not seem affected, and I may try to commit that
change and "wait and see".


    > * The any(*) part actually checks the thing that is used as the index vector. The index vector could be stored and then repeatedly used, like the following.

    > ? ? if (any(sel <- test & ok))
    > ??? ans[sel] <- rep(yes, length.out = length(ans))[sel]

yes, I know, and have had similar thoughts in the past.
However note  (I know you that) the current code is

    if (any(test[ok]))
	ans[test & ok] <- rep(yes, length.out = length(ans))[test & ok]

and   any(test[ok])    	     may be considerably faster than
      any(sel <- test & ok)
      
OTOH I think the current code would only be faster (for the
above) when any(.) returned FALSE ...
I think it may depend on the typical use cases which of the two
versions is more efficient.


    > * If 'test' is a factor, doing
    > storage.mode(test) <- "logical"
    > is not appropriate, but is.atomic(test) returns TRUE. Maybe use
    > if(!is.object(test))
    >    instead of
    > if(is.atomic(test)) .

This would be a considerable change I think...
Note that I'm currently really proposing to introduce an *additional*
ifelse function with different "more reasonable" semantic,  and
your last change would do that too.

My alternative should really work
- for factors
- for "array"s including "matrix" (as the current ifelse() does!)
- for "Date", "POSIXct", "ts"(timeseries), "zoo",
      "sparseVector", "sparseMatrix" (*), or "mpfr",
  without any special code, but rather by design.

 *) Currently needs the R-forge version of  Matrix, version 1.2-8.

A bit less than an hour ago, I have updated the gist with an updated
proposal ifelse2() {and the current alternatives that I know},
modified so it *does* keep more, e.g.  dim() attributes in
reasonable cases.

https://gist.github.com/mmaechler/9cfc3219c4b89649313bfe6853d87894#file-ifelse-def-r-L168

Hence my ifelse2() became even a bit longer (but not slower)
working for even more classes of  "yes" and "no".


    > On ifelse-checks.R:
    > * In function 'chkIfelse', if the fourth function argument names is not "NA.", the argument name is changed, but the function body still uses the old name. That makes error in chkIfelse(ifelseHW) .
    > A fix:
    > ? ? ? ? if(names(formals(FUN))[[4]] != "NA.") {
    > ? ? ? ? ? ? body(FUN) <- do.call(substitute, list(body(FUN),
    > ? ? ? ? ? ? ? ? setNames(list(quote(NA.)), names(formals(FUN))[[4]])))
    > ? ? ? ? ? ? names(formals(FUN))[[4]] <- "NA."
    > ? ? ? ? }

yes, thank you!  (a bit embarrassing for me ..)

    > After fixing, chkIfelse(ifelseHW) just fails at identical(iflt, as.POSIXlt(ifct)) .
    > 'iflt' has NA as 'tzone' and 'isdst' components.
    > * Because function 'chkIfelse' continues checking after failure,
    > as.POSIXlt(ifct)
    > may give error. The error happens, for example, in chkIfelse(ifelseR) . Maybe place it inside try(...).
    > * If 'lt' is a "POSIXlt" object, (lt-100) is a "POSIXct" object.
    > So,
    > FUN(c(TRUE, FALSE, NA, TRUE), lt, lt-100)
    > is an example of mixed class.

good; thank you for the hint.

    > * The part of function 'chkIfelse' in
    > for(i in seq_len(nFact))
    > uses 'NA.' function argument. That makes error when 'chkIfelse' is applied to function without fourth argument.
    > The part should be wrapped in
    > if(has.4th) .
yes of course

    > * Function 'ifelseJH' has fourth argument, but the argument is not for value if NA. So, instead of
    > chkIfelse(ifelseJH) ,
    > maybe call
    > chkIfelse(function(test, yes, no) ifelseJH(test, yes, no)) .
You are right;
I've decided to solve this differently.

I'm looking at these suggestions now, notably also your proposals below;
thank you, Suharto!

(I wanted to put my improved 'ifelse2' out first, quickly).
Martin


    > A concrete version of 'ifelse2' that starts the result from 'yes':
    > function(test, yes, no, NA. = NA) {
    > ? ? if(!is.logical(test))
    > ? ? ? ? test <- if(isS4(test)) methods::as(test, "logical") else as.logical(test)
    > ? ? n <- length(test)
    > ? ? ans <- rep(yes, length.out = n)
    > ? ? ans[!test & !is.na(test)] <- rep(no, length.out = n)[!test & !is.na(test)]
    > ? ? ans[is.na(test)] <- rep(NA., length.out = n)[is.na(test)]
    > ? ? ans
    > }

    > It requires 'rep' method that is compatible with subsetting. It also works with "POSIXlt" in R 2.7.2, when 'length' gives 9, and gives an appropriate result if time zones are the same.
    > For coercion of 'test', there is no need of keeping attributes. So, it doesn't do
    > storage.mode(test) <- "logical"
    > and goes directly to 'as.logical'.
    > It relies on subassignment for silent coercions of
    > logical < integer < double < complex .
    > Unlike 'ifelse', it never skips any subassignment. So, phenomenon as in "example of different return modes" in ?ifelse doesn't happen.

    > Another version, for keeping attributes as pointed out by Duncan Murdoch:
    > function(test, yes, no, NA. = NA) {
    > ? ? if(!is.logical(test))
    > ? ? ? ? test <- if(isS4(test)) methods::as(test, "logical") else as.logical(test)
    > ? ? n <- length(test)
    > ? ? n.yes <- length(yes); n.no <- length(no)
    > ? ? if (n.yes != n) {
    > ? ? ? ? if (n.no == n) {? # swap yes <-> no
    > ? ? ? ? ? ? test <- !test
    > ? ? ? ? ? ? ans <- yes; yes <- no; no <- ans
    > ? ? ? ? ? ? n.no <- n.yes
    > ? ? ? ? } else yes <- yes[rep_len(seq_len(n.yes), n)]
    > ? ? }
    > ? ? ans <- yes
    > ? ? if (n.no == 1L)
    > ? ? ? ? ans[!test] <- no
    > ? ? else
    > ? ? ? ? ans[!test & !is.na(test)] <- no[
    > ? ? ? ? ? ? if (n.no == n) !test & !is.na(test)
    > ? ? ? ? ? ? else rep_len(seq_len(n.no), n)[!test & !is.na(test)]]
    > ? ? stopifnot(length(NA.) == 1L)
    > ? ? ans[is.na(test)] <- NA.
    > ? ? ans
    > }

    > Note argument evaluation order: 'test', 'yes', 'no', 'NA.'.
    > First, it chooses the first of 'yes' and 'no' that has the same length as the result. If none of 'yes' and 'no' matches the length of the result, it chooses recycled (or truncated) 'yes'.
    > It uses 'rep' on the index and subsetting as a substitute for 'rep' on the value.
    > It requires 'length' method that is compatible with subsetting.
    > Additionally, it uses the same idea as dplyr::if_else, or more precisely the helper function 'replace_with'. It doesn't use 'rep' if the length of 'no' is 1 or is the same as the length of the result. For subassignment with value of length 1, recycling happens by itself and NA in index is OK.
    > It limits 'NA.' to be of length 1, considering 'NA.' just as a label for NA.

    > Cases where the last version above or 'ifelse2 or 'ifelseHW' in ifelse-def.R gives inappropriate answers:
    > - 'yes' and 'no' are "difftime" objects with different "units" attribute
    > - 'yes' and 'no' are "POSIXlt" objects with different time zone
    > Example: 'yes' in "UTC" and 'no' in "EST5EDT". The reverse, 'yes' in "EST5EDT" and 'no' in "UTC" gives error.

    > For the cases, c(yes, no) helps. Function 'ifelseJH' in ifelse-def.R gives a right answer for "POSIXlt" case.
    > ---------------------
    > Martin et al.,




    > On Tue, Nov 22, 2016 at 2:12 AM, Martin Maechler <maechler at stat.math.ethz.ch
    >> wrote:

    >> 
    >> Note that my premise was really to get *away* from inheriting
    >> too much from 'test'.
    >> Hence, I have *not* been talking about replacing ifelse() but
    >> rather of providing a new? ifelse2()
    >> 
    >> ? ? ? ? [ or if_else()? if Hadley was willing to ditch the dplyr one
    >> ? ? ? ? ? ? ? ? ? ? ? ? in favor of a base one]
    >> 
    >> ? ???> Specifically, based on an unrelated discussion with Henrik Bengtsson
    >> on
    >> ? ???> Twitter, I wonder if preserving the recycling behavior test is
    >> longer than
    >> ? ???> yes, no, but making the case where
    >> 
    >> ? ???> length( test ) < max(length( yes ), length( no ))
    >> 
    >> ? ???> would simplify usage for userRs in a useful way.
    >> 

    > That was a copyediting bug on my part, it seems I hit send with my message
    > only half-edited/proofread. Apologies.

    > That should have said that making the case where test is the one that will
    > be recycled (because it is shorter than either yes or no) an error. My
    > claim is that the fact that test itself can be recycled, rather than just
    > yes or no, is confusing to many R users. If we are writing an ifelse2 we
    > might want to drop that feature and just throw an error in that case.
    > (Users could still use the original ifelse if they understand and
    > specifically want that behavior).

    > Does that make more sense?



    >> 
    >> ? ???> Also, If we combine a stricter contract that the output will always
    >> be of
    >> ? ???> length with the suggestion of a specified output class
    >> 
    >> 
    > Here, again, I was talking about the restriction that the output be
    > guaranteed to be the length of test, regardless of the length of yes and
    > no. That, combined with a specific, guaranteed output class would make a
    > much narrower/more restricted but also (I argue) much easier to understand
    > function. Particularly for beginning and intermediate users.

    > I do hear what you're saying about silent conversion, though, so what I'm
    > describing might be a third function (ifelse3 for lack of a better name for
    > now), as you pointed out.


    >> that was not my intent here.... but would be another interesting
    >> extension. However, I would like to keep? R-semantic silent coercions
    >> such as
    >> ? ? ? ? ???logical < integer < double < complex
    >> 
    >> and your pseudo code below would not work so easily I think.
    >> 
    >> ? ???> the pseudo code could be
    >> 
    >> (I'm changing assignment '=' to? '<-' ...? [please!] )
    >> 
    >> ? ???> ifelse2 <- function(test, yes, no, outclass) {
    >> ? ???>???lenout? <- length(test)
    >> ? ???>???out <- as( rep(yes, length.out <- lenout), outclass)
    >> ? ???>???out[!test] <- as(rep(no, length.out = lenout)[!test], outclass)
    >> ? ???>???# handle NA stuff
    >> ? ???>???out
    >> ? ???> }
    >> 
    >> 
    >> ? ???> NAs could be tricky if outclass were allowed to be completely
    >> general, but
    >> ? ???> doable, I think? Another approach? if we ARE fast-passing while
    >> leaving
    >> ? ???> ifelse intact is that maybe NA's in test just aren't allowed in
    >> ifelse2.
    >> ? ???> I'm not saying we should definitely do that, but it's possible and
    >> would
    >> ? ???> make things faster.
    >> 
    >> ? ???> Finally, In terms of efficiency, with the stuff that Luke and I are
    >> working
    >> ? ???> on, the NA detection could be virtually free in certain cases, which
    >> could
    >> ? ???> give a nice boost for long vectors? that don't have any NAs (and
    >> 'know'
    >> ? ???> that they don't).
    >> 
    >> That *is* indeed a very promising prospect!
    >> Thank you in advance!
    >> 
    >> ? ???> Best,
    >> ? ???> ~G
    >> 
    >> I still am bit disappointed by the fact that it seems nobody has
    >> taken a good look at my ifelse2() proposal.
    >> 

    > I plan to look at it soon. Thanks again for all your work.

    > ~G


    >> 
    >> I really would like an alternative to ifelse() in *addition* to
    >> the current ifelse(), but hopefully in the future being used in
    >> quite a few places instead of ifelse()
    >> efficiency but for changed semantics, namely working for considerably
    >> more "vector like" classes of? 'yes' and 'no'? than the current
    >> ifelse().
    >> 
    >> As I said, the current proposal works for objects of class
    >> ? ? "Date", "POSIXct", "POSIXlt", "factor",? "mpfr" (pkg 'Rmpfr')
    >> and hopefully for "sparseVector" (in a next version of the 'Matrix' pkg).
    >> 
    >> Martin
    >> 
    >> ? ???> On Tue, Nov 15, 2016 at 3:58 AM, Martin Maechler <
    >> maechler at stat.math.ethz.ch
    >> ? ???>> wrote:
    >> 
    >> ? ???>> Finally getting back to this :
    >> ? ???>>
    >> ? ???>> >>>>> Hadley Wickham <h.wickham at gmail.com>
    >> ? ???>> >>>>>? ???on Mon, 15 Aug 2016 07:51:35 -0500 writes:
    >> ? ???>>
    >> ? ???>> > On Fri, Aug 12, 2016 at 11:31 AM, Hadley Wickham
    >> ? ???>> > <h.wickham at gmail.com> wrote:
    >> ? ???>> >>> >> One possibility would also be to consider a
    >> ? ???>> >>> "numbers-only" or >> rather "same type"-only {e.g.,
    >> ? ???>> >>> would also work for characters} >> version.
    >> ? ???>> >>>
    >> ? ???>> >>> > I don't know what you mean by these.
    >> ? ???>> >>>
    >> ? ???>> >>> In the mean time, Bob Rudis mentioned dplyr::if_else(),
    >> ? ???>> >>> which is very relevant, thank you Bob!
    >> ? ???>> >>>
    >> ? ???>> >>> As I have found, that actually works in such a "same
    >> ? ???>> >>> type"-only way: It does not try to coerce, but gives an
    >> ? ???>> >>> error when the classes differ, even in this somewhat
    >> ? ???>> >>> debatable case :
    >> ? ???>> >>>
    >> ? ???>> >>> > dplyr::if_else(c(TRUE, FALSE), 2:3, 0+10:11) Error:
    >> ? ???>> >>> `false` has type 'double' not 'integer'
    >> ? ???>> >>> >
    >> ? ???>> >>>
    >> ? ???>> >>> As documented, if_else() is clearly stricter than
    >> ? ???>> >>> ifelse() and e.g., also does no recycling (but of
    >> ? ???>> >>> length() 1).
    >> ? ???>> >>
    >> ? ???>> >> I agree that if_else() is currently too strict - it's
    >> ? ???>> >> particularly annoying if you want to replace some values
    >> ? ???>> >> with a missing:
    >> ? ???>> >>
    >> ? ???>> >> x <- sample(10) if_else(x > 5, NA, x) # Error: `false`
    >> ? ???>> >> has type 'integer' not 'logical'
    >> ? ???>> >>
    >> ? ???>> >> But I would like to make sure that this remains an error:
    >> ? ???>> >>
    >> ? ???>> >> if_else(x > 5, x, "BLAH")
    >> ? ???>> >>
    >> ? ???>> >> Because that seems more likely to be a user error (but
    >> ? ???>> >> reasonable people might certainly believe that it should
    >> ? ???>> >> just work)
    >> ? ???>> >>
    >> ? ???>> >> dplyr is more accommodating in other places (i.e. in
    >> ? ???>> >> bind_rows(), collapse() and the joins) but it's
    >> ? ???>> >> surprisingly hard to get all the details right. For
    >> ? ???>> >> example, what should the result of this call be?
    >> ? ???>> >>
    >> ? ???>> >> if_else(c(TRUE, FALSE), factor(c("a", "b")),
    >> ? ???>> >> factor(c("c", "b"))
    >> ? ???>> >>
    >> ? ???>> >> Strictly speaking I think you could argue it's an error,
    >> ? ???>> >> but that's not very user-friendly. Should it be a factor
    >> ? ???>> >> with the union of the levels? Should it be a character
    >> ? ???>> >> vector + warning? Should the behaviour change if one set
    >> ? ???>> >> of levels is a subset of the other set?
    >> ? ???>> >>
    >> ? ???>> >> There are similar issues for POSIXct (if the time zones
    >> ? ???>> >> are different, which should win?), and difftimes
    >> ? ???>> >> (similarly for units).? Ideally you'd like the behaviour
    >> ? ???>> >> to be extensible for new S3 classes, which suggests it
    >> ? ???>> >> should be a generic (and for the most general case, it
    >> ? ???>> >> would need to dispatch on both arguments).
    >> ? ???>>
    >> ? ???>> > One possible principle would be to use c() -
    >> ? ???>> > i.e. construct out as
    >> ? ???>>
    >> ? ???>> > out <- c(yes[0], no[0]
    >> ? ???>> > length(out) <- max(length(yes), length(no))
    >> ? ???>>
    >> ? ???>> yes; this would require that a? `length<-` method works for the
    >> ? ???>> class of the result.
    >> ? ???>>
    >> ? ???>> Duncan Murdoch mentioned a version of this, in his very
    >> ? ???>> first reply:
    >> ? ???>>
    >> ? ???>> ans <- c(yes, no)[seq_along(test)]
    >> ? ???>> ans <- ans[seq_along(test)]
    >> ? ???>>
    >> ? ???>> which is less efficient for atomic vectors, but requires
    >> ? ???>> less from the class: it "only" needs `c` and `[` to work
    >> ? ???>>
    >> ? ???>> and a mixture of your two proposals would be possible too:
    >> ? ???>>
    >> ? ???>> ans <- c(yes[0], no[0])
    >> ? ???>> ans <- ans[seq_along(test)]
    >> ? ???>>
    >> ? ???>> which does *not* work for my "mpfr" numbers (CRAN package 'Rmpfr'),
    >> ? ???>> but that's a buglet in the? c.mpfr() implementation of my Rmpfr
    >> ? ???>> package... (which has already been fixed in the development version
    >> on
    >> ? ???>> R-forge,
    >> ? ???>> https://r-forge.r-project.org/R/?group_id=386)
    >> ? ???>>
    >> ? ???>> > But of course that wouldn't help with factor responses.
    >> ? ???>>
    >> ? ???>> Yes.? However, a version of Duncan's suggestion -- of treating
    >> 'yes' first
    >> ? ???>> -- does help in that case.
    >> ? ???>>
    >> ? ???>> For once, mainly as "feasability experiment",
    >> ? ???>> I have created a github gist to make my current ifelse2() proposal
    >> ? ???>> available
    >> ? ???>> for commenting, cloning, pullrequesting, etc:
    >> ? ???>>
    >> ? ???>> Consisting of 2 files
    >> ? ???>> - ifelse-def.R :? Functions definitions only, basically all the
    >> current
    >> ? ???>> proposals, called? ifelse*()
    >> ? ???>> - ifelse-checks.R : A simplistic checking function
    >> ? ???>> and examples calling it, notably demonstrating that my
    >> ? ???>> ifelse2()? does work with
    >> ? ???>> "Date", <dateTime> (i.e. "POSIXct" and "POSIXlt"), factors,
    >> ? ???>> and "mpfr" (the arbitrary-precision numbers in my package "Rmpfr")
    >> ? ???>>
    >> ? ???>> Also if you are not on github, you can quickly get to the ifelse2()
    >> ? ???>> definition :
    >> ? ???>>
    >> ? ???>> https://gist.github.com/mmaechler/9cfc3219c4b89649313bfe6853d878
    >> ? ???>> 94#file-ifelse-def-r-L168
    >> ? ???>>
    >> ? ???>> > Also, if you're considering an improved ifelse(), I'd
    >> ? ???>> > strongly urge you to consider adding an `na` argument,
    >> ? ???>>
    >> ? ???>> I now did (called it 'NA.').
    >> ? ???>>
    >> ? ???>> > so that you can use ifelse() to transform all three
    >> ? ???>> > possible values in a logical vector.
    >> ? ???>>
    >> ? ???>> > Hadley
    >> ? ???>> > -- http://hadley.nz
    >> ? ???>>
    >> ? ???>> For those who really hate GH (and don't want or cannot easily
    >> follow the
    >> ? ???>> above URL), here's my current definition:
    >> ? ???>>
    >> ? ???>>
    >> ? ???>> ##' Martin Maechler, 14. Nov 2016 --- taking into account Duncan M.
    >> and
    >> ? ???>> Hadley's
    >> ? ???>> ##' ideas in the R-devel thread starting at (my mom's 86th
    >> birthday):
    >> ? ???>> ##' https://stat.ethz.ch/pipermail/r-devel/2016-August/072970.html
    >> ? ???>> ifelse2 <- function (test, yes, no, NA. = NA) {
    >> ? ???>> if(!is.logical(test)) {
    >> ? ???>> if(is.atomic(test))
    >> ? ???>> storage.mode(test) <- "logical"
    >> ? ???>> else ## typically a "class"; storage.mode<-() typically fails
    >> ? ???>> test <- if(isS4(test)) methods::as(test, "logical") else
    >> ? ???>> as.logical(test)
    >> ? ???>> }
    >> ? ???>>
    >> ? ???>> ## No longer optimize the? "if (a) x else y"? cases:
    >> ? ???>> ## Only "non-good" R users use ifelse(.) instead of if(.) in these
    >> ? ???>> cases.
    >> ? ???>>
    >> ? ???>> ans <-
    >> ? ???>> tryCatch(rep(if(is.object(yes) && identical(class(yes), class(no)))
    >> ? ???>> ## as c(o) or o[0] may not work for the class
    >> ? ???>> yes else c(yes[0], no[0]), length.out =
    >> ? ???>> length(test)),
    >> ? ???>> error = function(e) { ## try asymmetric, yes-leaning
    >> ? ???>> r <- yes
    >> ? ???>> r[!test] <- no[!test]
    >> ? ???>> r
    >> ? ???>> })
    >> ? ???>> ok <- !(nas <- is.na(test))
    >> ? ???>> if (any(test[ok]))
    >> ? ???>> ans[test & ok] <- rep(yes, length.out = length(ans))[test & ok]
    >> ? ???>> if (any(!test[ok]))
    >> ? ???>> ans[!test & ok] <- rep(no, length.out = length(ans))[!test & ok]
    >> ? ???>> ans[nas] <- NA. # possibly coerced to class(ans)
    >> ? ???>> ans
    >> ? ???>> }
    >> ? ???>>
    >> ? ???>> ______________________________________________
    >> ? ???>> R-devel at r-project.org mailing list
    >> ? ???>> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> ? ???>>
    >> 
    >> 
    >> 
    >> ? ???> --
    >> ? ???> Gabriel Becker, PhD
    >> ? ???> Associate Scientist (Bioinformatics)
    >> ? ???> Genentech Research
    >> 
    >> ? ???> [[alternative HTML version deleted]]
    >> 
    >> 


    > -- 
    > Gabriel Becker, PhD
    > Associate Scientist (Bioinformatics)
    > Genentech Research

    > ??? [[alternative HTML version deleted]]

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From gmbecker at ucdavis.edu  Mon Nov 28 16:58:57 2016
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Mon, 28 Nov 2016 07:58:57 -0800
Subject: [Rd] ifelse() woes ... can we agree on a ifelse2() ?
In-Reply-To: <20161128150049.0D9CF1C1526@lynne.stat.math.ethz.ch>
References: <1188177957.798916.1480180441229.ref@mail.yahoo.com>
	<1188177957.798916.1480180441229@mail.yahoo.com>
	<20161128150049.0D9CF1C1526@lynne.stat.math.ethz.ch>
Message-ID: <CADwqtCNSsb7Du5gf0NoAYZ3W=zQk+8paU7Qu1RnGmXwh9skCMg@mail.gmail.com>

Well, that's embarrassing. Sorry for the noise on that front, everyone. I
misunderstood something from the aforementioned unrelated conversation I
was having, but not double checking is on me (I rarely use if else and when
I do I avoid that situation in my own code, which is why I didn't already
know this)


I'd still argue that situation should at least warn, possibly error, as it
seems indicative of a bug in the user's code.

On Mon, Nov 28, 2016 at 7:00 AM, Martin Maechler <maechler at stat.math.ethz.ch
> wrote:

> >>>>> Suharto Anggono Suharto Anggono via R-devel <r-devel at r-project.org>
> >>>>>     on Sat, 26 Nov 2016 17:14:01 +0000 writes:
>
>     > Just stating, in 'ifelse', 'test' is not recycled. As I said in
> "R-intro: length of 'ifelse' result" (https://stat.ethz.ch/
> pipermail/r-devel/2016-September/073136.html), ifelse(condition, a, b)
> returns a vector of the length of 'condition', even if 'a' or 'b' is longer.
>
> yes and  ?ifelse (the help page) also does not say that test is
> recycled, rather
>
>    >>  If \code{yes} or \code{no} are too short, their elements are
> recycled.
>
> (*and* the problem you wrote the above has been corrected in the
>  R-intro manual shortly after).
>
>
>     > On current 'ifelse' code in R:
>
>     > * The part
>     > ans[nas] <- NA
>     > could be omitted because NA's are already in place.
>     > If the part is removed, variable 'nas' is no longer used.
>
> I agree that this seems logical.  If I apply the change, R's own
> full checks do not seem affected, and I may try to commit that
> change and "wait and see".
>
>
>     > * The any(*) part actually checks the thing that is used as the
> index vector. The index vector could be stored and then repeatedly used,
> like the following.
>
>     >     if (any(sel <- test & ok))
>     >     ans[sel] <- rep(yes, length.out = length(ans))[sel]
>
> yes, I know, and have had similar thoughts in the past.
> However note  (I know you that) the current code is
>
>     if (any(test[ok]))
>         ans[test & ok] <- rep(yes, length.out = length(ans))[test & ok]
>
> and   any(test[ok])          may be considerably faster than
>       any(sel <- test & ok)
>
> OTOH I think the current code would only be faster (for the
> above) when any(.) returned FALSE ...
> I think it may depend on the typical use cases which of the two
> versions is more efficient.
>
>
>     > * If 'test' is a factor, doing
>     > storage.mode(test) <- "logical"
>     > is not appropriate, but is.atomic(test) returns TRUE. Maybe use
>     > if(!is.object(test))
>     >    instead of
>     > if(is.atomic(test)) .
>
> This would be a considerable change I think...
> Note that I'm currently really proposing to introduce an *additional*
> ifelse function with different "more reasonable" semantic,  and
> your last change would do that too.
>
> My alternative should really work
> - for factors
> - for "array"s including "matrix" (as the current ifelse() does!)
> - for "Date", "POSIXct", "ts"(timeseries), "zoo",
>       "sparseVector", "sparseMatrix" (*), or "mpfr",
>   without any special code, but rather by design.
>
>  *) Currently needs the R-forge version of  Matrix, version 1.2-8.
>
> A bit less than an hour ago, I have updated the gist with an updated
> proposal ifelse2() {and the current alternatives that I know},
> modified so it *does* keep more, e.g.  dim() attributes in
> reasonable cases.
>
> https://gist.github.com/mmaechler/9cfc3219c4b89649313bfe6853d878
> 94#file-ifelse-def-r-L168
>
> Hence my ifelse2() became even a bit longer (but not slower)
> working for even more classes of  "yes" and "no".
>
>
>     > On ifelse-checks.R:
>     > * In function 'chkIfelse', if the fourth function argument names is
> not "NA.", the argument name is changed, but the function body still uses
> the old name. That makes error in chkIfelse(ifelseHW) .
>     > A fix:
>     >         if(names(formals(FUN))[[4]] != "NA.") {
>     >             body(FUN) <- do.call(substitute, list(body(FUN),
>     >                 setNames(list(quote(NA.)),
> names(formals(FUN))[[4]])))
>     >             names(formals(FUN))[[4]] <- "NA."
>     >         }
>
> yes, thank you!  (a bit embarrassing for me ..)
>
>     > After fixing, chkIfelse(ifelseHW) just fails at identical(iflt,
> as.POSIXlt(ifct)) .
>     > 'iflt' has NA as 'tzone' and 'isdst' components.
>     > * Because function 'chkIfelse' continues checking after failure,
>     > as.POSIXlt(ifct)
>     > may give error. The error happens, for example, in
> chkIfelse(ifelseR) . Maybe place it inside try(...).
>     > * If 'lt' is a "POSIXlt" object, (lt-100) is a "POSIXct" object.
>     > So,
>     > FUN(c(TRUE, FALSE, NA, TRUE), lt, lt-100)
>     > is an example of mixed class.
>
> good; thank you for the hint.
>
>     > * The part of function 'chkIfelse' in
>     > for(i in seq_len(nFact))
>     > uses 'NA.' function argument. That makes error when 'chkIfelse' is
> applied to function without fourth argument.
>     > The part should be wrapped in
>     > if(has.4th) .
> yes of course
>
>     > * Function 'ifelseJH' has fourth argument, but the argument is not
> for value if NA. So, instead of
>     > chkIfelse(ifelseJH) ,
>     > maybe call
>     > chkIfelse(function(test, yes, no) ifelseJH(test, yes, no)) .
> You are right;
> I've decided to solve this differently.
>
> I'm looking at these suggestions now, notably also your proposals below;
> thank you, Suharto!
>
> (I wanted to put my improved 'ifelse2' out first, quickly).
> Martin
>
>
>     > A concrete version of 'ifelse2' that starts the result from 'yes':
>     > function(test, yes, no, NA. = NA) {
>     >     if(!is.logical(test))
>     >         test <- if(isS4(test)) methods::as(test, "logical") else
> as.logical(test)
>     >     n <- length(test)
>     >     ans <- rep(yes, length.out = n)
>     >     ans[!test & !is.na(test)] <- rep(no, length.out = n)[!test & !
> is.na(test)]
>     >     ans[is.na(test)] <- rep(NA., length.out = n)[is.na(test)]
>     >     ans
>     > }
>
>     > It requires 'rep' method that is compatible with subsetting. It also
> works with "POSIXlt" in R 2.7.2, when 'length' gives 9, and gives an
> appropriate result if time zones are the same.
>     > For coercion of 'test', there is no need of keeping attributes. So,
> it doesn't do
>     > storage.mode(test) <- "logical"
>     > and goes directly to 'as.logical'.
>     > It relies on subassignment for silent coercions of
>     > logical < integer < double < complex .
>     > Unlike 'ifelse', it never skips any subassignment. So, phenomenon as
> in "example of different return modes" in ?ifelse doesn't happen.
>
>     > Another version, for keeping attributes as pointed out by Duncan
> Murdoch:
>     > function(test, yes, no, NA. = NA) {
>     >     if(!is.logical(test))
>     >         test <- if(isS4(test)) methods::as(test, "logical") else
> as.logical(test)
>     >     n <- length(test)
>     >     n.yes <- length(yes); n.no <- length(no)
>     >     if (n.yes != n) {
>     >         if (n.no == n) {  # swap yes <-> no
>     >             test <- !test
>     >             ans <- yes; yes <- no; no <- ans
>     >             n.no <- n.yes
>     >         } else yes <- yes[rep_len(seq_len(n.yes), n)]
>     >     }
>     >     ans <- yes
>     >     if (n.no == 1L)
>     >         ans[!test] <- no
>     >     else
>     >         ans[!test & !is.na(test)] <- no[
>     >             if (n.no == n) !test & !is.na(test)
>     >             else rep_len(seq_len(n.no), n)[!test & !is.na(test)]]
>     >     stopifnot(length(NA.) == 1L)
>     >     ans[is.na(test)] <- NA.
>     >     ans
>     > }
>
>     > Note argument evaluation order: 'test', 'yes', 'no', 'NA.'.
>     > First, it chooses the first of 'yes' and 'no' that has the same
> length as the result. If none of 'yes' and 'no' matches the length of the
> result, it chooses recycled (or truncated) 'yes'.
>     > It uses 'rep' on the index and subsetting as a substitute for 'rep'
> on the value.
>     > It requires 'length' method that is compatible with subsetting.
>     > Additionally, it uses the same idea as dplyr::if_else, or more
> precisely the helper function 'replace_with'. It doesn't use 'rep' if the
> length of 'no' is 1 or is the same as the length of the result. For
> subassignment with value of length 1, recycling happens by itself and NA in
> index is OK.
>     > It limits 'NA.' to be of length 1, considering 'NA.' just as a label
> for NA.
>
>     > Cases where the last version above or 'ifelse2 or 'ifelseHW' in
> ifelse-def.R gives inappropriate answers:
>     > - 'yes' and 'no' are "difftime" objects with different "units"
> attribute
>     > - 'yes' and 'no' are "POSIXlt" objects with different time zone
>     > Example: 'yes' in "UTC" and 'no' in "EST5EDT". The reverse, 'yes' in
> "EST5EDT" and 'no' in "UTC" gives error.
>
>     > For the cases, c(yes, no) helps. Function 'ifelseJH' in ifelse-def.R
> gives a right answer for "POSIXlt" case.
>     > ---------------------
>     > Martin et al.,
>
>
>
>
>     > On Tue, Nov 22, 2016 at 2:12 AM, Martin Maechler <maechler at
> stat.math.ethz.ch
>     >> wrote:
>
>     >>
>     >> Note that my premise was really to get *away* from inheriting
>     >> too much from 'test'.
>     >> Hence, I have *not* been talking about replacing ifelse() but
>     >> rather of providing a new  ifelse2()
>     >>
>     >>         [ or if_else()  if Hadley was willing to ditch the dplyr one
>     >>                         in favor of a base one]
>     >>
>     >>      > Specifically, based on an unrelated discussion with Henrik
> Bengtsson
>     >> on
>     >>      > Twitter, I wonder if preserving the recycling behavior test
> is
>     >> longer than
>     >>      > yes, no, but making the case where
>     >>
>     >>      > length( test ) < max(length( yes ), length( no ))
>     >>
>     >>      > would simplify usage for userRs in a useful way.
>     >>
>
>     > That was a copyediting bug on my part, it seems I hit send with my
> message
>     > only half-edited/proofread. Apologies.
>
>     > That should have said that making the case where test is the one
> that will
>     > be recycled (because it is shorter than either yes or no) an error.
> My
>     > claim is that the fact that test itself can be recycled, rather than
> just
>     > yes or no, is confusing to many R users. If we are writing an
> ifelse2 we
>     > might want to drop that feature and just throw an error in that case.
>     > (Users could still use the original ifelse if they understand and
>     > specifically want that behavior).
>
>     > Does that make more sense?
>
>
>
>     >>
>     >>      > Also, If we combine a stricter contract that the output will
> always
>     >> be of
>     >>      > length with the suggestion of a specified output class
>     >>
>     >>
>     > Here, again, I was talking about the restriction that the output be
>     > guaranteed to be the length of test, regardless of the length of yes
> and
>     > no. That, combined with a specific, guaranteed output class would
> make a
>     > much narrower/more restricted but also (I argue) much easier to
> understand
>     > function. Particularly for beginning and intermediate users.
>
>     > I do hear what you're saying about silent conversion, though, so
> what I'm
>     > describing might be a third function (ifelse3 for lack of a better
> name for
>     > now), as you pointed out.
>
>
>     >> that was not my intent here.... but would be another interesting
>     >> extension. However, I would like to keep  R-semantic silent
> coercions
>     >> such as
>     >>            logical < integer < double < complex
>     >>
>     >> and your pseudo code below would not work so easily I think.
>     >>
>     >>      > the pseudo code could be
>     >>
>     >> (I'm changing assignment '=' to  '<-' ...  [please!] )
>     >>
>     >>      > ifelse2 <- function(test, yes, no, outclass) {
>     >>      >   lenout  <- length(test)
>     >>      >   out <- as( rep(yes, length.out <- lenout), outclass)
>     >>      >   out[!test] <- as(rep(no, length.out = lenout)[!test],
> outclass)
>     >>      >   # handle NA stuff
>     >>      >   out
>     >>      > }
>     >>
>     >>
>     >>      > NAs could be tricky if outclass were allowed to be completely
>     >> general, but
>     >>      > doable, I think? Another approach  if we ARE fast-passing
> while
>     >> leaving
>     >>      > ifelse intact is that maybe NA's in test just aren't allowed
> in
>     >> ifelse2.
>     >>      > I'm not saying we should definitely do that, but it's
> possible and
>     >> would
>     >>      > make things faster.
>     >>
>     >>      > Finally, In terms of efficiency, with the stuff that Luke
> and I are
>     >> working
>     >>      > on, the NA detection could be virtually free in certain
> cases, which
>     >> could
>     >>      > give a nice boost for long vectors  that don't have any NAs
> (and
>     >> 'know'
>     >>      > that they don't).
>     >>
>     >> That *is* indeed a very promising prospect!
>     >> Thank you in advance!
>     >>
>     >>      > Best,
>     >>      > ~G
>     >>
>     >> I still am bit disappointed by the fact that it seems nobody has
>     >> taken a good look at my ifelse2() proposal.
>     >>
>
>     > I plan to look at it soon. Thanks again for all your work.
>
>     > ~G
>
>
>     >>
>     >> I really would like an alternative to ifelse() in *addition* to
>     >> the current ifelse(), but hopefully in the future being used in
>     >> quite a few places instead of ifelse()
>     >> efficiency but for changed semantics, namely working for
> considerably
>     >> more "vector like" classes of  'yes' and 'no'  than the current
>     >> ifelse().
>     >>
>     >> As I said, the current proposal works for objects of class
>     >>     "Date", "POSIXct", "POSIXlt", "factor",  "mpfr" (pkg 'Rmpfr')
>     >> and hopefully for "sparseVector" (in a next version of the 'Matrix'
> pkg).
>     >>
>     >> Martin
>     >>
>     >>      > On Tue, Nov 15, 2016 at 3:58 AM, Martin Maechler <
>     >> maechler at stat.math.ethz.ch
>     >>      >> wrote:
>     >>
>     >>      >> Finally getting back to this :
>     >>      >>
>     >>      >> >>>>> Hadley Wickham <h.wickham at gmail.com>
>     >>      >> >>>>>     on Mon, 15 Aug 2016 07:51:35 -0500 writes:
>     >>      >>
>     >>      >> > On Fri, Aug 12, 2016 at 11:31 AM, Hadley Wickham
>     >>      >> > <h.wickham at gmail.com> wrote:
>     >>      >> >>> >> One possibility would also be to consider a
>     >>      >> >>> "numbers-only" or >> rather "same type"-only {e.g.,
>     >>      >> >>> would also work for characters} >> version.
>     >>      >> >>>
>     >>      >> >>> > I don't know what you mean by these.
>     >>      >> >>>
>     >>      >> >>> In the mean time, Bob Rudis mentioned dplyr::if_else(),
>     >>      >> >>> which is very relevant, thank you Bob!
>     >>      >> >>>
>     >>      >> >>> As I have found, that actually works in such a "same
>     >>      >> >>> type"-only way: It does not try to coerce, but gives an
>     >>      >> >>> error when the classes differ, even in this somewhat
>     >>      >> >>> debatable case :
>     >>      >> >>>
>     >>      >> >>> > dplyr::if_else(c(TRUE, FALSE), 2:3, 0+10:11) Error:
>     >>      >> >>> `false` has type 'double' not 'integer'
>     >>      >> >>> >
>     >>      >> >>>
>     >>      >> >>> As documented, if_else() is clearly stricter than
>     >>      >> >>> ifelse() and e.g., also does no recycling (but of
>     >>      >> >>> length() 1).
>     >>      >> >>
>     >>      >> >> I agree that if_else() is currently too strict - it's
>     >>      >> >> particularly annoying if you want to replace some values
>     >>      >> >> with a missing:
>     >>      >> >>
>     >>      >> >> x <- sample(10) if_else(x > 5, NA, x) # Error: `false`
>     >>      >> >> has type 'integer' not 'logical'
>     >>      >> >>
>     >>      >> >> But I would like to make sure that this remains an error:
>     >>      >> >>
>     >>      >> >> if_else(x > 5, x, "BLAH")
>     >>      >> >>
>     >>      >> >> Because that seems more likely to be a user error (but
>     >>      >> >> reasonable people might certainly believe that it should
>     >>      >> >> just work)
>     >>      >> >>
>     >>      >> >> dplyr is more accommodating in other places (i.e. in
>     >>      >> >> bind_rows(), collapse() and the joins) but it's
>     >>      >> >> surprisingly hard to get all the details right. For
>     >>      >> >> example, what should the result of this call be?
>     >>      >> >>
>     >>      >> >> if_else(c(TRUE, FALSE), factor(c("a", "b")),
>     >>      >> >> factor(c("c", "b"))
>     >>      >> >>
>     >>      >> >> Strictly speaking I think you could argue it's an error,
>     >>      >> >> but that's not very user-friendly. Should it be a factor
>     >>      >> >> with the union of the levels? Should it be a character
>     >>      >> >> vector + warning? Should the behaviour change if one set
>     >>      >> >> of levels is a subset of the other set?
>     >>      >> >>
>     >>      >> >> There are similar issues for POSIXct (if the time zones
>     >>      >> >> are different, which should win?), and difftimes
>     >>      >> >> (similarly for units).  Ideally you'd like the behaviour
>     >>      >> >> to be extensible for new S3 classes, which suggests it
>     >>      >> >> should be a generic (and for the most general case, it
>     >>      >> >> would need to dispatch on both arguments).
>     >>      >>
>     >>      >> > One possible principle would be to use c() -
>     >>      >> > i.e. construct out as
>     >>      >>
>     >>      >> > out <- c(yes[0], no[0]
>     >>      >> > length(out) <- max(length(yes), length(no))
>     >>      >>
>     >>      >> yes; this would require that a  `length<-` method works for
> the
>     >>      >> class of the result.
>     >>      >>
>     >>      >> Duncan Murdoch mentioned a version of this, in his very
>     >>      >> first reply:
>     >>      >>
>     >>      >> ans <- c(yes, no)[seq_along(test)]
>     >>      >> ans <- ans[seq_along(test)]
>     >>      >>
>     >>      >> which is less efficient for atomic vectors, but requires
>     >>      >> less from the class: it "only" needs `c` and `[` to work
>     >>      >>
>     >>      >> and a mixture of your two proposals would be possible too:
>     >>      >>
>     >>      >> ans <- c(yes[0], no[0])
>     >>      >> ans <- ans[seq_along(test)]
>     >>      >>
>     >>      >> which does *not* work for my "mpfr" numbers (CRAN package
> 'Rmpfr'),
>     >>      >> but that's a buglet in the  c.mpfr() implementation of my
> Rmpfr
>     >>      >> package... (which has already been fixed in the development
> version
>     >> on
>     >>      >> R-forge,
>     >>      >> https://r-forge.r-project.org/R/?group_id=386)
>     >>      >>
>     >>      >> > But of course that wouldn't help with factor responses.
>     >>      >>
>     >>      >> Yes.  However, a version of Duncan's suggestion -- of
> treating
>     >> 'yes' first
>     >>      >> -- does help in that case.
>     >>      >>
>     >>      >> For once, mainly as "feasability experiment",
>     >>      >> I have created a github gist to make my current ifelse2()
> proposal
>     >>      >> available
>     >>      >> for commenting, cloning, pullrequesting, etc:
>     >>      >>
>     >>      >> Consisting of 2 files
>     >>      >> - ifelse-def.R :  Functions definitions only, basically all
> the
>     >> current
>     >>      >> proposals, called  ifelse*()
>     >>      >> - ifelse-checks.R : A simplistic checking function
>     >>      >> and examples calling it, notably demonstrating that my
>     >>      >> ifelse2()  does work with
>     >>      >> "Date", <dateTime> (i.e. "POSIXct" and "POSIXlt"), factors,
>     >>      >> and "mpfr" (the arbitrary-precision numbers in my package
> "Rmpfr")
>     >>      >>
>     >>      >> Also if you are not on github, you can quickly get to the
> ifelse2()
>     >>      >> definition :
>     >>      >>
>     >>      >> https://gist.github.com/mmaechler/
> 9cfc3219c4b89649313bfe6853d878
>     >>      >> 94#file-ifelse-def-r-L168
>     >>      >>
>     >>      >> > Also, if you're considering an improved ifelse(), I'd
>     >>      >> > strongly urge you to consider adding an `na` argument,
>     >>      >>
>     >>      >> I now did (called it 'NA.').
>     >>      >>
>     >>      >> > so that you can use ifelse() to transform all three
>     >>      >> > possible values in a logical vector.
>     >>      >>
>     >>      >> > Hadley
>     >>      >> > -- http://hadley.nz
>     >>      >>
>     >>      >> For those who really hate GH (and don't want or cannot
> easily
>     >> follow the
>     >>      >> above URL), here's my current definition:
>     >>      >>
>     >>      >>
>     >>      >> ##' Martin Maechler, 14. Nov 2016 --- taking into account
> Duncan M.
>     >> and
>     >>      >> Hadley's
>     >>      >> ##' ideas in the R-devel thread starting at (my mom's 86th
>     >> birthday):
>     >>      >> ##' https://stat.ethz.ch/pipermail/r-devel/2016-August/
> 072970.html
>     >>      >> ifelse2 <- function (test, yes, no, NA. = NA) {
>     >>      >> if(!is.logical(test)) {
>     >>      >> if(is.atomic(test))
>     >>      >> storage.mode(test) <- "logical"
>     >>      >> else ## typically a "class"; storage.mode<-() typically
> fails
>     >>      >> test <- if(isS4(test)) methods::as(test, "logical") else
>     >>      >> as.logical(test)
>     >>      >> }
>     >>      >>
>     >>      >> ## No longer optimize the  "if (a) x else y"  cases:
>     >>      >> ## Only "non-good" R users use ifelse(.) instead of if(.)
> in these
>     >>      >> cases.
>     >>      >>
>     >>      >> ans <-
>     >>      >> tryCatch(rep(if(is.object(yes) && identical(class(yes),
> class(no)))
>     >>      >> ## as c(o) or o[0] may not work for the class
>     >>      >> yes else c(yes[0], no[0]), length.out =
>     >>      >> length(test)),
>     >>      >> error = function(e) { ## try asymmetric, yes-leaning
>     >>      >> r <- yes
>     >>      >> r[!test] <- no[!test]
>     >>      >> r
>     >>      >> })
>     >>      >> ok <- !(nas <- is.na(test))
>     >>      >> if (any(test[ok]))
>     >>      >> ans[test & ok] <- rep(yes, length.out = length(ans))[test &
> ok]
>     >>      >> if (any(!test[ok]))
>     >>      >> ans[!test & ok] <- rep(no, length.out = length(ans))[!test
> & ok]
>     >>      >> ans[nas] <- NA. # possibly coerced to class(ans)
>     >>      >> ans
>     >>      >> }
>     >>      >>
>     >>      >> ______________________________________________
>     >>      >> R-devel at r-project.org mailing list
>     >>      >> https://stat.ethz.ch/mailman/listinfo/r-devel
>     >>      >>
>     >>
>     >>
>     >>
>     >>      > --
>     >>      > Gabriel Becker, PhD
>     >>      > Associate Scientist (Bioinformatics)
>     >>      > Genentech Research
>     >>
>     >>      > [[alternative HTML version deleted]]
>     >>
>     >>
>
>
>     > --
>     > Gabriel Becker, PhD
>     > Associate Scientist (Bioinformatics)
>     > Genentech Research
>
>     >     [[alternative HTML version deleted]]
>
>     > ______________________________________________
>     > R-devel at r-project.org mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Gabriel Becker, PhD
Associate Scientist (Bioinformatics)
Genentech Research

	[[alternative HTML version deleted]]


From suharto_anggono at yahoo.com  Tue Nov 29 17:45:12 2016
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Tue, 29 Nov 2016 16:45:12 +0000 (UTC)
Subject: [Rd] ifelse() woes ... can we agree on a ifelse2() ?
References: <7752800.2716601.1480437912601.ref@mail.yahoo.com>
Message-ID: <7752800.2716601.1480437912601@mail.yahoo.com>

Interspersed below.
--------------------------------------------


 Subject: Re: ifelse() woes ... can we agree on a ifelse2() ?
 To: R-devel at lists.R-project.org
 Date: Sunday, 27 November, 2016, 12:14 AM
 
On current 'ifelse' code in R:
...
* If 'test' is a factor, doing
storage.mode(test) <- "logical"
is not appropriate, but is.atomic(test) returns TRUE. Maybe use
if(!is.object(test))
instead of
if(is.atomic(test)) .
===================================
I now see that, for 'test' that is atomic and has "class" attribute, with current 'ifelse' code, changing
if(is.atomic(test))
to
if(!is.object(test))
removes class of 'test' and makes the result doesn't have class of 'test', which is not according to the documentation. The documentation of 'ifelse' says that the value is "A vector of the same length and attributes (including dimensions and "class") as 'test' ...".
===================================


function(test, yes, no, NA. = NA) {
    if(!is.logical(test))
        test <- if(isS4(test)) methods::as(test, "logical") else as.logical(test)
    n <- length(test)
    n.yes <- length(yes); n.no <- length(no)
    if (n.yes != n) {
        if (n.no == n) {  # swap yes <-> no
            test <- !test
            ans <- yes; yes <- no; no <- ans
            n.no <- n.yes
        } else yes <- yes[rep_len(seq_len(n.yes), n)]
    }
    ans <- yes
    if (n.no == 1L)
        ans[!test] <- no
    else
        ans[!test & !is.na(test)] <- no[
            if (n.no == n) !test & !is.na(test)
            else rep_len(seq_len(n.no), n)[!test & !is.na(test)]]
    stopifnot(length(NA.) == 1L)
    ans[is.na(test)] <- NA.
    ans
}

===================================
For data frame, indexing by logical matrix is different from indexing by logical vector.
Because there is an example like that, I think that it is better to remove
if(!is.logical(test))
in the function definition above, making 'as.logical' also applied to 'test' of mode "logical", stripping attributes. Doing so makes sure that 'test' is a plain logical vector, so that indexing is compatible with 'length'.


From lepennec at cmap.polytechnique.fr  Wed Nov 30 11:05:43 2016
From: lepennec at cmap.polytechnique.fr (Erwan Le Pennec)
Date: Wed, 30 Nov 2016 11:05:43 +0100
Subject: [Rd] pmin/pmax issue with ordered factors
Message-ID: <b4f9344d-87af-39b3-0b4c-b8c330c91e3c@cmap.polytechnique.fr>

     Dear all,

pmin/pmax used to work with ordered factors but fail now since this 
summer when those functions have tried to handle more cases.

A simple way to trigger the issue is:

 > min(ordered(c(1,5,6)))
[1] 1
Levels: 1 < 5 < 6
 > pmin(ordered(c(1,5,6)), ordered(c(1,5,6)))
Error in `mostattributes<-`(`*tmp*`, value = attributes(elts[[1L]])) :
   adding class "factor" to an invalid object

A simple fix is to explicitly test for the ordered class and use the 
internal method in that case as proposed in the attached patch.

     Yours,

         Erwan

-------------- next part --------------
A non-text attachment was scrubbed...
Name: patch.diff
Type: text/x-patch
Size: 1016 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20161130/71dc22b6/attachment.bin>

From Michael.Laviolette at dhhs.nh.gov  Wed Nov 30 15:16:42 2016
From: Michael.Laviolette at dhhs.nh.gov (Laviolette, Michael)
Date: Wed, 30 Nov 2016 14:16:42 +0000
Subject: [Rd] problem with normalizePath()
In-Reply-To: <22575.26225.614494.711839@stat.math.ethz.ch>
References: <e6592864a7b34cca92711b6c3c309484@dhhs.nh.gov>
	<CABKQe-Zh+xoX5geKqYvGMpO1bPx5BjwD61cTY-1tKagLw-KJMA@mail.gmail.com>
	<22575.26225.614494.711839@stat.math.ethz.ch>
Message-ID: <cbb1cb742eae4ed298f82b03642c9259@dhhs.nh.gov>

In researching another issue, I discovered a workaround: the network drive folder needs to be mapped to the local PC.

setwd("//Hzndhhsvf2/data/OCPH/EPI/BHSDM/Group/Michael Laviolette/Stat tools")
df1 <- readxl::read_excel("addrlist-4-MikeL.xls", 2)                                # fails, throws same error
df2 <- readxl::read_excel("Z:/Stat tools/addrlist-4-MikeL.xls", 2)      # works

-----Original Message-----
From: Martin Maechler [mailto:maechler at stat.math.ethz.ch] 
Sent: Friday, November 18, 2016 3:37 PM
To: Evan Cortens
Cc: Laviolette, Michael; r-devel at r-project.org
Subject: Re: [Rd] problem with normalizePath()

>>>>> Evan Cortens <ecortens at mtroyal.ca>
>>>>>     on Thu, 17 Nov 2016 15:51:03 -0700 writes:

    > I wonder if this could be related to the issue that I
    > submitted to bugzilla about two months ago? (
    > https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=17159)

    > That is to say, could it be that it's treating the first
    > path after the single backslash as an actual directory,
    > rather than as the name of the share?

    > -- 
    > Evan Cortens, PhD Institutional Analyst - Office of
    > Institutional Analysis Mount Royal University 403-440-6529

Could well be.  Thank you, Evan, also for your bug report including patch proposal.

In such situations we (R core) would be really happy if Microsoft showed another facet of their investment into R:
Ideally there should be enough staff who can judge and test such bugs and bug fixes? 

--> I'm BCC'ing this to one place at least.

Best,
Martin Maechler  ETH Zurich

    > On Thu, Nov 17, 2016 at 2:28 PM, Laviolette, Michael <
    > Michael.Laviolette at dhhs.nh.gov> wrote:

    >> The packages "readxl" and "haven" (and possibly others)
    >> no longer access files on shared network drives. The
    >> problem appears to be in the normalizePath()
    >> function. The file can be read from a local drive or by
    >> functions that don't call normalizePath(). The error
    >> thrown is
    >> 
    >> Error:
    >> path[1]="\\Hzndhhsvf2/data/OCPH/EPI/BHSDM/Group/17.xls":
    >> The system cannot find the file specified
    >> 
    >> Here's my session:
    >> 
    >> library(readxl) library(XLConnect)
    >> 
    >> # attempting to read file from network drive df1 <-
    >> read_excel("//Hzndhhsvf2/data/OCPH/EPI/BHSDM/Group/17.xls")
    >> # pathname is fully qualified, but error thrown as above
    >> 
    >> cat(normalizePath("//Hzndhhsvf2/data/OCPH/EPI/BHSDM/Group/17.xls"))
    >> # throws same error
    >> 
    >> # reading same file with different function df2 <-
    >> readWorksheetFromFile("//Hzndhhsvf2/data/OCPH/EPI/BHSDM/Group/17.xls",
    >> 1) # completes successfully
    >> 
    >> # reading same file from local drive df3 <-
    >> read_excel("C:/17.xls") # completes successfully
    >> 
    >> sessionInfo() R version 3.3.2 (2016-10-31) Platform:
    >> x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 7
    >> x64 (build 7601) Service Pack 1
    >> 
    >> locale: [1] LC_COLLATE=English_United States.1252
    >> LC_CTYPE=English_United States.1252 [3]
    >> LC_MONETARY=English_United States.1252 LC_NUMERIC=C [5]
    >> LC_TIME=English_United States.1252
    >> 
    >> attached base packages: [1] stats graphics grDevices
    >> utils datasets methods base
    >> 
    >> other attached packages: [1] readxl_0.1.1 dplyr_0.5.0
    >> XLConnect_0.2-12 [4] XLConnectJars_0.2-12 ROracle_1.2-1
    >> DBI_0.5-1
    >> 
    >> loaded via a namespace (and not attached): [1]
    >> magrittr_1.5 R6_2.2.0 assertthat_0.1 tools_3.3.2
    >> haven_1.0.0 [6] tibble_1.2 Rcpp_0.12.7 rJava_0.9-8
    >> 
    >> Please advise.  Thanks,
    >> 
    >> Michael Laviolette PhD MPH Public Health Statistician
    >> Bureau of Public Health Statistics and Informatics New
    >> Hampshire Division of Public Health Services 29 Hazen
    >> Drive Concord, NH 03301-6504 Phone: 603-271-5688 Fax:
    >> 603-271-7623 Email: Michael.Laviolette at dhhs.nh.gov
    >> 
    >> 
    >> 
    >> [[alternative HTML version deleted]]
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> 

    > 	[[alternative HTML version deleted]]

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From ecortens at mtroyal.ca  Wed Nov 30 17:58:59 2016
From: ecortens at mtroyal.ca (Evan Cortens)
Date: Wed, 30 Nov 2016 09:58:59 -0700
Subject: [Rd] problem with normalizePath()
In-Reply-To: <cbb1cb742eae4ed298f82b03642c9259@dhhs.nh.gov>
References: <e6592864a7b34cca92711b6c3c309484@dhhs.nh.gov>
	<CABKQe-Zh+xoX5geKqYvGMpO1bPx5BjwD61cTY-1tKagLw-KJMA@mail.gmail.com>
	<22575.26225.614494.711839@stat.math.ethz.ch>
	<cbb1cb742eae4ed298f82b03642c9259@dhhs.nh.gov>
Message-ID: <CABKQe-a0KKkF-CjbbEJjg0fHJum53JQMtys=pX+2Eqa7Nqh9pA@mail.gmail.com>

I found this as well. At our institution, our home directories are on
network shares that are mapped to local drives. The default, it appears, is
to set the location for libraries (etc) to the network share name
(//computer//share/director/a/b/user) rather than the local drive mapping
(H:/). Given the issue with dir.create(), this means it's impossible to
install packages (since it tries to "create" the share, not the highest
directory). This can be fixed in the same way Michael found, namely, set
the environment variables to use the local mapping rather than the network
share. But ideally, the fix would be to treat Windows network paths
correctly.

Best,

Evan

On Wed, Nov 30, 2016 at 7:16 AM, Laviolette, Michael <
Michael.Laviolette at dhhs.nh.gov> wrote:

> In researching another issue, I discovered a workaround: the network drive
> folder needs to be mapped to the local PC.
>
> setwd("//Hzndhhsvf2/data/OCPH/EPI/BHSDM/Group/Michael Laviolette/Stat
> tools")
> df1 <- readxl::read_excel("addrlist-4-MikeL.xls", 2)
>           # fails, throws same error
> df2 <- readxl::read_excel("Z:/Stat tools/addrlist-4-MikeL.xls", 2)      #
> works
>
> -----Original Message-----
> From: Martin Maechler [mailto:maechler at stat.math.ethz.ch]
> Sent: Friday, November 18, 2016 3:37 PM
> To: Evan Cortens
> Cc: Laviolette, Michael; r-devel at r-project.org
> Subject: Re: [Rd] problem with normalizePath()
>
> >>>>> Evan Cortens <ecortens at mtroyal.ca>
> >>>>>     on Thu, 17 Nov 2016 15:51:03 -0700 writes:
>
>     > I wonder if this could be related to the issue that I
>     > submitted to bugzilla about two months ago? (
>     > https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=17159)
>
>     > That is to say, could it be that it's treating the first
>     > path after the single backslash as an actual directory,
>     > rather than as the name of the share?
>
>     > --
>     > Evan Cortens, PhD Institutional Analyst - Office of
>     > Institutional Analysis Mount Royal University 403-440-6529
>
> Could well be.  Thank you, Evan, also for your bug report including patch
> proposal.
>
> In such situations we (R core) would be really happy if Microsoft showed
> another facet of their investment into R:
> Ideally there should be enough staff who can judge and test such bugs and
> bug fixes?
>
> --> I'm BCC'ing this to one place at least.
>
> Best,
> Martin Maechler  ETH Zurich
>
>     > On Thu, Nov 17, 2016 at 2:28 PM, Laviolette, Michael <
>     > Michael.Laviolette at dhhs.nh.gov> wrote:
>
>     >> The packages "readxl" and "haven" (and possibly others)
>     >> no longer access files on shared network drives. The
>     >> problem appears to be in the normalizePath()
>     >> function. The file can be read from a local drive or by
>     >> functions that don't call normalizePath(). The error
>     >> thrown is
>     >>
>     >> Error:
>     >> path[1]="\\Hzndhhsvf2/data/OCPH/EPI/BHSDM/Group/17.xls":
>     >> The system cannot find the file specified
>     >>
>     >> Here's my session:
>     >>
>     >> library(readxl) library(XLConnect)
>     >>
>     >> # attempting to read file from network drive df1 <-
>     >> read_excel("//Hzndhhsvf2/data/OCPH/EPI/BHSDM/Group/17.xls")
>     >> # pathname is fully qualified, but error thrown as above
>     >>
>     >> cat(normalizePath("//Hzndhhsvf2/data/OCPH/EPI/BHSDM/Group/17.xls"))
>     >> # throws same error
>     >>
>     >> # reading same file with different function df2 <-
>     >> readWorksheetFromFile("//Hzndhhsvf2/data/OCPH/EPI/
> BHSDM/Group/17.xls",
>     >> 1) # completes successfully
>     >>
>     >> # reading same file from local drive df3 <-
>     >> read_excel("C:/17.xls") # completes successfully
>     >>
>     >> sessionInfo() R version 3.3.2 (2016-10-31) Platform:
>     >> x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 7
>     >> x64 (build 7601) Service Pack 1
>     >>
>     >> locale: [1] LC_COLLATE=English_United States.1252
>     >> LC_CTYPE=English_United States.1252 [3]
>     >> LC_MONETARY=English_United States.1252 LC_NUMERIC=C [5]
>     >> LC_TIME=English_United States.1252
>     >>
>     >> attached base packages: [1] stats graphics grDevices
>     >> utils datasets methods base
>     >>
>     >> other attached packages: [1] readxl_0.1.1 dplyr_0.5.0
>     >> XLConnect_0.2-12 [4] XLConnectJars_0.2-12 ROracle_1.2-1
>     >> DBI_0.5-1
>     >>
>     >> loaded via a namespace (and not attached): [1]
>     >> magrittr_1.5 R6_2.2.0 assertthat_0.1 tools_3.3.2
>     >> haven_1.0.0 [6] tibble_1.2 Rcpp_0.12.7 rJava_0.9-8
>     >>
>     >> Please advise.  Thanks,
>     >>
>     >> Michael Laviolette PhD MPH Public Health Statistician
>     >> Bureau of Public Health Statistics and Informatics New
>     >> Hampshire Division of Public Health Services 29 Hazen
>     >> Drive Concord, NH 03301-6504 Phone: 603-271-5688 Fax:
>     >> 603-271-7623 Email: Michael.Laviolette at dhhs.nh.gov
>     >>
>     >>
>     >>
>     >> [[alternative HTML version deleted]]
>     >>
>     >> ______________________________________________
>     >> R-devel at r-project.org mailing list
>     >> https://stat.ethz.ch/mailman/listinfo/r-devel
>     >>
>
>     >   [[alternative HTML version deleted]]
>
>     > ______________________________________________
>     > R-devel at r-project.org mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Evan Cortens, PhD
Institutional Analyst - Office of Institutional Analysis
Mount Royal University
403-440-6529

	[[alternative HTML version deleted]]


