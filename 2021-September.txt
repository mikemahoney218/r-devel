From Thom@@@SOEIRO @end|ng |rom @p-hm@|r  Wed Sep  1 17:01:43 2021
From: Thom@@@SOEIRO @end|ng |rom @p-hm@|r (SOEIRO Thomas)
Date: Wed, 1 Sep 2021 15:01:43 +0000
Subject: [Rd] sep hard coded in write.ftable
Message-ID: <1a597120ad27455e9249bd6577ea39b2@SCWPR-EXDAG1-6A.aphm.ap-hm.fr>

Dear all,

(This is a follow up of a previous suggestion for ftable that was added in R 4.1.0: https://stat.ethz.ch/pipermail/r-devel/2020-May/079451.html)

The sep argument is hard coded in write.ftable:
	
write.ftable <- function(x, file = "", quote = TRUE, append = FALSE,
			 digits = getOption("digits"), ...)
{
    r <- format.ftable(x, quote = quote, digits = digits, ...)
    cat(t(r), file = file, append = append,
	sep = c(rep(" ", ncol(r) - 1), "\n"))
    invisible(x)
}

A minor change would allow users to modify it:

write.ftable2 <- function(x, file = "", quote = TRUE, append = FALSE,
                          digits = getOption("digits"), sep = " ", ...)
{
  r <- stats:::format.ftable(x, quote = quote, digits = digits, ...)
  cat(t(r), file = file, append = append,
      sep = c(rep(sep, ncol(r) - 1), "\n"))
  invisible(x)
}

This would allow to avoid a previous call to format.ftable (although write.ftable is significantly slower than write.table):

ftable(formula = wool + tension ~ breaks, data = warpbreaks) |>
  format(quote = FALSE) |>
  write.table(sep = ";", row.names = FALSE, col.names = FALSE)

ftable(formula = wool + tension ~ breaks, data = warpbreaks) |>
  write.ftable2(sep = ";")

Best regards,

Thomas


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Thu Sep  2 11:29:39 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 2 Sep 2021 11:29:39 +0200
Subject: [Rd] sep hard coded in write.ftable
In-Reply-To: <1a597120ad27455e9249bd6577ea39b2@SCWPR-EXDAG1-6A.aphm.ap-hm.fr>
References: <1a597120ad27455e9249bd6577ea39b2@SCWPR-EXDAG1-6A.aphm.ap-hm.fr>
Message-ID: <24880.39299.992900.911002@stat.math.ethz.ch>

>>>>> SOEIRO Thomas 
>>>>>     on Wed, 1 Sep 2021 15:01:43 +0000 writes:

    > Dear all,

    > (This is a follow up of a previous suggestion for ftable that was added in R 4.1.0: https://stat.ethz.ch/pipermail/r-devel/2020-May/079451.html)

    > The sep argument is hard coded in write.ftable:
	
    > write.ftable <- function(x, file = "", quote = TRUE, append = FALSE,
    > digits = getOption("digits"), ...)
    > {
    > r <- format.ftable(x, quote = quote, digits = digits, ...)
    > cat(t(r), file = file, append = append,
    > sep = c(rep(" ", ncol(r) - 1), "\n"))
    > invisible(x)
    > }

    > A minor change would allow users to modify it:

    > write.ftable2 <- function(x, file = "", quote = TRUE, append = FALSE,
    > digits = getOption("digits"), sep = " ", ...)
    > {
    > r <- stats:::format.ftable(x, quote = quote, digits = digits, ...)
    > cat(t(r), file = file, append = append,
    > sep = c(rep(sep, ncol(r) - 1), "\n"))
    > invisible(x)
    > }

I agree this sounds reasonable, and am currently running
'make check-devel' on sources modified accordingly ..

Martin


    > This would allow to avoid a previous call to format.ftable (although write.ftable is significantly slower than write.table):

    > ftable(formula = wool + tension ~ breaks, data = warpbreaks) |>
    > format(quote = FALSE) |>
    > write.table(sep = ";", row.names = FALSE, col.names = FALSE)

    > ftable(formula = wool + tension ~ breaks, data = warpbreaks) |>
    > write.ftable2(sep = ";")

    > Best regards,
    > Thomas

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Thu Sep  2 12:55:03 2021
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (SP))
Date: Thu, 2 Sep 2021 10:55:03 +0000
Subject: [Rd] sum() and mean() for (ALTREP) integer sequences
Message-ID: <159209eaff1e4ba99bc467eed45d336f@UM-MAIL3214.unimaas.nl>

Hi all,

I am trying to understand the performance of functions applied to integer sequences. Consider the following:

### begin example ###

library(lobstr)
library(microbenchmark)

x <- sample(1e6)
obj_size(x)
# 4,000,048 B

y <- 1:1e6
obj_size(y)
# 680 B

# So we can see that 'y' uses ALTREP. These are, as expected, the same:

sum(x)
# [1] 500000500000
sum(y)
# [1] 500000500000

# For 'x', we have to go through the trouble of actually summing up 1e6 integers.
# For 'y', knowing its form, we really just need to do:

1e6*(1e6+1)/2
# [1] 500000500000

# which should be a whole lot faster. And indeed, it is:

microbenchmark(sum(x),sum(y))

# Unit: nanoseconds                                                                                                     
#    expr    min       lq      mean   median       uq    max neval cld
#  sum(x) 533452 595204.5 634266.90 613102.5 638271.5 978519   100   b                                                  
#  sum(y)    183    245.5    446.09    338.5    447.0   3233   100  a

# Now what about mean()?

mean(x)
# [1] 500000.5
mean(y)
# [1] 500000.5

# which is the same as

(1e6+1)/2
# [1] 500000.5

# But this surprised me:

microbenchmark(mean(x),mean(y))

# Unit: microseconds                                                                                                    
#     expr      min        lq     mean   median       uq      max neval cld
#  mean(x)  935.389  943.4795 1021.423  954.689  985.122 2065.974   100  a                                              
#  mean(y) 3500.262 3581.9530 3814.664 3637.984 3734.598 5866.768   100   b

### end example ###

So why is mean() on an ALTREP sequence slower when sum() is faster?

And more generally, when using sum() on an ALTREP integer sequence, does R actually use something like n*(n+1)/2 (or generalized to sequences a:b -- (a+b)*(b-a+1)/2) for computing the sum? If so, why not (it seems) for mean()?

Best,
Wolfgang


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Sep  2 13:46:18 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 2 Sep 2021 07:46:18 -0400
Subject: [Rd] sum() and mean() for (ALTREP) integer sequences
In-Reply-To: <159209eaff1e4ba99bc467eed45d336f@UM-MAIL3214.unimaas.nl>
References: <159209eaff1e4ba99bc467eed45d336f@UM-MAIL3214.unimaas.nl>
Message-ID: <7189aade-9a94-ceb0-c9a9-1106c7592a2e@gmail.com>

On 02/09/2021 6:55 a.m., Viechtbauer, Wolfgang (SP) wrote:
> Hi all,
> 
> I am trying to understand the performance of functions applied to integer sequences. Consider the following:
> 
> ### begin example ###
> 
> library(lobstr)
> library(microbenchmark)
> 
> x <- sample(1e6)
> obj_size(x)
> # 4,000,048 B
> 
> y <- 1:1e6
> obj_size(y)
> # 680 B
> 
> # So we can see that 'y' uses ALTREP. These are, as expected, the same:
> 
> sum(x)
> # [1] 500000500000
> sum(y)
> # [1] 500000500000
> 
> # For 'x', we have to go through the trouble of actually summing up 1e6 integers.
> # For 'y', knowing its form, we really just need to do:
> 
> 1e6*(1e6+1)/2
> # [1] 500000500000
> 
> # which should be a whole lot faster. And indeed, it is:
> 
> microbenchmark(sum(x),sum(y))
> 
> # Unit: nanoseconds
> #    expr    min       lq      mean   median       uq    max neval cld
> #  sum(x) 533452 595204.5 634266.90 613102.5 638271.5 978519   100   b
> #  sum(y)    183    245.5    446.09    338.5    447.0   3233   100  a
> 
> # Now what about mean()?
> 
> mean(x)
> # [1] 500000.5
> mean(y)
> # [1] 500000.5
> 
> # which is the same as
> 
> (1e6+1)/2
> # [1] 500000.5
> 
> # But this surprised me:
> 
> microbenchmark(mean(x),mean(y))
> 
> # Unit: microseconds
> #     expr      min        lq     mean   median       uq      max neval cld
> #  mean(x)  935.389  943.4795 1021.423  954.689  985.122 2065.974   100  a
> #  mean(y) 3500.262 3581.9530 3814.664 3637.984 3734.598 5866.768   100   b
> 
> ### end example ###
> 
> So why is mean() on an ALTREP sequence slower when sum() is faster?
> 
> And more generally, when using sum() on an ALTREP integer sequence, does R actually use something like n*(n+1)/2 (or generalized to sequences a:b -- (a+b)*(b-a+1)/2) for computing the sum? If so, why not (it seems) for mean()?

The mean.default function looks like this:

function (x, trim = 0, na.rm = FALSE, ...)
{
     if (!is.numeric(x) && !is.complex(x) && !is.logical(x)) {
         warning("argument is not numeric or logical: returning NA")
         return(NA_real_)
     }
     if (na.rm)
         x <- x[!is.na(x)]
     if (!is.numeric(trim) || length(trim) != 1L)
         stop("'trim' must be numeric of length one")
     n <- length(x)
     if (trim > 0 && n) {
         if (is.complex(x))
             stop("trimmed means are not defined for complex data")
         if (anyNA(x))
             return(NA_real_)
         if (trim >= 0.5)
             return(stats::median(x, na.rm = FALSE))
         lo <- floor(n * trim) + 1
         hi <- n + 1 - lo
         x <- sort.int(x, partial = unique(c(lo, hi)))[lo:hi]
     }
     .Internal(mean(x))
}

So it does fixups for trimming and NA removal, then calls an internal 
function.  The internal function is the first part of do_summary, here:

https://github.com/wch/r-source/blob/f9c955fc6699a1f0482e4281ba658215c0e0b949/src/main/summary.c#L541-L556 


It is using separate functions for the mean by type.  The real_mean 
function here:

https://github.com/wch/r-source/blob/f9c955fc6699a1f0482e4281ba658215c0e0b949/src/main/summary.c#L476-L515 


makes a big effort to avoid overflows.

So I suspect the reason mean.default doesn't use sum(x)/length(x) at the 
end is that on a long vector sum(x) could overflow when mean(x) shouldn't.

So why not take the ALTREP into account?  I suspect it's just too much 
trouble for a rare case.

Duncan Murdoch


From Thom@@@SOEIRO @end|ng |rom @p-hm@|r  Thu Sep  2 13:09:35 2021
From: Thom@@@SOEIRO @end|ng |rom @p-hm@|r (SOEIRO Thomas)
Date: Thu, 2 Sep 2021 11:09:35 +0000
Subject: [Rd] sep hard coded in write.ftable
In-Reply-To: <24880.39299.992900.911002@stat.math.ethz.ch>
References: <1a597120ad27455e9249bd6577ea39b2@SCWPR-EXDAG1-6A.aphm.ap-hm.fr>
 <24880.39299.992900.911002@stat.math.ethz.ch>
Message-ID: <3883f6fe98d2418ca6bdf11abc93ce2d@SCWPR-EXDAG1-6A.aphm.ap-hm.fr>

Dear Martin,

Thank you very much for your prompt feedback!

Best regards,

Thomas

-----Message d'origine-----
De?: Martin Maechler [mailto:maechler at stat.math.ethz.ch] 
Envoy??: jeudi 2 septembre 2021 11:30
??: SOEIRO Thomas
Cc?: r-devel at r-project.org
Objet?: Re: [Rd] sep hard coded in write.ftable

EMAIL EXTERNE - TRAITER AVEC PR?CAUTION LIENS ET FICHIERS

>>>>> SOEIRO Thomas
>>>>>     on Wed, 1 Sep 2021 15:01:43 +0000 writes:

    > Dear all,

    > (This is a follow up of a previous suggestion for ftable that was added in R 4.1.0: https://urldefense.com/v3/__https://stat.ethz.ch/pipermail/r-devel/2020-May/079451.html__;!!JQ5agg!KmMY870t4h88LdWZEtwjGSopF57R5zxrL05DHa6nECGqI5_nFYUsC3OJoOzD0LQYZLOR$ )

    > The sep argument is hard coded in write.ftable:

    > write.ftable <- function(x, file = "", quote = TRUE, append = FALSE,
    > digits = getOption("digits"), ...)
    > {
    > r <- format.ftable(x, quote = quote, digits = digits, ...)
    > cat(t(r), file = file, append = append,
    > sep = c(rep(" ", ncol(r) - 1), "\n"))
    > invisible(x)
    > }

    > A minor change would allow users to modify it:

    > write.ftable2 <- function(x, file = "", quote = TRUE, append = FALSE,
    > digits = getOption("digits"), sep = " ", ...)
    > {
    > r <- stats:::format.ftable(x, quote = quote, digits = digits, ...)
    > cat(t(r), file = file, append = append,
    > sep = c(rep(sep, ncol(r) - 1), "\n"))
    > invisible(x)
    > }

I agree this sounds reasonable, and am currently running 'make check-devel' on sources modified accordingly ..

Martin


    > This would allow to avoid a previous call to format.ftable (although write.ftable is significantly slower than write.table):

    > ftable(formula = wool + tension ~ breaks, data = warpbreaks) |>
    > format(quote = FALSE) |>
    > write.table(sep = ";", row.names = FALSE, col.names = FALSE)

    > ftable(formula = wool + tension ~ breaks, data = warpbreaks) |>
    > write.ftable2(sep = ";")

    > Best regards,
    > Thomas

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-devel__;!!JQ5agg!KmMY870t4h88LdWZEtwjGSopF57R5zxrL05DHa6nECGqI5_nFYUsC3OJoOzD0M93CBRa$

From Thom@@@SOEIRO @end|ng |rom @p-hm@|r  Thu Sep  2 13:24:03 2021
From: Thom@@@SOEIRO @end|ng |rom @p-hm@|r (SOEIRO Thomas)
Date: Thu, 2 Sep 2021 11:24:03 +0000
Subject: [Rd] sep hard coded in write.ftable
References: <1a597120ad27455e9249bd6577ea39b2@SCWPR-EXDAG1-6A.aphm.ap-hm.fr>
 <24880.39299.992900.911002@stat.math.ethz.ch> 
Message-ID: <cd8b1ed8f75b47fb9d46872deb1e7a25@SCWPR-EXDAG1-6A.aphm.ap-hm.fr>

There is a small typo in the NEWS file: write.table -> write.ftable

-----Message d'origine-----
De?: SOEIRO Thomas 
Envoy??: jeudi 2 septembre 2021 13:10
??: 'Martin Maechler'
Cc?: r-devel at r-project.org
Objet?: RE: [Rd] sep hard coded in write.ftable

Dear Martin,

Thank you very much for your prompt feedback!

Best regards,

Thomas

-----Message d'origine-----
De?: Martin Maechler [mailto:maechler at stat.math.ethz.ch] 
Envoy??: jeudi 2 septembre 2021 11:30
??: SOEIRO Thomas
Cc?: r-devel at r-project.org
Objet?: Re: [Rd] sep hard coded in write.ftable

EMAIL EXTERNE - TRAITER AVEC PR?CAUTION LIENS ET FICHIERS

>>>>> SOEIRO Thomas
>>>>>     on Wed, 1 Sep 2021 15:01:43 +0000 writes:

    > Dear all,

    > (This is a follow up of a previous suggestion for ftable that was added in R 4.1.0: https://urldefense.com/v3/__https://stat.ethz.ch/pipermail/r-devel/2020-May/079451.html__;!!JQ5agg!KmMY870t4h88LdWZEtwjGSopF57R5zxrL05DHa6nECGqI5_nFYUsC3OJoOzD0LQYZLOR$ )

    > The sep argument is hard coded in write.ftable:

    > write.ftable <- function(x, file = "", quote = TRUE, append = FALSE,
    > digits = getOption("digits"), ...)
    > {
    > r <- format.ftable(x, quote = quote, digits = digits, ...)
    > cat(t(r), file = file, append = append,
    > sep = c(rep(" ", ncol(r) - 1), "\n"))
    > invisible(x)
    > }

    > A minor change would allow users to modify it:

    > write.ftable2 <- function(x, file = "", quote = TRUE, append = FALSE,
    > digits = getOption("digits"), sep = " ", ...)
    > {
    > r <- stats:::format.ftable(x, quote = quote, digits = digits, ...)
    > cat(t(r), file = file, append = append,
    > sep = c(rep(sep, ncol(r) - 1), "\n"))
    > invisible(x)
    > }

I agree this sounds reasonable, and am currently running 'make check-devel' on sources modified accordingly ..

Martin


    > This would allow to avoid a previous call to format.ftable (although write.ftable is significantly slower than write.table):

    > ftable(formula = wool + tension ~ breaks, data = warpbreaks) |>
    > format(quote = FALSE) |>
    > write.table(sep = ";", row.names = FALSE, col.names = FALSE)

    > ftable(formula = wool + tension ~ breaks, data = warpbreaks) |>
    > write.ftable2(sep = ";")

    > Best regards,
    > Thomas

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-devel__;!!JQ5agg!KmMY870t4h88LdWZEtwjGSopF57R5zxrL05DHa6nECGqI5_nFYUsC3OJoOzD0M93CBRa$

From Andre@G||||bert @end|ng |rom chu-rouen@|r  Thu Sep  2 21:54:18 2021
From: Andre@G||||bert @end|ng |rom chu-rouen@|r (GILLIBERT, Andre)
Date: Thu, 2 Sep 2021 19:54:18 +0000
Subject: [Rd] sum() and mean() for (ALTREP) integer sequences
In-Reply-To: <159209eaff1e4ba99bc467eed45d336f@UM-MAIL3214.unimaas.nl>
References: <159209eaff1e4ba99bc467eed45d336f@UM-MAIL3214.unimaas.nl>
Message-ID: <5f9a70cd96804175a8bbd3d4e92757e9@chu-rouen.fr>


Hello,


Please, find a long response below.


== difference between mean(x) and sum(x)/length(x) ==


At the core, mean(x) and sum(x)/length(x) works very differently for real numbers.

Mean is more accurate when applied to a vector with a small variance but a very high mean, especially on platforms without extended precision numbers (i.e. long double is 64 bits rather than 80 bits).


On a Windows 10 computer (with 80 bits long double):

k=1e6
base=2^51
realmean = mean(1:k)
sqa=(base+1):(base+k) # with ALTREP
sq=(base+1):(base+k)+0.0 # without ALTREP
mean(sq) - base - realmean  # correctly returns zero
sum(sq)/k - base - realmean # incorrectly returns -0.5
sum(sqa)/k - base - realmean # correctly returns zero

On a GNU/Linux x86_64 computer with extended precision floating point disabled, the difference is worse:
mean(sq) - base - realmean  # correctly returns zero
sum(sq)/k - base - realmean # incorrectly returns -1180
sum(sqa)/k - base - realmean # correctly returns zero

Therefore (without ALTREP) sum can be inaccurate, due to floating point rounding errors.

The good accuracy of mean() is due to a two-passes algorithm of the real_mean() function in src/main/summary.c.

The algorithm can be summarized by the following equivalent R code:
badmean=function(v) {sum(v)/length(v)}
goodmean=function(v) {center = badmean(v); center + badmean(v - center)}
goodmean(sq) - base - realmean # correctly returns zero


== should mean() call ALTINTEGER_SUM ? ==
As you noticed in the examples above, sum() is much more accurate with ALTREPs than with the naive algorithm, because there are no cumulative rounding errors.

Moreover, if we focus on INTSXP, the maximum possible value is lower : INT_MAX = 2^31-1

The sum of a large sequence (e.g. 1:(2^31-1)) can still overflow the exact integer range (0 to 2^53) of an FP64, and the division does not always round back to the correct value.

bad = 1:189812531L
mean(bad) - sum(bad)/length(bad) # returns -1.5e-08 on a platform with FP80
mean(bad) == 94906266 # correct value (the actual result is an integer)

The implementation of mean() on INTSXP do not use the two-passes trick, but relies on a LDOUBLE (typically FP80 on the x86 platform) that is large enough to avoid rounding bugs even with huge integer sequences.

Unfortunately the ALTINTEGER_SUM interface returns at best a FP64, and so, would not return the FP64 closest to the actual mean for some sequences.

Adding a MEAN function to the ALTREP interface could solve the problem.


== can mean performance be improved easily ? ==


The mean() implementation for integers, supports ALTREPs with poor iteration performances, using the slow INTEGER_ELT() macro.

Moreover, it converts each integer to LDOUBLE, which is slow.


It can be improved using ITERATE_BY_REGION0 and using a 64 bits integer (if available) that cannot overflow on small batches (size = 512).


# before patching (on Ubuntu x86_64 Silvermont Celeron J1900)
x = 1:1e8
y = 1:1e8+0L
system.time(mean(x)) # user 1.33 second
system.time(mean(y)) # user 0.32 second

# after patching (on Ubuntu x86_64 Silvermont Celeron J1900)
# after patching (on Ubuntu x86_64 Silvermont Celeron J1900)
x = 1:1e8
y = 1:1e8+0L
system.time(mean(x)) # user 0.29 second # more than x4 faster
system.time(mean(y)) # user 0.18 second # x 1.7 faster !

(patch attached to this message)

The patch is not optimal. It should ideally use isum(), and risum() but these functions are a mess, needing refactoring. For instance, they take a 'call' argument and may display a warning message related to the sum() function.

--
Sincerely
Andre GILLIBERT
________________________________
De : R-devel <r-devel-bounces at r-project.org> de la part de Viechtbauer, Wolfgang (SP) <wolfgang.viechtbauer at maastrichtuniversity.nl>
Envoy? : jeudi 2 septembre 2021 12:55:03
? : r-devel at r-project.org
Objet : [Rd] sum() and mean() for (ALTREP) integer sequences

ATTENTION: Cet e-mail provient d?une adresse mail ext?rieure au CHU de Rouen. Ne cliquez pas sur les liens ou n'ouvrez pas les pi?ces jointes ? moins de conna?tre l'exp?diteur et de savoir que le contenu est s?r. En cas de doute, transf?rer le mail ? ? DSI, S?curit? ? pour analyse. Merci de votre vigilance


Hi all,

I am trying to understand the performance of functions applied to integer sequences. Consider the following:

### begin example ###

library(lobstr)
library(microbenchmark)

x <- sample(1e6)
obj_size(x)
# 4,000,048 B

y <- 1:1e6
obj_size(y)
# 680 B

# So we can see that 'y' uses ALTREP. These are, as expected, the same:

sum(x)
# [1] 500000500000
sum(y)
# [1] 500000500000

# For 'x', we have to go through the trouble of actually summing up 1e6 integers.
# For 'y', knowing its form, we really just need to do:

1e6*(1e6+1)/2
# [1] 500000500000

# which should be a whole lot faster. And indeed, it is:

microbenchmark(sum(x),sum(y))

# Unit: nanoseconds
#    expr    min       lq      mean   median       uq    max neval cld
#  sum(x) 533452 595204.5 634266.90 613102.5 638271.5 978519   100   b
#  sum(y)    183    245.5    446.09    338.5    447.0   3233   100  a

# Now what about mean()?

mean(x)
# [1] 500000.5
mean(y)
# [1] 500000.5

# which is the same as

(1e6+1)/2
# [1] 500000.5

# But this surprised me:

microbenchmark(mean(x),mean(y))

# Unit: microseconds
#     expr      min        lq     mean   median       uq      max neval cld
#  mean(x)  935.389  943.4795 1021.423  954.689  985.122 2065.974   100  a
#  mean(y) 3500.262 3581.9530 3814.664 3637.984 3734.598 5866.768   100   b

### end example ###

So why is mean() on an ALTREP sequence slower when sum() is faster?

And more generally, when using sum() on an ALTREP integer sequence, does R actually use something like n*(n+1)/2 (or generalized to sequences a:b -- (a+b)*(b-a+1)/2) for computing the sum? If so, why not (it seems) for mean()?

Best,
Wolfgang

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Fri Sep  3 14:49:27 2021
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (SP))
Date: Fri, 3 Sep 2021 12:49:27 +0000
Subject: [Rd] sum() and mean() for (ALTREP) integer sequences
In-Reply-To: <7189aade-9a94-ceb0-c9a9-1106c7592a2e@gmail.com>
References: <159209eaff1e4ba99bc467eed45d336f@UM-MAIL3214.unimaas.nl>
 <7189aade-9a94-ceb0-c9a9-1106c7592a2e@gmail.com>
Message-ID: <77d3f0b36b4c41cb92fe0415a891c1dd@UM-MAIL3214.unimaas.nl>

>> Hi all,
>>
>> I am trying to understand the performance of functions applied to integer
>sequences. Consider the following:
>>
>> ### begin example ###
>>
>> library(lobstr)
>> library(microbenchmark)
>>
>> x <- sample(1e6)
>> obj_size(x)
>> # 4,000,048 B
>>
>> y <- 1:1e6
>> obj_size(y)
>> # 680 B
>>
>> # So we can see that 'y' uses ALTREP. These are, as expected, the same:
>>
>> sum(x)
>> # [1] 500000500000
>> sum(y)
>> # [1] 500000500000
>>
>> # For 'x', we have to go through the trouble of actually summing up 1e6
>integers.
>> # For 'y', knowing its form, we really just need to do:
>>
>> 1e6*(1e6+1)/2
>> # [1] 500000500000
>>
>> # which should be a whole lot faster. And indeed, it is:
>>
>> microbenchmark(sum(x),sum(y))
>>
>> # Unit: nanoseconds
>> #    expr    min       lq      mean   median       uq    max neval cld
>> #  sum(x) 533452 595204.5 634266.90 613102.5 638271.5 978519   100   b
>> #  sum(y)    183    245.5    446.09    338.5    447.0   3233   100  a
>>
>> # Now what about mean()?
>>
>> mean(x)
>> # [1] 500000.5
>> mean(y)
>> # [1] 500000.5
>>
>> # which is the same as
>>
>> (1e6+1)/2
>> # [1] 500000.5
>>
>> # But this surprised me:
>>
>> microbenchmark(mean(x),mean(y))
>>
>> # Unit: microseconds
>> #     expr      min        lq     mean   median       uq      max neval cld
>> #  mean(x)  935.389  943.4795 1021.423  954.689  985.122 2065.974   100  a
>> #  mean(y) 3500.262 3581.9530 3814.664 3637.984 3734.598 5866.768   100   b
>>
>> ### end example ###
>>
>> So why is mean() on an ALTREP sequence slower when sum() is faster?
>>
>> And more generally, when using sum() on an ALTREP integer sequence, does R
>actually use something like n*(n+1)/2 (or generalized to sequences a:b --
>(a+b)*(b-a+1)/2) for computing the sum? If so, why not (it seems) for mean()?
>
>The mean.default function looks like this:
>
>function (x, trim = 0, na.rm = FALSE, ...)
>{
>     if (!is.numeric(x) && !is.complex(x) && !is.logical(x)) {
>         warning("argument is not numeric or logical: returning NA")
>         return(NA_real_)
>     }
>     if (na.rm)
>         x <- x[!is.na(x)]
>     if (!is.numeric(trim) || length(trim) != 1L)
>         stop("'trim' must be numeric of length one")
>     n <- length(x)
>     if (trim > 0 && n) {
>         if (is.complex(x))
>             stop("trimmed means are not defined for complex data")
>         if (anyNA(x))
>             return(NA_real_)
>         if (trim >= 0.5)
>             return(stats::median(x, na.rm = FALSE))
>         lo <- floor(n * trim) + 1
>         hi <- n + 1 - lo
>         x <- sort.int(x, partial = unique(c(lo, hi)))[lo:hi]
>     }
>     .Internal(mean(x))
>}
>
>So it does fixups for trimming and NA removal, then calls an internal
>function.  The internal function is the first part of do_summary, here:
>
>https://github.com/wch/r-
>source/blob/f9c955fc6699a1f0482e4281ba658215c0e0b949/src/main/summary.c#L541-L556
>
>It is using separate functions for the mean by type.  The real_mean
>function here:
>
>https://github.com/wch/r-
>source/blob/f9c955fc6699a1f0482e4281ba658215c0e0b949/src/main/summary.c#L476-L515
>
>makes a big effort to avoid overflows.
>
>So I suspect the reason mean.default doesn't use sum(x)/length(x) at the
>end is that on a long vector sum(x) could overflow when mean(x) shouldn't.
>
>So why not take the ALTREP into account?  I suspect it's just too much
>trouble for a rare case.
>
>Duncan Murdoch

Hi Duncan,

Thanks for pointing me to the appropriate places in the C code. And ok, makes sense.

Best,
Wolfgang

From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Fri Sep  3 14:54:50 2021
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (SP))
Date: Fri, 3 Sep 2021 12:54:50 +0000
Subject: [Rd] sum() and mean() for (ALTREP) integer sequences
In-Reply-To: <5f9a70cd96804175a8bbd3d4e92757e9@chu-rouen.fr>
References: <159209eaff1e4ba99bc467eed45d336f@UM-MAIL3214.unimaas.nl>
 <5f9a70cd96804175a8bbd3d4e92757e9@chu-rouen.fr>
Message-ID: <a3bbb35090df43ed8d672ea5eea2db01@UM-MAIL3214.unimaas.nl>

Wow, thanks for this extensive reply, Andre. As Duncan mentioned, it's probably not worth the bother for such a rare case. And my curiosity as to why the timing difference was happening has been more than satisfied.

Best,
Wolfgang

>-----Original Message-----
>From: GILLIBERT, Andre [mailto:Andre.Gillibert at chu-rouen.fr]
>Sent: Thursday, 02 September, 2021 21:54
>To: Viechtbauer, Wolfgang (SP); r-devel at r-project.org
>Subject: RE: sum() and mean() for (ALTREP) integer sequences
>
>Hello,
>
>Please, find a long response below.
>
>== difference between mean(x) and sum(x)/length(x) ==
>
>At the core, mean(x) and sum(x)/length(x) works very differently for real numbers.
>Mean is more accurate when applied to a vector with a small variance but a very
>high mean, especially on platforms without extended precision numbers (i.e. long
>double is 64 bits rather than 80 bits).
>
>On a Windows 10 computer (with 80 bits long double):
>k=1e6
>base=2^51
>realmean = mean(1:k)
>sqa=(base+1):(base+k) # with ALTREP
>sq=(base+1):(base+k)+0.0 # without ALTREP
>mean(sq) - base - realmean? # correctly returns zero
>sum(sq)/k - base - realmean # incorrectly returns -0.5
>sum(sqa)/k - base - realmean # correctly returns zero
>
>On a GNU/Linux x86_64 computer with extended precision floating point disabled,
>the difference is worse:
>mean(sq) - base - realmean? # correctly returns zero
>sum(sq)/k - base - realmean # incorrectly returns -1180
>sum(sqa)/k - base - realmean # correctly returns zero
>
>Therefore (without ALTREP) sum can be inaccurate, due to floating point rounding
>errors.
>
>The good accuracy of mean() is due to a two-passes algorithm of the real_mean()
>function in src/main/summary.c.
>
>The algorithm can be summarized by the following equivalent R code:
>badmean=function(v) {sum(v)/length(v)}
>goodmean=function(v) {center = badmean(v); center + badmean(v - center)}
>goodmean(sq) - base - realmean # correctly returns zero
>
>== should mean() call ALTINTEGER_SUM ? ==
>As you noticed in the examples above, sum() is much more accurate with ALTREPs
>than with the naive algorithm, because there are no cumulative rounding errors.
>
>Moreover, if we focus on INTSXP, the maximum possible value is lower : INT_MAX =
>2^31-1
>The sum of a large sequence (e.g. 1:(2^31-1)) can still overflow the exact integer
>range (0 to 2^53) of an FP64, and the division does not always round back to the
>correct value.
>
>bad = 1:189812531L
>mean(bad) - sum(bad)/length(bad) # returns -1.5e-08 on a platform with FP80
>mean(bad) == 94906266 # correct value (the actual result is an integer)
>
>The implementation of mean() on INTSXP do not use the two-passes trick, but relies
>on a LDOUBLE (typically FP80 on the x86 platform) that is large enough to avoid
>rounding bugs even with huge integer sequences.
>
>Unfortunately the ALTINTEGER_SUM interface returns at best a FP64, and so, would
>not return the FP64 closest to the actual mean for some sequences.
>
>Adding a MEAN function to the ALTREP interface could solve the problem.
>
>== can mean performance be improved easily ? ==
>
>The mean() implementation for integers, supports ALTREPs?with poor iteration
>performances, using the slow INTEGER_ELT() macro.
>Moreover, it converts each integer to LDOUBLE, which is slow.
>
>It can be improved using ITERATE_BY_REGION0 and using a 64 bits integer (if
>available) that cannot overflow on small batches (size = 512).
>
># before patching (on Ubuntu x86_64 Silvermont Celeron J1900)
>x = 1:1e8
>y = 1:1e8+0L
>system.time(mean(x)) # user 1.33 second
>system.time(mean(y)) # user 0.32 second
>
># after patching (on Ubuntu x86_64 Silvermont Celeron J1900)
># after patching (on Ubuntu x86_64 Silvermont Celeron J1900)
>x = 1:1e8
>y = 1:1e8+0L
>system.time(mean(x)) # user 0.29 second # more than x4 faster
>system.time(mean(y)) # user 0.18 second # x 1.7 faster !
>
>(patch attached to this message)
>
>The patch is not optimal. It should ideally use isum(), and risum() but these
>functions are a mess, needing refactoring. For instance, they take a 'call'
>argument and may display a warning message related to the sum() function.
>
>--
>Sincerely
>Andre GILLIBERT
>________________________________________
>De : R-devel <r-devel-bounces at r-project.org> de la part de Viechtbauer, Wolfgang
>(SP) <wolfgang.viechtbauer at maastrichtuniversity.nl>
>Envoy? : jeudi 2 septembre 2021 12:55:03
>? : r-devel at r-project.org
>Objet : [Rd] sum() and mean() for (ALTREP) integer sequences
>
>Hi all,
>
>I am trying to understand the performance of functions applied to integer
>sequences. Consider the following:
>
>### begin example ###
>
>library(lobstr)
>library(microbenchmark)
>
>x <- sample(1e6)
>obj_size(x)
># 4,000,048 B
>
>y <- 1:1e6
>obj_size(y)
># 680 B
>
># So we can see that 'y' uses ALTREP. These are, as expected, the same:
>
>sum(x)
># [1] 500000500000
>sum(y)
># [1] 500000500000
>
># For 'x', we have to go through the trouble of actually summing up 1e6 integers.
># For 'y', knowing its form, we really just need to do:
>
>1e6*(1e6+1)/2
># [1] 500000500000
>
># which should be a whole lot faster. And indeed, it is:
>
>microbenchmark(sum(x),sum(y))
>
># Unit: nanoseconds
>#??? expr??? min?????? lq????? mean?? median?????? uq??? max neval cld
>#? sum(x) 533452 595204.5 634266.90 613102.5 638271.5 978519?? 100?? b
>#? sum(y)??? 183??? 245.5??? 446.09??? 338.5??? 447.0?? 3233?? 100? a
>
># Now what about mean()?
>
>mean(x)
># [1] 500000.5
>mean(y)
># [1] 500000.5
>
># which is the same as
>
>(1e6+1)/2
># [1] 500000.5
>
># But this surprised me:
>
>microbenchmark(mean(x),mean(y))
>
># Unit: microseconds
>#???? expr????? min??????? lq???? mean?? median?????? uq????? max neval cld
>#? mean(x)? 935.389? 943.4795 1021.423? 954.689? 985.122 2065.974?? 100? a
>#? mean(y) 3500.262 3581.9530 3814.664 3637.984 3734.598 5866.768?? 100?? b
>
>### end example ###
>
>So why is mean() on an ALTREP sequence slower when sum() is faster?
>
>And more generally, when using sum() on an ALTREP integer sequence, does R
>actually use something like n*(n+1)/2 (or generalized to sequences a:b --
>(a+b)*(b-a+1)/2) for computing the sum? If so, why not (it seems) for mean()?
>
>Best,
>Wolfgang


From ch|r|com @end|ng |rom goog|e@com  Tue Sep  7 19:44:03 2021
From: ch|r|com @end|ng |rom goog|e@com (Michael Chirico)
Date: Tue, 7 Sep 2021 10:44:03 -0700
Subject: [Rd] Should seq.Date() return double storage?
Message-ID: <CAD7Bkx8G-74PxQpchi2+ejTEKzOVaPih2o13pmbhmRRo9FTCLg@mail.gmail.com>

today <- Sys.Date()
typeof(today)
# [1] "double"
typeof(seq(today, by=1, length.out=2))
# [1] "integer"

Clearly minor as it doesn't seem to have come up before (e.g. coercion
to numeric will happen automatically whenever fractional dates are
needed); I only noticed because of a test using identical failing:

identical(
  seq(today, by=1, length.out=10),
  today + 0:9
)
# [1] FALSE

It's easy in this case to fix the test using coercion, but this could
(and did in practice) come up at deeper levels of nesting that become
more onerous to handle. And using all.equal() comes with its own
tradeoffs.

The fix would be easy enough -- at a glance there are two usages of
.Date(seq.int(...)) in seq.Date() that could be replaced by
.Date(as.numeric(seq.int(...))).

Mike C


From Kurt@Horn|k @end|ng |rom wu@@c@@t  Wed Sep  8 08:18:42 2021
From: Kurt@Horn|k @end|ng |rom wu@@c@@t (Kurt Hornik)
Date: Wed, 8 Sep 2021 08:18:42 +0200
Subject: [Rd] Should seq.Date() return double storage?
In-Reply-To: <CAD7Bkx8G-74PxQpchi2+ejTEKzOVaPih2o13pmbhmRRo9FTCLg@mail.gmail.com>
References: <CAD7Bkx8G-74PxQpchi2+ejTEKzOVaPih2o13pmbhmRRo9FTCLg@mail.gmail.com>
Message-ID: <24888.21954.735124.993759@hornik.net>

>>>>> Michael Chirico via R-devel writes:

> today <- Sys.Date()
> typeof(today)
> # [1] "double"
> typeof(seq(today, by=1, length.out=2))
> # [1] "integer"

> Clearly minor as it doesn't seem to have come up before (e.g. coercion
> to numeric will happen automatically whenever fractional dates are
> needed); I only noticed because of a test using identical failing:

> identical(
>   seq(today, by=1, length.out=10),
>   today + 0:9
> )
> # [1] FALSE

> It's easy in this case to fix the test using coercion, but this could
> (and did in practice) come up at deeper levels of nesting that become
> more onerous to handle. And using all.equal() comes with its own
> tradeoffs.

> The fix would be easy enough -- at a glance there are two usages of
> .Date(seq.int(...)) in seq.Date() that could be replaced by
> .Date(as.numeric(seq.int(...))).

Thanks.  Can you pls provide a patch for these?

Best
-k

> Mike C

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From yut@n|@|n| @end|ng |rom gm@||@com  Wed Sep  8 14:08:40 2021
From: yut@n|@|n| @end|ng |rom gm@||@com (Hiroaki Yutani)
Date: Wed, 8 Sep 2021 21:08:40 +0900
Subject: [Rd] Detect UCRT-built R from within R sessions (and in
 configure.win)
Message-ID: <CALyqOb8r7ajAumf5V0+YJk83X091NS2eRCs-cu=X6zO+09z0Rg@mail.gmail.com>

Hi,

Are there any proper ways to know whether the session is running on
the R that is built with the UCRT toolchain or not? Checking if the
encoding is UTF-8 might do the trick, but I'm not sure if it's always
reliable.

Also, I'd like to know if there's any mechanism to detect the UCRT in
configure.win. I know there are Makevars.ucrt and Makefile.ucrt, but
one might want to do some feature test that is specific to the UCRT
toolchain.

Best,
Hiroaki Yutani


From tom@@@k@||ber@ @end|ng |rom gm@||@com  Wed Sep  8 17:48:20 2021
From: tom@@@k@||ber@ @end|ng |rom gm@||@com (Tomas Kalibera)
Date: Wed, 8 Sep 2021 17:48:20 +0200
Subject: [Rd] Detect UCRT-built R from within R sessions (and in
 configure.win)
In-Reply-To: <CALyqOb8r7ajAumf5V0+YJk83X091NS2eRCs-cu=X6zO+09z0Rg@mail.gmail.com>
References: <CALyqOb8r7ajAumf5V0+YJk83X091NS2eRCs-cu=X6zO+09z0Rg@mail.gmail.com>
Message-ID: <a219a307-5200-a13e-b4d9-a1e7a646e137@gmail.com>


On 9/8/21 2:08 PM, Hiroaki Yutani wrote:
> Hi,
>
> Are there any proper ways to know whether the session is running on
> the R that is built with the UCRT toolchain or not? Checking if the
> encoding is UTF-8 might do the trick, but I'm not sure if it's always
> reliable.

There in not such a mechanism, yet, but can be added, at least for 
diagnostics.

You are right that checking for UTF-8 encoding would not always be 
reliable. For example, the version of Windows may be too old to allow R 
use UTF-8 as native encoding (e.g. Windows server 2016), then R will use 
the native code page as it does today in the MSVCRT builds.

> Also, I'd like to know if there's any mechanism to detect the UCRT in
> configure.win. I know there are Makevars.ucrt and Makefile.ucrt, but
> one might want to do some feature test that is specific to the UCRT
> toolchain.

We could add support for configure.ucrt, which would take precedence 
over configure.win on the UCRT builds (like Makevars.ucrt takes 
precedence over Makevars.win). Would that work for you?

Best
Tomas

>
> Best,
> Hiroaki Yutani
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From yut@n|@|n| @end|ng |rom gm@||@com  Thu Sep  9 05:54:57 2021
From: yut@n|@|n| @end|ng |rom gm@||@com (Hiroaki Yutani)
Date: Thu, 9 Sep 2021 12:54:57 +0900
Subject: [Rd] Detect UCRT-built R from within R sessions (and in
 configure.win)
In-Reply-To: <a219a307-5200-a13e-b4d9-a1e7a646e137@gmail.com>
References: <CALyqOb8r7ajAumf5V0+YJk83X091NS2eRCs-cu=X6zO+09z0Rg@mail.gmail.com>
 <a219a307-5200-a13e-b4d9-a1e7a646e137@gmail.com>
Message-ID: <CALyqOb8yer26avLG8wmGxpFQgEeYtxaPGOnixpYTssAJiOLfDA@mail.gmail.com>

Thank you for the prompt reply.

> There in not such a mechanism, yet, but can be added, at least for
> diagnostics.

For example, can R.version somehow contain the information?

> We could add support for configure.ucrt, which would take precedence
> over configure.win on the UCRT builds (like Makevars.ucrt takes
> precedence over Makevars.win). Would that work for you?

Yes, configure.ucrt should work for me. There might be someone who prefers
to switch by some envvar rather than creating another file, but I don't
have a strong opinion here.

Best,
Hiroaki Yutani

2021?9?9?(?) 0:48 Tomas Kalibera <tomas.kalibera at gmail.com>:

>
> On 9/8/21 2:08 PM, Hiroaki Yutani wrote:
> > Hi,
> >
> > Are there any proper ways to know whether the session is running on
> > the R that is built with the UCRT toolchain or not? Checking if the
> > encoding is UTF-8 might do the trick, but I'm not sure if it's always
> > reliable.
>
> There in not such a mechanism, yet, but can be added, at least for
> diagnostics.
>
> You are right that checking for UTF-8 encoding would not always be
> reliable. For example, the version of Windows may be too old to allow R
> use UTF-8 as native encoding (e.g. Windows server 2016), then R will use
> the native code page as it does today in the MSVCRT builds.
>
> > Also, I'd like to know if there's any mechanism to detect the UCRT in
> > configure.win. I know there are Makevars.ucrt and Makefile.ucrt, but
> > one might want to do some feature test that is specific to the UCRT
> > toolchain.
>
> We could add support for configure.ucrt, which would take precedence
> over configure.win on the UCRT builds (like Makevars.ucrt takes
> precedence over Makevars.win). Would that work for you?
>
> Best
> Tomas
>
> >
> > Best,
> > Hiroaki Yutani
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From @tevem@rt|n041 @end|ng |rom gm@||@com  Thu Sep  9 06:05:26 2021
From: @tevem@rt|n041 @end|ng |rom gm@||@com (Steve Martin)
Date: Thu, 9 Sep 2021 00:05:26 -0400
Subject: [Rd] Should Position() use match.fun()?
Message-ID: <CAP=dwz9FY4j77S0Qm+grtX+S=Hjud6UF5+csewX6J4mG2HUHnQ@mail.gmail.com>

Hello,

All of the funprog functions except Position() use match.fun() early
in the body of the function. (Filter() seems to rely on lapply() for
this, but the effect is the same.) In most cases this isn't a problem,
but I can't see why Position() shouldn't look something like

Position2 <- function(f, x, right = FALSE, nomatch = NA_integer_) {
    f <- match.fun(f) # the only difference from Position()
    ind <- if (right) rev(seq_along(x)) else seq_along(x)
    for (i in ind) {
        if (f(x[[i]])) return(i)
    }
    nomatch
}

This would make it consistent with the other funprog functions, and
would mean that Find() and Position() give the same result when
expected

> equals3 <- function(x) x == 3
> Position("equals3", 1:5)
Error in f(x[[i]]) : could not find function "f"
> Position2("equals3", 1:5)
[1] 3
> Find("equals3", 1:5)
[1] 3

Thanks,
Steve


From Kurt@Horn|k @end|ng |rom wu@@c@@t  Thu Sep  9 09:23:24 2021
From: Kurt@Horn|k @end|ng |rom wu@@c@@t (Kurt Hornik)
Date: Thu, 9 Sep 2021 09:23:24 +0200
Subject: [Rd] Should Position() use match.fun()?
In-Reply-To: <CAP=dwz9FY4j77S0Qm+grtX+S=Hjud6UF5+csewX6J4mG2HUHnQ@mail.gmail.com>
References: <CAP=dwz9FY4j77S0Qm+grtX+S=Hjud6UF5+csewX6J4mG2HUHnQ@mail.gmail.com>
Message-ID: <24889.46700.99366.498401@hornik.net>

>>>>> Steve Martin writes:

> Hello,
> All of the funprog functions except Position() use match.fun() early
> in the body of the function. (Filter() seems to rely on lapply() for
> this, but the effect is the same.) 

Right. 

> In most cases this isn't a problem, but I can't see why Position()
> shouldn't look something like

> Position2 <- function(f, x, right = FALSE, nomatch = NA_integer_) {
>     f <- match.fun(f) # the only difference from Position()
>     ind <- if (right) rev(seq_along(x)) else seq_along(x)
>     for (i in ind) {
>         if (f(x[[i]])) return(i)
>     }
>     nomatch
> }

> This would make it consistent with the other funprog functions, and
> would mean that Find() and Position() give the same result when
> expected

Indeed.  I'll look into adding the match.fun ...

Best
-k

>> equals3 <- function(x) x == 3
>> Position("equals3", 1:5)
> Error in f(x[[i]]) : could not find function "f"
>> Position2("equals3", 1:5)
> [1] 3
>> Find("equals3", 1:5)
> [1] 3

> Thanks,
> Steve

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Kurt@Horn|k @end|ng |rom wu@@c@@t  Thu Sep  9 15:24:02 2021
From: Kurt@Horn|k @end|ng |rom wu@@c@@t (Kurt Hornik)
Date: Thu, 9 Sep 2021 15:24:02 +0200
Subject: [Rd] Should Position() use match.fun()?
In-Reply-To: <24889.46700.99366.498401@hornik.net>
References: <CAP=dwz9FY4j77S0Qm+grtX+S=Hjud6UF5+csewX6J4mG2HUHnQ@mail.gmail.com>
 <24889.46700.99366.498401@hornik.net>
Message-ID: <24890.2802.938653.54969@hornik.net>

>>>>> Kurt Hornik writes:

>>>>> Steve Martin writes:
>> Hello,
>> All of the funprog functions except Position() use match.fun() early
>> in the body of the function. (Filter() seems to rely on lapply() for
>> this, but the effect is the same.) 

> Right. 

>> In most cases this isn't a problem, but I can't see why Position()
>> shouldn't look something like

>> Position2 <- function(f, x, right = FALSE, nomatch = NA_integer_) {
>> f <- match.fun(f) # the only difference from Position()
>> ind <- if (right) rev(seq_along(x)) else seq_along(x)
>> for (i in ind) {
>> if (f(x[[i]])) return(i)
>> }
>> nomatch
>> }

>> This would make it consistent with the other funprog functions, and
>> would mean that Find() and Position() give the same result when
>> expected

> Indeed.  I'll look into adding the match.fun ...

Changed now with c80873.

Best
-k

> Best
> -k

>>> equals3 <- function(x) x == 3
>>> Position("equals3", 1:5)
>> Error in f(x[[i]]) : could not find function "f"
>>> Position2("equals3", 1:5)
>> [1] 3
>>> Find("equals3", 1:5)
>> [1] 3

>> Thanks,
>> Steve

>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hp@ge@@on@g|thub @end|ng |rom gm@||@com  Fri Sep 10 02:54:06 2021
From: hp@ge@@on@g|thub @end|ng |rom gm@||@com (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Thu, 9 Sep 2021 17:54:06 -0700
Subject: [Rd] Unneeded if statements in RealFromComplex C code
Message-ID: <af8f0c90-b643-3151-82ba-4e3efccb1e1f@gmail.com>

Hi,

I just stumbled across these 2 lines in RealFromComplex (lines 208 & 209 
in src/main/coerce.c):

   double attribute_hidden

   RealFromComplex(Rcomplex x, int *warn)

   {

       if (ISNAN(x.r) || ISNAN(x.i))

           return NA_REAL;

       if (ISNAN(x.r)) return x.r;
               <- line 208
       if (ISNAN(x.i)) return NA_REAL;
           <- line 209
       if (x.i != 0)

           *warn |= WARN_IMAG;

       return x.r;

   }


They were added in 2015 (revision 69410).

They don't serve any purpose and might slow things down a little (unless 
compiler optimization is able to ignore them). In any case they should 
probably be removed.

Cheers,
H.

-- 
Herv? Pag?s

Bioconductor Core Team
hpages.on.github at gmail.com


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Fri Sep 10 11:24:09 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 10 Sep 2021 11:24:09 +0200
Subject: [Rd] Unneeded if statements in RealFromComplex C code
In-Reply-To: <af8f0c90-b643-3151-82ba-4e3efccb1e1f@gmail.com>
References: <af8f0c90-b643-3151-82ba-4e3efccb1e1f@gmail.com>
Message-ID: <24891.9273.43964.300205@stat.math.ethz.ch>

>>>>> Herv? Pag?s 
>>>>>     on Thu, 9 Sep 2021 17:54:06 -0700 writes:

    > Hi,

    > I just stumbled across these 2 lines in RealFromComplex (lines 208 & 209 
    > in src/main/coerce.c):

    > double attribute_hidden
    > RealFromComplex(Rcomplex x, int *warn)
    > {
    >   if (ISNAN(x.r) || ISNAN(x.i))
    >       return NA_REAL;
    >   if (ISNAN(x.r)) return x.r;        <- line 208
    >   if (ISNAN(x.i)) return NA_REAL;    <- line 209
    >   if (x.i != 0)
    >      *warn |= WARN_IMAG;
    >   return x.r;
    > }

    > They were added in 2015 (revision 69410).

by me.  "Of course" the intent at the time was to  *replace* the
previous 2 lines and return NA/NaN of the "exact same kind"....

but in the mean time, I have learned that trying to preserve
exact *kinds* of NaN / NA is typically not platform portable,
anyway because compiler/library optimizations and
implementations are pretty "free to do what they want" with these.

    > They don't serve any purpose and might slow things down a little (unless 
    > compiler optimization is able to ignore them). In any case they should 
    > probably be removed.

I've cleaned up now, indeed back compatibly, i.e., removing both
lines as you suggested.

Thank you, Herv?!

Martin


    > Cheers,
    > H.

    > -- 
    > Herv? Pag?s

    > Bioconductor Core Team
    > hpages.on.github at gmail.com


From hp@ge@@on@g|thub @end|ng |rom gm@||@com  Fri Sep 10 17:29:59 2021
From: hp@ge@@on@g|thub @end|ng |rom gm@||@com (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Fri, 10 Sep 2021 08:29:59 -0700
Subject: [Rd] Spurious warnings in coercion from double/complex/character to
 raw
Message-ID: <8b1874d6-b41b-8909-7ddb-2da0459618e2@gmail.com>

Hi,

The first warning below is unexpected and confusing:

   > as.raw(c(3e9, 5.1))
   [1] 00 05
   Warning messages:
   1: NAs introduced by coercion to integer range
   2: out-of-range values treated as 0 in coercion to raw

The reason we get it is that coercion from numeric to raw is currently 
implemented on top of coercion from numeric to int (file 
src/main/coerce.c, lines 700-710):

     case REALSXP:
         for (i = 0; i < n; i++) {
//          if ((i+1) % NINTERRUPT == 0) R_CheckUserInterrupt();
             tmp = IntegerFromReal(REAL_ELT(v, i), &warn);
             if(tmp == NA_INTEGER || tmp < 0 || tmp > 255) {
                 tmp = 0;
                 warn |= WARN_RAW;
             }
             pa[i] = (Rbyte) tmp;
         }
         break;

The first warning comes from the call to IntegerFromReal().

The following code avoids the spurious warning and is also simpler and 
slightly faster:

     case REALSXP:
         for (i = 0; i < n; i++) {
//          if ((i+1) % NINTERRUPT == 0) R_CheckUserInterrupt();
             double vi = REAL_ELT(v, i);
             if(ISNAN(vi) || (tmp = (int) vi) < 0 || tmp > 255) {
                 tmp = 0;
                 warn |= WARN_RAW;
             }
             pa[i] = (Rbyte) tmp;
         }
         break;

Coercion from complex to raw has the same problem:

   > as.raw(c(3e9+0i, 5.1))
   [1] 00 05
   Warning messages:
   1: NAs introduced by coercion to integer range
   2: out-of-range values treated as 0 in coercion to raw

Current implementation (file src/main/coerce.c, lines 711-721):

     case CPLXSXP:
         for (i = 0; i < n; i++) {
//          if ((i+1) % NINTERRUPT == 0) R_CheckUserInterrupt();
             tmp = IntegerFromComplex(COMPLEX_ELT(v, i), &warn);
             if(tmp == NA_INTEGER || tmp < 0 || tmp > 255) {
                 tmp = 0;
                 warn |= WARN_RAW;
             }
             pa[i] = (Rbyte) tmp;
         }
         break;

This implementation has the following additional problem when the 
supplied complex has a nonzero imaginary part:

   > as.raw(300+4i)
   [1] 00
   Warning messages:
   1: imaginary parts discarded in coercion
   2: out-of-range values treated as 0 in coercion to raw

   > as.raw(3e9+4i)
   [1] 00
   Warning messages:
   1: NAs introduced by coercion to integer range
   2: out-of-range values treated as 0 in coercion to raw

In one case we get a warning about the discarding of the imaginary part 
but not the other case, which is unexpected. We should see the exact 
same warning (or warnings) in both cases.

With the following fix we only get the warning about the discarding of 
the imaginary part if we are not in a "out-of-range values treated as 0 
in coercion to raw" situation:

     case CPLXSXP:
         for (i = 0; i < n; i++) {
//          if ((i+1) % NINTERRUPT == 0) R_CheckUserInterrupt();
             Rcomplex vi = COMPLEX_ELT(v, i);
             if(ISNAN(vi.r) || ISNAN(vi.i) || (tmp = (int) vi.r) < 0 || 
tmp > 255) {
                 tmp = 0;
                 warn |= WARN_RAW;
             } else {
                 if(vi.i != 0.0)
                     warn |= WARN_IMAG;
             }
             pa[i] = (Rbyte) tmp;
         }
         break;

Finally, coercion from character to raw has the same problem and its 
code can be fixed in a similar manner:

   > as.raw(c("3e9", 5.1))
   [1] 00 05
   Warning messages:
   1: NAs introduced by coercion to integer range
   2: out-of-range values treated as 0 in coercion to raw

Cheers,
H.


-- 
Herv? Pag?s

Bioconductor Core Team
hpages.on.github at gmail.com


From hp@ge@@on@g|thub @end|ng |rom gm@||@com  Fri Sep 10 17:48:01 2021
From: hp@ge@@on@g|thub @end|ng |rom gm@||@com (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Fri, 10 Sep 2021 08:48:01 -0700
Subject: [Rd] Unneeded if statements in RealFromComplex C code
In-Reply-To: <24891.9273.43964.300205@stat.math.ethz.ch>
References: <af8f0c90-b643-3151-82ba-4e3efccb1e1f@gmail.com>
 <24891.9273.43964.300205@stat.math.ethz.ch>
Message-ID: <08c59f31-555f-5ea0-cac2-868251f6990d@gmail.com>

Thanks Martin!

Best,
H.

On 10/09/2021 02:24, Martin Maechler wrote:
>>>>>> Herv? Pag?s
>>>>>>      on Thu, 9 Sep 2021 17:54:06 -0700 writes:
> 
>      > Hi,
> 
>      > I just stumbled across these 2 lines in RealFromComplex (lines 208 & 209
>      > in src/main/coerce.c):
> 
>      > double attribute_hidden
>      > RealFromComplex(Rcomplex x, int *warn)
>      > {
>      >   if (ISNAN(x.r) || ISNAN(x.i))
>      >       return NA_REAL;
>      >   if (ISNAN(x.r)) return x.r;        <- line 208
>      >   if (ISNAN(x.i)) return NA_REAL;    <- line 209
>      >   if (x.i != 0)
>      >      *warn |= WARN_IMAG;
>      >   return x.r;
>      > }
> 
>      > They were added in 2015 (revision 69410).
> 
> by me.  "Of course" the intent at the time was to  *replace* the
> previous 2 lines and return NA/NaN of the "exact same kind"....
> 
> but in the mean time, I have learned that trying to preserve
> exact *kinds* of NaN / NA is typically not platform portable,
> anyway because compiler/library optimizations and
> implementations are pretty "free to do what they want" with these.
> 
>      > They don't serve any purpose and might slow things down a little (unless
>      > compiler optimization is able to ignore them). In any case they should
>      > probably be removed.
> 
> I've cleaned up now, indeed back compatibly, i.e., removing both
> lines as you suggested.
> 
> Thank you, Herv?!
> 
> Martin
> 
> 
>      > Cheers,
>      > H.
> 
>      > --
>      > Herv? Pag?s
> 
>      > Bioconductor Core Team
>      > hpages.on.github at gmail.com
> 

-- 
Herv? Pag?s

Bioconductor Core Team
hpages.on.github at gmail.com


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Sep 10 18:12:02 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 10 Sep 2021 12:12:02 -0400
Subject: [Rd] 
 Spurious warnings in coercion from double/complex/character to raw
In-Reply-To: <8b1874d6-b41b-8909-7ddb-2da0459618e2@gmail.com>
References: <8b1874d6-b41b-8909-7ddb-2da0459618e2@gmail.com>
Message-ID: <2b1460bb-a8e8-42ee-6623-b07a5858b332@gmail.com>

On 10/09/2021 11:29 a.m., Herv? Pag?s wrote:
> Hi,
> 
> The first warning below is unexpected and confusing:
> 
>     > as.raw(c(3e9, 5.1))
>     [1] 00 05
>     Warning messages:
>     1: NAs introduced by coercion to integer range
>     2: out-of-range values treated as 0 in coercion to raw
> 
> The reason we get it is that coercion from numeric to raw is currently
> implemented on top of coercion from numeric to int (file
> src/main/coerce.c, lines 700-710):
> 
>       case REALSXP:
>           for (i = 0; i < n; i++) {
> //          if ((i+1) % NINTERRUPT == 0) R_CheckUserInterrupt();
>               tmp = IntegerFromReal(REAL_ELT(v, i), &warn);
>               if(tmp == NA_INTEGER || tmp < 0 || tmp > 255) {
>                   tmp = 0;
>                   warn |= WARN_RAW;
>               }
>               pa[i] = (Rbyte) tmp;
>           }
>           break;
> 
> The first warning comes from the call to IntegerFromReal().
> 
> The following code avoids the spurious warning and is also simpler and
> slightly faster:
> 
>       case REALSXP:
>           for (i = 0; i < n; i++) {
> //          if ((i+1) % NINTERRUPT == 0) R_CheckUserInterrupt();
>               double vi = REAL_ELT(v, i);
>               if(ISNAN(vi) || (tmp = (int) vi) < 0 || tmp > 255) {
>                   tmp = 0;
>                   warn |= WARN_RAW;
>               }
>               pa[i] = (Rbyte) tmp;
>           }
>           break;

Doesn't that give different results in case vi is so large that "(int) 
vi" overflows?  (I don't know what the C standard says, but some online 
references say that behaviour is implementation dependent.)

For example, if

   vi = 1.0 +  INT_MAX;

wouldn't "(int) vi" be equal to a small integer?

Duncan Murdoch


> 
> Coercion from complex to raw has the same problem:
> 
>     > as.raw(c(3e9+0i, 5.1))
>     [1] 00 05
>     Warning messages:
>     1: NAs introduced by coercion to integer range
>     2: out-of-range values treated as 0 in coercion to raw
> 
> Current implementation (file src/main/coerce.c, lines 711-721):
> 
>       case CPLXSXP:
>           for (i = 0; i < n; i++) {
> //          if ((i+1) % NINTERRUPT == 0) R_CheckUserInterrupt();
>               tmp = IntegerFromComplex(COMPLEX_ELT(v, i), &warn);
>               if(tmp == NA_INTEGER || tmp < 0 || tmp > 255) {
>                   tmp = 0;
>                   warn |= WARN_RAW;
>               }
>               pa[i] = (Rbyte) tmp;
>           }
>           break;
> 
> This implementation has the following additional problem when the
> supplied complex has a nonzero imaginary part:
> 
>     > as.raw(300+4i)
>     [1] 00
>     Warning messages:
>     1: imaginary parts discarded in coercion
>     2: out-of-range values treated as 0 in coercion to raw
> 
>     > as.raw(3e9+4i)
>     [1] 00
>     Warning messages:
>     1: NAs introduced by coercion to integer range
>     2: out-of-range values treated as 0 in coercion to raw
> 
> In one case we get a warning about the discarding of the imaginary part
> but not the other case, which is unexpected. We should see the exact
> same warning (or warnings) in both cases.
> 
> With the following fix we only get the warning about the discarding of
> the imaginary part if we are not in a "out-of-range values treated as 0
> in coercion to raw" situation:
> 
>       case CPLXSXP:
>           for (i = 0; i < n; i++) {
> //          if ((i+1) % NINTERRUPT == 0) R_CheckUserInterrupt();
>               Rcomplex vi = COMPLEX_ELT(v, i);
>               if(ISNAN(vi.r) || ISNAN(vi.i) || (tmp = (int) vi.r) < 0 ||
> tmp > 255) {
>                   tmp = 0;
>                   warn |= WARN_RAW;
>               } else {
>                   if(vi.i != 0.0)
>                       warn |= WARN_IMAG;
>               }
>               pa[i] = (Rbyte) tmp;
>           }
>           break;
> 
> Finally, coercion from character to raw has the same problem and its
> code can be fixed in a similar manner:
> 
>     > as.raw(c("3e9", 5.1))
>     [1] 00 05
>     Warning messages:
>     1: NAs introduced by coercion to integer range
>     2: out-of-range values treated as 0 in coercion to raw
> 
> Cheers,
> H.
> 
>


From Andre@G||||bert @end|ng |rom chu-rouen@|r  Fri Sep 10 18:36:25 2021
From: Andre@G||||bert @end|ng |rom chu-rouen@|r (GILLIBERT, Andre)
Date: Fri, 10 Sep 2021 16:36:25 +0000
Subject: [Rd] 
 Spurious warnings in coercion from double/complex/character to raw
In-Reply-To: <2b1460bb-a8e8-42ee-6623-b07a5858b332@gmail.com>
References: <8b1874d6-b41b-8909-7ddb-2da0459618e2@gmail.com>,
 <2b1460bb-a8e8-42ee-6623-b07a5858b332@gmail.com>
Message-ID: <29503b11191c48cc81a9b972b395c880@chu-rouen.fr>

Hello,


Integer overflow is undefined behavior by the C standard.


For instance, on my computer, with GCC 5.4.0, with the optimization level 2, the following program never stops:


include <stdio.h>


int main(void) {
        for(int i=1; i != 0; i++) {
                if ((i & 0xFFFFFFF) == 0) {
                        printf("%d\n", i);
                }
        }
}



This is due to a compiler optimization, that assumes that the integer can never overflow, and so, can never be equal to zero, and so, the for loop should never stops. You should always be very cautious when adding two integers, to avoid any overflow. There is no problem with unsigned integers.


Similarly, double-to-integer conversions are only safe if the double is in the range [INT_MIN to INT_MAX]


The standard contains:

When a finite value of real floating type is converted to an integer type other than _Bool,
the fractional part is discarded (i.e., the value is truncated toward zero). If the value of
the integral part cannot be represented by the integer type, the behavior is undefined


The easiest solution to avoid a risk when converting, is to check that the double (e.g. vi) is in range [0 to 255] BEFORE converting to an integer.


--

Sincerely

Andr? GILLIBERT

________________________________
De : R-devel <r-devel-bounces at r-project.org> de la part de Duncan Murdoch <murdoch.duncan at gmail.com>
Envoy? : vendredi 10 septembre 2021 18:12:02
? : Herv? Pag?s; r-devel
Objet : Re: [Rd] Spurious warnings in coercion from double/complex/character to raw

ATTENTION: Cet e-mail provient d?une adresse mail ext?rieure au CHU de Rouen. Ne cliquez pas sur les liens ou n'ouvrez pas les pi?ces jointes ? moins de conna?tre l'exp?diteur et de savoir que le contenu est s?r. En cas de doute, transf?rer le mail ? ? DSI, S?curit? ? pour analyse. Merci de votre vigilance


On 10/09/2021 11:29 a.m., Herv? Pag?s wrote:
> Hi,
>
> The first warning below is unexpected and confusing:
>
>     > as.raw(c(3e9, 5.1))
>     [1] 00 05
>     Warning messages:
>     1: NAs introduced by coercion to integer range
>     2: out-of-range values treated as 0 in coercion to raw
>
> The reason we get it is that coercion from numeric to raw is currently
> implemented on top of coercion from numeric to int (file
> src/main/coerce.c, lines 700-710):
>
>       case REALSXP:
>           for (i = 0; i < n; i++) {
> //          if ((i+1) % NINTERRUPT == 0) R_CheckUserInterrupt();
>               tmp = IntegerFromReal(REAL_ELT(v, i), &warn);
>               if(tmp == NA_INTEGER || tmp < 0 || tmp > 255) {
>                   tmp = 0;
>                   warn |= WARN_RAW;
>               }
>               pa[i] = (Rbyte) tmp;
>           }
>           break;
>
> The first warning comes from the call to IntegerFromReal().
>
> The following code avoids the spurious warning and is also simpler and
> slightly faster:
>
>       case REALSXP:
>           for (i = 0; i < n; i++) {
> //          if ((i+1) % NINTERRUPT == 0) R_CheckUserInterrupt();
>               double vi = REAL_ELT(v, i);
>               if(ISNAN(vi) || (tmp = (int) vi) < 0 || tmp > 255) {
>                   tmp = 0;
>                   warn |= WARN_RAW;
>               }
>               pa[i] = (Rbyte) tmp;
>           }
>           break;

Doesn't that give different results in case vi is so large that "(int)
vi" overflows?  (I don't know what the C standard says, but some online
references say that behaviour is implementation dependent.)

For example, if

   vi = 1.0 +  INT_MAX;

wouldn't "(int) vi" be equal to a small integer?

Duncan Murdoch


>
> Coercion from complex to raw has the same problem:
>
>     > as.raw(c(3e9+0i, 5.1))
>     [1] 00 05
>     Warning messages:
>     1: NAs introduced by coercion to integer range
>     2: out-of-range values treated as 0 in coercion to raw
>
> Current implementation (file src/main/coerce.c, lines 711-721):
>
>       case CPLXSXP:
>           for (i = 0; i < n; i++) {
> //          if ((i+1) % NINTERRUPT == 0) R_CheckUserInterrupt();
>               tmp = IntegerFromComplex(COMPLEX_ELT(v, i), &warn);
>               if(tmp == NA_INTEGER || tmp < 0 || tmp > 255) {
>                   tmp = 0;
>                   warn |= WARN_RAW;
>               }
>               pa[i] = (Rbyte) tmp;
>           }
>           break;
>
> This implementation has the following additional problem when the
> supplied complex has a nonzero imaginary part:
>
>     > as.raw(300+4i)
>     [1] 00
>     Warning messages:
>     1: imaginary parts discarded in coercion
>     2: out-of-range values treated as 0 in coercion to raw
>
>     > as.raw(3e9+4i)
>     [1] 00
>     Warning messages:
>     1: NAs introduced by coercion to integer range
>     2: out-of-range values treated as 0 in coercion to raw
>
> In one case we get a warning about the discarding of the imaginary part
> but not the other case, which is unexpected. We should see the exact
> same warning (or warnings) in both cases.
>
> With the following fix we only get the warning about the discarding of
> the imaginary part if we are not in a "out-of-range values treated as 0
> in coercion to raw" situation:
>
>       case CPLXSXP:
>           for (i = 0; i < n; i++) {
> //          if ((i+1) % NINTERRUPT == 0) R_CheckUserInterrupt();
>               Rcomplex vi = COMPLEX_ELT(v, i);
>               if(ISNAN(vi.r) || ISNAN(vi.i) || (tmp = (int) vi.r) < 0 ||
> tmp > 255) {
>                   tmp = 0;
>                   warn |= WARN_RAW;
>               } else {
>                   if(vi.i != 0.0)
>                       warn |= WARN_IMAG;
>               }
>               pa[i] = (Rbyte) tmp;
>           }
>           break;
>
> Finally, coercion from character to raw has the same problem and its
> code can be fixed in a similar manner:
>
>     > as.raw(c("3e9", 5.1))
>     [1] 00 05
>     Warning messages:
>     1: NAs introduced by coercion to integer range
>     2: out-of-range values treated as 0 in coercion to raw
>
> Cheers,
> H.
>
>

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


	[[alternative HTML version deleted]]


From hp@ge@@on@g|thub @end|ng |rom gm@||@com  Fri Sep 10 21:13:30 2021
From: hp@ge@@on@g|thub @end|ng |rom gm@||@com (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Fri, 10 Sep 2021 12:13:30 -0700
Subject: [Rd] 
 Spurious warnings in coercion from double/complex/character to raw
In-Reply-To: <2b1460bb-a8e8-42ee-6623-b07a5858b332@gmail.com>
References: <8b1874d6-b41b-8909-7ddb-2da0459618e2@gmail.com>
 <2b1460bb-a8e8-42ee-6623-b07a5858b332@gmail.com>
Message-ID: <fe49f407-ab9a-2cac-7fed-15cc4a6e18b3@gmail.com>



On 10/09/2021 09:12, Duncan Murdoch wrote:
> On 10/09/2021 11:29 a.m., Herv? Pag?s wrote:
>> Hi,
>>
>> The first warning below is unexpected and confusing:
>>
>> ??? > as.raw(c(3e9, 5.1))
>> ??? [1] 00 05
>> ??? Warning messages:
>> ??? 1: NAs introduced by coercion to integer range
>> ??? 2: out-of-range values treated as 0 in coercion to raw
>>
>> The reason we get it is that coercion from numeric to raw is currently
>> implemented on top of coercion from numeric to int (file
>> src/main/coerce.c, lines 700-710):
>>
>> ????? case REALSXP:
>> ????????? for (i = 0; i < n; i++) {
>> //????????? if ((i+1) % NINTERRUPT == 0) R_CheckUserInterrupt();
>> ????????????? tmp = IntegerFromReal(REAL_ELT(v, i), &warn);
>> ????????????? if(tmp == NA_INTEGER || tmp < 0 || tmp > 255) {
>> ????????????????? tmp = 0;
>> ????????????????? warn |= WARN_RAW;
>> ????????????? }
>> ????????????? pa[i] = (Rbyte) tmp;
>> ????????? }
>> ????????? break;
>>
>> The first warning comes from the call to IntegerFromReal().
>>
>> The following code avoids the spurious warning and is also simpler and
>> slightly faster:
>>
>> ????? case REALSXP:
>> ????????? for (i = 0; i < n; i++) {
>> //????????? if ((i+1) % NINTERRUPT == 0) R_CheckUserInterrupt();
>> ????????????? double vi = REAL_ELT(v, i);
>> ????????????? if(ISNAN(vi) || (tmp = (int) vi) < 0 || tmp > 255) {
>> ????????????????? tmp = 0;
>> ????????????????? warn |= WARN_RAW;
>> ????????????? }
>> ????????????? pa[i] = (Rbyte) tmp;
>> ????????? }
>> ????????? break;
> 
> Doesn't that give different results in case vi is so large that "(int) 
> vi" overflows?? (I don't know what the C standard says, but some online 
> references say that behaviour is implementation dependent.)
> 
> For example, if
> 
>  ? vi = 1.0 +? INT_MAX;
> 
> wouldn't "(int) vi" be equal to a small integer?

Good catch, thanks!

Replacing

     if(ISNAN(vi) || (tmp = (int) vi) < 0 || tmp > 255) {
         tmp = 0;

         warn |= WARN_RAW;

     }
     pa[i] = (Rbyte) tmp;

with

     if(ISNAN(vi) || vi <= -1.0 || vi >= 256.0)
  {
         tmp = 0;

         warn |= WARN_RAW;

     } else {
         tmp = (int) vi;
     }
     pa[i] = (Rbyte) tmp;

should address that.

FWIW IntegerFromReal() has a similar risk of int overflow 
(src/main/coerce.c, lines 128-138):

   int attribute_hidden

   IntegerFromReal(double x, int *warn)

   {

       if (ISNAN(x))

           return NA_INTEGER;

       else if (x >= INT_MAX+1. || x <= INT_MIN ) {

           *warn |= WARN_INT_NA;

           return NA_INTEGER;

       }

       return (int) x;

   }



The cast to int will also be an int overflow situation if x is > INT_MAX 
and < INT_MAX+1 so the risk is small! There are other instances of this 
situation in IntegerFromComplex() and IntegerFromString().

More below...

> 
> Duncan Murdoch
> 
> 
>>
>> Coercion from complex to raw has the same problem:
>>
>> ??? > as.raw(c(3e9+0i, 5.1))
>> ??? [1] 00 05
>> ??? Warning messages:
>> ??? 1: NAs introduced by coercion to integer range
>> ??? 2: out-of-range values treated as 0 in coercion to raw
>>
>> Current implementation (file src/main/coerce.c, lines 711-721):
>>
>> ????? case CPLXSXP:
>> ????????? for (i = 0; i < n; i++) {
>> //????????? if ((i+1) % NINTERRUPT == 0) R_CheckUserInterrupt();
>> ????????????? tmp = IntegerFromComplex(COMPLEX_ELT(v, i), &warn);
>> ????????????? if(tmp == NA_INTEGER || tmp < 0 || tmp > 255) {
>> ????????????????? tmp = 0;
>> ????????????????? warn |= WARN_RAW;
>> ????????????? }
>> ????????????? pa[i] = (Rbyte) tmp;
>> ????????? }
>> ????????? break;
>>
>> This implementation has the following additional problem when the
>> supplied complex has a nonzero imaginary part:
>>
>> ??? > as.raw(300+4i)
>> ??? [1] 00
>> ??? Warning messages:
>> ??? 1: imaginary parts discarded in coercion
>> ??? 2: out-of-range values treated as 0 in coercion to raw
>>
>> ??? > as.raw(3e9+4i)
>> ??? [1] 00
>> ??? Warning messages:
>> ??? 1: NAs introduced by coercion to integer range
>> ??? 2: out-of-range values treated as 0 in coercion to raw
>>
>> In one case we get a warning about the discarding of the imaginary part
>> but not the other case, which is unexpected. We should see the exact
>> same warning (or warnings) in both cases.
>>
>> With the following fix we only get the warning about the discarding of
>> the imaginary part if we are not in a "out-of-range values treated as 0
>> in coercion to raw" situation:
>>
>> ????? case CPLXSXP:
>> ????????? for (i = 0; i < n; i++) {
>> //????????? if ((i+1) % NINTERRUPT == 0) R_CheckUserInterrupt();
>> ????????????? Rcomplex vi = COMPLEX_ELT(v, i);
>> ????????????? if(ISNAN(vi.r) || ISNAN(vi.i) || (tmp = (int) vi.r) < 0 ||
>> tmp > 255) {
>> ????????????????? tmp = 0;
>> ????????????????? warn |= WARN_RAW;
>> ????????????? } else {
>> ????????????????? if(vi.i != 0.0)
>> ????????????????????? warn |= WARN_IMAG;
>> ????????????? }
>> ????????????? pa[i] = (Rbyte) tmp;
>> ????????? }
>> ????????? break;

Corrected version:

     if(ISNAN(vi.r) || ISNAN(vi.i) || vi.r <= -1.00 ||
  vi.r >= 256.00) {

         tmp = 0;

         warn |= WARN_RAW;

     } else {

         tmp = (int) vi.r;
         if(vi.i != 0.0)

             warn |= WARN_IMAG;

     }

     pa[i] = (Rbyte) tmp;

Hopefully this time I got it right.

Best,
H.

>>
>> Finally, coercion from character to raw has the same problem and its
>> code can be fixed in a similar manner:
>>
>> ??? > as.raw(c("3e9", 5.1))
>> ??? [1] 00 05
>> ??? Warning messages:
>> ??? 1: NAs introduced by coercion to integer range
>> ??? 2: out-of-range values treated as 0 in coercion to raw
>>
>> Cheers,
>> H.
>>
>>
> 

-- 
Herv? Pag?s

Bioconductor Core Team
hpages.on.github at gmail.com


From brod|e@g@@|@m @end|ng |rom y@hoo@com  Fri Sep 10 21:53:04 2021
From: brod|e@g@@|@m @end|ng |rom y@hoo@com (brodie gaslam)
Date: Fri, 10 Sep 2021 19:53:04 +0000 (UTC)
Subject: [Rd] 
 Spurious warnings in coercion from double/complex/character to raw
In-Reply-To: <fe49f407-ab9a-2cac-7fed-15cc4a6e18b3@gmail.com>
References: <8b1874d6-b41b-8909-7ddb-2da0459618e2@gmail.com>
 <2b1460bb-a8e8-42ee-6623-b07a5858b332@gmail.com>
 <fe49f407-ab9a-2cac-7fed-15cc4a6e18b3@gmail.com>
Message-ID: <1604597188.364742.1631303584179@mail.yahoo.com>


> On Friday, September 10, 2021, 03:13:54 PM EDT, Herv? Pag?s <hpages.on.github at gmail.com> wrote:
>
> Good catch, thanks!
>
> Replacing
>
>???? if(ISNAN(vi) || (tmp = (int) vi) < 0 || tmp > 255) {
>???????? tmp = 0;
>
>???????? warn |= WARN_RAW;
>
>???? }
>???? pa[i] = (Rbyte) tmp;
>
> with
>
>???? if(ISNAN(vi) || vi <= -1.0 || vi >= 256.0)
>?? {
>???????? tmp = 0;
>
>???????? warn |= WARN_RAW;
>
>???? } else {
>???????? tmp = (int) vi;
>???? }
>???? pa[i] = (Rbyte) tmp;
>
> should address that.
>
> FWIW IntegerFromReal() has a similar risk of int overflow
> (src/main/coerce.c, lines 128-138):
>
>
>?? int attribute_hidden
>
>?? IntegerFromReal(double x, int *warn)
>
>?? {
>
>?????? if (ISNAN(x))
>
>?????????? return NA_INTEGER;
>
>?????? else if (x >= INT_MAX+1. || x <= INT_MIN ) {
>
>?????????? *warn |= WARN_INT_NA;
>
>?????????? return NA_INTEGER;
>
>?????? }
>
>?????? return (int) x;
>
>?? }
>
>
>
> The cast to int will also be an int overflow situation if x is > INT_MAX
> and < INT_MAX+1 so the risk is small!

I might be being dense, but it feels this isn't a problem?? Quoting C99
6.3.1.4 again (emph added):

> When a finite value of real floating type is converted to an integer
> type other than _Bool, **the fractional part is discarded** (i.e., the
> value is truncated toward zero). If the value of the integral part
> cannot be represented by the integer type, the behavior is undefined.50)

Does the "fractional part is discarded" not save us here?

Best,

B.


From hp@ge@@on@g|thub @end|ng |rom gm@||@com  Fri Sep 10 23:14:39 2021
From: hp@ge@@on@g|thub @end|ng |rom gm@||@com (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Fri, 10 Sep 2021 14:14:39 -0700
Subject: [Rd] 
 Spurious warnings in coercion from double/complex/character to raw
In-Reply-To: <1604597188.364742.1631303584179@mail.yahoo.com>
References: <8b1874d6-b41b-8909-7ddb-2da0459618e2@gmail.com>
 <2b1460bb-a8e8-42ee-6623-b07a5858b332@gmail.com>
 <fe49f407-ab9a-2cac-7fed-15cc4a6e18b3@gmail.com>
 <1604597188.364742.1631303584179@mail.yahoo.com>
Message-ID: <ad5994f2-1e6b-6059-52aa-6c0f4c0d04b1@gmail.com>



On 10/09/2021 12:53, brodie gaslam wrote:
> 
>> On Friday, September 10, 2021, 03:13:54 PM EDT, Herv? Pag?s <hpages.on.github at gmail.com> wrote:
>>
>> Good catch, thanks!
>>
>> Replacing
>>
>>  ???? if(ISNAN(vi) || (tmp = (int) vi) < 0 || tmp > 255) {
>>  ???????? tmp = 0;
>>
>>  ???????? warn |= WARN_RAW;
>>
>>  ???? }
>>  ???? pa[i] = (Rbyte) tmp;
>>
>> with
>>
>>  ???? if(ISNAN(vi) || vi <= -1.0 || vi >= 256.0)
>>  ?? {
>>  ???????? tmp = 0;
>>
>>  ???????? warn |= WARN_RAW;
>>
>>  ???? } else {
>>  ???????? tmp = (int) vi;
>>  ???? }
>>  ???? pa[i] = (Rbyte) tmp;
>>
>> should address that.
>>
>> FWIW IntegerFromReal() has a similar risk of int overflow
>> (src/main/coerce.c, lines 128-138):
>>
>>
>>  ?? int attribute_hidden
>>
>>  ?? IntegerFromReal(double x, int *warn)
>>
>>  ?? {
>>
>>  ?????? if (ISNAN(x))
>>
>>  ?????????? return NA_INTEGER;
>>
>>  ?????? else if (x >= INT_MAX+1. || x <= INT_MIN ) {
>>
>>  ?????????? *warn |= WARN_INT_NA;
>>
>>  ?????????? return NA_INTEGER;
>>
>>  ?????? }
>>
>>  ?????? return (int) x;
>>
>>  ?? }
>>
>>
>>
>> The cast to int will also be an int overflow situation if x is > INT_MAX
>> and < INT_MAX+1 so the risk is small!
> 
> I might be being dense, but it feels this isn't a problem?? Quoting C99
> 6.3.1.4 again (emph added):
> 
>> When a finite value of real floating type is converted to an integer
>> type other than _Bool, **the fractional part is discarded** (i.e., the
>> value is truncated toward zero). If the value of the integral part
>> cannot be represented by the integer type, the behavior is undefined.50)
> 
> Does the "fractional part is discarded" not save us here?

I think it does. Thanks for clarifying and sorry for the false positive!

H.

> 
> Best,
> 
> B.
> 
> 

-- 
Herv? Pag?s

Bioconductor Core Team
hpages.on.github at gmail.com


From tom@@@k@||ber@ @end|ng |rom gm@||@com  Tue Sep 14 15:40:39 2021
From: tom@@@k@||ber@ @end|ng |rom gm@||@com (Tomas Kalibera)
Date: Tue, 14 Sep 2021 15:40:39 +0200
Subject: [Rd] Detect UCRT-built R from within R sessions (and in
 configure.win)
In-Reply-To: <CALyqOb8yer26avLG8wmGxpFQgEeYtxaPGOnixpYTssAJiOLfDA@mail.gmail.com>
References: <CALyqOb8r7ajAumf5V0+YJk83X091NS2eRCs-cu=X6zO+09z0Rg@mail.gmail.com>
 <a219a307-5200-a13e-b4d9-a1e7a646e137@gmail.com>
 <CALyqOb8yer26avLG8wmGxpFQgEeYtxaPGOnixpYTssAJiOLfDA@mail.gmail.com>
Message-ID: <d722d393-94e0-370b-e7bd-ca96e708a205@gmail.com>


On 9/9/21 5:54 AM, Hiroaki Yutani wrote:
> Thank you for the prompt reply.
>
> > There in not such a mechanism, yet, but can be added, at least for
> > diagnostics.
>
> For example, can R.version somehow contain the information?
Yes, now added to the experimental builds. R.version$crt contains "ucrt" 
(and would contain "msvcrt" if R was built against MSVCRT).
>
> > We could add support for configure.ucrt, which would take precedence
> > over configure.win on the UCRT builds (like Makevars.ucrt takes
> > precedence over Makevars.win). Would that work for you?
>
> Yes, configure.ucrt should work for me. There might be someone who 
> prefers to switch by some envvar rather than creating another file, 
> but I don't have a strong opinion here.

The experimental builds now support configure.ucrt and cleanup.ucrt files.

Best
Tomas

>
> Best,
> Hiroaki Yutani
>
> 2021?9?9?(?) 0:48 Tomas Kalibera <tomas.kalibera at gmail.com 
> <mailto:tomas.kalibera at gmail.com>>:
>
>
>     On 9/8/21 2:08 PM, Hiroaki Yutani wrote:
>     > Hi,
>     >
>     > Are there any proper ways to know whether the session is running on
>     > the R that is built with the UCRT toolchain or not? Checking if the
>     > encoding is UTF-8 might do the trick, but I'm not sure if it's
>     always
>     > reliable.
>
>     There in not such a mechanism, yet, but can be added, at least for
>     diagnostics.
>
>     You are right that checking for UTF-8 encoding would not always be
>     reliable. For example, the version of Windows may be too old to
>     allow R
>     use UTF-8 as native encoding (e.g. Windows server 2016), then R
>     will use
>     the native code page as it does today in the MSVCRT builds.
>
>     > Also, I'd like to know if there's any mechanism to detect the
>     UCRT in
>     > configure.win. I know there are Makevars.ucrt and Makefile.ucrt, but
>     > one might want to do some feature test that is specific to the UCRT
>     > toolchain.
>
>     We could add support for configure.ucrt, which would take precedence
>     over configure.win on the UCRT builds (like Makevars.ucrt takes
>     precedence over Makevars.win). Would that work for you?
>
>     Best
>     Tomas
>
>     >
>     > Best,
>     > Hiroaki Yutani
>     >
>     > ______________________________________________
>     > R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-devel
>     <https://stat.ethz.ch/mailman/listinfo/r-devel>
>

	[[alternative HTML version deleted]]


From @oun @end|ng |rom cer|@c@@|r  Tue Sep 14 15:22:56 2021
From: @oun @end|ng |rom cer|@c@@|r (Abel AOUN)
Date: Tue, 14 Sep 2021 15:22:56 +0200 (CEST)
Subject: [Rd] Question about quantile fuzz and GPL license
Message-ID: <1907231179.19658.1631625776595.JavaMail.zimbra@cerfacs.fr>

Hello, 

I'm currently working on Python numpy package to develop linear interpolation methods for quantiles. 
Currently, numpy only support the type 7 of Hyndman & Fan and I did the implementation for the 8 other methods to do as much as R ::quantile. 

As you may guess, I was inspired by R implementation as well as other sources, which lead to my questions: 

About fuzz (see first reference below for the source code), 
fuzz <- 4 * .Machine $ double.eps 
I think I understand why the machine epsilon is used to correct some edge cases where the float comparisons would fail. 
However I don't get why epsilon is multiplied by 4 instead of simply using epsilon. 
Is there someone who can explain this 4 ? 

About licence, 
Numpy is under license BSD and R is on GPL. 
The only thing I really cherry picked and rewrote for numpy is the fuzz part. 
I'm quite new to open source development. We are wondering if doing this breaks the license GPL and if I can credit the original authors. 
Plus, I'm not quite sure this is the right place to ask this, if not, sorry for the noise. 
The relevant discussion on numpy PR is here: [ https://github.com/numpy/numpy/pull/19857#discussion_r706019184 | https://github.com/numpy/numpy/pull/19857#discussion_r706019184 ] 


Thank you for your time. 

Regards, 
Abel Aoun 


References: 
The source code for R::quantile (fuzz is at line 82) [ https://github.com/wch/r-source/blob/79298c499218846d14500255efd622b5021c10ec/src/library/stats/R/quantile.R | https://github.com/wch/r-source/blob/79298c499218846d14500255efd622b5021c10ec/src/library/stats/R/quantile.R ] [ https://github.com/numpy/numpy/pull/19857 ] 
R doc for quantile : [ https://www.rdocumentation.org/packages/stats/versions/3.5.0/topics/quantile | https://www.rdocumentation.org/packages/stats/versions/3.5.0/topics/quantile ] 
The ongoing PR on numpy: [ https://github.com/numpy/numpy/pull/19857 | https://github.com/numpy/numpy/pull/19857 ] 



	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Tue Sep 14 16:11:56 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 14 Sep 2021 10:11:56 -0400
Subject: [Rd] Question about quantile fuzz and GPL license
In-Reply-To: <1907231179.19658.1631625776595.JavaMail.zimbra@cerfacs.fr>
References: <1907231179.19658.1631625776595.JavaMail.zimbra@cerfacs.fr>
Message-ID: <7095a8b3-11d7-e4c8-5785-76a21acbc1df@gmail.com>



On 9/14/21 9:22 AM, Abel AOUN wrote:
> Hello,
> 
> I'm currently working on Python numpy package to develop linear interpolation methods for quantiles.
> Currently, numpy only support the type 7 of Hyndman & Fan and I did the implementation for the 8 other methods to do as much as R ::quantile.
> 
> As you may guess, I was inspired by R implementation as well as other sources, which lead to my questions:
> 
> About fuzz (see first reference below for the source code),
> fuzz <- 4 * .Machine $ double.eps
> I think I understand why the machine epsilon is used to correct some edge cases where the float comparisons would fail.
> However I don't get why epsilon is multiplied by 4 instead of simply using epsilon.
> Is there someone who can explain this 4 ?

No, but doing a bit of archaeology

https://github.com/wch/r-source/blame/trunk/src/library/stats/R/quantile.R

   give the commit message for these lines as "add (modified) version of 
quantile.default from Rob Hyndman (17 years ago)".  This commit was made 
by Brian Ripley.

   However, the code from Rob Hyndman here:

https://stat.ethz.ch/pipermail/r-devel/2004-July/030204.html

   does **not** have the lines with the fuzz.  So my guess would be that 
Brian Ripley is the author of that particular bit of code.

   I can't say, myself, what the logic behind 4 * .Machine$double.eps is ...


> 
> About licence,
> Numpy is under license BSD and R is on GPL.
> The only thing I really cherry picked and rewrote for numpy is the fuzz part.
> I'm quite new to open source development. We are wondering if doing this breaks the license GPL and if I can credit the original authors.
> Plus, I'm not quite sure this is the right place to ask this, if not, sorry for the noise.
> The relevant discussion on numpy PR is here: [ https://github.com/numpy/numpy/pull/19857#discussion_r706019184 | https://github.com/numpy/numpy/pull/19857#discussion_r706019184 ]
> 
> 
> Thank you for your time.
> 
> Regards,
> Abel Aoun
> 
> 
> References:
> The source code for R::quantile (fuzz is at line 82) [ https://github.com/wch/r-source/blob/79298c499218846d14500255efd622b5021c10ec/src/library/stats/R/quantile.R | https://github.com/wch/r-source/blob/79298c499218846d14500255efd622b5021c10ec/src/library/stats/R/quantile.R ] [ https://github.com/numpy/numpy/pull/19857 ]
> R doc for quantile : [ https://www.rdocumentation.org/packages/stats/versions/3.5.0/topics/quantile | https://www.rdocumentation.org/packages/stats/versions/3.5.0/topics/quantile ]
> The ongoing PR on numpy: [ https://github.com/numpy/numpy/pull/19857 | https://github.com/numpy/numpy/pull/19857 ]
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics


From yut@n|@|n| @end|ng |rom gm@||@com  Tue Sep 14 16:44:44 2021
From: yut@n|@|n| @end|ng |rom gm@||@com (Hiroaki Yutani)
Date: Tue, 14 Sep 2021 23:44:44 +0900
Subject: [Rd] Detect UCRT-built R from within R sessions (and in
 configure.win)
In-Reply-To: <d722d393-94e0-370b-e7bd-ca96e708a205@gmail.com>
References: <CALyqOb8r7ajAumf5V0+YJk83X091NS2eRCs-cu=X6zO+09z0Rg@mail.gmail.com>
 <a219a307-5200-a13e-b4d9-a1e7a646e137@gmail.com>
 <CALyqOb8yer26avLG8wmGxpFQgEeYtxaPGOnixpYTssAJiOLfDA@mail.gmail.com>
 <d722d393-94e0-370b-e7bd-ca96e708a205@gmail.com>
Message-ID: <CALyqOb8FaPfVMU1-0BzXdNwrgMQtv+t5uiacasdQo=SZSQ4pug@mail.gmail.com>

Thanks for both, I'll try these features.

2021?9?14?(?) 22:40 Tomas Kalibera <tomas.kalibera at gmail.com>:

>
>
> On 9/9/21 5:54 AM, Hiroaki Yutani wrote:
>
> Thank you for the prompt reply.
>
> > There in not such a mechanism, yet, but can be added, at least for
> > diagnostics.
>
> For example, can R.version somehow contain the information?
>
> Yes, now added to the experimental builds. R.version$crt contains "ucrt" (and would contain "msvcrt" if R was built against MSVCRT).
>
>
> > We could add support for configure.ucrt, which would take precedence
> > over configure.win on the UCRT builds (like Makevars.ucrt takes
> > precedence over Makevars.win). Would that work for you?
>
> Yes, configure.ucrt should work for me. There might be someone who prefers to switch by some envvar rather than creating another file, but I don't have a strong opinion here.
>
> The experimental builds now support configure.ucrt and cleanup.ucrt files.
>
> Best
> Tomas
>
>
> Best,
> Hiroaki Yutani
>
> 2021?9?9?(?) 0:48 Tomas Kalibera <tomas.kalibera at gmail.com>:
>>
>>
>> On 9/8/21 2:08 PM, Hiroaki Yutani wrote:
>> > Hi,
>> >
>> > Are there any proper ways to know whether the session is running on
>> > the R that is built with the UCRT toolchain or not? Checking if the
>> > encoding is UTF-8 might do the trick, but I'm not sure if it's always
>> > reliable.
>>
>> There in not such a mechanism, yet, but can be added, at least for
>> diagnostics.
>>
>> You are right that checking for UTF-8 encoding would not always be
>> reliable. For example, the version of Windows may be too old to allow R
>> use UTF-8 as native encoding (e.g. Windows server 2016), then R will use
>> the native code page as it does today in the MSVCRT builds.
>>
>> > Also, I'd like to know if there's any mechanism to detect the UCRT in
>> > configure.win. I know there are Makevars.ucrt and Makefile.ucrt, but
>> > one might want to do some feature test that is specific to the UCRT
>> > toolchain.
>>
>> We could add support for configure.ucrt, which would take precedence
>> over configure.win on the UCRT builds (like Makevars.ucrt takes
>> precedence over Makevars.win). Would that work for you?
>>
>> Best
>> Tomas
>>
>> >
>> > Best,
>> > Hiroaki Yutani
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel


From Andre@G||||bert @end|ng |rom chu-rouen@|r  Tue Sep 14 18:13:05 2021
From: Andre@G||||bert @end|ng |rom chu-rouen@|r (GILLIBERT, Andre)
Date: Tue, 14 Sep 2021 16:13:05 +0000
Subject: [Rd] Question about quantile fuzz and GPL license
In-Reply-To: <7095a8b3-11d7-e4c8-5785-76a21acbc1df@gmail.com>
References: <1907231179.19658.1631625776595.JavaMail.zimbra@cerfacs.fr>,
 <7095a8b3-11d7-e4c8-5785-76a21acbc1df@gmail.com>
Message-ID: <f72a48fceb634e03aa3b4bcac3719de8@chu-rouen.fr>


On 9/14/21 9:22 AM, Abel AOUN wrote:
> However I don't get why epsilon is multiplied by 4 instead of simply using epsilon.
> Is there someone who can explain this 4 ?

.Machine$double.eps is the "precision" of floating point values for values close to 1.0 (between 0.5 and 2.0).

Using fuzz = .Machine$double.eps would have no effect if nppm is greater than or equal to 2.
Using fuzz = 4 * .Machine$double.eps can fix rounding errors for nppm < 8; for greater nppm, it has no effect.

Indeed:
2 + .Machine$double.eps == 2
8+ 4*.Machine$double.eps == 8

Since nppm is approximatively equal to the quantile multiplied by the sample size, it can be much greater than 2 or 8.

Maybe the rounding errors are only problematic for small nppm; or only that case is taken in account.

Moreover, if rounding errors are cumulative, they can be much greater than the precision of the floating point value. I do not know how this constant was chosen and what the use-cases were.

--
Sincerely
Andre GILLIBERT


	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Wed Sep 15 10:46:45 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Wed, 15 Sep 2021 10:46:45 +0200
Subject: [Rd] Question about quantile fuzz and GPL license
In-Reply-To: <f72a48fceb634e03aa3b4bcac3719de8@chu-rouen.fr>
References: <1907231179.19658.1631625776595.JavaMail.zimbra@cerfacs.fr>
 <7095a8b3-11d7-e4c8-5785-76a21acbc1df@gmail.com>
 <f72a48fceb634e03aa3b4bcac3719de8@chu-rouen.fr>
Message-ID: <24897.45813.910677.527364@stat.math.ethz.ch>

>>>>> GILLIBERT, Andre 
>>>>>     on Tue, 14 Sep 2021 16:13:05 +0000 writes:

    > On 9/14/21 9:22 AM, Abel AOUN wrote:
    >> However I don't get why epsilon is multiplied by 4 instead of simply using epsilon.
    >> Is there someone who can explain this 4 ?

    > .Machine$double.eps is the "precision" of floating point values for values close to 1.0 (between 0.5 and 2.0).

    > Using fuzz = .Machine$double.eps would have no effect if nppm is greater than or equal to 2.
    > Using fuzz = 4 * .Machine$double.eps can fix rounding errors for nppm < 8; for greater nppm, it has no effect.

    > Indeed:
    > 2 + .Machine$double.eps == 2
    > 8+ 4*.Machine$double.eps == 8

    > Since nppm is approximatively equal to the quantile multiplied by the sample size, it can be much greater than 2 or 8.

hmm: not "quantile":
 it is approximatively equal to the *'prob'* multiplied by the sample size
 {the quantiles themselves can be on any scale anyway, but they
  don't matter yet fortunately in these parts of the calculations}

but you're right in the main point that they are
approx. proportional to  n.

    > Maybe the rounding errors are only problematic for small nppm; or only that case is taken in account.

    > Moreover, if rounding errors are cumulative, they can be much greater than the precision of the floating point value. I do not know how this constant was chosen and what the use-cases were.

I vaguely remember I've been wondering about this also (back at the time).

Experiential wisdom would tell us to take such  fuzz values as
*relative* to the magnitude of the values they are added to,
here 'nppm' (which is always >= 0, hence no need for  abs(.) as usually).

So, instead of

    j <- floor(nppm + fuzz)
    h <- nppm - j
    if(any(sml <- abs(h) < fuzz, na.rm = TRUE)) h[sml] <- 0

it would be (something like)

    j <- floor(nppm*(1 + fuzz))
    h <- nppm - j
    if(any(sml <- abs(h) < fuzz*nppm, na.rm = TRUE)) h[sml] <- 0

or rather we would define fuzz as
   nppm * (k * .Machine$double.eps) 
for a small k.

- - -

OTOH,  type=7 is the default, and I guess used in 99.9% of
all uses of quantile, *and* does never use any fuzz ....

Martin

    > --
    > Sincerely
    > Andre GILLIBERT


    > [[alternative HTML version deleted]]


From Andre@G||||bert @end|ng |rom chu-rouen@|r  Wed Sep 15 18:52:33 2021
From: Andre@G||||bert @end|ng |rom chu-rouen@|r (GILLIBERT, Andre)
Date: Wed, 15 Sep 2021 16:52:33 +0000
Subject: [Rd] Question about quantile fuzz and GPL license
In-Reply-To: <24897.45813.910677.527364@stat.math.ethz.ch>
References: <1907231179.19658.1631625776595.JavaMail.zimbra@cerfacs.fr>
 <7095a8b3-11d7-e4c8-5785-76a21acbc1df@gmail.com>
 <f72a48fceb634e03aa3b4bcac3719de8@chu-rouen.fr>
 <24897.45813.910677.527364@stat.math.ethz.ch>
Message-ID: <76a1765f6717445fb82b463181206faf@chu-rouen.fr>

Martin Maechler wrote:
> OTOH,  type=7 is the default, and I guess used in 99.9% of
> all uses of quantile, *and* does never use any fuzz ....

Indeed. This also implies that this default should be well-thought when creating a new implementation of the quantile() procedure for a new programming language or library.
Most of the time, users use the default procedure, and do not report the procedure used in the statistical analysis reports, scientific or non-scientific articles produced.
The differences between all quantiles procedures are minor, unless they are used in crazy scenarios such as a sample size of 2, or with probs=0.001 for a sample of size 1000.
But, standardization of procedures is desirable for analysis reproducibility, as well as teaching (see https://doi.org/10.1080/10691898.2006.11910589 ).

Hyndman and Fan wanted that software package standardize their definition, but to no avail:
See https://robjhyndman.com/hyndsight/sample-quantiles-20-years-later/

In the absence of standard, my personal advice would be to use the same default as a popular statistical software, such as R or SAS.

R, Julia and NumPy (python) uses type 7 as default.
Microsoft Excel and LibreOffice Calc use type 7 as default (although Excel versions >= 2010 have new procedures).
SAS uses type 3 as default, unless prob=0.50
Stata uses type 2 or type 6, depending on the procedure (https://data.princeton.edu/stata/markdown/quantiles.htm)

-- 
Sincerely
Andr? GILLIBERT


From A|ex@nder@K@ever @end|ng |rom evotec@com  Thu Sep 16 16:00:03 2021
From: A|ex@nder@K@ever @end|ng |rom evotec@com (Alexander Kaever)
Date: Thu, 16 Sep 2021 14:00:03 +0000
Subject: [Rd] Slow try in combination with do.call
Message-ID: <CWLP123MB3938E6AE26CF55BE8AC63456F7DC9@CWLP123MB3938.GBRP123.PROD.OUTLOOK.COM>

Hi,

It seems like a try(do.call(f, args)) can be very slow on error depending on the args size. This is related to a complete deparse of the call using deparse(call)[1L] within the try function. How about replacing deparse(call)[1L] by deparse(call, nlines = 1)?

Best,
Alex


Example:

fun <- function(x) {
  stop("testing")
}
d <- rep(list(mtcars), 10000)
object.size(d)
# 72MB

system.time({
  try(do.call(fun, args = list(x = d)))
})
# 8s


Unsere Informationen zum Datenschutz finden Sie hier<https://www.evotec.com/de/about/site-information/datenschutzbestimmungen>.

Evotec International GmbH, Hamburg. Amtsgericht Hamburg HRB 72242
Gesch?ftsf?hrung: Dr. Cord Dohrmann, Dr. Craig Johnstone, Enno Spillner

STATEMENT OF CONFIDENTIALITY.

This email and any attachments may contain confidential, proprietary, privileged and/or private information.  
If received in error, please notify us immediately by reply email and then delete this email and any attachments from your system. Thank you.

From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Thu Sep 16 17:48:41 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 16 Sep 2021 17:48:41 +0200
Subject: [Rd] Slow try in combination with do.call
In-Reply-To: <CWLP123MB3938E6AE26CF55BE8AC63456F7DC9@CWLP123MB3938.GBRP123.PROD.OUTLOOK.COM>
References: <CWLP123MB3938E6AE26CF55BE8AC63456F7DC9@CWLP123MB3938.GBRP123.PROD.OUTLOOK.COM>
Message-ID: <24899.26457.944004.373721@stat.math.ethz.ch>

>>>>> Alexander Kaever 
>>>>>     on Thu, 16 Sep 2021 14:00:03 +0000 writes:

    > Hi,
    > It seems like a try(do.call(f, args)) can be very slow on error depending on the args size. This is related to a complete deparse of the call using deparse(call)[1L] within the try function. How about replacing deparse(call)[1L] by deparse(call, nlines = 1)?

    > Best,
    > Alex

an *excellent* idea!

I have checked that the resulting try() object continues to contain the
long large call; indeed that is not the problem, but the
deparse()ing  *is* as you say above.

{The experts typically use  tryCatch() directly, instead of  try() ,
 which may be the reason other experienced R developers have not
 stumbled over this ...}

Thanks a lot, notably also for the clear  repr.ex. below.

Best regards,
Martin


    > Example:

    > fun <- function(x) {
    > stop("testing")
    > }
    > d <- rep(list(mtcars), 10000)
    > object.size(d)
    > # 72MB

    > system.time({
    > try(do.call(fun, args = list(x = d)))
    > })
    > # 8s


    > Unsere Informationen zum Datenschutz finden Sie hier<https://www.evotec.com/de/about/site-information/datenschutzbestimmungen>.

    > Evotec International GmbH, Hamburg. Amtsgericht Hamburg HRB 72242
    > Gesch?ftsf?hrung: Dr. Cord Dohrmann, Dr. Craig Johnstone, Enno Spillner

    > STATEMENT OF CONFIDENTIALITY.

    > This email and any attachments may contain confidential, proprietary, privileged and/or private information.  
    > If received in error, please notify us immediately by reply email and then delete this email and any attachments from your system. Thank you.
    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Thu Sep 16 18:04:24 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 16 Sep 2021 18:04:24 +0200
Subject: [Rd] Slow try in combination with do.call
In-Reply-To: <24899.26457.944004.373721@stat.math.ethz.ch>
References: <CWLP123MB3938E6AE26CF55BE8AC63456F7DC9@CWLP123MB3938.GBRP123.PROD.OUTLOOK.COM>
 <24899.26457.944004.373721@stat.math.ethz.ch>
Message-ID: <24899.27400.17297.779309@stat.math.ethz.ch>

>>>>> Martin Maechler 
>>>>>     on Thu, 16 Sep 2021 17:48:41 +0200 writes:

>>>>> Alexander Kaever 
>>>>>     on Thu, 16 Sep 2021 14:00:03 +0000 writes:

    >> Hi,
    >> It seems like a try(do.call(f, args)) can be very slow on error depending on the args size. This is related to a complete deparse of the call using deparse(call)[1L] within the try function. How about replacing deparse(call)[1L] by deparse(call, nlines = 1)?

    >> Best,
    >> Alex

    > an *excellent* idea!

    > I have checked that the resulting try() object continues to contain the
    > long large call; indeed that is not the problem, but the
    > deparse()ing  *is* as you say above.

    > {The experts typically use  tryCatch() directly, instead of  try() ,
    > which may be the reason other experienced R developers have not
    > stumbled over this ...}

    > Thanks a lot, notably also for the clear  repr.ex. below.

    > Best regards,
    > Martin

OTOH, I find so many cases  of   deparse(*)[1]  (or similar) in
R's own sources, I'm wondering
if I'm forgetting something ... and using nlines=* is not always
faster & equivalent and hence better ??

Martin




    >> Example:

    >> fun <- function(x) {
    >> stop("testing")
    >> }
    >> d <- rep(list(mtcars), 10000)
    >> object.size(d)
    >> # 72MB

    >> system.time({
    >> try(do.call(fun, args = list(x = d)))
    >> })
    >> # 8s


From henr|k@bengt@@on @end|ng |rom gm@||@com  Fri Sep 17 10:47:48 2021
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Fri, 17 Sep 2021 10:47:48 +0200
Subject: [Rd] WISH: set.seed(seed) to produce error if length(seed) != 1
 (now silent)
Message-ID: <CAFDcVCSK1ePJbxK18bk_cbEmPenLeFPVoH52dLS2Qgy8Xa4eQg@mail.gmail.com>

Hi,

according to help("set.seed"), argument 'seed' to set.seed() should be:

  a single value, interpreted as an integer, or NULL (see ?Details?).

>From code inspection (src/main/RNG.c) and testing, it turns out that
if you pass a 'seed' with length greater than one, it silently uses
seed[1], e.g.

> set.seed(1); sum(.Random.seed)
[1] 4070365163
> set.seed(1:3); sum(.Random.seed)
[1] 4070365163
> set.seed(1:100); sum(.Random.seed)
[1] 4070365163

I'd like to suggest that set.seed() produces an error if length(seed)
> 1.  As a reference, for length(seed) == 0, we get:

> set.seed(integer(0))
Error in set.seed(integer(0)) : supplied seed is not a valid integer

/Henrik


From @vr@h@m@@d|er @end|ng |rom gm@||@com  Fri Sep 17 12:06:44 2021
From: @vr@h@m@@d|er @end|ng |rom gm@||@com (Avraham Adler)
Date: Fri, 17 Sep 2021 13:06:44 +0300
Subject: [Rd] WISH: set.seed(seed) to produce error if length(seed) != 1
 (now silent)
In-Reply-To: <CAFDcVCSK1ePJbxK18bk_cbEmPenLeFPVoH52dLS2Qgy8Xa4eQg@mail.gmail.com>
References: <CAFDcVCSK1ePJbxK18bk_cbEmPenLeFPVoH52dLS2Qgy8Xa4eQg@mail.gmail.com>
Message-ID: <CAL6gwnLXBNd=Q8=_ziJfGA1n8n7OeCB4U8Y3SwiZJ7DPs3EDGg@mail.gmail.com>

Hi, Henrik.

I?m curious, other than proper programming practice, why?

Avi

On Fri, Sep 17, 2021 at 11:48 AM Henrik Bengtsson <
henrik.bengtsson at gmail.com> wrote:

> Hi,
>
> according to help("set.seed"), argument 'seed' to set.seed() should be:
>
>   a single value, interpreted as an integer, or NULL (see ?Details?).
>
> From code inspection (src/main/RNG.c) and testing, it turns out that
> if you pass a 'seed' with length greater than one, it silently uses
> seed[1], e.g.
>
> > set.seed(1); sum(.Random.seed)
> [1] 4070365163
> > set.seed(1:3); sum(.Random.seed)
> [1] 4070365163
> > set.seed(1:100); sum(.Random.seed)
> [1] 4070365163
>
> I'd like to suggest that set.seed() produces an error if length(seed)
> > 1.  As a reference, for length(seed) == 0, we get:
>
> > set.seed(integer(0))
> Error in set.seed(integer(0)) : supplied seed is not a valid integer
>
> /Henrik
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
-- 
Sent from Gmail Mobile

	[[alternative HTML version deleted]]


From Andre@G||||bert @end|ng |rom chu-rouen@|r  Fri Sep 17 12:55:44 2021
From: Andre@G||||bert @end|ng |rom chu-rouen@|r (GILLIBERT, Andre)
Date: Fri, 17 Sep 2021 10:55:44 +0000
Subject: [Rd] WISH: set.seed(seed) to produce error if length(seed) != 1
 (now silent)
In-Reply-To: <CAL6gwnLXBNd=Q8=_ziJfGA1n8n7OeCB4U8Y3SwiZJ7DPs3EDGg@mail.gmail.com>
References: <CAFDcVCSK1ePJbxK18bk_cbEmPenLeFPVoH52dLS2Qgy8Xa4eQg@mail.gmail.com>
 <CAL6gwnLXBNd=Q8=_ziJfGA1n8n7OeCB4U8Y3SwiZJ7DPs3EDGg@mail.gmail.com>
Message-ID: <93a456da9ea8443ebd2b775c204910b2@chu-rouen.fr>

Hello,

A vector with a length >= 2 to set.seed would probably be a bug. An error message will help the user to fix his R code. The bug may be accidental or due to bad understanding of the set.seed function. For instance, a user may think that the whole state of the PRNG can be passed to set.seed.

The "if" instruction, emits a warning when the condition has length >= 2, because it is often a bug. I would expect a warning or error with set.seed().

Validating inputs and emitting errors early is a good practice.

Just my 2 cents.

Sincerely.
Andre GILLIBERT

-----Message d'origine-----
De?: R-devel [mailto:r-devel-bounces at r-project.org] De la part de Avraham Adler
Envoy??: vendredi 17 septembre 2021 12:07
??: Henrik Bengtsson
Cc?: R-devel
Objet?: Re: [Rd] WISH: set.seed(seed) to produce error if length(seed) != 1 (now silent)

Hi, Henrik.

I?m curious, other than proper programming practice, why?

Avi

On Fri, Sep 17, 2021 at 11:48 AM Henrik Bengtsson <
henrik.bengtsson at gmail.com> wrote:

> Hi,
>
> according to help("set.seed"), argument 'seed' to set.seed() should be:
>
>   a single value, interpreted as an integer, or NULL (see ?Details?).
>
> From code inspection (src/main/RNG.c) and testing, it turns out that
> if you pass a 'seed' with length greater than one, it silently uses
> seed[1], e.g.
>
> > set.seed(1); sum(.Random.seed)
> [1] 4070365163
> > set.seed(1:3); sum(.Random.seed)
> [1] 4070365163
> > set.seed(1:100); sum(.Random.seed)
> [1] 4070365163
>
> I'd like to suggest that set.seed() produces an error if length(seed)
> > 1.  As a reference, for length(seed) == 0, we get:
>
> > set.seed(integer(0))
> Error in set.seed(integer(0)) : supplied seed is not a valid integer
>
> /Henrik
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
--
Sent from Gmail Mobile

        [[alternative HTML version deleted]]

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From henr|k@bengt@@on @end|ng |rom gm@||@com  Fri Sep 17 14:38:46 2021
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Fri, 17 Sep 2021 14:38:46 +0200
Subject: [Rd] WISH: set.seed(seed) to produce error if length(seed) != 1
 (now silent)
In-Reply-To: <93a456da9ea8443ebd2b775c204910b2@chu-rouen.fr>
References: <CAFDcVCSK1ePJbxK18bk_cbEmPenLeFPVoH52dLS2Qgy8Xa4eQg@mail.gmail.com>
 <CAL6gwnLXBNd=Q8=_ziJfGA1n8n7OeCB4U8Y3SwiZJ7DPs3EDGg@mail.gmail.com>
 <93a456da9ea8443ebd2b775c204910b2@chu-rouen.fr>
Message-ID: <CAFDcVCRoLiR0tzCyRENOqP2xdYCGoT0Mx7x-vyuBVRArwiatiQ@mail.gmail.com>

> I?m curious, other than proper programming practice, why?

Life's too short for troubleshooting silent mistakes - mine or others.

While at it, searching the interwebs for use of set.seed(), gives
mistakes/misunderstandings like using set.seed(<double>), e.g.

> set.seed(6.1); sum(.Random.seed)
[1] 73930104
> set.seed(6.2); sum(.Random.seed)
[1] 73930104

which clearly is not what the user expected.  There are also a few
cases of set.seed(<character>), e.g.

> set.seed("42"); sum(.Random.seed)
[1] -2119381568
> set.seed(42); sum(.Random.seed)
[1] -2119381568

which works just because as.numeric("42") is used.

/Henrik

On Fri, Sep 17, 2021 at 12:55 PM GILLIBERT, Andre
<Andre.Gillibert at chu-rouen.fr> wrote:
>
> Hello,
>
> A vector with a length >= 2 to set.seed would probably be a bug. An error message will help the user to fix his R code. The bug may be accidental or due to bad understanding of the set.seed function. For instance, a user may think that the whole state of the PRNG can be passed to set.seed.
>
> The "if" instruction, emits a warning when the condition has length >= 2, because it is often a bug. I would expect a warning or error with set.seed().
>
> Validating inputs and emitting errors early is a good practice.
>
> Just my 2 cents.
>
> Sincerely.
> Andre GILLIBERT
>
> -----Message d'origine-----
> De : R-devel [mailto:r-devel-bounces at r-project.org] De la part de Avraham Adler
> Envoy? : vendredi 17 septembre 2021 12:07
> ? : Henrik Bengtsson
> Cc : R-devel
> Objet : Re: [Rd] WISH: set.seed(seed) to produce error if length(seed) != 1 (now silent)
>
> Hi, Henrik.
>
> I?m curious, other than proper programming practice, why?
>
> Avi
>
> On Fri, Sep 17, 2021 at 11:48 AM Henrik Bengtsson <
> henrik.bengtsson at gmail.com> wrote:
>
> > Hi,
> >
> > according to help("set.seed"), argument 'seed' to set.seed() should be:
> >
> >   a single value, interpreted as an integer, or NULL (see ?Details?).
> >
> > From code inspection (src/main/RNG.c) and testing, it turns out that
> > if you pass a 'seed' with length greater than one, it silently uses
> > seed[1], e.g.
> >
> > > set.seed(1); sum(.Random.seed)
> > [1] 4070365163
> > > set.seed(1:3); sum(.Random.seed)
> > [1] 4070365163
> > > set.seed(1:100); sum(.Random.seed)
> > [1] 4070365163
> >
> > I'd like to suggest that set.seed() produces an error if length(seed)
> > > 1.  As a reference, for length(seed) == 0, we get:
> >
> > > set.seed(integer(0))
> > Error in set.seed(integer(0)) : supplied seed is not a valid integer
> >
> > /Henrik
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> --
> Sent from Gmail Mobile
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Sep 17 15:10:16 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 17 Sep 2021 09:10:16 -0400
Subject: [Rd] WISH: set.seed(seed) to produce error if length(seed) != 1
 (now silent)
In-Reply-To: <CAFDcVCRoLiR0tzCyRENOqP2xdYCGoT0Mx7x-vyuBVRArwiatiQ@mail.gmail.com>
References: <CAFDcVCSK1ePJbxK18bk_cbEmPenLeFPVoH52dLS2Qgy8Xa4eQg@mail.gmail.com>
 <CAL6gwnLXBNd=Q8=_ziJfGA1n8n7OeCB4U8Y3SwiZJ7DPs3EDGg@mail.gmail.com>
 <93a456da9ea8443ebd2b775c204910b2@chu-rouen.fr>
 <CAFDcVCRoLiR0tzCyRENOqP2xdYCGoT0Mx7x-vyuBVRArwiatiQ@mail.gmail.com>
Message-ID: <5014898e-98cb-129f-96a0-027de9b465d1@gmail.com>

I'd say a more serious problem would be using set.seed(.Random.seed), 
because the first entry codes for RNGkind, it hardly varies at all.  So 
this sequence could really mislead someone:

 > set.seed(.Random.seed)
 > sum(.Random.seed)
[1] 24428993419

# Use it to get a new .Random.seed value:
 > runif(1)
[1] 0.3842704

 > sum(.Random.seed)
[1] -13435151647

# So let's make things really random, by using the new seed as a seed:
 > set.seed(.Random.seed)
 > sum(.Random.seed)
[1] 24428993419

# Back to the original!

Duncan Murdoch


On 17/09/2021 8:38 a.m., Henrik Bengtsson wrote:
>> I?m curious, other than proper programming practice, why?
> 
> Life's too short for troubleshooting silent mistakes - mine or others.
> 
> While at it, searching the interwebs for use of set.seed(), gives
> mistakes/misunderstandings like using set.seed(<double>), e.g.
> 
>> set.seed(6.1); sum(.Random.seed)
> [1] 73930104
>> set.seed(6.2); sum(.Random.seed)
> [1] 73930104
> 
> which clearly is not what the user expected.  There are also a few
> cases of set.seed(<character>), e.g.
> 
>> set.seed("42"); sum(.Random.seed)
> [1] -2119381568
>> set.seed(42); sum(.Random.seed)
> [1] -2119381568
> 
> which works just because as.numeric("42") is used.
> 
> /Henrik
> 
> On Fri, Sep 17, 2021 at 12:55 PM GILLIBERT, Andre
> <Andre.Gillibert at chu-rouen.fr> wrote:
>>
>> Hello,
>>
>> A vector with a length >= 2 to set.seed would probably be a bug. An error message will help the user to fix his R code. The bug may be accidental or due to bad understanding of the set.seed function. For instance, a user may think that the whole state of the PRNG can be passed to set.seed.
>>
>> The "if" instruction, emits a warning when the condition has length >= 2, because it is often a bug. I would expect a warning or error with set.seed().
>>
>> Validating inputs and emitting errors early is a good practice.
>>
>> Just my 2 cents.
>>
>> Sincerely.
>> Andre GILLIBERT
>>
>> -----Message d'origine-----
>> De : R-devel [mailto:r-devel-bounces at r-project.org] De la part de Avraham Adler
>> Envoy? : vendredi 17 septembre 2021 12:07
>> ? : Henrik Bengtsson
>> Cc : R-devel
>> Objet : Re: [Rd] WISH: set.seed(seed) to produce error if length(seed) != 1 (now silent)
>>
>> Hi, Henrik.
>>
>> I?m curious, other than proper programming practice, why?
>>
>> Avi
>>
>> On Fri, Sep 17, 2021 at 11:48 AM Henrik Bengtsson <
>> henrik.bengtsson at gmail.com> wrote:
>>
>>> Hi,
>>>
>>> according to help("set.seed"), argument 'seed' to set.seed() should be:
>>>
>>>    a single value, interpreted as an integer, or NULL (see ?Details?).
>>>
>>>  From code inspection (src/main/RNG.c) and testing, it turns out that
>>> if you pass a 'seed' with length greater than one, it silently uses
>>> seed[1], e.g.
>>>
>>>> set.seed(1); sum(.Random.seed)
>>> [1] 4070365163
>>>> set.seed(1:3); sum(.Random.seed)
>>> [1] 4070365163
>>>> set.seed(1:100); sum(.Random.seed)
>>> [1] 4070365163
>>>
>>> I'd like to suggest that set.seed() produces an error if length(seed)
>>>> 1.  As a reference, for length(seed) == 0, we get:
>>>
>>>> set.seed(integer(0))
>>> Error in set.seed(integer(0)) : supplied seed is not a valid integer
>>>
>>> /Henrik
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>> --
>> Sent from Gmail Mobile
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From henr|k@bengt@@on @end|ng |rom gm@||@com  Fri Sep 17 15:41:49 2021
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Fri, 17 Sep 2021 15:41:49 +0200
Subject: [Rd] WISH: set.seed(seed) to produce error if length(seed) != 1
 (now silent)
In-Reply-To: <5014898e-98cb-129f-96a0-027de9b465d1@gmail.com>
References: <CAFDcVCSK1ePJbxK18bk_cbEmPenLeFPVoH52dLS2Qgy8Xa4eQg@mail.gmail.com>
 <CAL6gwnLXBNd=Q8=_ziJfGA1n8n7OeCB4U8Y3SwiZJ7DPs3EDGg@mail.gmail.com>
 <93a456da9ea8443ebd2b775c204910b2@chu-rouen.fr>
 <CAFDcVCRoLiR0tzCyRENOqP2xdYCGoT0Mx7x-vyuBVRArwiatiQ@mail.gmail.com>
 <5014898e-98cb-129f-96a0-027de9b465d1@gmail.com>
Message-ID: <CAFDcVCR_ZtYRqA-qW+=Uhfb-fCoAJPW3mo69+ign8RMM7NMOXA@mail.gmail.com>

> I'd say a more serious problem would be using set.seed(.Random.seed) ...

Exactly, I'm pretty sure I also tried that at some point.  This leads
to another thing I wanted to get to, which is to add support for
exactly that case.  So, instead of having poke around with:

globalenv()$.Random.seed <- new_seed

where 'new_seed' is a valid ".Random.seed" seed, it would be
convenient to be able to do just set.seed(new_seed), which comes handy
in parallel processing.

/Henrik

On Fri, Sep 17, 2021 at 3:10 PM Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
> I'd say a more serious problem would be using set.seed(.Random.seed),
> because the first entry codes for RNGkind, it hardly varies at all.  So
> this sequence could really mislead someone:
>
>  > set.seed(.Random.seed)
>  > sum(.Random.seed)
> [1] 24428993419
>
> # Use it to get a new .Random.seed value:
>  > runif(1)
> [1] 0.3842704
>
>  > sum(.Random.seed)
> [1] -13435151647
>
> # So let's make things really random, by using the new seed as a seed:
>  > set.seed(.Random.seed)
>  > sum(.Random.seed)
> [1] 24428993419
>
> # Back to the original!
>
> Duncan Murdoch
>
>
> On 17/09/2021 8:38 a.m., Henrik Bengtsson wrote:
> >> I?m curious, other than proper programming practice, why?
> >
> > Life's too short for troubleshooting silent mistakes - mine or others.
> >
> > While at it, searching the interwebs for use of set.seed(), gives
> > mistakes/misunderstandings like using set.seed(<double>), e.g.
> >
> >> set.seed(6.1); sum(.Random.seed)
> > [1] 73930104
> >> set.seed(6.2); sum(.Random.seed)
> > [1] 73930104
> >
> > which clearly is not what the user expected.  There are also a few
> > cases of set.seed(<character>), e.g.
> >
> >> set.seed("42"); sum(.Random.seed)
> > [1] -2119381568
> >> set.seed(42); sum(.Random.seed)
> > [1] -2119381568
> >
> > which works just because as.numeric("42") is used.
> >
> > /Henrik
> >
> > On Fri, Sep 17, 2021 at 12:55 PM GILLIBERT, Andre
> > <Andre.Gillibert at chu-rouen.fr> wrote:
> >>
> >> Hello,
> >>
> >> A vector with a length >= 2 to set.seed would probably be a bug. An error message will help the user to fix his R code. The bug may be accidental or due to bad understanding of the set.seed function. For instance, a user may think that the whole state of the PRNG can be passed to set.seed.
> >>
> >> The "if" instruction, emits a warning when the condition has length >= 2, because it is often a bug. I would expect a warning or error with set.seed().
> >>
> >> Validating inputs and emitting errors early is a good practice.
> >>
> >> Just my 2 cents.
> >>
> >> Sincerely.
> >> Andre GILLIBERT
> >>
> >> -----Message d'origine-----
> >> De : R-devel [mailto:r-devel-bounces at r-project.org] De la part de Avraham Adler
> >> Envoy? : vendredi 17 septembre 2021 12:07
> >> ? : Henrik Bengtsson
> >> Cc : R-devel
> >> Objet : Re: [Rd] WISH: set.seed(seed) to produce error if length(seed) != 1 (now silent)
> >>
> >> Hi, Henrik.
> >>
> >> I?m curious, other than proper programming practice, why?
> >>
> >> Avi
> >>
> >> On Fri, Sep 17, 2021 at 11:48 AM Henrik Bengtsson <
> >> henrik.bengtsson at gmail.com> wrote:
> >>
> >>> Hi,
> >>>
> >>> according to help("set.seed"), argument 'seed' to set.seed() should be:
> >>>
> >>>    a single value, interpreted as an integer, or NULL (see ?Details?).
> >>>
> >>>  From code inspection (src/main/RNG.c) and testing, it turns out that
> >>> if you pass a 'seed' with length greater than one, it silently uses
> >>> seed[1], e.g.
> >>>
> >>>> set.seed(1); sum(.Random.seed)
> >>> [1] 4070365163
> >>>> set.seed(1:3); sum(.Random.seed)
> >>> [1] 4070365163
> >>>> set.seed(1:100); sum(.Random.seed)
> >>> [1] 4070365163
> >>>
> >>> I'd like to suggest that set.seed() produces an error if length(seed)
> >>>> 1.  As a reference, for length(seed) == 0, we get:
> >>>
> >>>> set.seed(integer(0))
> >>> Error in set.seed(integer(0)) : supplied seed is not a valid integer
> >>>
> >>> /Henrik
> >>>
> >>> ______________________________________________
> >>> R-devel at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>
> >> --
> >> Sent from Gmail Mobile
> >>
> >>          [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>


From @v|gro@@ @end|ng |rom ver|zon@net  Fri Sep 17 22:12:36 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Fri, 17 Sep 2021 16:12:36 -0400
Subject: [Rd] WISH: set.seed(seed) to produce error if length(seed) != 1
 (now silent)
In-Reply-To: <CAFDcVCRoLiR0tzCyRENOqP2xdYCGoT0Mx7x-vyuBVRArwiatiQ@mail.gmail.com>
References: <CAFDcVCSK1ePJbxK18bk_cbEmPenLeFPVoH52dLS2Qgy8Xa4eQg@mail.gmail.com>
 <CAL6gwnLXBNd=Q8=_ziJfGA1n8n7OeCB4U8Y3SwiZJ7DPs3EDGg@mail.gmail.com>
 <93a456da9ea8443ebd2b775c204910b2@chu-rouen.fr>
 <CAFDcVCRoLiR0tzCyRENOqP2xdYCGoT0Mx7x-vyuBVRArwiatiQ@mail.gmail.com>
Message-ID: <017e01d7ac00$5bcabdf0$136039d0$@verizon.net>

R wobbles a bit as there is no normal datatype that is a singleton variable.  Saying x <- 5 just creates a vector of current length 1. It is perfectly legal to then write x [2] <- 6 and so on. The vector lengthens. You can truncate it back to 1, if you wish: length(x) <- 1

So the question here is what happens if you supply more info than is needed? If it is an integer vector of length greater than one, should it ignore everything but the first entry? I note it happily accepts not-quite integers like TRUE and FALSE.  it also accepts floating point numbers like 1.23 or 1.2e5. 

The goal seems to be to set a unique starting point, rounded or transformed if needed. The visible part of the function does not even look at the seed before calling the internal representation. So although superficially choosing the first integer in a vector makes some sense, it can be a problem if a program assumes the entire vector is consumed and perhaps hashed in some way to make a seed. If the program later changes parts of the vector other than the first entry, it may assume re-setting the seed gets something else and yet it may be exactly the same.

So, yes, I suspect it is an ERROR to take anything that cannot be coerced by something like as.integer() into a vector of length 1.

I have noted other places in R where I may get a warning when giving a longer vector that only the fist element will be used.  Are they all problems that need to be addressed?

Here is a short one:

> x <- c(1:3)
> if (x > 2) y <- TRUE
Warning message:
  In if (x > 2) y <- TRUE :
  the condition has length > 1 and only the first element will be used
> y
Error: object 'y' not found

The above is not vectorized and makes the choice of x==1 and thus does not set y.

Now a vectorized variant works as expected, making a vector of length 3 for y:

> x
[1] 1 2 3

> y <- ifelse(x > 2, TRUE, FALSE)
> y
[1] FALSE FALSE  TRUE

I have no doubt fixing lots of this stuff, if indeed it is a fix, can break lots of existing code. Sure, it is not harmful to ask a programmer to always say x[1] to guarantee they are getting what they want, or to add a function like first(x) that does the same. 

R has some compromises or features I sometimes wonder about. If it had a concept of a numeric scalar, then some things that now happen might start being an error.

What happens when you multiply a vector by a scalar as in 5*x is that every component of x is multiplied by 5. but x*x does componentwise multiplication.  So say x is c(1:3) what should this do using a twosome times a threesome?

x[1:2]*x
[1] 1 4 3
Warning message:
  In x[1:2] * x :
  longer object length is not a multiple of shorter object length

Is it recycling to get a 1 in pseudo-position 3?

Yep, this shows recycling:

> x[1:2]*x
[1]  1  4  3  8  5 12  7 16  9
Warning message:
  In x[1:2] * x :
  longer object length is not a multiple of shorter object length

You do get a warning but not telling you what it did.

In essence, the earlier case of 5*x arguably recycled the 5 as many times as needed but with no warning. 

My point is that many languages, especially older ones, were designed a certain way and have been updated but we may be stuck with what we have. A brand new language might come up with a new way that includes vectorizing the heck out of things but allowing and even demanding that you explicitly convert things to a scalar in a context that needs it or to explicitly asking for recycling when you want it or ...




-----Original Message-----
From: R-devel <r-devel-bounces at r-project.org> On Behalf Of Henrik Bengtsson
Sent: Friday, September 17, 2021 8:39 AM
To: GILLIBERT, Andre <Andre.Gillibert at chu-rouen.fr>
Cc: R-devel <r-devel at r-project.org>
Subject: Re: [Rd] WISH: set.seed(seed) to produce error if length(seed) != 1 (now silent)

> I?m curious, other than proper programming practice, why?

Life's too short for troubleshooting silent mistakes - mine or others.

While at it, searching the interwebs for use of set.seed(), gives mistakes/misunderstandings like using set.seed(<double>), e.g.

> set.seed(6.1); sum(.Random.seed)
[1] 73930104
> set.seed(6.2); sum(.Random.seed)
[1] 73930104

which clearly is not what the user expected.  There are also a few cases of set.seed(<character>), e.g.

> set.seed("42"); sum(.Random.seed)
[1] -2119381568
> set.seed(42); sum(.Random.seed)
[1] -2119381568

which works just because as.numeric("42") is used.

/Henrik

On Fri, Sep 17, 2021 at 12:55 PM GILLIBERT, Andre <Andre.Gillibert at chu-rouen.fr> wrote:
>
> Hello,
>
> A vector with a length >= 2 to set.seed would probably be a bug. An error message will help the user to fix his R code. The bug may be accidental or due to bad understanding of the set.seed function. For instance, a user may think that the whole state of the PRNG can be passed to set.seed.
>
> The "if" instruction, emits a warning when the condition has length >= 2, because it is often a bug. I would expect a warning or error with set.seed().
>
> Validating inputs and emitting errors early is a good practice.
>
> Just my 2 cents.
>
> Sincerely.
> Andre GILLIBERT
>
> -----Message d'origine-----
> De : R-devel [mailto:r-devel-bounces at r-project.org] De la part de 
> Avraham Adler Envoy? : vendredi 17 septembre 2021 12:07 ? : Henrik 
> Bengtsson Cc : R-devel Objet : Re: [Rd] WISH: set.seed(seed) to 
> produce error if length(seed) != 1 (now silent)
>
> Hi, Henrik.
>
> I?m curious, other than proper programming practice, why?
>
> Avi
>
> On Fri, Sep 17, 2021 at 11:48 AM Henrik Bengtsson < 
> henrik.bengtsson at gmail.com> wrote:
>
> > Hi,
> >
> > according to help("set.seed"), argument 'seed' to set.seed() should be:
> >
> >   a single value, interpreted as an integer, or NULL (see ?Details?).
> >
> > From code inspection (src/main/RNG.c) and testing, it turns out that 
> > if you pass a 'seed' with length greater than one, it silently uses 
> > seed[1], e.g.
> >
> > > set.seed(1); sum(.Random.seed)
> > [1] 4070365163
> > > set.seed(1:3); sum(.Random.seed)
> > [1] 4070365163
> > > set.seed(1:100); sum(.Random.seed)
> > [1] 4070365163
> >
> > I'd like to suggest that set.seed() produces an error if 
> > length(seed)
> > > 1.  As a reference, for length(seed) == 0, we get:
> >
> > > set.seed(integer(0))
> > Error in set.seed(integer(0)) : supplied seed is not a valid integer
> >
> > /Henrik
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> --
> Sent from Gmail Mobile
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From j@ke@e|m@tedt @end|ng |rom gm@||@com  Fri Sep 17 23:57:18 2021
From: j@ke@e|m@tedt @end|ng |rom gm@||@com (Jake Elmstedt)
Date: Fri, 17 Sep 2021 14:57:18 -0700
Subject: [Rd] WISH: set.seed(seed) to produce error if length(seed) != 1
 (now silent)
In-Reply-To: <017e01d7ac00$5bcabdf0$136039d0$@verizon.net>
References: <CAFDcVCSK1ePJbxK18bk_cbEmPenLeFPVoH52dLS2Qgy8Xa4eQg@mail.gmail.com>
 <CAL6gwnLXBNd=Q8=_ziJfGA1n8n7OeCB4U8Y3SwiZJ7DPs3EDGg@mail.gmail.com>
 <93a456da9ea8443ebd2b775c204910b2@chu-rouen.fr>
 <CAFDcVCRoLiR0tzCyRENOqP2xdYCGoT0Mx7x-vyuBVRArwiatiQ@mail.gmail.com>
 <017e01d7ac00$5bcabdf0$136039d0$@verizon.net>
Message-ID: <CAPTrVR7YqgUZPzwU1yH9N8gUEwrvK_-mVOswSwG3mp_a+2ZNZg@mail.gmail.com>

What about splitting the baby and having set.seed(1:2), set.seed(6.1),
etc. issue a warning rather than throw an error?

It informs the user that their expectations have deviated from
reality, encourages proper programming practices, and carries
substantially lower risk of breaking things than an exception.


On Fri, Sep 17, 2021 at 1:13 PM Avi Gross via R-devel
<r-devel at r-project.org> wrote:
>
> R wobbles a bit as there is no normal datatype that is a singleton variable.  Saying x <- 5 just creates a vector of current length 1. It is perfectly legal to then write x [2] <- 6 and so on. The vector lengthens. You can truncate it back to 1, if you wish: length(x) <- 1
>
> So the question here is what happens if you supply more info than is needed? If it is an integer vector of length greater than one, should it ignore everything but the first entry? I note it happily accepts not-quite integers like TRUE and FALSE.  it also accepts floating point numbers like 1.23 or 1.2e5.
>
> The goal seems to be to set a unique starting point, rounded or transformed if needed. The visible part of the function does not even look at the seed before calling the internal representation. So although superficially choosing the first integer in a vector makes some sense, it can be a problem if a program assumes the entire vector is consumed and perhaps hashed in some way to make a seed. If the program later changes parts of the vector other than the first entry, it may assume re-setting the seed gets something else and yet it may be exactly the same.
>
> So, yes, I suspect it is an ERROR to take anything that cannot be coerced by something like as.integer() into a vector of length 1.
>
> I have noted other places in R where I may get a warning when giving a longer vector that only the fist element will be used.  Are they all problems that need to be addressed?
>
> Here is a short one:
>
> > x <- c(1:3)
> > if (x > 2) y <- TRUE
> Warning message:
>   In if (x > 2) y <- TRUE :
>   the condition has length > 1 and only the first element will be used
> > y
> Error: object 'y' not found
>
> The above is not vectorized and makes the choice of x==1 and thus does not set y.
>
> Now a vectorized variant works as expected, making a vector of length 3 for y:
>
> > x
> [1] 1 2 3
>
> > y <- ifelse(x > 2, TRUE, FALSE)
> > y
> [1] FALSE FALSE  TRUE
>
> I have no doubt fixing lots of this stuff, if indeed it is a fix, can break lots of existing code. Sure, it is not harmful to ask a programmer to always say x[1] to guarantee they are getting what they want, or to add a function like first(x) that does the same.
>
> R has some compromises or features I sometimes wonder about. If it had a concept of a numeric scalar, then some things that now happen might start being an error.
>
> What happens when you multiply a vector by a scalar as in 5*x is that every component of x is multiplied by 5. but x*x does componentwise multiplication.  So say x is c(1:3) what should this do using a twosome times a threesome?
>
> x[1:2]*x
> [1] 1 4 3
> Warning message:
>   In x[1:2] * x :
>   longer object length is not a multiple of shorter object length
>
> Is it recycling to get a 1 in pseudo-position 3?
>
> Yep, this shows recycling:
>
> > x[1:2]*x
> [1]  1  4  3  8  5 12  7 16  9
> Warning message:
>   In x[1:2] * x :
>   longer object length is not a multiple of shorter object length
>
> You do get a warning but not telling you what it did.
>
> In essence, the earlier case of 5*x arguably recycled the 5 as many times as needed but with no warning.
>
> My point is that many languages, especially older ones, were designed a certain way and have been updated but we may be stuck with what we have. A brand new language might come up with a new way that includes vectorizing the heck out of things but allowing and even demanding that you explicitly convert things to a scalar in a context that needs it or to explicitly asking for recycling when you want it or ...
>
>
>
>
> -----Original Message-----
> From: R-devel <r-devel-bounces at r-project.org> On Behalf Of Henrik Bengtsson
> Sent: Friday, September 17, 2021 8:39 AM
> To: GILLIBERT, Andre <Andre.Gillibert at chu-rouen.fr>
> Cc: R-devel <r-devel at r-project.org>
> Subject: Re: [Rd] WISH: set.seed(seed) to produce error if length(seed) != 1 (now silent)
>
> > I?m curious, other than proper programming practice, why?
>
> Life's too short for troubleshooting silent mistakes - mine or others.
>
> While at it, searching the interwebs for use of set.seed(), gives mistakes/misunderstandings like using set.seed(<double>), e.g.
>
> > set.seed(6.1); sum(.Random.seed)
> [1] 73930104
> > set.seed(6.2); sum(.Random.seed)
> [1] 73930104
>
> which clearly is not what the user expected.  There are also a few cases of set.seed(<character>), e.g.
>
> > set.seed("42"); sum(.Random.seed)
> [1] -2119381568
> > set.seed(42); sum(.Random.seed)
> [1] -2119381568
>
> which works just because as.numeric("42") is used.
>
> /Henrik
>
> On Fri, Sep 17, 2021 at 12:55 PM GILLIBERT, Andre <Andre.Gillibert at chu-rouen.fr> wrote:
> >
> > Hello,
> >
> > A vector with a length >= 2 to set.seed would probably be a bug. An error message will help the user to fix his R code. The bug may be accidental or due to bad understanding of the set.seed function. For instance, a user may think that the whole state of the PRNG can be passed to set.seed.
> >
> > The "if" instruction, emits a warning when the condition has length >= 2, because it is often a bug. I would expect a warning or error with set.seed().
> >
> > Validating inputs and emitting errors early is a good practice.
> >
> > Just my 2 cents.
> >
> > Sincerely.
> > Andre GILLIBERT
> >
> > -----Message d'origine-----
> > De : R-devel [mailto:r-devel-bounces at r-project.org] De la part de
> > Avraham Adler Envoy? : vendredi 17 septembre 2021 12:07 ? : Henrik
> > Bengtsson Cc : R-devel Objet : Re: [Rd] WISH: set.seed(seed) to
> > produce error if length(seed) != 1 (now silent)
> >
> > Hi, Henrik.
> >
> > I?m curious, other than proper programming practice, why?
> >
> > Avi
> >
> > On Fri, Sep 17, 2021 at 11:48 AM Henrik Bengtsson <
> > henrik.bengtsson at gmail.com> wrote:
> >
> > > Hi,
> > >
> > > according to help("set.seed"), argument 'seed' to set.seed() should be:
> > >
> > >   a single value, interpreted as an integer, or NULL (see ?Details?).
> > >
> > > From code inspection (src/main/RNG.c) and testing, it turns out that
> > > if you pass a 'seed' with length greater than one, it silently uses
> > > seed[1], e.g.
> > >
> > > > set.seed(1); sum(.Random.seed)
> > > [1] 4070365163
> > > > set.seed(1:3); sum(.Random.seed)
> > > [1] 4070365163
> > > > set.seed(1:100); sum(.Random.seed)
> > > [1] 4070365163
> > >
> > > I'd like to suggest that set.seed() produces an error if
> > > length(seed)
> > > > 1.  As a reference, for length(seed) == 0, we get:
> > >
> > > > set.seed(integer(0))
> > > Error in set.seed(integer(0)) : supplied seed is not a valid integer
> > >
> > > /Henrik
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > >
> > --
> > Sent from Gmail Mobile
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From yut@n|@|n| @end|ng |rom gm@||@com  Mon Sep 20 11:03:05 2021
From: yut@n|@|n| @end|ng |rom gm@||@com (Hiroaki Yutani)
Date: Mon, 20 Sep 2021 18:03:05 +0900
Subject: [Rd] Detect UCRT-built R from within R sessions (and in
 configure.win)
In-Reply-To: <CALyqOb8FaPfVMU1-0BzXdNwrgMQtv+t5uiacasdQo=SZSQ4pug@mail.gmail.com>
References: <CALyqOb8r7ajAumf5V0+YJk83X091NS2eRCs-cu=X6zO+09z0Rg@mail.gmail.com>
 <a219a307-5200-a13e-b4d9-a1e7a646e137@gmail.com>
 <CALyqOb8yer26avLG8wmGxpFQgEeYtxaPGOnixpYTssAJiOLfDA@mail.gmail.com>
 <d722d393-94e0-370b-e7bd-ca96e708a205@gmail.com>
 <CALyqOb8FaPfVMU1-0BzXdNwrgMQtv+t5uiacasdQo=SZSQ4pug@mail.gmail.com>
Message-ID: <CALyqOb9zyhg7_uiBbiaNwMo2333Qw7g_bRvv5cQGFfm94O+0Mw@mail.gmail.com>

I tried to use configure.ucrt, and found it results in the following
NOTE on the released version of R, unfortunately.

    * checking top-level files ... NOTE
    Non-standard file/directory found at top level:
    'configure.ucrt'

Will this be accepted by CRAN if I submit a package that contains
configure.ucrt? Or, is it too early to use it in a CRAN package?

In either case, while I don't have a strong opinion here, I'm starting
to feel that it might be preferable to provide an environmental
variable rather than creating ".ucrt" versions of files. In my
understanding, the plan is to switch all the Windows R to UCRT at some
point in future. But, it's not clear to me how to unify these ".win"
files and ".ucrt" files smoothly.

Best,
Hiroaki Yutani

2021?9?14?(?) 23:44 Hiroaki Yutani <yutani.ini at gmail.com>:

>
> Thanks for both, I'll try these features.
>
> 2021?9?14?(?) 22:40 Tomas Kalibera <tomas.kalibera at gmail.com>:
>
> >
> >
> > On 9/9/21 5:54 AM, Hiroaki Yutani wrote:
> >
> > Thank you for the prompt reply.
> >
> > > There in not such a mechanism, yet, but can be added, at least for
> > > diagnostics.
> >
> > For example, can R.version somehow contain the information?
> >
> > Yes, now added to the experimental builds. R.version$crt contains "ucrt" (and would contain "msvcrt" if R was built against MSVCRT).
> >
> >
> > > We could add support for configure.ucrt, which would take precedence
> > > over configure.win on the UCRT builds (like Makevars.ucrt takes
> > > precedence over Makevars.win). Would that work for you?
> >
> > Yes, configure.ucrt should work for me. There might be someone who prefers to switch by some envvar rather than creating another file, but I don't have a strong opinion here.
> >
> > The experimental builds now support configure.ucrt and cleanup.ucrt files.
> >
> > Best
> > Tomas
> >
> >
> > Best,
> > Hiroaki Yutani
> >
> > 2021?9?9?(?) 0:48 Tomas Kalibera <tomas.kalibera at gmail.com>:
> >>
> >>
> >> On 9/8/21 2:08 PM, Hiroaki Yutani wrote:
> >> > Hi,
> >> >
> >> > Are there any proper ways to know whether the session is running on
> >> > the R that is built with the UCRT toolchain or not? Checking if the
> >> > encoding is UTF-8 might do the trick, but I'm not sure if it's always
> >> > reliable.
> >>
> >> There in not such a mechanism, yet, but can be added, at least for
> >> diagnostics.
> >>
> >> You are right that checking for UTF-8 encoding would not always be
> >> reliable. For example, the version of Windows may be too old to allow R
> >> use UTF-8 as native encoding (e.g. Windows server 2016), then R will use
> >> the native code page as it does today in the MSVCRT builds.
> >>
> >> > Also, I'd like to know if there's any mechanism to detect the UCRT in
> >> > configure.win. I know there are Makevars.ucrt and Makefile.ucrt, but
> >> > one might want to do some feature test that is specific to the UCRT
> >> > toolchain.
> >>
> >> We could add support for configure.ucrt, which would take precedence
> >> over configure.win on the UCRT builds (like Makevars.ucrt takes
> >> precedence over Makevars.win). Would that work for you?
> >>
> >> Best
> >> Tomas
> >>
> >> >
> >> > Best,
> >> > Hiroaki Yutani
> >> >
> >> > ______________________________________________
> >> > R-devel at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-devel


From m|ke @end|ng |rom m|ke@p|@ce  Tue Sep 21 06:35:29 2021
From: m|ke @end|ng |rom m|ke@p|@ce (Mike Lee Williams)
Date: Mon, 20 Sep 2021 21:35:29 -0700
Subject: [Rd] Segfault in setMask in R 4.1
Message-ID: <eb72f226-4b87-4038-bf83-7f9ab5a512b8@www.fastmail.com>

I have inherited a build of R. We compile R from source and then use a custom
web application to allow users to enter R statements and render the output (it's
kind of like RStudio although the UX is quite different).

Things were going fine until I tried to upgrade to R 4.1.x. The build succeeds,
but I get the following segfault when I make qplot (ggplot2) calls:

     *** caught segfault ***
    address (nil), cause 'memory not mapped'

    Traceback:
     1: .setMask(NULL, NULL)
     2: resolveMask.NULL(NULL)
     3: (function (path) {    UseMethod("resolveMask")})(NULL)
     4: grid.newpage()
     5: print.ggplot(x)
     6: (function (x, ...) UseMethod("print"))(x)

I am not an R developer, so I don't really know how to read this. I am wondering
if this is a known issue or if anyone has any suggestions. Here's some things
I've tested:

- I get the same segfault in R 4.1.0 and R 4.1.1. I do not get this error in R
  4.0.4 or R 4.0.5.

- The problem appears to be specific to the (graphics?) features of R that
  ggplot2 uses. I do not get a segfault if I do a generic `plot(c(1,2,3))`.

- I have tried versions of ggplot2 3.3.3 and 3.3.5.

- The traceback points to files that were introduced in this commit
  https://github.com/wch/r-source/commit/16755bcddffe0cb4238d8a4979387d92b93a8324#diff-5c63f74229830cdde7886a50bf06dafcdf1d5b3d42cfa06b26814876e58c5ab0

I am not an R user or R developer so I'm a bit stuck here. I would be happy to
give the output of any commands. If anyone has any suggestions then please let
me know!

Thanks!
Mike Lee Williams


From Andre@G||||bert @end|ng |rom chu-rouen@|r  Tue Sep 21 12:37:29 2021
From: Andre@G||||bert @end|ng |rom chu-rouen@|r (GILLIBERT, Andre)
Date: Tue, 21 Sep 2021 10:37:29 +0000
Subject: [Rd] Segfault in setMask in R 4.1
In-Reply-To: <eb72f226-4b87-4038-bf83-7f9ab5a512b8@www.fastmail.com>
References: <eb72f226-4b87-4038-bf83-7f9ab5a512b8@www.fastmail.com>
Message-ID: <0ecbe616f10e40e9a8134c39ec38ffcb@chu-rouen.fr>

Hello,

Which graphic device (backend) do you use?
The setMask() function calls the internal setMask function associated to the graphic device.
If the Web application uses one of the standard graphic backend, the bug may come from the R core. If it uses a custom graphic backend, the bug may be in the backend.

-- 
Sincerely
Andr? GILLIBERT

ATTENTION: Cet e-mail provient d?une adresse mail ext?rieure au CHU de Rouen. Ne cliquez pas sur les liens ou n'ouvrez pas les pi?ces jointes ? moins de conna?tre l'exp?diteur et de savoir que le contenu est s?r. En cas de doute, transf?rer le mail ? ? DSI, S?curit? ? pour analyse. Merci de votre vigilance


I have inherited a build of R. We compile R from source and then use a custom
web application to allow users to enter R statements and render the output (it's
kind of like RStudio although the UX is quite different).

Things were going fine until I tried to upgrade to R 4.1.x. The build succeeds,
but I get the following segfault when I make qplot (ggplot2) calls:

     *** caught segfault ***
    address (nil), cause 'memory not mapped'

    Traceback:
     1: .setMask(NULL, NULL)
     2: resolveMask.NULL(NULL)
     3: (function (path) {    UseMethod("resolveMask")})(NULL)
     4: grid.newpage()
     5: print.ggplot(x)
     6: (function (x, ...) UseMethod("print"))(x)

I am not an R developer, so I don't really know how to read this. I am wondering
if this is a known issue or if anyone has any suggestions. Here's some things
I've tested:

- I get the same segfault in R 4.1.0 and R 4.1.1. I do not get this error in R
  4.0.4 or R 4.0.5.

- The problem appears to be specific to the (graphics?) features of R that
  ggplot2 uses. I do not get a segfault if I do a generic `plot(c(1,2,3))`.

- I have tried versions of ggplot2 3.3.3 and 3.3.5.

- The traceback points to files that were introduced in this commit
  https://github.com/wch/r-source/commit/16755bcddffe0cb4238d8a4979387d92b93a8324#diff-5c63f74229830cdde7886a50bf06dafcdf1d5b3d42cfa06b26814876e58c5ab0

I am not an R user or R developer so I'm a bit stuck here. I would be happy to
give the output of any commands. If anyone has any suggestions then please let
me know!

Thanks!
Mike Lee Williams

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From m|ke @end|ng |rom m|ke@p|@ce  Tue Sep 21 18:52:12 2021
From: m|ke @end|ng |rom m|ke@p|@ce (Mike Lee Williams)
Date: Tue, 21 Sep 2021 09:52:12 -0700
Subject: [Rd] Segfault in setMask in R 4.1
In-Reply-To: <0ecbe616f10e40e9a8134c39ec38ffcb@chu-rouen.fr>
References: <eb72f226-4b87-4038-bf83-7f9ab5a512b8@www.fastmail.com>
 <0ecbe616f10e40e9a8134c39ec38ffcb@chu-rouen.fr>
Message-ID: <bc1d9f50-e6c6-491a-b234-adc64ffcf9d6@www.fastmail.com>

Thank you! Here is the output of option("devices"), which I think means we're using Cairo:

    $device
    function (width = 1280, height = 960, pointsize = 24, units = "px", 
        bg = "white", dpi = 160, ...) 
    {
        devSym <- basename(tempfile(pattern = "SensePlot", tmpdir = ""))
        newDev <- Cairo(width = width, height = height, pointsize = pointsize, 
            bg = bg, units = units, dpi = dpi, type = "raster", ...)
        attr(newDev, "units") <- units
        attr(newDev, "dpi") <- dpi
        assign(devSym, newDev, SenseDevices)
        invisible(newDev)
    }
    <bytecode: 0x55b08ba031c0>
    <environment: namespace:Cairo>

"Sense" is the internal name of our application. I'm not sure what "devSym" and "newDev" are, but If there are no known issues with Cairo itself then our own code is presumably part of the problem.

I would like to confirm that by failing to reproduce the bug in "vanilla" R 4.1 with a Cairo device. If anyone has any tips for how to do that (on Linux) or any other comments I would be very grateful.

If our code is the problem then I'm still confused why a regular plot() works, but a ggplot2 qplot() segfaults. Maybe this is a clue!

I will post again if I figure anything out!

Mike

On Tue, Sep 21, 2021, at 3:37 AM, GILLIBERT, Andre wrote:
> Hello,
>
> Which graphic device (backend) do you use?
> The setMask() function calls the internal setMask function associated 
> to the graphic device.
> If the Web application uses one of the standard graphic backend, the 
> bug may come from the R core. If it uses a custom graphic backend, the 
> bug may be in the backend.
>
> -- 
> Sincerely
> Andr? GILLIBERT
>
> ATTENTION: Cet e-mail provient d?une adresse mail ext?rieure au CHU de 
> Rouen. Ne cliquez pas sur les liens ou n'ouvrez pas les pi?ces jointes 
> ? moins de conna?tre l'exp?diteur et de savoir que le contenu est s?r. 
> En cas de doute, transf?rer le mail ? ? DSI, S?curit? ? pour analyse. 
> Merci de votre vigilance
>
>
> I have inherited a build of R. We compile R from source and then use a custom
> web application to allow users to enter R statements and render the output (it's
> kind of like RStudio although the UX is quite different).
>
> Things were going fine until I tried to upgrade to R 4.1.x. The build succeeds,
> but I get the following segfault when I make qplot (ggplot2) calls:
>
>      *** caught segfault ***
>     address (nil), cause 'memory not mapped'
>
>     Traceback:
>      1: .setMask(NULL, NULL)
>      2: resolveMask.NULL(NULL)
>      3: (function (path) {    UseMethod("resolveMask")})(NULL)
>      4: grid.newpage()
>      5: print.ggplot(x)
>      6: (function (x, ...) UseMethod("print"))(x)
>
> I am not an R developer, so I don't really know how to read this. I am wondering
> if this is a known issue or if anyone has any suggestions. Here's some things
> I've tested:
>
> - I get the same segfault in R 4.1.0 and R 4.1.1. I do not get this error in R
>   4.0.4 or R 4.0.5.
>
> - The problem appears to be specific to the (graphics?) features of R that
>   ggplot2 uses. I do not get a segfault if I do a generic `plot(c(1,2,3))`.
>
> - I have tried versions of ggplot2 3.3.3 and 3.3.5.
>
> - The traceback points to files that were introduced in this commit
>   
> https://github.com/wch/r-source/commit/16755bcddffe0cb4238d8a4979387d92b93a8324#diff-5c63f74229830cdde7886a50bf06dafcdf1d5b3d42cfa06b26814876e58c5ab0
>
> I am not an R user or R developer so I'm a bit stuck here. I would be happy to
> give the output of any commands. If anyone has any suggestions then please let
> me know!
>
> Thanks!
> Mike Lee Williams
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz  Tue Sep 21 22:41:30 2021
From: p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz (Paul Murrell)
Date: Wed, 22 Sep 2021 08:41:30 +1200
Subject: [Rd] Segfault in setMask in R 4.1
In-Reply-To: <bc1d9f50-e6c6-491a-b234-adc64ffcf9d6@www.fastmail.com>
References: <eb72f226-4b87-4038-bf83-7f9ab5a512b8@www.fastmail.com>
 <0ecbe616f10e40e9a8134c39ec38ffcb@chu-rouen.fr>
 <bc1d9f50-e6c6-491a-b234-adc64ffcf9d6@www.fastmail.com>
Message-ID: <818dbef8-5c6c-f655-1abd-568cd4eab16d@stat.auckland.ac.nz>

Hi

dev->setMask() was introduced in R 4.1.0 ...

https://developer.r-project.org/Blog/public/2020/07/15/new-features-in-the-r-graphics-engine/

https://www.stat.auckland.ac.nz/~paul/Reports/GraphicsEngine/definitions/definitions.html

If your application is using its own custom graphics device, it will 
need updating, see ...

https://www.stat.auckland.ac.nz/~paul/Reports/GraphicsEngine/definitions/definitions.html#devices

But it looks like you may just be using the graphics device provided by 
the 'Cairo' package, which has already been updated.   If that is the 
case, your problem may be solved simply be reinstalling the 'Cairo' package.

Paul

p.s. the reason why it only happens for 'ggplot2' plots is that only 
'grid' (which underlies 'ggplot2') attempts to set masks (the 'graphics' 
package does not).

On 9/22/2021 4:52 AM, Mike Lee Williams wrote:
> Thank you! Here is the output of option("devices"), which I think means 
> we're using Cairo:
> 
> $device
> function (width = 1280, height = 960, pointsize = 24, units = "px",
> bg = "white", dpi = 160, ...)
> {
> devSym <- basename(tempfile(pattern = "SensePlot", tmpdir = ""))
> newDev <- Cairo(width = width, height = height, pointsize = pointsize,
> bg = bg, units = units, dpi = dpi, type = "raster", ...)
> attr(newDev, "units") <- units
> attr(newDev, "dpi") <- dpi
> assign(devSym, newDev, SenseDevices)
> invisible(newDev)
> }
> <bytecode: 0x55b08ba031c0>
> <environment: namespace:Cairo>
> 
> "Sense" is the internal name of our application. I'm not sure what 
> "devSym" and "newDev" are, but If there are no known issues with Cairo 
> itself then our own code is presumably part of the problem.
> 
> I would like to confirm that by failing to reproduce the bug in 
> "vanilla" R 4.1 with a Cairo device. If anyone has any tips for how to 
> do that (on Linux) or any other comments I would be very grateful.
> 
> If our code is the problem then I'm still confused why a regular plot() 
> works, but a ggplot2 qplot() segfaults. Maybe this is a clue!
> 
> I will post again if I figure anything out!
> 
> Mike
> 
> On Tue, Sep 21, 2021, at 3:37 AM, GILLIBERT, Andre wrote:
>  > Hello,
>  >
>  > Which graphic device (backend) do you use?
>  > The setMask() function calls the internal setMask function associated
>  > to the graphic device.
>  > If the Web application uses one of the standard graphic backend, the
>  > bug may come from the R core. If it uses a custom graphic backend, the
>  > bug may be in the backend.
>  >
>  > --
>  > Sincerely
>  > Andr? GILLIBERT
>  >
>  > ATTENTION: Cet e-mail provient d?une adresse mail ext?rieure au CHU de
>  > Rouen. Ne cliquez pas sur les liens ou n'ouvrez pas les pi?ces jointes
>  > ? moins de conna?tre l'exp?diteur et de savoir que le contenu est s?r.
>  > En cas de doute, transf?rer le mail ? ? DSI, S?curit? ? pour analyse.
>  > Merci de votre vigilance
>  >
>  >
>  > I have inherited a build of R. We compile R from source and then use 
> a custom
>  > web application to allow users to enter R statements and render the 
> output (it's
>  > kind of like RStudio although the UX is quite different).
>  >
>  > Things were going fine until I tried to upgrade to R 4.1.x. The build 
> succeeds,
>  > but I get the following segfault when I make qplot (ggplot2) calls:
>  >
>  > *** caught segfault ***
>  > address (nil), cause 'memory not mapped'
>  >
>  > Traceback:
>  > 1: .setMask(NULL, NULL)
>  > 2: resolveMask.NULL(NULL)
>  > 3: (function (path) { UseMethod("resolveMask")})(NULL)
>  > 4: grid.newpage()
>  > 5: print.ggplot(x)
>  > 6: (function (x, ...) UseMethod("print"))(x)
>  >
>  > I am not an R developer, so I don't really know how to read this. I 
> am wondering
>  > if this is a known issue or if anyone has any suggestions. Here's 
> some things
>  > I've tested:
>  >
>  > - I get the same segfault in R 4.1.0 and R 4.1.1. I do not get this 
> error in R
>  > 4.0.4 or R 4.0.5.
>  >
>  > - The problem appears to be specific to the (graphics?) features of R 
> that
>  > ggplot2 uses. I do not get a segfault if I do a generic `plot(c(1,2,3))`.
>  >
>  > - I have tried versions of ggplot2 3.3.3 and 3.3.5.
>  >
>  > - The traceback points to files that were introduced in this commit
>  >
>  > 
> https://github.com/wch/r-source/commit/16755bcddffe0cb4238d8a4979387d92b93a8324#diff-5c63f74229830cdde7886a50bf06dafcdf1d5b3d42cfa06b26814876e58c5ab0 
> <https://github.com/wch/r-source/commit/16755bcddffe0cb4238d8a4979387d92b93a8324#diff-5c63f74229830cdde7886a50bf06dafcdf1d5b3d42cfa06b26814876e58c5ab0>
>  >
>  > I am not an R user or R developer so I'm a bit stuck here. I would be 
> happy to
>  > give the output of any commands. If anyone has any suggestions then 
> please let
>  > me know!
>  >
>  > Thanks!
>  > Mike Lee Williams
>  >
>  > ______________________________________________
>  > R-devel at r-project.org mailing list
>  > https://stat.ethz.ch/mailman/listinfo/r-devel 
> <https://stat.ethz.ch/mailman/listinfo/r-devel>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel 
> <https://stat.ethz.ch/mailman/listinfo/r-devel>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From m|ke @end|ng |rom m|ke@p|@ce  Tue Sep 21 23:08:56 2021
From: m|ke @end|ng |rom m|ke@p|@ce (Mike Lee Williams)
Date: Tue, 21 Sep 2021 14:08:56 -0700
Subject: [Rd] Segfault in setMask in R 4.1
In-Reply-To: <818dbef8-5c6c-f655-1abd-568cd4eab16d@stat.auckland.ac.nz>
References: <eb72f226-4b87-4038-bf83-7f9ab5a512b8@www.fastmail.com>
 <0ecbe616f10e40e9a8134c39ec38ffcb@chu-rouen.fr>
 <bc1d9f50-e6c6-491a-b234-adc64ffcf9d6@www.fastmail.com>
 <818dbef8-5c6c-f655-1abd-568cd4eab16d@stat.auckland.ac.nz>
Message-ID: <768701f2-2fd4-4641-b1ea-e1f7e4287a3e@www.fastmail.com>

Thanks! AFAICT I am already using the latest version of Cairo, but these links gives me a ton of leads to follow up.

One question (which may be better directed at the maintainer of Cairo): exactly which version (or commit) of Cairo implements support for the new setMask API?

CRAN still points to 1.5-12.2. The NEWS file (https://www.rforge.net/Cairo/news.html) refers to changes implemented to support R 4.0.0 in Cairo 1.5-12, but my understanding is that setMask was added in R 4.1.0.

I see no mention of changes to support setMask or R 4.1.x in Cairo 1.5-13 (not on CRAN yet, but the only release since 1.5-12 according to the NEWS file). The 1.5-13 tarball at https://www.rforge.net/Cairo/files/ contains no mention of strings like "setMask", "releasePattern" or "setPattern", which seem like they should be in there if that version has implemented support for the new API.

Mike

On Tue, Sep 21, 2021, at 1:41 PM, Paul Murrell wrote:
> Hi
>
> dev->setMask() was introduced in R 4.1.0 ...
>
> https://developer.r-project.org/Blog/public/2020/07/15/new-features-in-the-r-graphics-engine/
>
> https://www.stat.auckland.ac.nz/~paul/Reports/GraphicsEngine/definitions/definitions.html
>
> If your application is using its own custom graphics device, it will 
> need updating, see ...
>
> https://www.stat.auckland.ac.nz/~paul/Reports/GraphicsEngine/definitions/definitions.html#devices
>
> But it looks like you may just be using the graphics device provided by 
> the 'Cairo' package, which has already been updated.   If that is the 
> case, your problem may be solved simply be reinstalling the 'Cairo' package.
>
> Paul
>
> p.s. the reason why it only happens for 'ggplot2' plots is that only 
> 'grid' (which underlies 'ggplot2') attempts to set masks (the 'graphics' 
> package does not).
>
> On 9/22/2021 4:52 AM, Mike Lee Williams wrote:
>> Thank you! Here is the output of option("devices"), which I think means 
>> we're using Cairo:
>> 
>> $device
>> function (width = 1280, height = 960, pointsize = 24, units = "px",
>> bg = "white", dpi = 160, ...)
>> {
>> devSym <- basename(tempfile(pattern = "SensePlot", tmpdir = ""))
>> newDev <- Cairo(width = width, height = height, pointsize = pointsize,
>> bg = bg, units = units, dpi = dpi, type = "raster", ...)
>> attr(newDev, "units") <- units
>> attr(newDev, "dpi") <- dpi
>> assign(devSym, newDev, SenseDevices)
>> invisible(newDev)
>> }
>> <bytecode: 0x55b08ba031c0>
>> <environment: namespace:Cairo>
>> 
>> "Sense" is the internal name of our application. I'm not sure what 
>> "devSym" and "newDev" are, but If there are no known issues with Cairo 
>> itself then our own code is presumably part of the problem.
>> 
>> I would like to confirm that by failing to reproduce the bug in 
>> "vanilla" R 4.1 with a Cairo device. If anyone has any tips for how to 
>> do that (on Linux) or any other comments I would be very grateful.
>> 
>> If our code is the problem then I'm still confused why a regular plot() 
>> works, but a ggplot2 qplot() segfaults. Maybe this is a clue!
>> 
>> I will post again if I figure anything out!
>> 
>> Mike
>> 
>> On Tue, Sep 21, 2021, at 3:37 AM, GILLIBERT, Andre wrote:
>>  > Hello,
>>  >
>>  > Which graphic device (backend) do you use?
>>  > The setMask() function calls the internal setMask function associated
>>  > to the graphic device.
>>  > If the Web application uses one of the standard graphic backend, the
>>  > bug may come from the R core. If it uses a custom graphic backend, the
>>  > bug may be in the backend.
>>  >
>>  > --
>>  > Sincerely
>>  > Andr? GILLIBERT
>>  >
>>  > ATTENTION: Cet e-mail provient d?une adresse mail ext?rieure au CHU de
>>  > Rouen. Ne cliquez pas sur les liens ou n'ouvrez pas les pi?ces jointes
>>  > ? moins de conna?tre l'exp?diteur et de savoir que le contenu est s?r.
>>  > En cas de doute, transf?rer le mail ? ? DSI, S?curit? ? pour analyse.
>>  > Merci de votre vigilance
>>  >
>>  >
>>  > I have inherited a build of R. We compile R from source and then use 
>> a custom
>>  > web application to allow users to enter R statements and render the 
>> output (it's
>>  > kind of like RStudio although the UX is quite different).
>>  >
>>  > Things were going fine until I tried to upgrade to R 4.1.x. The build 
>> succeeds,
>>  > but I get the following segfault when I make qplot (ggplot2) calls:
>>  >
>>  > *** caught segfault ***
>>  > address (nil), cause 'memory not mapped'
>>  >
>>  > Traceback:
>>  > 1: .setMask(NULL, NULL)
>>  > 2: resolveMask.NULL(NULL)
>>  > 3: (function (path) { UseMethod("resolveMask")})(NULL)
>>  > 4: grid.newpage()
>>  > 5: print.ggplot(x)
>>  > 6: (function (x, ...) UseMethod("print"))(x)
>>  >
>>  > I am not an R developer, so I don't really know how to read this. I 
>> am wondering
>>  > if this is a known issue or if anyone has any suggestions. Here's 
>> some things
>>  > I've tested:
>>  >
>>  > - I get the same segfault in R 4.1.0 and R 4.1.1. I do not get this 
>> error in R
>>  > 4.0.4 or R 4.0.5.
>>  >
>>  > - The problem appears to be specific to the (graphics?) features of R 
>> that
>>  > ggplot2 uses. I do not get a segfault if I do a generic `plot(c(1,2,3))`.
>>  >
>>  > - I have tried versions of ggplot2 3.3.3 and 3.3.5.
>>  >
>>  > - The traceback points to files that were introduced in this commit
>>  >
>>  > 
>> https://github.com/wch/r-source/commit/16755bcddffe0cb4238d8a4979387d92b93a8324#diff-5c63f74229830cdde7886a50bf06dafcdf1d5b3d42cfa06b26814876e58c5ab0 
>> <https://github.com/wch/r-source/commit/16755bcddffe0cb4238d8a4979387d92b93a8324#diff-5c63f74229830cdde7886a50bf06dafcdf1d5b3d42cfa06b26814876e58c5ab0>
>>  >
>>  > I am not an R user or R developer so I'm a bit stuck here. I would be 
>> happy to
>>  > give the output of any commands. If anyone has any suggestions then 
>> please let
>>  > me know!
>>  >
>>  > Thanks!
>>  > Mike Lee Williams
>>  >
>>  > ______________________________________________
>>  > R-devel at r-project.org mailing list
>>  > https://stat.ethz.ch/mailman/listinfo/r-devel 
>> <https://stat.ethz.ch/mailman/listinfo/r-devel>
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel 
>> <https://stat.ethz.ch/mailman/listinfo/r-devel>
>
> -- 
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/


From p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz  Tue Sep 21 23:24:39 2021
From: p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz (Paul Murrell)
Date: Wed, 22 Sep 2021 09:24:39 +1200
Subject: [Rd] Segfault in setMask in R 4.1
In-Reply-To: <768701f2-2fd4-4641-b1ea-e1f7e4287a3e@www.fastmail.com>
References: <eb72f226-4b87-4038-bf83-7f9ab5a512b8@www.fastmail.com>
 <0ecbe616f10e40e9a8134c39ec38ffcb@chu-rouen.fr>
 <bc1d9f50-e6c6-491a-b234-adc64ffcf9d6@www.fastmail.com>
 <818dbef8-5c6c-f655-1abd-568cd4eab16d@stat.auckland.ac.nz>
 <768701f2-2fd4-4641-b1ea-e1f7e4287a3e@www.fastmail.com>
Message-ID: <8b9a2b43-4187-f708-9a8a-2c8170dce430@stat.auckland.ac.nz>

Hi

The Cairo_1.5-12.2.tar.gz sources on CRAN contain the changes.  It looks 
like they have still not been merged back into the main package sources 
on R Forge (cc'ing the package maintainer as a gentle reminder).

I think the Cairo package NEWS file should say 4.1.0 rather than 4.0.0

Paul

On 9/22/2021 9:08 AM, Mike Lee Williams wrote:
> Thanks! AFAICT I am already using the latest version of Cairo, but these 
> links gives me a ton of leads to follow up.
> 
> One question (which may be better directed at the maintainer of Cairo): 
> exactly which version (or commit) of Cairo implements support for the 
> new setMask API?
> 
> CRAN still points to 1.5-12.2. The NEWS file 
> (https://www.rforge.net/Cairo/news.html 
> <https://www.rforge.net/Cairo/news.html>) 
> refers to changes implemented to support R 4.0.0 in Cairo 1.5-12, but my 
> understanding is that setMask was added in R 4.1.0.
> 
> I see no mention of changes to support setMask or R 4.1.x in Cairo 
> 1.5-13 (not on CRAN yet, but the only release since 1.5-12 according to 
> the NEWS file). The 1.5-13 tarball at 
> https://www.rforge.net/Cairo/files/ 
> <https://www.rforge.net/Cairo/files> 
> contains no mention of strings like "setMask", "releasePattern" or 
> "setPattern", which seem like they should be in there if that version 
> has implemented support for the new API.
> 
> Mike
> 
> On Tue, Sep 21, 2021, at 1:41 PM, Paul Murrell wrote:
>  > Hi
>  >
>  > dev->setMask() was introduced in R 4.1.0 ...
>  >
>  > 
> https://developer.r-project.org/Blog/public/2020/07/15/new-features-in-the-r-graphics-engine/ 
> <https://developer.r-project.org/Blog/public/2020/07/15/new-features-in-the-r-graphics-engine>
>  >
>  > 
> https://www.stat.auckland.ac.nz/~paul/Reports/GraphicsEngine/definitions/definitions.html 
> <https://www.stat.auckland.ac.nz/~paul/Reports/GraphicsEngine/definitions/definitions.html>
>  >
>  > If your application is using its own custom graphics device, it will
>  > need updating, see ...
>  >
>  > 
> https://www.stat.auckland.ac.nz/~paul/Reports/GraphicsEngine/definitions/definitions.html#devices 
> <https://www.stat.auckland.ac.nz/~paul/Reports/GraphicsEngine/definitions/definitions.html#devices>
>  >
>  > But it looks like you may just be using the graphics device provided by
>  > the 'Cairo' package, which has already been updated. If that is the
>  > case, your problem may be solved simply be reinstalling the 'Cairo' 
> package.
>  >
>  > Paul
>  >
>  > p.s. the reason why it only happens for 'ggplot2' plots is that only
>  > 'grid' (which underlies 'ggplot2') attempts to set masks (the 'graphics'
>  > package does not).
>  >
>  > On 9/22/2021 4:52 AM, Mike Lee Williams wrote:
>  >> Thank you! Here is the output of option("devices"), which I think means
>  >> we're using Cairo:
>  >>
>  >> $device
>  >> function (width = 1280, height = 960, pointsize = 24, units = "px",
>  >> bg = "white", dpi = 160, ...)
>  >> {
>  >> devSym <- basename(tempfile(pattern = "SensePlot", tmpdir = ""))
>  >> newDev <- Cairo(width = width, height = height, pointsize = pointsize,
>  >> bg = bg, units = units, dpi = dpi, type = "raster", ...)
>  >> attr(newDev, "units") <- units
>  >> attr(newDev, "dpi") <- dpi
>  >> assign(devSym, newDev, SenseDevices)
>  >> invisible(newDev)
>  >> }
>  >> <bytecode: 0x55b08ba031c0>
>  >> <environment: namespace:Cairo>
>  >>
>  >> "Sense" is the internal name of our application. I'm not sure what
>  >> "devSym" and "newDev" are, but If there are no known issues with Cairo
>  >> itself then our own code is presumably part of the problem.
>  >>
>  >> I would like to confirm that by failing to reproduce the bug in
>  >> "vanilla" R 4.1 with a Cairo device. If anyone has any tips for how to
>  >> do that (on Linux) or any other comments I would be very grateful.
>  >>
>  >> If our code is the problem then I'm still confused why a regular plot()
>  >> works, but a ggplot2 qplot() segfaults. Maybe this is a clue!
>  >>
>  >> I will post again if I figure anything out!
>  >>
>  >> Mike
>  >>
>  >> On Tue, Sep 21, 2021, at 3:37 AM, GILLIBERT, Andre wrote:
>  >> > Hello,
>  >> >
>  >> > Which graphic device (backend) do you use?
>  >> > The setMask() function calls the internal setMask function associated
>  >> > to the graphic device.
>  >> > If the Web application uses one of the standard graphic backend, the
>  >> > bug may come from the R core. If it uses a custom graphic backend, the
>  >> > bug may be in the backend.
>  >> >
>  >> > --
>  >> > Sincerely
>  >> > Andr? GILLIBERT
>  >> >
>  >> > ATTENTION: Cet e-mail provient d?une adresse mail ext?rieure au CHU de
>  >> > Rouen. Ne cliquez pas sur les liens ou n'ouvrez pas les pi?ces jointes
>  >> > ? moins de conna?tre l'exp?diteur et de savoir que le contenu est s?r.
>  >> > En cas de doute, transf?rer le mail ? ? DSI, S?curit? ? pour analyse.
>  >> > Merci de votre vigilance
>  >> >
>  >> >
>  >> > I have inherited a build of R. We compile R from source and then use
>  >> a custom
>  >> > web application to allow users to enter R statements and render the
>  >> output (it's
>  >> > kind of like RStudio although the UX is quite different).
>  >> >
>  >> > Things were going fine until I tried to upgrade to R 4.1.x. The build
>  >> succeeds,
>  >> > but I get the following segfault when I make qplot (ggplot2) calls:
>  >> >
>  >> > *** caught segfault ***
>  >> > address (nil), cause 'memory not mapped'
>  >> >
>  >> > Traceback:
>  >> > 1: .setMask(NULL, NULL)
>  >> > 2: resolveMask.NULL(NULL)
>  >> > 3: (function (path) { UseMethod("resolveMask")})(NULL)
>  >> > 4: grid.newpage()
>  >> > 5: print.ggplot(x)
>  >> > 6: (function (x, ...) UseMethod("print"))(x)
>  >> >
>  >> > I am not an R developer, so I don't really know how to read this. I
>  >> am wondering
>  >> > if this is a known issue or if anyone has any suggestions. Here's
>  >> some things
>  >> > I've tested:
>  >> >
>  >> > - I get the same segfault in R 4.1.0 and R 4.1.1. I do not get this
>  >> error in R
>  >> > 4.0.4 or R 4.0.5.
>  >> >
>  >> > - The problem appears to be specific to the (graphics?) features of R
>  >> that
>  >> > ggplot2 uses. I do not get a segfault if I do a generic 
> `plot(c(1,2,3))`.
>  >> >
>  >> > - I have tried versions of ggplot2 3.3.3 and 3.3.5.
>  >> >
>  >> > - The traceback points to files that were introduced in this commit
>  >> >
>  >> >
>  >> 
> https://github.com/wch/r-source/commit/16755bcddffe0cb4238d8a4979387d92b93a8324#diff-5c63f74229830cdde7886a50bf06dafcdf1d5b3d42cfa06b26814876e58c5ab0 
> <https://github.com/wch/r-source/commit/16755bcddffe0cb4238d8a4979387d92b93a8324#diff-5c63f74229830cdde7886a50bf06dafcdf1d5b3d42cfa06b26814876e58c5ab0> 
> 
>  >> 
> <https://github.com/wch/r-source/commit/16755bcddffe0cb4238d8a4979387d92b93a8324#diff-5c63f74229830cdde7886a50bf06dafcdf1d5b3d42cfa06b26814876e58c5ab0 
> <https://github.com/wch/r-source/commit/16755bcddffe0cb4238d8a4979387d92b93a8324#diff-5c63f74229830cdde7886a50bf06dafcdf1d5b3d42cfa06b26814876e58c5ab0>>
>  >> >
>  >> > I am not an R user or R developer so I'm a bit stuck here. I would be
>  >> happy to
>  >> > give the output of any commands. If anyone has any suggestions then
>  >> please let
>  >> > me know!
>  >> >
>  >> > Thanks!
>  >> > Mike Lee Williams
>  >> >
>  >> > ______________________________________________
>  >> > R-devel at r-project.org mailing list
>  >> > https://stat.ethz.ch/mailman/listinfo/r-devel 
> <https://stat.ethz.ch/mailman/listinfo/r-devel> 
> 
>  >> <https://stat.ethz.ch/mailman/listinfo/r-devel 
> <https://stat.ethz.ch/mailman/listinfo/r-devel>>
>  >>
>  >> ______________________________________________
>  >> R-devel at r-project.org mailing list
>  >> https://stat.ethz.ch/mailman/listinfo/r-devel 
> <https://stat.ethz.ch/mailman/listinfo/r-devel> 
> 
>  >> <https://stat.ethz.ch/mailman/listinfo/r-devel 
> <https://stat.ethz.ch/mailman/listinfo/r-devel>>
>  >
>  > --
>  > Dr Paul Murrell
>  > Department of Statistics
>  > The University of Auckland
>  > Private Bag 92019
>  > Auckland
>  > New Zealand
>  > 64 9 3737599 x85392
>  > paul at stat.auckland.ac.nz
>  > http://www.stat.auckland.ac.nz/~paul/ 
> <http://www.stat.auckland.ac.nz/~paul>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From m|ke @end|ng |rom m|ke@p|@ce  Wed Sep 22 05:27:02 2021
From: m|ke @end|ng |rom m|ke@p|@ce (Mike Lee Williams)
Date: Tue, 21 Sep 2021 20:27:02 -0700
Subject: [Rd] Segfault in setMask in R 4.1
In-Reply-To: <8b9a2b43-4187-f708-9a8a-2c8170dce430@stat.auckland.ac.nz>
References: <eb72f226-4b87-4038-bf83-7f9ab5a512b8@www.fastmail.com>
 <0ecbe616f10e40e9a8134c39ec38ffcb@chu-rouen.fr>
 <bc1d9f50-e6c6-491a-b234-adc64ffcf9d6@www.fastmail.com>
 <818dbef8-5c6c-f655-1abd-568cd4eab16d@stat.auckland.ac.nz>
 <768701f2-2fd4-4641-b1ea-e1f7e4287a3e@www.fastmail.com>
 <8b9a2b43-4187-f708-9a8a-2c8170dce430@stat.auckland.ac.nz>
Message-ID: <24a2abbc-737a-4b93-86ef-70f46480992f@www.fastmail.com>

I'm all set! My problem seems to have been a mixture of two things:

1. As Paul pointed out I needed to upgrade Cairo to get support for the new GE v13 (setMask, etc.). That support is apparently present in 1.5-12.2 (the current version on CRAN).

2. I was getting Cairo from https://github.com/s-u/Cairo/ rather than CRAN, and github and CRAN seem to have diverged, such that 1.5-13 (on github) doesn't contain the GE v13 change despite being a higher version than 1.5-12.2.

Simon Urbanek, the Cairo maintainer has kindly cleared this situation up for me, and there is now a 1.5-14 which I believe reconciles these two diverged sources, includes the GE v13 changes (see https://github.com/s-u/Cairo/) and fixes my segfual. I assume this will be pushed to CRAN at some point.

Thank you very much Paul, Andre and Simon for you help!

Mike

On Tue, Sep 21, 2021, at 2:24 PM, Paul Murrell wrote:
> Hi
>
> The Cairo_1.5-12.2.tar.gz sources on CRAN contain the changes.  It looks 
> like they have still not been merged back into the main package sources 
> on R Forge (cc'ing the package maintainer as a gentle reminder).
>
> I think the Cairo package NEWS file should say 4.1.0 rather than 4.0.0
>
> Paul
>
> On 9/22/2021 9:08 AM, Mike Lee Williams wrote:
>> Thanks! AFAICT I am already using the latest version of Cairo, but these 
>> links gives me a ton of leads to follow up.
>> 
>> One question (which may be better directed at the maintainer of Cairo): 
>> exactly which version (or commit) of Cairo implements support for the 
>> new setMask API?
>> 
>> CRAN still points to 1.5-12.2. The NEWS file 
>> (https://www.rforge.net/Cairo/news.html 
>> <https://www.rforge.net/Cairo/news.html>) 
>> refers to changes implemented to support R 4.0.0 in Cairo 1.5-12, but my 
>> understanding is that setMask was added in R 4.1.0.
>> 
>> I see no mention of changes to support setMask or R 4.1.x in Cairo 
>> 1.5-13 (not on CRAN yet, but the only release since 1.5-12 according to 
>> the NEWS file). The 1.5-13 tarball at 
>> https://www.rforge.net/Cairo/files/ 
>> <https://www.rforge.net/Cairo/files> 
>> contains no mention of strings like "setMask", "releasePattern" or 
>> "setPattern", which seem like they should be in there if that version 
>> has implemented support for the new API.
>> 
>> Mike
>> 
>> On Tue, Sep 21, 2021, at 1:41 PM, Paul Murrell wrote:
>>  > Hi
>>  >
>>  > dev->setMask() was introduced in R 4.1.0 ...
>>  >
>>  > 
>> https://developer.r-project.org/Blog/public/2020/07/15/new-features-in-the-r-graphics-engine/ 
>> <https://developer.r-project.org/Blog/public/2020/07/15/new-features-in-the-r-graphics-engine>
>>  >
>>  > 
>> https://www.stat.auckland.ac.nz/~paul/Reports/GraphicsEngine/definitions/definitions.html 
>> <https://www.stat.auckland.ac.nz/~paul/Reports/GraphicsEngine/definitions/definitions.html>
>>  >
>>  > If your application is using its own custom graphics device, it will
>>  > need updating, see ...
>>  >
>>  > 
>> https://www.stat.auckland.ac.nz/~paul/Reports/GraphicsEngine/definitions/definitions.html#devices 
>> <https://www.stat.auckland.ac.nz/~paul/Reports/GraphicsEngine/definitions/definitions.html#devices>
>>  >
>>  > But it looks like you may just be using the graphics device provided by
>>  > the 'Cairo' package, which has already been updated. If that is the
>>  > case, your problem may be solved simply be reinstalling the 'Cairo' 
>> package.
>>  >
>>  > Paul
>>  >
>>  > p.s. the reason why it only happens for 'ggplot2' plots is that only
>>  > 'grid' (which underlies 'ggplot2') attempts to set masks (the 'graphics'
>>  > package does not).
>>  >
>>  > On 9/22/2021 4:52 AM, Mike Lee Williams wrote:
>>  >> Thank you! Here is the output of option("devices"), which I think means
>>  >> we're using Cairo:
>>  >>
>>  >> $device
>>  >> function (width = 1280, height = 960, pointsize = 24, units = "px",
>>  >> bg = "white", dpi = 160, ...)
>>  >> {
>>  >> devSym <- basename(tempfile(pattern = "SensePlot", tmpdir = ""))
>>  >> newDev <- Cairo(width = width, height = height, pointsize = pointsize,
>>  >> bg = bg, units = units, dpi = dpi, type = "raster", ...)
>>  >> attr(newDev, "units") <- units
>>  >> attr(newDev, "dpi") <- dpi
>>  >> assign(devSym, newDev, SenseDevices)
>>  >> invisible(newDev)
>>  >> }
>>  >> <bytecode: 0x55b08ba031c0>
>>  >> <environment: namespace:Cairo>
>>  >>
>>  >> "Sense" is the internal name of our application. I'm not sure what
>>  >> "devSym" and "newDev" are, but If there are no known issues with Cairo
>>  >> itself then our own code is presumably part of the problem.
>>  >>
>>  >> I would like to confirm that by failing to reproduce the bug in
>>  >> "vanilla" R 4.1 with a Cairo device. If anyone has any tips for how to
>>  >> do that (on Linux) or any other comments I would be very grateful.
>>  >>
>>  >> If our code is the problem then I'm still confused why a regular plot()
>>  >> works, but a ggplot2 qplot() segfaults. Maybe this is a clue!
>>  >>
>>  >> I will post again if I figure anything out!
>>  >>
>>  >> Mike
>>  >>
>>  >> On Tue, Sep 21, 2021, at 3:37 AM, GILLIBERT, Andre wrote:
>>  >> > Hello,
>>  >> >
>>  >> > Which graphic device (backend) do you use?
>>  >> > The setMask() function calls the internal setMask function associated
>>  >> > to the graphic device.
>>  >> > If the Web application uses one of the standard graphic backend, the
>>  >> > bug may come from the R core. If it uses a custom graphic backend, the
>>  >> > bug may be in the backend.
>>  >> >
>>  >> > --
>>  >> > Sincerely
>>  >> > Andr? GILLIBERT
>>  >> >
>>  >> > ATTENTION: Cet e-mail provient d?une adresse mail ext?rieure au CHU de
>>  >> > Rouen. Ne cliquez pas sur les liens ou n'ouvrez pas les pi?ces jointes
>>  >> > ? moins de conna?tre l'exp?diteur et de savoir que le contenu est s?r.
>>  >> > En cas de doute, transf?rer le mail ? ? DSI, S?curit? ? pour analyse.
>>  >> > Merci de votre vigilance
>>  >> >
>>  >> >
>>  >> > I have inherited a build of R. We compile R from source and then use
>>  >> a custom
>>  >> > web application to allow users to enter R statements and render the
>>  >> output (it's
>>  >> > kind of like RStudio although the UX is quite different).
>>  >> >
>>  >> > Things were going fine until I tried to upgrade to R 4.1.x. The build
>>  >> succeeds,
>>  >> > but I get the following segfault when I make qplot (ggplot2) calls:
>>  >> >
>>  >> > *** caught segfault ***
>>  >> > address (nil), cause 'memory not mapped'
>>  >> >
>>  >> > Traceback:
>>  >> > 1: .setMask(NULL, NULL)
>>  >> > 2: resolveMask.NULL(NULL)
>>  >> > 3: (function (path) { UseMethod("resolveMask")})(NULL)
>>  >> > 4: grid.newpage()
>>  >> > 5: print.ggplot(x)
>>  >> > 6: (function (x, ...) UseMethod("print"))(x)
>>  >> >
>>  >> > I am not an R developer, so I don't really know how to read this. I
>>  >> am wondering
>>  >> > if this is a known issue or if anyone has any suggestions. Here's
>>  >> some things
>>  >> > I've tested:
>>  >> >
>>  >> > - I get the same segfault in R 4.1.0 and R 4.1.1. I do not get this
>>  >> error in R
>>  >> > 4.0.4 or R 4.0.5.
>>  >> >
>>  >> > - The problem appears to be specific to the (graphics?) features of R
>>  >> that
>>  >> > ggplot2 uses. I do not get a segfault if I do a generic 
>> `plot(c(1,2,3))`.
>>  >> >
>>  >> > - I have tried versions of ggplot2 3.3.3 and 3.3.5.
>>  >> >
>>  >> > - The traceback points to files that were introduced in this commit
>>  >> >
>>  >> >
>>  >> 
>> https://github.com/wch/r-source/commit/16755bcddffe0cb4238d8a4979387d92b93a8324#diff-5c63f74229830cdde7886a50bf06dafcdf1d5b3d42cfa06b26814876e58c5ab0 
>> <https://github.com/wch/r-source/commit/16755bcddffe0cb4238d8a4979387d92b93a8324#diff-5c63f74229830cdde7886a50bf06dafcdf1d5b3d42cfa06b26814876e58c5ab0> 
>> 
>>  >> 
>> <https://github.com/wch/r-source/commit/16755bcddffe0cb4238d8a4979387d92b93a8324#diff-5c63f74229830cdde7886a50bf06dafcdf1d5b3d42cfa06b26814876e58c5ab0 
>> <https://github.com/wch/r-source/commit/16755bcddffe0cb4238d8a4979387d92b93a8324#diff-5c63f74229830cdde7886a50bf06dafcdf1d5b3d42cfa06b26814876e58c5ab0>>
>>  >> >
>>  >> > I am not an R user or R developer so I'm a bit stuck here. I would be
>>  >> happy to
>>  >> > give the output of any commands. If anyone has any suggestions then
>>  >> please let
>>  >> > me know!
>>  >> >
>>  >> > Thanks!
>>  >> > Mike Lee Williams
>>  >> >
>>  >> > ______________________________________________
>>  >> > R-devel at r-project.org mailing list
>>  >> > https://stat.ethz.ch/mailman/listinfo/r-devel 
>> <https://stat.ethz.ch/mailman/listinfo/r-devel> 
>> 
>>  >> <https://stat.ethz.ch/mailman/listinfo/r-devel 
>> <https://stat.ethz.ch/mailman/listinfo/r-devel>>
>>  >>
>>  >> ______________________________________________
>>  >> R-devel at r-project.org mailing list
>>  >> https://stat.ethz.ch/mailman/listinfo/r-devel 
>> <https://stat.ethz.ch/mailman/listinfo/r-devel> 
>> 
>>  >> <https://stat.ethz.ch/mailman/listinfo/r-devel 
>> <https://stat.ethz.ch/mailman/listinfo/r-devel>>
>>  >
>>  > --
>>  > Dr Paul Murrell
>>  > Department of Statistics
>>  > The University of Auckland
>>  > Private Bag 92019
>>  > Auckland
>>  > New Zealand
>>  > 64 9 3737599 x85392
>>  > paul at stat.auckland.ac.nz
>>  > http://www.stat.auckland.ac.nz/~paul/ 
>> <http://www.stat.auckland.ac.nz/~paul>
>
> -- 
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/


From d@v|@ @end|ng |rom r@tud|o@com  Mon Sep 13 22:35:47 2021
From: d@v|@ @end|ng |rom r@tud|o@com (Davis Vaughan)
Date: Mon, 13 Sep 2021 16:35:47 -0400
Subject: [Rd] formatC(character()) returns length 1 result,
 but is documented otherwise
Message-ID: <CABzLhzzaxHwwB8zi4+hH=eNWUg=YpZU954pSS58wREwj8vdLMQ-6829@mail.gmail.com>

Hi all,

I believe I have either found a small bug, or a possible inconsistency in
documentation. formatC() returns a length 1 result if given a length 0
character() as input.

formatC(character())
#> [1] ""

But the return value documentation states that it returns: "A character
object of same size and attributes as x".

I'd love for this to return a size 0 result here, consistent with the docs
and my mental model of size stability for this function.

Here is where this happens (it is explicitly hard coded):
https://github.com/wch/r-source/blob/79298c499218846d14500255efd622b5021c10ec/src/library/base/R/format.R#L149

Thanks,
Davis Vaughan

	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Wed Sep 22 12:46:58 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Wed, 22 Sep 2021 12:46:58 +0200
Subject: [Rd] formatC(character()) returns length 1 result,
 but is documented otherwise
In-Reply-To: <CABzLhzzaxHwwB8zi4+hH=eNWUg=YpZU954pSS58wREwj8vdLMQ-6829@mail.gmail.com>
References: <CABzLhzzaxHwwB8zi4+hH=eNWUg=YpZU954pSS58wREwj8vdLMQ-6829@mail.gmail.com>
Message-ID: <24907.2466.770612.858657@stat.math.ethz.ch>

>>>>> Davis Vaughan 
>>>>>     on Mon, 13 Sep 2021 16:35:47 -0400 writes:

    > Hi all,

    > I believe I have either found a small bug, or a possible inconsistency in
    > documentation. formatC() returns a length 1 result if given a length 0
    > character() as input.

    > formatC(character())
    > #> [1] ""

    > But the return value documentation states that it returns: "A character
    > object of same size and attributes as x".

    > I'd love for this to return a size 0 result here, consistent with the docs
    > and my mental model of size stability for this function.

    > Here is where this happens (it is explicitly hard coded):
    > https://github.com/wch/r-source/blob/79298c499218846d14500255efd622b5021c10ec/src/library/base/R/format.R#L149

    > Thanks,
    > Davis Vaughan

    > [[alternative HTML version deleted]]

This may well be a "historical artefact" - definitely
older than R 1.0.0. ... and yes I've known much less about S and
its new dialect R, back in 1998.  ;-)

You are right in all you say, and my mental model corresponds to
yours,  so we will almost surely change this (for R-devel;
possibly even consider "back" porting to R 4.1.1 patched).

Thank you for the report and suggestion,
Martin


From henr|k@bengt@@on @end|ng |rom gm@||@com  Thu Sep 23 05:48:05 2021
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Wed, 22 Sep 2021 20:48:05 -0700
Subject: [Rd] R-devel: as.character() for hexmode no longer pads with zeros
Message-ID: <CAFDcVCQvHm6R37yCZ3Mua4JQe1q=DX-=kZB9+oUdiPE+rbjEAg@mail.gmail.com>

The update in rev 80946
(https://github.com/wch/r-source/commit/d970867722e14811e8ba6b0ba8e0f478ff482f5e)
caused as.character() on hexmode objects to no longer pads with zeros.

Before:

> x <- structure(as.integer(c(0,8,16,24,32)), class="hexmode")
> x
[1] "00" "08" "10" "18" "20"
> as.character(x)
[1] "00" "08" "10" "18" "20"

After:

> x <- structure(as.integer(c(0,8,16,24,32)), class="hexmode")
> x
[1] "00" "08" "10" "18" "20"
> as.character(x)
[1] "0"  "8"  "10" "18" "20"

Was that intended?

/Henrik

PS. This breaks R.utils::intToHex()
[https://cran.r-project.org/web/checks/check_results_R.utils.html]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Thu Sep 23 09:46:35 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 23 Sep 2021 09:46:35 +0200
Subject: [Rd] 
 R-devel: as.character() for hexmode no longer pads with zeros
In-Reply-To: <CAFDcVCQvHm6R37yCZ3Mua4JQe1q=DX-=kZB9+oUdiPE+rbjEAg@mail.gmail.com>
References: <CAFDcVCQvHm6R37yCZ3Mua4JQe1q=DX-=kZB9+oUdiPE+rbjEAg@mail.gmail.com>
Message-ID: <24908.12507.759291.102612@stat.math.ethz.ch>

>>>>> Henrik Bengtsson 
>>>>>     on Wed, 22 Sep 2021 20:48:05 -0700 writes:

    > The update in rev 80946
    > (https://github.com/wch/r-source/commit/d970867722e14811e8ba6b0ba8e0f478ff482f5e)
    > caused as.character() on hexmode objects to no longer pads with zeros.

Yes -- very much on purpose; by me, after discussing a related issue
within R-core which showed "how wrong" the previous (current R)
behavior of the as.character() method is for
hexmode and octmode objects :

If you look at the whole rev 80946 , you also read NEWS

 * as.character(<obj>) for "hexmode" or "octmode" objects now
   fulfills the important basic rule

  as.character(x)[j] === as.character(x[j]) 
  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

rather than just calling format().

The format() generic (notably for "atomic-alike" objects) should indeed
return a character vector where each string has the same "width",
however, the result of  as.character(x) --- at least for all
"atomic-alike" / "vector-alike" objects --
for a single x[j] should not be influenced by other elements in x.




    > Before:

    >> x <- structure(as.integer(c(0,8,16,24,32)), class="hexmode")
    >> x
    > [1] "00" "08" "10" "18" "20"
    >> as.character(x)
    > [1] "00" "08" "10" "18" "20"

    > After:

    >> x <- structure(as.integer(c(0,8,16,24,32)), class="hexmode")
    >> x
    > [1] "00" "08" "10" "18" "20"
    >> as.character(x)
    > [1] "0"  "8"  "10" "18" "20"

    > Was that intended?

Yes!
You have to explore your example a bit to notice how "illogical"
the behavior before was:

> as.character(as.hexmode(0:15))
 [1] "0" "1" "2" "3" "4" "5" "6" "7" "8" "9" "a" "b" "c" "d" "e" "f"
> as.character(as.hexmode(0:16))
 [1] "00" "01" "02" "03" "04" "05" "06" "07" "08" "09" "0a" "0b" "0c" "0d" "0e"
[16] "0f" "10"

> as.character(as.hexmode(16^(0:2)))
[1] "001" "010" "100"
> as.character(as.hexmode(16^(0:3)))
[1] "0001" "0010" "0100" "1000"
> as.character(as.hexmode(16^(0:4)))
[1] "00001" "00010" "00100" "01000" "10000"

all breaking the rule in the NEWS  and given above.

If you want format()  you should use format(),
but as.character() should never have used format() ..

Martin
    
    > /Henrik

    > PS. This breaks R.utils::intToHex()
    > [https://cran.r-project.org/web/checks/check_results_R.utils.html]


From henr|k@bengt@@on @end|ng |rom gm@||@com  Thu Sep 23 18:55:17 2021
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Thu, 23 Sep 2021 09:55:17 -0700
Subject: [Rd] 
 R-devel: as.character() for hexmode no longer pads with zeros
In-Reply-To: <24908.12507.759291.102612@stat.math.ethz.ch>
References: <CAFDcVCQvHm6R37yCZ3Mua4JQe1q=DX-=kZB9+oUdiPE+rbjEAg@mail.gmail.com>
 <24908.12507.759291.102612@stat.math.ethz.ch>
Message-ID: <CAFDcVCR7bHwP0C8e_NFVS4iJY=GsYSKH7vRfncav8X-SkSpozw@mail.gmail.com>

Thanks for confirming and giving details on the rationale (... and
I'll updated R.utils to use format() instead).

Regarding as.character(x)[j] === as.character(x[j]): I agree with this
- is that property of as.character()/subsetting explicitly
stated/documented somewhere?  I wonder if this is a property we should
all strive for for other types of objects?

/Henrik

On Thu, Sep 23, 2021 at 12:46 AM Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>
> >>>>> Henrik Bengtsson
> >>>>>     on Wed, 22 Sep 2021 20:48:05 -0700 writes:
>
>     > The update in rev 80946
>     > (https://github.com/wch/r-source/commit/d970867722e14811e8ba6b0ba8e0f478ff482f5e)
>     > caused as.character() on hexmode objects to no longer pads with zeros.
>
> Yes -- very much on purpose; by me, after discussing a related issue
> within R-core which showed "how wrong" the previous (current R)
> behavior of the as.character() method is for
> hexmode and octmode objects :
>
> If you look at the whole rev 80946 , you also read NEWS
>
>  * as.character(<obj>) for "hexmode" or "octmode" objects now
>    fulfills the important basic rule
>
>   as.character(x)[j] === as.character(x[j])
>   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
>
> rather than just calling format().
>
> The format() generic (notably for "atomic-alike" objects) should indeed
> return a character vector where each string has the same "width",
> however, the result of  as.character(x) --- at least for all
> "atomic-alike" / "vector-alike" objects --
> for a single x[j] should not be influenced by other elements in x.
>
>
>
>
>     > Before:
>
>     >> x <- structure(as.integer(c(0,8,16,24,32)), class="hexmode")
>     >> x
>     > [1] "00" "08" "10" "18" "20"
>     >> as.character(x)
>     > [1] "00" "08" "10" "18" "20"
>
>     > After:
>
>     >> x <- structure(as.integer(c(0,8,16,24,32)), class="hexmode")
>     >> x
>     > [1] "00" "08" "10" "18" "20"
>     >> as.character(x)
>     > [1] "0"  "8"  "10" "18" "20"
>
>     > Was that intended?
>
> Yes!
> You have to explore your example a bit to notice how "illogical"
> the behavior before was:
>
> > as.character(as.hexmode(0:15))
>  [1] "0" "1" "2" "3" "4" "5" "6" "7" "8" "9" "a" "b" "c" "d" "e" "f"
> > as.character(as.hexmode(0:16))
>  [1] "00" "01" "02" "03" "04" "05" "06" "07" "08" "09" "0a" "0b" "0c" "0d" "0e"
> [16] "0f" "10"
>
> > as.character(as.hexmode(16^(0:2)))
> [1] "001" "010" "100"
> > as.character(as.hexmode(16^(0:3)))
> [1] "0001" "0010" "0100" "1000"
> > as.character(as.hexmode(16^(0:4)))
> [1] "00001" "00010" "00100" "01000" "10000"
>
> all breaking the rule in the NEWS  and given above.
>
> If you want format()  you should use format(),
> but as.character() should never have used format() ..
>
> Martin
>
>     > /Henrik
>
>     > PS. This breaks R.utils::intToHex()
>     > [https://cran.r-project.org/web/checks/check_results_R.utils.html]
>


From tom@@@k@||ber@ @end|ng |rom gm@||@com  Thu Sep 23 19:16:14 2021
From: tom@@@k@||ber@ @end|ng |rom gm@||@com (Tomas Kalibera)
Date: Thu, 23 Sep 2021 19:16:14 +0200
Subject: [Rd] Detect UCRT-built R from within R sessions (and in
 configure.win)
In-Reply-To: <CALyqOb9zyhg7_uiBbiaNwMo2333Qw7g_bRvv5cQGFfm94O+0Mw@mail.gmail.com>
References: <CALyqOb8r7ajAumf5V0+YJk83X091NS2eRCs-cu=X6zO+09z0Rg@mail.gmail.com>
 <a219a307-5200-a13e-b4d9-a1e7a646e137@gmail.com>
 <CALyqOb8yer26avLG8wmGxpFQgEeYtxaPGOnixpYTssAJiOLfDA@mail.gmail.com>
 <d722d393-94e0-370b-e7bd-ca96e708a205@gmail.com>
 <CALyqOb8FaPfVMU1-0BzXdNwrgMQtv+t5uiacasdQo=SZSQ4pug@mail.gmail.com>
 <CALyqOb9zyhg7_uiBbiaNwMo2333Qw7g_bRvv5cQGFfm94O+0Mw@mail.gmail.com>
Message-ID: <2a72ed3a-eb5d-746c-9434-13b378483cef@gmail.com>


On 9/20/21 11:03 AM, Hiroaki Yutani wrote:
> I tried to use configure.ucrt, and found it results in the following
> NOTE on the released version of R, unfortunately.
>
>      * checking top-level files ... NOTE
>      Non-standard file/directory found at top level:
>      'configure.ucrt'
>
> Will this be accepted by CRAN if I submit a package that contains
> configure.ucrt? Or, is it too early to use it in a CRAN package?

Thanks, that's right, so I've ported this part to R-devel and R-patched, 
configure.ucrt and cleanup.ucrt will be treated as "standard". There is 
nothing we can do about already released versions, the NOTE will appear.

You can also use configure.win and branch on R.version$crt, e.g.

!is.null(R.version$crt) && R.version$crt == "ucrt"

or

identical(R.version$crt, "ucrt")

> In either case, while I don't have a strong opinion here, I'm starting
> to feel that it might be preferable to provide an environmental
> variable rather than creating ".ucrt" versions of files. In my
> understanding, the plan is to switch all the Windows R to UCRT at some
> point in future. But, it's not clear to me how to unify these ".win"
> files and ".ucrt" files smoothly.

With R.version$crt, you can already get a make (or even environment) 
variable. Writing R Extensions has examples how to invoke R in make 
files to get "R CMD config" values, so here you would invoke "Rscript" 
instead with one of the conditions above.

Either is fine. With .ucrt files, you can avoid copy pasting of common 
code using "include" directives. With the variable, you can use make 
conditionals. As you found now, with the variable you have the advantage 
of not getting a NOTE with already released versions of R. The .ucrt 
files are easier to maintain in hot-patches, but that is not an 
advantage for package authors.

Once a package depends on a version of R that will already use UCRT, one 
either would refactor/remove the conditionals, or integrate the ".ucrt" 
files back into the ".win". So, in the long term, there should be no 
conditionals on R.version$crt nor ".ucrt" files.

Best
Tomas
> Best,
> Hiroaki Yutani
>
> 2021?9?14?(?) 23:44 Hiroaki Yutani <yutani.ini at gmail.com>:
>
>> Thanks for both, I'll try these features.
>>
>> 2021?9?14?(?) 22:40 Tomas Kalibera <tomas.kalibera at gmail.com>:
>>
>>>
>>> On 9/9/21 5:54 AM, Hiroaki Yutani wrote:
>>>
>>> Thank you for the prompt reply.
>>>
>>>> There in not such a mechanism, yet, but can be added, at least for
>>>> diagnostics.
>>> For example, can R.version somehow contain the information?
>>>
>>> Yes, now added to the experimental builds. R.version$crt contains "ucrt" (and would contain "msvcrt" if R was built against MSVCRT).
>>>
>>>
>>>> We could add support for configure.ucrt, which would take precedence
>>>> over configure.win on the UCRT builds (like Makevars.ucrt takes
>>>> precedence over Makevars.win). Would that work for you?
>>> Yes, configure.ucrt should work for me. There might be someone who prefers to switch by some envvar rather than creating another file, but I don't have a strong opinion here.
>>>
>>> The experimental builds now support configure.ucrt and cleanup.ucrt files.
>>>
>>> Best
>>> Tomas
>>>
>>>
>>> Best,
>>> Hiroaki Yutani
>>>
>>> 2021?9?9?(?) 0:48 Tomas Kalibera <tomas.kalibera at gmail.com>:
>>>>
>>>> On 9/8/21 2:08 PM, Hiroaki Yutani wrote:
>>>>> Hi,
>>>>>
>>>>> Are there any proper ways to know whether the session is running on
>>>>> the R that is built with the UCRT toolchain or not? Checking if the
>>>>> encoding is UTF-8 might do the trick, but I'm not sure if it's always
>>>>> reliable.
>>>> There in not such a mechanism, yet, but can be added, at least for
>>>> diagnostics.
>>>>
>>>> You are right that checking for UTF-8 encoding would not always be
>>>> reliable. For example, the version of Windows may be too old to allow R
>>>> use UTF-8 as native encoding (e.g. Windows server 2016), then R will use
>>>> the native code page as it does today in the MSVCRT builds.
>>>>
>>>>> Also, I'd like to know if there's any mechanism to detect the UCRT in
>>>>> configure.win. I know there are Makevars.ucrt and Makefile.ucrt, but
>>>>> one might want to do some feature test that is specific to the UCRT
>>>>> toolchain.
>>>> We could add support for configure.ucrt, which would take precedence
>>>> over configure.win on the UCRT builds (like Makevars.ucrt takes
>>>> precedence over Makevars.win). Would that work for you?
>>>>
>>>> Best
>>>> Tomas
>>>>
>>>>> Best,
>>>>> Hiroaki Yutani
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel


From yut@n|@|n| @end|ng |rom gm@||@com  Fri Sep 24 03:31:56 2021
From: yut@n|@|n| @end|ng |rom gm@||@com (Hiroaki Yutani)
Date: Fri, 24 Sep 2021 10:31:56 +0900
Subject: [Rd] Detect UCRT-built R from within R sessions (and in
 configure.win)
In-Reply-To: <2a72ed3a-eb5d-746c-9434-13b378483cef@gmail.com>
References: <CALyqOb8r7ajAumf5V0+YJk83X091NS2eRCs-cu=X6zO+09z0Rg@mail.gmail.com>
 <a219a307-5200-a13e-b4d9-a1e7a646e137@gmail.com>
 <CALyqOb8yer26avLG8wmGxpFQgEeYtxaPGOnixpYTssAJiOLfDA@mail.gmail.com>
 <d722d393-94e0-370b-e7bd-ca96e708a205@gmail.com>
 <CALyqOb8FaPfVMU1-0BzXdNwrgMQtv+t5uiacasdQo=SZSQ4pug@mail.gmail.com>
 <CALyqOb9zyhg7_uiBbiaNwMo2333Qw7g_bRvv5cQGFfm94O+0Mw@mail.gmail.com>
 <2a72ed3a-eb5d-746c-9434-13b378483cef@gmail.com>
Message-ID: <CALyqOb_gREt25-_xxqkpSOPw7+hN9aHP9UY+oBDqK83XJ3mQCQ@mail.gmail.com>

> Thanks, that's right, so I've ported this part to R-devel and R-patched,

I noticed R-devel no longer complains about this from a while ago, thanks.

> With R.version$crt, you can already get a make (or even environment)
> variable. Writing R Extensions has examples how to invoke R in make
> files to get "R CMD config" values, so here you would invoke "Rscript"
> instead with one of the conditions above.

This slipped my mind, thanks for pointing it out! Yes, this works
perfectly without configure.ucrt. I will stick with this at least for
a while until the next version of R gets released.

> ... The .ucrt
> files are easier to maintain in hot-patches, but that is not an
> advantage for package authors.

I see, I think now I get your point. So, even if all the package
authors would choose to use the Rscript way, the .ucrt files would be
still needed to make room for the (R? or CRAN?) maintainers to
hot-patch the packages that don't work on UCRT nicely. Thanks for all
the efforts to make the UCRT R a reality.

Best,
Hiroaki Yutani

2021?9?24?(?) 2:16 Tomas Kalibera <tomas.kalibera at gmail.com>:


>
>
> On 9/20/21 11:03 AM, Hiroaki Yutani wrote:
> > I tried to use configure.ucrt, and found it results in the following
> > NOTE on the released version of R, unfortunately.
> >
> >      * checking top-level files ... NOTE
> >      Non-standard file/directory found at top level:
> >      'configure.ucrt'
> >
> > Will this be accepted by CRAN if I submit a package that contains
> > configure.ucrt? Or, is it too early to use it in a CRAN package?
>
> Thanks, that's right, so I've ported this part to R-devel and R-patched,
> configure.ucrt and cleanup.ucrt will be treated as "standard". There is
> nothing we can do about already released versions, the NOTE will appear.
>
> You can also use configure.win and branch on R.version$crt, e.g.
>
> !is.null(R.version$crt) && R.version$crt == "ucrt"
>
> or
>
> identical(R.version$crt, "ucrt")
>
> > In either case, while I don't have a strong opinion here, I'm starting
> > to feel that it might be preferable to provide an environmental
> > variable rather than creating ".ucrt" versions of files. In my
> > understanding, the plan is to switch all the Windows R to UCRT at some
> > point in future. But, it's not clear to me how to unify these ".win"
> > files and ".ucrt" files smoothly.
>
> With R.version$crt, you can already get a make (or even environment)
> variable. Writing R Extensions has examples how to invoke R in make
> files to get "R CMD config" values, so here you would invoke "Rscript"
> instead with one of the conditions above.
>
> Either is fine. With .ucrt files, you can avoid copy pasting of common
> code using "include" directives. With the variable, you can use make
> conditionals. As you found now, with the variable you have the advantage
> of not getting a NOTE with already released versions of R. The .ucrt
> files are easier to maintain in hot-patches, but that is not an
> advantage for package authors.
>
> Once a package depends on a version of R that will already use UCRT, one
> either would refactor/remove the conditionals, or integrate the ".ucrt"
> files back into the ".win". So, in the long term, there should be no
> conditionals on R.version$crt nor ".ucrt" files.
>
> Best
> Tomas
> > Best,
> > Hiroaki Yutani
> >
> > 2021?9?14?(?) 23:44 Hiroaki Yutani <yutani.ini at gmail.com>:
> >
> >> Thanks for both, I'll try these features.
> >>
> >> 2021?9?14?(?) 22:40 Tomas Kalibera <tomas.kalibera at gmail.com>:
> >>
> >>>
> >>> On 9/9/21 5:54 AM, Hiroaki Yutani wrote:
> >>>
> >>> Thank you for the prompt reply.
> >>>
> >>>> There in not such a mechanism, yet, but can be added, at least for
> >>>> diagnostics.
> >>> For example, can R.version somehow contain the information?
> >>>
> >>> Yes, now added to the experimental builds. R.version$crt contains "ucrt" (and would contain "msvcrt" if R was built against MSVCRT).
> >>>
> >>>
> >>>> We could add support for configure.ucrt, which would take precedence
> >>>> over configure.win on the UCRT builds (like Makevars.ucrt takes
> >>>> precedence over Makevars.win). Would that work for you?
> >>> Yes, configure.ucrt should work for me. There might be someone who prefers to switch by some envvar rather than creating another file, but I don't have a strong opinion here.
> >>>
> >>> The experimental builds now support configure.ucrt and cleanup.ucrt files.
> >>>
> >>> Best
> >>> Tomas
> >>>
> >>>
> >>> Best,
> >>> Hiroaki Yutani
> >>>
> >>> 2021?9?9?(?) 0:48 Tomas Kalibera <tomas.kalibera at gmail.com>:
> >>>>
> >>>> On 9/8/21 2:08 PM, Hiroaki Yutani wrote:
> >>>>> Hi,
> >>>>>
> >>>>> Are there any proper ways to know whether the session is running on
> >>>>> the R that is built with the UCRT toolchain or not? Checking if the
> >>>>> encoding is UTF-8 might do the trick, but I'm not sure if it's always
> >>>>> reliable.
> >>>> There in not such a mechanism, yet, but can be added, at least for
> >>>> diagnostics.
> >>>>
> >>>> You are right that checking for UTF-8 encoding would not always be
> >>>> reliable. For example, the version of Windows may be too old to allow R
> >>>> use UTF-8 as native encoding (e.g. Windows server 2016), then R will use
> >>>> the native code page as it does today in the MSVCRT builds.
> >>>>
> >>>>> Also, I'd like to know if there's any mechanism to detect the UCRT in
> >>>>> configure.win. I know there are Makevars.ucrt and Makefile.ucrt, but
> >>>>> one might want to do some feature test that is specific to the UCRT
> >>>>> toolchain.
> >>>> We could add support for configure.ucrt, which would take precedence
> >>>> over configure.win on the UCRT builds (like Makevars.ucrt takes
> >>>> precedence over Makevars.win). Would that work for you?
> >>>>
> >>>> Best
> >>>> Tomas
> >>>>
> >>>>> Best,
> >>>>> Hiroaki Yutani
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-devel at r-project.org mailing list
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-devel


From Thom@@@SOEIRO @end|ng |rom @p-hm@|r  Wed Sep 29 16:59:43 2021
From: Thom@@@SOEIRO @end|ng |rom @p-hm@|r (SOEIRO Thomas)
Date: Wed, 29 Sep 2021 14:59:43 +0000
Subject: [Rd] trunc.Date and round.Date + documentation of DateTimeClasses
Message-ID: <53f342303f1c4fc7b27e4a5f829d80f4@SCWPR-EXDAG1-6A.aphm.ap-hm.fr>

Dear All,

1) trunc.Date and round.Date:

Currently, the help page for trunc.Date and round.Date says "The methods for class "Date" are of little use except to remove fractional days". However, e.g., trunc.POSIXt(Sys.Date(), "years") and round.POSIXt(Sys.Date(), "years") work because the functions start with x <- as.POSIXlt(x).

Would you consider a simple implementation of trunc.Date and round.Date based on trunc.POSIXt and round.POSIXt? This would enable to avoid coercion from Date to POSIXt and back to Date for these simple manipulations.

For example:
# (I do not have a clear understanding of what "remove fractional days" means, and I did not implement it.)
	
trunc.Date2 <-
  function(x, units = c("days", "months", "years"), ...)
  {
    units <- match.arg(units)
    x <- as.POSIXlt(x)
    
    switch(units,
           "days" = {
             x$sec[] <- 0; x$min[] <- 0L; x$hour[] <- 0L;
             x$isdst[] <- -1L
           },
           "months" = {
             x$sec[] <- 0; x$min[] <- 0L; x$hour[] <- 0L;
             x$mday[] <- 1L
             x$isdst[] <- -1L
           },
           "years" = {
             x$sec[] <- 0; x$min[] <- 0L; x$hour[] <- 0L;
             x$mday[] <- 1L; x$mon[] <- 0L
             x$isdst[] <- -1L
           }
    )
    as.Date(x)
  }



2) documentation of DateTimeClasses:

It may be useful to add in the documentation of DateTimeClasses that manipulating elements of POSIXlt objects may results in "invalid" entries (e.g., mon = 12 or mday = 0), but that the object is nevertheless correctly printed/coerced.

Is this behavior explicitly supported?

d <- as.POSIXlt("2000-01-01")
unclass(d)
d$mon <- d$mon + 12
d$mday <- d$ mday - 1
unclass(d)
d
d <- as.POSIXlt(as.POSIXct(d))
dput(d)



Best,

Thomas


From Andre@G||||bert @end|ng |rom chu-rouen@|r  Thu Sep 30 12:52:38 2021
From: Andre@G||||bert @end|ng |rom chu-rouen@|r (GILLIBERT, Andre)
Date: Thu, 30 Sep 2021 10:52:38 +0000
Subject: [Rd] Workaround very slow NAN/Infinities arithmetic?
Message-ID: <3eebe90a11cc42e1a14a41b407e40690@chu-rouen.fr>

Dear R developers,

By default, R uses the "long double" data type to get extra precision for intermediate computations, with a small performance tradeoff.

Unfortunately, on all Intel x86 computers I have ever seen, long doubles (implemented in the x87 FPU) are extremely slow whenever a special representation (NA, NaN or infinities) is used; probably because it triggers poorly optimized microcode in the CPU firmware. A function such as sum() becomes more than hundred times slower!
Test code:
a=runif(1e7);system.time(for(i in 1:100)sum(a))
b=a;b[1]=NA;system.time(sum(b))

The slowdown factors are as follows on a few intel CPU:

1)      Pentium Gold G5400 (Coffee Lake, 8th generation) with R 64 bits : 140 times slower with NA

2)      Pentium G4400 (Skylake, 6th generation) with R 64 bits : 150 times slower with NA

3)      Pentium G3220 (Haswell, 4th generation) with R 64 bits : 130 times slower with NA

4)      Celeron J1900 (Atom Silvermont) with R 64 bits : 45 times slower with NA

I do not have access to more recent Intel CPUs, but I doubt that it has improved much.

Recent AMD CPUs have no significant slowdown.
There is no significant slowdown on Intel CPUs (more recent than Sandy Bridge) for 64 bits floating point calculations based on SSE2. Therefore, operators using doubles, such as '+' are unaffected.

I do not know whether recent ARM CPUs have slowdowns on FP64... Maybe somebody can test.

Since NAs are not rare in real-life, I think that it would worth an extra check in functions based on long doubles, such as sum(). The check for special representations do not necessarily have to be done at each iteration for cumulative functions.
If you are interested, I can write a bunch of patches to fix the main functions using long doubles: cumsum, cumprod, sum, prod, rowSums, colSums, matrix multiplication (matprod="internal").

What do you think of that?

--
Sincerely
Andr? GILLIBERT

	[[alternative HTML version deleted]]


From Thom@@@SOEIRO @end|ng |rom @p-hm@|r  Thu Sep 30 12:32:32 2021
From: Thom@@@SOEIRO @end|ng |rom @p-hm@|r (SOEIRO Thomas)
Date: Thu, 30 Sep 2021 10:32:32 +0000
Subject: [Rd] 
 trunc.Date and round.Date + documentation of DateTimeClasses
Message-ID: <e390399864c94399914bb1dacc53300e@SCWPR-EXDAG1-6A.aphm.ap-hm.fr>

About fractional days, trunc.Date2 actually seems to have no regression and to be backward compatible compared to the original trunc.Date:

frac <- as.Date("2020-01-01") + 0.5
identical(trunc(frac), trunc.Date2(frac))

(I may still miss something since I do not understand how trunc.Date manage fractional days with round(x - 0.4999999).)

-----Message d'origine-----
De?: SOEIRO Thomas 
Envoy??: mercredi 29 septembre 2021 17:00
??: 'r-devel at r-project.org'
Objet?: trunc.Date and round.Date + documentation of DateTimeClasses

Dear All,

1) trunc.Date and round.Date:

Currently, the help page for trunc.Date and round.Date says "The methods for class "Date" are of little use except to remove fractional days". However, e.g., trunc.POSIXt(Sys.Date(), "years") and round.POSIXt(Sys.Date(), "years") work because the functions start with x <- as.POSIXlt(x).

Would you consider a simple implementation of trunc.Date and round.Date based on trunc.POSIXt and round.POSIXt? This would enable to avoid coercion from Date to POSIXt and back to Date for these simple manipulations.

For example:
# (I do not have a clear understanding of what "remove fractional days" means, and I did not implement it.)
	
trunc.Date2 <-
  function(x, units = c("days", "months", "years"), ...)
  {
    units <- match.arg(units)
    x <- as.POSIXlt(x)
    
    switch(units,
           "days" = {
             x$sec[] <- 0; x$min[] <- 0L; x$hour[] <- 0L;
             x$isdst[] <- -1L
           },
           "months" = {
             x$sec[] <- 0; x$min[] <- 0L; x$hour[] <- 0L;
             x$mday[] <- 1L
             x$isdst[] <- -1L
           },
           "years" = {
             x$sec[] <- 0; x$min[] <- 0L; x$hour[] <- 0L;
             x$mday[] <- 1L; x$mon[] <- 0L
             x$isdst[] <- -1L
           }
    )
    as.Date(x)
  }



2) documentation of DateTimeClasses:

It may be useful to add in the documentation of DateTimeClasses that manipulating elements of POSIXlt objects may results in "invalid" entries (e.g., mon = 12 or mday = 0), but that the object is nevertheless correctly printed/coerced.

Is this behavior explicitly supported?

d <- as.POSIXlt("2000-01-01")
unclass(d)
d$mon <- d$mon + 12
d$mday <- d$ mday - 1
unclass(d)
d
d <- as.POSIXlt(as.POSIXct(d))
dput(d)



Best,

Thomas


From brod|e@g@@|@m @end|ng |rom y@hoo@com  Thu Sep 30 14:27:47 2021
From: brod|e@g@@|@m @end|ng |rom y@hoo@com (brodie gaslam)
Date: Thu, 30 Sep 2021 12:27:47 +0000 (UTC)
Subject: [Rd] Workaround very slow NAN/Infinities arithmetic?
In-Reply-To: <3eebe90a11cc42e1a14a41b407e40690@chu-rouen.fr>
References: <3eebe90a11cc42e1a14a41b407e40690@chu-rouen.fr>
Message-ID: <1810868025.554414.1633004867238@mail.yahoo.com>


Andr?,

I'm not an R core member, but happen to have looked a little bit at this
issue myself.? I've seen similar things on Skylake and Coffee Lake 2
(9700, one generation past your latest) too.? I think it would make sense
to have some handling of this, although I would want to show the trade-off
with performance impacts on CPUs that are not affected by this, and on
vectors that don't actually have NAs and similar.? I think the performance
impact is likely to be small so long as branch prediction is active, but
since branch prediction is involved you might need to check with different
ratios of NAs (not for your NA bailout branch, but for e.g. interaction
of what you add and the existing `na.rm=TRUE` logic).

You'll also need to think of cases such as c(Inf, NA), c(NaN, NA), etc.,
which might complicate the logic a fair bit.

Presumably the x87 FPU will remain common for a long time, but if there
was reason to think otherwise, then the value of this becomes
questionable.

Either way, I would probably wait to see what R Core says.

For reference this 2012 blog post[1] discusses some aspects of the issue,
including that at least "historically" AMD was not affected.

Since we're on the topic I want to point out that the default NA in R
starts off as a signaling NA:

??? example(numToBits)?? # for `bitC`
??? bitC(NA_real_)
??? ## [1] 0 11111111111 | 0000000000000000000000000000000000000000011110100010
??? bitC(NA_real_ + 0)
??? ## [1] 0 11111111111 | 1000000000000000000000000000000000000000011110100010

Notice the leading bit of the significant starts off as zero, which marks
it as a signaling NA, but becomes 1, i.e. non-signaling, after any
operation[2].

This is meaningful because the mere act of loading a signaling NA into the
x87 FPU is sufficient to trigger the slowdowns, even if the NA is not
actually used in arithmetic operations.? This happens sometimes under some
optimization levels.? I don't now of any benefit of starting off with a
signaling NA, especially since the encoding is lost pretty much as soon as
it is used.? If folks are interested I can provide patch to turn the NA
quiet by default.

Best,

B.

[1]: https://randomascii.wordpress.com/2012/05/20/thats-not-normalthe-performance-of-odd-floats/
[2]: https://en.wikipedia.org/wiki/NaN#Encoding





> On Thursday, September 30, 2021, 06:52:59 AM EDT, GILLIBERT, Andre <andre.gillibert at chu-rouen.fr> wrote:
>
> Dear R developers,
>
> By default, R uses the "long double" data type to get extra precision for intermediate computations, with a small performance tradeoff.
>
> Unfortunately, on all Intel x86 computers I have ever seen, long doubles (implemented in the x87 FPU) are extremely slow whenever a special representation (NA, NaN or infinities) is used; probably because it triggers poorly optimized microcode in the CPU firmware. A function such as sum() becomes more than hundred times slower!
> Test code:
> a=runif(1e7);system.time(for(i in 1:100)sum(a))
> b=a;b[1]=NA;system.time(sum(b))
>
> The slowdown factors are as follows on a few intel CPU:
>
> 1)????? Pentium Gold G5400 (Coffee Lake, 8th generation) with R 64 bits : 140 times slower with NA
>
> 2)????? Pentium G4400 (Skylake, 6th generation) with R 64 bits : 150 times slower with NA
>
> 3)????? Pentium G3220 (Haswell, 4th generation) with R 64 bits : 130 times slower with NA
>
> 4)????? Celeron J1900 (Atom Silvermont) with R 64 bits : 45 times slower with NA
>
> I do not have access to more recent Intel CPUs, but I doubt that it has improved much.
>
> Recent AMD CPUs have no significant slowdown.
> There is no significant slowdown on Intel CPUs (more recent than Sandy Bridge) for 64 bits floating point calculations based on SSE2. Therefore, operators using doubles, such as '+' are unaffected.
>
> I do not know whether recent ARM CPUs have slowdowns on FP64... Maybe somebody can test.
>
> Since NAs are not rare in real-life, I think that it would worth an extra check in functions based on long doubles, such as sum(). The check for special representations do not necessarily have to be done at each iteration for cumulative functions.
> If you are interested, I can write a bunch of patches to fix the main functions using long doubles: cumsum, cumprod, sum, prod, rowSums, colSums, matrix multiplication (matprod="internal").
>
> What do you think of that?
>
> --
> Sincerely
> Andr? GILLIBERT
>
>???? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Thu Sep 30 15:27:00 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 30 Sep 2021 15:27:00 +0200
Subject: [Rd] 
 trunc.Date and round.Date + documentation of DateTimeClasses
In-Reply-To: <e390399864c94399914bb1dacc53300e@SCWPR-EXDAG1-6A.aphm.ap-hm.fr>
References: <e390399864c94399914bb1dacc53300e@SCWPR-EXDAG1-6A.aphm.ap-hm.fr>
Message-ID: <24917.47908.119439.446125@stat.math.ethz.ch>

Excuse the exceptional top-reply:

Note that a very related issue has been raised not so long ago
by Dirk (in CC) on R's Bugzilla :

  trunc.Date should support months and years arguments as trunc.POSIXt does 
  https://bugs.r-project.org/show_bug.cgi?id=18099

which had some agreement (also with you: I agree we should
change something about this) but I also had proposed to approach
it more generally than in the PR .. which you already did by
mentioning trunc() and round() methods together.

Still, Dirk's proposal would try harder to remain back
compatible in those cases where  trunc.Date() currently does
"behave as it should".

Martin Maechler
ETH Zurich  and  R Core

>>>>> SOEIRO Thomas 
>>>>>     on Thu, 30 Sep 2021 10:32:32 +0000 writes:

    > About fractional days, trunc.Date2 actually seems to have no regression and to be backward compatible compared to the original trunc.Date:

    > frac <- as.Date("2020-01-01") + 0.5
    > identical(trunc(frac), trunc.Date2(frac))

    > (I may still miss something since I do not understand how
    > trunc.Date manage fractional days with round(x - 0.4999999).)

    > -----Message d'origine-----
    > De?: SOEIRO Thomas 
    > Envoy??: mercredi 29 septembre 2021 17:00
    > ??: 'r-devel at r-project.org'
    > Objet?: trunc.Date and round.Date + documentation of DateTimeClasses

    > Dear All,

    > 1) trunc.Date and round.Date:

    > Currently, the help page for trunc.Date and round.Date
    > says "The methods for class "Date" are of little use
    > except to remove fractional days". However, e.g.,
    > trunc.POSIXt(Sys.Date(), "years") and
    > round.POSIXt(Sys.Date(), "years") work because the
    > functions start with x <- as.POSIXlt(x).

    > Would you consider a simple implementation of trunc.Date
    > and round.Date based on trunc.POSIXt and round.POSIXt?
    > This would enable to avoid coercion from Date to POSIXt
    > and back to Date for these simple manipulations.

    > For example:
    > # (I do not have a clear understanding of what "remove fractional days" means, and I did not implement it.)
	
> trunc.Date2 <-
>   function(x, units = c("days", "months", "years"), ...)
>   {
>     units <- match.arg(units)
>     x <- as.POSIXlt(x)
>     
>     switch(units,
>            "days" = {
>              x$sec[] <- 0; x$min[] <- 0L; x$hour[] <- 0L;
>              x$isdst[] <- -1L
>            },
>            "months" = {
>              x$sec[] <- 0; x$min[] <- 0L; x$hour[] <- 0L;
>              x$mday[] <- 1L
>              x$isdst[] <- -1L
>            },
>            "years" = {
>              x$sec[] <- 0; x$min[] <- 0L; x$hour[] <- 0L;
>              x$mday[] <- 1L; x$mon[] <- 0L
>              x$isdst[] <- -1L
>            }
>     )
>     as.Date(x)
>   }



    > 2) documentation of DateTimeClasses:

    > It may be useful to add in the documentation of
    > DateTimeClasses that manipulating elements of POSIXlt
    > objects may results in "invalid" entries (e.g., mon = 12
    > or mday = 0), but that the object is nevertheless
    > correctly printed/coerced.

    > Is this behavior explicitly supported?

    > d <- as.POSIXlt("2000-01-01")
    > unclass(d)
    > d$mon <- d$mon + 12
    > d$mday <- d$ mday - 1
    > unclass(d)
    > d
    > d <- as.POSIXlt(as.POSIXct(d))
    > dput(d)



    > Best,
    > Thomas


From Thom@@@SOEIRO @end|ng |rom @p-hm@|r  Thu Sep 30 16:09:12 2021
From: Thom@@@SOEIRO @end|ng |rom @p-hm@|r (SOEIRO Thomas)
Date: Thu, 30 Sep 2021 14:09:12 +0000
Subject: [Rd] 
 trunc.Date and round.Date + documentation of DateTimeClasses
In-Reply-To: <24917.47908.119439.446125@stat.math.ethz.ch>
References: <e390399864c94399914bb1dacc53300e@SCWPR-EXDAG1-6A.aphm.ap-hm.fr>
 <24917.47908.119439.446125@stat.math.ethz.ch>
Message-ID: <3881423dcd97410d90c72aedd24f5c62@SCWPR-EXDAG1-6A.aphm.ap-hm.fr>

Sorry for missing the issue on Bugzilla with Dirk's (better) proposal before posting on the list. I agree adding the whole family (ceiling(), floor(), trunc(x), and round ()) would be very useful (while it may be useful to provide the enhanced trunc.Date in the meantime). I unfortunately don't have the skills to contribute for the related functions. In any case thanks for all the work!

In addition, what do you think about the second proposal? (documentation of DateTimeClasses)

-----Message d'origine-----
De?: Martin Maechler [mailto:maechler at stat.math.ethz.ch] 
Envoy??: jeudi 30 septembre 2021 15:27
??: SOEIRO Thomas
Cc?: r-devel at r-project.org; Dirk Eddelbuettel
Objet?: Re: [Rd] trunc.Date and round.Date + documentation of DateTimeClasses

EMAIL EXTERNE - TRAITER AVEC PR?CAUTION LIENS ET FICHIERS

Excuse the exceptional top-reply:

Note that a very related issue has been raised not so long ago by Dirk (in CC) on R's Bugzilla :

  trunc.Date should support months and years arguments as trunc.POSIXt does
  https://urldefense.com/v3/__https://bugs.r-project.org/show_bug.cgi?id=18099__;!!JQ5agg!IcA4cGE0MAGw1HNXz9F5WN_MhMReK2hNeT997bHYUMwGr3_tISpW0NTUF1Ll1MMV614A$

which had some agreement (also with you: I agree we should change something about this) but I also had proposed to approach it more generally than in the PR .. which you already did by mentioning trunc() and round() methods together.

Still, Dirk's proposal would try harder to remain back compatible in those cases where  trunc.Date() currently does "behave as it should".

Martin Maechler
ETH Zurich  and  R Core

>>>>> SOEIRO Thomas
>>>>>     on Thu, 30 Sep 2021 10:32:32 +0000 writes:

    > About fractional days, trunc.Date2 actually seems to have no regression and to be backward compatible compared to the original trunc.Date:

    > frac <- as.Date("2020-01-01") + 0.5
    > identical(trunc(frac), trunc.Date2(frac))

    > (I may still miss something since I do not understand how
    > trunc.Date manage fractional days with round(x - 0.4999999).)

    > -----Message d'origine-----
    > De : SOEIRO Thomas
    > Envoy? : mercredi 29 septembre 2021 17:00
    > ? : 'r-devel at r-project.org'
    > Objet : trunc.Date and round.Date + documentation of DateTimeClasses

    > Dear All,

    > 1) trunc.Date and round.Date:

    > Currently, the help page for trunc.Date and round.Date
    > says "The methods for class "Date" are of little use
    > except to remove fractional days". However, e.g.,
    > trunc.POSIXt(Sys.Date(), "years") and
    > round.POSIXt(Sys.Date(), "years") work because the
    > functions start with x <- as.POSIXlt(x).

    > Would you consider a simple implementation of trunc.Date
    > and round.Date based on trunc.POSIXt and round.POSIXt?
    > This would enable to avoid coercion from Date to POSIXt
    > and back to Date for these simple manipulations.

    > For example:
    > # (I do not have a clear understanding of what "remove fractional days" means, and I did not implement it.)

> trunc.Date2 <-
>   function(x, units = c("days", "months", "years"), ...)
>   {
>     units <- match.arg(units)
>     x <- as.POSIXlt(x)
>
>     switch(units,
>            "days" = {
>              x$sec[] <- 0; x$min[] <- 0L; x$hour[] <- 0L;
>              x$isdst[] <- -1L
>            },
>            "months" = {
>              x$sec[] <- 0; x$min[] <- 0L; x$hour[] <- 0L;
>              x$mday[] <- 1L
>              x$isdst[] <- -1L
>            },
>            "years" = {
>              x$sec[] <- 0; x$min[] <- 0L; x$hour[] <- 0L;
>              x$mday[] <- 1L; x$mon[] <- 0L
>              x$isdst[] <- -1L
>            }
>     )
>     as.Date(x)
>   }



    > 2) documentation of DateTimeClasses:

    > It may be useful to add in the documentation of
    > DateTimeClasses that manipulating elements of POSIXlt
    > objects may results in "invalid" entries (e.g., mon = 12
    > or mday = 0), but that the object is nevertheless
    > correctly printed/coerced.

    > Is this behavior explicitly supported?

    > d <- as.POSIXlt("2000-01-01")
    > unclass(d)
    > d$mon <- d$mon + 12
    > d$mday <- d$ mday - 1
    > unclass(d)
    > d
    > d <- as.POSIXlt(as.POSIXct(d))
    > dput(d)



    > Best,
    > Thomas


From Andre@G||||bert @end|ng |rom chu-rouen@|r  Thu Sep 30 18:06:43 2021
From: Andre@G||||bert @end|ng |rom chu-rouen@|r (GILLIBERT, Andre)
Date: Thu, 30 Sep 2021 16:06:43 +0000
Subject: [Rd] Workaround very slow NAN/Infinities arithmetic?
In-Reply-To: <1810868025.554414.1633004867238@mail.yahoo.com>
References: <3eebe90a11cc42e1a14a41b407e40690@chu-rouen.fr>
 <1810868025.554414.1633004867238@mail.yahoo.com>
Message-ID: <eb46ebcf7c7b4d5f8ea8af58d7a29d18@chu-rouen.fr>

Brodie Gaslam wrote:
> Andr?,

> I'm not an R core member, but happen to have looked a little bit at this
> issue myself.  I've seen similar things on Skylake and Coffee Lake 2
> (9700, one generation past your latest) too.  I think it would make sense
> to have some handling of this, although I would want to show the trade-off
> with performance impacts on CPUs that are not affected by this, and on
> vectors that don't actually have NAs and similar.  I think the performance
> impact is likely to be small so long as branch prediction is active, but
> since branch prediction is involved you might need to check with different
> ratios of NAs (not for your NA bailout branch, but for e.g. interaction
> of what you add and the existing `na.rm=TRUE` logic).

For operators such as '+', randomly placed NAs could slow down AMD processor due to many branch mispredictions. However, the functions using long doubles are mainly "cumulative" functions such as sum, mean, cumsum, etc. They can stop at the first NA found.

> You'll also need to think of cases such as c(Inf, NA), c(NaN, NA), etc.,
> which might complicate the logic a fair bit.

When an infinity is found, the rest of the vector must be searched for infinities of the opposite side or NAs.
Mixing NaN and NAs has always been platform-dependent in R, but, on x87, it seems that the first NA/NaN met wins. Being consistent with that behavior is easy.

I wrote a first patch for the sum() function, taking in account all those special +Inf/-Inf/NA/NaN cases. Without any NA, the sum() function was 1.6% slower with my first patch on a Celeron J1900. Not a big deal, in my opinion.

However, I could easily compensate that loss (and much more) by improving the code.
By splitting the na.rm=TRUE and na.rm=FALSE code paths, I could save a useless FP comparison (for NAN), a useless CMOV (for the 'updated' variable) and useless SSE->memory->FP87 moves (high latency).

My new code is x1.75 times faster, for sum(big_vector_without_NAs, na.rm=FALSE).
It is x1.35 times faster for sum(big_vector_without_NAs, na.rm=TRUE)

Of course, it is much faster if there are any NA, because it stops at the first NA found. For infinities on AMD CPUs, it may not necessarily be faster.

-- 
Sincerely
Andr? GILLIBERT

From iuke-tier@ey m@iii@g oii uiow@@edu  Thu Sep 30 19:24:53 2021
From: iuke-tier@ey m@iii@g oii uiow@@edu (iuke-tier@ey m@iii@g oii uiow@@edu)
Date: Thu, 30 Sep 2021 12:24:53 -0500 (CDT)
Subject: [Rd] 
 [External] Re: Workaround very slow NAN/Infinities arithmetic?
In-Reply-To: <1810868025.554414.1633004867238@mail.yahoo.com>
References: <3eebe90a11cc42e1a14a41b407e40690@chu-rouen.fr>
 <1810868025.554414.1633004867238@mail.yahoo.com>
Message-ID: <alpine.DEB.2.22.394.2109301143220.2872@luke-Latitude-7480>

On Thu, 30 Sep 2021, brodie gaslam via R-devel wrote:

>
> Andr?,
>
> I'm not an R core member, but happen to have looked a little bit at this
> issue myself.? I've seen similar things on Skylake and Coffee Lake 2
> (9700, one generation past your latest) too.? I think it would make sense
> to have some handling of this, although I would want to show the trade-off
> with performance impacts on CPUs that are not affected by this, and on
> vectors that don't actually have NAs and similar.? I think the performance
> impact is likely to be small so long as branch prediction is active, but
> since branch prediction is involved you might need to check with different
> ratios of NAs (not for your NA bailout branch, but for e.g. interaction
> of what you add and the existing `na.rm=TRUE` logic).

I would want to see realistic examples where this matters, not
microbenchmarks, before thinking about complicating the code. Not all
but most cases where sum(x) returns NaN/NA would eventually result in
an error; getting to the error faster is not likely to be useful.

My understanding is that arm64 does not support proper long doubles
(they are the same as regular doubles). So code using long doubles
isn't getting the hoped-for improved precision. Since that
architecture is becoming more common we should probably be looking at
replacing uses of long doubles with better algorithms that can work
with regular doubles, e.g Kahan summation or variants for sum.

> You'll also need to think of cases such as c(Inf, NA), c(NaN, NA), etc.,
> which might complicate the logic a fair bit.
>
> Presumably the x87 FPU will remain common for a long time, but if there
> was reason to think otherwise, then the value of this becomes
> questionable.
>
> Either way, I would probably wait to see what R Core says.
>
> For reference this 2012 blog post[1] discusses some aspects of the issue,
> including that at least "historically" AMD was not affected.
>
> Since we're on the topic I want to point out that the default NA in R
> starts off as a signaling NA:
>
> ??? example(numToBits)?? # for `bitC`
> ??? bitC(NA_real_)
> ??? ## [1] 0 11111111111 | 0000000000000000000000000000000000000000011110100010
> ??? bitC(NA_real_ + 0)
> ??? ## [1] 0 11111111111 | 1000000000000000000000000000000000000000011110100010
>
> Notice the leading bit of the significant starts off as zero, which marks
> it as a signaling NA, but becomes 1, i.e. non-signaling, after any
> operation[2].
>
> This is meaningful because the mere act of loading a signaling NA into the
> x87 FPU is sufficient to trigger the slowdowns, even if the NA is not
> actually used in arithmetic operations.? This happens sometimes under some
> optimization levels.? I don't now of any benefit of starting off with a
> signaling NA, especially since the encoding is lost pretty much as soon as
> it is used.? If folks are interested I can provide patch to turn the NA
> quiet by default.

In principle this might be a good idea, but the current bit pattern is
unfortunately baked into a number of packages and documents on
internals, as well as serialized objects. The work needed to sort that
out is probably not worth the effort.

It also doesn't seem to affect the performance issue here since
setting b[1] <- NA_real_ + 0 produces the same slowdown (at least on
my current Intel machine).

Best,

luke

>
> Best,
>
> B.
>
> [1]: https://randomascii.wordpress.com/2012/05/20/thats-not-normalthe-performance-of-odd-floats/
> [2]: https://en.wikipedia.org/wiki/NaN#Encoding
>
>
>
>
>
>> On Thursday, September 30, 2021, 06:52:59 AM EDT, GILLIBERT, Andre <andre.gillibert at chu-rouen.fr> wrote:
>>
>> Dear R developers,
>>
>> By default, R uses the "long double" data type to get extra precision for intermediate computations, with a small performance tradeoff.
>>
>> Unfortunately, on all Intel x86 computers I have ever seen, long doubles (implemented in the x87 FPU) are extremely slow whenever a special representation (NA, NaN or infinities) is used; probably because it triggers poorly optimized microcode in the CPU firmware. A function such as sum() becomes more than hundred times slower!
>> Test code:
>> a=runif(1e7);system.time(for(i in 1:100)sum(a))
>> b=a;b[1]=NA;system.time(sum(b))
>>
>> The slowdown factors are as follows on a few intel CPU:
>>
>> 1)????? Pentium Gold G5400 (Coffee Lake, 8th generation) with R 64 bits : 140 times slower with NA
>>
>> 2)????? Pentium G4400 (Skylake, 6th generation) with R 64 bits : 150 times slower with NA
>>
>> 3)????? Pentium G3220 (Haswell, 4th generation) with R 64 bits : 130 times slower with NA
>>
>> 4)????? Celeron J1900 (Atom Silvermont) with R 64 bits : 45 times slower with NA
>>
>> I do not have access to more recent Intel CPUs, but I doubt that it has improved much.
>>
>> Recent AMD CPUs have no significant slowdown.
>> There is no significant slowdown on Intel CPUs (more recent than Sandy Bridge) for 64 bits floating point calculations based on SSE2. Therefore, operators using doubles, such as '+' are unaffected.
>>
>> I do not know whether recent ARM CPUs have slowdowns on FP64... Maybe somebody can test.
>>
>> Since NAs are not rare in real-life, I think that it would worth an extra check in functions based on long doubles, such as sum(). The check for special representations do not necessarily have to be done at each iteration for cumulative functions.
>> If you are interested, I can write a bunch of patches to fix the main functions using long doubles: cumsum, cumprod, sum, prod, rowSums, colSums, matrix multiplication (matprod="internal").
>>
>> What do you think of that?
>>
>> --
>> Sincerely
>> Andr? GILLIBERT
>>
>> ???? [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From g@bembecker @end|ng |rom gm@||@com  Thu Sep 30 22:05:28 2021
From: g@bembecker @end|ng |rom gm@||@com (Gabriel Becker)
Date: Thu, 30 Sep 2021 13:05:28 -0700
Subject: [Rd] 
 [External] Re: Workaround very slow NAN/Infinities arithmetic?
In-Reply-To: <alpine.DEB.2.22.394.2109301143220.2872@luke-Latitude-7480>
References: <3eebe90a11cc42e1a14a41b407e40690@chu-rouen.fr>
 <1810868025.554414.1633004867238@mail.yahoo.com>
 <alpine.DEB.2.22.394.2109301143220.2872@luke-Latitude-7480>
Message-ID: <CAD4oTHE7MeOYG3MRbHbwHS76HpHj783__ku0GoNQN9iqOvvxUg@mail.gmail.com>

Mildly related (?) to this discussion, if you happen to be in a situation
where you know something is a C NAN, but need to check if its a proper R
NA, the R_IsNA function is surprisingly (to me, at least) expensive to do
in a tight loop because it calls the (again, surprisingly expensive to me)
isnan function.  This can happen in known sorted  Altrep REALSXPs where you
can easily determine the C-NAN status of all elements in the vector with a
binary search for the edge of the NANs, so in O(logn) calls to R_isnan. You
could notably also determine finiteness of all elements this way with a
couple more O(logn) passes if you needed to in the sorted case.

This came up when I was developing the patch for the unique/duplicated
fastpass for known-sorted vectors (thanks to Michael for working with me on
that and putting it in); I ended up writing an NAN_IS_R_NA macro to avoid
that isnan call since it's known. This was necessary (well, helpful at
least) because unique/duplicated care about the difference between NA and
NaN, while sorting and REAL_NO_NA (because ALTREP metadata/behavior is
closely linked to sort behavior) do not. In the case where you have a lot
of NAN values of solely one type or the other (by far most often because
they are all NAs and none are NaNs) the difference in speedup was
noticeably significant as I recall. I don't have the numbers handy but I
could run them again if desired.

~G

On Thu, Sep 30, 2021 at 10:25 AM <luke-tierney at uiowa.edu> wrote:

> On Thu, 30 Sep 2021, brodie gaslam via R-devel wrote:
>
> >
> > Andr?,
> >
> > I'm not an R core member, but happen to have looked a little bit at this
> > issue myself.  I've seen similar things on Skylake and Coffee Lake 2
> > (9700, one generation past your latest) too.  I think it would make sense
> > to have some handling of this, although I would want to show the
> trade-off
> > with performance impacts on CPUs that are not affected by this, and on
> > vectors that don't actually have NAs and similar.  I think the
> performance
> > impact is likely to be small so long as branch prediction is active, but
> > since branch prediction is involved you might need to check with
> different
> > ratios of NAs (not for your NA bailout branch, but for e.g. interaction
> > of what you add and the existing `na.rm=TRUE` logic).
>
> I would want to see realistic examples where this matters, not
> microbenchmarks, before thinking about complicating the code. Not all
> but most cases where sum(x) returns NaN/NA would eventually result in
> an error; getting to the error faster is not likely to be useful.
>
> My understanding is that arm64 does not support proper long doubles
> (they are the same as regular doubles). So code using long doubles
> isn't getting the hoped-for improved precision. Since that
> architecture is becoming more common we should probably be looking at
> replacing uses of long doubles with better algorithms that can work
> with regular doubles, e.g Kahan summation or variants for sum.
>
> > You'll also need to think of cases such as c(Inf, NA), c(NaN, NA), etc.,
> > which might complicate the logic a fair bit.
> >
> > Presumably the x87 FPU will remain common for a long time, but if there
> > was reason to think otherwise, then the value of this becomes
> > questionable.
> >
> > Either way, I would probably wait to see what R Core says.
> >
> > For reference this 2012 blog post[1] discusses some aspects of the issue,
> > including that at least "historically" AMD was not affected.
> >
> > Since we're on the topic I want to point out that the default NA in R
> > starts off as a signaling NA:
> >
> >     example(numToBits)   # for `bitC`
> >     bitC(NA_real_)
> >     ## [1] 0 11111111111 |
> 0000000000000000000000000000000000000000011110100010
> >     bitC(NA_real_ + 0)
> >     ## [1] 0 11111111111 |
> 1000000000000000000000000000000000000000011110100010
> >
> > Notice the leading bit of the significant starts off as zero, which marks
> > it as a signaling NA, but becomes 1, i.e. non-signaling, after any
> > operation[2].
> >
> > This is meaningful because the mere act of loading a signaling NA into
> the
> > x87 FPU is sufficient to trigger the slowdowns, even if the NA is not
> > actually used in arithmetic operations.  This happens sometimes under
> some
> > optimization levels.  I don't now of any benefit of starting off with a
> > signaling NA, especially since the encoding is lost pretty much as soon
> as
> > it is used.  If folks are interested I can provide patch to turn the NA
> > quiet by default.
>
> In principle this might be a good idea, but the current bit pattern is
> unfortunately baked into a number of packages and documents on
> internals, as well as serialized objects. The work needed to sort that
> out is probably not worth the effort.
>
> It also doesn't seem to affect the performance issue here since
> setting b[1] <- NA_real_ + 0 produces the same slowdown (at least on
> my current Intel machine).
>
> Best,
>
> luke
>
> >
> > Best,
> >
> > B.
> >
> > [1]:
> https://randomascii.wordpress.com/2012/05/20/thats-not-normalthe-performance-of-odd-floats/
> > [2]: https://en.wikipedia.org/wiki/NaN#Encoding
> >
> >
> >
> >
> >
> >> On Thursday, September 30, 2021, 06:52:59 AM EDT, GILLIBERT, Andre <
> andre.gillibert at chu-rouen.fr> wrote:
> >>
> >> Dear R developers,
> >>
> >> By default, R uses the "long double" data type to get extra precision
> for intermediate computations, with a small performance tradeoff.
> >>
> >> Unfortunately, on all Intel x86 computers I have ever seen, long
> doubles (implemented in the x87 FPU) are extremely slow whenever a special
> representation (NA, NaN or infinities) is used; probably because it
> triggers poorly optimized microcode in the CPU firmware. A function such as
> sum() becomes more than hundred times slower!
> >> Test code:
> >> a=runif(1e7);system.time(for(i in 1:100)sum(a))
> >> b=a;b[1]=NA;system.time(sum(b))
> >>
> >> The slowdown factors are as follows on a few intel CPU:
> >>
> >> 1)      Pentium Gold G5400 (Coffee Lake, 8th generation) with R 64 bits
> : 140 times slower with NA
> >>
> >> 2)      Pentium G4400 (Skylake, 6th generation) with R 64 bits : 150
> times slower with NA
> >>
> >> 3)      Pentium G3220 (Haswell, 4th generation) with R 64 bits : 130
> times slower with NA
> >>
> >> 4)      Celeron J1900 (Atom Silvermont) with R 64 bits : 45 times
> slower with NA
> >>
> >> I do not have access to more recent Intel CPUs, but I doubt that it has
> improved much.
> >>
> >> Recent AMD CPUs have no significant slowdown.
> >> There is no significant slowdown on Intel CPUs (more recent than Sandy
> Bridge) for 64 bits floating point calculations based on SSE2. Therefore,
> operators using doubles, such as '+' are unaffected.
> >>
> >> I do not know whether recent ARM CPUs have slowdowns on FP64... Maybe
> somebody can test.
> >>
> >> Since NAs are not rare in real-life, I think that it would worth an
> extra check in functions based on long doubles, such as sum(). The check
> for special representations do not necessarily have to be done at each
> iteration for cumulative functions.
> >> If you are interested, I can write a bunch of patches to fix the main
> functions using long doubles: cumsum, cumprod, sum, prod, rowSums, colSums,
> matrix multiplication (matprod="internal").
> >>
> >> What do you think of that?
> >>
> >> --
> >> Sincerely
> >> Andr? GILLIBERT
> >>
> >>      [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
> --
> Luke Tierney
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>     Actuarial Science
> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


